Epoch: 1| Step: 0
Training loss: 4.895087242126465
Validation loss: 5.150945812143306

Epoch: 6| Step: 1
Training loss: 5.262399673461914
Validation loss: 5.137768648004019

Epoch: 6| Step: 2
Training loss: 5.882397174835205
Validation loss: 5.125536323875509

Epoch: 6| Step: 3
Training loss: 5.327546119689941
Validation loss: 5.113842595008112

Epoch: 6| Step: 4
Training loss: 4.170233249664307
Validation loss: 5.1029885917581534

Epoch: 6| Step: 5
Training loss: 5.593278884887695
Validation loss: 5.0917907376443186

Epoch: 6| Step: 6
Training loss: 3.869570732116699
Validation loss: 5.080199882548342

Epoch: 6| Step: 7
Training loss: 4.008670806884766
Validation loss: 5.068448000056769

Epoch: 6| Step: 8
Training loss: 4.981217384338379
Validation loss: 5.055593070163522

Epoch: 6| Step: 9
Training loss: 3.2438583374023438
Validation loss: 5.041928916849116

Epoch: 6| Step: 10
Training loss: 6.853604316711426
Validation loss: 5.027544431788947

Epoch: 6| Step: 11
Training loss: 5.208193302154541
Validation loss: 5.010719022443218

Epoch: 6| Step: 12
Training loss: 4.323634147644043
Validation loss: 4.993288334979806

Epoch: 6| Step: 13
Training loss: 4.289606094360352
Validation loss: 4.97527346047022

Epoch: 2| Step: 0
Training loss: 4.612751483917236
Validation loss: 4.954583209048035

Epoch: 6| Step: 1
Training loss: 4.300106048583984
Validation loss: 4.933251411684098

Epoch: 6| Step: 2
Training loss: 3.3143205642700195
Validation loss: 4.908315745733118

Epoch: 6| Step: 3
Training loss: 4.752900123596191
Validation loss: 4.881721311999906

Epoch: 6| Step: 4
Training loss: 3.517158269882202
Validation loss: 4.853390826973864

Epoch: 6| Step: 5
Training loss: 5.504087924957275
Validation loss: 4.823553972346808

Epoch: 6| Step: 6
Training loss: 4.330874443054199
Validation loss: 4.790510951831776

Epoch: 6| Step: 7
Training loss: 5.480770111083984
Validation loss: 4.756887271840085

Epoch: 6| Step: 8
Training loss: 5.7117438316345215
Validation loss: 4.718420684978526

Epoch: 6| Step: 9
Training loss: 4.581939220428467
Validation loss: 4.679686459161902

Epoch: 6| Step: 10
Training loss: 5.655703544616699
Validation loss: 4.639330115369571

Epoch: 6| Step: 11
Training loss: 4.166777610778809
Validation loss: 4.595481108593685

Epoch: 6| Step: 12
Training loss: 3.8324966430664062
Validation loss: 4.5516499088656515

Epoch: 6| Step: 13
Training loss: 3.4354403018951416
Validation loss: 4.50751902467461

Epoch: 3| Step: 0
Training loss: 4.311336517333984
Validation loss: 4.463534929419077

Epoch: 6| Step: 1
Training loss: 5.636413097381592
Validation loss: 4.417461379881828

Epoch: 6| Step: 2
Training loss: 3.8833014965057373
Validation loss: 4.3714970311810895

Epoch: 6| Step: 3
Training loss: 4.7789998054504395
Validation loss: 4.327608636630479

Epoch: 6| Step: 4
Training loss: 3.9195470809936523
Validation loss: 4.284125825410248

Epoch: 6| Step: 5
Training loss: 3.618598222732544
Validation loss: 4.242548086309946

Epoch: 6| Step: 6
Training loss: 3.9249045848846436
Validation loss: 4.199106800940729

Epoch: 6| Step: 7
Training loss: 3.3320064544677734
Validation loss: 4.159406139004615

Epoch: 6| Step: 8
Training loss: 4.888898849487305
Validation loss: 4.120283378067837

Epoch: 6| Step: 9
Training loss: 3.673232078552246
Validation loss: 4.081485984145954

Epoch: 6| Step: 10
Training loss: 3.7115650177001953
Validation loss: 4.047505035195299

Epoch: 6| Step: 11
Training loss: 2.777188777923584
Validation loss: 4.013112288649364

Epoch: 6| Step: 12
Training loss: 3.4270739555358887
Validation loss: 3.9830269352082284

Epoch: 6| Step: 13
Training loss: 4.889837265014648
Validation loss: 3.951168175666563

Epoch: 4| Step: 0
Training loss: 3.7642507553100586
Validation loss: 3.9211301752316055

Epoch: 6| Step: 1
Training loss: 4.1192145347595215
Validation loss: 3.8929798885058333

Epoch: 6| Step: 2
Training loss: 4.171140670776367
Validation loss: 3.864257658681562

Epoch: 6| Step: 3
Training loss: 3.2750420570373535
Validation loss: 3.8369292495071248

Epoch: 6| Step: 4
Training loss: 3.1567776203155518
Validation loss: 3.8105873292492283

Epoch: 6| Step: 5
Training loss: 3.9593474864959717
Validation loss: 3.7878738577647875

Epoch: 6| Step: 6
Training loss: 4.067233085632324
Validation loss: 3.7689528875453497

Epoch: 6| Step: 7
Training loss: 3.4489612579345703
Validation loss: 3.7492372400017193

Epoch: 6| Step: 8
Training loss: 2.941234588623047
Validation loss: 3.730627898247011

Epoch: 6| Step: 9
Training loss: 3.6242265701293945
Validation loss: 3.7147056338607625

Epoch: 6| Step: 10
Training loss: 3.1418542861938477
Validation loss: 3.6974999930268977

Epoch: 6| Step: 11
Training loss: 3.376878261566162
Validation loss: 3.681026530522172

Epoch: 6| Step: 12
Training loss: 4.280641078948975
Validation loss: 3.665496544171405

Epoch: 6| Step: 13
Training loss: 4.16950798034668
Validation loss: 3.6522509205725884

Epoch: 5| Step: 0
Training loss: 3.4710216522216797
Validation loss: 3.6369592348734536

Epoch: 6| Step: 1
Training loss: 3.3382010459899902
Validation loss: 3.623621750903386

Epoch: 6| Step: 2
Training loss: 3.693737268447876
Validation loss: 3.6107123282647904

Epoch: 6| Step: 3
Training loss: 5.036071300506592
Validation loss: 3.59659004980518

Epoch: 6| Step: 4
Training loss: 3.7492215633392334
Validation loss: 3.5798843881135345

Epoch: 6| Step: 5
Training loss: 3.878593921661377
Validation loss: 3.564817351679648

Epoch: 6| Step: 6
Training loss: 3.653895378112793
Validation loss: 3.550054524534492

Epoch: 6| Step: 7
Training loss: 2.5263900756835938
Validation loss: 3.5359157464837514

Epoch: 6| Step: 8
Training loss: 3.055030345916748
Validation loss: 3.522236044688891

Epoch: 6| Step: 9
Training loss: 4.447151184082031
Validation loss: 3.5114465862192135

Epoch: 6| Step: 10
Training loss: 2.724247455596924
Validation loss: 3.4979750904985654

Epoch: 6| Step: 11
Training loss: 2.348947048187256
Validation loss: 3.482255735704976

Epoch: 6| Step: 12
Training loss: 3.8200650215148926
Validation loss: 3.4692226481694046

Epoch: 6| Step: 13
Training loss: 2.5405123233795166
Validation loss: 3.4518968443716727

Epoch: 6| Step: 0
Training loss: 3.779073715209961
Validation loss: 3.4398519480100243

Epoch: 6| Step: 1
Training loss: 3.090733051300049
Validation loss: 3.42692792800165

Epoch: 6| Step: 2
Training loss: 3.298037528991699
Validation loss: 3.4192434228876585

Epoch: 6| Step: 3
Training loss: 3.5364785194396973
Validation loss: 3.4124991201585337

Epoch: 6| Step: 4
Training loss: 2.9157254695892334
Validation loss: 3.4070574852728073

Epoch: 6| Step: 5
Training loss: 2.9272608757019043
Validation loss: 3.399213739620742

Epoch: 6| Step: 6
Training loss: 3.543942928314209
Validation loss: 3.3939401795787196

Epoch: 6| Step: 7
Training loss: 4.170609951019287
Validation loss: 3.382848752442227

Epoch: 6| Step: 8
Training loss: 3.076035976409912
Validation loss: 3.3746126159544914

Epoch: 6| Step: 9
Training loss: 2.267706871032715
Validation loss: 3.369189562336091

Epoch: 6| Step: 10
Training loss: 2.4741055965423584
Validation loss: 3.360389624872515

Epoch: 6| Step: 11
Training loss: 4.271171569824219
Validation loss: 3.352499146615305

Epoch: 6| Step: 12
Training loss: 3.4514033794403076
Validation loss: 3.3472473493186374

Epoch: 6| Step: 13
Training loss: 4.434744358062744
Validation loss: 3.3392258997886413

Epoch: 7| Step: 0
Training loss: 3.152837038040161
Validation loss: 3.3327595828681864

Epoch: 6| Step: 1
Training loss: 3.8682518005371094
Validation loss: 3.327446347923689

Epoch: 6| Step: 2
Training loss: 3.8279683589935303
Validation loss: 3.3192524704881894

Epoch: 6| Step: 3
Training loss: 3.0606913566589355
Validation loss: 3.3129037939092165

Epoch: 6| Step: 4
Training loss: 3.082749843597412
Validation loss: 3.3061696534515708

Epoch: 6| Step: 5
Training loss: 3.3938827514648438
Validation loss: 3.303228365477695

Epoch: 6| Step: 6
Training loss: 4.432548522949219
Validation loss: 3.2955295296125513

Epoch: 6| Step: 7
Training loss: 2.8281335830688477
Validation loss: 3.2895268214646207

Epoch: 6| Step: 8
Training loss: 3.0232295989990234
Validation loss: 3.285195181446691

Epoch: 6| Step: 9
Training loss: 2.8943605422973633
Validation loss: 3.278851383475847

Epoch: 6| Step: 10
Training loss: 2.784120559692383
Validation loss: 3.27385175612665

Epoch: 6| Step: 11
Training loss: 2.8377137184143066
Validation loss: 3.266038094797442

Epoch: 6| Step: 12
Training loss: 3.7113218307495117
Validation loss: 3.260682959710398

Epoch: 6| Step: 13
Training loss: 2.4702463150024414
Validation loss: 3.254999852949573

Epoch: 8| Step: 0
Training loss: 3.7088065147399902
Validation loss: 3.250269502721807

Epoch: 6| Step: 1
Training loss: 2.9057493209838867
Validation loss: 3.242107729757986

Epoch: 6| Step: 2
Training loss: 3.095125675201416
Validation loss: 3.2371479721479517

Epoch: 6| Step: 3
Training loss: 4.117212295532227
Validation loss: 3.231773773829142

Epoch: 6| Step: 4
Training loss: 2.608358860015869
Validation loss: 3.227325180525421

Epoch: 6| Step: 5
Training loss: 2.4460597038269043
Validation loss: 3.2253815512503348

Epoch: 6| Step: 6
Training loss: 2.626910448074341
Validation loss: 3.220547050558111

Epoch: 6| Step: 7
Training loss: 3.6924760341644287
Validation loss: 3.220562227310673

Epoch: 6| Step: 8
Training loss: 3.0161259174346924
Validation loss: 3.21390950551597

Epoch: 6| Step: 9
Training loss: 3.3903489112854004
Validation loss: 3.2070870399475098

Epoch: 6| Step: 10
Training loss: 2.4446592330932617
Validation loss: 3.2034400945068686

Epoch: 6| Step: 11
Training loss: 3.2462451457977295
Validation loss: 3.1981313972062964

Epoch: 6| Step: 12
Training loss: 4.091282367706299
Validation loss: 3.1916249900735836

Epoch: 6| Step: 13
Training loss: 3.8255436420440674
Validation loss: 3.185493069310342

Epoch: 9| Step: 0
Training loss: 3.4199447631835938
Validation loss: 3.181068828029017

Epoch: 6| Step: 1
Training loss: 2.9554662704467773
Validation loss: 3.180738115823397

Epoch: 6| Step: 2
Training loss: 3.631836414337158
Validation loss: 3.178035828375047

Epoch: 6| Step: 3
Training loss: 2.6276626586914062
Validation loss: 3.166748049438641

Epoch: 6| Step: 4
Training loss: 3.1926047801971436
Validation loss: 3.1634929667236986

Epoch: 6| Step: 5
Training loss: 2.6470932960510254
Validation loss: 3.161962380973242

Epoch: 6| Step: 6
Training loss: 2.856201648712158
Validation loss: 3.1597976376933437

Epoch: 6| Step: 7
Training loss: 2.9352006912231445
Validation loss: 3.155893341187508

Epoch: 6| Step: 8
Training loss: 3.0153417587280273
Validation loss: 3.1513492112518637

Epoch: 6| Step: 9
Training loss: 3.9115004539489746
Validation loss: 3.144552020616429

Epoch: 6| Step: 10
Training loss: 3.2435617446899414
Validation loss: 3.1389767944171862

Epoch: 6| Step: 11
Training loss: 2.907719135284424
Validation loss: 3.1345690193996636

Epoch: 6| Step: 12
Training loss: 3.999634027481079
Validation loss: 3.129965002818774

Epoch: 6| Step: 13
Training loss: 2.822725772857666
Validation loss: 3.127579132715861

Epoch: 10| Step: 0
Training loss: 1.7098119258880615
Validation loss: 3.1227576655726277

Epoch: 6| Step: 1
Training loss: 2.9588394165039062
Validation loss: 3.1148167271767893

Epoch: 6| Step: 2
Training loss: 3.358142375946045
Validation loss: 3.1100163229050173

Epoch: 6| Step: 3
Training loss: 3.918118953704834
Validation loss: 3.107120834371095

Epoch: 6| Step: 4
Training loss: 2.924938678741455
Validation loss: 3.1054433263758177

Epoch: 6| Step: 5
Training loss: 2.772334575653076
Validation loss: 3.09951973730518

Epoch: 6| Step: 6
Training loss: 3.9627671241760254
Validation loss: 3.101728288076257

Epoch: 6| Step: 7
Training loss: 3.3034448623657227
Validation loss: 3.094938883217432

Epoch: 6| Step: 8
Training loss: 2.939072847366333
Validation loss: 3.0908624382429224

Epoch: 6| Step: 9
Training loss: 3.3329944610595703
Validation loss: 3.0846701745064027

Epoch: 6| Step: 10
Training loss: 2.645693778991699
Validation loss: 3.080648899078369

Epoch: 6| Step: 11
Training loss: 4.030858516693115
Validation loss: 3.0733328711601997

Epoch: 6| Step: 12
Training loss: 2.9547863006591797
Validation loss: 3.0705900038442304

Epoch: 6| Step: 13
Training loss: 2.754331588745117
Validation loss: 3.069679662745486

Epoch: 11| Step: 0
Training loss: 3.0057597160339355
Validation loss: 3.0624849821931575

Epoch: 6| Step: 1
Training loss: 3.6127514839172363
Validation loss: 3.0600905649123655

Epoch: 6| Step: 2
Training loss: 4.104292869567871
Validation loss: 3.0531415503512145

Epoch: 6| Step: 3
Training loss: 3.0764083862304688
Validation loss: 3.048461596171061

Epoch: 6| Step: 4
Training loss: 2.975287914276123
Validation loss: 3.0438004847495788

Epoch: 6| Step: 5
Training loss: 2.6199240684509277
Validation loss: 3.0416415686248452

Epoch: 6| Step: 6
Training loss: 2.6770529747009277
Validation loss: 3.0417498516780075

Epoch: 6| Step: 7
Training loss: 3.353207588195801
Validation loss: 3.039948689040317

Epoch: 6| Step: 8
Training loss: 3.4305920600891113
Validation loss: 3.032324093644337

Epoch: 6| Step: 9
Training loss: 2.597951889038086
Validation loss: 3.029645514744584

Epoch: 6| Step: 10
Training loss: 2.5813698768615723
Validation loss: 3.0299958157283005

Epoch: 6| Step: 11
Training loss: 2.951873779296875
Validation loss: 3.0224337372728574

Epoch: 6| Step: 12
Training loss: 3.3838119506835938
Validation loss: 3.0190585044122513

Epoch: 6| Step: 13
Training loss: 2.6282520294189453
Validation loss: 3.0110595123742216

Epoch: 12| Step: 0
Training loss: 2.8389129638671875
Validation loss: 3.0096134011463453

Epoch: 6| Step: 1
Training loss: 3.9666659832000732
Validation loss: 3.008097853711856

Epoch: 6| Step: 2
Training loss: 3.002150297164917
Validation loss: 3.0051972917331162

Epoch: 6| Step: 3
Training loss: 3.1341354846954346
Validation loss: 2.9971373055570867

Epoch: 6| Step: 4
Training loss: 2.768383502960205
Validation loss: 2.9953808476847987

Epoch: 6| Step: 5
Training loss: 3.2993974685668945
Validation loss: 2.99095848555206

Epoch: 6| Step: 6
Training loss: 2.5997018814086914
Validation loss: 2.986002081183977

Epoch: 6| Step: 7
Training loss: 3.391667604446411
Validation loss: 2.9796111019708778

Epoch: 6| Step: 8
Training loss: 2.2659640312194824
Validation loss: 2.9763117118548323

Epoch: 6| Step: 9
Training loss: 3.553596258163452
Validation loss: 2.9747830539621334

Epoch: 6| Step: 10
Training loss: 2.762446880340576
Validation loss: 2.970763211609215

Epoch: 6| Step: 11
Training loss: 3.1734299659729004
Validation loss: 2.9669800548143286

Epoch: 6| Step: 12
Training loss: 3.552586555480957
Validation loss: 2.965465884054861

Epoch: 6| Step: 13
Training loss: 1.9543664455413818
Validation loss: 2.964155391980243

Epoch: 13| Step: 0
Training loss: 2.7953298091888428
Validation loss: 2.974075371219266

Epoch: 6| Step: 1
Training loss: 3.326274871826172
Validation loss: 2.974975396228093

Epoch: 6| Step: 2
Training loss: 1.994036316871643
Validation loss: 2.9691223252204155

Epoch: 6| Step: 3
Training loss: 2.515669345855713
Validation loss: 2.9611168266624532

Epoch: 6| Step: 4
Training loss: 2.517019271850586
Validation loss: 2.9513179743161766

Epoch: 6| Step: 5
Training loss: 4.190874099731445
Validation loss: 2.942646998231129

Epoch: 6| Step: 6
Training loss: 3.6641626358032227
Validation loss: 2.9427230896488314

Epoch: 6| Step: 7
Training loss: 2.9865779876708984
Validation loss: 2.942448772409911

Epoch: 6| Step: 8
Training loss: 3.2139039039611816
Validation loss: 2.939783655187135

Epoch: 6| Step: 9
Training loss: 2.408381938934326
Validation loss: 2.932727454811014

Epoch: 6| Step: 10
Training loss: 3.467578172683716
Validation loss: 2.928504974611344

Epoch: 6| Step: 11
Training loss: 3.1385254859924316
Validation loss: 2.9290902588957097

Epoch: 6| Step: 12
Training loss: 2.2835752964019775
Validation loss: 2.9375503550293627

Epoch: 6| Step: 13
Training loss: 4.4371442794799805
Validation loss: 2.9426019832652104

Epoch: 14| Step: 0
Training loss: 2.825465679168701
Validation loss: 2.9271645443413847

Epoch: 6| Step: 1
Training loss: 2.8707990646362305
Validation loss: 2.9195184476913942

Epoch: 6| Step: 2
Training loss: 3.1947407722473145
Validation loss: 2.9178043770533737

Epoch: 6| Step: 3
Training loss: 3.28524112701416
Validation loss: 2.9159401565469723

Epoch: 6| Step: 4
Training loss: 3.410475254058838
Validation loss: 2.9175548092011483

Epoch: 6| Step: 5
Training loss: 3.026106595993042
Validation loss: 2.912554761414887

Epoch: 6| Step: 6
Training loss: 2.6224942207336426
Validation loss: 2.9050528464778775

Epoch: 6| Step: 7
Training loss: 3.1892013549804688
Validation loss: 2.90631446530742

Epoch: 6| Step: 8
Training loss: 2.4263663291931152
Validation loss: 2.909449238930979

Epoch: 6| Step: 9
Training loss: 3.334367275238037
Validation loss: 2.9236673334593415

Epoch: 6| Step: 10
Training loss: 2.5921683311462402
Validation loss: 2.9211563551297752

Epoch: 6| Step: 11
Training loss: 3.19557523727417
Validation loss: 2.9005574718598397

Epoch: 6| Step: 12
Training loss: 2.7406561374664307
Validation loss: 2.89401432775682

Epoch: 6| Step: 13
Training loss: 3.453339099884033
Validation loss: 2.8910104895150788

Epoch: 15| Step: 0
Training loss: 3.4065632820129395
Validation loss: 2.8898704282699095

Epoch: 6| Step: 1
Training loss: 2.6669139862060547
Validation loss: 2.888261333588631

Epoch: 6| Step: 2
Training loss: 2.9535281658172607
Validation loss: 2.884777074219078

Epoch: 6| Step: 3
Training loss: 3.057237148284912
Validation loss: 2.8824087214726273

Epoch: 6| Step: 4
Training loss: 3.005207061767578
Validation loss: 2.8780330252903763

Epoch: 6| Step: 5
Training loss: 2.6236934661865234
Validation loss: 2.8726915851716073

Epoch: 6| Step: 6
Training loss: 3.0915489196777344
Validation loss: 2.8753185451671643

Epoch: 6| Step: 7
Training loss: 3.7497429847717285
Validation loss: 2.873385960055936

Epoch: 6| Step: 8
Training loss: 2.6298112869262695
Validation loss: 2.8670997619628906

Epoch: 6| Step: 9
Training loss: 3.165923595428467
Validation loss: 2.8662370558707946

Epoch: 6| Step: 10
Training loss: 2.4184799194335938
Validation loss: 2.8637142412124144

Epoch: 6| Step: 11
Training loss: 3.0850307941436768
Validation loss: 2.862604369399368

Epoch: 6| Step: 12
Training loss: 2.6395578384399414
Validation loss: 2.860525013298117

Epoch: 6| Step: 13
Training loss: 3.2127482891082764
Validation loss: 2.8547412836423485

Epoch: 16| Step: 0
Training loss: 3.250018835067749
Validation loss: 2.8543359951306413

Epoch: 6| Step: 1
Training loss: 2.8160276412963867
Validation loss: 2.8519721441371466

Epoch: 6| Step: 2
Training loss: 2.489480495452881
Validation loss: 2.8550226637112197

Epoch: 6| Step: 3
Training loss: 3.6862542629241943
Validation loss: 2.850441291768064

Epoch: 6| Step: 4
Training loss: 2.4393420219421387
Validation loss: 2.8464981561066

Epoch: 6| Step: 5
Training loss: 2.628314971923828
Validation loss: 2.8431872808805077

Epoch: 6| Step: 6
Training loss: 2.6305999755859375
Validation loss: 2.8411566083149244

Epoch: 6| Step: 7
Training loss: 3.592971086502075
Validation loss: 2.8447288159401185

Epoch: 6| Step: 8
Training loss: 3.5556704998016357
Validation loss: 2.8504066544194377

Epoch: 6| Step: 9
Training loss: 2.6735305786132812
Validation loss: 2.8436117274786836

Epoch: 6| Step: 10
Training loss: 3.5581536293029785
Validation loss: 2.835124500336186

Epoch: 6| Step: 11
Training loss: 2.1341311931610107
Validation loss: 2.834899810052687

Epoch: 6| Step: 12
Training loss: 3.1587440967559814
Validation loss: 2.8325666919831307

Epoch: 6| Step: 13
Training loss: 2.5510318279266357
Validation loss: 2.834272515389227

Epoch: 17| Step: 0
Training loss: 2.578497886657715
Validation loss: 2.8295338025657077

Epoch: 6| Step: 1
Training loss: 2.3433094024658203
Validation loss: 2.8273190606024956

Epoch: 6| Step: 2
Training loss: 3.074204921722412
Validation loss: 2.8243454194838002

Epoch: 6| Step: 3
Training loss: 2.8666629791259766
Validation loss: 2.82334223101216

Epoch: 6| Step: 4
Training loss: 2.609619140625
Validation loss: 2.8202154149291334

Epoch: 6| Step: 5
Training loss: 2.818854570388794
Validation loss: 2.818452594100788

Epoch: 6| Step: 6
Training loss: 2.3780946731567383
Validation loss: 2.8175693558108423

Epoch: 6| Step: 7
Training loss: 2.554131031036377
Validation loss: 2.8164294688932356

Epoch: 6| Step: 8
Training loss: 3.052020788192749
Validation loss: 2.8151934198153916

Epoch: 6| Step: 9
Training loss: 3.376589775085449
Validation loss: 2.8126472580817437

Epoch: 6| Step: 10
Training loss: 3.1084494590759277
Validation loss: 2.8121710208154496

Epoch: 6| Step: 11
Training loss: 4.035037040710449
Validation loss: 2.8088301843212498

Epoch: 6| Step: 12
Training loss: 3.348510265350342
Validation loss: 2.808069295780633

Epoch: 6| Step: 13
Training loss: 2.8715949058532715
Validation loss: 2.803832513029857

Epoch: 18| Step: 0
Training loss: 2.82893705368042
Validation loss: 2.8019027658688125

Epoch: 6| Step: 1
Training loss: 2.835233211517334
Validation loss: 2.7999456595349055

Epoch: 6| Step: 2
Training loss: 3.030719757080078
Validation loss: 2.800149727893132

Epoch: 6| Step: 3
Training loss: 2.324146032333374
Validation loss: 2.8005502018877255

Epoch: 6| Step: 4
Training loss: 3.303299903869629
Validation loss: 2.805097592774258

Epoch: 6| Step: 5
Training loss: 2.9875781536102295
Validation loss: 2.80091868933811

Epoch: 6| Step: 6
Training loss: 2.6028904914855957
Validation loss: 2.7949878220917075

Epoch: 6| Step: 7
Training loss: 3.0484683513641357
Validation loss: 2.7895400806139876

Epoch: 6| Step: 8
Training loss: 2.9491634368896484
Validation loss: 2.7943425383619083

Epoch: 6| Step: 9
Training loss: 3.7481698989868164
Validation loss: 2.787786058200303

Epoch: 6| Step: 10
Training loss: 2.4623403549194336
Validation loss: 2.7827911607680784

Epoch: 6| Step: 11
Training loss: 2.4804317951202393
Validation loss: 2.782979949828117

Epoch: 6| Step: 12
Training loss: 3.2410078048706055
Validation loss: 2.7805252152104534

Epoch: 6| Step: 13
Training loss: 3.0545854568481445
Validation loss: 2.780205390786612

Epoch: 19| Step: 0
Training loss: 3.680501937866211
Validation loss: 2.782268222942147

Epoch: 6| Step: 1
Training loss: 2.3903279304504395
Validation loss: 2.7809138041670605

Epoch: 6| Step: 2
Training loss: 3.215830087661743
Validation loss: 2.774277984455068

Epoch: 6| Step: 3
Training loss: 2.3026864528656006
Validation loss: 2.770743859711514

Epoch: 6| Step: 4
Training loss: 2.9093070030212402
Validation loss: 2.7694362132780013

Epoch: 6| Step: 5
Training loss: 3.2269625663757324
Validation loss: 2.766900611180131

Epoch: 6| Step: 6
Training loss: 3.0337071418762207
Validation loss: 2.7642775171546528

Epoch: 6| Step: 7
Training loss: 3.092634439468384
Validation loss: 2.766109794698736

Epoch: 6| Step: 8
Training loss: 3.727851390838623
Validation loss: 2.7636331922264508

Epoch: 6| Step: 9
Training loss: 2.9611313343048096
Validation loss: 2.761729609581732

Epoch: 6| Step: 10
Training loss: 2.2425570487976074
Validation loss: 2.754620885336271

Epoch: 6| Step: 11
Training loss: 2.7066893577575684
Validation loss: 2.7645737817210536

Epoch: 6| Step: 12
Training loss: 2.353825092315674
Validation loss: 2.7719595791191183

Epoch: 6| Step: 13
Training loss: 2.683715581893921
Validation loss: 2.763238383877662

Epoch: 20| Step: 0
Training loss: 3.2727935314178467
Validation loss: 2.752571072629703

Epoch: 6| Step: 1
Training loss: 3.2778728008270264
Validation loss: 2.744550689574211

Epoch: 6| Step: 2
Training loss: 2.6747279167175293
Validation loss: 2.7430683617950766

Epoch: 6| Step: 3
Training loss: 2.41664719581604
Validation loss: 2.758951579370806

Epoch: 6| Step: 4
Training loss: 3.029447078704834
Validation loss: 2.757943917346257

Epoch: 6| Step: 5
Training loss: 2.1710009574890137
Validation loss: 2.754252705522763

Epoch: 6| Step: 6
Training loss: 3.218130111694336
Validation loss: 2.74378728353849

Epoch: 6| Step: 7
Training loss: 2.48728346824646
Validation loss: 2.7365915031843286

Epoch: 6| Step: 8
Training loss: 3.338418960571289
Validation loss: 2.735297941392468

Epoch: 6| Step: 9
Training loss: 2.924999713897705
Validation loss: 2.7315913092705513

Epoch: 6| Step: 10
Training loss: 3.6119132041931152
Validation loss: 2.7289550842777377

Epoch: 6| Step: 11
Training loss: 2.390007972717285
Validation loss: 2.7279079293691986

Epoch: 6| Step: 12
Training loss: 2.705326557159424
Validation loss: 2.727425347092331

Epoch: 6| Step: 13
Training loss: 2.8387763500213623
Validation loss: 2.7238849055382515

Epoch: 21| Step: 0
Training loss: 2.281076192855835
Validation loss: 2.7219483288385535

Epoch: 6| Step: 1
Training loss: 3.3099992275238037
Validation loss: 2.7204066937969578

Epoch: 6| Step: 2
Training loss: 3.0239648818969727
Validation loss: 2.7194366942169848

Epoch: 6| Step: 3
Training loss: 2.0966029167175293
Validation loss: 2.7233434851451586

Epoch: 6| Step: 4
Training loss: 2.0912365913391113
Validation loss: 2.7128412851723294

Epoch: 6| Step: 5
Training loss: 2.572753429412842
Validation loss: 2.7131956931083434

Epoch: 6| Step: 6
Training loss: 3.956709384918213
Validation loss: 2.712599397987448

Epoch: 6| Step: 7
Training loss: 2.4669954776763916
Validation loss: 2.711720197431503

Epoch: 6| Step: 8
Training loss: 3.185051441192627
Validation loss: 2.716703845608619

Epoch: 6| Step: 9
Training loss: 2.7238731384277344
Validation loss: 2.712627169906452

Epoch: 6| Step: 10
Training loss: 3.2956652641296387
Validation loss: 2.7044687501845823

Epoch: 6| Step: 11
Training loss: 2.8666329383850098
Validation loss: 2.6991256667721655

Epoch: 6| Step: 12
Training loss: 3.175600290298462
Validation loss: 2.696321097753381

Epoch: 6| Step: 13
Training loss: 3.185377836227417
Validation loss: 2.699610043597478

Epoch: 22| Step: 0
Training loss: 2.576327323913574
Validation loss: 2.694988960860878

Epoch: 6| Step: 1
Training loss: 2.5297012329101562
Validation loss: 2.693898175352363

Epoch: 6| Step: 2
Training loss: 2.947629928588867
Validation loss: 2.699036326459659

Epoch: 6| Step: 3
Training loss: 3.204472780227661
Validation loss: 2.700436366501675

Epoch: 6| Step: 4
Training loss: 3.3329148292541504
Validation loss: 2.7010548653141147

Epoch: 6| Step: 5
Training loss: 2.630904197692871
Validation loss: 2.7044526479577504

Epoch: 6| Step: 6
Training loss: 3.5292069911956787
Validation loss: 2.701360635859992

Epoch: 6| Step: 7
Training loss: 2.479984998703003
Validation loss: 2.6958266214657853

Epoch: 6| Step: 8
Training loss: 2.843196392059326
Validation loss: 2.6923253741315616

Epoch: 6| Step: 9
Training loss: 2.51362943649292
Validation loss: 2.688080410803518

Epoch: 6| Step: 10
Training loss: 2.976400852203369
Validation loss: 2.6809097746367097

Epoch: 6| Step: 11
Training loss: 2.330489158630371
Validation loss: 2.6785089713270946

Epoch: 6| Step: 12
Training loss: 2.8614673614501953
Validation loss: 2.6830228656850834

Epoch: 6| Step: 13
Training loss: 3.3323545455932617
Validation loss: 2.6853171445990123

Epoch: 23| Step: 0
Training loss: 3.205941677093506
Validation loss: 2.679454690666609

Epoch: 6| Step: 1
Training loss: 2.7332091331481934
Validation loss: 2.6789752667950046

Epoch: 6| Step: 2
Training loss: 2.7300069332122803
Validation loss: 2.6753228838725756

Epoch: 6| Step: 3
Training loss: 2.5165700912475586
Validation loss: 2.683492447740288

Epoch: 6| Step: 4
Training loss: 2.9920265674591064
Validation loss: 2.6877759118233957

Epoch: 6| Step: 5
Training loss: 3.3326358795166016
Validation loss: 2.709687184262019

Epoch: 6| Step: 6
Training loss: 3.181257724761963
Validation loss: 2.7064405102883615

Epoch: 6| Step: 7
Training loss: 2.572295665740967
Validation loss: 2.6691116799590406

Epoch: 6| Step: 8
Training loss: 2.505415916442871
Validation loss: 2.6580276386712187

Epoch: 6| Step: 9
Training loss: 3.0470218658447266
Validation loss: 2.666491477720199

Epoch: 6| Step: 10
Training loss: 2.6826353073120117
Validation loss: 2.6795047226772515

Epoch: 6| Step: 11
Training loss: 2.7585573196411133
Validation loss: 2.671656549617808

Epoch: 6| Step: 12
Training loss: 2.8125665187835693
Validation loss: 2.6642160390013006

Epoch: 6| Step: 13
Training loss: 2.5013785362243652
Validation loss: 2.66231765285615

Epoch: 24| Step: 0
Training loss: 2.6482887268066406
Validation loss: 2.6558894829083513

Epoch: 6| Step: 1
Training loss: 2.6071252822875977
Validation loss: 2.6547184272478987

Epoch: 6| Step: 2
Training loss: 3.410883903503418
Validation loss: 2.6614118622195337

Epoch: 6| Step: 3
Training loss: 3.2580862045288086
Validation loss: 2.663262187793691

Epoch: 6| Step: 4
Training loss: 2.639557361602783
Validation loss: 2.6814812178252847

Epoch: 6| Step: 5
Training loss: 2.9473636150360107
Validation loss: 2.663837791771017

Epoch: 6| Step: 6
Training loss: 3.050321578979492
Validation loss: 2.645899070206509

Epoch: 6| Step: 7
Training loss: 2.1733760833740234
Validation loss: 2.6506311611462663

Epoch: 6| Step: 8
Training loss: 2.966939926147461
Validation loss: 2.6533035770539315

Epoch: 6| Step: 9
Training loss: 1.6044434309005737
Validation loss: 2.6537525730748333

Epoch: 6| Step: 10
Training loss: 3.182359457015991
Validation loss: 2.662024454403949

Epoch: 6| Step: 11
Training loss: 3.261277914047241
Validation loss: 2.6648606228572067

Epoch: 6| Step: 12
Training loss: 3.1075339317321777
Validation loss: 2.660790535711473

Epoch: 6| Step: 13
Training loss: 2.6362414360046387
Validation loss: 2.654601143252465

Epoch: 25| Step: 0
Training loss: 3.1785202026367188
Validation loss: 2.6423206585709766

Epoch: 6| Step: 1
Training loss: 1.8550050258636475
Validation loss: 2.63680431150621

Epoch: 6| Step: 2
Training loss: 2.8690247535705566
Validation loss: 2.6391156117121377

Epoch: 6| Step: 3
Training loss: 2.6131300926208496
Validation loss: 2.640138395370976

Epoch: 6| Step: 4
Training loss: 2.248800039291382
Validation loss: 2.6351800323814474

Epoch: 6| Step: 5
Training loss: 2.606989622116089
Validation loss: 2.6322309406854774

Epoch: 6| Step: 6
Training loss: 2.535752534866333
Validation loss: 2.636810327088961

Epoch: 6| Step: 7
Training loss: 3.0550973415374756
Validation loss: 2.6342301035440094

Epoch: 6| Step: 8
Training loss: 3.2123165130615234
Validation loss: 2.629453812876055

Epoch: 6| Step: 9
Training loss: 2.6587631702423096
Validation loss: 2.621766003229285

Epoch: 6| Step: 10
Training loss: 3.1532421112060547
Validation loss: 2.6208623916872087

Epoch: 6| Step: 11
Training loss: 3.0371899604797363
Validation loss: 2.6139797805457987

Epoch: 6| Step: 12
Training loss: 3.4103989601135254
Validation loss: 2.6143325477518062

Epoch: 6| Step: 13
Training loss: 2.747062921524048
Validation loss: 2.6130384963045836

Epoch: 26| Step: 0
Training loss: 3.01853084564209
Validation loss: 2.6099518268339095

Epoch: 6| Step: 1
Training loss: 2.8022003173828125
Validation loss: 2.6071447787746305

Epoch: 6| Step: 2
Training loss: 2.40234375
Validation loss: 2.6070176093809065

Epoch: 6| Step: 3
Training loss: 2.3407368659973145
Validation loss: 2.609246607749693

Epoch: 6| Step: 4
Training loss: 2.607800006866455
Validation loss: 2.6087488615384666

Epoch: 6| Step: 5
Training loss: 2.4298973083496094
Validation loss: 2.6033822695414224

Epoch: 6| Step: 6
Training loss: 1.7527186870574951
Validation loss: 2.6000200420297603

Epoch: 6| Step: 7
Training loss: 3.9190592765808105
Validation loss: 2.6039428018754527

Epoch: 6| Step: 8
Training loss: 2.6205410957336426
Validation loss: 2.5958208883962324

Epoch: 6| Step: 9
Training loss: 3.387131452560425
Validation loss: 2.5997534413491525

Epoch: 6| Step: 10
Training loss: 2.4878480434417725
Validation loss: 2.6098492568539036

Epoch: 6| Step: 11
Training loss: 3.527383327484131
Validation loss: 2.609958989645845

Epoch: 6| Step: 12
Training loss: 3.0437211990356445
Validation loss: 2.605731318073888

Epoch: 6| Step: 13
Training loss: 2.493377685546875
Validation loss: 2.6016100683519916

Epoch: 27| Step: 0
Training loss: 2.802746295928955
Validation loss: 2.597678097345496

Epoch: 6| Step: 1
Training loss: 1.6460866928100586
Validation loss: 2.588616373718426

Epoch: 6| Step: 2
Training loss: 3.9521331787109375
Validation loss: 2.589573324367564

Epoch: 6| Step: 3
Training loss: 3.516343116760254
Validation loss: 2.586556383358535

Epoch: 6| Step: 4
Training loss: 2.4749526977539062
Validation loss: 2.5865637410071587

Epoch: 6| Step: 5
Training loss: 3.1561949253082275
Validation loss: 2.5870595670515493

Epoch: 6| Step: 6
Training loss: 3.069061756134033
Validation loss: 2.5885971541045816

Epoch: 6| Step: 7
Training loss: 2.8417956829071045
Validation loss: 2.5847915885269

Epoch: 6| Step: 8
Training loss: 2.1208598613739014
Validation loss: 2.5821252612657446

Epoch: 6| Step: 9
Training loss: 3.0466818809509277
Validation loss: 2.579148079759331

Epoch: 6| Step: 10
Training loss: 2.166800022125244
Validation loss: 2.5759751463449128

Epoch: 6| Step: 11
Training loss: 2.84293270111084
Validation loss: 2.5844059964661956

Epoch: 6| Step: 12
Training loss: 2.198267698287964
Validation loss: 2.582467281690208

Epoch: 6| Step: 13
Training loss: 3.197383165359497
Validation loss: 2.5754347834535825

Epoch: 28| Step: 0
Training loss: 2.985809803009033
Validation loss: 2.5729112727667696

Epoch: 6| Step: 1
Training loss: 2.2962374687194824
Validation loss: 2.5789552375834477

Epoch: 6| Step: 2
Training loss: 2.816513776779175
Validation loss: 2.5861238818014822

Epoch: 6| Step: 3
Training loss: 2.7188878059387207
Validation loss: 2.5890246052895822

Epoch: 6| Step: 4
Training loss: 4.058679103851318
Validation loss: 2.5909832498078704

Epoch: 6| Step: 5
Training loss: 2.4126362800598145
Validation loss: 2.586902097989154

Epoch: 6| Step: 6
Training loss: 2.3002796173095703
Validation loss: 2.5775586571744693

Epoch: 6| Step: 7
Training loss: 1.9232300519943237
Validation loss: 2.5720761719570366

Epoch: 6| Step: 8
Training loss: 2.9540863037109375
Validation loss: 2.567904208296089

Epoch: 6| Step: 9
Training loss: 2.3462438583374023
Validation loss: 2.563689926619171

Epoch: 6| Step: 10
Training loss: 2.323917865753174
Validation loss: 2.5655041484422583

Epoch: 6| Step: 11
Training loss: 2.6298513412475586
Validation loss: 2.5845275284141622

Epoch: 6| Step: 12
Training loss: 3.6997292041778564
Validation loss: 2.6078300834983907

Epoch: 6| Step: 13
Training loss: 3.8970248699188232
Validation loss: 2.5692412391785653

Epoch: 29| Step: 0
Training loss: 2.8563590049743652
Validation loss: 2.555873547830889

Epoch: 6| Step: 1
Training loss: 2.4722533226013184
Validation loss: 2.5600360849852204

Epoch: 6| Step: 2
Training loss: 2.849738597869873
Validation loss: 2.568148410448464

Epoch: 6| Step: 3
Training loss: 2.7349281311035156
Validation loss: 2.569775806960239

Epoch: 6| Step: 4
Training loss: 3.4256491661071777
Validation loss: 2.5715163907697125

Epoch: 6| Step: 5
Training loss: 2.5578291416168213
Validation loss: 2.570572753106394

Epoch: 6| Step: 6
Training loss: 2.747199058532715
Validation loss: 2.5660614941709783

Epoch: 6| Step: 7
Training loss: 2.3434982299804688
Validation loss: 2.5613529938523487

Epoch: 6| Step: 8
Training loss: 2.9024362564086914
Validation loss: 2.551505293897403

Epoch: 6| Step: 9
Training loss: 2.9083659648895264
Validation loss: 2.5486784237687305

Epoch: 6| Step: 10
Training loss: 2.797184467315674
Validation loss: 2.557676721644658

Epoch: 6| Step: 11
Training loss: 2.976754665374756
Validation loss: 2.579875243607388

Epoch: 6| Step: 12
Training loss: 2.6115691661834717
Validation loss: 2.5959342141305246

Epoch: 6| Step: 13
Training loss: 2.468517780303955
Validation loss: 2.56160988858951

Epoch: 30| Step: 0
Training loss: 3.081801414489746
Validation loss: 2.5495394506762104

Epoch: 6| Step: 1
Training loss: 2.5004987716674805
Validation loss: 2.539159726071101

Epoch: 6| Step: 2
Training loss: 2.6552529335021973
Validation loss: 2.534289329282699

Epoch: 6| Step: 3
Training loss: 2.829610824584961
Validation loss: 2.5412284661364812

Epoch: 6| Step: 4
Training loss: 2.53011417388916
Validation loss: 2.5394777149282475

Epoch: 6| Step: 5
Training loss: 2.300673484802246
Validation loss: 2.5355689833241124

Epoch: 6| Step: 6
Training loss: 3.9131040573120117
Validation loss: 2.5390158955768873

Epoch: 6| Step: 7
Training loss: 2.8436439037323
Validation loss: 2.5538215893571095

Epoch: 6| Step: 8
Training loss: 3.2281694412231445
Validation loss: 2.540317327745499

Epoch: 6| Step: 9
Training loss: 2.5970702171325684
Validation loss: 2.529619247682633

Epoch: 6| Step: 10
Training loss: 2.592752456665039
Validation loss: 2.5316226226027294

Epoch: 6| Step: 11
Training loss: 3.1599929332733154
Validation loss: 2.5248553419625885

Epoch: 6| Step: 12
Training loss: 2.2318758964538574
Validation loss: 2.5258351782316804

Epoch: 6| Step: 13
Training loss: 1.1684051752090454
Validation loss: 2.525353621411067

Epoch: 31| Step: 0
Training loss: 3.3345255851745605
Validation loss: 2.5294476221966486

Epoch: 6| Step: 1
Training loss: 2.894359588623047
Validation loss: 2.5454455652544574

Epoch: 6| Step: 2
Training loss: 2.8002517223358154
Validation loss: 2.566076368413946

Epoch: 6| Step: 3
Training loss: 2.8930389881134033
Validation loss: 2.616598980401152

Epoch: 6| Step: 4
Training loss: 2.205373764038086
Validation loss: 2.634203213517384

Epoch: 6| Step: 5
Training loss: 3.133098602294922
Validation loss: 2.6325183299279984

Epoch: 6| Step: 6
Training loss: 2.777099847793579
Validation loss: 2.5851010455880115

Epoch: 6| Step: 7
Training loss: 3.1008429527282715
Validation loss: 2.5331436972464285

Epoch: 6| Step: 8
Training loss: 2.3095510005950928
Validation loss: 2.527376115963023

Epoch: 6| Step: 9
Training loss: 2.993844509124756
Validation loss: 2.5413404767231276

Epoch: 6| Step: 10
Training loss: 2.2503228187561035
Validation loss: 2.5609477437952513

Epoch: 6| Step: 11
Training loss: 1.8410248756408691
Validation loss: 2.5694030305390716

Epoch: 6| Step: 12
Training loss: 2.583261251449585
Validation loss: 2.5990047659925235

Epoch: 6| Step: 13
Training loss: 3.5553038120269775
Validation loss: 2.581719870208412

Epoch: 32| Step: 0
Training loss: 2.7408828735351562
Validation loss: 2.5520305838636173

Epoch: 6| Step: 1
Training loss: 1.9622241258621216
Validation loss: 2.5341795798270934

Epoch: 6| Step: 2
Training loss: 2.289335012435913
Validation loss: 2.52414458797824

Epoch: 6| Step: 3
Training loss: 2.8224399089813232
Validation loss: 2.5188105413990636

Epoch: 6| Step: 4
Training loss: 2.855541467666626
Validation loss: 2.544816614479147

Epoch: 6| Step: 5
Training loss: 3.0479660034179688
Validation loss: 2.5740440865998626

Epoch: 6| Step: 6
Training loss: 3.097500801086426
Validation loss: 2.55582364912956

Epoch: 6| Step: 7
Training loss: 2.816925048828125
Validation loss: 2.551310411063574

Epoch: 6| Step: 8
Training loss: 3.078158140182495
Validation loss: 2.5376210469071583

Epoch: 6| Step: 9
Training loss: 2.734109878540039
Validation loss: 2.525851370185934

Epoch: 6| Step: 10
Training loss: 2.1769862174987793
Validation loss: 2.5234385921109106

Epoch: 6| Step: 11
Training loss: 3.1726841926574707
Validation loss: 2.5241708550401913

Epoch: 6| Step: 12
Training loss: 2.7440590858459473
Validation loss: 2.518368369789534

Epoch: 6| Step: 13
Training loss: 2.7646520137786865
Validation loss: 2.514767849317161

Epoch: 33| Step: 0
Training loss: 3.2776942253112793
Validation loss: 2.5136873029893443

Epoch: 6| Step: 1
Training loss: 2.9187493324279785
Validation loss: 2.5094550040460404

Epoch: 6| Step: 2
Training loss: 2.6243724822998047
Validation loss: 2.5141490761951735

Epoch: 6| Step: 3
Training loss: 2.489835262298584
Validation loss: 2.5230061469539518

Epoch: 6| Step: 4
Training loss: 2.9384684562683105
Validation loss: 2.527713555161671

Epoch: 6| Step: 5
Training loss: 3.084904193878174
Validation loss: 2.5390603849964757

Epoch: 6| Step: 6
Training loss: 2.889030933380127
Validation loss: 2.545920233572683

Epoch: 6| Step: 7
Training loss: 3.103151321411133
Validation loss: 2.5370975976349204

Epoch: 6| Step: 8
Training loss: 2.265131711959839
Validation loss: 2.516496099451537

Epoch: 6| Step: 9
Training loss: 2.4631242752075195
Validation loss: 2.504614496743807

Epoch: 6| Step: 10
Training loss: 2.9778354167938232
Validation loss: 2.5013559274776007

Epoch: 6| Step: 11
Training loss: 2.930220127105713
Validation loss: 2.5025836190869732

Epoch: 6| Step: 12
Training loss: 1.7171118259429932
Validation loss: 2.503245307553199

Epoch: 6| Step: 13
Training loss: 2.2056310176849365
Validation loss: 2.506278117497762

Epoch: 34| Step: 0
Training loss: 3.479764223098755
Validation loss: 2.502239232422203

Epoch: 6| Step: 1
Training loss: 2.631972312927246
Validation loss: 2.49123284380923

Epoch: 6| Step: 2
Training loss: 3.0951693058013916
Validation loss: 2.4943848681706253

Epoch: 6| Step: 3
Training loss: 2.1501059532165527
Validation loss: 2.506600013343237

Epoch: 6| Step: 4
Training loss: 1.960519552230835
Validation loss: 2.520143114110475

Epoch: 6| Step: 5
Training loss: 3.028027057647705
Validation loss: 2.5734732920123684

Epoch: 6| Step: 6
Training loss: 2.357329845428467
Validation loss: 2.599733534679618

Epoch: 6| Step: 7
Training loss: 2.5443508625030518
Validation loss: 2.583486141697053

Epoch: 6| Step: 8
Training loss: 3.6349148750305176
Validation loss: 2.5632083723621983

Epoch: 6| Step: 9
Training loss: 2.5646142959594727
Validation loss: 2.514572875474089

Epoch: 6| Step: 10
Training loss: 2.9371252059936523
Validation loss: 2.487777066487138

Epoch: 6| Step: 11
Training loss: 2.7374587059020996
Validation loss: 2.486968360921388

Epoch: 6| Step: 12
Training loss: 2.4994571208953857
Validation loss: 2.4928815287928425

Epoch: 6| Step: 13
Training loss: 2.41644549369812
Validation loss: 2.5069343300275904

Epoch: 35| Step: 0
Training loss: 2.898205280303955
Validation loss: 2.5081831306539555

Epoch: 6| Step: 1
Training loss: 3.10038423538208
Validation loss: 2.5091318186893257

Epoch: 6| Step: 2
Training loss: 2.4612574577331543
Validation loss: 2.498472721345963

Epoch: 6| Step: 3
Training loss: 2.2142703533172607
Validation loss: 2.4871837092984106

Epoch: 6| Step: 4
Training loss: 2.635037422180176
Validation loss: 2.4834970479370444

Epoch: 6| Step: 5
Training loss: 2.707627534866333
Validation loss: 2.4863056162352204

Epoch: 6| Step: 6
Training loss: 3.562772274017334
Validation loss: 2.4956379616132347

Epoch: 6| Step: 7
Training loss: 2.1351137161254883
Validation loss: 2.5181559952356483

Epoch: 6| Step: 8
Training loss: 2.7923943996429443
Validation loss: 2.5333811390784478

Epoch: 6| Step: 9
Training loss: 2.2734687328338623
Validation loss: 2.534514752767419

Epoch: 6| Step: 10
Training loss: 3.1781766414642334
Validation loss: 2.5278658482336227

Epoch: 6| Step: 11
Training loss: 2.7291338443756104
Validation loss: 2.5075645651868594

Epoch: 6| Step: 12
Training loss: 2.4729580879211426
Validation loss: 2.4824044704437256

Epoch: 6| Step: 13
Training loss: 2.6770119667053223
Validation loss: 2.4752246384979575

Epoch: 36| Step: 0
Training loss: 2.4908652305603027
Validation loss: 2.4667094676725325

Epoch: 6| Step: 1
Training loss: 3.2385549545288086
Validation loss: 2.4810020564704813

Epoch: 6| Step: 2
Training loss: 2.7486138343811035
Validation loss: 2.5008623164187194

Epoch: 6| Step: 3
Training loss: 2.3176889419555664
Validation loss: 2.5187104030322005

Epoch: 6| Step: 4
Training loss: 2.6336159706115723
Validation loss: 2.5071778297424316

Epoch: 6| Step: 5
Training loss: 2.526892900466919
Validation loss: 2.497885347694479

Epoch: 6| Step: 6
Training loss: 3.5480763912200928
Validation loss: 2.5001351218069754

Epoch: 6| Step: 7
Training loss: 2.5281083583831787
Validation loss: 2.489556239497277

Epoch: 6| Step: 8
Training loss: 2.0428593158721924
Validation loss: 2.483738760794363

Epoch: 6| Step: 9
Training loss: 3.1331605911254883
Validation loss: 2.478677982925087

Epoch: 6| Step: 10
Training loss: 1.9283802509307861
Validation loss: 2.47545228978639

Epoch: 6| Step: 11
Training loss: 3.4715867042541504
Validation loss: 2.4848677035300963

Epoch: 6| Step: 12
Training loss: 2.769568920135498
Validation loss: 2.4911975681140857

Epoch: 6| Step: 13
Training loss: 2.574387550354004
Validation loss: 2.48776977292953

Epoch: 37| Step: 0
Training loss: 2.849647045135498
Validation loss: 2.490496604673324

Epoch: 6| Step: 1
Training loss: 2.8220481872558594
Validation loss: 2.489328039589749

Epoch: 6| Step: 2
Training loss: 2.4935460090637207
Validation loss: 2.488801658794444

Epoch: 6| Step: 3
Training loss: 2.8311562538146973
Validation loss: 2.484734732617614

Epoch: 6| Step: 4
Training loss: 2.4474973678588867
Validation loss: 2.4831958560533423

Epoch: 6| Step: 5
Training loss: 2.78342342376709
Validation loss: 2.4830095767974854

Epoch: 6| Step: 6
Training loss: 2.533125877380371
Validation loss: 2.4775424823966077

Epoch: 6| Step: 7
Training loss: 2.970750093460083
Validation loss: 2.4723954098199004

Epoch: 6| Step: 8
Training loss: 2.3815462589263916
Validation loss: 2.465919158791983

Epoch: 6| Step: 9
Training loss: 3.282972812652588
Validation loss: 2.4603289801587342

Epoch: 6| Step: 10
Training loss: 3.1982052326202393
Validation loss: 2.4608427452784714

Epoch: 6| Step: 11
Training loss: 2.393673896789551
Validation loss: 2.4530311297344904

Epoch: 6| Step: 12
Training loss: 2.210047960281372
Validation loss: 2.448453390470115

Epoch: 6| Step: 13
Training loss: 2.05623197555542
Validation loss: 2.453232175560408

Epoch: 38| Step: 0
Training loss: 2.5940041542053223
Validation loss: 2.4537490208943686

Epoch: 6| Step: 1
Training loss: 2.6542909145355225
Validation loss: 2.4550259882403958

Epoch: 6| Step: 2
Training loss: 2.2324514389038086
Validation loss: 2.452118524941065

Epoch: 6| Step: 3
Training loss: 3.3422188758850098
Validation loss: 2.4613400531071488

Epoch: 6| Step: 4
Training loss: 2.5985231399536133
Validation loss: 2.4514061148448656

Epoch: 6| Step: 5
Training loss: 2.816696882247925
Validation loss: 2.446311801992437

Epoch: 6| Step: 6
Training loss: 3.4415228366851807
Validation loss: 2.451065282667837

Epoch: 6| Step: 7
Training loss: 2.0109901428222656
Validation loss: 2.4488331989575456

Epoch: 6| Step: 8
Training loss: 2.2485785484313965
Validation loss: 2.4438258832500828

Epoch: 6| Step: 9
Training loss: 2.4333128929138184
Validation loss: 2.4392660920337965

Epoch: 6| Step: 10
Training loss: 3.1527042388916016
Validation loss: 2.441527940893686

Epoch: 6| Step: 11
Training loss: 2.355647087097168
Validation loss: 2.4414383595989597

Epoch: 6| Step: 12
Training loss: 2.9228856563568115
Validation loss: 2.4407836775625906

Epoch: 6| Step: 13
Training loss: 2.593580484390259
Validation loss: 2.4400334114669473

Epoch: 39| Step: 0
Training loss: 2.9183125495910645
Validation loss: 2.4417523363585114

Epoch: 6| Step: 1
Training loss: 3.0721511840820312
Validation loss: 2.4513113114141647

Epoch: 6| Step: 2
Training loss: 2.102806806564331
Validation loss: 2.4575749161422893

Epoch: 6| Step: 3
Training loss: 2.1002182960510254
Validation loss: 2.4476001237028386

Epoch: 6| Step: 4
Training loss: 2.7822625637054443
Validation loss: 2.4420157658156527

Epoch: 6| Step: 5
Training loss: 2.2941982746124268
Validation loss: 2.4430491821740263

Epoch: 6| Step: 6
Training loss: 3.239591121673584
Validation loss: 2.4460921390082246

Epoch: 6| Step: 7
Training loss: 2.2809908390045166
Validation loss: 2.459426933719266

Epoch: 6| Step: 8
Training loss: 2.348238468170166
Validation loss: 2.481767769782774

Epoch: 6| Step: 9
Training loss: 3.6428589820861816
Validation loss: 2.4885804063530377

Epoch: 6| Step: 10
Training loss: 2.431056499481201
Validation loss: 2.4682600293108212

Epoch: 6| Step: 11
Training loss: 2.2291579246520996
Validation loss: 2.4708336373811126

Epoch: 6| Step: 12
Training loss: 3.251157760620117
Validation loss: 2.4912549141914613

Epoch: 6| Step: 13
Training loss: 2.779852867126465
Validation loss: 2.490352943379392

Epoch: 40| Step: 0
Training loss: 3.070033550262451
Validation loss: 2.48455548286438

Epoch: 6| Step: 1
Training loss: 2.6821656227111816
Validation loss: 2.4589310564020628

Epoch: 6| Step: 2
Training loss: 2.1703360080718994
Validation loss: 2.448824255697189

Epoch: 6| Step: 3
Training loss: 3.4425361156463623
Validation loss: 2.4408940012736986

Epoch: 6| Step: 4
Training loss: 2.218862771987915
Validation loss: 2.4358870649850495

Epoch: 6| Step: 5
Training loss: 2.2495696544647217
Validation loss: 2.435532300702987

Epoch: 6| Step: 6
Training loss: 2.7665700912475586
Validation loss: 2.4321408899881507

Epoch: 6| Step: 7
Training loss: 2.2759251594543457
Validation loss: 2.4253104373972905

Epoch: 6| Step: 8
Training loss: 3.527517795562744
Validation loss: 2.4263553183565856

Epoch: 6| Step: 9
Training loss: 2.42016339302063
Validation loss: 2.419784668953188

Epoch: 6| Step: 10
Training loss: 2.1710548400878906
Validation loss: 2.4196318862258748

Epoch: 6| Step: 11
Training loss: 3.143615245819092
Validation loss: 2.4204390818072903

Epoch: 6| Step: 12
Training loss: 2.3859987258911133
Validation loss: 2.4245311239714264

Epoch: 6| Step: 13
Training loss: 2.9819157123565674
Validation loss: 2.4217872337628434

Epoch: 41| Step: 0
Training loss: 3.2891533374786377
Validation loss: 2.4283688529845207

Epoch: 6| Step: 1
Training loss: 3.2482213973999023
Validation loss: 2.424436353868054

Epoch: 6| Step: 2
Training loss: 2.003499984741211
Validation loss: 2.4225204939483316

Epoch: 6| Step: 3
Training loss: 3.0904462337493896
Validation loss: 2.4263925808732227

Epoch: 6| Step: 4
Training loss: 3.288844585418701
Validation loss: 2.4214909127963486

Epoch: 6| Step: 5
Training loss: 2.7793493270874023
Validation loss: 2.423670450846354

Epoch: 6| Step: 6
Training loss: 2.389575481414795
Validation loss: 2.4270646443931003

Epoch: 6| Step: 7
Training loss: 3.023895740509033
Validation loss: 2.4439800554706204

Epoch: 6| Step: 8
Training loss: 2.001246690750122
Validation loss: 2.4700888754219137

Epoch: 6| Step: 9
Training loss: 2.262939691543579
Validation loss: 2.477460999642649

Epoch: 6| Step: 10
Training loss: 2.849656105041504
Validation loss: 2.502025309429374

Epoch: 6| Step: 11
Training loss: 2.3638663291931152
Validation loss: 2.4840384375664497

Epoch: 6| Step: 12
Training loss: 1.8987380266189575
Validation loss: 2.4480249958653606

Epoch: 6| Step: 13
Training loss: 2.8212215900421143
Validation loss: 2.4301345604722218

Epoch: 42| Step: 0
Training loss: 2.841799736022949
Validation loss: 2.4182253858094573

Epoch: 6| Step: 1
Training loss: 2.17293119430542
Validation loss: 2.418489399776664

Epoch: 6| Step: 2
Training loss: 2.8705177307128906
Validation loss: 2.414939752189062

Epoch: 6| Step: 3
Training loss: 2.8238635063171387
Validation loss: 2.4215603413120395

Epoch: 6| Step: 4
Training loss: 2.679713010787964
Validation loss: 2.4213508944357596

Epoch: 6| Step: 5
Training loss: 2.6510586738586426
Validation loss: 2.419385576760897

Epoch: 6| Step: 6
Training loss: 2.325847625732422
Validation loss: 2.419002914941439

Epoch: 6| Step: 7
Training loss: 1.9458177089691162
Validation loss: 2.4224164357749363

Epoch: 6| Step: 8
Training loss: 2.3862690925598145
Validation loss: 2.425368426948465

Epoch: 6| Step: 9
Training loss: 2.6340649127960205
Validation loss: 2.4274833663817375

Epoch: 6| Step: 10
Training loss: 2.4867351055145264
Validation loss: 2.427148785642398

Epoch: 6| Step: 11
Training loss: 3.8262479305267334
Validation loss: 2.429138537376158

Epoch: 6| Step: 12
Training loss: 2.648815393447876
Validation loss: 2.4243203978384695

Epoch: 6| Step: 13
Training loss: 3.1423001289367676
Validation loss: 2.4239596397646013

Epoch: 43| Step: 0
Training loss: 2.875720977783203
Validation loss: 2.412024067294213

Epoch: 6| Step: 1
Training loss: 2.1965584754943848
Validation loss: 2.418221181438815

Epoch: 6| Step: 2
Training loss: 2.734492540359497
Validation loss: 2.407521346563934

Epoch: 6| Step: 3
Training loss: 2.004281520843506
Validation loss: 2.407567144722067

Epoch: 6| Step: 4
Training loss: 2.389892339706421
Validation loss: 2.4070000930499007

Epoch: 6| Step: 5
Training loss: 2.9484124183654785
Validation loss: 2.413036133653374

Epoch: 6| Step: 6
Training loss: 2.3163375854492188
Validation loss: 2.433836301167806

Epoch: 6| Step: 7
Training loss: 2.9171807765960693
Validation loss: 2.444329705289615

Epoch: 6| Step: 8
Training loss: 2.4686930179595947
Validation loss: 2.4625235014064337

Epoch: 6| Step: 9
Training loss: 3.2295420169830322
Validation loss: 2.448619032418856

Epoch: 6| Step: 10
Training loss: 2.6235694885253906
Validation loss: 2.443775838421237

Epoch: 6| Step: 11
Training loss: 3.0635409355163574
Validation loss: 2.4263988643564205

Epoch: 6| Step: 12
Training loss: 3.060697555541992
Validation loss: 2.421704105151597

Epoch: 6| Step: 13
Training loss: 1.9711203575134277
Validation loss: 2.4088912112738496

Epoch: 44| Step: 0
Training loss: 2.731111526489258
Validation loss: 2.402450389759515

Epoch: 6| Step: 1
Training loss: 2.347865104675293
Validation loss: 2.40320146981106

Epoch: 6| Step: 2
Training loss: 2.6421852111816406
Validation loss: 2.4063277988023657

Epoch: 6| Step: 3
Training loss: 2.490988254547119
Validation loss: 2.4086214778243855

Epoch: 6| Step: 4
Training loss: 3.0983006954193115
Validation loss: 2.4020600421454317

Epoch: 6| Step: 5
Training loss: 1.805533528327942
Validation loss: 2.399274892704461

Epoch: 6| Step: 6
Training loss: 2.6040902137756348
Validation loss: 2.409704969775292

Epoch: 6| Step: 7
Training loss: 3.3551366329193115
Validation loss: 2.438818432951486

Epoch: 6| Step: 8
Training loss: 3.0830111503601074
Validation loss: 2.449760719012189

Epoch: 6| Step: 9
Training loss: 2.3012869358062744
Validation loss: 2.4258819216041156

Epoch: 6| Step: 10
Training loss: 2.698544979095459
Validation loss: 2.3996624844048613

Epoch: 6| Step: 11
Training loss: 2.420182466506958
Validation loss: 2.395595822283017

Epoch: 6| Step: 12
Training loss: 3.0924949645996094
Validation loss: 2.391116367873325

Epoch: 6| Step: 13
Training loss: 2.1860485076904297
Validation loss: 2.39751249231318

Epoch: 45| Step: 0
Training loss: 2.900186777114868
Validation loss: 2.4087515877139185

Epoch: 6| Step: 1
Training loss: 2.8330230712890625
Validation loss: 2.4106361225087154

Epoch: 6| Step: 2
Training loss: 2.5934927463531494
Validation loss: 2.410537048052716

Epoch: 6| Step: 3
Training loss: 2.593900203704834
Validation loss: 2.4041870306896906

Epoch: 6| Step: 4
Training loss: 3.18145751953125
Validation loss: 2.3992537401055776

Epoch: 6| Step: 5
Training loss: 2.408738374710083
Validation loss: 2.3895948035742647

Epoch: 6| Step: 6
Training loss: 3.2975268363952637
Validation loss: 2.393535457631593

Epoch: 6| Step: 7
Training loss: 2.8458352088928223
Validation loss: 2.401521102074654

Epoch: 6| Step: 8
Training loss: 2.197695016860962
Validation loss: 2.417546905497069

Epoch: 6| Step: 9
Training loss: 2.5251364707946777
Validation loss: 2.4199263767529557

Epoch: 6| Step: 10
Training loss: 2.251366138458252
Validation loss: 2.41361548695513

Epoch: 6| Step: 11
Training loss: 2.834101915359497
Validation loss: 2.4235615961013304

Epoch: 6| Step: 12
Training loss: 1.8471429347991943
Validation loss: 2.435431859826529

Epoch: 6| Step: 13
Training loss: 2.858365058898926
Validation loss: 2.4371573745563464

Epoch: 46| Step: 0
Training loss: 1.8602294921875
Validation loss: 2.463448747511833

Epoch: 6| Step: 1
Training loss: 2.996190071105957
Validation loss: 2.454481424823884

Epoch: 6| Step: 2
Training loss: 3.272505283355713
Validation loss: 2.4120596967717653

Epoch: 6| Step: 3
Training loss: 2.4571704864501953
Validation loss: 2.3897962826554493

Epoch: 6| Step: 4
Training loss: 2.8243768215179443
Validation loss: 2.3826367316707486

Epoch: 6| Step: 5
Training loss: 2.53256893157959
Validation loss: 2.3889452565100884

Epoch: 6| Step: 6
Training loss: 2.588623523712158
Validation loss: 2.3896664034935737

Epoch: 6| Step: 7
Training loss: 2.679880380630493
Validation loss: 2.389145792171519

Epoch: 6| Step: 8
Training loss: 2.624471664428711
Validation loss: 2.387438794618012

Epoch: 6| Step: 9
Training loss: 2.719243049621582
Validation loss: 2.3847083686500468

Epoch: 6| Step: 10
Training loss: 2.585867404937744
Validation loss: 2.38931244163103

Epoch: 6| Step: 11
Training loss: 2.69472074508667
Validation loss: 2.3881708960379324

Epoch: 6| Step: 12
Training loss: 2.9205870628356934
Validation loss: 2.390869335461688

Epoch: 6| Step: 13
Training loss: 2.260589122772217
Validation loss: 2.3906011119965584

Epoch: 47| Step: 0
Training loss: 2.5618903636932373
Validation loss: 2.399345495367563

Epoch: 6| Step: 1
Training loss: 2.4811153411865234
Validation loss: 2.395019256940452

Epoch: 6| Step: 2
Training loss: 3.007340431213379
Validation loss: 2.3878451342223794

Epoch: 6| Step: 3
Training loss: 2.3985555171966553
Validation loss: 2.3851544369933424

Epoch: 6| Step: 4
Training loss: 3.506316900253296
Validation loss: 2.393891624225083

Epoch: 6| Step: 5
Training loss: 1.7667129039764404
Validation loss: 2.4041079551942888

Epoch: 6| Step: 6
Training loss: 2.341238260269165
Validation loss: 2.4143273292049283

Epoch: 6| Step: 7
Training loss: 3.036306858062744
Validation loss: 2.4379719893137612

Epoch: 6| Step: 8
Training loss: 2.117758274078369
Validation loss: 2.4656508199630247

Epoch: 6| Step: 9
Training loss: 2.8135759830474854
Validation loss: 2.4822947722609325

Epoch: 6| Step: 10
Training loss: 2.489255905151367
Validation loss: 2.4818573562047814

Epoch: 6| Step: 11
Training loss: 3.7706069946289062
Validation loss: 2.4582220879934167

Epoch: 6| Step: 12
Training loss: 2.1260600090026855
Validation loss: 2.439707866279028

Epoch: 6| Step: 13
Training loss: 2.5680062770843506
Validation loss: 2.4062282193091606

Epoch: 48| Step: 0
Training loss: 2.532581329345703
Validation loss: 2.3875423913360923

Epoch: 6| Step: 1
Training loss: 2.784923553466797
Validation loss: 2.38059570968792

Epoch: 6| Step: 2
Training loss: 2.5350921154022217
Validation loss: 2.3799239743140435

Epoch: 6| Step: 3
Training loss: 2.9780030250549316
Validation loss: 2.3833712377855854

Epoch: 6| Step: 4
Training loss: 2.4192378520965576
Validation loss: 2.3796641518992763

Epoch: 6| Step: 5
Training loss: 2.6808087825775146
Validation loss: 2.3876719218428417

Epoch: 6| Step: 6
Training loss: 2.374321699142456
Validation loss: 2.384946507792319

Epoch: 6| Step: 7
Training loss: 3.13519024848938
Validation loss: 2.3937172453890563

Epoch: 6| Step: 8
Training loss: 2.510235071182251
Validation loss: 2.4017918263712237

Epoch: 6| Step: 9
Training loss: 2.8523812294006348
Validation loss: 2.420175670295633

Epoch: 6| Step: 10
Training loss: 2.453575611114502
Validation loss: 2.4428875612956222

Epoch: 6| Step: 11
Training loss: 3.502155303955078
Validation loss: 2.4320982809989684

Epoch: 6| Step: 12
Training loss: 2.111743450164795
Validation loss: 2.4292122189716627

Epoch: 6| Step: 13
Training loss: 1.2614209651947021
Validation loss: 2.4351663858659807

Epoch: 49| Step: 0
Training loss: 3.007617712020874
Validation loss: 2.4199926724997898

Epoch: 6| Step: 1
Training loss: 3.4572701454162598
Validation loss: 2.4031115860067387

Epoch: 6| Step: 2
Training loss: 2.9772467613220215
Validation loss: 2.3887814014188704

Epoch: 6| Step: 3
Training loss: 1.9757461547851562
Validation loss: 2.378519246655126

Epoch: 6| Step: 4
Training loss: 2.66062593460083
Validation loss: 2.3735656276825936

Epoch: 6| Step: 5
Training loss: 2.802747964859009
Validation loss: 2.37551728628015

Epoch: 6| Step: 6
Training loss: 2.9810714721679688
Validation loss: 2.378034460929132

Epoch: 6| Step: 7
Training loss: 2.8489058017730713
Validation loss: 2.381623072008933

Epoch: 6| Step: 8
Training loss: 2.209453582763672
Validation loss: 2.38019589454897

Epoch: 6| Step: 9
Training loss: 2.150552272796631
Validation loss: 2.380469665732435

Epoch: 6| Step: 10
Training loss: 2.155667304992676
Validation loss: 2.3800845530725296

Epoch: 6| Step: 11
Training loss: 2.2640798091888428
Validation loss: 2.38235891249872

Epoch: 6| Step: 12
Training loss: 2.8043904304504395
Validation loss: 2.3813316193960046

Epoch: 6| Step: 13
Training loss: 2.7018139362335205
Validation loss: 2.384333131133869

Epoch: 50| Step: 0
Training loss: 2.833766460418701
Validation loss: 2.382996287397159

Epoch: 6| Step: 1
Training loss: 2.1879453659057617
Validation loss: 2.375515760913972

Epoch: 6| Step: 2
Training loss: 2.5287420749664307
Validation loss: 2.389487020431026

Epoch: 6| Step: 3
Training loss: 3.634603977203369
Validation loss: 2.3949670945444415

Epoch: 6| Step: 4
Training loss: 2.493919849395752
Validation loss: 2.4109653042208765

Epoch: 6| Step: 5
Training loss: 3.1900386810302734
Validation loss: 2.4180188461016585

Epoch: 6| Step: 6
Training loss: 2.4274299144744873
Validation loss: 2.4380755270681074

Epoch: 6| Step: 7
Training loss: 2.109302043914795
Validation loss: 2.4420135175028155

Epoch: 6| Step: 8
Training loss: 2.396195888519287
Validation loss: 2.410371631704351

Epoch: 6| Step: 9
Training loss: 2.931464433670044
Validation loss: 2.380426455569524

Epoch: 6| Step: 10
Training loss: 1.9140503406524658
Validation loss: 2.371459784046296

Epoch: 6| Step: 11
Training loss: 2.4307570457458496
Validation loss: 2.3655732447101223

Epoch: 6| Step: 12
Training loss: 2.5079030990600586
Validation loss: 2.362084734824396

Epoch: 6| Step: 13
Training loss: 3.775698661804199
Validation loss: 2.3602368805998113

Epoch: 51| Step: 0
Training loss: 3.1015591621398926
Validation loss: 2.359091022963165

Epoch: 6| Step: 1
Training loss: 2.4557957649230957
Validation loss: 2.358507010244554

Epoch: 6| Step: 2
Training loss: 2.5764641761779785
Validation loss: 2.360912428107313

Epoch: 6| Step: 3
Training loss: 2.9940361976623535
Validation loss: 2.3674605533640873

Epoch: 6| Step: 4
Training loss: 2.1167895793914795
Validation loss: 2.3760435504298054

Epoch: 6| Step: 5
Training loss: 3.0887362957000732
Validation loss: 2.3868660311545096

Epoch: 6| Step: 6
Training loss: 2.784783363342285
Validation loss: 2.3931428129955004

Epoch: 6| Step: 7
Training loss: 2.370389938354492
Validation loss: 2.4128476753029773

Epoch: 6| Step: 8
Training loss: 2.6725196838378906
Validation loss: 2.430637885165471

Epoch: 6| Step: 9
Training loss: 2.7050018310546875
Validation loss: 2.4217942376290598

Epoch: 6| Step: 10
Training loss: 2.62066912651062
Validation loss: 2.413450592307634

Epoch: 6| Step: 11
Training loss: 2.3084850311279297
Validation loss: 2.3970331120234665

Epoch: 6| Step: 12
Training loss: 2.0603373050689697
Validation loss: 2.3884355496334773

Epoch: 6| Step: 13
Training loss: 2.918195962905884
Validation loss: 2.3925343405815864

Epoch: 52| Step: 0
Training loss: 3.068547248840332
Validation loss: 2.382536534340151

Epoch: 6| Step: 1
Training loss: 2.2338666915893555
Validation loss: 2.384981060540804

Epoch: 6| Step: 2
Training loss: 2.580887794494629
Validation loss: 2.37729557611609

Epoch: 6| Step: 3
Training loss: 2.751804828643799
Validation loss: 2.377315725049665

Epoch: 6| Step: 4
Training loss: 2.8899283409118652
Validation loss: 2.3753907834329913

Epoch: 6| Step: 5
Training loss: 2.2730135917663574
Validation loss: 2.381257321244927

Epoch: 6| Step: 6
Training loss: 1.8709111213684082
Validation loss: 2.3872365310627925

Epoch: 6| Step: 7
Training loss: 2.1036150455474854
Validation loss: 2.4029658866185013

Epoch: 6| Step: 8
Training loss: 2.76784348487854
Validation loss: 2.419681618290563

Epoch: 6| Step: 9
Training loss: 3.3641316890716553
Validation loss: 2.4248728931591077

Epoch: 6| Step: 10
Training loss: 3.400327682495117
Validation loss: 2.4021368488188712

Epoch: 6| Step: 11
Training loss: 2.6316161155700684
Validation loss: 2.372798022403512

Epoch: 6| Step: 12
Training loss: 2.1203713417053223
Validation loss: 2.375613077994316

Epoch: 6| Step: 13
Training loss: 2.5456814765930176
Validation loss: 2.381789110040152

Epoch: 53| Step: 0
Training loss: 2.866722345352173
Validation loss: 2.342477588243382

Epoch: 6| Step: 1
Training loss: 2.796936511993408
Validation loss: 2.3408381118569324

Epoch: 6| Step: 2
Training loss: 3.0490880012512207
Validation loss: 2.342196959321217

Epoch: 6| Step: 3
Training loss: 1.776841163635254
Validation loss: 2.344560638550789

Epoch: 6| Step: 4
Training loss: 1.9824895858764648
Validation loss: 2.3515176080888316

Epoch: 6| Step: 5
Training loss: 2.682126045227051
Validation loss: 2.368570643086587

Epoch: 6| Step: 6
Training loss: 2.8567557334899902
Validation loss: 2.369826683434107

Epoch: 6| Step: 7
Training loss: 2.322057008743286
Validation loss: 2.3633872462857153

Epoch: 6| Step: 8
Training loss: 2.183922529220581
Validation loss: 2.3630187716535342

Epoch: 6| Step: 9
Training loss: 3.062350273132324
Validation loss: 2.3690569170059694

Epoch: 6| Step: 10
Training loss: 2.409207344055176
Validation loss: 2.3896747455802014

Epoch: 6| Step: 11
Training loss: 3.1429624557495117
Validation loss: 2.406583280973537

Epoch: 6| Step: 12
Training loss: 2.813448667526245
Validation loss: 2.420043832512312

Epoch: 6| Step: 13
Training loss: 2.958282470703125
Validation loss: 2.395392938326764

Epoch: 54| Step: 0
Training loss: 3.6542868614196777
Validation loss: 2.3709648475852063

Epoch: 6| Step: 1
Training loss: 1.909656286239624
Validation loss: 2.360448709098242

Epoch: 6| Step: 2
Training loss: 1.996063232421875
Validation loss: 2.344965322043306

Epoch: 6| Step: 3
Training loss: 3.2253286838531494
Validation loss: 2.3444727056769916

Epoch: 6| Step: 4
Training loss: 3.062549114227295
Validation loss: 2.3465010863478466

Epoch: 6| Step: 5
Training loss: 2.652127981185913
Validation loss: 2.347144232001356

Epoch: 6| Step: 6
Training loss: 2.53373384475708
Validation loss: 2.348042972626225

Epoch: 6| Step: 7
Training loss: 3.0033631324768066
Validation loss: 2.353846873006513

Epoch: 6| Step: 8
Training loss: 2.668322801589966
Validation loss: 2.3542398073339976

Epoch: 6| Step: 9
Training loss: 1.710219383239746
Validation loss: 2.3522724182375017

Epoch: 6| Step: 10
Training loss: 2.87777042388916
Validation loss: 2.346793036307058

Epoch: 6| Step: 11
Training loss: 2.937681198120117
Validation loss: 2.355166535223684

Epoch: 6| Step: 12
Training loss: 1.971346378326416
Validation loss: 2.3535326988466325

Epoch: 6| Step: 13
Training loss: 1.9992629289627075
Validation loss: 2.3758949490003687

Epoch: 55| Step: 0
Training loss: 2.2183618545532227
Validation loss: 2.3952574012100056

Epoch: 6| Step: 1
Training loss: 2.462470293045044
Validation loss: 2.414408040303056

Epoch: 6| Step: 2
Training loss: 2.2037458419799805
Validation loss: 2.406317562185308

Epoch: 6| Step: 3
Training loss: 3.71816086769104
Validation loss: 2.397526664118613

Epoch: 6| Step: 4
Training loss: 3.4832358360290527
Validation loss: 2.382975039943572

Epoch: 6| Step: 5
Training loss: 2.234912157058716
Validation loss: 2.368583366435061

Epoch: 6| Step: 6
Training loss: 2.6537771224975586
Validation loss: 2.3592313284515054

Epoch: 6| Step: 7
Training loss: 2.811911106109619
Validation loss: 2.346106703563403

Epoch: 6| Step: 8
Training loss: 2.4392495155334473
Validation loss: 2.335811174044045

Epoch: 6| Step: 9
Training loss: 2.3685832023620605
Validation loss: 2.3379193967388523

Epoch: 6| Step: 10
Training loss: 3.1594390869140625
Validation loss: 2.3291527917308192

Epoch: 6| Step: 11
Training loss: 1.9853672981262207
Validation loss: 2.3302486301750265

Epoch: 6| Step: 12
Training loss: 2.1142332553863525
Validation loss: 2.335617532012283

Epoch: 6| Step: 13
Training loss: 2.612407922744751
Validation loss: 2.3351508058527464

Epoch: 56| Step: 0
Training loss: 2.8209547996520996
Validation loss: 2.330460386891519

Epoch: 6| Step: 1
Training loss: 2.3789725303649902
Validation loss: 2.333117277391495

Epoch: 6| Step: 2
Training loss: 2.764042615890503
Validation loss: 2.336818487413468

Epoch: 6| Step: 3
Training loss: 1.808870792388916
Validation loss: 2.340397401522565

Epoch: 6| Step: 4
Training loss: 1.9260259866714478
Validation loss: 2.3369908435370332

Epoch: 6| Step: 5
Training loss: 2.8445167541503906
Validation loss: 2.3416353579490417

Epoch: 6| Step: 6
Training loss: 2.789590358734131
Validation loss: 2.331089054384539

Epoch: 6| Step: 7
Training loss: 3.2363228797912598
Validation loss: 2.335775875276135

Epoch: 6| Step: 8
Training loss: 2.4231491088867188
Validation loss: 2.3408262165643836

Epoch: 6| Step: 9
Training loss: 2.855983018875122
Validation loss: 2.341762363269765

Epoch: 6| Step: 10
Training loss: 2.905545234680176
Validation loss: 2.3324924694594515

Epoch: 6| Step: 11
Training loss: 2.1081206798553467
Validation loss: 2.3331701217159146

Epoch: 6| Step: 12
Training loss: 2.8518271446228027
Validation loss: 2.3413433413351736

Epoch: 6| Step: 13
Training loss: 2.3930790424346924
Validation loss: 2.343649151504681

Epoch: 57| Step: 0
Training loss: 2.0569705963134766
Validation loss: 2.3381324301483812

Epoch: 6| Step: 1
Training loss: 2.4042141437530518
Validation loss: 2.3556494815375215

Epoch: 6| Step: 2
Training loss: 2.5215091705322266
Validation loss: 2.3451304281911542

Epoch: 6| Step: 3
Training loss: 2.8865907192230225
Validation loss: 2.3345753813302643

Epoch: 6| Step: 4
Training loss: 2.4881680011749268
Validation loss: 2.332732741550733

Epoch: 6| Step: 5
Training loss: 2.7563421726226807
Validation loss: 2.329743681415435

Epoch: 6| Step: 6
Training loss: 2.299589157104492
Validation loss: 2.3443526734587965

Epoch: 6| Step: 7
Training loss: 2.4795570373535156
Validation loss: 2.3624473335922405

Epoch: 6| Step: 8
Training loss: 3.0524990558624268
Validation loss: 2.3505559582864084

Epoch: 6| Step: 9
Training loss: 2.6584649085998535
Validation loss: 2.3526127415318645

Epoch: 6| Step: 10
Training loss: 2.6328256130218506
Validation loss: 2.351197899028819

Epoch: 6| Step: 11
Training loss: 2.772059440612793
Validation loss: 2.3481660171221663

Epoch: 6| Step: 12
Training loss: 2.247159957885742
Validation loss: 2.3304236345393683

Epoch: 6| Step: 13
Training loss: 3.055666446685791
Validation loss: 2.331180182836389

Epoch: 58| Step: 0
Training loss: 3.590186834335327
Validation loss: 2.3216434627450924

Epoch: 6| Step: 1
Training loss: 2.115689754486084
Validation loss: 2.323189740539879

Epoch: 6| Step: 2
Training loss: 2.3429670333862305
Validation loss: 2.3195232370848298

Epoch: 6| Step: 3
Training loss: 2.755096673965454
Validation loss: 2.3261310054409887

Epoch: 6| Step: 4
Training loss: 1.622212290763855
Validation loss: 2.3186965988528345

Epoch: 6| Step: 5
Training loss: 2.456120491027832
Validation loss: 2.319604035346739

Epoch: 6| Step: 6
Training loss: 3.002350091934204
Validation loss: 2.3266324817493396

Epoch: 6| Step: 7
Training loss: 2.668254852294922
Validation loss: 2.335825243303853

Epoch: 6| Step: 8
Training loss: 2.3715860843658447
Validation loss: 2.3366822606773785

Epoch: 6| Step: 9
Training loss: 3.0450170040130615
Validation loss: 2.3402347282696794

Epoch: 6| Step: 10
Training loss: 1.863664150238037
Validation loss: 2.335282587235974

Epoch: 6| Step: 11
Training loss: 2.7121424674987793
Validation loss: 2.340136315232964

Epoch: 6| Step: 12
Training loss: 2.895197868347168
Validation loss: 2.337615264359341

Epoch: 6| Step: 13
Training loss: 2.7642359733581543
Validation loss: 2.3273605479989

Epoch: 59| Step: 0
Training loss: 2.7982518672943115
Validation loss: 2.3288584165675665

Epoch: 6| Step: 1
Training loss: 2.4480953216552734
Validation loss: 2.3256051309647097

Epoch: 6| Step: 2
Training loss: 3.085218906402588
Validation loss: 2.3286347876312914

Epoch: 6| Step: 3
Training loss: 2.059277057647705
Validation loss: 2.325498616823586

Epoch: 6| Step: 4
Training loss: 2.094362735748291
Validation loss: 2.322529685112738

Epoch: 6| Step: 5
Training loss: 2.862720251083374
Validation loss: 2.3285121456269295

Epoch: 6| Step: 6
Training loss: 2.8540878295898438
Validation loss: 2.340755388300906

Epoch: 6| Step: 7
Training loss: 2.755955219268799
Validation loss: 2.3395041419613745

Epoch: 6| Step: 8
Training loss: 3.356200695037842
Validation loss: 2.3373899049656366

Epoch: 6| Step: 9
Training loss: 1.7253053188323975
Validation loss: 2.3160987028511624

Epoch: 6| Step: 10
Training loss: 2.7996907234191895
Validation loss: 2.3048641092033795

Epoch: 6| Step: 11
Training loss: 2.457045078277588
Validation loss: 2.304082965338102

Epoch: 6| Step: 12
Training loss: 2.2010912895202637
Validation loss: 2.303428734502485

Epoch: 6| Step: 13
Training loss: 2.306044816970825
Validation loss: 2.308136240128548

Epoch: 60| Step: 0
Training loss: 1.634028673171997
Validation loss: 2.309128789491551

Epoch: 6| Step: 1
Training loss: 2.1498513221740723
Validation loss: 2.312535314149754

Epoch: 6| Step: 2
Training loss: 2.8301658630371094
Validation loss: 2.3263758510671635

Epoch: 6| Step: 3
Training loss: 3.0191290378570557
Validation loss: 2.3331799942960023

Epoch: 6| Step: 4
Training loss: 2.453378200531006
Validation loss: 2.341052883414812

Epoch: 6| Step: 5
Training loss: 2.86889910697937
Validation loss: 2.3731844784111105

Epoch: 6| Step: 6
Training loss: 2.815643787384033
Validation loss: 2.370356249552901

Epoch: 6| Step: 7
Training loss: 2.4756956100463867
Validation loss: 2.3509176213254213

Epoch: 6| Step: 8
Training loss: 2.7068371772766113
Validation loss: 2.3170090465135473

Epoch: 6| Step: 9
Training loss: 2.985844135284424
Validation loss: 2.3116389397651917

Epoch: 6| Step: 10
Training loss: 3.0513734817504883
Validation loss: 2.305827301035645

Epoch: 6| Step: 11
Training loss: 2.353400945663452
Validation loss: 2.3137733987582627

Epoch: 6| Step: 12
Training loss: 2.452866792678833
Validation loss: 2.320767666703911

Epoch: 6| Step: 13
Training loss: 2.0558061599731445
Validation loss: 2.3400865985501196

Epoch: 61| Step: 0
Training loss: 2.211369514465332
Validation loss: 2.327633391144455

Epoch: 6| Step: 1
Training loss: 2.826678991317749
Validation loss: 2.3161759094525407

Epoch: 6| Step: 2
Training loss: 3.1388373374938965
Validation loss: 2.3145774846435874

Epoch: 6| Step: 3
Training loss: 2.4714391231536865
Validation loss: 2.3043157362168833

Epoch: 6| Step: 4
Training loss: 2.135374069213867
Validation loss: 2.299240673741987

Epoch: 6| Step: 5
Training loss: 2.9835152626037598
Validation loss: 2.2948988470979916

Epoch: 6| Step: 6
Training loss: 1.9786689281463623
Validation loss: 2.2982416896409887

Epoch: 6| Step: 7
Training loss: 3.4979209899902344
Validation loss: 2.293825780191729

Epoch: 6| Step: 8
Training loss: 2.7916195392608643
Validation loss: 2.2936266135143977

Epoch: 6| Step: 9
Training loss: 2.5348525047302246
Validation loss: 2.3026138351809595

Epoch: 6| Step: 10
Training loss: 2.2056171894073486
Validation loss: 2.3173001889259583

Epoch: 6| Step: 11
Training loss: 2.275212526321411
Validation loss: 2.3220091019907305

Epoch: 6| Step: 12
Training loss: 2.338578701019287
Validation loss: 2.3251481979124007

Epoch: 6| Step: 13
Training loss: 2.529168128967285
Validation loss: 2.3310275693093576

Epoch: 62| Step: 0
Training loss: 2.6847290992736816
Validation loss: 2.346844906448036

Epoch: 6| Step: 1
Training loss: 1.2928471565246582
Validation loss: 2.373582834838539

Epoch: 6| Step: 2
Training loss: 2.9086239337921143
Validation loss: 2.3898061424173336

Epoch: 6| Step: 3
Training loss: 2.6950011253356934
Validation loss: 2.3818300744538665

Epoch: 6| Step: 4
Training loss: 3.0803492069244385
Validation loss: 2.377828909504798

Epoch: 6| Step: 5
Training loss: 2.172914981842041
Validation loss: 2.333660525660361

Epoch: 6| Step: 6
Training loss: 3.2495036125183105
Validation loss: 2.312745658300256

Epoch: 6| Step: 7
Training loss: 1.9072983264923096
Validation loss: 2.2970942886926795

Epoch: 6| Step: 8
Training loss: 3.198234796524048
Validation loss: 2.296231887673819

Epoch: 6| Step: 9
Training loss: 2.6478044986724854
Validation loss: 2.29378052167995

Epoch: 6| Step: 10
Training loss: 2.6873011589050293
Validation loss: 2.2966398654445523

Epoch: 6| Step: 11
Training loss: 2.408993721008301
Validation loss: 2.29990291595459

Epoch: 6| Step: 12
Training loss: 2.833773612976074
Validation loss: 2.3076362468863048

Epoch: 6| Step: 13
Training loss: 2.1392366886138916
Validation loss: 2.326413454548005

Epoch: 63| Step: 0
Training loss: 2.612981081008911
Validation loss: 2.339723325544788

Epoch: 6| Step: 1
Training loss: 2.450443983078003
Validation loss: 2.3456219421919955

Epoch: 6| Step: 2
Training loss: 2.4964699745178223
Validation loss: 2.3428011325097855

Epoch: 6| Step: 3
Training loss: 2.3198318481445312
Validation loss: 2.3466044907928794

Epoch: 6| Step: 4
Training loss: 3.0604348182678223
Validation loss: 2.321408433298911

Epoch: 6| Step: 5
Training loss: 2.6036438941955566
Validation loss: 2.299530780443581

Epoch: 6| Step: 6
Training loss: 2.6286110877990723
Validation loss: 2.2934876975192817

Epoch: 6| Step: 7
Training loss: 2.0786261558532715
Validation loss: 2.289156380520072

Epoch: 6| Step: 8
Training loss: 2.8651623725891113
Validation loss: 2.287455584413262

Epoch: 6| Step: 9
Training loss: 2.4459245204925537
Validation loss: 2.2846393533932265

Epoch: 6| Step: 10
Training loss: 2.296919584274292
Validation loss: 2.2856226557044574

Epoch: 6| Step: 11
Training loss: 2.7804393768310547
Validation loss: 2.2829027124630508

Epoch: 6| Step: 12
Training loss: 2.629120111465454
Validation loss: 2.2800137432672645

Epoch: 6| Step: 13
Training loss: 2.5322983264923096
Validation loss: 2.2827675829651537

Epoch: 64| Step: 0
Training loss: 2.5228288173675537
Validation loss: 2.2864464534226285

Epoch: 6| Step: 1
Training loss: 2.5306620597839355
Validation loss: 2.293972522981705

Epoch: 6| Step: 2
Training loss: 2.185936450958252
Validation loss: 2.322585303296325

Epoch: 6| Step: 3
Training loss: 2.602586507797241
Validation loss: 2.3671664294376167

Epoch: 6| Step: 4
Training loss: 3.180105209350586
Validation loss: 2.4218667578953568

Epoch: 6| Step: 5
Training loss: 2.6229844093322754
Validation loss: 2.448363980939311

Epoch: 6| Step: 6
Training loss: 2.9771649837493896
Validation loss: 2.433057379978959

Epoch: 6| Step: 7
Training loss: 2.5343494415283203
Validation loss: 2.391316898407475

Epoch: 6| Step: 8
Training loss: 2.8066253662109375
Validation loss: 2.3563744355273504

Epoch: 6| Step: 9
Training loss: 1.8930715322494507
Validation loss: 2.318134989789737

Epoch: 6| Step: 10
Training loss: 2.942687749862671
Validation loss: 2.290891703738961

Epoch: 6| Step: 11
Training loss: 2.8359813690185547
Validation loss: 2.284704226319508

Epoch: 6| Step: 12
Training loss: 2.0007693767547607
Validation loss: 2.2839725440548313

Epoch: 6| Step: 13
Training loss: 2.3254973888397217
Validation loss: 2.2949087389053835

Epoch: 65| Step: 0
Training loss: 2.4324865341186523
Validation loss: 2.307534763889928

Epoch: 6| Step: 1
Training loss: 2.1683592796325684
Validation loss: 2.3064933925546627

Epoch: 6| Step: 2
Training loss: 1.9624288082122803
Validation loss: 2.3084624480175715

Epoch: 6| Step: 3
Training loss: 2.9925403594970703
Validation loss: 2.3116695137434107

Epoch: 6| Step: 4
Training loss: 2.968099594116211
Validation loss: 2.3123696465646066

Epoch: 6| Step: 5
Training loss: 2.746458053588867
Validation loss: 2.306865502429265

Epoch: 6| Step: 6
Training loss: 2.6747894287109375
Validation loss: 2.3020211342842347

Epoch: 6| Step: 7
Training loss: 2.8495287895202637
Validation loss: 2.300490258842386

Epoch: 6| Step: 8
Training loss: 2.7789902687072754
Validation loss: 2.3036975206867343

Epoch: 6| Step: 9
Training loss: 2.933323383331299
Validation loss: 2.309596724407647

Epoch: 6| Step: 10
Training loss: 2.221592426300049
Validation loss: 2.3127798803390993

Epoch: 6| Step: 11
Training loss: 2.0800631046295166
Validation loss: 2.3241043372820784

Epoch: 6| Step: 12
Training loss: 2.376375198364258
Validation loss: 2.3401152395432994

Epoch: 6| Step: 13
Training loss: 2.8097949028015137
Validation loss: 2.3420323684651363

Epoch: 66| Step: 0
Training loss: 2.7855262756347656
Validation loss: 2.3368632562698854

Epoch: 6| Step: 1
Training loss: 3.1244192123413086
Validation loss: 2.342101127870621

Epoch: 6| Step: 2
Training loss: 2.8274271488189697
Validation loss: 2.3338163129744993

Epoch: 6| Step: 3
Training loss: 2.0738067626953125
Validation loss: 2.3305194249717136

Epoch: 6| Step: 4
Training loss: 2.5429787635803223
Validation loss: 2.3400588548311623

Epoch: 6| Step: 5
Training loss: 2.353193521499634
Validation loss: 2.3410825998552385

Epoch: 6| Step: 6
Training loss: 1.8563967943191528
Validation loss: 2.3382020637553227

Epoch: 6| Step: 7
Training loss: 2.4831252098083496
Validation loss: 2.3403123194171536

Epoch: 6| Step: 8
Training loss: 3.0968658924102783
Validation loss: 2.326590471370246

Epoch: 6| Step: 9
Training loss: 2.9786758422851562
Validation loss: 2.316636367510724

Epoch: 6| Step: 10
Training loss: 2.3210084438323975
Validation loss: 2.31230858320831

Epoch: 6| Step: 11
Training loss: 2.2538068294525146
Validation loss: 2.301847909086494

Epoch: 6| Step: 12
Training loss: 2.5876240730285645
Validation loss: 2.302603265290619

Epoch: 6| Step: 13
Training loss: 2.155482530593872
Validation loss: 2.296771995482906

Epoch: 67| Step: 0
Training loss: 2.8984813690185547
Validation loss: 2.2903443126268286

Epoch: 6| Step: 1
Training loss: 3.2859926223754883
Validation loss: 2.2853372071378972

Epoch: 6| Step: 2
Training loss: 3.01607608795166
Validation loss: 2.2805919506216563

Epoch: 6| Step: 3
Training loss: 2.20542573928833
Validation loss: 2.2759779345604683

Epoch: 6| Step: 4
Training loss: 1.5497407913208008
Validation loss: 2.281103972465761

Epoch: 6| Step: 5
Training loss: 2.597532033920288
Validation loss: 2.2793751737122894

Epoch: 6| Step: 6
Training loss: 2.767883539199829
Validation loss: 2.2775888212265505

Epoch: 6| Step: 7
Training loss: 2.440432071685791
Validation loss: 2.2805942925073768

Epoch: 6| Step: 8
Training loss: 2.6306214332580566
Validation loss: 2.2880996709228842

Epoch: 6| Step: 9
Training loss: 1.9231760501861572
Validation loss: 2.3077555830760668

Epoch: 6| Step: 10
Training loss: 2.510143995285034
Validation loss: 2.321188190931915

Epoch: 6| Step: 11
Training loss: 2.648117780685425
Validation loss: 2.3395121969202513

Epoch: 6| Step: 12
Training loss: 2.436871290206909
Validation loss: 2.3462964052795083

Epoch: 6| Step: 13
Training loss: 3.057968854904175
Validation loss: 2.345959592890996

Epoch: 68| Step: 0
Training loss: 3.0150537490844727
Validation loss: 2.3247927824656167

Epoch: 6| Step: 1
Training loss: 2.176967144012451
Validation loss: 2.2820525797464515

Epoch: 6| Step: 2
Training loss: 1.9122029542922974
Validation loss: 2.2719149640811387

Epoch: 6| Step: 3
Training loss: 2.5580952167510986
Validation loss: 2.266673562347248

Epoch: 6| Step: 4
Training loss: 1.788250207901001
Validation loss: 2.2679154257620535

Epoch: 6| Step: 5
Training loss: 2.961815357208252
Validation loss: 2.2714580746107202

Epoch: 6| Step: 6
Training loss: 3.2138671875
Validation loss: 2.265363600946242

Epoch: 6| Step: 7
Training loss: 2.437741994857788
Validation loss: 2.2700118480190152

Epoch: 6| Step: 8
Training loss: 2.513650894165039
Validation loss: 2.270589633654523

Epoch: 6| Step: 9
Training loss: 2.1570682525634766
Validation loss: 2.2724634729405886

Epoch: 6| Step: 10
Training loss: 2.0973002910614014
Validation loss: 2.2733175472546647

Epoch: 6| Step: 11
Training loss: 2.869886636734009
Validation loss: 2.2840072826672624

Epoch: 6| Step: 12
Training loss: 2.878941535949707
Validation loss: 2.295696122671968

Epoch: 6| Step: 13
Training loss: 3.583139181137085
Validation loss: 2.3133186063458844

Epoch: 69| Step: 0
Training loss: 2.500826358795166
Validation loss: 2.3214311394640195

Epoch: 6| Step: 1
Training loss: 2.7540957927703857
Validation loss: 2.320039410744944

Epoch: 6| Step: 2
Training loss: 2.8865771293640137
Validation loss: 2.329060485286097

Epoch: 6| Step: 3
Training loss: 2.14174485206604
Validation loss: 2.3257133255722704

Epoch: 6| Step: 4
Training loss: 2.492969036102295
Validation loss: 2.322888646074521

Epoch: 6| Step: 5
Training loss: 3.0220017433166504
Validation loss: 2.3120642554375435

Epoch: 6| Step: 6
Training loss: 2.662013053894043
Validation loss: 2.2863637042301956

Epoch: 6| Step: 7
Training loss: 2.433960199356079
Validation loss: 2.277097289280225

Epoch: 6| Step: 8
Training loss: 2.3293445110321045
Validation loss: 2.2724117540544078

Epoch: 6| Step: 9
Training loss: 1.9839569330215454
Validation loss: 2.265028856133902

Epoch: 6| Step: 10
Training loss: 2.268965244293213
Validation loss: 2.276580866946969

Epoch: 6| Step: 11
Training loss: 3.1329994201660156
Validation loss: 2.2634878389296995

Epoch: 6| Step: 12
Training loss: 2.8130383491516113
Validation loss: 2.2655608577112996

Epoch: 6| Step: 13
Training loss: 1.7595528364181519
Validation loss: 2.266141986334196

Epoch: 70| Step: 0
Training loss: 2.6558549404144287
Validation loss: 2.263982644645117

Epoch: 6| Step: 1
Training loss: 2.885690927505493
Validation loss: 2.2625740497343

Epoch: 6| Step: 2
Training loss: 2.4919304847717285
Validation loss: 2.2742409834297757

Epoch: 6| Step: 3
Training loss: 2.755685567855835
Validation loss: 2.2948902448018393

Epoch: 6| Step: 4
Training loss: 2.496339797973633
Validation loss: 2.322604012745683

Epoch: 6| Step: 5
Training loss: 2.2808542251586914
Validation loss: 2.311089741286411

Epoch: 6| Step: 6
Training loss: 2.721693515777588
Validation loss: 2.30458931000002

Epoch: 6| Step: 7
Training loss: 2.1173367500305176
Validation loss: 2.3005237425527265

Epoch: 6| Step: 8
Training loss: 2.885463237762451
Validation loss: 2.3021804696770123

Epoch: 6| Step: 9
Training loss: 2.040924549102783
Validation loss: 2.288789943982196

Epoch: 6| Step: 10
Training loss: 2.302621603012085
Validation loss: 2.2852172467016403

Epoch: 6| Step: 11
Training loss: 2.7355093955993652
Validation loss: 2.2764884861566688

Epoch: 6| Step: 12
Training loss: 2.652947425842285
Validation loss: 2.269279977326752

Epoch: 6| Step: 13
Training loss: 2.2633094787597656
Validation loss: 2.2621799130593576

Epoch: 71| Step: 0
Training loss: 2.584868907928467
Validation loss: 2.2657805142864103

Epoch: 6| Step: 1
Training loss: 2.295328378677368
Validation loss: 2.262306756870721

Epoch: 6| Step: 2
Training loss: 2.478771209716797
Validation loss: 2.2736410479391775

Epoch: 6| Step: 3
Training loss: 3.157025098800659
Validation loss: 2.274794452933855

Epoch: 6| Step: 4
Training loss: 2.579277515411377
Validation loss: 2.2683446253499677

Epoch: 6| Step: 5
Training loss: 2.4153261184692383
Validation loss: 2.2624962150409655

Epoch: 6| Step: 6
Training loss: 2.5084104537963867
Validation loss: 2.251756127162646

Epoch: 6| Step: 7
Training loss: 2.2142419815063477
Validation loss: 2.249151340094946

Epoch: 6| Step: 8
Training loss: 3.227783203125
Validation loss: 2.257315589535621

Epoch: 6| Step: 9
Training loss: 2.3240714073181152
Validation loss: 2.2537173340397496

Epoch: 6| Step: 10
Training loss: 2.32576060295105
Validation loss: 2.2561169593564925

Epoch: 6| Step: 11
Training loss: 2.084514617919922
Validation loss: 2.2608171419430803

Epoch: 6| Step: 12
Training loss: 3.0289077758789062
Validation loss: 2.280381618007537

Epoch: 6| Step: 13
Training loss: 2.081481456756592
Validation loss: 2.3006377758518344

Epoch: 72| Step: 0
Training loss: 2.5764212608337402
Validation loss: 2.308401100097164

Epoch: 6| Step: 1
Training loss: 1.4090598821640015
Validation loss: 2.3204326962911956

Epoch: 6| Step: 2
Training loss: 2.1017284393310547
Validation loss: 2.325645051976686

Epoch: 6| Step: 3
Training loss: 3.0862205028533936
Validation loss: 2.3218840988733436

Epoch: 6| Step: 4
Training loss: 2.485755443572998
Validation loss: 2.301693788138769

Epoch: 6| Step: 5
Training loss: 3.429537057876587
Validation loss: 2.287130537853446

Epoch: 6| Step: 6
Training loss: 2.350555896759033
Validation loss: 2.259902333700529

Epoch: 6| Step: 7
Training loss: 2.6976351737976074
Validation loss: 2.252527559957197

Epoch: 6| Step: 8
Training loss: 3.5927648544311523
Validation loss: 2.25398463203061

Epoch: 6| Step: 9
Training loss: 1.9384583234786987
Validation loss: 2.263571334141557

Epoch: 6| Step: 10
Training loss: 2.2301652431488037
Validation loss: 2.262311622660647

Epoch: 6| Step: 11
Training loss: 2.3721985816955566
Validation loss: 2.2823690317010366

Epoch: 6| Step: 12
Training loss: 2.3498713970184326
Validation loss: 2.3012533239139024

Epoch: 6| Step: 13
Training loss: 2.961949586868286
Validation loss: 2.3114607744319464

Epoch: 73| Step: 0
Training loss: 2.8477439880371094
Validation loss: 2.3065483595735286

Epoch: 6| Step: 1
Training loss: 2.539853096008301
Validation loss: 2.329263805061258

Epoch: 6| Step: 2
Training loss: 2.5602691173553467
Validation loss: 2.339852007486487

Epoch: 6| Step: 3
Training loss: 3.1965219974517822
Validation loss: 2.3506433348501883

Epoch: 6| Step: 4
Training loss: 2.4239981174468994
Validation loss: 2.339138456570205

Epoch: 6| Step: 5
Training loss: 2.273200273513794
Validation loss: 2.3061297068031887

Epoch: 6| Step: 6
Training loss: 2.5841047763824463
Validation loss: 2.288031683173231

Epoch: 6| Step: 7
Training loss: 2.464205265045166
Validation loss: 2.2845379485878894

Epoch: 6| Step: 8
Training loss: 1.9862135648727417
Validation loss: 2.275132994497976

Epoch: 6| Step: 9
Training loss: 2.264370918273926
Validation loss: 2.2862331328853482

Epoch: 6| Step: 10
Training loss: 3.062671661376953
Validation loss: 2.2920999116795038

Epoch: 6| Step: 11
Training loss: 2.663634777069092
Validation loss: 2.300805586640553

Epoch: 6| Step: 12
Training loss: 2.0810062885284424
Validation loss: 2.3013640629347933

Epoch: 6| Step: 13
Training loss: 2.5136642456054688
Validation loss: 2.2961276372273765

Epoch: 74| Step: 0
Training loss: 2.760995864868164
Validation loss: 2.283376378397788

Epoch: 6| Step: 1
Training loss: 2.7452993392944336
Validation loss: 2.2800919368702877

Epoch: 6| Step: 2
Training loss: 2.554750680923462
Validation loss: 2.271699264485349

Epoch: 6| Step: 3
Training loss: 2.280374526977539
Validation loss: 2.2744365353738107

Epoch: 6| Step: 4
Training loss: 2.5204226970672607
Validation loss: 2.269016847815565

Epoch: 6| Step: 5
Training loss: 2.1385459899902344
Validation loss: 2.25358501813745

Epoch: 6| Step: 6
Training loss: 2.4677486419677734
Validation loss: 2.267989562403771

Epoch: 6| Step: 7
Training loss: 2.5026841163635254
Validation loss: 2.2802606551877913

Epoch: 6| Step: 8
Training loss: 2.446397304534912
Validation loss: 2.2849565141944477

Epoch: 6| Step: 9
Training loss: 2.1236941814422607
Validation loss: 2.3132553664586877

Epoch: 6| Step: 10
Training loss: 3.181741237640381
Validation loss: 2.3457360972640333

Epoch: 6| Step: 11
Training loss: 2.4223241806030273
Validation loss: 2.3761364285663893

Epoch: 6| Step: 12
Training loss: 2.737126350402832
Validation loss: 2.436133312922652

Epoch: 6| Step: 13
Training loss: 2.456153631210327
Validation loss: 2.4098828966899584

Epoch: 75| Step: 0
Training loss: 2.5470752716064453
Validation loss: 2.3132361545357654

Epoch: 6| Step: 1
Training loss: 2.828542709350586
Validation loss: 2.2712568570208806

Epoch: 6| Step: 2
Training loss: 2.368983268737793
Validation loss: 2.2470757576727096

Epoch: 6| Step: 3
Training loss: 2.1380929946899414
Validation loss: 2.2381857210589993

Epoch: 6| Step: 4
Training loss: 2.6596574783325195
Validation loss: 2.2424484529802875

Epoch: 6| Step: 5
Training loss: 2.848766326904297
Validation loss: 2.2456624354085615

Epoch: 6| Step: 6
Training loss: 2.1567182540893555
Validation loss: 2.248055229904831

Epoch: 6| Step: 7
Training loss: 2.2344939708709717
Validation loss: 2.250329038148285

Epoch: 6| Step: 8
Training loss: 2.719668388366699
Validation loss: 2.2528384193297355

Epoch: 6| Step: 9
Training loss: 2.5590620040893555
Validation loss: 2.257752585154708

Epoch: 6| Step: 10
Training loss: 2.6152892112731934
Validation loss: 2.258946987890428

Epoch: 6| Step: 11
Training loss: 3.116424322128296
Validation loss: 2.2607942704231507

Epoch: 6| Step: 12
Training loss: 2.255573272705078
Validation loss: 2.267032015708185

Epoch: 6| Step: 13
Training loss: 2.181212902069092
Validation loss: 2.263678930139029

Epoch: 76| Step: 0
Training loss: 2.3867475986480713
Validation loss: 2.2597212124896306

Epoch: 6| Step: 1
Training loss: 2.906933069229126
Validation loss: 2.256326224214287

Epoch: 6| Step: 2
Training loss: 1.9136910438537598
Validation loss: 2.257831791395782

Epoch: 6| Step: 3
Training loss: 3.078000783920288
Validation loss: 2.25692843878141

Epoch: 6| Step: 4
Training loss: 2.3711681365966797
Validation loss: 2.275704711996099

Epoch: 6| Step: 5
Training loss: 2.3964881896972656
Validation loss: 2.309346524618005

Epoch: 6| Step: 6
Training loss: 2.8676962852478027
Validation loss: 2.3617795000794115

Epoch: 6| Step: 7
Training loss: 2.613398313522339
Validation loss: 2.3639979926488732

Epoch: 6| Step: 8
Training loss: 2.817713975906372
Validation loss: 2.343954934868761

Epoch: 6| Step: 9
Training loss: 2.32102108001709
Validation loss: 2.3326758005285777

Epoch: 6| Step: 10
Training loss: 2.672386646270752
Validation loss: 2.3141712091302358

Epoch: 6| Step: 11
Training loss: 2.6885552406311035
Validation loss: 2.2791924271532285

Epoch: 6| Step: 12
Training loss: 1.845991849899292
Validation loss: 2.2599293775455926

Epoch: 6| Step: 13
Training loss: 2.1930859088897705
Validation loss: 2.247690881452253

Epoch: 77| Step: 0
Training loss: 3.448143243789673
Validation loss: 2.2452681064605713

Epoch: 6| Step: 1
Training loss: 2.8879809379577637
Validation loss: 2.2434898909702095

Epoch: 6| Step: 2
Training loss: 2.2854697704315186
Validation loss: 2.2499374215320875

Epoch: 6| Step: 3
Training loss: 2.7249155044555664
Validation loss: 2.249408059222724

Epoch: 6| Step: 4
Training loss: 2.269599437713623
Validation loss: 2.251141368701894

Epoch: 6| Step: 5
Training loss: 3.1693472862243652
Validation loss: 2.2575001408976894

Epoch: 6| Step: 6
Training loss: 3.0159378051757812
Validation loss: 2.25519379749093

Epoch: 6| Step: 7
Training loss: 2.6274635791778564
Validation loss: 2.253733860549106

Epoch: 6| Step: 8
Training loss: 2.115063428878784
Validation loss: 2.2624502951099026

Epoch: 6| Step: 9
Training loss: 2.606081008911133
Validation loss: 2.2737548684561126

Epoch: 6| Step: 10
Training loss: 2.164361000061035
Validation loss: 2.3046776710018033

Epoch: 6| Step: 11
Training loss: 1.8457331657409668
Validation loss: 2.318089714614294

Epoch: 6| Step: 12
Training loss: 1.8087106943130493
Validation loss: 2.327887551758879

Epoch: 6| Step: 13
Training loss: 1.9049434661865234
Validation loss: 2.312887566063994

Epoch: 78| Step: 0
Training loss: 2.3655498027801514
Validation loss: 2.2844122404693277

Epoch: 6| Step: 1
Training loss: 2.415372610092163
Validation loss: 2.2692625317522275

Epoch: 6| Step: 2
Training loss: 2.662385940551758
Validation loss: 2.2583301862080893

Epoch: 6| Step: 3
Training loss: 2.5919814109802246
Validation loss: 2.242666567525556

Epoch: 6| Step: 4
Training loss: 1.9489624500274658
Validation loss: 2.229129716914187

Epoch: 6| Step: 5
Training loss: 2.5953869819641113
Validation loss: 2.222089834110711

Epoch: 6| Step: 6
Training loss: 2.2888166904449463
Validation loss: 2.220902269886386

Epoch: 6| Step: 7
Training loss: 3.0363364219665527
Validation loss: 2.2199515117112028

Epoch: 6| Step: 8
Training loss: 2.532498836517334
Validation loss: 2.2242939446562078

Epoch: 6| Step: 9
Training loss: 2.9807262420654297
Validation loss: 2.2241870767326763

Epoch: 6| Step: 10
Training loss: 2.4137024879455566
Validation loss: 2.2228524966906478

Epoch: 6| Step: 11
Training loss: 2.2302005290985107
Validation loss: 2.2320527620213007

Epoch: 6| Step: 12
Training loss: 2.5269110202789307
Validation loss: 2.238469454549974

Epoch: 6| Step: 13
Training loss: 2.451387643814087
Validation loss: 2.2436089233685563

Epoch: 79| Step: 0
Training loss: 2.762631416320801
Validation loss: 2.2561528144344205

Epoch: 6| Step: 1
Training loss: 2.906550645828247
Validation loss: 2.269758560324228

Epoch: 6| Step: 2
Training loss: 2.237250566482544
Validation loss: 2.2679842466949136

Epoch: 6| Step: 3
Training loss: 2.241520404815674
Validation loss: 2.2685117260102303

Epoch: 6| Step: 4
Training loss: 2.926987648010254
Validation loss: 2.2639495377899497

Epoch: 6| Step: 5
Training loss: 2.2402560710906982
Validation loss: 2.26281463971702

Epoch: 6| Step: 6
Training loss: 2.672236204147339
Validation loss: 2.276339542481207

Epoch: 6| Step: 7
Training loss: 2.9539265632629395
Validation loss: 2.2859933965949604

Epoch: 6| Step: 8
Training loss: 1.869623064994812
Validation loss: 2.2827422798320813

Epoch: 6| Step: 9
Training loss: 2.416835308074951
Validation loss: 2.306928861525751

Epoch: 6| Step: 10
Training loss: 1.9193384647369385
Validation loss: 2.3080029949065177

Epoch: 6| Step: 11
Training loss: 3.18727970123291
Validation loss: 2.2959567218698482

Epoch: 6| Step: 12
Training loss: 2.141528367996216
Validation loss: 2.2717610712974303

Epoch: 6| Step: 13
Training loss: 2.2523679733276367
Validation loss: 2.258058037809146

Epoch: 80| Step: 0
Training loss: 2.718977928161621
Validation loss: 2.2474030602362847

Epoch: 6| Step: 1
Training loss: 2.3041775226593018
Validation loss: 2.239653120758713

Epoch: 6| Step: 2
Training loss: 1.7150425910949707
Validation loss: 2.239316245561005

Epoch: 6| Step: 3
Training loss: 2.977102518081665
Validation loss: 2.248726265404814

Epoch: 6| Step: 4
Training loss: 2.558544635772705
Validation loss: 2.2529691957658335

Epoch: 6| Step: 5
Training loss: 1.9266437292099
Validation loss: 2.2551197954403457

Epoch: 6| Step: 6
Training loss: 2.555269956588745
Validation loss: 2.257025746889012

Epoch: 6| Step: 7
Training loss: 2.499028205871582
Validation loss: 2.280140952397418

Epoch: 6| Step: 8
Training loss: 2.3910717964172363
Validation loss: 2.261887647772348

Epoch: 6| Step: 9
Training loss: 3.006890296936035
Validation loss: 2.247872637164208

Epoch: 6| Step: 10
Training loss: 2.5358142852783203
Validation loss: 2.23482338587443

Epoch: 6| Step: 11
Training loss: 2.643359899520874
Validation loss: 2.2275483864609913

Epoch: 6| Step: 12
Training loss: 2.292628288269043
Validation loss: 2.22204376164303

Epoch: 6| Step: 13
Training loss: 2.797821044921875
Validation loss: 2.225412376465336

Epoch: 81| Step: 0
Training loss: 0.7610131502151489
Validation loss: 2.235150808929115

Epoch: 6| Step: 1
Training loss: 2.552309989929199
Validation loss: 2.2515693505605063

Epoch: 6| Step: 2
Training loss: 1.9287598133087158
Validation loss: 2.2668541195572063

Epoch: 6| Step: 3
Training loss: 3.369694948196411
Validation loss: 2.293157918478853

Epoch: 6| Step: 4
Training loss: 3.1971378326416016
Validation loss: 2.294600768755841

Epoch: 6| Step: 5
Training loss: 2.6535897254943848
Validation loss: 2.292355486141738

Epoch: 6| Step: 6
Training loss: 2.7712595462799072
Validation loss: 2.287904954725696

Epoch: 6| Step: 7
Training loss: 2.3009982109069824
Validation loss: 2.268859964545055

Epoch: 6| Step: 8
Training loss: 2.33450984954834
Validation loss: 2.249796317469689

Epoch: 6| Step: 9
Training loss: 2.6531734466552734
Validation loss: 2.228194172664355

Epoch: 6| Step: 10
Training loss: 1.9608449935913086
Validation loss: 2.222043421960646

Epoch: 6| Step: 11
Training loss: 2.8210740089416504
Validation loss: 2.220316790765332

Epoch: 6| Step: 12
Training loss: 2.33089017868042
Validation loss: 2.216162450851933

Epoch: 6| Step: 13
Training loss: 3.6765432357788086
Validation loss: 2.2235235962816464

Epoch: 82| Step: 0
Training loss: 2.722477436065674
Validation loss: 2.220276589034706

Epoch: 6| Step: 1
Training loss: 2.1275439262390137
Validation loss: 2.2259621556087206

Epoch: 6| Step: 2
Training loss: 3.0438733100891113
Validation loss: 2.2240628811620895

Epoch: 6| Step: 3
Training loss: 2.078578472137451
Validation loss: 2.225284581543297

Epoch: 6| Step: 4
Training loss: 2.072734832763672
Validation loss: 2.220881200605823

Epoch: 6| Step: 5
Training loss: 2.3992364406585693
Validation loss: 2.2200212888820197

Epoch: 6| Step: 6
Training loss: 2.576206684112549
Validation loss: 2.2129573219565937

Epoch: 6| Step: 7
Training loss: 2.278186321258545
Validation loss: 2.2319679208981094

Epoch: 6| Step: 8
Training loss: 2.1544079780578613
Validation loss: 2.239689847474457

Epoch: 6| Step: 9
Training loss: 2.1980948448181152
Validation loss: 2.2544468833554174

Epoch: 6| Step: 10
Training loss: 3.2443721294403076
Validation loss: 2.285182576025686

Epoch: 6| Step: 11
Training loss: 2.5362565517425537
Validation loss: 2.293658520585747

Epoch: 6| Step: 12
Training loss: 2.671023368835449
Validation loss: 2.2940680621772684

Epoch: 6| Step: 13
Training loss: 3.4267184734344482
Validation loss: 2.2841057944041427

Epoch: 83| Step: 0
Training loss: 2.5892016887664795
Validation loss: 2.2963257528120473

Epoch: 6| Step: 1
Training loss: 2.0097341537475586
Validation loss: 2.295989433924357

Epoch: 6| Step: 2
Training loss: 3.3091816902160645
Validation loss: 2.2781159980322725

Epoch: 6| Step: 3
Training loss: 2.5161995887756348
Validation loss: 2.250231227567119

Epoch: 6| Step: 4
Training loss: 2.532993793487549
Validation loss: 2.2516857347180768

Epoch: 6| Step: 5
Training loss: 1.4029769897460938
Validation loss: 2.23627995931974

Epoch: 6| Step: 6
Training loss: 2.7126550674438477
Validation loss: 2.2335432908868276

Epoch: 6| Step: 7
Training loss: 2.7794229984283447
Validation loss: 2.2282971669268865

Epoch: 6| Step: 8
Training loss: 2.7674760818481445
Validation loss: 2.232556161060128

Epoch: 6| Step: 9
Training loss: 2.404917001724243
Validation loss: 2.237551801948137

Epoch: 6| Step: 10
Training loss: 1.6341328620910645
Validation loss: 2.2494276031371085

Epoch: 6| Step: 11
Training loss: 2.54465651512146
Validation loss: 2.25019048875378

Epoch: 6| Step: 12
Training loss: 2.6391632556915283
Validation loss: 2.257237078041159

Epoch: 6| Step: 13
Training loss: 2.990954875946045
Validation loss: 2.249735878359887

Epoch: 84| Step: 0
Training loss: 2.8822383880615234
Validation loss: 2.24620178181638

Epoch: 6| Step: 1
Training loss: 2.318380355834961
Validation loss: 2.2502698770133396

Epoch: 6| Step: 2
Training loss: 2.0827267169952393
Validation loss: 2.240083932876587

Epoch: 6| Step: 3
Training loss: 2.6792678833007812
Validation loss: 2.2315705053267942

Epoch: 6| Step: 4
Training loss: 2.3479204177856445
Validation loss: 2.233160072757352

Epoch: 6| Step: 5
Training loss: 2.6640748977661133
Validation loss: 2.2297628502691946

Epoch: 6| Step: 6
Training loss: 2.9468533992767334
Validation loss: 2.2183473725472727

Epoch: 6| Step: 7
Training loss: 2.3169639110565186
Validation loss: 2.245483934238393

Epoch: 6| Step: 8
Training loss: 1.8032338619232178
Validation loss: 2.249390786693942

Epoch: 6| Step: 9
Training loss: 2.8325061798095703
Validation loss: 2.2370135040693384

Epoch: 6| Step: 10
Training loss: 2.3553247451782227
Validation loss: 2.2240188403796126

Epoch: 6| Step: 11
Training loss: 2.5715384483337402
Validation loss: 2.2222360103361067

Epoch: 6| Step: 12
Training loss: 1.8014085292816162
Validation loss: 2.2178206456604825

Epoch: 6| Step: 13
Training loss: 3.2957818508148193
Validation loss: 2.2237981750119116

Epoch: 85| Step: 0
Training loss: 3.1045093536376953
Validation loss: 2.238225272906724

Epoch: 6| Step: 1
Training loss: 2.2507195472717285
Validation loss: 2.2450415242102837

Epoch: 6| Step: 2
Training loss: 2.6302130222320557
Validation loss: 2.2478888778276342

Epoch: 6| Step: 3
Training loss: 2.5140957832336426
Validation loss: 2.244366527885519

Epoch: 6| Step: 4
Training loss: 1.8010368347167969
Validation loss: 2.239724979605726

Epoch: 6| Step: 5
Training loss: 2.095590591430664
Validation loss: 2.2453329191412976

Epoch: 6| Step: 6
Training loss: 2.1156094074249268
Validation loss: 2.256743199081831

Epoch: 6| Step: 7
Training loss: 1.8568267822265625
Validation loss: 2.25152434584915

Epoch: 6| Step: 8
Training loss: 3.2990217208862305
Validation loss: 2.251956196241481

Epoch: 6| Step: 9
Training loss: 2.2489771842956543
Validation loss: 2.2604021462061072

Epoch: 6| Step: 10
Training loss: 2.7198734283447266
Validation loss: 2.2590312560399375

Epoch: 6| Step: 11
Training loss: 2.4106101989746094
Validation loss: 2.249582379095016

Epoch: 6| Step: 12
Training loss: 2.4069676399230957
Validation loss: 2.2367791129696752

Epoch: 6| Step: 13
Training loss: 3.1873183250427246
Validation loss: 2.2347752483942176

Epoch: 86| Step: 0
Training loss: 2.192004680633545
Validation loss: 2.228097959231305

Epoch: 6| Step: 1
Training loss: 2.122176170349121
Validation loss: 2.240781613575515

Epoch: 6| Step: 2
Training loss: 2.3665733337402344
Validation loss: 2.2374356228818177

Epoch: 6| Step: 3
Training loss: 2.705873489379883
Validation loss: 2.234230572177518

Epoch: 6| Step: 4
Training loss: 2.023681163787842
Validation loss: 2.2163531472606044

Epoch: 6| Step: 5
Training loss: 2.1776814460754395
Validation loss: 2.218369701857208

Epoch: 6| Step: 6
Training loss: 2.7692947387695312
Validation loss: 2.227720788730088

Epoch: 6| Step: 7
Training loss: 3.5085396766662598
Validation loss: 2.223029951895437

Epoch: 6| Step: 8
Training loss: 1.6068544387817383
Validation loss: 2.2386943422338015

Epoch: 6| Step: 9
Training loss: 2.552217721939087
Validation loss: 2.2537068961769022

Epoch: 6| Step: 10
Training loss: 2.640474796295166
Validation loss: 2.269609192366241

Epoch: 6| Step: 11
Training loss: 2.298034191131592
Validation loss: 2.2901578154615176

Epoch: 6| Step: 12
Training loss: 2.8616931438446045
Validation loss: 2.273515575675554

Epoch: 6| Step: 13
Training loss: 2.7519848346710205
Validation loss: 2.2826674215255247

Epoch: 87| Step: 0
Training loss: 2.273963212966919
Validation loss: 2.257004084125642

Epoch: 6| Step: 1
Training loss: 2.3345134258270264
Validation loss: 2.238217637103091

Epoch: 6| Step: 2
Training loss: 3.2600958347320557
Validation loss: 2.2256300551916963

Epoch: 6| Step: 3
Training loss: 2.1166329383850098
Validation loss: 2.23921396270875

Epoch: 6| Step: 4
Training loss: 2.2437329292297363
Validation loss: 2.230656600767566

Epoch: 6| Step: 5
Training loss: 2.7539424896240234
Validation loss: 2.2316689183635097

Epoch: 6| Step: 6
Training loss: 2.014678955078125
Validation loss: 2.234474782020815

Epoch: 6| Step: 7
Training loss: 2.4641456604003906
Validation loss: 2.2215860082257177

Epoch: 6| Step: 8
Training loss: 3.0737853050231934
Validation loss: 2.221348657402941

Epoch: 6| Step: 9
Training loss: 1.7607083320617676
Validation loss: 2.2302273063249487

Epoch: 6| Step: 10
Training loss: 3.086533546447754
Validation loss: 2.2401879820772397

Epoch: 6| Step: 11
Training loss: 2.314098596572876
Validation loss: 2.2393815466152724

Epoch: 6| Step: 12
Training loss: 2.428600311279297
Validation loss: 2.250294872509536

Epoch: 6| Step: 13
Training loss: 2.1425862312316895
Validation loss: 2.2517629618285806

Epoch: 88| Step: 0
Training loss: 2.780379295349121
Validation loss: 2.2512939847925657

Epoch: 6| Step: 1
Training loss: 2.4471635818481445
Validation loss: 2.237746830909483

Epoch: 6| Step: 2
Training loss: 2.1872990131378174
Validation loss: 2.2389352398533977

Epoch: 6| Step: 3
Training loss: 1.8299560546875
Validation loss: 2.2282130807958622

Epoch: 6| Step: 4
Training loss: 2.3642849922180176
Validation loss: 2.230826547068934

Epoch: 6| Step: 5
Training loss: 1.8485041856765747
Validation loss: 2.2257247842768186

Epoch: 6| Step: 6
Training loss: 2.9439704418182373
Validation loss: 2.214844307591838

Epoch: 6| Step: 7
Training loss: 2.8587822914123535
Validation loss: 2.214658168054396

Epoch: 6| Step: 8
Training loss: 3.218588352203369
Validation loss: 2.1991154660460768

Epoch: 6| Step: 9
Training loss: 2.125138998031616
Validation loss: 2.18135630571714

Epoch: 6| Step: 10
Training loss: 2.6852381229400635
Validation loss: 2.2026689257673038

Epoch: 6| Step: 11
Training loss: 2.1057233810424805
Validation loss: 2.223504602268178

Epoch: 6| Step: 12
Training loss: 2.175262451171875
Validation loss: 2.2550525793465237

Epoch: 6| Step: 13
Training loss: 3.16912579536438
Validation loss: 2.2601365504726285

Epoch: 89| Step: 0
Training loss: 2.531581163406372
Validation loss: 2.2471610525602936

Epoch: 6| Step: 1
Training loss: 2.543614387512207
Validation loss: 2.2063948082667526

Epoch: 6| Step: 2
Training loss: 2.5609869956970215
Validation loss: 2.1951283408749487

Epoch: 6| Step: 3
Training loss: 2.405947685241699
Validation loss: 2.1815656397932317

Epoch: 6| Step: 4
Training loss: 2.750789165496826
Validation loss: 2.1768123680545437

Epoch: 6| Step: 5
Training loss: 2.34617018699646
Validation loss: 2.173918386941315

Epoch: 6| Step: 6
Training loss: 2.21926212310791
Validation loss: 2.1736122074947564

Epoch: 6| Step: 7
Training loss: 2.3306822776794434
Validation loss: 2.170583321202186

Epoch: 6| Step: 8
Training loss: 2.574882984161377
Validation loss: 2.1825444236878426

Epoch: 6| Step: 9
Training loss: 2.99432373046875
Validation loss: 2.1965923642599456

Epoch: 6| Step: 10
Training loss: 2.297008752822876
Validation loss: 2.2159950963912474

Epoch: 6| Step: 11
Training loss: 1.9638495445251465
Validation loss: 2.231031302482851

Epoch: 6| Step: 12
Training loss: 2.532261848449707
Validation loss: 2.2401814050571893

Epoch: 6| Step: 13
Training loss: 2.555248498916626
Validation loss: 2.246287371522637

Epoch: 90| Step: 0
Training loss: 3.073768138885498
Validation loss: 2.2230828526199504

Epoch: 6| Step: 1
Training loss: 2.845334529876709
Validation loss: 2.1982490529296217

Epoch: 6| Step: 2
Training loss: 2.6049880981445312
Validation loss: 2.1924830252124416

Epoch: 6| Step: 3
Training loss: 2.041207790374756
Validation loss: 2.1817355796854985

Epoch: 6| Step: 4
Training loss: 2.1649651527404785
Validation loss: 2.1858700501021517

Epoch: 6| Step: 5
Training loss: 1.8135812282562256
Validation loss: 2.1981336224463677

Epoch: 6| Step: 6
Training loss: 2.7323479652404785
Validation loss: 2.2015494069745465

Epoch: 6| Step: 7
Training loss: 2.309500217437744
Validation loss: 2.209022903955111

Epoch: 6| Step: 8
Training loss: 2.140979766845703
Validation loss: 2.227571201580827

Epoch: 6| Step: 9
Training loss: 2.653273344039917
Validation loss: 2.232969344303172

Epoch: 6| Step: 10
Training loss: 2.5242254734039307
Validation loss: 2.237078259068151

Epoch: 6| Step: 11
Training loss: 2.535588264465332
Validation loss: 2.2485314107710317

Epoch: 6| Step: 12
Training loss: 2.55940842628479
Validation loss: 2.244114716847738

Epoch: 6| Step: 13
Training loss: 2.1414551734924316
Validation loss: 2.246035688666887

Epoch: 91| Step: 0
Training loss: 2.1005072593688965
Validation loss: 2.244628737049718

Epoch: 6| Step: 1
Training loss: 2.6218385696411133
Validation loss: 2.2478380715975197

Epoch: 6| Step: 2
Training loss: 2.762308120727539
Validation loss: 2.2415411241592897

Epoch: 6| Step: 3
Training loss: 2.01796817779541
Validation loss: 2.2318957031414075

Epoch: 6| Step: 4
Training loss: 2.128958225250244
Validation loss: 2.2291521397970055

Epoch: 6| Step: 5
Training loss: 2.139740467071533
Validation loss: 2.2438829842434136

Epoch: 6| Step: 6
Training loss: 1.9239473342895508
Validation loss: 2.2379324346460323

Epoch: 6| Step: 7
Training loss: 2.6113059520721436
Validation loss: 2.2214409177021315

Epoch: 6| Step: 8
Training loss: 2.7978949546813965
Validation loss: 2.2164752662822766

Epoch: 6| Step: 9
Training loss: 2.209047317504883
Validation loss: 2.2192974346940235

Epoch: 6| Step: 10
Training loss: 2.735652446746826
Validation loss: 2.1997376154827815

Epoch: 6| Step: 11
Training loss: 2.338651657104492
Validation loss: 2.1931035339191394

Epoch: 6| Step: 12
Training loss: 2.795074939727783
Validation loss: 2.183505864553554

Epoch: 6| Step: 13
Training loss: 3.119028329849243
Validation loss: 2.195223771115785

Epoch: 92| Step: 0
Training loss: 2.1313557624816895
Validation loss: 2.20214666346068

Epoch: 6| Step: 1
Training loss: 1.843879222869873
Validation loss: 2.211655834669708

Epoch: 6| Step: 2
Training loss: 2.057645320892334
Validation loss: 2.223309232342628

Epoch: 6| Step: 3
Training loss: 2.8008220195770264
Validation loss: 2.2678221374429683

Epoch: 6| Step: 4
Training loss: 1.59187650680542
Validation loss: 2.318529230292125

Epoch: 6| Step: 5
Training loss: 2.59757924079895
Validation loss: 2.386144845716415

Epoch: 6| Step: 6
Training loss: 1.7823998928070068
Validation loss: 2.3454002616226033

Epoch: 6| Step: 7
Training loss: 3.3058266639709473
Validation loss: 2.289100036826185

Epoch: 6| Step: 8
Training loss: 3.268893241882324
Validation loss: 2.2478266749330746

Epoch: 6| Step: 9
Training loss: 2.7100861072540283
Validation loss: 2.21006376512589

Epoch: 6| Step: 10
Training loss: 2.526829957962036
Validation loss: 2.1773139046084498

Epoch: 6| Step: 11
Training loss: 2.762699604034424
Validation loss: 2.164542362254153

Epoch: 6| Step: 12
Training loss: 2.524381637573242
Validation loss: 2.163642530800194

Epoch: 6| Step: 13
Training loss: 2.1997766494750977
Validation loss: 2.157228401912156

Epoch: 93| Step: 0
Training loss: 2.9125280380249023
Validation loss: 2.1533601271208895

Epoch: 6| Step: 1
Training loss: 2.931729793548584
Validation loss: 2.1523832608294744

Epoch: 6| Step: 2
Training loss: 2.6079249382019043
Validation loss: 2.154088230543239

Epoch: 6| Step: 3
Training loss: 2.5717175006866455
Validation loss: 2.1558201864201534

Epoch: 6| Step: 4
Training loss: 1.7505557537078857
Validation loss: 2.161109257769841

Epoch: 6| Step: 5
Training loss: 2.41652774810791
Validation loss: 2.169194244569348

Epoch: 6| Step: 6
Training loss: 2.363849639892578
Validation loss: 2.181723294719573

Epoch: 6| Step: 7
Training loss: 2.530302047729492
Validation loss: 2.1925439578230663

Epoch: 6| Step: 8
Training loss: 2.171661853790283
Validation loss: 2.207847479851015

Epoch: 6| Step: 9
Training loss: 1.8426779508590698
Validation loss: 2.234247922897339

Epoch: 6| Step: 10
Training loss: 2.9668703079223633
Validation loss: 2.3202575996357906

Epoch: 6| Step: 11
Training loss: 3.198103666305542
Validation loss: 2.4657926379993396

Epoch: 6| Step: 12
Training loss: 2.0057122707366943
Validation loss: 2.5204366945451304

Epoch: 6| Step: 13
Training loss: 2.0994014739990234
Validation loss: 2.5381678458183043

Epoch: 94| Step: 0
Training loss: 2.493835926055908
Validation loss: 2.5019217101476525

Epoch: 6| Step: 1
Training loss: 2.3121562004089355
Validation loss: 2.484592406980453

Epoch: 6| Step: 2
Training loss: 2.9029054641723633
Validation loss: 2.3955699218216764

Epoch: 6| Step: 3
Training loss: 2.490023136138916
Validation loss: 2.295009136199951

Epoch: 6| Step: 4
Training loss: 2.3416922092437744
Validation loss: 2.25729275262484

Epoch: 6| Step: 5
Training loss: 2.9917306900024414
Validation loss: 2.240141284081244

Epoch: 6| Step: 6
Training loss: 2.3778600692749023
Validation loss: 2.244090716044108

Epoch: 6| Step: 7
Training loss: 2.6900572776794434
Validation loss: 2.232578509597368

Epoch: 6| Step: 8
Training loss: 2.3210418224334717
Validation loss: 2.254408795346496

Epoch: 6| Step: 9
Training loss: 2.898820400238037
Validation loss: 2.2451252552770797

Epoch: 6| Step: 10
Training loss: 2.2110743522644043
Validation loss: 2.234328644250029

Epoch: 6| Step: 11
Training loss: 2.1573128700256348
Validation loss: 2.237299637127948

Epoch: 6| Step: 12
Training loss: 2.366107940673828
Validation loss: 2.225029840264269

Epoch: 6| Step: 13
Training loss: 2.674086570739746
Validation loss: 2.247119511327436

Epoch: 95| Step: 0
Training loss: 2.651113748550415
Validation loss: 2.2390440099982807

Epoch: 6| Step: 1
Training loss: 3.192565441131592
Validation loss: 2.2354131796026744

Epoch: 6| Step: 2
Training loss: 1.7901530265808105
Validation loss: 2.235446491549092

Epoch: 6| Step: 3
Training loss: 2.2993874549865723
Validation loss: 2.2337152060642036

Epoch: 6| Step: 4
Training loss: 3.005162239074707
Validation loss: 2.238501420585058

Epoch: 6| Step: 5
Training loss: 2.495225191116333
Validation loss: 2.240992305099323

Epoch: 6| Step: 6
Training loss: 2.3929388523101807
Validation loss: 2.2364480162179596

Epoch: 6| Step: 7
Training loss: 2.2362258434295654
Validation loss: 2.2392846486901723

Epoch: 6| Step: 8
Training loss: 2.7467093467712402
Validation loss: 2.2350012025525494

Epoch: 6| Step: 9
Training loss: 2.1688990592956543
Validation loss: 2.2251898242581274

Epoch: 6| Step: 10
Training loss: 2.3544986248016357
Validation loss: 2.2306402396130305

Epoch: 6| Step: 11
Training loss: 2.7483065128326416
Validation loss: 2.218161811110794

Epoch: 6| Step: 12
Training loss: 2.0794177055358887
Validation loss: 2.201209481044482

Epoch: 6| Step: 13
Training loss: 1.5790255069732666
Validation loss: 2.208053526057992

Epoch: 96| Step: 0
Training loss: 2.1564483642578125
Validation loss: 2.208305007667952

Epoch: 6| Step: 1
Training loss: 2.8950300216674805
Validation loss: 2.218591574699648

Epoch: 6| Step: 2
Training loss: 2.0406394004821777
Validation loss: 2.2285507314948627

Epoch: 6| Step: 3
Training loss: 2.679762363433838
Validation loss: 2.2536103904888196

Epoch: 6| Step: 4
Training loss: 2.3834116458892822
Validation loss: 2.264839013417562

Epoch: 6| Step: 5
Training loss: 2.659437656402588
Validation loss: 2.2870700436253704

Epoch: 6| Step: 6
Training loss: 3.131626605987549
Validation loss: 2.2753225244501585

Epoch: 6| Step: 7
Training loss: 2.185837745666504
Validation loss: 2.2361335395484843

Epoch: 6| Step: 8
Training loss: 1.9753012657165527
Validation loss: 2.2138550435343096

Epoch: 6| Step: 9
Training loss: 2.6861252784729004
Validation loss: 2.19813508243971

Epoch: 6| Step: 10
Training loss: 2.098331928253174
Validation loss: 2.180079719071747

Epoch: 6| Step: 11
Training loss: 2.25933575630188
Validation loss: 2.180544621200972

Epoch: 6| Step: 12
Training loss: 2.8598899841308594
Validation loss: 2.1745126760134132

Epoch: 6| Step: 13
Training loss: 2.060896873474121
Validation loss: 2.177711316334304

Epoch: 97| Step: 0
Training loss: 2.6845169067382812
Validation loss: 2.1714993766559068

Epoch: 6| Step: 1
Training loss: 2.265979766845703
Validation loss: 2.1699341522750033

Epoch: 6| Step: 2
Training loss: 2.301487684249878
Validation loss: 2.1759022128197456

Epoch: 6| Step: 3
Training loss: 2.210672616958618
Validation loss: 2.182785992981285

Epoch: 6| Step: 4
Training loss: 1.6477065086364746
Validation loss: 2.200315039644959

Epoch: 6| Step: 5
Training loss: 3.0868260860443115
Validation loss: 2.2264595877739692

Epoch: 6| Step: 6
Training loss: 2.901036262512207
Validation loss: 2.2502207038223103

Epoch: 6| Step: 7
Training loss: 2.1265370845794678
Validation loss: 2.290321102706335

Epoch: 6| Step: 8
Training loss: 2.8481431007385254
Validation loss: 2.332517329082694

Epoch: 6| Step: 9
Training loss: 2.909902334213257
Validation loss: 2.343738217507639

Epoch: 6| Step: 10
Training loss: 2.174747943878174
Validation loss: 2.28714838335591

Epoch: 6| Step: 11
Training loss: 2.470562696456909
Validation loss: 2.2297715474200506

Epoch: 6| Step: 12
Training loss: 2.551565170288086
Validation loss: 2.2138980486059703

Epoch: 6| Step: 13
Training loss: 1.7421934604644775
Validation loss: 2.176836265030728

Epoch: 98| Step: 0
Training loss: 2.526628255844116
Validation loss: 2.1709254082813056

Epoch: 6| Step: 1
Training loss: 3.1167285442352295
Validation loss: 2.1563862190451673

Epoch: 6| Step: 2
Training loss: 2.0424938201904297
Validation loss: 2.152429937034525

Epoch: 6| Step: 3
Training loss: 2.387765645980835
Validation loss: 2.1618427051010953

Epoch: 6| Step: 4
Training loss: 1.7267282009124756
Validation loss: 2.1559315573784614

Epoch: 6| Step: 5
Training loss: 1.9343171119689941
Validation loss: 2.1561172687879173

Epoch: 6| Step: 6
Training loss: 1.7839514017105103
Validation loss: 2.1628868349136843

Epoch: 6| Step: 7
Training loss: 2.6369028091430664
Validation loss: 2.167914769982779

Epoch: 6| Step: 8
Training loss: 3.4724059104919434
Validation loss: 2.1711066717742593

Epoch: 6| Step: 9
Training loss: 2.9232161045074463
Validation loss: 2.1662674527014456

Epoch: 6| Step: 10
Training loss: 2.0579702854156494
Validation loss: 2.175800082504108

Epoch: 6| Step: 11
Training loss: 1.9290670156478882
Validation loss: 2.188276155020601

Epoch: 6| Step: 12
Training loss: 2.879410743713379
Validation loss: 2.2050999031271985

Epoch: 6| Step: 13
Training loss: 2.5036168098449707
Validation loss: 2.2059708487602974

Epoch: 99| Step: 0
Training loss: 2.7772703170776367
Validation loss: 2.201844725557553

Epoch: 6| Step: 1
Training loss: 2.267624616622925
Validation loss: 2.2030740963515414

Epoch: 6| Step: 2
Training loss: 2.089759111404419
Validation loss: 2.2076954098157984

Epoch: 6| Step: 3
Training loss: 2.503723621368408
Validation loss: 2.1894476247090164

Epoch: 6| Step: 4
Training loss: 2.3185529708862305
Validation loss: 2.1772931493738645

Epoch: 6| Step: 5
Training loss: 2.155024290084839
Validation loss: 2.174626845185475

Epoch: 6| Step: 6
Training loss: 1.8848576545715332
Validation loss: 2.1779545712214645

Epoch: 6| Step: 7
Training loss: 2.818427562713623
Validation loss: 2.1648610740579586

Epoch: 6| Step: 8
Training loss: 2.3207907676696777
Validation loss: 2.162850990090319

Epoch: 6| Step: 9
Training loss: 2.036757469177246
Validation loss: 2.158696056694113

Epoch: 6| Step: 10
Training loss: 2.5105810165405273
Validation loss: 2.1630995632499777

Epoch: 6| Step: 11
Training loss: 2.5417890548706055
Validation loss: 2.165491779645284

Epoch: 6| Step: 12
Training loss: 2.9652185440063477
Validation loss: 2.1651273414652836

Epoch: 6| Step: 13
Training loss: 2.459216356277466
Validation loss: 2.1585683848268244

Epoch: 100| Step: 0
Training loss: 1.8427908420562744
Validation loss: 2.1721786863060406

Epoch: 6| Step: 1
Training loss: 2.4363439083099365
Validation loss: 2.1850768263621996

Epoch: 6| Step: 2
Training loss: 2.6812047958374023
Validation loss: 2.2086568878542994

Epoch: 6| Step: 3
Training loss: 2.0025224685668945
Validation loss: 2.264481818804177

Epoch: 6| Step: 4
Training loss: 2.055009603500366
Validation loss: 2.3135180498964045

Epoch: 6| Step: 5
Training loss: 2.9264190196990967
Validation loss: 2.3559414930241083

Epoch: 6| Step: 6
Training loss: 1.911475658416748
Validation loss: 2.362876974126344

Epoch: 6| Step: 7
Training loss: 2.692002534866333
Validation loss: 2.3148693179571502

Epoch: 6| Step: 8
Training loss: 2.231544017791748
Validation loss: 2.272419560340143

Epoch: 6| Step: 9
Training loss: 2.330960750579834
Validation loss: 2.2258498514852216

Epoch: 6| Step: 10
Training loss: 2.813136577606201
Validation loss: 2.2014624329023462

Epoch: 6| Step: 11
Training loss: 2.947291374206543
Validation loss: 2.178243972921884

Epoch: 6| Step: 12
Training loss: 2.413706064224243
Validation loss: 2.172974004540392

Epoch: 6| Step: 13
Training loss: 2.267982244491577
Validation loss: 2.1620344513206073

Epoch: 101| Step: 0
Training loss: 2.9928507804870605
Validation loss: 2.159772467869584

Epoch: 6| Step: 1
Training loss: 3.0081214904785156
Validation loss: 2.1630669306683283

Epoch: 6| Step: 2
Training loss: 2.942793607711792
Validation loss: 2.160494855655137

Epoch: 6| Step: 3
Training loss: 2.039196491241455
Validation loss: 2.148612230054794

Epoch: 6| Step: 4
Training loss: 1.8063364028930664
Validation loss: 2.150745468754922

Epoch: 6| Step: 5
Training loss: 2.385474681854248
Validation loss: 2.150393941069162

Epoch: 6| Step: 6
Training loss: 2.570296049118042
Validation loss: 2.147794267182709

Epoch: 6| Step: 7
Training loss: 1.5901541709899902
Validation loss: 2.1516935568983837

Epoch: 6| Step: 8
Training loss: 2.4098010063171387
Validation loss: 2.166096915480911

Epoch: 6| Step: 9
Training loss: 2.1843671798706055
Validation loss: 2.1762083743208196

Epoch: 6| Step: 10
Training loss: 3.2273755073547363
Validation loss: 2.207506682283135

Epoch: 6| Step: 11
Training loss: 3.107510566711426
Validation loss: 2.249115836235785

Epoch: 6| Step: 12
Training loss: 1.5008232593536377
Validation loss: 2.2819403999595234

Epoch: 6| Step: 13
Training loss: 2.0745115280151367
Validation loss: 2.291048078126805

Epoch: 102| Step: 0
Training loss: 2.226318836212158
Validation loss: 2.2964509558934036

Epoch: 6| Step: 1
Training loss: 2.8204283714294434
Validation loss: 2.2701274656480357

Epoch: 6| Step: 2
Training loss: 2.8185300827026367
Validation loss: 2.2464952725236134

Epoch: 6| Step: 3
Training loss: 2.370408535003662
Validation loss: 2.237187247122488

Epoch: 6| Step: 4
Training loss: 2.367499351501465
Validation loss: 2.2283665518606863

Epoch: 6| Step: 5
Training loss: 2.11065673828125
Validation loss: 2.22999341769885

Epoch: 6| Step: 6
Training loss: 2.226383924484253
Validation loss: 2.252348410185947

Epoch: 6| Step: 7
Training loss: 2.9244625568389893
Validation loss: 2.2780078687975482

Epoch: 6| Step: 8
Training loss: 2.465329170227051
Validation loss: 2.2702288525078886

Epoch: 6| Step: 9
Training loss: 1.923063039779663
Validation loss: 2.2561791225146224

Epoch: 6| Step: 10
Training loss: 2.0987396240234375
Validation loss: 2.252327629314956

Epoch: 6| Step: 11
Training loss: 2.6486852169036865
Validation loss: 2.2172831181556947

Epoch: 6| Step: 12
Training loss: 2.4114136695861816
Validation loss: 2.217917416685371

Epoch: 6| Step: 13
Training loss: 2.156261682510376
Validation loss: 2.2008300237758185

Epoch: 103| Step: 0
Training loss: 2.8181636333465576
Validation loss: 2.219431000371133

Epoch: 6| Step: 1
Training loss: 1.9837965965270996
Validation loss: 2.2103654953741256

Epoch: 6| Step: 2
Training loss: 2.8184709548950195
Validation loss: 2.2297327108280633

Epoch: 6| Step: 3
Training loss: 2.3110032081604004
Validation loss: 2.234709075702134

Epoch: 6| Step: 4
Training loss: 2.941086530685425
Validation loss: 2.234514344123102

Epoch: 6| Step: 5
Training loss: 1.6368283033370972
Validation loss: 2.2124133174137404

Epoch: 6| Step: 6
Training loss: 2.3820128440856934
Validation loss: 2.2115906874338784

Epoch: 6| Step: 7
Training loss: 2.653963565826416
Validation loss: 2.1930989193659958

Epoch: 6| Step: 8
Training loss: 1.6997365951538086
Validation loss: 2.175657514602907

Epoch: 6| Step: 9
Training loss: 2.5694899559020996
Validation loss: 2.169725912873463

Epoch: 6| Step: 10
Training loss: 2.0011119842529297
Validation loss: 2.167458144567346

Epoch: 6| Step: 11
Training loss: 1.668192744255066
Validation loss: 2.1694436765486196

Epoch: 6| Step: 12
Training loss: 3.098818778991699
Validation loss: 2.1694276499491867

Epoch: 6| Step: 13
Training loss: 3.023793935775757
Validation loss: 2.17541326502318

Epoch: 104| Step: 0
Training loss: 2.5378193855285645
Validation loss: 2.168034415091238

Epoch: 6| Step: 1
Training loss: 2.2632622718811035
Validation loss: 2.1708241175579768

Epoch: 6| Step: 2
Training loss: 2.4746053218841553
Validation loss: 2.1876912732278146

Epoch: 6| Step: 3
Training loss: 1.7576408386230469
Validation loss: 2.24125059189335

Epoch: 6| Step: 4
Training loss: 2.3275370597839355
Validation loss: 2.2947832461326354

Epoch: 6| Step: 5
Training loss: 2.6134371757507324
Validation loss: 2.251242455615792

Epoch: 6| Step: 6
Training loss: 1.9164361953735352
Validation loss: 2.2060751940614436

Epoch: 6| Step: 7
Training loss: 2.4558820724487305
Validation loss: 2.1715989369218067

Epoch: 6| Step: 8
Training loss: 2.205500364303589
Validation loss: 2.159351107894733

Epoch: 6| Step: 9
Training loss: 2.4000020027160645
Validation loss: 2.161604817195605

Epoch: 6| Step: 10
Training loss: 3.0639257431030273
Validation loss: 2.160394714724633

Epoch: 6| Step: 11
Training loss: 2.456462860107422
Validation loss: 2.163538335472025

Epoch: 6| Step: 12
Training loss: 2.9159200191497803
Validation loss: 2.161236186181345

Epoch: 6| Step: 13
Training loss: 2.201707124710083
Validation loss: 2.1604359431933333

Epoch: 105| Step: 0
Training loss: 2.1824936866760254
Validation loss: 2.1751767461017897

Epoch: 6| Step: 1
Training loss: 2.375213623046875
Validation loss: 2.1740429811580206

Epoch: 6| Step: 2
Training loss: 2.9926040172576904
Validation loss: 2.1736906754073275

Epoch: 6| Step: 3
Training loss: 2.22092604637146
Validation loss: 2.1891100534828762

Epoch: 6| Step: 4
Training loss: 2.0938496589660645
Validation loss: 2.1894647767466884

Epoch: 6| Step: 5
Training loss: 2.559337854385376
Validation loss: 2.196807979255594

Epoch: 6| Step: 6
Training loss: 2.154214859008789
Validation loss: 2.212607378600746

Epoch: 6| Step: 7
Training loss: 2.3358540534973145
Validation loss: 2.253295603618827

Epoch: 6| Step: 8
Training loss: 2.1558613777160645
Validation loss: 2.2644909299829954

Epoch: 6| Step: 9
Training loss: 2.3513967990875244
Validation loss: 2.2878621573089273

Epoch: 6| Step: 10
Training loss: 2.351116418838501
Validation loss: 2.282679437309183

Epoch: 6| Step: 11
Training loss: 2.578080415725708
Validation loss: 2.2713251421528478

Epoch: 6| Step: 12
Training loss: 2.5658717155456543
Validation loss: 2.255666099568849

Epoch: 6| Step: 13
Training loss: 2.6523046493530273
Validation loss: 2.231623250951049

Epoch: 106| Step: 0
Training loss: 2.017707347869873
Validation loss: 2.2193583044954526

Epoch: 6| Step: 1
Training loss: 3.155937910079956
Validation loss: 2.209616179107338

Epoch: 6| Step: 2
Training loss: 2.131307363510132
Validation loss: 2.2081542835440686

Epoch: 6| Step: 3
Training loss: 2.578986167907715
Validation loss: 2.1952798417819444

Epoch: 6| Step: 4
Training loss: 1.8995654582977295
Validation loss: 2.1899482819341842

Epoch: 6| Step: 5
Training loss: 2.431732654571533
Validation loss: 2.1910165317596926

Epoch: 6| Step: 6
Training loss: 2.7703769207000732
Validation loss: 2.199341340731549

Epoch: 6| Step: 7
Training loss: 2.1269187927246094
Validation loss: 2.210365249264625

Epoch: 6| Step: 8
Training loss: 2.4324185848236084
Validation loss: 2.195686045513358

Epoch: 6| Step: 9
Training loss: 2.5429186820983887
Validation loss: 2.1977612305712957

Epoch: 6| Step: 10
Training loss: 2.5457653999328613
Validation loss: 2.1816483979584067

Epoch: 6| Step: 11
Training loss: 2.014601707458496
Validation loss: 2.1845094234712663

Epoch: 6| Step: 12
Training loss: 2.0783393383026123
Validation loss: 2.183225388168007

Epoch: 6| Step: 13
Training loss: 2.246161699295044
Validation loss: 2.178069499231154

Epoch: 107| Step: 0
Training loss: 2.030292510986328
Validation loss: 2.1865784532280377

Epoch: 6| Step: 1
Training loss: 2.334019422531128
Validation loss: 2.182433251411684

Epoch: 6| Step: 2
Training loss: 1.7659049034118652
Validation loss: 2.1930402145590833

Epoch: 6| Step: 3
Training loss: 2.3769705295562744
Validation loss: 2.208256342077768

Epoch: 6| Step: 4
Training loss: 2.490624189376831
Validation loss: 2.2310625994077293

Epoch: 6| Step: 5
Training loss: 3.1881024837493896
Validation loss: 2.273215852757936

Epoch: 6| Step: 6
Training loss: 2.6313514709472656
Validation loss: 2.258863695206181

Epoch: 6| Step: 7
Training loss: 2.783015251159668
Validation loss: 2.2237753970648653

Epoch: 6| Step: 8
Training loss: 2.845031499862671
Validation loss: 2.1991567970604025

Epoch: 6| Step: 9
Training loss: 2.420219898223877
Validation loss: 2.179652537069013

Epoch: 6| Step: 10
Training loss: 2.5919127464294434
Validation loss: 2.157415792506228

Epoch: 6| Step: 11
Training loss: 1.889439344406128
Validation loss: 2.166176349886002

Epoch: 6| Step: 12
Training loss: 1.7919577360153198
Validation loss: 2.1689670547362296

Epoch: 6| Step: 13
Training loss: 1.6811728477478027
Validation loss: 2.177128145771642

Epoch: 108| Step: 0
Training loss: 2.0166969299316406
Validation loss: 2.167177264408399

Epoch: 6| Step: 1
Training loss: 2.230106830596924
Validation loss: 2.2009026850423505

Epoch: 6| Step: 2
Training loss: 2.521244525909424
Validation loss: 2.2084106142802904

Epoch: 6| Step: 3
Training loss: 2.746433973312378
Validation loss: 2.192607351528701

Epoch: 6| Step: 4
Training loss: 2.6381242275238037
Validation loss: 2.1830835368043635

Epoch: 6| Step: 5
Training loss: 2.3234286308288574
Validation loss: 2.1960485186628116

Epoch: 6| Step: 6
Training loss: 2.232977867126465
Validation loss: 2.1882429968926216

Epoch: 6| Step: 7
Training loss: 1.7916635274887085
Validation loss: 2.1972348843851397

Epoch: 6| Step: 8
Training loss: 2.621192455291748
Validation loss: 2.2291492877467984

Epoch: 6| Step: 9
Training loss: 2.2660770416259766
Validation loss: 2.212386267159575

Epoch: 6| Step: 10
Training loss: 2.0728402137756348
Validation loss: 2.2142553021830897

Epoch: 6| Step: 11
Training loss: 3.191477060317993
Validation loss: 2.188084122955158

Epoch: 6| Step: 12
Training loss: 2.340879440307617
Validation loss: 2.156139786525439

Epoch: 6| Step: 13
Training loss: 2.5157411098480225
Validation loss: 2.135381419171569

Epoch: 109| Step: 0
Training loss: 2.6783411502838135
Validation loss: 2.134316711015599

Epoch: 6| Step: 1
Training loss: 2.3280887603759766
Validation loss: 2.14108250218053

Epoch: 6| Step: 2
Training loss: 2.046581268310547
Validation loss: 2.1480696291051884

Epoch: 6| Step: 3
Training loss: 2.5231072902679443
Validation loss: 2.1411012911027476

Epoch: 6| Step: 4
Training loss: 2.190188407897949
Validation loss: 2.144451928395097

Epoch: 6| Step: 5
Training loss: 2.3180811405181885
Validation loss: 2.161057908047912

Epoch: 6| Step: 6
Training loss: 1.7865833044052124
Validation loss: 2.1681167207738405

Epoch: 6| Step: 7
Training loss: 2.738154888153076
Validation loss: 2.177528258292906

Epoch: 6| Step: 8
Training loss: 2.5048279762268066
Validation loss: 2.1908268684981973

Epoch: 6| Step: 9
Training loss: 2.2438039779663086
Validation loss: 2.1861712266040105

Epoch: 6| Step: 10
Training loss: 2.6793651580810547
Validation loss: 2.202706398502473

Epoch: 6| Step: 11
Training loss: 2.161733627319336
Validation loss: 2.2164806166002826

Epoch: 6| Step: 12
Training loss: 2.114455223083496
Validation loss: 2.2639024360205537

Epoch: 6| Step: 13
Training loss: 3.1286733150482178
Validation loss: 2.2846891008397585

Epoch: 110| Step: 0
Training loss: 2.4259300231933594
Validation loss: 2.216383687911495

Epoch: 6| Step: 1
Training loss: 2.7621912956237793
Validation loss: 2.1777487916331135

Epoch: 6| Step: 2
Training loss: 1.7896515130996704
Validation loss: 2.152857149800947

Epoch: 6| Step: 3
Training loss: 2.044528007507324
Validation loss: 2.1669682610419487

Epoch: 6| Step: 4
Training loss: 2.6876511573791504
Validation loss: 2.149054194009432

Epoch: 6| Step: 5
Training loss: 1.9364999532699585
Validation loss: 2.1601405425738265

Epoch: 6| Step: 6
Training loss: 2.1317849159240723
Validation loss: 2.170681761157128

Epoch: 6| Step: 7
Training loss: 1.9095280170440674
Validation loss: 2.1652038763928156

Epoch: 6| Step: 8
Training loss: 2.331552028656006
Validation loss: 2.1646298695636053

Epoch: 6| Step: 9
Training loss: 2.708221912384033
Validation loss: 2.15918908580657

Epoch: 6| Step: 10
Training loss: 3.0878872871398926
Validation loss: 2.153105887033606

Epoch: 6| Step: 11
Training loss: 2.5799713134765625
Validation loss: 2.1481714556294103

Epoch: 6| Step: 12
Training loss: 1.8145711421966553
Validation loss: 2.146572677038049

Epoch: 6| Step: 13
Training loss: 2.2394442558288574
Validation loss: 2.1488105558579966

Epoch: 111| Step: 0
Training loss: 3.138889789581299
Validation loss: 2.1362319761706936

Epoch: 6| Step: 1
Training loss: 1.7797033786773682
Validation loss: 2.152359526644471

Epoch: 6| Step: 2
Training loss: 1.6412909030914307
Validation loss: 2.180358056099184

Epoch: 6| Step: 3
Training loss: 2.4641799926757812
Validation loss: 2.200984649760749

Epoch: 6| Step: 4
Training loss: 2.277229070663452
Validation loss: 2.2120352175927933

Epoch: 6| Step: 5
Training loss: 3.245314598083496
Validation loss: 2.2047957387021793

Epoch: 6| Step: 6
Training loss: 1.6880378723144531
Validation loss: 2.1705687725415794

Epoch: 6| Step: 7
Training loss: 2.0217549800872803
Validation loss: 2.159856216881865

Epoch: 6| Step: 8
Training loss: 1.9798243045806885
Validation loss: 2.15728417006872

Epoch: 6| Step: 9
Training loss: 2.271285057067871
Validation loss: 2.1622420011028165

Epoch: 6| Step: 10
Training loss: 3.101149082183838
Validation loss: 2.1599206462983163

Epoch: 6| Step: 11
Training loss: 2.4677932262420654
Validation loss: 2.163465478086984

Epoch: 6| Step: 12
Training loss: 2.1027090549468994
Validation loss: 2.164126606397731

Epoch: 6| Step: 13
Training loss: 2.5516233444213867
Validation loss: 2.178268050634733

Epoch: 112| Step: 0
Training loss: 3.1022772789001465
Validation loss: 2.204280053415606

Epoch: 6| Step: 1
Training loss: 2.074500322341919
Validation loss: 2.2167007218125048

Epoch: 6| Step: 2
Training loss: 2.095644950866699
Validation loss: 2.234753049829955

Epoch: 6| Step: 3
Training loss: 1.799584150314331
Validation loss: 2.222271034794469

Epoch: 6| Step: 4
Training loss: 0.9530718922615051
Validation loss: 2.2083489664139284

Epoch: 6| Step: 5
Training loss: 1.999997615814209
Validation loss: 2.1889664793527253

Epoch: 6| Step: 6
Training loss: 2.6210081577301025
Validation loss: 2.1543885943710164

Epoch: 6| Step: 7
Training loss: 2.832916259765625
Validation loss: 2.1324348321524997

Epoch: 6| Step: 8
Training loss: 2.8227009773254395
Validation loss: 2.125582592461699

Epoch: 6| Step: 9
Training loss: 2.0992953777313232
Validation loss: 2.133979594835671

Epoch: 6| Step: 10
Training loss: 2.8602051734924316
Validation loss: 2.134408697005241

Epoch: 6| Step: 11
Training loss: 2.6794331073760986
Validation loss: 2.14462290271636

Epoch: 6| Step: 12
Training loss: 2.3550195693969727
Validation loss: 2.1488185390349357

Epoch: 6| Step: 13
Training loss: 2.217262029647827
Validation loss: 2.156745187697872

Epoch: 113| Step: 0
Training loss: 2.4010653495788574
Validation loss: 2.16602905847693

Epoch: 6| Step: 1
Training loss: 2.5592398643493652
Validation loss: 2.1973240503700833

Epoch: 6| Step: 2
Training loss: 2.3506712913513184
Validation loss: 2.209967536310996

Epoch: 6| Step: 3
Training loss: 2.0579845905303955
Validation loss: 2.2134509676246235

Epoch: 6| Step: 4
Training loss: 2.492997646331787
Validation loss: 2.189452809672202

Epoch: 6| Step: 5
Training loss: 2.1349401473999023
Validation loss: 2.2043801956279303

Epoch: 6| Step: 6
Training loss: 2.8352246284484863
Validation loss: 2.1874305048296527

Epoch: 6| Step: 7
Training loss: 1.6873724460601807
Validation loss: 2.1655165585138465

Epoch: 6| Step: 8
Training loss: 2.773242473602295
Validation loss: 2.1511021173128517

Epoch: 6| Step: 9
Training loss: 2.0834615230560303
Validation loss: 2.1506973261474283

Epoch: 6| Step: 10
Training loss: 1.8616080284118652
Validation loss: 2.1501813601422053

Epoch: 6| Step: 11
Training loss: 2.3196258544921875
Validation loss: 2.150447799313453

Epoch: 6| Step: 12
Training loss: 2.375523090362549
Validation loss: 2.1548631601436163

Epoch: 6| Step: 13
Training loss: 3.1466472148895264
Validation loss: 2.1587203407800324

Epoch: 114| Step: 0
Training loss: 2.3250441551208496
Validation loss: 2.169434403860441

Epoch: 6| Step: 1
Training loss: 2.7413721084594727
Validation loss: 2.1883418918937765

Epoch: 6| Step: 2
Training loss: 2.6447808742523193
Validation loss: 2.2166167407907467

Epoch: 6| Step: 3
Training loss: 2.6190743446350098
Validation loss: 2.2249282072949153

Epoch: 6| Step: 4
Training loss: 2.335141181945801
Validation loss: 2.215311163215227

Epoch: 6| Step: 5
Training loss: 2.681272506713867
Validation loss: 2.1876154240741523

Epoch: 6| Step: 6
Training loss: 2.13059663772583
Validation loss: 2.173447952475599

Epoch: 6| Step: 7
Training loss: 2.800046443939209
Validation loss: 2.1724034022259455

Epoch: 6| Step: 8
Training loss: 2.409228801727295
Validation loss: 2.1612747305183

Epoch: 6| Step: 9
Training loss: 2.033681869506836
Validation loss: 2.1545881481580835

Epoch: 6| Step: 10
Training loss: 1.196467399597168
Validation loss: 2.149338932447536

Epoch: 6| Step: 11
Training loss: 2.057290554046631
Validation loss: 2.148489558568565

Epoch: 6| Step: 12
Training loss: 2.065798759460449
Validation loss: 2.144520071245009

Epoch: 6| Step: 13
Training loss: 2.233755111694336
Validation loss: 2.1605711854914182

Epoch: 115| Step: 0
Training loss: 2.415586471557617
Validation loss: 2.1870940193053214

Epoch: 6| Step: 1
Training loss: 2.179719924926758
Validation loss: 2.2178581632593626

Epoch: 6| Step: 2
Training loss: 2.5560805797576904
Validation loss: 2.226238860878893

Epoch: 6| Step: 3
Training loss: 1.7575749158859253
Validation loss: 2.245206004829817

Epoch: 6| Step: 4
Training loss: 2.591366767883301
Validation loss: 2.231957768881193

Epoch: 6| Step: 5
Training loss: 2.728426456451416
Validation loss: 2.239132478672971

Epoch: 6| Step: 6
Training loss: 2.5944759845733643
Validation loss: 2.220464383402178

Epoch: 6| Step: 7
Training loss: 2.9233651161193848
Validation loss: 2.1880577700112456

Epoch: 6| Step: 8
Training loss: 1.345909595489502
Validation loss: 2.1507912605039534

Epoch: 6| Step: 9
Training loss: 2.3498382568359375
Validation loss: 2.1402202703619517

Epoch: 6| Step: 10
Training loss: 1.424698829650879
Validation loss: 2.1362295471211916

Epoch: 6| Step: 11
Training loss: 2.1022789478302
Validation loss: 2.14650382021422

Epoch: 6| Step: 12
Training loss: 2.666008234024048
Validation loss: 2.1545604326391734

Epoch: 6| Step: 13
Training loss: 3.2658843994140625
Validation loss: 2.1411667793027815

Epoch: 116| Step: 0
Training loss: 2.062190532684326
Validation loss: 2.149665710746601

Epoch: 6| Step: 1
Training loss: 2.8395309448242188
Validation loss: 2.150762265728366

Epoch: 6| Step: 2
Training loss: 2.688516139984131
Validation loss: 2.165499218048588

Epoch: 6| Step: 3
Training loss: 2.9001755714416504
Validation loss: 2.201014006009666

Epoch: 6| Step: 4
Training loss: 1.9194854497909546
Validation loss: 2.21295004762629

Epoch: 6| Step: 5
Training loss: 2.372624397277832
Validation loss: 2.228860770502398

Epoch: 6| Step: 6
Training loss: 1.9473280906677246
Validation loss: 2.184648095920522

Epoch: 6| Step: 7
Training loss: 1.6107041835784912
Validation loss: 2.1758914788564048

Epoch: 6| Step: 8
Training loss: 2.680788993835449
Validation loss: 2.1569239670230496

Epoch: 6| Step: 9
Training loss: 2.2188634872436523
Validation loss: 2.1307238789014917

Epoch: 6| Step: 10
Training loss: 2.158027172088623
Validation loss: 2.133259952709239

Epoch: 6| Step: 11
Training loss: 2.5939226150512695
Validation loss: 2.124643289914695

Epoch: 6| Step: 12
Training loss: 1.7889115810394287
Validation loss: 2.1302133734508226

Epoch: 6| Step: 13
Training loss: 2.500819683074951
Validation loss: 2.1378798882166543

Epoch: 117| Step: 0
Training loss: 1.7856874465942383
Validation loss: 2.155593179887341

Epoch: 6| Step: 1
Training loss: 2.475918769836426
Validation loss: 2.1846870760763846

Epoch: 6| Step: 2
Training loss: 2.6501822471618652
Validation loss: 2.245294177404014

Epoch: 6| Step: 3
Training loss: 2.3883819580078125
Validation loss: 2.2606755802708287

Epoch: 6| Step: 4
Training loss: 1.419683814048767
Validation loss: 2.225244386221773

Epoch: 6| Step: 5
Training loss: 1.5904126167297363
Validation loss: 2.167480566168344

Epoch: 6| Step: 6
Training loss: 3.5341784954071045
Validation loss: 2.1505361269879084

Epoch: 6| Step: 7
Training loss: 2.3184962272644043
Validation loss: 2.123920694474251

Epoch: 6| Step: 8
Training loss: 2.0438485145568848
Validation loss: 2.1315317384658323

Epoch: 6| Step: 9
Training loss: 2.3045477867126465
Validation loss: 2.137149405735795

Epoch: 6| Step: 10
Training loss: 2.80452299118042
Validation loss: 2.1501315601410402

Epoch: 6| Step: 11
Training loss: 2.967503547668457
Validation loss: 2.173435736727971

Epoch: 6| Step: 12
Training loss: 2.4035961627960205
Validation loss: 2.1779353490439792

Epoch: 6| Step: 13
Training loss: 1.6707912683486938
Validation loss: 2.2016257675745154

Epoch: 118| Step: 0
Training loss: 1.7967031002044678
Validation loss: 2.2092202965931227

Epoch: 6| Step: 1
Training loss: 2.9319331645965576
Validation loss: 2.2124781095853416

Epoch: 6| Step: 2
Training loss: 2.317199468612671
Validation loss: 2.227118612617575

Epoch: 6| Step: 3
Training loss: 2.407825231552124
Validation loss: 2.2392369701016333

Epoch: 6| Step: 4
Training loss: 2.6881303787231445
Validation loss: 2.228514850780528

Epoch: 6| Step: 5
Training loss: 2.20180606842041
Validation loss: 2.2097471362801007

Epoch: 6| Step: 6
Training loss: 2.0686442852020264
Validation loss: 2.199371219963156

Epoch: 6| Step: 7
Training loss: 1.8353252410888672
Validation loss: 2.1765535903233353

Epoch: 6| Step: 8
Training loss: 2.258530378341675
Validation loss: 2.1829094271506033

Epoch: 6| Step: 9
Training loss: 2.429141044616699
Validation loss: 2.185804065837655

Epoch: 6| Step: 10
Training loss: 2.575394630432129
Validation loss: 2.2052489813937934

Epoch: 6| Step: 11
Training loss: 2.2816147804260254
Validation loss: 2.2173876852117558

Epoch: 6| Step: 12
Training loss: 2.0336194038391113
Validation loss: 2.1656178377007924

Epoch: 6| Step: 13
Training loss: 2.4540834426879883
Validation loss: 2.169346526104917

Epoch: 119| Step: 0
Training loss: 1.8960447311401367
Validation loss: 2.1430668202779626

Epoch: 6| Step: 1
Training loss: 2.304215669631958
Validation loss: 2.1400203499742734

Epoch: 6| Step: 2
Training loss: 2.5060458183288574
Validation loss: 2.1470422462750505

Epoch: 6| Step: 3
Training loss: 1.8806204795837402
Validation loss: 2.154091409457627

Epoch: 6| Step: 4
Training loss: 2.0640993118286133
Validation loss: 2.1673079306079495

Epoch: 6| Step: 5
Training loss: 2.3204898834228516
Validation loss: 2.158993746644707

Epoch: 6| Step: 6
Training loss: 1.700048565864563
Validation loss: 2.142793147794662

Epoch: 6| Step: 7
Training loss: 2.350475788116455
Validation loss: 2.1420801993339293

Epoch: 6| Step: 8
Training loss: 2.4164628982543945
Validation loss: 2.1489433203974078

Epoch: 6| Step: 9
Training loss: 1.521359920501709
Validation loss: 2.150996144099902

Epoch: 6| Step: 10
Training loss: 2.9574692249298096
Validation loss: 2.165108347451815

Epoch: 6| Step: 11
Training loss: 3.493804931640625
Validation loss: 2.1810698227215837

Epoch: 6| Step: 12
Training loss: 2.2041232585906982
Validation loss: 2.1763945933311217

Epoch: 6| Step: 13
Training loss: 2.263397693634033
Validation loss: 2.1714323259169057

Epoch: 120| Step: 0
Training loss: 2.373446226119995
Validation loss: 2.1589160760243735

Epoch: 6| Step: 1
Training loss: 1.8518118858337402
Validation loss: 2.1592381192791845

Epoch: 6| Step: 2
Training loss: 2.1472105979919434
Validation loss: 2.162316858127553

Epoch: 6| Step: 3
Training loss: 2.535318374633789
Validation loss: 2.169866310652866

Epoch: 6| Step: 4
Training loss: 1.9055994749069214
Validation loss: 2.166614647834532

Epoch: 6| Step: 5
Training loss: 1.6267958879470825
Validation loss: 2.1437565331817954

Epoch: 6| Step: 6
Training loss: 2.937976121902466
Validation loss: 2.1428702928686656

Epoch: 6| Step: 7
Training loss: 1.9191148281097412
Validation loss: 2.14449647677842

Epoch: 6| Step: 8
Training loss: 3.2148501873016357
Validation loss: 2.1556203288416707

Epoch: 6| Step: 9
Training loss: 2.233320474624634
Validation loss: 2.1616968134398102

Epoch: 6| Step: 10
Training loss: 2.434520959854126
Validation loss: 2.1553216416348695

Epoch: 6| Step: 11
Training loss: 1.7727141380310059
Validation loss: 2.1392681419208484

Epoch: 6| Step: 12
Training loss: 2.528139591217041
Validation loss: 2.1306411963637157

Epoch: 6| Step: 13
Training loss: 1.9767613410949707
Validation loss: 2.123172785646172

Epoch: 121| Step: 0
Training loss: 2.0556130409240723
Validation loss: 2.1292213265613844

Epoch: 6| Step: 1
Training loss: 2.515296220779419
Validation loss: 2.123430928876323

Epoch: 6| Step: 2
Training loss: 2.0019445419311523
Validation loss: 2.1195894364387757

Epoch: 6| Step: 3
Training loss: 2.0778050422668457
Validation loss: 2.1414080845412387

Epoch: 6| Step: 4
Training loss: 2.0845720767974854
Validation loss: 2.1586475064677577

Epoch: 6| Step: 5
Training loss: 1.9393388032913208
Validation loss: 2.1600801944732666

Epoch: 6| Step: 6
Training loss: 1.7646160125732422
Validation loss: 2.183412121188256

Epoch: 6| Step: 7
Training loss: 2.1415088176727295
Validation loss: 2.1635371638882543

Epoch: 6| Step: 8
Training loss: 1.3895831108093262
Validation loss: 2.1572298926691853

Epoch: 6| Step: 9
Training loss: 2.5566608905792236
Validation loss: 2.145204908104353

Epoch: 6| Step: 10
Training loss: 2.7491695880889893
Validation loss: 2.1332261844347884

Epoch: 6| Step: 11
Training loss: 2.078828811645508
Validation loss: 2.129790293273105

Epoch: 6| Step: 12
Training loss: 3.096630573272705
Validation loss: 2.1246076463371195

Epoch: 6| Step: 13
Training loss: 3.502577066421509
Validation loss: 2.1267351437640447

Epoch: 122| Step: 0
Training loss: 2.4190118312835693
Validation loss: 2.122950061675041

Epoch: 6| Step: 1
Training loss: 2.2870702743530273
Validation loss: 2.1330262307197816

Epoch: 6| Step: 2
Training loss: 2.241888999938965
Validation loss: 2.1219302403029574

Epoch: 6| Step: 3
Training loss: 2.155689001083374
Validation loss: 2.130278574523105

Epoch: 6| Step: 4
Training loss: 2.196826457977295
Validation loss: 2.1297936388241347

Epoch: 6| Step: 5
Training loss: 2.7681896686553955
Validation loss: 2.1271153393612114

Epoch: 6| Step: 6
Training loss: 1.6982488632202148
Validation loss: 2.120999123460503

Epoch: 6| Step: 7
Training loss: 2.7544381618499756
Validation loss: 2.136922981149407

Epoch: 6| Step: 8
Training loss: 2.1895737648010254
Validation loss: 2.14991355839596

Epoch: 6| Step: 9
Training loss: 2.1077094078063965
Validation loss: 2.1604737581745272

Epoch: 6| Step: 10
Training loss: 2.5086588859558105
Validation loss: 2.1949406721258677

Epoch: 6| Step: 11
Training loss: 1.5690851211547852
Validation loss: 2.2089261675393708

Epoch: 6| Step: 12
Training loss: 2.504410743713379
Validation loss: 2.2015174486303843

Epoch: 6| Step: 13
Training loss: 1.9899126291275024
Validation loss: 2.1928124812341507

Epoch: 123| Step: 0
Training loss: 2.659498929977417
Validation loss: 2.184682289759318

Epoch: 6| Step: 1
Training loss: 2.152707815170288
Validation loss: 2.1709758850835983

Epoch: 6| Step: 2
Training loss: 1.772078275680542
Validation loss: 2.1624245464160876

Epoch: 6| Step: 3
Training loss: 1.9639167785644531
Validation loss: 2.15443322735448

Epoch: 6| Step: 4
Training loss: 2.6877098083496094
Validation loss: 2.16175490297297

Epoch: 6| Step: 5
Training loss: 2.4405198097229004
Validation loss: 2.1596378036724624

Epoch: 6| Step: 6
Training loss: 1.3248530626296997
Validation loss: 2.1555966754113474

Epoch: 6| Step: 7
Training loss: 1.7032158374786377
Validation loss: 2.168266188713812

Epoch: 6| Step: 8
Training loss: 2.1028623580932617
Validation loss: 2.191109921342583

Epoch: 6| Step: 9
Training loss: 2.740455150604248
Validation loss: 2.1995760445953696

Epoch: 6| Step: 10
Training loss: 2.6117453575134277
Validation loss: 2.2191203281443608

Epoch: 6| Step: 11
Training loss: 2.964114189147949
Validation loss: 2.2094979273375643

Epoch: 6| Step: 12
Training loss: 2.827495574951172
Validation loss: 2.1819243149090837

Epoch: 6| Step: 13
Training loss: 1.2334091663360596
Validation loss: 2.160491645977061

Epoch: 124| Step: 0
Training loss: 2.2162489891052246
Validation loss: 2.1345030389806277

Epoch: 6| Step: 1
Training loss: 1.6144771575927734
Validation loss: 2.1433007012131395

Epoch: 6| Step: 2
Training loss: 1.6892118453979492
Validation loss: 2.1474267282793598

Epoch: 6| Step: 3
Training loss: 2.2297885417938232
Validation loss: 2.1450429718981505

Epoch: 6| Step: 4
Training loss: 2.332014560699463
Validation loss: 2.169306050064743

Epoch: 6| Step: 5
Training loss: 2.107759475708008
Validation loss: 2.175539452542541

Epoch: 6| Step: 6
Training loss: 1.8984442949295044
Validation loss: 2.172755733613045

Epoch: 6| Step: 7
Training loss: 2.0108416080474854
Validation loss: 2.164743359370898

Epoch: 6| Step: 8
Training loss: 2.5345921516418457
Validation loss: 2.173649105974423

Epoch: 6| Step: 9
Training loss: 2.5296597480773926
Validation loss: 2.1692831413720244

Epoch: 6| Step: 10
Training loss: 2.149552345275879
Validation loss: 2.1769163557278213

Epoch: 6| Step: 11
Training loss: 2.3742308616638184
Validation loss: 2.153027367848222

Epoch: 6| Step: 12
Training loss: 2.318986654281616
Validation loss: 2.1551084236432145

Epoch: 6| Step: 13
Training loss: 3.765437602996826
Validation loss: 2.1438302557955504

Epoch: 125| Step: 0
Training loss: 2.2411372661590576
Validation loss: 2.15319235350496

Epoch: 6| Step: 1
Training loss: 2.0382418632507324
Validation loss: 2.154639999071757

Epoch: 6| Step: 2
Training loss: 1.989425778388977
Validation loss: 2.1775575325053227

Epoch: 6| Step: 3
Training loss: 2.456453800201416
Validation loss: 2.2164353375793784

Epoch: 6| Step: 4
Training loss: 1.8370616436004639
Validation loss: 2.1900931378846527

Epoch: 6| Step: 5
Training loss: 2.286343574523926
Validation loss: 2.1958950745162142

Epoch: 6| Step: 6
Training loss: 3.053422689437866
Validation loss: 2.193322056083269

Epoch: 6| Step: 7
Training loss: 2.481494903564453
Validation loss: 2.151614712130639

Epoch: 6| Step: 8
Training loss: 2.159183979034424
Validation loss: 2.1460171668760237

Epoch: 6| Step: 9
Training loss: 2.6829020977020264
Validation loss: 2.125212033589681

Epoch: 6| Step: 10
Training loss: 2.022000789642334
Validation loss: 2.1227422016923145

Epoch: 6| Step: 11
Training loss: 1.9799875020980835
Validation loss: 2.12515990964828

Epoch: 6| Step: 12
Training loss: 2.0258102416992188
Validation loss: 2.140286091835268

Epoch: 6| Step: 13
Training loss: 1.7402739524841309
Validation loss: 2.1554053137379308

Epoch: 126| Step: 0
Training loss: 2.300644636154175
Validation loss: 2.178285337263538

Epoch: 6| Step: 1
Training loss: 2.043443202972412
Validation loss: 2.194385661873766

Epoch: 6| Step: 2
Training loss: 2.3513755798339844
Validation loss: 2.209670207833731

Epoch: 6| Step: 3
Training loss: 1.7912694215774536
Validation loss: 2.210182052786632

Epoch: 6| Step: 4
Training loss: 2.445814371109009
Validation loss: 2.25030549879997

Epoch: 6| Step: 5
Training loss: 2.6122207641601562
Validation loss: 2.231305617158131

Epoch: 6| Step: 6
Training loss: 2.0823066234588623
Validation loss: 2.2007193770459903

Epoch: 6| Step: 7
Training loss: 2.289048194885254
Validation loss: 2.171424796504359

Epoch: 6| Step: 8
Training loss: 2.421231746673584
Validation loss: 2.1500662526776715

Epoch: 6| Step: 9
Training loss: 1.751558542251587
Validation loss: 2.14371947832005

Epoch: 6| Step: 10
Training loss: 2.172037124633789
Validation loss: 2.137499834901543

Epoch: 6| Step: 11
Training loss: 1.825463056564331
Validation loss: 2.148165819465473

Epoch: 6| Step: 12
Training loss: 2.409254550933838
Validation loss: 2.140368010408135

Epoch: 6| Step: 13
Training loss: 2.600457191467285
Validation loss: 2.159991205379527

Epoch: 127| Step: 0
Training loss: 2.2330403327941895
Validation loss: 2.14667115160214

Epoch: 6| Step: 1
Training loss: 2.207132339477539
Validation loss: 2.1680034488760014

Epoch: 6| Step: 2
Training loss: 1.9016597270965576
Validation loss: 2.160953470455703

Epoch: 6| Step: 3
Training loss: 2.1813745498657227
Validation loss: 2.154282416066816

Epoch: 6| Step: 4
Training loss: 2.0780532360076904
Validation loss: 2.1681952976411387

Epoch: 6| Step: 5
Training loss: 1.7309638261795044
Validation loss: 2.1980671908265803

Epoch: 6| Step: 6
Training loss: 2.7698493003845215
Validation loss: 2.181098720078827

Epoch: 6| Step: 7
Training loss: 1.6048016548156738
Validation loss: 2.181537430773499

Epoch: 6| Step: 8
Training loss: 2.6677327156066895
Validation loss: 2.1824694013082855

Epoch: 6| Step: 9
Training loss: 2.0548105239868164
Validation loss: 2.163887740463339

Epoch: 6| Step: 10
Training loss: 2.187396764755249
Validation loss: 2.1422025824105866

Epoch: 6| Step: 11
Training loss: 2.0382416248321533
Validation loss: 2.147742323977973

Epoch: 6| Step: 12
Training loss: 2.554978847503662
Validation loss: 2.1207354299483763

Epoch: 6| Step: 13
Training loss: 2.661875009536743
Validation loss: 2.1267472685024305

Epoch: 128| Step: 0
Training loss: 2.323518753051758
Validation loss: 2.1278737257885676

Epoch: 6| Step: 1
Training loss: 2.3267455101013184
Validation loss: 2.1337030062111477

Epoch: 6| Step: 2
Training loss: 2.327853202819824
Validation loss: 2.146861862110835

Epoch: 6| Step: 3
Training loss: 1.8380745649337769
Validation loss: 2.1458271780321674

Epoch: 6| Step: 4
Training loss: 1.9038530588150024
Validation loss: 2.167530321305798

Epoch: 6| Step: 5
Training loss: 2.035287380218506
Validation loss: 2.1704607804616294

Epoch: 6| Step: 6
Training loss: 2.280003786087036
Validation loss: 2.1988877340029647

Epoch: 6| Step: 7
Training loss: 2.0004546642303467
Validation loss: 2.1973360661537416

Epoch: 6| Step: 8
Training loss: 2.471074104309082
Validation loss: 2.169813190737078

Epoch: 6| Step: 9
Training loss: 2.3958542346954346
Validation loss: 2.1499535293989283

Epoch: 6| Step: 10
Training loss: 2.584080934524536
Validation loss: 2.1382578701101322

Epoch: 6| Step: 11
Training loss: 1.8494303226470947
Validation loss: 2.143719729556832

Epoch: 6| Step: 12
Training loss: 2.5287718772888184
Validation loss: 2.14177990856991

Epoch: 6| Step: 13
Training loss: 1.9176055192947388
Validation loss: 2.15117742682016

Epoch: 129| Step: 0
Training loss: 2.389716148376465
Validation loss: 2.1575270775825746

Epoch: 6| Step: 1
Training loss: 1.6682465076446533
Validation loss: 2.1654028584880214

Epoch: 6| Step: 2
Training loss: 2.4895434379577637
Validation loss: 2.180180888022146

Epoch: 6| Step: 3
Training loss: 1.8991976976394653
Validation loss: 2.181343270886329

Epoch: 6| Step: 4
Training loss: 3.083192825317383
Validation loss: 2.1926583397773003

Epoch: 6| Step: 5
Training loss: 1.6819207668304443
Validation loss: 2.1911148614780878

Epoch: 6| Step: 6
Training loss: 2.473156690597534
Validation loss: 2.187968450207864

Epoch: 6| Step: 7
Training loss: 1.942942500114441
Validation loss: 2.1744837120015132

Epoch: 6| Step: 8
Training loss: 2.1044554710388184
Validation loss: 2.1563303880794074

Epoch: 6| Step: 9
Training loss: 2.334105968475342
Validation loss: 2.1586248669573056

Epoch: 6| Step: 10
Training loss: 1.893913984298706
Validation loss: 2.1479270547948857

Epoch: 6| Step: 11
Training loss: 2.097656011581421
Validation loss: 2.139573415120443

Epoch: 6| Step: 12
Training loss: 2.3814127445220947
Validation loss: 2.1347944813389934

Epoch: 6| Step: 13
Training loss: 1.8621268272399902
Validation loss: 2.1339842683525494

Epoch: 130| Step: 0
Training loss: 2.140909194946289
Validation loss: 2.1277036769415743

Epoch: 6| Step: 1
Training loss: 2.7123231887817383
Validation loss: 2.1188516065638554

Epoch: 6| Step: 2
Training loss: 2.436946392059326
Validation loss: 2.1086149318243868

Epoch: 6| Step: 3
Training loss: 2.411306381225586
Validation loss: 2.106226477571713

Epoch: 6| Step: 4
Training loss: 2.3629138469696045
Validation loss: 2.1186909060324393

Epoch: 6| Step: 5
Training loss: 2.1839141845703125
Validation loss: 2.137028883862239

Epoch: 6| Step: 6
Training loss: 1.3414827585220337
Validation loss: 2.157061348679245

Epoch: 6| Step: 7
Training loss: 2.0974106788635254
Validation loss: 2.1637691990021737

Epoch: 6| Step: 8
Training loss: 2.105797529220581
Validation loss: 2.1558329495050574

Epoch: 6| Step: 9
Training loss: 1.8822096586227417
Validation loss: 2.162833152278777

Epoch: 6| Step: 10
Training loss: 1.835057258605957
Validation loss: 2.1395117211085495

Epoch: 6| Step: 11
Training loss: 2.2684850692749023
Validation loss: 2.1466838057323168

Epoch: 6| Step: 12
Training loss: 2.3868627548217773
Validation loss: 2.120281296391641

Epoch: 6| Step: 13
Training loss: 2.542778968811035
Validation loss: 2.1125692949500134

Epoch: 131| Step: 0
Training loss: 2.3670332431793213
Validation loss: 2.107950800208635

Epoch: 6| Step: 1
Training loss: 2.24777889251709
Validation loss: 2.112157920355438

Epoch: 6| Step: 2
Training loss: 1.9857898950576782
Validation loss: 2.1151001350854033

Epoch: 6| Step: 3
Training loss: 1.952233910560608
Validation loss: 2.1208599062376123

Epoch: 6| Step: 4
Training loss: 1.672465205192566
Validation loss: 2.1348863147920176

Epoch: 6| Step: 5
Training loss: 2.0063350200653076
Validation loss: 2.129753033320109

Epoch: 6| Step: 6
Training loss: 1.9233156442642212
Validation loss: 2.1501558083359913

Epoch: 6| Step: 7
Training loss: 2.403067111968994
Validation loss: 2.1528498600887995

Epoch: 6| Step: 8
Training loss: 2.059913158416748
Validation loss: 2.1667319395208873

Epoch: 6| Step: 9
Training loss: 2.4777088165283203
Validation loss: 2.158608703203099

Epoch: 6| Step: 10
Training loss: 2.796461582183838
Validation loss: 2.172218532972438

Epoch: 6| Step: 11
Training loss: 2.3574302196502686
Validation loss: 2.1526253159328173

Epoch: 6| Step: 12
Training loss: 1.8227286338806152
Validation loss: 2.137825075016227

Epoch: 6| Step: 13
Training loss: 2.164606809616089
Validation loss: 2.1234706653061735

Epoch: 132| Step: 0
Training loss: 2.6686055660247803
Validation loss: 2.1019482817701114

Epoch: 6| Step: 1
Training loss: 2.704801559448242
Validation loss: 2.086320029791965

Epoch: 6| Step: 2
Training loss: 2.438386917114258
Validation loss: 2.086014647637644

Epoch: 6| Step: 3
Training loss: 2.2007148265838623
Validation loss: 2.0849879275086107

Epoch: 6| Step: 4
Training loss: 2.0876402854919434
Validation loss: 2.082962123296594

Epoch: 6| Step: 5
Training loss: 1.646981954574585
Validation loss: 2.0862466583969774

Epoch: 6| Step: 6
Training loss: 1.7358851432800293
Validation loss: 2.0911809372645553

Epoch: 6| Step: 7
Training loss: 1.7590041160583496
Validation loss: 2.106926953920754

Epoch: 6| Step: 8
Training loss: 2.2631418704986572
Validation loss: 2.1150483380081835

Epoch: 6| Step: 9
Training loss: 2.3925700187683105
Validation loss: 2.128571730788036

Epoch: 6| Step: 10
Training loss: 1.297309398651123
Validation loss: 2.1422114731163107

Epoch: 6| Step: 11
Training loss: 2.3065810203552246
Validation loss: 2.1541872678264493

Epoch: 6| Step: 12
Training loss: 2.5452284812927246
Validation loss: 2.1311754488175914

Epoch: 6| Step: 13
Training loss: 2.054523229598999
Validation loss: 2.124225407518366

Epoch: 133| Step: 0
Training loss: 2.0852930545806885
Validation loss: 2.104997270850725

Epoch: 6| Step: 1
Training loss: 1.7369704246520996
Validation loss: 2.095865459852321

Epoch: 6| Step: 2
Training loss: 1.83901846408844
Validation loss: 2.1057691445914646

Epoch: 6| Step: 3
Training loss: 1.9670077562332153
Validation loss: 2.0933651180677515

Epoch: 6| Step: 4
Training loss: 1.8825182914733887
Validation loss: 2.1016320490068003

Epoch: 6| Step: 5
Training loss: 1.667536735534668
Validation loss: 2.0942859444566952

Epoch: 6| Step: 6
Training loss: 2.504488468170166
Validation loss: 2.103733460108439

Epoch: 6| Step: 7
Training loss: 1.6487025022506714
Validation loss: 2.097197281417026

Epoch: 6| Step: 8
Training loss: 2.698291778564453
Validation loss: 2.105728869797081

Epoch: 6| Step: 9
Training loss: 2.6740424633026123
Validation loss: 2.110858956972758

Epoch: 6| Step: 10
Training loss: 2.336672306060791
Validation loss: 2.0970260686771844

Epoch: 6| Step: 11
Training loss: 2.2958741188049316
Validation loss: 2.1077932516733804

Epoch: 6| Step: 12
Training loss: 2.1707592010498047
Validation loss: 2.142801159171648

Epoch: 6| Step: 13
Training loss: 2.146249532699585
Validation loss: 2.142019151359476

Epoch: 134| Step: 0
Training loss: 1.9345545768737793
Validation loss: 2.1243156938142675

Epoch: 6| Step: 1
Training loss: 2.550200939178467
Validation loss: 2.12959054464935

Epoch: 6| Step: 2
Training loss: 2.1230874061584473
Validation loss: 2.12664351155681

Epoch: 6| Step: 3
Training loss: 2.2521376609802246
Validation loss: 2.110619068145752

Epoch: 6| Step: 4
Training loss: 1.8553835153579712
Validation loss: 2.0771634578704834

Epoch: 6| Step: 5
Training loss: 2.169837474822998
Validation loss: 2.06647498889636

Epoch: 6| Step: 6
Training loss: 2.20951771736145
Validation loss: 2.066148050369755

Epoch: 6| Step: 7
Training loss: 2.341810941696167
Validation loss: 2.0661468941678285

Epoch: 6| Step: 8
Training loss: 2.1468067169189453
Validation loss: 2.059211741211594

Epoch: 6| Step: 9
Training loss: 2.158470869064331
Validation loss: 2.0656551712302753

Epoch: 6| Step: 10
Training loss: 2.60664701461792
Validation loss: 2.0711304872266707

Epoch: 6| Step: 11
Training loss: 1.8969682455062866
Validation loss: 2.0781710173494075

Epoch: 6| Step: 12
Training loss: 2.0289664268493652
Validation loss: 2.083145903002831

Epoch: 6| Step: 13
Training loss: 1.4713311195373535
Validation loss: 2.107485604542558

Epoch: 135| Step: 0
Training loss: 1.6576319932937622
Validation loss: 2.164870382637106

Epoch: 6| Step: 1
Training loss: 2.5847702026367188
Validation loss: 2.21094871336414

Epoch: 6| Step: 2
Training loss: 2.620070457458496
Validation loss: 2.187519537505283

Epoch: 6| Step: 3
Training loss: 2.437819004058838
Validation loss: 2.1733331167569725

Epoch: 6| Step: 4
Training loss: 2.2436370849609375
Validation loss: 2.1312246707177933

Epoch: 6| Step: 5
Training loss: 2.351501226425171
Validation loss: 2.104749215546475

Epoch: 6| Step: 6
Training loss: 2.128939151763916
Validation loss: 2.097914864940028

Epoch: 6| Step: 7
Training loss: 2.486182928085327
Validation loss: 2.0776753182052285

Epoch: 6| Step: 8
Training loss: 1.3155295848846436
Validation loss: 2.0990195299989436

Epoch: 6| Step: 9
Training loss: 1.792710781097412
Validation loss: 2.092083154186126

Epoch: 6| Step: 10
Training loss: 2.1908016204833984
Validation loss: 2.0985654951423727

Epoch: 6| Step: 11
Training loss: 1.738578200340271
Validation loss: 2.103642971284928

Epoch: 6| Step: 12
Training loss: 2.2192320823669434
Validation loss: 2.1505050402815624

Epoch: 6| Step: 13
Training loss: 2.3438961505889893
Validation loss: 2.217025774781422

Epoch: 136| Step: 0
Training loss: 2.544186592102051
Validation loss: 2.2353204860482165

Epoch: 6| Step: 1
Training loss: 1.8150557279586792
Validation loss: 2.2239976339442755

Epoch: 6| Step: 2
Training loss: 2.0175774097442627
Validation loss: 2.230455331904914

Epoch: 6| Step: 3
Training loss: 3.0922250747680664
Validation loss: 2.2077415348381124

Epoch: 6| Step: 4
Training loss: 1.9899177551269531
Validation loss: 2.158339051790135

Epoch: 6| Step: 5
Training loss: 2.322307825088501
Validation loss: 2.102185377510645

Epoch: 6| Step: 6
Training loss: 1.9649730920791626
Validation loss: 2.07662029932904

Epoch: 6| Step: 7
Training loss: 2.1464743614196777
Validation loss: 2.0746966908054967

Epoch: 6| Step: 8
Training loss: 2.029498338699341
Validation loss: 2.069559456199728

Epoch: 6| Step: 9
Training loss: 2.117177963256836
Validation loss: 2.0726188228976343

Epoch: 6| Step: 10
Training loss: 2.5357155799865723
Validation loss: 2.0767329482622046

Epoch: 6| Step: 11
Training loss: 1.7901544570922852
Validation loss: 2.082315533391891

Epoch: 6| Step: 12
Training loss: 2.1331348419189453
Validation loss: 2.0847773385304276

Epoch: 6| Step: 13
Training loss: 0.9287441968917847
Validation loss: 2.092036315189895

Epoch: 137| Step: 0
Training loss: 2.1296472549438477
Validation loss: 2.115521959079209

Epoch: 6| Step: 1
Training loss: 1.9090993404388428
Validation loss: 2.141643444697062

Epoch: 6| Step: 2
Training loss: 1.1180989742279053
Validation loss: 2.160539578366023

Epoch: 6| Step: 3
Training loss: 1.984893560409546
Validation loss: 2.185788905748757

Epoch: 6| Step: 4
Training loss: 2.1330981254577637
Validation loss: 2.2084956117855605

Epoch: 6| Step: 5
Training loss: 2.3513636589050293
Validation loss: 2.191580859563684

Epoch: 6| Step: 6
Training loss: 2.062030553817749
Validation loss: 2.163318493032968

Epoch: 6| Step: 7
Training loss: 2.316777229309082
Validation loss: 2.1559943396558046

Epoch: 6| Step: 8
Training loss: 2.296349287033081
Validation loss: 2.1342923205385924

Epoch: 6| Step: 9
Training loss: 2.015220880508423
Validation loss: 2.142818466309578

Epoch: 6| Step: 10
Training loss: 2.6955246925354004
Validation loss: 2.1351268560655656

Epoch: 6| Step: 11
Training loss: 2.1760096549987793
Validation loss: 2.1402347305769562

Epoch: 6| Step: 12
Training loss: 2.097766637802124
Validation loss: 2.142129464816022

Epoch: 6| Step: 13
Training loss: 2.30098032951355
Validation loss: 2.137807789669242

Epoch: 138| Step: 0
Training loss: 1.7972348928451538
Validation loss: 2.1185948194996005

Epoch: 6| Step: 1
Training loss: 2.743515968322754
Validation loss: 2.105053911926926

Epoch: 6| Step: 2
Training loss: 1.682175636291504
Validation loss: 2.1037702650152226

Epoch: 6| Step: 3
Training loss: 2.9660048484802246
Validation loss: 2.1042955203722884

Epoch: 6| Step: 4
Training loss: 1.6855602264404297
Validation loss: 2.0906013775897283

Epoch: 6| Step: 5
Training loss: 2.32534122467041
Validation loss: 2.0874062417655863

Epoch: 6| Step: 6
Training loss: 2.0092949867248535
Validation loss: 2.0934608700454875

Epoch: 6| Step: 7
Training loss: 2.548001766204834
Validation loss: 2.1049915077865764

Epoch: 6| Step: 8
Training loss: 1.531904697418213
Validation loss: 2.0966082542173323

Epoch: 6| Step: 9
Training loss: 2.3366403579711914
Validation loss: 2.0908726376871907

Epoch: 6| Step: 10
Training loss: 1.6708831787109375
Validation loss: 2.1016158596161874

Epoch: 6| Step: 11
Training loss: 2.259993553161621
Validation loss: 2.10134550832933

Epoch: 6| Step: 12
Training loss: 1.1745026111602783
Validation loss: 2.1146833255726802

Epoch: 6| Step: 13
Training loss: 2.7653424739837646
Validation loss: 2.1239422188010266

Epoch: 139| Step: 0
Training loss: 2.6102399826049805
Validation loss: 2.1342110249304

Epoch: 6| Step: 1
Training loss: 2.187836170196533
Validation loss: 2.1211652371191208

Epoch: 6| Step: 2
Training loss: 1.9335293769836426
Validation loss: 2.1053030260147585

Epoch: 6| Step: 3
Training loss: 2.247048854827881
Validation loss: 2.1053507917670795

Epoch: 6| Step: 4
Training loss: 1.7851812839508057
Validation loss: 2.1051776357876357

Epoch: 6| Step: 5
Training loss: 1.8061718940734863
Validation loss: 2.0962423662985525

Epoch: 6| Step: 6
Training loss: 1.9996505975723267
Validation loss: 2.094398372916765

Epoch: 6| Step: 7
Training loss: 2.374725341796875
Validation loss: 2.106751072791315

Epoch: 6| Step: 8
Training loss: 1.6993122100830078
Validation loss: 2.1046625593657136

Epoch: 6| Step: 9
Training loss: 1.9488641023635864
Validation loss: 2.1191651846772883

Epoch: 6| Step: 10
Training loss: 2.1651675701141357
Validation loss: 2.125111545285871

Epoch: 6| Step: 11
Training loss: 1.703516960144043
Validation loss: 2.105723314387824

Epoch: 6| Step: 12
Training loss: 2.6178741455078125
Validation loss: 2.1112662848605903

Epoch: 6| Step: 13
Training loss: 2.2922072410583496
Validation loss: 2.0850563895317817

Epoch: 140| Step: 0
Training loss: 1.8775358200073242
Validation loss: 2.07757124593181

Epoch: 6| Step: 1
Training loss: 1.92678701877594
Validation loss: 2.088277957772696

Epoch: 6| Step: 2
Training loss: 2.497678756713867
Validation loss: 2.0878054634217293

Epoch: 6| Step: 3
Training loss: 1.875606894493103
Validation loss: 2.0785568709014566

Epoch: 6| Step: 4
Training loss: 1.7624657154083252
Validation loss: 2.0921058808603594

Epoch: 6| Step: 5
Training loss: 2.1972241401672363
Validation loss: 2.1159468466235745

Epoch: 6| Step: 6
Training loss: 1.863663673400879
Validation loss: 2.1227652834307764

Epoch: 6| Step: 7
Training loss: 1.588987112045288
Validation loss: 2.1241996570300032

Epoch: 6| Step: 8
Training loss: 2.5225765705108643
Validation loss: 2.1293794314066568

Epoch: 6| Step: 9
Training loss: 2.478485345840454
Validation loss: 2.1413306933577343

Epoch: 6| Step: 10
Training loss: 2.7727553844451904
Validation loss: 2.1510344192545903

Epoch: 6| Step: 11
Training loss: 1.9333326816558838
Validation loss: 2.126613281106436

Epoch: 6| Step: 12
Training loss: 2.1520004272460938
Validation loss: 2.1224821741862963

Epoch: 6| Step: 13
Training loss: 1.2141846418380737
Validation loss: 2.103926363811698

Epoch: 141| Step: 0
Training loss: 2.047633171081543
Validation loss: 2.0781648018026866

Epoch: 6| Step: 1
Training loss: 1.712968349456787
Validation loss: 2.0891918123409314

Epoch: 6| Step: 2
Training loss: 2.3311986923217773
Validation loss: 2.083978610654031

Epoch: 6| Step: 3
Training loss: 2.5666592121124268
Validation loss: 2.0975688298543296

Epoch: 6| Step: 4
Training loss: 1.7167870998382568
Validation loss: 2.1089394207923644

Epoch: 6| Step: 5
Training loss: 2.0865516662597656
Validation loss: 2.146660440711565

Epoch: 6| Step: 6
Training loss: 2.2901926040649414
Validation loss: 2.142462335607057

Epoch: 6| Step: 7
Training loss: 2.108590841293335
Validation loss: 2.149194468734085

Epoch: 6| Step: 8
Training loss: 1.999929428100586
Validation loss: 2.146368311297509

Epoch: 6| Step: 9
Training loss: 2.2747855186462402
Validation loss: 2.1392142234310025

Epoch: 6| Step: 10
Training loss: 2.3524329662323
Validation loss: 2.1173584768849034

Epoch: 6| Step: 11
Training loss: 1.6691436767578125
Validation loss: 2.082930696907864

Epoch: 6| Step: 12
Training loss: 2.0302059650421143
Validation loss: 2.066886173781528

Epoch: 6| Step: 13
Training loss: 2.011829137802124
Validation loss: 2.0694083821388984

Epoch: 142| Step: 0
Training loss: 1.7560160160064697
Validation loss: 2.058447409701604

Epoch: 6| Step: 1
Training loss: 2.493499279022217
Validation loss: 2.0628647176168298

Epoch: 6| Step: 2
Training loss: 2.1637988090515137
Validation loss: 2.078805233842583

Epoch: 6| Step: 3
Training loss: 1.741858720779419
Validation loss: 2.0958500882630706

Epoch: 6| Step: 4
Training loss: 2.595611572265625
Validation loss: 2.1373045598306963

Epoch: 6| Step: 5
Training loss: 2.534298896789551
Validation loss: 2.138571089313876

Epoch: 6| Step: 6
Training loss: 1.4577182531356812
Validation loss: 2.169944469646741

Epoch: 6| Step: 7
Training loss: 2.2286734580993652
Validation loss: 2.185651158773771

Epoch: 6| Step: 8
Training loss: 2.2642784118652344
Validation loss: 2.2136678003495738

Epoch: 6| Step: 9
Training loss: 1.1756139993667603
Validation loss: 2.186027701183032

Epoch: 6| Step: 10
Training loss: 2.9986095428466797
Validation loss: 2.1653700336333244

Epoch: 6| Step: 11
Training loss: 2.003035545349121
Validation loss: 2.1330078750528316

Epoch: 6| Step: 12
Training loss: 1.6534035205841064
Validation loss: 2.1148066264326855

Epoch: 6| Step: 13
Training loss: 1.9218196868896484
Validation loss: 2.1163782317151307

Epoch: 143| Step: 0
Training loss: 2.1692347526550293
Validation loss: 2.1186527821325485

Epoch: 6| Step: 1
Training loss: 2.238370895385742
Validation loss: 2.1321224986865954

Epoch: 6| Step: 2
Training loss: 2.4339613914489746
Validation loss: 2.1297400971894622

Epoch: 6| Step: 3
Training loss: 1.6927268505096436
Validation loss: 2.1300234666434665

Epoch: 6| Step: 4
Training loss: 1.89955472946167
Validation loss: 2.1440245797557216

Epoch: 6| Step: 5
Training loss: 1.9583908319473267
Validation loss: 2.116334251178208

Epoch: 6| Step: 6
Training loss: 2.6077237129211426
Validation loss: 2.117379311592348

Epoch: 6| Step: 7
Training loss: 2.403546094894409
Validation loss: 2.122957242432461

Epoch: 6| Step: 8
Training loss: 2.0119783878326416
Validation loss: 2.118605295817057

Epoch: 6| Step: 9
Training loss: 1.8819785118103027
Validation loss: 2.144503088407619

Epoch: 6| Step: 10
Training loss: 1.6409378051757812
Validation loss: 2.1689569257920787

Epoch: 6| Step: 11
Training loss: 1.5749661922454834
Validation loss: 2.1948563552671865

Epoch: 6| Step: 12
Training loss: 2.0827953815460205
Validation loss: 2.170195362901175

Epoch: 6| Step: 13
Training loss: 2.6000618934631348
Validation loss: 2.1453442868366035

Epoch: 144| Step: 0
Training loss: 2.340510606765747
Validation loss: 2.119461945308152

Epoch: 6| Step: 1
Training loss: 1.9655473232269287
Validation loss: 2.0868998855672856

Epoch: 6| Step: 2
Training loss: 1.0787670612335205
Validation loss: 2.0701028531597507

Epoch: 6| Step: 3
Training loss: 2.3914871215820312
Validation loss: 2.063021711123887

Epoch: 6| Step: 4
Training loss: 1.9648692607879639
Validation loss: 2.0688591541782504

Epoch: 6| Step: 5
Training loss: 2.0729012489318848
Validation loss: 2.082713859055632

Epoch: 6| Step: 6
Training loss: 2.375751256942749
Validation loss: 2.07804673974232

Epoch: 6| Step: 7
Training loss: 2.644923210144043
Validation loss: 2.0796577033176216

Epoch: 6| Step: 8
Training loss: 2.288630962371826
Validation loss: 2.082883316983459

Epoch: 6| Step: 9
Training loss: 1.7390694618225098
Validation loss: 2.1006033702563216

Epoch: 6| Step: 10
Training loss: 1.8497238159179688
Validation loss: 2.1147513158859743

Epoch: 6| Step: 11
Training loss: 1.2919015884399414
Validation loss: 2.1310192461936706

Epoch: 6| Step: 12
Training loss: 2.3120813369750977
Validation loss: 2.16082158652685

Epoch: 6| Step: 13
Training loss: 2.8369951248168945
Validation loss: 2.1643154723669893

Epoch: 145| Step: 0
Training loss: 2.4453811645507812
Validation loss: 2.1611322510627007

Epoch: 6| Step: 1
Training loss: 2.222313404083252
Validation loss: 2.1432541775447067

Epoch: 6| Step: 2
Training loss: 1.7211132049560547
Validation loss: 2.1145871018850677

Epoch: 6| Step: 3
Training loss: 2.0841939449310303
Validation loss: 2.107746852341519

Epoch: 6| Step: 4
Training loss: 1.8549855947494507
Validation loss: 2.0938329260836364

Epoch: 6| Step: 5
Training loss: 2.19333553314209
Validation loss: 2.0798839599855485

Epoch: 6| Step: 6
Training loss: 2.2732090950012207
Validation loss: 2.0599534037292644

Epoch: 6| Step: 7
Training loss: 2.562375068664551
Validation loss: 2.0620795988267466

Epoch: 6| Step: 8
Training loss: 2.2903037071228027
Validation loss: 2.070414343187886

Epoch: 6| Step: 9
Training loss: 1.666834831237793
Validation loss: 2.079344928905528

Epoch: 6| Step: 10
Training loss: 1.8211480379104614
Validation loss: 2.108089890531314

Epoch: 6| Step: 11
Training loss: 1.6710460186004639
Validation loss: 2.127899621122627

Epoch: 6| Step: 12
Training loss: 1.63993239402771
Validation loss: 2.1716387400063137

Epoch: 6| Step: 13
Training loss: 2.6513936519622803
Validation loss: 2.165515720203359

Epoch: 146| Step: 0
Training loss: 2.571305751800537
Validation loss: 2.1519385230156685

Epoch: 6| Step: 1
Training loss: 2.00376558303833
Validation loss: 2.1490474259981545

Epoch: 6| Step: 2
Training loss: 2.1837692260742188
Validation loss: 2.1286902036718143

Epoch: 6| Step: 3
Training loss: 2.027848482131958
Validation loss: 2.0985335252618276

Epoch: 6| Step: 4
Training loss: 1.9936549663543701
Validation loss: 2.0851378722857405

Epoch: 6| Step: 5
Training loss: 1.7310734987258911
Validation loss: 2.0838041920815744

Epoch: 6| Step: 6
Training loss: 2.2109804153442383
Validation loss: 2.0753907401074647

Epoch: 6| Step: 7
Training loss: 1.741143822669983
Validation loss: 2.065515459224742

Epoch: 6| Step: 8
Training loss: 1.3533902168273926
Validation loss: 2.09363232633119

Epoch: 6| Step: 9
Training loss: 2.4006736278533936
Validation loss: 2.1003424377851587

Epoch: 6| Step: 10
Training loss: 1.923025369644165
Validation loss: 2.1209291270984116

Epoch: 6| Step: 11
Training loss: 1.6768097877502441
Validation loss: 2.131524383380849

Epoch: 6| Step: 12
Training loss: 1.982407808303833
Validation loss: 2.1477054190892044

Epoch: 6| Step: 13
Training loss: 3.5449514389038086
Validation loss: 2.1606138137079056

Epoch: 147| Step: 0
Training loss: 2.091665029525757
Validation loss: 2.126579317995297

Epoch: 6| Step: 1
Training loss: 2.316627025604248
Validation loss: 2.1201556754368607

Epoch: 6| Step: 2
Training loss: 1.7463197708129883
Validation loss: 2.1097993876344416

Epoch: 6| Step: 3
Training loss: 2.575082540512085
Validation loss: 2.0797514748829666

Epoch: 6| Step: 4
Training loss: 1.7686489820480347
Validation loss: 2.0703146201308056

Epoch: 6| Step: 5
Training loss: 1.1598126888275146
Validation loss: 2.0690834573520127

Epoch: 6| Step: 6
Training loss: 2.5649590492248535
Validation loss: 2.0709200661669493

Epoch: 6| Step: 7
Training loss: 2.0968310832977295
Validation loss: 2.059952715391754

Epoch: 6| Step: 8
Training loss: 1.9111422300338745
Validation loss: 2.0721138408107143

Epoch: 6| Step: 9
Training loss: 1.6363346576690674
Validation loss: 2.0957559718880603

Epoch: 6| Step: 10
Training loss: 2.4319326877593994
Validation loss: 2.094641572685652

Epoch: 6| Step: 11
Training loss: 2.013449192047119
Validation loss: 2.100929116690031

Epoch: 6| Step: 12
Training loss: 1.7980445623397827
Validation loss: 2.0974403735130065

Epoch: 6| Step: 13
Training loss: 2.0502164363861084
Validation loss: 2.0933862245211037

Epoch: 148| Step: 0
Training loss: 1.9173080921173096
Validation loss: 2.0974964275155017

Epoch: 6| Step: 1
Training loss: 1.7172224521636963
Validation loss: 2.084817671006726

Epoch: 6| Step: 2
Training loss: 1.6740657091140747
Validation loss: 2.0955088420580794

Epoch: 6| Step: 3
Training loss: 1.5842351913452148
Validation loss: 2.1017390374214417

Epoch: 6| Step: 4
Training loss: 2.123012065887451
Validation loss: 2.107898533985179

Epoch: 6| Step: 5
Training loss: 1.965226411819458
Validation loss: 2.11611407931133

Epoch: 6| Step: 6
Training loss: 3.0883982181549072
Validation loss: 2.1144727532581618

Epoch: 6| Step: 7
Training loss: 2.1225831508636475
Validation loss: 2.103996756256268

Epoch: 6| Step: 8
Training loss: 2.5326333045959473
Validation loss: 2.105445090160575

Epoch: 6| Step: 9
Training loss: 1.875295877456665
Validation loss: 2.0849908526225756

Epoch: 6| Step: 10
Training loss: 2.3038570880889893
Validation loss: 2.0886241825678016

Epoch: 6| Step: 11
Training loss: 2.146634101867676
Validation loss: 2.070386237995599

Epoch: 6| Step: 12
Training loss: 1.5510762929916382
Validation loss: 2.088168445453849

Epoch: 6| Step: 13
Training loss: 1.3610234260559082
Validation loss: 2.087266834833289

Epoch: 149| Step: 0
Training loss: 2.1542534828186035
Validation loss: 2.0746663385821926

Epoch: 6| Step: 1
Training loss: 2.0171279907226562
Validation loss: 2.1026857104352725

Epoch: 6| Step: 2
Training loss: 2.626936435699463
Validation loss: 2.0942808069208616

Epoch: 6| Step: 3
Training loss: 1.7531651258468628
Validation loss: 2.1015947300900697

Epoch: 6| Step: 4
Training loss: 2.2461681365966797
Validation loss: 2.0966678896257953

Epoch: 6| Step: 5
Training loss: 2.3260695934295654
Validation loss: 2.1136968622925463

Epoch: 6| Step: 6
Training loss: 1.4461958408355713
Validation loss: 2.1064443229347147

Epoch: 6| Step: 7
Training loss: 2.009885787963867
Validation loss: 2.0981518427530923

Epoch: 6| Step: 8
Training loss: 1.7528033256530762
Validation loss: 2.097065810234316

Epoch: 6| Step: 9
Training loss: 1.5704455375671387
Validation loss: 2.094870400685136

Epoch: 6| Step: 10
Training loss: 2.480104923248291
Validation loss: 2.0915716027700775

Epoch: 6| Step: 11
Training loss: 1.6142315864562988
Validation loss: 2.090998072778025

Epoch: 6| Step: 12
Training loss: 1.33738112449646
Validation loss: 2.0846297753754484

Epoch: 6| Step: 13
Training loss: 3.025515556335449
Validation loss: 2.079412603891024

Epoch: 150| Step: 0
Training loss: 2.5706851482391357
Validation loss: 2.0872772714143157

Epoch: 6| Step: 1
Training loss: 1.561178207397461
Validation loss: 2.09698333022415

Epoch: 6| Step: 2
Training loss: 1.5248218774795532
Validation loss: 2.1019073660655687

Epoch: 6| Step: 3
Training loss: 1.9540235996246338
Validation loss: 2.0824783104722218

Epoch: 6| Step: 4
Training loss: 2.627918243408203
Validation loss: 2.0748129237082695

Epoch: 6| Step: 5
Training loss: 1.5583943128585815
Validation loss: 2.0865183132950977

Epoch: 6| Step: 6
Training loss: 1.6909257173538208
Validation loss: 2.080848281101514

Epoch: 6| Step: 7
Training loss: 1.745408058166504
Validation loss: 2.0939315390843216

Epoch: 6| Step: 8
Training loss: 1.9773491621017456
Validation loss: 2.092877056009026

Epoch: 6| Step: 9
Training loss: 1.8053460121154785
Validation loss: 2.1000341343623337

Epoch: 6| Step: 10
Training loss: 2.451247215270996
Validation loss: 2.0927629624643633

Epoch: 6| Step: 11
Training loss: 2.3642330169677734
Validation loss: 2.0980781278302594

Epoch: 6| Step: 12
Training loss: 1.2570180892944336
Validation loss: 2.086415449778239

Epoch: 6| Step: 13
Training loss: 3.3004212379455566
Validation loss: 2.0751354771275676

Epoch: 151| Step: 0
Training loss: 2.087588310241699
Validation loss: 2.0794149137312368

Epoch: 6| Step: 1
Training loss: 1.9703328609466553
Validation loss: 2.069818781268212

Epoch: 6| Step: 2
Training loss: 1.5504035949707031
Validation loss: 2.0725018491027174

Epoch: 6| Step: 3
Training loss: 2.1731858253479004
Validation loss: 2.069390255917785

Epoch: 6| Step: 4
Training loss: 2.184237003326416
Validation loss: 2.0756806801724177

Epoch: 6| Step: 5
Training loss: 2.0518457889556885
Validation loss: 2.0910146428692724

Epoch: 6| Step: 6
Training loss: 2.1313838958740234
Validation loss: 2.105411752577751

Epoch: 6| Step: 7
Training loss: 1.5636684894561768
Validation loss: 2.1265094459697766

Epoch: 6| Step: 8
Training loss: 2.0181055068969727
Validation loss: 2.129359784946647

Epoch: 6| Step: 9
Training loss: 2.518106698989868
Validation loss: 2.1236090634458806

Epoch: 6| Step: 10
Training loss: 2.442549228668213
Validation loss: 2.128340267365979

Epoch: 6| Step: 11
Training loss: 2.1190004348754883
Validation loss: 2.106251730713793

Epoch: 6| Step: 12
Training loss: 1.5136444568634033
Validation loss: 2.0944594208912184

Epoch: 6| Step: 13
Training loss: 1.1630024909973145
Validation loss: 2.089730183283488

Epoch: 152| Step: 0
Training loss: 1.6157333850860596
Validation loss: 2.0742922265042543

Epoch: 6| Step: 1
Training loss: 2.08229660987854
Validation loss: 2.0865145524342856

Epoch: 6| Step: 2
Training loss: 1.8544704914093018
Validation loss: 2.080692809115174

Epoch: 6| Step: 3
Training loss: 1.742330551147461
Validation loss: 2.089599299174483

Epoch: 6| Step: 4
Training loss: 2.280200481414795
Validation loss: 2.0811882941953597

Epoch: 6| Step: 5
Training loss: 1.6980706453323364
Validation loss: 2.0769932936596613

Epoch: 6| Step: 6
Training loss: 2.173036575317383
Validation loss: 2.0688235759735107

Epoch: 6| Step: 7
Training loss: 1.1923110485076904
Validation loss: 2.0583440796021493

Epoch: 6| Step: 8
Training loss: 2.4926347732543945
Validation loss: 2.0612906743121404

Epoch: 6| Step: 9
Training loss: 2.82645320892334
Validation loss: 2.0662373137730423

Epoch: 6| Step: 10
Training loss: 1.8648477792739868
Validation loss: 2.0796534886924167

Epoch: 6| Step: 11
Training loss: 1.9310510158538818
Validation loss: 2.0812204486580304

Epoch: 6| Step: 12
Training loss: 1.5708597898483276
Validation loss: 2.0903959569110664

Epoch: 6| Step: 13
Training loss: 2.549328088760376
Validation loss: 2.0953460124231156

Epoch: 153| Step: 0
Training loss: 2.40336012840271
Validation loss: 2.096864188871076

Epoch: 6| Step: 1
Training loss: 1.9028878211975098
Validation loss: 2.0857724169249177

Epoch: 6| Step: 2
Training loss: 2.452601432800293
Validation loss: 2.094233465451066

Epoch: 6| Step: 3
Training loss: 1.9993059635162354
Validation loss: 2.106230471723823

Epoch: 6| Step: 4
Training loss: 1.8182590007781982
Validation loss: 2.114362426983413

Epoch: 6| Step: 5
Training loss: 1.5116865634918213
Validation loss: 2.1036006481416765

Epoch: 6| Step: 6
Training loss: 1.8249372243881226
Validation loss: 2.1095806501244985

Epoch: 6| Step: 7
Training loss: 2.4652438163757324
Validation loss: 2.095530325366605

Epoch: 6| Step: 8
Training loss: 1.8235608339309692
Validation loss: 2.112180732911633

Epoch: 6| Step: 9
Training loss: 1.9372870922088623
Validation loss: 2.1144191321506294

Epoch: 6| Step: 10
Training loss: 1.8474628925323486
Validation loss: 2.0953618480313208

Epoch: 6| Step: 11
Training loss: 2.559572458267212
Validation loss: 2.0924541963044034

Epoch: 6| Step: 12
Training loss: 1.1284806728363037
Validation loss: 2.0886268974632345

Epoch: 6| Step: 13
Training loss: 1.7481836080551147
Validation loss: 2.0560945464718725

Epoch: 154| Step: 0
Training loss: 1.7616865634918213
Validation loss: 2.0582248344216296

Epoch: 6| Step: 1
Training loss: 2.6226353645324707
Validation loss: 2.0487770290784937

Epoch: 6| Step: 2
Training loss: 1.5319373607635498
Validation loss: 2.0479711524901854

Epoch: 6| Step: 3
Training loss: 2.2211427688598633
Validation loss: 2.049833320802258

Epoch: 6| Step: 4
Training loss: 1.3291850090026855
Validation loss: 2.0585835287647862

Epoch: 6| Step: 5
Training loss: 1.9925596714019775
Validation loss: 2.056033780497889

Epoch: 6| Step: 6
Training loss: 1.9831008911132812
Validation loss: 2.0569878906332035

Epoch: 6| Step: 7
Training loss: 2.173121690750122
Validation loss: 2.0572976604584725

Epoch: 6| Step: 8
Training loss: 1.2174170017242432
Validation loss: 2.0733422335758003

Epoch: 6| Step: 9
Training loss: 1.7713361978530884
Validation loss: 2.0825596599168676

Epoch: 6| Step: 10
Training loss: 1.7894799709320068
Validation loss: 2.064948986935359

Epoch: 6| Step: 11
Training loss: 2.5955121517181396
Validation loss: 2.060375339241438

Epoch: 6| Step: 12
Training loss: 1.9181997776031494
Validation loss: 2.0546147195241784

Epoch: 6| Step: 13
Training loss: 2.844064474105835
Validation loss: 2.075299609091974

Epoch: 155| Step: 0
Training loss: 2.5649819374084473
Validation loss: 2.0638563697056105

Epoch: 6| Step: 1
Training loss: 2.559197425842285
Validation loss: 2.0701641780073925

Epoch: 6| Step: 2
Training loss: 1.6991742849349976
Validation loss: 2.0803853068300473

Epoch: 6| Step: 3
Training loss: 1.413257360458374
Validation loss: 2.0718928998516453

Epoch: 6| Step: 4
Training loss: 1.5370501279830933
Validation loss: 2.0713822072552097

Epoch: 6| Step: 5
Training loss: 2.680027961730957
Validation loss: 2.069691196564705

Epoch: 6| Step: 6
Training loss: 1.8173062801361084
Validation loss: 2.072184108918713

Epoch: 6| Step: 7
Training loss: 1.9978142976760864
Validation loss: 2.0865517623962893

Epoch: 6| Step: 8
Training loss: 2.3942317962646484
Validation loss: 2.1333404100069435

Epoch: 6| Step: 9
Training loss: 1.3450440168380737
Validation loss: 2.123773305646835

Epoch: 6| Step: 10
Training loss: 1.6661171913146973
Validation loss: 2.1104250723315823

Epoch: 6| Step: 11
Training loss: 2.1400415897369385
Validation loss: 2.114409864589732

Epoch: 6| Step: 12
Training loss: 1.8229100704193115
Validation loss: 2.098605853255077

Epoch: 6| Step: 13
Training loss: 1.1958203315734863
Validation loss: 2.0915425541580364

Epoch: 156| Step: 0
Training loss: 2.649113178253174
Validation loss: 2.0865188157686623

Epoch: 6| Step: 1
Training loss: 1.582627534866333
Validation loss: 2.083540678024292

Epoch: 6| Step: 2
Training loss: 1.9581334590911865
Validation loss: 2.092198133468628

Epoch: 6| Step: 3
Training loss: 1.1950315237045288
Validation loss: 2.092404632158177

Epoch: 6| Step: 4
Training loss: 2.0316386222839355
Validation loss: 2.094414467452675

Epoch: 6| Step: 5
Training loss: 1.5395115613937378
Validation loss: 2.0898865679258942

Epoch: 6| Step: 6
Training loss: 1.7830220460891724
Validation loss: 2.0885146740944154

Epoch: 6| Step: 7
Training loss: 2.221561908721924
Validation loss: 2.072098724303707

Epoch: 6| Step: 8
Training loss: 2.317901849746704
Validation loss: 2.0708687843814975

Epoch: 6| Step: 9
Training loss: 1.8811217546463013
Validation loss: 2.0705248719902447

Epoch: 6| Step: 10
Training loss: 2.073188543319702
Validation loss: 2.0675377858582364

Epoch: 6| Step: 11
Training loss: 1.8938567638397217
Validation loss: 2.0619058147553475

Epoch: 6| Step: 12
Training loss: 2.388023853302002
Validation loss: 2.0711710683761106

Epoch: 6| Step: 13
Training loss: 1.4111497402191162
Validation loss: 2.048785355783278

Epoch: 157| Step: 0
Training loss: 1.8682966232299805
Validation loss: 2.0611648969752814

Epoch: 6| Step: 1
Training loss: 1.9204163551330566
Validation loss: 2.071234231354088

Epoch: 6| Step: 2
Training loss: 2.6646080017089844
Validation loss: 2.072083201459659

Epoch: 6| Step: 3
Training loss: 1.8625952005386353
Validation loss: 2.0725911060969033

Epoch: 6| Step: 4
Training loss: 2.2386021614074707
Validation loss: 2.0598873079464

Epoch: 6| Step: 5
Training loss: 1.9051032066345215
Validation loss: 2.063887221838838

Epoch: 6| Step: 6
Training loss: 2.124619722366333
Validation loss: 2.060819387435913

Epoch: 6| Step: 7
Training loss: 1.7489042282104492
Validation loss: 2.0931182497291156

Epoch: 6| Step: 8
Training loss: 1.8076701164245605
Validation loss: 2.095534760464904

Epoch: 6| Step: 9
Training loss: 1.704616904258728
Validation loss: 2.106461642890848

Epoch: 6| Step: 10
Training loss: 1.856407880783081
Validation loss: 2.0820408815978677

Epoch: 6| Step: 11
Training loss: 1.438319206237793
Validation loss: 2.0860743522644043

Epoch: 6| Step: 12
Training loss: 2.2013356685638428
Validation loss: 2.0857194418548257

Epoch: 6| Step: 13
Training loss: 1.326138973236084
Validation loss: 2.0837520604492514

Epoch: 158| Step: 0
Training loss: 1.5288615226745605
Validation loss: 2.096869750689435

Epoch: 6| Step: 1
Training loss: 1.8632988929748535
Validation loss: 2.0972268555753972

Epoch: 6| Step: 2
Training loss: 2.4734904766082764
Validation loss: 2.134315098485639

Epoch: 6| Step: 3
Training loss: 2.03065824508667
Validation loss: 2.1769072996672763

Epoch: 6| Step: 4
Training loss: 1.9342031478881836
Validation loss: 2.1619156176044094

Epoch: 6| Step: 5
Training loss: 2.132589101791382
Validation loss: 2.112769155092137

Epoch: 6| Step: 6
Training loss: 2.1988096237182617
Validation loss: 2.087070926543205

Epoch: 6| Step: 7
Training loss: 1.762791395187378
Validation loss: 2.0743326320443103

Epoch: 6| Step: 8
Training loss: 1.890594482421875
Validation loss: 2.0550622709335817

Epoch: 6| Step: 9
Training loss: 2.199681520462036
Validation loss: 2.0545268084413264

Epoch: 6| Step: 10
Training loss: 2.4833760261535645
Validation loss: 2.059407627710732

Epoch: 6| Step: 11
Training loss: 1.303971529006958
Validation loss: 2.063816273084251

Epoch: 6| Step: 12
Training loss: 1.5994477272033691
Validation loss: 2.067327719862743

Epoch: 6| Step: 13
Training loss: 1.846556305885315
Validation loss: 2.067473546151192

Epoch: 159| Step: 0
Training loss: 1.975074052810669
Validation loss: 2.072329636543028

Epoch: 6| Step: 1
Training loss: 1.8899086713790894
Validation loss: 2.0936171367604244

Epoch: 6| Step: 2
Training loss: 2.3438491821289062
Validation loss: 2.1000237259813535

Epoch: 6| Step: 3
Training loss: 2.171335458755493
Validation loss: 2.106836490733649

Epoch: 6| Step: 4
Training loss: 1.7902573347091675
Validation loss: 2.124133312573997

Epoch: 6| Step: 5
Training loss: 2.092982769012451
Validation loss: 2.11686110496521

Epoch: 6| Step: 6
Training loss: 2.215346097946167
Validation loss: 2.1281782350232525

Epoch: 6| Step: 7
Training loss: 1.8588844537734985
Validation loss: 2.1370650222224574

Epoch: 6| Step: 8
Training loss: 2.4893414974212646
Validation loss: 2.120921560513076

Epoch: 6| Step: 9
Training loss: 1.9228615760803223
Validation loss: 2.095806006462343

Epoch: 6| Step: 10
Training loss: 1.5586433410644531
Validation loss: 2.0852164478712183

Epoch: 6| Step: 11
Training loss: 1.4051995277404785
Validation loss: 2.0732349041969544

Epoch: 6| Step: 12
Training loss: 2.025451183319092
Validation loss: 2.0642713603153022

Epoch: 6| Step: 13
Training loss: 0.7752917408943176
Validation loss: 2.064223971418155

Epoch: 160| Step: 0
Training loss: 1.676882028579712
Validation loss: 2.0681668071336645

Epoch: 6| Step: 1
Training loss: 1.370544195175171
Validation loss: 2.067235182690364

Epoch: 6| Step: 2
Training loss: 2.3492207527160645
Validation loss: 2.08441525120889

Epoch: 6| Step: 3
Training loss: 2.427402973175049
Validation loss: 2.107492523808633

Epoch: 6| Step: 4
Training loss: 2.6507179737091064
Validation loss: 2.1414550504376813

Epoch: 6| Step: 5
Training loss: 1.8980361223220825
Validation loss: 2.1358741355198685

Epoch: 6| Step: 6
Training loss: 1.9726192951202393
Validation loss: 2.1288718767063592

Epoch: 6| Step: 7
Training loss: 1.290143609046936
Validation loss: 2.084343743580644

Epoch: 6| Step: 8
Training loss: 1.8803093433380127
Validation loss: 2.0539128472728114

Epoch: 6| Step: 9
Training loss: 1.764325499534607
Validation loss: 2.038819756559146

Epoch: 6| Step: 10
Training loss: 1.945649266242981
Validation loss: 2.052352827082398

Epoch: 6| Step: 11
Training loss: 2.3883986473083496
Validation loss: 2.0507632417063557

Epoch: 6| Step: 12
Training loss: 1.6621379852294922
Validation loss: 2.0590528185649584

Epoch: 6| Step: 13
Training loss: 1.8022708892822266
Validation loss: 2.0551363627115884

Epoch: 161| Step: 0
Training loss: 1.3744792938232422
Validation loss: 2.079863167578174

Epoch: 6| Step: 1
Training loss: 1.950249195098877
Validation loss: 2.0833183796175065

Epoch: 6| Step: 2
Training loss: 0.9141246676445007
Validation loss: 2.10865234175036

Epoch: 6| Step: 3
Training loss: 2.1280360221862793
Validation loss: 2.112574792677356

Epoch: 6| Step: 4
Training loss: 2.082550287246704
Validation loss: 2.095943517582391

Epoch: 6| Step: 5
Training loss: 1.9610917568206787
Validation loss: 2.0939266374034267

Epoch: 6| Step: 6
Training loss: 2.385415554046631
Validation loss: 2.101931310469104

Epoch: 6| Step: 7
Training loss: 2.053368330001831
Validation loss: 2.0740241401938984

Epoch: 6| Step: 8
Training loss: 2.14570951461792
Validation loss: 2.0846874636988484

Epoch: 6| Step: 9
Training loss: 1.7884571552276611
Validation loss: 2.0687788942808747

Epoch: 6| Step: 10
Training loss: 2.207408905029297
Validation loss: 2.0756207384088987

Epoch: 6| Step: 11
Training loss: 1.8812332153320312
Validation loss: 2.0857839661259807

Epoch: 6| Step: 12
Training loss: 1.9962608814239502
Validation loss: 2.0937618286378923

Epoch: 6| Step: 13
Training loss: 1.693991780281067
Validation loss: 2.098297429341142

Epoch: 162| Step: 0
Training loss: 0.9729577302932739
Validation loss: 2.069646473853819

Epoch: 6| Step: 1
Training loss: 2.025977611541748
Validation loss: 2.0692947603041127

Epoch: 6| Step: 2
Training loss: 2.232795000076294
Validation loss: 2.0589096187263407

Epoch: 6| Step: 3
Training loss: 2.110013723373413
Validation loss: 2.063987772951844

Epoch: 6| Step: 4
Training loss: 2.202310085296631
Validation loss: 2.057453302926915

Epoch: 6| Step: 5
Training loss: 1.330039620399475
Validation loss: 2.068879897876452

Epoch: 6| Step: 6
Training loss: 2.1748764514923096
Validation loss: 2.07301845858174

Epoch: 6| Step: 7
Training loss: 2.4001262187957764
Validation loss: 2.0871336306295087

Epoch: 6| Step: 8
Training loss: 1.8544708490371704
Validation loss: 2.106886605421702

Epoch: 6| Step: 9
Training loss: 1.3622843027114868
Validation loss: 2.1292929880080687

Epoch: 6| Step: 10
Training loss: 1.744767189025879
Validation loss: 2.142707263269732

Epoch: 6| Step: 11
Training loss: 2.3073153495788574
Validation loss: 2.108476984885431

Epoch: 6| Step: 12
Training loss: 2.3050179481506348
Validation loss: 2.0889427508077314

Epoch: 6| Step: 13
Training loss: 1.5803279876708984
Validation loss: 2.074224281054671

Epoch: 163| Step: 0
Training loss: 1.8176474571228027
Validation loss: 2.066822046874672

Epoch: 6| Step: 1
Training loss: 1.3301284313201904
Validation loss: 2.059315430220737

Epoch: 6| Step: 2
Training loss: 0.957179844379425
Validation loss: 2.055382679867488

Epoch: 6| Step: 3
Training loss: 2.202773094177246
Validation loss: 2.064527077059592

Epoch: 6| Step: 4
Training loss: 1.5310893058776855
Validation loss: 2.0795094992524836

Epoch: 6| Step: 5
Training loss: 2.158505439758301
Validation loss: 2.077898492095291

Epoch: 6| Step: 6
Training loss: 2.395646095275879
Validation loss: 2.0835774508855676

Epoch: 6| Step: 7
Training loss: 1.6522300243377686
Validation loss: 2.0861470058400142

Epoch: 6| Step: 8
Training loss: 1.8806737661361694
Validation loss: 2.0921127001444497

Epoch: 6| Step: 9
Training loss: 2.0264086723327637
Validation loss: 2.1009250712651077

Epoch: 6| Step: 10
Training loss: 2.494734287261963
Validation loss: 2.0846208654424196

Epoch: 6| Step: 11
Training loss: 2.077998161315918
Validation loss: 2.0827202668754

Epoch: 6| Step: 12
Training loss: 1.7975057363510132
Validation loss: 2.0808627977166125

Epoch: 6| Step: 13
Training loss: 2.5675323009490967
Validation loss: 2.074976364771525

Epoch: 164| Step: 0
Training loss: 2.0135557651519775
Validation loss: 2.0850489498466573

Epoch: 6| Step: 1
Training loss: 1.6764817237854004
Validation loss: 2.0789775374115154

Epoch: 6| Step: 2
Training loss: 2.236882209777832
Validation loss: 2.084961037481985

Epoch: 6| Step: 3
Training loss: 2.490351676940918
Validation loss: 2.110560558175528

Epoch: 6| Step: 4
Training loss: 1.7559025287628174
Validation loss: 2.111059183715492

Epoch: 6| Step: 5
Training loss: 1.4599504470825195
Validation loss: 2.1110682487487793

Epoch: 6| Step: 6
Training loss: 2.207368850708008
Validation loss: 2.10121440246541

Epoch: 6| Step: 7
Training loss: 1.649970531463623
Validation loss: 2.0928477215510544

Epoch: 6| Step: 8
Training loss: 2.422464370727539
Validation loss: 2.0924636240928405

Epoch: 6| Step: 9
Training loss: 1.7898234128952026
Validation loss: 2.069902834071908

Epoch: 6| Step: 10
Training loss: 1.4704097509384155
Validation loss: 2.073785910042383

Epoch: 6| Step: 11
Training loss: 1.7702805995941162
Validation loss: 2.064445530214617

Epoch: 6| Step: 12
Training loss: 1.5775309801101685
Validation loss: 2.0509274172526535

Epoch: 6| Step: 13
Training loss: 1.3409384489059448
Validation loss: 2.0284971011582242

Epoch: 165| Step: 0
Training loss: 1.5638046264648438
Validation loss: 2.046234812787784

Epoch: 6| Step: 1
Training loss: 1.6765379905700684
Validation loss: 2.0396641967117146

Epoch: 6| Step: 2
Training loss: 2.606128692626953
Validation loss: 2.0535159149477558

Epoch: 6| Step: 3
Training loss: 2.006120204925537
Validation loss: 2.0603573373568955

Epoch: 6| Step: 4
Training loss: 1.7521371841430664
Validation loss: 2.065766954934725

Epoch: 6| Step: 5
Training loss: 2.2576780319213867
Validation loss: 2.083318225799068

Epoch: 6| Step: 6
Training loss: 1.70156991481781
Validation loss: 2.083038863315377

Epoch: 6| Step: 7
Training loss: 1.645383358001709
Validation loss: 2.0637350659216604

Epoch: 6| Step: 8
Training loss: 1.706794023513794
Validation loss: 2.0869895424894107

Epoch: 6| Step: 9
Training loss: 2.0397064685821533
Validation loss: 2.094680905342102

Epoch: 6| Step: 10
Training loss: 1.3672282695770264
Validation loss: 2.084225828929614

Epoch: 6| Step: 11
Training loss: 2.0813658237457275
Validation loss: 2.0929996608405985

Epoch: 6| Step: 12
Training loss: 1.7811623811721802
Validation loss: 2.0796751950376775

Epoch: 6| Step: 13
Training loss: 1.85770845413208
Validation loss: 2.085771702951001

Epoch: 166| Step: 0
Training loss: 1.1921852827072144
Validation loss: 2.0714774349684357

Epoch: 6| Step: 1
Training loss: 2.0735042095184326
Validation loss: 2.0521871171971804

Epoch: 6| Step: 2
Training loss: 1.8342459201812744
Validation loss: 2.0607584740525935

Epoch: 6| Step: 3
Training loss: 2.143200635910034
Validation loss: 2.0440469480329946

Epoch: 6| Step: 4
Training loss: 2.1435306072235107
Validation loss: 2.050766298847814

Epoch: 6| Step: 5
Training loss: 1.6741266250610352
Validation loss: 2.0562864695825884

Epoch: 6| Step: 6
Training loss: 1.372310996055603
Validation loss: 2.02787317896402

Epoch: 6| Step: 7
Training loss: 2.098851442337036
Validation loss: 2.0531953586045133

Epoch: 6| Step: 8
Training loss: 1.2701330184936523
Validation loss: 2.0376044883522937

Epoch: 6| Step: 9
Training loss: 2.272092580795288
Validation loss: 2.0468325435474353

Epoch: 6| Step: 10
Training loss: 1.3093743324279785
Validation loss: 2.061756213506063

Epoch: 6| Step: 11
Training loss: 2.230900287628174
Validation loss: 2.082553594343124

Epoch: 6| Step: 12
Training loss: 2.210815906524658
Validation loss: 2.083555430494329

Epoch: 6| Step: 13
Training loss: 2.0907785892486572
Validation loss: 2.093748405415525

Epoch: 167| Step: 0
Training loss: 1.7431259155273438
Validation loss: 2.1099468072255454

Epoch: 6| Step: 1
Training loss: 1.7137099504470825
Validation loss: 2.12920707015581

Epoch: 6| Step: 2
Training loss: 1.5576016902923584
Validation loss: 2.1310768486351095

Epoch: 6| Step: 3
Training loss: 1.4958893060684204
Validation loss: 2.131756983777528

Epoch: 6| Step: 4
Training loss: 1.9062104225158691
Validation loss: 2.1214915001264183

Epoch: 6| Step: 5
Training loss: 1.6354968547821045
Validation loss: 2.1289382391078497

Epoch: 6| Step: 6
Training loss: 2.3102426528930664
Validation loss: 2.110728448437106

Epoch: 6| Step: 7
Training loss: 2.300600528717041
Validation loss: 2.093408097503006

Epoch: 6| Step: 8
Training loss: 1.9739408493041992
Validation loss: 2.08348495985872

Epoch: 6| Step: 9
Training loss: 1.6232082843780518
Validation loss: 2.0863029392816688

Epoch: 6| Step: 10
Training loss: 1.680485725402832
Validation loss: 2.057761674286217

Epoch: 6| Step: 11
Training loss: 1.8555686473846436
Validation loss: 2.065212265137703

Epoch: 6| Step: 12
Training loss: 2.759185314178467
Validation loss: 2.061283790937034

Epoch: 6| Step: 13
Training loss: 0.82917720079422
Validation loss: 2.0400048071338284

Epoch: 168| Step: 0
Training loss: 2.345153331756592
Validation loss: 2.0376012479105303

Epoch: 6| Step: 1
Training loss: 1.8667523860931396
Validation loss: 2.0367671635843094

Epoch: 6| Step: 2
Training loss: 1.833920955657959
Validation loss: 2.0630690731028074

Epoch: 6| Step: 3
Training loss: 1.8158016204833984
Validation loss: 2.062750575362995

Epoch: 6| Step: 4
Training loss: 1.63334059715271
Validation loss: 2.0666952184451524

Epoch: 6| Step: 5
Training loss: 2.0489535331726074
Validation loss: 2.078542478622929

Epoch: 6| Step: 6
Training loss: 1.5016200542449951
Validation loss: 2.089026233201386

Epoch: 6| Step: 7
Training loss: 2.0328145027160645
Validation loss: 2.0806323969235985

Epoch: 6| Step: 8
Training loss: 2.2819433212280273
Validation loss: 2.103885322488764

Epoch: 6| Step: 9
Training loss: 1.4294607639312744
Validation loss: 2.0713725974482875

Epoch: 6| Step: 10
Training loss: 2.246062755584717
Validation loss: 2.0962667926665275

Epoch: 6| Step: 11
Training loss: 1.8139700889587402
Validation loss: 2.074822010532502

Epoch: 6| Step: 12
Training loss: 1.4666366577148438
Validation loss: 2.094693504354005

Epoch: 6| Step: 13
Training loss: 1.2284284830093384
Validation loss: 2.102693227029616

Epoch: 169| Step: 0
Training loss: 1.9013645648956299
Validation loss: 2.0744528603810135

Epoch: 6| Step: 1
Training loss: 1.7622994184494019
Validation loss: 2.078641745351976

Epoch: 6| Step: 2
Training loss: 2.454603910446167
Validation loss: 2.0951474482013333

Epoch: 6| Step: 3
Training loss: 1.5142509937286377
Validation loss: 2.106393914068899

Epoch: 6| Step: 4
Training loss: 1.8395906686782837
Validation loss: 2.098197962648125

Epoch: 6| Step: 5
Training loss: 1.3131964206695557
Validation loss: 2.0568731651511243

Epoch: 6| Step: 6
Training loss: 1.5894691944122314
Validation loss: 2.0491114636903167

Epoch: 6| Step: 7
Training loss: 2.109531879425049
Validation loss: 2.0437261648075555

Epoch: 6| Step: 8
Training loss: 1.9456878900527954
Validation loss: 2.025095473053635

Epoch: 6| Step: 9
Training loss: 1.8399070501327515
Validation loss: 2.015032381139776

Epoch: 6| Step: 10
Training loss: 1.892701268196106
Validation loss: 2.011171817779541

Epoch: 6| Step: 11
Training loss: 1.6459143161773682
Validation loss: 2.020094420320244

Epoch: 6| Step: 12
Training loss: 1.940138578414917
Validation loss: 2.0366388213249946

Epoch: 6| Step: 13
Training loss: 2.0371978282928467
Validation loss: 2.039733220172185

Epoch: 170| Step: 0
Training loss: 1.4487029314041138
Validation loss: 2.0519353881958993

Epoch: 6| Step: 1
Training loss: 2.378047227859497
Validation loss: 2.0524018836277786

Epoch: 6| Step: 2
Training loss: 1.573655605316162
Validation loss: 2.0452352300766976

Epoch: 6| Step: 3
Training loss: 1.7794737815856934
Validation loss: 2.0495336465938117

Epoch: 6| Step: 4
Training loss: 1.9371085166931152
Validation loss: 2.0527132095829135

Epoch: 6| Step: 5
Training loss: 2.3507885932922363
Validation loss: 2.0681128001982167

Epoch: 6| Step: 6
Training loss: 1.7417781352996826
Validation loss: 2.0788502872631116

Epoch: 6| Step: 7
Training loss: 1.0344128608703613
Validation loss: 2.0763637481197232

Epoch: 6| Step: 8
Training loss: 1.4724558591842651
Validation loss: 2.093928555006622

Epoch: 6| Step: 9
Training loss: 2.0224809646606445
Validation loss: 2.115399049174401

Epoch: 6| Step: 10
Training loss: 2.1157031059265137
Validation loss: 2.1050540452362387

Epoch: 6| Step: 11
Training loss: 2.2954158782958984
Validation loss: 2.085962680078322

Epoch: 6| Step: 12
Training loss: 1.5505731105804443
Validation loss: 2.0807456534395934

Epoch: 6| Step: 13
Training loss: 1.7770075798034668
Validation loss: 2.0588536775240334

Epoch: 171| Step: 0
Training loss: 1.341388463973999
Validation loss: 2.0524784031734673

Epoch: 6| Step: 1
Training loss: 2.094834327697754
Validation loss: 2.047228132524798

Epoch: 6| Step: 2
Training loss: 2.1100027561187744
Validation loss: 2.0396953218726703

Epoch: 6| Step: 3
Training loss: 1.5696370601654053
Validation loss: 2.0455072567027104

Epoch: 6| Step: 4
Training loss: 2.0787289142608643
Validation loss: 2.043144596520291

Epoch: 6| Step: 5
Training loss: 1.8894025087356567
Validation loss: 2.0566726551261

Epoch: 6| Step: 6
Training loss: 2.3025968074798584
Validation loss: 2.048838782054122

Epoch: 6| Step: 7
Training loss: 1.9000396728515625
Validation loss: 2.0784302296177035

Epoch: 6| Step: 8
Training loss: 1.8934013843536377
Validation loss: 2.073879116324968

Epoch: 6| Step: 9
Training loss: 2.0741467475891113
Validation loss: 2.052231378452752

Epoch: 6| Step: 10
Training loss: 1.4471145868301392
Validation loss: 2.0424321056694112

Epoch: 6| Step: 11
Training loss: 1.7703189849853516
Validation loss: 2.059126694997152

Epoch: 6| Step: 12
Training loss: 1.6347839832305908
Validation loss: 2.0468049959469865

Epoch: 6| Step: 13
Training loss: 0.8212243318557739
Validation loss: 2.052173040246451

Epoch: 172| Step: 0
Training loss: 2.006575584411621
Validation loss: 2.089683102023217

Epoch: 6| Step: 1
Training loss: 1.6986069679260254
Validation loss: 2.1228805331773657

Epoch: 6| Step: 2
Training loss: 2.2673234939575195
Validation loss: 2.1698906934389504

Epoch: 6| Step: 3
Training loss: 2.242748737335205
Validation loss: 2.178366081688994

Epoch: 6| Step: 4
Training loss: 1.691998839378357
Validation loss: 2.218934584689397

Epoch: 6| Step: 5
Training loss: 1.823503017425537
Validation loss: 2.18202051039665

Epoch: 6| Step: 6
Training loss: 1.6495165824890137
Validation loss: 2.1274137830221527

Epoch: 6| Step: 7
Training loss: 1.78913414478302
Validation loss: 2.1098044841520247

Epoch: 6| Step: 8
Training loss: 1.3195679187774658
Validation loss: 2.075040332732662

Epoch: 6| Step: 9
Training loss: 2.3519532680511475
Validation loss: 2.0608682529900664

Epoch: 6| Step: 10
Training loss: 1.509840488433838
Validation loss: 2.050367101546257

Epoch: 6| Step: 11
Training loss: 1.8039122819900513
Validation loss: 2.0404641038628033

Epoch: 6| Step: 12
Training loss: 1.6372315883636475
Validation loss: 2.0364560798932145

Epoch: 6| Step: 13
Training loss: 2.351898670196533
Validation loss: 2.0220235188802085

Epoch: 173| Step: 0
Training loss: 1.6814675331115723
Validation loss: 2.038262269830191

Epoch: 6| Step: 1
Training loss: 1.9382535219192505
Validation loss: 2.0530818457244546

Epoch: 6| Step: 2
Training loss: 1.8025059700012207
Validation loss: 2.0876926888701735

Epoch: 6| Step: 3
Training loss: 1.5899176597595215
Validation loss: 2.0807119082379084

Epoch: 6| Step: 4
Training loss: 1.4963324069976807
Validation loss: 2.051200553935061

Epoch: 6| Step: 5
Training loss: 1.7555415630340576
Validation loss: 2.0549665010103615

Epoch: 6| Step: 6
Training loss: 2.258453369140625
Validation loss: 2.0306871693621398

Epoch: 6| Step: 7
Training loss: 2.0455832481384277
Validation loss: 2.051119558272823

Epoch: 6| Step: 8
Training loss: 1.7048389911651611
Validation loss: 2.030800016977454

Epoch: 6| Step: 9
Training loss: 1.4595308303833008
Validation loss: 2.049264392545146

Epoch: 6| Step: 10
Training loss: 1.5039691925048828
Validation loss: 2.07846761262545

Epoch: 6| Step: 11
Training loss: 1.9184257984161377
Validation loss: 2.097359324014315

Epoch: 6| Step: 12
Training loss: 2.540203094482422
Validation loss: 2.1349533386127924

Epoch: 6| Step: 13
Training loss: 2.021470069885254
Validation loss: 2.134824260588615

Epoch: 174| Step: 0
Training loss: 1.542593240737915
Validation loss: 2.137333026496313

Epoch: 6| Step: 1
Training loss: 1.7198113203048706
Validation loss: 2.111302339902488

Epoch: 6| Step: 2
Training loss: 1.5091571807861328
Validation loss: 2.064958433951101

Epoch: 6| Step: 3
Training loss: 1.7371572256088257
Validation loss: 2.025297482808431

Epoch: 6| Step: 4
Training loss: 1.35985267162323
Validation loss: 2.033306262826407

Epoch: 6| Step: 5
Training loss: 2.0905838012695312
Validation loss: 2.0048747267774356

Epoch: 6| Step: 6
Training loss: 2.2244508266448975
Validation loss: 2.0212959345950874

Epoch: 6| Step: 7
Training loss: 1.7401936054229736
Validation loss: 2.010548045558314

Epoch: 6| Step: 8
Training loss: 2.015101194381714
Validation loss: 2.021301382331438

Epoch: 6| Step: 9
Training loss: 1.5371830463409424
Validation loss: 2.0423360396456975

Epoch: 6| Step: 10
Training loss: 2.0588581562042236
Validation loss: 2.097483581112277

Epoch: 6| Step: 11
Training loss: 1.9381589889526367
Validation loss: 2.1016205433876283

Epoch: 6| Step: 12
Training loss: 2.188930034637451
Validation loss: 2.0863102636029645

Epoch: 6| Step: 13
Training loss: 1.9416574239730835
Validation loss: 2.0624927807879705

Epoch: 175| Step: 0
Training loss: 2.2814249992370605
Validation loss: 2.042009480537907

Epoch: 6| Step: 1
Training loss: 2.239772319793701
Validation loss: 2.0258384622553343

Epoch: 6| Step: 2
Training loss: 2.1109797954559326
Validation loss: 2.0277251710173902

Epoch: 6| Step: 3
Training loss: 1.4115777015686035
Validation loss: 2.0293301138826596

Epoch: 6| Step: 4
Training loss: 2.0876779556274414
Validation loss: 2.0458980478266233

Epoch: 6| Step: 5
Training loss: 1.6605136394500732
Validation loss: 2.058575217441846

Epoch: 6| Step: 6
Training loss: 2.148575782775879
Validation loss: 2.0792604620738695

Epoch: 6| Step: 7
Training loss: 1.8041232824325562
Validation loss: 2.0889344100029237

Epoch: 6| Step: 8
Training loss: 1.3677337169647217
Validation loss: 2.109063374098911

Epoch: 6| Step: 9
Training loss: 2.3645052909851074
Validation loss: 2.132626978299951

Epoch: 6| Step: 10
Training loss: 1.6215295791625977
Validation loss: 2.1050343013578847

Epoch: 6| Step: 11
Training loss: 0.9485296607017517
Validation loss: 2.1073205932494132

Epoch: 6| Step: 12
Training loss: 1.1658684015274048
Validation loss: 2.0684769730414114

Epoch: 6| Step: 13
Training loss: 1.984438419342041
Validation loss: 2.0496407657541256

Epoch: 176| Step: 0
Training loss: 1.5395326614379883
Validation loss: 2.038623079176872

Epoch: 6| Step: 1
Training loss: 1.905095100402832
Validation loss: 2.034793520486483

Epoch: 6| Step: 2
Training loss: 1.744800329208374
Validation loss: 2.0220274540685836

Epoch: 6| Step: 3
Training loss: 1.9367260932922363
Validation loss: 2.0174340971054567

Epoch: 6| Step: 4
Training loss: 1.6667391061782837
Validation loss: 2.0131507522316388

Epoch: 6| Step: 5
Training loss: 1.48319411277771
Validation loss: 2.0346391739383822

Epoch: 6| Step: 6
Training loss: 1.6267082691192627
Validation loss: 2.041015778818438

Epoch: 6| Step: 7
Training loss: 2.1764187812805176
Validation loss: 2.060058396349671

Epoch: 6| Step: 8
Training loss: 1.3167948722839355
Validation loss: 2.0611265654204995

Epoch: 6| Step: 9
Training loss: 1.650393009185791
Validation loss: 2.0423068538788827

Epoch: 6| Step: 10
Training loss: 2.4756786823272705
Validation loss: 2.045872152492564

Epoch: 6| Step: 11
Training loss: 2.017090320587158
Validation loss: 2.0157979803700603

Epoch: 6| Step: 12
Training loss: 1.6630103588104248
Validation loss: 2.0233190085298274

Epoch: 6| Step: 13
Training loss: 1.760286569595337
Validation loss: 2.019876500611664

Epoch: 177| Step: 0
Training loss: 1.3398382663726807
Validation loss: 2.014611715911537

Epoch: 6| Step: 1
Training loss: 1.407168984413147
Validation loss: 2.011166916098646

Epoch: 6| Step: 2
Training loss: 1.4262794256210327
Validation loss: 2.00949498017629

Epoch: 6| Step: 3
Training loss: 2.04451322555542
Validation loss: 2.012602657400152

Epoch: 6| Step: 4
Training loss: 1.6846016645431519
Validation loss: 2.0199060029880975

Epoch: 6| Step: 5
Training loss: 1.2643591165542603
Validation loss: 2.03416153436066

Epoch: 6| Step: 6
Training loss: 1.5165891647338867
Validation loss: 2.0567112109994374

Epoch: 6| Step: 7
Training loss: 1.6975417137145996
Validation loss: 2.0919491424355456

Epoch: 6| Step: 8
Training loss: 1.8438163995742798
Validation loss: 2.0927743757924726

Epoch: 6| Step: 9
Training loss: 2.4441609382629395
Validation loss: 2.1092147545147966

Epoch: 6| Step: 10
Training loss: 2.1774420738220215
Validation loss: 2.095663975643855

Epoch: 6| Step: 11
Training loss: 1.833677053451538
Validation loss: 2.056720874642813

Epoch: 6| Step: 12
Training loss: 1.8805975914001465
Validation loss: 2.05243533144715

Epoch: 6| Step: 13
Training loss: 2.6050498485565186
Validation loss: 2.0427256322676137

Epoch: 178| Step: 0
Training loss: 2.099303722381592
Validation loss: 2.039233051320558

Epoch: 6| Step: 1
Training loss: 1.84780752658844
Validation loss: 2.0241699475114063

Epoch: 6| Step: 2
Training loss: 1.9336011409759521
Validation loss: 2.036965897006373

Epoch: 6| Step: 3
Training loss: 1.9741458892822266
Validation loss: 2.048223962065994

Epoch: 6| Step: 4
Training loss: 1.7901912927627563
Validation loss: 2.059748895706669

Epoch: 6| Step: 5
Training loss: 1.3230235576629639
Validation loss: 2.0874248166238107

Epoch: 6| Step: 6
Training loss: 1.944368600845337
Validation loss: 2.1182280202065744

Epoch: 6| Step: 7
Training loss: 1.4994549751281738
Validation loss: 2.1035427931816346

Epoch: 6| Step: 8
Training loss: 1.6621372699737549
Validation loss: 2.100590549489503

Epoch: 6| Step: 9
Training loss: 1.8670873641967773
Validation loss: 2.0782816128064225

Epoch: 6| Step: 10
Training loss: 1.5732488632202148
Validation loss: 2.0531464263957035

Epoch: 6| Step: 11
Training loss: 1.9569411277770996
Validation loss: 2.0327853079765075

Epoch: 6| Step: 12
Training loss: 1.9403616189956665
Validation loss: 2.028823935857383

Epoch: 6| Step: 13
Training loss: 1.1222920417785645
Validation loss: 2.0198258379454255

Epoch: 179| Step: 0
Training loss: 1.844973087310791
Validation loss: 2.020934993220914

Epoch: 6| Step: 1
Training loss: 1.6464886665344238
Validation loss: 2.0007773599317

Epoch: 6| Step: 2
Training loss: 1.0506964921951294
Validation loss: 2.003606419409475

Epoch: 6| Step: 3
Training loss: 1.3414666652679443
Validation loss: 2.0016050492563555

Epoch: 6| Step: 4
Training loss: 1.6995079517364502
Validation loss: 2.0164372382625455

Epoch: 6| Step: 5
Training loss: 2.321636438369751
Validation loss: 2.0395258882994294

Epoch: 6| Step: 6
Training loss: 2.063241481781006
Validation loss: 2.0582567645657446

Epoch: 6| Step: 7
Training loss: 1.990865707397461
Validation loss: 2.073305232550508

Epoch: 6| Step: 8
Training loss: 1.833207368850708
Validation loss: 2.105953031970609

Epoch: 6| Step: 9
Training loss: 1.4198558330535889
Validation loss: 2.1049285409271077

Epoch: 6| Step: 10
Training loss: 2.1442341804504395
Validation loss: 2.0782853787945164

Epoch: 6| Step: 11
Training loss: 1.41183602809906
Validation loss: 2.044759110737872

Epoch: 6| Step: 12
Training loss: 1.7822309732437134
Validation loss: 2.0406355524575837

Epoch: 6| Step: 13
Training loss: 3.021439790725708
Validation loss: 2.054500518306609

Epoch: 180| Step: 0
Training loss: 2.272515058517456
Validation loss: 2.0603609033810195

Epoch: 6| Step: 1
Training loss: 1.6261324882507324
Validation loss: 2.0554099159856

Epoch: 6| Step: 2
Training loss: 1.6420038938522339
Validation loss: 2.0283682077161727

Epoch: 6| Step: 3
Training loss: 0.9385110139846802
Validation loss: 2.0406637935228247

Epoch: 6| Step: 4
Training loss: 2.0152480602264404
Validation loss: 2.035549748328424

Epoch: 6| Step: 5
Training loss: 1.316603422164917
Validation loss: 2.0779372902326685

Epoch: 6| Step: 6
Training loss: 2.3092589378356934
Validation loss: 2.12139537513897

Epoch: 6| Step: 7
Training loss: 1.5074026584625244
Validation loss: 2.17259576243739

Epoch: 6| Step: 8
Training loss: 1.5745943784713745
Validation loss: 2.224087421612073

Epoch: 6| Step: 9
Training loss: 1.4813512563705444
Validation loss: 2.2263505638286634

Epoch: 6| Step: 10
Training loss: 2.534440040588379
Validation loss: 2.190239352564658

Epoch: 6| Step: 11
Training loss: 2.174820899963379
Validation loss: 2.140292870101108

Epoch: 6| Step: 12
Training loss: 2.1399571895599365
Validation loss: 2.064040186584637

Epoch: 6| Step: 13
Training loss: 1.7455660104751587
Validation loss: 2.0390555961157686

Epoch: 181| Step: 0
Training loss: 1.8319746255874634
Validation loss: 2.06603713445766

Epoch: 6| Step: 1
Training loss: 2.4610795974731445
Validation loss: 2.0838659745390697

Epoch: 6| Step: 2
Training loss: 2.4566469192504883
Validation loss: 2.074309077314151

Epoch: 6| Step: 3
Training loss: 2.115971565246582
Validation loss: 2.0674143696344025

Epoch: 6| Step: 4
Training loss: 1.5786570310592651
Validation loss: 2.045080707919213

Epoch: 6| Step: 5
Training loss: 1.0854756832122803
Validation loss: 2.027104849456459

Epoch: 6| Step: 6
Training loss: 1.5900440216064453
Validation loss: 2.005391579802318

Epoch: 6| Step: 7
Training loss: 2.4535415172576904
Validation loss: 2.0335626140717538

Epoch: 6| Step: 8
Training loss: 1.912125587463379
Validation loss: 2.101690947368581

Epoch: 6| Step: 9
Training loss: 1.1985664367675781
Validation loss: 2.1388413675369753

Epoch: 6| Step: 10
Training loss: 1.5643383264541626
Validation loss: 2.169573886420137

Epoch: 6| Step: 11
Training loss: 1.4067952632904053
Validation loss: 2.1843720892424225

Epoch: 6| Step: 12
Training loss: 1.9463399648666382
Validation loss: 2.1835874511349584

Epoch: 6| Step: 13
Training loss: 2.2165310382843018
Validation loss: 2.1540998951081307

Epoch: 182| Step: 0
Training loss: 1.8471713066101074
Validation loss: 2.0872921200208765

Epoch: 6| Step: 1
Training loss: 1.364830493927002
Validation loss: 2.045837034461319

Epoch: 6| Step: 2
Training loss: 2.465956687927246
Validation loss: 2.037181151810513

Epoch: 6| Step: 3
Training loss: 1.7561829090118408
Validation loss: 2.0481448506796234

Epoch: 6| Step: 4
Training loss: 1.5876365900039673
Validation loss: 2.0361120598290556

Epoch: 6| Step: 5
Training loss: 1.7058157920837402
Validation loss: 2.0170810273898545

Epoch: 6| Step: 6
Training loss: 1.7796950340270996
Validation loss: 2.0057765976075204

Epoch: 6| Step: 7
Training loss: 2.3470711708068848
Validation loss: 1.9960612507276638

Epoch: 6| Step: 8
Training loss: 1.4563040733337402
Validation loss: 1.9913963233270953

Epoch: 6| Step: 9
Training loss: 1.9995585680007935
Validation loss: 1.9935188037092968

Epoch: 6| Step: 10
Training loss: 1.8276766538619995
Validation loss: 2.0177337405502156

Epoch: 6| Step: 11
Training loss: 0.9724249839782715
Validation loss: 2.0299793622827016

Epoch: 6| Step: 12
Training loss: 1.6790003776550293
Validation loss: 2.053125391724289

Epoch: 6| Step: 13
Training loss: 2.181694746017456
Validation loss: 2.061262135864586

Epoch: 183| Step: 0
Training loss: 1.7812350988388062
Validation loss: 2.05629881992135

Epoch: 6| Step: 1
Training loss: 1.674912691116333
Validation loss: 2.0616287364754626

Epoch: 6| Step: 2
Training loss: 1.9644170999526978
Validation loss: 2.0520636599550963

Epoch: 6| Step: 3
Training loss: 1.961027979850769
Validation loss: 2.019120820106999

Epoch: 6| Step: 4
Training loss: 1.9711365699768066
Validation loss: 2.02952056290001

Epoch: 6| Step: 5
Training loss: 1.4267908334732056
Validation loss: 1.9950281612334713

Epoch: 6| Step: 6
Training loss: 1.3197987079620361
Validation loss: 1.9943734471515944

Epoch: 6| Step: 7
Training loss: 1.8431450128555298
Validation loss: 2.0181121031443277

Epoch: 6| Step: 8
Training loss: 1.9149553775787354
Validation loss: 2.015752115557271

Epoch: 6| Step: 9
Training loss: 1.9266128540039062
Validation loss: 2.0124550096450315

Epoch: 6| Step: 10
Training loss: 1.0433523654937744
Validation loss: 2.0117513389997583

Epoch: 6| Step: 11
Training loss: 1.5923213958740234
Validation loss: 2.0207945967233307

Epoch: 6| Step: 12
Training loss: 1.9428865909576416
Validation loss: 2.062281826490997

Epoch: 6| Step: 13
Training loss: 2.4522180557250977
Validation loss: 2.1026444460756037

Epoch: 184| Step: 0
Training loss: 1.9090337753295898
Validation loss: 2.1598001910794165

Epoch: 6| Step: 1
Training loss: 2.3889360427856445
Validation loss: 2.1625626369189193

Epoch: 6| Step: 2
Training loss: 2.012178897857666
Validation loss: 2.1570114525415565

Epoch: 6| Step: 3
Training loss: 1.428765058517456
Validation loss: 2.1102348809601157

Epoch: 6| Step: 4
Training loss: 1.882293701171875
Validation loss: 2.098542110894316

Epoch: 6| Step: 5
Training loss: 2.205587148666382
Validation loss: 2.036917991535638

Epoch: 6| Step: 6
Training loss: 1.4016449451446533
Validation loss: 2.031889623211276

Epoch: 6| Step: 7
Training loss: 2.0487256050109863
Validation loss: 2.029162383848621

Epoch: 6| Step: 8
Training loss: 1.9791629314422607
Validation loss: 2.0516036325885403

Epoch: 6| Step: 9
Training loss: 1.4630475044250488
Validation loss: 2.036965080486831

Epoch: 6| Step: 10
Training loss: 1.7932859659194946
Validation loss: 2.042750491890856

Epoch: 6| Step: 11
Training loss: 1.4262197017669678
Validation loss: 2.009602177527643

Epoch: 6| Step: 12
Training loss: 2.0665950775146484
Validation loss: 2.0237612109030447

Epoch: 6| Step: 13
Training loss: 1.193748950958252
Validation loss: 2.0354638227852444

Epoch: 185| Step: 0
Training loss: 1.3908636569976807
Validation loss: 2.0964088593759844

Epoch: 6| Step: 1
Training loss: 2.005014181137085
Validation loss: 2.126825265986945

Epoch: 6| Step: 2
Training loss: 0.9923099279403687
Validation loss: 2.1485335929419405

Epoch: 6| Step: 3
Training loss: 1.40584397315979
Validation loss: 2.149951897641664

Epoch: 6| Step: 4
Training loss: 1.2628958225250244
Validation loss: 2.1544966505419825

Epoch: 6| Step: 5
Training loss: 1.6852649450302124
Validation loss: 2.1574732718929166

Epoch: 6| Step: 6
Training loss: 1.4773083925247192
Validation loss: 2.136857881340929

Epoch: 6| Step: 7
Training loss: 2.1846752166748047
Validation loss: 2.0956404824410715

Epoch: 6| Step: 8
Training loss: 1.6312443017959595
Validation loss: 2.0491943026101715

Epoch: 6| Step: 9
Training loss: 2.395198345184326
Validation loss: 2.0163580781670025

Epoch: 6| Step: 10
Training loss: 2.1296541690826416
Validation loss: 2.0037902555158063

Epoch: 6| Step: 11
Training loss: 2.2695584297180176
Validation loss: 1.9979320482541156

Epoch: 6| Step: 12
Training loss: 1.947239875793457
Validation loss: 1.977749664296386

Epoch: 6| Step: 13
Training loss: 2.1112287044525146
Validation loss: 1.9573031445985198

Epoch: 186| Step: 0
Training loss: 1.9086519479751587
Validation loss: 1.9665246138008692

Epoch: 6| Step: 1
Training loss: 1.539778709411621
Validation loss: 1.9531015426881853

Epoch: 6| Step: 2
Training loss: 1.389784336090088
Validation loss: 1.954519348759805

Epoch: 6| Step: 3
Training loss: 1.5336500406265259
Validation loss: 1.9667459687879008

Epoch: 6| Step: 4
Training loss: 1.4078277349472046
Validation loss: 1.9797234586490098

Epoch: 6| Step: 5
Training loss: 2.1123735904693604
Validation loss: 2.0126864346124793

Epoch: 6| Step: 6
Training loss: 2.4110803604125977
Validation loss: 2.0337082070689045

Epoch: 6| Step: 7
Training loss: 1.5957190990447998
Validation loss: 2.0414664001875025

Epoch: 6| Step: 8
Training loss: 1.1780977249145508
Validation loss: 2.0429558959058536

Epoch: 6| Step: 9
Training loss: 1.7050466537475586
Validation loss: 2.030832529067993

Epoch: 6| Step: 10
Training loss: 2.200716495513916
Validation loss: 2.00506256985408

Epoch: 6| Step: 11
Training loss: 1.9407687187194824
Validation loss: 2.005359779122055

Epoch: 6| Step: 12
Training loss: 2.353015422821045
Validation loss: 1.9851770465091994

Epoch: 6| Step: 13
Training loss: 1.1734744310379028
Validation loss: 1.981629107588081

Epoch: 187| Step: 0
Training loss: 1.5872526168823242
Validation loss: 2.0032138837281095

Epoch: 6| Step: 1
Training loss: 1.3181157112121582
Validation loss: 1.9898880912411598

Epoch: 6| Step: 2
Training loss: 2.4328768253326416
Validation loss: 1.9933480447338474

Epoch: 6| Step: 3
Training loss: 2.442112445831299
Validation loss: 2.0034290923867175

Epoch: 6| Step: 4
Training loss: 1.5761845111846924
Validation loss: 2.030170588083165

Epoch: 6| Step: 5
Training loss: 2.1624460220336914
Validation loss: 2.0312939049095236

Epoch: 6| Step: 6
Training loss: 2.30009126663208
Validation loss: 2.0423352615807646

Epoch: 6| Step: 7
Training loss: 1.3568370342254639
Validation loss: 2.0627156380684144

Epoch: 6| Step: 8
Training loss: 1.2243690490722656
Validation loss: 2.062020994001819

Epoch: 6| Step: 9
Training loss: 1.466813087463379
Validation loss: 2.0512530816498624

Epoch: 6| Step: 10
Training loss: 1.1406062841415405
Validation loss: 2.061234927946521

Epoch: 6| Step: 11
Training loss: 1.7834351062774658
Validation loss: 2.0396893896082395

Epoch: 6| Step: 12
Training loss: 1.6792925596237183
Validation loss: 2.0270559992841495

Epoch: 6| Step: 13
Training loss: 1.1862462759017944
Validation loss: 2.0064990289749636

Epoch: 188| Step: 0
Training loss: 1.5576303005218506
Validation loss: 2.0112026481218237

Epoch: 6| Step: 1
Training loss: 1.484236478805542
Validation loss: 2.009719062876958

Epoch: 6| Step: 2
Training loss: 1.5932928323745728
Validation loss: 2.012280551336145

Epoch: 6| Step: 3
Training loss: 1.5032777786254883
Validation loss: 2.031024673933624

Epoch: 6| Step: 4
Training loss: 1.8761787414550781
Validation loss: 2.0394286622283277

Epoch: 6| Step: 5
Training loss: 1.7581408023834229
Validation loss: 2.0276837707847677

Epoch: 6| Step: 6
Training loss: 0.7372862100601196
Validation loss: 2.0269278582706245

Epoch: 6| Step: 7
Training loss: 1.1641769409179688
Validation loss: 2.0066853107944613

Epoch: 6| Step: 8
Training loss: 2.325173854827881
Validation loss: 2.004747772729525

Epoch: 6| Step: 9
Training loss: 1.724293828010559
Validation loss: 1.996004166141633

Epoch: 6| Step: 10
Training loss: 1.7274636030197144
Validation loss: 1.9934401332691152

Epoch: 6| Step: 11
Training loss: 2.3472437858581543
Validation loss: 1.9993403855190481

Epoch: 6| Step: 12
Training loss: 2.0954999923706055
Validation loss: 1.9982734982685377

Epoch: 6| Step: 13
Training loss: 1.7756543159484863
Validation loss: 1.998687751831547

Epoch: 189| Step: 0
Training loss: 1.0435482263565063
Validation loss: 2.024460618213941

Epoch: 6| Step: 1
Training loss: 1.4878991842269897
Validation loss: 2.0171658146765923

Epoch: 6| Step: 2
Training loss: 2.409183979034424
Validation loss: 2.0346757288902038

Epoch: 6| Step: 3
Training loss: 0.9275415539741516
Validation loss: 2.079164925441947

Epoch: 6| Step: 4
Training loss: 2.399428367614746
Validation loss: 2.0847766989020893

Epoch: 6| Step: 5
Training loss: 2.5213396549224854
Validation loss: 2.1089096094972346

Epoch: 6| Step: 6
Training loss: 2.0109200477600098
Validation loss: 2.115982637610487

Epoch: 6| Step: 7
Training loss: 1.5064821243286133
Validation loss: 2.104963401312469

Epoch: 6| Step: 8
Training loss: 1.330332636833191
Validation loss: 2.0946657529441257

Epoch: 6| Step: 9
Training loss: 2.154144048690796
Validation loss: 2.065320640481928

Epoch: 6| Step: 10
Training loss: 1.449368953704834
Validation loss: 2.0570628745581514

Epoch: 6| Step: 11
Training loss: 1.2659755945205688
Validation loss: 2.057469365417316

Epoch: 6| Step: 12
Training loss: 1.5934374332427979
Validation loss: 2.029162350521293

Epoch: 6| Step: 13
Training loss: 1.565854549407959
Validation loss: 2.0221347975474533

Epoch: 190| Step: 0
Training loss: 1.6874699592590332
Validation loss: 2.014637016480969

Epoch: 6| Step: 1
Training loss: 2.1018199920654297
Validation loss: 1.988983695225049

Epoch: 6| Step: 2
Training loss: 1.1422104835510254
Validation loss: 1.9727048104809177

Epoch: 6| Step: 3
Training loss: 2.378826856613159
Validation loss: 1.968939301788166

Epoch: 6| Step: 4
Training loss: 1.3437162637710571
Validation loss: 1.9772034024679532

Epoch: 6| Step: 5
Training loss: 1.59047269821167
Validation loss: 1.9693098888602307

Epoch: 6| Step: 6
Training loss: 1.4198460578918457
Validation loss: 1.9878963270495016

Epoch: 6| Step: 7
Training loss: 1.9633558988571167
Validation loss: 1.9738766685608895

Epoch: 6| Step: 8
Training loss: 0.9586209654808044
Validation loss: 1.98754915114372

Epoch: 6| Step: 9
Training loss: 1.7296671867370605
Validation loss: 2.014791488647461

Epoch: 6| Step: 10
Training loss: 1.2896215915679932
Validation loss: 2.00237746648891

Epoch: 6| Step: 11
Training loss: 2.225562572479248
Validation loss: 2.021219450940368

Epoch: 6| Step: 12
Training loss: 2.3255772590637207
Validation loss: 2.022883633131622

Epoch: 6| Step: 13
Training loss: 1.341003656387329
Validation loss: 2.013846963964483

Epoch: 191| Step: 0
Training loss: 1.82466459274292
Validation loss: 1.9996839210551272

Epoch: 6| Step: 1
Training loss: 1.6411769390106201
Validation loss: 2.0162405942075994

Epoch: 6| Step: 2
Training loss: 1.1531705856323242
Validation loss: 2.031817800255232

Epoch: 6| Step: 3
Training loss: 2.244611978530884
Validation loss: 2.0480851191346363

Epoch: 6| Step: 4
Training loss: 1.3961355686187744
Validation loss: 2.048526797243344

Epoch: 6| Step: 5
Training loss: 1.2813639640808105
Validation loss: 2.0643375509528705

Epoch: 6| Step: 6
Training loss: 1.3116368055343628
Validation loss: 2.0587672495072886

Epoch: 6| Step: 7
Training loss: 1.8486998081207275
Validation loss: 2.0681736776905675

Epoch: 6| Step: 8
Training loss: 1.1573188304901123
Validation loss: 2.077665859653104

Epoch: 6| Step: 9
Training loss: 1.8495842218399048
Validation loss: 2.067046508994154

Epoch: 6| Step: 10
Training loss: 1.6727087497711182
Validation loss: 2.077099189963392

Epoch: 6| Step: 11
Training loss: 2.3145694732666016
Validation loss: 2.06889671151356

Epoch: 6| Step: 12
Training loss: 1.2676690816879272
Validation loss: 2.062907244569512

Epoch: 6| Step: 13
Training loss: 2.904934883117676
Validation loss: 2.040546158308624

Epoch: 192| Step: 0
Training loss: 1.6709578037261963
Validation loss: 2.0284297620096514

Epoch: 6| Step: 1
Training loss: 1.5655250549316406
Validation loss: 2.007581216032787

Epoch: 6| Step: 2
Training loss: 1.1943410634994507
Validation loss: 2.0218330762719594

Epoch: 6| Step: 3
Training loss: 1.4285109043121338
Validation loss: 2.0188427971255396

Epoch: 6| Step: 4
Training loss: 1.9181556701660156
Validation loss: 1.9697057175379928

Epoch: 6| Step: 5
Training loss: 1.58786940574646
Validation loss: 1.9735104576233895

Epoch: 6| Step: 6
Training loss: 1.5533778667449951
Validation loss: 1.9693295122474752

Epoch: 6| Step: 7
Training loss: 1.485848307609558
Validation loss: 1.9779310559713712

Epoch: 6| Step: 8
Training loss: 1.9421069622039795
Validation loss: 1.9703307613249748

Epoch: 6| Step: 9
Training loss: 1.0404187440872192
Validation loss: 1.963526830878309

Epoch: 6| Step: 10
Training loss: 1.8370219469070435
Validation loss: 1.9610375101848314

Epoch: 6| Step: 11
Training loss: 2.0807204246520996
Validation loss: 1.9730190333499704

Epoch: 6| Step: 12
Training loss: 2.1008665561676025
Validation loss: 1.9745379904265046

Epoch: 6| Step: 13
Training loss: 1.8162784576416016
Validation loss: 1.9981800458764518

Epoch: 193| Step: 0
Training loss: 1.085810899734497
Validation loss: 2.0163536712687504

Epoch: 6| Step: 1
Training loss: 2.0233707427978516
Validation loss: 2.007312592639718

Epoch: 6| Step: 2
Training loss: 2.0528650283813477
Validation loss: 1.9988027259867678

Epoch: 6| Step: 3
Training loss: 2.4273219108581543
Validation loss: 1.9958091089802403

Epoch: 6| Step: 4
Training loss: 1.250014305114746
Validation loss: 2.01339618877698

Epoch: 6| Step: 5
Training loss: 1.5392597913742065
Validation loss: 2.0305485815130253

Epoch: 6| Step: 6
Training loss: 1.4432533979415894
Validation loss: 2.007670457645129

Epoch: 6| Step: 7
Training loss: 1.8760912418365479
Validation loss: 2.020472664986887

Epoch: 6| Step: 8
Training loss: 1.051681399345398
Validation loss: 2.0135722429521623

Epoch: 6| Step: 9
Training loss: 1.1759905815124512
Validation loss: 2.028607233878105

Epoch: 6| Step: 10
Training loss: 1.4591058492660522
Validation loss: 2.053455796293033

Epoch: 6| Step: 11
Training loss: 2.3039469718933105
Validation loss: 2.0742174566432996

Epoch: 6| Step: 12
Training loss: 1.953721284866333
Validation loss: 2.067283748298563

Epoch: 6| Step: 13
Training loss: 1.438241958618164
Validation loss: 2.0660627477912494

Epoch: 194| Step: 0
Training loss: 1.3851932287216187
Validation loss: 2.064561847717531

Epoch: 6| Step: 1
Training loss: 1.2929635047912598
Validation loss: 2.0695823341287594

Epoch: 6| Step: 2
Training loss: 1.9899338483810425
Validation loss: 2.0647891952145483

Epoch: 6| Step: 3
Training loss: 1.3192801475524902
Validation loss: 2.049527851484155

Epoch: 6| Step: 4
Training loss: 1.9381473064422607
Validation loss: 2.0413660605748496

Epoch: 6| Step: 5
Training loss: 1.92271089553833
Validation loss: 2.0512090703492523

Epoch: 6| Step: 6
Training loss: 1.835791826248169
Validation loss: 2.073823577614241

Epoch: 6| Step: 7
Training loss: 0.9155325293540955
Validation loss: 2.1053261333896267

Epoch: 6| Step: 8
Training loss: 2.8927435874938965
Validation loss: 2.1421537450564805

Epoch: 6| Step: 9
Training loss: 1.340938687324524
Validation loss: 2.1176753774766

Epoch: 6| Step: 10
Training loss: 1.7966073751449585
Validation loss: 2.052676409803411

Epoch: 6| Step: 11
Training loss: 1.7621997594833374
Validation loss: 2.021691647909021

Epoch: 6| Step: 12
Training loss: 1.3660966157913208
Validation loss: 1.9954517015846827

Epoch: 6| Step: 13
Training loss: 1.6319929361343384
Validation loss: 1.9987784329281058

Epoch: 195| Step: 0
Training loss: 2.0686240196228027
Validation loss: 1.9906282809472853

Epoch: 6| Step: 1
Training loss: 1.735984206199646
Validation loss: 2.004245368383264

Epoch: 6| Step: 2
Training loss: 1.5796425342559814
Validation loss: 1.9885243818324099

Epoch: 6| Step: 3
Training loss: 1.8901269435882568
Validation loss: 1.982922900107599

Epoch: 6| Step: 4
Training loss: 1.599862813949585
Validation loss: 1.992924451828003

Epoch: 6| Step: 5
Training loss: 2.0307180881500244
Validation loss: 2.0110139590437695

Epoch: 6| Step: 6
Training loss: 1.8782011270523071
Validation loss: 2.044112067068777

Epoch: 6| Step: 7
Training loss: 1.617177963256836
Validation loss: 2.0836933607696206

Epoch: 6| Step: 8
Training loss: 1.8074042797088623
Validation loss: 2.0967339366994877

Epoch: 6| Step: 9
Training loss: 1.409895658493042
Validation loss: 2.113388660133526

Epoch: 6| Step: 10
Training loss: 1.2508232593536377
Validation loss: 2.094261707798127

Epoch: 6| Step: 11
Training loss: 1.779133677482605
Validation loss: 2.048243858480966

Epoch: 6| Step: 12
Training loss: 1.398385763168335
Validation loss: 2.0433114292801067

Epoch: 6| Step: 13
Training loss: 0.838050365447998
Validation loss: 2.0294039108419932

Epoch: 196| Step: 0
Training loss: 1.676792860031128
Validation loss: 2.033054790189189

Epoch: 6| Step: 1
Training loss: 1.6488800048828125
Validation loss: 2.038673654679329

Epoch: 6| Step: 2
Training loss: 1.6536617279052734
Validation loss: 2.0194964537056546

Epoch: 6| Step: 3
Training loss: 1.8123672008514404
Validation loss: 1.9936029500858758

Epoch: 6| Step: 4
Training loss: 1.5928853750228882
Validation loss: 1.9976714964835875

Epoch: 6| Step: 5
Training loss: 1.7784888744354248
Validation loss: 1.9793027729116461

Epoch: 6| Step: 6
Training loss: 1.4999699592590332
Validation loss: 1.9839270448171964

Epoch: 6| Step: 7
Training loss: 1.2379295825958252
Validation loss: 1.980408049398853

Epoch: 6| Step: 8
Training loss: 1.7036874294281006
Validation loss: 1.9830914799885084

Epoch: 6| Step: 9
Training loss: 1.5270763635635376
Validation loss: 2.01061935065895

Epoch: 6| Step: 10
Training loss: 1.8233414888381958
Validation loss: 2.0247794812725437

Epoch: 6| Step: 11
Training loss: 1.9812697172164917
Validation loss: 2.0236524715218493

Epoch: 6| Step: 12
Training loss: 1.2709481716156006
Validation loss: 2.0271355182893815

Epoch: 6| Step: 13
Training loss: 1.740483045578003
Validation loss: 2.0317172747786327

Epoch: 197| Step: 0
Training loss: 1.352256178855896
Validation loss: 2.0149038760892806

Epoch: 6| Step: 1
Training loss: 1.4784117937088013
Validation loss: 1.9848849017132995

Epoch: 6| Step: 2
Training loss: 1.7345054149627686
Validation loss: 1.9807356813902497

Epoch: 6| Step: 3
Training loss: 1.0254513025283813
Validation loss: 1.9752133879610287

Epoch: 6| Step: 4
Training loss: 1.8670700788497925
Validation loss: 1.9784226007359003

Epoch: 6| Step: 5
Training loss: 1.3310773372650146
Validation loss: 1.9675180027561803

Epoch: 6| Step: 6
Training loss: 1.7780346870422363
Validation loss: 1.9830139183229016

Epoch: 6| Step: 7
Training loss: 1.5498487949371338
Validation loss: 1.9880923366033902

Epoch: 6| Step: 8
Training loss: 1.4586764574050903
Validation loss: 2.008492064732377

Epoch: 6| Step: 9
Training loss: 1.6610068082809448
Validation loss: 2.0328314740170716

Epoch: 6| Step: 10
Training loss: 2.0975751876831055
Validation loss: 2.063727914646108

Epoch: 6| Step: 11
Training loss: 2.2040467262268066
Validation loss: 2.074213462491189

Epoch: 6| Step: 12
Training loss: 1.7969982624053955
Validation loss: 2.0941027838696717

Epoch: 6| Step: 13
Training loss: 1.1040635108947754
Validation loss: 2.0909904574835174

Epoch: 198| Step: 0
Training loss: 1.64127516746521
Validation loss: 2.0618576144659393

Epoch: 6| Step: 1
Training loss: 1.7269043922424316
Validation loss: 2.0386704450012534

Epoch: 6| Step: 2
Training loss: 1.8770190477371216
Validation loss: 2.020131488000193

Epoch: 6| Step: 3
Training loss: 1.5887258052825928
Validation loss: 2.0082809899442937

Epoch: 6| Step: 4
Training loss: 2.015855550765991
Validation loss: 1.9873226816936205

Epoch: 6| Step: 5
Training loss: 0.95759516954422
Validation loss: 1.9737885331594816

Epoch: 6| Step: 6
Training loss: 1.5117838382720947
Validation loss: 1.9936486059619534

Epoch: 6| Step: 7
Training loss: 1.8093254566192627
Validation loss: 1.9721148578069543

Epoch: 6| Step: 8
Training loss: 1.6386187076568604
Validation loss: 1.9683782439078055

Epoch: 6| Step: 9
Training loss: 1.3419169187545776
Validation loss: 1.987444834042621

Epoch: 6| Step: 10
Training loss: 1.2814390659332275
Validation loss: 1.9998625016981555

Epoch: 6| Step: 11
Training loss: 1.901930332183838
Validation loss: 2.0189928034300446

Epoch: 6| Step: 12
Training loss: 1.8463239669799805
Validation loss: 2.0181839427640362

Epoch: 6| Step: 13
Training loss: 0.9883956909179688
Validation loss: 2.0332341476153304

Epoch: 199| Step: 0
Training loss: 1.7189438343048096
Validation loss: 2.023768071205385

Epoch: 6| Step: 1
Training loss: 1.9696632623672485
Validation loss: 2.002634856008714

Epoch: 6| Step: 2
Training loss: 1.444894790649414
Validation loss: 2.001485142656552

Epoch: 6| Step: 3
Training loss: 1.4441330432891846
Validation loss: 2.010391672452291

Epoch: 6| Step: 4
Training loss: 0.8238643407821655
Validation loss: 1.99618568599865

Epoch: 6| Step: 5
Training loss: 1.5164604187011719
Validation loss: 2.0031473200808287

Epoch: 6| Step: 6
Training loss: 1.7809240818023682
Validation loss: 1.9971908933372908

Epoch: 6| Step: 7
Training loss: 1.2066296339035034
Validation loss: 1.9982094662163847

Epoch: 6| Step: 8
Training loss: 1.345726490020752
Validation loss: 1.9814835440727971

Epoch: 6| Step: 9
Training loss: 1.1417710781097412
Validation loss: 1.9818463428046114

Epoch: 6| Step: 10
Training loss: 1.6921944618225098
Validation loss: 1.9885326457279984

Epoch: 6| Step: 11
Training loss: 2.2815921306610107
Validation loss: 1.9947068896344913

Epoch: 6| Step: 12
Training loss: 1.9547691345214844
Validation loss: 2.026164948299367

Epoch: 6| Step: 13
Training loss: 2.2637035846710205
Validation loss: 2.0210462847063617

Epoch: 200| Step: 0
Training loss: 1.5118720531463623
Validation loss: 2.029437941889609

Epoch: 6| Step: 1
Training loss: 1.3816810846328735
Validation loss: 2.032931538038356

Epoch: 6| Step: 2
Training loss: 1.510704755783081
Validation loss: 2.039084331963652

Epoch: 6| Step: 3
Training loss: 1.9291332960128784
Validation loss: 2.0164002500554568

Epoch: 6| Step: 4
Training loss: 1.5896532535552979
Validation loss: 2.015652105372439

Epoch: 6| Step: 5
Training loss: 1.7233392000198364
Validation loss: 2.001651963879985

Epoch: 6| Step: 6
Training loss: 1.6788809299468994
Validation loss: 1.9667452330230384

Epoch: 6| Step: 7
Training loss: 1.4746613502502441
Validation loss: 1.9719802589826687

Epoch: 6| Step: 8
Training loss: 1.6159051656723022
Validation loss: 1.973249049596889

Epoch: 6| Step: 9
Training loss: 1.3433701992034912
Validation loss: 1.986763220961376

Epoch: 6| Step: 10
Training loss: 1.8081886768341064
Validation loss: 1.9787555279270295

Epoch: 6| Step: 11
Training loss: 1.570651888847351
Validation loss: 1.9822828654320008

Epoch: 6| Step: 12
Training loss: 1.2366281747817993
Validation loss: 1.9863763598985569

Epoch: 6| Step: 13
Training loss: 1.8785337209701538
Validation loss: 2.0067933964472946

Epoch: 201| Step: 0
Training loss: 1.6300421953201294
Validation loss: 2.018515856035294

Epoch: 6| Step: 1
Training loss: 2.003450632095337
Validation loss: 2.0474967059268745

Epoch: 6| Step: 2
Training loss: 1.9374167919158936
Validation loss: 2.073707075529201

Epoch: 6| Step: 3
Training loss: 1.2628384828567505
Validation loss: 2.070539851342478

Epoch: 6| Step: 4
Training loss: 1.8297303915023804
Validation loss: 2.057889048771192

Epoch: 6| Step: 5
Training loss: 1.6257308721542358
Validation loss: 2.0286601358844387

Epoch: 6| Step: 6
Training loss: 1.3884413242340088
Validation loss: 2.017347402470086

Epoch: 6| Step: 7
Training loss: 1.6794859170913696
Validation loss: 1.995627385313793

Epoch: 6| Step: 8
Training loss: 1.8320119380950928
Validation loss: 1.9848076861391786

Epoch: 6| Step: 9
Training loss: 1.2651255130767822
Validation loss: 1.9946020931325934

Epoch: 6| Step: 10
Training loss: 1.4397393465042114
Validation loss: 1.9961645410906883

Epoch: 6| Step: 11
Training loss: 1.3083020448684692
Validation loss: 1.9778392186728857

Epoch: 6| Step: 12
Training loss: 1.253522276878357
Validation loss: 1.9885897303140292

Epoch: 6| Step: 13
Training loss: 2.2803409099578857
Validation loss: 2.0168834886243268

Epoch: 202| Step: 0
Training loss: 1.3878307342529297
Validation loss: 2.0355717648742018

Epoch: 6| Step: 1
Training loss: 1.4426445960998535
Validation loss: 2.0343438233098676

Epoch: 6| Step: 2
Training loss: 1.493733286857605
Validation loss: 2.002818730569655

Epoch: 6| Step: 3
Training loss: 1.5747568607330322
Validation loss: 2.0246189755778157

Epoch: 6| Step: 4
Training loss: 1.548678994178772
Validation loss: 2.015131632486979

Epoch: 6| Step: 5
Training loss: 1.771841287612915
Validation loss: 1.997940045531078

Epoch: 6| Step: 6
Training loss: 1.5223190784454346
Validation loss: 1.9939941065285796

Epoch: 6| Step: 7
Training loss: 2.365748882293701
Validation loss: 1.9826183062727734

Epoch: 6| Step: 8
Training loss: 1.3932019472122192
Validation loss: 1.9768648096310195

Epoch: 6| Step: 9
Training loss: 1.2227561473846436
Validation loss: 1.9662170563974688

Epoch: 6| Step: 10
Training loss: 1.862024188041687
Validation loss: 1.9693598644707793

Epoch: 6| Step: 11
Training loss: 1.746154546737671
Validation loss: 1.958606932752876

Epoch: 6| Step: 12
Training loss: 1.361257791519165
Validation loss: 1.949104655173517

Epoch: 6| Step: 13
Training loss: 1.40093994140625
Validation loss: 1.932008404885569

Epoch: 203| Step: 0
Training loss: 1.2117137908935547
Validation loss: 1.9535406135743665

Epoch: 6| Step: 1
Training loss: 2.2208714485168457
Validation loss: 1.933055172684372

Epoch: 6| Step: 2
Training loss: 1.4830992221832275
Validation loss: 1.9622147826738254

Epoch: 6| Step: 3
Training loss: 1.2553507089614868
Validation loss: 1.9657207022431076

Epoch: 6| Step: 4
Training loss: 1.5200796127319336
Validation loss: 2.005333158277696

Epoch: 6| Step: 5
Training loss: 1.7499653100967407
Validation loss: 2.0215341814102663

Epoch: 6| Step: 6
Training loss: 2.163766622543335
Validation loss: 2.0395273136836227

Epoch: 6| Step: 7
Training loss: 1.3079397678375244
Validation loss: 2.0582297181570404

Epoch: 6| Step: 8
Training loss: 1.705787181854248
Validation loss: 2.0820458922334897

Epoch: 6| Step: 9
Training loss: 2.061689853668213
Validation loss: 2.0678011063606507

Epoch: 6| Step: 10
Training loss: 0.971904456615448
Validation loss: 2.0379008900734688

Epoch: 6| Step: 11
Training loss: 1.6323078870773315
Validation loss: 2.0484110539959324

Epoch: 6| Step: 12
Training loss: 1.6890051364898682
Validation loss: 2.0026545832234044

Epoch: 6| Step: 13
Training loss: 0.7658047676086426
Validation loss: 2.001996845327398

Epoch: 204| Step: 0
Training loss: 2.330996036529541
Validation loss: 2.007762562844061

Epoch: 6| Step: 1
Training loss: 1.625167727470398
Validation loss: 1.999892263002293

Epoch: 6| Step: 2
Training loss: 0.8737290501594543
Validation loss: 1.9903288682301838

Epoch: 6| Step: 3
Training loss: 1.0982933044433594
Validation loss: 1.9946110428020518

Epoch: 6| Step: 4
Training loss: 1.7434163093566895
Validation loss: 2.005377581042628

Epoch: 6| Step: 5
Training loss: 1.3543074131011963
Validation loss: 2.0217583410201536

Epoch: 6| Step: 6
Training loss: 1.9501228332519531
Validation loss: 2.016150830894388

Epoch: 6| Step: 7
Training loss: 2.0172231197357178
Validation loss: 2.017314200760216

Epoch: 6| Step: 8
Training loss: 1.5120333433151245
Validation loss: 2.013872156861008

Epoch: 6| Step: 9
Training loss: 1.1538296937942505
Validation loss: 2.0401390406393234

Epoch: 6| Step: 10
Training loss: 2.0864570140838623
Validation loss: 2.0153657813226022

Epoch: 6| Step: 11
Training loss: 1.0024747848510742
Validation loss: 2.0320649762307443

Epoch: 6| Step: 12
Training loss: 1.8791272640228271
Validation loss: 2.019678135072031

Epoch: 6| Step: 13
Training loss: 1.1515918970108032
Validation loss: 2.002268332307057

Epoch: 205| Step: 0
Training loss: 1.4948194026947021
Validation loss: 2.0080581365093106

Epoch: 6| Step: 1
Training loss: 1.0433071851730347
Validation loss: 1.9728957324899652

Epoch: 6| Step: 2
Training loss: 1.46524977684021
Validation loss: 1.9769033014133413

Epoch: 6| Step: 3
Training loss: 2.2776126861572266
Validation loss: 1.9606752126447615

Epoch: 6| Step: 4
Training loss: 1.8583983182907104
Validation loss: 1.9802066574814499

Epoch: 6| Step: 5
Training loss: 1.9424970149993896
Validation loss: 1.9891313634892946

Epoch: 6| Step: 6
Training loss: 1.8742592334747314
Validation loss: 2.003596659629576

Epoch: 6| Step: 7
Training loss: 1.4741525650024414
Validation loss: 2.0653355224158174

Epoch: 6| Step: 8
Training loss: 1.6819193363189697
Validation loss: 2.097202600971345

Epoch: 6| Step: 9
Training loss: 1.1396145820617676
Validation loss: 2.0780822897470124

Epoch: 6| Step: 10
Training loss: 1.9194121360778809
Validation loss: 2.028221394426079

Epoch: 6| Step: 11
Training loss: 1.0266450643539429
Validation loss: 1.9798906939004057

Epoch: 6| Step: 12
Training loss: 1.249756097793579
Validation loss: 1.9681154220334944

Epoch: 6| Step: 13
Training loss: 1.6592507362365723
Validation loss: 1.981088980551689

Epoch: 206| Step: 0
Training loss: 2.0550827980041504
Validation loss: 1.9806304631694671

Epoch: 6| Step: 1
Training loss: 1.2785378694534302
Validation loss: 1.9824181782302035

Epoch: 6| Step: 2
Training loss: 1.8277995586395264
Validation loss: 1.9904402020157024

Epoch: 6| Step: 3
Training loss: 1.6410629749298096
Validation loss: 2.002176343753774

Epoch: 6| Step: 4
Training loss: 2.0674617290496826
Validation loss: 2.0092890775331886

Epoch: 6| Step: 5
Training loss: 1.4990638494491577
Validation loss: 2.0292559849318637

Epoch: 6| Step: 6
Training loss: 2.207770347595215
Validation loss: 2.0223385749324674

Epoch: 6| Step: 7
Training loss: 1.551958680152893
Validation loss: 2.045151592582785

Epoch: 6| Step: 8
Training loss: 1.363736867904663
Validation loss: 2.026616193914926

Epoch: 6| Step: 9
Training loss: 0.9288975596427917
Validation loss: 2.0197320343345724

Epoch: 6| Step: 10
Training loss: 1.2212779521942139
Validation loss: 2.0048399035648634

Epoch: 6| Step: 11
Training loss: 0.9682599902153015
Validation loss: 2.0018376406802925

Epoch: 6| Step: 12
Training loss: 1.4309674501419067
Validation loss: 1.9965076241441952

Epoch: 6| Step: 13
Training loss: 1.632584810256958
Validation loss: 2.000925762678987

Epoch: 207| Step: 0
Training loss: 1.6213427782058716
Validation loss: 2.002354803905692

Epoch: 6| Step: 1
Training loss: 1.259064793586731
Validation loss: 2.007362855378018

Epoch: 6| Step: 2
Training loss: 1.2157151699066162
Validation loss: 2.012102616730557

Epoch: 6| Step: 3
Training loss: 1.6285468339920044
Validation loss: 2.007886452059592

Epoch: 6| Step: 4
Training loss: 1.6991605758666992
Validation loss: 2.01855125991247

Epoch: 6| Step: 5
Training loss: 1.7453269958496094
Validation loss: 2.013382573281565

Epoch: 6| Step: 6
Training loss: 1.3476403951644897
Validation loss: 1.9886783630617204

Epoch: 6| Step: 7
Training loss: 1.4010882377624512
Validation loss: 1.9638486241781583

Epoch: 6| Step: 8
Training loss: 1.6525330543518066
Validation loss: 1.9662326510234545

Epoch: 6| Step: 9
Training loss: 1.5909755229949951
Validation loss: 1.9827332419733847

Epoch: 6| Step: 10
Training loss: 1.348625898361206
Validation loss: 2.000263188474922

Epoch: 6| Step: 11
Training loss: 1.611297845840454
Validation loss: 1.9702363039857598

Epoch: 6| Step: 12
Training loss: 1.5542850494384766
Validation loss: 1.9802263475233508

Epoch: 6| Step: 13
Training loss: 1.9021472930908203
Validation loss: 1.9821003765188239

Epoch: 208| Step: 0
Training loss: 1.7234132289886475
Validation loss: 1.9746533593823832

Epoch: 6| Step: 1
Training loss: 1.414778709411621
Validation loss: 1.972948681923651

Epoch: 6| Step: 2
Training loss: 1.4176609516143799
Validation loss: 1.994952917098999

Epoch: 6| Step: 3
Training loss: 1.9995663166046143
Validation loss: 1.9973085388060539

Epoch: 6| Step: 4
Training loss: 1.73495614528656
Validation loss: 1.9963748954957532

Epoch: 6| Step: 5
Training loss: 1.728468894958496
Validation loss: 2.0009831305473083

Epoch: 6| Step: 6
Training loss: 1.4907362461090088
Validation loss: 2.011928023830537

Epoch: 6| Step: 7
Training loss: 1.4357199668884277
Validation loss: 1.975053556503788

Epoch: 6| Step: 8
Training loss: 1.5617334842681885
Validation loss: 1.9712559253938737

Epoch: 6| Step: 9
Training loss: 1.714505672454834
Validation loss: 1.9776945678136681

Epoch: 6| Step: 10
Training loss: 0.9469398260116577
Validation loss: 1.985719798713602

Epoch: 6| Step: 11
Training loss: 1.1300451755523682
Validation loss: 1.9834264760376306

Epoch: 6| Step: 12
Training loss: 1.3015029430389404
Validation loss: 1.9903533843255812

Epoch: 6| Step: 13
Training loss: 1.6984596252441406
Validation loss: 1.9933114333819317

Epoch: 209| Step: 0
Training loss: 1.362304925918579
Validation loss: 2.0209570777031685

Epoch: 6| Step: 1
Training loss: 2.2838351726531982
Validation loss: 2.030645083355647

Epoch: 6| Step: 2
Training loss: 1.7240898609161377
Validation loss: 2.0303486649708082

Epoch: 6| Step: 3
Training loss: 1.5366253852844238
Validation loss: 2.009661013080228

Epoch: 6| Step: 4
Training loss: 1.256655216217041
Validation loss: 2.0276741161141345

Epoch: 6| Step: 5
Training loss: 1.7310004234313965
Validation loss: 2.015814463297526

Epoch: 6| Step: 6
Training loss: 0.7801328897476196
Validation loss: 1.9908586420038694

Epoch: 6| Step: 7
Training loss: 1.2005765438079834
Validation loss: 1.9555366411004016

Epoch: 6| Step: 8
Training loss: 1.2247709035873413
Validation loss: 1.9804323809121245

Epoch: 6| Step: 9
Training loss: 1.2352583408355713
Validation loss: 1.9813979056573683

Epoch: 6| Step: 10
Training loss: 1.5291199684143066
Validation loss: 1.9692866879124795

Epoch: 6| Step: 11
Training loss: 1.2435545921325684
Validation loss: 1.9836891581935268

Epoch: 6| Step: 12
Training loss: 2.144806385040283
Validation loss: 2.0075359318846013

Epoch: 6| Step: 13
Training loss: 2.0946567058563232
Validation loss: 2.0456385727851623

Epoch: 210| Step: 0
Training loss: 1.1543550491333008
Validation loss: 2.0797456541369037

Epoch: 6| Step: 1
Training loss: 1.6533221006393433
Validation loss: 2.064688223664479

Epoch: 6| Step: 2
Training loss: 1.5179219245910645
Validation loss: 2.023866932879212

Epoch: 6| Step: 3
Training loss: 1.182450294494629
Validation loss: 2.0129073512169624

Epoch: 6| Step: 4
Training loss: 2.1690690517425537
Validation loss: 1.9905015806997977

Epoch: 6| Step: 5
Training loss: 1.5944693088531494
Validation loss: 1.975780802388345

Epoch: 6| Step: 6
Training loss: 1.5137250423431396
Validation loss: 1.9702535419053928

Epoch: 6| Step: 7
Training loss: 1.784866213798523
Validation loss: 1.959378324529176

Epoch: 6| Step: 8
Training loss: 1.5409436225891113
Validation loss: 1.9687287961283038

Epoch: 6| Step: 9
Training loss: 1.7668375968933105
Validation loss: 1.9580891157991143

Epoch: 6| Step: 10
Training loss: 1.6576669216156006
Validation loss: 1.9771575004823747

Epoch: 6| Step: 11
Training loss: 1.1164594888687134
Validation loss: 1.972465249799913

Epoch: 6| Step: 12
Training loss: 1.0429261922836304
Validation loss: 1.9922637401088592

Epoch: 6| Step: 13
Training loss: 1.3197168111801147
Validation loss: 1.9908955263835129

Epoch: 211| Step: 0
Training loss: 1.4763939380645752
Validation loss: 2.0111538094858967

Epoch: 6| Step: 1
Training loss: 1.4319096803665161
Validation loss: 2.0203841194029777

Epoch: 6| Step: 2
Training loss: 1.561838150024414
Validation loss: 1.999902489364788

Epoch: 6| Step: 3
Training loss: 1.0671294927597046
Validation loss: 1.9763327375535042

Epoch: 6| Step: 4
Training loss: 1.8742611408233643
Validation loss: 1.9697872566920456

Epoch: 6| Step: 5
Training loss: 0.8680158853530884
Validation loss: 1.952021950034685

Epoch: 6| Step: 6
Training loss: 1.6559686660766602
Validation loss: 1.9789373759300477

Epoch: 6| Step: 7
Training loss: 1.8316242694854736
Validation loss: 1.959495162451139

Epoch: 6| Step: 8
Training loss: 1.380718469619751
Validation loss: 1.9499071836471558

Epoch: 6| Step: 9
Training loss: 1.9469125270843506
Validation loss: 1.9524523276154713

Epoch: 6| Step: 10
Training loss: 1.592499017715454
Validation loss: 1.9575959341500395

Epoch: 6| Step: 11
Training loss: 1.7091561555862427
Validation loss: 1.956045505821064

Epoch: 6| Step: 12
Training loss: 1.1675176620483398
Validation loss: 1.976407330523255

Epoch: 6| Step: 13
Training loss: 1.3455653190612793
Validation loss: 1.9884877025440175

Epoch: 212| Step: 0
Training loss: 1.1486220359802246
Validation loss: 1.969377766373337

Epoch: 6| Step: 1
Training loss: 1.8711036443710327
Validation loss: 1.9723355116382721

Epoch: 6| Step: 2
Training loss: 1.3750838041305542
Validation loss: 1.9869460854479062

Epoch: 6| Step: 3
Training loss: 1.4393912553787231
Validation loss: 1.9809418493701565

Epoch: 6| Step: 4
Training loss: 1.2782074213027954
Validation loss: 1.9695498148600261

Epoch: 6| Step: 5
Training loss: 2.5006351470947266
Validation loss: 1.9709872212461246

Epoch: 6| Step: 6
Training loss: 0.9275667667388916
Validation loss: 1.9659155850769372

Epoch: 6| Step: 7
Training loss: 1.711376428604126
Validation loss: 1.9550109242880216

Epoch: 6| Step: 8
Training loss: 1.4341709613800049
Validation loss: 1.973563976185296

Epoch: 6| Step: 9
Training loss: 1.3143436908721924
Validation loss: 1.9862327024500857

Epoch: 6| Step: 10
Training loss: 1.8327033519744873
Validation loss: 1.9816851128814041

Epoch: 6| Step: 11
Training loss: 0.7541149854660034
Validation loss: 2.000612348638555

Epoch: 6| Step: 12
Training loss: 1.7517610788345337
Validation loss: 2.006423055484731

Epoch: 6| Step: 13
Training loss: 1.305336833000183
Validation loss: 2.013251546890505

Epoch: 213| Step: 0
Training loss: 1.3991032838821411
Validation loss: 2.013985518486269

Epoch: 6| Step: 1
Training loss: 1.4599475860595703
Validation loss: 2.027565780506339

Epoch: 6| Step: 2
Training loss: 1.8882700204849243
Validation loss: 2.0189231608503606

Epoch: 6| Step: 3
Training loss: 1.3401963710784912
Validation loss: 2.0079560382391817

Epoch: 6| Step: 4
Training loss: 1.4056856632232666
Validation loss: 2.011723518371582

Epoch: 6| Step: 5
Training loss: 0.5052727460861206
Validation loss: 1.976938057971257

Epoch: 6| Step: 6
Training loss: 1.9234495162963867
Validation loss: 1.9895135100169847

Epoch: 6| Step: 7
Training loss: 1.5459705591201782
Validation loss: 1.9828585065821165

Epoch: 6| Step: 8
Training loss: 1.6688368320465088
Validation loss: 1.9782165404289

Epoch: 6| Step: 9
Training loss: 1.4951913356781006
Validation loss: 1.977047517735471

Epoch: 6| Step: 10
Training loss: 1.0642471313476562
Validation loss: 1.9848906173500964

Epoch: 6| Step: 11
Training loss: 1.9118469953536987
Validation loss: 1.9853669904893445

Epoch: 6| Step: 12
Training loss: 1.2797290086746216
Validation loss: 2.014845412264588

Epoch: 6| Step: 13
Training loss: 1.817311406135559
Validation loss: 2.0114669902350313

Epoch: 214| Step: 0
Training loss: 1.6310503482818604
Validation loss: 2.02644488375674

Epoch: 6| Step: 1
Training loss: 1.987177848815918
Validation loss: 2.0311244790272047

Epoch: 6| Step: 2
Training loss: 1.108541488647461
Validation loss: 2.0209651711166545

Epoch: 6| Step: 3
Training loss: 1.3181922435760498
Validation loss: 1.9966738249665947

Epoch: 6| Step: 4
Training loss: 1.319140911102295
Validation loss: 1.9730832910024991

Epoch: 6| Step: 5
Training loss: 1.7689465284347534
Validation loss: 1.9508011392367783

Epoch: 6| Step: 6
Training loss: 0.7411526441574097
Validation loss: 1.9320707654440274

Epoch: 6| Step: 7
Training loss: 1.4748938083648682
Validation loss: 1.9432201539316485

Epoch: 6| Step: 8
Training loss: 1.509098768234253
Validation loss: 1.9340218536315426

Epoch: 6| Step: 9
Training loss: 1.7185049057006836
Validation loss: 1.9245785115867533

Epoch: 6| Step: 10
Training loss: 1.471628189086914
Validation loss: 1.9315490671383437

Epoch: 6| Step: 11
Training loss: 1.465785026550293
Validation loss: 1.951508011869205

Epoch: 6| Step: 12
Training loss: 1.2490642070770264
Validation loss: 1.9800189195140716

Epoch: 6| Step: 13
Training loss: 1.8747098445892334
Validation loss: 1.9796491707524946

Epoch: 215| Step: 0
Training loss: 1.5021696090698242
Validation loss: 2.0064779353398148

Epoch: 6| Step: 1
Training loss: 2.224395513534546
Validation loss: 2.042825263033631

Epoch: 6| Step: 2
Training loss: 1.599202036857605
Validation loss: 2.038561039073493

Epoch: 6| Step: 3
Training loss: 1.976333737373352
Validation loss: 2.0494518485120548

Epoch: 6| Step: 4
Training loss: 1.7904382944107056
Validation loss: 2.062149456752244

Epoch: 6| Step: 5
Training loss: 1.0941078662872314
Validation loss: 2.031420261629166

Epoch: 6| Step: 6
Training loss: 0.936546802520752
Validation loss: 2.016237102529054

Epoch: 6| Step: 7
Training loss: 1.4401812553405762
Validation loss: 1.9940898213335263

Epoch: 6| Step: 8
Training loss: 1.4809762239456177
Validation loss: 1.997216809180475

Epoch: 6| Step: 9
Training loss: 1.2939989566802979
Validation loss: 1.9860719878186461

Epoch: 6| Step: 10
Training loss: 1.3815466165542603
Validation loss: 1.9778482785788916

Epoch: 6| Step: 11
Training loss: 1.0995899438858032
Validation loss: 1.9981187928107478

Epoch: 6| Step: 12
Training loss: 1.3491990566253662
Validation loss: 1.9632613248722528

Epoch: 6| Step: 13
Training loss: 1.1910855770111084
Validation loss: 1.9728326079665974

Epoch: 216| Step: 0
Training loss: 1.2700523138046265
Validation loss: 1.9593659190721409

Epoch: 6| Step: 1
Training loss: 1.9094765186309814
Validation loss: 1.9558336222043602

Epoch: 6| Step: 2
Training loss: 1.6927909851074219
Validation loss: 1.9262739740392214

Epoch: 6| Step: 3
Training loss: 0.9208526611328125
Validation loss: 1.9356462019746021

Epoch: 6| Step: 4
Training loss: 1.9952967166900635
Validation loss: 1.9206691736816077

Epoch: 6| Step: 5
Training loss: 1.3250253200531006
Validation loss: 1.9525080111718947

Epoch: 6| Step: 6
Training loss: 1.154649019241333
Validation loss: 1.9269860124075284

Epoch: 6| Step: 7
Training loss: 1.2975718975067139
Validation loss: 1.9421571467512397

Epoch: 6| Step: 8
Training loss: 1.3138470649719238
Validation loss: 1.951823611413279

Epoch: 6| Step: 9
Training loss: 1.4315249919891357
Validation loss: 1.9580879416517032

Epoch: 6| Step: 10
Training loss: 0.9448877573013306
Validation loss: 1.965776656263618

Epoch: 6| Step: 11
Training loss: 1.4932515621185303
Validation loss: 1.9709416871429772

Epoch: 6| Step: 12
Training loss: 1.6476256847381592
Validation loss: 1.9703034611158474

Epoch: 6| Step: 13
Training loss: 2.207702398300171
Validation loss: 1.9824447913836407

Epoch: 217| Step: 0
Training loss: 1.6322141885757446
Validation loss: 1.9738820752789896

Epoch: 6| Step: 1
Training loss: 1.6656908988952637
Validation loss: 1.9880032872640958

Epoch: 6| Step: 2
Training loss: 1.3343359231948853
Validation loss: 1.9815408375955397

Epoch: 6| Step: 3
Training loss: 0.8272516131401062
Validation loss: 1.960765072094497

Epoch: 6| Step: 4
Training loss: 1.8001857995986938
Validation loss: 1.9692914101385302

Epoch: 6| Step: 5
Training loss: 1.347909927368164
Validation loss: 1.967160560751474

Epoch: 6| Step: 6
Training loss: 1.6482051610946655
Validation loss: 1.9543073484974522

Epoch: 6| Step: 7
Training loss: 1.7327768802642822
Validation loss: 1.9837165083936465

Epoch: 6| Step: 8
Training loss: 0.8987041711807251
Validation loss: 1.978334783225931

Epoch: 6| Step: 9
Training loss: 1.5199427604675293
Validation loss: 1.995675007502238

Epoch: 6| Step: 10
Training loss: 1.4762729406356812
Validation loss: 2.0047733014629734

Epoch: 6| Step: 11
Training loss: 1.6493686437606812
Validation loss: 2.038043168283278

Epoch: 6| Step: 12
Training loss: 1.2433316707611084
Validation loss: 2.0165801561006935

Epoch: 6| Step: 13
Training loss: 1.217878818511963
Validation loss: 2.012529973060854

Epoch: 218| Step: 0
Training loss: 1.5326673984527588
Validation loss: 1.9649829249228201

Epoch: 6| Step: 1
Training loss: 1.6047711372375488
Validation loss: 1.9512716967572448

Epoch: 6| Step: 2
Training loss: 0.7395488023757935
Validation loss: 1.9254801824528684

Epoch: 6| Step: 3
Training loss: 1.1718418598175049
Validation loss: 1.9151503924400575

Epoch: 6| Step: 4
Training loss: 1.005311131477356
Validation loss: 1.9236772983304915

Epoch: 6| Step: 5
Training loss: 1.9114474058151245
Validation loss: 1.9203427004557785

Epoch: 6| Step: 6
Training loss: 2.0929465293884277
Validation loss: 1.9464053876938359

Epoch: 6| Step: 7
Training loss: 1.4932242631912231
Validation loss: 1.934224206914184

Epoch: 6| Step: 8
Training loss: 1.67268705368042
Validation loss: 1.9607452961706346

Epoch: 6| Step: 9
Training loss: 1.1011850833892822
Validation loss: 1.9726029211475002

Epoch: 6| Step: 10
Training loss: 1.2541135549545288
Validation loss: 1.971893133655671

Epoch: 6| Step: 11
Training loss: 1.5532870292663574
Validation loss: 1.9654065767923992

Epoch: 6| Step: 12
Training loss: 1.5154235363006592
Validation loss: 1.9766047436703917

Epoch: 6| Step: 13
Training loss: 1.4080561399459839
Validation loss: 1.9688665584851337

Epoch: 219| Step: 0
Training loss: 1.0974136590957642
Validation loss: 1.9544107003878521

Epoch: 6| Step: 1
Training loss: 1.611739158630371
Validation loss: 1.9429453752374137

Epoch: 6| Step: 2
Training loss: 1.048873782157898
Validation loss: 1.9369245447138304

Epoch: 6| Step: 3
Training loss: 1.605574607849121
Validation loss: 1.9517873115437006

Epoch: 6| Step: 4
Training loss: 1.3432807922363281
Validation loss: 1.9455205817376413

Epoch: 6| Step: 5
Training loss: 1.2964946031570435
Validation loss: 1.9552140940902054

Epoch: 6| Step: 6
Training loss: 1.466394305229187
Validation loss: 1.9551525961968206

Epoch: 6| Step: 7
Training loss: 1.3286290168762207
Validation loss: 1.96173446665528

Epoch: 6| Step: 8
Training loss: 1.740407943725586
Validation loss: 1.9727246338321316

Epoch: 6| Step: 9
Training loss: 1.2458897829055786
Validation loss: 1.9667255058083484

Epoch: 6| Step: 10
Training loss: 1.5381615161895752
Validation loss: 1.9565661620068293

Epoch: 6| Step: 11
Training loss: 1.2494795322418213
Validation loss: 1.9351474238980202

Epoch: 6| Step: 12
Training loss: 1.8397715091705322
Validation loss: 1.943367463286205

Epoch: 6| Step: 13
Training loss: 1.3620529174804688
Validation loss: 1.9274079979106944

Epoch: 220| Step: 0
Training loss: 1.3100457191467285
Validation loss: 1.9255702905757452

Epoch: 6| Step: 1
Training loss: 1.4078742265701294
Validation loss: 1.9416216470861947

Epoch: 6| Step: 2
Training loss: 1.4945696592330933
Validation loss: 1.9161501007695352

Epoch: 6| Step: 3
Training loss: 1.3932055234909058
Validation loss: 1.9181667412481

Epoch: 6| Step: 4
Training loss: 1.7307697534561157
Validation loss: 1.9211739852864256

Epoch: 6| Step: 5
Training loss: 1.16945481300354
Validation loss: 1.9786119102149882

Epoch: 6| Step: 6
Training loss: 1.5171259641647339
Validation loss: 1.9990157593962967

Epoch: 6| Step: 7
Training loss: 1.5577372312545776
Validation loss: 2.026839961287796

Epoch: 6| Step: 8
Training loss: 1.7770233154296875
Validation loss: 2.0138277212778726

Epoch: 6| Step: 9
Training loss: 1.665954351425171
Validation loss: 1.986135644297446

Epoch: 6| Step: 10
Training loss: 0.7689489126205444
Validation loss: 1.9939659769817064

Epoch: 6| Step: 11
Training loss: 1.321131706237793
Validation loss: 1.9555186533158826

Epoch: 6| Step: 12
Training loss: 1.2055633068084717
Validation loss: 1.9314132967302877

Epoch: 6| Step: 13
Training loss: 1.46346914768219
Validation loss: 1.9301594303500267

Epoch: 221| Step: 0
Training loss: 1.3011839389801025
Validation loss: 1.9388375179741972

Epoch: 6| Step: 1
Training loss: 1.3761473894119263
Validation loss: 1.939500508769866

Epoch: 6| Step: 2
Training loss: 1.7481889724731445
Validation loss: 1.9663999426749446

Epoch: 6| Step: 3
Training loss: 1.5400018692016602
Validation loss: 1.9676635047440887

Epoch: 6| Step: 4
Training loss: 1.8359906673431396
Validation loss: 2.003754477347097

Epoch: 6| Step: 5
Training loss: 1.774249792098999
Validation loss: 1.9869065156546972

Epoch: 6| Step: 6
Training loss: 0.6746024489402771
Validation loss: 1.9724403324947561

Epoch: 6| Step: 7
Training loss: 1.4488894939422607
Validation loss: 2.007400346058671

Epoch: 6| Step: 8
Training loss: 1.4670867919921875
Validation loss: 2.0040920190913702

Epoch: 6| Step: 9
Training loss: 1.227776050567627
Validation loss: 2.005784652566397

Epoch: 6| Step: 10
Training loss: 1.6337367296218872
Validation loss: 1.9914236940363401

Epoch: 6| Step: 11
Training loss: 1.4964349269866943
Validation loss: 1.994692874211137

Epoch: 6| Step: 12
Training loss: 1.1429661512374878
Validation loss: 1.9842179962383804

Epoch: 6| Step: 13
Training loss: 0.8306717276573181
Validation loss: 1.9608777376913256

Epoch: 222| Step: 0
Training loss: 1.205533504486084
Validation loss: 1.96212564873439

Epoch: 6| Step: 1
Training loss: 1.3710081577301025
Validation loss: 1.9291280290131927

Epoch: 6| Step: 2
Training loss: 1.113208532333374
Validation loss: 1.9379361111630675

Epoch: 6| Step: 3
Training loss: 1.308659315109253
Validation loss: 1.935614211584932

Epoch: 6| Step: 4
Training loss: 1.3674068450927734
Validation loss: 1.920275959917294

Epoch: 6| Step: 5
Training loss: 1.5760126113891602
Validation loss: 1.9428329852319532

Epoch: 6| Step: 6
Training loss: 0.8491911292076111
Validation loss: 1.9329736373757804

Epoch: 6| Step: 7
Training loss: 1.4042364358901978
Validation loss: 1.9377330208337435

Epoch: 6| Step: 8
Training loss: 1.9362187385559082
Validation loss: 1.9785734761145808

Epoch: 6| Step: 9
Training loss: 1.621882438659668
Validation loss: 1.9787114051080519

Epoch: 6| Step: 10
Training loss: 1.4134413003921509
Validation loss: 2.0028741154619443

Epoch: 6| Step: 11
Training loss: 1.6734504699707031
Validation loss: 2.012111258763139

Epoch: 6| Step: 12
Training loss: 1.2435321807861328
Validation loss: 1.9956110933775544

Epoch: 6| Step: 13
Training loss: 1.4706107378005981
Validation loss: 1.9804235735247213

Epoch: 223| Step: 0
Training loss: 1.3020657300949097
Validation loss: 1.9597594994370655

Epoch: 6| Step: 1
Training loss: 0.9996777176856995
Validation loss: 1.9683795282917638

Epoch: 6| Step: 2
Training loss: 1.799133539199829
Validation loss: 1.9456377388328634

Epoch: 6| Step: 3
Training loss: 1.8228089809417725
Validation loss: 1.9650481452224076

Epoch: 6| Step: 4
Training loss: 1.5828406810760498
Validation loss: 1.965301949490783

Epoch: 6| Step: 5
Training loss: 1.1034440994262695
Validation loss: 1.973811585416076

Epoch: 6| Step: 6
Training loss: 0.9041821360588074
Validation loss: 1.981290772397031

Epoch: 6| Step: 7
Training loss: 1.664677619934082
Validation loss: 1.96693076497765

Epoch: 6| Step: 8
Training loss: 1.6357979774475098
Validation loss: 1.9688996422675349

Epoch: 6| Step: 9
Training loss: 1.5160366296768188
Validation loss: 1.9626096115317395

Epoch: 6| Step: 10
Training loss: 1.8795698881149292
Validation loss: 1.9371263365591727

Epoch: 6| Step: 11
Training loss: 0.9355667233467102
Validation loss: 1.9284639563611758

Epoch: 6| Step: 12
Training loss: 1.116991639137268
Validation loss: 1.9313997055894585

Epoch: 6| Step: 13
Training loss: 1.2771220207214355
Validation loss: 1.9030659608943488

Epoch: 224| Step: 0
Training loss: 1.2657079696655273
Validation loss: 1.9036292658057263

Epoch: 6| Step: 1
Training loss: 0.9987996816635132
Validation loss: 1.9162172860996698

Epoch: 6| Step: 2
Training loss: 1.2510648965835571
Validation loss: 1.9085019480797552

Epoch: 6| Step: 3
Training loss: 1.6432685852050781
Validation loss: 1.920202188594367

Epoch: 6| Step: 4
Training loss: 1.1121219396591187
Validation loss: 1.9409595535647484

Epoch: 6| Step: 5
Training loss: 1.5544941425323486
Validation loss: 1.9652366971456876

Epoch: 6| Step: 6
Training loss: 1.4801243543624878
Validation loss: 1.9791796361246417

Epoch: 6| Step: 7
Training loss: 1.0885682106018066
Validation loss: 1.9889812892483127

Epoch: 6| Step: 8
Training loss: 1.2925167083740234
Validation loss: 1.9919648913926975

Epoch: 6| Step: 9
Training loss: 1.561509132385254
Validation loss: 1.978951399044324

Epoch: 6| Step: 10
Training loss: 1.0225818157196045
Validation loss: 1.9704566104437715

Epoch: 6| Step: 11
Training loss: 1.6725155115127563
Validation loss: 1.9749592658012145

Epoch: 6| Step: 12
Training loss: 1.9597017765045166
Validation loss: 1.9651482002709502

Epoch: 6| Step: 13
Training loss: 2.03426194190979
Validation loss: 1.9523175121635519

Epoch: 225| Step: 0
Training loss: 1.350257396697998
Validation loss: 1.9637684309354393

Epoch: 6| Step: 1
Training loss: 1.1006901264190674
Validation loss: 1.9409992310308641

Epoch: 6| Step: 2
Training loss: 1.258854627609253
Validation loss: 1.934623408061202

Epoch: 6| Step: 3
Training loss: 1.2240283489227295
Validation loss: 1.9446217731762958

Epoch: 6| Step: 4
Training loss: 1.7996268272399902
Validation loss: 1.9914929687335927

Epoch: 6| Step: 5
Training loss: 2.181462287902832
Validation loss: 2.013420452353775

Epoch: 6| Step: 6
Training loss: 1.7219980955123901
Validation loss: 2.0410715469750027

Epoch: 6| Step: 7
Training loss: 1.5009899139404297
Validation loss: 2.0366012075895905

Epoch: 6| Step: 8
Training loss: 0.7473048567771912
Validation loss: 2.029943927641838

Epoch: 6| Step: 9
Training loss: 1.4142096042633057
Validation loss: 1.992970279468003

Epoch: 6| Step: 10
Training loss: 0.950265109539032
Validation loss: 1.9362176823359665

Epoch: 6| Step: 11
Training loss: 1.5470905303955078
Validation loss: 1.9275118099745883

Epoch: 6| Step: 12
Training loss: 1.4207096099853516
Validation loss: 1.9375004447916502

Epoch: 6| Step: 13
Training loss: 1.319629192352295
Validation loss: 1.9314257752510808

Epoch: 226| Step: 0
Training loss: 0.8234307765960693
Validation loss: 1.9218633585078742

Epoch: 6| Step: 1
Training loss: 2.0722665786743164
Validation loss: 1.9071208251419889

Epoch: 6| Step: 2
Training loss: 1.7420183420181274
Validation loss: 1.917559080226447

Epoch: 6| Step: 3
Training loss: 0.9897928237915039
Validation loss: 1.9448271310457619

Epoch: 6| Step: 4
Training loss: 1.1198160648345947
Validation loss: 1.9719024217256935

Epoch: 6| Step: 5
Training loss: 1.0244722366333008
Validation loss: 1.9993199956032537

Epoch: 6| Step: 6
Training loss: 1.7269465923309326
Validation loss: 1.9839757347619662

Epoch: 6| Step: 7
Training loss: 0.9342159628868103
Validation loss: 1.9629805062406807

Epoch: 6| Step: 8
Training loss: 1.269557237625122
Validation loss: 1.9212994537045878

Epoch: 6| Step: 9
Training loss: 1.1642895936965942
Validation loss: 1.931384790328241

Epoch: 6| Step: 10
Training loss: 1.6001231670379639
Validation loss: 1.942520591520494

Epoch: 6| Step: 11
Training loss: 1.931696891784668
Validation loss: 1.9232697589423067

Epoch: 6| Step: 12
Training loss: 1.367694616317749
Validation loss: 1.913760035268722

Epoch: 6| Step: 13
Training loss: 2.228644371032715
Validation loss: 1.9452657622675742

Epoch: 227| Step: 0
Training loss: 1.4873335361480713
Validation loss: 1.9471300827559603

Epoch: 6| Step: 1
Training loss: 1.5918508768081665
Validation loss: 1.9682325111922396

Epoch: 6| Step: 2
Training loss: 0.718164324760437
Validation loss: 1.9751400024660173

Epoch: 6| Step: 3
Training loss: 1.5666747093200684
Validation loss: 1.9797156805633216

Epoch: 6| Step: 4
Training loss: 1.4072768688201904
Validation loss: 1.9984897439197828

Epoch: 6| Step: 5
Training loss: 0.9778143167495728
Validation loss: 1.9933335909279444

Epoch: 6| Step: 6
Training loss: 1.5763099193572998
Validation loss: 1.9739745457967122

Epoch: 6| Step: 7
Training loss: 1.3092970848083496
Validation loss: 1.9621384195102158

Epoch: 6| Step: 8
Training loss: 0.957025945186615
Validation loss: 1.9635802584309732

Epoch: 6| Step: 9
Training loss: 1.53281831741333
Validation loss: 1.952774135015344

Epoch: 6| Step: 10
Training loss: 1.197823405265808
Validation loss: 1.945047237539804

Epoch: 6| Step: 11
Training loss: 2.014671802520752
Validation loss: 1.9557006615464405

Epoch: 6| Step: 12
Training loss: 1.1344499588012695
Validation loss: 1.9498253304471251

Epoch: 6| Step: 13
Training loss: 2.187821388244629
Validation loss: 1.9619227737508795

Epoch: 228| Step: 0
Training loss: 1.2383613586425781
Validation loss: 1.9454042770529305

Epoch: 6| Step: 1
Training loss: 1.3756264448165894
Validation loss: 1.9723919565959642

Epoch: 6| Step: 2
Training loss: 1.786590576171875
Validation loss: 1.9852040019086612

Epoch: 6| Step: 3
Training loss: 0.9412127733230591
Validation loss: 1.9892401387614589

Epoch: 6| Step: 4
Training loss: 1.7634201049804688
Validation loss: 1.989397213023196

Epoch: 6| Step: 5
Training loss: 1.6800174713134766
Validation loss: 1.974625414417636

Epoch: 6| Step: 6
Training loss: 0.9333146810531616
Validation loss: 1.9502154960427234

Epoch: 6| Step: 7
Training loss: 1.279921531677246
Validation loss: 1.9263096727350706

Epoch: 6| Step: 8
Training loss: 1.0907886028289795
Validation loss: 1.9324074035049768

Epoch: 6| Step: 9
Training loss: 1.0271780490875244
Validation loss: 1.9322006240967782

Epoch: 6| Step: 10
Training loss: 1.7177293300628662
Validation loss: 1.930004209600469

Epoch: 6| Step: 11
Training loss: 1.0386958122253418
Validation loss: 1.9451561781667894

Epoch: 6| Step: 12
Training loss: 1.5793343782424927
Validation loss: 1.9719491235671505

Epoch: 6| Step: 13
Training loss: 1.9187602996826172
Validation loss: 1.9928152971370245

Epoch: 229| Step: 0
Training loss: 1.381565809249878
Validation loss: 1.9729793687020578

Epoch: 6| Step: 1
Training loss: 1.6414819955825806
Validation loss: 1.9902181471547773

Epoch: 6| Step: 2
Training loss: 1.4127421379089355
Validation loss: 1.973832179141301

Epoch: 6| Step: 3
Training loss: 1.4855955839157104
Validation loss: 1.979500223231572

Epoch: 6| Step: 4
Training loss: 1.4072225093841553
Validation loss: 1.98195223141742

Epoch: 6| Step: 5
Training loss: 1.1662464141845703
Validation loss: 1.9654355549043225

Epoch: 6| Step: 6
Training loss: 1.7048912048339844
Validation loss: 1.9496937977370394

Epoch: 6| Step: 7
Training loss: 1.2378708124160767
Validation loss: 1.9402919828250844

Epoch: 6| Step: 8
Training loss: 1.6193653345108032
Validation loss: 1.9068978832614036

Epoch: 6| Step: 9
Training loss: 1.4977171421051025
Validation loss: 1.933916844347472

Epoch: 6| Step: 10
Training loss: 1.1361123323440552
Validation loss: 1.9833508050569923

Epoch: 6| Step: 11
Training loss: 1.2591471672058105
Validation loss: 2.0039629385035527

Epoch: 6| Step: 12
Training loss: 0.7052420377731323
Validation loss: 2.035257600968884

Epoch: 6| Step: 13
Training loss: 2.0865345001220703
Validation loss: 2.0569639436660276

Epoch: 230| Step: 0
Training loss: 1.2123092412948608
Validation loss: 1.9970871197280062

Epoch: 6| Step: 1
Training loss: 0.8806939721107483
Validation loss: 1.9321441317117343

Epoch: 6| Step: 2
Training loss: 1.5425574779510498
Validation loss: 1.9269546437007126

Epoch: 6| Step: 3
Training loss: 0.9247772693634033
Validation loss: 1.9419185935810048

Epoch: 6| Step: 4
Training loss: 1.5377434492111206
Validation loss: 1.9360677990862118

Epoch: 6| Step: 5
Training loss: 1.3251054286956787
Validation loss: 1.935272414197204

Epoch: 6| Step: 6
Training loss: 1.5099711418151855
Validation loss: 1.9237972049302952

Epoch: 6| Step: 7
Training loss: 1.5107226371765137
Validation loss: 1.9370717528045818

Epoch: 6| Step: 8
Training loss: 1.7390062808990479
Validation loss: 1.970789804253527

Epoch: 6| Step: 9
Training loss: 1.688239336013794
Validation loss: 2.018513734622668

Epoch: 6| Step: 10
Training loss: 1.2761372327804565
Validation loss: 2.0306488801074285

Epoch: 6| Step: 11
Training loss: 1.6193962097167969
Validation loss: 2.015303119536369

Epoch: 6| Step: 12
Training loss: 1.145726203918457
Validation loss: 1.9952914753267843

Epoch: 6| Step: 13
Training loss: 1.2838579416275024
Validation loss: 1.9875465516121156

Epoch: 231| Step: 0
Training loss: 1.2662452459335327
Validation loss: 1.9748988484823575

Epoch: 6| Step: 1
Training loss: 1.674630880355835
Validation loss: 1.94065389966452

Epoch: 6| Step: 2
Training loss: 1.1580257415771484
Validation loss: 1.9051735657517628

Epoch: 6| Step: 3
Training loss: 1.531854510307312
Validation loss: 1.8969719538124659

Epoch: 6| Step: 4
Training loss: 1.9915369749069214
Validation loss: 1.8936298995889642

Epoch: 6| Step: 5
Training loss: 0.8737359642982483
Validation loss: 1.9136011203130086

Epoch: 6| Step: 6
Training loss: 1.1348391771316528
Validation loss: 1.947770248177231

Epoch: 6| Step: 7
Training loss: 1.563804268836975
Validation loss: 2.0172783943914596

Epoch: 6| Step: 8
Training loss: 1.8093981742858887
Validation loss: 2.0317216047676663

Epoch: 6| Step: 9
Training loss: 1.4143446683883667
Validation loss: 2.0070297025865123

Epoch: 6| Step: 10
Training loss: 1.3246971368789673
Validation loss: 2.0065630289816085

Epoch: 6| Step: 11
Training loss: 1.5445327758789062
Validation loss: 1.9707521289907477

Epoch: 6| Step: 12
Training loss: 0.6860482692718506
Validation loss: 1.9632659445526779

Epoch: 6| Step: 13
Training loss: 1.415578007698059
Validation loss: 1.9293814384809105

Epoch: 232| Step: 0
Training loss: 1.7320635318756104
Validation loss: 1.902096280487635

Epoch: 6| Step: 1
Training loss: 1.4392588138580322
Validation loss: 1.9046286741892497

Epoch: 6| Step: 2
Training loss: 1.4955639839172363
Validation loss: 1.9040599458961076

Epoch: 6| Step: 3
Training loss: 1.293108582496643
Validation loss: 1.89986712701859

Epoch: 6| Step: 4
Training loss: 0.7019374370574951
Validation loss: 1.8987733715323991

Epoch: 6| Step: 5
Training loss: 1.7060099840164185
Validation loss: 1.914279157115567

Epoch: 6| Step: 6
Training loss: 1.5202131271362305
Validation loss: 1.9147417673500635

Epoch: 6| Step: 7
Training loss: 1.4361382722854614
Validation loss: 1.946891810304375

Epoch: 6| Step: 8
Training loss: 0.7345049977302551
Validation loss: 1.960391665017733

Epoch: 6| Step: 9
Training loss: 1.423806071281433
Validation loss: 1.9955383500745218

Epoch: 6| Step: 10
Training loss: 1.2497745752334595
Validation loss: 1.9846953294610465

Epoch: 6| Step: 11
Training loss: 1.4069290161132812
Validation loss: 1.9456070969181676

Epoch: 6| Step: 12
Training loss: 2.056454658508301
Validation loss: 1.9245513998052126

Epoch: 6| Step: 13
Training loss: 0.795633852481842
Validation loss: 1.9131161833322177

Epoch: 233| Step: 0
Training loss: 1.4958438873291016
Validation loss: 1.9315892932235554

Epoch: 6| Step: 1
Training loss: 0.8330280780792236
Validation loss: 1.9544409039199993

Epoch: 6| Step: 2
Training loss: 1.1427795886993408
Validation loss: 1.9265801791221864

Epoch: 6| Step: 3
Training loss: 1.8154633045196533
Validation loss: 1.9360819990916918

Epoch: 6| Step: 4
Training loss: 1.3109853267669678
Validation loss: 1.9350283274086573

Epoch: 6| Step: 5
Training loss: 1.331511378288269
Validation loss: 1.9405854671232161

Epoch: 6| Step: 6
Training loss: 1.1792607307434082
Validation loss: 1.9508479884875718

Epoch: 6| Step: 7
Training loss: 1.0340080261230469
Validation loss: 1.9480518269282516

Epoch: 6| Step: 8
Training loss: 1.8903409242630005
Validation loss: 1.95036865562521

Epoch: 6| Step: 9
Training loss: 0.9087981581687927
Validation loss: 1.921527877930672

Epoch: 6| Step: 10
Training loss: 1.7776727676391602
Validation loss: 1.9134466673738213

Epoch: 6| Step: 11
Training loss: 1.1193201541900635
Validation loss: 1.8888216044313164

Epoch: 6| Step: 12
Training loss: 1.6295363903045654
Validation loss: 1.8894489939494798

Epoch: 6| Step: 13
Training loss: 1.4535784721374512
Validation loss: 1.8773743247473111

Epoch: 234| Step: 0
Training loss: 0.8958691358566284
Validation loss: 1.9060409504880187

Epoch: 6| Step: 1
Training loss: 1.5860247611999512
Validation loss: 1.914146702776673

Epoch: 6| Step: 2
Training loss: 0.9204564690589905
Validation loss: 1.960167702808175

Epoch: 6| Step: 3
Training loss: 1.081539273262024
Validation loss: 2.008353171810027

Epoch: 6| Step: 4
Training loss: 1.7605892419815063
Validation loss: 2.011873952804073

Epoch: 6| Step: 5
Training loss: 1.5322120189666748
Validation loss: 2.0181178905630626

Epoch: 6| Step: 6
Training loss: 0.6978236436843872
Validation loss: 1.9970530797076482

Epoch: 6| Step: 7
Training loss: 0.7520527243614197
Validation loss: 2.0297517571398007

Epoch: 6| Step: 8
Training loss: 1.4425346851348877
Validation loss: 1.974955638249715

Epoch: 6| Step: 9
Training loss: 1.4305806159973145
Validation loss: 1.929383941875991

Epoch: 6| Step: 10
Training loss: 1.8562170267105103
Validation loss: 1.908546809227236

Epoch: 6| Step: 11
Training loss: 1.6252553462982178
Validation loss: 1.9215292084601618

Epoch: 6| Step: 12
Training loss: 1.65632963180542
Validation loss: 1.9165925851432226

Epoch: 6| Step: 13
Training loss: 1.2224774360656738
Validation loss: 1.9112183727243894

Epoch: 235| Step: 0
Training loss: 1.6415541172027588
Validation loss: 1.9216578647654543

Epoch: 6| Step: 1
Training loss: 1.2100791931152344
Validation loss: 1.9131577143105127

Epoch: 6| Step: 2
Training loss: 1.2463197708129883
Validation loss: 1.9126797299231253

Epoch: 6| Step: 3
Training loss: 2.01543927192688
Validation loss: 1.9161586633292578

Epoch: 6| Step: 4
Training loss: 0.8741505146026611
Validation loss: 1.9401830524526618

Epoch: 6| Step: 5
Training loss: 1.3835117816925049
Validation loss: 1.9348041113986765

Epoch: 6| Step: 6
Training loss: 1.020392656326294
Validation loss: 1.9314778581742318

Epoch: 6| Step: 7
Training loss: 1.3119120597839355
Validation loss: 1.946099901712069

Epoch: 6| Step: 8
Training loss: 1.7567012310028076
Validation loss: 1.9782994536943332

Epoch: 6| Step: 9
Training loss: 1.2822916507720947
Validation loss: 1.998093133331627

Epoch: 6| Step: 10
Training loss: 1.341634750366211
Validation loss: 2.0220104135492796

Epoch: 6| Step: 11
Training loss: 0.9346850514411926
Validation loss: 1.976310988908173

Epoch: 6| Step: 12
Training loss: 1.2583293914794922
Validation loss: 1.9459879705982823

Epoch: 6| Step: 13
Training loss: 0.9838530421257019
Validation loss: 1.90920187452788

Epoch: 236| Step: 0
Training loss: 1.6893184185028076
Validation loss: 1.8906784262708438

Epoch: 6| Step: 1
Training loss: 1.7151334285736084
Validation loss: 1.9211111414817073

Epoch: 6| Step: 2
Training loss: 0.9922991991043091
Validation loss: 1.9175200564886934

Epoch: 6| Step: 3
Training loss: 0.8244413137435913
Validation loss: 1.9069414664340276

Epoch: 6| Step: 4
Training loss: 1.9809715747833252
Validation loss: 1.9194940033779349

Epoch: 6| Step: 5
Training loss: 0.7381176948547363
Validation loss: 1.9147237949473883

Epoch: 6| Step: 6
Training loss: 0.9298079013824463
Validation loss: 1.9326955720942507

Epoch: 6| Step: 7
Training loss: 1.2479989528656006
Validation loss: 1.9312680587973645

Epoch: 6| Step: 8
Training loss: 1.5355833768844604
Validation loss: 1.9779179096221924

Epoch: 6| Step: 9
Training loss: 1.2840752601623535
Validation loss: 2.0009917392525622

Epoch: 6| Step: 10
Training loss: 1.4909396171569824
Validation loss: 2.0366722563261628

Epoch: 6| Step: 11
Training loss: 1.1849538087844849
Validation loss: 2.0239829952998827

Epoch: 6| Step: 12
Training loss: 1.6424434185028076
Validation loss: 2.031224444348325

Epoch: 6| Step: 13
Training loss: 1.0664740800857544
Validation loss: 1.9313953384276359

Epoch: 237| Step: 0
Training loss: 1.7527657747268677
Validation loss: 1.8885960091826737

Epoch: 6| Step: 1
Training loss: 1.253082275390625
Validation loss: 1.8860680326338737

Epoch: 6| Step: 2
Training loss: 1.6073845624923706
Validation loss: 1.8903231184969667

Epoch: 6| Step: 3
Training loss: 1.7425274848937988
Validation loss: 1.8872882845581218

Epoch: 6| Step: 4
Training loss: 1.500584363937378
Validation loss: 1.8914249417602376

Epoch: 6| Step: 5
Training loss: 0.8564289212226868
Validation loss: 1.8725685445211266

Epoch: 6| Step: 6
Training loss: 0.8442211747169495
Validation loss: 1.9243646014121272

Epoch: 6| Step: 7
Training loss: 0.9760411381721497
Validation loss: 1.9611678456747403

Epoch: 6| Step: 8
Training loss: 0.8713849186897278
Validation loss: 2.0138546395045456

Epoch: 6| Step: 9
Training loss: 1.3450833559036255
Validation loss: 2.0036149691509944

Epoch: 6| Step: 10
Training loss: 1.2777900695800781
Validation loss: 2.0166269386968305

Epoch: 6| Step: 11
Training loss: 1.3207398653030396
Validation loss: 1.9714794235844766

Epoch: 6| Step: 12
Training loss: 1.8907618522644043
Validation loss: 1.9549951386708084

Epoch: 6| Step: 13
Training loss: 1.1352320909500122
Validation loss: 1.9201929005243445

Epoch: 238| Step: 0
Training loss: 1.6501147747039795
Validation loss: 1.93421959236104

Epoch: 6| Step: 1
Training loss: 0.9059857130050659
Validation loss: 1.9125477703668738

Epoch: 6| Step: 2
Training loss: 1.4168941974639893
Validation loss: 1.9093826099108624

Epoch: 6| Step: 3
Training loss: 1.4912357330322266
Validation loss: 1.9051637059898787

Epoch: 6| Step: 4
Training loss: 1.0435235500335693
Validation loss: 1.9118544158115183

Epoch: 6| Step: 5
Training loss: 1.5090179443359375
Validation loss: 1.8872634364712624

Epoch: 6| Step: 6
Training loss: 1.0804789066314697
Validation loss: 1.9303892863694059

Epoch: 6| Step: 7
Training loss: 1.526328206062317
Validation loss: 1.9578874713631087

Epoch: 6| Step: 8
Training loss: 1.155851125717163
Validation loss: 1.967335416424659

Epoch: 6| Step: 9
Training loss: 1.125997543334961
Validation loss: 1.9600075598685973

Epoch: 6| Step: 10
Training loss: 1.4675737619400024
Validation loss: 1.9403731874240342

Epoch: 6| Step: 11
Training loss: 1.1142317056655884
Validation loss: 1.8891936937967937

Epoch: 6| Step: 12
Training loss: 1.3243093490600586
Validation loss: 1.8777111819995347

Epoch: 6| Step: 13
Training loss: 1.5055060386657715
Validation loss: 1.8726941603486256

Epoch: 239| Step: 0
Training loss: 0.8332986831665039
Validation loss: 1.855785822355619

Epoch: 6| Step: 1
Training loss: 1.5274407863616943
Validation loss: 1.8783544096895444

Epoch: 6| Step: 2
Training loss: 1.718157410621643
Validation loss: 1.8800810472939604

Epoch: 6| Step: 3
Training loss: 1.3314592838287354
Validation loss: 1.9238256216049194

Epoch: 6| Step: 4
Training loss: 1.2493443489074707
Validation loss: 1.9605274879804222

Epoch: 6| Step: 5
Training loss: 1.88290536403656
Validation loss: 1.9369452845665716

Epoch: 6| Step: 6
Training loss: 1.3330597877502441
Validation loss: 1.9033477498639015

Epoch: 6| Step: 7
Training loss: 0.9289836883544922
Validation loss: 1.8713694798049105

Epoch: 6| Step: 8
Training loss: 1.4424055814743042
Validation loss: 1.8718891630890548

Epoch: 6| Step: 9
Training loss: 1.2770329713821411
Validation loss: 1.8801354990210584

Epoch: 6| Step: 10
Training loss: 0.9662275910377502
Validation loss: 1.8720761473460863

Epoch: 6| Step: 11
Training loss: 1.3554987907409668
Validation loss: 1.8625430342971638

Epoch: 6| Step: 12
Training loss: 1.2080824375152588
Validation loss: 1.8958514428907824

Epoch: 6| Step: 13
Training loss: 0.910709798336029
Validation loss: 1.8930297769525999

Epoch: 240| Step: 0
Training loss: 1.5469863414764404
Validation loss: 1.884298659140064

Epoch: 6| Step: 1
Training loss: 1.2685655355453491
Validation loss: 1.8919850293026175

Epoch: 6| Step: 2
Training loss: 1.2344988584518433
Validation loss: 1.9215936994039884

Epoch: 6| Step: 3
Training loss: 0.9933924674987793
Validation loss: 1.914837533427823

Epoch: 6| Step: 4
Training loss: 1.6390807628631592
Validation loss: 1.9021883882502073

Epoch: 6| Step: 5
Training loss: 0.9027708768844604
Validation loss: 1.8769973990737752

Epoch: 6| Step: 6
Training loss: 1.5031625032424927
Validation loss: 1.8834444040893226

Epoch: 6| Step: 7
Training loss: 1.868943452835083
Validation loss: 1.878811179950673

Epoch: 6| Step: 8
Training loss: 1.034794569015503
Validation loss: 1.888083255419167

Epoch: 6| Step: 9
Training loss: 1.2663121223449707
Validation loss: 1.876152250074571

Epoch: 6| Step: 10
Training loss: 1.107116937637329
Validation loss: 1.8742914584375197

Epoch: 6| Step: 11
Training loss: 1.5419751405715942
Validation loss: 1.8774570572760798

Epoch: 6| Step: 12
Training loss: 0.760581910610199
Validation loss: 1.900062717417235

Epoch: 6| Step: 13
Training loss: 1.242159128189087
Validation loss: 1.9319540967223465

Epoch: 241| Step: 0
Training loss: 1.1810986995697021
Validation loss: 1.908873035061744

Epoch: 6| Step: 1
Training loss: 2.195903778076172
Validation loss: 1.9142486562011063

Epoch: 6| Step: 2
Training loss: 1.4683411121368408
Validation loss: 1.9042603200481785

Epoch: 6| Step: 3
Training loss: 1.0373103618621826
Validation loss: 1.915652959577499

Epoch: 6| Step: 4
Training loss: 1.0076032876968384
Validation loss: 1.8969330480021815

Epoch: 6| Step: 5
Training loss: 0.39122748374938965
Validation loss: 1.8932263953711397

Epoch: 6| Step: 6
Training loss: 1.5021576881408691
Validation loss: 1.8792058601174304

Epoch: 6| Step: 7
Training loss: 1.1102502346038818
Validation loss: 1.9321825440211962

Epoch: 6| Step: 8
Training loss: 1.8071249723434448
Validation loss: 1.9211398119567542

Epoch: 6| Step: 9
Training loss: 1.3572297096252441
Validation loss: 1.9306693538542716

Epoch: 6| Step: 10
Training loss: 1.0991404056549072
Validation loss: 1.9174690708037345

Epoch: 6| Step: 11
Training loss: 1.1805462837219238
Validation loss: 1.9030851933263964

Epoch: 6| Step: 12
Training loss: 1.2798312902450562
Validation loss: 1.9140439776964084

Epoch: 6| Step: 13
Training loss: 1.3684499263763428
Validation loss: 1.9530560073032175

Epoch: 242| Step: 0
Training loss: 1.5730364322662354
Validation loss: 1.9704086972821144

Epoch: 6| Step: 1
Training loss: 0.7586014270782471
Validation loss: 2.0045558021914576

Epoch: 6| Step: 2
Training loss: 0.8501867055892944
Validation loss: 2.00179898354315

Epoch: 6| Step: 3
Training loss: 0.5601586103439331
Validation loss: 1.963323793103618

Epoch: 6| Step: 4
Training loss: 1.4338793754577637
Validation loss: 1.9240844031815887

Epoch: 6| Step: 5
Training loss: 1.449981689453125
Validation loss: 1.8999162848277757

Epoch: 6| Step: 6
Training loss: 0.7899278402328491
Validation loss: 1.915889310580428

Epoch: 6| Step: 7
Training loss: 1.1963939666748047
Validation loss: 1.8985032650732225

Epoch: 6| Step: 8
Training loss: 1.2389264106750488
Validation loss: 1.909180110500705

Epoch: 6| Step: 9
Training loss: 2.3048720359802246
Validation loss: 1.9007025713561683

Epoch: 6| Step: 10
Training loss: 1.2666348218917847
Validation loss: 1.9227187043877059

Epoch: 6| Step: 11
Training loss: 1.640268087387085
Validation loss: 1.9536660127742316

Epoch: 6| Step: 12
Training loss: 1.0924960374832153
Validation loss: 1.9856940520706998

Epoch: 6| Step: 13
Training loss: 1.8189778327941895
Validation loss: 1.9809034485970773

Epoch: 243| Step: 0
Training loss: 1.2208603620529175
Validation loss: 1.9483126286537416

Epoch: 6| Step: 1
Training loss: 0.9603835940361023
Validation loss: 1.9140925125409198

Epoch: 6| Step: 2
Training loss: 1.3882696628570557
Validation loss: 1.8844122976385138

Epoch: 6| Step: 3
Training loss: 1.2657623291015625
Validation loss: 1.8772804326908563

Epoch: 6| Step: 4
Training loss: 1.3481099605560303
Validation loss: 1.9078946959587835

Epoch: 6| Step: 5
Training loss: 0.7328557372093201
Validation loss: 1.9164062033417404

Epoch: 6| Step: 6
Training loss: 0.9487893581390381
Validation loss: 1.9120841205760997

Epoch: 6| Step: 7
Training loss: 0.8295480012893677
Validation loss: 1.9228561924349876

Epoch: 6| Step: 8
Training loss: 1.1446597576141357
Validation loss: 1.9643648657747494

Epoch: 6| Step: 9
Training loss: 1.4043028354644775
Validation loss: 1.9678599321714012

Epoch: 6| Step: 10
Training loss: 1.6236436367034912
Validation loss: 1.9759995655346942

Epoch: 6| Step: 11
Training loss: 1.7094736099243164
Validation loss: 1.9345581198251376

Epoch: 6| Step: 12
Training loss: 1.7041552066802979
Validation loss: 1.9304748260846702

Epoch: 6| Step: 13
Training loss: 1.2981829643249512
Validation loss: 1.8804706476067985

Epoch: 244| Step: 0
Training loss: 1.0407350063323975
Validation loss: 1.8501929031905306

Epoch: 6| Step: 1
Training loss: 1.7218892574310303
Validation loss: 1.8538885001213319

Epoch: 6| Step: 2
Training loss: 1.4449541568756104
Validation loss: 1.8704920122700353

Epoch: 6| Step: 3
Training loss: 0.9746189117431641
Validation loss: 1.8753798148965324

Epoch: 6| Step: 4
Training loss: 1.188159704208374
Validation loss: 1.906766741506515

Epoch: 6| Step: 5
Training loss: 1.645445704460144
Validation loss: 1.938890440489656

Epoch: 6| Step: 6
Training loss: 1.0110657215118408
Validation loss: 1.9737758508292578

Epoch: 6| Step: 7
Training loss: 1.3453431129455566
Validation loss: 1.9797454764766078

Epoch: 6| Step: 8
Training loss: 1.4033994674682617
Validation loss: 1.9629790911110498

Epoch: 6| Step: 9
Training loss: 1.4266548156738281
Validation loss: 1.9526598607340167

Epoch: 6| Step: 10
Training loss: 1.2311272621154785
Validation loss: 1.901219142380581

Epoch: 6| Step: 11
Training loss: 0.5229825973510742
Validation loss: 1.8460483192115702

Epoch: 6| Step: 12
Training loss: 1.0355193614959717
Validation loss: 1.8340699044607018

Epoch: 6| Step: 13
Training loss: 1.788318157196045
Validation loss: 1.8369020274890366

Epoch: 245| Step: 0
Training loss: 1.1086786985397339
Validation loss: 1.8401069692386094

Epoch: 6| Step: 1
Training loss: 1.818145751953125
Validation loss: 1.8316755615254885

Epoch: 6| Step: 2
Training loss: 1.4297865629196167
Validation loss: 1.8028182573215936

Epoch: 6| Step: 3
Training loss: 1.1980212926864624
Validation loss: 1.8363056528952815

Epoch: 6| Step: 4
Training loss: 1.392091989517212
Validation loss: 1.8804563168556458

Epoch: 6| Step: 5
Training loss: 1.4240870475769043
Validation loss: 1.9266050656636555

Epoch: 6| Step: 6
Training loss: 1.1355453729629517
Validation loss: 1.9443031177725842

Epoch: 6| Step: 7
Training loss: 1.5021030902862549
Validation loss: 1.969709728353767

Epoch: 6| Step: 8
Training loss: 1.074276328086853
Validation loss: 1.9559172212436635

Epoch: 6| Step: 9
Training loss: 1.0041358470916748
Validation loss: 1.9491148661541682

Epoch: 6| Step: 10
Training loss: 1.4208440780639648
Validation loss: 1.9253789083932036

Epoch: 6| Step: 11
Training loss: 0.9071763753890991
Validation loss: 1.934775060222995

Epoch: 6| Step: 12
Training loss: 0.9439477920532227
Validation loss: 1.917195450875067

Epoch: 6| Step: 13
Training loss: 1.067577600479126
Validation loss: 1.9170649731031029

Epoch: 246| Step: 0
Training loss: 1.5089399814605713
Validation loss: 1.9000847467812159

Epoch: 6| Step: 1
Training loss: 1.3280768394470215
Validation loss: 1.888170349982477

Epoch: 6| Step: 2
Training loss: 0.9467008709907532
Validation loss: 1.9040910851570867

Epoch: 6| Step: 3
Training loss: 0.9986357688903809
Validation loss: 1.913916294292737

Epoch: 6| Step: 4
Training loss: 1.3871028423309326
Validation loss: 1.9483053274052118

Epoch: 6| Step: 5
Training loss: 0.978865385055542
Validation loss: 1.9562695372489192

Epoch: 6| Step: 6
Training loss: 1.0531455278396606
Validation loss: 1.9775383895443333

Epoch: 6| Step: 7
Training loss: 1.4263684749603271
Validation loss: 1.990346134349864

Epoch: 6| Step: 8
Training loss: 1.0078184604644775
Validation loss: 1.9296063095010736

Epoch: 6| Step: 9
Training loss: 1.4926304817199707
Validation loss: 1.8747044917075866

Epoch: 6| Step: 10
Training loss: 1.339933156967163
Validation loss: 1.8478107042210077

Epoch: 6| Step: 11
Training loss: 1.0874080657958984
Validation loss: 1.854497371181365

Epoch: 6| Step: 12
Training loss: 1.1258280277252197
Validation loss: 1.8508178239227624

Epoch: 6| Step: 13
Training loss: 2.052570343017578
Validation loss: 1.8521033076829807

Epoch: 247| Step: 0
Training loss: 1.0245952606201172
Validation loss: 1.8663674118698284

Epoch: 6| Step: 1
Training loss: 0.9957176446914673
Validation loss: 1.871239508351972

Epoch: 6| Step: 2
Training loss: 1.0058932304382324
Validation loss: 1.9001605408166045

Epoch: 6| Step: 3
Training loss: 0.9959612488746643
Validation loss: 1.9002796898606003

Epoch: 6| Step: 4
Training loss: 0.9706229567527771
Validation loss: 1.93439664635607

Epoch: 6| Step: 5
Training loss: 1.4078304767608643
Validation loss: 1.971872962931151

Epoch: 6| Step: 6
Training loss: 1.331099033355713
Validation loss: 2.0093234751814153

Epoch: 6| Step: 7
Training loss: 1.515932321548462
Validation loss: 2.0104112932758946

Epoch: 6| Step: 8
Training loss: 1.4065027236938477
Validation loss: 1.972099458017657

Epoch: 6| Step: 9
Training loss: 1.7643696069717407
Validation loss: 1.9429820878531343

Epoch: 6| Step: 10
Training loss: 1.0862398147583008
Validation loss: 1.9042707938019947

Epoch: 6| Step: 11
Training loss: 1.0089213848114014
Validation loss: 1.8943252717295

Epoch: 6| Step: 12
Training loss: 1.2151867151260376
Validation loss: 1.8870167527147519

Epoch: 6| Step: 13
Training loss: 1.6284233331680298
Validation loss: 1.8875826404940697

Epoch: 248| Step: 0
Training loss: 1.1398677825927734
Validation loss: 1.8897961070460658

Epoch: 6| Step: 1
Training loss: 1.8125228881835938
Validation loss: 1.8842973555288007

Epoch: 6| Step: 2
Training loss: 0.9673194885253906
Validation loss: 1.8885333089418308

Epoch: 6| Step: 3
Training loss: 0.7628212571144104
Validation loss: 1.9086246157205233

Epoch: 6| Step: 4
Training loss: 1.1522653102874756
Validation loss: 1.9295962574661418

Epoch: 6| Step: 5
Training loss: 1.6749656200408936
Validation loss: 1.9385452283326017

Epoch: 6| Step: 6
Training loss: 1.4533631801605225
Validation loss: 1.9850824366333664

Epoch: 6| Step: 7
Training loss: 1.1669025421142578
Validation loss: 1.9534645965022426

Epoch: 6| Step: 8
Training loss: 0.9149874448776245
Validation loss: 1.9108785506217711

Epoch: 6| Step: 9
Training loss: 1.1079885959625244
Validation loss: 1.9174275513618224

Epoch: 6| Step: 10
Training loss: 0.9010463356971741
Validation loss: 1.8780053725806616

Epoch: 6| Step: 11
Training loss: 1.2256170511245728
Validation loss: 1.9015261460376043

Epoch: 6| Step: 12
Training loss: 1.0408008098602295
Validation loss: 1.895750416222439

Epoch: 6| Step: 13
Training loss: 1.8403767347335815
Validation loss: 1.9307963976296045

Epoch: 249| Step: 0
Training loss: 1.3853001594543457
Validation loss: 1.913429642236361

Epoch: 6| Step: 1
Training loss: 1.1065751314163208
Validation loss: 1.8712668162520214

Epoch: 6| Step: 2
Training loss: 1.035442590713501
Validation loss: 1.8721201765921809

Epoch: 6| Step: 3
Training loss: 1.0410559177398682
Validation loss: 1.8763018500420354

Epoch: 6| Step: 4
Training loss: 1.6385252475738525
Validation loss: 1.8937934534524077

Epoch: 6| Step: 5
Training loss: 0.906970202922821
Validation loss: 1.9061314239296863

Epoch: 6| Step: 6
Training loss: 1.4536139965057373
Validation loss: 1.9226958674769248

Epoch: 6| Step: 7
Training loss: 1.3375463485717773
Validation loss: 1.9089971896140807

Epoch: 6| Step: 8
Training loss: 1.6924705505371094
Validation loss: 1.8968667753281132

Epoch: 6| Step: 9
Training loss: 1.1955500841140747
Validation loss: 1.8907048804785616

Epoch: 6| Step: 10
Training loss: 0.8414444923400879
Validation loss: 1.879083876968712

Epoch: 6| Step: 11
Training loss: 1.202061414718628
Validation loss: 1.8894103932124313

Epoch: 6| Step: 12
Training loss: 0.9407394528388977
Validation loss: 1.8782874127869964

Epoch: 6| Step: 13
Training loss: 0.9923437833786011
Validation loss: 1.9299525791598904

Epoch: 250| Step: 0
Training loss: 0.7604119777679443
Validation loss: 1.9633571050500358

Epoch: 6| Step: 1
Training loss: 1.224571704864502
Validation loss: 1.9765695205298803

Epoch: 6| Step: 2
Training loss: 1.0763473510742188
Validation loss: 1.9527987998018983

Epoch: 6| Step: 3
Training loss: 1.6066094636917114
Validation loss: 1.9647333237432665

Epoch: 6| Step: 4
Training loss: 1.1281245946884155
Validation loss: 1.931226981583462

Epoch: 6| Step: 5
Training loss: 1.3425159454345703
Validation loss: 1.9404834560168687

Epoch: 6| Step: 6
Training loss: 1.0151474475860596
Validation loss: 1.931089194872046

Epoch: 6| Step: 7
Training loss: 0.9614427089691162
Validation loss: 1.9245488797464678

Epoch: 6| Step: 8
Training loss: 1.7630882263183594
Validation loss: 1.921621504650321

Epoch: 6| Step: 9
Training loss: 1.3241446018218994
Validation loss: 1.908790748606446

Epoch: 6| Step: 10
Training loss: 1.1039328575134277
Validation loss: 1.9479818369752617

Epoch: 6| Step: 11
Training loss: 1.1601120233535767
Validation loss: 1.9618570548231884

Epoch: 6| Step: 12
Training loss: 1.3209526538848877
Validation loss: 1.9537972711747693

Epoch: 6| Step: 13
Training loss: 1.2424112558364868
Validation loss: 1.913838928745639

Epoch: 251| Step: 0
Training loss: 1.254457950592041
Validation loss: 1.9195546898790585

Epoch: 6| Step: 1
Training loss: 0.8849475383758545
Validation loss: 1.9102104120357062

Epoch: 6| Step: 2
Training loss: 1.2988818883895874
Validation loss: 1.9041477146969046

Epoch: 6| Step: 3
Training loss: 1.1278246641159058
Validation loss: 1.905011733373006

Epoch: 6| Step: 4
Training loss: 1.218984842300415
Validation loss: 1.8807479207233717

Epoch: 6| Step: 5
Training loss: 1.6296870708465576
Validation loss: 1.8924256165822346

Epoch: 6| Step: 6
Training loss: 1.162341594696045
Validation loss: 1.901811384385632

Epoch: 6| Step: 7
Training loss: 0.9075115919113159
Validation loss: 1.8779693213842248

Epoch: 6| Step: 8
Training loss: 1.126842737197876
Validation loss: 1.8840596855327647

Epoch: 6| Step: 9
Training loss: 1.0047686100006104
Validation loss: 1.8849929865970407

Epoch: 6| Step: 10
Training loss: 1.156742811203003
Validation loss: 1.8942547728938441

Epoch: 6| Step: 11
Training loss: 1.3533003330230713
Validation loss: 1.8848788020431355

Epoch: 6| Step: 12
Training loss: 1.6894220113754272
Validation loss: 1.9146655836412985

Epoch: 6| Step: 13
Training loss: 1.0050561428070068
Validation loss: 1.9466893339669833

Epoch: 252| Step: 0
Training loss: 1.2315045595169067
Validation loss: 1.9428480184206398

Epoch: 6| Step: 1
Training loss: 0.6804789304733276
Validation loss: 1.9378427638802478

Epoch: 6| Step: 2
Training loss: 1.3421862125396729
Validation loss: 1.9072357428971158

Epoch: 6| Step: 3
Training loss: 1.3418166637420654
Validation loss: 1.880105359579927

Epoch: 6| Step: 4
Training loss: 0.707019567489624
Validation loss: 1.8624678760446527

Epoch: 6| Step: 5
Training loss: 0.7146384716033936
Validation loss: 1.8482226684529295

Epoch: 6| Step: 6
Training loss: 1.778967022895813
Validation loss: 1.81953566305099

Epoch: 6| Step: 7
Training loss: 1.3772029876708984
Validation loss: 1.838795486316886

Epoch: 6| Step: 8
Training loss: 1.5949323177337646
Validation loss: 1.851076550381158

Epoch: 6| Step: 9
Training loss: 1.2153977155685425
Validation loss: 1.8652411622385825

Epoch: 6| Step: 10
Training loss: 1.5806422233581543
Validation loss: 1.918373179692094

Epoch: 6| Step: 11
Training loss: 1.0286891460418701
Validation loss: 1.9749216674476542

Epoch: 6| Step: 12
Training loss: 1.2517879009246826
Validation loss: 2.023500216904507

Epoch: 6| Step: 13
Training loss: 0.9066846370697021
Validation loss: 2.011796533420522

Epoch: 253| Step: 0
Training loss: 1.3070857524871826
Validation loss: 2.0216199249349613

Epoch: 6| Step: 1
Training loss: 0.9855749011039734
Validation loss: 2.03086559618673

Epoch: 6| Step: 2
Training loss: 1.3455066680908203
Validation loss: 1.9962096983386624

Epoch: 6| Step: 3
Training loss: 0.3812280595302582
Validation loss: 1.96905670883835

Epoch: 6| Step: 4
Training loss: 1.2057826519012451
Validation loss: 1.9444170677533714

Epoch: 6| Step: 5
Training loss: 1.320478916168213
Validation loss: 1.9593594151158487

Epoch: 6| Step: 6
Training loss: 0.8800364136695862
Validation loss: 1.9443087270182948

Epoch: 6| Step: 7
Training loss: 1.2244279384613037
Validation loss: 1.9157667211306992

Epoch: 6| Step: 8
Training loss: 1.341379165649414
Validation loss: 1.9227746302081692

Epoch: 6| Step: 9
Training loss: 1.3012843132019043
Validation loss: 1.949480797654839

Epoch: 6| Step: 10
Training loss: 1.4011600017547607
Validation loss: 1.928375236449703

Epoch: 6| Step: 11
Training loss: 1.3163740634918213
Validation loss: 1.9024792999349616

Epoch: 6| Step: 12
Training loss: 1.407546877861023
Validation loss: 1.8664484921322073

Epoch: 6| Step: 13
Training loss: 1.3522915840148926
Validation loss: 1.8644986844831897

Epoch: 254| Step: 0
Training loss: 0.9468148946762085
Validation loss: 1.8861749249119912

Epoch: 6| Step: 1
Training loss: 1.4110021591186523
Validation loss: 1.8944820409180017

Epoch: 6| Step: 2
Training loss: 1.2145414352416992
Validation loss: 1.9073369567112257

Epoch: 6| Step: 3
Training loss: 0.980584979057312
Validation loss: 1.8992910308222617

Epoch: 6| Step: 4
Training loss: 1.064511775970459
Validation loss: 1.8849689781024892

Epoch: 6| Step: 5
Training loss: 1.8131643533706665
Validation loss: 1.870047184728807

Epoch: 6| Step: 6
Training loss: 1.2365834712982178
Validation loss: 1.854647663331801

Epoch: 6| Step: 7
Training loss: 1.337693214416504
Validation loss: 1.895485778008738

Epoch: 6| Step: 8
Training loss: 1.5530099868774414
Validation loss: 1.9260701979360273

Epoch: 6| Step: 9
Training loss: 0.7248014211654663
Validation loss: 1.8954584777996104

Epoch: 6| Step: 10
Training loss: 0.7741613388061523
Validation loss: 1.914436541577821

Epoch: 6| Step: 11
Training loss: 1.1040372848510742
Validation loss: 1.9491669413863972

Epoch: 6| Step: 12
Training loss: 1.1674554347991943
Validation loss: 1.9834100815557665

Epoch: 6| Step: 13
Training loss: 1.1095880270004272
Validation loss: 1.9961392879486084

Epoch: 255| Step: 0
Training loss: 1.6433241367340088
Validation loss: 1.9505424576420938

Epoch: 6| Step: 1
Training loss: 0.7715108394622803
Validation loss: 1.8843645177861696

Epoch: 6| Step: 2
Training loss: 1.019013524055481
Validation loss: 1.895049318190544

Epoch: 6| Step: 3
Training loss: 1.3964567184448242
Validation loss: 1.864362124473818

Epoch: 6| Step: 4
Training loss: 1.1846507787704468
Validation loss: 1.8663606477040116

Epoch: 6| Step: 5
Training loss: 1.351055383682251
Validation loss: 1.8792297993936846

Epoch: 6| Step: 6
Training loss: 1.0357592105865479
Validation loss: 1.8990392044026365

Epoch: 6| Step: 7
Training loss: 1.5211381912231445
Validation loss: 1.9203818280209777

Epoch: 6| Step: 8
Training loss: 0.7082815766334534
Validation loss: 2.0021924664897304

Epoch: 6| Step: 9
Training loss: 1.247154951095581
Validation loss: 2.0160583039765716

Epoch: 6| Step: 10
Training loss: 1.1673305034637451
Validation loss: 2.0333375930786133

Epoch: 6| Step: 11
Training loss: 1.0241495370864868
Validation loss: 1.9944434704319123

Epoch: 6| Step: 12
Training loss: 0.9638271331787109
Validation loss: 1.958713271284616

Epoch: 6| Step: 13
Training loss: 1.905943751335144
Validation loss: 1.9396426280339558

Epoch: 256| Step: 0
Training loss: 0.5722501277923584
Validation loss: 1.9091357351631246

Epoch: 6| Step: 1
Training loss: 1.1961174011230469
Validation loss: 1.9266699962718512

Epoch: 6| Step: 2
Training loss: 1.3028955459594727
Validation loss: 1.9483031470288512

Epoch: 6| Step: 3
Training loss: 1.4236524105072021
Validation loss: 1.9308907165322253

Epoch: 6| Step: 4
Training loss: 1.713527798652649
Validation loss: 1.9109539883111113

Epoch: 6| Step: 5
Training loss: 1.427436351776123
Validation loss: 1.898320412123075

Epoch: 6| Step: 6
Training loss: 1.2391421794891357
Validation loss: 1.8750976234353998

Epoch: 6| Step: 7
Training loss: 1.0058362483978271
Validation loss: 1.8896822493563417

Epoch: 6| Step: 8
Training loss: 0.8415350914001465
Validation loss: 1.922759602146764

Epoch: 6| Step: 9
Training loss: 1.4395661354064941
Validation loss: 1.9856888478802097

Epoch: 6| Step: 10
Training loss: 0.8422086834907532
Validation loss: 2.016162062204012

Epoch: 6| Step: 11
Training loss: 1.05906343460083
Validation loss: 2.015194300682314

Epoch: 6| Step: 12
Training loss: 1.349273681640625
Validation loss: 2.010586198940072

Epoch: 6| Step: 13
Training loss: 0.9503700733184814
Validation loss: 1.9713847534630888

Epoch: 257| Step: 0
Training loss: 1.394039273262024
Validation loss: 1.9612560220943984

Epoch: 6| Step: 1
Training loss: 1.5354270935058594
Validation loss: 1.9585715891212545

Epoch: 6| Step: 2
Training loss: 1.7513649463653564
Validation loss: 1.9522449290880592

Epoch: 6| Step: 3
Training loss: 1.2962555885314941
Validation loss: 1.9608882319542669

Epoch: 6| Step: 4
Training loss: 0.45084887742996216
Validation loss: 1.9461137351169382

Epoch: 6| Step: 5
Training loss: 1.0439462661743164
Validation loss: 1.9431697207112466

Epoch: 6| Step: 6
Training loss: 1.1821200847625732
Validation loss: 1.9557757364806307

Epoch: 6| Step: 7
Training loss: 0.7401185035705566
Validation loss: 1.930701937726749

Epoch: 6| Step: 8
Training loss: 1.2467989921569824
Validation loss: 1.9281257813976658

Epoch: 6| Step: 9
Training loss: 0.9420562386512756
Validation loss: 1.9221380884929369

Epoch: 6| Step: 10
Training loss: 0.9331609010696411
Validation loss: 1.9227086215890863

Epoch: 6| Step: 11
Training loss: 0.9410589337348938
Validation loss: 1.9124160300018966

Epoch: 6| Step: 12
Training loss: 1.547938585281372
Validation loss: 1.9091912597738288

Epoch: 6| Step: 13
Training loss: 1.043691873550415
Validation loss: 1.9130200275810816

Epoch: 258| Step: 0
Training loss: 0.9665296077728271
Validation loss: 1.8888852057918426

Epoch: 6| Step: 1
Training loss: 1.5130274295806885
Validation loss: 1.8854494594758557

Epoch: 6| Step: 2
Training loss: 1.4994230270385742
Validation loss: 1.882739370869052

Epoch: 6| Step: 3
Training loss: 1.2772448062896729
Validation loss: 1.8892047559061358

Epoch: 6| Step: 4
Training loss: 1.6514759063720703
Validation loss: 1.9169031984062606

Epoch: 6| Step: 5
Training loss: 0.9947080016136169
Validation loss: 1.966659830462548

Epoch: 6| Step: 6
Training loss: 1.1054084300994873
Validation loss: 1.992178729785386

Epoch: 6| Step: 7
Training loss: 0.9641724824905396
Validation loss: 1.9872220318804505

Epoch: 6| Step: 8
Training loss: 1.0218005180358887
Validation loss: 1.9465020600185599

Epoch: 6| Step: 9
Training loss: 0.5290541648864746
Validation loss: 1.9558622939612276

Epoch: 6| Step: 10
Training loss: 1.1543259620666504
Validation loss: 1.8955040054936563

Epoch: 6| Step: 11
Training loss: 0.8294439315795898
Validation loss: 1.8815190087082565

Epoch: 6| Step: 12
Training loss: 1.6085482835769653
Validation loss: 1.8699995856131277

Epoch: 6| Step: 13
Training loss: 0.9084538221359253
Validation loss: 1.868881187131328

Epoch: 259| Step: 0
Training loss: 1.2328177690505981
Validation loss: 1.863038529631912

Epoch: 6| Step: 1
Training loss: 1.3456579446792603
Validation loss: 1.8505131454877957

Epoch: 6| Step: 2
Training loss: 0.9987397193908691
Validation loss: 1.8590768742304977

Epoch: 6| Step: 3
Training loss: 1.111569881439209
Validation loss: 1.9123697152701757

Epoch: 6| Step: 4
Training loss: 1.1213605403900146
Validation loss: 1.9598659828145018

Epoch: 6| Step: 5
Training loss: 1.7124543190002441
Validation loss: 2.010772289768342

Epoch: 6| Step: 6
Training loss: 1.4054527282714844
Validation loss: 2.0315309968045963

Epoch: 6| Step: 7
Training loss: 0.853194534778595
Validation loss: 2.0057378097247054

Epoch: 6| Step: 8
Training loss: 1.1972081661224365
Validation loss: 1.9146705571041311

Epoch: 6| Step: 9
Training loss: 0.7564213871955872
Validation loss: 1.8631204148774505

Epoch: 6| Step: 10
Training loss: 1.3668019771575928
Validation loss: 1.8637880766263573

Epoch: 6| Step: 11
Training loss: 1.0325233936309814
Validation loss: 1.8591841625910934

Epoch: 6| Step: 12
Training loss: 0.7596522569656372
Validation loss: 1.8503473202387493

Epoch: 6| Step: 13
Training loss: 1.2473726272583008
Validation loss: 1.8618217745134908

Epoch: 260| Step: 0
Training loss: 1.4518346786499023
Validation loss: 1.8823021752859956

Epoch: 6| Step: 1
Training loss: 1.0541023015975952
Validation loss: 1.9192259632131106

Epoch: 6| Step: 2
Training loss: 0.7398098707199097
Validation loss: 1.9498228116702008

Epoch: 6| Step: 3
Training loss: 0.8664602041244507
Validation loss: 1.9437921406120382

Epoch: 6| Step: 4
Training loss: 1.3279473781585693
Validation loss: 1.9624495890832716

Epoch: 6| Step: 5
Training loss: 0.9272286891937256
Validation loss: 1.9568332549064391

Epoch: 6| Step: 6
Training loss: 1.140260934829712
Validation loss: 1.9565004494882399

Epoch: 6| Step: 7
Training loss: 1.3229252099990845
Validation loss: 1.9144008364728702

Epoch: 6| Step: 8
Training loss: 0.6964614987373352
Validation loss: 1.906055929840252

Epoch: 6| Step: 9
Training loss: 1.580820083618164
Validation loss: 1.8861359896198395

Epoch: 6| Step: 10
Training loss: 1.264614224433899
Validation loss: 1.8709472046103528

Epoch: 6| Step: 11
Training loss: 1.0172715187072754
Validation loss: 1.8767232253987303

Epoch: 6| Step: 12
Training loss: 1.298099398612976
Validation loss: 1.8714577049337409

Epoch: 6| Step: 13
Training loss: 0.7293063998222351
Validation loss: 1.8704740488401024

Epoch: 261| Step: 0
Training loss: 0.9198558330535889
Validation loss: 1.872519189311612

Epoch: 6| Step: 1
Training loss: 0.6906135678291321
Validation loss: 1.864192170481528

Epoch: 6| Step: 2
Training loss: 0.9712353348731995
Validation loss: 1.8773961695291663

Epoch: 6| Step: 3
Training loss: 1.2453339099884033
Validation loss: 1.9029810505528604

Epoch: 6| Step: 4
Training loss: 0.857399582862854
Validation loss: 1.9203769891492781

Epoch: 6| Step: 5
Training loss: 1.054267406463623
Validation loss: 1.9150029638762116

Epoch: 6| Step: 6
Training loss: 1.09408700466156
Validation loss: 1.918728115738079

Epoch: 6| Step: 7
Training loss: 1.2355561256408691
Validation loss: 1.8728511115556121

Epoch: 6| Step: 8
Training loss: 0.8354983925819397
Validation loss: 1.8979203444655224

Epoch: 6| Step: 9
Training loss: 1.0802137851715088
Validation loss: 1.881864514402164

Epoch: 6| Step: 10
Training loss: 1.364410638809204
Validation loss: 1.8886959719401535

Epoch: 6| Step: 11
Training loss: 1.401820182800293
Validation loss: 1.8963064198852868

Epoch: 6| Step: 12
Training loss: 1.5993880033493042
Validation loss: 1.9007593277961976

Epoch: 6| Step: 13
Training loss: 1.0512757301330566
Validation loss: 1.9101467286386797

Epoch: 262| Step: 0
Training loss: 1.075674057006836
Validation loss: 1.8964420390385452

Epoch: 6| Step: 1
Training loss: 1.008115291595459
Validation loss: 1.906050020648587

Epoch: 6| Step: 2
Training loss: 0.9256947040557861
Validation loss: 1.8799462933694162

Epoch: 6| Step: 3
Training loss: 0.9484995007514954
Validation loss: 1.8949386214697233

Epoch: 6| Step: 4
Training loss: 1.3065199851989746
Validation loss: 1.8998835471368605

Epoch: 6| Step: 5
Training loss: 1.2069156169891357
Validation loss: 1.915784881960961

Epoch: 6| Step: 6
Training loss: 0.9313061833381653
Validation loss: 1.9345123152579031

Epoch: 6| Step: 7
Training loss: 1.1220629215240479
Validation loss: 1.9408159486709102

Epoch: 6| Step: 8
Training loss: 0.7851237654685974
Validation loss: 1.9335492900622788

Epoch: 6| Step: 9
Training loss: 1.5236964225769043
Validation loss: 1.9739395283883618

Epoch: 6| Step: 10
Training loss: 1.0648250579833984
Validation loss: 1.938027428042504

Epoch: 6| Step: 11
Training loss: 0.8296462297439575
Validation loss: 1.947900031202583

Epoch: 6| Step: 12
Training loss: 1.250023603439331
Validation loss: 1.9107122575083086

Epoch: 6| Step: 13
Training loss: 1.4605573415756226
Validation loss: 1.903029598215575

Epoch: 263| Step: 0
Training loss: 1.3070032596588135
Validation loss: 1.8713587381506478

Epoch: 6| Step: 1
Training loss: 1.2147008180618286
Validation loss: 1.869087621729861

Epoch: 6| Step: 2
Training loss: 0.8527257442474365
Validation loss: 1.885458328390634

Epoch: 6| Step: 3
Training loss: 0.828155517578125
Validation loss: 1.8797773648333806

Epoch: 6| Step: 4
Training loss: 1.4866235256195068
Validation loss: 1.8764068195896764

Epoch: 6| Step: 5
Training loss: 1.0990424156188965
Validation loss: 1.9164195188912012

Epoch: 6| Step: 6
Training loss: 0.7815179228782654
Validation loss: 1.9103695756645613

Epoch: 6| Step: 7
Training loss: 1.0942492485046387
Validation loss: 1.913856501220375

Epoch: 6| Step: 8
Training loss: 0.6793537735939026
Validation loss: 1.9200303964717413

Epoch: 6| Step: 9
Training loss: 0.8695822954177856
Validation loss: 1.8984647284271896

Epoch: 6| Step: 10
Training loss: 1.4824731349945068
Validation loss: 1.8926073940851356

Epoch: 6| Step: 11
Training loss: 1.7100989818572998
Validation loss: 1.8557091156641643

Epoch: 6| Step: 12
Training loss: 0.9652479887008667
Validation loss: 1.886213307739586

Epoch: 6| Step: 13
Training loss: 0.5104907751083374
Validation loss: 1.8882594928946546

Epoch: 264| Step: 0
Training loss: 1.1045185327529907
Validation loss: 1.9037770045700895

Epoch: 6| Step: 1
Training loss: 0.8746911287307739
Validation loss: 1.8898358063031269

Epoch: 6| Step: 2
Training loss: 1.1911101341247559
Validation loss: 1.9070036103648524

Epoch: 6| Step: 3
Training loss: 1.007737398147583
Validation loss: 1.9265284871542325

Epoch: 6| Step: 4
Training loss: 1.1944752931594849
Validation loss: 1.940994015303991

Epoch: 6| Step: 5
Training loss: 1.2890539169311523
Validation loss: 1.9382022862793298

Epoch: 6| Step: 6
Training loss: 0.9249492883682251
Validation loss: 1.889494010197219

Epoch: 6| Step: 7
Training loss: 1.0068867206573486
Validation loss: 1.8512622720451766

Epoch: 6| Step: 8
Training loss: 0.8227863311767578
Validation loss: 1.8534887324097336

Epoch: 6| Step: 9
Training loss: 0.9704620838165283
Validation loss: 1.8301392755200785

Epoch: 6| Step: 10
Training loss: 1.4437936544418335
Validation loss: 1.8521615023254066

Epoch: 6| Step: 11
Training loss: 1.4860126972198486
Validation loss: 1.868798969894327

Epoch: 6| Step: 12
Training loss: 0.9353592991828918
Validation loss: 1.9049787085543397

Epoch: 6| Step: 13
Training loss: 1.0006310939788818
Validation loss: 1.9415061781483312

Epoch: 265| Step: 0
Training loss: 0.8435770273208618
Validation loss: 1.9839017545023272

Epoch: 6| Step: 1
Training loss: 1.3960206508636475
Validation loss: 1.982487573418566

Epoch: 6| Step: 2
Training loss: 0.5493698120117188
Validation loss: 1.9949541425192228

Epoch: 6| Step: 3
Training loss: 1.4330157041549683
Validation loss: 1.976947997206001

Epoch: 6| Step: 4
Training loss: 1.1213632822036743
Validation loss: 1.9529642571685135

Epoch: 6| Step: 5
Training loss: 1.0207502841949463
Validation loss: 1.9063973990819787

Epoch: 6| Step: 6
Training loss: 0.8332370519638062
Validation loss: 1.8674632387776529

Epoch: 6| Step: 7
Training loss: 1.3845558166503906
Validation loss: 1.8625795482307352

Epoch: 6| Step: 8
Training loss: 1.4649709463119507
Validation loss: 1.8578433221386326

Epoch: 6| Step: 9
Training loss: 0.9596766233444214
Validation loss: 1.8414478763457267

Epoch: 6| Step: 10
Training loss: 1.6647976636886597
Validation loss: 1.8508974890555105

Epoch: 6| Step: 11
Training loss: 0.9782521724700928
Validation loss: 1.8515241376815303

Epoch: 6| Step: 12
Training loss: 1.026012897491455
Validation loss: 1.8786705463163313

Epoch: 6| Step: 13
Training loss: 0.3400658071041107
Validation loss: 1.8805115594658801

Epoch: 266| Step: 0
Training loss: 0.8856276273727417
Validation loss: 1.9335404724203131

Epoch: 6| Step: 1
Training loss: 0.9728355407714844
Validation loss: 1.9668264107037616

Epoch: 6| Step: 2
Training loss: 1.2565038204193115
Validation loss: 1.9615582983980897

Epoch: 6| Step: 3
Training loss: 1.481919527053833
Validation loss: 1.944056007169908

Epoch: 6| Step: 4
Training loss: 0.7215545177459717
Validation loss: 1.900970451293453

Epoch: 6| Step: 5
Training loss: 1.2224632501602173
Validation loss: 1.8960463680246824

Epoch: 6| Step: 6
Training loss: 1.1160855293273926
Validation loss: 1.8999309706431564

Epoch: 6| Step: 7
Training loss: 1.0772379636764526
Validation loss: 1.9158743389191166

Epoch: 6| Step: 8
Training loss: 0.8104133605957031
Validation loss: 1.9312221619390673

Epoch: 6| Step: 9
Training loss: 0.7667123079299927
Validation loss: 1.9304390953433128

Epoch: 6| Step: 10
Training loss: 1.0347284078598022
Validation loss: 1.9290469718235794

Epoch: 6| Step: 11
Training loss: 1.0280154943466187
Validation loss: 1.922897578567587

Epoch: 6| Step: 12
Training loss: 2.020940065383911
Validation loss: 1.9257600974011164

Epoch: 6| Step: 13
Training loss: 0.4369182586669922
Validation loss: 1.908404299007949

Epoch: 267| Step: 0
Training loss: 1.1741241216659546
Validation loss: 1.8861722664166523

Epoch: 6| Step: 1
Training loss: 1.0499818325042725
Validation loss: 1.8756655826363513

Epoch: 6| Step: 2
Training loss: 1.336279273033142
Validation loss: 1.86333252281271

Epoch: 6| Step: 3
Training loss: 1.0172001123428345
Validation loss: 1.8686654003717567

Epoch: 6| Step: 4
Training loss: 1.0066699981689453
Validation loss: 1.885878345017792

Epoch: 6| Step: 5
Training loss: 1.4365226030349731
Validation loss: 1.9282945407334195

Epoch: 6| Step: 6
Training loss: 0.7792226076126099
Validation loss: 1.8923718903654365

Epoch: 6| Step: 7
Training loss: 1.1422932147979736
Validation loss: 1.8881185746962024

Epoch: 6| Step: 8
Training loss: 1.0340187549591064
Validation loss: 1.877540385851296

Epoch: 6| Step: 9
Training loss: 0.8396964073181152
Validation loss: 1.9006940792965632

Epoch: 6| Step: 10
Training loss: 1.8212721347808838
Validation loss: 1.8703447221427836

Epoch: 6| Step: 11
Training loss: 0.5510609149932861
Validation loss: 1.8523282133122927

Epoch: 6| Step: 12
Training loss: 1.1224230527877808
Validation loss: 1.8407350842670729

Epoch: 6| Step: 13
Training loss: 0.6648485660552979
Validation loss: 1.84498990479336

Epoch: 268| Step: 0
Training loss: 0.8739751577377319
Validation loss: 1.8491760402597406

Epoch: 6| Step: 1
Training loss: 1.1471972465515137
Validation loss: 1.8734415833668043

Epoch: 6| Step: 2
Training loss: 1.2375057935714722
Validation loss: 1.9098124901453655

Epoch: 6| Step: 3
Training loss: 1.0001887083053589
Validation loss: 1.9300305279352332

Epoch: 6| Step: 4
Training loss: 1.20315682888031
Validation loss: 1.9485404106878466

Epoch: 6| Step: 5
Training loss: 0.9178245067596436
Validation loss: 1.9647739036108858

Epoch: 6| Step: 6
Training loss: 1.4721195697784424
Validation loss: 1.9377618733272757

Epoch: 6| Step: 7
Training loss: 1.446202039718628
Validation loss: 1.9368036395759993

Epoch: 6| Step: 8
Training loss: 0.9915574193000793
Validation loss: 1.886027859103295

Epoch: 6| Step: 9
Training loss: 0.7359142303466797
Validation loss: 1.873705158951462

Epoch: 6| Step: 10
Training loss: 1.2797632217407227
Validation loss: 1.811304271862071

Epoch: 6| Step: 11
Training loss: 0.8591790199279785
Validation loss: 1.832018590742542

Epoch: 6| Step: 12
Training loss: 1.1585787534713745
Validation loss: 1.8147156776920441

Epoch: 6| Step: 13
Training loss: 0.7436704039573669
Validation loss: 1.8296173490503782

Epoch: 269| Step: 0
Training loss: 0.9969909191131592
Validation loss: 1.8587010342587706

Epoch: 6| Step: 1
Training loss: 0.720938503742218
Validation loss: 1.9250883184453493

Epoch: 6| Step: 2
Training loss: 0.9923009872436523
Validation loss: 1.9994068825116722

Epoch: 6| Step: 3
Training loss: 0.907179594039917
Validation loss: 2.0142986953899427

Epoch: 6| Step: 4
Training loss: 1.2657442092895508
Validation loss: 1.999890600481341

Epoch: 6| Step: 5
Training loss: 1.235537052154541
Validation loss: 1.961060438104855

Epoch: 6| Step: 6
Training loss: 1.0909206867218018
Validation loss: 1.8925974407503683

Epoch: 6| Step: 7
Training loss: 1.3984971046447754
Validation loss: 1.8989782717920118

Epoch: 6| Step: 8
Training loss: 1.2108521461486816
Validation loss: 1.8652598281060495

Epoch: 6| Step: 9
Training loss: 0.8142962455749512
Validation loss: 1.8236539120315223

Epoch: 6| Step: 10
Training loss: 0.7546559572219849
Validation loss: 1.8279107411702473

Epoch: 6| Step: 11
Training loss: 1.2647311687469482
Validation loss: 1.837453644762757

Epoch: 6| Step: 12
Training loss: 0.7570255994796753
Validation loss: 1.853552928534887

Epoch: 6| Step: 13
Training loss: 1.8580586910247803
Validation loss: 1.8885343472162883

Epoch: 270| Step: 0
Training loss: 1.0991120338439941
Validation loss: 1.9278123468481085

Epoch: 6| Step: 1
Training loss: 1.0531264543533325
Validation loss: 1.9964294574593986

Epoch: 6| Step: 2
Training loss: 1.0203871726989746
Validation loss: 2.0088828558562906

Epoch: 6| Step: 3
Training loss: 0.968582808971405
Validation loss: 2.019616657687772

Epoch: 6| Step: 4
Training loss: 0.9165927171707153
Validation loss: 1.993222664761287

Epoch: 6| Step: 5
Training loss: 0.6816504001617432
Validation loss: 1.983967347811627

Epoch: 6| Step: 6
Training loss: 1.619014024734497
Validation loss: 1.927170491987659

Epoch: 6| Step: 7
Training loss: 0.939549446105957
Validation loss: 1.9167317075114096

Epoch: 6| Step: 8
Training loss: 1.411573052406311
Validation loss: 1.91386886565916

Epoch: 6| Step: 9
Training loss: 0.7865651845932007
Validation loss: 1.888168781034408

Epoch: 6| Step: 10
Training loss: 1.774259328842163
Validation loss: 1.8880635179499143

Epoch: 6| Step: 11
Training loss: 0.7214096188545227
Validation loss: 1.881808089953597

Epoch: 6| Step: 12
Training loss: 0.9731763601303101
Validation loss: 1.8824943957790252

Epoch: 6| Step: 13
Training loss: 0.9182463884353638
Validation loss: 1.9092640082041423

Epoch: 271| Step: 0
Training loss: 1.4560775756835938
Validation loss: 1.8979333933963571

Epoch: 6| Step: 1
Training loss: 1.1770819425582886
Validation loss: 1.8925816935877646

Epoch: 6| Step: 2
Training loss: 1.0067368745803833
Validation loss: 1.8856723270108622

Epoch: 6| Step: 3
Training loss: 0.4661146402359009
Validation loss: 1.903083405187053

Epoch: 6| Step: 4
Training loss: 0.6693035960197449
Validation loss: 1.9187878062648158

Epoch: 6| Step: 5
Training loss: 1.1258060932159424
Validation loss: 1.942080387505152

Epoch: 6| Step: 6
Training loss: 1.116410732269287
Validation loss: 1.9118585894184728

Epoch: 6| Step: 7
Training loss: 1.4513278007507324
Validation loss: 1.9132993618647258

Epoch: 6| Step: 8
Training loss: 0.9737407565116882
Validation loss: 1.8740022451646867

Epoch: 6| Step: 9
Training loss: 0.9277915954589844
Validation loss: 1.874284835271938

Epoch: 6| Step: 10
Training loss: 1.3951401710510254
Validation loss: 1.8486838853487404

Epoch: 6| Step: 11
Training loss: 0.8096234202384949
Validation loss: 1.8380536699807772

Epoch: 6| Step: 12
Training loss: 0.8389512300491333
Validation loss: 1.822643813266549

Epoch: 6| Step: 13
Training loss: 1.0945916175842285
Validation loss: 1.8365547490376297

Epoch: 272| Step: 0
Training loss: 0.9375766515731812
Validation loss: 1.8520809347911547

Epoch: 6| Step: 1
Training loss: 1.3628740310668945
Validation loss: 1.8628509788103

Epoch: 6| Step: 2
Training loss: 0.9653969407081604
Validation loss: 1.8805930742653467

Epoch: 6| Step: 3
Training loss: 1.1304312944412231
Validation loss: 1.8939939493774085

Epoch: 6| Step: 4
Training loss: 1.2843800783157349
Validation loss: 1.94750081082826

Epoch: 6| Step: 5
Training loss: 0.8707690834999084
Validation loss: 1.910264668926116

Epoch: 6| Step: 6
Training loss: 1.0563387870788574
Validation loss: 1.8763011040226105

Epoch: 6| Step: 7
Training loss: 1.4138976335525513
Validation loss: 1.8510526662231774

Epoch: 6| Step: 8
Training loss: 0.9891912937164307
Validation loss: 1.863478583674277

Epoch: 6| Step: 9
Training loss: 1.1497713327407837
Validation loss: 1.8548066718603975

Epoch: 6| Step: 10
Training loss: 0.870158314704895
Validation loss: 1.8696898901334373

Epoch: 6| Step: 11
Training loss: 0.41987699270248413
Validation loss: 1.8442585865656536

Epoch: 6| Step: 12
Training loss: 1.0376782417297363
Validation loss: 1.8654140926176501

Epoch: 6| Step: 13
Training loss: 1.4499492645263672
Validation loss: 1.8849590721950735

Epoch: 273| Step: 0
Training loss: 1.1092971563339233
Validation loss: 1.8940455926361905

Epoch: 6| Step: 1
Training loss: 1.2693288326263428
Validation loss: 1.9298503450168076

Epoch: 6| Step: 2
Training loss: 1.3240082263946533
Validation loss: 1.948656689736151

Epoch: 6| Step: 3
Training loss: 0.6590107679367065
Validation loss: 1.9536726115852274

Epoch: 6| Step: 4
Training loss: 0.9446918368339539
Validation loss: 1.9299231113926056

Epoch: 6| Step: 5
Training loss: 1.1538996696472168
Validation loss: 1.9276243050893147

Epoch: 6| Step: 6
Training loss: 1.0563933849334717
Validation loss: 1.8925569954738821

Epoch: 6| Step: 7
Training loss: 0.6971047520637512
Validation loss: 1.8642567126981673

Epoch: 6| Step: 8
Training loss: 1.5405884981155396
Validation loss: 1.8563328737853675

Epoch: 6| Step: 9
Training loss: 0.7824802994728088
Validation loss: 1.8822304292391705

Epoch: 6| Step: 10
Training loss: 0.9254114627838135
Validation loss: 1.8889496377719346

Epoch: 6| Step: 11
Training loss: 0.846869707107544
Validation loss: 1.9114860193703764

Epoch: 6| Step: 12
Training loss: 1.0485824346542358
Validation loss: 1.8990006985202912

Epoch: 6| Step: 13
Training loss: 1.0393567085266113
Validation loss: 1.920741763166202

Epoch: 274| Step: 0
Training loss: 0.7482335567474365
Validation loss: 1.9474592260135117

Epoch: 6| Step: 1
Training loss: 0.9482899904251099
Validation loss: 1.8946492774512178

Epoch: 6| Step: 2
Training loss: 1.6380853652954102
Validation loss: 1.8443679143023748

Epoch: 6| Step: 3
Training loss: 1.1045383214950562
Validation loss: 1.8229790938797819

Epoch: 6| Step: 4
Training loss: 0.8358227014541626
Validation loss: 1.8161214115799114

Epoch: 6| Step: 5
Training loss: 1.0149174928665161
Validation loss: 1.7946904961780836

Epoch: 6| Step: 6
Training loss: 0.6582493782043457
Validation loss: 1.827185889726044

Epoch: 6| Step: 7
Training loss: 1.1833969354629517
Validation loss: 1.7990989967059063

Epoch: 6| Step: 8
Training loss: 0.9825350046157837
Validation loss: 1.8195150513802805

Epoch: 6| Step: 9
Training loss: 1.0280581712722778
Validation loss: 1.843142218487237

Epoch: 6| Step: 10
Training loss: 0.9636939167976379
Validation loss: 1.8636091627100462

Epoch: 6| Step: 11
Training loss: 1.1032192707061768
Validation loss: 1.8919962401031165

Epoch: 6| Step: 12
Training loss: 1.0719369649887085
Validation loss: 1.9750473550570908

Epoch: 6| Step: 13
Training loss: 1.056868314743042
Validation loss: 1.9455881170047227

Epoch: 275| Step: 0
Training loss: 0.7028732299804688
Validation loss: 1.9681593743703698

Epoch: 6| Step: 1
Training loss: 1.4626431465148926
Validation loss: 1.9342855996983026

Epoch: 6| Step: 2
Training loss: 0.6781675815582275
Validation loss: 1.892105467857853

Epoch: 6| Step: 3
Training loss: 0.7413172721862793
Validation loss: 1.8637608353809645

Epoch: 6| Step: 4
Training loss: 1.2667925357818604
Validation loss: 1.8450592615271126

Epoch: 6| Step: 5
Training loss: 1.0363471508026123
Validation loss: 1.841614410441409

Epoch: 6| Step: 6
Training loss: 1.5688893795013428
Validation loss: 1.8563364628822572

Epoch: 6| Step: 7
Training loss: 1.1534981727600098
Validation loss: 1.892393087828031

Epoch: 6| Step: 8
Training loss: 1.1714482307434082
Validation loss: 1.9478948167575303

Epoch: 6| Step: 9
Training loss: 0.8065612316131592
Validation loss: 1.9699457678743588

Epoch: 6| Step: 10
Training loss: 1.1607080698013306
Validation loss: 2.020851235235891

Epoch: 6| Step: 11
Training loss: 0.9259033203125
Validation loss: 2.013532564204226

Epoch: 6| Step: 12
Training loss: 0.5927566289901733
Validation loss: 1.9454058511282808

Epoch: 6| Step: 13
Training loss: 1.0304903984069824
Validation loss: 1.9122184963636502

Epoch: 276| Step: 0
Training loss: 1.5469045639038086
Validation loss: 1.848609257769841

Epoch: 6| Step: 1
Training loss: 0.8805895447731018
Validation loss: 1.8428221210356681

Epoch: 6| Step: 2
Training loss: 1.578811764717102
Validation loss: 1.7981450544890536

Epoch: 6| Step: 3
Training loss: 1.1009482145309448
Validation loss: 1.7915319050512006

Epoch: 6| Step: 4
Training loss: 1.2777812480926514
Validation loss: 1.789421554534666

Epoch: 6| Step: 5
Training loss: 0.820712685585022
Validation loss: 1.7978683517825218

Epoch: 6| Step: 6
Training loss: 0.7132563591003418
Validation loss: 1.8186561369126844

Epoch: 6| Step: 7
Training loss: 0.7475231885910034
Validation loss: 1.8605399439411778

Epoch: 6| Step: 8
Training loss: 1.2609567642211914
Validation loss: 1.9248240237594934

Epoch: 6| Step: 9
Training loss: 0.9735125303268433
Validation loss: 1.9478359401866954

Epoch: 6| Step: 10
Training loss: 0.7098110914230347
Validation loss: 1.974321871675471

Epoch: 6| Step: 11
Training loss: 1.1385273933410645
Validation loss: 1.939269676003405

Epoch: 6| Step: 12
Training loss: 0.8700814843177795
Validation loss: 1.864066646945092

Epoch: 6| Step: 13
Training loss: 0.6929141283035278
Validation loss: 1.8384085598812308

Epoch: 277| Step: 0
Training loss: 1.126711130142212
Validation loss: 1.8753334245374125

Epoch: 6| Step: 1
Training loss: 0.951911449432373
Validation loss: 1.8647153326260146

Epoch: 6| Step: 2
Training loss: 1.3864070177078247
Validation loss: 1.8678165610118578

Epoch: 6| Step: 3
Training loss: 1.0367400646209717
Validation loss: 1.8837211644777687

Epoch: 6| Step: 4
Training loss: 1.2332663536071777
Validation loss: 1.895341629623085

Epoch: 6| Step: 5
Training loss: 1.001084566116333
Validation loss: 1.882032068826819

Epoch: 6| Step: 6
Training loss: 0.8814115524291992
Validation loss: 1.8865685514224473

Epoch: 6| Step: 7
Training loss: 1.0631295442581177
Validation loss: 1.8850888949568554

Epoch: 6| Step: 8
Training loss: 0.7113618850708008
Validation loss: 1.8864313505029167

Epoch: 6| Step: 9
Training loss: 0.9377011060714722
Validation loss: 1.89855606068847

Epoch: 6| Step: 10
Training loss: 0.7361607551574707
Validation loss: 1.8887047754820956

Epoch: 6| Step: 11
Training loss: 0.9123388528823853
Validation loss: 1.8982314050838511

Epoch: 6| Step: 12
Training loss: 1.2673529386520386
Validation loss: 1.9110572209922216

Epoch: 6| Step: 13
Training loss: 0.8117759227752686
Validation loss: 1.9386925517871816

Epoch: 278| Step: 0
Training loss: 1.3424677848815918
Validation loss: 1.9376346424061766

Epoch: 6| Step: 1
Training loss: 1.1396586894989014
Validation loss: 1.9268425818412536

Epoch: 6| Step: 2
Training loss: 0.5721582174301147
Validation loss: 1.9315423247634724

Epoch: 6| Step: 3
Training loss: 1.3574455976486206
Validation loss: 1.918394498927619

Epoch: 6| Step: 4
Training loss: 1.3417268991470337
Validation loss: 1.8941796633505052

Epoch: 6| Step: 5
Training loss: 0.747231125831604
Validation loss: 1.867126569953016

Epoch: 6| Step: 6
Training loss: 0.7983489036560059
Validation loss: 1.8638352809413787

Epoch: 6| Step: 7
Training loss: 1.086548924446106
Validation loss: 1.8428406253937752

Epoch: 6| Step: 8
Training loss: 0.8743324875831604
Validation loss: 1.8616508578741422

Epoch: 6| Step: 9
Training loss: 0.9457598924636841
Validation loss: 1.896948254236611

Epoch: 6| Step: 10
Training loss: 0.9834204912185669
Validation loss: 1.8994529298556748

Epoch: 6| Step: 11
Training loss: 0.8976992964744568
Validation loss: 1.946703774954683

Epoch: 6| Step: 12
Training loss: 0.9018682241439819
Validation loss: 1.9483006538883332

Epoch: 6| Step: 13
Training loss: 1.3781156539916992
Validation loss: 1.9260057646741149

Epoch: 279| Step: 0
Training loss: 1.2909603118896484
Validation loss: 1.9103935098135343

Epoch: 6| Step: 1
Training loss: 1.0727612972259521
Validation loss: 1.9003385420768493

Epoch: 6| Step: 2
Training loss: 1.498950719833374
Validation loss: 1.8896362294432938

Epoch: 6| Step: 3
Training loss: 0.7459320425987244
Validation loss: 1.8938712817366405

Epoch: 6| Step: 4
Training loss: 1.2460460662841797
Validation loss: 1.8752145216029177

Epoch: 6| Step: 5
Training loss: 1.1005311012268066
Validation loss: 1.8790617155772384

Epoch: 6| Step: 6
Training loss: 1.2163958549499512
Validation loss: 1.8625627820209791

Epoch: 6| Step: 7
Training loss: 0.6039915084838867
Validation loss: 1.863740300619474

Epoch: 6| Step: 8
Training loss: 1.3390699625015259
Validation loss: 1.8932506192115046

Epoch: 6| Step: 9
Training loss: 0.7264490127563477
Validation loss: 1.9122348754636702

Epoch: 6| Step: 10
Training loss: 0.6412022113800049
Validation loss: 1.8882418986289733

Epoch: 6| Step: 11
Training loss: 0.9050867557525635
Validation loss: 1.858164853947137

Epoch: 6| Step: 12
Training loss: 0.6717342138290405
Validation loss: 1.8166221072596889

Epoch: 6| Step: 13
Training loss: 1.5599826574325562
Validation loss: 1.8215511127184796

Epoch: 280| Step: 0
Training loss: 0.7974967360496521
Validation loss: 1.8106755543780584

Epoch: 6| Step: 1
Training loss: 0.8796664476394653
Validation loss: 1.8029753956743466

Epoch: 6| Step: 2
Training loss: 0.5462256073951721
Validation loss: 1.8287856707008936

Epoch: 6| Step: 3
Training loss: 0.8084277510643005
Validation loss: 1.8620026842240365

Epoch: 6| Step: 4
Training loss: 1.177703619003296
Validation loss: 1.8572831974234632

Epoch: 6| Step: 5
Training loss: 0.9343469142913818
Validation loss: 1.8430526628289172

Epoch: 6| Step: 6
Training loss: 0.9471858739852905
Validation loss: 1.8348971682210122

Epoch: 6| Step: 7
Training loss: 1.001672625541687
Validation loss: 1.8766203054817774

Epoch: 6| Step: 8
Training loss: 0.9483157992362976
Validation loss: 1.8401324556719871

Epoch: 6| Step: 9
Training loss: 1.182523250579834
Validation loss: 1.8493549849397393

Epoch: 6| Step: 10
Training loss: 0.897689700126648
Validation loss: 1.9237028783367527

Epoch: 6| Step: 11
Training loss: 0.9269667863845825
Validation loss: 1.9627561928123556

Epoch: 6| Step: 12
Training loss: 1.3067580461502075
Validation loss: 1.9372866474172121

Epoch: 6| Step: 13
Training loss: 1.4742069244384766
Validation loss: 1.9754080887763732

Epoch: 281| Step: 0
Training loss: 0.8006759881973267
Validation loss: 1.9152218769955378

Epoch: 6| Step: 1
Training loss: 0.6800845265388489
Validation loss: 1.8883967681597638

Epoch: 6| Step: 2
Training loss: 1.1934453248977661
Validation loss: 1.8398145001421693

Epoch: 6| Step: 3
Training loss: 0.9289472699165344
Validation loss: 1.864614289294007

Epoch: 6| Step: 4
Training loss: 0.7034681439399719
Validation loss: 1.8198385341193086

Epoch: 6| Step: 5
Training loss: 1.4128117561340332
Validation loss: 1.8612300285729029

Epoch: 6| Step: 6
Training loss: 0.6765181422233582
Validation loss: 1.880961448915543

Epoch: 6| Step: 7
Training loss: 0.8790377378463745
Validation loss: 1.8862654175809634

Epoch: 6| Step: 8
Training loss: 1.4673439264297485
Validation loss: 1.9287669427933232

Epoch: 6| Step: 9
Training loss: 0.7225269079208374
Validation loss: 1.9941374281401276

Epoch: 6| Step: 10
Training loss: 1.4536104202270508
Validation loss: 2.0137759306097545

Epoch: 6| Step: 11
Training loss: 1.0767276287078857
Validation loss: 1.9805771740533973

Epoch: 6| Step: 12
Training loss: 0.7995045185089111
Validation loss: 1.9708559128545946

Epoch: 6| Step: 13
Training loss: 1.1310290098190308
Validation loss: 1.902778479360765

Epoch: 282| Step: 0
Training loss: 1.0368528366088867
Validation loss: 1.8714862318449124

Epoch: 6| Step: 1
Training loss: 0.8437628746032715
Validation loss: 1.853874223206633

Epoch: 6| Step: 2
Training loss: 0.5827809572219849
Validation loss: 1.8360651898127731

Epoch: 6| Step: 3
Training loss: 0.8030245304107666
Validation loss: 1.7973629325948737

Epoch: 6| Step: 4
Training loss: 1.7692606449127197
Validation loss: 1.8087874304863714

Epoch: 6| Step: 5
Training loss: 1.1583865880966187
Validation loss: 1.811916930701143

Epoch: 6| Step: 6
Training loss: 0.6068578958511353
Validation loss: 1.8320908918175647

Epoch: 6| Step: 7
Training loss: 1.3771052360534668
Validation loss: 1.862226132423647

Epoch: 6| Step: 8
Training loss: 0.6253924369812012
Validation loss: 1.8840388251889137

Epoch: 6| Step: 9
Training loss: 0.9252985119819641
Validation loss: 1.9546322720025175

Epoch: 6| Step: 10
Training loss: 0.8545687794685364
Validation loss: 1.9731780995604813

Epoch: 6| Step: 11
Training loss: 1.2788214683532715
Validation loss: 1.9389109790966075

Epoch: 6| Step: 12
Training loss: 0.9560186862945557
Validation loss: 1.9386495633791851

Epoch: 6| Step: 13
Training loss: 0.8700040578842163
Validation loss: 1.9158299712724582

Epoch: 283| Step: 0
Training loss: 1.299572467803955
Validation loss: 1.8534593069425194

Epoch: 6| Step: 1
Training loss: 0.5697205662727356
Validation loss: 1.8073788868483676

Epoch: 6| Step: 2
Training loss: 1.0531786680221558
Validation loss: 1.7983103644463323

Epoch: 6| Step: 3
Training loss: 1.2625327110290527
Validation loss: 1.7812312879870016

Epoch: 6| Step: 4
Training loss: 1.141334891319275
Validation loss: 1.7631825349664176

Epoch: 6| Step: 5
Training loss: 1.0426356792449951
Validation loss: 1.760945015056159

Epoch: 6| Step: 6
Training loss: 0.8409025073051453
Validation loss: 1.7708382221960253

Epoch: 6| Step: 7
Training loss: 0.698137104511261
Validation loss: 1.8058442531093475

Epoch: 6| Step: 8
Training loss: 0.83077073097229
Validation loss: 1.8045779940902547

Epoch: 6| Step: 9
Training loss: 0.8061457872390747
Validation loss: 1.84277799565305

Epoch: 6| Step: 10
Training loss: 1.3879846334457397
Validation loss: 1.8646230172085505

Epoch: 6| Step: 11
Training loss: 0.9027005434036255
Validation loss: 1.8940609731981832

Epoch: 6| Step: 12
Training loss: 1.0278993844985962
Validation loss: 1.904217626458855

Epoch: 6| Step: 13
Training loss: 0.9721596240997314
Validation loss: 1.914788915264991

Epoch: 284| Step: 0
Training loss: 0.9557787179946899
Validation loss: 1.9171669739548878

Epoch: 6| Step: 1
Training loss: 0.6799594759941101
Validation loss: 1.9186356516294583

Epoch: 6| Step: 2
Training loss: 0.7023539543151855
Validation loss: 1.9459350493646437

Epoch: 6| Step: 3
Training loss: 0.8474152088165283
Validation loss: 1.9189368473586215

Epoch: 6| Step: 4
Training loss: 1.129697322845459
Validation loss: 1.8637720743815105

Epoch: 6| Step: 5
Training loss: 1.5971271991729736
Validation loss: 1.8429868157191942

Epoch: 6| Step: 6
Training loss: 1.311855673789978
Validation loss: 1.7990193623368458

Epoch: 6| Step: 7
Training loss: 0.9459353089332581
Validation loss: 1.7615802339328233

Epoch: 6| Step: 8
Training loss: 1.3707972764968872
Validation loss: 1.7585941899207331

Epoch: 6| Step: 9
Training loss: 1.098181128501892
Validation loss: 1.7674508453697286

Epoch: 6| Step: 10
Training loss: 0.8968003392219543
Validation loss: 1.7952820075455533

Epoch: 6| Step: 11
Training loss: 0.6972528696060181
Validation loss: 1.8168379042738227

Epoch: 6| Step: 12
Training loss: 0.9733316898345947
Validation loss: 1.8868804631694671

Epoch: 6| Step: 13
Training loss: 0.5639669299125671
Validation loss: 1.9259827342084659

Epoch: 285| Step: 0
Training loss: 1.320063591003418
Validation loss: 1.9361073970794678

Epoch: 6| Step: 1
Training loss: 0.9345198273658752
Validation loss: 1.9052704995678318

Epoch: 6| Step: 2
Training loss: 0.983375072479248
Validation loss: 1.8958408448003954

Epoch: 6| Step: 3
Training loss: 1.151334285736084
Validation loss: 1.8673548570243261

Epoch: 6| Step: 4
Training loss: 0.6560468673706055
Validation loss: 1.8369435815400974

Epoch: 6| Step: 5
Training loss: 0.6207001209259033
Validation loss: 1.808877561682014

Epoch: 6| Step: 6
Training loss: 1.0020010471343994
Validation loss: 1.8038464233439455

Epoch: 6| Step: 7
Training loss: 0.6564126014709473
Validation loss: 1.8297332050979778

Epoch: 6| Step: 8
Training loss: 1.245080828666687
Validation loss: 1.8233803113301594

Epoch: 6| Step: 9
Training loss: 0.7179111242294312
Validation loss: 1.8452605355170466

Epoch: 6| Step: 10
Training loss: 0.8503971695899963
Validation loss: 1.8770539888771631

Epoch: 6| Step: 11
Training loss: 0.8958292007446289
Validation loss: 1.89109976701839

Epoch: 6| Step: 12
Training loss: 1.5615527629852295
Validation loss: 1.9016945105727001

Epoch: 6| Step: 13
Training loss: 0.9153075814247131
Validation loss: 1.8827089545547322

Epoch: 286| Step: 0
Training loss: 0.5485345125198364
Validation loss: 1.9135442395364084

Epoch: 6| Step: 1
Training loss: 1.519164800643921
Validation loss: 1.8912632824272237

Epoch: 6| Step: 2
Training loss: 1.139756202697754
Validation loss: 1.8606800853565175

Epoch: 6| Step: 3
Training loss: 0.7225898504257202
Validation loss: 1.8429043331453878

Epoch: 6| Step: 4
Training loss: 1.262894868850708
Validation loss: 1.8663368584007345

Epoch: 6| Step: 5
Training loss: 1.1377708911895752
Validation loss: 1.8463937454326178

Epoch: 6| Step: 6
Training loss: 0.42055952548980713
Validation loss: 1.8389676988765757

Epoch: 6| Step: 7
Training loss: 0.9735656976699829
Validation loss: 1.8031711386096092

Epoch: 6| Step: 8
Training loss: 0.8664048910140991
Validation loss: 1.8410228554920485

Epoch: 6| Step: 9
Training loss: 1.0434370040893555
Validation loss: 1.828389706150178

Epoch: 6| Step: 10
Training loss: 1.0761562585830688
Validation loss: 1.8218813019414102

Epoch: 6| Step: 11
Training loss: 1.1263773441314697
Validation loss: 1.810950292054043

Epoch: 6| Step: 12
Training loss: 0.8211218118667603
Validation loss: 1.795127441806178

Epoch: 6| Step: 13
Training loss: 0.5860416889190674
Validation loss: 1.7912255435861566

Epoch: 287| Step: 0
Training loss: 1.1541569232940674
Validation loss: 1.7788070273655716

Epoch: 6| Step: 1
Training loss: 1.0421587228775024
Validation loss: 1.766662331037624

Epoch: 6| Step: 2
Training loss: 1.2310621738433838
Validation loss: 1.7769459421916673

Epoch: 6| Step: 3
Training loss: 0.6990962028503418
Validation loss: 1.8032590881470711

Epoch: 6| Step: 4
Training loss: 0.9575679302215576
Validation loss: 1.8245367196298414

Epoch: 6| Step: 5
Training loss: 1.150068998336792
Validation loss: 1.8314017172782653

Epoch: 6| Step: 6
Training loss: 0.8080483675003052
Validation loss: 1.878215415503389

Epoch: 6| Step: 7
Training loss: 0.6143668293952942
Validation loss: 1.9013606809800672

Epoch: 6| Step: 8
Training loss: 0.7269446849822998
Validation loss: 1.906588690255278

Epoch: 6| Step: 9
Training loss: 1.4388606548309326
Validation loss: 1.9001841852741856

Epoch: 6| Step: 10
Training loss: 0.8221684098243713
Validation loss: 1.8889802373865598

Epoch: 6| Step: 11
Training loss: 0.5651726722717285
Validation loss: 1.8594082658008864

Epoch: 6| Step: 12
Training loss: 0.7934007048606873
Validation loss: 1.8337035153501777

Epoch: 6| Step: 13
Training loss: 1.3937350511550903
Validation loss: 1.8189600667645853

Epoch: 288| Step: 0
Training loss: 1.2645012140274048
Validation loss: 1.8249629005309074

Epoch: 6| Step: 1
Training loss: 0.5575700402259827
Validation loss: 1.8162817621743808

Epoch: 6| Step: 2
Training loss: 0.8926194310188293
Validation loss: 1.8575957205987745

Epoch: 6| Step: 3
Training loss: 1.1378109455108643
Validation loss: 1.842089883742794

Epoch: 6| Step: 4
Training loss: 0.4493022561073303
Validation loss: 1.8671702569530857

Epoch: 6| Step: 5
Training loss: 1.022658348083496
Validation loss: 1.893713915219871

Epoch: 6| Step: 6
Training loss: 1.463606834411621
Validation loss: 1.9603458732687018

Epoch: 6| Step: 7
Training loss: 0.9179792404174805
Validation loss: 1.9519232857611872

Epoch: 6| Step: 8
Training loss: 0.5885025262832642
Validation loss: 1.9441729143101683

Epoch: 6| Step: 9
Training loss: 1.1432490348815918
Validation loss: 1.9214347690664313

Epoch: 6| Step: 10
Training loss: 1.312746286392212
Validation loss: 1.8793305966161913

Epoch: 6| Step: 11
Training loss: 0.7520565986633301
Validation loss: 1.826882457220426

Epoch: 6| Step: 12
Training loss: 0.5556707382202148
Validation loss: 1.7948216058874642

Epoch: 6| Step: 13
Training loss: 0.7927988767623901
Validation loss: 1.803207120587749

Epoch: 289| Step: 0
Training loss: 1.6882424354553223
Validation loss: 1.821313481177053

Epoch: 6| Step: 1
Training loss: 0.7438315153121948
Validation loss: 1.8178150282111218

Epoch: 6| Step: 2
Training loss: 0.6537217497825623
Validation loss: 1.8562581077698739

Epoch: 6| Step: 3
Training loss: 1.461313247680664
Validation loss: 1.9028101403226134

Epoch: 6| Step: 4
Training loss: 0.8449196815490723
Validation loss: 1.9419662567877

Epoch: 6| Step: 5
Training loss: 0.8850418329238892
Validation loss: 1.9613151370838124

Epoch: 6| Step: 6
Training loss: 1.0238926410675049
Validation loss: 1.9779290101861442

Epoch: 6| Step: 7
Training loss: 0.7794288396835327
Validation loss: 1.934459904188751

Epoch: 6| Step: 8
Training loss: 0.7632521390914917
Validation loss: 1.8652528973035916

Epoch: 6| Step: 9
Training loss: 1.2713603973388672
Validation loss: 1.8016910155614216

Epoch: 6| Step: 10
Training loss: 0.8828930258750916
Validation loss: 1.7890851420740927

Epoch: 6| Step: 11
Training loss: 0.9311990737915039
Validation loss: 1.7948794070110525

Epoch: 6| Step: 12
Training loss: 0.6899338960647583
Validation loss: 1.790485841612662

Epoch: 6| Step: 13
Training loss: 0.6663348078727722
Validation loss: 1.810266835715181

Epoch: 290| Step: 0
Training loss: 0.9287611246109009
Validation loss: 1.86425369785678

Epoch: 6| Step: 1
Training loss: 0.7113680839538574
Validation loss: 1.8876776054341307

Epoch: 6| Step: 2
Training loss: 0.8590412139892578
Validation loss: 1.9011668056570075

Epoch: 6| Step: 3
Training loss: 1.178206443786621
Validation loss: 1.9248569088597451

Epoch: 6| Step: 4
Training loss: 0.9221831560134888
Validation loss: 1.923721134021718

Epoch: 6| Step: 5
Training loss: 1.1458526849746704
Validation loss: 1.8373859056862452

Epoch: 6| Step: 6
Training loss: 1.119105577468872
Validation loss: 1.8022410843961982

Epoch: 6| Step: 7
Training loss: 1.6204479932785034
Validation loss: 1.7846003552918792

Epoch: 6| Step: 8
Training loss: 0.6785397529602051
Validation loss: 1.7896434466044109

Epoch: 6| Step: 9
Training loss: 1.2532298564910889
Validation loss: 1.7819614538582422

Epoch: 6| Step: 10
Training loss: 0.43408143520355225
Validation loss: 1.8047791168253908

Epoch: 6| Step: 11
Training loss: 0.6554068326950073
Validation loss: 1.832180123175344

Epoch: 6| Step: 12
Training loss: 1.2250832319259644
Validation loss: 1.8659364677244616

Epoch: 6| Step: 13
Training loss: 0.7103588581085205
Validation loss: 1.9297508655055877

Epoch: 291| Step: 0
Training loss: 1.1402316093444824
Validation loss: 1.9607783299620434

Epoch: 6| Step: 1
Training loss: 0.8670832514762878
Validation loss: 1.9109438465487572

Epoch: 6| Step: 2
Training loss: 0.9984129667282104
Validation loss: 1.8694877047692575

Epoch: 6| Step: 3
Training loss: 0.8995370268821716
Validation loss: 1.878604491551717

Epoch: 6| Step: 4
Training loss: 1.0548475980758667
Validation loss: 1.8106321275875132

Epoch: 6| Step: 5
Training loss: 0.6134249567985535
Validation loss: 1.8274979822097286

Epoch: 6| Step: 6
Training loss: 1.3510894775390625
Validation loss: 1.8244807310001825

Epoch: 6| Step: 7
Training loss: 0.9868965744972229
Validation loss: 1.851012550374513

Epoch: 6| Step: 8
Training loss: 0.3992902934551239
Validation loss: 1.8213228077016852

Epoch: 6| Step: 9
Training loss: 1.260371208190918
Validation loss: 1.8164306661134124

Epoch: 6| Step: 10
Training loss: 1.0307025909423828
Validation loss: 1.8417327916750343

Epoch: 6| Step: 11
Training loss: 0.837527334690094
Validation loss: 1.8316273035541657

Epoch: 6| Step: 12
Training loss: 0.9649905562400818
Validation loss: 1.8878278822027228

Epoch: 6| Step: 13
Training loss: 0.439059317111969
Validation loss: 1.8688012323071879

Epoch: 292| Step: 0
Training loss: 0.46557825803756714
Validation loss: 1.866072226596135

Epoch: 6| Step: 1
Training loss: 0.5804184675216675
Validation loss: 1.852072879832278

Epoch: 6| Step: 2
Training loss: 1.0136548280715942
Validation loss: 1.8169201676563551

Epoch: 6| Step: 3
Training loss: 1.3323606252670288
Validation loss: 1.8281816513307634

Epoch: 6| Step: 4
Training loss: 0.8508437275886536
Validation loss: 1.8053827401130431

Epoch: 6| Step: 5
Training loss: 1.069915533065796
Validation loss: 1.8034565410306376

Epoch: 6| Step: 6
Training loss: 0.8615134954452515
Validation loss: 1.822536273669171

Epoch: 6| Step: 7
Training loss: 1.2221779823303223
Validation loss: 1.8446758677882533

Epoch: 6| Step: 8
Training loss: 1.061297059059143
Validation loss: 1.8540908675039969

Epoch: 6| Step: 9
Training loss: 1.1976453065872192
Validation loss: 1.862492125521424

Epoch: 6| Step: 10
Training loss: 1.1418190002441406
Validation loss: 1.8703813193946757

Epoch: 6| Step: 11
Training loss: 0.6083160638809204
Validation loss: 1.8895385854987687

Epoch: 6| Step: 12
Training loss: 0.7555806636810303
Validation loss: 1.9165005414716658

Epoch: 6| Step: 13
Training loss: 0.21388183534145355
Validation loss: 1.928881622129871

Epoch: 293| Step: 0
Training loss: 1.1344377994537354
Validation loss: 1.9048816760381062

Epoch: 6| Step: 1
Training loss: 0.8340228199958801
Validation loss: 1.8921059639223161

Epoch: 6| Step: 2
Training loss: 0.9937535524368286
Validation loss: 1.89209944458418

Epoch: 6| Step: 3
Training loss: 0.5516625642776489
Validation loss: 1.884431844116539

Epoch: 6| Step: 4
Training loss: 1.4005482196807861
Validation loss: 1.8677396389745897

Epoch: 6| Step: 5
Training loss: 0.8486568331718445
Validation loss: 1.8383944560122747

Epoch: 6| Step: 6
Training loss: 0.518526554107666
Validation loss: 1.8519727158290085

Epoch: 6| Step: 7
Training loss: 1.065662145614624
Validation loss: 1.809259101908694

Epoch: 6| Step: 8
Training loss: 0.8095550537109375
Validation loss: 1.824970410716149

Epoch: 6| Step: 9
Training loss: 0.9100924134254456
Validation loss: 1.8188317642417005

Epoch: 6| Step: 10
Training loss: 0.6771133542060852
Validation loss: 1.7940627580047936

Epoch: 6| Step: 11
Training loss: 1.0343866348266602
Validation loss: 1.8194873486795733

Epoch: 6| Step: 12
Training loss: 0.9001469612121582
Validation loss: 1.794951949068295

Epoch: 6| Step: 13
Training loss: 1.220905065536499
Validation loss: 1.79673598658654

Epoch: 294| Step: 0
Training loss: 1.0878639221191406
Validation loss: 1.802220913671678

Epoch: 6| Step: 1
Training loss: 0.9375838041305542
Validation loss: 1.7807663640668314

Epoch: 6| Step: 2
Training loss: 1.0096614360809326
Validation loss: 1.7832824978777158

Epoch: 6| Step: 3
Training loss: 0.7369335889816284
Validation loss: 1.7933009004080167

Epoch: 6| Step: 4
Training loss: 1.051445484161377
Validation loss: 1.7675972984683128

Epoch: 6| Step: 5
Training loss: 0.5546358823776245
Validation loss: 1.780285059764821

Epoch: 6| Step: 6
Training loss: 0.31882816553115845
Validation loss: 1.773671209171254

Epoch: 6| Step: 7
Training loss: 1.1392085552215576
Validation loss: 1.7803024425301501

Epoch: 6| Step: 8
Training loss: 0.565098762512207
Validation loss: 1.7914561097339918

Epoch: 6| Step: 9
Training loss: 1.1245008707046509
Validation loss: 1.8418480004033735

Epoch: 6| Step: 10
Training loss: 1.1775784492492676
Validation loss: 1.9014402345944477

Epoch: 6| Step: 11
Training loss: 1.108093500137329
Validation loss: 1.9695341638339463

Epoch: 6| Step: 12
Training loss: 0.8420017957687378
Validation loss: 1.988647440428375

Epoch: 6| Step: 13
Training loss: 1.1096433401107788
Validation loss: 1.9869627568029589

Epoch: 295| Step: 0
Training loss: 0.7959388494491577
Validation loss: 1.959380385696247

Epoch: 6| Step: 1
Training loss: 1.3467401266098022
Validation loss: 1.9103597582027476

Epoch: 6| Step: 2
Training loss: 0.33725109696388245
Validation loss: 1.8478878851859801

Epoch: 6| Step: 3
Training loss: 1.325293779373169
Validation loss: 1.817688666364198

Epoch: 6| Step: 4
Training loss: 0.719054102897644
Validation loss: 1.779186673061822

Epoch: 6| Step: 5
Training loss: 0.8053598403930664
Validation loss: 1.783984955920968

Epoch: 6| Step: 6
Training loss: 0.8430252075195312
Validation loss: 1.740033039482691

Epoch: 6| Step: 7
Training loss: 0.6018289923667908
Validation loss: 1.773102347568799

Epoch: 6| Step: 8
Training loss: 0.9358168840408325
Validation loss: 1.8055058038362892

Epoch: 6| Step: 9
Training loss: 1.1222949028015137
Validation loss: 1.8471348683039348

Epoch: 6| Step: 10
Training loss: 1.0069341659545898
Validation loss: 1.882537736687609

Epoch: 6| Step: 11
Training loss: 0.9833390712738037
Validation loss: 1.9310768317150813

Epoch: 6| Step: 12
Training loss: 0.878414511680603
Validation loss: 1.9408242189756004

Epoch: 6| Step: 13
Training loss: 0.713047206401825
Validation loss: 1.8820049057724655

Epoch: 296| Step: 0
Training loss: 0.8046310544013977
Validation loss: 1.861918362238074

Epoch: 6| Step: 1
Training loss: 0.5961834192276001
Validation loss: 1.8241183539872527

Epoch: 6| Step: 2
Training loss: 1.2871973514556885
Validation loss: 1.812599817911784

Epoch: 6| Step: 3
Training loss: 0.9993508458137512
Validation loss: 1.7884319982221049

Epoch: 6| Step: 4
Training loss: 1.4103198051452637
Validation loss: 1.782420927478421

Epoch: 6| Step: 5
Training loss: 0.8395552635192871
Validation loss: 1.795028394268405

Epoch: 6| Step: 6
Training loss: 0.681174635887146
Validation loss: 1.8060259011483961

Epoch: 6| Step: 7
Training loss: 0.5361854434013367
Validation loss: 1.8004529578711397

Epoch: 6| Step: 8
Training loss: 0.8257019519805908
Validation loss: 1.847198922147033

Epoch: 6| Step: 9
Training loss: 0.9884459972381592
Validation loss: 1.8651506516241259

Epoch: 6| Step: 10
Training loss: 0.8642949461936951
Validation loss: 1.8485097410858318

Epoch: 6| Step: 11
Training loss: 0.6103098392486572
Validation loss: 1.8477774832838325

Epoch: 6| Step: 12
Training loss: 0.8331296443939209
Validation loss: 1.8155585001873713

Epoch: 6| Step: 13
Training loss: 1.1390200853347778
Validation loss: 1.8251710373868224

Epoch: 297| Step: 0
Training loss: 0.7444530725479126
Validation loss: 1.8219192643319406

Epoch: 6| Step: 1
Training loss: 0.634329080581665
Validation loss: 1.825791007728987

Epoch: 6| Step: 2
Training loss: 0.8059980869293213
Validation loss: 1.821338345927577

Epoch: 6| Step: 3
Training loss: 0.9106990098953247
Validation loss: 1.8072136973821988

Epoch: 6| Step: 4
Training loss: 1.2867419719696045
Validation loss: 1.857135530441038

Epoch: 6| Step: 5
Training loss: 0.3084021210670471
Validation loss: 1.8675473748996694

Epoch: 6| Step: 6
Training loss: 1.2251942157745361
Validation loss: 1.9499422721965338

Epoch: 6| Step: 7
Training loss: 1.2908130884170532
Validation loss: 1.9502076538660194

Epoch: 6| Step: 8
Training loss: 0.8545613288879395
Validation loss: 1.9555027279802548

Epoch: 6| Step: 9
Training loss: 1.2413880825042725
Validation loss: 1.9360478501166067

Epoch: 6| Step: 10
Training loss: 0.741358757019043
Validation loss: 1.87356916294303

Epoch: 6| Step: 11
Training loss: 0.7565287351608276
Validation loss: 1.8217677967522734

Epoch: 6| Step: 12
Training loss: 0.9217857122421265
Validation loss: 1.7585221413643128

Epoch: 6| Step: 13
Training loss: 0.4339922070503235
Validation loss: 1.7633515968117663

Epoch: 298| Step: 0
Training loss: 1.4305503368377686
Validation loss: 1.746734050012404

Epoch: 6| Step: 1
Training loss: 0.8476629257202148
Validation loss: 1.743768758671258

Epoch: 6| Step: 2
Training loss: 0.9895340204238892
Validation loss: 1.7561646981905865

Epoch: 6| Step: 3
Training loss: 0.7476329803466797
Validation loss: 1.8256051642920381

Epoch: 6| Step: 4
Training loss: 1.040679693222046
Validation loss: 1.8937908334116782

Epoch: 6| Step: 5
Training loss: 0.8256646394729614
Validation loss: 1.9804858328193746

Epoch: 6| Step: 6
Training loss: 0.5616390705108643
Validation loss: 1.9734470254631453

Epoch: 6| Step: 7
Training loss: 0.7688953876495361
Validation loss: 1.9829972303041847

Epoch: 6| Step: 8
Training loss: 0.8232067823410034
Validation loss: 1.901334245999654

Epoch: 6| Step: 9
Training loss: 1.1328740119934082
Validation loss: 1.8297128318458475

Epoch: 6| Step: 10
Training loss: 0.9989243745803833
Validation loss: 1.7798872352928243

Epoch: 6| Step: 11
Training loss: 0.761626124382019
Validation loss: 1.7601921545561923

Epoch: 6| Step: 12
Training loss: 0.8065662980079651
Validation loss: 1.7595237224332747

Epoch: 6| Step: 13
Training loss: 0.8931517004966736
Validation loss: 1.7458805243174236

Epoch: 299| Step: 0
Training loss: 1.540712833404541
Validation loss: 1.7487263653867988

Epoch: 6| Step: 1
Training loss: 1.0570573806762695
Validation loss: 1.7357003483721005

Epoch: 6| Step: 2
Training loss: 0.9074819684028625
Validation loss: 1.785493891726258

Epoch: 6| Step: 3
Training loss: 0.9249188899993896
Validation loss: 1.82181135044303

Epoch: 6| Step: 4
Training loss: 0.9218618273735046
Validation loss: 1.880423270246034

Epoch: 6| Step: 5
Training loss: 0.4717458486557007
Validation loss: 1.902350261647214

Epoch: 6| Step: 6
Training loss: 1.1953480243682861
Validation loss: 1.9420170758360176

Epoch: 6| Step: 7
Training loss: 0.6424535512924194
Validation loss: 1.9166004696199972

Epoch: 6| Step: 8
Training loss: 0.9699049592018127
Validation loss: 1.9233745644169469

Epoch: 6| Step: 9
Training loss: 0.5765395760536194
Validation loss: 1.872441586627755

Epoch: 6| Step: 10
Training loss: 0.542472243309021
Validation loss: 1.796166681474255

Epoch: 6| Step: 11
Training loss: 0.8430824875831604
Validation loss: 1.794498589731032

Epoch: 6| Step: 12
Training loss: 0.9325635433197021
Validation loss: 1.763559159412179

Epoch: 6| Step: 13
Training loss: 0.9664434790611267
Validation loss: 1.7462015587796447

Epoch: 300| Step: 0
Training loss: 1.1391853094100952
Validation loss: 1.7352067732041883

Epoch: 6| Step: 1
Training loss: 0.6665413975715637
Validation loss: 1.7388127311583488

Epoch: 6| Step: 2
Training loss: 1.1549115180969238
Validation loss: 1.807642961061129

Epoch: 6| Step: 3
Training loss: 0.6145024299621582
Validation loss: 1.8416198351049935

Epoch: 6| Step: 4
Training loss: 0.8987172245979309
Validation loss: 1.8694604955693728

Epoch: 6| Step: 5
Training loss: 0.852225661277771
Validation loss: 1.959064402887898

Epoch: 6| Step: 6
Training loss: 0.757857620716095
Validation loss: 1.9396951583123976

Epoch: 6| Step: 7
Training loss: 1.0755243301391602
Validation loss: 1.9248619925591253

Epoch: 6| Step: 8
Training loss: 0.8695133328437805
Validation loss: 1.8747921387354534

Epoch: 6| Step: 9
Training loss: 0.623698353767395
Validation loss: 1.7974142489894744

Epoch: 6| Step: 10
Training loss: 0.7910023927688599
Validation loss: 1.7534523138435938

Epoch: 6| Step: 11
Training loss: 0.8916144371032715
Validation loss: 1.7932978266028947

Epoch: 6| Step: 12
Training loss: 0.965667188167572
Validation loss: 1.774087066291481

Epoch: 6| Step: 13
Training loss: 1.0447551012039185
Validation loss: 1.8273806238687167

Epoch: 301| Step: 0
Training loss: 0.8181169033050537
Validation loss: 1.8468941680846676

Epoch: 6| Step: 1
Training loss: 0.603216826915741
Validation loss: 1.8739470256272184

Epoch: 6| Step: 2
Training loss: 1.0554099082946777
Validation loss: 1.8746536777865501

Epoch: 6| Step: 3
Training loss: 0.9443771839141846
Validation loss: 1.8699094364720006

Epoch: 6| Step: 4
Training loss: 0.7314131259918213
Validation loss: 1.8748278335858417

Epoch: 6| Step: 5
Training loss: 0.5668120384216309
Validation loss: 1.8564103521326536

Epoch: 6| Step: 6
Training loss: 0.8566807508468628
Validation loss: 1.8436424270752938

Epoch: 6| Step: 7
Training loss: 0.832144021987915
Validation loss: 1.8384586534192484

Epoch: 6| Step: 8
Training loss: 1.1236342191696167
Validation loss: 1.8533734019084642

Epoch: 6| Step: 9
Training loss: 0.521468997001648
Validation loss: 1.8509293551086097

Epoch: 6| Step: 10
Training loss: 0.8267074823379517
Validation loss: 1.8505345659871255

Epoch: 6| Step: 11
Training loss: 0.8393566608428955
Validation loss: 1.8220454531331216

Epoch: 6| Step: 12
Training loss: 1.0002721548080444
Validation loss: 1.8285109637885966

Epoch: 6| Step: 13
Training loss: 1.1356980800628662
Validation loss: 1.8052647421436925

Epoch: 302| Step: 0
Training loss: 1.1558921337127686
Validation loss: 1.7677926863393476

Epoch: 6| Step: 1
Training loss: 0.9270497560501099
Validation loss: 1.7408839643642466

Epoch: 6| Step: 2
Training loss: 0.8717464208602905
Validation loss: 1.745035840618995

Epoch: 6| Step: 3
Training loss: 0.7246585488319397
Validation loss: 1.7814633154099988

Epoch: 6| Step: 4
Training loss: 0.49641644954681396
Validation loss: 1.7847067732964792

Epoch: 6| Step: 5
Training loss: 0.5687521696090698
Validation loss: 1.8530032275825419

Epoch: 6| Step: 6
Training loss: 1.4123773574829102
Validation loss: 1.8559573004322667

Epoch: 6| Step: 7
Training loss: 1.2446515560150146
Validation loss: 1.8429665155308221

Epoch: 6| Step: 8
Training loss: 0.9198194742202759
Validation loss: 1.824244055696713

Epoch: 6| Step: 9
Training loss: 0.5954395532608032
Validation loss: 1.8211775966869888

Epoch: 6| Step: 10
Training loss: 0.9768663048744202
Validation loss: 1.8029802448006087

Epoch: 6| Step: 11
Training loss: 0.9557965397834778
Validation loss: 1.8153833919955837

Epoch: 6| Step: 12
Training loss: 0.5192546844482422
Validation loss: 1.835533216435422

Epoch: 6| Step: 13
Training loss: 0.28725895285606384
Validation loss: 1.8457038479466592

Epoch: 303| Step: 0
Training loss: 0.8991835117340088
Validation loss: 1.873645128742341

Epoch: 6| Step: 1
Training loss: 1.0407503843307495
Validation loss: 1.8789230572280062

Epoch: 6| Step: 2
Training loss: 0.7810726165771484
Validation loss: 1.927826972417934

Epoch: 6| Step: 3
Training loss: 0.2800544202327728
Validation loss: 1.9302167661728398

Epoch: 6| Step: 4
Training loss: 1.22548508644104
Validation loss: 1.8990134359687887

Epoch: 6| Step: 5
Training loss: 0.877591609954834
Validation loss: 1.8604689093046292

Epoch: 6| Step: 6
Training loss: 0.803766667842865
Validation loss: 1.8401367779700988

Epoch: 6| Step: 7
Training loss: 1.0519449710845947
Validation loss: 1.8207350520677463

Epoch: 6| Step: 8
Training loss: 0.4971349835395813
Validation loss: 1.8114276022039435

Epoch: 6| Step: 9
Training loss: 0.7666971683502197
Validation loss: 1.8012117993447088

Epoch: 6| Step: 10
Training loss: 1.1610817909240723
Validation loss: 1.7974841030695106

Epoch: 6| Step: 11
Training loss: 0.8220267295837402
Validation loss: 1.765117883682251

Epoch: 6| Step: 12
Training loss: 0.9425647258758545
Validation loss: 1.8092532721898889

Epoch: 6| Step: 13
Training loss: 0.5653873682022095
Validation loss: 1.795077916114561

Epoch: 304| Step: 0
Training loss: 1.0703983306884766
Validation loss: 1.8092585302168323

Epoch: 6| Step: 1
Training loss: 1.0118299722671509
Validation loss: 1.8585417193751181

Epoch: 6| Step: 2
Training loss: 0.7085298895835876
Validation loss: 1.86685017231972

Epoch: 6| Step: 3
Training loss: 0.5343446731567383
Validation loss: 1.8153245295247724

Epoch: 6| Step: 4
Training loss: 0.6698942184448242
Validation loss: 1.8004215519915345

Epoch: 6| Step: 5
Training loss: 1.2725121974945068
Validation loss: 1.7322180501876339

Epoch: 6| Step: 6
Training loss: 0.5902742147445679
Validation loss: 1.7631030467248732

Epoch: 6| Step: 7
Training loss: 0.5113228559494019
Validation loss: 1.819276084182083

Epoch: 6| Step: 8
Training loss: 0.7280023694038391
Validation loss: 1.868932959853962

Epoch: 6| Step: 9
Training loss: 1.148979902267456
Validation loss: 1.8877554862729964

Epoch: 6| Step: 10
Training loss: 0.7159598469734192
Validation loss: 1.892392755836569

Epoch: 6| Step: 11
Training loss: 0.9847308993339539
Validation loss: 1.9223678265848467

Epoch: 6| Step: 12
Training loss: 0.8389379978179932
Validation loss: 1.915415576709214

Epoch: 6| Step: 13
Training loss: 1.0823663473129272
Validation loss: 1.8997906279820267

Epoch: 305| Step: 0
Training loss: 1.3102400302886963
Validation loss: 1.857109724834401

Epoch: 6| Step: 1
Training loss: 0.8790522217750549
Validation loss: 1.8330632025195706

Epoch: 6| Step: 2
Training loss: 1.1574773788452148
Validation loss: 1.8301688650602936

Epoch: 6| Step: 3
Training loss: 0.6347401142120361
Validation loss: 1.8264794772671116

Epoch: 6| Step: 4
Training loss: 1.1230037212371826
Validation loss: 1.7907382378014185

Epoch: 6| Step: 5
Training loss: 0.8458229303359985
Validation loss: 1.7848149371403519

Epoch: 6| Step: 6
Training loss: 0.5147523283958435
Validation loss: 1.803444399628588

Epoch: 6| Step: 7
Training loss: 0.3350861370563507
Validation loss: 1.7888499331730667

Epoch: 6| Step: 8
Training loss: 0.8046443462371826
Validation loss: 1.8060808630399807

Epoch: 6| Step: 9
Training loss: 0.6514196395874023
Validation loss: 1.8270504192639423

Epoch: 6| Step: 10
Training loss: 1.0146853923797607
Validation loss: 1.852488802325341

Epoch: 6| Step: 11
Training loss: 0.8552554845809937
Validation loss: 1.832692744911358

Epoch: 6| Step: 12
Training loss: 0.5517494678497314
Validation loss: 1.8039870903056154

Epoch: 6| Step: 13
Training loss: 0.9646121263504028
Validation loss: 1.789177498509807

Epoch: 306| Step: 0
Training loss: 1.060707449913025
Validation loss: 1.7825709004555979

Epoch: 6| Step: 1
Training loss: 1.0168334245681763
Validation loss: 1.7761702358081777

Epoch: 6| Step: 2
Training loss: 0.6472172141075134
Validation loss: 1.791763118518296

Epoch: 6| Step: 3
Training loss: 0.6153351068496704
Validation loss: 1.8242821911329865

Epoch: 6| Step: 4
Training loss: 0.6210951209068298
Validation loss: 1.8262234977496568

Epoch: 6| Step: 5
Training loss: 0.7564681768417358
Validation loss: 1.8392230900385047

Epoch: 6| Step: 6
Training loss: 0.6444168090820312
Validation loss: 1.8460720251965266

Epoch: 6| Step: 7
Training loss: 0.9992657899856567
Validation loss: 1.8594719722706785

Epoch: 6| Step: 8
Training loss: 0.8582714200019836
Validation loss: 1.842097293946051

Epoch: 6| Step: 9
Training loss: 0.665518045425415
Validation loss: 1.8713783166741813

Epoch: 6| Step: 10
Training loss: 0.7426847815513611
Validation loss: 1.8871893805842246

Epoch: 6| Step: 11
Training loss: 0.8186436295509338
Validation loss: 1.8868827563460155

Epoch: 6| Step: 12
Training loss: 0.7969000935554504
Validation loss: 1.8790872045742568

Epoch: 6| Step: 13
Training loss: 1.3839762210845947
Validation loss: 1.8437078306751866

Epoch: 307| Step: 0
Training loss: 1.3077392578125
Validation loss: 1.796836168535294

Epoch: 6| Step: 1
Training loss: 0.6272660493850708
Validation loss: 1.789015559739964

Epoch: 6| Step: 2
Training loss: 0.742538332939148
Validation loss: 1.7725949992415726

Epoch: 6| Step: 3
Training loss: 0.5518527626991272
Validation loss: 1.7754387791438768

Epoch: 6| Step: 4
Training loss: 1.1371378898620605
Validation loss: 1.782339185796758

Epoch: 6| Step: 5
Training loss: 1.123307704925537
Validation loss: 1.8239564754629647

Epoch: 6| Step: 6
Training loss: 0.8354341983795166
Validation loss: 1.8320160527383127

Epoch: 6| Step: 7
Training loss: 0.4553232491016388
Validation loss: 1.8579163346239316

Epoch: 6| Step: 8
Training loss: 0.6668880581855774
Validation loss: 1.8815078658442344

Epoch: 6| Step: 9
Training loss: 0.6332796812057495
Validation loss: 1.8477156034079931

Epoch: 6| Step: 10
Training loss: 0.793581485748291
Validation loss: 1.8622879071902203

Epoch: 6| Step: 11
Training loss: 1.16902756690979
Validation loss: 1.8605458723601473

Epoch: 6| Step: 12
Training loss: 0.4279976487159729
Validation loss: 1.8463148788739276

Epoch: 6| Step: 13
Training loss: 0.6741523742675781
Validation loss: 1.8248479923894327

Epoch: 308| Step: 0
Training loss: 0.4889020025730133
Validation loss: 1.8199591559748496

Epoch: 6| Step: 1
Training loss: 0.9618821144104004
Validation loss: 1.808787671468591

Epoch: 6| Step: 2
Training loss: 0.7085134387016296
Validation loss: 1.8168460246055358

Epoch: 6| Step: 3
Training loss: 0.6737340688705444
Validation loss: 1.8185763756434123

Epoch: 6| Step: 4
Training loss: 0.56687992811203
Validation loss: 1.8452470610218663

Epoch: 6| Step: 5
Training loss: 1.0292880535125732
Validation loss: 1.8435700708819973

Epoch: 6| Step: 6
Training loss: 1.1052029132843018
Validation loss: 1.85005065958987

Epoch: 6| Step: 7
Training loss: 0.8653738498687744
Validation loss: 1.8554924841850036

Epoch: 6| Step: 8
Training loss: 0.8636320233345032
Validation loss: 1.869836744441781

Epoch: 6| Step: 9
Training loss: 0.7785750031471252
Validation loss: 1.8557669731878466

Epoch: 6| Step: 10
Training loss: 1.0431547164916992
Validation loss: 1.8427147596113143

Epoch: 6| Step: 11
Training loss: 0.37900733947753906
Validation loss: 1.814988540064904

Epoch: 6| Step: 12
Training loss: 0.6496989727020264
Validation loss: 1.8161742917952999

Epoch: 6| Step: 13
Training loss: 1.2526391744613647
Validation loss: 1.823853927273904

Epoch: 309| Step: 0
Training loss: 1.174567699432373
Validation loss: 1.8179858012865948

Epoch: 6| Step: 1
Training loss: 0.7305479645729065
Validation loss: 1.7882802281328427

Epoch: 6| Step: 2
Training loss: 0.6594717502593994
Validation loss: 1.8282840815923547

Epoch: 6| Step: 3
Training loss: 0.9326456785202026
Validation loss: 1.8321821561423681

Epoch: 6| Step: 4
Training loss: 0.7124801278114319
Validation loss: 1.8494530006121563

Epoch: 6| Step: 5
Training loss: 0.7890613675117493
Validation loss: 1.8654388753316735

Epoch: 6| Step: 6
Training loss: 0.3804105818271637
Validation loss: 1.8875033752892607

Epoch: 6| Step: 7
Training loss: 1.0566697120666504
Validation loss: 1.911053733159137

Epoch: 6| Step: 8
Training loss: 0.8644458651542664
Validation loss: 1.9406366604630665

Epoch: 6| Step: 9
Training loss: 0.9401119351387024
Validation loss: 1.8875482697640695

Epoch: 6| Step: 10
Training loss: 0.889814019203186
Validation loss: 1.8461142983487857

Epoch: 6| Step: 11
Training loss: 0.39284828305244446
Validation loss: 1.8058675489118021

Epoch: 6| Step: 12
Training loss: 0.8967396020889282
Validation loss: 1.8057237055993849

Epoch: 6| Step: 13
Training loss: 1.1299891471862793
Validation loss: 1.759310713378332

Epoch: 310| Step: 0
Training loss: 0.8473731279373169
Validation loss: 1.7901046506820186

Epoch: 6| Step: 1
Training loss: 0.8262485265731812
Validation loss: 1.7724151419055076

Epoch: 6| Step: 2
Training loss: 0.8534161448478699
Validation loss: 1.72957411889107

Epoch: 6| Step: 3
Training loss: 1.0621848106384277
Validation loss: 1.7812029597579793

Epoch: 6| Step: 4
Training loss: 0.5259272456169128
Validation loss: 1.855676520255304

Epoch: 6| Step: 5
Training loss: 0.4469097852706909
Validation loss: 1.9258939719969226

Epoch: 6| Step: 6
Training loss: 1.2103123664855957
Validation loss: 1.9651749057154502

Epoch: 6| Step: 7
Training loss: 0.5427857637405396
Validation loss: 1.940360887076265

Epoch: 6| Step: 8
Training loss: 0.7745490670204163
Validation loss: 1.91959120381263

Epoch: 6| Step: 9
Training loss: 0.972760796546936
Validation loss: 1.8499266383468465

Epoch: 6| Step: 10
Training loss: 0.7602613568305969
Validation loss: 1.8613542561889977

Epoch: 6| Step: 11
Training loss: 1.0765327215194702
Validation loss: 1.848786484810614

Epoch: 6| Step: 12
Training loss: 0.8909144401550293
Validation loss: 1.8281716890232538

Epoch: 6| Step: 13
Training loss: 0.5527708530426025
Validation loss: 1.814291443876041

Epoch: 311| Step: 0
Training loss: 0.9496285915374756
Validation loss: 1.8300654131879088

Epoch: 6| Step: 1
Training loss: 0.7125200629234314
Validation loss: 1.851236076765163

Epoch: 6| Step: 2
Training loss: 1.014562964439392
Validation loss: 1.8542499055144608

Epoch: 6| Step: 3
Training loss: 0.6741740703582764
Validation loss: 1.8995989702081169

Epoch: 6| Step: 4
Training loss: 0.7720596790313721
Validation loss: 1.9066247081243863

Epoch: 6| Step: 5
Training loss: 0.8267964720726013
Validation loss: 1.9037292747087375

Epoch: 6| Step: 6
Training loss: 0.7877079844474792
Validation loss: 1.8969364294441797

Epoch: 6| Step: 7
Training loss: 0.7535099387168884
Validation loss: 1.8569607093770018

Epoch: 6| Step: 8
Training loss: 0.43749210238456726
Validation loss: 1.816616560823174

Epoch: 6| Step: 9
Training loss: 0.8407367467880249
Validation loss: 1.8010805627351165

Epoch: 6| Step: 10
Training loss: 0.487380713224411
Validation loss: 1.798858973928677

Epoch: 6| Step: 11
Training loss: 0.5902561545372009
Validation loss: 1.7753651129302157

Epoch: 6| Step: 12
Training loss: 1.2120275497436523
Validation loss: 1.774186457357099

Epoch: 6| Step: 13
Training loss: 1.128275990486145
Validation loss: 1.8193323496849305

Epoch: 312| Step: 0
Training loss: 0.9490033388137817
Validation loss: 1.8369999470249299

Epoch: 6| Step: 1
Training loss: 0.9025191068649292
Validation loss: 1.8726694199346727

Epoch: 6| Step: 2
Training loss: 0.9804595708847046
Validation loss: 1.896163753283921

Epoch: 6| Step: 3
Training loss: 0.8269977569580078
Validation loss: 1.9193329580368534

Epoch: 6| Step: 4
Training loss: 1.2161027193069458
Validation loss: 1.9301765041966592

Epoch: 6| Step: 5
Training loss: 0.8112361431121826
Validation loss: 1.882802463346912

Epoch: 6| Step: 6
Training loss: 0.574773907661438
Validation loss: 1.8139716937977781

Epoch: 6| Step: 7
Training loss: 0.4736905097961426
Validation loss: 1.8389457130944857

Epoch: 6| Step: 8
Training loss: 0.5211403369903564
Validation loss: 1.8134513016669982

Epoch: 6| Step: 9
Training loss: 0.7600665092468262
Validation loss: 1.8154120163250995

Epoch: 6| Step: 10
Training loss: 0.7293264865875244
Validation loss: 1.797499329813065

Epoch: 6| Step: 11
Training loss: 0.5594998002052307
Validation loss: 1.788973674979261

Epoch: 6| Step: 12
Training loss: 0.8789950609207153
Validation loss: 1.7765826281680857

Epoch: 6| Step: 13
Training loss: 0.9694380164146423
Validation loss: 1.8151393064888575

Epoch: 313| Step: 0
Training loss: 0.9910811185836792
Validation loss: 1.836181830334407

Epoch: 6| Step: 1
Training loss: 0.6632668375968933
Validation loss: 1.8331595261891682

Epoch: 6| Step: 2
Training loss: 0.45454496145248413
Validation loss: 1.8415178214350054

Epoch: 6| Step: 3
Training loss: 0.8479489684104919
Validation loss: 1.8375556891964329

Epoch: 6| Step: 4
Training loss: 1.2211798429489136
Validation loss: 1.855537308800605

Epoch: 6| Step: 5
Training loss: 1.0676360130310059
Validation loss: 1.848271757043818

Epoch: 6| Step: 6
Training loss: 0.5622564554214478
Validation loss: 1.8831135508834675

Epoch: 6| Step: 7
Training loss: 0.9476606845855713
Validation loss: 1.8498919702345324

Epoch: 6| Step: 8
Training loss: 0.39295870065689087
Validation loss: 1.8577719426924182

Epoch: 6| Step: 9
Training loss: 0.778638482093811
Validation loss: 1.8309436293058499

Epoch: 6| Step: 10
Training loss: 0.3476382791996002
Validation loss: 1.8138689853811776

Epoch: 6| Step: 11
Training loss: 0.82732093334198
Validation loss: 1.806504544391427

Epoch: 6| Step: 12
Training loss: 0.9865173697471619
Validation loss: 1.8081172217604935

Epoch: 6| Step: 13
Training loss: 0.6756554841995239
Validation loss: 1.8217710718031852

Epoch: 314| Step: 0
Training loss: 0.6408832669258118
Validation loss: 1.8620221255927958

Epoch: 6| Step: 1
Training loss: 0.7875028848648071
Validation loss: 1.8460078457350373

Epoch: 6| Step: 2
Training loss: 0.8093663454055786
Validation loss: 1.8399993540138326

Epoch: 6| Step: 3
Training loss: 0.8998146057128906
Validation loss: 1.8536335422146706

Epoch: 6| Step: 4
Training loss: 0.6390340328216553
Validation loss: 1.8766952176247873

Epoch: 6| Step: 5
Training loss: 0.7448452711105347
Validation loss: 1.885526664795414

Epoch: 6| Step: 6
Training loss: 0.7894909381866455
Validation loss: 1.908882205204297

Epoch: 6| Step: 7
Training loss: 0.45725566148757935
Validation loss: 1.9035164258813346

Epoch: 6| Step: 8
Training loss: 0.6680265665054321
Validation loss: 1.92814447610609

Epoch: 6| Step: 9
Training loss: 0.6384307742118835
Validation loss: 1.9299458611396052

Epoch: 6| Step: 10
Training loss: 1.2529062032699585
Validation loss: 1.9221276185845817

Epoch: 6| Step: 11
Training loss: 0.5115157961845398
Validation loss: 1.9413618169805056

Epoch: 6| Step: 12
Training loss: 1.1671466827392578
Validation loss: 1.8834785133279779

Epoch: 6| Step: 13
Training loss: 0.8316470980644226
Validation loss: 1.8809959580821376

Epoch: 315| Step: 0
Training loss: 0.5573680400848389
Validation loss: 1.8409917380220147

Epoch: 6| Step: 1
Training loss: 0.8532763719558716
Validation loss: 1.8600983747871973

Epoch: 6| Step: 2
Training loss: 0.6170428395271301
Validation loss: 1.8425333615272277

Epoch: 6| Step: 3
Training loss: 0.7641539573669434
Validation loss: 1.842854784381005

Epoch: 6| Step: 4
Training loss: 0.9706934690475464
Validation loss: 1.837465093981835

Epoch: 6| Step: 5
Training loss: 1.175745964050293
Validation loss: 1.843868806797971

Epoch: 6| Step: 6
Training loss: 0.7846511602401733
Validation loss: 1.838226536268829

Epoch: 6| Step: 7
Training loss: 0.7300772666931152
Validation loss: 1.8574576300959433

Epoch: 6| Step: 8
Training loss: 0.9169198274612427
Validation loss: 1.892732920185212

Epoch: 6| Step: 9
Training loss: 0.5807111263275146
Validation loss: 1.8929791565864318

Epoch: 6| Step: 10
Training loss: 0.42368531227111816
Validation loss: 1.9051641277087632

Epoch: 6| Step: 11
Training loss: 0.7361409664154053
Validation loss: 1.9019460216645272

Epoch: 6| Step: 12
Training loss: 0.9133771657943726
Validation loss: 1.8982167333684943

Epoch: 6| Step: 13
Training loss: 0.8274127840995789
Validation loss: 1.8959966398054553

Epoch: 316| Step: 0
Training loss: 1.0834784507751465
Validation loss: 1.8727418491917271

Epoch: 6| Step: 1
Training loss: 0.3778213560581207
Validation loss: 1.872242582741604

Epoch: 6| Step: 2
Training loss: 0.7596533298492432
Validation loss: 1.8790348499051985

Epoch: 6| Step: 3
Training loss: 0.591315507888794
Validation loss: 1.831005936027855

Epoch: 6| Step: 4
Training loss: 0.47115859389305115
Validation loss: 1.8290341977150208

Epoch: 6| Step: 5
Training loss: 0.7405109405517578
Validation loss: 1.806079702992593

Epoch: 6| Step: 6
Training loss: 1.0431534051895142
Validation loss: 1.847990494902416

Epoch: 6| Step: 7
Training loss: 1.0416874885559082
Validation loss: 1.8297263858138875

Epoch: 6| Step: 8
Training loss: 0.7838455438613892
Validation loss: 1.8465214737000004

Epoch: 6| Step: 9
Training loss: 0.9383226633071899
Validation loss: 1.8548524328457412

Epoch: 6| Step: 10
Training loss: 0.819469690322876
Validation loss: 1.886111327396926

Epoch: 6| Step: 11
Training loss: 0.7415947914123535
Validation loss: 1.8773668017438663

Epoch: 6| Step: 12
Training loss: 0.6992058157920837
Validation loss: 1.8804838324105868

Epoch: 6| Step: 13
Training loss: 0.4243415594100952
Validation loss: 1.8688423531029814

Epoch: 317| Step: 0
Training loss: 0.7872317433357239
Validation loss: 1.8821818982401202

Epoch: 6| Step: 1
Training loss: 1.023468255996704
Validation loss: 1.8625935303267611

Epoch: 6| Step: 2
Training loss: 0.9298118352890015
Validation loss: 1.881606032771449

Epoch: 6| Step: 3
Training loss: 0.6894288063049316
Validation loss: 1.8440264476242887

Epoch: 6| Step: 4
Training loss: 0.6940473318099976
Validation loss: 1.8568916577164845

Epoch: 6| Step: 5
Training loss: 0.4723668396472931
Validation loss: 1.8595722631741596

Epoch: 6| Step: 6
Training loss: 0.6404153108596802
Validation loss: 1.8795857596141037

Epoch: 6| Step: 7
Training loss: 0.633807897567749
Validation loss: 1.896820108095805

Epoch: 6| Step: 8
Training loss: 0.3979972004890442
Validation loss: 1.8815309463008758

Epoch: 6| Step: 9
Training loss: 1.2365120649337769
Validation loss: 1.915200339850559

Epoch: 6| Step: 10
Training loss: 1.0378477573394775
Validation loss: 1.8965500913640505

Epoch: 6| Step: 11
Training loss: 0.4481436312198639
Validation loss: 1.8589650251532113

Epoch: 6| Step: 12
Training loss: 0.6642450094223022
Validation loss: 1.8589170773824055

Epoch: 6| Step: 13
Training loss: 1.1038322448730469
Validation loss: 1.8872825304667156

Epoch: 318| Step: 0
Training loss: 0.5332107543945312
Validation loss: 1.9369468688964844

Epoch: 6| Step: 1
Training loss: 0.8555744886398315
Validation loss: 1.952531458229147

Epoch: 6| Step: 2
Training loss: 0.6190877556800842
Validation loss: 1.971404831896546

Epoch: 6| Step: 3
Training loss: 1.0705413818359375
Validation loss: 1.9757959637590634

Epoch: 6| Step: 4
Training loss: 0.7869154810905457
Validation loss: 1.9275788530226676

Epoch: 6| Step: 5
Training loss: 0.883622407913208
Validation loss: 1.8864800519840692

Epoch: 6| Step: 6
Training loss: 0.6490518450737
Validation loss: 1.8861805290304205

Epoch: 6| Step: 7
Training loss: 0.7627427577972412
Validation loss: 1.8669585053638746

Epoch: 6| Step: 8
Training loss: 0.8594033122062683
Validation loss: 1.8846973860135643

Epoch: 6| Step: 9
Training loss: 0.5518081188201904
Validation loss: 1.8516296686664704

Epoch: 6| Step: 10
Training loss: 1.236496925354004
Validation loss: 1.8628979959795553

Epoch: 6| Step: 11
Training loss: 0.7617397904396057
Validation loss: 1.8683223378273748

Epoch: 6| Step: 12
Training loss: 0.6593608260154724
Validation loss: 1.873248992427703

Epoch: 6| Step: 13
Training loss: 0.699800431728363
Validation loss: 1.8573323270326019

Epoch: 319| Step: 0
Training loss: 0.7698240876197815
Validation loss: 1.8307649884172665

Epoch: 6| Step: 1
Training loss: 1.204291582107544
Validation loss: 1.8026899086531771

Epoch: 6| Step: 2
Training loss: 0.4819706678390503
Validation loss: 1.795911935067946

Epoch: 6| Step: 3
Training loss: 0.47306662797927856
Validation loss: 1.8251074334626556

Epoch: 6| Step: 4
Training loss: 0.7749375104904175
Validation loss: 1.829884107394885

Epoch: 6| Step: 5
Training loss: 0.5591046810150146
Validation loss: 1.8285978378788117

Epoch: 6| Step: 6
Training loss: 0.7641814947128296
Validation loss: 1.8089770219659294

Epoch: 6| Step: 7
Training loss: 0.5682820081710815
Validation loss: 1.789209996500323

Epoch: 6| Step: 8
Training loss: 1.1416361331939697
Validation loss: 1.7661461701957129

Epoch: 6| Step: 9
Training loss: 0.7988948822021484
Validation loss: 1.7888252606955908

Epoch: 6| Step: 10
Training loss: 1.0732320547103882
Validation loss: 1.7769326420240505

Epoch: 6| Step: 11
Training loss: 0.8638498783111572
Validation loss: 1.8147186835606892

Epoch: 6| Step: 12
Training loss: 0.706623911857605
Validation loss: 1.8511164034566572

Epoch: 6| Step: 13
Training loss: 0.47095292806625366
Validation loss: 1.8710027112755725

Epoch: 320| Step: 0
Training loss: 0.6905062198638916
Validation loss: 1.9159228724818076

Epoch: 6| Step: 1
Training loss: 1.4699978828430176
Validation loss: 1.902216524206182

Epoch: 6| Step: 2
Training loss: 0.7547968029975891
Validation loss: 1.8974701037970922

Epoch: 6| Step: 3
Training loss: 0.794716477394104
Validation loss: 1.8875516230060208

Epoch: 6| Step: 4
Training loss: 0.8785905838012695
Validation loss: 1.832827010462361

Epoch: 6| Step: 5
Training loss: 0.4259956479072571
Validation loss: 1.803396963304089

Epoch: 6| Step: 6
Training loss: 0.9232620596885681
Validation loss: 1.8028488133543281

Epoch: 6| Step: 7
Training loss: 1.002255916595459
Validation loss: 1.7592736597984069

Epoch: 6| Step: 8
Training loss: 0.47797149419784546
Validation loss: 1.7678846184925368

Epoch: 6| Step: 9
Training loss: 0.39443618059158325
Validation loss: 1.746172273030845

Epoch: 6| Step: 10
Training loss: 0.5362379550933838
Validation loss: 1.8054240313909387

Epoch: 6| Step: 11
Training loss: 0.6421701908111572
Validation loss: 1.7968099617188977

Epoch: 6| Step: 12
Training loss: 0.5219860672950745
Validation loss: 1.8140413402229227

Epoch: 6| Step: 13
Training loss: 0.9764391779899597
Validation loss: 1.8479121231263684

Epoch: 321| Step: 0
Training loss: 0.9167331457138062
Validation loss: 1.8639144538551249

Epoch: 6| Step: 1
Training loss: 0.8590957522392273
Validation loss: 1.8878084331430414

Epoch: 6| Step: 2
Training loss: 1.141261339187622
Validation loss: 1.8742647632475822

Epoch: 6| Step: 3
Training loss: 0.7420369386672974
Validation loss: 1.8554819604401946

Epoch: 6| Step: 4
Training loss: 0.7431213855743408
Validation loss: 1.8411628418071295

Epoch: 6| Step: 5
Training loss: 0.24171610176563263
Validation loss: 1.8570869532964562

Epoch: 6| Step: 6
Training loss: 0.5305376052856445
Validation loss: 1.8449704441972958

Epoch: 6| Step: 7
Training loss: 0.8758368492126465
Validation loss: 1.85357653966514

Epoch: 6| Step: 8
Training loss: 0.6910954713821411
Validation loss: 1.8683349060755905

Epoch: 6| Step: 9
Training loss: 0.7418326139450073
Validation loss: 1.8627461746174803

Epoch: 6| Step: 10
Training loss: 0.4192437529563904
Validation loss: 1.8823646704355876

Epoch: 6| Step: 11
Training loss: 0.5542583465576172
Validation loss: 1.8812997059155536

Epoch: 6| Step: 12
Training loss: 0.7280089855194092
Validation loss: 1.8948027715888074

Epoch: 6| Step: 13
Training loss: 1.588944673538208
Validation loss: 1.8776000058779152

Epoch: 322| Step: 0
Training loss: 0.9473757743835449
Validation loss: 1.8790211472460019

Epoch: 6| Step: 1
Training loss: 0.6165118217468262
Validation loss: 1.9096481723170127

Epoch: 6| Step: 2
Training loss: 0.828854501247406
Validation loss: 1.87776993936108

Epoch: 6| Step: 3
Training loss: 0.871595025062561
Validation loss: 1.8774843587670276

Epoch: 6| Step: 4
Training loss: 0.7266957759857178
Validation loss: 1.8872285914677445

Epoch: 6| Step: 5
Training loss: 0.43305113911628723
Validation loss: 1.8565521188961562

Epoch: 6| Step: 6
Training loss: 0.6088658571243286
Validation loss: 1.8797875424867034

Epoch: 6| Step: 7
Training loss: 1.0683544874191284
Validation loss: 1.8520103186689398

Epoch: 6| Step: 8
Training loss: 0.882861316204071
Validation loss: 1.8860623105879752

Epoch: 6| Step: 9
Training loss: 0.9175534248352051
Validation loss: 1.8359882959755518

Epoch: 6| Step: 10
Training loss: 0.3885633051395416
Validation loss: 1.8582793538288405

Epoch: 6| Step: 11
Training loss: 0.9512010812759399
Validation loss: 1.8562917170986053

Epoch: 6| Step: 12
Training loss: 0.7635030746459961
Validation loss: 1.8489220385910363

Epoch: 6| Step: 13
Training loss: 0.7440846562385559
Validation loss: 1.8582634002931657

Epoch: 323| Step: 0
Training loss: 1.0407805442810059
Validation loss: 1.8986265890059932

Epoch: 6| Step: 1
Training loss: 0.7524206638336182
Validation loss: 1.894753304860925

Epoch: 6| Step: 2
Training loss: 0.7091582417488098
Validation loss: 1.8625453274737123

Epoch: 6| Step: 3
Training loss: 0.819923996925354
Validation loss: 1.785802250267357

Epoch: 6| Step: 4
Training loss: 0.8084465265274048
Validation loss: 1.8077942684132566

Epoch: 6| Step: 5
Training loss: 0.711889386177063
Validation loss: 1.7629615465799968

Epoch: 6| Step: 6
Training loss: 0.46374422311782837
Validation loss: 1.7842871578790809

Epoch: 6| Step: 7
Training loss: 0.6425272822380066
Validation loss: 1.7743511828043128

Epoch: 6| Step: 8
Training loss: 0.7665400505065918
Validation loss: 1.8007317255902033

Epoch: 6| Step: 9
Training loss: 0.7370855212211609
Validation loss: 1.800781721709877

Epoch: 6| Step: 10
Training loss: 0.6866175532341003
Validation loss: 1.8388702677142235

Epoch: 6| Step: 11
Training loss: 0.5279414653778076
Validation loss: 1.9065576317489787

Epoch: 6| Step: 12
Training loss: 0.9764220714569092
Validation loss: 1.9278718809927664

Epoch: 6| Step: 13
Training loss: 1.2747128009796143
Validation loss: 1.916427372604288

Epoch: 324| Step: 0
Training loss: 0.5751684904098511
Validation loss: 1.8684968653545584

Epoch: 6| Step: 1
Training loss: 0.6482855081558228
Validation loss: 1.8377980045093003

Epoch: 6| Step: 2
Training loss: 0.5717192888259888
Validation loss: 1.8157992286066855

Epoch: 6| Step: 3
Training loss: 0.797751784324646
Validation loss: 1.80105810652497

Epoch: 6| Step: 4
Training loss: 0.9708662033081055
Validation loss: 1.8322919517435052

Epoch: 6| Step: 5
Training loss: 1.005552887916565
Validation loss: 1.8328720446555846

Epoch: 6| Step: 6
Training loss: 1.0551190376281738
Validation loss: 1.858181256119923

Epoch: 6| Step: 7
Training loss: 1.0168558359146118
Validation loss: 1.910834909767233

Epoch: 6| Step: 8
Training loss: 0.8844587802886963
Validation loss: 1.933317203675547

Epoch: 6| Step: 9
Training loss: 0.919518768787384
Validation loss: 1.9225898506820842

Epoch: 6| Step: 10
Training loss: 0.8342104554176331
Validation loss: 1.9279765646944764

Epoch: 6| Step: 11
Training loss: 0.6409519910812378
Validation loss: 1.86568832653825

Epoch: 6| Step: 12
Training loss: 0.44472235441207886
Validation loss: 1.8607065164914696

Epoch: 6| Step: 13
Training loss: 0.5333516001701355
Validation loss: 1.828172137660365

Epoch: 325| Step: 0
Training loss: 0.6356476545333862
Validation loss: 1.8694812097857076

Epoch: 6| Step: 1
Training loss: 0.9678889513015747
Validation loss: 1.8968544903621878

Epoch: 6| Step: 2
Training loss: 0.7359354496002197
Validation loss: 1.924960897814843

Epoch: 6| Step: 3
Training loss: 0.977493405342102
Validation loss: 1.9257736488055157

Epoch: 6| Step: 4
Training loss: 0.686133861541748
Validation loss: 1.9043297460002284

Epoch: 6| Step: 5
Training loss: 0.5705577731132507
Validation loss: 1.8344412490885744

Epoch: 6| Step: 6
Training loss: 0.5421580076217651
Validation loss: 1.7954337084165184

Epoch: 6| Step: 7
Training loss: 0.8414387702941895
Validation loss: 1.771587206471351

Epoch: 6| Step: 8
Training loss: 1.1184415817260742
Validation loss: 1.7871650559927827

Epoch: 6| Step: 9
Training loss: 0.7580459713935852
Validation loss: 1.7790135158005582

Epoch: 6| Step: 10
Training loss: 0.4156219959259033
Validation loss: 1.8389719417018275

Epoch: 6| Step: 11
Training loss: 0.4916982650756836
Validation loss: 1.8446923225156722

Epoch: 6| Step: 12
Training loss: 0.8517230749130249
Validation loss: 1.880139954628483

Epoch: 6| Step: 13
Training loss: 0.8556388020515442
Validation loss: 1.9002342095939062

Epoch: 326| Step: 0
Training loss: 1.0066142082214355
Validation loss: 1.8870790748186008

Epoch: 6| Step: 1
Training loss: 0.6611126661300659
Validation loss: 1.9056617418924968

Epoch: 6| Step: 2
Training loss: 1.0382368564605713
Validation loss: 1.8579107676782916

Epoch: 6| Step: 3
Training loss: 0.9110254049301147
Validation loss: 1.8184221380500383

Epoch: 6| Step: 4
Training loss: 0.5784361958503723
Validation loss: 1.8161819622080813

Epoch: 6| Step: 5
Training loss: 0.9163910746574402
Validation loss: 1.7963852997749084

Epoch: 6| Step: 6
Training loss: 0.742067277431488
Validation loss: 1.7931451451393865

Epoch: 6| Step: 7
Training loss: 0.7072954773902893
Validation loss: 1.8153401420962425

Epoch: 6| Step: 8
Training loss: 0.9417717456817627
Validation loss: 1.8225567174214188

Epoch: 6| Step: 9
Training loss: 0.6579374670982361
Validation loss: 1.8650320537628666

Epoch: 6| Step: 10
Training loss: 0.6761779189109802
Validation loss: 1.9135786269300727

Epoch: 6| Step: 11
Training loss: 0.6842359304428101
Validation loss: 1.9439006928474671

Epoch: 6| Step: 12
Training loss: 0.6644411087036133
Validation loss: 1.957017619122741

Epoch: 6| Step: 13
Training loss: 0.48476749658584595
Validation loss: 1.9597911065624607

Epoch: 327| Step: 0
Training loss: 0.6143925189971924
Validation loss: 1.9387700583345147

Epoch: 6| Step: 1
Training loss: 1.0384443998336792
Validation loss: 1.9229316173061248

Epoch: 6| Step: 2
Training loss: 0.5899439454078674
Validation loss: 1.893285100178052

Epoch: 6| Step: 3
Training loss: 0.977374255657196
Validation loss: 1.8416638528147051

Epoch: 6| Step: 4
Training loss: 1.019775629043579
Validation loss: 1.842904185736051

Epoch: 6| Step: 5
Training loss: 0.7773102521896362
Validation loss: 1.8307385611277756

Epoch: 6| Step: 6
Training loss: 0.771548867225647
Validation loss: 1.8039225583435388

Epoch: 6| Step: 7
Training loss: 0.5184463262557983
Validation loss: 1.8274711152558685

Epoch: 6| Step: 8
Training loss: 0.7647230625152588
Validation loss: 1.8294318722140404

Epoch: 6| Step: 9
Training loss: 0.8459281921386719
Validation loss: 1.8482375875596078

Epoch: 6| Step: 10
Training loss: 0.5744577646255493
Validation loss: 1.8347216575376448

Epoch: 6| Step: 11
Training loss: 0.7884201407432556
Validation loss: 1.8550452737398044

Epoch: 6| Step: 12
Training loss: 0.7079801559448242
Validation loss: 1.8150173310310609

Epoch: 6| Step: 13
Training loss: 0.7019187808036804
Validation loss: 1.8232935705492574

Epoch: 328| Step: 0
Training loss: 0.5162922739982605
Validation loss: 1.807790938244071

Epoch: 6| Step: 1
Training loss: 0.6055796146392822
Validation loss: 1.8300912790401007

Epoch: 6| Step: 2
Training loss: 0.7421743273735046
Validation loss: 1.8557516272350023

Epoch: 6| Step: 3
Training loss: 0.6702873110771179
Validation loss: 1.8492293075848651

Epoch: 6| Step: 4
Training loss: 0.844208836555481
Validation loss: 1.9075769711566228

Epoch: 6| Step: 5
Training loss: 0.8760767579078674
Validation loss: 1.936649021281991

Epoch: 6| Step: 6
Training loss: 0.8081469535827637
Validation loss: 1.9486600506690241

Epoch: 6| Step: 7
Training loss: 0.6853551864624023
Validation loss: 1.9597472888167187

Epoch: 6| Step: 8
Training loss: 1.1623505353927612
Validation loss: 1.9014059548736901

Epoch: 6| Step: 9
Training loss: 0.736656665802002
Validation loss: 1.8903565432435723

Epoch: 6| Step: 10
Training loss: 0.47254490852355957
Validation loss: 1.850335185245801

Epoch: 6| Step: 11
Training loss: 0.8637878894805908
Validation loss: 1.8405379223567184

Epoch: 6| Step: 12
Training loss: 0.6285367012023926
Validation loss: 1.8236395300075572

Epoch: 6| Step: 13
Training loss: 0.7257640361785889
Validation loss: 1.7950090797998572

Epoch: 329| Step: 0
Training loss: 0.6296389698982239
Validation loss: 1.812038677994923

Epoch: 6| Step: 1
Training loss: 1.0166712999343872
Validation loss: 1.8335207200819446

Epoch: 6| Step: 2
Training loss: 0.6075087785720825
Validation loss: 1.832232238144003

Epoch: 6| Step: 3
Training loss: 0.8320977687835693
Validation loss: 1.847392556487873

Epoch: 6| Step: 4
Training loss: 0.611235499382019
Validation loss: 1.8561840852101643

Epoch: 6| Step: 5
Training loss: 1.115799903869629
Validation loss: 1.8803194274184525

Epoch: 6| Step: 6
Training loss: 0.8051429390907288
Validation loss: 1.850972931872132

Epoch: 6| Step: 7
Training loss: 0.6280757188796997
Validation loss: 1.862072024294125

Epoch: 6| Step: 8
Training loss: 0.36162543296813965
Validation loss: 1.872762078879982

Epoch: 6| Step: 9
Training loss: 0.7541366815567017
Validation loss: 1.8564193479476436

Epoch: 6| Step: 10
Training loss: 0.42702746391296387
Validation loss: 1.8499329666937552

Epoch: 6| Step: 11
Training loss: 0.9382662773132324
Validation loss: 1.8821980748125302

Epoch: 6| Step: 12
Training loss: 0.5585502982139587
Validation loss: 1.853019522082421

Epoch: 6| Step: 13
Training loss: 0.36579424142837524
Validation loss: 1.8479879030617334

Epoch: 330| Step: 0
Training loss: 0.882346510887146
Validation loss: 1.8847851086688299

Epoch: 6| Step: 1
Training loss: 0.5897471904754639
Validation loss: 1.8589348139301423

Epoch: 6| Step: 2
Training loss: 0.6153292059898376
Validation loss: 1.822046620871431

Epoch: 6| Step: 3
Training loss: 0.602941632270813
Validation loss: 1.8148275639421196

Epoch: 6| Step: 4
Training loss: 0.8302941918373108
Validation loss: 1.8355827075178905

Epoch: 6| Step: 5
Training loss: 0.5190925598144531
Validation loss: 1.826352757792319

Epoch: 6| Step: 6
Training loss: 0.7363513708114624
Validation loss: 1.8054427767312655

Epoch: 6| Step: 7
Training loss: 0.6110804080963135
Validation loss: 1.8368295161954817

Epoch: 6| Step: 8
Training loss: 0.4579369127750397
Validation loss: 1.8418485092860397

Epoch: 6| Step: 9
Training loss: 0.9037561416625977
Validation loss: 1.8364528571405718

Epoch: 6| Step: 10
Training loss: 0.7613239288330078
Validation loss: 1.8189049613091253

Epoch: 6| Step: 11
Training loss: 1.0268012285232544
Validation loss: 1.8115904382480088

Epoch: 6| Step: 12
Training loss: 0.4925650358200073
Validation loss: 1.8575271842300252

Epoch: 6| Step: 13
Training loss: 0.7900108695030212
Validation loss: 1.8713032814764208

Epoch: 331| Step: 0
Training loss: 0.9240908026695251
Validation loss: 1.902931971575624

Epoch: 6| Step: 1
Training loss: 0.7318803071975708
Validation loss: 1.9226080602215183

Epoch: 6| Step: 2
Training loss: 1.1499792337417603
Validation loss: 1.8867571892276886

Epoch: 6| Step: 3
Training loss: 0.47884511947631836
Validation loss: 1.8213103560991184

Epoch: 6| Step: 4
Training loss: 1.2200672626495361
Validation loss: 1.7770280709830664

Epoch: 6| Step: 5
Training loss: 0.6638937592506409
Validation loss: 1.7472398883552962

Epoch: 6| Step: 6
Training loss: 0.7307747006416321
Validation loss: 1.7564857493164718

Epoch: 6| Step: 7
Training loss: 0.5224590301513672
Validation loss: 1.7636595451703636

Epoch: 6| Step: 8
Training loss: 0.23234084248542786
Validation loss: 1.7461493451108214

Epoch: 6| Step: 9
Training loss: 0.5326980352401733
Validation loss: 1.8086886732809004

Epoch: 6| Step: 10
Training loss: 0.7090842723846436
Validation loss: 1.8554442467228058

Epoch: 6| Step: 11
Training loss: 0.5914501547813416
Validation loss: 1.9098354924109675

Epoch: 6| Step: 12
Training loss: 0.6540245413780212
Validation loss: 1.9165496903081094

Epoch: 6| Step: 13
Training loss: 0.7261125445365906
Validation loss: 1.9169025651870235

Epoch: 332| Step: 0
Training loss: 0.4921143651008606
Validation loss: 1.9055169038875128

Epoch: 6| Step: 1
Training loss: 0.842893660068512
Validation loss: 1.894856055577596

Epoch: 6| Step: 2
Training loss: 0.8316665291786194
Validation loss: 1.8639146897100634

Epoch: 6| Step: 3
Training loss: 0.8295426368713379
Validation loss: 1.8326342169956495

Epoch: 6| Step: 4
Training loss: 0.9857074022293091
Validation loss: 1.788090681516996

Epoch: 6| Step: 5
Training loss: 0.40504446625709534
Validation loss: 1.7658953705141622

Epoch: 6| Step: 6
Training loss: 0.5727962255477905
Validation loss: 1.7571339261147283

Epoch: 6| Step: 7
Training loss: 0.6642824411392212
Validation loss: 1.745957043863112

Epoch: 6| Step: 8
Training loss: 0.5218657851219177
Validation loss: 1.7432079507458595

Epoch: 6| Step: 9
Training loss: 0.8116347789764404
Validation loss: 1.7668989422500774

Epoch: 6| Step: 10
Training loss: 1.0544794797897339
Validation loss: 1.8214757186110302

Epoch: 6| Step: 11
Training loss: 1.004916787147522
Validation loss: 1.851518169526131

Epoch: 6| Step: 12
Training loss: 0.39649856090545654
Validation loss: 1.8385096121859807

Epoch: 6| Step: 13
Training loss: 0.3374033272266388
Validation loss: 1.845650326821112

Epoch: 333| Step: 0
Training loss: 0.3668089509010315
Validation loss: 1.787817455107166

Epoch: 6| Step: 1
Training loss: 0.9306285381317139
Validation loss: 1.8141280310128325

Epoch: 6| Step: 2
Training loss: 0.4631737470626831
Validation loss: 1.789337879867964

Epoch: 6| Step: 3
Training loss: 0.48519396781921387
Validation loss: 1.8099049624576364

Epoch: 6| Step: 4
Training loss: 0.6224300861358643
Validation loss: 1.7769095474673855

Epoch: 6| Step: 5
Training loss: 0.6260113716125488
Validation loss: 1.80942754719847

Epoch: 6| Step: 6
Training loss: 1.0770007371902466
Validation loss: 1.7923004883591847

Epoch: 6| Step: 7
Training loss: 0.8767167329788208
Validation loss: 1.809718381974005

Epoch: 6| Step: 8
Training loss: 0.6038293242454529
Validation loss: 1.8201904277647696

Epoch: 6| Step: 9
Training loss: 0.7034251689910889
Validation loss: 1.8253790691334715

Epoch: 6| Step: 10
Training loss: 0.8521896004676819
Validation loss: 1.8391025553467453

Epoch: 6| Step: 11
Training loss: 0.4455571472644806
Validation loss: 1.853914547992009

Epoch: 6| Step: 12
Training loss: 0.6778132915496826
Validation loss: 1.8571565446033274

Epoch: 6| Step: 13
Training loss: 1.0361360311508179
Validation loss: 1.9011639625795427

Epoch: 334| Step: 0
Training loss: 0.4467920660972595
Validation loss: 1.9875715009627803

Epoch: 6| Step: 1
Training loss: 0.7439604997634888
Validation loss: 2.0176406022041076

Epoch: 6| Step: 2
Training loss: 0.6557376980781555
Validation loss: 2.0034347311142953

Epoch: 6| Step: 3
Training loss: 0.6132054328918457
Validation loss: 1.9195455812638806

Epoch: 6| Step: 4
Training loss: 0.9191471338272095
Validation loss: 1.8688792759372341

Epoch: 6| Step: 5
Training loss: 0.6925841569900513
Validation loss: 1.8576996249537314

Epoch: 6| Step: 6
Training loss: 0.614264965057373
Validation loss: 1.8207790736229188

Epoch: 6| Step: 7
Training loss: 0.9376220703125
Validation loss: 1.7810325648195

Epoch: 6| Step: 8
Training loss: 0.9271551966667175
Validation loss: 1.7642744023312804

Epoch: 6| Step: 9
Training loss: 0.5724879503250122
Validation loss: 1.7813121759763328

Epoch: 6| Step: 10
Training loss: 0.7426636219024658
Validation loss: 1.7648945572555705

Epoch: 6| Step: 11
Training loss: 0.7145075798034668
Validation loss: 1.7373364381892706

Epoch: 6| Step: 12
Training loss: 0.703056275844574
Validation loss: 1.796572821114653

Epoch: 6| Step: 13
Training loss: 1.069627046585083
Validation loss: 1.8436514715994559

Epoch: 335| Step: 0
Training loss: 0.5483040809631348
Validation loss: 1.967966611667346

Epoch: 6| Step: 1
Training loss: 0.5539723634719849
Validation loss: 2.023978599938013

Epoch: 6| Step: 2
Training loss: 1.082335352897644
Validation loss: 2.041985668161864

Epoch: 6| Step: 3
Training loss: 0.9234374761581421
Validation loss: 2.060096395912991

Epoch: 6| Step: 4
Training loss: 0.7557352185249329
Validation loss: 2.0041216547771166

Epoch: 6| Step: 5
Training loss: 0.3974495828151703
Validation loss: 1.8888493712230394

Epoch: 6| Step: 6
Training loss: 0.537233293056488
Validation loss: 1.8031970775255592

Epoch: 6| Step: 7
Training loss: 0.5545401573181152
Validation loss: 1.7458931540930143

Epoch: 6| Step: 8
Training loss: 1.1125109195709229
Validation loss: 1.7451320386702014

Epoch: 6| Step: 9
Training loss: 0.8386717438697815
Validation loss: 1.7323689691482052

Epoch: 6| Step: 10
Training loss: 0.9213165044784546
Validation loss: 1.7349287438136276

Epoch: 6| Step: 11
Training loss: 0.8597800731658936
Validation loss: 1.7295839812165947

Epoch: 6| Step: 12
Training loss: 0.6841046214103699
Validation loss: 1.7496399482091267

Epoch: 6| Step: 13
Training loss: 0.7370986938476562
Validation loss: 1.7432284073163105

Epoch: 336| Step: 0
Training loss: 0.5489746332168579
Validation loss: 1.7934266315993441

Epoch: 6| Step: 1
Training loss: 0.903558611869812
Validation loss: 1.8487699595830773

Epoch: 6| Step: 2
Training loss: 0.569598376750946
Validation loss: 1.9284614209205873

Epoch: 6| Step: 3
Training loss: 0.7814473509788513
Validation loss: 1.9339742404158398

Epoch: 6| Step: 4
Training loss: 0.689303994178772
Validation loss: 1.9782462889148342

Epoch: 6| Step: 5
Training loss: 0.9057104587554932
Validation loss: 1.9849457176782752

Epoch: 6| Step: 6
Training loss: 0.5070823431015015
Validation loss: 1.9146742692557714

Epoch: 6| Step: 7
Training loss: 0.6401000022888184
Validation loss: 1.8152615895835302

Epoch: 6| Step: 8
Training loss: 1.0362253189086914
Validation loss: 1.7450161698043987

Epoch: 6| Step: 9
Training loss: 0.9154021143913269
Validation loss: 1.7086096002209572

Epoch: 6| Step: 10
Training loss: 0.850866973400116
Validation loss: 1.7292832866791756

Epoch: 6| Step: 11
Training loss: 0.5314074754714966
Validation loss: 1.7069755907981627

Epoch: 6| Step: 12
Training loss: 0.5825862288475037
Validation loss: 1.6757657117741083

Epoch: 6| Step: 13
Training loss: 0.7051357626914978
Validation loss: 1.724120137512043

Epoch: 337| Step: 0
Training loss: 0.5476032495498657
Validation loss: 1.7618865402795936

Epoch: 6| Step: 1
Training loss: 0.7833315134048462
Validation loss: 1.8243008852005005

Epoch: 6| Step: 2
Training loss: 0.7484961748123169
Validation loss: 1.9107286327628679

Epoch: 6| Step: 3
Training loss: 0.5979061722755432
Validation loss: 1.935540885053655

Epoch: 6| Step: 4
Training loss: 0.24171149730682373
Validation loss: 1.9386086835656116

Epoch: 6| Step: 5
Training loss: 0.513431191444397
Validation loss: 1.8767703989500641

Epoch: 6| Step: 6
Training loss: 0.87319415807724
Validation loss: 1.85940981423983

Epoch: 6| Step: 7
Training loss: 1.1860712766647339
Validation loss: 1.7938956470899685

Epoch: 6| Step: 8
Training loss: 0.4672642946243286
Validation loss: 1.7576374981992988

Epoch: 6| Step: 9
Training loss: 0.7759248614311218
Validation loss: 1.7954316728858537

Epoch: 6| Step: 10
Training loss: 0.4751356244087219
Validation loss: 1.7767814936176423

Epoch: 6| Step: 11
Training loss: 0.9334008693695068
Validation loss: 1.7962453544780772

Epoch: 6| Step: 12
Training loss: 1.0685371160507202
Validation loss: 1.805788122197633

Epoch: 6| Step: 13
Training loss: 1.0200936794281006
Validation loss: 1.8344951291238107

Epoch: 338| Step: 0
Training loss: 0.6110121011734009
Validation loss: 1.8750243520223966

Epoch: 6| Step: 1
Training loss: 0.7681057453155518
Validation loss: 1.8463635137004237

Epoch: 6| Step: 2
Training loss: 0.7176780700683594
Validation loss: 1.8624949327079199

Epoch: 6| Step: 3
Training loss: 0.8092082738876343
Validation loss: 1.8380002385826522

Epoch: 6| Step: 4
Training loss: 0.33709460496902466
Validation loss: 1.824711020274829

Epoch: 6| Step: 5
Training loss: 0.5575371980667114
Validation loss: 1.8129474424546765

Epoch: 6| Step: 6
Training loss: 0.6214492917060852
Validation loss: 1.7816401784138014

Epoch: 6| Step: 7
Training loss: 0.566468358039856
Validation loss: 1.7749814166817615

Epoch: 6| Step: 8
Training loss: 0.8424282073974609
Validation loss: 1.7544478985571093

Epoch: 6| Step: 9
Training loss: 0.9511440992355347
Validation loss: 1.7638726157526816

Epoch: 6| Step: 10
Training loss: 0.9657289981842041
Validation loss: 1.7711292466809672

Epoch: 6| Step: 11
Training loss: 0.4726164937019348
Validation loss: 1.8030616211634811

Epoch: 6| Step: 12
Training loss: 0.671917200088501
Validation loss: 1.8388101759777273

Epoch: 6| Step: 13
Training loss: 0.5882313251495361
Validation loss: 1.8730373715841642

Epoch: 339| Step: 0
Training loss: 0.4553762376308441
Validation loss: 1.8815344302884993

Epoch: 6| Step: 1
Training loss: 0.8834818601608276
Validation loss: 1.8961891256352907

Epoch: 6| Step: 2
Training loss: 0.6044840216636658
Validation loss: 1.9005736266413042

Epoch: 6| Step: 3
Training loss: 0.6383145451545715
Validation loss: 1.8520853198984617

Epoch: 6| Step: 4
Training loss: 0.7336385250091553
Validation loss: 1.8424457888449393

Epoch: 6| Step: 5
Training loss: 0.6329417824745178
Validation loss: 1.8169502545428533

Epoch: 6| Step: 6
Training loss: 0.8917372226715088
Validation loss: 1.8417601982752483

Epoch: 6| Step: 7
Training loss: 0.8603092432022095
Validation loss: 1.8210531716705651

Epoch: 6| Step: 8
Training loss: 1.0508841276168823
Validation loss: 1.8440828015727382

Epoch: 6| Step: 9
Training loss: 0.3658274710178375
Validation loss: 1.8246310795507124

Epoch: 6| Step: 10
Training loss: 0.6390342712402344
Validation loss: 1.8562944255849367

Epoch: 6| Step: 11
Training loss: 0.5073757171630859
Validation loss: 1.8631380193976945

Epoch: 6| Step: 12
Training loss: 0.41315826773643494
Validation loss: 1.8841498949194466

Epoch: 6| Step: 13
Training loss: 0.7754458785057068
Validation loss: 1.8713254018496441

Epoch: 340| Step: 0
Training loss: 0.761915922164917
Validation loss: 1.8500662811340824

Epoch: 6| Step: 1
Training loss: 0.7207010388374329
Validation loss: 1.8353509031316286

Epoch: 6| Step: 2
Training loss: 1.0016679763793945
Validation loss: 1.8212841954282535

Epoch: 6| Step: 3
Training loss: 0.4040428400039673
Validation loss: 1.784869941332007

Epoch: 6| Step: 4
Training loss: 0.7434542775154114
Validation loss: 1.8184745478373703

Epoch: 6| Step: 5
Training loss: 0.6802283525466919
Validation loss: 1.8008821830954602

Epoch: 6| Step: 6
Training loss: 0.47174859046936035
Validation loss: 1.782153550014701

Epoch: 6| Step: 7
Training loss: 0.6022419333457947
Validation loss: 1.818417804215544

Epoch: 6| Step: 8
Training loss: 0.707892656326294
Validation loss: 1.8264116471813572

Epoch: 6| Step: 9
Training loss: 0.6500339508056641
Validation loss: 1.8423955466157647

Epoch: 6| Step: 10
Training loss: 0.5873206853866577
Validation loss: 1.8546767234802246

Epoch: 6| Step: 11
Training loss: 0.3945765197277069
Validation loss: 1.8755462695193548

Epoch: 6| Step: 12
Training loss: 0.8332910537719727
Validation loss: 1.9209508972783242

Epoch: 6| Step: 13
Training loss: 0.8377134799957275
Validation loss: 1.942659862579838

Epoch: 341| Step: 0
Training loss: 0.7325204610824585
Validation loss: 1.907416792326076

Epoch: 6| Step: 1
Training loss: 0.40656810998916626
Validation loss: 1.861743571937725

Epoch: 6| Step: 2
Training loss: 0.9137924313545227
Validation loss: 1.8241147866813086

Epoch: 6| Step: 3
Training loss: 0.6514675617218018
Validation loss: 1.7986175629400438

Epoch: 6| Step: 4
Training loss: 0.5327192544937134
Validation loss: 1.7939828506080053

Epoch: 6| Step: 5
Training loss: 0.4179047644138336
Validation loss: 1.7712967447055283

Epoch: 6| Step: 6
Training loss: 0.5556519031524658
Validation loss: 1.7742666557270994

Epoch: 6| Step: 7
Training loss: 0.6642515659332275
Validation loss: 1.7382108267917429

Epoch: 6| Step: 8
Training loss: 0.6125414371490479
Validation loss: 1.7802257755751252

Epoch: 6| Step: 9
Training loss: 0.8458740711212158
Validation loss: 1.8122713488917197

Epoch: 6| Step: 10
Training loss: 0.8362388014793396
Validation loss: 1.853801199184951

Epoch: 6| Step: 11
Training loss: 0.4700762927532196
Validation loss: 1.8564851335299912

Epoch: 6| Step: 12
Training loss: 0.819542646408081
Validation loss: 1.888428294530479

Epoch: 6| Step: 13
Training loss: 1.1812727451324463
Validation loss: 1.8786395621556107

Epoch: 342| Step: 0
Training loss: 0.6435474753379822
Validation loss: 1.9326035771318661

Epoch: 6| Step: 1
Training loss: 0.7504878044128418
Validation loss: 1.8819263340324484

Epoch: 6| Step: 2
Training loss: 0.2765439450740814
Validation loss: 1.8664352650283484

Epoch: 6| Step: 3
Training loss: 0.844367504119873
Validation loss: 1.8310163021087646

Epoch: 6| Step: 4
Training loss: 0.6303111910820007
Validation loss: 1.787019298922631

Epoch: 6| Step: 5
Training loss: 0.6006422638893127
Validation loss: 1.7900837365017142

Epoch: 6| Step: 6
Training loss: 0.5180802345275879
Validation loss: 1.7554669521188224

Epoch: 6| Step: 7
Training loss: 0.35660913586616516
Validation loss: 1.763401746749878

Epoch: 6| Step: 8
Training loss: 1.2051811218261719
Validation loss: 1.7540700320274598

Epoch: 6| Step: 9
Training loss: 0.7385931015014648
Validation loss: 1.7536537416519657

Epoch: 6| Step: 10
Training loss: 0.6595433950424194
Validation loss: 1.7632823221145137

Epoch: 6| Step: 11
Training loss: 0.5593589544296265
Validation loss: 1.7693355198829406

Epoch: 6| Step: 12
Training loss: 0.7089167833328247
Validation loss: 1.7863864719226796

Epoch: 6| Step: 13
Training loss: 0.6241748332977295
Validation loss: 1.8177732908597557

Epoch: 343| Step: 0
Training loss: 0.6384379267692566
Validation loss: 1.8549312391588766

Epoch: 6| Step: 1
Training loss: 0.27164575457572937
Validation loss: 1.8757232273778608

Epoch: 6| Step: 2
Training loss: 0.7419499158859253
Validation loss: 1.8814282109660487

Epoch: 6| Step: 3
Training loss: 0.5548695921897888
Validation loss: 1.858771857394967

Epoch: 6| Step: 4
Training loss: 0.8404529094696045
Validation loss: 1.857519034416445

Epoch: 6| Step: 5
Training loss: 0.5446422100067139
Validation loss: 1.8121382151880572

Epoch: 6| Step: 6
Training loss: 0.4420396685600281
Validation loss: 1.786958896985618

Epoch: 6| Step: 7
Training loss: 1.0404844284057617
Validation loss: 1.7528614574863064

Epoch: 6| Step: 8
Training loss: 0.44694823026657104
Validation loss: 1.7552861077811128

Epoch: 6| Step: 9
Training loss: 0.6773716807365417
Validation loss: 1.7897740410220238

Epoch: 6| Step: 10
Training loss: 0.9975895881652832
Validation loss: 1.7879161552716327

Epoch: 6| Step: 11
Training loss: 0.3689703643321991
Validation loss: 1.7741456467618224

Epoch: 6| Step: 12
Training loss: 0.8865988254547119
Validation loss: 1.8243096720787786

Epoch: 6| Step: 13
Training loss: 0.5632578730583191
Validation loss: 1.870050884062244

Epoch: 344| Step: 0
Training loss: 0.7518640756607056
Validation loss: 1.8507235127110635

Epoch: 6| Step: 1
Training loss: 0.5560017228126526
Validation loss: 1.8219146779788438

Epoch: 6| Step: 2
Training loss: 0.6660946011543274
Validation loss: 1.7985617537652292

Epoch: 6| Step: 3
Training loss: 0.4502706527709961
Validation loss: 1.7913476818351335

Epoch: 6| Step: 4
Training loss: 1.0490394830703735
Validation loss: 1.79936719453463

Epoch: 6| Step: 5
Training loss: 1.0695829391479492
Validation loss: 1.8247638979265768

Epoch: 6| Step: 6
Training loss: 0.45711076259613037
Validation loss: 1.8560062582774828

Epoch: 6| Step: 7
Training loss: 0.4636945128440857
Validation loss: 1.8172617650801135

Epoch: 6| Step: 8
Training loss: 0.14459609985351562
Validation loss: 1.8212493799066032

Epoch: 6| Step: 9
Training loss: 0.9113220572471619
Validation loss: 1.7880314165546047

Epoch: 6| Step: 10
Training loss: 0.4256554841995239
Validation loss: 1.7721382033440374

Epoch: 6| Step: 11
Training loss: 0.8781884908676147
Validation loss: 1.7751637992038523

Epoch: 6| Step: 12
Training loss: 0.3520369231700897
Validation loss: 1.7766078287555325

Epoch: 6| Step: 13
Training loss: 0.9373414516448975
Validation loss: 1.7686084547350485

Epoch: 345| Step: 0
Training loss: 0.5658107995986938
Validation loss: 1.77403760469088

Epoch: 6| Step: 1
Training loss: 0.5274912118911743
Validation loss: 1.7831957891423216

Epoch: 6| Step: 2
Training loss: 0.8021589517593384
Validation loss: 1.7785988212913595

Epoch: 6| Step: 3
Training loss: 0.25279009342193604
Validation loss: 1.7657108370975783

Epoch: 6| Step: 4
Training loss: 0.7710944414138794
Validation loss: 1.8062699417914114

Epoch: 6| Step: 5
Training loss: 0.5169942378997803
Validation loss: 1.7960792203103342

Epoch: 6| Step: 6
Training loss: 0.6796165704727173
Validation loss: 1.7957996604263142

Epoch: 6| Step: 7
Training loss: 0.9054046869277954
Validation loss: 1.765687023439715

Epoch: 6| Step: 8
Training loss: 0.5078449249267578
Validation loss: 1.7824326638252503

Epoch: 6| Step: 9
Training loss: 0.5633158087730408
Validation loss: 1.8027085950297694

Epoch: 6| Step: 10
Training loss: 0.975521445274353
Validation loss: 1.80042855329411

Epoch: 6| Step: 11
Training loss: 0.49199235439300537
Validation loss: 1.8106992013992802

Epoch: 6| Step: 12
Training loss: 0.8499584197998047
Validation loss: 1.7869848269288258

Epoch: 6| Step: 13
Training loss: 0.812317430973053
Validation loss: 1.7812963980500416

Epoch: 346| Step: 0
Training loss: 0.4183828830718994
Validation loss: 1.7976029713948567

Epoch: 6| Step: 1
Training loss: 0.6026838421821594
Validation loss: 1.8103569374289563

Epoch: 6| Step: 2
Training loss: 0.639244794845581
Validation loss: 1.786863926918276

Epoch: 6| Step: 3
Training loss: 0.4639095664024353
Validation loss: 1.809014860019889

Epoch: 6| Step: 4
Training loss: 0.39035966992378235
Validation loss: 1.8165188579149143

Epoch: 6| Step: 5
Training loss: 1.0124541521072388
Validation loss: 1.8138921773561867

Epoch: 6| Step: 6
Training loss: 1.262154221534729
Validation loss: 1.8316949746942008

Epoch: 6| Step: 7
Training loss: 0.70640629529953
Validation loss: 1.8395863450983518

Epoch: 6| Step: 8
Training loss: 0.4022615849971771
Validation loss: 1.836095981700446

Epoch: 6| Step: 9
Training loss: 0.584026575088501
Validation loss: 1.8494387608702465

Epoch: 6| Step: 10
Training loss: 0.7831776738166809
Validation loss: 1.8462221045647897

Epoch: 6| Step: 11
Training loss: 0.7307164072990417
Validation loss: 1.8318868708866898

Epoch: 6| Step: 12
Training loss: 0.4029773473739624
Validation loss: 1.8105186493166032

Epoch: 6| Step: 13
Training loss: 0.49149289727211
Validation loss: 1.803233943959718

Epoch: 347| Step: 0
Training loss: 0.5650860071182251
Validation loss: 1.7793816110139251

Epoch: 6| Step: 1
Training loss: 0.5983086228370667
Validation loss: 1.7485634562789754

Epoch: 6| Step: 2
Training loss: 0.6339715123176575
Validation loss: 1.7655558675848029

Epoch: 6| Step: 3
Training loss: 1.0981850624084473
Validation loss: 1.782886706372743

Epoch: 6| Step: 4
Training loss: 0.5683472156524658
Validation loss: 1.8449203404047156

Epoch: 6| Step: 5
Training loss: 0.7209676504135132
Validation loss: 1.8388142560117988

Epoch: 6| Step: 6
Training loss: 0.5689269304275513
Validation loss: 1.8227919282451752

Epoch: 6| Step: 7
Training loss: 0.5064588785171509
Validation loss: 1.7624586448874524

Epoch: 6| Step: 8
Training loss: 0.864712655544281
Validation loss: 1.7590411350291262

Epoch: 6| Step: 9
Training loss: 0.4859466850757599
Validation loss: 1.7883023497878865

Epoch: 6| Step: 10
Training loss: 0.45199355483055115
Validation loss: 1.7883041827909407

Epoch: 6| Step: 11
Training loss: 0.8196536302566528
Validation loss: 1.8133900498831144

Epoch: 6| Step: 12
Training loss: 0.4531339406967163
Validation loss: 1.8263732899901688

Epoch: 6| Step: 13
Training loss: 0.8172072172164917
Validation loss: 1.867798541181831

Epoch: 348| Step: 0
Training loss: 0.6725030541419983
Validation loss: 1.9125880605431014

Epoch: 6| Step: 1
Training loss: 0.5315444469451904
Validation loss: 1.9271182091005388

Epoch: 6| Step: 2
Training loss: 0.45557135343551636
Validation loss: 1.89413450097525

Epoch: 6| Step: 3
Training loss: 0.5602446794509888
Validation loss: 1.8758605167429934

Epoch: 6| Step: 4
Training loss: 0.7221779227256775
Validation loss: 1.8642768206134919

Epoch: 6| Step: 5
Training loss: 0.5021151304244995
Validation loss: 1.821171683649863

Epoch: 6| Step: 6
Training loss: 0.6479639410972595
Validation loss: 1.8159510973961122

Epoch: 6| Step: 7
Training loss: 1.0570967197418213
Validation loss: 1.7825543124188659

Epoch: 6| Step: 8
Training loss: 0.47935813665390015
Validation loss: 1.7672220724885181

Epoch: 6| Step: 9
Training loss: 0.6023423075675964
Validation loss: 1.7640568851142802

Epoch: 6| Step: 10
Training loss: 0.9590245485305786
Validation loss: 1.7942726253181376

Epoch: 6| Step: 11
Training loss: 0.5943570733070374
Validation loss: 1.790456339877139

Epoch: 6| Step: 12
Training loss: 0.7865292429924011
Validation loss: 1.8195155641084075

Epoch: 6| Step: 13
Training loss: 0.6613921523094177
Validation loss: 1.8578236615785988

Epoch: 349| Step: 0
Training loss: 0.7312811017036438
Validation loss: 1.872212484318723

Epoch: 6| Step: 1
Training loss: 0.7696808576583862
Validation loss: 1.8849986573701263

Epoch: 6| Step: 2
Training loss: 0.3896194100379944
Validation loss: 1.8618822764324885

Epoch: 6| Step: 3
Training loss: 0.5384244918823242
Validation loss: 1.8798442156084123

Epoch: 6| Step: 4
Training loss: 0.3697434961795807
Validation loss: 1.8552356676388813

Epoch: 6| Step: 5
Training loss: 0.6233292818069458
Validation loss: 1.826901371761035

Epoch: 6| Step: 6
Training loss: 0.7982625365257263
Validation loss: 1.800095570984707

Epoch: 6| Step: 7
Training loss: 1.0497033596038818
Validation loss: 1.798692452010288

Epoch: 6| Step: 8
Training loss: 0.6519394516944885
Validation loss: 1.7918461292020735

Epoch: 6| Step: 9
Training loss: 0.41635310649871826
Validation loss: 1.8170408036119194

Epoch: 6| Step: 10
Training loss: 0.7378199100494385
Validation loss: 1.7794126567020212

Epoch: 6| Step: 11
Training loss: 0.39966028928756714
Validation loss: 1.7796737737553094

Epoch: 6| Step: 12
Training loss: 0.5311017632484436
Validation loss: 1.8053122887047388

Epoch: 6| Step: 13
Training loss: 0.7405089139938354
Validation loss: 1.8036911628579582

Epoch: 350| Step: 0
Training loss: 0.7761399149894714
Validation loss: 1.846346378326416

Epoch: 6| Step: 1
Training loss: 0.38563814759254456
Validation loss: 1.866434738200198

Epoch: 6| Step: 2
Training loss: 0.8845043778419495
Validation loss: 1.90024015467654

Epoch: 6| Step: 3
Training loss: 1.0709742307662964
Validation loss: 1.9178782034945745

Epoch: 6| Step: 4
Training loss: 0.9762994050979614
Validation loss: 1.894774002413596

Epoch: 6| Step: 5
Training loss: 0.4767860174179077
Validation loss: 1.866962097024405

Epoch: 6| Step: 6
Training loss: 0.5585100650787354
Validation loss: 1.8097775674635364

Epoch: 6| Step: 7
Training loss: 0.44744667410850525
Validation loss: 1.7439700916249266

Epoch: 6| Step: 8
Training loss: 0.40731027722358704
Validation loss: 1.7441422849573114

Epoch: 6| Step: 9
Training loss: 0.46505218744277954
Validation loss: 1.7646791826012314

Epoch: 6| Step: 10
Training loss: 0.6390621066093445
Validation loss: 1.7849519791141633

Epoch: 6| Step: 11
Training loss: 0.5783669948577881
Validation loss: 1.7714167589782386

Epoch: 6| Step: 12
Training loss: 0.6880813837051392
Validation loss: 1.7990636235924178

Epoch: 6| Step: 13
Training loss: 0.7299759984016418
Validation loss: 1.8329692694448656

Epoch: 351| Step: 0
Training loss: 0.8434878587722778
Validation loss: 1.92572586254407

Epoch: 6| Step: 1
Training loss: 1.0139281749725342
Validation loss: 1.9089589747049476

Epoch: 6| Step: 2
Training loss: 0.6300129294395447
Validation loss: 1.9009451866149902

Epoch: 6| Step: 3
Training loss: 0.5100919008255005
Validation loss: 1.8512281243519118

Epoch: 6| Step: 4
Training loss: 0.8391427993774414
Validation loss: 1.8115515696105136

Epoch: 6| Step: 5
Training loss: 0.6051571369171143
Validation loss: 1.7998127886044082

Epoch: 6| Step: 6
Training loss: 0.576097846031189
Validation loss: 1.780002837540001

Epoch: 6| Step: 7
Training loss: 0.44791826605796814
Validation loss: 1.769047765321629

Epoch: 6| Step: 8
Training loss: 0.6061800122261047
Validation loss: 1.7696734769369966

Epoch: 6| Step: 9
Training loss: 0.7366607189178467
Validation loss: 1.8052713166001022

Epoch: 6| Step: 10
Training loss: 0.5485070943832397
Validation loss: 1.8011543661035516

Epoch: 6| Step: 11
Training loss: 0.359455943107605
Validation loss: 1.7948374799502793

Epoch: 6| Step: 12
Training loss: 0.5216935873031616
Validation loss: 1.7964348882757208

Epoch: 6| Step: 13
Training loss: 0.8412863612174988
Validation loss: 1.8319232694564327

Epoch: 352| Step: 0
Training loss: 0.6116845607757568
Validation loss: 1.8505460741699382

Epoch: 6| Step: 1
Training loss: 0.36509495973587036
Validation loss: 1.9071471152767059

Epoch: 6| Step: 2
Training loss: 0.9798463582992554
Validation loss: 1.8654884240960563

Epoch: 6| Step: 3
Training loss: 0.6227955222129822
Validation loss: 1.8302416378451931

Epoch: 6| Step: 4
Training loss: 0.7263209819793701
Validation loss: 1.8070799727593698

Epoch: 6| Step: 5
Training loss: 0.42771828174591064
Validation loss: 1.8054171608340355

Epoch: 6| Step: 6
Training loss: 0.5817115306854248
Validation loss: 1.7528856403084212

Epoch: 6| Step: 7
Training loss: 0.8593182563781738
Validation loss: 1.7656876579407723

Epoch: 6| Step: 8
Training loss: 0.6448398232460022
Validation loss: 1.7389487886941561

Epoch: 6| Step: 9
Training loss: 0.8680689334869385
Validation loss: 1.7253197162382063

Epoch: 6| Step: 10
Training loss: 0.5014340877532959
Validation loss: 1.7716216284741637

Epoch: 6| Step: 11
Training loss: 0.3411492705345154
Validation loss: 1.7815710344622213

Epoch: 6| Step: 12
Training loss: 0.4228685200214386
Validation loss: 1.8590032272441412

Epoch: 6| Step: 13
Training loss: 0.7646787166595459
Validation loss: 1.8832120344203005

Epoch: 353| Step: 0
Training loss: 0.5610182881355286
Validation loss: 1.885542916995223

Epoch: 6| Step: 1
Training loss: 0.7262006402015686
Validation loss: 1.9039138337617278

Epoch: 6| Step: 2
Training loss: 0.8670564889907837
Validation loss: 1.8853403150394399

Epoch: 6| Step: 3
Training loss: 0.2867357134819031
Validation loss: 1.8580262942980694

Epoch: 6| Step: 4
Training loss: 0.7327489852905273
Validation loss: 1.8094750988867976

Epoch: 6| Step: 5
Training loss: 0.5833970308303833
Validation loss: 1.8002447248787008

Epoch: 6| Step: 6
Training loss: 0.5540456175804138
Validation loss: 1.8108886634149859

Epoch: 6| Step: 7
Training loss: 0.643945574760437
Validation loss: 1.775328879715294

Epoch: 6| Step: 8
Training loss: 0.22753727436065674
Validation loss: 1.7874714571942565

Epoch: 6| Step: 9
Training loss: 0.6723853945732117
Validation loss: 1.7875286584259362

Epoch: 6| Step: 10
Training loss: 0.7092787027359009
Validation loss: 1.7983120320945658

Epoch: 6| Step: 11
Training loss: 0.4978209137916565
Validation loss: 1.78316242207763

Epoch: 6| Step: 12
Training loss: 0.7259371280670166
Validation loss: 1.7727500469453874

Epoch: 6| Step: 13
Training loss: 0.8618663549423218
Validation loss: 1.7900330110262799

Epoch: 354| Step: 0
Training loss: 0.9577428102493286
Validation loss: 1.8085419747137255

Epoch: 6| Step: 1
Training loss: 0.20498360693454742
Validation loss: 1.812544418919471

Epoch: 6| Step: 2
Training loss: 0.36556240916252136
Validation loss: 1.8356383897924935

Epoch: 6| Step: 3
Training loss: 0.5659389495849609
Validation loss: 1.8441083918335617

Epoch: 6| Step: 4
Training loss: 0.5750777721405029
Validation loss: 1.8689524589046356

Epoch: 6| Step: 5
Training loss: 0.5313366651535034
Validation loss: 1.905183925423571

Epoch: 6| Step: 6
Training loss: 0.5438337326049805
Validation loss: 1.9138456467659242

Epoch: 6| Step: 7
Training loss: 0.98581862449646
Validation loss: 1.919517332507718

Epoch: 6| Step: 8
Training loss: 0.683713972568512
Validation loss: 1.8768138500951952

Epoch: 6| Step: 9
Training loss: 0.6885271072387695
Validation loss: 1.8526100932910878

Epoch: 6| Step: 10
Training loss: 0.5779440402984619
Validation loss: 1.8194652436881937

Epoch: 6| Step: 11
Training loss: 0.5858098864555359
Validation loss: 1.8054717215158607

Epoch: 6| Step: 12
Training loss: 0.4277954697608948
Validation loss: 1.796443998172719

Epoch: 6| Step: 13
Training loss: 0.5566758513450623
Validation loss: 1.7751436182247695

Epoch: 355| Step: 0
Training loss: 0.5109727382659912
Validation loss: 1.7803545997988792

Epoch: 6| Step: 1
Training loss: 0.7415025234222412
Validation loss: 1.7521351921942927

Epoch: 6| Step: 2
Training loss: 0.6923955082893372
Validation loss: 1.7471572481175905

Epoch: 6| Step: 3
Training loss: 0.38237816095352173
Validation loss: 1.7577977782936507

Epoch: 6| Step: 4
Training loss: 0.7815663814544678
Validation loss: 1.7538057886144167

Epoch: 6| Step: 5
Training loss: 0.7974205017089844
Validation loss: 1.7708038040386733

Epoch: 6| Step: 6
Training loss: 0.8347324728965759
Validation loss: 1.805517432510212

Epoch: 6| Step: 7
Training loss: 0.5453430414199829
Validation loss: 1.8481396987874021

Epoch: 6| Step: 8
Training loss: 0.3882148861885071
Validation loss: 1.8730181071066088

Epoch: 6| Step: 9
Training loss: 0.4355316758155823
Validation loss: 1.8463388130229006

Epoch: 6| Step: 10
Training loss: 0.5232992172241211
Validation loss: 1.8450753829812492

Epoch: 6| Step: 11
Training loss: 0.56307053565979
Validation loss: 1.8337666078280377

Epoch: 6| Step: 12
Training loss: 0.9043916463851929
Validation loss: 1.8177260160446167

Epoch: 6| Step: 13
Training loss: 0.18665902316570282
Validation loss: 1.8128465298683412

Epoch: 356| Step: 0
Training loss: 0.6579493284225464
Validation loss: 1.8412591398403209

Epoch: 6| Step: 1
Training loss: 0.45378556847572327
Validation loss: 1.854048313633088

Epoch: 6| Step: 2
Training loss: 0.5433747172355652
Validation loss: 1.8654452293149886

Epoch: 6| Step: 3
Training loss: 0.4640581011772156
Validation loss: 1.845100546395907

Epoch: 6| Step: 4
Training loss: 0.691973865032196
Validation loss: 1.8561251394210323

Epoch: 6| Step: 5
Training loss: 0.6045916080474854
Validation loss: 1.8293294880979805

Epoch: 6| Step: 6
Training loss: 0.2780340313911438
Validation loss: 1.814393215281989

Epoch: 6| Step: 7
Training loss: 0.8532674908638
Validation loss: 1.7988196880586687

Epoch: 6| Step: 8
Training loss: 0.7707834839820862
Validation loss: 1.786396804676261

Epoch: 6| Step: 9
Training loss: 0.9031310081481934
Validation loss: 1.810689890256492

Epoch: 6| Step: 10
Training loss: 0.5117112994194031
Validation loss: 1.8162755889277304

Epoch: 6| Step: 11
Training loss: 0.47618988156318665
Validation loss: 1.8334278060543923

Epoch: 6| Step: 12
Training loss: 0.5188400745391846
Validation loss: 1.8502259844092912

Epoch: 6| Step: 13
Training loss: 0.44318604469299316
Validation loss: 1.8562464611504668

Epoch: 357| Step: 0
Training loss: 0.4486548602581024
Validation loss: 1.849472826527011

Epoch: 6| Step: 1
Training loss: 0.5961241722106934
Validation loss: 1.8205605399224065

Epoch: 6| Step: 2
Training loss: 0.27924466133117676
Validation loss: 1.7698786156151884

Epoch: 6| Step: 3
Training loss: 0.5863702893257141
Validation loss: 1.822442139348676

Epoch: 6| Step: 4
Training loss: 0.4211488366127014
Validation loss: 1.8037947326578119

Epoch: 6| Step: 5
Training loss: 0.5799411535263062
Validation loss: 1.7974493170297274

Epoch: 6| Step: 6
Training loss: 0.6511675119400024
Validation loss: 1.7974826315397858

Epoch: 6| Step: 7
Training loss: 0.5284853577613831
Validation loss: 1.7906490692528345

Epoch: 6| Step: 8
Training loss: 0.9152600765228271
Validation loss: 1.794293063943104

Epoch: 6| Step: 9
Training loss: 0.6127004027366638
Validation loss: 1.815130247864672

Epoch: 6| Step: 10
Training loss: 0.7965024709701538
Validation loss: 1.8524775774248186

Epoch: 6| Step: 11
Training loss: 0.6635036468505859
Validation loss: 1.8564681019834293

Epoch: 6| Step: 12
Training loss: 0.7328134775161743
Validation loss: 1.8446754819603377

Epoch: 6| Step: 13
Training loss: 0.17073579132556915
Validation loss: 1.8073322696070517

Epoch: 358| Step: 0
Training loss: 0.5793877840042114
Validation loss: 1.801147727556126

Epoch: 6| Step: 1
Training loss: 1.082394003868103
Validation loss: 1.7661399187580231

Epoch: 6| Step: 2
Training loss: 0.5252395868301392
Validation loss: 1.7892220763749973

Epoch: 6| Step: 3
Training loss: 0.5610568523406982
Validation loss: 1.790437820137188

Epoch: 6| Step: 4
Training loss: 0.47112107276916504
Validation loss: 1.7914604974049393

Epoch: 6| Step: 5
Training loss: 0.36882513761520386
Validation loss: 1.8230680188825052

Epoch: 6| Step: 6
Training loss: 0.8196322917938232
Validation loss: 1.8579550853339575

Epoch: 6| Step: 7
Training loss: 0.5869128108024597
Validation loss: 1.8554902102357598

Epoch: 6| Step: 8
Training loss: 0.43405455350875854
Validation loss: 1.8743261393680368

Epoch: 6| Step: 9
Training loss: 0.4766753911972046
Validation loss: 1.8920097107528357

Epoch: 6| Step: 10
Training loss: 0.6850062608718872
Validation loss: 1.9188406800711026

Epoch: 6| Step: 11
Training loss: 0.4037671685218811
Validation loss: 1.9065555321272982

Epoch: 6| Step: 12
Training loss: 0.6663650274276733
Validation loss: 1.8944325549628145

Epoch: 6| Step: 13
Training loss: 0.8163906931877136
Validation loss: 1.8952236226809922

Epoch: 359| Step: 0
Training loss: 0.44189226627349854
Validation loss: 1.866831446206698

Epoch: 6| Step: 1
Training loss: 0.7977924346923828
Validation loss: 1.8242826346428163

Epoch: 6| Step: 2
Training loss: 0.4650691747665405
Validation loss: 1.783163320633673

Epoch: 6| Step: 3
Training loss: 0.3052835762500763
Validation loss: 1.7728640264080417

Epoch: 6| Step: 4
Training loss: 0.8054811954498291
Validation loss: 1.7541668773979269

Epoch: 6| Step: 5
Training loss: 0.4707845449447632
Validation loss: 1.720725405600763

Epoch: 6| Step: 6
Training loss: 0.6514239311218262
Validation loss: 1.7479869704092703

Epoch: 6| Step: 7
Training loss: 0.655210554599762
Validation loss: 1.7664411234599289

Epoch: 6| Step: 8
Training loss: 0.6022307276725769
Validation loss: 1.8039275625700593

Epoch: 6| Step: 9
Training loss: 0.5054745078086853
Validation loss: 1.8263486495582006

Epoch: 6| Step: 10
Training loss: 0.865423858165741
Validation loss: 1.8378250150270359

Epoch: 6| Step: 11
Training loss: 0.2518463730812073
Validation loss: 1.8292717254290016

Epoch: 6| Step: 12
Training loss: 0.6566811800003052
Validation loss: 1.8004144019978021

Epoch: 6| Step: 13
Training loss: 0.813859224319458
Validation loss: 1.8064924914349791

Epoch: 360| Step: 0
Training loss: 0.5111044049263
Validation loss: 1.792608489272415

Epoch: 6| Step: 1
Training loss: 0.7561518549919128
Validation loss: 1.7814671544618503

Epoch: 6| Step: 2
Training loss: 0.6233665347099304
Validation loss: 1.7375552295356669

Epoch: 6| Step: 3
Training loss: 0.8040693998336792
Validation loss: 1.738740590310866

Epoch: 6| Step: 4
Training loss: 0.6411658525466919
Validation loss: 1.7305720775358138

Epoch: 6| Step: 5
Training loss: 0.6196001768112183
Validation loss: 1.759076064632785

Epoch: 6| Step: 6
Training loss: 0.3671230971813202
Validation loss: 1.7276824520480247

Epoch: 6| Step: 7
Training loss: 0.5092792510986328
Validation loss: 1.709303811032285

Epoch: 6| Step: 8
Training loss: 0.4570823013782501
Validation loss: 1.7229393246353313

Epoch: 6| Step: 9
Training loss: 0.6737106442451477
Validation loss: 1.7509176000472038

Epoch: 6| Step: 10
Training loss: 0.4240451455116272
Validation loss: 1.7447463158638246

Epoch: 6| Step: 11
Training loss: 0.34544456005096436
Validation loss: 1.7932352840259511

Epoch: 6| Step: 12
Training loss: 1.04417884349823
Validation loss: 1.8390328268851004

Epoch: 6| Step: 13
Training loss: 0.8469732403755188
Validation loss: 1.8234784359573035

Epoch: 361| Step: 0
Training loss: 0.7178921699523926
Validation loss: 1.823616329059806

Epoch: 6| Step: 1
Training loss: 0.3727785050868988
Validation loss: 1.8647770022833219

Epoch: 6| Step: 2
Training loss: 0.5178024768829346
Validation loss: 1.8985743702098887

Epoch: 6| Step: 3
Training loss: 1.0152822732925415
Validation loss: 1.8405684322439215

Epoch: 6| Step: 4
Training loss: 0.6669752597808838
Validation loss: 1.8420118683127946

Epoch: 6| Step: 5
Training loss: 0.43824490904808044
Validation loss: 1.7973138914313367

Epoch: 6| Step: 6
Training loss: 0.5193668603897095
Validation loss: 1.785467601591541

Epoch: 6| Step: 7
Training loss: 0.6007475852966309
Validation loss: 1.7631048105096305

Epoch: 6| Step: 8
Training loss: 0.25090518593788147
Validation loss: 1.7324731349945068

Epoch: 6| Step: 9
Training loss: 0.451127827167511
Validation loss: 1.752635407191451

Epoch: 6| Step: 10
Training loss: 0.38936933875083923
Validation loss: 1.744328966704748

Epoch: 6| Step: 11
Training loss: 0.8122317790985107
Validation loss: 1.7148604457096388

Epoch: 6| Step: 12
Training loss: 0.6594737768173218
Validation loss: 1.7512373847346152

Epoch: 6| Step: 13
Training loss: 0.938208818435669
Validation loss: 1.7293631030667214

Epoch: 362| Step: 0
Training loss: 0.6059184670448303
Validation loss: 1.715278797252204

Epoch: 6| Step: 1
Training loss: 0.22183623909950256
Validation loss: 1.730181126184361

Epoch: 6| Step: 2
Training loss: 0.7020865082740784
Validation loss: 1.7572425283411497

Epoch: 6| Step: 3
Training loss: 0.714072585105896
Validation loss: 1.7692419252087992

Epoch: 6| Step: 4
Training loss: 0.5370825529098511
Validation loss: 1.781995552842335

Epoch: 6| Step: 5
Training loss: 0.4347669184207916
Validation loss: 1.7602937606073195

Epoch: 6| Step: 6
Training loss: 0.5927747488021851
Validation loss: 1.7447571741637362

Epoch: 6| Step: 7
Training loss: 0.43663448095321655
Validation loss: 1.7509344136843117

Epoch: 6| Step: 8
Training loss: 0.7490352392196655
Validation loss: 1.740977817966092

Epoch: 6| Step: 9
Training loss: 0.5087157487869263
Validation loss: 1.737267953093334

Epoch: 6| Step: 10
Training loss: 1.0752686262130737
Validation loss: 1.7124838688040291

Epoch: 6| Step: 11
Training loss: 0.40707460045814514
Validation loss: 1.7576809288353048

Epoch: 6| Step: 12
Training loss: 0.5254877209663391
Validation loss: 1.7511552995251072

Epoch: 6| Step: 13
Training loss: 0.5027437806129456
Validation loss: 1.7430925689717776

Epoch: 363| Step: 0
Training loss: 0.8663396835327148
Validation loss: 1.7645153999328613

Epoch: 6| Step: 1
Training loss: 0.5820255279541016
Validation loss: 1.7718720410459785

Epoch: 6| Step: 2
Training loss: 0.5607708692550659
Validation loss: 1.7359204215388144

Epoch: 6| Step: 3
Training loss: 0.49120327830314636
Validation loss: 1.7501350705341627

Epoch: 6| Step: 4
Training loss: 0.5066418647766113
Validation loss: 1.745470102115344

Epoch: 6| Step: 5
Training loss: 0.5051751732826233
Validation loss: 1.7282887530583206

Epoch: 6| Step: 6
Training loss: 0.6080940961837769
Validation loss: 1.7395497009318361

Epoch: 6| Step: 7
Training loss: 0.6315843462944031
Validation loss: 1.6962222976069297

Epoch: 6| Step: 8
Training loss: 0.6765980124473572
Validation loss: 1.7149806932736469

Epoch: 6| Step: 9
Training loss: 0.41759541630744934
Validation loss: 1.7067746577724334

Epoch: 6| Step: 10
Training loss: 0.3531055450439453
Validation loss: 1.7372339957503862

Epoch: 6| Step: 11
Training loss: 0.4852273166179657
Validation loss: 1.7364810243729623

Epoch: 6| Step: 12
Training loss: 0.51087486743927
Validation loss: 1.7265766692417923

Epoch: 6| Step: 13
Training loss: 0.9040957689285278
Validation loss: 1.7763680309377692

Epoch: 364| Step: 0
Training loss: 0.47628822922706604
Validation loss: 1.81551952515879

Epoch: 6| Step: 1
Training loss: 0.5870603322982788
Validation loss: 1.8221529606849916

Epoch: 6| Step: 2
Training loss: 0.4466572105884552
Validation loss: 1.8336866312129523

Epoch: 6| Step: 3
Training loss: 0.84843510389328
Validation loss: 1.779353025139019

Epoch: 6| Step: 4
Training loss: 0.5861197113990784
Validation loss: 1.778130398001722

Epoch: 6| Step: 5
Training loss: 0.9325494766235352
Validation loss: 1.7465658008411367

Epoch: 6| Step: 6
Training loss: 0.24794870615005493
Validation loss: 1.7321280279467184

Epoch: 6| Step: 7
Training loss: 0.5042911171913147
Validation loss: 1.7440623391059138

Epoch: 6| Step: 8
Training loss: 0.7021701335906982
Validation loss: 1.7094980004013225

Epoch: 6| Step: 9
Training loss: 0.5111369490623474
Validation loss: 1.7328758393564532

Epoch: 6| Step: 10
Training loss: 0.427179753780365
Validation loss: 1.7643105958097725

Epoch: 6| Step: 11
Training loss: 0.5889155268669128
Validation loss: 1.8002167799139535

Epoch: 6| Step: 12
Training loss: 0.3505725860595703
Validation loss: 1.8377587461984286

Epoch: 6| Step: 13
Training loss: 0.8499228358268738
Validation loss: 1.8430854261562388

Epoch: 365| Step: 0
Training loss: 0.4542602300643921
Validation loss: 1.8318608871070288

Epoch: 6| Step: 1
Training loss: 0.5044103860855103
Validation loss: 1.8110245889233005

Epoch: 6| Step: 2
Training loss: 0.6140937805175781
Validation loss: 1.7663958752027122

Epoch: 6| Step: 3
Training loss: 0.536672830581665
Validation loss: 1.7684384110153362

Epoch: 6| Step: 4
Training loss: 0.7710679769515991
Validation loss: 1.7762653955849268

Epoch: 6| Step: 5
Training loss: 0.6116501092910767
Validation loss: 1.7708288636258853

Epoch: 6| Step: 6
Training loss: 0.3601013422012329
Validation loss: 1.7810368845539708

Epoch: 6| Step: 7
Training loss: 0.6448311805725098
Validation loss: 1.787794223395727

Epoch: 6| Step: 8
Training loss: 0.6734964847564697
Validation loss: 1.8183624385505595

Epoch: 6| Step: 9
Training loss: 0.2332461178302765
Validation loss: 1.8188304965214064

Epoch: 6| Step: 10
Training loss: 0.7063577175140381
Validation loss: 1.8277559100940663

Epoch: 6| Step: 11
Training loss: 0.45379728078842163
Validation loss: 1.790864397120732

Epoch: 6| Step: 12
Training loss: 0.8008222579956055
Validation loss: 1.8142536365857689

Epoch: 6| Step: 13
Training loss: 0.6357952952384949
Validation loss: 1.8078390705970027

Epoch: 366| Step: 0
Training loss: 0.5456987619400024
Validation loss: 1.80723605104672

Epoch: 6| Step: 1
Training loss: 0.6172128319740295
Validation loss: 1.82410482821926

Epoch: 6| Step: 2
Training loss: 0.5732323527336121
Validation loss: 1.8091509752376105

Epoch: 6| Step: 3
Training loss: 0.2583915889263153
Validation loss: 1.7912264011239494

Epoch: 6| Step: 4
Training loss: 0.6741407513618469
Validation loss: 1.7758365818249282

Epoch: 6| Step: 5
Training loss: 0.6610040664672852
Validation loss: 1.7649769488201346

Epoch: 6| Step: 6
Training loss: 0.32243746519088745
Validation loss: 1.7711855788384714

Epoch: 6| Step: 7
Training loss: 0.584028959274292
Validation loss: 1.772323005942888

Epoch: 6| Step: 8
Training loss: 0.7714716196060181
Validation loss: 1.78884768614205

Epoch: 6| Step: 9
Training loss: 0.7590645551681519
Validation loss: 1.7797845563580912

Epoch: 6| Step: 10
Training loss: 0.5229055285453796
Validation loss: 1.7626064451791907

Epoch: 6| Step: 11
Training loss: 0.38967016339302063
Validation loss: 1.769654445750739

Epoch: 6| Step: 12
Training loss: 0.4141830801963806
Validation loss: 1.77699875831604

Epoch: 6| Step: 13
Training loss: 0.6913687586784363
Validation loss: 1.772482777154574

Epoch: 367| Step: 0
Training loss: 0.4502488374710083
Validation loss: 1.7960919449406285

Epoch: 6| Step: 1
Training loss: 0.5077364444732666
Validation loss: 1.800532566603794

Epoch: 6| Step: 2
Training loss: 0.6618162989616394
Validation loss: 1.803004405831778

Epoch: 6| Step: 3
Training loss: 0.3606778383255005
Validation loss: 1.8029591742382254

Epoch: 6| Step: 4
Training loss: 0.6972416639328003
Validation loss: 1.7924281973992624

Epoch: 6| Step: 5
Training loss: 0.5104150772094727
Validation loss: 1.7835911191919798

Epoch: 6| Step: 6
Training loss: 0.43079254031181335
Validation loss: 1.7575386249890892

Epoch: 6| Step: 7
Training loss: 1.0482157468795776
Validation loss: 1.7769615957813878

Epoch: 6| Step: 8
Training loss: 0.6536345481872559
Validation loss: 1.7887153792124924

Epoch: 6| Step: 9
Training loss: 0.46535152196884155
Validation loss: 1.7954868860142206

Epoch: 6| Step: 10
Training loss: 0.475762277841568
Validation loss: 1.8026933926408009

Epoch: 6| Step: 11
Training loss: 0.3674622178077698
Validation loss: 1.7956567118244786

Epoch: 6| Step: 12
Training loss: 0.36185699701309204
Validation loss: 1.795950980596645

Epoch: 6| Step: 13
Training loss: 0.789376974105835
Validation loss: 1.7982980410257976

Epoch: 368| Step: 0
Training loss: 0.7834314107894897
Validation loss: 1.7687361535205637

Epoch: 6| Step: 1
Training loss: 0.6729884147644043
Validation loss: 1.779560076293125

Epoch: 6| Step: 2
Training loss: 0.23303282260894775
Validation loss: 1.7767415943966116

Epoch: 6| Step: 3
Training loss: 0.29596829414367676
Validation loss: 1.7845325226424842

Epoch: 6| Step: 4
Training loss: 0.5353042483329773
Validation loss: 1.7864751751704881

Epoch: 6| Step: 5
Training loss: 0.5390340089797974
Validation loss: 1.7891576572131085

Epoch: 6| Step: 6
Training loss: 0.877240002155304
Validation loss: 1.812024780499038

Epoch: 6| Step: 7
Training loss: 0.21744346618652344
Validation loss: 1.8157661371333624

Epoch: 6| Step: 8
Training loss: 0.626968502998352
Validation loss: 1.8102241254621936

Epoch: 6| Step: 9
Training loss: 0.5585098266601562
Validation loss: 1.8349693846958939

Epoch: 6| Step: 10
Training loss: 0.4866759777069092
Validation loss: 1.8070313994602492

Epoch: 6| Step: 11
Training loss: 0.5549039244651794
Validation loss: 1.7748586926408993

Epoch: 6| Step: 12
Training loss: 0.523517370223999
Validation loss: 1.76643693318931

Epoch: 6| Step: 13
Training loss: 0.77372145652771
Validation loss: 1.729440935196415

Epoch: 369| Step: 0
Training loss: 0.30267587304115295
Validation loss: 1.7111903441849576

Epoch: 6| Step: 1
Training loss: 0.7642831206321716
Validation loss: 1.701398206013505

Epoch: 6| Step: 2
Training loss: 0.4612806439399719
Validation loss: 1.6895307648566462

Epoch: 6| Step: 3
Training loss: 0.738287091255188
Validation loss: 1.7181464446488248

Epoch: 6| Step: 4
Training loss: 0.3983743488788605
Validation loss: 1.731329829462113

Epoch: 6| Step: 5
Training loss: 0.5883913636207581
Validation loss: 1.7586440065855622

Epoch: 6| Step: 6
Training loss: 0.7596217393875122
Validation loss: 1.792327065621653

Epoch: 6| Step: 7
Training loss: 0.4358997941017151
Validation loss: 1.8834128046548495

Epoch: 6| Step: 8
Training loss: 1.0859203338623047
Validation loss: 1.8702069315859067

Epoch: 6| Step: 9
Training loss: 0.5833908319473267
Validation loss: 1.8762488903537873

Epoch: 6| Step: 10
Training loss: 0.42994382977485657
Validation loss: 1.8297723262540755

Epoch: 6| Step: 11
Training loss: 0.4421725571155548
Validation loss: 1.8436245033817906

Epoch: 6| Step: 12
Training loss: 0.5251954197883606
Validation loss: 1.7904622650915576

Epoch: 6| Step: 13
Training loss: 0.5012049674987793
Validation loss: 1.7292716272415654

Epoch: 370| Step: 0
Training loss: 0.45895496010780334
Validation loss: 1.7376663582299345

Epoch: 6| Step: 1
Training loss: 0.5093011856079102
Validation loss: 1.693843242942646

Epoch: 6| Step: 2
Training loss: 0.4692321717739105
Validation loss: 1.7441750931483444

Epoch: 6| Step: 3
Training loss: 0.6032249331474304
Validation loss: 1.7295671457885413

Epoch: 6| Step: 4
Training loss: 0.5074436664581299
Validation loss: 1.7830500961631857

Epoch: 6| Step: 5
Training loss: 0.439142644405365
Validation loss: 1.8116492456005466

Epoch: 6| Step: 6
Training loss: 0.3155931830406189
Validation loss: 1.7929451632243332

Epoch: 6| Step: 7
Training loss: 0.9143030047416687
Validation loss: 1.786421646354019

Epoch: 6| Step: 8
Training loss: 0.42754441499710083
Validation loss: 1.7923054925857052

Epoch: 6| Step: 9
Training loss: 0.601418673992157
Validation loss: 1.7746635175520373

Epoch: 6| Step: 10
Training loss: 0.6586670875549316
Validation loss: 1.8140669958565825

Epoch: 6| Step: 11
Training loss: 0.4864915907382965
Validation loss: 1.8242352354911067

Epoch: 6| Step: 12
Training loss: 0.2661867141723633
Validation loss: 1.8271164868467598

Epoch: 6| Step: 13
Training loss: 0.9524165391921997
Validation loss: 1.847611250415925

Epoch: 371| Step: 0
Training loss: 0.7978731393814087
Validation loss: 1.8053215062746437

Epoch: 6| Step: 1
Training loss: 0.7075165510177612
Validation loss: 1.7841154477929557

Epoch: 6| Step: 2
Training loss: 0.4618796706199646
Validation loss: 1.7739429038058045

Epoch: 6| Step: 3
Training loss: 0.4348483383655548
Validation loss: 1.7499092317396594

Epoch: 6| Step: 4
Training loss: 0.7198514938354492
Validation loss: 1.735818257895849

Epoch: 6| Step: 5
Training loss: 0.600588321685791
Validation loss: 1.7274090115742018

Epoch: 6| Step: 6
Training loss: 0.7025957107543945
Validation loss: 1.7578661544348604

Epoch: 6| Step: 7
Training loss: 0.19534289836883545
Validation loss: 1.760288602562361

Epoch: 6| Step: 8
Training loss: 0.6919218897819519
Validation loss: 1.7803826537183536

Epoch: 6| Step: 9
Training loss: 0.3783920407295227
Validation loss: 1.8014466454905849

Epoch: 6| Step: 10
Training loss: 0.5321995615959167
Validation loss: 1.7905920397850774

Epoch: 6| Step: 11
Training loss: 0.3399060070514679
Validation loss: 1.8031483580989223

Epoch: 6| Step: 12
Training loss: 0.45067262649536133
Validation loss: 1.83755608079254

Epoch: 6| Step: 13
Training loss: 0.5179105401039124
Validation loss: 1.8192913429711455

Epoch: 372| Step: 0
Training loss: 0.2733522951602936
Validation loss: 1.806392672241375

Epoch: 6| Step: 1
Training loss: 0.24842338263988495
Validation loss: 1.77266441493906

Epoch: 6| Step: 2
Training loss: 0.3268374800682068
Validation loss: 1.7450506020617742

Epoch: 6| Step: 3
Training loss: 0.2379496842622757
Validation loss: 1.7313516921894525

Epoch: 6| Step: 4
Training loss: 0.7860087156295776
Validation loss: 1.7264362086531937

Epoch: 6| Step: 5
Training loss: 0.8860287070274353
Validation loss: 1.7133908771699475

Epoch: 6| Step: 6
Training loss: 0.33089199662208557
Validation loss: 1.722862502580048

Epoch: 6| Step: 7
Training loss: 0.9058868885040283
Validation loss: 1.7524161031169276

Epoch: 6| Step: 8
Training loss: 0.5642286539077759
Validation loss: 1.7583073621155114

Epoch: 6| Step: 9
Training loss: 0.8802201151847839
Validation loss: 1.7494822830282233

Epoch: 6| Step: 10
Training loss: 0.5050814151763916
Validation loss: 1.7805618291260095

Epoch: 6| Step: 11
Training loss: 0.4088406264781952
Validation loss: 1.8178425578660862

Epoch: 6| Step: 12
Training loss: 0.4526054859161377
Validation loss: 1.8407174130921722

Epoch: 6| Step: 13
Training loss: 0.5773705840110779
Validation loss: 1.8627362751191663

Epoch: 373| Step: 0
Training loss: 0.24713505804538727
Validation loss: 1.818633214119942

Epoch: 6| Step: 1
Training loss: 0.48452383279800415
Validation loss: 1.8081182151712396

Epoch: 6| Step: 2
Training loss: 0.2786801755428314
Validation loss: 1.7999236455527685

Epoch: 6| Step: 3
Training loss: 0.5158399343490601
Validation loss: 1.7927338448903893

Epoch: 6| Step: 4
Training loss: 0.47864317893981934
Validation loss: 1.794176991267871

Epoch: 6| Step: 5
Training loss: 0.5839101672172546
Validation loss: 1.7860889639905704

Epoch: 6| Step: 6
Training loss: 0.5270857810974121
Validation loss: 1.7800012942283385

Epoch: 6| Step: 7
Training loss: 0.4341622591018677
Validation loss: 1.7480548402314544

Epoch: 6| Step: 8
Training loss: 0.8058217167854309
Validation loss: 1.7847454317154423

Epoch: 6| Step: 9
Training loss: 0.6292135715484619
Validation loss: 1.7785930607908516

Epoch: 6| Step: 10
Training loss: 0.574374794960022
Validation loss: 1.8096907754098215

Epoch: 6| Step: 11
Training loss: 0.6113154888153076
Validation loss: 1.7824666500091553

Epoch: 6| Step: 12
Training loss: 0.445506751537323
Validation loss: 1.7823871451039468

Epoch: 6| Step: 13
Training loss: 0.580957293510437
Validation loss: 1.7625707875015915

Epoch: 374| Step: 0
Training loss: 0.43966615200042725
Validation loss: 1.7388203938802083

Epoch: 6| Step: 1
Training loss: 0.8024024367332458
Validation loss: 1.7341366301300705

Epoch: 6| Step: 2
Training loss: 0.7012952566146851
Validation loss: 1.7558814235912856

Epoch: 6| Step: 3
Training loss: 0.3982265889644623
Validation loss: 1.7613237378417805

Epoch: 6| Step: 4
Training loss: 0.43742141127586365
Validation loss: 1.7653776919969948

Epoch: 6| Step: 5
Training loss: 0.41772449016571045
Validation loss: 1.7672253834303988

Epoch: 6| Step: 6
Training loss: 0.6064320206642151
Validation loss: 1.7891000278534428

Epoch: 6| Step: 7
Training loss: 0.5737574100494385
Validation loss: 1.7885761863441878

Epoch: 6| Step: 8
Training loss: 0.26599037647247314
Validation loss: 1.803191440079802

Epoch: 6| Step: 9
Training loss: 0.5513262748718262
Validation loss: 1.8363018292252735

Epoch: 6| Step: 10
Training loss: 0.4203993082046509
Validation loss: 1.8181852384280133

Epoch: 6| Step: 11
Training loss: 0.5779694318771362
Validation loss: 1.7792954944795178

Epoch: 6| Step: 12
Training loss: 0.526778519153595
Validation loss: 1.776100766274237

Epoch: 6| Step: 13
Training loss: 0.6810042858123779
Validation loss: 1.7446240462282652

Epoch: 375| Step: 0
Training loss: 0.6766786575317383
Validation loss: 1.7213069110788324

Epoch: 6| Step: 1
Training loss: 0.30349743366241455
Validation loss: 1.7480537711933095

Epoch: 6| Step: 2
Training loss: 0.40818601846694946
Validation loss: 1.7636709546530118

Epoch: 6| Step: 3
Training loss: 0.5929988026618958
Validation loss: 1.7759961094907535

Epoch: 6| Step: 4
Training loss: 0.35580816864967346
Validation loss: 1.8222917869526853

Epoch: 6| Step: 5
Training loss: 0.707877516746521
Validation loss: 1.813020621576617

Epoch: 6| Step: 6
Training loss: 0.6408678889274597
Validation loss: 1.8228866964258172

Epoch: 6| Step: 7
Training loss: 0.16807921230793
Validation loss: 1.8407308850237118

Epoch: 6| Step: 8
Training loss: 0.7301203012466431
Validation loss: 1.8294805044768958

Epoch: 6| Step: 9
Training loss: 0.44414177536964417
Validation loss: 1.8084987978781424

Epoch: 6| Step: 10
Training loss: 0.4614907503128052
Validation loss: 1.7874786059061687

Epoch: 6| Step: 11
Training loss: 0.4078596532344818
Validation loss: 1.753168330397657

Epoch: 6| Step: 12
Training loss: 0.925273597240448
Validation loss: 1.7598783175150554

Epoch: 6| Step: 13
Training loss: 0.41731885075569153
Validation loss: 1.7409563884940198

Epoch: 376| Step: 0
Training loss: 0.3820675015449524
Validation loss: 1.7568518974447762

Epoch: 6| Step: 1
Training loss: 0.4480104148387909
Validation loss: 1.7983368737723238

Epoch: 6| Step: 2
Training loss: 0.530991792678833
Validation loss: 1.7909051013249222

Epoch: 6| Step: 3
Training loss: 0.44612056016921997
Validation loss: 1.819671453968171

Epoch: 6| Step: 4
Training loss: 0.7872180938720703
Validation loss: 1.8214904210900749

Epoch: 6| Step: 5
Training loss: 0.5879455208778381
Validation loss: 1.8518992021519651

Epoch: 6| Step: 6
Training loss: 0.748893678188324
Validation loss: 1.861755540294032

Epoch: 6| Step: 7
Training loss: 0.631260871887207
Validation loss: 1.854959782733712

Epoch: 6| Step: 8
Training loss: 0.47636574506759644
Validation loss: 1.8539039691289265

Epoch: 6| Step: 9
Training loss: 0.41027963161468506
Validation loss: 1.8166832821343535

Epoch: 6| Step: 10
Training loss: 0.6168351769447327
Validation loss: 1.7907585290170485

Epoch: 6| Step: 11
Training loss: 0.31405913829803467
Validation loss: 1.7585606485284784

Epoch: 6| Step: 12
Training loss: 0.41617584228515625
Validation loss: 1.7513943910598755

Epoch: 6| Step: 13
Training loss: 0.7394385933876038
Validation loss: 1.7393790752657

Epoch: 377| Step: 0
Training loss: 0.465278297662735
Validation loss: 1.7605217092780656

Epoch: 6| Step: 1
Training loss: 0.6793779134750366
Validation loss: 1.7865569796613467

Epoch: 6| Step: 2
Training loss: 0.8010771870613098
Validation loss: 1.7944799033544396

Epoch: 6| Step: 3
Training loss: 0.6852853298187256
Validation loss: 1.84413404105812

Epoch: 6| Step: 4
Training loss: 0.6585195660591125
Validation loss: 1.8455697003231253

Epoch: 6| Step: 5
Training loss: 0.37654587626457214
Validation loss: 1.8507437629084433

Epoch: 6| Step: 6
Training loss: 0.40427565574645996
Validation loss: 1.8152453155927761

Epoch: 6| Step: 7
Training loss: 0.3594403862953186
Validation loss: 1.8297190794380762

Epoch: 6| Step: 8
Training loss: 0.2338801622390747
Validation loss: 1.7946326771090109

Epoch: 6| Step: 9
Training loss: 0.5298429131507874
Validation loss: 1.8174000773378598

Epoch: 6| Step: 10
Training loss: 0.6466519832611084
Validation loss: 1.7594775064017183

Epoch: 6| Step: 11
Training loss: 0.24967961013317108
Validation loss: 1.7845007399077057

Epoch: 6| Step: 12
Training loss: 0.5145448446273804
Validation loss: 1.8087765427045925

Epoch: 6| Step: 13
Training loss: 0.5292144417762756
Validation loss: 1.8101022115317724

Epoch: 378| Step: 0
Training loss: 0.5244364142417908
Validation loss: 1.840082089106242

Epoch: 6| Step: 1
Training loss: 0.612381637096405
Validation loss: 1.8330570690093502

Epoch: 6| Step: 2
Training loss: 0.6061869263648987
Validation loss: 1.8640389057897753

Epoch: 6| Step: 3
Training loss: 0.869623064994812
Validation loss: 1.8123437884033367

Epoch: 6| Step: 4
Training loss: 0.43191128969192505
Validation loss: 1.803510631284406

Epoch: 6| Step: 5
Training loss: 0.3876088261604309
Validation loss: 1.8043657464365805

Epoch: 6| Step: 6
Training loss: 0.5510646104812622
Validation loss: 1.7969131200544295

Epoch: 6| Step: 7
Training loss: 0.40676721930503845
Validation loss: 1.8236717498430641

Epoch: 6| Step: 8
Training loss: 0.4252578020095825
Validation loss: 1.835625785012399

Epoch: 6| Step: 9
Training loss: 0.3543586730957031
Validation loss: 1.7871902552984094

Epoch: 6| Step: 10
Training loss: 0.2640509009361267
Validation loss: 1.7757241161920692

Epoch: 6| Step: 11
Training loss: 0.7458161115646362
Validation loss: 1.7550828341514833

Epoch: 6| Step: 12
Training loss: 0.39277195930480957
Validation loss: 1.756165082736682

Epoch: 6| Step: 13
Training loss: 0.4656389057636261
Validation loss: 1.7429039196301532

Epoch: 379| Step: 0
Training loss: 0.4074566960334778
Validation loss: 1.7514284003165461

Epoch: 6| Step: 1
Training loss: 0.7636452913284302
Validation loss: 1.7402160744513235

Epoch: 6| Step: 2
Training loss: 0.5195989608764648
Validation loss: 1.7583245320986676

Epoch: 6| Step: 3
Training loss: 0.7175963521003723
Validation loss: 1.778570887862995

Epoch: 6| Step: 4
Training loss: 0.23802368342876434
Validation loss: 1.747747766074314

Epoch: 6| Step: 5
Training loss: 0.5957161784172058
Validation loss: 1.7984468321646414

Epoch: 6| Step: 6
Training loss: 0.4587571620941162
Validation loss: 1.7776718613921956

Epoch: 6| Step: 7
Training loss: 0.2773941457271576
Validation loss: 1.7865206400553386

Epoch: 6| Step: 8
Training loss: 0.526637077331543
Validation loss: 1.7623738140188239

Epoch: 6| Step: 9
Training loss: 0.5826137065887451
Validation loss: 1.7206004563198294

Epoch: 6| Step: 10
Training loss: 0.2500108480453491
Validation loss: 1.7172541336346698

Epoch: 6| Step: 11
Training loss: 0.6730205416679382
Validation loss: 1.7365615637071672

Epoch: 6| Step: 12
Training loss: 0.41263657808303833
Validation loss: 1.7276850336341447

Epoch: 6| Step: 13
Training loss: 0.7554762363433838
Validation loss: 1.7741417897644864

Epoch: 380| Step: 0
Training loss: 0.4736299216747284
Validation loss: 1.8104447805753319

Epoch: 6| Step: 1
Training loss: 0.7603095173835754
Validation loss: 1.8404940277017572

Epoch: 6| Step: 2
Training loss: 0.5397624373435974
Validation loss: 1.91472424486632

Epoch: 6| Step: 3
Training loss: 0.47650840878486633
Validation loss: 1.9363357725963797

Epoch: 6| Step: 4
Training loss: 0.5253250002861023
Validation loss: 1.9483027342827088

Epoch: 6| Step: 5
Training loss: 0.31495702266693115
Validation loss: 1.909903061005377

Epoch: 6| Step: 6
Training loss: 0.5431766510009766
Validation loss: 1.8316618998845418

Epoch: 6| Step: 7
Training loss: 0.43855735659599304
Validation loss: 1.7722823799297374

Epoch: 6| Step: 8
Training loss: 0.5983754396438599
Validation loss: 1.7316633860270183

Epoch: 6| Step: 9
Training loss: 0.5404554605484009
Validation loss: 1.6973689192084855

Epoch: 6| Step: 10
Training loss: 0.3944055438041687
Validation loss: 1.6640154238670104

Epoch: 6| Step: 11
Training loss: 0.4696425795555115
Validation loss: 1.7152963915178854

Epoch: 6| Step: 12
Training loss: 0.8376463651657104
Validation loss: 1.6986134641913957

Epoch: 6| Step: 13
Training loss: 0.6314309239387512
Validation loss: 1.7365825573603313

Epoch: 381| Step: 0
Training loss: 0.5574204325675964
Validation loss: 1.8389618935123566

Epoch: 6| Step: 1
Training loss: 0.4912016987800598
Validation loss: 1.8811254091160272

Epoch: 6| Step: 2
Training loss: 0.5699650049209595
Validation loss: 1.846473865611579

Epoch: 6| Step: 3
Training loss: 0.8045275807380676
Validation loss: 1.8680732788578156

Epoch: 6| Step: 4
Training loss: 0.5572860836982727
Validation loss: 1.83604129668205

Epoch: 6| Step: 5
Training loss: 0.37231868505477905
Validation loss: 1.8182938752635833

Epoch: 6| Step: 6
Training loss: 0.592978835105896
Validation loss: 1.7814522943189066

Epoch: 6| Step: 7
Training loss: 0.5898434519767761
Validation loss: 1.7852184477672781

Epoch: 6| Step: 8
Training loss: 0.50439453125
Validation loss: 1.7591071821028186

Epoch: 6| Step: 9
Training loss: 0.47976696491241455
Validation loss: 1.7659406187713786

Epoch: 6| Step: 10
Training loss: 0.6399118900299072
Validation loss: 1.780202386199787

Epoch: 6| Step: 11
Training loss: 0.39637696743011475
Validation loss: 1.8262910458349413

Epoch: 6| Step: 12
Training loss: 0.597884476184845
Validation loss: 1.8069150435027255

Epoch: 6| Step: 13
Training loss: 0.5520320534706116
Validation loss: 1.8375745845097367

Epoch: 382| Step: 0
Training loss: 0.6142938137054443
Validation loss: 1.8195064055022372

Epoch: 6| Step: 1
Training loss: 1.1882715225219727
Validation loss: 1.848188925814885

Epoch: 6| Step: 2
Training loss: 0.42288118600845337
Validation loss: 1.8291440215162051

Epoch: 6| Step: 3
Training loss: 0.18078693747520447
Validation loss: 1.7984291648352018

Epoch: 6| Step: 4
Training loss: 0.3439435064792633
Validation loss: 1.7880660474941295

Epoch: 6| Step: 5
Training loss: 0.3087877035140991
Validation loss: 1.7843609202292658

Epoch: 6| Step: 6
Training loss: 0.40054816007614136
Validation loss: 1.7613418755992767

Epoch: 6| Step: 7
Training loss: 0.37487825751304626
Validation loss: 1.7899524447738484

Epoch: 6| Step: 8
Training loss: 0.4554779529571533
Validation loss: 1.7549225809753581

Epoch: 6| Step: 9
Training loss: 0.6340823173522949
Validation loss: 1.78913055440431

Epoch: 6| Step: 10
Training loss: 0.5478571653366089
Validation loss: 1.7578776997904624

Epoch: 6| Step: 11
Training loss: 0.49613699316978455
Validation loss: 1.7771647021334658

Epoch: 6| Step: 12
Training loss: 0.42877262830734253
Validation loss: 1.7607731396152126

Epoch: 6| Step: 13
Training loss: 0.41740572452545166
Validation loss: 1.789721409479777

Epoch: 383| Step: 0
Training loss: 0.6180380582809448
Validation loss: 1.7746785840680521

Epoch: 6| Step: 1
Training loss: 0.21549628674983978
Validation loss: 1.790866050668942

Epoch: 6| Step: 2
Training loss: 0.38122445344924927
Validation loss: 1.8093246106178529

Epoch: 6| Step: 3
Training loss: 0.3866761326789856
Validation loss: 1.8283363016702796

Epoch: 6| Step: 4
Training loss: 0.5095160007476807
Validation loss: 1.7914540742033271

Epoch: 6| Step: 5
Training loss: 0.8324249982833862
Validation loss: 1.7810617339226507

Epoch: 6| Step: 6
Training loss: 0.6605998277664185
Validation loss: 1.7493885678629721

Epoch: 6| Step: 7
Training loss: 0.4386743903160095
Validation loss: 1.7280779525797854

Epoch: 6| Step: 8
Training loss: 0.4777566194534302
Validation loss: 1.7152022738610544

Epoch: 6| Step: 9
Training loss: 0.5165246725082397
Validation loss: 1.695332892479435

Epoch: 6| Step: 10
Training loss: 0.3309817910194397
Validation loss: 1.7154263680981052

Epoch: 6| Step: 11
Training loss: 0.7962363958358765
Validation loss: 1.733862623091667

Epoch: 6| Step: 12
Training loss: 0.37266653776168823
Validation loss: 1.7495416966817712

Epoch: 6| Step: 13
Training loss: 0.3639999330043793
Validation loss: 1.7774548735669864

Epoch: 384| Step: 0
Training loss: 0.528119683265686
Validation loss: 1.7592686440355034

Epoch: 6| Step: 1
Training loss: 0.3433356285095215
Validation loss: 1.753332059870484

Epoch: 6| Step: 2
Training loss: 0.594858705997467
Validation loss: 1.7839020580373786

Epoch: 6| Step: 3
Training loss: 0.41501423716545105
Validation loss: 1.7818991702090028

Epoch: 6| Step: 4
Training loss: 0.47043296694755554
Validation loss: 1.7923319455116027

Epoch: 6| Step: 5
Training loss: 0.5395870208740234
Validation loss: 1.7690221878790087

Epoch: 6| Step: 6
Training loss: 0.41535040736198425
Validation loss: 1.7491658015917706

Epoch: 6| Step: 7
Training loss: 0.6610604524612427
Validation loss: 1.734862640339841

Epoch: 6| Step: 8
Training loss: 0.3606981337070465
Validation loss: 1.705913701365071

Epoch: 6| Step: 9
Training loss: 0.37075722217559814
Validation loss: 1.7096295267023065

Epoch: 6| Step: 10
Training loss: 0.5630497336387634
Validation loss: 1.7044810441232496

Epoch: 6| Step: 11
Training loss: 0.5459485650062561
Validation loss: 1.7067861428824804

Epoch: 6| Step: 12
Training loss: 0.6582835912704468
Validation loss: 1.718806653894404

Epoch: 6| Step: 13
Training loss: 0.6642463207244873
Validation loss: 1.7203393623393068

Epoch: 385| Step: 0
Training loss: 0.39128533005714417
Validation loss: 1.7464620733773837

Epoch: 6| Step: 1
Training loss: 0.39742085337638855
Validation loss: 1.785327596049155

Epoch: 6| Step: 2
Training loss: 0.49667155742645264
Validation loss: 1.8244081953520417

Epoch: 6| Step: 3
Training loss: 0.8757728338241577
Validation loss: 1.8109178722545665

Epoch: 6| Step: 4
Training loss: 0.40464353561401367
Validation loss: 1.8114930352857035

Epoch: 6| Step: 5
Training loss: 0.3837195038795471
Validation loss: 1.7729763369406424

Epoch: 6| Step: 6
Training loss: 0.435785710811615
Validation loss: 1.7493236910912298

Epoch: 6| Step: 7
Training loss: 0.5453115701675415
Validation loss: 1.754128699661583

Epoch: 6| Step: 8
Training loss: 0.3574232757091522
Validation loss: 1.7282853562344787

Epoch: 6| Step: 9
Training loss: 0.31018683314323425
Validation loss: 1.7959418835178498

Epoch: 6| Step: 10
Training loss: 0.4770149886608124
Validation loss: 1.8046011424833728

Epoch: 6| Step: 11
Training loss: 0.5576773881912231
Validation loss: 1.8178628272907709

Epoch: 6| Step: 12
Training loss: 0.8989467620849609
Validation loss: 1.7737711885923981

Epoch: 6| Step: 13
Training loss: 0.3331286907196045
Validation loss: 1.771343095328218

Epoch: 386| Step: 0
Training loss: 0.4152216911315918
Validation loss: 1.773775682654432

Epoch: 6| Step: 1
Training loss: 0.3107839822769165
Validation loss: 1.749482176637137

Epoch: 6| Step: 2
Training loss: 0.3754275441169739
Validation loss: 1.7456063352605349

Epoch: 6| Step: 3
Training loss: 0.5615720748901367
Validation loss: 1.74883105421579

Epoch: 6| Step: 4
Training loss: 0.44826579093933105
Validation loss: 1.7288485855184577

Epoch: 6| Step: 5
Training loss: 0.23184147477149963
Validation loss: 1.728578245767983

Epoch: 6| Step: 6
Training loss: 0.441255122423172
Validation loss: 1.7242972235525809

Epoch: 6| Step: 7
Training loss: 0.26751333475112915
Validation loss: 1.7137058409311439

Epoch: 6| Step: 8
Training loss: 0.8445896506309509
Validation loss: 1.7125439041404313

Epoch: 6| Step: 9
Training loss: 0.8119707703590393
Validation loss: 1.694909723856116

Epoch: 6| Step: 10
Training loss: 0.5837014317512512
Validation loss: 1.7435146044659358

Epoch: 6| Step: 11
Training loss: 0.5058646202087402
Validation loss: 1.750174012235416

Epoch: 6| Step: 12
Training loss: 0.4726581871509552
Validation loss: 1.7821481714966476

Epoch: 6| Step: 13
Training loss: 0.6320916414260864
Validation loss: 1.8170751365282203

Epoch: 387| Step: 0
Training loss: 0.6534366607666016
Validation loss: 1.8053699385735296

Epoch: 6| Step: 1
Training loss: 0.38819119334220886
Validation loss: 1.8212175817899807

Epoch: 6| Step: 2
Training loss: 0.4664834141731262
Validation loss: 1.7821358993489256

Epoch: 6| Step: 3
Training loss: 0.2949966788291931
Validation loss: 1.7900847247851792

Epoch: 6| Step: 4
Training loss: 0.44504207372665405
Validation loss: 1.7989757830096829

Epoch: 6| Step: 5
Training loss: 0.6359186768531799
Validation loss: 1.7749973163809827

Epoch: 6| Step: 6
Training loss: 0.3817451298236847
Validation loss: 1.746230653537217

Epoch: 6| Step: 7
Training loss: 0.35923734307289124
Validation loss: 1.7292965176284953

Epoch: 6| Step: 8
Training loss: 0.5563341975212097
Validation loss: 1.7491959397510817

Epoch: 6| Step: 9
Training loss: 0.6985054016113281
Validation loss: 1.7340564727783203

Epoch: 6| Step: 10
Training loss: 0.38118380308151245
Validation loss: 1.7497091998336136

Epoch: 6| Step: 11
Training loss: 0.666875958442688
Validation loss: 1.7228804596008793

Epoch: 6| Step: 12
Training loss: 0.5067204236984253
Validation loss: 1.6980012655258179

Epoch: 6| Step: 13
Training loss: 0.4435466527938843
Validation loss: 1.6946889341518443

Epoch: 388| Step: 0
Training loss: 0.6060044765472412
Validation loss: 1.7338983602421258

Epoch: 6| Step: 1
Training loss: 0.5960901975631714
Validation loss: 1.7379498276659238

Epoch: 6| Step: 2
Training loss: 0.4219636917114258
Validation loss: 1.7735342697430683

Epoch: 6| Step: 3
Training loss: 0.5856117606163025
Validation loss: 1.7963667249166837

Epoch: 6| Step: 4
Training loss: 0.3834434151649475
Validation loss: 1.8081622444173342

Epoch: 6| Step: 5
Training loss: 0.3205210864543915
Validation loss: 1.8225770022279473

Epoch: 6| Step: 6
Training loss: 0.26794305443763733
Validation loss: 1.8411976586106003

Epoch: 6| Step: 7
Training loss: 0.7399709224700928
Validation loss: 1.827585425428165

Epoch: 6| Step: 8
Training loss: 0.4089967906475067
Validation loss: 1.7987475215747792

Epoch: 6| Step: 9
Training loss: 0.46789199113845825
Validation loss: 1.7586474239185292

Epoch: 6| Step: 10
Training loss: 0.3766210377216339
Validation loss: 1.7422623288246892

Epoch: 6| Step: 11
Training loss: 0.5130776166915894
Validation loss: 1.7236471112056444

Epoch: 6| Step: 12
Training loss: 0.4164179861545563
Validation loss: 1.7493321549507879

Epoch: 6| Step: 13
Training loss: 0.345012366771698
Validation loss: 1.714053020682386

Epoch: 389| Step: 0
Training loss: 0.5422836542129517
Validation loss: 1.7297379201458347

Epoch: 6| Step: 1
Training loss: 0.3600478172302246
Validation loss: 1.740098916074281

Epoch: 6| Step: 2
Training loss: 0.40224525332450867
Validation loss: 1.7521826144187682

Epoch: 6| Step: 3
Training loss: 0.3496975898742676
Validation loss: 1.7653526542007283

Epoch: 6| Step: 4
Training loss: 0.40459346771240234
Validation loss: 1.7937607637015722

Epoch: 6| Step: 5
Training loss: 0.6481710076332092
Validation loss: 1.7860089604572584

Epoch: 6| Step: 6
Training loss: 0.6670905947685242
Validation loss: 1.8126476836460892

Epoch: 6| Step: 7
Training loss: 0.3856320381164551
Validation loss: 1.8157486813042754

Epoch: 6| Step: 8
Training loss: 0.487053781747818
Validation loss: 1.8659051092722083

Epoch: 6| Step: 9
Training loss: 0.6144556403160095
Validation loss: 1.8575674769698933

Epoch: 6| Step: 10
Training loss: 0.3916705250740051
Validation loss: 1.8690624506242814

Epoch: 6| Step: 11
Training loss: 0.4210393726825714
Validation loss: 1.8094744913039669

Epoch: 6| Step: 12
Training loss: 0.2842133045196533
Validation loss: 1.7387090049764162

Epoch: 6| Step: 13
Training loss: 0.7369071245193481
Validation loss: 1.7404637298276346

Epoch: 390| Step: 0
Training loss: 0.2745096981525421
Validation loss: 1.7001839901811333

Epoch: 6| Step: 1
Training loss: 0.497133731842041
Validation loss: 1.6915351652329969

Epoch: 6| Step: 2
Training loss: 0.46727707982063293
Validation loss: 1.6741059416083879

Epoch: 6| Step: 3
Training loss: 0.5903411507606506
Validation loss: 1.6606537859926942

Epoch: 6| Step: 4
Training loss: 0.20390674471855164
Validation loss: 1.683141859628821

Epoch: 6| Step: 5
Training loss: 0.5065943598747253
Validation loss: 1.7036290732763146

Epoch: 6| Step: 6
Training loss: 0.7717809081077576
Validation loss: 1.7352226434215423

Epoch: 6| Step: 7
Training loss: 0.5959879159927368
Validation loss: 1.767122531449923

Epoch: 6| Step: 8
Training loss: 0.2991057336330414
Validation loss: 1.8241372313550723

Epoch: 6| Step: 9
Training loss: 0.6926404237747192
Validation loss: 1.7832029045269053

Epoch: 6| Step: 10
Training loss: 0.6103095412254333
Validation loss: 1.7671259475010697

Epoch: 6| Step: 11
Training loss: 0.5476158857345581
Validation loss: 1.799205458292397

Epoch: 6| Step: 12
Training loss: 0.38512730598449707
Validation loss: 1.7450642547299784

Epoch: 6| Step: 13
Training loss: 0.2970496416091919
Validation loss: 1.7590942716085782

Epoch: 391| Step: 0
Training loss: 0.3444356918334961
Validation loss: 1.7443751904272264

Epoch: 6| Step: 1
Training loss: 0.22878259420394897
Validation loss: 1.7511034396386915

Epoch: 6| Step: 2
Training loss: 0.3929917514324188
Validation loss: 1.738316177040018

Epoch: 6| Step: 3
Training loss: 0.47423213720321655
Validation loss: 1.759258290772797

Epoch: 6| Step: 4
Training loss: 0.18808694183826447
Validation loss: 1.794269363085429

Epoch: 6| Step: 5
Training loss: 0.7263206243515015
Validation loss: 1.8375073914886804

Epoch: 6| Step: 6
Training loss: 0.48012030124664307
Validation loss: 1.831255591043862

Epoch: 6| Step: 7
Training loss: 0.45157527923583984
Validation loss: 1.7970170820913007

Epoch: 6| Step: 8
Training loss: 0.6447402834892273
Validation loss: 1.7723146087379866

Epoch: 6| Step: 9
Training loss: 0.714631974697113
Validation loss: 1.7262524033105502

Epoch: 6| Step: 10
Training loss: 0.4793139100074768
Validation loss: 1.6941324190426899

Epoch: 6| Step: 11
Training loss: 0.5309993624687195
Validation loss: 1.6819000295413438

Epoch: 6| Step: 12
Training loss: 0.41768306493759155
Validation loss: 1.6746037403742473

Epoch: 6| Step: 13
Training loss: 0.2906527817249298
Validation loss: 1.6860769000104678

Epoch: 392| Step: 0
Training loss: 0.3266439139842987
Validation loss: 1.7090739639856483

Epoch: 6| Step: 1
Training loss: 0.3787153363227844
Validation loss: 1.717754215322515

Epoch: 6| Step: 2
Training loss: 0.42298948764801025
Validation loss: 1.7238682495650424

Epoch: 6| Step: 3
Training loss: 0.4773883819580078
Validation loss: 1.7502340744900446

Epoch: 6| Step: 4
Training loss: 0.6024032831192017
Validation loss: 1.7606058492455432

Epoch: 6| Step: 5
Training loss: 0.542548418045044
Validation loss: 1.7492893767613236

Epoch: 6| Step: 6
Training loss: 0.6458572149276733
Validation loss: 1.7742318055963004

Epoch: 6| Step: 7
Training loss: 0.6511045098304749
Validation loss: 1.7805811359036354

Epoch: 6| Step: 8
Training loss: 0.407295286655426
Validation loss: 1.7811308227559572

Epoch: 6| Step: 9
Training loss: 0.32648128271102905
Validation loss: 1.7893560714619134

Epoch: 6| Step: 10
Training loss: 0.5634422898292542
Validation loss: 1.763564718666897

Epoch: 6| Step: 11
Training loss: 0.257992684841156
Validation loss: 1.7565291030432588

Epoch: 6| Step: 12
Training loss: 0.43758654594421387
Validation loss: 1.7367356086290011

Epoch: 6| Step: 13
Training loss: 0.3732101619243622
Validation loss: 1.7264079663061327

Epoch: 393| Step: 0
Training loss: 0.5084173679351807
Validation loss: 1.7307887333695606

Epoch: 6| Step: 1
Training loss: 0.42604368925094604
Validation loss: 1.7305950298104236

Epoch: 6| Step: 2
Training loss: 0.7096461057662964
Validation loss: 1.7444460033088602

Epoch: 6| Step: 3
Training loss: 0.3472778797149658
Validation loss: 1.7628304099523893

Epoch: 6| Step: 4
Training loss: 0.2791610658168793
Validation loss: 1.7681494964066373

Epoch: 6| Step: 5
Training loss: 0.5475755333900452
Validation loss: 1.751292759372342

Epoch: 6| Step: 6
Training loss: 0.36708539724349976
Validation loss: 1.7806751189693328

Epoch: 6| Step: 7
Training loss: 0.3947429955005646
Validation loss: 1.7343305169895131

Epoch: 6| Step: 8
Training loss: 0.5897971987724304
Validation loss: 1.7180872027591994

Epoch: 6| Step: 9
Training loss: 0.45604807138442993
Validation loss: 1.7329750907036565

Epoch: 6| Step: 10
Training loss: 0.5173910856246948
Validation loss: 1.7134205833558114

Epoch: 6| Step: 11
Training loss: 0.43137234449386597
Validation loss: 1.719674192449098

Epoch: 6| Step: 12
Training loss: 0.24541202187538147
Validation loss: 1.715441885814872

Epoch: 6| Step: 13
Training loss: 0.5998243093490601
Validation loss: 1.717130232882756

Epoch: 394| Step: 0
Training loss: 0.3864540457725525
Validation loss: 1.7014456872017152

Epoch: 6| Step: 1
Training loss: 0.48859351873397827
Validation loss: 1.7144567120459773

Epoch: 6| Step: 2
Training loss: 0.4217985272407532
Validation loss: 1.7073855194994199

Epoch: 6| Step: 3
Training loss: 0.5081172585487366
Validation loss: 1.6971226430708362

Epoch: 6| Step: 4
Training loss: 0.6057252883911133
Validation loss: 1.7033498441019366

Epoch: 6| Step: 5
Training loss: 0.3576427102088928
Validation loss: 1.6921650876281082

Epoch: 6| Step: 6
Training loss: 0.347301185131073
Validation loss: 1.7250171720340688

Epoch: 6| Step: 7
Training loss: 0.25584495067596436
Validation loss: 1.705075030685753

Epoch: 6| Step: 8
Training loss: 0.35219359397888184
Validation loss: 1.7222702221203876

Epoch: 6| Step: 9
Training loss: 0.5536017417907715
Validation loss: 1.7681278669705955

Epoch: 6| Step: 10
Training loss: 0.39915138483047485
Validation loss: 1.8146833591563727

Epoch: 6| Step: 11
Training loss: 0.464181125164032
Validation loss: 1.7930250334483322

Epoch: 6| Step: 12
Training loss: 0.6510858535766602
Validation loss: 1.772912258742958

Epoch: 6| Step: 13
Training loss: 0.6724236011505127
Validation loss: 1.742702430294406

Epoch: 395| Step: 0
Training loss: 0.3547791540622711
Validation loss: 1.7187373740698701

Epoch: 6| Step: 1
Training loss: 0.5215135812759399
Validation loss: 1.7122537269387195

Epoch: 6| Step: 2
Training loss: 0.49392926692962646
Validation loss: 1.691523039212791

Epoch: 6| Step: 3
Training loss: 0.5544801950454712
Validation loss: 1.7038562631094327

Epoch: 6| Step: 4
Training loss: 0.4173237681388855
Validation loss: 1.685191039116152

Epoch: 6| Step: 5
Training loss: 0.7967966198921204
Validation loss: 1.7132832029814362

Epoch: 6| Step: 6
Training loss: 0.39818012714385986
Validation loss: 1.7189539260761713

Epoch: 6| Step: 7
Training loss: 0.6041690707206726
Validation loss: 1.7707709420111872

Epoch: 6| Step: 8
Training loss: 0.4805627763271332
Validation loss: 1.768659399401757

Epoch: 6| Step: 9
Training loss: 0.28435975313186646
Validation loss: 1.768763393484136

Epoch: 6| Step: 10
Training loss: 0.3728071451187134
Validation loss: 1.802320070164178

Epoch: 6| Step: 11
Training loss: 0.302784264087677
Validation loss: 1.778412470253565

Epoch: 6| Step: 12
Training loss: 0.46635186672210693
Validation loss: 1.720826091304902

Epoch: 6| Step: 13
Training loss: 0.2236085683107376
Validation loss: 1.7217634313849992

Epoch: 396| Step: 0
Training loss: 0.2969210147857666
Validation loss: 1.6730591520186393

Epoch: 6| Step: 1
Training loss: 0.45438873767852783
Validation loss: 1.6557728077775689

Epoch: 6| Step: 2
Training loss: 0.6586918234825134
Validation loss: 1.644777859410932

Epoch: 6| Step: 3
Training loss: 0.8535847663879395
Validation loss: 1.6886277352609942

Epoch: 6| Step: 4
Training loss: 0.2735925316810608
Validation loss: 1.680250387037954

Epoch: 6| Step: 5
Training loss: 0.5873146057128906
Validation loss: 1.7142328844275525

Epoch: 6| Step: 6
Training loss: 0.29210153222084045
Validation loss: 1.738696813583374

Epoch: 6| Step: 7
Training loss: 0.31460437178611755
Validation loss: 1.792704504023316

Epoch: 6| Step: 8
Training loss: 0.5091729164123535
Validation loss: 1.791326181862944

Epoch: 6| Step: 9
Training loss: 0.7499905824661255
Validation loss: 1.7417062251798567

Epoch: 6| Step: 10
Training loss: 0.28898653388023376
Validation loss: 1.7777059565308273

Epoch: 6| Step: 11
Training loss: 0.4458979368209839
Validation loss: 1.8145201116479852

Epoch: 6| Step: 12
Training loss: 0.2853984236717224
Validation loss: 1.7926593275480374

Epoch: 6| Step: 13
Training loss: 0.33115777373313904
Validation loss: 1.7902667971067532

Epoch: 397| Step: 0
Training loss: 0.5313502550125122
Validation loss: 1.7808416479377336

Epoch: 6| Step: 1
Training loss: 0.3137119710445404
Validation loss: 1.7958305266595656

Epoch: 6| Step: 2
Training loss: 0.31286704540252686
Validation loss: 1.7865715693402033

Epoch: 6| Step: 3
Training loss: 0.38386473059654236
Validation loss: 1.7876525412323654

Epoch: 6| Step: 4
Training loss: 0.573379397392273
Validation loss: 1.7842579913395706

Epoch: 6| Step: 5
Training loss: 0.5993958115577698
Validation loss: 1.773466146120461

Epoch: 6| Step: 6
Training loss: 0.20331650972366333
Validation loss: 1.7390807854231967

Epoch: 6| Step: 7
Training loss: 0.37790971994400024
Validation loss: 1.7406884303656958

Epoch: 6| Step: 8
Training loss: 0.43312785029411316
Validation loss: 1.7298389122050295

Epoch: 6| Step: 9
Training loss: 0.4719236493110657
Validation loss: 1.7425108507115354

Epoch: 6| Step: 10
Training loss: 0.6311686038970947
Validation loss: 1.7260855808052966

Epoch: 6| Step: 11
Training loss: 0.40075427293777466
Validation loss: 1.7371876483322473

Epoch: 6| Step: 12
Training loss: 0.7374832034111023
Validation loss: 1.7477805255561747

Epoch: 6| Step: 13
Training loss: 0.35814645886421204
Validation loss: 1.7502626385740054

Epoch: 398| Step: 0
Training loss: 0.5061559081077576
Validation loss: 1.7946647533806421

Epoch: 6| Step: 1
Training loss: 0.6015739440917969
Validation loss: 1.7942724996997463

Epoch: 6| Step: 2
Training loss: 0.5737261772155762
Validation loss: 1.8140465380043111

Epoch: 6| Step: 3
Training loss: 0.4092470407485962
Validation loss: 1.8095490304372643

Epoch: 6| Step: 4
Training loss: 0.34191709756851196
Validation loss: 1.8172283544335315

Epoch: 6| Step: 5
Training loss: 0.4959288537502289
Validation loss: 1.8078997840163529

Epoch: 6| Step: 6
Training loss: 0.09433455765247345
Validation loss: 1.7889543220561037

Epoch: 6| Step: 7
Training loss: 0.37893936038017273
Validation loss: 1.7637290108588435

Epoch: 6| Step: 8
Training loss: 0.7198396921157837
Validation loss: 1.7213278893501527

Epoch: 6| Step: 9
Training loss: 0.3772844672203064
Validation loss: 1.6996258753602222

Epoch: 6| Step: 10
Training loss: 0.3802257776260376
Validation loss: 1.6853137247024044

Epoch: 6| Step: 11
Training loss: 0.41329821944236755
Validation loss: 1.6908274030172696

Epoch: 6| Step: 12
Training loss: 0.5230890512466431
Validation loss: 1.6716156826224378

Epoch: 6| Step: 13
Training loss: 0.5455858707427979
Validation loss: 1.713447759228368

Epoch: 399| Step: 0
Training loss: 0.4520910978317261
Validation loss: 1.716515359058175

Epoch: 6| Step: 1
Training loss: 0.4900484085083008
Validation loss: 1.7216167514042189

Epoch: 6| Step: 2
Training loss: 0.6276200413703918
Validation loss: 1.7477121071148944

Epoch: 6| Step: 3
Training loss: 0.26417791843414307
Validation loss: 1.742398928570491

Epoch: 6| Step: 4
Training loss: 0.6079014539718628
Validation loss: 1.7961458224122242

Epoch: 6| Step: 5
Training loss: 0.27701032161712646
Validation loss: 1.8143208680614349

Epoch: 6| Step: 6
Training loss: 0.2504540681838989
Validation loss: 1.8014242110713836

Epoch: 6| Step: 7
Training loss: 0.448002427816391
Validation loss: 1.7874779162868377

Epoch: 6| Step: 8
Training loss: 0.3686767816543579
Validation loss: 1.8348805622387958

Epoch: 6| Step: 9
Training loss: 0.17274457216262817
Validation loss: 1.8338578734346616

Epoch: 6| Step: 10
Training loss: 0.62486732006073
Validation loss: 1.8061739911315262

Epoch: 6| Step: 11
Training loss: 0.6554269790649414
Validation loss: 1.7987987943874892

Epoch: 6| Step: 12
Training loss: 0.3499723970890045
Validation loss: 1.7793045120854531

Epoch: 6| Step: 13
Training loss: 0.7099229097366333
Validation loss: 1.7972478379485428

Epoch: 400| Step: 0
Training loss: 0.5679420232772827
Validation loss: 1.7658772648021739

Epoch: 6| Step: 1
Training loss: 0.5744616389274597
Validation loss: 1.7350445383338517

Epoch: 6| Step: 2
Training loss: 0.5553207397460938
Validation loss: 1.7288889820857714

Epoch: 6| Step: 3
Training loss: 0.4369770586490631
Validation loss: 1.7494566286763837

Epoch: 6| Step: 4
Training loss: 0.31585395336151123
Validation loss: 1.7326790081557406

Epoch: 6| Step: 5
Training loss: 0.6154863834381104
Validation loss: 1.756530184899607

Epoch: 6| Step: 6
Training loss: 0.4652303457260132
Validation loss: 1.73201806699076

Epoch: 6| Step: 7
Training loss: 0.3060600757598877
Validation loss: 1.7549835456314908

Epoch: 6| Step: 8
Training loss: 0.4622269868850708
Validation loss: 1.7461307817889797

Epoch: 6| Step: 9
Training loss: 0.3019290566444397
Validation loss: 1.727078640332786

Epoch: 6| Step: 10
Training loss: 0.3871099054813385
Validation loss: 1.7301284074783325

Epoch: 6| Step: 11
Training loss: 0.6205379366874695
Validation loss: 1.747055676675612

Epoch: 6| Step: 12
Training loss: 0.2406553328037262
Validation loss: 1.819838067536713

Epoch: 6| Step: 13
Training loss: 0.3141169846057892
Validation loss: 1.848843236123362

Epoch: 401| Step: 0
Training loss: 0.5535058975219727
Validation loss: 1.7960225548795474

Epoch: 6| Step: 1
Training loss: 0.40731000900268555
Validation loss: 1.7781127729723532

Epoch: 6| Step: 2
Training loss: 0.2576141357421875
Validation loss: 1.769747995561169

Epoch: 6| Step: 3
Training loss: 0.2335616648197174
Validation loss: 1.7480794665633992

Epoch: 6| Step: 4
Training loss: 0.2727532684803009
Validation loss: 1.751149909470671

Epoch: 6| Step: 5
Training loss: 0.5142221450805664
Validation loss: 1.7298970658292052

Epoch: 6| Step: 6
Training loss: 0.5721925497055054
Validation loss: 1.7375114733173

Epoch: 6| Step: 7
Training loss: 0.7583659887313843
Validation loss: 1.7739987962989396

Epoch: 6| Step: 8
Training loss: 0.46546950936317444
Validation loss: 1.7691274201998146

Epoch: 6| Step: 9
Training loss: 0.20076201856136322
Validation loss: 1.766946409338264

Epoch: 6| Step: 10
Training loss: 0.39032673835754395
Validation loss: 1.7397594528813516

Epoch: 6| Step: 11
Training loss: 0.4372958540916443
Validation loss: 1.7625227346215198

Epoch: 6| Step: 12
Training loss: 0.4308544993400574
Validation loss: 1.7363891191379999

Epoch: 6| Step: 13
Training loss: 0.34109243750572205
Validation loss: 1.7253575453194239

Epoch: 402| Step: 0
Training loss: 0.3249949812889099
Validation loss: 1.7603252959507767

Epoch: 6| Step: 1
Training loss: 0.4040907621383667
Validation loss: 1.7728635931527743

Epoch: 6| Step: 2
Training loss: 0.574955940246582
Validation loss: 1.769379251746721

Epoch: 6| Step: 3
Training loss: 0.2612086832523346
Validation loss: 1.764332535446331

Epoch: 6| Step: 4
Training loss: 0.2633485198020935
Validation loss: 1.7482420590616041

Epoch: 6| Step: 5
Training loss: 0.31366097927093506
Validation loss: 1.7932746230915029

Epoch: 6| Step: 6
Training loss: 0.2852334976196289
Validation loss: 1.7548891395650885

Epoch: 6| Step: 7
Training loss: 0.6788065433502197
Validation loss: 1.7596018801453293

Epoch: 6| Step: 8
Training loss: 0.2958376407623291
Validation loss: 1.7521175184557516

Epoch: 6| Step: 9
Training loss: 0.3179995119571686
Validation loss: 1.753966616046044

Epoch: 6| Step: 10
Training loss: 0.6026505827903748
Validation loss: 1.7361051895285164

Epoch: 6| Step: 11
Training loss: 0.42791497707366943
Validation loss: 1.7417270419418172

Epoch: 6| Step: 12
Training loss: 0.4550594091415405
Validation loss: 1.7684428127863074

Epoch: 6| Step: 13
Training loss: 0.7092504501342773
Validation loss: 1.7456650785220567

Epoch: 403| Step: 0
Training loss: 0.43095535039901733
Validation loss: 1.7541989370058941

Epoch: 6| Step: 1
Training loss: 0.38396334648132324
Validation loss: 1.7427236931298369

Epoch: 6| Step: 2
Training loss: 0.40574246644973755
Validation loss: 1.752658644030171

Epoch: 6| Step: 3
Training loss: 0.6537780165672302
Validation loss: 1.7635028746820265

Epoch: 6| Step: 4
Training loss: 0.29903119802474976
Validation loss: 1.7408957583929903

Epoch: 6| Step: 5
Training loss: 0.4671744406223297
Validation loss: 1.7752445820839173

Epoch: 6| Step: 6
Training loss: 0.31057414412498474
Validation loss: 1.7488441621103594

Epoch: 6| Step: 7
Training loss: 0.288760244846344
Validation loss: 1.7830187313018306

Epoch: 6| Step: 8
Training loss: 0.19615118205547333
Validation loss: 1.7577874839946788

Epoch: 6| Step: 9
Training loss: 0.54972904920578
Validation loss: 1.732685637730424

Epoch: 6| Step: 10
Training loss: 0.46728086471557617
Validation loss: 1.6836771913754043

Epoch: 6| Step: 11
Training loss: 0.5596789121627808
Validation loss: 1.6874609480621994

Epoch: 6| Step: 12
Training loss: 0.5601423978805542
Validation loss: 1.7006054078378985

Epoch: 6| Step: 13
Training loss: 0.5331240892410278
Validation loss: 1.72927902847208

Epoch: 404| Step: 0
Training loss: 0.2020806223154068
Validation loss: 1.7349902314524497

Epoch: 6| Step: 1
Training loss: 0.32437199354171753
Validation loss: 1.7536657138537335

Epoch: 6| Step: 2
Training loss: 0.6396042108535767
Validation loss: 1.7856309913819837

Epoch: 6| Step: 3
Training loss: 0.3189602494239807
Validation loss: 1.8245008581428117

Epoch: 6| Step: 4
Training loss: 0.28041526675224304
Validation loss: 1.8325351156214231

Epoch: 6| Step: 5
Training loss: 0.5616658926010132
Validation loss: 1.7894838087020382

Epoch: 6| Step: 6
Training loss: 0.20039668679237366
Validation loss: 1.8066668151527323

Epoch: 6| Step: 7
Training loss: 0.36667102575302124
Validation loss: 1.7887769117150256

Epoch: 6| Step: 8
Training loss: 0.3999853730201721
Validation loss: 1.7619170514486169

Epoch: 6| Step: 9
Training loss: 0.8091235160827637
Validation loss: 1.745839931631601

Epoch: 6| Step: 10
Training loss: 0.7036794424057007
Validation loss: 1.7415595746809436

Epoch: 6| Step: 11
Training loss: 0.38788631558418274
Validation loss: 1.7298220421678276

Epoch: 6| Step: 12
Training loss: 0.46328747272491455
Validation loss: 1.7208053219702937

Epoch: 6| Step: 13
Training loss: 0.2761736810207367
Validation loss: 1.7568715592866302

Epoch: 405| Step: 0
Training loss: 0.6246405839920044
Validation loss: 1.7609119428101407

Epoch: 6| Step: 1
Training loss: 0.3239125609397888
Validation loss: 1.806204918892153

Epoch: 6| Step: 2
Training loss: 0.4792414903640747
Validation loss: 1.826982746842087

Epoch: 6| Step: 3
Training loss: 0.2511976361274719
Validation loss: 1.8236587406486593

Epoch: 6| Step: 4
Training loss: 0.5022498369216919
Validation loss: 1.7785115491959356

Epoch: 6| Step: 5
Training loss: 0.5164163112640381
Validation loss: 1.745232500055785

Epoch: 6| Step: 6
Training loss: 0.2745545208454132
Validation loss: 1.7620367593662714

Epoch: 6| Step: 7
Training loss: 0.4015316963195801
Validation loss: 1.7678913916310957

Epoch: 6| Step: 8
Training loss: 0.6352275609970093
Validation loss: 1.7750548931860155

Epoch: 6| Step: 9
Training loss: 0.21383064985275269
Validation loss: 1.8075368750479914

Epoch: 6| Step: 10
Training loss: 0.3343372941017151
Validation loss: 1.7885425026698778

Epoch: 6| Step: 11
Training loss: 0.5122878551483154
Validation loss: 1.8063156950858332

Epoch: 6| Step: 12
Training loss: 0.35264214873313904
Validation loss: 1.8009698506324523

Epoch: 6| Step: 13
Training loss: 0.6689796447753906
Validation loss: 1.8159085883889148

Epoch: 406| Step: 0
Training loss: 0.37656885385513306
Validation loss: 1.8180374086544078

Epoch: 6| Step: 1
Training loss: 0.3588981032371521
Validation loss: 1.800129767387144

Epoch: 6| Step: 2
Training loss: 0.4286147654056549
Validation loss: 1.75978845806532

Epoch: 6| Step: 3
Training loss: 0.5107518434524536
Validation loss: 1.7322447838321808

Epoch: 6| Step: 4
Training loss: 0.5677154660224915
Validation loss: 1.7630256811777751

Epoch: 6| Step: 5
Training loss: 0.24794019758701324
Validation loss: 1.7543418356167373

Epoch: 6| Step: 6
Training loss: 0.5792992115020752
Validation loss: 1.7311929707886071

Epoch: 6| Step: 7
Training loss: 0.4251946210861206
Validation loss: 1.7262901388188845

Epoch: 6| Step: 8
Training loss: 0.3011314868927002
Validation loss: 1.7494744934061521

Epoch: 6| Step: 9
Training loss: 0.3571344017982483
Validation loss: 1.7032028346933343

Epoch: 6| Step: 10
Training loss: 0.5864308476448059
Validation loss: 1.7278915156600296

Epoch: 6| Step: 11
Training loss: 0.32797855138778687
Validation loss: 1.7355047041370022

Epoch: 6| Step: 12
Training loss: 0.4585077166557312
Validation loss: 1.735974806611256

Epoch: 6| Step: 13
Training loss: 0.46953466534614563
Validation loss: 1.7443795992482094

Epoch: 407| Step: 0
Training loss: 0.62352454662323
Validation loss: 1.7714935656516784

Epoch: 6| Step: 1
Training loss: 0.3662444055080414
Validation loss: 1.7806744601136895

Epoch: 6| Step: 2
Training loss: 0.413358598947525
Validation loss: 1.773154426646489

Epoch: 6| Step: 3
Training loss: 0.34180113673210144
Validation loss: 1.765208310978387

Epoch: 6| Step: 4
Training loss: 0.3528715670108795
Validation loss: 1.7743329360920896

Epoch: 6| Step: 5
Training loss: 0.42058587074279785
Validation loss: 1.7343319564737298

Epoch: 6| Step: 6
Training loss: 0.5821528434753418
Validation loss: 1.7421214247262606

Epoch: 6| Step: 7
Training loss: 0.6533675789833069
Validation loss: 1.7491850852966309

Epoch: 6| Step: 8
Training loss: 0.3920878767967224
Validation loss: 1.7371995346520537

Epoch: 6| Step: 9
Training loss: 0.5541165471076965
Validation loss: 1.7679853849513556

Epoch: 6| Step: 10
Training loss: 0.35846805572509766
Validation loss: 1.7828188711597073

Epoch: 6| Step: 11
Training loss: 0.3507685959339142
Validation loss: 1.7872981332963513

Epoch: 6| Step: 12
Training loss: 0.3145357668399811
Validation loss: 1.7754420926493983

Epoch: 6| Step: 13
Training loss: 0.113789863884449
Validation loss: 1.7461631951793548

Epoch: 408| Step: 0
Training loss: 0.1909787356853485
Validation loss: 1.7074361706292758

Epoch: 6| Step: 1
Training loss: 0.5817497372627258
Validation loss: 1.695246046589267

Epoch: 6| Step: 2
Training loss: 0.5381531715393066
Validation loss: 1.690365736202527

Epoch: 6| Step: 3
Training loss: 0.27246731519699097
Validation loss: 1.743309014586992

Epoch: 6| Step: 4
Training loss: 0.2658883333206177
Validation loss: 1.7196617203374063

Epoch: 6| Step: 5
Training loss: 0.5678818225860596
Validation loss: 1.7182383370655838

Epoch: 6| Step: 6
Training loss: 0.32870981097221375
Validation loss: 1.7191926010193364

Epoch: 6| Step: 7
Training loss: 0.6046512722969055
Validation loss: 1.7377360828461186

Epoch: 6| Step: 8
Training loss: 0.474695086479187
Validation loss: 1.7610692875359648

Epoch: 6| Step: 9
Training loss: 0.3253212571144104
Validation loss: 1.7848057362341112

Epoch: 6| Step: 10
Training loss: 0.5271958112716675
Validation loss: 1.7952183279939877

Epoch: 6| Step: 11
Training loss: 0.13240787386894226
Validation loss: 1.786885505081505

Epoch: 6| Step: 12
Training loss: 0.5122324824333191
Validation loss: 1.786757153849448

Epoch: 6| Step: 13
Training loss: 0.5069004893302917
Validation loss: 1.7513314447095316

Epoch: 409| Step: 0
Training loss: 0.5412615537643433
Validation loss: 1.7475363964675574

Epoch: 6| Step: 1
Training loss: 0.4102529287338257
Validation loss: 1.771883910702121

Epoch: 6| Step: 2
Training loss: 0.3014371693134308
Validation loss: 1.7812810456880959

Epoch: 6| Step: 3
Training loss: 0.5133259296417236
Validation loss: 1.7434634995716873

Epoch: 6| Step: 4
Training loss: 0.4156661331653595
Validation loss: 1.7550493389047601

Epoch: 6| Step: 5
Training loss: 0.4663957953453064
Validation loss: 1.7236435823543097

Epoch: 6| Step: 6
Training loss: 0.27974069118499756
Validation loss: 1.7210744119459582

Epoch: 6| Step: 7
Training loss: 0.4392317235469818
Validation loss: 1.7020842727794443

Epoch: 6| Step: 8
Training loss: 0.33521318435668945
Validation loss: 1.7637553490618223

Epoch: 6| Step: 9
Training loss: 0.3861638605594635
Validation loss: 1.7484916628047984

Epoch: 6| Step: 10
Training loss: 0.3429734408855438
Validation loss: 1.7461170534933768

Epoch: 6| Step: 11
Training loss: 0.3596954941749573
Validation loss: 1.720306110638444

Epoch: 6| Step: 12
Training loss: 0.5258190035820007
Validation loss: 1.772942163610971

Epoch: 6| Step: 13
Training loss: 0.0986514687538147
Validation loss: 1.7855324181177283

Epoch: 410| Step: 0
Training loss: 0.4401002526283264
Validation loss: 1.8115145032123854

Epoch: 6| Step: 1
Training loss: 0.49472761154174805
Validation loss: 1.8297198228938605

Epoch: 6| Step: 2
Training loss: 0.25806766748428345
Validation loss: 1.7672745245759205

Epoch: 6| Step: 3
Training loss: 0.517529308795929
Validation loss: 1.7688374211711269

Epoch: 6| Step: 4
Training loss: 0.3632580041885376
Validation loss: 1.7455651478100849

Epoch: 6| Step: 5
Training loss: 0.4289126992225647
Validation loss: 1.748404356741136

Epoch: 6| Step: 6
Training loss: 0.4967733919620514
Validation loss: 1.7316229087050243

Epoch: 6| Step: 7
Training loss: 0.2776484787464142
Validation loss: 1.7597646559438398

Epoch: 6| Step: 8
Training loss: 0.37369269132614136
Validation loss: 1.7548401330107002

Epoch: 6| Step: 9
Training loss: 0.4336680769920349
Validation loss: 1.7800883099596987

Epoch: 6| Step: 10
Training loss: 0.3526991605758667
Validation loss: 1.780559721813407

Epoch: 6| Step: 11
Training loss: 0.43343108892440796
Validation loss: 1.752031321166664

Epoch: 6| Step: 12
Training loss: 0.3871545195579529
Validation loss: 1.7518468185137677

Epoch: 6| Step: 13
Training loss: 0.4091693162918091
Validation loss: 1.7233857941883866

Epoch: 411| Step: 0
Training loss: 0.4399193823337555
Validation loss: 1.6982031022348711

Epoch: 6| Step: 1
Training loss: 0.5571492910385132
Validation loss: 1.6862040617132699

Epoch: 6| Step: 2
Training loss: 0.3065403401851654
Validation loss: 1.6948940471936298

Epoch: 6| Step: 3
Training loss: 0.2918204963207245
Validation loss: 1.71082821712699

Epoch: 6| Step: 4
Training loss: 0.2993658781051636
Validation loss: 1.716119271452709

Epoch: 6| Step: 5
Training loss: 0.49170929193496704
Validation loss: 1.7274924144949964

Epoch: 6| Step: 6
Training loss: 0.49131080508232117
Validation loss: 1.7384070427187028

Epoch: 6| Step: 7
Training loss: 0.37619146704673767
Validation loss: 1.8009861335959485

Epoch: 6| Step: 8
Training loss: 0.2483358383178711
Validation loss: 1.7490976138781476

Epoch: 6| Step: 9
Training loss: 0.5297941565513611
Validation loss: 1.7506850842506654

Epoch: 6| Step: 10
Training loss: 0.47251078486442566
Validation loss: 1.743273127463556

Epoch: 6| Step: 11
Training loss: 0.6024171113967896
Validation loss: 1.6707910209573724

Epoch: 6| Step: 12
Training loss: 0.28890085220336914
Validation loss: 1.6812227592673352

Epoch: 6| Step: 13
Training loss: 0.418658971786499
Validation loss: 1.6820832875467115

Epoch: 412| Step: 0
Training loss: 0.4950180649757385
Validation loss: 1.729437917791387

Epoch: 6| Step: 1
Training loss: 0.5609906911849976
Validation loss: 1.7603156335892216

Epoch: 6| Step: 2
Training loss: 0.22126299142837524
Validation loss: 1.7559510264345395

Epoch: 6| Step: 3
Training loss: 0.3718155026435852
Validation loss: 1.7294144399704472

Epoch: 6| Step: 4
Training loss: 0.2777771055698395
Validation loss: 1.772522000856297

Epoch: 6| Step: 5
Training loss: 0.48864057660102844
Validation loss: 1.764566731709306

Epoch: 6| Step: 6
Training loss: 0.45900940895080566
Validation loss: 1.7407535442741968

Epoch: 6| Step: 7
Training loss: 0.35469022393226624
Validation loss: 1.7157116833553518

Epoch: 6| Step: 8
Training loss: 0.6980884671211243
Validation loss: 1.7103213783233397

Epoch: 6| Step: 9
Training loss: 0.4003368616104126
Validation loss: 1.7132724882454

Epoch: 6| Step: 10
Training loss: 0.23677374422550201
Validation loss: 1.7026074496648644

Epoch: 6| Step: 11
Training loss: 0.45169055461883545
Validation loss: 1.720230233284735

Epoch: 6| Step: 12
Training loss: 0.14006146788597107
Validation loss: 1.7123309104673323

Epoch: 6| Step: 13
Training loss: 0.26406288146972656
Validation loss: 1.730200513716667

Epoch: 413| Step: 0
Training loss: 0.3460093140602112
Validation loss: 1.700099334921888

Epoch: 6| Step: 1
Training loss: 0.49701038002967834
Validation loss: 1.7218953896594305

Epoch: 6| Step: 2
Training loss: 0.25088703632354736
Validation loss: 1.7013344136617516

Epoch: 6| Step: 3
Training loss: 0.4088027775287628
Validation loss: 1.7201088141369563

Epoch: 6| Step: 4
Training loss: 0.2902098298072815
Validation loss: 1.7646504602124613

Epoch: 6| Step: 5
Training loss: 0.5926960706710815
Validation loss: 1.8171950335143714

Epoch: 6| Step: 6
Training loss: 0.19965943694114685
Validation loss: 1.80242544733068

Epoch: 6| Step: 7
Training loss: 0.5725939273834229
Validation loss: 1.7636063227089502

Epoch: 6| Step: 8
Training loss: 0.3702947497367859
Validation loss: 1.7329407763737503

Epoch: 6| Step: 9
Training loss: 0.5871172547340393
Validation loss: 1.6767050809757684

Epoch: 6| Step: 10
Training loss: 0.16917306184768677
Validation loss: 1.6360545222477247

Epoch: 6| Step: 11
Training loss: 0.5216873288154602
Validation loss: 1.6446521718014953

Epoch: 6| Step: 12
Training loss: 0.4280633330345154
Validation loss: 1.659457907881788

Epoch: 6| Step: 13
Training loss: 0.4581514596939087
Validation loss: 1.6599388250740625

Epoch: 414| Step: 0
Training loss: 0.3799126148223877
Validation loss: 1.6736131739872757

Epoch: 6| Step: 1
Training loss: 0.45633664727211
Validation loss: 1.6505766043099024

Epoch: 6| Step: 2
Training loss: 0.43048951029777527
Validation loss: 1.6947500680082588

Epoch: 6| Step: 3
Training loss: 0.19658619165420532
Validation loss: 1.6845627779601722

Epoch: 6| Step: 4
Training loss: 0.47543099522590637
Validation loss: 1.6854586524348105

Epoch: 6| Step: 5
Training loss: 0.3451981544494629
Validation loss: 1.7670254092062674

Epoch: 6| Step: 6
Training loss: 0.48018577694892883
Validation loss: 1.8098325242278397

Epoch: 6| Step: 7
Training loss: 0.5336061716079712
Validation loss: 1.854572401251844

Epoch: 6| Step: 8
Training loss: 0.48481255769729614
Validation loss: 1.8847847330954768

Epoch: 6| Step: 9
Training loss: 0.40313929319381714
Validation loss: 1.8746325815877607

Epoch: 6| Step: 10
Training loss: 0.2518143355846405
Validation loss: 1.8204745874609998

Epoch: 6| Step: 11
Training loss: 0.36963093280792236
Validation loss: 1.7754866256508777

Epoch: 6| Step: 12
Training loss: 0.5937731862068176
Validation loss: 1.7065395168078843

Epoch: 6| Step: 13
Training loss: 0.616447389125824
Validation loss: 1.7349697107909827

Epoch: 415| Step: 0
Training loss: 0.3251130282878876
Validation loss: 1.6940053509127708

Epoch: 6| Step: 1
Training loss: 0.2691550850868225
Validation loss: 1.6862546910521805

Epoch: 6| Step: 2
Training loss: 0.22521895170211792
Validation loss: 1.6623930764454666

Epoch: 6| Step: 3
Training loss: 0.3491482734680176
Validation loss: 1.678046868693444

Epoch: 6| Step: 4
Training loss: 0.3345167636871338
Validation loss: 1.699923453792449

Epoch: 6| Step: 5
Training loss: 0.24833355844020844
Validation loss: 1.7076839144511888

Epoch: 6| Step: 6
Training loss: 0.5991167426109314
Validation loss: 1.7361732657237718

Epoch: 6| Step: 7
Training loss: 0.5662660002708435
Validation loss: 1.7432355650009648

Epoch: 6| Step: 8
Training loss: 0.3011530935764313
Validation loss: 1.741400816107309

Epoch: 6| Step: 9
Training loss: 0.31009507179260254
Validation loss: 1.7196286057913175

Epoch: 6| Step: 10
Training loss: 0.6261594295501709
Validation loss: 1.7348705568621237

Epoch: 6| Step: 11
Training loss: 0.5459872484207153
Validation loss: 1.7713948065234768

Epoch: 6| Step: 12
Training loss: 0.43927881121635437
Validation loss: 1.796638718215368

Epoch: 6| Step: 13
Training loss: 0.5125210285186768
Validation loss: 1.8022678000952608

Epoch: 416| Step: 0
Training loss: 0.3856978416442871
Validation loss: 1.7723281665514874

Epoch: 6| Step: 1
Training loss: 0.4976838529109955
Validation loss: 1.7556796740460139

Epoch: 6| Step: 2
Training loss: 0.5519317984580994
Validation loss: 1.7502428434228385

Epoch: 6| Step: 3
Training loss: 0.6756753325462341
Validation loss: 1.731915968720631

Epoch: 6| Step: 4
Training loss: 0.24367675185203552
Validation loss: 1.688476066435537

Epoch: 6| Step: 5
Training loss: 0.35885846614837646
Validation loss: 1.7112677007593133

Epoch: 6| Step: 6
Training loss: 0.3816005289554596
Validation loss: 1.7002988797362133

Epoch: 6| Step: 7
Training loss: 0.21557113528251648
Validation loss: 1.7506603066639235

Epoch: 6| Step: 8
Training loss: 0.3333802819252014
Validation loss: 1.7483991346051615

Epoch: 6| Step: 9
Training loss: 0.2512193024158478
Validation loss: 1.7989732629509383

Epoch: 6| Step: 10
Training loss: 0.6191504001617432
Validation loss: 1.8163472080743441

Epoch: 6| Step: 11
Training loss: 0.5184051990509033
Validation loss: 1.8807681350297825

Epoch: 6| Step: 12
Training loss: 0.373216450214386
Validation loss: 1.879245319674092

Epoch: 6| Step: 13
Training loss: 0.5806321501731873
Validation loss: 1.8692827660550353

Epoch: 417| Step: 0
Training loss: 0.4749263823032379
Validation loss: 1.87718032252404

Epoch: 6| Step: 1
Training loss: 0.20023323595523834
Validation loss: 1.8225950848671697

Epoch: 6| Step: 2
Training loss: 0.26497989892959595
Validation loss: 1.7503558743384577

Epoch: 6| Step: 3
Training loss: 0.377338171005249
Validation loss: 1.6936498534294866

Epoch: 6| Step: 4
Training loss: 0.4741429090499878
Validation loss: 1.6653650883705384

Epoch: 6| Step: 5
Training loss: 0.35929685831069946
Validation loss: 1.6553849494585426

Epoch: 6| Step: 6
Training loss: 0.4354560077190399
Validation loss: 1.6465647528248448

Epoch: 6| Step: 7
Training loss: 0.5278400182723999
Validation loss: 1.644020990658832

Epoch: 6| Step: 8
Training loss: 0.6882795095443726
Validation loss: 1.6615727524603567

Epoch: 6| Step: 9
Training loss: 0.3461993634700775
Validation loss: 1.7017252599039385

Epoch: 6| Step: 10
Training loss: 0.22942176461219788
Validation loss: 1.7410390300135459

Epoch: 6| Step: 11
Training loss: 0.549142062664032
Validation loss: 1.7149141424445695

Epoch: 6| Step: 12
Training loss: 0.5497881770133972
Validation loss: 1.7223345848821825

Epoch: 6| Step: 13
Training loss: 0.2790752351284027
Validation loss: 1.7573310611068562

Epoch: 418| Step: 0
Training loss: 0.5233292579650879
Validation loss: 1.759524312070621

Epoch: 6| Step: 1
Training loss: 0.2557176351547241
Validation loss: 1.7753741292543308

Epoch: 6| Step: 2
Training loss: 0.28494423627853394
Validation loss: 1.7648137769391459

Epoch: 6| Step: 3
Training loss: 0.46351879835128784
Validation loss: 1.759848420337964

Epoch: 6| Step: 4
Training loss: 0.4763823449611664
Validation loss: 1.7559500304601525

Epoch: 6| Step: 5
Training loss: 0.322853147983551
Validation loss: 1.7563551677170621

Epoch: 6| Step: 6
Training loss: 0.3206360638141632
Validation loss: 1.7906771821360434

Epoch: 6| Step: 7
Training loss: 0.3192339241504669
Validation loss: 1.7831432383547547

Epoch: 6| Step: 8
Training loss: 0.35954564809799194
Validation loss: 1.792408320211595

Epoch: 6| Step: 9
Training loss: 0.2991258502006531
Validation loss: 1.7691307196053125

Epoch: 6| Step: 10
Training loss: 0.37433934211730957
Validation loss: 1.7520512278361986

Epoch: 6| Step: 11
Training loss: 0.5641347765922546
Validation loss: 1.7400570069589922

Epoch: 6| Step: 12
Training loss: 0.5672352910041809
Validation loss: 1.720172869261875

Epoch: 6| Step: 13
Training loss: 0.3932760953903198
Validation loss: 1.7286748347743865

Epoch: 419| Step: 0
Training loss: 0.2979222536087036
Validation loss: 1.696421201511096

Epoch: 6| Step: 1
Training loss: 0.22477906942367554
Validation loss: 1.697680470763996

Epoch: 6| Step: 2
Training loss: 0.5165563821792603
Validation loss: 1.7166872229627383

Epoch: 6| Step: 3
Training loss: 0.3526344299316406
Validation loss: 1.719567637289724

Epoch: 6| Step: 4
Training loss: 0.43850165605545044
Validation loss: 1.7348596883076493

Epoch: 6| Step: 5
Training loss: 0.4834367632865906
Validation loss: 1.7594782101210726

Epoch: 6| Step: 6
Training loss: 0.49099308252334595
Validation loss: 1.7574439305131153

Epoch: 6| Step: 7
Training loss: 0.3051856756210327
Validation loss: 1.7257788694033058

Epoch: 6| Step: 8
Training loss: 0.4166192412376404
Validation loss: 1.693600541801863

Epoch: 6| Step: 9
Training loss: 0.36691367626190186
Validation loss: 1.7073225205944431

Epoch: 6| Step: 10
Training loss: 0.21896123886108398
Validation loss: 1.7252552278580204

Epoch: 6| Step: 11
Training loss: 0.48408111929893494
Validation loss: 1.7779986627640263

Epoch: 6| Step: 12
Training loss: 0.596360445022583
Validation loss: 1.7813768476568244

Epoch: 6| Step: 13
Training loss: 0.4815901219844818
Validation loss: 1.792142137404411

Epoch: 420| Step: 0
Training loss: 0.4127005338668823
Validation loss: 1.8133418790755733

Epoch: 6| Step: 1
Training loss: 0.2921069860458374
Validation loss: 1.835114235519081

Epoch: 6| Step: 2
Training loss: 0.44713571667671204
Validation loss: 1.7890563049624044

Epoch: 6| Step: 3
Training loss: 0.42860499024391174
Validation loss: 1.7274647041033673

Epoch: 6| Step: 4
Training loss: 0.3958396911621094
Validation loss: 1.753516210022793

Epoch: 6| Step: 5
Training loss: 0.4006492793560028
Validation loss: 1.7237434553843674

Epoch: 6| Step: 6
Training loss: 0.373691201210022
Validation loss: 1.7064809440284647

Epoch: 6| Step: 7
Training loss: 0.5965949296951294
Validation loss: 1.7205909349585091

Epoch: 6| Step: 8
Training loss: 0.5264312624931335
Validation loss: 1.6947469070393553

Epoch: 6| Step: 9
Training loss: 0.3760669231414795
Validation loss: 1.7066232812020086

Epoch: 6| Step: 10
Training loss: 0.3255033493041992
Validation loss: 1.7281745531225716

Epoch: 6| Step: 11
Training loss: 0.35517942905426025
Validation loss: 1.6923709595075218

Epoch: 6| Step: 12
Training loss: 0.2582033574581146
Validation loss: 1.6815438103932205

Epoch: 6| Step: 13
Training loss: 0.27827224135398865
Validation loss: 1.675797858545857

Epoch: 421| Step: 0
Training loss: 0.28388988971710205
Validation loss: 1.687508088286205

Epoch: 6| Step: 1
Training loss: 0.49663394689559937
Validation loss: 1.6581557514846965

Epoch: 6| Step: 2
Training loss: 0.6535986661911011
Validation loss: 1.711794255882181

Epoch: 6| Step: 3
Training loss: 0.3256494998931885
Validation loss: 1.7401162296213128

Epoch: 6| Step: 4
Training loss: 0.319631427526474
Validation loss: 1.752174364623203

Epoch: 6| Step: 5
Training loss: 0.21847161650657654
Validation loss: 1.844913185283702

Epoch: 6| Step: 6
Training loss: 0.5456514954566956
Validation loss: 1.8299009364138368

Epoch: 6| Step: 7
Training loss: 0.28916388750076294
Validation loss: 1.829119146511119

Epoch: 6| Step: 8
Training loss: 0.4710328280925751
Validation loss: 1.8147830796498123

Epoch: 6| Step: 9
Training loss: 0.5153241753578186
Validation loss: 1.7541690590561076

Epoch: 6| Step: 10
Training loss: 0.4123360514640808
Validation loss: 1.7279157074548865

Epoch: 6| Step: 11
Training loss: 0.24770107865333557
Validation loss: 1.722476319600177

Epoch: 6| Step: 12
Training loss: 0.1727966070175171
Validation loss: 1.6898206459578646

Epoch: 6| Step: 13
Training loss: 0.40400540828704834
Validation loss: 1.6548192815114093

Epoch: 422| Step: 0
Training loss: 0.2854618728160858
Validation loss: 1.7081557191828245

Epoch: 6| Step: 1
Training loss: 0.5541031360626221
Validation loss: 1.7128755161839146

Epoch: 6| Step: 2
Training loss: 0.3257044553756714
Validation loss: 1.6965391161621257

Epoch: 6| Step: 3
Training loss: 0.519987165927887
Validation loss: 1.7300789343413485

Epoch: 6| Step: 4
Training loss: 0.2622239589691162
Validation loss: 1.76844863225055

Epoch: 6| Step: 5
Training loss: 0.4007446765899658
Validation loss: 1.7419037498453611

Epoch: 6| Step: 6
Training loss: 0.29955214262008667
Validation loss: 1.7467470502340665

Epoch: 6| Step: 7
Training loss: 0.43985944986343384
Validation loss: 1.7249654140523685

Epoch: 6| Step: 8
Training loss: 0.35340335965156555
Validation loss: 1.661533099348827

Epoch: 6| Step: 9
Training loss: 0.3571186661720276
Validation loss: 1.6478228543394355

Epoch: 6| Step: 10
Training loss: 0.47446408867836
Validation loss: 1.663285473341583

Epoch: 6| Step: 11
Training loss: 0.41688817739486694
Validation loss: 1.6562040595598118

Epoch: 6| Step: 12
Training loss: 0.32887256145477295
Validation loss: 1.6930688959296032

Epoch: 6| Step: 13
Training loss: 0.3391885459423065
Validation loss: 1.7103088876252532

Epoch: 423| Step: 0
Training loss: 0.3887946605682373
Validation loss: 1.7526607346791092

Epoch: 6| Step: 1
Training loss: 0.3532700538635254
Validation loss: 1.773610745706866

Epoch: 6| Step: 2
Training loss: 0.3656863272190094
Validation loss: 1.79413087906376

Epoch: 6| Step: 3
Training loss: 0.22451575100421906
Validation loss: 1.7958259800428986

Epoch: 6| Step: 4
Training loss: 0.32382795214653015
Validation loss: 1.7608105264684206

Epoch: 6| Step: 5
Training loss: 0.2890145778656006
Validation loss: 1.7457148977505264

Epoch: 6| Step: 6
Training loss: 0.3286020755767822
Validation loss: 1.73399684890624

Epoch: 6| Step: 7
Training loss: 0.3536800742149353
Validation loss: 1.724072346123316

Epoch: 6| Step: 8
Training loss: 0.42040860652923584
Validation loss: 1.7181125738287484

Epoch: 6| Step: 9
Training loss: 0.3831266760826111
Validation loss: 1.7267188384968748

Epoch: 6| Step: 10
Training loss: 0.3642710745334625
Validation loss: 1.6892045646585443

Epoch: 6| Step: 11
Training loss: 0.5926717519760132
Validation loss: 1.701685582437823

Epoch: 6| Step: 12
Training loss: 0.26145005226135254
Validation loss: 1.6967849705808906

Epoch: 6| Step: 13
Training loss: 0.47094884514808655
Validation loss: 1.7316894108249294

Epoch: 424| Step: 0
Training loss: 0.5082210302352905
Validation loss: 1.7324573609136766

Epoch: 6| Step: 1
Training loss: 0.4601537883281708
Validation loss: 1.7013705468946887

Epoch: 6| Step: 2
Training loss: 0.4955165386199951
Validation loss: 1.7126061365168581

Epoch: 6| Step: 3
Training loss: 0.3059690296649933
Validation loss: 1.6678355752780873

Epoch: 6| Step: 4
Training loss: 0.48954543471336365
Validation loss: 1.6472012560854676

Epoch: 6| Step: 5
Training loss: 0.281588613986969
Validation loss: 1.673171845815515

Epoch: 6| Step: 6
Training loss: 0.2914808690547943
Validation loss: 1.6925073092983616

Epoch: 6| Step: 7
Training loss: 0.4338361620903015
Validation loss: 1.7056953817285516

Epoch: 6| Step: 8
Training loss: 0.38142403960227966
Validation loss: 1.6971767730610345

Epoch: 6| Step: 9
Training loss: 0.3341551423072815
Validation loss: 1.6854103688270814

Epoch: 6| Step: 10
Training loss: 0.28869011998176575
Validation loss: 1.7046622768525155

Epoch: 6| Step: 11
Training loss: 0.32633405923843384
Validation loss: 1.6946829724055466

Epoch: 6| Step: 12
Training loss: 0.2986130118370056
Validation loss: 1.7153724008990872

Epoch: 6| Step: 13
Training loss: 0.17529459297657013
Validation loss: 1.766740478495116

Epoch: 425| Step: 0
Training loss: 0.3183421492576599
Validation loss: 1.7837267575725433

Epoch: 6| Step: 1
Training loss: 0.36825332045555115
Validation loss: 1.8352398526284002

Epoch: 6| Step: 2
Training loss: 0.4318866431713104
Validation loss: 1.8189934530565817

Epoch: 6| Step: 3
Training loss: 0.18075701594352722
Validation loss: 1.753909872424218

Epoch: 6| Step: 4
Training loss: 0.32925716042518616
Validation loss: 1.7546338176214566

Epoch: 6| Step: 5
Training loss: 0.6467561721801758
Validation loss: 1.683916252146485

Epoch: 6| Step: 6
Training loss: 0.21169859170913696
Validation loss: 1.6821780589319044

Epoch: 6| Step: 7
Training loss: 0.500810980796814
Validation loss: 1.675840344480289

Epoch: 6| Step: 8
Training loss: 0.36816030740737915
Validation loss: 1.6567196192279938

Epoch: 6| Step: 9
Training loss: 0.45751845836639404
Validation loss: 1.6532247938135618

Epoch: 6| Step: 10
Training loss: 0.35246697068214417
Validation loss: 1.6979035344175113

Epoch: 6| Step: 11
Training loss: 0.5340895652770996
Validation loss: 1.7115699527084187

Epoch: 6| Step: 12
Training loss: 0.3440815210342407
Validation loss: 1.7478355643569783

Epoch: 6| Step: 13
Training loss: 0.1798362135887146
Validation loss: 1.7910424663174538

Epoch: 426| Step: 0
Training loss: 0.3276703357696533
Validation loss: 1.7976582498960598

Epoch: 6| Step: 1
Training loss: 0.48500120639801025
Validation loss: 1.8357751882204445

Epoch: 6| Step: 2
Training loss: 0.33288025856018066
Validation loss: 1.8518086530828988

Epoch: 6| Step: 3
Training loss: 0.4778576195240021
Validation loss: 1.8390114922677316

Epoch: 6| Step: 4
Training loss: 0.49886542558670044
Validation loss: 1.8175209491483626

Epoch: 6| Step: 5
Training loss: 0.47142916917800903
Validation loss: 1.759822799313453

Epoch: 6| Step: 6
Training loss: 0.2674131989479065
Validation loss: 1.6808935044914164

Epoch: 6| Step: 7
Training loss: 0.2594977021217346
Validation loss: 1.7063407449312107

Epoch: 6| Step: 8
Training loss: 0.5393799543380737
Validation loss: 1.6854160780547767

Epoch: 6| Step: 9
Training loss: 0.17645606398582458
Validation loss: 1.7028454542160034

Epoch: 6| Step: 10
Training loss: 0.3098412752151489
Validation loss: 1.696044901365875

Epoch: 6| Step: 11
Training loss: 0.2628438472747803
Validation loss: 1.710160723937455

Epoch: 6| Step: 12
Training loss: 0.3855246901512146
Validation loss: 1.7108324484158588

Epoch: 6| Step: 13
Training loss: 0.45230185985565186
Validation loss: 1.725941668274582

Epoch: 427| Step: 0
Training loss: 0.4353877604007721
Validation loss: 1.7574954532807874

Epoch: 6| Step: 1
Training loss: 0.5746107697486877
Validation loss: 1.7449000356017903

Epoch: 6| Step: 2
Training loss: 0.3580366373062134
Validation loss: 1.7547899753816667

Epoch: 6| Step: 3
Training loss: 0.3507210314273834
Validation loss: 1.7651568176925823

Epoch: 6| Step: 4
Training loss: 0.3604242205619812
Validation loss: 1.7560204331592848

Epoch: 6| Step: 5
Training loss: 0.46516674757003784
Validation loss: 1.727110210285392

Epoch: 6| Step: 6
Training loss: 0.40756136178970337
Validation loss: 1.7419868130837717

Epoch: 6| Step: 7
Training loss: 0.2236936092376709
Validation loss: 1.756332383360914

Epoch: 6| Step: 8
Training loss: 0.3141835331916809
Validation loss: 1.7268756461399857

Epoch: 6| Step: 9
Training loss: 0.3282302916049957
Validation loss: 1.7174915382939

Epoch: 6| Step: 10
Training loss: 0.13590332865715027
Validation loss: 1.7181916884196702

Epoch: 6| Step: 11
Training loss: 0.4608583152294159
Validation loss: 1.7068324947869906

Epoch: 6| Step: 12
Training loss: 0.3202483057975769
Validation loss: 1.7336271732084212

Epoch: 6| Step: 13
Training loss: 0.12808561325073242
Validation loss: 1.7753588384197605

Epoch: 428| Step: 0
Training loss: 0.17234297096729279
Validation loss: 1.8100704582788611

Epoch: 6| Step: 1
Training loss: 0.4981260299682617
Validation loss: 1.8155617201200096

Epoch: 6| Step: 2
Training loss: 0.5193681716918945
Validation loss: 1.8188420239315237

Epoch: 6| Step: 3
Training loss: 0.2886497676372528
Validation loss: 1.7869591059223298

Epoch: 6| Step: 4
Training loss: 0.24897634983062744
Validation loss: 1.7527677711620127

Epoch: 6| Step: 5
Training loss: 0.3290855288505554
Validation loss: 1.7333208937798776

Epoch: 6| Step: 6
Training loss: 0.11895620077848434
Validation loss: 1.7222701580293718

Epoch: 6| Step: 7
Training loss: 0.7683629989624023
Validation loss: 1.6950959544028006

Epoch: 6| Step: 8
Training loss: 0.3405744135379791
Validation loss: 1.6607020721640637

Epoch: 6| Step: 9
Training loss: 0.27666181325912476
Validation loss: 1.675168566806342

Epoch: 6| Step: 10
Training loss: 0.14006280899047852
Validation loss: 1.7084375760888542

Epoch: 6| Step: 11
Training loss: 0.39835238456726074
Validation loss: 1.6760347120223507

Epoch: 6| Step: 12
Training loss: 0.40712815523147583
Validation loss: 1.6880694089397308

Epoch: 6| Step: 13
Training loss: 0.41761234402656555
Validation loss: 1.702092268133676

Epoch: 429| Step: 0
Training loss: 0.5558543801307678
Validation loss: 1.6807505315349949

Epoch: 6| Step: 1
Training loss: 0.18077373504638672
Validation loss: 1.678507529279237

Epoch: 6| Step: 2
Training loss: 0.5746334195137024
Validation loss: 1.6986179826080159

Epoch: 6| Step: 3
Training loss: 0.4408424496650696
Validation loss: 1.7010502930610412

Epoch: 6| Step: 4
Training loss: 0.3240095376968384
Validation loss: 1.711472007536119

Epoch: 6| Step: 5
Training loss: 0.11227003484964371
Validation loss: 1.7267738747340378

Epoch: 6| Step: 6
Training loss: 0.38581541180610657
Validation loss: 1.735250405085984

Epoch: 6| Step: 7
Training loss: 0.3216674327850342
Validation loss: 1.7446976874464302

Epoch: 6| Step: 8
Training loss: 0.4528663158416748
Validation loss: 1.7429426639310774

Epoch: 6| Step: 9
Training loss: 0.207550510764122
Validation loss: 1.695385249712134

Epoch: 6| Step: 10
Training loss: 0.3240596055984497
Validation loss: 1.706686838980644

Epoch: 6| Step: 11
Training loss: 0.3091905117034912
Validation loss: 1.7003504383948542

Epoch: 6| Step: 12
Training loss: 0.5190203785896301
Validation loss: 1.7241372728860507

Epoch: 6| Step: 13
Training loss: 0.15979914367198944
Validation loss: 1.7384570593475013

Epoch: 430| Step: 0
Training loss: 0.36758625507354736
Validation loss: 1.721336841583252

Epoch: 6| Step: 1
Training loss: 0.5311319231987
Validation loss: 1.720744022118148

Epoch: 6| Step: 2
Training loss: 0.12257248163223267
Validation loss: 1.7261317135185323

Epoch: 6| Step: 3
Training loss: 0.2746838927268982
Validation loss: 1.727994175367458

Epoch: 6| Step: 4
Training loss: 0.3212307095527649
Validation loss: 1.7286273740953015

Epoch: 6| Step: 5
Training loss: 0.48223376274108887
Validation loss: 1.746032891734954

Epoch: 6| Step: 6
Training loss: 0.22366341948509216
Validation loss: 1.7870972515434347

Epoch: 6| Step: 7
Training loss: 0.35393744707107544
Validation loss: 1.7685365446152226

Epoch: 6| Step: 8
Training loss: 0.4778573215007782
Validation loss: 1.7560437046071535

Epoch: 6| Step: 9
Training loss: 0.4692828357219696
Validation loss: 1.7663820071886944

Epoch: 6| Step: 10
Training loss: 0.36103159189224243
Validation loss: 1.7604617303417576

Epoch: 6| Step: 11
Training loss: 0.2994695007801056
Validation loss: 1.7310281953504008

Epoch: 6| Step: 12
Training loss: 0.27336084842681885
Validation loss: 1.7109749176168954

Epoch: 6| Step: 13
Training loss: 0.338608980178833
Validation loss: 1.6574526371494416

Epoch: 431| Step: 0
Training loss: 0.40925389528274536
Validation loss: 1.6625086825381044

Epoch: 6| Step: 1
Training loss: 0.35500839352607727
Validation loss: 1.684161151609113

Epoch: 6| Step: 2
Training loss: 0.27620241045951843
Validation loss: 1.6969732187127555

Epoch: 6| Step: 3
Training loss: 0.3491153120994568
Validation loss: 1.7074436814554277

Epoch: 6| Step: 4
Training loss: 0.40539270639419556
Validation loss: 1.7412031337779055

Epoch: 6| Step: 5
Training loss: 0.40894031524658203
Validation loss: 1.742903656856988

Epoch: 6| Step: 6
Training loss: 0.3951720893383026
Validation loss: 1.7383571196627874

Epoch: 6| Step: 7
Training loss: 0.12671533226966858
Validation loss: 1.7178127355473016

Epoch: 6| Step: 8
Training loss: 0.32739582657814026
Validation loss: 1.7065890758268294

Epoch: 6| Step: 9
Training loss: 0.3024745285511017
Validation loss: 1.7164868667561521

Epoch: 6| Step: 10
Training loss: 0.4802590608596802
Validation loss: 1.7481481670051493

Epoch: 6| Step: 11
Training loss: 0.3798142671585083
Validation loss: 1.7580225941955403

Epoch: 6| Step: 12
Training loss: 0.34771525859832764
Validation loss: 1.7443448343584615

Epoch: 6| Step: 13
Training loss: 0.23644214868545532
Validation loss: 1.754736449128838

Epoch: 432| Step: 0
Training loss: 0.3361670970916748
Validation loss: 1.7612886262196366

Epoch: 6| Step: 1
Training loss: 0.47193408012390137
Validation loss: 1.7182068209494314

Epoch: 6| Step: 2
Training loss: 0.6231644153594971
Validation loss: 1.7362530077657392

Epoch: 6| Step: 3
Training loss: 0.48710617423057556
Validation loss: 1.7214621613102574

Epoch: 6| Step: 4
Training loss: 0.6140298843383789
Validation loss: 1.7324156145895682

Epoch: 6| Step: 5
Training loss: 0.22512635588645935
Validation loss: 1.7422297475158528

Epoch: 6| Step: 6
Training loss: 0.5357000231742859
Validation loss: 1.7447029621370378

Epoch: 6| Step: 7
Training loss: 0.22201669216156006
Validation loss: 1.7855441224190496

Epoch: 6| Step: 8
Training loss: 0.17282691597938538
Validation loss: 1.825266012581446

Epoch: 6| Step: 9
Training loss: 0.39116424322128296
Validation loss: 1.8502041011728265

Epoch: 6| Step: 10
Training loss: 0.3161761462688446
Validation loss: 1.8481033745632376

Epoch: 6| Step: 11
Training loss: 0.2885458767414093
Validation loss: 1.7848808560320126

Epoch: 6| Step: 12
Training loss: 0.4821247458457947
Validation loss: 1.7348723603833107

Epoch: 6| Step: 13
Training loss: 0.3378257751464844
Validation loss: 1.6959428870549766

Epoch: 433| Step: 0
Training loss: 0.14755645394325256
Validation loss: 1.6885220184121081

Epoch: 6| Step: 1
Training loss: 0.46245628595352173
Validation loss: 1.682666196618029

Epoch: 6| Step: 2
Training loss: 0.4352022707462311
Validation loss: 1.6815320855827742

Epoch: 6| Step: 3
Training loss: 0.4482117295265198
Validation loss: 1.714060241176236

Epoch: 6| Step: 4
Training loss: 0.47830748558044434
Validation loss: 1.7532727359443583

Epoch: 6| Step: 5
Training loss: 0.35079920291900635
Validation loss: 1.7582779956120316

Epoch: 6| Step: 6
Training loss: 0.44398653507232666
Validation loss: 1.7708062164245113

Epoch: 6| Step: 7
Training loss: 0.30317598581314087
Validation loss: 1.7773208900164532

Epoch: 6| Step: 8
Training loss: 0.2282434105873108
Validation loss: 1.7747575083086569

Epoch: 6| Step: 9
Training loss: 0.38208454847335815
Validation loss: 1.7998547733470958

Epoch: 6| Step: 10
Training loss: 0.34004729986190796
Validation loss: 1.796848056136921

Epoch: 6| Step: 11
Training loss: 0.4210978150367737
Validation loss: 1.7845143220757926

Epoch: 6| Step: 12
Training loss: 0.4627333879470825
Validation loss: 1.7625203004447363

Epoch: 6| Step: 13
Training loss: 0.2845858931541443
Validation loss: 1.7058623298521964

Epoch: 434| Step: 0
Training loss: 0.3457217812538147
Validation loss: 1.6950636589398949

Epoch: 6| Step: 1
Training loss: 0.4518500566482544
Validation loss: 1.6888521435440227

Epoch: 6| Step: 2
Training loss: 0.4986170828342438
Validation loss: 1.6772715032741587

Epoch: 6| Step: 3
Training loss: 0.33576226234436035
Validation loss: 1.663267829084909

Epoch: 6| Step: 4
Training loss: 0.6239437460899353
Validation loss: 1.6657618399589293

Epoch: 6| Step: 5
Training loss: 0.26710307598114014
Validation loss: 1.6670679764081073

Epoch: 6| Step: 6
Training loss: 0.22133947908878326
Validation loss: 1.7181129686294063

Epoch: 6| Step: 7
Training loss: 0.36062806844711304
Validation loss: 1.7436133482122933

Epoch: 6| Step: 8
Training loss: 0.49699851870536804
Validation loss: 1.7669563114002187

Epoch: 6| Step: 9
Training loss: 0.22849756479263306
Validation loss: 1.8159975005734352

Epoch: 6| Step: 10
Training loss: 0.3728240728378296
Validation loss: 1.8496430702106927

Epoch: 6| Step: 11
Training loss: 0.2679862380027771
Validation loss: 1.8566394441871232

Epoch: 6| Step: 12
Training loss: 0.49468550086021423
Validation loss: 1.803422458710209

Epoch: 6| Step: 13
Training loss: 0.28756338357925415
Validation loss: 1.7713969599816106

Epoch: 435| Step: 0
Training loss: 0.27567535638809204
Validation loss: 1.7041711243250037

Epoch: 6| Step: 1
Training loss: 0.36951133608818054
Validation loss: 1.687563120677907

Epoch: 6| Step: 2
Training loss: 0.24176432192325592
Validation loss: 1.6507119350535895

Epoch: 6| Step: 3
Training loss: 0.606556236743927
Validation loss: 1.624778514267296

Epoch: 6| Step: 4
Training loss: 0.13573698699474335
Validation loss: 1.6211768401566373

Epoch: 6| Step: 5
Training loss: 0.38527190685272217
Validation loss: 1.6199675785597933

Epoch: 6| Step: 6
Training loss: 0.1651880443096161
Validation loss: 1.66964461470163

Epoch: 6| Step: 7
Training loss: 0.675913393497467
Validation loss: 1.6646770200421732

Epoch: 6| Step: 8
Training loss: 0.24255022406578064
Validation loss: 1.7327584323062692

Epoch: 6| Step: 9
Training loss: 0.3698180913925171
Validation loss: 1.755956986899017

Epoch: 6| Step: 10
Training loss: 0.4124873876571655
Validation loss: 1.7599180488176243

Epoch: 6| Step: 11
Training loss: 0.5079875588417053
Validation loss: 1.7513062633493894

Epoch: 6| Step: 12
Training loss: 0.45976555347442627
Validation loss: 1.7296781232280116

Epoch: 6| Step: 13
Training loss: 0.3362586200237274
Validation loss: 1.7107049495943132

Epoch: 436| Step: 0
Training loss: 0.39818865060806274
Validation loss: 1.7048135393409318

Epoch: 6| Step: 1
Training loss: 0.4169358015060425
Validation loss: 1.711437020250546

Epoch: 6| Step: 2
Training loss: 0.3169252276420593
Validation loss: 1.6982150359820294

Epoch: 6| Step: 3
Training loss: 0.502191960811615
Validation loss: 1.6942336610568467

Epoch: 6| Step: 4
Training loss: 0.4194504916667938
Validation loss: 1.6830951693237468

Epoch: 6| Step: 5
Training loss: 0.30402272939682007
Validation loss: 1.687927899822112

Epoch: 6| Step: 6
Training loss: 0.24013933539390564
Validation loss: 1.7092803908932594

Epoch: 6| Step: 7
Training loss: 0.5629651546478271
Validation loss: 1.696807192217919

Epoch: 6| Step: 8
Training loss: 0.3033257722854614
Validation loss: 1.7242714012822797

Epoch: 6| Step: 9
Training loss: 0.34231388568878174
Validation loss: 1.774084537259994

Epoch: 6| Step: 10
Training loss: 0.3175843358039856
Validation loss: 1.7932356916448122

Epoch: 6| Step: 11
Training loss: 0.3984573483467102
Validation loss: 1.78561233961454

Epoch: 6| Step: 12
Training loss: 0.28803759813308716
Validation loss: 1.7649236943132134

Epoch: 6| Step: 13
Training loss: 0.25130143761634827
Validation loss: 1.7125733270440051

Epoch: 437| Step: 0
Training loss: 0.4379788041114807
Validation loss: 1.6682717588640028

Epoch: 6| Step: 1
Training loss: 0.5628228187561035
Validation loss: 1.6330304786723147

Epoch: 6| Step: 2
Training loss: 0.41584646701812744
Validation loss: 1.6076337983531337

Epoch: 6| Step: 3
Training loss: 0.4465753436088562
Validation loss: 1.6080805883612683

Epoch: 6| Step: 4
Training loss: 0.4406670331954956
Validation loss: 1.608159698465819

Epoch: 6| Step: 5
Training loss: 0.3462960720062256
Validation loss: 1.6273827219522128

Epoch: 6| Step: 6
Training loss: 0.4762474298477173
Validation loss: 1.6219425342416252

Epoch: 6| Step: 7
Training loss: 0.23698823153972626
Validation loss: 1.6280505695650656

Epoch: 6| Step: 8
Training loss: 0.252579927444458
Validation loss: 1.650323115369325

Epoch: 6| Step: 9
Training loss: 0.4463766813278198
Validation loss: 1.7033252639155234

Epoch: 6| Step: 10
Training loss: 0.35954082012176514
Validation loss: 1.728351245644272

Epoch: 6| Step: 11
Training loss: 0.38473278284072876
Validation loss: 1.7493936310532272

Epoch: 6| Step: 12
Training loss: 0.16440755128860474
Validation loss: 1.77992509770137

Epoch: 6| Step: 13
Training loss: 0.3330661356449127
Validation loss: 1.7767722029839792

Epoch: 438| Step: 0
Training loss: 0.3966923952102661
Validation loss: 1.7832027122538576

Epoch: 6| Step: 1
Training loss: 0.3328576385974884
Validation loss: 1.7851212075961533

Epoch: 6| Step: 2
Training loss: 0.37947195768356323
Validation loss: 1.7459899263997232

Epoch: 6| Step: 3
Training loss: 0.5810856819152832
Validation loss: 1.7546444990301644

Epoch: 6| Step: 4
Training loss: 0.16795502603054047
Validation loss: 1.7723920550397647

Epoch: 6| Step: 5
Training loss: 0.25679999589920044
Validation loss: 1.7663323212695379

Epoch: 6| Step: 6
Training loss: 0.2687266170978546
Validation loss: 1.7284309402588875

Epoch: 6| Step: 7
Training loss: 0.5068777203559875
Validation loss: 1.757201079399355

Epoch: 6| Step: 8
Training loss: 0.5942840576171875
Validation loss: 1.722954551378886

Epoch: 6| Step: 9
Training loss: 0.3473142981529236
Validation loss: 1.7127031510876072

Epoch: 6| Step: 10
Training loss: 0.48203372955322266
Validation loss: 1.7296976517605525

Epoch: 6| Step: 11
Training loss: 0.2719915509223938
Validation loss: 1.728135073056785

Epoch: 6| Step: 12
Training loss: 0.212734192609787
Validation loss: 1.729162455886923

Epoch: 6| Step: 13
Training loss: 0.4562511444091797
Validation loss: 1.7347548674511653

Epoch: 439| Step: 0
Training loss: 0.3560298979282379
Validation loss: 1.742664312803617

Epoch: 6| Step: 1
Training loss: 0.4906567335128784
Validation loss: 1.7750865964479343

Epoch: 6| Step: 2
Training loss: 0.20722177624702454
Validation loss: 1.7674351276889924

Epoch: 6| Step: 3
Training loss: 0.16038209199905396
Validation loss: 1.725798709418184

Epoch: 6| Step: 4
Training loss: 0.3615206182003021
Validation loss: 1.738739735336714

Epoch: 6| Step: 5
Training loss: 0.5631037354469299
Validation loss: 1.6963738613231207

Epoch: 6| Step: 6
Training loss: 0.34438368678092957
Validation loss: 1.669263493630194

Epoch: 6| Step: 7
Training loss: 0.2832910418510437
Validation loss: 1.6682218518308414

Epoch: 6| Step: 8
Training loss: 0.27184373140335083
Validation loss: 1.6707528797529076

Epoch: 6| Step: 9
Training loss: 0.48153966665267944
Validation loss: 1.677519795715168

Epoch: 6| Step: 10
Training loss: 0.40547844767570496
Validation loss: 1.6761796628275225

Epoch: 6| Step: 11
Training loss: 0.3331540822982788
Validation loss: 1.6852789630172074

Epoch: 6| Step: 12
Training loss: 0.36579298973083496
Validation loss: 1.738723716428203

Epoch: 6| Step: 13
Training loss: 0.42968255281448364
Validation loss: 1.7246485192288634

Epoch: 440| Step: 0
Training loss: 0.35529571771621704
Validation loss: 1.7071874705694055

Epoch: 6| Step: 1
Training loss: 0.23912306129932404
Validation loss: 1.6918066483671947

Epoch: 6| Step: 2
Training loss: 0.4702730178833008
Validation loss: 1.6971671427449873

Epoch: 6| Step: 3
Training loss: 0.4168184995651245
Validation loss: 1.6882838203061012

Epoch: 6| Step: 4
Training loss: 0.17390978336334229
Validation loss: 1.703461758552059

Epoch: 6| Step: 5
Training loss: 0.17537373304367065
Validation loss: 1.7130300665414462

Epoch: 6| Step: 6
Training loss: 0.4985440671443939
Validation loss: 1.758232101317375

Epoch: 6| Step: 7
Training loss: 0.3683847486972809
Validation loss: 1.7547841430992208

Epoch: 6| Step: 8
Training loss: 0.29819950461387634
Validation loss: 1.7610943150776688

Epoch: 6| Step: 9
Training loss: 0.396537184715271
Validation loss: 1.7169328479356663

Epoch: 6| Step: 10
Training loss: 0.1895374357700348
Validation loss: 1.7168373113037438

Epoch: 6| Step: 11
Training loss: 0.3814818859100342
Validation loss: 1.7209267949545255

Epoch: 6| Step: 12
Training loss: 0.281381756067276
Validation loss: 1.7417612344987932

Epoch: 6| Step: 13
Training loss: 0.40200275182724
Validation loss: 1.7182400623957317

Epoch: 441| Step: 0
Training loss: 0.3052426874637604
Validation loss: 1.6951748812070457

Epoch: 6| Step: 1
Training loss: 0.14884275197982788
Validation loss: 1.672040057438676

Epoch: 6| Step: 2
Training loss: 0.25660523772239685
Validation loss: 1.6617554733830113

Epoch: 6| Step: 3
Training loss: 0.26995885372161865
Validation loss: 1.6616609557982414

Epoch: 6| Step: 4
Training loss: 0.4582638144493103
Validation loss: 1.6863694678070724

Epoch: 6| Step: 5
Training loss: 0.35863935947418213
Validation loss: 1.6989025223639704

Epoch: 6| Step: 6
Training loss: 0.20914629101753235
Validation loss: 1.73217890467695

Epoch: 6| Step: 7
Training loss: 0.25679314136505127
Validation loss: 1.7728096938902331

Epoch: 6| Step: 8
Training loss: 0.5115085244178772
Validation loss: 1.788812848829454

Epoch: 6| Step: 9
Training loss: 0.4635624885559082
Validation loss: 1.7862065479319582

Epoch: 6| Step: 10
Training loss: 0.3141292929649353
Validation loss: 1.7861293772215485

Epoch: 6| Step: 11
Training loss: 0.3175457715988159
Validation loss: 1.7633573944850633

Epoch: 6| Step: 12
Training loss: 0.31975001096725464
Validation loss: 1.75038396158526

Epoch: 6| Step: 13
Training loss: 0.3068930208683014
Validation loss: 1.731531661043885

Epoch: 442| Step: 0
Training loss: 0.26900017261505127
Validation loss: 1.6978931991002892

Epoch: 6| Step: 1
Training loss: 0.2724507749080658
Validation loss: 1.7067021862153084

Epoch: 6| Step: 2
Training loss: 0.49549365043640137
Validation loss: 1.688268635862617

Epoch: 6| Step: 3
Training loss: 0.2525850534439087
Validation loss: 1.7120642226229432

Epoch: 6| Step: 4
Training loss: 0.22722995281219482
Validation loss: 1.6932684747121667

Epoch: 6| Step: 5
Training loss: 0.27123937010765076
Validation loss: 1.7194023504052112

Epoch: 6| Step: 6
Training loss: 0.34279268980026245
Validation loss: 1.70632613858869

Epoch: 6| Step: 7
Training loss: 0.4089871048927307
Validation loss: 1.7213313169376825

Epoch: 6| Step: 8
Training loss: 0.2141648232936859
Validation loss: 1.752112204028714

Epoch: 6| Step: 9
Training loss: 0.40078336000442505
Validation loss: 1.7173954004882483

Epoch: 6| Step: 10
Training loss: 0.27309131622314453
Validation loss: 1.7709029079765402

Epoch: 6| Step: 11
Training loss: 0.362457275390625
Validation loss: 1.7625361565620667

Epoch: 6| Step: 12
Training loss: 0.4293265640735626
Validation loss: 1.7711082017549904

Epoch: 6| Step: 13
Training loss: 0.4514285624027252
Validation loss: 1.7207100417024346

Epoch: 443| Step: 0
Training loss: 0.3221368193626404
Validation loss: 1.7125759483665548

Epoch: 6| Step: 1
Training loss: 0.2462443709373474
Validation loss: 1.68135271533843

Epoch: 6| Step: 2
Training loss: 0.21173009276390076
Validation loss: 1.675753637026715

Epoch: 6| Step: 3
Training loss: 0.19374549388885498
Validation loss: 1.6437018302179152

Epoch: 6| Step: 4
Training loss: 0.5612282752990723
Validation loss: 1.6895037184479416

Epoch: 6| Step: 5
Training loss: 0.23720546066761017
Validation loss: 1.6757609895480576

Epoch: 6| Step: 6
Training loss: 0.21022632718086243
Validation loss: 1.6764066027056785

Epoch: 6| Step: 7
Training loss: 0.3232777714729309
Validation loss: 1.7224236534487816

Epoch: 6| Step: 8
Training loss: 0.2364477664232254
Validation loss: 1.7268045974034134

Epoch: 6| Step: 9
Training loss: 0.31500881910324097
Validation loss: 1.7131718256140267

Epoch: 6| Step: 10
Training loss: 0.3426545262336731
Validation loss: 1.756591009837325

Epoch: 6| Step: 11
Training loss: 0.4629356861114502
Validation loss: 1.757421362784601

Epoch: 6| Step: 12
Training loss: 0.4459436535835266
Validation loss: 1.7595409936802362

Epoch: 6| Step: 13
Training loss: 0.303846150636673
Validation loss: 1.7362190818273893

Epoch: 444| Step: 0
Training loss: 0.3865128755569458
Validation loss: 1.7221111456553142

Epoch: 6| Step: 1
Training loss: 0.34768715500831604
Validation loss: 1.7341873030508719

Epoch: 6| Step: 2
Training loss: 0.34288549423217773
Validation loss: 1.7493672768274944

Epoch: 6| Step: 3
Training loss: 0.7046768665313721
Validation loss: 1.7222565515066988

Epoch: 6| Step: 4
Training loss: 0.24007993936538696
Validation loss: 1.739753665462617

Epoch: 6| Step: 5
Training loss: 0.3126727342605591
Validation loss: 1.706967152575011

Epoch: 6| Step: 6
Training loss: 0.2287537157535553
Validation loss: 1.7456301963457497

Epoch: 6| Step: 7
Training loss: 0.37988415360450745
Validation loss: 1.7477355951903968

Epoch: 6| Step: 8
Training loss: 0.25797969102859497
Validation loss: 1.7330936719012517

Epoch: 6| Step: 9
Training loss: 0.13681474328041077
Validation loss: 1.7191930817019554

Epoch: 6| Step: 10
Training loss: 0.3053964376449585
Validation loss: 1.7205616248551237

Epoch: 6| Step: 11
Training loss: 0.3150240182876587
Validation loss: 1.6985395544318742

Epoch: 6| Step: 12
Training loss: 0.41971153020858765
Validation loss: 1.6766331618832004

Epoch: 6| Step: 13
Training loss: 0.43642646074295044
Validation loss: 1.6808283418737433

Epoch: 445| Step: 0
Training loss: 0.39781641960144043
Validation loss: 1.6538057647725588

Epoch: 6| Step: 1
Training loss: 0.2820323705673218
Validation loss: 1.6819965685567548

Epoch: 6| Step: 2
Training loss: 0.22089844942092896
Validation loss: 1.716396326659828

Epoch: 6| Step: 3
Training loss: 0.28416332602500916
Validation loss: 1.7495870449209725

Epoch: 6| Step: 4
Training loss: 0.3681267499923706
Validation loss: 1.7680388830041374

Epoch: 6| Step: 5
Training loss: 0.48405390977859497
Validation loss: 1.7647157612667288

Epoch: 6| Step: 6
Training loss: 0.46846985816955566
Validation loss: 1.751544834465109

Epoch: 6| Step: 7
Training loss: 0.3967609107494354
Validation loss: 1.7467011956758396

Epoch: 6| Step: 8
Training loss: 0.2466924637556076
Validation loss: 1.7141515721556961

Epoch: 6| Step: 9
Training loss: 0.5154615640640259
Validation loss: 1.6719775917709514

Epoch: 6| Step: 10
Training loss: 0.1397097408771515
Validation loss: 1.6637193259372507

Epoch: 6| Step: 11
Training loss: 0.3302879333496094
Validation loss: 1.6675161200184976

Epoch: 6| Step: 12
Training loss: 0.5326316952705383
Validation loss: 1.6524954201072775

Epoch: 6| Step: 13
Training loss: 0.2523004710674286
Validation loss: 1.693272598328129

Epoch: 446| Step: 0
Training loss: 0.3965669870376587
Validation loss: 1.7102174169273787

Epoch: 6| Step: 1
Training loss: 0.35235750675201416
Validation loss: 1.6927250200702297

Epoch: 6| Step: 2
Training loss: 0.4780101478099823
Validation loss: 1.7079908745263213

Epoch: 6| Step: 3
Training loss: 0.33526909351348877
Validation loss: 1.7237091884818128

Epoch: 6| Step: 4
Training loss: 0.25945815443992615
Validation loss: 1.7274401341715167

Epoch: 6| Step: 5
Training loss: 0.35631299018859863
Validation loss: 1.72612044888158

Epoch: 6| Step: 6
Training loss: 0.3912186920642853
Validation loss: 1.7479264377265848

Epoch: 6| Step: 7
Training loss: 0.21065178513526917
Validation loss: 1.6730340129585677

Epoch: 6| Step: 8
Training loss: 0.3779742121696472
Validation loss: 1.6702590232254357

Epoch: 6| Step: 9
Training loss: 0.2966621518135071
Validation loss: 1.7047440031523347

Epoch: 6| Step: 10
Training loss: 0.4087110161781311
Validation loss: 1.7330304384231567

Epoch: 6| Step: 11
Training loss: 0.44321614503860474
Validation loss: 1.7196310784227105

Epoch: 6| Step: 12
Training loss: 0.4410480856895447
Validation loss: 1.7171825003880326

Epoch: 6| Step: 13
Training loss: 0.3023798167705536
Validation loss: 1.7521309250144548

Epoch: 447| Step: 0
Training loss: 0.33258599042892456
Validation loss: 1.774664794245074

Epoch: 6| Step: 1
Training loss: 0.3592768907546997
Validation loss: 1.7868170379310526

Epoch: 6| Step: 2
Training loss: 0.3868088722229004
Validation loss: 1.7518055926087082

Epoch: 6| Step: 3
Training loss: 0.2326933890581131
Validation loss: 1.7699525279383506

Epoch: 6| Step: 4
Training loss: 0.29155102372169495
Validation loss: 1.7351374292886386

Epoch: 6| Step: 5
Training loss: 0.37045109272003174
Validation loss: 1.6951568600951985

Epoch: 6| Step: 6
Training loss: 0.20371046662330627
Validation loss: 1.6761576206453386

Epoch: 6| Step: 7
Training loss: 0.36071479320526123
Validation loss: 1.647563325461521

Epoch: 6| Step: 8
Training loss: 0.5117453336715698
Validation loss: 1.628631624483293

Epoch: 6| Step: 9
Training loss: 0.30260106921195984
Validation loss: 1.632083010929887

Epoch: 6| Step: 10
Training loss: 0.38190245628356934
Validation loss: 1.6419352510923981

Epoch: 6| Step: 11
Training loss: 0.24441537261009216
Validation loss: 1.6237571688108547

Epoch: 6| Step: 12
Training loss: 0.6331238150596619
Validation loss: 1.644744320582318

Epoch: 6| Step: 13
Training loss: 0.24544313549995422
Validation loss: 1.6445140146440076

Epoch: 448| Step: 0
Training loss: 0.2050032913684845
Validation loss: 1.6512928598670549

Epoch: 6| Step: 1
Training loss: 0.47845593094825745
Validation loss: 1.66244109471639

Epoch: 6| Step: 2
Training loss: 0.2615910470485687
Validation loss: 1.718988295524351

Epoch: 6| Step: 3
Training loss: 0.3071133494377136
Validation loss: 1.7446856396172636

Epoch: 6| Step: 4
Training loss: 0.26984524726867676
Validation loss: 1.746549899860095

Epoch: 6| Step: 5
Training loss: 0.4252598285675049
Validation loss: 1.7714592231217252

Epoch: 6| Step: 6
Training loss: 0.5104707479476929
Validation loss: 1.7755933653923772

Epoch: 6| Step: 7
Training loss: 0.33117949962615967
Validation loss: 1.7846265979992446

Epoch: 6| Step: 8
Training loss: 0.35965070128440857
Validation loss: 1.784201072108361

Epoch: 6| Step: 9
Training loss: 0.3527730405330658
Validation loss: 1.803040514710129

Epoch: 6| Step: 10
Training loss: 0.16517373919487
Validation loss: 1.723000818683255

Epoch: 6| Step: 11
Training loss: 0.27948543429374695
Validation loss: 1.6959506568088327

Epoch: 6| Step: 12
Training loss: 0.23749491572380066
Validation loss: 1.7093859423873246

Epoch: 6| Step: 13
Training loss: 0.2347971647977829
Validation loss: 1.6888968290821198

Epoch: 449| Step: 0
Training loss: 0.15396329760551453
Validation loss: 1.7193355227029452

Epoch: 6| Step: 1
Training loss: 0.16599401831626892
Validation loss: 1.7220799692215458

Epoch: 6| Step: 2
Training loss: 0.37202394008636475
Validation loss: 1.7230490394817886

Epoch: 6| Step: 3
Training loss: 0.49586668610572815
Validation loss: 1.718929979108995

Epoch: 6| Step: 4
Training loss: 0.27520570158958435
Validation loss: 1.7483252658638904

Epoch: 6| Step: 5
Training loss: 0.27386102080345154
Validation loss: 1.7216218658672866

Epoch: 6| Step: 6
Training loss: 0.3965115547180176
Validation loss: 1.7107025115720687

Epoch: 6| Step: 7
Training loss: 0.21279937028884888
Validation loss: 1.7156353227553829

Epoch: 6| Step: 8
Training loss: 0.2736884355545044
Validation loss: 1.6987132180121638

Epoch: 6| Step: 9
Training loss: 0.33116716146469116
Validation loss: 1.6893792242132208

Epoch: 6| Step: 10
Training loss: 0.34946897625923157
Validation loss: 1.6899712598452004

Epoch: 6| Step: 11
Training loss: 0.23384352028369904
Validation loss: 1.7176757461281233

Epoch: 6| Step: 12
Training loss: 0.5194331407546997
Validation loss: 1.6874764888517317

Epoch: 6| Step: 13
Training loss: 0.4741387963294983
Validation loss: 1.6841646150876117

Epoch: 450| Step: 0
Training loss: 0.36805349588394165
Validation loss: 1.6629622482484387

Epoch: 6| Step: 1
Training loss: 0.32167863845825195
Validation loss: 1.6877126924453243

Epoch: 6| Step: 2
Training loss: 0.580883264541626
Validation loss: 1.6140510856464345

Epoch: 6| Step: 3
Training loss: 0.29984086751937866
Validation loss: 1.6212025547540316

Epoch: 6| Step: 4
Training loss: 0.44055843353271484
Validation loss: 1.6377545223441174

Epoch: 6| Step: 5
Training loss: 0.24972528219223022
Validation loss: 1.663765964969512

Epoch: 6| Step: 6
Training loss: 0.4046267867088318
Validation loss: 1.6732532670420985

Epoch: 6| Step: 7
Training loss: 0.33033257722854614
Validation loss: 1.6607170656163206

Epoch: 6| Step: 8
Training loss: 0.3382800221443176
Validation loss: 1.734511524118403

Epoch: 6| Step: 9
Training loss: 0.3280400037765503
Validation loss: 1.7620541357224988

Epoch: 6| Step: 10
Training loss: 0.27068471908569336
Validation loss: 1.7666714716983098

Epoch: 6| Step: 11
Training loss: 0.26766884326934814
Validation loss: 1.767074934256974

Epoch: 6| Step: 12
Training loss: 0.21757201850414276
Validation loss: 1.7121763549825197

Epoch: 6| Step: 13
Training loss: 0.2584547996520996
Validation loss: 1.6647378667708366

Epoch: 451| Step: 0
Training loss: 0.6232837438583374
Validation loss: 1.6931926563221922

Epoch: 6| Step: 1
Training loss: 0.35567769408226013
Validation loss: 1.659466330723096

Epoch: 6| Step: 2
Training loss: 0.3096429109573364
Validation loss: 1.6520945442620145

Epoch: 6| Step: 3
Training loss: 0.30688610672950745
Validation loss: 1.6624753039370301

Epoch: 6| Step: 4
Training loss: 0.4464026689529419
Validation loss: 1.6137201536086299

Epoch: 6| Step: 5
Training loss: 0.2551010251045227
Validation loss: 1.6246113046523063

Epoch: 6| Step: 6
Training loss: 0.43620383739471436
Validation loss: 1.6546315429031209

Epoch: 6| Step: 7
Training loss: 0.22528070211410522
Validation loss: 1.6441664811103576

Epoch: 6| Step: 8
Training loss: 0.1034763753414154
Validation loss: 1.69569948668121

Epoch: 6| Step: 9
Training loss: 0.4086993336677551
Validation loss: 1.717712551034907

Epoch: 6| Step: 10
Training loss: 0.35200172662734985
Validation loss: 1.7216641012058462

Epoch: 6| Step: 11
Training loss: 0.14737629890441895
Validation loss: 1.737906817466982

Epoch: 6| Step: 12
Training loss: 0.4662390649318695
Validation loss: 1.758257991524153

Epoch: 6| Step: 13
Training loss: 0.16676290333271027
Validation loss: 1.7427297715217835

Epoch: 452| Step: 0
Training loss: 0.21351511776447296
Validation loss: 1.729961879791752

Epoch: 6| Step: 1
Training loss: 0.41881829500198364
Validation loss: 1.7158617191417243

Epoch: 6| Step: 2
Training loss: 0.387241005897522
Validation loss: 1.6840839219349686

Epoch: 6| Step: 3
Training loss: 0.25051766633987427
Validation loss: 1.6680405460378176

Epoch: 6| Step: 4
Training loss: 0.41428059339523315
Validation loss: 1.6853198787217498

Epoch: 6| Step: 5
Training loss: 0.16482166945934296
Validation loss: 1.6561093215019471

Epoch: 6| Step: 6
Training loss: 0.29917091131210327
Validation loss: 1.6364738684828564

Epoch: 6| Step: 7
Training loss: 0.19332796335220337
Validation loss: 1.6632894521118493

Epoch: 6| Step: 8
Training loss: 0.2892568111419678
Validation loss: 1.6831929465775848

Epoch: 6| Step: 9
Training loss: 0.35515907406806946
Validation loss: 1.7280885711792977

Epoch: 6| Step: 10
Training loss: 0.39390748739242554
Validation loss: 1.7522598620383971

Epoch: 6| Step: 11
Training loss: 0.3121040165424347
Validation loss: 1.792813947123866

Epoch: 6| Step: 12
Training loss: 0.37342628836631775
Validation loss: 1.829503781052046

Epoch: 6| Step: 13
Training loss: 0.2698734998703003
Validation loss: 1.7960296715459516

Epoch: 453| Step: 0
Training loss: 0.20415595173835754
Validation loss: 1.7775770976979246

Epoch: 6| Step: 1
Training loss: 0.40994155406951904
Validation loss: 1.7475693636043097

Epoch: 6| Step: 2
Training loss: 0.39164063334465027
Validation loss: 1.7069753587886851

Epoch: 6| Step: 3
Training loss: 0.12961864471435547
Validation loss: 1.6698423175401584

Epoch: 6| Step: 4
Training loss: 0.2752886414527893
Validation loss: 1.635747524999803

Epoch: 6| Step: 5
Training loss: 0.16098789870738983
Validation loss: 1.6221577044456237

Epoch: 6| Step: 6
Training loss: 0.1607469618320465
Validation loss: 1.6141007734883217

Epoch: 6| Step: 7
Training loss: 0.3218108117580414
Validation loss: 1.629008944316577

Epoch: 6| Step: 8
Training loss: 0.31767886877059937
Validation loss: 1.6412964969552972

Epoch: 6| Step: 9
Training loss: 0.34675806760787964
Validation loss: 1.6613365629667878

Epoch: 6| Step: 10
Training loss: 0.4553397297859192
Validation loss: 1.671487218590193

Epoch: 6| Step: 11
Training loss: 0.452109694480896
Validation loss: 1.6914263322789183

Epoch: 6| Step: 12
Training loss: 0.562213659286499
Validation loss: 1.7158526746175622

Epoch: 6| Step: 13
Training loss: 0.198599711060524
Validation loss: 1.728068805509998

Epoch: 454| Step: 0
Training loss: 0.2130585014820099
Validation loss: 1.7011945132286317

Epoch: 6| Step: 1
Training loss: 0.3522270917892456
Validation loss: 1.7334892378058484

Epoch: 6| Step: 2
Training loss: 0.2173132449388504
Validation loss: 1.7139861429891279

Epoch: 6| Step: 3
Training loss: 0.4325023293495178
Validation loss: 1.727826565824529

Epoch: 6| Step: 4
Training loss: 0.43099743127822876
Validation loss: 1.712788486993441

Epoch: 6| Step: 5
Training loss: 0.3789445161819458
Validation loss: 1.74027419090271

Epoch: 6| Step: 6
Training loss: 0.3185121417045593
Validation loss: 1.7338615284171155

Epoch: 6| Step: 7
Training loss: 0.3761345148086548
Validation loss: 1.7577445353231123

Epoch: 6| Step: 8
Training loss: 0.48820412158966064
Validation loss: 1.7593834502722627

Epoch: 6| Step: 9
Training loss: 0.4504084587097168
Validation loss: 1.744967552923387

Epoch: 6| Step: 10
Training loss: 0.17282764613628387
Validation loss: 1.6980756316133725

Epoch: 6| Step: 11
Training loss: 0.22343990206718445
Validation loss: 1.7118741030334144

Epoch: 6| Step: 12
Training loss: 0.30868446826934814
Validation loss: 1.687047617409819

Epoch: 6| Step: 13
Training loss: 0.21801716089248657
Validation loss: 1.681377915925877

Epoch: 455| Step: 0
Training loss: 0.1629028022289276
Validation loss: 1.6356017897205968

Epoch: 6| Step: 1
Training loss: 0.5464640259742737
Validation loss: 1.6072482844834686

Epoch: 6| Step: 2
Training loss: 0.43571025133132935
Validation loss: 1.6120835555497037

Epoch: 6| Step: 3
Training loss: 0.34119629859924316
Validation loss: 1.6022744986318773

Epoch: 6| Step: 4
Training loss: 0.5113433599472046
Validation loss: 1.6438085686775945

Epoch: 6| Step: 5
Training loss: 0.41208523511886597
Validation loss: 1.6519436426060174

Epoch: 6| Step: 6
Training loss: 0.3431386947631836
Validation loss: 1.650159728142523

Epoch: 6| Step: 7
Training loss: 0.43891748785972595
Validation loss: 1.696315957653907

Epoch: 6| Step: 8
Training loss: 0.3694092929363251
Validation loss: 1.6805714099637923

Epoch: 6| Step: 9
Training loss: 0.33059799671173096
Validation loss: 1.6960792785049768

Epoch: 6| Step: 10
Training loss: 0.25356191396713257
Validation loss: 1.7022108506130915

Epoch: 6| Step: 11
Training loss: 0.20710504055023193
Validation loss: 1.721321052120578

Epoch: 6| Step: 12
Training loss: 0.1802472174167633
Validation loss: 1.7003897018330072

Epoch: 6| Step: 13
Training loss: 0.3120044767856598
Validation loss: 1.7201026819085563

Epoch: 456| Step: 0
Training loss: 0.4190498888492584
Validation loss: 1.7336950584124493

Epoch: 6| Step: 1
Training loss: 0.3991169333457947
Validation loss: 1.7543024978330057

Epoch: 6| Step: 2
Training loss: 0.30198514461517334
Validation loss: 1.7484490525337957

Epoch: 6| Step: 3
Training loss: 0.49329057335853577
Validation loss: 1.7208175530997656

Epoch: 6| Step: 4
Training loss: 0.4012869894504547
Validation loss: 1.7056798409390193

Epoch: 6| Step: 5
Training loss: 0.19335633516311646
Validation loss: 1.714480447512801

Epoch: 6| Step: 6
Training loss: 0.3283880949020386
Validation loss: 1.708713352039296

Epoch: 6| Step: 7
Training loss: 0.20505407452583313
Validation loss: 1.7202013974548669

Epoch: 6| Step: 8
Training loss: 0.1609262228012085
Validation loss: 1.7132767861889255

Epoch: 6| Step: 9
Training loss: 0.31471168994903564
Validation loss: 1.6884751268612441

Epoch: 6| Step: 10
Training loss: 0.3173505961894989
Validation loss: 1.6604762615696076

Epoch: 6| Step: 11
Training loss: 0.2883496880531311
Validation loss: 1.6804471503021896

Epoch: 6| Step: 12
Training loss: 0.26666712760925293
Validation loss: 1.7109015500673683

Epoch: 6| Step: 13
Training loss: 0.3156721293926239
Validation loss: 1.69342605785657

Epoch: 457| Step: 0
Training loss: 0.22168031334877014
Validation loss: 1.752185357514248

Epoch: 6| Step: 1
Training loss: 0.3729025721549988
Validation loss: 1.7422042687733967

Epoch: 6| Step: 2
Training loss: 0.2600790858268738
Validation loss: 1.7003771451211744

Epoch: 6| Step: 3
Training loss: 0.27200162410736084
Validation loss: 1.6880515698463685

Epoch: 6| Step: 4
Training loss: 0.3523664176464081
Validation loss: 1.6802841335214593

Epoch: 6| Step: 5
Training loss: 0.337189257144928
Validation loss: 1.6635897236485635

Epoch: 6| Step: 6
Training loss: 0.3189985156059265
Validation loss: 1.6768569459197342

Epoch: 6| Step: 7
Training loss: 0.4877270460128784
Validation loss: 1.6645442106390511

Epoch: 6| Step: 8
Training loss: 0.28662580251693726
Validation loss: 1.6470105648040771

Epoch: 6| Step: 9
Training loss: 0.37143346667289734
Validation loss: 1.6561110583684777

Epoch: 6| Step: 10
Training loss: 0.25078678131103516
Validation loss: 1.6617147012423443

Epoch: 6| Step: 11
Training loss: 0.2528378963470459
Validation loss: 1.6869825586195915

Epoch: 6| Step: 12
Training loss: 0.23626254498958588
Validation loss: 1.7024068973397697

Epoch: 6| Step: 13
Training loss: 0.37594127655029297
Validation loss: 1.6730922563101656

Epoch: 458| Step: 0
Training loss: 0.30279189348220825
Validation loss: 1.684253574699484

Epoch: 6| Step: 1
Training loss: 0.1912161111831665
Validation loss: 1.6689513062918058

Epoch: 6| Step: 2
Training loss: 0.34105271100997925
Validation loss: 1.678719380850433

Epoch: 6| Step: 3
Training loss: 0.21731147170066833
Validation loss: 1.6966419296879922

Epoch: 6| Step: 4
Training loss: 0.24383865296840668
Validation loss: 1.6966747186517204

Epoch: 6| Step: 5
Training loss: 0.4615030884742737
Validation loss: 1.6894037569722822

Epoch: 6| Step: 6
Training loss: 0.4349178969860077
Validation loss: 1.717227816581726

Epoch: 6| Step: 7
Training loss: 0.24173323810100555
Validation loss: 1.7148872985634753

Epoch: 6| Step: 8
Training loss: 0.34969693422317505
Validation loss: 1.7188021675232918

Epoch: 6| Step: 9
Training loss: 0.38416415452957153
Validation loss: 1.7393016610094296

Epoch: 6| Step: 10
Training loss: 0.2569595277309418
Validation loss: 1.71791458898975

Epoch: 6| Step: 11
Training loss: 0.270616739988327
Validation loss: 1.7282753413723362

Epoch: 6| Step: 12
Training loss: 0.29266539216041565
Validation loss: 1.7168277399514311

Epoch: 6| Step: 13
Training loss: 0.35985755920410156
Validation loss: 1.6791227876499135

Epoch: 459| Step: 0
Training loss: 0.20644336938858032
Validation loss: 1.7155297366521691

Epoch: 6| Step: 1
Training loss: 0.34439653158187866
Validation loss: 1.7197149549761126

Epoch: 6| Step: 2
Training loss: 0.35898086428642273
Validation loss: 1.6985369382366058

Epoch: 6| Step: 3
Training loss: 0.5073257684707642
Validation loss: 1.6730270167832733

Epoch: 6| Step: 4
Training loss: 0.4152907729148865
Validation loss: 1.6580573602389264

Epoch: 6| Step: 5
Training loss: 0.27873116731643677
Validation loss: 1.6500039869739163

Epoch: 6| Step: 6
Training loss: 0.42495813965797424
Validation loss: 1.6307521340667561

Epoch: 6| Step: 7
Training loss: 0.16432249546051025
Validation loss: 1.6348636432360577

Epoch: 6| Step: 8
Training loss: 0.29311153292655945
Validation loss: 1.6716701535768406

Epoch: 6| Step: 9
Training loss: 0.3058251738548279
Validation loss: 1.649922578565536

Epoch: 6| Step: 10
Training loss: 0.2322649359703064
Validation loss: 1.707123935863536

Epoch: 6| Step: 11
Training loss: 0.3259011507034302
Validation loss: 1.7232105667873094

Epoch: 6| Step: 12
Training loss: 0.4725823402404785
Validation loss: 1.6962825047072543

Epoch: 6| Step: 13
Training loss: 0.22220580279827118
Validation loss: 1.738721501442694

Epoch: 460| Step: 0
Training loss: 0.5069268941879272
Validation loss: 1.7213117525141726

Epoch: 6| Step: 1
Training loss: 0.2631530165672302
Validation loss: 1.7302458799013527

Epoch: 6| Step: 2
Training loss: 0.2896813154220581
Validation loss: 1.707323730632823

Epoch: 6| Step: 3
Training loss: 0.3334614634513855
Validation loss: 1.6715678655973045

Epoch: 6| Step: 4
Training loss: 0.24294933676719666
Validation loss: 1.6586952683746174

Epoch: 6| Step: 5
Training loss: 0.31783327460289
Validation loss: 1.6393391240027644

Epoch: 6| Step: 6
Training loss: 0.19446313381195068
Validation loss: 1.6231414028393325

Epoch: 6| Step: 7
Training loss: 0.3323517143726349
Validation loss: 1.6290572894516813

Epoch: 6| Step: 8
Training loss: 0.2256048321723938
Validation loss: 1.6244965778884066

Epoch: 6| Step: 9
Training loss: 0.2552894353866577
Validation loss: 1.6746435870406449

Epoch: 6| Step: 10
Training loss: 0.4179915189743042
Validation loss: 1.6371583451506913

Epoch: 6| Step: 11
Training loss: 0.3685603141784668
Validation loss: 1.665241260682383

Epoch: 6| Step: 12
Training loss: 0.3293716311454773
Validation loss: 1.7017308358223207

Epoch: 6| Step: 13
Training loss: 0.3652322292327881
Validation loss: 1.7075417093051377

Epoch: 461| Step: 0
Training loss: 0.29271039366722107
Validation loss: 1.7355103595282442

Epoch: 6| Step: 1
Training loss: 0.6050376296043396
Validation loss: 1.73910722168543

Epoch: 6| Step: 2
Training loss: 0.3563142418861389
Validation loss: 1.7201889919978317

Epoch: 6| Step: 3
Training loss: 0.23959237337112427
Validation loss: 1.6884824281097741

Epoch: 6| Step: 4
Training loss: 0.25208985805511475
Validation loss: 1.6628791901373094

Epoch: 6| Step: 5
Training loss: 0.27776145935058594
Validation loss: 1.6519550136340562

Epoch: 6| Step: 6
Training loss: 0.30378663539886475
Validation loss: 1.609011564203488

Epoch: 6| Step: 7
Training loss: 0.21570992469787598
Validation loss: 1.6446209287130704

Epoch: 6| Step: 8
Training loss: 0.18748913705348969
Validation loss: 1.6358415234473445

Epoch: 6| Step: 9
Training loss: 0.31643086671829224
Validation loss: 1.635345091742854

Epoch: 6| Step: 10
Training loss: 0.33952486515045166
Validation loss: 1.6560338466398177

Epoch: 6| Step: 11
Training loss: 0.29814255237579346
Validation loss: 1.6677023351833384

Epoch: 6| Step: 12
Training loss: 0.2511198818683624
Validation loss: 1.6914250940404914

Epoch: 6| Step: 13
Training loss: 0.37000730633735657
Validation loss: 1.6957635507788709

Epoch: 462| Step: 0
Training loss: 0.21430793404579163
Validation loss: 1.7052976918476883

Epoch: 6| Step: 1
Training loss: 0.18159367144107819
Validation loss: 1.7346082477159397

Epoch: 6| Step: 2
Training loss: 0.28541433811187744
Validation loss: 1.7312476378615185

Epoch: 6| Step: 3
Training loss: 0.36350977420806885
Validation loss: 1.7168802933026386

Epoch: 6| Step: 4
Training loss: 0.3504791259765625
Validation loss: 1.6923438022213597

Epoch: 6| Step: 5
Training loss: 0.4482021927833557
Validation loss: 1.6607377541962491

Epoch: 6| Step: 6
Training loss: 0.3562002182006836
Validation loss: 1.6447291592115998

Epoch: 6| Step: 7
Training loss: 0.2580503821372986
Validation loss: 1.6412568143619004

Epoch: 6| Step: 8
Training loss: 0.23960460722446442
Validation loss: 1.6449114859745066

Epoch: 6| Step: 9
Training loss: 0.35134369134902954
Validation loss: 1.6383567087111934

Epoch: 6| Step: 10
Training loss: 0.193699449300766
Validation loss: 1.6465382037624237

Epoch: 6| Step: 11
Training loss: 0.4158901572227478
Validation loss: 1.6496577544878888

Epoch: 6| Step: 12
Training loss: 0.3287810683250427
Validation loss: 1.6749522160458308

Epoch: 6| Step: 13
Training loss: 0.2939360737800598
Validation loss: 1.697054878357918

Epoch: 463| Step: 0
Training loss: 0.3237593472003937
Validation loss: 1.6848318615267355

Epoch: 6| Step: 1
Training loss: 0.3863394856452942
Validation loss: 1.686821340232767

Epoch: 6| Step: 2
Training loss: 0.3747953474521637
Validation loss: 1.7246475591454455

Epoch: 6| Step: 3
Training loss: 0.3715972900390625
Validation loss: 1.7133312622706096

Epoch: 6| Step: 4
Training loss: 0.3392519950866699
Validation loss: 1.675600540253424

Epoch: 6| Step: 5
Training loss: 0.164882093667984
Validation loss: 1.6848975894271687

Epoch: 6| Step: 6
Training loss: 0.4188702404499054
Validation loss: 1.6448069798049105

Epoch: 6| Step: 7
Training loss: 0.1125744879245758
Validation loss: 1.6363618950689993

Epoch: 6| Step: 8
Training loss: 0.18122254312038422
Validation loss: 1.658382232471179

Epoch: 6| Step: 9
Training loss: 0.2752050757408142
Validation loss: 1.6780001912065732

Epoch: 6| Step: 10
Training loss: 0.21568092703819275
Validation loss: 1.680599699738205

Epoch: 6| Step: 11
Training loss: 0.24629539251327515
Validation loss: 1.6943716861868416

Epoch: 6| Step: 12
Training loss: 0.3164428174495697
Validation loss: 1.723092354753966

Epoch: 6| Step: 13
Training loss: 0.4130896329879761
Validation loss: 1.7351326263079079

Epoch: 464| Step: 0
Training loss: 0.35793882608413696
Validation loss: 1.7600136649224065

Epoch: 6| Step: 1
Training loss: 0.46887901425361633
Validation loss: 1.7306027149641385

Epoch: 6| Step: 2
Training loss: 0.32892608642578125
Validation loss: 1.7722896619509625

Epoch: 6| Step: 3
Training loss: 0.29636502265930176
Validation loss: 1.7121039295709262

Epoch: 6| Step: 4
Training loss: 0.33706554770469666
Validation loss: 1.7106076850686023

Epoch: 6| Step: 5
Training loss: 0.3704480826854706
Validation loss: 1.6915917415772714

Epoch: 6| Step: 6
Training loss: 0.3476364016532898
Validation loss: 1.6593133813591414

Epoch: 6| Step: 7
Training loss: 0.3322720527648926
Validation loss: 1.6181553615036832

Epoch: 6| Step: 8
Training loss: 0.13763615489006042
Validation loss: 1.6087340859956638

Epoch: 6| Step: 9
Training loss: 0.2503544092178345
Validation loss: 1.6413993694448983

Epoch: 6| Step: 10
Training loss: 0.3859475553035736
Validation loss: 1.6509208756108438

Epoch: 6| Step: 11
Training loss: 0.21292851865291595
Validation loss: 1.6440198677842335

Epoch: 6| Step: 12
Training loss: 0.18884041905403137
Validation loss: 1.6259062815737981

Epoch: 6| Step: 13
Training loss: 0.39044392108917236
Validation loss: 1.6495518684387207

Epoch: 465| Step: 0
Training loss: 0.38424402475357056
Validation loss: 1.6600418783003283

Epoch: 6| Step: 1
Training loss: 0.14796516299247742
Validation loss: 1.700648412268649

Epoch: 6| Step: 2
Training loss: 0.39802291989326477
Validation loss: 1.6870493760672949

Epoch: 6| Step: 3
Training loss: 0.34268850088119507
Validation loss: 1.6543601712872904

Epoch: 6| Step: 4
Training loss: 0.4818398952484131
Validation loss: 1.6508968389162453

Epoch: 6| Step: 5
Training loss: 0.22267736494541168
Validation loss: 1.6297608524240472

Epoch: 6| Step: 6
Training loss: 0.2824151813983917
Validation loss: 1.682677149772644

Epoch: 6| Step: 7
Training loss: 0.22448721528053284
Validation loss: 1.658902092646527

Epoch: 6| Step: 8
Training loss: 0.291042685508728
Validation loss: 1.7015850428612

Epoch: 6| Step: 9
Training loss: 0.2663974463939667
Validation loss: 1.6936557574938702

Epoch: 6| Step: 10
Training loss: 0.2930322289466858
Validation loss: 1.6999817355986564

Epoch: 6| Step: 11
Training loss: 0.23578524589538574
Validation loss: 1.7166564285114247

Epoch: 6| Step: 12
Training loss: 0.2609001398086548
Validation loss: 1.725092267477384

Epoch: 6| Step: 13
Training loss: 0.24345514178276062
Validation loss: 1.7224454931033555

Epoch: 466| Step: 0
Training loss: 0.34247279167175293
Validation loss: 1.7351002154811737

Epoch: 6| Step: 1
Training loss: 0.24327659606933594
Validation loss: 1.717094277822843

Epoch: 6| Step: 2
Training loss: 0.20722098648548126
Validation loss: 1.7025081111538796

Epoch: 6| Step: 3
Training loss: 0.1924009621143341
Validation loss: 1.72968642686003

Epoch: 6| Step: 4
Training loss: 0.29896605014801025
Validation loss: 1.69132052698443

Epoch: 6| Step: 5
Training loss: 0.24848632514476776
Validation loss: 1.6896266116890857

Epoch: 6| Step: 6
Training loss: 0.32066792249679565
Validation loss: 1.684250465003393

Epoch: 6| Step: 7
Training loss: 0.29744768142700195
Validation loss: 1.6746636706013833

Epoch: 6| Step: 8
Training loss: 0.21519669890403748
Validation loss: 1.6669530342983943

Epoch: 6| Step: 9
Training loss: 0.38375890254974365
Validation loss: 1.658563797191907

Epoch: 6| Step: 10
Training loss: 0.1208258643746376
Validation loss: 1.6810150184938986

Epoch: 6| Step: 11
Training loss: 0.3169470429420471
Validation loss: 1.650791541222603

Epoch: 6| Step: 12
Training loss: 0.31492605805397034
Validation loss: 1.6532138278407436

Epoch: 6| Step: 13
Training loss: 0.5310919880867004
Validation loss: 1.6648982724835795

Epoch: 467| Step: 0
Training loss: 0.3141549229621887
Validation loss: 1.6211616454585906

Epoch: 6| Step: 1
Training loss: 0.2571786344051361
Validation loss: 1.6518661796405751

Epoch: 6| Step: 2
Training loss: 0.19926048815250397
Validation loss: 1.6725940909436954

Epoch: 6| Step: 3
Training loss: 0.5100432634353638
Validation loss: 1.7109407173689974

Epoch: 6| Step: 4
Training loss: 0.2563624978065491
Validation loss: 1.7102033245948054

Epoch: 6| Step: 5
Training loss: 0.2836075723171234
Validation loss: 1.7245605927641674

Epoch: 6| Step: 6
Training loss: 0.18803101778030396
Validation loss: 1.6906040419814408

Epoch: 6| Step: 7
Training loss: 0.25352948904037476
Validation loss: 1.7154659314822125

Epoch: 6| Step: 8
Training loss: 0.31220078468322754
Validation loss: 1.7043048668933172

Epoch: 6| Step: 9
Training loss: 0.1731238067150116
Validation loss: 1.7038741291210215

Epoch: 6| Step: 10
Training loss: 0.17863260209560394
Validation loss: 1.6725846080369846

Epoch: 6| Step: 11
Training loss: 0.35733333230018616
Validation loss: 1.674140784048265

Epoch: 6| Step: 12
Training loss: 0.09406217932701111
Validation loss: 1.6804138172057368

Epoch: 6| Step: 13
Training loss: 0.2979414761066437
Validation loss: 1.6947515869653353

Epoch: 468| Step: 0
Training loss: 0.23755484819412231
Validation loss: 1.6718407369429065

Epoch: 6| Step: 1
Training loss: 0.2817405164241791
Validation loss: 1.6843819496452168

Epoch: 6| Step: 2
Training loss: 0.2863171100616455
Validation loss: 1.7085512030509211

Epoch: 6| Step: 3
Training loss: 0.30986353754997253
Validation loss: 1.6606481767469836

Epoch: 6| Step: 4
Training loss: 0.3237643837928772
Validation loss: 1.6385360738282562

Epoch: 6| Step: 5
Training loss: 0.3248281478881836
Validation loss: 1.6074344009481452

Epoch: 6| Step: 6
Training loss: 0.2342287003993988
Validation loss: 1.6125694846594205

Epoch: 6| Step: 7
Training loss: 0.2181089222431183
Validation loss: 1.581773022169708

Epoch: 6| Step: 8
Training loss: 0.3523868918418884
Validation loss: 1.5901078043445465

Epoch: 6| Step: 9
Training loss: 0.29437243938446045
Validation loss: 1.5961899680476035

Epoch: 6| Step: 10
Training loss: 0.23859138786792755
Validation loss: 1.6025278106812508

Epoch: 6| Step: 11
Training loss: 0.26450222730636597
Validation loss: 1.6403768036955146

Epoch: 6| Step: 12
Training loss: 0.4537540078163147
Validation loss: 1.6302001924924954

Epoch: 6| Step: 13
Training loss: 0.23523327708244324
Validation loss: 1.6634510742720736

Epoch: 469| Step: 0
Training loss: 0.38271695375442505
Validation loss: 1.6841464452846076

Epoch: 6| Step: 1
Training loss: 0.37733957171440125
Validation loss: 1.710112332015909

Epoch: 6| Step: 2
Training loss: 0.26324784755706787
Validation loss: 1.6915763603743685

Epoch: 6| Step: 3
Training loss: 0.4100005626678467
Validation loss: 1.6519259829674997

Epoch: 6| Step: 4
Training loss: 0.14624759554862976
Validation loss: 1.6606014608055033

Epoch: 6| Step: 5
Training loss: 0.39042264223098755
Validation loss: 1.6185839176177979

Epoch: 6| Step: 6
Training loss: 0.1956184208393097
Validation loss: 1.6241259792799592

Epoch: 6| Step: 7
Training loss: 0.2225116640329361
Validation loss: 1.6350185217395905

Epoch: 6| Step: 8
Training loss: 0.17454159259796143
Validation loss: 1.6611602293547763

Epoch: 6| Step: 9
Training loss: 0.18174725770950317
Validation loss: 1.65081222339343

Epoch: 6| Step: 10
Training loss: 0.11327603459358215
Validation loss: 1.6717671399475427

Epoch: 6| Step: 11
Training loss: 0.12833845615386963
Validation loss: 1.687024849717335

Epoch: 6| Step: 12
Training loss: 0.5265547037124634
Validation loss: 1.6633133804926308

Epoch: 6| Step: 13
Training loss: 0.5944350361824036
Validation loss: 1.655218501244822

Epoch: 470| Step: 0
Training loss: 0.29603612422943115
Validation loss: 1.6314177782304826

Epoch: 6| Step: 1
Training loss: 0.46336662769317627
Validation loss: 1.662517511716453

Epoch: 6| Step: 2
Training loss: 0.29252082109451294
Validation loss: 1.6259287384248549

Epoch: 6| Step: 3
Training loss: 0.217600479722023
Validation loss: 1.6674734187382523

Epoch: 6| Step: 4
Training loss: 0.37827256321907043
Validation loss: 1.6602659097281836

Epoch: 6| Step: 5
Training loss: 0.21618019044399261
Validation loss: 1.648374338303843

Epoch: 6| Step: 6
Training loss: 0.19977179169654846
Validation loss: 1.653355949668474

Epoch: 6| Step: 7
Training loss: 0.10286234319210052
Validation loss: 1.6920622061657649

Epoch: 6| Step: 8
Training loss: 0.30394402146339417
Validation loss: 1.6580028559571953

Epoch: 6| Step: 9
Training loss: 0.27515196800231934
Validation loss: 1.6467609495245001

Epoch: 6| Step: 10
Training loss: 0.0937415063381195
Validation loss: 1.6230771157049364

Epoch: 6| Step: 11
Training loss: 0.3490595817565918
Validation loss: 1.6504356912387315

Epoch: 6| Step: 12
Training loss: 0.28419971466064453
Validation loss: 1.6246727141000892

Epoch: 6| Step: 13
Training loss: 0.24713659286499023
Validation loss: 1.6381545759016467

Epoch: 471| Step: 0
Training loss: 0.15685021877288818
Validation loss: 1.644815230882296

Epoch: 6| Step: 1
Training loss: 0.17779287695884705
Validation loss: 1.667536707334621

Epoch: 6| Step: 2
Training loss: 0.49566715955734253
Validation loss: 1.6727230074585124

Epoch: 6| Step: 3
Training loss: 0.2615175247192383
Validation loss: 1.6753452875280892

Epoch: 6| Step: 4
Training loss: 0.28891828656196594
Validation loss: 1.7324774970290482

Epoch: 6| Step: 5
Training loss: 0.2612413763999939
Validation loss: 1.7483940893603909

Epoch: 6| Step: 6
Training loss: 0.4110719561576843
Validation loss: 1.7550592550667383

Epoch: 6| Step: 7
Training loss: 0.2199753224849701
Validation loss: 1.7779057679637786

Epoch: 6| Step: 8
Training loss: 0.23243555426597595
Validation loss: 1.7471136021357712

Epoch: 6| Step: 9
Training loss: 0.3164653778076172
Validation loss: 1.7164999092778852

Epoch: 6| Step: 10
Training loss: 0.3237651586532593
Validation loss: 1.6981867410803353

Epoch: 6| Step: 11
Training loss: 0.2865525186061859
Validation loss: 1.6852805652926046

Epoch: 6| Step: 12
Training loss: 0.3813658654689789
Validation loss: 1.6526639717881397

Epoch: 6| Step: 13
Training loss: 0.2383398413658142
Validation loss: 1.654424273839561

Epoch: 472| Step: 0
Training loss: 0.18093250691890717
Validation loss: 1.6634922168588127

Epoch: 6| Step: 1
Training loss: 0.35989707708358765
Validation loss: 1.6606201523093767

Epoch: 6| Step: 2
Training loss: 0.4205029010772705
Validation loss: 1.6467388035148702

Epoch: 6| Step: 3
Training loss: 0.2381298691034317
Validation loss: 1.5944486074550177

Epoch: 6| Step: 4
Training loss: 0.3239901661872864
Validation loss: 1.6636780602957613

Epoch: 6| Step: 5
Training loss: 0.29168105125427246
Validation loss: 1.6355341301169446

Epoch: 6| Step: 6
Training loss: 0.41772764921188354
Validation loss: 1.6956477062676543

Epoch: 6| Step: 7
Training loss: 0.20858316123485565
Validation loss: 1.7146250881174558

Epoch: 6| Step: 8
Training loss: 0.23642699420452118
Validation loss: 1.6873366179004792

Epoch: 6| Step: 9
Training loss: 0.23893925547599792
Validation loss: 1.6968406810555408

Epoch: 6| Step: 10
Training loss: 0.3035675585269928
Validation loss: 1.6899335666369366

Epoch: 6| Step: 11
Training loss: 0.21819737553596497
Validation loss: 1.6741069132281887

Epoch: 6| Step: 12
Training loss: 0.1806143969297409
Validation loss: 1.6789663953165854

Epoch: 6| Step: 13
Training loss: 0.24082797765731812
Validation loss: 1.677804426480365

Epoch: 473| Step: 0
Training loss: 0.1682663857936859
Validation loss: 1.695625404516856

Epoch: 6| Step: 1
Training loss: 0.2107396274805069
Validation loss: 1.6892771374794744

Epoch: 6| Step: 2
Training loss: 0.2517074942588806
Validation loss: 1.7176522683071833

Epoch: 6| Step: 3
Training loss: 0.44924256205558777
Validation loss: 1.757504795187263

Epoch: 6| Step: 4
Training loss: 0.2525634765625
Validation loss: 1.7449135370151971

Epoch: 6| Step: 5
Training loss: 0.2467919886112213
Validation loss: 1.7401287940240675

Epoch: 6| Step: 6
Training loss: 0.23518763482570648
Validation loss: 1.7267199664987543

Epoch: 6| Step: 7
Training loss: 0.299066424369812
Validation loss: 1.714286247889201

Epoch: 6| Step: 8
Training loss: 0.26885831356048584
Validation loss: 1.6968346026635939

Epoch: 6| Step: 9
Training loss: 0.4159638583660126
Validation loss: 1.682255712888574

Epoch: 6| Step: 10
Training loss: 0.31366217136383057
Validation loss: 1.6355331174788936

Epoch: 6| Step: 11
Training loss: 0.264402836561203
Validation loss: 1.6576898854265931

Epoch: 6| Step: 12
Training loss: 0.2603378891944885
Validation loss: 1.6201785046567199

Epoch: 6| Step: 13
Training loss: 0.19959066808223724
Validation loss: 1.6227212285482755

Epoch: 474| Step: 0
Training loss: 0.4168199896812439
Validation loss: 1.6104437458899714

Epoch: 6| Step: 1
Training loss: 0.23114323616027832
Validation loss: 1.6622645188403387

Epoch: 6| Step: 2
Training loss: 0.3300940692424774
Validation loss: 1.6812261496820757

Epoch: 6| Step: 3
Training loss: 0.4813133776187897
Validation loss: 1.6689676456553961

Epoch: 6| Step: 4
Training loss: 0.2585962414741516
Validation loss: 1.7036827482203

Epoch: 6| Step: 5
Training loss: 0.31889134645462036
Validation loss: 1.7329698172948693

Epoch: 6| Step: 6
Training loss: 0.16377988457679749
Validation loss: 1.712103324551736

Epoch: 6| Step: 7
Training loss: 0.23264598846435547
Validation loss: 1.7249142956990067

Epoch: 6| Step: 8
Training loss: 0.15690994262695312
Validation loss: 1.7189821735505135

Epoch: 6| Step: 9
Training loss: 0.1775617003440857
Validation loss: 1.750383565502782

Epoch: 6| Step: 10
Training loss: 0.19542567431926727
Validation loss: 1.7252900587615145

Epoch: 6| Step: 11
Training loss: 0.24404175579547882
Validation loss: 1.7228192398625035

Epoch: 6| Step: 12
Training loss: 0.29438677430152893
Validation loss: 1.7172849476337433

Epoch: 6| Step: 13
Training loss: 0.5210403800010681
Validation loss: 1.7159531398486065

Epoch: 475| Step: 0
Training loss: 0.3068344295024872
Validation loss: 1.7362853391196138

Epoch: 6| Step: 1
Training loss: 0.25313740968704224
Validation loss: 1.7276620159866989

Epoch: 6| Step: 2
Training loss: 0.23705387115478516
Validation loss: 1.7421567491305772

Epoch: 6| Step: 3
Training loss: 0.2284826785326004
Validation loss: 1.707824271212342

Epoch: 6| Step: 4
Training loss: 0.3085281252861023
Validation loss: 1.7176604065843808

Epoch: 6| Step: 5
Training loss: 0.2676640748977661
Validation loss: 1.6976696650187175

Epoch: 6| Step: 6
Training loss: 0.3346608281135559
Validation loss: 1.6841184862198368

Epoch: 6| Step: 7
Training loss: 0.26298704743385315
Validation loss: 1.6994111550751554

Epoch: 6| Step: 8
Training loss: 0.41201797127723694
Validation loss: 1.6991540334557975

Epoch: 6| Step: 9
Training loss: 0.14582335948944092
Validation loss: 1.7176237670324181

Epoch: 6| Step: 10
Training loss: 0.16791124641895294
Validation loss: 1.748067226461185

Epoch: 6| Step: 11
Training loss: 0.2650755047798157
Validation loss: 1.7206378470184982

Epoch: 6| Step: 12
Training loss: 0.2603790760040283
Validation loss: 1.6986413360923849

Epoch: 6| Step: 13
Training loss: 0.30376994609832764
Validation loss: 1.6796549956003826

Epoch: 476| Step: 0
Training loss: 0.3733634352684021
Validation loss: 1.6200521735734836

Epoch: 6| Step: 1
Training loss: 0.3976737856864929
Validation loss: 1.6082817226327875

Epoch: 6| Step: 2
Training loss: 0.35919150710105896
Validation loss: 1.616331825974167

Epoch: 6| Step: 3
Training loss: 0.3097342550754547
Validation loss: 1.6354713747578282

Epoch: 6| Step: 4
Training loss: 0.2086273431777954
Validation loss: 1.6152380743334371

Epoch: 6| Step: 5
Training loss: 0.20095866918563843
Validation loss: 1.6740078605631346

Epoch: 6| Step: 6
Training loss: 0.24818414449691772
Validation loss: 1.670754804406115

Epoch: 6| Step: 7
Training loss: 0.17881539463996887
Validation loss: 1.7194283341848722

Epoch: 6| Step: 8
Training loss: 0.21045486629009247
Validation loss: 1.7553042801477576

Epoch: 6| Step: 9
Training loss: 0.372010201215744
Validation loss: 1.7555666046757852

Epoch: 6| Step: 10
Training loss: 0.3655264377593994
Validation loss: 1.7267706599286807

Epoch: 6| Step: 11
Training loss: 0.22214242815971375
Validation loss: 1.7261735713610085

Epoch: 6| Step: 12
Training loss: 0.2253180742263794
Validation loss: 1.6994227811854372

Epoch: 6| Step: 13
Training loss: 0.1177021786570549
Validation loss: 1.7002859166873399

Epoch: 477| Step: 0
Training loss: 0.34626656770706177
Validation loss: 1.6958605512495963

Epoch: 6| Step: 1
Training loss: 0.3407197594642639
Validation loss: 1.6656377212975615

Epoch: 6| Step: 2
Training loss: 0.3994392156600952
Validation loss: 1.6587641892894622

Epoch: 6| Step: 3
Training loss: 0.21368154883384705
Validation loss: 1.6133695417834866

Epoch: 6| Step: 4
Training loss: 0.24426725506782532
Validation loss: 1.6522594010958107

Epoch: 6| Step: 5
Training loss: 0.2867271304130554
Validation loss: 1.652707193487434

Epoch: 6| Step: 6
Training loss: 0.2949632406234741
Validation loss: 1.6595285348994757

Epoch: 6| Step: 7
Training loss: 0.22465714812278748
Validation loss: 1.6844260141413698

Epoch: 6| Step: 8
Training loss: 0.29762348532676697
Validation loss: 1.7060862959072154

Epoch: 6| Step: 9
Training loss: 0.2737315893173218
Validation loss: 1.677897177716737

Epoch: 6| Step: 10
Training loss: 0.16365323960781097
Validation loss: 1.7015519308787521

Epoch: 6| Step: 11
Training loss: 0.14222058653831482
Validation loss: 1.698395566273761

Epoch: 6| Step: 12
Training loss: 0.3023390769958496
Validation loss: 1.6773749679647467

Epoch: 6| Step: 13
Training loss: 0.37861666083335876
Validation loss: 1.6736772060394287

Epoch: 478| Step: 0
Training loss: 0.14607781171798706
Validation loss: 1.620035074090445

Epoch: 6| Step: 1
Training loss: 0.4356524348258972
Validation loss: 1.6462337740005986

Epoch: 6| Step: 2
Training loss: 0.1978953778743744
Validation loss: 1.6274737363220544

Epoch: 6| Step: 3
Training loss: 0.39011088013648987
Validation loss: 1.6360370792368406

Epoch: 6| Step: 4
Training loss: 0.43037229776382446
Validation loss: 1.6101955072854155

Epoch: 6| Step: 5
Training loss: 0.2942359447479248
Validation loss: 1.603691292065446

Epoch: 6| Step: 6
Training loss: 0.2562284469604492
Validation loss: 1.6077580862147833

Epoch: 6| Step: 7
Training loss: 0.23942670226097107
Validation loss: 1.6451797305896718

Epoch: 6| Step: 8
Training loss: 0.40217021107673645
Validation loss: 1.6690757223354873

Epoch: 6| Step: 9
Training loss: 0.2549619674682617
Validation loss: 1.65516149228619

Epoch: 6| Step: 10
Training loss: 0.20777198672294617
Validation loss: 1.6630241973425752

Epoch: 6| Step: 11
Training loss: 0.21348309516906738
Validation loss: 1.6892307061021046

Epoch: 6| Step: 12
Training loss: 0.12452702969312668
Validation loss: 1.6820716178545387

Epoch: 6| Step: 13
Training loss: 0.14893756806850433
Validation loss: 1.6437183695454751

Epoch: 479| Step: 0
Training loss: 0.23684993386268616
Validation loss: 1.6396656613196097

Epoch: 6| Step: 1
Training loss: 0.09361991286277771
Validation loss: 1.6379446547518495

Epoch: 6| Step: 2
Training loss: 0.28009605407714844
Validation loss: 1.6390644414450533

Epoch: 6| Step: 3
Training loss: 0.2929701805114746
Validation loss: 1.6241118049108854

Epoch: 6| Step: 4
Training loss: 0.2536473274230957
Validation loss: 1.6150530512614916

Epoch: 6| Step: 5
Training loss: 0.3655228018760681
Validation loss: 1.6222745116038988

Epoch: 6| Step: 6
Training loss: 0.31351107358932495
Validation loss: 1.6390827355846282

Epoch: 6| Step: 7
Training loss: 0.37279173731803894
Validation loss: 1.6525813648777623

Epoch: 6| Step: 8
Training loss: 0.2519126832485199
Validation loss: 1.6392071477828487

Epoch: 6| Step: 9
Training loss: 0.3732749819755554
Validation loss: 1.6539656257116666

Epoch: 6| Step: 10
Training loss: 0.22945544123649597
Validation loss: 1.6662999942738523

Epoch: 6| Step: 11
Training loss: 0.19122029840946198
Validation loss: 1.6254884594230241

Epoch: 6| Step: 12
Training loss: 0.18552517890930176
Validation loss: 1.6574841955656647

Epoch: 6| Step: 13
Training loss: 0.36519134044647217
Validation loss: 1.6198438957173338

Epoch: 480| Step: 0
Training loss: 0.1552617847919464
Validation loss: 1.6120287192765104

Epoch: 6| Step: 1
Training loss: 0.22366008162498474
Validation loss: 1.6709756325649958

Epoch: 6| Step: 2
Training loss: 0.2400929033756256
Validation loss: 1.6746011485335648

Epoch: 6| Step: 3
Training loss: 0.33851996064186096
Validation loss: 1.6740283376427108

Epoch: 6| Step: 4
Training loss: 0.28104498982429504
Validation loss: 1.6876922538203578

Epoch: 6| Step: 5
Training loss: 0.3343048095703125
Validation loss: 1.6908671548289638

Epoch: 6| Step: 6
Training loss: 0.49791884422302246
Validation loss: 1.722596388991161

Epoch: 6| Step: 7
Training loss: 0.17579452693462372
Validation loss: 1.7106440092927666

Epoch: 6| Step: 8
Training loss: 0.21510358154773712
Validation loss: 1.6634158639497654

Epoch: 6| Step: 9
Training loss: 0.27591001987457275
Validation loss: 1.6538500452554354

Epoch: 6| Step: 10
Training loss: 0.5304339528083801
Validation loss: 1.6432174867199314

Epoch: 6| Step: 11
Training loss: 0.18377023935317993
Validation loss: 1.6075309271453528

Epoch: 6| Step: 12
Training loss: 0.18121905624866486
Validation loss: 1.6170874705878637

Epoch: 6| Step: 13
Training loss: 0.22277535498142242
Validation loss: 1.623212319548412

Epoch: 481| Step: 0
Training loss: 0.25496751070022583
Validation loss: 1.5992281834284465

Epoch: 6| Step: 1
Training loss: 0.3258450925350189
Validation loss: 1.5957123758972331

Epoch: 6| Step: 2
Training loss: 0.2028021663427353
Validation loss: 1.6224685330544748

Epoch: 6| Step: 3
Training loss: 0.15942639112472534
Validation loss: 1.6937782328615907

Epoch: 6| Step: 4
Training loss: 0.1340324878692627
Validation loss: 1.6895094674120668

Epoch: 6| Step: 5
Training loss: 0.37538015842437744
Validation loss: 1.740735580844264

Epoch: 6| Step: 6
Training loss: 0.39829689264297485
Validation loss: 1.7381915020686325

Epoch: 6| Step: 7
Training loss: 0.3304828703403473
Validation loss: 1.7704294214966476

Epoch: 6| Step: 8
Training loss: 0.30788323283195496
Validation loss: 1.7254577298318186

Epoch: 6| Step: 9
Training loss: 0.24666643142700195
Validation loss: 1.6615744431813557

Epoch: 6| Step: 10
Training loss: 0.3413161635398865
Validation loss: 1.6445303411893948

Epoch: 6| Step: 11
Training loss: 0.49377670884132385
Validation loss: 1.6116659897629932

Epoch: 6| Step: 12
Training loss: 0.3147071599960327
Validation loss: 1.6225835982189383

Epoch: 6| Step: 13
Training loss: 0.28280341625213623
Validation loss: 1.5979720764262701

Epoch: 482| Step: 0
Training loss: 0.19788365066051483
Validation loss: 1.5907583916059105

Epoch: 6| Step: 1
Training loss: 0.286712646484375
Validation loss: 1.6135575848241006

Epoch: 6| Step: 2
Training loss: 0.3691220283508301
Validation loss: 1.6538694417604836

Epoch: 6| Step: 3
Training loss: 0.2642563581466675
Validation loss: 1.673808382403466

Epoch: 6| Step: 4
Training loss: 0.2520020008087158
Validation loss: 1.6942527037794872

Epoch: 6| Step: 5
Training loss: 0.2698964774608612
Validation loss: 1.709905493643976

Epoch: 6| Step: 6
Training loss: 0.27799680829048157
Validation loss: 1.7032977637424265

Epoch: 6| Step: 7
Training loss: 0.30952221155166626
Validation loss: 1.6683789145561956

Epoch: 6| Step: 8
Training loss: 0.19880282878875732
Validation loss: 1.6490573088328044

Epoch: 6| Step: 9
Training loss: 0.3434314429759979
Validation loss: 1.6807077866728588

Epoch: 6| Step: 10
Training loss: 0.1254831850528717
Validation loss: 1.6903758754012406

Epoch: 6| Step: 11
Training loss: 0.28541862964630127
Validation loss: 1.6822201103292487

Epoch: 6| Step: 12
Training loss: 0.2550671696662903
Validation loss: 1.7099639574686687

Epoch: 6| Step: 13
Training loss: 0.26660192012786865
Validation loss: 1.679220002184632

Epoch: 483| Step: 0
Training loss: 0.22292117774486542
Validation loss: 1.7166084833042596

Epoch: 6| Step: 1
Training loss: 0.31661179661750793
Validation loss: 1.707807151220178

Epoch: 6| Step: 2
Training loss: 0.3578415513038635
Validation loss: 1.7099669287281651

Epoch: 6| Step: 3
Training loss: 0.2240486741065979
Validation loss: 1.7011836574923607

Epoch: 6| Step: 4
Training loss: 0.3683331608772278
Validation loss: 1.7047545717608543

Epoch: 6| Step: 5
Training loss: 0.2745968997478485
Validation loss: 1.690767329226258

Epoch: 6| Step: 6
Training loss: 0.42628973722457886
Validation loss: 1.7027257168164818

Epoch: 6| Step: 7
Training loss: 0.34979256987571716
Validation loss: 1.6793249550686087

Epoch: 6| Step: 8
Training loss: 0.3506172299385071
Validation loss: 1.7052830419232767

Epoch: 6| Step: 9
Training loss: 0.2566456198692322
Validation loss: 1.6671294884015155

Epoch: 6| Step: 10
Training loss: 0.27130958437919617
Validation loss: 1.6540700261310866

Epoch: 6| Step: 11
Training loss: 0.1623576283454895
Validation loss: 1.6200422599751463

Epoch: 6| Step: 12
Training loss: 0.22906622290611267
Validation loss: 1.6038864684361283

Epoch: 6| Step: 13
Training loss: 0.38392722606658936
Validation loss: 1.6082436166783816

Epoch: 484| Step: 0
Training loss: 0.28021135926246643
Validation loss: 1.5818814321230816

Epoch: 6| Step: 1
Training loss: 0.48221713304519653
Validation loss: 1.5829541247378114

Epoch: 6| Step: 2
Training loss: 0.33987167477607727
Validation loss: 1.5993759657747002

Epoch: 6| Step: 3
Training loss: 0.3095771074295044
Validation loss: 1.6154634388544227

Epoch: 6| Step: 4
Training loss: 0.2519148588180542
Validation loss: 1.6182817220687866

Epoch: 6| Step: 5
Training loss: 0.3382510840892792
Validation loss: 1.624652090892997

Epoch: 6| Step: 6
Training loss: 0.1539311707019806
Validation loss: 1.655783163603916

Epoch: 6| Step: 7
Training loss: 0.2686645984649658
Validation loss: 1.6691926192211848

Epoch: 6| Step: 8
Training loss: 0.22839927673339844
Validation loss: 1.6739088155890023

Epoch: 6| Step: 9
Training loss: 0.2451247125864029
Validation loss: 1.7127278248469036

Epoch: 6| Step: 10
Training loss: 0.2866077721118927
Validation loss: 1.6610440483657263

Epoch: 6| Step: 11
Training loss: 0.14604300260543823
Validation loss: 1.658255983424443

Epoch: 6| Step: 12
Training loss: 0.17291393876075745
Validation loss: 1.6134124391822404

Epoch: 6| Step: 13
Training loss: 0.16830934584140778
Validation loss: 1.6183822424181047

Epoch: 485| Step: 0
Training loss: 0.14010363817214966
Validation loss: 1.6066163047667472

Epoch: 6| Step: 1
Training loss: 0.3974372148513794
Validation loss: 1.6044938205390848

Epoch: 6| Step: 2
Training loss: 0.18303516507148743
Validation loss: 1.588667751640402

Epoch: 6| Step: 3
Training loss: 0.28126853704452515
Validation loss: 1.625582855234864

Epoch: 6| Step: 4
Training loss: 0.2137967050075531
Validation loss: 1.6564957993004912

Epoch: 6| Step: 5
Training loss: 0.3269580006599426
Validation loss: 1.625986332534462

Epoch: 6| Step: 6
Training loss: 0.31791067123413086
Validation loss: 1.647665294267798

Epoch: 6| Step: 7
Training loss: 0.24145394563674927
Validation loss: 1.6457087455257293

Epoch: 6| Step: 8
Training loss: 0.1705119013786316
Validation loss: 1.6621634985810967

Epoch: 6| Step: 9
Training loss: 0.2402406483888626
Validation loss: 1.6449417414203766

Epoch: 6| Step: 10
Training loss: 0.45448777079582214
Validation loss: 1.6340060669888732

Epoch: 6| Step: 11
Training loss: 0.11349214613437653
Validation loss: 1.6409362618641188

Epoch: 6| Step: 12
Training loss: 0.2086954563856125
Validation loss: 1.617956292244696

Epoch: 6| Step: 13
Training loss: 0.34223777055740356
Validation loss: 1.6386231325005973

Epoch: 486| Step: 0
Training loss: 0.2539593577384949
Validation loss: 1.6361364600478963

Epoch: 6| Step: 1
Training loss: 0.20679955184459686
Validation loss: 1.6666006375384588

Epoch: 6| Step: 2
Training loss: 0.3815721869468689
Validation loss: 1.6745912656989148

Epoch: 6| Step: 3
Training loss: 0.31028640270233154
Validation loss: 1.6816753443851267

Epoch: 6| Step: 4
Training loss: 0.289527952671051
Validation loss: 1.6896312185513076

Epoch: 6| Step: 5
Training loss: 0.30159637331962585
Validation loss: 1.680943912075412

Epoch: 6| Step: 6
Training loss: 0.2282295525074005
Validation loss: 1.6697382221939743

Epoch: 6| Step: 7
Training loss: 0.29278308153152466
Validation loss: 1.6885245557754271

Epoch: 6| Step: 8
Training loss: 0.2274271547794342
Validation loss: 1.6618845360253447

Epoch: 6| Step: 9
Training loss: 0.24967658519744873
Validation loss: 1.665886991767473

Epoch: 6| Step: 10
Training loss: 0.2888680100440979
Validation loss: 1.6842687463247648

Epoch: 6| Step: 11
Training loss: 0.22269068658351898
Validation loss: 1.6812242820698728

Epoch: 6| Step: 12
Training loss: 0.23277819156646729
Validation loss: 1.6689625914378832

Epoch: 6| Step: 13
Training loss: 0.3128736913204193
Validation loss: 1.6501235000548824

Epoch: 487| Step: 0
Training loss: 0.19763237237930298
Validation loss: 1.6164571726193993

Epoch: 6| Step: 1
Training loss: 0.2932577133178711
Validation loss: 1.6472616323860743

Epoch: 6| Step: 2
Training loss: 0.16161872446537018
Validation loss: 1.631539781888326

Epoch: 6| Step: 3
Training loss: 0.2195790559053421
Validation loss: 1.6308098877629926

Epoch: 6| Step: 4
Training loss: 0.22234362363815308
Validation loss: 1.634092104050421

Epoch: 6| Step: 5
Training loss: 0.19024191796779633
Validation loss: 1.655168455134156

Epoch: 6| Step: 6
Training loss: 0.23733291029930115
Validation loss: 1.635538875415761

Epoch: 6| Step: 7
Training loss: 0.2805526554584503
Validation loss: 1.6776182459246727

Epoch: 6| Step: 8
Training loss: 0.2668553590774536
Validation loss: 1.7120702407693351

Epoch: 6| Step: 9
Training loss: 0.3204334080219269
Validation loss: 1.6800423770822503

Epoch: 6| Step: 10
Training loss: 0.30179619789123535
Validation loss: 1.6800961712355256

Epoch: 6| Step: 11
Training loss: 0.3524995446205139
Validation loss: 1.643499760217564

Epoch: 6| Step: 12
Training loss: 0.26713883876800537
Validation loss: 1.6208469072977703

Epoch: 6| Step: 13
Training loss: 0.20404213666915894
Validation loss: 1.5879227692081082

Epoch: 488| Step: 0
Training loss: 0.2559368908405304
Validation loss: 1.615775651829217

Epoch: 6| Step: 1
Training loss: 0.2625567615032196
Validation loss: 1.6096772980946366

Epoch: 6| Step: 2
Training loss: 0.23527228832244873
Validation loss: 1.5986914762886621

Epoch: 6| Step: 3
Training loss: 0.21954502165317535
Validation loss: 1.5991031085291216

Epoch: 6| Step: 4
Training loss: 0.22154884040355682
Validation loss: 1.5959020865860807

Epoch: 6| Step: 5
Training loss: 0.24403974413871765
Validation loss: 1.624773668986495

Epoch: 6| Step: 6
Training loss: 0.2664930820465088
Validation loss: 1.629166538997363

Epoch: 6| Step: 7
Training loss: 0.27568942308425903
Validation loss: 1.6600844783167685

Epoch: 6| Step: 8
Training loss: 0.30494266748428345
Validation loss: 1.6564518367090533

Epoch: 6| Step: 9
Training loss: 0.3278703987598419
Validation loss: 1.6735201240867696

Epoch: 6| Step: 10
Training loss: 0.14095525443553925
Validation loss: 1.712586642593466

Epoch: 6| Step: 11
Training loss: 0.3143397569656372
Validation loss: 1.6832999772922967

Epoch: 6| Step: 12
Training loss: 0.13568736612796783
Validation loss: 1.6899167773544148

Epoch: 6| Step: 13
Training loss: 0.2360464185476303
Validation loss: 1.62135390568805

Epoch: 489| Step: 0
Training loss: 0.07651365548372269
Validation loss: 1.648559324202999

Epoch: 6| Step: 1
Training loss: 0.1997705101966858
Validation loss: 1.6254212740928895

Epoch: 6| Step: 2
Training loss: 0.25113916397094727
Validation loss: 1.6190122250587708

Epoch: 6| Step: 3
Training loss: 0.2569804787635803
Validation loss: 1.59534587014106

Epoch: 6| Step: 4
Training loss: 0.26219019293785095
Validation loss: 1.6297972445846887

Epoch: 6| Step: 5
Training loss: 0.2729280889034271
Validation loss: 1.649378917550528

Epoch: 6| Step: 6
Training loss: 0.27770692110061646
Validation loss: 1.6709221511758783

Epoch: 6| Step: 7
Training loss: 0.21403636038303375
Validation loss: 1.677395598862761

Epoch: 6| Step: 8
Training loss: 0.1252899467945099
Validation loss: 1.669778891789016

Epoch: 6| Step: 9
Training loss: 0.5314511656761169
Validation loss: 1.6693441380736649

Epoch: 6| Step: 10
Training loss: 0.16689950227737427
Validation loss: 1.6840975854986457

Epoch: 6| Step: 11
Training loss: 0.25064095854759216
Validation loss: 1.6491168993775562

Epoch: 6| Step: 12
Training loss: 0.35692083835601807
Validation loss: 1.636694565896065

Epoch: 6| Step: 13
Training loss: 0.10337046533823013
Validation loss: 1.656328389721532

Epoch: 490| Step: 0
Training loss: 0.3275737166404724
Validation loss: 1.6264662178613807

Epoch: 6| Step: 1
Training loss: 0.15177559852600098
Validation loss: 1.6336479866376488

Epoch: 6| Step: 2
Training loss: 0.20286698639392853
Validation loss: 1.612853588596467

Epoch: 6| Step: 3
Training loss: 0.1704632043838501
Validation loss: 1.617837449555756

Epoch: 6| Step: 4
Training loss: 0.21187174320220947
Validation loss: 1.648953527532598

Epoch: 6| Step: 5
Training loss: 0.3198143243789673
Validation loss: 1.6601011881264307

Epoch: 6| Step: 6
Training loss: 0.28649380803108215
Validation loss: 1.6631494683604087

Epoch: 6| Step: 7
Training loss: 0.20936638116836548
Validation loss: 1.6703767891853087

Epoch: 6| Step: 8
Training loss: 0.4651409983634949
Validation loss: 1.6408974047630065

Epoch: 6| Step: 9
Training loss: 0.16566604375839233
Validation loss: 1.6543543466957666

Epoch: 6| Step: 10
Training loss: 0.31419074535369873
Validation loss: 1.6270184311815488

Epoch: 6| Step: 11
Training loss: 0.24417206645011902
Validation loss: 1.6402434251641715

Epoch: 6| Step: 12
Training loss: 0.2988840639591217
Validation loss: 1.6233315724198536

Epoch: 6| Step: 13
Training loss: 0.23196002840995789
Validation loss: 1.644778936139999

Epoch: 491| Step: 0
Training loss: 0.2149258255958557
Validation loss: 1.6469570513694518

Epoch: 6| Step: 1
Training loss: 0.23868931829929352
Validation loss: 1.6393895469686037

Epoch: 6| Step: 2
Training loss: 0.16146071255207062
Validation loss: 1.6536052560293546

Epoch: 6| Step: 3
Training loss: 0.24445796012878418
Validation loss: 1.6604822476704915

Epoch: 6| Step: 4
Training loss: 0.3178858757019043
Validation loss: 1.624291532783098

Epoch: 6| Step: 5
Training loss: 0.20447701215744019
Validation loss: 1.6456729968388875

Epoch: 6| Step: 6
Training loss: 0.2465871423482895
Validation loss: 1.632296331467167

Epoch: 6| Step: 7
Training loss: 0.3653091788291931
Validation loss: 1.6771316887230001

Epoch: 6| Step: 8
Training loss: 0.3423488140106201
Validation loss: 1.68057499136976

Epoch: 6| Step: 9
Training loss: 0.3172406852245331
Validation loss: 1.6675510778222034

Epoch: 6| Step: 10
Training loss: 0.12111793458461761
Validation loss: 1.6659214035157235

Epoch: 6| Step: 11
Training loss: 0.20348146557807922
Validation loss: 1.6257214443657988

Epoch: 6| Step: 12
Training loss: 0.3126785159111023
Validation loss: 1.643382441612982

Epoch: 6| Step: 13
Training loss: 0.32838475704193115
Validation loss: 1.624094473418369

Epoch: 492| Step: 0
Training loss: 0.23344109952449799
Validation loss: 1.6266823667351917

Epoch: 6| Step: 1
Training loss: 0.16765420138835907
Validation loss: 1.6201415715679046

Epoch: 6| Step: 2
Training loss: 0.2440808266401291
Validation loss: 1.6274889951111169

Epoch: 6| Step: 3
Training loss: 0.26553329825401306
Validation loss: 1.6092507185474518

Epoch: 6| Step: 4
Training loss: 0.29432255029678345
Validation loss: 1.5957147357284382

Epoch: 6| Step: 5
Training loss: 0.20611897110939026
Validation loss: 1.5976521007476314

Epoch: 6| Step: 6
Training loss: 0.3497233986854553
Validation loss: 1.5998501457193846

Epoch: 6| Step: 7
Training loss: 0.1667715609073639
Validation loss: 1.6032958248610139

Epoch: 6| Step: 8
Training loss: 0.2405272126197815
Validation loss: 1.6277521348768664

Epoch: 6| Step: 9
Training loss: 0.12522831559181213
Validation loss: 1.6948414810242192

Epoch: 6| Step: 10
Training loss: 0.403413325548172
Validation loss: 1.6875397248934674

Epoch: 6| Step: 11
Training loss: 0.21143952012062073
Validation loss: 1.6929272105616908

Epoch: 6| Step: 12
Training loss: 0.354322612285614
Validation loss: 1.69806807784624

Epoch: 6| Step: 13
Training loss: 0.3190731704235077
Validation loss: 1.6979291964602727

Epoch: 493| Step: 0
Training loss: 0.2691807746887207
Validation loss: 1.6440888245900471

Epoch: 6| Step: 1
Training loss: 0.11673267185688019
Validation loss: 1.6287117722213909

Epoch: 6| Step: 2
Training loss: 0.3167972266674042
Validation loss: 1.621522403532459

Epoch: 6| Step: 3
Training loss: 0.19382277131080627
Validation loss: 1.6157899595076037

Epoch: 6| Step: 4
Training loss: 0.18292579054832458
Validation loss: 1.6218719238876014

Epoch: 6| Step: 5
Training loss: 0.3520779013633728
Validation loss: 1.601015083251461

Epoch: 6| Step: 6
Training loss: 0.21594364941120148
Validation loss: 1.6185423046030023

Epoch: 6| Step: 7
Training loss: 0.1962803602218628
Validation loss: 1.5924347523720033

Epoch: 6| Step: 8
Training loss: 0.23520657420158386
Validation loss: 1.6362877289454143

Epoch: 6| Step: 9
Training loss: 0.3279152512550354
Validation loss: 1.6630622084422777

Epoch: 6| Step: 10
Training loss: 0.2705796957015991
Validation loss: 1.6366472090444257

Epoch: 6| Step: 11
Training loss: 0.12279565632343292
Validation loss: 1.6576421927380305

Epoch: 6| Step: 12
Training loss: 0.26292064785957336
Validation loss: 1.6528845935739496

Epoch: 6| Step: 13
Training loss: 0.07115185260772705
Validation loss: 1.626915911192535

Epoch: 494| Step: 0
Training loss: 0.3410433232784271
Validation loss: 1.6363406565881544

Epoch: 6| Step: 1
Training loss: 0.14559924602508545
Validation loss: 1.6493088160791705

Epoch: 6| Step: 2
Training loss: 0.2532012462615967
Validation loss: 1.6187225272578578

Epoch: 6| Step: 3
Training loss: 0.3420047163963318
Validation loss: 1.6156729049580072

Epoch: 6| Step: 4
Training loss: 0.25485503673553467
Validation loss: 1.6167236463997954

Epoch: 6| Step: 5
Training loss: 0.2807377576828003
Validation loss: 1.6125469348763908

Epoch: 6| Step: 6
Training loss: 0.30932432413101196
Validation loss: 1.5916298083079758

Epoch: 6| Step: 7
Training loss: 0.20885509252548218
Validation loss: 1.615765897176599

Epoch: 6| Step: 8
Training loss: 0.35180342197418213
Validation loss: 1.6097082937917402

Epoch: 6| Step: 9
Training loss: 0.17237553000450134
Validation loss: 1.6170488531871507

Epoch: 6| Step: 10
Training loss: 0.24341097474098206
Validation loss: 1.6584393221844909

Epoch: 6| Step: 11
Training loss: 0.19210723042488098
Validation loss: 1.6727062527851393

Epoch: 6| Step: 12
Training loss: 0.3058958947658539
Validation loss: 1.6838121721821446

Epoch: 6| Step: 13
Training loss: 0.28520411252975464
Validation loss: 1.6771517274200276

Epoch: 495| Step: 0
Training loss: 0.23509761691093445
Validation loss: 1.6744174700911327

Epoch: 6| Step: 1
Training loss: 0.12562993168830872
Validation loss: 1.624937625341518

Epoch: 6| Step: 2
Training loss: 0.14692547917366028
Validation loss: 1.6117692019349785

Epoch: 6| Step: 3
Training loss: 0.11818701773881912
Validation loss: 1.5910006030913322

Epoch: 6| Step: 4
Training loss: 0.2717446982860565
Validation loss: 1.5980511403852893

Epoch: 6| Step: 5
Training loss: 0.128148153424263
Validation loss: 1.5710587873253772

Epoch: 6| Step: 6
Training loss: 0.37230783700942993
Validation loss: 1.5710195905418807

Epoch: 6| Step: 7
Training loss: 0.3361366093158722
Validation loss: 1.5865116747476722

Epoch: 6| Step: 8
Training loss: 0.2824106514453888
Validation loss: 1.5746219824719172

Epoch: 6| Step: 9
Training loss: 0.18611600995063782
Validation loss: 1.5870527234128726

Epoch: 6| Step: 10
Training loss: 0.3392283320426941
Validation loss: 1.567246840846154

Epoch: 6| Step: 11
Training loss: 0.3707613945007324
Validation loss: 1.565995152278613

Epoch: 6| Step: 12
Training loss: 0.32910728454589844
Validation loss: 1.5877085308874808

Epoch: 6| Step: 13
Training loss: 0.324023574590683
Validation loss: 1.6100791365869584

Epoch: 496| Step: 0
Training loss: 0.28223875164985657
Validation loss: 1.6133400253070298

Epoch: 6| Step: 1
Training loss: 0.14573454856872559
Validation loss: 1.616363961209533

Epoch: 6| Step: 2
Training loss: 0.37005943059921265
Validation loss: 1.6460000943112116

Epoch: 6| Step: 3
Training loss: 0.4126434326171875
Validation loss: 1.649629250649483

Epoch: 6| Step: 4
Training loss: 0.20816099643707275
Validation loss: 1.6294608910878499

Epoch: 6| Step: 5
Training loss: 0.24497199058532715
Validation loss: 1.5861495605079077

Epoch: 6| Step: 6
Training loss: 0.26073241233825684
Validation loss: 1.624685920694823

Epoch: 6| Step: 7
Training loss: 0.40422970056533813
Validation loss: 1.613084000925864

Epoch: 6| Step: 8
Training loss: 0.2734597325325012
Validation loss: 1.6281642683090702

Epoch: 6| Step: 9
Training loss: 0.20675696432590485
Validation loss: 1.6174761185082056

Epoch: 6| Step: 10
Training loss: 0.1572410762310028
Validation loss: 1.5926701766188427

Epoch: 6| Step: 11
Training loss: 0.13385018706321716
Validation loss: 1.621960732244676

Epoch: 6| Step: 12
Training loss: 0.22495965659618378
Validation loss: 1.6049759413606377

Epoch: 6| Step: 13
Training loss: 0.35518011450767517
Validation loss: 1.6038824396748697

Epoch: 497| Step: 0
Training loss: 0.26338985562324524
Validation loss: 1.6438871352903304

Epoch: 6| Step: 1
Training loss: 0.2897944748401642
Validation loss: 1.649639307811696

Epoch: 6| Step: 2
Training loss: 0.2316470444202423
Validation loss: 1.6629745062961374

Epoch: 6| Step: 3
Training loss: 0.18714763224124908
Validation loss: 1.6271828066918157

Epoch: 6| Step: 4
Training loss: 0.17769092321395874
Validation loss: 1.6711290959388978

Epoch: 6| Step: 5
Training loss: 0.4074343144893646
Validation loss: 1.6690110801368632

Epoch: 6| Step: 6
Training loss: 0.1258302628993988
Validation loss: 1.6782633450723463

Epoch: 6| Step: 7
Training loss: 0.3511950969696045
Validation loss: 1.6604934674437328

Epoch: 6| Step: 8
Training loss: 0.16018390655517578
Validation loss: 1.6508997037846556

Epoch: 6| Step: 9
Training loss: 0.17228147387504578
Validation loss: 1.6247550133735902

Epoch: 6| Step: 10
Training loss: 0.3650689721107483
Validation loss: 1.6059130417403353

Epoch: 6| Step: 11
Training loss: 0.20452386140823364
Validation loss: 1.6335805000797394

Epoch: 6| Step: 12
Training loss: 0.3400815725326538
Validation loss: 1.592163202583149

Epoch: 6| Step: 13
Training loss: 0.18953460454940796
Validation loss: 1.623237802136329

Epoch: 498| Step: 0
Training loss: 0.1356050819158554
Validation loss: 1.6392040368049376

Epoch: 6| Step: 1
Training loss: 0.30495065450668335
Validation loss: 1.65111800419387

Epoch: 6| Step: 2
Training loss: 0.33410024642944336
Validation loss: 1.679609929361651

Epoch: 6| Step: 3
Training loss: 0.31064897775650024
Validation loss: 1.7139268972540413

Epoch: 6| Step: 4
Training loss: 0.20613732933998108
Validation loss: 1.7144319844502274

Epoch: 6| Step: 5
Training loss: 0.21403993666172028
Validation loss: 1.6725686596285911

Epoch: 6| Step: 6
Training loss: 0.19864490628242493
Validation loss: 1.6900039424178421

Epoch: 6| Step: 7
Training loss: 0.233242928981781
Validation loss: 1.6718289416323426

Epoch: 6| Step: 8
Training loss: 0.3209724724292755
Validation loss: 1.6354402585696148

Epoch: 6| Step: 9
Training loss: 0.20666439831256866
Validation loss: 1.6199335513576385

Epoch: 6| Step: 10
Training loss: 0.28461575508117676
Validation loss: 1.633990050644003

Epoch: 6| Step: 11
Training loss: 0.20003116130828857
Validation loss: 1.6379892800443916

Epoch: 6| Step: 12
Training loss: 0.22820109128952026
Validation loss: 1.6098817368989349

Epoch: 6| Step: 13
Training loss: 0.33841803669929504
Validation loss: 1.6135147265208665

Epoch: 499| Step: 0
Training loss: 0.2808455228805542
Validation loss: 1.6396000513466455

Epoch: 6| Step: 1
Training loss: 0.19063471257686615
Validation loss: 1.6621620744787238

Epoch: 6| Step: 2
Training loss: 0.34567680954933167
Validation loss: 1.6351630046803465

Epoch: 6| Step: 3
Training loss: 0.19605010747909546
Validation loss: 1.655387891236172

Epoch: 6| Step: 4
Training loss: 0.42196282744407654
Validation loss: 1.6724501796948013

Epoch: 6| Step: 5
Training loss: 0.2516601085662842
Validation loss: 1.7155497394582278

Epoch: 6| Step: 6
Training loss: 0.18847107887268066
Validation loss: 1.6868807718317995

Epoch: 6| Step: 7
Training loss: 0.35406386852264404
Validation loss: 1.6596361129514632

Epoch: 6| Step: 8
Training loss: 0.17267966270446777
Validation loss: 1.6822333406376582

Epoch: 6| Step: 9
Training loss: 0.139616459608078
Validation loss: 1.67218489544366

Epoch: 6| Step: 10
Training loss: 0.22050203382968903
Validation loss: 1.666089629614225

Epoch: 6| Step: 11
Training loss: 0.3186866044998169
Validation loss: 1.6748806789357176

Epoch: 6| Step: 12
Training loss: 0.20745941996574402
Validation loss: 1.6585983807040798

Epoch: 6| Step: 13
Training loss: 0.2553172707557678
Validation loss: 1.6374701171792962

Epoch: 500| Step: 0
Training loss: 0.2593129277229309
Validation loss: 1.6375781502774966

Epoch: 6| Step: 1
Training loss: 0.25546860694885254
Validation loss: 1.6141407669231456

Epoch: 6| Step: 2
Training loss: 0.20027652382850647
Validation loss: 1.6100123492620324

Epoch: 6| Step: 3
Training loss: 0.21421994268894196
Validation loss: 1.6272630383891444

Epoch: 6| Step: 4
Training loss: 0.20630836486816406
Validation loss: 1.609993161693696

Epoch: 6| Step: 5
Training loss: 0.17500445246696472
Validation loss: 1.6956304696298414

Epoch: 6| Step: 6
Training loss: 0.33483392000198364
Validation loss: 1.684973603935652

Epoch: 6| Step: 7
Training loss: 0.18717500567436218
Validation loss: 1.6718739604437223

Epoch: 6| Step: 8
Training loss: 0.1947941929101944
Validation loss: 1.6635564424658333

Epoch: 6| Step: 9
Training loss: 0.3981732130050659
Validation loss: 1.648169134893725

Epoch: 6| Step: 10
Training loss: 0.10997769981622696
Validation loss: 1.654991582516701

Epoch: 6| Step: 11
Training loss: 0.2637455463409424
Validation loss: 1.6424259665191814

Epoch: 6| Step: 12
Training loss: 0.27567338943481445
Validation loss: 1.6640862226486206

Epoch: 6| Step: 13
Training loss: 0.23552672564983368
Validation loss: 1.6702825061736568

Testing loss: 1.8160601059595745
