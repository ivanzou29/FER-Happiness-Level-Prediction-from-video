Epoch: 1| Step: 0
Training loss: 6.1301777033228335
Validation loss: 5.754188713283426

Epoch: 6| Step: 1
Training loss: 5.48224687721685
Validation loss: 5.749092108845143

Epoch: 6| Step: 2
Training loss: 5.370708970592408
Validation loss: 5.74404380448875

Epoch: 6| Step: 3
Training loss: 6.070995552585401
Validation loss: 5.739347919780082

Epoch: 6| Step: 4
Training loss: 6.161539197075647
Validation loss: 5.73479681393533

Epoch: 6| Step: 5
Training loss: 6.518971852873326
Validation loss: 5.730148635193793

Epoch: 6| Step: 6
Training loss: 4.97278589407787
Validation loss: 5.725301664552542

Epoch: 6| Step: 7
Training loss: 6.0380419501723415
Validation loss: 5.720860292339967

Epoch: 6| Step: 8
Training loss: 6.466926059567413
Validation loss: 5.715751322148039

Epoch: 6| Step: 9
Training loss: 3.8903040006650293
Validation loss: 5.711132628169948

Epoch: 6| Step: 10
Training loss: 6.694918786739325
Validation loss: 5.7063833088161475

Epoch: 6| Step: 11
Training loss: 5.763238014740566
Validation loss: 5.70144708741021

Epoch: 6| Step: 12
Training loss: 5.107770288665823
Validation loss: 5.696121876494065

Epoch: 6| Step: 13
Training loss: 4.999977874706906
Validation loss: 5.6911928938940815

Epoch: 2| Step: 0
Training loss: 6.101920416538992
Validation loss: 5.685869960785459

Epoch: 6| Step: 1
Training loss: 5.35461748454189
Validation loss: 5.680207970778025

Epoch: 6| Step: 2
Training loss: 6.475845352428087
Validation loss: 5.674573898418844

Epoch: 6| Step: 3
Training loss: 4.247241527468312
Validation loss: 5.668306360794796

Epoch: 6| Step: 4
Training loss: 5.558689483869032
Validation loss: 5.662289125975971

Epoch: 6| Step: 5
Training loss: 6.056271214246255
Validation loss: 5.656318607479652

Epoch: 6| Step: 6
Training loss: 4.578067505771659
Validation loss: 5.6496169959140445

Epoch: 6| Step: 7
Training loss: 5.829816721003181
Validation loss: 5.642882589023857

Epoch: 6| Step: 8
Training loss: 6.012686351021623
Validation loss: 5.635197278901007

Epoch: 6| Step: 9
Training loss: 5.659420916046135
Validation loss: 5.627832659761532

Epoch: 6| Step: 10
Training loss: 5.172519240345854
Validation loss: 5.620030870583108

Epoch: 6| Step: 11
Training loss: 5.607743134791027
Validation loss: 5.612123751261869

Epoch: 6| Step: 12
Training loss: 6.113944839682931
Validation loss: 5.603484104594988

Epoch: 6| Step: 13
Training loss: 6.7890394625256425
Validation loss: 5.593758227475815

Epoch: 3| Step: 0
Training loss: 3.76116476604507
Validation loss: 5.584643344191018

Epoch: 6| Step: 1
Training loss: 4.551745346173392
Validation loss: 5.574122363004952

Epoch: 6| Step: 2
Training loss: 7.042535972733551
Validation loss: 5.564572619079651

Epoch: 6| Step: 3
Training loss: 6.352557002400687
Validation loss: 5.554212296571586

Epoch: 6| Step: 4
Training loss: 5.830065693035321
Validation loss: 5.542589325310832

Epoch: 6| Step: 5
Training loss: 5.226464149450675
Validation loss: 5.531081156108663

Epoch: 6| Step: 6
Training loss: 6.774317982258868
Validation loss: 5.51866482824912

Epoch: 6| Step: 7
Training loss: 5.845704430128488
Validation loss: 5.506247480165906

Epoch: 6| Step: 8
Training loss: 4.388131624930461
Validation loss: 5.493025971793266

Epoch: 6| Step: 9
Training loss: 5.426681454862523
Validation loss: 5.4803850059393

Epoch: 6| Step: 10
Training loss: 4.920363227338042
Validation loss: 5.465869698455292

Epoch: 6| Step: 11
Training loss: 5.94122133587986
Validation loss: 5.451717897649089

Epoch: 6| Step: 12
Training loss: 5.769112377419165
Validation loss: 5.436764163896593

Epoch: 6| Step: 13
Training loss: 4.344833348703139
Validation loss: 5.4209872082174595

Epoch: 4| Step: 0
Training loss: 4.714798845710979
Validation loss: 5.405918554791366

Epoch: 6| Step: 1
Training loss: 6.0600020778136265
Validation loss: 5.390888372107167

Epoch: 6| Step: 2
Training loss: 5.408686623498438
Validation loss: 5.3748809522727

Epoch: 6| Step: 3
Training loss: 6.535761247119245
Validation loss: 5.358229837534616

Epoch: 6| Step: 4
Training loss: 5.5486650184470925
Validation loss: 5.340529289648773

Epoch: 6| Step: 5
Training loss: 4.465057341238394
Validation loss: 5.323991033473104

Epoch: 6| Step: 6
Training loss: 5.511177842101939
Validation loss: 5.306124408960975

Epoch: 6| Step: 7
Training loss: 5.204152048832094
Validation loss: 5.2879688900710144

Epoch: 6| Step: 8
Training loss: 4.415748044815067
Validation loss: 5.270372875093957

Epoch: 6| Step: 9
Training loss: 5.518655695384892
Validation loss: 5.251643379233656

Epoch: 6| Step: 10
Training loss: 6.271068615053341
Validation loss: 5.233440470390791

Epoch: 6| Step: 11
Training loss: 5.3726688031516865
Validation loss: 5.212656158486993

Epoch: 6| Step: 12
Training loss: 4.344460628205119
Validation loss: 5.1933658258601465

Epoch: 6| Step: 13
Training loss: 4.628400428916615
Validation loss: 5.174617428732543

Epoch: 5| Step: 0
Training loss: 5.837894218905719
Validation loss: 5.1554204458071204

Epoch: 6| Step: 1
Training loss: 3.4336888774240744
Validation loss: 5.134307163724525

Epoch: 6| Step: 2
Training loss: 4.567265151594094
Validation loss: 5.116209429243295

Epoch: 6| Step: 3
Training loss: 5.125797488805057
Validation loss: 5.094686947821007

Epoch: 6| Step: 4
Training loss: 5.524735747357062
Validation loss: 5.075914300999654

Epoch: 6| Step: 5
Training loss: 4.445797322254626
Validation loss: 5.0569005373304785

Epoch: 6| Step: 6
Training loss: 5.892781073009082
Validation loss: 5.035987343410286

Epoch: 6| Step: 7
Training loss: 5.45690891617531
Validation loss: 5.015038937892187

Epoch: 6| Step: 8
Training loss: 5.1184810954388835
Validation loss: 4.993857525921225

Epoch: 6| Step: 9
Training loss: 5.200603068667328
Validation loss: 4.972447865447417

Epoch: 6| Step: 10
Training loss: 4.472938548678475
Validation loss: 4.952900112402846

Epoch: 6| Step: 11
Training loss: 4.496525588785798
Validation loss: 4.932706502692699

Epoch: 6| Step: 12
Training loss: 5.660903618058624
Validation loss: 4.911222512142288

Epoch: 6| Step: 13
Training loss: 5.540323347990888
Validation loss: 4.890234859730255

Epoch: 6| Step: 0
Training loss: 5.320197060742837
Validation loss: 4.870510131978608

Epoch: 6| Step: 1
Training loss: 3.4988958797046474
Validation loss: 4.851974331644593

Epoch: 6| Step: 2
Training loss: 4.544092539556896
Validation loss: 4.8335342761494475

Epoch: 6| Step: 3
Training loss: 4.792403233625287
Validation loss: 4.814502940100851

Epoch: 6| Step: 4
Training loss: 4.806910848636396
Validation loss: 4.796681911586205

Epoch: 6| Step: 5
Training loss: 5.4972475273719725
Validation loss: 4.7783683314263685

Epoch: 6| Step: 6
Training loss: 3.944912427503169
Validation loss: 4.761902509291801

Epoch: 6| Step: 7
Training loss: 5.352169787623229
Validation loss: 4.743317502358519

Epoch: 6| Step: 8
Training loss: 5.09758403624617
Validation loss: 4.727536976898183

Epoch: 6| Step: 9
Training loss: 5.502327686542557
Validation loss: 4.710542891987785

Epoch: 6| Step: 10
Training loss: 5.402788057075055
Validation loss: 4.693178786622461

Epoch: 6| Step: 11
Training loss: 4.555384273462146
Validation loss: 4.676369667303458

Epoch: 6| Step: 12
Training loss: 4.644024871864711
Validation loss: 4.6604886134643255

Epoch: 6| Step: 13
Training loss: 3.699666657768112
Validation loss: 4.646769301271636

Epoch: 7| Step: 0
Training loss: 4.8068892233686125
Validation loss: 4.631691477393473

Epoch: 6| Step: 1
Training loss: 4.859258619674995
Validation loss: 4.617406343210848

Epoch: 6| Step: 2
Training loss: 5.258017095294961
Validation loss: 4.604263290544356

Epoch: 6| Step: 3
Training loss: 5.12307517028976
Validation loss: 4.589955804207993

Epoch: 6| Step: 4
Training loss: 4.673811393226424
Validation loss: 4.5786676563678

Epoch: 6| Step: 5
Training loss: 3.4261086110693793
Validation loss: 4.5657571046827385

Epoch: 6| Step: 6
Training loss: 5.557058179884751
Validation loss: 4.55507812671094

Epoch: 6| Step: 7
Training loss: 5.316377548599969
Validation loss: 4.542698378993536

Epoch: 6| Step: 8
Training loss: 4.497207622937659
Validation loss: 4.532723982198643

Epoch: 6| Step: 9
Training loss: 4.595452855887393
Validation loss: 4.521595320156275

Epoch: 6| Step: 10
Training loss: 3.7207463139307677
Validation loss: 4.512464249760475

Epoch: 6| Step: 11
Training loss: 4.923489163635236
Validation loss: 4.5038649848109396

Epoch: 6| Step: 12
Training loss: 3.826605047423217
Validation loss: 4.494455536012356

Epoch: 6| Step: 13
Training loss: 3.506940499650774
Validation loss: 4.486146592730792

Epoch: 8| Step: 0
Training loss: 4.23164397846724
Validation loss: 4.479620481807045

Epoch: 6| Step: 1
Training loss: 5.1354226917698345
Validation loss: 4.470871352785151

Epoch: 6| Step: 2
Training loss: 4.126947810056326
Validation loss: 4.463446181668272

Epoch: 6| Step: 3
Training loss: 4.890593799820605
Validation loss: 4.45679473932474

Epoch: 6| Step: 4
Training loss: 5.020382535121223
Validation loss: 4.451168744149117

Epoch: 6| Step: 5
Training loss: 4.844708944579687
Validation loss: 4.4421790280770495

Epoch: 6| Step: 6
Training loss: 3.965838468200561
Validation loss: 4.436205232380528

Epoch: 6| Step: 7
Training loss: 4.9409766210216395
Validation loss: 4.426034840220598

Epoch: 6| Step: 8
Training loss: 4.004069880421644
Validation loss: 4.418446820381922

Epoch: 6| Step: 9
Training loss: 4.43958738420225
Validation loss: 4.409093538121617

Epoch: 6| Step: 10
Training loss: 3.799712702280667
Validation loss: 4.401927626062877

Epoch: 6| Step: 11
Training loss: 5.010281482334756
Validation loss: 4.3930004264151385

Epoch: 6| Step: 12
Training loss: 4.80487506779461
Validation loss: 4.382124862613035

Epoch: 6| Step: 13
Training loss: 3.6490318582053054
Validation loss: 4.376189194185379

Epoch: 9| Step: 0
Training loss: 3.7117361393904376
Validation loss: 4.364467027912752

Epoch: 6| Step: 1
Training loss: 4.210154727801729
Validation loss: 4.3576411504374235

Epoch: 6| Step: 2
Training loss: 4.995611744670637
Validation loss: 4.348512955097526

Epoch: 6| Step: 3
Training loss: 5.339013392998758
Validation loss: 4.339468804992205

Epoch: 6| Step: 4
Training loss: 4.3974669014019625
Validation loss: 4.329288971633502

Epoch: 6| Step: 5
Training loss: 4.935751110299946
Validation loss: 4.320988945244343

Epoch: 6| Step: 6
Training loss: 4.963965457571683
Validation loss: 4.3104099025714975

Epoch: 6| Step: 7
Training loss: 4.516229820005773
Validation loss: 4.301599767927041

Epoch: 6| Step: 8
Training loss: 3.8552676441186398
Validation loss: 4.290273636032882

Epoch: 6| Step: 9
Training loss: 3.9816239976306527
Validation loss: 4.280875598981861

Epoch: 6| Step: 10
Training loss: 4.275839400841326
Validation loss: 4.271574213138294

Epoch: 6| Step: 11
Training loss: 4.485845132087404
Validation loss: 4.264656674279791

Epoch: 6| Step: 12
Training loss: 4.34626400874823
Validation loss: 4.256335150770846

Epoch: 6| Step: 13
Training loss: 2.7473351831958333
Validation loss: 4.251359607490963

Epoch: 10| Step: 0
Training loss: 5.492036950339245
Validation loss: 4.243631021871017

Epoch: 6| Step: 1
Training loss: 3.78327118630698
Validation loss: 4.237146415772373

Epoch: 6| Step: 2
Training loss: 4.406574859547702
Validation loss: 4.228551881264283

Epoch: 6| Step: 3
Training loss: 4.605186706137839
Validation loss: 4.224585963242606

Epoch: 6| Step: 4
Training loss: 4.351674268509648
Validation loss: 4.21833834141788

Epoch: 6| Step: 5
Training loss: 3.997777321305201
Validation loss: 4.21159835001988

Epoch: 6| Step: 6
Training loss: 3.427443341455365
Validation loss: 4.206343592341927

Epoch: 6| Step: 7
Training loss: 4.170358446481975
Validation loss: 4.200280568253681

Epoch: 6| Step: 8
Training loss: 2.978822505963336
Validation loss: 4.19516313652507

Epoch: 6| Step: 9
Training loss: 3.3846444682225534
Validation loss: 4.19079934697518

Epoch: 6| Step: 10
Training loss: 4.847693234901217
Validation loss: 4.185346678795262

Epoch: 6| Step: 11
Training loss: 5.187405504951655
Validation loss: 4.17984001579865

Epoch: 6| Step: 12
Training loss: 4.817012900257794
Validation loss: 4.1748497934764615

Epoch: 6| Step: 13
Training loss: 4.568474398335518
Validation loss: 4.169171147084364

Epoch: 11| Step: 0
Training loss: 4.163464243785137
Validation loss: 4.1616840785170295

Epoch: 6| Step: 1
Training loss: 4.348048875325207
Validation loss: 4.157741752945302

Epoch: 6| Step: 2
Training loss: 4.806056080491376
Validation loss: 4.152354512434021

Epoch: 6| Step: 3
Training loss: 3.94299586804314
Validation loss: 4.146182705883662

Epoch: 6| Step: 4
Training loss: 4.419169862215998
Validation loss: 4.141544197136852

Epoch: 6| Step: 5
Training loss: 3.9351923401877653
Validation loss: 4.138227869488396

Epoch: 6| Step: 6
Training loss: 3.316328319626929
Validation loss: 4.133191395114413

Epoch: 6| Step: 7
Training loss: 4.3387004675163015
Validation loss: 4.127019870568262

Epoch: 6| Step: 8
Training loss: 4.894417069573018
Validation loss: 4.12200042061851

Epoch: 6| Step: 9
Training loss: 5.451012319637325
Validation loss: 4.116290050521872

Epoch: 6| Step: 10
Training loss: 3.416568630641823
Validation loss: 4.112459592561169

Epoch: 6| Step: 11
Training loss: 5.069129088650952
Validation loss: 4.108249040447064

Epoch: 6| Step: 12
Training loss: 2.7623307603459115
Validation loss: 4.103036714430063

Epoch: 6| Step: 13
Training loss: 3.927433649251748
Validation loss: 4.099510655487716

Epoch: 12| Step: 0
Training loss: 4.490377097829635
Validation loss: 4.095312557240882

Epoch: 6| Step: 1
Training loss: 3.4500539250236786
Validation loss: 4.091375001909825

Epoch: 6| Step: 2
Training loss: 4.422539650937154
Validation loss: 4.088064474403118

Epoch: 6| Step: 3
Training loss: 4.050796317474388
Validation loss: 4.084265966349018

Epoch: 6| Step: 4
Training loss: 4.156089148599726
Validation loss: 4.080163546997457

Epoch: 6| Step: 5
Training loss: 3.3695991535805185
Validation loss: 4.073766123743569

Epoch: 6| Step: 6
Training loss: 3.98916278478464
Validation loss: 4.070733991477956

Epoch: 6| Step: 7
Training loss: 5.342854742715528
Validation loss: 4.067924869477562

Epoch: 6| Step: 8
Training loss: 3.585489747926064
Validation loss: 4.062509006335653

Epoch: 6| Step: 9
Training loss: 4.332712764809566
Validation loss: 4.0587354282742

Epoch: 6| Step: 10
Training loss: 4.401202401681432
Validation loss: 4.055448780367059

Epoch: 6| Step: 11
Training loss: 3.63129299748976
Validation loss: 4.052714241492774

Epoch: 6| Step: 12
Training loss: 3.9713318604223278
Validation loss: 4.049171041253677

Epoch: 6| Step: 13
Training loss: 5.940404884077143
Validation loss: 4.047089169779919

Epoch: 13| Step: 0
Training loss: 4.347562365619292
Validation loss: 4.04299587410873

Epoch: 6| Step: 1
Training loss: 4.458859896833477
Validation loss: 4.039009323495226

Epoch: 6| Step: 2
Training loss: 4.057404124407595
Validation loss: 4.036309871847724

Epoch: 6| Step: 3
Training loss: 4.177524356280219
Validation loss: 4.032601635723986

Epoch: 6| Step: 4
Training loss: 4.247460448028723
Validation loss: 4.029877688781533

Epoch: 6| Step: 5
Training loss: 4.094557354936102
Validation loss: 4.027097114151635

Epoch: 6| Step: 6
Training loss: 3.6896105400014307
Validation loss: 4.025549525410569

Epoch: 6| Step: 7
Training loss: 3.528351125574698
Validation loss: 4.022478409264883

Epoch: 6| Step: 8
Training loss: 4.914987352729429
Validation loss: 4.018175429475445

Epoch: 6| Step: 9
Training loss: 4.492795262895027
Validation loss: 4.0153412368916

Epoch: 6| Step: 10
Training loss: 5.356230856150153
Validation loss: 4.011643902617726

Epoch: 6| Step: 11
Training loss: 3.4760472976750227
Validation loss: 4.009151608347827

Epoch: 6| Step: 12
Training loss: 3.2918031559584673
Validation loss: 4.007235118463218

Epoch: 6| Step: 13
Training loss: 3.407024750400459
Validation loss: 4.003730234378534

Epoch: 14| Step: 0
Training loss: 4.974204278693906
Validation loss: 4.000793678236561

Epoch: 6| Step: 1
Training loss: 3.8203740339257672
Validation loss: 3.9944775732454336

Epoch: 6| Step: 2
Training loss: 3.598146618487741
Validation loss: 3.9903599917451444

Epoch: 6| Step: 3
Training loss: 4.169601449559531
Validation loss: 3.984849671591498

Epoch: 6| Step: 4
Training loss: 3.7944843316824737
Validation loss: 3.9811989692091974

Epoch: 6| Step: 5
Training loss: 4.371153093877768
Validation loss: 3.974663852990414

Epoch: 6| Step: 6
Training loss: 3.677682771893018
Validation loss: 3.972673588461208

Epoch: 6| Step: 7
Training loss: 4.163265874930561
Validation loss: 3.969708378084219

Epoch: 6| Step: 8
Training loss: 4.041547295029945
Validation loss: 3.965280887501084

Epoch: 6| Step: 9
Training loss: 4.741461860153371
Validation loss: 3.9590054397479535

Epoch: 6| Step: 10
Training loss: 4.596334755255871
Validation loss: 3.9571085245514106

Epoch: 6| Step: 11
Training loss: 3.625801129441772
Validation loss: 3.953524267372537

Epoch: 6| Step: 12
Training loss: 3.7537186304814765
Validation loss: 3.953156068689438

Epoch: 6| Step: 13
Training loss: 4.184026159740819
Validation loss: 3.949646280000806

Epoch: 15| Step: 0
Training loss: 3.614506628155221
Validation loss: 3.9489393116220333

Epoch: 6| Step: 1
Training loss: 3.442596541459023
Validation loss: 3.943474215001583

Epoch: 6| Step: 2
Training loss: 3.6208897670010542
Validation loss: 3.9391016647920245

Epoch: 6| Step: 3
Training loss: 4.051935397522799
Validation loss: 3.933467008652725

Epoch: 6| Step: 4
Training loss: 3.998490048562961
Validation loss: 3.9269089947194185

Epoch: 6| Step: 5
Training loss: 4.772789344549098
Validation loss: 3.922676982655294

Epoch: 6| Step: 6
Training loss: 4.128327847968533
Validation loss: 3.917875975516432

Epoch: 6| Step: 7
Training loss: 4.956180821208961
Validation loss: 3.9149703439170183

Epoch: 6| Step: 8
Training loss: 4.169900834256049
Validation loss: 3.9109144015997206

Epoch: 6| Step: 9
Training loss: 3.9015643283654855
Validation loss: 3.906332543598225

Epoch: 6| Step: 10
Training loss: 2.9816316308368536
Validation loss: 3.901710160646026

Epoch: 6| Step: 11
Training loss: 5.295548624608758
Validation loss: 3.899649525006417

Epoch: 6| Step: 12
Training loss: 3.3564026923937926
Validation loss: 3.8952175248336207

Epoch: 6| Step: 13
Training loss: 4.204845204083929
Validation loss: 3.894134803121393

Epoch: 16| Step: 0
Training loss: 4.577103328299427
Validation loss: 3.8899240776245283

Epoch: 6| Step: 1
Training loss: 4.17018533271946
Validation loss: 3.887478003709875

Epoch: 6| Step: 2
Training loss: 4.638121677896626
Validation loss: 3.8820872705437806

Epoch: 6| Step: 3
Training loss: 4.613873061836151
Validation loss: 3.8780639263920467

Epoch: 6| Step: 4
Training loss: 2.4210164178719378
Validation loss: 3.8741067047903632

Epoch: 6| Step: 5
Training loss: 3.763880408646218
Validation loss: 3.870764546291081

Epoch: 6| Step: 6
Training loss: 3.5932936668919617
Validation loss: 3.8689755685131506

Epoch: 6| Step: 7
Training loss: 4.279745241230368
Validation loss: 3.8629686326632813

Epoch: 6| Step: 8
Training loss: 4.887916082832489
Validation loss: 3.860845507428797

Epoch: 6| Step: 9
Training loss: 3.6448808279558333
Validation loss: 3.8571611172201052

Epoch: 6| Step: 10
Training loss: 4.324431788874795
Validation loss: 3.8544190878163684

Epoch: 6| Step: 11
Training loss: 3.2206006701790604
Validation loss: 3.850088207298226

Epoch: 6| Step: 12
Training loss: 3.8271692445291117
Validation loss: 3.847141927888137

Epoch: 6| Step: 13
Training loss: 3.621008813349531
Validation loss: 3.8403566356543237

Epoch: 17| Step: 0
Training loss: 3.8586999712123866
Validation loss: 3.8388887377248606

Epoch: 6| Step: 1
Training loss: 4.196009629506716
Validation loss: 3.8339817377951615

Epoch: 6| Step: 2
Training loss: 3.952707743580918
Validation loss: 3.83101953431146

Epoch: 6| Step: 3
Training loss: 4.033254672037425
Validation loss: 3.8281485715252974

Epoch: 6| Step: 4
Training loss: 3.2215004437766153
Validation loss: 3.8221058499380303

Epoch: 6| Step: 5
Training loss: 4.139662835954849
Validation loss: 3.8177639807593553

Epoch: 6| Step: 6
Training loss: 4.183986499348845
Validation loss: 3.815369802022576

Epoch: 6| Step: 7
Training loss: 3.304014890503292
Validation loss: 3.8105932154595314

Epoch: 6| Step: 8
Training loss: 3.4168418901373334
Validation loss: 3.8077819830805684

Epoch: 6| Step: 9
Training loss: 3.917439296619693
Validation loss: 3.799972713428621

Epoch: 6| Step: 10
Training loss: 4.799762465639576
Validation loss: 3.7981112056242203

Epoch: 6| Step: 11
Training loss: 4.431110994340476
Validation loss: 3.795928409006575

Epoch: 6| Step: 12
Training loss: 4.101730372308636
Validation loss: 3.792168732868661

Epoch: 6| Step: 13
Training loss: 3.8735458352718197
Validation loss: 3.786715749930595

Epoch: 18| Step: 0
Training loss: 4.292950311678442
Validation loss: 3.7827122775431987

Epoch: 6| Step: 1
Training loss: 4.250419595986185
Validation loss: 3.7778578081607597

Epoch: 6| Step: 2
Training loss: 4.764479802848161
Validation loss: 3.774220750093839

Epoch: 6| Step: 3
Training loss: 3.7125741662217693
Validation loss: 3.769659648453155

Epoch: 6| Step: 4
Training loss: 4.043360771302049
Validation loss: 3.7659498232996476

Epoch: 6| Step: 5
Training loss: 4.338448122381516
Validation loss: 3.7623991331082594

Epoch: 6| Step: 6
Training loss: 3.7382942606062777
Validation loss: 3.7609171187380097

Epoch: 6| Step: 7
Training loss: 3.2897746930181637
Validation loss: 3.758652765452552

Epoch: 6| Step: 8
Training loss: 2.8308498680867857
Validation loss: 3.7548445114788933

Epoch: 6| Step: 9
Training loss: 3.026974366325571
Validation loss: 3.753274692357148

Epoch: 6| Step: 10
Training loss: 4.596374384877924
Validation loss: 3.7496953368764028

Epoch: 6| Step: 11
Training loss: 3.581172128732825
Validation loss: 3.7452859132072147

Epoch: 6| Step: 12
Training loss: 3.9455838251767736
Validation loss: 3.743962335283768

Epoch: 6| Step: 13
Training loss: 4.379415191557424
Validation loss: 3.741861038719235

Epoch: 19| Step: 0
Training loss: 3.7033065558242857
Validation loss: 3.73672893084103

Epoch: 6| Step: 1
Training loss: 4.189515724692567
Validation loss: 3.7325818515905356

Epoch: 6| Step: 2
Training loss: 4.335160139353319
Validation loss: 3.7299811172238324

Epoch: 6| Step: 3
Training loss: 4.324225366272039
Validation loss: 3.7258928706479453

Epoch: 6| Step: 4
Training loss: 3.5728011191380444
Validation loss: 3.7229077094636467

Epoch: 6| Step: 5
Training loss: 3.3046140549887517
Validation loss: 3.721013514399375

Epoch: 6| Step: 6
Training loss: 3.2700632407696357
Validation loss: 3.7167572006779053

Epoch: 6| Step: 7
Training loss: 3.0291563059241784
Validation loss: 3.715799905815996

Epoch: 6| Step: 8
Training loss: 4.221308857578339
Validation loss: 3.71216104246627

Epoch: 6| Step: 9
Training loss: 4.879821349454085
Validation loss: 3.70941048344338

Epoch: 6| Step: 10
Training loss: 3.638149615088024
Validation loss: 3.7072730079190577

Epoch: 6| Step: 11
Training loss: 3.491465653951035
Validation loss: 3.70444082553181

Epoch: 6| Step: 12
Training loss: 4.153587463670336
Validation loss: 3.703016062232693

Epoch: 6| Step: 13
Training loss: 4.161699207704728
Validation loss: 3.702043678587952

Epoch: 20| Step: 0
Training loss: 4.3532632623692935
Validation loss: 3.6990042963870193

Epoch: 6| Step: 1
Training loss: 3.8929055512144486
Validation loss: 3.695739209465989

Epoch: 6| Step: 2
Training loss: 3.3038548351661254
Validation loss: 3.6935282037339987

Epoch: 6| Step: 3
Training loss: 3.7266919895283075
Validation loss: 3.6925285567853443

Epoch: 6| Step: 4
Training loss: 4.2688901372781185
Validation loss: 3.6926097725102687

Epoch: 6| Step: 5
Training loss: 4.468209614125295
Validation loss: 3.687736107393584

Epoch: 6| Step: 6
Training loss: 3.5417893033205985
Validation loss: 3.685623945899404

Epoch: 6| Step: 7
Training loss: 3.22713614991722
Validation loss: 3.68384409705698

Epoch: 6| Step: 8
Training loss: 3.5832195411771015
Validation loss: 3.6819784818510475

Epoch: 6| Step: 9
Training loss: 3.9524804596294265
Validation loss: 3.6782447514348493

Epoch: 6| Step: 10
Training loss: 2.7572709110998264
Validation loss: 3.6779369688174874

Epoch: 6| Step: 11
Training loss: 4.199042056602343
Validation loss: 3.6767541602724116

Epoch: 6| Step: 12
Training loss: 4.733698931978383
Validation loss: 3.6750626662553985

Epoch: 6| Step: 13
Training loss: 3.617940408278108
Validation loss: 3.6706874039617867

Epoch: 21| Step: 0
Training loss: 3.8021705652271938
Validation loss: 3.670069451461914

Epoch: 6| Step: 1
Training loss: 4.047942856517234
Validation loss: 3.6678594166927803

Epoch: 6| Step: 2
Training loss: 3.4195166695806645
Validation loss: 3.6622107428846933

Epoch: 6| Step: 3
Training loss: 3.394493603250677
Validation loss: 3.661744480868836

Epoch: 6| Step: 4
Training loss: 4.0229970746505
Validation loss: 3.6604624404877955

Epoch: 6| Step: 5
Training loss: 4.302516936956536
Validation loss: 3.663335035149159

Epoch: 6| Step: 6
Training loss: 3.683454719257893
Validation loss: 3.656567171606998

Epoch: 6| Step: 7
Training loss: 3.691695073853005
Validation loss: 3.6662242031404095

Epoch: 6| Step: 8
Training loss: 3.426700620915948
Validation loss: 3.6723548884515758

Epoch: 6| Step: 9
Training loss: 4.262994535066384
Validation loss: 3.6665266453994803

Epoch: 6| Step: 10
Training loss: 3.5412458880421163
Validation loss: 3.6596581836376902

Epoch: 6| Step: 11
Training loss: 4.379785590650341
Validation loss: 3.6555681528036725

Epoch: 6| Step: 12
Training loss: 3.8968293383874397
Validation loss: 3.662296559396253

Epoch: 6| Step: 13
Training loss: 3.9791581052251987
Validation loss: 3.665150267770268

Epoch: 22| Step: 0
Training loss: 3.848605430987663
Validation loss: 3.660014793576345

Epoch: 6| Step: 1
Training loss: 3.0370384085358344
Validation loss: 3.654530882083622

Epoch: 6| Step: 2
Training loss: 4.495158664164773
Validation loss: 3.6482476481939177

Epoch: 6| Step: 3
Training loss: 3.765942572027692
Validation loss: 3.6445840322362297

Epoch: 6| Step: 4
Training loss: 3.71827758865827
Validation loss: 3.6403028224221115

Epoch: 6| Step: 5
Training loss: 4.308043900488382
Validation loss: 3.6411488776783076

Epoch: 6| Step: 6
Training loss: 4.205824655053124
Validation loss: 3.6359707384574023

Epoch: 6| Step: 7
Training loss: 3.0860994320646644
Validation loss: 3.632463595593783

Epoch: 6| Step: 8
Training loss: 3.67770144244748
Validation loss: 3.6278448444696925

Epoch: 6| Step: 9
Training loss: 3.2779416799425354
Validation loss: 3.6279183925468903

Epoch: 6| Step: 10
Training loss: 3.534518054660797
Validation loss: 3.6266708441325104

Epoch: 6| Step: 11
Training loss: 4.31253892079357
Validation loss: 3.623947617383934

Epoch: 6| Step: 12
Training loss: 3.018925259322349
Validation loss: 3.62338585536618

Epoch: 6| Step: 13
Training loss: 5.410577177894168
Validation loss: 3.623723329675428

Epoch: 23| Step: 0
Training loss: 4.3661363459226195
Validation loss: 3.618613694311852

Epoch: 6| Step: 1
Training loss: 3.97116495984562
Validation loss: 3.615794319258647

Epoch: 6| Step: 2
Training loss: 3.55717713081801
Validation loss: 3.616473352618918

Epoch: 6| Step: 3
Training loss: 3.3141577549131065
Validation loss: 3.611661043144612

Epoch: 6| Step: 4
Training loss: 3.9118786351933177
Validation loss: 3.6134706615499845

Epoch: 6| Step: 5
Training loss: 3.9520838878083566
Validation loss: 3.612528636699789

Epoch: 6| Step: 6
Training loss: 4.277158020725086
Validation loss: 3.610951912722947

Epoch: 6| Step: 7
Training loss: 2.8046460161886824
Validation loss: 3.609320373931498

Epoch: 6| Step: 8
Training loss: 4.017236527240573
Validation loss: 3.608656932336109

Epoch: 6| Step: 9
Training loss: 3.668503272421278
Validation loss: 3.607026767709049

Epoch: 6| Step: 10
Training loss: 4.417601768301528
Validation loss: 3.605285936401132

Epoch: 6| Step: 11
Training loss: 3.635487873651592
Validation loss: 3.601669609248298

Epoch: 6| Step: 12
Training loss: 3.270308936454774
Validation loss: 3.60093400499592

Epoch: 6| Step: 13
Training loss: 3.7936080880936824
Validation loss: 3.598352678716188

Epoch: 24| Step: 0
Training loss: 3.3549147693706334
Validation loss: 3.5985350936574565

Epoch: 6| Step: 1
Training loss: 3.967707339315306
Validation loss: 3.597427141926817

Epoch: 6| Step: 2
Training loss: 1.9020727696983697
Validation loss: 3.5947710167817104

Epoch: 6| Step: 3
Training loss: 4.276041691447485
Validation loss: 3.595102679976812

Epoch: 6| Step: 4
Training loss: 4.3763425674389484
Validation loss: 3.593702033294822

Epoch: 6| Step: 5
Training loss: 3.522739112811733
Validation loss: 3.5913198393025514

Epoch: 6| Step: 6
Training loss: 3.7535282067707225
Validation loss: 3.589225136844894

Epoch: 6| Step: 7
Training loss: 4.322301368893099
Validation loss: 3.5896523518677608

Epoch: 6| Step: 8
Training loss: 2.6476631945634064
Validation loss: 3.588267687635119

Epoch: 6| Step: 9
Training loss: 4.636934707612996
Validation loss: 3.5887235082857805

Epoch: 6| Step: 10
Training loss: 3.838925442948659
Validation loss: 3.5868811366097235

Epoch: 6| Step: 11
Training loss: 4.392799137809139
Validation loss: 3.586283883912373

Epoch: 6| Step: 12
Training loss: 3.0179731486992276
Validation loss: 3.583996569492673

Epoch: 6| Step: 13
Training loss: 4.178336978804757
Validation loss: 3.583100496403164

Epoch: 25| Step: 0
Training loss: 3.5340710739475645
Validation loss: 3.5819107335803193

Epoch: 6| Step: 1
Training loss: 2.758124228519943
Validation loss: 3.5800100676243245

Epoch: 6| Step: 2
Training loss: 3.074907664331571
Validation loss: 3.578033688269396

Epoch: 6| Step: 3
Training loss: 3.894170042254596
Validation loss: 3.579449819756273

Epoch: 6| Step: 4
Training loss: 3.801485504110711
Validation loss: 3.5778002367894532

Epoch: 6| Step: 5
Training loss: 3.7832757236839103
Validation loss: 3.57775514887813

Epoch: 6| Step: 6
Training loss: 3.949108873116014
Validation loss: 3.5758029861759404

Epoch: 6| Step: 7
Training loss: 4.3309863165756175
Validation loss: 3.5761729675055807

Epoch: 6| Step: 8
Training loss: 4.020545646113282
Validation loss: 3.578353925382507

Epoch: 6| Step: 9
Training loss: 4.2135117399695625
Validation loss: 3.5757637506342523

Epoch: 6| Step: 10
Training loss: 4.097570602060102
Validation loss: 3.574345160363208

Epoch: 6| Step: 11
Training loss: 3.872653866217493
Validation loss: 3.573284748114729

Epoch: 6| Step: 12
Training loss: 3.538278926647297
Validation loss: 3.5720058861133146

Epoch: 6| Step: 13
Training loss: 3.6698223463918724
Validation loss: 3.571412779924021

Epoch: 26| Step: 0
Training loss: 4.1166940932705165
Validation loss: 3.5687071820345433

Epoch: 6| Step: 1
Training loss: 4.0439758520716556
Validation loss: 3.5675068479152703

Epoch: 6| Step: 2
Training loss: 3.5834872781967633
Validation loss: 3.5666414190584637

Epoch: 6| Step: 3
Training loss: 4.343039694692284
Validation loss: 3.564995091088919

Epoch: 6| Step: 4
Training loss: 3.358952411420123
Validation loss: 3.5637288919960204

Epoch: 6| Step: 5
Training loss: 3.4303846758567804
Validation loss: 3.564788351102935

Epoch: 6| Step: 6
Training loss: 3.677521345438363
Validation loss: 3.562744929542497

Epoch: 6| Step: 7
Training loss: 4.359112912848541
Validation loss: 3.5624288059986964

Epoch: 6| Step: 8
Training loss: 2.591230708637921
Validation loss: 3.562328113553531

Epoch: 6| Step: 9
Training loss: 4.52431025016478
Validation loss: 3.5605807932187665

Epoch: 6| Step: 10
Training loss: 3.732946401935297
Validation loss: 3.5597200361147254

Epoch: 6| Step: 11
Training loss: 3.4878645730281956
Validation loss: 3.5597637227105117

Epoch: 6| Step: 12
Training loss: 3.241858187577275
Validation loss: 3.5590290863064054

Epoch: 6| Step: 13
Training loss: 3.8486596982298034
Validation loss: 3.5597930739020884

Epoch: 27| Step: 0
Training loss: 4.704530018147444
Validation loss: 3.559189597405408

Epoch: 6| Step: 1
Training loss: 4.064573492406171
Validation loss: 3.557110166068528

Epoch: 6| Step: 2
Training loss: 3.7220464889517393
Validation loss: 3.558074469152608

Epoch: 6| Step: 3
Training loss: 3.6754023065745254
Validation loss: 3.559118911986311

Epoch: 6| Step: 4
Training loss: 2.8399703510509813
Validation loss: 3.557677148628016

Epoch: 6| Step: 5
Training loss: 4.249984741183545
Validation loss: 3.5573119991689937

Epoch: 6| Step: 6
Training loss: 3.452610581689801
Validation loss: 3.554199121735272

Epoch: 6| Step: 7
Training loss: 3.5906116880430727
Validation loss: 3.5530135699141745

Epoch: 6| Step: 8
Training loss: 3.978625169162626
Validation loss: 3.553280542590973

Epoch: 6| Step: 9
Training loss: 3.5461668408297555
Validation loss: 3.551613724881616

Epoch: 6| Step: 10
Training loss: 3.2980769709852087
Validation loss: 3.551598856716204

Epoch: 6| Step: 11
Training loss: 3.907914562333914
Validation loss: 3.550567514748316

Epoch: 6| Step: 12
Training loss: 4.054654571458296
Validation loss: 3.550198975226336

Epoch: 6| Step: 13
Training loss: 2.650049849707099
Validation loss: 3.549921898774932

Epoch: 28| Step: 0
Training loss: 3.713316851316225
Validation loss: 3.5493592750677934

Epoch: 6| Step: 1
Training loss: 3.8244431832125696
Validation loss: 3.549029219886165

Epoch: 6| Step: 2
Training loss: 4.036457808299697
Validation loss: 3.5472731401822943

Epoch: 6| Step: 3
Training loss: 3.840363538143562
Validation loss: 3.5473395202381597

Epoch: 6| Step: 4
Training loss: 4.042477372388671
Validation loss: 3.54604927408879

Epoch: 6| Step: 5
Training loss: 4.250995968073959
Validation loss: 3.547605441391045

Epoch: 6| Step: 6
Training loss: 3.3108608580823855
Validation loss: 3.5473341563999723

Epoch: 6| Step: 7
Training loss: 3.5405761984738735
Validation loss: 3.5470781107769835

Epoch: 6| Step: 8
Training loss: 3.8529802850555006
Validation loss: 3.5464112299923833

Epoch: 6| Step: 9
Training loss: 3.665592093941976
Validation loss: 3.5473303318960046

Epoch: 6| Step: 10
Training loss: 2.686982748245265
Validation loss: 3.546387585854129

Epoch: 6| Step: 11
Training loss: 3.762124995303272
Validation loss: 3.544134171270439

Epoch: 6| Step: 12
Training loss: 3.7220577627513807
Validation loss: 3.5459656588047994

Epoch: 6| Step: 13
Training loss: 4.275178711485254
Validation loss: 3.542573480976616

Epoch: 29| Step: 0
Training loss: 3.923164672359262
Validation loss: 3.5427500077075758

Epoch: 6| Step: 1
Training loss: 3.9874175777706253
Validation loss: 3.5418584599159195

Epoch: 6| Step: 2
Training loss: 3.8378314841181185
Validation loss: 3.5390056382881903

Epoch: 6| Step: 3
Training loss: 3.9190079745566573
Validation loss: 3.5397422518206514

Epoch: 6| Step: 4
Training loss: 3.5088981868380995
Validation loss: 3.5383955459636174

Epoch: 6| Step: 5
Training loss: 3.649655908538834
Validation loss: 3.5395697078314505

Epoch: 6| Step: 6
Training loss: 3.240725267968757
Validation loss: 3.539176304708791

Epoch: 6| Step: 7
Training loss: 3.7754891388142924
Validation loss: 3.5412848834438804

Epoch: 6| Step: 8
Training loss: 3.402772300525504
Validation loss: 3.5381898195901074

Epoch: 6| Step: 9
Training loss: 4.6470933012489315
Validation loss: 3.5366969966439386

Epoch: 6| Step: 10
Training loss: 3.8673736835705474
Validation loss: 3.5334476533328916

Epoch: 6| Step: 11
Training loss: 3.755332207543518
Validation loss: 3.5341026768967456

Epoch: 6| Step: 12
Training loss: 3.5666118783991196
Validation loss: 3.5315388684679188

Epoch: 6| Step: 13
Training loss: 2.5472603722833913
Validation loss: 3.5319707499562623

Epoch: 30| Step: 0
Training loss: 3.7776146429654616
Validation loss: 3.5305091457543267

Epoch: 6| Step: 1
Training loss: 4.131165491760467
Validation loss: 3.530167759652924

Epoch: 6| Step: 2
Training loss: 3.7342181950931113
Validation loss: 3.5239698071922723

Epoch: 6| Step: 3
Training loss: 3.7684449839484055
Validation loss: 3.522511814591671

Epoch: 6| Step: 4
Training loss: 4.288103173537723
Validation loss: 3.521296132463934

Epoch: 6| Step: 5
Training loss: 3.1787410892867207
Validation loss: 3.5170708071302865

Epoch: 6| Step: 6
Training loss: 4.062979097726147
Validation loss: 3.5266930291494942

Epoch: 6| Step: 7
Training loss: 3.54229157862403
Validation loss: 3.5472419508835626

Epoch: 6| Step: 8
Training loss: 3.824505398754848
Validation loss: 3.5540420741398564

Epoch: 6| Step: 9
Training loss: 3.705589279283159
Validation loss: 3.5422621996592527

Epoch: 6| Step: 10
Training loss: 4.270977979241982
Validation loss: 3.5303844073809034

Epoch: 6| Step: 11
Training loss: 3.544483874456096
Validation loss: 3.5279376929526105

Epoch: 6| Step: 12
Training loss: 2.52488454422572
Validation loss: 3.522492030356327

Epoch: 6| Step: 13
Training loss: 3.57172123935986
Validation loss: 3.522102775632501

Epoch: 31| Step: 0
Training loss: 4.634282462700326
Validation loss: 3.5200831810756674

Epoch: 6| Step: 1
Training loss: 3.8010346660443264
Validation loss: 3.5185977230885284

Epoch: 6| Step: 2
Training loss: 3.2443130327926952
Validation loss: 3.519649293172452

Epoch: 6| Step: 3
Training loss: 3.5399093456837534
Validation loss: 3.518223976563833

Epoch: 6| Step: 4
Training loss: 4.675593602646553
Validation loss: 3.522018850969941

Epoch: 6| Step: 5
Training loss: 3.870466225704765
Validation loss: 3.515129234150641

Epoch: 6| Step: 6
Training loss: 4.030185056086595
Validation loss: 3.5121069628578074

Epoch: 6| Step: 7
Training loss: 3.5429761522714154
Validation loss: 3.5119041786212235

Epoch: 6| Step: 8
Training loss: 2.9002472607665686
Validation loss: 3.5112530189839695

Epoch: 6| Step: 9
Training loss: 2.4143088008328197
Validation loss: 3.5093809854013367

Epoch: 6| Step: 10
Training loss: 4.012599176149731
Validation loss: 3.50969199096748

Epoch: 6| Step: 11
Training loss: 3.784900762952761
Validation loss: 3.50844511137025

Epoch: 6| Step: 12
Training loss: 3.419342636822634
Validation loss: 3.504222328507061

Epoch: 6| Step: 13
Training loss: 3.5826330313836268
Validation loss: 3.5041676917618494

Epoch: 32| Step: 0
Training loss: 4.239838513591985
Validation loss: 3.502621490780897

Epoch: 6| Step: 1
Training loss: 2.591415549702327
Validation loss: 3.5020018769442127

Epoch: 6| Step: 2
Training loss: 3.5214097644012976
Validation loss: 3.498895588090078

Epoch: 6| Step: 3
Training loss: 3.4983227662000647
Validation loss: 3.4988398071979594

Epoch: 6| Step: 4
Training loss: 3.8621694972784413
Validation loss: 3.499089332040162

Epoch: 6| Step: 5
Training loss: 3.4105021682551167
Validation loss: 3.4974496899116763

Epoch: 6| Step: 6
Training loss: 3.7679680463808825
Validation loss: 3.4978562922846836

Epoch: 6| Step: 7
Training loss: 3.985102089755228
Validation loss: 3.493721539998585

Epoch: 6| Step: 8
Training loss: 4.440286540502491
Validation loss: 3.4932934910863787

Epoch: 6| Step: 9
Training loss: 4.205190611883769
Validation loss: 3.4884599979018565

Epoch: 6| Step: 10
Training loss: 3.872273377990196
Validation loss: 3.4881967695711693

Epoch: 6| Step: 11
Training loss: 2.8127581160040633
Validation loss: 3.4870873953314736

Epoch: 6| Step: 12
Training loss: 3.8582875808628656
Validation loss: 3.485912510393686

Epoch: 6| Step: 13
Training loss: 3.0724554373083435
Validation loss: 3.4845294841811905

Epoch: 33| Step: 0
Training loss: 3.4625007767108364
Validation loss: 3.4846328543557834

Epoch: 6| Step: 1
Training loss: 3.109120880937683
Validation loss: 3.4833462001654945

Epoch: 6| Step: 2
Training loss: 3.8793461944852874
Validation loss: 3.4820238131743926

Epoch: 6| Step: 3
Training loss: 3.365771073170632
Validation loss: 3.482405507782518

Epoch: 6| Step: 4
Training loss: 3.390774350019332
Validation loss: 3.481337787197846

Epoch: 6| Step: 5
Training loss: 3.4912300589511323
Validation loss: 3.480850344834552

Epoch: 6| Step: 6
Training loss: 3.637197034875594
Validation loss: 3.4796082543874505

Epoch: 6| Step: 7
Training loss: 4.418283898187221
Validation loss: 3.4790986096010657

Epoch: 6| Step: 8
Training loss: 4.61123960895562
Validation loss: 3.479510232812432

Epoch: 6| Step: 9
Training loss: 3.6032859005366005
Validation loss: 3.474591859079353

Epoch: 6| Step: 10
Training loss: 3.810606564475161
Validation loss: 3.4739851974159754

Epoch: 6| Step: 11
Training loss: 3.8714986179472013
Validation loss: 3.4740605121661066

Epoch: 6| Step: 12
Training loss: 3.2517108815555176
Validation loss: 3.473520335108312

Epoch: 6| Step: 13
Training loss: 3.407879920652849
Validation loss: 3.472852931230825

Epoch: 34| Step: 0
Training loss: 4.128600196719293
Validation loss: 3.4738310634866068

Epoch: 6| Step: 1
Training loss: 3.4069382558411254
Validation loss: 3.4735808991748067

Epoch: 6| Step: 2
Training loss: 3.903360747890698
Validation loss: 3.4702690971675003

Epoch: 6| Step: 3
Training loss: 3.601404414151854
Validation loss: 3.466473675870493

Epoch: 6| Step: 4
Training loss: 4.3160664282239445
Validation loss: 3.4648711365796894

Epoch: 6| Step: 5
Training loss: 3.98910373497587
Validation loss: 3.465059153581597

Epoch: 6| Step: 6
Training loss: 3.176762615754899
Validation loss: 3.4640959699607725

Epoch: 6| Step: 7
Training loss: 4.462413216396167
Validation loss: 3.463849220557821

Epoch: 6| Step: 8
Training loss: 3.450358667941489
Validation loss: 3.4632744764321894

Epoch: 6| Step: 9
Training loss: 2.7094843154906605
Validation loss: 3.4591282374409964

Epoch: 6| Step: 10
Training loss: 3.056864945343085
Validation loss: 3.459518030045517

Epoch: 6| Step: 11
Training loss: 3.8040005104794647
Validation loss: 3.4565150856374576

Epoch: 6| Step: 12
Training loss: 2.9038568303149517
Validation loss: 3.456217243070727

Epoch: 6| Step: 13
Training loss: 4.441264530225756
Validation loss: 3.457166946275777

Epoch: 35| Step: 0
Training loss: 3.7809506132284842
Validation loss: 3.4553317189435355

Epoch: 6| Step: 1
Training loss: 4.223137050925925
Validation loss: 3.4543219879374107

Epoch: 6| Step: 2
Training loss: 4.350701567101169
Validation loss: 3.4534783521046206

Epoch: 6| Step: 3
Training loss: 2.850153828535133
Validation loss: 3.4542542849710993

Epoch: 6| Step: 4
Training loss: 4.297135112865623
Validation loss: 3.4520629502773352

Epoch: 6| Step: 5
Training loss: 3.9962153411593677
Validation loss: 3.4539987110869186

Epoch: 6| Step: 6
Training loss: 3.1326872308281666
Validation loss: 3.4532660880196975

Epoch: 6| Step: 7
Training loss: 3.778025868316669
Validation loss: 3.451621346697688

Epoch: 6| Step: 8
Training loss: 3.5064460794765355
Validation loss: 3.4559172903440767

Epoch: 6| Step: 9
Training loss: 3.338225462286894
Validation loss: 3.453724524154054

Epoch: 6| Step: 10
Training loss: 4.26969028466388
Validation loss: 3.449127013577199

Epoch: 6| Step: 11
Training loss: 2.9121144510246673
Validation loss: 3.44938391683016

Epoch: 6| Step: 12
Training loss: 2.9140098096568527
Validation loss: 3.447738426237842

Epoch: 6| Step: 13
Training loss: 3.4228328949205644
Validation loss: 3.4471586458844343

Epoch: 36| Step: 0
Training loss: 3.771725979241837
Validation loss: 3.447982426597375

Epoch: 6| Step: 1
Training loss: 3.049728231360337
Validation loss: 3.447480084887775

Epoch: 6| Step: 2
Training loss: 4.194026586562019
Validation loss: 3.446226523571931

Epoch: 6| Step: 3
Training loss: 3.9952259184131447
Validation loss: 3.447087982071035

Epoch: 6| Step: 4
Training loss: 3.674729556558247
Validation loss: 3.444852649704568

Epoch: 6| Step: 5
Training loss: 3.5109384452706505
Validation loss: 3.4455599265942043

Epoch: 6| Step: 6
Training loss: 3.4942383344708956
Validation loss: 3.444435159532001

Epoch: 6| Step: 7
Training loss: 3.8166090287655337
Validation loss: 3.4437478124387026

Epoch: 6| Step: 8
Training loss: 3.9222001020788153
Validation loss: 3.443327468563152

Epoch: 6| Step: 9
Training loss: 3.2238784969142698
Validation loss: 3.443415308641657

Epoch: 6| Step: 10
Training loss: 4.027404370300313
Validation loss: 3.44235075774607

Epoch: 6| Step: 11
Training loss: 3.6171123587463936
Validation loss: 3.4426589214389414

Epoch: 6| Step: 12
Training loss: 3.283953325114156
Validation loss: 3.441628348137633

Epoch: 6| Step: 13
Training loss: 3.4807047994010825
Validation loss: 3.4408428431240314

Epoch: 37| Step: 0
Training loss: 3.378248840941597
Validation loss: 3.4393981659754123

Epoch: 6| Step: 1
Training loss: 3.9356098785279516
Validation loss: 3.440530274002849

Epoch: 6| Step: 2
Training loss: 3.963292492099175
Validation loss: 3.4399572537323504

Epoch: 6| Step: 3
Training loss: 3.4643241897041954
Validation loss: 3.4394633185674373

Epoch: 6| Step: 4
Training loss: 3.1091251752162656
Validation loss: 3.437720795641214

Epoch: 6| Step: 5
Training loss: 4.426872745067944
Validation loss: 3.436525348747108

Epoch: 6| Step: 6
Training loss: 3.0185286225520565
Validation loss: 3.437089303728438

Epoch: 6| Step: 7
Training loss: 3.069788453706981
Validation loss: 3.436047945573209

Epoch: 6| Step: 8
Training loss: 3.900764703362162
Validation loss: 3.436419592967933

Epoch: 6| Step: 9
Training loss: 3.4923203547592987
Validation loss: 3.4349087178288116

Epoch: 6| Step: 10
Training loss: 3.65714337772553
Validation loss: 3.4350955104665486

Epoch: 6| Step: 11
Training loss: 3.644064919422113
Validation loss: 3.433240580289038

Epoch: 6| Step: 12
Training loss: 3.895540739825429
Validation loss: 3.4322130954647614

Epoch: 6| Step: 13
Training loss: 4.222404648927801
Validation loss: 3.4320511919564582

Epoch: 38| Step: 0
Training loss: 2.5020770028124493
Validation loss: 3.431659098244122

Epoch: 6| Step: 1
Training loss: 3.149219501015477
Validation loss: 3.431069061740444

Epoch: 6| Step: 2
Training loss: 3.6877476237285975
Validation loss: 3.429599713467521

Epoch: 6| Step: 3
Training loss: 4.08850787041499
Validation loss: 3.4292014402178106

Epoch: 6| Step: 4
Training loss: 3.4407136633706767
Validation loss: 3.4294904393012184

Epoch: 6| Step: 5
Training loss: 3.2117185362062077
Validation loss: 3.4286155897132082

Epoch: 6| Step: 6
Training loss: 2.7983520699245434
Validation loss: 3.4289720715832557

Epoch: 6| Step: 7
Training loss: 3.6907001122721397
Validation loss: 3.4280144996447937

Epoch: 6| Step: 8
Training loss: 4.184409752061159
Validation loss: 3.428019873690664

Epoch: 6| Step: 9
Training loss: 3.859304821287544
Validation loss: 3.427274106523228

Epoch: 6| Step: 10
Training loss: 3.660707283677904
Validation loss: 3.426206731283356

Epoch: 6| Step: 11
Training loss: 4.210934102865629
Validation loss: 3.4255644572449904

Epoch: 6| Step: 12
Training loss: 4.356912115450884
Validation loss: 3.4249604244653824

Epoch: 6| Step: 13
Training loss: 3.853418116005297
Validation loss: 3.4256045824135617

Epoch: 39| Step: 0
Training loss: 3.6869271043483245
Validation loss: 3.4248578551607203

Epoch: 6| Step: 1
Training loss: 2.823788432028186
Validation loss: 3.4229974468306605

Epoch: 6| Step: 2
Training loss: 3.514567712109546
Validation loss: 3.422629902763276

Epoch: 6| Step: 3
Training loss: 4.3307621492593
Validation loss: 3.4227582924925586

Epoch: 6| Step: 4
Training loss: 4.0804233432370935
Validation loss: 3.4226915036496703

Epoch: 6| Step: 5
Training loss: 3.849278637571342
Validation loss: 3.422111730421493

Epoch: 6| Step: 6
Training loss: 3.1668477926822756
Validation loss: 3.421657501214501

Epoch: 6| Step: 7
Training loss: 3.192279896867035
Validation loss: 3.4220200973916626

Epoch: 6| Step: 8
Training loss: 3.7735790281429944
Validation loss: 3.429550955656008

Epoch: 6| Step: 9
Training loss: 3.142552330048734
Validation loss: 3.4350998032297855

Epoch: 6| Step: 10
Training loss: 3.939221565881384
Validation loss: 3.442682287576775

Epoch: 6| Step: 11
Training loss: 3.564301018800813
Validation loss: 3.428730088985513

Epoch: 6| Step: 12
Training loss: 4.474862566494492
Validation loss: 3.4269695909549927

Epoch: 6| Step: 13
Training loss: 2.7230441502617806
Validation loss: 3.4223659940598683

Epoch: 40| Step: 0
Training loss: 3.861992199550596
Validation loss: 3.4218077968370744

Epoch: 6| Step: 1
Training loss: 3.7882836868740872
Validation loss: 3.422041745051052

Epoch: 6| Step: 2
Training loss: 3.008142230303344
Validation loss: 3.424043867179047

Epoch: 6| Step: 3
Training loss: 3.8644373507145455
Validation loss: 3.4265315423299674

Epoch: 6| Step: 4
Training loss: 3.0355771041776745
Validation loss: 3.4188721249418714

Epoch: 6| Step: 5
Training loss: 3.511353606355353
Validation loss: 3.418567423388215

Epoch: 6| Step: 6
Training loss: 2.3495103366492103
Validation loss: 3.420158220409357

Epoch: 6| Step: 7
Training loss: 3.7279499278246315
Validation loss: 3.4203011465192676

Epoch: 6| Step: 8
Training loss: 4.402327719441754
Validation loss: 3.4201934664070723

Epoch: 6| Step: 9
Training loss: 4.210339335631629
Validation loss: 3.4211773354314294

Epoch: 6| Step: 10
Training loss: 4.096450962960909
Validation loss: 3.4197963788719843

Epoch: 6| Step: 11
Training loss: 3.416277204196563
Validation loss: 3.419050924954576

Epoch: 6| Step: 12
Training loss: 3.9069797902264343
Validation loss: 3.4207209871277184

Epoch: 6| Step: 13
Training loss: 3.1001273036782266
Validation loss: 3.419257593503765

Epoch: 41| Step: 0
Training loss: 3.8851457489442467
Validation loss: 3.416731395353403

Epoch: 6| Step: 1
Training loss: 2.894483805279179
Validation loss: 3.4177002012636613

Epoch: 6| Step: 2
Training loss: 3.770258794750638
Validation loss: 3.4159181786943886

Epoch: 6| Step: 3
Training loss: 3.8829743564573374
Validation loss: 3.4160243140098836

Epoch: 6| Step: 4
Training loss: 3.0172854580971507
Validation loss: 3.415621013489106

Epoch: 6| Step: 5
Training loss: 2.905184806946403
Validation loss: 3.413414860084731

Epoch: 6| Step: 6
Training loss: 3.6948649677798717
Validation loss: 3.4132648843905953

Epoch: 6| Step: 7
Training loss: 4.365584132031219
Validation loss: 3.412890422606361

Epoch: 6| Step: 8
Training loss: 2.5474167698075396
Validation loss: 3.4114087453527624

Epoch: 6| Step: 9
Training loss: 4.604789703239397
Validation loss: 3.412534968284781

Epoch: 6| Step: 10
Training loss: 3.606053793609067
Validation loss: 3.41054154005068

Epoch: 6| Step: 11
Training loss: 3.6895469544547033
Validation loss: 3.4101653268145413

Epoch: 6| Step: 12
Training loss: 3.740177514662442
Validation loss: 3.4109776550033524

Epoch: 6| Step: 13
Training loss: 3.8654524793189537
Validation loss: 3.411341325484356

Epoch: 42| Step: 0
Training loss: 4.047170503056493
Validation loss: 3.4090291645179964

Epoch: 6| Step: 1
Training loss: 3.5484690844105686
Validation loss: 3.409610109676434

Epoch: 6| Step: 2
Training loss: 3.2440155391015204
Validation loss: 3.408968763652308

Epoch: 6| Step: 3
Training loss: 4.298307200945644
Validation loss: 3.410357669313981

Epoch: 6| Step: 4
Training loss: 3.5130319484405717
Validation loss: 3.4142577615614385

Epoch: 6| Step: 5
Training loss: 3.4359010619017734
Validation loss: 3.4063479847929856

Epoch: 6| Step: 6
Training loss: 4.156285565446399
Validation loss: 3.405760604323656

Epoch: 6| Step: 7
Training loss: 3.485000622611079
Validation loss: 3.4057582828832103

Epoch: 6| Step: 8
Training loss: 2.99163733621173
Validation loss: 3.4064137740331577

Epoch: 6| Step: 9
Training loss: 4.0116479081805005
Validation loss: 3.405988162542894

Epoch: 6| Step: 10
Training loss: 3.6396908850992697
Validation loss: 3.405118893130294

Epoch: 6| Step: 11
Training loss: 3.456382906188123
Validation loss: 3.405425239895951

Epoch: 6| Step: 12
Training loss: 3.491250409523366
Validation loss: 3.4052621666496043

Epoch: 6| Step: 13
Training loss: 3.0560306025665454
Validation loss: 3.4045432402870888

Epoch: 43| Step: 0
Training loss: 4.249765726252136
Validation loss: 3.4057148617191597

Epoch: 6| Step: 1
Training loss: 3.9203893271589068
Validation loss: 3.4040812685306796

Epoch: 6| Step: 2
Training loss: 2.52364686268678
Validation loss: 3.404362345428064

Epoch: 6| Step: 3
Training loss: 3.1118643299233213
Validation loss: 3.4037491000917086

Epoch: 6| Step: 4
Training loss: 2.6516578023280024
Validation loss: 3.404588349550696

Epoch: 6| Step: 5
Training loss: 4.492628629835236
Validation loss: 3.4025957025486933

Epoch: 6| Step: 6
Training loss: 4.14006620271244
Validation loss: 3.401668306492711

Epoch: 6| Step: 7
Training loss: 3.8555166131385055
Validation loss: 3.4034792199647743

Epoch: 6| Step: 8
Training loss: 3.7575703818505577
Validation loss: 3.402248712165516

Epoch: 6| Step: 9
Training loss: 3.7491216266609144
Validation loss: 3.401415413974169

Epoch: 6| Step: 10
Training loss: 2.9684611932917537
Validation loss: 3.4009580346399653

Epoch: 6| Step: 11
Training loss: 3.210418287933224
Validation loss: 3.400252222602084

Epoch: 6| Step: 12
Training loss: 4.511118610315296
Validation loss: 3.3993925075474096

Epoch: 6| Step: 13
Training loss: 2.098447398306537
Validation loss: 3.400290898818078

Epoch: 44| Step: 0
Training loss: 3.4039556493144856
Validation loss: 3.4006025513306986

Epoch: 6| Step: 1
Training loss: 3.0696380884029986
Validation loss: 3.3989190801070084

Epoch: 6| Step: 2
Training loss: 3.963345790572891
Validation loss: 3.3984462445139165

Epoch: 6| Step: 3
Training loss: 3.456741165662995
Validation loss: 3.3986035951490705

Epoch: 6| Step: 4
Training loss: 4.135414155563758
Validation loss: 3.3974838418061797

Epoch: 6| Step: 5
Training loss: 4.343029813273722
Validation loss: 3.3975143632859317

Epoch: 6| Step: 6
Training loss: 3.1024671335500558
Validation loss: 3.396197882966671

Epoch: 6| Step: 7
Training loss: 3.6534298184687444
Validation loss: 3.396154732099337

Epoch: 6| Step: 8
Training loss: 3.283189182376701
Validation loss: 3.3964029198452734

Epoch: 6| Step: 9
Training loss: 2.9729908417766926
Validation loss: 3.3951778497687415

Epoch: 6| Step: 10
Training loss: 4.085829199090513
Validation loss: 3.395495860678675

Epoch: 6| Step: 11
Training loss: 3.1327601402264116
Validation loss: 3.3950577637958745

Epoch: 6| Step: 12
Training loss: 3.7337727719491487
Validation loss: 3.3948288778366598

Epoch: 6| Step: 13
Training loss: 4.380068649381082
Validation loss: 3.3943556220188067

Epoch: 45| Step: 0
Training loss: 3.2868386767437303
Validation loss: 3.394377937028096

Epoch: 6| Step: 1
Training loss: 3.1143861195738776
Validation loss: 3.393520143890386

Epoch: 6| Step: 2
Training loss: 3.18094034842594
Validation loss: 3.394284225994065

Epoch: 6| Step: 3
Training loss: 3.7756922207199923
Validation loss: 3.3954008380497487

Epoch: 6| Step: 4
Training loss: 3.94619082503468
Validation loss: 3.39360097928365

Epoch: 6| Step: 5
Training loss: 3.5307912612964203
Validation loss: 3.393369515561323

Epoch: 6| Step: 6
Training loss: 3.9908319549547544
Validation loss: 3.3929446357846587

Epoch: 6| Step: 7
Training loss: 4.1007341983571886
Validation loss: 3.3921942635191678

Epoch: 6| Step: 8
Training loss: 3.910878849237481
Validation loss: 3.3915665908186376

Epoch: 6| Step: 9
Training loss: 2.9103853071558063
Validation loss: 3.3912373906477447

Epoch: 6| Step: 10
Training loss: 3.2021703274354727
Validation loss: 3.391559942031262

Epoch: 6| Step: 11
Training loss: 4.422577818967048
Validation loss: 3.3910689025794403

Epoch: 6| Step: 12
Training loss: 3.5451876622123595
Validation loss: 3.390817490726734

Epoch: 6| Step: 13
Training loss: 3.3570910829534557
Validation loss: 3.3913793479383347

Epoch: 46| Step: 0
Training loss: 3.1508605568701915
Validation loss: 3.3913701770001845

Epoch: 6| Step: 1
Training loss: 4.289664360023436
Validation loss: 3.390393631028669

Epoch: 6| Step: 2
Training loss: 3.698786000253514
Validation loss: 3.390458793757142

Epoch: 6| Step: 3
Training loss: 3.570265220813188
Validation loss: 3.389751049687855

Epoch: 6| Step: 4
Training loss: 3.6765742971714945
Validation loss: 3.389219365166211

Epoch: 6| Step: 5
Training loss: 4.223642634562279
Validation loss: 3.3888848518949586

Epoch: 6| Step: 6
Training loss: 3.1794565477780923
Validation loss: 3.3893737434916353

Epoch: 6| Step: 7
Training loss: 3.848749894144937
Validation loss: 3.388673587789301

Epoch: 6| Step: 8
Training loss: 3.360580866649619
Validation loss: 3.3885195997294915

Epoch: 6| Step: 9
Training loss: 3.626654148874932
Validation loss: 3.387776786322445

Epoch: 6| Step: 10
Training loss: 3.0689204897010502
Validation loss: 3.3872690504183853

Epoch: 6| Step: 11
Training loss: 3.657219913002967
Validation loss: 3.3875985060599674

Epoch: 6| Step: 12
Training loss: 3.390792772211902
Validation loss: 3.3873180739988555

Epoch: 6| Step: 13
Training loss: 3.766910570963132
Validation loss: 3.387426328423654

Epoch: 47| Step: 0
Training loss: 3.9313256430815655
Validation loss: 3.3869300815428143

Epoch: 6| Step: 1
Training loss: 3.587151614828076
Validation loss: 3.3865352905995842

Epoch: 6| Step: 2
Training loss: 3.475805307289188
Validation loss: 3.386197694305662

Epoch: 6| Step: 3
Training loss: 3.5786985245872294
Validation loss: 3.3861629302825316

Epoch: 6| Step: 4
Training loss: 3.3603480149737885
Validation loss: 3.3867158439952947

Epoch: 6| Step: 5
Training loss: 3.860567348865572
Validation loss: 3.3860409497855875

Epoch: 6| Step: 6
Training loss: 3.4203805664873745
Validation loss: 3.385946102472026

Epoch: 6| Step: 7
Training loss: 2.9967772339595125
Validation loss: 3.385012496915722

Epoch: 6| Step: 8
Training loss: 3.6909659955719927
Validation loss: 3.38489176704703

Epoch: 6| Step: 9
Training loss: 3.613447525734978
Validation loss: 3.3850538782897175

Epoch: 6| Step: 10
Training loss: 4.044988597575598
Validation loss: 3.38436813789355

Epoch: 6| Step: 11
Training loss: 4.015703133739494
Validation loss: 3.384614398008002

Epoch: 6| Step: 12
Training loss: 3.4203052839583825
Validation loss: 3.3834624091618246

Epoch: 6| Step: 13
Training loss: 3.4125318085581835
Validation loss: 3.3837430531820236

Epoch: 48| Step: 0
Training loss: 3.5167589859498176
Validation loss: 3.383515817313903

Epoch: 6| Step: 1
Training loss: 3.118908858601309
Validation loss: 3.383277091005341

Epoch: 6| Step: 2
Training loss: 3.2544081210448628
Validation loss: 3.383229786551067

Epoch: 6| Step: 3
Training loss: 2.920283082800605
Validation loss: 3.3819086424256355

Epoch: 6| Step: 4
Training loss: 3.917476299825231
Validation loss: 3.381841152961157

Epoch: 6| Step: 5
Training loss: 4.180800359295707
Validation loss: 3.3821181028625267

Epoch: 6| Step: 6
Training loss: 4.131365401925677
Validation loss: 3.382099888866199

Epoch: 6| Step: 7
Training loss: 4.0415607451621876
Validation loss: 3.3816494188313766

Epoch: 6| Step: 8
Training loss: 3.8018517549962114
Validation loss: 3.3814952200736865

Epoch: 6| Step: 9
Training loss: 3.617996553772592
Validation loss: 3.3810691180530936

Epoch: 6| Step: 10
Training loss: 3.295584041717855
Validation loss: 3.3814242030082493

Epoch: 6| Step: 11
Training loss: 2.8127248038412067
Validation loss: 3.380554474754263

Epoch: 6| Step: 12
Training loss: 3.1925878870254825
Validation loss: 3.381197530078416

Epoch: 6| Step: 13
Training loss: 4.85295008966236
Validation loss: 3.380313295952206

Epoch: 49| Step: 0
Training loss: 3.8135224519085944
Validation loss: 3.3813873125446436

Epoch: 6| Step: 1
Training loss: 2.9926314460357055
Validation loss: 3.38021048675918

Epoch: 6| Step: 2
Training loss: 3.5593802193326254
Validation loss: 3.380308518008269

Epoch: 6| Step: 3
Training loss: 3.832463760154868
Validation loss: 3.3788378614050747

Epoch: 6| Step: 4
Training loss: 3.4478860874875257
Validation loss: 3.3789778237649095

Epoch: 6| Step: 5
Training loss: 3.7757620591746033
Validation loss: 3.3795376243422584

Epoch: 6| Step: 6
Training loss: 4.225358773973972
Validation loss: 3.378595013652182

Epoch: 6| Step: 7
Training loss: 4.326950850438375
Validation loss: 3.377996651009221

Epoch: 6| Step: 8
Training loss: 4.0511748693762435
Validation loss: 3.3774682495014643

Epoch: 6| Step: 9
Training loss: 3.858647698818672
Validation loss: 3.3774777686351847

Epoch: 6| Step: 10
Training loss: 3.323021642926129
Validation loss: 3.3770348633007914

Epoch: 6| Step: 11
Training loss: 2.3123160624165906
Validation loss: 3.3761628227901626

Epoch: 6| Step: 12
Training loss: 3.184367417016701
Validation loss: 3.376557817455053

Epoch: 6| Step: 13
Training loss: 3.1283496452100024
Validation loss: 3.3768326718230623

Epoch: 50| Step: 0
Training loss: 3.154325899634265
Validation loss: 3.3761318455520937

Epoch: 6| Step: 1
Training loss: 4.2774055093286805
Validation loss: 3.3763854837796035

Epoch: 6| Step: 2
Training loss: 4.071334388427531
Validation loss: 3.375800926065966

Epoch: 6| Step: 3
Training loss: 3.4115042103407776
Validation loss: 3.3762911700883254

Epoch: 6| Step: 4
Training loss: 3.8393345725160235
Validation loss: 3.3750776405777443

Epoch: 6| Step: 5
Training loss: 4.055447604573076
Validation loss: 3.3745161504986716

Epoch: 6| Step: 6
Training loss: 3.2521953504007057
Validation loss: 3.3748001713997415

Epoch: 6| Step: 7
Training loss: 2.6557681375893427
Validation loss: 3.3755962767242487

Epoch: 6| Step: 8
Training loss: 3.376879274830503
Validation loss: 3.375935513340403

Epoch: 6| Step: 9
Training loss: 3.940036501642763
Validation loss: 3.3750648872096214

Epoch: 6| Step: 10
Training loss: 3.868203139595283
Validation loss: 3.375789467962719

Epoch: 6| Step: 11
Training loss: 2.6143501045998767
Validation loss: 3.375793615909942

Epoch: 6| Step: 12
Training loss: 3.6021148191936216
Validation loss: 3.375624325096991

Epoch: 6| Step: 13
Training loss: 4.156067349428818
Validation loss: 3.3756335798241017

Epoch: 51| Step: 0
Training loss: 3.041163015254454
Validation loss: 3.373071039531779

Epoch: 6| Step: 1
Training loss: 4.069551656711769
Validation loss: 3.373841967026305

Epoch: 6| Step: 2
Training loss: 3.641085092180425
Validation loss: 3.373106108728334

Epoch: 6| Step: 3
Training loss: 4.836622741170255
Validation loss: 3.373328124109627

Epoch: 6| Step: 4
Training loss: 3.8158819488563087
Validation loss: 3.3730367543313045

Epoch: 6| Step: 5
Training loss: 3.012005625320592
Validation loss: 3.372982363957384

Epoch: 6| Step: 6
Training loss: 3.8443421938852587
Validation loss: 3.3729510694477165

Epoch: 6| Step: 7
Training loss: 3.5499891146640716
Validation loss: 3.373328117269864

Epoch: 6| Step: 8
Training loss: 3.1269747788717766
Validation loss: 3.3730798786879

Epoch: 6| Step: 9
Training loss: 3.3415374565987643
Validation loss: 3.37120174062503

Epoch: 6| Step: 10
Training loss: 4.748363012022702
Validation loss: 3.3726943179442457

Epoch: 6| Step: 11
Training loss: 2.5143400903184747
Validation loss: 3.3706731523783304

Epoch: 6| Step: 12
Training loss: 2.6460284864488197
Validation loss: 3.3703801824073363

Epoch: 6| Step: 13
Training loss: 3.31725229495604
Validation loss: 3.371779664301314

Epoch: 52| Step: 0
Training loss: 3.8409171481404534
Validation loss: 3.3706311350602483

Epoch: 6| Step: 1
Training loss: 3.01387676894822
Validation loss: 3.370337898252674

Epoch: 6| Step: 2
Training loss: 3.9682217944823948
Validation loss: 3.370095982222198

Epoch: 6| Step: 3
Training loss: 3.2520035656748765
Validation loss: 3.3697502708196945

Epoch: 6| Step: 4
Training loss: 3.722112081489214
Validation loss: 3.3696964634213322

Epoch: 6| Step: 5
Training loss: 3.896800092942345
Validation loss: 3.370044923479699

Epoch: 6| Step: 6
Training loss: 3.9985759107418284
Validation loss: 3.3701138495565237

Epoch: 6| Step: 7
Training loss: 2.826354088804645
Validation loss: 3.369243207394981

Epoch: 6| Step: 8
Training loss: 3.7948145672071125
Validation loss: 3.368667888102947

Epoch: 6| Step: 9
Training loss: 4.250799889182738
Validation loss: 3.3685295172092284

Epoch: 6| Step: 10
Training loss: 4.1728820728246285
Validation loss: 3.3683556554974605

Epoch: 6| Step: 11
Training loss: 3.157680980240663
Validation loss: 3.368276378847873

Epoch: 6| Step: 12
Training loss: 2.9652969355762155
Validation loss: 3.3684457801871646

Epoch: 6| Step: 13
Training loss: 2.7705463652807563
Validation loss: 3.3682413841894205

Epoch: 53| Step: 0
Training loss: 4.3037808496775
Validation loss: 3.3668273241309374

Epoch: 6| Step: 1
Training loss: 2.9647585086354615
Validation loss: 3.366974085654737

Epoch: 6| Step: 2
Training loss: 3.9318434032407015
Validation loss: 3.3673619914928588

Epoch: 6| Step: 3
Training loss: 3.0337311333634323
Validation loss: 3.366662209959765

Epoch: 6| Step: 4
Training loss: 4.382159668959794
Validation loss: 3.3666624741927675

Epoch: 6| Step: 5
Training loss: 3.4041801953523554
Validation loss: 3.3656157675980656

Epoch: 6| Step: 6
Training loss: 3.736280011247649
Validation loss: 3.365162859361348

Epoch: 6| Step: 7
Training loss: 2.3378286202095104
Validation loss: 3.3651811010367747

Epoch: 6| Step: 8
Training loss: 2.775884188443193
Validation loss: 3.3648018199177328

Epoch: 6| Step: 9
Training loss: 4.126962137280151
Validation loss: 3.3648895720657217

Epoch: 6| Step: 10
Training loss: 3.8809037304413536
Validation loss: 3.3644673408658514

Epoch: 6| Step: 11
Training loss: 3.7359220101591
Validation loss: 3.3643108793384413

Epoch: 6| Step: 12
Training loss: 3.63388367314183
Validation loss: 3.3639884480482185

Epoch: 6| Step: 13
Training loss: 3.4526957939919365
Validation loss: 3.363944393227413

Epoch: 54| Step: 0
Training loss: 3.822750382440658
Validation loss: 3.363488662367082

Epoch: 6| Step: 1
Training loss: 3.270377757099828
Validation loss: 3.363746168354878

Epoch: 6| Step: 2
Training loss: 4.307934099265363
Validation loss: 3.362916254092264

Epoch: 6| Step: 3
Training loss: 4.063337973220926
Validation loss: 3.3630464828792648

Epoch: 6| Step: 4
Training loss: 2.7431040044655957
Validation loss: 3.363212113767177

Epoch: 6| Step: 5
Training loss: 3.3833596577739913
Validation loss: 3.3627597539402636

Epoch: 6| Step: 6
Training loss: 2.9046329388513876
Validation loss: 3.3631282352021286

Epoch: 6| Step: 7
Training loss: 4.535765614342517
Validation loss: 3.361897689391107

Epoch: 6| Step: 8
Training loss: 2.7394656505377237
Validation loss: 3.361471698489006

Epoch: 6| Step: 9
Training loss: 3.7014385519856976
Validation loss: 3.36283373732015

Epoch: 6| Step: 10
Training loss: 3.0336215780054108
Validation loss: 3.3615499924239005

Epoch: 6| Step: 11
Training loss: 3.562752162642261
Validation loss: 3.361929574823412

Epoch: 6| Step: 12
Training loss: 4.281330191425068
Validation loss: 3.3602409770991066

Epoch: 6| Step: 13
Training loss: 3.2065350500630294
Validation loss: 3.3606494833569402

Epoch: 55| Step: 0
Training loss: 3.714105606952329
Validation loss: 3.360412156721021

Epoch: 6| Step: 1
Training loss: 3.7230343541587274
Validation loss: 3.3594211812719164

Epoch: 6| Step: 2
Training loss: 4.048886539315711
Validation loss: 3.3602596353506264

Epoch: 6| Step: 3
Training loss: 3.4180351556049233
Validation loss: 3.359892122875438

Epoch: 6| Step: 4
Training loss: 2.8826110273220817
Validation loss: 3.359495726560258

Epoch: 6| Step: 5
Training loss: 2.843735076529781
Validation loss: 3.3590379603604847

Epoch: 6| Step: 6
Training loss: 4.3540702456273515
Validation loss: 3.3599820816411436

Epoch: 6| Step: 7
Training loss: 3.771829013496723
Validation loss: 3.3586625652746003

Epoch: 6| Step: 8
Training loss: 3.352051599201011
Validation loss: 3.358952548800844

Epoch: 6| Step: 9
Training loss: 2.91187373947113
Validation loss: 3.3581639657050775

Epoch: 6| Step: 10
Training loss: 3.670888825140381
Validation loss: 3.3580080075133476

Epoch: 6| Step: 11
Training loss: 4.149728347895573
Validation loss: 3.3580788662957595

Epoch: 6| Step: 12
Training loss: 3.7877631722347673
Validation loss: 3.3576150582897033

Epoch: 6| Step: 13
Training loss: 3.0615846472649038
Validation loss: 3.358115884559531

Epoch: 56| Step: 0
Training loss: 4.013265547406988
Validation loss: 3.3573150355287837

Epoch: 6| Step: 1
Training loss: 2.541829265542286
Validation loss: 3.3580523035887437

Epoch: 6| Step: 2
Training loss: 4.112762331494652
Validation loss: 3.3579940304083706

Epoch: 6| Step: 3
Training loss: 2.9362283754425347
Validation loss: 3.3583754742624072

Epoch: 6| Step: 4
Training loss: 3.3700567708200118
Validation loss: 3.3588181892974354

Epoch: 6| Step: 5
Training loss: 3.859473099793834
Validation loss: 3.3579104062841694

Epoch: 6| Step: 6
Training loss: 3.5748993439275836
Validation loss: 3.357469569031306

Epoch: 6| Step: 7
Training loss: 3.1144358792480005
Validation loss: 3.3571790061045754

Epoch: 6| Step: 8
Training loss: 3.407844100448826
Validation loss: 3.3569396738245283

Epoch: 6| Step: 9
Training loss: 3.7830308235883088
Validation loss: 3.356593429582234

Epoch: 6| Step: 10
Training loss: 3.7644993536061047
Validation loss: 3.356778997005308

Epoch: 6| Step: 11
Training loss: 4.379378389466363
Validation loss: 3.3562636187647126

Epoch: 6| Step: 12
Training loss: 3.2333513934492966
Validation loss: 3.3562668421581985

Epoch: 6| Step: 13
Training loss: 3.908556447984355
Validation loss: 3.355563147757956

Epoch: 57| Step: 0
Training loss: 2.7624433934552717
Validation loss: 3.355522160589266

Epoch: 6| Step: 1
Training loss: 3.7431885210686695
Validation loss: 3.3554282842733096

Epoch: 6| Step: 2
Training loss: 4.339596306092712
Validation loss: 3.355302215782812

Epoch: 6| Step: 3
Training loss: 4.1352575673487895
Validation loss: 3.354941826864325

Epoch: 6| Step: 4
Training loss: 3.212684916951918
Validation loss: 3.3545558328909633

Epoch: 6| Step: 5
Training loss: 3.977042358464454
Validation loss: 3.3539710890051704

Epoch: 6| Step: 6
Training loss: 3.3709913395148297
Validation loss: 3.3546379824182235

Epoch: 6| Step: 7
Training loss: 4.2524348745231295
Validation loss: 3.354002497930572

Epoch: 6| Step: 8
Training loss: 3.6996441025584748
Validation loss: 3.352996920793362

Epoch: 6| Step: 9
Training loss: 3.3262111551739633
Validation loss: 3.3536674073423054

Epoch: 6| Step: 10
Training loss: 3.114505694558215
Validation loss: 3.3529454900352604

Epoch: 6| Step: 11
Training loss: 2.9346864902647742
Validation loss: 3.35347986014411

Epoch: 6| Step: 12
Training loss: 3.927838537048095
Validation loss: 3.3525624205258406

Epoch: 6| Step: 13
Training loss: 2.4071855584109154
Validation loss: 3.352532694186584

Epoch: 58| Step: 0
Training loss: 3.3231411721533943
Validation loss: 3.352451322777097

Epoch: 6| Step: 1
Training loss: 3.585601059499752
Validation loss: 3.3525778272823334

Epoch: 6| Step: 2
Training loss: 3.6048023934774163
Validation loss: 3.351601005302605

Epoch: 6| Step: 3
Training loss: 3.193413130281501
Validation loss: 3.351437929179376

Epoch: 6| Step: 4
Training loss: 2.8955944337802153
Validation loss: 3.351255087294637

Epoch: 6| Step: 5
Training loss: 3.0962779188379703
Validation loss: 3.3517296437674666

Epoch: 6| Step: 6
Training loss: 3.5179592944854052
Validation loss: 3.350507733972361

Epoch: 6| Step: 7
Training loss: 3.9687803973137705
Validation loss: 3.350627629285178

Epoch: 6| Step: 8
Training loss: 4.530694967017231
Validation loss: 3.349677904195103

Epoch: 6| Step: 9
Training loss: 3.212648701473155
Validation loss: 3.3504119067596436

Epoch: 6| Step: 10
Training loss: 3.6282063477536504
Validation loss: 3.3501834232669943

Epoch: 6| Step: 11
Training loss: 4.425524388508242
Validation loss: 3.3493307236378858

Epoch: 6| Step: 12
Training loss: 2.912836138929449
Validation loss: 3.349278604336817

Epoch: 6| Step: 13
Training loss: 4.072105203300028
Validation loss: 3.34940736643965

Epoch: 59| Step: 0
Training loss: 3.9807827182741162
Validation loss: 3.34923707793355

Epoch: 6| Step: 1
Training loss: 3.556691571058787
Validation loss: 3.3486905519180357

Epoch: 6| Step: 2
Training loss: 3.6479983341146314
Validation loss: 3.348839241265137

Epoch: 6| Step: 3
Training loss: 3.242325745358364
Validation loss: 3.3493754865598415

Epoch: 6| Step: 4
Training loss: 3.880886651813427
Validation loss: 3.3478229593337514

Epoch: 6| Step: 5
Training loss: 4.309478143311065
Validation loss: 3.347752721236958

Epoch: 6| Step: 6
Training loss: 2.8923720570377887
Validation loss: 3.347294946733

Epoch: 6| Step: 7
Training loss: 3.7453191153189778
Validation loss: 3.347222553034677

Epoch: 6| Step: 8
Training loss: 3.4258519581856275
Validation loss: 3.3470114916754947

Epoch: 6| Step: 9
Training loss: 3.9086328181606094
Validation loss: 3.34638571552152

Epoch: 6| Step: 10
Training loss: 3.572187936979869
Validation loss: 3.347443978372359

Epoch: 6| Step: 11
Training loss: 3.299697463299355
Validation loss: 3.3462521308571196

Epoch: 6| Step: 12
Training loss: 2.140901867858565
Validation loss: 3.34670783880395

Epoch: 6| Step: 13
Training loss: 4.377321771624058
Validation loss: 3.3454855967829418

Epoch: 60| Step: 0
Training loss: 3.1841769380527754
Validation loss: 3.345783311964446

Epoch: 6| Step: 1
Training loss: 3.6475660439173367
Validation loss: 3.344993811555544

Epoch: 6| Step: 2
Training loss: 2.9841234989944665
Validation loss: 3.345594970314322

Epoch: 6| Step: 3
Training loss: 3.267665681731893
Validation loss: 3.3449507021820155

Epoch: 6| Step: 4
Training loss: 3.86826662362456
Validation loss: 3.3446696560381537

Epoch: 6| Step: 5
Training loss: 3.9953779696343195
Validation loss: 3.3452233024437046

Epoch: 6| Step: 6
Training loss: 3.1954839609119934
Validation loss: 3.3445410786979872

Epoch: 6| Step: 7
Training loss: 3.6484246917434437
Validation loss: 3.344141315743237

Epoch: 6| Step: 8
Training loss: 4.285599997676859
Validation loss: 3.3434811778165545

Epoch: 6| Step: 9
Training loss: 3.326848748014115
Validation loss: 3.3442600563900675

Epoch: 6| Step: 10
Training loss: 4.114467699703607
Validation loss: 3.3435714500735187

Epoch: 6| Step: 11
Training loss: 3.3924707407803507
Validation loss: 3.343176175978971

Epoch: 6| Step: 12
Training loss: 3.2855468227525706
Validation loss: 3.3431016279773216

Epoch: 6| Step: 13
Training loss: 3.7576297707651594
Validation loss: 3.3432227765501206

Epoch: 61| Step: 0
Training loss: 3.808594250801249
Validation loss: 3.343132072350471

Epoch: 6| Step: 1
Training loss: 2.964200036654039
Validation loss: 3.3425807156229004

Epoch: 6| Step: 2
Training loss: 4.827004707013276
Validation loss: 3.3422318743108232

Epoch: 6| Step: 3
Training loss: 3.5810364451488588
Validation loss: 3.341087763518929

Epoch: 6| Step: 4
Training loss: 3.7036410587805557
Validation loss: 3.34145358481365

Epoch: 6| Step: 5
Training loss: 3.3341850305299583
Validation loss: 3.3414648215454084

Epoch: 6| Step: 6
Training loss: 2.9899248377816283
Validation loss: 3.3424318521747325

Epoch: 6| Step: 7
Training loss: 4.083090846328918
Validation loss: 3.3424135730135136

Epoch: 6| Step: 8
Training loss: 2.651978862309976
Validation loss: 3.3405882015231514

Epoch: 6| Step: 9
Training loss: 3.61293270595121
Validation loss: 3.342965895197588

Epoch: 6| Step: 10
Training loss: 3.232177872682625
Validation loss: 3.3429073344922076

Epoch: 6| Step: 11
Training loss: 3.254201374202633
Validation loss: 3.343203852982389

Epoch: 6| Step: 12
Training loss: 3.9565193168971726
Validation loss: 3.356367659483318

Epoch: 6| Step: 13
Training loss: 3.5953870942137467
Validation loss: 3.3444885152908537

Epoch: 62| Step: 0
Training loss: 2.915971473313604
Validation loss: 3.3430817098869845

Epoch: 6| Step: 1
Training loss: 3.1908545700114397
Validation loss: 3.341277935191704

Epoch: 6| Step: 2
Training loss: 4.158202207609105
Validation loss: 3.3391867547397434

Epoch: 6| Step: 3
Training loss: 3.1652608227039725
Validation loss: 3.338633576997588

Epoch: 6| Step: 4
Training loss: 3.262920519156275
Validation loss: 3.3394163284108394

Epoch: 6| Step: 5
Training loss: 2.95629905998701
Validation loss: 3.338978121464224

Epoch: 6| Step: 6
Training loss: 4.229734686428704
Validation loss: 3.338453361972993

Epoch: 6| Step: 7
Training loss: 3.5862687234266786
Validation loss: 3.3384769997771233

Epoch: 6| Step: 8
Training loss: 3.057328821288998
Validation loss: 3.3384917666005562

Epoch: 6| Step: 9
Training loss: 4.450717208157825
Validation loss: 3.3389657093159446

Epoch: 6| Step: 10
Training loss: 4.195492532799151
Validation loss: 3.3380969316382156

Epoch: 6| Step: 11
Training loss: 3.473669876102519
Validation loss: 3.3377712952329346

Epoch: 6| Step: 12
Training loss: 3.58984481263586
Validation loss: 3.337353760312665

Epoch: 6| Step: 13
Training loss: 3.2186751866210757
Validation loss: 3.337037067446892

Epoch: 63| Step: 0
Training loss: 3.997279672664166
Validation loss: 3.3370698203699996

Epoch: 6| Step: 1
Training loss: 3.6986731959777863
Validation loss: 3.3367559202297064

Epoch: 6| Step: 2
Training loss: 3.157560019991099
Validation loss: 3.336899143491642

Epoch: 6| Step: 3
Training loss: 3.361882892690862
Validation loss: 3.3351950681316267

Epoch: 6| Step: 4
Training loss: 4.051659778467242
Validation loss: 3.3363333020572066

Epoch: 6| Step: 5
Training loss: 2.757772040137874
Validation loss: 3.3356958005709276

Epoch: 6| Step: 6
Training loss: 3.92224544888092
Validation loss: 3.3359379949086865

Epoch: 6| Step: 7
Training loss: 3.360317364191355
Validation loss: 3.3349735644189202

Epoch: 6| Step: 8
Training loss: 4.668664958541916
Validation loss: 3.334546181286497

Epoch: 6| Step: 9
Training loss: 2.7803188865599417
Validation loss: 3.334568356839209

Epoch: 6| Step: 10
Training loss: 3.576973675732026
Validation loss: 3.334379776135488

Epoch: 6| Step: 11
Training loss: 3.837066670657522
Validation loss: 3.333798708782709

Epoch: 6| Step: 12
Training loss: 3.033247456714831
Validation loss: 3.3338967375276765

Epoch: 6| Step: 13
Training loss: 3.136002816364425
Validation loss: 3.3329136973981606

Epoch: 64| Step: 0
Training loss: 2.8992487756546117
Validation loss: 3.332936892212483

Epoch: 6| Step: 1
Training loss: 3.6187664235850865
Validation loss: 3.332963280492236

Epoch: 6| Step: 2
Training loss: 4.246575265935812
Validation loss: 3.332666173947401

Epoch: 6| Step: 3
Training loss: 3.907472464964165
Validation loss: 3.3322125724685376

Epoch: 6| Step: 4
Training loss: 3.451284755378426
Validation loss: 3.3317857815941103

Epoch: 6| Step: 5
Training loss: 3.558741008504664
Validation loss: 3.333006774123977

Epoch: 6| Step: 6
Training loss: 3.894175430006086
Validation loss: 3.332411523741207

Epoch: 6| Step: 7
Training loss: 2.6960831134843883
Validation loss: 3.3314083221891027

Epoch: 6| Step: 8
Training loss: 3.2121043811431296
Validation loss: 3.331550925042609

Epoch: 6| Step: 9
Training loss: 2.9243662612239865
Validation loss: 3.331472490150095

Epoch: 6| Step: 10
Training loss: 4.345486959160209
Validation loss: 3.3307506944115453

Epoch: 6| Step: 11
Training loss: 3.7437747145714253
Validation loss: 3.3301516304327397

Epoch: 6| Step: 12
Training loss: 3.358667769396173
Validation loss: 3.3306865787391517

Epoch: 6| Step: 13
Training loss: 3.833077726273217
Validation loss: 3.3299911869228938

Epoch: 65| Step: 0
Training loss: 3.725303965205888
Validation loss: 3.331445547544641

Epoch: 6| Step: 1
Training loss: 3.08155499974131
Validation loss: 3.330157448780114

Epoch: 6| Step: 2
Training loss: 3.9231726942555865
Validation loss: 3.3291692617296587

Epoch: 6| Step: 3
Training loss: 3.582145331343457
Validation loss: 3.32940371494406

Epoch: 6| Step: 4
Training loss: 3.2488270623701974
Validation loss: 3.3288297737448356

Epoch: 6| Step: 5
Training loss: 2.7907109878466434
Validation loss: 3.3292875307070506

Epoch: 6| Step: 6
Training loss: 3.61702258267576
Validation loss: 3.328842721190477

Epoch: 6| Step: 7
Training loss: 3.9055197071246814
Validation loss: 3.328332716099192

Epoch: 6| Step: 8
Training loss: 3.971195458748163
Validation loss: 3.328180094179194

Epoch: 6| Step: 9
Training loss: 3.9075157861274787
Validation loss: 3.3282156702809105

Epoch: 6| Step: 10
Training loss: 2.7759380404733673
Validation loss: 3.328242468033065

Epoch: 6| Step: 11
Training loss: 4.088762112969532
Validation loss: 3.328583326781389

Epoch: 6| Step: 12
Training loss: 3.0115730854041165
Validation loss: 3.3279053228812354

Epoch: 6| Step: 13
Training loss: 4.229021016636743
Validation loss: 3.3269455760229194

Epoch: 66| Step: 0
Training loss: 3.9247249871386414
Validation loss: 3.3272912183030297

Epoch: 6| Step: 1
Training loss: 3.290826102666059
Validation loss: 3.3265358516635866

Epoch: 6| Step: 2
Training loss: 3.5652708019754202
Validation loss: 3.3265016740914737

Epoch: 6| Step: 3
Training loss: 3.3497256778733977
Validation loss: 3.3274447331150587

Epoch: 6| Step: 4
Training loss: 3.155476994797659
Validation loss: 3.325688944679111

Epoch: 6| Step: 5
Training loss: 4.382954369083124
Validation loss: 3.3275219193090217

Epoch: 6| Step: 6
Training loss: 4.094588565115929
Validation loss: 3.3266527469718707

Epoch: 6| Step: 7
Training loss: 3.1619698845372035
Validation loss: 3.3259315593946335

Epoch: 6| Step: 8
Training loss: 3.4727213352484876
Validation loss: 3.325653861883845

Epoch: 6| Step: 9
Training loss: 3.6079714469541098
Validation loss: 3.325525869869556

Epoch: 6| Step: 10
Training loss: 3.7873309711470644
Validation loss: 3.325344899766402

Epoch: 6| Step: 11
Training loss: 3.1986846664333575
Validation loss: 3.32535385961635

Epoch: 6| Step: 12
Training loss: 3.0340860215466896
Validation loss: 3.3259991027028906

Epoch: 6| Step: 13
Training loss: 3.6964888847490456
Validation loss: 3.3246447680355327

Epoch: 67| Step: 0
Training loss: 3.40668897687421
Validation loss: 3.324085590235719

Epoch: 6| Step: 1
Training loss: 4.303991798081081
Validation loss: 3.3243380634415214

Epoch: 6| Step: 2
Training loss: 3.6507587114614304
Validation loss: 3.3243800011214426

Epoch: 6| Step: 3
Training loss: 3.900634880230662
Validation loss: 3.324340070033749

Epoch: 6| Step: 4
Training loss: 3.5244131154317793
Validation loss: 3.323827763603599

Epoch: 6| Step: 5
Training loss: 3.467528394432947
Validation loss: 3.324207141863135

Epoch: 6| Step: 6
Training loss: 3.6919276923789277
Validation loss: 3.322891505796738

Epoch: 6| Step: 7
Training loss: 3.719754123560601
Validation loss: 3.3226551409851512

Epoch: 6| Step: 8
Training loss: 3.1564448834675005
Validation loss: 3.322902340851185

Epoch: 6| Step: 9
Training loss: 3.4353450609605742
Validation loss: 3.3218802369343994

Epoch: 6| Step: 10
Training loss: 3.2957123790076164
Validation loss: 3.321600296666978

Epoch: 6| Step: 11
Training loss: 3.67478068209838
Validation loss: 3.32201219170712

Epoch: 6| Step: 12
Training loss: 3.6791564169395703
Validation loss: 3.3213907532057196

Epoch: 6| Step: 13
Training loss: 1.9583207867267804
Validation loss: 3.3211261483427874

Epoch: 68| Step: 0
Training loss: 3.69783240567055
Validation loss: 3.32122506212434

Epoch: 6| Step: 1
Training loss: 3.241542080901598
Validation loss: 3.3210601331671037

Epoch: 6| Step: 2
Training loss: 3.0749165035169774
Validation loss: 3.3208697964738993

Epoch: 6| Step: 3
Training loss: 3.835550883091271
Validation loss: 3.3208642312750327

Epoch: 6| Step: 4
Training loss: 3.5704527311936896
Validation loss: 3.3205482764983594

Epoch: 6| Step: 5
Training loss: 3.6369940861466925
Validation loss: 3.320524687094537

Epoch: 6| Step: 6
Training loss: 2.702970467268155
Validation loss: 3.320262229968371

Epoch: 6| Step: 7
Training loss: 2.979173371278559
Validation loss: 3.319030554394001

Epoch: 6| Step: 8
Training loss: 2.9190015075930615
Validation loss: 3.3205527729344024

Epoch: 6| Step: 9
Training loss: 4.176860216734767
Validation loss: 3.3194686452382403

Epoch: 6| Step: 10
Training loss: 3.722398779052036
Validation loss: 3.320031147279604

Epoch: 6| Step: 11
Training loss: 4.185045576314561
Validation loss: 3.3189472632156924

Epoch: 6| Step: 12
Training loss: 4.144916656723814
Validation loss: 3.3179831140945923

Epoch: 6| Step: 13
Training loss: 3.562741856981747
Validation loss: 3.318578835805968

Epoch: 69| Step: 0
Training loss: 3.9297536309746812
Validation loss: 3.3184010205028844

Epoch: 6| Step: 1
Training loss: 3.232257684415702
Validation loss: 3.3178906358371862

Epoch: 6| Step: 2
Training loss: 4.201077441116715
Validation loss: 3.3177935281109754

Epoch: 6| Step: 3
Training loss: 4.180122367126397
Validation loss: 3.3175165905900696

Epoch: 6| Step: 4
Training loss: 3.953277584945845
Validation loss: 3.3170200496236815

Epoch: 6| Step: 5
Training loss: 2.8884259081175285
Validation loss: 3.316666231935023

Epoch: 6| Step: 6
Training loss: 3.7503115206706754
Validation loss: 3.316569567606179

Epoch: 6| Step: 7
Training loss: 3.8744742744429614
Validation loss: 3.3162165089308715

Epoch: 6| Step: 8
Training loss: 3.163656778578625
Validation loss: 3.31636583638992

Epoch: 6| Step: 9
Training loss: 3.1426579362728844
Validation loss: 3.316305068173539

Epoch: 6| Step: 10
Training loss: 3.6593784087936463
Validation loss: 3.315983502980632

Epoch: 6| Step: 11
Training loss: 3.1859411279827
Validation loss: 3.315711826542513

Epoch: 6| Step: 12
Training loss: 2.977988875041034
Validation loss: 3.315766210000929

Epoch: 6| Step: 13
Training loss: 3.1469544356168604
Validation loss: 3.3154243057078987

Epoch: 70| Step: 0
Training loss: 3.533290847187
Validation loss: 3.315075047383321

Epoch: 6| Step: 1
Training loss: 3.9587207136163984
Validation loss: 3.3142640935902454

Epoch: 6| Step: 2
Training loss: 3.673600071628251
Validation loss: 3.3153386412477346

Epoch: 6| Step: 3
Training loss: 2.8404280154644224
Validation loss: 3.3142187419602602

Epoch: 6| Step: 4
Training loss: 3.841143957450107
Validation loss: 3.3143094198474423

Epoch: 6| Step: 5
Training loss: 4.1599033905695535
Validation loss: 3.314217508956572

Epoch: 6| Step: 6
Training loss: 3.1393316082364042
Validation loss: 3.314587582852264

Epoch: 6| Step: 7
Training loss: 3.456665433505165
Validation loss: 3.313447944718185

Epoch: 6| Step: 8
Training loss: 3.6298579845549206
Validation loss: 3.313707451637981

Epoch: 6| Step: 9
Training loss: 3.3895077600633674
Validation loss: 3.313462126752449

Epoch: 6| Step: 10
Training loss: 3.9378221168155427
Validation loss: 3.3131518218918874

Epoch: 6| Step: 11
Training loss: 3.6192175686640025
Validation loss: 3.3126947582135506

Epoch: 6| Step: 12
Training loss: 3.341990212801123
Validation loss: 3.312762870117528

Epoch: 6| Step: 13
Training loss: 2.560707768114441
Validation loss: 3.3126795296941545

Epoch: 71| Step: 0
Training loss: 3.28500195298507
Validation loss: 3.3121543327791763

Epoch: 6| Step: 1
Training loss: 2.985119472138335
Validation loss: 3.312489818171159

Epoch: 6| Step: 2
Training loss: 3.70189018425443
Validation loss: 3.3119322990152926

Epoch: 6| Step: 3
Training loss: 3.6506274428683536
Validation loss: 3.311483815883201

Epoch: 6| Step: 4
Training loss: 4.2629278689784655
Validation loss: 3.3114834365414763

Epoch: 6| Step: 5
Training loss: 2.960729425612792
Validation loss: 3.3106146516528057

Epoch: 6| Step: 6
Training loss: 3.8045114088725898
Validation loss: 3.3115725125272655

Epoch: 6| Step: 7
Training loss: 3.211415350411162
Validation loss: 3.31052736351678

Epoch: 6| Step: 8
Training loss: 3.750266765006967
Validation loss: 3.3104938849013834

Epoch: 6| Step: 9
Training loss: 4.031609097832354
Validation loss: 3.3105157414451374

Epoch: 6| Step: 10
Training loss: 3.3327741789727283
Validation loss: 3.3102399747622067

Epoch: 6| Step: 11
Training loss: 3.4317091282025025
Validation loss: 3.3093732834768077

Epoch: 6| Step: 12
Training loss: 3.7222015007036924
Validation loss: 3.310377757202217

Epoch: 6| Step: 13
Training loss: 3.247453719140426
Validation loss: 3.308886635430763

Epoch: 72| Step: 0
Training loss: 3.2071918256846255
Validation loss: 3.310411171940951

Epoch: 6| Step: 1
Training loss: 3.1209767191958826
Validation loss: 3.3103944212461403

Epoch: 6| Step: 2
Training loss: 3.9566106695140357
Validation loss: 3.311852179542446

Epoch: 6| Step: 3
Training loss: 2.679973709347573
Validation loss: 3.3129931419665106

Epoch: 6| Step: 4
Training loss: 3.6036685900799625
Validation loss: 3.3118516469749264

Epoch: 6| Step: 5
Training loss: 4.536041252271585
Validation loss: 3.3098273118146593

Epoch: 6| Step: 6
Training loss: 3.9670104772700086
Validation loss: 3.3082861540328894

Epoch: 6| Step: 7
Training loss: 3.8348691738448353
Validation loss: 3.307708300579497

Epoch: 6| Step: 8
Training loss: 3.4957118331897905
Validation loss: 3.3080746497152136

Epoch: 6| Step: 9
Training loss: 3.4432699156168387
Validation loss: 3.3084068184998228

Epoch: 6| Step: 10
Training loss: 2.7446779424185412
Validation loss: 3.306916792616547

Epoch: 6| Step: 11
Training loss: 2.919260742460444
Validation loss: 3.307386935122119

Epoch: 6| Step: 12
Training loss: 4.053691058017082
Validation loss: 3.307065414403752

Epoch: 6| Step: 13
Training loss: 3.7252028442044267
Validation loss: 3.3076748151325988

Epoch: 73| Step: 0
Training loss: 3.515110232495453
Validation loss: 3.3074371442837873

Epoch: 6| Step: 1
Training loss: 3.969258073139624
Validation loss: 3.3063588764922844

Epoch: 6| Step: 2
Training loss: 2.7467515138681127
Validation loss: 3.306785047952872

Epoch: 6| Step: 3
Training loss: 3.9463957555253524
Validation loss: 3.3066717252641356

Epoch: 6| Step: 4
Training loss: 3.2772065453345616
Validation loss: 3.306265119369981

Epoch: 6| Step: 5
Training loss: 3.742337982401366
Validation loss: 3.3057057531623366

Epoch: 6| Step: 6
Training loss: 3.036824557083094
Validation loss: 3.3067924222823737

Epoch: 6| Step: 7
Training loss: 3.6823147022582527
Validation loss: 3.3054952594992

Epoch: 6| Step: 8
Training loss: 4.021833437072779
Validation loss: 3.305733698128736

Epoch: 6| Step: 9
Training loss: 2.8178619982173214
Validation loss: 3.304904646391292

Epoch: 6| Step: 10
Training loss: 3.7392291199685923
Validation loss: 3.305456890312237

Epoch: 6| Step: 11
Training loss: 4.161123759634309
Validation loss: 3.3042500136342587

Epoch: 6| Step: 12
Training loss: 3.552486870330021
Validation loss: 3.3047382404465293

Epoch: 6| Step: 13
Training loss: 2.7454384337945195
Validation loss: 3.3042373259454862

Epoch: 74| Step: 0
Training loss: 3.626346732594665
Validation loss: 3.3044263568347123

Epoch: 6| Step: 1
Training loss: 3.6368273135984266
Validation loss: 3.30360678738082

Epoch: 6| Step: 2
Training loss: 3.9153498742457677
Validation loss: 3.304643389280589

Epoch: 6| Step: 3
Training loss: 3.487181760426179
Validation loss: 3.304177050029855

Epoch: 6| Step: 4
Training loss: 3.598728877406723
Validation loss: 3.3018958914313847

Epoch: 6| Step: 5
Training loss: 4.459171085734498
Validation loss: 3.3038846037459098

Epoch: 6| Step: 6
Training loss: 3.7329356719717395
Validation loss: 3.3025518718791465

Epoch: 6| Step: 7
Training loss: 3.6356331980289696
Validation loss: 3.301812600489784

Epoch: 6| Step: 8
Training loss: 4.085533691058181
Validation loss: 3.302255212149616

Epoch: 6| Step: 9
Training loss: 3.4098280566318087
Validation loss: 3.3016728882708914

Epoch: 6| Step: 10
Training loss: 2.9987288007030606
Validation loss: 3.3013359775014095

Epoch: 6| Step: 11
Training loss: 3.5012824569990015
Validation loss: 3.302772515009045

Epoch: 6| Step: 12
Training loss: 2.2664027490493472
Validation loss: 3.3026383391828587

Epoch: 6| Step: 13
Training loss: 1.9841667126053837
Validation loss: 3.3016085239495996

Epoch: 75| Step: 0
Training loss: 4.053002861965025
Validation loss: 3.302364315801503

Epoch: 6| Step: 1
Training loss: 3.609831017425225
Validation loss: 3.302501215834119

Epoch: 6| Step: 2
Training loss: 3.330382821470953
Validation loss: 3.3021967384370012

Epoch: 6| Step: 3
Training loss: 2.414289149042493
Validation loss: 3.3025846345681704

Epoch: 6| Step: 4
Training loss: 3.4600936515349665
Validation loss: 3.3519509228072932

Epoch: 6| Step: 5
Training loss: 4.2245472953280885
Validation loss: 3.3130061946361664

Epoch: 6| Step: 6
Training loss: 2.900388323336629
Validation loss: 3.300132379831824

Epoch: 6| Step: 7
Training loss: 3.275654408541783
Validation loss: 3.299883172797197

Epoch: 6| Step: 8
Training loss: 4.313025401078872
Validation loss: 3.300619273159451

Epoch: 6| Step: 9
Training loss: 4.388750972807452
Validation loss: 3.300987971624172

Epoch: 6| Step: 10
Training loss: 3.7509594007922296
Validation loss: 3.3029749727426116

Epoch: 6| Step: 11
Training loss: 3.309862202199117
Validation loss: 3.305924039300167

Epoch: 6| Step: 12
Training loss: 2.939418734225729
Validation loss: 3.303773402405934

Epoch: 6| Step: 13
Training loss: 2.623776741200515
Validation loss: 3.301517182741732

Epoch: 76| Step: 0
Training loss: 2.873575604072274
Validation loss: 3.3002440984717674

Epoch: 6| Step: 1
Training loss: 2.9412021439497673
Validation loss: 3.3015275816642338

Epoch: 6| Step: 2
Training loss: 3.775339346279408
Validation loss: 3.3029869651857506

Epoch: 6| Step: 3
Training loss: 3.6215211683932096
Validation loss: 3.3007189164280373

Epoch: 6| Step: 4
Training loss: 3.5994104008524297
Validation loss: 3.3017640380478457

Epoch: 6| Step: 5
Training loss: 3.4927522002181757
Validation loss: 3.2996364083081637

Epoch: 6| Step: 6
Training loss: 4.042247350343299
Validation loss: 3.2997536847295277

Epoch: 6| Step: 7
Training loss: 4.3218172567375825
Validation loss: 3.298600698964486

Epoch: 6| Step: 8
Training loss: 3.655200383737652
Validation loss: 3.2997216693047733

Epoch: 6| Step: 9
Training loss: 3.247449754615526
Validation loss: 3.2989929173989174

Epoch: 6| Step: 10
Training loss: 3.6421065692591728
Validation loss: 3.2985868727191625

Epoch: 6| Step: 11
Training loss: 2.8911025194155595
Validation loss: 3.298067105304117

Epoch: 6| Step: 12
Training loss: 3.956140144835753
Validation loss: 3.2969660413736097

Epoch: 6| Step: 13
Training loss: 2.9502037171967337
Validation loss: 3.2986713043978635

Epoch: 77| Step: 0
Training loss: 4.300376769126784
Validation loss: 3.296482764436168

Epoch: 6| Step: 1
Training loss: 4.68675856766508
Validation loss: 3.2970592573843893

Epoch: 6| Step: 2
Training loss: 3.5717576856196045
Validation loss: 3.2960254916271503

Epoch: 6| Step: 3
Training loss: 3.5458287784055567
Validation loss: 3.296138254790698

Epoch: 6| Step: 4
Training loss: 3.785986337885965
Validation loss: 3.2961380836810807

Epoch: 6| Step: 5
Training loss: 2.7219785615860177
Validation loss: 3.2962373133235516

Epoch: 6| Step: 6
Training loss: 3.2507619698156023
Validation loss: 3.2950890816663674

Epoch: 6| Step: 7
Training loss: 2.9428448040580535
Validation loss: 3.2952883931147205

Epoch: 6| Step: 8
Training loss: 2.6764594116668023
Validation loss: 3.2951125248398063

Epoch: 6| Step: 9
Training loss: 3.8820990476869914
Validation loss: 3.2942519144298616

Epoch: 6| Step: 10
Training loss: 4.159268537917192
Validation loss: 3.293279218313384

Epoch: 6| Step: 11
Training loss: 2.6412580284361313
Validation loss: 3.2946231385009748

Epoch: 6| Step: 12
Training loss: 3.2333739569822293
Validation loss: 3.2930171922457934

Epoch: 6| Step: 13
Training loss: 3.387651959491267
Validation loss: 3.2940892351842934

Epoch: 78| Step: 0
Training loss: 3.973836447803508
Validation loss: 3.293222257356714

Epoch: 6| Step: 1
Training loss: 3.0983896625959972
Validation loss: 3.29309231197336

Epoch: 6| Step: 2
Training loss: 3.6259073897589946
Validation loss: 3.292425813956877

Epoch: 6| Step: 3
Training loss: 4.2868248499689745
Validation loss: 3.2935729907998836

Epoch: 6| Step: 4
Training loss: 3.7849813918912325
Validation loss: 3.2920394853519466

Epoch: 6| Step: 5
Training loss: 3.2366189590012913
Validation loss: 3.292994485421064

Epoch: 6| Step: 6
Training loss: 3.0669339837480925
Validation loss: 3.2915842978744445

Epoch: 6| Step: 7
Training loss: 3.7420130551639033
Validation loss: 3.2922068586571247

Epoch: 6| Step: 8
Training loss: 4.015473715459472
Validation loss: 3.2918814286224753

Epoch: 6| Step: 9
Training loss: 3.4093580152890977
Validation loss: 3.291127059548003

Epoch: 6| Step: 10
Training loss: 2.9239031438689214
Validation loss: 3.291363831610172

Epoch: 6| Step: 11
Training loss: 3.1382409911532747
Validation loss: 3.2921504958872427

Epoch: 6| Step: 12
Training loss: 3.4310355697918316
Validation loss: 3.2902304339419572

Epoch: 6| Step: 13
Training loss: 3.4948273991872423
Validation loss: 3.290541323450887

Epoch: 79| Step: 0
Training loss: 4.401956400716458
Validation loss: 3.2899842927330067

Epoch: 6| Step: 1
Training loss: 3.383351342540096
Validation loss: 3.2899005015159397

Epoch: 6| Step: 2
Training loss: 3.7099642792496135
Validation loss: 3.2897068084648993

Epoch: 6| Step: 3
Training loss: 3.305903650614088
Validation loss: 3.2890677440962874

Epoch: 6| Step: 4
Training loss: 2.86561711933213
Validation loss: 3.28935351911228

Epoch: 6| Step: 5
Training loss: 4.22000804086796
Validation loss: 3.289177589155709

Epoch: 6| Step: 6
Training loss: 3.750438283103543
Validation loss: 3.2892154888640617

Epoch: 6| Step: 7
Training loss: 3.4329598702080664
Validation loss: 3.2881204675951556

Epoch: 6| Step: 8
Training loss: 3.9031557569063136
Validation loss: 3.288147907098346

Epoch: 6| Step: 9
Training loss: 2.3082308153140008
Validation loss: 3.2883175312246724

Epoch: 6| Step: 10
Training loss: 3.6496476774136006
Validation loss: 3.2882023846787116

Epoch: 6| Step: 11
Training loss: 3.778154351283709
Validation loss: 3.288304844431459

Epoch: 6| Step: 12
Training loss: 3.2364672099714995
Validation loss: 3.2875531949685475

Epoch: 6| Step: 13
Training loss: 2.5476490552906497
Validation loss: 3.2875232519940694

Epoch: 80| Step: 0
Training loss: 3.5337610009922558
Validation loss: 3.2861565894929194

Epoch: 6| Step: 1
Training loss: 3.497980079886423
Validation loss: 3.285946277511522

Epoch: 6| Step: 2
Training loss: 3.9511161193081676
Validation loss: 3.287034928884457

Epoch: 6| Step: 3
Training loss: 4.2416299414902845
Validation loss: 3.2857400545327438

Epoch: 6| Step: 4
Training loss: 2.604407785061447
Validation loss: 3.2867138290074958

Epoch: 6| Step: 5
Training loss: 2.5937139669466225
Validation loss: 3.2862896994051582

Epoch: 6| Step: 6
Training loss: 4.053699997914955
Validation loss: 3.285523288696809

Epoch: 6| Step: 7
Training loss: 3.3438349918009678
Validation loss: 3.286620152651899

Epoch: 6| Step: 8
Training loss: 3.127205337560455
Validation loss: 3.2863924964972173

Epoch: 6| Step: 9
Training loss: 4.260749238082924
Validation loss: 3.2874536548524587

Epoch: 6| Step: 10
Training loss: 3.7000209498456726
Validation loss: 3.2855885369418276

Epoch: 6| Step: 11
Training loss: 3.5968130575326547
Validation loss: 3.2848489661121665

Epoch: 6| Step: 12
Training loss: 3.224659356157924
Validation loss: 3.2839442866567885

Epoch: 6| Step: 13
Training loss: 2.9873825816299258
Validation loss: 3.283534129351109

Epoch: 81| Step: 0
Training loss: 3.8634656470622684
Validation loss: 3.2840265342968706

Epoch: 6| Step: 1
Training loss: 3.1922728763764128
Validation loss: 3.284301826185905

Epoch: 6| Step: 2
Training loss: 3.966907704400178
Validation loss: 3.2834418020346705

Epoch: 6| Step: 3
Training loss: 3.6841513736536586
Validation loss: 3.283029531371268

Epoch: 6| Step: 4
Training loss: 3.2995678358600817
Validation loss: 3.2833366388612752

Epoch: 6| Step: 5
Training loss: 2.6190424025264827
Validation loss: 3.2827866010722984

Epoch: 6| Step: 6
Training loss: 2.807139820151314
Validation loss: 3.2830976230966202

Epoch: 6| Step: 7
Training loss: 3.4087810387088284
Validation loss: 3.282590738470394

Epoch: 6| Step: 8
Training loss: 4.121063897625882
Validation loss: 3.282535931897949

Epoch: 6| Step: 9
Training loss: 3.0340712484645573
Validation loss: 3.2824232840866663

Epoch: 6| Step: 10
Training loss: 4.531393114658042
Validation loss: 3.281624699462897

Epoch: 6| Step: 11
Training loss: 2.90920443746815
Validation loss: 3.2819828838131455

Epoch: 6| Step: 12
Training loss: 3.443017311870341
Validation loss: 3.2815250560758167

Epoch: 6| Step: 13
Training loss: 4.324713839727691
Validation loss: 3.281632705301343

Epoch: 82| Step: 0
Training loss: 3.507437841037277
Validation loss: 3.2809441974296103

Epoch: 6| Step: 1
Training loss: 2.956129049847213
Validation loss: 3.2810654736270752

Epoch: 6| Step: 2
Training loss: 3.6038969670342995
Validation loss: 3.2808182658428784

Epoch: 6| Step: 3
Training loss: 2.798438290628378
Validation loss: 3.280409347893153

Epoch: 6| Step: 4
Training loss: 3.52381884758991
Validation loss: 3.2802755648310535

Epoch: 6| Step: 5
Training loss: 3.2532649146634935
Validation loss: 3.2807121730670166

Epoch: 6| Step: 6
Training loss: 3.4315002794828415
Validation loss: 3.2810122933646255

Epoch: 6| Step: 7
Training loss: 3.293937061072158
Validation loss: 3.2808794850568237

Epoch: 6| Step: 8
Training loss: 3.9162384502534016
Validation loss: 3.2820016331158035

Epoch: 6| Step: 9
Training loss: 3.894838556315363
Validation loss: 3.281243616772765

Epoch: 6| Step: 10
Training loss: 3.1225474079280686
Validation loss: 3.2787437903583547

Epoch: 6| Step: 11
Training loss: 3.991421680192882
Validation loss: 3.2788944209603477

Epoch: 6| Step: 12
Training loss: 4.1609426981843
Validation loss: 3.2788980894514874

Epoch: 6| Step: 13
Training loss: 3.7781930972541833
Validation loss: 3.279533306713242

Epoch: 83| Step: 0
Training loss: 3.3332315588354935
Validation loss: 3.2787445972761806

Epoch: 6| Step: 1
Training loss: 3.5798193239193985
Validation loss: 3.279226018151156

Epoch: 6| Step: 2
Training loss: 4.1748105126055854
Validation loss: 3.2779215473574124

Epoch: 6| Step: 3
Training loss: 3.755593769047109
Validation loss: 3.2778218367600114

Epoch: 6| Step: 4
Training loss: 2.9090654415403003
Validation loss: 3.278906191079145

Epoch: 6| Step: 5
Training loss: 3.405679357483075
Validation loss: 3.2779426450396567

Epoch: 6| Step: 6
Training loss: 2.6696835281037097
Validation loss: 3.2783609933587816

Epoch: 6| Step: 7
Training loss: 3.751685463106804
Validation loss: 3.278071751200141

Epoch: 6| Step: 8
Training loss: 3.5328709755688914
Validation loss: 3.27667346104359

Epoch: 6| Step: 9
Training loss: 4.010216064720477
Validation loss: 3.2763343786040777

Epoch: 6| Step: 10
Training loss: 3.378192945391655
Validation loss: 3.276270711350799

Epoch: 6| Step: 11
Training loss: 2.8579264656147694
Validation loss: 3.2767921116575662

Epoch: 6| Step: 12
Training loss: 4.505197490465938
Validation loss: 3.2762185378037656

Epoch: 6| Step: 13
Training loss: 2.538010787291632
Validation loss: 3.276863955256667

Epoch: 84| Step: 0
Training loss: 3.1600077703839147
Validation loss: 3.276460894094675

Epoch: 6| Step: 1
Training loss: 4.5237461439391895
Validation loss: 3.2759231104316124

Epoch: 6| Step: 2
Training loss: 3.572453564288015
Validation loss: 3.276206551448571

Epoch: 6| Step: 3
Training loss: 3.616996348131618
Validation loss: 3.275270547582832

Epoch: 6| Step: 4
Training loss: 3.1915901719397746
Validation loss: 3.2747245144167594

Epoch: 6| Step: 5
Training loss: 4.240936038502116
Validation loss: 3.274486467168508

Epoch: 6| Step: 6
Training loss: 3.1449652141351447
Validation loss: 3.2734833837307553

Epoch: 6| Step: 7
Training loss: 2.9289844534042326
Validation loss: 3.2746753193205294

Epoch: 6| Step: 8
Training loss: 3.3039747691541956
Validation loss: 3.2748035992301343

Epoch: 6| Step: 9
Training loss: 3.566703458103075
Validation loss: 3.2736821679491457

Epoch: 6| Step: 10
Training loss: 3.3131875818023757
Validation loss: 3.274141616193235

Epoch: 6| Step: 11
Training loss: 2.708260393383162
Validation loss: 3.2737474438945107

Epoch: 6| Step: 12
Training loss: 4.057460769961956
Validation loss: 3.272782957933376

Epoch: 6| Step: 13
Training loss: 3.578548889371988
Validation loss: 3.272805343613228

Epoch: 85| Step: 0
Training loss: 3.143094586407091
Validation loss: 3.2731999935616054

Epoch: 6| Step: 1
Training loss: 3.9137763187153416
Validation loss: 3.2728255155034756

Epoch: 6| Step: 2
Training loss: 3.10189179562924
Validation loss: 3.2733018170396653

Epoch: 6| Step: 3
Training loss: 3.687184983068416
Validation loss: 3.2712388976922315

Epoch: 6| Step: 4
Training loss: 3.8869626376056896
Validation loss: 3.2712140389177793

Epoch: 6| Step: 5
Training loss: 3.081718399936761
Validation loss: 3.2724327436538276

Epoch: 6| Step: 6
Training loss: 3.514930758275849
Validation loss: 3.273469050420293

Epoch: 6| Step: 7
Training loss: 3.640831413475177
Validation loss: 3.2727062471617505

Epoch: 6| Step: 8
Training loss: 3.7580761727758714
Validation loss: 3.272186025189756

Epoch: 6| Step: 9
Training loss: 3.4245493293024243
Validation loss: 3.270543984591106

Epoch: 6| Step: 10
Training loss: 3.0690067222722957
Validation loss: 3.269931005403758

Epoch: 6| Step: 11
Training loss: 3.4640080111721514
Validation loss: 3.270976283252863

Epoch: 6| Step: 12
Training loss: 3.84435087640146
Validation loss: 3.2713419326336206

Epoch: 6| Step: 13
Training loss: 3.6813558048399253
Validation loss: 3.27007337673826

Epoch: 86| Step: 0
Training loss: 3.756779455360762
Validation loss: 3.270497855815966

Epoch: 6| Step: 1
Training loss: 3.0000483191095753
Validation loss: 3.270021180358412

Epoch: 6| Step: 2
Training loss: 3.5403489896658393
Validation loss: 3.2703734237121047

Epoch: 6| Step: 3
Training loss: 3.5363751243873636
Validation loss: 3.2705837306311536

Epoch: 6| Step: 4
Training loss: 3.838061830230318
Validation loss: 3.2691287151409174

Epoch: 6| Step: 5
Training loss: 3.1725100929093695
Validation loss: 3.268660901938668

Epoch: 6| Step: 6
Training loss: 2.930680495778235
Validation loss: 3.2695056082494243

Epoch: 6| Step: 7
Training loss: 4.190854223753894
Validation loss: 3.2693432455555813

Epoch: 6| Step: 8
Training loss: 2.4229366805697867
Validation loss: 3.2687591751814695

Epoch: 6| Step: 9
Training loss: 3.7221967607705952
Validation loss: 3.268835183333265

Epoch: 6| Step: 10
Training loss: 4.185596090179624
Validation loss: 3.269572402464394

Epoch: 6| Step: 11
Training loss: 3.8008050868824728
Validation loss: 3.268915094491634

Epoch: 6| Step: 12
Training loss: 3.8133418920283093
Validation loss: 3.26868913380871

Epoch: 6| Step: 13
Training loss: 2.2116983674840673
Validation loss: 3.267533427796035

Epoch: 87| Step: 0
Training loss: 4.089901578507116
Validation loss: 3.2678741138018825

Epoch: 6| Step: 1
Training loss: 3.8995660589350254
Validation loss: 3.2674050287934167

Epoch: 6| Step: 2
Training loss: 3.0871171845244763
Validation loss: 3.2660833909322036

Epoch: 6| Step: 3
Training loss: 2.9483791747841357
Validation loss: 3.267787861817897

Epoch: 6| Step: 4
Training loss: 2.9547791061846254
Validation loss: 3.267841944519447

Epoch: 6| Step: 5
Training loss: 3.4910717574967163
Validation loss: 3.266284024951377

Epoch: 6| Step: 6
Training loss: 3.761546225072468
Validation loss: 3.266867014668103

Epoch: 6| Step: 7
Training loss: 3.6235630212701158
Validation loss: 3.26661785969071

Epoch: 6| Step: 8
Training loss: 3.523150582483733
Validation loss: 3.2668218306062333

Epoch: 6| Step: 9
Training loss: 3.991924359333128
Validation loss: 3.2662717823719607

Epoch: 6| Step: 10
Training loss: 3.1687856578137334
Validation loss: 3.267094758628932

Epoch: 6| Step: 11
Training loss: 3.1909257020396917
Validation loss: 3.265101580881433

Epoch: 6| Step: 12
Training loss: 4.256573025941279
Validation loss: 3.2659605552237005

Epoch: 6| Step: 13
Training loss: 2.227769277032672
Validation loss: 3.263611834922981

Epoch: 88| Step: 0
Training loss: 2.5658283482951543
Validation loss: 3.265073487588076

Epoch: 6| Step: 1
Training loss: 4.146528303980091
Validation loss: 3.265270107301319

Epoch: 6| Step: 2
Training loss: 3.5760532028200327
Validation loss: 3.2667340252427364

Epoch: 6| Step: 3
Training loss: 2.455406925638028
Validation loss: 3.265357267420083

Epoch: 6| Step: 4
Training loss: 4.137698193554284
Validation loss: 3.2673043773947756

Epoch: 6| Step: 5
Training loss: 3.7005678514378983
Validation loss: 3.265837462129191

Epoch: 6| Step: 6
Training loss: 3.3070426466700624
Validation loss: 3.2643864583079965

Epoch: 6| Step: 7
Training loss: 4.317733022192055
Validation loss: 3.2650416927235053

Epoch: 6| Step: 8
Training loss: 3.441289027249438
Validation loss: 3.2645162922074737

Epoch: 6| Step: 9
Training loss: 3.3301079085911507
Validation loss: 3.2633033236477345

Epoch: 6| Step: 10
Training loss: 2.712580553959412
Validation loss: 3.263572179148018

Epoch: 6| Step: 11
Training loss: 3.391011299593702
Validation loss: 3.2633210615895836

Epoch: 6| Step: 12
Training loss: 4.029610707149249
Validation loss: 3.263109084558324

Epoch: 6| Step: 13
Training loss: 3.4145124824129303
Validation loss: 3.262587979785743

Epoch: 89| Step: 0
Training loss: 2.814109934862955
Validation loss: 3.261175079553588

Epoch: 6| Step: 1
Training loss: 3.4149517935035516
Validation loss: 3.2629734851620626

Epoch: 6| Step: 2
Training loss: 3.471658398097522
Validation loss: 3.2632287429492544

Epoch: 6| Step: 3
Training loss: 4.134457468145996
Validation loss: 3.263206938924618

Epoch: 6| Step: 4
Training loss: 3.344093233834785
Validation loss: 3.2648379262552525

Epoch: 6| Step: 5
Training loss: 2.4025557261661974
Validation loss: 3.263354110514205

Epoch: 6| Step: 6
Training loss: 4.2027848683967175
Validation loss: 3.2657388160066927

Epoch: 6| Step: 7
Training loss: 3.8836504456105994
Validation loss: 3.2616057636414086

Epoch: 6| Step: 8
Training loss: 2.926750480940517
Validation loss: 3.2617107424417595

Epoch: 6| Step: 9
Training loss: 3.835581341464387
Validation loss: 3.2617177077924135

Epoch: 6| Step: 10
Training loss: 3.880747316889986
Validation loss: 3.260212693957762

Epoch: 6| Step: 11
Training loss: 3.815191600782796
Validation loss: 3.2601087772685386

Epoch: 6| Step: 12
Training loss: 3.443678418642686
Validation loss: 3.260735382812117

Epoch: 6| Step: 13
Training loss: 2.717444183000974
Validation loss: 3.2605580384394504

Epoch: 90| Step: 0
Training loss: 3.839984444944348
Validation loss: 3.2589240391255068

Epoch: 6| Step: 1
Training loss: 3.4116934581227056
Validation loss: 3.2592048068960264

Epoch: 6| Step: 2
Training loss: 3.949847766501899
Validation loss: 3.2580683667149914

Epoch: 6| Step: 3
Training loss: 3.829764999670052
Validation loss: 3.2603761199397794

Epoch: 6| Step: 4
Training loss: 3.5347367348630137
Validation loss: 3.259211933345618

Epoch: 6| Step: 5
Training loss: 3.074853698227434
Validation loss: 3.258455999217179

Epoch: 6| Step: 6
Training loss: 3.4080925953603147
Validation loss: 3.258238079926977

Epoch: 6| Step: 7
Training loss: 3.713164807529881
Validation loss: 3.2584481535825596

Epoch: 6| Step: 8
Training loss: 3.0240416403734263
Validation loss: 3.2588594228512693

Epoch: 6| Step: 9
Training loss: 3.1233201661811156
Validation loss: 3.257803453545158

Epoch: 6| Step: 10
Training loss: 3.9573428604631653
Validation loss: 3.2589014117753896

Epoch: 6| Step: 11
Training loss: 3.3390928260807726
Validation loss: 3.2579180306743356

Epoch: 6| Step: 12
Training loss: 2.959645172966807
Validation loss: 3.2569431008413856

Epoch: 6| Step: 13
Training loss: 3.9047316384997792
Validation loss: 3.257126996196306

Epoch: 91| Step: 0
Training loss: 3.493116421650598
Validation loss: 3.2576635072914835

Epoch: 6| Step: 1
Training loss: 2.6589491650046373
Validation loss: 3.258671096941672

Epoch: 6| Step: 2
Training loss: 4.387731501457425
Validation loss: 3.2572866496284094

Epoch: 6| Step: 3
Training loss: 3.4791984937358023
Validation loss: 3.2572320138786854

Epoch: 6| Step: 4
Training loss: 3.10505260822246
Validation loss: 3.2562264022490135

Epoch: 6| Step: 5
Training loss: 3.4259761115475587
Validation loss: 3.256368857099247

Epoch: 6| Step: 6
Training loss: 3.085249039352684
Validation loss: 3.2559081709486706

Epoch: 6| Step: 7
Training loss: 3.82746003272719
Validation loss: 3.2570443982933655

Epoch: 6| Step: 8
Training loss: 3.8227967842007895
Validation loss: 3.2555414149357476

Epoch: 6| Step: 9
Training loss: 3.507795372052421
Validation loss: 3.2570361667237684

Epoch: 6| Step: 10
Training loss: 2.7538544778489036
Validation loss: 3.2543729701400053

Epoch: 6| Step: 11
Training loss: 3.459026558272567
Validation loss: 3.254038277042416

Epoch: 6| Step: 12
Training loss: 3.5277222422903423
Validation loss: 3.25654304846467

Epoch: 6| Step: 13
Training loss: 4.567991113844477
Validation loss: 3.2559434942490477

Epoch: 92| Step: 0
Training loss: 4.125473457677312
Validation loss: 3.2562112292876364

Epoch: 6| Step: 1
Training loss: 3.801043071138487
Validation loss: 3.2558859336550263

Epoch: 6| Step: 2
Training loss: 3.383043664517967
Validation loss: 3.2576203314043517

Epoch: 6| Step: 3
Training loss: 4.259081842041431
Validation loss: 3.2574442765560403

Epoch: 6| Step: 4
Training loss: 3.1835512123308467
Validation loss: 3.25750396676899

Epoch: 6| Step: 5
Training loss: 2.766855084847574
Validation loss: 3.2566020726823077

Epoch: 6| Step: 6
Training loss: 2.995370471693829
Validation loss: 3.2536643773168743

Epoch: 6| Step: 7
Training loss: 3.819691987926434
Validation loss: 3.2545486074375582

Epoch: 6| Step: 8
Training loss: 3.924437639320073
Validation loss: 3.253126222398789

Epoch: 6| Step: 9
Training loss: 3.437344772995566
Validation loss: 3.2530444425951637

Epoch: 6| Step: 10
Training loss: 2.861699228014477
Validation loss: 3.2522262539840177

Epoch: 6| Step: 11
Training loss: 3.0309693511349685
Validation loss: 3.2508075442855833

Epoch: 6| Step: 12
Training loss: 3.9095364592925956
Validation loss: 3.2510022068757887

Epoch: 6| Step: 13
Training loss: 2.757188245454783
Validation loss: 3.251052643378963

Epoch: 93| Step: 0
Training loss: 3.0590579872982664
Validation loss: 3.250611825058353

Epoch: 6| Step: 1
Training loss: 3.866720152079417
Validation loss: 3.2497198080312693

Epoch: 6| Step: 2
Training loss: 3.5626560645469176
Validation loss: 3.250216651176198

Epoch: 6| Step: 3
Training loss: 2.5641394232277013
Validation loss: 3.2489202029229753

Epoch: 6| Step: 4
Training loss: 3.282833334971514
Validation loss: 3.2500113494144798

Epoch: 6| Step: 5
Training loss: 4.229117758081317
Validation loss: 3.248561493448094

Epoch: 6| Step: 6
Training loss: 3.6679766800117286
Validation loss: 3.2473188183693016

Epoch: 6| Step: 7
Training loss: 3.50524346086983
Validation loss: 3.2502702201536753

Epoch: 6| Step: 8
Training loss: 3.5043864691913846
Validation loss: 3.2505436908697156

Epoch: 6| Step: 9
Training loss: 3.561225797089598
Validation loss: 3.2481871519199075

Epoch: 6| Step: 10
Training loss: 3.347757665106204
Validation loss: 3.2479101676433615

Epoch: 6| Step: 11
Training loss: 3.2572363474342594
Validation loss: 3.249228378778821

Epoch: 6| Step: 12
Training loss: 3.576126406686307
Validation loss: 3.247363937490622

Epoch: 6| Step: 13
Training loss: 3.938832859728247
Validation loss: 3.2487973416738654

Epoch: 94| Step: 0
Training loss: 3.2948269380958317
Validation loss: 3.251720167287673

Epoch: 6| Step: 1
Training loss: 3.1398590824068915
Validation loss: 3.2505623730812583

Epoch: 6| Step: 2
Training loss: 3.9130174532315127
Validation loss: 3.255284252569412

Epoch: 6| Step: 3
Training loss: 3.015130195147295
Validation loss: 3.254625428740915

Epoch: 6| Step: 4
Training loss: 3.634753555695975
Validation loss: 3.249735348940253

Epoch: 6| Step: 5
Training loss: 3.55781139563073
Validation loss: 3.243160649226457

Epoch: 6| Step: 6
Training loss: 3.75403543144825
Validation loss: 3.2450210162878244

Epoch: 6| Step: 7
Training loss: 3.2118791744741735
Validation loss: 3.241915797959128

Epoch: 6| Step: 8
Training loss: 2.6611905096956217
Validation loss: 3.245606014952355

Epoch: 6| Step: 9
Training loss: 4.51069852845428
Validation loss: 3.2440318533464936

Epoch: 6| Step: 10
Training loss: 3.5617555877862346
Validation loss: 3.241269151007237

Epoch: 6| Step: 11
Training loss: 3.3833190679640923
Validation loss: 3.2413204080839066

Epoch: 6| Step: 12
Training loss: 3.3684572450048673
Validation loss: 3.2418862890960662

Epoch: 6| Step: 13
Training loss: 3.6647923765401735
Validation loss: 3.244016304080545

Epoch: 95| Step: 0
Training loss: 3.126263324963871
Validation loss: 3.2406252150511237

Epoch: 6| Step: 1
Training loss: 3.389379316464728
Validation loss: 3.241067764207772

Epoch: 6| Step: 2
Training loss: 4.050038165630839
Validation loss: 3.245465364217777

Epoch: 6| Step: 3
Training loss: 3.433002373258691
Validation loss: 3.2425884719910196

Epoch: 6| Step: 4
Training loss: 3.585966488257695
Validation loss: 3.2450894639325845

Epoch: 6| Step: 5
Training loss: 3.632260910325511
Validation loss: 3.2478622650345494

Epoch: 6| Step: 6
Training loss: 2.9430087766059563
Validation loss: 3.2501790097571863

Epoch: 6| Step: 7
Training loss: 4.077261530055762
Validation loss: 3.2477899582888368

Epoch: 6| Step: 8
Training loss: 3.6053055450433207
Validation loss: 3.2430298923755507

Epoch: 6| Step: 9
Training loss: 3.1227195048087317
Validation loss: 3.2417131543724342

Epoch: 6| Step: 10
Training loss: 4.38704483844772
Validation loss: 3.2424045419426886

Epoch: 6| Step: 11
Training loss: 2.966513504046449
Validation loss: 3.2391252740225283

Epoch: 6| Step: 12
Training loss: 2.9128032346376953
Validation loss: 3.2408989522324814

Epoch: 6| Step: 13
Training loss: 3.0410806971100666
Validation loss: 3.2383435979317174

Epoch: 96| Step: 0
Training loss: 3.218721852596133
Validation loss: 3.2382335295406213

Epoch: 6| Step: 1
Training loss: 2.899046306986363
Validation loss: 3.2382322042701417

Epoch: 6| Step: 2
Training loss: 3.738553187764505
Validation loss: 3.2385158061253785

Epoch: 6| Step: 3
Training loss: 3.976455297317874
Validation loss: 3.2382070050275362

Epoch: 6| Step: 4
Training loss: 3.999883292402947
Validation loss: 3.234295869873558

Epoch: 6| Step: 5
Training loss: 3.1732732387537204
Validation loss: 3.236398815233784

Epoch: 6| Step: 6
Training loss: 4.354084263558748
Validation loss: 3.2363205172319827

Epoch: 6| Step: 7
Training loss: 3.455237937496044
Validation loss: 3.236817088579764

Epoch: 6| Step: 8
Training loss: 3.4170514952251607
Validation loss: 3.236932801390179

Epoch: 6| Step: 9
Training loss: 3.43505189592675
Validation loss: 3.236426249662763

Epoch: 6| Step: 10
Training loss: 2.799061692921185
Validation loss: 3.2360732288922773

Epoch: 6| Step: 11
Training loss: 2.287676811680826
Validation loss: 3.2357152098445936

Epoch: 6| Step: 12
Training loss: 3.60052117707729
Validation loss: 3.2369365760450437

Epoch: 6| Step: 13
Training loss: 4.255154345141497
Validation loss: 3.237903230659171

Epoch: 97| Step: 0
Training loss: 3.042650316297557
Validation loss: 3.236899914345233

Epoch: 6| Step: 1
Training loss: 2.9949113285649704
Validation loss: 3.24024380438723

Epoch: 6| Step: 2
Training loss: 3.8127318765135607
Validation loss: 3.2438872745407297

Epoch: 6| Step: 3
Training loss: 3.348391724743983
Validation loss: 3.2391480506009502

Epoch: 6| Step: 4
Training loss: 3.763118685425771
Validation loss: 3.2384335156648234

Epoch: 6| Step: 5
Training loss: 3.9752102634312023
Validation loss: 3.2372397711560637

Epoch: 6| Step: 6
Training loss: 3.429024391112042
Validation loss: 3.2361721716871297

Epoch: 6| Step: 7
Training loss: 3.4378309610739946
Validation loss: 3.236789022253823

Epoch: 6| Step: 8
Training loss: 3.9522815151257493
Validation loss: 3.234022575772814

Epoch: 6| Step: 9
Training loss: 3.0997121369622778
Validation loss: 3.2324167610734977

Epoch: 6| Step: 10
Training loss: 2.7372588726432614
Validation loss: 3.23258265024923

Epoch: 6| Step: 11
Training loss: 3.0599485395505046
Validation loss: 3.2352071441331893

Epoch: 6| Step: 12
Training loss: 4.368392750727591
Validation loss: 3.232574283427208

Epoch: 6| Step: 13
Training loss: 3.3183848092113117
Validation loss: 3.2322884002957

Epoch: 98| Step: 0
Training loss: 3.3340352908751254
Validation loss: 3.232385016162018

Epoch: 6| Step: 1
Training loss: 4.1149384293057825
Validation loss: 3.232378499954144

Epoch: 6| Step: 2
Training loss: 3.9007402548917316
Validation loss: 3.2309967655835967

Epoch: 6| Step: 3
Training loss: 3.270520496998767
Validation loss: 3.231787137468228

Epoch: 6| Step: 4
Training loss: 3.5561431922360107
Validation loss: 3.232488655094724

Epoch: 6| Step: 5
Training loss: 3.6635551833459394
Validation loss: 3.2332961201363144

Epoch: 6| Step: 6
Training loss: 2.658934280329357
Validation loss: 3.231770319564009

Epoch: 6| Step: 7
Training loss: 3.676154706511751
Validation loss: 3.230861898156507

Epoch: 6| Step: 8
Training loss: 3.31363226774595
Validation loss: 3.230982113666944

Epoch: 6| Step: 9
Training loss: 3.2959590561555094
Validation loss: 3.229831869710533

Epoch: 6| Step: 10
Training loss: 3.3340145527614156
Validation loss: 3.230866160755418

Epoch: 6| Step: 11
Training loss: 4.377237674122998
Validation loss: 3.228345804084669

Epoch: 6| Step: 12
Training loss: 3.2789522390932873
Validation loss: 3.230269734231664

Epoch: 6| Step: 13
Training loss: 1.4278985175715935
Validation loss: 3.227451512555132

Epoch: 99| Step: 0
Training loss: 4.19445291873393
Validation loss: 3.2292664754939127

Epoch: 6| Step: 1
Training loss: 3.687652067508009
Validation loss: 3.228680775288702

Epoch: 6| Step: 2
Training loss: 3.3127521922719096
Validation loss: 3.227798793559271

Epoch: 6| Step: 3
Training loss: 3.8036142829102926
Validation loss: 3.228715010914623

Epoch: 6| Step: 4
Training loss: 3.62929543501411
Validation loss: 3.2278843858711386

Epoch: 6| Step: 5
Training loss: 2.1577613067631254
Validation loss: 3.22772121939627

Epoch: 6| Step: 6
Training loss: 3.567131244551696
Validation loss: 3.2294766746011554

Epoch: 6| Step: 7
Training loss: 3.363766518916945
Validation loss: 3.229649780262093

Epoch: 6| Step: 8
Training loss: 3.3426270783033716
Validation loss: 3.2275228666421967

Epoch: 6| Step: 9
Training loss: 3.3505735561105396
Validation loss: 3.231628469303732

Epoch: 6| Step: 10
Training loss: 2.333534254778596
Validation loss: 3.2341511269283543

Epoch: 6| Step: 11
Training loss: 3.8390561108037238
Validation loss: 3.230803549499487

Epoch: 6| Step: 12
Training loss: 4.085421644509625
Validation loss: 3.229469123725057

Epoch: 6| Step: 13
Training loss: 3.441631816351972
Validation loss: 3.226706496468912

Epoch: 100| Step: 0
Training loss: 2.242778633694342
Validation loss: 3.225709269556912

Epoch: 6| Step: 1
Training loss: 4.285711261203244
Validation loss: 3.2243678345962072

Epoch: 6| Step: 2
Training loss: 3.7729764858132895
Validation loss: 3.2254145920558477

Epoch: 6| Step: 3
Training loss: 2.8312812180303264
Validation loss: 3.2250633873910153

Epoch: 6| Step: 4
Training loss: 3.5780924833061256
Validation loss: 3.2244638609276897

Epoch: 6| Step: 5
Training loss: 3.7607407927727223
Validation loss: 3.2244098576488276

Epoch: 6| Step: 6
Training loss: 3.4205606801840673
Validation loss: 3.224639814720893

Epoch: 6| Step: 7
Training loss: 3.4750257202953
Validation loss: 3.2247330798933143

Epoch: 6| Step: 8
Training loss: 3.3168016249708363
Validation loss: 3.2240113266215866

Epoch: 6| Step: 9
Training loss: 2.8137803448295275
Validation loss: 3.2250634319060705

Epoch: 6| Step: 10
Training loss: 3.0375415752061663
Validation loss: 3.2234485221874247

Epoch: 6| Step: 11
Training loss: 4.133852159075806
Validation loss: 3.2234615055959708

Epoch: 6| Step: 12
Training loss: 3.1537595686916684
Validation loss: 3.225775263543257

Epoch: 6| Step: 13
Training loss: 4.741153107751077
Validation loss: 3.225315665010983

Epoch: 101| Step: 0
Training loss: 3.4722258877205046
Validation loss: 3.22615256398509

Epoch: 6| Step: 1
Training loss: 3.5349590436189606
Validation loss: 3.225569572878003

Epoch: 6| Step: 2
Training loss: 3.5287372122143372
Validation loss: 3.227340996432074

Epoch: 6| Step: 3
Training loss: 4.776408617849604
Validation loss: 3.2256403669548033

Epoch: 6| Step: 4
Training loss: 3.4340353411642743
Validation loss: 3.22673339995003

Epoch: 6| Step: 5
Training loss: 2.150086924547836
Validation loss: 3.224402016631152

Epoch: 6| Step: 6
Training loss: 3.001368846136963
Validation loss: 3.223128462445595

Epoch: 6| Step: 7
Training loss: 3.4115065864858343
Validation loss: 3.2217531698811235

Epoch: 6| Step: 8
Training loss: 3.294178515360765
Validation loss: 3.2234766633113363

Epoch: 6| Step: 9
Training loss: 3.6775492228021656
Validation loss: 3.2209321719182276

Epoch: 6| Step: 10
Training loss: 3.633455084297778
Validation loss: 3.2217001428969847

Epoch: 6| Step: 11
Training loss: 3.2032387317842446
Validation loss: 3.222865558189893

Epoch: 6| Step: 12
Training loss: 3.2710099061252076
Validation loss: 3.222834194885101

Epoch: 6| Step: 13
Training loss: 3.898344906489
Validation loss: 3.220940769556336

Epoch: 102| Step: 0
Training loss: 3.6510709941881507
Validation loss: 3.223952050842136

Epoch: 6| Step: 1
Training loss: 3.608118540396129
Validation loss: 3.2235948065870064

Epoch: 6| Step: 2
Training loss: 2.9653416392715455
Validation loss: 3.222947278099353

Epoch: 6| Step: 3
Training loss: 3.886289824008421
Validation loss: 3.224133926951511

Epoch: 6| Step: 4
Training loss: 3.9081344331560075
Validation loss: 3.221386768616016

Epoch: 6| Step: 5
Training loss: 3.4978717055090347
Validation loss: 3.2205501102079754

Epoch: 6| Step: 6
Training loss: 3.784502884383784
Validation loss: 3.221567109671026

Epoch: 6| Step: 7
Training loss: 2.868161402471528
Validation loss: 3.21947619518227

Epoch: 6| Step: 8
Training loss: 4.366894652454951
Validation loss: 3.222225868719025

Epoch: 6| Step: 9
Training loss: 3.0568989507454054
Validation loss: 3.224765784154742

Epoch: 6| Step: 10
Training loss: 2.542586009203381
Validation loss: 3.2250016754202

Epoch: 6| Step: 11
Training loss: 3.212635046350587
Validation loss: 3.2243144331872085

Epoch: 6| Step: 12
Training loss: 3.4560148134973727
Validation loss: 3.226705304708314

Epoch: 6| Step: 13
Training loss: 3.3259796248297606
Validation loss: 3.227470982160125

Epoch: 103| Step: 0
Training loss: 3.3017845299403352
Validation loss: 3.222399518229962

Epoch: 6| Step: 1
Training loss: 3.5013103756913395
Validation loss: 3.2210978216502024

Epoch: 6| Step: 2
Training loss: 3.649415499773934
Validation loss: 3.218687711392362

Epoch: 6| Step: 3
Training loss: 3.4045065521432654
Validation loss: 3.221732279554566

Epoch: 6| Step: 4
Training loss: 3.953970837475405
Validation loss: 3.219807187669716

Epoch: 6| Step: 5
Training loss: 3.283231736239478
Validation loss: 3.2205142108411575

Epoch: 6| Step: 6
Training loss: 4.188316151808505
Validation loss: 3.220800335940095

Epoch: 6| Step: 7
Training loss: 3.4335747241989236
Validation loss: 3.2231419458501995

Epoch: 6| Step: 8
Training loss: 2.7999706505190924
Validation loss: 3.2221722885985105

Epoch: 6| Step: 9
Training loss: 3.612454772454906
Validation loss: 3.2228233368168584

Epoch: 6| Step: 10
Training loss: 3.773677589249964
Validation loss: 3.2194488129995547

Epoch: 6| Step: 11
Training loss: 3.5578691601168044
Validation loss: 3.2183231493256113

Epoch: 6| Step: 12
Training loss: 2.524205330163956
Validation loss: 3.217677927769708

Epoch: 6| Step: 13
Training loss: 3.1619094116244595
Validation loss: 3.2161425056388824

Epoch: 104| Step: 0
Training loss: 3.9109357881866136
Validation loss: 3.2171073996954567

Epoch: 6| Step: 1
Training loss: 4.170274749047591
Validation loss: 3.215921688784145

Epoch: 6| Step: 2
Training loss: 2.649683386404356
Validation loss: 3.2163729182915954

Epoch: 6| Step: 3
Training loss: 3.4710913651909148
Validation loss: 3.2168734239565113

Epoch: 6| Step: 4
Training loss: 3.180682502297254
Validation loss: 3.2168470285474737

Epoch: 6| Step: 5
Training loss: 3.2368425916900727
Validation loss: 3.217609675431991

Epoch: 6| Step: 6
Training loss: 3.2686613286028146
Validation loss: 3.2153718398725193

Epoch: 6| Step: 7
Training loss: 3.254909475213327
Validation loss: 3.2166523265269253

Epoch: 6| Step: 8
Training loss: 3.0198189621782054
Validation loss: 3.2158604829797643

Epoch: 6| Step: 9
Training loss: 3.1300273891627817
Validation loss: 3.215609953370437

Epoch: 6| Step: 10
Training loss: 4.194744618659339
Validation loss: 3.215722876075626

Epoch: 6| Step: 11
Training loss: 3.78868947503387
Validation loss: 3.217892422733213

Epoch: 6| Step: 12
Training loss: 3.4131319012910053
Validation loss: 3.2154408158139853

Epoch: 6| Step: 13
Training loss: 3.5803293159797827
Validation loss: 3.21629401480835

Epoch: 105| Step: 0
Training loss: 2.8038730129377587
Validation loss: 3.215943783109396

Epoch: 6| Step: 1
Training loss: 3.8031289670323267
Validation loss: 3.2166902104397646

Epoch: 6| Step: 2
Training loss: 3.766948673077857
Validation loss: 3.218300072421262

Epoch: 6| Step: 3
Training loss: 3.617202264413712
Validation loss: 3.218758974621331

Epoch: 6| Step: 4
Training loss: 3.058060055060071
Validation loss: 3.2175868388122444

Epoch: 6| Step: 5
Training loss: 3.103721808660009
Validation loss: 3.21537584474646

Epoch: 6| Step: 6
Training loss: 4.3393503864902865
Validation loss: 3.217700091302289

Epoch: 6| Step: 7
Training loss: 3.6123301641014955
Validation loss: 3.215041660204843

Epoch: 6| Step: 8
Training loss: 3.6968109770234814
Validation loss: 3.217641241043345

Epoch: 6| Step: 9
Training loss: 3.3431768193474847
Validation loss: 3.21746123131916

Epoch: 6| Step: 10
Training loss: 3.391569366434068
Validation loss: 3.2144892562198124

Epoch: 6| Step: 11
Training loss: 2.42140596831744
Validation loss: 3.213544381714688

Epoch: 6| Step: 12
Training loss: 3.6155407578422696
Validation loss: 3.2124423937721778

Epoch: 6| Step: 13
Training loss: 3.5775101978895067
Validation loss: 3.211655776768098

Epoch: 106| Step: 0
Training loss: 3.138451578590504
Validation loss: 3.2108206044420986

Epoch: 6| Step: 1
Training loss: 3.1484303817479242
Validation loss: 3.2120907987300447

Epoch: 6| Step: 2
Training loss: 2.923160372249468
Validation loss: 3.212131330306761

Epoch: 6| Step: 3
Training loss: 3.9471286332765794
Validation loss: 3.2111586579981637

Epoch: 6| Step: 4
Training loss: 3.000579936875631
Validation loss: 3.2114578239459646

Epoch: 6| Step: 5
Training loss: 3.1602823918350365
Validation loss: 3.212685556927402

Epoch: 6| Step: 6
Training loss: 3.882866289161505
Validation loss: 3.212330105129416

Epoch: 6| Step: 7
Training loss: 3.2708254933516376
Validation loss: 3.211242744306901

Epoch: 6| Step: 8
Training loss: 3.347694138587369
Validation loss: 3.210856989047853

Epoch: 6| Step: 9
Training loss: 4.075557207264133
Validation loss: 3.210162569946808

Epoch: 6| Step: 10
Training loss: 3.8117077113650626
Validation loss: 3.210055759212588

Epoch: 6| Step: 11
Training loss: 4.004442132583875
Validation loss: 3.2111619344403834

Epoch: 6| Step: 12
Training loss: 3.332673452546558
Validation loss: 3.211478154461456

Epoch: 6| Step: 13
Training loss: 2.8560072447206735
Validation loss: 3.209672668809282

Epoch: 107| Step: 0
Training loss: 2.9807659915878073
Validation loss: 3.2119628540176723

Epoch: 6| Step: 1
Training loss: 3.3200055866883855
Validation loss: 3.210806579850988

Epoch: 6| Step: 2
Training loss: 4.5556264861459415
Validation loss: 3.2138421473997103

Epoch: 6| Step: 3
Training loss: 2.816185719060791
Validation loss: 3.2179209534232975

Epoch: 6| Step: 4
Training loss: 1.8167821351665026
Validation loss: 3.2213924372294085

Epoch: 6| Step: 5
Training loss: 3.842129125225333
Validation loss: 3.2208417608163082

Epoch: 6| Step: 6
Training loss: 3.2553335587892516
Validation loss: 3.2236711774201994

Epoch: 6| Step: 7
Training loss: 3.6750043804116643
Validation loss: 3.2248033072314874

Epoch: 6| Step: 8
Training loss: 4.101583891313266
Validation loss: 3.2138949275330453

Epoch: 6| Step: 9
Training loss: 2.9443190945828372
Validation loss: 3.211361851765507

Epoch: 6| Step: 10
Training loss: 3.7947374142958865
Validation loss: 3.207529922806281

Epoch: 6| Step: 11
Training loss: 3.1532775176621475
Validation loss: 3.208433585697472

Epoch: 6| Step: 12
Training loss: 4.009378168308496
Validation loss: 3.2104238904701496

Epoch: 6| Step: 13
Training loss: 3.2358131344269827
Validation loss: 3.2097110344593123

Epoch: 108| Step: 0
Training loss: 3.680336799758381
Validation loss: 3.210520821754691

Epoch: 6| Step: 1
Training loss: 3.7801300155643207
Validation loss: 3.2096643732574313

Epoch: 6| Step: 2
Training loss: 3.3766485355966167
Validation loss: 3.2087122663167365

Epoch: 6| Step: 3
Training loss: 3.5030467532536527
Validation loss: 3.2079442404499376

Epoch: 6| Step: 4
Training loss: 4.010288358675291
Validation loss: 3.2083947189546294

Epoch: 6| Step: 5
Training loss: 3.7099244351158984
Validation loss: 3.208024032561008

Epoch: 6| Step: 6
Training loss: 2.622468545177764
Validation loss: 3.205363505331495

Epoch: 6| Step: 7
Training loss: 3.661214994951514
Validation loss: 3.207846922826342

Epoch: 6| Step: 8
Training loss: 3.3601831218227702
Validation loss: 3.2050854101928907

Epoch: 6| Step: 9
Training loss: 3.593397571034358
Validation loss: 3.207706259622138

Epoch: 6| Step: 10
Training loss: 4.122079451134445
Validation loss: 3.2090962183100835

Epoch: 6| Step: 11
Training loss: 2.8862393488301263
Validation loss: 3.2122889439871267

Epoch: 6| Step: 12
Training loss: 2.3182793646024002
Validation loss: 3.207312180234293

Epoch: 6| Step: 13
Training loss: 3.2839486786413388
Validation loss: 3.2103869579448996

Epoch: 109| Step: 0
Training loss: 3.412765291402868
Validation loss: 3.2104205302268274

Epoch: 6| Step: 1
Training loss: 3.5703712642182563
Validation loss: 3.2085796070439603

Epoch: 6| Step: 2
Training loss: 2.3174343561548123
Validation loss: 3.207845480309757

Epoch: 6| Step: 3
Training loss: 4.01917747964867
Validation loss: 3.208142026501486

Epoch: 6| Step: 4
Training loss: 3.36506717065028
Validation loss: 3.2056466226231963

Epoch: 6| Step: 5
Training loss: 3.148686325804478
Validation loss: 3.20468550155663

Epoch: 6| Step: 6
Training loss: 3.8741203047900212
Validation loss: 3.2043767636623453

Epoch: 6| Step: 7
Training loss: 2.950828507024536
Validation loss: 3.2037594874883313

Epoch: 6| Step: 8
Training loss: 3.7642268834179204
Validation loss: 3.2033324215747583

Epoch: 6| Step: 9
Training loss: 2.8304157569045567
Validation loss: 3.2016619750901536

Epoch: 6| Step: 10
Training loss: 3.699558907068863
Validation loss: 3.203766730068573

Epoch: 6| Step: 11
Training loss: 3.022651353301151
Validation loss: 3.202540568276933

Epoch: 6| Step: 12
Training loss: 4.250700948917591
Validation loss: 3.202775820816505

Epoch: 6| Step: 13
Training loss: 3.794235756458201
Validation loss: 3.202279397000518

Epoch: 110| Step: 0
Training loss: 3.3570133868357646
Validation loss: 3.2030307790933286

Epoch: 6| Step: 1
Training loss: 3.1683945375564697
Validation loss: 3.2016825423650155

Epoch: 6| Step: 2
Training loss: 4.005220344568438
Validation loss: 3.2051724400918875

Epoch: 6| Step: 3
Training loss: 3.855192566847735
Validation loss: 3.2034543944276463

Epoch: 6| Step: 4
Training loss: 3.3492386593325905
Validation loss: 3.2030241135247155

Epoch: 6| Step: 5
Training loss: 3.313598738491347
Validation loss: 3.2019814935985536

Epoch: 6| Step: 6
Training loss: 3.3997596711883
Validation loss: 3.202887067704231

Epoch: 6| Step: 7
Training loss: 3.0877843810786407
Validation loss: 3.202428455987352

Epoch: 6| Step: 8
Training loss: 3.7389289191264754
Validation loss: 3.1994348510836117

Epoch: 6| Step: 9
Training loss: 3.495578561682743
Validation loss: 3.20202873192448

Epoch: 6| Step: 10
Training loss: 3.3034942853603066
Validation loss: 3.201596489787755

Epoch: 6| Step: 11
Training loss: 3.357984530096903
Validation loss: 3.1996910819024493

Epoch: 6| Step: 12
Training loss: 3.3047290555897884
Validation loss: 3.2002033185714924

Epoch: 6| Step: 13
Training loss: 3.510690710462311
Validation loss: 3.2017138037932575

Epoch: 111| Step: 0
Training loss: 3.8714935681362195
Validation loss: 3.200046731911414

Epoch: 6| Step: 1
Training loss: 3.7051710439883827
Validation loss: 3.2003395244615067

Epoch: 6| Step: 2
Training loss: 3.483857120636798
Validation loss: 3.2004580091781274

Epoch: 6| Step: 3
Training loss: 3.159573759473378
Validation loss: 3.1987936600994336

Epoch: 6| Step: 4
Training loss: 2.4564270343996766
Validation loss: 3.1977928987162305

Epoch: 6| Step: 5
Training loss: 3.712972817672571
Validation loss: 3.1978429430611524

Epoch: 6| Step: 6
Training loss: 3.6842907663799975
Validation loss: 3.200727027871252

Epoch: 6| Step: 7
Training loss: 3.1987849909130843
Validation loss: 3.197829247163266

Epoch: 6| Step: 8
Training loss: 2.7148453307661766
Validation loss: 3.197448534002076

Epoch: 6| Step: 9
Training loss: 3.832276378261344
Validation loss: 3.2009607590424674

Epoch: 6| Step: 10
Training loss: 2.841457239154473
Validation loss: 3.202431859839878

Epoch: 6| Step: 11
Training loss: 4.016799932988965
Validation loss: 3.2049316897511613

Epoch: 6| Step: 12
Training loss: 3.291321909430772
Validation loss: 3.2193707891839276

Epoch: 6| Step: 13
Training loss: 4.194517262706005
Validation loss: 3.223113198896265

Epoch: 112| Step: 0
Training loss: 3.460976215085732
Validation loss: 3.238446328960213

Epoch: 6| Step: 1
Training loss: 3.3195124840424786
Validation loss: 3.2380328422618394

Epoch: 6| Step: 2
Training loss: 3.440511320836441
Validation loss: 3.226179631807489

Epoch: 6| Step: 3
Training loss: 3.1534175438420053
Validation loss: 3.2095223759000007

Epoch: 6| Step: 4
Training loss: 3.2170322612346025
Validation loss: 3.199546263813046

Epoch: 6| Step: 5
Training loss: 4.4894595147544365
Validation loss: 3.1979262539668203

Epoch: 6| Step: 6
Training loss: 4.665374213579697
Validation loss: 3.197732729664254

Epoch: 6| Step: 7
Training loss: 2.9835432401438573
Validation loss: 3.1972903611392334

Epoch: 6| Step: 8
Training loss: 3.1743396522880754
Validation loss: 3.196789937073555

Epoch: 6| Step: 9
Training loss: 3.7711660052217844
Validation loss: 3.196879880037337

Epoch: 6| Step: 10
Training loss: 2.195551197474106
Validation loss: 3.1936300785583085

Epoch: 6| Step: 11
Training loss: 3.406075569376252
Validation loss: 3.1947694067136383

Epoch: 6| Step: 12
Training loss: 2.705302689798799
Validation loss: 3.1939184386802335

Epoch: 6| Step: 13
Training loss: 3.595431921085103
Validation loss: 3.1955411028778222

Epoch: 113| Step: 0
Training loss: 3.5045030780897912
Validation loss: 3.1930364084121017

Epoch: 6| Step: 1
Training loss: 2.768388821916373
Validation loss: 3.1961006784852906

Epoch: 6| Step: 2
Training loss: 3.1690983387070064
Validation loss: 3.194964701669868

Epoch: 6| Step: 3
Training loss: 3.7099376736981187
Validation loss: 3.194785564792899

Epoch: 6| Step: 4
Training loss: 3.4847799159957358
Validation loss: 3.195013995147243

Epoch: 6| Step: 5
Training loss: 2.3459648348424023
Validation loss: 3.192004165170001

Epoch: 6| Step: 6
Training loss: 3.869399422661073
Validation loss: 3.1949629468199294

Epoch: 6| Step: 7
Training loss: 3.6762443356176875
Validation loss: 3.1937939640693416

Epoch: 6| Step: 8
Training loss: 4.0596359721130435
Validation loss: 3.194570206896218

Epoch: 6| Step: 9
Training loss: 2.7077403275193164
Validation loss: 3.193226177459116

Epoch: 6| Step: 10
Training loss: 3.847972752290245
Validation loss: 3.1948146541047477

Epoch: 6| Step: 11
Training loss: 3.6169194890501775
Validation loss: 3.194348974229486

Epoch: 6| Step: 12
Training loss: 3.5659085748562593
Validation loss: 3.195679163264776

Epoch: 6| Step: 13
Training loss: 3.4601351322400427
Validation loss: 3.1942348231918127

Epoch: 114| Step: 0
Training loss: 2.8605931089864325
Validation loss: 3.1990405765844496

Epoch: 6| Step: 1
Training loss: 3.2422498582105614
Validation loss: 3.2020176071496915

Epoch: 6| Step: 2
Training loss: 4.25082389475025
Validation loss: 3.2018898227888015

Epoch: 6| Step: 3
Training loss: 3.4109724713156573
Validation loss: 3.199418381548304

Epoch: 6| Step: 4
Training loss: 3.421202432387482
Validation loss: 3.1966914490394367

Epoch: 6| Step: 5
Training loss: 3.3485890961622213
Validation loss: 3.195107739962264

Epoch: 6| Step: 6
Training loss: 3.804319767345
Validation loss: 3.193841374061453

Epoch: 6| Step: 7
Training loss: 3.7091162780159337
Validation loss: 3.1930728447255783

Epoch: 6| Step: 8
Training loss: 3.1254455248818376
Validation loss: 3.189866733349933

Epoch: 6| Step: 9
Training loss: 3.4716471352640537
Validation loss: 3.19197495306405

Epoch: 6| Step: 10
Training loss: 3.3939444470419566
Validation loss: 3.190974305121442

Epoch: 6| Step: 11
Training loss: 3.6117454770415613
Validation loss: 3.1912505290746513

Epoch: 6| Step: 12
Training loss: 2.7282263807967784
Validation loss: 3.1925372439697424

Epoch: 6| Step: 13
Training loss: 3.6098163549571485
Validation loss: 3.191635363997809

Epoch: 115| Step: 0
Training loss: 3.3567757420273376
Validation loss: 3.1914023122455544

Epoch: 6| Step: 1
Training loss: 4.258243419994421
Validation loss: 3.1898488979741044

Epoch: 6| Step: 2
Training loss: 4.139578287511603
Validation loss: 3.191368379236534

Epoch: 6| Step: 3
Training loss: 3.2478247478822717
Validation loss: 3.1873466700930195

Epoch: 6| Step: 4
Training loss: 2.800584687766694
Validation loss: 3.189995127110452

Epoch: 6| Step: 5
Training loss: 2.896435315982881
Validation loss: 3.1906101576743615

Epoch: 6| Step: 6
Training loss: 3.0231958731371535
Validation loss: 3.1876702758811386

Epoch: 6| Step: 7
Training loss: 3.229369782653457
Validation loss: 3.190769515761516

Epoch: 6| Step: 8
Training loss: 3.4245525318404684
Validation loss: 3.1896507732894412

Epoch: 6| Step: 9
Training loss: 3.3569500354710993
Validation loss: 3.1874317457052315

Epoch: 6| Step: 10
Training loss: 3.233462587375193
Validation loss: 3.1880609098029358

Epoch: 6| Step: 11
Training loss: 3.898959749822676
Validation loss: 3.1882791083742235

Epoch: 6| Step: 12
Training loss: 3.844252638788205
Validation loss: 3.1879970493553893

Epoch: 6| Step: 13
Training loss: 2.7820362308482247
Validation loss: 3.1872915191320152

Epoch: 116| Step: 0
Training loss: 3.559682434576739
Validation loss: 3.189702724824482

Epoch: 6| Step: 1
Training loss: 3.551382553167207
Validation loss: 3.186740117920698

Epoch: 6| Step: 2
Training loss: 2.970513231778047
Validation loss: 3.1887827195786493

Epoch: 6| Step: 3
Training loss: 3.4744611583058704
Validation loss: 3.188582252504936

Epoch: 6| Step: 4
Training loss: 2.9261283719525206
Validation loss: 3.188725386557163

Epoch: 6| Step: 5
Training loss: 3.8866558127363486
Validation loss: 3.1891491327761132

Epoch: 6| Step: 6
Training loss: 3.3206910400027128
Validation loss: 3.1859811135398464

Epoch: 6| Step: 7
Training loss: 3.8089797230303737
Validation loss: 3.187852579812676

Epoch: 6| Step: 8
Training loss: 3.396689621008921
Validation loss: 3.18438678534666

Epoch: 6| Step: 9
Training loss: 3.523254931133059
Validation loss: 3.184883586460985

Epoch: 6| Step: 10
Training loss: 3.9088500868106553
Validation loss: 3.186346438495312

Epoch: 6| Step: 11
Training loss: 3.8551928142217036
Validation loss: 3.184986952781371

Epoch: 6| Step: 12
Training loss: 2.898886756319459
Validation loss: 3.1830012024885783

Epoch: 6| Step: 13
Training loss: 2.0267382472765525
Validation loss: 3.1847400092719345

Epoch: 117| Step: 0
Training loss: 3.1948889565908685
Validation loss: 3.1884681506948063

Epoch: 6| Step: 1
Training loss: 2.9898379191991418
Validation loss: 3.1871822841454454

Epoch: 6| Step: 2
Training loss: 3.251040952210418
Validation loss: 3.1873791418581714

Epoch: 6| Step: 3
Training loss: 3.6608121400308384
Validation loss: 3.1850878914239322

Epoch: 6| Step: 4
Training loss: 3.625124435919865
Validation loss: 3.1872136733195187

Epoch: 6| Step: 5
Training loss: 4.153223757290835
Validation loss: 3.184204917417514

Epoch: 6| Step: 6
Training loss: 2.302319774884713
Validation loss: 3.184109800100575

Epoch: 6| Step: 7
Training loss: 3.5852757593395537
Validation loss: 3.1830713840690295

Epoch: 6| Step: 8
Training loss: 3.14456218443635
Validation loss: 3.185331978998711

Epoch: 6| Step: 9
Training loss: 3.2128092932334935
Validation loss: 3.186216175049443

Epoch: 6| Step: 10
Training loss: 3.6705677059046833
Validation loss: 3.1856274043506607

Epoch: 6| Step: 11
Training loss: 3.579462725851705
Validation loss: 3.185772277374518

Epoch: 6| Step: 12
Training loss: 4.3754939209193235
Validation loss: 3.191638157655985

Epoch: 6| Step: 13
Training loss: 2.157459085900918
Validation loss: 3.1833257251690035

Epoch: 118| Step: 0
Training loss: 3.247408493902412
Validation loss: 3.1843053180943657

Epoch: 6| Step: 1
Training loss: 2.940942248947692
Validation loss: 3.1880255902620256

Epoch: 6| Step: 2
Training loss: 3.473045644823199
Validation loss: 3.185811186745385

Epoch: 6| Step: 3
Training loss: 3.877078329606118
Validation loss: 3.1847475213030974

Epoch: 6| Step: 4
Training loss: 3.4082159965731154
Validation loss: 3.183085602540825

Epoch: 6| Step: 5
Training loss: 2.1807211335876
Validation loss: 3.18181199921656

Epoch: 6| Step: 6
Training loss: 2.9880370994011205
Validation loss: 3.183089354067656

Epoch: 6| Step: 7
Training loss: 4.119024167465285
Validation loss: 3.1839901337457595

Epoch: 6| Step: 8
Training loss: 2.808538062295628
Validation loss: 3.183643387835888

Epoch: 6| Step: 9
Training loss: 3.2762005418219404
Validation loss: 3.1904738851556798

Epoch: 6| Step: 10
Training loss: 3.756508583143328
Validation loss: 3.187588970560044

Epoch: 6| Step: 11
Training loss: 4.363657826674302
Validation loss: 3.1868594670324875

Epoch: 6| Step: 12
Training loss: 3.6691629986409304
Validation loss: 3.181014676799515

Epoch: 6| Step: 13
Training loss: 3.414926519985731
Validation loss: 3.1820234220526045

Epoch: 119| Step: 0
Training loss: 3.117194383656638
Validation loss: 3.1803905367648446

Epoch: 6| Step: 1
Training loss: 3.0746099085050673
Validation loss: 3.18459717910154

Epoch: 6| Step: 2
Training loss: 3.3425865644888053
Validation loss: 3.193577341603295

Epoch: 6| Step: 3
Training loss: 4.048611183813555
Validation loss: 3.1958771645038384

Epoch: 6| Step: 4
Training loss: 3.55256700252565
Validation loss: 3.19163591019914

Epoch: 6| Step: 5
Training loss: 3.842972219286844
Validation loss: 3.1845939880302683

Epoch: 6| Step: 6
Training loss: 3.3392686136738954
Validation loss: 3.1794554834433058

Epoch: 6| Step: 7
Training loss: 3.4911709186954627
Validation loss: 3.177859419763707

Epoch: 6| Step: 8
Training loss: 3.604735195471059
Validation loss: 3.178685058319038

Epoch: 6| Step: 9
Training loss: 2.8537953453120646
Validation loss: 3.1783721945465353

Epoch: 6| Step: 10
Training loss: 3.1115416066218318
Validation loss: 3.177930480455204

Epoch: 6| Step: 11
Training loss: 3.835391252396548
Validation loss: 3.1789252488305735

Epoch: 6| Step: 12
Training loss: 3.743888579846257
Validation loss: 3.179239982174951

Epoch: 6| Step: 13
Training loss: 2.4859062610056477
Validation loss: 3.1789942155887636

Epoch: 120| Step: 0
Training loss: 4.052906622845616
Validation loss: 3.1792894235007343

Epoch: 6| Step: 1
Training loss: 3.4191207601013103
Validation loss: 3.1789407390624906

Epoch: 6| Step: 2
Training loss: 3.3450240800615183
Validation loss: 3.1781376636355394

Epoch: 6| Step: 3
Training loss: 3.5996501752638888
Validation loss: 3.1810919739835355

Epoch: 6| Step: 4
Training loss: 2.499610489065426
Validation loss: 3.1777988837749995

Epoch: 6| Step: 5
Training loss: 2.7800271421246423
Validation loss: 3.178557977256347

Epoch: 6| Step: 6
Training loss: 3.4131908569800014
Validation loss: 3.178160185187627

Epoch: 6| Step: 7
Training loss: 3.1057733734241317
Validation loss: 3.1778741996342608

Epoch: 6| Step: 8
Training loss: 2.8375641332428265
Validation loss: 3.176816338762234

Epoch: 6| Step: 9
Training loss: 3.782063168188298
Validation loss: 3.177399270043286

Epoch: 6| Step: 10
Training loss: 3.7651040124394046
Validation loss: 3.177117304600988

Epoch: 6| Step: 11
Training loss: 3.307678456354227
Validation loss: 3.1780564112926286

Epoch: 6| Step: 12
Training loss: 4.017234390679514
Validation loss: 3.179147899950061

Epoch: 6| Step: 13
Training loss: 3.9335330174293115
Validation loss: 3.17747620578101

Epoch: 121| Step: 0
Training loss: 3.548488703584636
Validation loss: 3.178584730143231

Epoch: 6| Step: 1
Training loss: 3.1509513568809937
Validation loss: 3.176162720831271

Epoch: 6| Step: 2
Training loss: 3.4177550156387495
Validation loss: 3.1771985277056687

Epoch: 6| Step: 3
Training loss: 3.3689566299396114
Validation loss: 3.177805056902943

Epoch: 6| Step: 4
Training loss: 4.249092678381767
Validation loss: 3.1771056423416013

Epoch: 6| Step: 5
Training loss: 4.120184196873012
Validation loss: 3.1768704716090683

Epoch: 6| Step: 6
Training loss: 2.9061553283366384
Validation loss: 3.176509531144417

Epoch: 6| Step: 7
Training loss: 3.3704244893037054
Validation loss: 3.176465059287045

Epoch: 6| Step: 8
Training loss: 3.2022772434733664
Validation loss: 3.1756374372632177

Epoch: 6| Step: 9
Training loss: 3.5733319959590553
Validation loss: 3.177018840154706

Epoch: 6| Step: 10
Training loss: 3.1777865939547842
Validation loss: 3.1744438303410716

Epoch: 6| Step: 11
Training loss: 3.4562835746914113
Validation loss: 3.1737390780518964

Epoch: 6| Step: 12
Training loss: 3.4774122249843638
Validation loss: 3.175931266897558

Epoch: 6| Step: 13
Training loss: 1.747203977449487
Validation loss: 3.1742249286690183

Epoch: 122| Step: 0
Training loss: 2.9477195718789937
Validation loss: 3.175035429041379

Epoch: 6| Step: 1
Training loss: 3.1403539739924566
Validation loss: 3.1755366398236946

Epoch: 6| Step: 2
Training loss: 3.321966643338787
Validation loss: 3.1799025097932305

Epoch: 6| Step: 3
Training loss: 3.7406288038599342
Validation loss: 3.180804873814289

Epoch: 6| Step: 4
Training loss: 3.7602187480602987
Validation loss: 3.1807973524718474

Epoch: 6| Step: 5
Training loss: 3.1422617428818382
Validation loss: 3.175128446019933

Epoch: 6| Step: 6
Training loss: 3.782082962473745
Validation loss: 3.1720976594528163

Epoch: 6| Step: 7
Training loss: 3.932752502250494
Validation loss: 3.1735063842555564

Epoch: 6| Step: 8
Training loss: 3.2559302584890437
Validation loss: 3.1730313793933207

Epoch: 6| Step: 9
Training loss: 3.2903357281744916
Validation loss: 3.1698505417670484

Epoch: 6| Step: 10
Training loss: 3.3091416518925327
Validation loss: 3.171271851523935

Epoch: 6| Step: 11
Training loss: 3.34907022925045
Validation loss: 3.1711918185904393

Epoch: 6| Step: 12
Training loss: 3.518515792830752
Validation loss: 3.1698123156098026

Epoch: 6| Step: 13
Training loss: 3.286134408664174
Validation loss: 3.1692421796136045

Epoch: 123| Step: 0
Training loss: 3.359587906589082
Validation loss: 3.168922202038361

Epoch: 6| Step: 1
Training loss: 2.863913514403142
Validation loss: 3.1710504647974282

Epoch: 6| Step: 2
Training loss: 3.8849240860953924
Validation loss: 3.1708348733553464

Epoch: 6| Step: 3
Training loss: 3.7582274146425596
Validation loss: 3.1708972401256363

Epoch: 6| Step: 4
Training loss: 4.040974325021553
Validation loss: 3.170705582443499

Epoch: 6| Step: 5
Training loss: 3.2489475600265902
Validation loss: 3.1703800897869154

Epoch: 6| Step: 6
Training loss: 3.210540078621593
Validation loss: 3.169290762545325

Epoch: 6| Step: 7
Training loss: 2.9641073767482773
Validation loss: 3.170368836976405

Epoch: 6| Step: 8
Training loss: 3.651564897529099
Validation loss: 3.171101628857357

Epoch: 6| Step: 9
Training loss: 3.797050315043337
Validation loss: 3.1703252372145596

Epoch: 6| Step: 10
Training loss: 3.298637172306018
Validation loss: 3.171524528790603

Epoch: 6| Step: 11
Training loss: 2.879429763130753
Validation loss: 3.1692657722771598

Epoch: 6| Step: 12
Training loss: 3.88304165139014
Validation loss: 3.169965912170553

Epoch: 6| Step: 13
Training loss: 2.0668451027081995
Validation loss: 3.1689922334914993

Epoch: 124| Step: 0
Training loss: 3.967086323142423
Validation loss: 3.1679980790763853

Epoch: 6| Step: 1
Training loss: 3.0440461940894536
Validation loss: 3.1690716740001723

Epoch: 6| Step: 2
Training loss: 3.794847991271254
Validation loss: 3.1698651333376224

Epoch: 6| Step: 3
Training loss: 3.7269602949127263
Validation loss: 3.169990898536687

Epoch: 6| Step: 4
Training loss: 3.39708631993476
Validation loss: 3.1700196112642076

Epoch: 6| Step: 5
Training loss: 3.4170060028032374
Validation loss: 3.170371392231506

Epoch: 6| Step: 6
Training loss: 2.4816588903253622
Validation loss: 3.1699164661464465

Epoch: 6| Step: 7
Training loss: 3.549730269164924
Validation loss: 3.1696655702778878

Epoch: 6| Step: 8
Training loss: 2.657091074906293
Validation loss: 3.169618628518996

Epoch: 6| Step: 9
Training loss: 3.5035937796152385
Validation loss: 3.1693383514176685

Epoch: 6| Step: 10
Training loss: 3.1088888277070943
Validation loss: 3.170239681512078

Epoch: 6| Step: 11
Training loss: 3.78230207955368
Validation loss: 3.1677093429998955

Epoch: 6| Step: 12
Training loss: 3.416002782816055
Validation loss: 3.1688944283264373

Epoch: 6| Step: 13
Training loss: 3.845135694869934
Validation loss: 3.1682193627084527

Epoch: 125| Step: 0
Training loss: 2.73728988050089
Validation loss: 3.1683612336222904

Epoch: 6| Step: 1
Training loss: 3.4846418475278047
Validation loss: 3.167612566537929

Epoch: 6| Step: 2
Training loss: 3.0892370426492475
Validation loss: 3.1669882452933487

Epoch: 6| Step: 3
Training loss: 3.5219976693210113
Validation loss: 3.165104703169404

Epoch: 6| Step: 4
Training loss: 3.6130138731309245
Validation loss: 3.1665562209431934

Epoch: 6| Step: 5
Training loss: 3.102413954237059
Validation loss: 3.166457275069535

Epoch: 6| Step: 6
Training loss: 3.4907633290420543
Validation loss: 3.1662265512761576

Epoch: 6| Step: 7
Training loss: 3.9330336655941895
Validation loss: 3.166229330107886

Epoch: 6| Step: 8
Training loss: 3.9402712803119497
Validation loss: 3.1653065769555706

Epoch: 6| Step: 9
Training loss: 3.097331122596971
Validation loss: 3.165739657772905

Epoch: 6| Step: 10
Training loss: 3.5140660877472376
Validation loss: 3.1656469479999885

Epoch: 6| Step: 11
Training loss: 3.6854663995751555
Validation loss: 3.1643907010906602

Epoch: 6| Step: 12
Training loss: 3.215237080092411
Validation loss: 3.1631340979032077

Epoch: 6| Step: 13
Training loss: 2.992881116826321
Validation loss: 3.164180179880276

Epoch: 126| Step: 0
Training loss: 3.6018533651273748
Validation loss: 3.1646326335051858

Epoch: 6| Step: 1
Training loss: 3.136933087808488
Validation loss: 3.163202481790007

Epoch: 6| Step: 2
Training loss: 3.452187665530301
Validation loss: 3.163115085727025

Epoch: 6| Step: 3
Training loss: 3.788871209733225
Validation loss: 3.163537965778361

Epoch: 6| Step: 4
Training loss: 3.4437573441498084
Validation loss: 3.1632791728164893

Epoch: 6| Step: 5
Training loss: 3.7511803358880944
Validation loss: 3.16417988982619

Epoch: 6| Step: 6
Training loss: 2.824642671925081
Validation loss: 3.163286251981707

Epoch: 6| Step: 7
Training loss: 4.005325824947236
Validation loss: 3.1647751463778353

Epoch: 6| Step: 8
Training loss: 2.5772946956946563
Validation loss: 3.1638815251404795

Epoch: 6| Step: 9
Training loss: 4.028089600400843
Validation loss: 3.1621619784541206

Epoch: 6| Step: 10
Training loss: 2.7276121376265423
Validation loss: 3.1632600642591444

Epoch: 6| Step: 11
Training loss: 3.4415515951234803
Validation loss: 3.161710964846132

Epoch: 6| Step: 12
Training loss: 3.597343174403675
Validation loss: 3.1641351920117637

Epoch: 6| Step: 13
Training loss: 2.6439784499139964
Validation loss: 3.1623782819503674

Epoch: 127| Step: 0
Training loss: 3.692702163813091
Validation loss: 3.1599471560761643

Epoch: 6| Step: 1
Training loss: 3.1572617523846973
Validation loss: 3.1627053584490397

Epoch: 6| Step: 2
Training loss: 3.6795608919882166
Validation loss: 3.163045714385952

Epoch: 6| Step: 3
Training loss: 3.4942583945968346
Validation loss: 3.1617731977990404

Epoch: 6| Step: 4
Training loss: 3.1495560772244624
Validation loss: 3.1628225230576668

Epoch: 6| Step: 5
Training loss: 3.2065542333273473
Validation loss: 3.1609816293761193

Epoch: 6| Step: 6
Training loss: 3.5202779538778746
Validation loss: 3.163289834916645

Epoch: 6| Step: 7
Training loss: 3.675775542138236
Validation loss: 3.160316890623545

Epoch: 6| Step: 8
Training loss: 2.5247734950232417
Validation loss: 3.1607880654292106

Epoch: 6| Step: 9
Training loss: 3.180791639721512
Validation loss: 3.1639711622805815

Epoch: 6| Step: 10
Training loss: 3.3550958392898873
Validation loss: 3.1610922920381075

Epoch: 6| Step: 11
Training loss: 3.883711221560896
Validation loss: 3.1616746211821245

Epoch: 6| Step: 12
Training loss: 3.7993904227163227
Validation loss: 3.1605752131576863

Epoch: 6| Step: 13
Training loss: 3.018308088287263
Validation loss: 3.1588840773171305

Epoch: 128| Step: 0
Training loss: 3.3778564233436024
Validation loss: 3.15903250181549

Epoch: 6| Step: 1
Training loss: 3.1329520710512626
Validation loss: 3.159238140159287

Epoch: 6| Step: 2
Training loss: 4.024178860703098
Validation loss: 3.1580404334495142

Epoch: 6| Step: 3
Training loss: 3.497828627465431
Validation loss: 3.159303706604322

Epoch: 6| Step: 4
Training loss: 2.6332504858996
Validation loss: 3.160462242486421

Epoch: 6| Step: 5
Training loss: 2.639907649187796
Validation loss: 3.1552318099094445

Epoch: 6| Step: 6
Training loss: 4.19567323977172
Validation loss: 3.1585983495922867

Epoch: 6| Step: 7
Training loss: 2.851118831870188
Validation loss: 3.156800478643455

Epoch: 6| Step: 8
Training loss: 4.331685168491101
Validation loss: 3.1573219529899075

Epoch: 6| Step: 9
Training loss: 3.1041083277056933
Validation loss: 3.1578347146754964

Epoch: 6| Step: 10
Training loss: 3.1667622668910407
Validation loss: 3.1575011481678406

Epoch: 6| Step: 11
Training loss: 3.532973012605714
Validation loss: 3.158470723322523

Epoch: 6| Step: 12
Training loss: 3.0642197120715178
Validation loss: 3.158761721742987

Epoch: 6| Step: 13
Training loss: 3.7696512944373026
Validation loss: 3.158210343797909

Epoch: 129| Step: 0
Training loss: 3.2766886659998082
Validation loss: 3.15656858444799

Epoch: 6| Step: 1
Training loss: 2.604952050351666
Validation loss: 3.1569352512264173

Epoch: 6| Step: 2
Training loss: 3.598253960510716
Validation loss: 3.1580385671619577

Epoch: 6| Step: 3
Training loss: 3.9745527483681165
Validation loss: 3.1552075403010913

Epoch: 6| Step: 4
Training loss: 3.6943491028710698
Validation loss: 3.1547321677171167

Epoch: 6| Step: 5
Training loss: 2.9626859067377396
Validation loss: 3.155725086821924

Epoch: 6| Step: 6
Training loss: 3.0956801741558544
Validation loss: 3.156688051011527

Epoch: 6| Step: 7
Training loss: 3.3556341590124004
Validation loss: 3.1554647659036816

Epoch: 6| Step: 8
Training loss: 3.4530214320052655
Validation loss: 3.1550771165999043

Epoch: 6| Step: 9
Training loss: 3.21630381248933
Validation loss: 3.1556457750167897

Epoch: 6| Step: 10
Training loss: 3.3894164572826453
Validation loss: 3.1575090237890944

Epoch: 6| Step: 11
Training loss: 3.568679536300857
Validation loss: 3.15615942390604

Epoch: 6| Step: 12
Training loss: 3.6432719942765437
Validation loss: 3.15578165948433

Epoch: 6| Step: 13
Training loss: 3.7907682059991177
Validation loss: 3.1559577172199655

Epoch: 130| Step: 0
Training loss: 3.3641546269553277
Validation loss: 3.155216759036717

Epoch: 6| Step: 1
Training loss: 3.293746548674366
Validation loss: 3.1541471734768534

Epoch: 6| Step: 2
Training loss: 3.1490555149586523
Validation loss: 3.152437454418602

Epoch: 6| Step: 3
Training loss: 2.685146809689817
Validation loss: 3.154079671035985

Epoch: 6| Step: 4
Training loss: 3.2123562910539403
Validation loss: 3.1550513052049585

Epoch: 6| Step: 5
Training loss: 2.794757915515304
Validation loss: 3.1542126157344117

Epoch: 6| Step: 6
Training loss: 3.864542108334736
Validation loss: 3.1526340080024444

Epoch: 6| Step: 7
Training loss: 3.626387232038169
Validation loss: 3.1534803762074404

Epoch: 6| Step: 8
Training loss: 4.122605062040092
Validation loss: 3.1535441161874926

Epoch: 6| Step: 9
Training loss: 3.7027731941603683
Validation loss: 3.152928504800038

Epoch: 6| Step: 10
Training loss: 2.8796581181948575
Validation loss: 3.1525449088727124

Epoch: 6| Step: 11
Training loss: 3.653639945879448
Validation loss: 3.1535632023237516

Epoch: 6| Step: 12
Training loss: 3.66294404550566
Validation loss: 3.15366920883956

Epoch: 6| Step: 13
Training loss: 3.242988358826377
Validation loss: 3.1525019311087004

Epoch: 131| Step: 0
Training loss: 3.094588040989078
Validation loss: 3.152532309983599

Epoch: 6| Step: 1
Training loss: 3.693528242603033
Validation loss: 3.1529805881910686

Epoch: 6| Step: 2
Training loss: 4.303099628448488
Validation loss: 3.153287176185362

Epoch: 6| Step: 3
Training loss: 3.9711683219408522
Validation loss: 3.153842652469043

Epoch: 6| Step: 4
Training loss: 3.1748704718653578
Validation loss: 3.1515172773170708

Epoch: 6| Step: 5
Training loss: 2.0113399408215273
Validation loss: 3.1512610531068224

Epoch: 6| Step: 6
Training loss: 3.6589926841643936
Validation loss: 3.1517048195478967

Epoch: 6| Step: 7
Training loss: 2.860072316675963
Validation loss: 3.152048500735623

Epoch: 6| Step: 8
Training loss: 3.389636198794889
Validation loss: 3.1501951895830853

Epoch: 6| Step: 9
Training loss: 3.266987055682509
Validation loss: 3.148900897620075

Epoch: 6| Step: 10
Training loss: 3.518294342514055
Validation loss: 3.1536655117351167

Epoch: 6| Step: 11
Training loss: 3.5719582001481984
Validation loss: 3.1499057526820304

Epoch: 6| Step: 12
Training loss: 3.5020115385273938
Validation loss: 3.1528524466727763

Epoch: 6| Step: 13
Training loss: 2.7824308481731803
Validation loss: 3.152823928874205

Epoch: 132| Step: 0
Training loss: 3.0714677573711096
Validation loss: 3.150350806173931

Epoch: 6| Step: 1
Training loss: 3.332117399329597
Validation loss: 3.1481764657271567

Epoch: 6| Step: 2
Training loss: 3.255558395890815
Validation loss: 3.14976852570481

Epoch: 6| Step: 3
Training loss: 3.665679509764942
Validation loss: 3.149436162674084

Epoch: 6| Step: 4
Training loss: 3.72450708289823
Validation loss: 3.1499611406978096

Epoch: 6| Step: 5
Training loss: 3.2644381031741996
Validation loss: 3.1486830462304627

Epoch: 6| Step: 6
Training loss: 3.597495871747626
Validation loss: 3.1500477362871884

Epoch: 6| Step: 7
Training loss: 3.861052978468317
Validation loss: 3.1499143985016937

Epoch: 6| Step: 8
Training loss: 2.9749379768638073
Validation loss: 3.1485500040271654

Epoch: 6| Step: 9
Training loss: 3.128006061499301
Validation loss: 3.1489917264570253

Epoch: 6| Step: 10
Training loss: 4.083948413429666
Validation loss: 3.1500318288944826

Epoch: 6| Step: 11
Training loss: 3.4466118470879925
Validation loss: 3.1464575039848897

Epoch: 6| Step: 12
Training loss: 2.8150100527595727
Validation loss: 3.1479732442187545

Epoch: 6| Step: 13
Training loss: 2.834581623726398
Validation loss: 3.1473814663159803

Epoch: 133| Step: 0
Training loss: 2.7706312999830125
Validation loss: 3.145784462560915

Epoch: 6| Step: 1
Training loss: 3.442458581834571
Validation loss: 3.1457853712242163

Epoch: 6| Step: 2
Training loss: 3.815894319994298
Validation loss: 3.146687466173933

Epoch: 6| Step: 3
Training loss: 3.840582185759567
Validation loss: 3.147382490996156

Epoch: 6| Step: 4
Training loss: 4.06777423930617
Validation loss: 3.146668548529542

Epoch: 6| Step: 5
Training loss: 3.130624516007867
Validation loss: 3.1453861249289647

Epoch: 6| Step: 6
Training loss: 3.413905927965438
Validation loss: 3.1443984495662907

Epoch: 6| Step: 7
Training loss: 4.029855412996626
Validation loss: 3.1435606440731547

Epoch: 6| Step: 8
Training loss: 2.6901506171904512
Validation loss: 3.144206861149563

Epoch: 6| Step: 9
Training loss: 3.4112084372432205
Validation loss: 3.146230451040827

Epoch: 6| Step: 10
Training loss: 3.7413951058738553
Validation loss: 3.1445740807103615

Epoch: 6| Step: 11
Training loss: 3.102076413411829
Validation loss: 3.14477359095473

Epoch: 6| Step: 12
Training loss: 2.8955573812683757
Validation loss: 3.1446633567669595

Epoch: 6| Step: 13
Training loss: 2.1613642538040807
Validation loss: 3.145282887626374

Epoch: 134| Step: 0
Training loss: 3.4878566436530622
Validation loss: 3.146343512273236

Epoch: 6| Step: 1
Training loss: 3.8007968067191906
Validation loss: 3.1483303483289737

Epoch: 6| Step: 2
Training loss: 2.702608974352285
Validation loss: 3.1450930607717575

Epoch: 6| Step: 3
Training loss: 3.8088123434865504
Validation loss: 3.1476651205663866

Epoch: 6| Step: 4
Training loss: 2.184689160022915
Validation loss: 3.1449001655584

Epoch: 6| Step: 5
Training loss: 3.413156210158188
Validation loss: 3.1487087388494563

Epoch: 6| Step: 6
Training loss: 2.6014697542355067
Validation loss: 3.1449050239912855

Epoch: 6| Step: 7
Training loss: 3.643072263526068
Validation loss: 3.1446910868740785

Epoch: 6| Step: 8
Training loss: 4.111683476329554
Validation loss: 3.1444725989602658

Epoch: 6| Step: 9
Training loss: 3.292786580722553
Validation loss: 3.144481293145087

Epoch: 6| Step: 10
Training loss: 3.5023425301135505
Validation loss: 3.142885024622666

Epoch: 6| Step: 11
Training loss: 3.130587046601269
Validation loss: 3.145098786197074

Epoch: 6| Step: 12
Training loss: 3.8086374446612123
Validation loss: 3.1438247689060796

Epoch: 6| Step: 13
Training loss: 3.5680288945811407
Validation loss: 3.1421347005547453

Epoch: 135| Step: 0
Training loss: 2.976084272760396
Validation loss: 3.142648276080881

Epoch: 6| Step: 1
Training loss: 3.8046885026307713
Validation loss: 3.142489997086287

Epoch: 6| Step: 2
Training loss: 3.5737492487487326
Validation loss: 3.1406618990664334

Epoch: 6| Step: 3
Training loss: 3.54923307704364
Validation loss: 3.1403473533542603

Epoch: 6| Step: 4
Training loss: 2.9595019400903317
Validation loss: 3.14072580777237

Epoch: 6| Step: 5
Training loss: 3.451552088917356
Validation loss: 3.1406509283247783

Epoch: 6| Step: 6
Training loss: 3.6084345133091746
Validation loss: 3.141141188379994

Epoch: 6| Step: 7
Training loss: 2.884275649189552
Validation loss: 3.1414047952217774

Epoch: 6| Step: 8
Training loss: 3.531737167377209
Validation loss: 3.1407120293174846

Epoch: 6| Step: 9
Training loss: 3.7371321838454805
Validation loss: 3.1424225379313766

Epoch: 6| Step: 10
Training loss: 4.165333165722728
Validation loss: 3.1412771216578803

Epoch: 6| Step: 11
Training loss: 2.768421892483202
Validation loss: 3.142634886199692

Epoch: 6| Step: 12
Training loss: 3.248955632182461
Validation loss: 3.1398402999825783

Epoch: 6| Step: 13
Training loss: 2.5031914367621964
Validation loss: 3.1413440569932005

Epoch: 136| Step: 0
Training loss: 3.484714645459269
Validation loss: 3.1412392896435986

Epoch: 6| Step: 1
Training loss: 2.122048628477282
Validation loss: 3.140299896602912

Epoch: 6| Step: 2
Training loss: 3.7007916660335396
Validation loss: 3.142050482301356

Epoch: 6| Step: 3
Training loss: 3.446517214704561
Validation loss: 3.1406156535390393

Epoch: 6| Step: 4
Training loss: 3.59220760251892
Validation loss: 3.143115156836481

Epoch: 6| Step: 5
Training loss: 3.522225791161859
Validation loss: 3.140732625146652

Epoch: 6| Step: 6
Training loss: 3.8010334115510664
Validation loss: 3.144090057119241

Epoch: 6| Step: 7
Training loss: 3.058105117917212
Validation loss: 3.139415384153196

Epoch: 6| Step: 8
Training loss: 4.276338530568802
Validation loss: 3.140338027292264

Epoch: 6| Step: 9
Training loss: 2.412781211789489
Validation loss: 3.1386572478630117

Epoch: 6| Step: 10
Training loss: 3.806025150466545
Validation loss: 3.138048115899622

Epoch: 6| Step: 11
Training loss: 2.834718552601111
Validation loss: 3.1367124257252352

Epoch: 6| Step: 12
Training loss: 3.816049643091667
Validation loss: 3.137410542790966

Epoch: 6| Step: 13
Training loss: 2.5531970234567445
Validation loss: 3.1366083438864902

Epoch: 137| Step: 0
Training loss: 3.388417452624743
Validation loss: 3.1384251828250163

Epoch: 6| Step: 1
Training loss: 3.5399440989417914
Validation loss: 3.137194310701926

Epoch: 6| Step: 2
Training loss: 4.052256654826053
Validation loss: 3.135661783238653

Epoch: 6| Step: 3
Training loss: 3.075147553912254
Validation loss: 3.136310946303389

Epoch: 6| Step: 4
Training loss: 2.9440836075541474
Validation loss: 3.1353361782876124

Epoch: 6| Step: 5
Training loss: 3.035310679941526
Validation loss: 3.138422938921487

Epoch: 6| Step: 6
Training loss: 3.5392831897767834
Validation loss: 3.1372838866476362

Epoch: 6| Step: 7
Training loss: 3.468142482034987
Validation loss: 3.1385114857151057

Epoch: 6| Step: 8
Training loss: 3.275109348946779
Validation loss: 3.140473440234854

Epoch: 6| Step: 9
Training loss: 3.5731286226060384
Validation loss: 3.1380061552330525

Epoch: 6| Step: 10
Training loss: 4.062055827581241
Validation loss: 3.1422667848827004

Epoch: 6| Step: 11
Training loss: 2.669794711675457
Validation loss: 3.138800454957725

Epoch: 6| Step: 12
Training loss: 3.408286789356344
Validation loss: 3.138990564345441

Epoch: 6| Step: 13
Training loss: 2.98763221224714
Validation loss: 3.137448874469129

Epoch: 138| Step: 0
Training loss: 3.7017394745347896
Validation loss: 3.135263145633968

Epoch: 6| Step: 1
Training loss: 3.642775264856319
Validation loss: 3.1353967115651415

Epoch: 6| Step: 2
Training loss: 3.119514533690029
Validation loss: 3.135299513357487

Epoch: 6| Step: 3
Training loss: 3.038232371260049
Validation loss: 3.135397919226193

Epoch: 6| Step: 4
Training loss: 3.6742804257478348
Validation loss: 3.1362317239094812

Epoch: 6| Step: 5
Training loss: 3.6415688269512825
Validation loss: 3.1351155264651336

Epoch: 6| Step: 6
Training loss: 3.038110265140865
Validation loss: 3.1352998657732765

Epoch: 6| Step: 7
Training loss: 2.9904509203719294
Validation loss: 3.1347938000410793

Epoch: 6| Step: 8
Training loss: 4.05127562225535
Validation loss: 3.134729011461619

Epoch: 6| Step: 9
Training loss: 4.229803228468494
Validation loss: 3.138342921106156

Epoch: 6| Step: 10
Training loss: 2.7428888798762214
Validation loss: 3.135474942020464

Epoch: 6| Step: 11
Training loss: 3.302074219764303
Validation loss: 3.1351037668394315

Epoch: 6| Step: 12
Training loss: 3.1016947143970115
Validation loss: 3.1341049158945564

Epoch: 6| Step: 13
Training loss: 2.0293926256810684
Validation loss: 3.138732111164505

Epoch: 139| Step: 0
Training loss: 3.5774551497553038
Validation loss: 3.136165150309365

Epoch: 6| Step: 1
Training loss: 2.7858745403096856
Validation loss: 3.1331856534288582

Epoch: 6| Step: 2
Training loss: 3.64482797475768
Validation loss: 3.132564500185373

Epoch: 6| Step: 3
Training loss: 3.4118955530993014
Validation loss: 3.130640073262827

Epoch: 6| Step: 4
Training loss: 2.564240213636386
Validation loss: 3.1310871684103763

Epoch: 6| Step: 5
Training loss: 3.6431137550221036
Validation loss: 3.1313180342429385

Epoch: 6| Step: 6
Training loss: 2.9059822205264134
Validation loss: 3.130252280019018

Epoch: 6| Step: 7
Training loss: 3.4067024140494904
Validation loss: 3.131310501285378

Epoch: 6| Step: 8
Training loss: 3.575219986556143
Validation loss: 3.131096449974768

Epoch: 6| Step: 9
Training loss: 3.9817122593778036
Validation loss: 3.1309437198733794

Epoch: 6| Step: 10
Training loss: 3.6524116387407095
Validation loss: 3.129884512920378

Epoch: 6| Step: 11
Training loss: 3.5800008729049213
Validation loss: 3.1304785043150947

Epoch: 6| Step: 12
Training loss: 2.799993726178361
Validation loss: 3.131816664925688

Epoch: 6| Step: 13
Training loss: 3.664850666703996
Validation loss: 3.1311975514155126

Epoch: 140| Step: 0
Training loss: 3.2774946248514545
Validation loss: 3.1322657987025297

Epoch: 6| Step: 1
Training loss: 3.594141532467484
Validation loss: 3.132187416886703

Epoch: 6| Step: 2
Training loss: 3.5255536070792
Validation loss: 3.1327425132865336

Epoch: 6| Step: 3
Training loss: 3.428168097114725
Validation loss: 3.130782022478225

Epoch: 6| Step: 4
Training loss: 3.2407708807457
Validation loss: 3.1324330715065187

Epoch: 6| Step: 5
Training loss: 4.2778025759904335
Validation loss: 3.131158973727073

Epoch: 6| Step: 6
Training loss: 3.6565854171401218
Validation loss: 3.1302123966627127

Epoch: 6| Step: 7
Training loss: 3.060525841753268
Validation loss: 3.1304606491481923

Epoch: 6| Step: 8
Training loss: 2.059388443435529
Validation loss: 3.130535050873993

Epoch: 6| Step: 9
Training loss: 3.520514042990326
Validation loss: 3.1275256150139374

Epoch: 6| Step: 10
Training loss: 2.992630808687315
Validation loss: 3.1268320951977513

Epoch: 6| Step: 11
Training loss: 3.358899459892338
Validation loss: 3.1280282412129474

Epoch: 6| Step: 12
Training loss: 3.621253346503189
Validation loss: 3.1279030816409943

Epoch: 6| Step: 13
Training loss: 3.238516841550745
Validation loss: 3.126586717966656

Epoch: 141| Step: 0
Training loss: 3.847004202959161
Validation loss: 3.126632367455916

Epoch: 6| Step: 1
Training loss: 3.381905872526236
Validation loss: 3.1260937899227077

Epoch: 6| Step: 2
Training loss: 3.2334006495858487
Validation loss: 3.1274715092612326

Epoch: 6| Step: 3
Training loss: 2.774514604335838
Validation loss: 3.1269984592404945

Epoch: 6| Step: 4
Training loss: 3.5856799197300604
Validation loss: 3.1265229991058656

Epoch: 6| Step: 5
Training loss: 2.422315889651181
Validation loss: 3.1250004036195556

Epoch: 6| Step: 6
Training loss: 3.8642170913320686
Validation loss: 3.12583493143632

Epoch: 6| Step: 7
Training loss: 3.8258929537979625
Validation loss: 3.1262677416611466

Epoch: 6| Step: 8
Training loss: 4.186485053656849
Validation loss: 3.1251426565772107

Epoch: 6| Step: 9
Training loss: 2.7375798218120027
Validation loss: 3.125599803172622

Epoch: 6| Step: 10
Training loss: 3.0878662262832726
Validation loss: 3.1254692742540002

Epoch: 6| Step: 11
Training loss: 3.6267549936206667
Validation loss: 3.1259732148144153

Epoch: 6| Step: 12
Training loss: 2.944355533465055
Validation loss: 3.1260041508355796

Epoch: 6| Step: 13
Training loss: 3.2860100506415804
Validation loss: 3.1255584857631424

Epoch: 142| Step: 0
Training loss: 3.1977513339931822
Validation loss: 3.125509413350423

Epoch: 6| Step: 1
Training loss: 3.172372863482623
Validation loss: 3.1280069482810777

Epoch: 6| Step: 2
Training loss: 3.6050008054777347
Validation loss: 3.1272132140589735

Epoch: 6| Step: 3
Training loss: 2.655522504926276
Validation loss: 3.1258656170437424

Epoch: 6| Step: 4
Training loss: 3.6118341960935583
Validation loss: 3.1257664763908606

Epoch: 6| Step: 5
Training loss: 3.422570284225565
Validation loss: 3.12636051218279

Epoch: 6| Step: 6
Training loss: 2.5047605964336745
Validation loss: 3.1252713682420556

Epoch: 6| Step: 7
Training loss: 3.479234949839065
Validation loss: 3.126451241471606

Epoch: 6| Step: 8
Training loss: 2.8764296584404865
Validation loss: 3.1238237345289797

Epoch: 6| Step: 9
Training loss: 3.7282583029002336
Validation loss: 3.122487095998338

Epoch: 6| Step: 10
Training loss: 3.4927186156699013
Validation loss: 3.1247304738623516

Epoch: 6| Step: 11
Training loss: 4.030355664785425
Validation loss: 3.1223521181778557

Epoch: 6| Step: 12
Training loss: 3.7147225762308786
Validation loss: 3.125856803010086

Epoch: 6| Step: 13
Training loss: 3.4603692615131973
Validation loss: 3.1327493905872252

Epoch: 143| Step: 0
Training loss: 2.861176470490432
Validation loss: 3.130187750430577

Epoch: 6| Step: 1
Training loss: 2.9797277566863865
Validation loss: 3.1390211156326258

Epoch: 6| Step: 2
Training loss: 3.5545958790132732
Validation loss: 3.133515021917514

Epoch: 6| Step: 3
Training loss: 2.676466448964997
Validation loss: 3.1376631762917957

Epoch: 6| Step: 4
Training loss: 3.2339325385668554
Validation loss: 3.1346161700499295

Epoch: 6| Step: 5
Training loss: 3.433895648968228
Validation loss: 3.1262259115318987

Epoch: 6| Step: 6
Training loss: 4.036787857223071
Validation loss: 3.126278996584683

Epoch: 6| Step: 7
Training loss: 3.5369416675799563
Validation loss: 3.125087237217169

Epoch: 6| Step: 8
Training loss: 3.495297406248842
Validation loss: 3.122852712424844

Epoch: 6| Step: 9
Training loss: 3.290736843718953
Validation loss: 3.1230731068688677

Epoch: 6| Step: 10
Training loss: 3.2474707518590042
Validation loss: 3.1190958768245443

Epoch: 6| Step: 11
Training loss: 3.6131719789220633
Validation loss: 3.1187759897126224

Epoch: 6| Step: 12
Training loss: 3.6931122566554606
Validation loss: 3.1204025873144787

Epoch: 6| Step: 13
Training loss: 3.417894530444179
Validation loss: 3.119038488347165

Epoch: 144| Step: 0
Training loss: 3.3066556223818195
Validation loss: 3.1196168766378487

Epoch: 6| Step: 1
Training loss: 3.5137357933927023
Validation loss: 3.1185728030631616

Epoch: 6| Step: 2
Training loss: 3.0847703489026133
Validation loss: 3.119213027509842

Epoch: 6| Step: 3
Training loss: 2.47526193639129
Validation loss: 3.1196294662912707

Epoch: 6| Step: 4
Training loss: 3.1391942954984704
Validation loss: 3.118670911404901

Epoch: 6| Step: 5
Training loss: 3.3136496798001223
Validation loss: 3.119225170044736

Epoch: 6| Step: 6
Training loss: 3.5891108548233013
Validation loss: 3.120143522877146

Epoch: 6| Step: 7
Training loss: 3.334872287895701
Validation loss: 3.1187014710375225

Epoch: 6| Step: 8
Training loss: 3.998611686105537
Validation loss: 3.118850550994305

Epoch: 6| Step: 9
Training loss: 3.325752379686619
Validation loss: 3.1194827953205055

Epoch: 6| Step: 10
Training loss: 2.7083349570245034
Validation loss: 3.119415140234554

Epoch: 6| Step: 11
Training loss: 4.005555586360015
Validation loss: 3.1216671963201974

Epoch: 6| Step: 12
Training loss: 3.698695886028509
Validation loss: 3.1187067303286438

Epoch: 6| Step: 13
Training loss: 3.423776733918008
Validation loss: 3.1196129403062804

Epoch: 145| Step: 0
Training loss: 2.5534950763213473
Validation loss: 3.1187070015953724

Epoch: 6| Step: 1
Training loss: 3.8101331524347315
Validation loss: 3.120536678403063

Epoch: 6| Step: 2
Training loss: 2.385346512963674
Validation loss: 3.1182904560640243

Epoch: 6| Step: 3
Training loss: 3.1911017320483888
Validation loss: 3.1189953497177165

Epoch: 6| Step: 4
Training loss: 3.6515193233132797
Validation loss: 3.120209235460613

Epoch: 6| Step: 5
Training loss: 3.06380761704416
Validation loss: 3.1179381977884915

Epoch: 6| Step: 6
Training loss: 3.8739393690068527
Validation loss: 3.117167617085139

Epoch: 6| Step: 7
Training loss: 4.548841333103946
Validation loss: 3.117060377430112

Epoch: 6| Step: 8
Training loss: 3.5900884136055593
Validation loss: 3.115083194571701

Epoch: 6| Step: 9
Training loss: 3.431876281393462
Validation loss: 3.115380418149412

Epoch: 6| Step: 10
Training loss: 2.826588250038181
Validation loss: 3.115415431444032

Epoch: 6| Step: 11
Training loss: 3.07136436091122
Validation loss: 3.115613643428762

Epoch: 6| Step: 12
Training loss: 3.6526573332126393
Validation loss: 3.1150522620189185

Epoch: 6| Step: 13
Training loss: 2.4896916534822027
Validation loss: 3.115702450906862

Epoch: 146| Step: 0
Training loss: 2.4190279069089504
Validation loss: 3.114692684971159

Epoch: 6| Step: 1
Training loss: 3.2193626635520043
Validation loss: 3.114268561758302

Epoch: 6| Step: 2
Training loss: 4.5506869457771755
Validation loss: 3.1147155887285725

Epoch: 6| Step: 3
Training loss: 2.788874601130807
Validation loss: 3.1152041640250325

Epoch: 6| Step: 4
Training loss: 3.053695790906232
Validation loss: 3.1150972493346942

Epoch: 6| Step: 5
Training loss: 3.7662039030832637
Validation loss: 3.1158291779955434

Epoch: 6| Step: 6
Training loss: 3.1258510193764697
Validation loss: 3.114288569373014

Epoch: 6| Step: 7
Training loss: 3.5127843612739786
Validation loss: 3.1150064173137717

Epoch: 6| Step: 8
Training loss: 3.9150916781354645
Validation loss: 3.114244154023001

Epoch: 6| Step: 9
Training loss: 2.611649030598694
Validation loss: 3.1148371049664263

Epoch: 6| Step: 10
Training loss: 3.331853792534153
Validation loss: 3.114369526253841

Epoch: 6| Step: 11
Training loss: 2.51123953559332
Validation loss: 3.1139681414967075

Epoch: 6| Step: 12
Training loss: 3.5817452985304414
Validation loss: 3.1157062095146055

Epoch: 6| Step: 13
Training loss: 4.477071203916843
Validation loss: 3.1129577874646106

Epoch: 147| Step: 0
Training loss: 3.949904385145852
Validation loss: 3.113804322662096

Epoch: 6| Step: 1
Training loss: 2.599091143581549
Validation loss: 3.115139928417228

Epoch: 6| Step: 2
Training loss: 2.639067241151751
Validation loss: 3.1127224326718603

Epoch: 6| Step: 3
Training loss: 3.6391406000518587
Validation loss: 3.1138346023801167

Epoch: 6| Step: 4
Training loss: 3.1505397092069085
Validation loss: 3.112529326889369

Epoch: 6| Step: 5
Training loss: 3.5743390839545373
Validation loss: 3.1128049753187956

Epoch: 6| Step: 6
Training loss: 3.131416142790059
Validation loss: 3.1125865289868906

Epoch: 6| Step: 7
Training loss: 3.266390915994114
Validation loss: 3.1112582977136416

Epoch: 6| Step: 8
Training loss: 3.648485857297972
Validation loss: 3.113227898026101

Epoch: 6| Step: 9
Training loss: 3.837144836491818
Validation loss: 3.110785771247009

Epoch: 6| Step: 10
Training loss: 3.925839065961081
Validation loss: 3.110710200766838

Epoch: 6| Step: 11
Training loss: 2.8661838198781067
Validation loss: 3.110407059787515

Epoch: 6| Step: 12
Training loss: 2.196310556322683
Validation loss: 3.1120199009893015

Epoch: 6| Step: 13
Training loss: 4.536373215003455
Validation loss: 3.1134420522100625

Epoch: 148| Step: 0
Training loss: 3.5298528017038864
Validation loss: 3.111846760920071

Epoch: 6| Step: 1
Training loss: 2.7853426877575815
Validation loss: 3.111242285106553

Epoch: 6| Step: 2
Training loss: 3.4278478880777117
Validation loss: 3.1108518883485825

Epoch: 6| Step: 3
Training loss: 3.098671129953362
Validation loss: 3.1105884565525908

Epoch: 6| Step: 4
Training loss: 3.437129052694695
Validation loss: 3.1102794284755957

Epoch: 6| Step: 5
Training loss: 3.5247314513156947
Validation loss: 3.1111552974631644

Epoch: 6| Step: 6
Training loss: 3.1333632900618666
Validation loss: 3.1102929255022413

Epoch: 6| Step: 7
Training loss: 3.493487975747782
Validation loss: 3.110205927792078

Epoch: 6| Step: 8
Training loss: 3.156393217859897
Validation loss: 3.1097106818355087

Epoch: 6| Step: 9
Training loss: 2.6399731254654717
Validation loss: 3.110646108064641

Epoch: 6| Step: 10
Training loss: 3.8324621426876844
Validation loss: 3.1127833192351226

Epoch: 6| Step: 11
Training loss: 3.414761329900751
Validation loss: 3.1117863338638903

Epoch: 6| Step: 12
Training loss: 4.271559838010821
Validation loss: 3.110180316057146

Epoch: 6| Step: 13
Training loss: 2.746152874457975
Validation loss: 3.109960050716372

Epoch: 149| Step: 0
Training loss: 4.184071973863583
Validation loss: 3.109855812145486

Epoch: 6| Step: 1
Training loss: 3.7370718312044833
Validation loss: 3.1083043374520307

Epoch: 6| Step: 2
Training loss: 3.149351985822326
Validation loss: 3.10711159385529

Epoch: 6| Step: 3
Training loss: 2.9182668020470106
Validation loss: 3.10752330861541

Epoch: 6| Step: 4
Training loss: 2.6353530172469677
Validation loss: 3.108211666401447

Epoch: 6| Step: 5
Training loss: 3.3478714685686715
Validation loss: 3.1095068162579427

Epoch: 6| Step: 6
Training loss: 3.308875205939173
Validation loss: 3.107510596492144

Epoch: 6| Step: 7
Training loss: 3.441099744260717
Validation loss: 3.1094444128228447

Epoch: 6| Step: 8
Training loss: 3.9067308053706906
Validation loss: 3.111557854150463

Epoch: 6| Step: 9
Training loss: 3.2298268945562434
Validation loss: 3.1108556742433584

Epoch: 6| Step: 10
Training loss: 3.7367712018389057
Validation loss: 3.1134380290241395

Epoch: 6| Step: 11
Training loss: 3.61946538465494
Validation loss: 3.1101649960636535

Epoch: 6| Step: 12
Training loss: 2.5078353167770446
Validation loss: 3.1088404916178973

Epoch: 6| Step: 13
Training loss: 2.5437424943143068
Validation loss: 3.1082130025707246

Epoch: 150| Step: 0
Training loss: 3.8605720424246686
Validation loss: 3.1054516913142245

Epoch: 6| Step: 1
Training loss: 3.035543174088514
Validation loss: 3.1056894015662895

Epoch: 6| Step: 2
Training loss: 3.45555740232374
Validation loss: 3.105153239960002

Epoch: 6| Step: 3
Training loss: 3.302658720858824
Validation loss: 3.1047768660321724

Epoch: 6| Step: 4
Training loss: 3.502116925503759
Validation loss: 3.106186691738031

Epoch: 6| Step: 5
Training loss: 3.9991714096173694
Validation loss: 3.104236606675228

Epoch: 6| Step: 6
Training loss: 3.8684129410988852
Validation loss: 3.1029300019847676

Epoch: 6| Step: 7
Training loss: 2.766472120990165
Validation loss: 3.104429357898213

Epoch: 6| Step: 8
Training loss: 3.4682572848261994
Validation loss: 3.1032785198214246

Epoch: 6| Step: 9
Training loss: 3.3921075207925218
Validation loss: 3.102917007484628

Epoch: 6| Step: 10
Training loss: 2.77746762027631
Validation loss: 3.103879087882906

Epoch: 6| Step: 11
Training loss: 2.8850214902186497
Validation loss: 3.103548402255066

Epoch: 6| Step: 12
Training loss: 3.064039193881277
Validation loss: 3.1043192271333844

Epoch: 6| Step: 13
Training loss: 3.3756273887440775
Validation loss: 3.1046818362642123

Epoch: 151| Step: 0
Training loss: 3.403323254796074
Validation loss: 3.10560774540795

Epoch: 6| Step: 1
Training loss: 3.5875564942912668
Validation loss: 3.1084558162317553

Epoch: 6| Step: 2
Training loss: 3.039354952589781
Validation loss: 3.1049862602970477

Epoch: 6| Step: 3
Training loss: 2.868021747511978
Validation loss: 3.108922303653224

Epoch: 6| Step: 4
Training loss: 4.013751472370705
Validation loss: 3.1044648563996193

Epoch: 6| Step: 5
Training loss: 3.223499534553647
Validation loss: 3.104081859587737

Epoch: 6| Step: 6
Training loss: 3.405047843249686
Validation loss: 3.1061766985812036

Epoch: 6| Step: 7
Training loss: 3.4588589249731205
Validation loss: 3.1052993923264376

Epoch: 6| Step: 8
Training loss: 3.4523223358339594
Validation loss: 3.1018399213987524

Epoch: 6| Step: 9
Training loss: 2.7210906903547882
Validation loss: 3.1029306150250755

Epoch: 6| Step: 10
Training loss: 2.9011571417152315
Validation loss: 3.102440712578879

Epoch: 6| Step: 11
Training loss: 3.1302948917009066
Validation loss: 3.1015615544103707

Epoch: 6| Step: 12
Training loss: 3.977036723281247
Validation loss: 3.100315818683178

Epoch: 6| Step: 13
Training loss: 3.7254905838469154
Validation loss: 3.103041774911479

Epoch: 152| Step: 0
Training loss: 2.8503885439321066
Validation loss: 3.100617842842365

Epoch: 6| Step: 1
Training loss: 3.9647650950480195
Validation loss: 3.1004396142104347

Epoch: 6| Step: 2
Training loss: 3.402505338666036
Validation loss: 3.099923115496997

Epoch: 6| Step: 3
Training loss: 3.49285895871052
Validation loss: 3.098540454519414

Epoch: 6| Step: 4
Training loss: 3.240594605879946
Validation loss: 3.099779106404985

Epoch: 6| Step: 5
Training loss: 3.3755746987911763
Validation loss: 3.0993359550833945

Epoch: 6| Step: 6
Training loss: 3.303280073006625
Validation loss: 3.098072422072493

Epoch: 6| Step: 7
Training loss: 3.6205335263945657
Validation loss: 3.0991369303343936

Epoch: 6| Step: 8
Training loss: 3.1191577469004077
Validation loss: 3.0989787428443973

Epoch: 6| Step: 9
Training loss: 3.6422861918035667
Validation loss: 3.098834795758839

Epoch: 6| Step: 10
Training loss: 3.0171403783420603
Validation loss: 3.10206836565234

Epoch: 6| Step: 11
Training loss: 3.168778735750961
Validation loss: 3.1029903900044307

Epoch: 6| Step: 12
Training loss: 3.5534377363897804
Validation loss: 3.1045732619353217

Epoch: 6| Step: 13
Training loss: 2.8388262031570295
Validation loss: 3.1057795609429077

Epoch: 153| Step: 0
Training loss: 3.3936309849786306
Validation loss: 3.1034701592021126

Epoch: 6| Step: 1
Training loss: 2.9411890119397426
Validation loss: 3.102955624818255

Epoch: 6| Step: 2
Training loss: 3.94865484390494
Validation loss: 3.105352598177266

Epoch: 6| Step: 3
Training loss: 2.644793588988928
Validation loss: 3.107741328821337

Epoch: 6| Step: 4
Training loss: 3.6645365654391986
Validation loss: 3.1038228981776577

Epoch: 6| Step: 5
Training loss: 3.9978443536120825
Validation loss: 3.0991023551969374

Epoch: 6| Step: 6
Training loss: 3.154387273762684
Validation loss: 3.0982122681189495

Epoch: 6| Step: 7
Training loss: 3.321836449443378
Validation loss: 3.09757103514597

Epoch: 6| Step: 8
Training loss: 2.760627844068234
Validation loss: 3.095966269932348

Epoch: 6| Step: 9
Training loss: 3.8416238502438906
Validation loss: 3.0970605526936965

Epoch: 6| Step: 10
Training loss: 3.0396048642904336
Validation loss: 3.097447271466595

Epoch: 6| Step: 11
Training loss: 3.1939367489795307
Validation loss: 3.097223489127947

Epoch: 6| Step: 12
Training loss: 3.638280940695781
Validation loss: 3.0948675197944584

Epoch: 6| Step: 13
Training loss: 2.7956388501566813
Validation loss: 3.0964827613508286

Epoch: 154| Step: 0
Training loss: 2.4033974918402863
Validation loss: 3.0949082073637424

Epoch: 6| Step: 1
Training loss: 2.6412042287244715
Validation loss: 3.0945412949793285

Epoch: 6| Step: 2
Training loss: 2.9906648989958633
Validation loss: 3.094597349182116

Epoch: 6| Step: 3
Training loss: 4.2814286466206015
Validation loss: 3.096136846903767

Epoch: 6| Step: 4
Training loss: 3.4247080601923408
Validation loss: 3.0953683872153896

Epoch: 6| Step: 5
Training loss: 3.403468685117607
Validation loss: 3.0931204790001385

Epoch: 6| Step: 6
Training loss: 4.446113500851184
Validation loss: 3.094811219489783

Epoch: 6| Step: 7
Training loss: 3.0139917882492298
Validation loss: 3.094781789113869

Epoch: 6| Step: 8
Training loss: 3.5221096336375313
Validation loss: 3.092629761958581

Epoch: 6| Step: 9
Training loss: 3.6209332246393835
Validation loss: 3.0928784258601807

Epoch: 6| Step: 10
Training loss: 2.9486198170811364
Validation loss: 3.0948641798761733

Epoch: 6| Step: 11
Training loss: 3.1155891623009397
Validation loss: 3.0968187313568762

Epoch: 6| Step: 12
Training loss: 3.6099226895240872
Validation loss: 3.099870170417729

Epoch: 6| Step: 13
Training loss: 2.4035085939936573
Validation loss: 3.107138381873422

Epoch: 155| Step: 0
Training loss: 2.806214238472068
Validation loss: 3.1083863425695015

Epoch: 6| Step: 1
Training loss: 2.591910479771658
Validation loss: 3.1124686989312185

Epoch: 6| Step: 2
Training loss: 4.0392570522535065
Validation loss: 3.1053239397145433

Epoch: 6| Step: 3
Training loss: 3.1411105108048756
Validation loss: 3.09560978272147

Epoch: 6| Step: 4
Training loss: 3.147979172886124
Validation loss: 3.096625946839345

Epoch: 6| Step: 5
Training loss: 4.160740312580259
Validation loss: 3.0944076987497717

Epoch: 6| Step: 6
Training loss: 4.021056542929426
Validation loss: 3.0946371481018256

Epoch: 6| Step: 7
Training loss: 3.0244077559871285
Validation loss: 3.0935789151915802

Epoch: 6| Step: 8
Training loss: 3.7594429650509
Validation loss: 3.095475137739689

Epoch: 6| Step: 9
Training loss: 3.4938414751064233
Validation loss: 3.093531458645386

Epoch: 6| Step: 10
Training loss: 3.528961385245966
Validation loss: 3.091760185447456

Epoch: 6| Step: 11
Training loss: 2.769888657077649
Validation loss: 3.0926523988882

Epoch: 6| Step: 12
Training loss: 3.5183080310956805
Validation loss: 3.0932732201553166

Epoch: 6| Step: 13
Training loss: 0.5978165205936459
Validation loss: 3.092013715726307

Epoch: 156| Step: 0
Training loss: 3.5193171801226786
Validation loss: 3.0904263363483624

Epoch: 6| Step: 1
Training loss: 3.774309203750421
Validation loss: 3.0918179376312915

Epoch: 6| Step: 2
Training loss: 2.721253393518928
Validation loss: 3.0906643918349586

Epoch: 6| Step: 3
Training loss: 3.1599730637766434
Validation loss: 3.0897023627165705

Epoch: 6| Step: 4
Training loss: 3.2108155758767087
Validation loss: 3.0904014814897627

Epoch: 6| Step: 5
Training loss: 2.793182663628539
Validation loss: 3.091485593673191

Epoch: 6| Step: 6
Training loss: 3.196151660514832
Validation loss: 3.090196398464342

Epoch: 6| Step: 7
Training loss: 4.254637039787534
Validation loss: 3.090148355698086

Epoch: 6| Step: 8
Training loss: 3.7473189624627774
Validation loss: 3.094682781777139

Epoch: 6| Step: 9
Training loss: 3.4025377115350195
Validation loss: 3.0930327206181496

Epoch: 6| Step: 10
Training loss: 2.5053466843267405
Validation loss: 3.093514644072606

Epoch: 6| Step: 11
Training loss: 3.3250661054651065
Validation loss: 3.09172722517488

Epoch: 6| Step: 12
Training loss: 3.986536613967005
Validation loss: 3.090175879789743

Epoch: 6| Step: 13
Training loss: 2.186655371954676
Validation loss: 3.0907765867619474

Epoch: 157| Step: 0
Training loss: 3.490180136286382
Validation loss: 3.0913932120692786

Epoch: 6| Step: 1
Training loss: 3.5052552959287047
Validation loss: 3.0919561089808782

Epoch: 6| Step: 2
Training loss: 3.25847254957338
Validation loss: 3.093222146212864

Epoch: 6| Step: 3
Training loss: 3.657478843309666
Validation loss: 3.088328665728753

Epoch: 6| Step: 4
Training loss: 3.2690350555939514
Validation loss: 3.0895229816271104

Epoch: 6| Step: 5
Training loss: 3.0676142748848885
Validation loss: 3.0881194527987708

Epoch: 6| Step: 6
Training loss: 3.6607278644163723
Validation loss: 3.08707399179755

Epoch: 6| Step: 7
Training loss: 3.426280908455619
Validation loss: 3.0862832119392802

Epoch: 6| Step: 8
Training loss: 3.3138983312193213
Validation loss: 3.084369653775549

Epoch: 6| Step: 9
Training loss: 3.9162872752958306
Validation loss: 3.0855774239079765

Epoch: 6| Step: 10
Training loss: 2.986927478789836
Validation loss: 3.0861302361426572

Epoch: 6| Step: 11
Training loss: 2.722282394946508
Validation loss: 3.085985490356478

Epoch: 6| Step: 12
Training loss: 3.0903437194265653
Validation loss: 3.0845694642945185

Epoch: 6| Step: 13
Training loss: 3.2467617628307868
Validation loss: 3.0857667928977857

Epoch: 158| Step: 0
Training loss: 2.9281219775531357
Validation loss: 3.088690780799894

Epoch: 6| Step: 1
Training loss: 3.78668881029272
Validation loss: 3.086305650376711

Epoch: 6| Step: 2
Training loss: 3.1591630843845007
Validation loss: 3.0878490454460814

Epoch: 6| Step: 3
Training loss: 2.8547933591226906
Validation loss: 3.0883186073160878

Epoch: 6| Step: 4
Training loss: 3.498895743422465
Validation loss: 3.0891855924324183

Epoch: 6| Step: 5
Training loss: 3.072289681992192
Validation loss: 3.087263567931027

Epoch: 6| Step: 6
Training loss: 2.810827648143144
Validation loss: 3.093391209548193

Epoch: 6| Step: 7
Training loss: 3.792749494821501
Validation loss: 3.086878731738651

Epoch: 6| Step: 8
Training loss: 2.957840479956721
Validation loss: 3.090523875759016

Epoch: 6| Step: 9
Training loss: 3.262920226879968
Validation loss: 3.096388165055207

Epoch: 6| Step: 10
Training loss: 3.8135628391328673
Validation loss: 3.087281321672483

Epoch: 6| Step: 11
Training loss: 3.9923649877222434
Validation loss: 3.094195043349547

Epoch: 6| Step: 12
Training loss: 3.1158127585628987
Validation loss: 3.0859789192241514

Epoch: 6| Step: 13
Training loss: 3.556549188401111
Validation loss: 3.0840637059251805

Epoch: 159| Step: 0
Training loss: 2.9171079211013176
Validation loss: 3.0849506994108706

Epoch: 6| Step: 1
Training loss: 3.610024662092087
Validation loss: 3.08341741959961

Epoch: 6| Step: 2
Training loss: 3.1827852872528832
Validation loss: 3.083416658011154

Epoch: 6| Step: 3
Training loss: 3.672970093100347
Validation loss: 3.082433794390792

Epoch: 6| Step: 4
Training loss: 3.322255003932905
Validation loss: 3.082333377389746

Epoch: 6| Step: 5
Training loss: 3.6839639552503747
Validation loss: 3.082551525033211

Epoch: 6| Step: 6
Training loss: 2.6486467036888697
Validation loss: 3.081692067281778

Epoch: 6| Step: 7
Training loss: 3.591885290255591
Validation loss: 3.084362307871698

Epoch: 6| Step: 8
Training loss: 4.0371533129865895
Validation loss: 3.0818261040930763

Epoch: 6| Step: 9
Training loss: 2.8131246932647613
Validation loss: 3.0821024880515795

Epoch: 6| Step: 10
Training loss: 3.2410310084417064
Validation loss: 3.0842750250931514

Epoch: 6| Step: 11
Training loss: 3.340346270674316
Validation loss: 3.0812662471446144

Epoch: 6| Step: 12
Training loss: 3.1674593552388077
Validation loss: 3.081028924966952

Epoch: 6| Step: 13
Training loss: 3.3188223333432374
Validation loss: 3.080773268285952

Epoch: 160| Step: 0
Training loss: 3.339287177217424
Validation loss: 3.082096898464355

Epoch: 6| Step: 1
Training loss: 3.7757045972491645
Validation loss: 3.082000414935054

Epoch: 6| Step: 2
Training loss: 2.3221298960939922
Validation loss: 3.081109566751762

Epoch: 6| Step: 3
Training loss: 3.2680932167420544
Validation loss: 3.0828910123468054

Epoch: 6| Step: 4
Training loss: 3.387998345799138
Validation loss: 3.0812606718485958

Epoch: 6| Step: 5
Training loss: 3.231624889946432
Validation loss: 3.0837586820951657

Epoch: 6| Step: 6
Training loss: 3.400219820433748
Validation loss: 3.0819959165000093

Epoch: 6| Step: 7
Training loss: 2.696116451940516
Validation loss: 3.0790138075361955

Epoch: 6| Step: 8
Training loss: 3.7932649255181237
Validation loss: 3.0815505472442446

Epoch: 6| Step: 9
Training loss: 3.552500158708584
Validation loss: 3.0786973525128536

Epoch: 6| Step: 10
Training loss: 3.7259185682521423
Validation loss: 3.079751411589318

Epoch: 6| Step: 11
Training loss: 3.2279165165539516
Validation loss: 3.08114585062293

Epoch: 6| Step: 12
Training loss: 3.091098304046761
Validation loss: 3.080291645136113

Epoch: 6| Step: 13
Training loss: 3.8095176163123514
Validation loss: 3.082580860935221

Epoch: 161| Step: 0
Training loss: 4.00078956440749
Validation loss: 3.0828994303215627

Epoch: 6| Step: 1
Training loss: 3.409762190415987
Validation loss: 3.082135844867086

Epoch: 6| Step: 2
Training loss: 2.8065098869439096
Validation loss: 3.084177579817368

Epoch: 6| Step: 3
Training loss: 3.4715663714365395
Validation loss: 3.0841916548914203

Epoch: 6| Step: 4
Training loss: 3.4879679266828645
Validation loss: 3.080091144274331

Epoch: 6| Step: 5
Training loss: 2.7060557447670255
Validation loss: 3.0859369384133744

Epoch: 6| Step: 6
Training loss: 3.6531353587321056
Validation loss: 3.0863917560443177

Epoch: 6| Step: 7
Training loss: 2.635375091667085
Validation loss: 3.0857353089174127

Epoch: 6| Step: 8
Training loss: 4.008679509960134
Validation loss: 3.0863063107436086

Epoch: 6| Step: 9
Training loss: 3.355415885606561
Validation loss: 3.081750923208649

Epoch: 6| Step: 10
Training loss: 3.4455264624073654
Validation loss: 3.0804960077518557

Epoch: 6| Step: 11
Training loss: 3.252361466714371
Validation loss: 3.0789686443690587

Epoch: 6| Step: 12
Training loss: 3.088848353957759
Validation loss: 3.07720285239451

Epoch: 6| Step: 13
Training loss: 2.8087739634626936
Validation loss: 3.0761422579619437

Epoch: 162| Step: 0
Training loss: 3.532926178511589
Validation loss: 3.0766570811230722

Epoch: 6| Step: 1
Training loss: 3.88651018206098
Validation loss: 3.0756899905847193

Epoch: 6| Step: 2
Training loss: 3.1642026516992408
Validation loss: 3.0767297459547116

Epoch: 6| Step: 3
Training loss: 1.591522305451224
Validation loss: 3.0762946537411056

Epoch: 6| Step: 4
Training loss: 3.642034298797605
Validation loss: 3.0763091407226493

Epoch: 6| Step: 5
Training loss: 3.364149240809765
Validation loss: 3.076654972986592

Epoch: 6| Step: 6
Training loss: 2.436293768139736
Validation loss: 3.075288527477032

Epoch: 6| Step: 7
Training loss: 3.576695852264278
Validation loss: 3.076316330853596

Epoch: 6| Step: 8
Training loss: 2.59089098624394
Validation loss: 3.076294325399845

Epoch: 6| Step: 9
Training loss: 3.9050742859557754
Validation loss: 3.074951363108948

Epoch: 6| Step: 10
Training loss: 3.659870409312858
Validation loss: 3.0746439444428395

Epoch: 6| Step: 11
Training loss: 3.756231344116395
Validation loss: 3.0773249710275996

Epoch: 6| Step: 12
Training loss: 3.2805099379335614
Validation loss: 3.074940204614237

Epoch: 6| Step: 13
Training loss: 3.591315863191572
Validation loss: 3.075674226232738

Epoch: 163| Step: 0
Training loss: 2.3418332209244204
Validation loss: 3.0756244062483935

Epoch: 6| Step: 1
Training loss: 3.1140419139650564
Validation loss: 3.074860830064821

Epoch: 6| Step: 2
Training loss: 3.646483590402299
Validation loss: 3.073089764646941

Epoch: 6| Step: 3
Training loss: 3.3416616032309157
Validation loss: 3.075305792657741

Epoch: 6| Step: 4
Training loss: 3.414563593982914
Validation loss: 3.0741097485566766

Epoch: 6| Step: 5
Training loss: 3.9868515396205324
Validation loss: 3.074502825418704

Epoch: 6| Step: 6
Training loss: 3.127264499351049
Validation loss: 3.074260613973046

Epoch: 6| Step: 7
Training loss: 4.1552425683709435
Validation loss: 3.073494832227083

Epoch: 6| Step: 8
Training loss: 2.8410276020646754
Validation loss: 3.0744987546135754

Epoch: 6| Step: 9
Training loss: 3.92551669467733
Validation loss: 3.0778595084411533

Epoch: 6| Step: 10
Training loss: 3.3461367921200695
Validation loss: 3.0727103743736404

Epoch: 6| Step: 11
Training loss: 2.908465125769498
Validation loss: 3.0739997124546337

Epoch: 6| Step: 12
Training loss: 2.85589153953642
Validation loss: 3.071279565136627

Epoch: 6| Step: 13
Training loss: 3.014781774717686
Validation loss: 3.0722867647894394

Epoch: 164| Step: 0
Training loss: 1.9310994407458224
Validation loss: 3.0708521934557127

Epoch: 6| Step: 1
Training loss: 3.2012981880967177
Validation loss: 3.0695244209475563

Epoch: 6| Step: 2
Training loss: 3.0690516243996258
Validation loss: 3.069159290265353

Epoch: 6| Step: 3
Training loss: 4.0334093091970695
Validation loss: 3.0703900450142245

Epoch: 6| Step: 4
Training loss: 4.09787967098249
Validation loss: 3.0712563516472673

Epoch: 6| Step: 5
Training loss: 3.207223493828841
Validation loss: 3.0702920237882325

Epoch: 6| Step: 6
Training loss: 3.128248738557739
Validation loss: 3.070202700217638

Epoch: 6| Step: 7
Training loss: 3.5080426316927684
Validation loss: 3.069289596211072

Epoch: 6| Step: 8
Training loss: 3.1353207866080504
Validation loss: 3.0694362468464935

Epoch: 6| Step: 9
Training loss: 2.729701293141847
Validation loss: 3.0686640815527304

Epoch: 6| Step: 10
Training loss: 3.26546350107164
Validation loss: 3.072919956467614

Epoch: 6| Step: 11
Training loss: 3.3748741126424378
Validation loss: 3.080207927417702

Epoch: 6| Step: 12
Training loss: 3.636684265956607
Validation loss: 3.0746143527094114

Epoch: 6| Step: 13
Training loss: 4.06039115750302
Validation loss: 3.074315594491673

Epoch: 165| Step: 0
Training loss: 3.394981573894763
Validation loss: 3.0747450444650295

Epoch: 6| Step: 1
Training loss: 3.37701412430448
Validation loss: 3.0714102735891826

Epoch: 6| Step: 2
Training loss: 2.8351471275084017
Validation loss: 3.0736219783789953

Epoch: 6| Step: 3
Training loss: 3.9205723761139337
Validation loss: 3.0732261336422555

Epoch: 6| Step: 4
Training loss: 2.8949690885326516
Validation loss: 3.067530679192396

Epoch: 6| Step: 5
Training loss: 3.754448731411102
Validation loss: 3.068409100726713

Epoch: 6| Step: 6
Training loss: 2.629150016558643
Validation loss: 3.0683206272086636

Epoch: 6| Step: 7
Training loss: 2.9328072581907407
Validation loss: 3.069020268827319

Epoch: 6| Step: 8
Training loss: 3.026470545689851
Validation loss: 3.068767981679869

Epoch: 6| Step: 9
Training loss: 3.1619220793627907
Validation loss: 3.0785111603124693

Epoch: 6| Step: 10
Training loss: 3.417821564911304
Validation loss: 3.0746113626694473

Epoch: 6| Step: 11
Training loss: 4.359694383741698
Validation loss: 3.080102980762837

Epoch: 6| Step: 12
Training loss: 3.399681407363023
Validation loss: 3.073720568159989

Epoch: 6| Step: 13
Training loss: 3.09787898567712
Validation loss: 3.067501595500536

Epoch: 166| Step: 0
Training loss: 3.253294228907639
Validation loss: 3.066573513786603

Epoch: 6| Step: 1
Training loss: 3.4533391687596726
Validation loss: 3.0669951490585485

Epoch: 6| Step: 2
Training loss: 2.415236400620057
Validation loss: 3.0657154971836142

Epoch: 6| Step: 3
Training loss: 2.4226893870803936
Validation loss: 3.069981615813744

Epoch: 6| Step: 4
Training loss: 3.0603432359362444
Validation loss: 3.0766143464980265

Epoch: 6| Step: 5
Training loss: 4.083677056825547
Validation loss: 3.0806259140605707

Epoch: 6| Step: 6
Training loss: 2.98813635780268
Validation loss: 3.0825692876167374

Epoch: 6| Step: 7
Training loss: 3.597944382717433
Validation loss: 3.0730579413963457

Epoch: 6| Step: 8
Training loss: 3.568817827478727
Validation loss: 3.074110624199547

Epoch: 6| Step: 9
Training loss: 3.716202576633326
Validation loss: 3.068345181347131

Epoch: 6| Step: 10
Training loss: 3.5085790939211816
Validation loss: 3.06582852150327

Epoch: 6| Step: 11
Training loss: 3.295703263897117
Validation loss: 3.061869890669391

Epoch: 6| Step: 12
Training loss: 3.4948379051155185
Validation loss: 3.0651894931973063

Epoch: 6| Step: 13
Training loss: 3.4437272972840174
Validation loss: 3.0646585504783888

Epoch: 167| Step: 0
Training loss: 4.005252250890288
Validation loss: 3.0641653770142354

Epoch: 6| Step: 1
Training loss: 2.9237312499607535
Validation loss: 3.063829306360855

Epoch: 6| Step: 2
Training loss: 2.5653712306280037
Validation loss: 3.0656234675310303

Epoch: 6| Step: 3
Training loss: 3.9980181314229943
Validation loss: 3.063945876800122

Epoch: 6| Step: 4
Training loss: 2.950224567206409
Validation loss: 3.063675153328676

Epoch: 6| Step: 5
Training loss: 2.987553366978477
Validation loss: 3.06289420354284

Epoch: 6| Step: 6
Training loss: 3.5232721192652154
Validation loss: 3.06330981753292

Epoch: 6| Step: 7
Training loss: 3.4798602632990026
Validation loss: 3.0620608279614894

Epoch: 6| Step: 8
Training loss: 3.4805519102631726
Validation loss: 3.061496100460924

Epoch: 6| Step: 9
Training loss: 2.942907510053949
Validation loss: 3.0635288419777704

Epoch: 6| Step: 10
Training loss: 3.799998313501887
Validation loss: 3.0646513229583094

Epoch: 6| Step: 11
Training loss: 2.996108392035604
Validation loss: 3.0637449036728097

Epoch: 6| Step: 12
Training loss: 2.9777662991860794
Validation loss: 3.0633719171809686

Epoch: 6| Step: 13
Training loss: 3.746391976650655
Validation loss: 3.065568181846314

Epoch: 168| Step: 0
Training loss: 3.3486191423058678
Validation loss: 3.0653481949796078

Epoch: 6| Step: 1
Training loss: 3.6733896580951217
Validation loss: 3.065194315718168

Epoch: 6| Step: 2
Training loss: 4.276086965763153
Validation loss: 3.0647811697856486

Epoch: 6| Step: 3
Training loss: 2.4317476915435017
Validation loss: 3.064826710986154

Epoch: 6| Step: 4
Training loss: 3.1072966564179754
Validation loss: 3.0663415464502544

Epoch: 6| Step: 5
Training loss: 3.0558677012980966
Validation loss: 3.069088552010256

Epoch: 6| Step: 6
Training loss: 2.7482237714863835
Validation loss: 3.0661331919438273

Epoch: 6| Step: 7
Training loss: 3.599913113923086
Validation loss: 3.0633086542613697

Epoch: 6| Step: 8
Training loss: 3.8011051679000576
Validation loss: 3.0689696182551307

Epoch: 6| Step: 9
Training loss: 3.057658514123063
Validation loss: 3.068495990982341

Epoch: 6| Step: 10
Training loss: 3.201395898582818
Validation loss: 3.066919581210542

Epoch: 6| Step: 11
Training loss: 3.451423467458201
Validation loss: 3.06354782950123

Epoch: 6| Step: 12
Training loss: 2.917232313256323
Validation loss: 3.061509088222662

Epoch: 6| Step: 13
Training loss: 3.5765721312226972
Validation loss: 3.0601051732674573

Epoch: 169| Step: 0
Training loss: 3.3932948697751257
Validation loss: 3.060880680330848

Epoch: 6| Step: 1
Training loss: 2.961447800116514
Validation loss: 3.060986186361988

Epoch: 6| Step: 2
Training loss: 3.8321264412632075
Validation loss: 3.05952097100942

Epoch: 6| Step: 3
Training loss: 3.7641076794260884
Validation loss: 3.0590787792244996

Epoch: 6| Step: 4
Training loss: 2.866443339971095
Validation loss: 3.060496108486916

Epoch: 6| Step: 5
Training loss: 3.4122720383737266
Validation loss: 3.058727453790987

Epoch: 6| Step: 6
Training loss: 2.8115477751367166
Validation loss: 3.059211953147012

Epoch: 6| Step: 7
Training loss: 3.0164581887161077
Validation loss: 3.0577709441933574

Epoch: 6| Step: 8
Training loss: 3.9791946543296794
Validation loss: 3.058405918993358

Epoch: 6| Step: 9
Training loss: 3.417093637971319
Validation loss: 3.06139693612072

Epoch: 6| Step: 10
Training loss: 3.782857253807702
Validation loss: 3.058962521965442

Epoch: 6| Step: 11
Training loss: 2.8751894017732704
Validation loss: 3.0600959461399793

Epoch: 6| Step: 12
Training loss: 2.982948161857347
Validation loss: 3.0582263267832905

Epoch: 6| Step: 13
Training loss: 2.9226194035242505
Validation loss: 3.0593299858137466

Epoch: 170| Step: 0
Training loss: 2.673470182681675
Validation loss: 3.0619747020246812

Epoch: 6| Step: 1
Training loss: 2.216259808117915
Validation loss: 3.058493485713747

Epoch: 6| Step: 2
Training loss: 2.384180595502152
Validation loss: 3.06192413501045

Epoch: 6| Step: 3
Training loss: 3.903495733095331
Validation loss: 3.0667589344168

Epoch: 6| Step: 4
Training loss: 3.208138761358958
Validation loss: 3.0734969275171133

Epoch: 6| Step: 5
Training loss: 3.5887513267862756
Validation loss: 3.0715508703234455

Epoch: 6| Step: 6
Training loss: 4.000223391970621
Validation loss: 3.0809833037368906

Epoch: 6| Step: 7
Training loss: 3.6881591724958183
Validation loss: 3.0671900066131688

Epoch: 6| Step: 8
Training loss: 3.3555056977375
Validation loss: 3.056503338210647

Epoch: 6| Step: 9
Training loss: 3.49542072999974
Validation loss: 3.0580230043331835

Epoch: 6| Step: 10
Training loss: 2.749262797638843
Validation loss: 3.056470684679581

Epoch: 6| Step: 11
Training loss: 4.020945545798325
Validation loss: 3.0566841739625485

Epoch: 6| Step: 12
Training loss: 3.255130532924441
Validation loss: 3.0569362415263677

Epoch: 6| Step: 13
Training loss: 3.2657482361241574
Validation loss: 3.059088351340695

Epoch: 171| Step: 0
Training loss: 3.6263704011555347
Validation loss: 3.059214487278739

Epoch: 6| Step: 1
Training loss: 3.346936570285965
Validation loss: 3.060386095570242

Epoch: 6| Step: 2
Training loss: 2.971044517026926
Validation loss: 3.0664889985266055

Epoch: 6| Step: 3
Training loss: 3.628119080478725
Validation loss: 3.071756371961876

Epoch: 6| Step: 4
Training loss: 3.2986675288857907
Validation loss: 3.058134862694172

Epoch: 6| Step: 5
Training loss: 3.182149547810239
Validation loss: 3.0569618607488227

Epoch: 6| Step: 6
Training loss: 3.2710234633338637
Validation loss: 3.057004166505368

Epoch: 6| Step: 7
Training loss: 2.675026000422387
Validation loss: 3.055350180653831

Epoch: 6| Step: 8
Training loss: 3.072445349459456
Validation loss: 3.056172872335517

Epoch: 6| Step: 9
Training loss: 3.9550343602902696
Validation loss: 3.0579885939362006

Epoch: 6| Step: 10
Training loss: 3.325724134252701
Validation loss: 3.057747871289024

Epoch: 6| Step: 11
Training loss: 3.946770426979975
Validation loss: 3.056856973123149

Epoch: 6| Step: 12
Training loss: 2.6369447964447548
Validation loss: 3.061853442271073

Epoch: 6| Step: 13
Training loss: 3.294389411490915
Validation loss: 3.0569626616343415

Epoch: 172| Step: 0
Training loss: 3.1984146840409653
Validation loss: 3.0590578498582195

Epoch: 6| Step: 1
Training loss: 4.210402757312438
Validation loss: 3.0601251672363126

Epoch: 6| Step: 2
Training loss: 3.0139788151776785
Validation loss: 3.0563295527619876

Epoch: 6| Step: 3
Training loss: 3.431742892969586
Validation loss: 3.054037915018625

Epoch: 6| Step: 4
Training loss: 3.158853646718879
Validation loss: 3.0515661078900624

Epoch: 6| Step: 5
Training loss: 2.997870961349624
Validation loss: 3.052088792535562

Epoch: 6| Step: 6
Training loss: 3.642210390075473
Validation loss: 3.0511878063102387

Epoch: 6| Step: 7
Training loss: 2.851083041081251
Validation loss: 3.0503824471318093

Epoch: 6| Step: 8
Training loss: 2.831195323828775
Validation loss: 3.048758226788094

Epoch: 6| Step: 9
Training loss: 3.064993641085975
Validation loss: 3.0511083305854845

Epoch: 6| Step: 10
Training loss: 3.9031684622623968
Validation loss: 3.050545838807749

Epoch: 6| Step: 11
Training loss: 3.315284422443537
Validation loss: 3.051443051643995

Epoch: 6| Step: 12
Training loss: 2.3880791166480657
Validation loss: 3.0495686082591074

Epoch: 6| Step: 13
Training loss: 4.404848349274075
Validation loss: 3.050124288951951

Epoch: 173| Step: 0
Training loss: 2.7379552453941334
Validation loss: 3.049067291800937

Epoch: 6| Step: 1
Training loss: 3.5612193700317394
Validation loss: 3.0494384264099264

Epoch: 6| Step: 2
Training loss: 3.8510707208543296
Validation loss: 3.0487541838330836

Epoch: 6| Step: 3
Training loss: 3.0624370957745684
Validation loss: 3.0494036753383162

Epoch: 6| Step: 4
Training loss: 3.2935835331176926
Validation loss: 3.0491044244466856

Epoch: 6| Step: 5
Training loss: 3.0791692366393586
Validation loss: 3.049733148941344

Epoch: 6| Step: 6
Training loss: 3.711623857168785
Validation loss: 3.049348549991275

Epoch: 6| Step: 7
Training loss: 3.4246569607877904
Validation loss: 3.049158335091087

Epoch: 6| Step: 8
Training loss: 3.4260632389108934
Validation loss: 3.0473429928106213

Epoch: 6| Step: 9
Training loss: 2.990885717812394
Validation loss: 3.048132150689287

Epoch: 6| Step: 10
Training loss: 3.0274061233493863
Validation loss: 3.0490670202241295

Epoch: 6| Step: 11
Training loss: 3.2268347082701756
Validation loss: 3.054434887630708

Epoch: 6| Step: 12
Training loss: 3.5802113143528165
Validation loss: 3.0613193961113114

Epoch: 6| Step: 13
Training loss: 3.2525541099603883
Validation loss: 3.0838964763391634

Epoch: 174| Step: 0
Training loss: 3.1264123395389305
Validation loss: 3.087281804958124

Epoch: 6| Step: 1
Training loss: 3.2990504314710996
Validation loss: 3.0702646212046427

Epoch: 6| Step: 2
Training loss: 3.0033814129242766
Validation loss: 3.0578323363865922

Epoch: 6| Step: 3
Training loss: 3.5208023942720383
Validation loss: 3.0539215380564415

Epoch: 6| Step: 4
Training loss: 3.050845801223693
Validation loss: 3.048968723805953

Epoch: 6| Step: 5
Training loss: 3.986422143749795
Validation loss: 3.047162053648358

Epoch: 6| Step: 6
Training loss: 4.0733626463772366
Validation loss: 3.046217370719842

Epoch: 6| Step: 7
Training loss: 2.526336799500755
Validation loss: 3.0464104983286324

Epoch: 6| Step: 8
Training loss: 3.2184332534342737
Validation loss: 3.047915097464458

Epoch: 6| Step: 9
Training loss: 3.4518551800386934
Validation loss: 3.046861268321001

Epoch: 6| Step: 10
Training loss: 3.2225088744710884
Validation loss: 3.04731481095024

Epoch: 6| Step: 11
Training loss: 2.7633204799517292
Validation loss: 3.046269304280654

Epoch: 6| Step: 12
Training loss: 3.25761665469111
Validation loss: 3.045091106914083

Epoch: 6| Step: 13
Training loss: 3.7037991582084606
Validation loss: 3.0467564040442117

Epoch: 175| Step: 0
Training loss: 3.523958493303293
Validation loss: 3.0465080635569417

Epoch: 6| Step: 1
Training loss: 2.858424961708589
Validation loss: 3.0483048459344286

Epoch: 6| Step: 2
Training loss: 3.3497614078106834
Validation loss: 3.0457565976912395

Epoch: 6| Step: 3
Training loss: 3.7093069248653454
Validation loss: 3.048669880945326

Epoch: 6| Step: 4
Training loss: 2.646966666443716
Validation loss: 3.045567634900369

Epoch: 6| Step: 5
Training loss: 2.3826157785726223
Validation loss: 3.0539555577653403

Epoch: 6| Step: 6
Training loss: 3.7928661642924304
Validation loss: 3.0493032450710373

Epoch: 6| Step: 7
Training loss: 3.4546062347778106
Validation loss: 3.0485825239974913

Epoch: 6| Step: 8
Training loss: 3.8156397663802366
Validation loss: 3.054584527140204

Epoch: 6| Step: 9
Training loss: 3.125606325456454
Validation loss: 3.0462119298896275

Epoch: 6| Step: 10
Training loss: 3.695934412683933
Validation loss: 3.0435749281973985

Epoch: 6| Step: 11
Training loss: 3.5805706345114303
Validation loss: 3.043681764373689

Epoch: 6| Step: 12
Training loss: 2.1476352372846645
Validation loss: 3.0444572269069656

Epoch: 6| Step: 13
Training loss: 3.8934211947268613
Validation loss: 3.041210595221637

Epoch: 176| Step: 0
Training loss: 2.738202887051867
Validation loss: 3.0409943453844663

Epoch: 6| Step: 1
Training loss: 3.4139886145376748
Validation loss: 3.042315392139918

Epoch: 6| Step: 2
Training loss: 3.43009261604031
Validation loss: 3.0415905600036433

Epoch: 6| Step: 3
Training loss: 2.6724326460855417
Validation loss: 3.0412070126091284

Epoch: 6| Step: 4
Training loss: 3.371044525458979
Validation loss: 3.042750710021804

Epoch: 6| Step: 5
Training loss: 3.9038563222633447
Validation loss: 3.04050410415796

Epoch: 6| Step: 6
Training loss: 3.699683541863618
Validation loss: 3.041718628479275

Epoch: 6| Step: 7
Training loss: 3.0602860525229665
Validation loss: 3.041872212849162

Epoch: 6| Step: 8
Training loss: 2.258388775734976
Validation loss: 3.0436716847593734

Epoch: 6| Step: 9
Training loss: 3.4633929151367076
Validation loss: 3.041994792440882

Epoch: 6| Step: 10
Training loss: 4.006787025772328
Validation loss: 3.0421344194015405

Epoch: 6| Step: 11
Training loss: 2.966576834900894
Validation loss: 3.040288968560191

Epoch: 6| Step: 12
Training loss: 3.35616386771898
Validation loss: 3.0421119551671185

Epoch: 6| Step: 13
Training loss: 3.603593299256018
Validation loss: 3.0413492862877725

Epoch: 177| Step: 0
Training loss: 2.904370592383629
Validation loss: 3.04191013956948

Epoch: 6| Step: 1
Training loss: 3.1261376408241275
Validation loss: 3.0463849612039278

Epoch: 6| Step: 2
Training loss: 3.2463731335659594
Validation loss: 3.04627874244331

Epoch: 6| Step: 3
Training loss: 3.2960652446214955
Validation loss: 3.0433213900543006

Epoch: 6| Step: 4
Training loss: 3.877190001815834
Validation loss: 3.041811717226138

Epoch: 6| Step: 5
Training loss: 3.731472275852922
Validation loss: 3.0427061393041153

Epoch: 6| Step: 6
Training loss: 2.891695391450918
Validation loss: 3.0421968821971266

Epoch: 6| Step: 7
Training loss: 3.578988716459434
Validation loss: 3.04147942326733

Epoch: 6| Step: 8
Training loss: 2.8866340098248076
Validation loss: 3.041080389413898

Epoch: 6| Step: 9
Training loss: 3.1946513417640072
Validation loss: 3.0392451841014454

Epoch: 6| Step: 10
Training loss: 2.6522786690054883
Validation loss: 3.0375413608338757

Epoch: 6| Step: 11
Training loss: 3.9169996133608866
Validation loss: 3.039140940222595

Epoch: 6| Step: 12
Training loss: 3.744253460333545
Validation loss: 3.0383945659742846

Epoch: 6| Step: 13
Training loss: 2.5227442872819417
Validation loss: 3.0387250931925753

Epoch: 178| Step: 0
Training loss: 3.5176872477955206
Validation loss: 3.0392080819873333

Epoch: 6| Step: 1
Training loss: 3.3502672800507005
Validation loss: 3.04270318362739

Epoch: 6| Step: 2
Training loss: 2.5858923225259653
Validation loss: 3.040021506796355

Epoch: 6| Step: 3
Training loss: 3.6234278722769218
Validation loss: 3.0417550299318874

Epoch: 6| Step: 4
Training loss: 3.265712755110155
Validation loss: 3.0402988806267275

Epoch: 6| Step: 5
Training loss: 3.349053998008929
Validation loss: 3.04160395136318

Epoch: 6| Step: 6
Training loss: 2.7971271422548822
Validation loss: 3.0404332675208083

Epoch: 6| Step: 7
Training loss: 3.7221967607705952
Validation loss: 3.0446906569481373

Epoch: 6| Step: 8
Training loss: 3.7030340899804877
Validation loss: 3.040633596064077

Epoch: 6| Step: 9
Training loss: 3.6328157814585316
Validation loss: 3.0371366344197055

Epoch: 6| Step: 10
Training loss: 2.7599149044021294
Validation loss: 3.0370193413761006

Epoch: 6| Step: 11
Training loss: 3.1334005740911652
Validation loss: 3.037493213615768

Epoch: 6| Step: 12
Training loss: 3.21130190821086
Validation loss: 3.035189437753394

Epoch: 6| Step: 13
Training loss: 3.4109986128948235
Validation loss: 3.03720411929654

Epoch: 179| Step: 0
Training loss: 3.543441253076092
Validation loss: 3.036076296134392

Epoch: 6| Step: 1
Training loss: 3.5479944285937135
Validation loss: 3.0357895639898813

Epoch: 6| Step: 2
Training loss: 3.245057529356829
Validation loss: 3.034558892854048

Epoch: 6| Step: 3
Training loss: 2.975563342187348
Validation loss: 3.0357463706059873

Epoch: 6| Step: 4
Training loss: 3.20144713581651
Validation loss: 3.0341583700807595

Epoch: 6| Step: 5
Training loss: 3.5328937856913507
Validation loss: 3.0325714113389206

Epoch: 6| Step: 6
Training loss: 3.163718574575844
Validation loss: 3.033677399828742

Epoch: 6| Step: 7
Training loss: 3.7596994210892016
Validation loss: 3.0336185830547673

Epoch: 6| Step: 8
Training loss: 3.5079731723886147
Validation loss: 3.0325632095617134

Epoch: 6| Step: 9
Training loss: 2.6646445972437602
Validation loss: 3.032351032645859

Epoch: 6| Step: 10
Training loss: 2.959591844100634
Validation loss: 3.033952936160301

Epoch: 6| Step: 11
Training loss: 3.4904338350602773
Validation loss: 3.0314688240433925

Epoch: 6| Step: 12
Training loss: 3.620930195790591
Validation loss: 3.031992848439302

Epoch: 6| Step: 13
Training loss: 2.339501765101094
Validation loss: 3.0321766813611206

Epoch: 180| Step: 0
Training loss: 3.3482105770998807
Validation loss: 3.034816260719875

Epoch: 6| Step: 1
Training loss: 2.849807157182725
Validation loss: 3.031863296961104

Epoch: 6| Step: 2
Training loss: 3.2834099336263707
Validation loss: 3.0361917139775714

Epoch: 6| Step: 3
Training loss: 4.101891727858051
Validation loss: 3.035690053103911

Epoch: 6| Step: 4
Training loss: 2.7557022623092093
Validation loss: 3.0415938117629087

Epoch: 6| Step: 5
Training loss: 3.719904359798101
Validation loss: 3.0428580073448406

Epoch: 6| Step: 6
Training loss: 3.4183924123592786
Validation loss: 3.0391816171947554

Epoch: 6| Step: 7
Training loss: 3.982554180497504
Validation loss: 3.0363055164542208

Epoch: 6| Step: 8
Training loss: 2.7142978915321416
Validation loss: 3.042450478659244

Epoch: 6| Step: 9
Training loss: 2.852652730639244
Validation loss: 3.031426956869181

Epoch: 6| Step: 10
Training loss: 2.714158488999079
Validation loss: 3.033538407870662

Epoch: 6| Step: 11
Training loss: 3.542925143578121
Validation loss: 3.031387285397351

Epoch: 6| Step: 12
Training loss: 2.9766871308594753
Validation loss: 3.0292659601461103

Epoch: 6| Step: 13
Training loss: 3.606645220647524
Validation loss: 3.030269220984864

Epoch: 181| Step: 0
Training loss: 3.688247992735902
Validation loss: 3.030335926514067

Epoch: 6| Step: 1
Training loss: 3.2484558545319304
Validation loss: 3.028795288439929

Epoch: 6| Step: 2
Training loss: 2.7168554961998708
Validation loss: 3.0278188274855085

Epoch: 6| Step: 3
Training loss: 3.0866998044810576
Validation loss: 3.029930241856406

Epoch: 6| Step: 4
Training loss: 2.8250790205174736
Validation loss: 3.0278534198800524

Epoch: 6| Step: 5
Training loss: 3.9590115953214444
Validation loss: 3.027276333241166

Epoch: 6| Step: 6
Training loss: 3.283245823915533
Validation loss: 3.0285097047036675

Epoch: 6| Step: 7
Training loss: 3.049246310305726
Validation loss: 3.0284893225510725

Epoch: 6| Step: 8
Training loss: 3.9052560991425564
Validation loss: 3.026719059845972

Epoch: 6| Step: 9
Training loss: 3.3543578541606935
Validation loss: 3.0279257954145664

Epoch: 6| Step: 10
Training loss: 3.3182424038573246
Validation loss: 3.027003197438205

Epoch: 6| Step: 11
Training loss: 3.2382978892157706
Validation loss: 3.029958566797758

Epoch: 6| Step: 12
Training loss: 3.391883440768099
Validation loss: 3.0290633428323757

Epoch: 6| Step: 13
Training loss: 2.417271527418479
Validation loss: 3.027222788309753

Epoch: 182| Step: 0
Training loss: 3.544623244136264
Validation loss: 3.027028068096317

Epoch: 6| Step: 1
Training loss: 3.0748028327564594
Validation loss: 3.029603714688669

Epoch: 6| Step: 2
Training loss: 3.7472618278771286
Validation loss: 3.0305253078000054

Epoch: 6| Step: 3
Training loss: 3.4920484954682616
Validation loss: 3.032458206762694

Epoch: 6| Step: 4
Training loss: 3.349876424303659
Validation loss: 3.0407656690584797

Epoch: 6| Step: 5
Training loss: 3.1924373310483167
Validation loss: 3.042288566750282

Epoch: 6| Step: 6
Training loss: 3.422334823022017
Validation loss: 3.035735611854898

Epoch: 6| Step: 7
Training loss: 3.1129145579806856
Validation loss: 3.0397173995760425

Epoch: 6| Step: 8
Training loss: 3.03789884358418
Validation loss: 3.0266377972710488

Epoch: 6| Step: 9
Training loss: 3.429080848655186
Validation loss: 3.017817783127648

Epoch: 6| Step: 10
Training loss: 3.477700722206041
Validation loss: 3.016119422785422

Epoch: 6| Step: 11
Training loss: 3.1766099587576258
Validation loss: 3.0228835693315093

Epoch: 6| Step: 12
Training loss: 2.8424961553730457
Validation loss: 3.024649416565356

Epoch: 6| Step: 13
Training loss: 2.991916574508447
Validation loss: 3.0141796397561875

Epoch: 183| Step: 0
Training loss: 2.77909270211489
Validation loss: 3.0149604770365914

Epoch: 6| Step: 1
Training loss: 4.14010259823664
Validation loss: 3.0142250048145334

Epoch: 6| Step: 2
Training loss: 3.828572398919672
Validation loss: 3.016716123540493

Epoch: 6| Step: 3
Training loss: 3.733848119620763
Validation loss: 3.0168070630684745

Epoch: 6| Step: 4
Training loss: 2.799322325578623
Validation loss: 3.0153400588954558

Epoch: 6| Step: 5
Training loss: 3.3559375297815643
Validation loss: 3.013069063886295

Epoch: 6| Step: 6
Training loss: 2.5294572109231
Validation loss: 3.018500848569351

Epoch: 6| Step: 7
Training loss: 3.091125916714393
Validation loss: 3.014505082229927

Epoch: 6| Step: 8
Training loss: 2.8298048225738652
Validation loss: 3.016294942760461

Epoch: 6| Step: 9
Training loss: 4.161630002309558
Validation loss: 3.0200984333895424

Epoch: 6| Step: 10
Training loss: 2.6397855428807744
Validation loss: 3.01623638114049

Epoch: 6| Step: 11
Training loss: 3.583722928772871
Validation loss: 3.013976547521227

Epoch: 6| Step: 12
Training loss: 3.206181254402811
Validation loss: 3.010137898840964

Epoch: 6| Step: 13
Training loss: 2.2401846736326805
Validation loss: 3.011863118012094

Epoch: 184| Step: 0
Training loss: 3.6550540109132275
Validation loss: 3.01259757382471

Epoch: 6| Step: 1
Training loss: 3.405111420050596
Validation loss: 3.011394791610869

Epoch: 6| Step: 2
Training loss: 2.3546481245022934
Validation loss: 3.013033832084493

Epoch: 6| Step: 3
Training loss: 3.2938788662046288
Validation loss: 3.006336150598818

Epoch: 6| Step: 4
Training loss: 3.168359922818887
Validation loss: 3.008197007987567

Epoch: 6| Step: 5
Training loss: 3.247002613251025
Validation loss: 3.0055800673452393

Epoch: 6| Step: 6
Training loss: 3.4206075193438377
Validation loss: 3.0054515524731116

Epoch: 6| Step: 7
Training loss: 3.195031337912688
Validation loss: 3.0079401469382803

Epoch: 6| Step: 8
Training loss: 4.167885462206732
Validation loss: 3.0059344275993847

Epoch: 6| Step: 9
Training loss: 3.4210937165484414
Validation loss: 3.0092386807359586

Epoch: 6| Step: 10
Training loss: 3.6271641289339387
Validation loss: 3.0082416877584532

Epoch: 6| Step: 11
Training loss: 2.4969004490096123
Validation loss: 3.0065936466426337

Epoch: 6| Step: 12
Training loss: 2.9592206098974763
Validation loss: 3.006148738510281

Epoch: 6| Step: 13
Training loss: 2.9945019568033873
Validation loss: 3.0071347825523724

Epoch: 185| Step: 0
Training loss: 2.738924263894869
Validation loss: 3.0106399813243376

Epoch: 6| Step: 1
Training loss: 3.061907652575497
Validation loss: 3.0034835118776617

Epoch: 6| Step: 2
Training loss: 3.1883596121354296
Validation loss: 3.0075221270598798

Epoch: 6| Step: 3
Training loss: 2.7966976002955306
Validation loss: 3.0070171479244956

Epoch: 6| Step: 4
Training loss: 3.6905011394495357
Validation loss: 3.0042836906270773

Epoch: 6| Step: 5
Training loss: 3.3569815692594527
Validation loss: 3.004530333374032

Epoch: 6| Step: 6
Training loss: 3.3846734898921507
Validation loss: 3.003316821470097

Epoch: 6| Step: 7
Training loss: 3.1499704268747584
Validation loss: 3.0052733433576893

Epoch: 6| Step: 8
Training loss: 2.2874286536258275
Validation loss: 3.003704351067606

Epoch: 6| Step: 9
Training loss: 3.130696864202886
Validation loss: 3.0040787278037597

Epoch: 6| Step: 10
Training loss: 3.685862161303831
Validation loss: 3.0024022257140093

Epoch: 6| Step: 11
Training loss: 3.536377821142994
Validation loss: 3.0032125921586394

Epoch: 6| Step: 12
Training loss: 3.8269002395438023
Validation loss: 3.0058845024777976

Epoch: 6| Step: 13
Training loss: 3.9749500775351234
Validation loss: 3.001994486910052

Epoch: 186| Step: 0
Training loss: 2.7529285616295587
Validation loss: 3.0029894758532505

Epoch: 6| Step: 1
Training loss: 3.3274700254584872
Validation loss: 3.0014159303259365

Epoch: 6| Step: 2
Training loss: 3.3728673342670077
Validation loss: 3.001356683768776

Epoch: 6| Step: 3
Training loss: 3.546813157672596
Validation loss: 3.0016958338451474

Epoch: 6| Step: 4
Training loss: 2.852417031367854
Validation loss: 3.0019526228533118

Epoch: 6| Step: 5
Training loss: 3.625623452078244
Validation loss: 3.001849154932041

Epoch: 6| Step: 6
Training loss: 3.049773886381848
Validation loss: 2.9994672657750465

Epoch: 6| Step: 7
Training loss: 3.0129928565587933
Validation loss: 3.0006425709455207

Epoch: 6| Step: 8
Training loss: 3.8539261751493084
Validation loss: 3.0030772720994734

Epoch: 6| Step: 9
Training loss: 3.356616923984243
Validation loss: 3.0013309657369875

Epoch: 6| Step: 10
Training loss: 3.0610224993881134
Validation loss: 3.000995766401094

Epoch: 6| Step: 11
Training loss: 3.514436512435381
Validation loss: 3.001559724542912

Epoch: 6| Step: 12
Training loss: 3.2950746945147755
Validation loss: 3.0031292243731382

Epoch: 6| Step: 13
Training loss: 2.839961620125205
Validation loss: 3.00201165781928

Epoch: 187| Step: 0
Training loss: 3.6871898973322836
Validation loss: 2.9999376174292722

Epoch: 6| Step: 1
Training loss: 3.6288214962098895
Validation loss: 3.000170087607252

Epoch: 6| Step: 2
Training loss: 3.749785226393585
Validation loss: 3.002488112872543

Epoch: 6| Step: 3
Training loss: 2.423980683498404
Validation loss: 3.0005447856971768

Epoch: 6| Step: 4
Training loss: 3.8059358213449013
Validation loss: 3.0006628996108686

Epoch: 6| Step: 5
Training loss: 3.0317358827020833
Validation loss: 3.0027293348234525

Epoch: 6| Step: 6
Training loss: 3.0543955787822523
Validation loss: 2.999829177197411

Epoch: 6| Step: 7
Training loss: 3.126991247913298
Validation loss: 2.9997361487574437

Epoch: 6| Step: 8
Training loss: 3.320500626563823
Validation loss: 2.9984855538010105

Epoch: 6| Step: 9
Training loss: 3.140033723200583
Validation loss: 2.9995083816267054

Epoch: 6| Step: 10
Training loss: 3.2095974170016452
Validation loss: 2.9968275366412604

Epoch: 6| Step: 11
Training loss: 2.8880362801214687
Validation loss: 3.0005681181900776

Epoch: 6| Step: 12
Training loss: 2.6989796335215845
Validation loss: 2.9985284272455996

Epoch: 6| Step: 13
Training loss: 3.970245800336283
Validation loss: 2.9977612106169436

Epoch: 188| Step: 0
Training loss: 3.4282149714275247
Validation loss: 2.9969330769680886

Epoch: 6| Step: 1
Training loss: 3.1996821066789227
Validation loss: 2.997006267638679

Epoch: 6| Step: 2
Training loss: 4.117275751025835
Validation loss: 2.9967712097628203

Epoch: 6| Step: 3
Training loss: 2.2999141594168324
Validation loss: 2.9981740039752447

Epoch: 6| Step: 4
Training loss: 3.4582169907698135
Validation loss: 2.9964342888671207

Epoch: 6| Step: 5
Training loss: 2.954678404424376
Validation loss: 2.9964243095546172

Epoch: 6| Step: 6
Training loss: 3.514448587894426
Validation loss: 2.997294872711828

Epoch: 6| Step: 7
Training loss: 2.8421821044736446
Validation loss: 2.994828872485219

Epoch: 6| Step: 8
Training loss: 2.987094458982636
Validation loss: 2.995610939449653

Epoch: 6| Step: 9
Training loss: 3.71865408637471
Validation loss: 2.9953120461759286

Epoch: 6| Step: 10
Training loss: 2.9495097642016876
Validation loss: 2.9957993077086122

Epoch: 6| Step: 11
Training loss: 3.0380146799341845
Validation loss: 2.9951476707923925

Epoch: 6| Step: 12
Training loss: 3.7328775507998033
Validation loss: 2.9948669566801853

Epoch: 6| Step: 13
Training loss: 3.0036747995806308
Validation loss: 2.995786765881893

Epoch: 189| Step: 0
Training loss: 3.143906733888841
Validation loss: 2.9966366964424282

Epoch: 6| Step: 1
Training loss: 2.920715101808565
Validation loss: 2.997305463242162

Epoch: 6| Step: 2
Training loss: 3.399996836043737
Validation loss: 2.9953897337888433

Epoch: 6| Step: 3
Training loss: 2.9945409697492598
Validation loss: 2.992928784239781

Epoch: 6| Step: 4
Training loss: 3.3490080090640855
Validation loss: 2.995534528467691

Epoch: 6| Step: 5
Training loss: 3.0763554012713876
Validation loss: 2.996917805946664

Epoch: 6| Step: 6
Training loss: 3.018752931707945
Validation loss: 2.998944325808969

Epoch: 6| Step: 7
Training loss: 3.519762105705685
Validation loss: 2.9991842300728706

Epoch: 6| Step: 8
Training loss: 3.722391989776106
Validation loss: 3.000102220865182

Epoch: 6| Step: 9
Training loss: 3.0493895498258197
Validation loss: 3.0019463716324073

Epoch: 6| Step: 10
Training loss: 3.887759950048256
Validation loss: 3.002748477996443

Epoch: 6| Step: 11
Training loss: 3.462425721401212
Validation loss: 3.0026238138105894

Epoch: 6| Step: 12
Training loss: 2.8902300590630365
Validation loss: 2.99715117667734

Epoch: 6| Step: 13
Training loss: 3.014986909550073
Validation loss: 2.996214246895794

Epoch: 190| Step: 0
Training loss: 3.2681704005496424
Validation loss: 2.9902479980648824

Epoch: 6| Step: 1
Training loss: 3.1685102684332573
Validation loss: 2.9931329371813935

Epoch: 6| Step: 2
Training loss: 2.271031525621926
Validation loss: 2.9910338109786725

Epoch: 6| Step: 3
Training loss: 2.6896254540377575
Validation loss: 2.992802462949184

Epoch: 6| Step: 4
Training loss: 3.620590685288851
Validation loss: 2.9927250987944065

Epoch: 6| Step: 5
Training loss: 3.0145519501889804
Validation loss: 2.992996749399843

Epoch: 6| Step: 6
Training loss: 3.3197927270095007
Validation loss: 2.993872076934879

Epoch: 6| Step: 7
Training loss: 3.582742568413678
Validation loss: 2.9910153162333244

Epoch: 6| Step: 8
Training loss: 3.4275390569352244
Validation loss: 2.9951758855788273

Epoch: 6| Step: 9
Training loss: 3.881376987413154
Validation loss: 2.992693572289247

Epoch: 6| Step: 10
Training loss: 3.598282849545326
Validation loss: 2.994011721852332

Epoch: 6| Step: 11
Training loss: 3.3324211938902275
Validation loss: 2.9920382361124243

Epoch: 6| Step: 12
Training loss: 3.454925481983594
Validation loss: 2.991402167549009

Epoch: 6| Step: 13
Training loss: 2.3865481251664193
Validation loss: 2.9913568891667737

Epoch: 191| Step: 0
Training loss: 2.6759236318756128
Validation loss: 2.991991150010939

Epoch: 6| Step: 1
Training loss: 3.2258670971922507
Validation loss: 2.992276949720742

Epoch: 6| Step: 2
Training loss: 3.4465080833722124
Validation loss: 2.99135992128775

Epoch: 6| Step: 3
Training loss: 3.2080507690712246
Validation loss: 2.990172655479985

Epoch: 6| Step: 4
Training loss: 3.2434703081564624
Validation loss: 2.98978110221626

Epoch: 6| Step: 5
Training loss: 3.8487672392709023
Validation loss: 2.9908237400111997

Epoch: 6| Step: 6
Training loss: 3.4092419284546818
Validation loss: 2.989414505452175

Epoch: 6| Step: 7
Training loss: 3.59812382446079
Validation loss: 2.9897936074986067

Epoch: 6| Step: 8
Training loss: 3.0911024691018096
Validation loss: 2.9900910795741877

Epoch: 6| Step: 9
Training loss: 2.8249259263851485
Validation loss: 2.992716425462179

Epoch: 6| Step: 10
Training loss: 3.494601855213959
Validation loss: 2.99113862151775

Epoch: 6| Step: 11
Training loss: 2.3221828744324013
Validation loss: 2.9919001999520756

Epoch: 6| Step: 12
Training loss: 3.294193858980068
Validation loss: 2.9911745208928253

Epoch: 6| Step: 13
Training loss: 4.004406885621794
Validation loss: 2.9919508091234155

Epoch: 192| Step: 0
Training loss: 3.2403091320866864
Validation loss: 2.990968592878516

Epoch: 6| Step: 1
Training loss: 3.137442879327833
Validation loss: 2.989917186955638

Epoch: 6| Step: 2
Training loss: 3.6183923152530766
Validation loss: 2.990932232463132

Epoch: 6| Step: 3
Training loss: 2.4860291162628685
Validation loss: 2.9937567239369387

Epoch: 6| Step: 4
Training loss: 3.288703953280346
Validation loss: 2.9959861529729475

Epoch: 6| Step: 5
Training loss: 3.3047371357826774
Validation loss: 2.9888282111775872

Epoch: 6| Step: 6
Training loss: 3.659037644027144
Validation loss: 2.988938789107678

Epoch: 6| Step: 7
Training loss: 3.337728336824232
Validation loss: 2.9899108822761806

Epoch: 6| Step: 8
Training loss: 3.052620659270375
Validation loss: 2.990031456859534

Epoch: 6| Step: 9
Training loss: 3.282664257626098
Validation loss: 2.988922405099476

Epoch: 6| Step: 10
Training loss: 3.4454962925750534
Validation loss: 2.988582984960862

Epoch: 6| Step: 11
Training loss: 3.1571733993552193
Validation loss: 2.9868345772326115

Epoch: 6| Step: 12
Training loss: 3.4612379783236995
Validation loss: 2.986774426870587

Epoch: 6| Step: 13
Training loss: 2.7906100043121382
Validation loss: 2.9916125569583345

Epoch: 193| Step: 0
Training loss: 3.222563179290523
Validation loss: 2.987404510870846

Epoch: 6| Step: 1
Training loss: 3.859482983765771
Validation loss: 2.990171423460039

Epoch: 6| Step: 2
Training loss: 3.9663951225192298
Validation loss: 2.987114673873071

Epoch: 6| Step: 3
Training loss: 3.022758151279306
Validation loss: 2.987683418853789

Epoch: 6| Step: 4
Training loss: 2.3000636382213786
Validation loss: 2.9890372953990467

Epoch: 6| Step: 5
Training loss: 2.902782381369445
Validation loss: 2.9878739986379896

Epoch: 6| Step: 6
Training loss: 3.014059184039454
Validation loss: 2.985145499021053

Epoch: 6| Step: 7
Training loss: 3.2643016707473658
Validation loss: 2.986019116951513

Epoch: 6| Step: 8
Training loss: 3.3271878494602167
Validation loss: 2.9846042965245694

Epoch: 6| Step: 9
Training loss: 2.193483398409457
Validation loss: 2.987916672566065

Epoch: 6| Step: 10
Training loss: 3.671252258736497
Validation loss: 2.9864090697310073

Epoch: 6| Step: 11
Training loss: 3.232730760826993
Validation loss: 2.9837876252816

Epoch: 6| Step: 12
Training loss: 3.241440578967558
Validation loss: 2.983303658406629

Epoch: 6| Step: 13
Training loss: 4.208938378881506
Validation loss: 2.985004392397268

Epoch: 194| Step: 0
Training loss: 2.957056083222178
Validation loss: 2.983825375275975

Epoch: 6| Step: 1
Training loss: 3.0988337814989184
Validation loss: 2.9833700950031794

Epoch: 6| Step: 2
Training loss: 3.329672869860955
Validation loss: 2.9856788618755443

Epoch: 6| Step: 3
Training loss: 2.819460922552187
Validation loss: 2.985383722137707

Epoch: 6| Step: 4
Training loss: 3.593721207213122
Validation loss: 2.9856251135988265

Epoch: 6| Step: 5
Training loss: 3.5497505530174176
Validation loss: 2.9823230401706216

Epoch: 6| Step: 6
Training loss: 3.3634221737498358
Validation loss: 2.9847784978122

Epoch: 6| Step: 7
Training loss: 3.4094658466267065
Validation loss: 2.982591258855041

Epoch: 6| Step: 8
Training loss: 2.8020189601684193
Validation loss: 2.981328683282055

Epoch: 6| Step: 9
Training loss: 3.7556035455074106
Validation loss: 2.982530376532449

Epoch: 6| Step: 10
Training loss: 3.2852548046955055
Validation loss: 2.981675432743126

Epoch: 6| Step: 11
Training loss: 3.4166865619607405
Validation loss: 2.9855688123661843

Epoch: 6| Step: 12
Training loss: 2.4593107144825463
Validation loss: 2.9848331425543835

Epoch: 6| Step: 13
Training loss: 3.6765470609004347
Validation loss: 2.981599618169843

Epoch: 195| Step: 0
Training loss: 3.0679105336897634
Validation loss: 2.983500044809554

Epoch: 6| Step: 1
Training loss: 2.2197196883142567
Validation loss: 2.985819343328353

Epoch: 6| Step: 2
Training loss: 3.261212301624893
Validation loss: 2.983973950291505

Epoch: 6| Step: 3
Training loss: 3.5115397813996836
Validation loss: 2.989597607078634

Epoch: 6| Step: 4
Training loss: 3.39251375109838
Validation loss: 2.9884809928730647

Epoch: 6| Step: 5
Training loss: 3.8850133173455337
Validation loss: 2.9849707505930967

Epoch: 6| Step: 6
Training loss: 3.9282118223999922
Validation loss: 2.981996323300277

Epoch: 6| Step: 7
Training loss: 3.7828886406541673
Validation loss: 2.980227709918959

Epoch: 6| Step: 8
Training loss: 2.8857707737057052
Validation loss: 2.9793609244871764

Epoch: 6| Step: 9
Training loss: 3.068659601997212
Validation loss: 2.9793032675026954

Epoch: 6| Step: 10
Training loss: 2.6894144735557757
Validation loss: 2.978736712748025

Epoch: 6| Step: 11
Training loss: 3.1358404200589804
Validation loss: 2.9799745632990198

Epoch: 6| Step: 12
Training loss: 3.208668150502452
Validation loss: 2.978079631007781

Epoch: 6| Step: 13
Training loss: 3.1103823769568573
Validation loss: 2.9787559292109065

Epoch: 196| Step: 0
Training loss: 3.178546522725654
Validation loss: 2.980457459691817

Epoch: 6| Step: 1
Training loss: 3.5650224288513095
Validation loss: 2.9785831332276675

Epoch: 6| Step: 2
Training loss: 3.279432974394342
Validation loss: 2.9801928305220633

Epoch: 6| Step: 3
Training loss: 3.312418810731147
Validation loss: 2.9769241543508733

Epoch: 6| Step: 4
Training loss: 2.6054945548408224
Validation loss: 2.9803670445079544

Epoch: 6| Step: 5
Training loss: 3.1556140523362877
Validation loss: 2.9778726252669796

Epoch: 6| Step: 6
Training loss: 2.896983149381068
Validation loss: 2.9786319142299114

Epoch: 6| Step: 7
Training loss: 3.2971662781391906
Validation loss: 2.979471450235364

Epoch: 6| Step: 8
Training loss: 3.277508591699578
Validation loss: 2.9803950259066037

Epoch: 6| Step: 9
Training loss: 3.014744130881196
Validation loss: 2.9805948938787243

Epoch: 6| Step: 10
Training loss: 3.6071868472944324
Validation loss: 2.984246056452393

Epoch: 6| Step: 11
Training loss: 3.916846467348356
Validation loss: 2.987372575512847

Epoch: 6| Step: 12
Training loss: 3.1669107309617774
Validation loss: 2.989476061395626

Epoch: 6| Step: 13
Training loss: 2.9655984312581762
Validation loss: 2.985945011322926

Epoch: 197| Step: 0
Training loss: 2.9339079301322113
Validation loss: 2.984345408299746

Epoch: 6| Step: 1
Training loss: 3.2675900912251006
Validation loss: 2.9851462255651073

Epoch: 6| Step: 2
Training loss: 3.3043387298873426
Validation loss: 2.9796271684993294

Epoch: 6| Step: 3
Training loss: 2.6746805196341854
Validation loss: 2.9766699189376395

Epoch: 6| Step: 4
Training loss: 2.948378204412535
Validation loss: 2.976619913799936

Epoch: 6| Step: 5
Training loss: 3.644866437309493
Validation loss: 2.9768583989159136

Epoch: 6| Step: 6
Training loss: 2.9755790467490772
Validation loss: 2.975800440543453

Epoch: 6| Step: 7
Training loss: 3.180775149416799
Validation loss: 2.9758331754942753

Epoch: 6| Step: 8
Training loss: 3.3617366562458852
Validation loss: 2.976095190301313

Epoch: 6| Step: 9
Training loss: 3.333116683277203
Validation loss: 2.9751339572809132

Epoch: 6| Step: 10
Training loss: 3.728120042489042
Validation loss: 2.9756872257341938

Epoch: 6| Step: 11
Training loss: 3.478486289618723
Validation loss: 2.9756071420962806

Epoch: 6| Step: 12
Training loss: 2.74910565485401
Validation loss: 2.975531529598618

Epoch: 6| Step: 13
Training loss: 4.068918644798429
Validation loss: 2.974986861584176

Epoch: 198| Step: 0
Training loss: 3.2848101965477015
Validation loss: 2.9745476475757955

Epoch: 6| Step: 1
Training loss: 3.6015950695890404
Validation loss: 2.9752111601798528

Epoch: 6| Step: 2
Training loss: 3.1478598090708356
Validation loss: 2.9790957728053393

Epoch: 6| Step: 3
Training loss: 3.2838609752337393
Validation loss: 2.974453067390135

Epoch: 6| Step: 4
Training loss: 3.433086544413867
Validation loss: 2.9750870060540033

Epoch: 6| Step: 5
Training loss: 2.917233620898636
Validation loss: 2.9749268620442906

Epoch: 6| Step: 6
Training loss: 3.1850594545860593
Validation loss: 2.9764914206603716

Epoch: 6| Step: 7
Training loss: 3.2093209237034555
Validation loss: 2.978870610050113

Epoch: 6| Step: 8
Training loss: 4.064476588711706
Validation loss: 2.978544199601553

Epoch: 6| Step: 9
Training loss: 2.839694978156937
Validation loss: 2.9856646044572024

Epoch: 6| Step: 10
Training loss: 2.6786643874976925
Validation loss: 2.9815341317976545

Epoch: 6| Step: 11
Training loss: 3.6182122972493347
Validation loss: 2.9823562055359076

Epoch: 6| Step: 12
Training loss: 3.389804582617913
Validation loss: 2.9774964464797584

Epoch: 6| Step: 13
Training loss: 1.806384523127592
Validation loss: 2.9809271222447573

Epoch: 199| Step: 0
Training loss: 3.905640821640046
Validation loss: 2.9726425583891856

Epoch: 6| Step: 1
Training loss: 2.986379858732732
Validation loss: 2.9744566321501344

Epoch: 6| Step: 2
Training loss: 3.8091941634104907
Validation loss: 2.975566752258872

Epoch: 6| Step: 3
Training loss: 3.3747362104394574
Validation loss: 2.9719430898258103

Epoch: 6| Step: 4
Training loss: 2.8149667730453958
Validation loss: 2.9703502554000405

Epoch: 6| Step: 5
Training loss: 3.1900678277054437
Validation loss: 2.970790498143363

Epoch: 6| Step: 6
Training loss: 2.946649141849286
Validation loss: 2.97192545276131

Epoch: 6| Step: 7
Training loss: 3.326058619346787
Validation loss: 2.9704385382223104

Epoch: 6| Step: 8
Training loss: 3.3882333785095287
Validation loss: 2.9725071584508624

Epoch: 6| Step: 9
Training loss: 3.2380977712081704
Validation loss: 2.9710081517918927

Epoch: 6| Step: 10
Training loss: 3.3558987396386093
Validation loss: 2.9730713597732645

Epoch: 6| Step: 11
Training loss: 2.985224577923686
Validation loss: 2.9723704327348384

Epoch: 6| Step: 12
Training loss: 3.186858168664338
Validation loss: 2.975210174432887

Epoch: 6| Step: 13
Training loss: 2.3678382507833087
Validation loss: 2.9724469639629554

Epoch: 200| Step: 0
Training loss: 2.55410339957493
Validation loss: 2.9758528862441813

Epoch: 6| Step: 1
Training loss: 3.988243708120933
Validation loss: 2.9765196236695664

Epoch: 6| Step: 2
Training loss: 2.993332765688202
Validation loss: 2.9760398992720085

Epoch: 6| Step: 3
Training loss: 3.1578641484268184
Validation loss: 2.970704498854867

Epoch: 6| Step: 4
Training loss: 3.9345049896460678
Validation loss: 2.9698010452049965

Epoch: 6| Step: 5
Training loss: 3.1786830355918276
Validation loss: 2.969244557730409

Epoch: 6| Step: 6
Training loss: 3.2901726885523206
Validation loss: 2.9693240920510946

Epoch: 6| Step: 7
Training loss: 2.7138911709818707
Validation loss: 2.965770953398536

Epoch: 6| Step: 8
Training loss: 3.320426813289537
Validation loss: 2.968143810996636

Epoch: 6| Step: 9
Training loss: 3.636818004528008
Validation loss: 2.967091484931006

Epoch: 6| Step: 10
Training loss: 3.118767588839117
Validation loss: 2.9692076834878245

Epoch: 6| Step: 11
Training loss: 3.214412396068985
Validation loss: 2.967498919821679

Epoch: 6| Step: 12
Training loss: 3.0243744889140856
Validation loss: 2.9696889932680075

Epoch: 6| Step: 13
Training loss: 2.8821225051309876
Validation loss: 2.9693826498932845

Epoch: 201| Step: 0
Training loss: 4.082330282109296
Validation loss: 2.9705612796954615

Epoch: 6| Step: 1
Training loss: 3.1346897199240873
Validation loss: 2.9731378982634835

Epoch: 6| Step: 2
Training loss: 2.8211353401408017
Validation loss: 2.9835781912162256

Epoch: 6| Step: 3
Training loss: 3.063977566270897
Validation loss: 2.9939385461727546

Epoch: 6| Step: 4
Training loss: 2.853368234450659
Validation loss: 2.982660291584306

Epoch: 6| Step: 5
Training loss: 3.007373807547501
Validation loss: 2.9790366236412336

Epoch: 6| Step: 6
Training loss: 3.461830454517551
Validation loss: 2.9771341064558214

Epoch: 6| Step: 7
Training loss: 3.534218949465875
Validation loss: 2.9728016655727267

Epoch: 6| Step: 8
Training loss: 3.688871225700323
Validation loss: 2.97537330594043

Epoch: 6| Step: 9
Training loss: 3.1359778796505746
Validation loss: 2.9735448900559884

Epoch: 6| Step: 10
Training loss: 2.4788303521118142
Validation loss: 2.9691588711222168

Epoch: 6| Step: 11
Training loss: 2.9391473249882933
Validation loss: 2.9667482061634454

Epoch: 6| Step: 12
Training loss: 3.3305809737645973
Validation loss: 2.965105461474133

Epoch: 6| Step: 13
Training loss: 3.8551776006930916
Validation loss: 2.9655444340139177

Epoch: 202| Step: 0
Training loss: 4.006879612431053
Validation loss: 2.9653902343667857

Epoch: 6| Step: 1
Training loss: 2.8158121739029314
Validation loss: 2.966360548286797

Epoch: 6| Step: 2
Training loss: 3.018084378043179
Validation loss: 2.966122442106777

Epoch: 6| Step: 3
Training loss: 2.866281641749307
Validation loss: 2.966018306832811

Epoch: 6| Step: 4
Training loss: 3.1598239719277617
Validation loss: 2.9678602036924637

Epoch: 6| Step: 5
Training loss: 3.294761522661532
Validation loss: 2.964854674345041

Epoch: 6| Step: 6
Training loss: 3.214288378517621
Validation loss: 2.965023656747709

Epoch: 6| Step: 7
Training loss: 3.4766121507163823
Validation loss: 2.965350279418382

Epoch: 6| Step: 8
Training loss: 3.1627572840799036
Validation loss: 2.965611864068632

Epoch: 6| Step: 9
Training loss: 3.87859854193175
Validation loss: 2.9646542355200585

Epoch: 6| Step: 10
Training loss: 3.0417140974413965
Validation loss: 2.9653956341568857

Epoch: 6| Step: 11
Training loss: 3.151032318017296
Validation loss: 2.9639465902002753

Epoch: 6| Step: 12
Training loss: 3.247334928127527
Validation loss: 2.964573893620919

Epoch: 6| Step: 13
Training loss: 2.5836495134203132
Validation loss: 2.963369785842571

Epoch: 203| Step: 0
Training loss: 3.5885750040499897
Validation loss: 2.9656790004107423

Epoch: 6| Step: 1
Training loss: 2.9471240556311478
Validation loss: 2.9653668593694933

Epoch: 6| Step: 2
Training loss: 3.2310362459237663
Validation loss: 2.9636761313883717

Epoch: 6| Step: 3
Training loss: 3.186040506760354
Validation loss: 2.9657098424737587

Epoch: 6| Step: 4
Training loss: 3.0496265995774934
Validation loss: 2.9693008766659132

Epoch: 6| Step: 5
Training loss: 4.12693972208543
Validation loss: 2.9662319884137056

Epoch: 6| Step: 6
Training loss: 3.39289365189492
Validation loss: 2.964863743059976

Epoch: 6| Step: 7
Training loss: 2.748988312247843
Validation loss: 2.963447375671544

Epoch: 6| Step: 8
Training loss: 3.066599379367973
Validation loss: 2.9629115064334006

Epoch: 6| Step: 9
Training loss: 3.2474440280710155
Validation loss: 2.9624700352724975

Epoch: 6| Step: 10
Training loss: 2.720746414486458
Validation loss: 2.962622949601631

Epoch: 6| Step: 11
Training loss: 3.8425035394020632
Validation loss: 2.964410108150081

Epoch: 6| Step: 12
Training loss: 3.1189622153206895
Validation loss: 2.9632391011847847

Epoch: 6| Step: 13
Training loss: 2.3777558249453463
Validation loss: 2.9642232011779015

Epoch: 204| Step: 0
Training loss: 3.3773549658796242
Validation loss: 2.9657635108232614

Epoch: 6| Step: 1
Training loss: 3.480623286762799
Validation loss: 2.9618760064074814

Epoch: 6| Step: 2
Training loss: 2.8198992566449874
Validation loss: 2.964113232079328

Epoch: 6| Step: 3
Training loss: 2.795977059397091
Validation loss: 2.9618071479416237

Epoch: 6| Step: 4
Training loss: 3.120114283791685
Validation loss: 2.960983433157342

Epoch: 6| Step: 5
Training loss: 2.9711462689797625
Validation loss: 2.9607492836709635

Epoch: 6| Step: 6
Training loss: 2.9367557962713877
Validation loss: 2.9616793269989254

Epoch: 6| Step: 7
Training loss: 3.386605970359428
Validation loss: 2.959972707860387

Epoch: 6| Step: 8
Training loss: 3.159642577419322
Validation loss: 2.960389551106359

Epoch: 6| Step: 9
Training loss: 3.1139633599332597
Validation loss: 2.9590782046412816

Epoch: 6| Step: 10
Training loss: 3.328799470425733
Validation loss: 2.960495313189315

Epoch: 6| Step: 11
Training loss: 3.99510608747083
Validation loss: 2.9591757270993395

Epoch: 6| Step: 12
Training loss: 3.1362748265414586
Validation loss: 2.96210824932442

Epoch: 6| Step: 13
Training loss: 3.754634155453283
Validation loss: 2.9663098533982515

Epoch: 205| Step: 0
Training loss: 3.588020069027913
Validation loss: 2.9626077907466866

Epoch: 6| Step: 1
Training loss: 3.262690928050032
Validation loss: 2.961838872509989

Epoch: 6| Step: 2
Training loss: 3.3488189209455927
Validation loss: 2.9628306348908655

Epoch: 6| Step: 3
Training loss: 2.5169308513225697
Validation loss: 2.9629181484695324

Epoch: 6| Step: 4
Training loss: 3.2666612651027735
Validation loss: 2.9619327813688314

Epoch: 6| Step: 5
Training loss: 3.318350753189211
Validation loss: 2.9609441858590015

Epoch: 6| Step: 6
Training loss: 2.764930422357589
Validation loss: 2.9648306518007685

Epoch: 6| Step: 7
Training loss: 3.1196649405714494
Validation loss: 2.961295280472053

Epoch: 6| Step: 8
Training loss: 3.661483149582324
Validation loss: 2.9626967663536496

Epoch: 6| Step: 9
Training loss: 2.863903024981646
Validation loss: 2.958461241937256

Epoch: 6| Step: 10
Training loss: 3.7132871878568663
Validation loss: 2.9580260768182116

Epoch: 6| Step: 11
Training loss: 3.439224781469386
Validation loss: 2.9614850272150153

Epoch: 6| Step: 12
Training loss: 2.8743550779710243
Validation loss: 2.9593593898421737

Epoch: 6| Step: 13
Training loss: 3.4190348504770838
Validation loss: 2.959702860368096

Epoch: 206| Step: 0
Training loss: 2.958475584093478
Validation loss: 2.960330720979304

Epoch: 6| Step: 1
Training loss: 3.140625910972349
Validation loss: 2.9640118986243573

Epoch: 6| Step: 2
Training loss: 3.948582266843352
Validation loss: 2.954108336727437

Epoch: 6| Step: 3
Training loss: 2.986642984341779
Validation loss: 2.9569953826009097

Epoch: 6| Step: 4
Training loss: 2.8497060925370485
Validation loss: 2.958095763420951

Epoch: 6| Step: 5
Training loss: 3.5119598950852926
Validation loss: 2.9596904063805347

Epoch: 6| Step: 6
Training loss: 3.58997976483351
Validation loss: 2.9606146854408855

Epoch: 6| Step: 7
Training loss: 3.255362414973151
Validation loss: 2.959762324014823

Epoch: 6| Step: 8
Training loss: 2.9325254808962797
Validation loss: 2.9616680871133254

Epoch: 6| Step: 9
Training loss: 3.5519163627572174
Validation loss: 2.965295457199286

Epoch: 6| Step: 10
Training loss: 2.9238178505267873
Validation loss: 2.961948337492331

Epoch: 6| Step: 11
Training loss: 3.03016375712923
Validation loss: 2.956497091035933

Epoch: 6| Step: 12
Training loss: 3.185716616319956
Validation loss: 2.9658488616049565

Epoch: 6| Step: 13
Training loss: 3.2089772424601195
Validation loss: 2.955373456391591

Epoch: 207| Step: 0
Training loss: 3.669081254135793
Validation loss: 2.9559273411263027

Epoch: 6| Step: 1
Training loss: 3.642922654618033
Validation loss: 2.9559828834695865

Epoch: 6| Step: 2
Training loss: 3.284329812767098
Validation loss: 2.9539936708975474

Epoch: 6| Step: 3
Training loss: 3.6825383313703224
Validation loss: 2.9541240703010403

Epoch: 6| Step: 4
Training loss: 2.4755456804542355
Validation loss: 2.9560976906827396

Epoch: 6| Step: 5
Training loss: 2.4019097160949325
Validation loss: 2.952552615365452

Epoch: 6| Step: 6
Training loss: 3.542505740832063
Validation loss: 2.952428461824069

Epoch: 6| Step: 7
Training loss: 2.3897271558410207
Validation loss: 2.95523768423385

Epoch: 6| Step: 8
Training loss: 2.801523363017688
Validation loss: 2.955265337099348

Epoch: 6| Step: 9
Training loss: 3.1772106374447984
Validation loss: 2.9547218718703276

Epoch: 6| Step: 10
Training loss: 3.6181233392192054
Validation loss: 2.9553464507944662

Epoch: 6| Step: 11
Training loss: 3.018925101373036
Validation loss: 2.9538113226840945

Epoch: 6| Step: 12
Training loss: 3.798877203852308
Validation loss: 2.9535050675768497

Epoch: 6| Step: 13
Training loss: 3.3383608732898393
Validation loss: 2.953401019523671

Epoch: 208| Step: 0
Training loss: 2.8100455700583296
Validation loss: 2.95533707355234

Epoch: 6| Step: 1
Training loss: 3.034891045765559
Validation loss: 2.9561238724859615

Epoch: 6| Step: 2
Training loss: 2.6634286255035735
Validation loss: 2.9533189105582136

Epoch: 6| Step: 3
Training loss: 3.4649348542666027
Validation loss: 2.9560314381505504

Epoch: 6| Step: 4
Training loss: 3.0624009719719534
Validation loss: 2.9547880088727747

Epoch: 6| Step: 5
Training loss: 3.5153506023557464
Validation loss: 2.954652289637494

Epoch: 6| Step: 6
Training loss: 3.7215222195514612
Validation loss: 2.9541494798888563

Epoch: 6| Step: 7
Training loss: 3.8056910011957132
Validation loss: 2.9565156647088413

Epoch: 6| Step: 8
Training loss: 3.508426875832872
Validation loss: 2.954452993014794

Epoch: 6| Step: 9
Training loss: 2.758901235274829
Validation loss: 2.9619653796325527

Epoch: 6| Step: 10
Training loss: 2.557754588651265
Validation loss: 2.9597085407826333

Epoch: 6| Step: 11
Training loss: 3.8915711749911464
Validation loss: 2.9593692455194

Epoch: 6| Step: 12
Training loss: 2.9559183785573917
Validation loss: 2.953236503295179

Epoch: 6| Step: 13
Training loss: 3.0354673012668982
Validation loss: 2.950489337520868

Epoch: 209| Step: 0
Training loss: 2.6719692280533587
Validation loss: 2.9505601092230633

Epoch: 6| Step: 1
Training loss: 3.301566162685054
Validation loss: 2.9519345988355914

Epoch: 6| Step: 2
Training loss: 2.507100226956264
Validation loss: 2.9529103204717577

Epoch: 6| Step: 3
Training loss: 4.035063839470031
Validation loss: 2.9535513958136383

Epoch: 6| Step: 4
Training loss: 3.224292316711299
Validation loss: 2.9499549846993176

Epoch: 6| Step: 5
Training loss: 3.0794013615744382
Validation loss: 2.9554501779362266

Epoch: 6| Step: 6
Training loss: 2.917359478728153
Validation loss: 2.953424830358139

Epoch: 6| Step: 7
Training loss: 3.6310533427630505
Validation loss: 2.9525630182027074

Epoch: 6| Step: 8
Training loss: 2.7795329419246215
Validation loss: 2.9535988916140665

Epoch: 6| Step: 9
Training loss: 3.727739128358399
Validation loss: 2.955767832131763

Epoch: 6| Step: 10
Training loss: 3.515343141913106
Validation loss: 2.957966081654392

Epoch: 6| Step: 11
Training loss: 3.051803905901905
Validation loss: 2.949772080031957

Epoch: 6| Step: 12
Training loss: 3.3613806126966765
Validation loss: 2.9503513985494263

Epoch: 6| Step: 13
Training loss: 2.9084528296404693
Validation loss: 2.9500543477770567

Epoch: 210| Step: 0
Training loss: 2.9339453109397677
Validation loss: 2.9538453158962645

Epoch: 6| Step: 1
Training loss: 3.5292522889927196
Validation loss: 2.95457899902265

Epoch: 6| Step: 2
Training loss: 3.7000545858532217
Validation loss: 2.953903336138444

Epoch: 6| Step: 3
Training loss: 3.4579236963788005
Validation loss: 2.9534646740804105

Epoch: 6| Step: 4
Training loss: 3.288905921525353
Validation loss: 2.9527564707817864

Epoch: 6| Step: 5
Training loss: 3.5950706377371535
Validation loss: 2.955984774121535

Epoch: 6| Step: 6
Training loss: 3.5237326487817335
Validation loss: 2.963130853609463

Epoch: 6| Step: 7
Training loss: 3.013512222105754
Validation loss: 2.9599051320167384

Epoch: 6| Step: 8
Training loss: 2.75771281897025
Validation loss: 2.9516725863617874

Epoch: 6| Step: 9
Training loss: 3.19029053850786
Validation loss: 2.9499266137529556

Epoch: 6| Step: 10
Training loss: 2.5033137294375876
Validation loss: 2.94769842410432

Epoch: 6| Step: 11
Training loss: 3.6517166333688
Validation loss: 2.9467754363157908

Epoch: 6| Step: 12
Training loss: 2.340864719801974
Validation loss: 2.94614379063067

Epoch: 6| Step: 13
Training loss: 3.4673632349877517
Validation loss: 2.9461971027433456

Epoch: 211| Step: 0
Training loss: 2.804339629040121
Validation loss: 2.947480239023306

Epoch: 6| Step: 1
Training loss: 3.3120678313860283
Validation loss: 2.946201159391288

Epoch: 6| Step: 2
Training loss: 1.8872783454952384
Validation loss: 2.9443548299420406

Epoch: 6| Step: 3
Training loss: 2.815781607384678
Validation loss: 2.945115513547972

Epoch: 6| Step: 4
Training loss: 3.8779291956528272
Validation loss: 2.9463400653227576

Epoch: 6| Step: 5
Training loss: 2.6995438684953625
Validation loss: 2.9440316835275624

Epoch: 6| Step: 6
Training loss: 4.208640411554488
Validation loss: 2.9453033092863814

Epoch: 6| Step: 7
Training loss: 3.4358393038829584
Validation loss: 2.9443758450075252

Epoch: 6| Step: 8
Training loss: 3.1676445170661154
Validation loss: 2.943756300814503

Epoch: 6| Step: 9
Training loss: 3.6294948728750898
Validation loss: 2.9485708690826136

Epoch: 6| Step: 10
Training loss: 3.354453664944381
Validation loss: 2.947623493350056

Epoch: 6| Step: 11
Training loss: 3.379118772669817
Validation loss: 2.9461227142113393

Epoch: 6| Step: 12
Training loss: 3.1350716604897966
Validation loss: 2.947640358262913

Epoch: 6| Step: 13
Training loss: 2.477754131721298
Validation loss: 2.9505768991371326

Epoch: 212| Step: 0
Training loss: 2.68757487348009
Validation loss: 2.946743206798338

Epoch: 6| Step: 1
Training loss: 3.7319550274656805
Validation loss: 2.9488868248973175

Epoch: 6| Step: 2
Training loss: 2.6774780239767
Validation loss: 2.9461841913929594

Epoch: 6| Step: 3
Training loss: 3.3104533944674284
Validation loss: 2.943905779046967

Epoch: 6| Step: 4
Training loss: 3.5980098521599735
Validation loss: 2.9536953703150903

Epoch: 6| Step: 5
Training loss: 2.5441312462042123
Validation loss: 2.951525577385512

Epoch: 6| Step: 6
Training loss: 2.6943197439992255
Validation loss: 2.9450293077017258

Epoch: 6| Step: 7
Training loss: 3.681390388544944
Validation loss: 2.954306196154044

Epoch: 6| Step: 8
Training loss: 2.962422584777665
Validation loss: 2.9483019231624734

Epoch: 6| Step: 9
Training loss: 2.7146031115248848
Validation loss: 2.942340270181678

Epoch: 6| Step: 10
Training loss: 3.5556067986239563
Validation loss: 2.944018948160074

Epoch: 6| Step: 11
Training loss: 3.0929310032486876
Validation loss: 2.9445396121477407

Epoch: 6| Step: 12
Training loss: 3.647612451881517
Validation loss: 2.9407952789224114

Epoch: 6| Step: 13
Training loss: 4.194536588441262
Validation loss: 2.9413466357698628

Epoch: 213| Step: 0
Training loss: 3.0025096568540715
Validation loss: 2.9393489833507047

Epoch: 6| Step: 1
Training loss: 3.780190437606004
Validation loss: 2.9422330848075777

Epoch: 6| Step: 2
Training loss: 3.40789629148011
Validation loss: 2.9402031165708578

Epoch: 6| Step: 3
Training loss: 2.8093870101179776
Validation loss: 2.9430589495160193

Epoch: 6| Step: 4
Training loss: 3.876458416563588
Validation loss: 2.9382313682084984

Epoch: 6| Step: 5
Training loss: 2.651050819925771
Validation loss: 2.939343114447367

Epoch: 6| Step: 6
Training loss: 3.529895624017101
Validation loss: 2.941193391026198

Epoch: 6| Step: 7
Training loss: 1.9515529562088372
Validation loss: 2.9391866880248214

Epoch: 6| Step: 8
Training loss: 2.478015653836343
Validation loss: 2.9412599272351443

Epoch: 6| Step: 9
Training loss: 3.0558302515030142
Validation loss: 2.9388091591819676

Epoch: 6| Step: 10
Training loss: 2.9933891572681603
Validation loss: 2.9394024753918497

Epoch: 6| Step: 11
Training loss: 3.9859324085497665
Validation loss: 2.939448743320958

Epoch: 6| Step: 12
Training loss: 3.3370482406901703
Validation loss: 2.9392564069907468

Epoch: 6| Step: 13
Training loss: 3.8218619046177937
Validation loss: 2.9404910395909027

Epoch: 214| Step: 0
Training loss: 2.5795360980553568
Validation loss: 2.939905020350364

Epoch: 6| Step: 1
Training loss: 3.580973195401507
Validation loss: 2.9432997881347522

Epoch: 6| Step: 2
Training loss: 2.7264819638837783
Validation loss: 2.940897210976841

Epoch: 6| Step: 3
Training loss: 3.805769310274834
Validation loss: 2.9445403460990778

Epoch: 6| Step: 4
Training loss: 3.545696314769129
Validation loss: 2.9406662517430546

Epoch: 6| Step: 5
Training loss: 2.5472713232305724
Validation loss: 2.9398795626405936

Epoch: 6| Step: 6
Training loss: 3.2155511756778683
Validation loss: 2.94054682119239

Epoch: 6| Step: 7
Training loss: 3.5498911934954767
Validation loss: 2.9394575241154612

Epoch: 6| Step: 8
Training loss: 3.3145679280905918
Validation loss: 2.940158498016014

Epoch: 6| Step: 9
Training loss: 3.3661207027088436
Validation loss: 2.9385541230206003

Epoch: 6| Step: 10
Training loss: 2.8254442523944214
Validation loss: 2.939342337333563

Epoch: 6| Step: 11
Training loss: 3.6507397725030533
Validation loss: 2.94193784380692

Epoch: 6| Step: 12
Training loss: 2.642612589564151
Validation loss: 2.9416366962099607

Epoch: 6| Step: 13
Training loss: 3.442827015887979
Validation loss: 2.938100021755259

Epoch: 215| Step: 0
Training loss: 3.6232121761482134
Validation loss: 2.9375288173612133

Epoch: 6| Step: 1
Training loss: 3.742236302322374
Validation loss: 2.9391532361499992

Epoch: 6| Step: 2
Training loss: 3.533607033859137
Validation loss: 2.9413515968410993

Epoch: 6| Step: 3
Training loss: 3.3059936539438475
Validation loss: 2.9387241292322384

Epoch: 6| Step: 4
Training loss: 2.7151570749948393
Validation loss: 2.9351765509961636

Epoch: 6| Step: 5
Training loss: 3.2543653368087555
Validation loss: 2.944156040516027

Epoch: 6| Step: 6
Training loss: 2.7066988389995483
Validation loss: 2.938972597994973

Epoch: 6| Step: 7
Training loss: 3.443567919893682
Validation loss: 2.93958014288501

Epoch: 6| Step: 8
Training loss: 3.3221773542892095
Validation loss: 2.9379409427675256

Epoch: 6| Step: 9
Training loss: 2.8294222896492602
Validation loss: 2.939475779850986

Epoch: 6| Step: 10
Training loss: 3.5285634311565537
Validation loss: 2.93852490218519

Epoch: 6| Step: 11
Training loss: 3.2093467763163046
Validation loss: 2.9444659374776294

Epoch: 6| Step: 12
Training loss: 2.6363393100823993
Validation loss: 2.9395641474507856

Epoch: 6| Step: 13
Training loss: 2.657313593932606
Validation loss: 2.937909251591774

Epoch: 216| Step: 0
Training loss: 3.192955882861124
Validation loss: 2.937802840457682

Epoch: 6| Step: 1
Training loss: 3.06197928848089
Validation loss: 2.939284807664766

Epoch: 6| Step: 2
Training loss: 2.8172268459050014
Validation loss: 2.9367022734802903

Epoch: 6| Step: 3
Training loss: 3.0117481987251877
Validation loss: 2.9368695953053834

Epoch: 6| Step: 4
Training loss: 3.2166708740312275
Validation loss: 2.935860339653905

Epoch: 6| Step: 5
Training loss: 3.2204487586218757
Validation loss: 2.9385433242397156

Epoch: 6| Step: 6
Training loss: 2.807153664182981
Validation loss: 2.9420600028092783

Epoch: 6| Step: 7
Training loss: 3.7827864118556476
Validation loss: 2.9366565192406022

Epoch: 6| Step: 8
Training loss: 3.382978968235529
Validation loss: 2.9484121046246363

Epoch: 6| Step: 9
Training loss: 2.823571855212013
Validation loss: 2.938925008877957

Epoch: 6| Step: 10
Training loss: 3.497282880870251
Validation loss: 2.940411305163451

Epoch: 6| Step: 11
Training loss: 2.8219706133658082
Validation loss: 2.934007714331927

Epoch: 6| Step: 12
Training loss: 3.4037804006619132
Validation loss: 2.9346820997216905

Epoch: 6| Step: 13
Training loss: 4.155830304746644
Validation loss: 2.938605600328164

Epoch: 217| Step: 0
Training loss: 4.272191844204392
Validation loss: 2.935463658789152

Epoch: 6| Step: 1
Training loss: 2.8001582305340946
Validation loss: 2.932964977598557

Epoch: 6| Step: 2
Training loss: 2.4600154057462302
Validation loss: 2.934549630820637

Epoch: 6| Step: 3
Training loss: 3.2942254145008003
Validation loss: 2.9343504453505336

Epoch: 6| Step: 4
Training loss: 3.566716158752262
Validation loss: 2.9349289138743155

Epoch: 6| Step: 5
Training loss: 3.112291051752762
Validation loss: 2.9371903901496346

Epoch: 6| Step: 6
Training loss: 2.233539558492436
Validation loss: 2.9351962378072076

Epoch: 6| Step: 7
Training loss: 3.2158231297911284
Validation loss: 2.936181401926919

Epoch: 6| Step: 8
Training loss: 3.348494541609771
Validation loss: 2.9371179748129683

Epoch: 6| Step: 9
Training loss: 3.333040860378571
Validation loss: 2.93712107340129

Epoch: 6| Step: 10
Training loss: 3.583941267622228
Validation loss: 2.938020745982856

Epoch: 6| Step: 11
Training loss: 3.462812135584681
Validation loss: 2.9377542916716153

Epoch: 6| Step: 12
Training loss: 3.159252287370983
Validation loss: 2.933507749144219

Epoch: 6| Step: 13
Training loss: 2.172313618451346
Validation loss: 2.9393017387388

Epoch: 218| Step: 0
Training loss: 2.9916833995751384
Validation loss: 2.9392591919470545

Epoch: 6| Step: 1
Training loss: 3.486503053865965
Validation loss: 2.936153396448278

Epoch: 6| Step: 2
Training loss: 3.0554324751446327
Validation loss: 2.9485929496011747

Epoch: 6| Step: 3
Training loss: 2.891708088632191
Validation loss: 2.9397844879963557

Epoch: 6| Step: 4
Training loss: 3.3184634097508847
Validation loss: 2.9450738681313866

Epoch: 6| Step: 5
Training loss: 3.0962526621862922
Validation loss: 2.936305097817377

Epoch: 6| Step: 6
Training loss: 3.582820693022073
Validation loss: 2.934900492012885

Epoch: 6| Step: 7
Training loss: 2.755739291877917
Validation loss: 2.9326440649711256

Epoch: 6| Step: 8
Training loss: 2.359693088941658
Validation loss: 2.9335419015997117

Epoch: 6| Step: 9
Training loss: 3.656637057170303
Validation loss: 2.931359666965931

Epoch: 6| Step: 10
Training loss: 3.0332713515548004
Validation loss: 2.9282516476442826

Epoch: 6| Step: 11
Training loss: 3.37949298328857
Validation loss: 2.929199211310784

Epoch: 6| Step: 12
Training loss: 3.4911269384562686
Validation loss: 2.9291046967357217

Epoch: 6| Step: 13
Training loss: 3.917201201845178
Validation loss: 2.9281512120241686

Epoch: 219| Step: 0
Training loss: 3.1838073284378026
Validation loss: 2.9283954556701244

Epoch: 6| Step: 1
Training loss: 3.3983883908987664
Validation loss: 2.9319819416834796

Epoch: 6| Step: 2
Training loss: 3.0686345842026785
Validation loss: 2.9286049887396515

Epoch: 6| Step: 3
Training loss: 3.3677039226137717
Validation loss: 2.939378126220104

Epoch: 6| Step: 4
Training loss: 2.324184487995891
Validation loss: 2.931069290968712

Epoch: 6| Step: 5
Training loss: 3.321668208980505
Validation loss: 2.943674862524541

Epoch: 6| Step: 6
Training loss: 2.913963663915379
Validation loss: 2.9365628924537917

Epoch: 6| Step: 7
Training loss: 3.493615730994823
Validation loss: 2.936337118867009

Epoch: 6| Step: 8
Training loss: 3.2654661295087335
Validation loss: 2.945428146999496

Epoch: 6| Step: 9
Training loss: 3.1345666554845795
Validation loss: 2.939643151368615

Epoch: 6| Step: 10
Training loss: 3.2118705637541725
Validation loss: 2.946284223729269

Epoch: 6| Step: 11
Training loss: 3.6185127615372195
Validation loss: 2.9338466728113883

Epoch: 6| Step: 12
Training loss: 3.400463263422175
Validation loss: 2.9316993732578958

Epoch: 6| Step: 13
Training loss: 2.9386355863209537
Validation loss: 2.9344182270288273

Epoch: 220| Step: 0
Training loss: 3.7069352904301587
Validation loss: 2.93023861093898

Epoch: 6| Step: 1
Training loss: 2.49743883548717
Validation loss: 2.934188136534199

Epoch: 6| Step: 2
Training loss: 3.3972099805812186
Validation loss: 2.927246137101398

Epoch: 6| Step: 3
Training loss: 3.5076009775799646
Validation loss: 2.9283323321133943

Epoch: 6| Step: 4
Training loss: 3.2899736968035445
Validation loss: 2.9266684341063263

Epoch: 6| Step: 5
Training loss: 3.169250003408763
Validation loss: 2.925360365689666

Epoch: 6| Step: 6
Training loss: 3.615761131684637
Validation loss: 2.9249999075862316

Epoch: 6| Step: 7
Training loss: 3.0130031434608364
Validation loss: 2.9279614441030617

Epoch: 6| Step: 8
Training loss: 2.4845049362271765
Validation loss: 2.928291533597514

Epoch: 6| Step: 9
Training loss: 2.9696637805247166
Validation loss: 2.933134461701652

Epoch: 6| Step: 10
Training loss: 2.882398953019036
Validation loss: 2.9262785596588774

Epoch: 6| Step: 11
Training loss: 3.397546971594997
Validation loss: 2.925883127702168

Epoch: 6| Step: 12
Training loss: 3.295214917550028
Validation loss: 2.925736534179683

Epoch: 6| Step: 13
Training loss: 3.5677041306668147
Validation loss: 2.930349275615474

Epoch: 221| Step: 0
Training loss: 3.091017932811441
Validation loss: 2.926824240672271

Epoch: 6| Step: 1
Training loss: 2.7270742553684184
Validation loss: 2.931763124742823

Epoch: 6| Step: 2
Training loss: 3.5077423564465198
Validation loss: 2.9301426407771385

Epoch: 6| Step: 3
Training loss: 2.718064320356891
Validation loss: 2.9263872549422385

Epoch: 6| Step: 4
Training loss: 3.4290235567571434
Validation loss: 2.9319349307378038

Epoch: 6| Step: 5
Training loss: 3.2369483625072064
Validation loss: 2.9281300358635898

Epoch: 6| Step: 6
Training loss: 3.142743814580188
Validation loss: 2.9275398845703102

Epoch: 6| Step: 7
Training loss: 2.510558624263827
Validation loss: 2.9335887828003977

Epoch: 6| Step: 8
Training loss: 3.0409242080932692
Validation loss: 2.939362491639496

Epoch: 6| Step: 9
Training loss: 3.3936817085040922
Validation loss: 2.9304435803325104

Epoch: 6| Step: 10
Training loss: 3.9747577761377215
Validation loss: 2.9256230197654465

Epoch: 6| Step: 11
Training loss: 3.66968773160406
Validation loss: 2.927090010104233

Epoch: 6| Step: 12
Training loss: 3.3902216376935517
Validation loss: 2.9194178852889534

Epoch: 6| Step: 13
Training loss: 2.2843386499771747
Validation loss: 2.923027874096371

Epoch: 222| Step: 0
Training loss: 3.1819542905256557
Validation loss: 2.9226983269089004

Epoch: 6| Step: 1
Training loss: 3.1889799085853205
Validation loss: 2.923595962898925

Epoch: 6| Step: 2
Training loss: 3.142522134513258
Validation loss: 2.9227490607414106

Epoch: 6| Step: 3
Training loss: 2.7143945994801513
Validation loss: 2.9217250773008723

Epoch: 6| Step: 4
Training loss: 3.8482850156459967
Validation loss: 2.921695024800716

Epoch: 6| Step: 5
Training loss: 2.256698597616846
Validation loss: 2.9239482700005173

Epoch: 6| Step: 6
Training loss: 3.748656350060268
Validation loss: 2.921423474819864

Epoch: 6| Step: 7
Training loss: 3.6279800267789555
Validation loss: 2.9220040199476904

Epoch: 6| Step: 8
Training loss: 3.1645352234154096
Validation loss: 2.918125119899444

Epoch: 6| Step: 9
Training loss: 2.990158468786735
Validation loss: 2.920390162154071

Epoch: 6| Step: 10
Training loss: 3.115448507285956
Validation loss: 2.920176290985514

Epoch: 6| Step: 11
Training loss: 3.4704020921872325
Validation loss: 2.9269415404641457

Epoch: 6| Step: 12
Training loss: 3.068398536709031
Validation loss: 2.9311777403803108

Epoch: 6| Step: 13
Training loss: 2.9138368411810442
Validation loss: 2.9298034706269394

Epoch: 223| Step: 0
Training loss: 3.3969723404147656
Validation loss: 2.9287722908590377

Epoch: 6| Step: 1
Training loss: 3.5055623133198415
Validation loss: 2.9353670288892544

Epoch: 6| Step: 2
Training loss: 2.6507798360994514
Validation loss: 2.9268042873276414

Epoch: 6| Step: 3
Training loss: 3.066479646812678
Validation loss: 2.922807928075333

Epoch: 6| Step: 4
Training loss: 3.1862096231565356
Validation loss: 2.927937700249201

Epoch: 6| Step: 5
Training loss: 3.6373281326853397
Validation loss: 2.930457474353308

Epoch: 6| Step: 6
Training loss: 3.972307668150746
Validation loss: 2.92732159295867

Epoch: 6| Step: 7
Training loss: 2.900913219701642
Validation loss: 2.9235043793187088

Epoch: 6| Step: 8
Training loss: 2.844353580348101
Validation loss: 2.9241238649434766

Epoch: 6| Step: 9
Training loss: 3.204482074851097
Validation loss: 2.922979095694867

Epoch: 6| Step: 10
Training loss: 2.093753871629466
Validation loss: 2.919604934171349

Epoch: 6| Step: 11
Training loss: 3.699843872487883
Validation loss: 2.9197334081939967

Epoch: 6| Step: 12
Training loss: 3.377808426695637
Validation loss: 2.9188074830948385

Epoch: 6| Step: 13
Training loss: 2.516988538744009
Validation loss: 2.9167443055632227

Epoch: 224| Step: 0
Training loss: 3.3364316051761147
Validation loss: 2.917428867815509

Epoch: 6| Step: 1
Training loss: 3.2393211103251773
Validation loss: 2.9157814622164304

Epoch: 6| Step: 2
Training loss: 3.3150839174445808
Validation loss: 2.9201938192064874

Epoch: 6| Step: 3
Training loss: 2.5735521857271775
Validation loss: 2.9175354754966807

Epoch: 6| Step: 4
Training loss: 3.097739681549041
Validation loss: 2.916913983338209

Epoch: 6| Step: 5
Training loss: 3.011435330880475
Validation loss: 2.917441825581601

Epoch: 6| Step: 6
Training loss: 2.7909836763938576
Validation loss: 2.918208156731435

Epoch: 6| Step: 7
Training loss: 3.259258873133524
Validation loss: 2.9150651328961548

Epoch: 6| Step: 8
Training loss: 3.5564270458163985
Validation loss: 2.9166294277175373

Epoch: 6| Step: 9
Training loss: 3.9412032378495954
Validation loss: 2.9179789941115377

Epoch: 6| Step: 10
Training loss: 3.7939047164414297
Validation loss: 2.921663985727581

Epoch: 6| Step: 11
Training loss: 1.513779608061301
Validation loss: 2.9259440058897597

Epoch: 6| Step: 12
Training loss: 3.6666071337866506
Validation loss: 2.9180686382174

Epoch: 6| Step: 13
Training loss: 2.977652442802785
Validation loss: 2.9169259766189133

Epoch: 225| Step: 0
Training loss: 2.550354996448564
Validation loss: 2.9174812591561277

Epoch: 6| Step: 1
Training loss: 2.4785277454269248
Validation loss: 2.9153879972406

Epoch: 6| Step: 2
Training loss: 3.5746616443492987
Validation loss: 2.918390656391993

Epoch: 6| Step: 3
Training loss: 3.234763891456636
Validation loss: 2.9151999153418333

Epoch: 6| Step: 4
Training loss: 3.413658414971962
Validation loss: 2.9201647447414056

Epoch: 6| Step: 5
Training loss: 2.8501779199578117
Validation loss: 2.913450331679221

Epoch: 6| Step: 6
Training loss: 2.6058975164326594
Validation loss: 2.915527913100568

Epoch: 6| Step: 7
Training loss: 3.876004734835572
Validation loss: 2.9216256861419905

Epoch: 6| Step: 8
Training loss: 3.019561412112858
Validation loss: 2.912673786007559

Epoch: 6| Step: 9
Training loss: 3.466288750174307
Validation loss: 2.920711223932274

Epoch: 6| Step: 10
Training loss: 3.4450391457690794
Validation loss: 2.915593983390564

Epoch: 6| Step: 11
Training loss: 3.8349113257151894
Validation loss: 2.91326220828266

Epoch: 6| Step: 12
Training loss: 3.0054735477687857
Validation loss: 2.9137542411129393

Epoch: 6| Step: 13
Training loss: 2.895580930253033
Validation loss: 2.9215341715452077

Epoch: 226| Step: 0
Training loss: 3.0949596775860893
Validation loss: 2.9192678645033263

Epoch: 6| Step: 1
Training loss: 2.661417523473709
Validation loss: 2.9148785156433914

Epoch: 6| Step: 2
Training loss: 2.852199702725262
Validation loss: 2.913875419103071

Epoch: 6| Step: 3
Training loss: 3.543647272144885
Validation loss: 2.916127031626257

Epoch: 6| Step: 4
Training loss: 3.193720115327708
Validation loss: 2.9138652450263516

Epoch: 6| Step: 5
Training loss: 2.83239743726313
Validation loss: 2.914154459486454

Epoch: 6| Step: 6
Training loss: 2.8224455568183444
Validation loss: 2.917569101423533

Epoch: 6| Step: 7
Training loss: 2.9731845862412083
Validation loss: 2.9135089187787546

Epoch: 6| Step: 8
Training loss: 3.4207547239563563
Validation loss: 2.917284739762799

Epoch: 6| Step: 9
Training loss: 3.937010477305475
Validation loss: 2.917451322868795

Epoch: 6| Step: 10
Training loss: 3.1665279625748695
Validation loss: 2.9134642046674064

Epoch: 6| Step: 11
Training loss: 3.404948414595247
Validation loss: 2.9135840784015405

Epoch: 6| Step: 12
Training loss: 3.4870247793977303
Validation loss: 2.9136306032233117

Epoch: 6| Step: 13
Training loss: 3.1179984431333247
Validation loss: 2.912187223131948

Epoch: 227| Step: 0
Training loss: 2.9291242948228544
Validation loss: 2.916261058209532

Epoch: 6| Step: 1
Training loss: 3.3725438540854427
Validation loss: 2.9158441347693027

Epoch: 6| Step: 2
Training loss: 3.0280641154023313
Validation loss: 2.9130585873979453

Epoch: 6| Step: 3
Training loss: 2.4393803117573536
Validation loss: 2.9150604665551025

Epoch: 6| Step: 4
Training loss: 3.3352244416854493
Validation loss: 2.9095334212630903

Epoch: 6| Step: 5
Training loss: 3.2604499953316424
Validation loss: 2.9131065497921944

Epoch: 6| Step: 6
Training loss: 3.0043386239947973
Validation loss: 2.91553087196312

Epoch: 6| Step: 7
Training loss: 2.9273630101364665
Validation loss: 2.911458021036943

Epoch: 6| Step: 8
Training loss: 3.30717760425029
Validation loss: 2.910316490953117

Epoch: 6| Step: 9
Training loss: 2.953549147729592
Validation loss: 2.9117289948286857

Epoch: 6| Step: 10
Training loss: 3.502580781123527
Validation loss: 2.911013457815594

Epoch: 6| Step: 11
Training loss: 3.5605176797863662
Validation loss: 2.910296318722985

Epoch: 6| Step: 12
Training loss: 3.925380644594363
Validation loss: 2.9107407378178505

Epoch: 6| Step: 13
Training loss: 2.6969892952791077
Validation loss: 2.9123612147359097

Epoch: 228| Step: 0
Training loss: 3.1518791830173916
Validation loss: 2.9113281374689315

Epoch: 6| Step: 1
Training loss: 2.9644913495381995
Validation loss: 2.911148022759453

Epoch: 6| Step: 2
Training loss: 2.7348104075772905
Validation loss: 2.913494381664305

Epoch: 6| Step: 3
Training loss: 2.9518494449876713
Validation loss: 2.914735072421226

Epoch: 6| Step: 4
Training loss: 3.2380983602417928
Validation loss: 2.9130088658422695

Epoch: 6| Step: 5
Training loss: 2.6472637985378547
Validation loss: 2.915619479052606

Epoch: 6| Step: 6
Training loss: 3.505780215418993
Validation loss: 2.921125737837588

Epoch: 6| Step: 7
Training loss: 3.11571328239902
Validation loss: 2.9309526339481486

Epoch: 6| Step: 8
Training loss: 3.8847188587164307
Validation loss: 2.9174790061246445

Epoch: 6| Step: 9
Training loss: 3.6648385663667775
Validation loss: 2.9206259585063776

Epoch: 6| Step: 10
Training loss: 3.6788619425388527
Validation loss: 2.9140526490051992

Epoch: 6| Step: 11
Training loss: 3.407320186939179
Validation loss: 2.9075791249069045

Epoch: 6| Step: 12
Training loss: 2.7886655722730027
Validation loss: 2.912328775143463

Epoch: 6| Step: 13
Training loss: 2.151379821158434
Validation loss: 2.910686651217687

Epoch: 229| Step: 0
Training loss: 2.6891164132564827
Validation loss: 2.912878044584746

Epoch: 6| Step: 1
Training loss: 2.889158959684242
Validation loss: 2.9106147074094255

Epoch: 6| Step: 2
Training loss: 2.328196274863249
Validation loss: 2.9103362481516277

Epoch: 6| Step: 3
Training loss: 3.1133293425747484
Validation loss: 2.9254635786626215

Epoch: 6| Step: 4
Training loss: 3.2786881391337435
Validation loss: 2.9343455178731945

Epoch: 6| Step: 5
Training loss: 3.0812513865995865
Validation loss: 2.9298431552021933

Epoch: 6| Step: 6
Training loss: 3.165252838401043
Validation loss: 2.915502559086578

Epoch: 6| Step: 7
Training loss: 2.9929845161789452
Validation loss: 2.911934864764826

Epoch: 6| Step: 8
Training loss: 3.4206954804374585
Validation loss: 2.9052062712485394

Epoch: 6| Step: 9
Training loss: 3.823205145294693
Validation loss: 2.904444359090601

Epoch: 6| Step: 10
Training loss: 3.6329864132178487
Validation loss: 2.9074845917494065

Epoch: 6| Step: 11
Training loss: 3.4063818669823345
Validation loss: 2.9034065859123075

Epoch: 6| Step: 12
Training loss: 2.8326440608534424
Validation loss: 2.906553406303306

Epoch: 6| Step: 13
Training loss: 4.099973185381779
Validation loss: 2.9084149281483684

Epoch: 230| Step: 0
Training loss: 2.714440097577208
Validation loss: 2.9071740039920644

Epoch: 6| Step: 1
Training loss: 3.492338787445861
Validation loss: 2.906740896715222

Epoch: 6| Step: 2
Training loss: 3.488557913510677
Validation loss: 2.9109493285208368

Epoch: 6| Step: 3
Training loss: 2.6658089470311883
Validation loss: 2.908615793641932

Epoch: 6| Step: 4
Training loss: 2.8293936397274724
Validation loss: 2.914773371076735

Epoch: 6| Step: 5
Training loss: 3.4421923429132124
Validation loss: 2.9227425831045424

Epoch: 6| Step: 6
Training loss: 3.65737089272114
Validation loss: 2.9287774264124122

Epoch: 6| Step: 7
Training loss: 3.377451253746758
Validation loss: 2.914795705863214

Epoch: 6| Step: 8
Training loss: 3.3862469090376863
Validation loss: 2.9092154605917027

Epoch: 6| Step: 9
Training loss: 3.4201382623576166
Validation loss: 2.9069940798949165

Epoch: 6| Step: 10
Training loss: 3.598578352496666
Validation loss: 2.902698737215809

Epoch: 6| Step: 11
Training loss: 2.3730773170308215
Validation loss: 2.9036746806080203

Epoch: 6| Step: 12
Training loss: 2.7714182205315896
Validation loss: 2.903114729753764

Epoch: 6| Step: 13
Training loss: 3.265089219234002
Validation loss: 2.9024807969639053

Epoch: 231| Step: 0
Training loss: 3.082441836857965
Validation loss: 2.9012470687767493

Epoch: 6| Step: 1
Training loss: 2.3298925052453674
Validation loss: 2.9042427857959128

Epoch: 6| Step: 2
Training loss: 2.671347136527604
Validation loss: 2.9060308801862327

Epoch: 6| Step: 3
Training loss: 3.3717140873509455
Validation loss: 2.904147323078124

Epoch: 6| Step: 4
Training loss: 3.5945205525813435
Validation loss: 2.902413791322617

Epoch: 6| Step: 5
Training loss: 3.891868055688762
Validation loss: 2.900735334154248

Epoch: 6| Step: 6
Training loss: 3.22668235131332
Validation loss: 2.9016738927030894

Epoch: 6| Step: 7
Training loss: 2.977465555166365
Validation loss: 2.9034270837047083

Epoch: 6| Step: 8
Training loss: 2.995835274460066
Validation loss: 2.902816762844108

Epoch: 6| Step: 9
Training loss: 3.470638001903798
Validation loss: 2.903340742469245

Epoch: 6| Step: 10
Training loss: 3.5512771511953347
Validation loss: 2.9014033635210836

Epoch: 6| Step: 11
Training loss: 2.913107053173136
Validation loss: 2.904099650570564

Epoch: 6| Step: 12
Training loss: 3.060310671126151
Validation loss: 2.90249442914252

Epoch: 6| Step: 13
Training loss: 3.2865987144187745
Validation loss: 2.9043123576241343

Epoch: 232| Step: 0
Training loss: 2.681043632052678
Validation loss: 2.9001979940277085

Epoch: 6| Step: 1
Training loss: 2.697523719322704
Validation loss: 2.913366794937016

Epoch: 6| Step: 2
Training loss: 3.443984141066276
Validation loss: 2.912423677450967

Epoch: 6| Step: 3
Training loss: 2.6236645162395313
Validation loss: 2.9129587104378993

Epoch: 6| Step: 4
Training loss: 3.368792582793032
Validation loss: 2.90587721105451

Epoch: 6| Step: 5
Training loss: 3.5962141793767226
Validation loss: 2.9095828532937102

Epoch: 6| Step: 6
Training loss: 3.3780605426464985
Validation loss: 2.906490276300146

Epoch: 6| Step: 7
Training loss: 3.601711841060464
Validation loss: 2.9009546856109116

Epoch: 6| Step: 8
Training loss: 2.3359789382167984
Validation loss: 2.9021603353221734

Epoch: 6| Step: 9
Training loss: 3.345547344547217
Validation loss: 2.9002497309320616

Epoch: 6| Step: 10
Training loss: 3.183936576872931
Validation loss: 2.8986077037143536

Epoch: 6| Step: 11
Training loss: 3.2112829017958244
Validation loss: 2.898764789025689

Epoch: 6| Step: 12
Training loss: 3.5004751700327237
Validation loss: 2.8978183612329897

Epoch: 6| Step: 13
Training loss: 3.536485959349171
Validation loss: 2.899740408487059

Epoch: 233| Step: 0
Training loss: 3.512343031881766
Validation loss: 2.897695163448519

Epoch: 6| Step: 1
Training loss: 2.7320735292160365
Validation loss: 2.900031249939124

Epoch: 6| Step: 2
Training loss: 2.7853187203335152
Validation loss: 2.8987739477613617

Epoch: 6| Step: 3
Training loss: 3.242362805878054
Validation loss: 2.901171547127914

Epoch: 6| Step: 4
Training loss: 3.3062006234590537
Validation loss: 2.902462236111884

Epoch: 6| Step: 5
Training loss: 2.8594877293779195
Validation loss: 2.9023185961529636

Epoch: 6| Step: 6
Training loss: 2.8955280682786437
Validation loss: 2.9053281481334308

Epoch: 6| Step: 7
Training loss: 2.929950671773482
Validation loss: 2.9120655355967107

Epoch: 6| Step: 8
Training loss: 2.9693058497414984
Validation loss: 2.911327387219561

Epoch: 6| Step: 9
Training loss: 3.396813576852741
Validation loss: 2.918197863349781

Epoch: 6| Step: 10
Training loss: 3.638493908775214
Validation loss: 2.91553486488402

Epoch: 6| Step: 11
Training loss: 3.8825365425153806
Validation loss: 2.9076917452655997

Epoch: 6| Step: 12
Training loss: 3.204716877684093
Validation loss: 2.905449642257569

Epoch: 6| Step: 13
Training loss: 2.9765708302458895
Validation loss: 2.8992686029691535

Epoch: 234| Step: 0
Training loss: 3.1677450719624494
Validation loss: 2.8954871227376913

Epoch: 6| Step: 1
Training loss: 2.62759080826105
Validation loss: 2.8962526676600606

Epoch: 6| Step: 2
Training loss: 3.319232935708812
Validation loss: 2.8972219957736813

Epoch: 6| Step: 3
Training loss: 2.7961615819342693
Validation loss: 2.898464195571436

Epoch: 6| Step: 4
Training loss: 3.083277074627076
Validation loss: 2.8996235166391395

Epoch: 6| Step: 5
Training loss: 3.4231239025482654
Validation loss: 2.8987513179551687

Epoch: 6| Step: 6
Training loss: 2.9555907274446405
Validation loss: 2.897102538757959

Epoch: 6| Step: 7
Training loss: 3.2846979826305445
Validation loss: 2.896037362725915

Epoch: 6| Step: 8
Training loss: 2.981955301278549
Validation loss: 2.8973604573857705

Epoch: 6| Step: 9
Training loss: 3.3747383298807057
Validation loss: 2.8978352337921924

Epoch: 6| Step: 10
Training loss: 3.0959446376611597
Validation loss: 2.897198063706653

Epoch: 6| Step: 11
Training loss: 3.406262878953577
Validation loss: 2.898615599087279

Epoch: 6| Step: 12
Training loss: 3.8458372822111335
Validation loss: 2.8975787712602483

Epoch: 6| Step: 13
Training loss: 3.0416780410623603
Validation loss: 2.8982113481663143

Epoch: 235| Step: 0
Training loss: 3.2468210959342843
Validation loss: 2.902628474899952

Epoch: 6| Step: 1
Training loss: 2.7520589923191308
Validation loss: 2.8999700558509316

Epoch: 6| Step: 2
Training loss: 2.8525502623560515
Validation loss: 2.897521445796379

Epoch: 6| Step: 3
Training loss: 3.399591359657612
Validation loss: 2.904955279718217

Epoch: 6| Step: 4
Training loss: 3.1425439845779923
Validation loss: 2.8995683836118147

Epoch: 6| Step: 5
Training loss: 3.0490042264764554
Validation loss: 2.8988172550294626

Epoch: 6| Step: 6
Training loss: 3.6856890612063298
Validation loss: 2.900704310310946

Epoch: 6| Step: 7
Training loss: 4.012045366907389
Validation loss: 2.9006458720242945

Epoch: 6| Step: 8
Training loss: 2.2442616296453903
Validation loss: 2.8982374213274436

Epoch: 6| Step: 9
Training loss: 2.8381303868413803
Validation loss: 2.9002685353238613

Epoch: 6| Step: 10
Training loss: 3.1888308271320045
Validation loss: 2.9026693038061735

Epoch: 6| Step: 11
Training loss: 2.613103247540347
Validation loss: 2.899697352830946

Epoch: 6| Step: 12
Training loss: 3.795520430955006
Validation loss: 2.899822147051416

Epoch: 6| Step: 13
Training loss: 3.34969535695039
Validation loss: 2.9076515352937435

Epoch: 236| Step: 0
Training loss: 2.209483932550645
Validation loss: 2.898521275967054

Epoch: 6| Step: 1
Training loss: 3.5184732385885873
Validation loss: 2.909676934132091

Epoch: 6| Step: 2
Training loss: 3.22355456229816
Validation loss: 2.9092659378392276

Epoch: 6| Step: 3
Training loss: 3.2958256647058546
Validation loss: 2.9113373658726047

Epoch: 6| Step: 4
Training loss: 3.313050854063198
Validation loss: 2.9047044747894795

Epoch: 6| Step: 5
Training loss: 3.1586865377749813
Validation loss: 2.901577889564882

Epoch: 6| Step: 6
Training loss: 3.4659888472952702
Validation loss: 2.8936196984397116

Epoch: 6| Step: 7
Training loss: 3.1742206788485556
Validation loss: 2.8942230128244106

Epoch: 6| Step: 8
Training loss: 3.055019663046633
Validation loss: 2.897745109725335

Epoch: 6| Step: 9
Training loss: 3.1986107254267346
Validation loss: 2.8960402538647667

Epoch: 6| Step: 10
Training loss: 3.830049988343234
Validation loss: 2.8939466039470134

Epoch: 6| Step: 11
Training loss: 2.154687840805414
Validation loss: 2.8973364857604107

Epoch: 6| Step: 12
Training loss: 2.958313758319691
Validation loss: 2.895485229769345

Epoch: 6| Step: 13
Training loss: 3.8405862829555297
Validation loss: 2.8928321843740736

Epoch: 237| Step: 0
Training loss: 2.792374383599225
Validation loss: 2.8935352277011224

Epoch: 6| Step: 1
Training loss: 3.571316834472957
Validation loss: 2.894265300468768

Epoch: 6| Step: 2
Training loss: 3.052868079285688
Validation loss: 2.89182412846303

Epoch: 6| Step: 3
Training loss: 3.522120735104952
Validation loss: 2.893596882138864

Epoch: 6| Step: 4
Training loss: 3.434836170448638
Validation loss: 2.8920464751883492

Epoch: 6| Step: 5
Training loss: 3.6440065584762293
Validation loss: 2.89292873561936

Epoch: 6| Step: 6
Training loss: 2.997481083368802
Validation loss: 2.894638708071039

Epoch: 6| Step: 7
Training loss: 3.719207350872847
Validation loss: 2.8954227009116504

Epoch: 6| Step: 8
Training loss: 2.9371327921454777
Validation loss: 2.894816612244184

Epoch: 6| Step: 9
Training loss: 3.104266393369522
Validation loss: 2.8999867983168555

Epoch: 6| Step: 10
Training loss: 2.525351256309292
Validation loss: 2.8965695102663425

Epoch: 6| Step: 11
Training loss: 2.8621422556585085
Validation loss: 2.89901556308182

Epoch: 6| Step: 12
Training loss: 3.0457545641216996
Validation loss: 2.8936850073676816

Epoch: 6| Step: 13
Training loss: 3.0296143513623903
Validation loss: 2.901475913895654

Epoch: 238| Step: 0
Training loss: 3.606448089077932
Validation loss: 2.899239096713821

Epoch: 6| Step: 1
Training loss: 3.123588243122522
Validation loss: 2.899647264241233

Epoch: 6| Step: 2
Training loss: 2.9843596612825714
Validation loss: 2.897064765749892

Epoch: 6| Step: 3
Training loss: 3.1745304210969874
Validation loss: 2.8987428153709476

Epoch: 6| Step: 4
Training loss: 1.8960247641809242
Validation loss: 2.8964435580407994

Epoch: 6| Step: 5
Training loss: 3.493381782467552
Validation loss: 2.896079539782689

Epoch: 6| Step: 6
Training loss: 2.6712533327973516
Validation loss: 2.9070622930632917

Epoch: 6| Step: 7
Training loss: 3.8010305262149977
Validation loss: 2.89487622824284

Epoch: 6| Step: 8
Training loss: 3.72185175429611
Validation loss: 2.89088135402654

Epoch: 6| Step: 9
Training loss: 3.0540021434843863
Validation loss: 2.8924464816162203

Epoch: 6| Step: 10
Training loss: 3.2118373083429477
Validation loss: 2.8902378930565056

Epoch: 6| Step: 11
Training loss: 2.6554330803769752
Validation loss: 2.889083090103242

Epoch: 6| Step: 12
Training loss: 3.670560431033475
Validation loss: 2.891743284409475

Epoch: 6| Step: 13
Training loss: 2.628871787130165
Validation loss: 2.8904231938072944

Epoch: 239| Step: 0
Training loss: 3.0636799932953767
Validation loss: 2.8891309465051953

Epoch: 6| Step: 1
Training loss: 3.7585675597244737
Validation loss: 2.8915346531884207

Epoch: 6| Step: 2
Training loss: 3.2557750157787533
Validation loss: 2.888408144510954

Epoch: 6| Step: 3
Training loss: 3.248275299206272
Validation loss: 2.888496767968883

Epoch: 6| Step: 4
Training loss: 3.398489133946832
Validation loss: 2.890952919871137

Epoch: 6| Step: 5
Training loss: 2.4418671439957134
Validation loss: 2.892013938921731

Epoch: 6| Step: 6
Training loss: 3.145637421897041
Validation loss: 2.8894685346986813

Epoch: 6| Step: 7
Training loss: 2.8054163418800857
Validation loss: 2.888928524801912

Epoch: 6| Step: 8
Training loss: 2.445567742332325
Validation loss: 2.8884478111490566

Epoch: 6| Step: 9
Training loss: 2.897940292280376
Validation loss: 2.893248920338719

Epoch: 6| Step: 10
Training loss: 3.707643480463387
Validation loss: 2.890284199400769

Epoch: 6| Step: 11
Training loss: 3.5149736267229112
Validation loss: 2.885753482363205

Epoch: 6| Step: 12
Training loss: 3.3806163539624285
Validation loss: 2.8911221818017134

Epoch: 6| Step: 13
Training loss: 2.992590655465053
Validation loss: 2.8918525623517617

Epoch: 240| Step: 0
Training loss: 3.407293177462159
Validation loss: 2.8889957944064544

Epoch: 6| Step: 1
Training loss: 2.894424333541165
Validation loss: 2.889882013894691

Epoch: 6| Step: 2
Training loss: 3.6759177171466204
Validation loss: 2.8896957300603305

Epoch: 6| Step: 3
Training loss: 3.383146696783994
Validation loss: 2.889343013801763

Epoch: 6| Step: 4
Training loss: 2.696337518805801
Validation loss: 2.8842867515866324

Epoch: 6| Step: 5
Training loss: 2.789513217613685
Validation loss: 2.887900661341105

Epoch: 6| Step: 6
Training loss: 3.066558017741043
Validation loss: 2.8864808045916663

Epoch: 6| Step: 7
Training loss: 2.601069406512467
Validation loss: 2.886011652190896

Epoch: 6| Step: 8
Training loss: 3.284453363327606
Validation loss: 2.885102065895508

Epoch: 6| Step: 9
Training loss: 3.881644551099642
Validation loss: 2.887939892872233

Epoch: 6| Step: 10
Training loss: 2.9465695235981553
Validation loss: 2.887102990055823

Epoch: 6| Step: 11
Training loss: 2.5770706332692246
Validation loss: 2.8861670363372594

Epoch: 6| Step: 12
Training loss: 3.6653719841547545
Validation loss: 2.8894136976673157

Epoch: 6| Step: 13
Training loss: 3.3150977259251473
Validation loss: 2.884031725203699

Epoch: 241| Step: 0
Training loss: 2.932845953708376
Validation loss: 2.886567667449752

Epoch: 6| Step: 1
Training loss: 3.6099118580717278
Validation loss: 2.886060745382125

Epoch: 6| Step: 2
Training loss: 2.9765697088679928
Validation loss: 2.8855530554924935

Epoch: 6| Step: 3
Training loss: 3.6660619294824768
Validation loss: 2.885541137934286

Epoch: 6| Step: 4
Training loss: 3.265078266134577
Validation loss: 2.888769980779259

Epoch: 6| Step: 5
Training loss: 2.7583660834482036
Validation loss: 2.887169694841804

Epoch: 6| Step: 6
Training loss: 3.5009036941074285
Validation loss: 2.882950303798373

Epoch: 6| Step: 7
Training loss: 3.3688224487440874
Validation loss: 2.881280043923177

Epoch: 6| Step: 8
Training loss: 3.552152631126559
Validation loss: 2.880417767426118

Epoch: 6| Step: 9
Training loss: 3.0916756505570033
Validation loss: 2.8857919613222878

Epoch: 6| Step: 10
Training loss: 2.254026624615401
Validation loss: 2.8828730934343074

Epoch: 6| Step: 11
Training loss: 2.6814301721463725
Validation loss: 2.884067594220925

Epoch: 6| Step: 12
Training loss: 3.612582676347328
Validation loss: 2.8869049231143338

Epoch: 6| Step: 13
Training loss: 2.437825499100069
Validation loss: 2.8826822755639605

Epoch: 242| Step: 0
Training loss: 3.0898323300002297
Validation loss: 2.88128829908178

Epoch: 6| Step: 1
Training loss: 3.183121310324996
Validation loss: 2.880742087224824

Epoch: 6| Step: 2
Training loss: 3.12260787960762
Validation loss: 2.8836119591206284

Epoch: 6| Step: 3
Training loss: 3.3612674084798124
Validation loss: 2.877637230527202

Epoch: 6| Step: 4
Training loss: 3.9093937544826423
Validation loss: 2.880294344278538

Epoch: 6| Step: 5
Training loss: 3.5555744783242336
Validation loss: 2.880950401930093

Epoch: 6| Step: 6
Training loss: 2.4237301520036105
Validation loss: 2.8805845237059033

Epoch: 6| Step: 7
Training loss: 2.9598618619491837
Validation loss: 2.8799729997185044

Epoch: 6| Step: 8
Training loss: 2.6731294955059046
Validation loss: 2.8835600655050904

Epoch: 6| Step: 9
Training loss: 2.514362089278992
Validation loss: 2.8808635708163246

Epoch: 6| Step: 10
Training loss: 3.869483959479726
Validation loss: 2.884579072965101

Epoch: 6| Step: 11
Training loss: 2.8761489894194248
Validation loss: 2.8815575014520025

Epoch: 6| Step: 12
Training loss: 3.113030666475986
Validation loss: 2.8862812089689203

Epoch: 6| Step: 13
Training loss: 3.472455219504615
Validation loss: 2.8861698281086707

Epoch: 243| Step: 0
Training loss: 3.401374617553972
Validation loss: 2.8912833739212753

Epoch: 6| Step: 1
Training loss: 2.9109875202232502
Validation loss: 2.8871422457452605

Epoch: 6| Step: 2
Training loss: 3.5898987409927114
Validation loss: 2.901411238032648

Epoch: 6| Step: 3
Training loss: 3.178946143851804
Validation loss: 2.894720464933777

Epoch: 6| Step: 4
Training loss: 3.2041706146361424
Validation loss: 2.884349810720347

Epoch: 6| Step: 5
Training loss: 3.68384940270554
Validation loss: 2.8800942424824223

Epoch: 6| Step: 6
Training loss: 2.797598974200337
Validation loss: 2.88099146508675

Epoch: 6| Step: 7
Training loss: 2.6467735442226585
Validation loss: 2.87771446556001

Epoch: 6| Step: 8
Training loss: 2.804901794917619
Validation loss: 2.8787593045185234

Epoch: 6| Step: 9
Training loss: 3.183052550576865
Validation loss: 2.878700840194502

Epoch: 6| Step: 10
Training loss: 2.8495780833293063
Validation loss: 2.878395556986672

Epoch: 6| Step: 11
Training loss: 3.047100195754368
Validation loss: 2.8797028497850765

Epoch: 6| Step: 12
Training loss: 3.3446230595299307
Validation loss: 2.8806127748502806

Epoch: 6| Step: 13
Training loss: 3.8060568473928416
Validation loss: 2.879389844940667

Epoch: 244| Step: 0
Training loss: 3.305330110300864
Validation loss: 2.8790728988207936

Epoch: 6| Step: 1
Training loss: 2.962839446760535
Validation loss: 2.88215495737346

Epoch: 6| Step: 2
Training loss: 2.9323511654027334
Validation loss: 2.882737128591403

Epoch: 6| Step: 3
Training loss: 2.341548037889703
Validation loss: 2.887875299134033

Epoch: 6| Step: 4
Training loss: 3.286488012471021
Validation loss: 2.8938966381767894

Epoch: 6| Step: 5
Training loss: 3.272479442884487
Validation loss: 2.890606872093786

Epoch: 6| Step: 6
Training loss: 4.019765893372948
Validation loss: 2.9021483008972706

Epoch: 6| Step: 7
Training loss: 3.078699358493816
Validation loss: 2.8815630280883258

Epoch: 6| Step: 8
Training loss: 2.9265214011854894
Validation loss: 2.876879950852732

Epoch: 6| Step: 9
Training loss: 2.894593684749637
Validation loss: 2.8783805878070208

Epoch: 6| Step: 10
Training loss: 3.0726275464270802
Validation loss: 2.8791730457157656

Epoch: 6| Step: 11
Training loss: 4.05797994486298
Validation loss: 2.8839644055910623

Epoch: 6| Step: 12
Training loss: 3.240456728120857
Validation loss: 2.885555751018067

Epoch: 6| Step: 13
Training loss: 2.1849368746649755
Validation loss: 2.887713261597697

Epoch: 245| Step: 0
Training loss: 2.8740196215040075
Validation loss: 2.9023084442787366

Epoch: 6| Step: 1
Training loss: 2.4674103397671896
Validation loss: 2.8908773509975587

Epoch: 6| Step: 2
Training loss: 3.2814530082754527
Validation loss: 2.895428439258072

Epoch: 6| Step: 3
Training loss: 2.877661758237792
Validation loss: 2.8796629798934053

Epoch: 6| Step: 4
Training loss: 3.1525288921003316
Validation loss: 2.877232017315746

Epoch: 6| Step: 5
Training loss: 3.199027962870372
Validation loss: 2.8750418490110037

Epoch: 6| Step: 6
Training loss: 3.817969978945858
Validation loss: 2.878677363295106

Epoch: 6| Step: 7
Training loss: 3.7860777749820316
Validation loss: 2.8936319247063658

Epoch: 6| Step: 8
Training loss: 3.462403135631784
Validation loss: 2.910438805667694

Epoch: 6| Step: 9
Training loss: 2.740398464605469
Validation loss: 2.95055306271338

Epoch: 6| Step: 10
Training loss: 3.2960980842310477
Validation loss: 2.97945757311214

Epoch: 6| Step: 11
Training loss: 2.8876862304874935
Validation loss: 2.94365866900205

Epoch: 6| Step: 12
Training loss: 3.3949172455669734
Validation loss: 2.9233955435229495

Epoch: 6| Step: 13
Training loss: 2.9125948321575788
Validation loss: 2.9070878670771654

Epoch: 246| Step: 0
Training loss: 3.4421022990760584
Validation loss: 2.8952883879510094

Epoch: 6| Step: 1
Training loss: 3.1936356077965034
Validation loss: 2.885305465084215

Epoch: 6| Step: 2
Training loss: 2.8609968078232804
Validation loss: 2.8869268412376003

Epoch: 6| Step: 3
Training loss: 3.004390682451724
Validation loss: 2.8739987859694915

Epoch: 6| Step: 4
Training loss: 3.4535842521069857
Validation loss: 2.874439634308919

Epoch: 6| Step: 5
Training loss: 2.935108266260032
Validation loss: 2.8747678728098425

Epoch: 6| Step: 6
Training loss: 2.9751493849233626
Validation loss: 2.8815734763557233

Epoch: 6| Step: 7
Training loss: 3.051262928623937
Validation loss: 2.880375667208252

Epoch: 6| Step: 8
Training loss: 3.421278113297402
Validation loss: 2.8803420583287167

Epoch: 6| Step: 9
Training loss: 3.953351281968575
Validation loss: 2.8767144137199434

Epoch: 6| Step: 10
Training loss: 3.2058161153811064
Validation loss: 2.8754125916986135

Epoch: 6| Step: 11
Training loss: 2.8295247528778464
Validation loss: 2.8733894684454464

Epoch: 6| Step: 12
Training loss: 3.140705468204985
Validation loss: 2.873175442894332

Epoch: 6| Step: 13
Training loss: 2.5815597311406098
Validation loss: 2.8693167015352383

Epoch: 247| Step: 0
Training loss: 3.3786254060489473
Validation loss: 2.867532670933822

Epoch: 6| Step: 1
Training loss: 3.566468287384857
Validation loss: 2.869028057767674

Epoch: 6| Step: 2
Training loss: 3.268693422371258
Validation loss: 2.8735281684323466

Epoch: 6| Step: 3
Training loss: 3.4532456873175907
Validation loss: 2.8713663009361237

Epoch: 6| Step: 4
Training loss: 3.388587726350729
Validation loss: 2.8717413666267864

Epoch: 6| Step: 5
Training loss: 2.3616120299500682
Validation loss: 2.870211993890273

Epoch: 6| Step: 6
Training loss: 3.2930809716846894
Validation loss: 2.8768857128184835

Epoch: 6| Step: 7
Training loss: 2.7128658417132017
Validation loss: 2.8738870727090404

Epoch: 6| Step: 8
Training loss: 3.4830864546563225
Validation loss: 2.8808700838858052

Epoch: 6| Step: 9
Training loss: 3.2091580771707116
Validation loss: 2.877423687536422

Epoch: 6| Step: 10
Training loss: 2.881473881759508
Validation loss: 2.8743071093424404

Epoch: 6| Step: 11
Training loss: 3.1344300467771884
Validation loss: 2.8796953298769985

Epoch: 6| Step: 12
Training loss: 3.5804987200939937
Validation loss: 2.8903777660034375

Epoch: 6| Step: 13
Training loss: 1.2460096085699912
Validation loss: 2.8846723207187672

Epoch: 248| Step: 0
Training loss: 3.0479382347096506
Validation loss: 2.8812143577140166

Epoch: 6| Step: 1
Training loss: 3.4318136172692006
Validation loss: 2.878204242748024

Epoch: 6| Step: 2
Training loss: 3.2449436468512416
Validation loss: 2.8713008807852773

Epoch: 6| Step: 3
Training loss: 2.6104566879025755
Validation loss: 2.8709483137944733

Epoch: 6| Step: 4
Training loss: 3.0870626595442854
Validation loss: 2.8719452032473507

Epoch: 6| Step: 5
Training loss: 3.225727555171526
Validation loss: 2.868717382388002

Epoch: 6| Step: 6
Training loss: 3.573972199488245
Validation loss: 2.867095606917472

Epoch: 6| Step: 7
Training loss: 2.7681232095980888
Validation loss: 2.865059999127143

Epoch: 6| Step: 8
Training loss: 3.2925453140048644
Validation loss: 2.867464522314216

Epoch: 6| Step: 9
Training loss: 3.242408101493527
Validation loss: 2.863111139073621

Epoch: 6| Step: 10
Training loss: 2.9323966965687576
Validation loss: 2.867157683265381

Epoch: 6| Step: 11
Training loss: 3.767306636918453
Validation loss: 2.8671974301994005

Epoch: 6| Step: 12
Training loss: 2.945519720827082
Validation loss: 2.87148258070014

Epoch: 6| Step: 13
Training loss: 2.766171589949757
Validation loss: 2.8642713240727304

Epoch: 249| Step: 0
Training loss: 3.030238975946084
Validation loss: 2.8664303716794204

Epoch: 6| Step: 1
Training loss: 3.2657907252263
Validation loss: 2.869940794727515

Epoch: 6| Step: 2
Training loss: 3.411973816264711
Validation loss: 2.867383223915171

Epoch: 6| Step: 3
Training loss: 3.2577466340576375
Validation loss: 2.8658018650935686

Epoch: 6| Step: 4
Training loss: 3.170206166491625
Validation loss: 2.8685171254200075

Epoch: 6| Step: 5
Training loss: 2.991297337962096
Validation loss: 2.8699335029307185

Epoch: 6| Step: 6
Training loss: 3.372584573577454
Validation loss: 2.865189437211279

Epoch: 6| Step: 7
Training loss: 2.934058425612835
Validation loss: 2.8686522646598305

Epoch: 6| Step: 8
Training loss: 3.6099121222538795
Validation loss: 2.869725680273321

Epoch: 6| Step: 9
Training loss: 2.741640911348491
Validation loss: 2.868208889329159

Epoch: 6| Step: 10
Training loss: 3.487778032493305
Validation loss: 2.8723723890950077

Epoch: 6| Step: 11
Training loss: 2.5576971681724068
Validation loss: 2.8769367074054877

Epoch: 6| Step: 12
Training loss: 3.166441825781672
Validation loss: 2.8784609628472144

Epoch: 6| Step: 13
Training loss: 3.0320869155645256
Validation loss: 2.8784645600952543

Epoch: 250| Step: 0
Training loss: 2.8290080172552243
Validation loss: 2.8865261205380497

Epoch: 6| Step: 1
Training loss: 2.2451253644438416
Validation loss: 2.889392506441732

Epoch: 6| Step: 2
Training loss: 3.446945253349673
Validation loss: 2.8893817031511912

Epoch: 6| Step: 3
Training loss: 3.2332360662662847
Validation loss: 2.885743806131057

Epoch: 6| Step: 4
Training loss: 2.7673677460066965
Validation loss: 2.891399148844426

Epoch: 6| Step: 5
Training loss: 3.5235338557362454
Validation loss: 2.8858245579667545

Epoch: 6| Step: 6
Training loss: 3.595328075734949
Validation loss: 2.874284557156712

Epoch: 6| Step: 7
Training loss: 3.4891734931125256
Validation loss: 2.869273626260086

Epoch: 6| Step: 8
Training loss: 3.3313073359094596
Validation loss: 2.866655196879746

Epoch: 6| Step: 9
Training loss: 3.4329187556453076
Validation loss: 2.8642466172508865

Epoch: 6| Step: 10
Training loss: 3.171825389755966
Validation loss: 2.864014691754045

Epoch: 6| Step: 11
Training loss: 3.6275786074659675
Validation loss: 2.866861914185784

Epoch: 6| Step: 12
Training loss: 2.5933740182478404
Validation loss: 2.864511548407892

Epoch: 6| Step: 13
Training loss: 2.2518010878046235
Validation loss: 2.8671502091386074

Epoch: 251| Step: 0
Training loss: 3.7161327736974155
Validation loss: 2.8632210048045477

Epoch: 6| Step: 1
Training loss: 3.0144334722009036
Validation loss: 2.865235125687005

Epoch: 6| Step: 2
Training loss: 3.223907782549132
Validation loss: 2.865030504750895

Epoch: 6| Step: 3
Training loss: 3.0670770190916365
Validation loss: 2.864723388887506

Epoch: 6| Step: 4
Training loss: 2.77440821893084
Validation loss: 2.867867423732916

Epoch: 6| Step: 5
Training loss: 2.479766602146873
Validation loss: 2.864183941664611

Epoch: 6| Step: 6
Training loss: 3.1255189083334782
Validation loss: 2.865592044791078

Epoch: 6| Step: 7
Training loss: 2.8393980828299368
Validation loss: 2.87125852546046

Epoch: 6| Step: 8
Training loss: 3.6855062493620756
Validation loss: 2.8680838047084993

Epoch: 6| Step: 9
Training loss: 3.6750361693801654
Validation loss: 2.8778528724732557

Epoch: 6| Step: 10
Training loss: 3.147495933572507
Validation loss: 2.8675833705393354

Epoch: 6| Step: 11
Training loss: 3.346429482093637
Validation loss: 2.8656375398733993

Epoch: 6| Step: 12
Training loss: 2.9597039786085384
Validation loss: 2.86215408075689

Epoch: 6| Step: 13
Training loss: 2.8461922020419412
Validation loss: 2.866867757093934

Epoch: 252| Step: 0
Training loss: 2.8610279746049616
Validation loss: 2.8653295487334436

Epoch: 6| Step: 1
Training loss: 3.2211389657343665
Validation loss: 2.862283214960267

Epoch: 6| Step: 2
Training loss: 3.146261291362399
Validation loss: 2.8627767972574474

Epoch: 6| Step: 3
Training loss: 2.724199030339574
Validation loss: 2.859050117898696

Epoch: 6| Step: 4
Training loss: 3.831357626468959
Validation loss: 2.8635839036993658

Epoch: 6| Step: 5
Training loss: 2.791482852938472
Validation loss: 2.8614273026662045

Epoch: 6| Step: 6
Training loss: 3.0320622250656273
Validation loss: 2.858491303439919

Epoch: 6| Step: 7
Training loss: 3.368965688393147
Validation loss: 2.862730294920177

Epoch: 6| Step: 8
Training loss: 2.8419772480880106
Validation loss: 2.8632160587793964

Epoch: 6| Step: 9
Training loss: 3.163711189264075
Validation loss: 2.8599211549292396

Epoch: 6| Step: 10
Training loss: 3.5790169616109706
Validation loss: 2.8612754831774274

Epoch: 6| Step: 11
Training loss: 3.4912646138793284
Validation loss: 2.8595084285822407

Epoch: 6| Step: 12
Training loss: 2.998140394510456
Validation loss: 2.861347391697217

Epoch: 6| Step: 13
Training loss: 2.7817632651617425
Validation loss: 2.861679882163553

Epoch: 253| Step: 0
Training loss: 3.062277960999753
Validation loss: 2.8638406157995893

Epoch: 6| Step: 1
Training loss: 2.873078077031453
Validation loss: 2.855022522760788

Epoch: 6| Step: 2
Training loss: 3.029960436672851
Validation loss: 2.868735750492595

Epoch: 6| Step: 3
Training loss: 2.6752982713062297
Validation loss: 2.884131733688658

Epoch: 6| Step: 4
Training loss: 3.625543093283052
Validation loss: 2.873865127391609

Epoch: 6| Step: 5
Training loss: 3.0880567782227293
Validation loss: 2.8811131793013733

Epoch: 6| Step: 6
Training loss: 3.187390194665811
Validation loss: 2.8811606626812423

Epoch: 6| Step: 7
Training loss: 3.5034045962832767
Validation loss: 2.890025042504041

Epoch: 6| Step: 8
Training loss: 2.5334941193937928
Validation loss: 2.873825857156532

Epoch: 6| Step: 9
Training loss: 2.9854842915477087
Validation loss: 2.8778057906211867

Epoch: 6| Step: 10
Training loss: 3.509854068819902
Validation loss: 2.870702299156103

Epoch: 6| Step: 11
Training loss: 3.1833170951975016
Validation loss: 2.8629959430554446

Epoch: 6| Step: 12
Training loss: 3.1896277413161913
Validation loss: 2.8569115491631774

Epoch: 6| Step: 13
Training loss: 3.860760274144094
Validation loss: 2.8573457369358186

Epoch: 254| Step: 0
Training loss: 2.760484994486504
Validation loss: 2.8547057009631644

Epoch: 6| Step: 1
Training loss: 3.3716923081734627
Validation loss: 2.8587517729621084

Epoch: 6| Step: 2
Training loss: 3.189794873665009
Validation loss: 2.855843486998065

Epoch: 6| Step: 3
Training loss: 3.294172001538507
Validation loss: 2.8556449446019383

Epoch: 6| Step: 4
Training loss: 2.7732277374460677
Validation loss: 2.8558211471847383

Epoch: 6| Step: 5
Training loss: 3.0850813438535716
Validation loss: 2.857764665852148

Epoch: 6| Step: 6
Training loss: 3.907707491763748
Validation loss: 2.8557778494969273

Epoch: 6| Step: 7
Training loss: 3.11572675012709
Validation loss: 2.85588270827122

Epoch: 6| Step: 8
Training loss: 3.4813235482300318
Validation loss: 2.8553798753674693

Epoch: 6| Step: 9
Training loss: 3.176951888236726
Validation loss: 2.85434283371617

Epoch: 6| Step: 10
Training loss: 2.8031731132537376
Validation loss: 2.8546031070009

Epoch: 6| Step: 11
Training loss: 3.073124730884229
Validation loss: 2.855793584393559

Epoch: 6| Step: 12
Training loss: 2.725346947377809
Validation loss: 2.8555467974048847

Epoch: 6| Step: 13
Training loss: 3.241638872539021
Validation loss: 2.8572034797704724

Epoch: 255| Step: 0
Training loss: 2.2753435776721407
Validation loss: 2.8557140858314045

Epoch: 6| Step: 1
Training loss: 3.1855576524955636
Validation loss: 2.855438707649084

Epoch: 6| Step: 2
Training loss: 3.137325850437166
Validation loss: 2.85550899810278

Epoch: 6| Step: 3
Training loss: 2.852154730345982
Validation loss: 2.8579447631374357

Epoch: 6| Step: 4
Training loss: 2.943794810608051
Validation loss: 2.8556980039736706

Epoch: 6| Step: 5
Training loss: 2.9372329590533863
Validation loss: 2.8662394752150178

Epoch: 6| Step: 6
Training loss: 3.451836945591462
Validation loss: 2.8605634448777035

Epoch: 6| Step: 7
Training loss: 3.0399738112375663
Validation loss: 2.8595622325438335

Epoch: 6| Step: 8
Training loss: 3.521836147415601
Validation loss: 2.8615383027462595

Epoch: 6| Step: 9
Training loss: 2.7062118633305405
Validation loss: 2.8684766281654848

Epoch: 6| Step: 10
Training loss: 3.940079343742376
Validation loss: 2.8631014024359858

Epoch: 6| Step: 11
Training loss: 3.2303308828841417
Validation loss: 2.8635534451381726

Epoch: 6| Step: 12
Training loss: 3.4779540973637277
Validation loss: 2.858195012476666

Epoch: 6| Step: 13
Training loss: 3.053680019630819
Validation loss: 2.858236266217555

Epoch: 256| Step: 0
Training loss: 2.321092468076472
Validation loss: 2.8595407017568517

Epoch: 6| Step: 1
Training loss: 3.1240008473511156
Validation loss: 2.8628825673812837

Epoch: 6| Step: 2
Training loss: 3.531658587828309
Validation loss: 2.860829923295024

Epoch: 6| Step: 3
Training loss: 2.5804421848797223
Validation loss: 2.862870486498476

Epoch: 6| Step: 4
Training loss: 3.371728229598652
Validation loss: 2.861120313454453

Epoch: 6| Step: 5
Training loss: 2.8162516685105015
Validation loss: 2.8631814972500713

Epoch: 6| Step: 6
Training loss: 3.6238298829594475
Validation loss: 2.872009487578946

Epoch: 6| Step: 7
Training loss: 3.0206181592052816
Validation loss: 2.8597533703409286

Epoch: 6| Step: 8
Training loss: 3.018597338747527
Validation loss: 2.8558536792666422

Epoch: 6| Step: 9
Training loss: 2.9256922628114537
Validation loss: 2.8574857755043612

Epoch: 6| Step: 10
Training loss: 3.384501892134399
Validation loss: 2.8532527250428745

Epoch: 6| Step: 11
Training loss: 3.4545206555019394
Validation loss: 2.853454470148473

Epoch: 6| Step: 12
Training loss: 3.6810453141047024
Validation loss: 2.849768669125265

Epoch: 6| Step: 13
Training loss: 2.747286151064592
Validation loss: 2.851961708865789

Epoch: 257| Step: 0
Training loss: 3.6186716812434505
Validation loss: 2.850631977844587

Epoch: 6| Step: 1
Training loss: 3.754494326254073
Validation loss: 2.852361060489406

Epoch: 6| Step: 2
Training loss: 3.3166722347142494
Validation loss: 2.852129751376757

Epoch: 6| Step: 3
Training loss: 3.092905256752313
Validation loss: 2.849827849336461

Epoch: 6| Step: 4
Training loss: 3.0011460976050337
Validation loss: 2.8497066323064795

Epoch: 6| Step: 5
Training loss: 3.079555430839219
Validation loss: 2.8539246133971834

Epoch: 6| Step: 6
Training loss: 2.995236111155891
Validation loss: 2.8526489669374975

Epoch: 6| Step: 7
Training loss: 3.352067958179315
Validation loss: 2.8562531670738855

Epoch: 6| Step: 8
Training loss: 3.162528563359152
Validation loss: 2.8591614658098727

Epoch: 6| Step: 9
Training loss: 3.0705355109450547
Validation loss: 2.856082320693015

Epoch: 6| Step: 10
Training loss: 3.7042564241042464
Validation loss: 2.852269147228507

Epoch: 6| Step: 11
Training loss: 2.388845541903304
Validation loss: 2.8512550115172868

Epoch: 6| Step: 12
Training loss: 2.5516060726745935
Validation loss: 2.8533412661119666

Epoch: 6| Step: 13
Training loss: 2.1921310450162803
Validation loss: 2.850962920513917

Epoch: 258| Step: 0
Training loss: 2.7847116765567517
Validation loss: 2.851506899837931

Epoch: 6| Step: 1
Training loss: 3.064456081449737
Validation loss: 2.848114250970927

Epoch: 6| Step: 2
Training loss: 2.8280251838393675
Validation loss: 2.8518035377740576

Epoch: 6| Step: 3
Training loss: 2.508968859117815
Validation loss: 2.8505844302088903

Epoch: 6| Step: 4
Training loss: 2.7455759007861245
Validation loss: 2.851652836713734

Epoch: 6| Step: 5
Training loss: 3.080020688718199
Validation loss: 2.85226632676947

Epoch: 6| Step: 6
Training loss: 3.0390890164432043
Validation loss: 2.850818494157001

Epoch: 6| Step: 7
Training loss: 3.181231449575243
Validation loss: 2.854158076474064

Epoch: 6| Step: 8
Training loss: 3.773372673283403
Validation loss: 2.8550206460643186

Epoch: 6| Step: 9
Training loss: 3.4079784242726094
Validation loss: 2.852331423116244

Epoch: 6| Step: 10
Training loss: 3.6799613057051044
Validation loss: 2.8532892963550265

Epoch: 6| Step: 11
Training loss: 2.5751036539788745
Validation loss: 2.8603448548248793

Epoch: 6| Step: 12
Training loss: 3.6672883951604907
Validation loss: 2.857415173008189

Epoch: 6| Step: 13
Training loss: 3.5557368815068155
Validation loss: 2.8517590338024754

Epoch: 259| Step: 0
Training loss: 2.4110376857627025
Validation loss: 2.851425434166708

Epoch: 6| Step: 1
Training loss: 3.533329444259327
Validation loss: 2.8530976751911568

Epoch: 6| Step: 2
Training loss: 3.4350588366759864
Validation loss: 2.8474819878880155

Epoch: 6| Step: 3
Training loss: 3.361131785375591
Validation loss: 2.849867575745499

Epoch: 6| Step: 4
Training loss: 3.4987549610927307
Validation loss: 2.8514715319822863

Epoch: 6| Step: 5
Training loss: 3.1684049219040022
Validation loss: 2.845846974084889

Epoch: 6| Step: 6
Training loss: 2.838981067117335
Validation loss: 2.8495049223466458

Epoch: 6| Step: 7
Training loss: 3.490576455676042
Validation loss: 2.847471146232323

Epoch: 6| Step: 8
Training loss: 3.1758617283007076
Validation loss: 2.8474317829864106

Epoch: 6| Step: 9
Training loss: 3.083479199095146
Validation loss: 2.846369358615109

Epoch: 6| Step: 10
Training loss: 2.7568491693193353
Validation loss: 2.847130055056699

Epoch: 6| Step: 11
Training loss: 3.399754060938191
Validation loss: 2.847068727926033

Epoch: 6| Step: 12
Training loss: 2.7487719134489
Validation loss: 2.84592747523046

Epoch: 6| Step: 13
Training loss: 2.6705219791538504
Validation loss: 2.8467432041498126

Epoch: 260| Step: 0
Training loss: 3.5551727969724634
Validation loss: 2.8498874169280586

Epoch: 6| Step: 1
Training loss: 3.2923114161261227
Validation loss: 2.8546823931312364

Epoch: 6| Step: 2
Training loss: 3.344352026247217
Validation loss: 2.853607070480775

Epoch: 6| Step: 3
Training loss: 3.823896041829681
Validation loss: 2.8599656403529448

Epoch: 6| Step: 4
Training loss: 3.2838874026660343
Validation loss: 2.871181289982378

Epoch: 6| Step: 5
Training loss: 3.6431271054976277
Validation loss: 2.866469753963873

Epoch: 6| Step: 6
Training loss: 2.3965271539453017
Validation loss: 2.8610286161808234

Epoch: 6| Step: 7
Training loss: 2.792411609913934
Validation loss: 2.8561192058358604

Epoch: 6| Step: 8
Training loss: 2.9730636578162493
Validation loss: 2.8497871557641115

Epoch: 6| Step: 9
Training loss: 3.139426842636814
Validation loss: 2.8464729230192543

Epoch: 6| Step: 10
Training loss: 2.6594738414071046
Validation loss: 2.8459278301496758

Epoch: 6| Step: 11
Training loss: 2.5941121411579955
Validation loss: 2.849194076085153

Epoch: 6| Step: 12
Training loss: 2.6645947593064205
Validation loss: 2.845659503994746

Epoch: 6| Step: 13
Training loss: 3.7107696816494853
Validation loss: 2.844558189893075

Epoch: 261| Step: 0
Training loss: 3.1778772248162546
Validation loss: 2.8461793945835465

Epoch: 6| Step: 1
Training loss: 2.9937724007104913
Validation loss: 2.8476576292031615

Epoch: 6| Step: 2
Training loss: 2.8373848240537463
Validation loss: 2.8487760969921427

Epoch: 6| Step: 3
Training loss: 2.671054290185462
Validation loss: 2.8454839429574905

Epoch: 6| Step: 4
Training loss: 2.824145135408166
Validation loss: 2.847591893044915

Epoch: 6| Step: 5
Training loss: 3.64305564061747
Validation loss: 2.8472060052940273

Epoch: 6| Step: 6
Training loss: 3.488289178409943
Validation loss: 2.8478682937424895

Epoch: 6| Step: 7
Training loss: 3.306255861215859
Validation loss: 2.848845766232792

Epoch: 6| Step: 8
Training loss: 4.182207093228921
Validation loss: 2.847411711762069

Epoch: 6| Step: 9
Training loss: 3.1405014089682313
Validation loss: 2.8463102271876446

Epoch: 6| Step: 10
Training loss: 2.4197133908123827
Validation loss: 2.847607249143

Epoch: 6| Step: 11
Training loss: 2.2159147818254428
Validation loss: 2.8471935229418657

Epoch: 6| Step: 12
Training loss: 3.4405642636626594
Validation loss: 2.846853267502574

Epoch: 6| Step: 13
Training loss: 3.231995670306261
Validation loss: 2.84555276214237

Epoch: 262| Step: 0
Training loss: 2.9910746364942318
Validation loss: 2.8471113449652146

Epoch: 6| Step: 1
Training loss: 3.35928472353264
Validation loss: 2.8550573581538226

Epoch: 6| Step: 2
Training loss: 1.446924001963858
Validation loss: 2.8496550420316016

Epoch: 6| Step: 3
Training loss: 2.8050565768977225
Validation loss: 2.8641697691159616

Epoch: 6| Step: 4
Training loss: 3.479499039601729
Validation loss: 2.868574315546131

Epoch: 6| Step: 5
Training loss: 3.1112925688489357
Validation loss: 2.8791267521065547

Epoch: 6| Step: 6
Training loss: 3.3133214255975423
Validation loss: 2.871396430203494

Epoch: 6| Step: 7
Training loss: 2.7889972753938896
Validation loss: 2.8686284070330834

Epoch: 6| Step: 8
Training loss: 3.719947558002606
Validation loss: 2.874832927812611

Epoch: 6| Step: 9
Training loss: 3.1788505933702993
Validation loss: 2.8572947121183376

Epoch: 6| Step: 10
Training loss: 3.115020687224394
Validation loss: 2.8539465296958024

Epoch: 6| Step: 11
Training loss: 3.3127223965824313
Validation loss: 2.84736121840759

Epoch: 6| Step: 12
Training loss: 3.566239118054699
Validation loss: 2.849730380261004

Epoch: 6| Step: 13
Training loss: 3.2616453607948745
Validation loss: 2.844919216993619

Epoch: 263| Step: 0
Training loss: 3.29894318275518
Validation loss: 2.8430257544576967

Epoch: 6| Step: 1
Training loss: 2.7221155491729805
Validation loss: 2.846195340171209

Epoch: 6| Step: 2
Training loss: 2.996807306855719
Validation loss: 2.845088181867731

Epoch: 6| Step: 3
Training loss: 2.8910037230787977
Validation loss: 2.844041105594918

Epoch: 6| Step: 4
Training loss: 3.684807004183673
Validation loss: 2.8440725816772443

Epoch: 6| Step: 5
Training loss: 3.287087905641415
Validation loss: 2.8442049182109486

Epoch: 6| Step: 6
Training loss: 3.1322206618330806
Validation loss: 2.848245530244375

Epoch: 6| Step: 7
Training loss: 3.4575881768027568
Validation loss: 2.843659129150758

Epoch: 6| Step: 8
Training loss: 3.0511199333351704
Validation loss: 2.84627263217576

Epoch: 6| Step: 9
Training loss: 3.1422260815088485
Validation loss: 2.851946259355787

Epoch: 6| Step: 10
Training loss: 3.311786214830187
Validation loss: 2.851744510035535

Epoch: 6| Step: 11
Training loss: 2.2648415098675967
Validation loss: 2.851834400501058

Epoch: 6| Step: 12
Training loss: 3.162274795173245
Validation loss: 2.8563292839998455

Epoch: 6| Step: 13
Training loss: 3.401319382424968
Validation loss: 2.8556032480875797

Epoch: 264| Step: 0
Training loss: 2.5533599670687726
Validation loss: 2.844266473837356

Epoch: 6| Step: 1
Training loss: 3.6455456138794884
Validation loss: 2.8488860854059874

Epoch: 6| Step: 2
Training loss: 3.9349731330002853
Validation loss: 2.850374868516011

Epoch: 6| Step: 3
Training loss: 3.210752161621849
Validation loss: 2.846802397725976

Epoch: 6| Step: 4
Training loss: 1.498302452835655
Validation loss: 2.8429183726588847

Epoch: 6| Step: 5
Training loss: 3.278453543520775
Validation loss: 2.845249744709896

Epoch: 6| Step: 6
Training loss: 3.0087904888324273
Validation loss: 2.8421998936090795

Epoch: 6| Step: 7
Training loss: 2.8321393433035205
Validation loss: 2.8388536561579913

Epoch: 6| Step: 8
Training loss: 3.247790245611959
Validation loss: 2.83931016336091

Epoch: 6| Step: 9
Training loss: 3.598310148144711
Validation loss: 2.840456462932241

Epoch: 6| Step: 10
Training loss: 3.2331217673650747
Validation loss: 2.843497356022288

Epoch: 6| Step: 11
Training loss: 2.704141591038599
Validation loss: 2.837643888228781

Epoch: 6| Step: 12
Training loss: 3.4161545129266275
Validation loss: 2.838496703083129

Epoch: 6| Step: 13
Training loss: 2.9751489041032744
Validation loss: 2.840901705078786

Epoch: 265| Step: 0
Training loss: 2.9399407169307654
Validation loss: 2.8397030292028953

Epoch: 6| Step: 1
Training loss: 2.904354010239949
Validation loss: 2.8390814922757457

Epoch: 6| Step: 2
Training loss: 3.189267734201681
Validation loss: 2.8393598997051024

Epoch: 6| Step: 3
Training loss: 2.853435747620033
Validation loss: 2.84193626168816

Epoch: 6| Step: 4
Training loss: 3.7103055074505877
Validation loss: 2.8394159941410795

Epoch: 6| Step: 5
Training loss: 3.283510138177534
Validation loss: 2.838214497688608

Epoch: 6| Step: 6
Training loss: 2.324522982648869
Validation loss: 2.8356111793507

Epoch: 6| Step: 7
Training loss: 3.284511144485881
Validation loss: 2.8408568588630985

Epoch: 6| Step: 8
Training loss: 3.006894454560096
Validation loss: 2.8414616636742984

Epoch: 6| Step: 9
Training loss: 3.213288052452227
Validation loss: 2.844875808353237

Epoch: 6| Step: 10
Training loss: 3.1399650829341876
Validation loss: 2.8475326177475546

Epoch: 6| Step: 11
Training loss: 3.1053864474156785
Validation loss: 2.841623962281624

Epoch: 6| Step: 12
Training loss: 3.3838785443164987
Validation loss: 2.848390773786196

Epoch: 6| Step: 13
Training loss: 3.482925866371147
Validation loss: 2.8433431600061305

Epoch: 266| Step: 0
Training loss: 3.0476082726412987
Validation loss: 2.8424461374924626

Epoch: 6| Step: 1
Training loss: 3.470308795568008
Validation loss: 2.841585522171156

Epoch: 6| Step: 2
Training loss: 3.1096577731423203
Validation loss: 2.8377032738723025

Epoch: 6| Step: 3
Training loss: 3.5256761430000663
Validation loss: 2.8374558291806116

Epoch: 6| Step: 4
Training loss: 3.213120954889802
Validation loss: 2.8367494718907356

Epoch: 6| Step: 5
Training loss: 2.8058506670889343
Validation loss: 2.8385297931755096

Epoch: 6| Step: 6
Training loss: 3.377933781211382
Validation loss: 2.8407861589400945

Epoch: 6| Step: 7
Training loss: 2.9645524717446055
Validation loss: 2.8381519662382364

Epoch: 6| Step: 8
Training loss: 3.7061224929979675
Validation loss: 2.834561596270386

Epoch: 6| Step: 9
Training loss: 3.3495773447357053
Validation loss: 2.83596217321763

Epoch: 6| Step: 10
Training loss: 2.616415792534946
Validation loss: 2.83747986940015

Epoch: 6| Step: 11
Training loss: 2.8978154010937134
Validation loss: 2.834921917812079

Epoch: 6| Step: 12
Training loss: 2.6472039064527815
Validation loss: 2.835057152841564

Epoch: 6| Step: 13
Training loss: 2.7347076213708013
Validation loss: 2.837429813689515

Epoch: 267| Step: 0
Training loss: 3.698571862575045
Validation loss: 2.83947414959626

Epoch: 6| Step: 1
Training loss: 2.9455171306567185
Validation loss: 2.8442869503218384

Epoch: 6| Step: 2
Training loss: 2.6084225680978546
Validation loss: 2.847672218827028

Epoch: 6| Step: 3
Training loss: 3.234357750888108
Validation loss: 2.8442111997526704

Epoch: 6| Step: 4
Training loss: 3.086810720005776
Validation loss: 2.8384681375280145

Epoch: 6| Step: 5
Training loss: 3.093256130680134
Validation loss: 2.839366253362125

Epoch: 6| Step: 6
Training loss: 2.9282558350864383
Validation loss: 2.842682506574558

Epoch: 6| Step: 7
Training loss: 3.044171978096271
Validation loss: 2.8376254652230757

Epoch: 6| Step: 8
Training loss: 3.2335879340330336
Validation loss: 2.843592239433872

Epoch: 6| Step: 9
Training loss: 3.5607367719691005
Validation loss: 2.8396661122882683

Epoch: 6| Step: 10
Training loss: 3.5628857320127296
Validation loss: 2.8383860501482454

Epoch: 6| Step: 11
Training loss: 3.1177277443423113
Validation loss: 2.84605612964535

Epoch: 6| Step: 12
Training loss: 2.7129680493417663
Validation loss: 2.835403070660373

Epoch: 6| Step: 13
Training loss: 2.6077300957516325
Validation loss: 2.845495595829462

Epoch: 268| Step: 0
Training loss: 3.2077543718856596
Validation loss: 2.8322359169967637

Epoch: 6| Step: 1
Training loss: 2.8327097112961788
Validation loss: 2.8307987243116517

Epoch: 6| Step: 2
Training loss: 3.198072365481807
Validation loss: 2.8314533046467663

Epoch: 6| Step: 3
Training loss: 3.229059393957031
Validation loss: 2.8325633613966117

Epoch: 6| Step: 4
Training loss: 2.403853374763794
Validation loss: 2.835886549225701

Epoch: 6| Step: 5
Training loss: 3.3162992749973057
Validation loss: 2.835065902488281

Epoch: 6| Step: 6
Training loss: 2.9220492877080155
Validation loss: 2.831094505739392

Epoch: 6| Step: 7
Training loss: 3.9960141588863296
Validation loss: 2.8317678736564376

Epoch: 6| Step: 8
Training loss: 2.4922474821041436
Validation loss: 2.8310770977796804

Epoch: 6| Step: 9
Training loss: 3.4195327058073923
Validation loss: 2.8288195218482866

Epoch: 6| Step: 10
Training loss: 3.4520397293262253
Validation loss: 2.83209158296007

Epoch: 6| Step: 11
Training loss: 2.1175539044541565
Validation loss: 2.833245280259015

Epoch: 6| Step: 12
Training loss: 3.7184696893270943
Validation loss: 2.8308859246445763

Epoch: 6| Step: 13
Training loss: 2.8650231780867186
Validation loss: 2.8343748757603757

Epoch: 269| Step: 0
Training loss: 3.341032260660238
Validation loss: 2.8321453637543796

Epoch: 6| Step: 1
Training loss: 3.6304749546445394
Validation loss: 2.831929679523027

Epoch: 6| Step: 2
Training loss: 3.759126746652725
Validation loss: 2.8343898494178754

Epoch: 6| Step: 3
Training loss: 3.0042573602101657
Validation loss: 2.8355823234429893

Epoch: 6| Step: 4
Training loss: 2.7492404235523202
Validation loss: 2.8288209102353714

Epoch: 6| Step: 5
Training loss: 3.133813864472203
Validation loss: 2.8330665519482414

Epoch: 6| Step: 6
Training loss: 3.2995478927251107
Validation loss: 2.8329137989770867

Epoch: 6| Step: 7
Training loss: 3.1226975160286226
Validation loss: 2.840843663675065

Epoch: 6| Step: 8
Training loss: 2.829449254016528
Validation loss: 2.836338556453417

Epoch: 6| Step: 9
Training loss: 3.1785442724644564
Validation loss: 2.8384829604388986

Epoch: 6| Step: 10
Training loss: 2.9693061709190105
Validation loss: 2.8338299680362615

Epoch: 6| Step: 11
Training loss: 2.4216540820360763
Validation loss: 2.8350470738950824

Epoch: 6| Step: 12
Training loss: 3.455128084450134
Validation loss: 2.831842293155165

Epoch: 6| Step: 13
Training loss: 2.1621360604862905
Validation loss: 2.837421763421503

Epoch: 270| Step: 0
Training loss: 3.1846823112588516
Validation loss: 2.8315238555248463

Epoch: 6| Step: 1
Training loss: 2.680590063300127
Validation loss: 2.8352336307805768

Epoch: 6| Step: 2
Training loss: 3.3072491180005814
Validation loss: 2.833447257423188

Epoch: 6| Step: 3
Training loss: 3.414775293868864
Validation loss: 2.831962849968856

Epoch: 6| Step: 4
Training loss: 2.842107780726844
Validation loss: 2.8317994472303845

Epoch: 6| Step: 5
Training loss: 3.52214970706243
Validation loss: 2.831342419001926

Epoch: 6| Step: 6
Training loss: 2.92513383086429
Validation loss: 2.8314976497212894

Epoch: 6| Step: 7
Training loss: 2.7437638753831246
Validation loss: 2.829207542271912

Epoch: 6| Step: 8
Training loss: 3.2008983781504363
Validation loss: 2.8294238299594183

Epoch: 6| Step: 9
Training loss: 3.3524552870121944
Validation loss: 2.82996338163483

Epoch: 6| Step: 10
Training loss: 2.6004850888725994
Validation loss: 2.8326169078778705

Epoch: 6| Step: 11
Training loss: 3.436492217329413
Validation loss: 2.8277074922306733

Epoch: 6| Step: 12
Training loss: 3.055383627322013
Validation loss: 2.8319355438094753

Epoch: 6| Step: 13
Training loss: 3.5216318312253634
Validation loss: 2.838062241298812

Epoch: 271| Step: 0
Training loss: 3.0415946394522444
Validation loss: 2.8477923773722713

Epoch: 6| Step: 1
Training loss: 2.705986492904256
Validation loss: 2.8515686493595314

Epoch: 6| Step: 2
Training loss: 3.1700220568157316
Validation loss: 2.8408630530541514

Epoch: 6| Step: 3
Training loss: 2.6033886980852228
Validation loss: 2.841647130027962

Epoch: 6| Step: 4
Training loss: 3.2647420611294864
Validation loss: 2.8360663816113654

Epoch: 6| Step: 5
Training loss: 3.1424731230515817
Validation loss: 2.829024815392622

Epoch: 6| Step: 6
Training loss: 3.3122377111849186
Validation loss: 2.828603677369437

Epoch: 6| Step: 7
Training loss: 3.301825544401033
Validation loss: 2.8297002658109953

Epoch: 6| Step: 8
Training loss: 2.670276364371595
Validation loss: 2.8283749038656194

Epoch: 6| Step: 9
Training loss: 3.6754959757874563
Validation loss: 2.827149410489565

Epoch: 6| Step: 10
Training loss: 3.5785099805261265
Validation loss: 2.8280341030033767

Epoch: 6| Step: 11
Training loss: 3.0831049413548572
Validation loss: 2.830390974651866

Epoch: 6| Step: 12
Training loss: 3.015627529953602
Validation loss: 2.8239464582964744

Epoch: 6| Step: 13
Training loss: 2.9847541288651955
Validation loss: 2.8333863398777037

Epoch: 272| Step: 0
Training loss: 3.1405014089682313
Validation loss: 2.835797361019228

Epoch: 6| Step: 1
Training loss: 2.891726722057012
Validation loss: 2.8396199212323148

Epoch: 6| Step: 2
Training loss: 2.925649887008447
Validation loss: 2.8369416352150063

Epoch: 6| Step: 3
Training loss: 3.1306094369103548
Validation loss: 2.8405234914733044

Epoch: 6| Step: 4
Training loss: 2.484319338384911
Validation loss: 2.83618501072226

Epoch: 6| Step: 5
Training loss: 3.142957741502129
Validation loss: 2.831473835312902

Epoch: 6| Step: 6
Training loss: 3.5233257132176834
Validation loss: 2.8271711643813124

Epoch: 6| Step: 7
Training loss: 3.76707069851948
Validation loss: 2.8319900906874187

Epoch: 6| Step: 8
Training loss: 3.2786282192218636
Validation loss: 2.8346084621406002

Epoch: 6| Step: 9
Training loss: 2.488305587290224
Validation loss: 2.8346215714943543

Epoch: 6| Step: 10
Training loss: 3.191791114339741
Validation loss: 2.8367544423723667

Epoch: 6| Step: 11
Training loss: 3.526441963647443
Validation loss: 2.830941983235138

Epoch: 6| Step: 12
Training loss: 2.9186007671883494
Validation loss: 2.847724851043632

Epoch: 6| Step: 13
Training loss: 3.100042090591665
Validation loss: 2.8314445809586397

Epoch: 273| Step: 0
Training loss: 3.246031759429895
Validation loss: 2.8371343972624636

Epoch: 6| Step: 1
Training loss: 3.7767943305188147
Validation loss: 2.8288512497668137

Epoch: 6| Step: 2
Training loss: 2.5847151249942937
Validation loss: 2.828478476362811

Epoch: 6| Step: 3
Training loss: 3.681901723168649
Validation loss: 2.819654281390043

Epoch: 6| Step: 4
Training loss: 3.5947752443813767
Validation loss: 2.8253276657793447

Epoch: 6| Step: 5
Training loss: 3.4393411040815085
Validation loss: 2.8253015522224283

Epoch: 6| Step: 6
Training loss: 2.5377217200616973
Validation loss: 2.81890699951949

Epoch: 6| Step: 7
Training loss: 3.1849672315220356
Validation loss: 2.8249932299478475

Epoch: 6| Step: 8
Training loss: 2.7456111565303214
Validation loss: 2.819652774838798

Epoch: 6| Step: 9
Training loss: 2.9938095118713854
Validation loss: 2.8198081190372974

Epoch: 6| Step: 10
Training loss: 2.6993358713623135
Validation loss: 2.8217655579520633

Epoch: 6| Step: 11
Training loss: 3.157264470900242
Validation loss: 2.825874718297871

Epoch: 6| Step: 12
Training loss: 2.862858219304248
Validation loss: 2.8292628612007524

Epoch: 6| Step: 13
Training loss: 2.7292511808010733
Validation loss: 2.8320514745842313

Epoch: 274| Step: 0
Training loss: 3.682256818046217
Validation loss: 2.8339393849441117

Epoch: 6| Step: 1
Training loss: 3.027567406052813
Validation loss: 2.8389707501596706

Epoch: 6| Step: 2
Training loss: 2.492706627426063
Validation loss: 2.8428284509660835

Epoch: 6| Step: 3
Training loss: 3.4667635891887976
Validation loss: 2.838671559235656

Epoch: 6| Step: 4
Training loss: 3.587652988694023
Validation loss: 2.8288976619683996

Epoch: 6| Step: 5
Training loss: 2.989087603115151
Validation loss: 2.819482875790849

Epoch: 6| Step: 6
Training loss: 3.057002212538588
Validation loss: 2.8173956143734253

Epoch: 6| Step: 7
Training loss: 3.2251493670745557
Validation loss: 2.8195798811635173

Epoch: 6| Step: 8
Training loss: 2.779880658064928
Validation loss: 2.8202139435805726

Epoch: 6| Step: 9
Training loss: 3.1501485940913896
Validation loss: 2.8206337193718403

Epoch: 6| Step: 10
Training loss: 2.7437676987479067
Validation loss: 2.822915009589417

Epoch: 6| Step: 11
Training loss: 2.731614468696273
Validation loss: 2.8247915785461895

Epoch: 6| Step: 12
Training loss: 3.626192094195219
Validation loss: 2.8208988359555085

Epoch: 6| Step: 13
Training loss: 2.9762651590332134
Validation loss: 2.8223003478564266

Epoch: 275| Step: 0
Training loss: 3.260958755489692
Validation loss: 2.8226035919663035

Epoch: 6| Step: 1
Training loss: 3.837000557770936
Validation loss: 2.8208838670256045

Epoch: 6| Step: 2
Training loss: 3.057166613090512
Validation loss: 2.8221641790545884

Epoch: 6| Step: 3
Training loss: 3.075036993036819
Validation loss: 2.822373220319693

Epoch: 6| Step: 4
Training loss: 2.8810050280976305
Validation loss: 2.82523588570927

Epoch: 6| Step: 5
Training loss: 3.210380561587633
Validation loss: 2.8217168988249344

Epoch: 6| Step: 6
Training loss: 2.6992572610539622
Validation loss: 2.824146368143403

Epoch: 6| Step: 7
Training loss: 3.026194338249208
Validation loss: 2.844451203023643

Epoch: 6| Step: 8
Training loss: 2.91636129324695
Validation loss: 2.8296161972336673

Epoch: 6| Step: 9
Training loss: 3.5540561660338517
Validation loss: 2.823284060934768

Epoch: 6| Step: 10
Training loss: 2.7998558654471934
Validation loss: 2.8227752676167417

Epoch: 6| Step: 11
Training loss: 2.511916560664239
Validation loss: 2.8236309071688668

Epoch: 6| Step: 12
Training loss: 3.163077646205172
Validation loss: 2.8239033364236863

Epoch: 6| Step: 13
Training loss: 3.791211838044365
Validation loss: 2.826582985959091

Epoch: 276| Step: 0
Training loss: 3.169812363327074
Validation loss: 2.820871901639653

Epoch: 6| Step: 1
Training loss: 2.885826953862896
Validation loss: 2.8173241901140536

Epoch: 6| Step: 2
Training loss: 3.645907911718619
Validation loss: 2.8198189406799914

Epoch: 6| Step: 3
Training loss: 2.494465041364647
Validation loss: 2.820356731188964

Epoch: 6| Step: 4
Training loss: 3.0852881412323083
Validation loss: 2.817485733584994

Epoch: 6| Step: 5
Training loss: 2.7606850163761085
Validation loss: 2.820894109268416

Epoch: 6| Step: 6
Training loss: 3.4889743710093457
Validation loss: 2.8168825976086564

Epoch: 6| Step: 7
Training loss: 3.431001937042908
Validation loss: 2.818423311578821

Epoch: 6| Step: 8
Training loss: 2.6250981812054226
Validation loss: 2.820006685888306

Epoch: 6| Step: 9
Training loss: 3.0482503281171334
Validation loss: 2.817326192016218

Epoch: 6| Step: 10
Training loss: 2.6437695080914416
Validation loss: 2.8170550050333762

Epoch: 6| Step: 11
Training loss: 3.7715546706615646
Validation loss: 2.817402667253608

Epoch: 6| Step: 12
Training loss: 2.9099999302605166
Validation loss: 2.8139404008379607

Epoch: 6| Step: 13
Training loss: 3.5312289347062507
Validation loss: 2.81821119010308

Epoch: 277| Step: 0
Training loss: 3.220989596255631
Validation loss: 2.816972804217817

Epoch: 6| Step: 1
Training loss: 3.2784032189025267
Validation loss: 2.814650415583712

Epoch: 6| Step: 2
Training loss: 3.0859452259594744
Validation loss: 2.8191780520014134

Epoch: 6| Step: 3
Training loss: 3.417331971933146
Validation loss: 2.8182307824956836

Epoch: 6| Step: 4
Training loss: 2.9386548957704353
Validation loss: 2.812640140373605

Epoch: 6| Step: 5
Training loss: 3.2734219134194107
Validation loss: 2.817358387867354

Epoch: 6| Step: 6
Training loss: 3.4484450443463577
Validation loss: 2.816707094206616

Epoch: 6| Step: 7
Training loss: 3.0693131002073564
Validation loss: 2.814273760737629

Epoch: 6| Step: 8
Training loss: 3.1200445939814094
Validation loss: 2.8156754882877713

Epoch: 6| Step: 9
Training loss: 3.2973269473717295
Validation loss: 2.8161427523641684

Epoch: 6| Step: 10
Training loss: 2.198619699960066
Validation loss: 2.8208984606199454

Epoch: 6| Step: 11
Training loss: 2.869625209035499
Validation loss: 2.8186650185816484

Epoch: 6| Step: 12
Training loss: 3.2055970120040262
Validation loss: 2.817737759262929

Epoch: 6| Step: 13
Training loss: 2.955925476456279
Validation loss: 2.818281164647472

Epoch: 278| Step: 0
Training loss: 2.5121462444814213
Validation loss: 2.8286591712435287

Epoch: 6| Step: 1
Training loss: 3.0419981440551633
Validation loss: 2.8320121323757426

Epoch: 6| Step: 2
Training loss: 2.590599812752163
Validation loss: 2.8352300573487206

Epoch: 6| Step: 3
Training loss: 3.299159989227786
Validation loss: 2.8211597838708578

Epoch: 6| Step: 4
Training loss: 3.4825092332529977
Validation loss: 2.823976115776662

Epoch: 6| Step: 5
Training loss: 3.3153573434209465
Validation loss: 2.8219071659741446

Epoch: 6| Step: 6
Training loss: 3.219068048559602
Validation loss: 2.815603133554837

Epoch: 6| Step: 7
Training loss: 3.5482637484637625
Validation loss: 2.816224923699178

Epoch: 6| Step: 8
Training loss: 2.4741611330667066
Validation loss: 2.814133743621721

Epoch: 6| Step: 9
Training loss: 3.349525953316152
Validation loss: 2.8108637891604715

Epoch: 6| Step: 10
Training loss: 2.8224110918934304
Validation loss: 2.8121021914605135

Epoch: 6| Step: 11
Training loss: 3.4517394172913476
Validation loss: 2.812136266743909

Epoch: 6| Step: 12
Training loss: 3.0313907865884238
Validation loss: 2.812093705850314

Epoch: 6| Step: 13
Training loss: 3.3070603817946007
Validation loss: 2.8120010717339716

Epoch: 279| Step: 0
Training loss: 3.0464564891859083
Validation loss: 2.8139234415895613

Epoch: 6| Step: 1
Training loss: 3.4138373468734864
Validation loss: 2.813726141943967

Epoch: 6| Step: 2
Training loss: 3.157458234617987
Validation loss: 2.815426087111186

Epoch: 6| Step: 3
Training loss: 2.696198867786974
Validation loss: 2.812192506741411

Epoch: 6| Step: 4
Training loss: 3.04328903060148
Validation loss: 2.8146841157317444

Epoch: 6| Step: 5
Training loss: 3.3970662474642213
Validation loss: 2.813686174493994

Epoch: 6| Step: 6
Training loss: 2.619194786882893
Validation loss: 2.814243732279864

Epoch: 6| Step: 7
Training loss: 3.30633979776374
Validation loss: 2.815298565363036

Epoch: 6| Step: 8
Training loss: 2.8102549599477427
Validation loss: 2.813910737801965

Epoch: 6| Step: 9
Training loss: 2.498923069741021
Validation loss: 2.816959208658848

Epoch: 6| Step: 10
Training loss: 3.053496379774567
Validation loss: 2.8144188755489963

Epoch: 6| Step: 11
Training loss: 3.219160479695096
Validation loss: 2.8136561342984225

Epoch: 6| Step: 12
Training loss: 3.916727525495253
Validation loss: 2.8130669025889588

Epoch: 6| Step: 13
Training loss: 3.1611982780138104
Validation loss: 2.815132338512568

Epoch: 280| Step: 0
Training loss: 3.451455934121939
Validation loss: 2.813803473967455

Epoch: 6| Step: 1
Training loss: 3.698601515130362
Validation loss: 2.815127894467077

Epoch: 6| Step: 2
Training loss: 2.513509678442772
Validation loss: 2.819523817615114

Epoch: 6| Step: 3
Training loss: 3.3169898069016366
Validation loss: 2.8177646525718147

Epoch: 6| Step: 4
Training loss: 3.401390739313379
Validation loss: 2.8245549457501316

Epoch: 6| Step: 5
Training loss: 3.0671160417065177
Validation loss: 2.8243065202027027

Epoch: 6| Step: 6
Training loss: 2.4092635073265845
Validation loss: 2.8323118538856993

Epoch: 6| Step: 7
Training loss: 3.3719898504826213
Validation loss: 2.8189264615734784

Epoch: 6| Step: 8
Training loss: 2.831877353038328
Validation loss: 2.815464556581265

Epoch: 6| Step: 9
Training loss: 3.0354212739726654
Validation loss: 2.828145033151781

Epoch: 6| Step: 10
Training loss: 3.319327892844768
Validation loss: 2.8167702546293976

Epoch: 6| Step: 11
Training loss: 3.065181881360438
Validation loss: 2.811547807050605

Epoch: 6| Step: 12
Training loss: 2.6365435054610735
Validation loss: 2.816461572778892

Epoch: 6| Step: 13
Training loss: 3.219322820265396
Validation loss: 2.812178949150548

Epoch: 281| Step: 0
Training loss: 3.2477820237402737
Validation loss: 2.8124075492694884

Epoch: 6| Step: 1
Training loss: 2.711111717232739
Validation loss: 2.8097761174043225

Epoch: 6| Step: 2
Training loss: 3.559349942809903
Validation loss: 2.811128259481374

Epoch: 6| Step: 3
Training loss: 3.3639295354169487
Validation loss: 2.813146206122476

Epoch: 6| Step: 4
Training loss: 2.639681675821994
Validation loss: 2.808058689610132

Epoch: 6| Step: 5
Training loss: 3.482253176999154
Validation loss: 2.809501027101994

Epoch: 6| Step: 6
Training loss: 2.925690958949744
Validation loss: 2.811276477582209

Epoch: 6| Step: 7
Training loss: 3.2679986677412214
Validation loss: 2.808788739542799

Epoch: 6| Step: 8
Training loss: 3.4067040936926736
Validation loss: 2.8086467950532414

Epoch: 6| Step: 9
Training loss: 2.78092483162687
Validation loss: 2.806355740535373

Epoch: 6| Step: 10
Training loss: 2.890635557413153
Validation loss: 2.8086155782419526

Epoch: 6| Step: 11
Training loss: 3.6593179465389865
Validation loss: 2.809716330824723

Epoch: 6| Step: 12
Training loss: 2.551540851676382
Validation loss: 2.8129769908632034

Epoch: 6| Step: 13
Training loss: 2.4819391172874057
Validation loss: 2.8138242933089557

Epoch: 282| Step: 0
Training loss: 3.0744272086248543
Validation loss: 2.8328453532875986

Epoch: 6| Step: 1
Training loss: 3.1480029542223242
Validation loss: 2.8467249318885997

Epoch: 6| Step: 2
Training loss: 3.0134103183139525
Validation loss: 2.8595761249076146

Epoch: 6| Step: 3
Training loss: 2.809610875022192
Validation loss: 2.8380848681381243

Epoch: 6| Step: 4
Training loss: 3.272631270512958
Validation loss: 2.837096377948829

Epoch: 6| Step: 5
Training loss: 3.114393468745017
Validation loss: 2.8233785912399907

Epoch: 6| Step: 6
Training loss: 3.426282996012181
Validation loss: 2.8106815489125347

Epoch: 6| Step: 7
Training loss: 3.5580093456658055
Validation loss: 2.8134624370377783

Epoch: 6| Step: 8
Training loss: 3.3294351354130405
Validation loss: 2.814218115285288

Epoch: 6| Step: 9
Training loss: 3.634741617540611
Validation loss: 2.8108555424169896

Epoch: 6| Step: 10
Training loss: 2.2223818430263913
Validation loss: 2.8118864440725204

Epoch: 6| Step: 11
Training loss: 2.8311124587176417
Validation loss: 2.8185836605760337

Epoch: 6| Step: 12
Training loss: 2.945917446836666
Validation loss: 2.8201605434009074

Epoch: 6| Step: 13
Training loss: 2.980060914460314
Validation loss: 2.8268536824163313

Epoch: 283| Step: 0
Training loss: 2.847824698700109
Validation loss: 2.8425974402835172

Epoch: 6| Step: 1
Training loss: 2.554614891396973
Validation loss: 2.8276114619914208

Epoch: 6| Step: 2
Training loss: 3.1824597170213904
Validation loss: 2.8167686091051967

Epoch: 6| Step: 3
Training loss: 3.033093078935805
Validation loss: 2.815078967612289

Epoch: 6| Step: 4
Training loss: 2.851228375651812
Validation loss: 2.815763278057886

Epoch: 6| Step: 5
Training loss: 3.096969778571823
Validation loss: 2.815433111234207

Epoch: 6| Step: 6
Training loss: 2.5204730971856204
Validation loss: 2.814315456984511

Epoch: 6| Step: 7
Training loss: 3.776112242291248
Validation loss: 2.810650408515348

Epoch: 6| Step: 8
Training loss: 2.9138355320143576
Validation loss: 2.813995002272839

Epoch: 6| Step: 9
Training loss: 3.524550031796363
Validation loss: 2.811468502655572

Epoch: 6| Step: 10
Training loss: 3.435845549126324
Validation loss: 2.811097593698013

Epoch: 6| Step: 11
Training loss: 3.386881224926953
Validation loss: 2.812898176986869

Epoch: 6| Step: 12
Training loss: 2.729393655980955
Validation loss: 2.815632361751068

Epoch: 6| Step: 13
Training loss: 3.708520363080973
Validation loss: 2.819209548330983

Epoch: 284| Step: 0
Training loss: 2.989338207939636
Validation loss: 2.823316007240067

Epoch: 6| Step: 1
Training loss: 3.056269165478235
Validation loss: 2.8238955099601313

Epoch: 6| Step: 2
Training loss: 3.340403513261338
Validation loss: 2.8194700324759405

Epoch: 6| Step: 3
Training loss: 3.1840041194486566
Validation loss: 2.81688369882763

Epoch: 6| Step: 4
Training loss: 2.965616761207191
Validation loss: 2.8105887542358916

Epoch: 6| Step: 5
Training loss: 3.269186897328681
Validation loss: 2.8101872422838414

Epoch: 6| Step: 6
Training loss: 4.255424627863562
Validation loss: 2.80440345925695

Epoch: 6| Step: 7
Training loss: 2.951607935138235
Validation loss: 2.8085360285708654

Epoch: 6| Step: 8
Training loss: 2.87287260210317
Validation loss: 2.8042261801883446

Epoch: 6| Step: 9
Training loss: 2.5728097396644882
Validation loss: 2.7998204348011804

Epoch: 6| Step: 10
Training loss: 3.6045142798107173
Validation loss: 2.804972237666797

Epoch: 6| Step: 11
Training loss: 3.12056188145559
Validation loss: 2.8000758175099874

Epoch: 6| Step: 12
Training loss: 1.8918153152654078
Validation loss: 2.8026718321897297

Epoch: 6| Step: 13
Training loss: 2.76909381118187
Validation loss: 2.800537715262155

Epoch: 285| Step: 0
Training loss: 3.251735370665547
Validation loss: 2.8018636187726624

Epoch: 6| Step: 1
Training loss: 3.2392190971740504
Validation loss: 2.802609998731607

Epoch: 6| Step: 2
Training loss: 3.349479401405092
Validation loss: 2.799635419021616

Epoch: 6| Step: 3
Training loss: 3.072771713372544
Validation loss: 2.8026986624259087

Epoch: 6| Step: 4
Training loss: 3.347768490132702
Validation loss: 2.8039204950660834

Epoch: 6| Step: 5
Training loss: 2.9660502154060135
Validation loss: 2.8052127915337937

Epoch: 6| Step: 6
Training loss: 3.1911038240274565
Validation loss: 2.80971646951252

Epoch: 6| Step: 7
Training loss: 2.850246847070162
Validation loss: 2.8090788986603177

Epoch: 6| Step: 8
Training loss: 3.2929612201500507
Validation loss: 2.8099355165184847

Epoch: 6| Step: 9
Training loss: 2.7672130098895624
Validation loss: 2.8133432562079155

Epoch: 6| Step: 10
Training loss: 3.591186670740128
Validation loss: 2.8135002882328894

Epoch: 6| Step: 11
Training loss: 2.7464346748665487
Validation loss: 2.8097446604023166

Epoch: 6| Step: 12
Training loss: 3.0131299068630155
Validation loss: 2.806603474151013

Epoch: 6| Step: 13
Training loss: 2.3483235811888816
Validation loss: 2.804547037197355

Epoch: 286| Step: 0
Training loss: 3.048519531898188
Validation loss: 2.8018530306393608

Epoch: 6| Step: 1
Training loss: 3.3185910059313484
Validation loss: 2.8011694294303395

Epoch: 6| Step: 2
Training loss: 2.8265097204608405
Validation loss: 2.7975413677306435

Epoch: 6| Step: 3
Training loss: 3.055694180050921
Validation loss: 2.794863187844893

Epoch: 6| Step: 4
Training loss: 2.8192359792961654
Validation loss: 2.7978158810621756

Epoch: 6| Step: 5
Training loss: 2.5094912605384283
Validation loss: 2.7970666288668076

Epoch: 6| Step: 6
Training loss: 2.9698656094133407
Validation loss: 2.7956020886481285

Epoch: 6| Step: 7
Training loss: 3.626444824623703
Validation loss: 2.7968345937527324

Epoch: 6| Step: 8
Training loss: 3.462302324181585
Validation loss: 2.797026883477399

Epoch: 6| Step: 9
Training loss: 2.727653569304692
Validation loss: 2.794864591265713

Epoch: 6| Step: 10
Training loss: 3.363031712577907
Validation loss: 2.7965146284767344

Epoch: 6| Step: 11
Training loss: 2.8632422804945312
Validation loss: 2.796375469513448

Epoch: 6| Step: 12
Training loss: 3.438023891408125
Validation loss: 2.8023476327137438

Epoch: 6| Step: 13
Training loss: 3.348761110248198
Validation loss: 2.797165874388839

Epoch: 287| Step: 0
Training loss: 3.081456429335179
Validation loss: 2.7943794949492653

Epoch: 6| Step: 1
Training loss: 3.1111396114618253
Validation loss: 2.79559106413623

Epoch: 6| Step: 2
Training loss: 3.3411584240900885
Validation loss: 2.7994622886169913

Epoch: 6| Step: 3
Training loss: 3.485434743070879
Validation loss: 2.7942194561455906

Epoch: 6| Step: 4
Training loss: 2.9222284603012025
Validation loss: 2.797744072404113

Epoch: 6| Step: 5
Training loss: 3.040537811942494
Validation loss: 2.7999808136111253

Epoch: 6| Step: 6
Training loss: 2.8847890967858585
Validation loss: 2.8031485949883317

Epoch: 6| Step: 7
Training loss: 3.330876605379748
Validation loss: 2.8064224699923788

Epoch: 6| Step: 8
Training loss: 2.8388443438408397
Validation loss: 2.8204714018154697

Epoch: 6| Step: 9
Training loss: 2.83808199925747
Validation loss: 2.8268942962118713

Epoch: 6| Step: 10
Training loss: 3.133119030651324
Validation loss: 2.8213830199602663

Epoch: 6| Step: 11
Training loss: 3.1485206460504522
Validation loss: 2.8067954965055035

Epoch: 6| Step: 12
Training loss: 2.9183779101522895
Validation loss: 2.7989353765381724

Epoch: 6| Step: 13
Training loss: 3.546782908315402
Validation loss: 2.7903022854287594

Epoch: 288| Step: 0
Training loss: 3.7737056407867406
Validation loss: 2.792200342066145

Epoch: 6| Step: 1
Training loss: 3.246591688174181
Validation loss: 2.7943206927314423

Epoch: 6| Step: 2
Training loss: 2.8767446117368896
Validation loss: 2.793270306779877

Epoch: 6| Step: 3
Training loss: 3.4670898313720846
Validation loss: 2.797452112610739

Epoch: 6| Step: 4
Training loss: 3.222120575744904
Validation loss: 2.792248221003644

Epoch: 6| Step: 5
Training loss: 2.895232945690977
Validation loss: 2.7935773481711115

Epoch: 6| Step: 6
Training loss: 3.2592303440548522
Validation loss: 2.7950859129176306

Epoch: 6| Step: 7
Training loss: 2.8297215797229947
Validation loss: 2.7967047997895453

Epoch: 6| Step: 8
Training loss: 3.4134983321135937
Validation loss: 2.792495000088956

Epoch: 6| Step: 9
Training loss: 2.8284041124732884
Validation loss: 2.7929872151504544

Epoch: 6| Step: 10
Training loss: 2.270849058697582
Validation loss: 2.7933513099112917

Epoch: 6| Step: 11
Training loss: 3.475515006344552
Validation loss: 2.796404932598647

Epoch: 6| Step: 12
Training loss: 2.8422542453035917
Validation loss: 2.7983773035611734

Epoch: 6| Step: 13
Training loss: 2.3770619526558234
Validation loss: 2.7968057658364547

Epoch: 289| Step: 0
Training loss: 3.2750819771094446
Validation loss: 2.7975553545655316

Epoch: 6| Step: 1
Training loss: 3.431053358881097
Validation loss: 2.8063357875276296

Epoch: 6| Step: 2
Training loss: 3.5358041749127
Validation loss: 2.7968124618225163

Epoch: 6| Step: 3
Training loss: 3.2592076669167414
Validation loss: 2.807392774604268

Epoch: 6| Step: 4
Training loss: 2.2771157204528487
Validation loss: 2.805709770478526

Epoch: 6| Step: 5
Training loss: 2.7523655687258315
Validation loss: 2.8042165426112433

Epoch: 6| Step: 6
Training loss: 2.694392923690583
Validation loss: 2.8180617538302015

Epoch: 6| Step: 7
Training loss: 2.998651201306949
Validation loss: 2.8156254401016616

Epoch: 6| Step: 8
Training loss: 3.4171515485130843
Validation loss: 2.8114038097234113

Epoch: 6| Step: 9
Training loss: 3.078441622952713
Validation loss: 2.8128256624058667

Epoch: 6| Step: 10
Training loss: 2.8117173695435014
Validation loss: 2.8024272940130674

Epoch: 6| Step: 11
Training loss: 3.1478126985021
Validation loss: 2.7983548860917558

Epoch: 6| Step: 12
Training loss: 3.168955995985458
Validation loss: 2.795733941082129

Epoch: 6| Step: 13
Training loss: 3.456412567123242
Validation loss: 2.7926015309424916

Epoch: 290| Step: 0
Training loss: 2.5453881914605976
Validation loss: 2.7920749483907334

Epoch: 6| Step: 1
Training loss: 2.956124049400968
Validation loss: 2.793469851456389

Epoch: 6| Step: 2
Training loss: 3.019806645753065
Validation loss: 2.7955382904005726

Epoch: 6| Step: 3
Training loss: 3.050468165002841
Validation loss: 2.790036602724759

Epoch: 6| Step: 4
Training loss: 3.1824328968198574
Validation loss: 2.7878166107581803

Epoch: 6| Step: 5
Training loss: 2.4751782324222797
Validation loss: 2.792412119444985

Epoch: 6| Step: 6
Training loss: 3.0822685740178337
Validation loss: 2.788351087090064

Epoch: 6| Step: 7
Training loss: 3.531001664603421
Validation loss: 2.790667158578978

Epoch: 6| Step: 8
Training loss: 3.549426266151708
Validation loss: 2.792565754882763

Epoch: 6| Step: 9
Training loss: 3.995282968136725
Validation loss: 2.7961533028314594

Epoch: 6| Step: 10
Training loss: 2.996532343427162
Validation loss: 2.794883979498091

Epoch: 6| Step: 11
Training loss: 2.882577943434589
Validation loss: 2.7950159410201905

Epoch: 6| Step: 12
Training loss: 3.0115735604088134
Validation loss: 2.794510487684108

Epoch: 6| Step: 13
Training loss: 2.4773013580169483
Validation loss: 2.7942854166785214

Epoch: 291| Step: 0
Training loss: 3.44493367367969
Validation loss: 2.7949674371620308

Epoch: 6| Step: 1
Training loss: 2.9424434216293345
Validation loss: 2.799512627590765

Epoch: 6| Step: 2
Training loss: 3.5881609370989005
Validation loss: 2.8013491211683723

Epoch: 6| Step: 3
Training loss: 3.127257180427312
Validation loss: 2.798045943712056

Epoch: 6| Step: 4
Training loss: 2.1708198014885225
Validation loss: 2.797908919771459

Epoch: 6| Step: 5
Training loss: 3.5284227514191002
Validation loss: 2.794657965278657

Epoch: 6| Step: 6
Training loss: 2.9308949334774836
Validation loss: 2.790251926377834

Epoch: 6| Step: 7
Training loss: 2.966488910735978
Validation loss: 2.789725428720667

Epoch: 6| Step: 8
Training loss: 2.994861334391201
Validation loss: 2.7880154855598547

Epoch: 6| Step: 9
Training loss: 3.0658715820691604
Validation loss: 2.7904888754717176

Epoch: 6| Step: 10
Training loss: 2.5231540390811737
Validation loss: 2.7880131398591055

Epoch: 6| Step: 11
Training loss: 3.099565223230362
Validation loss: 2.7877113629292833

Epoch: 6| Step: 12
Training loss: 3.3476006982883524
Validation loss: 2.793890689018928

Epoch: 6| Step: 13
Training loss: 3.525749310873506
Validation loss: 2.796287567967267

Epoch: 292| Step: 0
Training loss: 2.7438306966050368
Validation loss: 2.806109949273171

Epoch: 6| Step: 1
Training loss: 3.184429410070917
Validation loss: 2.7980303174450083

Epoch: 6| Step: 2
Training loss: 3.1130891786148354
Validation loss: 2.7962346386821606

Epoch: 6| Step: 3
Training loss: 2.800693654242779
Validation loss: 2.7931365537757955

Epoch: 6| Step: 4
Training loss: 3.391362263908991
Validation loss: 2.788807489485204

Epoch: 6| Step: 5
Training loss: 2.9710514182947705
Validation loss: 2.7892512887816667

Epoch: 6| Step: 6
Training loss: 2.95687273172579
Validation loss: 2.788237856569266

Epoch: 6| Step: 7
Training loss: 3.261857044691702
Validation loss: 2.7892897994033254

Epoch: 6| Step: 8
Training loss: 3.2814829425778216
Validation loss: 2.791164471180204

Epoch: 6| Step: 9
Training loss: 2.388170565560073
Validation loss: 2.789205656223586

Epoch: 6| Step: 10
Training loss: 3.571354219480131
Validation loss: 2.7867072353725817

Epoch: 6| Step: 11
Training loss: 3.394087328927575
Validation loss: 2.7859869825788435

Epoch: 6| Step: 12
Training loss: 3.1854923882142763
Validation loss: 2.7903988003449394

Epoch: 6| Step: 13
Training loss: 2.855479771374934
Validation loss: 2.790748278606278

Epoch: 293| Step: 0
Training loss: 2.7924649724582054
Validation loss: 2.7870271225078445

Epoch: 6| Step: 1
Training loss: 3.1340223150085706
Validation loss: 2.78522704395372

Epoch: 6| Step: 2
Training loss: 3.5486804551434727
Validation loss: 2.7895813553523494

Epoch: 6| Step: 3
Training loss: 3.584720047537027
Validation loss: 2.791806243385034

Epoch: 6| Step: 4
Training loss: 3.704141340537468
Validation loss: 2.7865940383344663

Epoch: 6| Step: 5
Training loss: 3.072721123804647
Validation loss: 2.7856162975515057

Epoch: 6| Step: 6
Training loss: 2.684389576633653
Validation loss: 2.794712005025762

Epoch: 6| Step: 7
Training loss: 2.830076440109057
Validation loss: 2.798483588505047

Epoch: 6| Step: 8
Training loss: 3.0835588389919515
Validation loss: 2.793870597439321

Epoch: 6| Step: 9
Training loss: 2.7671824234970286
Validation loss: 2.789191747924379

Epoch: 6| Step: 10
Training loss: 2.6304716576429024
Validation loss: 2.793654073421984

Epoch: 6| Step: 11
Training loss: 3.1815406591589155
Validation loss: 2.805166181206639

Epoch: 6| Step: 12
Training loss: 2.74502686006228
Validation loss: 2.8048318430500045

Epoch: 6| Step: 13
Training loss: 3.4503816089492894
Validation loss: 2.7998030136916436

Epoch: 294| Step: 0
Training loss: 2.99063859097413
Validation loss: 2.7978853614485235

Epoch: 6| Step: 1
Training loss: 3.1243312883152305
Validation loss: 2.8082920694981803

Epoch: 6| Step: 2
Training loss: 3.561192322702797
Validation loss: 2.8012275991737408

Epoch: 6| Step: 3
Training loss: 3.231072993198688
Validation loss: 2.7981441604299913

Epoch: 6| Step: 4
Training loss: 3.548017007092439
Validation loss: 2.7984011692197917

Epoch: 6| Step: 5
Training loss: 2.445237228648811
Validation loss: 2.7877173997812164

Epoch: 6| Step: 6
Training loss: 3.025386999927218
Validation loss: 2.7828737445620804

Epoch: 6| Step: 7
Training loss: 3.0617294899259835
Validation loss: 2.7874052536262313

Epoch: 6| Step: 8
Training loss: 3.2480248538226744
Validation loss: 2.7818090327061995

Epoch: 6| Step: 9
Training loss: 2.9096256463637276
Validation loss: 2.784067301153819

Epoch: 6| Step: 10
Training loss: 2.7215878813678422
Validation loss: 2.7863049714592716

Epoch: 6| Step: 11
Training loss: 2.9925750401775644
Validation loss: 2.786962115189163

Epoch: 6| Step: 12
Training loss: 3.106840548035571
Validation loss: 2.784291735997768

Epoch: 6| Step: 13
Training loss: 3.248754996471665
Validation loss: 2.785079666205675

Epoch: 295| Step: 0
Training loss: 3.7404108150289517
Validation loss: 2.7850379805404226

Epoch: 6| Step: 1
Training loss: 2.489141917233901
Validation loss: 2.7843109096598124

Epoch: 6| Step: 2
Training loss: 3.4803158504925173
Validation loss: 2.7830182416323797

Epoch: 6| Step: 3
Training loss: 2.8428811223592696
Validation loss: 2.7866120774539733

Epoch: 6| Step: 4
Training loss: 2.1421557890856433
Validation loss: 2.788019295135501

Epoch: 6| Step: 5
Training loss: 3.674263165363854
Validation loss: 2.783839691369127

Epoch: 6| Step: 6
Training loss: 3.361341743508147
Validation loss: 2.7875718288730997

Epoch: 6| Step: 7
Training loss: 2.6317407254635157
Validation loss: 2.7861345736531664

Epoch: 6| Step: 8
Training loss: 3.7128998717664974
Validation loss: 2.782446485574063

Epoch: 6| Step: 9
Training loss: 2.576030273247767
Validation loss: 2.7849567936013693

Epoch: 6| Step: 10
Training loss: 3.4091650012663477
Validation loss: 2.785819835880143

Epoch: 6| Step: 11
Training loss: 3.2384150975523776
Validation loss: 2.7903409827526118

Epoch: 6| Step: 12
Training loss: 2.9615313656595226
Validation loss: 2.781337747253137

Epoch: 6| Step: 13
Training loss: 1.828002599547393
Validation loss: 2.7835879148709273

Epoch: 296| Step: 0
Training loss: 3.6507406867998524
Validation loss: 2.785609990635087

Epoch: 6| Step: 1
Training loss: 2.962482783915396
Validation loss: 2.789157486079407

Epoch: 6| Step: 2
Training loss: 3.1066655761760495
Validation loss: 2.7879417886026254

Epoch: 6| Step: 3
Training loss: 2.9772487059662542
Validation loss: 2.787090016388287

Epoch: 6| Step: 4
Training loss: 3.5783852561686174
Validation loss: 2.7862004164271283

Epoch: 6| Step: 5
Training loss: 3.3966435751038033
Validation loss: 2.791935856464045

Epoch: 6| Step: 6
Training loss: 2.7914741411769115
Validation loss: 2.796102993231361

Epoch: 6| Step: 7
Training loss: 2.3427717074490797
Validation loss: 2.7964786494583374

Epoch: 6| Step: 8
Training loss: 3.0090320047062775
Validation loss: 2.790411987854453

Epoch: 6| Step: 9
Training loss: 2.8886150898745875
Validation loss: 2.8006605253675447

Epoch: 6| Step: 10
Training loss: 3.46244114574445
Validation loss: 2.789213933889757

Epoch: 6| Step: 11
Training loss: 3.0280886810297787
Validation loss: 2.7831553069236263

Epoch: 6| Step: 12
Training loss: 2.8377662836232216
Validation loss: 2.788321201475653

Epoch: 6| Step: 13
Training loss: 2.867582621361071
Validation loss: 2.7809257968206245

Epoch: 297| Step: 0
Training loss: 3.3639075640884433
Validation loss: 2.781539241972986

Epoch: 6| Step: 1
Training loss: 3.3991820473465992
Validation loss: 2.780928698852933

Epoch: 6| Step: 2
Training loss: 3.0812770757201307
Validation loss: 2.7808966509559037

Epoch: 6| Step: 3
Training loss: 2.972911768594907
Validation loss: 2.7763746927186954

Epoch: 6| Step: 4
Training loss: 2.896491289291309
Validation loss: 2.7819203473051712

Epoch: 6| Step: 5
Training loss: 2.928911355523691
Validation loss: 2.7812039854384922

Epoch: 6| Step: 6
Training loss: 3.374708374987524
Validation loss: 2.7776529672400083

Epoch: 6| Step: 7
Training loss: 2.362844379494033
Validation loss: 2.7822255148283292

Epoch: 6| Step: 8
Training loss: 2.674329912626223
Validation loss: 2.779444413643343

Epoch: 6| Step: 9
Training loss: 3.3771718419357013
Validation loss: 2.7826685853163844

Epoch: 6| Step: 10
Training loss: 2.736064802919318
Validation loss: 2.778406948152699

Epoch: 6| Step: 11
Training loss: 3.0448067712468974
Validation loss: 2.779367121800307

Epoch: 6| Step: 12
Training loss: 3.6678629282026076
Validation loss: 2.7814943031858688

Epoch: 6| Step: 13
Training loss: 3.228403374485393
Validation loss: 2.788182913473638

Epoch: 298| Step: 0
Training loss: 3.0165615702775552
Validation loss: 2.783890638827465

Epoch: 6| Step: 1
Training loss: 3.7956508342756323
Validation loss: 2.7875283549076157

Epoch: 6| Step: 2
Training loss: 3.0022078972484203
Validation loss: 2.784201191511562

Epoch: 6| Step: 3
Training loss: 3.6203197652046626
Validation loss: 2.779022080301497

Epoch: 6| Step: 4
Training loss: 2.371403832560992
Validation loss: 2.7779245547685356

Epoch: 6| Step: 5
Training loss: 3.658977045821767
Validation loss: 2.7815148159640297

Epoch: 6| Step: 6
Training loss: 2.792099012991113
Validation loss: 2.778810152428654

Epoch: 6| Step: 7
Training loss: 2.849764656924062
Validation loss: 2.7726463362190974

Epoch: 6| Step: 8
Training loss: 3.0703305154131133
Validation loss: 2.7744852728490352

Epoch: 6| Step: 9
Training loss: 3.4607323441504576
Validation loss: 2.778214622794265

Epoch: 6| Step: 10
Training loss: 2.810681751400149
Validation loss: 2.778209222765248

Epoch: 6| Step: 11
Training loss: 2.688673960640445
Validation loss: 2.7775158076339843

Epoch: 6| Step: 12
Training loss: 2.8791858221613893
Validation loss: 2.7773802095044506

Epoch: 6| Step: 13
Training loss: 2.6641129743431446
Validation loss: 2.7768210154564645

Epoch: 299| Step: 0
Training loss: 3.356210753142126
Validation loss: 2.775764567092127

Epoch: 6| Step: 1
Training loss: 2.8384823480876666
Validation loss: 2.774305858375295

Epoch: 6| Step: 2
Training loss: 3.0787825293609394
Validation loss: 2.7791759596770116

Epoch: 6| Step: 3
Training loss: 3.4966452733619704
Validation loss: 2.7788194924888785

Epoch: 6| Step: 4
Training loss: 2.678914484126535
Validation loss: 2.7725132239919303

Epoch: 6| Step: 5
Training loss: 3.7565068060352376
Validation loss: 2.7784913187092406

Epoch: 6| Step: 6
Training loss: 2.423325332023218
Validation loss: 2.7759084183381035

Epoch: 6| Step: 7
Training loss: 2.8994349488238114
Validation loss: 2.7819329594226385

Epoch: 6| Step: 8
Training loss: 3.287005218288178
Validation loss: 2.7745655400765354

Epoch: 6| Step: 9
Training loss: 2.5569112356187684
Validation loss: 2.774839557501966

Epoch: 6| Step: 10
Training loss: 3.4525579616976505
Validation loss: 2.77941790128083

Epoch: 6| Step: 11
Training loss: 2.943756582977645
Validation loss: 2.781281962711683

Epoch: 6| Step: 12
Training loss: 3.074049056724602
Validation loss: 2.7819544476261067

Epoch: 6| Step: 13
Training loss: 3.0368055578042275
Validation loss: 2.780543570486022

Epoch: 300| Step: 0
Training loss: 3.267812771760233
Validation loss: 2.784327400155775

Epoch: 6| Step: 1
Training loss: 2.631320066266682
Validation loss: 2.7808397429957923

Epoch: 6| Step: 2
Training loss: 2.962239887391239
Validation loss: 2.785885236102865

Epoch: 6| Step: 3
Training loss: 3.1559366504997803
Validation loss: 2.7949910925403803

Epoch: 6| Step: 4
Training loss: 2.977150045563513
Validation loss: 2.7937656795354164

Epoch: 6| Step: 5
Training loss: 3.089651610601127
Validation loss: 2.8066139274441366

Epoch: 6| Step: 6
Training loss: 2.750907054777285
Validation loss: 2.810548588017381

Epoch: 6| Step: 7
Training loss: 2.93013245319001
Validation loss: 2.808514494548345

Epoch: 6| Step: 8
Training loss: 3.0467000275280234
Validation loss: 2.8017661180471296

Epoch: 6| Step: 9
Training loss: 2.9268635478377076
Validation loss: 2.7865787793267263

Epoch: 6| Step: 10
Training loss: 2.9936956285226044
Validation loss: 2.788768319519176

Epoch: 6| Step: 11
Training loss: 3.442457473702755
Validation loss: 2.7817275533837007

Epoch: 6| Step: 12
Training loss: 3.87002305391133
Validation loss: 2.775682298908182

Epoch: 6| Step: 13
Training loss: 2.834763465177195
Validation loss: 2.773088985200386

Epoch: 301| Step: 0
Training loss: 3.419188537924391
Validation loss: 2.777750975640177

Epoch: 6| Step: 1
Training loss: 3.170448771819833
Validation loss: 2.772012690119888

Epoch: 6| Step: 2
Training loss: 3.143492343423025
Validation loss: 2.7789601560512995

Epoch: 6| Step: 3
Training loss: 3.3884218151162586
Validation loss: 2.7773011340764513

Epoch: 6| Step: 4
Training loss: 3.73895557344727
Validation loss: 2.773606054697592

Epoch: 6| Step: 5
Training loss: 3.448008617700132
Validation loss: 2.7759292937800493

Epoch: 6| Step: 6
Training loss: 3.0720033139568574
Validation loss: 2.77509584602253

Epoch: 6| Step: 7
Training loss: 2.844669067765623
Validation loss: 2.778192178278084

Epoch: 6| Step: 8
Training loss: 1.9873481764475296
Validation loss: 2.773929880501578

Epoch: 6| Step: 9
Training loss: 3.2513209372836815
Validation loss: 2.773059910431748

Epoch: 6| Step: 10
Training loss: 2.4556544195768777
Validation loss: 2.777299978393798

Epoch: 6| Step: 11
Training loss: 2.7599912687522883
Validation loss: 2.7788122558823325

Epoch: 6| Step: 12
Training loss: 2.8567115594399604
Validation loss: 2.77945080003743

Epoch: 6| Step: 13
Training loss: 3.375089432273208
Validation loss: 2.7766653178168825

Epoch: 302| Step: 0
Training loss: 2.8166008616177356
Validation loss: 2.781266368538046

Epoch: 6| Step: 1
Training loss: 3.2307797412561614
Validation loss: 2.7738437944841507

Epoch: 6| Step: 2
Training loss: 3.5562626628951977
Validation loss: 2.7803854239714667

Epoch: 6| Step: 3
Training loss: 2.8896221998956686
Validation loss: 2.7806277840161293

Epoch: 6| Step: 4
Training loss: 2.816983019727854
Validation loss: 2.7884697317960114

Epoch: 6| Step: 5
Training loss: 3.3516481473067437
Validation loss: 2.7917157920172433

Epoch: 6| Step: 6
Training loss: 2.8463965875524746
Validation loss: 2.7961637768550895

Epoch: 6| Step: 7
Training loss: 3.3398230479530175
Validation loss: 2.78763422948846

Epoch: 6| Step: 8
Training loss: 3.1961353986511947
Validation loss: 2.791287039295135

Epoch: 6| Step: 9
Training loss: 3.05573147546683
Validation loss: 2.7726912954386007

Epoch: 6| Step: 10
Training loss: 3.025974992990379
Validation loss: 2.771382217266347

Epoch: 6| Step: 11
Training loss: 3.3387787844303647
Validation loss: 2.7757465507586225

Epoch: 6| Step: 12
Training loss: 3.1465486298529215
Validation loss: 2.773459741739222

Epoch: 6| Step: 13
Training loss: 1.8656972899880229
Validation loss: 2.772284107978071

Epoch: 303| Step: 0
Training loss: 3.2428592583449554
Validation loss: 2.7757917811669652

Epoch: 6| Step: 1
Training loss: 3.0214351361534177
Validation loss: 2.771460125852548

Epoch: 6| Step: 2
Training loss: 3.4996302273104902
Validation loss: 2.7746577294859796

Epoch: 6| Step: 3
Training loss: 2.994227259428301
Validation loss: 2.772996927613261

Epoch: 6| Step: 4
Training loss: 2.961716521757108
Validation loss: 2.7742474180024645

Epoch: 6| Step: 5
Training loss: 2.8755122847874217
Validation loss: 2.779636795944718

Epoch: 6| Step: 6
Training loss: 2.3894932879305575
Validation loss: 2.7768801900876126

Epoch: 6| Step: 7
Training loss: 3.0283599919804502
Validation loss: 2.781188555826044

Epoch: 6| Step: 8
Training loss: 3.8881558469141355
Validation loss: 2.7880238164136735

Epoch: 6| Step: 9
Training loss: 2.3373978046781967
Validation loss: 2.7769261525878526

Epoch: 6| Step: 10
Training loss: 3.874678813790142
Validation loss: 2.788289115342387

Epoch: 6| Step: 11
Training loss: 2.4995012739544173
Validation loss: 2.774168513876188

Epoch: 6| Step: 12
Training loss: 2.8387954645114983
Validation loss: 2.773782802717725

Epoch: 6| Step: 13
Training loss: 3.3637431289449577
Validation loss: 2.7727514300866516

Epoch: 304| Step: 0
Training loss: 2.956194377480738
Validation loss: 2.7680444893213245

Epoch: 6| Step: 1
Training loss: 2.0052533297423722
Validation loss: 2.7664721015298372

Epoch: 6| Step: 2
Training loss: 2.646776066432029
Validation loss: 2.766476189122292

Epoch: 6| Step: 3
Training loss: 3.499319146554215
Validation loss: 2.77102266587388

Epoch: 6| Step: 4
Training loss: 3.1317395587076233
Validation loss: 2.771335652189304

Epoch: 6| Step: 5
Training loss: 3.1670418734539094
Validation loss: 2.76591089864808

Epoch: 6| Step: 6
Training loss: 3.251916760307188
Validation loss: 2.7715447643063964

Epoch: 6| Step: 7
Training loss: 2.4845308458881976
Validation loss: 2.7782993830500535

Epoch: 6| Step: 8
Training loss: 3.174261839356117
Validation loss: 2.782196230540845

Epoch: 6| Step: 9
Training loss: 3.0428219173395754
Validation loss: 2.7774605684427707

Epoch: 6| Step: 10
Training loss: 3.094943038095793
Validation loss: 2.7732552657570495

Epoch: 6| Step: 11
Training loss: 3.4537640148628177
Validation loss: 2.7724724210836587

Epoch: 6| Step: 12
Training loss: 3.463016892835066
Validation loss: 2.771853588890151

Epoch: 6| Step: 13
Training loss: 3.597811187158095
Validation loss: 2.765126191634719

Epoch: 305| Step: 0
Training loss: 3.517334924876345
Validation loss: 2.7730570551713374

Epoch: 6| Step: 1
Training loss: 2.9906237627144447
Validation loss: 2.7733633232220725

Epoch: 6| Step: 2
Training loss: 2.428874281424088
Validation loss: 2.767289810214936

Epoch: 6| Step: 3
Training loss: 3.315534245635894
Validation loss: 2.768485065502175

Epoch: 6| Step: 4
Training loss: 3.370716909339934
Validation loss: 2.7674814163448005

Epoch: 6| Step: 5
Training loss: 2.7259230424033376
Validation loss: 2.770149533016268

Epoch: 6| Step: 6
Training loss: 2.5591419826531565
Validation loss: 2.7676547818084862

Epoch: 6| Step: 7
Training loss: 3.399453618521656
Validation loss: 2.7679841866561663

Epoch: 6| Step: 8
Training loss: 2.4428894908455523
Validation loss: 2.769350377793402

Epoch: 6| Step: 9
Training loss: 2.993765233265899
Validation loss: 2.7745406313355176

Epoch: 6| Step: 10
Training loss: 3.339661995922533
Validation loss: 2.7766329344916714

Epoch: 6| Step: 11
Training loss: 2.8749424472521543
Validation loss: 2.7710711734631404

Epoch: 6| Step: 12
Training loss: 3.304731941375231
Validation loss: 2.7718312500977893

Epoch: 6| Step: 13
Training loss: 3.8223669226804433
Validation loss: 2.773030016259571

Epoch: 306| Step: 0
Training loss: 3.1844710375798004
Validation loss: 2.7806596874992726

Epoch: 6| Step: 1
Training loss: 2.976128654201196
Validation loss: 2.7761473350558994

Epoch: 6| Step: 2
Training loss: 2.8659582179365435
Validation loss: 2.7793293490425333

Epoch: 6| Step: 3
Training loss: 3.6048762040171454
Validation loss: 2.7757153601607976

Epoch: 6| Step: 4
Training loss: 3.5220944706011035
Validation loss: 2.7844133517169154

Epoch: 6| Step: 5
Training loss: 2.4288519989757438
Validation loss: 2.7790338236685495

Epoch: 6| Step: 6
Training loss: 2.9419735871768946
Validation loss: 2.766938810706093

Epoch: 6| Step: 7
Training loss: 3.026157781810155
Validation loss: 2.770683460005016

Epoch: 6| Step: 8
Training loss: 2.933461761553087
Validation loss: 2.766317916764508

Epoch: 6| Step: 9
Training loss: 3.1478101233059936
Validation loss: 2.7608213657776592

Epoch: 6| Step: 10
Training loss: 3.0018390740574494
Validation loss: 2.762910231999646

Epoch: 6| Step: 11
Training loss: 2.933199717628531
Validation loss: 2.7615670931846505

Epoch: 6| Step: 12
Training loss: 3.3897186333573583
Validation loss: 2.769463542794033

Epoch: 6| Step: 13
Training loss: 2.809806211855393
Validation loss: 2.7710449815797507

Epoch: 307| Step: 0
Training loss: 2.6936064254840453
Validation loss: 2.76484085348646

Epoch: 6| Step: 1
Training loss: 2.790841526290184
Validation loss: 2.7719267313829286

Epoch: 6| Step: 2
Training loss: 2.825183497858117
Validation loss: 2.771012468736403

Epoch: 6| Step: 3
Training loss: 3.293727294148715
Validation loss: 2.7648714741275824

Epoch: 6| Step: 4
Training loss: 3.638988863968589
Validation loss: 2.7610080191607613

Epoch: 6| Step: 5
Training loss: 3.2953697492637746
Validation loss: 2.7653546306308243

Epoch: 6| Step: 6
Training loss: 2.998842969934437
Validation loss: 2.7650701606917667

Epoch: 6| Step: 7
Training loss: 2.8077403165935424
Validation loss: 2.7653896685181603

Epoch: 6| Step: 8
Training loss: 3.3720451418116464
Validation loss: 2.7619770839690636

Epoch: 6| Step: 9
Training loss: 2.9773271834974357
Validation loss: 2.7681822571346166

Epoch: 6| Step: 10
Training loss: 3.1174550336028335
Validation loss: 2.77221179055602

Epoch: 6| Step: 11
Training loss: 2.2136727926273574
Validation loss: 2.773983450707371

Epoch: 6| Step: 12
Training loss: 3.2767834008172683
Validation loss: 2.770629126473237

Epoch: 6| Step: 13
Training loss: 3.697404652282426
Validation loss: 2.7669456984915004

Epoch: 308| Step: 0
Training loss: 3.5350518479922135
Validation loss: 2.7699317924234776

Epoch: 6| Step: 1
Training loss: 3.2594098536382536
Validation loss: 2.7658389614556778

Epoch: 6| Step: 2
Training loss: 2.7276940388806206
Validation loss: 2.7709318682124913

Epoch: 6| Step: 3
Training loss: 2.467728898582791
Validation loss: 2.7724076319293216

Epoch: 6| Step: 4
Training loss: 2.759265981315638
Validation loss: 2.7679094876981667

Epoch: 6| Step: 5
Training loss: 3.3606516696580426
Validation loss: 2.7658998280871865

Epoch: 6| Step: 6
Training loss: 3.2680532380230183
Validation loss: 2.7690570194504884

Epoch: 6| Step: 7
Training loss: 1.9014399768785752
Validation loss: 2.7630839121098605

Epoch: 6| Step: 8
Training loss: 3.502802408084562
Validation loss: 2.763085502390476

Epoch: 6| Step: 9
Training loss: 3.4795777007629782
Validation loss: 2.7671741271750694

Epoch: 6| Step: 10
Training loss: 2.753630149473882
Validation loss: 2.765802562073206

Epoch: 6| Step: 11
Training loss: 3.1569003200025385
Validation loss: 2.7643195375181664

Epoch: 6| Step: 12
Training loss: 3.5105165793730038
Validation loss: 2.767057153336084

Epoch: 6| Step: 13
Training loss: 2.6280529797060495
Validation loss: 2.766094120005862

Epoch: 309| Step: 0
Training loss: 3.072309393064746
Validation loss: 2.763692480173018

Epoch: 6| Step: 1
Training loss: 2.8621367578041297
Validation loss: 2.76524851860811

Epoch: 6| Step: 2
Training loss: 3.0744982426356544
Validation loss: 2.7603942932101395

Epoch: 6| Step: 3
Training loss: 3.3227736742271086
Validation loss: 2.7654515351005307

Epoch: 6| Step: 4
Training loss: 3.159233571555537
Validation loss: 2.7640574486430913

Epoch: 6| Step: 5
Training loss: 3.3497722263619445
Validation loss: 2.768215682086664

Epoch: 6| Step: 6
Training loss: 2.9466481709079613
Validation loss: 2.7621201060541485

Epoch: 6| Step: 7
Training loss: 3.626386706074269
Validation loss: 2.7602729148528984

Epoch: 6| Step: 8
Training loss: 2.8822543629965582
Validation loss: 2.7629294705327188

Epoch: 6| Step: 9
Training loss: 2.8467604244554203
Validation loss: 2.7623984781138518

Epoch: 6| Step: 10
Training loss: 2.7200712304044763
Validation loss: 2.7651780475695187

Epoch: 6| Step: 11
Training loss: 3.135881171982204
Validation loss: 2.7627631336115313

Epoch: 6| Step: 12
Training loss: 2.8537612589991226
Validation loss: 2.7666284348976644

Epoch: 6| Step: 13
Training loss: 3.001698172271728
Validation loss: 2.766314862247835

Epoch: 310| Step: 0
Training loss: 3.1708393379251483
Validation loss: 2.7715250231807964

Epoch: 6| Step: 1
Training loss: 3.066092583230792
Validation loss: 2.781647426466159

Epoch: 6| Step: 2
Training loss: 2.864815793864569
Validation loss: 2.7692305927010987

Epoch: 6| Step: 3
Training loss: 2.323725800370258
Validation loss: 2.7805145699791

Epoch: 6| Step: 4
Training loss: 2.677277752141039
Validation loss: 2.777101585231521

Epoch: 6| Step: 5
Training loss: 3.022294018007947
Validation loss: 2.774326171111173

Epoch: 6| Step: 6
Training loss: 3.3922972884085993
Validation loss: 2.7747394367378373

Epoch: 6| Step: 7
Training loss: 3.410034736836724
Validation loss: 2.7773332345391726

Epoch: 6| Step: 8
Training loss: 2.8298793009437975
Validation loss: 2.763575305162474

Epoch: 6| Step: 9
Training loss: 2.9367165027882796
Validation loss: 2.7603382293707956

Epoch: 6| Step: 10
Training loss: 3.624529314724313
Validation loss: 2.7632534416342076

Epoch: 6| Step: 11
Training loss: 3.4692657362236115
Validation loss: 2.756363041226248

Epoch: 6| Step: 12
Training loss: 3.0747197093220633
Validation loss: 2.755341176534667

Epoch: 6| Step: 13
Training loss: 2.6538531091741384
Validation loss: 2.766443043401418

Epoch: 311| Step: 0
Training loss: 3.091926114145827
Validation loss: 2.760217172693206

Epoch: 6| Step: 1
Training loss: 2.7532639640523957
Validation loss: 2.7560951314223243

Epoch: 6| Step: 2
Training loss: 2.1451550741982266
Validation loss: 2.763163124414866

Epoch: 6| Step: 3
Training loss: 3.2244366530816397
Validation loss: 2.758570093424908

Epoch: 6| Step: 4
Training loss: 3.4851669985193476
Validation loss: 2.757608846745349

Epoch: 6| Step: 5
Training loss: 3.328133883039055
Validation loss: 2.7601575646642105

Epoch: 6| Step: 6
Training loss: 3.330678327508961
Validation loss: 2.7618884227264733

Epoch: 6| Step: 7
Training loss: 2.6695354547598673
Validation loss: 2.759993466430012

Epoch: 6| Step: 8
Training loss: 2.5913385418616377
Validation loss: 2.7608638609381857

Epoch: 6| Step: 9
Training loss: 3.0704404692638105
Validation loss: 2.7645847632285463

Epoch: 6| Step: 10
Training loss: 3.6829495559456995
Validation loss: 2.7715353904804823

Epoch: 6| Step: 11
Training loss: 3.2591119822868833
Validation loss: 2.7692105351301226

Epoch: 6| Step: 12
Training loss: 2.887458180046269
Validation loss: 2.7699561243642385

Epoch: 6| Step: 13
Training loss: 3.083456775840479
Validation loss: 2.768731242244362

Epoch: 312| Step: 0
Training loss: 3.1341059956302857
Validation loss: 2.768618503811758

Epoch: 6| Step: 1
Training loss: 3.0169737966864374
Validation loss: 2.765872622347757

Epoch: 6| Step: 2
Training loss: 2.6955389397634844
Validation loss: 2.7627102487283772

Epoch: 6| Step: 3
Training loss: 2.9177147934794565
Validation loss: 2.757480024368556

Epoch: 6| Step: 4
Training loss: 3.4038784625705514
Validation loss: 2.7636729918557053

Epoch: 6| Step: 5
Training loss: 2.988280930861911
Validation loss: 2.7567182069414704

Epoch: 6| Step: 6
Training loss: 3.244379318431375
Validation loss: 2.7539746170907544

Epoch: 6| Step: 7
Training loss: 3.633716232935509
Validation loss: 2.754227785452469

Epoch: 6| Step: 8
Training loss: 3.0273853323757107
Validation loss: 2.757253072385413

Epoch: 6| Step: 9
Training loss: 3.36179055596679
Validation loss: 2.756843429866249

Epoch: 6| Step: 10
Training loss: 2.8275492382400045
Validation loss: 2.7549752753027676

Epoch: 6| Step: 11
Training loss: 2.6797393704835333
Validation loss: 2.7536546003229185

Epoch: 6| Step: 12
Training loss: 2.983918639436629
Validation loss: 2.7592721496195534

Epoch: 6| Step: 13
Training loss: 2.786069316387834
Validation loss: 2.763998493388932

Epoch: 313| Step: 0
Training loss: 3.20122013672436
Validation loss: 2.7576397773138135

Epoch: 6| Step: 1
Training loss: 3.171680463265423
Validation loss: 2.759436760845797

Epoch: 6| Step: 2
Training loss: 3.007529188412447
Validation loss: 2.768531435914266

Epoch: 6| Step: 3
Training loss: 2.8041477374665584
Validation loss: 2.7606680614920203

Epoch: 6| Step: 4
Training loss: 3.4144194741506184
Validation loss: 2.768411203302819

Epoch: 6| Step: 5
Training loss: 2.899485930557178
Validation loss: 2.7790028184890927

Epoch: 6| Step: 6
Training loss: 2.7286618957415687
Validation loss: 2.766937304174473

Epoch: 6| Step: 7
Training loss: 3.4192584062492344
Validation loss: 2.7661219815945524

Epoch: 6| Step: 8
Training loss: 3.0430952053213685
Validation loss: 2.767953085489983

Epoch: 6| Step: 9
Training loss: 2.4546342811181723
Validation loss: 2.766139366446068

Epoch: 6| Step: 10
Training loss: 3.0391690350763794
Validation loss: 2.7596969917020773

Epoch: 6| Step: 11
Training loss: 3.5986716362814164
Validation loss: 2.7553992986935962

Epoch: 6| Step: 12
Training loss: 3.0051990599244016
Validation loss: 2.7624580090197597

Epoch: 6| Step: 13
Training loss: 2.8372051674008825
Validation loss: 2.759922097670001

Epoch: 314| Step: 0
Training loss: 3.0748906061826387
Validation loss: 2.7567038520248954

Epoch: 6| Step: 1
Training loss: 2.576673434282753
Validation loss: 2.7551531533868174

Epoch: 6| Step: 2
Training loss: 3.241741692100594
Validation loss: 2.7540552763833586

Epoch: 6| Step: 3
Training loss: 3.5597874537250456
Validation loss: 2.753776397936785

Epoch: 6| Step: 4
Training loss: 3.3412935735199625
Validation loss: 2.7506762947349968

Epoch: 6| Step: 5
Training loss: 2.6484537039742126
Validation loss: 2.75176798760184

Epoch: 6| Step: 6
Training loss: 2.660359513503554
Validation loss: 2.752781205985931

Epoch: 6| Step: 7
Training loss: 3.180660914231248
Validation loss: 2.7522012471541046

Epoch: 6| Step: 8
Training loss: 3.3065552539924505
Validation loss: 2.752808718515747

Epoch: 6| Step: 9
Training loss: 2.214981855227721
Validation loss: 2.755261385780806

Epoch: 6| Step: 10
Training loss: 3.2157924360126406
Validation loss: 2.7522205940782816

Epoch: 6| Step: 11
Training loss: 3.0364951147313097
Validation loss: 2.7504451331785083

Epoch: 6| Step: 12
Training loss: 3.3535110749095516
Validation loss: 2.7555052578290016

Epoch: 6| Step: 13
Training loss: 3.306331433048722
Validation loss: 2.7585325553984688

Epoch: 315| Step: 0
Training loss: 2.2084906420070065
Validation loss: 2.763338243316433

Epoch: 6| Step: 1
Training loss: 2.7307216106986663
Validation loss: 2.757447485460858

Epoch: 6| Step: 2
Training loss: 3.1424283595936155
Validation loss: 2.768509167545866

Epoch: 6| Step: 3
Training loss: 3.485422567091601
Validation loss: 2.770508567571133

Epoch: 6| Step: 4
Training loss: 3.0642436766178345
Validation loss: 2.774767448963799

Epoch: 6| Step: 5
Training loss: 2.918812498285302
Validation loss: 2.787988064369496

Epoch: 6| Step: 6
Training loss: 3.5361758284545317
Validation loss: 2.7858018063546095

Epoch: 6| Step: 7
Training loss: 2.198159648848871
Validation loss: 2.781901612408729

Epoch: 6| Step: 8
Training loss: 3.4009726703805327
Validation loss: 2.7589336130087623

Epoch: 6| Step: 9
Training loss: 2.964105607173279
Validation loss: 2.752766421234381

Epoch: 6| Step: 10
Training loss: 4.045325258661442
Validation loss: 2.7537023134399825

Epoch: 6| Step: 11
Training loss: 3.2627863615794084
Validation loss: 2.75287058007624

Epoch: 6| Step: 12
Training loss: 2.834470931914312
Validation loss: 2.7516181777072894

Epoch: 6| Step: 13
Training loss: 2.2331183040592175
Validation loss: 2.7516514470361413

Epoch: 316| Step: 0
Training loss: 2.7608240558695987
Validation loss: 2.7521924874331622

Epoch: 6| Step: 1
Training loss: 3.2476657407547154
Validation loss: 2.752355896721707

Epoch: 6| Step: 2
Training loss: 3.073751838252265
Validation loss: 2.7523456443974843

Epoch: 6| Step: 3
Training loss: 2.423497302696658
Validation loss: 2.750370205807409

Epoch: 6| Step: 4
Training loss: 2.511014516298544
Validation loss: 2.7521064145195284

Epoch: 6| Step: 5
Training loss: 3.5322920350494837
Validation loss: 2.756455938001898

Epoch: 6| Step: 6
Training loss: 2.974851101266588
Validation loss: 2.7577543180776747

Epoch: 6| Step: 7
Training loss: 3.100461211812228
Validation loss: 2.762407284819048

Epoch: 6| Step: 8
Training loss: 3.2152919526379313
Validation loss: 2.7579074385337408

Epoch: 6| Step: 9
Training loss: 3.1201297192627835
Validation loss: 2.764522076030777

Epoch: 6| Step: 10
Training loss: 3.5678224123051683
Validation loss: 2.770545654635273

Epoch: 6| Step: 11
Training loss: 3.0296075834974654
Validation loss: 2.7751793657548

Epoch: 6| Step: 12
Training loss: 2.950806691709224
Validation loss: 2.776903048647051

Epoch: 6| Step: 13
Training loss: 3.1752303092507588
Validation loss: 2.7846507193679995

Epoch: 317| Step: 0
Training loss: 2.820746052986811
Validation loss: 2.766177646469632

Epoch: 6| Step: 1
Training loss: 2.7517937098965417
Validation loss: 2.771045989071207

Epoch: 6| Step: 2
Training loss: 2.664269581909896
Validation loss: 2.7496229614322876

Epoch: 6| Step: 3
Training loss: 3.526753356122925
Validation loss: 2.7576952740891105

Epoch: 6| Step: 4
Training loss: 3.226514321768788
Validation loss: 2.7506480297118974

Epoch: 6| Step: 5
Training loss: 2.9595261081034407
Validation loss: 2.7455156200526787

Epoch: 6| Step: 6
Training loss: 3.078925169136716
Validation loss: 2.746049758478715

Epoch: 6| Step: 7
Training loss: 3.2703532617819966
Validation loss: 2.745792752203401

Epoch: 6| Step: 8
Training loss: 2.942502571046495
Validation loss: 2.742570532753837

Epoch: 6| Step: 9
Training loss: 3.0364960569434314
Validation loss: 2.744217069575079

Epoch: 6| Step: 10
Training loss: 2.636017882834919
Validation loss: 2.7468041749509413

Epoch: 6| Step: 11
Training loss: 2.692993050629679
Validation loss: 2.747921964913365

Epoch: 6| Step: 12
Training loss: 3.9804323323898343
Validation loss: 2.7498512554120755

Epoch: 6| Step: 13
Training loss: 2.8990721303408344
Validation loss: 2.751064568055971

Epoch: 318| Step: 0
Training loss: 3.0677283674448397
Validation loss: 2.7490051815640792

Epoch: 6| Step: 1
Training loss: 3.0736748918352186
Validation loss: 2.7512629490430998

Epoch: 6| Step: 2
Training loss: 2.5803736272748274
Validation loss: 2.7500339162903433

Epoch: 6| Step: 3
Training loss: 3.429070141261535
Validation loss: 2.748887746071015

Epoch: 6| Step: 4
Training loss: 2.3201037997011986
Validation loss: 2.7481801666788717

Epoch: 6| Step: 5
Training loss: 3.046400766879875
Validation loss: 2.755359438872582

Epoch: 6| Step: 6
Training loss: 3.5957386651217527
Validation loss: 2.7601373891473764

Epoch: 6| Step: 7
Training loss: 3.1791217872448305
Validation loss: 2.7545219860019414

Epoch: 6| Step: 8
Training loss: 2.843609816900252
Validation loss: 2.761035121022442

Epoch: 6| Step: 9
Training loss: 3.605135983932712
Validation loss: 2.750502740840586

Epoch: 6| Step: 10
Training loss: 3.193374008471823
Validation loss: 2.7575220838637566

Epoch: 6| Step: 11
Training loss: 3.232141433029042
Validation loss: 2.758554114362111

Epoch: 6| Step: 12
Training loss: 2.366327916558756
Validation loss: 2.7522340604632345

Epoch: 6| Step: 13
Training loss: 2.8487076355553045
Validation loss: 2.7435629954798

Epoch: 319| Step: 0
Training loss: 3.0256128494280334
Validation loss: 2.7536568784684925

Epoch: 6| Step: 1
Training loss: 3.137047395318348
Validation loss: 2.7499356406801403

Epoch: 6| Step: 2
Training loss: 3.0080464854199422
Validation loss: 2.754154592728997

Epoch: 6| Step: 3
Training loss: 3.1647140773931524
Validation loss: 2.761882110821873

Epoch: 6| Step: 4
Training loss: 3.646356483345765
Validation loss: 2.756576791572831

Epoch: 6| Step: 5
Training loss: 2.366140606221068
Validation loss: 2.7537691299651126

Epoch: 6| Step: 6
Training loss: 3.169534204720015
Validation loss: 2.7466309364112265

Epoch: 6| Step: 7
Training loss: 3.3259255748686605
Validation loss: 2.7444227459921757

Epoch: 6| Step: 8
Training loss: 3.023796750196518
Validation loss: 2.746462403588799

Epoch: 6| Step: 9
Training loss: 3.2617254748246545
Validation loss: 2.7429607123832445

Epoch: 6| Step: 10
Training loss: 2.755984124402301
Validation loss: 2.7461721809088675

Epoch: 6| Step: 11
Training loss: 2.631846174174201
Validation loss: 2.74459806957646

Epoch: 6| Step: 12
Training loss: 3.1025110903287345
Validation loss: 2.741868603944516

Epoch: 6| Step: 13
Training loss: 2.9722118872663867
Validation loss: 2.742075342825447

Epoch: 320| Step: 0
Training loss: 2.6518483211875457
Validation loss: 2.7457111303128774

Epoch: 6| Step: 1
Training loss: 2.8316274631324334
Validation loss: 2.7421981530382395

Epoch: 6| Step: 2
Training loss: 3.61427958125537
Validation loss: 2.7473860107084542

Epoch: 6| Step: 3
Training loss: 2.6446784695508656
Validation loss: 2.743312512715495

Epoch: 6| Step: 4
Training loss: 3.0015248555926095
Validation loss: 2.7443298884157077

Epoch: 6| Step: 5
Training loss: 3.842672305491023
Validation loss: 2.749676975359385

Epoch: 6| Step: 6
Training loss: 2.508928282465722
Validation loss: 2.744128317512125

Epoch: 6| Step: 7
Training loss: 3.3999651402201043
Validation loss: 2.7571783858110135

Epoch: 6| Step: 8
Training loss: 2.75388625117406
Validation loss: 2.7574174276070207

Epoch: 6| Step: 9
Training loss: 2.5260550796834345
Validation loss: 2.7707143343670086

Epoch: 6| Step: 10
Training loss: 2.6584935306443813
Validation loss: 2.754672241038385

Epoch: 6| Step: 11
Training loss: 3.3641403111283847
Validation loss: 2.7490029415292634

Epoch: 6| Step: 12
Training loss: 3.4918556823796973
Validation loss: 2.7689118873192453

Epoch: 6| Step: 13
Training loss: 3.102574104204849
Validation loss: 2.764550789911228

Epoch: 321| Step: 0
Training loss: 3.0796594812985334
Validation loss: 2.751177430376203

Epoch: 6| Step: 1
Training loss: 3.0967605277113712
Validation loss: 2.753349194448088

Epoch: 6| Step: 2
Training loss: 3.0917177557687006
Validation loss: 2.755189129591721

Epoch: 6| Step: 3
Training loss: 2.8010251246302333
Validation loss: 2.7455369282732023

Epoch: 6| Step: 4
Training loss: 3.175884550134222
Validation loss: 2.747678731631901

Epoch: 6| Step: 5
Training loss: 2.8765828295087235
Validation loss: 2.7456024121993092

Epoch: 6| Step: 6
Training loss: 3.102698898640898
Validation loss: 2.743944373127313

Epoch: 6| Step: 7
Training loss: 2.528173012861063
Validation loss: 2.7420773445037057

Epoch: 6| Step: 8
Training loss: 3.6147741584353095
Validation loss: 2.742165815166393

Epoch: 6| Step: 9
Training loss: 2.5564981279521124
Validation loss: 2.7486695607264773

Epoch: 6| Step: 10
Training loss: 3.3061874989477293
Validation loss: 2.741019623692504

Epoch: 6| Step: 11
Training loss: 3.056070546379491
Validation loss: 2.7487876360084993

Epoch: 6| Step: 12
Training loss: 3.2399974366166133
Validation loss: 2.7378678269183316

Epoch: 6| Step: 13
Training loss: 3.082017016166435
Validation loss: 2.7406891013182544

Epoch: 322| Step: 0
Training loss: 3.0731144900682406
Validation loss: 2.7508756626852153

Epoch: 6| Step: 1
Training loss: 2.4330455474854795
Validation loss: 2.744509289668087

Epoch: 6| Step: 2
Training loss: 3.299597894850249
Validation loss: 2.751822401942894

Epoch: 6| Step: 3
Training loss: 2.662821461071869
Validation loss: 2.7448643659212313

Epoch: 6| Step: 4
Training loss: 3.3593045959192303
Validation loss: 2.739552938485385

Epoch: 6| Step: 5
Training loss: 2.50311523892789
Validation loss: 2.7394481619194186

Epoch: 6| Step: 6
Training loss: 2.8062485624789697
Validation loss: 2.742043183013377

Epoch: 6| Step: 7
Training loss: 2.7240496316833185
Validation loss: 2.7409277086700135

Epoch: 6| Step: 8
Training loss: 3.25672275969953
Validation loss: 2.739777022461842

Epoch: 6| Step: 9
Training loss: 3.066351512250298
Validation loss: 2.7387763396421527

Epoch: 6| Step: 10
Training loss: 3.3943778509283624
Validation loss: 2.7399691163455713

Epoch: 6| Step: 11
Training loss: 3.6176811524056665
Validation loss: 2.741885435720116

Epoch: 6| Step: 12
Training loss: 3.4916635414661874
Validation loss: 2.7389081636642927

Epoch: 6| Step: 13
Training loss: 2.5450983696233767
Validation loss: 2.7450042525223255

Epoch: 323| Step: 0
Training loss: 2.807632302948442
Validation loss: 2.748801209677559

Epoch: 6| Step: 1
Training loss: 3.5496702229089183
Validation loss: 2.7402869863795645

Epoch: 6| Step: 2
Training loss: 3.110180314408598
Validation loss: 2.7442000615232875

Epoch: 6| Step: 3
Training loss: 3.4226438451149033
Validation loss: 2.741761791475214

Epoch: 6| Step: 4
Training loss: 3.3451991283407856
Validation loss: 2.745925280369913

Epoch: 6| Step: 5
Training loss: 3.1657827716460547
Validation loss: 2.737911038835609

Epoch: 6| Step: 6
Training loss: 3.2380678776111367
Validation loss: 2.744383850517575

Epoch: 6| Step: 7
Training loss: 2.544120656595068
Validation loss: 2.7400598902631965

Epoch: 6| Step: 8
Training loss: 2.856724579030077
Validation loss: 2.7447583920245715

Epoch: 6| Step: 9
Training loss: 2.8371690330236303
Validation loss: 2.742817780141865

Epoch: 6| Step: 10
Training loss: 2.7789266075609054
Validation loss: 2.741799398754354

Epoch: 6| Step: 11
Training loss: 2.8196881308476156
Validation loss: 2.740715253107195

Epoch: 6| Step: 12
Training loss: 3.37381059386546
Validation loss: 2.7438492831492045

Epoch: 6| Step: 13
Training loss: 2.299644513231893
Validation loss: 2.7461947638976723

Epoch: 324| Step: 0
Training loss: 3.4150813697068405
Validation loss: 2.75094949201077

Epoch: 6| Step: 1
Training loss: 2.662087253582199
Validation loss: 2.751132182941185

Epoch: 6| Step: 2
Training loss: 3.398686682674969
Validation loss: 2.749890473497553

Epoch: 6| Step: 3
Training loss: 3.112724608624371
Validation loss: 2.7503146693510696

Epoch: 6| Step: 4
Training loss: 2.981814099571242
Validation loss: 2.7545851278620215

Epoch: 6| Step: 5
Training loss: 2.963163560681981
Validation loss: 2.7523765866097656

Epoch: 6| Step: 6
Training loss: 3.003856405531681
Validation loss: 2.7496796549103513

Epoch: 6| Step: 7
Training loss: 3.1039954187320054
Validation loss: 2.7489707014254847

Epoch: 6| Step: 8
Training loss: 2.632548423676748
Validation loss: 2.747596243915704

Epoch: 6| Step: 9
Training loss: 3.1386174860136657
Validation loss: 2.7417528113934795

Epoch: 6| Step: 10
Training loss: 2.7573808975298464
Validation loss: 2.737263677254564

Epoch: 6| Step: 11
Training loss: 3.0932975977718904
Validation loss: 2.736633965277371

Epoch: 6| Step: 12
Training loss: 3.280094488225083
Validation loss: 2.7359686463692037

Epoch: 6| Step: 13
Training loss: 3.107893854594423
Validation loss: 2.735531596614462

Epoch: 325| Step: 0
Training loss: 2.7274054942904336
Validation loss: 2.7361068617975466

Epoch: 6| Step: 1
Training loss: 2.687393186353929
Validation loss: 2.7382106391853975

Epoch: 6| Step: 2
Training loss: 2.541595416295016
Validation loss: 2.7368964410896446

Epoch: 6| Step: 3
Training loss: 3.4725910262171342
Validation loss: 2.734807953434884

Epoch: 6| Step: 4
Training loss: 3.1106905047368127
Validation loss: 2.734626020168994

Epoch: 6| Step: 5
Training loss: 2.9800676348390707
Validation loss: 2.735019250496691

Epoch: 6| Step: 6
Training loss: 2.9934015823887155
Validation loss: 2.7389573420322137

Epoch: 6| Step: 7
Training loss: 3.031055090232108
Validation loss: 2.7361490483917073

Epoch: 6| Step: 8
Training loss: 2.8716499049457105
Validation loss: 2.737091626641231

Epoch: 6| Step: 9
Training loss: 2.9018015297259603
Validation loss: 2.739915019577484

Epoch: 6| Step: 10
Training loss: 3.1426633985672625
Validation loss: 2.737353824434948

Epoch: 6| Step: 11
Training loss: 3.1093964695788308
Validation loss: 2.738193452451052

Epoch: 6| Step: 12
Training loss: 3.7363048977486337
Validation loss: 2.745921150048239

Epoch: 6| Step: 13
Training loss: 3.3587769441762547
Validation loss: 2.7342072869358476

Epoch: 326| Step: 0
Training loss: 2.9861625390959383
Validation loss: 2.7312622518140968

Epoch: 6| Step: 1
Training loss: 2.888515217977871
Validation loss: 2.7367793524903625

Epoch: 6| Step: 2
Training loss: 3.4121151046835836
Validation loss: 2.740051494042956

Epoch: 6| Step: 3
Training loss: 3.2988036963923064
Validation loss: 2.734701542026936

Epoch: 6| Step: 4
Training loss: 2.511055723871669
Validation loss: 2.7395130595915296

Epoch: 6| Step: 5
Training loss: 3.21827323864053
Validation loss: 2.744658928088159

Epoch: 6| Step: 6
Training loss: 3.6160285691508354
Validation loss: 2.74123677475502

Epoch: 6| Step: 7
Training loss: 2.8425164534093432
Validation loss: 2.7370138515729

Epoch: 6| Step: 8
Training loss: 2.768945457155512
Validation loss: 2.7384324644899416

Epoch: 6| Step: 9
Training loss: 3.066593781586444
Validation loss: 2.739858713529083

Epoch: 6| Step: 10
Training loss: 3.2444098887352455
Validation loss: 2.744849829462162

Epoch: 6| Step: 11
Training loss: 2.273704382054509
Validation loss: 2.732090490774276

Epoch: 6| Step: 12
Training loss: 3.292410191127191
Validation loss: 2.7340399199002303

Epoch: 6| Step: 13
Training loss: 2.9217927482574
Validation loss: 2.7366223453580254

Epoch: 327| Step: 0
Training loss: 2.319858288218699
Validation loss: 2.7340784730700025

Epoch: 6| Step: 1
Training loss: 2.954538158594473
Validation loss: 2.736086535169479

Epoch: 6| Step: 2
Training loss: 3.848593164998141
Validation loss: 2.7350768029839965

Epoch: 6| Step: 3
Training loss: 3.0320205495636197
Validation loss: 2.738035215578376

Epoch: 6| Step: 4
Training loss: 3.419729178341209
Validation loss: 2.7362589965762956

Epoch: 6| Step: 5
Training loss: 3.4500696810996963
Validation loss: 2.7367364533773584

Epoch: 6| Step: 6
Training loss: 3.2845625369232905
Validation loss: 2.730992836654775

Epoch: 6| Step: 7
Training loss: 2.767499299363734
Validation loss: 2.7339268855416092

Epoch: 6| Step: 8
Training loss: 3.548640278204693
Validation loss: 2.737697656215735

Epoch: 6| Step: 9
Training loss: 2.7117927367531123
Validation loss: 2.734405022381626

Epoch: 6| Step: 10
Training loss: 2.715345070198306
Validation loss: 2.7386543747975476

Epoch: 6| Step: 11
Training loss: 2.434556602197657
Validation loss: 2.741311124126123

Epoch: 6| Step: 12
Training loss: 2.782315853636933
Validation loss: 2.753976195875557

Epoch: 6| Step: 13
Training loss: 2.940594929816034
Validation loss: 2.7496466367678916

Epoch: 328| Step: 0
Training loss: 3.3937779546608513
Validation loss: 2.7504799536806415

Epoch: 6| Step: 1
Training loss: 3.7701265013338174
Validation loss: 2.7540780274452215

Epoch: 6| Step: 2
Training loss: 2.2648798276166713
Validation loss: 2.7383052733650746

Epoch: 6| Step: 3
Training loss: 3.605829520479541
Validation loss: 2.7357467178086776

Epoch: 6| Step: 4
Training loss: 2.871747706666982
Validation loss: 2.7263469117770827

Epoch: 6| Step: 5
Training loss: 3.7140876329443855
Validation loss: 2.7306543250451942

Epoch: 6| Step: 6
Training loss: 3.0918277201556763
Validation loss: 2.729689245503255

Epoch: 6| Step: 7
Training loss: 1.6273757733633933
Validation loss: 2.7277367456200436

Epoch: 6| Step: 8
Training loss: 2.4669224215565175
Validation loss: 2.7302955200333

Epoch: 6| Step: 9
Training loss: 3.585138768020272
Validation loss: 2.7254171032106806

Epoch: 6| Step: 10
Training loss: 3.713783345465988
Validation loss: 2.7240992627484064

Epoch: 6| Step: 11
Training loss: 2.1734588117397915
Validation loss: 2.729862760928424

Epoch: 6| Step: 12
Training loss: 2.6219362817815877
Validation loss: 2.7307601506334196

Epoch: 6| Step: 13
Training loss: 2.6339808738263195
Validation loss: 2.732974020208434

Epoch: 329| Step: 0
Training loss: 3.4840292994321613
Validation loss: 2.73501158914437

Epoch: 6| Step: 1
Training loss: 2.3081423968546035
Validation loss: 2.7317939692489555

Epoch: 6| Step: 2
Training loss: 2.180789026556863
Validation loss: 2.7310901868701563

Epoch: 6| Step: 3
Training loss: 3.2052202024706014
Validation loss: 2.736407976911211

Epoch: 6| Step: 4
Training loss: 3.216544126900841
Validation loss: 2.725319530594829

Epoch: 6| Step: 5
Training loss: 3.2029246197803527
Validation loss: 2.7327344209995417

Epoch: 6| Step: 6
Training loss: 2.831786762076047
Validation loss: 2.7297904504009924

Epoch: 6| Step: 7
Training loss: 3.4571327668710436
Validation loss: 2.7325928377057647

Epoch: 6| Step: 8
Training loss: 2.935874326796728
Validation loss: 2.7343650252809257

Epoch: 6| Step: 9
Training loss: 3.3094811268504754
Validation loss: 2.743458745845903

Epoch: 6| Step: 10
Training loss: 2.7054641393125958
Validation loss: 2.7452166012140196

Epoch: 6| Step: 11
Training loss: 3.4945374503913245
Validation loss: 2.74506565490288

Epoch: 6| Step: 12
Training loss: 3.0199197023339748
Validation loss: 2.745988500404387

Epoch: 6| Step: 13
Training loss: 2.8247505415431364
Validation loss: 2.7360697155061

Epoch: 330| Step: 0
Training loss: 3.0297122476244773
Validation loss: 2.7317357380651037

Epoch: 6| Step: 1
Training loss: 3.368575869785766
Validation loss: 2.7344678731167615

Epoch: 6| Step: 2
Training loss: 2.912982975939824
Validation loss: 2.72782034419464

Epoch: 6| Step: 3
Training loss: 3.597639682329862
Validation loss: 2.7264831909413276

Epoch: 6| Step: 4
Training loss: 3.1913340827691856
Validation loss: 2.727371403760131

Epoch: 6| Step: 5
Training loss: 2.1454440260630725
Validation loss: 2.726162013994994

Epoch: 6| Step: 6
Training loss: 3.01123945526519
Validation loss: 2.7306225057798064

Epoch: 6| Step: 7
Training loss: 2.8451621772653675
Validation loss: 2.727942487997442

Epoch: 6| Step: 8
Training loss: 3.138347654088821
Validation loss: 2.726736805772387

Epoch: 6| Step: 9
Training loss: 3.192468100009784
Validation loss: 2.7265119199148127

Epoch: 6| Step: 10
Training loss: 2.840142445551446
Validation loss: 2.7249228180266605

Epoch: 6| Step: 11
Training loss: 3.273777472929512
Validation loss: 2.7291918799362813

Epoch: 6| Step: 12
Training loss: 2.7439394839817717
Validation loss: 2.7294739606017844

Epoch: 6| Step: 13
Training loss: 3.1171979019641607
Validation loss: 2.7300717865396926

Epoch: 331| Step: 0
Training loss: 3.588497137597154
Validation loss: 2.7326804296192395

Epoch: 6| Step: 1
Training loss: 3.0144170209505337
Validation loss: 2.7380745195776757

Epoch: 6| Step: 2
Training loss: 3.2769212052548986
Validation loss: 2.7404227051541348

Epoch: 6| Step: 3
Training loss: 3.546084143572442
Validation loss: 2.748008792074949

Epoch: 6| Step: 4
Training loss: 2.995721945639471
Validation loss: 2.7418361574649173

Epoch: 6| Step: 5
Training loss: 3.2024431200656567
Validation loss: 2.73786639896299

Epoch: 6| Step: 6
Training loss: 3.0377382663791845
Validation loss: 2.73764246668555

Epoch: 6| Step: 7
Training loss: 3.1512686823677347
Validation loss: 2.731450253104902

Epoch: 6| Step: 8
Training loss: 2.3259286441042426
Validation loss: 2.7280896051458154

Epoch: 6| Step: 9
Training loss: 2.9084180723012594
Validation loss: 2.7316130290254055

Epoch: 6| Step: 10
Training loss: 2.7830936450506982
Validation loss: 2.7270525631673994

Epoch: 6| Step: 11
Training loss: 2.596305782947551
Validation loss: 2.7314216023526567

Epoch: 6| Step: 12
Training loss: 3.2224533849500863
Validation loss: 2.724769368176752

Epoch: 6| Step: 13
Training loss: 2.3861246071866677
Validation loss: 2.7278275281146716

Epoch: 332| Step: 0
Training loss: 2.8728745938531386
Validation loss: 2.7267297872724963

Epoch: 6| Step: 1
Training loss: 2.779318492427349
Validation loss: 2.7253364024939186

Epoch: 6| Step: 2
Training loss: 2.1404777531901273
Validation loss: 2.728178535987389

Epoch: 6| Step: 3
Training loss: 3.0351163451567547
Validation loss: 2.7261763096834226

Epoch: 6| Step: 4
Training loss: 3.171285941010889
Validation loss: 2.728942601382985

Epoch: 6| Step: 5
Training loss: 2.722310070212004
Validation loss: 2.7237508841432505

Epoch: 6| Step: 6
Training loss: 3.1966267986284342
Validation loss: 2.7267537140306928

Epoch: 6| Step: 7
Training loss: 3.3245176725544643
Validation loss: 2.730711085630699

Epoch: 6| Step: 8
Training loss: 2.686697995482001
Validation loss: 2.725893739175397

Epoch: 6| Step: 9
Training loss: 2.5664047636030705
Validation loss: 2.7309924358208297

Epoch: 6| Step: 10
Training loss: 3.2615450692905767
Validation loss: 2.7440942553594594

Epoch: 6| Step: 11
Training loss: 3.8384156467381203
Validation loss: 2.7471548111871695

Epoch: 6| Step: 12
Training loss: 3.6923336095389403
Validation loss: 2.7368965356959642

Epoch: 6| Step: 13
Training loss: 2.750959749072244
Validation loss: 2.73572995696727

Epoch: 333| Step: 0
Training loss: 2.8558167377305486
Validation loss: 2.728640906716818

Epoch: 6| Step: 1
Training loss: 2.204187448135606
Validation loss: 2.7376785203628926

Epoch: 6| Step: 2
Training loss: 3.0397584407603557
Validation loss: 2.7339368731117517

Epoch: 6| Step: 3
Training loss: 2.801523703430433
Validation loss: 2.7308336352396543

Epoch: 6| Step: 4
Training loss: 2.6157827678393692
Validation loss: 2.7258305919901273

Epoch: 6| Step: 5
Training loss: 3.878887687400511
Validation loss: 2.728540963297135

Epoch: 6| Step: 6
Training loss: 3.4947048731722297
Validation loss: 2.7237129622463394

Epoch: 6| Step: 7
Training loss: 3.1897259587932796
Validation loss: 2.7278696952010497

Epoch: 6| Step: 8
Training loss: 2.8918088396137396
Validation loss: 2.725342393610922

Epoch: 6| Step: 9
Training loss: 3.291255699932235
Validation loss: 2.726781858188334

Epoch: 6| Step: 10
Training loss: 3.2497326667582223
Validation loss: 2.7217729730880595

Epoch: 6| Step: 11
Training loss: 3.342747760911465
Validation loss: 2.723826930591588

Epoch: 6| Step: 12
Training loss: 2.3425342712826613
Validation loss: 2.726160778329417

Epoch: 6| Step: 13
Training loss: 2.8962924145131153
Validation loss: 2.7239695511350113

Epoch: 334| Step: 0
Training loss: 2.758470235310328
Validation loss: 2.723413282566815

Epoch: 6| Step: 1
Training loss: 4.033911484404891
Validation loss: 2.7210404655017943

Epoch: 6| Step: 2
Training loss: 2.7224564116380345
Validation loss: 2.730228687267519

Epoch: 6| Step: 3
Training loss: 2.508925146537891
Validation loss: 2.7354850369934844

Epoch: 6| Step: 4
Training loss: 3.5745199774876077
Validation loss: 2.733892086765547

Epoch: 6| Step: 5
Training loss: 3.6843602666325697
Validation loss: 2.7337751508183814

Epoch: 6| Step: 6
Training loss: 3.351391767941576
Validation loss: 2.734384715917058

Epoch: 6| Step: 7
Training loss: 2.112700828621924
Validation loss: 2.7264803419103085

Epoch: 6| Step: 8
Training loss: 2.994874549492801
Validation loss: 2.7242252303253016

Epoch: 6| Step: 9
Training loss: 2.9230934907080757
Validation loss: 2.7364035577227184

Epoch: 6| Step: 10
Training loss: 3.1626345579448367
Validation loss: 2.736084588137809

Epoch: 6| Step: 11
Training loss: 2.2532880917170095
Validation loss: 2.7265532620632524

Epoch: 6| Step: 12
Training loss: 2.9775831019722
Validation loss: 2.7265615108605843

Epoch: 6| Step: 13
Training loss: 2.7180850213277923
Validation loss: 2.7277314458477653

Epoch: 335| Step: 0
Training loss: 2.8520400392094616
Validation loss: 2.735975315088961

Epoch: 6| Step: 1
Training loss: 3.26296026849012
Validation loss: 2.7398563911616107

Epoch: 6| Step: 2
Training loss: 3.307185678460828
Validation loss: 2.734835785980379

Epoch: 6| Step: 3
Training loss: 2.5366401267783303
Validation loss: 2.7370317594417024

Epoch: 6| Step: 4
Training loss: 2.6095070263018267
Validation loss: 2.74920761834006

Epoch: 6| Step: 5
Training loss: 2.9017979145841566
Validation loss: 2.7454091689147306

Epoch: 6| Step: 6
Training loss: 3.686531068907664
Validation loss: 2.742694460212544

Epoch: 6| Step: 7
Training loss: 3.2182231583019316
Validation loss: 2.7323327810871763

Epoch: 6| Step: 8
Training loss: 3.0260717463790243
Validation loss: 2.7274504153485295

Epoch: 6| Step: 9
Training loss: 2.662620265912967
Validation loss: 2.722053415308881

Epoch: 6| Step: 10
Training loss: 3.1961928369738657
Validation loss: 2.7205396982004895

Epoch: 6| Step: 11
Training loss: 3.0437115801945893
Validation loss: 2.720813920664237

Epoch: 6| Step: 12
Training loss: 2.8420425151568343
Validation loss: 2.7187970244240347

Epoch: 6| Step: 13
Training loss: 3.2884445516033454
Validation loss: 2.722534945327065

Epoch: 336| Step: 0
Training loss: 2.8772478023941273
Validation loss: 2.7221217762313796

Epoch: 6| Step: 1
Training loss: 2.84958962949379
Validation loss: 2.7149399635356146

Epoch: 6| Step: 2
Training loss: 3.272125345324151
Validation loss: 2.717466734917764

Epoch: 6| Step: 3
Training loss: 2.7946598935184714
Validation loss: 2.720991892290805

Epoch: 6| Step: 4
Training loss: 2.8846753725514565
Validation loss: 2.7203005045879918

Epoch: 6| Step: 5
Training loss: 2.8737508299080945
Validation loss: 2.720634794391948

Epoch: 6| Step: 6
Training loss: 2.521394073500423
Validation loss: 2.7213848106204286

Epoch: 6| Step: 7
Training loss: 3.0659627217056427
Validation loss: 2.7149735982807712

Epoch: 6| Step: 8
Training loss: 3.605102784996992
Validation loss: 2.722274325295392

Epoch: 6| Step: 9
Training loss: 3.4218223254186357
Validation loss: 2.7233959007850266

Epoch: 6| Step: 10
Training loss: 2.6773634193839966
Validation loss: 2.72658187088798

Epoch: 6| Step: 11
Training loss: 3.018200342909086
Validation loss: 2.71861515693796

Epoch: 6| Step: 12
Training loss: 3.486082197646108
Validation loss: 2.7271900808108653

Epoch: 6| Step: 13
Training loss: 2.822566349678931
Validation loss: 2.723894638069422

Epoch: 337| Step: 0
Training loss: 3.296366575549939
Validation loss: 2.7294638195710355

Epoch: 6| Step: 1
Training loss: 2.6356671079872696
Validation loss: 2.726893062611595

Epoch: 6| Step: 2
Training loss: 3.0723556437463677
Validation loss: 2.719510837714974

Epoch: 6| Step: 3
Training loss: 2.861503600901315
Validation loss: 2.720010985760035

Epoch: 6| Step: 4
Training loss: 3.249794146547452
Validation loss: 2.7163082799378793

Epoch: 6| Step: 5
Training loss: 2.8506757637761373
Validation loss: 2.7268929916315945

Epoch: 6| Step: 6
Training loss: 2.908394791209688
Validation loss: 2.72086362488492

Epoch: 6| Step: 7
Training loss: 3.325635811957162
Validation loss: 2.719705225503164

Epoch: 6| Step: 8
Training loss: 3.0495879786119358
Validation loss: 2.717866710014898

Epoch: 6| Step: 9
Training loss: 2.795720549429597
Validation loss: 2.7242084607072

Epoch: 6| Step: 10
Training loss: 2.825537156205852
Validation loss: 2.7224696005594855

Epoch: 6| Step: 11
Training loss: 2.951189001956424
Validation loss: 2.721445703102846

Epoch: 6| Step: 12
Training loss: 3.613721600067638
Validation loss: 2.7293082636291146

Epoch: 6| Step: 13
Training loss: 2.8125108506735135
Validation loss: 2.7142191506800093

Epoch: 338| Step: 0
Training loss: 3.4007881541305838
Validation loss: 2.725925064406614

Epoch: 6| Step: 1
Training loss: 2.9158607641083454
Validation loss: 2.726904338066733

Epoch: 6| Step: 2
Training loss: 3.088120087042774
Validation loss: 2.7206204356624446

Epoch: 6| Step: 3
Training loss: 2.8449166388609477
Validation loss: 2.7166807121348113

Epoch: 6| Step: 4
Training loss: 3.424112224379698
Validation loss: 2.715347956404315

Epoch: 6| Step: 5
Training loss: 2.7926026004258158
Validation loss: 2.718005302672068

Epoch: 6| Step: 6
Training loss: 2.987685359806836
Validation loss: 2.7114508381808764

Epoch: 6| Step: 7
Training loss: 3.0389730641362878
Validation loss: 2.711990562806108

Epoch: 6| Step: 8
Training loss: 3.229641459025664
Validation loss: 2.714046284362811

Epoch: 6| Step: 9
Training loss: 3.2388603327695358
Validation loss: 2.7122828295753485

Epoch: 6| Step: 10
Training loss: 3.287464469456583
Validation loss: 2.713375565855105

Epoch: 6| Step: 11
Training loss: 2.524991622759831
Validation loss: 2.7115301085158725

Epoch: 6| Step: 12
Training loss: 2.9071283141254773
Validation loss: 2.7123848899890484

Epoch: 6| Step: 13
Training loss: 2.2760866860506415
Validation loss: 2.723557512717428

Epoch: 339| Step: 0
Training loss: 3.195239973294412
Validation loss: 2.7219833310081536

Epoch: 6| Step: 1
Training loss: 2.8776392225428795
Validation loss: 2.718952163423687

Epoch: 6| Step: 2
Training loss: 3.062936245734568
Validation loss: 2.71635567506723

Epoch: 6| Step: 3
Training loss: 3.586479461870641
Validation loss: 2.7170129832197527

Epoch: 6| Step: 4
Training loss: 2.892617028983821
Validation loss: 2.713895745852546

Epoch: 6| Step: 5
Training loss: 2.996553030210914
Validation loss: 2.7164003154678924

Epoch: 6| Step: 6
Training loss: 3.457056215702578
Validation loss: 2.7117305015531286

Epoch: 6| Step: 7
Training loss: 3.1733465680345936
Validation loss: 2.7126142746646638

Epoch: 6| Step: 8
Training loss: 2.860268541813272
Validation loss: 2.712022821871167

Epoch: 6| Step: 9
Training loss: 3.200001305341454
Validation loss: 2.718026228573918

Epoch: 6| Step: 10
Training loss: 3.0842775153588313
Validation loss: 2.721893833254844

Epoch: 6| Step: 11
Training loss: 2.706642288073165
Validation loss: 2.7126282712804795

Epoch: 6| Step: 12
Training loss: 2.479017226472856
Validation loss: 2.7085702945485113

Epoch: 6| Step: 13
Training loss: 2.436340153896722
Validation loss: 2.7103756785250313

Epoch: 340| Step: 0
Training loss: 3.5678953841058494
Validation loss: 2.710431440284014

Epoch: 6| Step: 1
Training loss: 2.6561694862280705
Validation loss: 2.7204877622413304

Epoch: 6| Step: 2
Training loss: 2.014484881494164
Validation loss: 2.713257560495349

Epoch: 6| Step: 3
Training loss: 3.2310130757404045
Validation loss: 2.713007851622196

Epoch: 6| Step: 4
Training loss: 2.43828570100573
Validation loss: 2.713434128697768

Epoch: 6| Step: 5
Training loss: 3.0531829484888977
Validation loss: 2.7175172173254003

Epoch: 6| Step: 6
Training loss: 3.385362047586241
Validation loss: 2.7107777335814616

Epoch: 6| Step: 7
Training loss: 3.7678817381472545
Validation loss: 2.7229582669263954

Epoch: 6| Step: 8
Training loss: 3.21693858313401
Validation loss: 2.7108119505131136

Epoch: 6| Step: 9
Training loss: 3.493638660929268
Validation loss: 2.715332037386879

Epoch: 6| Step: 10
Training loss: 2.2985446596352324
Validation loss: 2.7070392069369444

Epoch: 6| Step: 11
Training loss: 2.743671939234726
Validation loss: 2.711870590428077

Epoch: 6| Step: 12
Training loss: 2.7847494333850364
Validation loss: 2.708473123077555

Epoch: 6| Step: 13
Training loss: 3.3595915968509975
Validation loss: 2.7095361321541183

Epoch: 341| Step: 0
Training loss: 2.951542344435962
Validation loss: 2.707338142397758

Epoch: 6| Step: 1
Training loss: 3.550130551583783
Validation loss: 2.7143390891444623

Epoch: 6| Step: 2
Training loss: 3.0136449766905566
Validation loss: 2.708781012427085

Epoch: 6| Step: 3
Training loss: 3.2027283957972603
Validation loss: 2.71258517545978

Epoch: 6| Step: 4
Training loss: 2.966242644907324
Validation loss: 2.7085157220984275

Epoch: 6| Step: 5
Training loss: 2.7570052654007147
Validation loss: 2.712173411404464

Epoch: 6| Step: 6
Training loss: 3.389052065758056
Validation loss: 2.7114469238632193

Epoch: 6| Step: 7
Training loss: 2.4097326268079278
Validation loss: 2.7089668343919944

Epoch: 6| Step: 8
Training loss: 2.625103085628174
Validation loss: 2.7102121511238435

Epoch: 6| Step: 9
Training loss: 2.433978936586165
Validation loss: 2.706958217825696

Epoch: 6| Step: 10
Training loss: 3.429000472857781
Validation loss: 2.707225942959521

Epoch: 6| Step: 11
Training loss: 3.304600779881299
Validation loss: 2.7030646840055472

Epoch: 6| Step: 12
Training loss: 3.0495055751596336
Validation loss: 2.709604928089052

Epoch: 6| Step: 13
Training loss: 3.083549560663231
Validation loss: 2.712432286567685

Epoch: 342| Step: 0
Training loss: 2.129717806896425
Validation loss: 2.7220136878451164

Epoch: 6| Step: 1
Training loss: 2.8285053482153453
Validation loss: 2.722237543053618

Epoch: 6| Step: 2
Training loss: 2.7856871111036927
Validation loss: 2.72685258819937

Epoch: 6| Step: 3
Training loss: 3.275597344587272
Validation loss: 2.721251940829912

Epoch: 6| Step: 4
Training loss: 3.1388710400309257
Validation loss: 2.730774489843786

Epoch: 6| Step: 5
Training loss: 2.5428606470337995
Validation loss: 2.7560828884802704

Epoch: 6| Step: 6
Training loss: 3.500615746966547
Validation loss: 2.7413510600937316

Epoch: 6| Step: 7
Training loss: 3.2661354359602353
Validation loss: 2.721889515769037

Epoch: 6| Step: 8
Training loss: 3.163249045462688
Validation loss: 2.722121972121673

Epoch: 6| Step: 9
Training loss: 3.318096399692355
Validation loss: 2.7173012718562544

Epoch: 6| Step: 10
Training loss: 2.016634193137939
Validation loss: 2.70864917263953

Epoch: 6| Step: 11
Training loss: 3.988197437866606
Validation loss: 2.7016987629769025

Epoch: 6| Step: 12
Training loss: 3.0307711193491436
Validation loss: 2.710499580742392

Epoch: 6| Step: 13
Training loss: 2.7564639503672224
Validation loss: 2.7059594114556007

Epoch: 343| Step: 0
Training loss: 2.7472131653334166
Validation loss: 2.7087973683833253

Epoch: 6| Step: 1
Training loss: 2.960634724377765
Validation loss: 2.705703949523813

Epoch: 6| Step: 2
Training loss: 3.2454864264336463
Validation loss: 2.7085820385981703

Epoch: 6| Step: 3
Training loss: 3.1547771076477003
Validation loss: 2.7060667588880136

Epoch: 6| Step: 4
Training loss: 3.040249394175448
Validation loss: 2.707482246032644

Epoch: 6| Step: 5
Training loss: 3.1465057429151075
Validation loss: 2.711021609040462

Epoch: 6| Step: 6
Training loss: 3.3057762859458846
Validation loss: 2.7095132152416297

Epoch: 6| Step: 7
Training loss: 3.3549181805112336
Validation loss: 2.707040066837799

Epoch: 6| Step: 8
Training loss: 2.675483809597337
Validation loss: 2.7079455499559817

Epoch: 6| Step: 9
Training loss: 3.354469017159789
Validation loss: 2.7078448710971093

Epoch: 6| Step: 10
Training loss: 2.4242500718675264
Validation loss: 2.7085444144888626

Epoch: 6| Step: 11
Training loss: 2.587587135801183
Validation loss: 2.710624860019283

Epoch: 6| Step: 12
Training loss: 3.3314623509157126
Validation loss: 2.7100041270821538

Epoch: 6| Step: 13
Training loss: 2.7212740702302693
Validation loss: 2.729468678291312

Epoch: 344| Step: 0
Training loss: 3.255805039710456
Validation loss: 2.7287011910084864

Epoch: 6| Step: 1
Training loss: 3.012835858249241
Validation loss: 2.726092081401053

Epoch: 6| Step: 2
Training loss: 2.733364681513833
Validation loss: 2.7221543070117726

Epoch: 6| Step: 3
Training loss: 2.8740302399150726
Validation loss: 2.7279367629078526

Epoch: 6| Step: 4
Training loss: 2.8641246266554394
Validation loss: 2.7403375919304156

Epoch: 6| Step: 5
Training loss: 3.9569071291768605
Validation loss: 2.74098393477026

Epoch: 6| Step: 6
Training loss: 2.858660666033629
Validation loss: 2.74422273080589

Epoch: 6| Step: 7
Training loss: 2.909084127700011
Validation loss: 2.7340027258342596

Epoch: 6| Step: 8
Training loss: 2.9879314542003805
Validation loss: 2.7357414401132347

Epoch: 6| Step: 9
Training loss: 2.884732565822759
Validation loss: 2.7375151873489565

Epoch: 6| Step: 10
Training loss: 2.933876237335341
Validation loss: 2.7279516441687703

Epoch: 6| Step: 11
Training loss: 3.1675267975478274
Validation loss: 2.714851226997009

Epoch: 6| Step: 12
Training loss: 2.8650789329214157
Validation loss: 2.712479636951989

Epoch: 6| Step: 13
Training loss: 2.7419659560390515
Validation loss: 2.706673345481278

Epoch: 345| Step: 0
Training loss: 3.7819802075719946
Validation loss: 2.703586206846917

Epoch: 6| Step: 1
Training loss: 2.3822915430128706
Validation loss: 2.7096104894400943

Epoch: 6| Step: 2
Training loss: 2.068427267572291
Validation loss: 2.7143830052485463

Epoch: 6| Step: 3
Training loss: 3.3522097800623842
Validation loss: 2.7231321321630357

Epoch: 6| Step: 4
Training loss: 3.1185185164965645
Validation loss: 2.719314188509785

Epoch: 6| Step: 5
Training loss: 3.6749167971372287
Validation loss: 2.7094068161984883

Epoch: 6| Step: 6
Training loss: 2.6604763740246153
Validation loss: 2.703422727731707

Epoch: 6| Step: 7
Training loss: 2.8814148034483424
Validation loss: 2.7044774397675444

Epoch: 6| Step: 8
Training loss: 2.2085787318892693
Validation loss: 2.7021800076411018

Epoch: 6| Step: 9
Training loss: 2.96336148769648
Validation loss: 2.7067169161794222

Epoch: 6| Step: 10
Training loss: 3.4269416261882486
Validation loss: 2.7076719651866106

Epoch: 6| Step: 11
Training loss: 3.167113991981976
Validation loss: 2.7027455578738824

Epoch: 6| Step: 12
Training loss: 3.0007396421996617
Validation loss: 2.7033652889296627

Epoch: 6| Step: 13
Training loss: 3.1318578621192352
Validation loss: 2.7039178001836284

Epoch: 346| Step: 0
Training loss: 3.054902754514221
Validation loss: 2.7042025570560986

Epoch: 6| Step: 1
Training loss: 3.901620303311297
Validation loss: 2.7039990045603663

Epoch: 6| Step: 2
Training loss: 3.2156935318445803
Validation loss: 2.706487029786709

Epoch: 6| Step: 3
Training loss: 2.7839025642510644
Validation loss: 2.701298042411444

Epoch: 6| Step: 4
Training loss: 2.5821111207921335
Validation loss: 2.7041346688988264

Epoch: 6| Step: 5
Training loss: 3.0587666390811767
Validation loss: 2.6995105096890626

Epoch: 6| Step: 6
Training loss: 2.863922338807344
Validation loss: 2.7023728975939956

Epoch: 6| Step: 7
Training loss: 3.0162030392408568
Validation loss: 2.7001206133316367

Epoch: 6| Step: 8
Training loss: 3.089239666671987
Validation loss: 2.7060418240514363

Epoch: 6| Step: 9
Training loss: 3.779796226297008
Validation loss: 2.70735270319289

Epoch: 6| Step: 10
Training loss: 2.617360761230892
Validation loss: 2.712822927328136

Epoch: 6| Step: 11
Training loss: 2.3375144917247974
Validation loss: 2.702947275594215

Epoch: 6| Step: 12
Training loss: 2.979931304191047
Validation loss: 2.7118340546689366

Epoch: 6| Step: 13
Training loss: 2.2566563375096704
Validation loss: 2.7219647844642396

Epoch: 347| Step: 0
Training loss: 3.185404219435695
Validation loss: 2.7196950697276345

Epoch: 6| Step: 1
Training loss: 3.4779594443678437
Validation loss: 2.7241087499270114

Epoch: 6| Step: 2
Training loss: 2.5292216521753326
Validation loss: 2.716685217195046

Epoch: 6| Step: 3
Training loss: 3.189353254521817
Validation loss: 2.7115060124398815

Epoch: 6| Step: 4
Training loss: 3.2292088331525344
Validation loss: 2.7134468503407487

Epoch: 6| Step: 5
Training loss: 2.771329180490066
Validation loss: 2.700216312812995

Epoch: 6| Step: 6
Training loss: 2.415884176269511
Validation loss: 2.7016897370296755

Epoch: 6| Step: 7
Training loss: 2.7344189449593737
Validation loss: 2.7027658431029993

Epoch: 6| Step: 8
Training loss: 2.909852123370329
Validation loss: 2.703764180343963

Epoch: 6| Step: 9
Training loss: 3.1238807199641085
Validation loss: 2.711138431386313

Epoch: 6| Step: 10
Training loss: 3.502317887227103
Validation loss: 2.7041852802673967

Epoch: 6| Step: 11
Training loss: 3.1942408473789907
Validation loss: 2.6955269505745156

Epoch: 6| Step: 12
Training loss: 2.5937891578016505
Validation loss: 2.6954522409189794

Epoch: 6| Step: 13
Training loss: 3.356234905983284
Validation loss: 2.70382426076267

Epoch: 348| Step: 0
Training loss: 2.61610996212379
Validation loss: 2.707582654324162

Epoch: 6| Step: 1
Training loss: 3.2491939718921032
Validation loss: 2.715697331780214

Epoch: 6| Step: 2
Training loss: 3.1623204839968166
Validation loss: 2.7171947862278265

Epoch: 6| Step: 3
Training loss: 2.421088897119209
Validation loss: 2.7189753590705625

Epoch: 6| Step: 4
Training loss: 3.128499170079791
Validation loss: 2.7336289361030657

Epoch: 6| Step: 5
Training loss: 3.425749235971423
Validation loss: 2.737278203425748

Epoch: 6| Step: 6
Training loss: 2.9310091419942896
Validation loss: 2.7548582134212993

Epoch: 6| Step: 7
Training loss: 3.11175507359778
Validation loss: 2.7422670859365343

Epoch: 6| Step: 8
Training loss: 2.9973030683589124
Validation loss: 2.7588546193681056

Epoch: 6| Step: 9
Training loss: 3.175308849301458
Validation loss: 2.7255666836916936

Epoch: 6| Step: 10
Training loss: 2.953977592956646
Validation loss: 2.7258170327839624

Epoch: 6| Step: 11
Training loss: 2.482084165782916
Validation loss: 2.7091962170183885

Epoch: 6| Step: 12
Training loss: 3.317394311596938
Validation loss: 2.707102020649747

Epoch: 6| Step: 13
Training loss: 3.230014976726568
Validation loss: 2.6982504344864315

Epoch: 349| Step: 0
Training loss: 3.0023838744310094
Validation loss: 2.6987343886877344

Epoch: 6| Step: 1
Training loss: 3.215456268065361
Validation loss: 2.6969495084938497

Epoch: 6| Step: 2
Training loss: 3.356749462279639
Validation loss: 2.7064664617575005

Epoch: 6| Step: 3
Training loss: 2.850795527741548
Validation loss: 2.701624159467301

Epoch: 6| Step: 4
Training loss: 2.920582857878942
Validation loss: 2.6994217806842546

Epoch: 6| Step: 5
Training loss: 3.208774552825327
Validation loss: 2.7010811542757183

Epoch: 6| Step: 6
Training loss: 2.9139908278091173
Validation loss: 2.703321070557224

Epoch: 6| Step: 7
Training loss: 1.6809066251637927
Validation loss: 2.70121853159612

Epoch: 6| Step: 8
Training loss: 3.000478388472809
Validation loss: 2.697588498489321

Epoch: 6| Step: 9
Training loss: 2.6331616631415327
Validation loss: 2.70124738359014

Epoch: 6| Step: 10
Training loss: 3.2700098706017706
Validation loss: 2.7047774602135957

Epoch: 6| Step: 11
Training loss: 3.1774837720983315
Validation loss: 2.718683663722182

Epoch: 6| Step: 12
Training loss: 3.334097647460664
Validation loss: 2.728354302999

Epoch: 6| Step: 13
Training loss: 3.6638662452438284
Validation loss: 2.7495236669447722

Epoch: 350| Step: 0
Training loss: 3.2321097139677977
Validation loss: 2.740210557531126

Epoch: 6| Step: 1
Training loss: 2.417850423700093
Validation loss: 2.737086043387362

Epoch: 6| Step: 2
Training loss: 2.496891950757446
Validation loss: 2.751665706261562

Epoch: 6| Step: 3
Training loss: 2.9555647525628324
Validation loss: 2.7247477121967316

Epoch: 6| Step: 4
Training loss: 2.906834697357879
Validation loss: 2.718794893396946

Epoch: 6| Step: 5
Training loss: 3.578600189772155
Validation loss: 2.726210962452092

Epoch: 6| Step: 6
Training loss: 3.5211076497915963
Validation loss: 2.7322608934167403

Epoch: 6| Step: 7
Training loss: 2.73810223090817
Validation loss: 2.7271703335280537

Epoch: 6| Step: 8
Training loss: 3.0170733674725105
Validation loss: 2.720097143108199

Epoch: 6| Step: 9
Training loss: 3.5003149708304155
Validation loss: 2.7283274463927296

Epoch: 6| Step: 10
Training loss: 2.749099410584292
Validation loss: 2.7184151620204555

Epoch: 6| Step: 11
Training loss: 3.028150566630895
Validation loss: 2.7306155432710195

Epoch: 6| Step: 12
Training loss: 3.2323433950065064
Validation loss: 2.7178683531641448

Epoch: 6| Step: 13
Training loss: 2.2550835931005615
Validation loss: 2.70496007326242

Epoch: 351| Step: 0
Training loss: 2.8357390867660746
Validation loss: 2.6980363096567594

Epoch: 6| Step: 1
Training loss: 3.399318116194825
Validation loss: 2.699568253676759

Epoch: 6| Step: 2
Training loss: 3.0710387790508413
Validation loss: 2.695785013553751

Epoch: 6| Step: 3
Training loss: 3.1589965955927837
Validation loss: 2.6971166468782

Epoch: 6| Step: 4
Training loss: 2.607217044857244
Validation loss: 2.6976250399701622

Epoch: 6| Step: 5
Training loss: 3.0594088465812397
Validation loss: 2.6959681216015094

Epoch: 6| Step: 6
Training loss: 3.0704678018133746
Validation loss: 2.6997436983639846

Epoch: 6| Step: 7
Training loss: 3.1204260349391983
Validation loss: 2.6976486185657382

Epoch: 6| Step: 8
Training loss: 2.778876331115736
Validation loss: 2.6972596846241363

Epoch: 6| Step: 9
Training loss: 3.1394077048552784
Validation loss: 2.698259656259611

Epoch: 6| Step: 10
Training loss: 3.0367543690729244
Validation loss: 2.6942992239089114

Epoch: 6| Step: 11
Training loss: 2.7421110745726893
Validation loss: 2.6972587417664764

Epoch: 6| Step: 12
Training loss: 2.851658148010598
Validation loss: 2.694938868942427

Epoch: 6| Step: 13
Training loss: 3.694347037717926
Validation loss: 2.6925766328088447

Epoch: 352| Step: 0
Training loss: 3.7537041489642813
Validation loss: 2.694992935333042

Epoch: 6| Step: 1
Training loss: 2.652062919480199
Validation loss: 2.697426656476944

Epoch: 6| Step: 2
Training loss: 3.345296911909765
Validation loss: 2.698106213102459

Epoch: 6| Step: 3
Training loss: 3.2467796803674065
Validation loss: 2.696740047854231

Epoch: 6| Step: 4
Training loss: 2.998659788224182
Validation loss: 2.6934605753244223

Epoch: 6| Step: 5
Training loss: 2.7235309175543634
Validation loss: 2.695930508786934

Epoch: 6| Step: 6
Training loss: 2.546920495124237
Validation loss: 2.6982946247927435

Epoch: 6| Step: 7
Training loss: 2.2000026356074414
Validation loss: 2.7031458997846136

Epoch: 6| Step: 8
Training loss: 3.103429275761463
Validation loss: 2.717890322408037

Epoch: 6| Step: 9
Training loss: 3.2888666307566785
Validation loss: 2.717869254914974

Epoch: 6| Step: 10
Training loss: 2.7824181664455665
Validation loss: 2.716113159170671

Epoch: 6| Step: 11
Training loss: 3.0308851828731904
Validation loss: 2.7163577174051685

Epoch: 6| Step: 12
Training loss: 2.5934953679487798
Validation loss: 2.707016728198323

Epoch: 6| Step: 13
Training loss: 3.958876575871109
Validation loss: 2.7048127643613875

Epoch: 353| Step: 0
Training loss: 3.2176433253284555
Validation loss: 2.7049906950674902

Epoch: 6| Step: 1
Training loss: 3.0496774158922806
Validation loss: 2.692486880261296

Epoch: 6| Step: 2
Training loss: 3.36740217830005
Validation loss: 2.6924627641991954

Epoch: 6| Step: 3
Training loss: 2.5356401589993354
Validation loss: 2.6921752343582726

Epoch: 6| Step: 4
Training loss: 2.279371454870523
Validation loss: 2.6920269335066327

Epoch: 6| Step: 5
Training loss: 2.908715955455514
Validation loss: 2.689775558090075

Epoch: 6| Step: 6
Training loss: 3.3286933234586487
Validation loss: 2.689372863627602

Epoch: 6| Step: 7
Training loss: 2.176881686519897
Validation loss: 2.6926993851514887

Epoch: 6| Step: 8
Training loss: 3.403763729856484
Validation loss: 2.6995914525375047

Epoch: 6| Step: 9
Training loss: 2.543038878521305
Validation loss: 2.693520247877534

Epoch: 6| Step: 10
Training loss: 2.5795177974600856
Validation loss: 2.694911303569618

Epoch: 6| Step: 11
Training loss: 3.244948055280658
Validation loss: 2.6991470660052808

Epoch: 6| Step: 12
Training loss: 3.628843966012191
Validation loss: 2.700389355288757

Epoch: 6| Step: 13
Training loss: 3.8281973695726337
Validation loss: 2.6970199980784626

Epoch: 354| Step: 0
Training loss: 2.5729213101941006
Validation loss: 2.7034489650138673

Epoch: 6| Step: 1
Training loss: 3.2246964718420017
Validation loss: 2.697104066827953

Epoch: 6| Step: 2
Training loss: 2.6181868282183482
Validation loss: 2.696183812221288

Epoch: 6| Step: 3
Training loss: 2.5131005361827765
Validation loss: 2.7029244839753197

Epoch: 6| Step: 4
Training loss: 2.6322648472105907
Validation loss: 2.700676739636937

Epoch: 6| Step: 5
Training loss: 3.3397148241289027
Validation loss: 2.7066700474837027

Epoch: 6| Step: 6
Training loss: 3.4000281108367294
Validation loss: 2.7084960459508345

Epoch: 6| Step: 7
Training loss: 2.7196385477230667
Validation loss: 2.7055967118233033

Epoch: 6| Step: 8
Training loss: 3.1767516583190467
Validation loss: 2.704652967900971

Epoch: 6| Step: 9
Training loss: 3.2190033155591893
Validation loss: 2.693456726235175

Epoch: 6| Step: 10
Training loss: 3.1002085154147765
Validation loss: 2.707215191129349

Epoch: 6| Step: 11
Training loss: 2.7823956305302273
Validation loss: 2.713328164967413

Epoch: 6| Step: 12
Training loss: 3.1710790377715194
Validation loss: 2.7005335411291504

Epoch: 6| Step: 13
Training loss: 3.762051227965071
Validation loss: 2.71554926382858

Epoch: 355| Step: 0
Training loss: 2.9975292840056924
Validation loss: 2.7073620445214908

Epoch: 6| Step: 1
Training loss: 3.3629219669632224
Validation loss: 2.7253856818383926

Epoch: 6| Step: 2
Training loss: 3.347514092755442
Validation loss: 2.7275999454162974

Epoch: 6| Step: 3
Training loss: 3.3674511728803727
Validation loss: 2.723802377167961

Epoch: 6| Step: 4
Training loss: 2.38728288392287
Validation loss: 2.7321679790587297

Epoch: 6| Step: 5
Training loss: 2.270654922149594
Validation loss: 2.746978494477836

Epoch: 6| Step: 6
Training loss: 3.1194613392765764
Validation loss: 2.7630329706880854

Epoch: 6| Step: 7
Training loss: 3.048960593044294
Validation loss: 2.746127194548824

Epoch: 6| Step: 8
Training loss: 2.7810860917730533
Validation loss: 2.739149609454128

Epoch: 6| Step: 9
Training loss: 2.7722855015601557
Validation loss: 2.7275623326870253

Epoch: 6| Step: 10
Training loss: 3.676384936064247
Validation loss: 2.713225305717242

Epoch: 6| Step: 11
Training loss: 3.018128615847389
Validation loss: 2.7067420181220387

Epoch: 6| Step: 12
Training loss: 2.7225145606850463
Validation loss: 2.702401954030639

Epoch: 6| Step: 13
Training loss: 3.1466765294755583
Validation loss: 2.6879352962059855

Epoch: 356| Step: 0
Training loss: 3.525944327621929
Validation loss: 2.692924956518045

Epoch: 6| Step: 1
Training loss: 2.8233514617494047
Validation loss: 2.69378020757345

Epoch: 6| Step: 2
Training loss: 2.678755172603453
Validation loss: 2.6955547711937307

Epoch: 6| Step: 3
Training loss: 2.9449634294554623
Validation loss: 2.6952731022177927

Epoch: 6| Step: 4
Training loss: 3.5630302703796386
Validation loss: 2.694844778127441

Epoch: 6| Step: 5
Training loss: 3.35776612545774
Validation loss: 2.692449266422652

Epoch: 6| Step: 6
Training loss: 3.3261996865579793
Validation loss: 2.6912342483727647

Epoch: 6| Step: 7
Training loss: 3.0150781639683686
Validation loss: 2.685299894518823

Epoch: 6| Step: 8
Training loss: 2.8321437208270206
Validation loss: 2.6881866178937823

Epoch: 6| Step: 9
Training loss: 3.2144135828166984
Validation loss: 2.687447119323977

Epoch: 6| Step: 10
Training loss: 2.6461591344773705
Validation loss: 2.6899944813913375

Epoch: 6| Step: 11
Training loss: 2.469363269203571
Validation loss: 2.684674645860495

Epoch: 6| Step: 12
Training loss: 2.3574230886233414
Validation loss: 2.6865942884284975

Epoch: 6| Step: 13
Training loss: 3.2879635386150814
Validation loss: 2.691948332609328

Epoch: 357| Step: 0
Training loss: 3.2310946871768462
Validation loss: 2.6909443798779384

Epoch: 6| Step: 1
Training loss: 2.3265054689363973
Validation loss: 2.6845554113594665

Epoch: 6| Step: 2
Training loss: 2.9027641474532073
Validation loss: 2.6921300332324085

Epoch: 6| Step: 3
Training loss: 3.2538895440560043
Validation loss: 2.698516640890656

Epoch: 6| Step: 4
Training loss: 2.9425484312831247
Validation loss: 2.7137333346377326

Epoch: 6| Step: 5
Training loss: 3.424506860579955
Validation loss: 2.719478531726265

Epoch: 6| Step: 6
Training loss: 2.7236117160071722
Validation loss: 2.7325263271064193

Epoch: 6| Step: 7
Training loss: 3.1099908113497197
Validation loss: 2.735528994109911

Epoch: 6| Step: 8
Training loss: 3.127434507030349
Validation loss: 2.7427377979815546

Epoch: 6| Step: 9
Training loss: 3.080396714361103
Validation loss: 2.7403226918628008

Epoch: 6| Step: 10
Training loss: 3.1427331937152863
Validation loss: 2.740574577901257

Epoch: 6| Step: 11
Training loss: 2.4972916237599407
Validation loss: 2.7137749026318514

Epoch: 6| Step: 12
Training loss: 3.022710983952135
Validation loss: 2.696911637499342

Epoch: 6| Step: 13
Training loss: 3.3014221652635487
Validation loss: 2.7075961969062323

Epoch: 358| Step: 0
Training loss: 3.3873805683098244
Validation loss: 2.692223196220513

Epoch: 6| Step: 1
Training loss: 3.1602627768085116
Validation loss: 2.6894015953370216

Epoch: 6| Step: 2
Training loss: 2.1106617711472904
Validation loss: 2.688480006779252

Epoch: 6| Step: 3
Training loss: 3.382207309778027
Validation loss: 2.6918828186800674

Epoch: 6| Step: 4
Training loss: 2.9856638097766073
Validation loss: 2.6867073418307124

Epoch: 6| Step: 5
Training loss: 3.1525180016895322
Validation loss: 2.688962305339567

Epoch: 6| Step: 6
Training loss: 3.3751770255674676
Validation loss: 2.682823804252366

Epoch: 6| Step: 7
Training loss: 3.1526934537286677
Validation loss: 2.687521540218493

Epoch: 6| Step: 8
Training loss: 2.967326736598273
Validation loss: 2.688875338189069

Epoch: 6| Step: 9
Training loss: 3.178069281675725
Validation loss: 2.6884227846373525

Epoch: 6| Step: 10
Training loss: 3.032913695292575
Validation loss: 2.6862573624485875

Epoch: 6| Step: 11
Training loss: 2.890687849031706
Validation loss: 2.686100566088684

Epoch: 6| Step: 12
Training loss: 2.453178259398957
Validation loss: 2.6998753249606304

Epoch: 6| Step: 13
Training loss: 2.292285199933833
Validation loss: 2.7019262966516813

Epoch: 359| Step: 0
Training loss: 3.3495799071681205
Validation loss: 2.718208751331399

Epoch: 6| Step: 1
Training loss: 3.5561541874587594
Validation loss: 2.7239681450693314

Epoch: 6| Step: 2
Training loss: 3.365520303526952
Validation loss: 2.7289442021650463

Epoch: 6| Step: 3
Training loss: 3.0102082458646744
Validation loss: 2.728892190359057

Epoch: 6| Step: 4
Training loss: 3.2733033364417725
Validation loss: 2.735638493028918

Epoch: 6| Step: 5
Training loss: 2.9915911127465695
Validation loss: 2.7283731424940108

Epoch: 6| Step: 6
Training loss: 2.569890877600101
Validation loss: 2.704898904434435

Epoch: 6| Step: 7
Training loss: 2.9920042295579035
Validation loss: 2.6932781068342635

Epoch: 6| Step: 8
Training loss: 2.896970146122817
Validation loss: 2.6837801533821724

Epoch: 6| Step: 9
Training loss: 2.0950013022771534
Validation loss: 2.679496981991275

Epoch: 6| Step: 10
Training loss: 2.9516704549680752
Validation loss: 2.6800690980187905

Epoch: 6| Step: 11
Training loss: 2.495812915172919
Validation loss: 2.6809643610747327

Epoch: 6| Step: 12
Training loss: 3.122938162585674
Validation loss: 2.6819517027502924

Epoch: 6| Step: 13
Training loss: 3.386461083137165
Validation loss: 2.6827387461752448

Epoch: 360| Step: 0
Training loss: 2.827617114919201
Validation loss: 2.6814915464938753

Epoch: 6| Step: 1
Training loss: 3.161171880792329
Validation loss: 2.68275211506671

Epoch: 6| Step: 2
Training loss: 3.602028243594346
Validation loss: 2.6816309158759717

Epoch: 6| Step: 3
Training loss: 2.950070693898542
Validation loss: 2.6814413333090994

Epoch: 6| Step: 4
Training loss: 3.4729794672593277
Validation loss: 2.6809673368864764

Epoch: 6| Step: 5
Training loss: 2.972406324189057
Validation loss: 2.690039949506633

Epoch: 6| Step: 6
Training loss: 2.9563051892022414
Validation loss: 2.6806249295186144

Epoch: 6| Step: 7
Training loss: 3.1336963957259703
Validation loss: 2.6792007396916326

Epoch: 6| Step: 8
Training loss: 2.929621418525573
Validation loss: 2.6790321055907116

Epoch: 6| Step: 9
Training loss: 2.840708520918306
Validation loss: 2.682021713809813

Epoch: 6| Step: 10
Training loss: 2.438509414201014
Validation loss: 2.679711369406034

Epoch: 6| Step: 11
Training loss: 2.890406749837191
Validation loss: 2.679866011219004

Epoch: 6| Step: 12
Training loss: 3.273093558293929
Validation loss: 2.6799676933355516

Epoch: 6| Step: 13
Training loss: 1.9205863788369995
Validation loss: 2.6764877293279903

Epoch: 361| Step: 0
Training loss: 3.3581418635180817
Validation loss: 2.680462789194

Epoch: 6| Step: 1
Training loss: 2.8165232386741814
Validation loss: 2.687962672745208

Epoch: 6| Step: 2
Training loss: 3.271082210588749
Validation loss: 2.6826362191838315

Epoch: 6| Step: 3
Training loss: 3.140651721745773
Validation loss: 2.68681321522772

Epoch: 6| Step: 4
Training loss: 2.918175298077979
Validation loss: 2.6801115200588836

Epoch: 6| Step: 5
Training loss: 2.7344920977996017
Validation loss: 2.690472368295954

Epoch: 6| Step: 6
Training loss: 2.9280903849799964
Validation loss: 2.6943082907899374

Epoch: 6| Step: 7
Training loss: 2.2799731299841466
Validation loss: 2.6928372091152637

Epoch: 6| Step: 8
Training loss: 3.236399141590314
Validation loss: 2.6982397152993873

Epoch: 6| Step: 9
Training loss: 3.1083065478386964
Validation loss: 2.7105838575350543

Epoch: 6| Step: 10
Training loss: 3.2625802918123656
Validation loss: 2.6981026262348315

Epoch: 6| Step: 11
Training loss: 2.9441542232483333
Validation loss: 2.6893520055163918

Epoch: 6| Step: 12
Training loss: 3.088375779704445
Validation loss: 2.6901440178450233

Epoch: 6| Step: 13
Training loss: 2.6555741291735555
Validation loss: 2.681814501849755

Epoch: 362| Step: 0
Training loss: 3.3785460881026315
Validation loss: 2.6813557724498738

Epoch: 6| Step: 1
Training loss: 2.8414255220747138
Validation loss: 2.6822950398780043

Epoch: 6| Step: 2
Training loss: 3.2217958723650506
Validation loss: 2.676689080294283

Epoch: 6| Step: 3
Training loss: 2.925954001283505
Validation loss: 2.676298270003952

Epoch: 6| Step: 4
Training loss: 3.0025568239042415
Validation loss: 2.677031607064502

Epoch: 6| Step: 5
Training loss: 2.7005892640397717
Validation loss: 2.682490237028581

Epoch: 6| Step: 6
Training loss: 3.344475212955426
Validation loss: 2.6760687287778224

Epoch: 6| Step: 7
Training loss: 2.947230031055776
Validation loss: 2.6820536661494403

Epoch: 6| Step: 8
Training loss: 3.103466458468319
Validation loss: 2.682799377720833

Epoch: 6| Step: 9
Training loss: 2.8479479311994527
Validation loss: 2.6776117303159968

Epoch: 6| Step: 10
Training loss: 3.1071961403022312
Validation loss: 2.6788065223441637

Epoch: 6| Step: 11
Training loss: 2.8766610695912296
Validation loss: 2.681606694536602

Epoch: 6| Step: 12
Training loss: 2.4798208276567633
Validation loss: 2.6797142643343688

Epoch: 6| Step: 13
Training loss: 3.2626486908802392
Validation loss: 2.677666403156959

Epoch: 363| Step: 0
Training loss: 2.862544903132304
Validation loss: 2.682352385096038

Epoch: 6| Step: 1
Training loss: 3.558954716787987
Validation loss: 2.6746829877314187

Epoch: 6| Step: 2
Training loss: 2.845091115769625
Validation loss: 2.6835037056086923

Epoch: 6| Step: 3
Training loss: 3.3045902463341794
Validation loss: 2.684604466205591

Epoch: 6| Step: 4
Training loss: 2.4320418061377476
Validation loss: 2.6929310887618385

Epoch: 6| Step: 5
Training loss: 3.2191587021982877
Validation loss: 2.6941347387860564

Epoch: 6| Step: 6
Training loss: 2.704268373556564
Validation loss: 2.712118029533313

Epoch: 6| Step: 7
Training loss: 2.9139538455782303
Validation loss: 2.7054763497862817

Epoch: 6| Step: 8
Training loss: 2.731171742590424
Validation loss: 2.70302733212221

Epoch: 6| Step: 9
Training loss: 2.929073991751952
Validation loss: 2.7163520901186646

Epoch: 6| Step: 10
Training loss: 2.8658414170340776
Validation loss: 2.7025006073568965

Epoch: 6| Step: 11
Training loss: 3.137487257973379
Validation loss: 2.701308203766551

Epoch: 6| Step: 12
Training loss: 3.328070841603796
Validation loss: 2.6928190178148173

Epoch: 6| Step: 13
Training loss: 3.044965409707223
Validation loss: 2.6932357513069736

Epoch: 364| Step: 0
Training loss: 2.783979212655914
Validation loss: 2.692986019391909

Epoch: 6| Step: 1
Training loss: 2.8313438686279335
Validation loss: 2.684588527227089

Epoch: 6| Step: 2
Training loss: 3.6787343987753993
Validation loss: 2.681851505842493

Epoch: 6| Step: 3
Training loss: 2.982100493796703
Validation loss: 2.6766631534548098

Epoch: 6| Step: 4
Training loss: 3.1900585602075884
Validation loss: 2.686208032388338

Epoch: 6| Step: 5
Training loss: 3.217728832439323
Validation loss: 2.6790980763465724

Epoch: 6| Step: 6
Training loss: 2.7761679519833864
Validation loss: 2.6780326021795067

Epoch: 6| Step: 7
Training loss: 2.853757081726885
Validation loss: 2.675660864176763

Epoch: 6| Step: 8
Training loss: 3.3980283293550704
Validation loss: 2.67906657582669

Epoch: 6| Step: 9
Training loss: 2.9119100931038076
Validation loss: 2.683155608273917

Epoch: 6| Step: 10
Training loss: 2.7200377472894908
Validation loss: 2.6930012213504275

Epoch: 6| Step: 11
Training loss: 2.970746142234567
Validation loss: 2.6823566008769397

Epoch: 6| Step: 12
Training loss: 2.1717338241689634
Validation loss: 2.6772783036926486

Epoch: 6| Step: 13
Training loss: 3.428384103085384
Validation loss: 2.694382661089196

Epoch: 365| Step: 0
Training loss: 2.5550411807808184
Validation loss: 2.694540504443456

Epoch: 6| Step: 1
Training loss: 2.665607172379799
Validation loss: 2.709461633738936

Epoch: 6| Step: 2
Training loss: 3.103895563836453
Validation loss: 2.7033234831078223

Epoch: 6| Step: 3
Training loss: 2.582953630250487
Validation loss: 2.719597168331236

Epoch: 6| Step: 4
Training loss: 3.253459702862012
Validation loss: 2.715648348639342

Epoch: 6| Step: 5
Training loss: 3.291084881967857
Validation loss: 2.7262839923074833

Epoch: 6| Step: 6
Training loss: 3.481559950558234
Validation loss: 2.720579509381034

Epoch: 6| Step: 7
Training loss: 2.9126660475651294
Validation loss: 2.713356638290258

Epoch: 6| Step: 8
Training loss: 2.9562022812199835
Validation loss: 2.709685729291658

Epoch: 6| Step: 9
Training loss: 3.0681602952504083
Validation loss: 2.699268347553984

Epoch: 6| Step: 10
Training loss: 3.2671670147742984
Validation loss: 2.6867400266009565

Epoch: 6| Step: 11
Training loss: 2.9142418363885025
Validation loss: 2.69340184089829

Epoch: 6| Step: 12
Training loss: 3.0509187909136486
Validation loss: 2.682913464401116

Epoch: 6| Step: 13
Training loss: 2.415423654551979
Validation loss: 2.6867582647856363

Epoch: 366| Step: 0
Training loss: 2.897509485448101
Validation loss: 2.6765134844998255

Epoch: 6| Step: 1
Training loss: 2.8928789578646317
Validation loss: 2.6711918143876314

Epoch: 6| Step: 2
Training loss: 3.1187555102832865
Validation loss: 2.677121348203107

Epoch: 6| Step: 3
Training loss: 2.7601578981042083
Validation loss: 2.6789025229325407

Epoch: 6| Step: 4
Training loss: 2.4583129450927808
Validation loss: 2.680629067682199

Epoch: 6| Step: 5
Training loss: 3.7724912732568803
Validation loss: 2.674777657429785

Epoch: 6| Step: 6
Training loss: 2.982260709054052
Validation loss: 2.674703695696353

Epoch: 6| Step: 7
Training loss: 3.3203035960358553
Validation loss: 2.6764361856736927

Epoch: 6| Step: 8
Training loss: 3.4500591770570126
Validation loss: 2.676246481303901

Epoch: 6| Step: 9
Training loss: 2.5664435954403246
Validation loss: 2.675161090455226

Epoch: 6| Step: 10
Training loss: 3.1883023318112733
Validation loss: 2.6699501659804223

Epoch: 6| Step: 11
Training loss: 3.055857558690579
Validation loss: 2.676888938393785

Epoch: 6| Step: 12
Training loss: 2.890787315966421
Validation loss: 2.674843248151067

Epoch: 6| Step: 13
Training loss: 1.702596599958411
Validation loss: 2.6692556675025663

Epoch: 367| Step: 0
Training loss: 2.2737765239659593
Validation loss: 2.6773646459723923

Epoch: 6| Step: 1
Training loss: 3.534374373998342
Validation loss: 2.6748593956718927

Epoch: 6| Step: 2
Training loss: 2.646800387613338
Validation loss: 2.673607421525841

Epoch: 6| Step: 3
Training loss: 2.45936287049304
Validation loss: 2.6810604651200447

Epoch: 6| Step: 4
Training loss: 2.5975034281585954
Validation loss: 2.6921873660752906

Epoch: 6| Step: 5
Training loss: 2.9406464951932563
Validation loss: 2.68927277543939

Epoch: 6| Step: 6
Training loss: 3.2136204409514475
Validation loss: 2.685720252681756

Epoch: 6| Step: 7
Training loss: 3.100674057556849
Validation loss: 2.6863040356830576

Epoch: 6| Step: 8
Training loss: 3.1750451392622026
Validation loss: 2.681652666712317

Epoch: 6| Step: 9
Training loss: 2.8650741064263836
Validation loss: 2.684195038127481

Epoch: 6| Step: 10
Training loss: 3.171752025306231
Validation loss: 2.701242377778698

Epoch: 6| Step: 11
Training loss: 3.2808295570941564
Validation loss: 2.7047755911130302

Epoch: 6| Step: 12
Training loss: 3.3570540106243487
Validation loss: 2.700342830095323

Epoch: 6| Step: 13
Training loss: 3.0830019351781166
Validation loss: 2.7184861691290614

Epoch: 368| Step: 0
Training loss: 2.0235593309878097
Validation loss: 2.716338579392673

Epoch: 6| Step: 1
Training loss: 2.8950418904754076
Validation loss: 2.7219782451311727

Epoch: 6| Step: 2
Training loss: 2.5211178537593093
Validation loss: 2.716358227045635

Epoch: 6| Step: 3
Training loss: 3.797163461786941
Validation loss: 2.7308822802927857

Epoch: 6| Step: 4
Training loss: 2.417174866833806
Validation loss: 2.7247052982678523

Epoch: 6| Step: 5
Training loss: 2.936520352249377
Validation loss: 2.736887485322137

Epoch: 6| Step: 6
Training loss: 3.7602802508998736
Validation loss: 2.7209586758367146

Epoch: 6| Step: 7
Training loss: 2.894667649240677
Validation loss: 2.7128873099909976

Epoch: 6| Step: 8
Training loss: 3.0336803642991748
Validation loss: 2.706034055552369

Epoch: 6| Step: 9
Training loss: 3.5969518578717006
Validation loss: 2.684163044421887

Epoch: 6| Step: 10
Training loss: 3.110090777185448
Validation loss: 2.672313249098896

Epoch: 6| Step: 11
Training loss: 2.7677538593200897
Validation loss: 2.6778723086123883

Epoch: 6| Step: 12
Training loss: 2.8833272004108217
Validation loss: 2.680627365364696

Epoch: 6| Step: 13
Training loss: 2.646168324647577
Validation loss: 2.6726880201761034

Epoch: 369| Step: 0
Training loss: 2.6258042329680724
Validation loss: 2.670027473991685

Epoch: 6| Step: 1
Training loss: 3.501401892965795
Validation loss: 2.6730607275494878

Epoch: 6| Step: 2
Training loss: 2.591191972229109
Validation loss: 2.677432207527525

Epoch: 6| Step: 3
Training loss: 2.8594248616191345
Validation loss: 2.678150909471186

Epoch: 6| Step: 4
Training loss: 2.7841699252832184
Validation loss: 2.6893901545464733

Epoch: 6| Step: 5
Training loss: 2.9822920475589902
Validation loss: 2.7195507695359975

Epoch: 6| Step: 6
Training loss: 3.219447384440634
Validation loss: 2.6979849201715873

Epoch: 6| Step: 7
Training loss: 3.60366184175746
Validation loss: 2.706693029195994

Epoch: 6| Step: 8
Training loss: 2.779379912454198
Validation loss: 2.7011601850996545

Epoch: 6| Step: 9
Training loss: 2.8361490133976193
Validation loss: 2.6867431906686585

Epoch: 6| Step: 10
Training loss: 2.9579776675481964
Validation loss: 2.677440981561992

Epoch: 6| Step: 11
Training loss: 3.4553657269714457
Validation loss: 2.6836414114699143

Epoch: 6| Step: 12
Training loss: 2.435540805738729
Validation loss: 2.6688466973416283

Epoch: 6| Step: 13
Training loss: 3.2488600859240084
Validation loss: 2.669934160642801

Epoch: 370| Step: 0
Training loss: 2.8665857333209996
Validation loss: 2.6672808211678385

Epoch: 6| Step: 1
Training loss: 3.3689874851971533
Validation loss: 2.6724731230635417

Epoch: 6| Step: 2
Training loss: 2.6913817118064545
Validation loss: 2.6772108613025214

Epoch: 6| Step: 3
Training loss: 3.089360523656861
Validation loss: 2.6781576197347032

Epoch: 6| Step: 4
Training loss: 2.765623448258304
Validation loss: 2.6770608466191796

Epoch: 6| Step: 5
Training loss: 2.9700317828086544
Validation loss: 2.6808469286223047

Epoch: 6| Step: 6
Training loss: 2.9907706070773323
Validation loss: 2.6895655111082983

Epoch: 6| Step: 7
Training loss: 3.378648269595205
Validation loss: 2.697678773132866

Epoch: 6| Step: 8
Training loss: 3.2596730287084554
Validation loss: 2.679195585997272

Epoch: 6| Step: 9
Training loss: 2.7088078205466672
Validation loss: 2.671651951196089

Epoch: 6| Step: 10
Training loss: 2.87018497123513
Validation loss: 2.6622438897943272

Epoch: 6| Step: 11
Training loss: 3.2312092053551673
Validation loss: 2.671329610778808

Epoch: 6| Step: 12
Training loss: 2.720973892047407
Validation loss: 2.6664942761299257

Epoch: 6| Step: 13
Training loss: 2.9719580733985906
Validation loss: 2.6702767061549473

Epoch: 371| Step: 0
Training loss: 2.372597332355717
Validation loss: 2.6678257821331774

Epoch: 6| Step: 1
Training loss: 2.988511658805174
Validation loss: 2.6664509923174733

Epoch: 6| Step: 2
Training loss: 2.459518168643445
Validation loss: 2.671933488026361

Epoch: 6| Step: 3
Training loss: 3.41118858765774
Validation loss: 2.673545101952404

Epoch: 6| Step: 4
Training loss: 2.7436057224443697
Validation loss: 2.6774428276147995

Epoch: 6| Step: 5
Training loss: 3.266011484447127
Validation loss: 2.6681787042522553

Epoch: 6| Step: 6
Training loss: 2.633665948295165
Validation loss: 2.67542225000015

Epoch: 6| Step: 7
Training loss: 3.0578412802642463
Validation loss: 2.6973090777387356

Epoch: 6| Step: 8
Training loss: 3.0900005392425953
Validation loss: 2.706284896226594

Epoch: 6| Step: 9
Training loss: 3.5592344609649023
Validation loss: 2.6916598182356672

Epoch: 6| Step: 10
Training loss: 3.07112681531901
Validation loss: 2.6714026851555044

Epoch: 6| Step: 11
Training loss: 2.503523441754258
Validation loss: 2.6706135795824073

Epoch: 6| Step: 12
Training loss: 3.0655349951547697
Validation loss: 2.6656831762658726

Epoch: 6| Step: 13
Training loss: 3.768227845011358
Validation loss: 2.6696566199943725

Epoch: 372| Step: 0
Training loss: 2.93558699630558
Validation loss: 2.6598945934590477

Epoch: 6| Step: 1
Training loss: 3.4711974161771892
Validation loss: 2.664982900243158

Epoch: 6| Step: 2
Training loss: 2.8125374685546727
Validation loss: 2.6614772931693023

Epoch: 6| Step: 3
Training loss: 2.0300855379921656
Validation loss: 2.667173852359431

Epoch: 6| Step: 4
Training loss: 2.6354811186818834
Validation loss: 2.670465269809229

Epoch: 6| Step: 5
Training loss: 3.0187437701111635
Validation loss: 2.6688330954948305

Epoch: 6| Step: 6
Training loss: 2.942636584642232
Validation loss: 2.6704240347077546

Epoch: 6| Step: 7
Training loss: 2.7658665438416015
Validation loss: 2.669521069906325

Epoch: 6| Step: 8
Training loss: 3.0978461997443496
Validation loss: 2.6720737032455193

Epoch: 6| Step: 9
Training loss: 3.1938526950756194
Validation loss: 2.6652932703379513

Epoch: 6| Step: 10
Training loss: 3.1286608805748903
Validation loss: 2.6686024827295274

Epoch: 6| Step: 11
Training loss: 3.3305763923418135
Validation loss: 2.670607239141908

Epoch: 6| Step: 12
Training loss: 3.0273928927462954
Validation loss: 2.6718254566906525

Epoch: 6| Step: 13
Training loss: 3.6573909707288
Validation loss: 2.6733026907715915

Epoch: 373| Step: 0
Training loss: 2.823409390586676
Validation loss: 2.673508218881491

Epoch: 6| Step: 1
Training loss: 3.086942176002952
Validation loss: 2.671313695280107

Epoch: 6| Step: 2
Training loss: 3.477418532689049
Validation loss: 2.679245673821771

Epoch: 6| Step: 3
Training loss: 2.9860010959753542
Validation loss: 2.668675328218421

Epoch: 6| Step: 4
Training loss: 2.965778188497363
Validation loss: 2.6833503472928832

Epoch: 6| Step: 5
Training loss: 2.74451723602826
Validation loss: 2.692505529880572

Epoch: 6| Step: 6
Training loss: 2.4274915971227506
Validation loss: 2.6988578925464393

Epoch: 6| Step: 7
Training loss: 2.7010037251926624
Validation loss: 2.6968387904236586

Epoch: 6| Step: 8
Training loss: 3.1008213800864395
Validation loss: 2.7202028883947746

Epoch: 6| Step: 9
Training loss: 3.4485451547111907
Validation loss: 2.7026494556462612

Epoch: 6| Step: 10
Training loss: 3.2471280246281014
Validation loss: 2.7229064910209204

Epoch: 6| Step: 11
Training loss: 2.854624152354999
Validation loss: 2.713354989574345

Epoch: 6| Step: 12
Training loss: 3.1329847940075326
Validation loss: 2.7036147875090655

Epoch: 6| Step: 13
Training loss: 2.5885602207145713
Validation loss: 2.690815630981242

Epoch: 374| Step: 0
Training loss: 3.342371576277277
Validation loss: 2.6664780798749064

Epoch: 6| Step: 1
Training loss: 3.0036440016783548
Validation loss: 2.6643419877858574

Epoch: 6| Step: 2
Training loss: 3.099674140046837
Validation loss: 2.6690614494039284

Epoch: 6| Step: 3
Training loss: 3.4724892746695866
Validation loss: 2.660657184924774

Epoch: 6| Step: 4
Training loss: 3.761799875812649
Validation loss: 2.6676680292810673

Epoch: 6| Step: 5
Training loss: 2.5493297331789897
Validation loss: 2.6637140900927383

Epoch: 6| Step: 6
Training loss: 3.187087088375013
Validation loss: 2.665285660085867

Epoch: 6| Step: 7
Training loss: 3.4580342879705204
Validation loss: 2.6614853708853135

Epoch: 6| Step: 8
Training loss: 2.517289742229088
Validation loss: 2.667701415805489

Epoch: 6| Step: 9
Training loss: 2.2624011023387895
Validation loss: 2.66620023811602

Epoch: 6| Step: 10
Training loss: 2.004607377268554
Validation loss: 2.663902849780876

Epoch: 6| Step: 11
Training loss: 2.977455946230467
Validation loss: 2.6628160754234402

Epoch: 6| Step: 12
Training loss: 2.2552357261585745
Validation loss: 2.674289779139443

Epoch: 6| Step: 13
Training loss: 3.645320107803222
Validation loss: 2.6655406773003545

Epoch: 375| Step: 0
Training loss: 2.8236211669495965
Validation loss: 2.6754641425310473

Epoch: 6| Step: 1
Training loss: 3.1842064390782645
Validation loss: 2.672974199249055

Epoch: 6| Step: 2
Training loss: 3.486997430063651
Validation loss: 2.6854123102894842

Epoch: 6| Step: 3
Training loss: 2.696697730540511
Validation loss: 2.6837377320174323

Epoch: 6| Step: 4
Training loss: 3.4814227131542093
Validation loss: 2.7069573256989314

Epoch: 6| Step: 5
Training loss: 3.6249926336805545
Validation loss: 2.6985639589954755

Epoch: 6| Step: 6
Training loss: 2.483741631534572
Validation loss: 2.706972507913807

Epoch: 6| Step: 7
Training loss: 2.703188680438941
Validation loss: 2.7112060869634194

Epoch: 6| Step: 8
Training loss: 3.117606916391455
Validation loss: 2.7018421426329446

Epoch: 6| Step: 9
Training loss: 2.3574443269306777
Validation loss: 2.6873345358703857

Epoch: 6| Step: 10
Training loss: 2.7486362543723564
Validation loss: 2.6851564325855084

Epoch: 6| Step: 11
Training loss: 2.755972013057348
Validation loss: 2.694069959361488

Epoch: 6| Step: 12
Training loss: 2.80984660126998
Validation loss: 2.683892811429163

Epoch: 6| Step: 13
Training loss: 3.3932912161660926
Validation loss: 2.671239223037074

Epoch: 376| Step: 0
Training loss: 3.0408625824527697
Validation loss: 2.670168205984409

Epoch: 6| Step: 1
Training loss: 3.2383852068845895
Validation loss: 2.6737759662955822

Epoch: 6| Step: 2
Training loss: 1.776823399425495
Validation loss: 2.660916514913026

Epoch: 6| Step: 3
Training loss: 3.020140434688304
Validation loss: 2.6682674921917964

Epoch: 6| Step: 4
Training loss: 3.391058828137771
Validation loss: 2.6702257175476185

Epoch: 6| Step: 5
Training loss: 2.9028168776544123
Validation loss: 2.6599089850738524

Epoch: 6| Step: 6
Training loss: 2.6466833736587403
Validation loss: 2.658425984899463

Epoch: 6| Step: 7
Training loss: 2.9888581959386578
Validation loss: 2.6671742973868575

Epoch: 6| Step: 8
Training loss: 2.9938673279135863
Validation loss: 2.6599121078088146

Epoch: 6| Step: 9
Training loss: 2.798786980272633
Validation loss: 2.663237018516492

Epoch: 6| Step: 10
Training loss: 3.5148187009415266
Validation loss: 2.6607750160996884

Epoch: 6| Step: 11
Training loss: 2.87371996704178
Validation loss: 2.662177351153234

Epoch: 6| Step: 12
Training loss: 2.8803601262319805
Validation loss: 2.674106553771223

Epoch: 6| Step: 13
Training loss: 3.6942382283288775
Validation loss: 2.6772253551775402

Epoch: 377| Step: 0
Training loss: 2.6540541604559054
Validation loss: 2.697265151671331

Epoch: 6| Step: 1
Training loss: 2.9924322680565805
Validation loss: 2.711603045917494

Epoch: 6| Step: 2
Training loss: 2.2604750407426657
Validation loss: 2.7330286633422145

Epoch: 6| Step: 3
Training loss: 3.526962242744195
Validation loss: 2.759885265414166

Epoch: 6| Step: 4
Training loss: 3.169865916211254
Validation loss: 2.7765533290335354

Epoch: 6| Step: 5
Training loss: 2.721119516772563
Validation loss: 2.7224100474484705

Epoch: 6| Step: 6
Training loss: 2.6053655280808696
Validation loss: 2.695307428474999

Epoch: 6| Step: 7
Training loss: 2.7897020135713286
Validation loss: 2.6728765345698

Epoch: 6| Step: 8
Training loss: 3.307533139201926
Validation loss: 2.6663999468972386

Epoch: 6| Step: 9
Training loss: 3.3506404435325403
Validation loss: 2.675495972922765

Epoch: 6| Step: 10
Training loss: 3.410343615091894
Validation loss: 2.6753804028085124

Epoch: 6| Step: 11
Training loss: 3.05398247038901
Validation loss: 2.6710356673918945

Epoch: 6| Step: 12
Training loss: 2.7472146406884446
Validation loss: 2.6673461858398615

Epoch: 6| Step: 13
Training loss: 3.3064367115396283
Validation loss: 2.6619992822679857

Epoch: 378| Step: 0
Training loss: 2.865464360550819
Validation loss: 2.658922586959489

Epoch: 6| Step: 1
Training loss: 3.0845304347549707
Validation loss: 2.6616286600600336

Epoch: 6| Step: 2
Training loss: 3.4312796058141877
Validation loss: 2.657825990258155

Epoch: 6| Step: 3
Training loss: 3.1148290292713976
Validation loss: 2.6567020646851205

Epoch: 6| Step: 4
Training loss: 2.8592926180285736
Validation loss: 2.6597993458384996

Epoch: 6| Step: 5
Training loss: 3.34481381044965
Validation loss: 2.660070305198266

Epoch: 6| Step: 6
Training loss: 2.9367921666301937
Validation loss: 2.667764346127349

Epoch: 6| Step: 7
Training loss: 3.2654956262688004
Validation loss: 2.6680742821651866

Epoch: 6| Step: 8
Training loss: 3.22623913047405
Validation loss: 2.6681989755648847

Epoch: 6| Step: 9
Training loss: 2.9673381459832684
Validation loss: 2.665470640191086

Epoch: 6| Step: 10
Training loss: 2.1959221152997213
Validation loss: 2.6660611986810614

Epoch: 6| Step: 11
Training loss: 2.9386524618132035
Validation loss: 2.665765581887721

Epoch: 6| Step: 12
Training loss: 2.5059925736715334
Validation loss: 2.6631793319661905

Epoch: 6| Step: 13
Training loss: 2.821913837828838
Validation loss: 2.6677268046218954

Epoch: 379| Step: 0
Training loss: 2.389577498978995
Validation loss: 2.664825519758159

Epoch: 6| Step: 1
Training loss: 3.4470265940499925
Validation loss: 2.6717847506495

Epoch: 6| Step: 2
Training loss: 2.635708266298256
Validation loss: 2.6720901351793045

Epoch: 6| Step: 3
Training loss: 3.3290183430948694
Validation loss: 2.679995422934853

Epoch: 6| Step: 4
Training loss: 2.9472565647640727
Validation loss: 2.679328037388704

Epoch: 6| Step: 5
Training loss: 2.657845948921006
Validation loss: 2.6836603967238877

Epoch: 6| Step: 6
Training loss: 2.924758386006631
Validation loss: 2.6871767147721712

Epoch: 6| Step: 7
Training loss: 3.3264056855487536
Validation loss: 2.6827453341133607

Epoch: 6| Step: 8
Training loss: 2.48635286497167
Validation loss: 2.679048771395627

Epoch: 6| Step: 9
Training loss: 3.364715731036367
Validation loss: 2.6799328023040423

Epoch: 6| Step: 10
Training loss: 3.018578540679371
Validation loss: 2.6769564023017147

Epoch: 6| Step: 11
Training loss: 3.5540579102048064
Validation loss: 2.6758231661317176

Epoch: 6| Step: 12
Training loss: 2.874300664349857
Validation loss: 2.668156170035329

Epoch: 6| Step: 13
Training loss: 2.3550888438383435
Validation loss: 2.6580690215350913

Epoch: 380| Step: 0
Training loss: 3.2041683823705345
Validation loss: 2.6519659096031316

Epoch: 6| Step: 1
Training loss: 2.9810652829571582
Validation loss: 2.6514987887892563

Epoch: 6| Step: 2
Training loss: 3.5978847435243875
Validation loss: 2.6488798958191637

Epoch: 6| Step: 3
Training loss: 3.0344069254302597
Validation loss: 2.652318110026357

Epoch: 6| Step: 4
Training loss: 2.9592128753563514
Validation loss: 2.654148288070182

Epoch: 6| Step: 5
Training loss: 2.664214636074803
Validation loss: 2.651780355785526

Epoch: 6| Step: 6
Training loss: 2.4647555327913926
Validation loss: 2.6557905095292256

Epoch: 6| Step: 7
Training loss: 2.8679836737302398
Validation loss: 2.65197741807518

Epoch: 6| Step: 8
Training loss: 2.799044401726363
Validation loss: 2.6511280485659774

Epoch: 6| Step: 9
Training loss: 2.376994149097757
Validation loss: 2.6480350298080557

Epoch: 6| Step: 10
Training loss: 3.4309852595244736
Validation loss: 2.6513093393821587

Epoch: 6| Step: 11
Training loss: 3.026532149273478
Validation loss: 2.6459427038145518

Epoch: 6| Step: 12
Training loss: 3.6092230694653846
Validation loss: 2.653353878109072

Epoch: 6| Step: 13
Training loss: 2.1557468435394207
Validation loss: 2.651815331072628

Epoch: 381| Step: 0
Training loss: 2.7748394069082374
Validation loss: 2.6480192202073223

Epoch: 6| Step: 1
Training loss: 3.3380164786195476
Validation loss: 2.655013221263014

Epoch: 6| Step: 2
Training loss: 3.394636602489855
Validation loss: 2.666958335979172

Epoch: 6| Step: 3
Training loss: 3.3881341601024344
Validation loss: 2.6620235327406396

Epoch: 6| Step: 4
Training loss: 3.0798025449402293
Validation loss: 2.68737843346572

Epoch: 6| Step: 5
Training loss: 2.1085170555230035
Validation loss: 2.6810630545191194

Epoch: 6| Step: 6
Training loss: 3.346300097472758
Validation loss: 2.6757160990518285

Epoch: 6| Step: 7
Training loss: 2.592652973602198
Validation loss: 2.68779608966787

Epoch: 6| Step: 8
Training loss: 2.335482039431335
Validation loss: 2.674138814471728

Epoch: 6| Step: 9
Training loss: 3.155391765277778
Validation loss: 2.6784656682989785

Epoch: 6| Step: 10
Training loss: 2.40722884048447
Validation loss: 2.6600291720642746

Epoch: 6| Step: 11
Training loss: 3.787762039234928
Validation loss: 2.6598701317759885

Epoch: 6| Step: 12
Training loss: 2.9273248937084513
Validation loss: 2.6496570327685802

Epoch: 6| Step: 13
Training loss: 2.477595742509169
Validation loss: 2.652628130533211

Epoch: 382| Step: 0
Training loss: 2.9809579510261686
Validation loss: 2.6529850746619537

Epoch: 6| Step: 1
Training loss: 2.9688910199853757
Validation loss: 2.6537974086269576

Epoch: 6| Step: 2
Training loss: 2.897624187029825
Validation loss: 2.6434700707839465

Epoch: 6| Step: 3
Training loss: 3.598808509957874
Validation loss: 2.6542890883423302

Epoch: 6| Step: 4
Training loss: 3.0157606657671754
Validation loss: 2.650091435686681

Epoch: 6| Step: 5
Training loss: 3.071119673140877
Validation loss: 2.6506900997058684

Epoch: 6| Step: 6
Training loss: 3.2784499073748274
Validation loss: 2.6544083843474255

Epoch: 6| Step: 7
Training loss: 2.790109304385748
Validation loss: 2.651167315241311

Epoch: 6| Step: 8
Training loss: 2.96657619195485
Validation loss: 2.6528553213600383

Epoch: 6| Step: 9
Training loss: 2.2296926881961032
Validation loss: 2.6559911245862966

Epoch: 6| Step: 10
Training loss: 2.7654688731807298
Validation loss: 2.656480387107161

Epoch: 6| Step: 11
Training loss: 2.8847722367899857
Validation loss: 2.649734749020756

Epoch: 6| Step: 12
Training loss: 3.0263145616995897
Validation loss: 2.6520784410792237

Epoch: 6| Step: 13
Training loss: 3.1578037478907506
Validation loss: 2.6589910871222946

Epoch: 383| Step: 0
Training loss: 3.0407785312198805
Validation loss: 2.658746657628002

Epoch: 6| Step: 1
Training loss: 2.161145168429432
Validation loss: 2.6529722602210066

Epoch: 6| Step: 2
Training loss: 2.5647837069150365
Validation loss: 2.6704393343842243

Epoch: 6| Step: 3
Training loss: 3.2360536209115187
Validation loss: 2.670646526591968

Epoch: 6| Step: 4
Training loss: 2.604780892732728
Validation loss: 2.6705971856010806

Epoch: 6| Step: 5
Training loss: 3.64083219929092
Validation loss: 2.6673763134280133

Epoch: 6| Step: 6
Training loss: 3.060496083357258
Validation loss: 2.6570059562584634

Epoch: 6| Step: 7
Training loss: 3.3549240078684015
Validation loss: 2.6694528956517787

Epoch: 6| Step: 8
Training loss: 2.8670853848683993
Validation loss: 2.6686143584791844

Epoch: 6| Step: 9
Training loss: 2.538355802343472
Validation loss: 2.6646034356252235

Epoch: 6| Step: 10
Training loss: 2.6801537644699405
Validation loss: 2.668437554978193

Epoch: 6| Step: 11
Training loss: 3.283840065466271
Validation loss: 2.673898449430659

Epoch: 6| Step: 12
Training loss: 3.2727624019509913
Validation loss: 2.678893902494954

Epoch: 6| Step: 13
Training loss: 3.1977377643722416
Validation loss: 2.6957420450316327

Epoch: 384| Step: 0
Training loss: 2.813813390301616
Validation loss: 2.6826226557184376

Epoch: 6| Step: 1
Training loss: 3.106089020209312
Validation loss: 2.6751661158418893

Epoch: 6| Step: 2
Training loss: 3.1549268914169066
Validation loss: 2.6791648569127897

Epoch: 6| Step: 3
Training loss: 3.1039044740961286
Validation loss: 2.6659765260571335

Epoch: 6| Step: 4
Training loss: 2.7912550570574135
Validation loss: 2.6727655070138603

Epoch: 6| Step: 5
Training loss: 3.012103935576158
Validation loss: 2.6634593802127013

Epoch: 6| Step: 6
Training loss: 2.3784865837560796
Validation loss: 2.653957001191605

Epoch: 6| Step: 7
Training loss: 2.1576395395004635
Validation loss: 2.6580084783500846

Epoch: 6| Step: 8
Training loss: 3.427697510262945
Validation loss: 2.655581555838703

Epoch: 6| Step: 9
Training loss: 3.070123176464513
Validation loss: 2.649828585031734

Epoch: 6| Step: 10
Training loss: 2.650041572676561
Validation loss: 2.6515281097666525

Epoch: 6| Step: 11
Training loss: 3.753818602238358
Validation loss: 2.658398043811561

Epoch: 6| Step: 12
Training loss: 2.9653918095227105
Validation loss: 2.654478355024714

Epoch: 6| Step: 13
Training loss: 3.0062968609304104
Validation loss: 2.6508781988229764

Epoch: 385| Step: 0
Training loss: 3.4432797479537522
Validation loss: 2.6529999386015075

Epoch: 6| Step: 1
Training loss: 3.590329873063492
Validation loss: 2.6502719190925133

Epoch: 6| Step: 2
Training loss: 2.642859151463868
Validation loss: 2.6476290784808585

Epoch: 6| Step: 3
Training loss: 2.867546703487092
Validation loss: 2.6477846897169695

Epoch: 6| Step: 4
Training loss: 3.058227361216871
Validation loss: 2.643632101184377

Epoch: 6| Step: 5
Training loss: 2.903924319108685
Validation loss: 2.6448907872993446

Epoch: 6| Step: 6
Training loss: 3.166700229132294
Validation loss: 2.642387544123889

Epoch: 6| Step: 7
Training loss: 2.7168473349409483
Validation loss: 2.6472013304187287

Epoch: 6| Step: 8
Training loss: 2.8953926977011886
Validation loss: 2.643624545914972

Epoch: 6| Step: 9
Training loss: 2.987727174940008
Validation loss: 2.6417280498683926

Epoch: 6| Step: 10
Training loss: 3.3651013206883587
Validation loss: 2.6501003103992637

Epoch: 6| Step: 11
Training loss: 1.7338448478866177
Validation loss: 2.6452063341679986

Epoch: 6| Step: 12
Training loss: 2.86848175190904
Validation loss: 2.6634387628924756

Epoch: 6| Step: 13
Training loss: 3.1257517101262113
Validation loss: 2.663354033848493

Epoch: 386| Step: 0
Training loss: 3.1760690706463097
Validation loss: 2.6854244821052986

Epoch: 6| Step: 1
Training loss: 3.2082811491714542
Validation loss: 2.6950635464834134

Epoch: 6| Step: 2
Training loss: 2.9311869535193305
Validation loss: 2.7141060663310896

Epoch: 6| Step: 3
Training loss: 3.9994570840506696
Validation loss: 2.705875040844665

Epoch: 6| Step: 4
Training loss: 2.892475092854001
Validation loss: 2.6910574877397404

Epoch: 6| Step: 5
Training loss: 3.2180563169948697
Validation loss: 2.6875086395742938

Epoch: 6| Step: 6
Training loss: 2.8624494523162203
Validation loss: 2.6589565224655773

Epoch: 6| Step: 7
Training loss: 2.826010656602641
Validation loss: 2.6449517233136586

Epoch: 6| Step: 8
Training loss: 2.7043986765153702
Validation loss: 2.6470936112139056

Epoch: 6| Step: 9
Training loss: 2.7610144681624
Validation loss: 2.642952156837475

Epoch: 6| Step: 10
Training loss: 2.820810627998544
Validation loss: 2.6552136247048614

Epoch: 6| Step: 11
Training loss: 2.681771138370803
Validation loss: 2.6490710470479844

Epoch: 6| Step: 12
Training loss: 2.3335674599851433
Validation loss: 2.6504089372730606

Epoch: 6| Step: 13
Training loss: 3.236269041545393
Validation loss: 2.6499267054099946

Epoch: 387| Step: 0
Training loss: 2.797704818632099
Validation loss: 2.6494342441884124

Epoch: 6| Step: 1
Training loss: 3.0040433973893315
Validation loss: 2.647734926564852

Epoch: 6| Step: 2
Training loss: 3.3516821495342226
Validation loss: 2.6544027691517726

Epoch: 6| Step: 3
Training loss: 3.0195899947794675
Validation loss: 2.6486937183302963

Epoch: 6| Step: 4
Training loss: 3.4561213271072453
Validation loss: 2.6484819861571465

Epoch: 6| Step: 5
Training loss: 3.019568202494622
Validation loss: 2.6461204125663267

Epoch: 6| Step: 6
Training loss: 2.8578722397455936
Validation loss: 2.6486516341966735

Epoch: 6| Step: 7
Training loss: 3.310729939398322
Validation loss: 2.649275149442831

Epoch: 6| Step: 8
Training loss: 2.427851728578311
Validation loss: 2.6453222669870047

Epoch: 6| Step: 9
Training loss: 2.889143940678785
Validation loss: 2.6533146080433947

Epoch: 6| Step: 10
Training loss: 2.904064710479325
Validation loss: 2.6458292282753484

Epoch: 6| Step: 11
Training loss: 2.0564567577917803
Validation loss: 2.6439525736772094

Epoch: 6| Step: 12
Training loss: 2.5955614865066896
Validation loss: 2.651410920601246

Epoch: 6| Step: 13
Training loss: 4.124281618390996
Validation loss: 2.661461750287839

Epoch: 388| Step: 0
Training loss: 2.8224412487257453
Validation loss: 2.653234009060394

Epoch: 6| Step: 1
Training loss: 2.733333978032602
Validation loss: 2.6571345642533744

Epoch: 6| Step: 2
Training loss: 3.29562831647718
Validation loss: 2.6547093613481114

Epoch: 6| Step: 3
Training loss: 2.9082347696502824
Validation loss: 2.663179228965409

Epoch: 6| Step: 4
Training loss: 3.2059514670788665
Validation loss: 2.66519140638996

Epoch: 6| Step: 5
Training loss: 2.9628122479024555
Validation loss: 2.668883136693387

Epoch: 6| Step: 6
Training loss: 3.276512868175155
Validation loss: 2.674478146122822

Epoch: 6| Step: 7
Training loss: 3.167185657201456
Validation loss: 2.672435368552066

Epoch: 6| Step: 8
Training loss: 3.0935352905983224
Validation loss: 2.6665930234702637

Epoch: 6| Step: 9
Training loss: 2.8897396897027186
Validation loss: 2.6864425961862546

Epoch: 6| Step: 10
Training loss: 2.606577395725987
Validation loss: 2.66451688283685

Epoch: 6| Step: 11
Training loss: 3.0238292351599823
Validation loss: 2.662882146583389

Epoch: 6| Step: 12
Training loss: 2.5374127001848894
Validation loss: 2.6616433408843685

Epoch: 6| Step: 13
Training loss: 3.011237871740231
Validation loss: 2.6564151198659927

Epoch: 389| Step: 0
Training loss: 2.731946204380524
Validation loss: 2.6553055292367453

Epoch: 6| Step: 1
Training loss: 3.3166523944285675
Validation loss: 2.6537858153085043

Epoch: 6| Step: 2
Training loss: 3.0368628693169755
Validation loss: 2.6570023959200832

Epoch: 6| Step: 3
Training loss: 3.0430906611691224
Validation loss: 2.667719216687775

Epoch: 6| Step: 4
Training loss: 2.1905004359812805
Validation loss: 2.6566674808618242

Epoch: 6| Step: 5
Training loss: 2.729501795879779
Validation loss: 2.6590112009425

Epoch: 6| Step: 6
Training loss: 3.3392986008852255
Validation loss: 2.6625999675329908

Epoch: 6| Step: 7
Training loss: 2.9354263453507894
Validation loss: 2.659410119642099

Epoch: 6| Step: 8
Training loss: 3.112631621124749
Validation loss: 2.657759585052779

Epoch: 6| Step: 9
Training loss: 3.1662324975844345
Validation loss: 2.6629592477482094

Epoch: 6| Step: 10
Training loss: 2.765617241282814
Validation loss: 2.6559477062839636

Epoch: 6| Step: 11
Training loss: 2.731739888896298
Validation loss: 2.668549198754728

Epoch: 6| Step: 12
Training loss: 3.3442485116854215
Validation loss: 2.6571432330930507

Epoch: 6| Step: 13
Training loss: 3.011649718526311
Validation loss: 2.656888830200983

Epoch: 390| Step: 0
Training loss: 3.054866541618008
Validation loss: 2.653390243271602

Epoch: 6| Step: 1
Training loss: 3.182746484265668
Validation loss: 2.6517045692580266

Epoch: 6| Step: 2
Training loss: 3.5170277149539078
Validation loss: 2.6535518147791506

Epoch: 6| Step: 3
Training loss: 3.400677944360831
Validation loss: 2.6506042561225422

Epoch: 6| Step: 4
Training loss: 3.3288848439378644
Validation loss: 2.6477334509679644

Epoch: 6| Step: 5
Training loss: 2.52347774886874
Validation loss: 2.6453489293436494

Epoch: 6| Step: 6
Training loss: 3.1165079317792173
Validation loss: 2.6416451331362403

Epoch: 6| Step: 7
Training loss: 3.248700689137511
Validation loss: 2.6395136540678337

Epoch: 6| Step: 8
Training loss: 2.5573611952477466
Validation loss: 2.6502552387066562

Epoch: 6| Step: 9
Training loss: 3.0105828544037747
Validation loss: 2.6404954801210625

Epoch: 6| Step: 10
Training loss: 2.387314043242835
Validation loss: 2.6419821708552504

Epoch: 6| Step: 11
Training loss: 2.5442913032470966
Validation loss: 2.635243294168138

Epoch: 6| Step: 12
Training loss: 2.2955333917640703
Validation loss: 2.640829341618009

Epoch: 6| Step: 13
Training loss: 3.2312010888653417
Validation loss: 2.6438913722229733

Epoch: 391| Step: 0
Training loss: 3.261831900638422
Validation loss: 2.6405178552442954

Epoch: 6| Step: 1
Training loss: 3.4505181462499364
Validation loss: 2.64839145848945

Epoch: 6| Step: 2
Training loss: 2.598999043504481
Validation loss: 2.648814410329569

Epoch: 6| Step: 3
Training loss: 3.066539669171514
Validation loss: 2.65218084781298

Epoch: 6| Step: 4
Training loss: 2.7050117567162975
Validation loss: 2.650285257328305

Epoch: 6| Step: 5
Training loss: 2.4830216854406753
Validation loss: 2.658318058967459

Epoch: 6| Step: 6
Training loss: 3.156264503370143
Validation loss: 2.6517292851212373

Epoch: 6| Step: 7
Training loss: 2.810930534723122
Validation loss: 2.6513839517795863

Epoch: 6| Step: 8
Training loss: 2.8349984455945365
Validation loss: 2.6596161506962885

Epoch: 6| Step: 9
Training loss: 3.3016279771037707
Validation loss: 2.6426888900227126

Epoch: 6| Step: 10
Training loss: 2.639227954653549
Validation loss: 2.6577482926075

Epoch: 6| Step: 11
Training loss: 3.148473696820075
Validation loss: 2.6450273088500484

Epoch: 6| Step: 12
Training loss: 2.7963876139747783
Validation loss: 2.6445681765885216

Epoch: 6| Step: 13
Training loss: 3.3796655408169674
Validation loss: 2.662830524417731

Epoch: 392| Step: 0
Training loss: 3.157574668357802
Validation loss: 2.642038035107435

Epoch: 6| Step: 1
Training loss: 3.229532495921339
Validation loss: 2.650338091133805

Epoch: 6| Step: 2
Training loss: 3.0315277916164276
Validation loss: 2.6506204429820364

Epoch: 6| Step: 3
Training loss: 2.7404671948715227
Validation loss: 2.6439786971657586

Epoch: 6| Step: 4
Training loss: 3.496093886391408
Validation loss: 2.6503003143930735

Epoch: 6| Step: 5
Training loss: 3.2945253216095582
Validation loss: 2.6581865262095152

Epoch: 6| Step: 6
Training loss: 2.96794679718454
Validation loss: 2.6537863669124215

Epoch: 6| Step: 7
Training loss: 2.811435413208278
Validation loss: 2.6629387777014406

Epoch: 6| Step: 8
Training loss: 2.719492843694261
Validation loss: 2.6677906890589758

Epoch: 6| Step: 9
Training loss: 1.9424368197305721
Validation loss: 2.6597054346025075

Epoch: 6| Step: 10
Training loss: 3.1069779093889855
Validation loss: 2.6551271925942665

Epoch: 6| Step: 11
Training loss: 2.673548748615661
Validation loss: 2.6558228044859664

Epoch: 6| Step: 12
Training loss: 2.8282828102552187
Validation loss: 2.6577297627458036

Epoch: 6| Step: 13
Training loss: 3.4611984395670703
Validation loss: 2.662333931992198

Epoch: 393| Step: 0
Training loss: 2.679144445616872
Validation loss: 2.666441893205417

Epoch: 6| Step: 1
Training loss: 3.3029148406675803
Validation loss: 2.66142675631773

Epoch: 6| Step: 2
Training loss: 3.2320776995298766
Validation loss: 2.6787745054331675

Epoch: 6| Step: 3
Training loss: 3.3902269824171904
Validation loss: 2.696060974148367

Epoch: 6| Step: 4
Training loss: 3.155230669152657
Validation loss: 2.6992918738052727

Epoch: 6| Step: 5
Training loss: 3.1354521858172064
Validation loss: 2.7160482035813676

Epoch: 6| Step: 6
Training loss: 2.8972237814239405
Validation loss: 2.718317509717401

Epoch: 6| Step: 7
Training loss: 2.2208964750988933
Validation loss: 2.7175675421977408

Epoch: 6| Step: 8
Training loss: 2.796303035282588
Validation loss: 2.6887993758493693

Epoch: 6| Step: 9
Training loss: 2.5649919256191063
Validation loss: 2.681230444109804

Epoch: 6| Step: 10
Training loss: 3.4009415444810354
Validation loss: 2.6778115597629326

Epoch: 6| Step: 11
Training loss: 2.637701910887017
Validation loss: 2.6637971552424564

Epoch: 6| Step: 12
Training loss: 3.0026320990757265
Validation loss: 2.645811990838033

Epoch: 6| Step: 13
Training loss: 3.051545773883692
Validation loss: 2.6380476174263605

Epoch: 394| Step: 0
Training loss: 3.043102256578661
Validation loss: 2.6430922741885396

Epoch: 6| Step: 1
Training loss: 2.8457904244609464
Validation loss: 2.6439889440341493

Epoch: 6| Step: 2
Training loss: 3.212369650485807
Validation loss: 2.6451813955040655

Epoch: 6| Step: 3
Training loss: 2.5237063804964506
Validation loss: 2.645330206993584

Epoch: 6| Step: 4
Training loss: 2.2326104726082208
Validation loss: 2.6470069565766225

Epoch: 6| Step: 5
Training loss: 2.8595560985811446
Validation loss: 2.650952991140643

Epoch: 6| Step: 6
Training loss: 2.2493965611294935
Validation loss: 2.648903466985971

Epoch: 6| Step: 7
Training loss: 3.32945862318647
Validation loss: 2.6621016631966694

Epoch: 6| Step: 8
Training loss: 3.238695879667704
Validation loss: 2.6664293847599927

Epoch: 6| Step: 9
Training loss: 3.37153702138901
Validation loss: 2.6572293912352114

Epoch: 6| Step: 10
Training loss: 3.4399126775880737
Validation loss: 2.6516334551220924

Epoch: 6| Step: 11
Training loss: 3.4219516414612032
Validation loss: 2.650788564405865

Epoch: 6| Step: 12
Training loss: 3.080923599380505
Validation loss: 2.651395148534344

Epoch: 6| Step: 13
Training loss: 1.7332024261975292
Validation loss: 2.6489833102749354

Epoch: 395| Step: 0
Training loss: 2.603955608716152
Validation loss: 2.6445530093348424

Epoch: 6| Step: 1
Training loss: 3.2631964163133715
Validation loss: 2.644427807826453

Epoch: 6| Step: 2
Training loss: 2.9810692818366955
Validation loss: 2.6480359292001405

Epoch: 6| Step: 3
Training loss: 3.0006984851231895
Validation loss: 2.660360082053709

Epoch: 6| Step: 4
Training loss: 3.240960828987561
Validation loss: 2.669047392410408

Epoch: 6| Step: 5
Training loss: 2.7775873648760436
Validation loss: 2.669124205028796

Epoch: 6| Step: 6
Training loss: 2.876073719708647
Validation loss: 2.6841888262323876

Epoch: 6| Step: 7
Training loss: 2.933812200588223
Validation loss: 2.692402648299256

Epoch: 6| Step: 8
Training loss: 2.5579883587224113
Validation loss: 2.678873428844508

Epoch: 6| Step: 9
Training loss: 3.06079770480208
Validation loss: 2.691232729945178

Epoch: 6| Step: 10
Training loss: 3.3546941749140338
Validation loss: 2.699581658880095

Epoch: 6| Step: 11
Training loss: 2.8199240292806307
Validation loss: 2.7198563888056015

Epoch: 6| Step: 12
Training loss: 3.10950933578373
Validation loss: 2.702846163944514

Epoch: 6| Step: 13
Training loss: 2.7692457732584805
Validation loss: 2.6704846424934416

Epoch: 396| Step: 0
Training loss: 2.9781630810827693
Validation loss: 2.6435924171112974

Epoch: 6| Step: 1
Training loss: 3.5577470628486236
Validation loss: 2.6426425844091304

Epoch: 6| Step: 2
Training loss: 2.80796049191865
Validation loss: 2.636358658339413

Epoch: 6| Step: 3
Training loss: 2.924758386006631
Validation loss: 2.6377128031948867

Epoch: 6| Step: 4
Training loss: 3.144869692578817
Validation loss: 2.6366076874975355

Epoch: 6| Step: 5
Training loss: 2.754173666232896
Validation loss: 2.640263599145369

Epoch: 6| Step: 6
Training loss: 3.3199252991143067
Validation loss: 2.644773156698892

Epoch: 6| Step: 7
Training loss: 3.260031257900794
Validation loss: 2.650272436604545

Epoch: 6| Step: 8
Training loss: 2.6677934133797105
Validation loss: 2.646877097150432

Epoch: 6| Step: 9
Training loss: 2.581964212029227
Validation loss: 2.6407554299601013

Epoch: 6| Step: 10
Training loss: 3.0669268318058047
Validation loss: 2.6429346523162556

Epoch: 6| Step: 11
Training loss: 2.350886149425581
Validation loss: 2.642526506863068

Epoch: 6| Step: 12
Training loss: 3.2014556256277813
Validation loss: 2.645845807696653

Epoch: 6| Step: 13
Training loss: 2.721048895887583
Validation loss: 2.648411972247628

Epoch: 397| Step: 0
Training loss: 3.1650142038999873
Validation loss: 2.648521534050609

Epoch: 6| Step: 1
Training loss: 2.7789280660790143
Validation loss: 2.640707227447619

Epoch: 6| Step: 2
Training loss: 2.6962211514672956
Validation loss: 2.6397716417330934

Epoch: 6| Step: 3
Training loss: 3.1726970640862366
Validation loss: 2.6394132875319825

Epoch: 6| Step: 4
Training loss: 2.8545660217529365
Validation loss: 2.6447659410453017

Epoch: 6| Step: 5
Training loss: 3.106621985161923
Validation loss: 2.6343577485725223

Epoch: 6| Step: 6
Training loss: 2.5601699283945702
Validation loss: 2.6415757687639436

Epoch: 6| Step: 7
Training loss: 3.0335733220947376
Validation loss: 2.6448783058469854

Epoch: 6| Step: 8
Training loss: 2.9226871116658644
Validation loss: 2.6449838317287604

Epoch: 6| Step: 9
Training loss: 3.0788725124428225
Validation loss: 2.6485944556158283

Epoch: 6| Step: 10
Training loss: 2.6381016700361934
Validation loss: 2.6529424662374437

Epoch: 6| Step: 11
Training loss: 3.072424863264401
Validation loss: 2.6568685063663455

Epoch: 6| Step: 12
Training loss: 3.3460830677618127
Validation loss: 2.65350432295715

Epoch: 6| Step: 13
Training loss: 2.951940066662182
Validation loss: 2.6779165929897957

Epoch: 398| Step: 0
Training loss: 2.8929298903049356
Validation loss: 2.671858854592258

Epoch: 6| Step: 1
Training loss: 2.7837300762119574
Validation loss: 2.6881831951730395

Epoch: 6| Step: 2
Training loss: 2.597923689534215
Validation loss: 2.7108775800670815

Epoch: 6| Step: 3
Training loss: 3.187366856804908
Validation loss: 2.7365024396914945

Epoch: 6| Step: 4
Training loss: 2.6971012095752696
Validation loss: 2.7416549037792346

Epoch: 6| Step: 5
Training loss: 3.5584767696109583
Validation loss: 2.732532784690183

Epoch: 6| Step: 6
Training loss: 2.310121808329082
Validation loss: 2.6922067709953397

Epoch: 6| Step: 7
Training loss: 3.365975500361041
Validation loss: 2.6656805228792675

Epoch: 6| Step: 8
Training loss: 2.0688870110909017
Validation loss: 2.64391566564065

Epoch: 6| Step: 9
Training loss: 3.1331771676396403
Validation loss: 2.64220589051091

Epoch: 6| Step: 10
Training loss: 2.5385185715463927
Validation loss: 2.6336928045806216

Epoch: 6| Step: 11
Training loss: 3.6547011004550005
Validation loss: 2.6373697754659258

Epoch: 6| Step: 12
Training loss: 2.8897058623687464
Validation loss: 2.6351694748830283

Epoch: 6| Step: 13
Training loss: 3.780181860005462
Validation loss: 2.6367690467670832

Epoch: 399| Step: 0
Training loss: 2.5697443835719174
Validation loss: 2.6370439240946646

Epoch: 6| Step: 1
Training loss: 3.0341502993326532
Validation loss: 2.639576725637841

Epoch: 6| Step: 2
Training loss: 2.884489569243273
Validation loss: 2.63956167441701

Epoch: 6| Step: 3
Training loss: 2.966933809175281
Validation loss: 2.639694200298527

Epoch: 6| Step: 4
Training loss: 3.0309504724758476
Validation loss: 2.64353683106046

Epoch: 6| Step: 5
Training loss: 2.63303960618693
Validation loss: 2.652716360433673

Epoch: 6| Step: 6
Training loss: 3.518850516853613
Validation loss: 2.6566883427610604

Epoch: 6| Step: 7
Training loss: 3.283640544738535
Validation loss: 2.656536951074114

Epoch: 6| Step: 8
Training loss: 3.3366392590149454
Validation loss: 2.6498837169396303

Epoch: 6| Step: 9
Training loss: 3.428728043294342
Validation loss: 2.643907563334569

Epoch: 6| Step: 10
Training loss: 2.7737791039073296
Validation loss: 2.648932899921837

Epoch: 6| Step: 11
Training loss: 1.7337752671384252
Validation loss: 2.659773860627783

Epoch: 6| Step: 12
Training loss: 2.7993109127611584
Validation loss: 2.650177099509685

Epoch: 6| Step: 13
Training loss: 3.3879258623625086
Validation loss: 2.647487792319328

Epoch: 400| Step: 0
Training loss: 2.6649245492299363
Validation loss: 2.639584712064168

Epoch: 6| Step: 1
Training loss: 2.3602178217695777
Validation loss: 2.641300587552937

Epoch: 6| Step: 2
Training loss: 3.2533011177166835
Validation loss: 2.6430700760509507

Epoch: 6| Step: 3
Training loss: 3.023530864998994
Validation loss: 2.633973054362009

Epoch: 6| Step: 4
Training loss: 3.3632550210849352
Validation loss: 2.638444026422959

Epoch: 6| Step: 5
Training loss: 2.7759982470086357
Validation loss: 2.6407593015005113

Epoch: 6| Step: 6
Training loss: 3.43058719869238
Validation loss: 2.642016185195446

Epoch: 6| Step: 7
Training loss: 3.064834794637455
Validation loss: 2.641871701282121

Epoch: 6| Step: 8
Training loss: 2.4847320683910112
Validation loss: 2.6403915972976755

Epoch: 6| Step: 9
Training loss: 2.7541881227643423
Validation loss: 2.642522896941542

Epoch: 6| Step: 10
Training loss: 3.054186377433536
Validation loss: 2.6461809501804083

Epoch: 6| Step: 11
Training loss: 3.016584648857974
Validation loss: 2.6421183245589903

Epoch: 6| Step: 12
Training loss: 2.9705883558225525
Validation loss: 2.631551920882097

Epoch: 6| Step: 13
Training loss: 3.2090362340320446
Validation loss: 2.6476575026091935

Epoch: 401| Step: 0
Training loss: 3.12722485497591
Validation loss: 2.6365920330120542

Epoch: 6| Step: 1
Training loss: 2.2075337335897096
Validation loss: 2.639204587512401

Epoch: 6| Step: 2
Training loss: 2.9024802749581253
Validation loss: 2.641616168292731

Epoch: 6| Step: 3
Training loss: 2.8114861250346244
Validation loss: 2.6451615545026086

Epoch: 6| Step: 4
Training loss: 2.7297874986993804
Validation loss: 2.6514152426262525

Epoch: 6| Step: 5
Training loss: 2.780725493961264
Validation loss: 2.6504996339722693

Epoch: 6| Step: 6
Training loss: 2.841405216245172
Validation loss: 2.6508751805300266

Epoch: 6| Step: 7
Training loss: 3.2825248058395764
Validation loss: 2.639572201636626

Epoch: 6| Step: 8
Training loss: 2.9884682590585414
Validation loss: 2.6502294005391396

Epoch: 6| Step: 9
Training loss: 3.1948785090741936
Validation loss: 2.651190454138924

Epoch: 6| Step: 10
Training loss: 2.499505757114032
Validation loss: 2.649062767926919

Epoch: 6| Step: 11
Training loss: 3.5732161653107535
Validation loss: 2.641853137694178

Epoch: 6| Step: 12
Training loss: 2.84403369871796
Validation loss: 2.6402802465286612

Epoch: 6| Step: 13
Training loss: 3.743610660972215
Validation loss: 2.6483140232347604

Epoch: 402| Step: 0
Training loss: 1.8347005370048377
Validation loss: 2.649646150860062

Epoch: 6| Step: 1
Training loss: 3.3559584165959055
Validation loss: 2.6526207661504935

Epoch: 6| Step: 2
Training loss: 2.4893340514021447
Validation loss: 2.656586431615211

Epoch: 6| Step: 3
Training loss: 3.1428166424011925
Validation loss: 2.665538834545825

Epoch: 6| Step: 4
Training loss: 3.295271786492062
Validation loss: 2.654692803483037

Epoch: 6| Step: 5
Training loss: 3.181947846681184
Validation loss: 2.6503975545059117

Epoch: 6| Step: 6
Training loss: 2.301106298830379
Validation loss: 2.655165796671328

Epoch: 6| Step: 7
Training loss: 3.0638960167194855
Validation loss: 2.6572367206555136

Epoch: 6| Step: 8
Training loss: 3.0834355895810788
Validation loss: 2.6622237166196014

Epoch: 6| Step: 9
Training loss: 2.995018638081582
Validation loss: 2.651668835503566

Epoch: 6| Step: 10
Training loss: 2.9372977329174104
Validation loss: 2.649477955977298

Epoch: 6| Step: 11
Training loss: 3.0922447164599713
Validation loss: 2.642670046967284

Epoch: 6| Step: 12
Training loss: 3.1452161339268514
Validation loss: 2.6432905632020014

Epoch: 6| Step: 13
Training loss: 3.286062725617747
Validation loss: 2.6398050261182555

Epoch: 403| Step: 0
Training loss: 3.1271200999200097
Validation loss: 2.6420443140854886

Epoch: 6| Step: 1
Training loss: 3.593447465186961
Validation loss: 2.6384756553409643

Epoch: 6| Step: 2
Training loss: 2.7394506811557795
Validation loss: 2.633610605378117

Epoch: 6| Step: 3
Training loss: 3.5088598646053786
Validation loss: 2.6314437500637577

Epoch: 6| Step: 4
Training loss: 2.998946481734073
Validation loss: 2.632621887985818

Epoch: 6| Step: 5
Training loss: 2.4043198808302253
Validation loss: 2.6305027236025422

Epoch: 6| Step: 6
Training loss: 2.710234713085235
Validation loss: 2.6349877274261635

Epoch: 6| Step: 7
Training loss: 2.480044255015611
Validation loss: 2.6366410186017117

Epoch: 6| Step: 8
Training loss: 2.6997403691110575
Validation loss: 2.640294909150098

Epoch: 6| Step: 9
Training loss: 2.78532899211194
Validation loss: 2.6584034287669267

Epoch: 6| Step: 10
Training loss: 3.2043258276913362
Validation loss: 2.661846711382216

Epoch: 6| Step: 11
Training loss: 2.599645142914623
Validation loss: 2.6592088543738286

Epoch: 6| Step: 12
Training loss: 3.0613946282212865
Validation loss: 2.662521067929832

Epoch: 6| Step: 13
Training loss: 3.4345751717071824
Validation loss: 2.670521549083959

Epoch: 404| Step: 0
Training loss: 3.1342395757018173
Validation loss: 2.674535764383376

Epoch: 6| Step: 1
Training loss: 2.9310192285724974
Validation loss: 2.6720497550585427

Epoch: 6| Step: 2
Training loss: 2.7925966241661104
Validation loss: 2.6697688311922096

Epoch: 6| Step: 3
Training loss: 3.111378699859667
Validation loss: 2.663070798699311

Epoch: 6| Step: 4
Training loss: 2.9254278929643087
Validation loss: 2.6608193162193214

Epoch: 6| Step: 5
Training loss: 3.2418039117964956
Validation loss: 2.654320591229774

Epoch: 6| Step: 6
Training loss: 2.132441897210052
Validation loss: 2.655045564297317

Epoch: 6| Step: 7
Training loss: 3.493429010211836
Validation loss: 2.6390063567499515

Epoch: 6| Step: 8
Training loss: 2.9559780649034644
Validation loss: 2.645188266937733

Epoch: 6| Step: 9
Training loss: 2.972589519618953
Validation loss: 2.6318014720815426

Epoch: 6| Step: 10
Training loss: 2.1939658382124283
Validation loss: 2.6311346563348645

Epoch: 6| Step: 11
Training loss: 3.47815837449944
Validation loss: 2.6421643890281974

Epoch: 6| Step: 12
Training loss: 3.1399928733113076
Validation loss: 2.629648303282194

Epoch: 6| Step: 13
Training loss: 2.2278887095093483
Validation loss: 2.6247724560444246

Epoch: 405| Step: 0
Training loss: 2.910447565641517
Validation loss: 2.634027259688281

Epoch: 6| Step: 1
Training loss: 2.061804220575255
Validation loss: 2.636220389622065

Epoch: 6| Step: 2
Training loss: 3.202473643996266
Validation loss: 2.6252996641844777

Epoch: 6| Step: 3
Training loss: 2.510130384485862
Validation loss: 2.6243767933676905

Epoch: 6| Step: 4
Training loss: 2.588596601817935
Validation loss: 2.6277105212188943

Epoch: 6| Step: 5
Training loss: 3.2672153232726995
Validation loss: 2.624488916563705

Epoch: 6| Step: 6
Training loss: 3.459084731745738
Validation loss: 2.629782455666366

Epoch: 6| Step: 7
Training loss: 3.0655483722345283
Validation loss: 2.628563773940165

Epoch: 6| Step: 8
Training loss: 3.1383014643167435
Validation loss: 2.636143587823079

Epoch: 6| Step: 9
Training loss: 3.230959946030214
Validation loss: 2.627950893621134

Epoch: 6| Step: 10
Training loss: 2.5108681005110687
Validation loss: 2.6302089019030763

Epoch: 6| Step: 11
Training loss: 3.0699119403647783
Validation loss: 2.630764223119526

Epoch: 6| Step: 12
Training loss: 3.075396417636327
Validation loss: 2.6397902432662517

Epoch: 6| Step: 13
Training loss: 3.0704820891856324
Validation loss: 2.646697127113032

Epoch: 406| Step: 0
Training loss: 3.2217485108877177
Validation loss: 2.6421446476270005

Epoch: 6| Step: 1
Training loss: 3.2137088742438316
Validation loss: 2.641771402013747

Epoch: 6| Step: 2
Training loss: 3.019205606328614
Validation loss: 2.6343939594525687

Epoch: 6| Step: 3
Training loss: 2.906430802822713
Validation loss: 2.637440846509851

Epoch: 6| Step: 4
Training loss: 3.4179227117435156
Validation loss: 2.6302052633794957

Epoch: 6| Step: 5
Training loss: 2.380076754638638
Validation loss: 2.6335131776420035

Epoch: 6| Step: 6
Training loss: 2.316330083460039
Validation loss: 2.645662090162387

Epoch: 6| Step: 7
Training loss: 3.19517595143941
Validation loss: 2.6411134710153275

Epoch: 6| Step: 8
Training loss: 2.9947559299271758
Validation loss: 2.6339421485634973

Epoch: 6| Step: 9
Training loss: 2.0881772250529838
Validation loss: 2.636776196800832

Epoch: 6| Step: 10
Training loss: 2.6738388250790286
Validation loss: 2.640954748667399

Epoch: 6| Step: 11
Training loss: 3.4164053344027474
Validation loss: 2.6419899054833715

Epoch: 6| Step: 12
Training loss: 3.1878771091357425
Validation loss: 2.6305170089868763

Epoch: 6| Step: 13
Training loss: 3.0307366634542117
Validation loss: 2.6286590903203364

Epoch: 407| Step: 0
Training loss: 3.1639585124694554
Validation loss: 2.626624942884574

Epoch: 6| Step: 1
Training loss: 2.7556702503651556
Validation loss: 2.6366329357504177

Epoch: 6| Step: 2
Training loss: 2.939817772232753
Validation loss: 2.6258606298270415

Epoch: 6| Step: 3
Training loss: 2.990433061553106
Validation loss: 2.635217928507295

Epoch: 6| Step: 4
Training loss: 3.119161415866839
Validation loss: 2.6271306623337822

Epoch: 6| Step: 5
Training loss: 3.3604762911409316
Validation loss: 2.6300470192849055

Epoch: 6| Step: 6
Training loss: 3.042055514489317
Validation loss: 2.6416319346943657

Epoch: 6| Step: 7
Training loss: 2.7751997386084417
Validation loss: 2.6261827789717382

Epoch: 6| Step: 8
Training loss: 2.8805872488000115
Validation loss: 2.634441048422531

Epoch: 6| Step: 9
Training loss: 2.3501860686965017
Validation loss: 2.633543889402814

Epoch: 6| Step: 10
Training loss: 2.806950413351892
Validation loss: 2.6374329838425083

Epoch: 6| Step: 11
Training loss: 3.1192665910694632
Validation loss: 2.649806279821523

Epoch: 6| Step: 12
Training loss: 2.9326983226892427
Validation loss: 2.6540611142042625

Epoch: 6| Step: 13
Training loss: 3.2217391865148386
Validation loss: 2.650809558645573

Epoch: 408| Step: 0
Training loss: 3.107243866680162
Validation loss: 2.6424210526298824

Epoch: 6| Step: 1
Training loss: 2.651193810514547
Validation loss: 2.6374395410890186

Epoch: 6| Step: 2
Training loss: 3.149259019924013
Validation loss: 2.6379991331725274

Epoch: 6| Step: 3
Training loss: 2.8284625278773707
Validation loss: 2.6374522842237953

Epoch: 6| Step: 4
Training loss: 2.4752390119953884
Validation loss: 2.626292834708281

Epoch: 6| Step: 5
Training loss: 3.3086228622723044
Validation loss: 2.622629118470661

Epoch: 6| Step: 6
Training loss: 3.159781114264638
Validation loss: 2.6298431110426694

Epoch: 6| Step: 7
Training loss: 2.7874481059491267
Validation loss: 2.631513097038478

Epoch: 6| Step: 8
Training loss: 3.0112050925865446
Validation loss: 2.629603175810405

Epoch: 6| Step: 9
Training loss: 2.868590798874374
Validation loss: 2.628021905761175

Epoch: 6| Step: 10
Training loss: 2.6994562555207247
Validation loss: 2.6426173159648565

Epoch: 6| Step: 11
Training loss: 2.605157424651024
Validation loss: 2.6446218312862437

Epoch: 6| Step: 12
Training loss: 3.100805387165126
Validation loss: 2.6339183408214772

Epoch: 6| Step: 13
Training loss: 3.775014859606063
Validation loss: 2.650605182691378

Epoch: 409| Step: 0
Training loss: 2.9194624625522185
Validation loss: 2.6488555346938174

Epoch: 6| Step: 1
Training loss: 2.920555265489228
Validation loss: 2.656590383340805

Epoch: 6| Step: 2
Training loss: 2.9108635164565837
Validation loss: 2.686943538412477

Epoch: 6| Step: 3
Training loss: 2.670246006922919
Validation loss: 2.6756029146696245

Epoch: 6| Step: 4
Training loss: 2.8531324271599487
Validation loss: 2.6974326440051093

Epoch: 6| Step: 5
Training loss: 2.8574071898118882
Validation loss: 2.7086288079567757

Epoch: 6| Step: 6
Training loss: 3.5755942110930796
Validation loss: 2.7024441877142995

Epoch: 6| Step: 7
Training loss: 2.952769586075857
Validation loss: 2.6916429733543614

Epoch: 6| Step: 8
Training loss: 3.272700042322333
Validation loss: 2.661692058063966

Epoch: 6| Step: 9
Training loss: 2.9828474519339383
Validation loss: 2.661702482345836

Epoch: 6| Step: 10
Training loss: 2.290550711599385
Validation loss: 2.6654049640620032

Epoch: 6| Step: 11
Training loss: 3.104261631547768
Validation loss: 2.6514828567445257

Epoch: 6| Step: 12
Training loss: 2.9648188211752533
Validation loss: 2.640126376820405

Epoch: 6| Step: 13
Training loss: 2.7279783578724572
Validation loss: 2.6297417671065983

Epoch: 410| Step: 0
Training loss: 2.483894253646793
Validation loss: 2.6264642468768185

Epoch: 6| Step: 1
Training loss: 3.1156748684457205
Validation loss: 2.6226300725181804

Epoch: 6| Step: 2
Training loss: 2.820737262556763
Validation loss: 2.621534956269592

Epoch: 6| Step: 3
Training loss: 2.938906393818282
Validation loss: 2.6206129871773545

Epoch: 6| Step: 4
Training loss: 3.006280047926756
Validation loss: 2.6210587452439245

Epoch: 6| Step: 5
Training loss: 3.1901799324017186
Validation loss: 2.61487677678938

Epoch: 6| Step: 6
Training loss: 3.063664740345352
Validation loss: 2.619005198262337

Epoch: 6| Step: 7
Training loss: 2.523838259403987
Validation loss: 2.6199061059006077

Epoch: 6| Step: 8
Training loss: 2.9654146431380055
Validation loss: 2.6147661905472037

Epoch: 6| Step: 9
Training loss: 3.216160445495441
Validation loss: 2.6239567957819316

Epoch: 6| Step: 10
Training loss: 3.008581286186368
Validation loss: 2.6182744680215437

Epoch: 6| Step: 11
Training loss: 2.52109383322116
Validation loss: 2.620315448185684

Epoch: 6| Step: 12
Training loss: 3.247315545250761
Validation loss: 2.625651026370002

Epoch: 6| Step: 13
Training loss: 3.146128979531381
Validation loss: 2.6223424476391703

Epoch: 411| Step: 0
Training loss: 3.0447057582460864
Validation loss: 2.6349781139546984

Epoch: 6| Step: 1
Training loss: 3.157601548689005
Validation loss: 2.6377295036095543

Epoch: 6| Step: 2
Training loss: 3.37105513425703
Validation loss: 2.637623126681383

Epoch: 6| Step: 3
Training loss: 3.2949673163916007
Validation loss: 2.648522117725355

Epoch: 6| Step: 4
Training loss: 2.66506992656299
Validation loss: 2.650392153284547

Epoch: 6| Step: 5
Training loss: 3.08391634266316
Validation loss: 2.6457099494978027

Epoch: 6| Step: 6
Training loss: 2.076700281490583
Validation loss: 2.6555365224929552

Epoch: 6| Step: 7
Training loss: 2.5281994180371297
Validation loss: 2.6478038846279355

Epoch: 6| Step: 8
Training loss: 3.3866717237399735
Validation loss: 2.662128600482363

Epoch: 6| Step: 9
Training loss: 2.9960848374215545
Validation loss: 2.6548854307527923

Epoch: 6| Step: 10
Training loss: 2.623027241875519
Validation loss: 2.6474109184260772

Epoch: 6| Step: 11
Training loss: 2.458956353934616
Validation loss: 2.6494140595971234

Epoch: 6| Step: 12
Training loss: 3.09566430870775
Validation loss: 2.637934809088155

Epoch: 6| Step: 13
Training loss: 3.34573205689293
Validation loss: 2.6494504352932764

Epoch: 412| Step: 0
Training loss: 3.2904220996696063
Validation loss: 2.6503751844403016

Epoch: 6| Step: 1
Training loss: 2.4965566764034968
Validation loss: 2.644809121262255

Epoch: 6| Step: 2
Training loss: 2.907078286548805
Validation loss: 2.6413005564938064

Epoch: 6| Step: 3
Training loss: 2.8691085491633674
Validation loss: 2.652485461791777

Epoch: 6| Step: 4
Training loss: 3.044542251030612
Validation loss: 2.6465097857293935

Epoch: 6| Step: 5
Training loss: 3.0892209897557286
Validation loss: 2.642008552529726

Epoch: 6| Step: 6
Training loss: 2.57669758439689
Validation loss: 2.6506930867769114

Epoch: 6| Step: 7
Training loss: 3.152218500648405
Validation loss: 2.6475724006975683

Epoch: 6| Step: 8
Training loss: 3.23956486900113
Validation loss: 2.6364358622765134

Epoch: 6| Step: 9
Training loss: 2.3369769077163998
Validation loss: 2.6438819414220136

Epoch: 6| Step: 10
Training loss: 3.1967447890148737
Validation loss: 2.6506309794757272

Epoch: 6| Step: 11
Training loss: 2.369672320927376
Validation loss: 2.654942609998171

Epoch: 6| Step: 12
Training loss: 3.59492141871194
Validation loss: 2.648075101349967

Epoch: 6| Step: 13
Training loss: 2.6139518208168093
Validation loss: 2.645303390356703

Epoch: 413| Step: 0
Training loss: 2.897818363002349
Validation loss: 2.6451912791205174

Epoch: 6| Step: 1
Training loss: 3.055072730864053
Validation loss: 2.637509645064253

Epoch: 6| Step: 2
Training loss: 3.0185908621154143
Validation loss: 2.639429886857635

Epoch: 6| Step: 3
Training loss: 2.766512970695928
Validation loss: 2.6399721359287707

Epoch: 6| Step: 4
Training loss: 2.722548626341985
Validation loss: 2.641414057708652

Epoch: 6| Step: 5
Training loss: 2.628004988063218
Validation loss: 2.6550805284354304

Epoch: 6| Step: 6
Training loss: 2.750965729117602
Validation loss: 2.6319555109430492

Epoch: 6| Step: 7
Training loss: 3.020029438961618
Validation loss: 2.641329911091996

Epoch: 6| Step: 8
Training loss: 2.2875711315331224
Validation loss: 2.6375510487206237

Epoch: 6| Step: 9
Training loss: 2.7720169942756003
Validation loss: 2.632589919967113

Epoch: 6| Step: 10
Training loss: 3.5170298842265995
Validation loss: 2.627820678820118

Epoch: 6| Step: 11
Training loss: 3.2153018889176552
Validation loss: 2.628632652689045

Epoch: 6| Step: 12
Training loss: 3.5210510427366204
Validation loss: 2.6375392974848157

Epoch: 6| Step: 13
Training loss: 2.7027238316612174
Validation loss: 2.628822175017086

Epoch: 414| Step: 0
Training loss: 3.4678486520725844
Validation loss: 2.6237864621546776

Epoch: 6| Step: 1
Training loss: 3.4926383390996874
Validation loss: 2.6300433854111303

Epoch: 6| Step: 2
Training loss: 2.5994406171745483
Validation loss: 2.6316139821179902

Epoch: 6| Step: 3
Training loss: 2.9069103188133507
Validation loss: 2.6263637291556186

Epoch: 6| Step: 4
Training loss: 3.22711812331621
Validation loss: 2.6181752549352137

Epoch: 6| Step: 5
Training loss: 2.494293375498199
Validation loss: 2.6188834525993907

Epoch: 6| Step: 6
Training loss: 2.687719469202356
Validation loss: 2.625428737546082

Epoch: 6| Step: 7
Training loss: 3.283992674667236
Validation loss: 2.6170455284346508

Epoch: 6| Step: 8
Training loss: 2.9476098933291617
Validation loss: 2.632663899222726

Epoch: 6| Step: 9
Training loss: 3.248248288440921
Validation loss: 2.62785798851071

Epoch: 6| Step: 10
Training loss: 2.064440998774403
Validation loss: 2.649243609783152

Epoch: 6| Step: 11
Training loss: 3.042731494983007
Validation loss: 2.6528226665397074

Epoch: 6| Step: 12
Training loss: 2.1504929576227196
Validation loss: 2.6523920203691644

Epoch: 6| Step: 13
Training loss: 3.363617954391228
Validation loss: 2.6588576062516176

Epoch: 415| Step: 0
Training loss: 3.2431487715124323
Validation loss: 2.6552303086999234

Epoch: 6| Step: 1
Training loss: 2.0443004695096687
Validation loss: 2.6493099439491776

Epoch: 6| Step: 2
Training loss: 3.1300784235870474
Validation loss: 2.638650573356417

Epoch: 6| Step: 3
Training loss: 2.7659301589456375
Validation loss: 2.626185975976165

Epoch: 6| Step: 4
Training loss: 2.8026641943249504
Validation loss: 2.6292988325064415

Epoch: 6| Step: 5
Training loss: 2.856797687934019
Validation loss: 2.6476936947475136

Epoch: 6| Step: 6
Training loss: 3.111704504855355
Validation loss: 2.6540804337253743

Epoch: 6| Step: 7
Training loss: 3.98380039035993
Validation loss: 2.6453172459599243

Epoch: 6| Step: 8
Training loss: 2.2619810067618102
Validation loss: 2.653542151179591

Epoch: 6| Step: 9
Training loss: 2.6649597983700826
Validation loss: 2.638114734543811

Epoch: 6| Step: 10
Training loss: 3.14440311147111
Validation loss: 2.6354145388238144

Epoch: 6| Step: 11
Training loss: 2.4849804794189554
Validation loss: 2.634980340983038

Epoch: 6| Step: 12
Training loss: 3.297866889030124
Validation loss: 2.6257876207306294

Epoch: 6| Step: 13
Training loss: 2.9610073916759427
Validation loss: 2.6223209908630287

Epoch: 416| Step: 0
Training loss: 3.416766110965668
Validation loss: 2.6233123084729937

Epoch: 6| Step: 1
Training loss: 2.901176864971052
Validation loss: 2.6162898402962034

Epoch: 6| Step: 2
Training loss: 2.7348278433613893
Validation loss: 2.6273234944830652

Epoch: 6| Step: 3
Training loss: 2.7932480465684035
Validation loss: 2.6221303259893136

Epoch: 6| Step: 4
Training loss: 3.0650071761030167
Validation loss: 2.62253851658762

Epoch: 6| Step: 5
Training loss: 3.013180072679133
Validation loss: 2.619339939317074

Epoch: 6| Step: 6
Training loss: 2.9432586065406463
Validation loss: 2.6304330390911366

Epoch: 6| Step: 7
Training loss: 2.7051650270901226
Validation loss: 2.6257561377383003

Epoch: 6| Step: 8
Training loss: 2.8066518381169536
Validation loss: 2.630744397144699

Epoch: 6| Step: 9
Training loss: 2.8778294447782033
Validation loss: 2.6421816095107364

Epoch: 6| Step: 10
Training loss: 2.6238611566515417
Validation loss: 2.6322883295223036

Epoch: 6| Step: 11
Training loss: 2.478435494019636
Validation loss: 2.6430335824740174

Epoch: 6| Step: 12
Training loss: 3.5123946204617487
Validation loss: 2.6385214443100717

Epoch: 6| Step: 13
Training loss: 3.3361443270101625
Validation loss: 2.6411344489785935

Epoch: 417| Step: 0
Training loss: 2.5410043656072605
Validation loss: 2.6461154502148085

Epoch: 6| Step: 1
Training loss: 2.942579706582278
Validation loss: 2.646410432380519

Epoch: 6| Step: 2
Training loss: 3.4405404256323098
Validation loss: 2.640331711476029

Epoch: 6| Step: 3
Training loss: 3.809396324692607
Validation loss: 2.6330387406181424

Epoch: 6| Step: 4
Training loss: 2.4091679109270845
Validation loss: 2.653345503171872

Epoch: 6| Step: 5
Training loss: 2.9999148038846712
Validation loss: 2.6463928761417814

Epoch: 6| Step: 6
Training loss: 3.0066256472826725
Validation loss: 2.655837656404725

Epoch: 6| Step: 7
Training loss: 2.471010356391993
Validation loss: 2.6513058477818796

Epoch: 6| Step: 8
Training loss: 2.6142346477657856
Validation loss: 2.63705936591126

Epoch: 6| Step: 9
Training loss: 2.358247702384031
Validation loss: 2.6421376266153755

Epoch: 6| Step: 10
Training loss: 2.8270887299394554
Validation loss: 2.6410269540841393

Epoch: 6| Step: 11
Training loss: 2.6744236975950186
Validation loss: 2.6321992648964954

Epoch: 6| Step: 12
Training loss: 3.778278917532997
Validation loss: 2.6266111555782587

Epoch: 6| Step: 13
Training loss: 2.6264016178745444
Validation loss: 2.6285889385337367

Epoch: 418| Step: 0
Training loss: 3.5228557910017173
Validation loss: 2.6177364904331273

Epoch: 6| Step: 1
Training loss: 2.2662193834074604
Validation loss: 2.6193010176585796

Epoch: 6| Step: 2
Training loss: 2.9282089367930437
Validation loss: 2.6245183507707215

Epoch: 6| Step: 3
Training loss: 2.4374253677288853
Validation loss: 2.627592776170669

Epoch: 6| Step: 4
Training loss: 2.702914808623646
Validation loss: 2.6259316394284964

Epoch: 6| Step: 5
Training loss: 2.954414207371035
Validation loss: 2.6403637746097997

Epoch: 6| Step: 6
Training loss: 2.799866679968556
Validation loss: 2.6467957384203293

Epoch: 6| Step: 7
Training loss: 3.602560902066832
Validation loss: 2.6514100484602228

Epoch: 6| Step: 8
Training loss: 2.2137116729675332
Validation loss: 2.651288734909583

Epoch: 6| Step: 9
Training loss: 3.432480215972764
Validation loss: 2.656801727922822

Epoch: 6| Step: 10
Training loss: 2.848222841009948
Validation loss: 2.671651268940781

Epoch: 6| Step: 11
Training loss: 2.5982158775118718
Validation loss: 2.646548281085979

Epoch: 6| Step: 12
Training loss: 3.629313828951494
Validation loss: 2.639778143641306

Epoch: 6| Step: 13
Training loss: 2.7310689940368054
Validation loss: 2.6409617980624924

Epoch: 419| Step: 0
Training loss: 3.005501788448347
Validation loss: 2.629833488513134

Epoch: 6| Step: 1
Training loss: 2.5858292571402544
Validation loss: 2.626607632122234

Epoch: 6| Step: 2
Training loss: 2.84931066776389
Validation loss: 2.6089266128426885

Epoch: 6| Step: 3
Training loss: 2.755299317288476
Validation loss: 2.6112410217685937

Epoch: 6| Step: 4
Training loss: 2.780726694316852
Validation loss: 2.6169017750265233

Epoch: 6| Step: 5
Training loss: 2.112889956987092
Validation loss: 2.6226759465452005

Epoch: 6| Step: 6
Training loss: 2.836458016539262
Validation loss: 2.6213776479147914

Epoch: 6| Step: 7
Training loss: 3.5684529142433523
Validation loss: 2.6188842112514044

Epoch: 6| Step: 8
Training loss: 3.043643117669083
Validation loss: 2.6296403110507454

Epoch: 6| Step: 9
Training loss: 2.570286063664152
Validation loss: 2.6336428705549846

Epoch: 6| Step: 10
Training loss: 3.7040746573716374
Validation loss: 2.6228847213937403

Epoch: 6| Step: 11
Training loss: 2.859004262434673
Validation loss: 2.619220237246599

Epoch: 6| Step: 12
Training loss: 3.238166245648986
Validation loss: 2.6372962762173167

Epoch: 6| Step: 13
Training loss: 2.843956070025496
Validation loss: 2.618392030938642

Epoch: 420| Step: 0
Training loss: 3.4379779830147745
Validation loss: 2.6229984487061464

Epoch: 6| Step: 1
Training loss: 3.1044004894152497
Validation loss: 2.614990886684195

Epoch: 6| Step: 2
Training loss: 2.757139561493751
Validation loss: 2.613843735207345

Epoch: 6| Step: 3
Training loss: 2.313815181067553
Validation loss: 2.608183463648102

Epoch: 6| Step: 4
Training loss: 3.4823851784031183
Validation loss: 2.6188089714798597

Epoch: 6| Step: 5
Training loss: 2.893221621957047
Validation loss: 2.617511267020713

Epoch: 6| Step: 6
Training loss: 3.1955996060271716
Validation loss: 2.6087266149469754

Epoch: 6| Step: 7
Training loss: 3.304268163314348
Validation loss: 2.626014396277692

Epoch: 6| Step: 8
Training loss: 2.703329883374115
Validation loss: 2.6232985242788476

Epoch: 6| Step: 9
Training loss: 2.333539874154457
Validation loss: 2.626268999109951

Epoch: 6| Step: 10
Training loss: 2.78186954070091
Validation loss: 2.635759602645591

Epoch: 6| Step: 11
Training loss: 2.7745584291240895
Validation loss: 2.652999257830644

Epoch: 6| Step: 12
Training loss: 2.50916204059554
Validation loss: 2.6325543153094904

Epoch: 6| Step: 13
Training loss: 3.4276219710914715
Validation loss: 2.6464747451687547

Epoch: 421| Step: 0
Training loss: 2.9969178897783855
Validation loss: 2.6241281793200693

Epoch: 6| Step: 1
Training loss: 2.9528382177219026
Validation loss: 2.625602192127565

Epoch: 6| Step: 2
Training loss: 3.2770862137154744
Validation loss: 2.626211477682216

Epoch: 6| Step: 3
Training loss: 2.6070686243914594
Validation loss: 2.6220477887550424

Epoch: 6| Step: 4
Training loss: 3.0678154106860744
Validation loss: 2.621767394611308

Epoch: 6| Step: 5
Training loss: 3.0244952576786597
Validation loss: 2.6170253359971434

Epoch: 6| Step: 6
Training loss: 3.0295156649511767
Validation loss: 2.6241295284869413

Epoch: 6| Step: 7
Training loss: 2.4668958437193425
Validation loss: 2.616215586169645

Epoch: 6| Step: 8
Training loss: 2.850992558625143
Validation loss: 2.6233952495819652

Epoch: 6| Step: 9
Training loss: 2.9155519989458476
Validation loss: 2.6251262862947593

Epoch: 6| Step: 10
Training loss: 3.1580578753511444
Validation loss: 2.622623948426376

Epoch: 6| Step: 11
Training loss: 2.7916373540753283
Validation loss: 2.637996890228234

Epoch: 6| Step: 12
Training loss: 3.1264010531155266
Validation loss: 2.638912850922227

Epoch: 6| Step: 13
Training loss: 2.537854655619931
Validation loss: 2.638067578013536

Epoch: 422| Step: 0
Training loss: 2.6386162154103734
Validation loss: 2.6343603858235367

Epoch: 6| Step: 1
Training loss: 2.720910978353394
Validation loss: 2.640693780641975

Epoch: 6| Step: 2
Training loss: 2.925043356810492
Validation loss: 2.6205521524002333

Epoch: 6| Step: 3
Training loss: 2.948925443299915
Validation loss: 2.6391615934137427

Epoch: 6| Step: 4
Training loss: 2.490935965046896
Validation loss: 2.638607335106106

Epoch: 6| Step: 5
Training loss: 3.2016735230795583
Validation loss: 2.64479787142337

Epoch: 6| Step: 6
Training loss: 3.1760381428136113
Validation loss: 2.6258017570044663

Epoch: 6| Step: 7
Training loss: 2.690408507885101
Validation loss: 2.6199899043652923

Epoch: 6| Step: 8
Training loss: 1.6182523161189257
Validation loss: 2.6276276597339367

Epoch: 6| Step: 9
Training loss: 3.2101479555061374
Validation loss: 2.640596276389353

Epoch: 6| Step: 10
Training loss: 3.550856452036431
Validation loss: 2.6157325075946223

Epoch: 6| Step: 11
Training loss: 3.461197061901902
Validation loss: 2.6179937960668545

Epoch: 6| Step: 12
Training loss: 3.0936510474823864
Validation loss: 2.6236961865305535

Epoch: 6| Step: 13
Training loss: 2.838675866177358
Validation loss: 2.6118405980255592

Epoch: 423| Step: 0
Training loss: 3.329156133820475
Validation loss: 2.6206918376532147

Epoch: 6| Step: 1
Training loss: 2.783571624453798
Validation loss: 2.6179942171394277

Epoch: 6| Step: 2
Training loss: 3.1058225034363383
Validation loss: 2.6307511815526063

Epoch: 6| Step: 3
Training loss: 3.1261355053703306
Validation loss: 2.636291046273476

Epoch: 6| Step: 4
Training loss: 2.895054078857049
Validation loss: 2.6371842464819117

Epoch: 6| Step: 5
Training loss: 2.229898196064841
Validation loss: 2.631471361644545

Epoch: 6| Step: 6
Training loss: 3.2695919199866803
Validation loss: 2.6381602630309686

Epoch: 6| Step: 7
Training loss: 2.5843705791910687
Validation loss: 2.6327723490344397

Epoch: 6| Step: 8
Training loss: 2.445212560201892
Validation loss: 2.637609990729884

Epoch: 6| Step: 9
Training loss: 3.2501544915673124
Validation loss: 2.630061865673592

Epoch: 6| Step: 10
Training loss: 2.7762924758567897
Validation loss: 2.6255122611250883

Epoch: 6| Step: 11
Training loss: 3.259932379460093
Validation loss: 2.6436305825682327

Epoch: 6| Step: 12
Training loss: 2.725038293691926
Validation loss: 2.646770971644112

Epoch: 6| Step: 13
Training loss: 3.204574331501481
Validation loss: 2.6442965390945026

Epoch: 424| Step: 0
Training loss: 2.9819121259282295
Validation loss: 2.631254888123769

Epoch: 6| Step: 1
Training loss: 2.7265446615865248
Validation loss: 2.627886132372737

Epoch: 6| Step: 2
Training loss: 3.073322402978797
Validation loss: 2.6407176170992335

Epoch: 6| Step: 3
Training loss: 3.0264549476525993
Validation loss: 2.623690423527523

Epoch: 6| Step: 4
Training loss: 2.851375375120959
Validation loss: 2.61286956945078

Epoch: 6| Step: 5
Training loss: 3.2108362186543338
Validation loss: 2.617633652375367

Epoch: 6| Step: 6
Training loss: 2.620291528862395
Validation loss: 2.61433894530922

Epoch: 6| Step: 7
Training loss: 2.632996232954055
Validation loss: 2.6135561404679204

Epoch: 6| Step: 8
Training loss: 2.8684069459532364
Validation loss: 2.6100821305386086

Epoch: 6| Step: 9
Training loss: 2.644253737343225
Validation loss: 2.611260430326806

Epoch: 6| Step: 10
Training loss: 2.7357887319120127
Validation loss: 2.6084905939135337

Epoch: 6| Step: 11
Training loss: 3.13363355118196
Validation loss: 2.614463743279031

Epoch: 6| Step: 12
Training loss: 3.2822383300425026
Validation loss: 2.6164328797208527

Epoch: 6| Step: 13
Training loss: 3.5269250631826803
Validation loss: 2.6126642587581657

Epoch: 425| Step: 0
Training loss: 3.107269033992611
Validation loss: 2.6246709163199546

Epoch: 6| Step: 1
Training loss: 2.9060954391234204
Validation loss: 2.6244214993323554

Epoch: 6| Step: 2
Training loss: 3.3276908483881567
Validation loss: 2.6302903389896373

Epoch: 6| Step: 3
Training loss: 3.5752143848934734
Validation loss: 2.6427583328558932

Epoch: 6| Step: 4
Training loss: 2.5668519444494886
Validation loss: 2.632255282230664

Epoch: 6| Step: 5
Training loss: 2.5065867437986284
Validation loss: 2.619794272914427

Epoch: 6| Step: 6
Training loss: 3.3829068001164213
Validation loss: 2.614983740807619

Epoch: 6| Step: 7
Training loss: 3.094168894758654
Validation loss: 2.6040771337725612

Epoch: 6| Step: 8
Training loss: 2.902953873139426
Validation loss: 2.6181501846168125

Epoch: 6| Step: 9
Training loss: 3.1516661642535806
Validation loss: 2.611463835002192

Epoch: 6| Step: 10
Training loss: 2.3678895016419332
Validation loss: 2.6053056666648517

Epoch: 6| Step: 11
Training loss: 2.5873252625366137
Validation loss: 2.6139066263551314

Epoch: 6| Step: 12
Training loss: 2.454543948574439
Validation loss: 2.610177176968176

Epoch: 6| Step: 13
Training loss: 2.787111599125339
Validation loss: 2.619326961253963

Epoch: 426| Step: 0
Training loss: 3.0908249407548287
Validation loss: 2.6242334337451383

Epoch: 6| Step: 1
Training loss: 3.5300051765295875
Validation loss: 2.634669976853401

Epoch: 6| Step: 2
Training loss: 2.859583112303588
Validation loss: 2.6334796317232994

Epoch: 6| Step: 3
Training loss: 3.1478149707322096
Validation loss: 2.613466916161971

Epoch: 6| Step: 4
Training loss: 2.4885087081453294
Validation loss: 2.6308505289290025

Epoch: 6| Step: 5
Training loss: 3.105968814150441
Validation loss: 2.6287670236679106

Epoch: 6| Step: 6
Training loss: 2.9155933766832405
Validation loss: 2.6346827791163747

Epoch: 6| Step: 7
Training loss: 1.8977852159935542
Validation loss: 2.650431134398923

Epoch: 6| Step: 8
Training loss: 2.640998678459117
Validation loss: 2.660253969217026

Epoch: 6| Step: 9
Training loss: 3.022576734453837
Validation loss: 2.664390779743967

Epoch: 6| Step: 10
Training loss: 2.7388560172122993
Validation loss: 2.682980250330209

Epoch: 6| Step: 11
Training loss: 3.3049503880180624
Validation loss: 2.677704205503145

Epoch: 6| Step: 12
Training loss: 3.1519310739019826
Validation loss: 2.667489551344929

Epoch: 6| Step: 13
Training loss: 2.674714213996777
Validation loss: 2.6354842158875242

Epoch: 427| Step: 0
Training loss: 3.065975163766658
Validation loss: 2.6444983973887317

Epoch: 6| Step: 1
Training loss: 3.214587436623137
Validation loss: 2.619603673688812

Epoch: 6| Step: 2
Training loss: 2.606186248950982
Validation loss: 2.635737107371903

Epoch: 6| Step: 3
Training loss: 2.9266043346895616
Validation loss: 2.63304995307098

Epoch: 6| Step: 4
Training loss: 2.8953320917906686
Validation loss: 2.6246122063040995

Epoch: 6| Step: 5
Training loss: 2.4075440729371427
Validation loss: 2.615089624052905

Epoch: 6| Step: 6
Training loss: 2.927795287370853
Validation loss: 2.6126644275307793

Epoch: 6| Step: 7
Training loss: 3.394451039445391
Validation loss: 2.6348861853691834

Epoch: 6| Step: 8
Training loss: 2.961533297782916
Validation loss: 2.62854417958424

Epoch: 6| Step: 9
Training loss: 3.078917270690042
Validation loss: 2.616389567274539

Epoch: 6| Step: 10
Training loss: 2.538767636123773
Validation loss: 2.62514933734118

Epoch: 6| Step: 11
Training loss: 2.2553663895849674
Validation loss: 2.6218925527798373

Epoch: 6| Step: 12
Training loss: 3.474319934851221
Validation loss: 2.62075666467447

Epoch: 6| Step: 13
Training loss: 3.0140082418206315
Validation loss: 2.6204496146358016

Epoch: 428| Step: 0
Training loss: 2.831060245715051
Validation loss: 2.6372793057378843

Epoch: 6| Step: 1
Training loss: 2.9476920717409896
Validation loss: 2.623743978515529

Epoch: 6| Step: 2
Training loss: 3.253512025470004
Validation loss: 2.6269756798782895

Epoch: 6| Step: 3
Training loss: 3.478065011740165
Validation loss: 2.625628141809006

Epoch: 6| Step: 4
Training loss: 2.3917199911980473
Validation loss: 2.6180695635587843

Epoch: 6| Step: 5
Training loss: 2.8088795565582254
Validation loss: 2.6251000425824005

Epoch: 6| Step: 6
Training loss: 2.9624592838628048
Validation loss: 2.632104043601033

Epoch: 6| Step: 7
Training loss: 3.5447765982628296
Validation loss: 2.6436704561350597

Epoch: 6| Step: 8
Training loss: 2.755171335088502
Validation loss: 2.6343237385025837

Epoch: 6| Step: 9
Training loss: 2.576290703405217
Validation loss: 2.6486584366175796

Epoch: 6| Step: 10
Training loss: 2.8463059561166637
Validation loss: 2.6440992936385554

Epoch: 6| Step: 11
Training loss: 2.84885191965673
Validation loss: 2.659044552024543

Epoch: 6| Step: 12
Training loss: 2.7042200593619534
Validation loss: 2.653508494720304

Epoch: 6| Step: 13
Training loss: 2.6338136846503892
Validation loss: 2.6514325287220477

Epoch: 429| Step: 0
Training loss: 2.991742531780575
Validation loss: 2.675759319218242

Epoch: 6| Step: 1
Training loss: 2.9197213298606033
Validation loss: 2.6719024835254985

Epoch: 6| Step: 2
Training loss: 3.0587006960668965
Validation loss: 2.674997814876418

Epoch: 6| Step: 3
Training loss: 3.249148330604126
Validation loss: 2.688492111307047

Epoch: 6| Step: 4
Training loss: 2.97058482439293
Validation loss: 2.6809174753477305

Epoch: 6| Step: 5
Training loss: 3.2153521630562807
Validation loss: 2.663671810169629

Epoch: 6| Step: 6
Training loss: 2.767156144777095
Validation loss: 2.645608314116244

Epoch: 6| Step: 7
Training loss: 2.642850942125742
Validation loss: 2.6385599172731693

Epoch: 6| Step: 8
Training loss: 2.6873183965315977
Validation loss: 2.637170460913868

Epoch: 6| Step: 9
Training loss: 3.6547556374580297
Validation loss: 2.6308732326154267

Epoch: 6| Step: 10
Training loss: 2.558489289226108
Validation loss: 2.624729162054604

Epoch: 6| Step: 11
Training loss: 2.527009119347201
Validation loss: 2.6250694713003715

Epoch: 6| Step: 12
Training loss: 2.6574807401230127
Validation loss: 2.626749699783338

Epoch: 6| Step: 13
Training loss: 3.106573942244152
Validation loss: 2.6218573513960166

Epoch: 430| Step: 0
Training loss: 3.5085152174918766
Validation loss: 2.6339944639105166

Epoch: 6| Step: 1
Training loss: 3.434230012063379
Validation loss: 2.6264695831036997

Epoch: 6| Step: 2
Training loss: 2.866668571057537
Validation loss: 2.6261870995636674

Epoch: 6| Step: 3
Training loss: 2.912502167664077
Validation loss: 2.623236041538816

Epoch: 6| Step: 4
Training loss: 3.01294284588844
Validation loss: 2.6298906928662844

Epoch: 6| Step: 5
Training loss: 2.8262828918459686
Validation loss: 2.6361301206559764

Epoch: 6| Step: 6
Training loss: 2.744265038327373
Validation loss: 2.628383876457541

Epoch: 6| Step: 7
Training loss: 2.9251920262091775
Validation loss: 2.6196705264535436

Epoch: 6| Step: 8
Training loss: 2.9134437374550273
Validation loss: 2.6208948419622553

Epoch: 6| Step: 9
Training loss: 2.8205845244614363
Validation loss: 2.6297471619985613

Epoch: 6| Step: 10
Training loss: 2.3379124486632827
Validation loss: 2.6155748532039693

Epoch: 6| Step: 11
Training loss: 2.873872950687684
Validation loss: 2.627136205059029

Epoch: 6| Step: 12
Training loss: 2.768167824602326
Validation loss: 2.6204661746214155

Epoch: 6| Step: 13
Training loss: 2.877495056201125
Validation loss: 2.618832741842675

Epoch: 431| Step: 0
Training loss: 3.295928674629818
Validation loss: 2.6267531459469167

Epoch: 6| Step: 1
Training loss: 3.2894379680099974
Validation loss: 2.621546857478706

Epoch: 6| Step: 2
Training loss: 2.6604002898052483
Validation loss: 2.6278133873497196

Epoch: 6| Step: 3
Training loss: 2.794876919324202
Validation loss: 2.6232573115006197

Epoch: 6| Step: 4
Training loss: 2.050745326136251
Validation loss: 2.625082835049234

Epoch: 6| Step: 5
Training loss: 2.534230961216601
Validation loss: 2.6095837848565338

Epoch: 6| Step: 6
Training loss: 2.47388889148361
Validation loss: 2.617282769335394

Epoch: 6| Step: 7
Training loss: 3.3017513136304717
Validation loss: 2.6177194950005567

Epoch: 6| Step: 8
Training loss: 3.7770190567856905
Validation loss: 2.6155505700176165

Epoch: 6| Step: 9
Training loss: 2.4993470292888382
Validation loss: 2.5990078579186027

Epoch: 6| Step: 10
Training loss: 3.3055508254700343
Validation loss: 2.6081471444311664

Epoch: 6| Step: 11
Training loss: 2.8310210011146935
Validation loss: 2.612119775897307

Epoch: 6| Step: 12
Training loss: 2.9323994609382162
Validation loss: 2.6258295001603473

Epoch: 6| Step: 13
Training loss: 2.6140001616766133
Validation loss: 2.623592659649037

Epoch: 432| Step: 0
Training loss: 2.569539890292177
Validation loss: 2.6420280678904873

Epoch: 6| Step: 1
Training loss: 2.806520166114981
Validation loss: 2.6235321656185926

Epoch: 6| Step: 2
Training loss: 3.1446043396979326
Validation loss: 2.6379313804476863

Epoch: 6| Step: 3
Training loss: 3.433629301579316
Validation loss: 2.635451054975931

Epoch: 6| Step: 4
Training loss: 2.893437517402831
Validation loss: 2.636363215082707

Epoch: 6| Step: 5
Training loss: 3.2638571302523673
Validation loss: 2.6392906697709555

Epoch: 6| Step: 6
Training loss: 2.7494613813569453
Validation loss: 2.6448517356755215

Epoch: 6| Step: 7
Training loss: 2.877231229663371
Validation loss: 2.6354021211983367

Epoch: 6| Step: 8
Training loss: 2.700477317721864
Validation loss: 2.6428985380837164

Epoch: 6| Step: 9
Training loss: 2.925809933938165
Validation loss: 2.647683006167428

Epoch: 6| Step: 10
Training loss: 2.5724724966642016
Validation loss: 2.649540969352075

Epoch: 6| Step: 11
Training loss: 2.8128065154155313
Validation loss: 2.6535844287451775

Epoch: 6| Step: 12
Training loss: 2.8656304312584844
Validation loss: 2.66256149916543

Epoch: 6| Step: 13
Training loss: 3.2725598745208955
Validation loss: 2.6519453537334097

Epoch: 433| Step: 0
Training loss: 3.0685648130024368
Validation loss: 2.6554214391698325

Epoch: 6| Step: 1
Training loss: 3.316103576579451
Validation loss: 2.664567559277571

Epoch: 6| Step: 2
Training loss: 2.706634536452237
Validation loss: 2.6557983728699615

Epoch: 6| Step: 3
Training loss: 2.7647905545642892
Validation loss: 2.670684860264876

Epoch: 6| Step: 4
Training loss: 3.2941484069189477
Validation loss: 2.686853765624221

Epoch: 6| Step: 5
Training loss: 2.731841390381614
Validation loss: 2.688620556690094

Epoch: 6| Step: 6
Training loss: 3.311492334803068
Validation loss: 2.682958045870225

Epoch: 6| Step: 7
Training loss: 2.5659062146644436
Validation loss: 2.7276568156148486

Epoch: 6| Step: 8
Training loss: 2.4025164286263134
Validation loss: 2.7107156424745993

Epoch: 6| Step: 9
Training loss: 2.36397563726842
Validation loss: 2.7066642376183476

Epoch: 6| Step: 10
Training loss: 2.9199246511797003
Validation loss: 2.7159525654518775

Epoch: 6| Step: 11
Training loss: 2.8791270281376664
Validation loss: 2.679945712631737

Epoch: 6| Step: 12
Training loss: 3.272350631580586
Validation loss: 2.662110874407719

Epoch: 6| Step: 13
Training loss: 3.2149748653776076
Validation loss: 2.6447939757459675

Epoch: 434| Step: 0
Training loss: 2.686691694908214
Validation loss: 2.6351208287116363

Epoch: 6| Step: 1
Training loss: 2.6092798821022076
Validation loss: 2.63161503811857

Epoch: 6| Step: 2
Training loss: 2.8731598977705257
Validation loss: 2.6305152917821375

Epoch: 6| Step: 3
Training loss: 2.9322438391426355
Validation loss: 2.6213211751438568

Epoch: 6| Step: 4
Training loss: 3.03585230088851
Validation loss: 2.625376022525802

Epoch: 6| Step: 5
Training loss: 2.441848202185609
Validation loss: 2.6389416336577005

Epoch: 6| Step: 6
Training loss: 2.749879314201949
Validation loss: 2.635817632523334

Epoch: 6| Step: 7
Training loss: 3.2207451719890265
Validation loss: 2.6353852786013596

Epoch: 6| Step: 8
Training loss: 3.4849275569966514
Validation loss: 2.6259770994439413

Epoch: 6| Step: 9
Training loss: 3.1595357278601868
Validation loss: 2.6186310677121254

Epoch: 6| Step: 10
Training loss: 3.03993726364452
Validation loss: 2.621665842151728

Epoch: 6| Step: 11
Training loss: 2.5264446658067823
Validation loss: 2.6099419619237634

Epoch: 6| Step: 12
Training loss: 3.174659296213326
Validation loss: 2.60968798928525

Epoch: 6| Step: 13
Training loss: 3.211178958473776
Validation loss: 2.606339697756121

Epoch: 435| Step: 0
Training loss: 3.1268332635327023
Validation loss: 2.5994880256994404

Epoch: 6| Step: 1
Training loss: 2.7549174298826435
Validation loss: 2.597728486513549

Epoch: 6| Step: 2
Training loss: 2.8380935921912633
Validation loss: 2.6108343926052737

Epoch: 6| Step: 3
Training loss: 2.9329791079120784
Validation loss: 2.613751909266044

Epoch: 6| Step: 4
Training loss: 2.904474844286614
Validation loss: 2.623522187702312

Epoch: 6| Step: 5
Training loss: 2.6943744298571093
Validation loss: 2.6320088685358782

Epoch: 6| Step: 6
Training loss: 2.945136512739998
Validation loss: 2.6533297290778552

Epoch: 6| Step: 7
Training loss: 2.6789596948329226
Validation loss: 2.6716939647371736

Epoch: 6| Step: 8
Training loss: 3.5875487852600827
Validation loss: 2.677405313618582

Epoch: 6| Step: 9
Training loss: 2.8622420482100224
Validation loss: 2.6841225355150287

Epoch: 6| Step: 10
Training loss: 3.062239966738662
Validation loss: 2.692278148435385

Epoch: 6| Step: 11
Training loss: 2.372170017073984
Validation loss: 2.7221830308158026

Epoch: 6| Step: 12
Training loss: 3.1885036309628196
Validation loss: 2.724983124362261

Epoch: 6| Step: 13
Training loss: 2.8886710496427996
Validation loss: 2.727014326188894

Epoch: 436| Step: 0
Training loss: 2.551451987719147
Validation loss: 2.6989091770706235

Epoch: 6| Step: 1
Training loss: 3.0753514530958235
Validation loss: 2.6965246536677228

Epoch: 6| Step: 2
Training loss: 2.784192275571113
Validation loss: 2.7114260341700107

Epoch: 6| Step: 3
Training loss: 2.92860103552337
Validation loss: 2.70925599340334

Epoch: 6| Step: 4
Training loss: 3.0123371127716507
Validation loss: 2.7014261645552877

Epoch: 6| Step: 5
Training loss: 2.5295538223129443
Validation loss: 2.7100053597086857

Epoch: 6| Step: 6
Training loss: 3.14834935370173
Validation loss: 2.7022607092487028

Epoch: 6| Step: 7
Training loss: 2.7992874056173735
Validation loss: 2.688790285624433

Epoch: 6| Step: 8
Training loss: 3.357912392814527
Validation loss: 2.663675538683342

Epoch: 6| Step: 9
Training loss: 2.6706683016140538
Validation loss: 2.6592560891071257

Epoch: 6| Step: 10
Training loss: 3.7049400291788817
Validation loss: 2.665552226225615

Epoch: 6| Step: 11
Training loss: 3.0333565539913994
Validation loss: 2.6393380482497073

Epoch: 6| Step: 12
Training loss: 2.847321667265552
Validation loss: 2.630250285977681

Epoch: 6| Step: 13
Training loss: 1.98468129354812
Validation loss: 2.615369519627372

Epoch: 437| Step: 0
Training loss: 2.6134674507713798
Validation loss: 2.6161767165110317

Epoch: 6| Step: 1
Training loss: 3.088090903382099
Validation loss: 2.613898998897398

Epoch: 6| Step: 2
Training loss: 2.5249295857497462
Validation loss: 2.616423098131383

Epoch: 6| Step: 3
Training loss: 2.8731527613687953
Validation loss: 2.623808922120804

Epoch: 6| Step: 4
Training loss: 2.3911159235710078
Validation loss: 2.6353754525685043

Epoch: 6| Step: 5
Training loss: 3.150033096866212
Validation loss: 2.6384901968206047

Epoch: 6| Step: 6
Training loss: 3.2485462752162975
Validation loss: 2.6321209500494485

Epoch: 6| Step: 7
Training loss: 2.8208604106044883
Validation loss: 2.626806423782805

Epoch: 6| Step: 8
Training loss: 3.2951554428737038
Validation loss: 2.605918661803077

Epoch: 6| Step: 9
Training loss: 3.245909243778645
Validation loss: 2.599489250078652

Epoch: 6| Step: 10
Training loss: 2.987094778247486
Validation loss: 2.594909003780782

Epoch: 6| Step: 11
Training loss: 3.2555597141081627
Validation loss: 2.5932507282144304

Epoch: 6| Step: 12
Training loss: 2.877590173655646
Validation loss: 2.5958399244508006

Epoch: 6| Step: 13
Training loss: 2.873347761320044
Validation loss: 2.599506301089499

Epoch: 438| Step: 0
Training loss: 3.122807305685835
Validation loss: 2.599687479971221

Epoch: 6| Step: 1
Training loss: 3.0203928834625455
Validation loss: 2.601147990986422

Epoch: 6| Step: 2
Training loss: 2.719458038387886
Validation loss: 2.604789925758508

Epoch: 6| Step: 3
Training loss: 3.3191685759238547
Validation loss: 2.617688508460576

Epoch: 6| Step: 4
Training loss: 2.887099637105584
Validation loss: 2.630206531453782

Epoch: 6| Step: 5
Training loss: 3.103172825870199
Validation loss: 2.6410215298159163

Epoch: 6| Step: 6
Training loss: 3.259808484636229
Validation loss: 2.652346105497644

Epoch: 6| Step: 7
Training loss: 2.50078570417051
Validation loss: 2.6461618384407357

Epoch: 6| Step: 8
Training loss: 3.506111531234853
Validation loss: 2.6547089557560097

Epoch: 6| Step: 9
Training loss: 2.6796319805655275
Validation loss: 2.6691913465444648

Epoch: 6| Step: 10
Training loss: 2.2355651886713286
Validation loss: 2.6389989300682437

Epoch: 6| Step: 11
Training loss: 3.0511497831784085
Validation loss: 2.6487495223314967

Epoch: 6| Step: 12
Training loss: 2.5694398645125345
Validation loss: 2.6260897341880645

Epoch: 6| Step: 13
Training loss: 2.705842256553825
Validation loss: 2.630244134793113

Epoch: 439| Step: 0
Training loss: 2.8827369080430585
Validation loss: 2.6237479044703673

Epoch: 6| Step: 1
Training loss: 2.10264213653089
Validation loss: 2.62664036201626

Epoch: 6| Step: 2
Training loss: 2.318129826198973
Validation loss: 2.6113925007087846

Epoch: 6| Step: 3
Training loss: 3.23482948832585
Validation loss: 2.6092225825381146

Epoch: 6| Step: 4
Training loss: 3.1555271642897185
Validation loss: 2.6141222063559177

Epoch: 6| Step: 5
Training loss: 2.8354241192841436
Validation loss: 2.6142840630676742

Epoch: 6| Step: 6
Training loss: 3.2006811728275553
Validation loss: 2.6147879563882332

Epoch: 6| Step: 7
Training loss: 2.946475014588904
Validation loss: 2.605868004709052

Epoch: 6| Step: 8
Training loss: 2.6125249067515544
Validation loss: 2.610148675188897

Epoch: 6| Step: 9
Training loss: 3.5369923581209854
Validation loss: 2.6116393194377903

Epoch: 6| Step: 10
Training loss: 3.277105129498466
Validation loss: 2.5961292067480026

Epoch: 6| Step: 11
Training loss: 2.8102860956044937
Validation loss: 2.601199886207906

Epoch: 6| Step: 12
Training loss: 2.8735804162881036
Validation loss: 2.60295253351185

Epoch: 6| Step: 13
Training loss: 2.7974156544424145
Validation loss: 2.610107017577978

Epoch: 440| Step: 0
Training loss: 3.31420724886292
Validation loss: 2.594186146460693

Epoch: 6| Step: 1
Training loss: 2.8192752188105747
Validation loss: 2.603312258112056

Epoch: 6| Step: 2
Training loss: 3.1715839421570475
Validation loss: 2.5992671802689786

Epoch: 6| Step: 3
Training loss: 2.9425080807946804
Validation loss: 2.59957373282394

Epoch: 6| Step: 4
Training loss: 2.8125054253419894
Validation loss: 2.6008275876271867

Epoch: 6| Step: 5
Training loss: 2.471236123956325
Validation loss: 2.6034760502422256

Epoch: 6| Step: 6
Training loss: 3.1053603435284574
Validation loss: 2.5938047909079933

Epoch: 6| Step: 7
Training loss: 2.4451046206317963
Validation loss: 2.6051600835895576

Epoch: 6| Step: 8
Training loss: 2.723063237380908
Validation loss: 2.6014984348633114

Epoch: 6| Step: 9
Training loss: 3.542801992914441
Validation loss: 2.6002330882217173

Epoch: 6| Step: 10
Training loss: 2.8904070797818475
Validation loss: 2.5946912030145204

Epoch: 6| Step: 11
Training loss: 2.885411525313184
Validation loss: 2.606735124181877

Epoch: 6| Step: 12
Training loss: 2.8758220326693418
Validation loss: 2.630371583501922

Epoch: 6| Step: 13
Training loss: 2.408395974511655
Validation loss: 2.6741321190494425

Epoch: 441| Step: 0
Training loss: 2.773883450612698
Validation loss: 2.7015682216151857

Epoch: 6| Step: 1
Training loss: 3.3905778872824914
Validation loss: 2.737581399750732

Epoch: 6| Step: 2
Training loss: 2.9371022705933827
Validation loss: 2.7519403065486316

Epoch: 6| Step: 3
Training loss: 3.054531708083659
Validation loss: 2.767386308793966

Epoch: 6| Step: 4
Training loss: 2.626421951990476
Validation loss: 2.737517750505927

Epoch: 6| Step: 5
Training loss: 3.6552593486737566
Validation loss: 2.731798308618987

Epoch: 6| Step: 6
Training loss: 2.8864440374296847
Validation loss: 2.6912890331242716

Epoch: 6| Step: 7
Training loss: 2.4064699543088444
Validation loss: 2.646826916914691

Epoch: 6| Step: 8
Training loss: 2.520953299029689
Validation loss: 2.627228800019473

Epoch: 6| Step: 9
Training loss: 3.1096494927324794
Validation loss: 2.61910550702486

Epoch: 6| Step: 10
Training loss: 2.779274828482262
Validation loss: 2.6188905193120235

Epoch: 6| Step: 11
Training loss: 3.0965115331000437
Validation loss: 2.614852882227465

Epoch: 6| Step: 12
Training loss: 2.502689059772953
Validation loss: 2.6143655098341076

Epoch: 6| Step: 13
Training loss: 3.38884635717944
Validation loss: 2.6123233923684674

Epoch: 442| Step: 0
Training loss: 2.8224847517116936
Validation loss: 2.6102571981333775

Epoch: 6| Step: 1
Training loss: 2.9566277615447154
Validation loss: 2.602059984839267

Epoch: 6| Step: 2
Training loss: 2.751520863379922
Validation loss: 2.6036900854968774

Epoch: 6| Step: 3
Training loss: 3.0204003034637745
Validation loss: 2.61596600442449

Epoch: 6| Step: 4
Training loss: 2.7761253549487206
Validation loss: 2.611629226388665

Epoch: 6| Step: 5
Training loss: 2.921050419451625
Validation loss: 2.61256134173933

Epoch: 6| Step: 6
Training loss: 3.2247977614754375
Validation loss: 2.627576385009374

Epoch: 6| Step: 7
Training loss: 2.7167294766082737
Validation loss: 2.6375781696731884

Epoch: 6| Step: 8
Training loss: 2.5386149320072655
Validation loss: 2.6590557242349724

Epoch: 6| Step: 9
Training loss: 3.243336816245467
Validation loss: 2.6846188409038585

Epoch: 6| Step: 10
Training loss: 2.7126985046600844
Validation loss: 2.6868793851750143

Epoch: 6| Step: 11
Training loss: 2.9051761078759815
Validation loss: 2.680649279272676

Epoch: 6| Step: 12
Training loss: 3.1033158811193893
Validation loss: 2.6608077901081115

Epoch: 6| Step: 13
Training loss: 3.645670394889509
Validation loss: 2.638522045742884

Epoch: 443| Step: 0
Training loss: 2.7191442444937124
Validation loss: 2.627678326616447

Epoch: 6| Step: 1
Training loss: 2.8771221787143486
Validation loss: 2.612772732163451

Epoch: 6| Step: 2
Training loss: 2.9307195447826286
Validation loss: 2.6181990060828495

Epoch: 6| Step: 3
Training loss: 2.440617255321919
Validation loss: 2.606994574721019

Epoch: 6| Step: 4
Training loss: 3.418387809132113
Validation loss: 2.598213329870075

Epoch: 6| Step: 5
Training loss: 2.8064126152381395
Validation loss: 2.6056998519463708

Epoch: 6| Step: 6
Training loss: 3.2033485892809486
Validation loss: 2.6032880781757832

Epoch: 6| Step: 7
Training loss: 2.4772574716182563
Validation loss: 2.6094159589803207

Epoch: 6| Step: 8
Training loss: 2.991393300125812
Validation loss: 2.6129608009327066

Epoch: 6| Step: 9
Training loss: 2.8817153124640615
Validation loss: 2.6213665547259555

Epoch: 6| Step: 10
Training loss: 2.960972285003457
Validation loss: 2.60875505561177

Epoch: 6| Step: 11
Training loss: 2.8847886009050336
Validation loss: 2.611889320512935

Epoch: 6| Step: 12
Training loss: 3.0421265206595525
Validation loss: 2.6100194640049317

Epoch: 6| Step: 13
Training loss: 3.1902718553131524
Validation loss: 2.613593296745329

Epoch: 444| Step: 0
Training loss: 2.203295761957673
Validation loss: 2.618774387477978

Epoch: 6| Step: 1
Training loss: 2.8858538869033503
Validation loss: 2.617998813680742

Epoch: 6| Step: 2
Training loss: 2.8002065071520232
Validation loss: 2.6159364004868304

Epoch: 6| Step: 3
Training loss: 3.0476619388905664
Validation loss: 2.619089847768147

Epoch: 6| Step: 4
Training loss: 3.0990913597641083
Validation loss: 2.617518934881933

Epoch: 6| Step: 5
Training loss: 2.7229470490383125
Validation loss: 2.6318711038014286

Epoch: 6| Step: 6
Training loss: 3.385011306360653
Validation loss: 2.6317434344997324

Epoch: 6| Step: 7
Training loss: 3.1308516075718527
Validation loss: 2.6335955268744673

Epoch: 6| Step: 8
Training loss: 3.114117862957677
Validation loss: 2.647404263863891

Epoch: 6| Step: 9
Training loss: 3.1244286587085606
Validation loss: 2.6447644318041448

Epoch: 6| Step: 10
Training loss: 2.4295500198179925
Validation loss: 2.629291731366118

Epoch: 6| Step: 11
Training loss: 2.2418010524851084
Validation loss: 2.609977031303855

Epoch: 6| Step: 12
Training loss: 3.546994782832492
Validation loss: 2.601147781057775

Epoch: 6| Step: 13
Training loss: 2.610187335544279
Validation loss: 2.6018298562736772

Epoch: 445| Step: 0
Training loss: 2.4661488410477523
Validation loss: 2.5983055623835303

Epoch: 6| Step: 1
Training loss: 3.0316813053940193
Validation loss: 2.596433174595856

Epoch: 6| Step: 2
Training loss: 2.6578997705878082
Validation loss: 2.599798464043766

Epoch: 6| Step: 3
Training loss: 2.989810168514048
Validation loss: 2.597422936103953

Epoch: 6| Step: 4
Training loss: 3.237814728156506
Validation loss: 2.618058722699308

Epoch: 6| Step: 5
Training loss: 2.769430957694605
Validation loss: 2.625526905648212

Epoch: 6| Step: 6
Training loss: 3.099323684996829
Validation loss: 2.6165322602819923

Epoch: 6| Step: 7
Training loss: 2.244259398714476
Validation loss: 2.617186248147194

Epoch: 6| Step: 8
Training loss: 2.7662192530588845
Validation loss: 2.616255932433987

Epoch: 6| Step: 9
Training loss: 3.342686849548654
Validation loss: 2.5944386554073233

Epoch: 6| Step: 10
Training loss: 2.8341280626694254
Validation loss: 2.622429862537201

Epoch: 6| Step: 11
Training loss: 3.1791609344497407
Validation loss: 2.618717492433605

Epoch: 6| Step: 12
Training loss: 3.1289897626573424
Validation loss: 2.634429432202934

Epoch: 6| Step: 13
Training loss: 2.595671068715478
Validation loss: 2.6322679637834487

Epoch: 446| Step: 0
Training loss: 2.302952206883048
Validation loss: 2.6451913004422622

Epoch: 6| Step: 1
Training loss: 3.097956100517311
Validation loss: 2.659471578015497

Epoch: 6| Step: 2
Training loss: 2.9202946759818387
Validation loss: 2.657979619485075

Epoch: 6| Step: 3
Training loss: 2.902342107061278
Validation loss: 2.6793933789390616

Epoch: 6| Step: 4
Training loss: 2.844475622138711
Validation loss: 2.6730459080264963

Epoch: 6| Step: 5
Training loss: 3.1574932709030974
Validation loss: 2.687496362728053

Epoch: 6| Step: 6
Training loss: 3.2622856332793098
Validation loss: 2.6451794397105144

Epoch: 6| Step: 7
Training loss: 2.7678921991756336
Validation loss: 2.6528384127247318

Epoch: 6| Step: 8
Training loss: 2.293818405752852
Validation loss: 2.63983735251452

Epoch: 6| Step: 9
Training loss: 2.71840665556602
Validation loss: 2.63375718943858

Epoch: 6| Step: 10
Training loss: 2.7701572845920093
Validation loss: 2.6295951610186763

Epoch: 6| Step: 11
Training loss: 2.6504733832418386
Validation loss: 2.6051295617248

Epoch: 6| Step: 12
Training loss: 3.4285497494420896
Validation loss: 2.6096276749244316

Epoch: 6| Step: 13
Training loss: 3.7688778325759413
Validation loss: 2.6065675663332892

Epoch: 447| Step: 0
Training loss: 3.5960827761194034
Validation loss: 2.599046124715672

Epoch: 6| Step: 1
Training loss: 2.8381629807905298
Validation loss: 2.6065969993230564

Epoch: 6| Step: 2
Training loss: 3.197943241037963
Validation loss: 2.6169329599517197

Epoch: 6| Step: 3
Training loss: 2.4097553828654523
Validation loss: 2.618106768389092

Epoch: 6| Step: 4
Training loss: 3.0630151743523877
Validation loss: 2.634889658836496

Epoch: 6| Step: 5
Training loss: 3.392396244494898
Validation loss: 2.650848734295577

Epoch: 6| Step: 6
Training loss: 2.5376094475054365
Validation loss: 2.645073470948379

Epoch: 6| Step: 7
Training loss: 3.139084471364123
Validation loss: 2.649622157675804

Epoch: 6| Step: 8
Training loss: 2.5812222458499585
Validation loss: 2.663895588744702

Epoch: 6| Step: 9
Training loss: 2.9752998777926516
Validation loss: 2.6527527014777283

Epoch: 6| Step: 10
Training loss: 2.9449362274156163
Validation loss: 2.6588596995046054

Epoch: 6| Step: 11
Training loss: 2.9404039030233653
Validation loss: 2.6631153003284673

Epoch: 6| Step: 12
Training loss: 2.4061793527512036
Validation loss: 2.6705087448731932

Epoch: 6| Step: 13
Training loss: 1.783486818975535
Validation loss: 2.651262727928221

Epoch: 448| Step: 0
Training loss: 3.1092198012068555
Validation loss: 2.6544537980371468

Epoch: 6| Step: 1
Training loss: 3.0471000392655294
Validation loss: 2.6542585123062077

Epoch: 6| Step: 2
Training loss: 2.8316547432914696
Validation loss: 2.6664928503327237

Epoch: 6| Step: 3
Training loss: 2.5975180223443703
Validation loss: 2.6784835651400103

Epoch: 6| Step: 4
Training loss: 3.1593730319023607
Validation loss: 2.718752870333048

Epoch: 6| Step: 5
Training loss: 2.9855218251659927
Validation loss: 2.7175706845233267

Epoch: 6| Step: 6
Training loss: 2.9432015784883325
Validation loss: 2.7121265859597568

Epoch: 6| Step: 7
Training loss: 2.5517904204348363
Validation loss: 2.7003691262580203

Epoch: 6| Step: 8
Training loss: 2.9326079194096804
Validation loss: 2.722777108621535

Epoch: 6| Step: 9
Training loss: 2.7880012779944403
Validation loss: 2.6975557503407694

Epoch: 6| Step: 10
Training loss: 3.1119331303254554
Validation loss: 2.675888380578683

Epoch: 6| Step: 11
Training loss: 3.240635659063277
Validation loss: 2.66654399684533

Epoch: 6| Step: 12
Training loss: 2.6305283052813695
Validation loss: 2.6447536741951523

Epoch: 6| Step: 13
Training loss: 2.4146933117215634
Validation loss: 2.6295095564300954

Epoch: 449| Step: 0
Training loss: 3.0117706808914493
Validation loss: 2.6143938058063307

Epoch: 6| Step: 1
Training loss: 3.3549468908071733
Validation loss: 2.6156868940331712

Epoch: 6| Step: 2
Training loss: 2.948268550364495
Validation loss: 2.6078916531980725

Epoch: 6| Step: 3
Training loss: 2.4189865114956413
Validation loss: 2.6146685302826547

Epoch: 6| Step: 4
Training loss: 2.686624961163318
Validation loss: 2.6181706895475982

Epoch: 6| Step: 5
Training loss: 3.222188649788249
Validation loss: 2.615474519794246

Epoch: 6| Step: 6
Training loss: 2.9997315286671222
Validation loss: 2.6163007227807222

Epoch: 6| Step: 7
Training loss: 2.9499431604631603
Validation loss: 2.609990187479452

Epoch: 6| Step: 8
Training loss: 3.1735404016216804
Validation loss: 2.619866992052902

Epoch: 6| Step: 9
Training loss: 3.0170215278542734
Validation loss: 2.6154547112243667

Epoch: 6| Step: 10
Training loss: 2.5659480273721065
Validation loss: 2.6092361266852007

Epoch: 6| Step: 11
Training loss: 2.279492262806849
Validation loss: 2.623496144878656

Epoch: 6| Step: 12
Training loss: 3.11974808923073
Validation loss: 2.639508569543405

Epoch: 6| Step: 13
Training loss: 2.869898208514352
Validation loss: 2.6392167616477944

Epoch: 450| Step: 0
Training loss: 3.3437577006884167
Validation loss: 2.6383855704196177

Epoch: 6| Step: 1
Training loss: 2.7867156768516663
Validation loss: 2.6428801747418107

Epoch: 6| Step: 2
Training loss: 2.757745066566678
Validation loss: 2.643971176823379

Epoch: 6| Step: 3
Training loss: 3.446660407433892
Validation loss: 2.6208398475711436

Epoch: 6| Step: 4
Training loss: 2.2409752948357573
Validation loss: 2.6362441080160446

Epoch: 6| Step: 5
Training loss: 2.993936610129893
Validation loss: 2.627263357624807

Epoch: 6| Step: 6
Training loss: 3.0236037255460153
Validation loss: 2.619938297180783

Epoch: 6| Step: 7
Training loss: 2.478817463705543
Validation loss: 2.625092803127169

Epoch: 6| Step: 8
Training loss: 2.8391092182151256
Validation loss: 2.6330513882147617

Epoch: 6| Step: 9
Training loss: 2.603914681005234
Validation loss: 2.6188927727465066

Epoch: 6| Step: 10
Training loss: 2.395833642931932
Validation loss: 2.6385329346650988

Epoch: 6| Step: 11
Training loss: 3.2695779193204455
Validation loss: 2.6329159681460914

Epoch: 6| Step: 12
Training loss: 2.7019650831698296
Validation loss: 2.6359748406497125

Epoch: 6| Step: 13
Training loss: 3.750401284681758
Validation loss: 2.623656605446918

Epoch: 451| Step: 0
Training loss: 2.74701033986815
Validation loss: 2.6291150254566467

Epoch: 6| Step: 1
Training loss: 2.6914253843205898
Validation loss: 2.6054061594572224

Epoch: 6| Step: 2
Training loss: 3.5933346715675745
Validation loss: 2.6067696781018

Epoch: 6| Step: 3
Training loss: 3.2637075243041034
Validation loss: 2.6130623708843523

Epoch: 6| Step: 4
Training loss: 2.5742494063223416
Validation loss: 2.607947404272214

Epoch: 6| Step: 5
Training loss: 2.6195464022568222
Validation loss: 2.619457986823243

Epoch: 6| Step: 6
Training loss: 3.393217721579693
Validation loss: 2.6209260586057814

Epoch: 6| Step: 7
Training loss: 2.9362291874316435
Validation loss: 2.625885498148044

Epoch: 6| Step: 8
Training loss: 2.567720909681079
Validation loss: 2.6309964862715103

Epoch: 6| Step: 9
Training loss: 2.8048184930075317
Validation loss: 2.6343713805043003

Epoch: 6| Step: 10
Training loss: 2.926752110177545
Validation loss: 2.6286858719509874

Epoch: 6| Step: 11
Training loss: 2.660524407228763
Validation loss: 2.621339521299546

Epoch: 6| Step: 12
Training loss: 2.9037331788934297
Validation loss: 2.6308542318484394

Epoch: 6| Step: 13
Training loss: 2.3630483969737965
Validation loss: 2.626522532879418

Epoch: 452| Step: 0
Training loss: 2.866006467632229
Validation loss: 2.6166141338050823

Epoch: 6| Step: 1
Training loss: 3.2664170468253904
Validation loss: 2.616682544299799

Epoch: 6| Step: 2
Training loss: 2.8931683872452996
Validation loss: 2.631369988838001

Epoch: 6| Step: 3
Training loss: 3.20365640837693
Validation loss: 2.6178989237517256

Epoch: 6| Step: 4
Training loss: 3.1333929651416246
Validation loss: 2.623989309116933

Epoch: 6| Step: 5
Training loss: 2.8163053412487935
Validation loss: 2.6414507939736964

Epoch: 6| Step: 6
Training loss: 2.7995102896919426
Validation loss: 2.645182265822039

Epoch: 6| Step: 7
Training loss: 2.6073479002556468
Validation loss: 2.654576580703262

Epoch: 6| Step: 8
Training loss: 2.671578374091079
Validation loss: 2.668214207292115

Epoch: 6| Step: 9
Training loss: 3.2174466651698967
Validation loss: 2.683135072551402

Epoch: 6| Step: 10
Training loss: 2.408029071987223
Validation loss: 2.6778092707044077

Epoch: 6| Step: 11
Training loss: 2.6888339258606835
Validation loss: 2.6652326791632412

Epoch: 6| Step: 12
Training loss: 3.185112751113324
Validation loss: 2.6457623834054114

Epoch: 6| Step: 13
Training loss: 2.531026571326493
Validation loss: 2.6282802991493357

Epoch: 453| Step: 0
Training loss: 3.0479859503074294
Validation loss: 2.6209187636046862

Epoch: 6| Step: 1
Training loss: 3.0386378915899233
Validation loss: 2.6212802339713708

Epoch: 6| Step: 2
Training loss: 3.244445014834535
Validation loss: 2.618884982628968

Epoch: 6| Step: 3
Training loss: 2.960349797122915
Validation loss: 2.6126642587581657

Epoch: 6| Step: 4
Training loss: 3.45803415007797
Validation loss: 2.6310303717567596

Epoch: 6| Step: 5
Training loss: 3.2621058434225287
Validation loss: 2.627140815855892

Epoch: 6| Step: 6
Training loss: 2.6928100468346705
Validation loss: 2.6244470470003027

Epoch: 6| Step: 7
Training loss: 2.809486554978721
Validation loss: 2.6363253771489763

Epoch: 6| Step: 8
Training loss: 2.766773998139531
Validation loss: 2.6457562915404234

Epoch: 6| Step: 9
Training loss: 3.159599717295714
Validation loss: 2.645675203576556

Epoch: 6| Step: 10
Training loss: 2.6132122766262142
Validation loss: 2.65032931684845

Epoch: 6| Step: 11
Training loss: 2.038506910846178
Validation loss: 2.629102188281005

Epoch: 6| Step: 12
Training loss: 2.7167702844279695
Validation loss: 2.6228034052674745

Epoch: 6| Step: 13
Training loss: 2.1078692678126907
Validation loss: 2.6303568178068835

Epoch: 454| Step: 0
Training loss: 2.6881826553955612
Validation loss: 2.611930942336619

Epoch: 6| Step: 1
Training loss: 2.7972694843352444
Validation loss: 2.615046591303966

Epoch: 6| Step: 2
Training loss: 2.707376829605615
Validation loss: 2.6095173687431523

Epoch: 6| Step: 3
Training loss: 3.5075264795001235
Validation loss: 2.609787037300738

Epoch: 6| Step: 4
Training loss: 3.156672987590881
Validation loss: 2.6144335084927848

Epoch: 6| Step: 5
Training loss: 2.7962673102479543
Validation loss: 2.6178344367781294

Epoch: 6| Step: 6
Training loss: 1.8985516549156771
Validation loss: 2.6358508899739936

Epoch: 6| Step: 7
Training loss: 2.736767577689416
Validation loss: 2.6397457427110846

Epoch: 6| Step: 8
Training loss: 3.1730957688703394
Validation loss: 2.655570625803832

Epoch: 6| Step: 9
Training loss: 3.469418160636168
Validation loss: 2.658366844801044

Epoch: 6| Step: 10
Training loss: 2.6848980039975667
Validation loss: 2.6677499805530056

Epoch: 6| Step: 11
Training loss: 2.861293795122555
Validation loss: 2.6449639562906735

Epoch: 6| Step: 12
Training loss: 2.4020255521611054
Validation loss: 2.6649500073096934

Epoch: 6| Step: 13
Training loss: 3.269941625511521
Validation loss: 2.6466822471489646

Epoch: 455| Step: 0
Training loss: 3.019036927418446
Validation loss: 2.6973899935067003

Epoch: 6| Step: 1
Training loss: 3.4440295540386696
Validation loss: 2.693873583763389

Epoch: 6| Step: 2
Training loss: 2.5138532192259158
Validation loss: 2.678342309070139

Epoch: 6| Step: 3
Training loss: 2.7053156448915296
Validation loss: 2.6870754666902963

Epoch: 6| Step: 4
Training loss: 2.70820308274286
Validation loss: 2.6873781386933167

Epoch: 6| Step: 5
Training loss: 3.305074466206904
Validation loss: 2.6695846876525366

Epoch: 6| Step: 6
Training loss: 3.2042616897468585
Validation loss: 2.667043190825802

Epoch: 6| Step: 7
Training loss: 2.9809048434851264
Validation loss: 2.6498118350989825

Epoch: 6| Step: 8
Training loss: 2.5357059770290635
Validation loss: 2.627580630134828

Epoch: 6| Step: 9
Training loss: 3.0094980248392305
Validation loss: 2.6116310011661286

Epoch: 6| Step: 10
Training loss: 2.724233950109498
Validation loss: 2.619675059379738

Epoch: 6| Step: 11
Training loss: 2.769196870791981
Validation loss: 2.6187315425447015

Epoch: 6| Step: 12
Training loss: 2.666431257665472
Validation loss: 2.6310640385458104

Epoch: 6| Step: 13
Training loss: 2.685304232646442
Validation loss: 2.6274884193149357

Epoch: 456| Step: 0
Training loss: 3.751087793887417
Validation loss: 2.6237002004967014

Epoch: 6| Step: 1
Training loss: 3.037919091720007
Validation loss: 2.6101860852450125

Epoch: 6| Step: 2
Training loss: 2.997891957011307
Validation loss: 2.6244900115733025

Epoch: 6| Step: 3
Training loss: 3.3025576534624435
Validation loss: 2.604730592437842

Epoch: 6| Step: 4
Training loss: 3.0508406434279385
Validation loss: 2.615645623561636

Epoch: 6| Step: 5
Training loss: 2.653115790792597
Validation loss: 2.5940684303334605

Epoch: 6| Step: 6
Training loss: 2.7384355313839137
Validation loss: 2.6019360294682543

Epoch: 6| Step: 7
Training loss: 2.0879761524007847
Validation loss: 2.6002571269885983

Epoch: 6| Step: 8
Training loss: 2.843062432976584
Validation loss: 2.622149351842179

Epoch: 6| Step: 9
Training loss: 2.269570118871655
Validation loss: 2.6223484501868164

Epoch: 6| Step: 10
Training loss: 3.0555696506367807
Validation loss: 2.6507541152332545

Epoch: 6| Step: 11
Training loss: 2.950014929006269
Validation loss: 2.6537484808273266

Epoch: 6| Step: 12
Training loss: 2.565302084372937
Validation loss: 2.6797800652311357

Epoch: 6| Step: 13
Training loss: 2.7915797908037794
Validation loss: 2.685083284728434

Epoch: 457| Step: 0
Training loss: 2.909493881730489
Validation loss: 2.683137153074808

Epoch: 6| Step: 1
Training loss: 3.0829102165717353
Validation loss: 2.702955695071237

Epoch: 6| Step: 2
Training loss: 3.2088328051164345
Validation loss: 2.7242291582781664

Epoch: 6| Step: 3
Training loss: 2.829614910709179
Validation loss: 2.749234666349814

Epoch: 6| Step: 4
Training loss: 2.9523133469384213
Validation loss: 2.755122421013539

Epoch: 6| Step: 5
Training loss: 2.7586283139008363
Validation loss: 2.7248437256194613

Epoch: 6| Step: 6
Training loss: 2.862454283236783
Validation loss: 2.690142843779274

Epoch: 6| Step: 7
Training loss: 2.4066061771888934
Validation loss: 2.6527502023462404

Epoch: 6| Step: 8
Training loss: 2.330303222834222
Validation loss: 2.6346466374001913

Epoch: 6| Step: 9
Training loss: 2.7321044213933283
Validation loss: 2.615173195518323

Epoch: 6| Step: 10
Training loss: 2.702589389900062
Validation loss: 2.5983330880405022

Epoch: 6| Step: 11
Training loss: 2.8784822024878083
Validation loss: 2.606005289723661

Epoch: 6| Step: 12
Training loss: 3.5531380766373815
Validation loss: 2.609341181093245

Epoch: 6| Step: 13
Training loss: 3.3186036503307053
Validation loss: 2.6113255371367594

Epoch: 458| Step: 0
Training loss: 2.5595056670465794
Validation loss: 2.6203770016739396

Epoch: 6| Step: 1
Training loss: 2.8778769983724515
Validation loss: 2.612242259768083

Epoch: 6| Step: 2
Training loss: 2.416141244618479
Validation loss: 2.63103073033099

Epoch: 6| Step: 3
Training loss: 2.6847138267614303
Validation loss: 2.6188737134458275

Epoch: 6| Step: 4
Training loss: 3.1855122969555736
Validation loss: 2.6379243521095304

Epoch: 6| Step: 5
Training loss: 2.5394241779662665
Validation loss: 2.6495989712177583

Epoch: 6| Step: 6
Training loss: 2.4057020083574643
Validation loss: 2.6455701490884977

Epoch: 6| Step: 7
Training loss: 3.332517206100379
Validation loss: 2.656121089540972

Epoch: 6| Step: 8
Training loss: 3.0833454303675984
Validation loss: 2.6362313434817035

Epoch: 6| Step: 9
Training loss: 2.705719689262957
Validation loss: 2.6256041556692646

Epoch: 6| Step: 10
Training loss: 2.6503706546894095
Validation loss: 2.619588176928769

Epoch: 6| Step: 11
Training loss: 4.0971837675944505
Validation loss: 2.6077244282155836

Epoch: 6| Step: 12
Training loss: 2.851426881674444
Validation loss: 2.6010193932113586

Epoch: 6| Step: 13
Training loss: 2.742709553031684
Validation loss: 2.6060616035090307

Epoch: 459| Step: 0
Training loss: 2.7250501925544266
Validation loss: 2.6068819036351614

Epoch: 6| Step: 1
Training loss: 2.770477692766748
Validation loss: 2.596660220310504

Epoch: 6| Step: 2
Training loss: 2.553471173615411
Validation loss: 2.5934991933968856

Epoch: 6| Step: 3
Training loss: 2.7089576197308896
Validation loss: 2.605960931370214

Epoch: 6| Step: 4
Training loss: 2.60781612773115
Validation loss: 2.601441087088073

Epoch: 6| Step: 5
Training loss: 3.11653348328774
Validation loss: 2.606669688315752

Epoch: 6| Step: 6
Training loss: 2.781414584315641
Validation loss: 2.606460776257599

Epoch: 6| Step: 7
Training loss: 3.3059466332791647
Validation loss: 2.619895550542467

Epoch: 6| Step: 8
Training loss: 3.212841351255901
Validation loss: 2.6194830206473387

Epoch: 6| Step: 9
Training loss: 3.2434173825054757
Validation loss: 2.62101022842086

Epoch: 6| Step: 10
Training loss: 2.8158272453604307
Validation loss: 2.6196628599970473

Epoch: 6| Step: 11
Training loss: 2.629136414109504
Validation loss: 2.6252686948518056

Epoch: 6| Step: 12
Training loss: 3.0176795720204703
Validation loss: 2.61600828118312

Epoch: 6| Step: 13
Training loss: 2.9117307768650864
Validation loss: 2.6225029778200417

Epoch: 460| Step: 0
Training loss: 3.347397855492248
Validation loss: 2.6275532615901067

Epoch: 6| Step: 1
Training loss: 2.912575841088148
Validation loss: 2.622969521319505

Epoch: 6| Step: 2
Training loss: 3.221152436773997
Validation loss: 2.620259747954485

Epoch: 6| Step: 3
Training loss: 3.016389581870873
Validation loss: 2.630656363431698

Epoch: 6| Step: 4
Training loss: 2.547434552281322
Validation loss: 2.6319441993450563

Epoch: 6| Step: 5
Training loss: 3.0782269301214935
Validation loss: 2.617280346039775

Epoch: 6| Step: 6
Training loss: 2.8284551101151534
Validation loss: 2.6070903541971657

Epoch: 6| Step: 7
Training loss: 2.8004959791141326
Validation loss: 2.61294536485068

Epoch: 6| Step: 8
Training loss: 2.874182543431915
Validation loss: 2.6196306858833296

Epoch: 6| Step: 9
Training loss: 2.249651987924457
Validation loss: 2.6228673194816716

Epoch: 6| Step: 10
Training loss: 2.903103016748543
Validation loss: 2.60695502425711

Epoch: 6| Step: 11
Training loss: 2.812395221030014
Validation loss: 2.613156034530272

Epoch: 6| Step: 12
Training loss: 3.01564555581158
Validation loss: 2.6224306436252265

Epoch: 6| Step: 13
Training loss: 2.58134924672413
Validation loss: 2.627203598978514

Epoch: 461| Step: 0
Training loss: 3.545420613159848
Validation loss: 2.6475382970014087

Epoch: 6| Step: 1
Training loss: 2.594254502099086
Validation loss: 2.6502023065156606

Epoch: 6| Step: 2
Training loss: 3.1479382746266444
Validation loss: 2.6880463743266163

Epoch: 6| Step: 3
Training loss: 2.73528113473686
Validation loss: 2.6832876434925383

Epoch: 6| Step: 4
Training loss: 2.3940291757359398
Validation loss: 2.666222294639927

Epoch: 6| Step: 5
Training loss: 3.3664173210140826
Validation loss: 2.649112833230382

Epoch: 6| Step: 6
Training loss: 2.6796303790263094
Validation loss: 2.6379856230000147

Epoch: 6| Step: 7
Training loss: 2.5322373901559385
Validation loss: 2.634019196068173

Epoch: 6| Step: 8
Training loss: 2.5481104750285923
Validation loss: 2.6293541394271243

Epoch: 6| Step: 9
Training loss: 3.227210323888013
Validation loss: 2.62256325022988

Epoch: 6| Step: 10
Training loss: 2.4518837673896905
Validation loss: 2.626104255416537

Epoch: 6| Step: 11
Training loss: 2.746701603300002
Validation loss: 2.6163577174127655

Epoch: 6| Step: 12
Training loss: 3.289250674267461
Validation loss: 2.640764901050421

Epoch: 6| Step: 13
Training loss: 2.7282770662869353
Validation loss: 2.6207436716173085

Epoch: 462| Step: 0
Training loss: 3.0680740388891317
Validation loss: 2.649897313503445

Epoch: 6| Step: 1
Training loss: 2.991996261023159
Validation loss: 2.697450768076821

Epoch: 6| Step: 2
Training loss: 3.071405968313597
Validation loss: 2.7087391075281992

Epoch: 6| Step: 3
Training loss: 2.556044844996619
Validation loss: 2.713285189865617

Epoch: 6| Step: 4
Training loss: 2.9726349156901155
Validation loss: 2.6952723783836166

Epoch: 6| Step: 5
Training loss: 3.6901620857181965
Validation loss: 2.7269206840329305

Epoch: 6| Step: 6
Training loss: 2.3798040690835376
Validation loss: 2.6964963629363665

Epoch: 6| Step: 7
Training loss: 2.39283042355974
Validation loss: 2.6791157158635115

Epoch: 6| Step: 8
Training loss: 2.9796680659844084
Validation loss: 2.6518126531756936

Epoch: 6| Step: 9
Training loss: 2.6563286264787696
Validation loss: 2.6355977594239377

Epoch: 6| Step: 10
Training loss: 3.1449147245311364
Validation loss: 2.6099084705844087

Epoch: 6| Step: 11
Training loss: 2.5746004924293935
Validation loss: 2.596556923685675

Epoch: 6| Step: 12
Training loss: 3.0227706134267756
Validation loss: 2.5805955809655194

Epoch: 6| Step: 13
Training loss: 3.031898822364489
Validation loss: 2.581968134986954

Epoch: 463| Step: 0
Training loss: 2.682017656175725
Validation loss: 2.60257439219486

Epoch: 6| Step: 1
Training loss: 2.8337178436864447
Validation loss: 2.6069165647669204

Epoch: 6| Step: 2
Training loss: 2.8362387925351507
Validation loss: 2.6286049235139823

Epoch: 6| Step: 3
Training loss: 2.820269555269475
Validation loss: 2.6264336026495534

Epoch: 6| Step: 4
Training loss: 2.937147728108581
Validation loss: 2.6376891281373065

Epoch: 6| Step: 5
Training loss: 2.7888833210126696
Validation loss: 2.6347074503232824

Epoch: 6| Step: 6
Training loss: 3.1648975918610343
Validation loss: 2.616334325326095

Epoch: 6| Step: 7
Training loss: 3.081840634948334
Validation loss: 2.6163514169634716

Epoch: 6| Step: 8
Training loss: 3.388934298421277
Validation loss: 2.6112185342076555

Epoch: 6| Step: 9
Training loss: 3.2972738738827334
Validation loss: 2.611597048521727

Epoch: 6| Step: 10
Training loss: 2.7317716576084363
Validation loss: 2.5977207365504387

Epoch: 6| Step: 11
Training loss: 2.6205946877835116
Validation loss: 2.595818018495685

Epoch: 6| Step: 12
Training loss: 2.9389513366865434
Validation loss: 2.6006475094312456

Epoch: 6| Step: 13
Training loss: 2.11220671293819
Validation loss: 2.5863016876665554

Epoch: 464| Step: 0
Training loss: 2.56756593465414
Validation loss: 2.590680429718719

Epoch: 6| Step: 1
Training loss: 2.6967925057994244
Validation loss: 2.6052467810152207

Epoch: 6| Step: 2
Training loss: 3.004994843743545
Validation loss: 2.6004600663720083

Epoch: 6| Step: 3
Training loss: 2.913592671418544
Validation loss: 2.6053962183926944

Epoch: 6| Step: 4
Training loss: 2.4677313139459875
Validation loss: 2.6201210474627934

Epoch: 6| Step: 5
Training loss: 2.9839528369397956
Validation loss: 2.6322730583981957

Epoch: 6| Step: 6
Training loss: 3.1835578027111624
Validation loss: 2.629526881723977

Epoch: 6| Step: 7
Training loss: 3.0584022978474423
Validation loss: 2.6222542007820264

Epoch: 6| Step: 8
Training loss: 2.545595186856441
Validation loss: 2.5994544835006184

Epoch: 6| Step: 9
Training loss: 2.9209908356331806
Validation loss: 2.5993255672091964

Epoch: 6| Step: 10
Training loss: 3.3212912160478907
Validation loss: 2.5806681976777086

Epoch: 6| Step: 11
Training loss: 2.50863852518872
Validation loss: 2.580125230537078

Epoch: 6| Step: 12
Training loss: 3.3456629334823225
Validation loss: 2.5775509013300666

Epoch: 6| Step: 13
Training loss: 2.9375357118424295
Validation loss: 2.584198742923349

Epoch: 465| Step: 0
Training loss: 3.2238598604626634
Validation loss: 2.5886661686699273

Epoch: 6| Step: 1
Training loss: 3.2390586370876626
Validation loss: 2.5955640831733047

Epoch: 6| Step: 2
Training loss: 3.2737949513032594
Validation loss: 2.612819055950915

Epoch: 6| Step: 3
Training loss: 2.665587316070045
Validation loss: 2.6238964650068297

Epoch: 6| Step: 4
Training loss: 2.8885781129137387
Validation loss: 2.63913477626591

Epoch: 6| Step: 5
Training loss: 2.3789651797657916
Validation loss: 2.6570020157644296

Epoch: 6| Step: 6
Training loss: 3.280227065716813
Validation loss: 2.664973703768854

Epoch: 6| Step: 7
Training loss: 3.047472303482137
Validation loss: 2.666018167469198

Epoch: 6| Step: 8
Training loss: 2.6403736243146656
Validation loss: 2.6782659714112116

Epoch: 6| Step: 9
Training loss: 2.5808937695178646
Validation loss: 2.6839439444336644

Epoch: 6| Step: 10
Training loss: 3.2660344063417646
Validation loss: 2.670107205045229

Epoch: 6| Step: 11
Training loss: 2.3261437914840233
Validation loss: 2.666681580604359

Epoch: 6| Step: 12
Training loss: 3.043223849023215
Validation loss: 2.6329810175399713

Epoch: 6| Step: 13
Training loss: 1.8876826823167745
Validation loss: 2.6159302068240207

Epoch: 466| Step: 0
Training loss: 2.8468158669721397
Validation loss: 2.5980810858727024

Epoch: 6| Step: 1
Training loss: 3.411712745711885
Validation loss: 2.5847251456000016

Epoch: 6| Step: 2
Training loss: 2.7174512018982946
Validation loss: 2.585313010340163

Epoch: 6| Step: 3
Training loss: 2.969845218414234
Validation loss: 2.583728633676201

Epoch: 6| Step: 4
Training loss: 2.538811022702671
Validation loss: 2.5876475487826993

Epoch: 6| Step: 5
Training loss: 3.055037144311833
Validation loss: 2.5988177781557003

Epoch: 6| Step: 6
Training loss: 2.75436895284558
Validation loss: 2.5898048314928315

Epoch: 6| Step: 7
Training loss: 3.0799963824758714
Validation loss: 2.5961212732752457

Epoch: 6| Step: 8
Training loss: 3.1643343584983317
Validation loss: 2.5992952234041877

Epoch: 6| Step: 9
Training loss: 2.3605568054384247
Validation loss: 2.5847921129562983

Epoch: 6| Step: 10
Training loss: 3.1921899736705726
Validation loss: 2.6015796906548956

Epoch: 6| Step: 11
Training loss: 2.156740326348221
Validation loss: 2.6044640280652627

Epoch: 6| Step: 12
Training loss: 2.9883342264503496
Validation loss: 2.601562063457385

Epoch: 6| Step: 13
Training loss: 2.8945864364572977
Validation loss: 2.6319612875050167

Epoch: 467| Step: 0
Training loss: 2.375986998410086
Validation loss: 2.648976582239971

Epoch: 6| Step: 1
Training loss: 3.061749736203721
Validation loss: 2.6661598678297143

Epoch: 6| Step: 2
Training loss: 2.9615208999692353
Validation loss: 2.6852385709364675

Epoch: 6| Step: 3
Training loss: 2.5223163204406633
Validation loss: 2.678276956234942

Epoch: 6| Step: 4
Training loss: 3.3173473087866845
Validation loss: 2.6789313927750587

Epoch: 6| Step: 5
Training loss: 2.8597645311857627
Validation loss: 2.7000081813814396

Epoch: 6| Step: 6
Training loss: 2.9626907351615213
Validation loss: 2.669970295179976

Epoch: 6| Step: 7
Training loss: 2.3328465453497773
Validation loss: 2.6522839571617056

Epoch: 6| Step: 8
Training loss: 2.692932139281438
Validation loss: 2.632752663795471

Epoch: 6| Step: 9
Training loss: 3.397600864600172
Validation loss: 2.619227991131043

Epoch: 6| Step: 10
Training loss: 3.158113439415345
Validation loss: 2.614424721571157

Epoch: 6| Step: 11
Training loss: 2.883416006707464
Validation loss: 2.606626135944243

Epoch: 6| Step: 12
Training loss: 2.943272539362741
Validation loss: 2.6096681377753312

Epoch: 6| Step: 13
Training loss: 2.620506709800068
Validation loss: 2.6053662089984106

Epoch: 468| Step: 0
Training loss: 3.1601665105287693
Validation loss: 2.601427781245955

Epoch: 6| Step: 1
Training loss: 3.1274564625052292
Validation loss: 2.615654583782522

Epoch: 6| Step: 2
Training loss: 2.798579202937581
Validation loss: 2.6320151597514103

Epoch: 6| Step: 3
Training loss: 2.8988166828389765
Validation loss: 2.645702934071636

Epoch: 6| Step: 4
Training loss: 2.9849044569817593
Validation loss: 2.7020425321433814

Epoch: 6| Step: 5
Training loss: 2.9041817801988508
Validation loss: 2.7171617658346663

Epoch: 6| Step: 6
Training loss: 3.076722885918691
Validation loss: 2.717232848153562

Epoch: 6| Step: 7
Training loss: 3.2288807075795316
Validation loss: 2.71785344404797

Epoch: 6| Step: 8
Training loss: 2.3762468779260955
Validation loss: 2.7047974524949847

Epoch: 6| Step: 9
Training loss: 2.6019510431514714
Validation loss: 2.680523805045746

Epoch: 6| Step: 10
Training loss: 2.4837052504141988
Validation loss: 2.6489574296993537

Epoch: 6| Step: 11
Training loss: 3.20184404765144
Validation loss: 2.6493919250710785

Epoch: 6| Step: 12
Training loss: 2.6632415311967503
Validation loss: 2.6602497010630772

Epoch: 6| Step: 13
Training loss: 3.304531373288185
Validation loss: 2.645500877938573

Epoch: 469| Step: 0
Training loss: 3.2128790487063483
Validation loss: 2.6512671285176936

Epoch: 6| Step: 1
Training loss: 2.9685868067810532
Validation loss: 2.6489210859453394

Epoch: 6| Step: 2
Training loss: 2.3455758675670024
Validation loss: 2.6492506603468473

Epoch: 6| Step: 3
Training loss: 3.0797557867754315
Validation loss: 2.6629926504678845

Epoch: 6| Step: 4
Training loss: 2.9367728449331616
Validation loss: 2.6539038424099535

Epoch: 6| Step: 5
Training loss: 3.4444783902973737
Validation loss: 2.626517499338963

Epoch: 6| Step: 6
Training loss: 2.405425091328998
Validation loss: 2.6190484361297033

Epoch: 6| Step: 7
Training loss: 2.777417231578915
Validation loss: 2.615689457979426

Epoch: 6| Step: 8
Training loss: 3.04330093862361
Validation loss: 2.60794187384722

Epoch: 6| Step: 9
Training loss: 2.515948920394001
Validation loss: 2.5893241700038936

Epoch: 6| Step: 10
Training loss: 2.2395584696491073
Validation loss: 2.595882564537328

Epoch: 6| Step: 11
Training loss: 2.9177801640657286
Validation loss: 2.594083218767209

Epoch: 6| Step: 12
Training loss: 3.15703973238003
Validation loss: 2.586839012723753

Epoch: 6| Step: 13
Training loss: 3.135748726295347
Validation loss: 2.585041674783823

Epoch: 470| Step: 0
Training loss: 3.206145262912991
Validation loss: 2.589080400589644

Epoch: 6| Step: 1
Training loss: 3.3775421740809266
Validation loss: 2.5924351998654256

Epoch: 6| Step: 2
Training loss: 2.9294273973079847
Validation loss: 2.601026410881718

Epoch: 6| Step: 3
Training loss: 2.8743411428734817
Validation loss: 2.625189640052865

Epoch: 6| Step: 4
Training loss: 2.7271999717891444
Validation loss: 2.6666618265087543

Epoch: 6| Step: 5
Training loss: 2.572709562998597
Validation loss: 2.6941047615102

Epoch: 6| Step: 6
Training loss: 3.4174381563608827
Validation loss: 2.717542529873461

Epoch: 6| Step: 7
Training loss: 3.06910165298575
Validation loss: 2.6898655840963115

Epoch: 6| Step: 8
Training loss: 2.835289410816966
Validation loss: 2.661072609250445

Epoch: 6| Step: 9
Training loss: 2.5736312079933055
Validation loss: 2.6275646769744183

Epoch: 6| Step: 10
Training loss: 3.035945755284228
Validation loss: 2.617441958487049

Epoch: 6| Step: 11
Training loss: 2.6126602415742526
Validation loss: 2.5811103756222327

Epoch: 6| Step: 12
Training loss: 2.5727686871639603
Validation loss: 2.5669544120470786

Epoch: 6| Step: 13
Training loss: 2.1294384772286805
Validation loss: 2.5700113759890924

Epoch: 471| Step: 0
Training loss: 2.5585128654915423
Validation loss: 2.5674293915848008

Epoch: 6| Step: 1
Training loss: 2.3302880805711874
Validation loss: 2.569473341565286

Epoch: 6| Step: 2
Training loss: 2.8179198706871573
Validation loss: 2.579312171696922

Epoch: 6| Step: 3
Training loss: 2.9178937419764504
Validation loss: 2.5753427577043304

Epoch: 6| Step: 4
Training loss: 3.275117502215808
Validation loss: 2.5756389814326517

Epoch: 6| Step: 5
Training loss: 3.8732999948805666
Validation loss: 2.5761739568230704

Epoch: 6| Step: 6
Training loss: 2.6999612275624583
Validation loss: 2.584712604711123

Epoch: 6| Step: 7
Training loss: 2.9857653829252895
Validation loss: 2.586565677561416

Epoch: 6| Step: 8
Training loss: 2.7098701420600606
Validation loss: 2.59420191849009

Epoch: 6| Step: 9
Training loss: 1.9117497387468456
Validation loss: 2.592146918604142

Epoch: 6| Step: 10
Training loss: 3.1020725705225023
Validation loss: 2.6083759971803264

Epoch: 6| Step: 11
Training loss: 3.237666275290931
Validation loss: 2.6231635702116605

Epoch: 6| Step: 12
Training loss: 2.8636289544167934
Validation loss: 2.6169181811276436

Epoch: 6| Step: 13
Training loss: 3.050121279947356
Validation loss: 2.610880593678867

Epoch: 472| Step: 0
Training loss: 3.361444447979985
Validation loss: 2.611077632295243

Epoch: 6| Step: 1
Training loss: 3.211059567992213
Validation loss: 2.621966163123693

Epoch: 6| Step: 2
Training loss: 2.8845355252680114
Validation loss: 2.621116245754525

Epoch: 6| Step: 3
Training loss: 2.756912992497127
Validation loss: 2.6232549430765015

Epoch: 6| Step: 4
Training loss: 2.987196302739181
Validation loss: 2.628441414716849

Epoch: 6| Step: 5
Training loss: 2.629048994023518
Validation loss: 2.6175374095458626

Epoch: 6| Step: 6
Training loss: 2.9608267005984263
Validation loss: 2.6096664697229355

Epoch: 6| Step: 7
Training loss: 2.837024827065277
Validation loss: 2.6155954243904547

Epoch: 6| Step: 8
Training loss: 2.7248320676521547
Validation loss: 2.623305086561095

Epoch: 6| Step: 9
Training loss: 3.1381802129304375
Validation loss: 2.632051730613873

Epoch: 6| Step: 10
Training loss: 2.6000045372850003
Validation loss: 2.668485932920329

Epoch: 6| Step: 11
Training loss: 2.312044047176962
Validation loss: 2.6546497579585244

Epoch: 6| Step: 12
Training loss: 2.86235283219276
Validation loss: 2.66102882973112

Epoch: 6| Step: 13
Training loss: 3.126879317718886
Validation loss: 2.642837507197391

Epoch: 473| Step: 0
Training loss: 2.7184876063213266
Validation loss: 2.6405395826026723

Epoch: 6| Step: 1
Training loss: 3.0239574369735167
Validation loss: 2.6335539432432116

Epoch: 6| Step: 2
Training loss: 3.1460280368668747
Validation loss: 2.635344437240014

Epoch: 6| Step: 3
Training loss: 2.2681867126159068
Validation loss: 2.627494382786998

Epoch: 6| Step: 4
Training loss: 3.2931988365364964
Validation loss: 2.6507809183142954

Epoch: 6| Step: 5
Training loss: 2.8354252964834883
Validation loss: 2.6558556647033233

Epoch: 6| Step: 6
Training loss: 2.9776375498737195
Validation loss: 2.6407301036550406

Epoch: 6| Step: 7
Training loss: 3.012372887173325
Validation loss: 2.656392121056808

Epoch: 6| Step: 8
Training loss: 3.106165470684782
Validation loss: 2.622614074581206

Epoch: 6| Step: 9
Training loss: 3.0091318382825993
Validation loss: 2.6364798061037567

Epoch: 6| Step: 10
Training loss: 2.31797410676991
Validation loss: 2.6129163222425915

Epoch: 6| Step: 11
Training loss: 2.0840415767981315
Validation loss: 2.614773426238785

Epoch: 6| Step: 12
Training loss: 2.7859613183287597
Validation loss: 2.6013666407065577

Epoch: 6| Step: 13
Training loss: 3.3561446871298184
Validation loss: 2.5938659614371753

Epoch: 474| Step: 0
Training loss: 2.979473142709946
Validation loss: 2.5781436157548856

Epoch: 6| Step: 1
Training loss: 3.315779879563298
Validation loss: 2.576784768872741

Epoch: 6| Step: 2
Training loss: 2.1353027561478486
Validation loss: 2.5793826200779866

Epoch: 6| Step: 3
Training loss: 3.221993599012139
Validation loss: 2.576105326429915

Epoch: 6| Step: 4
Training loss: 2.5807306242835084
Validation loss: 2.5815578532657164

Epoch: 6| Step: 5
Training loss: 2.752531273826169
Validation loss: 2.599591768958226

Epoch: 6| Step: 6
Training loss: 2.728196493394012
Validation loss: 2.608233165603137

Epoch: 6| Step: 7
Training loss: 2.504334602077729
Validation loss: 2.6139405333081633

Epoch: 6| Step: 8
Training loss: 3.276002448028656
Validation loss: 2.641426033373732

Epoch: 6| Step: 9
Training loss: 2.9566888850372526
Validation loss: 2.6673822939249874

Epoch: 6| Step: 10
Training loss: 2.57284096878038
Validation loss: 2.6750958189863456

Epoch: 6| Step: 11
Training loss: 2.9929352864242063
Validation loss: 2.669861185303607

Epoch: 6| Step: 12
Training loss: 2.984763554548752
Validation loss: 2.667242184826351

Epoch: 6| Step: 13
Training loss: 3.5934847526518747
Validation loss: 2.628399575928536

Epoch: 475| Step: 0
Training loss: 3.050366401551758
Validation loss: 2.6076677492282587

Epoch: 6| Step: 1
Training loss: 2.7576005978534117
Validation loss: 2.5761111520982825

Epoch: 6| Step: 2
Training loss: 2.950260771524293
Validation loss: 2.5812359498305613

Epoch: 6| Step: 3
Training loss: 3.0615955496391605
Validation loss: 2.5721570499853894

Epoch: 6| Step: 4
Training loss: 2.330902081829197
Validation loss: 2.5669601206617347

Epoch: 6| Step: 5
Training loss: 2.9397976594181294
Validation loss: 2.567038633798118

Epoch: 6| Step: 6
Training loss: 2.9493383926476975
Validation loss: 2.577483305214158

Epoch: 6| Step: 7
Training loss: 2.4239247169890343
Validation loss: 2.5865711644893636

Epoch: 6| Step: 8
Training loss: 3.3177871255586098
Validation loss: 2.6027575549766575

Epoch: 6| Step: 9
Training loss: 2.978648978828272
Validation loss: 2.6114304976735787

Epoch: 6| Step: 10
Training loss: 2.752074846076055
Validation loss: 2.619274596171497

Epoch: 6| Step: 11
Training loss: 2.7686482085725572
Validation loss: 2.6452322223691085

Epoch: 6| Step: 12
Training loss: 2.9353103593176613
Validation loss: 2.6607871040673516

Epoch: 6| Step: 13
Training loss: 2.9163779706220003
Validation loss: 2.677576344222015

Epoch: 476| Step: 0
Training loss: 3.1492090534050514
Validation loss: 2.6689322298523828

Epoch: 6| Step: 1
Training loss: 2.229898837579001
Validation loss: 2.6563493588206444

Epoch: 6| Step: 2
Training loss: 2.8257599947686054
Validation loss: 2.6344394320612903

Epoch: 6| Step: 3
Training loss: 2.6368846699821487
Validation loss: 2.6001758791641962

Epoch: 6| Step: 4
Training loss: 2.9681437626284013
Validation loss: 2.598015243565632

Epoch: 6| Step: 5
Training loss: 3.0626592789315765
Validation loss: 2.5947681103665263

Epoch: 6| Step: 6
Training loss: 2.6874823458779256
Validation loss: 2.5849734117287757

Epoch: 6| Step: 7
Training loss: 2.8083643706858266
Validation loss: 2.5810066781636753

Epoch: 6| Step: 8
Training loss: 2.735557867058319
Validation loss: 2.576607248895541

Epoch: 6| Step: 9
Training loss: 3.177006521495049
Validation loss: 2.578804828882337

Epoch: 6| Step: 10
Training loss: 3.352012764089313
Validation loss: 2.5837895704676783

Epoch: 6| Step: 11
Training loss: 2.982217857912259
Validation loss: 2.5837005237836452

Epoch: 6| Step: 12
Training loss: 2.6709393206994423
Validation loss: 2.5946807713407214

Epoch: 6| Step: 13
Training loss: 3.060310203686163
Validation loss: 2.6082120468602183

Epoch: 477| Step: 0
Training loss: 2.770107967875354
Validation loss: 2.614580824518677

Epoch: 6| Step: 1
Training loss: 3.2096736304721
Validation loss: 2.6398833256843455

Epoch: 6| Step: 2
Training loss: 3.081039675329909
Validation loss: 2.6578198990357706

Epoch: 6| Step: 3
Training loss: 3.177385176197932
Validation loss: 2.670454306612484

Epoch: 6| Step: 4
Training loss: 3.0486324621412124
Validation loss: 2.6647347329352913

Epoch: 6| Step: 5
Training loss: 2.7632472274795354
Validation loss: 2.6522247062047226

Epoch: 6| Step: 6
Training loss: 2.498404184277952
Validation loss: 2.652944302280096

Epoch: 6| Step: 7
Training loss: 2.7273484111168007
Validation loss: 2.652455727096766

Epoch: 6| Step: 8
Training loss: 2.5488795717389294
Validation loss: 2.655893375939898

Epoch: 6| Step: 9
Training loss: 3.0069601064914795
Validation loss: 2.6560388026282378

Epoch: 6| Step: 10
Training loss: 2.2148194219205113
Validation loss: 2.6387781979917277

Epoch: 6| Step: 11
Training loss: 3.0894539028913863
Validation loss: 2.6599411866564187

Epoch: 6| Step: 12
Training loss: 2.564635061883244
Validation loss: 2.648722959053447

Epoch: 6| Step: 13
Training loss: 3.526166379329937
Validation loss: 2.6545141852003478

Epoch: 478| Step: 0
Training loss: 2.726014352694907
Validation loss: 2.6558789278156794

Epoch: 6| Step: 1
Training loss: 2.8248413581527845
Validation loss: 2.6306968716915904

Epoch: 6| Step: 2
Training loss: 2.5077573585984134
Validation loss: 2.641033832444036

Epoch: 6| Step: 3
Training loss: 3.0352272604708
Validation loss: 2.6382149901450203

Epoch: 6| Step: 4
Training loss: 3.15471891526427
Validation loss: 2.631281770966397

Epoch: 6| Step: 5
Training loss: 3.074963800480841
Validation loss: 2.6300723987510057

Epoch: 6| Step: 6
Training loss: 3.002232197960576
Validation loss: 2.6123541883766572

Epoch: 6| Step: 7
Training loss: 2.4127290369920997
Validation loss: 2.6170999002038013

Epoch: 6| Step: 8
Training loss: 2.949101042766968
Validation loss: 2.60354741828852

Epoch: 6| Step: 9
Training loss: 2.8071177375055036
Validation loss: 2.6029543467069445

Epoch: 6| Step: 10
Training loss: 2.2090763305628283
Validation loss: 2.603201789207405

Epoch: 6| Step: 11
Training loss: 3.2299532680851084
Validation loss: 2.59634192024218

Epoch: 6| Step: 12
Training loss: 3.3390047146014723
Validation loss: 2.60616907786109

Epoch: 6| Step: 13
Training loss: 2.3823009504685833
Validation loss: 2.60567704993589

Epoch: 479| Step: 0
Training loss: 2.5032798233442466
Validation loss: 2.611942018181292

Epoch: 6| Step: 1
Training loss: 3.2953484784220137
Validation loss: 2.6199488484526725

Epoch: 6| Step: 2
Training loss: 2.8921639959286027
Validation loss: 2.6375645951381617

Epoch: 6| Step: 3
Training loss: 3.3612980505990446
Validation loss: 2.6453920544970555

Epoch: 6| Step: 4
Training loss: 2.8990292009433714
Validation loss: 2.653859855758333

Epoch: 6| Step: 5
Training loss: 2.883461152993949
Validation loss: 2.6564125373232175

Epoch: 6| Step: 6
Training loss: 2.96058125227435
Validation loss: 2.6463953483400346

Epoch: 6| Step: 7
Training loss: 3.0105657485601953
Validation loss: 2.6404567062224147

Epoch: 6| Step: 8
Training loss: 2.476980276399643
Validation loss: 2.6298449758850153

Epoch: 6| Step: 9
Training loss: 2.6728128493839654
Validation loss: 2.6303227111710754

Epoch: 6| Step: 10
Training loss: 2.9607049453117344
Validation loss: 2.643065348519984

Epoch: 6| Step: 11
Training loss: 2.3651654259407375
Validation loss: 2.654972769707275

Epoch: 6| Step: 12
Training loss: 2.515491079236907
Validation loss: 2.652954494226388

Epoch: 6| Step: 13
Training loss: 3.147841782923631
Validation loss: 2.6480896230318005

Epoch: 480| Step: 0
Training loss: 3.1255994603258364
Validation loss: 2.639957173389465

Epoch: 6| Step: 1
Training loss: 2.7306157019368027
Validation loss: 2.6353063288307443

Epoch: 6| Step: 2
Training loss: 3.1670497026846456
Validation loss: 2.637507485295156

Epoch: 6| Step: 3
Training loss: 2.526984305667787
Validation loss: 2.6459680742082927

Epoch: 6| Step: 4
Training loss: 2.5530935558684664
Validation loss: 2.6333974404694507

Epoch: 6| Step: 5
Training loss: 2.498249871876863
Validation loss: 2.636700753925731

Epoch: 6| Step: 6
Training loss: 2.8184350863390453
Validation loss: 2.6445831285499537

Epoch: 6| Step: 7
Training loss: 2.658661051034816
Validation loss: 2.6559463057128854

Epoch: 6| Step: 8
Training loss: 2.526020440605622
Validation loss: 2.647805149115041

Epoch: 6| Step: 9
Training loss: 3.216917831286953
Validation loss: 2.655845088124653

Epoch: 6| Step: 10
Training loss: 2.669712195154387
Validation loss: 2.6693408296393013

Epoch: 6| Step: 11
Training loss: 3.362252923332655
Validation loss: 2.6731911122173875

Epoch: 6| Step: 12
Training loss: 2.9987189418747464
Validation loss: 2.6910781020920864

Epoch: 6| Step: 13
Training loss: 2.688153475779328
Validation loss: 2.6746847973484478

Epoch: 481| Step: 0
Training loss: 2.23260128872226
Validation loss: 2.6604899222357212

Epoch: 6| Step: 1
Training loss: 2.790922340878976
Validation loss: 2.6780463468433156

Epoch: 6| Step: 2
Training loss: 2.890433145290688
Validation loss: 2.676273397873981

Epoch: 6| Step: 3
Training loss: 2.417910179205297
Validation loss: 2.6675214557507734

Epoch: 6| Step: 4
Training loss: 3.0114416645599915
Validation loss: 2.6840942659281857

Epoch: 6| Step: 5
Training loss: 3.3455463468448197
Validation loss: 2.6887626438674337

Epoch: 6| Step: 6
Training loss: 2.83383361289202
Validation loss: 2.654140827451577

Epoch: 6| Step: 7
Training loss: 2.6206092443522504
Validation loss: 2.648370629002196

Epoch: 6| Step: 8
Training loss: 2.390741283106866
Validation loss: 2.625578094440024

Epoch: 6| Step: 9
Training loss: 3.3130904337258738
Validation loss: 2.638123278331416

Epoch: 6| Step: 10
Training loss: 2.8071011754071438
Validation loss: 2.625961663726232

Epoch: 6| Step: 11
Training loss: 2.605470580138975
Validation loss: 2.6524031481106505

Epoch: 6| Step: 12
Training loss: 3.21026663721552
Validation loss: 2.647475324078814

Epoch: 6| Step: 13
Training loss: 3.375929245356502
Validation loss: 2.644396805601999

Epoch: 482| Step: 0
Training loss: 2.2337169611899177
Validation loss: 2.63603987388461

Epoch: 6| Step: 1
Training loss: 2.419054320754847
Validation loss: 2.61915533647069

Epoch: 6| Step: 2
Training loss: 2.1256143018615394
Validation loss: 2.618344280299174

Epoch: 6| Step: 3
Training loss: 3.233254648673523
Validation loss: 2.6203737682317585

Epoch: 6| Step: 4
Training loss: 3.1025032519278133
Validation loss: 2.605679363990925

Epoch: 6| Step: 5
Training loss: 2.661823125774001
Validation loss: 2.6304617089734235

Epoch: 6| Step: 6
Training loss: 2.97375516091693
Validation loss: 2.63067225447712

Epoch: 6| Step: 7
Training loss: 2.9158200443034406
Validation loss: 2.6502359440201175

Epoch: 6| Step: 8
Training loss: 3.3256970356160043
Validation loss: 2.7039226261140574

Epoch: 6| Step: 9
Training loss: 3.050770934181503
Validation loss: 2.734917291872906

Epoch: 6| Step: 10
Training loss: 2.9458010645227155
Validation loss: 2.7138947728784246

Epoch: 6| Step: 11
Training loss: 3.0363892710418163
Validation loss: 2.7282721941686567

Epoch: 6| Step: 12
Training loss: 3.0465946948887566
Validation loss: 2.689895746809429

Epoch: 6| Step: 13
Training loss: 2.539118276130165
Validation loss: 2.653781171591123

Epoch: 483| Step: 0
Training loss: 2.6402507268447533
Validation loss: 2.6323739260390475

Epoch: 6| Step: 1
Training loss: 2.932474260534317
Validation loss: 2.6072329484803265

Epoch: 6| Step: 2
Training loss: 2.5283397380602723
Validation loss: 2.602476999439031

Epoch: 6| Step: 3
Training loss: 3.2460012044005353
Validation loss: 2.5888262143535807

Epoch: 6| Step: 4
Training loss: 2.6908702565772162
Validation loss: 2.6056719259495704

Epoch: 6| Step: 5
Training loss: 3.0254878698965415
Validation loss: 2.607926084645417

Epoch: 6| Step: 6
Training loss: 2.2372936047030167
Validation loss: 2.6108611881885166

Epoch: 6| Step: 7
Training loss: 2.8188850827212915
Validation loss: 2.6073617736912276

Epoch: 6| Step: 8
Training loss: 2.8622522105284163
Validation loss: 2.605328370573804

Epoch: 6| Step: 9
Training loss: 2.4541106946830684
Validation loss: 2.6190333295820403

Epoch: 6| Step: 10
Training loss: 3.2467414953341165
Validation loss: 2.6229370769557705

Epoch: 6| Step: 11
Training loss: 2.879487557385801
Validation loss: 2.614546639554654

Epoch: 6| Step: 12
Training loss: 3.531609305947638
Validation loss: 2.6203426976329833

Epoch: 6| Step: 13
Training loss: 2.7909174715672562
Validation loss: 2.6211907679196984

Epoch: 484| Step: 0
Training loss: 2.271809312796947
Validation loss: 2.6128323155570716

Epoch: 6| Step: 1
Training loss: 1.9200951002331132
Validation loss: 2.6090395198858114

Epoch: 6| Step: 2
Training loss: 3.0231315201678575
Validation loss: 2.6254587841946413

Epoch: 6| Step: 3
Training loss: 3.1483975164179503
Validation loss: 2.6252798838519498

Epoch: 6| Step: 4
Training loss: 3.2383267499536443
Validation loss: 2.612247484708091

Epoch: 6| Step: 5
Training loss: 3.2627594709439394
Validation loss: 2.6277545065703105

Epoch: 6| Step: 6
Training loss: 3.398790363101557
Validation loss: 2.6077457023028523

Epoch: 6| Step: 7
Training loss: 2.286252220323756
Validation loss: 2.6167990716913905

Epoch: 6| Step: 8
Training loss: 2.8313819298732024
Validation loss: 2.617366557760245

Epoch: 6| Step: 9
Training loss: 2.5944633881637205
Validation loss: 2.631672817460132

Epoch: 6| Step: 10
Training loss: 2.846695600566586
Validation loss: 2.6344986081417434

Epoch: 6| Step: 11
Training loss: 2.7113952250298547
Validation loss: 2.6288372262885926

Epoch: 6| Step: 12
Training loss: 3.007634145229485
Validation loss: 2.639672408681146

Epoch: 6| Step: 13
Training loss: 2.9339071175006706
Validation loss: 2.655049158158046

Epoch: 485| Step: 0
Training loss: 2.865135352380997
Validation loss: 2.6635149913174923

Epoch: 6| Step: 1
Training loss: 2.6175110574250087
Validation loss: 2.663756675392905

Epoch: 6| Step: 2
Training loss: 2.9197686911114595
Validation loss: 2.6409534148909968

Epoch: 6| Step: 3
Training loss: 2.652810506524469
Validation loss: 2.6283694468287457

Epoch: 6| Step: 4
Training loss: 2.6477696299653224
Validation loss: 2.6300670230463066

Epoch: 6| Step: 5
Training loss: 2.8742920377055596
Validation loss: 2.618943698674091

Epoch: 6| Step: 6
Training loss: 3.341192533068064
Validation loss: 2.6278619053926437

Epoch: 6| Step: 7
Training loss: 2.4827107547296747
Validation loss: 2.6223012017488325

Epoch: 6| Step: 8
Training loss: 2.496542924514636
Validation loss: 2.6361282077447283

Epoch: 6| Step: 9
Training loss: 2.9348879624774304
Validation loss: 2.6483988152726425

Epoch: 6| Step: 10
Training loss: 3.2827286068175154
Validation loss: 2.6719607915311645

Epoch: 6| Step: 11
Training loss: 2.9912936715725262
Validation loss: 2.6771722016479846

Epoch: 6| Step: 12
Training loss: 2.823345803912957
Validation loss: 2.6781573966976837

Epoch: 6| Step: 13
Training loss: 2.9483786895983752
Validation loss: 2.6567732351731346

Epoch: 486| Step: 0
Training loss: 3.329314829585371
Validation loss: 2.625634889641033

Epoch: 6| Step: 1
Training loss: 2.729422045302906
Validation loss: 2.6015432437695387

Epoch: 6| Step: 2
Training loss: 2.6919369997812015
Validation loss: 2.5970321785205432

Epoch: 6| Step: 3
Training loss: 3.281985100646665
Validation loss: 2.577497877488088

Epoch: 6| Step: 4
Training loss: 3.071411246824355
Validation loss: 2.573921982597114

Epoch: 6| Step: 5
Training loss: 2.8696577775926606
Validation loss: 2.573921769202911

Epoch: 6| Step: 6
Training loss: 2.4842802785414237
Validation loss: 2.569497942476113

Epoch: 6| Step: 7
Training loss: 2.680662105816681
Validation loss: 2.574003120663139

Epoch: 6| Step: 8
Training loss: 2.965892339942795
Validation loss: 2.5761454898365885

Epoch: 6| Step: 9
Training loss: 3.101091401958475
Validation loss: 2.5840229982149965

Epoch: 6| Step: 10
Training loss: 2.9294321177753564
Validation loss: 2.5875407387675753

Epoch: 6| Step: 11
Training loss: 2.5169785927311916
Validation loss: 2.5876663466830396

Epoch: 6| Step: 12
Training loss: 2.4112547314064985
Validation loss: 2.5849980555422105

Epoch: 6| Step: 13
Training loss: 3.0960162560975064
Validation loss: 2.583220492970603

Epoch: 487| Step: 0
Training loss: 3.0555448377787338
Validation loss: 2.5877377921211586

Epoch: 6| Step: 1
Training loss: 2.7119214473702113
Validation loss: 2.5881654684679223

Epoch: 6| Step: 2
Training loss: 2.870464229986133
Validation loss: 2.591819488537769

Epoch: 6| Step: 3
Training loss: 2.556722221500376
Validation loss: 2.5790065209195916

Epoch: 6| Step: 4
Training loss: 3.103801390045384
Validation loss: 2.5848133318010795

Epoch: 6| Step: 5
Training loss: 2.1526974146893485
Validation loss: 2.5910685190031986

Epoch: 6| Step: 6
Training loss: 2.8916742843249095
Validation loss: 2.588448642866587

Epoch: 6| Step: 7
Training loss: 2.8088469623284893
Validation loss: 2.598076524151697

Epoch: 6| Step: 8
Training loss: 2.855710542515946
Validation loss: 2.604151405207717

Epoch: 6| Step: 9
Training loss: 2.9605070017580597
Validation loss: 2.5943211048927157

Epoch: 6| Step: 10
Training loss: 2.9235006287862624
Validation loss: 2.6089265548668146

Epoch: 6| Step: 11
Training loss: 2.8001939910717395
Validation loss: 2.6120763045830917

Epoch: 6| Step: 12
Training loss: 3.2439552727284022
Validation loss: 2.633142379991144

Epoch: 6| Step: 13
Training loss: 3.218316799011376
Validation loss: 2.6106045445472446

Epoch: 488| Step: 0
Training loss: 3.2406644989814195
Validation loss: 2.6104975012624747

Epoch: 6| Step: 1
Training loss: 2.882345683854619
Validation loss: 2.5780968677903786

Epoch: 6| Step: 2
Training loss: 3.447553048835671
Validation loss: 2.5872827430078558

Epoch: 6| Step: 3
Training loss: 3.3059316326810113
Validation loss: 2.582728257671553

Epoch: 6| Step: 4
Training loss: 2.6044504443364622
Validation loss: 2.579649616687087

Epoch: 6| Step: 5
Training loss: 2.4648333033901046
Validation loss: 2.581288249344139

Epoch: 6| Step: 6
Training loss: 2.654102130227053
Validation loss: 2.5984194242425516

Epoch: 6| Step: 7
Training loss: 2.4907499849173385
Validation loss: 2.590122438362804

Epoch: 6| Step: 8
Training loss: 2.3423776296206626
Validation loss: 2.5977513938205936

Epoch: 6| Step: 9
Training loss: 2.7462678205687188
Validation loss: 2.6104752370983966

Epoch: 6| Step: 10
Training loss: 2.7193415206570206
Validation loss: 2.629128996600957

Epoch: 6| Step: 11
Training loss: 3.080358014787823
Validation loss: 2.6436478739882125

Epoch: 6| Step: 12
Training loss: 2.794662026322616
Validation loss: 2.632422653162167

Epoch: 6| Step: 13
Training loss: 2.910499337473317
Validation loss: 2.6251582094596095

Epoch: 489| Step: 0
Training loss: 2.6322879438495965
Validation loss: 2.6069799391820547

Epoch: 6| Step: 1
Training loss: 2.807773433152416
Validation loss: 2.5989846292688985

Epoch: 6| Step: 2
Training loss: 2.2780302135282486
Validation loss: 2.5774646419208023

Epoch: 6| Step: 3
Training loss: 3.4178194721866175
Validation loss: 2.567428199845772

Epoch: 6| Step: 4
Training loss: 2.6678273734618374
Validation loss: 2.5754680377835224

Epoch: 6| Step: 5
Training loss: 3.091262279567863
Validation loss: 2.580745116632251

Epoch: 6| Step: 6
Training loss: 3.0638617777112467
Validation loss: 2.5742922068493685

Epoch: 6| Step: 7
Training loss: 2.088699398283918
Validation loss: 2.577422409305305

Epoch: 6| Step: 8
Training loss: 3.131594147491346
Validation loss: 2.5843165514969786

Epoch: 6| Step: 9
Training loss: 2.6492050994008385
Validation loss: 2.591591812976843

Epoch: 6| Step: 10
Training loss: 3.2535687439853453
Validation loss: 2.586691338771701

Epoch: 6| Step: 11
Training loss: 2.7742425314362804
Validation loss: 2.6095465233512933

Epoch: 6| Step: 12
Training loss: 2.812710732936342
Validation loss: 2.622207638922054

Epoch: 6| Step: 13
Training loss: 2.777972572702088
Validation loss: 2.647585025344549

Epoch: 490| Step: 0
Training loss: 3.181254982335474
Validation loss: 2.6497766011687305

Epoch: 6| Step: 1
Training loss: 3.220094862778575
Validation loss: 2.659623419560109

Epoch: 6| Step: 2
Training loss: 2.6470920442229393
Validation loss: 2.6489132805817532

Epoch: 6| Step: 3
Training loss: 3.2566987473447755
Validation loss: 2.6626001456571955

Epoch: 6| Step: 4
Training loss: 3.110795353200237
Validation loss: 2.670136285197739

Epoch: 6| Step: 5
Training loss: 3.03781784969126
Validation loss: 2.674763447412396

Epoch: 6| Step: 6
Training loss: 2.278646472749166
Validation loss: 2.6644942233604847

Epoch: 6| Step: 7
Training loss: 2.7605335330816154
Validation loss: 2.6545412970223285

Epoch: 6| Step: 8
Training loss: 2.578558498119183
Validation loss: 2.6939276039677744

Epoch: 6| Step: 9
Training loss: 2.4006297874651232
Validation loss: 2.6827966151255547

Epoch: 6| Step: 10
Training loss: 2.547900596021083
Validation loss: 2.681904910756475

Epoch: 6| Step: 11
Training loss: 3.001710404143244
Validation loss: 2.699230131560974

Epoch: 6| Step: 12
Training loss: 2.935026710297733
Validation loss: 2.6734582191848166

Epoch: 6| Step: 13
Training loss: 2.234202985211052
Validation loss: 2.678696881377604

Epoch: 491| Step: 0
Training loss: 2.9224334020017877
Validation loss: 2.655467482365612

Epoch: 6| Step: 1
Training loss: 2.7762974566955534
Validation loss: 2.636571668429231

Epoch: 6| Step: 2
Training loss: 2.458144670995029
Validation loss: 2.6531042824271136

Epoch: 6| Step: 3
Training loss: 2.5893323114270683
Validation loss: 2.6204821484954994

Epoch: 6| Step: 4
Training loss: 3.312765146835921
Validation loss: 2.6111387722470516

Epoch: 6| Step: 5
Training loss: 2.6340008778842168
Validation loss: 2.607902397714391

Epoch: 6| Step: 6
Training loss: 3.03815907678757
Validation loss: 2.585273011171062

Epoch: 6| Step: 7
Training loss: 2.3964840765395596
Validation loss: 2.585177136383819

Epoch: 6| Step: 8
Training loss: 2.7823695811839246
Validation loss: 2.5880573930831106

Epoch: 6| Step: 9
Training loss: 2.858753240972966
Validation loss: 2.5874474715749116

Epoch: 6| Step: 10
Training loss: 3.2891967456087574
Validation loss: 2.581783149774578

Epoch: 6| Step: 11
Training loss: 2.7875474934316737
Validation loss: 2.600534298167962

Epoch: 6| Step: 12
Training loss: 2.776964808283993
Validation loss: 2.6093301457895

Epoch: 6| Step: 13
Training loss: 3.1240512170537316
Validation loss: 2.639454989618455

Epoch: 492| Step: 0
Training loss: 3.2855121360813584
Validation loss: 2.643798416374311

Epoch: 6| Step: 1
Training loss: 2.673579692793589
Validation loss: 2.6703688266943186

Epoch: 6| Step: 2
Training loss: 2.8131802901754694
Validation loss: 2.647269613842365

Epoch: 6| Step: 3
Training loss: 3.130023123561281
Validation loss: 2.6587654368857185

Epoch: 6| Step: 4
Training loss: 2.997792703496966
Validation loss: 2.6603588505161015

Epoch: 6| Step: 5
Training loss: 2.611780120375044
Validation loss: 2.6656767019594474

Epoch: 6| Step: 6
Training loss: 2.3525147395224564
Validation loss: 2.6758043303009624

Epoch: 6| Step: 7
Training loss: 2.3888776788768884
Validation loss: 2.6857339083667275

Epoch: 6| Step: 8
Training loss: 3.1354696748800306
Validation loss: 2.7069413895378607

Epoch: 6| Step: 9
Training loss: 3.021113485740909
Validation loss: 2.684137172583604

Epoch: 6| Step: 10
Training loss: 2.8650694463545
Validation loss: 2.6827392784476083

Epoch: 6| Step: 11
Training loss: 2.5061476460625274
Validation loss: 2.663913333739076

Epoch: 6| Step: 12
Training loss: 2.8140424101778025
Validation loss: 2.666596902683308

Epoch: 6| Step: 13
Training loss: 3.1466245519384444
Validation loss: 2.6534333208226055

Epoch: 493| Step: 0
Training loss: 2.729253102649429
Validation loss: 2.6454549277728647

Epoch: 6| Step: 1
Training loss: 2.998488681310677
Validation loss: 2.6279112341917727

Epoch: 6| Step: 2
Training loss: 3.0086890590630957
Validation loss: 2.62288210388143

Epoch: 6| Step: 3
Training loss: 3.299049853320253
Validation loss: 2.61590236750061

Epoch: 6| Step: 4
Training loss: 2.9131080352937424
Validation loss: 2.628019544557514

Epoch: 6| Step: 5
Training loss: 2.4414955061809267
Validation loss: 2.6251717563502344

Epoch: 6| Step: 6
Training loss: 2.717482698976809
Validation loss: 2.632647765553628

Epoch: 6| Step: 7
Training loss: 2.8066153103742675
Validation loss: 2.642336850761967

Epoch: 6| Step: 8
Training loss: 3.754921925592776
Validation loss: 2.631271707469947

Epoch: 6| Step: 9
Training loss: 2.821937578928942
Validation loss: 2.635316496574789

Epoch: 6| Step: 10
Training loss: 2.30941731952302
Validation loss: 2.6449412049048533

Epoch: 6| Step: 11
Training loss: 2.5757729638671885
Validation loss: 2.6709365698328136

Epoch: 6| Step: 12
Training loss: 2.4434609517817303
Validation loss: 2.68791663299851

Epoch: 6| Step: 13
Training loss: 2.72719000560846
Validation loss: 2.656729993696011

Epoch: 494| Step: 0
Training loss: 2.7533664904884754
Validation loss: 2.644631665617029

Epoch: 6| Step: 1
Training loss: 2.9387756175194717
Validation loss: 2.6657983733984754

Epoch: 6| Step: 2
Training loss: 2.936184527697208
Validation loss: 2.6267555751430525

Epoch: 6| Step: 3
Training loss: 2.8308817036557308
Validation loss: 2.6190582754541336

Epoch: 6| Step: 4
Training loss: 3.2662700399316162
Validation loss: 2.624713620347995

Epoch: 6| Step: 5
Training loss: 3.1023360279902636
Validation loss: 2.6176949349659244

Epoch: 6| Step: 6
Training loss: 3.115969312308615
Validation loss: 2.610209218139891

Epoch: 6| Step: 7
Training loss: 2.7007984005243078
Validation loss: 2.590474360930712

Epoch: 6| Step: 8
Training loss: 2.717564730044383
Validation loss: 2.58333965311326

Epoch: 6| Step: 9
Training loss: 2.362505925892659
Validation loss: 2.5839528648547314

Epoch: 6| Step: 10
Training loss: 2.8064985033551535
Validation loss: 2.581995482334556

Epoch: 6| Step: 11
Training loss: 2.267501685195515
Validation loss: 2.579897075456076

Epoch: 6| Step: 12
Training loss: 2.883597745145905
Validation loss: 2.5741316892524697

Epoch: 6| Step: 13
Training loss: 3.020993528832049
Validation loss: 2.5715008219858864

Epoch: 495| Step: 0
Training loss: 3.1385506379237413
Validation loss: 2.5648428308711817

Epoch: 6| Step: 1
Training loss: 2.9612304220522576
Validation loss: 2.5721180113744233

Epoch: 6| Step: 2
Training loss: 3.0697940456630124
Validation loss: 2.580299002766064

Epoch: 6| Step: 3
Training loss: 2.738980496490665
Validation loss: 2.605031149499657

Epoch: 6| Step: 4
Training loss: 2.016946049193296
Validation loss: 2.6091278285287087

Epoch: 6| Step: 5
Training loss: 3.1076735245368714
Validation loss: 2.622880014170324

Epoch: 6| Step: 6
Training loss: 3.184505776667076
Validation loss: 2.6587455738343833

Epoch: 6| Step: 7
Training loss: 2.780697799899157
Validation loss: 2.6718751842223103

Epoch: 6| Step: 8
Training loss: 2.8888790321997053
Validation loss: 2.6826655008596108

Epoch: 6| Step: 9
Training loss: 2.106650960095117
Validation loss: 2.703391193914088

Epoch: 6| Step: 10
Training loss: 2.9718685434874987
Validation loss: 2.680859038926452

Epoch: 6| Step: 11
Training loss: 3.144105870636204
Validation loss: 2.63166016128988

Epoch: 6| Step: 12
Training loss: 2.5792109196512207
Validation loss: 2.614476887663389

Epoch: 6| Step: 13
Training loss: 3.4182753768712115
Validation loss: 2.5854829024852206

Epoch: 496| Step: 0
Training loss: 2.867669421032556
Validation loss: 2.584805395334795

Epoch: 6| Step: 1
Training loss: 2.812214137490696
Validation loss: 2.586356935711518

Epoch: 6| Step: 2
Training loss: 2.4322729552459363
Validation loss: 2.5906010358893927

Epoch: 6| Step: 3
Training loss: 2.2109275790689518
Validation loss: 2.5811396410282406

Epoch: 6| Step: 4
Training loss: 3.413882043464515
Validation loss: 2.5813268960165097

Epoch: 6| Step: 5
Training loss: 2.4580475808140694
Validation loss: 2.5933004771309003

Epoch: 6| Step: 6
Training loss: 2.609312136686632
Validation loss: 2.599424638262407

Epoch: 6| Step: 7
Training loss: 2.5196468829448873
Validation loss: 2.607589355340274

Epoch: 6| Step: 8
Training loss: 2.8321782356791716
Validation loss: 2.6174638627050544

Epoch: 6| Step: 9
Training loss: 3.248692469569999
Validation loss: 2.6138479256437077

Epoch: 6| Step: 10
Training loss: 2.9298470008664834
Validation loss: 2.6373275193834114

Epoch: 6| Step: 11
Training loss: 2.7256475186746227
Validation loss: 2.636904202847514

Epoch: 6| Step: 12
Training loss: 2.7993202814953335
Validation loss: 2.644559896942287

Epoch: 6| Step: 13
Training loss: 4.019055278093242
Validation loss: 2.63405206064009

Epoch: 497| Step: 0
Training loss: 2.9076352663465292
Validation loss: 2.6341035382693843

Epoch: 6| Step: 1
Training loss: 2.9057838312178506
Validation loss: 2.642477493583784

Epoch: 6| Step: 2
Training loss: 2.9885467610803853
Validation loss: 2.6546665188914016

Epoch: 6| Step: 3
Training loss: 2.6393087142363982
Validation loss: 2.6589310050725494

Epoch: 6| Step: 4
Training loss: 3.2937093424594983
Validation loss: 2.6544160933909766

Epoch: 6| Step: 5
Training loss: 2.6439082934739884
Validation loss: 2.6431325700341914

Epoch: 6| Step: 6
Training loss: 2.3412796225560273
Validation loss: 2.5993500108462557

Epoch: 6| Step: 7
Training loss: 3.0133905384519024
Validation loss: 2.603921383699109

Epoch: 6| Step: 8
Training loss: 2.3035269191155208
Validation loss: 2.5866203768363096

Epoch: 6| Step: 9
Training loss: 2.984830012760882
Validation loss: 2.574873257815371

Epoch: 6| Step: 10
Training loss: 3.1808463569383156
Validation loss: 2.578995086429851

Epoch: 6| Step: 11
Training loss: 3.1545470525304293
Validation loss: 2.5656317605181638

Epoch: 6| Step: 12
Training loss: 2.501432389944778
Validation loss: 2.5649497325118005

Epoch: 6| Step: 13
Training loss: 2.7978562493143553
Validation loss: 2.5635602904913215

Epoch: 498| Step: 0
Training loss: 2.754563706289186
Validation loss: 2.5634731022762103

Epoch: 6| Step: 1
Training loss: 3.0009360442574633
Validation loss: 2.5714349849983598

Epoch: 6| Step: 2
Training loss: 3.127217230999996
Validation loss: 2.5706862690205705

Epoch: 6| Step: 3
Training loss: 3.4334262637798814
Validation loss: 2.5771056655084754

Epoch: 6| Step: 4
Training loss: 2.8630191115721773
Validation loss: 2.5854809709412843

Epoch: 6| Step: 5
Training loss: 2.877492736223931
Validation loss: 2.5948293895878063

Epoch: 6| Step: 6
Training loss: 2.9500383665531777
Validation loss: 2.5837046991092985

Epoch: 6| Step: 7
Training loss: 2.668178566854929
Validation loss: 2.60252447184425

Epoch: 6| Step: 8
Training loss: 2.5877673540805817
Validation loss: 2.6451333279210933

Epoch: 6| Step: 9
Training loss: 2.737540369302263
Validation loss: 2.661303790702562

Epoch: 6| Step: 10
Training loss: 2.2445202963615207
Validation loss: 2.687046664312807

Epoch: 6| Step: 11
Training loss: 2.98584938578044
Validation loss: 2.65398381925811

Epoch: 6| Step: 12
Training loss: 2.192875170910956
Validation loss: 2.6883338789728928

Epoch: 6| Step: 13
Training loss: 3.4596207914759947
Validation loss: 2.6592555781636054

Epoch: 499| Step: 0
Training loss: 2.8502587251177505
Validation loss: 2.646740625489339

Epoch: 6| Step: 1
Training loss: 2.663816916145729
Validation loss: 2.6308403029975715

Epoch: 6| Step: 2
Training loss: 3.139758545648946
Validation loss: 2.620530827708835

Epoch: 6| Step: 3
Training loss: 2.5690555919781244
Validation loss: 2.617116498037602

Epoch: 6| Step: 4
Training loss: 2.881656570049165
Validation loss: 2.6070224196813685

Epoch: 6| Step: 5
Training loss: 2.5487173706779855
Validation loss: 2.6117200663529845

Epoch: 6| Step: 6
Training loss: 2.520568350323947
Validation loss: 2.619907062896768

Epoch: 6| Step: 7
Training loss: 2.5298818022367318
Validation loss: 2.594705782389089

Epoch: 6| Step: 8
Training loss: 3.1845132634896967
Validation loss: 2.59978983375169

Epoch: 6| Step: 9
Training loss: 3.3875116214341703
Validation loss: 2.5956240290037114

Epoch: 6| Step: 10
Training loss: 3.2672723876783896
Validation loss: 2.6042519484471276

Epoch: 6| Step: 11
Training loss: 2.681725708347293
Validation loss: 2.6071932079233346

Epoch: 6| Step: 12
Training loss: 2.3203431201288733
Validation loss: 2.609451582651051

Epoch: 6| Step: 13
Training loss: 2.5966299223677125
Validation loss: 2.6301423140778666

Epoch: 500| Step: 0
Training loss: 2.0319662151907236
Validation loss: 2.6178384440634277

Epoch: 6| Step: 1
Training loss: 3.5573425438269357
Validation loss: 2.621377704637315

Epoch: 6| Step: 2
Training loss: 3.1778178048743704
Validation loss: 2.6159511221372713

Epoch: 6| Step: 3
Training loss: 2.70664898263701
Validation loss: 2.60419542522343

Epoch: 6| Step: 4
Training loss: 3.1883039769524304
Validation loss: 2.5956122736340594

Epoch: 6| Step: 5
Training loss: 2.7290900901553847
Validation loss: 2.5775814802271753

Epoch: 6| Step: 6
Training loss: 2.484243137530952
Validation loss: 2.5751524473407406

Epoch: 6| Step: 7
Training loss: 3.234595544639599
Validation loss: 2.5683775245290055

Epoch: 6| Step: 8
Training loss: 2.5230858147323127
Validation loss: 2.5701743398383923

Epoch: 6| Step: 9
Training loss: 2.6787691461161027
Validation loss: 2.567972557808568

Epoch: 6| Step: 10
Training loss: 2.1826495208734813
Validation loss: 2.567655068627796

Epoch: 6| Step: 11
Training loss: 3.250406533270994
Validation loss: 2.576143616971314

Epoch: 6| Step: 12
Training loss: 2.7320360043500416
Validation loss: 2.5714874120659648

Epoch: 6| Step: 13
Training loss: 2.9263353217851407
Validation loss: 2.574461387345563

Testing loss: 2.7880860591189895
