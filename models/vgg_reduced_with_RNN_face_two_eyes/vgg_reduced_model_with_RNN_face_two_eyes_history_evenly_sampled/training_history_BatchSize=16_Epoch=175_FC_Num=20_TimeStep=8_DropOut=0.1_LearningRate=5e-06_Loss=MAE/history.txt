Epoch: 1| Step: 0
Training loss: 4.039480686187744
Validation loss: 5.220768179944766

Epoch: 6| Step: 1
Training loss: 4.190685272216797
Validation loss: 5.215991579076295

Epoch: 6| Step: 2
Training loss: 4.410284519195557
Validation loss: 5.211519979661511

Epoch: 6| Step: 3
Training loss: 4.327350616455078
Validation loss: 5.206893028751496

Epoch: 6| Step: 4
Training loss: 4.664266109466553
Validation loss: 5.202632017033075

Epoch: 6| Step: 5
Training loss: 4.847074031829834
Validation loss: 5.197999508150162

Epoch: 6| Step: 6
Training loss: 6.343339920043945
Validation loss: 5.193641601070281

Epoch: 6| Step: 7
Training loss: 3.979633331298828
Validation loss: 5.188986311676682

Epoch: 6| Step: 8
Training loss: 4.731377601623535
Validation loss: 5.18418671495171

Epoch: 6| Step: 9
Training loss: 5.185230731964111
Validation loss: 5.179066806711177

Epoch: 6| Step: 10
Training loss: 4.899688720703125
Validation loss: 5.17400090412427

Epoch: 6| Step: 11
Training loss: 6.257655143737793
Validation loss: 5.168447130469866

Epoch: 6| Step: 12
Training loss: 6.1580705642700195
Validation loss: 5.1626681102219445

Epoch: 6| Step: 13
Training loss: 6.38374662399292
Validation loss: 5.156472913680538

Epoch: 2| Step: 0
Training loss: 4.652018070220947
Validation loss: 5.1506773271868305

Epoch: 6| Step: 1
Training loss: 5.1648101806640625
Validation loss: 5.1443306758839595

Epoch: 6| Step: 2
Training loss: 4.38486909866333
Validation loss: 5.137184635285409

Epoch: 6| Step: 3
Training loss: 4.5604248046875
Validation loss: 5.130112278846003

Epoch: 6| Step: 4
Training loss: 5.328592300415039
Validation loss: 5.122481330748527

Epoch: 6| Step: 5
Training loss: 3.9854624271392822
Validation loss: 5.114944570808

Epoch: 6| Step: 6
Training loss: 3.7871556282043457
Validation loss: 5.107142207443073

Epoch: 6| Step: 7
Training loss: 4.934049606323242
Validation loss: 5.098104599983461

Epoch: 6| Step: 8
Training loss: 4.587074279785156
Validation loss: 5.088940846022739

Epoch: 6| Step: 9
Training loss: 5.610167503356934
Validation loss: 5.0789338696387505

Epoch: 6| Step: 10
Training loss: 5.985362529754639
Validation loss: 5.068824306611092

Epoch: 6| Step: 11
Training loss: 4.311656475067139
Validation loss: 5.05785080181655

Epoch: 6| Step: 12
Training loss: 5.571959972381592
Validation loss: 5.046941967420681

Epoch: 6| Step: 13
Training loss: 6.228837966918945
Validation loss: 5.035144344452889

Epoch: 3| Step: 0
Training loss: 5.124035835266113
Validation loss: 5.022588945204212

Epoch: 6| Step: 1
Training loss: 5.075013160705566
Validation loss: 5.009556831852082

Epoch: 6| Step: 2
Training loss: 3.2822039127349854
Validation loss: 4.994734964063091

Epoch: 6| Step: 3
Training loss: 3.9945099353790283
Validation loss: 4.980978365867369

Epoch: 6| Step: 4
Training loss: 4.2419843673706055
Validation loss: 4.965652055637811

Epoch: 6| Step: 5
Training loss: 4.004026889801025
Validation loss: 4.948646791519657

Epoch: 6| Step: 6
Training loss: 5.8859782218933105
Validation loss: 4.933457184863347

Epoch: 6| Step: 7
Training loss: 6.4752349853515625
Validation loss: 4.914467427038377

Epoch: 6| Step: 8
Training loss: 5.057787895202637
Validation loss: 4.8956289086290585

Epoch: 6| Step: 9
Training loss: 4.095088958740234
Validation loss: 4.876053171773111

Epoch: 6| Step: 10
Training loss: 4.271295547485352
Validation loss: 4.8567743660301295

Epoch: 6| Step: 11
Training loss: 4.952341079711914
Validation loss: 4.834741828262165

Epoch: 6| Step: 12
Training loss: 5.045727729797363
Validation loss: 4.8108709858309835

Epoch: 6| Step: 13
Training loss: 4.193981647491455
Validation loss: 4.788640001768707

Epoch: 4| Step: 0
Training loss: 4.223058700561523
Validation loss: 4.763440101377426

Epoch: 6| Step: 1
Training loss: 3.655282735824585
Validation loss: 4.7373026647875385

Epoch: 6| Step: 2
Training loss: 3.870755672454834
Validation loss: 4.711556916595788

Epoch: 6| Step: 3
Training loss: 5.4058837890625
Validation loss: 4.685493197492374

Epoch: 6| Step: 4
Training loss: 3.7529103755950928
Validation loss: 4.657002479799332

Epoch: 6| Step: 5
Training loss: 4.782886505126953
Validation loss: 4.628373730567194

Epoch: 6| Step: 6
Training loss: 5.5832061767578125
Validation loss: 4.597599547396424

Epoch: 6| Step: 7
Training loss: 5.614289283752441
Validation loss: 4.567380443696053

Epoch: 6| Step: 8
Training loss: 5.222902774810791
Validation loss: 4.53687536075551

Epoch: 6| Step: 9
Training loss: 3.099306583404541
Validation loss: 4.505515062680808

Epoch: 6| Step: 10
Training loss: 4.120787620544434
Validation loss: 4.472140471140544

Epoch: 6| Step: 11
Training loss: 4.435937881469727
Validation loss: 4.439903948896674

Epoch: 6| Step: 12
Training loss: 3.302250385284424
Validation loss: 4.405920767015027

Epoch: 6| Step: 13
Training loss: 3.637877941131592
Validation loss: 4.373921948094522

Epoch: 5| Step: 0
Training loss: 3.427851915359497
Validation loss: 4.341836596048006

Epoch: 6| Step: 1
Training loss: 4.524287700653076
Validation loss: 4.310423281884963

Epoch: 6| Step: 2
Training loss: 4.64333438873291
Validation loss: 4.278362925334643

Epoch: 6| Step: 3
Training loss: 3.7153828144073486
Validation loss: 4.249099141807966

Epoch: 6| Step: 4
Training loss: 3.738335371017456
Validation loss: 4.218809199589555

Epoch: 6| Step: 5
Training loss: 2.4179728031158447
Validation loss: 4.189808509683096

Epoch: 6| Step: 6
Training loss: 4.3807477951049805
Validation loss: 4.162503760348084

Epoch: 6| Step: 7
Training loss: 3.9556169509887695
Validation loss: 4.13813058791622

Epoch: 6| Step: 8
Training loss: 3.627135753631592
Validation loss: 4.112098493883686

Epoch: 6| Step: 9
Training loss: 3.416269302368164
Validation loss: 4.08863293227329

Epoch: 6| Step: 10
Training loss: 3.053574562072754
Validation loss: 4.066858363407914

Epoch: 6| Step: 11
Training loss: 5.443238258361816
Validation loss: 4.043762683868408

Epoch: 6| Step: 12
Training loss: 4.232093811035156
Validation loss: 4.022469848714849

Epoch: 6| Step: 13
Training loss: 6.132290363311768
Validation loss: 4.0001249467172935

Epoch: 6| Step: 0
Training loss: 2.9122750759124756
Validation loss: 3.9790149709229827

Epoch: 6| Step: 1
Training loss: 3.8572936058044434
Validation loss: 3.9588309308534027

Epoch: 6| Step: 2
Training loss: 4.4544830322265625
Validation loss: 3.938229053251205

Epoch: 6| Step: 3
Training loss: 4.48384952545166
Validation loss: 3.920045662951726

Epoch: 6| Step: 4
Training loss: 4.249142169952393
Validation loss: 3.900380849838257

Epoch: 6| Step: 5
Training loss: 3.699850559234619
Validation loss: 3.8829282432474117

Epoch: 6| Step: 6
Training loss: 3.5850038528442383
Validation loss: 3.8652802231491252

Epoch: 6| Step: 7
Training loss: 4.312382698059082
Validation loss: 3.8484160413024244

Epoch: 6| Step: 8
Training loss: 3.521841049194336
Validation loss: 3.831391719079787

Epoch: 6| Step: 9
Training loss: 3.856086254119873
Validation loss: 3.8151661734427176

Epoch: 6| Step: 10
Training loss: 2.9346871376037598
Validation loss: 3.8004211610363376

Epoch: 6| Step: 11
Training loss: 3.6847493648529053
Validation loss: 3.7874200420994915

Epoch: 6| Step: 12
Training loss: 3.527217388153076
Validation loss: 3.771181321913196

Epoch: 6| Step: 13
Training loss: 2.8786933422088623
Validation loss: 3.758357750472202

Epoch: 7| Step: 0
Training loss: 4.739011764526367
Validation loss: 3.745489348647415

Epoch: 6| Step: 1
Training loss: 2.7554590702056885
Validation loss: 3.734586177333709

Epoch: 6| Step: 2
Training loss: 2.676968574523926
Validation loss: 3.7250905139471895

Epoch: 6| Step: 3
Training loss: 3.565171480178833
Validation loss: 3.7099597172070573

Epoch: 6| Step: 4
Training loss: 4.245285987854004
Validation loss: 3.700051446114817

Epoch: 6| Step: 5
Training loss: 4.986019134521484
Validation loss: 3.6896256785238943

Epoch: 6| Step: 6
Training loss: 3.327042579650879
Validation loss: 3.6791720236501386

Epoch: 6| Step: 7
Training loss: 2.8828024864196777
Validation loss: 3.666746690709104

Epoch: 6| Step: 8
Training loss: 4.456565856933594
Validation loss: 3.654815499500562

Epoch: 6| Step: 9
Training loss: 2.6780483722686768
Validation loss: 3.6421399936881116

Epoch: 6| Step: 10
Training loss: 3.1404032707214355
Validation loss: 3.6298249665127007

Epoch: 6| Step: 11
Training loss: 3.3917784690856934
Validation loss: 3.6189894060934744

Epoch: 6| Step: 12
Training loss: 3.70857572555542
Validation loss: 3.606763157793271

Epoch: 6| Step: 13
Training loss: 3.521385908126831
Validation loss: 3.5955342990095898

Epoch: 8| Step: 0
Training loss: 3.423013210296631
Validation loss: 3.5850406769783265

Epoch: 6| Step: 1
Training loss: 3.496720552444458
Validation loss: 3.575171924406482

Epoch: 6| Step: 2
Training loss: 3.590805768966675
Validation loss: 3.567468556024695

Epoch: 6| Step: 3
Training loss: 4.339127540588379
Validation loss: 3.5578912842658257

Epoch: 6| Step: 4
Training loss: 3.0823493003845215
Validation loss: 3.5473330918178765

Epoch: 6| Step: 5
Training loss: 4.086771488189697
Validation loss: 3.5362540265565277

Epoch: 6| Step: 6
Training loss: 3.0370564460754395
Validation loss: 3.522905836823166

Epoch: 6| Step: 7
Training loss: 4.106776237487793
Validation loss: 3.5130464979397353

Epoch: 6| Step: 8
Training loss: 3.0492639541625977
Validation loss: 3.5009828793105258

Epoch: 6| Step: 9
Training loss: 2.7317886352539062
Validation loss: 3.4931680130702194

Epoch: 6| Step: 10
Training loss: 3.1919498443603516
Validation loss: 3.482740289421492

Epoch: 6| Step: 11
Training loss: 4.064189434051514
Validation loss: 3.4741244546828733

Epoch: 6| Step: 12
Training loss: 2.845294713973999
Validation loss: 3.462851047515869

Epoch: 6| Step: 13
Training loss: 3.304840326309204
Validation loss: 3.459055926210137

Epoch: 9| Step: 0
Training loss: 3.4971508979797363
Validation loss: 3.4488855638811664

Epoch: 6| Step: 1
Training loss: 3.591348648071289
Validation loss: 3.443061197957685

Epoch: 6| Step: 2
Training loss: 3.3864145278930664
Validation loss: 3.4350312730317474

Epoch: 6| Step: 3
Training loss: 2.986751079559326
Validation loss: 3.4273328396581833

Epoch: 6| Step: 4
Training loss: 2.3058314323425293
Validation loss: 3.419806775226388

Epoch: 6| Step: 5
Training loss: 4.347038269042969
Validation loss: 3.413921017800608

Epoch: 6| Step: 6
Training loss: 3.8164453506469727
Validation loss: 3.405038720817976

Epoch: 6| Step: 7
Training loss: 3.7944374084472656
Validation loss: 3.3957778869136686

Epoch: 6| Step: 8
Training loss: 2.6945838928222656
Validation loss: 3.389439503351847

Epoch: 6| Step: 9
Training loss: 3.6085686683654785
Validation loss: 3.3810302672847623

Epoch: 6| Step: 10
Training loss: 3.5738179683685303
Validation loss: 3.3748621632975917

Epoch: 6| Step: 11
Training loss: 2.707529067993164
Validation loss: 3.3708140157884166

Epoch: 6| Step: 12
Training loss: 2.9598522186279297
Validation loss: 3.3636473737737185

Epoch: 6| Step: 13
Training loss: 3.9593958854675293
Validation loss: 3.3552665838631253

Epoch: 10| Step: 0
Training loss: 2.967848777770996
Validation loss: 3.349183738872569

Epoch: 6| Step: 1
Training loss: 3.6560592651367188
Validation loss: 3.3395292887123684

Epoch: 6| Step: 2
Training loss: 3.5404515266418457
Validation loss: 3.335567464110672

Epoch: 6| Step: 3
Training loss: 2.828263282775879
Validation loss: 3.330640821046727

Epoch: 6| Step: 4
Training loss: 3.9883785247802734
Validation loss: 3.324405598384078

Epoch: 6| Step: 5
Training loss: 3.428314208984375
Validation loss: 3.3181896414808048

Epoch: 6| Step: 6
Training loss: 3.631744384765625
Validation loss: 3.315808409003801

Epoch: 6| Step: 7
Training loss: 2.311596155166626
Validation loss: 3.3084414133461575

Epoch: 6| Step: 8
Training loss: 2.642127513885498
Validation loss: 3.3010211324179046

Epoch: 6| Step: 9
Training loss: 3.8690855503082275
Validation loss: 3.295840594076341

Epoch: 6| Step: 10
Training loss: 2.8668246269226074
Validation loss: 3.2906661341267247

Epoch: 6| Step: 11
Training loss: 3.27034330368042
Validation loss: 3.286577873332526

Epoch: 6| Step: 12
Training loss: 3.664243221282959
Validation loss: 3.2823818550314954

Epoch: 6| Step: 13
Training loss: 3.1837892532348633
Validation loss: 3.2754605124073644

Epoch: 11| Step: 0
Training loss: 2.998903274536133
Validation loss: 3.2674308797364593

Epoch: 6| Step: 1
Training loss: 3.488565444946289
Validation loss: 3.263393314935828

Epoch: 6| Step: 2
Training loss: 2.9741086959838867
Validation loss: 3.2591245533317648

Epoch: 6| Step: 3
Training loss: 4.279706954956055
Validation loss: 3.2541516416816303

Epoch: 6| Step: 4
Training loss: 2.4229941368103027
Validation loss: 3.252130418695429

Epoch: 6| Step: 5
Training loss: 2.9834158420562744
Validation loss: 3.247358932290026

Epoch: 6| Step: 6
Training loss: 3.251675605773926
Validation loss: 3.2425160510565645

Epoch: 6| Step: 7
Training loss: 3.071614980697632
Validation loss: 3.2349178278318016

Epoch: 6| Step: 8
Training loss: 3.2671117782592773
Validation loss: 3.2308326690427718

Epoch: 6| Step: 9
Training loss: 3.2232542037963867
Validation loss: 3.225402121902794

Epoch: 6| Step: 10
Training loss: 2.59063982963562
Validation loss: 3.219353557914816

Epoch: 6| Step: 11
Training loss: 3.3020851612091064
Validation loss: 3.218833428557201

Epoch: 6| Step: 12
Training loss: 3.9975080490112305
Validation loss: 3.212848417220577

Epoch: 6| Step: 13
Training loss: 3.3759243488311768
Validation loss: 3.2063272255723194

Epoch: 12| Step: 0
Training loss: 3.128437042236328
Validation loss: 3.2049060662587485

Epoch: 6| Step: 1
Training loss: 3.8638923168182373
Validation loss: 3.1976888025960615

Epoch: 6| Step: 2
Training loss: 3.7119927406311035
Validation loss: 3.1947359808029665

Epoch: 6| Step: 3
Training loss: 3.7686357498168945
Validation loss: 3.1921542895737516

Epoch: 6| Step: 4
Training loss: 2.6756114959716797
Validation loss: 3.187084254398141

Epoch: 6| Step: 5
Training loss: 2.776956081390381
Validation loss: 3.1836774272303425

Epoch: 6| Step: 6
Training loss: 2.689924478530884
Validation loss: 3.1806128358328216

Epoch: 6| Step: 7
Training loss: 3.6092638969421387
Validation loss: 3.1709246840528262

Epoch: 6| Step: 8
Training loss: 2.830590009689331
Validation loss: 3.1665315089687223

Epoch: 6| Step: 9
Training loss: 1.9373385906219482
Validation loss: 3.1645585721538914

Epoch: 6| Step: 10
Training loss: 2.9882349967956543
Validation loss: 3.16227795744455

Epoch: 6| Step: 11
Training loss: 2.8846991062164307
Validation loss: 3.1576347684347503

Epoch: 6| Step: 12
Training loss: 4.13653039932251
Validation loss: 3.153512062564973

Epoch: 6| Step: 13
Training loss: 3.803982973098755
Validation loss: 3.1511731968131116

Epoch: 13| Step: 0
Training loss: 2.6917593479156494
Validation loss: 3.148266233423705

Epoch: 6| Step: 1
Training loss: 2.8008973598480225
Validation loss: 3.1448094280817176

Epoch: 6| Step: 2
Training loss: 2.7019777297973633
Validation loss: 3.138623035082253

Epoch: 6| Step: 3
Training loss: 2.9472033977508545
Validation loss: 3.136889893521545

Epoch: 6| Step: 4
Training loss: 3.9911603927612305
Validation loss: 3.1338628517684115

Epoch: 6| Step: 5
Training loss: 3.0318925380706787
Validation loss: 3.125528279171195

Epoch: 6| Step: 6
Training loss: 3.609102249145508
Validation loss: 3.1215558077699397

Epoch: 6| Step: 7
Training loss: 2.9822921752929688
Validation loss: 3.1165863083254908

Epoch: 6| Step: 8
Training loss: 4.153525352478027
Validation loss: 3.116378814943375

Epoch: 6| Step: 9
Training loss: 3.816638946533203
Validation loss: 3.1140453456550516

Epoch: 6| Step: 10
Training loss: 3.245907783508301
Validation loss: 3.1094650504409627

Epoch: 6| Step: 11
Training loss: 1.9621235132217407
Validation loss: 3.1065854616062616

Epoch: 6| Step: 12
Training loss: 2.7240095138549805
Validation loss: 3.1046219359162035

Epoch: 6| Step: 13
Training loss: 3.5360119342803955
Validation loss: 3.1012599570776826

Epoch: 14| Step: 0
Training loss: 2.999394416809082
Validation loss: 3.0997974923861924

Epoch: 6| Step: 1
Training loss: 3.929816722869873
Validation loss: 3.097744834038519

Epoch: 6| Step: 2
Training loss: 2.4509706497192383
Validation loss: 3.0947346277134393

Epoch: 6| Step: 3
Training loss: 2.2363712787628174
Validation loss: 3.0913380602354645

Epoch: 6| Step: 4
Training loss: 3.04077410697937
Validation loss: 3.093374921429542

Epoch: 6| Step: 5
Training loss: 2.6877546310424805
Validation loss: 3.0880450023117887

Epoch: 6| Step: 6
Training loss: 3.482459306716919
Validation loss: 3.0850882735303653

Epoch: 6| Step: 7
Training loss: 2.7074484825134277
Validation loss: 3.078042394371443

Epoch: 6| Step: 8
Training loss: 3.960878610610962
Validation loss: 3.072329234051448

Epoch: 6| Step: 9
Training loss: 3.205373764038086
Validation loss: 3.0710441989283406

Epoch: 6| Step: 10
Training loss: 4.135268211364746
Validation loss: 3.0724102194591234

Epoch: 6| Step: 11
Training loss: 2.542969226837158
Validation loss: 3.07234094219823

Epoch: 6| Step: 12
Training loss: 3.75366473197937
Validation loss: 3.069578852704776

Epoch: 6| Step: 13
Training loss: 2.0324149131774902
Validation loss: 3.069405735179942

Epoch: 15| Step: 0
Training loss: 3.247025728225708
Validation loss: 3.058787145922261

Epoch: 6| Step: 1
Training loss: 2.0242865085601807
Validation loss: 3.054666124364381

Epoch: 6| Step: 2
Training loss: 3.138577938079834
Validation loss: 3.051030117978332

Epoch: 6| Step: 3
Training loss: 4.098394870758057
Validation loss: 3.052769132839736

Epoch: 6| Step: 4
Training loss: 3.352949619293213
Validation loss: 3.043257690245105

Epoch: 6| Step: 5
Training loss: 2.532104969024658
Validation loss: 3.0422893211405766

Epoch: 6| Step: 6
Training loss: 3.6885547637939453
Validation loss: 3.0421077461652857

Epoch: 6| Step: 7
Training loss: 3.49716854095459
Validation loss: 3.0378715684337

Epoch: 6| Step: 8
Training loss: 3.095937728881836
Validation loss: 3.0372015506990495

Epoch: 6| Step: 9
Training loss: 2.9213433265686035
Validation loss: 3.0296990153610066

Epoch: 6| Step: 10
Training loss: 2.1206507682800293
Validation loss: 3.0258736533503376

Epoch: 6| Step: 11
Training loss: 3.2250728607177734
Validation loss: 3.0217290206622054

Epoch: 6| Step: 12
Training loss: 2.757791519165039
Validation loss: 3.01826504225372

Epoch: 6| Step: 13
Training loss: 3.854600667953491
Validation loss: 3.016577087422853

Epoch: 16| Step: 0
Training loss: 2.9012393951416016
Validation loss: 3.0151052116065897

Epoch: 6| Step: 1
Training loss: 2.351060390472412
Validation loss: 3.016314273239464

Epoch: 6| Step: 2
Training loss: 3.7981746196746826
Validation loss: 3.020075636525308

Epoch: 6| Step: 3
Training loss: 3.312866687774658
Validation loss: 3.019519749508109

Epoch: 6| Step: 4
Training loss: 3.9487216472625732
Validation loss: 3.0126369486572924

Epoch: 6| Step: 5
Training loss: 2.631601333618164
Validation loss: 3.002836896527198

Epoch: 6| Step: 6
Training loss: 2.5803916454315186
Validation loss: 3.0004219470485562

Epoch: 6| Step: 7
Training loss: 3.447913646697998
Validation loss: 2.9983460057166313

Epoch: 6| Step: 8
Training loss: 3.4450557231903076
Validation loss: 2.9935736040915213

Epoch: 6| Step: 9
Training loss: 2.096057176589966
Validation loss: 2.9884697596232095

Epoch: 6| Step: 10
Training loss: 3.7328619956970215
Validation loss: 2.9915065227016324

Epoch: 6| Step: 11
Training loss: 3.087829113006592
Validation loss: 2.9857159147980394

Epoch: 6| Step: 12
Training loss: 2.7592759132385254
Validation loss: 2.983441234916769

Epoch: 6| Step: 13
Training loss: 2.5481061935424805
Validation loss: 2.9816578972724175

Epoch: 17| Step: 0
Training loss: 3.0153253078460693
Validation loss: 2.974547101605323

Epoch: 6| Step: 1
Training loss: 3.608565092086792
Validation loss: 2.970267798310967

Epoch: 6| Step: 2
Training loss: 2.6330511569976807
Validation loss: 2.9639756500080066

Epoch: 6| Step: 3
Training loss: 3.040605068206787
Validation loss: 2.9589783940263974

Epoch: 6| Step: 4
Training loss: 3.593013286590576
Validation loss: 2.956484874089559

Epoch: 6| Step: 5
Training loss: 2.5492300987243652
Validation loss: 2.9520255622043403

Epoch: 6| Step: 6
Training loss: 3.1156580448150635
Validation loss: 2.9516546034043833

Epoch: 6| Step: 7
Training loss: 2.2614805698394775
Validation loss: 2.947950396486508

Epoch: 6| Step: 8
Training loss: 2.935133934020996
Validation loss: 2.9543827015866517

Epoch: 6| Step: 9
Training loss: 3.142111301422119
Validation loss: 2.9616882826692317

Epoch: 6| Step: 10
Training loss: 2.915464162826538
Validation loss: 2.9793966277953117

Epoch: 6| Step: 11
Training loss: 3.467113971710205
Validation loss: 2.952702683787192

Epoch: 6| Step: 12
Training loss: 3.1244471073150635
Validation loss: 2.9429210462877826

Epoch: 6| Step: 13
Training loss: 3.0473172664642334
Validation loss: 2.9380130396094373

Epoch: 18| Step: 0
Training loss: 2.963132381439209
Validation loss: 2.9380253873845583

Epoch: 6| Step: 1
Training loss: 3.3340039253234863
Validation loss: 2.9387318754708893

Epoch: 6| Step: 2
Training loss: 3.12134051322937
Validation loss: 2.943334510249476

Epoch: 6| Step: 3
Training loss: 2.635416030883789
Validation loss: 2.9365042947953746

Epoch: 6| Step: 4
Training loss: 3.0724401473999023
Validation loss: 2.934874265424667

Epoch: 6| Step: 5
Training loss: 3.113689422607422
Validation loss: 2.9318221935661892

Epoch: 6| Step: 6
Training loss: 2.2976176738739014
Validation loss: 2.9284242917132635

Epoch: 6| Step: 7
Training loss: 2.922041893005371
Validation loss: 2.928720005096928

Epoch: 6| Step: 8
Training loss: 3.7338790893554688
Validation loss: 2.925486477472449

Epoch: 6| Step: 9
Training loss: 2.930760383605957
Validation loss: 2.923690278043029

Epoch: 6| Step: 10
Training loss: 3.3675546646118164
Validation loss: 2.9205138350045807

Epoch: 6| Step: 11
Training loss: 2.657796859741211
Validation loss: 2.9187325841637066

Epoch: 6| Step: 12
Training loss: 3.1509618759155273
Validation loss: 2.9177245606658277

Epoch: 6| Step: 13
Training loss: 2.8927299976348877
Validation loss: 2.915526024756893

Epoch: 19| Step: 0
Training loss: 3.410848379135132
Validation loss: 2.9131795308923207

Epoch: 6| Step: 1
Training loss: 3.123624086380005
Validation loss: 2.9103239710612963

Epoch: 6| Step: 2
Training loss: 3.419224262237549
Validation loss: 2.9096097587257304

Epoch: 6| Step: 3
Training loss: 3.134544610977173
Validation loss: 2.9038372116704143

Epoch: 6| Step: 4
Training loss: 2.934957981109619
Validation loss: 2.9019495569249636

Epoch: 6| Step: 5
Training loss: 3.217402935028076
Validation loss: 2.8960535295547976

Epoch: 6| Step: 6
Training loss: 2.759507179260254
Validation loss: 2.896813456730176

Epoch: 6| Step: 7
Training loss: 2.851795196533203
Validation loss: 2.8918111093582644

Epoch: 6| Step: 8
Training loss: 3.6731839179992676
Validation loss: 2.889954920737974

Epoch: 6| Step: 9
Training loss: 2.5876739025115967
Validation loss: 2.887150146627939

Epoch: 6| Step: 10
Training loss: 2.5811047554016113
Validation loss: 2.888571636651152

Epoch: 6| Step: 11
Training loss: 2.5114409923553467
Validation loss: 2.8869156734917754

Epoch: 6| Step: 12
Training loss: 3.383655548095703
Validation loss: 2.885472748869209

Epoch: 6| Step: 13
Training loss: 1.7793564796447754
Validation loss: 2.882313238677158

Epoch: 20| Step: 0
Training loss: 2.583584785461426
Validation loss: 2.8824665084961922

Epoch: 6| Step: 1
Training loss: 2.962005138397217
Validation loss: 2.878138224283854

Epoch: 6| Step: 2
Training loss: 3.2102317810058594
Validation loss: 2.8787676621508855

Epoch: 6| Step: 3
Training loss: 2.647859573364258
Validation loss: 2.877603687265868

Epoch: 6| Step: 4
Training loss: 3.2993252277374268
Validation loss: 2.870855200675226

Epoch: 6| Step: 5
Training loss: 2.8084442615509033
Validation loss: 2.872304703599663

Epoch: 6| Step: 6
Training loss: 3.289644241333008
Validation loss: 2.8690579860441145

Epoch: 6| Step: 7
Training loss: 3.6446971893310547
Validation loss: 2.8686436888992146

Epoch: 6| Step: 8
Training loss: 2.596492290496826
Validation loss: 2.868763631389987

Epoch: 6| Step: 9
Training loss: 2.997896432876587
Validation loss: 2.867236809063983

Epoch: 6| Step: 10
Training loss: 3.0928432941436768
Validation loss: 2.8685781109717583

Epoch: 6| Step: 11
Training loss: 2.2943003177642822
Validation loss: 2.866421663632957

Epoch: 6| Step: 12
Training loss: 2.6325480937957764
Validation loss: 2.865602611213602

Epoch: 6| Step: 13
Training loss: 4.095300674438477
Validation loss: 2.8728506001093055

Epoch: 21| Step: 0
Training loss: 2.2859854698181152
Validation loss: 2.8606527338745775

Epoch: 6| Step: 1
Training loss: 2.6607723236083984
Validation loss: 2.8606424716211136

Epoch: 6| Step: 2
Training loss: 2.3602583408355713
Validation loss: 2.8635811267360562

Epoch: 6| Step: 3
Training loss: 2.9317984580993652
Validation loss: 2.86712985397667

Epoch: 6| Step: 4
Training loss: 3.267547130584717
Validation loss: 2.864642009940199

Epoch: 6| Step: 5
Training loss: 2.9372410774230957
Validation loss: 2.8633813601668163

Epoch: 6| Step: 6
Training loss: 3.9808855056762695
Validation loss: 2.855843577333676

Epoch: 6| Step: 7
Training loss: 2.458662986755371
Validation loss: 2.853577095975158

Epoch: 6| Step: 8
Training loss: 3.0206191539764404
Validation loss: 2.851728423949211

Epoch: 6| Step: 9
Training loss: 3.8039422035217285
Validation loss: 2.8520704546282367

Epoch: 6| Step: 10
Training loss: 2.814314126968384
Validation loss: 2.8490982876029065

Epoch: 6| Step: 11
Training loss: 3.694918155670166
Validation loss: 2.848311678055794

Epoch: 6| Step: 12
Training loss: 2.502483606338501
Validation loss: 2.845055974939818

Epoch: 6| Step: 13
Training loss: 2.6878275871276855
Validation loss: 2.8439698091117283

Epoch: 22| Step: 0
Training loss: 2.6501474380493164
Validation loss: 2.842983135613062

Epoch: 6| Step: 1
Training loss: 3.608668327331543
Validation loss: 2.8435986118931926

Epoch: 6| Step: 2
Training loss: 2.596827507019043
Validation loss: 2.842809902724399

Epoch: 6| Step: 3
Training loss: 3.8601837158203125
Validation loss: 2.840860579603462

Epoch: 6| Step: 4
Training loss: 3.20133900642395
Validation loss: 2.8393779646965767

Epoch: 6| Step: 5
Training loss: 3.034301519393921
Validation loss: 2.8398289052389

Epoch: 6| Step: 6
Training loss: 2.8316822052001953
Validation loss: 2.8363737983088337

Epoch: 6| Step: 7
Training loss: 2.519308090209961
Validation loss: 2.83702830601764

Epoch: 6| Step: 8
Training loss: 2.87837553024292
Validation loss: 2.834426208208966

Epoch: 6| Step: 9
Training loss: 2.711921453475952
Validation loss: 2.8346821492718113

Epoch: 6| Step: 10
Training loss: 2.861138343811035
Validation loss: 2.836215939573062

Epoch: 6| Step: 11
Training loss: 3.028411388397217
Validation loss: 2.8368182079766386

Epoch: 6| Step: 12
Training loss: 2.6136975288391113
Validation loss: 2.834011229135657

Epoch: 6| Step: 13
Training loss: 2.9752540588378906
Validation loss: 2.835091793408958

Epoch: 23| Step: 0
Training loss: 2.2112412452697754
Validation loss: 2.8290719550143004

Epoch: 6| Step: 1
Training loss: 3.127624988555908
Validation loss: 2.826299700685727

Epoch: 6| Step: 2
Training loss: 3.583475112915039
Validation loss: 2.8273912527227916

Epoch: 6| Step: 3
Training loss: 2.971205234527588
Validation loss: 2.826117948819232

Epoch: 6| Step: 4
Training loss: 3.110774517059326
Validation loss: 2.8235165021752797

Epoch: 6| Step: 5
Training loss: 2.511836528778076
Validation loss: 2.8234285103377474

Epoch: 6| Step: 6
Training loss: 2.3708083629608154
Validation loss: 2.8213269120903424

Epoch: 6| Step: 7
Training loss: 3.099663019180298
Validation loss: 2.819896203215404

Epoch: 6| Step: 8
Training loss: 3.0433554649353027
Validation loss: 2.8166744401378017

Epoch: 6| Step: 9
Training loss: 2.5197930335998535
Validation loss: 2.8174410584152385

Epoch: 6| Step: 10
Training loss: 3.2439212799072266
Validation loss: 2.8160552568333124

Epoch: 6| Step: 11
Training loss: 3.7713782787323
Validation loss: 2.816251649651476

Epoch: 6| Step: 12
Training loss: 3.2786500453948975
Validation loss: 2.8136505285898843

Epoch: 6| Step: 13
Training loss: 1.8888068199157715
Validation loss: 2.8132755192377235

Epoch: 24| Step: 0
Training loss: 3.0733485221862793
Validation loss: 2.812398002993676

Epoch: 6| Step: 1
Training loss: 2.749000072479248
Validation loss: 2.8149772151823966

Epoch: 6| Step: 2
Training loss: 3.022852897644043
Validation loss: 2.8125945727030435

Epoch: 6| Step: 3
Training loss: 2.708540439605713
Validation loss: 2.8110998856124056

Epoch: 6| Step: 4
Training loss: 2.9371321201324463
Validation loss: 2.8082240807112826

Epoch: 6| Step: 5
Training loss: 3.0378127098083496
Validation loss: 2.8099475214558263

Epoch: 6| Step: 6
Training loss: 3.619438886642456
Validation loss: 2.8101671229126635

Epoch: 6| Step: 7
Training loss: 3.6701242923736572
Validation loss: 2.810392354124336

Epoch: 6| Step: 8
Training loss: 3.0195956230163574
Validation loss: 2.806918495444841

Epoch: 6| Step: 9
Training loss: 2.8133411407470703
Validation loss: 2.8060718736340924

Epoch: 6| Step: 10
Training loss: 3.2015767097473145
Validation loss: 2.8043693906517437

Epoch: 6| Step: 11
Training loss: 1.6614078283309937
Validation loss: 2.8045672114177416

Epoch: 6| Step: 12
Training loss: 2.768186330795288
Validation loss: 2.8002397168067192

Epoch: 6| Step: 13
Training loss: 2.730280876159668
Validation loss: 2.8024102564780944

Epoch: 25| Step: 0
Training loss: 2.3554434776306152
Validation loss: 2.7999647919849684

Epoch: 6| Step: 1
Training loss: 3.1197080612182617
Validation loss: 2.8014273617857244

Epoch: 6| Step: 2
Training loss: 3.4131128787994385
Validation loss: 2.801358243470551

Epoch: 6| Step: 3
Training loss: 2.5814895629882812
Validation loss: 2.803948038367815

Epoch: 6| Step: 4
Training loss: 2.7560808658599854
Validation loss: 2.8019008585201797

Epoch: 6| Step: 5
Training loss: 2.3753223419189453
Validation loss: 2.798989934305991

Epoch: 6| Step: 6
Training loss: 2.8781964778900146
Validation loss: 2.8029468546631517

Epoch: 6| Step: 7
Training loss: 4.320570468902588
Validation loss: 2.800938629334973

Epoch: 6| Step: 8
Training loss: 3.4437918663024902
Validation loss: 2.7997017778376097

Epoch: 6| Step: 9
Training loss: 3.0978150367736816
Validation loss: 2.7985874811808267

Epoch: 6| Step: 10
Training loss: 2.6368813514709473
Validation loss: 2.7959487361292683

Epoch: 6| Step: 11
Training loss: 2.3897757530212402
Validation loss: 2.7940277463646344

Epoch: 6| Step: 12
Training loss: 3.113615036010742
Validation loss: 2.7938258340281825

Epoch: 6| Step: 13
Training loss: 2.208791971206665
Validation loss: 2.7970890639930643

Epoch: 26| Step: 0
Training loss: 2.8670237064361572
Validation loss: 2.798943476010394

Epoch: 6| Step: 1
Training loss: 2.7064125537872314
Validation loss: 2.8055597479625414

Epoch: 6| Step: 2
Training loss: 3.0354058742523193
Validation loss: 2.7926989345140356

Epoch: 6| Step: 3
Training loss: 3.150629997253418
Validation loss: 2.79148498658211

Epoch: 6| Step: 4
Training loss: 2.5142998695373535
Validation loss: 2.788934494859429

Epoch: 6| Step: 5
Training loss: 3.5241119861602783
Validation loss: 2.791050382839736

Epoch: 6| Step: 6
Training loss: 2.8274364471435547
Validation loss: 2.7942228778716056

Epoch: 6| Step: 7
Training loss: 2.3646507263183594
Validation loss: 2.7954741190838557

Epoch: 6| Step: 8
Training loss: 3.657534122467041
Validation loss: 2.79041055710085

Epoch: 6| Step: 9
Training loss: 3.2208242416381836
Validation loss: 2.791418803635464

Epoch: 6| Step: 10
Training loss: 3.566185235977173
Validation loss: 2.7871784522969234

Epoch: 6| Step: 11
Training loss: 2.096839666366577
Validation loss: 2.7846175496296217

Epoch: 6| Step: 12
Training loss: 1.8565897941589355
Validation loss: 2.783068523612074

Epoch: 6| Step: 13
Training loss: 4.089930534362793
Validation loss: 2.7848708924426826

Epoch: 27| Step: 0
Training loss: 3.2911763191223145
Validation loss: 2.7813854960985083

Epoch: 6| Step: 1
Training loss: 3.4610447883605957
Validation loss: 2.7800111180992535

Epoch: 6| Step: 2
Training loss: 2.3878014087677
Validation loss: 2.7785750614699496

Epoch: 6| Step: 3
Training loss: 2.8728384971618652
Validation loss: 2.7781195691836778

Epoch: 6| Step: 4
Training loss: 2.3619203567504883
Validation loss: 2.7799888580076155

Epoch: 6| Step: 5
Training loss: 2.764152765274048
Validation loss: 2.7778764642694944

Epoch: 6| Step: 6
Training loss: 2.781169891357422
Validation loss: 2.776159812045354

Epoch: 6| Step: 7
Training loss: 3.0663890838623047
Validation loss: 2.776747078023931

Epoch: 6| Step: 8
Training loss: 3.468046188354492
Validation loss: 2.7732874629318074

Epoch: 6| Step: 9
Training loss: 2.696831703186035
Validation loss: 2.772391321838543

Epoch: 6| Step: 10
Training loss: 2.752279758453369
Validation loss: 2.773197222781438

Epoch: 6| Step: 11
Training loss: 2.510071277618408
Validation loss: 2.7699331929606776

Epoch: 6| Step: 12
Training loss: 3.4665825366973877
Validation loss: 2.7683598533753426

Epoch: 6| Step: 13
Training loss: 2.920323371887207
Validation loss: 2.7701492565934376

Epoch: 28| Step: 0
Training loss: 3.074028968811035
Validation loss: 2.767511055033694

Epoch: 6| Step: 1
Training loss: 2.9887378215789795
Validation loss: 2.7677063736864316

Epoch: 6| Step: 2
Training loss: 2.9139561653137207
Validation loss: 2.765882307483304

Epoch: 6| Step: 3
Training loss: 3.6317172050476074
Validation loss: 2.7646364088981383

Epoch: 6| Step: 4
Training loss: 2.8989243507385254
Validation loss: 2.7624075694750716

Epoch: 6| Step: 5
Training loss: 2.404954195022583
Validation loss: 2.7602415315566526

Epoch: 6| Step: 6
Training loss: 3.064249038696289
Validation loss: 2.7570503937300814

Epoch: 6| Step: 7
Training loss: 2.8035809993743896
Validation loss: 2.7568389215776996

Epoch: 6| Step: 8
Training loss: 2.3576111793518066
Validation loss: 2.7580794390811714

Epoch: 6| Step: 9
Training loss: 2.960594654083252
Validation loss: 2.7579125358212377

Epoch: 6| Step: 10
Training loss: 2.5839900970458984
Validation loss: 2.7565706878580074

Epoch: 6| Step: 11
Training loss: 3.1122775077819824
Validation loss: 2.754991054534912

Epoch: 6| Step: 12
Training loss: 3.215346097946167
Validation loss: 2.7509172501102572

Epoch: 6| Step: 13
Training loss: 2.4822025299072266
Validation loss: 2.745122822382117

Epoch: 29| Step: 0
Training loss: 3.6529715061187744
Validation loss: 2.7439823509544454

Epoch: 6| Step: 1
Training loss: 2.762211799621582
Validation loss: 2.7433032810047107

Epoch: 6| Step: 2
Training loss: 3.8915963172912598
Validation loss: 2.742929276599679

Epoch: 6| Step: 3
Training loss: 2.5148403644561768
Validation loss: 2.741789997264903

Epoch: 6| Step: 4
Training loss: 3.5038530826568604
Validation loss: 2.739621616178943

Epoch: 6| Step: 5
Training loss: 2.5780608654022217
Validation loss: 2.7380110115133305

Epoch: 6| Step: 6
Training loss: 2.5615015029907227
Validation loss: 2.7396160376969205

Epoch: 6| Step: 7
Training loss: 2.8293991088867188
Validation loss: 2.73651441707406

Epoch: 6| Step: 8
Training loss: 1.997334361076355
Validation loss: 2.7292634261551725

Epoch: 6| Step: 9
Training loss: 3.3253769874572754
Validation loss: 2.731290417332803

Epoch: 6| Step: 10
Training loss: 3.1301331520080566
Validation loss: 2.726167501941804

Epoch: 6| Step: 11
Training loss: 2.705843448638916
Validation loss: 2.7269240822843326

Epoch: 6| Step: 12
Training loss: 2.2118782997131348
Validation loss: 2.7261560475954445

Epoch: 6| Step: 13
Training loss: 2.6845052242279053
Validation loss: 2.7253805334850023

Epoch: 30| Step: 0
Training loss: 2.5624961853027344
Validation loss: 2.7224733162951726

Epoch: 6| Step: 1
Training loss: 2.5889525413513184
Validation loss: 2.7195333767962713

Epoch: 6| Step: 2
Training loss: 1.9912590980529785
Validation loss: 2.7208627218841226

Epoch: 6| Step: 3
Training loss: 3.226008415222168
Validation loss: 2.7198212710759972

Epoch: 6| Step: 4
Training loss: 3.073230266571045
Validation loss: 2.7176007045212613

Epoch: 6| Step: 5
Training loss: 3.264504909515381
Validation loss: 2.721130427493844

Epoch: 6| Step: 6
Training loss: 3.083950996398926
Validation loss: 2.7194689012342885

Epoch: 6| Step: 7
Training loss: 2.952155113220215
Validation loss: 2.7161783582420758

Epoch: 6| Step: 8
Training loss: 2.6038429737091064
Validation loss: 2.7172753272518033

Epoch: 6| Step: 9
Training loss: 3.0127391815185547
Validation loss: 2.719240186034992

Epoch: 6| Step: 10
Training loss: 3.2305397987365723
Validation loss: 2.7179710198474187

Epoch: 6| Step: 11
Training loss: 3.077376127243042
Validation loss: 2.7156199434752106

Epoch: 6| Step: 12
Training loss: 2.81937575340271
Validation loss: 2.710587078525174

Epoch: 6| Step: 13
Training loss: 2.700989007949829
Validation loss: 2.711571062764814

Epoch: 31| Step: 0
Training loss: 2.7542834281921387
Validation loss: 2.709972007300264

Epoch: 6| Step: 1
Training loss: 3.7309017181396484
Validation loss: 2.7087543497803392

Epoch: 6| Step: 2
Training loss: 2.498642683029175
Validation loss: 2.709120153098978

Epoch: 6| Step: 3
Training loss: 3.6636781692504883
Validation loss: 2.704779855666622

Epoch: 6| Step: 4
Training loss: 2.697033643722534
Validation loss: 2.705201771951491

Epoch: 6| Step: 5
Training loss: 2.8495237827301025
Validation loss: 2.7096820287807013

Epoch: 6| Step: 6
Training loss: 2.791079521179199
Validation loss: 2.7060168174005326

Epoch: 6| Step: 7
Training loss: 2.378169298171997
Validation loss: 2.7046815990119852

Epoch: 6| Step: 8
Training loss: 2.9201247692108154
Validation loss: 2.706866528398247

Epoch: 6| Step: 9
Training loss: 2.5343544483184814
Validation loss: 2.7039585254525624

Epoch: 6| Step: 10
Training loss: 2.8117122650146484
Validation loss: 2.706123593033001

Epoch: 6| Step: 11
Training loss: 2.887698173522949
Validation loss: 2.6999889445561234

Epoch: 6| Step: 12
Training loss: 3.147709846496582
Validation loss: 2.7026984947983936

Epoch: 6| Step: 13
Training loss: 2.213503837585449
Validation loss: 2.7046340075872277

Epoch: 32| Step: 0
Training loss: 2.121762275695801
Validation loss: 2.704655211458924

Epoch: 6| Step: 1
Training loss: 2.458827495574951
Validation loss: 2.7036387587106354

Epoch: 6| Step: 2
Training loss: 3.606856346130371
Validation loss: 2.707175272767262

Epoch: 6| Step: 3
Training loss: 2.4660122394561768
Validation loss: 2.7093547313444075

Epoch: 6| Step: 4
Training loss: 2.704996109008789
Validation loss: 2.709376714562857

Epoch: 6| Step: 5
Training loss: 2.9631717205047607
Validation loss: 2.7005997678285003

Epoch: 6| Step: 6
Training loss: 3.353750705718994
Validation loss: 2.692631806096723

Epoch: 6| Step: 7
Training loss: 3.0023345947265625
Validation loss: 2.69591454023956

Epoch: 6| Step: 8
Training loss: 3.602102279663086
Validation loss: 2.692693446272163

Epoch: 6| Step: 9
Training loss: 2.6757946014404297
Validation loss: 2.6936454080766246

Epoch: 6| Step: 10
Training loss: 3.1511998176574707
Validation loss: 2.6921776110126125

Epoch: 6| Step: 11
Training loss: 2.4979820251464844
Validation loss: 2.6958404382069907

Epoch: 6| Step: 12
Training loss: 2.8828296661376953
Validation loss: 2.689902308166668

Epoch: 6| Step: 13
Training loss: 2.371035575866699
Validation loss: 2.6946360001000027

Epoch: 33| Step: 0
Training loss: 2.5740103721618652
Validation loss: 2.693037120244836

Epoch: 6| Step: 1
Training loss: 3.09854793548584
Validation loss: 2.6965856782851683

Epoch: 6| Step: 2
Training loss: 2.770648956298828
Validation loss: 2.700548259160852

Epoch: 6| Step: 3
Training loss: 3.6911659240722656
Validation loss: 2.701499531345983

Epoch: 6| Step: 4
Training loss: 2.765294313430786
Validation loss: 2.692215547766737

Epoch: 6| Step: 5
Training loss: 2.7877540588378906
Validation loss: 2.6918849432340233

Epoch: 6| Step: 6
Training loss: 3.198401689529419
Validation loss: 2.691566582648985

Epoch: 6| Step: 7
Training loss: 1.613885521888733
Validation loss: 2.6944674009917886

Epoch: 6| Step: 8
Training loss: 3.587775707244873
Validation loss: 2.7027592915360645

Epoch: 6| Step: 9
Training loss: 3.349696636199951
Validation loss: 2.695902262964556

Epoch: 6| Step: 10
Training loss: 3.2979767322540283
Validation loss: 2.685052328212287

Epoch: 6| Step: 11
Training loss: 2.3130042552948
Validation loss: 2.6784195412871656

Epoch: 6| Step: 12
Training loss: 2.403862953186035
Validation loss: 2.690002105569327

Epoch: 6| Step: 13
Training loss: 2.184231996536255
Validation loss: 2.6937797736096125

Epoch: 34| Step: 0
Training loss: 2.4170801639556885
Validation loss: 2.701087651714202

Epoch: 6| Step: 1
Training loss: 2.0627870559692383
Validation loss: 2.7068090925934496

Epoch: 6| Step: 2
Training loss: 3.420290231704712
Validation loss: 2.694659891948905

Epoch: 6| Step: 3
Training loss: 3.005070447921753
Validation loss: 2.6787082277318484

Epoch: 6| Step: 4
Training loss: 2.5842854976654053
Validation loss: 2.679587730797388

Epoch: 6| Step: 5
Training loss: 2.801100730895996
Validation loss: 2.6826592645337506

Epoch: 6| Step: 6
Training loss: 3.1212515830993652
Validation loss: 2.6849326779765468

Epoch: 6| Step: 7
Training loss: 3.1321682929992676
Validation loss: 2.6832680830391507

Epoch: 6| Step: 8
Training loss: 2.509370803833008
Validation loss: 2.680186853613905

Epoch: 6| Step: 9
Training loss: 3.431499719619751
Validation loss: 2.6811467575770553

Epoch: 6| Step: 10
Training loss: 2.9954700469970703
Validation loss: 2.680171387169951

Epoch: 6| Step: 11
Training loss: 2.834799289703369
Validation loss: 2.681088432188957

Epoch: 6| Step: 12
Training loss: 2.783924102783203
Validation loss: 2.6841614759096535

Epoch: 6| Step: 13
Training loss: 2.8087401390075684
Validation loss: 2.6832072811741985

Epoch: 35| Step: 0
Training loss: 1.441190481185913
Validation loss: 2.6813672845081618

Epoch: 6| Step: 1
Training loss: 2.9622251987457275
Validation loss: 2.677583094566099

Epoch: 6| Step: 2
Training loss: 3.5899620056152344
Validation loss: 2.6752916279659478

Epoch: 6| Step: 3
Training loss: 3.1746878623962402
Validation loss: 2.6738276712356077

Epoch: 6| Step: 4
Training loss: 2.5352821350097656
Validation loss: 2.6719444182611283

Epoch: 6| Step: 5
Training loss: 1.828373670578003
Validation loss: 2.670417183188982

Epoch: 6| Step: 6
Training loss: 2.6203360557556152
Validation loss: 2.6687578206421225

Epoch: 6| Step: 7
Training loss: 3.190612554550171
Validation loss: 2.664843472101355

Epoch: 6| Step: 8
Training loss: 3.3991241455078125
Validation loss: 2.6668308217038392

Epoch: 6| Step: 9
Training loss: 3.4669113159179688
Validation loss: 2.6676041259560535

Epoch: 6| Step: 10
Training loss: 2.6294353008270264
Validation loss: 2.6632053570080827

Epoch: 6| Step: 11
Training loss: 3.0919647216796875
Validation loss: 2.6654876303929154

Epoch: 6| Step: 12
Training loss: 2.5516395568847656
Validation loss: 2.6633128017507572

Epoch: 6| Step: 13
Training loss: 3.594294309616089
Validation loss: 2.66606403422612

Epoch: 36| Step: 0
Training loss: 2.648812770843506
Validation loss: 2.6607829498988327

Epoch: 6| Step: 1
Training loss: 2.3164966106414795
Validation loss: 2.6599602494188535

Epoch: 6| Step: 2
Training loss: 2.4082014560699463
Validation loss: 2.663682194166286

Epoch: 6| Step: 3
Training loss: 2.7638165950775146
Validation loss: 2.664613077717443

Epoch: 6| Step: 4
Training loss: 2.373788833618164
Validation loss: 2.6630696673547067

Epoch: 6| Step: 5
Training loss: 2.7348811626434326
Validation loss: 2.6638539170706146

Epoch: 6| Step: 6
Training loss: 3.2518110275268555
Validation loss: 2.6631074566994943

Epoch: 6| Step: 7
Training loss: 3.497394561767578
Validation loss: 2.6619565076725458

Epoch: 6| Step: 8
Training loss: 2.9174752235412598
Validation loss: 2.6610264214136268

Epoch: 6| Step: 9
Training loss: 3.1294877529144287
Validation loss: 2.6594253765639437

Epoch: 6| Step: 10
Training loss: 2.774976968765259
Validation loss: 2.663580725269933

Epoch: 6| Step: 11
Training loss: 2.3579416275024414
Validation loss: 2.667112247918242

Epoch: 6| Step: 12
Training loss: 3.815861701965332
Validation loss: 2.666761875152588

Epoch: 6| Step: 13
Training loss: 2.5031046867370605
Validation loss: 2.664444077399469

Epoch: 37| Step: 0
Training loss: 3.154252052307129
Validation loss: 2.6622849843835317

Epoch: 6| Step: 1
Training loss: 1.8304619789123535
Validation loss: 2.65807423796705

Epoch: 6| Step: 2
Training loss: 2.3065946102142334
Validation loss: 2.6597307318000385

Epoch: 6| Step: 3
Training loss: 3.3634400367736816
Validation loss: 2.6533058022940033

Epoch: 6| Step: 4
Training loss: 3.1507744789123535
Validation loss: 2.6549560690438874

Epoch: 6| Step: 5
Training loss: 3.480386257171631
Validation loss: 2.6511071343575754

Epoch: 6| Step: 6
Training loss: 3.18983793258667
Validation loss: 2.653676179147536

Epoch: 6| Step: 7
Training loss: 2.401318073272705
Validation loss: 2.652884947356357

Epoch: 6| Step: 8
Training loss: 2.4234838485717773
Validation loss: 2.6522549147246988

Epoch: 6| Step: 9
Training loss: 2.824873208999634
Validation loss: 2.6451763030021422

Epoch: 6| Step: 10
Training loss: 3.637273073196411
Validation loss: 2.6474024711116666

Epoch: 6| Step: 11
Training loss: 2.7308621406555176
Validation loss: 2.6489252633945917

Epoch: 6| Step: 12
Training loss: 1.9456355571746826
Validation loss: 2.649564919933196

Epoch: 6| Step: 13
Training loss: 3.2248334884643555
Validation loss: 2.6537673319539716

Epoch: 38| Step: 0
Training loss: 3.6430211067199707
Validation loss: 2.655031027332429

Epoch: 6| Step: 1
Training loss: 3.044536828994751
Validation loss: 2.662561739644697

Epoch: 6| Step: 2
Training loss: 3.790369987487793
Validation loss: 2.662226487231511

Epoch: 6| Step: 3
Training loss: 2.8821773529052734
Validation loss: 2.649195368571948

Epoch: 6| Step: 4
Training loss: 2.5541882514953613
Validation loss: 2.6433774630228677

Epoch: 6| Step: 5
Training loss: 2.9153223037719727
Validation loss: 2.64541030955571

Epoch: 6| Step: 6
Training loss: 2.473869562149048
Validation loss: 2.646343549092611

Epoch: 6| Step: 7
Training loss: 2.760220766067505
Validation loss: 2.650131602441111

Epoch: 6| Step: 8
Training loss: 2.4925906658172607
Validation loss: 2.65009202495698

Epoch: 6| Step: 9
Training loss: 2.12988543510437
Validation loss: 2.6478636239164617

Epoch: 6| Step: 10
Training loss: 2.587566614151001
Validation loss: 2.636531999034266

Epoch: 6| Step: 11
Training loss: 2.397808074951172
Validation loss: 2.639107677244371

Epoch: 6| Step: 12
Training loss: 2.8160510063171387
Validation loss: 2.6409689739186275

Epoch: 6| Step: 13
Training loss: 3.1605045795440674
Validation loss: 2.6386674117016535

Epoch: 39| Step: 0
Training loss: 2.624586582183838
Validation loss: 2.640104155386648

Epoch: 6| Step: 1
Training loss: 3.3683457374572754
Validation loss: 2.6400588507293374

Epoch: 6| Step: 2
Training loss: 3.4540624618530273
Validation loss: 2.6379155497397146

Epoch: 6| Step: 3
Training loss: 3.6575849056243896
Validation loss: 2.64002130364859

Epoch: 6| Step: 4
Training loss: 2.4791464805603027
Validation loss: 2.6379688606467298

Epoch: 6| Step: 5
Training loss: 3.0615384578704834
Validation loss: 2.63689935335549

Epoch: 6| Step: 6
Training loss: 3.0575499534606934
Validation loss: 2.6367384003054712

Epoch: 6| Step: 7
Training loss: 2.7071175575256348
Validation loss: 2.639179939864784

Epoch: 6| Step: 8
Training loss: 2.1603188514709473
Validation loss: 2.635064201970254

Epoch: 6| Step: 9
Training loss: 2.912924289703369
Validation loss: 2.633806413219821

Epoch: 6| Step: 10
Training loss: 2.4443366527557373
Validation loss: 2.6353867489804506

Epoch: 6| Step: 11
Training loss: 3.071201801300049
Validation loss: 2.6351784275424097

Epoch: 6| Step: 12
Training loss: 2.5128979682922363
Validation loss: 2.63395171524376

Epoch: 6| Step: 13
Training loss: 1.1811015605926514
Validation loss: 2.638162274514475

Epoch: 40| Step: 0
Training loss: 3.0075368881225586
Validation loss: 2.641550402487478

Epoch: 6| Step: 1
Training loss: 2.406994342803955
Validation loss: 2.643654400302518

Epoch: 6| Step: 2
Training loss: 2.652656078338623
Validation loss: 2.643743263777866

Epoch: 6| Step: 3
Training loss: 3.056539297103882
Validation loss: 2.645997831898351

Epoch: 6| Step: 4
Training loss: 2.805757999420166
Validation loss: 2.6444353698402323

Epoch: 6| Step: 5
Training loss: 2.5171189308166504
Validation loss: 2.6402714739563646

Epoch: 6| Step: 6
Training loss: 3.518928050994873
Validation loss: 2.6330856354005876

Epoch: 6| Step: 7
Training loss: 2.6981465816497803
Validation loss: 2.629504819070139

Epoch: 6| Step: 8
Training loss: 2.978950023651123
Validation loss: 2.6282569746817313

Epoch: 6| Step: 9
Training loss: 2.8745479583740234
Validation loss: 2.625435916326379

Epoch: 6| Step: 10
Training loss: 2.2208614349365234
Validation loss: 2.6265051698171966

Epoch: 6| Step: 11
Training loss: 2.67606782913208
Validation loss: 2.626660790494693

Epoch: 6| Step: 12
Training loss: 3.2516841888427734
Validation loss: 2.6270085509105394

Epoch: 6| Step: 13
Training loss: 2.592804431915283
Validation loss: 2.6280154540974605

Epoch: 41| Step: 0
Training loss: 3.2251245975494385
Validation loss: 2.624214033926687

Epoch: 6| Step: 1
Training loss: 3.07191801071167
Validation loss: 2.622604282953406

Epoch: 6| Step: 2
Training loss: 2.1806533336639404
Validation loss: 2.6271667224104687

Epoch: 6| Step: 3
Training loss: 2.2137207984924316
Validation loss: 2.6311941557033087

Epoch: 6| Step: 4
Training loss: 3.575974941253662
Validation loss: 2.6361490885416665

Epoch: 6| Step: 5
Training loss: 2.674889326095581
Validation loss: 2.6323866075085056

Epoch: 6| Step: 6
Training loss: 2.8124890327453613
Validation loss: 2.6225179574822866

Epoch: 6| Step: 7
Training loss: 2.8380308151245117
Validation loss: 2.6204691522864887

Epoch: 6| Step: 8
Training loss: 3.483438491821289
Validation loss: 2.620808478324644

Epoch: 6| Step: 9
Training loss: 1.8317724466323853
Validation loss: 2.6179147125572286

Epoch: 6| Step: 10
Training loss: 2.6263985633850098
Validation loss: 2.6225260739685385

Epoch: 6| Step: 11
Training loss: 2.6228389739990234
Validation loss: 2.622422815651022

Epoch: 6| Step: 12
Training loss: 2.876990795135498
Validation loss: 2.623105231151786

Epoch: 6| Step: 13
Training loss: 3.5812902450561523
Validation loss: 2.6211450433218353

Epoch: 42| Step: 0
Training loss: 2.408710241317749
Validation loss: 2.616265212335894

Epoch: 6| Step: 1
Training loss: 2.7126221656799316
Validation loss: 2.619779812392368

Epoch: 6| Step: 2
Training loss: 2.9669787883758545
Validation loss: 2.6204312719324583

Epoch: 6| Step: 3
Training loss: 3.919861316680908
Validation loss: 2.6222563251372306

Epoch: 6| Step: 4
Training loss: 2.8819901943206787
Validation loss: 2.625793631358813

Epoch: 6| Step: 5
Training loss: 3.148704767227173
Validation loss: 2.6256126242299236

Epoch: 6| Step: 6
Training loss: 1.857371211051941
Validation loss: 2.62261018958143

Epoch: 6| Step: 7
Training loss: 2.928568124771118
Validation loss: 2.622324066777383

Epoch: 6| Step: 8
Training loss: 3.1925814151763916
Validation loss: 2.6194237662899877

Epoch: 6| Step: 9
Training loss: 2.098510980606079
Validation loss: 2.615496229099971

Epoch: 6| Step: 10
Training loss: 3.3964340686798096
Validation loss: 2.613541333906112

Epoch: 6| Step: 11
Training loss: 2.685990333557129
Validation loss: 2.612603869489444

Epoch: 6| Step: 12
Training loss: 2.5125155448913574
Validation loss: 2.6137366423042874

Epoch: 6| Step: 13
Training loss: 2.2257258892059326
Validation loss: 2.61451046441191

Epoch: 43| Step: 0
Training loss: 1.6390049457550049
Validation loss: 2.6133291080433834

Epoch: 6| Step: 1
Training loss: 3.2117855548858643
Validation loss: 2.615225140766431

Epoch: 6| Step: 2
Training loss: 2.8501908779144287
Validation loss: 2.6119663817908174

Epoch: 6| Step: 3
Training loss: 2.9150776863098145
Validation loss: 2.6132094296075965

Epoch: 6| Step: 4
Training loss: 2.542884349822998
Validation loss: 2.6142791060991186

Epoch: 6| Step: 5
Training loss: 2.81552791595459
Validation loss: 2.6133951166624665

Epoch: 6| Step: 6
Training loss: 3.7359094619750977
Validation loss: 2.6155203952584216

Epoch: 6| Step: 7
Training loss: 2.7793354988098145
Validation loss: 2.6151870655757126

Epoch: 6| Step: 8
Training loss: 3.094815254211426
Validation loss: 2.6146734068470616

Epoch: 6| Step: 9
Training loss: 2.9681529998779297
Validation loss: 2.616073695562219

Epoch: 6| Step: 10
Training loss: 2.653538227081299
Validation loss: 2.6116381768257386

Epoch: 6| Step: 11
Training loss: 2.4680519104003906
Validation loss: 2.612001616467712

Epoch: 6| Step: 12
Training loss: 2.484560012817383
Validation loss: 2.610474027613158

Epoch: 6| Step: 13
Training loss: 3.1314949989318848
Validation loss: 2.6104562564562728

Epoch: 44| Step: 0
Training loss: 2.4149985313415527
Validation loss: 2.6082463931011897

Epoch: 6| Step: 1
Training loss: 2.7380247116088867
Validation loss: 2.6109128177806897

Epoch: 6| Step: 2
Training loss: 3.376948833465576
Validation loss: 2.608719479653143

Epoch: 6| Step: 3
Training loss: 2.616637706756592
Validation loss: 2.6077435836997083

Epoch: 6| Step: 4
Training loss: 2.3236279487609863
Validation loss: 2.6091362071293656

Epoch: 6| Step: 5
Training loss: 2.532656192779541
Validation loss: 2.606722257470572

Epoch: 6| Step: 6
Training loss: 3.4802117347717285
Validation loss: 2.60691237449646

Epoch: 6| Step: 7
Training loss: 3.3538942337036133
Validation loss: 2.6087218253843245

Epoch: 6| Step: 8
Training loss: 3.489419460296631
Validation loss: 2.604322933381604

Epoch: 6| Step: 9
Training loss: 1.6177494525909424
Validation loss: 2.6090429059920774

Epoch: 6| Step: 10
Training loss: 3.0783727169036865
Validation loss: 2.607844829559326

Epoch: 6| Step: 11
Training loss: 2.2659871578216553
Validation loss: 2.605454465394379

Epoch: 6| Step: 12
Training loss: 3.0156567096710205
Validation loss: 2.6049038030767955

Epoch: 6| Step: 13
Training loss: 2.7458343505859375
Validation loss: 2.608300159054418

Epoch: 45| Step: 0
Training loss: 3.228139877319336
Validation loss: 2.6170130340001916

Epoch: 6| Step: 1
Training loss: 3.0291731357574463
Validation loss: 2.6110347547838764

Epoch: 6| Step: 2
Training loss: 1.8200225830078125
Validation loss: 2.6079523947931107

Epoch: 6| Step: 3
Training loss: 2.9942007064819336
Validation loss: 2.612093412747947

Epoch: 6| Step: 4
Training loss: 1.967846155166626
Validation loss: 2.612524755539433

Epoch: 6| Step: 5
Training loss: 2.6281418800354004
Validation loss: 2.6155134554832213

Epoch: 6| Step: 6
Training loss: 3.1371347904205322
Validation loss: 2.610742538206039

Epoch: 6| Step: 7
Training loss: 2.4376044273376465
Validation loss: 2.6071052012904996

Epoch: 6| Step: 8
Training loss: 2.4041366577148438
Validation loss: 2.607322741580266

Epoch: 6| Step: 9
Training loss: 3.898961067199707
Validation loss: 2.6032037504257692

Epoch: 6| Step: 10
Training loss: 3.0840225219726562
Validation loss: 2.602280673160348

Epoch: 6| Step: 11
Training loss: 2.6668953895568848
Validation loss: 2.604342688796341

Epoch: 6| Step: 12
Training loss: 2.78588604927063
Validation loss: 2.6082042160854546

Epoch: 6| Step: 13
Training loss: 3.0269546508789062
Validation loss: 2.614032783815938

Epoch: 46| Step: 0
Training loss: 2.7362899780273438
Validation loss: 2.6130703315939954

Epoch: 6| Step: 1
Training loss: 2.7905542850494385
Validation loss: 2.6085489257689445

Epoch: 6| Step: 2
Training loss: 3.2487361431121826
Validation loss: 2.6054034899639826

Epoch: 6| Step: 3
Training loss: 3.157395839691162
Validation loss: 2.602019895789444

Epoch: 6| Step: 4
Training loss: 1.5500504970550537
Validation loss: 2.6008005501121603

Epoch: 6| Step: 5
Training loss: 2.9675235748291016
Validation loss: 2.6096004286120014

Epoch: 6| Step: 6
Training loss: 3.1136324405670166
Validation loss: 2.6075755960197857

Epoch: 6| Step: 7
Training loss: 2.7885947227478027
Validation loss: 2.603532806519539

Epoch: 6| Step: 8
Training loss: 2.30741024017334
Validation loss: 2.604108936043196

Epoch: 6| Step: 9
Training loss: 2.926218271255493
Validation loss: 2.6089565177117624

Epoch: 6| Step: 10
Training loss: 2.9958853721618652
Validation loss: 2.60643292755209

Epoch: 6| Step: 11
Training loss: 3.1881422996520996
Validation loss: 2.6058674166279454

Epoch: 6| Step: 12
Training loss: 2.7578282356262207
Validation loss: 2.608185875800348

Epoch: 6| Step: 13
Training loss: 2.3040623664855957
Validation loss: 2.605642262325492

Epoch: 47| Step: 0
Training loss: 2.9067115783691406
Validation loss: 2.5995797546960975

Epoch: 6| Step: 1
Training loss: 2.548232316970825
Validation loss: 2.5984802989549536

Epoch: 6| Step: 2
Training loss: 1.977767825126648
Validation loss: 2.5979071253089496

Epoch: 6| Step: 3
Training loss: 2.501688241958618
Validation loss: 2.5979761564603416

Epoch: 6| Step: 4
Training loss: 3.730194091796875
Validation loss: 2.6040243205203804

Epoch: 6| Step: 5
Training loss: 3.5650877952575684
Validation loss: 2.6027736792000393

Epoch: 6| Step: 6
Training loss: 2.8065552711486816
Validation loss: 2.604219328972601

Epoch: 6| Step: 7
Training loss: 2.6562395095825195
Validation loss: 2.5976217485243276

Epoch: 6| Step: 8
Training loss: 2.9097635746002197
Validation loss: 2.5991083729651665

Epoch: 6| Step: 9
Training loss: 3.300222873687744
Validation loss: 2.600726601898029

Epoch: 6| Step: 10
Training loss: 2.188103199005127
Validation loss: 2.610465495817123

Epoch: 6| Step: 11
Training loss: 2.576357364654541
Validation loss: 2.619459311167399

Epoch: 6| Step: 12
Training loss: 2.5286943912506104
Validation loss: 2.6173162691054808

Epoch: 6| Step: 13
Training loss: 2.8173439502716064
Validation loss: 2.6187801514902422

Epoch: 48| Step: 0
Training loss: 1.9933056831359863
Validation loss: 2.6049129245101765

Epoch: 6| Step: 1
Training loss: 3.344752788543701
Validation loss: 2.6056126958580426

Epoch: 6| Step: 2
Training loss: 3.0408027172088623
Validation loss: 2.6059443155924478

Epoch: 6| Step: 3
Training loss: 2.8911194801330566
Validation loss: 2.612221307651971

Epoch: 6| Step: 4
Training loss: 2.0988078117370605
Validation loss: 2.617953764495029

Epoch: 6| Step: 5
Training loss: 2.899763822555542
Validation loss: 2.6351735950798116

Epoch: 6| Step: 6
Training loss: 2.8391923904418945
Validation loss: 2.6494604131226898

Epoch: 6| Step: 7
Training loss: 2.1310951709747314
Validation loss: 2.64339449585125

Epoch: 6| Step: 8
Training loss: 2.736527919769287
Validation loss: 2.638503756574405

Epoch: 6| Step: 9
Training loss: 3.678618907928467
Validation loss: 2.6235455056672454

Epoch: 6| Step: 10
Training loss: 2.6464762687683105
Validation loss: 2.6114615317313903

Epoch: 6| Step: 11
Training loss: 2.99764347076416
Validation loss: 2.598255326670985

Epoch: 6| Step: 12
Training loss: 2.6861209869384766
Validation loss: 2.5970341672179518

Epoch: 6| Step: 13
Training loss: 3.3793818950653076
Validation loss: 2.6047589317444833

Epoch: 49| Step: 0
Training loss: 2.8040223121643066
Validation loss: 2.606469251776254

Epoch: 6| Step: 1
Training loss: 1.95406973361969
Validation loss: 2.6123966093986266

Epoch: 6| Step: 2
Training loss: 2.3158462047576904
Validation loss: 2.6083003167183167

Epoch: 6| Step: 3
Training loss: 3.374131679534912
Validation loss: 2.6160671172603482

Epoch: 6| Step: 4
Training loss: 2.8639330863952637
Validation loss: 2.6097125545624764

Epoch: 6| Step: 5
Training loss: 3.282740354537964
Validation loss: 2.61071212573718

Epoch: 6| Step: 6
Training loss: 3.2897815704345703
Validation loss: 2.6050427600901616

Epoch: 6| Step: 7
Training loss: 2.7941176891326904
Validation loss: 2.6050043234261135

Epoch: 6| Step: 8
Training loss: 2.8510899543762207
Validation loss: 2.5997652648597636

Epoch: 6| Step: 9
Training loss: 2.2813916206359863
Validation loss: 2.5926760704286638

Epoch: 6| Step: 10
Training loss: 2.619335174560547
Validation loss: 2.5902588546917005

Epoch: 6| Step: 11
Training loss: 3.4840316772460938
Validation loss: 2.5924764615233227

Epoch: 6| Step: 12
Training loss: 2.0449788570404053
Validation loss: 2.5906673400632796

Epoch: 6| Step: 13
Training loss: 3.16286301612854
Validation loss: 2.5876724899456067

Epoch: 50| Step: 0
Training loss: 2.983940362930298
Validation loss: 2.5908880618310746

Epoch: 6| Step: 1
Training loss: 2.5736560821533203
Validation loss: 2.59253998725645

Epoch: 6| Step: 2
Training loss: 2.735306739807129
Validation loss: 2.5927009479973906

Epoch: 6| Step: 3
Training loss: 3.0211074352264404
Validation loss: 2.592531875897479

Epoch: 6| Step: 4
Training loss: 3.069953203201294
Validation loss: 2.5969265609659176

Epoch: 6| Step: 5
Training loss: 2.53663969039917
Validation loss: 2.5996480680281118

Epoch: 6| Step: 6
Training loss: 2.718562126159668
Validation loss: 2.6038959564701205

Epoch: 6| Step: 7
Training loss: 3.1415441036224365
Validation loss: 2.6034784624653478

Epoch: 6| Step: 8
Training loss: 2.1618845462799072
Validation loss: 2.5986318742075274

Epoch: 6| Step: 9
Training loss: 2.5453901290893555
Validation loss: 2.6156556196110223

Epoch: 6| Step: 10
Training loss: 2.5383028984069824
Validation loss: 2.621340746520668

Epoch: 6| Step: 11
Training loss: 3.3731675148010254
Validation loss: 2.6294439326050463

Epoch: 6| Step: 12
Training loss: 2.9846107959747314
Validation loss: 2.618721264664845

Epoch: 6| Step: 13
Training loss: 2.3603646755218506
Validation loss: 2.6059458589041107

Epoch: 51| Step: 0
Training loss: 3.6431593894958496
Validation loss: 2.603593739130164

Epoch: 6| Step: 1
Training loss: 3.254120349884033
Validation loss: 2.6030086932643766

Epoch: 6| Step: 2
Training loss: 2.8054308891296387
Validation loss: 2.591519578810661

Epoch: 6| Step: 3
Training loss: 2.833714008331299
Validation loss: 2.5913893612482215

Epoch: 6| Step: 4
Training loss: 2.776954412460327
Validation loss: 2.5840026665759344

Epoch: 6| Step: 5
Training loss: 2.2272019386291504
Validation loss: 2.583339506579984

Epoch: 6| Step: 6
Training loss: 3.444052219390869
Validation loss: 2.581149774212991

Epoch: 6| Step: 7
Training loss: 2.3428311347961426
Validation loss: 2.581763513626591

Epoch: 6| Step: 8
Training loss: 1.6165881156921387
Validation loss: 2.5824364590388473

Epoch: 6| Step: 9
Training loss: 2.887138843536377
Validation loss: 2.5845831158340618

Epoch: 6| Step: 10
Training loss: 3.304556369781494
Validation loss: 2.588136398664085

Epoch: 6| Step: 11
Training loss: 2.9919705390930176
Validation loss: 2.5905406346885105

Epoch: 6| Step: 12
Training loss: 2.118734836578369
Validation loss: 2.5916075270663024

Epoch: 6| Step: 13
Training loss: 2.553788900375366
Validation loss: 2.588683420611966

Epoch: 52| Step: 0
Training loss: 1.7821669578552246
Validation loss: 2.586245777786419

Epoch: 6| Step: 1
Training loss: 2.1051628589630127
Validation loss: 2.5856217158738004

Epoch: 6| Step: 2
Training loss: 3.264690399169922
Validation loss: 2.5818672923631567

Epoch: 6| Step: 3
Training loss: 2.972127914428711
Validation loss: 2.5805676803793958

Epoch: 6| Step: 4
Training loss: 2.6306276321411133
Validation loss: 2.5853083441334386

Epoch: 6| Step: 5
Training loss: 3.0526018142700195
Validation loss: 2.589502053876077

Epoch: 6| Step: 6
Training loss: 2.7453107833862305
Validation loss: 2.590305656515142

Epoch: 6| Step: 7
Training loss: 2.337029457092285
Validation loss: 2.5920478784909813

Epoch: 6| Step: 8
Training loss: 2.484066963195801
Validation loss: 2.591636324441561

Epoch: 6| Step: 9
Training loss: 2.8654260635375977
Validation loss: 2.5894220106063353

Epoch: 6| Step: 10
Training loss: 2.7642102241516113
Validation loss: 2.58864511212995

Epoch: 6| Step: 11
Training loss: 3.6422338485717773
Validation loss: 2.5854404664808706

Epoch: 6| Step: 12
Training loss: 2.7232699394226074
Validation loss: 2.5827003038057716

Epoch: 6| Step: 13
Training loss: 3.97855281829834
Validation loss: 2.577998843244327

Epoch: 53| Step: 0
Training loss: 3.1003170013427734
Validation loss: 2.5785437681341685

Epoch: 6| Step: 1
Training loss: 2.3818798065185547
Validation loss: 2.5759294545778664

Epoch: 6| Step: 2
Training loss: 3.8535850048065186
Validation loss: 2.576742402968868

Epoch: 6| Step: 3
Training loss: 3.1446805000305176
Validation loss: 2.5770134848933064

Epoch: 6| Step: 4
Training loss: 2.1554133892059326
Validation loss: 2.576265840120213

Epoch: 6| Step: 5
Training loss: 2.3070878982543945
Validation loss: 2.5752864678700766

Epoch: 6| Step: 6
Training loss: 2.5860633850097656
Validation loss: 2.5766003413866927

Epoch: 6| Step: 7
Training loss: 2.241380214691162
Validation loss: 2.5771488605007047

Epoch: 6| Step: 8
Training loss: 3.276186943054199
Validation loss: 2.577851785126553

Epoch: 6| Step: 9
Training loss: 2.481297492980957
Validation loss: 2.5815307427478094

Epoch: 6| Step: 10
Training loss: 2.0774993896484375
Validation loss: 2.5841844363879134

Epoch: 6| Step: 11
Training loss: 3.1414942741394043
Validation loss: 2.586616272567421

Epoch: 6| Step: 12
Training loss: 2.8360581398010254
Validation loss: 2.5830609234430457

Epoch: 6| Step: 13
Training loss: 3.5331850051879883
Validation loss: 2.5787935820958947

Epoch: 54| Step: 0
Training loss: 2.3025431632995605
Validation loss: 2.5714670355601976

Epoch: 6| Step: 1
Training loss: 3.1030044555664062
Validation loss: 2.5731766121361845

Epoch: 6| Step: 2
Training loss: 2.531693696975708
Validation loss: 2.577507600989393

Epoch: 6| Step: 3
Training loss: 2.839205741882324
Validation loss: 2.5755738442943943

Epoch: 6| Step: 4
Training loss: 2.2824084758758545
Validation loss: 2.5747939437948246

Epoch: 6| Step: 5
Training loss: 2.631558895111084
Validation loss: 2.5732819290571314

Epoch: 6| Step: 6
Training loss: 2.8659508228302
Validation loss: 2.5763520553547847

Epoch: 6| Step: 7
Training loss: 2.9037561416625977
Validation loss: 2.5757027492728284

Epoch: 6| Step: 8
Training loss: 3.632188558578491
Validation loss: 2.577837727403128

Epoch: 6| Step: 9
Training loss: 3.4513931274414062
Validation loss: 2.578291103404055

Epoch: 6| Step: 10
Training loss: 2.3011670112609863
Validation loss: 2.5737050271803334

Epoch: 6| Step: 11
Training loss: 2.8221917152404785
Validation loss: 2.5782635083762546

Epoch: 6| Step: 12
Training loss: 1.791365623474121
Validation loss: 2.5756670915952293

Epoch: 6| Step: 13
Training loss: 3.5653393268585205
Validation loss: 2.5739118463249615

Epoch: 55| Step: 0
Training loss: 2.1034741401672363
Validation loss: 2.576340731754098

Epoch: 6| Step: 1
Training loss: 2.8063912391662598
Validation loss: 2.5754059104509253

Epoch: 6| Step: 2
Training loss: 2.50693941116333
Validation loss: 2.5766325073857463

Epoch: 6| Step: 3
Training loss: 2.336707353591919
Validation loss: 2.5763957795276435

Epoch: 6| Step: 4
Training loss: 2.5490188598632812
Validation loss: 2.581068456813853

Epoch: 6| Step: 5
Training loss: 2.76322603225708
Validation loss: 2.5877621635313957

Epoch: 6| Step: 6
Training loss: 2.7861876487731934
Validation loss: 2.5935421143808672

Epoch: 6| Step: 7
Training loss: 2.7326197624206543
Validation loss: 2.5945868081943964

Epoch: 6| Step: 8
Training loss: 2.878591537475586
Validation loss: 2.5945308285374797

Epoch: 6| Step: 9
Training loss: 2.03407621383667
Validation loss: 2.5795376685357865

Epoch: 6| Step: 10
Training loss: 2.8780062198638916
Validation loss: 2.5739687950380388

Epoch: 6| Step: 11
Training loss: 3.2445335388183594
Validation loss: 2.570489537331366

Epoch: 6| Step: 12
Training loss: 3.926177978515625
Validation loss: 2.5671569121781217

Epoch: 6| Step: 13
Training loss: 3.31009840965271
Validation loss: 2.5652610460917153

Epoch: 56| Step: 0
Training loss: 3.0948326587677
Validation loss: 2.566076470959571

Epoch: 6| Step: 1
Training loss: 2.6662020683288574
Validation loss: 2.569715469114242

Epoch: 6| Step: 2
Training loss: 2.0836169719696045
Validation loss: 2.568963748152538

Epoch: 6| Step: 3
Training loss: 3.0690383911132812
Validation loss: 2.5745354980550785

Epoch: 6| Step: 4
Training loss: 2.1427574157714844
Validation loss: 2.573846709343695

Epoch: 6| Step: 5
Training loss: 2.3405630588531494
Validation loss: 2.5730889228082474

Epoch: 6| Step: 6
Training loss: 2.458529472351074
Validation loss: 2.572870123770929

Epoch: 6| Step: 7
Training loss: 2.5262391567230225
Validation loss: 2.5710855376335884

Epoch: 6| Step: 8
Training loss: 2.9464197158813477
Validation loss: 2.569404996851439

Epoch: 6| Step: 9
Training loss: 2.5220630168914795
Validation loss: 2.569477709390784

Epoch: 6| Step: 10
Training loss: 3.542558431625366
Validation loss: 2.5636149606397076

Epoch: 6| Step: 11
Training loss: 3.221240997314453
Validation loss: 2.5599222977956138

Epoch: 6| Step: 12
Training loss: 3.1715474128723145
Validation loss: 2.5605017087792836

Epoch: 6| Step: 13
Training loss: 2.8985347747802734
Validation loss: 2.5617916712196926

Epoch: 57| Step: 0
Training loss: 2.3616819381713867
Validation loss: 2.5603423144227717

Epoch: 6| Step: 1
Training loss: 2.523662805557251
Validation loss: 2.5608751030378443

Epoch: 6| Step: 2
Training loss: 2.4134559631347656
Validation loss: 2.5683289856039067

Epoch: 6| Step: 3
Training loss: 2.976990222930908
Validation loss: 2.56286116825637

Epoch: 6| Step: 4
Training loss: 1.893827199935913
Validation loss: 2.5670198343133412

Epoch: 6| Step: 5
Training loss: 2.9361660480499268
Validation loss: 2.5674121584943546

Epoch: 6| Step: 6
Training loss: 3.3170793056488037
Validation loss: 2.566403217213128

Epoch: 6| Step: 7
Training loss: 3.0733485221862793
Validation loss: 2.5666231468159664

Epoch: 6| Step: 8
Training loss: 2.887709617614746
Validation loss: 2.569548688909059

Epoch: 6| Step: 9
Training loss: 2.7053403854370117
Validation loss: 2.565745105025589

Epoch: 6| Step: 10
Training loss: 3.1925506591796875
Validation loss: 2.5670299478756484

Epoch: 6| Step: 11
Training loss: 2.6824941635131836
Validation loss: 2.5721936020799863

Epoch: 6| Step: 12
Training loss: 2.8580880165100098
Validation loss: 2.5762336536120345

Epoch: 6| Step: 13
Training loss: 2.8275015354156494
Validation loss: 2.575387144601473

Epoch: 58| Step: 0
Training loss: 2.678713083267212
Validation loss: 2.5665166249839206

Epoch: 6| Step: 1
Training loss: 3.519167900085449
Validation loss: 2.5649372980158818

Epoch: 6| Step: 2
Training loss: 3.392284870147705
Validation loss: 2.561540044764037

Epoch: 6| Step: 3
Training loss: 2.4250102043151855
Validation loss: 2.5603332186257965

Epoch: 6| Step: 4
Training loss: 2.720954656600952
Validation loss: 2.57320596069418

Epoch: 6| Step: 5
Training loss: 3.3005876541137695
Validation loss: 2.5697805035498833

Epoch: 6| Step: 6
Training loss: 2.880770206451416
Validation loss: 2.5645806404852096

Epoch: 6| Step: 7
Training loss: 2.995145320892334
Validation loss: 2.5635194342623473

Epoch: 6| Step: 8
Training loss: 2.7166943550109863
Validation loss: 2.559649021394791

Epoch: 6| Step: 9
Training loss: 2.5611228942871094
Validation loss: 2.5557851970836682

Epoch: 6| Step: 10
Training loss: 3.063856363296509
Validation loss: 2.5591721611638225

Epoch: 6| Step: 11
Training loss: 2.136197566986084
Validation loss: 2.562298138936361

Epoch: 6| Step: 12
Training loss: 2.0766048431396484
Validation loss: 2.5608045593384774

Epoch: 6| Step: 13
Training loss: 1.6829333305358887
Validation loss: 2.561828164644139

Epoch: 59| Step: 0
Training loss: 2.404794454574585
Validation loss: 2.559532698764596

Epoch: 6| Step: 1
Training loss: 2.8755829334259033
Validation loss: 2.5625424077433925

Epoch: 6| Step: 2
Training loss: 2.290499687194824
Validation loss: 2.5662239264416438

Epoch: 6| Step: 3
Training loss: 3.235150098800659
Validation loss: 2.5754567294992428

Epoch: 6| Step: 4
Training loss: 2.861283302307129
Validation loss: 2.5847171173300794

Epoch: 6| Step: 5
Training loss: 2.756502151489258
Validation loss: 2.583020051320394

Epoch: 6| Step: 6
Training loss: 3.132481575012207
Validation loss: 2.573648550177133

Epoch: 6| Step: 7
Training loss: 2.391481399536133
Validation loss: 2.5720013187777613

Epoch: 6| Step: 8
Training loss: 3.4609572887420654
Validation loss: 2.5725962859328075

Epoch: 6| Step: 9
Training loss: 2.9435579776763916
Validation loss: 2.5651619254901843

Epoch: 6| Step: 10
Training loss: 2.309556484222412
Validation loss: 2.562664447292205

Epoch: 6| Step: 11
Training loss: 2.949225902557373
Validation loss: 2.554629619403552

Epoch: 6| Step: 12
Training loss: 2.5003662109375
Validation loss: 2.5482603170538463

Epoch: 6| Step: 13
Training loss: 2.3155171871185303
Validation loss: 2.5464757001528175

Epoch: 60| Step: 0
Training loss: 2.069474220275879
Validation loss: 2.542580384080128

Epoch: 6| Step: 1
Training loss: 2.916135549545288
Validation loss: 2.5459623311155584

Epoch: 6| Step: 2
Training loss: 3.382631778717041
Validation loss: 2.5468997263139292

Epoch: 6| Step: 3
Training loss: 2.6670479774475098
Validation loss: 2.5452330497003373

Epoch: 6| Step: 4
Training loss: 2.3265557289123535
Validation loss: 2.547545891936107

Epoch: 6| Step: 5
Training loss: 3.0324528217315674
Validation loss: 2.546348715341219

Epoch: 6| Step: 6
Training loss: 2.530553102493286
Validation loss: 2.5458178238202165

Epoch: 6| Step: 7
Training loss: 2.245893955230713
Validation loss: 2.540678447292697

Epoch: 6| Step: 8
Training loss: 2.277039051055908
Validation loss: 2.5296250069013206

Epoch: 6| Step: 9
Training loss: 2.8307881355285645
Validation loss: 2.5275789204464165

Epoch: 6| Step: 10
Training loss: 3.2938756942749023
Validation loss: 2.5249449540210027

Epoch: 6| Step: 11
Training loss: 3.137136697769165
Validation loss: 2.528051132796913

Epoch: 6| Step: 12
Training loss: 2.9292373657226562
Validation loss: 2.527491943810576

Epoch: 6| Step: 13
Training loss: 2.647397994995117
Validation loss: 2.5272202132850565

Epoch: 61| Step: 0
Training loss: 2.714156150817871
Validation loss: 2.5268348519520094

Epoch: 6| Step: 1
Training loss: 2.8155019283294678
Validation loss: 2.5256660676771596

Epoch: 6| Step: 2
Training loss: 2.788606882095337
Validation loss: 2.5262712124855287

Epoch: 6| Step: 3
Training loss: 3.267016887664795
Validation loss: 2.525600582040766

Epoch: 6| Step: 4
Training loss: 2.4290411472320557
Validation loss: 2.524266299381051

Epoch: 6| Step: 5
Training loss: 2.5124218463897705
Validation loss: 2.525025752282912

Epoch: 6| Step: 6
Training loss: 2.6154799461364746
Validation loss: 2.52239663370194

Epoch: 6| Step: 7
Training loss: 2.557816982269287
Validation loss: 2.5212224106634817

Epoch: 6| Step: 8
Training loss: 3.3780012130737305
Validation loss: 2.5223415436283236

Epoch: 6| Step: 9
Training loss: 2.4024720191955566
Validation loss: 2.5220530135657198

Epoch: 6| Step: 10
Training loss: 2.602041721343994
Validation loss: 2.5241675479437715

Epoch: 6| Step: 11
Training loss: 2.943740129470825
Validation loss: 2.5265277072947514

Epoch: 6| Step: 12
Training loss: 2.443368911743164
Validation loss: 2.5256411695993073

Epoch: 6| Step: 13
Training loss: 2.7546045780181885
Validation loss: 2.524385654798118

Epoch: 62| Step: 0
Training loss: 2.9608633518218994
Validation loss: 2.5232375334667903

Epoch: 6| Step: 1
Training loss: 2.823759078979492
Validation loss: 2.525509936835176

Epoch: 6| Step: 2
Training loss: 3.5364725589752197
Validation loss: 2.522459699261573

Epoch: 6| Step: 3
Training loss: 3.305163860321045
Validation loss: 2.5226581814468547

Epoch: 6| Step: 4
Training loss: 2.085674285888672
Validation loss: 2.5121692098597044

Epoch: 6| Step: 5
Training loss: 2.705738067626953
Validation loss: 2.514937190599339

Epoch: 6| Step: 6
Training loss: 2.822232246398926
Validation loss: 2.517257469956593

Epoch: 6| Step: 7
Training loss: 3.0093801021575928
Validation loss: 2.514144597514983

Epoch: 6| Step: 8
Training loss: 3.0676889419555664
Validation loss: 2.5165025905896257

Epoch: 6| Step: 9
Training loss: 2.8104517459869385
Validation loss: 2.5158113074559036

Epoch: 6| Step: 10
Training loss: 2.5170369148254395
Validation loss: 2.5159602703586703

Epoch: 6| Step: 11
Training loss: 2.123234748840332
Validation loss: 2.5161487389636297

Epoch: 6| Step: 12
Training loss: 2.0793027877807617
Validation loss: 2.517505940570626

Epoch: 6| Step: 13
Training loss: 1.929007887840271
Validation loss: 2.5156373003477692

Epoch: 63| Step: 0
Training loss: 2.9032750129699707
Validation loss: 2.520081845662927

Epoch: 6| Step: 1
Training loss: 2.6259169578552246
Validation loss: 2.5163907774033083

Epoch: 6| Step: 2
Training loss: 2.925611734390259
Validation loss: 2.518285902597571

Epoch: 6| Step: 3
Training loss: 2.1513872146606445
Validation loss: 2.5172935044893654

Epoch: 6| Step: 4
Training loss: 3.0657544136047363
Validation loss: 2.5222967747719056

Epoch: 6| Step: 5
Training loss: 3.1499691009521484
Validation loss: 2.518057915472215

Epoch: 6| Step: 6
Training loss: 2.3039259910583496
Validation loss: 2.51917177631009

Epoch: 6| Step: 7
Training loss: 2.2226240634918213
Validation loss: 2.517879475829422

Epoch: 6| Step: 8
Training loss: 2.3255739212036133
Validation loss: 2.5143873435194775

Epoch: 6| Step: 9
Training loss: 2.3137803077697754
Validation loss: 2.5122154323003625

Epoch: 6| Step: 10
Training loss: 3.403005599975586
Validation loss: 2.5202006755336637

Epoch: 6| Step: 11
Training loss: 3.0255327224731445
Validation loss: 2.5204592212553947

Epoch: 6| Step: 12
Training loss: 2.980818510055542
Validation loss: 2.510135204561295

Epoch: 6| Step: 13
Training loss: 2.580066204071045
Validation loss: 2.5116436173838954

Epoch: 64| Step: 0
Training loss: 2.3909897804260254
Validation loss: 2.515569830453524

Epoch: 6| Step: 1
Training loss: 2.799191474914551
Validation loss: 2.5141399393799486

Epoch: 6| Step: 2
Training loss: 2.2417593002319336
Validation loss: 2.5109287718290925

Epoch: 6| Step: 3
Training loss: 2.352714776992798
Validation loss: 2.5190852560022825

Epoch: 6| Step: 4
Training loss: 3.366140365600586
Validation loss: 2.519132073207568

Epoch: 6| Step: 5
Training loss: 2.6111865043640137
Validation loss: 2.515301722352223

Epoch: 6| Step: 6
Training loss: 2.894019365310669
Validation loss: 2.513708640170354

Epoch: 6| Step: 7
Training loss: 2.4549102783203125
Validation loss: 2.5130965773777296

Epoch: 6| Step: 8
Training loss: 2.453434944152832
Validation loss: 2.5116141906348606

Epoch: 6| Step: 9
Training loss: 2.5882277488708496
Validation loss: 2.515098935814314

Epoch: 6| Step: 10
Training loss: 2.717097043991089
Validation loss: 2.515466267062772

Epoch: 6| Step: 11
Training loss: 3.5740838050842285
Validation loss: 2.5198640361908944

Epoch: 6| Step: 12
Training loss: 2.6489851474761963
Validation loss: 2.518924936171501

Epoch: 6| Step: 13
Training loss: 3.32612681388855
Validation loss: 2.523276416204309

Epoch: 65| Step: 0
Training loss: 2.5608859062194824
Validation loss: 2.5182069706660446

Epoch: 6| Step: 1
Training loss: 2.9725069999694824
Validation loss: 2.5218629042307534

Epoch: 6| Step: 2
Training loss: 2.602339267730713
Validation loss: 2.526696907576694

Epoch: 6| Step: 3
Training loss: 2.6535024642944336
Validation loss: 2.5260706024785198

Epoch: 6| Step: 4
Training loss: 2.7940707206726074
Validation loss: 2.5159665846055552

Epoch: 6| Step: 5
Training loss: 2.166775703430176
Validation loss: 2.511700161041752

Epoch: 6| Step: 6
Training loss: 2.6606316566467285
Validation loss: 2.5082752576438327

Epoch: 6| Step: 7
Training loss: 3.529978036880493
Validation loss: 2.5025088735806045

Epoch: 6| Step: 8
Training loss: 2.638077735900879
Validation loss: 2.5002971618406233

Epoch: 6| Step: 9
Training loss: 2.517068862915039
Validation loss: 2.5040005535207768

Epoch: 6| Step: 10
Training loss: 3.279305934906006
Validation loss: 2.5063068046364734

Epoch: 6| Step: 11
Training loss: 2.2785346508026123
Validation loss: 2.515495131092687

Epoch: 6| Step: 12
Training loss: 2.6250619888305664
Validation loss: 2.515589142358431

Epoch: 6| Step: 13
Training loss: 2.911067485809326
Validation loss: 2.5148338758817284

Epoch: 66| Step: 0
Training loss: 2.7433242797851562
Validation loss: 2.508385581354941

Epoch: 6| Step: 1
Training loss: 2.5885839462280273
Validation loss: 2.5027397576198784

Epoch: 6| Step: 2
Training loss: 2.198991060256958
Validation loss: 2.5028191125521095

Epoch: 6| Step: 3
Training loss: 2.7242822647094727
Validation loss: 2.505469755459857

Epoch: 6| Step: 4
Training loss: 2.631619930267334
Validation loss: 2.497666561475364

Epoch: 6| Step: 5
Training loss: 3.3118650913238525
Validation loss: 2.4965171455055155

Epoch: 6| Step: 6
Training loss: 2.856971502304077
Validation loss: 2.504015919982746

Epoch: 6| Step: 7
Training loss: 2.8284997940063477
Validation loss: 2.5053054132769184

Epoch: 6| Step: 8
Training loss: 2.1928493976593018
Validation loss: 2.5097782214482627

Epoch: 6| Step: 9
Training loss: 2.4619357585906982
Validation loss: 2.510626241724978

Epoch: 6| Step: 10
Training loss: 2.908186435699463
Validation loss: 2.520319636150073

Epoch: 6| Step: 11
Training loss: 2.8907055854797363
Validation loss: 2.5309289168286067

Epoch: 6| Step: 12
Training loss: 3.1571874618530273
Validation loss: 2.5378081798553467

Epoch: 6| Step: 13
Training loss: 2.14569354057312
Validation loss: 2.533253180083408

Epoch: 67| Step: 0
Training loss: 3.5478391647338867
Validation loss: 2.5504267164455947

Epoch: 6| Step: 1
Training loss: 3.0996346473693848
Validation loss: 2.536866960986968

Epoch: 6| Step: 2
Training loss: 3.6166536808013916
Validation loss: 2.5189893912243586

Epoch: 6| Step: 3
Training loss: 2.870713472366333
Validation loss: 2.5090771195709065

Epoch: 6| Step: 4
Training loss: 2.290121555328369
Validation loss: 2.5022819234478857

Epoch: 6| Step: 5
Training loss: 1.8470420837402344
Validation loss: 2.4990884001537035

Epoch: 6| Step: 6
Training loss: 2.6262946128845215
Validation loss: 2.4993370181770733

Epoch: 6| Step: 7
Training loss: 3.213674545288086
Validation loss: 2.4992035588910504

Epoch: 6| Step: 8
Training loss: 3.004481077194214
Validation loss: 2.5002144587937223

Epoch: 6| Step: 9
Training loss: 2.3871493339538574
Validation loss: 2.4964572434784262

Epoch: 6| Step: 10
Training loss: 2.213149309158325
Validation loss: 2.4929364983753493

Epoch: 6| Step: 11
Training loss: 2.4227793216705322
Validation loss: 2.492756658984769

Epoch: 6| Step: 12
Training loss: 2.067645788192749
Validation loss: 2.4950474154564644

Epoch: 6| Step: 13
Training loss: 2.756084442138672
Validation loss: 2.498188154671782

Epoch: 68| Step: 0
Training loss: 2.6903669834136963
Validation loss: 2.4929077932911534

Epoch: 6| Step: 1
Training loss: 2.636948347091675
Validation loss: 2.4886582179736068

Epoch: 6| Step: 2
Training loss: 2.6663379669189453
Validation loss: 2.4909128963306384

Epoch: 6| Step: 3
Training loss: 2.6132445335388184
Validation loss: 2.495489872911925

Epoch: 6| Step: 4
Training loss: 2.8193588256835938
Validation loss: 2.4946173493580153

Epoch: 6| Step: 5
Training loss: 3.048123598098755
Validation loss: 2.491404325731339

Epoch: 6| Step: 6
Training loss: 3.1410186290740967
Validation loss: 2.4897844765775945

Epoch: 6| Step: 7
Training loss: 2.472881317138672
Validation loss: 2.4934285404861614

Epoch: 6| Step: 8
Training loss: 2.6085269451141357
Validation loss: 2.498779119983796

Epoch: 6| Step: 9
Training loss: 2.2758824825286865
Validation loss: 2.5010961460810837

Epoch: 6| Step: 10
Training loss: 2.825396776199341
Validation loss: 2.505086273275396

Epoch: 6| Step: 11
Training loss: 2.7729814052581787
Validation loss: 2.5071123851242887

Epoch: 6| Step: 12
Training loss: 2.516378879547119
Validation loss: 2.506606594208748

Epoch: 6| Step: 13
Training loss: 2.7627429962158203
Validation loss: 2.496732355445944

Epoch: 69| Step: 0
Training loss: 2.4315989017486572
Validation loss: 2.4942067720556773

Epoch: 6| Step: 1
Training loss: 2.7454960346221924
Validation loss: 2.4898668232784478

Epoch: 6| Step: 2
Training loss: 2.5970025062561035
Validation loss: 2.489054395306495

Epoch: 6| Step: 3
Training loss: 3.534717082977295
Validation loss: 2.484652044952557

Epoch: 6| Step: 4
Training loss: 2.3730995655059814
Validation loss: 2.485144022972353

Epoch: 6| Step: 5
Training loss: 2.0911812782287598
Validation loss: 2.4835239584727953

Epoch: 6| Step: 6
Training loss: 3.2212648391723633
Validation loss: 2.4952936698031682

Epoch: 6| Step: 7
Training loss: 2.2345073223114014
Validation loss: 2.493220067793323

Epoch: 6| Step: 8
Training loss: 2.9111268520355225
Validation loss: 2.4915403807035057

Epoch: 6| Step: 9
Training loss: 3.034820079803467
Validation loss: 2.486088319491315

Epoch: 6| Step: 10
Training loss: 2.5487349033355713
Validation loss: 2.4869839350382485

Epoch: 6| Step: 11
Training loss: 2.174971103668213
Validation loss: 2.482950525899087

Epoch: 6| Step: 12
Training loss: 3.259504795074463
Validation loss: 2.487854573034471

Epoch: 6| Step: 13
Training loss: 2.6278905868530273
Validation loss: 2.4904286041054675

Epoch: 70| Step: 0
Training loss: 1.8156428337097168
Validation loss: 2.4842269548805813

Epoch: 6| Step: 1
Training loss: 2.462790012359619
Validation loss: 2.4895671003608295

Epoch: 6| Step: 2
Training loss: 2.6533656120300293
Validation loss: 2.497201960573914

Epoch: 6| Step: 3
Training loss: 2.8112897872924805
Validation loss: 2.4907490053484516

Epoch: 6| Step: 4
Training loss: 1.6915254592895508
Validation loss: 2.489962654729043

Epoch: 6| Step: 5
Training loss: 2.8024885654449463
Validation loss: 2.495948742794734

Epoch: 6| Step: 6
Training loss: 2.683600902557373
Validation loss: 2.495335150790471

Epoch: 6| Step: 7
Training loss: 3.5577495098114014
Validation loss: 2.4988486792451594

Epoch: 6| Step: 8
Training loss: 2.6871838569641113
Validation loss: 2.498339614560527

Epoch: 6| Step: 9
Training loss: 3.2073402404785156
Validation loss: 2.4966824080354426

Epoch: 6| Step: 10
Training loss: 2.8373570442199707
Validation loss: 2.4886382882313063

Epoch: 6| Step: 11
Training loss: 3.239896535873413
Validation loss: 2.483476459339101

Epoch: 6| Step: 12
Training loss: 2.3254127502441406
Validation loss: 2.4843215916746404

Epoch: 6| Step: 13
Training loss: 3.211836576461792
Validation loss: 2.496426723336661

Epoch: 71| Step: 0
Training loss: 3.765017509460449
Validation loss: 2.492029336190993

Epoch: 6| Step: 1
Training loss: 2.133549928665161
Validation loss: 2.484600587557721

Epoch: 6| Step: 2
Training loss: 2.367478847503662
Validation loss: 2.483379876741799

Epoch: 6| Step: 3
Training loss: 3.314746379852295
Validation loss: 2.481694552206224

Epoch: 6| Step: 4
Training loss: 1.9354922771453857
Validation loss: 2.4867773748213247

Epoch: 6| Step: 5
Training loss: 2.0980124473571777
Validation loss: 2.4864957255701863

Epoch: 6| Step: 6
Training loss: 2.7375340461730957
Validation loss: 2.4848850260498705

Epoch: 6| Step: 7
Training loss: 2.2292675971984863
Validation loss: 2.485340646518174

Epoch: 6| Step: 8
Training loss: 3.0363545417785645
Validation loss: 2.486126240863595

Epoch: 6| Step: 9
Training loss: 2.3561387062072754
Validation loss: 2.4840592543284097

Epoch: 6| Step: 10
Training loss: 2.5975022315979004
Validation loss: 2.4800222663469214

Epoch: 6| Step: 11
Training loss: 2.9384922981262207
Validation loss: 2.4822380337663876

Epoch: 6| Step: 12
Training loss: 2.9711475372314453
Validation loss: 2.4846914404182026

Epoch: 6| Step: 13
Training loss: 3.647444009780884
Validation loss: 2.4798476311468307

Epoch: 72| Step: 0
Training loss: 2.4719607830047607
Validation loss: 2.4842173719918854

Epoch: 6| Step: 1
Training loss: 2.3766539096832275
Validation loss: 2.4820191885835383

Epoch: 6| Step: 2
Training loss: 2.243004322052002
Validation loss: 2.4821748759156916

Epoch: 6| Step: 3
Training loss: 2.724829912185669
Validation loss: 2.4847272698597243

Epoch: 6| Step: 4
Training loss: 3.469038724899292
Validation loss: 2.488769890159689

Epoch: 6| Step: 5
Training loss: 3.0315756797790527
Validation loss: 2.4870980888284664

Epoch: 6| Step: 6
Training loss: 3.085301399230957
Validation loss: 2.483488141849477

Epoch: 6| Step: 7
Training loss: 2.819581985473633
Validation loss: 2.478866589966641

Epoch: 6| Step: 8
Training loss: 2.8250794410705566
Validation loss: 2.4741836542724283

Epoch: 6| Step: 9
Training loss: 2.0326647758483887
Validation loss: 2.477317366548764

Epoch: 6| Step: 10
Training loss: 2.3567605018615723
Validation loss: 2.4777973185303392

Epoch: 6| Step: 11
Training loss: 2.9192209243774414
Validation loss: 2.476700859685098

Epoch: 6| Step: 12
Training loss: 2.6402032375335693
Validation loss: 2.4790441528443368

Epoch: 6| Step: 13
Training loss: 2.7569358348846436
Validation loss: 2.4819748401641846

Epoch: 73| Step: 0
Training loss: 2.6433465480804443
Validation loss: 2.4789322806942846

Epoch: 6| Step: 1
Training loss: 2.3372373580932617
Validation loss: 2.4797814943457164

Epoch: 6| Step: 2
Training loss: 2.9236176013946533
Validation loss: 2.4783674927167993

Epoch: 6| Step: 3
Training loss: 2.3416450023651123
Validation loss: 2.478887532346992

Epoch: 6| Step: 4
Training loss: 2.617356300354004
Validation loss: 2.482390090983401

Epoch: 6| Step: 5
Training loss: 3.226386070251465
Validation loss: 2.484398006111063

Epoch: 6| Step: 6
Training loss: 3.172356367111206
Validation loss: 2.4785045039269233

Epoch: 6| Step: 7
Training loss: 3.064025640487671
Validation loss: 2.483235072064143

Epoch: 6| Step: 8
Training loss: 2.5308680534362793
Validation loss: 2.4828427325012865

Epoch: 6| Step: 9
Training loss: 2.5103001594543457
Validation loss: 2.4810367784192486

Epoch: 6| Step: 10
Training loss: 2.485874891281128
Validation loss: 2.4774608483878513

Epoch: 6| Step: 11
Training loss: 2.9333138465881348
Validation loss: 2.4813800832276702

Epoch: 6| Step: 12
Training loss: 2.2479472160339355
Validation loss: 2.4758497284304712

Epoch: 6| Step: 13
Training loss: 2.542529344558716
Validation loss: 2.476989781984719

Epoch: 74| Step: 0
Training loss: 2.2587780952453613
Validation loss: 2.4782056962290118

Epoch: 6| Step: 1
Training loss: 2.3240208625793457
Validation loss: 2.4790611959272817

Epoch: 6| Step: 2
Training loss: 2.8587749004364014
Validation loss: 2.477694570377309

Epoch: 6| Step: 3
Training loss: 2.25439453125
Validation loss: 2.4772133724663847

Epoch: 6| Step: 4
Training loss: 3.0365519523620605
Validation loss: 2.4808707365425686

Epoch: 6| Step: 5
Training loss: 2.80961012840271
Validation loss: 2.486379482412851

Epoch: 6| Step: 6
Training loss: 3.146958351135254
Validation loss: 2.4767427034275507

Epoch: 6| Step: 7
Training loss: 2.897589683532715
Validation loss: 2.4781108902346705

Epoch: 6| Step: 8
Training loss: 3.067289352416992
Validation loss: 2.479804854239187

Epoch: 6| Step: 9
Training loss: 3.056363105773926
Validation loss: 2.477846917285714

Epoch: 6| Step: 10
Training loss: 2.4616808891296387
Validation loss: 2.4751034705869612

Epoch: 6| Step: 11
Training loss: 3.008824110031128
Validation loss: 2.4695145186557563

Epoch: 6| Step: 12
Training loss: 2.174393653869629
Validation loss: 2.4698789376084522

Epoch: 6| Step: 13
Training loss: 1.9544332027435303
Validation loss: 2.47316074884066

Epoch: 75| Step: 0
Training loss: 2.07900333404541
Validation loss: 2.4755223592122397

Epoch: 6| Step: 1
Training loss: 2.5839102268218994
Validation loss: 2.4768187692088466

Epoch: 6| Step: 2
Training loss: 2.3547561168670654
Validation loss: 2.4828046803833335

Epoch: 6| Step: 3
Training loss: 3.0813164710998535
Validation loss: 2.5019742545261177

Epoch: 6| Step: 4
Training loss: 2.1928207874298096
Validation loss: 2.498056310479359

Epoch: 6| Step: 5
Training loss: 2.645031452178955
Validation loss: 2.4986315799015824

Epoch: 6| Step: 6
Training loss: 2.689239263534546
Validation loss: 2.497936079579015

Epoch: 6| Step: 7
Training loss: 3.153247833251953
Validation loss: 2.4945350180390062

Epoch: 6| Step: 8
Training loss: 3.0021705627441406
Validation loss: 2.489249224303871

Epoch: 6| Step: 9
Training loss: 2.766204357147217
Validation loss: 2.4808454539186213

Epoch: 6| Step: 10
Training loss: 3.0671653747558594
Validation loss: 2.472424243086128

Epoch: 6| Step: 11
Training loss: 2.607755184173584
Validation loss: 2.474653559346353

Epoch: 6| Step: 12
Training loss: 2.917064905166626
Validation loss: 2.4712393104389148

Epoch: 6| Step: 13
Training loss: 2.475534439086914
Validation loss: 2.480188854279057

Epoch: 76| Step: 0
Training loss: 3.8898258209228516
Validation loss: 2.4716633583909724

Epoch: 6| Step: 1
Training loss: 3.5388147830963135
Validation loss: 2.4721315958166636

Epoch: 6| Step: 2
Training loss: 1.6773741245269775
Validation loss: 2.4715380412276073

Epoch: 6| Step: 3
Training loss: 2.6022729873657227
Validation loss: 2.4695098989753315

Epoch: 6| Step: 4
Training loss: 3.4262702465057373
Validation loss: 2.4679916084453626

Epoch: 6| Step: 5
Training loss: 2.0622634887695312
Validation loss: 2.4659392192799556

Epoch: 6| Step: 6
Training loss: 2.346548557281494
Validation loss: 2.4668423360393894

Epoch: 6| Step: 7
Training loss: 2.406078815460205
Validation loss: 2.4692592223485312

Epoch: 6| Step: 8
Training loss: 2.082547664642334
Validation loss: 2.463281910906556

Epoch: 6| Step: 9
Training loss: 3.191734790802002
Validation loss: 2.4691477642264417

Epoch: 6| Step: 10
Training loss: 2.501659870147705
Validation loss: 2.4691091481075493

Epoch: 6| Step: 11
Training loss: 2.610257387161255
Validation loss: 2.4702246881300405

Epoch: 6| Step: 12
Training loss: 2.7460289001464844
Validation loss: 2.4731103758658133

Epoch: 6| Step: 13
Training loss: 2.4301939010620117
Validation loss: 2.47470514235958

Epoch: 77| Step: 0
Training loss: 2.663203001022339
Validation loss: 2.47726591684485

Epoch: 6| Step: 1
Training loss: 3.0244626998901367
Validation loss: 2.4835032416928198

Epoch: 6| Step: 2
Training loss: 3.0518195629119873
Validation loss: 2.4911136896379533

Epoch: 6| Step: 3
Training loss: 2.2493176460266113
Validation loss: 2.4941230589343655

Epoch: 6| Step: 4
Training loss: 1.761161208152771
Validation loss: 2.498157265365765

Epoch: 6| Step: 5
Training loss: 2.5224833488464355
Validation loss: 2.4924606687279156

Epoch: 6| Step: 6
Training loss: 2.659947395324707
Validation loss: 2.4752532718002156

Epoch: 6| Step: 7
Training loss: 3.3141746520996094
Validation loss: 2.4695639764108965

Epoch: 6| Step: 8
Training loss: 2.1689462661743164
Validation loss: 2.4692203614019577

Epoch: 6| Step: 9
Training loss: 3.3793816566467285
Validation loss: 2.467474945129887

Epoch: 6| Step: 10
Training loss: 2.551625967025757
Validation loss: 2.4626135159564275

Epoch: 6| Step: 11
Training loss: 2.3576149940490723
Validation loss: 2.4618745183431976

Epoch: 6| Step: 12
Training loss: 3.045368194580078
Validation loss: 2.4652304828807874

Epoch: 6| Step: 13
Training loss: 3.1443657875061035
Validation loss: 2.4645834917663247

Epoch: 78| Step: 0
Training loss: 2.4308886528015137
Validation loss: 2.462929435955581

Epoch: 6| Step: 1
Training loss: 2.729609727859497
Validation loss: 2.4641415944663425

Epoch: 6| Step: 2
Training loss: 3.0077099800109863
Validation loss: 2.462275807575513

Epoch: 6| Step: 3
Training loss: 3.208343744277954
Validation loss: 2.4644978354054112

Epoch: 6| Step: 4
Training loss: 2.377598762512207
Validation loss: 2.464032955067132

Epoch: 6| Step: 5
Training loss: 2.739830255508423
Validation loss: 2.4681557583552536

Epoch: 6| Step: 6
Training loss: 2.775118827819824
Validation loss: 2.4633929780734483

Epoch: 6| Step: 7
Training loss: 3.1064975261688232
Validation loss: 2.468884741106341

Epoch: 6| Step: 8
Training loss: 2.7756690979003906
Validation loss: 2.4646362848179315

Epoch: 6| Step: 9
Training loss: 2.5597214698791504
Validation loss: 2.4677550843966904

Epoch: 6| Step: 10
Training loss: 2.4288225173950195
Validation loss: 2.472131929089946

Epoch: 6| Step: 11
Training loss: 2.6478075981140137
Validation loss: 2.472980437740203

Epoch: 6| Step: 12
Training loss: 2.2677104473114014
Validation loss: 2.472457278159357

Epoch: 6| Step: 13
Training loss: 2.4178290367126465
Validation loss: 2.471299981558195

Epoch: 79| Step: 0
Training loss: 1.9790478944778442
Validation loss: 2.4808423493498113

Epoch: 6| Step: 1
Training loss: 2.783992290496826
Validation loss: 2.4764519929885864

Epoch: 6| Step: 2
Training loss: 2.274441719055176
Validation loss: 2.480000267746628

Epoch: 6| Step: 3
Training loss: 2.5776758193969727
Validation loss: 2.4834211667378745

Epoch: 6| Step: 4
Training loss: 2.855318069458008
Validation loss: 2.473822368088589

Epoch: 6| Step: 5
Training loss: 2.2197513580322266
Validation loss: 2.482207623861169

Epoch: 6| Step: 6
Training loss: 3.4167301654815674
Validation loss: 2.479000711953768

Epoch: 6| Step: 7
Training loss: 2.586491584777832
Validation loss: 2.4760109711718816

Epoch: 6| Step: 8
Training loss: 2.647170066833496
Validation loss: 2.4765677452087402

Epoch: 6| Step: 9
Training loss: 2.9616353511810303
Validation loss: 2.476524435063844

Epoch: 6| Step: 10
Training loss: 2.3437929153442383
Validation loss: 2.4754059391637004

Epoch: 6| Step: 11
Training loss: 2.584510564804077
Validation loss: 2.4768036129654094

Epoch: 6| Step: 12
Training loss: 3.225759506225586
Validation loss: 2.4737083886259343

Epoch: 6| Step: 13
Training loss: 3.3828256130218506
Validation loss: 2.4711777164090063

Epoch: 80| Step: 0
Training loss: 2.1940102577209473
Validation loss: 2.4758891110779135

Epoch: 6| Step: 1
Training loss: 2.564286470413208
Validation loss: 2.4753647158222813

Epoch: 6| Step: 2
Training loss: 2.9066107273101807
Validation loss: 2.4727304776509604

Epoch: 6| Step: 3
Training loss: 2.7134788036346436
Validation loss: 2.476418695142192

Epoch: 6| Step: 4
Training loss: 2.483933448791504
Validation loss: 2.482040810328658

Epoch: 6| Step: 5
Training loss: 3.837242364883423
Validation loss: 2.4836239660939863

Epoch: 6| Step: 6
Training loss: 1.986963152885437
Validation loss: 2.4866112124535347

Epoch: 6| Step: 7
Training loss: 3.5215115547180176
Validation loss: 2.486135798115884

Epoch: 6| Step: 8
Training loss: 2.8910839557647705
Validation loss: 2.483377666883571

Epoch: 6| Step: 9
Training loss: 2.735044479370117
Validation loss: 2.476990376749346

Epoch: 6| Step: 10
Training loss: 2.4492592811584473
Validation loss: 2.466041890523767

Epoch: 6| Step: 11
Training loss: 2.1541059017181396
Validation loss: 2.4733699598620014

Epoch: 6| Step: 12
Training loss: 2.5112295150756836
Validation loss: 2.4713176604240172

Epoch: 6| Step: 13
Training loss: 2.6480870246887207
Validation loss: 2.4659903280196653

Epoch: 81| Step: 0
Training loss: 1.9395335912704468
Validation loss: 2.468623238225137

Epoch: 6| Step: 1
Training loss: 2.7958381175994873
Validation loss: 2.47129641297043

Epoch: 6| Step: 2
Training loss: 2.9632630348205566
Validation loss: 2.468377867052632

Epoch: 6| Step: 3
Training loss: 2.953456163406372
Validation loss: 2.4692272217042985

Epoch: 6| Step: 4
Training loss: 2.8044400215148926
Validation loss: 2.4697655452195035

Epoch: 6| Step: 5
Training loss: 2.6838064193725586
Validation loss: 2.4648484670987694

Epoch: 6| Step: 6
Training loss: 1.7916004657745361
Validation loss: 2.4618610951208297

Epoch: 6| Step: 7
Training loss: 3.446004867553711
Validation loss: 2.462182883293398

Epoch: 6| Step: 8
Training loss: 3.173731803894043
Validation loss: 2.4624545651097454

Epoch: 6| Step: 9
Training loss: 2.7624645233154297
Validation loss: 2.471543247981738

Epoch: 6| Step: 10
Training loss: 1.6363104581832886
Validation loss: 2.4698672627889984

Epoch: 6| Step: 11
Training loss: 2.994217872619629
Validation loss: 2.4732085453566683

Epoch: 6| Step: 12
Training loss: 3.030299663543701
Validation loss: 2.4678153043152182

Epoch: 6| Step: 13
Training loss: 2.518707752227783
Validation loss: 2.4756651873229654

Epoch: 82| Step: 0
Training loss: 2.920044422149658
Validation loss: 2.468599473276446

Epoch: 6| Step: 1
Training loss: 3.114305019378662
Validation loss: 2.464750741117744

Epoch: 6| Step: 2
Training loss: 3.3526666164398193
Validation loss: 2.4651558296654814

Epoch: 6| Step: 3
Training loss: 1.9586284160614014
Validation loss: 2.457670409192321

Epoch: 6| Step: 4
Training loss: 1.99165678024292
Validation loss: 2.4552893151519117

Epoch: 6| Step: 5
Training loss: 3.3439290523529053
Validation loss: 2.4545511173945602

Epoch: 6| Step: 6
Training loss: 1.8244096040725708
Validation loss: 2.4539471159699144

Epoch: 6| Step: 7
Training loss: 1.8996957540512085
Validation loss: 2.4572191546040196

Epoch: 6| Step: 8
Training loss: 2.683323860168457
Validation loss: 2.4561646907560286

Epoch: 6| Step: 9
Training loss: 3.163558006286621
Validation loss: 2.4635266552689257

Epoch: 6| Step: 10
Training loss: 2.235396146774292
Validation loss: 2.4709593031996038

Epoch: 6| Step: 11
Training loss: 3.7526445388793945
Validation loss: 2.4702280849538822

Epoch: 6| Step: 12
Training loss: 2.4831225872039795
Validation loss: 2.482106536947271

Epoch: 6| Step: 13
Training loss: 2.965296745300293
Validation loss: 2.466255280279344

Epoch: 83| Step: 0
Training loss: 2.759509325027466
Validation loss: 2.472549802513533

Epoch: 6| Step: 1
Training loss: 3.0417869091033936
Validation loss: 2.4659253243477113

Epoch: 6| Step: 2
Training loss: 2.306715965270996
Validation loss: 2.4647377126960346

Epoch: 6| Step: 3
Training loss: 2.1776392459869385
Validation loss: 2.4604595117671515

Epoch: 6| Step: 4
Training loss: 2.216525077819824
Validation loss: 2.4563846985499063

Epoch: 6| Step: 5
Training loss: 2.181675434112549
Validation loss: 2.4509538296730287

Epoch: 6| Step: 6
Training loss: 3.2831649780273438
Validation loss: 2.450245180437642

Epoch: 6| Step: 7
Training loss: 3.2870397567749023
Validation loss: 2.4535553532262004

Epoch: 6| Step: 8
Training loss: 3.1540768146514893
Validation loss: 2.4578633359683457

Epoch: 6| Step: 9
Training loss: 2.610473871231079
Validation loss: 2.451024023435449

Epoch: 6| Step: 10
Training loss: 2.685086965560913
Validation loss: 2.447550396765432

Epoch: 6| Step: 11
Training loss: 2.972043514251709
Validation loss: 2.4484290435749996

Epoch: 6| Step: 12
Training loss: 2.5407216548919678
Validation loss: 2.453386950236495

Epoch: 6| Step: 13
Training loss: 1.8199083805084229
Validation loss: 2.4505430318975963

Epoch: 84| Step: 0
Training loss: 2.3496761322021484
Validation loss: 2.4574459752728863

Epoch: 6| Step: 1
Training loss: 2.8266286849975586
Validation loss: 2.4575811252799085

Epoch: 6| Step: 2
Training loss: 2.307216167449951
Validation loss: 2.4660178692110124

Epoch: 6| Step: 3
Training loss: 1.9970636367797852
Validation loss: 2.4599743530314457

Epoch: 6| Step: 4
Training loss: 3.5890679359436035
Validation loss: 2.4595293665444977

Epoch: 6| Step: 5
Training loss: 2.022834539413452
Validation loss: 2.4632161740333802

Epoch: 6| Step: 6
Training loss: 2.606933116912842
Validation loss: 2.4585978984832764

Epoch: 6| Step: 7
Training loss: 2.5502848625183105
Validation loss: 2.4573330802302205

Epoch: 6| Step: 8
Training loss: 2.928900718688965
Validation loss: 2.4524317992630826

Epoch: 6| Step: 9
Training loss: 3.631276845932007
Validation loss: 2.453434095587782

Epoch: 6| Step: 10
Training loss: 2.8550705909729004
Validation loss: 2.4586032436740015

Epoch: 6| Step: 11
Training loss: 2.7257883548736572
Validation loss: 2.4515732257596907

Epoch: 6| Step: 12
Training loss: 2.8628571033477783
Validation loss: 2.4541692836310274

Epoch: 6| Step: 13
Training loss: 1.793438196182251
Validation loss: 2.4582414216892694

Epoch: 85| Step: 0
Training loss: 2.513367176055908
Validation loss: 2.4531564507433163

Epoch: 6| Step: 1
Training loss: 3.4694411754608154
Validation loss: 2.4613435370947725

Epoch: 6| Step: 2
Training loss: 3.440345287322998
Validation loss: 2.46072071085694

Epoch: 6| Step: 3
Training loss: 2.5312037467956543
Validation loss: 2.4607586040291736

Epoch: 6| Step: 4
Training loss: 2.779064178466797
Validation loss: 2.461462487456619

Epoch: 6| Step: 5
Training loss: 2.540740489959717
Validation loss: 2.4665926400051323

Epoch: 6| Step: 6
Training loss: 2.758983612060547
Validation loss: 2.4579962402261715

Epoch: 6| Step: 7
Training loss: 2.8141722679138184
Validation loss: 2.455802789298437

Epoch: 6| Step: 8
Training loss: 2.050321102142334
Validation loss: 2.4539633822697464

Epoch: 6| Step: 9
Training loss: 2.1747918128967285
Validation loss: 2.4525488909854682

Epoch: 6| Step: 10
Training loss: 2.6203651428222656
Validation loss: 2.4580178876076975

Epoch: 6| Step: 11
Training loss: 2.4435977935791016
Validation loss: 2.456602745158698

Epoch: 6| Step: 12
Training loss: 2.486865997314453
Validation loss: 2.451516875656702

Epoch: 6| Step: 13
Training loss: 2.79620623588562
Validation loss: 2.45350557245234

Epoch: 86| Step: 0
Training loss: 3.5504722595214844
Validation loss: 2.4549255627457813

Epoch: 6| Step: 1
Training loss: 2.286064386367798
Validation loss: 2.4545027876412995

Epoch: 6| Step: 2
Training loss: 2.8150181770324707
Validation loss: 2.45465374249284

Epoch: 6| Step: 3
Training loss: 2.3825645446777344
Validation loss: 2.4564832948869273

Epoch: 6| Step: 4
Training loss: 3.163268566131592
Validation loss: 2.453451894944714

Epoch: 6| Step: 5
Training loss: 3.3014674186706543
Validation loss: 2.45351077664283

Epoch: 6| Step: 6
Training loss: 1.8892041444778442
Validation loss: 2.462427067500289

Epoch: 6| Step: 7
Training loss: 2.232358932495117
Validation loss: 2.4572949499212284

Epoch: 6| Step: 8
Training loss: 2.6005806922912598
Validation loss: 2.4571403636727283

Epoch: 6| Step: 9
Training loss: 3.274691104888916
Validation loss: 2.452220642438499

Epoch: 6| Step: 10
Training loss: 3.247084140777588
Validation loss: 2.457383437823224

Epoch: 6| Step: 11
Training loss: 2.259869337081909
Validation loss: 2.4584792044854935

Epoch: 6| Step: 12
Training loss: 2.2763378620147705
Validation loss: 2.44920091987938

Epoch: 6| Step: 13
Training loss: 1.5376615524291992
Validation loss: 2.4555918914015575

Epoch: 87| Step: 0
Training loss: 1.885513186454773
Validation loss: 2.45234247689606

Epoch: 6| Step: 1
Training loss: 2.500542163848877
Validation loss: 2.457313237651702

Epoch: 6| Step: 2
Training loss: 2.4739797115325928
Validation loss: 2.4548433339723976

Epoch: 6| Step: 3
Training loss: 2.6172196865081787
Validation loss: 2.456002691740631

Epoch: 6| Step: 4
Training loss: 3.086656093597412
Validation loss: 2.4550585977492796

Epoch: 6| Step: 5
Training loss: 2.7514190673828125
Validation loss: 2.455336093902588

Epoch: 6| Step: 6
Training loss: 1.615656852722168
Validation loss: 2.459081821544196

Epoch: 6| Step: 7
Training loss: 2.8323779106140137
Validation loss: 2.46431468379113

Epoch: 6| Step: 8
Training loss: 3.4615702629089355
Validation loss: 2.4654742261414886

Epoch: 6| Step: 9
Training loss: 2.999793529510498
Validation loss: 2.464774062556605

Epoch: 6| Step: 10
Training loss: 3.0014214515686035
Validation loss: 2.467925848499421

Epoch: 6| Step: 11
Training loss: 2.7932682037353516
Validation loss: 2.4608913442139984

Epoch: 6| Step: 12
Training loss: 2.6445393562316895
Validation loss: 2.462276061375936

Epoch: 6| Step: 13
Training loss: 2.7202048301696777
Validation loss: 2.4568336394525345

Epoch: 88| Step: 0
Training loss: 3.166074514389038
Validation loss: 2.4540507562698854

Epoch: 6| Step: 1
Training loss: 2.2988154888153076
Validation loss: 2.459625969650925

Epoch: 6| Step: 2
Training loss: 2.7799835205078125
Validation loss: 2.4573662588673253

Epoch: 6| Step: 3
Training loss: 2.850445508956909
Validation loss: 2.456746470543646

Epoch: 6| Step: 4
Training loss: 2.3446593284606934
Validation loss: 2.455582595640613

Epoch: 6| Step: 5
Training loss: 2.6393442153930664
Validation loss: 2.4550738103928103

Epoch: 6| Step: 6
Training loss: 2.2461020946502686
Validation loss: 2.4570139428620696

Epoch: 6| Step: 7
Training loss: 2.578035831451416
Validation loss: 2.4511709725984963

Epoch: 6| Step: 8
Training loss: 3.103952646255493
Validation loss: 2.452539937470549

Epoch: 6| Step: 9
Training loss: 2.781996011734009
Validation loss: 2.449635931240615

Epoch: 6| Step: 10
Training loss: 2.850705623626709
Validation loss: 2.455594801133679

Epoch: 6| Step: 11
Training loss: 2.485441207885742
Validation loss: 2.451768716176351

Epoch: 6| Step: 12
Training loss: 2.589995861053467
Validation loss: 2.4525784702711206

Epoch: 6| Step: 13
Training loss: 2.512990951538086
Validation loss: 2.4512450105400494

Epoch: 89| Step: 0
Training loss: 3.186631679534912
Validation loss: 2.454959956548547

Epoch: 6| Step: 1
Training loss: 1.8757481575012207
Validation loss: 2.452486458645072

Epoch: 6| Step: 2
Training loss: 3.2484469413757324
Validation loss: 2.4535422914771625

Epoch: 6| Step: 3
Training loss: 2.899538040161133
Validation loss: 2.4554814189992924

Epoch: 6| Step: 4
Training loss: 2.782409429550171
Validation loss: 2.4528732979169456

Epoch: 6| Step: 5
Training loss: 2.5285286903381348
Validation loss: 2.4521387161747104

Epoch: 6| Step: 6
Training loss: 2.901599884033203
Validation loss: 2.4519416388644966

Epoch: 6| Step: 7
Training loss: 2.637847423553467
Validation loss: 2.452821911022227

Epoch: 6| Step: 8
Training loss: 2.352536678314209
Validation loss: 2.450036969236148

Epoch: 6| Step: 9
Training loss: 3.3834080696105957
Validation loss: 2.4479169461034958

Epoch: 6| Step: 10
Training loss: 2.4182729721069336
Validation loss: 2.444705481170326

Epoch: 6| Step: 11
Training loss: 2.664523124694824
Validation loss: 2.4468613029808126

Epoch: 6| Step: 12
Training loss: 2.51193904876709
Validation loss: 2.441699061342465

Epoch: 6| Step: 13
Training loss: 1.3023320436477661
Validation loss: 2.443359690327798

Epoch: 90| Step: 0
Training loss: 2.613839626312256
Validation loss: 2.4524121848485803

Epoch: 6| Step: 1
Training loss: 3.432781219482422
Validation loss: 2.4560603531458045

Epoch: 6| Step: 2
Training loss: 2.543184280395508
Validation loss: 2.468485962960028

Epoch: 6| Step: 3
Training loss: 2.6634902954101562
Validation loss: 2.462930638303039

Epoch: 6| Step: 4
Training loss: 3.0005922317504883
Validation loss: 2.4660391064100367

Epoch: 6| Step: 5
Training loss: 2.9873783588409424
Validation loss: 2.463031538071171

Epoch: 6| Step: 6
Training loss: 2.3969526290893555
Validation loss: 2.45892656746731

Epoch: 6| Step: 7
Training loss: 2.0713813304901123
Validation loss: 2.443517774663946

Epoch: 6| Step: 8
Training loss: 2.369964599609375
Validation loss: 2.452531986339118

Epoch: 6| Step: 9
Training loss: 2.5837347507476807
Validation loss: 2.4436975961090415

Epoch: 6| Step: 10
Training loss: 2.388956069946289
Validation loss: 2.4418152557906283

Epoch: 6| Step: 11
Training loss: 3.153944730758667
Validation loss: 2.4417788444026822

Epoch: 6| Step: 12
Training loss: 2.240280866622925
Validation loss: 2.4394335951856387

Epoch: 6| Step: 13
Training loss: 3.013313055038452
Validation loss: 2.447028442095685

Epoch: 91| Step: 0
Training loss: 2.469831943511963
Validation loss: 2.45602076027983

Epoch: 6| Step: 1
Training loss: 1.9487783908843994
Validation loss: 2.4628067785693752

Epoch: 6| Step: 2
Training loss: 2.4705042839050293
Validation loss: 2.4784082084573726

Epoch: 6| Step: 3
Training loss: 3.1595962047576904
Validation loss: 2.4838590186129332

Epoch: 6| Step: 4
Training loss: 3.3561387062072754
Validation loss: 2.480320757435214

Epoch: 6| Step: 5
Training loss: 2.2741384506225586
Validation loss: 2.46158109172698

Epoch: 6| Step: 6
Training loss: 1.6615748405456543
Validation loss: 2.445576419112503

Epoch: 6| Step: 7
Training loss: 3.3308682441711426
Validation loss: 2.4469362663966354

Epoch: 6| Step: 8
Training loss: 2.9853062629699707
Validation loss: 2.444665344812537

Epoch: 6| Step: 9
Training loss: 2.8289384841918945
Validation loss: 2.457807138401975

Epoch: 6| Step: 10
Training loss: 2.929741621017456
Validation loss: 2.450769211656304

Epoch: 6| Step: 11
Training loss: 2.877871513366699
Validation loss: 2.4624784966950775

Epoch: 6| Step: 12
Training loss: 2.490436553955078
Validation loss: 2.461811819384175

Epoch: 6| Step: 13
Training loss: 2.66117525100708
Validation loss: 2.460256458610617

Epoch: 92| Step: 0
Training loss: 2.6718590259552
Validation loss: 2.4464562682695288

Epoch: 6| Step: 1
Training loss: 1.7503941059112549
Validation loss: 2.4389495567608903

Epoch: 6| Step: 2
Training loss: 2.531792402267456
Validation loss: 2.435369009612709

Epoch: 6| Step: 3
Training loss: 1.9745627641677856
Validation loss: 2.4338577806308703

Epoch: 6| Step: 4
Training loss: 2.7518310546875
Validation loss: 2.438458606760989

Epoch: 6| Step: 5
Training loss: 2.3414578437805176
Validation loss: 2.433152461564669

Epoch: 6| Step: 6
Training loss: 2.713628053665161
Validation loss: 2.436429949216945

Epoch: 6| Step: 7
Training loss: 3.046262741088867
Validation loss: 2.4386248921835296

Epoch: 6| Step: 8
Training loss: 3.132399797439575
Validation loss: 2.4424529460168656

Epoch: 6| Step: 9
Training loss: 2.837315082550049
Validation loss: 2.4457069045753888

Epoch: 6| Step: 10
Training loss: 2.5065553188323975
Validation loss: 2.4422479316752446

Epoch: 6| Step: 11
Training loss: 3.1375813484191895
Validation loss: 2.443147320901194

Epoch: 6| Step: 12
Training loss: 2.8540093898773193
Validation loss: 2.443285975404965

Epoch: 6| Step: 13
Training loss: 3.244899272918701
Validation loss: 2.439246569910357

Epoch: 93| Step: 0
Training loss: 2.122559070587158
Validation loss: 2.4401785942815963

Epoch: 6| Step: 1
Training loss: 3.3436203002929688
Validation loss: 2.4393243892218477

Epoch: 6| Step: 2
Training loss: 3.136132001876831
Validation loss: 2.4395280807249007

Epoch: 6| Step: 3
Training loss: 2.771008014678955
Validation loss: 2.4334243446268062

Epoch: 6| Step: 4
Training loss: 2.8529043197631836
Validation loss: 2.4421762881740445

Epoch: 6| Step: 5
Training loss: 3.1322848796844482
Validation loss: 2.4446368525105138

Epoch: 6| Step: 6
Training loss: 2.9426093101501465
Validation loss: 2.448271559130761

Epoch: 6| Step: 7
Training loss: 2.1129372119903564
Validation loss: 2.4494980945382068

Epoch: 6| Step: 8
Training loss: 2.0779740810394287
Validation loss: 2.450171885951873

Epoch: 6| Step: 9
Training loss: 2.602865219116211
Validation loss: 2.4516115880781606

Epoch: 6| Step: 10
Training loss: 2.3958468437194824
Validation loss: 2.4521599149191253

Epoch: 6| Step: 11
Training loss: 2.766374111175537
Validation loss: 2.4528550845320507

Epoch: 6| Step: 12
Training loss: 2.5203490257263184
Validation loss: 2.4561293304607434

Epoch: 6| Step: 13
Training loss: 2.341346263885498
Validation loss: 2.4425426670300063

Epoch: 94| Step: 0
Training loss: 2.2283823490142822
Validation loss: 2.4379161250206733

Epoch: 6| Step: 1
Training loss: 3.869305372238159
Validation loss: 2.433343815547164

Epoch: 6| Step: 2
Training loss: 2.3061635494232178
Validation loss: 2.4261608867235083

Epoch: 6| Step: 3
Training loss: 2.5174436569213867
Validation loss: 2.4272259255891204

Epoch: 6| Step: 4
Training loss: 2.9271292686462402
Validation loss: 2.4367842007708806

Epoch: 6| Step: 5
Training loss: 2.39872670173645
Validation loss: 2.4385279506765385

Epoch: 6| Step: 6
Training loss: 2.533116102218628
Validation loss: 2.4414479322330926

Epoch: 6| Step: 7
Training loss: 2.137479782104492
Validation loss: 2.446812945027505

Epoch: 6| Step: 8
Training loss: 3.413677215576172
Validation loss: 2.440348953329107

Epoch: 6| Step: 9
Training loss: 2.7411324977874756
Validation loss: 2.441136024331534

Epoch: 6| Step: 10
Training loss: 2.3764865398406982
Validation loss: 2.4389312036575808

Epoch: 6| Step: 11
Training loss: 2.896939754486084
Validation loss: 2.435141122469338

Epoch: 6| Step: 12
Training loss: 2.6605019569396973
Validation loss: 2.4341735583479687

Epoch: 6| Step: 13
Training loss: 2.0484023094177246
Validation loss: 2.434222964830296

Epoch: 95| Step: 0
Training loss: 3.1323187351226807
Validation loss: 2.446331654825518

Epoch: 6| Step: 1
Training loss: 2.744929790496826
Validation loss: 2.460372781240812

Epoch: 6| Step: 2
Training loss: 2.7965922355651855
Validation loss: 2.4824681922953618

Epoch: 6| Step: 3
Training loss: 2.1957149505615234
Validation loss: 2.5071465738358034

Epoch: 6| Step: 4
Training loss: 2.079864263534546
Validation loss: 2.5019934459399154

Epoch: 6| Step: 5
Training loss: 3.3161401748657227
Validation loss: 2.4982025238775436

Epoch: 6| Step: 6
Training loss: 2.1469104290008545
Validation loss: 2.505564720399918

Epoch: 6| Step: 7
Training loss: 2.7600479125976562
Validation loss: 2.5015418862783783

Epoch: 6| Step: 8
Training loss: 2.988325595855713
Validation loss: 2.50832788918608

Epoch: 6| Step: 9
Training loss: 2.7467124462127686
Validation loss: 2.482674942221693

Epoch: 6| Step: 10
Training loss: 3.1953554153442383
Validation loss: 2.457520869470412

Epoch: 6| Step: 11
Training loss: 1.954095482826233
Validation loss: 2.4422561853162703

Epoch: 6| Step: 12
Training loss: 2.4624814987182617
Validation loss: 2.444744563871814

Epoch: 6| Step: 13
Training loss: 2.933671712875366
Validation loss: 2.4561109594119492

Epoch: 96| Step: 0
Training loss: 2.684051513671875
Validation loss: 2.454425104202763

Epoch: 6| Step: 1
Training loss: 2.5368759632110596
Validation loss: 2.452479544506278

Epoch: 6| Step: 2
Training loss: 2.2810628414154053
Validation loss: 2.445495774669032

Epoch: 6| Step: 3
Training loss: 1.7156908512115479
Validation loss: 2.443305864129015

Epoch: 6| Step: 4
Training loss: 3.268465042114258
Validation loss: 2.438927096705283

Epoch: 6| Step: 5
Training loss: 3.555964708328247
Validation loss: 2.438944357697682

Epoch: 6| Step: 6
Training loss: 2.4610483646392822
Validation loss: 2.432378525375038

Epoch: 6| Step: 7
Training loss: 2.047678232192993
Validation loss: 2.42973655526356

Epoch: 6| Step: 8
Training loss: 2.9053955078125
Validation loss: 2.4294701084013908

Epoch: 6| Step: 9
Training loss: 3.162903070449829
Validation loss: 2.426154634003998

Epoch: 6| Step: 10
Training loss: 3.063805103302002
Validation loss: 2.4251297904599096

Epoch: 6| Step: 11
Training loss: 3.1684064865112305
Validation loss: 2.4269450223574074

Epoch: 6| Step: 12
Training loss: 2.1167001724243164
Validation loss: 2.4270966693919194

Epoch: 6| Step: 13
Training loss: 2.2968740463256836
Validation loss: 2.424824732606129

Epoch: 97| Step: 0
Training loss: 3.2059988975524902
Validation loss: 2.428902974692724

Epoch: 6| Step: 1
Training loss: 3.0540943145751953
Validation loss: 2.431711309699602

Epoch: 6| Step: 2
Training loss: 2.2229678630828857
Validation loss: 2.4502913644236903

Epoch: 6| Step: 3
Training loss: 2.797767162322998
Validation loss: 2.44738071708269

Epoch: 6| Step: 4
Training loss: 2.939983367919922
Validation loss: 2.4666783835298274

Epoch: 6| Step: 5
Training loss: 2.697688341140747
Validation loss: 2.471386606975268

Epoch: 6| Step: 6
Training loss: 2.9887142181396484
Validation loss: 2.4766725058196695

Epoch: 6| Step: 7
Training loss: 2.172731876373291
Validation loss: 2.4629415209575365

Epoch: 6| Step: 8
Training loss: 1.826191782951355
Validation loss: 2.4546432597662813

Epoch: 6| Step: 9
Training loss: 2.692843437194824
Validation loss: 2.443259367378809

Epoch: 6| Step: 10
Training loss: 2.66099214553833
Validation loss: 2.427497063913653

Epoch: 6| Step: 11
Training loss: 2.462676763534546
Validation loss: 2.4231150278481106

Epoch: 6| Step: 12
Training loss: 2.8328728675842285
Validation loss: 2.4193680824772006

Epoch: 6| Step: 13
Training loss: 2.812443733215332
Validation loss: 2.4155518034453034

Epoch: 98| Step: 0
Training loss: 1.9698413610458374
Validation loss: 2.422730553534723

Epoch: 6| Step: 1
Training loss: 2.2873849868774414
Validation loss: 2.418845889388874

Epoch: 6| Step: 2
Training loss: 1.9617230892181396
Validation loss: 2.41853843709474

Epoch: 6| Step: 3
Training loss: 2.435946464538574
Validation loss: 2.4200517823619228

Epoch: 6| Step: 4
Training loss: 3.1066761016845703
Validation loss: 2.4161015172158518

Epoch: 6| Step: 5
Training loss: 2.999697685241699
Validation loss: 2.419616242890717

Epoch: 6| Step: 6
Training loss: 1.9711410999298096
Validation loss: 2.4154065475668958

Epoch: 6| Step: 7
Training loss: 2.8550896644592285
Validation loss: 2.4180914022589244

Epoch: 6| Step: 8
Training loss: 2.5173463821411133
Validation loss: 2.4206876729124334

Epoch: 6| Step: 9
Training loss: 3.6664910316467285
Validation loss: 2.4235155326063915

Epoch: 6| Step: 10
Training loss: 3.2272684574127197
Validation loss: 2.4213600312509844

Epoch: 6| Step: 11
Training loss: 2.313126564025879
Validation loss: 2.421194632848104

Epoch: 6| Step: 12
Training loss: 3.255039691925049
Validation loss: 2.4197431174657678

Epoch: 6| Step: 13
Training loss: 2.5668413639068604
Validation loss: 2.4266083701964347

Epoch: 99| Step: 0
Training loss: 2.494140148162842
Validation loss: 2.421075636340726

Epoch: 6| Step: 1
Training loss: 2.4311656951904297
Validation loss: 2.4274252101939213

Epoch: 6| Step: 2
Training loss: 2.7372026443481445
Validation loss: 2.4246106224675334

Epoch: 6| Step: 3
Training loss: 2.643951177597046
Validation loss: 2.422229033644481

Epoch: 6| Step: 4
Training loss: 2.502790927886963
Validation loss: 2.4206429489197268

Epoch: 6| Step: 5
Training loss: 2.7823007106781006
Validation loss: 2.421874471890029

Epoch: 6| Step: 6
Training loss: 2.665717124938965
Validation loss: 2.4225355425188617

Epoch: 6| Step: 7
Training loss: 2.8559517860412598
Validation loss: 2.430448679513829

Epoch: 6| Step: 8
Training loss: 2.412872314453125
Validation loss: 2.424111650836083

Epoch: 6| Step: 9
Training loss: 2.999490976333618
Validation loss: 2.431091759794502

Epoch: 6| Step: 10
Training loss: 2.33274507522583
Validation loss: 2.4329058521537372

Epoch: 6| Step: 11
Training loss: 2.863025665283203
Validation loss: 2.429646691968364

Epoch: 6| Step: 12
Training loss: 2.6365628242492676
Validation loss: 2.429563178811022

Epoch: 6| Step: 13
Training loss: 2.76461124420166
Validation loss: 2.436943374654298

Epoch: 100| Step: 0
Training loss: 2.09273624420166
Validation loss: 2.4324766487203617

Epoch: 6| Step: 1
Training loss: 2.6902785301208496
Validation loss: 2.4259864361055437

Epoch: 6| Step: 2
Training loss: 2.869008779525757
Validation loss: 2.4275157374720417

Epoch: 6| Step: 3
Training loss: 3.1293349266052246
Validation loss: 2.422730609934817

Epoch: 6| Step: 4
Training loss: 3.558349609375
Validation loss: 2.4170210566571964

Epoch: 6| Step: 5
Training loss: 3.4086976051330566
Validation loss: 2.422234683908442

Epoch: 6| Step: 6
Training loss: 2.2459797859191895
Validation loss: 2.4188494810494046

Epoch: 6| Step: 7
Training loss: 1.9305341243743896
Validation loss: 2.4188790628986974

Epoch: 6| Step: 8
Training loss: 2.5882201194763184
Validation loss: 2.421144844383322

Epoch: 6| Step: 9
Training loss: 2.6982884407043457
Validation loss: 2.4165208801146476

Epoch: 6| Step: 10
Training loss: 2.5938422679901123
Validation loss: 2.41456017955657

Epoch: 6| Step: 11
Training loss: 2.959618091583252
Validation loss: 2.4119761400325324

Epoch: 6| Step: 12
Training loss: 1.6052110195159912
Validation loss: 2.423100474060223

Epoch: 6| Step: 13
Training loss: 2.630035400390625
Validation loss: 2.4193502523565806

Epoch: 101| Step: 0
Training loss: 2.7424893379211426
Validation loss: 2.415802797963542

Epoch: 6| Step: 1
Training loss: 2.6474244594573975
Validation loss: 2.420691018463463

Epoch: 6| Step: 2
Training loss: 2.4993488788604736
Validation loss: 2.4316156192492415

Epoch: 6| Step: 3
Training loss: 2.6428632736206055
Validation loss: 2.437233599283362

Epoch: 6| Step: 4
Training loss: 2.9321115016937256
Validation loss: 2.436351565904515

Epoch: 6| Step: 5
Training loss: 2.1572670936584473
Validation loss: 2.441591783236432

Epoch: 6| Step: 6
Training loss: 2.4662063121795654
Validation loss: 2.438172160938222

Epoch: 6| Step: 7
Training loss: 1.8783986568450928
Validation loss: 2.4420143327405377

Epoch: 6| Step: 8
Training loss: 3.158806085586548
Validation loss: 2.444872530557776

Epoch: 6| Step: 9
Training loss: 2.9772276878356934
Validation loss: 2.4496576298949537

Epoch: 6| Step: 10
Training loss: 2.547698497772217
Validation loss: 2.451026698594452

Epoch: 6| Step: 11
Training loss: 3.1396210193634033
Validation loss: 2.4443315306017475

Epoch: 6| Step: 12
Training loss: 2.690849781036377
Validation loss: 2.4334761352949243

Epoch: 6| Step: 13
Training loss: 2.475463628768921
Validation loss: 2.4256556674998295

Epoch: 102| Step: 0
Training loss: 3.2949461936950684
Validation loss: 2.4215521940621

Epoch: 6| Step: 1
Training loss: 2.616621494293213
Validation loss: 2.4274340701359574

Epoch: 6| Step: 2
Training loss: 2.37961745262146
Validation loss: 2.423457891710343

Epoch: 6| Step: 3
Training loss: 2.836658477783203
Validation loss: 2.4244855757682555

Epoch: 6| Step: 4
Training loss: 2.406721591949463
Validation loss: 2.4251454543041926

Epoch: 6| Step: 5
Training loss: 3.086024045944214
Validation loss: 2.4200295171430035

Epoch: 6| Step: 6
Training loss: 2.507298231124878
Validation loss: 2.4287978936267156

Epoch: 6| Step: 7
Training loss: 2.3516063690185547
Validation loss: 2.4282719140411704

Epoch: 6| Step: 8
Training loss: 2.592985153198242
Validation loss: 2.427467187245687

Epoch: 6| Step: 9
Training loss: 2.167135715484619
Validation loss: 2.4304592532496296

Epoch: 6| Step: 10
Training loss: 3.089472770690918
Validation loss: 2.4306156558375203

Epoch: 6| Step: 11
Training loss: 2.4963841438293457
Validation loss: 2.425994262900404

Epoch: 6| Step: 12
Training loss: 2.203763484954834
Validation loss: 2.4240139069095736

Epoch: 6| Step: 13
Training loss: 3.107529640197754
Validation loss: 2.416104203911238

Epoch: 103| Step: 0
Training loss: 3.543139696121216
Validation loss: 2.413571447454473

Epoch: 6| Step: 1
Training loss: 2.6833205223083496
Validation loss: 2.4136342951046523

Epoch: 6| Step: 2
Training loss: 2.8534984588623047
Validation loss: 2.420650191204522

Epoch: 6| Step: 3
Training loss: 1.5516314506530762
Validation loss: 2.421217103158274

Epoch: 6| Step: 4
Training loss: 3.1188600063323975
Validation loss: 2.4168262250961794

Epoch: 6| Step: 5
Training loss: 2.43241810798645
Validation loss: 2.4130360259804675

Epoch: 6| Step: 6
Training loss: 2.0132789611816406
Validation loss: 2.4093614188573693

Epoch: 6| Step: 7
Training loss: 2.431633949279785
Validation loss: 2.4112157616564023

Epoch: 6| Step: 8
Training loss: 3.1977500915527344
Validation loss: 2.41452891595902

Epoch: 6| Step: 9
Training loss: 2.2588307857513428
Validation loss: 2.4134037545932236

Epoch: 6| Step: 10
Training loss: 2.916327476501465
Validation loss: 2.4197214700842418

Epoch: 6| Step: 11
Training loss: 2.423617362976074
Validation loss: 2.4210462749645276

Epoch: 6| Step: 12
Training loss: 2.6231472492218018
Validation loss: 2.4200061726313766

Epoch: 6| Step: 13
Training loss: 3.2751169204711914
Validation loss: 2.427851107812697

Epoch: 104| Step: 0
Training loss: 2.0255637168884277
Validation loss: 2.4273511107249925

Epoch: 6| Step: 1
Training loss: 2.6306204795837402
Validation loss: 2.4311759856439408

Epoch: 6| Step: 2
Training loss: 2.3962550163269043
Validation loss: 2.4297729743424283

Epoch: 6| Step: 3
Training loss: 3.322004795074463
Validation loss: 2.4277399560456634

Epoch: 6| Step: 4
Training loss: 2.44991135597229
Validation loss: 2.4251463003056024

Epoch: 6| Step: 5
Training loss: 2.6549854278564453
Validation loss: 2.4328245475728023

Epoch: 6| Step: 6
Training loss: 2.6396639347076416
Validation loss: 2.4312031627983175

Epoch: 6| Step: 7
Training loss: 2.9626173973083496
Validation loss: 2.4222889843807427

Epoch: 6| Step: 8
Training loss: 2.5812783241271973
Validation loss: 2.4227934780941216

Epoch: 6| Step: 9
Training loss: 2.947601079940796
Validation loss: 2.4316575783555225

Epoch: 6| Step: 10
Training loss: 3.193816661834717
Validation loss: 2.4172607314202095

Epoch: 6| Step: 11
Training loss: 2.9429728984832764
Validation loss: 2.4110365785578245

Epoch: 6| Step: 12
Training loss: 1.4620685577392578
Validation loss: 2.408398033470236

Epoch: 6| Step: 13
Training loss: 2.745307445526123
Validation loss: 2.4137775769797702

Epoch: 105| Step: 0
Training loss: 2.89682674407959
Validation loss: 2.4204231641625844

Epoch: 6| Step: 1
Training loss: 2.3993992805480957
Validation loss: 2.4116481145222983

Epoch: 6| Step: 2
Training loss: 2.701936721801758
Validation loss: 2.411295985662809

Epoch: 6| Step: 3
Training loss: 3.4381675720214844
Validation loss: 2.411804060782156

Epoch: 6| Step: 4
Training loss: 2.8109843730926514
Validation loss: 2.412605303590016

Epoch: 6| Step: 5
Training loss: 2.6795284748077393
Validation loss: 2.4117228574650262

Epoch: 6| Step: 6
Training loss: 2.1256208419799805
Validation loss: 2.4120744735963884

Epoch: 6| Step: 7
Training loss: 3.454263687133789
Validation loss: 2.4051109103746313

Epoch: 6| Step: 8
Training loss: 2.0041165351867676
Validation loss: 2.4060848118156515

Epoch: 6| Step: 9
Training loss: 2.275054693222046
Validation loss: 2.407780908769177

Epoch: 6| Step: 10
Training loss: 2.1224732398986816
Validation loss: 2.4000372732839277

Epoch: 6| Step: 11
Training loss: 2.985733985900879
Validation loss: 2.405846885455552

Epoch: 6| Step: 12
Training loss: 2.461263656616211
Validation loss: 2.4065162930437314

Epoch: 6| Step: 13
Training loss: 2.4987123012542725
Validation loss: 2.4098894160280944

Epoch: 106| Step: 0
Training loss: 3.0032858848571777
Validation loss: 2.4139680606062695

Epoch: 6| Step: 1
Training loss: 2.065633535385132
Validation loss: 2.4201793670654297

Epoch: 6| Step: 2
Training loss: 3.1848015785217285
Validation loss: 2.4320384276810514

Epoch: 6| Step: 3
Training loss: 1.9772322177886963
Validation loss: 2.4377196937479

Epoch: 6| Step: 4
Training loss: 2.7291417121887207
Validation loss: 2.4425562222798667

Epoch: 6| Step: 5
Training loss: 3.471008777618408
Validation loss: 2.4374207911952848

Epoch: 6| Step: 6
Training loss: 3.372349977493286
Validation loss: 2.427923725497338

Epoch: 6| Step: 7
Training loss: 2.6820292472839355
Validation loss: 2.4236336215849845

Epoch: 6| Step: 8
Training loss: 2.289339542388916
Validation loss: 2.418195568105226

Epoch: 6| Step: 9
Training loss: 3.116344928741455
Validation loss: 2.413032409965351

Epoch: 6| Step: 10
Training loss: 2.5306506156921387
Validation loss: 2.4105708958000265

Epoch: 6| Step: 11
Training loss: 2.4062271118164062
Validation loss: 2.4108550087098153

Epoch: 6| Step: 12
Training loss: 2.115034818649292
Validation loss: 2.4107020490912983

Epoch: 6| Step: 13
Training loss: 1.6523765325546265
Validation loss: 2.4043978901319605

Epoch: 107| Step: 0
Training loss: 2.8036394119262695
Validation loss: 2.4052841612087783

Epoch: 6| Step: 1
Training loss: 2.8191680908203125
Validation loss: 2.4033364762542067

Epoch: 6| Step: 2
Training loss: 2.416553497314453
Validation loss: 2.41187927287112

Epoch: 6| Step: 3
Training loss: 2.8342294692993164
Validation loss: 2.415619819395004

Epoch: 6| Step: 4
Training loss: 2.9438631534576416
Validation loss: 2.4195244081558718

Epoch: 6| Step: 5
Training loss: 2.732046127319336
Validation loss: 2.4287499407286286

Epoch: 6| Step: 6
Training loss: 2.3035237789154053
Validation loss: 2.4286211177866948

Epoch: 6| Step: 7
Training loss: 2.667043685913086
Validation loss: 2.4280044365954656

Epoch: 6| Step: 8
Training loss: 2.3678061962127686
Validation loss: 2.4310136713007444

Epoch: 6| Step: 9
Training loss: 3.4509453773498535
Validation loss: 2.435662777193131

Epoch: 6| Step: 10
Training loss: 3.002824306488037
Validation loss: 2.427853335616409

Epoch: 6| Step: 11
Training loss: 2.2184951305389404
Validation loss: 2.4212252350263697

Epoch: 6| Step: 12
Training loss: 1.8848016262054443
Validation loss: 2.4127576171710925

Epoch: 6| Step: 13
Training loss: 2.4544479846954346
Validation loss: 2.4136212589920207

Epoch: 108| Step: 0
Training loss: 2.8408703804016113
Validation loss: 2.417508758524413

Epoch: 6| Step: 1
Training loss: 3.142022132873535
Validation loss: 2.4199128048394316

Epoch: 6| Step: 2
Training loss: 2.279102325439453
Validation loss: 2.4194165839943835

Epoch: 6| Step: 3
Training loss: 2.475013494491577
Validation loss: 2.4117370267068186

Epoch: 6| Step: 4
Training loss: 2.7134766578674316
Validation loss: 2.414128165091238

Epoch: 6| Step: 5
Training loss: 3.373589515686035
Validation loss: 2.4092095667316067

Epoch: 6| Step: 6
Training loss: 2.7172391414642334
Validation loss: 2.4021088820631786

Epoch: 6| Step: 7
Training loss: 2.1807918548583984
Validation loss: 2.399711439686437

Epoch: 6| Step: 8
Training loss: 2.546410083770752
Validation loss: 2.4049094441116496

Epoch: 6| Step: 9
Training loss: 2.3484601974487305
Validation loss: 2.4012732018706617

Epoch: 6| Step: 10
Training loss: 2.4834916591644287
Validation loss: 2.404587399575018

Epoch: 6| Step: 11
Training loss: 2.545337677001953
Validation loss: 2.4073292683529597

Epoch: 6| Step: 12
Training loss: 2.6712279319763184
Validation loss: 2.4064961223192114

Epoch: 6| Step: 13
Training loss: 2.523923873901367
Validation loss: 2.40885522801389

Epoch: 109| Step: 0
Training loss: 3.026634693145752
Validation loss: 2.417514767698062

Epoch: 6| Step: 1
Training loss: 2.631385087966919
Validation loss: 2.412375268115792

Epoch: 6| Step: 2
Training loss: 2.331176996231079
Validation loss: 2.4177671555549867

Epoch: 6| Step: 3
Training loss: 3.052628517150879
Validation loss: 2.4310113922242196

Epoch: 6| Step: 4
Training loss: 2.4778847694396973
Validation loss: 2.430879887714181

Epoch: 6| Step: 5
Training loss: 2.595363140106201
Validation loss: 2.441379395864343

Epoch: 6| Step: 6
Training loss: 1.9935235977172852
Validation loss: 2.445460601519513

Epoch: 6| Step: 7
Training loss: 2.66782546043396
Validation loss: 2.447465173659786

Epoch: 6| Step: 8
Training loss: 2.7061662673950195
Validation loss: 2.4492529976752495

Epoch: 6| Step: 9
Training loss: 2.7539961338043213
Validation loss: 2.4391534302824285

Epoch: 6| Step: 10
Training loss: 2.798140525817871
Validation loss: 2.4350230796362764

Epoch: 6| Step: 11
Training loss: 3.030076026916504
Validation loss: 2.428887085248065

Epoch: 6| Step: 12
Training loss: 1.9600067138671875
Validation loss: 2.420995404643397

Epoch: 6| Step: 13
Training loss: 3.115260124206543
Validation loss: 2.4111686291233188

Epoch: 110| Step: 0
Training loss: 3.1084351539611816
Validation loss: 2.4026424730977705

Epoch: 6| Step: 1
Training loss: 2.4801857471466064
Validation loss: 2.395790846117081

Epoch: 6| Step: 2
Training loss: 2.8282532691955566
Validation loss: 2.397978295562088

Epoch: 6| Step: 3
Training loss: 2.998396158218384
Validation loss: 2.391530144599176

Epoch: 6| Step: 4
Training loss: 2.3366212844848633
Validation loss: 2.398798365746775

Epoch: 6| Step: 5
Training loss: 2.3678689002990723
Validation loss: 2.397075412093952

Epoch: 6| Step: 6
Training loss: 2.2947261333465576
Validation loss: 2.396239980574577

Epoch: 6| Step: 7
Training loss: 2.024141788482666
Validation loss: 2.391804566947363

Epoch: 6| Step: 8
Training loss: 2.563830614089966
Validation loss: 2.397248924419444

Epoch: 6| Step: 9
Training loss: 3.1137852668762207
Validation loss: 2.395197194109681

Epoch: 6| Step: 10
Training loss: 2.587120532989502
Validation loss: 2.397008949710477

Epoch: 6| Step: 11
Training loss: 3.1042232513427734
Validation loss: 2.3984105535732803

Epoch: 6| Step: 12
Training loss: 2.4564480781555176
Validation loss: 2.3947497670368483

Epoch: 6| Step: 13
Training loss: 2.6746580600738525
Validation loss: 2.3941832511655745

Epoch: 111| Step: 0
Training loss: 2.933948040008545
Validation loss: 2.399626313999135

Epoch: 6| Step: 1
Training loss: 2.276111125946045
Validation loss: 2.3982507567251883

Epoch: 6| Step: 2
Training loss: 3.161853790283203
Validation loss: 2.3980376233336744

Epoch: 6| Step: 3
Training loss: 2.9647068977355957
Validation loss: 2.4021854759544454

Epoch: 6| Step: 4
Training loss: 1.831286907196045
Validation loss: 2.4088983945949103

Epoch: 6| Step: 5
Training loss: 2.2264740467071533
Validation loss: 2.4116748302213606

Epoch: 6| Step: 6
Training loss: 2.130497694015503
Validation loss: 2.418272533724385

Epoch: 6| Step: 7
Training loss: 3.203685760498047
Validation loss: 2.4236866171642015

Epoch: 6| Step: 8
Training loss: 3.2454681396484375
Validation loss: 2.4202283915653022

Epoch: 6| Step: 9
Training loss: 2.0757312774658203
Validation loss: 2.4128144043748097

Epoch: 6| Step: 10
Training loss: 2.637936592102051
Validation loss: 2.406777915134225

Epoch: 6| Step: 11
Training loss: 2.347372055053711
Validation loss: 2.402574849385087

Epoch: 6| Step: 12
Training loss: 2.798264503479004
Validation loss: 2.398997555496872

Epoch: 6| Step: 13
Training loss: 3.308161497116089
Validation loss: 2.4008001127550678

Epoch: 112| Step: 0
Training loss: 2.3186349868774414
Validation loss: 2.397603060609551

Epoch: 6| Step: 1
Training loss: 3.1503567695617676
Validation loss: 2.399139896515877

Epoch: 6| Step: 2
Training loss: 2.3525147438049316
Validation loss: 2.396399995332123

Epoch: 6| Step: 3
Training loss: 2.5578250885009766
Validation loss: 2.392374748824745

Epoch: 6| Step: 4
Training loss: 2.41818904876709
Validation loss: 2.3957877697483188

Epoch: 6| Step: 5
Training loss: 2.711404800415039
Validation loss: 2.3960501968219714

Epoch: 6| Step: 6
Training loss: 2.246241569519043
Validation loss: 2.4054818255926973

Epoch: 6| Step: 7
Training loss: 3.6233887672424316
Validation loss: 2.405609525660033

Epoch: 6| Step: 8
Training loss: 2.396810531616211
Validation loss: 2.415287022949547

Epoch: 6| Step: 9
Training loss: 2.697331428527832
Validation loss: 2.415226456939533

Epoch: 6| Step: 10
Training loss: 2.0587353706359863
Validation loss: 2.4040486222954205

Epoch: 6| Step: 11
Training loss: 2.8212883472442627
Validation loss: 2.4035006441095823

Epoch: 6| Step: 12
Training loss: 2.432690143585205
Validation loss: 2.4053884975371824

Epoch: 6| Step: 13
Training loss: 3.3015518188476562
Validation loss: 2.4080092291678152

Epoch: 113| Step: 0
Training loss: 3.1157398223876953
Validation loss: 2.389719969482832

Epoch: 6| Step: 1
Training loss: 2.378715753555298
Validation loss: 2.4007339528811875

Epoch: 6| Step: 2
Training loss: 2.695831060409546
Validation loss: 2.3985562324523926

Epoch: 6| Step: 3
Training loss: 2.975855588912964
Validation loss: 2.3949279298064527

Epoch: 6| Step: 4
Training loss: 2.367199420928955
Validation loss: 2.3963299541063208

Epoch: 6| Step: 5
Training loss: 2.3133158683776855
Validation loss: 2.3968196581768733

Epoch: 6| Step: 6
Training loss: 2.2899131774902344
Validation loss: 2.3882030646006265

Epoch: 6| Step: 7
Training loss: 2.616755723953247
Validation loss: 2.395109407363399

Epoch: 6| Step: 8
Training loss: 2.6384952068328857
Validation loss: 2.401418791022352

Epoch: 6| Step: 9
Training loss: 2.1834187507629395
Validation loss: 2.398213981300272

Epoch: 6| Step: 10
Training loss: 2.258718490600586
Validation loss: 2.4000024334076913

Epoch: 6| Step: 11
Training loss: 3.186624050140381
Validation loss: 2.39941176291435

Epoch: 6| Step: 12
Training loss: 2.848327159881592
Validation loss: 2.3934344963360856

Epoch: 6| Step: 13
Training loss: 3.2001984119415283
Validation loss: 2.3933465570531864

Epoch: 114| Step: 0
Training loss: 1.5806602239608765
Validation loss: 2.386503022204163

Epoch: 6| Step: 1
Training loss: 2.6697702407836914
Validation loss: 2.3944107101809595

Epoch: 6| Step: 2
Training loss: 1.907343864440918
Validation loss: 2.402916419890619

Epoch: 6| Step: 3
Training loss: 2.4335856437683105
Validation loss: 2.4104941762903684

Epoch: 6| Step: 4
Training loss: 3.1342532634735107
Validation loss: 2.409188675624068

Epoch: 6| Step: 5
Training loss: 2.578761100769043
Validation loss: 2.411926177240187

Epoch: 6| Step: 6
Training loss: 3.1223628520965576
Validation loss: 2.4112588180008756

Epoch: 6| Step: 7
Training loss: 3.288346529006958
Validation loss: 2.412342753461612

Epoch: 6| Step: 8
Training loss: 2.6103196144104004
Validation loss: 2.416223656746649

Epoch: 6| Step: 9
Training loss: 2.687939167022705
Validation loss: 2.424071788787842

Epoch: 6| Step: 10
Training loss: 2.6193318367004395
Validation loss: 2.4206103714563514

Epoch: 6| Step: 11
Training loss: 2.3483119010925293
Validation loss: 2.4192275642066874

Epoch: 6| Step: 12
Training loss: 3.103006362915039
Validation loss: 2.4175744274611115

Epoch: 6| Step: 13
Training loss: 2.666229486465454
Validation loss: 2.416988795803439

Epoch: 115| Step: 0
Training loss: 2.923598289489746
Validation loss: 2.4108233708207325

Epoch: 6| Step: 1
Training loss: 3.161686658859253
Validation loss: 2.4003445897051083

Epoch: 6| Step: 2
Training loss: 2.567901849746704
Validation loss: 2.390905982704573

Epoch: 6| Step: 3
Training loss: 2.914569139480591
Validation loss: 2.391080102612895

Epoch: 6| Step: 4
Training loss: 3.189373731613159
Validation loss: 2.387092830032431

Epoch: 6| Step: 5
Training loss: 2.0456600189208984
Validation loss: 2.3904403102013374

Epoch: 6| Step: 6
Training loss: 2.7320516109466553
Validation loss: 2.390240453904675

Epoch: 6| Step: 7
Training loss: 2.588343381881714
Validation loss: 2.389845294337119

Epoch: 6| Step: 8
Training loss: 2.921884298324585
Validation loss: 2.390204673172325

Epoch: 6| Step: 9
Training loss: 2.265204429626465
Validation loss: 2.389763193745767

Epoch: 6| Step: 10
Training loss: 2.003279685974121
Validation loss: 2.3892051378885903

Epoch: 6| Step: 11
Training loss: 3.1471781730651855
Validation loss: 2.3926138160049275

Epoch: 6| Step: 12
Training loss: 2.1763522624969482
Validation loss: 2.394154692208895

Epoch: 6| Step: 13
Training loss: 1.8283038139343262
Validation loss: 2.390480992614582

Epoch: 116| Step: 0
Training loss: 2.597130298614502
Validation loss: 2.404491142560077

Epoch: 6| Step: 1
Training loss: 2.637510299682617
Validation loss: 2.4100158829842844

Epoch: 6| Step: 2
Training loss: 2.357149124145508
Validation loss: 2.4214811658346527

Epoch: 6| Step: 3
Training loss: 2.527967929840088
Validation loss: 2.4237323140585296

Epoch: 6| Step: 4
Training loss: 2.9320340156555176
Validation loss: 2.432149751212007

Epoch: 6| Step: 5
Training loss: 2.7313811779022217
Validation loss: 2.4249162955950667

Epoch: 6| Step: 6
Training loss: 1.7859914302825928
Validation loss: 2.417825545034101

Epoch: 6| Step: 7
Training loss: 3.1322317123413086
Validation loss: 2.4077435180705082

Epoch: 6| Step: 8
Training loss: 2.2071244716644287
Validation loss: 2.394595638398201

Epoch: 6| Step: 9
Training loss: 2.8298988342285156
Validation loss: 2.3916456725007746

Epoch: 6| Step: 10
Training loss: 2.902069568634033
Validation loss: 2.387914626829086

Epoch: 6| Step: 11
Training loss: 2.922912120819092
Validation loss: 2.385831909794961

Epoch: 6| Step: 12
Training loss: 2.163285493850708
Validation loss: 2.387787481789948

Epoch: 6| Step: 13
Training loss: 3.435480833053589
Validation loss: 2.3834283262170772

Epoch: 117| Step: 0
Training loss: 2.3362832069396973
Validation loss: 2.385202588573579

Epoch: 6| Step: 1
Training loss: 3.319584369659424
Validation loss: 2.3823387404923797

Epoch: 6| Step: 2
Training loss: 2.968107223510742
Validation loss: 2.3810713060440554

Epoch: 6| Step: 3
Training loss: 2.81339168548584
Validation loss: 2.381117054211196

Epoch: 6| Step: 4
Training loss: 2.4579992294311523
Validation loss: 2.376804638934392

Epoch: 6| Step: 5
Training loss: 2.9445083141326904
Validation loss: 2.3813270599611345

Epoch: 6| Step: 6
Training loss: 2.5581917762756348
Validation loss: 2.3820135388323056

Epoch: 6| Step: 7
Training loss: 2.9975733757019043
Validation loss: 2.3816973701600106

Epoch: 6| Step: 8
Training loss: 2.8224399089813232
Validation loss: 2.3836780799332487

Epoch: 6| Step: 9
Training loss: 2.374102830886841
Validation loss: 2.3869551022847495

Epoch: 6| Step: 10
Training loss: 2.5234785079956055
Validation loss: 2.3903318118023615

Epoch: 6| Step: 11
Training loss: 2.3955841064453125
Validation loss: 2.3963540728374193

Epoch: 6| Step: 12
Training loss: 1.8539161682128906
Validation loss: 2.4019796386841805

Epoch: 6| Step: 13
Training loss: 2.0919294357299805
Validation loss: 2.4066318209453295

Epoch: 118| Step: 0
Training loss: 2.5645644664764404
Validation loss: 2.4022767595065537

Epoch: 6| Step: 1
Training loss: 1.8323720693588257
Validation loss: 2.411547637754871

Epoch: 6| Step: 2
Training loss: 2.5598158836364746
Validation loss: 2.41193816995108

Epoch: 6| Step: 3
Training loss: 2.0430757999420166
Validation loss: 2.4053587887876775

Epoch: 6| Step: 4
Training loss: 2.9950149059295654
Validation loss: 2.410536745543121

Epoch: 6| Step: 5
Training loss: 3.04487943649292
Validation loss: 2.395420200081282

Epoch: 6| Step: 6
Training loss: 2.816877841949463
Validation loss: 2.3899412693515902

Epoch: 6| Step: 7
Training loss: 2.829954147338867
Validation loss: 2.385128898005332

Epoch: 6| Step: 8
Training loss: 3.1836485862731934
Validation loss: 2.3808413987518637

Epoch: 6| Step: 9
Training loss: 2.783451557159424
Validation loss: 2.378659273988457

Epoch: 6| Step: 10
Training loss: 2.7142484188079834
Validation loss: 2.3757680128979426

Epoch: 6| Step: 11
Training loss: 2.8899917602539062
Validation loss: 2.3786679083301174

Epoch: 6| Step: 12
Training loss: 1.8058984279632568
Validation loss: 2.37874968846639

Epoch: 6| Step: 13
Training loss: 2.752161741256714
Validation loss: 2.380969209055747

Epoch: 119| Step: 0
Training loss: 3.2429745197296143
Validation loss: 2.3827593608569075

Epoch: 6| Step: 1
Training loss: 2.431144952774048
Validation loss: 2.3780719259733796

Epoch: 6| Step: 2
Training loss: 2.214024066925049
Validation loss: 2.3797956307729087

Epoch: 6| Step: 3
Training loss: 2.230022430419922
Validation loss: 2.382376076072775

Epoch: 6| Step: 4
Training loss: 2.9413294792175293
Validation loss: 2.378501681871312

Epoch: 6| Step: 5
Training loss: 3.4319710731506348
Validation loss: 2.383307928680092

Epoch: 6| Step: 6
Training loss: 2.339595317840576
Validation loss: 2.3840903030928744

Epoch: 6| Step: 7
Training loss: 2.191765308380127
Validation loss: 2.3842716832314768

Epoch: 6| Step: 8
Training loss: 2.6645138263702393
Validation loss: 2.383577885166291

Epoch: 6| Step: 9
Training loss: 2.736037254333496
Validation loss: 2.384995009309502

Epoch: 6| Step: 10
Training loss: 2.6571083068847656
Validation loss: 2.3795125766467025

Epoch: 6| Step: 11
Training loss: 2.3423595428466797
Validation loss: 2.3869359877801712

Epoch: 6| Step: 12
Training loss: 2.741668939590454
Validation loss: 2.383052954109766

Epoch: 6| Step: 13
Training loss: 2.2562122344970703
Validation loss: 2.389039438257935

Epoch: 120| Step: 0
Training loss: 2.4745776653289795
Validation loss: 2.4010781626547537

Epoch: 6| Step: 1
Training loss: 2.0082578659057617
Validation loss: 2.4077733434656614

Epoch: 6| Step: 2
Training loss: 3.1319613456726074
Validation loss: 2.4289287905539236

Epoch: 6| Step: 3
Training loss: 3.3700499534606934
Validation loss: 2.4326150058418192

Epoch: 6| Step: 4
Training loss: 2.0633223056793213
Validation loss: 2.4440039127103743

Epoch: 6| Step: 5
Training loss: 2.8517589569091797
Validation loss: 2.4281221102642756

Epoch: 6| Step: 6
Training loss: 2.533057451248169
Validation loss: 2.4269023415862874

Epoch: 6| Step: 7
Training loss: 2.4017086029052734
Validation loss: 2.410203121041739

Epoch: 6| Step: 8
Training loss: 3.0582423210144043
Validation loss: 2.390791557168448

Epoch: 6| Step: 9
Training loss: 2.5943660736083984
Validation loss: 2.379434326643585

Epoch: 6| Step: 10
Training loss: 2.2758309841156006
Validation loss: 2.376619321043773

Epoch: 6| Step: 11
Training loss: 2.734943151473999
Validation loss: 2.3796779494131766

Epoch: 6| Step: 12
Training loss: 3.0436601638793945
Validation loss: 2.387949138559321

Epoch: 6| Step: 13
Training loss: 2.0197627544403076
Validation loss: 2.39073436234587

Epoch: 121| Step: 0
Training loss: 2.6940860748291016
Validation loss: 2.392256518845917

Epoch: 6| Step: 1
Training loss: 2.4574098587036133
Validation loss: 2.395409168735627

Epoch: 6| Step: 2
Training loss: 2.51108980178833
Validation loss: 2.3919090917033534

Epoch: 6| Step: 3
Training loss: 2.479043960571289
Validation loss: 2.3981818614467496

Epoch: 6| Step: 4
Training loss: 2.856125831604004
Validation loss: 2.3907704135423065

Epoch: 6| Step: 5
Training loss: 2.798393964767456
Validation loss: 2.3890123623673634

Epoch: 6| Step: 6
Training loss: 2.7649097442626953
Validation loss: 2.3810517608478503

Epoch: 6| Step: 7
Training loss: 2.1722240447998047
Validation loss: 2.3769288447595414

Epoch: 6| Step: 8
Training loss: 1.9634054899215698
Validation loss: 2.37754028074203

Epoch: 6| Step: 9
Training loss: 2.9582583904266357
Validation loss: 2.3846576034381823

Epoch: 6| Step: 10
Training loss: 2.6647403240203857
Validation loss: 2.389421578376524

Epoch: 6| Step: 11
Training loss: 2.946485996246338
Validation loss: 2.3905516260413715

Epoch: 6| Step: 12
Training loss: 3.0719046592712402
Validation loss: 2.3945638197724537

Epoch: 6| Step: 13
Training loss: 2.3011484146118164
Validation loss: 2.4076080399174846

Epoch: 122| Step: 0
Training loss: 2.9586129188537598
Validation loss: 2.4156409655847857

Epoch: 6| Step: 1
Training loss: 2.9115259647369385
Validation loss: 2.4155301535001366

Epoch: 6| Step: 2
Training loss: 2.8033695220947266
Validation loss: 2.4199915573161137

Epoch: 6| Step: 3
Training loss: 2.946920394897461
Validation loss: 2.422844950870801

Epoch: 6| Step: 4
Training loss: 2.6777920722961426
Validation loss: 2.4265979643790954

Epoch: 6| Step: 5
Training loss: 2.8607378005981445
Validation loss: 2.4148886229402278

Epoch: 6| Step: 6
Training loss: 2.4379215240478516
Validation loss: 2.4212308545266428

Epoch: 6| Step: 7
Training loss: 2.4836888313293457
Validation loss: 2.4004251136574695

Epoch: 6| Step: 8
Training loss: 2.098374843597412
Validation loss: 2.4018582733728553

Epoch: 6| Step: 9
Training loss: 1.9471832513809204
Validation loss: 2.398020270050213

Epoch: 6| Step: 10
Training loss: 3.040095329284668
Validation loss: 2.3865657442359516

Epoch: 6| Step: 11
Training loss: 2.637613534927368
Validation loss: 2.382553203131563

Epoch: 6| Step: 12
Training loss: 2.361929178237915
Validation loss: 2.3826175774297407

Epoch: 6| Step: 13
Training loss: 2.494558572769165
Validation loss: 2.378076289289741

Epoch: 123| Step: 0
Training loss: 3.484320640563965
Validation loss: 2.3820529189161075

Epoch: 6| Step: 1
Training loss: 1.2620090246200562
Validation loss: 2.3814494250923075

Epoch: 6| Step: 2
Training loss: 2.3596322536468506
Validation loss: 2.3822548235616376

Epoch: 6| Step: 3
Training loss: 3.099748134613037
Validation loss: 2.3936288356781006

Epoch: 6| Step: 4
Training loss: 2.415536880493164
Validation loss: 2.3988779924249135

Epoch: 6| Step: 5
Training loss: 2.606123924255371
Validation loss: 2.399704425565658

Epoch: 6| Step: 6
Training loss: 2.643332004547119
Validation loss: 2.4024229562410744

Epoch: 6| Step: 7
Training loss: 2.853549003601074
Validation loss: 2.4252770844326226

Epoch: 6| Step: 8
Training loss: 2.8799924850463867
Validation loss: 2.414742831260927

Epoch: 6| Step: 9
Training loss: 2.41328763961792
Validation loss: 2.408264370374782

Epoch: 6| Step: 10
Training loss: 3.053952693939209
Validation loss: 2.412512625417402

Epoch: 6| Step: 11
Training loss: 2.146869659423828
Validation loss: 2.3987628183057232

Epoch: 6| Step: 12
Training loss: 2.686197519302368
Validation loss: 2.3883266269519763

Epoch: 6| Step: 13
Training loss: 2.7493526935577393
Validation loss: 2.3850863184980167

Epoch: 124| Step: 0
Training loss: 2.6966891288757324
Validation loss: 2.3850878515551166

Epoch: 6| Step: 1
Training loss: 2.4077935218811035
Validation loss: 2.380499903873731

Epoch: 6| Step: 2
Training loss: 2.738124132156372
Validation loss: 2.376573221657866

Epoch: 6| Step: 3
Training loss: 2.121565341949463
Validation loss: 2.3787025123514156

Epoch: 6| Step: 4
Training loss: 2.4137845039367676
Validation loss: 2.380831600517355

Epoch: 6| Step: 5
Training loss: 2.762906551361084
Validation loss: 2.378285846402568

Epoch: 6| Step: 6
Training loss: 2.630566120147705
Validation loss: 2.3825314814044583

Epoch: 6| Step: 7
Training loss: 3.1958045959472656
Validation loss: 2.3891103421488116

Epoch: 6| Step: 8
Training loss: 2.7300338745117188
Validation loss: 2.3895010179088962

Epoch: 6| Step: 9
Training loss: 2.8485424518585205
Validation loss: 2.3878162766015656

Epoch: 6| Step: 10
Training loss: 1.8750450611114502
Validation loss: 2.393532165917017

Epoch: 6| Step: 11
Training loss: 2.4358608722686768
Validation loss: 2.3853188842855473

Epoch: 6| Step: 12
Training loss: 2.896031141281128
Validation loss: 2.3881943507861068

Epoch: 6| Step: 13
Training loss: 2.794459342956543
Validation loss: 2.3920034618787867

Epoch: 125| Step: 0
Training loss: 2.0655808448791504
Validation loss: 2.394022444243072

Epoch: 6| Step: 1
Training loss: 2.449312448501587
Validation loss: 2.396549629908736

Epoch: 6| Step: 2
Training loss: 2.2236974239349365
Validation loss: 2.3928284721989788

Epoch: 6| Step: 3
Training loss: 3.038627862930298
Validation loss: 2.392555447034938

Epoch: 6| Step: 4
Training loss: 2.7233424186706543
Validation loss: 2.3937628153831727

Epoch: 6| Step: 5
Training loss: 1.8235523700714111
Validation loss: 2.389559789370465

Epoch: 6| Step: 6
Training loss: 3.2034764289855957
Validation loss: 2.386660929649107

Epoch: 6| Step: 7
Training loss: 2.5872936248779297
Validation loss: 2.388107568986954

Epoch: 6| Step: 8
Training loss: 2.0869460105895996
Validation loss: 2.3799878294749925

Epoch: 6| Step: 9
Training loss: 3.0311806201934814
Validation loss: 2.389320999063471

Epoch: 6| Step: 10
Training loss: 2.651010274887085
Validation loss: 2.387928790943597

Epoch: 6| Step: 11
Training loss: 3.3246965408325195
Validation loss: 2.380393630714827

Epoch: 6| Step: 12
Training loss: 2.776870012283325
Validation loss: 2.3848985484851304

Epoch: 6| Step: 13
Training loss: 2.375136375427246
Validation loss: 2.3865260821516796

Epoch: 126| Step: 0
Training loss: 2.60404372215271
Validation loss: 2.3819745740582867

Epoch: 6| Step: 1
Training loss: 2.3852601051330566
Validation loss: 2.3828528978491343

Epoch: 6| Step: 2
Training loss: 2.9553864002227783
Validation loss: 2.3799651874009

Epoch: 6| Step: 3
Training loss: 2.1554746627807617
Validation loss: 2.382678744613483

Epoch: 6| Step: 4
Training loss: 2.5749917030334473
Validation loss: 2.386468724537921

Epoch: 6| Step: 5
Training loss: 2.3819918632507324
Validation loss: 2.388477517712501

Epoch: 6| Step: 6
Training loss: 2.935802459716797
Validation loss: 2.3868222223815097

Epoch: 6| Step: 7
Training loss: 2.689723014831543
Validation loss: 2.3894758147578083

Epoch: 6| Step: 8
Training loss: 3.3492422103881836
Validation loss: 2.395524299272927

Epoch: 6| Step: 9
Training loss: 2.837296724319458
Validation loss: 2.3994919741025535

Epoch: 6| Step: 10
Training loss: 1.8653541803359985
Validation loss: 2.3943828921164236

Epoch: 6| Step: 11
Training loss: 2.8052878379821777
Validation loss: 2.3872666435856975

Epoch: 6| Step: 12
Training loss: 2.44811749458313
Validation loss: 2.3822541698332755

Epoch: 6| Step: 13
Training loss: 2.4923341274261475
Validation loss: 2.374626172486172

Epoch: 127| Step: 0
Training loss: 2.5105321407318115
Validation loss: 2.3820170023108043

Epoch: 6| Step: 1
Training loss: 3.2301878929138184
Validation loss: 2.381743554146059

Epoch: 6| Step: 2
Training loss: 2.918942928314209
Validation loss: 2.377553445036693

Epoch: 6| Step: 3
Training loss: 2.5824685096740723
Validation loss: 2.3849357763926187

Epoch: 6| Step: 4
Training loss: 2.21920108795166
Validation loss: 2.3895461328567995

Epoch: 6| Step: 5
Training loss: 2.0340189933776855
Validation loss: 2.3886955399667062

Epoch: 6| Step: 6
Training loss: 2.8706107139587402
Validation loss: 2.3905644109172206

Epoch: 6| Step: 7
Training loss: 2.695931911468506
Validation loss: 2.3960202150447394

Epoch: 6| Step: 8
Training loss: 3.1377720832824707
Validation loss: 2.40203433908442

Epoch: 6| Step: 9
Training loss: 2.455996513366699
Validation loss: 2.39527650033274

Epoch: 6| Step: 10
Training loss: 1.8863472938537598
Validation loss: 2.395265069059146

Epoch: 6| Step: 11
Training loss: 3.3361172676086426
Validation loss: 2.394107526348483

Epoch: 6| Step: 12
Training loss: 2.385618209838867
Validation loss: 2.3918772589775825

Epoch: 6| Step: 13
Training loss: 1.8396649360656738
Validation loss: 2.4070544191586074

Epoch: 128| Step: 0
Training loss: 2.0786380767822266
Validation loss: 2.412364741807343

Epoch: 6| Step: 1
Training loss: 2.67794132232666
Validation loss: 2.409226830287646

Epoch: 6| Step: 2
Training loss: 2.1864051818847656
Validation loss: 2.405827881187521

Epoch: 6| Step: 3
Training loss: 2.2747397422790527
Validation loss: 2.413147464875252

Epoch: 6| Step: 4
Training loss: 2.8556230068206787
Validation loss: 2.3962380552804596

Epoch: 6| Step: 5
Training loss: 2.877805233001709
Validation loss: 2.3888743385191886

Epoch: 6| Step: 6
Training loss: 2.350179672241211
Validation loss: 2.387786857543453

Epoch: 6| Step: 7
Training loss: 2.6852800846099854
Validation loss: 2.3895436743254304

Epoch: 6| Step: 8
Training loss: 2.3470985889434814
Validation loss: 2.3874885523191063

Epoch: 6| Step: 9
Training loss: 3.0678911209106445
Validation loss: 2.3902071983583513

Epoch: 6| Step: 10
Training loss: 2.8136208057403564
Validation loss: 2.3875050801102833

Epoch: 6| Step: 11
Training loss: 3.656128406524658
Validation loss: 2.382249075879333

Epoch: 6| Step: 12
Training loss: 2.5482017993927
Validation loss: 2.3790248799067673

Epoch: 6| Step: 13
Training loss: 1.858886957168579
Validation loss: 2.3816740692302747

Epoch: 129| Step: 0
Training loss: 2.508945941925049
Validation loss: 2.3699121680310977

Epoch: 6| Step: 1
Training loss: 2.8509082794189453
Validation loss: 2.374245156524002

Epoch: 6| Step: 2
Training loss: 3.0358078479766846
Validation loss: 2.366167647864229

Epoch: 6| Step: 3
Training loss: 2.45259690284729
Validation loss: 2.3759125483933317

Epoch: 6| Step: 4
Training loss: 2.102822780609131
Validation loss: 2.3758786980823805

Epoch: 6| Step: 5
Training loss: 2.6655004024505615
Validation loss: 2.375370763963269

Epoch: 6| Step: 6
Training loss: 2.2110137939453125
Validation loss: 2.3753154893075266

Epoch: 6| Step: 7
Training loss: 2.3452835083007812
Validation loss: 2.3822975312509844

Epoch: 6| Step: 8
Training loss: 2.8497474193573
Validation loss: 2.3852018899815057

Epoch: 6| Step: 9
Training loss: 2.564622163772583
Validation loss: 2.3825927139610372

Epoch: 6| Step: 10
Training loss: 2.431541919708252
Validation loss: 2.3828299686472905

Epoch: 6| Step: 11
Training loss: 2.931959867477417
Validation loss: 2.37010928123228

Epoch: 6| Step: 12
Training loss: 2.4757418632507324
Validation loss: 2.3745511295974895

Epoch: 6| Step: 13
Training loss: 3.1794593334198
Validation loss: 2.3717661903750513

Epoch: 130| Step: 0
Training loss: 2.0615227222442627
Validation loss: 2.3795406510753017

Epoch: 6| Step: 1
Training loss: 2.5654642581939697
Validation loss: 2.3781194635616836

Epoch: 6| Step: 2
Training loss: 2.6242995262145996
Validation loss: 2.374695688165644

Epoch: 6| Step: 3
Training loss: 3.6028494834899902
Validation loss: 2.3714837797226442

Epoch: 6| Step: 4
Training loss: 2.1551995277404785
Validation loss: 2.3643638908222155

Epoch: 6| Step: 5
Training loss: 2.4606685638427734
Validation loss: 2.3695652228529736

Epoch: 6| Step: 6
Training loss: 2.675126314163208
Validation loss: 2.363799807845905

Epoch: 6| Step: 7
Training loss: 3.278765916824341
Validation loss: 2.366075083773623

Epoch: 6| Step: 8
Training loss: 2.1767563819885254
Validation loss: 2.3661570677193264

Epoch: 6| Step: 9
Training loss: 2.468965768814087
Validation loss: 2.368403820581334

Epoch: 6| Step: 10
Training loss: 2.7550995349884033
Validation loss: 2.3667819602515108

Epoch: 6| Step: 11
Training loss: 2.7524352073669434
Validation loss: 2.3695556630370436

Epoch: 6| Step: 12
Training loss: 1.835570216178894
Validation loss: 2.3756551793826524

Epoch: 6| Step: 13
Training loss: 3.12595272064209
Validation loss: 2.376570168361869

Epoch: 131| Step: 0
Training loss: 2.3590526580810547
Validation loss: 2.39693005623356

Epoch: 6| Step: 1
Training loss: 1.8120882511138916
Validation loss: 2.396590271303731

Epoch: 6| Step: 2
Training loss: 2.271336555480957
Validation loss: 2.4117021509396133

Epoch: 6| Step: 3
Training loss: 2.4731273651123047
Validation loss: 2.4066451006038214

Epoch: 6| Step: 4
Training loss: 3.226144552230835
Validation loss: 2.411702481649255

Epoch: 6| Step: 5
Training loss: 2.101003646850586
Validation loss: 2.4093939283842682

Epoch: 6| Step: 6
Training loss: 2.9451394081115723
Validation loss: 2.407583229003414

Epoch: 6| Step: 7
Training loss: 2.669579029083252
Validation loss: 2.399851426001518

Epoch: 6| Step: 8
Training loss: 2.1721208095550537
Validation loss: 2.3986497540627756

Epoch: 6| Step: 9
Training loss: 2.526214599609375
Validation loss: 2.385439459995557

Epoch: 6| Step: 10
Training loss: 2.7623934745788574
Validation loss: 2.378859112339635

Epoch: 6| Step: 11
Training loss: 2.6243224143981934
Validation loss: 2.380647818247477

Epoch: 6| Step: 12
Training loss: 3.7014307975769043
Validation loss: 2.377735827558784

Epoch: 6| Step: 13
Training loss: 2.8558263778686523
Validation loss: 2.3732984553101244

Epoch: 132| Step: 0
Training loss: 2.4887356758117676
Validation loss: 2.3675626093341458

Epoch: 6| Step: 1
Training loss: 3.6834256649017334
Validation loss: 2.364180446952902

Epoch: 6| Step: 2
Training loss: 2.506564140319824
Validation loss: 2.3658912079308623

Epoch: 6| Step: 3
Training loss: 2.0845866203308105
Validation loss: 2.361289785754296

Epoch: 6| Step: 4
Training loss: 2.727023124694824
Validation loss: 2.360009544639177

Epoch: 6| Step: 5
Training loss: 2.1715941429138184
Validation loss: 2.358302398394513

Epoch: 6| Step: 6
Training loss: 2.6880335807800293
Validation loss: 2.3596251215986026

Epoch: 6| Step: 7
Training loss: 2.090832233428955
Validation loss: 2.365601065338299

Epoch: 6| Step: 8
Training loss: 2.778632164001465
Validation loss: 2.36489382097798

Epoch: 6| Step: 9
Training loss: 2.7646098136901855
Validation loss: 2.365059596236034

Epoch: 6| Step: 10
Training loss: 3.2164697647094727
Validation loss: 2.3754138228713826

Epoch: 6| Step: 11
Training loss: 2.4566965103149414
Validation loss: 2.366202688986255

Epoch: 6| Step: 12
Training loss: 2.3761470317840576
Validation loss: 2.378124396006266

Epoch: 6| Step: 13
Training loss: 2.1969380378723145
Validation loss: 2.380697778476182

Epoch: 133| Step: 0
Training loss: 2.67122483253479
Validation loss: 2.3839123531054427

Epoch: 6| Step: 1
Training loss: 2.507542610168457
Validation loss: 2.382256530946301

Epoch: 6| Step: 2
Training loss: 2.865642547607422
Validation loss: 2.382605416800386

Epoch: 6| Step: 3
Training loss: 1.736242651939392
Validation loss: 2.3804132246202037

Epoch: 6| Step: 4
Training loss: 1.9150431156158447
Validation loss: 2.379722455496429

Epoch: 6| Step: 5
Training loss: 2.596315622329712
Validation loss: 2.3845214151567027

Epoch: 6| Step: 6
Training loss: 2.7276859283447266
Validation loss: 2.3842659073491252

Epoch: 6| Step: 7
Training loss: 2.5149307250976562
Validation loss: 2.3868077134573333

Epoch: 6| Step: 8
Training loss: 2.51944637298584
Validation loss: 2.377390633347214

Epoch: 6| Step: 9
Training loss: 2.146921157836914
Validation loss: 2.381128789276205

Epoch: 6| Step: 10
Training loss: 3.220099449157715
Validation loss: 2.393151024336456

Epoch: 6| Step: 11
Training loss: 3.0902178287506104
Validation loss: 2.374634399208971

Epoch: 6| Step: 12
Training loss: 2.946930170059204
Validation loss: 2.368703435826045

Epoch: 6| Step: 13
Training loss: 3.1276602745056152
Validation loss: 2.3630232093154744

Epoch: 134| Step: 0
Training loss: 2.50201153755188
Validation loss: 2.3611888116405857

Epoch: 6| Step: 1
Training loss: 3.1957507133483887
Validation loss: 2.3599632375983783

Epoch: 6| Step: 2
Training loss: 2.8204193115234375
Validation loss: 2.355398783119776

Epoch: 6| Step: 3
Training loss: 2.189114570617676
Validation loss: 2.353419585894513

Epoch: 6| Step: 4
Training loss: 2.9871480464935303
Validation loss: 2.3495248107499975

Epoch: 6| Step: 5
Training loss: 2.4413299560546875
Validation loss: 2.3496546719663884

Epoch: 6| Step: 6
Training loss: 3.6745734214782715
Validation loss: 2.3518489355682046

Epoch: 6| Step: 7
Training loss: 2.112460136413574
Validation loss: 2.358491233600083

Epoch: 6| Step: 8
Training loss: 2.380903720855713
Validation loss: 2.3522793567308815

Epoch: 6| Step: 9
Training loss: 1.6345736980438232
Validation loss: 2.3639465352540374

Epoch: 6| Step: 10
Training loss: 2.8932199478149414
Validation loss: 2.361543970723306

Epoch: 6| Step: 11
Training loss: 2.6911885738372803
Validation loss: 2.367713059148481

Epoch: 6| Step: 12
Training loss: 2.450587272644043
Validation loss: 2.3731718845264886

Epoch: 6| Step: 13
Training loss: 1.975037932395935
Validation loss: 2.382071248946651

Epoch: 135| Step: 0
Training loss: 2.5988969802856445
Validation loss: 2.3813873644798034

Epoch: 6| Step: 1
Training loss: 2.667263984680176
Validation loss: 2.3823403645587224

Epoch: 6| Step: 2
Training loss: 3.378916025161743
Validation loss: 2.382319563178606

Epoch: 6| Step: 3
Training loss: 2.9135513305664062
Validation loss: 2.381462412495767

Epoch: 6| Step: 4
Training loss: 2.1745829582214355
Validation loss: 2.3812498251597085

Epoch: 6| Step: 5
Training loss: 2.4289002418518066
Validation loss: 2.3824197989638134

Epoch: 6| Step: 6
Training loss: 2.582836866378784
Validation loss: 2.3767380534961657

Epoch: 6| Step: 7
Training loss: 2.286680221557617
Validation loss: 2.3871930042902627

Epoch: 6| Step: 8
Training loss: 2.4935824871063232
Validation loss: 2.3846291803544566

Epoch: 6| Step: 9
Training loss: 2.6089277267456055
Validation loss: 2.3947578040502404

Epoch: 6| Step: 10
Training loss: 2.3196771144866943
Validation loss: 2.3994545346947125

Epoch: 6| Step: 11
Training loss: 2.940768241882324
Validation loss: 2.3987900492965535

Epoch: 6| Step: 12
Training loss: 2.5052521228790283
Validation loss: 2.4092303937481296

Epoch: 6| Step: 13
Training loss: 2.151211738586426
Validation loss: 2.402049567109795

Epoch: 136| Step: 0
Training loss: 2.6105477809906006
Validation loss: 2.3805235150039836

Epoch: 6| Step: 1
Training loss: 1.87850022315979
Validation loss: 2.3751239161337576

Epoch: 6| Step: 2
Training loss: 2.509284019470215
Validation loss: 2.369670675646874

Epoch: 6| Step: 3
Training loss: 2.412412643432617
Validation loss: 2.3703584696656916

Epoch: 6| Step: 4
Training loss: 2.1749634742736816
Validation loss: 2.361987280589278

Epoch: 6| Step: 5
Training loss: 3.407011032104492
Validation loss: 2.355154219494071

Epoch: 6| Step: 6
Training loss: 2.702622413635254
Validation loss: 2.368029212438932

Epoch: 6| Step: 7
Training loss: 2.346658706665039
Validation loss: 2.3699397066588044

Epoch: 6| Step: 8
Training loss: 2.263307809829712
Validation loss: 2.362229065228534

Epoch: 6| Step: 9
Training loss: 3.0714621543884277
Validation loss: 2.366960305039601

Epoch: 6| Step: 10
Training loss: 2.3914785385131836
Validation loss: 2.353308303381807

Epoch: 6| Step: 11
Training loss: 3.060375213623047
Validation loss: 2.3600825673790387

Epoch: 6| Step: 12
Training loss: 2.558565616607666
Validation loss: 2.3501385873363865

Epoch: 6| Step: 13
Training loss: 2.9155569076538086
Validation loss: 2.359597688080162

Epoch: 137| Step: 0
Training loss: 2.807291030883789
Validation loss: 2.3493480246554137

Epoch: 6| Step: 1
Training loss: 2.0313100814819336
Validation loss: 2.348711854668074

Epoch: 6| Step: 2
Training loss: 2.8031444549560547
Validation loss: 2.3460991305689656

Epoch: 6| Step: 3
Training loss: 2.8521876335144043
Validation loss: 2.346783907182755

Epoch: 6| Step: 4
Training loss: 2.627124786376953
Validation loss: 2.3459977744728007

Epoch: 6| Step: 5
Training loss: 2.4390995502471924
Validation loss: 2.349420355212304

Epoch: 6| Step: 6
Training loss: 2.957029104232788
Validation loss: 2.3555738759297196

Epoch: 6| Step: 7
Training loss: 2.1421189308166504
Validation loss: 2.3412174947800173

Epoch: 6| Step: 8
Training loss: 2.717148780822754
Validation loss: 2.339865151272025

Epoch: 6| Step: 9
Training loss: 3.0230941772460938
Validation loss: 2.3443755308787027

Epoch: 6| Step: 10
Training loss: 2.4558520317077637
Validation loss: 2.34439484278361

Epoch: 6| Step: 11
Training loss: 2.27142333984375
Validation loss: 2.357755402083038

Epoch: 6| Step: 12
Training loss: 2.596489906311035
Validation loss: 2.3513395529921337

Epoch: 6| Step: 13
Training loss: 2.097348213195801
Validation loss: 2.360072905017484

Epoch: 138| Step: 0
Training loss: 1.5620415210723877
Validation loss: 2.3655843478377148

Epoch: 6| Step: 1
Training loss: 2.4073355197906494
Validation loss: 2.3450964061162805

Epoch: 6| Step: 2
Training loss: 3.321746349334717
Validation loss: 2.354075979161006

Epoch: 6| Step: 3
Training loss: 2.0238637924194336
Validation loss: 2.351991864942735

Epoch: 6| Step: 4
Training loss: 3.3259682655334473
Validation loss: 2.3460637523281958

Epoch: 6| Step: 5
Training loss: 1.829301118850708
Validation loss: 2.3484859184552263

Epoch: 6| Step: 6
Training loss: 2.69901180267334
Validation loss: 2.3477570459406865

Epoch: 6| Step: 7
Training loss: 2.7060673236846924
Validation loss: 2.3493574639802337

Epoch: 6| Step: 8
Training loss: 3.0433590412139893
Validation loss: 2.357502955262379

Epoch: 6| Step: 9
Training loss: 2.507812261581421
Validation loss: 2.357825756072998

Epoch: 6| Step: 10
Training loss: 2.8961431980133057
Validation loss: 2.3611503057582404

Epoch: 6| Step: 11
Training loss: 2.544468402862549
Validation loss: 2.3531667545277584

Epoch: 6| Step: 12
Training loss: 2.826125383377075
Validation loss: 2.3464104129422094

Epoch: 6| Step: 13
Training loss: 2.2765111923217773
Validation loss: 2.3421488115864415

Epoch: 139| Step: 0
Training loss: 2.727762460708618
Validation loss: 2.34973543946461

Epoch: 6| Step: 1
Training loss: 1.9834266901016235
Validation loss: 2.3450164384739374

Epoch: 6| Step: 2
Training loss: 2.7119295597076416
Validation loss: 2.3453367089712494

Epoch: 6| Step: 3
Training loss: 2.271993637084961
Validation loss: 2.339651305188415

Epoch: 6| Step: 4
Training loss: 2.831249475479126
Validation loss: 2.3490861538917787

Epoch: 6| Step: 5
Training loss: 2.698591709136963
Validation loss: 2.3451546417769564

Epoch: 6| Step: 6
Training loss: 2.6196908950805664
Validation loss: 2.340646546374085

Epoch: 6| Step: 7
Training loss: 2.593545436859131
Validation loss: 2.3471191031958467

Epoch: 6| Step: 8
Training loss: 3.171372413635254
Validation loss: 2.3427722377161824

Epoch: 6| Step: 9
Training loss: 3.242594003677368
Validation loss: 2.340046044318907

Epoch: 6| Step: 10
Training loss: 2.4051272869110107
Validation loss: 2.3367369892776653

Epoch: 6| Step: 11
Training loss: 2.203572988510132
Validation loss: 2.341084280321675

Epoch: 6| Step: 12
Training loss: 2.1250767707824707
Validation loss: 2.339139853754351

Epoch: 6| Step: 13
Training loss: 2.3169236183166504
Validation loss: 2.3400882597892516

Epoch: 140| Step: 0
Training loss: 2.151360034942627
Validation loss: 2.3453777323486986

Epoch: 6| Step: 1
Training loss: 1.8952291011810303
Validation loss: 2.342339690013598

Epoch: 6| Step: 2
Training loss: 2.7058773040771484
Validation loss: 2.3482926507149973

Epoch: 6| Step: 3
Training loss: 2.7370333671569824
Validation loss: 2.3474310187883276

Epoch: 6| Step: 4
Training loss: 2.7264304161071777
Validation loss: 2.3465262459170435

Epoch: 6| Step: 5
Training loss: 2.4495160579681396
Validation loss: 2.3484701469380367

Epoch: 6| Step: 6
Training loss: 2.030895709991455
Validation loss: 2.3430176499069377

Epoch: 6| Step: 7
Training loss: 2.3217878341674805
Validation loss: 2.348136809564406

Epoch: 6| Step: 8
Training loss: 2.971161365509033
Validation loss: 2.3487381627482753

Epoch: 6| Step: 9
Training loss: 3.4264039993286133
Validation loss: 2.349768687320012

Epoch: 6| Step: 10
Training loss: 3.5760204792022705
Validation loss: 2.345352198487969

Epoch: 6| Step: 11
Training loss: 1.87095046043396
Validation loss: 2.3388981588425173

Epoch: 6| Step: 12
Training loss: 2.3400673866271973
Validation loss: 2.3402077818429596

Epoch: 6| Step: 13
Training loss: 2.85430908203125
Validation loss: 2.342825069222399

Epoch: 141| Step: 0
Training loss: 2.3309545516967773
Validation loss: 2.3481089607361825

Epoch: 6| Step: 1
Training loss: 2.498640537261963
Validation loss: 2.3524596537313154

Epoch: 6| Step: 2
Training loss: 3.2114672660827637
Validation loss: 2.357368597420313

Epoch: 6| Step: 3
Training loss: 2.425741195678711
Validation loss: 2.3639948701345794

Epoch: 6| Step: 4
Training loss: 2.3095602989196777
Validation loss: 2.36780652564059

Epoch: 6| Step: 5
Training loss: 2.298349618911743
Validation loss: 2.3738075123038342

Epoch: 6| Step: 6
Training loss: 2.253796100616455
Validation loss: 2.3674851707232896

Epoch: 6| Step: 7
Training loss: 2.581601619720459
Validation loss: 2.377862456024334

Epoch: 6| Step: 8
Training loss: 2.1918349266052246
Validation loss: 2.3770103211043985

Epoch: 6| Step: 9
Training loss: 3.1635630130767822
Validation loss: 2.3703989110967165

Epoch: 6| Step: 10
Training loss: 2.9065916538238525
Validation loss: 2.3600886816619546

Epoch: 6| Step: 11
Training loss: 2.4524760246276855
Validation loss: 2.367156372275404

Epoch: 6| Step: 12
Training loss: 2.7711496353149414
Validation loss: 2.3557554547504713

Epoch: 6| Step: 13
Training loss: 2.5987207889556885
Validation loss: 2.350359914123371

Epoch: 142| Step: 0
Training loss: 3.010023593902588
Validation loss: 2.3401792844136557

Epoch: 6| Step: 1
Training loss: 2.287839651107788
Validation loss: 2.336074158709536

Epoch: 6| Step: 2
Training loss: 1.8043606281280518
Validation loss: 2.333421540516679

Epoch: 6| Step: 3
Training loss: 2.547508955001831
Validation loss: 2.3320292119056947

Epoch: 6| Step: 4
Training loss: 2.322786808013916
Validation loss: 2.334726707909697

Epoch: 6| Step: 5
Training loss: 2.561185121536255
Validation loss: 2.327761270666635

Epoch: 6| Step: 6
Training loss: 2.923241138458252
Validation loss: 2.331462347379295

Epoch: 6| Step: 7
Training loss: 2.5075454711914062
Validation loss: 2.343330588392032

Epoch: 6| Step: 8
Training loss: 2.5262324810028076
Validation loss: 2.3406689192659114

Epoch: 6| Step: 9
Training loss: 2.217395305633545
Validation loss: 2.3369519813086397

Epoch: 6| Step: 10
Training loss: 3.0855770111083984
Validation loss: 2.340855362594769

Epoch: 6| Step: 11
Training loss: 2.2594847679138184
Validation loss: 2.347471273073586

Epoch: 6| Step: 12
Training loss: 3.121664524078369
Validation loss: 2.353405393579955

Epoch: 6| Step: 13
Training loss: 2.960787534713745
Validation loss: 2.3537433480703704

Epoch: 143| Step: 0
Training loss: 2.309018135070801
Validation loss: 2.353649990532988

Epoch: 6| Step: 1
Training loss: 3.363048553466797
Validation loss: 2.3541259304169686

Epoch: 6| Step: 2
Training loss: 1.939871072769165
Validation loss: 2.3610058984448834

Epoch: 6| Step: 3
Training loss: 2.544968605041504
Validation loss: 2.34875673888832

Epoch: 6| Step: 4
Training loss: 2.4946446418762207
Validation loss: 2.3581747342181463

Epoch: 6| Step: 5
Training loss: 1.9536161422729492
Validation loss: 2.359674549871875

Epoch: 6| Step: 6
Training loss: 3.085881471633911
Validation loss: 2.3733785613890617

Epoch: 6| Step: 7
Training loss: 2.5190846920013428
Validation loss: 2.3653138786233883

Epoch: 6| Step: 8
Training loss: 2.5318541526794434
Validation loss: 2.3539447451150544

Epoch: 6| Step: 9
Training loss: 2.277690887451172
Validation loss: 2.348808137319421

Epoch: 6| Step: 10
Training loss: 3.4185562133789062
Validation loss: 2.3456266336543585

Epoch: 6| Step: 11
Training loss: 2.3945629596710205
Validation loss: 2.335614969653468

Epoch: 6| Step: 12
Training loss: 2.678765296936035
Validation loss: 2.3342462560181976

Epoch: 6| Step: 13
Training loss: 2.4951512813568115
Validation loss: 2.340237130400955

Epoch: 144| Step: 0
Training loss: 1.948561668395996
Validation loss: 2.3377857772252892

Epoch: 6| Step: 1
Training loss: 2.5202465057373047
Validation loss: 2.328692443909184

Epoch: 6| Step: 2
Training loss: 3.1867575645446777
Validation loss: 2.326650224706178

Epoch: 6| Step: 3
Training loss: 2.510079860687256
Validation loss: 2.3256618438228482

Epoch: 6| Step: 4
Training loss: 2.8774938583374023
Validation loss: 2.314688718447121

Epoch: 6| Step: 5
Training loss: 1.9191991090774536
Validation loss: 2.3225907433417534

Epoch: 6| Step: 6
Training loss: 2.735931396484375
Validation loss: 2.3197395519543718

Epoch: 6| Step: 7
Training loss: 2.30570125579834
Validation loss: 2.324899060751802

Epoch: 6| Step: 8
Training loss: 2.93912935256958
Validation loss: 2.332370937511485

Epoch: 6| Step: 9
Training loss: 2.615082263946533
Validation loss: 2.333146649022256

Epoch: 6| Step: 10
Training loss: 2.255467653274536
Validation loss: 2.338922664683352

Epoch: 6| Step: 11
Training loss: 3.195236921310425
Validation loss: 2.3407829192376908

Epoch: 6| Step: 12
Training loss: 1.7258825302124023
Validation loss: 2.341522949998097

Epoch: 6| Step: 13
Training loss: 3.626840353012085
Validation loss: 2.3411754818372827

Epoch: 145| Step: 0
Training loss: 3.2367589473724365
Validation loss: 2.3448328254043416

Epoch: 6| Step: 1
Training loss: 2.3937346935272217
Validation loss: 2.342023600814163

Epoch: 6| Step: 2
Training loss: 3.482144832611084
Validation loss: 2.355890457348157

Epoch: 6| Step: 3
Training loss: 2.4071779251098633
Validation loss: 2.346990586608969

Epoch: 6| Step: 4
Training loss: 2.5088906288146973
Validation loss: 2.343417953419429

Epoch: 6| Step: 5
Training loss: 2.003016710281372
Validation loss: 2.3464857045040337

Epoch: 6| Step: 6
Training loss: 2.767484188079834
Validation loss: 2.3396311575366604

Epoch: 6| Step: 7
Training loss: 2.2815823554992676
Validation loss: 2.333770654534781

Epoch: 6| Step: 8
Training loss: 2.353078842163086
Validation loss: 2.333981421685988

Epoch: 6| Step: 9
Training loss: 2.849823474884033
Validation loss: 2.3264070992828696

Epoch: 6| Step: 10
Training loss: 2.6092989444732666
Validation loss: 2.3302981122847526

Epoch: 6| Step: 11
Training loss: 2.4805517196655273
Validation loss: 2.329027583522181

Epoch: 6| Step: 12
Training loss: 2.121295928955078
Validation loss: 2.328408843727522

Epoch: 6| Step: 13
Training loss: 2.260124444961548
Validation loss: 2.3225181538571595

Epoch: 146| Step: 0
Training loss: 2.9332289695739746
Validation loss: 2.327351757275161

Epoch: 6| Step: 1
Training loss: 2.2813801765441895
Validation loss: 2.327473173859299

Epoch: 6| Step: 2
Training loss: 2.396267890930176
Validation loss: 2.3250396431133313

Epoch: 6| Step: 3
Training loss: 3.163536310195923
Validation loss: 2.3237580342959334

Epoch: 6| Step: 4
Training loss: 2.6344969272613525
Validation loss: 2.3316749988063687

Epoch: 6| Step: 5
Training loss: 2.3898794651031494
Validation loss: 2.3375174486508934

Epoch: 6| Step: 6
Training loss: 2.812981128692627
Validation loss: 2.3392215236540763

Epoch: 6| Step: 7
Training loss: 2.264298915863037
Validation loss: 2.3356935798480944

Epoch: 6| Step: 8
Training loss: 2.568964958190918
Validation loss: 2.3373442029440277

Epoch: 6| Step: 9
Training loss: 2.3082222938537598
Validation loss: 2.343970993513702

Epoch: 6| Step: 10
Training loss: 2.418837070465088
Validation loss: 2.353805234355311

Epoch: 6| Step: 11
Training loss: 1.8673644065856934
Validation loss: 2.352440572554065

Epoch: 6| Step: 12
Training loss: 3.216287851333618
Validation loss: 2.3608708522653066

Epoch: 6| Step: 13
Training loss: 2.663048267364502
Validation loss: 2.3693218923384145

Epoch: 147| Step: 0
Training loss: 1.913459300994873
Validation loss: 2.3535015198492233

Epoch: 6| Step: 1
Training loss: 2.3664803504943848
Validation loss: 2.356700728016515

Epoch: 6| Step: 2
Training loss: 2.890934467315674
Validation loss: 2.3585994961441203

Epoch: 6| Step: 3
Training loss: 3.069063663482666
Validation loss: 2.347903263184332

Epoch: 6| Step: 4
Training loss: 3.4316604137420654
Validation loss: 2.348401600314725

Epoch: 6| Step: 5
Training loss: 2.1007251739501953
Validation loss: 2.338842302240351

Epoch: 6| Step: 6
Training loss: 2.3685121536254883
Validation loss: 2.341134730205741

Epoch: 6| Step: 7
Training loss: 2.601595640182495
Validation loss: 2.346045204388198

Epoch: 6| Step: 8
Training loss: 1.7153375148773193
Validation loss: 2.3556242630045903

Epoch: 6| Step: 9
Training loss: 3.0652358531951904
Validation loss: 2.3495206243248394

Epoch: 6| Step: 10
Training loss: 1.9742313623428345
Validation loss: 2.34452853023365

Epoch: 6| Step: 11
Training loss: 3.1254379749298096
Validation loss: 2.3315330295152563

Epoch: 6| Step: 12
Training loss: 3.010206460952759
Validation loss: 2.3336436761322843

Epoch: 6| Step: 13
Training loss: 2.2578775882720947
Validation loss: 2.3238450404136413

Epoch: 148| Step: 0
Training loss: 2.5412468910217285
Validation loss: 2.318669342225598

Epoch: 6| Step: 1
Training loss: 2.6203458309173584
Validation loss: 2.327559712112591

Epoch: 6| Step: 2
Training loss: 2.8194937705993652
Validation loss: 2.336749510098529

Epoch: 6| Step: 3
Training loss: 2.220884323120117
Validation loss: 2.343962143826228

Epoch: 6| Step: 4
Training loss: 2.2964582443237305
Validation loss: 2.337769998017178

Epoch: 6| Step: 5
Training loss: 2.5591835975646973
Validation loss: 2.3236698745399393

Epoch: 6| Step: 6
Training loss: 2.9890878200531006
Validation loss: 2.3190110883405133

Epoch: 6| Step: 7
Training loss: 3.144231081008911
Validation loss: 2.3215981683423443

Epoch: 6| Step: 8
Training loss: 2.3745858669281006
Validation loss: 2.3126501934502715

Epoch: 6| Step: 9
Training loss: 2.8039374351501465
Validation loss: 2.311751704062185

Epoch: 6| Step: 10
Training loss: 2.7070300579071045
Validation loss: 2.3211001426942888

Epoch: 6| Step: 11
Training loss: 1.883065104484558
Validation loss: 2.3146827015825497

Epoch: 6| Step: 12
Training loss: 2.271939277648926
Validation loss: 2.3275841000259563

Epoch: 6| Step: 13
Training loss: 2.625328540802002
Validation loss: 2.3284429093842864

Epoch: 149| Step: 0
Training loss: 2.5153942108154297
Validation loss: 2.328884747720534

Epoch: 6| Step: 1
Training loss: 2.1243607997894287
Validation loss: 2.3384729687885573

Epoch: 6| Step: 2
Training loss: 2.6229403018951416
Validation loss: 2.335314594289308

Epoch: 6| Step: 3
Training loss: 1.7397499084472656
Validation loss: 2.343561574976931

Epoch: 6| Step: 4
Training loss: 3.236109972000122
Validation loss: 2.345241854267736

Epoch: 6| Step: 5
Training loss: 2.6829891204833984
Validation loss: 2.3445286109883297

Epoch: 6| Step: 6
Training loss: 2.6961050033569336
Validation loss: 2.3365233713580715

Epoch: 6| Step: 7
Training loss: 2.701272487640381
Validation loss: 2.331982179354596

Epoch: 6| Step: 8
Training loss: 2.719303607940674
Validation loss: 2.333308178891418

Epoch: 6| Step: 9
Training loss: 3.0561695098876953
Validation loss: 2.3275501535784815

Epoch: 6| Step: 10
Training loss: 1.6266050338745117
Validation loss: 2.3231005540458103

Epoch: 6| Step: 11
Training loss: 2.6900529861450195
Validation loss: 2.322391456173312

Epoch: 6| Step: 12
Training loss: 3.3088574409484863
Validation loss: 2.3186676579137004

Epoch: 6| Step: 13
Training loss: 1.6397976875305176
Validation loss: 2.3146397016381703

Epoch: 150| Step: 0
Training loss: 2.835416793823242
Validation loss: 2.316538336456463

Epoch: 6| Step: 1
Training loss: 2.422858238220215
Validation loss: 2.3097144352492465

Epoch: 6| Step: 2
Training loss: 3.046804904937744
Validation loss: 2.321756575697212

Epoch: 6| Step: 3
Training loss: 2.956432342529297
Validation loss: 2.3259998495860765

Epoch: 6| Step: 4
Training loss: 2.7705626487731934
Validation loss: 2.341013090584868

Epoch: 6| Step: 5
Training loss: 2.88964581489563
Validation loss: 2.3402328081028436

Epoch: 6| Step: 6
Training loss: 2.167711019515991
Validation loss: 2.331086645844162

Epoch: 6| Step: 7
Training loss: 2.450000524520874
Validation loss: 2.3306026048557733

Epoch: 6| Step: 8
Training loss: 2.3515913486480713
Validation loss: 2.3221159468414965

Epoch: 6| Step: 9
Training loss: 2.1343986988067627
Validation loss: 2.3288021138919297

Epoch: 6| Step: 10
Training loss: 2.7932050228118896
Validation loss: 2.3314067086865826

Epoch: 6| Step: 11
Training loss: 1.824066400527954
Validation loss: 2.3187916291657316

Epoch: 6| Step: 12
Training loss: 2.4652411937713623
Validation loss: 2.328383009920838

Epoch: 6| Step: 13
Training loss: 2.723033905029297
Validation loss: 2.3335157978919243

Epoch: 151| Step: 0
Training loss: 2.8792724609375
Validation loss: 2.3226463256343717

Epoch: 6| Step: 1
Training loss: 1.6408791542053223
Validation loss: 2.323462076084588

Epoch: 6| Step: 2
Training loss: 2.190882444381714
Validation loss: 2.329687371048876

Epoch: 6| Step: 3
Training loss: 2.5769519805908203
Validation loss: 2.3243267587436143

Epoch: 6| Step: 4
Training loss: 2.752983331680298
Validation loss: 2.332722392133487

Epoch: 6| Step: 5
Training loss: 2.1919643878936768
Validation loss: 2.3314583250271377

Epoch: 6| Step: 6
Training loss: 1.8816797733306885
Validation loss: 2.3337977983618297

Epoch: 6| Step: 7
Training loss: 3.252596378326416
Validation loss: 2.3309904913748465

Epoch: 6| Step: 8
Training loss: 2.8361029624938965
Validation loss: 2.3271050325004

Epoch: 6| Step: 9
Training loss: 3.068636417388916
Validation loss: 2.320683986909928

Epoch: 6| Step: 10
Training loss: 2.704227924346924
Validation loss: 2.3299856980641684

Epoch: 6| Step: 11
Training loss: 2.228062629699707
Validation loss: 2.3275037132283694

Epoch: 6| Step: 12
Training loss: 2.809767723083496
Validation loss: 2.318173034216768

Epoch: 6| Step: 13
Training loss: 2.798898458480835
Validation loss: 2.3280965461525867

Epoch: 152| Step: 0
Training loss: 2.046477794647217
Validation loss: 2.3298862877712456

Epoch: 6| Step: 1
Training loss: 2.6467700004577637
Validation loss: 2.33118672268365

Epoch: 6| Step: 2
Training loss: 2.64963960647583
Validation loss: 2.333164503497462

Epoch: 6| Step: 3
Training loss: 2.8622829914093018
Validation loss: 2.3292686067601687

Epoch: 6| Step: 4
Training loss: 2.27810001373291
Validation loss: 2.330697621068647

Epoch: 6| Step: 5
Training loss: 2.3709959983825684
Validation loss: 2.336887818510814

Epoch: 6| Step: 6
Training loss: 3.076814651489258
Validation loss: 2.33166169094783

Epoch: 6| Step: 7
Training loss: 2.407254457473755
Validation loss: 2.3258689936771186

Epoch: 6| Step: 8
Training loss: 3.0413479804992676
Validation loss: 2.33033690914031

Epoch: 6| Step: 9
Training loss: 2.218144416809082
Validation loss: 2.32248628780406

Epoch: 6| Step: 10
Training loss: 2.2259128093719482
Validation loss: 2.3256588469269457

Epoch: 6| Step: 11
Training loss: 2.0865492820739746
Validation loss: 2.3266459203535512

Epoch: 6| Step: 12
Training loss: 2.5472970008850098
Validation loss: 2.3243111923176754

Epoch: 6| Step: 13
Training loss: 3.603403329849243
Validation loss: 2.3217816070843766

Epoch: 153| Step: 0
Training loss: 2.0654373168945312
Validation loss: 2.3152891435930805

Epoch: 6| Step: 1
Training loss: 2.921017646789551
Validation loss: 2.320976448315446

Epoch: 6| Step: 2
Training loss: 2.1472747325897217
Validation loss: 2.3125771655831286

Epoch: 6| Step: 3
Training loss: 2.6129703521728516
Validation loss: 2.321523940691384

Epoch: 6| Step: 4
Training loss: 3.11026668548584
Validation loss: 2.321294161581224

Epoch: 6| Step: 5
Training loss: 2.645272731781006
Validation loss: 2.3225868132806595

Epoch: 6| Step: 6
Training loss: 2.7943267822265625
Validation loss: 2.3313480525888424

Epoch: 6| Step: 7
Training loss: 2.5229105949401855
Validation loss: 2.314216116423248

Epoch: 6| Step: 8
Training loss: 1.980581283569336
Validation loss: 2.3186931251197733

Epoch: 6| Step: 9
Training loss: 2.9436333179473877
Validation loss: 2.3137449269653647

Epoch: 6| Step: 10
Training loss: 2.71936297416687
Validation loss: 2.314483657959969

Epoch: 6| Step: 11
Training loss: 2.5453109741210938
Validation loss: 2.317005700962518

Epoch: 6| Step: 12
Training loss: 2.243612766265869
Validation loss: 2.3064592525523198

Epoch: 6| Step: 13
Training loss: 2.1510417461395264
Validation loss: 2.307081876262542

Epoch: 154| Step: 0
Training loss: 2.3648953437805176
Validation loss: 2.306793289799844

Epoch: 6| Step: 1
Training loss: 2.2628588676452637
Validation loss: 2.3037571445588143

Epoch: 6| Step: 2
Training loss: 2.1002960205078125
Validation loss: 2.306038823179019

Epoch: 6| Step: 3
Training loss: 1.9564051628112793
Validation loss: 2.301730627654701

Epoch: 6| Step: 4
Training loss: 2.690542221069336
Validation loss: 2.30838256753901

Epoch: 6| Step: 5
Training loss: 2.3958921432495117
Validation loss: 2.3021555767264417

Epoch: 6| Step: 6
Training loss: 2.509544610977173
Validation loss: 2.306264620955272

Epoch: 6| Step: 7
Training loss: 2.786977767944336
Validation loss: 2.311252699103407

Epoch: 6| Step: 8
Training loss: 3.870985746383667
Validation loss: 2.3069202105204263

Epoch: 6| Step: 9
Training loss: 2.144798994064331
Validation loss: 2.3121531086583293

Epoch: 6| Step: 10
Training loss: 2.171724319458008
Validation loss: 2.311149694586313

Epoch: 6| Step: 11
Training loss: 2.3081741333007812
Validation loss: 2.3178789051630164

Epoch: 6| Step: 12
Training loss: 3.599881649017334
Validation loss: 2.324875636767316

Epoch: 6| Step: 13
Training loss: 2.460259437561035
Validation loss: 2.3362988272020893

Epoch: 155| Step: 0
Training loss: 2.4436392784118652
Validation loss: 2.336678276779831

Epoch: 6| Step: 1
Training loss: 2.675722599029541
Validation loss: 2.33070570166393

Epoch: 6| Step: 2
Training loss: 2.6988096237182617
Validation loss: 2.3227383090603735

Epoch: 6| Step: 3
Training loss: 2.006193161010742
Validation loss: 2.316503788835259

Epoch: 6| Step: 4
Training loss: 2.614187240600586
Validation loss: 2.322792371114095

Epoch: 6| Step: 5
Training loss: 2.956470012664795
Validation loss: 2.313194123647546

Epoch: 6| Step: 6
Training loss: 2.878674030303955
Validation loss: 2.319401841009817

Epoch: 6| Step: 7
Training loss: 2.3819544315338135
Validation loss: 2.318659113299462

Epoch: 6| Step: 8
Training loss: 2.0554919242858887
Validation loss: 2.322826208606843

Epoch: 6| Step: 9
Training loss: 2.102388381958008
Validation loss: 2.315991945164178

Epoch: 6| Step: 10
Training loss: 2.5140738487243652
Validation loss: 2.3258660147267003

Epoch: 6| Step: 11
Training loss: 3.262523651123047
Validation loss: 2.318266343044978

Epoch: 6| Step: 12
Training loss: 2.2994840145111084
Validation loss: 2.3106435421974427

Epoch: 6| Step: 13
Training loss: 2.8040151596069336
Validation loss: 2.3171452783769175

Epoch: 156| Step: 0
Training loss: 1.4043304920196533
Validation loss: 2.3285904981756724

Epoch: 6| Step: 1
Training loss: 2.9504618644714355
Validation loss: 2.320028531935907

Epoch: 6| Step: 2
Training loss: 2.5430126190185547
Validation loss: 2.324750349085818

Epoch: 6| Step: 3
Training loss: 2.4175078868865967
Validation loss: 2.322304359046362

Epoch: 6| Step: 4
Training loss: 2.76294207572937
Validation loss: 2.3244593579282045

Epoch: 6| Step: 5
Training loss: 2.9993302822113037
Validation loss: 2.33337337740006

Epoch: 6| Step: 6
Training loss: 2.545226812362671
Validation loss: 2.3268118199481758

Epoch: 6| Step: 7
Training loss: 2.2533926963806152
Validation loss: 2.3229135364614506

Epoch: 6| Step: 8
Training loss: 2.508756637573242
Validation loss: 2.313631293594196

Epoch: 6| Step: 9
Training loss: 2.549323081970215
Validation loss: 2.3253208975638113

Epoch: 6| Step: 10
Training loss: 3.3191046714782715
Validation loss: 2.3164164225260415

Epoch: 6| Step: 11
Training loss: 2.907809019088745
Validation loss: 2.314581230122556

Epoch: 6| Step: 12
Training loss: 1.9784607887268066
Validation loss: 2.3125651151903215

Epoch: 6| Step: 13
Training loss: 2.279343843460083
Validation loss: 2.3096342932793403

Epoch: 157| Step: 0
Training loss: 2.7590694427490234
Validation loss: 2.3127190836014284

Epoch: 6| Step: 1
Training loss: 2.5478639602661133
Validation loss: 2.31570771432692

Epoch: 6| Step: 2
Training loss: 2.827842950820923
Validation loss: 2.3200363933399157

Epoch: 6| Step: 3
Training loss: 2.544102191925049
Validation loss: 2.3298782840851815

Epoch: 6| Step: 4
Training loss: 2.5378546714782715
Validation loss: 2.335854971280662

Epoch: 6| Step: 5
Training loss: 2.5178990364074707
Validation loss: 2.3310309738241215

Epoch: 6| Step: 6
Training loss: 2.4516587257385254
Validation loss: 2.3262058765657487

Epoch: 6| Step: 7
Training loss: 2.5705108642578125
Validation loss: 2.318778899408156

Epoch: 6| Step: 8
Training loss: 2.5295848846435547
Validation loss: 2.3127624655282624

Epoch: 6| Step: 9
Training loss: 2.563249111175537
Validation loss: 2.302417480817405

Epoch: 6| Step: 10
Training loss: 2.615419626235962
Validation loss: 2.3004330127469954

Epoch: 6| Step: 11
Training loss: 2.1372129917144775
Validation loss: 2.3032227844320317

Epoch: 6| Step: 12
Training loss: 2.9339163303375244
Validation loss: 2.3065736139974287

Epoch: 6| Step: 13
Training loss: 1.7282776832580566
Validation loss: 2.302823333330052

Epoch: 158| Step: 0
Training loss: 2.8553950786590576
Validation loss: 2.309975134429111

Epoch: 6| Step: 1
Training loss: 2.642338991165161
Validation loss: 2.3248641978028

Epoch: 6| Step: 2
Training loss: 2.933044672012329
Validation loss: 2.3349503624823784

Epoch: 6| Step: 3
Training loss: 2.584695339202881
Validation loss: 2.332824509630921

Epoch: 6| Step: 4
Training loss: 2.8186585903167725
Validation loss: 2.3403618515178723

Epoch: 6| Step: 5
Training loss: 2.5418498516082764
Validation loss: 2.334305965772239

Epoch: 6| Step: 6
Training loss: 2.601419687271118
Validation loss: 2.3277700665176555

Epoch: 6| Step: 7
Training loss: 2.0199007987976074
Validation loss: 2.325409609784362

Epoch: 6| Step: 8
Training loss: 2.463949680328369
Validation loss: 2.3065275453752085

Epoch: 6| Step: 9
Training loss: 2.253016948699951
Validation loss: 2.307995065566032

Epoch: 6| Step: 10
Training loss: 2.926692008972168
Validation loss: 2.3020397950244207

Epoch: 6| Step: 11
Training loss: 2.5189108848571777
Validation loss: 2.2986529770717827

Epoch: 6| Step: 12
Training loss: 1.7873809337615967
Validation loss: 2.3024584119037916

Epoch: 6| Step: 13
Training loss: 3.1635513305664062
Validation loss: 2.3074095838813373

Epoch: 159| Step: 0
Training loss: 2.0268654823303223
Validation loss: 2.303077495226296

Epoch: 6| Step: 1
Training loss: 1.7453821897506714
Validation loss: 2.301878635601331

Epoch: 6| Step: 2
Training loss: 2.6271767616271973
Validation loss: 2.2993376742127123

Epoch: 6| Step: 3
Training loss: 2.669334888458252
Validation loss: 2.295811712100942

Epoch: 6| Step: 4
Training loss: 2.6242942810058594
Validation loss: 2.2884261121032057

Epoch: 6| Step: 5
Training loss: 2.040215015411377
Validation loss: 2.2877159554471254

Epoch: 6| Step: 6
Training loss: 2.8512539863586426
Validation loss: 2.2852121681295414

Epoch: 6| Step: 7
Training loss: 3.2831063270568848
Validation loss: 2.291156002270278

Epoch: 6| Step: 8
Training loss: 2.5582809448242188
Validation loss: 2.2894820064626713

Epoch: 6| Step: 9
Training loss: 2.186469793319702
Validation loss: 2.2911924995401853

Epoch: 6| Step: 10
Training loss: 2.876309633255005
Validation loss: 2.2963087007563603

Epoch: 6| Step: 11
Training loss: 2.893827199935913
Validation loss: 2.3051939369529806

Epoch: 6| Step: 12
Training loss: 2.840785503387451
Validation loss: 2.3093060883142615

Epoch: 6| Step: 13
Training loss: 2.356045722961426
Validation loss: 2.317373074511046

Epoch: 160| Step: 0
Training loss: 2.5042648315429688
Validation loss: 2.3312943853357786

Epoch: 6| Step: 1
Training loss: 2.8662781715393066
Validation loss: 2.3296317720925934

Epoch: 6| Step: 2
Training loss: 2.130758285522461
Validation loss: 2.3398050620991695

Epoch: 6| Step: 3
Training loss: 2.1620540618896484
Validation loss: 2.339166800181071

Epoch: 6| Step: 4
Training loss: 2.5064032077789307
Validation loss: 2.343047285592684

Epoch: 6| Step: 5
Training loss: 2.2717220783233643
Validation loss: 2.337312993182931

Epoch: 6| Step: 6
Training loss: 2.4992823600769043
Validation loss: 2.336461837573718

Epoch: 6| Step: 7
Training loss: 2.3348875045776367
Validation loss: 2.320246022234681

Epoch: 6| Step: 8
Training loss: 2.463475227355957
Validation loss: 2.3213771594467985

Epoch: 6| Step: 9
Training loss: 2.4587762355804443
Validation loss: 2.3144159599017073

Epoch: 6| Step: 10
Training loss: 3.2903618812561035
Validation loss: 2.3098855095524944

Epoch: 6| Step: 11
Training loss: 3.1227824687957764
Validation loss: 2.3053960313079176

Epoch: 6| Step: 12
Training loss: 1.754639744758606
Validation loss: 2.3099748575559227

Epoch: 6| Step: 13
Training loss: 3.7315890789031982
Validation loss: 2.304767111296295

Epoch: 161| Step: 0
Training loss: 2.1022520065307617
Validation loss: 2.301759094320318

Epoch: 6| Step: 1
Training loss: 2.546942710876465
Validation loss: 2.2993816919224237

Epoch: 6| Step: 2
Training loss: 3.300797462463379
Validation loss: 2.2917440014500774

Epoch: 6| Step: 3
Training loss: 2.889786720275879
Validation loss: 2.291256079109766

Epoch: 6| Step: 4
Training loss: 2.871354103088379
Validation loss: 2.2939429744597404

Epoch: 6| Step: 5
Training loss: 1.8807493448257446
Validation loss: 2.2907830848488757

Epoch: 6| Step: 6
Training loss: 2.347851276397705
Validation loss: 2.280647567523423

Epoch: 6| Step: 7
Training loss: 2.5339486598968506
Validation loss: 2.2868174737499607

Epoch: 6| Step: 8
Training loss: 1.6835148334503174
Validation loss: 2.284987042027135

Epoch: 6| Step: 9
Training loss: 2.434248924255371
Validation loss: 2.291884832484748

Epoch: 6| Step: 10
Training loss: 3.0443458557128906
Validation loss: 2.28806407220902

Epoch: 6| Step: 11
Training loss: 2.6337904930114746
Validation loss: 2.304971889782977

Epoch: 6| Step: 12
Training loss: 2.7293500900268555
Validation loss: 2.303839155422744

Epoch: 6| Step: 13
Training loss: 2.422377586364746
Validation loss: 2.31134775505271

Epoch: 162| Step: 0
Training loss: 2.8814644813537598
Validation loss: 2.3280960539335847

Epoch: 6| Step: 1
Training loss: 1.931931734085083
Validation loss: 2.3373418341400805

Epoch: 6| Step: 2
Training loss: 3.15657901763916
Validation loss: 2.3555699856050554

Epoch: 6| Step: 3
Training loss: 2.46189546585083
Validation loss: 2.349449570460986

Epoch: 6| Step: 4
Training loss: 2.845715045928955
Validation loss: 2.3500113128333964

Epoch: 6| Step: 5
Training loss: 2.2776613235473633
Validation loss: 2.3398031162959274

Epoch: 6| Step: 6
Training loss: 2.9879631996154785
Validation loss: 2.3208696662738757

Epoch: 6| Step: 7
Training loss: 2.484555244445801
Validation loss: 2.3075107502680954

Epoch: 6| Step: 8
Training loss: 2.3741140365600586
Validation loss: 2.297287823051535

Epoch: 6| Step: 9
Training loss: 2.459815263748169
Validation loss: 2.2989717747575495

Epoch: 6| Step: 10
Training loss: 2.708205223083496
Validation loss: 2.3044830112047094

Epoch: 6| Step: 11
Training loss: 2.0932223796844482
Validation loss: 2.3120414364722466

Epoch: 6| Step: 12
Training loss: 2.8946971893310547
Validation loss: 2.312694785415485

Epoch: 6| Step: 13
Training loss: 1.9704867601394653
Validation loss: 2.307433702612436

Epoch: 163| Step: 0
Training loss: 2.605496883392334
Validation loss: 2.311432132156946

Epoch: 6| Step: 1
Training loss: 2.4880847930908203
Validation loss: 2.3123720371594993

Epoch: 6| Step: 2
Training loss: 2.345945119857788
Validation loss: 2.3015085599755727

Epoch: 6| Step: 3
Training loss: 2.4644205570220947
Validation loss: 2.3048340120623187

Epoch: 6| Step: 4
Training loss: 2.6238982677459717
Validation loss: 2.299893119001901

Epoch: 6| Step: 5
Training loss: 2.021214008331299
Validation loss: 2.2930163619338826

Epoch: 6| Step: 6
Training loss: 2.134291648864746
Validation loss: 2.317858148646611

Epoch: 6| Step: 7
Training loss: 3.183610439300537
Validation loss: 2.313374685984786

Epoch: 6| Step: 8
Training loss: 2.4100148677825928
Validation loss: 2.3126663905318066

Epoch: 6| Step: 9
Training loss: 1.9411243200302124
Validation loss: 2.324107094477582

Epoch: 6| Step: 10
Training loss: 2.833082675933838
Validation loss: 2.336237302390478

Epoch: 6| Step: 11
Training loss: 3.003749370574951
Validation loss: 2.339427499360936

Epoch: 6| Step: 12
Training loss: 2.76446270942688
Validation loss: 2.3428054035350843

Epoch: 6| Step: 13
Training loss: 2.803513765335083
Validation loss: 2.3364110300617833

Epoch: 164| Step: 0
Training loss: 3.0817959308624268
Validation loss: 2.340425750260712

Epoch: 6| Step: 1
Training loss: 2.631030797958374
Validation loss: 2.3424763089867047

Epoch: 6| Step: 2
Training loss: 3.0912904739379883
Validation loss: 2.353115142032664

Epoch: 6| Step: 3
Training loss: 1.6132395267486572
Validation loss: 2.3389256513246925

Epoch: 6| Step: 4
Training loss: 2.5035338401794434
Validation loss: 2.3450998747220604

Epoch: 6| Step: 5
Training loss: 2.704686164855957
Validation loss: 2.328573365365305

Epoch: 6| Step: 6
Training loss: 3.3870701789855957
Validation loss: 2.325309363744592

Epoch: 6| Step: 7
Training loss: 1.9092957973480225
Validation loss: 2.319974555764147

Epoch: 6| Step: 8
Training loss: 1.9528629779815674
Validation loss: 2.299271665593629

Epoch: 6| Step: 9
Training loss: 1.9033349752426147
Validation loss: 2.289528964668192

Epoch: 6| Step: 10
Training loss: 2.3080854415893555
Validation loss: 2.2913350097594725

Epoch: 6| Step: 11
Training loss: 2.4223642349243164
Validation loss: 2.2923022777803483

Epoch: 6| Step: 12
Training loss: 2.7103629112243652
Validation loss: 2.289441603486256

Epoch: 6| Step: 13
Training loss: 3.5752782821655273
Validation loss: 2.2834242005502023

Epoch: 165| Step: 0
Training loss: 2.7816295623779297
Validation loss: 2.2886527968991186

Epoch: 6| Step: 1
Training loss: 2.244227409362793
Validation loss: 2.2870903374046407

Epoch: 6| Step: 2
Training loss: 2.140777349472046
Validation loss: 2.2878352083185667

Epoch: 6| Step: 3
Training loss: 2.318228006362915
Validation loss: 2.2812159830524075

Epoch: 6| Step: 4
Training loss: 2.3609774112701416
Validation loss: 2.2833811775330575

Epoch: 6| Step: 5
Training loss: 2.4934518337249756
Validation loss: 2.281930793998062

Epoch: 6| Step: 6
Training loss: 2.4717462062835693
Validation loss: 2.2921875138436594

Epoch: 6| Step: 7
Training loss: 3.0667641162872314
Validation loss: 2.2821479817872405

Epoch: 6| Step: 8
Training loss: 3.4058592319488525
Validation loss: 2.3004226902479767

Epoch: 6| Step: 9
Training loss: 2.3485147953033447
Validation loss: 2.2972111522510485

Epoch: 6| Step: 10
Training loss: 2.5364365577697754
Validation loss: 2.301957017631941

Epoch: 6| Step: 11
Training loss: 2.4034268856048584
Validation loss: 2.300844075859234

Epoch: 6| Step: 12
Training loss: 2.1703360080718994
Validation loss: 2.321528175825714

Epoch: 6| Step: 13
Training loss: 2.844815254211426
Validation loss: 2.3217226971862135

Epoch: 166| Step: 0
Training loss: 2.1711480617523193
Validation loss: 2.330898279784828

Epoch: 6| Step: 1
Training loss: 3.5113401412963867
Validation loss: 2.3228076401577202

Epoch: 6| Step: 2
Training loss: 2.8788020610809326
Validation loss: 2.317094438819475

Epoch: 6| Step: 3
Training loss: 2.962449789047241
Validation loss: 2.3273557693727556

Epoch: 6| Step: 4
Training loss: 1.797705888748169
Validation loss: 2.3189367299438803

Epoch: 6| Step: 5
Training loss: 1.719693660736084
Validation loss: 2.3034728662942046

Epoch: 6| Step: 6
Training loss: 2.5687429904937744
Validation loss: 2.3081894484899377

Epoch: 6| Step: 7
Training loss: 2.246321678161621
Validation loss: 2.292510255690544

Epoch: 6| Step: 8
Training loss: 2.946988582611084
Validation loss: 2.29633730201311

Epoch: 6| Step: 9
Training loss: 2.3309311866760254
Validation loss: 2.2897631916948544

Epoch: 6| Step: 10
Training loss: 2.589285373687744
Validation loss: 2.2794029712677

Epoch: 6| Step: 11
Training loss: 2.65767240524292
Validation loss: 2.285319041180354

Epoch: 6| Step: 12
Training loss: 2.8016815185546875
Validation loss: 2.277376554345572

Epoch: 6| Step: 13
Training loss: 2.109434127807617
Validation loss: 2.2816203204534387

Epoch: 167| Step: 0
Training loss: 2.6036548614501953
Validation loss: 2.278438047696185

Epoch: 6| Step: 1
Training loss: 3.1310248374938965
Validation loss: 2.2869514034640406

Epoch: 6| Step: 2
Training loss: 2.686948776245117
Validation loss: 2.2882587537970593

Epoch: 6| Step: 3
Training loss: 2.395034074783325
Validation loss: 2.28715742018915

Epoch: 6| Step: 4
Training loss: 2.1406407356262207
Validation loss: 2.2977335478669856

Epoch: 6| Step: 5
Training loss: 3.1686456203460693
Validation loss: 2.3052701719345583

Epoch: 6| Step: 6
Training loss: 2.8861587047576904
Validation loss: 2.3045591128769742

Epoch: 6| Step: 7
Training loss: 2.0981569290161133
Validation loss: 2.3020179604971283

Epoch: 6| Step: 8
Training loss: 2.01625919342041
Validation loss: 2.321906305128528

Epoch: 6| Step: 9
Training loss: 2.0924224853515625
Validation loss: 2.320385576576315

Epoch: 6| Step: 10
Training loss: 2.774904727935791
Validation loss: 2.322483008907687

Epoch: 6| Step: 11
Training loss: 2.286360263824463
Validation loss: 2.33405993318045

Epoch: 6| Step: 12
Training loss: 2.77009916305542
Validation loss: 2.3327166367602605

Epoch: 6| Step: 13
Training loss: 2.1364569664001465
Validation loss: 2.318773615744806

Epoch: 168| Step: 0
Training loss: 3.428844928741455
Validation loss: 2.3073019571201776

Epoch: 6| Step: 1
Training loss: 2.421884059906006
Validation loss: 2.2936417774487565

Epoch: 6| Step: 2
Training loss: 2.61971116065979
Validation loss: 2.2908356035909345

Epoch: 6| Step: 3
Training loss: 2.6916794776916504
Validation loss: 2.288763628211073

Epoch: 6| Step: 4
Training loss: 2.8928046226501465
Validation loss: 2.270076095416982

Epoch: 6| Step: 5
Training loss: 2.9635162353515625
Validation loss: 2.272243356191984

Epoch: 6| Step: 6
Training loss: 2.052198886871338
Validation loss: 2.275513490041097

Epoch: 6| Step: 7
Training loss: 2.0246453285217285
Validation loss: 2.2679458818128033

Epoch: 6| Step: 8
Training loss: 2.2044758796691895
Validation loss: 2.26778858195069

Epoch: 6| Step: 9
Training loss: 2.212390422821045
Validation loss: 2.2677984186398086

Epoch: 6| Step: 10
Training loss: 2.8428151607513428
Validation loss: 2.2767327639364425

Epoch: 6| Step: 11
Training loss: 2.1322381496429443
Validation loss: 2.272305566777465

Epoch: 6| Step: 12
Training loss: 2.216714859008789
Validation loss: 2.281695870942967

Epoch: 6| Step: 13
Training loss: 2.8019485473632812
Validation loss: 2.300205769077424

Epoch: 169| Step: 0
Training loss: 2.7689175605773926
Validation loss: 2.3003021850380847

Epoch: 6| Step: 1
Training loss: 1.9703360795974731
Validation loss: 2.30327247804211

Epoch: 6| Step: 2
Training loss: 2.580984592437744
Validation loss: 2.302120121576453

Epoch: 6| Step: 3
Training loss: 2.408259153366089
Validation loss: 2.2977459533240205

Epoch: 6| Step: 4
Training loss: 2.108600378036499
Validation loss: 2.30606650024332

Epoch: 6| Step: 5
Training loss: 3.6427853107452393
Validation loss: 2.308200546490249

Epoch: 6| Step: 6
Training loss: 2.144627094268799
Validation loss: 2.311794860388643

Epoch: 6| Step: 7
Training loss: 2.1195478439331055
Validation loss: 2.30180444512316

Epoch: 6| Step: 8
Training loss: 2.0009968280792236
Validation loss: 2.3175399123981433

Epoch: 6| Step: 9
Training loss: 1.9789716005325317
Validation loss: 2.321218377800398

Epoch: 6| Step: 10
Training loss: 3.3174538612365723
Validation loss: 2.321978284466651

Epoch: 6| Step: 11
Training loss: 2.6528844833374023
Validation loss: 2.313799956793426

Epoch: 6| Step: 12
Training loss: 3.042491912841797
Validation loss: 2.313628973499421

Epoch: 6| Step: 13
Training loss: 2.584346294403076
Validation loss: 2.317897827394547

Epoch: 170| Step: 0
Training loss: 1.48533296585083
Validation loss: 2.313062355082522

Epoch: 6| Step: 1
Training loss: 2.926311492919922
Validation loss: 2.3097108538432787

Epoch: 6| Step: 2
Training loss: 2.6239874362945557
Validation loss: 2.3066103061040244

Epoch: 6| Step: 3
Training loss: 2.306112766265869
Validation loss: 2.304502220563991

Epoch: 6| Step: 4
Training loss: 2.0766096115112305
Validation loss: 2.283041295184884

Epoch: 6| Step: 5
Training loss: 2.761871337890625
Validation loss: 2.2792535110186507

Epoch: 6| Step: 6
Training loss: 2.3382792472839355
Validation loss: 2.274835712166243

Epoch: 6| Step: 7
Training loss: 3.1099743843078613
Validation loss: 2.2707875838843723

Epoch: 6| Step: 8
Training loss: 2.596397638320923
Validation loss: 2.2793716922883065

Epoch: 6| Step: 9
Training loss: 2.52219820022583
Validation loss: 2.280008190421648

Epoch: 6| Step: 10
Training loss: 2.684432029724121
Validation loss: 2.2874138188618485

Epoch: 6| Step: 11
Training loss: 2.777939796447754
Validation loss: 2.294973974586815

Epoch: 6| Step: 12
Training loss: 3.149691104888916
Validation loss: 2.299415830642946

Epoch: 6| Step: 13
Training loss: 1.6697074174880981
Validation loss: 2.2892594029826503

Epoch: 171| Step: 0
Training loss: 3.4482169151306152
Validation loss: 2.293347999613772

Epoch: 6| Step: 1
Training loss: 2.2208504676818848
Validation loss: 2.2786511298148864

Epoch: 6| Step: 2
Training loss: 3.240220785140991
Validation loss: 2.266561436396773

Epoch: 6| Step: 3
Training loss: 1.766994595527649
Validation loss: 2.2656197765822053

Epoch: 6| Step: 4
Training loss: 2.1009440422058105
Validation loss: 2.26546206525577

Epoch: 6| Step: 5
Training loss: 2.5629758834838867
Validation loss: 2.2670868981269097

Epoch: 6| Step: 6
Training loss: 2.505741596221924
Validation loss: 2.273554430213026

Epoch: 6| Step: 7
Training loss: 1.8450651168823242
Validation loss: 2.278586715780279

Epoch: 6| Step: 8
Training loss: 2.5559005737304688
Validation loss: 2.284925591561102

Epoch: 6| Step: 9
Training loss: 2.5188794136047363
Validation loss: 2.285297662981095

Epoch: 6| Step: 10
Training loss: 2.1663618087768555
Validation loss: 2.2935916223833637

Epoch: 6| Step: 11
Training loss: 2.738093376159668
Validation loss: 2.3006175205271733

Epoch: 6| Step: 12
Training loss: 3.213548183441162
Validation loss: 2.301120169701115

Epoch: 6| Step: 13
Training loss: 2.2203476428985596
Validation loss: 2.300342341904999

Epoch: 172| Step: 0
Training loss: 1.6986314058303833
Validation loss: 2.3032246302532893

Epoch: 6| Step: 1
Training loss: 3.5045077800750732
Validation loss: 2.3170506338919363

Epoch: 6| Step: 2
Training loss: 2.866687774658203
Validation loss: 2.312850413783904

Epoch: 6| Step: 3
Training loss: 2.6607213020324707
Validation loss: 2.3154229810160976

Epoch: 6| Step: 4
Training loss: 1.930609941482544
Validation loss: 2.308515456414992

Epoch: 6| Step: 5
Training loss: 2.729057788848877
Validation loss: 2.3031425937529533

Epoch: 6| Step: 6
Training loss: 3.012636184692383
Validation loss: 2.308176273940712

Epoch: 6| Step: 7
Training loss: 2.3621578216552734
Validation loss: 2.3045761226325907

Epoch: 6| Step: 8
Training loss: 2.9633593559265137
Validation loss: 2.2924680658566055

Epoch: 6| Step: 9
Training loss: 2.05969500541687
Validation loss: 2.286538703467256

Epoch: 6| Step: 10
Training loss: 2.536593437194824
Validation loss: 2.2800246387399654

Epoch: 6| Step: 11
Training loss: 2.328314781188965
Validation loss: 2.2823889588796966

Epoch: 6| Step: 12
Training loss: 2.0138015747070312
Validation loss: 2.278306817495695

Epoch: 6| Step: 13
Training loss: 2.3619015216827393
Validation loss: 2.2722163533651702

Epoch: 173| Step: 0
Training loss: 2.0547304153442383
Validation loss: 2.269221741666076

Epoch: 6| Step: 1
Training loss: 2.974729061126709
Validation loss: 2.273804562066191

Epoch: 6| Step: 2
Training loss: 2.4578397274017334
Validation loss: 2.276162819195819

Epoch: 6| Step: 3
Training loss: 2.9382033348083496
Validation loss: 2.2757502653265513

Epoch: 6| Step: 4
Training loss: 2.4106245040893555
Validation loss: 2.278425174374734

Epoch: 6| Step: 5
Training loss: 2.403956890106201
Validation loss: 2.285101052253477

Epoch: 6| Step: 6
Training loss: 2.318925380706787
Validation loss: 2.2696842583276893

Epoch: 6| Step: 7
Training loss: 2.1879262924194336
Validation loss: 2.281148085030176

Epoch: 6| Step: 8
Training loss: 1.9678025245666504
Validation loss: 2.287136980282363

Epoch: 6| Step: 9
Training loss: 2.563396453857422
Validation loss: 2.294894387645106

Epoch: 6| Step: 10
Training loss: 2.859584331512451
Validation loss: 2.307469070598643

Epoch: 6| Step: 11
Training loss: 2.5449209213256836
Validation loss: 2.3212527613486014

Epoch: 6| Step: 12
Training loss: 2.8225293159484863
Validation loss: 2.323615550994873

Epoch: 6| Step: 13
Training loss: 2.86446213722229
Validation loss: 2.327882259122787

Epoch: 174| Step: 0
Training loss: 2.9643802642822266
Validation loss: 2.3102990324779222

Epoch: 6| Step: 1
Training loss: 2.8052642345428467
Validation loss: 2.2937372166623353

Epoch: 6| Step: 2
Training loss: 2.6800754070281982
Validation loss: 2.2935935322956373

Epoch: 6| Step: 3
Training loss: 2.0063061714172363
Validation loss: 2.2747860800835396

Epoch: 6| Step: 4
Training loss: 2.557407855987549
Validation loss: 2.2889040311177573

Epoch: 6| Step: 5
Training loss: 3.290759563446045
Validation loss: 2.27954726834451

Epoch: 6| Step: 6
Training loss: 2.519409656524658
Validation loss: 2.287558035183978

Epoch: 6| Step: 7
Training loss: 2.340846538543701
Validation loss: 2.2731451347310054

Epoch: 6| Step: 8
Training loss: 3.0038812160491943
Validation loss: 2.2889750439633607

Epoch: 6| Step: 9
Training loss: 2.4027814865112305
Validation loss: 2.275999266614196

Epoch: 6| Step: 10
Training loss: 2.2824766635894775
Validation loss: 2.290069672369188

Epoch: 6| Step: 11
Training loss: 1.272068977355957
Validation loss: 2.2795093867086593

Epoch: 6| Step: 12
Training loss: 2.13676118850708
Validation loss: 2.2709227249186528

Epoch: 6| Step: 13
Training loss: 3.0036652088165283
Validation loss: 2.286684315691712

Epoch: 175| Step: 0
Training loss: 2.1735992431640625
Validation loss: 2.2852775999294814

Epoch: 6| Step: 1
Training loss: 2.640132427215576
Validation loss: 2.282383180433704

Epoch: 6| Step: 2
Training loss: 2.588693380355835
Validation loss: 2.2778640024123655

Epoch: 6| Step: 3
Training loss: 3.089785099029541
Validation loss: 2.28606746017292

Epoch: 6| Step: 4
Training loss: 2.2180213928222656
Validation loss: 2.277781142983385

Epoch: 6| Step: 5
Training loss: 2.0046896934509277
Validation loss: 2.2722518187697216

Epoch: 6| Step: 6
Training loss: 2.848580837249756
Validation loss: 2.272753551442136

Epoch: 6| Step: 7
Training loss: 2.9927725791931152
Validation loss: 2.2740363920888593

Epoch: 6| Step: 8
Training loss: 2.5495429039001465
Validation loss: 2.271471923397433

Epoch: 6| Step: 9
Training loss: 2.4104928970336914
Validation loss: 2.2834038324253534

Epoch: 6| Step: 10
Training loss: 2.7881929874420166
Validation loss: 2.286157715705133

Epoch: 6| Step: 11
Training loss: 2.6061110496520996
Validation loss: 2.285149476861441

Epoch: 6| Step: 12
Training loss: 2.430172920227051
Validation loss: 2.2920521125998548

Epoch: 6| Step: 13
Training loss: 1.2789037227630615
Validation loss: 2.2921022676652476

Testing loss: 2.4889431953430177
