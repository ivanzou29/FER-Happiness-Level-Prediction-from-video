Epoch: 1| Step: 0
Training loss: 6.4219293522449
Validation loss: 5.851414456526433

Epoch: 5| Step: 1
Training loss: 6.317541243400042
Validation loss: 5.845474696713001

Epoch: 5| Step: 2
Training loss: 5.5055108638369035
Validation loss: 5.8400302270176425

Epoch: 5| Step: 3
Training loss: 4.976318736671247
Validation loss: 5.834324733440412

Epoch: 5| Step: 4
Training loss: 6.399184783036912
Validation loss: 5.8291936797048765

Epoch: 5| Step: 5
Training loss: 5.249417772251684
Validation loss: 5.8242408358786655

Epoch: 5| Step: 6
Training loss: 5.896900022096819
Validation loss: 5.819518122805949

Epoch: 5| Step: 7
Training loss: 6.169711040240731
Validation loss: 5.8153564829839155

Epoch: 5| Step: 8
Training loss: 6.015586000786734
Validation loss: 5.810504473308062

Epoch: 5| Step: 9
Training loss: 5.868849761407482
Validation loss: 5.806048308144832

Epoch: 5| Step: 10
Training loss: 5.3348880925548015
Validation loss: 5.801547546916273

Epoch: 2| Step: 0
Training loss: 5.4186155872327895
Validation loss: 5.797150498114037

Epoch: 5| Step: 1
Training loss: 4.950309073306903
Validation loss: 5.792422069697863

Epoch: 5| Step: 2
Training loss: 5.8867935955552175
Validation loss: 5.787783868316914

Epoch: 5| Step: 3
Training loss: 5.47319068450213
Validation loss: 5.783338692371146

Epoch: 5| Step: 4
Training loss: 5.223141769632403
Validation loss: 5.778375872447523

Epoch: 5| Step: 5
Training loss: 5.938267708386415
Validation loss: 5.773191094838265

Epoch: 5| Step: 6
Training loss: 6.473554660511252
Validation loss: 5.767834939477758

Epoch: 5| Step: 7
Training loss: 5.413720410481255
Validation loss: 5.7620412539878645

Epoch: 5| Step: 8
Training loss: 5.733236672821211
Validation loss: 5.756008488312597

Epoch: 5| Step: 9
Training loss: 6.382894975369841
Validation loss: 5.749944375416916

Epoch: 5| Step: 10
Training loss: 6.819093645564098
Validation loss: 5.743145852795255

Epoch: 3| Step: 0
Training loss: 6.1626915706547845
Validation loss: 5.736759337106057

Epoch: 5| Step: 1
Training loss: 6.170915050940012
Validation loss: 5.729145687956077

Epoch: 5| Step: 2
Training loss: 5.102046458727772
Validation loss: 5.721498421235716

Epoch: 5| Step: 3
Training loss: 4.905405542871971
Validation loss: 5.713555277081687

Epoch: 5| Step: 4
Training loss: 6.905581066479682
Validation loss: 5.704764519795568

Epoch: 5| Step: 5
Training loss: 5.247690873729662
Validation loss: 5.696022129810405

Epoch: 5| Step: 6
Training loss: 5.000717493076032
Validation loss: 5.686454364009629

Epoch: 5| Step: 7
Training loss: 6.098912013850138
Validation loss: 5.677514687443457

Epoch: 5| Step: 8
Training loss: 5.821904275833867
Validation loss: 5.666901416488468

Epoch: 5| Step: 9
Training loss: 5.874387993285283
Validation loss: 5.656180242256619

Epoch: 5| Step: 10
Training loss: 5.331455834049908
Validation loss: 5.644449585791772

Epoch: 4| Step: 0
Training loss: 5.615180026910904
Validation loss: 5.632582510925551

Epoch: 5| Step: 1
Training loss: 5.998197602713766
Validation loss: 5.619607153740496

Epoch: 5| Step: 2
Training loss: 6.091718599208549
Validation loss: 5.6058256261145605

Epoch: 5| Step: 3
Training loss: 5.800463611884223
Validation loss: 5.592310452745408

Epoch: 5| Step: 4
Training loss: 5.126632244422811
Validation loss: 5.577494063645937

Epoch: 5| Step: 5
Training loss: 5.5160237025027605
Validation loss: 5.5627744338983405

Epoch: 5| Step: 6
Training loss: 5.0671525462895
Validation loss: 5.547346661630951

Epoch: 5| Step: 7
Training loss: 4.717274820505769
Validation loss: 5.531142789769095

Epoch: 5| Step: 8
Training loss: 5.879232951366662
Validation loss: 5.513925800919907

Epoch: 5| Step: 9
Training loss: 5.530555293535939
Validation loss: 5.497914326198076

Epoch: 5| Step: 10
Training loss: 6.120434363415312
Validation loss: 5.479221806770621

Epoch: 5| Step: 0
Training loss: 6.197560771907313
Validation loss: 5.460674946842515

Epoch: 5| Step: 1
Training loss: 5.140928868179908
Validation loss: 5.441447570326821

Epoch: 5| Step: 2
Training loss: 5.635838387646069
Validation loss: 5.4218984921766715

Epoch: 5| Step: 3
Training loss: 4.265622093562998
Validation loss: 5.402349750109526

Epoch: 5| Step: 4
Training loss: 4.802477816957935
Validation loss: 5.383003008005106

Epoch: 5| Step: 5
Training loss: 6.042034094150169
Validation loss: 5.361717592064774

Epoch: 5| Step: 6
Training loss: 5.459596133543785
Validation loss: 5.341865426479454

Epoch: 5| Step: 7
Training loss: 5.105383197327379
Validation loss: 5.320882745750204

Epoch: 5| Step: 8
Training loss: 5.585124435472928
Validation loss: 5.300731524403061

Epoch: 5| Step: 9
Training loss: 4.938680000784267
Validation loss: 5.278823208565313

Epoch: 5| Step: 10
Training loss: 6.049442032234642
Validation loss: 5.257447776229812

Epoch: 6| Step: 0
Training loss: 4.553311855066299
Validation loss: 5.2365226109896135

Epoch: 5| Step: 1
Training loss: 5.380465899860397
Validation loss: 5.215443414014856

Epoch: 5| Step: 2
Training loss: 5.495139488553246
Validation loss: 5.194081355605783

Epoch: 5| Step: 3
Training loss: 5.007547023360051
Validation loss: 5.17254341697858

Epoch: 5| Step: 4
Training loss: 6.233359806324167
Validation loss: 5.149932612866217

Epoch: 5| Step: 5
Training loss: 5.680312425322007
Validation loss: 5.12863767208552

Epoch: 5| Step: 6
Training loss: 6.203093944250818
Validation loss: 5.106989367535588

Epoch: 5| Step: 7
Training loss: 4.839788379614158
Validation loss: 5.081903091354174

Epoch: 5| Step: 8
Training loss: 3.8553536039432217
Validation loss: 5.060883969388363

Epoch: 5| Step: 9
Training loss: 4.720668377509685
Validation loss: 5.03753331924852

Epoch: 5| Step: 10
Training loss: 4.455453150315712
Validation loss: 5.014482054811997

Epoch: 7| Step: 0
Training loss: 4.567604867016345
Validation loss: 4.991682092600095

Epoch: 5| Step: 1
Training loss: 5.546360045693908
Validation loss: 4.968780026300304

Epoch: 5| Step: 2
Training loss: 5.033883679009561
Validation loss: 4.94611392415318

Epoch: 5| Step: 3
Training loss: 4.835933753090734
Validation loss: 4.922048880973795

Epoch: 5| Step: 4
Training loss: 4.876705947130234
Validation loss: 4.899236227032184

Epoch: 5| Step: 5
Training loss: 5.3054951880162395
Validation loss: 4.874444002724277

Epoch: 5| Step: 6
Training loss: 4.827573874415538
Validation loss: 4.850701455144416

Epoch: 5| Step: 7
Training loss: 3.535720021517066
Validation loss: 4.82930446540945

Epoch: 5| Step: 8
Training loss: 4.207766101239961
Validation loss: 4.806598856806078

Epoch: 5| Step: 9
Training loss: 5.816838439911766
Validation loss: 4.784871925142443

Epoch: 5| Step: 10
Training loss: 5.494627322470724
Validation loss: 4.761994317907552

Epoch: 8| Step: 0
Training loss: 4.509434029872861
Validation loss: 4.739241635205848

Epoch: 5| Step: 1
Training loss: 4.54049812239394
Validation loss: 4.717665757106841

Epoch: 5| Step: 2
Training loss: 4.009952323420865
Validation loss: 4.6975811323102

Epoch: 5| Step: 3
Training loss: 6.017503955239112
Validation loss: 4.677039437570258

Epoch: 5| Step: 4
Training loss: 4.615085594565502
Validation loss: 4.655714633157066

Epoch: 5| Step: 5
Training loss: 4.2745402306388005
Validation loss: 4.634048025736761

Epoch: 5| Step: 6
Training loss: 3.751407994747332
Validation loss: 4.61520150640189

Epoch: 5| Step: 7
Training loss: 4.530177759047039
Validation loss: 4.594863786714742

Epoch: 5| Step: 8
Training loss: 5.290906756447322
Validation loss: 4.57671609386085

Epoch: 5| Step: 9
Training loss: 5.6738802305051514
Validation loss: 4.558277482766716

Epoch: 5| Step: 10
Training loss: 4.1198513381951205
Validation loss: 4.540967281003502

Epoch: 9| Step: 0
Training loss: 4.949673096622416
Validation loss: 4.5227339864110885

Epoch: 5| Step: 1
Training loss: 5.147329300898162
Validation loss: 4.5069728161752725

Epoch: 5| Step: 2
Training loss: 3.9144838757321123
Validation loss: 4.488615947584302

Epoch: 5| Step: 3
Training loss: 5.060771505772868
Validation loss: 4.47080022649034

Epoch: 5| Step: 4
Training loss: 4.040292932446913
Validation loss: 4.453027906872366

Epoch: 5| Step: 5
Training loss: 4.694383983235252
Validation loss: 4.437444233316456

Epoch: 5| Step: 6
Training loss: 4.092276271514114
Validation loss: 4.419714640794246

Epoch: 5| Step: 7
Training loss: 4.831967500653141
Validation loss: 4.40562820556397

Epoch: 5| Step: 8
Training loss: 4.177814955467035
Validation loss: 4.387905756766701

Epoch: 5| Step: 9
Training loss: 4.286355865230226
Validation loss: 4.371905628041265

Epoch: 5| Step: 10
Training loss: 4.571854499150358
Validation loss: 4.358731805206364

Epoch: 10| Step: 0
Training loss: 3.792006397048769
Validation loss: 4.345160657100633

Epoch: 5| Step: 1
Training loss: 4.714606682886326
Validation loss: 4.332899313663607

Epoch: 5| Step: 2
Training loss: 4.39056765698764
Validation loss: 4.322209901802062

Epoch: 5| Step: 3
Training loss: 4.905655162736532
Validation loss: 4.310599282883746

Epoch: 5| Step: 4
Training loss: 4.5269188537538065
Validation loss: 4.29932190732257

Epoch: 5| Step: 5
Training loss: 4.056401766860557
Validation loss: 4.290867735995432

Epoch: 5| Step: 6
Training loss: 4.24578334091349
Validation loss: 4.280527227362116

Epoch: 5| Step: 7
Training loss: 5.1636030076398995
Validation loss: 4.272014753247606

Epoch: 5| Step: 8
Training loss: 4.847605493665589
Validation loss: 4.264153757905441

Epoch: 5| Step: 9
Training loss: 3.8376320632924736
Validation loss: 4.255013261527617

Epoch: 5| Step: 10
Training loss: 3.6611569073877037
Validation loss: 4.248511520017474

Epoch: 11| Step: 0
Training loss: 4.56487410974469
Validation loss: 4.240280018336515

Epoch: 5| Step: 1
Training loss: 4.114780134814171
Validation loss: 4.232861676214348

Epoch: 5| Step: 2
Training loss: 3.829129955183564
Validation loss: 4.225097891371362

Epoch: 5| Step: 3
Training loss: 3.473614006002295
Validation loss: 4.219914492641039

Epoch: 5| Step: 4
Training loss: 5.361999047273226
Validation loss: 4.215065014956837

Epoch: 5| Step: 5
Training loss: 4.056448081988739
Validation loss: 4.206997171427473

Epoch: 5| Step: 6
Training loss: 4.954343627814961
Validation loss: 4.200414498849185

Epoch: 5| Step: 7
Training loss: 4.058523726387032
Validation loss: 4.1963810028552855

Epoch: 5| Step: 8
Training loss: 3.70484453026969
Validation loss: 4.190949989070902

Epoch: 5| Step: 9
Training loss: 4.277544631769753
Validation loss: 4.182753695234818

Epoch: 5| Step: 10
Training loss: 5.015220744636435
Validation loss: 4.177559304903144

Epoch: 12| Step: 0
Training loss: 2.897930748743268
Validation loss: 4.171956376956637

Epoch: 5| Step: 1
Training loss: 4.094156725531265
Validation loss: 4.164926924153629

Epoch: 5| Step: 2
Training loss: 4.048727311214744
Validation loss: 4.160685753361876

Epoch: 5| Step: 3
Training loss: 4.023145468770751
Validation loss: 4.154272795462471

Epoch: 5| Step: 4
Training loss: 4.614286230897938
Validation loss: 4.148311853403424

Epoch: 5| Step: 5
Training loss: 3.8718869410000494
Validation loss: 4.141493403670463

Epoch: 5| Step: 6
Training loss: 4.300579457828411
Validation loss: 4.134748041173101

Epoch: 5| Step: 7
Training loss: 4.397881752259871
Validation loss: 4.1275618929639295

Epoch: 5| Step: 8
Training loss: 5.219111629908325
Validation loss: 4.119788230051485

Epoch: 5| Step: 9
Training loss: 4.436313954201634
Validation loss: 4.1105664439431715

Epoch: 5| Step: 10
Training loss: 4.767273264525762
Validation loss: 4.099247333462111

Epoch: 13| Step: 0
Training loss: 4.620781701742277
Validation loss: 4.087168272476796

Epoch: 5| Step: 1
Training loss: 4.524964280804182
Validation loss: 4.079875015634223

Epoch: 5| Step: 2
Training loss: 3.798780677322582
Validation loss: 4.065773112822506

Epoch: 5| Step: 3
Training loss: 4.421793690934758
Validation loss: 4.06078832519385

Epoch: 5| Step: 4
Training loss: 4.770077885725628
Validation loss: 4.04933305528264

Epoch: 5| Step: 5
Training loss: 4.405197991934589
Validation loss: 4.042384769002479

Epoch: 5| Step: 6
Training loss: 4.001339449730274
Validation loss: 4.032263664364772

Epoch: 5| Step: 7
Training loss: 3.513458805292764
Validation loss: 4.029645028751525

Epoch: 5| Step: 8
Training loss: 4.128555845984536
Validation loss: 4.021834885315369

Epoch: 5| Step: 9
Training loss: 4.049655033066498
Validation loss: 4.01583801090171

Epoch: 5| Step: 10
Training loss: 3.6092834461044663
Validation loss: 4.007760543852676

Epoch: 14| Step: 0
Training loss: 3.247392341879054
Validation loss: 4.001635563160765

Epoch: 5| Step: 1
Training loss: 3.4651987954012666
Validation loss: 3.9943993952819876

Epoch: 5| Step: 2
Training loss: 3.786170721171775
Validation loss: 3.988911464222543

Epoch: 5| Step: 3
Training loss: 3.4606098510785404
Validation loss: 3.9815950311876875

Epoch: 5| Step: 4
Training loss: 4.394430337383027
Validation loss: 3.975712998502095

Epoch: 5| Step: 5
Training loss: 4.856526512021003
Validation loss: 3.9708908930303504

Epoch: 5| Step: 6
Training loss: 4.492660683298794
Validation loss: 3.96328509217189

Epoch: 5| Step: 7
Training loss: 4.879465258958087
Validation loss: 3.9550161342505143

Epoch: 5| Step: 8
Training loss: 3.8548707198694405
Validation loss: 3.949315007583917

Epoch: 5| Step: 9
Training loss: 4.120712132434582
Validation loss: 3.9429186823134543

Epoch: 5| Step: 10
Training loss: 4.403932651929906
Validation loss: 3.9386400485560404

Epoch: 15| Step: 0
Training loss: 3.059466981527921
Validation loss: 3.931736407906814

Epoch: 5| Step: 1
Training loss: 4.300995006325117
Validation loss: 3.9250799174729405

Epoch: 5| Step: 2
Training loss: 4.015451152912433
Validation loss: 3.92156091247906

Epoch: 5| Step: 3
Training loss: 4.584899264927339
Validation loss: 3.913809219420473

Epoch: 5| Step: 4
Training loss: 3.593792857038953
Validation loss: 3.909154927031024

Epoch: 5| Step: 5
Training loss: 4.0940947642276875
Validation loss: 3.903577473289727

Epoch: 5| Step: 6
Training loss: 4.084403747597521
Validation loss: 3.897758420631338

Epoch: 5| Step: 7
Training loss: 4.290011163799281
Validation loss: 3.892752620340131

Epoch: 5| Step: 8
Training loss: 4.738804925848303
Validation loss: 3.8874064858114386

Epoch: 5| Step: 9
Training loss: 3.7527764532534125
Validation loss: 3.8832857435270496

Epoch: 5| Step: 10
Training loss: 3.8971955608804256
Validation loss: 3.8783786055721206

Epoch: 16| Step: 0
Training loss: 3.41120675981793
Validation loss: 3.8734088797386534

Epoch: 5| Step: 1
Training loss: 3.7758536175786577
Validation loss: 3.8700816617854907

Epoch: 5| Step: 2
Training loss: 4.292953866059844
Validation loss: 3.8642099010623707

Epoch: 5| Step: 3
Training loss: 4.037554165975792
Validation loss: 3.858755619226713

Epoch: 5| Step: 4
Training loss: 3.5454215546164556
Validation loss: 3.8540157342883514

Epoch: 5| Step: 5
Training loss: 4.517728427839049
Validation loss: 3.84906231291548

Epoch: 5| Step: 6
Training loss: 3.8351680815268074
Validation loss: 3.8447429509282083

Epoch: 5| Step: 7
Training loss: 4.352635797423185
Validation loss: 3.8391744393997826

Epoch: 5| Step: 8
Training loss: 4.543860835805385
Validation loss: 3.8372538360005093

Epoch: 5| Step: 9
Training loss: 3.657053671647712
Validation loss: 3.8344494709286985

Epoch: 5| Step: 10
Training loss: 4.017654796530796
Validation loss: 3.829121052029792

Epoch: 17| Step: 0
Training loss: 3.9336816347943637
Validation loss: 3.8232928545832303

Epoch: 5| Step: 1
Training loss: 3.5718232345501186
Validation loss: 3.821479855726187

Epoch: 5| Step: 2
Training loss: 3.7945457817931927
Validation loss: 3.816278624261817

Epoch: 5| Step: 3
Training loss: 3.78013569199765
Validation loss: 3.81232999775299

Epoch: 5| Step: 4
Training loss: 4.296411107771511
Validation loss: 3.8053108427871476

Epoch: 5| Step: 5
Training loss: 4.260942173316332
Validation loss: 3.803263118808611

Epoch: 5| Step: 6
Training loss: 4.008081616741351
Validation loss: 3.7963775412865983

Epoch: 5| Step: 7
Training loss: 4.024359677009067
Validation loss: 3.793402037484331

Epoch: 5| Step: 8
Training loss: 2.8265945761712574
Validation loss: 3.7867316284663426

Epoch: 5| Step: 9
Training loss: 4.2401543060150955
Validation loss: 3.78321229478071

Epoch: 5| Step: 10
Training loss: 4.79844058455005
Validation loss: 3.781068798046668

Epoch: 18| Step: 0
Training loss: 4.092348281014826
Validation loss: 3.781179146919391

Epoch: 5| Step: 1
Training loss: 3.8591288746797145
Validation loss: 3.777862542046146

Epoch: 5| Step: 2
Training loss: 3.0369242620937795
Validation loss: 3.771685636136081

Epoch: 5| Step: 3
Training loss: 4.587713518292935
Validation loss: 3.7652360656306967

Epoch: 5| Step: 4
Training loss: 3.844041146517634
Validation loss: 3.760142644318107

Epoch: 5| Step: 5
Training loss: 3.1678743736423916
Validation loss: 3.7565603905248084

Epoch: 5| Step: 6
Training loss: 4.066205960635373
Validation loss: 3.7586679781706693

Epoch: 5| Step: 7
Training loss: 4.1274159610171095
Validation loss: 3.7524169680253783

Epoch: 5| Step: 8
Training loss: 4.301967640845959
Validation loss: 3.746646118261715

Epoch: 5| Step: 9
Training loss: 3.145040719598029
Validation loss: 3.7430879202101948

Epoch: 5| Step: 10
Training loss: 4.796315113905153
Validation loss: 3.740448479768237

Epoch: 19| Step: 0
Training loss: 3.7663215214635555
Validation loss: 3.7389878581480214

Epoch: 5| Step: 1
Training loss: 4.150157162551432
Validation loss: 3.7336745554114246

Epoch: 5| Step: 2
Training loss: 3.4151078987110886
Validation loss: 3.7288922192673413

Epoch: 5| Step: 3
Training loss: 3.1942701061792613
Validation loss: 3.7254362441785505

Epoch: 5| Step: 4
Training loss: 4.486416554690086
Validation loss: 3.721402455023797

Epoch: 5| Step: 5
Training loss: 3.8277419540901723
Validation loss: 3.7229083181970113

Epoch: 5| Step: 6
Training loss: 3.881640988618907
Validation loss: 3.7160938732238367

Epoch: 5| Step: 7
Training loss: 4.034381448635677
Validation loss: 3.7117827368550627

Epoch: 5| Step: 8
Training loss: 4.217506734122444
Validation loss: 3.708832801973331

Epoch: 5| Step: 9
Training loss: 3.613650741243196
Validation loss: 3.7053797454960735

Epoch: 5| Step: 10
Training loss: 4.21354569040805
Validation loss: 3.702247436379406

Epoch: 20| Step: 0
Training loss: 3.765667800343512
Validation loss: 3.6993485507766932

Epoch: 5| Step: 1
Training loss: 3.5156343587115018
Validation loss: 3.6940650293810466

Epoch: 5| Step: 2
Training loss: 3.6048279231002933
Validation loss: 3.6911382495089025

Epoch: 5| Step: 3
Training loss: 4.3689225627998045
Validation loss: 3.688231520608332

Epoch: 5| Step: 4
Training loss: 3.40632755296247
Validation loss: 3.688132701590288

Epoch: 5| Step: 5
Training loss: 3.615838806635845
Validation loss: 3.684377227829567

Epoch: 5| Step: 6
Training loss: 3.4565343812247646
Validation loss: 3.679713727898813

Epoch: 5| Step: 7
Training loss: 4.10358441607023
Validation loss: 3.673417252763651

Epoch: 5| Step: 8
Training loss: 3.2027053185903713
Validation loss: 3.670963185486297

Epoch: 5| Step: 9
Training loss: 5.146520694843378
Validation loss: 3.669335548091441

Epoch: 5| Step: 10
Training loss: 4.0054832069845885
Validation loss: 3.6655969616213357

Epoch: 21| Step: 0
Training loss: 3.8647194124651483
Validation loss: 3.6591533236280727

Epoch: 5| Step: 1
Training loss: 3.7411860836341635
Validation loss: 3.6541109351333687

Epoch: 5| Step: 2
Training loss: 3.8374912821021447
Validation loss: 3.6536861279432133

Epoch: 5| Step: 3
Training loss: 3.958773110035881
Validation loss: 3.6526481613427295

Epoch: 5| Step: 4
Training loss: 3.463924040756644
Validation loss: 3.6501268204949917

Epoch: 5| Step: 5
Training loss: 3.475720524359251
Validation loss: 3.642102796409405

Epoch: 5| Step: 6
Training loss: 3.937011325121291
Validation loss: 3.6399044693648057

Epoch: 5| Step: 7
Training loss: 3.9735689718237346
Validation loss: 3.6354297656860983

Epoch: 5| Step: 8
Training loss: 3.2122014660294607
Validation loss: 3.631788622050147

Epoch: 5| Step: 9
Training loss: 4.632292488337687
Validation loss: 3.6293126182320607

Epoch: 5| Step: 10
Training loss: 3.9364952137492932
Validation loss: 3.629032691034909

Epoch: 22| Step: 0
Training loss: 4.475214623786783
Validation loss: 3.6236040711189896

Epoch: 5| Step: 1
Training loss: 3.98931160076957
Validation loss: 3.6211574218000315

Epoch: 5| Step: 2
Training loss: 3.751749266488067
Validation loss: 3.6163197906544755

Epoch: 5| Step: 3
Training loss: 3.532233447299414
Validation loss: 3.614134992839256

Epoch: 5| Step: 4
Training loss: 3.358718311087922
Validation loss: 3.6094680331643056

Epoch: 5| Step: 5
Training loss: 3.596710975546099
Validation loss: 3.6070957510010393

Epoch: 5| Step: 6
Training loss: 4.406803177543271
Validation loss: 3.6070313050392597

Epoch: 5| Step: 7
Training loss: 3.7098438458341656
Validation loss: 3.6062493202201864

Epoch: 5| Step: 8
Training loss: 4.261753211507092
Validation loss: 3.6045045373616227

Epoch: 5| Step: 9
Training loss: 2.9628502296706585
Validation loss: 3.5989644631524045

Epoch: 5| Step: 10
Training loss: 3.5163279190949943
Validation loss: 3.594107618546279

Epoch: 23| Step: 0
Training loss: 3.8074992167220936
Validation loss: 3.5931144277173273

Epoch: 5| Step: 1
Training loss: 3.3144093894433255
Validation loss: 3.5924014321477293

Epoch: 5| Step: 2
Training loss: 3.4670995961581745
Validation loss: 3.587811861949897

Epoch: 5| Step: 3
Training loss: 3.5537921155110572
Validation loss: 3.587461809547669

Epoch: 5| Step: 4
Training loss: 4.3625868037203706
Validation loss: 3.5833025375572967

Epoch: 5| Step: 5
Training loss: 4.180544870446717
Validation loss: 3.5818971220154676

Epoch: 5| Step: 6
Training loss: 2.875979381100062
Validation loss: 3.5809817246968945

Epoch: 5| Step: 7
Training loss: 4.55234327236086
Validation loss: 3.5815784328584477

Epoch: 5| Step: 8
Training loss: 3.6157278984284247
Validation loss: 3.577153325196861

Epoch: 5| Step: 9
Training loss: 4.08048504470648
Validation loss: 3.5742303208037707

Epoch: 5| Step: 10
Training loss: 3.436085357884743
Validation loss: 3.574110710510076

Epoch: 24| Step: 0
Training loss: 3.908727363835621
Validation loss: 3.569701528906593

Epoch: 5| Step: 1
Training loss: 4.058314823262473
Validation loss: 3.5702035797157023

Epoch: 5| Step: 2
Training loss: 3.6880055743690447
Validation loss: 3.5684995823683714

Epoch: 5| Step: 3
Training loss: 4.65364032297461
Validation loss: 3.564198786772188

Epoch: 5| Step: 4
Training loss: 3.9233223117704887
Validation loss: 3.5618745894967563

Epoch: 5| Step: 5
Training loss: 3.701913112203961
Validation loss: 3.56011548033704

Epoch: 5| Step: 6
Training loss: 4.30270334475874
Validation loss: 3.5590053214221684

Epoch: 5| Step: 7
Training loss: 3.4524259248006106
Validation loss: 3.5564599004403417

Epoch: 5| Step: 8
Training loss: 2.586662905270834
Validation loss: 3.5528314962297367

Epoch: 5| Step: 9
Training loss: 2.730154125767547
Validation loss: 3.5505416902839055

Epoch: 5| Step: 10
Training loss: 3.934734887349849
Validation loss: 3.549911369547258

Epoch: 25| Step: 0
Training loss: 3.4703365512308157
Validation loss: 3.5463610239620635

Epoch: 5| Step: 1
Training loss: 2.883123779031994
Validation loss: 3.547574625008589

Epoch: 5| Step: 2
Training loss: 3.707361301083624
Validation loss: 3.5447358838375203

Epoch: 5| Step: 3
Training loss: 3.6511723399302287
Validation loss: 3.5419406912740885

Epoch: 5| Step: 4
Training loss: 3.3521272765875674
Validation loss: 3.5407861796197957

Epoch: 5| Step: 5
Training loss: 3.309952097889005
Validation loss: 3.5367472441790295

Epoch: 5| Step: 6
Training loss: 3.271922632725073
Validation loss: 3.5356719186687218

Epoch: 5| Step: 7
Training loss: 4.669974766730482
Validation loss: 3.5358944673414507

Epoch: 5| Step: 8
Training loss: 3.801835700902299
Validation loss: 3.5331792176054653

Epoch: 5| Step: 9
Training loss: 4.433629671867142
Validation loss: 3.5320666667706035

Epoch: 5| Step: 10
Training loss: 4.330518590869821
Validation loss: 3.5320216047444517

Epoch: 26| Step: 0
Training loss: 3.9397522070947693
Validation loss: 3.5263403672101776

Epoch: 5| Step: 1
Training loss: 3.4932133407465575
Validation loss: 3.523994630400885

Epoch: 5| Step: 2
Training loss: 2.459713586090491
Validation loss: 3.5225017419960376

Epoch: 5| Step: 3
Training loss: 4.142995249508641
Validation loss: 3.5206543746546535

Epoch: 5| Step: 4
Training loss: 3.9522286706938026
Validation loss: 3.516906153363417

Epoch: 5| Step: 5
Training loss: 3.911492941441263
Validation loss: 3.5177681522957482

Epoch: 5| Step: 6
Training loss: 3.6596882621706364
Validation loss: 3.512682652993086

Epoch: 5| Step: 7
Training loss: 3.688005057192829
Validation loss: 3.508984693071105

Epoch: 5| Step: 8
Training loss: 4.330451202494666
Validation loss: 3.5122230730957384

Epoch: 5| Step: 9
Training loss: 3.5135732131176645
Validation loss: 3.507263460733004

Epoch: 5| Step: 10
Training loss: 3.5557229347038426
Validation loss: 3.504812246044654

Epoch: 27| Step: 0
Training loss: 3.2207210394532853
Validation loss: 3.5037552717838834

Epoch: 5| Step: 1
Training loss: 3.404672519883721
Validation loss: 3.5014619425555913

Epoch: 5| Step: 2
Training loss: 3.0400368665668265
Validation loss: 3.4975804932925634

Epoch: 5| Step: 3
Training loss: 3.6026683772789174
Validation loss: 3.4967106056633668

Epoch: 5| Step: 4
Training loss: 3.6713542163098634
Validation loss: 3.494610602651849

Epoch: 5| Step: 5
Training loss: 4.018650206755115
Validation loss: 3.491037535522845

Epoch: 5| Step: 6
Training loss: 4.088419698203954
Validation loss: 3.4895337226927503

Epoch: 5| Step: 7
Training loss: 4.255545644413822
Validation loss: 3.4862075975559135

Epoch: 5| Step: 8
Training loss: 3.3553019116882914
Validation loss: 3.4864203605653983

Epoch: 5| Step: 9
Training loss: 4.0972084404377735
Validation loss: 3.4834343948301623

Epoch: 5| Step: 10
Training loss: 3.807652377650607
Validation loss: 3.4794573550374444

Epoch: 28| Step: 0
Training loss: 4.6983309927496215
Validation loss: 3.4775118582515168

Epoch: 5| Step: 1
Training loss: 3.465662226292119
Validation loss: 3.475497928716141

Epoch: 5| Step: 2
Training loss: 2.7369284777873157
Validation loss: 3.475421714203142

Epoch: 5| Step: 3
Training loss: 4.785990241417379
Validation loss: 3.47216896661642

Epoch: 5| Step: 4
Training loss: 3.9584355926689767
Validation loss: 3.4774001403456736

Epoch: 5| Step: 5
Training loss: 3.8857895550329817
Validation loss: 3.4646708486284497

Epoch: 5| Step: 6
Training loss: 2.5983940740226483
Validation loss: 3.464556573722734

Epoch: 5| Step: 7
Training loss: 3.448904781373212
Validation loss: 3.4620841692078637

Epoch: 5| Step: 8
Training loss: 3.476189685505418
Validation loss: 3.4633946279839383

Epoch: 5| Step: 9
Training loss: 3.5706867046957256
Validation loss: 3.4610211206649595

Epoch: 5| Step: 10
Training loss: 3.216367413793881
Validation loss: 3.455849881237617

Epoch: 29| Step: 0
Training loss: 3.950040435584049
Validation loss: 3.45408520136325

Epoch: 5| Step: 1
Training loss: 3.5388318254017896
Validation loss: 3.4580152157475834

Epoch: 5| Step: 2
Training loss: 4.0617125701710535
Validation loss: 3.454556641801223

Epoch: 5| Step: 3
Training loss: 3.429864483483427
Validation loss: 3.4528818590101746

Epoch: 5| Step: 4
Training loss: 3.5241076050003204
Validation loss: 3.450447624050598

Epoch: 5| Step: 5
Training loss: 3.64348571761143
Validation loss: 3.4505395497398594

Epoch: 5| Step: 6
Training loss: 3.860311170695275
Validation loss: 3.449038396539783

Epoch: 5| Step: 7
Training loss: 3.563260181367225
Validation loss: 3.447061081903683

Epoch: 5| Step: 8
Training loss: 3.4541182664548744
Validation loss: 3.4442854314873617

Epoch: 5| Step: 9
Training loss: 3.881836551690203
Validation loss: 3.4433534665056134

Epoch: 5| Step: 10
Training loss: 3.3422174952633665
Validation loss: 3.442244300635988

Epoch: 30| Step: 0
Training loss: 3.7311251876633174
Validation loss: 3.4386952608940633

Epoch: 5| Step: 1
Training loss: 3.769395894995378
Validation loss: 3.4407013783082174

Epoch: 5| Step: 2
Training loss: 3.7183546609464946
Validation loss: 3.441419360916282

Epoch: 5| Step: 3
Training loss: 3.5057388667484997
Validation loss: 3.4315344616830084

Epoch: 5| Step: 4
Training loss: 4.299352313210718
Validation loss: 3.4292535364587082

Epoch: 5| Step: 5
Training loss: 2.8977594533619144
Validation loss: 3.430745745875776

Epoch: 5| Step: 6
Training loss: 4.2202152674581095
Validation loss: 3.426651984201243

Epoch: 5| Step: 7
Training loss: 3.6896618470522826
Validation loss: 3.4250845906831286

Epoch: 5| Step: 8
Training loss: 3.3929207759999223
Validation loss: 3.42600364420145

Epoch: 5| Step: 9
Training loss: 3.1456204441279345
Validation loss: 3.4227927986769418

Epoch: 5| Step: 10
Training loss: 3.5620562628404837
Validation loss: 3.4186185628218504

Epoch: 31| Step: 0
Training loss: 2.8904554162670864
Validation loss: 3.4160025936951732

Epoch: 5| Step: 1
Training loss: 3.9256644008574115
Validation loss: 3.4145991972936836

Epoch: 5| Step: 2
Training loss: 3.154483716409049
Validation loss: 3.414725455754429

Epoch: 5| Step: 3
Training loss: 3.0839308769702773
Validation loss: 3.4113413194723146

Epoch: 5| Step: 4
Training loss: 3.4052573341227355
Validation loss: 3.408981305955517

Epoch: 5| Step: 5
Training loss: 3.779579361010852
Validation loss: 3.4075278077153914

Epoch: 5| Step: 6
Training loss: 4.815142413892288
Validation loss: 3.4066392040797315

Epoch: 5| Step: 7
Training loss: 3.554284242665622
Validation loss: 3.405034130007843

Epoch: 5| Step: 8
Training loss: 3.0478179255092757
Validation loss: 3.4023564267348836

Epoch: 5| Step: 9
Training loss: 3.993554883318758
Validation loss: 3.4008922589627844

Epoch: 5| Step: 10
Training loss: 3.931689501333988
Validation loss: 3.4025188390774113

Epoch: 32| Step: 0
Training loss: 2.804779476262158
Validation loss: 3.394272396752044

Epoch: 5| Step: 1
Training loss: 3.823190428089932
Validation loss: 3.3939254512639976

Epoch: 5| Step: 2
Training loss: 3.288934628137078
Validation loss: 3.3895787302909146

Epoch: 5| Step: 3
Training loss: 3.5370360376853336
Validation loss: 3.3876506699714084

Epoch: 5| Step: 4
Training loss: 3.6529727169827737
Validation loss: 3.386132013487011

Epoch: 5| Step: 5
Training loss: 3.0695333875501594
Validation loss: 3.3817271811732894

Epoch: 5| Step: 6
Training loss: 4.341212128161813
Validation loss: 3.3834442713530946

Epoch: 5| Step: 7
Training loss: 3.6129049899112333
Validation loss: 3.3784632139898014

Epoch: 5| Step: 8
Training loss: 4.026520075961269
Validation loss: 3.381464037706525

Epoch: 5| Step: 9
Training loss: 3.549269619878818
Validation loss: 3.379867783550387

Epoch: 5| Step: 10
Training loss: 3.8046372427940316
Validation loss: 3.3764700048681244

Epoch: 33| Step: 0
Training loss: 3.4876143788822374
Validation loss: 3.3793342315017703

Epoch: 5| Step: 1
Training loss: 4.114193256414074
Validation loss: 3.375898421651121

Epoch: 5| Step: 2
Training loss: 3.689120696213458
Validation loss: 3.373736345118162

Epoch: 5| Step: 3
Training loss: 3.1846125370935745
Validation loss: 3.372146971400198

Epoch: 5| Step: 4
Training loss: 3.5635250022399667
Validation loss: 3.3738144258625518

Epoch: 5| Step: 5
Training loss: 3.368390994502524
Validation loss: 3.3741325606643637

Epoch: 5| Step: 6
Training loss: 3.201739351108476
Validation loss: 3.3702774885718645

Epoch: 5| Step: 7
Training loss: 4.306491370004342
Validation loss: 3.3697701712598875

Epoch: 5| Step: 8
Training loss: 3.4832796162626396
Validation loss: 3.3718683228457085

Epoch: 5| Step: 9
Training loss: 3.383299900384591
Validation loss: 3.367375919055418

Epoch: 5| Step: 10
Training loss: 3.70672188081944
Validation loss: 3.367337571298236

Epoch: 34| Step: 0
Training loss: 3.0475491291495334
Validation loss: 3.363908416118356

Epoch: 5| Step: 1
Training loss: 3.8731470907830006
Validation loss: 3.3641655501052083

Epoch: 5| Step: 2
Training loss: 3.8478374302996023
Validation loss: 3.364219304227288

Epoch: 5| Step: 3
Training loss: 3.145262980177896
Validation loss: 3.363308443703638

Epoch: 5| Step: 4
Training loss: 2.615712310901583
Validation loss: 3.361104149979155

Epoch: 5| Step: 5
Training loss: 3.2214449368853533
Validation loss: 3.3593002520880844

Epoch: 5| Step: 6
Training loss: 3.7376171387142305
Validation loss: 3.3557784184378536

Epoch: 5| Step: 7
Training loss: 4.583034968056934
Validation loss: 3.3567386753803126

Epoch: 5| Step: 8
Training loss: 4.129752455859756
Validation loss: 3.3544111616851895

Epoch: 5| Step: 9
Training loss: 3.169434157932568
Validation loss: 3.3558719228579434

Epoch: 5| Step: 10
Training loss: 3.7070850171449834
Validation loss: 3.3551182014698067

Epoch: 35| Step: 0
Training loss: 4.304281392127181
Validation loss: 3.356015102611264

Epoch: 5| Step: 1
Training loss: 3.674054347226577
Validation loss: 3.351970349190599

Epoch: 5| Step: 2
Training loss: 3.5287145103537427
Validation loss: 3.3522176693316754

Epoch: 5| Step: 3
Training loss: 4.251696977097333
Validation loss: 3.353442198996074

Epoch: 5| Step: 4
Training loss: 3.980517386157109
Validation loss: 3.350786498618115

Epoch: 5| Step: 5
Training loss: 3.6700831160111584
Validation loss: 3.348013434523409

Epoch: 5| Step: 6
Training loss: 3.2820087827091924
Validation loss: 3.3526426651849826

Epoch: 5| Step: 7
Training loss: 3.105701672917821
Validation loss: 3.345596295967146

Epoch: 5| Step: 8
Training loss: 3.254179687734449
Validation loss: 3.3480112905068995

Epoch: 5| Step: 9
Training loss: 2.8361021051897994
Validation loss: 3.345356906733443

Epoch: 5| Step: 10
Training loss: 3.1319309430748854
Validation loss: 3.3434960467528567

Epoch: 36| Step: 0
Training loss: 3.3783640167343467
Validation loss: 3.3420781811352187

Epoch: 5| Step: 1
Training loss: 3.998137636556807
Validation loss: 3.343107998919182

Epoch: 5| Step: 2
Training loss: 3.0027924892438826
Validation loss: 3.3443453955117843

Epoch: 5| Step: 3
Training loss: 3.8443100684048073
Validation loss: 3.3421894948325437

Epoch: 5| Step: 4
Training loss: 3.9580134747754343
Validation loss: 3.3396565104000313

Epoch: 5| Step: 5
Training loss: 3.524126683264906
Validation loss: 3.339945480619412

Epoch: 5| Step: 6
Training loss: 3.4502337335109536
Validation loss: 3.3394489106031604

Epoch: 5| Step: 7
Training loss: 3.5656689386226534
Validation loss: 3.339540982251177

Epoch: 5| Step: 8
Training loss: 3.196373947419664
Validation loss: 3.3382517327335077

Epoch: 5| Step: 9
Training loss: 3.7296724598025586
Validation loss: 3.3358348863218366

Epoch: 5| Step: 10
Training loss: 3.5463440619530293
Validation loss: 3.3338031981131278

Epoch: 37| Step: 0
Training loss: 2.690586889974007
Validation loss: 3.335088388316809

Epoch: 5| Step: 1
Training loss: 3.79016109939443
Validation loss: 3.3337153743930332

Epoch: 5| Step: 2
Training loss: 3.9706577311565354
Validation loss: 3.33373698948889

Epoch: 5| Step: 3
Training loss: 4.1852178475434805
Validation loss: 3.333998760336026

Epoch: 5| Step: 4
Training loss: 3.7811198566833966
Validation loss: 3.3306054941218877

Epoch: 5| Step: 5
Training loss: 3.254472149826915
Validation loss: 3.3331501031065685

Epoch: 5| Step: 6
Training loss: 3.3449478143062454
Validation loss: 3.3307816419045446

Epoch: 5| Step: 7
Training loss: 3.102200459322275
Validation loss: 3.330087841956683

Epoch: 5| Step: 8
Training loss: 3.231870999603953
Validation loss: 3.3285613362520765

Epoch: 5| Step: 9
Training loss: 3.992874713433024
Validation loss: 3.328535577757489

Epoch: 5| Step: 10
Training loss: 3.632562444140981
Validation loss: 3.327900047543363

Epoch: 38| Step: 0
Training loss: 4.083028483526663
Validation loss: 3.326649350774279

Epoch: 5| Step: 1
Training loss: 3.1189950850516217
Validation loss: 3.3314529488567417

Epoch: 5| Step: 2
Training loss: 3.673531925443275
Validation loss: 3.327417025959637

Epoch: 5| Step: 3
Training loss: 4.186114181543305
Validation loss: 3.326754783868812

Epoch: 5| Step: 4
Training loss: 3.138641338282923
Validation loss: 3.3232647239085296

Epoch: 5| Step: 5
Training loss: 3.9848632513344717
Validation loss: 3.3245505071758905

Epoch: 5| Step: 6
Training loss: 2.7166836658094153
Validation loss: 3.324108532761227

Epoch: 5| Step: 7
Training loss: 3.4330522372779875
Validation loss: 3.3252148473932954

Epoch: 5| Step: 8
Training loss: 3.2946134647914698
Validation loss: 3.3392455096720592

Epoch: 5| Step: 9
Training loss: 3.70707652764762
Validation loss: 3.325947434831506

Epoch: 5| Step: 10
Training loss: 3.577486739224023
Validation loss: 3.3253772713698204

Epoch: 39| Step: 0
Training loss: 3.4626482659831357
Validation loss: 3.3294033006840706

Epoch: 5| Step: 1
Training loss: 3.5073712247672324
Validation loss: 3.3260345911407345

Epoch: 5| Step: 2
Training loss: 3.3332256935542066
Validation loss: 3.326480583823407

Epoch: 5| Step: 3
Training loss: 3.3382600297527927
Validation loss: 3.326058525312316

Epoch: 5| Step: 4
Training loss: 3.9603858578664375
Validation loss: 3.323011456304893

Epoch: 5| Step: 5
Training loss: 3.5789251640534507
Validation loss: 3.323730951207021

Epoch: 5| Step: 6
Training loss: 3.9050861303230815
Validation loss: 3.330474136916761

Epoch: 5| Step: 7
Training loss: 4.001341118101305
Validation loss: 3.331679154204052

Epoch: 5| Step: 8
Training loss: 3.5074220707692896
Validation loss: 3.327829714041732

Epoch: 5| Step: 9
Training loss: 3.0347259098576638
Validation loss: 3.3239150348805846

Epoch: 5| Step: 10
Training loss: 3.4386462987962427
Validation loss: 3.3224309046150533

Epoch: 40| Step: 0
Training loss: 3.443822560177683
Validation loss: 3.319491619673568

Epoch: 5| Step: 1
Training loss: 3.768565948698839
Validation loss: 3.318303828823028

Epoch: 5| Step: 2
Training loss: 3.4170065609961338
Validation loss: 3.3183860298507772

Epoch: 5| Step: 3
Training loss: 3.0484463283424668
Validation loss: 3.3169568433344363

Epoch: 5| Step: 4
Training loss: 3.8575829426420363
Validation loss: 3.3163627752012266

Epoch: 5| Step: 5
Training loss: 3.8468388497631874
Validation loss: 3.3165534493962814

Epoch: 5| Step: 6
Training loss: 3.195239973294412
Validation loss: 3.3152349213763865

Epoch: 5| Step: 7
Training loss: 3.2314098975280565
Validation loss: 3.314702067279458

Epoch: 5| Step: 8
Training loss: 3.7438127974145505
Validation loss: 3.313993250908963

Epoch: 5| Step: 9
Training loss: 3.3180134791122837
Validation loss: 3.313313989972987

Epoch: 5| Step: 10
Training loss: 4.173112892772051
Validation loss: 3.3140744897926893

Epoch: 41| Step: 0
Training loss: 3.1651862515431866
Validation loss: 3.3121107557284843

Epoch: 5| Step: 1
Training loss: 3.8448298728420522
Validation loss: 3.310920368101806

Epoch: 5| Step: 2
Training loss: 3.293051577213079
Validation loss: 3.3092059944205228

Epoch: 5| Step: 3
Training loss: 3.1594883386221966
Validation loss: 3.30950424033541

Epoch: 5| Step: 4
Training loss: 4.1748509454674085
Validation loss: 3.3097402321881155

Epoch: 5| Step: 5
Training loss: 3.266860363206611
Validation loss: 3.3092905595508326

Epoch: 5| Step: 6
Training loss: 3.5320964237672716
Validation loss: 3.309794042995591

Epoch: 5| Step: 7
Training loss: 3.52471562313884
Validation loss: 3.3130546781834025

Epoch: 5| Step: 8
Training loss: 2.9576732991668453
Validation loss: 3.3117809169125665

Epoch: 5| Step: 9
Training loss: 4.043265482015328
Validation loss: 3.31256865300434

Epoch: 5| Step: 10
Training loss: 3.9096534245643206
Validation loss: 3.306388106913034

Epoch: 42| Step: 0
Training loss: 3.6559144216575814
Validation loss: 3.3058223481983755

Epoch: 5| Step: 1
Training loss: 4.037915064968481
Validation loss: 3.308110305642741

Epoch: 5| Step: 2
Training loss: 3.287373088519178
Validation loss: 3.311221816655043

Epoch: 5| Step: 3
Training loss: 2.918734081151383
Validation loss: 3.3094799571510887

Epoch: 5| Step: 4
Training loss: 3.0198679115764553
Validation loss: 3.3110507821763218

Epoch: 5| Step: 5
Training loss: 3.9310145175678377
Validation loss: 3.3204913926596378

Epoch: 5| Step: 6
Training loss: 3.7668341124008475
Validation loss: 3.3081872393011813

Epoch: 5| Step: 7
Training loss: 3.5839497827009064
Validation loss: 3.3075495804007633

Epoch: 5| Step: 8
Training loss: 3.912263681508119
Validation loss: 3.3091990980372947

Epoch: 5| Step: 9
Training loss: 2.9946443117903305
Validation loss: 3.3106932632121477

Epoch: 5| Step: 10
Training loss: 3.7274612846385144
Validation loss: 3.3096001536084434

Epoch: 43| Step: 0
Training loss: 3.3859980783293713
Validation loss: 3.3074735790889576

Epoch: 5| Step: 1
Training loss: 3.934814869695505
Validation loss: 3.304959206131633

Epoch: 5| Step: 2
Training loss: 3.39167495151667
Validation loss: 3.306894747934849

Epoch: 5| Step: 3
Training loss: 3.4727169413460572
Validation loss: 3.3028338939148845

Epoch: 5| Step: 4
Training loss: 2.934322017886053
Validation loss: 3.3093204651557167

Epoch: 5| Step: 5
Training loss: 4.609854152796875
Validation loss: 3.3174795381370443

Epoch: 5| Step: 6
Training loss: 3.7870829336847702
Validation loss: 3.3065958603878953

Epoch: 5| Step: 7
Training loss: 2.7334621976698505
Validation loss: 3.305501332201219

Epoch: 5| Step: 8
Training loss: 2.763942400628881
Validation loss: 3.3055005411218947

Epoch: 5| Step: 9
Training loss: 3.9691952433102355
Validation loss: 3.3058801909068856

Epoch: 5| Step: 10
Training loss: 3.6114873608586255
Validation loss: 3.3046109441250877

Epoch: 44| Step: 0
Training loss: 4.04601664627128
Validation loss: 3.3004639746539968

Epoch: 5| Step: 1
Training loss: 3.4486532817025055
Validation loss: 3.3001293082460132

Epoch: 5| Step: 2
Training loss: 3.9070087153794244
Validation loss: 3.2998108545802594

Epoch: 5| Step: 3
Training loss: 3.1901944309880745
Validation loss: 3.3008308420025525

Epoch: 5| Step: 4
Training loss: 3.3921652956129997
Validation loss: 3.300361971612646

Epoch: 5| Step: 5
Training loss: 3.1470850460560125
Validation loss: 3.299424772198408

Epoch: 5| Step: 6
Training loss: 3.8738433588329837
Validation loss: 3.30385716302845

Epoch: 5| Step: 7
Training loss: 3.915219438621988
Validation loss: 3.3023559456746128

Epoch: 5| Step: 8
Training loss: 3.1835104714951292
Validation loss: 3.2997891664198398

Epoch: 5| Step: 9
Training loss: 2.8618525210062358
Validation loss: 3.297216909626561

Epoch: 5| Step: 10
Training loss: 3.8123711736207038
Validation loss: 3.297975713430207

Epoch: 45| Step: 0
Training loss: 3.1488177730085853
Validation loss: 3.2967583676942

Epoch: 5| Step: 1
Training loss: 3.5311990919916587
Validation loss: 3.295744695519428

Epoch: 5| Step: 2
Training loss: 3.522472985450355
Validation loss: 3.29554874345843

Epoch: 5| Step: 3
Training loss: 3.215617461052038
Validation loss: 3.2945156429439084

Epoch: 5| Step: 4
Training loss: 3.818891951549541
Validation loss: 3.294376459373455

Epoch: 5| Step: 5
Training loss: 4.034286420043242
Validation loss: 3.2928933308309145

Epoch: 5| Step: 6
Training loss: 3.719597215073537
Validation loss: 3.292567800464935

Epoch: 5| Step: 7
Training loss: 3.1299848852310617
Validation loss: 3.2917100154026024

Epoch: 5| Step: 8
Training loss: 3.8993779884616746
Validation loss: 3.2909768104546484

Epoch: 5| Step: 9
Training loss: 3.6506051071453114
Validation loss: 3.2916517873925937

Epoch: 5| Step: 10
Training loss: 2.9851760188718286
Validation loss: 3.2895531453421176

Epoch: 46| Step: 0
Training loss: 3.8966999959920763
Validation loss: 3.290241082807005

Epoch: 5| Step: 1
Training loss: 3.906253906248047
Validation loss: 3.28870207461453

Epoch: 5| Step: 2
Training loss: 3.4413671761934728
Validation loss: 3.28924032538339

Epoch: 5| Step: 3
Training loss: 3.3616221873931527
Validation loss: 3.287917410961263

Epoch: 5| Step: 4
Training loss: 3.643255764925728
Validation loss: 3.2872724417750723

Epoch: 5| Step: 5
Training loss: 3.9975814660260083
Validation loss: 3.2872807925976897

Epoch: 5| Step: 6
Training loss: 2.76814706751799
Validation loss: 3.289172312498991

Epoch: 5| Step: 7
Training loss: 3.643748895504295
Validation loss: 3.2868366659764767

Epoch: 5| Step: 8
Training loss: 3.1356302655399935
Validation loss: 3.286483339159599

Epoch: 5| Step: 9
Training loss: 3.6681320267839284
Validation loss: 3.289475358143301

Epoch: 5| Step: 10
Training loss: 3.1257449978664305
Validation loss: 3.2870662614410784

Epoch: 47| Step: 0
Training loss: 3.5424247080057536
Validation loss: 3.287538621996023

Epoch: 5| Step: 1
Training loss: 3.1326692695885585
Validation loss: 3.2856259373301615

Epoch: 5| Step: 2
Training loss: 3.0828324160195977
Validation loss: 3.285498332784877

Epoch: 5| Step: 3
Training loss: 3.1934948067133866
Validation loss: 3.2850314959640063

Epoch: 5| Step: 4
Training loss: 3.3723627312212687
Validation loss: 3.2853888329011296

Epoch: 5| Step: 5
Training loss: 3.6584778869386034
Validation loss: 3.2845119999403605

Epoch: 5| Step: 6
Training loss: 3.897514279812241
Validation loss: 3.283890942233307

Epoch: 5| Step: 7
Training loss: 3.5562652104861994
Validation loss: 3.281938694463026

Epoch: 5| Step: 8
Training loss: 3.2007833714067293
Validation loss: 3.2832294015616843

Epoch: 5| Step: 9
Training loss: 3.9347344026034032
Validation loss: 3.2843424673006814

Epoch: 5| Step: 10
Training loss: 4.161020853523452
Validation loss: 3.284682017095641

Epoch: 48| Step: 0
Training loss: 3.3275561495771737
Validation loss: 3.2833831603639476

Epoch: 5| Step: 1
Training loss: 3.0874560519036582
Validation loss: 3.281373466516613

Epoch: 5| Step: 2
Training loss: 2.3530619457049378
Validation loss: 3.281754627869966

Epoch: 5| Step: 3
Training loss: 3.0515328042049883
Validation loss: 3.281695916990899

Epoch: 5| Step: 4
Training loss: 3.4633483067893454
Validation loss: 3.2825053995792794

Epoch: 5| Step: 5
Training loss: 3.8942961626639367
Validation loss: 3.2833392639214867

Epoch: 5| Step: 6
Training loss: 3.46390284134632
Validation loss: 3.2811848740919274

Epoch: 5| Step: 7
Training loss: 4.083659308261068
Validation loss: 3.2806316943641463

Epoch: 5| Step: 8
Training loss: 4.1089549266936
Validation loss: 3.2799484335714824

Epoch: 5| Step: 9
Training loss: 4.190495572520098
Validation loss: 3.276587041661166

Epoch: 5| Step: 10
Training loss: 3.261604864450794
Validation loss: 3.277414609996703

Epoch: 49| Step: 0
Training loss: 4.0871456540938595
Validation loss: 3.275147798132876

Epoch: 5| Step: 1
Training loss: 3.5364004738091
Validation loss: 3.2756240296544115

Epoch: 5| Step: 2
Training loss: 3.7051283169867295
Validation loss: 3.276438927744156

Epoch: 5| Step: 3
Training loss: 3.6510034723320204
Validation loss: 3.2733632990044828

Epoch: 5| Step: 4
Training loss: 3.325927438675045
Validation loss: 3.2751827182443862

Epoch: 5| Step: 5
Training loss: 2.984352950568906
Validation loss: 3.273516222767135

Epoch: 5| Step: 6
Training loss: 3.6163591462168507
Validation loss: 3.2724594537431098

Epoch: 5| Step: 7
Training loss: 3.2063326521959765
Validation loss: 3.274527760130577

Epoch: 5| Step: 8
Training loss: 4.09390840879108
Validation loss: 3.271115279065555

Epoch: 5| Step: 9
Training loss: 3.1171174388077416
Validation loss: 3.269734810230881

Epoch: 5| Step: 10
Training loss: 3.1477310486117664
Validation loss: 3.2686119214656135

Epoch: 50| Step: 0
Training loss: 3.34293248530663
Validation loss: 3.270087548539932

Epoch: 5| Step: 1
Training loss: 3.3919533092146317
Validation loss: 3.2708694621130516

Epoch: 5| Step: 2
Training loss: 3.9610392239541903
Validation loss: 3.2705088801256337

Epoch: 5| Step: 3
Training loss: 2.5613153091675525
Validation loss: 3.2738379726071445

Epoch: 5| Step: 4
Training loss: 3.95111563657147
Validation loss: 3.2802464729513323

Epoch: 5| Step: 5
Training loss: 3.0553052818991078
Validation loss: 3.2750992872713245

Epoch: 5| Step: 6
Training loss: 4.125494956174696
Validation loss: 3.2679973357141527

Epoch: 5| Step: 7
Training loss: 3.8423712513884047
Validation loss: 3.2627607721088223

Epoch: 5| Step: 8
Training loss: 3.489223237697788
Validation loss: 3.2636842451578354

Epoch: 5| Step: 9
Training loss: 3.2408691667410174
Validation loss: 3.2660537032466213

Epoch: 5| Step: 10
Training loss: 3.369118970718455
Validation loss: 3.266001674184997

Epoch: 51| Step: 0
Training loss: 4.427185320707911
Validation loss: 3.2659536836974365

Epoch: 5| Step: 1
Training loss: 3.0178788217393087
Validation loss: 3.263312357998383

Epoch: 5| Step: 2
Training loss: 2.3789076531066264
Validation loss: 3.265550318454409

Epoch: 5| Step: 3
Training loss: 3.710241762494356
Validation loss: 3.2643761028493308

Epoch: 5| Step: 4
Training loss: 3.7078988895889595
Validation loss: 3.262813984279361

Epoch: 5| Step: 5
Training loss: 3.1311892444556473
Validation loss: 3.264411428760155

Epoch: 5| Step: 6
Training loss: 3.541961089219353
Validation loss: 3.2636728914473

Epoch: 5| Step: 7
Training loss: 3.7526045337529457
Validation loss: 3.2650610127692445

Epoch: 5| Step: 8
Training loss: 3.517971222309258
Validation loss: 3.2605117463704993

Epoch: 5| Step: 9
Training loss: 3.2945561502812417
Validation loss: 3.259413361583432

Epoch: 5| Step: 10
Training loss: 3.7458343256919715
Validation loss: 3.260262299149415

Epoch: 52| Step: 0
Training loss: 2.9170198135932344
Validation loss: 3.26174686432786

Epoch: 5| Step: 1
Training loss: 4.398182510925856
Validation loss: 3.2608767986826708

Epoch: 5| Step: 2
Training loss: 3.7737029872719208
Validation loss: 3.259959878499094

Epoch: 5| Step: 3
Training loss: 2.6481377085924804
Validation loss: 3.259664891861942

Epoch: 5| Step: 4
Training loss: 3.455380906832662
Validation loss: 3.2589196834278855

Epoch: 5| Step: 5
Training loss: 3.567398986027873
Validation loss: 3.257250158734913

Epoch: 5| Step: 6
Training loss: 3.745391811761274
Validation loss: 3.259165512033869

Epoch: 5| Step: 7
Training loss: 3.5446767843132077
Validation loss: 3.257722224761252

Epoch: 5| Step: 8
Training loss: 3.3332607420328584
Validation loss: 3.258726197891327

Epoch: 5| Step: 9
Training loss: 3.4612867467602766
Validation loss: 3.2560158435370252

Epoch: 5| Step: 10
Training loss: 3.387391407482364
Validation loss: 3.25498243503813

Epoch: 53| Step: 0
Training loss: 3.0933771390389198
Validation loss: 3.256604262709118

Epoch: 5| Step: 1
Training loss: 3.4425720249417617
Validation loss: 3.258747685750448

Epoch: 5| Step: 2
Training loss: 3.7016487881227134
Validation loss: 3.2640151899574654

Epoch: 5| Step: 3
Training loss: 3.4947351639676465
Validation loss: 3.2641993623195615

Epoch: 5| Step: 4
Training loss: 3.179073640021445
Validation loss: 3.2582416300482273

Epoch: 5| Step: 5
Training loss: 3.8431869962899476
Validation loss: 3.257227988845696

Epoch: 5| Step: 6
Training loss: 3.647821868646546
Validation loss: 3.2547472949303007

Epoch: 5| Step: 7
Training loss: 2.8092179539865696
Validation loss: 3.252439887743063

Epoch: 5| Step: 8
Training loss: 4.167523003636554
Validation loss: 3.252427205246331

Epoch: 5| Step: 9
Training loss: 3.482129249965365
Validation loss: 3.254534222244894

Epoch: 5| Step: 10
Training loss: 3.4581705231240973
Validation loss: 3.25219579420233

Epoch: 54| Step: 0
Training loss: 3.4273675184293086
Validation loss: 3.253165898334846

Epoch: 5| Step: 1
Training loss: 3.2338136932269985
Validation loss: 3.250560319368221

Epoch: 5| Step: 2
Training loss: 3.080173488536388
Validation loss: 3.251733164745288

Epoch: 5| Step: 3
Training loss: 3.5256186625520565
Validation loss: 3.252813627941865

Epoch: 5| Step: 4
Training loss: 3.7827320819864254
Validation loss: 3.2534685580982488

Epoch: 5| Step: 5
Training loss: 3.999602894144874
Validation loss: 3.252564038025248

Epoch: 5| Step: 6
Training loss: 3.7560063897221725
Validation loss: 3.253070749984185

Epoch: 5| Step: 7
Training loss: 3.431469708410845
Validation loss: 3.250466446577357

Epoch: 5| Step: 8
Training loss: 3.134641194473591
Validation loss: 3.249146190783168

Epoch: 5| Step: 9
Training loss: 3.505547486779757
Validation loss: 3.248138468867084

Epoch: 5| Step: 10
Training loss: 3.4980872240833163
Validation loss: 3.2500516131698776

Epoch: 55| Step: 0
Training loss: 4.114789405523282
Validation loss: 3.255831342116416

Epoch: 5| Step: 1
Training loss: 3.614267575473169
Validation loss: 3.2498750717851523

Epoch: 5| Step: 2
Training loss: 3.246437173940198
Validation loss: 3.2485280422854896

Epoch: 5| Step: 3
Training loss: 3.3630483017196924
Validation loss: 3.247031908236084

Epoch: 5| Step: 4
Training loss: 2.6838062540953818
Validation loss: 3.24528316370968

Epoch: 5| Step: 5
Training loss: 3.5914953705785573
Validation loss: 3.248092897989246

Epoch: 5| Step: 6
Training loss: 3.317957574813415
Validation loss: 3.245393070423875

Epoch: 5| Step: 7
Training loss: 3.3155966625386895
Validation loss: 3.2457563462512233

Epoch: 5| Step: 8
Training loss: 3.6617788913379044
Validation loss: 3.2428476878424175

Epoch: 5| Step: 9
Training loss: 3.7615420417834615
Validation loss: 3.2413912852423485

Epoch: 5| Step: 10
Training loss: 3.5936673362180978
Validation loss: 3.2414348750244875

Epoch: 56| Step: 0
Training loss: 3.877141545326918
Validation loss: 3.241710612647167

Epoch: 5| Step: 1
Training loss: 3.1086842138602475
Validation loss: 3.2411355589460467

Epoch: 5| Step: 2
Training loss: 3.4484905368475425
Validation loss: 3.241640998335274

Epoch: 5| Step: 3
Training loss: 2.8611904697049906
Validation loss: 3.2406430905721075

Epoch: 5| Step: 4
Training loss: 3.7575004590834324
Validation loss: 3.2411576348404862

Epoch: 5| Step: 5
Training loss: 3.984688301484239
Validation loss: 3.23948443959245

Epoch: 5| Step: 6
Training loss: 3.9302857931339354
Validation loss: 3.241593271975676

Epoch: 5| Step: 7
Training loss: 3.436468767325865
Validation loss: 3.2420585811290312

Epoch: 5| Step: 8
Training loss: 3.4759483909419164
Validation loss: 3.2387317389794266

Epoch: 5| Step: 9
Training loss: 3.3729979617002126
Validation loss: 3.2374631693294678

Epoch: 5| Step: 10
Training loss: 2.7527396686925827
Validation loss: 3.240368463085865

Epoch: 57| Step: 0
Training loss: 3.245649066309126
Validation loss: 3.2427456259368888

Epoch: 5| Step: 1
Training loss: 3.7423832151326044
Validation loss: 3.267123826375126

Epoch: 5| Step: 2
Training loss: 3.406837762640685
Validation loss: 3.23713163876838

Epoch: 5| Step: 3
Training loss: 3.228466589728953
Validation loss: 3.24471276634604

Epoch: 5| Step: 4
Training loss: 3.537180284266455
Validation loss: 3.2793711504655287

Epoch: 5| Step: 5
Training loss: 3.022937979821318
Validation loss: 3.3034363550878174

Epoch: 5| Step: 6
Training loss: 3.2815592302204926
Validation loss: 3.2584439317861973

Epoch: 5| Step: 7
Training loss: 3.4979443644248156
Validation loss: 3.2443928715544907

Epoch: 5| Step: 8
Training loss: 3.8661569166155223
Validation loss: 3.2427551792572475

Epoch: 5| Step: 9
Training loss: 4.11500540713283
Validation loss: 3.2401394498129044

Epoch: 5| Step: 10
Training loss: 3.3867373350484873
Validation loss: 3.2427966810081243

Epoch: 58| Step: 0
Training loss: 2.759350485601
Validation loss: 3.242140600876141

Epoch: 5| Step: 1
Training loss: 3.9132239991164246
Validation loss: 3.2439197161495006

Epoch: 5| Step: 2
Training loss: 3.7860023332398205
Validation loss: 3.242996547001369

Epoch: 5| Step: 3
Training loss: 3.6056507267185403
Validation loss: 3.2450067421242226

Epoch: 5| Step: 4
Training loss: 3.2642334523955667
Validation loss: 3.241141166917713

Epoch: 5| Step: 5
Training loss: 2.4663853003718086
Validation loss: 3.2391051257426335

Epoch: 5| Step: 6
Training loss: 3.620501917401941
Validation loss: 3.238902487561785

Epoch: 5| Step: 7
Training loss: 3.3264694752728268
Validation loss: 3.2367373496706127

Epoch: 5| Step: 8
Training loss: 3.935353132831961
Validation loss: 3.2399885113298614

Epoch: 5| Step: 9
Training loss: 3.7214400875707265
Validation loss: 3.239251740655606

Epoch: 5| Step: 10
Training loss: 3.7106442626740996
Validation loss: 3.2346278939801874

Epoch: 59| Step: 0
Training loss: 3.3014679504807796
Validation loss: 3.237836614496797

Epoch: 5| Step: 1
Training loss: 4.411589505325828
Validation loss: 3.235551875714588

Epoch: 5| Step: 2
Training loss: 3.49627446394849
Validation loss: 3.234802363702255

Epoch: 5| Step: 3
Training loss: 3.189953626337473
Validation loss: 3.2314024416115212

Epoch: 5| Step: 4
Training loss: 3.6316565858847794
Validation loss: 3.234091288693527

Epoch: 5| Step: 5
Training loss: 3.5129539006414854
Validation loss: 3.229611834837182

Epoch: 5| Step: 6
Training loss: 3.5058563827459377
Validation loss: 3.2326890156510513

Epoch: 5| Step: 7
Training loss: 2.5622714801401223
Validation loss: 3.231857419352793

Epoch: 5| Step: 8
Training loss: 3.875234658304112
Validation loss: 3.2315144673645846

Epoch: 5| Step: 9
Training loss: 3.014131957144233
Validation loss: 3.2310862181164643

Epoch: 5| Step: 10
Training loss: 3.4904076053470954
Validation loss: 3.230562067502462

Epoch: 60| Step: 0
Training loss: 3.4124272880213455
Validation loss: 3.2335950122875947

Epoch: 5| Step: 1
Training loss: 2.944279092268419
Validation loss: 3.2362385844611072

Epoch: 5| Step: 2
Training loss: 3.713111256842229
Validation loss: 3.232514087667971

Epoch: 5| Step: 3
Training loss: 3.8194097220643926
Validation loss: 3.234931779380402

Epoch: 5| Step: 4
Training loss: 4.108380215411515
Validation loss: 3.2276001691606906

Epoch: 5| Step: 5
Training loss: 3.0256147406297154
Validation loss: 3.227406673475461

Epoch: 5| Step: 6
Training loss: 3.229748646785247
Validation loss: 3.232186200872797

Epoch: 5| Step: 7
Training loss: 3.2321591365557785
Validation loss: 3.2353571820820597

Epoch: 5| Step: 8
Training loss: 3.054808319122028
Validation loss: 3.2364098036083795

Epoch: 5| Step: 9
Training loss: 3.6064779702099075
Validation loss: 3.24492448670456

Epoch: 5| Step: 10
Training loss: 4.043232932189946
Validation loss: 3.2463593833889335

Epoch: 61| Step: 0
Training loss: 2.843484719447503
Validation loss: 3.2398817066558974

Epoch: 5| Step: 1
Training loss: 4.037992767403083
Validation loss: 3.235774872269156

Epoch: 5| Step: 2
Training loss: 3.8347049139058145
Validation loss: 3.2312166680647723

Epoch: 5| Step: 3
Training loss: 3.755696738020267
Validation loss: 3.229813521608326

Epoch: 5| Step: 4
Training loss: 2.899044826659709
Validation loss: 3.226892003734828

Epoch: 5| Step: 5
Training loss: 3.807317494497438
Validation loss: 3.2289694565417877

Epoch: 5| Step: 6
Training loss: 3.3274760441881464
Validation loss: 3.225799459993312

Epoch: 5| Step: 7
Training loss: 2.8338844286950367
Validation loss: 3.225962210299308

Epoch: 5| Step: 8
Training loss: 3.7341588169234745
Validation loss: 3.2257672478231703

Epoch: 5| Step: 9
Training loss: 3.5062888729776103
Validation loss: 3.2263357471180356

Epoch: 5| Step: 10
Training loss: 3.4279790633373475
Validation loss: 3.227907777065307

Epoch: 62| Step: 0
Training loss: 4.2617856587752945
Validation loss: 3.2282769371082005

Epoch: 5| Step: 1
Training loss: 3.6332037602222997
Validation loss: 3.226962954699592

Epoch: 5| Step: 2
Training loss: 3.4892845974867543
Validation loss: 3.224192051224722

Epoch: 5| Step: 3
Training loss: 3.0989548798015596
Validation loss: 3.225214206436832

Epoch: 5| Step: 4
Training loss: 3.3221305626848716
Validation loss: 3.2253413552402788

Epoch: 5| Step: 5
Training loss: 2.732526317724476
Validation loss: 3.223937804263284

Epoch: 5| Step: 6
Training loss: 2.9792793270408056
Validation loss: 3.2273932793784446

Epoch: 5| Step: 7
Training loss: 3.6103254115566292
Validation loss: 3.226670505104775

Epoch: 5| Step: 8
Training loss: 3.71219512509641
Validation loss: 3.22485753684567

Epoch: 5| Step: 9
Training loss: 3.738448853756504
Validation loss: 3.2246233801057698

Epoch: 5| Step: 10
Training loss: 3.3528262159010276
Validation loss: 3.224109266358451

Epoch: 63| Step: 0
Training loss: 2.9581822280619203
Validation loss: 3.222489708220112

Epoch: 5| Step: 1
Training loss: 2.826825934217691
Validation loss: 3.223638064422272

Epoch: 5| Step: 2
Training loss: 3.2998516511806715
Validation loss: 3.2210858339276176

Epoch: 5| Step: 3
Training loss: 3.7530888869353074
Validation loss: 3.2194694099776124

Epoch: 5| Step: 4
Training loss: 3.341853236621074
Validation loss: 3.2198883984083437

Epoch: 5| Step: 5
Training loss: 3.5269652170921852
Validation loss: 3.220153391145038

Epoch: 5| Step: 6
Training loss: 3.43842788657502
Validation loss: 3.221666875954377

Epoch: 5| Step: 7
Training loss: 3.589822497216741
Validation loss: 3.2202458675534897

Epoch: 5| Step: 8
Training loss: 3.7703784366158595
Validation loss: 3.218320491945263

Epoch: 5| Step: 9
Training loss: 3.5036144666693407
Validation loss: 3.2221917654381897

Epoch: 5| Step: 10
Training loss: 4.057585575425896
Validation loss: 3.2192886718972686

Epoch: 64| Step: 0
Training loss: 4.063961998423926
Validation loss: 3.21955473800152

Epoch: 5| Step: 1
Training loss: 3.43412032011793
Validation loss: 3.219427040546148

Epoch: 5| Step: 2
Training loss: 3.859697212637565
Validation loss: 3.2192259692561755

Epoch: 5| Step: 3
Training loss: 3.267807518658941
Validation loss: 3.219161831133545

Epoch: 5| Step: 4
Training loss: 3.1786173301309315
Validation loss: 3.2161593709880547

Epoch: 5| Step: 5
Training loss: 2.557881915828936
Validation loss: 3.217328758285994

Epoch: 5| Step: 6
Training loss: 4.247270268452005
Validation loss: 3.217483926206042

Epoch: 5| Step: 7
Training loss: 3.1969747906246693
Validation loss: 3.216283015098403

Epoch: 5| Step: 8
Training loss: 3.110333318971222
Validation loss: 3.2174596735945147

Epoch: 5| Step: 9
Training loss: 3.511960981286955
Validation loss: 3.2153376009068735

Epoch: 5| Step: 10
Training loss: 3.347914197280312
Validation loss: 3.214917899774476

Epoch: 65| Step: 0
Training loss: 3.5733129135184174
Validation loss: 3.212953141690752

Epoch: 5| Step: 1
Training loss: 2.4147954031955656
Validation loss: 3.214297183749298

Epoch: 5| Step: 2
Training loss: 3.769032689463651
Validation loss: 3.2170006992107103

Epoch: 5| Step: 3
Training loss: 3.672395190463102
Validation loss: 3.2156687905784245

Epoch: 5| Step: 4
Training loss: 3.1554954306675627
Validation loss: 3.213612040715119

Epoch: 5| Step: 5
Training loss: 3.370520267794032
Validation loss: 3.2146509076036716

Epoch: 5| Step: 6
Training loss: 3.8871002776781545
Validation loss: 3.2163759758104384

Epoch: 5| Step: 7
Training loss: 3.0267865855733755
Validation loss: 3.2155741192365226

Epoch: 5| Step: 8
Training loss: 4.423331623973003
Validation loss: 3.2156467756821625

Epoch: 5| Step: 9
Training loss: 3.227033751574543
Validation loss: 3.2150139045494392

Epoch: 5| Step: 10
Training loss: 3.1299431424567774
Validation loss: 3.213765752789512

Epoch: 66| Step: 0
Training loss: 3.8769036815959295
Validation loss: 3.2148844661618057

Epoch: 5| Step: 1
Training loss: 3.2656118584327385
Validation loss: 3.2147858099784434

Epoch: 5| Step: 2
Training loss: 3.7234111392760485
Validation loss: 3.217838045462816

Epoch: 5| Step: 3
Training loss: 3.386504028975758
Validation loss: 3.2281275103635836

Epoch: 5| Step: 4
Training loss: 3.642060614838221
Validation loss: 3.2288951046403755

Epoch: 5| Step: 5
Training loss: 3.578860144910473
Validation loss: 3.2227559173375986

Epoch: 5| Step: 6
Training loss: 2.939572191836851
Validation loss: 3.2140223374861687

Epoch: 5| Step: 7
Training loss: 2.9553684008848595
Validation loss: 3.2133342557451434

Epoch: 5| Step: 8
Training loss: 3.67583858757419
Validation loss: 3.2127319372551524

Epoch: 5| Step: 9
Training loss: 3.193497046439861
Validation loss: 3.2112168255273534

Epoch: 5| Step: 10
Training loss: 3.7383978336216113
Validation loss: 3.212171786350461

Epoch: 67| Step: 0
Training loss: 3.340535981122538
Validation loss: 3.2109633252259737

Epoch: 5| Step: 1
Training loss: 3.6435786368902656
Validation loss: 3.211095065296916

Epoch: 5| Step: 2
Training loss: 3.849219052264614
Validation loss: 3.210189691936291

Epoch: 5| Step: 3
Training loss: 3.518895234656092
Validation loss: 3.2104256967591893

Epoch: 5| Step: 4
Training loss: 3.2705032927241837
Validation loss: 3.2111836862914607

Epoch: 5| Step: 5
Training loss: 3.0633272883120704
Validation loss: 3.209921670752249

Epoch: 5| Step: 6
Training loss: 2.8864777377928843
Validation loss: 3.209952260936625

Epoch: 5| Step: 7
Training loss: 3.6342738996041217
Validation loss: 3.2093224206747917

Epoch: 5| Step: 8
Training loss: 3.7055670174861963
Validation loss: 3.208001355459247

Epoch: 5| Step: 9
Training loss: 3.3419000374473393
Validation loss: 3.2076187781695142

Epoch: 5| Step: 10
Training loss: 3.6956384365870387
Validation loss: 3.207450189538823

Epoch: 68| Step: 0
Training loss: 3.773608344023268
Validation loss: 3.2072112016573353

Epoch: 5| Step: 1
Training loss: 3.239621831699922
Validation loss: 3.20952432008318

Epoch: 5| Step: 2
Training loss: 3.233412742295071
Validation loss: 3.2079184324752648

Epoch: 5| Step: 3
Training loss: 3.4455306141984727
Validation loss: 3.206950692142578

Epoch: 5| Step: 4
Training loss: 2.7222797675332613
Validation loss: 3.207235576528698

Epoch: 5| Step: 5
Training loss: 3.415228393647184
Validation loss: 3.210702744870897

Epoch: 5| Step: 6
Training loss: 3.1998002824448557
Validation loss: 3.2064773716583845

Epoch: 5| Step: 7
Training loss: 4.157964825913066
Validation loss: 3.208863257080976

Epoch: 5| Step: 8
Training loss: 3.1923973010817592
Validation loss: 3.206015400896352

Epoch: 5| Step: 9
Training loss: 3.904975011650365
Validation loss: 3.2046198412440607

Epoch: 5| Step: 10
Training loss: 3.5018926680155094
Validation loss: 3.2064619408982127

Epoch: 69| Step: 0
Training loss: 3.202710231816093
Validation loss: 3.204846319561184

Epoch: 5| Step: 1
Training loss: 3.2353611424077156
Validation loss: 3.2049508954108097

Epoch: 5| Step: 2
Training loss: 3.8043395711678927
Validation loss: 3.2049518600902203

Epoch: 5| Step: 3
Training loss: 4.452449493036065
Validation loss: 3.207595328534009

Epoch: 5| Step: 4
Training loss: 2.8352355929110318
Validation loss: 3.203984735993067

Epoch: 5| Step: 5
Training loss: 3.7270466551975883
Validation loss: 3.204606004712318

Epoch: 5| Step: 6
Training loss: 3.054871380435022
Validation loss: 3.2033404806286834

Epoch: 5| Step: 7
Training loss: 3.46125519889532
Validation loss: 3.2036969858451436

Epoch: 5| Step: 8
Training loss: 3.2178850215383425
Validation loss: 3.2046434982470133

Epoch: 5| Step: 9
Training loss: 3.455276026430196
Validation loss: 3.2044464082877666

Epoch: 5| Step: 10
Training loss: 3.202029305976222
Validation loss: 3.203624444096324

Epoch: 70| Step: 0
Training loss: 3.4894405202916583
Validation loss: 3.202624906472766

Epoch: 5| Step: 1
Training loss: 3.758002579733312
Validation loss: 3.202610840388385

Epoch: 5| Step: 2
Training loss: 3.070983036969513
Validation loss: 3.2034174047585764

Epoch: 5| Step: 3
Training loss: 2.842428717881128
Validation loss: 3.202532435164682

Epoch: 5| Step: 4
Training loss: 3.4393951740397624
Validation loss: 3.200432707964065

Epoch: 5| Step: 5
Training loss: 3.2982913766909983
Validation loss: 3.20255501570729

Epoch: 5| Step: 6
Training loss: 3.896517538823467
Validation loss: 3.1996043932662914

Epoch: 5| Step: 7
Training loss: 3.710203720627692
Validation loss: 3.2008271858175155

Epoch: 5| Step: 8
Training loss: 3.1477798267230215
Validation loss: 3.200099935848987

Epoch: 5| Step: 9
Training loss: 3.495888338501182
Validation loss: 3.2017025458067807

Epoch: 5| Step: 10
Training loss: 3.6696957878403174
Validation loss: 3.1982544876910417

Epoch: 71| Step: 0
Training loss: 2.934455755095531
Validation loss: 3.200124724582631

Epoch: 5| Step: 1
Training loss: 3.6304419874235494
Validation loss: 3.2005726062901214

Epoch: 5| Step: 2
Training loss: 3.7436788052267653
Validation loss: 3.2003211050025837

Epoch: 5| Step: 3
Training loss: 3.2871177886293097
Validation loss: 3.2028212952817716

Epoch: 5| Step: 4
Training loss: 2.9648242894515313
Validation loss: 3.202099230633275

Epoch: 5| Step: 5
Training loss: 3.9243387333433075
Validation loss: 3.206939471725938

Epoch: 5| Step: 6
Training loss: 4.072746149706751
Validation loss: 3.2029522512830493

Epoch: 5| Step: 7
Training loss: 3.2847129350297504
Validation loss: 3.1999200673784913

Epoch: 5| Step: 8
Training loss: 3.3383257355193283
Validation loss: 3.1971233640286862

Epoch: 5| Step: 9
Training loss: 3.5316510268173054
Validation loss: 3.195083407367473

Epoch: 5| Step: 10
Training loss: 2.911192270495203
Validation loss: 3.196967025056377

Epoch: 72| Step: 0
Training loss: 3.311124552060126
Validation loss: 3.199452307704896

Epoch: 5| Step: 1
Training loss: 3.31558314377003
Validation loss: 3.197411053113824

Epoch: 5| Step: 2
Training loss: 3.4797522838164894
Validation loss: 3.1982593308031366

Epoch: 5| Step: 3
Training loss: 3.36126088280723
Validation loss: 3.198499698499932

Epoch: 5| Step: 4
Training loss: 3.3475035517974994
Validation loss: 3.197570324011488

Epoch: 5| Step: 5
Training loss: 4.167582042598215
Validation loss: 3.1977249915912362

Epoch: 5| Step: 6
Training loss: 4.037200793821604
Validation loss: 3.1995585357545764

Epoch: 5| Step: 7
Training loss: 4.012588718657527
Validation loss: 3.1971304187722347

Epoch: 5| Step: 8
Training loss: 2.243649952817687
Validation loss: 3.1986188893492717

Epoch: 5| Step: 9
Training loss: 3.398645995310549
Validation loss: 3.2001339965755324

Epoch: 5| Step: 10
Training loss: 2.64654509414893
Validation loss: 3.1974583020361265

Epoch: 73| Step: 0
Training loss: 3.435607805519595
Validation loss: 3.1971773575186235

Epoch: 5| Step: 1
Training loss: 2.9942643649516385
Validation loss: 3.194406638888489

Epoch: 5| Step: 2
Training loss: 3.0198993335139677
Validation loss: 3.195231097894651

Epoch: 5| Step: 3
Training loss: 4.182586520178548
Validation loss: 3.194234462831735

Epoch: 5| Step: 4
Training loss: 2.659451518767783
Validation loss: 3.194121056538971

Epoch: 5| Step: 5
Training loss: 3.8788991200054057
Validation loss: 3.198472434101073

Epoch: 5| Step: 6
Training loss: 3.654098007850441
Validation loss: 3.2018128835769475

Epoch: 5| Step: 7
Training loss: 3.668420863293772
Validation loss: 3.19513303359681

Epoch: 5| Step: 8
Training loss: 2.9097644516564456
Validation loss: 3.193558152636408

Epoch: 5| Step: 9
Training loss: 3.6683327328723196
Validation loss: 3.194411434866794

Epoch: 5| Step: 10
Training loss: 3.5035070831980692
Validation loss: 3.1916325880084244

Epoch: 74| Step: 0
Training loss: 3.2096788301556005
Validation loss: 3.191144287967204

Epoch: 5| Step: 1
Training loss: 3.0780692313317277
Validation loss: 3.1889257328881127

Epoch: 5| Step: 2
Training loss: 3.339153088995113
Validation loss: 3.1880699080934445

Epoch: 5| Step: 3
Training loss: 3.0149279169224394
Validation loss: 3.190925255340387

Epoch: 5| Step: 4
Training loss: 3.692507947785354
Validation loss: 3.1897440954454117

Epoch: 5| Step: 5
Training loss: 2.2346511350075273
Validation loss: 3.189716175920998

Epoch: 5| Step: 6
Training loss: 3.6399746424451975
Validation loss: 3.1888758267623474

Epoch: 5| Step: 7
Training loss: 4.475553015950541
Validation loss: 3.1892380549185777

Epoch: 5| Step: 8
Training loss: 3.4037563050177013
Validation loss: 3.186629539827302

Epoch: 5| Step: 9
Training loss: 3.631947535425787
Validation loss: 3.186616283263358

Epoch: 5| Step: 10
Training loss: 3.7332169401099407
Validation loss: 3.190819358524376

Epoch: 75| Step: 0
Training loss: 3.0066242199232516
Validation loss: 3.1907024763550567

Epoch: 5| Step: 1
Training loss: 3.9798818348351106
Validation loss: 3.193087469876065

Epoch: 5| Step: 2
Training loss: 3.2514392893598028
Validation loss: 3.1841902659610826

Epoch: 5| Step: 3
Training loss: 3.6801931110797526
Validation loss: 3.186532800558665

Epoch: 5| Step: 4
Training loss: 3.5171927114386228
Validation loss: 3.1858802901036922

Epoch: 5| Step: 5
Training loss: 3.4465293897767255
Validation loss: 3.186043990883628

Epoch: 5| Step: 6
Training loss: 3.8421018214715725
Validation loss: 3.1868144518012382

Epoch: 5| Step: 7
Training loss: 3.279058978305075
Validation loss: 3.185860678984461

Epoch: 5| Step: 8
Training loss: 3.7559733817362875
Validation loss: 3.186595884233718

Epoch: 5| Step: 9
Training loss: 2.669302432485727
Validation loss: 3.1846589471140248

Epoch: 5| Step: 10
Training loss: 3.1705717970619602
Validation loss: 3.1868347175024634

Epoch: 76| Step: 0
Training loss: 4.233653552542307
Validation loss: 3.1857563254573296

Epoch: 5| Step: 1
Training loss: 3.3331238362918114
Validation loss: 3.1859906503896434

Epoch: 5| Step: 2
Training loss: 3.6885284024272735
Validation loss: 3.1839587047405633

Epoch: 5| Step: 3
Training loss: 2.4990792486257543
Validation loss: 3.186556241070187

Epoch: 5| Step: 4
Training loss: 2.9503512803753225
Validation loss: 3.19262956554451

Epoch: 5| Step: 5
Training loss: 3.92923219746824
Validation loss: 3.194137301369269

Epoch: 5| Step: 6
Training loss: 3.9070436205531767
Validation loss: 3.1830684524174626

Epoch: 5| Step: 7
Training loss: 3.106642399339758
Validation loss: 3.183466668394957

Epoch: 5| Step: 8
Training loss: 3.4814827038226976
Validation loss: 3.1822836939440937

Epoch: 5| Step: 9
Training loss: 3.3287944568124908
Validation loss: 3.1825477192704588

Epoch: 5| Step: 10
Training loss: 2.9024801106720233
Validation loss: 3.183590532959662

Epoch: 77| Step: 0
Training loss: 2.7088552607850898
Validation loss: 3.1825985462554396

Epoch: 5| Step: 1
Training loss: 3.1200953332078916
Validation loss: 3.183395672495776

Epoch: 5| Step: 2
Training loss: 3.710364496263055
Validation loss: 3.1829777776785138

Epoch: 5| Step: 3
Training loss: 3.1826353163318437
Validation loss: 3.181873278253367

Epoch: 5| Step: 4
Training loss: 3.5613017158328284
Validation loss: 3.1840000340516403

Epoch: 5| Step: 5
Training loss: 4.011183601797492
Validation loss: 3.1801262065830604

Epoch: 5| Step: 6
Training loss: 3.959900729736501
Validation loss: 3.181018852263876

Epoch: 5| Step: 7
Training loss: 4.344704063530473
Validation loss: 3.1808333406287144

Epoch: 5| Step: 8
Training loss: 2.6142055547576275
Validation loss: 3.1828347790218574

Epoch: 5| Step: 9
Training loss: 2.8421936806836485
Validation loss: 3.1804189758511217

Epoch: 5| Step: 10
Training loss: 3.2359797969984347
Validation loss: 3.18422646857458

Epoch: 78| Step: 0
Training loss: 3.8867788645633805
Validation loss: 3.18153016136276

Epoch: 5| Step: 1
Training loss: 3.7603387093674794
Validation loss: 3.183261879255013

Epoch: 5| Step: 2
Training loss: 3.1611616235268
Validation loss: 3.1817305562802782

Epoch: 5| Step: 3
Training loss: 2.934300567365435
Validation loss: 3.180767802096122

Epoch: 5| Step: 4
Training loss: 3.042712689302681
Validation loss: 3.1820399864543343

Epoch: 5| Step: 5
Training loss: 4.201635841418969
Validation loss: 3.187012857381731

Epoch: 5| Step: 6
Training loss: 3.859457656037008
Validation loss: 3.181065688654752

Epoch: 5| Step: 7
Training loss: 2.8817263989263524
Validation loss: 3.1803340366924555

Epoch: 5| Step: 8
Training loss: 3.2175486276267184
Validation loss: 3.1805726131312517

Epoch: 5| Step: 9
Training loss: 3.3949942146892442
Validation loss: 3.179356903533178

Epoch: 5| Step: 10
Training loss: 3.0892893683288283
Validation loss: 3.180119720339355

Epoch: 79| Step: 0
Training loss: 3.474148510136462
Validation loss: 3.1790289838803822

Epoch: 5| Step: 1
Training loss: 3.3719065582523857
Validation loss: 3.1820226308907924

Epoch: 5| Step: 2
Training loss: 3.1070957744019014
Validation loss: 3.1786720089637654

Epoch: 5| Step: 3
Training loss: 3.1807607578082773
Validation loss: 3.1793341840339755

Epoch: 5| Step: 4
Training loss: 3.697311151207095
Validation loss: 3.178918294008017

Epoch: 5| Step: 5
Training loss: 2.9920778578149605
Validation loss: 3.1807180726365822

Epoch: 5| Step: 6
Training loss: 4.029728565398793
Validation loss: 3.1792955114863464

Epoch: 5| Step: 7
Training loss: 3.5056594324078705
Validation loss: 3.1809595248564073

Epoch: 5| Step: 8
Training loss: 2.923212571413666
Validation loss: 3.1831913732843655

Epoch: 5| Step: 9
Training loss: 3.172830672590126
Validation loss: 3.181157647672904

Epoch: 5| Step: 10
Training loss: 4.156955745121005
Validation loss: 3.1833001581258795

Epoch: 80| Step: 0
Training loss: 3.458289241892705
Validation loss: 3.179613894468078

Epoch: 5| Step: 1
Training loss: 3.389803879277652
Validation loss: 3.1793323294396356

Epoch: 5| Step: 2
Training loss: 4.110105732395424
Validation loss: 3.1791353492343135

Epoch: 5| Step: 3
Training loss: 3.2991883175544103
Validation loss: 3.176677873393241

Epoch: 5| Step: 4
Training loss: 3.253674850387398
Validation loss: 3.1771723441100614

Epoch: 5| Step: 5
Training loss: 2.987882939140657
Validation loss: 3.1818037180444647

Epoch: 5| Step: 6
Training loss: 3.307408576561047
Validation loss: 3.1795103542751297

Epoch: 5| Step: 7
Training loss: 2.8938508051210596
Validation loss: 3.178177316625283

Epoch: 5| Step: 8
Training loss: 3.6328261508480084
Validation loss: 3.1831212394510464

Epoch: 5| Step: 9
Training loss: 3.342020746309365
Validation loss: 3.180276289376261

Epoch: 5| Step: 10
Training loss: 3.8992309985907596
Validation loss: 3.175205961585903

Epoch: 81| Step: 0
Training loss: 3.684027896025801
Validation loss: 3.1748820995389515

Epoch: 5| Step: 1
Training loss: 3.685955823437989
Validation loss: 3.1754777573580926

Epoch: 5| Step: 2
Training loss: 3.5676851517789685
Validation loss: 3.1740092774242723

Epoch: 5| Step: 3
Training loss: 3.6604591333874645
Validation loss: 3.1750730795988997

Epoch: 5| Step: 4
Training loss: 2.900937547076561
Validation loss: 3.1741132587489975

Epoch: 5| Step: 5
Training loss: 3.2826479885562603
Validation loss: 3.1725130472469525

Epoch: 5| Step: 6
Training loss: 3.3114256646119924
Validation loss: 3.1740344548834267

Epoch: 5| Step: 7
Training loss: 3.0662101537119195
Validation loss: 3.173941255608842

Epoch: 5| Step: 8
Training loss: 3.5737069519161513
Validation loss: 3.174622099432275

Epoch: 5| Step: 9
Training loss: 3.2640045379999814
Validation loss: 3.17589260941825

Epoch: 5| Step: 10
Training loss: 3.6069035511410457
Validation loss: 3.17421465866365

Epoch: 82| Step: 0
Training loss: 3.7816050969627963
Validation loss: 3.1738371862592945

Epoch: 5| Step: 1
Training loss: 3.466673358274995
Validation loss: 3.1740779245420447

Epoch: 5| Step: 2
Training loss: 3.9349427168868245
Validation loss: 3.171908105394269

Epoch: 5| Step: 3
Training loss: 3.8123641693432675
Validation loss: 3.1701146693691378

Epoch: 5| Step: 4
Training loss: 2.95208689694581
Validation loss: 3.168841781301545

Epoch: 5| Step: 5
Training loss: 3.4980820441594704
Validation loss: 3.170065712504366

Epoch: 5| Step: 6
Training loss: 2.502487280448425
Validation loss: 3.1692147654394955

Epoch: 5| Step: 7
Training loss: 3.2402105347789334
Validation loss: 3.16737985162897

Epoch: 5| Step: 8
Training loss: 3.508388412538564
Validation loss: 3.170056782796803

Epoch: 5| Step: 9
Training loss: 3.4977438330575175
Validation loss: 3.1686142327997566

Epoch: 5| Step: 10
Training loss: 3.181671798113093
Validation loss: 3.1677576192491763

Epoch: 83| Step: 0
Training loss: 3.6531057287120676
Validation loss: 3.168649958031495

Epoch: 5| Step: 1
Training loss: 2.88606388990461
Validation loss: 3.166014651695733

Epoch: 5| Step: 2
Training loss: 2.91102568676596
Validation loss: 3.1668019894591275

Epoch: 5| Step: 3
Training loss: 3.4338206627417325
Validation loss: 3.1669947155285

Epoch: 5| Step: 4
Training loss: 3.2691771248261126
Validation loss: 3.165141443206533

Epoch: 5| Step: 5
Training loss: 3.455202332243118
Validation loss: 3.1656212964831063

Epoch: 5| Step: 6
Training loss: 3.854669582787643
Validation loss: 3.1669811460710493

Epoch: 5| Step: 7
Training loss: 3.2242177798263016
Validation loss: 3.164969208446437

Epoch: 5| Step: 8
Training loss: 3.6160770961172104
Validation loss: 3.164397900912225

Epoch: 5| Step: 9
Training loss: 3.523404884610339
Validation loss: 3.1631029430965225

Epoch: 5| Step: 10
Training loss: 3.7136984743429835
Validation loss: 3.1646279244422937

Epoch: 84| Step: 0
Training loss: 3.6086612672801217
Validation loss: 3.166119271284863

Epoch: 5| Step: 1
Training loss: 3.0692102526068545
Validation loss: 3.1674732083533206

Epoch: 5| Step: 2
Training loss: 3.814317363895491
Validation loss: 3.1686462856878337

Epoch: 5| Step: 3
Training loss: 3.4278875333037115
Validation loss: 3.1708568339331085

Epoch: 5| Step: 4
Training loss: 3.012737888424844
Validation loss: 3.1718146625904162

Epoch: 5| Step: 5
Training loss: 3.5652431166520695
Validation loss: 3.1666051575840246

Epoch: 5| Step: 6
Training loss: 3.2955171943856114
Validation loss: 3.16494577977737

Epoch: 5| Step: 7
Training loss: 3.6148957805462976
Validation loss: 3.1646152991289997

Epoch: 5| Step: 8
Training loss: 3.1152991213393104
Validation loss: 3.1650111145836286

Epoch: 5| Step: 9
Training loss: 3.3604367020055643
Validation loss: 3.1626894952662985

Epoch: 5| Step: 10
Training loss: 3.666837702721262
Validation loss: 3.1649356092639462

Epoch: 85| Step: 0
Training loss: 2.6186166988851065
Validation loss: 3.1635993216422404

Epoch: 5| Step: 1
Training loss: 3.774635898639412
Validation loss: 3.1640468283563545

Epoch: 5| Step: 2
Training loss: 3.7805891484108707
Validation loss: 3.1616260882548928

Epoch: 5| Step: 3
Training loss: 2.9455922446725378
Validation loss: 3.162197810630843

Epoch: 5| Step: 4
Training loss: 3.0771160505376725
Validation loss: 3.159414179740473

Epoch: 5| Step: 5
Training loss: 2.9795237151621845
Validation loss: 3.163272425105165

Epoch: 5| Step: 6
Training loss: 3.4777998533215198
Validation loss: 3.160830932148929

Epoch: 5| Step: 7
Training loss: 3.3921257951730386
Validation loss: 3.160927340401799

Epoch: 5| Step: 8
Training loss: 3.815686879449035
Validation loss: 3.160800948540645

Epoch: 5| Step: 9
Training loss: 4.240181520643064
Validation loss: 3.1601262113154847

Epoch: 5| Step: 10
Training loss: 3.085501879112748
Validation loss: 3.1593857114333246

Epoch: 86| Step: 0
Training loss: 3.528388019823304
Validation loss: 3.1609458190984654

Epoch: 5| Step: 1
Training loss: 3.0294558534404055
Validation loss: 3.1596866215461197

Epoch: 5| Step: 2
Training loss: 3.883368530987104
Validation loss: 3.1597902466368653

Epoch: 5| Step: 3
Training loss: 2.867725955804141
Validation loss: 3.1596748178712315

Epoch: 5| Step: 4
Training loss: 3.12000791450866
Validation loss: 3.1607588365334944

Epoch: 5| Step: 5
Training loss: 3.5135858343933215
Validation loss: 3.1650355925135996

Epoch: 5| Step: 6
Training loss: 3.645913927913134
Validation loss: 3.160997790664713

Epoch: 5| Step: 7
Training loss: 3.628212787574812
Validation loss: 3.159955225178572

Epoch: 5| Step: 8
Training loss: 3.3005612271805647
Validation loss: 3.161425818600643

Epoch: 5| Step: 9
Training loss: 3.7818512241547295
Validation loss: 3.158693692973819

Epoch: 5| Step: 10
Training loss: 3.01977585447044
Validation loss: 3.159683376919233

Epoch: 87| Step: 0
Training loss: 3.2957951372700682
Validation loss: 3.159926726048702

Epoch: 5| Step: 1
Training loss: 3.5134353261206503
Validation loss: 3.1579154019218434

Epoch: 5| Step: 2
Training loss: 3.87775188068194
Validation loss: 3.159152030199294

Epoch: 5| Step: 3
Training loss: 3.101726537253382
Validation loss: 3.15626336136212

Epoch: 5| Step: 4
Training loss: 3.6918253988637924
Validation loss: 3.1578985632263543

Epoch: 5| Step: 5
Training loss: 2.804872979536765
Validation loss: 3.156783901995549

Epoch: 5| Step: 6
Training loss: 3.4817731919586175
Validation loss: 3.1581949532001996

Epoch: 5| Step: 7
Training loss: 3.361767577770397
Validation loss: 3.1556659549210986

Epoch: 5| Step: 8
Training loss: 3.3668335907851983
Validation loss: 3.156032451197508

Epoch: 5| Step: 9
Training loss: 3.6059808005838976
Validation loss: 3.1555463472964047

Epoch: 5| Step: 10
Training loss: 3.2651910082806244
Validation loss: 3.154813064331969

Epoch: 88| Step: 0
Training loss: 2.7620817428801425
Validation loss: 3.1550762252384352

Epoch: 5| Step: 1
Training loss: 3.1746882848835343
Validation loss: 3.1527497075571858

Epoch: 5| Step: 2
Training loss: 3.859082786215748
Validation loss: 3.155047032808004

Epoch: 5| Step: 3
Training loss: 3.847283452752125
Validation loss: 3.15371055303244

Epoch: 5| Step: 4
Training loss: 3.378617784832479
Validation loss: 3.1524608134041032

Epoch: 5| Step: 5
Training loss: 2.647308198863152
Validation loss: 3.1537850687590825

Epoch: 5| Step: 6
Training loss: 3.9005488180707752
Validation loss: 3.154087272346298

Epoch: 5| Step: 7
Training loss: 2.658810268018536
Validation loss: 3.152783719575912

Epoch: 5| Step: 8
Training loss: 3.9860277525322774
Validation loss: 3.1524234596002234

Epoch: 5| Step: 9
Training loss: 3.6842696701407913
Validation loss: 3.151088246782871

Epoch: 5| Step: 10
Training loss: 3.130206539176812
Validation loss: 3.1516429181391596

Epoch: 89| Step: 0
Training loss: 3.612314323748637
Validation loss: 3.1524457070140905

Epoch: 5| Step: 1
Training loss: 3.201814858063305
Validation loss: 3.149027667790226

Epoch: 5| Step: 2
Training loss: 3.552310895295959
Validation loss: 3.1488343850799456

Epoch: 5| Step: 3
Training loss: 2.9452032175204272
Validation loss: 3.1501176787058345

Epoch: 5| Step: 4
Training loss: 3.710665337470371
Validation loss: 3.1486011599894894

Epoch: 5| Step: 5
Training loss: 3.632865002980817
Validation loss: 3.14616887623547

Epoch: 5| Step: 6
Training loss: 3.5134163255196817
Validation loss: 3.1457340350034646

Epoch: 5| Step: 7
Training loss: 2.8758192139150625
Validation loss: 3.1459066122628903

Epoch: 5| Step: 8
Training loss: 3.794296079545956
Validation loss: 3.1443808177525385

Epoch: 5| Step: 9
Training loss: 3.1630673951197017
Validation loss: 3.1455376158806385

Epoch: 5| Step: 10
Training loss: 3.2991891847442454
Validation loss: 3.1456311204431255

Epoch: 90| Step: 0
Training loss: 3.292990470624539
Validation loss: 3.1443688750898913

Epoch: 5| Step: 1
Training loss: 2.718366398550795
Validation loss: 3.1444127418129404

Epoch: 5| Step: 2
Training loss: 3.3983540141056507
Validation loss: 3.1419315982274143

Epoch: 5| Step: 3
Training loss: 3.485374820425341
Validation loss: 3.144045714595447

Epoch: 5| Step: 4
Training loss: 3.42703067696574
Validation loss: 3.1427864608253104

Epoch: 5| Step: 5
Training loss: 2.798640200261552
Validation loss: 3.140560021521841

Epoch: 5| Step: 6
Training loss: 3.4894360107904085
Validation loss: 3.1420917231820757

Epoch: 5| Step: 7
Training loss: 3.5151971853412514
Validation loss: 3.1422629731960634

Epoch: 5| Step: 8
Training loss: 3.3888338341609785
Validation loss: 3.1405906636595633

Epoch: 5| Step: 9
Training loss: 3.8650870736049208
Validation loss: 3.141956079719627

Epoch: 5| Step: 10
Training loss: 3.9034015493407166
Validation loss: 3.143026066820177

Epoch: 91| Step: 0
Training loss: 2.913313454910072
Validation loss: 3.140959913909305

Epoch: 5| Step: 1
Training loss: 3.115728739672893
Validation loss: 3.1410023289088724

Epoch: 5| Step: 2
Training loss: 3.7143707134665633
Validation loss: 3.1422180174625645

Epoch: 5| Step: 3
Training loss: 3.4440075398981764
Validation loss: 3.1413093547360624

Epoch: 5| Step: 4
Training loss: 3.184982502408673
Validation loss: 3.141472326827361

Epoch: 5| Step: 5
Training loss: 3.502283305204556
Validation loss: 3.1389713749011743

Epoch: 5| Step: 6
Training loss: 3.5137048521503487
Validation loss: 3.143253188928375

Epoch: 5| Step: 7
Training loss: 3.409706252078596
Validation loss: 3.1372832672456745

Epoch: 5| Step: 8
Training loss: 3.3370682454959857
Validation loss: 3.1369661500690116

Epoch: 5| Step: 9
Training loss: 3.5533213914261403
Validation loss: 3.1378064516316497

Epoch: 5| Step: 10
Training loss: 3.6219150965580083
Validation loss: 3.1372365175705483

Epoch: 92| Step: 0
Training loss: 4.181214811122831
Validation loss: 3.137043873121853

Epoch: 5| Step: 1
Training loss: 3.372095341593688
Validation loss: 3.1369946976155623

Epoch: 5| Step: 2
Training loss: 4.035389039524861
Validation loss: 3.1381266339902036

Epoch: 5| Step: 3
Training loss: 3.0219139183402293
Validation loss: 3.136821281894481

Epoch: 5| Step: 4
Training loss: 2.5687403175190084
Validation loss: 3.1343542611695376

Epoch: 5| Step: 5
Training loss: 3.2802827408509034
Validation loss: 3.136627475862944

Epoch: 5| Step: 6
Training loss: 3.870540144335301
Validation loss: 3.134223339419557

Epoch: 5| Step: 7
Training loss: 2.948964574104981
Validation loss: 3.1362214406603766

Epoch: 5| Step: 8
Training loss: 3.4450790083950866
Validation loss: 3.135665869478953

Epoch: 5| Step: 9
Training loss: 3.215479995231108
Validation loss: 3.1365893311240836

Epoch: 5| Step: 10
Training loss: 2.958775357458853
Validation loss: 3.135679251510754

Epoch: 93| Step: 0
Training loss: 2.9851479053755066
Validation loss: 3.1355949988627017

Epoch: 5| Step: 1
Training loss: 3.580659060629995
Validation loss: 3.134730439373095

Epoch: 5| Step: 2
Training loss: 3.874360062456081
Validation loss: 3.1370157460753316

Epoch: 5| Step: 3
Training loss: 3.8282901650434695
Validation loss: 3.135360029354499

Epoch: 5| Step: 4
Training loss: 3.5816389262132655
Validation loss: 3.136413728569399

Epoch: 5| Step: 5
Training loss: 3.0289163946966267
Validation loss: 3.1360303034172134

Epoch: 5| Step: 6
Training loss: 3.1876407667006235
Validation loss: 3.133700194926145

Epoch: 5| Step: 7
Training loss: 3.6854607067132785
Validation loss: 3.1316039490236802

Epoch: 5| Step: 8
Training loss: 3.072629563879872
Validation loss: 3.1315509706107703

Epoch: 5| Step: 9
Training loss: 3.3656789847943793
Validation loss: 3.1314968918373616

Epoch: 5| Step: 10
Training loss: 2.8585562445762305
Validation loss: 3.131555430606589

Epoch: 94| Step: 0
Training loss: 3.528816127069671
Validation loss: 3.132946757936863

Epoch: 5| Step: 1
Training loss: 3.644374243000693
Validation loss: 3.131729498102829

Epoch: 5| Step: 2
Training loss: 3.1836133710572505
Validation loss: 3.132292333947724

Epoch: 5| Step: 3
Training loss: 3.349955424681211
Validation loss: 3.131186097204304

Epoch: 5| Step: 4
Training loss: 2.8976087182148165
Validation loss: 3.131525451584495

Epoch: 5| Step: 5
Training loss: 3.473491280809043
Validation loss: 3.131851771144051

Epoch: 5| Step: 6
Training loss: 3.1545955740924994
Validation loss: 3.129863873555104

Epoch: 5| Step: 7
Training loss: 3.993981243954832
Validation loss: 3.1327232381060686

Epoch: 5| Step: 8
Training loss: 3.5691478340482767
Validation loss: 3.130753193914911

Epoch: 5| Step: 9
Training loss: 2.868140288408023
Validation loss: 3.130391932461677

Epoch: 5| Step: 10
Training loss: 3.4859284500421803
Validation loss: 3.1290699819676417

Epoch: 95| Step: 0
Training loss: 3.5621874488116414
Validation loss: 3.130533096943318

Epoch: 5| Step: 1
Training loss: 3.1878359748447926
Validation loss: 3.1284671557434076

Epoch: 5| Step: 2
Training loss: 3.343971031227757
Validation loss: 3.13086797597533

Epoch: 5| Step: 3
Training loss: 3.2080584982202134
Validation loss: 3.130174021413137

Epoch: 5| Step: 4
Training loss: 3.5071410490180632
Validation loss: 3.1332577682089617

Epoch: 5| Step: 5
Training loss: 3.3326079215040703
Validation loss: 3.1320292935321943

Epoch: 5| Step: 6
Training loss: 3.4933645837662444
Validation loss: 3.1334382912994214

Epoch: 5| Step: 7
Training loss: 3.4950257785266645
Validation loss: 3.13230473024414

Epoch: 5| Step: 8
Training loss: 3.1659225459598033
Validation loss: 3.1287685919774515

Epoch: 5| Step: 9
Training loss: 3.6913986286710347
Validation loss: 3.128652381693803

Epoch: 5| Step: 10
Training loss: 3.226638164972368
Validation loss: 3.129189348944918

Epoch: 96| Step: 0
Training loss: 4.165468933890756
Validation loss: 3.1280508920191643

Epoch: 5| Step: 1
Training loss: 3.199561393004513
Validation loss: 3.127295401284656

Epoch: 5| Step: 2
Training loss: 2.9888867531461147
Validation loss: 3.126410609350251

Epoch: 5| Step: 3
Training loss: 3.6998419392821886
Validation loss: 3.12719717247652

Epoch: 5| Step: 4
Training loss: 3.473259546249078
Validation loss: 3.1275995644224426

Epoch: 5| Step: 5
Training loss: 3.0836007457621903
Validation loss: 3.1300670979644765

Epoch: 5| Step: 6
Training loss: 3.7974496414431718
Validation loss: 3.130135288600769

Epoch: 5| Step: 7
Training loss: 2.9531705338131466
Validation loss: 3.1278307540652177

Epoch: 5| Step: 8
Training loss: 2.6491719805662273
Validation loss: 3.1261151102369538

Epoch: 5| Step: 9
Training loss: 3.3938238989440004
Validation loss: 3.1273104980011253

Epoch: 5| Step: 10
Training loss: 3.6062148490792567
Validation loss: 3.12673377394303

Epoch: 97| Step: 0
Training loss: 3.4462770249417853
Validation loss: 3.1219372907525917

Epoch: 5| Step: 1
Training loss: 3.17364272295017
Validation loss: 3.1254219393800637

Epoch: 5| Step: 2
Training loss: 2.7156054848341786
Validation loss: 3.124276803945053

Epoch: 5| Step: 3
Training loss: 3.7356945563521884
Validation loss: 3.1255529378008413

Epoch: 5| Step: 4
Training loss: 3.4608413304041257
Validation loss: 3.1259660880538873

Epoch: 5| Step: 5
Training loss: 3.3382211770389114
Validation loss: 3.1293979076344964

Epoch: 5| Step: 6
Training loss: 3.2006232191221278
Validation loss: 3.1264758753400432

Epoch: 5| Step: 7
Training loss: 3.7463923584877428
Validation loss: 3.127132041232465

Epoch: 5| Step: 8
Training loss: 3.5444128422406207
Validation loss: 3.1250397792458307

Epoch: 5| Step: 9
Training loss: 3.553024808600039
Validation loss: 3.1247868586219876

Epoch: 5| Step: 10
Training loss: 3.1537885982708174
Validation loss: 3.1265601006794808

Epoch: 98| Step: 0
Training loss: 3.5412783391150504
Validation loss: 3.1259789933012994

Epoch: 5| Step: 1
Training loss: 3.1655295656059033
Validation loss: 3.1247289117522654

Epoch: 5| Step: 2
Training loss: 3.3028744172150346
Validation loss: 3.123324162684069

Epoch: 5| Step: 3
Training loss: 4.070461277796177
Validation loss: 3.122766721381524

Epoch: 5| Step: 4
Training loss: 3.5596855155397447
Validation loss: 3.1241657628418116

Epoch: 5| Step: 5
Training loss: 3.262138294031945
Validation loss: 3.125780792317901

Epoch: 5| Step: 6
Training loss: 3.368675664247895
Validation loss: 3.1205701460539608

Epoch: 5| Step: 7
Training loss: 2.6014931242802644
Validation loss: 3.122263053168511

Epoch: 5| Step: 8
Training loss: 2.8552352872455584
Validation loss: 3.120141672539051

Epoch: 5| Step: 9
Training loss: 3.8796931733402187
Validation loss: 3.122974611448146

Epoch: 5| Step: 10
Training loss: 3.304627762924178
Validation loss: 3.1238811729678093

Epoch: 99| Step: 0
Training loss: 2.7534086603046903
Validation loss: 3.122862434672923

Epoch: 5| Step: 1
Training loss: 3.261108195101207
Validation loss: 3.1252961705460947

Epoch: 5| Step: 2
Training loss: 3.615296497769535
Validation loss: 3.122438510632297

Epoch: 5| Step: 3
Training loss: 3.7864336785200736
Validation loss: 3.1198497753588956

Epoch: 5| Step: 4
Training loss: 3.672974636913607
Validation loss: 3.1202960602528242

Epoch: 5| Step: 5
Training loss: 3.9424674776485973
Validation loss: 3.1194766070404603

Epoch: 5| Step: 6
Training loss: 3.2504933789697334
Validation loss: 3.119940580588939

Epoch: 5| Step: 7
Training loss: 3.53387515634119
Validation loss: 3.123658755020522

Epoch: 5| Step: 8
Training loss: 2.6944339813169096
Validation loss: 3.1225097184451283

Epoch: 5| Step: 9
Training loss: 3.398537399752948
Validation loss: 3.1211732268531405

Epoch: 5| Step: 10
Training loss: 2.966282672533348
Validation loss: 3.122306048121745

Epoch: 100| Step: 0
Training loss: 2.5671450685139336
Validation loss: 3.119485237756475

Epoch: 5| Step: 1
Training loss: 3.756106935337755
Validation loss: 3.122193187980584

Epoch: 5| Step: 2
Training loss: 3.670615381935908
Validation loss: 3.1204846910215713

Epoch: 5| Step: 3
Training loss: 2.9947400074801727
Validation loss: 3.11778535757857

Epoch: 5| Step: 4
Training loss: 3.759741020617545
Validation loss: 3.118651656117846

Epoch: 5| Step: 5
Training loss: 3.136887333236318
Validation loss: 3.11930419810228

Epoch: 5| Step: 6
Training loss: 3.91300100220556
Validation loss: 3.1186791432011285

Epoch: 5| Step: 7
Training loss: 3.527981080599203
Validation loss: 3.1172291553481637

Epoch: 5| Step: 8
Training loss: 3.311828113288087
Validation loss: 3.1177569038477375

Epoch: 5| Step: 9
Training loss: 3.4182718894590747
Validation loss: 3.116805988422424

Epoch: 5| Step: 10
Training loss: 2.7201728167049386
Validation loss: 3.1162438642218326

Epoch: 101| Step: 0
Training loss: 2.7629410818792417
Validation loss: 3.118245085658881

Epoch: 5| Step: 1
Training loss: 3.8309061963400057
Validation loss: 3.116507007176243

Epoch: 5| Step: 2
Training loss: 3.147717717816305
Validation loss: 3.1175560791025236

Epoch: 5| Step: 3
Training loss: 2.884933725055296
Validation loss: 3.118104497830851

Epoch: 5| Step: 4
Training loss: 3.5987850576258666
Validation loss: 3.119648832234678

Epoch: 5| Step: 5
Training loss: 3.3349912494047054
Validation loss: 3.1162962250881345

Epoch: 5| Step: 6
Training loss: 3.3606335079063427
Validation loss: 3.118636887403096

Epoch: 5| Step: 7
Training loss: 4.39108089374419
Validation loss: 3.115606723366086

Epoch: 5| Step: 8
Training loss: 3.6975729482597957
Validation loss: 3.119403224444287

Epoch: 5| Step: 9
Training loss: 2.8370713838693606
Validation loss: 3.11639684090718

Epoch: 5| Step: 10
Training loss: 2.7654881847614052
Validation loss: 3.118851583404179

Epoch: 102| Step: 0
Training loss: 2.7688984437161595
Validation loss: 3.1189514904583113

Epoch: 5| Step: 1
Training loss: 3.6385329624919747
Validation loss: 3.1199291746150783

Epoch: 5| Step: 2
Training loss: 3.1496696238365773
Validation loss: 3.116681883051338

Epoch: 5| Step: 3
Training loss: 3.614174034551514
Validation loss: 3.1185348444089156

Epoch: 5| Step: 4
Training loss: 2.9596348617201875
Validation loss: 3.115341802593719

Epoch: 5| Step: 5
Training loss: 3.4657081807286843
Validation loss: 3.1130329739760296

Epoch: 5| Step: 6
Training loss: 3.3154265233784606
Validation loss: 3.1142223161407214

Epoch: 5| Step: 7
Training loss: 3.209580628995925
Validation loss: 3.1125306233171597

Epoch: 5| Step: 8
Training loss: 3.4236157313881614
Validation loss: 3.1123039099164065

Epoch: 5| Step: 9
Training loss: 3.3441241759100766
Validation loss: 3.109665942234723

Epoch: 5| Step: 10
Training loss: 4.115114562431826
Validation loss: 3.1081330343023237

Epoch: 103| Step: 0
Training loss: 3.187882194793029
Validation loss: 3.1126643435665495

Epoch: 5| Step: 1
Training loss: 3.49045664928594
Validation loss: 3.113119168830213

Epoch: 5| Step: 2
Training loss: 3.6502245951491448
Validation loss: 3.110866568760303

Epoch: 5| Step: 3
Training loss: 3.195728079112402
Validation loss: 3.1109764133564624

Epoch: 5| Step: 4
Training loss: 3.452433659318752
Validation loss: 3.1115867847578964

Epoch: 5| Step: 5
Training loss: 3.6912756518316505
Validation loss: 3.1107886968486564

Epoch: 5| Step: 6
Training loss: 3.981879795630218
Validation loss: 3.1095296122857152

Epoch: 5| Step: 7
Training loss: 2.8187313984259244
Validation loss: 3.110356211145688

Epoch: 5| Step: 8
Training loss: 3.0321274893235
Validation loss: 3.1112473032174712

Epoch: 5| Step: 9
Training loss: 3.1250729361605694
Validation loss: 3.1075914552362667

Epoch: 5| Step: 10
Training loss: 3.247911956242116
Validation loss: 3.1099985616360337

Epoch: 104| Step: 0
Training loss: 3.0468729654941122
Validation loss: 3.110590950477313

Epoch: 5| Step: 1
Training loss: 3.3579740220065286
Validation loss: 3.1091794732517184

Epoch: 5| Step: 2
Training loss: 3.0500649992473585
Validation loss: 3.109159042750065

Epoch: 5| Step: 3
Training loss: 3.693097279254648
Validation loss: 3.1104817911854323

Epoch: 5| Step: 4
Training loss: 3.7651860784620372
Validation loss: 3.1098415539828066

Epoch: 5| Step: 5
Training loss: 3.2199746181838216
Validation loss: 3.113411604813994

Epoch: 5| Step: 6
Training loss: 3.1647645524661683
Validation loss: 3.1129692856881306

Epoch: 5| Step: 7
Training loss: 3.3456600830017402
Validation loss: 3.1120762079491073

Epoch: 5| Step: 8
Training loss: 2.6174976677506194
Validation loss: 3.1108337894993148

Epoch: 5| Step: 9
Training loss: 3.6374878034354428
Validation loss: 3.1097362034576905

Epoch: 5| Step: 10
Training loss: 3.9927070413984316
Validation loss: 3.1087266461743503

Epoch: 105| Step: 0
Training loss: 2.8120960369342227
Validation loss: 3.1071247663580315

Epoch: 5| Step: 1
Training loss: 3.4761850216419004
Validation loss: 3.105836000846617

Epoch: 5| Step: 2
Training loss: 2.8743364978259547
Validation loss: 3.106112300217166

Epoch: 5| Step: 3
Training loss: 2.5382327557995
Validation loss: 3.107001732264726

Epoch: 5| Step: 4
Training loss: 3.5516532272115624
Validation loss: 3.1079482516793098

Epoch: 5| Step: 5
Training loss: 3.746466179593627
Validation loss: 3.105856984778819

Epoch: 5| Step: 6
Training loss: 3.316502438285963
Validation loss: 3.107444479247869

Epoch: 5| Step: 7
Training loss: 3.05807486818326
Validation loss: 3.106212021126803

Epoch: 5| Step: 8
Training loss: 3.2685147144254265
Validation loss: 3.1072909636443056

Epoch: 5| Step: 9
Training loss: 4.19131614680645
Validation loss: 3.1048107966859795

Epoch: 5| Step: 10
Training loss: 3.8749158296365067
Validation loss: 3.104469445319495

Epoch: 106| Step: 0
Training loss: 2.920591184525226
Validation loss: 3.1066675302644335

Epoch: 5| Step: 1
Training loss: 3.9088553323390305
Validation loss: 3.1040435412023157

Epoch: 5| Step: 2
Training loss: 3.5312084094273657
Validation loss: 3.1053223381218555

Epoch: 5| Step: 3
Training loss: 3.2952688924220217
Validation loss: 3.10411999910937

Epoch: 5| Step: 4
Training loss: 2.922958091683373
Validation loss: 3.102706092065149

Epoch: 5| Step: 5
Training loss: 2.941491519659625
Validation loss: 3.105335900448663

Epoch: 5| Step: 6
Training loss: 3.2434741305311507
Validation loss: 3.105541150959548

Epoch: 5| Step: 7
Training loss: 2.810184203521354
Validation loss: 3.103089388386998

Epoch: 5| Step: 8
Training loss: 3.9042541287836303
Validation loss: 3.1033766920185526

Epoch: 5| Step: 9
Training loss: 3.263765088341972
Validation loss: 3.103362900564998

Epoch: 5| Step: 10
Training loss: 4.056281392074452
Validation loss: 3.1044191476787857

Epoch: 107| Step: 0
Training loss: 3.39971801486041
Validation loss: 3.103582791567489

Epoch: 5| Step: 1
Training loss: 3.3651078389135005
Validation loss: 3.1049685739378003

Epoch: 5| Step: 2
Training loss: 3.1825299878741538
Validation loss: 3.1012281235174606

Epoch: 5| Step: 3
Training loss: 3.137090107560913
Validation loss: 3.101895769325646

Epoch: 5| Step: 4
Training loss: 3.1839934864552646
Validation loss: 3.101631980211368

Epoch: 5| Step: 5
Training loss: 3.067884421786364
Validation loss: 3.107440185121677

Epoch: 5| Step: 6
Training loss: 3.9381457813455047
Validation loss: 3.1058029670857166

Epoch: 5| Step: 7
Training loss: 3.405855068445135
Validation loss: 3.1040863805247656

Epoch: 5| Step: 8
Training loss: 3.4729047757139493
Validation loss: 3.103504101664022

Epoch: 5| Step: 9
Training loss: 3.2911942702347834
Validation loss: 3.101474129105546

Epoch: 5| Step: 10
Training loss: 3.4704974472592696
Validation loss: 3.0999274357490965

Epoch: 108| Step: 0
Training loss: 2.925782879776749
Validation loss: 3.0987595460370714

Epoch: 5| Step: 1
Training loss: 3.9853527589743365
Validation loss: 3.100659189984323

Epoch: 5| Step: 2
Training loss: 3.6352461344044693
Validation loss: 3.102920084264629

Epoch: 5| Step: 3
Training loss: 2.770155305054851
Validation loss: 3.1035548205429606

Epoch: 5| Step: 4
Training loss: 3.0688727888414986
Validation loss: 3.1026624008034034

Epoch: 5| Step: 5
Training loss: 3.599086083860469
Validation loss: 3.107605887889147

Epoch: 5| Step: 6
Training loss: 3.3114849910681063
Validation loss: 3.0997929245548588

Epoch: 5| Step: 7
Training loss: 3.2779422618163605
Validation loss: 3.096181038454295

Epoch: 5| Step: 8
Training loss: 3.60184462760049
Validation loss: 3.097689959887011

Epoch: 5| Step: 9
Training loss: 3.1406459522971804
Validation loss: 3.097683347375493

Epoch: 5| Step: 10
Training loss: 3.4659065758231256
Validation loss: 3.0955320205986183

Epoch: 109| Step: 0
Training loss: 3.0005416381164105
Validation loss: 3.0969680046173296

Epoch: 5| Step: 1
Training loss: 4.634687639264356
Validation loss: 3.094782049223687

Epoch: 5| Step: 2
Training loss: 4.103292743307534
Validation loss: 3.0965344479777066

Epoch: 5| Step: 3
Training loss: 2.9318507638294258
Validation loss: 3.0967647248874517

Epoch: 5| Step: 4
Training loss: 3.554068911878792
Validation loss: 3.0970430942371627

Epoch: 5| Step: 5
Training loss: 2.6398223921246844
Validation loss: 3.096379085791585

Epoch: 5| Step: 6
Training loss: 3.220555956215364
Validation loss: 3.097408774166254

Epoch: 5| Step: 7
Training loss: 3.6806110753764236
Validation loss: 3.094887373678759

Epoch: 5| Step: 8
Training loss: 2.765614482622569
Validation loss: 3.0948100332674797

Epoch: 5| Step: 9
Training loss: 2.8779739257394823
Validation loss: 3.0949910743575795

Epoch: 5| Step: 10
Training loss: 2.9175163847815404
Validation loss: 3.0937398630893664

Epoch: 110| Step: 0
Training loss: 3.038875152383273
Validation loss: 3.0948892084667947

Epoch: 5| Step: 1
Training loss: 3.559608624622353
Validation loss: 3.09379540479812

Epoch: 5| Step: 2
Training loss: 3.594323154023143
Validation loss: 3.093605141694004

Epoch: 5| Step: 3
Training loss: 3.1331156824149553
Validation loss: 3.0930796560221863

Epoch: 5| Step: 4
Training loss: 3.407978284354714
Validation loss: 3.09381055891757

Epoch: 5| Step: 5
Training loss: 3.7814325966371736
Validation loss: 3.0929110804425504

Epoch: 5| Step: 6
Training loss: 3.4428227223347294
Validation loss: 3.0917838254165058

Epoch: 5| Step: 7
Training loss: 3.6497379574707995
Validation loss: 3.092082345110946

Epoch: 5| Step: 8
Training loss: 3.4466173810650873
Validation loss: 3.0926729749077326

Epoch: 5| Step: 9
Training loss: 2.3372674428542126
Validation loss: 3.091323276991772

Epoch: 5| Step: 10
Training loss: 3.267803432907654
Validation loss: 3.0926548061453203

Epoch: 111| Step: 0
Training loss: 3.1557619831758554
Validation loss: 3.092953026271221

Epoch: 5| Step: 1
Training loss: 3.406351630418344
Validation loss: 3.099943390196061

Epoch: 5| Step: 2
Training loss: 3.50867354736098
Validation loss: 3.1223889080492415

Epoch: 5| Step: 3
Training loss: 3.6601002301109196
Validation loss: 3.1061154382095597

Epoch: 5| Step: 4
Training loss: 2.795092051701362
Validation loss: 3.091277842517465

Epoch: 5| Step: 5
Training loss: 3.553115664883364
Validation loss: 3.08887827327496

Epoch: 5| Step: 6
Training loss: 3.7284011623423727
Validation loss: 3.0902038648952317

Epoch: 5| Step: 7
Training loss: 2.992271003852767
Validation loss: 3.09245641667267

Epoch: 5| Step: 8
Training loss: 3.4855149119398385
Validation loss: 3.100713074053972

Epoch: 5| Step: 9
Training loss: 2.88803727076777
Validation loss: 3.1032661628857743

Epoch: 5| Step: 10
Training loss: 3.695218558861425
Validation loss: 3.1429551394890938

Epoch: 112| Step: 0
Training loss: 3.7314619250153624
Validation loss: 3.125974308840427

Epoch: 5| Step: 1
Training loss: 2.7233314935622737
Validation loss: 3.094182230899035

Epoch: 5| Step: 2
Training loss: 2.9831204798400637
Validation loss: 3.0878146511053837

Epoch: 5| Step: 3
Training loss: 3.6699117403565493
Validation loss: 3.0896767212449983

Epoch: 5| Step: 4
Training loss: 3.254435666762248
Validation loss: 3.090938871605525

Epoch: 5| Step: 5
Training loss: 3.1410649688909564
Validation loss: 3.0952802022476664

Epoch: 5| Step: 6
Training loss: 3.7732514835102764
Validation loss: 3.102736954359525

Epoch: 5| Step: 7
Training loss: 3.1434412233911027
Validation loss: 3.1066040201123375

Epoch: 5| Step: 8
Training loss: 4.075683330509831
Validation loss: 3.113340875657273

Epoch: 5| Step: 9
Training loss: 3.1525715458470676
Validation loss: 3.099599312666711

Epoch: 5| Step: 10
Training loss: 3.107011212847133
Validation loss: 3.0893600888264885

Epoch: 113| Step: 0
Training loss: 3.2054492984249414
Validation loss: 3.085725611760165

Epoch: 5| Step: 1
Training loss: 3.45421324277858
Validation loss: 3.0877851133612397

Epoch: 5| Step: 2
Training loss: 3.12791535763967
Validation loss: 3.0876122018401775

Epoch: 5| Step: 3
Training loss: 3.740870871307035
Validation loss: 3.0864444979226815

Epoch: 5| Step: 4
Training loss: 3.515616048165686
Validation loss: 3.08637145628185

Epoch: 5| Step: 5
Training loss: 3.3616011939215955
Validation loss: 3.0862331736279676

Epoch: 5| Step: 6
Training loss: 2.6711026687227712
Validation loss: 3.0881741035658616

Epoch: 5| Step: 7
Training loss: 3.5881286442466878
Validation loss: 3.0871117767471086

Epoch: 5| Step: 8
Training loss: 3.0629681599176695
Validation loss: 3.0877538309573116

Epoch: 5| Step: 9
Training loss: 3.6204797909429045
Validation loss: 3.0861173702731417

Epoch: 5| Step: 10
Training loss: 3.3862349396712554
Validation loss: 3.0867899753483377

Epoch: 114| Step: 0
Training loss: 3.3468774448246936
Validation loss: 3.085071677880048

Epoch: 5| Step: 1
Training loss: 3.3982136970578503
Validation loss: 3.084194412876908

Epoch: 5| Step: 2
Training loss: 3.6368621896222177
Validation loss: 3.084874137039001

Epoch: 5| Step: 3
Training loss: 2.923246500370557
Validation loss: 3.0860406108892358

Epoch: 5| Step: 4
Training loss: 3.4235813293468498
Validation loss: 3.0843128243834865

Epoch: 5| Step: 5
Training loss: 3.9500117048259136
Validation loss: 3.0835617189262994

Epoch: 5| Step: 6
Training loss: 3.5734017861153267
Validation loss: 3.084278685683263

Epoch: 5| Step: 7
Training loss: 2.9393384334456227
Validation loss: 3.083582914295712

Epoch: 5| Step: 8
Training loss: 3.421289402571414
Validation loss: 3.0817316510319577

Epoch: 5| Step: 9
Training loss: 3.0107429793929383
Validation loss: 3.0817966279079725

Epoch: 5| Step: 10
Training loss: 2.987025656611338
Validation loss: 3.08236328758632

Epoch: 115| Step: 0
Training loss: 3.067894058348018
Validation loss: 3.0826703422779027

Epoch: 5| Step: 1
Training loss: 3.4960794288725534
Validation loss: 3.084169353188209

Epoch: 5| Step: 2
Training loss: 2.167402313741456
Validation loss: 3.082713575083471

Epoch: 5| Step: 3
Training loss: 3.473382691479902
Validation loss: 3.085588630342737

Epoch: 5| Step: 4
Training loss: 4.0965980930864205
Validation loss: 3.085836289805985

Epoch: 5| Step: 5
Training loss: 2.707493862240246
Validation loss: 3.0810077153560345

Epoch: 5| Step: 6
Training loss: 4.442944692188031
Validation loss: 3.080803325938236

Epoch: 5| Step: 7
Training loss: 3.4218414165642956
Validation loss: 3.0805704636277804

Epoch: 5| Step: 8
Training loss: 3.18795563676281
Validation loss: 3.08298718860555

Epoch: 5| Step: 9
Training loss: 3.460717738904978
Validation loss: 3.08045551680789

Epoch: 5| Step: 10
Training loss: 2.4935308680424173
Validation loss: 3.0806814833272975

Epoch: 116| Step: 0
Training loss: 2.975192177600019
Validation loss: 3.0806836536173643

Epoch: 5| Step: 1
Training loss: 3.6383817252975934
Validation loss: 3.0813223498193176

Epoch: 5| Step: 2
Training loss: 3.600227290501799
Validation loss: 3.0819390799378317

Epoch: 5| Step: 3
Training loss: 2.7310412329316636
Validation loss: 3.0812023290695425

Epoch: 5| Step: 4
Training loss: 3.1581037761700563
Validation loss: 3.0797841820483907

Epoch: 5| Step: 5
Training loss: 3.2542217417674975
Validation loss: 3.0817637274474308

Epoch: 5| Step: 6
Training loss: 3.2923363274029
Validation loss: 3.0765240440481105

Epoch: 5| Step: 7
Training loss: 3.7950416188728484
Validation loss: 3.078600866532728

Epoch: 5| Step: 8
Training loss: 4.189814824494014
Validation loss: 3.0760370534171466

Epoch: 5| Step: 9
Training loss: 2.555907911620751
Validation loss: 3.078656182566727

Epoch: 5| Step: 10
Training loss: 3.2098162473094467
Validation loss: 3.077884410440031

Epoch: 117| Step: 0
Training loss: 3.26919229407131
Validation loss: 3.0768756128804187

Epoch: 5| Step: 1
Training loss: 2.821679457672864
Validation loss: 3.077139446432224

Epoch: 5| Step: 2
Training loss: 3.388498509614281
Validation loss: 3.0781035321806445

Epoch: 5| Step: 3
Training loss: 3.1466369781332832
Validation loss: 3.075576684331486

Epoch: 5| Step: 4
Training loss: 3.7353599877355963
Validation loss: 3.078191667884926

Epoch: 5| Step: 5
Training loss: 3.327907787989524
Validation loss: 3.076044503378084

Epoch: 5| Step: 6
Training loss: 3.562768357191412
Validation loss: 3.0762341637725523

Epoch: 5| Step: 7
Training loss: 3.229850220883442
Validation loss: 3.0741963709449944

Epoch: 5| Step: 8
Training loss: 3.330605598804091
Validation loss: 3.076103601539573

Epoch: 5| Step: 9
Training loss: 3.1378592843962707
Validation loss: 3.0736878948607087

Epoch: 5| Step: 10
Training loss: 3.7674591536101745
Validation loss: 3.0751823091791985

Epoch: 118| Step: 0
Training loss: 2.988017470741519
Validation loss: 3.0764758177710196

Epoch: 5| Step: 1
Training loss: 2.8354453087975666
Validation loss: 3.07664229747308

Epoch: 5| Step: 2
Training loss: 3.9819615852499446
Validation loss: 3.074529806665559

Epoch: 5| Step: 3
Training loss: 4.142184902954439
Validation loss: 3.0779763104572613

Epoch: 5| Step: 4
Training loss: 2.9948817142825432
Validation loss: 3.0805501729405296

Epoch: 5| Step: 5
Training loss: 3.063259419852558
Validation loss: 3.079977421442745

Epoch: 5| Step: 6
Training loss: 3.123117413896161
Validation loss: 3.078225832450972

Epoch: 5| Step: 7
Training loss: 3.210116613296077
Validation loss: 3.0798045810002783

Epoch: 5| Step: 8
Training loss: 3.287411526842048
Validation loss: 3.0761340523468435

Epoch: 5| Step: 9
Training loss: 3.011422821824295
Validation loss: 3.0753361371596117

Epoch: 5| Step: 10
Training loss: 3.87846146076151
Validation loss: 3.074792542501315

Epoch: 119| Step: 0
Training loss: 3.92616821203876
Validation loss: 3.0748441118246754

Epoch: 5| Step: 1
Training loss: 3.526067796588735
Validation loss: 3.0724908671732347

Epoch: 5| Step: 2
Training loss: 2.6150235923738574
Validation loss: 3.0742905743581614

Epoch: 5| Step: 3
Training loss: 2.903624630609714
Validation loss: 3.072545245238535

Epoch: 5| Step: 4
Training loss: 3.506780595802185
Validation loss: 3.0734674715451815

Epoch: 5| Step: 5
Training loss: 3.2386361032391555
Validation loss: 3.0722499323630976

Epoch: 5| Step: 6
Training loss: 3.74793580781729
Validation loss: 3.071955425629327

Epoch: 5| Step: 7
Training loss: 3.3093795473753724
Validation loss: 3.073640864350328

Epoch: 5| Step: 8
Training loss: 2.499665524042403
Validation loss: 3.072834858223383

Epoch: 5| Step: 9
Training loss: 3.763202061848497
Validation loss: 3.0738972718615845

Epoch: 5| Step: 10
Training loss: 3.34400782081383
Validation loss: 3.077175253920102

Epoch: 120| Step: 0
Training loss: 3.8085089884398142
Validation loss: 3.076374029629228

Epoch: 5| Step: 1
Training loss: 2.957252806573578
Validation loss: 3.0733045777758323

Epoch: 5| Step: 2
Training loss: 3.0536678397782233
Validation loss: 3.073810725281132

Epoch: 5| Step: 3
Training loss: 3.12454342367734
Validation loss: 3.0730775374233894

Epoch: 5| Step: 4
Training loss: 3.3234126439350975
Validation loss: 3.0742052138434044

Epoch: 5| Step: 5
Training loss: 3.825808450868179
Validation loss: 3.0717992158993264

Epoch: 5| Step: 6
Training loss: 2.836244172468121
Validation loss: 3.070569759862105

Epoch: 5| Step: 7
Training loss: 3.5734322104604628
Validation loss: 3.0724527355370093

Epoch: 5| Step: 8
Training loss: 3.4043467392719275
Validation loss: 3.070748500765606

Epoch: 5| Step: 9
Training loss: 3.1980741546984484
Validation loss: 3.0716007630557285

Epoch: 5| Step: 10
Training loss: 3.433344184216386
Validation loss: 3.069832263770803

Epoch: 121| Step: 0
Training loss: 3.09081552996273
Validation loss: 3.0663385767693465

Epoch: 5| Step: 1
Training loss: 3.1039596249618895
Validation loss: 3.0663208974101366

Epoch: 5| Step: 2
Training loss: 3.0885363488154227
Validation loss: 3.0668040859612398

Epoch: 5| Step: 3
Training loss: 3.572332632897373
Validation loss: 3.0674323016577874

Epoch: 5| Step: 4
Training loss: 3.100594549692764
Validation loss: 3.066422974113912

Epoch: 5| Step: 5
Training loss: 3.6257131466986676
Validation loss: 3.065115915776509

Epoch: 5| Step: 6
Training loss: 3.4404382805739977
Validation loss: 3.065631630615966

Epoch: 5| Step: 7
Training loss: 3.6784435202361587
Validation loss: 3.0643760538497706

Epoch: 5| Step: 8
Training loss: 3.601519867816415
Validation loss: 3.0663029821775654

Epoch: 5| Step: 9
Training loss: 2.825878536710653
Validation loss: 3.0655049399987853

Epoch: 5| Step: 10
Training loss: 3.423735369803906
Validation loss: 3.0657894523967855

Epoch: 122| Step: 0
Training loss: 3.3131095757203655
Validation loss: 3.065837278159491

Epoch: 5| Step: 1
Training loss: 3.7070668804679268
Validation loss: 3.066646432598055

Epoch: 5| Step: 2
Training loss: 3.1642296264214367
Validation loss: 3.0663646800991735

Epoch: 5| Step: 3
Training loss: 2.8454702016248494
Validation loss: 3.0659143075603206

Epoch: 5| Step: 4
Training loss: 3.7046846734868355
Validation loss: 3.07030353400278

Epoch: 5| Step: 5
Training loss: 3.2414723538277914
Validation loss: 3.070375653678628

Epoch: 5| Step: 6
Training loss: 3.3399688161890424
Validation loss: 3.0657003404929744

Epoch: 5| Step: 7
Training loss: 3.227994661017142
Validation loss: 3.0683329059734907

Epoch: 5| Step: 8
Training loss: 3.6055880410080077
Validation loss: 3.06644248546486

Epoch: 5| Step: 9
Training loss: 3.007891131277392
Validation loss: 3.069699387740178

Epoch: 5| Step: 10
Training loss: 3.4120487236130685
Validation loss: 3.067931368402582

Epoch: 123| Step: 0
Training loss: 3.5817994819631793
Validation loss: 3.0673521962521506

Epoch: 5| Step: 1
Training loss: 3.0564147280744205
Validation loss: 3.064027282787223

Epoch: 5| Step: 2
Training loss: 3.3721028361449212
Validation loss: 3.0654746704566573

Epoch: 5| Step: 3
Training loss: 3.7756312215192103
Validation loss: 3.0623292605411536

Epoch: 5| Step: 4
Training loss: 3.4804358689524255
Validation loss: 3.063791720428826

Epoch: 5| Step: 5
Training loss: 2.4959639394612783
Validation loss: 3.0612735397771114

Epoch: 5| Step: 6
Training loss: 2.833978317748523
Validation loss: 3.063827983468385

Epoch: 5| Step: 7
Training loss: 3.142199676657007
Validation loss: 3.0631777423824214

Epoch: 5| Step: 8
Training loss: 3.584400254736799
Validation loss: 3.0631476230878403

Epoch: 5| Step: 9
Training loss: 3.1688881326697995
Validation loss: 3.063440362248561

Epoch: 5| Step: 10
Training loss: 3.953397477601482
Validation loss: 3.0611794843250633

Epoch: 124| Step: 0
Training loss: 3.7650935007671515
Validation loss: 3.061765926431054

Epoch: 5| Step: 1
Training loss: 2.664335264857719
Validation loss: 3.0591942694749172

Epoch: 5| Step: 2
Training loss: 4.1668044003928015
Validation loss: 3.0641766098857843

Epoch: 5| Step: 3
Training loss: 3.1321478921166572
Validation loss: 3.062653960224773

Epoch: 5| Step: 4
Training loss: 3.3782690252184606
Validation loss: 3.0626449249311367

Epoch: 5| Step: 5
Training loss: 3.4687942639525167
Validation loss: 3.0603044017279655

Epoch: 5| Step: 6
Training loss: 3.3267194618617433
Validation loss: 3.0585961371250248

Epoch: 5| Step: 7
Training loss: 3.522437789075241
Validation loss: 3.059910611876453

Epoch: 5| Step: 8
Training loss: 2.949781028250067
Validation loss: 3.059415912192265

Epoch: 5| Step: 9
Training loss: 2.8631411904587356
Validation loss: 3.0610425627407376

Epoch: 5| Step: 10
Training loss: 2.9981518456786165
Validation loss: 3.060016992492165

Epoch: 125| Step: 0
Training loss: 3.0586490942769795
Validation loss: 3.062075006371419

Epoch: 5| Step: 1
Training loss: 3.870941990592374
Validation loss: 3.05917479234464

Epoch: 5| Step: 2
Training loss: 3.234404485448331
Validation loss: 3.0592855024499017

Epoch: 5| Step: 3
Training loss: 3.375893792375569
Validation loss: 3.058923490040008

Epoch: 5| Step: 4
Training loss: 3.8689895284574596
Validation loss: 3.0575405192239056

Epoch: 5| Step: 5
Training loss: 3.070017870872746
Validation loss: 3.0588960149466726

Epoch: 5| Step: 6
Training loss: 3.747455623839851
Validation loss: 3.059275537933541

Epoch: 5| Step: 7
Training loss: 3.1236169424794595
Validation loss: 3.057035013856638

Epoch: 5| Step: 8
Training loss: 2.344084957347315
Validation loss: 3.0562293349860306

Epoch: 5| Step: 9
Training loss: 3.1230612271988853
Validation loss: 3.057169514532766

Epoch: 5| Step: 10
Training loss: 3.4575001888868124
Validation loss: 3.0560264182340218

Epoch: 126| Step: 0
Training loss: 3.132413995754057
Validation loss: 3.0562690212022647

Epoch: 5| Step: 1
Training loss: 3.7861757588404497
Validation loss: 3.0576640460964777

Epoch: 5| Step: 2
Training loss: 3.0471106804882404
Validation loss: 3.0555952502742767

Epoch: 5| Step: 3
Training loss: 3.2605585101943624
Validation loss: 3.0568154092244155

Epoch: 5| Step: 4
Training loss: 2.7103011294073305
Validation loss: 3.0563753314532915

Epoch: 5| Step: 5
Training loss: 3.7182528379838953
Validation loss: 3.0563284170303833

Epoch: 5| Step: 6
Training loss: 3.290619905038568
Validation loss: 3.0568742090600165

Epoch: 5| Step: 7
Training loss: 3.812784153089036
Validation loss: 3.0558369579359854

Epoch: 5| Step: 8
Training loss: 3.1802361692144783
Validation loss: 3.0555556593441566

Epoch: 5| Step: 9
Training loss: 2.9362332473738184
Validation loss: 3.0640891754596815

Epoch: 5| Step: 10
Training loss: 3.477690987186176
Validation loss: 3.0606424927801017

Epoch: 127| Step: 0
Training loss: 3.9271076447858353
Validation loss: 3.0645681935406643

Epoch: 5| Step: 1
Training loss: 2.8126846252878344
Validation loss: 3.059506468217086

Epoch: 5| Step: 2
Training loss: 3.710627042934632
Validation loss: 3.055684667776114

Epoch: 5| Step: 3
Training loss: 2.7751342740951856
Validation loss: 3.055413563885565

Epoch: 5| Step: 4
Training loss: 2.9238206230072428
Validation loss: 3.05379404010489

Epoch: 5| Step: 5
Training loss: 3.438037344809064
Validation loss: 3.0535200061762544

Epoch: 5| Step: 6
Training loss: 3.126706382266061
Validation loss: 3.052452041332409

Epoch: 5| Step: 7
Training loss: 3.7007213147177866
Validation loss: 3.0533463372364116

Epoch: 5| Step: 8
Training loss: 3.5068483110770985
Validation loss: 3.0555443259810016

Epoch: 5| Step: 9
Training loss: 3.2516272945813163
Validation loss: 3.0560418116504207

Epoch: 5| Step: 10
Training loss: 3.1546046434605666
Validation loss: 3.055487984077631

Epoch: 128| Step: 0
Training loss: 3.6454707955443824
Validation loss: 3.0531339689526007

Epoch: 5| Step: 1
Training loss: 3.8353404029061817
Validation loss: 3.0527549311888094

Epoch: 5| Step: 2
Training loss: 3.393330281474222
Validation loss: 3.0530077446998134

Epoch: 5| Step: 3
Training loss: 2.721022522109366
Validation loss: 3.0524462294769417

Epoch: 5| Step: 4
Training loss: 2.969968686179571
Validation loss: 3.0521924068911863

Epoch: 5| Step: 5
Training loss: 3.3484848581615108
Validation loss: 3.053691490878502

Epoch: 5| Step: 6
Training loss: 3.786619677072994
Validation loss: 3.0547939735489695

Epoch: 5| Step: 7
Training loss: 3.4301270917918956
Validation loss: 3.052983641573508

Epoch: 5| Step: 8
Training loss: 3.1284799654506457
Validation loss: 3.050624080403131

Epoch: 5| Step: 9
Training loss: 3.2158289126441333
Validation loss: 3.0499387538926106

Epoch: 5| Step: 10
Training loss: 2.7703486044866015
Validation loss: 3.049131669115432

Epoch: 129| Step: 0
Training loss: 3.004861389619361
Validation loss: 3.0497431858256623

Epoch: 5| Step: 1
Training loss: 3.473409598886688
Validation loss: 3.0489114363686176

Epoch: 5| Step: 2
Training loss: 2.766529258701543
Validation loss: 3.047638082854551

Epoch: 5| Step: 3
Training loss: 4.0258712962803305
Validation loss: 3.047985242106768

Epoch: 5| Step: 4
Training loss: 3.2818745336639417
Validation loss: 3.048010096318943

Epoch: 5| Step: 5
Training loss: 3.5723483835752656
Validation loss: 3.04711827436781

Epoch: 5| Step: 6
Training loss: 2.918272357552743
Validation loss: 3.0493579945968445

Epoch: 5| Step: 7
Training loss: 3.9549339286985683
Validation loss: 3.048278076617103

Epoch: 5| Step: 8
Training loss: 3.0751273958441767
Validation loss: 3.0469611379491535

Epoch: 5| Step: 9
Training loss: 2.718286058150081
Validation loss: 3.046977366370409

Epoch: 5| Step: 10
Training loss: 3.3922170250309263
Validation loss: 3.047312962660669

Epoch: 130| Step: 0
Training loss: 3.4205969248281147
Validation loss: 3.0463072107607316

Epoch: 5| Step: 1
Training loss: 3.5531501547695488
Validation loss: 3.0456258387634207

Epoch: 5| Step: 2
Training loss: 3.5482887441814768
Validation loss: 3.046964436142139

Epoch: 5| Step: 3
Training loss: 2.607349454752703
Validation loss: 3.0472646913674857

Epoch: 5| Step: 4
Training loss: 3.431138411689464
Validation loss: 3.0453237130430675

Epoch: 5| Step: 5
Training loss: 3.6560601079160766
Validation loss: 3.046726830063631

Epoch: 5| Step: 6
Training loss: 3.126254020850011
Validation loss: 3.0467817807089936

Epoch: 5| Step: 7
Training loss: 3.050148638245859
Validation loss: 3.045025965594739

Epoch: 5| Step: 8
Training loss: 3.073866944013998
Validation loss: 3.0470410811030506

Epoch: 5| Step: 9
Training loss: 3.394871737454823
Validation loss: 3.046108718066605

Epoch: 5| Step: 10
Training loss: 3.48141559090574
Validation loss: 3.046041059311696

Epoch: 131| Step: 0
Training loss: 3.4146581344060962
Validation loss: 3.046896423651569

Epoch: 5| Step: 1
Training loss: 3.713255469523448
Validation loss: 3.0495155035056793

Epoch: 5| Step: 2
Training loss: 2.9997746065028514
Validation loss: 3.0460877467149015

Epoch: 5| Step: 3
Training loss: 2.9383775739391984
Validation loss: 3.044634664032787

Epoch: 5| Step: 4
Training loss: 3.5915669320428583
Validation loss: 3.044537275384474

Epoch: 5| Step: 5
Training loss: 2.432117289814283
Validation loss: 3.04543215547412

Epoch: 5| Step: 6
Training loss: 2.6557015245436335
Validation loss: 3.0464409227907208

Epoch: 5| Step: 7
Training loss: 3.896678336533649
Validation loss: 3.0460657955691888

Epoch: 5| Step: 8
Training loss: 3.239489211568342
Validation loss: 3.0439855892337837

Epoch: 5| Step: 9
Training loss: 3.1966102408426886
Validation loss: 3.041544982750679

Epoch: 5| Step: 10
Training loss: 4.088206024323438
Validation loss: 3.041894715093505

Epoch: 132| Step: 0
Training loss: 3.353514771858511
Validation loss: 3.0424672207018824

Epoch: 5| Step: 1
Training loss: 3.276838261356344
Validation loss: 3.0425358327067853

Epoch: 5| Step: 2
Training loss: 3.650492120253342
Validation loss: 3.040323916566843

Epoch: 5| Step: 3
Training loss: 3.5019687837334663
Validation loss: 3.0426862069667857

Epoch: 5| Step: 4
Training loss: 3.7940491258319353
Validation loss: 3.0421702908761388

Epoch: 5| Step: 5
Training loss: 2.7093237215357213
Validation loss: 3.043018082707684

Epoch: 5| Step: 6
Training loss: 3.5561191903511737
Validation loss: 3.0422498913925975

Epoch: 5| Step: 7
Training loss: 3.154709090470246
Validation loss: 3.0403087774830384

Epoch: 5| Step: 8
Training loss: 3.033205797497615
Validation loss: 3.0417736746563206

Epoch: 5| Step: 9
Training loss: 2.746998622920327
Validation loss: 3.0408700705346776

Epoch: 5| Step: 10
Training loss: 3.455987494710974
Validation loss: 3.0421936976553603

Epoch: 133| Step: 0
Training loss: 3.1554558387486535
Validation loss: 3.0404620283455954

Epoch: 5| Step: 1
Training loss: 3.7703496015029843
Validation loss: 3.039810685387168

Epoch: 5| Step: 2
Training loss: 3.235345077623293
Validation loss: 3.0434563249436843

Epoch: 5| Step: 3
Training loss: 3.322009705246282
Validation loss: 3.040397971689439

Epoch: 5| Step: 4
Training loss: 3.661775896274726
Validation loss: 3.0388047569585783

Epoch: 5| Step: 5
Training loss: 3.2219062811057237
Validation loss: 3.0399168316129797

Epoch: 5| Step: 6
Training loss: 2.3715845948005754
Validation loss: 3.0403688257592765

Epoch: 5| Step: 7
Training loss: 3.8937022590465866
Validation loss: 3.039023537263064

Epoch: 5| Step: 8
Training loss: 3.439558765147263
Validation loss: 3.0381696868840953

Epoch: 5| Step: 9
Training loss: 3.060871391887176
Validation loss: 3.03994466630061

Epoch: 5| Step: 10
Training loss: 2.913509694863813
Validation loss: 3.0432002833690386

Epoch: 134| Step: 0
Training loss: 3.3508893384018714
Validation loss: 3.0388549376136145

Epoch: 5| Step: 1
Training loss: 2.0174880769322936
Validation loss: 3.03754026280864

Epoch: 5| Step: 2
Training loss: 3.622928685319535
Validation loss: 3.0388727565157527

Epoch: 5| Step: 3
Training loss: 2.8252822329892853
Validation loss: 3.0377811326936133

Epoch: 5| Step: 4
Training loss: 3.279254706306451
Validation loss: 3.037037100141502

Epoch: 5| Step: 5
Training loss: 3.769395894995378
Validation loss: 3.0360888353399678

Epoch: 5| Step: 6
Training loss: 3.495613755675765
Validation loss: 3.038137103796075

Epoch: 5| Step: 7
Training loss: 4.0289626618541945
Validation loss: 3.035713793598651

Epoch: 5| Step: 8
Training loss: 2.7411623176853634
Validation loss: 3.0362512011316602

Epoch: 5| Step: 9
Training loss: 3.7609605193374653
Validation loss: 3.0369683554663123

Epoch: 5| Step: 10
Training loss: 2.8918132917037895
Validation loss: 3.0376120083442433

Epoch: 135| Step: 0
Training loss: 3.0900258469966593
Validation loss: 3.0347391963464103

Epoch: 5| Step: 1
Training loss: 3.2662618645774812
Validation loss: 3.0354343260051935

Epoch: 5| Step: 2
Training loss: 4.078397895188685
Validation loss: 3.0357728467673324

Epoch: 5| Step: 3
Training loss: 3.218255458727886
Validation loss: 3.035079808334377

Epoch: 5| Step: 4
Training loss: 2.858108323326149
Validation loss: 3.0338943866780275

Epoch: 5| Step: 5
Training loss: 3.0887625209503624
Validation loss: 3.0366467235383032

Epoch: 5| Step: 6
Training loss: 3.1561227905019136
Validation loss: 3.0353862230671425

Epoch: 5| Step: 7
Training loss: 3.850024304994431
Validation loss: 3.037853962857705

Epoch: 5| Step: 8
Training loss: 3.2960407955367126
Validation loss: 3.0388867486928186

Epoch: 5| Step: 9
Training loss: 2.670658749385658
Validation loss: 3.0439609927220532

Epoch: 5| Step: 10
Training loss: 3.540205545654229
Validation loss: 3.041789600373292

Epoch: 136| Step: 0
Training loss: 3.2564761853875264
Validation loss: 3.0387223394960188

Epoch: 5| Step: 1
Training loss: 3.1906492346311195
Validation loss: 3.0359188246351425

Epoch: 5| Step: 2
Training loss: 3.8779135794726525
Validation loss: 3.0383661568319353

Epoch: 5| Step: 3
Training loss: 2.8821903374087294
Validation loss: 3.0358427348872703

Epoch: 5| Step: 4
Training loss: 3.3803106840103574
Validation loss: 3.033823508943458

Epoch: 5| Step: 5
Training loss: 3.623843962394316
Validation loss: 3.03257259654546

Epoch: 5| Step: 6
Training loss: 3.741658661174635
Validation loss: 3.034327769723772

Epoch: 5| Step: 7
Training loss: 3.1758980629846616
Validation loss: 3.0331609495993357

Epoch: 5| Step: 8
Training loss: 2.7912470279170405
Validation loss: 3.0329739136473908

Epoch: 5| Step: 9
Training loss: 2.7770193261918816
Validation loss: 3.032059908365803

Epoch: 5| Step: 10
Training loss: 3.4613140237217697
Validation loss: 3.030841941587703

Epoch: 137| Step: 0
Training loss: 3.119750840435256
Validation loss: 3.032175085942496

Epoch: 5| Step: 1
Training loss: 3.655746294847338
Validation loss: 3.0325004857750737

Epoch: 5| Step: 2
Training loss: 3.305683680240902
Validation loss: 3.0312960720250537

Epoch: 5| Step: 3
Training loss: 3.023336877060243
Validation loss: 3.032391927511688

Epoch: 5| Step: 4
Training loss: 2.86249909380103
Validation loss: 3.0310766096288875

Epoch: 5| Step: 5
Training loss: 3.2716430989947094
Validation loss: 3.0304275596225723

Epoch: 5| Step: 6
Training loss: 3.584016173011188
Validation loss: 3.030268378357941

Epoch: 5| Step: 7
Training loss: 3.5627066569035026
Validation loss: 3.027719869176218

Epoch: 5| Step: 8
Training loss: 3.1696835920145605
Validation loss: 3.0312636687724646

Epoch: 5| Step: 9
Training loss: 3.4368141183630643
Validation loss: 3.029227718551569

Epoch: 5| Step: 10
Training loss: 3.194528945321222
Validation loss: 3.0318280062115543

Epoch: 138| Step: 0
Training loss: 3.5841743605979843
Validation loss: 3.030646046319519

Epoch: 5| Step: 1
Training loss: 3.1447244336039466
Validation loss: 3.0312123779966225

Epoch: 5| Step: 2
Training loss: 3.216036347084187
Validation loss: 3.028861543133321

Epoch: 5| Step: 3
Training loss: 3.5117626081365128
Validation loss: 3.028339625751216

Epoch: 5| Step: 4
Training loss: 3.5207617637688577
Validation loss: 3.029786827810991

Epoch: 5| Step: 5
Training loss: 3.370910427373442
Validation loss: 3.029430588053588

Epoch: 5| Step: 6
Training loss: 2.6710491130945138
Validation loss: 3.028986958994069

Epoch: 5| Step: 7
Training loss: 3.088750016302389
Validation loss: 3.02765125841849

Epoch: 5| Step: 8
Training loss: 3.4296332769952027
Validation loss: 3.0299949013947245

Epoch: 5| Step: 9
Training loss: 3.794342326597094
Validation loss: 3.028499226679235

Epoch: 5| Step: 10
Training loss: 2.6739333405841843
Validation loss: 3.0282664727969077

Epoch: 139| Step: 0
Training loss: 3.06405304436049
Validation loss: 3.026677219294231

Epoch: 5| Step: 1
Training loss: 3.3114212006851633
Validation loss: 3.028178746519333

Epoch: 5| Step: 2
Training loss: 3.6953527597569042
Validation loss: 3.0264454044671116

Epoch: 5| Step: 3
Training loss: 4.2195827086174384
Validation loss: 3.0265211002616583

Epoch: 5| Step: 4
Training loss: 3.286210733427951
Validation loss: 3.0276998136242415

Epoch: 5| Step: 5
Training loss: 3.6795879763611103
Validation loss: 3.0254367082956026

Epoch: 5| Step: 6
Training loss: 2.7641392396891225
Validation loss: 3.029002950247568

Epoch: 5| Step: 7
Training loss: 2.6814464434884533
Validation loss: 3.0293939166486936

Epoch: 5| Step: 8
Training loss: 3.072531638296823
Validation loss: 3.0286933723715244

Epoch: 5| Step: 9
Training loss: 2.72493750124313
Validation loss: 3.030894180894215

Epoch: 5| Step: 10
Training loss: 3.45951645311241
Validation loss: 3.0276250736438683

Epoch: 140| Step: 0
Training loss: 3.5108602151144157
Validation loss: 3.02488603545892

Epoch: 5| Step: 1
Training loss: 3.816402876509832
Validation loss: 3.0251984664286597

Epoch: 5| Step: 2
Training loss: 2.657958704062887
Validation loss: 3.025382403755763

Epoch: 5| Step: 3
Training loss: 3.61954139923774
Validation loss: 3.0252324752544695

Epoch: 5| Step: 4
Training loss: 3.8159331826012295
Validation loss: 3.026151153620964

Epoch: 5| Step: 5
Training loss: 2.603543738566093
Validation loss: 3.0231541551207917

Epoch: 5| Step: 6
Training loss: 2.7730520920866284
Validation loss: 3.0257716876087613

Epoch: 5| Step: 7
Training loss: 3.5565289433230856
Validation loss: 3.0256821274751555

Epoch: 5| Step: 8
Training loss: 2.981862553458782
Validation loss: 3.0257674309294935

Epoch: 5| Step: 9
Training loss: 3.130842621699562
Validation loss: 3.025633557683132

Epoch: 5| Step: 10
Training loss: 3.47721997162663
Validation loss: 3.0240177556836323

Epoch: 141| Step: 0
Training loss: 2.886662917571537
Validation loss: 3.0257791316994735

Epoch: 5| Step: 1
Training loss: 3.486400340638619
Validation loss: 3.024719383711168

Epoch: 5| Step: 2
Training loss: 3.3776572327966
Validation loss: 3.0241785010780426

Epoch: 5| Step: 3
Training loss: 3.1264199654776244
Validation loss: 3.0254434024493952

Epoch: 5| Step: 4
Training loss: 3.576046802410761
Validation loss: 3.023013280057633

Epoch: 5| Step: 5
Training loss: 2.6476378007135133
Validation loss: 3.022860903517586

Epoch: 5| Step: 6
Training loss: 3.7474756009234538
Validation loss: 3.0221311152788815

Epoch: 5| Step: 7
Training loss: 3.960523956199406
Validation loss: 3.0220159765137615

Epoch: 5| Step: 8
Training loss: 2.4438718994645425
Validation loss: 3.02323764484847

Epoch: 5| Step: 9
Training loss: 3.645607874120664
Validation loss: 3.0209034018758385

Epoch: 5| Step: 10
Training loss: 2.8981622529242395
Validation loss: 3.021095209082556

Epoch: 142| Step: 0
Training loss: 3.6898255854379007
Validation loss: 3.023159363544316

Epoch: 5| Step: 1
Training loss: 3.920485048841339
Validation loss: 3.0208876749539195

Epoch: 5| Step: 2
Training loss: 3.2828087873406093
Validation loss: 3.0204153352337775

Epoch: 5| Step: 3
Training loss: 3.231463757644169
Validation loss: 3.0231976437402848

Epoch: 5| Step: 4
Training loss: 2.9412134925531768
Validation loss: 3.024534390619889

Epoch: 5| Step: 5
Training loss: 3.333778701275348
Validation loss: 3.0237138829637296

Epoch: 5| Step: 6
Training loss: 3.8337299031221246
Validation loss: 3.0224442568225975

Epoch: 5| Step: 7
Training loss: 3.319903180192834
Validation loss: 3.022568624299225

Epoch: 5| Step: 8
Training loss: 2.2281944317586415
Validation loss: 3.027671829108013

Epoch: 5| Step: 9
Training loss: 3.158999312615388
Validation loss: 3.0269443763244617

Epoch: 5| Step: 10
Training loss: 2.8341452239415372
Validation loss: 3.0282438675908065

Epoch: 143| Step: 0
Training loss: 3.34351355171224
Validation loss: 3.0209598643472733

Epoch: 5| Step: 1
Training loss: 3.456728060945654
Validation loss: 3.0205177478915917

Epoch: 5| Step: 2
Training loss: 3.2178087061800102
Validation loss: 3.019859898565035

Epoch: 5| Step: 3
Training loss: 3.7106017272024063
Validation loss: 3.018905170820833

Epoch: 5| Step: 4
Training loss: 3.1545227158895965
Validation loss: 3.0183841801027946

Epoch: 5| Step: 5
Training loss: 2.706405941740906
Validation loss: 3.020135090335592

Epoch: 5| Step: 6
Training loss: 3.1957992518736793
Validation loss: 3.0205236279712726

Epoch: 5| Step: 7
Training loss: 3.2221412940842566
Validation loss: 3.0196845026043353

Epoch: 5| Step: 8
Training loss: 2.787234350983251
Validation loss: 3.0193939077989813

Epoch: 5| Step: 9
Training loss: 4.184333173159602
Validation loss: 3.0204417251032423

Epoch: 5| Step: 10
Training loss: 2.89938297942458
Validation loss: 3.018222318345282

Epoch: 144| Step: 0
Training loss: 3.1039485641425784
Validation loss: 3.01943841169657

Epoch: 5| Step: 1
Training loss: 3.5654074867495615
Validation loss: 3.0183902613858136

Epoch: 5| Step: 2
Training loss: 3.3764501211379128
Validation loss: 3.018616887459213

Epoch: 5| Step: 3
Training loss: 2.5898216557315474
Validation loss: 3.0190232525402356

Epoch: 5| Step: 4
Training loss: 3.611224472679265
Validation loss: 3.021258956803107

Epoch: 5| Step: 5
Training loss: 2.815492013379684
Validation loss: 3.0202731372980227

Epoch: 5| Step: 6
Training loss: 3.3390135686963713
Validation loss: 3.021845108737671

Epoch: 5| Step: 7
Training loss: 2.362989978338002
Validation loss: 3.0171721490157095

Epoch: 5| Step: 8
Training loss: 3.480362022467502
Validation loss: 3.0166601952149286

Epoch: 5| Step: 9
Training loss: 4.192275555311821
Validation loss: 3.015906029503397

Epoch: 5| Step: 10
Training loss: 3.380482917687191
Validation loss: 3.0156456119190627

Epoch: 145| Step: 0
Training loss: 3.5330716725995788
Validation loss: 3.0142624935385167

Epoch: 5| Step: 1
Training loss: 3.2172384323823966
Validation loss: 3.0146499563043037

Epoch: 5| Step: 2
Training loss: 3.490485337621529
Validation loss: 3.0138182649679632

Epoch: 5| Step: 3
Training loss: 3.728957072642346
Validation loss: 3.013693590828753

Epoch: 5| Step: 4
Training loss: 4.084709376779335
Validation loss: 3.0147165499333224

Epoch: 5| Step: 5
Training loss: 2.9253421550723195
Validation loss: 3.014337626926983

Epoch: 5| Step: 6
Training loss: 3.2266479185311083
Validation loss: 3.0137868902117324

Epoch: 5| Step: 7
Training loss: 3.227893471700768
Validation loss: 3.013923868684194

Epoch: 5| Step: 8
Training loss: 2.6642207213370956
Validation loss: 3.013962798647905

Epoch: 5| Step: 9
Training loss: 2.4865108881301023
Validation loss: 3.0143308281642405

Epoch: 5| Step: 10
Training loss: 3.2292869463433767
Validation loss: 3.01104977710532

Epoch: 146| Step: 0
Training loss: 3.3781736075744533
Validation loss: 3.012120234344857

Epoch: 5| Step: 1
Training loss: 3.466284898375219
Validation loss: 3.0119721089148555

Epoch: 5| Step: 2
Training loss: 2.564339605464163
Validation loss: 3.011940023786365

Epoch: 5| Step: 3
Training loss: 3.063764038800837
Validation loss: 3.0108844609217167

Epoch: 5| Step: 4
Training loss: 3.4076235740235763
Validation loss: 3.0133751653683745

Epoch: 5| Step: 5
Training loss: 3.794497526575424
Validation loss: 3.011538426884306

Epoch: 5| Step: 6
Training loss: 3.1363704578290292
Validation loss: 3.011234181953574

Epoch: 5| Step: 7
Training loss: 3.8618751489577825
Validation loss: 3.0129084498823113

Epoch: 5| Step: 8
Training loss: 3.0138637953815723
Validation loss: 3.011790992327162

Epoch: 5| Step: 9
Training loss: 2.9567277518251633
Validation loss: 3.010980955072001

Epoch: 5| Step: 10
Training loss: 3.2751176478097133
Validation loss: 3.0094063507625504

Epoch: 147| Step: 0
Training loss: 4.268635899371865
Validation loss: 3.009683205350453

Epoch: 5| Step: 1
Training loss: 3.3797342509697024
Validation loss: 3.009332674524697

Epoch: 5| Step: 2
Training loss: 3.1036878553630087
Validation loss: 3.011577903548647

Epoch: 5| Step: 3
Training loss: 2.787774908083662
Validation loss: 3.008024311212121

Epoch: 5| Step: 4
Training loss: 3.1689030296196843
Validation loss: 3.0106162278904884

Epoch: 5| Step: 5
Training loss: 3.0475375506596576
Validation loss: 3.0084629360771014

Epoch: 5| Step: 6
Training loss: 3.1033326293693206
Validation loss: 3.007336896166394

Epoch: 5| Step: 7
Training loss: 3.251271219327292
Validation loss: 3.010126433653282

Epoch: 5| Step: 8
Training loss: 3.5644963342843354
Validation loss: 3.007157079261186

Epoch: 5| Step: 9
Training loss: 3.409757575537884
Validation loss: 3.007090754719974

Epoch: 5| Step: 10
Training loss: 2.6268040043932355
Validation loss: 3.007341801229144

Epoch: 148| Step: 0
Training loss: 3.425637184515325
Validation loss: 3.0073007413277533

Epoch: 5| Step: 1
Training loss: 3.2344767236607717
Validation loss: 3.0071395413117026

Epoch: 5| Step: 2
Training loss: 3.3869497886970197
Validation loss: 3.0087751979001003

Epoch: 5| Step: 3
Training loss: 3.6347273179402673
Validation loss: 3.0073560023380748

Epoch: 5| Step: 4
Training loss: 3.4080500614805556
Validation loss: 3.0101125513663947

Epoch: 5| Step: 5
Training loss: 3.087055863161973
Validation loss: 3.0070616099250134

Epoch: 5| Step: 6
Training loss: 3.582775175995691
Validation loss: 3.007330464333198

Epoch: 5| Step: 7
Training loss: 2.911562422436808
Validation loss: 3.0101007028264792

Epoch: 5| Step: 8
Training loss: 3.065814968371067
Validation loss: 3.012402012921113

Epoch: 5| Step: 9
Training loss: 3.2772611077929605
Validation loss: 3.0136494002114507

Epoch: 5| Step: 10
Training loss: 2.9468798931643496
Validation loss: 3.0158708274432025

Epoch: 149| Step: 0
Training loss: 3.138729757215579
Validation loss: 3.010702366937597

Epoch: 5| Step: 1
Training loss: 3.4706314070917417
Validation loss: 3.0073760136914514

Epoch: 5| Step: 2
Training loss: 2.835182783097806
Validation loss: 3.0040264369360097

Epoch: 5| Step: 3
Training loss: 3.36713241213457
Validation loss: 3.0053433802929237

Epoch: 5| Step: 4
Training loss: 3.62930804800979
Validation loss: 3.0041505257768812

Epoch: 5| Step: 5
Training loss: 3.5436764717883804
Validation loss: 3.0065884427760063

Epoch: 5| Step: 6
Training loss: 3.0747428166216926
Validation loss: 3.011032131562474

Epoch: 5| Step: 7
Training loss: 3.1956552634101563
Validation loss: 3.009236072997518

Epoch: 5| Step: 8
Training loss: 3.188104759141586
Validation loss: 3.0064309710295243

Epoch: 5| Step: 9
Training loss: 2.9260776914554243
Validation loss: 3.0036199701505004

Epoch: 5| Step: 10
Training loss: 3.6581267406434064
Validation loss: 3.0016224603019817

Epoch: 150| Step: 0
Training loss: 3.3234208221806205
Validation loss: 3.003052440408393

Epoch: 5| Step: 1
Training loss: 2.970656575798187
Validation loss: 3.003379193603052

Epoch: 5| Step: 2
Training loss: 2.9474112321139385
Validation loss: 3.0047573162693046

Epoch: 5| Step: 3
Training loss: 3.146124584197516
Validation loss: 3.0053680147739517

Epoch: 5| Step: 4
Training loss: 2.932933748367742
Validation loss: 3.004397727271958

Epoch: 5| Step: 5
Training loss: 3.7190693950533067
Validation loss: 3.0058229994011927

Epoch: 5| Step: 6
Training loss: 3.178920044005385
Validation loss: 3.0036502049837024

Epoch: 5| Step: 7
Training loss: 3.374174794226314
Validation loss: 3.003950825039166

Epoch: 5| Step: 8
Training loss: 3.698052646482966
Validation loss: 3.003591996854852

Epoch: 5| Step: 9
Training loss: 3.330535588767133
Validation loss: 3.0042076222626144

Epoch: 5| Step: 10
Training loss: 3.357510497303315
Validation loss: 3.0036016843471347

Epoch: 151| Step: 0
Training loss: 2.8729416486296175
Validation loss: 3.002372157626326

Epoch: 5| Step: 1
Training loss: 2.652837468574747
Validation loss: 3.002298802319704

Epoch: 5| Step: 2
Training loss: 3.163424354532693
Validation loss: 3.0030213356255753

Epoch: 5| Step: 3
Training loss: 3.163292006881562
Validation loss: 3.0022311783900575

Epoch: 5| Step: 4
Training loss: 3.524072424950831
Validation loss: 3.004095945683157

Epoch: 5| Step: 5
Training loss: 2.821084970794937
Validation loss: 3.0030250022095175

Epoch: 5| Step: 6
Training loss: 3.5964922186752606
Validation loss: 3.002358261686029

Epoch: 5| Step: 7
Training loss: 3.3840162148684625
Validation loss: 3.001578989624373

Epoch: 5| Step: 8
Training loss: 3.553388353987007
Validation loss: 3.0008126152969963

Epoch: 5| Step: 9
Training loss: 3.404735823590779
Validation loss: 3.0025650239725454

Epoch: 5| Step: 10
Training loss: 3.7967956283499156
Validation loss: 3.001911885496423

Epoch: 152| Step: 0
Training loss: 2.8558591479234967
Validation loss: 3.0027540786876123

Epoch: 5| Step: 1
Training loss: 4.200272850983026
Validation loss: 3.000886907359137

Epoch: 5| Step: 2
Training loss: 3.1642002405396923
Validation loss: 3.00450511607053

Epoch: 5| Step: 3
Training loss: 3.6172912450953216
Validation loss: 3.0072111366274332

Epoch: 5| Step: 4
Training loss: 3.360794973787446
Validation loss: 2.9995419851648335

Epoch: 5| Step: 5
Training loss: 3.2212422916081795
Validation loss: 2.9946780512348297

Epoch: 5| Step: 6
Training loss: 3.0839789633917847
Validation loss: 2.994412982784096

Epoch: 5| Step: 7
Training loss: 3.3782609797519276
Validation loss: 2.991809601022419

Epoch: 5| Step: 8
Training loss: 2.896201204128422
Validation loss: 2.991243825197779

Epoch: 5| Step: 9
Training loss: 2.68669764052049
Validation loss: 2.988942544156692

Epoch: 5| Step: 10
Training loss: 3.266223177356274
Validation loss: 2.9896617489089574

Epoch: 153| Step: 0
Training loss: 3.805071237626582
Validation loss: 2.9871808343287496

Epoch: 5| Step: 1
Training loss: 3.5731425014705795
Validation loss: 2.98895937749112

Epoch: 5| Step: 2
Training loss: 3.4053172663063425
Validation loss: 2.988249313716807

Epoch: 5| Step: 3
Training loss: 3.1706369172933866
Validation loss: 2.988175459003951

Epoch: 5| Step: 4
Training loss: 2.7867982365913226
Validation loss: 2.990179433723995

Epoch: 5| Step: 5
Training loss: 3.058856431538134
Validation loss: 2.9927817194027773

Epoch: 5| Step: 6
Training loss: 3.185486250908034
Validation loss: 2.9890762604526957

Epoch: 5| Step: 7
Training loss: 2.54375917775141
Validation loss: 2.992065839324425

Epoch: 5| Step: 8
Training loss: 3.7283194376914346
Validation loss: 2.988375256988861

Epoch: 5| Step: 9
Training loss: 3.2801571433873318
Validation loss: 2.988363800956829

Epoch: 5| Step: 10
Training loss: 3.2072581351496168
Validation loss: 2.985971973710621

Epoch: 154| Step: 0
Training loss: 3.2740258027343363
Validation loss: 2.986408031023437

Epoch: 5| Step: 1
Training loss: 3.3541554200041133
Validation loss: 2.9878030880069066

Epoch: 5| Step: 2
Training loss: 3.028709211968297
Validation loss: 2.9873221222033917

Epoch: 5| Step: 3
Training loss: 3.661443949961006
Validation loss: 2.9827480519103915

Epoch: 5| Step: 4
Training loss: 3.2374876220937816
Validation loss: 2.981822877694722

Epoch: 5| Step: 5
Training loss: 3.2137943376637845
Validation loss: 2.984955071395453

Epoch: 5| Step: 6
Training loss: 3.254383212482661
Validation loss: 2.984337579094944

Epoch: 5| Step: 7
Training loss: 3.2042200217167984
Validation loss: 2.984057891032758

Epoch: 5| Step: 8
Training loss: 3.148908480494515
Validation loss: 2.9851207697949933

Epoch: 5| Step: 9
Training loss: 3.09358754357631
Validation loss: 2.985666733478888

Epoch: 5| Step: 10
Training loss: 3.4073488755274393
Validation loss: 2.9855670555115905

Epoch: 155| Step: 0
Training loss: 3.37769549071596
Validation loss: 2.98593621269206

Epoch: 5| Step: 1
Training loss: 3.23690151736278
Validation loss: 2.988760152939437

Epoch: 5| Step: 2
Training loss: 3.267549084832476
Validation loss: 2.9947612536554913

Epoch: 5| Step: 3
Training loss: 3.2260586619994407
Validation loss: 2.9927259494220806

Epoch: 5| Step: 4
Training loss: 3.133619399573253
Validation loss: 2.997314609967933

Epoch: 5| Step: 5
Training loss: 3.2800409905268153
Validation loss: 2.9924192614876

Epoch: 5| Step: 6
Training loss: 3.2895806056263597
Validation loss: 2.990693234079408

Epoch: 5| Step: 7
Training loss: 3.527794016068967
Validation loss: 2.9876278240002248

Epoch: 5| Step: 8
Training loss: 3.6358094681778366
Validation loss: 2.9858395067496724

Epoch: 5| Step: 9
Training loss: 2.7605552974414285
Validation loss: 2.9849564696094553

Epoch: 5| Step: 10
Training loss: 3.0172056492912023
Validation loss: 2.9848548088120497

Epoch: 156| Step: 0
Training loss: 2.625726962471806
Validation loss: 2.985209038322953

Epoch: 5| Step: 1
Training loss: 3.479228097217229
Validation loss: 2.986510015789782

Epoch: 5| Step: 2
Training loss: 3.643681499694481
Validation loss: 2.9855839027256774

Epoch: 5| Step: 3
Training loss: 3.726274203298972
Validation loss: 2.986322079724708

Epoch: 5| Step: 4
Training loss: 2.9466585275989283
Validation loss: 2.982748463605834

Epoch: 5| Step: 5
Training loss: 3.2629446318614206
Validation loss: 2.982475581293555

Epoch: 5| Step: 6
Training loss: 3.083652239279342
Validation loss: 2.9823914920068275

Epoch: 5| Step: 7
Training loss: 3.2434911841479557
Validation loss: 2.983238398497192

Epoch: 5| Step: 8
Training loss: 2.620919825870791
Validation loss: 2.9806608231912586

Epoch: 5| Step: 9
Training loss: 3.794556840194169
Validation loss: 2.977985378213204

Epoch: 5| Step: 10
Training loss: 3.1580340187409934
Validation loss: 2.9763586514798104

Epoch: 157| Step: 0
Training loss: 3.7872561838969676
Validation loss: 2.9773840521524257

Epoch: 5| Step: 1
Training loss: 2.9880409293684473
Validation loss: 2.9781959019689612

Epoch: 5| Step: 2
Training loss: 3.4020373691522554
Validation loss: 2.9780197660911005

Epoch: 5| Step: 3
Training loss: 3.564537937775227
Validation loss: 2.9790881182636637

Epoch: 5| Step: 4
Training loss: 3.061989410810642
Validation loss: 2.977903123236342

Epoch: 5| Step: 5
Training loss: 3.4336423555824513
Validation loss: 2.9787624218824567

Epoch: 5| Step: 6
Training loss: 2.8597997131108475
Validation loss: 2.9792327139225403

Epoch: 5| Step: 7
Training loss: 3.047861731749696
Validation loss: 2.9814861472117866

Epoch: 5| Step: 8
Training loss: 3.1022771593304204
Validation loss: 2.98246594036304

Epoch: 5| Step: 9
Training loss: 3.6863125974476274
Validation loss: 2.9764227857618204

Epoch: 5| Step: 10
Training loss: 2.550928272257261
Validation loss: 2.975800681762366

Epoch: 158| Step: 0
Training loss: 3.3468817189894478
Validation loss: 2.9764671854103137

Epoch: 5| Step: 1
Training loss: 2.630584589166773
Validation loss: 2.975964900783766

Epoch: 5| Step: 2
Training loss: 2.6834499092921282
Validation loss: 2.974693349888417

Epoch: 5| Step: 3
Training loss: 3.105953615351938
Validation loss: 2.974143195332754

Epoch: 5| Step: 4
Training loss: 3.4974275399610257
Validation loss: 2.973499040585029

Epoch: 5| Step: 5
Training loss: 3.930207417185771
Validation loss: 2.9731320667416323

Epoch: 5| Step: 6
Training loss: 2.581684960763668
Validation loss: 2.9733282963854335

Epoch: 5| Step: 7
Training loss: 2.8952429922111467
Validation loss: 2.972059802700558

Epoch: 5| Step: 8
Training loss: 3.1917967913390335
Validation loss: 2.9737513401374844

Epoch: 5| Step: 9
Training loss: 3.5466024823463997
Validation loss: 2.9726022214125787

Epoch: 5| Step: 10
Training loss: 4.126742832875754
Validation loss: 2.973007497253553

Epoch: 159| Step: 0
Training loss: 2.834787014558186
Validation loss: 2.9726943405643373

Epoch: 5| Step: 1
Training loss: 3.584215868715874
Validation loss: 2.9731266434936496

Epoch: 5| Step: 2
Training loss: 2.7873523074312274
Validation loss: 2.97355988797318

Epoch: 5| Step: 3
Training loss: 3.2336258320070583
Validation loss: 2.973710569908177

Epoch: 5| Step: 4
Training loss: 3.3851245617170194
Validation loss: 2.972083154386338

Epoch: 5| Step: 5
Training loss: 2.9198318926875184
Validation loss: 2.974525773514165

Epoch: 5| Step: 6
Training loss: 3.450252391041799
Validation loss: 2.972663587352783

Epoch: 5| Step: 7
Training loss: 3.9055602418362856
Validation loss: 2.971662835650732

Epoch: 5| Step: 8
Training loss: 3.5867735442884894
Validation loss: 2.969335565421306

Epoch: 5| Step: 9
Training loss: 2.884186538705718
Validation loss: 2.971364019083035

Epoch: 5| Step: 10
Training loss: 2.9231792945541932
Validation loss: 2.9703290400314515

Epoch: 160| Step: 0
Training loss: 3.0773704882097155
Validation loss: 2.970392973083123

Epoch: 5| Step: 1
Training loss: 3.562954789963963
Validation loss: 2.9725516036487307

Epoch: 5| Step: 2
Training loss: 3.183243546209951
Validation loss: 2.970000603238909

Epoch: 5| Step: 3
Training loss: 3.3924379907280633
Validation loss: 2.9722338128581884

Epoch: 5| Step: 4
Training loss: 3.8260659421750782
Validation loss: 2.9720292956617644

Epoch: 5| Step: 5
Training loss: 2.848512455408641
Validation loss: 2.969030339163572

Epoch: 5| Step: 6
Training loss: 3.480816585058155
Validation loss: 2.9684317383130225

Epoch: 5| Step: 7
Training loss: 3.14157333100464
Validation loss: 2.9689915850732467

Epoch: 5| Step: 8
Training loss: 3.334361219869238
Validation loss: 2.9691058383326134

Epoch: 5| Step: 9
Training loss: 2.710886402363134
Validation loss: 2.9715481294217594

Epoch: 5| Step: 10
Training loss: 2.9660172583913256
Validation loss: 2.9680937788187776

Epoch: 161| Step: 0
Training loss: 3.3922039521818617
Validation loss: 2.9689687340664594

Epoch: 5| Step: 1
Training loss: 3.4602342153668317
Validation loss: 2.966737008813439

Epoch: 5| Step: 2
Training loss: 3.152798720265506
Validation loss: 2.9681663021404194

Epoch: 5| Step: 3
Training loss: 3.3090583628179115
Validation loss: 2.967533957921395

Epoch: 5| Step: 4
Training loss: 3.4049935079504294
Validation loss: 2.9663962186194093

Epoch: 5| Step: 5
Training loss: 3.39688376501895
Validation loss: 2.967577033189763

Epoch: 5| Step: 6
Training loss: 3.48141559090574
Validation loss: 2.9670128152937996

Epoch: 5| Step: 7
Training loss: 2.1562779742651514
Validation loss: 2.9679026959193586

Epoch: 5| Step: 8
Training loss: 3.2651943671190415
Validation loss: 2.9672674841555535

Epoch: 5| Step: 9
Training loss: 3.37041600067991
Validation loss: 2.9665841769200285

Epoch: 5| Step: 10
Training loss: 3.089987885287835
Validation loss: 2.9671502855563245

Epoch: 162| Step: 0
Training loss: 2.9976695863985325
Validation loss: 2.9659887800549547

Epoch: 5| Step: 1
Training loss: 2.940289086382328
Validation loss: 2.964647249316794

Epoch: 5| Step: 2
Training loss: 2.822338443859455
Validation loss: 2.9641243130670825

Epoch: 5| Step: 3
Training loss: 3.6102005976264726
Validation loss: 2.9656088289624583

Epoch: 5| Step: 4
Training loss: 2.822174894465035
Validation loss: 2.965220716936283

Epoch: 5| Step: 5
Training loss: 3.4005462768618666
Validation loss: 2.9674182247045042

Epoch: 5| Step: 6
Training loss: 3.7815271701585673
Validation loss: 2.9673495190385095

Epoch: 5| Step: 7
Training loss: 3.3904366858437767
Validation loss: 2.966255277080827

Epoch: 5| Step: 8
Training loss: 2.9557497984492387
Validation loss: 2.9668502022424597

Epoch: 5| Step: 9
Training loss: 3.1443780897288724
Validation loss: 2.964991367494707

Epoch: 5| Step: 10
Training loss: 3.709883690833409
Validation loss: 2.9642656050027103

Epoch: 163| Step: 0
Training loss: 3.320387033860129
Validation loss: 2.9699163333801373

Epoch: 5| Step: 1
Training loss: 3.746076693212602
Validation loss: 2.9646945249849943

Epoch: 5| Step: 2
Training loss: 3.116239704799057
Validation loss: 2.9644810257451475

Epoch: 5| Step: 3
Training loss: 2.419637421645603
Validation loss: 2.9632505349598253

Epoch: 5| Step: 4
Training loss: 3.21936532962793
Validation loss: 2.964586105716075

Epoch: 5| Step: 5
Training loss: 3.4411575279462454
Validation loss: 2.961917419043283

Epoch: 5| Step: 6
Training loss: 2.67072597135129
Validation loss: 2.9633393891840853

Epoch: 5| Step: 7
Training loss: 3.150186890401585
Validation loss: 2.9622869617559195

Epoch: 5| Step: 8
Training loss: 3.4722080349102518
Validation loss: 2.9616190388175934

Epoch: 5| Step: 9
Training loss: 3.5784334940959126
Validation loss: 2.963234701903504

Epoch: 5| Step: 10
Training loss: 3.3560185187446057
Validation loss: 2.9606944810296114

Epoch: 164| Step: 0
Training loss: 3.396421759863463
Validation loss: 2.9620227647917634

Epoch: 5| Step: 1
Training loss: 3.11253005170294
Validation loss: 2.960713848364848

Epoch: 5| Step: 2
Training loss: 2.9544327681066305
Validation loss: 2.9623049383336073

Epoch: 5| Step: 3
Training loss: 3.6410836516181626
Validation loss: 2.9616843423026182

Epoch: 5| Step: 4
Training loss: 3.2131353499597
Validation loss: 2.9579137911637847

Epoch: 5| Step: 5
Training loss: 3.315805189753536
Validation loss: 2.959310075445527

Epoch: 5| Step: 6
Training loss: 2.895442762496533
Validation loss: 2.959580344217882

Epoch: 5| Step: 7
Training loss: 3.841968402611484
Validation loss: 2.9611973620476393

Epoch: 5| Step: 8
Training loss: 2.3398588304240655
Validation loss: 2.9586161995724924

Epoch: 5| Step: 9
Training loss: 3.535502346231715
Validation loss: 2.9587265324132512

Epoch: 5| Step: 10
Training loss: 3.1352359216920136
Validation loss: 2.9597716751104683

Epoch: 165| Step: 0
Training loss: 3.3284856036761514
Validation loss: 2.9621641630271425

Epoch: 5| Step: 1
Training loss: 2.87132492691745
Validation loss: 2.9603106851805876

Epoch: 5| Step: 2
Training loss: 3.125339642187441
Validation loss: 2.9621652214870267

Epoch: 5| Step: 3
Training loss: 3.366086704671931
Validation loss: 2.9610281751355356

Epoch: 5| Step: 4
Training loss: 2.648189206707845
Validation loss: 2.9608506378732753

Epoch: 5| Step: 5
Training loss: 3.7544590188752975
Validation loss: 2.9602275095323276

Epoch: 5| Step: 6
Training loss: 3.959089280607818
Validation loss: 2.9628762341297334

Epoch: 5| Step: 7
Training loss: 2.91318038393451
Validation loss: 2.962399622522177

Epoch: 5| Step: 8
Training loss: 2.6873663935607564
Validation loss: 2.9618135721681895

Epoch: 5| Step: 9
Training loss: 3.403908300847873
Validation loss: 2.9620526773021183

Epoch: 5| Step: 10
Training loss: 3.334095502184661
Validation loss: 2.959498303610202

Epoch: 166| Step: 0
Training loss: 2.59922690268437
Validation loss: 2.958845958696202

Epoch: 5| Step: 1
Training loss: 3.7013771020360857
Validation loss: 2.9557207424095626

Epoch: 5| Step: 2
Training loss: 3.7660896995911037
Validation loss: 2.955020313480802

Epoch: 5| Step: 3
Training loss: 2.8748968354664823
Validation loss: 2.95541199176818

Epoch: 5| Step: 4
Training loss: 3.492921892814696
Validation loss: 2.956317206520294

Epoch: 5| Step: 5
Training loss: 3.5797210198926437
Validation loss: 2.9563054883783817

Epoch: 5| Step: 6
Training loss: 3.3414828020789447
Validation loss: 2.9543801365335494

Epoch: 5| Step: 7
Training loss: 3.1668578809595798
Validation loss: 2.954359210853708

Epoch: 5| Step: 8
Training loss: 3.120260535635077
Validation loss: 2.953924342288698

Epoch: 5| Step: 9
Training loss: 2.761600907332668
Validation loss: 2.9554517948218275

Epoch: 5| Step: 10
Training loss: 2.904171764600996
Validation loss: 2.9570627275735886

Epoch: 167| Step: 0
Training loss: 2.706310357880971
Validation loss: 2.9545629225315704

Epoch: 5| Step: 1
Training loss: 3.087442924188175
Validation loss: 2.9530397259502474

Epoch: 5| Step: 2
Training loss: 3.2465818476580073
Validation loss: 2.955558692938585

Epoch: 5| Step: 3
Training loss: 3.019758958607594
Validation loss: 2.956963721376771

Epoch: 5| Step: 4
Training loss: 3.6018402588290988
Validation loss: 2.9604807045783725

Epoch: 5| Step: 5
Training loss: 3.2786210927517114
Validation loss: 2.9559937807198344

Epoch: 5| Step: 6
Training loss: 3.626239827670084
Validation loss: 2.95564620325442

Epoch: 5| Step: 7
Training loss: 3.486985533036376
Validation loss: 2.9536656847630485

Epoch: 5| Step: 8
Training loss: 2.901691265874716
Validation loss: 2.9549068351969967

Epoch: 5| Step: 9
Training loss: 3.5508547062929283
Validation loss: 2.956866671313986

Epoch: 5| Step: 10
Training loss: 2.8697192580451345
Validation loss: 2.9579442409771364

Epoch: 168| Step: 0
Training loss: 3.4230968784683675
Validation loss: 2.9569624313040963

Epoch: 5| Step: 1
Training loss: 3.3247275047215306
Validation loss: 2.9552505221979706

Epoch: 5| Step: 2
Training loss: 3.507357901361392
Validation loss: 2.9582491109789992

Epoch: 5| Step: 3
Training loss: 3.1224315006020786
Validation loss: 2.960630064051165

Epoch: 5| Step: 4
Training loss: 3.514591590737481
Validation loss: 2.9552474061839646

Epoch: 5| Step: 5
Training loss: 2.7795018048844136
Validation loss: 2.95561082819997

Epoch: 5| Step: 6
Training loss: 2.8565915427313713
Validation loss: 2.9538539662371144

Epoch: 5| Step: 7
Training loss: 3.0818038102272904
Validation loss: 2.954003932407084

Epoch: 5| Step: 8
Training loss: 3.242163232919349
Validation loss: 2.957484703469263

Epoch: 5| Step: 9
Training loss: 3.3232279824024205
Validation loss: 2.9548096603135803

Epoch: 5| Step: 10
Training loss: 3.360224416822289
Validation loss: 2.957094724979587

Epoch: 169| Step: 0
Training loss: 2.897391487834679
Validation loss: 2.9581131414827637

Epoch: 5| Step: 1
Training loss: 2.49663832668353
Validation loss: 2.9613510026223406

Epoch: 5| Step: 2
Training loss: 3.355475286937026
Validation loss: 2.9566177172422328

Epoch: 5| Step: 3
Training loss: 3.7859013220758415
Validation loss: 2.9590893079492955

Epoch: 5| Step: 4
Training loss: 3.2400897121960393
Validation loss: 2.9499316733713576

Epoch: 5| Step: 5
Training loss: 3.904125643052893
Validation loss: 2.9517206769346687

Epoch: 5| Step: 6
Training loss: 3.862763558194904
Validation loss: 2.9495015296246807

Epoch: 5| Step: 7
Training loss: 3.1007231145835945
Validation loss: 2.948212920079173

Epoch: 5| Step: 8
Training loss: 2.7360274199344303
Validation loss: 2.948949562375251

Epoch: 5| Step: 9
Training loss: 3.0543412502571585
Validation loss: 2.9486682860843962

Epoch: 5| Step: 10
Training loss: 2.6802115859303393
Validation loss: 2.9518932424240076

Epoch: 170| Step: 0
Training loss: 3.1059215287552977
Validation loss: 2.9502111990251088

Epoch: 5| Step: 1
Training loss: 3.521377536466872
Validation loss: 2.951109396729888

Epoch: 5| Step: 2
Training loss: 3.5844332463288664
Validation loss: 2.95285022136747

Epoch: 5| Step: 3
Training loss: 3.3849596076933226
Validation loss: 2.9601620717148465

Epoch: 5| Step: 4
Training loss: 2.893451360530679
Validation loss: 2.960580395008705

Epoch: 5| Step: 5
Training loss: 2.798748135005982
Validation loss: 2.9556765775495633

Epoch: 5| Step: 6
Training loss: 2.1723320569267854
Validation loss: 2.9559431413388535

Epoch: 5| Step: 7
Training loss: 3.250714296927151
Validation loss: 2.95095619332212

Epoch: 5| Step: 8
Training loss: 3.533796624333851
Validation loss: 2.9496146509189556

Epoch: 5| Step: 9
Training loss: 3.3451488100259845
Validation loss: 2.946542490384466

Epoch: 5| Step: 10
Training loss: 3.7368818352370874
Validation loss: 2.9440780563447944

Epoch: 171| Step: 0
Training loss: 3.0809175633115187
Validation loss: 2.9463139897439614

Epoch: 5| Step: 1
Training loss: 3.783682300981511
Validation loss: 2.9448922046368775

Epoch: 5| Step: 2
Training loss: 3.3368994869084654
Validation loss: 2.9489656277398475

Epoch: 5| Step: 3
Training loss: 3.5348245538880736
Validation loss: 2.953838515028583

Epoch: 5| Step: 4
Training loss: 3.095073994628652
Validation loss: 2.952540743357245

Epoch: 5| Step: 5
Training loss: 2.9372259783261323
Validation loss: 2.9538973477440043

Epoch: 5| Step: 6
Training loss: 3.0969568451537435
Validation loss: 2.9528565470068564

Epoch: 5| Step: 7
Training loss: 3.3528048829130728
Validation loss: 2.9554897532124826

Epoch: 5| Step: 8
Training loss: 2.774330446728151
Validation loss: 2.949142914701402

Epoch: 5| Step: 9
Training loss: 3.682938809792034
Validation loss: 2.948364720040065

Epoch: 5| Step: 10
Training loss: 2.6973579053955383
Validation loss: 2.9491067688116943

Epoch: 172| Step: 0
Training loss: 3.1541532595982362
Validation loss: 2.9479746360446266

Epoch: 5| Step: 1
Training loss: 3.5247460618773965
Validation loss: 2.947143384273936

Epoch: 5| Step: 2
Training loss: 3.442936153443664
Validation loss: 2.9444417781924823

Epoch: 5| Step: 3
Training loss: 3.433922449203825
Validation loss: 2.946391909514646

Epoch: 5| Step: 4
Training loss: 3.3241986678667788
Validation loss: 2.9412074539161988

Epoch: 5| Step: 5
Training loss: 2.498603144457405
Validation loss: 2.9456104937192036

Epoch: 5| Step: 6
Training loss: 3.2898642679524475
Validation loss: 2.9473834681583657

Epoch: 5| Step: 7
Training loss: 3.23205896282233
Validation loss: 2.949345059601038

Epoch: 5| Step: 8
Training loss: 3.318885263103929
Validation loss: 2.954064025396343

Epoch: 5| Step: 9
Training loss: 3.100571942635739
Validation loss: 2.95893501103293

Epoch: 5| Step: 10
Training loss: 3.088667731368553
Validation loss: 2.955734928731365

Epoch: 173| Step: 0
Training loss: 2.9669916667866207
Validation loss: 2.947955253716969

Epoch: 5| Step: 1
Training loss: 2.8861765681425515
Validation loss: 2.94553962572292

Epoch: 5| Step: 2
Training loss: 2.7865839184182497
Validation loss: 2.9423438363819807

Epoch: 5| Step: 3
Training loss: 3.081002221968115
Validation loss: 2.941604994302522

Epoch: 5| Step: 4
Training loss: 2.609315608827757
Validation loss: 2.942246051398923

Epoch: 5| Step: 5
Training loss: 3.5041403123467076
Validation loss: 2.9453241495952156

Epoch: 5| Step: 6
Training loss: 3.2043520182229437
Validation loss: 2.943637286518357

Epoch: 5| Step: 7
Training loss: 3.228101460314706
Validation loss: 2.941644890055148

Epoch: 5| Step: 8
Training loss: 3.364772700756886
Validation loss: 2.9411138281795637

Epoch: 5| Step: 9
Training loss: 4.002359886218814
Validation loss: 2.9398365838337215

Epoch: 5| Step: 10
Training loss: 3.665106325779985
Validation loss: 2.9392943861362064

Epoch: 174| Step: 0
Training loss: 3.4253516803258512
Validation loss: 2.941055666332455

Epoch: 5| Step: 1
Training loss: 3.7139931395862265
Validation loss: 2.9384597749868213

Epoch: 5| Step: 2
Training loss: 3.364011324197803
Validation loss: 2.9390455538008022

Epoch: 5| Step: 3
Training loss: 3.5813574703261932
Validation loss: 2.9376962073014963

Epoch: 5| Step: 4
Training loss: 2.839539817276977
Validation loss: 2.938496616307242

Epoch: 5| Step: 5
Training loss: 2.898595759346003
Validation loss: 2.937680413669457

Epoch: 5| Step: 6
Training loss: 2.719292071442862
Validation loss: 2.93959943653679

Epoch: 5| Step: 7
Training loss: 2.9719978636044697
Validation loss: 2.9377977582051327

Epoch: 5| Step: 8
Training loss: 3.21564178017556
Validation loss: 2.9396201507120208

Epoch: 5| Step: 9
Training loss: 3.2617307377212343
Validation loss: 2.9369554331246284

Epoch: 5| Step: 10
Training loss: 3.3522762081087025
Validation loss: 2.9414386739581886

Epoch: 175| Step: 0
Training loss: 3.5202511338033746
Validation loss: 2.9382194173942855

Epoch: 5| Step: 1
Training loss: 2.958139834097802
Validation loss: 2.942684796749465

Epoch: 5| Step: 2
Training loss: 3.7089464488006296
Validation loss: 2.9455621806707892

Epoch: 5| Step: 3
Training loss: 2.527436008567731
Validation loss: 2.9497039524012894

Epoch: 5| Step: 4
Training loss: 3.2545963943044205
Validation loss: 2.9550290861770536

Epoch: 5| Step: 5
Training loss: 3.434871709168665
Validation loss: 2.9545074367938455

Epoch: 5| Step: 6
Training loss: 2.434385608654877
Validation loss: 2.9482649408972397

Epoch: 5| Step: 7
Training loss: 3.886453498722131
Validation loss: 2.949057883661946

Epoch: 5| Step: 8
Training loss: 3.0631219660493514
Validation loss: 2.9410712500721234

Epoch: 5| Step: 9
Training loss: 3.3557896133150256
Validation loss: 2.9385670434681246

Epoch: 5| Step: 10
Training loss: 2.964981417670085
Validation loss: 2.93521209459028

Epoch: 176| Step: 0
Training loss: 3.4113100597200723
Validation loss: 2.9338021035143504

Epoch: 5| Step: 1
Training loss: 2.6599370163079232
Validation loss: 2.937469231787593

Epoch: 5| Step: 2
Training loss: 3.0624850525783183
Validation loss: 2.935616256864082

Epoch: 5| Step: 3
Training loss: 3.0694080214451476
Validation loss: 2.9360294304705166

Epoch: 5| Step: 4
Training loss: 2.7055801091090688
Validation loss: 2.9343395070385707

Epoch: 5| Step: 5
Training loss: 3.1177139793690696
Validation loss: 2.936132524225699

Epoch: 5| Step: 6
Training loss: 3.451451098680738
Validation loss: 2.934589435541771

Epoch: 5| Step: 7
Training loss: 3.505920307618121
Validation loss: 2.9347420712118346

Epoch: 5| Step: 8
Training loss: 3.5516902821718044
Validation loss: 2.932708032816198

Epoch: 5| Step: 9
Training loss: 3.7340113251263545
Validation loss: 2.933758214263082

Epoch: 5| Step: 10
Training loss: 2.9452388359591968
Validation loss: 2.9341435191266036

Epoch: 177| Step: 0
Training loss: 2.8268462604324363
Validation loss: 2.932743311741106

Epoch: 5| Step: 1
Training loss: 3.2243381619553495
Validation loss: 2.932834132171761

Epoch: 5| Step: 2
Training loss: 3.8492200432959693
Validation loss: 2.9328716656482228

Epoch: 5| Step: 3
Training loss: 3.3096718861201957
Validation loss: 2.93254286886491

Epoch: 5| Step: 4
Training loss: 2.531748498879454
Validation loss: 2.9302303432033447

Epoch: 5| Step: 5
Training loss: 3.0478409238640025
Validation loss: 2.930334307625133

Epoch: 5| Step: 6
Training loss: 3.225128372357987
Validation loss: 2.9322742600141902

Epoch: 5| Step: 7
Training loss: 3.3626596405819065
Validation loss: 2.9309395041229407

Epoch: 5| Step: 8
Training loss: 3.0090118791238587
Validation loss: 2.93298141284418

Epoch: 5| Step: 9
Training loss: 3.2447515804616986
Validation loss: 2.9325652230495773

Epoch: 5| Step: 10
Training loss: 3.638625746151511
Validation loss: 2.932510327315559

Epoch: 178| Step: 0
Training loss: 3.042709555011327
Validation loss: 2.93617341111579

Epoch: 5| Step: 1
Training loss: 3.4097409339558826
Validation loss: 2.9339228318324038

Epoch: 5| Step: 2
Training loss: 2.9474377641910094
Validation loss: 2.933983570288556

Epoch: 5| Step: 3
Training loss: 3.142900392309079
Validation loss: 2.9353849415075013

Epoch: 5| Step: 4
Training loss: 3.4971849837646487
Validation loss: 2.9330505171363837

Epoch: 5| Step: 5
Training loss: 3.1752954841145082
Validation loss: 2.932925538926748

Epoch: 5| Step: 6
Training loss: 3.429617009926594
Validation loss: 2.9333754299681902

Epoch: 5| Step: 7
Training loss: 2.9123559613281134
Validation loss: 2.9352224296206817

Epoch: 5| Step: 8
Training loss: 3.0480178645854474
Validation loss: 2.9323331249688773

Epoch: 5| Step: 9
Training loss: 3.3287201112042073
Validation loss: 2.935133113772792

Epoch: 5| Step: 10
Training loss: 3.4332218250820508
Validation loss: 2.9408546654742476

Epoch: 179| Step: 0
Training loss: 2.853752904448533
Validation loss: 2.9330869666543427

Epoch: 5| Step: 1
Training loss: 3.0466134766068182
Validation loss: 2.9406168034524414

Epoch: 5| Step: 2
Training loss: 3.0026052606762064
Validation loss: 2.938982932885766

Epoch: 5| Step: 3
Training loss: 3.8134566810861386
Validation loss: 2.9353651668789795

Epoch: 5| Step: 4
Training loss: 2.8361219445981773
Validation loss: 2.9291012973399893

Epoch: 5| Step: 5
Training loss: 3.5481570443337036
Validation loss: 2.928338512861251

Epoch: 5| Step: 6
Training loss: 3.157989324859686
Validation loss: 2.9270249402793365

Epoch: 5| Step: 7
Training loss: 3.1220793236204805
Validation loss: 2.9283472114100735

Epoch: 5| Step: 8
Training loss: 3.323227264971639
Validation loss: 2.930331082004015

Epoch: 5| Step: 9
Training loss: 3.4464615962142515
Validation loss: 2.9306763074267064

Epoch: 5| Step: 10
Training loss: 3.0771081474472792
Validation loss: 2.928568033487465

Epoch: 180| Step: 0
Training loss: 2.8250914263489286
Validation loss: 2.9282106089934645

Epoch: 5| Step: 1
Training loss: 3.654971950856511
Validation loss: 2.9275799395955975

Epoch: 5| Step: 2
Training loss: 2.7319090268527897
Validation loss: 2.927748115506924

Epoch: 5| Step: 3
Training loss: 3.35126570518994
Validation loss: 2.9270883626627895

Epoch: 5| Step: 4
Training loss: 3.265750864332082
Validation loss: 2.927218141598256

Epoch: 5| Step: 5
Training loss: 2.7471673421474927
Validation loss: 2.925803136248772

Epoch: 5| Step: 6
Training loss: 3.5156525335293347
Validation loss: 2.927688238928632

Epoch: 5| Step: 7
Training loss: 3.7190888835463802
Validation loss: 2.929120608375963

Epoch: 5| Step: 8
Training loss: 2.7457082377424302
Validation loss: 2.929966444073732

Epoch: 5| Step: 9
Training loss: 3.4753207271407542
Validation loss: 2.9268523012563534

Epoch: 5| Step: 10
Training loss: 3.0675744813863184
Validation loss: 2.926493349254732

Epoch: 181| Step: 0
Training loss: 3.137159114724051
Validation loss: 2.927327650606716

Epoch: 5| Step: 1
Training loss: 3.2785659711633848
Validation loss: 2.9274931595826432

Epoch: 5| Step: 2
Training loss: 3.499255782432
Validation loss: 2.9260226801405116

Epoch: 5| Step: 3
Training loss: 3.253010895676517
Validation loss: 2.9250802750847997

Epoch: 5| Step: 4
Training loss: 3.344959503749795
Validation loss: 2.928735384110942

Epoch: 5| Step: 5
Training loss: 3.127689729907656
Validation loss: 2.9279766947739296

Epoch: 5| Step: 6
Training loss: 3.095062902054784
Validation loss: 2.928065018919375

Epoch: 5| Step: 7
Training loss: 3.4497884104984573
Validation loss: 2.9270539150716477

Epoch: 5| Step: 8
Training loss: 3.0398853433469823
Validation loss: 2.927612018423439

Epoch: 5| Step: 9
Training loss: 2.720337152341987
Validation loss: 2.924043855172228

Epoch: 5| Step: 10
Training loss: 3.311056002286999
Validation loss: 2.9249796735984406

Epoch: 182| Step: 0
Training loss: 3.1403898084646893
Validation loss: 2.9261042575164344

Epoch: 5| Step: 1
Training loss: 3.2524649735601825
Validation loss: 2.921292503842776

Epoch: 5| Step: 2
Training loss: 3.3439487861654027
Validation loss: 2.9262129251066082

Epoch: 5| Step: 3
Training loss: 3.3387803554261826
Validation loss: 2.9292584881338493

Epoch: 5| Step: 4
Training loss: 3.2152554699147013
Validation loss: 2.925162412476204

Epoch: 5| Step: 5
Training loss: 2.7074016631382873
Validation loss: 2.9225831602965364

Epoch: 5| Step: 6
Training loss: 3.5052702597390453
Validation loss: 2.922522632279625

Epoch: 5| Step: 7
Training loss: 2.757238398547681
Validation loss: 2.9267136660734354

Epoch: 5| Step: 8
Training loss: 3.731990036667979
Validation loss: 2.9243708145315765

Epoch: 5| Step: 9
Training loss: 2.9758969661760633
Validation loss: 2.9272623916409417

Epoch: 5| Step: 10
Training loss: 3.1974937996047377
Validation loss: 2.920777004059751

Epoch: 183| Step: 0
Training loss: 3.7725643308702104
Validation loss: 2.9226100019769627

Epoch: 5| Step: 1
Training loss: 3.380342705186028
Validation loss: 2.920616508408992

Epoch: 5| Step: 2
Training loss: 2.982950080108603
Validation loss: 2.919667930314198

Epoch: 5| Step: 3
Training loss: 3.092362834630014
Validation loss: 2.9196989080705618

Epoch: 5| Step: 4
Training loss: 3.4155534155657
Validation loss: 2.919997826532018

Epoch: 5| Step: 5
Training loss: 2.479249862001582
Validation loss: 2.9199321789857575

Epoch: 5| Step: 6
Training loss: 3.4224142407413938
Validation loss: 2.9194037367567347

Epoch: 5| Step: 7
Training loss: 3.0857590249516895
Validation loss: 2.9181312721909696

Epoch: 5| Step: 8
Training loss: 3.700173791463873
Validation loss: 2.919243802291098

Epoch: 5| Step: 9
Training loss: 2.9204620372027073
Validation loss: 2.918732663510421

Epoch: 5| Step: 10
Training loss: 2.707891858627977
Validation loss: 2.9192643394894526

Epoch: 184| Step: 0
Training loss: 2.943839030934142
Validation loss: 2.917450140103219

Epoch: 5| Step: 1
Training loss: 3.5074843357250285
Validation loss: 2.9168536277184938

Epoch: 5| Step: 2
Training loss: 2.6902484590447817
Validation loss: 2.9165704321623336

Epoch: 5| Step: 3
Training loss: 2.9575560896416597
Validation loss: 2.9180564616246776

Epoch: 5| Step: 4
Training loss: 3.072026907346029
Validation loss: 2.9184891861967093

Epoch: 5| Step: 5
Training loss: 3.2416076877069773
Validation loss: 2.9224881405211987

Epoch: 5| Step: 6
Training loss: 3.193543781707267
Validation loss: 2.9218714132040726

Epoch: 5| Step: 7
Training loss: 3.657647803052103
Validation loss: 2.921031149849472

Epoch: 5| Step: 8
Training loss: 3.3695929270671
Validation loss: 2.9177303138544586

Epoch: 5| Step: 9
Training loss: 2.8184894788165713
Validation loss: 2.916059499966222

Epoch: 5| Step: 10
Training loss: 3.731985181396764
Validation loss: 2.9149166118904595

Epoch: 185| Step: 0
Training loss: 2.4045226597692926
Validation loss: 2.916135592534473

Epoch: 5| Step: 1
Training loss: 2.9386255258852354
Validation loss: 2.9166238040382164

Epoch: 5| Step: 2
Training loss: 4.0955755225711545
Validation loss: 2.9178190026382262

Epoch: 5| Step: 3
Training loss: 3.0600828635770645
Validation loss: 2.9192304959782067

Epoch: 5| Step: 4
Training loss: 3.2784923773079613
Validation loss: 2.919039690550833

Epoch: 5| Step: 5
Training loss: 2.7100421405345156
Validation loss: 2.9225244015941

Epoch: 5| Step: 6
Training loss: 3.247949393455996
Validation loss: 2.918907181883203

Epoch: 5| Step: 7
Training loss: 3.386944298015018
Validation loss: 2.917449241165911

Epoch: 5| Step: 8
Training loss: 3.3659549590353826
Validation loss: 2.918109153575021

Epoch: 5| Step: 9
Training loss: 3.3456629334823225
Validation loss: 2.916133445716351

Epoch: 5| Step: 10
Training loss: 3.2017677967383826
Validation loss: 2.917128316906164

Epoch: 186| Step: 0
Training loss: 3.2498560653505266
Validation loss: 2.9149448469075496

Epoch: 5| Step: 1
Training loss: 2.9730405621730376
Validation loss: 2.9169959525527287

Epoch: 5| Step: 2
Training loss: 3.2193046017953355
Validation loss: 2.92026789554065

Epoch: 5| Step: 3
Training loss: 3.037083940307484
Validation loss: 2.9173841751195266

Epoch: 5| Step: 4
Training loss: 3.6272190799687514
Validation loss: 2.9155272026213863

Epoch: 5| Step: 5
Training loss: 3.6562573033447356
Validation loss: 2.917204240987236

Epoch: 5| Step: 6
Training loss: 2.4588429089879495
Validation loss: 2.915587895208741

Epoch: 5| Step: 7
Training loss: 3.2563072038483964
Validation loss: 2.915080783464564

Epoch: 5| Step: 8
Training loss: 2.602579187366577
Validation loss: 2.912248113849244

Epoch: 5| Step: 9
Training loss: 3.169138963892391
Validation loss: 2.9119892433549976

Epoch: 5| Step: 10
Training loss: 3.830347529249039
Validation loss: 2.9114977716368

Epoch: 187| Step: 0
Training loss: 3.494841043243813
Validation loss: 2.91228563270733

Epoch: 5| Step: 1
Training loss: 3.1773026354202303
Validation loss: 2.9181860632963748

Epoch: 5| Step: 2
Training loss: 2.7545482130749313
Validation loss: 2.9249822206029585

Epoch: 5| Step: 3
Training loss: 3.076442665412729
Validation loss: 2.9275185305982525

Epoch: 5| Step: 4
Training loss: 2.9601900068076388
Validation loss: 2.92688690099812

Epoch: 5| Step: 5
Training loss: 3.3958240501105297
Validation loss: 2.9200580012749784

Epoch: 5| Step: 6
Training loss: 3.5168896922280353
Validation loss: 2.912588554626453

Epoch: 5| Step: 7
Training loss: 3.5690321348137926
Validation loss: 2.910735014685931

Epoch: 5| Step: 8
Training loss: 2.91973227201094
Validation loss: 2.9083131648836216

Epoch: 5| Step: 9
Training loss: 3.5959261732320034
Validation loss: 2.909539811119738

Epoch: 5| Step: 10
Training loss: 2.4608872181433146
Validation loss: 2.90988296598773

Epoch: 188| Step: 0
Training loss: 2.831211997612903
Validation loss: 2.9125255602783997

Epoch: 5| Step: 1
Training loss: 3.17250843957811
Validation loss: 2.912837649212204

Epoch: 5| Step: 2
Training loss: 3.0333274722479344
Validation loss: 2.914879461987076

Epoch: 5| Step: 3
Training loss: 3.300776049367205
Validation loss: 2.916825597508401

Epoch: 5| Step: 4
Training loss: 3.9637107996835277
Validation loss: 2.913802157743202

Epoch: 5| Step: 5
Training loss: 3.0512687108061187
Validation loss: 2.9126479089698156

Epoch: 5| Step: 6
Training loss: 2.5819016970914292
Validation loss: 2.9131025737837315

Epoch: 5| Step: 7
Training loss: 3.6916352700533746
Validation loss: 2.913896039007611

Epoch: 5| Step: 8
Training loss: 3.5348789169531014
Validation loss: 2.9129454475817558

Epoch: 5| Step: 9
Training loss: 2.4866537523658723
Validation loss: 2.9087716378048007

Epoch: 5| Step: 10
Training loss: 3.269389342005124
Validation loss: 2.9099099160076465

Epoch: 189| Step: 0
Training loss: 3.184532130204634
Validation loss: 2.907759000459911

Epoch: 5| Step: 1
Training loss: 2.515115627110773
Validation loss: 2.9087818596632173

Epoch: 5| Step: 2
Training loss: 2.469694415660445
Validation loss: 2.906459361957375

Epoch: 5| Step: 3
Training loss: 3.157530118990402
Validation loss: 2.909519170915859

Epoch: 5| Step: 4
Training loss: 3.5575019174813245
Validation loss: 2.907584748445752

Epoch: 5| Step: 5
Training loss: 3.189245157650654
Validation loss: 2.906783540240578

Epoch: 5| Step: 6
Training loss: 3.2863257976393605
Validation loss: 2.9071933213515018

Epoch: 5| Step: 7
Training loss: 3.297573214535897
Validation loss: 2.9090661685790358

Epoch: 5| Step: 8
Training loss: 3.241657259681474
Validation loss: 2.9067010651871397

Epoch: 5| Step: 9
Training loss: 3.9501447337228544
Validation loss: 2.908559165197811

Epoch: 5| Step: 10
Training loss: 3.052015457874114
Validation loss: 2.9071361510838627

Epoch: 190| Step: 0
Training loss: 3.149612548251223
Validation loss: 2.9078129590164443

Epoch: 5| Step: 1
Training loss: 3.0010812718166813
Validation loss: 2.905372641567212

Epoch: 5| Step: 2
Training loss: 3.4223632464175524
Validation loss: 2.906736626242718

Epoch: 5| Step: 3
Training loss: 3.709591269997531
Validation loss: 2.908049115766891

Epoch: 5| Step: 4
Training loss: 3.251376960736498
Validation loss: 2.9100216356708013

Epoch: 5| Step: 5
Training loss: 3.3539174305187216
Validation loss: 2.9087682948491724

Epoch: 5| Step: 6
Training loss: 2.999208981815299
Validation loss: 2.911414744182018

Epoch: 5| Step: 7
Training loss: 2.9662233542922603
Validation loss: 2.9133111625764156

Epoch: 5| Step: 8
Training loss: 3.4546864289170376
Validation loss: 2.915678833243797

Epoch: 5| Step: 9
Training loss: 2.5841155764948103
Validation loss: 2.916472146950069

Epoch: 5| Step: 10
Training loss: 3.15011287063135
Validation loss: 2.917409145468362

Epoch: 191| Step: 0
Training loss: 2.590032003934042
Validation loss: 2.913725955845083

Epoch: 5| Step: 1
Training loss: 2.4646058851958546
Validation loss: 2.9085864888594233

Epoch: 5| Step: 2
Training loss: 3.4971421699630105
Validation loss: 2.9058052637454916

Epoch: 5| Step: 3
Training loss: 3.7444427002230793
Validation loss: 2.906053763830281

Epoch: 5| Step: 4
Training loss: 2.6443877188246625
Validation loss: 2.9048439106137924

Epoch: 5| Step: 5
Training loss: 3.706071671156737
Validation loss: 2.904443628246952

Epoch: 5| Step: 6
Training loss: 2.6429434986808245
Validation loss: 2.9033266206667996

Epoch: 5| Step: 7
Training loss: 3.2899484777619428
Validation loss: 2.9048449299471906

Epoch: 5| Step: 8
Training loss: 3.6371396125468194
Validation loss: 2.904281752439324

Epoch: 5| Step: 9
Training loss: 3.3929730560465137
Validation loss: 2.903461887988118

Epoch: 5| Step: 10
Training loss: 3.1411290309943443
Validation loss: 2.9062717933997644

Epoch: 192| Step: 0
Training loss: 3.1196837409217593
Validation loss: 2.906638782901277

Epoch: 5| Step: 1
Training loss: 2.9282237554321973
Validation loss: 2.9081531264912166

Epoch: 5| Step: 2
Training loss: 3.44142647952695
Validation loss: 2.9134869172972873

Epoch: 5| Step: 3
Training loss: 3.4222880075029964
Validation loss: 2.9076175160559723

Epoch: 5| Step: 4
Training loss: 2.786070514441081
Validation loss: 2.9140115973365495

Epoch: 5| Step: 5
Training loss: 2.9528408014703613
Validation loss: 2.904405113938712

Epoch: 5| Step: 6
Training loss: 3.267044270028966
Validation loss: 2.907990501538038

Epoch: 5| Step: 7
Training loss: 2.9922472596737224
Validation loss: 2.9056125258851964

Epoch: 5| Step: 8
Training loss: 3.547317678915849
Validation loss: 2.9037208591949204

Epoch: 5| Step: 9
Training loss: 2.957781314836593
Validation loss: 2.904391907351858

Epoch: 5| Step: 10
Training loss: 3.652123364005927
Validation loss: 2.9046571353391255

Epoch: 193| Step: 0
Training loss: 3.3691520889750612
Validation loss: 2.9078680776682

Epoch: 5| Step: 1
Training loss: 2.8890800677725235
Validation loss: 2.9061527965890206

Epoch: 5| Step: 2
Training loss: 3.907131492337196
Validation loss: 2.901331675501334

Epoch: 5| Step: 3
Training loss: 3.3472246316889684
Validation loss: 2.9073401100422136

Epoch: 5| Step: 4
Training loss: 2.9003214098959247
Validation loss: 2.904315551236108

Epoch: 5| Step: 5
Training loss: 2.8624859338939506
Validation loss: 2.9043035182386863

Epoch: 5| Step: 6
Training loss: 2.9786015932778005
Validation loss: 2.9033689443676254

Epoch: 5| Step: 7
Training loss: 2.765222035162377
Validation loss: 2.9035303236433196

Epoch: 5| Step: 8
Training loss: 3.1050495368581115
Validation loss: 2.9043674906313846

Epoch: 5| Step: 9
Training loss: 3.1638442729527783
Validation loss: 2.9045178361838127

Epoch: 5| Step: 10
Training loss: 3.700969857613392
Validation loss: 2.9006254928963227

Epoch: 194| Step: 0
Training loss: 3.5361988869482723
Validation loss: 2.905787623144884

Epoch: 5| Step: 1
Training loss: 3.3117021283531036
Validation loss: 2.9020042461012165

Epoch: 5| Step: 2
Training loss: 3.413517330122892
Validation loss: 2.903868374306366

Epoch: 5| Step: 3
Training loss: 3.675594831841356
Validation loss: 2.900068418553569

Epoch: 5| Step: 4
Training loss: 2.4959032824802336
Validation loss: 2.901338447467141

Epoch: 5| Step: 5
Training loss: 3.1580486649090895
Validation loss: 2.9015584208437004

Epoch: 5| Step: 6
Training loss: 3.142890378850602
Validation loss: 2.9002999253529125

Epoch: 5| Step: 7
Training loss: 2.697160966018033
Validation loss: 2.9021371140094154

Epoch: 5| Step: 8
Training loss: 3.3127855861561204
Validation loss: 2.9027650553541005

Epoch: 5| Step: 9
Training loss: 2.705554465759949
Validation loss: 2.90045838536337

Epoch: 5| Step: 10
Training loss: 3.4566148065289735
Validation loss: 2.9072261048371497

Epoch: 195| Step: 0
Training loss: 3.248041883546225
Validation loss: 2.907823882500266

Epoch: 5| Step: 1
Training loss: 3.627656423717665
Validation loss: 2.905437801899614

Epoch: 5| Step: 2
Training loss: 2.9213592563711086
Validation loss: 2.903964036880488

Epoch: 5| Step: 3
Training loss: 3.378464792332065
Validation loss: 2.9069075884108737

Epoch: 5| Step: 4
Training loss: 2.512355029730105
Validation loss: 2.902270422796027

Epoch: 5| Step: 5
Training loss: 3.4177444122806757
Validation loss: 2.9006720399651273

Epoch: 5| Step: 6
Training loss: 2.8591218429812844
Validation loss: 2.898358905755868

Epoch: 5| Step: 7
Training loss: 3.612172153472312
Validation loss: 2.8981684210561682

Epoch: 5| Step: 8
Training loss: 3.0839594815235816
Validation loss: 2.8980347634636066

Epoch: 5| Step: 9
Training loss: 2.9433480346704233
Validation loss: 2.898732547498843

Epoch: 5| Step: 10
Training loss: 3.3117657693421387
Validation loss: 2.895950604201706

Epoch: 196| Step: 0
Training loss: 2.814472778166982
Validation loss: 2.8977075459234336

Epoch: 5| Step: 1
Training loss: 3.7035116645688007
Validation loss: 2.895999703298438

Epoch: 5| Step: 2
Training loss: 3.3200748134134868
Validation loss: 2.8961116656717154

Epoch: 5| Step: 3
Training loss: 2.7438450338463327
Validation loss: 2.8965567166816926

Epoch: 5| Step: 4
Training loss: 3.5771628339698016
Validation loss: 2.89548056286221

Epoch: 5| Step: 5
Training loss: 3.501524184637397
Validation loss: 2.8957418635516077

Epoch: 5| Step: 6
Training loss: 2.7193664202755334
Validation loss: 2.898279389460225

Epoch: 5| Step: 7
Training loss: 3.3681210243879773
Validation loss: 2.9050253851536154

Epoch: 5| Step: 8
Training loss: 2.888334779498719
Validation loss: 2.899912996015987

Epoch: 5| Step: 9
Training loss: 2.748847459814808
Validation loss: 2.896838712063978

Epoch: 5| Step: 10
Training loss: 3.4999449589352363
Validation loss: 2.897080433918199

Epoch: 197| Step: 0
Training loss: 3.6757820283440994
Validation loss: 2.893460026628145

Epoch: 5| Step: 1
Training loss: 3.3071176237834456
Validation loss: 2.8932854690021568

Epoch: 5| Step: 2
Training loss: 3.229664196120418
Validation loss: 2.8943003872029727

Epoch: 5| Step: 3
Training loss: 2.7985943672009537
Validation loss: 2.895492506800389

Epoch: 5| Step: 4
Training loss: 3.7045707616670303
Validation loss: 2.8961620933572148

Epoch: 5| Step: 5
Training loss: 3.396757144515327
Validation loss: 2.894013847265277

Epoch: 5| Step: 6
Training loss: 2.6252204257515137
Validation loss: 2.8928385614939693

Epoch: 5| Step: 7
Training loss: 2.449296137851104
Validation loss: 2.8921407098664327

Epoch: 5| Step: 8
Training loss: 3.927283945533194
Validation loss: 2.8913393175132707

Epoch: 5| Step: 9
Training loss: 3.002464871292373
Validation loss: 2.891944934657105

Epoch: 5| Step: 10
Training loss: 2.33737791425961
Validation loss: 2.895336638517576

Epoch: 198| Step: 0
Training loss: 2.956905629401128
Validation loss: 2.8913528816363785

Epoch: 5| Step: 1
Training loss: 3.7113952996811865
Validation loss: 2.893085482407986

Epoch: 5| Step: 2
Training loss: 3.6864663954610086
Validation loss: 2.8928357043758433

Epoch: 5| Step: 3
Training loss: 2.722374878277192
Validation loss: 2.8899221304640146

Epoch: 5| Step: 4
Training loss: 2.8697533209720274
Validation loss: 2.897365961841802

Epoch: 5| Step: 5
Training loss: 3.468512449636191
Validation loss: 2.8912267198896844

Epoch: 5| Step: 6
Training loss: 3.0344243683025356
Validation loss: 2.890967950761301

Epoch: 5| Step: 7
Training loss: 2.980318038149705
Validation loss: 2.8910639621645817

Epoch: 5| Step: 8
Training loss: 3.2985274526238055
Validation loss: 2.890158069061893

Epoch: 5| Step: 9
Training loss: 3.044712962385031
Validation loss: 2.886968817504579

Epoch: 5| Step: 10
Training loss: 3.045808889253552
Validation loss: 2.885442805095014

Epoch: 199| Step: 0
Training loss: 2.7623632129618123
Validation loss: 2.8865702625576564

Epoch: 5| Step: 1
Training loss: 2.6021919290947673
Validation loss: 2.887452098241529

Epoch: 5| Step: 2
Training loss: 3.709791404021598
Validation loss: 2.8854379700159742

Epoch: 5| Step: 3
Training loss: 2.2531026005788886
Validation loss: 2.8876817702589674

Epoch: 5| Step: 4
Training loss: 2.8201774078730297
Validation loss: 2.8880808535426414

Epoch: 5| Step: 5
Training loss: 3.0690480508979823
Validation loss: 2.8877069157725623

Epoch: 5| Step: 6
Training loss: 3.3261740253864893
Validation loss: 2.88831644993695

Epoch: 5| Step: 7
Training loss: 3.057399628708034
Validation loss: 2.886947167879316

Epoch: 5| Step: 8
Training loss: 3.0949183868346175
Validation loss: 2.8846373737160755

Epoch: 5| Step: 9
Training loss: 4.380633841162919
Validation loss: 2.8872426845673975

Epoch: 5| Step: 10
Training loss: 3.414601578042097
Validation loss: 2.8870451750939057

Epoch: 200| Step: 0
Training loss: 3.356585528830379
Validation loss: 2.8858614271857554

Epoch: 5| Step: 1
Training loss: 3.1409684178496144
Validation loss: 2.889952014826047

Epoch: 5| Step: 2
Training loss: 3.371965244842651
Validation loss: 2.8875458311916558

Epoch: 5| Step: 3
Training loss: 3.277322798651744
Validation loss: 2.8949936040023085

Epoch: 5| Step: 4
Training loss: 2.921001120050275
Validation loss: 2.8869402626980762

Epoch: 5| Step: 5
Training loss: 2.778993269635946
Validation loss: 2.893236070424978

Epoch: 5| Step: 6
Training loss: 3.3135246275617893
Validation loss: 2.8856737235498637

Epoch: 5| Step: 7
Training loss: 3.053810403470831
Validation loss: 2.8867254585575477

Epoch: 5| Step: 8
Training loss: 3.060366607595924
Validation loss: 2.8943976892818344

Epoch: 5| Step: 9
Training loss: 3.4445332102122173
Validation loss: 2.8857736182744227

Epoch: 5| Step: 10
Training loss: 3.1818900013534237
Validation loss: 2.887264877155548

Epoch: 201| Step: 0
Training loss: 3.6764113953257005
Validation loss: 2.8818242127338984

Epoch: 5| Step: 1
Training loss: 3.206606726479445
Validation loss: 2.882928588425751

Epoch: 5| Step: 2
Training loss: 2.9874789887651074
Validation loss: 2.881896640423781

Epoch: 5| Step: 3
Training loss: 3.307758320403891
Validation loss: 2.883311702906287

Epoch: 5| Step: 4
Training loss: 3.3841740288772164
Validation loss: 2.880407588204865

Epoch: 5| Step: 5
Training loss: 3.9114792878681315
Validation loss: 2.879421319235455

Epoch: 5| Step: 6
Training loss: 2.9881851878963404
Validation loss: 2.8815152150380006

Epoch: 5| Step: 7
Training loss: 2.9954612094059345
Validation loss: 2.8792267377481964

Epoch: 5| Step: 8
Training loss: 3.0074362779622477
Validation loss: 2.8822888292400446

Epoch: 5| Step: 9
Training loss: 2.6181701637319343
Validation loss: 2.881226335878156

Epoch: 5| Step: 10
Training loss: 2.5263595433482635
Validation loss: 2.8817384292287307

Epoch: 202| Step: 0
Training loss: 3.1400045664565783
Validation loss: 2.8821400637572783

Epoch: 5| Step: 1
Training loss: 3.6061496608268686
Validation loss: 2.881994774913447

Epoch: 5| Step: 2
Training loss: 2.9145778987707516
Validation loss: 2.883919599647505

Epoch: 5| Step: 3
Training loss: 3.439831030044759
Validation loss: 2.888969105405365

Epoch: 5| Step: 4
Training loss: 3.1711175324195957
Validation loss: 2.8835701686971453

Epoch: 5| Step: 5
Training loss: 3.2108780978386093
Validation loss: 2.8851854613682875

Epoch: 5| Step: 6
Training loss: 2.858959730667284
Validation loss: 2.8869623608183166

Epoch: 5| Step: 7
Training loss: 3.3119271700771167
Validation loss: 2.8821336985452346

Epoch: 5| Step: 8
Training loss: 3.258121173972747
Validation loss: 2.8821151792206314

Epoch: 5| Step: 9
Training loss: 2.624194521166107
Validation loss: 2.8809950743025454

Epoch: 5| Step: 10
Training loss: 3.3113535210572818
Validation loss: 2.880574235606934

Epoch: 203| Step: 0
Training loss: 3.093641799421821
Validation loss: 2.87973418356264

Epoch: 5| Step: 1
Training loss: 3.4851999717489113
Validation loss: 2.877615125831349

Epoch: 5| Step: 2
Training loss: 3.57850584976765
Validation loss: 2.8780161697640483

Epoch: 5| Step: 3
Training loss: 3.5170068356358337
Validation loss: 2.8758995687235145

Epoch: 5| Step: 4
Training loss: 2.6007893647846236
Validation loss: 2.8769796171539785

Epoch: 5| Step: 5
Training loss: 2.9537231808291184
Validation loss: 2.876925643476534

Epoch: 5| Step: 6
Training loss: 2.8172102586077656
Validation loss: 2.8779276368929714

Epoch: 5| Step: 7
Training loss: 3.527974998454734
Validation loss: 2.8758017308018227

Epoch: 5| Step: 8
Training loss: 3.0260192730195943
Validation loss: 2.881520030898452

Epoch: 5| Step: 9
Training loss: 2.959267338986755
Validation loss: 2.880107521319716

Epoch: 5| Step: 10
Training loss: 3.217439847797366
Validation loss: 2.883947924793623

Epoch: 204| Step: 0
Training loss: 2.9770017284814996
Validation loss: 2.888625217098569

Epoch: 5| Step: 1
Training loss: 2.5641878663448026
Validation loss: 2.8812628484177036

Epoch: 5| Step: 2
Training loss: 3.559213561297883
Validation loss: 2.8839255200029505

Epoch: 5| Step: 3
Training loss: 3.3810080281263577
Validation loss: 2.885364150982123

Epoch: 5| Step: 4
Training loss: 3.5344551866577256
Validation loss: 2.885859611407957

Epoch: 5| Step: 5
Training loss: 2.983746367549403
Validation loss: 2.8843955947677036

Epoch: 5| Step: 6
Training loss: 3.331240919147303
Validation loss: 2.8838332521932832

Epoch: 5| Step: 7
Training loss: 2.6950213731190713
Validation loss: 2.8818293425473342

Epoch: 5| Step: 8
Training loss: 2.859360825133496
Validation loss: 2.879548607172826

Epoch: 5| Step: 9
Training loss: 3.1757253944580692
Validation loss: 2.874789190566573

Epoch: 5| Step: 10
Training loss: 3.756809790817513
Validation loss: 2.8786596606494768

Epoch: 205| Step: 0
Training loss: 3.0014899050955717
Validation loss: 2.8756983400655067

Epoch: 5| Step: 1
Training loss: 2.942307130363798
Validation loss: 2.8768744820539625

Epoch: 5| Step: 2
Training loss: 3.5293755071311006
Validation loss: 2.8760534124867734

Epoch: 5| Step: 3
Training loss: 3.1168327416492057
Validation loss: 2.8753569908768397

Epoch: 5| Step: 4
Training loss: 2.7361752060957953
Validation loss: 2.8767090773910082

Epoch: 5| Step: 5
Training loss: 3.4242567717808363
Validation loss: 2.8764166549584416

Epoch: 5| Step: 6
Training loss: 2.522295619673412
Validation loss: 2.8744274530553717

Epoch: 5| Step: 7
Training loss: 3.878980622438128
Validation loss: 2.8760427338005927

Epoch: 5| Step: 8
Training loss: 3.393068619641043
Validation loss: 2.872899770810081

Epoch: 5| Step: 9
Training loss: 3.1732065196570556
Validation loss: 2.8725184546819142

Epoch: 5| Step: 10
Training loss: 2.9296494138149383
Validation loss: 2.8752631663986667

Epoch: 206| Step: 0
Training loss: 3.0785525262269413
Validation loss: 2.872676663196798

Epoch: 5| Step: 1
Training loss: 2.615228084587982
Validation loss: 2.872324241872285

Epoch: 5| Step: 2
Training loss: 3.3933710325753768
Validation loss: 2.872823594089083

Epoch: 5| Step: 3
Training loss: 3.2764028442079858
Validation loss: 2.874130632983362

Epoch: 5| Step: 4
Training loss: 2.9622031855879705
Validation loss: 2.8742760218864567

Epoch: 5| Step: 5
Training loss: 3.2457908369684936
Validation loss: 2.8751490190076363

Epoch: 5| Step: 6
Training loss: 3.155928491514769
Validation loss: 2.8748333968746045

Epoch: 5| Step: 7
Training loss: 2.9413837163500247
Validation loss: 2.871646341119998

Epoch: 5| Step: 8
Training loss: 3.359087838607813
Validation loss: 2.871440292337567

Epoch: 5| Step: 9
Training loss: 3.331926780216754
Validation loss: 2.8731489370782026

Epoch: 5| Step: 10
Training loss: 3.4498900022800774
Validation loss: 2.8731721539950015

Epoch: 207| Step: 0
Training loss: 3.3838037179516687
Validation loss: 2.8714293393662014

Epoch: 5| Step: 1
Training loss: 3.5274264810688405
Validation loss: 2.8714880785165033

Epoch: 5| Step: 2
Training loss: 2.9007922372936106
Validation loss: 2.8724661562728593

Epoch: 5| Step: 3
Training loss: 3.2532512834499956
Validation loss: 2.8735542692830807

Epoch: 5| Step: 4
Training loss: 3.619466175109422
Validation loss: 2.8732821043379535

Epoch: 5| Step: 5
Training loss: 3.022942238788683
Validation loss: 2.871594904409423

Epoch: 5| Step: 6
Training loss: 3.0264933911548693
Validation loss: 2.8724986703072566

Epoch: 5| Step: 7
Training loss: 2.9508021670310396
Validation loss: 2.873060250654956

Epoch: 5| Step: 8
Training loss: 3.3930736788151483
Validation loss: 2.873958770044604

Epoch: 5| Step: 9
Training loss: 2.7441805039084084
Validation loss: 2.8746222416833818

Epoch: 5| Step: 10
Training loss: 2.8376494985848493
Validation loss: 2.8722145744002883

Epoch: 208| Step: 0
Training loss: 2.753684436711975
Validation loss: 2.881618221806687

Epoch: 5| Step: 1
Training loss: 3.1477063562983374
Validation loss: 2.8742483439610216

Epoch: 5| Step: 2
Training loss: 3.0225254625079323
Validation loss: 2.874990146686064

Epoch: 5| Step: 3
Training loss: 3.1842524122127345
Validation loss: 2.8703237903438183

Epoch: 5| Step: 4
Training loss: 3.1644455666069775
Validation loss: 2.8695649862481862

Epoch: 5| Step: 5
Training loss: 2.887905181596277
Validation loss: 2.8702586358200453

Epoch: 5| Step: 6
Training loss: 2.845410375781322
Validation loss: 2.8673289882364354

Epoch: 5| Step: 7
Training loss: 2.9764441118701397
Validation loss: 2.8669495744417923

Epoch: 5| Step: 8
Training loss: 3.5741891328178648
Validation loss: 2.8678939640595864

Epoch: 5| Step: 9
Training loss: 3.6062710449027815
Validation loss: 2.8688783615884637

Epoch: 5| Step: 10
Training loss: 3.611020328326119
Validation loss: 2.8702505490104726

Epoch: 209| Step: 0
Training loss: 3.6173211684771767
Validation loss: 2.8678667497180537

Epoch: 5| Step: 1
Training loss: 3.068513843283243
Validation loss: 2.866130446124714

Epoch: 5| Step: 2
Training loss: 3.462288689620766
Validation loss: 2.8668697440734534

Epoch: 5| Step: 3
Training loss: 3.1839942352587784
Validation loss: 2.8652483078619193

Epoch: 5| Step: 4
Training loss: 3.070821550019706
Validation loss: 2.8661670060723474

Epoch: 5| Step: 5
Training loss: 3.1286877045047716
Validation loss: 2.866678915321966

Epoch: 5| Step: 6
Training loss: 3.016733232750786
Validation loss: 2.866063916270779

Epoch: 5| Step: 7
Training loss: 3.8647794990758593
Validation loss: 2.863691966220138

Epoch: 5| Step: 8
Training loss: 2.5788218163435057
Validation loss: 2.867105787798912

Epoch: 5| Step: 9
Training loss: 2.463048411071281
Validation loss: 2.8651438294309313

Epoch: 5| Step: 10
Training loss: 3.088094918081939
Validation loss: 2.864565995836043

Epoch: 210| Step: 0
Training loss: 3.331114236953057
Validation loss: 2.8645720224166507

Epoch: 5| Step: 1
Training loss: 3.50192235198066
Validation loss: 2.8653679807682635

Epoch: 5| Step: 2
Training loss: 2.9219905402038893
Validation loss: 2.8680629367785198

Epoch: 5| Step: 3
Training loss: 3.49323941288944
Validation loss: 2.8654366400086415

Epoch: 5| Step: 4
Training loss: 2.792938445667108
Validation loss: 2.867978959389657

Epoch: 5| Step: 5
Training loss: 3.2276061358386077
Validation loss: 2.8664328848494938

Epoch: 5| Step: 6
Training loss: 2.677630555347428
Validation loss: 2.864936604274369

Epoch: 5| Step: 7
Training loss: 2.9986197157333843
Validation loss: 2.86687811047616

Epoch: 5| Step: 8
Training loss: 3.2991620126877543
Validation loss: 2.8655960992450824

Epoch: 5| Step: 9
Training loss: 3.488684345804396
Validation loss: 2.8635659260074484

Epoch: 5| Step: 10
Training loss: 2.8866520152553434
Validation loss: 2.8628771945244216

Epoch: 211| Step: 0
Training loss: 2.425571893328373
Validation loss: 2.8609712626729626

Epoch: 5| Step: 1
Training loss: 3.402807053074579
Validation loss: 2.861282323067307

Epoch: 5| Step: 2
Training loss: 3.0439022331628376
Validation loss: 2.865758704782085

Epoch: 5| Step: 3
Training loss: 3.594456080857285
Validation loss: 2.8627508954556498

Epoch: 5| Step: 4
Training loss: 3.3348499821403284
Validation loss: 2.8649023462720287

Epoch: 5| Step: 5
Training loss: 3.0985627934395157
Validation loss: 2.8618391440293296

Epoch: 5| Step: 6
Training loss: 2.6623169670412286
Validation loss: 2.863428676428

Epoch: 5| Step: 7
Training loss: 3.6986346483565966
Validation loss: 2.8634160096316403

Epoch: 5| Step: 8
Training loss: 2.6669280897586276
Validation loss: 2.8635099528094106

Epoch: 5| Step: 9
Training loss: 3.5136057840591515
Validation loss: 2.866913381266084

Epoch: 5| Step: 10
Training loss: 3.0407035731232486
Validation loss: 2.8651735910683973

Epoch: 212| Step: 0
Training loss: 3.6454760276457243
Validation loss: 2.8639852098862306

Epoch: 5| Step: 1
Training loss: 3.138611864751842
Validation loss: 2.865154303572619

Epoch: 5| Step: 2
Training loss: 2.9037415538571403
Validation loss: 2.865886652320221

Epoch: 5| Step: 3
Training loss: 2.8169340149745183
Validation loss: 2.866991905793831

Epoch: 5| Step: 4
Training loss: 3.7424293392138734
Validation loss: 2.8676555035098565

Epoch: 5| Step: 5
Training loss: 2.840090062768473
Validation loss: 2.867175615188856

Epoch: 5| Step: 6
Training loss: 2.5479659101999412
Validation loss: 2.8684954473544755

Epoch: 5| Step: 7
Training loss: 3.3280967747024226
Validation loss: 2.8676715031124598

Epoch: 5| Step: 8
Training loss: 3.223994750442207
Validation loss: 2.8682528279157693

Epoch: 5| Step: 9
Training loss: 3.149084133639066
Validation loss: 2.870324385184196

Epoch: 5| Step: 10
Training loss: 3.240744690261937
Validation loss: 2.8659578583417686

Epoch: 213| Step: 0
Training loss: 3.7362669936272566
Validation loss: 2.8652758754383205

Epoch: 5| Step: 1
Training loss: 3.0964690310917455
Validation loss: 2.8586331557315225

Epoch: 5| Step: 2
Training loss: 3.3744367906622292
Validation loss: 2.86080216859969

Epoch: 5| Step: 3
Training loss: 3.174509692443
Validation loss: 2.8591742572579713

Epoch: 5| Step: 4
Training loss: 2.9544558478152037
Validation loss: 2.8590626345667576

Epoch: 5| Step: 5
Training loss: 2.853370908269924
Validation loss: 2.858001580872145

Epoch: 5| Step: 6
Training loss: 3.3246160644062357
Validation loss: 2.8583946006444183

Epoch: 5| Step: 7
Training loss: 2.980953312152164
Validation loss: 2.858117648222743

Epoch: 5| Step: 8
Training loss: 2.976112471875259
Validation loss: 2.8585466664096613

Epoch: 5| Step: 9
Training loss: 3.2146894897680243
Validation loss: 2.857277682707946

Epoch: 5| Step: 10
Training loss: 2.9100774357511296
Validation loss: 2.856501766965498

Epoch: 214| Step: 0
Training loss: 3.0840118967462593
Validation loss: 2.8596011517912094

Epoch: 5| Step: 1
Training loss: 3.02324413696518
Validation loss: 2.8561447082141935

Epoch: 5| Step: 2
Training loss: 3.2300421399653825
Validation loss: 2.858208357177139

Epoch: 5| Step: 3
Training loss: 2.8033376861822723
Validation loss: 2.8559293167199904

Epoch: 5| Step: 4
Training loss: 2.2212818368015883
Validation loss: 2.8573490404630193

Epoch: 5| Step: 5
Training loss: 3.532037427762237
Validation loss: 2.8567034764594457

Epoch: 5| Step: 6
Training loss: 3.282819971786922
Validation loss: 2.8618520247343193

Epoch: 5| Step: 7
Training loss: 3.116240622899973
Validation loss: 2.8621637077589424

Epoch: 5| Step: 8
Training loss: 3.397032559135209
Validation loss: 2.868473501006147

Epoch: 5| Step: 9
Training loss: 3.4350725793181
Validation loss: 2.864210816863324

Epoch: 5| Step: 10
Training loss: 3.438594574488984
Validation loss: 2.8628154471385794

Epoch: 215| Step: 0
Training loss: 3.382931608081017
Validation loss: 2.8593563377559894

Epoch: 5| Step: 1
Training loss: 3.702976658421236
Validation loss: 2.8583049326341676

Epoch: 5| Step: 2
Training loss: 3.0145676098149643
Validation loss: 2.855266834761151

Epoch: 5| Step: 3
Training loss: 3.4073648290768888
Validation loss: 2.8568183707341093

Epoch: 5| Step: 4
Training loss: 2.8000151838163396
Validation loss: 2.8560577898749426

Epoch: 5| Step: 5
Training loss: 3.3656591500450883
Validation loss: 2.853116389155587

Epoch: 5| Step: 6
Training loss: 2.7861363210030925
Validation loss: 2.858078694422403

Epoch: 5| Step: 7
Training loss: 3.258191861905062
Validation loss: 2.857097434801306

Epoch: 5| Step: 8
Training loss: 2.7053827107402504
Validation loss: 2.855469590340936

Epoch: 5| Step: 9
Training loss: 3.0820012351002033
Validation loss: 2.8549225101809634

Epoch: 5| Step: 10
Training loss: 3.0539318818475376
Validation loss: 2.8537128471828703

Epoch: 216| Step: 0
Training loss: 3.8711018798003685
Validation loss: 2.858293204622457

Epoch: 5| Step: 1
Training loss: 2.492604092305921
Validation loss: 2.8577609420748415

Epoch: 5| Step: 2
Training loss: 3.280754851265788
Validation loss: 2.8580706547755663

Epoch: 5| Step: 3
Training loss: 3.5318983714947665
Validation loss: 2.8606290460595605

Epoch: 5| Step: 4
Training loss: 2.6938690300861556
Validation loss: 2.8596561301976213

Epoch: 5| Step: 5
Training loss: 2.9360369021411947
Validation loss: 2.8581248212684183

Epoch: 5| Step: 6
Training loss: 3.7116097252984033
Validation loss: 2.85848909449518

Epoch: 5| Step: 7
Training loss: 2.487695070985356
Validation loss: 2.8610216609890133

Epoch: 5| Step: 8
Training loss: 3.0555108173062147
Validation loss: 2.860437457711432

Epoch: 5| Step: 9
Training loss: 3.0622117821666635
Validation loss: 2.857696424238718

Epoch: 5| Step: 10
Training loss: 3.2370049293251912
Validation loss: 2.858302200646752

Epoch: 217| Step: 0
Training loss: 3.022013326356741
Validation loss: 2.8638337139863363

Epoch: 5| Step: 1
Training loss: 3.0581955534816543
Validation loss: 2.868488033018079

Epoch: 5| Step: 2
Training loss: 3.2068135679015306
Validation loss: 2.8683829718850236

Epoch: 5| Step: 3
Training loss: 2.9586377233516696
Validation loss: 2.8700500729865412

Epoch: 5| Step: 4
Training loss: 3.396410668721176
Validation loss: 2.8638599282558346

Epoch: 5| Step: 5
Training loss: 2.695486311905909
Validation loss: 2.861061059480999

Epoch: 5| Step: 6
Training loss: 3.008067727097524
Validation loss: 2.864990546106694

Epoch: 5| Step: 7
Training loss: 3.5060987470509533
Validation loss: 2.8615555200232285

Epoch: 5| Step: 8
Training loss: 3.1185443573390783
Validation loss: 2.8599558840426327

Epoch: 5| Step: 9
Training loss: 3.601897184828868
Validation loss: 2.8571639150291768

Epoch: 5| Step: 10
Training loss: 2.964121211570938
Validation loss: 2.852972140106513

Epoch: 218| Step: 0
Training loss: 3.101270224687098
Validation loss: 2.851015231212542

Epoch: 5| Step: 1
Training loss: 3.0927726666106556
Validation loss: 2.8502272229088383

Epoch: 5| Step: 2
Training loss: 3.25952542507404
Validation loss: 2.8521995490254493

Epoch: 5| Step: 3
Training loss: 3.397015434106549
Validation loss: 2.8506384133970615

Epoch: 5| Step: 4
Training loss: 2.681743489270074
Validation loss: 2.8512719060653486

Epoch: 5| Step: 5
Training loss: 2.663461925122022
Validation loss: 2.8527667671894275

Epoch: 5| Step: 6
Training loss: 3.406273938016158
Validation loss: 2.8569536810827336

Epoch: 5| Step: 7
Training loss: 3.352340074518056
Validation loss: 2.8523592278795706

Epoch: 5| Step: 8
Training loss: 3.250327020478289
Validation loss: 2.8545032288113603

Epoch: 5| Step: 9
Training loss: 3.8249833898245993
Validation loss: 2.855144686761576

Epoch: 5| Step: 10
Training loss: 2.308114713743517
Validation loss: 2.850359620866862

Epoch: 219| Step: 0
Training loss: 2.8623521658357567
Validation loss: 2.8472739418975532

Epoch: 5| Step: 1
Training loss: 3.07335545052647
Validation loss: 2.8483669642606766

Epoch: 5| Step: 2
Training loss: 3.192637622707782
Validation loss: 2.8483777323039

Epoch: 5| Step: 3
Training loss: 3.9138123818771215
Validation loss: 2.847479745193816

Epoch: 5| Step: 4
Training loss: 2.8172530807165486
Validation loss: 2.8508139195934494

Epoch: 5| Step: 5
Training loss: 3.1373933325641166
Validation loss: 2.8526270415685966

Epoch: 5| Step: 6
Training loss: 2.420589179520801
Validation loss: 2.854642093859356

Epoch: 5| Step: 7
Training loss: 3.0982226783509987
Validation loss: 2.8567171763216894

Epoch: 5| Step: 8
Training loss: 3.5955702442685955
Validation loss: 2.8576392711942393

Epoch: 5| Step: 9
Training loss: 3.314678123808272
Validation loss: 2.8576205285361507

Epoch: 5| Step: 10
Training loss: 2.9557804500931444
Validation loss: 2.854518677953764

Epoch: 220| Step: 0
Training loss: 3.1343447013447876
Validation loss: 2.8573749589328123

Epoch: 5| Step: 1
Training loss: 3.3416710210630693
Validation loss: 2.862179470247843

Epoch: 5| Step: 2
Training loss: 2.6937818520913113
Validation loss: 2.8593205380039985

Epoch: 5| Step: 3
Training loss: 3.129420548936645
Validation loss: 2.8609676425335873

Epoch: 5| Step: 4
Training loss: 3.2841902865109227
Validation loss: 2.857243689978623

Epoch: 5| Step: 5
Training loss: 3.484945207819122
Validation loss: 2.8566857175136384

Epoch: 5| Step: 6
Training loss: 3.5043127192036057
Validation loss: 2.851672498711267

Epoch: 5| Step: 7
Training loss: 3.0253058286817325
Validation loss: 2.84917416483996

Epoch: 5| Step: 8
Training loss: 2.4726343620982765
Validation loss: 2.8470671503386726

Epoch: 5| Step: 9
Training loss: 2.832335651744091
Validation loss: 2.8478274821484635

Epoch: 5| Step: 10
Training loss: 3.605739331243723
Validation loss: 2.849120664995021

Epoch: 221| Step: 0
Training loss: 2.954465531555316
Validation loss: 2.849835110715723

Epoch: 5| Step: 1
Training loss: 2.966435704902569
Validation loss: 2.8488330890397213

Epoch: 5| Step: 2
Training loss: 2.4254745805549
Validation loss: 2.8493217147581897

Epoch: 5| Step: 3
Training loss: 3.4506665622479256
Validation loss: 2.8471141029983618

Epoch: 5| Step: 4
Training loss: 3.755049548273012
Validation loss: 2.85004046371281

Epoch: 5| Step: 5
Training loss: 3.1892496430708643
Validation loss: 2.8490218201786472

Epoch: 5| Step: 6
Training loss: 3.3481162966967046
Validation loss: 2.84802385242473

Epoch: 5| Step: 7
Training loss: 3.442188741204951
Validation loss: 2.8505443652916544

Epoch: 5| Step: 8
Training loss: 3.194088876441974
Validation loss: 2.8483974538101102

Epoch: 5| Step: 9
Training loss: 2.71561760061856
Validation loss: 2.848872657443419

Epoch: 5| Step: 10
Training loss: 2.9388953608069244
Validation loss: 2.8524451813162144

Epoch: 222| Step: 0
Training loss: 2.9341518719455544
Validation loss: 2.8550134400771774

Epoch: 5| Step: 1
Training loss: 3.5445701067288984
Validation loss: 2.8584174674383114

Epoch: 5| Step: 2
Training loss: 2.936566143530915
Validation loss: 2.847646881843877

Epoch: 5| Step: 3
Training loss: 2.8289808801279297
Validation loss: 2.847709608110524

Epoch: 5| Step: 4
Training loss: 3.393132139835375
Validation loss: 2.8456210445240537

Epoch: 5| Step: 5
Training loss: 3.2844434910682367
Validation loss: 2.8426219150047967

Epoch: 5| Step: 6
Training loss: 3.386524445658841
Validation loss: 2.8439162425595006

Epoch: 5| Step: 7
Training loss: 3.1240699910078553
Validation loss: 2.8425212523684804

Epoch: 5| Step: 8
Training loss: 3.4783143847951203
Validation loss: 2.841914146322938

Epoch: 5| Step: 9
Training loss: 2.821992748756744
Validation loss: 2.8419332505590607

Epoch: 5| Step: 10
Training loss: 2.6746035023543038
Validation loss: 2.839162752305478

Epoch: 223| Step: 0
Training loss: 3.310557101523659
Validation loss: 2.8436301169040714

Epoch: 5| Step: 1
Training loss: 3.434481040699002
Validation loss: 2.841491779819104

Epoch: 5| Step: 2
Training loss: 3.1533990958240516
Validation loss: 2.8427180423981926

Epoch: 5| Step: 3
Training loss: 3.246231388336872
Validation loss: 2.8460729613749716

Epoch: 5| Step: 4
Training loss: 3.5799670412901334
Validation loss: 2.8441829610985976

Epoch: 5| Step: 5
Training loss: 3.2148584340016257
Validation loss: 2.854757713184824

Epoch: 5| Step: 6
Training loss: 2.544230205376797
Validation loss: 2.8516013054729497

Epoch: 5| Step: 7
Training loss: 2.7350554573252763
Validation loss: 2.8551522255383177

Epoch: 5| Step: 8
Training loss: 3.2000480946264487
Validation loss: 2.8536819975844745

Epoch: 5| Step: 9
Training loss: 2.9594444194252882
Validation loss: 2.8528277876101393

Epoch: 5| Step: 10
Training loss: 3.0832749094883622
Validation loss: 2.849978947341325

Epoch: 224| Step: 0
Training loss: 2.5936759110865197
Validation loss: 2.8481244438958067

Epoch: 5| Step: 1
Training loss: 3.0840088044274667
Validation loss: 2.8452212703810935

Epoch: 5| Step: 2
Training loss: 3.3799296510587253
Validation loss: 2.84733677361935

Epoch: 5| Step: 3
Training loss: 3.317628453289661
Validation loss: 2.845147135054331

Epoch: 5| Step: 4
Training loss: 3.864739400312034
Validation loss: 2.8477748500282227

Epoch: 5| Step: 5
Training loss: 3.4636801020364403
Validation loss: 2.8418616653925874

Epoch: 5| Step: 6
Training loss: 2.337593537769354
Validation loss: 2.8414689897401013

Epoch: 5| Step: 7
Training loss: 2.9285961508953506
Validation loss: 2.840226189923033

Epoch: 5| Step: 8
Training loss: 2.854548983248687
Validation loss: 2.839748261067805

Epoch: 5| Step: 9
Training loss: 3.1916575525484023
Validation loss: 2.8407312656581483

Epoch: 5| Step: 10
Training loss: 3.3654386931046445
Validation loss: 2.841671895309929

Epoch: 225| Step: 0
Training loss: 3.366487576344902
Validation loss: 2.8400673742750335

Epoch: 5| Step: 1
Training loss: 3.459855369014652
Validation loss: 2.8408538610286045

Epoch: 5| Step: 2
Training loss: 3.2404637913716794
Validation loss: 2.8381621118401963

Epoch: 5| Step: 3
Training loss: 2.541775612502556
Validation loss: 2.838410971233903

Epoch: 5| Step: 4
Training loss: 2.794881355210516
Validation loss: 2.839111692361677

Epoch: 5| Step: 5
Training loss: 2.6199129858928334
Validation loss: 2.8383217124168048

Epoch: 5| Step: 6
Training loss: 3.178188711182317
Validation loss: 2.83762416968159

Epoch: 5| Step: 7
Training loss: 3.056527210605586
Validation loss: 2.836497632395013

Epoch: 5| Step: 8
Training loss: 3.527070669627265
Validation loss: 2.837002230628186

Epoch: 5| Step: 9
Training loss: 3.051716405969096
Validation loss: 2.8375747290636877

Epoch: 5| Step: 10
Training loss: 3.5984551187896394
Validation loss: 2.841945627018967

Epoch: 226| Step: 0
Training loss: 2.7955137381873634
Validation loss: 2.8436793377487937

Epoch: 5| Step: 1
Training loss: 2.794521769656043
Validation loss: 2.8657094337639553

Epoch: 5| Step: 2
Training loss: 3.256682641397873
Validation loss: 2.879990527832185

Epoch: 5| Step: 3
Training loss: 3.1445191187654196
Validation loss: 2.9047599710317455

Epoch: 5| Step: 4
Training loss: 3.5121507898688473
Validation loss: 2.914938548052843

Epoch: 5| Step: 5
Training loss: 3.1142103467298416
Validation loss: 2.910586579241488

Epoch: 5| Step: 6
Training loss: 3.3534088384370193
Validation loss: 2.8834936604075114

Epoch: 5| Step: 7
Training loss: 3.333464015942133
Validation loss: 2.8441047776199637

Epoch: 5| Step: 8
Training loss: 3.5577859307102453
Validation loss: 2.8353670887249875

Epoch: 5| Step: 9
Training loss: 2.8078604684000346
Validation loss: 2.8359697195959814

Epoch: 5| Step: 10
Training loss: 2.8306340842376034
Validation loss: 2.843653087098243

Epoch: 227| Step: 0
Training loss: 3.684206510125746
Validation loss: 2.875857174155457

Epoch: 5| Step: 1
Training loss: 3.3536912253366293
Validation loss: 2.870316207457937

Epoch: 5| Step: 2
Training loss: 3.21236757235561
Validation loss: 2.8394076804464397

Epoch: 5| Step: 3
Training loss: 2.77890430071797
Validation loss: 2.838263898258418

Epoch: 5| Step: 4
Training loss: 3.2161577767627847
Validation loss: 2.834498269724447

Epoch: 5| Step: 5
Training loss: 3.1178898605655054
Validation loss: 2.8367419998848713

Epoch: 5| Step: 6
Training loss: 2.8544308802324174
Validation loss: 2.8431380410274327

Epoch: 5| Step: 7
Training loss: 2.6282122802756347
Validation loss: 2.8567874236530058

Epoch: 5| Step: 8
Training loss: 2.9171167480519418
Validation loss: 2.8722115200383342

Epoch: 5| Step: 9
Training loss: 3.468357510742896
Validation loss: 2.888200687249025

Epoch: 5| Step: 10
Training loss: 3.4143437808720276
Validation loss: 2.878642689945847

Epoch: 228| Step: 0
Training loss: 3.136982337831409
Validation loss: 2.8773436800050227

Epoch: 5| Step: 1
Training loss: 3.7247010386269173
Validation loss: 2.8514667139219907

Epoch: 5| Step: 2
Training loss: 2.9761603777135517
Validation loss: 2.839648486034642

Epoch: 5| Step: 3
Training loss: 3.1305384575565784
Validation loss: 2.8306876151384315

Epoch: 5| Step: 4
Training loss: 3.5304089109984726
Validation loss: 2.8323987913123263

Epoch: 5| Step: 5
Training loss: 2.892968295079545
Validation loss: 2.8320386366700108

Epoch: 5| Step: 6
Training loss: 3.4193236711791606
Validation loss: 2.8313776670681494

Epoch: 5| Step: 7
Training loss: 3.1778646206789993
Validation loss: 2.832385960403036

Epoch: 5| Step: 8
Training loss: 3.1332636101723197
Validation loss: 2.836334566831763

Epoch: 5| Step: 9
Training loss: 2.6489746989290794
Validation loss: 2.8380164080501062

Epoch: 5| Step: 10
Training loss: 2.5509060278571147
Validation loss: 2.839987948226142

Epoch: 229| Step: 0
Training loss: 3.4718479378621545
Validation loss: 2.8420275105569126

Epoch: 5| Step: 1
Training loss: 2.286950709363476
Validation loss: 2.8478961564835292

Epoch: 5| Step: 2
Training loss: 2.9971465209539567
Validation loss: 2.8389085451088083

Epoch: 5| Step: 3
Training loss: 3.1339847340750606
Validation loss: 2.8365277271329954

Epoch: 5| Step: 4
Training loss: 3.3656500826921945
Validation loss: 2.8346610610777687

Epoch: 5| Step: 5
Training loss: 2.800858883599787
Validation loss: 2.833475796690721

Epoch: 5| Step: 6
Training loss: 3.2601292557630637
Validation loss: 2.832284281356547

Epoch: 5| Step: 7
Training loss: 3.458504607467373
Validation loss: 2.8348123941328645

Epoch: 5| Step: 8
Training loss: 3.2864083569933933
Validation loss: 2.8344930112910096

Epoch: 5| Step: 9
Training loss: 3.2403871248466705
Validation loss: 2.833949960846653

Epoch: 5| Step: 10
Training loss: 3.0351549931625454
Validation loss: 2.8312526267604374

Epoch: 230| Step: 0
Training loss: 2.6724729705385752
Validation loss: 2.8295965785776738

Epoch: 5| Step: 1
Training loss: 2.461370908325694
Validation loss: 2.8310731722808415

Epoch: 5| Step: 2
Training loss: 3.105064125811709
Validation loss: 2.8329810955659043

Epoch: 5| Step: 3
Training loss: 3.278453688966529
Validation loss: 2.8306477744204326

Epoch: 5| Step: 4
Training loss: 2.985205250237806
Validation loss: 2.8288439154926768

Epoch: 5| Step: 5
Training loss: 2.688211923385457
Validation loss: 2.832238322924135

Epoch: 5| Step: 6
Training loss: 3.1621428517954615
Validation loss: 2.82933763653783

Epoch: 5| Step: 7
Training loss: 2.9345946858388823
Validation loss: 2.8258917990550954

Epoch: 5| Step: 8
Training loss: 3.8037729907085347
Validation loss: 2.8271715878505748

Epoch: 5| Step: 9
Training loss: 3.5889002708934314
Validation loss: 2.828359009180497

Epoch: 5| Step: 10
Training loss: 3.5888079289325368
Validation loss: 2.8271642727955384

Epoch: 231| Step: 0
Training loss: 3.1319091712185227
Validation loss: 2.827817066256893

Epoch: 5| Step: 1
Training loss: 3.2032613585686116
Validation loss: 2.8315647002048654

Epoch: 5| Step: 2
Training loss: 2.9641094680628224
Validation loss: 2.8281112296186675

Epoch: 5| Step: 3
Training loss: 3.3231655653450107
Validation loss: 2.8256554815854837

Epoch: 5| Step: 4
Training loss: 2.914975266261702
Validation loss: 2.8264320168143318

Epoch: 5| Step: 5
Training loss: 3.1653771200785688
Validation loss: 2.8271237054980998

Epoch: 5| Step: 6
Training loss: 2.945345850586214
Validation loss: 2.8260734557920175

Epoch: 5| Step: 7
Training loss: 3.53081813635822
Validation loss: 2.826794568095758

Epoch: 5| Step: 8
Training loss: 2.8795834369868234
Validation loss: 2.8247334066913012

Epoch: 5| Step: 9
Training loss: 3.043731476337692
Validation loss: 2.8257361814500426

Epoch: 5| Step: 10
Training loss: 3.323114195944754
Validation loss: 2.823503109515549

Epoch: 232| Step: 0
Training loss: 3.1947297028779578
Validation loss: 2.8253924627258926

Epoch: 5| Step: 1
Training loss: 2.927419206528917
Validation loss: 2.825836978421473

Epoch: 5| Step: 2
Training loss: 3.184451571546259
Validation loss: 2.8267501546824545

Epoch: 5| Step: 3
Training loss: 3.59320648063815
Validation loss: 2.824911123088812

Epoch: 5| Step: 4
Training loss: 2.460506728481123
Validation loss: 2.826020222576741

Epoch: 5| Step: 5
Training loss: 2.9515328126608837
Validation loss: 2.8269692520898393

Epoch: 5| Step: 6
Training loss: 2.778298687305998
Validation loss: 2.829139674753249

Epoch: 5| Step: 7
Training loss: 3.372262338870677
Validation loss: 2.83153031368262

Epoch: 5| Step: 8
Training loss: 3.174433536008611
Validation loss: 2.8350208274124156

Epoch: 5| Step: 9
Training loss: 3.716529118910738
Validation loss: 2.83672348878218

Epoch: 5| Step: 10
Training loss: 2.8550846452073584
Validation loss: 2.8307040378769783

Epoch: 233| Step: 0
Training loss: 3.642266161448463
Validation loss: 2.8319871269186323

Epoch: 5| Step: 1
Training loss: 2.5541212288412294
Validation loss: 2.8343363115575633

Epoch: 5| Step: 2
Training loss: 2.7934387238437197
Validation loss: 2.835151833145956

Epoch: 5| Step: 3
Training loss: 2.6923328681439416
Validation loss: 2.8356715464389906

Epoch: 5| Step: 4
Training loss: 3.603228599468379
Validation loss: 2.8388619263224966

Epoch: 5| Step: 5
Training loss: 3.44613838244731
Validation loss: 2.8420776205958007

Epoch: 5| Step: 6
Training loss: 2.868430884071348
Validation loss: 2.832673691528393

Epoch: 5| Step: 7
Training loss: 2.6834656353038944
Validation loss: 2.827427085125697

Epoch: 5| Step: 8
Training loss: 3.6279344191590948
Validation loss: 2.8254731365314116

Epoch: 5| Step: 9
Training loss: 2.887024322565869
Validation loss: 2.8219851377484533

Epoch: 5| Step: 10
Training loss: 3.3851401974200366
Validation loss: 2.821949662438989

Epoch: 234| Step: 0
Training loss: 3.3463582356746095
Validation loss: 2.8219846644444426

Epoch: 5| Step: 1
Training loss: 3.4458949835788677
Validation loss: 2.8225874831297006

Epoch: 5| Step: 2
Training loss: 3.314893038075563
Validation loss: 2.819916146316838

Epoch: 5| Step: 3
Training loss: 2.597210058454656
Validation loss: 2.819246814956369

Epoch: 5| Step: 4
Training loss: 2.872010708695958
Validation loss: 2.8203151178948622

Epoch: 5| Step: 5
Training loss: 3.167172408291467
Validation loss: 2.818375193275674

Epoch: 5| Step: 6
Training loss: 3.268592471818133
Validation loss: 2.8183259971464323

Epoch: 5| Step: 7
Training loss: 2.5631063720800134
Validation loss: 2.8207938318396066

Epoch: 5| Step: 8
Training loss: 3.210746369625143
Validation loss: 2.8216180348456703

Epoch: 5| Step: 9
Training loss: 3.082638447445379
Validation loss: 2.8198941000838285

Epoch: 5| Step: 10
Training loss: 3.4500005749688154
Validation loss: 2.8226521713229955

Epoch: 235| Step: 0
Training loss: 3.144383094093249
Validation loss: 2.822801884976744

Epoch: 5| Step: 1
Training loss: 3.1291682101540923
Validation loss: 2.8259807755386275

Epoch: 5| Step: 2
Training loss: 3.5839787870358344
Validation loss: 2.8287139462458173

Epoch: 5| Step: 3
Training loss: 3.2413534907168375
Validation loss: 2.828529190788726

Epoch: 5| Step: 4
Training loss: 2.913019970496382
Validation loss: 2.8316136418815927

Epoch: 5| Step: 5
Training loss: 3.169840794605775
Validation loss: 2.837134369250798

Epoch: 5| Step: 6
Training loss: 2.839801604366165
Validation loss: 2.820187745402787

Epoch: 5| Step: 7
Training loss: 2.883003869463295
Validation loss: 2.81804781601097

Epoch: 5| Step: 8
Training loss: 3.1141417497579407
Validation loss: 2.818744021369966

Epoch: 5| Step: 9
Training loss: 3.272513539145652
Validation loss: 2.820333838499281

Epoch: 5| Step: 10
Training loss: 3.0547388565156184
Validation loss: 2.8254668895474784

Epoch: 236| Step: 0
Training loss: 2.965432009431927
Validation loss: 2.8271017671589957

Epoch: 5| Step: 1
Training loss: 3.2329605621754856
Validation loss: 2.831450286896561

Epoch: 5| Step: 2
Training loss: 3.2255778068604006
Validation loss: 2.8318205316924856

Epoch: 5| Step: 3
Training loss: 3.663410445961666
Validation loss: 2.8371937099887545

Epoch: 5| Step: 4
Training loss: 2.9832032784470304
Validation loss: 2.834527969650902

Epoch: 5| Step: 5
Training loss: 2.8140222456540114
Validation loss: 2.838525895143294

Epoch: 5| Step: 6
Training loss: 3.425762041618755
Validation loss: 2.830616483252974

Epoch: 5| Step: 7
Training loss: 2.57371828716466
Validation loss: 2.8299806333857775

Epoch: 5| Step: 8
Training loss: 3.4086351355856244
Validation loss: 2.8291736254797617

Epoch: 5| Step: 9
Training loss: 2.775662585362414
Validation loss: 2.82601027559589

Epoch: 5| Step: 10
Training loss: 3.3105608464399134
Validation loss: 2.8225024951423245

Epoch: 237| Step: 0
Training loss: 3.0155905291707
Validation loss: 2.823887140585996

Epoch: 5| Step: 1
Training loss: 3.0102136316876975
Validation loss: 2.822243357310557

Epoch: 5| Step: 2
Training loss: 2.6074184003371044
Validation loss: 2.821641969687243

Epoch: 5| Step: 3
Training loss: 3.52159093948405
Validation loss: 2.822421775483844

Epoch: 5| Step: 4
Training loss: 3.49726365616742
Validation loss: 2.8272350349803026

Epoch: 5| Step: 5
Training loss: 2.809042776660042
Validation loss: 2.8294859418148577

Epoch: 5| Step: 6
Training loss: 3.1995125101223154
Validation loss: 2.8348678582573434

Epoch: 5| Step: 7
Training loss: 3.350419283007463
Validation loss: 2.828883094687281

Epoch: 5| Step: 8
Training loss: 2.7764510854200593
Validation loss: 2.8270388221421108

Epoch: 5| Step: 9
Training loss: 3.087650026699582
Validation loss: 2.82587581419829

Epoch: 5| Step: 10
Training loss: 3.4396845031930394
Validation loss: 2.8281803509808157

Epoch: 238| Step: 0
Training loss: 3.014080699749031
Validation loss: 2.8209595133365104

Epoch: 5| Step: 1
Training loss: 2.8308945051592476
Validation loss: 2.8194726793401745

Epoch: 5| Step: 2
Training loss: 3.0848763874829417
Validation loss: 2.8175853444393475

Epoch: 5| Step: 3
Training loss: 3.4788754430777926
Validation loss: 2.819407430821047

Epoch: 5| Step: 4
Training loss: 3.039201512626398
Validation loss: 2.8151092603622456

Epoch: 5| Step: 5
Training loss: 3.047221472187659
Validation loss: 2.815436935613239

Epoch: 5| Step: 6
Training loss: 3.197944583004721
Validation loss: 2.8149463455687216

Epoch: 5| Step: 7
Training loss: 3.2644198443469272
Validation loss: 2.8162969274715506

Epoch: 5| Step: 8
Training loss: 3.1761408340688164
Validation loss: 2.816315825892431

Epoch: 5| Step: 9
Training loss: 3.138319393322157
Validation loss: 2.8169020627281873

Epoch: 5| Step: 10
Training loss: 3.041162701665751
Validation loss: 2.8165066335798805

Epoch: 239| Step: 0
Training loss: 3.0562871076519325
Validation loss: 2.816307862737241

Epoch: 5| Step: 1
Training loss: 3.251135701037042
Validation loss: 2.8146450909234106

Epoch: 5| Step: 2
Training loss: 3.486140740324828
Validation loss: 2.8240400177866234

Epoch: 5| Step: 3
Training loss: 3.248533651700482
Validation loss: 2.835801627124848

Epoch: 5| Step: 4
Training loss: 3.0756944073894084
Validation loss: 2.8405339038736566

Epoch: 5| Step: 5
Training loss: 3.2961054622480934
Validation loss: 2.8189294026964924

Epoch: 5| Step: 6
Training loss: 3.9425638727542602
Validation loss: 2.816504970607471

Epoch: 5| Step: 7
Training loss: 2.497299547828753
Validation loss: 2.816121324756211

Epoch: 5| Step: 8
Training loss: 2.7503476356643346
Validation loss: 2.8149588989673973

Epoch: 5| Step: 9
Training loss: 2.6112400174166965
Validation loss: 2.813318624278189

Epoch: 5| Step: 10
Training loss: 2.844064716069572
Validation loss: 2.8117634764821915

Epoch: 240| Step: 0
Training loss: 2.5607219202657845
Validation loss: 2.81232494506772

Epoch: 5| Step: 1
Training loss: 2.7403028483682506
Validation loss: 2.8125029195863798

Epoch: 5| Step: 2
Training loss: 3.1016057009054454
Validation loss: 2.8126318669368655

Epoch: 5| Step: 3
Training loss: 3.37851038030543
Validation loss: 2.8138244527492944

Epoch: 5| Step: 4
Training loss: 2.509248791628884
Validation loss: 2.8119047312038394

Epoch: 5| Step: 5
Training loss: 3.308693624202811
Validation loss: 2.815539580005648

Epoch: 5| Step: 6
Training loss: 3.448511554456958
Validation loss: 2.8194448339494107

Epoch: 5| Step: 7
Training loss: 2.939403972024668
Validation loss: 2.8155739742548254

Epoch: 5| Step: 8
Training loss: 3.536108135399603
Validation loss: 2.8179751182632096

Epoch: 5| Step: 9
Training loss: 3.0955951467268723
Validation loss: 2.816956297331412

Epoch: 5| Step: 10
Training loss: 3.542322808614727
Validation loss: 2.8211852551408767

Epoch: 241| Step: 0
Training loss: 3.404652632192958
Validation loss: 2.8178883162733617

Epoch: 5| Step: 1
Training loss: 3.3536188535182188
Validation loss: 2.8198070807829123

Epoch: 5| Step: 2
Training loss: 3.356054181685712
Validation loss: 2.8156654018761995

Epoch: 5| Step: 3
Training loss: 2.8678519910770515
Validation loss: 2.815257318955054

Epoch: 5| Step: 4
Training loss: 2.6060943081318446
Validation loss: 2.8151152616830535

Epoch: 5| Step: 5
Training loss: 3.459254146074172
Validation loss: 2.813998453261475

Epoch: 5| Step: 6
Training loss: 2.88535236236493
Validation loss: 2.8108279454743603

Epoch: 5| Step: 7
Training loss: 2.776759433578165
Validation loss: 2.813707553223396

Epoch: 5| Step: 8
Training loss: 3.080182312610482
Validation loss: 2.8142407434451395

Epoch: 5| Step: 9
Training loss: 3.1344956136147357
Validation loss: 2.8148707398473394

Epoch: 5| Step: 10
Training loss: 3.305971730281567
Validation loss: 2.8144750936172733

Epoch: 242| Step: 0
Training loss: 2.9620546030270063
Validation loss: 2.8116434413168205

Epoch: 5| Step: 1
Training loss: 2.7131793072477883
Validation loss: 2.8144578834545784

Epoch: 5| Step: 2
Training loss: 3.2550991843680035
Validation loss: 2.811942700006945

Epoch: 5| Step: 3
Training loss: 3.384846487691762
Validation loss: 2.8158666480002634

Epoch: 5| Step: 4
Training loss: 3.529639222725538
Validation loss: 2.8158184022466943

Epoch: 5| Step: 5
Training loss: 2.7030617590766526
Validation loss: 2.81214888373805

Epoch: 5| Step: 6
Training loss: 3.372243532647286
Validation loss: 2.81169516511158

Epoch: 5| Step: 7
Training loss: 3.0032420124673966
Validation loss: 2.8122582280417445

Epoch: 5| Step: 8
Training loss: 3.1529635702799825
Validation loss: 2.8133104922586236

Epoch: 5| Step: 9
Training loss: 3.3598845339417394
Validation loss: 2.813602593255326

Epoch: 5| Step: 10
Training loss: 2.666482938954028
Validation loss: 2.8131320913041598

Epoch: 243| Step: 0
Training loss: 2.933178096333738
Validation loss: 2.8130066245573633

Epoch: 5| Step: 1
Training loss: 2.6686521132516505
Validation loss: 2.811672354167355

Epoch: 5| Step: 2
Training loss: 3.5730437468384415
Validation loss: 2.814229832941664

Epoch: 5| Step: 3
Training loss: 2.916715421723271
Validation loss: 2.8146461001139915

Epoch: 5| Step: 4
Training loss: 3.211986658070979
Validation loss: 2.8082479285446067

Epoch: 5| Step: 5
Training loss: 2.494337631247712
Validation loss: 2.8122733313077144

Epoch: 5| Step: 6
Training loss: 2.8565873695979414
Validation loss: 2.807340016341465

Epoch: 5| Step: 7
Training loss: 4.016012803881778
Validation loss: 2.8111327973979425

Epoch: 5| Step: 8
Training loss: 3.5564090793743
Validation loss: 2.8052028694716644

Epoch: 5| Step: 9
Training loss: 3.007325130461889
Validation loss: 2.8049204483934194

Epoch: 5| Step: 10
Training loss: 2.5807551059644673
Validation loss: 2.801805394524295

Epoch: 244| Step: 0
Training loss: 3.254347314513533
Validation loss: 2.802417949387853

Epoch: 5| Step: 1
Training loss: 3.4609645041624257
Validation loss: 2.8000228765171347

Epoch: 5| Step: 2
Training loss: 3.039352756162338
Validation loss: 2.8040453800504515

Epoch: 5| Step: 3
Training loss: 2.697042424208818
Validation loss: 2.80152450870773

Epoch: 5| Step: 4
Training loss: 3.065529084333491
Validation loss: 2.801903200396049

Epoch: 5| Step: 5
Training loss: 2.7373290753239314
Validation loss: 2.7982979199929536

Epoch: 5| Step: 6
Training loss: 2.708785552393131
Validation loss: 2.7996358072805827

Epoch: 5| Step: 7
Training loss: 3.248634638453539
Validation loss: 2.798229736146691

Epoch: 5| Step: 8
Training loss: 3.426477133213294
Validation loss: 2.794640270726629

Epoch: 5| Step: 9
Training loss: 3.05718002678719
Validation loss: 2.795851074043138

Epoch: 5| Step: 10
Training loss: 3.3835134154502384
Validation loss: 2.800369269694956

Epoch: 245| Step: 0
Training loss: 2.3700284622994245
Validation loss: 2.79598841797229

Epoch: 5| Step: 1
Training loss: 3.427681651348433
Validation loss: 2.79675990088001

Epoch: 5| Step: 2
Training loss: 3.143188948269952
Validation loss: 2.799042411478163

Epoch: 5| Step: 3
Training loss: 3.2367686384528738
Validation loss: 2.7993255950098135

Epoch: 5| Step: 4
Training loss: 3.16693376786621
Validation loss: 2.7973852571512214

Epoch: 5| Step: 5
Training loss: 3.3516282295237385
Validation loss: 2.796286291779288

Epoch: 5| Step: 6
Training loss: 2.2786637369088316
Validation loss: 2.795462066230031

Epoch: 5| Step: 7
Training loss: 3.060896628916533
Validation loss: 2.797530734830209

Epoch: 5| Step: 8
Training loss: 3.313928116335914
Validation loss: 2.793947879401131

Epoch: 5| Step: 9
Training loss: 3.2937422055581105
Validation loss: 2.7975231122537734

Epoch: 5| Step: 10
Training loss: 3.2753702434890615
Validation loss: 2.7959848576489135

Epoch: 246| Step: 0
Training loss: 3.1142425010402843
Validation loss: 2.7964328057226417

Epoch: 5| Step: 1
Training loss: 3.1353159198649183
Validation loss: 2.79897866233783

Epoch: 5| Step: 2
Training loss: 3.4792888109767475
Validation loss: 2.80039950185479

Epoch: 5| Step: 3
Training loss: 3.13883199799631
Validation loss: 2.794647704855556

Epoch: 5| Step: 4
Training loss: 2.5592439014734416
Validation loss: 2.797584301217582

Epoch: 5| Step: 5
Training loss: 3.0286627670868675
Validation loss: 2.801750712001716

Epoch: 5| Step: 6
Training loss: 3.6457936021365613
Validation loss: 2.799064982806425

Epoch: 5| Step: 7
Training loss: 3.016938709054981
Validation loss: 2.7994079064898143

Epoch: 5| Step: 8
Training loss: 2.9381742312378876
Validation loss: 2.7994948364338192

Epoch: 5| Step: 9
Training loss: 3.151671308342232
Validation loss: 2.8015627664333107

Epoch: 5| Step: 10
Training loss: 2.671844660714992
Validation loss: 2.796997157472476

Epoch: 247| Step: 0
Training loss: 3.07466000173706
Validation loss: 2.7978268464111014

Epoch: 5| Step: 1
Training loss: 2.912224811438148
Validation loss: 2.798619422773706

Epoch: 5| Step: 2
Training loss: 3.5036107920041784
Validation loss: 2.7986305745933

Epoch: 5| Step: 3
Training loss: 2.792075615910966
Validation loss: 2.796222004889819

Epoch: 5| Step: 4
Training loss: 3.123578473068508
Validation loss: 2.795639860706191

Epoch: 5| Step: 5
Training loss: 3.3511308156397406
Validation loss: 2.7964038939059503

Epoch: 5| Step: 6
Training loss: 3.3569175070637285
Validation loss: 2.7996010331654997

Epoch: 5| Step: 7
Training loss: 2.819281645920364
Validation loss: 2.792740609910636

Epoch: 5| Step: 8
Training loss: 3.097980727606782
Validation loss: 2.7947221000960907

Epoch: 5| Step: 9
Training loss: 2.769670103651831
Validation loss: 2.792037770842732

Epoch: 5| Step: 10
Training loss: 3.211031947173912
Validation loss: 2.795609902618298

Epoch: 248| Step: 0
Training loss: 3.510571726346749
Validation loss: 2.7912007666867416

Epoch: 5| Step: 1
Training loss: 2.8977072893565423
Validation loss: 2.790018060617441

Epoch: 5| Step: 2
Training loss: 2.940867016164229
Validation loss: 2.789717431936269

Epoch: 5| Step: 3
Training loss: 3.052437424326853
Validation loss: 2.7922893675146665

Epoch: 5| Step: 4
Training loss: 3.235343161634505
Validation loss: 2.792101316695842

Epoch: 5| Step: 5
Training loss: 3.011764981203207
Validation loss: 2.793597205097199

Epoch: 5| Step: 6
Training loss: 2.9123371324311016
Validation loss: 2.7952214775672797

Epoch: 5| Step: 7
Training loss: 3.060267043086273
Validation loss: 2.7919792241533696

Epoch: 5| Step: 8
Training loss: 3.2997077234477397
Validation loss: 2.7898829226570037

Epoch: 5| Step: 9
Training loss: 2.9831957659269093
Validation loss: 2.789198663479125

Epoch: 5| Step: 10
Training loss: 3.1297493511912
Validation loss: 2.792499183624334

Epoch: 249| Step: 0
Training loss: 3.000001589456773
Validation loss: 2.786824209584794

Epoch: 5| Step: 1
Training loss: 2.6578674777185127
Validation loss: 2.7868891612471085

Epoch: 5| Step: 2
Training loss: 3.1270292178729564
Validation loss: 2.788877261405478

Epoch: 5| Step: 3
Training loss: 3.308082514046282
Validation loss: 2.787264225256857

Epoch: 5| Step: 4
Training loss: 3.0406904003798076
Validation loss: 2.7899116383270823

Epoch: 5| Step: 5
Training loss: 3.5706161937474823
Validation loss: 2.7876396397689995

Epoch: 5| Step: 6
Training loss: 3.1232963495768815
Validation loss: 2.788722988858351

Epoch: 5| Step: 7
Training loss: 2.540444053972361
Validation loss: 2.7909768222119165

Epoch: 5| Step: 8
Training loss: 3.325946793525756
Validation loss: 2.787224697882122

Epoch: 5| Step: 9
Training loss: 3.4550149155997287
Validation loss: 2.7951845619891094

Epoch: 5| Step: 10
Training loss: 2.731887121546761
Validation loss: 2.7948845931462456

Epoch: 250| Step: 0
Training loss: 2.6086821407161707
Validation loss: 2.7895937848741776

Epoch: 5| Step: 1
Training loss: 3.237478343051659
Validation loss: 2.786281317783927

Epoch: 5| Step: 2
Training loss: 3.2213653013283126
Validation loss: 2.787004040672604

Epoch: 5| Step: 3
Training loss: 2.8308454885625154
Validation loss: 2.787349228138536

Epoch: 5| Step: 4
Training loss: 3.0876852373780057
Validation loss: 2.785579118473531

Epoch: 5| Step: 5
Training loss: 2.666476501201074
Validation loss: 2.7838578054320156

Epoch: 5| Step: 6
Training loss: 2.840760053019791
Validation loss: 2.7870784688562655

Epoch: 5| Step: 7
Training loss: 2.670343060260003
Validation loss: 2.787047113487359

Epoch: 5| Step: 8
Training loss: 3.718760514444826
Validation loss: 2.7916255030186083

Epoch: 5| Step: 9
Training loss: 3.408960506372696
Validation loss: 2.7916290881866774

Epoch: 5| Step: 10
Training loss: 3.6034431098733544
Validation loss: 2.7934485050620523

Epoch: 251| Step: 0
Training loss: 3.0589459095936666
Validation loss: 2.792103670898313

Epoch: 5| Step: 1
Training loss: 3.551489831707144
Validation loss: 2.7850957204421114

Epoch: 5| Step: 2
Training loss: 2.6796563594332166
Validation loss: 2.7833775264873326

Epoch: 5| Step: 3
Training loss: 3.1503477903647954
Validation loss: 2.785399665706699

Epoch: 5| Step: 4
Training loss: 3.134307428546317
Validation loss: 2.7818662166567156

Epoch: 5| Step: 5
Training loss: 2.8285080455377662
Validation loss: 2.7803488535799286

Epoch: 5| Step: 6
Training loss: 3.311552380025026
Validation loss: 2.780564199072252

Epoch: 5| Step: 7
Training loss: 2.7669208314114417
Validation loss: 2.7801706806053814

Epoch: 5| Step: 8
Training loss: 2.840623751095538
Validation loss: 2.7813986922518095

Epoch: 5| Step: 9
Training loss: 3.2398243576289953
Validation loss: 2.7831259992585577

Epoch: 5| Step: 10
Training loss: 3.38905713092806
Validation loss: 2.7810481856523754

Epoch: 252| Step: 0
Training loss: 2.904196557247364
Validation loss: 2.781268868331075

Epoch: 5| Step: 1
Training loss: 2.689814081396792
Validation loss: 2.7828294703475978

Epoch: 5| Step: 2
Training loss: 3.0800138767970195
Validation loss: 2.7833289248135795

Epoch: 5| Step: 3
Training loss: 3.0948965086758657
Validation loss: 2.786736434538695

Epoch: 5| Step: 4
Training loss: 3.477052529764077
Validation loss: 2.787447679204197

Epoch: 5| Step: 5
Training loss: 2.942106166207689
Validation loss: 2.7861632055780263

Epoch: 5| Step: 6
Training loss: 2.8938664587986542
Validation loss: 2.779044987662449

Epoch: 5| Step: 7
Training loss: 3.781284678907026
Validation loss: 2.7764216368103476

Epoch: 5| Step: 8
Training loss: 2.901270055541308
Validation loss: 2.780534794946472

Epoch: 5| Step: 9
Training loss: 3.01860207773783
Validation loss: 2.7817091614087524

Epoch: 5| Step: 10
Training loss: 3.102379679225653
Validation loss: 2.780469861731507

Epoch: 253| Step: 0
Training loss: 2.8432707330297813
Validation loss: 2.7784991180583805

Epoch: 5| Step: 1
Training loss: 3.526915734431193
Validation loss: 2.7818891512828

Epoch: 5| Step: 2
Training loss: 3.415741043004251
Validation loss: 2.7836377645392067

Epoch: 5| Step: 3
Training loss: 2.771818392239009
Validation loss: 2.7817919264119753

Epoch: 5| Step: 4
Training loss: 3.5937975009598513
Validation loss: 2.786836149132476

Epoch: 5| Step: 5
Training loss: 3.2621574426635354
Validation loss: 2.784359727137218

Epoch: 5| Step: 6
Training loss: 2.615384337589197
Validation loss: 2.7842291002555313

Epoch: 5| Step: 7
Training loss: 3.330616336409657
Validation loss: 2.7840297883049834

Epoch: 5| Step: 8
Training loss: 2.591543523023697
Validation loss: 2.786103947464216

Epoch: 5| Step: 9
Training loss: 2.8487781046895
Validation loss: 2.7835075044163737

Epoch: 5| Step: 10
Training loss: 3.000891394109544
Validation loss: 2.7797918014723755

Epoch: 254| Step: 0
Training loss: 3.0243415368080053
Validation loss: 2.772986282879169

Epoch: 5| Step: 1
Training loss: 2.3775184730108947
Validation loss: 2.7728410161721

Epoch: 5| Step: 2
Training loss: 3.1025970040525186
Validation loss: 2.7752906913125885

Epoch: 5| Step: 3
Training loss: 3.2649332436342684
Validation loss: 2.773954401025039

Epoch: 5| Step: 4
Training loss: 2.907200155500241
Validation loss: 2.7745865642178544

Epoch: 5| Step: 5
Training loss: 2.839570379939006
Validation loss: 2.778380573523963

Epoch: 5| Step: 6
Training loss: 3.3455789858117497
Validation loss: 2.776952718281719

Epoch: 5| Step: 7
Training loss: 3.120127579697091
Validation loss: 2.7766377577604877

Epoch: 5| Step: 8
Training loss: 3.6378237708023393
Validation loss: 2.7789460073574315

Epoch: 5| Step: 9
Training loss: 2.974658427143982
Validation loss: 2.7783368551615055

Epoch: 5| Step: 10
Training loss: 3.299710902642173
Validation loss: 2.7758948128293097

Epoch: 255| Step: 0
Training loss: 3.233854979944375
Validation loss: 2.776331184698595

Epoch: 5| Step: 1
Training loss: 2.876995886583938
Validation loss: 2.7761593306800103

Epoch: 5| Step: 2
Training loss: 3.457710087393377
Validation loss: 2.7730359292961864

Epoch: 5| Step: 3
Training loss: 2.6879584342830887
Validation loss: 2.775110159382419

Epoch: 5| Step: 4
Training loss: 2.9038477988488642
Validation loss: 2.7747194679567344

Epoch: 5| Step: 5
Training loss: 2.8586743439611615
Validation loss: 2.7757722198654475

Epoch: 5| Step: 6
Training loss: 3.557502587666646
Validation loss: 2.7750202576203558

Epoch: 5| Step: 7
Training loss: 3.321378218214935
Validation loss: 2.774663648293269

Epoch: 5| Step: 8
Training loss: 3.0777871193344284
Validation loss: 2.7792940653493314

Epoch: 5| Step: 9
Training loss: 3.07974943875793
Validation loss: 2.7795448288605025

Epoch: 5| Step: 10
Training loss: 2.7075645725091473
Validation loss: 2.779267422414364

Epoch: 256| Step: 0
Training loss: 3.407057640150173
Validation loss: 2.7861193526155206

Epoch: 5| Step: 1
Training loss: 3.2941239436073393
Validation loss: 2.784577245461207

Epoch: 5| Step: 2
Training loss: 3.3867439524274934
Validation loss: 2.7793999759617387

Epoch: 5| Step: 3
Training loss: 2.831807978806651
Validation loss: 2.779878892949681

Epoch: 5| Step: 4
Training loss: 2.971409459760009
Validation loss: 2.7790011930369376

Epoch: 5| Step: 5
Training loss: 3.1103951012455076
Validation loss: 2.7775618269938755

Epoch: 5| Step: 6
Training loss: 2.2328445421593246
Validation loss: 2.7753673050598047

Epoch: 5| Step: 7
Training loss: 3.775630968932479
Validation loss: 2.773926436964305

Epoch: 5| Step: 8
Training loss: 2.9975644397569847
Validation loss: 2.7703405110525425

Epoch: 5| Step: 9
Training loss: 2.7510526549757675
Validation loss: 2.7707708747875066

Epoch: 5| Step: 10
Training loss: 2.928556585108127
Validation loss: 2.774773059875028

Epoch: 257| Step: 0
Training loss: 2.484322697310834
Validation loss: 2.770879676783492

Epoch: 5| Step: 1
Training loss: 2.5785464780360448
Validation loss: 2.769803170177872

Epoch: 5| Step: 2
Training loss: 3.6683780982061984
Validation loss: 2.771619731573336

Epoch: 5| Step: 3
Training loss: 2.3519212822943567
Validation loss: 2.769276561817269

Epoch: 5| Step: 4
Training loss: 3.1599478635229263
Validation loss: 2.768273568199801

Epoch: 5| Step: 5
Training loss: 2.927948865610762
Validation loss: 2.766837441350126

Epoch: 5| Step: 6
Training loss: 3.847130754089663
Validation loss: 2.768747491274535

Epoch: 5| Step: 7
Training loss: 3.1671261872283583
Validation loss: 2.7702310826528262

Epoch: 5| Step: 8
Training loss: 3.271484083488793
Validation loss: 2.771128252426842

Epoch: 5| Step: 9
Training loss: 3.5294306296424085
Validation loss: 2.7667600558378243

Epoch: 5| Step: 10
Training loss: 2.420018228824783
Validation loss: 2.7694108932434904

Epoch: 258| Step: 0
Training loss: 2.991987814353159
Validation loss: 2.768830850660954

Epoch: 5| Step: 1
Training loss: 3.6582951490861353
Validation loss: 2.77249555732271

Epoch: 5| Step: 2
Training loss: 2.8500265086764878
Validation loss: 2.772374298204464

Epoch: 5| Step: 3
Training loss: 3.2555768508851153
Validation loss: 2.7739251930015874

Epoch: 5| Step: 4
Training loss: 2.9414770920772666
Validation loss: 2.7717091748004226

Epoch: 5| Step: 5
Training loss: 3.384726038204382
Validation loss: 2.7725070916195578

Epoch: 5| Step: 6
Training loss: 3.0898508488975027
Validation loss: 2.7682549743187135

Epoch: 5| Step: 7
Training loss: 3.4550436221955887
Validation loss: 2.7680917487993146

Epoch: 5| Step: 8
Training loss: 2.427467534076986
Validation loss: 2.7703702417676124

Epoch: 5| Step: 9
Training loss: 3.135257518358085
Validation loss: 2.770552688907146

Epoch: 5| Step: 10
Training loss: 2.341040711099008
Validation loss: 2.7714742110116295

Epoch: 259| Step: 0
Training loss: 2.677099373815155
Validation loss: 2.770524048334668

Epoch: 5| Step: 1
Training loss: 3.0660437497217026
Validation loss: 2.7713723590928065

Epoch: 5| Step: 2
Training loss: 3.224397020377536
Validation loss: 2.7686783546899

Epoch: 5| Step: 3
Training loss: 2.62909660387064
Validation loss: 2.7649674266207986

Epoch: 5| Step: 4
Training loss: 3.3005486581327883
Validation loss: 2.769236928589661

Epoch: 5| Step: 5
Training loss: 2.888768605230511
Validation loss: 2.7666822771308297

Epoch: 5| Step: 6
Training loss: 3.0327343010389556
Validation loss: 2.7701284242994473

Epoch: 5| Step: 7
Training loss: 3.294485084693297
Validation loss: 2.7663077430608713

Epoch: 5| Step: 8
Training loss: 3.0035460495496213
Validation loss: 2.7683167713105945

Epoch: 5| Step: 9
Training loss: 2.8744554418566377
Validation loss: 2.7658566743508803

Epoch: 5| Step: 10
Training loss: 3.861374804108974
Validation loss: 2.7650539892573645

Epoch: 260| Step: 0
Training loss: 3.0073114943943544
Validation loss: 2.7663386041683578

Epoch: 5| Step: 1
Training loss: 2.5634942335700455
Validation loss: 2.767911293789598

Epoch: 5| Step: 2
Training loss: 3.2275724516049036
Validation loss: 2.7685946231012006

Epoch: 5| Step: 3
Training loss: 3.2474177445705172
Validation loss: 2.7668490566807082

Epoch: 5| Step: 4
Training loss: 2.9209343523159763
Validation loss: 2.7666453476949404

Epoch: 5| Step: 5
Training loss: 2.8663262261204494
Validation loss: 2.7654986108453183

Epoch: 5| Step: 6
Training loss: 3.366707964602944
Validation loss: 2.7676443425424906

Epoch: 5| Step: 7
Training loss: 3.3708866625992995
Validation loss: 2.766949709409486

Epoch: 5| Step: 8
Training loss: 3.376682427292018
Validation loss: 2.7663957372237573

Epoch: 5| Step: 9
Training loss: 2.986334671602128
Validation loss: 2.766207364466646

Epoch: 5| Step: 10
Training loss: 2.7876377259857694
Validation loss: 2.767810615824069

Epoch: 261| Step: 0
Training loss: 2.950893628821304
Validation loss: 2.768568466125325

Epoch: 5| Step: 1
Training loss: 2.9571047815329177
Validation loss: 2.7668893717657577

Epoch: 5| Step: 2
Training loss: 3.2690599983803073
Validation loss: 2.768660810776598

Epoch: 5| Step: 3
Training loss: 2.9790749346786605
Validation loss: 2.7690368087871056

Epoch: 5| Step: 4
Training loss: 3.2766867741860053
Validation loss: 2.772340221528118

Epoch: 5| Step: 5
Training loss: 3.17767705320534
Validation loss: 2.771040136549145

Epoch: 5| Step: 6
Training loss: 2.7079232908059194
Validation loss: 2.7744674468708235

Epoch: 5| Step: 7
Training loss: 3.3208435351998022
Validation loss: 2.7709212738325375

Epoch: 5| Step: 8
Training loss: 3.12828836995734
Validation loss: 2.7667905662874834

Epoch: 5| Step: 9
Training loss: 2.7492473612730444
Validation loss: 2.767079292564932

Epoch: 5| Step: 10
Training loss: 3.299233844712613
Validation loss: 2.767772406550333

Epoch: 262| Step: 0
Training loss: 3.287969774687385
Validation loss: 2.767868295526773

Epoch: 5| Step: 1
Training loss: 3.4933460199936213
Validation loss: 2.769974904885332

Epoch: 5| Step: 2
Training loss: 3.3280802978952115
Validation loss: 2.7681105151115704

Epoch: 5| Step: 3
Training loss: 2.4720452444139625
Validation loss: 2.7703876508557586

Epoch: 5| Step: 4
Training loss: 3.0011918561419972
Validation loss: 2.7664891403841883

Epoch: 5| Step: 5
Training loss: 2.954248608168782
Validation loss: 2.7659127579492555

Epoch: 5| Step: 6
Training loss: 2.9150267941010677
Validation loss: 2.766432406810199

Epoch: 5| Step: 7
Training loss: 3.348869611277788
Validation loss: 2.7673777138628295

Epoch: 5| Step: 8
Training loss: 3.511825610816769
Validation loss: 2.767177443853946

Epoch: 5| Step: 9
Training loss: 2.6876291643197994
Validation loss: 2.7679524019643003

Epoch: 5| Step: 10
Training loss: 2.5602958317533835
Validation loss: 2.7674474591334652

Epoch: 263| Step: 0
Training loss: 3.0973545230573634
Validation loss: 2.7671369912175727

Epoch: 5| Step: 1
Training loss: 2.7857174943199823
Validation loss: 2.76578861950906

Epoch: 5| Step: 2
Training loss: 3.1122032606237355
Validation loss: 2.765972340197147

Epoch: 5| Step: 3
Training loss: 3.1524644566225573
Validation loss: 2.761742960292357

Epoch: 5| Step: 4
Training loss: 2.9015142762383306
Validation loss: 2.766195555525956

Epoch: 5| Step: 5
Training loss: 3.22736206492738
Validation loss: 2.7676863022246123

Epoch: 5| Step: 6
Training loss: 2.8542083588685254
Validation loss: 2.7693856085881343

Epoch: 5| Step: 7
Training loss: 3.033685865632012
Validation loss: 2.766114006472842

Epoch: 5| Step: 8
Training loss: 3.4210361515065215
Validation loss: 2.7765710271294357

Epoch: 5| Step: 9
Training loss: 3.156776610906605
Validation loss: 2.783703728994368

Epoch: 5| Step: 10
Training loss: 3.0592903912605425
Validation loss: 2.7685471870098093

Epoch: 264| Step: 0
Training loss: 2.5787216883190176
Validation loss: 2.7667275676950553

Epoch: 5| Step: 1
Training loss: 3.1773389536265895
Validation loss: 2.7625841104092457

Epoch: 5| Step: 2
Training loss: 3.5311330590253878
Validation loss: 2.760413196365735

Epoch: 5| Step: 3
Training loss: 3.1436276482193968
Validation loss: 2.7605074278819717

Epoch: 5| Step: 4
Training loss: 3.311296640300213
Validation loss: 2.7598802698181575

Epoch: 5| Step: 5
Training loss: 3.5520475204914685
Validation loss: 2.7574967441173874

Epoch: 5| Step: 6
Training loss: 2.6317080210101427
Validation loss: 2.7593548940533377

Epoch: 5| Step: 7
Training loss: 3.247875693117632
Validation loss: 2.7583053684356766

Epoch: 5| Step: 8
Training loss: 2.719753913125492
Validation loss: 2.758185942048868

Epoch: 5| Step: 9
Training loss: 3.2678521697507565
Validation loss: 2.7609945951053683

Epoch: 5| Step: 10
Training loss: 2.3154424556796838
Validation loss: 2.7612649930912188

Epoch: 265| Step: 0
Training loss: 2.873353071771904
Validation loss: 2.7595724092148926

Epoch: 5| Step: 1
Training loss: 3.0159005943430057
Validation loss: 2.7622890914744453

Epoch: 5| Step: 2
Training loss: 3.407003616819262
Validation loss: 2.7568860718946415

Epoch: 5| Step: 3
Training loss: 3.2553895131870716
Validation loss: 2.7599092753597017

Epoch: 5| Step: 4
Training loss: 2.8037582175567652
Validation loss: 2.759105343197234

Epoch: 5| Step: 5
Training loss: 2.810085871188742
Validation loss: 2.755410297003527

Epoch: 5| Step: 6
Training loss: 2.9136589527674635
Validation loss: 2.7571629584289314

Epoch: 5| Step: 7
Training loss: 3.4340689442044994
Validation loss: 2.7554655074652934

Epoch: 5| Step: 8
Training loss: 3.159343148060569
Validation loss: 2.7582285633221124

Epoch: 5| Step: 9
Training loss: 3.2421729397734054
Validation loss: 2.7579541364476947

Epoch: 5| Step: 10
Training loss: 2.8107691207082017
Validation loss: 2.761251261580708

Epoch: 266| Step: 0
Training loss: 2.944602172353708
Validation loss: 2.7597173905997923

Epoch: 5| Step: 1
Training loss: 3.1278813620701067
Validation loss: 2.7646812338233833

Epoch: 5| Step: 2
Training loss: 2.635997713189298
Validation loss: 2.7620310354377646

Epoch: 5| Step: 3
Training loss: 3.364807704061993
Validation loss: 2.7600912511001225

Epoch: 5| Step: 4
Training loss: 2.639710217090581
Validation loss: 2.759287542910707

Epoch: 5| Step: 5
Training loss: 2.752922845664831
Validation loss: 2.758459944372494

Epoch: 5| Step: 6
Training loss: 2.9305389387755434
Validation loss: 2.756198225031993

Epoch: 5| Step: 7
Training loss: 3.7687981243445488
Validation loss: 2.7608118227551834

Epoch: 5| Step: 8
Training loss: 3.519058517563557
Validation loss: 2.7605986343435958

Epoch: 5| Step: 9
Training loss: 2.6114574049430774
Validation loss: 2.758604347636441

Epoch: 5| Step: 10
Training loss: 3.358595788763847
Validation loss: 2.7579904181834136

Epoch: 267| Step: 0
Training loss: 3.2344401624814227
Validation loss: 2.757572255056499

Epoch: 5| Step: 1
Training loss: 2.7532989481640793
Validation loss: 2.7594202804691927

Epoch: 5| Step: 2
Training loss: 2.833611156829806
Validation loss: 2.7624875545151766

Epoch: 5| Step: 3
Training loss: 3.481300537180865
Validation loss: 2.763737469099866

Epoch: 5| Step: 4
Training loss: 2.969430785172008
Validation loss: 2.765738977403703

Epoch: 5| Step: 5
Training loss: 3.508117390659547
Validation loss: 2.774033685524821

Epoch: 5| Step: 6
Training loss: 3.0804680750993905
Validation loss: 2.7710702057620584

Epoch: 5| Step: 7
Training loss: 2.7141886188235014
Validation loss: 2.7731042685145613

Epoch: 5| Step: 8
Training loss: 3.179460897033357
Validation loss: 2.771913193267784

Epoch: 5| Step: 9
Training loss: 2.963624726233795
Validation loss: 2.767621148149513

Epoch: 5| Step: 10
Training loss: 3.000681481841875
Validation loss: 2.7702250349949447

Epoch: 268| Step: 0
Training loss: 2.718327193433547
Validation loss: 2.766436478707504

Epoch: 5| Step: 1
Training loss: 3.0073232277585027
Validation loss: 2.7623652621189967

Epoch: 5| Step: 2
Training loss: 2.6098266941571344
Validation loss: 2.759468061119832

Epoch: 5| Step: 3
Training loss: 2.7657775836814897
Validation loss: 2.764038630234029

Epoch: 5| Step: 4
Training loss: 2.9599167969325055
Validation loss: 2.7648890170504274

Epoch: 5| Step: 5
Training loss: 2.6773098108897164
Validation loss: 2.764087191754051

Epoch: 5| Step: 6
Training loss: 3.1487505357233783
Validation loss: 2.7543771239251056

Epoch: 5| Step: 7
Training loss: 3.164838530894703
Validation loss: 2.754900897344972

Epoch: 5| Step: 8
Training loss: 4.015852509818461
Validation loss: 2.7537165182898447

Epoch: 5| Step: 9
Training loss: 2.995275910521661
Validation loss: 2.750173941711127

Epoch: 5| Step: 10
Training loss: 3.489229660710671
Validation loss: 2.753763557250899

Epoch: 269| Step: 0
Training loss: 3.1879783720194634
Validation loss: 2.751525891855646

Epoch: 5| Step: 1
Training loss: 2.859383504886173
Validation loss: 2.7514313546016607

Epoch: 5| Step: 2
Training loss: 2.9482192208860343
Validation loss: 2.7511312198747513

Epoch: 5| Step: 3
Training loss: 3.173486459975134
Validation loss: 2.7505941737262845

Epoch: 5| Step: 4
Training loss: 3.462516889289952
Validation loss: 2.7509133284930942

Epoch: 5| Step: 5
Training loss: 2.9547678096837093
Validation loss: 2.752637925449698

Epoch: 5| Step: 6
Training loss: 3.143361583702778
Validation loss: 2.7525953982935127

Epoch: 5| Step: 7
Training loss: 3.1016956368032402
Validation loss: 2.7499457062165384

Epoch: 5| Step: 8
Training loss: 3.4570424225190224
Validation loss: 2.7554471704687784

Epoch: 5| Step: 9
Training loss: 3.0546693923296426
Validation loss: 2.7511934876926176

Epoch: 5| Step: 10
Training loss: 2.070993217983957
Validation loss: 2.7523004841638676

Epoch: 270| Step: 0
Training loss: 2.8362784693009115
Validation loss: 2.7532317524286296

Epoch: 5| Step: 1
Training loss: 3.261237304241695
Validation loss: 2.7587632363014674

Epoch: 5| Step: 2
Training loss: 2.712433152319969
Validation loss: 2.754189566458602

Epoch: 5| Step: 3
Training loss: 3.051755937499424
Validation loss: 2.7486186730061593

Epoch: 5| Step: 4
Training loss: 3.2041037948121605
Validation loss: 2.750198245244189

Epoch: 5| Step: 5
Training loss: 2.99514043131672
Validation loss: 2.748049041182558

Epoch: 5| Step: 6
Training loss: 3.4195006332787323
Validation loss: 2.7500227016432994

Epoch: 5| Step: 7
Training loss: 3.2666979035681076
Validation loss: 2.7480308179552915

Epoch: 5| Step: 8
Training loss: 2.849296610181279
Validation loss: 2.7473878750814373

Epoch: 5| Step: 9
Training loss: 3.008348134885886
Validation loss: 2.7502564798191202

Epoch: 5| Step: 10
Training loss: 3.0924863450189104
Validation loss: 2.7490350693477175

Epoch: 271| Step: 0
Training loss: 3.354666883869902
Validation loss: 2.7438092181655453

Epoch: 5| Step: 1
Training loss: 3.087697128612914
Validation loss: 2.7448225224913796

Epoch: 5| Step: 2
Training loss: 2.802108726717294
Validation loss: 2.7480175166209673

Epoch: 5| Step: 3
Training loss: 2.2422703318963326
Validation loss: 2.7465661182521397

Epoch: 5| Step: 4
Training loss: 2.9269538027157895
Validation loss: 2.747530717002193

Epoch: 5| Step: 5
Training loss: 3.2472795691501104
Validation loss: 2.744000122597986

Epoch: 5| Step: 6
Training loss: 2.9434781218270194
Validation loss: 2.7452044292906432

Epoch: 5| Step: 7
Training loss: 3.3646546504884007
Validation loss: 2.744650516047338

Epoch: 5| Step: 8
Training loss: 2.6958398275478936
Validation loss: 2.742562291912069

Epoch: 5| Step: 9
Training loss: 3.508517799753064
Validation loss: 2.7418744869432676

Epoch: 5| Step: 10
Training loss: 3.3546936063528787
Validation loss: 2.741162094163344

Epoch: 272| Step: 0
Training loss: 3.8901582614114973
Validation loss: 2.742165804882534

Epoch: 5| Step: 1
Training loss: 3.262887637907543
Validation loss: 2.744630227473717

Epoch: 5| Step: 2
Training loss: 2.4968885132539715
Validation loss: 2.7453954281336537

Epoch: 5| Step: 3
Training loss: 2.8352688928608196
Validation loss: 2.7520792857450673

Epoch: 5| Step: 4
Training loss: 2.7161595072025677
Validation loss: 2.753623276793906

Epoch: 5| Step: 5
Training loss: 2.7423333892704793
Validation loss: 2.7484991083388204

Epoch: 5| Step: 6
Training loss: 2.9973837252631115
Validation loss: 2.7578751407799404

Epoch: 5| Step: 7
Training loss: 2.79829873444383
Validation loss: 2.7571661030481707

Epoch: 5| Step: 8
Training loss: 3.286857681475413
Validation loss: 2.7465127665437383

Epoch: 5| Step: 9
Training loss: 3.5514276669405422
Validation loss: 2.7576069223469797

Epoch: 5| Step: 10
Training loss: 2.823599382075826
Validation loss: 2.7440509109858398

Epoch: 273| Step: 0
Training loss: 2.9674192959770966
Validation loss: 2.752689047135594

Epoch: 5| Step: 1
Training loss: 2.813158848204401
Validation loss: 2.750909019275693

Epoch: 5| Step: 2
Training loss: 3.295748405150009
Validation loss: 2.746468522240059

Epoch: 5| Step: 3
Training loss: 3.0977446073267045
Validation loss: 2.751092885643131

Epoch: 5| Step: 4
Training loss: 2.7448574012446847
Validation loss: 2.754236484713898

Epoch: 5| Step: 5
Training loss: 3.139175156299226
Validation loss: 2.75821414934519

Epoch: 5| Step: 6
Training loss: 3.297592591206956
Validation loss: 2.7633078821528874

Epoch: 5| Step: 7
Training loss: 3.228613988689863
Validation loss: 2.7587391754933765

Epoch: 5| Step: 8
Training loss: 3.302306126600649
Validation loss: 2.746094037536168

Epoch: 5| Step: 9
Training loss: 2.919390596263584
Validation loss: 2.7396888171411264

Epoch: 5| Step: 10
Training loss: 2.7980196864026574
Validation loss: 2.738257028879466

Epoch: 274| Step: 0
Training loss: 2.759464277160302
Validation loss: 2.739976710972122

Epoch: 5| Step: 1
Training loss: 3.1257515575750126
Validation loss: 2.7417542232991576

Epoch: 5| Step: 2
Training loss: 3.3670739245455383
Validation loss: 2.741801391751373

Epoch: 5| Step: 3
Training loss: 3.2498229051903884
Validation loss: 2.7445984815003217

Epoch: 5| Step: 4
Training loss: 2.903798535812096
Validation loss: 2.7457926364293885

Epoch: 5| Step: 5
Training loss: 3.385761482089167
Validation loss: 2.747061682001635

Epoch: 5| Step: 6
Training loss: 2.5794792548726497
Validation loss: 2.747186655466807

Epoch: 5| Step: 7
Training loss: 2.9335053248990257
Validation loss: 2.749969783367112

Epoch: 5| Step: 8
Training loss: 3.2556722000224507
Validation loss: 2.7483650644441253

Epoch: 5| Step: 9
Training loss: 3.0825179456697374
Validation loss: 2.7469369081706776

Epoch: 5| Step: 10
Training loss: 3.0567922536273113
Validation loss: 2.747567860432827

Epoch: 275| Step: 0
Training loss: 3.0933746726737694
Validation loss: 2.7460794963836386

Epoch: 5| Step: 1
Training loss: 3.2106369137742505
Validation loss: 2.751238224417524

Epoch: 5| Step: 2
Training loss: 2.7454456416473145
Validation loss: 2.753099721244264

Epoch: 5| Step: 3
Training loss: 3.288458326941332
Validation loss: 2.7619117914994686

Epoch: 5| Step: 4
Training loss: 3.1228007397926016
Validation loss: 2.7510861929976245

Epoch: 5| Step: 5
Training loss: 3.2551349275577572
Validation loss: 2.748721950963364

Epoch: 5| Step: 6
Training loss: 2.9357122297283103
Validation loss: 2.7469168184736943

Epoch: 5| Step: 7
Training loss: 2.8078857717999868
Validation loss: 2.743264541325156

Epoch: 5| Step: 8
Training loss: 2.451289759988965
Validation loss: 2.7427904576136024

Epoch: 5| Step: 9
Training loss: 3.5195048306878145
Validation loss: 2.7465301989770214

Epoch: 5| Step: 10
Training loss: 3.1331146170662696
Validation loss: 2.7448499933760178

Epoch: 276| Step: 0
Training loss: 3.006153947402055
Validation loss: 2.7456888710737997

Epoch: 5| Step: 1
Training loss: 2.5712414022477184
Validation loss: 2.7437079445160593

Epoch: 5| Step: 2
Training loss: 2.8937674272642755
Validation loss: 2.7496534214905677

Epoch: 5| Step: 3
Training loss: 3.3719810829763257
Validation loss: 2.7550370984512424

Epoch: 5| Step: 4
Training loss: 3.344573587970754
Validation loss: 2.751146916371226

Epoch: 5| Step: 5
Training loss: 2.6907771334465185
Validation loss: 2.7601493187452633

Epoch: 5| Step: 6
Training loss: 3.541694521326968
Validation loss: 2.751557840211031

Epoch: 5| Step: 7
Training loss: 2.6950280080836766
Validation loss: 2.7365431123805672

Epoch: 5| Step: 8
Training loss: 3.201461285489455
Validation loss: 2.7366981043958445

Epoch: 5| Step: 9
Training loss: 3.260283121089806
Validation loss: 2.7375432133781543

Epoch: 5| Step: 10
Training loss: 2.898925575640573
Validation loss: 2.734323732800822

Epoch: 277| Step: 0
Training loss: 3.0427026595589823
Validation loss: 2.7342661068002037

Epoch: 5| Step: 1
Training loss: 2.981467063567071
Validation loss: 2.7340078784231303

Epoch: 5| Step: 2
Training loss: 2.9982164167248757
Validation loss: 2.733749193339887

Epoch: 5| Step: 3
Training loss: 3.122242741123289
Validation loss: 2.7343366244621925

Epoch: 5| Step: 4
Training loss: 2.8289486860554685
Validation loss: 2.7343172353804546

Epoch: 5| Step: 5
Training loss: 2.713722930731026
Validation loss: 2.7335841756601305

Epoch: 5| Step: 6
Training loss: 3.3101245351914725
Validation loss: 2.7338528642349345

Epoch: 5| Step: 7
Training loss: 2.919593613968824
Validation loss: 2.7344768236834627

Epoch: 5| Step: 8
Training loss: 3.2067237548610628
Validation loss: 2.7382667553642257

Epoch: 5| Step: 9
Training loss: 3.1018810348867096
Validation loss: 2.7358736052732002

Epoch: 5| Step: 10
Training loss: 3.4077693805301594
Validation loss: 2.7397004015969117

Epoch: 278| Step: 0
Training loss: 3.044176833912638
Validation loss: 2.733906226693513

Epoch: 5| Step: 1
Training loss: 3.080941397976617
Validation loss: 2.736839955849439

Epoch: 5| Step: 2
Training loss: 3.5138648480048214
Validation loss: 2.732716260756842

Epoch: 5| Step: 3
Training loss: 3.3702574009607145
Validation loss: 2.734285033074657

Epoch: 5| Step: 4
Training loss: 3.2604303979229043
Validation loss: 2.7348320007483355

Epoch: 5| Step: 5
Training loss: 3.1279347181800787
Validation loss: 2.7327891749299584

Epoch: 5| Step: 6
Training loss: 2.8307712040610435
Validation loss: 2.733903941467056

Epoch: 5| Step: 7
Training loss: 2.8568749676864846
Validation loss: 2.731982111772876

Epoch: 5| Step: 8
Training loss: 2.606832670582869
Validation loss: 2.739972459406027

Epoch: 5| Step: 9
Training loss: 3.2213065355377837
Validation loss: 2.736761762399106

Epoch: 5| Step: 10
Training loss: 2.457429450294317
Validation loss: 2.7371413040800197

Epoch: 279| Step: 0
Training loss: 3.7460108838348405
Validation loss: 2.7366332711187895

Epoch: 5| Step: 1
Training loss: 2.7806338367077377
Validation loss: 2.73932711793052

Epoch: 5| Step: 2
Training loss: 2.7082640027684537
Validation loss: 2.7363146787102566

Epoch: 5| Step: 3
Training loss: 3.4085781994993236
Validation loss: 2.738931326962493

Epoch: 5| Step: 4
Training loss: 3.3241005505572248
Validation loss: 2.743442466645028

Epoch: 5| Step: 5
Training loss: 2.849701072676445
Validation loss: 2.7481097337145375

Epoch: 5| Step: 6
Training loss: 2.967152537159486
Validation loss: 2.7462794323489716

Epoch: 5| Step: 7
Training loss: 2.110863167719711
Validation loss: 2.7459607930375793

Epoch: 5| Step: 8
Training loss: 2.798198365559093
Validation loss: 2.7482763801052985

Epoch: 5| Step: 9
Training loss: 3.4241403545062807
Validation loss: 2.74496817551997

Epoch: 5| Step: 10
Training loss: 3.1963447078776013
Validation loss: 2.747023779533063

Epoch: 280| Step: 0
Training loss: 3.1386144474950113
Validation loss: 2.744975241714856

Epoch: 5| Step: 1
Training loss: 3.3643333570527654
Validation loss: 2.7400019863215177

Epoch: 5| Step: 2
Training loss: 2.723522251055763
Validation loss: 2.738417268522616

Epoch: 5| Step: 3
Training loss: 3.2563745632252608
Validation loss: 2.7379628502884645

Epoch: 5| Step: 4
Training loss: 2.6754965526292693
Validation loss: 2.738782970635715

Epoch: 5| Step: 5
Training loss: 2.862661838537491
Validation loss: 2.739266873760122

Epoch: 5| Step: 6
Training loss: 2.907580655554492
Validation loss: 2.737181686764719

Epoch: 5| Step: 7
Training loss: 3.0111183132008863
Validation loss: 2.7382014002875175

Epoch: 5| Step: 8
Training loss: 3.366230910651146
Validation loss: 2.739754926483378

Epoch: 5| Step: 9
Training loss: 2.7364498440819314
Validation loss: 2.7342538683147017

Epoch: 5| Step: 10
Training loss: 3.4613535611580906
Validation loss: 2.735016564550021

Epoch: 281| Step: 0
Training loss: 2.2759331183369746
Validation loss: 2.7345971280069428

Epoch: 5| Step: 1
Training loss: 2.389232154944799
Validation loss: 2.7354938952002468

Epoch: 5| Step: 2
Training loss: 3.1091708782422787
Validation loss: 2.7360441292932323

Epoch: 5| Step: 3
Training loss: 3.0353666058358963
Validation loss: 2.7320293194461085

Epoch: 5| Step: 4
Training loss: 3.677773919604513
Validation loss: 2.7334369134323007

Epoch: 5| Step: 5
Training loss: 2.9807912669538665
Validation loss: 2.731651723435503

Epoch: 5| Step: 6
Training loss: 3.375276059763743
Validation loss: 2.731315271139186

Epoch: 5| Step: 7
Training loss: 3.281927710890616
Validation loss: 2.731685089533415

Epoch: 5| Step: 8
Training loss: 3.1723122882546457
Validation loss: 2.7315060895784598

Epoch: 5| Step: 9
Training loss: 2.807288448824952
Validation loss: 2.729001846603181

Epoch: 5| Step: 10
Training loss: 3.1894148516533978
Validation loss: 2.727955627840821

Epoch: 282| Step: 0
Training loss: 3.4913766077387627
Validation loss: 2.730948716406069

Epoch: 5| Step: 1
Training loss: 3.527332529787318
Validation loss: 2.731731200579067

Epoch: 5| Step: 2
Training loss: 3.1344215275514444
Validation loss: 2.727207801259819

Epoch: 5| Step: 3
Training loss: 2.6033004133786335
Validation loss: 2.7272543376881844

Epoch: 5| Step: 4
Training loss: 2.4724994627794814
Validation loss: 2.7294994487332365

Epoch: 5| Step: 5
Training loss: 2.9871257467757832
Validation loss: 2.7323464515122717

Epoch: 5| Step: 6
Training loss: 3.3409900148271627
Validation loss: 2.7345792135694316

Epoch: 5| Step: 7
Training loss: 2.541981307602533
Validation loss: 2.7321329899187834

Epoch: 5| Step: 8
Training loss: 3.406504910231332
Validation loss: 2.730141266941297

Epoch: 5| Step: 9
Training loss: 2.934609959694738
Validation loss: 2.733122341042088

Epoch: 5| Step: 10
Training loss: 2.7957531261356685
Validation loss: 2.7282683678818183

Epoch: 283| Step: 0
Training loss: 3.0766272604400124
Validation loss: 2.729164712193314

Epoch: 5| Step: 1
Training loss: 3.011376743713434
Validation loss: 2.7321945267427177

Epoch: 5| Step: 2
Training loss: 2.9812098790314097
Validation loss: 2.729741815943873

Epoch: 5| Step: 3
Training loss: 3.3230417321724635
Validation loss: 2.7307074580356567

Epoch: 5| Step: 4
Training loss: 3.331434297026257
Validation loss: 2.7311056526441235

Epoch: 5| Step: 5
Training loss: 2.711534329987171
Validation loss: 2.732205388577304

Epoch: 5| Step: 6
Training loss: 2.4041957260658706
Validation loss: 2.7270861867104794

Epoch: 5| Step: 7
Training loss: 2.8808355401556383
Validation loss: 2.7291388029210233

Epoch: 5| Step: 8
Training loss: 3.1699248835090468
Validation loss: 2.7267105387205386

Epoch: 5| Step: 9
Training loss: 2.7186822115460108
Validation loss: 2.727683340474507

Epoch: 5| Step: 10
Training loss: 3.7750705636610444
Validation loss: 2.7265260520440773

Epoch: 284| Step: 0
Training loss: 2.621004697193651
Validation loss: 2.7264692645109165

Epoch: 5| Step: 1
Training loss: 3.0459937753094035
Validation loss: 2.7306545813478156

Epoch: 5| Step: 2
Training loss: 3.2626362680791807
Validation loss: 2.726553926819644

Epoch: 5| Step: 3
Training loss: 2.8395740743044393
Validation loss: 2.72107149424259

Epoch: 5| Step: 4
Training loss: 2.751663398517383
Validation loss: 2.7219531810371382

Epoch: 5| Step: 5
Training loss: 3.610648586941658
Validation loss: 2.7198063475850573

Epoch: 5| Step: 6
Training loss: 3.0205089175656723
Validation loss: 2.7245144598798223

Epoch: 5| Step: 7
Training loss: 3.1847315714978426
Validation loss: 2.726153960529823

Epoch: 5| Step: 8
Training loss: 3.213598777391288
Validation loss: 2.7231294387280025

Epoch: 5| Step: 9
Training loss: 2.5662370739224336
Validation loss: 2.7264856412936775

Epoch: 5| Step: 10
Training loss: 3.239341129844983
Validation loss: 2.726376037117133

Epoch: 285| Step: 0
Training loss: 3.278404818830025
Validation loss: 2.7271549657621765

Epoch: 5| Step: 1
Training loss: 2.6773079408065867
Validation loss: 2.726286175781835

Epoch: 5| Step: 2
Training loss: 3.214057687209647
Validation loss: 2.7255409358607374

Epoch: 5| Step: 3
Training loss: 2.6999007383396907
Validation loss: 2.7240025586477357

Epoch: 5| Step: 4
Training loss: 3.163142920720127
Validation loss: 2.7298363295575774

Epoch: 5| Step: 5
Training loss: 2.8804101212207027
Validation loss: 2.731500038773907

Epoch: 5| Step: 6
Training loss: 3.4565001688642223
Validation loss: 2.7266480385167355

Epoch: 5| Step: 7
Training loss: 3.2948638422479064
Validation loss: 2.7296741248338905

Epoch: 5| Step: 8
Training loss: 2.9738170547910663
Validation loss: 2.7284394912467884

Epoch: 5| Step: 9
Training loss: 3.081153270758414
Validation loss: 2.729090293999882

Epoch: 5| Step: 10
Training loss: 2.560944154648109
Validation loss: 2.7319061928643005

Epoch: 286| Step: 0
Training loss: 2.9022583159532047
Validation loss: 2.7285254284909866

Epoch: 5| Step: 1
Training loss: 2.9111264243786836
Validation loss: 2.729563576108529

Epoch: 5| Step: 2
Training loss: 2.5547925828325844
Validation loss: 2.7298149372864664

Epoch: 5| Step: 3
Training loss: 3.286468425237493
Validation loss: 2.733505086269753

Epoch: 5| Step: 4
Training loss: 3.1826630337676702
Validation loss: 2.7310479465378394

Epoch: 5| Step: 5
Training loss: 3.166174515744189
Validation loss: 2.732107977696524

Epoch: 5| Step: 6
Training loss: 2.6486976518269234
Validation loss: 2.7306464265940207

Epoch: 5| Step: 7
Training loss: 3.2116946327827627
Validation loss: 2.732631442250832

Epoch: 5| Step: 8
Training loss: 3.0938329203889188
Validation loss: 2.733650068764497

Epoch: 5| Step: 9
Training loss: 3.096307179335363
Validation loss: 2.7236587082615524

Epoch: 5| Step: 10
Training loss: 3.349250760914277
Validation loss: 2.7245998208771622

Epoch: 287| Step: 0
Training loss: 3.416585936794357
Validation loss: 2.7226425732922785

Epoch: 5| Step: 1
Training loss: 3.0221613277895214
Validation loss: 2.7218304256158765

Epoch: 5| Step: 2
Training loss: 2.963931379298685
Validation loss: 2.7225079531581557

Epoch: 5| Step: 3
Training loss: 3.087794727667693
Validation loss: 2.7185427169791048

Epoch: 5| Step: 4
Training loss: 3.253199689522558
Validation loss: 2.7177406580754533

Epoch: 5| Step: 5
Training loss: 2.8894629539785677
Validation loss: 2.718739739760408

Epoch: 5| Step: 6
Training loss: 2.7822574119691943
Validation loss: 2.7157632765625803

Epoch: 5| Step: 7
Training loss: 3.421302224911528
Validation loss: 2.72125656267697

Epoch: 5| Step: 8
Training loss: 2.531034201383015
Validation loss: 2.719592242014114

Epoch: 5| Step: 9
Training loss: 3.035944341709754
Validation loss: 2.717481858417949

Epoch: 5| Step: 10
Training loss: 2.9049422080090608
Validation loss: 2.7199252234349878

Epoch: 288| Step: 0
Training loss: 3.4358753873546113
Validation loss: 2.7161296597458784

Epoch: 5| Step: 1
Training loss: 3.4441019643383495
Validation loss: 2.716364537141707

Epoch: 5| Step: 2
Training loss: 3.639116883516457
Validation loss: 2.7157226763949476

Epoch: 5| Step: 3
Training loss: 2.788999583499039
Validation loss: 2.71700381943585

Epoch: 5| Step: 4
Training loss: 2.4972490433933503
Validation loss: 2.713521107548977

Epoch: 5| Step: 5
Training loss: 3.6689778037887915
Validation loss: 2.7157946818282355

Epoch: 5| Step: 6
Training loss: 2.5442040602877203
Validation loss: 2.7175444439649463

Epoch: 5| Step: 7
Training loss: 2.254311034350297
Validation loss: 2.717862615343021

Epoch: 5| Step: 8
Training loss: 3.1760624647267552
Validation loss: 2.715452973695915

Epoch: 5| Step: 9
Training loss: 2.248966933553936
Validation loss: 2.7159351227070996

Epoch: 5| Step: 10
Training loss: 3.2842525731579224
Validation loss: 2.716808968486105

Epoch: 289| Step: 0
Training loss: 2.8298183029671033
Validation loss: 2.7227466463669523

Epoch: 5| Step: 1
Training loss: 3.1722921463593208
Validation loss: 2.719010114926957

Epoch: 5| Step: 2
Training loss: 3.141479983124992
Validation loss: 2.7192492622457505

Epoch: 5| Step: 3
Training loss: 3.3380109074473236
Validation loss: 2.7245218548210897

Epoch: 5| Step: 4
Training loss: 3.1748614603890317
Validation loss: 2.7241113369914083

Epoch: 5| Step: 5
Training loss: 2.7126138654444922
Validation loss: 2.729983493020755

Epoch: 5| Step: 6
Training loss: 2.498182780704916
Validation loss: 2.7244601616335844

Epoch: 5| Step: 7
Training loss: 3.152970829532028
Validation loss: 2.7229402975703416

Epoch: 5| Step: 8
Training loss: 3.0538311706822894
Validation loss: 2.722620318481951

Epoch: 5| Step: 9
Training loss: 3.2403649044591094
Validation loss: 2.7219720667196867

Epoch: 5| Step: 10
Training loss: 3.0019474066715217
Validation loss: 2.7165205464441877

Epoch: 290| Step: 0
Training loss: 3.0236450439505362
Validation loss: 2.7169840443528774

Epoch: 5| Step: 1
Training loss: 3.250879315485664
Validation loss: 2.714237760539963

Epoch: 5| Step: 2
Training loss: 3.0764240658033164
Validation loss: 2.714979614153781

Epoch: 5| Step: 3
Training loss: 2.897994262036737
Validation loss: 2.7133879599230233

Epoch: 5| Step: 4
Training loss: 3.203255255306991
Validation loss: 2.7167008499037264

Epoch: 5| Step: 5
Training loss: 2.8714800308811177
Validation loss: 2.713376128020564

Epoch: 5| Step: 6
Training loss: 3.6082695923799744
Validation loss: 2.7123672815809483

Epoch: 5| Step: 7
Training loss: 3.227380090165849
Validation loss: 2.7128011296752663

Epoch: 5| Step: 8
Training loss: 2.576425813157275
Validation loss: 2.71231363903026

Epoch: 5| Step: 9
Training loss: 2.825921480571509
Validation loss: 2.71212566528503

Epoch: 5| Step: 10
Training loss: 2.6552124689867376
Validation loss: 2.7158384280811827

Epoch: 291| Step: 0
Training loss: 3.416380490359238
Validation loss: 2.715768754503803

Epoch: 5| Step: 1
Training loss: 2.739233006655731
Validation loss: 2.7191115673913986

Epoch: 5| Step: 2
Training loss: 2.6765538346327915
Validation loss: 2.725212170154361

Epoch: 5| Step: 3
Training loss: 2.655218664672754
Validation loss: 2.7223462233582563

Epoch: 5| Step: 4
Training loss: 2.635657519365368
Validation loss: 2.731472382475181

Epoch: 5| Step: 5
Training loss: 3.289929490884672
Validation loss: 2.734316282799201

Epoch: 5| Step: 6
Training loss: 3.4655147276964295
Validation loss: 2.749576810118246

Epoch: 5| Step: 7
Training loss: 3.8073461748736097
Validation loss: 2.7389505617018064

Epoch: 5| Step: 8
Training loss: 3.140721865246725
Validation loss: 2.7364102366249345

Epoch: 5| Step: 9
Training loss: 2.524527771858775
Validation loss: 2.7181383104173187

Epoch: 5| Step: 10
Training loss: 2.726430283103356
Validation loss: 2.7119086401093755

Epoch: 292| Step: 0
Training loss: 2.8074527805124574
Validation loss: 2.7090001789574263

Epoch: 5| Step: 1
Training loss: 3.0497566876526125
Validation loss: 2.7114560080970826

Epoch: 5| Step: 2
Training loss: 2.864558956158114
Validation loss: 2.7133733502606923

Epoch: 5| Step: 3
Training loss: 2.325894509794225
Validation loss: 2.7142091528925802

Epoch: 5| Step: 4
Training loss: 3.1542438136500652
Validation loss: 2.71657897920439

Epoch: 5| Step: 5
Training loss: 3.1503744296410283
Validation loss: 2.715902705277444

Epoch: 5| Step: 6
Training loss: 3.002239980500009
Validation loss: 2.717239193957453

Epoch: 5| Step: 7
Training loss: 3.1380553099873874
Validation loss: 2.715221859290997

Epoch: 5| Step: 8
Training loss: 3.042786814352135
Validation loss: 2.716481736536883

Epoch: 5| Step: 9
Training loss: 3.28488089079891
Validation loss: 2.7126282778960134

Epoch: 5| Step: 10
Training loss: 3.607301454955805
Validation loss: 2.7185367476548277

Epoch: 293| Step: 0
Training loss: 3.3010981842110905
Validation loss: 2.721006276854043

Epoch: 5| Step: 1
Training loss: 3.162169391705767
Validation loss: 2.731844553825732

Epoch: 5| Step: 2
Training loss: 3.5238161412229716
Validation loss: 2.7379978510694496

Epoch: 5| Step: 3
Training loss: 3.103117661020872
Validation loss: 2.7502811293780476

Epoch: 5| Step: 4
Training loss: 2.231767319832658
Validation loss: 2.760306651050822

Epoch: 5| Step: 5
Training loss: 2.7103223295065435
Validation loss: 2.753197290769658

Epoch: 5| Step: 6
Training loss: 3.276978537178705
Validation loss: 2.7390056855636162

Epoch: 5| Step: 7
Training loss: 3.0527187549584385
Validation loss: 2.7390263649154996

Epoch: 5| Step: 8
Training loss: 3.2440168620093477
Validation loss: 2.724515974343598

Epoch: 5| Step: 9
Training loss: 2.8051912073254046
Validation loss: 2.7213634753206635

Epoch: 5| Step: 10
Training loss: 2.8384126313071474
Validation loss: 2.716156158429214

Epoch: 294| Step: 0
Training loss: 2.501948265053096
Validation loss: 2.712351773232913

Epoch: 5| Step: 1
Training loss: 2.6528166179465495
Validation loss: 2.7144637803883316

Epoch: 5| Step: 2
Training loss: 3.0774275091141527
Validation loss: 2.7149127863193883

Epoch: 5| Step: 3
Training loss: 3.144074325061548
Validation loss: 2.709500100447191

Epoch: 5| Step: 4
Training loss: 3.457335515829864
Validation loss: 2.710618242425057

Epoch: 5| Step: 5
Training loss: 3.4058804092781485
Validation loss: 2.712224890292453

Epoch: 5| Step: 6
Training loss: 3.2937230957785504
Validation loss: 2.7114031039204645

Epoch: 5| Step: 7
Training loss: 2.7663093194406105
Validation loss: 2.7138643866266037

Epoch: 5| Step: 8
Training loss: 2.657186634754918
Validation loss: 2.7174697462283603

Epoch: 5| Step: 9
Training loss: 2.8601466737496746
Validation loss: 2.7129354301433484

Epoch: 5| Step: 10
Training loss: 3.4184444423444282
Validation loss: 2.7123394991934813

Epoch: 295| Step: 0
Training loss: 2.3426492776603496
Validation loss: 2.707921648249106

Epoch: 5| Step: 1
Training loss: 2.692572663441527
Validation loss: 2.7103490410360194

Epoch: 5| Step: 2
Training loss: 2.9240215392982782
Validation loss: 2.71112801846731

Epoch: 5| Step: 3
Training loss: 3.0960838685418266
Validation loss: 2.7087610632699284

Epoch: 5| Step: 4
Training loss: 3.5219230695962533
Validation loss: 2.7078918822962104

Epoch: 5| Step: 5
Training loss: 3.133863467827747
Validation loss: 2.7061951592374682

Epoch: 5| Step: 6
Training loss: 3.2864395519914926
Validation loss: 2.710757481826788

Epoch: 5| Step: 7
Training loss: 2.9152785313071026
Validation loss: 2.711576849716706

Epoch: 5| Step: 8
Training loss: 3.079585159900612
Validation loss: 2.710395303193214

Epoch: 5| Step: 9
Training loss: 3.477153873508993
Validation loss: 2.7136407958105155

Epoch: 5| Step: 10
Training loss: 2.6497063312115547
Validation loss: 2.7085041386688284

Epoch: 296| Step: 0
Training loss: 3.1312640161257694
Validation loss: 2.7146716203977803

Epoch: 5| Step: 1
Training loss: 2.807953274721212
Validation loss: 2.7207594703593716

Epoch: 5| Step: 2
Training loss: 2.96760761968897
Validation loss: 2.722123460134017

Epoch: 5| Step: 3
Training loss: 3.490389845533549
Validation loss: 2.7233736267143467

Epoch: 5| Step: 4
Training loss: 2.51817334865076
Validation loss: 2.727484552827632

Epoch: 5| Step: 5
Training loss: 2.9214862422067505
Validation loss: 2.7191261094528207

Epoch: 5| Step: 6
Training loss: 2.8116333367935527
Validation loss: 2.7115248007036636

Epoch: 5| Step: 7
Training loss: 2.6692374076921386
Validation loss: 2.7116134683574953

Epoch: 5| Step: 8
Training loss: 3.5000863745794333
Validation loss: 2.709466068484819

Epoch: 5| Step: 9
Training loss: 3.3916686249398493
Validation loss: 2.709881512469172

Epoch: 5| Step: 10
Training loss: 2.9419188033879418
Validation loss: 2.706732149940922

Epoch: 297| Step: 0
Training loss: 3.1976985463528558
Validation loss: 2.710591560976232

Epoch: 5| Step: 1
Training loss: 2.4696960568005273
Validation loss: 2.7083257638779745

Epoch: 5| Step: 2
Training loss: 3.5331488711112318
Validation loss: 2.70705769285108

Epoch: 5| Step: 3
Training loss: 3.257382151769426
Validation loss: 2.7075426359439208

Epoch: 5| Step: 4
Training loss: 3.2459756437223417
Validation loss: 2.7061515100356934

Epoch: 5| Step: 5
Training loss: 3.0687268848675164
Validation loss: 2.7067988653050183

Epoch: 5| Step: 6
Training loss: 2.247085272827481
Validation loss: 2.711669541229157

Epoch: 5| Step: 7
Training loss: 3.118916044229884
Validation loss: 2.707435372594739

Epoch: 5| Step: 8
Training loss: 2.8453890928949983
Validation loss: 2.7138366261780535

Epoch: 5| Step: 9
Training loss: 3.234860885907132
Validation loss: 2.7120997028852716

Epoch: 5| Step: 10
Training loss: 2.895214828927147
Validation loss: 2.7140342862493236

Epoch: 298| Step: 0
Training loss: 3.159442306993933
Validation loss: 2.717677878949831

Epoch: 5| Step: 1
Training loss: 2.779668122385381
Validation loss: 2.7258265732354245

Epoch: 5| Step: 2
Training loss: 3.1059935312295868
Validation loss: 2.731692292382679

Epoch: 5| Step: 3
Training loss: 3.1919775536687283
Validation loss: 2.728181496007606

Epoch: 5| Step: 4
Training loss: 3.103130876088029
Validation loss: 2.7264417179706197

Epoch: 5| Step: 5
Training loss: 2.7720950033963887
Validation loss: 2.7203940631695374

Epoch: 5| Step: 6
Training loss: 3.563697212227011
Validation loss: 2.7363583545514474

Epoch: 5| Step: 7
Training loss: 3.0488146745579345
Validation loss: 2.7254361755925136

Epoch: 5| Step: 8
Training loss: 2.9053625577192386
Validation loss: 2.7317943099047675

Epoch: 5| Step: 9
Training loss: 2.6114617872018777
Validation loss: 2.7276807859336603

Epoch: 5| Step: 10
Training loss: 3.0465807650397445
Validation loss: 2.7157178147935754

Epoch: 299| Step: 0
Training loss: 3.406561321065524
Validation loss: 2.706075051186061

Epoch: 5| Step: 1
Training loss: 2.8031874021390775
Validation loss: 2.7023458491849204

Epoch: 5| Step: 2
Training loss: 2.7289051386811543
Validation loss: 2.7017963650176267

Epoch: 5| Step: 3
Training loss: 2.4905648524585255
Validation loss: 2.6982642965877086

Epoch: 5| Step: 4
Training loss: 3.2205749079049157
Validation loss: 2.7026867672214308

Epoch: 5| Step: 5
Training loss: 2.808606228648174
Validation loss: 2.7070874139967516

Epoch: 5| Step: 6
Training loss: 3.6049400925651853
Validation loss: 2.703935630484101

Epoch: 5| Step: 7
Training loss: 3.3195348928588215
Validation loss: 2.7076554660912997

Epoch: 5| Step: 8
Training loss: 3.425569395084851
Validation loss: 2.707622369129415

Epoch: 5| Step: 9
Training loss: 2.5929122858890645
Validation loss: 2.705539313489789

Epoch: 5| Step: 10
Training loss: 2.718239571899294
Validation loss: 2.7067702728015623

Epoch: 300| Step: 0
Training loss: 2.7913008397994976
Validation loss: 2.7022436211709424

Epoch: 5| Step: 1
Training loss: 2.650936511838981
Validation loss: 2.701802534532323

Epoch: 5| Step: 2
Training loss: 2.9967758019093087
Validation loss: 2.7018281537136297

Epoch: 5| Step: 3
Training loss: 3.137876760043049
Validation loss: 2.703642505939682

Epoch: 5| Step: 4
Training loss: 3.093890716743382
Validation loss: 2.7038765329120613

Epoch: 5| Step: 5
Training loss: 3.140887956381287
Validation loss: 2.711255257208526

Epoch: 5| Step: 6
Training loss: 3.1146825223882764
Validation loss: 2.7164193766010976

Epoch: 5| Step: 7
Training loss: 3.051655310778598
Validation loss: 2.7332017425937547

Epoch: 5| Step: 8
Training loss: 2.7746946252730744
Validation loss: 2.754832955259998

Epoch: 5| Step: 9
Training loss: 3.0877550398166442
Validation loss: 2.750827455066609

Epoch: 5| Step: 10
Training loss: 3.5951829789964544
Validation loss: 2.732650214732229

Testing loss: 2.9269285330785864
