Epoch: 1| Step: 0
Training loss: 5.101960287898846
Validation loss: 5.7962465212295715

Epoch: 5| Step: 1
Training loss: 5.98510833310753
Validation loss: 5.792340651140975

Epoch: 5| Step: 2
Training loss: 6.099115601511867
Validation loss: 5.78839257575337

Epoch: 5| Step: 3
Training loss: 6.377028198734967
Validation loss: 5.784626615392147

Epoch: 5| Step: 4
Training loss: 6.127698965402568
Validation loss: 5.780721529525399

Epoch: 5| Step: 5
Training loss: 6.103634373844822
Validation loss: 5.776856168809553

Epoch: 5| Step: 6
Training loss: 4.970532943120633
Validation loss: 5.77267031383464

Epoch: 5| Step: 7
Training loss: 5.978503182668366
Validation loss: 5.76843060242417

Epoch: 5| Step: 8
Training loss: 5.664549076621641
Validation loss: 5.764005164736106

Epoch: 5| Step: 9
Training loss: 5.646787705878775
Validation loss: 5.759422934684687

Epoch: 5| Step: 10
Training loss: 5.686671940814871
Validation loss: 5.7548583266198285

Epoch: 2| Step: 0
Training loss: 5.631576762313907
Validation loss: 5.749976815724904

Epoch: 5| Step: 1
Training loss: 5.191530615104131
Validation loss: 5.745425658548296

Epoch: 5| Step: 2
Training loss: 5.409146806210992
Validation loss: 5.740164985825332

Epoch: 5| Step: 3
Training loss: 5.861294607430824
Validation loss: 5.7348743503066135

Epoch: 5| Step: 4
Training loss: 5.710592820480911
Validation loss: 5.729353397790492

Epoch: 5| Step: 5
Training loss: 5.104853037662575
Validation loss: 5.723421626132414

Epoch: 5| Step: 6
Training loss: 6.100097480370255
Validation loss: 5.717441560898815

Epoch: 5| Step: 7
Training loss: 7.012094675681629
Validation loss: 5.710971616308633

Epoch: 5| Step: 8
Training loss: 5.774118344602118
Validation loss: 5.704497003095309

Epoch: 5| Step: 9
Training loss: 4.797529045521971
Validation loss: 5.697454905738864

Epoch: 5| Step: 10
Training loss: 6.496878534694956
Validation loss: 5.690251394035897

Epoch: 3| Step: 0
Training loss: 5.403731801524989
Validation loss: 5.682535734074792

Epoch: 5| Step: 1
Training loss: 5.144288957432647
Validation loss: 5.674308800463838

Epoch: 5| Step: 2
Training loss: 5.339464041570156
Validation loss: 5.666417106740546

Epoch: 5| Step: 3
Training loss: 6.151631283151458
Validation loss: 5.656955944845002

Epoch: 5| Step: 4
Training loss: 6.410819754471062
Validation loss: 5.648282028366728

Epoch: 5| Step: 5
Training loss: 4.893379581312556
Validation loss: 5.63913916282258

Epoch: 5| Step: 6
Training loss: 5.893568522793412
Validation loss: 5.629376722021931

Epoch: 5| Step: 7
Training loss: 6.027906370573646
Validation loss: 5.618658712179955

Epoch: 5| Step: 8
Training loss: 5.38832551866919
Validation loss: 5.607622591150325

Epoch: 5| Step: 9
Training loss: 5.1914744031808375
Validation loss: 5.596319027906826

Epoch: 5| Step: 10
Training loss: 6.43778442939611
Validation loss: 5.585083216019137

Epoch: 4| Step: 0
Training loss: 4.651181118174972
Validation loss: 5.571828882247413

Epoch: 5| Step: 1
Training loss: 5.933694362729109
Validation loss: 5.559097799990459

Epoch: 5| Step: 2
Training loss: 6.4027870308714245
Validation loss: 5.5465049332499525

Epoch: 5| Step: 3
Training loss: 5.753425904402626
Validation loss: 5.532752574822214

Epoch: 5| Step: 4
Training loss: 5.526554161801032
Validation loss: 5.517864522003176

Epoch: 5| Step: 5
Training loss: 4.4229631466728465
Validation loss: 5.50441571768669

Epoch: 5| Step: 6
Training loss: 5.541346758258652
Validation loss: 5.489362335317685

Epoch: 5| Step: 7
Training loss: 5.38776337229873
Validation loss: 5.474210754527406

Epoch: 5| Step: 8
Training loss: 6.382126060376519
Validation loss: 5.457905614583918

Epoch: 5| Step: 9
Training loss: 5.626533299322398
Validation loss: 5.442173199184392

Epoch: 5| Step: 10
Training loss: 4.884480183958214
Validation loss: 5.425623658251999

Epoch: 5| Step: 0
Training loss: 5.690471166535155
Validation loss: 5.408239431643802

Epoch: 5| Step: 1
Training loss: 6.11023754850578
Validation loss: 5.391029496582203

Epoch: 5| Step: 2
Training loss: 5.154453403861376
Validation loss: 5.3726296794319826

Epoch: 5| Step: 3
Training loss: 5.784101782909651
Validation loss: 5.353748282043931

Epoch: 5| Step: 4
Training loss: 5.009679009058735
Validation loss: 5.334014811866618

Epoch: 5| Step: 5
Training loss: 5.80986668812959
Validation loss: 5.314318015407422

Epoch: 5| Step: 6
Training loss: 4.5686006910398635
Validation loss: 5.292243516541496

Epoch: 5| Step: 7
Training loss: 4.501242995782396
Validation loss: 5.272286100064825

Epoch: 5| Step: 8
Training loss: 5.013471765094953
Validation loss: 5.250432263776845

Epoch: 5| Step: 9
Training loss: 5.0149864669723705
Validation loss: 5.2286743153219115

Epoch: 5| Step: 10
Training loss: 6.115219403726484
Validation loss: 5.2051311836600505

Epoch: 6| Step: 0
Training loss: 5.834628079548872
Validation loss: 5.1821222403027445

Epoch: 5| Step: 1
Training loss: 5.199807699022294
Validation loss: 5.1590573183364965

Epoch: 5| Step: 2
Training loss: 4.990059125775501
Validation loss: 5.133932403560985

Epoch: 5| Step: 3
Training loss: 5.2795989034489
Validation loss: 5.110107730596555

Epoch: 5| Step: 4
Training loss: 5.36394410506902
Validation loss: 5.086204348787942

Epoch: 5| Step: 5
Training loss: 5.111494925273207
Validation loss: 5.0600671020433365

Epoch: 5| Step: 6
Training loss: 6.127086673213806
Validation loss: 5.037212597299339

Epoch: 5| Step: 7
Training loss: 4.624825964050313
Validation loss: 5.013031262399037

Epoch: 5| Step: 8
Training loss: 4.79701516011896
Validation loss: 4.988060447309434

Epoch: 5| Step: 9
Training loss: 3.92022305535169
Validation loss: 4.965767359713666

Epoch: 5| Step: 10
Training loss: 4.7432383546593275
Validation loss: 4.944749323775176

Epoch: 7| Step: 0
Training loss: 5.077002016756484
Validation loss: 4.920670579727797

Epoch: 5| Step: 1
Training loss: 4.739543850353516
Validation loss: 4.898895534814901

Epoch: 5| Step: 2
Training loss: 5.577255052961201
Validation loss: 4.878107025806449

Epoch: 5| Step: 3
Training loss: 5.120623324717664
Validation loss: 4.856880287530061

Epoch: 5| Step: 4
Training loss: 5.655956787602566
Validation loss: 4.836221503880134

Epoch: 5| Step: 5
Training loss: 4.525239733673432
Validation loss: 4.814581940750227

Epoch: 5| Step: 6
Training loss: 4.702140629049851
Validation loss: 4.794531901394097

Epoch: 5| Step: 7
Training loss: 4.877460739001191
Validation loss: 4.775702036004138

Epoch: 5| Step: 8
Training loss: 4.7466342445580665
Validation loss: 4.756416559336908

Epoch: 5| Step: 9
Training loss: 4.514121468575767
Validation loss: 4.738570200119919

Epoch: 5| Step: 10
Training loss: 4.022559683139449
Validation loss: 4.721138189892994

Epoch: 8| Step: 0
Training loss: 4.553709995074157
Validation loss: 4.702513363673708

Epoch: 5| Step: 1
Training loss: 4.793077985269588
Validation loss: 4.686252851942376

Epoch: 5| Step: 2
Training loss: 4.9094700056823175
Validation loss: 4.6695875027029725

Epoch: 5| Step: 3
Training loss: 4.917165483074518
Validation loss: 4.654274353361451

Epoch: 5| Step: 4
Training loss: 4.666561307171882
Validation loss: 4.636172030399964

Epoch: 5| Step: 5
Training loss: 4.523048924439794
Validation loss: 4.615139279169933

Epoch: 5| Step: 6
Training loss: 4.410012228466561
Validation loss: 4.595386701591211

Epoch: 5| Step: 7
Training loss: 4.966281877670312
Validation loss: 4.566228884904909

Epoch: 5| Step: 8
Training loss: 4.749163102157941
Validation loss: 4.537645641513816

Epoch: 5| Step: 9
Training loss: 5.110006590837084
Validation loss: 4.516832429483567

Epoch: 5| Step: 10
Training loss: 3.872875615737374
Validation loss: 4.502755530338255

Epoch: 9| Step: 0
Training loss: 5.58574320848731
Validation loss: 4.489760431227089

Epoch: 5| Step: 1
Training loss: 4.09355128148118
Validation loss: 4.479996977664438

Epoch: 5| Step: 2
Training loss: 4.780441914006327
Validation loss: 4.467741998492049

Epoch: 5| Step: 3
Training loss: 3.8540908531086955
Validation loss: 4.456304578307825

Epoch: 5| Step: 4
Training loss: 4.1678637247340635
Validation loss: 4.441859337352735

Epoch: 5| Step: 5
Training loss: 3.472990313875908
Validation loss: 4.431091635853823

Epoch: 5| Step: 6
Training loss: 5.0406378124473905
Validation loss: 4.418557407610924

Epoch: 5| Step: 7
Training loss: 4.501287064340121
Validation loss: 4.408030905031355

Epoch: 5| Step: 8
Training loss: 4.856695386967059
Validation loss: 4.397205477854826

Epoch: 5| Step: 9
Training loss: 4.374458715469232
Validation loss: 4.388138425262909

Epoch: 5| Step: 10
Training loss: 4.871380562739493
Validation loss: 4.376541932449168

Epoch: 10| Step: 0
Training loss: 5.094598617541184
Validation loss: 4.367471877680688

Epoch: 5| Step: 1
Training loss: 4.493556814060163
Validation loss: 4.357739613469047

Epoch: 5| Step: 2
Training loss: 3.9674312773571465
Validation loss: 4.349054765531744

Epoch: 5| Step: 3
Training loss: 4.7880902197933635
Validation loss: 4.339570998050829

Epoch: 5| Step: 4
Training loss: 3.886789415186757
Validation loss: 4.330647636515679

Epoch: 5| Step: 5
Training loss: 3.74400116805523
Validation loss: 4.321731252245147

Epoch: 5| Step: 6
Training loss: 4.702212222925366
Validation loss: 4.313865772307552

Epoch: 5| Step: 7
Training loss: 4.415181300068615
Validation loss: 4.305364249420003

Epoch: 5| Step: 8
Training loss: 4.215227705301808
Validation loss: 4.2980200483379765

Epoch: 5| Step: 9
Training loss: 4.8947716826670735
Validation loss: 4.288447590408564

Epoch: 5| Step: 10
Training loss: 4.425982289743823
Validation loss: 4.2794506105122485

Epoch: 11| Step: 0
Training loss: 3.41835405194349
Validation loss: 4.272588812170458

Epoch: 5| Step: 1
Training loss: 4.45077613320039
Validation loss: 4.2635059787115095

Epoch: 5| Step: 2
Training loss: 3.3751775906781147
Validation loss: 4.25747843065242

Epoch: 5| Step: 3
Training loss: 4.693388432013153
Validation loss: 4.248682610533854

Epoch: 5| Step: 4
Training loss: 4.666880511879237
Validation loss: 4.242527196676623

Epoch: 5| Step: 5
Training loss: 3.753943213877261
Validation loss: 4.235319860617602

Epoch: 5| Step: 6
Training loss: 4.438423383035376
Validation loss: 4.227530389552113

Epoch: 5| Step: 7
Training loss: 4.444708972582136
Validation loss: 4.222604244154357

Epoch: 5| Step: 8
Training loss: 4.244963410380442
Validation loss: 4.216668068355697

Epoch: 5| Step: 9
Training loss: 5.485558189288606
Validation loss: 4.210152558833867

Epoch: 5| Step: 10
Training loss: 4.593413463903093
Validation loss: 4.203737478312435

Epoch: 12| Step: 0
Training loss: 4.317216146445178
Validation loss: 4.197632851494237

Epoch: 5| Step: 1
Training loss: 4.163898285853837
Validation loss: 4.192156895204092

Epoch: 5| Step: 2
Training loss: 3.7586350522163645
Validation loss: 4.185643724571642

Epoch: 5| Step: 3
Training loss: 4.580082705887901
Validation loss: 4.18056521986203

Epoch: 5| Step: 4
Training loss: 4.712293236848576
Validation loss: 4.175835037356992

Epoch: 5| Step: 5
Training loss: 3.5638390417090893
Validation loss: 4.170432719847647

Epoch: 5| Step: 6
Training loss: 5.0049172064367
Validation loss: 4.164282077447863

Epoch: 5| Step: 7
Training loss: 4.342816808341166
Validation loss: 4.160210584460634

Epoch: 5| Step: 8
Training loss: 4.114954420650757
Validation loss: 4.153609447440104

Epoch: 5| Step: 9
Training loss: 4.602249275601594
Validation loss: 4.148770546788749

Epoch: 5| Step: 10
Training loss: 3.911819759624299
Validation loss: 4.14467907203432

Epoch: 13| Step: 0
Training loss: 4.984172948490928
Validation loss: 4.138564086849038

Epoch: 5| Step: 1
Training loss: 4.307812119222077
Validation loss: 4.1338825417347955

Epoch: 5| Step: 2
Training loss: 3.5566136769211796
Validation loss: 4.129032084778428

Epoch: 5| Step: 3
Training loss: 4.68624678071594
Validation loss: 4.124306236040834

Epoch: 5| Step: 4
Training loss: 4.138464021886528
Validation loss: 4.120799449448432

Epoch: 5| Step: 5
Training loss: 4.657766824758753
Validation loss: 4.115733600093408

Epoch: 5| Step: 6
Training loss: 3.8272216976753173
Validation loss: 4.112323777433089

Epoch: 5| Step: 7
Training loss: 4.330647638883585
Validation loss: 4.107256109084751

Epoch: 5| Step: 8
Training loss: 3.2185864453288633
Validation loss: 4.102637073017379

Epoch: 5| Step: 9
Training loss: 4.50190906296225
Validation loss: 4.098574271523324

Epoch: 5| Step: 10
Training loss: 4.304432717760671
Validation loss: 4.094115625990476

Epoch: 14| Step: 0
Training loss: 4.221548099130399
Validation loss: 4.090557903845451

Epoch: 5| Step: 1
Training loss: 4.379204609734058
Validation loss: 4.085686216511703

Epoch: 5| Step: 2
Training loss: 3.534392992103713
Validation loss: 4.082644607710395

Epoch: 5| Step: 3
Training loss: 4.115106219453843
Validation loss: 4.077461600785741

Epoch: 5| Step: 4
Training loss: 3.5937538478664863
Validation loss: 4.072710466584935

Epoch: 5| Step: 5
Training loss: 4.461449481825591
Validation loss: 4.068797440662872

Epoch: 5| Step: 6
Training loss: 4.481381789734203
Validation loss: 4.064488429004266

Epoch: 5| Step: 7
Training loss: 4.868713629492483
Validation loss: 4.060729872487501

Epoch: 5| Step: 8
Training loss: 4.106064772238543
Validation loss: 4.056714597945274

Epoch: 5| Step: 9
Training loss: 3.626594981812744
Validation loss: 4.051586481390566

Epoch: 5| Step: 10
Training loss: 4.791954872199067
Validation loss: 4.048273240685433

Epoch: 15| Step: 0
Training loss: 4.625144956224493
Validation loss: 4.0425144740294865

Epoch: 5| Step: 1
Training loss: 4.764885716864088
Validation loss: 4.038118949090874

Epoch: 5| Step: 2
Training loss: 3.6194493120430256
Validation loss: 4.033340378906583

Epoch: 5| Step: 3
Training loss: 2.953520087400329
Validation loss: 4.027848743628722

Epoch: 5| Step: 4
Training loss: 4.466568207485924
Validation loss: 4.023827438343045

Epoch: 5| Step: 5
Training loss: 4.674502651258323
Validation loss: 4.019276182215902

Epoch: 5| Step: 6
Training loss: 4.337262695153197
Validation loss: 4.015228863548048

Epoch: 5| Step: 7
Training loss: 4.398301334204473
Validation loss: 4.010246342064006

Epoch: 5| Step: 8
Training loss: 4.500408154097448
Validation loss: 4.00445532834797

Epoch: 5| Step: 9
Training loss: 3.6884919464945924
Validation loss: 3.999862199378575

Epoch: 5| Step: 10
Training loss: 3.2341951329440506
Validation loss: 3.993429233543012

Epoch: 16| Step: 0
Training loss: 5.432608497965143
Validation loss: 3.9894478727070033

Epoch: 5| Step: 1
Training loss: 3.874262585769851
Validation loss: 3.984840816555092

Epoch: 5| Step: 2
Training loss: 3.520525962158486
Validation loss: 3.9806790754032253

Epoch: 5| Step: 3
Training loss: 4.2766534117574775
Validation loss: 3.976751894399143

Epoch: 5| Step: 4
Training loss: 4.408006034099236
Validation loss: 3.9733688327331893

Epoch: 5| Step: 5
Training loss: 4.442291681474865
Validation loss: 3.96946178303429

Epoch: 5| Step: 6
Training loss: 3.432036201721829
Validation loss: 3.96313099718992

Epoch: 5| Step: 7
Training loss: 2.7835530378997677
Validation loss: 3.9596056350120166

Epoch: 5| Step: 8
Training loss: 4.335316766519426
Validation loss: 3.955981460770723

Epoch: 5| Step: 9
Training loss: 3.5352843877847575
Validation loss: 3.950114350061073

Epoch: 5| Step: 10
Training loss: 4.769175323277616
Validation loss: 3.9482602292392253

Epoch: 17| Step: 0
Training loss: 3.3977024730451184
Validation loss: 3.9450831992062714

Epoch: 5| Step: 1
Training loss: 5.118592327144156
Validation loss: 3.9405644958664885

Epoch: 5| Step: 2
Training loss: 3.8046547890261566
Validation loss: 3.9379034322366913

Epoch: 5| Step: 3
Training loss: 4.2388761463254285
Validation loss: 3.9314655368706655

Epoch: 5| Step: 4
Training loss: 4.316417518014139
Validation loss: 3.927857574513138

Epoch: 5| Step: 5
Training loss: 3.839974510783794
Validation loss: 3.9235241242561982

Epoch: 5| Step: 6
Training loss: 4.226987129922825
Validation loss: 3.9209453763999806

Epoch: 5| Step: 7
Training loss: 4.247619410964263
Validation loss: 3.915574228858662

Epoch: 5| Step: 8
Training loss: 3.701642347241901
Validation loss: 3.9141474790671182

Epoch: 5| Step: 9
Training loss: 3.656340117036794
Validation loss: 3.9086671605100247

Epoch: 5| Step: 10
Training loss: 4.116520112758484
Validation loss: 3.904082332863852

Epoch: 18| Step: 0
Training loss: 4.274159595356967
Validation loss: 3.899737605472526

Epoch: 5| Step: 1
Training loss: 3.7833158036104564
Validation loss: 3.8953886903073993

Epoch: 5| Step: 2
Training loss: 4.460401726664586
Validation loss: 3.8934567563741123

Epoch: 5| Step: 3
Training loss: 3.310480185768187
Validation loss: 3.8882554807548333

Epoch: 5| Step: 4
Training loss: 4.409531041337231
Validation loss: 3.8849642827103907

Epoch: 5| Step: 5
Training loss: 4.440445043580496
Validation loss: 3.8813220243670488

Epoch: 5| Step: 6
Training loss: 4.2057924563091404
Validation loss: 3.8770541695078604

Epoch: 5| Step: 7
Training loss: 3.6104154862308206
Validation loss: 3.873122380609269

Epoch: 5| Step: 8
Training loss: 4.083357337310199
Validation loss: 3.8689808787048516

Epoch: 5| Step: 9
Training loss: 3.5988379245311197
Validation loss: 3.8654880077851406

Epoch: 5| Step: 10
Training loss: 4.15220893073995
Validation loss: 3.8633675995437233

Epoch: 19| Step: 0
Training loss: 4.373252519659482
Validation loss: 3.857011244966161

Epoch: 5| Step: 1
Training loss: 4.192976373985756
Validation loss: 3.852708227407455

Epoch: 5| Step: 2
Training loss: 3.007359220360222
Validation loss: 3.847615330475759

Epoch: 5| Step: 3
Training loss: 3.4274731137078858
Validation loss: 3.8457763730228547

Epoch: 5| Step: 4
Training loss: 4.001864237284572
Validation loss: 3.8423476243322554

Epoch: 5| Step: 5
Training loss: 3.5435518670240387
Validation loss: 3.8393524930242533

Epoch: 5| Step: 6
Training loss: 4.015536177428405
Validation loss: 3.832115702677785

Epoch: 5| Step: 7
Training loss: 4.230948437716677
Validation loss: 3.828390735463004

Epoch: 5| Step: 8
Training loss: 4.474879615911952
Validation loss: 3.8241575072091067

Epoch: 5| Step: 9
Training loss: 5.070925447770908
Validation loss: 3.821904885478375

Epoch: 5| Step: 10
Training loss: 3.120153560038386
Validation loss: 3.820480818414355

Epoch: 20| Step: 0
Training loss: 4.095841899771026
Validation loss: 3.8149609986957698

Epoch: 5| Step: 1
Training loss: 4.168361598827422
Validation loss: 3.8091022662914527

Epoch: 5| Step: 2
Training loss: 3.7489852803964694
Validation loss: 3.8079076496792705

Epoch: 5| Step: 3
Training loss: 4.176381852124619
Validation loss: 3.8018116021019783

Epoch: 5| Step: 4
Training loss: 3.7201123987670655
Validation loss: 3.800436088137263

Epoch: 5| Step: 5
Training loss: 3.3306266444784334
Validation loss: 3.7965910175020388

Epoch: 5| Step: 6
Training loss: 4.296981310829746
Validation loss: 3.794319839606433

Epoch: 5| Step: 7
Training loss: 3.6228677463720143
Validation loss: 3.7874258008054373

Epoch: 5| Step: 8
Training loss: 4.232172431865459
Validation loss: 3.782708348088608

Epoch: 5| Step: 9
Training loss: 3.8416193817825453
Validation loss: 3.778712441635351

Epoch: 5| Step: 10
Training loss: 4.352813047909789
Validation loss: 3.7779867474158886

Epoch: 21| Step: 0
Training loss: 3.4715531853270933
Validation loss: 3.7734463986568483

Epoch: 5| Step: 1
Training loss: 4.443181873171641
Validation loss: 3.767490736784101

Epoch: 5| Step: 2
Training loss: 4.2778534049963275
Validation loss: 3.763104996277771

Epoch: 5| Step: 3
Training loss: 3.937689277095965
Validation loss: 3.7586654818267795

Epoch: 5| Step: 4
Training loss: 3.2404041947097855
Validation loss: 3.75524589698765

Epoch: 5| Step: 5
Training loss: 3.4978665252660313
Validation loss: 3.7533254050793263

Epoch: 5| Step: 6
Training loss: 4.59243672600913
Validation loss: 3.7497570410337135

Epoch: 5| Step: 7
Training loss: 3.4758121666591117
Validation loss: 3.749159139613456

Epoch: 5| Step: 8
Training loss: 3.7861481775223433
Validation loss: 3.7382741672515936

Epoch: 5| Step: 9
Training loss: 4.3246417299620665
Validation loss: 3.7393461292665933

Epoch: 5| Step: 10
Training loss: 3.9210157935036776
Validation loss: 3.7372021543158906

Epoch: 22| Step: 0
Training loss: 3.879331444430794
Validation loss: 3.730701707832304

Epoch: 5| Step: 1
Training loss: 3.2654779574494723
Validation loss: 3.724896777822546

Epoch: 5| Step: 2
Training loss: 4.278622231521877
Validation loss: 3.721317789357547

Epoch: 5| Step: 3
Training loss: 3.9203705960861326
Validation loss: 3.7208983138686538

Epoch: 5| Step: 4
Training loss: 3.6204118302589157
Validation loss: 3.715922137266924

Epoch: 5| Step: 5
Training loss: 4.003486306102396
Validation loss: 3.7094947422199764

Epoch: 5| Step: 6
Training loss: 4.454114730337091
Validation loss: 3.7095009303455027

Epoch: 5| Step: 7
Training loss: 4.614971526317438
Validation loss: 3.706038150633997

Epoch: 5| Step: 8
Training loss: 3.4006835530867705
Validation loss: 3.7038549047687157

Epoch: 5| Step: 9
Training loss: 2.963316432302514
Validation loss: 3.706079370222801

Epoch: 5| Step: 10
Training loss: 4.162610915713852
Validation loss: 3.7072252030718276

Epoch: 23| Step: 0
Training loss: 4.4256879454943
Validation loss: 3.6994394765227105

Epoch: 5| Step: 1
Training loss: 4.069249576304925
Validation loss: 3.694166769548912

Epoch: 5| Step: 2
Training loss: 3.0974373469508842
Validation loss: 3.6907873640702467

Epoch: 5| Step: 3
Training loss: 3.3425407718748184
Validation loss: 3.687483981990907

Epoch: 5| Step: 4
Training loss: 3.8227816912169614
Validation loss: 3.6872802162753358

Epoch: 5| Step: 5
Training loss: 3.4536912548744976
Validation loss: 3.685115480531265

Epoch: 5| Step: 6
Training loss: 3.8337148531809833
Validation loss: 3.6858398610410674

Epoch: 5| Step: 7
Training loss: 4.231716996853059
Validation loss: 3.6778325045065396

Epoch: 5| Step: 8
Training loss: 3.7571593289944074
Validation loss: 3.670877591134578

Epoch: 5| Step: 9
Training loss: 4.372087871830664
Validation loss: 3.6615137578470653

Epoch: 5| Step: 10
Training loss: 3.9281682439227925
Validation loss: 3.660093791761157

Epoch: 24| Step: 0
Training loss: 2.7971244146712357
Validation loss: 3.6624183757404802

Epoch: 5| Step: 1
Training loss: 4.103409182490251
Validation loss: 3.663389508000129

Epoch: 5| Step: 2
Training loss: 3.4305695461823604
Validation loss: 3.657041580562716

Epoch: 5| Step: 3
Training loss: 4.292293367028029
Validation loss: 3.649297023229175

Epoch: 5| Step: 4
Training loss: 3.2305186405042625
Validation loss: 3.64571747251489

Epoch: 5| Step: 5
Training loss: 4.273111222833438
Validation loss: 3.643782843411141

Epoch: 5| Step: 6
Training loss: 4.135686498850277
Validation loss: 3.639716891264181

Epoch: 5| Step: 7
Training loss: 4.655114771557942
Validation loss: 3.6355267043907467

Epoch: 5| Step: 8
Training loss: 3.2230986320418613
Validation loss: 3.6322661487507086

Epoch: 5| Step: 9
Training loss: 4.217870097765114
Validation loss: 3.62544751826051

Epoch: 5| Step: 10
Training loss: 3.279449841019927
Validation loss: 3.6215428212848226

Epoch: 25| Step: 0
Training loss: 4.142986041915403
Validation loss: 3.6215618902764195

Epoch: 5| Step: 1
Training loss: 3.029006914616397
Validation loss: 3.6173470080416985

Epoch: 5| Step: 2
Training loss: 3.303640646190962
Validation loss: 3.6140268768733597

Epoch: 5| Step: 3
Training loss: 3.5090611196018053
Validation loss: 3.612341766122325

Epoch: 5| Step: 4
Training loss: 4.456397423572787
Validation loss: 3.613816069244967

Epoch: 5| Step: 5
Training loss: 3.7343398854667726
Validation loss: 3.606439601528839

Epoch: 5| Step: 6
Training loss: 3.599738530094427
Validation loss: 3.600861047730172

Epoch: 5| Step: 7
Training loss: 4.192473233978597
Validation loss: 3.597626640491296

Epoch: 5| Step: 8
Training loss: 3.4405097962927282
Validation loss: 3.5907954529224777

Epoch: 5| Step: 9
Training loss: 4.165853548183386
Validation loss: 3.589029222784021

Epoch: 5| Step: 10
Training loss: 3.996303399963895
Validation loss: 3.5848157315179816

Epoch: 26| Step: 0
Training loss: 3.050774685392265
Validation loss: 3.579804229154453

Epoch: 5| Step: 1
Training loss: 4.466143508183919
Validation loss: 3.5797695305759514

Epoch: 5| Step: 2
Training loss: 4.163328868373882
Validation loss: 3.5762463008211745

Epoch: 5| Step: 3
Training loss: 3.5009215367886335
Validation loss: 3.57440397016999

Epoch: 5| Step: 4
Training loss: 3.8131650751068524
Validation loss: 3.5712499740584334

Epoch: 5| Step: 5
Training loss: 2.509761255163997
Validation loss: 3.568004975525175

Epoch: 5| Step: 6
Training loss: 3.6486040032436176
Validation loss: 3.564194744441947

Epoch: 5| Step: 7
Training loss: 4.776427785504217
Validation loss: 3.56341771048101

Epoch: 5| Step: 8
Training loss: 3.18361681596322
Validation loss: 3.5595946195282187

Epoch: 5| Step: 9
Training loss: 3.872232371687453
Validation loss: 3.561511196292456

Epoch: 5| Step: 10
Training loss: 3.9629915768853654
Validation loss: 3.5620588624250815

Epoch: 27| Step: 0
Training loss: 3.8872911501406624
Validation loss: 3.5666148168064815

Epoch: 5| Step: 1
Training loss: 4.171402465119013
Validation loss: 3.5523974369647653

Epoch: 5| Step: 2
Training loss: 2.5523044308756413
Validation loss: 3.546819554457021

Epoch: 5| Step: 3
Training loss: 3.7481312227921055
Validation loss: 3.5432040724335603

Epoch: 5| Step: 4
Training loss: 3.5729148279005534
Validation loss: 3.5385834236703197

Epoch: 5| Step: 5
Training loss: 3.7933233784800295
Validation loss: 3.541287265171172

Epoch: 5| Step: 6
Training loss: 4.150302848336511
Validation loss: 3.537928923898365

Epoch: 5| Step: 7
Training loss: 4.470099398811385
Validation loss: 3.5335133949164885

Epoch: 5| Step: 8
Training loss: 3.807310731407822
Validation loss: 3.5386819402837997

Epoch: 5| Step: 9
Training loss: 3.2914389680421965
Validation loss: 3.546291641429879

Epoch: 5| Step: 10
Training loss: 3.3969754285802436
Validation loss: 3.5495111707487537

Epoch: 28| Step: 0
Training loss: 4.01524855931012
Validation loss: 3.5473081840922123

Epoch: 5| Step: 1
Training loss: 3.665791638319244
Validation loss: 3.5412421959590272

Epoch: 5| Step: 2
Training loss: 4.102436197866868
Validation loss: 3.5328818589052187

Epoch: 5| Step: 3
Training loss: 3.7144202663866994
Validation loss: 3.5282095552647372

Epoch: 5| Step: 4
Training loss: 4.079783369184881
Validation loss: 3.5235878589648637

Epoch: 5| Step: 5
Training loss: 3.6716457863547434
Validation loss: 3.515206106153032

Epoch: 5| Step: 6
Training loss: 3.464665112626524
Validation loss: 3.511590908707122

Epoch: 5| Step: 7
Training loss: 3.481773328911004
Validation loss: 3.5106806959606875

Epoch: 5| Step: 8
Training loss: 3.4083938151793767
Validation loss: 3.5171339202743215

Epoch: 5| Step: 9
Training loss: 3.6240925146256173
Validation loss: 3.501008770270897

Epoch: 5| Step: 10
Training loss: 3.7213451402295328
Validation loss: 3.5006491678713307

Epoch: 29| Step: 0
Training loss: 3.9008451377485223
Validation loss: 3.4988511055931277

Epoch: 5| Step: 1
Training loss: 3.8240365753579413
Validation loss: 3.4958099768867674

Epoch: 5| Step: 2
Training loss: 4.057928946920687
Validation loss: 3.501447564310449

Epoch: 5| Step: 3
Training loss: 3.5541463251340493
Validation loss: 3.497805412770945

Epoch: 5| Step: 4
Training loss: 4.208194440809521
Validation loss: 3.4954846784988907

Epoch: 5| Step: 5
Training loss: 3.034940223419401
Validation loss: 3.491811857602548

Epoch: 5| Step: 6
Training loss: 4.431236036787107
Validation loss: 3.4869190333321503

Epoch: 5| Step: 7
Training loss: 2.497214482113568
Validation loss: 3.4805016292637956

Epoch: 5| Step: 8
Training loss: 3.6484482170780765
Validation loss: 3.4766841375390416

Epoch: 5| Step: 9
Training loss: 3.3815437739267713
Validation loss: 3.472589407972561

Epoch: 5| Step: 10
Training loss: 3.8146951328119036
Validation loss: 3.47481046974092

Epoch: 30| Step: 0
Training loss: 4.20691994579144
Validation loss: 3.4701102000276998

Epoch: 5| Step: 1
Training loss: 3.9194686011754944
Validation loss: 3.469010136117959

Epoch: 5| Step: 2
Training loss: 3.4535585709494656
Validation loss: 3.4652617998035864

Epoch: 5| Step: 3
Training loss: 3.66505350404329
Validation loss: 3.4638034131668904

Epoch: 5| Step: 4
Training loss: 3.281997740787191
Validation loss: 3.463345801883029

Epoch: 5| Step: 5
Training loss: 3.5236901575415196
Validation loss: 3.4650777372045463

Epoch: 5| Step: 6
Training loss: 3.165972851153067
Validation loss: 3.4596844131984574

Epoch: 5| Step: 7
Training loss: 3.4349933154445056
Validation loss: 3.454725469326213

Epoch: 5| Step: 8
Training loss: 3.8065565715530987
Validation loss: 3.4535572897073883

Epoch: 5| Step: 9
Training loss: 3.909374482835572
Validation loss: 3.45383350960499

Epoch: 5| Step: 10
Training loss: 4.002909079333692
Validation loss: 3.4514404577151527

Epoch: 31| Step: 0
Training loss: 3.413599327670582
Validation loss: 3.453790143565377

Epoch: 5| Step: 1
Training loss: 4.423070092339488
Validation loss: 3.45250691509859

Epoch: 5| Step: 2
Training loss: 3.3329856373328393
Validation loss: 3.4480960537682015

Epoch: 5| Step: 3
Training loss: 4.3223836669799685
Validation loss: 3.4487975334654286

Epoch: 5| Step: 4
Training loss: 4.225384052585718
Validation loss: 3.44327718675405

Epoch: 5| Step: 5
Training loss: 3.710642206590006
Validation loss: 3.443485060628258

Epoch: 5| Step: 6
Training loss: 3.0404636320634375
Validation loss: 3.4380128181503617

Epoch: 5| Step: 7
Training loss: 2.9430991844394647
Validation loss: 3.435669545314207

Epoch: 5| Step: 8
Training loss: 2.8201239779118676
Validation loss: 3.4373759436572224

Epoch: 5| Step: 9
Training loss: 4.004356396189665
Validation loss: 3.4331888469715257

Epoch: 5| Step: 10
Training loss: 3.602007195083744
Validation loss: 3.431876789359181

Epoch: 32| Step: 0
Training loss: 4.41833893888663
Validation loss: 3.43174074448906

Epoch: 5| Step: 1
Training loss: 3.4977312909448584
Validation loss: 3.4311875885135734

Epoch: 5| Step: 2
Training loss: 3.686474932420966
Validation loss: 3.431510020032585

Epoch: 5| Step: 3
Training loss: 3.348262131122062
Validation loss: 3.431183231083007

Epoch: 5| Step: 4
Training loss: 3.2100233275614634
Validation loss: 3.429828247079585

Epoch: 5| Step: 5
Training loss: 3.500067846458061
Validation loss: 3.4258241025315743

Epoch: 5| Step: 6
Training loss: 2.7745885045586323
Validation loss: 3.4246600554293036

Epoch: 5| Step: 7
Training loss: 3.250185154262339
Validation loss: 3.4220935787121882

Epoch: 5| Step: 8
Training loss: 4.083878824556638
Validation loss: 3.421794360541363

Epoch: 5| Step: 9
Training loss: 4.282346042197205
Validation loss: 3.4181793239906364

Epoch: 5| Step: 10
Training loss: 3.763414929442719
Validation loss: 3.41529575780045

Epoch: 33| Step: 0
Training loss: 3.5127517827160943
Validation loss: 3.413483421125688

Epoch: 5| Step: 1
Training loss: 3.445545422212681
Validation loss: 3.4147259422471308

Epoch: 5| Step: 2
Training loss: 2.891012464793993
Validation loss: 3.4129819071537404

Epoch: 5| Step: 3
Training loss: 4.040880395498924
Validation loss: 3.4110432549915495

Epoch: 5| Step: 4
Training loss: 4.505769633642523
Validation loss: 3.409173688184956

Epoch: 5| Step: 5
Training loss: 3.8662627376392202
Validation loss: 3.40460776775031

Epoch: 5| Step: 6
Training loss: 4.310968099321675
Validation loss: 3.404831325086409

Epoch: 5| Step: 7
Training loss: 3.002573975375144
Validation loss: 3.4041353879433376

Epoch: 5| Step: 8
Training loss: 2.3125729935956634
Validation loss: 3.399507021286455

Epoch: 5| Step: 9
Training loss: 3.616739925105488
Validation loss: 3.4005627478287046

Epoch: 5| Step: 10
Training loss: 3.8898737538305466
Validation loss: 3.4002820052423854

Epoch: 34| Step: 0
Training loss: 2.942565284335368
Validation loss: 3.3988299022452177

Epoch: 5| Step: 1
Training loss: 4.171661257179605
Validation loss: 3.398264658465553

Epoch: 5| Step: 2
Training loss: 3.6201842317014696
Validation loss: 3.3986197753122442

Epoch: 5| Step: 3
Training loss: 4.097165146482239
Validation loss: 3.3964456282652864

Epoch: 5| Step: 4
Training loss: 3.6537029817461626
Validation loss: 3.393904437041882

Epoch: 5| Step: 5
Training loss: 4.079798563304158
Validation loss: 3.391575789949301

Epoch: 5| Step: 6
Training loss: 3.847925662760123
Validation loss: 3.392336815568869

Epoch: 5| Step: 7
Training loss: 3.4876272308221066
Validation loss: 3.3877413808961876

Epoch: 5| Step: 8
Training loss: 2.8916744492249284
Validation loss: 3.3899886077172536

Epoch: 5| Step: 9
Training loss: 2.6760131735427546
Validation loss: 3.387301599176048

Epoch: 5| Step: 10
Training loss: 4.0348950843454165
Validation loss: 3.3887480342777874

Epoch: 35| Step: 0
Training loss: 3.4983804225311905
Validation loss: 3.3849376910734876

Epoch: 5| Step: 1
Training loss: 3.4794824574923595
Validation loss: 3.385486869494302

Epoch: 5| Step: 2
Training loss: 3.514579108747662
Validation loss: 3.3812303328973745

Epoch: 5| Step: 3
Training loss: 4.602413597477003
Validation loss: 3.382020167273241

Epoch: 5| Step: 4
Training loss: 2.963664950112181
Validation loss: 3.3830736698842907

Epoch: 5| Step: 5
Training loss: 4.092878875066048
Validation loss: 3.3830571213468987

Epoch: 5| Step: 6
Training loss: 4.227385548328748
Validation loss: 3.3863185320550118

Epoch: 5| Step: 7
Training loss: 2.6910667703624203
Validation loss: 3.3824881428199993

Epoch: 5| Step: 8
Training loss: 3.287318548844506
Validation loss: 3.377732154338471

Epoch: 5| Step: 9
Training loss: 3.8086395730416482
Validation loss: 3.377300979044243

Epoch: 5| Step: 10
Training loss: 2.965372513372714
Validation loss: 3.3761809108751257

Epoch: 36| Step: 0
Training loss: 3.783328281236768
Validation loss: 3.372140401400687

Epoch: 5| Step: 1
Training loss: 3.4827988142974298
Validation loss: 3.371017626872989

Epoch: 5| Step: 2
Training loss: 2.7838694206559738
Validation loss: 3.3706324554299636

Epoch: 5| Step: 3
Training loss: 3.6547194969991343
Validation loss: 3.371056623288522

Epoch: 5| Step: 4
Training loss: 3.374806857763785
Validation loss: 3.3693101183235763

Epoch: 5| Step: 5
Training loss: 3.650407214507181
Validation loss: 3.366524582866612

Epoch: 5| Step: 6
Training loss: 4.422204103118565
Validation loss: 3.369961199769096

Epoch: 5| Step: 7
Training loss: 4.250973085191261
Validation loss: 3.3654340220181327

Epoch: 5| Step: 8
Training loss: 2.857654825389907
Validation loss: 3.3631199065359856

Epoch: 5| Step: 9
Training loss: 2.9222777389970807
Validation loss: 3.3637183006432703

Epoch: 5| Step: 10
Training loss: 4.023143572394797
Validation loss: 3.3621388731335284

Epoch: 37| Step: 0
Training loss: 4.7070695424401965
Validation loss: 3.360807074185866

Epoch: 5| Step: 1
Training loss: 4.0205245352381755
Validation loss: 3.3606267262122986

Epoch: 5| Step: 2
Training loss: 3.3358414432891776
Validation loss: 3.3613166602722737

Epoch: 5| Step: 3
Training loss: 3.4313640971573887
Validation loss: 3.3619273237739713

Epoch: 5| Step: 4
Training loss: 3.266655426265555
Validation loss: 3.3636497610192753

Epoch: 5| Step: 5
Training loss: 3.18829335829911
Validation loss: 3.355376621840884

Epoch: 5| Step: 6
Training loss: 3.491227873647732
Validation loss: 3.3569790857896273

Epoch: 5| Step: 7
Training loss: 3.530080956241257
Validation loss: 3.3558146278557976

Epoch: 5| Step: 8
Training loss: 2.5757600051610035
Validation loss: 3.355076366818556

Epoch: 5| Step: 9
Training loss: 3.7487135905920517
Validation loss: 3.3526023626329433

Epoch: 5| Step: 10
Training loss: 3.828007412097097
Validation loss: 3.3522233056051705

Epoch: 38| Step: 0
Training loss: 3.647701082916145
Validation loss: 3.351199739058188

Epoch: 5| Step: 1
Training loss: 3.558134248213255
Validation loss: 3.3527591121088403

Epoch: 5| Step: 2
Training loss: 3.909066733473043
Validation loss: 3.353945921600317

Epoch: 5| Step: 3
Training loss: 2.710344497067789
Validation loss: 3.3504701098105545

Epoch: 5| Step: 4
Training loss: 3.7428987022347306
Validation loss: 3.3492065443855448

Epoch: 5| Step: 5
Training loss: 4.043415255008874
Validation loss: 3.3491179962876094

Epoch: 5| Step: 6
Training loss: 2.6043134927684344
Validation loss: 3.3485177073545733

Epoch: 5| Step: 7
Training loss: 3.5590511827810616
Validation loss: 3.3456499530484067

Epoch: 5| Step: 8
Training loss: 3.9602138001110916
Validation loss: 3.3448842497510487

Epoch: 5| Step: 9
Training loss: 4.290894275281159
Validation loss: 3.346043332848669

Epoch: 5| Step: 10
Training loss: 2.7956808940264204
Validation loss: 3.342622307847153

Epoch: 39| Step: 0
Training loss: 3.1679004139708864
Validation loss: 3.346098135063552

Epoch: 5| Step: 1
Training loss: 3.5471768019744
Validation loss: 3.348734141380311

Epoch: 5| Step: 2
Training loss: 3.34400354297578
Validation loss: 3.344836054357785

Epoch: 5| Step: 3
Training loss: 2.908493652588645
Validation loss: 3.3431901115126426

Epoch: 5| Step: 4
Training loss: 4.051126375274816
Validation loss: 3.3399057970350485

Epoch: 5| Step: 5
Training loss: 3.190884457611427
Validation loss: 3.3420802998089325

Epoch: 5| Step: 6
Training loss: 4.075682862527264
Validation loss: 3.3402362187264245

Epoch: 5| Step: 7
Training loss: 4.401102292096612
Validation loss: 3.3381141630900446

Epoch: 5| Step: 8
Training loss: 3.8730467518831926
Validation loss: 3.340622066146305

Epoch: 5| Step: 9
Training loss: 3.2461248917353966
Validation loss: 3.34019541188853

Epoch: 5| Step: 10
Training loss: 3.153857542450402
Validation loss: 3.336067203525608

Epoch: 40| Step: 0
Training loss: 2.576119122315744
Validation loss: 3.334613616220291

Epoch: 5| Step: 1
Training loss: 3.421851171123153
Validation loss: 3.3356031324386524

Epoch: 5| Step: 2
Training loss: 3.4806173958595137
Validation loss: 3.335646518636167

Epoch: 5| Step: 3
Training loss: 3.940098828271988
Validation loss: 3.3387112600893376

Epoch: 5| Step: 4
Training loss: 4.649075299272497
Validation loss: 3.333362325931923

Epoch: 5| Step: 5
Training loss: 3.0700778240566087
Validation loss: 3.335283681485515

Epoch: 5| Step: 6
Training loss: 3.9566240468310134
Validation loss: 3.3338299340345103

Epoch: 5| Step: 7
Training loss: 3.492450064190854
Validation loss: 3.3331319860949082

Epoch: 5| Step: 8
Training loss: 3.3487935754917597
Validation loss: 3.330109100298778

Epoch: 5| Step: 9
Training loss: 3.1373744863504163
Validation loss: 3.329155768813344

Epoch: 5| Step: 10
Training loss: 3.794180208100043
Validation loss: 3.333337418235819

Epoch: 41| Step: 0
Training loss: 3.0784572673717094
Validation loss: 3.3324968508751285

Epoch: 5| Step: 1
Training loss: 3.974170497498626
Validation loss: 3.334959367779842

Epoch: 5| Step: 2
Training loss: 3.7347966039956946
Validation loss: 3.3327848080546616

Epoch: 5| Step: 3
Training loss: 3.564267707078093
Validation loss: 3.3303543735978276

Epoch: 5| Step: 4
Training loss: 3.2280598045774664
Validation loss: 3.329870108196212

Epoch: 5| Step: 5
Training loss: 3.573590065952257
Validation loss: 3.327489069322868

Epoch: 5| Step: 6
Training loss: 3.8656378829852396
Validation loss: 3.3288047381771335

Epoch: 5| Step: 7
Training loss: 3.6424260084691977
Validation loss: 3.32812134879601

Epoch: 5| Step: 8
Training loss: 3.783467170823957
Validation loss: 3.3240974949490347

Epoch: 5| Step: 9
Training loss: 3.0158450980236764
Validation loss: 3.3245840755757343

Epoch: 5| Step: 10
Training loss: 3.590705709986205
Validation loss: 3.3238891794485492

Epoch: 42| Step: 0
Training loss: 4.5796502082214845
Validation loss: 3.3291094834287285

Epoch: 5| Step: 1
Training loss: 2.8831674414156487
Validation loss: 3.3246774934485273

Epoch: 5| Step: 2
Training loss: 2.921012057406501
Validation loss: 3.3284272611216363

Epoch: 5| Step: 3
Training loss: 3.5473241311608548
Validation loss: 3.329429945658428

Epoch: 5| Step: 4
Training loss: 3.8624997481559005
Validation loss: 3.326484730060752

Epoch: 5| Step: 5
Training loss: 3.134167461427282
Validation loss: 3.3259845871891134

Epoch: 5| Step: 6
Training loss: 3.473851756568108
Validation loss: 3.321365646127399

Epoch: 5| Step: 7
Training loss: 3.098979037346586
Validation loss: 3.3224881765427337

Epoch: 5| Step: 8
Training loss: 3.4517322337948464
Validation loss: 3.322212491544971

Epoch: 5| Step: 9
Training loss: 3.832632221845034
Validation loss: 3.3203302599862026

Epoch: 5| Step: 10
Training loss: 4.074490970576757
Validation loss: 3.3198814734833477

Epoch: 43| Step: 0
Training loss: 3.4095510183853617
Validation loss: 3.3195092867424556

Epoch: 5| Step: 1
Training loss: 3.5757527712587387
Validation loss: 3.3171550928041538

Epoch: 5| Step: 2
Training loss: 4.018188608211679
Validation loss: 3.3174396770002397

Epoch: 5| Step: 3
Training loss: 3.8453877999296955
Validation loss: 3.317245093806641

Epoch: 5| Step: 4
Training loss: 2.6288537392891342
Validation loss: 3.313962357053157

Epoch: 5| Step: 5
Training loss: 3.87849846700776
Validation loss: 3.3142044324369038

Epoch: 5| Step: 6
Training loss: 3.6637353161322674
Validation loss: 3.3117980847977835

Epoch: 5| Step: 7
Training loss: 2.919071096528715
Validation loss: 3.3127110731905507

Epoch: 5| Step: 8
Training loss: 3.259981087705833
Validation loss: 3.3107035372932745

Epoch: 5| Step: 9
Training loss: 3.6564586612467327
Validation loss: 3.312825105532089

Epoch: 5| Step: 10
Training loss: 4.012796437374158
Validation loss: 3.3137055113301264

Epoch: 44| Step: 0
Training loss: 2.6534490740115597
Validation loss: 3.312943082009884

Epoch: 5| Step: 1
Training loss: 2.4613579284965548
Validation loss: 3.312223369109269

Epoch: 5| Step: 2
Training loss: 3.3144654974540733
Validation loss: 3.3090849066541135

Epoch: 5| Step: 3
Training loss: 3.977877116664823
Validation loss: 3.3112960658359705

Epoch: 5| Step: 4
Training loss: 4.0505093195400335
Validation loss: 3.310189911118468

Epoch: 5| Step: 5
Training loss: 3.7331514149575438
Validation loss: 3.3100652308217553

Epoch: 5| Step: 6
Training loss: 3.817504974541861
Validation loss: 3.3108628759399

Epoch: 5| Step: 7
Training loss: 3.787718481428585
Validation loss: 3.310667654531241

Epoch: 5| Step: 8
Training loss: 3.5417827063605563
Validation loss: 3.3059882490363655

Epoch: 5| Step: 9
Training loss: 3.636854060654083
Validation loss: 3.304679448388896

Epoch: 5| Step: 10
Training loss: 3.645796610329375
Validation loss: 3.3054343782998434

Epoch: 45| Step: 0
Training loss: 3.1587808867296654
Validation loss: 3.3026494262029846

Epoch: 5| Step: 1
Training loss: 3.5962170964480378
Validation loss: 3.3064381195721446

Epoch: 5| Step: 2
Training loss: 4.4756523125737635
Validation loss: 3.3034864225230844

Epoch: 5| Step: 3
Training loss: 3.562232024169475
Validation loss: 3.3015217625579627

Epoch: 5| Step: 4
Training loss: 3.645512128940319
Validation loss: 3.300754128330309

Epoch: 5| Step: 5
Training loss: 3.061884292678763
Validation loss: 3.3020401834049675

Epoch: 5| Step: 6
Training loss: 3.4652609934089247
Validation loss: 3.3018128341965074

Epoch: 5| Step: 7
Training loss: 3.647297258291986
Validation loss: 3.3072892151309072

Epoch: 5| Step: 8
Training loss: 3.7637264800057384
Validation loss: 3.2997484731541777

Epoch: 5| Step: 9
Training loss: 3.2993056751735543
Validation loss: 3.299349334325251

Epoch: 5| Step: 10
Training loss: 2.9675465604090867
Validation loss: 3.3022978603531823

Epoch: 46| Step: 0
Training loss: 2.53801482667192
Validation loss: 3.3000666438533184

Epoch: 5| Step: 1
Training loss: 3.3490430347574254
Validation loss: 3.2999143662688715

Epoch: 5| Step: 2
Training loss: 3.475965538635452
Validation loss: 3.2975579426162205

Epoch: 5| Step: 3
Training loss: 3.4647185121285298
Validation loss: 3.298783641391333

Epoch: 5| Step: 4
Training loss: 4.02948905867414
Validation loss: 3.2999968125075294

Epoch: 5| Step: 5
Training loss: 3.4214761579954702
Validation loss: 3.298647204152892

Epoch: 5| Step: 6
Training loss: 4.284699324359983
Validation loss: 3.2984113544168125

Epoch: 5| Step: 7
Training loss: 3.184205540573909
Validation loss: 3.29701423205221

Epoch: 5| Step: 8
Training loss: 3.9432956488241717
Validation loss: 3.298051773485869

Epoch: 5| Step: 9
Training loss: 3.324516094818834
Validation loss: 3.29764493967963

Epoch: 5| Step: 10
Training loss: 3.5945969620161784
Validation loss: 3.2950491955227714

Epoch: 47| Step: 0
Training loss: 3.66716551999631
Validation loss: 3.2944397953971825

Epoch: 5| Step: 1
Training loss: 3.7970940169599188
Validation loss: 3.2936102717216325

Epoch: 5| Step: 2
Training loss: 3.5046245812505186
Validation loss: 3.2915936891984656

Epoch: 5| Step: 3
Training loss: 4.099603326728507
Validation loss: 3.289723378888508

Epoch: 5| Step: 4
Training loss: 2.8433864486879075
Validation loss: 3.2828713071413564

Epoch: 5| Step: 5
Training loss: 2.0496062482108797
Validation loss: 3.2856441212259617

Epoch: 5| Step: 6
Training loss: 3.3089703162053046
Validation loss: 3.2822968796955023

Epoch: 5| Step: 7
Training loss: 3.9636871003760503
Validation loss: 3.282363205860126

Epoch: 5| Step: 8
Training loss: 3.8565298859902075
Validation loss: 3.2827116117811883

Epoch: 5| Step: 9
Training loss: 3.775104162534894
Validation loss: 3.283965389362848

Epoch: 5| Step: 10
Training loss: 3.4435478414195178
Validation loss: 3.2837147281988233

Epoch: 48| Step: 0
Training loss: 3.659909495501055
Validation loss: 3.281074352807633

Epoch: 5| Step: 1
Training loss: 3.559687524862007
Validation loss: 3.2805668164085438

Epoch: 5| Step: 2
Training loss: 3.8428787856827067
Validation loss: 3.2806816269009134

Epoch: 5| Step: 3
Training loss: 2.4424644191184584
Validation loss: 3.2744245584576346

Epoch: 5| Step: 4
Training loss: 3.85209209522979
Validation loss: 3.276832378064784

Epoch: 5| Step: 5
Training loss: 3.895101033027913
Validation loss: 3.2725496444145965

Epoch: 5| Step: 6
Training loss: 2.9016648085002292
Validation loss: 3.271844865151443

Epoch: 5| Step: 7
Training loss: 3.3491512419025953
Validation loss: 3.269734924702405

Epoch: 5| Step: 8
Training loss: 3.5697344222245504
Validation loss: 3.2709454408213747

Epoch: 5| Step: 9
Training loss: 3.7319642269959057
Validation loss: 3.2707209826778056

Epoch: 5| Step: 10
Training loss: 3.5916564150587966
Validation loss: 3.263977627554081

Epoch: 49| Step: 0
Training loss: 3.2970358280529566
Validation loss: 3.267175919171948

Epoch: 5| Step: 1
Training loss: 3.820819719651547
Validation loss: 3.2686489349278354

Epoch: 5| Step: 2
Training loss: 3.4922384305308065
Validation loss: 3.270387535421433

Epoch: 5| Step: 3
Training loss: 2.854522088932081
Validation loss: 3.28778092982146

Epoch: 5| Step: 4
Training loss: 4.063168279995011
Validation loss: 3.288225841086814

Epoch: 5| Step: 5
Training loss: 2.8117997887314807
Validation loss: 3.2709068967782913

Epoch: 5| Step: 6
Training loss: 3.5571680154529015
Validation loss: 3.2665953970771735

Epoch: 5| Step: 7
Training loss: 3.4448935325348575
Validation loss: 3.262735474730423

Epoch: 5| Step: 8
Training loss: 3.8344567076442333
Validation loss: 3.2688590202675263

Epoch: 5| Step: 9
Training loss: 3.6965126201796554
Validation loss: 3.2659581846508177

Epoch: 5| Step: 10
Training loss: 3.5488361868716907
Validation loss: 3.2636317274349835

Epoch: 50| Step: 0
Training loss: 3.420585772670851
Validation loss: 3.2628679529985427

Epoch: 5| Step: 1
Training loss: 3.141908146273787
Validation loss: 3.2579341981866263

Epoch: 5| Step: 2
Training loss: 4.265729630413202
Validation loss: 3.2583692272726874

Epoch: 5| Step: 3
Training loss: 3.9343914295244358
Validation loss: 3.2576958888313055

Epoch: 5| Step: 4
Training loss: 2.8030600753971364
Validation loss: 3.257084490100466

Epoch: 5| Step: 5
Training loss: 3.3334155231515608
Validation loss: 3.2563969782526296

Epoch: 5| Step: 6
Training loss: 3.743923350095672
Validation loss: 3.259218424221907

Epoch: 5| Step: 7
Training loss: 3.1297918583215747
Validation loss: 3.2571545543387885

Epoch: 5| Step: 8
Training loss: 3.621785810687332
Validation loss: 3.253504514616947

Epoch: 5| Step: 9
Training loss: 3.452328689380054
Validation loss: 3.252264160212801

Epoch: 5| Step: 10
Training loss: 3.4290804314846306
Validation loss: 3.2510240012819063

Epoch: 51| Step: 0
Training loss: 3.8832211807056844
Validation loss: 3.2504666445408774

Epoch: 5| Step: 1
Training loss: 3.1982834861360288
Validation loss: 3.2463918508337146

Epoch: 5| Step: 2
Training loss: 3.3764275251575593
Validation loss: 3.2511294794745393

Epoch: 5| Step: 3
Training loss: 4.0101677887551945
Validation loss: 3.2488857067625116

Epoch: 5| Step: 4
Training loss: 3.208767717027959
Validation loss: 3.2479193774167174

Epoch: 5| Step: 5
Training loss: 4.007530990737767
Validation loss: 3.247564010251364

Epoch: 5| Step: 6
Training loss: 3.658631812383753
Validation loss: 3.2544850984831006

Epoch: 5| Step: 7
Training loss: 3.603136095359109
Validation loss: 3.2641799743430164

Epoch: 5| Step: 8
Training loss: 2.894408353392196
Validation loss: 3.2684071806321557

Epoch: 5| Step: 9
Training loss: 3.2420691043424017
Validation loss: 3.2775027471565745

Epoch: 5| Step: 10
Training loss: 3.0729669254309395
Validation loss: 3.255241458584818

Epoch: 52| Step: 0
Training loss: 3.7141922661270916
Validation loss: 3.2445313421621695

Epoch: 5| Step: 1
Training loss: 4.024576266712673
Validation loss: 3.2478947056159795

Epoch: 5| Step: 2
Training loss: 3.172300112945148
Validation loss: 3.251394368716906

Epoch: 5| Step: 3
Training loss: 3.1717771317740815
Validation loss: 3.2524873997669173

Epoch: 5| Step: 4
Training loss: 3.5145164267806925
Validation loss: 3.252374718574289

Epoch: 5| Step: 5
Training loss: 3.5079266841799916
Validation loss: 3.2516609015021336

Epoch: 5| Step: 6
Training loss: 3.116504106685063
Validation loss: 3.247643988541412

Epoch: 5| Step: 7
Training loss: 3.9901941029462478
Validation loss: 3.2432192514252383

Epoch: 5| Step: 8
Training loss: 2.48943490153846
Validation loss: 3.240609180317963

Epoch: 5| Step: 9
Training loss: 3.682387347599216
Validation loss: 3.240914690480106

Epoch: 5| Step: 10
Training loss: 3.79889402356885
Validation loss: 3.2396091306764707

Epoch: 53| Step: 0
Training loss: 3.7338281973334215
Validation loss: 3.2393493462329013

Epoch: 5| Step: 1
Training loss: 4.004007715939948
Validation loss: 3.2383736758116646

Epoch: 5| Step: 2
Training loss: 3.179555829295414
Validation loss: 3.2411760674248344

Epoch: 5| Step: 3
Training loss: 3.2218485611904724
Validation loss: 3.23891729994386

Epoch: 5| Step: 4
Training loss: 3.378648410727726
Validation loss: 3.2399887336710798

Epoch: 5| Step: 5
Training loss: 3.4958403255739783
Validation loss: 3.2354377616315753

Epoch: 5| Step: 6
Training loss: 3.2818767130754103
Validation loss: 3.237699354087502

Epoch: 5| Step: 7
Training loss: 3.855042036844081
Validation loss: 3.237049135719378

Epoch: 5| Step: 8
Training loss: 3.927432192308749
Validation loss: 3.236632360859927

Epoch: 5| Step: 9
Training loss: 2.839519330033653
Validation loss: 3.2342645999724593

Epoch: 5| Step: 10
Training loss: 3.1819905556395356
Validation loss: 3.237792368179914

Epoch: 54| Step: 0
Training loss: 3.5623361650238343
Validation loss: 3.2375277169424086

Epoch: 5| Step: 1
Training loss: 3.5518062778089416
Validation loss: 3.238210493190751

Epoch: 5| Step: 2
Training loss: 3.433300574309964
Validation loss: 3.2382057003300253

Epoch: 5| Step: 3
Training loss: 3.8972237021806775
Validation loss: 3.2368907429153455

Epoch: 5| Step: 4
Training loss: 3.171089262957992
Validation loss: 3.2348846482639075

Epoch: 5| Step: 5
Training loss: 2.5905187311222373
Validation loss: 3.2352536429645524

Epoch: 5| Step: 6
Training loss: 3.817047283956087
Validation loss: 3.2338897466299708

Epoch: 5| Step: 7
Training loss: 3.7957204311314334
Validation loss: 3.234163701948624

Epoch: 5| Step: 8
Training loss: 3.79507742821635
Validation loss: 3.2340001451851204

Epoch: 5| Step: 9
Training loss: 3.0082801356239495
Validation loss: 3.2313225341774974

Epoch: 5| Step: 10
Training loss: 3.3946739667208146
Validation loss: 3.2323628771812314

Epoch: 55| Step: 0
Training loss: 4.473029161924037
Validation loss: 3.230006788978057

Epoch: 5| Step: 1
Training loss: 3.6832422794692747
Validation loss: 3.228489818685373

Epoch: 5| Step: 2
Training loss: 3.2653571936204333
Validation loss: 3.22456158418569

Epoch: 5| Step: 3
Training loss: 2.7149464978870506
Validation loss: 3.22711700161534

Epoch: 5| Step: 4
Training loss: 2.8192599966499965
Validation loss: 3.2269664661391726

Epoch: 5| Step: 5
Training loss: 3.3451292811843483
Validation loss: 3.2270491729419466

Epoch: 5| Step: 6
Training loss: 3.2033572229082714
Validation loss: 3.2251271211919317

Epoch: 5| Step: 7
Training loss: 2.7879464617313268
Validation loss: 3.2260870680218683

Epoch: 5| Step: 8
Training loss: 4.468440972160166
Validation loss: 3.2272166392257398

Epoch: 5| Step: 9
Training loss: 3.6976785645818073
Validation loss: 3.2231798712024395

Epoch: 5| Step: 10
Training loss: 3.1529537400161978
Validation loss: 3.227320792058336

Epoch: 56| Step: 0
Training loss: 3.5377871339547524
Validation loss: 3.2226032879934454

Epoch: 5| Step: 1
Training loss: 3.539364968147052
Validation loss: 3.2233468831565406

Epoch: 5| Step: 2
Training loss: 3.830352882283801
Validation loss: 3.22544459100196

Epoch: 5| Step: 3
Training loss: 2.9256803650518126
Validation loss: 3.222493068607073

Epoch: 5| Step: 4
Training loss: 2.941606451468283
Validation loss: 3.226745115630099

Epoch: 5| Step: 5
Training loss: 3.6326095688448388
Validation loss: 3.226055484921346

Epoch: 5| Step: 6
Training loss: 3.3953496826495297
Validation loss: 3.2275911841744116

Epoch: 5| Step: 7
Training loss: 3.628339873135557
Validation loss: 3.224324910949878

Epoch: 5| Step: 8
Training loss: 3.1928083311832003
Validation loss: 3.2231848804780063

Epoch: 5| Step: 9
Training loss: 3.7546899078780513
Validation loss: 3.2258276664384935

Epoch: 5| Step: 10
Training loss: 3.671270702227059
Validation loss: 3.220241805844133

Epoch: 57| Step: 0
Training loss: 3.8500732266286612
Validation loss: 3.2214567641113123

Epoch: 5| Step: 1
Training loss: 3.3915150963909704
Validation loss: 3.2215237412658344

Epoch: 5| Step: 2
Training loss: 3.3623502109447254
Validation loss: 3.2200715549512995

Epoch: 5| Step: 3
Training loss: 3.225931840274705
Validation loss: 3.2244084249272893

Epoch: 5| Step: 4
Training loss: 3.5674194367473957
Validation loss: 3.222243189139415

Epoch: 5| Step: 5
Training loss: 3.070079066597258
Validation loss: 3.223268032678911

Epoch: 5| Step: 6
Training loss: 2.954318658086921
Validation loss: 3.2196895392170233

Epoch: 5| Step: 7
Training loss: 3.9096992827774475
Validation loss: 3.2184772258393886

Epoch: 5| Step: 8
Training loss: 3.593454896171693
Validation loss: 3.2167073789563383

Epoch: 5| Step: 9
Training loss: 3.3971983305648177
Validation loss: 3.2157256408356014

Epoch: 5| Step: 10
Training loss: 3.7512496137761824
Validation loss: 3.2162610115802153

Epoch: 58| Step: 0
Training loss: 3.577171898384026
Validation loss: 3.21412978690148

Epoch: 5| Step: 1
Training loss: 3.541711619970723
Validation loss: 3.2143841420924857

Epoch: 5| Step: 2
Training loss: 3.6817872359733883
Validation loss: 3.2141229202198995

Epoch: 5| Step: 3
Training loss: 3.5801973297035876
Validation loss: 3.2127376514618224

Epoch: 5| Step: 4
Training loss: 3.612793859653644
Validation loss: 3.214828837862802

Epoch: 5| Step: 5
Training loss: 3.7612251124219456
Validation loss: 3.21247487202591

Epoch: 5| Step: 6
Training loss: 3.370943810939849
Validation loss: 3.211987540822514

Epoch: 5| Step: 7
Training loss: 3.537745755019804
Validation loss: 3.209888503768984

Epoch: 5| Step: 8
Training loss: 3.250665449827038
Validation loss: 3.2108775932348967

Epoch: 5| Step: 9
Training loss: 3.3738623220396255
Validation loss: 3.210571672217631

Epoch: 5| Step: 10
Training loss: 2.485695541950081
Validation loss: 3.2086122394518233

Epoch: 59| Step: 0
Training loss: 2.9122649265757876
Validation loss: 3.2112416952973386

Epoch: 5| Step: 1
Training loss: 3.4476873469468434
Validation loss: 3.208472081223181

Epoch: 5| Step: 2
Training loss: 3.6706347379680313
Validation loss: 3.2085974781263173

Epoch: 5| Step: 3
Training loss: 3.97169133323686
Validation loss: 3.21117220762984

Epoch: 5| Step: 4
Training loss: 3.6654770973332
Validation loss: 3.209492920661866

Epoch: 5| Step: 5
Training loss: 3.654462980800264
Validation loss: 3.2110480761128013

Epoch: 5| Step: 6
Training loss: 3.2776548035680237
Validation loss: 3.208286184905498

Epoch: 5| Step: 7
Training loss: 2.54850651257577
Validation loss: 3.2075933008597914

Epoch: 5| Step: 8
Training loss: 3.261938907708431
Validation loss: 3.206715195853375

Epoch: 5| Step: 9
Training loss: 3.750086719781796
Validation loss: 3.202795636530995

Epoch: 5| Step: 10
Training loss: 3.660035741037427
Validation loss: 3.2044202089272416

Epoch: 60| Step: 0
Training loss: 4.170354101574533
Validation loss: 3.2040254981341256

Epoch: 5| Step: 1
Training loss: 3.1268613231176063
Validation loss: 3.2057391816349954

Epoch: 5| Step: 2
Training loss: 3.1812104648014574
Validation loss: 3.2058005582860827

Epoch: 5| Step: 3
Training loss: 3.7894595223296044
Validation loss: 3.205862443953321

Epoch: 5| Step: 4
Training loss: 3.928502414146712
Validation loss: 3.204411781372737

Epoch: 5| Step: 5
Training loss: 3.619198332901359
Validation loss: 3.201582210992192

Epoch: 5| Step: 6
Training loss: 3.237134852492657
Validation loss: 3.2021334550330636

Epoch: 5| Step: 7
Training loss: 3.1735716543010195
Validation loss: 3.2023577956107387

Epoch: 5| Step: 8
Training loss: 2.368366011041338
Validation loss: 3.202588301864873

Epoch: 5| Step: 9
Training loss: 3.4303322709521513
Validation loss: 3.2027005654495495

Epoch: 5| Step: 10
Training loss: 3.6516798099320176
Validation loss: 3.201859641585026

Epoch: 61| Step: 0
Training loss: 3.562832331632747
Validation loss: 3.200571483295819

Epoch: 5| Step: 1
Training loss: 3.151149291835605
Validation loss: 3.1994986643236527

Epoch: 5| Step: 2
Training loss: 3.8673643129560444
Validation loss: 3.201655937641863

Epoch: 5| Step: 3
Training loss: 3.7405928556993975
Validation loss: 3.200419019944707

Epoch: 5| Step: 4
Training loss: 3.635487742489783
Validation loss: 3.2000274159041506

Epoch: 5| Step: 5
Training loss: 3.3623495018615266
Validation loss: 3.203328841011425

Epoch: 5| Step: 6
Training loss: 3.0076818660755213
Validation loss: 3.2090518153847993

Epoch: 5| Step: 7
Training loss: 3.4717762436027657
Validation loss: 3.2099603145516435

Epoch: 5| Step: 8
Training loss: 3.7170085515951987
Validation loss: 3.2027185645912635

Epoch: 5| Step: 9
Training loss: 3.4635487644820757
Validation loss: 3.201731023791865

Epoch: 5| Step: 10
Training loss: 2.6854252458252357
Validation loss: 3.1985162400924323

Epoch: 62| Step: 0
Training loss: 3.560664456968962
Validation loss: 3.1991221670403736

Epoch: 5| Step: 1
Training loss: 3.5048263515496174
Validation loss: 3.197819224525103

Epoch: 5| Step: 2
Training loss: 3.487258197236318
Validation loss: 3.1963594896962033

Epoch: 5| Step: 3
Training loss: 3.3837401635626274
Validation loss: 3.195623576894718

Epoch: 5| Step: 4
Training loss: 3.6452107506461098
Validation loss: 3.1983834961703095

Epoch: 5| Step: 5
Training loss: 3.639265993750196
Validation loss: 3.198356403915557

Epoch: 5| Step: 6
Training loss: 2.839533100164305
Validation loss: 3.198362462020135

Epoch: 5| Step: 7
Training loss: 3.417010049699669
Validation loss: 3.1971938818974053

Epoch: 5| Step: 8
Training loss: 3.632476069141172
Validation loss: 3.1969739133505515

Epoch: 5| Step: 9
Training loss: 2.50727719687225
Validation loss: 3.197972768986429

Epoch: 5| Step: 10
Training loss: 4.139598560865195
Validation loss: 3.197038535893336

Epoch: 63| Step: 0
Training loss: 2.859362993058807
Validation loss: 3.1961768384072267

Epoch: 5| Step: 1
Training loss: 4.059956854980929
Validation loss: 3.1971000779722227

Epoch: 5| Step: 2
Training loss: 3.0365907477705654
Validation loss: 3.1957413042964657

Epoch: 5| Step: 3
Training loss: 4.0842900355636464
Validation loss: 3.1983203035302403

Epoch: 5| Step: 4
Training loss: 3.37284527978561
Validation loss: 3.1958562662712824

Epoch: 5| Step: 5
Training loss: 2.6617241494650528
Validation loss: 3.1954296756595784

Epoch: 5| Step: 6
Training loss: 3.123579694326931
Validation loss: 3.195817147095084

Epoch: 5| Step: 7
Training loss: 3.359536242496639
Validation loss: 3.1950966416389073

Epoch: 5| Step: 8
Training loss: 4.013041693228691
Validation loss: 3.1952033242009152

Epoch: 5| Step: 9
Training loss: 3.5173669187182552
Validation loss: 3.1904260876348873

Epoch: 5| Step: 10
Training loss: 3.455907468740319
Validation loss: 3.191813897776413

Epoch: 64| Step: 0
Training loss: 3.3421811139873685
Validation loss: 3.192870569840452

Epoch: 5| Step: 1
Training loss: 3.607777692082521
Validation loss: 3.1934375133339215

Epoch: 5| Step: 2
Training loss: 3.637299422669094
Validation loss: 3.1934938401786095

Epoch: 5| Step: 3
Training loss: 2.962085028448589
Validation loss: 3.190273807209881

Epoch: 5| Step: 4
Training loss: 4.1896395555110155
Validation loss: 3.1923740303412806

Epoch: 5| Step: 5
Training loss: 3.285358726621105
Validation loss: 3.18995799181987

Epoch: 5| Step: 6
Training loss: 3.5129790118616935
Validation loss: 3.19136990712136

Epoch: 5| Step: 7
Training loss: 3.831450220946797
Validation loss: 3.1976977751036113

Epoch: 5| Step: 8
Training loss: 3.0968181154510104
Validation loss: 3.188096040786364

Epoch: 5| Step: 9
Training loss: 3.533330253983601
Validation loss: 3.19002150923438

Epoch: 5| Step: 10
Training loss: 2.393951196407318
Validation loss: 3.1894647413071042

Epoch: 65| Step: 0
Training loss: 3.7226734140967106
Validation loss: 3.186732333847894

Epoch: 5| Step: 1
Training loss: 3.154861598054796
Validation loss: 3.1840727571994654

Epoch: 5| Step: 2
Training loss: 3.801578826179364
Validation loss: 3.187898378934623

Epoch: 5| Step: 3
Training loss: 2.525139768905584
Validation loss: 3.1885213596924693

Epoch: 5| Step: 4
Training loss: 3.1922234337605198
Validation loss: 3.188853155787736

Epoch: 5| Step: 5
Training loss: 3.740765454707604
Validation loss: 3.1888793785337666

Epoch: 5| Step: 6
Training loss: 2.927288405722661
Validation loss: 3.1855324196429198

Epoch: 5| Step: 7
Training loss: 4.125675492898718
Validation loss: 3.1864943585831997

Epoch: 5| Step: 8
Training loss: 3.6047851972564713
Validation loss: 3.1874974600845953

Epoch: 5| Step: 9
Training loss: 3.44035484368989
Validation loss: 3.183425489999911

Epoch: 5| Step: 10
Training loss: 3.2114679125852175
Validation loss: 3.1859137158761697

Epoch: 66| Step: 0
Training loss: 3.6488201585998574
Validation loss: 3.1842622150914917

Epoch: 5| Step: 1
Training loss: 3.644041627497492
Validation loss: 3.182666524810329

Epoch: 5| Step: 2
Training loss: 3.4122787459752426
Validation loss: 3.183597710297008

Epoch: 5| Step: 3
Training loss: 3.6853852754632146
Validation loss: 3.1813382086771886

Epoch: 5| Step: 4
Training loss: 3.889434509753836
Validation loss: 3.182720373698542

Epoch: 5| Step: 5
Training loss: 3.7576074365826106
Validation loss: 3.1812972815548366

Epoch: 5| Step: 6
Training loss: 3.035786959635744
Validation loss: 3.1816227499568006

Epoch: 5| Step: 7
Training loss: 3.417575591227344
Validation loss: 3.187082398815084

Epoch: 5| Step: 8
Training loss: 3.5040343058139145
Validation loss: 3.1826678136114506

Epoch: 5| Step: 9
Training loss: 3.412146967138726
Validation loss: 3.184259588863299

Epoch: 5| Step: 10
Training loss: 1.583961420798346
Validation loss: 3.180183113412787

Epoch: 67| Step: 0
Training loss: 3.5030300103681724
Validation loss: 3.178843938391071

Epoch: 5| Step: 1
Training loss: 2.9503234815236588
Validation loss: 3.1791633213604973

Epoch: 5| Step: 2
Training loss: 3.1584703548236455
Validation loss: 3.178003402188868

Epoch: 5| Step: 3
Training loss: 3.8302232869450896
Validation loss: 3.1764334258853957

Epoch: 5| Step: 4
Training loss: 3.765229517006216
Validation loss: 3.1786878698109406

Epoch: 5| Step: 5
Training loss: 3.5531006341667433
Validation loss: 3.179494357233921

Epoch: 5| Step: 6
Training loss: 2.8844353468048927
Validation loss: 3.1790135053684216

Epoch: 5| Step: 7
Training loss: 2.597091819993716
Validation loss: 3.175098041922708

Epoch: 5| Step: 8
Training loss: 3.1709158814387752
Validation loss: 3.1788140214582583

Epoch: 5| Step: 9
Training loss: 3.807456009949451
Validation loss: 3.1793260141346225

Epoch: 5| Step: 10
Training loss: 4.2853414100835145
Validation loss: 3.1840482517083566

Epoch: 68| Step: 0
Training loss: 2.982502454707118
Validation loss: 3.1824633049533575

Epoch: 5| Step: 1
Training loss: 3.478587591593067
Validation loss: 3.1804610741955073

Epoch: 5| Step: 2
Training loss: 3.279576337946854
Validation loss: 3.1824613418217966

Epoch: 5| Step: 3
Training loss: 3.655939463934357
Validation loss: 3.178897255254571

Epoch: 5| Step: 4
Training loss: 3.891433447984217
Validation loss: 3.174441019128311

Epoch: 5| Step: 5
Training loss: 3.2136186603903676
Validation loss: 3.174581574294125

Epoch: 5| Step: 6
Training loss: 2.909510270691408
Validation loss: 3.1729713887742994

Epoch: 5| Step: 7
Training loss: 3.9842970896564704
Validation loss: 3.174037096033518

Epoch: 5| Step: 8
Training loss: 3.3914047258782714
Validation loss: 3.174058267154773

Epoch: 5| Step: 9
Training loss: 2.9640834069608113
Validation loss: 3.174093795422894

Epoch: 5| Step: 10
Training loss: 3.7924145530373976
Validation loss: 3.1722353323366654

Epoch: 69| Step: 0
Training loss: 3.461522037923601
Validation loss: 3.1754934630078875

Epoch: 5| Step: 1
Training loss: 2.5403637178081615
Validation loss: 3.172150255673768

Epoch: 5| Step: 2
Training loss: 3.217496757594611
Validation loss: 3.174090298182175

Epoch: 5| Step: 3
Training loss: 3.8583857083044264
Validation loss: 3.17240802839191

Epoch: 5| Step: 4
Training loss: 3.557470820743565
Validation loss: 3.169560142440262

Epoch: 5| Step: 5
Training loss: 3.1264765493616764
Validation loss: 3.1719943305542424

Epoch: 5| Step: 6
Training loss: 3.8799835890983307
Validation loss: 3.1707986795463756

Epoch: 5| Step: 7
Training loss: 3.1694329543429682
Validation loss: 3.1715626785367688

Epoch: 5| Step: 8
Training loss: 3.8682274239004015
Validation loss: 3.1702306633418753

Epoch: 5| Step: 9
Training loss: 3.6341070022239688
Validation loss: 3.17029051255673

Epoch: 5| Step: 10
Training loss: 3.0421550480581656
Validation loss: 3.169454626165563

Epoch: 70| Step: 0
Training loss: 3.6310897187726394
Validation loss: 3.1728220593204344

Epoch: 5| Step: 1
Training loss: 4.284886952425741
Validation loss: 3.170943255034678

Epoch: 5| Step: 2
Training loss: 3.2236788150402114
Validation loss: 3.168890024927716

Epoch: 5| Step: 3
Training loss: 3.5760838712888416
Validation loss: 3.169713006322748

Epoch: 5| Step: 4
Training loss: 3.0428880477604845
Validation loss: 3.1711786009693865

Epoch: 5| Step: 5
Training loss: 3.542701719540161
Validation loss: 3.1685007914345653

Epoch: 5| Step: 6
Training loss: 3.5877298102058965
Validation loss: 3.1682093054692326

Epoch: 5| Step: 7
Training loss: 3.4306282022036974
Validation loss: 3.166267438397416

Epoch: 5| Step: 8
Training loss: 2.742055167023717
Validation loss: 3.1676230117204747

Epoch: 5| Step: 9
Training loss: 3.4127296621990757
Validation loss: 3.1695036790158437

Epoch: 5| Step: 10
Training loss: 2.8126895416817232
Validation loss: 3.1714309485817718

Epoch: 71| Step: 0
Training loss: 3.955048345759804
Validation loss: 3.171428264843532

Epoch: 5| Step: 1
Training loss: 3.202645317074237
Validation loss: 3.1669797035589404

Epoch: 5| Step: 2
Training loss: 3.7685255853696216
Validation loss: 3.1662612314396155

Epoch: 5| Step: 3
Training loss: 2.02862896175657
Validation loss: 3.1676675761507864

Epoch: 5| Step: 4
Training loss: 3.730529720746839
Validation loss: 3.1675522644805825

Epoch: 5| Step: 5
Training loss: 3.325663341235959
Validation loss: 3.164906920075042

Epoch: 5| Step: 6
Training loss: 3.9105145178806926
Validation loss: 3.1659884209520666

Epoch: 5| Step: 7
Training loss: 4.02879388788258
Validation loss: 3.1650799252726176

Epoch: 5| Step: 8
Training loss: 3.1061014550533397
Validation loss: 3.169515069165917

Epoch: 5| Step: 9
Training loss: 2.6765498261783547
Validation loss: 3.167451635476236

Epoch: 5| Step: 10
Training loss: 3.329350635345603
Validation loss: 3.1748902267730226

Epoch: 72| Step: 0
Training loss: 3.458243326754706
Validation loss: 3.175242944836908

Epoch: 5| Step: 1
Training loss: 3.1735105009336477
Validation loss: 3.175945380110192

Epoch: 5| Step: 2
Training loss: 2.984260596833737
Validation loss: 3.1760784693674102

Epoch: 5| Step: 3
Training loss: 3.4251342301622145
Validation loss: 3.1681837483343944

Epoch: 5| Step: 4
Training loss: 3.40700725572338
Validation loss: 3.1636031043802286

Epoch: 5| Step: 5
Training loss: 3.1752478795646315
Validation loss: 3.1628443106927393

Epoch: 5| Step: 6
Training loss: 3.3750333431150974
Validation loss: 3.162417091658677

Epoch: 5| Step: 7
Training loss: 3.602066898400383
Validation loss: 3.163885693235472

Epoch: 5| Step: 8
Training loss: 3.9066999252604844
Validation loss: 3.1661865121857966

Epoch: 5| Step: 9
Training loss: 3.581829968104315
Validation loss: 3.1641208413904565

Epoch: 5| Step: 10
Training loss: 3.485430228386895
Validation loss: 3.16306007231653

Epoch: 73| Step: 0
Training loss: 3.396554008415011
Validation loss: 3.1629546463866673

Epoch: 5| Step: 1
Training loss: 3.2091713013306378
Validation loss: 3.162874900668156

Epoch: 5| Step: 2
Training loss: 3.495894749268265
Validation loss: 3.161824409009053

Epoch: 5| Step: 3
Training loss: 4.110566289272788
Validation loss: 3.1616060274795927

Epoch: 5| Step: 4
Training loss: 2.9968461306775547
Validation loss: 3.1601323264840318

Epoch: 5| Step: 5
Training loss: 3.2394557980929224
Validation loss: 3.1592378293646055

Epoch: 5| Step: 6
Training loss: 3.697671343049035
Validation loss: 3.1599505310501184

Epoch: 5| Step: 7
Training loss: 2.6768925718825822
Validation loss: 3.160802661526576

Epoch: 5| Step: 8
Training loss: 3.6868096691447234
Validation loss: 3.1584546708546895

Epoch: 5| Step: 9
Training loss: 3.8197393006847093
Validation loss: 3.1575469328577497

Epoch: 5| Step: 10
Training loss: 2.8832656793613736
Validation loss: 3.1616912273255844

Epoch: 74| Step: 0
Training loss: 3.4413361385274412
Validation loss: 3.158529658239509

Epoch: 5| Step: 1
Training loss: 4.008433035537781
Validation loss: 3.1636885583703354

Epoch: 5| Step: 2
Training loss: 2.4837218571658597
Validation loss: 3.171015461077854

Epoch: 5| Step: 3
Training loss: 2.6402047629853866
Validation loss: 3.172897682383351

Epoch: 5| Step: 4
Training loss: 3.4188257854088677
Validation loss: 3.1820779924070024

Epoch: 5| Step: 5
Training loss: 3.5220543965477322
Validation loss: 3.2124826447963053

Epoch: 5| Step: 6
Training loss: 2.951686932842255
Validation loss: 3.1828758015532945

Epoch: 5| Step: 7
Training loss: 3.9243591465745986
Validation loss: 3.1583933051470763

Epoch: 5| Step: 8
Training loss: 2.8722604055057634
Validation loss: 3.1586918059702547

Epoch: 5| Step: 9
Training loss: 3.859245761452623
Validation loss: 3.157479322039355

Epoch: 5| Step: 10
Training loss: 4.077696094393551
Validation loss: 3.154737518903325

Epoch: 75| Step: 0
Training loss: 4.076413317897251
Validation loss: 3.1585315380350427

Epoch: 5| Step: 1
Training loss: 3.108952019066932
Validation loss: 3.158002781148567

Epoch: 5| Step: 2
Training loss: 3.3361288904681
Validation loss: 3.1609045906290714

Epoch: 5| Step: 3
Training loss: 2.7617081314163348
Validation loss: 3.1617570283115155

Epoch: 5| Step: 4
Training loss: 3.7769323241311716
Validation loss: 3.1631321195334787

Epoch: 5| Step: 5
Training loss: 3.3564732994087043
Validation loss: 3.1632308898127515

Epoch: 5| Step: 6
Training loss: 2.7686534615041083
Validation loss: 3.158918166121149

Epoch: 5| Step: 7
Training loss: 4.259620100821236
Validation loss: 3.1587060440944748

Epoch: 5| Step: 8
Training loss: 3.8912148392384944
Validation loss: 3.15615285266817

Epoch: 5| Step: 9
Training loss: 3.2559787337056214
Validation loss: 3.15559267947981

Epoch: 5| Step: 10
Training loss: 2.3024076920850725
Validation loss: 3.1534741733474405

Epoch: 76| Step: 0
Training loss: 3.4853247472875717
Validation loss: 3.1538594315335238

Epoch: 5| Step: 1
Training loss: 3.226760821216668
Validation loss: 3.1540194890143907

Epoch: 5| Step: 2
Training loss: 3.837404300850834
Validation loss: 3.1515735854910423

Epoch: 5| Step: 3
Training loss: 2.2342283827687868
Validation loss: 3.1522494234882816

Epoch: 5| Step: 4
Training loss: 3.7620878583189596
Validation loss: 3.1520131761954175

Epoch: 5| Step: 5
Training loss: 3.446947328391397
Validation loss: 3.1537577136898767

Epoch: 5| Step: 6
Training loss: 3.624719280028288
Validation loss: 3.150357732921599

Epoch: 5| Step: 7
Training loss: 3.332013647786522
Validation loss: 3.1543157265758683

Epoch: 5| Step: 8
Training loss: 3.849653471176923
Validation loss: 3.1533549012768565

Epoch: 5| Step: 9
Training loss: 2.9098793256455386
Validation loss: 3.151354031532945

Epoch: 5| Step: 10
Training loss: 3.473470002510084
Validation loss: 3.1508316695510863

Epoch: 77| Step: 0
Training loss: 3.683335231475571
Validation loss: 3.148512130752941

Epoch: 5| Step: 1
Training loss: 2.817737196082872
Validation loss: 3.1474449030013663

Epoch: 5| Step: 2
Training loss: 3.7366525256943977
Validation loss: 3.148672518677087

Epoch: 5| Step: 3
Training loss: 3.284849245511103
Validation loss: 3.152525800307422

Epoch: 5| Step: 4
Training loss: 3.0820357367382583
Validation loss: 3.1494956541068975

Epoch: 5| Step: 5
Training loss: 4.083627080407311
Validation loss: 3.148062988226331

Epoch: 5| Step: 6
Training loss: 3.43740345212426
Validation loss: 3.153782992669496

Epoch: 5| Step: 7
Training loss: 3.720907402938847
Validation loss: 3.1490014201065217

Epoch: 5| Step: 8
Training loss: 3.5139010801510087
Validation loss: 3.148169926685935

Epoch: 5| Step: 9
Training loss: 2.551091267321756
Validation loss: 3.1463754050124715

Epoch: 5| Step: 10
Training loss: 3.2460955127477162
Validation loss: 3.1456668426413095

Epoch: 78| Step: 0
Training loss: 3.3890942752767836
Validation loss: 3.147014844799955

Epoch: 5| Step: 1
Training loss: 4.46594491697612
Validation loss: 3.1477202686547017

Epoch: 5| Step: 2
Training loss: 3.3832438064030286
Validation loss: 3.147768849026269

Epoch: 5| Step: 3
Training loss: 3.379724515940597
Validation loss: 3.147727090426925

Epoch: 5| Step: 4
Training loss: 2.9352749453018196
Validation loss: 3.14583107379739

Epoch: 5| Step: 5
Training loss: 2.9155739145004587
Validation loss: 3.1479230838255603

Epoch: 5| Step: 6
Training loss: 3.435669845280044
Validation loss: 3.1480046847590906

Epoch: 5| Step: 7
Training loss: 3.610269410919549
Validation loss: 3.1483079342187876

Epoch: 5| Step: 8
Training loss: 2.939347355862857
Validation loss: 3.1459217940580553

Epoch: 5| Step: 9
Training loss: 3.585495998488324
Validation loss: 3.1472416660231337

Epoch: 5| Step: 10
Training loss: 3.084726293901709
Validation loss: 3.1467028381019944

Epoch: 79| Step: 0
Training loss: 3.1939903452517706
Validation loss: 3.1452106728054408

Epoch: 5| Step: 1
Training loss: 3.828406747842856
Validation loss: 3.145844516898616

Epoch: 5| Step: 2
Training loss: 2.888063852983291
Validation loss: 3.1440899821039148

Epoch: 5| Step: 3
Training loss: 3.3382154633663776
Validation loss: 3.144390599809574

Epoch: 5| Step: 4
Training loss: 2.722741189997228
Validation loss: 3.1431327386558614

Epoch: 5| Step: 5
Training loss: 2.8073805946509385
Validation loss: 3.142997375033126

Epoch: 5| Step: 6
Training loss: 3.528337881391354
Validation loss: 3.1434888610695206

Epoch: 5| Step: 7
Training loss: 3.9754601170292028
Validation loss: 3.1433712539362046

Epoch: 5| Step: 8
Training loss: 3.788493005487078
Validation loss: 3.1428019252484263

Epoch: 5| Step: 9
Training loss: 3.4943685185429123
Validation loss: 3.141821069307764

Epoch: 5| Step: 10
Training loss: 3.5943585751270497
Validation loss: 3.1425053283621174

Epoch: 80| Step: 0
Training loss: 3.978421539257845
Validation loss: 3.1420809336682876

Epoch: 5| Step: 1
Training loss: 4.214238672247921
Validation loss: 3.1397693268132754

Epoch: 5| Step: 2
Training loss: 3.0512577715332876
Validation loss: 3.1432423283658855

Epoch: 5| Step: 3
Training loss: 3.354271280935822
Validation loss: 3.1415122998073097

Epoch: 5| Step: 4
Training loss: 3.65566985915586
Validation loss: 3.140877185586435

Epoch: 5| Step: 5
Training loss: 2.929330219099878
Validation loss: 3.1401786048203157

Epoch: 5| Step: 6
Training loss: 3.1288443760463065
Validation loss: 3.138609193791301

Epoch: 5| Step: 7
Training loss: 2.824539693954937
Validation loss: 3.1381161837600384

Epoch: 5| Step: 8
Training loss: 3.764804354950558
Validation loss: 3.136446837173199

Epoch: 5| Step: 9
Training loss: 3.211811624240583
Validation loss: 3.1385077609531327

Epoch: 5| Step: 10
Training loss: 2.8381486999825944
Validation loss: 3.137430325201737

Epoch: 81| Step: 0
Training loss: 3.2199532935504647
Validation loss: 3.138364668751291

Epoch: 5| Step: 1
Training loss: 3.7514770142182674
Validation loss: 3.135877197205104

Epoch: 5| Step: 2
Training loss: 3.2093470734715632
Validation loss: 3.1361258375269445

Epoch: 5| Step: 3
Training loss: 3.346441593834021
Validation loss: 3.135738015515799

Epoch: 5| Step: 4
Training loss: 3.127904229085828
Validation loss: 3.137328877946716

Epoch: 5| Step: 5
Training loss: 4.082314396579412
Validation loss: 3.1351771376458775

Epoch: 5| Step: 6
Training loss: 3.520947847629604
Validation loss: 3.1355708233610167

Epoch: 5| Step: 7
Training loss: 3.2837604909670457
Validation loss: 3.137285120548277

Epoch: 5| Step: 8
Training loss: 3.9905273807926025
Validation loss: 3.1350548119455492

Epoch: 5| Step: 9
Training loss: 2.8148614929978284
Validation loss: 3.1419368006828616

Epoch: 5| Step: 10
Training loss: 2.584402775644035
Validation loss: 3.153152258245272

Epoch: 82| Step: 0
Training loss: 3.0203270498873547
Validation loss: 3.139794630233652

Epoch: 5| Step: 1
Training loss: 2.3707082017035566
Validation loss: 3.1349310929053753

Epoch: 5| Step: 2
Training loss: 3.933190666995056
Validation loss: 3.1354882962503994

Epoch: 5| Step: 3
Training loss: 3.4509430632977773
Validation loss: 3.1335212315616383

Epoch: 5| Step: 4
Training loss: 3.146853974015454
Validation loss: 3.1359967391623096

Epoch: 5| Step: 5
Training loss: 3.6313339670160993
Validation loss: 3.1346348676429456

Epoch: 5| Step: 6
Training loss: 2.9171733052869198
Validation loss: 3.1322706750955303

Epoch: 5| Step: 7
Training loss: 3.734076707490337
Validation loss: 3.135116180639526

Epoch: 5| Step: 8
Training loss: 3.7203649011708206
Validation loss: 3.1330893202471173

Epoch: 5| Step: 9
Training loss: 3.6456183379223748
Validation loss: 3.133575647643877

Epoch: 5| Step: 10
Training loss: 3.448628531705731
Validation loss: 3.133087635476289

Epoch: 83| Step: 0
Training loss: 2.8780855952743285
Validation loss: 3.133293656837832

Epoch: 5| Step: 1
Training loss: 3.487722114955184
Validation loss: 3.1341289726456067

Epoch: 5| Step: 2
Training loss: 3.980268089619917
Validation loss: 3.1318889921299577

Epoch: 5| Step: 3
Training loss: 2.92687788453857
Validation loss: 3.1308374532145873

Epoch: 5| Step: 4
Training loss: 2.922161394250888
Validation loss: 3.133395506369193

Epoch: 5| Step: 5
Training loss: 3.171082195553214
Validation loss: 3.1337762908557187

Epoch: 5| Step: 6
Training loss: 3.1481082261323836
Validation loss: 3.131091216407263

Epoch: 5| Step: 7
Training loss: 3.610738389432132
Validation loss: 3.130915916317734

Epoch: 5| Step: 8
Training loss: 3.6198936539514484
Validation loss: 3.1305514897210793

Epoch: 5| Step: 9
Training loss: 3.3916433185145536
Validation loss: 3.1304511707918223

Epoch: 5| Step: 10
Training loss: 4.001431447437284
Validation loss: 3.130097338300975

Epoch: 84| Step: 0
Training loss: 4.206172249742851
Validation loss: 3.1299089952674373

Epoch: 5| Step: 1
Training loss: 3.60194881460877
Validation loss: 3.1303913952291396

Epoch: 5| Step: 2
Training loss: 3.0782191847900267
Validation loss: 3.1310943645727445

Epoch: 5| Step: 3
Training loss: 3.1282845592676574
Validation loss: 3.130931601496868

Epoch: 5| Step: 4
Training loss: 3.6600548924566554
Validation loss: 3.1297546386070496

Epoch: 5| Step: 5
Training loss: 3.431229577064534
Validation loss: 3.1303008456606256

Epoch: 5| Step: 6
Training loss: 2.6914315852286324
Validation loss: 3.129269232982757

Epoch: 5| Step: 7
Training loss: 3.4269393998891626
Validation loss: 3.129115022548524

Epoch: 5| Step: 8
Training loss: 3.300225602732435
Validation loss: 3.1277527430568064

Epoch: 5| Step: 9
Training loss: 2.9883525765078316
Validation loss: 3.1295936178393924

Epoch: 5| Step: 10
Training loss: 3.55379171298004
Validation loss: 3.1300892544738566

Epoch: 85| Step: 0
Training loss: 3.211481869628131
Validation loss: 3.1289564735509523

Epoch: 5| Step: 1
Training loss: 2.858340717302429
Validation loss: 3.1287909322082257

Epoch: 5| Step: 2
Training loss: 3.256991568854584
Validation loss: 3.1292161937417693

Epoch: 5| Step: 3
Training loss: 3.3195067381677674
Validation loss: 3.1263880577702268

Epoch: 5| Step: 4
Training loss: 3.533871648075697
Validation loss: 3.127317557756863

Epoch: 5| Step: 5
Training loss: 3.278408891369225
Validation loss: 3.127830930284062

Epoch: 5| Step: 6
Training loss: 3.5882707040450295
Validation loss: 3.1270146871253908

Epoch: 5| Step: 7
Training loss: 3.5207529604313663
Validation loss: 3.128781076798006

Epoch: 5| Step: 8
Training loss: 3.324903478153627
Validation loss: 3.1278032080690803

Epoch: 5| Step: 9
Training loss: 3.469948501424634
Validation loss: 3.126014650577215

Epoch: 5| Step: 10
Training loss: 3.8611478247295925
Validation loss: 3.1276990608976134

Epoch: 86| Step: 0
Training loss: 3.272255331266637
Validation loss: 3.126718108701208

Epoch: 5| Step: 1
Training loss: 3.2721887359747956
Validation loss: 3.1282847969237086

Epoch: 5| Step: 2
Training loss: 3.0794218013575647
Validation loss: 3.125722093729741

Epoch: 5| Step: 3
Training loss: 3.5465824493887776
Validation loss: 3.128472111808314

Epoch: 5| Step: 4
Training loss: 3.3907580371545714
Validation loss: 3.1310166035494493

Epoch: 5| Step: 5
Training loss: 3.3472326092978766
Validation loss: 3.1355551581185317

Epoch: 5| Step: 6
Training loss: 3.443423629221825
Validation loss: 3.134202241124394

Epoch: 5| Step: 7
Training loss: 3.0150751591008236
Validation loss: 3.132784112378151

Epoch: 5| Step: 8
Training loss: 3.333486187927002
Validation loss: 3.1335108379685397

Epoch: 5| Step: 9
Training loss: 3.922065882198023
Validation loss: 3.12778104520148

Epoch: 5| Step: 10
Training loss: 3.5381190914124256
Validation loss: 3.1232304359972622

Epoch: 87| Step: 0
Training loss: 2.94639992307797
Validation loss: 3.1239183387433385

Epoch: 5| Step: 1
Training loss: 3.937873701496841
Validation loss: 3.123240637253442

Epoch: 5| Step: 2
Training loss: 2.9357552724078033
Validation loss: 3.1220513425858205

Epoch: 5| Step: 3
Training loss: 3.1892266178468582
Validation loss: 3.1212399970162386

Epoch: 5| Step: 4
Training loss: 3.141428223186566
Validation loss: 3.1222293310612774

Epoch: 5| Step: 5
Training loss: 3.5764281401388662
Validation loss: 3.1250068738308032

Epoch: 5| Step: 6
Training loss: 3.3804051949768628
Validation loss: 3.1230511928155695

Epoch: 5| Step: 7
Training loss: 2.981007538538643
Validation loss: 3.121221886945749

Epoch: 5| Step: 8
Training loss: 3.749185346489168
Validation loss: 3.122488322609766

Epoch: 5| Step: 9
Training loss: 3.8084254770518764
Validation loss: 3.1218212720844707

Epoch: 5| Step: 10
Training loss: 3.348165146240039
Validation loss: 3.121477455994266

Epoch: 88| Step: 0
Training loss: 3.9944014708910696
Validation loss: 3.121049320604388

Epoch: 5| Step: 1
Training loss: 3.7426647925168917
Validation loss: 3.1191411296502904

Epoch: 5| Step: 2
Training loss: 2.979765682865059
Validation loss: 3.1197730176189786

Epoch: 5| Step: 3
Training loss: 3.24212690549551
Validation loss: 3.1207388828431353

Epoch: 5| Step: 4
Training loss: 3.18592107225105
Validation loss: 3.1227445359040886

Epoch: 5| Step: 5
Training loss: 3.034210175458348
Validation loss: 3.1253001817482264

Epoch: 5| Step: 6
Training loss: 2.9856877660192844
Validation loss: 3.1178322887283647

Epoch: 5| Step: 7
Training loss: 3.7529465860844504
Validation loss: 3.118708236269701

Epoch: 5| Step: 8
Training loss: 3.1474853287431412
Validation loss: 3.123801722335835

Epoch: 5| Step: 9
Training loss: 3.4098981167515805
Validation loss: 3.118533389352227

Epoch: 5| Step: 10
Training loss: 3.5507568089952284
Validation loss: 3.1208326925723404

Epoch: 89| Step: 0
Training loss: 3.284439280830951
Validation loss: 3.119094228878782

Epoch: 5| Step: 1
Training loss: 3.209493716234818
Validation loss: 3.1214514883145643

Epoch: 5| Step: 2
Training loss: 2.8572751866077573
Validation loss: 3.1210395245316387

Epoch: 5| Step: 3
Training loss: 3.5059967439139132
Validation loss: 3.116290028834932

Epoch: 5| Step: 4
Training loss: 3.569056183462296
Validation loss: 3.11803452630783

Epoch: 5| Step: 5
Training loss: 3.6782091414713385
Validation loss: 3.1158776854111263

Epoch: 5| Step: 6
Training loss: 3.2697676524171344
Validation loss: 3.114710412413466

Epoch: 5| Step: 7
Training loss: 2.9981292613883683
Validation loss: 3.1161170059110797

Epoch: 5| Step: 8
Training loss: 4.085321967184658
Validation loss: 3.113217864887231

Epoch: 5| Step: 9
Training loss: 2.907819098742345
Validation loss: 3.1145275485622683

Epoch: 5| Step: 10
Training loss: 3.579488169774577
Validation loss: 3.112687139530987

Epoch: 90| Step: 0
Training loss: 3.715630513179914
Validation loss: 3.1129034367422648

Epoch: 5| Step: 1
Training loss: 3.7250805993289036
Validation loss: 3.114479225079486

Epoch: 5| Step: 2
Training loss: 2.7814102126706666
Validation loss: 3.115286584134326

Epoch: 5| Step: 3
Training loss: 3.3050450341277204
Validation loss: 3.11290674742314

Epoch: 5| Step: 4
Training loss: 3.1589469340456953
Validation loss: 3.115650369696782

Epoch: 5| Step: 5
Training loss: 4.239443739983738
Validation loss: 3.1150491141005014

Epoch: 5| Step: 6
Training loss: 3.2284075100999146
Validation loss: 3.116294555918111

Epoch: 5| Step: 7
Training loss: 3.3441665247379984
Validation loss: 3.11408812356943

Epoch: 5| Step: 8
Training loss: 2.9502244055789935
Validation loss: 3.112732950036102

Epoch: 5| Step: 9
Training loss: 2.6624004291667043
Validation loss: 3.112415506002068

Epoch: 5| Step: 10
Training loss: 3.708459930544959
Validation loss: 3.1141406803879423

Epoch: 91| Step: 0
Training loss: 3.328170417869749
Validation loss: 3.1125795058284473

Epoch: 5| Step: 1
Training loss: 2.728296815895404
Validation loss: 3.1133356460033417

Epoch: 5| Step: 2
Training loss: 2.8853384803801276
Validation loss: 3.1174647241657993

Epoch: 5| Step: 3
Training loss: 2.9410398541305054
Validation loss: 3.116504700603216

Epoch: 5| Step: 4
Training loss: 3.4838118162169707
Validation loss: 3.1196409851222193

Epoch: 5| Step: 5
Training loss: 3.4978801574679914
Validation loss: 3.1282399238630556

Epoch: 5| Step: 6
Training loss: 3.414361098301515
Validation loss: 3.1199525822479885

Epoch: 5| Step: 7
Training loss: 3.5812767840011315
Validation loss: 3.111880700988156

Epoch: 5| Step: 8
Training loss: 3.7698330615088924
Validation loss: 3.108887831570354

Epoch: 5| Step: 9
Training loss: 3.475910802901738
Validation loss: 3.111449898772214

Epoch: 5| Step: 10
Training loss: 3.879886376595078
Validation loss: 3.1085615177640746

Epoch: 92| Step: 0
Training loss: 2.648385196495656
Validation loss: 3.108691520433632

Epoch: 5| Step: 1
Training loss: 3.869894910267734
Validation loss: 3.110466884775832

Epoch: 5| Step: 2
Training loss: 3.9619681016387953
Validation loss: 3.107899839920631

Epoch: 5| Step: 3
Training loss: 2.821877254176797
Validation loss: 3.108642091872017

Epoch: 5| Step: 4
Training loss: 3.39320296626053
Validation loss: 3.113866347274877

Epoch: 5| Step: 5
Training loss: 3.719436453925519
Validation loss: 3.1098466477222266

Epoch: 5| Step: 6
Training loss: 3.312599036697573
Validation loss: 3.108926693035826

Epoch: 5| Step: 7
Training loss: 3.5161303347754234
Validation loss: 3.1078881810620533

Epoch: 5| Step: 8
Training loss: 3.140998324700133
Validation loss: 3.1076848624757965

Epoch: 5| Step: 9
Training loss: 3.3830419731276407
Validation loss: 3.1069943210530067

Epoch: 5| Step: 10
Training loss: 3.0147472942468903
Validation loss: 3.1057267850400776

Epoch: 93| Step: 0
Training loss: 3.504087785762102
Validation loss: 3.1090543534932302

Epoch: 5| Step: 1
Training loss: 3.4863305869213996
Validation loss: 3.105117520632221

Epoch: 5| Step: 2
Training loss: 3.056914705413665
Validation loss: 3.10736210276505

Epoch: 5| Step: 3
Training loss: 3.5614319923738136
Validation loss: 3.106812675655099

Epoch: 5| Step: 4
Training loss: 3.480037846633491
Validation loss: 3.108668648987408

Epoch: 5| Step: 5
Training loss: 3.160803201700924
Validation loss: 3.1077719695305412

Epoch: 5| Step: 6
Training loss: 3.4002358074319754
Validation loss: 3.111930504019088

Epoch: 5| Step: 7
Training loss: 3.5124977953486463
Validation loss: 3.113514533715629

Epoch: 5| Step: 8
Training loss: 3.6713043418761555
Validation loss: 3.1209852373360363

Epoch: 5| Step: 9
Training loss: 3.0435068146924036
Validation loss: 3.105322072290412

Epoch: 5| Step: 10
Training loss: 3.0604868909146545
Validation loss: 3.102341546405027

Epoch: 94| Step: 0
Training loss: 3.0167079423922334
Validation loss: 3.1012726087220948

Epoch: 5| Step: 1
Training loss: 3.4516854025570027
Validation loss: 3.1031683581272422

Epoch: 5| Step: 2
Training loss: 3.9504389024091338
Validation loss: 3.1043621435816897

Epoch: 5| Step: 3
Training loss: 3.1829541271762003
Validation loss: 3.1045058096064793

Epoch: 5| Step: 4
Training loss: 3.7754161377985613
Validation loss: 3.1085197371944124

Epoch: 5| Step: 5
Training loss: 3.738154330435909
Validation loss: 3.1085230492452203

Epoch: 5| Step: 6
Training loss: 2.9570230259648684
Validation loss: 3.105508762916274

Epoch: 5| Step: 7
Training loss: 2.5680043718532533
Validation loss: 3.1055128970871095

Epoch: 5| Step: 8
Training loss: 4.042236497697817
Validation loss: 3.1049275384881643

Epoch: 5| Step: 9
Training loss: 3.024904984172072
Validation loss: 3.1022237899971334

Epoch: 5| Step: 10
Training loss: 2.954366433115257
Validation loss: 3.101696847667631

Epoch: 95| Step: 0
Training loss: 3.798996572020516
Validation loss: 3.1037621150183563

Epoch: 5| Step: 1
Training loss: 3.4444058494729957
Validation loss: 3.1071477861316663

Epoch: 5| Step: 2
Training loss: 3.112247845956855
Validation loss: 3.104991287692947

Epoch: 5| Step: 3
Training loss: 3.8329543188942363
Validation loss: 3.104436889193514

Epoch: 5| Step: 4
Training loss: 3.2475055511873534
Validation loss: 3.1063303162938674

Epoch: 5| Step: 5
Training loss: 2.685924955630565
Validation loss: 3.123060439980352

Epoch: 5| Step: 6
Training loss: 3.038335953580724
Validation loss: 3.1144459331574064

Epoch: 5| Step: 7
Training loss: 3.3513443882536453
Validation loss: 3.104563403139422

Epoch: 5| Step: 8
Training loss: 3.5718369849877893
Validation loss: 3.1095435058261733

Epoch: 5| Step: 9
Training loss: 3.1892701264096437
Validation loss: 3.1048800952179034

Epoch: 5| Step: 10
Training loss: 3.59609524040846
Validation loss: 3.1028944289154903

Epoch: 96| Step: 0
Training loss: 3.5344029756850377
Validation loss: 3.098339923232345

Epoch: 5| Step: 1
Training loss: 4.089742081771191
Validation loss: 3.0983146536020834

Epoch: 5| Step: 2
Training loss: 2.950161208581018
Validation loss: 3.1001408870781

Epoch: 5| Step: 3
Training loss: 2.952970147488045
Validation loss: 3.0972255733317415

Epoch: 5| Step: 4
Training loss: 2.850977673066167
Validation loss: 3.096017134653077

Epoch: 5| Step: 5
Training loss: 3.2752419826420214
Validation loss: 3.100014767394947

Epoch: 5| Step: 6
Training loss: 3.393838230061022
Validation loss: 3.098013566731593

Epoch: 5| Step: 7
Training loss: 3.2116316813008696
Validation loss: 3.0989809590554063

Epoch: 5| Step: 8
Training loss: 3.7001244343633837
Validation loss: 3.097580893850841

Epoch: 5| Step: 9
Training loss: 3.3213849658125283
Validation loss: 3.100647940454586

Epoch: 5| Step: 10
Training loss: 3.5172340610291317
Validation loss: 3.0991132463613553

Epoch: 97| Step: 0
Training loss: 2.628970821318811
Validation loss: 3.096881361059001

Epoch: 5| Step: 1
Training loss: 2.9088308708512574
Validation loss: 3.094108455538105

Epoch: 5| Step: 2
Training loss: 3.147185954818066
Validation loss: 3.0940583523802423

Epoch: 5| Step: 3
Training loss: 3.8239869465385685
Validation loss: 3.0922819084681956

Epoch: 5| Step: 4
Training loss: 3.0881151459132714
Validation loss: 3.094640657261399

Epoch: 5| Step: 5
Training loss: 3.680599674624198
Validation loss: 3.0939978778569155

Epoch: 5| Step: 6
Training loss: 3.2769319732561786
Validation loss: 3.0942372302712444

Epoch: 5| Step: 7
Training loss: 4.074210791429188
Validation loss: 3.096688279097547

Epoch: 5| Step: 8
Training loss: 3.4549293464469617
Validation loss: 3.0932753509460147

Epoch: 5| Step: 9
Training loss: 3.229342023128512
Validation loss: 3.0982887797363325

Epoch: 5| Step: 10
Training loss: 3.3982971863993656
Validation loss: 3.0976649663400346

Epoch: 98| Step: 0
Training loss: 2.6251530375602052
Validation loss: 3.0948252751954257

Epoch: 5| Step: 1
Training loss: 3.6006713559080668
Validation loss: 3.0927411072306317

Epoch: 5| Step: 2
Training loss: 3.6957935237926662
Validation loss: 3.097476629340376

Epoch: 5| Step: 3
Training loss: 3.5115025743390595
Validation loss: 3.09614303132446

Epoch: 5| Step: 4
Training loss: 3.1492379735172085
Validation loss: 3.0937439988998823

Epoch: 5| Step: 5
Training loss: 2.5096901967629446
Validation loss: 3.0926584833430066

Epoch: 5| Step: 6
Training loss: 3.2768226909518634
Validation loss: 3.0927582459710155

Epoch: 5| Step: 7
Training loss: 3.5487561048003036
Validation loss: 3.0923391957711908

Epoch: 5| Step: 8
Training loss: 3.331037652725059
Validation loss: 3.0913380352152764

Epoch: 5| Step: 9
Training loss: 3.634923965309528
Validation loss: 3.0913568386623025

Epoch: 5| Step: 10
Training loss: 3.8550019604867187
Validation loss: 3.091336733217048

Epoch: 99| Step: 0
Training loss: 4.001403562345343
Validation loss: 3.0892583766695827

Epoch: 5| Step: 1
Training loss: 3.1607983741935657
Validation loss: 3.088140193506353

Epoch: 5| Step: 2
Training loss: 2.6816764545755976
Validation loss: 3.0903664734780567

Epoch: 5| Step: 3
Training loss: 3.381626264751622
Validation loss: 3.088933853432646

Epoch: 5| Step: 4
Training loss: 3.238446754855359
Validation loss: 3.0873332893925745

Epoch: 5| Step: 5
Training loss: 4.007073585255375
Validation loss: 3.0896188120407437

Epoch: 5| Step: 6
Training loss: 3.7905437916786164
Validation loss: 3.0859375132919897

Epoch: 5| Step: 7
Training loss: 3.758504125826521
Validation loss: 3.0911812590759884

Epoch: 5| Step: 8
Training loss: 3.2141091676698257
Validation loss: 3.0851908816814726

Epoch: 5| Step: 9
Training loss: 2.7486566383566857
Validation loss: 3.088749252708811

Epoch: 5| Step: 10
Training loss: 2.2967914384446506
Validation loss: 3.086667570061601

Epoch: 100| Step: 0
Training loss: 3.1646782170013883
Validation loss: 3.086498440775899

Epoch: 5| Step: 1
Training loss: 2.732084873841502
Validation loss: 3.087225195253285

Epoch: 5| Step: 2
Training loss: 3.2181816710406927
Validation loss: 3.087414649174579

Epoch: 5| Step: 3
Training loss: 3.84234506626036
Validation loss: 3.0956391928034255

Epoch: 5| Step: 4
Training loss: 3.588217947227314
Validation loss: 3.0903379191034386

Epoch: 5| Step: 5
Training loss: 3.7198948740717803
Validation loss: 3.0925147046409815

Epoch: 5| Step: 6
Training loss: 3.349834432353654
Validation loss: 3.0917493197903854

Epoch: 5| Step: 7
Training loss: 2.405053175498941
Validation loss: 3.0882700389250575

Epoch: 5| Step: 8
Training loss: 3.0180044323665562
Validation loss: 3.0849781394076667

Epoch: 5| Step: 9
Training loss: 3.807259632120204
Validation loss: 3.0841810318862986

Epoch: 5| Step: 10
Training loss: 3.776999993447245
Validation loss: 3.0861745477206526

Epoch: 101| Step: 0
Training loss: 3.1995329277584483
Validation loss: 3.0852295804613723

Epoch: 5| Step: 1
Training loss: 3.9395975248154143
Validation loss: 3.0858631030048285

Epoch: 5| Step: 2
Training loss: 2.999692583227833
Validation loss: 3.085115121340282

Epoch: 5| Step: 3
Training loss: 3.4666890388158125
Validation loss: 3.0845560201034337

Epoch: 5| Step: 4
Training loss: 3.8762543401660015
Validation loss: 3.0829917171928556

Epoch: 5| Step: 5
Training loss: 3.2628547563274513
Validation loss: 3.0818640748336716

Epoch: 5| Step: 6
Training loss: 3.371175647859106
Validation loss: 3.0833844782327033

Epoch: 5| Step: 7
Training loss: 3.017238363255088
Validation loss: 3.0844520284361217

Epoch: 5| Step: 8
Training loss: 3.6051333386103983
Validation loss: 3.0860516229152966

Epoch: 5| Step: 9
Training loss: 2.9175402468378984
Validation loss: 3.0838349022249303

Epoch: 5| Step: 10
Training loss: 2.9119449725139415
Validation loss: 3.0911172316969684

Epoch: 102| Step: 0
Training loss: 3.4330789052027546
Validation loss: 3.094633782254048

Epoch: 5| Step: 1
Training loss: 3.1685993587644217
Validation loss: 3.0973467543757343

Epoch: 5| Step: 2
Training loss: 3.672857924042284
Validation loss: 3.1010652156217615

Epoch: 5| Step: 3
Training loss: 3.3045885147889735
Validation loss: 3.1001153691577232

Epoch: 5| Step: 4
Training loss: 3.465621912467276
Validation loss: 3.0922646999347205

Epoch: 5| Step: 5
Training loss: 3.143462763683941
Validation loss: 3.083111754761652

Epoch: 5| Step: 6
Training loss: 2.80794266116187
Validation loss: 3.080516396996819

Epoch: 5| Step: 7
Training loss: 3.5581938836127107
Validation loss: 3.079176689845542

Epoch: 5| Step: 8
Training loss: 3.5716209768510874
Validation loss: 3.0813505010279383

Epoch: 5| Step: 9
Training loss: 3.3066824444527705
Validation loss: 3.0812534250303054

Epoch: 5| Step: 10
Training loss: 3.3643181915844513
Validation loss: 3.080703645511929

Epoch: 103| Step: 0
Training loss: 3.5958911653879944
Validation loss: 3.0805258642183158

Epoch: 5| Step: 1
Training loss: 3.4967595494688735
Validation loss: 3.077366111298476

Epoch: 5| Step: 2
Training loss: 4.040080962172442
Validation loss: 3.0788205809364184

Epoch: 5| Step: 3
Training loss: 2.759128159469657
Validation loss: 3.0772669251886775

Epoch: 5| Step: 4
Training loss: 3.2390221276276763
Validation loss: 3.0826983880349608

Epoch: 5| Step: 5
Training loss: 2.384668546633059
Validation loss: 3.0773269554101663

Epoch: 5| Step: 6
Training loss: 3.420176323924098
Validation loss: 3.078211165436513

Epoch: 5| Step: 7
Training loss: 3.3191810744618797
Validation loss: 3.077728079321568

Epoch: 5| Step: 8
Training loss: 3.3087114945935627
Validation loss: 3.0826636975483406

Epoch: 5| Step: 9
Training loss: 3.622162464704659
Validation loss: 3.077205540831091

Epoch: 5| Step: 10
Training loss: 3.3115490682066206
Validation loss: 3.0859051703881484

Epoch: 104| Step: 0
Training loss: 3.361033469390158
Validation loss: 3.083995976258977

Epoch: 5| Step: 1
Training loss: 3.350558186046178
Validation loss: 3.093194970802216

Epoch: 5| Step: 2
Training loss: 3.3264139997843665
Validation loss: 3.0986239979460235

Epoch: 5| Step: 3
Training loss: 3.6128803092585726
Validation loss: 3.091183274371822

Epoch: 5| Step: 4
Training loss: 3.5240559172680883
Validation loss: 3.0833573533053507

Epoch: 5| Step: 5
Training loss: 3.219916863641769
Validation loss: 3.0814910859918156

Epoch: 5| Step: 6
Training loss: 3.0272205746110794
Validation loss: 3.075431738597423

Epoch: 5| Step: 7
Training loss: 3.34124676419896
Validation loss: 3.0752975623029175

Epoch: 5| Step: 8
Training loss: 3.2627216190760784
Validation loss: 3.0734772903728786

Epoch: 5| Step: 9
Training loss: 2.997683266325841
Validation loss: 3.0742328047905065

Epoch: 5| Step: 10
Training loss: 3.758830545245568
Validation loss: 3.073383064116798

Epoch: 105| Step: 0
Training loss: 3.347450134270595
Validation loss: 3.0727139703144637

Epoch: 5| Step: 1
Training loss: 3.657416002895665
Validation loss: 3.0727402814601557

Epoch: 5| Step: 2
Training loss: 3.224511480665006
Validation loss: 3.0731998074697473

Epoch: 5| Step: 3
Training loss: 3.2676402905211743
Validation loss: 3.073917764923695

Epoch: 5| Step: 4
Training loss: 3.7946978319817988
Validation loss: 3.0747832944156968

Epoch: 5| Step: 5
Training loss: 3.0817487270500825
Validation loss: 3.074279436814223

Epoch: 5| Step: 6
Training loss: 3.597894153329418
Validation loss: 3.0733088912358517

Epoch: 5| Step: 7
Training loss: 3.620947051960383
Validation loss: 3.0734431318276973

Epoch: 5| Step: 8
Training loss: 3.1313687848309675
Validation loss: 3.072483511225284

Epoch: 5| Step: 9
Training loss: 2.5622183482135394
Validation loss: 3.071360997104063

Epoch: 5| Step: 10
Training loss: 3.2525334387430362
Validation loss: 3.071375929708703

Epoch: 106| Step: 0
Training loss: 3.0557286666229047
Validation loss: 3.0712592331010793

Epoch: 5| Step: 1
Training loss: 3.2895711836168737
Validation loss: 3.070951947384621

Epoch: 5| Step: 2
Training loss: 3.5689343353070937
Validation loss: 3.071123125696569

Epoch: 5| Step: 3
Training loss: 3.3127271466378407
Validation loss: 3.0700765923709925

Epoch: 5| Step: 4
Training loss: 3.7269807656797185
Validation loss: 3.0735275943255083

Epoch: 5| Step: 5
Training loss: 3.2513218172406644
Validation loss: 3.0751063322725596

Epoch: 5| Step: 6
Training loss: 2.8574227093834224
Validation loss: 3.0750643764359715

Epoch: 5| Step: 7
Training loss: 3.0974145629036007
Validation loss: 3.0808102767441805

Epoch: 5| Step: 8
Training loss: 3.630755492268946
Validation loss: 3.0766203910095604

Epoch: 5| Step: 9
Training loss: 3.8601166170915597
Validation loss: 3.0731317766392445

Epoch: 5| Step: 10
Training loss: 2.787578369544311
Validation loss: 3.0689343381988223

Epoch: 107| Step: 0
Training loss: 3.327644134311712
Validation loss: 3.072936124550583

Epoch: 5| Step: 1
Training loss: 3.4044812010841174
Validation loss: 3.0709645962972636

Epoch: 5| Step: 2
Training loss: 3.1685767854377214
Validation loss: 3.0781921909082968

Epoch: 5| Step: 3
Training loss: 3.922451751976311
Validation loss: 3.073101097538748

Epoch: 5| Step: 4
Training loss: 3.4494490584385638
Validation loss: 3.067748216462774

Epoch: 5| Step: 5
Training loss: 3.2363431535370735
Validation loss: 3.067884445184226

Epoch: 5| Step: 6
Training loss: 2.961281467075714
Validation loss: 3.067005467146852

Epoch: 5| Step: 7
Training loss: 3.4016360610066045
Validation loss: 3.0668282944654996

Epoch: 5| Step: 8
Training loss: 3.396132535956485
Validation loss: 3.0659604490172696

Epoch: 5| Step: 9
Training loss: 3.221119869328903
Validation loss: 3.0686974365753117

Epoch: 5| Step: 10
Training loss: 3.052616285503869
Validation loss: 3.0666854448086864

Epoch: 108| Step: 0
Training loss: 3.5920767164300305
Validation loss: 3.0655313389435177

Epoch: 5| Step: 1
Training loss: 3.162416081577891
Validation loss: 3.067358887523067

Epoch: 5| Step: 2
Training loss: 3.0211360560479283
Validation loss: 3.066016466364727

Epoch: 5| Step: 3
Training loss: 3.544148207801116
Validation loss: 3.0672456295688146

Epoch: 5| Step: 4
Training loss: 3.3904182617163747
Validation loss: 3.0685287329317465

Epoch: 5| Step: 5
Training loss: 3.1491218372178125
Validation loss: 3.0681401915433546

Epoch: 5| Step: 6
Training loss: 3.0462885365574657
Validation loss: 3.0689890089984333

Epoch: 5| Step: 7
Training loss: 3.1500231060815502
Validation loss: 3.067558190606777

Epoch: 5| Step: 8
Training loss: 2.679010956443148
Validation loss: 3.0692350535504005

Epoch: 5| Step: 9
Training loss: 3.7745968634986165
Validation loss: 3.069374607325943

Epoch: 5| Step: 10
Training loss: 4.049530454190221
Validation loss: 3.0654831956343567

Epoch: 109| Step: 0
Training loss: 3.012611266807827
Validation loss: 3.071726894291531

Epoch: 5| Step: 1
Training loss: 3.13238948715369
Validation loss: 3.0732128558831935

Epoch: 5| Step: 2
Training loss: 3.4170990802085917
Validation loss: 3.0713023360553255

Epoch: 5| Step: 3
Training loss: 3.9357751368357383
Validation loss: 3.077185000516191

Epoch: 5| Step: 4
Training loss: 3.306456901552066
Validation loss: 3.075673309358937

Epoch: 5| Step: 5
Training loss: 3.2291883078229384
Validation loss: 3.070118912805558

Epoch: 5| Step: 6
Training loss: 4.0490184395093
Validation loss: 3.065242103094134

Epoch: 5| Step: 7
Training loss: 2.6158686261218125
Validation loss: 3.0632669502660566

Epoch: 5| Step: 8
Training loss: 3.418241897567825
Validation loss: 3.0610081913132836

Epoch: 5| Step: 9
Training loss: 2.8967986293301715
Validation loss: 3.0627384314808785

Epoch: 5| Step: 10
Training loss: 3.3798742065496477
Validation loss: 3.0629270873990624

Epoch: 110| Step: 0
Training loss: 3.4026527658625025
Validation loss: 3.062416760282561

Epoch: 5| Step: 1
Training loss: 3.63658841695497
Validation loss: 3.062036667163423

Epoch: 5| Step: 2
Training loss: 2.8868956556817973
Validation loss: 3.0609065052388233

Epoch: 5| Step: 3
Training loss: 4.2751965572389
Validation loss: 3.0616849149878176

Epoch: 5| Step: 4
Training loss: 2.926454270576993
Validation loss: 3.060374340308975

Epoch: 5| Step: 5
Training loss: 2.8119355377036443
Validation loss: 3.0587290454176923

Epoch: 5| Step: 6
Training loss: 2.6101834991960042
Validation loss: 3.0614935966887864

Epoch: 5| Step: 7
Training loss: 3.599672429758366
Validation loss: 3.0611156191673348

Epoch: 5| Step: 8
Training loss: 3.2245031994368856
Validation loss: 3.059204706893019

Epoch: 5| Step: 9
Training loss: 3.1467812396328063
Validation loss: 3.0591508266391645

Epoch: 5| Step: 10
Training loss: 3.7946579979346047
Validation loss: 3.0617346444500915

Epoch: 111| Step: 0
Training loss: 3.3892417230698464
Validation loss: 3.058822523327652

Epoch: 5| Step: 1
Training loss: 3.5103160870157715
Validation loss: 3.060289926104257

Epoch: 5| Step: 2
Training loss: 3.3231631260339065
Validation loss: 3.05821299563591

Epoch: 5| Step: 3
Training loss: 3.045542890387916
Validation loss: 3.057645454668703

Epoch: 5| Step: 4
Training loss: 3.6485542098988746
Validation loss: 3.0567400442828396

Epoch: 5| Step: 5
Training loss: 3.6480900927846123
Validation loss: 3.0609728998978123

Epoch: 5| Step: 6
Training loss: 2.635614460595461
Validation loss: 3.0561884059386943

Epoch: 5| Step: 7
Training loss: 3.93455855689017
Validation loss: 3.0588815779152783

Epoch: 5| Step: 8
Training loss: 3.3635803869402587
Validation loss: 3.0576414217879226

Epoch: 5| Step: 9
Training loss: 2.847534009614826
Validation loss: 3.0593713764481483

Epoch: 5| Step: 10
Training loss: 2.9472390913732722
Validation loss: 3.056413738321161

Epoch: 112| Step: 0
Training loss: 3.4966571375229423
Validation loss: 3.056068585104829

Epoch: 5| Step: 1
Training loss: 3.5771152454182835
Validation loss: 3.0582772835379597

Epoch: 5| Step: 2
Training loss: 2.6558688619595414
Validation loss: 3.0625360539925635

Epoch: 5| Step: 3
Training loss: 3.766869556960431
Validation loss: 3.0546915602795384

Epoch: 5| Step: 4
Training loss: 3.7784244289334588
Validation loss: 3.058827592234265

Epoch: 5| Step: 5
Training loss: 3.122040377065587
Validation loss: 3.0614011516335538

Epoch: 5| Step: 6
Training loss: 3.861669807965139
Validation loss: 3.06081164365542

Epoch: 5| Step: 7
Training loss: 2.7226522218518445
Validation loss: 3.0591333672053405

Epoch: 5| Step: 8
Training loss: 3.0455112633153187
Validation loss: 3.0555484102923196

Epoch: 5| Step: 9
Training loss: 3.3217421382197485
Validation loss: 3.055609466236249

Epoch: 5| Step: 10
Training loss: 2.845896822294254
Validation loss: 3.0535202672821917

Epoch: 113| Step: 0
Training loss: 3.3708331912448948
Validation loss: 3.0554849065205807

Epoch: 5| Step: 1
Training loss: 3.731151514335059
Validation loss: 3.0541898810278005

Epoch: 5| Step: 2
Training loss: 2.737688160879
Validation loss: 3.056386832846426

Epoch: 5| Step: 3
Training loss: 2.9901184418353086
Validation loss: 3.053888014933545

Epoch: 5| Step: 4
Training loss: 3.0637652839021055
Validation loss: 3.054262313203522

Epoch: 5| Step: 5
Training loss: 3.2570028419564214
Validation loss: 3.054593082291974

Epoch: 5| Step: 6
Training loss: 3.1396548162843443
Validation loss: 3.0513805311142943

Epoch: 5| Step: 7
Training loss: 3.463880953507323
Validation loss: 3.0537402549535337

Epoch: 5| Step: 8
Training loss: 3.825768566831131
Validation loss: 3.058949897174537

Epoch: 5| Step: 9
Training loss: 3.4663646847681244
Validation loss: 3.0547810025551385

Epoch: 5| Step: 10
Training loss: 3.3533129978005722
Validation loss: 3.0567060169840556

Epoch: 114| Step: 0
Training loss: 2.6939163793883734
Validation loss: 3.0513242685997435

Epoch: 5| Step: 1
Training loss: 3.5455489179415647
Validation loss: 3.054363975390437

Epoch: 5| Step: 2
Training loss: 3.710797951734725
Validation loss: 3.05057765991502

Epoch: 5| Step: 3
Training loss: 3.4060744494075914
Validation loss: 3.0534593660263885

Epoch: 5| Step: 4
Training loss: 3.084280298203414
Validation loss: 3.0509120266136436

Epoch: 5| Step: 5
Training loss: 4.077552959909796
Validation loss: 3.0528564621862557

Epoch: 5| Step: 6
Training loss: 3.1964164636234966
Validation loss: 3.0507468268280764

Epoch: 5| Step: 7
Training loss: 3.7368458510310103
Validation loss: 3.055950307346163

Epoch: 5| Step: 8
Training loss: 3.065536395084456
Validation loss: 3.0530885086030914

Epoch: 5| Step: 9
Training loss: 2.578624884953654
Validation loss: 3.0547291029227805

Epoch: 5| Step: 10
Training loss: 3.0710144017191463
Validation loss: 3.051817677504225

Epoch: 115| Step: 0
Training loss: 2.8728038858836236
Validation loss: 3.051140818845595

Epoch: 5| Step: 1
Training loss: 3.4048379193463885
Validation loss: 3.0528603401559806

Epoch: 5| Step: 2
Training loss: 3.6009947356164655
Validation loss: 3.0556987289515507

Epoch: 5| Step: 3
Training loss: 3.5853481099240474
Validation loss: 3.0580100118256337

Epoch: 5| Step: 4
Training loss: 3.6972762005428517
Validation loss: 3.066379618641739

Epoch: 5| Step: 5
Training loss: 3.8544439405075197
Validation loss: 3.061827312203174

Epoch: 5| Step: 6
Training loss: 3.1866789115553456
Validation loss: 3.0653341329058157

Epoch: 5| Step: 7
Training loss: 2.583833605000066
Validation loss: 3.068672828446651

Epoch: 5| Step: 8
Training loss: 3.6737297405918663
Validation loss: 3.0640244296733856

Epoch: 5| Step: 9
Training loss: 2.8068782145707507
Validation loss: 3.052666035888291

Epoch: 5| Step: 10
Training loss: 2.9244420815503056
Validation loss: 3.04788325781132

Epoch: 116| Step: 0
Training loss: 3.1753387330552805
Validation loss: 3.0474322553813296

Epoch: 5| Step: 1
Training loss: 3.218632816292614
Validation loss: 3.046382138693055

Epoch: 5| Step: 2
Training loss: 3.328994708977457
Validation loss: 3.04747962053616

Epoch: 5| Step: 3
Training loss: 3.4258981682585583
Validation loss: 3.048648949075277

Epoch: 5| Step: 4
Training loss: 3.299859454312091
Validation loss: 3.0475356091300214

Epoch: 5| Step: 5
Training loss: 3.936458631591032
Validation loss: 3.04844656885882

Epoch: 5| Step: 6
Training loss: 3.7254201869665664
Validation loss: 3.0472738042331713

Epoch: 5| Step: 7
Training loss: 2.9339373472424297
Validation loss: 3.04774714446446

Epoch: 5| Step: 8
Training loss: 2.5965343375841696
Validation loss: 3.047086706555245

Epoch: 5| Step: 9
Training loss: 3.4098125341350274
Validation loss: 3.049205426251147

Epoch: 5| Step: 10
Training loss: 3.2400810292790436
Validation loss: 3.047668328507999

Epoch: 117| Step: 0
Training loss: 3.094634266876708
Validation loss: 3.0457608415848876

Epoch: 5| Step: 1
Training loss: 3.336832609848732
Validation loss: 3.046107509512012

Epoch: 5| Step: 2
Training loss: 3.9125352266815967
Validation loss: 3.046289576727905

Epoch: 5| Step: 3
Training loss: 3.128636799805573
Validation loss: 3.0452610938197653

Epoch: 5| Step: 4
Training loss: 3.6945105684588455
Validation loss: 3.0464620095231894

Epoch: 5| Step: 5
Training loss: 2.89575301317389
Validation loss: 3.0435573962584352

Epoch: 5| Step: 6
Training loss: 3.3113159366665506
Validation loss: 3.0450637452713414

Epoch: 5| Step: 7
Training loss: 3.2294157034713935
Validation loss: 3.0449633966574963

Epoch: 5| Step: 8
Training loss: 3.0645183218347447
Validation loss: 3.0439685675087347

Epoch: 5| Step: 9
Training loss: 3.4259754156331814
Validation loss: 3.0462364114451232

Epoch: 5| Step: 10
Training loss: 3.229723843322518
Validation loss: 3.0425416019833866

Epoch: 118| Step: 0
Training loss: 3.6900867505718082
Validation loss: 3.048227937549443

Epoch: 5| Step: 1
Training loss: 3.182172624241751
Validation loss: 3.0434585790584365

Epoch: 5| Step: 2
Training loss: 3.024341221475112
Validation loss: 3.048393375598392

Epoch: 5| Step: 3
Training loss: 3.598730467424985
Validation loss: 3.0485570378638864

Epoch: 5| Step: 4
Training loss: 3.529125553568697
Validation loss: 3.042426308747327

Epoch: 5| Step: 5
Training loss: 3.6731879301653625
Validation loss: 3.046837091328418

Epoch: 5| Step: 6
Training loss: 2.709063407113648
Validation loss: 3.0438830624512203

Epoch: 5| Step: 7
Training loss: 3.292152240204068
Validation loss: 3.0429780004175053

Epoch: 5| Step: 8
Training loss: 3.058534818936587
Validation loss: 3.043569785034074

Epoch: 5| Step: 9
Training loss: 3.5165439337214273
Validation loss: 3.0424908425907526

Epoch: 5| Step: 10
Training loss: 2.938619522060413
Validation loss: 3.049860266919554

Epoch: 119| Step: 0
Training loss: 2.9036968871048883
Validation loss: 3.0401514881112304

Epoch: 5| Step: 1
Training loss: 3.398455179102722
Validation loss: 3.0447056016341807

Epoch: 5| Step: 2
Training loss: 3.2084262058307838
Validation loss: 3.0444847017844188

Epoch: 5| Step: 3
Training loss: 3.45711773263118
Validation loss: 3.0426473251787023

Epoch: 5| Step: 4
Training loss: 3.6128015148166424
Validation loss: 3.0475647639106507

Epoch: 5| Step: 5
Training loss: 3.10867286307268
Validation loss: 3.0418084252453474

Epoch: 5| Step: 6
Training loss: 2.858178060186326
Validation loss: 3.038533359420485

Epoch: 5| Step: 7
Training loss: 2.6937950396036197
Validation loss: 3.0370545582961053

Epoch: 5| Step: 8
Training loss: 4.263249109394148
Validation loss: 3.037950733697874

Epoch: 5| Step: 9
Training loss: 3.255400352409481
Validation loss: 3.0369335098187733

Epoch: 5| Step: 10
Training loss: 3.3870099040433717
Validation loss: 3.036769991874705

Epoch: 120| Step: 0
Training loss: 3.2506201225820663
Validation loss: 3.0361210325739894

Epoch: 5| Step: 1
Training loss: 2.9939275318617917
Validation loss: 3.0394688205019667

Epoch: 5| Step: 2
Training loss: 3.3840823003802774
Validation loss: 3.038495922094776

Epoch: 5| Step: 3
Training loss: 3.4608482194325165
Validation loss: 3.0400225760966038

Epoch: 5| Step: 4
Training loss: 3.2175530735905618
Validation loss: 3.036672242094443

Epoch: 5| Step: 5
Training loss: 3.1252284157244667
Validation loss: 3.039723732519191

Epoch: 5| Step: 6
Training loss: 3.808697164060752
Validation loss: 3.0362731379551726

Epoch: 5| Step: 7
Training loss: 3.325529420623008
Validation loss: 3.038193456943584

Epoch: 5| Step: 8
Training loss: 3.0603380941471614
Validation loss: 3.03709824544899

Epoch: 5| Step: 9
Training loss: 2.964887173903839
Validation loss: 3.035761120335739

Epoch: 5| Step: 10
Training loss: 3.7780633534844137
Validation loss: 3.0342705945150428

Epoch: 121| Step: 0
Training loss: 3.9131910987319944
Validation loss: 3.04206092820143

Epoch: 5| Step: 1
Training loss: 3.3385049914142337
Validation loss: 3.036350436110514

Epoch: 5| Step: 2
Training loss: 3.7427032688671784
Validation loss: 3.035869705056041

Epoch: 5| Step: 3
Training loss: 3.259849003296317
Validation loss: 3.0367853832865483

Epoch: 5| Step: 4
Training loss: 4.0168578633960355
Validation loss: 3.0409682097460893

Epoch: 5| Step: 5
Training loss: 2.75753445615018
Validation loss: 3.0374542104926867

Epoch: 5| Step: 6
Training loss: 2.569452112776394
Validation loss: 3.0349760422388874

Epoch: 5| Step: 7
Training loss: 3.414093226942677
Validation loss: 3.0333325879843076

Epoch: 5| Step: 8
Training loss: 3.0326839869852895
Validation loss: 3.0329074647774887

Epoch: 5| Step: 9
Training loss: 3.191587482662016
Validation loss: 3.031344596757684

Epoch: 5| Step: 10
Training loss: 2.7051655558975414
Validation loss: 3.033082223714833

Epoch: 122| Step: 0
Training loss: 3.420225538435243
Validation loss: 3.0312789257628587

Epoch: 5| Step: 1
Training loss: 3.367199112237082
Validation loss: 3.029822600095141

Epoch: 5| Step: 2
Training loss: 3.3263246923387237
Validation loss: 3.031615206190877

Epoch: 5| Step: 3
Training loss: 3.1000171722428704
Validation loss: 3.035604778505872

Epoch: 5| Step: 4
Training loss: 3.2427313291079667
Validation loss: 3.032290044400779

Epoch: 5| Step: 5
Training loss: 2.421456479242499
Validation loss: 3.0325671312347002

Epoch: 5| Step: 6
Training loss: 3.640944831126347
Validation loss: 3.0330216956157465

Epoch: 5| Step: 7
Training loss: 4.013673538244789
Validation loss: 3.02886710908115

Epoch: 5| Step: 8
Training loss: 3.5263229701170586
Validation loss: 3.0307912797655123

Epoch: 5| Step: 9
Training loss: 3.0696046901508973
Validation loss: 3.030529053617171

Epoch: 5| Step: 10
Training loss: 2.8944857821580734
Validation loss: 3.028786361208124

Epoch: 123| Step: 0
Training loss: 2.9750937695511497
Validation loss: 3.028244847926442

Epoch: 5| Step: 1
Training loss: 3.4099848159049255
Validation loss: 3.0268162400414718

Epoch: 5| Step: 2
Training loss: 3.0281266313829938
Validation loss: 3.028313918461007

Epoch: 5| Step: 3
Training loss: 2.6844590303815625
Validation loss: 3.0307909092765666

Epoch: 5| Step: 4
Training loss: 3.000464085604743
Validation loss: 3.030822651048796

Epoch: 5| Step: 5
Training loss: 3.7967497879543686
Validation loss: 3.031589635764822

Epoch: 5| Step: 6
Training loss: 3.5373773668148423
Validation loss: 3.0302164040672843

Epoch: 5| Step: 7
Training loss: 3.3675706826815746
Validation loss: 3.02969691335859

Epoch: 5| Step: 8
Training loss: 3.602398756670753
Validation loss: 3.032324548588972

Epoch: 5| Step: 9
Training loss: 3.432263912075205
Validation loss: 3.0303342006894347

Epoch: 5| Step: 10
Training loss: 3.398501481078761
Validation loss: 3.0294013433760383

Epoch: 124| Step: 0
Training loss: 3.0988941004317843
Validation loss: 3.030375048326026

Epoch: 5| Step: 1
Training loss: 3.2752419826420214
Validation loss: 3.0265170021895216

Epoch: 5| Step: 2
Training loss: 3.7548643987276065
Validation loss: 3.029610353940624

Epoch: 5| Step: 3
Training loss: 3.172705179948889
Validation loss: 3.0276044763872516

Epoch: 5| Step: 4
Training loss: 3.141340032001514
Validation loss: 3.026612233074086

Epoch: 5| Step: 5
Training loss: 3.7935573070175144
Validation loss: 3.028376631607848

Epoch: 5| Step: 6
Training loss: 3.230472587758452
Validation loss: 3.0326251213570212

Epoch: 5| Step: 7
Training loss: 2.8133177522104296
Validation loss: 3.033448491372214

Epoch: 5| Step: 8
Training loss: 3.0970181244420507
Validation loss: 3.0342404637131155

Epoch: 5| Step: 9
Training loss: 3.4386618298036424
Validation loss: 3.0246474688195955

Epoch: 5| Step: 10
Training loss: 3.4058976297366317
Validation loss: 3.028872050374803

Epoch: 125| Step: 0
Training loss: 3.764695302075357
Validation loss: 3.02689959996298

Epoch: 5| Step: 1
Training loss: 3.2355898727034025
Validation loss: 3.0299473593683786

Epoch: 5| Step: 2
Training loss: 3.017018050774833
Validation loss: 3.029681511321095

Epoch: 5| Step: 3
Training loss: 2.983874533666926
Validation loss: 3.0338778009734764

Epoch: 5| Step: 4
Training loss: 3.338423720412332
Validation loss: 3.0337720510323445

Epoch: 5| Step: 5
Training loss: 3.408353943206728
Validation loss: 3.0412445994834965

Epoch: 5| Step: 6
Training loss: 3.0318535272753615
Validation loss: 3.033166597249118

Epoch: 5| Step: 7
Training loss: 3.774550627178524
Validation loss: 3.030560392085885

Epoch: 5| Step: 8
Training loss: 3.636571108794834
Validation loss: 3.0273344873768937

Epoch: 5| Step: 9
Training loss: 3.48396634155903
Validation loss: 3.0266198944784595

Epoch: 5| Step: 10
Training loss: 2.3055298381223905
Validation loss: 3.0270502775584966

Epoch: 126| Step: 0
Training loss: 3.0769923880913437
Validation loss: 3.0265920185624906

Epoch: 5| Step: 1
Training loss: 3.779960097046808
Validation loss: 3.027627432687625

Epoch: 5| Step: 2
Training loss: 3.1237514290380854
Validation loss: 3.027375390730636

Epoch: 5| Step: 3
Training loss: 3.1156662979373353
Validation loss: 3.0270961170886275

Epoch: 5| Step: 4
Training loss: 4.093871602589208
Validation loss: 3.0276903895180105

Epoch: 5| Step: 5
Training loss: 3.4331596021924145
Validation loss: 3.0287503168294845

Epoch: 5| Step: 6
Training loss: 2.6700084926170127
Validation loss: 3.029480419629682

Epoch: 5| Step: 7
Training loss: 2.3885278416624596
Validation loss: 3.0304309062647716

Epoch: 5| Step: 8
Training loss: 3.401787170364074
Validation loss: 3.036687429699829

Epoch: 5| Step: 9
Training loss: 3.067522096189025
Validation loss: 3.0337622528468935

Epoch: 5| Step: 10
Training loss: 3.8255438374381026
Validation loss: 3.0326715368332313

Epoch: 127| Step: 0
Training loss: 3.872031520730969
Validation loss: 3.0257955076178606

Epoch: 5| Step: 1
Training loss: 3.802943901320312
Validation loss: 3.027411739394354

Epoch: 5| Step: 2
Training loss: 2.579501160442626
Validation loss: 3.0232427378032747

Epoch: 5| Step: 3
Training loss: 2.7143324116583445
Validation loss: 3.0285570602153826

Epoch: 5| Step: 4
Training loss: 3.2228954989316194
Validation loss: 3.025146508421208

Epoch: 5| Step: 5
Training loss: 3.0702881169018283
Validation loss: 3.0243072873948726

Epoch: 5| Step: 6
Training loss: 3.42945363978813
Validation loss: 3.0224948838276644

Epoch: 5| Step: 7
Training loss: 3.112256425878948
Validation loss: 3.0192906741629812

Epoch: 5| Step: 8
Training loss: 3.7837346008410857
Validation loss: 3.0213293910837895

Epoch: 5| Step: 9
Training loss: 2.8334130855630533
Validation loss: 3.0206578804523274

Epoch: 5| Step: 10
Training loss: 3.5677070710488565
Validation loss: 3.021872041797981

Epoch: 128| Step: 0
Training loss: 2.8288846339316716
Validation loss: 3.021892348116458

Epoch: 5| Step: 1
Training loss: 3.6432674134187173
Validation loss: 3.020236111941416

Epoch: 5| Step: 2
Training loss: 3.3639964407721705
Validation loss: 3.0191821385081035

Epoch: 5| Step: 3
Training loss: 3.3321623334781263
Validation loss: 3.0212335261351955

Epoch: 5| Step: 4
Training loss: 2.9230861499578973
Validation loss: 3.0192475402323313

Epoch: 5| Step: 5
Training loss: 3.2621096439610415
Validation loss: 3.0186236646787377

Epoch: 5| Step: 6
Training loss: 3.232815426382194
Validation loss: 3.0184769828856037

Epoch: 5| Step: 7
Training loss: 4.008014755648255
Validation loss: 3.0184915656051783

Epoch: 5| Step: 8
Training loss: 2.881267350614193
Validation loss: 3.0167513505789145

Epoch: 5| Step: 9
Training loss: 3.4481178678293953
Validation loss: 3.01930109923588

Epoch: 5| Step: 10
Training loss: 3.095816490432151
Validation loss: 3.017533490017153

Epoch: 129| Step: 0
Training loss: 2.6214031827060236
Validation loss: 3.020329002116851

Epoch: 5| Step: 1
Training loss: 3.4694407007383683
Validation loss: 3.018327231180476

Epoch: 5| Step: 2
Training loss: 3.5104407848280506
Validation loss: 3.0182897929426415

Epoch: 5| Step: 3
Training loss: 2.8966532765361777
Validation loss: 3.0168801182928533

Epoch: 5| Step: 4
Training loss: 2.4700774474878586
Validation loss: 3.016982231185075

Epoch: 5| Step: 5
Training loss: 3.8789846790755607
Validation loss: 3.0173275342374803

Epoch: 5| Step: 6
Training loss: 3.687837488280336
Validation loss: 3.019343446160623

Epoch: 5| Step: 7
Training loss: 3.5069823780253406
Validation loss: 3.0241029212799027

Epoch: 5| Step: 8
Training loss: 3.344595116030241
Validation loss: 3.025644316768887

Epoch: 5| Step: 9
Training loss: 3.1010400442559756
Validation loss: 3.0260084915453525

Epoch: 5| Step: 10
Training loss: 3.460459794601184
Validation loss: 3.0179494283482153

Epoch: 130| Step: 0
Training loss: 3.2142757688095998
Validation loss: 3.0159743532412446

Epoch: 5| Step: 1
Training loss: 3.1307229091438113
Validation loss: 3.0134916347277296

Epoch: 5| Step: 2
Training loss: 2.857653991074258
Validation loss: 3.013348548564708

Epoch: 5| Step: 3
Training loss: 3.088225547390471
Validation loss: 3.0137949329800993

Epoch: 5| Step: 4
Training loss: 3.756508583143328
Validation loss: 3.0150833013156215

Epoch: 5| Step: 5
Training loss: 3.7271881537981786
Validation loss: 3.0173312046778564

Epoch: 5| Step: 6
Training loss: 3.141578036271485
Validation loss: 3.0169991324014256

Epoch: 5| Step: 7
Training loss: 3.2853521953119746
Validation loss: 3.0180690594480835

Epoch: 5| Step: 8
Training loss: 3.907717863856527
Validation loss: 3.019965089825602

Epoch: 5| Step: 9
Training loss: 2.793086208194486
Validation loss: 3.016222163195937

Epoch: 5| Step: 10
Training loss: 3.001720888564871
Validation loss: 3.018259842357771

Epoch: 131| Step: 0
Training loss: 3.3120311189286045
Validation loss: 3.016242861128376

Epoch: 5| Step: 1
Training loss: 2.784512181868289
Validation loss: 3.020219464812899

Epoch: 5| Step: 2
Training loss: 3.923184727069318
Validation loss: 3.0181005137044896

Epoch: 5| Step: 3
Training loss: 3.92488450773368
Validation loss: 3.0177979370091066

Epoch: 5| Step: 4
Training loss: 3.726381053545864
Validation loss: 3.0147925317139155

Epoch: 5| Step: 5
Training loss: 2.84284019588395
Validation loss: 3.012244241680948

Epoch: 5| Step: 6
Training loss: 3.0406670343016464
Validation loss: 3.0094458843579814

Epoch: 5| Step: 7
Training loss: 2.53896531139114
Validation loss: 3.0127182760377464

Epoch: 5| Step: 8
Training loss: 2.9866021119816026
Validation loss: 3.0094059554921233

Epoch: 5| Step: 9
Training loss: 3.2018062202770157
Validation loss: 3.00931959788163

Epoch: 5| Step: 10
Training loss: 3.574809975008724
Validation loss: 3.0096835298852835

Epoch: 132| Step: 0
Training loss: 3.2732315180755016
Validation loss: 3.0100897101809276

Epoch: 5| Step: 1
Training loss: 2.5081545397465974
Validation loss: 3.0097298162006183

Epoch: 5| Step: 2
Training loss: 3.268946368590004
Validation loss: 3.0078566229548054

Epoch: 5| Step: 3
Training loss: 3.6809205663971465
Validation loss: 3.0060423363073077

Epoch: 5| Step: 4
Training loss: 3.8811954070596295
Validation loss: 3.008786770482915

Epoch: 5| Step: 5
Training loss: 3.4480459567412676
Validation loss: 3.0088743583760866

Epoch: 5| Step: 6
Training loss: 3.2867725220115545
Validation loss: 3.0085699377709094

Epoch: 5| Step: 7
Training loss: 3.325778760991992
Validation loss: 3.007220152629797

Epoch: 5| Step: 8
Training loss: 2.9936035630123885
Validation loss: 3.006882630853355

Epoch: 5| Step: 9
Training loss: 3.28747766871537
Validation loss: 3.0076928530312257

Epoch: 5| Step: 10
Training loss: 2.8839524245762513
Validation loss: 3.0077522006500885

Epoch: 133| Step: 0
Training loss: 3.367871987145853
Validation loss: 3.010646894862506

Epoch: 5| Step: 1
Training loss: 3.5144924119646817
Validation loss: 3.008356830472322

Epoch: 5| Step: 2
Training loss: 2.974746270138699
Validation loss: 3.0113582257771854

Epoch: 5| Step: 3
Training loss: 3.6803024652821557
Validation loss: 3.0110836537035115

Epoch: 5| Step: 4
Training loss: 2.8926227985978854
Validation loss: 3.0092690294996043

Epoch: 5| Step: 5
Training loss: 3.117655248133735
Validation loss: 3.011323307681742

Epoch: 5| Step: 6
Training loss: 4.116085476846899
Validation loss: 3.0084568560306435

Epoch: 5| Step: 7
Training loss: 3.4744394742223066
Validation loss: 3.00605656913988

Epoch: 5| Step: 8
Training loss: 2.6203620446468148
Validation loss: 3.005489249578432

Epoch: 5| Step: 9
Training loss: 3.2690452661142975
Validation loss: 3.0059108817538003

Epoch: 5| Step: 10
Training loss: 2.675827226452634
Validation loss: 3.0040813297784816

Epoch: 134| Step: 0
Training loss: 3.3221022864572625
Validation loss: 3.0046392259396204

Epoch: 5| Step: 1
Training loss: 3.3574228691734276
Validation loss: 3.004936125887626

Epoch: 5| Step: 2
Training loss: 3.149231159902133
Validation loss: 3.0038759528821997

Epoch: 5| Step: 3
Training loss: 3.0745439951142455
Validation loss: 3.0033281607126536

Epoch: 5| Step: 4
Training loss: 3.122279394342058
Validation loss: 3.0054128637000455

Epoch: 5| Step: 5
Training loss: 3.260393981529674
Validation loss: 3.0040247787764582

Epoch: 5| Step: 6
Training loss: 3.796326774295633
Validation loss: 3.0025683863014505

Epoch: 5| Step: 7
Training loss: 2.967463003569087
Validation loss: 3.0015717554111725

Epoch: 5| Step: 8
Training loss: 3.277475856805563
Validation loss: 3.002547326004549

Epoch: 5| Step: 9
Training loss: 2.860733626647087
Validation loss: 3.0028968108256904

Epoch: 5| Step: 10
Training loss: 3.851281455659662
Validation loss: 3.0030898654308906

Epoch: 135| Step: 0
Training loss: 2.95472746468502
Validation loss: 3.002537132207689

Epoch: 5| Step: 1
Training loss: 3.2654202775804215
Validation loss: 3.004004881643856

Epoch: 5| Step: 2
Training loss: 2.8728404019537277
Validation loss: 3.002176312347616

Epoch: 5| Step: 3
Training loss: 3.5824497523381043
Validation loss: 3.003173057604691

Epoch: 5| Step: 4
Training loss: 3.2713680599658375
Validation loss: 3.004052876904599

Epoch: 5| Step: 5
Training loss: 3.0221900436458506
Validation loss: 3.0108426591692132

Epoch: 5| Step: 6
Training loss: 3.0356099343195995
Validation loss: 3.0082331128527384

Epoch: 5| Step: 7
Training loss: 3.5176669146119792
Validation loss: 3.0092837198814815

Epoch: 5| Step: 8
Training loss: 3.683017527878022
Validation loss: 3.0059753816480055

Epoch: 5| Step: 9
Training loss: 3.6263768442370212
Validation loss: 3.0000941593337846

Epoch: 5| Step: 10
Training loss: 3.0469163158256465
Validation loss: 3.0027522226060555

Epoch: 136| Step: 0
Training loss: 2.7109112037460665
Validation loss: 2.9994391622969387

Epoch: 5| Step: 1
Training loss: 3.4486896459006973
Validation loss: 2.9976525368593556

Epoch: 5| Step: 2
Training loss: 2.7967077450317555
Validation loss: 2.9979201100541504

Epoch: 5| Step: 3
Training loss: 3.27296389702111
Validation loss: 2.9994234638585895

Epoch: 5| Step: 4
Training loss: 3.137200609490023
Validation loss: 2.99858496905116

Epoch: 5| Step: 5
Training loss: 3.6664365060412587
Validation loss: 3.0007979295781566

Epoch: 5| Step: 6
Training loss: 3.0569671163989693
Validation loss: 3.000355726775263

Epoch: 5| Step: 7
Training loss: 3.5263515018863276
Validation loss: 2.999678433866428

Epoch: 5| Step: 8
Training loss: 3.302602412262403
Validation loss: 3.00036801025952

Epoch: 5| Step: 9
Training loss: 3.7881949463884856
Validation loss: 3.0000895227043665

Epoch: 5| Step: 10
Training loss: 3.157371548345129
Validation loss: 3.0018808338003153

Epoch: 137| Step: 0
Training loss: 3.7320066467585766
Validation loss: 2.997283165094445

Epoch: 5| Step: 1
Training loss: 3.598505472857252
Validation loss: 2.9972982905611127

Epoch: 5| Step: 2
Training loss: 3.517477539251067
Validation loss: 2.9963137511956295

Epoch: 5| Step: 3
Training loss: 2.902303333437466
Validation loss: 2.9963404423180213

Epoch: 5| Step: 4
Training loss: 3.1653246964023745
Validation loss: 3.005827378142535

Epoch: 5| Step: 5
Training loss: 2.9858394844260823
Validation loss: 2.99636714689198

Epoch: 5| Step: 6
Training loss: 2.754977922714586
Validation loss: 2.997251914906396

Epoch: 5| Step: 7
Training loss: 3.6004082077439685
Validation loss: 3.0053961651728294

Epoch: 5| Step: 8
Training loss: 3.108304400134659
Validation loss: 3.0018126162977445

Epoch: 5| Step: 9
Training loss: 3.224542091448633
Validation loss: 3.0117642951288945

Epoch: 5| Step: 10
Training loss: 3.2820621030465578
Validation loss: 3.0171190832810786

Epoch: 138| Step: 0
Training loss: 3.160332485042614
Validation loss: 3.019166188641323

Epoch: 5| Step: 1
Training loss: 2.8983233241704873
Validation loss: 3.0332658562315737

Epoch: 5| Step: 2
Training loss: 3.8461446358497087
Validation loss: 3.0226470633907314

Epoch: 5| Step: 3
Training loss: 3.3488522399582283
Validation loss: 3.0084148492632345

Epoch: 5| Step: 4
Training loss: 3.2561125859939883
Validation loss: 3.0036161839468063

Epoch: 5| Step: 5
Training loss: 3.3979884760831296
Validation loss: 2.995456221556312

Epoch: 5| Step: 6
Training loss: 3.5471195355113907
Validation loss: 2.9927316348296396

Epoch: 5| Step: 7
Training loss: 3.179408705577509
Validation loss: 2.9954669538099656

Epoch: 5| Step: 8
Training loss: 3.3883286535928447
Validation loss: 2.9942533090298467

Epoch: 5| Step: 9
Training loss: 2.927320006951017
Validation loss: 2.9974978824367056

Epoch: 5| Step: 10
Training loss: 2.92217950713152
Validation loss: 2.993163248826281

Epoch: 139| Step: 0
Training loss: 2.6133387264209036
Validation loss: 2.9979019092045887

Epoch: 5| Step: 1
Training loss: 2.8234634339113156
Validation loss: 2.9961466482086285

Epoch: 5| Step: 2
Training loss: 3.2216315842593275
Validation loss: 2.9959709250438564

Epoch: 5| Step: 3
Training loss: 3.7071753133229266
Validation loss: 2.99470951147759

Epoch: 5| Step: 4
Training loss: 3.5614283773645043
Validation loss: 2.994374509259019

Epoch: 5| Step: 5
Training loss: 3.642027097857835
Validation loss: 2.9949446489906206

Epoch: 5| Step: 6
Training loss: 3.9355322144190334
Validation loss: 2.9933225850466085

Epoch: 5| Step: 7
Training loss: 2.297449779605014
Validation loss: 2.9927499433619067

Epoch: 5| Step: 8
Training loss: 3.8493631207703536
Validation loss: 2.992609733281415

Epoch: 5| Step: 9
Training loss: 3.0789010091183826
Validation loss: 2.991738973906816

Epoch: 5| Step: 10
Training loss: 2.741517683424021
Validation loss: 2.987868018267626

Epoch: 140| Step: 0
Training loss: 3.1116098011816278
Validation loss: 2.989042776833589

Epoch: 5| Step: 1
Training loss: 2.2180707724642503
Validation loss: 2.9913805564262628

Epoch: 5| Step: 2
Training loss: 3.7223613738308234
Validation loss: 2.9914415397217877

Epoch: 5| Step: 3
Training loss: 2.8492668212651138
Validation loss: 3.000140463709358

Epoch: 5| Step: 4
Training loss: 3.3718399512702883
Validation loss: 3.0011081802242425

Epoch: 5| Step: 5
Training loss: 3.4612024347929577
Validation loss: 2.9959878224270873

Epoch: 5| Step: 6
Training loss: 3.5
Validation loss: 2.988793107919148

Epoch: 5| Step: 7
Training loss: 2.930869065118344
Validation loss: 2.990413836113674

Epoch: 5| Step: 8
Training loss: 3.600433503647105
Validation loss: 2.987549208588771

Epoch: 5| Step: 9
Training loss: 3.876886462351944
Validation loss: 2.987379911046897

Epoch: 5| Step: 10
Training loss: 2.8996572883940472
Validation loss: 2.9879516050846493

Epoch: 141| Step: 0
Training loss: 3.3297358809652313
Validation loss: 2.985916548757325

Epoch: 5| Step: 1
Training loss: 2.9914930847587913
Validation loss: 2.990438959638706

Epoch: 5| Step: 2
Training loss: 3.3771075979526346
Validation loss: 2.988276653378752

Epoch: 5| Step: 3
Training loss: 3.138557778583086
Validation loss: 2.9916848066414525

Epoch: 5| Step: 4
Training loss: 3.089221915886468
Validation loss: 2.9933640191080535

Epoch: 5| Step: 5
Training loss: 2.710148501391975
Validation loss: 2.9901479952652887

Epoch: 5| Step: 6
Training loss: 3.8954306953697944
Validation loss: 2.997515322851947

Epoch: 5| Step: 7
Training loss: 3.1579568610020163
Validation loss: 2.9948821731024253

Epoch: 5| Step: 8
Training loss: 3.792172129269426
Validation loss: 2.988336115507753

Epoch: 5| Step: 9
Training loss: 2.8829901415669235
Validation loss: 2.9898917820944515

Epoch: 5| Step: 10
Training loss: 3.3761033974221597
Validation loss: 2.9920268138123567

Epoch: 142| Step: 0
Training loss: 3.6317721282039064
Validation loss: 2.9877033208562835

Epoch: 5| Step: 1
Training loss: 2.8298595862719296
Validation loss: 2.986952611040219

Epoch: 5| Step: 2
Training loss: 3.18911358251783
Validation loss: 2.986483033365583

Epoch: 5| Step: 3
Training loss: 2.953844416752329
Validation loss: 2.984939669526739

Epoch: 5| Step: 4
Training loss: 3.0105868140759355
Validation loss: 2.981994571218589

Epoch: 5| Step: 5
Training loss: 3.2917814274995028
Validation loss: 2.986322390487525

Epoch: 5| Step: 6
Training loss: 3.7794369220660338
Validation loss: 2.985859386698857

Epoch: 5| Step: 7
Training loss: 3.3324795742224533
Validation loss: 2.986984295123659

Epoch: 5| Step: 8
Training loss: 3.5169802617790116
Validation loss: 2.9854742232525178

Epoch: 5| Step: 9
Training loss: 3.041438803999535
Validation loss: 2.9847355986438218

Epoch: 5| Step: 10
Training loss: 3.1746312084928108
Validation loss: 2.985546421408853

Epoch: 143| Step: 0
Training loss: 3.8731461058739174
Validation loss: 2.985704876154225

Epoch: 5| Step: 1
Training loss: 2.994346696166097
Validation loss: 2.9890464108193093

Epoch: 5| Step: 2
Training loss: 2.6852431468870845
Validation loss: 2.9857838105907195

Epoch: 5| Step: 3
Training loss: 2.891158266108921
Validation loss: 2.988733338365729

Epoch: 5| Step: 4
Training loss: 3.5015187374377894
Validation loss: 2.9882539670018984

Epoch: 5| Step: 5
Training loss: 3.7981704574106945
Validation loss: 2.9863341548108213

Epoch: 5| Step: 6
Training loss: 3.526123376497791
Validation loss: 2.9844639210875124

Epoch: 5| Step: 7
Training loss: 2.7485144677588984
Validation loss: 2.9846436295304803

Epoch: 5| Step: 8
Training loss: 2.932297665379262
Validation loss: 2.983576849066861

Epoch: 5| Step: 9
Training loss: 3.346910355752505
Validation loss: 2.982021693981108

Epoch: 5| Step: 10
Training loss: 3.332904231744584
Validation loss: 2.9836003099570094

Epoch: 144| Step: 0
Training loss: 3.7493094762185093
Validation loss: 2.984692798494672

Epoch: 5| Step: 1
Training loss: 3.52568466355143
Validation loss: 2.9832924406991452

Epoch: 5| Step: 2
Training loss: 3.513652604258578
Validation loss: 2.9824224681125564

Epoch: 5| Step: 3
Training loss: 3.2209213488266286
Validation loss: 2.981428823682123

Epoch: 5| Step: 4
Training loss: 2.931507247340681
Validation loss: 2.98362070662113

Epoch: 5| Step: 5
Training loss: 3.366237001730396
Validation loss: 2.9812734738352313

Epoch: 5| Step: 6
Training loss: 3.1916306602365982
Validation loss: 2.9817326208448613

Epoch: 5| Step: 7
Training loss: 3.2926999816177167
Validation loss: 2.981798436445975

Epoch: 5| Step: 8
Training loss: 2.8238313232437537
Validation loss: 2.986180690448556

Epoch: 5| Step: 9
Training loss: 2.559780072957757
Validation loss: 2.9883023627962486

Epoch: 5| Step: 10
Training loss: 3.5566631486107236
Validation loss: 2.994567877855579

Epoch: 145| Step: 0
Training loss: 3.884049462251958
Validation loss: 2.997733317770883

Epoch: 5| Step: 1
Training loss: 2.8727969145811123
Validation loss: 2.9937320196003254

Epoch: 5| Step: 2
Training loss: 3.095845139191315
Validation loss: 2.9859059375796866

Epoch: 5| Step: 3
Training loss: 3.66268042422686
Validation loss: 2.990721539749764

Epoch: 5| Step: 4
Training loss: 3.3388594755321876
Validation loss: 2.9836882849336552

Epoch: 5| Step: 5
Training loss: 2.523747569777824
Validation loss: 2.9834528497333563

Epoch: 5| Step: 6
Training loss: 2.8807486406154417
Validation loss: 2.9795361309913004

Epoch: 5| Step: 7
Training loss: 4.095453737713201
Validation loss: 2.976988711331997

Epoch: 5| Step: 8
Training loss: 2.9441080640986703
Validation loss: 2.981256895495248

Epoch: 5| Step: 9
Training loss: 3.1058192793031147
Validation loss: 2.9804659923681074

Epoch: 5| Step: 10
Training loss: 3.054046641684996
Validation loss: 2.977725568431622

Epoch: 146| Step: 0
Training loss: 3.3892027513283733
Validation loss: 2.979234037376866

Epoch: 5| Step: 1
Training loss: 2.9404345524702364
Validation loss: 2.9774794372687245

Epoch: 5| Step: 2
Training loss: 3.6512047281824738
Validation loss: 2.9819195436732726

Epoch: 5| Step: 3
Training loss: 3.56906460045099
Validation loss: 2.976898518903321

Epoch: 5| Step: 4
Training loss: 2.964742264248346
Validation loss: 2.9792041347381173

Epoch: 5| Step: 5
Training loss: 3.286743506358066
Validation loss: 2.9786744494550996

Epoch: 5| Step: 6
Training loss: 3.215400360238758
Validation loss: 2.980921854651112

Epoch: 5| Step: 7
Training loss: 3.265995570425661
Validation loss: 2.97864327945092

Epoch: 5| Step: 8
Training loss: 3.4636864347486362
Validation loss: 2.9802311163738016

Epoch: 5| Step: 9
Training loss: 3.152102927991461
Validation loss: 2.97359432358074

Epoch: 5| Step: 10
Training loss: 2.708733357940376
Validation loss: 2.9801312970301344

Epoch: 147| Step: 0
Training loss: 2.810479179876631
Validation loss: 2.978124789304779

Epoch: 5| Step: 1
Training loss: 3.2461162249616806
Validation loss: 2.9727534313723245

Epoch: 5| Step: 2
Training loss: 3.696090777582825
Validation loss: 2.9791315118109685

Epoch: 5| Step: 3
Training loss: 3.749545896374135
Validation loss: 2.9754401014061997

Epoch: 5| Step: 4
Training loss: 2.400236269129363
Validation loss: 2.974776464060907

Epoch: 5| Step: 5
Training loss: 3.166532630760713
Validation loss: 2.9771602685918803

Epoch: 5| Step: 6
Training loss: 3.6394169321581034
Validation loss: 2.977705465433704

Epoch: 5| Step: 7
Training loss: 2.7082714856250756
Validation loss: 2.9741123114273047

Epoch: 5| Step: 8
Training loss: 3.5642544625717174
Validation loss: 2.978872132465726

Epoch: 5| Step: 9
Training loss: 3.2207183744996013
Validation loss: 2.9754222214192056

Epoch: 5| Step: 10
Training loss: 3.311438912359412
Validation loss: 2.981382319840391

Epoch: 148| Step: 0
Training loss: 2.7145938017246367
Validation loss: 2.9809318351206517

Epoch: 5| Step: 1
Training loss: 3.3198527657366723
Validation loss: 2.988945626758501

Epoch: 5| Step: 2
Training loss: 3.512521688048173
Validation loss: 2.9877182459840643

Epoch: 5| Step: 3
Training loss: 3.4960983873048854
Validation loss: 2.9780855019091894

Epoch: 5| Step: 4
Training loss: 3.8737450074825013
Validation loss: 2.976042817784699

Epoch: 5| Step: 5
Training loss: 2.9888393703677605
Validation loss: 2.971791557407881

Epoch: 5| Step: 6
Training loss: 3.237508094806935
Validation loss: 2.9727695595438037

Epoch: 5| Step: 7
Training loss: 2.4447691682469213
Validation loss: 2.970961688481788

Epoch: 5| Step: 8
Training loss: 3.2544451904932745
Validation loss: 2.970661408526412

Epoch: 5| Step: 9
Training loss: 3.2437190471488027
Validation loss: 2.969399434391145

Epoch: 5| Step: 10
Training loss: 3.5183135878314395
Validation loss: 2.9712659398100882

Epoch: 149| Step: 0
Training loss: 3.725984476553686
Validation loss: 2.969716679904343

Epoch: 5| Step: 1
Training loss: 3.157478924195422
Validation loss: 2.9706977348572416

Epoch: 5| Step: 2
Training loss: 3.5841347145750087
Validation loss: 2.969379628138311

Epoch: 5| Step: 3
Training loss: 2.9587838989430324
Validation loss: 2.9696292820731345

Epoch: 5| Step: 4
Training loss: 3.4028485314588655
Validation loss: 2.9738170944463196

Epoch: 5| Step: 5
Training loss: 3.3441410014345365
Validation loss: 2.9845916269121595

Epoch: 5| Step: 6
Training loss: 3.2412359472897707
Validation loss: 2.980756432854318

Epoch: 5| Step: 7
Training loss: 2.800147417138737
Validation loss: 2.9692486864981

Epoch: 5| Step: 8
Training loss: 2.9279825768291117
Validation loss: 2.9720778702554176

Epoch: 5| Step: 9
Training loss: 3.087668404252889
Validation loss: 2.9729781761359733

Epoch: 5| Step: 10
Training loss: 3.4428178747681732
Validation loss: 2.9677612264268363

Epoch: 150| Step: 0
Training loss: 3.892375138766333
Validation loss: 2.9678692947522487

Epoch: 5| Step: 1
Training loss: 3.414453130586103
Validation loss: 2.966145549266632

Epoch: 5| Step: 2
Training loss: 3.1102198694157295
Validation loss: 2.96769676156281

Epoch: 5| Step: 3
Training loss: 2.723806830448365
Validation loss: 2.966584661720794

Epoch: 5| Step: 4
Training loss: 3.4693726676667818
Validation loss: 2.966159934646769

Epoch: 5| Step: 5
Training loss: 3.100358167076855
Validation loss: 2.9685360255521966

Epoch: 5| Step: 6
Training loss: 3.325256257471963
Validation loss: 2.9654537966904946

Epoch: 5| Step: 7
Training loss: 3.3057866714706425
Validation loss: 2.968594874423953

Epoch: 5| Step: 8
Training loss: 3.4155137667818964
Validation loss: 2.9686154156388254

Epoch: 5| Step: 9
Training loss: 3.066456477245888
Validation loss: 2.9738939970565146

Epoch: 5| Step: 10
Training loss: 2.706992497242457
Validation loss: 2.969416987174077

Epoch: 151| Step: 0
Training loss: 2.720694975282796
Validation loss: 2.971742580442303

Epoch: 5| Step: 1
Training loss: 3.369018623243963
Validation loss: 2.9743968701424413

Epoch: 5| Step: 2
Training loss: 3.6308027717565463
Validation loss: 2.9726422004884605

Epoch: 5| Step: 3
Training loss: 3.0512485512585856
Validation loss: 2.9823794680060907

Epoch: 5| Step: 4
Training loss: 2.9799399450510475
Validation loss: 2.9805258442769405

Epoch: 5| Step: 5
Training loss: 3.245751758834996
Validation loss: 2.972870804034477

Epoch: 5| Step: 6
Training loss: 3.56640798813108
Validation loss: 2.969226889095497

Epoch: 5| Step: 7
Training loss: 3.415583849883281
Validation loss: 2.9728927299406878

Epoch: 5| Step: 8
Training loss: 3.7837982418638334
Validation loss: 2.967210419881516

Epoch: 5| Step: 9
Training loss: 3.0157859640695825
Validation loss: 2.9652303439067054

Epoch: 5| Step: 10
Training loss: 2.69611176512676
Validation loss: 2.967247223906533

Epoch: 152| Step: 0
Training loss: 3.8441181781874363
Validation loss: 2.964663026404253

Epoch: 5| Step: 1
Training loss: 3.7202865888068954
Validation loss: 2.963073515866246

Epoch: 5| Step: 2
Training loss: 3.1393873518484923
Validation loss: 2.963892169306574

Epoch: 5| Step: 3
Training loss: 2.789181490371408
Validation loss: 2.9626175828324226

Epoch: 5| Step: 4
Training loss: 3.714846573917828
Validation loss: 2.9636810429707516

Epoch: 5| Step: 5
Training loss: 2.676961952950842
Validation loss: 2.964067952857805

Epoch: 5| Step: 6
Training loss: 2.469181071443368
Validation loss: 2.9619921587040596

Epoch: 5| Step: 7
Training loss: 3.2763380796955888
Validation loss: 2.962259355398148

Epoch: 5| Step: 8
Training loss: 3.5923052993713664
Validation loss: 2.9616140268658047

Epoch: 5| Step: 9
Training loss: 3.012152377130712
Validation loss: 2.963037219788397

Epoch: 5| Step: 10
Training loss: 3.1350782006836537
Validation loss: 2.9632993641922014

Epoch: 153| Step: 0
Training loss: 3.2696531721965676
Validation loss: 2.9653322953661836

Epoch: 5| Step: 1
Training loss: 2.441442773164309
Validation loss: 2.9674091707077928

Epoch: 5| Step: 2
Training loss: 3.644967039820046
Validation loss: 2.9692320591506443

Epoch: 5| Step: 3
Training loss: 3.2566533576539807
Validation loss: 2.9655216731499943

Epoch: 5| Step: 4
Training loss: 3.670134176353301
Validation loss: 2.9624590294423023

Epoch: 5| Step: 5
Training loss: 3.413809830243605
Validation loss: 2.961250519154909

Epoch: 5| Step: 6
Training loss: 3.272387352061732
Validation loss: 2.963773401348367

Epoch: 5| Step: 7
Training loss: 3.1139498845785867
Validation loss: 2.962703631687108

Epoch: 5| Step: 8
Training loss: 3.197292171640709
Validation loss: 2.963554027768115

Epoch: 5| Step: 9
Training loss: 3.0226067084193633
Validation loss: 2.9637810271090803

Epoch: 5| Step: 10
Training loss: 3.264890305223004
Validation loss: 2.9621087305303573

Epoch: 154| Step: 0
Training loss: 3.3117886625210002
Validation loss: 2.9618460414779104

Epoch: 5| Step: 1
Training loss: 3.375699429976035
Validation loss: 2.9625356021041798

Epoch: 5| Step: 2
Training loss: 3.267166285033196
Validation loss: 2.9613377452676617

Epoch: 5| Step: 3
Training loss: 3.080242222760883
Validation loss: 2.9608864767533642

Epoch: 5| Step: 4
Training loss: 3.2265644212028937
Validation loss: 2.962464033041505

Epoch: 5| Step: 5
Training loss: 3.266278069277367
Validation loss: 2.9614849908572736

Epoch: 5| Step: 6
Training loss: 2.9741909561882656
Validation loss: 2.9603540785865947

Epoch: 5| Step: 7
Training loss: 3.378476930366486
Validation loss: 2.9599810051135345

Epoch: 5| Step: 8
Training loss: 3.201044514178222
Validation loss: 2.9589787087903536

Epoch: 5| Step: 9
Training loss: 2.960074346742769
Validation loss: 2.962230447157607

Epoch: 5| Step: 10
Training loss: 3.6802572469360735
Validation loss: 2.9600846876369946

Epoch: 155| Step: 0
Training loss: 2.5937054182150816
Validation loss: 2.9607498516853186

Epoch: 5| Step: 1
Training loss: 3.3686477787171016
Validation loss: 2.9613259370475284

Epoch: 5| Step: 2
Training loss: 3.133483510442856
Validation loss: 2.9637492264500227

Epoch: 5| Step: 3
Training loss: 3.997720784286493
Validation loss: 2.9629324439600846

Epoch: 5| Step: 4
Training loss: 3.7959106225283588
Validation loss: 2.9665692526224183

Epoch: 5| Step: 5
Training loss: 3.0107638852911784
Validation loss: 2.9685610837903593

Epoch: 5| Step: 6
Training loss: 3.348969565808259
Validation loss: 2.9635572457752435

Epoch: 5| Step: 7
Training loss: 2.2031431806098256
Validation loss: 2.9623883360419176

Epoch: 5| Step: 8
Training loss: 3.5924409555402534
Validation loss: 2.9623912835810886

Epoch: 5| Step: 9
Training loss: 2.936157731530489
Validation loss: 2.9659144021462436

Epoch: 5| Step: 10
Training loss: 3.2459468509931977
Validation loss: 2.963102676303323

Epoch: 156| Step: 0
Training loss: 3.7616227911160953
Validation loss: 2.964219726164918

Epoch: 5| Step: 1
Training loss: 2.7480056640311203
Validation loss: 2.9623647625461955

Epoch: 5| Step: 2
Training loss: 3.6529866840945866
Validation loss: 2.9609611368075988

Epoch: 5| Step: 3
Training loss: 3.2272638108329343
Validation loss: 2.9592038482341767

Epoch: 5| Step: 4
Training loss: 3.349312407116402
Validation loss: 2.956756619357725

Epoch: 5| Step: 5
Training loss: 2.9883505021591565
Validation loss: 2.9543260592057994

Epoch: 5| Step: 6
Training loss: 2.7570391643234378
Validation loss: 2.954655684798433

Epoch: 5| Step: 7
Training loss: 2.9414939512676614
Validation loss: 2.953446876323616

Epoch: 5| Step: 8
Training loss: 3.782138436352297
Validation loss: 2.954091176362485

Epoch: 5| Step: 9
Training loss: 2.200584841066282
Validation loss: 2.954179656961729

Epoch: 5| Step: 10
Training loss: 3.8556881487568297
Validation loss: 2.951693152408106

Epoch: 157| Step: 0
Training loss: 3.0917291688042248
Validation loss: 2.9537119896500705

Epoch: 5| Step: 1
Training loss: 3.5005773340626156
Validation loss: 2.9503296509588393

Epoch: 5| Step: 2
Training loss: 3.2893163442627826
Validation loss: 2.953437413192517

Epoch: 5| Step: 3
Training loss: 3.7279833118409016
Validation loss: 2.9549081279022915

Epoch: 5| Step: 4
Training loss: 3.177881126086702
Validation loss: 2.9519449960346518

Epoch: 5| Step: 5
Training loss: 3.4116796213067753
Validation loss: 2.9526485100590736

Epoch: 5| Step: 6
Training loss: 3.0964927460523755
Validation loss: 2.9545191985106083

Epoch: 5| Step: 7
Training loss: 3.140775610505608
Validation loss: 2.9572672820240595

Epoch: 5| Step: 8
Training loss: 2.4129605540510797
Validation loss: 2.959975891652549

Epoch: 5| Step: 9
Training loss: 3.516300797676964
Validation loss: 2.9655204455850472

Epoch: 5| Step: 10
Training loss: 2.9816157982291265
Validation loss: 2.9590968158273117

Epoch: 158| Step: 0
Training loss: 3.0077127811696434
Validation loss: 2.960966586233838

Epoch: 5| Step: 1
Training loss: 3.2059359986026283
Validation loss: 2.9570999353188148

Epoch: 5| Step: 2
Training loss: 2.769426136685432
Validation loss: 2.9595875857883076

Epoch: 5| Step: 3
Training loss: 3.11781369757842
Validation loss: 2.9585411337340357

Epoch: 5| Step: 4
Training loss: 3.9000663947298104
Validation loss: 2.9552955635011418

Epoch: 5| Step: 5
Training loss: 3.5098483628342594
Validation loss: 2.9554215891014843

Epoch: 5| Step: 6
Training loss: 3.350599030413795
Validation loss: 2.9532032730694446

Epoch: 5| Step: 7
Training loss: 3.169188616189537
Validation loss: 2.955216350830313

Epoch: 5| Step: 8
Training loss: 2.5225955278892136
Validation loss: 2.954880510735689

Epoch: 5| Step: 9
Training loss: 3.268887874693302
Validation loss: 2.952529898483922

Epoch: 5| Step: 10
Training loss: 3.595394388565206
Validation loss: 2.9516470998644246

Epoch: 159| Step: 0
Training loss: 3.157694873006374
Validation loss: 2.952941345382959

Epoch: 5| Step: 1
Training loss: 2.8263960975432156
Validation loss: 2.9557207424095626

Epoch: 5| Step: 2
Training loss: 2.628359143943381
Validation loss: 2.9566634591219274

Epoch: 5| Step: 3
Training loss: 2.9843941732859234
Validation loss: 2.9519776550904817

Epoch: 5| Step: 4
Training loss: 3.66226952774807
Validation loss: 2.9541762048465596

Epoch: 5| Step: 5
Training loss: 3.6565559454828924
Validation loss: 2.953657239576048

Epoch: 5| Step: 6
Training loss: 3.6116318025712077
Validation loss: 2.957907629746804

Epoch: 5| Step: 7
Training loss: 3.0848882895450473
Validation loss: 2.958373898082611

Epoch: 5| Step: 8
Training loss: 3.5418113828525795
Validation loss: 2.958629115591781

Epoch: 5| Step: 9
Training loss: 2.828545976361895
Validation loss: 2.9575282475577542

Epoch: 5| Step: 10
Training loss: 3.4325342550881435
Validation loss: 2.9609836548039645

Epoch: 160| Step: 0
Training loss: 3.266504780657096
Validation loss: 2.960219524741138

Epoch: 5| Step: 1
Training loss: 2.8835291191470978
Validation loss: 2.9621431555925857

Epoch: 5| Step: 2
Training loss: 3.2982578360572106
Validation loss: 2.961101907837919

Epoch: 5| Step: 3
Training loss: 2.643041915399534
Validation loss: 2.968050983993516

Epoch: 5| Step: 4
Training loss: 3.1625145410497444
Validation loss: 2.9714083053745624

Epoch: 5| Step: 5
Training loss: 3.1828558505462428
Validation loss: 2.9617277657868444

Epoch: 5| Step: 6
Training loss: 3.3084102791422767
Validation loss: 2.9554302183474452

Epoch: 5| Step: 7
Training loss: 3.221523090313546
Validation loss: 2.952379863518694

Epoch: 5| Step: 8
Training loss: 3.340315150851314
Validation loss: 2.9525362109170343

Epoch: 5| Step: 9
Training loss: 3.4725999516492445
Validation loss: 2.947847843327009

Epoch: 5| Step: 10
Training loss: 3.732490223528763
Validation loss: 2.9491065940836076

Epoch: 161| Step: 0
Training loss: 3.6608802624866943
Validation loss: 2.950503111947913

Epoch: 5| Step: 1
Training loss: 2.8704245273945563
Validation loss: 2.950885669162253

Epoch: 5| Step: 2
Training loss: 2.9123823215794213
Validation loss: 2.95170990026758

Epoch: 5| Step: 3
Training loss: 2.711902633494552
Validation loss: 2.94828677241117

Epoch: 5| Step: 4
Training loss: 3.547557882706404
Validation loss: 2.9516730796914903

Epoch: 5| Step: 5
Training loss: 3.144206420043191
Validation loss: 2.946421791468033

Epoch: 5| Step: 6
Training loss: 3.01084639882085
Validation loss: 2.94583931696748

Epoch: 5| Step: 7
Training loss: 2.9170343621407118
Validation loss: 2.943738743072724

Epoch: 5| Step: 8
Training loss: 3.859084639649854
Validation loss: 2.9462079648363915

Epoch: 5| Step: 9
Training loss: 3.2851283812729926
Validation loss: 2.9462541868016934

Epoch: 5| Step: 10
Training loss: 3.47045870098981
Validation loss: 2.947001241848293

Epoch: 162| Step: 0
Training loss: 3.7523104861371745
Validation loss: 2.9436854979120572

Epoch: 5| Step: 1
Training loss: 3.499364250208836
Validation loss: 2.944647040478325

Epoch: 5| Step: 2
Training loss: 3.435346032583388
Validation loss: 2.946016960885732

Epoch: 5| Step: 3
Training loss: 3.231671664027704
Validation loss: 2.944392267929515

Epoch: 5| Step: 4
Training loss: 3.392862873502782
Validation loss: 2.9474402100287347

Epoch: 5| Step: 5
Training loss: 2.9157798145401657
Validation loss: 2.945395062813899

Epoch: 5| Step: 6
Training loss: 3.7428178037408544
Validation loss: 2.9482885027867276

Epoch: 5| Step: 7
Training loss: 2.9496725579558345
Validation loss: 2.9412963883276735

Epoch: 5| Step: 8
Training loss: 2.4178436197617916
Validation loss: 2.9481102061588595

Epoch: 5| Step: 9
Training loss: 3.0950699889815634
Validation loss: 2.94865755564366

Epoch: 5| Step: 10
Training loss: 2.7454487679390285
Validation loss: 2.9423177811507557

Epoch: 163| Step: 0
Training loss: 3.5719145471447793
Validation loss: 2.940836179441999

Epoch: 5| Step: 1
Training loss: 2.821999507620138
Validation loss: 2.9400404481028675

Epoch: 5| Step: 2
Training loss: 3.6749951680469537
Validation loss: 2.9387641164357983

Epoch: 5| Step: 3
Training loss: 2.78054217643284
Validation loss: 2.942741711109875

Epoch: 5| Step: 4
Training loss: 3.0414107402275485
Validation loss: 2.9425916788927866

Epoch: 5| Step: 5
Training loss: 3.422975406773466
Validation loss: 2.9432706710305236

Epoch: 5| Step: 6
Training loss: 2.580730254746922
Validation loss: 2.943300483199861

Epoch: 5| Step: 7
Training loss: 3.5837717601273833
Validation loss: 2.9433002428014206

Epoch: 5| Step: 8
Training loss: 3.2233743873146197
Validation loss: 2.9436375312438168

Epoch: 5| Step: 9
Training loss: 3.267024566221746
Validation loss: 2.9406862261059112

Epoch: 5| Step: 10
Training loss: 3.4132545615087304
Validation loss: 2.9429711346021397

Epoch: 164| Step: 0
Training loss: 3.0350549158095936
Validation loss: 2.9397253100514247

Epoch: 5| Step: 1
Training loss: 3.1191238087563287
Validation loss: 2.9365681584286794

Epoch: 5| Step: 2
Training loss: 3.170364546407353
Validation loss: 2.938262587376346

Epoch: 5| Step: 3
Training loss: 3.5355641166646765
Validation loss: 2.937577983385723

Epoch: 5| Step: 4
Training loss: 2.968594838153289
Validation loss: 2.944580831546599

Epoch: 5| Step: 5
Training loss: 2.2957900203027664
Validation loss: 2.939258097327837

Epoch: 5| Step: 6
Training loss: 3.345287504285413
Validation loss: 2.9473729626686276

Epoch: 5| Step: 7
Training loss: 3.6239100165827205
Validation loss: 2.9507328190407254

Epoch: 5| Step: 8
Training loss: 3.30173716049257
Validation loss: 2.965139483427676

Epoch: 5| Step: 9
Training loss: 3.582639686219765
Validation loss: 2.956787044672444

Epoch: 5| Step: 10
Training loss: 3.3235281418535307
Validation loss: 2.943925336946607

Epoch: 165| Step: 0
Training loss: 3.222688949881448
Validation loss: 2.9374972927942413

Epoch: 5| Step: 1
Training loss: 3.181749279960598
Validation loss: 2.9381668374224192

Epoch: 5| Step: 2
Training loss: 2.670071712773831
Validation loss: 2.9385992335433104

Epoch: 5| Step: 3
Training loss: 3.1488866745928967
Validation loss: 2.9367200286779256

Epoch: 5| Step: 4
Training loss: 3.144541864791867
Validation loss: 2.93886939014895

Epoch: 5| Step: 5
Training loss: 3.8280791610775973
Validation loss: 2.9381409030793

Epoch: 5| Step: 6
Training loss: 3.237378039327357
Validation loss: 2.9371247340955056

Epoch: 5| Step: 7
Training loss: 2.987737070038563
Validation loss: 2.940109526864222

Epoch: 5| Step: 8
Training loss: 3.532805513748759
Validation loss: 2.938248868119383

Epoch: 5| Step: 9
Training loss: 2.796226554161824
Validation loss: 2.9378422904459875

Epoch: 5| Step: 10
Training loss: 3.6094011578293217
Validation loss: 2.937914092812284

Epoch: 166| Step: 0
Training loss: 3.8905802651403443
Validation loss: 2.9374621582386538

Epoch: 5| Step: 1
Training loss: 3.4128960683507867
Validation loss: 2.939384269786869

Epoch: 5| Step: 2
Training loss: 2.8324401981138303
Validation loss: 2.9403147192845034

Epoch: 5| Step: 3
Training loss: 2.7590531538419296
Validation loss: 2.938548026573643

Epoch: 5| Step: 4
Training loss: 3.3281605320139636
Validation loss: 2.940758046210068

Epoch: 5| Step: 5
Training loss: 3.045273266887478
Validation loss: 2.9365986715641257

Epoch: 5| Step: 6
Training loss: 2.971136479116882
Validation loss: 2.9396419060203147

Epoch: 5| Step: 7
Training loss: 3.2462659071751796
Validation loss: 2.9387125319865093

Epoch: 5| Step: 8
Training loss: 3.579088239658014
Validation loss: 2.939587136336048

Epoch: 5| Step: 9
Training loss: 3.412235565559712
Validation loss: 2.9402523765105046

Epoch: 5| Step: 10
Training loss: 2.691056315977828
Validation loss: 2.9355395094994083

Epoch: 167| Step: 0
Training loss: 3.6716648772159277
Validation loss: 2.942447333595396

Epoch: 5| Step: 1
Training loss: 2.8447173433059505
Validation loss: 2.939767217856833

Epoch: 5| Step: 2
Training loss: 2.6813127132453123
Validation loss: 2.940524882519916

Epoch: 5| Step: 3
Training loss: 2.911800212042975
Validation loss: 2.9374302978205304

Epoch: 5| Step: 4
Training loss: 3.416837843041734
Validation loss: 2.9384937084875027

Epoch: 5| Step: 5
Training loss: 3.1668608923794124
Validation loss: 2.9347841130709664

Epoch: 5| Step: 6
Training loss: 3.726950059487066
Validation loss: 2.9341107873803396

Epoch: 5| Step: 7
Training loss: 3.3743356121411896
Validation loss: 2.9350724820831218

Epoch: 5| Step: 8
Training loss: 3.215428981608302
Validation loss: 2.9344368565816557

Epoch: 5| Step: 9
Training loss: 2.9499257029859596
Validation loss: 2.936524261629782

Epoch: 5| Step: 10
Training loss: 3.360068741958056
Validation loss: 2.936676711184622

Epoch: 168| Step: 0
Training loss: 2.922734914300724
Validation loss: 2.936753380818062

Epoch: 5| Step: 1
Training loss: 3.6512099520672194
Validation loss: 2.935718212427813

Epoch: 5| Step: 2
Training loss: 3.1426316867813524
Validation loss: 2.9376552211757976

Epoch: 5| Step: 3
Training loss: 3.61413498148986
Validation loss: 2.9382417728896204

Epoch: 5| Step: 4
Training loss: 3.288066939867527
Validation loss: 2.935667022446437

Epoch: 5| Step: 5
Training loss: 3.2930412963261
Validation loss: 2.936038562897947

Epoch: 5| Step: 6
Training loss: 2.772800082176018
Validation loss: 2.93718400633194

Epoch: 5| Step: 7
Training loss: 2.6032763268859407
Validation loss: 2.9405911696962646

Epoch: 5| Step: 8
Training loss: 3.8033808475594486
Validation loss: 2.942521229570134

Epoch: 5| Step: 9
Training loss: 3.3365295027805173
Validation loss: 2.941664788053449

Epoch: 5| Step: 10
Training loss: 2.691247234989771
Validation loss: 2.938608802908205

Epoch: 169| Step: 0
Training loss: 3.3268053187472835
Validation loss: 2.938331800417408

Epoch: 5| Step: 1
Training loss: 4.0180329105744
Validation loss: 2.936224792210496

Epoch: 5| Step: 2
Training loss: 2.6734255925888206
Validation loss: 2.9342666736156557

Epoch: 5| Step: 3
Training loss: 3.5141533378099234
Validation loss: 2.9276400994782743

Epoch: 5| Step: 4
Training loss: 3.3027714795465273
Validation loss: 2.9308743203306333

Epoch: 5| Step: 5
Training loss: 3.5441556076091336
Validation loss: 2.928275683988574

Epoch: 5| Step: 6
Training loss: 2.6030750173690778
Validation loss: 2.927038656089454

Epoch: 5| Step: 7
Training loss: 3.1684997339379475
Validation loss: 2.925862854259949

Epoch: 5| Step: 8
Training loss: 3.2741980932262673
Validation loss: 2.926016242168502

Epoch: 5| Step: 9
Training loss: 3.109815096740172
Validation loss: 2.9267996274400305

Epoch: 5| Step: 10
Training loss: 2.3640458312521657
Validation loss: 2.9245194550039137

Epoch: 170| Step: 0
Training loss: 3.0963857193032456
Validation loss: 2.926622842291508

Epoch: 5| Step: 1
Training loss: 2.859729348827851
Validation loss: 2.9263755203247146

Epoch: 5| Step: 2
Training loss: 3.198855797529972
Validation loss: 2.9249282404606944

Epoch: 5| Step: 3
Training loss: 3.270839197109012
Validation loss: 2.9273916207768234

Epoch: 5| Step: 4
Training loss: 3.6432753971957723
Validation loss: 2.925560327988045

Epoch: 5| Step: 5
Training loss: 2.9947422366278493
Validation loss: 2.9274394516783464

Epoch: 5| Step: 6
Training loss: 2.973189718373254
Validation loss: 2.9244188193223075

Epoch: 5| Step: 7
Training loss: 2.861651738845675
Validation loss: 2.9341230371450164

Epoch: 5| Step: 8
Training loss: 3.532691458813842
Validation loss: 2.9306932514936554

Epoch: 5| Step: 9
Training loss: 2.974804296387687
Validation loss: 2.929967986650187

Epoch: 5| Step: 10
Training loss: 3.87512169923719
Validation loss: 2.9425791280907094

Epoch: 171| Step: 0
Training loss: 3.6265918262089794
Validation loss: 2.9396069854717135

Epoch: 5| Step: 1
Training loss: 2.802687673146401
Validation loss: 2.9443202038639473

Epoch: 5| Step: 2
Training loss: 3.1346783111866556
Validation loss: 2.9534298336383835

Epoch: 5| Step: 3
Training loss: 2.97325018063696
Validation loss: 2.957228762154523

Epoch: 5| Step: 4
Training loss: 3.491885997890771
Validation loss: 2.9482487369347448

Epoch: 5| Step: 5
Training loss: 2.9487734426849714
Validation loss: 2.9399642400217982

Epoch: 5| Step: 6
Training loss: 2.93632613731724
Validation loss: 2.927254488582989

Epoch: 5| Step: 7
Training loss: 3.0995866069185842
Validation loss: 2.923483927151744

Epoch: 5| Step: 8
Training loss: 3.3983390004583316
Validation loss: 2.9244035755197086

Epoch: 5| Step: 9
Training loss: 3.7614587553339747
Validation loss: 2.921426893679936

Epoch: 5| Step: 10
Training loss: 2.99898003087482
Validation loss: 2.9263277631435165

Epoch: 172| Step: 0
Training loss: 3.654479812781344
Validation loss: 2.930593583633111

Epoch: 5| Step: 1
Training loss: 3.6991943874181255
Validation loss: 2.9313894568440655

Epoch: 5| Step: 2
Training loss: 3.1945993984805763
Validation loss: 2.9293727201944417

Epoch: 5| Step: 3
Training loss: 3.2294216096385266
Validation loss: 2.9285553490516483

Epoch: 5| Step: 4
Training loss: 3.7356226923659244
Validation loss: 2.9283698418734625

Epoch: 5| Step: 5
Training loss: 2.963656422695564
Validation loss: 2.926102144295954

Epoch: 5| Step: 6
Training loss: 2.384604458748372
Validation loss: 2.9240115162565252

Epoch: 5| Step: 7
Training loss: 3.032397809928825
Validation loss: 2.9238396181979467

Epoch: 5| Step: 8
Training loss: 3.4436111228342288
Validation loss: 2.926837024580796

Epoch: 5| Step: 9
Training loss: 3.0028810971678563
Validation loss: 2.927975771050287

Epoch: 5| Step: 10
Training loss: 2.701036738106649
Validation loss: 2.928850981044047

Epoch: 173| Step: 0
Training loss: 3.5012347904244043
Validation loss: 2.925927482924347

Epoch: 5| Step: 1
Training loss: 3.163223419075361
Validation loss: 2.928188864184984

Epoch: 5| Step: 2
Training loss: 4.085575707721666
Validation loss: 2.9289468569852843

Epoch: 5| Step: 3
Training loss: 2.860927806360728
Validation loss: 2.927862945865941

Epoch: 5| Step: 4
Training loss: 2.973856178751658
Validation loss: 2.931207954540212

Epoch: 5| Step: 5
Training loss: 3.1541946819746043
Validation loss: 2.931707054464928

Epoch: 5| Step: 6
Training loss: 3.1773794734495184
Validation loss: 2.928770385266207

Epoch: 5| Step: 7
Training loss: 3.2091424755636506
Validation loss: 2.9296683843392386

Epoch: 5| Step: 8
Training loss: 3.3655119442170283
Validation loss: 2.9269595939842055

Epoch: 5| Step: 9
Training loss: 2.9918929868930024
Validation loss: 2.9261184507487723

Epoch: 5| Step: 10
Training loss: 2.4462781468069834
Validation loss: 2.9273640470252857

Epoch: 174| Step: 0
Training loss: 3.423609881672736
Validation loss: 2.936024803561028

Epoch: 5| Step: 1
Training loss: 3.51576741248013
Validation loss: 2.9319302921204224

Epoch: 5| Step: 2
Training loss: 3.040159679535796
Validation loss: 2.9260346430955213

Epoch: 5| Step: 3
Training loss: 3.5121833740014634
Validation loss: 2.934187137879168

Epoch: 5| Step: 4
Training loss: 3.42987352010123
Validation loss: 2.9300277037715836

Epoch: 5| Step: 5
Training loss: 2.135138951052487
Validation loss: 2.932512535578475

Epoch: 5| Step: 6
Training loss: 2.640075716753527
Validation loss: 2.9366638138473786

Epoch: 5| Step: 7
Training loss: 3.5438030905001314
Validation loss: 2.933566647025038

Epoch: 5| Step: 8
Training loss: 3.666874243900526
Validation loss: 2.934597662167865

Epoch: 5| Step: 9
Training loss: 2.9075348997768558
Validation loss: 2.9288503779581982

Epoch: 5| Step: 10
Training loss: 3.1700328870926597
Validation loss: 2.9261315838079884

Epoch: 175| Step: 0
Training loss: 3.130001643122525
Validation loss: 2.923414832617615

Epoch: 5| Step: 1
Training loss: 3.1138010392816438
Validation loss: 2.9246038758516466

Epoch: 5| Step: 2
Training loss: 3.6866336386674488
Validation loss: 2.922886590258597

Epoch: 5| Step: 3
Training loss: 3.0582198770736415
Validation loss: 2.921280300319475

Epoch: 5| Step: 4
Training loss: 2.9126572071264385
Validation loss: 2.920391157626533

Epoch: 5| Step: 5
Training loss: 3.609532472552388
Validation loss: 2.9210576266503736

Epoch: 5| Step: 6
Training loss: 3.04649812372683
Validation loss: 2.919451941768276

Epoch: 5| Step: 7
Training loss: 3.120162882343407
Validation loss: 2.9168220431755487

Epoch: 5| Step: 8
Training loss: 3.4264100562269375
Validation loss: 2.915573024656882

Epoch: 5| Step: 9
Training loss: 2.5143666407640337
Validation loss: 2.918297259687339

Epoch: 5| Step: 10
Training loss: 3.4941230206288636
Validation loss: 2.918021778263404

Epoch: 176| Step: 0
Training loss: 3.300453449653189
Validation loss: 2.9147113527553725

Epoch: 5| Step: 1
Training loss: 3.870152548609902
Validation loss: 2.916268836341064

Epoch: 5| Step: 2
Training loss: 3.6125446620411075
Validation loss: 2.912557495963656

Epoch: 5| Step: 3
Training loss: 3.181679741213275
Validation loss: 2.9142968747945073

Epoch: 5| Step: 4
Training loss: 3.10178311041412
Validation loss: 2.9145850639218205

Epoch: 5| Step: 5
Training loss: 2.632803263209409
Validation loss: 2.912643099688215

Epoch: 5| Step: 6
Training loss: 3.3310522539660563
Validation loss: 2.914217948203963

Epoch: 5| Step: 7
Training loss: 2.9416750193649306
Validation loss: 2.9126612770410127

Epoch: 5| Step: 8
Training loss: 3.0512918394252724
Validation loss: 2.9154971187691405

Epoch: 5| Step: 9
Training loss: 3.1679130577526102
Validation loss: 2.9137502193566545

Epoch: 5| Step: 10
Training loss: 2.7714561584627764
Validation loss: 2.9153248074871008

Epoch: 177| Step: 0
Training loss: 3.7514950632995556
Validation loss: 2.9174167316106296

Epoch: 5| Step: 1
Training loss: 2.4745687166771364
Validation loss: 2.9164736887527196

Epoch: 5| Step: 2
Training loss: 3.2337790414680603
Validation loss: 2.918582625070781

Epoch: 5| Step: 3
Training loss: 3.1658885066630336
Validation loss: 2.926725363421567

Epoch: 5| Step: 4
Training loss: 3.056059780325053
Validation loss: 2.9199149266373388

Epoch: 5| Step: 5
Training loss: 3.3555201925080262
Validation loss: 2.9248090148605614

Epoch: 5| Step: 6
Training loss: 3.5273997153471357
Validation loss: 2.9212734973552594

Epoch: 5| Step: 7
Training loss: 2.842285114308645
Validation loss: 2.9172040634695233

Epoch: 5| Step: 8
Training loss: 2.688268063819693
Validation loss: 2.9166955785299886

Epoch: 5| Step: 9
Training loss: 3.663444418109498
Validation loss: 2.918714079526377

Epoch: 5| Step: 10
Training loss: 3.1916805602353104
Validation loss: 2.91322877200346

Epoch: 178| Step: 0
Training loss: 2.974092675340853
Validation loss: 2.9110582976362216

Epoch: 5| Step: 1
Training loss: 3.0963004032447805
Validation loss: 2.912591281463705

Epoch: 5| Step: 2
Training loss: 3.0408961395721885
Validation loss: 2.9139699648774013

Epoch: 5| Step: 3
Training loss: 3.1172442514707823
Validation loss: 2.913585419357327

Epoch: 5| Step: 4
Training loss: 2.820223059253092
Validation loss: 2.9123934849586206

Epoch: 5| Step: 5
Training loss: 2.8454847808414807
Validation loss: 2.9122045027739785

Epoch: 5| Step: 6
Training loss: 3.1459983293998146
Validation loss: 2.9105498787741033

Epoch: 5| Step: 7
Training loss: 3.2601658213749385
Validation loss: 2.9135138462994243

Epoch: 5| Step: 8
Training loss: 3.458224988105802
Validation loss: 2.914246433664963

Epoch: 5| Step: 9
Training loss: 3.944029948942982
Validation loss: 2.9106351698532302

Epoch: 5| Step: 10
Training loss: 3.3128903716763847
Validation loss: 2.9135615829843

Epoch: 179| Step: 0
Training loss: 2.9099012839231735
Validation loss: 2.9124784139690325

Epoch: 5| Step: 1
Training loss: 3.310488395962113
Validation loss: 2.916126233380505

Epoch: 5| Step: 2
Training loss: 2.90753112776306
Validation loss: 2.91433273461663

Epoch: 5| Step: 3
Training loss: 3.3506588017616408
Validation loss: 2.921058735988689

Epoch: 5| Step: 4
Training loss: 3.376735664810025
Validation loss: 2.918027946586756

Epoch: 5| Step: 5
Training loss: 3.418560914105482
Validation loss: 2.919215526303706

Epoch: 5| Step: 6
Training loss: 3.1926583830186375
Validation loss: 2.9184574577244775

Epoch: 5| Step: 7
Training loss: 3.265525268784012
Validation loss: 2.914541961921173

Epoch: 5| Step: 8
Training loss: 3.1861184810104946
Validation loss: 2.9121446851443817

Epoch: 5| Step: 9
Training loss: 3.082021348209696
Validation loss: 2.9104453318286754

Epoch: 5| Step: 10
Training loss: 3.1064035604118083
Validation loss: 2.90850598203938

Epoch: 180| Step: 0
Training loss: 2.915188405669822
Validation loss: 2.9068165973398026

Epoch: 5| Step: 1
Training loss: 2.9148376906471793
Validation loss: 2.9051367146504856

Epoch: 5| Step: 2
Training loss: 3.6441223634762587
Validation loss: 2.907466906669749

Epoch: 5| Step: 3
Training loss: 3.3245338801589477
Validation loss: 2.9049448731881293

Epoch: 5| Step: 4
Training loss: 3.263478719130818
Validation loss: 2.908133113800196

Epoch: 5| Step: 5
Training loss: 3.130174853526151
Validation loss: 2.9065301173321205

Epoch: 5| Step: 6
Training loss: 3.245689614819111
Validation loss: 2.9044929562499253

Epoch: 5| Step: 7
Training loss: 3.123277570972416
Validation loss: 2.9045886282624465

Epoch: 5| Step: 8
Training loss: 3.4020945548631496
Validation loss: 2.9042776937325994

Epoch: 5| Step: 9
Training loss: 2.723526715619092
Validation loss: 2.904572329802715

Epoch: 5| Step: 10
Training loss: 3.385059341744447
Validation loss: 2.906524955700307

Epoch: 181| Step: 0
Training loss: 3.148746144048943
Validation loss: 2.9018397870502914

Epoch: 5| Step: 1
Training loss: 3.315056444150729
Validation loss: 2.9032279347852885

Epoch: 5| Step: 2
Training loss: 2.811149951313001
Validation loss: 2.9054916015070833

Epoch: 5| Step: 3
Training loss: 3.685497322012198
Validation loss: 2.9111361941300924

Epoch: 5| Step: 4
Training loss: 2.95166221599649
Validation loss: 2.911225765388428

Epoch: 5| Step: 5
Training loss: 2.929701334602752
Validation loss: 2.9291432144845224

Epoch: 5| Step: 6
Training loss: 3.435079381211533
Validation loss: 2.9424363739784667

Epoch: 5| Step: 7
Training loss: 2.887581372456221
Validation loss: 2.925694285197956

Epoch: 5| Step: 8
Training loss: 3.1260325442601262
Validation loss: 2.9152399596412284

Epoch: 5| Step: 9
Training loss: 2.8207227244777195
Validation loss: 2.9101425603332753

Epoch: 5| Step: 10
Training loss: 4.019876685837009
Validation loss: 2.9040019426127173

Epoch: 182| Step: 0
Training loss: 3.0378424934104973
Validation loss: 2.9063828272903676

Epoch: 5| Step: 1
Training loss: 3.002046681660635
Validation loss: 2.90305578276303

Epoch: 5| Step: 2
Training loss: 3.104590640887354
Validation loss: 2.90330464974999

Epoch: 5| Step: 3
Training loss: 2.9188376566693823
Validation loss: 2.899175085437712

Epoch: 5| Step: 4
Training loss: 3.260347473255313
Validation loss: 2.8968227487737184

Epoch: 5| Step: 5
Training loss: 3.2280230230009086
Validation loss: 2.899330644795982

Epoch: 5| Step: 6
Training loss: 3.581705758751401
Validation loss: 2.900310211541907

Epoch: 5| Step: 7
Training loss: 3.868997785925016
Validation loss: 2.89994022964082

Epoch: 5| Step: 8
Training loss: 2.8552534906786673
Validation loss: 2.9009803563274787

Epoch: 5| Step: 9
Training loss: 2.876496133033544
Validation loss: 2.9017743877815025

Epoch: 5| Step: 10
Training loss: 3.259329536391562
Validation loss: 2.8993145396027686

Epoch: 183| Step: 0
Training loss: 2.9928833473585295
Validation loss: 2.899304745932145

Epoch: 5| Step: 1
Training loss: 3.610139707995063
Validation loss: 2.8986157795122627

Epoch: 5| Step: 2
Training loss: 3.2534174924137615
Validation loss: 2.9048130771538925

Epoch: 5| Step: 3
Training loss: 3.0131424088322345
Validation loss: 2.9220114616801567

Epoch: 5| Step: 4
Training loss: 3.1750889923359518
Validation loss: 2.9156509447323344

Epoch: 5| Step: 5
Training loss: 2.9500404678413914
Validation loss: 2.9262607157008933

Epoch: 5| Step: 6
Training loss: 3.578804051626941
Validation loss: 2.9148990536949406

Epoch: 5| Step: 7
Training loss: 3.244399012794763
Validation loss: 2.9028700961573706

Epoch: 5| Step: 8
Training loss: 2.892035887467833
Validation loss: 2.900623997466773

Epoch: 5| Step: 9
Training loss: 3.531304012999527
Validation loss: 2.9016892691668317

Epoch: 5| Step: 10
Training loss: 2.641944781163128
Validation loss: 2.9003018399286207

Epoch: 184| Step: 0
Training loss: 2.9393325933033125
Validation loss: 2.9023062633833465

Epoch: 5| Step: 1
Training loss: 2.9338755872231035
Validation loss: 2.9022001253770426

Epoch: 5| Step: 2
Training loss: 3.3027372625283062
Validation loss: 2.905591998071116

Epoch: 5| Step: 3
Training loss: 2.8577596134988195
Validation loss: 2.9028929075733974

Epoch: 5| Step: 4
Training loss: 3.029371643127508
Validation loss: 2.904575429570971

Epoch: 5| Step: 5
Training loss: 2.778107314166146
Validation loss: 2.902133532853481

Epoch: 5| Step: 6
Training loss: 3.37337172047884
Validation loss: 2.9038215059105443

Epoch: 5| Step: 7
Training loss: 3.2033981578935213
Validation loss: 2.9029804724260684

Epoch: 5| Step: 8
Training loss: 3.7190234941200484
Validation loss: 2.899438596974156

Epoch: 5| Step: 9
Training loss: 3.3477264717419866
Validation loss: 2.903587795350568

Epoch: 5| Step: 10
Training loss: 3.4991767460047334
Validation loss: 2.904236578484216

Epoch: 185| Step: 0
Training loss: 2.814417376215103
Validation loss: 2.9005970672294

Epoch: 5| Step: 1
Training loss: 3.5153638954688486
Validation loss: 2.8990349573538774

Epoch: 5| Step: 2
Training loss: 2.9972717277139584
Validation loss: 2.895328497790579

Epoch: 5| Step: 3
Training loss: 3.9691375783468033
Validation loss: 2.9023208053049143

Epoch: 5| Step: 4
Training loss: 2.6824503632545493
Validation loss: 2.9039211745043896

Epoch: 5| Step: 5
Training loss: 3.1794421502009764
Validation loss: 2.8996143508614716

Epoch: 5| Step: 6
Training loss: 3.0452461779571767
Validation loss: 2.900217288020097

Epoch: 5| Step: 7
Training loss: 2.9987548787378246
Validation loss: 2.90114940613286

Epoch: 5| Step: 8
Training loss: 3.368213470707124
Validation loss: 2.8964519762095513

Epoch: 5| Step: 9
Training loss: 3.1637536922510154
Validation loss: 2.9035793722654537

Epoch: 5| Step: 10
Training loss: 3.102368612773389
Validation loss: 2.903969561483284

Epoch: 186| Step: 0
Training loss: 2.7579464109939313
Validation loss: 2.898770035226604

Epoch: 5| Step: 1
Training loss: 2.6496691695221615
Validation loss: 2.90081484410808

Epoch: 5| Step: 2
Training loss: 3.044181219804634
Validation loss: 2.897719329396975

Epoch: 5| Step: 3
Training loss: 3.0483086758703144
Validation loss: 2.8979113714092013

Epoch: 5| Step: 4
Training loss: 3.186861011558965
Validation loss: 2.8958183182540824

Epoch: 5| Step: 5
Training loss: 2.688422200089457
Validation loss: 2.896802176371817

Epoch: 5| Step: 6
Training loss: 3.345158645676778
Validation loss: 2.8966773440883364

Epoch: 5| Step: 7
Training loss: 3.8416913730270967
Validation loss: 2.9019161553032977

Epoch: 5| Step: 8
Training loss: 3.670528603302409
Validation loss: 2.8958239752552677

Epoch: 5| Step: 9
Training loss: 4.0375203890920455
Validation loss: 2.8943134192848943

Epoch: 5| Step: 10
Training loss: 2.073648665368373
Validation loss: 2.8894954790445104

Epoch: 187| Step: 0
Training loss: 2.5097882340299735
Validation loss: 2.8901126672500146

Epoch: 5| Step: 1
Training loss: 3.274588371208585
Validation loss: 2.8934165860141037

Epoch: 5| Step: 2
Training loss: 2.1993486220395098
Validation loss: 2.888887927211252

Epoch: 5| Step: 3
Training loss: 2.899278544428947
Validation loss: 2.8906777263733714

Epoch: 5| Step: 4
Training loss: 2.8683703734425867
Validation loss: 2.8927831746396038

Epoch: 5| Step: 5
Training loss: 3.295175267885085
Validation loss: 2.8930413742232077

Epoch: 5| Step: 6
Training loss: 4.063348300104113
Validation loss: 2.8962894457330792

Epoch: 5| Step: 7
Training loss: 3.645491723904694
Validation loss: 2.8968172291257233

Epoch: 5| Step: 8
Training loss: 3.003589390188598
Validation loss: 2.8950319583763986

Epoch: 5| Step: 9
Training loss: 3.27635801856951
Validation loss: 2.8977272555010702

Epoch: 5| Step: 10
Training loss: 3.599905166436531
Validation loss: 2.8934718344874977

Epoch: 188| Step: 0
Training loss: 3.3641971488543687
Validation loss: 2.8933950537443143

Epoch: 5| Step: 1
Training loss: 2.8444736105032877
Validation loss: 2.892593563995512

Epoch: 5| Step: 2
Training loss: 3.0537282701079103
Validation loss: 2.8951613227144297

Epoch: 5| Step: 3
Training loss: 2.9321926138608756
Validation loss: 2.8907239174761816

Epoch: 5| Step: 4
Training loss: 3.641966216616188
Validation loss: 2.8905599899985734

Epoch: 5| Step: 5
Training loss: 3.0453053661750236
Validation loss: 2.8906005876081764

Epoch: 5| Step: 6
Training loss: 3.7029622360063383
Validation loss: 2.8885078656793888

Epoch: 5| Step: 7
Training loss: 2.7842736256787237
Validation loss: 2.8877749950597313

Epoch: 5| Step: 8
Training loss: 3.2894733380769248
Validation loss: 2.887574261929977

Epoch: 5| Step: 9
Training loss: 2.5546852601767704
Validation loss: 2.888462230243509

Epoch: 5| Step: 10
Training loss: 3.6083959267159735
Validation loss: 2.8880521304215105

Epoch: 189| Step: 0
Training loss: 2.4367105232532857
Validation loss: 2.889985647670112

Epoch: 5| Step: 1
Training loss: 3.347945388895459
Validation loss: 2.8896334485413746

Epoch: 5| Step: 2
Training loss: 3.2868866961209977
Validation loss: 2.8905464310238096

Epoch: 5| Step: 3
Training loss: 3.172744105742293
Validation loss: 2.8975238205186287

Epoch: 5| Step: 4
Training loss: 3.294817531088996
Validation loss: 2.8997390964925254

Epoch: 5| Step: 5
Training loss: 3.9765214899193038
Validation loss: 2.908007840498971

Epoch: 5| Step: 6
Training loss: 3.2655809025319593
Validation loss: 2.907974692913901

Epoch: 5| Step: 7
Training loss: 2.3555885904422857
Validation loss: 2.8984291707403376

Epoch: 5| Step: 8
Training loss: 3.515101279350192
Validation loss: 2.886672333175113

Epoch: 5| Step: 9
Training loss: 3.2327435935537165
Validation loss: 2.885247503036508

Epoch: 5| Step: 10
Training loss: 2.6923821040758953
Validation loss: 2.885806399017015

Epoch: 190| Step: 0
Training loss: 3.368685855856372
Validation loss: 2.88327933926031

Epoch: 5| Step: 1
Training loss: 3.191318244607814
Validation loss: 2.886997036366338

Epoch: 5| Step: 2
Training loss: 3.425615052179356
Validation loss: 2.886112188984198

Epoch: 5| Step: 3
Training loss: 2.8650581290055124
Validation loss: 2.8872162333082865

Epoch: 5| Step: 4
Training loss: 3.186183283493846
Validation loss: 2.885043651020042

Epoch: 5| Step: 5
Training loss: 3.3047899451282676
Validation loss: 2.888497550774237

Epoch: 5| Step: 6
Training loss: 3.172999290814878
Validation loss: 2.888725126903112

Epoch: 5| Step: 7
Training loss: 2.9335605908994817
Validation loss: 2.886054994627906

Epoch: 5| Step: 8
Training loss: 2.7397763337781535
Validation loss: 2.8856277692161667

Epoch: 5| Step: 9
Training loss: 3.323713790966035
Validation loss: 2.8832051759806894

Epoch: 5| Step: 10
Training loss: 3.476873559644621
Validation loss: 2.882046172785497

Epoch: 191| Step: 0
Training loss: 3.4019527101094877
Validation loss: 2.8829387952048027

Epoch: 5| Step: 1
Training loss: 3.4773034838417245
Validation loss: 2.8830971468229056

Epoch: 5| Step: 2
Training loss: 3.372752394906301
Validation loss: 2.8859973265608834

Epoch: 5| Step: 3
Training loss: 3.4409481440802074
Validation loss: 2.885044003792961

Epoch: 5| Step: 4
Training loss: 2.7867229490513203
Validation loss: 2.887586450758665

Epoch: 5| Step: 5
Training loss: 3.370064128412731
Validation loss: 2.884993660350912

Epoch: 5| Step: 6
Training loss: 2.6993125534871973
Validation loss: 2.886689176744742

Epoch: 5| Step: 7
Training loss: 2.925098619673267
Validation loss: 2.8968578974542676

Epoch: 5| Step: 8
Training loss: 3.0970974161939933
Validation loss: 2.893263614112354

Epoch: 5| Step: 9
Training loss: 3.4900581302556377
Validation loss: 2.8886384576071538

Epoch: 5| Step: 10
Training loss: 2.632185864231218
Validation loss: 2.88124084983709

Epoch: 192| Step: 0
Training loss: 3.9473092342423417
Validation loss: 2.88099454217486

Epoch: 5| Step: 1
Training loss: 2.748394844457182
Validation loss: 2.8827084856232394

Epoch: 5| Step: 2
Training loss: 3.2495389758083917
Validation loss: 2.8789531339790826

Epoch: 5| Step: 3
Training loss: 3.0394661838754455
Validation loss: 2.882494243061139

Epoch: 5| Step: 4
Training loss: 2.8171186035668607
Validation loss: 2.8808717835640363

Epoch: 5| Step: 5
Training loss: 3.1462161271246294
Validation loss: 2.879493604374568

Epoch: 5| Step: 6
Training loss: 3.045963718391091
Validation loss: 2.880555762325238

Epoch: 5| Step: 7
Training loss: 3.2279128234795755
Validation loss: 2.880165120393872

Epoch: 5| Step: 8
Training loss: 3.11173285410005
Validation loss: 2.8803423102120878

Epoch: 5| Step: 9
Training loss: 3.049952434731725
Validation loss: 2.882727179887793

Epoch: 5| Step: 10
Training loss: 3.396024421666987
Validation loss: 2.8876912358074014

Epoch: 193| Step: 0
Training loss: 3.1946664170990573
Validation loss: 2.889000824078876

Epoch: 5| Step: 1
Training loss: 2.6550491311220354
Validation loss: 2.8905735285111076

Epoch: 5| Step: 2
Training loss: 3.379281330789443
Validation loss: 2.8876368266800623

Epoch: 5| Step: 3
Training loss: 2.504849879474052
Validation loss: 2.8863740739919868

Epoch: 5| Step: 4
Training loss: 3.7334336886087542
Validation loss: 2.8830790062627782

Epoch: 5| Step: 5
Training loss: 3.26903024205187
Validation loss: 2.8807248698196926

Epoch: 5| Step: 6
Training loss: 3.0639990427000776
Validation loss: 2.875993584591674

Epoch: 5| Step: 7
Training loss: 3.780466424129722
Validation loss: 2.8770735736701676

Epoch: 5| Step: 8
Training loss: 2.1970087740501114
Validation loss: 2.8748365679456938

Epoch: 5| Step: 9
Training loss: 2.923695369502004
Validation loss: 2.8769381670282472

Epoch: 5| Step: 10
Training loss: 3.8855684197920457
Validation loss: 2.877773509371684

Epoch: 194| Step: 0
Training loss: 2.8356129694433947
Validation loss: 2.8765759350965343

Epoch: 5| Step: 1
Training loss: 3.366682470555242
Validation loss: 2.8728274500459103

Epoch: 5| Step: 2
Training loss: 3.274201005920811
Validation loss: 2.8734644301862504

Epoch: 5| Step: 3
Training loss: 3.173546411776225
Validation loss: 2.875315248986978

Epoch: 5| Step: 4
Training loss: 2.8105798736607372
Validation loss: 2.874572049712941

Epoch: 5| Step: 5
Training loss: 3.4397819574139845
Validation loss: 2.87660071426414

Epoch: 5| Step: 6
Training loss: 2.9950296235569835
Validation loss: 2.87644257986839

Epoch: 5| Step: 7
Training loss: 3.192923475840096
Validation loss: 2.877855898577454

Epoch: 5| Step: 8
Training loss: 3.3117084637099925
Validation loss: 2.878425516487791

Epoch: 5| Step: 9
Training loss: 3.4577806942765923
Validation loss: 2.8791628959294733

Epoch: 5| Step: 10
Training loss: 2.8957278188972206
Validation loss: 2.87513046628482

Epoch: 195| Step: 0
Training loss: 2.9888794144484603
Validation loss: 2.879335128476178

Epoch: 5| Step: 1
Training loss: 2.889311786003844
Validation loss: 2.8801002169876466

Epoch: 5| Step: 2
Training loss: 3.0755987499336226
Validation loss: 2.881660272733788

Epoch: 5| Step: 3
Training loss: 2.2740804805152237
Validation loss: 2.8815220656037464

Epoch: 5| Step: 4
Training loss: 3.8354179822984076
Validation loss: 2.8773434884454394

Epoch: 5| Step: 5
Training loss: 3.009505788589338
Validation loss: 2.8723358742152705

Epoch: 5| Step: 6
Training loss: 3.622074656870878
Validation loss: 2.874870015576998

Epoch: 5| Step: 7
Training loss: 3.5992065138015765
Validation loss: 2.871183513270309

Epoch: 5| Step: 8
Training loss: 3.1498529551260033
Validation loss: 2.8745606217313724

Epoch: 5| Step: 9
Training loss: 2.562503256446816
Validation loss: 2.8741427468134355

Epoch: 5| Step: 10
Training loss: 3.5519543546974255
Validation loss: 2.871815675089277

Epoch: 196| Step: 0
Training loss: 3.1875737499606167
Validation loss: 2.871402100498765

Epoch: 5| Step: 1
Training loss: 3.0891132479846886
Validation loss: 2.872802790037396

Epoch: 5| Step: 2
Training loss: 3.5001290161332106
Validation loss: 2.8749112413784412

Epoch: 5| Step: 3
Training loss: 3.0775169120466432
Validation loss: 2.8726520483002242

Epoch: 5| Step: 4
Training loss: 2.946016020193263
Validation loss: 2.8727472886272607

Epoch: 5| Step: 5
Training loss: 3.2535897017395454
Validation loss: 2.8724562532125693

Epoch: 5| Step: 6
Training loss: 3.182669775810156
Validation loss: 2.8710270503136472

Epoch: 5| Step: 7
Training loss: 3.7688535407221084
Validation loss: 2.8724860345820176

Epoch: 5| Step: 8
Training loss: 3.0837144014787907
Validation loss: 2.8750075990666515

Epoch: 5| Step: 9
Training loss: 2.5019083368966397
Validation loss: 2.878996085801453

Epoch: 5| Step: 10
Training loss: 3.0954591287913296
Validation loss: 2.88106677983385

Epoch: 197| Step: 0
Training loss: 2.925119485615409
Validation loss: 2.887103048661381

Epoch: 5| Step: 1
Training loss: 3.0942644404394666
Validation loss: 2.8869023780366483

Epoch: 5| Step: 2
Training loss: 3.15381551087113
Validation loss: 2.8757328804268933

Epoch: 5| Step: 3
Training loss: 3.187127484264184
Validation loss: 2.8702597058424018

Epoch: 5| Step: 4
Training loss: 3.106098384726109
Validation loss: 2.870049739808378

Epoch: 5| Step: 5
Training loss: 3.474877521359875
Validation loss: 2.8702831649551745

Epoch: 5| Step: 6
Training loss: 2.7394971555976007
Validation loss: 2.8700143440976897

Epoch: 5| Step: 7
Training loss: 3.456706127675998
Validation loss: 2.8688084639405207

Epoch: 5| Step: 8
Training loss: 3.2757788685654203
Validation loss: 2.8664496917295157

Epoch: 5| Step: 9
Training loss: 3.313540745031202
Validation loss: 2.872200980590264

Epoch: 5| Step: 10
Training loss: 3.0138547771377078
Validation loss: 2.8715155370858034

Epoch: 198| Step: 0
Training loss: 3.079469029125439
Validation loss: 2.872114606178235

Epoch: 5| Step: 1
Training loss: 3.786233187789592
Validation loss: 2.871934364675884

Epoch: 5| Step: 2
Training loss: 3.3397245330056586
Validation loss: 2.86888556134533

Epoch: 5| Step: 3
Training loss: 3.5034657076995708
Validation loss: 2.8717721311348234

Epoch: 5| Step: 4
Training loss: 3.0110364405752663
Validation loss: 2.8716713244092267

Epoch: 5| Step: 5
Training loss: 2.7338385355444337
Validation loss: 2.8683635933555287

Epoch: 5| Step: 6
Training loss: 3.342266003015336
Validation loss: 2.86875620692137

Epoch: 5| Step: 7
Training loss: 3.77124718068858
Validation loss: 2.86999891048075

Epoch: 5| Step: 8
Training loss: 2.717064345882881
Validation loss: 2.868373577577809

Epoch: 5| Step: 9
Training loss: 2.708227380489606
Validation loss: 2.8721228957138174

Epoch: 5| Step: 10
Training loss: 2.4299053327542333
Validation loss: 2.8714024174492807

Epoch: 199| Step: 0
Training loss: 3.647155405752672
Validation loss: 2.871473954517556

Epoch: 5| Step: 1
Training loss: 3.133165296823913
Validation loss: 2.872819588207601

Epoch: 5| Step: 2
Training loss: 2.527636739501434
Validation loss: 2.8714727813832925

Epoch: 5| Step: 3
Training loss: 3.234349789728516
Validation loss: 2.88353026337166

Epoch: 5| Step: 4
Training loss: 2.4864918069832984
Validation loss: 2.8774624177632333

Epoch: 5| Step: 5
Training loss: 2.967702741116662
Validation loss: 2.87751354645941

Epoch: 5| Step: 6
Training loss: 3.5693289906738146
Validation loss: 2.8766695839715446

Epoch: 5| Step: 7
Training loss: 3.497817721547449
Validation loss: 2.874428840818302

Epoch: 5| Step: 8
Training loss: 3.4735374062224746
Validation loss: 2.875111243800755

Epoch: 5| Step: 9
Training loss: 2.499697285444752
Validation loss: 2.8738580302074417

Epoch: 5| Step: 10
Training loss: 3.5148731021032837
Validation loss: 2.8785269826321533

Epoch: 200| Step: 0
Training loss: 2.8030118479265655
Validation loss: 2.874612897196357

Epoch: 5| Step: 1
Training loss: 2.989267383499052
Validation loss: 2.8736616499855936

Epoch: 5| Step: 2
Training loss: 2.497324656459048
Validation loss: 2.870466324328586

Epoch: 5| Step: 3
Training loss: 2.5869089935126346
Validation loss: 2.8706845285767866

Epoch: 5| Step: 4
Training loss: 3.7801542349537884
Validation loss: 2.8664258390240516

Epoch: 5| Step: 5
Training loss: 2.931888984056447
Validation loss: 2.8681832242854344

Epoch: 5| Step: 6
Training loss: 3.062847195621353
Validation loss: 2.8654058817384316

Epoch: 5| Step: 7
Training loss: 3.527492313065727
Validation loss: 2.866079751229846

Epoch: 5| Step: 8
Training loss: 3.2437136080249487
Validation loss: 2.8669649672452877

Epoch: 5| Step: 9
Training loss: 3.4936448028504397
Validation loss: 2.8655368313597003

Epoch: 5| Step: 10
Training loss: 3.646151036543415
Validation loss: 2.8662481153623003

Epoch: 201| Step: 0
Training loss: 3.3036195729403897
Validation loss: 2.865685281468287

Epoch: 5| Step: 1
Training loss: 3.1142232084938577
Validation loss: 2.86971461891657

Epoch: 5| Step: 2
Training loss: 2.8305454750201817
Validation loss: 2.875526068888806

Epoch: 5| Step: 3
Training loss: 2.9260742692680344
Validation loss: 2.8728575639893914

Epoch: 5| Step: 4
Training loss: 3.081662077363061
Validation loss: 2.875734921901264

Epoch: 5| Step: 5
Training loss: 2.8453597658223204
Validation loss: 2.875653458817179

Epoch: 5| Step: 6
Training loss: 3.3790624681644057
Validation loss: 2.8720141006849333

Epoch: 5| Step: 7
Training loss: 3.8168058000771965
Validation loss: 2.8674994095030693

Epoch: 5| Step: 8
Training loss: 3.5648530918578287
Validation loss: 2.867625873122211

Epoch: 5| Step: 9
Training loss: 3.0436946605374975
Validation loss: 2.8671584969327495

Epoch: 5| Step: 10
Training loss: 2.6152872503289957
Validation loss: 2.8656160547331986

Epoch: 202| Step: 0
Training loss: 2.937363641698831
Validation loss: 2.861574543300579

Epoch: 5| Step: 1
Training loss: 3.7130768401652663
Validation loss: 2.864341668071315

Epoch: 5| Step: 2
Training loss: 3.4214505145708634
Validation loss: 2.8618566954200326

Epoch: 5| Step: 3
Training loss: 2.606983665189793
Validation loss: 2.863003527420862

Epoch: 5| Step: 4
Training loss: 3.2341886457485844
Validation loss: 2.8623445412317485

Epoch: 5| Step: 5
Training loss: 3.2495460193179353
Validation loss: 2.8617956820837334

Epoch: 5| Step: 6
Training loss: 3.3027480907369697
Validation loss: 2.8621675100038106

Epoch: 5| Step: 7
Training loss: 3.0816775507001473
Validation loss: 2.8631280442477323

Epoch: 5| Step: 8
Training loss: 3.118991110125828
Validation loss: 2.8627034308971298

Epoch: 5| Step: 9
Training loss: 3.174904264673779
Validation loss: 2.8658579554409234

Epoch: 5| Step: 10
Training loss: 2.690656804019759
Validation loss: 2.8635420322707077

Epoch: 203| Step: 0
Training loss: 2.9952236936455323
Validation loss: 2.8660941030674008

Epoch: 5| Step: 1
Training loss: 3.3809204448647403
Validation loss: 2.864396909910387

Epoch: 5| Step: 2
Training loss: 2.5324882022021766
Validation loss: 2.8642124888349825

Epoch: 5| Step: 3
Training loss: 3.2412340347832496
Validation loss: 2.864112738085622

Epoch: 5| Step: 4
Training loss: 2.6166039570706836
Validation loss: 2.8617857403071874

Epoch: 5| Step: 5
Training loss: 3.076837105650384
Validation loss: 2.862896522434399

Epoch: 5| Step: 6
Training loss: 3.0703733792469414
Validation loss: 2.8621352162891376

Epoch: 5| Step: 7
Training loss: 3.4218946482473145
Validation loss: 2.860836257048669

Epoch: 5| Step: 8
Training loss: 3.4834013121571403
Validation loss: 2.8619116197472483

Epoch: 5| Step: 9
Training loss: 3.253548372332644
Validation loss: 2.863876331298459

Epoch: 5| Step: 10
Training loss: 3.5037312373551375
Validation loss: 2.863413757034618

Epoch: 204| Step: 0
Training loss: 3.2269097757839162
Validation loss: 2.8647976440330196

Epoch: 5| Step: 1
Training loss: 3.1807607578082773
Validation loss: 2.8633987337070925

Epoch: 5| Step: 2
Training loss: 2.920894029742161
Validation loss: 2.863371681670366

Epoch: 5| Step: 3
Training loss: 3.0313807193846394
Validation loss: 2.8622629415607004

Epoch: 5| Step: 4
Training loss: 2.6085171688568485
Validation loss: 2.8635927076332135

Epoch: 5| Step: 5
Training loss: 3.050015752782946
Validation loss: 2.8645979847165104

Epoch: 5| Step: 6
Training loss: 3.1865677311700864
Validation loss: 2.8653644905470155

Epoch: 5| Step: 7
Training loss: 3.5099793264535544
Validation loss: 2.8648096979966855

Epoch: 5| Step: 8
Training loss: 2.8930871323756526
Validation loss: 2.86431961113454

Epoch: 5| Step: 9
Training loss: 3.808716319141506
Validation loss: 2.864627392263164

Epoch: 5| Step: 10
Training loss: 3.137937544143418
Validation loss: 2.8615872200399384

Epoch: 205| Step: 0
Training loss: 2.810698207574499
Validation loss: 2.857972933091867

Epoch: 5| Step: 1
Training loss: 3.000040212997494
Validation loss: 2.8595220450769077

Epoch: 5| Step: 2
Training loss: 3.60344019865167
Validation loss: 2.8574260576808985

Epoch: 5| Step: 3
Training loss: 3.0909147275271502
Validation loss: 2.8582369389157054

Epoch: 5| Step: 4
Training loss: 2.8967000272678622
Validation loss: 2.857570439856786

Epoch: 5| Step: 5
Training loss: 3.130226037879337
Validation loss: 2.85592489037733

Epoch: 5| Step: 6
Training loss: 3.824023981170795
Validation loss: 2.8543064995459613

Epoch: 5| Step: 7
Training loss: 2.3058367433880056
Validation loss: 2.8556238578434088

Epoch: 5| Step: 8
Training loss: 3.5301137801034224
Validation loss: 2.857855533126562

Epoch: 5| Step: 9
Training loss: 3.211023334181976
Validation loss: 2.8562865684424628

Epoch: 5| Step: 10
Training loss: 2.9786103980823766
Validation loss: 2.855268441936842

Epoch: 206| Step: 0
Training loss: 3.1099889714575983
Validation loss: 2.855547068533145

Epoch: 5| Step: 1
Training loss: 2.669886869969868
Validation loss: 2.855091903094074

Epoch: 5| Step: 2
Training loss: 2.2532656600578953
Validation loss: 2.8560947929206515

Epoch: 5| Step: 3
Training loss: 3.1162802539983403
Validation loss: 2.854361297915039

Epoch: 5| Step: 4
Training loss: 3.4506678059304354
Validation loss: 2.8564997934159733

Epoch: 5| Step: 5
Training loss: 3.1171613419661397
Validation loss: 2.8544546373814725

Epoch: 5| Step: 6
Training loss: 3.8281018314828237
Validation loss: 2.856734400220083

Epoch: 5| Step: 7
Training loss: 3.308322359414401
Validation loss: 2.8527431784116732

Epoch: 5| Step: 8
Training loss: 2.8814179477027038
Validation loss: 2.85619951260408

Epoch: 5| Step: 9
Training loss: 2.983755956227527
Validation loss: 2.8546877634507566

Epoch: 5| Step: 10
Training loss: 3.7071529324240027
Validation loss: 2.8561361891957104

Epoch: 207| Step: 0
Training loss: 3.374051278602572
Validation loss: 2.8580391884406082

Epoch: 5| Step: 1
Training loss: 2.6547626594739513
Validation loss: 2.858598037472263

Epoch: 5| Step: 2
Training loss: 2.9868102997347457
Validation loss: 2.854865740721147

Epoch: 5| Step: 3
Training loss: 3.4059613306759036
Validation loss: 2.8554525258050982

Epoch: 5| Step: 4
Training loss: 3.0382640741029037
Validation loss: 2.8543369418170865

Epoch: 5| Step: 5
Training loss: 3.453494091072512
Validation loss: 2.8562540520617095

Epoch: 5| Step: 6
Training loss: 2.7691910162134614
Validation loss: 2.8598619038992674

Epoch: 5| Step: 7
Training loss: 3.2473509335976454
Validation loss: 2.8612944751656233

Epoch: 5| Step: 8
Training loss: 3.6103214492759577
Validation loss: 2.8626534195126765

Epoch: 5| Step: 9
Training loss: 2.9754886642596534
Validation loss: 2.8579543872751803

Epoch: 5| Step: 10
Training loss: 2.953661995963886
Validation loss: 2.855179194729582

Epoch: 208| Step: 0
Training loss: 3.1435967045867805
Validation loss: 2.8577832182824863

Epoch: 5| Step: 1
Training loss: 2.9854175284562574
Validation loss: 2.8597960968670897

Epoch: 5| Step: 2
Training loss: 3.2243032604739477
Validation loss: 2.863101130232287

Epoch: 5| Step: 3
Training loss: 4.084722918261376
Validation loss: 2.8633005402640754

Epoch: 5| Step: 4
Training loss: 2.8192604194889
Validation loss: 2.8678344629691317

Epoch: 5| Step: 5
Training loss: 3.264578035435925
Validation loss: 2.8697984249179163

Epoch: 5| Step: 6
Training loss: 2.389822532257836
Validation loss: 2.8641697816469818

Epoch: 5| Step: 7
Training loss: 2.9643274392951935
Validation loss: 2.858470689246548

Epoch: 5| Step: 8
Training loss: 3.374518183471687
Validation loss: 2.852667987599972

Epoch: 5| Step: 9
Training loss: 2.788133397007406
Validation loss: 2.850777864185929

Epoch: 5| Step: 10
Training loss: 3.3859482254963953
Validation loss: 2.8515710156007774

Epoch: 209| Step: 0
Training loss: 3.2417964101943424
Validation loss: 2.8528683659211542

Epoch: 5| Step: 1
Training loss: 3.2359003717861103
Validation loss: 2.8543598294416817

Epoch: 5| Step: 2
Training loss: 3.3376061869098526
Validation loss: 2.8504782613090214

Epoch: 5| Step: 3
Training loss: 2.9961225565454312
Validation loss: 2.8511515003289394

Epoch: 5| Step: 4
Training loss: 2.6718808893506916
Validation loss: 2.84756607099005

Epoch: 5| Step: 5
Training loss: 3.3185050802141656
Validation loss: 2.847773447475948

Epoch: 5| Step: 6
Training loss: 3.167001371932026
Validation loss: 2.8517528470967326

Epoch: 5| Step: 7
Training loss: 3.068140246690861
Validation loss: 2.84724085078301

Epoch: 5| Step: 8
Training loss: 3.072849147938494
Validation loss: 2.845614066988832

Epoch: 5| Step: 9
Training loss: 2.704455186198598
Validation loss: 2.8486465934737786

Epoch: 5| Step: 10
Training loss: 3.8268123945429235
Validation loss: 2.8475195471263666

Epoch: 210| Step: 0
Training loss: 3.188434089973628
Validation loss: 2.847887498466608

Epoch: 5| Step: 1
Training loss: 3.3518881472860196
Validation loss: 2.849326033493298

Epoch: 5| Step: 2
Training loss: 3.2302375904485836
Validation loss: 2.853962070780897

Epoch: 5| Step: 3
Training loss: 3.143234459409811
Validation loss: 2.8500736878300805

Epoch: 5| Step: 4
Training loss: 3.3266945213828447
Validation loss: 2.849275634346782

Epoch: 5| Step: 5
Training loss: 3.4284251329454336
Validation loss: 2.8506226653334146

Epoch: 5| Step: 6
Training loss: 2.9686219840306083
Validation loss: 2.852668384817274

Epoch: 5| Step: 7
Training loss: 3.191472439213792
Validation loss: 2.8511642980407657

Epoch: 5| Step: 8
Training loss: 2.93197729527112
Validation loss: 2.845877458202712

Epoch: 5| Step: 9
Training loss: 2.6147595431055835
Validation loss: 2.847308921611108

Epoch: 5| Step: 10
Training loss: 3.1334682929280846
Validation loss: 2.8469462398937053

Epoch: 211| Step: 0
Training loss: 3.2982581252020626
Validation loss: 2.852565858679998

Epoch: 5| Step: 1
Training loss: 3.2937618943059372
Validation loss: 2.848204481031412

Epoch: 5| Step: 2
Training loss: 2.938587068740909
Validation loss: 2.8496771571474504

Epoch: 5| Step: 3
Training loss: 3.2611225245671553
Validation loss: 2.8507779415238

Epoch: 5| Step: 4
Training loss: 2.8817315284690994
Validation loss: 2.8565423918071

Epoch: 5| Step: 5
Training loss: 3.2832864890331126
Validation loss: 2.8556515560364724

Epoch: 5| Step: 6
Training loss: 2.6295375661101463
Validation loss: 2.8530134154542353

Epoch: 5| Step: 7
Training loss: 3.3679982778041904
Validation loss: 2.8488577023153128

Epoch: 5| Step: 8
Training loss: 3.247117304641164
Validation loss: 2.846490285458589

Epoch: 5| Step: 9
Training loss: 3.2241890885819124
Validation loss: 2.8442495421844605

Epoch: 5| Step: 10
Training loss: 3.0415979316644193
Validation loss: 2.8443997756492188

Epoch: 212| Step: 0
Training loss: 3.155942694178782
Validation loss: 2.8459732342215776

Epoch: 5| Step: 1
Training loss: 3.766285691926199
Validation loss: 2.8452282966342706

Epoch: 5| Step: 2
Training loss: 3.481809895005541
Validation loss: 2.8489605913608647

Epoch: 5| Step: 3
Training loss: 3.12467268183266
Validation loss: 2.8459774274227723

Epoch: 5| Step: 4
Training loss: 3.0701506671527627
Validation loss: 2.8456556292423856

Epoch: 5| Step: 5
Training loss: 3.2105938432847725
Validation loss: 2.8480491950556446

Epoch: 5| Step: 6
Training loss: 2.938808231012114
Validation loss: 2.8465017414763487

Epoch: 5| Step: 7
Training loss: 2.8410682189764347
Validation loss: 2.8470146905588676

Epoch: 5| Step: 8
Training loss: 2.867957404188774
Validation loss: 2.847518404637065

Epoch: 5| Step: 9
Training loss: 2.982603176279627
Validation loss: 2.846136324026561

Epoch: 5| Step: 10
Training loss: 2.9771772735987048
Validation loss: 2.847175499384067

Epoch: 213| Step: 0
Training loss: 2.330333200132315
Validation loss: 2.8526188095138054

Epoch: 5| Step: 1
Training loss: 2.9658289944719813
Validation loss: 2.8501901670725105

Epoch: 5| Step: 2
Training loss: 3.3872963875813666
Validation loss: 2.8485242632894034

Epoch: 5| Step: 3
Training loss: 3.3006041349485775
Validation loss: 2.8447720290012257

Epoch: 5| Step: 4
Training loss: 3.268523467695239
Validation loss: 2.8467984740992587

Epoch: 5| Step: 5
Training loss: 2.8076317085222313
Validation loss: 2.8439638746362634

Epoch: 5| Step: 6
Training loss: 3.4268984913860043
Validation loss: 2.845912901434543

Epoch: 5| Step: 7
Training loss: 2.8762075127452245
Validation loss: 2.8433117714226768

Epoch: 5| Step: 8
Training loss: 2.9602566945403233
Validation loss: 2.8418302306761327

Epoch: 5| Step: 9
Training loss: 3.783540142529459
Validation loss: 2.840370058248682

Epoch: 5| Step: 10
Training loss: 3.179232778065945
Validation loss: 2.843127249532644

Epoch: 214| Step: 0
Training loss: 3.15530502223243
Validation loss: 2.8456867847686738

Epoch: 5| Step: 1
Training loss: 3.452273578884552
Validation loss: 2.8451807262727007

Epoch: 5| Step: 2
Training loss: 3.065592236202818
Validation loss: 2.843414952210129

Epoch: 5| Step: 3
Training loss: 3.330861001267634
Validation loss: 2.84411468204911

Epoch: 5| Step: 4
Training loss: 3.1257863390556238
Validation loss: 2.845684273096172

Epoch: 5| Step: 5
Training loss: 2.9607178297059433
Validation loss: 2.8427195718968217

Epoch: 5| Step: 6
Training loss: 2.9625008112266493
Validation loss: 2.8423057178119637

Epoch: 5| Step: 7
Training loss: 3.2782391494644716
Validation loss: 2.8446620536493272

Epoch: 5| Step: 8
Training loss: 3.102236580804838
Validation loss: 2.8424334385215646

Epoch: 5| Step: 9
Training loss: 2.8718719050709316
Validation loss: 2.844559797711687

Epoch: 5| Step: 10
Training loss: 3.2268112123706216
Validation loss: 2.8475495109729017

Epoch: 215| Step: 0
Training loss: 3.368672974790516
Validation loss: 2.8514761747182615

Epoch: 5| Step: 1
Training loss: 3.0742676087584226
Validation loss: 2.852486567643981

Epoch: 5| Step: 2
Training loss: 2.7510662612672667
Validation loss: 2.855240972576086

Epoch: 5| Step: 3
Training loss: 3.599414640096744
Validation loss: 2.8547243621786675

Epoch: 5| Step: 4
Training loss: 3.082039140466373
Validation loss: 2.8450374364200157

Epoch: 5| Step: 5
Training loss: 2.490808278690889
Validation loss: 2.8490241273466306

Epoch: 5| Step: 6
Training loss: 3.3510783096948837
Validation loss: 2.847407292886516

Epoch: 5| Step: 7
Training loss: 3.276331821483864
Validation loss: 2.8465177347925827

Epoch: 5| Step: 8
Training loss: 3.1622628827972212
Validation loss: 2.8419001838577866

Epoch: 5| Step: 9
Training loss: 3.098586184598355
Validation loss: 2.8407088981487427

Epoch: 5| Step: 10
Training loss: 3.117269185078698
Validation loss: 2.8454563926538956

Epoch: 216| Step: 0
Training loss: 3.1016103130662067
Validation loss: 2.8394252558282727

Epoch: 5| Step: 1
Training loss: 3.025771075880939
Validation loss: 2.841111531492373

Epoch: 5| Step: 2
Training loss: 3.423436474854365
Validation loss: 2.839321995967631

Epoch: 5| Step: 3
Training loss: 3.0154607065936467
Validation loss: 2.8374616178976124

Epoch: 5| Step: 4
Training loss: 2.4443708562852406
Validation loss: 2.8392536325258897

Epoch: 5| Step: 5
Training loss: 2.9412642364870742
Validation loss: 2.838001647741886

Epoch: 5| Step: 6
Training loss: 3.276537899567134
Validation loss: 2.835894038853459

Epoch: 5| Step: 7
Training loss: 3.978768986241099
Validation loss: 2.8394616305460616

Epoch: 5| Step: 8
Training loss: 3.120719724929251
Validation loss: 2.8360543103389415

Epoch: 5| Step: 9
Training loss: 2.504438846498762
Validation loss: 2.835753947447208

Epoch: 5| Step: 10
Training loss: 3.401394384222306
Validation loss: 2.8342668441981953

Epoch: 217| Step: 0
Training loss: 3.0669010224840756
Validation loss: 2.8354605426181236

Epoch: 5| Step: 1
Training loss: 3.2617088089294617
Validation loss: 2.8371316801296094

Epoch: 5| Step: 2
Training loss: 3.5282008417186788
Validation loss: 2.8382465478198213

Epoch: 5| Step: 3
Training loss: 3.168589125542911
Validation loss: 2.8394080993821125

Epoch: 5| Step: 4
Training loss: 2.26784927100756
Validation loss: 2.8410100564475878

Epoch: 5| Step: 5
Training loss: 2.9350608276094685
Validation loss: 2.8354570861058654

Epoch: 5| Step: 6
Training loss: 3.269500622896426
Validation loss: 2.8456125849923826

Epoch: 5| Step: 7
Training loss: 3.3774530891193235
Validation loss: 2.8410881085266797

Epoch: 5| Step: 8
Training loss: 3.1055284794275586
Validation loss: 2.8386416904287017

Epoch: 5| Step: 9
Training loss: 3.2372686001476545
Validation loss: 2.8425125734706618

Epoch: 5| Step: 10
Training loss: 3.0504956765049656
Validation loss: 2.847569059957551

Epoch: 218| Step: 0
Training loss: 2.372207103693976
Validation loss: 2.843704028086472

Epoch: 5| Step: 1
Training loss: 3.132707779577687
Validation loss: 2.845628543666138

Epoch: 5| Step: 2
Training loss: 3.2025851655426294
Validation loss: 2.8414429514451194

Epoch: 5| Step: 3
Training loss: 3.159249570565943
Validation loss: 2.8418342784363455

Epoch: 5| Step: 4
Training loss: 3.2701949126222627
Validation loss: 2.84039523089134

Epoch: 5| Step: 5
Training loss: 3.315324119269201
Validation loss: 2.841669576759666

Epoch: 5| Step: 6
Training loss: 2.916125674256698
Validation loss: 2.839719530254911

Epoch: 5| Step: 7
Training loss: 3.369277199451052
Validation loss: 2.839163647135289

Epoch: 5| Step: 8
Training loss: 3.3320572953810608
Validation loss: 2.834883978248999

Epoch: 5| Step: 9
Training loss: 2.9846469295900855
Validation loss: 2.832087647099628

Epoch: 5| Step: 10
Training loss: 3.2805010712919387
Validation loss: 2.8351112408876196

Epoch: 219| Step: 0
Training loss: 3.485892337521907
Validation loss: 2.832052814315263

Epoch: 5| Step: 1
Training loss: 2.9195736884793537
Validation loss: 2.8368289904184714

Epoch: 5| Step: 2
Training loss: 2.5713832677150372
Validation loss: 2.8325148479391564

Epoch: 5| Step: 3
Training loss: 3.175785003697428
Validation loss: 2.8343791856131215

Epoch: 5| Step: 4
Training loss: 3.2212954335677915
Validation loss: 2.8379179985228546

Epoch: 5| Step: 5
Training loss: 3.34857471378952
Validation loss: 2.8435571139266647

Epoch: 5| Step: 6
Training loss: 3.2369881361542734
Validation loss: 2.8386208797050707

Epoch: 5| Step: 7
Training loss: 2.2821545832345724
Validation loss: 2.8391224034048306

Epoch: 5| Step: 8
Training loss: 3.8672733181765766
Validation loss: 2.8306574216304323

Epoch: 5| Step: 9
Training loss: 3.29529797771034
Validation loss: 2.829334568508131

Epoch: 5| Step: 10
Training loss: 2.610566649475504
Validation loss: 2.831457335552014

Epoch: 220| Step: 0
Training loss: 2.6335119569129297
Validation loss: 2.8324209683013626

Epoch: 5| Step: 1
Training loss: 3.290981140861618
Validation loss: 2.8284942761149097

Epoch: 5| Step: 2
Training loss: 3.4896091441248496
Validation loss: 2.8282514321908154

Epoch: 5| Step: 3
Training loss: 2.7024611170509676
Validation loss: 2.8292679499442053

Epoch: 5| Step: 4
Training loss: 2.7573025585882243
Validation loss: 2.8280402482266496

Epoch: 5| Step: 5
Training loss: 3.3512329793211113
Validation loss: 2.8280622454601616

Epoch: 5| Step: 6
Training loss: 3.1615215129708574
Validation loss: 2.8289316862847

Epoch: 5| Step: 7
Training loss: 3.4815977515276493
Validation loss: 2.8264727681853503

Epoch: 5| Step: 8
Training loss: 3.2233341498178305
Validation loss: 2.829927621329894

Epoch: 5| Step: 9
Training loss: 3.2322693388292
Validation loss: 2.826702707776378

Epoch: 5| Step: 10
Training loss: 2.919326731781582
Validation loss: 2.8270268918753234

Epoch: 221| Step: 0
Training loss: 2.863440286713472
Validation loss: 2.827705103300437

Epoch: 5| Step: 1
Training loss: 3.381809852492888
Validation loss: 2.8293969015927845

Epoch: 5| Step: 2
Training loss: 3.337789195814835
Validation loss: 2.8293173345641733

Epoch: 5| Step: 3
Training loss: 2.9422149154512174
Validation loss: 2.831982953738633

Epoch: 5| Step: 4
Training loss: 2.9063837164194046
Validation loss: 2.8316421951028103

Epoch: 5| Step: 5
Training loss: 3.2054969007244725
Validation loss: 2.8328726162887574

Epoch: 5| Step: 6
Training loss: 2.998121786268912
Validation loss: 2.8298091701888883

Epoch: 5| Step: 7
Training loss: 3.231686566668486
Validation loss: 2.8422463295650244

Epoch: 5| Step: 8
Training loss: 3.0669901103683346
Validation loss: 2.842142984580739

Epoch: 5| Step: 9
Training loss: 3.5253183965073185
Validation loss: 2.8358964145574435

Epoch: 5| Step: 10
Training loss: 2.7875891461679307
Validation loss: 2.837476873418777

Epoch: 222| Step: 0
Training loss: 2.9537226965211776
Validation loss: 2.8402784293895467

Epoch: 5| Step: 1
Training loss: 2.6424253748061983
Validation loss: 2.8381754640185566

Epoch: 5| Step: 2
Training loss: 2.5484733948556553
Validation loss: 2.8273522102966937

Epoch: 5| Step: 3
Training loss: 3.5804458487583797
Validation loss: 2.8252671901921085

Epoch: 5| Step: 4
Training loss: 2.9741750839711414
Validation loss: 2.825582467855753

Epoch: 5| Step: 5
Training loss: 3.244470440602196
Validation loss: 2.828412948867425

Epoch: 5| Step: 6
Training loss: 3.1692481979192872
Validation loss: 2.829072677348913

Epoch: 5| Step: 7
Training loss: 2.7890100126910826
Validation loss: 2.8284675183599197

Epoch: 5| Step: 8
Training loss: 3.1526768164543584
Validation loss: 2.8342724919925137

Epoch: 5| Step: 9
Training loss: 3.3780570137176853
Validation loss: 2.8353482928736904

Epoch: 5| Step: 10
Training loss: 3.903534700806487
Validation loss: 2.832364510859552

Epoch: 223| Step: 0
Training loss: 3.1503437036377164
Validation loss: 2.83160853381413

Epoch: 5| Step: 1
Training loss: 2.883860658557142
Validation loss: 2.8286484423315033

Epoch: 5| Step: 2
Training loss: 3.5735162763832045
Validation loss: 2.8280207256065855

Epoch: 5| Step: 3
Training loss: 3.059440797559975
Validation loss: 2.8276939736694375

Epoch: 5| Step: 4
Training loss: 3.1487234283937395
Validation loss: 2.8257654599731103

Epoch: 5| Step: 5
Training loss: 3.105536463736998
Validation loss: 2.8248203305030604

Epoch: 5| Step: 6
Training loss: 3.122111702347242
Validation loss: 2.825311317499631

Epoch: 5| Step: 7
Training loss: 3.0084513196412814
Validation loss: 2.8259867846161355

Epoch: 5| Step: 8
Training loss: 2.931528880958709
Validation loss: 2.8250586480113

Epoch: 5| Step: 9
Training loss: 3.37808228076669
Validation loss: 2.8258062127916235

Epoch: 5| Step: 10
Training loss: 2.919508031395999
Validation loss: 2.824766578145582

Epoch: 224| Step: 0
Training loss: 2.5168994021221494
Validation loss: 2.8276228503400707

Epoch: 5| Step: 1
Training loss: 3.228320513377996
Validation loss: 2.833583329142275

Epoch: 5| Step: 2
Training loss: 3.413464386877853
Validation loss: 2.8447851230601966

Epoch: 5| Step: 3
Training loss: 2.955204468703183
Validation loss: 2.860472270179358

Epoch: 5| Step: 4
Training loss: 2.506414671551342
Validation loss: 2.848368730136152

Epoch: 5| Step: 5
Training loss: 3.1650958599019026
Validation loss: 2.8303735360980937

Epoch: 5| Step: 6
Training loss: 3.1342438355648667
Validation loss: 2.827648384880097

Epoch: 5| Step: 7
Training loss: 3.635729859131663
Validation loss: 2.820783784633257

Epoch: 5| Step: 8
Training loss: 4.1221837920813575
Validation loss: 2.8202707796996647

Epoch: 5| Step: 9
Training loss: 2.5945166867980887
Validation loss: 2.822900558103022

Epoch: 5| Step: 10
Training loss: 2.713534032380146
Validation loss: 2.8260224432932666

Epoch: 225| Step: 0
Training loss: 2.798982135504449
Validation loss: 2.8242883156416534

Epoch: 5| Step: 1
Training loss: 3.2035583202994853
Validation loss: 2.824961407879074

Epoch: 5| Step: 2
Training loss: 2.560477132887691
Validation loss: 2.8213447656709034

Epoch: 5| Step: 3
Training loss: 3.3555575659902357
Validation loss: 2.8237130122139638

Epoch: 5| Step: 4
Training loss: 3.482115693038793
Validation loss: 2.821519906096385

Epoch: 5| Step: 5
Training loss: 3.1489672345334174
Validation loss: 2.8260728207948476

Epoch: 5| Step: 6
Training loss: 3.3850173636460212
Validation loss: 2.8228102230574423

Epoch: 5| Step: 7
Training loss: 3.072171412901074
Validation loss: 2.8229083982229333

Epoch: 5| Step: 8
Training loss: 2.9997447223135256
Validation loss: 2.8223213960979208

Epoch: 5| Step: 9
Training loss: 3.136213706130764
Validation loss: 2.823277563029101

Epoch: 5| Step: 10
Training loss: 3.09507245399577
Validation loss: 2.8255675092213766

Epoch: 226| Step: 0
Training loss: 2.6875948334751127
Validation loss: 2.8307825987161506

Epoch: 5| Step: 1
Training loss: 2.882918358490013
Validation loss: 2.8296289627865043

Epoch: 5| Step: 2
Training loss: 3.0022317214779144
Validation loss: 2.8338414517133548

Epoch: 5| Step: 3
Training loss: 3.019447078740728
Validation loss: 2.8316520399129557

Epoch: 5| Step: 4
Training loss: 3.0704165530833505
Validation loss: 2.828881262727087

Epoch: 5| Step: 5
Training loss: 3.138167145458781
Validation loss: 2.834290714283547

Epoch: 5| Step: 6
Training loss: 3.347246712524249
Validation loss: 2.8449969446591994

Epoch: 5| Step: 7
Training loss: 3.819321579931784
Validation loss: 2.8491557444073328

Epoch: 5| Step: 8
Training loss: 3.1485806188877
Validation loss: 2.8323640374797456

Epoch: 5| Step: 9
Training loss: 3.3737804893990084
Validation loss: 2.8338096430621595

Epoch: 5| Step: 10
Training loss: 2.5894911397991196
Validation loss: 2.825276068156166

Epoch: 227| Step: 0
Training loss: 3.0711786732447144
Validation loss: 2.8185629009476556

Epoch: 5| Step: 1
Training loss: 3.426544208886572
Validation loss: 2.8175455682155977

Epoch: 5| Step: 2
Training loss: 2.851363836187581
Validation loss: 2.817061322543437

Epoch: 5| Step: 3
Training loss: 2.959076228462946
Validation loss: 2.8182316685074333

Epoch: 5| Step: 4
Training loss: 2.6987288343722433
Validation loss: 2.8161489025982807

Epoch: 5| Step: 5
Training loss: 3.931207988375045
Validation loss: 2.8212340615591183

Epoch: 5| Step: 6
Training loss: 3.112411932867492
Validation loss: 2.8180754004722615

Epoch: 5| Step: 7
Training loss: 2.96754447151676
Validation loss: 2.8180423785961843

Epoch: 5| Step: 8
Training loss: 3.519786761934209
Validation loss: 2.817975473063995

Epoch: 5| Step: 9
Training loss: 2.5342369822822297
Validation loss: 2.8163168799983915

Epoch: 5| Step: 10
Training loss: 2.9422197774695733
Validation loss: 2.819857302036906

Epoch: 228| Step: 0
Training loss: 3.412157448144463
Validation loss: 2.825175723034568

Epoch: 5| Step: 1
Training loss: 2.47663643422763
Validation loss: 2.8249933061766352

Epoch: 5| Step: 2
Training loss: 3.103637616092827
Validation loss: 2.827124042828319

Epoch: 5| Step: 3
Training loss: 3.2191585540735095
Validation loss: 2.831203022359097

Epoch: 5| Step: 4
Training loss: 3.3671689486601055
Validation loss: 2.826504224950389

Epoch: 5| Step: 5
Training loss: 2.7876626997879974
Validation loss: 2.828584548361494

Epoch: 5| Step: 6
Training loss: 3.111165513592343
Validation loss: 2.8203245295704162

Epoch: 5| Step: 7
Training loss: 3.3750115853569964
Validation loss: 2.8205085745094025

Epoch: 5| Step: 8
Training loss: 2.1914128866112184
Validation loss: 2.8168458048161864

Epoch: 5| Step: 9
Training loss: 3.75770616281783
Validation loss: 2.8152002778059084

Epoch: 5| Step: 10
Training loss: 3.180733323624158
Validation loss: 2.8185915081559796

Epoch: 229| Step: 0
Training loss: 2.685696462453238
Validation loss: 2.812490841065583

Epoch: 5| Step: 1
Training loss: 3.3623865158046655
Validation loss: 2.8162136358196763

Epoch: 5| Step: 2
Training loss: 2.703121030947908
Validation loss: 2.819212858353269

Epoch: 5| Step: 3
Training loss: 3.366052422970351
Validation loss: 2.8153761319241863

Epoch: 5| Step: 4
Training loss: 3.305530918432009
Validation loss: 2.8159798054125416

Epoch: 5| Step: 5
Training loss: 2.642935921072993
Validation loss: 2.8162577302076186

Epoch: 5| Step: 6
Training loss: 3.671000145114365
Validation loss: 2.8166085663616323

Epoch: 5| Step: 7
Training loss: 2.746950279133034
Validation loss: 2.81249506869049

Epoch: 5| Step: 8
Training loss: 3.280259046327095
Validation loss: 2.8149144700303443

Epoch: 5| Step: 9
Training loss: 3.0164272051727763
Validation loss: 2.811324961774724

Epoch: 5| Step: 10
Training loss: 3.3206012914390284
Validation loss: 2.8161985099902105

Epoch: 230| Step: 0
Training loss: 3.3732224481122266
Validation loss: 2.8159238140330656

Epoch: 5| Step: 1
Training loss: 3.2455400529481264
Validation loss: 2.815007255986504

Epoch: 5| Step: 2
Training loss: 3.4537090653359033
Validation loss: 2.8141479121744846

Epoch: 5| Step: 3
Training loss: 2.8264429137752494
Validation loss: 2.8194214392077317

Epoch: 5| Step: 4
Training loss: 2.7573150099594983
Validation loss: 2.8200163495013033

Epoch: 5| Step: 5
Training loss: 3.397921117377782
Validation loss: 2.8192648924840853

Epoch: 5| Step: 6
Training loss: 3.4388775926143205
Validation loss: 2.8151391375243264

Epoch: 5| Step: 7
Training loss: 3.1622342325951878
Validation loss: 2.8167168191982417

Epoch: 5| Step: 8
Training loss: 2.7346726609748204
Validation loss: 2.819513139410359

Epoch: 5| Step: 9
Training loss: 2.5310085793737493
Validation loss: 2.819006851164857

Epoch: 5| Step: 10
Training loss: 3.143369016825728
Validation loss: 2.8170056875620535

Epoch: 231| Step: 0
Training loss: 2.9868438255469614
Validation loss: 2.8179920822394817

Epoch: 5| Step: 1
Training loss: 2.8318881294655016
Validation loss: 2.816828020292902

Epoch: 5| Step: 2
Training loss: 2.9769051422188517
Validation loss: 2.8134254327652153

Epoch: 5| Step: 3
Training loss: 3.17297945384176
Validation loss: 2.812141545103114

Epoch: 5| Step: 4
Training loss: 2.8879216930731113
Validation loss: 2.8143846220375712

Epoch: 5| Step: 5
Training loss: 3.0254686418180756
Validation loss: 2.8104272768060907

Epoch: 5| Step: 6
Training loss: 3.059512335370728
Validation loss: 2.8086178492310374

Epoch: 5| Step: 7
Training loss: 3.425998102369078
Validation loss: 2.812802004807493

Epoch: 5| Step: 8
Training loss: 2.8453135122248163
Validation loss: 2.8210137885282927

Epoch: 5| Step: 9
Training loss: 3.755721495860386
Validation loss: 2.8187490190542883

Epoch: 5| Step: 10
Training loss: 3.1405867389227233
Validation loss: 2.8278887576452956

Epoch: 232| Step: 0
Training loss: 3.10762396346521
Validation loss: 2.8161833030606247

Epoch: 5| Step: 1
Training loss: 3.557235039650787
Validation loss: 2.819724061015806

Epoch: 5| Step: 2
Training loss: 2.920896641747609
Validation loss: 2.810830760998765

Epoch: 5| Step: 3
Training loss: 2.8497864091041363
Validation loss: 2.8165572040382223

Epoch: 5| Step: 4
Training loss: 2.656926147571645
Validation loss: 2.8197961499957276

Epoch: 5| Step: 5
Training loss: 2.9976870839688314
Validation loss: 2.814335321535906

Epoch: 5| Step: 6
Training loss: 3.2715364093343204
Validation loss: 2.8134901156603416

Epoch: 5| Step: 7
Training loss: 3.149199211421496
Validation loss: 2.8086902132272162

Epoch: 5| Step: 8
Training loss: 3.346558291768951
Validation loss: 2.8151727972171705

Epoch: 5| Step: 9
Training loss: 3.5301312049926543
Validation loss: 2.8087154580383786

Epoch: 5| Step: 10
Training loss: 2.5381203179784753
Validation loss: 2.8091506521120073

Epoch: 233| Step: 0
Training loss: 2.851178872418287
Validation loss: 2.8104276051940844

Epoch: 5| Step: 1
Training loss: 2.9483613845873737
Validation loss: 2.8025015321340447

Epoch: 5| Step: 2
Training loss: 3.2871421590202634
Validation loss: 2.8074348177753383

Epoch: 5| Step: 3
Training loss: 3.5352358308549574
Validation loss: 2.8076020345328

Epoch: 5| Step: 4
Training loss: 2.555935802596742
Validation loss: 2.8084750544817503

Epoch: 5| Step: 5
Training loss: 3.521413420492877
Validation loss: 2.806036773224684

Epoch: 5| Step: 6
Training loss: 3.4606821900310276
Validation loss: 2.8086120348381125

Epoch: 5| Step: 7
Training loss: 3.195977699039652
Validation loss: 2.8069633998021333

Epoch: 5| Step: 8
Training loss: 3.1230042760638335
Validation loss: 2.8070580166860006

Epoch: 5| Step: 9
Training loss: 2.7192188604054865
Validation loss: 2.8046772689557318

Epoch: 5| Step: 10
Training loss: 2.8366896627579568
Validation loss: 2.8104696613448716

Epoch: 234| Step: 0
Training loss: 3.080311884261282
Validation loss: 2.807474442301023

Epoch: 5| Step: 1
Training loss: 3.1924683987361115
Validation loss: 2.814067240749165

Epoch: 5| Step: 2
Training loss: 3.276325126639482
Validation loss: 2.8094120022878593

Epoch: 5| Step: 3
Training loss: 3.628450790090503
Validation loss: 2.811745354372739

Epoch: 5| Step: 4
Training loss: 2.9525386490581504
Validation loss: 2.807692932847758

Epoch: 5| Step: 5
Training loss: 3.5669011820287926
Validation loss: 2.8084414906921626

Epoch: 5| Step: 6
Training loss: 2.723632112204105
Validation loss: 2.8068193499549006

Epoch: 5| Step: 7
Training loss: 3.071762247432007
Validation loss: 2.811159929900602

Epoch: 5| Step: 8
Training loss: 2.5043761099652735
Validation loss: 2.816608384324217

Epoch: 5| Step: 9
Training loss: 2.4959159871353136
Validation loss: 2.814475932534867

Epoch: 5| Step: 10
Training loss: 3.503101745582732
Validation loss: 2.808276674605801

Epoch: 235| Step: 0
Training loss: 3.0052249231437043
Validation loss: 2.8123391364067354

Epoch: 5| Step: 1
Training loss: 2.299687745832577
Validation loss: 2.8037870014199546

Epoch: 5| Step: 2
Training loss: 3.176065167150052
Validation loss: 2.8065055653510154

Epoch: 5| Step: 3
Training loss: 2.9968230592047225
Validation loss: 2.8025641180789544

Epoch: 5| Step: 4
Training loss: 2.5689781922943857
Validation loss: 2.8032354080169055

Epoch: 5| Step: 5
Training loss: 3.685566670132651
Validation loss: 2.80455524124626

Epoch: 5| Step: 6
Training loss: 2.852138011808566
Validation loss: 2.806134670060186

Epoch: 5| Step: 7
Training loss: 3.098583722379424
Validation loss: 2.805380413058113

Epoch: 5| Step: 8
Training loss: 3.732215160991468
Validation loss: 2.8003839262545784

Epoch: 5| Step: 9
Training loss: 3.409558430605263
Validation loss: 2.803440918972721

Epoch: 5| Step: 10
Training loss: 3.0503699969389118
Validation loss: 2.8029243484033004

Epoch: 236| Step: 0
Training loss: 2.5211865096261326
Validation loss: 2.807334120767283

Epoch: 5| Step: 1
Training loss: 3.368495748971615
Validation loss: 2.8008099436350276

Epoch: 5| Step: 2
Training loss: 3.3771443089497493
Validation loss: 2.801985711552063

Epoch: 5| Step: 3
Training loss: 2.958109206901607
Validation loss: 2.805976826571431

Epoch: 5| Step: 4
Training loss: 3.2149253269381055
Validation loss: 2.8096837992230923

Epoch: 5| Step: 5
Training loss: 2.7586086085893555
Validation loss: 2.8095161798644166

Epoch: 5| Step: 6
Training loss: 3.2934442541102227
Validation loss: 2.813401165133641

Epoch: 5| Step: 7
Training loss: 3.0104288983124037
Validation loss: 2.8051839601557833

Epoch: 5| Step: 8
Training loss: 3.0730608028078303
Validation loss: 2.802543567269318

Epoch: 5| Step: 9
Training loss: 3.4579973325702533
Validation loss: 2.804200757830318

Epoch: 5| Step: 10
Training loss: 2.9842022750961377
Validation loss: 2.804605915684713

Epoch: 237| Step: 0
Training loss: 2.9770223908074076
Validation loss: 2.8016573826971785

Epoch: 5| Step: 1
Training loss: 3.152675757715749
Validation loss: 2.800786513145704

Epoch: 5| Step: 2
Training loss: 2.325742180611133
Validation loss: 2.797739937946209

Epoch: 5| Step: 3
Training loss: 3.3515135576991786
Validation loss: 2.8011458536837304

Epoch: 5| Step: 4
Training loss: 3.368347676161842
Validation loss: 2.800593170717377

Epoch: 5| Step: 5
Training loss: 2.577410234725238
Validation loss: 2.7994180075205106

Epoch: 5| Step: 6
Training loss: 3.8098302780355615
Validation loss: 2.800980406947088

Epoch: 5| Step: 7
Training loss: 2.4697207703075614
Validation loss: 2.8057885199326638

Epoch: 5| Step: 8
Training loss: 3.021654495352211
Validation loss: 2.80034073175262

Epoch: 5| Step: 9
Training loss: 3.4630215744329105
Validation loss: 2.7994570513703354

Epoch: 5| Step: 10
Training loss: 3.3172318831577305
Validation loss: 2.8000394594251117

Epoch: 238| Step: 0
Training loss: 3.3692327602891092
Validation loss: 2.803619157527305

Epoch: 5| Step: 1
Training loss: 3.017606252397227
Validation loss: 2.799580086074027

Epoch: 5| Step: 2
Training loss: 2.7097000683842865
Validation loss: 2.7997254606947233

Epoch: 5| Step: 3
Training loss: 3.4043750327194156
Validation loss: 2.798713417646046

Epoch: 5| Step: 4
Training loss: 2.8530503663311424
Validation loss: 2.7993280310541007

Epoch: 5| Step: 5
Training loss: 3.3555147925027953
Validation loss: 2.796031412897314

Epoch: 5| Step: 6
Training loss: 2.5420660007471367
Validation loss: 2.801254058868775

Epoch: 5| Step: 7
Training loss: 3.415145597467888
Validation loss: 2.8004285582560566

Epoch: 5| Step: 8
Training loss: 2.8473807830905886
Validation loss: 2.7957373660117213

Epoch: 5| Step: 9
Training loss: 3.6324684554408657
Validation loss: 2.797184183521605

Epoch: 5| Step: 10
Training loss: 2.6647576015373655
Validation loss: 2.7995497644808554

Epoch: 239| Step: 0
Training loss: 3.213366701050461
Validation loss: 2.8009283571469936

Epoch: 5| Step: 1
Training loss: 3.0361472614443903
Validation loss: 2.7988589307099283

Epoch: 5| Step: 2
Training loss: 3.4884635988698016
Validation loss: 2.7984715557412034

Epoch: 5| Step: 3
Training loss: 2.2264605582474712
Validation loss: 2.806316316719359

Epoch: 5| Step: 4
Training loss: 3.004912169532821
Validation loss: 2.8062329818874994

Epoch: 5| Step: 5
Training loss: 3.6928431706455394
Validation loss: 2.804942519090841

Epoch: 5| Step: 6
Training loss: 3.3296863314243024
Validation loss: 2.809317722936885

Epoch: 5| Step: 7
Training loss: 2.297238898482624
Validation loss: 2.808195068581889

Epoch: 5| Step: 8
Training loss: 2.688800763121397
Validation loss: 2.8078027802876604

Epoch: 5| Step: 9
Training loss: 3.356986682818841
Validation loss: 2.8004822010368167

Epoch: 5| Step: 10
Training loss: 3.4292509109574842
Validation loss: 2.797588516546512

Epoch: 240| Step: 0
Training loss: 3.261028797021339
Validation loss: 2.7953745725016343

Epoch: 5| Step: 1
Training loss: 3.026038182443177
Validation loss: 2.7989895068100408

Epoch: 5| Step: 2
Training loss: 2.9124889062498283
Validation loss: 2.7965900649291022

Epoch: 5| Step: 3
Training loss: 3.404311582234797
Validation loss: 2.8012657657763937

Epoch: 5| Step: 4
Training loss: 2.9368382784018476
Validation loss: 2.7961248456353287

Epoch: 5| Step: 5
Training loss: 2.9116705110288357
Validation loss: 2.797143588354751

Epoch: 5| Step: 6
Training loss: 3.0976642546003132
Validation loss: 2.797253092131699

Epoch: 5| Step: 7
Training loss: 3.4921571871062747
Validation loss: 2.7983883848888023

Epoch: 5| Step: 8
Training loss: 3.2409158074055116
Validation loss: 2.796645031694178

Epoch: 5| Step: 9
Training loss: 2.9891546032799257
Validation loss: 2.8028086616967536

Epoch: 5| Step: 10
Training loss: 2.6369373824287328
Validation loss: 2.794301132696766

Epoch: 241| Step: 0
Training loss: 3.472927293187211
Validation loss: 2.8004207751248256

Epoch: 5| Step: 1
Training loss: 3.110978829508315
Validation loss: 2.8008234628960853

Epoch: 5| Step: 2
Training loss: 2.9363534191199703
Validation loss: 2.805627680889415

Epoch: 5| Step: 3
Training loss: 2.8001026305054473
Validation loss: 2.8065135855498333

Epoch: 5| Step: 4
Training loss: 2.9181836315939127
Validation loss: 2.795811671737686

Epoch: 5| Step: 5
Training loss: 3.6163736503023403
Validation loss: 2.80445066913403

Epoch: 5| Step: 6
Training loss: 2.863699056371222
Validation loss: 2.798955126757649

Epoch: 5| Step: 7
Training loss: 3.2653906341121224
Validation loss: 2.800841382910132

Epoch: 5| Step: 8
Training loss: 2.4622809724171786
Validation loss: 2.800667907816895

Epoch: 5| Step: 9
Training loss: 3.3514384355679794
Validation loss: 2.8065918223918214

Epoch: 5| Step: 10
Training loss: 3.054413063619262
Validation loss: 2.809695938169598

Epoch: 242| Step: 0
Training loss: 2.8754449582961796
Validation loss: 2.8139834977321074

Epoch: 5| Step: 1
Training loss: 3.2703926291675707
Validation loss: 2.7953775017204876

Epoch: 5| Step: 2
Training loss: 3.4957437521210224
Validation loss: 2.793112174115713

Epoch: 5| Step: 3
Training loss: 2.957650405786925
Validation loss: 2.7914208827568783

Epoch: 5| Step: 4
Training loss: 3.3667481881522945
Validation loss: 2.791871233408807

Epoch: 5| Step: 5
Training loss: 3.1102376536736065
Validation loss: 2.7893114919542423

Epoch: 5| Step: 6
Training loss: 2.444130023569335
Validation loss: 2.7902055135853003

Epoch: 5| Step: 7
Training loss: 3.1934856984762074
Validation loss: 2.790601466210261

Epoch: 5| Step: 8
Training loss: 2.893633951780946
Validation loss: 2.7897661474546265

Epoch: 5| Step: 9
Training loss: 3.067171698600965
Validation loss: 2.7911458603308277

Epoch: 5| Step: 10
Training loss: 3.3048124537731725
Validation loss: 2.7884292000731175

Epoch: 243| Step: 0
Training loss: 2.7995519347676736
Validation loss: 2.7891694818172423

Epoch: 5| Step: 1
Training loss: 3.416721172983475
Validation loss: 2.7923002361299085

Epoch: 5| Step: 2
Training loss: 2.6768317395049497
Validation loss: 2.791610102538853

Epoch: 5| Step: 3
Training loss: 3.204579985854962
Validation loss: 2.7912450578258774

Epoch: 5| Step: 4
Training loss: 2.6031810777355124
Validation loss: 2.7964446969119865

Epoch: 5| Step: 5
Training loss: 3.6325474796224517
Validation loss: 2.801991379581564

Epoch: 5| Step: 6
Training loss: 3.1164531559831765
Validation loss: 2.800066422921267

Epoch: 5| Step: 7
Training loss: 2.8610239746091914
Validation loss: 2.7956728216598123

Epoch: 5| Step: 8
Training loss: 3.2500713047128325
Validation loss: 2.799368322552791

Epoch: 5| Step: 9
Training loss: 3.1172814223593166
Validation loss: 2.792765478413994

Epoch: 5| Step: 10
Training loss: 3.23574387336227
Validation loss: 2.7929106193635467

Epoch: 244| Step: 0
Training loss: 2.9280741000153436
Validation loss: 2.788432653281922

Epoch: 5| Step: 1
Training loss: 3.691199822683872
Validation loss: 2.7854281174291544

Epoch: 5| Step: 2
Training loss: 2.574494643759402
Validation loss: 2.7832565673809357

Epoch: 5| Step: 3
Training loss: 3.722311158011332
Validation loss: 2.7901055665762384

Epoch: 5| Step: 4
Training loss: 3.6624355323507727
Validation loss: 2.7860358636254428

Epoch: 5| Step: 5
Training loss: 2.867911348779032
Validation loss: 2.787179018347104

Epoch: 5| Step: 6
Training loss: 2.2109573417285464
Validation loss: 2.7891422282278286

Epoch: 5| Step: 7
Training loss: 3.145483860705145
Validation loss: 2.788238757628482

Epoch: 5| Step: 8
Training loss: 2.4409641201221857
Validation loss: 2.7861159269044347

Epoch: 5| Step: 9
Training loss: 2.8601681802558647
Validation loss: 2.7878286867519098

Epoch: 5| Step: 10
Training loss: 3.523670941589474
Validation loss: 2.784670550647343

Epoch: 245| Step: 0
Training loss: 2.6900123563291247
Validation loss: 2.788684439153028

Epoch: 5| Step: 1
Training loss: 3.4473123779584562
Validation loss: 2.788235563464193

Epoch: 5| Step: 2
Training loss: 3.748619715661225
Validation loss: 2.7886743433702184

Epoch: 5| Step: 3
Training loss: 3.2006410969837997
Validation loss: 2.787069120600102

Epoch: 5| Step: 4
Training loss: 2.725367155626025
Validation loss: 2.789171578377573

Epoch: 5| Step: 5
Training loss: 3.0994139948070916
Validation loss: 2.7903223916766846

Epoch: 5| Step: 6
Training loss: 3.1275833133422637
Validation loss: 2.7859563970966743

Epoch: 5| Step: 7
Training loss: 3.2264754535303513
Validation loss: 2.7874942317244282

Epoch: 5| Step: 8
Training loss: 2.47408307748139
Validation loss: 2.8010575179163744

Epoch: 5| Step: 9
Training loss: 3.033266949887897
Validation loss: 2.7944087781646765

Epoch: 5| Step: 10
Training loss: 2.9715379975155476
Validation loss: 2.804202105381979

Epoch: 246| Step: 0
Training loss: 3.2601383240730515
Validation loss: 2.812121797242793

Epoch: 5| Step: 1
Training loss: 3.1564037927606954
Validation loss: 2.8117434816143785

Epoch: 5| Step: 2
Training loss: 3.02686251845495
Validation loss: 2.8029292444171165

Epoch: 5| Step: 3
Training loss: 3.2428520532691727
Validation loss: 2.8025839149907603

Epoch: 5| Step: 4
Training loss: 3.427913684991279
Validation loss: 2.79740036923483

Epoch: 5| Step: 5
Training loss: 3.14124940956435
Validation loss: 2.7937288383201255

Epoch: 5| Step: 6
Training loss: 3.1460421326587262
Validation loss: 2.788824787156849

Epoch: 5| Step: 7
Training loss: 3.1607801201147168
Validation loss: 2.785140743792631

Epoch: 5| Step: 8
Training loss: 3.028682447208329
Validation loss: 2.7830375622430896

Epoch: 5| Step: 9
Training loss: 2.3296120010310517
Validation loss: 2.7838633980215186

Epoch: 5| Step: 10
Training loss: 2.9210012832946988
Validation loss: 2.782462711634051

Epoch: 247| Step: 0
Training loss: 2.8663588321617923
Validation loss: 2.780658318397078

Epoch: 5| Step: 1
Training loss: 3.7748026461518513
Validation loss: 2.7825988921912588

Epoch: 5| Step: 2
Training loss: 3.436236478765757
Validation loss: 2.781149408526888

Epoch: 5| Step: 3
Training loss: 2.357967133504101
Validation loss: 2.778420547818823

Epoch: 5| Step: 4
Training loss: 2.7679346645064293
Validation loss: 2.7810960888144263

Epoch: 5| Step: 5
Training loss: 3.130127781462554
Validation loss: 2.7795305217352957

Epoch: 5| Step: 6
Training loss: 3.304151270583186
Validation loss: 2.780445985997339

Epoch: 5| Step: 7
Training loss: 3.2449102895412087
Validation loss: 2.7803606060959614

Epoch: 5| Step: 8
Training loss: 3.0467695169040505
Validation loss: 2.7816265699749567

Epoch: 5| Step: 9
Training loss: 2.796332962108258
Validation loss: 2.778094441060222

Epoch: 5| Step: 10
Training loss: 3.029557847096069
Validation loss: 2.7827683024176735

Epoch: 248| Step: 0
Training loss: 2.667988767311437
Validation loss: 2.78072022787901

Epoch: 5| Step: 1
Training loss: 2.9735090157933595
Validation loss: 2.786239360262951

Epoch: 5| Step: 2
Training loss: 3.082151461385441
Validation loss: 2.7895801303177357

Epoch: 5| Step: 3
Training loss: 3.210660825072431
Validation loss: 2.7996352889914786

Epoch: 5| Step: 4
Training loss: 3.527858354410877
Validation loss: 2.804302597633707

Epoch: 5| Step: 5
Training loss: 2.7923164939862906
Validation loss: 2.8032229978281893

Epoch: 5| Step: 6
Training loss: 3.2674155551123336
Validation loss: 2.7892940621931523

Epoch: 5| Step: 7
Training loss: 2.8520647834599995
Validation loss: 2.7855139337876578

Epoch: 5| Step: 8
Training loss: 3.122182873273928
Validation loss: 2.784848891403668

Epoch: 5| Step: 9
Training loss: 3.2408513636605325
Validation loss: 2.785533565649853

Epoch: 5| Step: 10
Training loss: 3.152447666880361
Validation loss: 2.783456684415315

Epoch: 249| Step: 0
Training loss: 3.100031169611602
Validation loss: 2.78758822926447

Epoch: 5| Step: 1
Training loss: 3.2613418452707266
Validation loss: 2.782832272743853

Epoch: 5| Step: 2
Training loss: 3.171767660495183
Validation loss: 2.7819433957545567

Epoch: 5| Step: 3
Training loss: 2.53916766609128
Validation loss: 2.7838617984297187

Epoch: 5| Step: 4
Training loss: 3.0716186540659405
Validation loss: 2.778562674602513

Epoch: 5| Step: 5
Training loss: 3.4954791162756695
Validation loss: 2.781623848389471

Epoch: 5| Step: 6
Training loss: 3.374451769347481
Validation loss: 2.7805939292665838

Epoch: 5| Step: 7
Training loss: 2.7782473697037173
Validation loss: 2.7796255319527585

Epoch: 5| Step: 8
Training loss: 3.0427910455372644
Validation loss: 2.776248595333823

Epoch: 5| Step: 9
Training loss: 3.074322050460278
Validation loss: 2.781993340317823

Epoch: 5| Step: 10
Training loss: 3.038492418966147
Validation loss: 2.7836472016798424

Epoch: 250| Step: 0
Training loss: 2.9263115314465664
Validation loss: 2.7858082941260633

Epoch: 5| Step: 1
Training loss: 3.789660094023587
Validation loss: 2.78825751706355

Epoch: 5| Step: 2
Training loss: 2.766826131736817
Validation loss: 2.801828155871508

Epoch: 5| Step: 3
Training loss: 3.1859548975164085
Validation loss: 2.797592949966042

Epoch: 5| Step: 4
Training loss: 2.685578391150299
Validation loss: 2.8104377560129206

Epoch: 5| Step: 5
Training loss: 2.4047975987146386
Validation loss: 2.8000560770264475

Epoch: 5| Step: 6
Training loss: 3.4310721207112467
Validation loss: 2.793559738544073

Epoch: 5| Step: 7
Training loss: 3.1162898939190327
Validation loss: 2.7897440908582927

Epoch: 5| Step: 8
Training loss: 3.1885595617547153
Validation loss: 2.783942469385862

Epoch: 5| Step: 9
Training loss: 3.1112373947065985
Validation loss: 2.7827068604455505

Epoch: 5| Step: 10
Training loss: 3.1383993128970036
Validation loss: 2.7778526684362945

Epoch: 251| Step: 0
Training loss: 3.033236295244821
Validation loss: 2.785358096198833

Epoch: 5| Step: 1
Training loss: 3.858105284595526
Validation loss: 2.7829444943264443

Epoch: 5| Step: 2
Training loss: 2.3789615718628982
Validation loss: 2.7737297064779294

Epoch: 5| Step: 3
Training loss: 3.4581164709524117
Validation loss: 2.7788705670437177

Epoch: 5| Step: 4
Training loss: 3.1298945434160035
Validation loss: 2.7755373035412734

Epoch: 5| Step: 5
Training loss: 2.8862043239833652
Validation loss: 2.7822057057430167

Epoch: 5| Step: 6
Training loss: 2.6050001921260124
Validation loss: 2.774901316871667

Epoch: 5| Step: 7
Training loss: 3.504258562320172
Validation loss: 2.77880465945483

Epoch: 5| Step: 8
Training loss: 2.876213978422052
Validation loss: 2.78166689391956

Epoch: 5| Step: 9
Training loss: 3.1130038608094517
Validation loss: 2.7784777729048464

Epoch: 5| Step: 10
Training loss: 2.7182553597717294
Validation loss: 2.778388906509041

Epoch: 252| Step: 0
Training loss: 4.074508056902295
Validation loss: 2.7826721824851037

Epoch: 5| Step: 1
Training loss: 2.59358178018363
Validation loss: 2.7905766638591216

Epoch: 5| Step: 2
Training loss: 2.4380058350591014
Validation loss: 2.7871281953858844

Epoch: 5| Step: 3
Training loss: 3.6357720901771917
Validation loss: 2.7858851256758888

Epoch: 5| Step: 4
Training loss: 2.291387217273869
Validation loss: 2.7894787180098404

Epoch: 5| Step: 5
Training loss: 2.900433205442911
Validation loss: 2.78739457286293

Epoch: 5| Step: 6
Training loss: 2.659805431563906
Validation loss: 2.7867804994936933

Epoch: 5| Step: 7
Training loss: 3.0882337308393524
Validation loss: 2.783128268939467

Epoch: 5| Step: 8
Training loss: 3.6239864642498882
Validation loss: 2.78115511441209

Epoch: 5| Step: 9
Training loss: 3.3067297430585296
Validation loss: 2.778587498387781

Epoch: 5| Step: 10
Training loss: 2.669703264642015
Validation loss: 2.7842243803734514

Epoch: 253| Step: 0
Training loss: 1.8739374965027382
Validation loss: 2.7767064487303066

Epoch: 5| Step: 1
Training loss: 3.1038944884585558
Validation loss: 2.774547881855317

Epoch: 5| Step: 2
Training loss: 3.210979971871631
Validation loss: 2.7791401168716865

Epoch: 5| Step: 3
Training loss: 3.410161004166932
Validation loss: 2.7729969507258057

Epoch: 5| Step: 4
Training loss: 3.4572705547028755
Validation loss: 2.776170185797878

Epoch: 5| Step: 5
Training loss: 3.3118561892777034
Validation loss: 2.7829425155941867

Epoch: 5| Step: 6
Training loss: 3.1242972537473044
Validation loss: 2.7795795928756615

Epoch: 5| Step: 7
Training loss: 3.2127503709413663
Validation loss: 2.7876202314998886

Epoch: 5| Step: 8
Training loss: 2.968664067681071
Validation loss: 2.781780115432217

Epoch: 5| Step: 9
Training loss: 3.207381383853766
Validation loss: 2.7826310853962433

Epoch: 5| Step: 10
Training loss: 2.5807600022727906
Validation loss: 2.778248844265232

Epoch: 254| Step: 0
Training loss: 3.709183641879244
Validation loss: 2.7789221978683543

Epoch: 5| Step: 1
Training loss: 3.2842996140384253
Validation loss: 2.775560006903617

Epoch: 5| Step: 2
Training loss: 2.919368382689176
Validation loss: 2.7729700383482

Epoch: 5| Step: 3
Training loss: 2.460703908339608
Validation loss: 2.772692492800136

Epoch: 5| Step: 4
Training loss: 3.396139275434595
Validation loss: 2.7756958795977664

Epoch: 5| Step: 5
Training loss: 3.5775080652899103
Validation loss: 2.7776994596399316

Epoch: 5| Step: 6
Training loss: 3.0705614450105783
Validation loss: 2.774054151814173

Epoch: 5| Step: 7
Training loss: 3.0407035731232486
Validation loss: 2.7691867363643117

Epoch: 5| Step: 8
Training loss: 2.83561095152064
Validation loss: 2.7711657266833263

Epoch: 5| Step: 9
Training loss: 2.9272058173964983
Validation loss: 2.7762056532490673

Epoch: 5| Step: 10
Training loss: 2.1795175137429847
Validation loss: 2.7791716352453006

Epoch: 255| Step: 0
Training loss: 3.538834789773538
Validation loss: 2.7948830695741216

Epoch: 5| Step: 1
Training loss: 2.4773859526312565
Validation loss: 2.80384574043133

Epoch: 5| Step: 2
Training loss: 3.187499551212055
Validation loss: 2.8086272909762604

Epoch: 5| Step: 3
Training loss: 2.695470125316207
Validation loss: 2.8012600733993445

Epoch: 5| Step: 4
Training loss: 3.1608360888985985
Validation loss: 2.7977438579842393

Epoch: 5| Step: 5
Training loss: 2.7180997575161
Validation loss: 2.797532600607957

Epoch: 5| Step: 6
Training loss: 3.0091838138175935
Validation loss: 2.799673290500009

Epoch: 5| Step: 7
Training loss: 2.9583782318003453
Validation loss: 2.7992651364736174

Epoch: 5| Step: 8
Training loss: 2.799606949603038
Validation loss: 2.7968681510895976

Epoch: 5| Step: 9
Training loss: 3.872108611293884
Validation loss: 2.793295648732623

Epoch: 5| Step: 10
Training loss: 3.4245916582591085
Validation loss: 2.7956348336314245

Epoch: 256| Step: 0
Training loss: 3.025276196694143
Validation loss: 2.799367520318408

Epoch: 5| Step: 1
Training loss: 3.1825725391928024
Validation loss: 2.7990996042178384

Epoch: 5| Step: 2
Training loss: 3.343041032873085
Validation loss: 2.803566193831638

Epoch: 5| Step: 3
Training loss: 2.367988174041653
Validation loss: 2.8101874256494703

Epoch: 5| Step: 4
Training loss: 2.936834544024748
Validation loss: 2.8033410158596266

Epoch: 5| Step: 5
Training loss: 2.5992693718124777
Validation loss: 2.8003188234457705

Epoch: 5| Step: 6
Training loss: 3.249011256129479
Validation loss: 2.799561438223219

Epoch: 5| Step: 7
Training loss: 3.450576601357509
Validation loss: 2.800059330951824

Epoch: 5| Step: 8
Training loss: 3.2886871341161465
Validation loss: 2.801133313428973

Epoch: 5| Step: 9
Training loss: 3.1276949134301097
Validation loss: 2.8003750719074323

Epoch: 5| Step: 10
Training loss: 3.3712933283458906
Validation loss: 2.79626632376222

Epoch: 257| Step: 0
Training loss: 2.8013167248481237
Validation loss: 2.7937969209604585

Epoch: 5| Step: 1
Training loss: 2.6111161139510184
Validation loss: 2.7893603965397573

Epoch: 5| Step: 2
Training loss: 3.3904648140894507
Validation loss: 2.7840596877567765

Epoch: 5| Step: 3
Training loss: 2.7908876575260337
Validation loss: 2.7717187302494546

Epoch: 5| Step: 4
Training loss: 3.5019495847549034
Validation loss: 2.7660954675856675

Epoch: 5| Step: 5
Training loss: 2.573114971801993
Validation loss: 2.76324116175342

Epoch: 5| Step: 6
Training loss: 4.002600063238313
Validation loss: 2.766415895826089

Epoch: 5| Step: 7
Training loss: 3.289826438059265
Validation loss: 2.7651462510185434

Epoch: 5| Step: 8
Training loss: 2.9004244921212945
Validation loss: 2.761523413140283

Epoch: 5| Step: 9
Training loss: 2.4083461796331043
Validation loss: 2.7659455003532947

Epoch: 5| Step: 10
Training loss: 3.2881681626283434
Validation loss: 2.761858656400564

Epoch: 258| Step: 0
Training loss: 2.8058646874242745
Validation loss: 2.762123279371007

Epoch: 5| Step: 1
Training loss: 2.7386133098747165
Validation loss: 2.76350721454795

Epoch: 5| Step: 2
Training loss: 3.336141468396651
Validation loss: 2.764587638830547

Epoch: 5| Step: 3
Training loss: 2.4694575008204036
Validation loss: 2.7673175337750333

Epoch: 5| Step: 4
Training loss: 3.392268894225872
Validation loss: 2.7701529636649886

Epoch: 5| Step: 5
Training loss: 3.552628878914028
Validation loss: 2.770278866551936

Epoch: 5| Step: 6
Training loss: 2.8253094900288396
Validation loss: 2.7694659717807206

Epoch: 5| Step: 7
Training loss: 2.8647958202737436
Validation loss: 2.7734576980061014

Epoch: 5| Step: 8
Training loss: 3.353272328690852
Validation loss: 2.77367969907215

Epoch: 5| Step: 9
Training loss: 3.5002753285696624
Validation loss: 2.7716747588171353

Epoch: 5| Step: 10
Training loss: 2.7070308096308713
Validation loss: 2.774184827166044

Epoch: 259| Step: 0
Training loss: 3.4095529763318075
Validation loss: 2.767759837351242

Epoch: 5| Step: 1
Training loss: 3.0341352122484677
Validation loss: 2.7658455702048306

Epoch: 5| Step: 2
Training loss: 3.368042733254337
Validation loss: 2.770029194794499

Epoch: 5| Step: 3
Training loss: 3.293958196267051
Validation loss: 2.764085141090973

Epoch: 5| Step: 4
Training loss: 3.0951747503540883
Validation loss: 2.7601255347317872

Epoch: 5| Step: 5
Training loss: 2.702947357161878
Validation loss: 2.764169242998387

Epoch: 5| Step: 6
Training loss: 2.9031678951120745
Validation loss: 2.759942448460211

Epoch: 5| Step: 7
Training loss: 3.067437842748964
Validation loss: 2.7610849925438803

Epoch: 5| Step: 8
Training loss: 2.828669037311372
Validation loss: 2.762364850060337

Epoch: 5| Step: 9
Training loss: 2.9403416301473437
Validation loss: 2.762519635941938

Epoch: 5| Step: 10
Training loss: 3.0899840273644905
Validation loss: 2.7638202199122865

Epoch: 260| Step: 0
Training loss: 2.97715100655723
Validation loss: 2.760078071047666

Epoch: 5| Step: 1
Training loss: 3.3559064124497118
Validation loss: 2.7641043853586638

Epoch: 5| Step: 2
Training loss: 2.5982540503985745
Validation loss: 2.760889478989967

Epoch: 5| Step: 3
Training loss: 2.602549322798724
Validation loss: 2.758655523243833

Epoch: 5| Step: 4
Training loss: 3.4256399684468315
Validation loss: 2.7577037281458088

Epoch: 5| Step: 5
Training loss: 3.3063572482217727
Validation loss: 2.759682211023072

Epoch: 5| Step: 6
Training loss: 2.8366436039860834
Validation loss: 2.7666926996414998

Epoch: 5| Step: 7
Training loss: 3.020711295633428
Validation loss: 2.7629200220116807

Epoch: 5| Step: 8
Training loss: 2.510981283892144
Validation loss: 2.770149533016268

Epoch: 5| Step: 9
Training loss: 3.8674019185743393
Validation loss: 2.7677044562430035

Epoch: 5| Step: 10
Training loss: 2.984013720309544
Validation loss: 2.7773923059532017

Epoch: 261| Step: 0
Training loss: 3.073313714362666
Validation loss: 2.776785845762675

Epoch: 5| Step: 1
Training loss: 3.140390567665186
Validation loss: 2.7804284923624922

Epoch: 5| Step: 2
Training loss: 2.852959277718458
Validation loss: 2.772021143053659

Epoch: 5| Step: 3
Training loss: 3.186081215244181
Validation loss: 2.7733247670785985

Epoch: 5| Step: 4
Training loss: 3.3537115574132415
Validation loss: 2.7698792443276106

Epoch: 5| Step: 5
Training loss: 3.3917701299259377
Validation loss: 2.764791292651907

Epoch: 5| Step: 6
Training loss: 3.073784415791977
Validation loss: 2.7577169455755253

Epoch: 5| Step: 7
Training loss: 2.937034894767765
Validation loss: 2.7532789332878833

Epoch: 5| Step: 8
Training loss: 2.789443815435076
Validation loss: 2.7534446527854817

Epoch: 5| Step: 9
Training loss: 2.7978789163420696
Validation loss: 2.7572787216608305

Epoch: 5| Step: 10
Training loss: 3.1769173667374675
Validation loss: 2.7560699329661804

Epoch: 262| Step: 0
Training loss: 3.4299232905849184
Validation loss: 2.7557803881255185

Epoch: 5| Step: 1
Training loss: 2.5956149463013367
Validation loss: 2.754438692448611

Epoch: 5| Step: 2
Training loss: 2.3817626641558345
Validation loss: 2.7521844374821236

Epoch: 5| Step: 3
Training loss: 3.526907081654133
Validation loss: 2.7568074334029906

Epoch: 5| Step: 4
Training loss: 3.070879468912033
Validation loss: 2.751141729720836

Epoch: 5| Step: 5
Training loss: 3.0516559357995274
Validation loss: 2.7560268690247716

Epoch: 5| Step: 6
Training loss: 2.833568581931325
Validation loss: 2.7553508678331986

Epoch: 5| Step: 7
Training loss: 3.4975292476715434
Validation loss: 2.7561557202555282

Epoch: 5| Step: 8
Training loss: 3.038528042356129
Validation loss: 2.762659619635156

Epoch: 5| Step: 9
Training loss: 3.031101813086117
Validation loss: 2.7639439941256705

Epoch: 5| Step: 10
Training loss: 3.083272280389309
Validation loss: 2.761719673635691

Epoch: 263| Step: 0
Training loss: 2.8097049812126924
Validation loss: 2.7686308857726076

Epoch: 5| Step: 1
Training loss: 3.081593839019685
Validation loss: 2.7619941106414196

Epoch: 5| Step: 2
Training loss: 2.696217879668625
Validation loss: 2.7699529387339448

Epoch: 5| Step: 3
Training loss: 2.9407249766106185
Validation loss: 2.7639967264787892

Epoch: 5| Step: 4
Training loss: 3.1065358757625674
Validation loss: 2.762486300761371

Epoch: 5| Step: 5
Training loss: 2.73962996023747
Validation loss: 2.759029445863793

Epoch: 5| Step: 6
Training loss: 3.531271470266242
Validation loss: 2.7518286120853728

Epoch: 5| Step: 7
Training loss: 3.277715032231986
Validation loss: 2.753796779249072

Epoch: 5| Step: 8
Training loss: 3.277754747629528
Validation loss: 2.759045876541052

Epoch: 5| Step: 9
Training loss: 2.921220512322925
Validation loss: 2.755261685386587

Epoch: 5| Step: 10
Training loss: 3.261799885545888
Validation loss: 2.754954005652644

Epoch: 264| Step: 0
Training loss: 2.735565013789954
Validation loss: 2.753225545451057

Epoch: 5| Step: 1
Training loss: 3.1140221607985286
Validation loss: 2.7570927168166692

Epoch: 5| Step: 2
Training loss: 3.1814700666953195
Validation loss: 2.752562394636587

Epoch: 5| Step: 3
Training loss: 2.393501695149819
Validation loss: 2.755550962828122

Epoch: 5| Step: 4
Training loss: 3.2130029722473665
Validation loss: 2.7552075985715367

Epoch: 5| Step: 5
Training loss: 3.0841644988266683
Validation loss: 2.759029845412045

Epoch: 5| Step: 6
Training loss: 3.2532335481297308
Validation loss: 2.7624203697706156

Epoch: 5| Step: 7
Training loss: 2.6985164451868453
Validation loss: 2.757382760723322

Epoch: 5| Step: 8
Training loss: 3.1812342974981602
Validation loss: 2.7570083116343174

Epoch: 5| Step: 9
Training loss: 3.7065533570139135
Validation loss: 2.75650696655884

Epoch: 5| Step: 10
Training loss: 2.9923113207185006
Validation loss: 2.7557619090302534

Epoch: 265| Step: 0
Training loss: 3.064193879948058
Validation loss: 2.7525462000120475

Epoch: 5| Step: 1
Training loss: 2.4742465095661137
Validation loss: 2.751711119142817

Epoch: 5| Step: 2
Training loss: 3.3842367297217626
Validation loss: 2.7498076642923555

Epoch: 5| Step: 3
Training loss: 3.280513281087296
Validation loss: 2.7479570562166824

Epoch: 5| Step: 4
Training loss: 2.9474342050238094
Validation loss: 2.7495386849813297

Epoch: 5| Step: 5
Training loss: 2.660303052977085
Validation loss: 2.7497014399170845

Epoch: 5| Step: 6
Training loss: 3.551987647653701
Validation loss: 2.751177106097956

Epoch: 5| Step: 7
Training loss: 2.9939950607758514
Validation loss: 2.748200520463738

Epoch: 5| Step: 8
Training loss: 3.518030183117213
Validation loss: 2.7498350998258463

Epoch: 5| Step: 9
Training loss: 2.7088308806550168
Validation loss: 2.7499893408276965

Epoch: 5| Step: 10
Training loss: 2.8767401363263043
Validation loss: 2.7492951315275063

Epoch: 266| Step: 0
Training loss: 2.637690341101618
Validation loss: 2.754963797882354

Epoch: 5| Step: 1
Training loss: 3.7561676168690377
Validation loss: 2.7536322526110752

Epoch: 5| Step: 2
Training loss: 3.3763264062929483
Validation loss: 2.7540278717206914

Epoch: 5| Step: 3
Training loss: 3.0184644860248984
Validation loss: 2.752721035076035

Epoch: 5| Step: 4
Training loss: 2.5577497415178003
Validation loss: 2.749527355494783

Epoch: 5| Step: 5
Training loss: 3.1138126776476924
Validation loss: 2.751070755680527

Epoch: 5| Step: 6
Training loss: 2.716244299259866
Validation loss: 2.7535596818117876

Epoch: 5| Step: 7
Training loss: 3.2757296673902747
Validation loss: 2.7548845787415055

Epoch: 5| Step: 8
Training loss: 2.7258807972393173
Validation loss: 2.7535636666079237

Epoch: 5| Step: 9
Training loss: 2.938853986645437
Validation loss: 2.7567243372380803

Epoch: 5| Step: 10
Training loss: 3.3628444055639437
Validation loss: 2.7548781614539903

Epoch: 267| Step: 0
Training loss: 3.448209275720875
Validation loss: 2.7529211927076833

Epoch: 5| Step: 1
Training loss: 2.9179427670467173
Validation loss: 2.7488640893799507

Epoch: 5| Step: 2
Training loss: 2.8336059401770286
Validation loss: 2.751923545588131

Epoch: 5| Step: 3
Training loss: 2.8982140796850344
Validation loss: 2.7490923382043286

Epoch: 5| Step: 4
Training loss: 3.212730630989751
Validation loss: 2.752789332885713

Epoch: 5| Step: 5
Training loss: 2.583723797566097
Validation loss: 2.750138166504785

Epoch: 5| Step: 6
Training loss: 2.168246964482325
Validation loss: 2.7472608680779738

Epoch: 5| Step: 7
Training loss: 3.3047055363444713
Validation loss: 2.7511753132485683

Epoch: 5| Step: 8
Training loss: 2.8062880685513822
Validation loss: 2.756995059191807

Epoch: 5| Step: 9
Training loss: 3.8339755446360995
Validation loss: 2.756312791287082

Epoch: 5| Step: 10
Training loss: 3.3628461071129188
Validation loss: 2.751031487325281

Epoch: 268| Step: 0
Training loss: 2.4368035715401337
Validation loss: 2.7535907574826175

Epoch: 5| Step: 1
Training loss: 3.691404570725478
Validation loss: 2.748599923777564

Epoch: 5| Step: 2
Training loss: 2.6834137480002114
Validation loss: 2.7485402428872354

Epoch: 5| Step: 3
Training loss: 3.2385373077575923
Validation loss: 2.745648733026721

Epoch: 5| Step: 4
Training loss: 3.1291427618164254
Validation loss: 2.7462665034000953

Epoch: 5| Step: 5
Training loss: 3.3547912553183177
Validation loss: 2.747823029729343

Epoch: 5| Step: 6
Training loss: 2.7477523114438767
Validation loss: 2.745476650419137

Epoch: 5| Step: 7
Training loss: 2.7585424910552447
Validation loss: 2.743917343041257

Epoch: 5| Step: 8
Training loss: 2.9062429448524076
Validation loss: 2.7446488534379503

Epoch: 5| Step: 9
Training loss: 3.11953623919586
Validation loss: 2.743296396186275

Epoch: 5| Step: 10
Training loss: 3.4298418223217615
Validation loss: 2.7473185807687663

Epoch: 269| Step: 0
Training loss: 2.835921358425137
Validation loss: 2.7428194475998846

Epoch: 5| Step: 1
Training loss: 3.4424934878041844
Validation loss: 2.7433314522731154

Epoch: 5| Step: 2
Training loss: 3.0824453948320936
Validation loss: 2.7446059801851184

Epoch: 5| Step: 3
Training loss: 3.102208452197207
Validation loss: 2.742729523993005

Epoch: 5| Step: 4
Training loss: 3.6375260814242956
Validation loss: 2.7438049846843677

Epoch: 5| Step: 5
Training loss: 3.0906032395633405
Validation loss: 2.744338658286973

Epoch: 5| Step: 6
Training loss: 3.3711995520404505
Validation loss: 2.7445571426243434

Epoch: 5| Step: 7
Training loss: 2.887528033760357
Validation loss: 2.744755912218341

Epoch: 5| Step: 8
Training loss: 2.902882583729813
Validation loss: 2.7410582171128293

Epoch: 5| Step: 9
Training loss: 2.4466452577193043
Validation loss: 2.7428460744491265

Epoch: 5| Step: 10
Training loss: 2.5579634727333644
Validation loss: 2.7473203901321184

Epoch: 270| Step: 0
Training loss: 3.11454351053115
Validation loss: 2.746312331348498

Epoch: 5| Step: 1
Training loss: 3.292659867213689
Validation loss: 2.746215109993078

Epoch: 5| Step: 2
Training loss: 2.2059154829641496
Validation loss: 2.747359040610808

Epoch: 5| Step: 3
Training loss: 2.9336621800961113
Validation loss: 2.7437570377883462

Epoch: 5| Step: 4
Training loss: 3.1567942839314083
Validation loss: 2.748896784913807

Epoch: 5| Step: 5
Training loss: 3.3263608169875436
Validation loss: 2.7484961706662294

Epoch: 5| Step: 6
Training loss: 3.1371677785117305
Validation loss: 2.749858743502025

Epoch: 5| Step: 7
Training loss: 2.735681624895212
Validation loss: 2.747887654973781

Epoch: 5| Step: 8
Training loss: 3.5979035631098393
Validation loss: 2.7406348026801095

Epoch: 5| Step: 9
Training loss: 3.2413387796326667
Validation loss: 2.7438175374836167

Epoch: 5| Step: 10
Training loss: 2.5610712301588308
Validation loss: 2.742487563284715

Epoch: 271| Step: 0
Training loss: 3.3193988575236917
Validation loss: 2.7435107235168217

Epoch: 5| Step: 1
Training loss: 2.5327550863904547
Validation loss: 2.742232519205083

Epoch: 5| Step: 2
Training loss: 3.119335533936484
Validation loss: 2.7482731730764454

Epoch: 5| Step: 3
Training loss: 2.507267212335764
Validation loss: 2.7433339258909855

Epoch: 5| Step: 4
Training loss: 3.0437518423337275
Validation loss: 2.7460984551335135

Epoch: 5| Step: 5
Training loss: 3.3451647751256885
Validation loss: 2.749329985943058

Epoch: 5| Step: 6
Training loss: 3.13754941741811
Validation loss: 2.7471529130608485

Epoch: 5| Step: 7
Training loss: 3.3352298745423887
Validation loss: 2.7475047747127586

Epoch: 5| Step: 8
Training loss: 2.9419687247516744
Validation loss: 2.747750061990723

Epoch: 5| Step: 9
Training loss: 3.113788175773822
Validation loss: 2.7545284003964454

Epoch: 5| Step: 10
Training loss: 3.0334167601742035
Validation loss: 2.742750780017441

Epoch: 272| Step: 0
Training loss: 3.0550838125566386
Validation loss: 2.746106423968233

Epoch: 5| Step: 1
Training loss: 2.9810275332699914
Validation loss: 2.7416118322233034

Epoch: 5| Step: 2
Training loss: 3.0533656701897915
Validation loss: 2.7478782592224906

Epoch: 5| Step: 3
Training loss: 2.9632050781758505
Validation loss: 2.745752875236525

Epoch: 5| Step: 4
Training loss: 3.5442659301873385
Validation loss: 2.7571229716139825

Epoch: 5| Step: 5
Training loss: 3.390181692650069
Validation loss: 2.7482451006868187

Epoch: 5| Step: 6
Training loss: 3.1624780525983898
Validation loss: 2.749188455364402

Epoch: 5| Step: 7
Training loss: 2.869600283869614
Validation loss: 2.7471909462602317

Epoch: 5| Step: 8
Training loss: 2.4849317394682884
Validation loss: 2.7477156864600953

Epoch: 5| Step: 9
Training loss: 3.150231240882598
Validation loss: 2.7418160490942802

Epoch: 5| Step: 10
Training loss: 2.822651661801298
Validation loss: 2.7381422642362616

Epoch: 273| Step: 0
Training loss: 3.392219274118159
Validation loss: 2.7420640180297133

Epoch: 5| Step: 1
Training loss: 3.3670181267218964
Validation loss: 2.7372507993787676

Epoch: 5| Step: 2
Training loss: 2.9815022487807825
Validation loss: 2.7380862822042564

Epoch: 5| Step: 3
Training loss: 2.6013254968410116
Validation loss: 2.739101110288651

Epoch: 5| Step: 4
Training loss: 3.050461599721346
Validation loss: 2.7381852742727086

Epoch: 5| Step: 5
Training loss: 2.924221300332427
Validation loss: 2.7373541953046594

Epoch: 5| Step: 6
Training loss: 3.1519245686775723
Validation loss: 2.737527563900585

Epoch: 5| Step: 7
Training loss: 2.8383669364882866
Validation loss: 2.7385398795622407

Epoch: 5| Step: 8
Training loss: 3.4565619715914466
Validation loss: 2.739813896729156

Epoch: 5| Step: 9
Training loss: 2.733323859764367
Validation loss: 2.7360170033549074

Epoch: 5| Step: 10
Training loss: 2.9227965834392347
Validation loss: 2.739451220189707

Epoch: 274| Step: 0
Training loss: 2.6268437586144384
Validation loss: 2.737886151498813

Epoch: 5| Step: 1
Training loss: 2.8391614511447747
Validation loss: 2.739994318785323

Epoch: 5| Step: 2
Training loss: 2.666104515745659
Validation loss: 2.7379711330636516

Epoch: 5| Step: 3
Training loss: 2.8792328565159533
Validation loss: 2.7364290956057524

Epoch: 5| Step: 4
Training loss: 3.0333875218116972
Validation loss: 2.7422715657904306

Epoch: 5| Step: 5
Training loss: 3.508717851263882
Validation loss: 2.7460352432319235

Epoch: 5| Step: 6
Training loss: 3.258280256250448
Validation loss: 2.7391358017068286

Epoch: 5| Step: 7
Training loss: 3.315446514822908
Validation loss: 2.7425081238389963

Epoch: 5| Step: 8
Training loss: 2.8569507432108976
Validation loss: 2.740823636600843

Epoch: 5| Step: 9
Training loss: 3.0768485738830966
Validation loss: 2.7365063420587274

Epoch: 5| Step: 10
Training loss: 3.4020945548631496
Validation loss: 2.741664305897041

Epoch: 275| Step: 0
Training loss: 3.287019434858382
Validation loss: 2.743273001538357

Epoch: 5| Step: 1
Training loss: 2.90453837865059
Validation loss: 2.7366302331190386

Epoch: 5| Step: 2
Training loss: 2.518588009303608
Validation loss: 2.7375609033327457

Epoch: 5| Step: 3
Training loss: 2.9462481158594023
Validation loss: 2.734291074903436

Epoch: 5| Step: 4
Training loss: 3.2744648852956386
Validation loss: 2.7375461754468087

Epoch: 5| Step: 5
Training loss: 2.2259710228979834
Validation loss: 2.7375660595256286

Epoch: 5| Step: 6
Training loss: 2.7649462885408145
Validation loss: 2.7387996154446483

Epoch: 5| Step: 7
Training loss: 3.3849579172603512
Validation loss: 2.7396485968029833

Epoch: 5| Step: 8
Training loss: 3.431920048340387
Validation loss: 2.746529932021552

Epoch: 5| Step: 9
Training loss: 3.017689210890172
Validation loss: 2.7467447630443087

Epoch: 5| Step: 10
Training loss: 3.595423831069769
Validation loss: 2.7409432246261605

Epoch: 276| Step: 0
Training loss: 3.0411525100153005
Validation loss: 2.740967359344137

Epoch: 5| Step: 1
Training loss: 2.6326091019934816
Validation loss: 2.7404674979656525

Epoch: 5| Step: 2
Training loss: 3.8271062001289473
Validation loss: 2.7373361031726495

Epoch: 5| Step: 3
Training loss: 2.9995539651535132
Validation loss: 2.740749824008556

Epoch: 5| Step: 4
Training loss: 2.8806455164265863
Validation loss: 2.7361488638121347

Epoch: 5| Step: 5
Training loss: 3.223027026492483
Validation loss: 2.7375658834698022

Epoch: 5| Step: 6
Training loss: 2.8559847051173537
Validation loss: 2.7339667118268625

Epoch: 5| Step: 7
Training loss: 3.7449339661423404
Validation loss: 2.7328194614518897

Epoch: 5| Step: 8
Training loss: 3.040258177284603
Validation loss: 2.73621604995399

Epoch: 5| Step: 9
Training loss: 2.5246928490885323
Validation loss: 2.731226715576598

Epoch: 5| Step: 10
Training loss: 2.283300967114717
Validation loss: 2.73389777406548

Epoch: 277| Step: 0
Training loss: 2.6731336874705853
Validation loss: 2.733997476653665

Epoch: 5| Step: 1
Training loss: 2.977142677934713
Validation loss: 2.7359908132170987

Epoch: 5| Step: 2
Training loss: 3.0116646015925066
Validation loss: 2.7402563847842454

Epoch: 5| Step: 3
Training loss: 2.6665624260396665
Validation loss: 2.7390057482739354

Epoch: 5| Step: 4
Training loss: 3.50367652709878
Validation loss: 2.7448736795257074

Epoch: 5| Step: 5
Training loss: 2.6904155973145105
Validation loss: 2.7349869210094595

Epoch: 5| Step: 6
Training loss: 3.3649569245935553
Validation loss: 2.7345500012253585

Epoch: 5| Step: 7
Training loss: 3.2605213640036945
Validation loss: 2.7346704804467517

Epoch: 5| Step: 8
Training loss: 2.8578518839229394
Validation loss: 2.731512485753281

Epoch: 5| Step: 9
Training loss: 3.5369912796064
Validation loss: 2.7328846938309015

Epoch: 5| Step: 10
Training loss: 2.7669122146506138
Validation loss: 2.7336673900350816

Epoch: 278| Step: 0
Training loss: 3.1682977658408666
Validation loss: 2.729161850931978

Epoch: 5| Step: 1
Training loss: 3.4320205017935783
Validation loss: 2.732019323964065

Epoch: 5| Step: 2
Training loss: 2.604493285995269
Validation loss: 2.733504206558457

Epoch: 5| Step: 3
Training loss: 3.1695462402109627
Validation loss: 2.730823376278022

Epoch: 5| Step: 4
Training loss: 3.595663075635871
Validation loss: 2.7329151425168683

Epoch: 5| Step: 5
Training loss: 2.8433718587122057
Validation loss: 2.731902036655335

Epoch: 5| Step: 6
Training loss: 3.560218883814784
Validation loss: 2.7342249009617046

Epoch: 5| Step: 7
Training loss: 2.302809955886966
Validation loss: 2.729853559515943

Epoch: 5| Step: 8
Training loss: 2.783580703554888
Validation loss: 2.7311940919845803

Epoch: 5| Step: 9
Training loss: 2.27497408087082
Validation loss: 2.7308091274476443

Epoch: 5| Step: 10
Training loss: 3.4594773081853867
Validation loss: 2.733553000096297

Epoch: 279| Step: 0
Training loss: 2.9242318995162537
Validation loss: 2.7378526877447076

Epoch: 5| Step: 1
Training loss: 3.243360633486899
Validation loss: 2.735410413991166

Epoch: 5| Step: 2
Training loss: 2.767981694315318
Validation loss: 2.7350791697145387

Epoch: 5| Step: 3
Training loss: 3.3741386162052067
Validation loss: 2.7389106300449195

Epoch: 5| Step: 4
Training loss: 2.7338992331631107
Validation loss: 2.7353907757246625

Epoch: 5| Step: 5
Training loss: 2.4293726873521764
Validation loss: 2.733579051345435

Epoch: 5| Step: 6
Training loss: 3.246866182493366
Validation loss: 2.731896163148975

Epoch: 5| Step: 7
Training loss: 2.4023843405170973
Validation loss: 2.7305428536566567

Epoch: 5| Step: 8
Training loss: 3.471800004507931
Validation loss: 2.7261211464569524

Epoch: 5| Step: 9
Training loss: 3.3746563771830904
Validation loss: 2.727468058911342

Epoch: 5| Step: 10
Training loss: 3.330156019983394
Validation loss: 2.7293830628607094

Epoch: 280| Step: 0
Training loss: 3.0098215502692733
Validation loss: 2.727265717400137

Epoch: 5| Step: 1
Training loss: 2.6182955545589097
Validation loss: 2.7297206962272407

Epoch: 5| Step: 2
Training loss: 2.4340331046831722
Validation loss: 2.724234499682702

Epoch: 5| Step: 3
Training loss: 3.2510647130114894
Validation loss: 2.7310803484671524

Epoch: 5| Step: 4
Training loss: 3.1066818459048564
Validation loss: 2.7289351122657064

Epoch: 5| Step: 5
Training loss: 3.0621920060966374
Validation loss: 2.7272696823340525

Epoch: 5| Step: 6
Training loss: 2.9123592359064716
Validation loss: 2.7260879445401636

Epoch: 5| Step: 7
Training loss: 3.094009850888885
Validation loss: 2.7259655304898356

Epoch: 5| Step: 8
Training loss: 3.465467532323789
Validation loss: 2.7283876530447997

Epoch: 5| Step: 9
Training loss: 2.9422701799198365
Validation loss: 2.7284791899803844

Epoch: 5| Step: 10
Training loss: 3.471518296837613
Validation loss: 2.7331624698233217

Epoch: 281| Step: 0
Training loss: 3.4185236714709504
Validation loss: 2.729060533481516

Epoch: 5| Step: 1
Training loss: 3.4380140440400475
Validation loss: 2.7272885725612

Epoch: 5| Step: 2
Training loss: 3.0047810921298566
Validation loss: 2.734210790810247

Epoch: 5| Step: 3
Training loss: 2.645537642729338
Validation loss: 2.7346444236580267

Epoch: 5| Step: 4
Training loss: 2.7644638813796494
Validation loss: 2.7279570609839783

Epoch: 5| Step: 5
Training loss: 3.2855735268859423
Validation loss: 2.72585768010445

Epoch: 5| Step: 6
Training loss: 3.243596003116465
Validation loss: 2.7272512469404426

Epoch: 5| Step: 7
Training loss: 3.352540342584594
Validation loss: 2.7280641066614697

Epoch: 5| Step: 8
Training loss: 2.9128109287093613
Validation loss: 2.7229935293010747

Epoch: 5| Step: 9
Training loss: 2.654282233708009
Validation loss: 2.7279397372869867

Epoch: 5| Step: 10
Training loss: 2.4667449728246758
Validation loss: 2.7256785316508765

Epoch: 282| Step: 0
Training loss: 3.415053723472605
Validation loss: 2.729748123276866

Epoch: 5| Step: 1
Training loss: 3.0268948129828206
Validation loss: 2.730016586521971

Epoch: 5| Step: 2
Training loss: 3.0582056883351596
Validation loss: 2.729029786272611

Epoch: 5| Step: 3
Training loss: 2.769735955554025
Validation loss: 2.7275428644324036

Epoch: 5| Step: 4
Training loss: 2.543193566951193
Validation loss: 2.7237994815670636

Epoch: 5| Step: 5
Training loss: 2.6191061246620824
Validation loss: 2.725427910690624

Epoch: 5| Step: 6
Training loss: 3.679548321661292
Validation loss: 2.7226439913417244

Epoch: 5| Step: 7
Training loss: 2.08920729027677
Validation loss: 2.730332358975239

Epoch: 5| Step: 8
Training loss: 3.2506252567677687
Validation loss: 2.7216655273803854

Epoch: 5| Step: 9
Training loss: 2.758350784461683
Validation loss: 2.724859873200125

Epoch: 5| Step: 10
Training loss: 3.9273853270206343
Validation loss: 2.7261809175396543

Epoch: 283| Step: 0
Training loss: 2.6701911840676607
Validation loss: 2.7255828693155246

Epoch: 5| Step: 1
Training loss: 3.328578004766221
Validation loss: 2.7238687153743846

Epoch: 5| Step: 2
Training loss: 3.111513715382464
Validation loss: 2.729471437792617

Epoch: 5| Step: 3
Training loss: 3.332265078712912
Validation loss: 2.724472463873297

Epoch: 5| Step: 4
Training loss: 3.0051641521588963
Validation loss: 2.721918631351667

Epoch: 5| Step: 5
Training loss: 2.958238161373959
Validation loss: 2.7195441953430826

Epoch: 5| Step: 6
Training loss: 2.8103743255645646
Validation loss: 2.7211797613698185

Epoch: 5| Step: 7
Training loss: 3.3955627208765042
Validation loss: 2.7227252680689666

Epoch: 5| Step: 8
Training loss: 2.6609204688789965
Validation loss: 2.720606759085874

Epoch: 5| Step: 9
Training loss: 2.7309409239451017
Validation loss: 2.7230281001825514

Epoch: 5| Step: 10
Training loss: 3.3471633744156106
Validation loss: 2.7239989710576626

Epoch: 284| Step: 0
Training loss: 3.050954112920335
Validation loss: 2.7239106933955357

Epoch: 5| Step: 1
Training loss: 2.90278303844537
Validation loss: 2.719440433356604

Epoch: 5| Step: 2
Training loss: 3.2689400962272415
Validation loss: 2.7265039220186473

Epoch: 5| Step: 3
Training loss: 3.0785384312000215
Validation loss: 2.7227434469300857

Epoch: 5| Step: 4
Training loss: 2.2785900755826938
Validation loss: 2.725217003529923

Epoch: 5| Step: 5
Training loss: 2.9734771036306014
Validation loss: 2.726102067582456

Epoch: 5| Step: 6
Training loss: 2.9647129919597317
Validation loss: 2.721994941841324

Epoch: 5| Step: 7
Training loss: 3.782374065191168
Validation loss: 2.7224128687219857

Epoch: 5| Step: 8
Training loss: 3.043446024729917
Validation loss: 2.723692032032092

Epoch: 5| Step: 9
Training loss: 3.0398935000687533
Validation loss: 2.7247267250102882

Epoch: 5| Step: 10
Training loss: 2.8086527472017635
Validation loss: 2.7227677034262086

Epoch: 285| Step: 0
Training loss: 3.5257236143811506
Validation loss: 2.721228854087016

Epoch: 5| Step: 1
Training loss: 2.8141280654309675
Validation loss: 2.721818682216987

Epoch: 5| Step: 2
Training loss: 3.0682937935583787
Validation loss: 2.7203495269436386

Epoch: 5| Step: 3
Training loss: 2.70788930529778
Validation loss: 2.718916631770627

Epoch: 5| Step: 4
Training loss: 3.026591545914847
Validation loss: 2.7220959807470178

Epoch: 5| Step: 5
Training loss: 2.7763619491629705
Validation loss: 2.72327991397005

Epoch: 5| Step: 6
Training loss: 3.1314211678690898
Validation loss: 2.7186855091163658

Epoch: 5| Step: 7
Training loss: 3.3710545684553104
Validation loss: 2.723588992831769

Epoch: 5| Step: 8
Training loss: 3.274567402230855
Validation loss: 2.7238164899428985

Epoch: 5| Step: 9
Training loss: 2.599456301108147
Validation loss: 2.720188658385915

Epoch: 5| Step: 10
Training loss: 2.953153741282922
Validation loss: 2.7235842930518936

Epoch: 286| Step: 0
Training loss: 3.512406024150854
Validation loss: 2.724190448780181

Epoch: 5| Step: 1
Training loss: 2.5010236551721117
Validation loss: 2.7243962321891115

Epoch: 5| Step: 2
Training loss: 2.8173276370247144
Validation loss: 2.7200779201921006

Epoch: 5| Step: 3
Training loss: 3.2508664076692995
Validation loss: 2.7210373252988913

Epoch: 5| Step: 4
Training loss: 2.5892944674038567
Validation loss: 2.718354392155695

Epoch: 5| Step: 5
Training loss: 3.377015536312369
Validation loss: 2.719439837564529

Epoch: 5| Step: 6
Training loss: 3.275015148098689
Validation loss: 2.7176624452430396

Epoch: 5| Step: 7
Training loss: 3.2939315601087804
Validation loss: 2.717059865983172

Epoch: 5| Step: 8
Training loss: 3.097627464054852
Validation loss: 2.7163442855130806

Epoch: 5| Step: 9
Training loss: 2.067040964297393
Validation loss: 2.7144069992841566

Epoch: 5| Step: 10
Training loss: 3.291934103101117
Validation loss: 2.7197862837095923

Epoch: 287| Step: 0
Training loss: 2.5953234760160266
Validation loss: 2.7156663398131307

Epoch: 5| Step: 1
Training loss: 3.1711949714093417
Validation loss: 2.719016647039836

Epoch: 5| Step: 2
Training loss: 3.6216633666565197
Validation loss: 2.719364267069005

Epoch: 5| Step: 3
Training loss: 3.552286599049563
Validation loss: 2.7139978268477627

Epoch: 5| Step: 4
Training loss: 3.0346247184292263
Validation loss: 2.7178063787726146

Epoch: 5| Step: 5
Training loss: 2.764202290779712
Validation loss: 2.7159546939895556

Epoch: 5| Step: 6
Training loss: 3.385188090115015
Validation loss: 2.7159533677833485

Epoch: 5| Step: 7
Training loss: 2.8368500221364723
Validation loss: 2.715504951192622

Epoch: 5| Step: 8
Training loss: 2.986619674392401
Validation loss: 2.714736293514284

Epoch: 5| Step: 9
Training loss: 2.087392007010225
Validation loss: 2.7157862058689366

Epoch: 5| Step: 10
Training loss: 3.039692399123079
Validation loss: 2.713375740646059

Epoch: 288| Step: 0
Training loss: 2.9419150754599057
Validation loss: 2.716230466626021

Epoch: 5| Step: 1
Training loss: 3.23870971937318
Validation loss: 2.718404398804849

Epoch: 5| Step: 2
Training loss: 3.636735139639827
Validation loss: 2.712551749264919

Epoch: 5| Step: 3
Training loss: 3.042361001669187
Validation loss: 2.719371846650098

Epoch: 5| Step: 4
Training loss: 2.723680957411068
Validation loss: 2.7221387338744596

Epoch: 5| Step: 5
Training loss: 2.709399487869846
Validation loss: 2.720059002508385

Epoch: 5| Step: 6
Training loss: 3.318820896576778
Validation loss: 2.7221878422587817

Epoch: 5| Step: 7
Training loss: 3.123517714859172
Validation loss: 2.7187415822876755

Epoch: 5| Step: 8
Training loss: 2.845674638991776
Validation loss: 2.7245539372858754

Epoch: 5| Step: 9
Training loss: 2.506123957710862
Validation loss: 2.7165212372487204

Epoch: 5| Step: 10
Training loss: 3.1097709365337445
Validation loss: 2.71879721678215

Epoch: 289| Step: 0
Training loss: 2.6613235489271077
Validation loss: 2.7220854034917994

Epoch: 5| Step: 1
Training loss: 3.6565609009108972
Validation loss: 2.7167540996170616

Epoch: 5| Step: 2
Training loss: 3.0786310544813094
Validation loss: 2.7151579124966227

Epoch: 5| Step: 3
Training loss: 2.3168485839918453
Validation loss: 2.717570350574758

Epoch: 5| Step: 4
Training loss: 2.421721619702091
Validation loss: 2.714585810267876

Epoch: 5| Step: 5
Training loss: 2.624572991653935
Validation loss: 2.7222364741782368

Epoch: 5| Step: 6
Training loss: 3.5147020272814267
Validation loss: 2.7202307648219826

Epoch: 5| Step: 7
Training loss: 3.025195022475614
Validation loss: 2.7308391139299513

Epoch: 5| Step: 8
Training loss: 3.537994425698607
Validation loss: 2.7323334397461516

Epoch: 5| Step: 9
Training loss: 3.2626668134698913
Validation loss: 2.718327877177296

Epoch: 5| Step: 10
Training loss: 2.8907508616496886
Validation loss: 2.7147553219473175

Epoch: 290| Step: 0
Training loss: 3.178347893534694
Validation loss: 2.7092220965292286

Epoch: 5| Step: 1
Training loss: 3.2325074337241717
Validation loss: 2.709882239023354

Epoch: 5| Step: 2
Training loss: 2.990918400800835
Validation loss: 2.7139467254299925

Epoch: 5| Step: 3
Training loss: 3.3094171537572907
Validation loss: 2.7136756785623404

Epoch: 5| Step: 4
Training loss: 3.2347852658634944
Validation loss: 2.7138904247189393

Epoch: 5| Step: 5
Training loss: 3.123062295977015
Validation loss: 2.713175059989361

Epoch: 5| Step: 6
Training loss: 2.7301203296677845
Validation loss: 2.7149588470129014

Epoch: 5| Step: 7
Training loss: 3.062769819557182
Validation loss: 2.7205948219432825

Epoch: 5| Step: 8
Training loss: 2.908526933524025
Validation loss: 2.7175321962089076

Epoch: 5| Step: 9
Training loss: 2.1747349632402004
Validation loss: 2.719735837763619

Epoch: 5| Step: 10
Training loss: 3.258088244288107
Validation loss: 2.7193468396087632

Epoch: 291| Step: 0
Training loss: 2.739905818239427
Validation loss: 2.7187953535480696

Epoch: 5| Step: 1
Training loss: 3.4888044864085987
Validation loss: 2.7199140297968047

Epoch: 5| Step: 2
Training loss: 3.2891587630657697
Validation loss: 2.7167625550993484

Epoch: 5| Step: 3
Training loss: 2.7573569464560945
Validation loss: 2.7179752934441037

Epoch: 5| Step: 4
Training loss: 3.4480449886971587
Validation loss: 2.7145271183317643

Epoch: 5| Step: 5
Training loss: 2.766053419820606
Validation loss: 2.7152483196255326

Epoch: 5| Step: 6
Training loss: 3.2702562993483757
Validation loss: 2.71580778510517

Epoch: 5| Step: 7
Training loss: 2.86889946575203
Validation loss: 2.7126536615809895

Epoch: 5| Step: 8
Training loss: 2.592131235938843
Validation loss: 2.7165215222527253

Epoch: 5| Step: 9
Training loss: 3.2001227474512417
Validation loss: 2.7111045448097735

Epoch: 5| Step: 10
Training loss: 2.672744787868891
Validation loss: 2.7181041338392795

Epoch: 292| Step: 0
Training loss: 3.029125452264102
Validation loss: 2.722731866594354

Epoch: 5| Step: 1
Training loss: 3.4865156363701866
Validation loss: 2.7213866306320758

Epoch: 5| Step: 2
Training loss: 3.0443564936733822
Validation loss: 2.7193425232641935

Epoch: 5| Step: 3
Training loss: 2.8776852879662065
Validation loss: 2.722331072262261

Epoch: 5| Step: 4
Training loss: 3.1513046953538124
Validation loss: 2.7270191300478186

Epoch: 5| Step: 5
Training loss: 2.071166125241326
Validation loss: 2.7179478796455423

Epoch: 5| Step: 6
Training loss: 3.448083848540012
Validation loss: 2.721156288689761

Epoch: 5| Step: 7
Training loss: 3.0007782562407774
Validation loss: 2.7205847599505497

Epoch: 5| Step: 8
Training loss: 3.0950058979230897
Validation loss: 2.724928172183639

Epoch: 5| Step: 9
Training loss: 3.037019253586528
Validation loss: 2.7252123724075

Epoch: 5| Step: 10
Training loss: 2.763551354897536
Validation loss: 2.7264043205768056

Epoch: 293| Step: 0
Training loss: 2.6470502522897017
Validation loss: 2.7302827031874477

Epoch: 5| Step: 1
Training loss: 3.1890418119754766
Validation loss: 2.736396549026906

Epoch: 5| Step: 2
Training loss: 3.251602071423222
Validation loss: 2.729203531491746

Epoch: 5| Step: 3
Training loss: 3.3222106534344653
Validation loss: 2.72418758982282

Epoch: 5| Step: 4
Training loss: 3.2069847112849676
Validation loss: 2.7200462326204993

Epoch: 5| Step: 5
Training loss: 3.2534885756657124
Validation loss: 2.707238199463534

Epoch: 5| Step: 6
Training loss: 2.8953144697253657
Validation loss: 2.7062444963114807

Epoch: 5| Step: 7
Training loss: 2.7373098263809683
Validation loss: 2.7075963588146204

Epoch: 5| Step: 8
Training loss: 2.9894562449452065
Validation loss: 2.7046137061802384

Epoch: 5| Step: 9
Training loss: 2.5189204458869914
Validation loss: 2.7078293898662777

Epoch: 5| Step: 10
Training loss: 3.175412765465161
Validation loss: 2.709918733929823

Epoch: 294| Step: 0
Training loss: 2.639902320702018
Validation loss: 2.706917045206242

Epoch: 5| Step: 1
Training loss: 2.738593808782075
Validation loss: 2.7024537319420787

Epoch: 5| Step: 2
Training loss: 3.0999850242006906
Validation loss: 2.7085548042130005

Epoch: 5| Step: 3
Training loss: 2.9785032978740813
Validation loss: 2.7069239502867157

Epoch: 5| Step: 4
Training loss: 3.0604332937503482
Validation loss: 2.708141587681856

Epoch: 5| Step: 5
Training loss: 3.383147119618566
Validation loss: 2.7133757841075914

Epoch: 5| Step: 6
Training loss: 3.041946415686944
Validation loss: 2.7083732295982674

Epoch: 5| Step: 7
Training loss: 3.1749529256860276
Validation loss: 2.71743814994235

Epoch: 5| Step: 8
Training loss: 3.011805828730595
Validation loss: 2.712481142540582

Epoch: 5| Step: 9
Training loss: 3.4447937313166315
Validation loss: 2.7105296315939555

Epoch: 5| Step: 10
Training loss: 2.4997727290799863
Validation loss: 2.709783311392075

Epoch: 295| Step: 0
Training loss: 3.0550675802045197
Validation loss: 2.7092311077908753

Epoch: 5| Step: 1
Training loss: 2.5803622624284737
Validation loss: 2.7080879059205163

Epoch: 5| Step: 2
Training loss: 2.867286119142259
Validation loss: 2.7070029071285986

Epoch: 5| Step: 3
Training loss: 2.949118828501833
Validation loss: 2.7072312648818553

Epoch: 5| Step: 4
Training loss: 2.652959423492518
Validation loss: 2.713472308564297

Epoch: 5| Step: 5
Training loss: 2.745040061950176
Validation loss: 2.7106043536528968

Epoch: 5| Step: 6
Training loss: 2.8084072427805924
Validation loss: 2.7132477453021733

Epoch: 5| Step: 7
Training loss: 3.6551258934872832
Validation loss: 2.712709784775052

Epoch: 5| Step: 8
Training loss: 2.5240788545275863
Validation loss: 2.7193098065919745

Epoch: 5| Step: 9
Training loss: 3.853265412951899
Validation loss: 2.7191592106432783

Epoch: 5| Step: 10
Training loss: 3.324727648142953
Validation loss: 2.709129647751081

Epoch: 296| Step: 0
Training loss: 2.886365401718703
Validation loss: 2.705127807506859

Epoch: 5| Step: 1
Training loss: 2.1409263677144756
Validation loss: 2.705359995548267

Epoch: 5| Step: 2
Training loss: 3.1674366232441127
Validation loss: 2.701760304102686

Epoch: 5| Step: 3
Training loss: 3.0061815472143416
Validation loss: 2.6981687578057523

Epoch: 5| Step: 4
Training loss: 2.888394706794549
Validation loss: 2.704074294366008

Epoch: 5| Step: 5
Training loss: 3.350394234305652
Validation loss: 2.7015664432909907

Epoch: 5| Step: 6
Training loss: 3.2249941212208713
Validation loss: 2.704082440135971

Epoch: 5| Step: 7
Training loss: 3.193479725847561
Validation loss: 2.707116084592624

Epoch: 5| Step: 8
Training loss: 3.0115702353743594
Validation loss: 2.7090574490769526

Epoch: 5| Step: 9
Training loss: 3.2046869702945533
Validation loss: 2.7133462348288204

Epoch: 5| Step: 10
Training loss: 3.047974217032971
Validation loss: 2.7196390718309695

Epoch: 297| Step: 0
Training loss: 2.197872962939001
Validation loss: 2.709919922132219

Epoch: 5| Step: 1
Training loss: 2.612364193247492
Validation loss: 2.701920999386646

Epoch: 5| Step: 2
Training loss: 2.803141303211717
Validation loss: 2.70702637468359

Epoch: 5| Step: 3
Training loss: 2.947421909685868
Validation loss: 2.7051958635922797

Epoch: 5| Step: 4
Training loss: 3.3933923915777515
Validation loss: 2.7047735798380583

Epoch: 5| Step: 5
Training loss: 2.9616009213075696
Validation loss: 2.6980851099001795

Epoch: 5| Step: 6
Training loss: 3.108150068374141
Validation loss: 2.7042673070587586

Epoch: 5| Step: 7
Training loss: 3.621242943975114
Validation loss: 2.7055993317492124

Epoch: 5| Step: 8
Training loss: 3.32551250093273
Validation loss: 2.705108355014915

Epoch: 5| Step: 9
Training loss: 2.8708638832301254
Validation loss: 2.710173923437632

Epoch: 5| Step: 10
Training loss: 3.1811046394758726
Validation loss: 2.7096320005400667

Epoch: 298| Step: 0
Training loss: 2.7057446261206923
Validation loss: 2.7160068770939603

Epoch: 5| Step: 1
Training loss: 3.1848998590892554
Validation loss: 2.722972237675144

Epoch: 5| Step: 2
Training loss: 3.0091281936229866
Validation loss: 2.727847585474138

Epoch: 5| Step: 3
Training loss: 3.2819558973772183
Validation loss: 2.737871671625865

Epoch: 5| Step: 4
Training loss: 3.446522887186716
Validation loss: 2.7178978815752752

Epoch: 5| Step: 5
Training loss: 3.0706013550906874
Validation loss: 2.710226959442258

Epoch: 5| Step: 6
Training loss: 3.3365759495443283
Validation loss: 2.7085483311081444

Epoch: 5| Step: 7
Training loss: 3.2765525981442387
Validation loss: 2.7158264482687144

Epoch: 5| Step: 8
Training loss: 2.715737438617779
Validation loss: 2.703378795740046

Epoch: 5| Step: 9
Training loss: 2.5767749372618916
Validation loss: 2.7028857292457844

Epoch: 5| Step: 10
Training loss: 2.3227902935418463
Validation loss: 2.7001383766103015

Epoch: 299| Step: 0
Training loss: 3.0754399860984543
Validation loss: 2.7054087224379155

Epoch: 5| Step: 1
Training loss: 2.70997976485577
Validation loss: 2.7027323628130926

Epoch: 5| Step: 2
Training loss: 3.139023253754241
Validation loss: 2.698666272250465

Epoch: 5| Step: 3
Training loss: 3.2518199813209168
Validation loss: 2.6964622419628865

Epoch: 5| Step: 4
Training loss: 2.721436149177543
Validation loss: 2.699563275377916

Epoch: 5| Step: 5
Training loss: 2.7743281264189985
Validation loss: 2.696616020140261

Epoch: 5| Step: 6
Training loss: 3.223348499276882
Validation loss: 2.7013303655807652

Epoch: 5| Step: 7
Training loss: 2.937311531676314
Validation loss: 2.7003286876789216

Epoch: 5| Step: 8
Training loss: 3.369103119130007
Validation loss: 2.6946790619332717

Epoch: 5| Step: 9
Training loss: 3.0297741000629252
Validation loss: 2.698279818446205

Epoch: 5| Step: 10
Training loss: 2.899525728577623
Validation loss: 2.7006228155142504

Epoch: 300| Step: 0
Training loss: 2.5119445604353867
Validation loss: 2.7024380855949364

Epoch: 5| Step: 1
Training loss: 2.5134963038735867
Validation loss: 2.7038784870180925

Epoch: 5| Step: 2
Training loss: 3.032003879202422
Validation loss: 2.7193023460966863

Epoch: 5| Step: 3
Training loss: 2.6824799604280636
Validation loss: 2.723496065016098

Epoch: 5| Step: 4
Training loss: 2.8241181203977614
Validation loss: 2.719866635407211

Epoch: 5| Step: 5
Training loss: 3.5900180180769548
Validation loss: 2.7303211591782186

Epoch: 5| Step: 6
Training loss: 2.973105037061652
Validation loss: 2.727611002245713

Epoch: 5| Step: 7
Training loss: 3.6924087697034587
Validation loss: 2.7039052166954454

Epoch: 5| Step: 8
Training loss: 3.2260772857489775
Validation loss: 2.697939171180331

Epoch: 5| Step: 9
Training loss: 2.838250512172707
Validation loss: 2.6972578930042084

Epoch: 5| Step: 10
Training loss: 3.1476618187524426
Validation loss: 2.6985443052865374

Epoch: 301| Step: 0
Training loss: 2.8946317379866424
Validation loss: 2.7005026789191358

Epoch: 5| Step: 1
Training loss: 3.089244606002861
Validation loss: 2.704580808019412

Epoch: 5| Step: 2
Training loss: 2.5757076142985387
Validation loss: 2.704203373302

Epoch: 5| Step: 3
Training loss: 3.215155659373503
Validation loss: 2.7076829935629037

Epoch: 5| Step: 4
Training loss: 3.125345745033816
Validation loss: 2.702323393069749

Epoch: 5| Step: 5
Training loss: 3.604456733688412
Validation loss: 2.700313718747873

Epoch: 5| Step: 6
Training loss: 2.8119956518006655
Validation loss: 2.700865682952966

Epoch: 5| Step: 7
Training loss: 2.228170463451299
Validation loss: 2.7129382348107165

Epoch: 5| Step: 8
Training loss: 2.9235211799262784
Validation loss: 2.718256031744552

Epoch: 5| Step: 9
Training loss: 3.356975177299263
Validation loss: 2.7195801938978432

Epoch: 5| Step: 10
Training loss: 3.3529567708301378
Validation loss: 2.7273110712751722

Epoch: 302| Step: 0
Training loss: 3.0187902096425954
Validation loss: 2.710357660744997

Epoch: 5| Step: 1
Training loss: 3.0500684386532626
Validation loss: 2.7149665965847563

Epoch: 5| Step: 2
Training loss: 2.428459617701544
Validation loss: 2.7131643581914826

Epoch: 5| Step: 3
Training loss: 3.3048742074732105
Validation loss: 2.7150274432220454

Epoch: 5| Step: 4
Training loss: 3.547246300172419
Validation loss: 2.701054823758012

Epoch: 5| Step: 5
Training loss: 2.8594475408639055
Validation loss: 2.7035424377664197

Epoch: 5| Step: 6
Training loss: 2.9162442219297198
Validation loss: 2.7055864746635283

Epoch: 5| Step: 7
Training loss: 2.8774894219675518
Validation loss: 2.7025378697624203

Epoch: 5| Step: 8
Training loss: 3.3075159832834204
Validation loss: 2.7042858071810447

Epoch: 5| Step: 9
Training loss: 2.557504856108738
Validation loss: 2.7063656501998428

Epoch: 5| Step: 10
Training loss: 3.1856480622724406
Validation loss: 2.7108751884245836

Epoch: 303| Step: 0
Training loss: 3.3532612370298693
Validation loss: 2.7011321469754663

Epoch: 5| Step: 1
Training loss: 2.9856125427714493
Validation loss: 2.704325202113269

Epoch: 5| Step: 2
Training loss: 2.793590641810505
Validation loss: 2.702248703395899

Epoch: 5| Step: 3
Training loss: 2.845750210070743
Validation loss: 2.69489454179775

Epoch: 5| Step: 4
Training loss: 2.6164291877458723
Validation loss: 2.69562013881808

Epoch: 5| Step: 5
Training loss: 2.958644975894166
Validation loss: 2.6934055825101746

Epoch: 5| Step: 6
Training loss: 3.5084779783560527
Validation loss: 2.693797797581361

Epoch: 5| Step: 7
Training loss: 2.9435681912594176
Validation loss: 2.695522934193798

Epoch: 5| Step: 8
Training loss: 2.609637675512605
Validation loss: 2.6955159409407234

Epoch: 5| Step: 9
Training loss: 3.3334165244847527
Validation loss: 2.6946484371133583

Epoch: 5| Step: 10
Training loss: 3.1383927796241147
Validation loss: 2.698773897428442

Epoch: 304| Step: 0
Training loss: 2.945612965443271
Validation loss: 2.6954691837347555

Epoch: 5| Step: 1
Training loss: 2.1086811195977333
Validation loss: 2.6962804833878504

Epoch: 5| Step: 2
Training loss: 2.870979981536326
Validation loss: 2.7024948720065742

Epoch: 5| Step: 3
Training loss: 2.308845932252604
Validation loss: 2.6953611241407684

Epoch: 5| Step: 4
Training loss: 3.1905056115659916
Validation loss: 2.71042680281538

Epoch: 5| Step: 5
Training loss: 3.0492489687423796
Validation loss: 2.717760170134497

Epoch: 5| Step: 6
Training loss: 3.459458011227382
Validation loss: 2.7228184029669387

Epoch: 5| Step: 7
Training loss: 3.1698623059328965
Validation loss: 2.736785332608534

Epoch: 5| Step: 8
Training loss: 3.1314767477508276
Validation loss: 2.7397976997346722

Epoch: 5| Step: 9
Training loss: 2.648348916521873
Validation loss: 2.725392739544357

Epoch: 5| Step: 10
Training loss: 4.038060312985505
Validation loss: 2.7203038223432685

Epoch: 305| Step: 0
Training loss: 2.9609859734344384
Validation loss: 2.732458097950237

Epoch: 5| Step: 1
Training loss: 3.0857999746847895
Validation loss: 2.7240359986750415

Epoch: 5| Step: 2
Training loss: 3.297656793691468
Validation loss: 2.7271534950658256

Epoch: 5| Step: 3
Training loss: 2.9061609069950327
Validation loss: 2.7143519661625386

Epoch: 5| Step: 4
Training loss: 3.3407536566629448
Validation loss: 2.69078163804953

Epoch: 5| Step: 5
Training loss: 2.5710271983775983
Validation loss: 2.6913550225401903

Epoch: 5| Step: 6
Training loss: 3.100472746457527
Validation loss: 2.6900800095486965

Epoch: 5| Step: 7
Training loss: 3.3620638709868698
Validation loss: 2.6919207813735846

Epoch: 5| Step: 8
Training loss: 2.28326609111075
Validation loss: 2.6978853358267108

Epoch: 5| Step: 9
Training loss: 2.607783214662932
Validation loss: 2.6963724542694107

Epoch: 5| Step: 10
Training loss: 3.536986965544769
Validation loss: 2.6971196029676285

Epoch: 306| Step: 0
Training loss: 2.8568621156911456
Validation loss: 2.699411635970701

Epoch: 5| Step: 1
Training loss: 2.4814847052043434
Validation loss: 2.705622679772548

Epoch: 5| Step: 2
Training loss: 3.697875088023658
Validation loss: 2.711381153026542

Epoch: 5| Step: 3
Training loss: 2.4354844196207317
Validation loss: 2.7086615433772203

Epoch: 5| Step: 4
Training loss: 3.533931557977563
Validation loss: 2.702658974486531

Epoch: 5| Step: 5
Training loss: 2.989596766708622
Validation loss: 2.7001566553188616

Epoch: 5| Step: 6
Training loss: 2.988522349087196
Validation loss: 2.6974637475744783

Epoch: 5| Step: 7
Training loss: 3.528686403085891
Validation loss: 2.6986277052637666

Epoch: 5| Step: 8
Training loss: 2.8646491765633635
Validation loss: 2.6954446910883587

Epoch: 5| Step: 9
Training loss: 3.1949025383114713
Validation loss: 2.697933390024661

Epoch: 5| Step: 10
Training loss: 2.173249831828584
Validation loss: 2.7002946046874476

Epoch: 307| Step: 0
Training loss: 3.333139572869916
Validation loss: 2.706504487008567

Epoch: 5| Step: 1
Training loss: 3.135229229737125
Validation loss: 2.7061230452158145

Epoch: 5| Step: 2
Training loss: 2.8365888031591764
Validation loss: 2.704951458151714

Epoch: 5| Step: 3
Training loss: 2.9298590444568733
Validation loss: 2.698685368395199

Epoch: 5| Step: 4
Training loss: 2.2140543504779004
Validation loss: 2.7042864252715955

Epoch: 5| Step: 5
Training loss: 3.113872706423871
Validation loss: 2.6978249483002625

Epoch: 5| Step: 6
Training loss: 3.392337630229801
Validation loss: 2.700296028776483

Epoch: 5| Step: 7
Training loss: 2.7132999559016326
Validation loss: 2.695511900766664

Epoch: 5| Step: 8
Training loss: 2.8734913060189693
Validation loss: 2.686847635253419

Epoch: 5| Step: 9
Training loss: 3.011041983279749
Validation loss: 2.6864265364210937

Epoch: 5| Step: 10
Training loss: 3.5354218272566946
Validation loss: 2.6852207654212004

Epoch: 308| Step: 0
Training loss: 3.436844225667836
Validation loss: 2.6871194858657543

Epoch: 5| Step: 1
Training loss: 2.7297081058381707
Validation loss: 2.6837963598496213

Epoch: 5| Step: 2
Training loss: 3.222239112444344
Validation loss: 2.684095103571079

Epoch: 5| Step: 3
Training loss: 2.814970330307276
Validation loss: 2.6892363416324314

Epoch: 5| Step: 4
Training loss: 3.2445399562793282
Validation loss: 2.6879313648113414

Epoch: 5| Step: 5
Training loss: 2.601529049586705
Validation loss: 2.687507251635281

Epoch: 5| Step: 6
Training loss: 3.123787453966123
Validation loss: 2.684322435156442

Epoch: 5| Step: 7
Training loss: 2.863378338384229
Validation loss: 2.6881982154392463

Epoch: 5| Step: 8
Training loss: 3.18072897610878
Validation loss: 2.6876031684580717

Epoch: 5| Step: 9
Training loss: 3.134628416487071
Validation loss: 2.68915829885028

Epoch: 5| Step: 10
Training loss: 2.5719437915598697
Validation loss: 2.6893381489530994

Epoch: 309| Step: 0
Training loss: 3.5102787311443953
Validation loss: 2.6981477862131316

Epoch: 5| Step: 1
Training loss: 2.8216760778598773
Validation loss: 2.69600603152404

Epoch: 5| Step: 2
Training loss: 2.7481569703259354
Validation loss: 2.693958023817866

Epoch: 5| Step: 3
Training loss: 2.6798987124646754
Validation loss: 2.690639046746474

Epoch: 5| Step: 4
Training loss: 2.9189379613176922
Validation loss: 2.6883848145069575

Epoch: 5| Step: 5
Training loss: 3.3968659373621346
Validation loss: 2.688757256785709

Epoch: 5| Step: 6
Training loss: 2.8762461408036333
Validation loss: 2.6870397968813178

Epoch: 5| Step: 7
Training loss: 2.669694869933147
Validation loss: 2.686004688189242

Epoch: 5| Step: 8
Training loss: 3.2644902498225545
Validation loss: 2.686176484495747

Epoch: 5| Step: 9
Training loss: 3.1031172000291414
Validation loss: 2.6852484679832176

Epoch: 5| Step: 10
Training loss: 2.974850460108838
Validation loss: 2.6876205527951726

Epoch: 310| Step: 0
Training loss: 3.299441816343861
Validation loss: 2.6886078081613087

Epoch: 5| Step: 1
Training loss: 2.5356524765034147
Validation loss: 2.687135356405289

Epoch: 5| Step: 2
Training loss: 2.889039630706538
Validation loss: 2.6909989838069412

Epoch: 5| Step: 3
Training loss: 3.021490687614608
Validation loss: 2.6876888909891354

Epoch: 5| Step: 4
Training loss: 3.1896885856805213
Validation loss: 2.697543299686702

Epoch: 5| Step: 5
Training loss: 2.9224962196293016
Validation loss: 2.696940646310543

Epoch: 5| Step: 6
Training loss: 2.9572345860262
Validation loss: 2.701584966653158

Epoch: 5| Step: 7
Training loss: 3.137654584138872
Validation loss: 2.6967717573600694

Epoch: 5| Step: 8
Training loss: 3.071768301491321
Validation loss: 2.6957940373984393

Epoch: 5| Step: 9
Training loss: 3.5381453717320306
Validation loss: 2.7023614149550874

Epoch: 5| Step: 10
Training loss: 2.2327459839295787
Validation loss: 2.688987878106298

Epoch: 311| Step: 0
Training loss: 3.3910765457086014
Validation loss: 2.692324029804627

Epoch: 5| Step: 1
Training loss: 2.9358874825789507
Validation loss: 2.686648340491219

Epoch: 5| Step: 2
Training loss: 2.9794771437263607
Validation loss: 2.6836306530360248

Epoch: 5| Step: 3
Training loss: 3.152726576767939
Validation loss: 2.685064464209309

Epoch: 5| Step: 4
Training loss: 2.986320460667078
Validation loss: 2.6789115730223934

Epoch: 5| Step: 5
Training loss: 2.3630523318558985
Validation loss: 2.681829688747815

Epoch: 5| Step: 6
Training loss: 2.899269334233078
Validation loss: 2.679849153429405

Epoch: 5| Step: 7
Training loss: 3.527426075529118
Validation loss: 2.6827913030223858

Epoch: 5| Step: 8
Training loss: 2.505157872020268
Validation loss: 2.6835445916547425

Epoch: 5| Step: 9
Training loss: 3.730897441418591
Validation loss: 2.6836965164817634

Epoch: 5| Step: 10
Training loss: 2.1177360696722847
Validation loss: 2.6859426075809734

Epoch: 312| Step: 0
Training loss: 3.321012535349533
Validation loss: 2.688166297034819

Epoch: 5| Step: 1
Training loss: 2.6784261954761863
Validation loss: 2.6913916353185243

Epoch: 5| Step: 2
Training loss: 2.805700347697622
Validation loss: 2.6922005718727715

Epoch: 5| Step: 3
Training loss: 2.8464346150404007
Validation loss: 2.688298535313988

Epoch: 5| Step: 4
Training loss: 2.799245330743966
Validation loss: 2.694934974400526

Epoch: 5| Step: 5
Training loss: 2.6225318204187507
Validation loss: 2.688558400604915

Epoch: 5| Step: 6
Training loss: 3.041182771277555
Validation loss: 2.68737253705755

Epoch: 5| Step: 7
Training loss: 3.1742209792921505
Validation loss: 2.687719736276115

Epoch: 5| Step: 8
Training loss: 3.9981191504672555
Validation loss: 2.682479855301285

Epoch: 5| Step: 9
Training loss: 2.5465640012741577
Validation loss: 2.679950124475165

Epoch: 5| Step: 10
Training loss: 2.948105840824928
Validation loss: 2.685574164198777

Epoch: 313| Step: 0
Training loss: 2.7801286815802286
Validation loss: 2.6849630534071167

Epoch: 5| Step: 1
Training loss: 2.725481228814351
Validation loss: 2.684283464385225

Epoch: 5| Step: 2
Training loss: 3.261173408284412
Validation loss: 2.6909257327767975

Epoch: 5| Step: 3
Training loss: 2.272822241099429
Validation loss: 2.693532419221856

Epoch: 5| Step: 4
Training loss: 3.032306447719838
Validation loss: 2.686989033825164

Epoch: 5| Step: 5
Training loss: 3.3925237305386777
Validation loss: 2.682967379925979

Epoch: 5| Step: 6
Training loss: 3.632843345593174
Validation loss: 2.6810880438128337

Epoch: 5| Step: 7
Training loss: 2.6919759692725016
Validation loss: 2.679765318263783

Epoch: 5| Step: 8
Training loss: 2.642791310893342
Validation loss: 2.680375624697972

Epoch: 5| Step: 9
Training loss: 3.5755113942836
Validation loss: 2.6795192974130106

Epoch: 5| Step: 10
Training loss: 2.682787467293212
Validation loss: 2.682326851333366

Epoch: 314| Step: 0
Training loss: 2.9801749988350754
Validation loss: 2.6775484430788197

Epoch: 5| Step: 1
Training loss: 3.55508024959419
Validation loss: 2.6777199298352365

Epoch: 5| Step: 2
Training loss: 3.1314491863437337
Validation loss: 2.6797361660974883

Epoch: 5| Step: 3
Training loss: 3.388454322537468
Validation loss: 2.6782486115456328

Epoch: 5| Step: 4
Training loss: 2.941222733526465
Validation loss: 2.6809454848654717

Epoch: 5| Step: 5
Training loss: 2.6740997154229125
Validation loss: 2.6873625471903972

Epoch: 5| Step: 6
Training loss: 2.973579093059518
Validation loss: 2.6834794304779916

Epoch: 5| Step: 7
Training loss: 2.8291249904643525
Validation loss: 2.6973996611134887

Epoch: 5| Step: 8
Training loss: 2.367170579302149
Validation loss: 2.686221488994075

Epoch: 5| Step: 9
Training loss: 2.9561630849179057
Validation loss: 2.684725467955705

Epoch: 5| Step: 10
Training loss: 3.0752550096916824
Validation loss: 2.682673360920185

Epoch: 315| Step: 0
Training loss: 3.0550719504616515
Validation loss: 2.6886216522788646

Epoch: 5| Step: 1
Training loss: 3.1926189532482026
Validation loss: 2.6872411127686537

Epoch: 5| Step: 2
Training loss: 2.441033565304533
Validation loss: 2.684136894647189

Epoch: 5| Step: 3
Training loss: 2.8788825646180527
Validation loss: 2.684403660248642

Epoch: 5| Step: 4
Training loss: 2.6921080185132813
Validation loss: 2.6835023070002757

Epoch: 5| Step: 5
Training loss: 2.9724591023139744
Validation loss: 2.679693572129186

Epoch: 5| Step: 6
Training loss: 3.0591147260448555
Validation loss: 2.680430484096573

Epoch: 5| Step: 7
Training loss: 2.531113420734165
Validation loss: 2.6883176192786684

Epoch: 5| Step: 8
Training loss: 3.451201718886243
Validation loss: 2.69222346760869

Epoch: 5| Step: 9
Training loss: 3.108012758825323
Validation loss: 2.694216848912123

Epoch: 5| Step: 10
Training loss: 3.5345965706393274
Validation loss: 2.6901660724605496

Epoch: 316| Step: 0
Training loss: 3.026862991060281
Validation loss: 2.689990699772727

Epoch: 5| Step: 1
Training loss: 2.6418762853911257
Validation loss: 2.6856009815541673

Epoch: 5| Step: 2
Training loss: 2.6323786980919857
Validation loss: 2.6906387494728863

Epoch: 5| Step: 3
Training loss: 2.7776107123256266
Validation loss: 2.689774678373295

Epoch: 5| Step: 4
Training loss: 2.726764660530134
Validation loss: 2.688368216114341

Epoch: 5| Step: 5
Training loss: 3.3401312810258377
Validation loss: 2.6808864590386565

Epoch: 5| Step: 6
Training loss: 2.797740951402103
Validation loss: 2.6832973504435644

Epoch: 5| Step: 7
Training loss: 3.405919890200284
Validation loss: 2.6851140005023635

Epoch: 5| Step: 8
Training loss: 3.680959558606251
Validation loss: 2.6824886888033643

Epoch: 5| Step: 9
Training loss: 2.9310377747708727
Validation loss: 2.6784216940222874

Epoch: 5| Step: 10
Training loss: 2.815534014824764
Validation loss: 2.676147278775525

Epoch: 317| Step: 0
Training loss: 3.1091426590035467
Validation loss: 2.673269356460297

Epoch: 5| Step: 1
Training loss: 2.919378509486708
Validation loss: 2.6766991990683753

Epoch: 5| Step: 2
Training loss: 3.217371080449304
Validation loss: 2.6792362009737203

Epoch: 5| Step: 3
Training loss: 2.7645487442286685
Validation loss: 2.6763358407068716

Epoch: 5| Step: 4
Training loss: 3.4187447500798784
Validation loss: 2.6750638764983132

Epoch: 5| Step: 5
Training loss: 2.959493239557298
Validation loss: 2.6799675536728444

Epoch: 5| Step: 6
Training loss: 2.4878621130142204
Validation loss: 2.681361644323306

Epoch: 5| Step: 7
Training loss: 3.0618165479703863
Validation loss: 2.6799240512552087

Epoch: 5| Step: 8
Training loss: 3.536300153757571
Validation loss: 2.6802687404288945

Epoch: 5| Step: 9
Training loss: 2.3970363637229224
Validation loss: 2.6811750837949666

Epoch: 5| Step: 10
Training loss: 2.8939478565572267
Validation loss: 2.687274867150743

Epoch: 318| Step: 0
Training loss: 3.045129207381591
Validation loss: 2.6864826387775813

Epoch: 5| Step: 1
Training loss: 2.4032171383024394
Validation loss: 2.6845392944662563

Epoch: 5| Step: 2
Training loss: 3.3085675199115214
Validation loss: 2.695192148578099

Epoch: 5| Step: 3
Training loss: 3.55267666124439
Validation loss: 2.6902248051077655

Epoch: 5| Step: 4
Training loss: 2.5762140763696553
Validation loss: 2.6749347662521186

Epoch: 5| Step: 5
Training loss: 2.95549215075077
Validation loss: 2.6758783047251753

Epoch: 5| Step: 6
Training loss: 3.081650317574914
Validation loss: 2.674835693822776

Epoch: 5| Step: 7
Training loss: 3.0629599089656177
Validation loss: 2.672047489846941

Epoch: 5| Step: 8
Training loss: 2.9817690031665145
Validation loss: 2.6670916824915927

Epoch: 5| Step: 9
Training loss: 2.8010111651894336
Validation loss: 2.6740460616318056

Epoch: 5| Step: 10
Training loss: 3.0584228779696705
Validation loss: 2.6671901895271004

Epoch: 319| Step: 0
Training loss: 3.242058955941997
Validation loss: 2.6681161377741267

Epoch: 5| Step: 1
Training loss: 2.8643713485424813
Validation loss: 2.67195282703831

Epoch: 5| Step: 2
Training loss: 3.1944092310931858
Validation loss: 2.6722100151048176

Epoch: 5| Step: 3
Training loss: 3.138661240356128
Validation loss: 2.6699990110006446

Epoch: 5| Step: 4
Training loss: 2.626302486804836
Validation loss: 2.6708107218536234

Epoch: 5| Step: 5
Training loss: 3.5403872404207126
Validation loss: 2.6736827991131134

Epoch: 5| Step: 6
Training loss: 2.710795637920732
Validation loss: 2.677346888632794

Epoch: 5| Step: 7
Training loss: 3.0339063822737455
Validation loss: 2.669934459261473

Epoch: 5| Step: 8
Training loss: 2.9790003447799767
Validation loss: 2.676455051540276

Epoch: 5| Step: 9
Training loss: 3.181707017368595
Validation loss: 2.6788990070069727

Epoch: 5| Step: 10
Training loss: 2.077879927102401
Validation loss: 2.6742117746978584

Epoch: 320| Step: 0
Training loss: 3.2334518220827073
Validation loss: 2.675420130897825

Epoch: 5| Step: 1
Training loss: 3.3751782970662907
Validation loss: 2.6736580992168375

Epoch: 5| Step: 2
Training loss: 3.0423990874532594
Validation loss: 2.673234401977239

Epoch: 5| Step: 3
Training loss: 3.255550633044494
Validation loss: 2.671159742676063

Epoch: 5| Step: 4
Training loss: 2.950158299223707
Validation loss: 2.6730608340057693

Epoch: 5| Step: 5
Training loss: 2.943521212942499
Validation loss: 2.6739832412756983

Epoch: 5| Step: 6
Training loss: 2.5894185863659587
Validation loss: 2.673910959369011

Epoch: 5| Step: 7
Training loss: 2.8259691483365232
Validation loss: 2.6740345599365694

Epoch: 5| Step: 8
Training loss: 2.796995703793807
Validation loss: 2.675282858551996

Epoch: 5| Step: 9
Training loss: 2.981200921956243
Validation loss: 2.6767184394789703

Epoch: 5| Step: 10
Training loss: 2.859981451707995
Validation loss: 2.689195165564717

Epoch: 321| Step: 0
Training loss: 3.1262270235104257
Validation loss: 2.6783285716682266

Epoch: 5| Step: 1
Training loss: 2.488553929022598
Validation loss: 2.6718517754137925

Epoch: 5| Step: 2
Training loss: 2.8145624016454756
Validation loss: 2.677400067419685

Epoch: 5| Step: 3
Training loss: 3.292730972194513
Validation loss: 2.670438687339382

Epoch: 5| Step: 4
Training loss: 3.916098181408462
Validation loss: 2.67315392600328

Epoch: 5| Step: 5
Training loss: 2.888371429397569
Validation loss: 2.670751582428041

Epoch: 5| Step: 6
Training loss: 2.490209003394036
Validation loss: 2.671298966833438

Epoch: 5| Step: 7
Training loss: 3.0753371883456104
Validation loss: 2.6671055296762862

Epoch: 5| Step: 8
Training loss: 2.969527453967335
Validation loss: 2.6669974330246236

Epoch: 5| Step: 9
Training loss: 3.2443572723603937
Validation loss: 2.67157703641146

Epoch: 5| Step: 10
Training loss: 2.1473384751135254
Validation loss: 2.678493702977172

Epoch: 322| Step: 0
Training loss: 3.2425781014712083
Validation loss: 2.689697262169891

Epoch: 5| Step: 1
Training loss: 2.9708103459036432
Validation loss: 2.6805180571032317

Epoch: 5| Step: 2
Training loss: 2.2937393063496043
Validation loss: 2.6826838565736737

Epoch: 5| Step: 3
Training loss: 3.821265353395654
Validation loss: 2.679729037413013

Epoch: 5| Step: 4
Training loss: 3.2958754339475016
Validation loss: 2.6745215339099477

Epoch: 5| Step: 5
Training loss: 3.30343337193997
Validation loss: 2.6775177400916124

Epoch: 5| Step: 6
Training loss: 2.591268248358076
Validation loss: 2.671525912366198

Epoch: 5| Step: 7
Training loss: 2.7389507264367032
Validation loss: 2.6705781468384266

Epoch: 5| Step: 8
Training loss: 2.431824949088197
Validation loss: 2.662517541926475

Epoch: 5| Step: 9
Training loss: 2.9997852566473044
Validation loss: 2.669608599374174

Epoch: 5| Step: 10
Training loss: 2.969046166353675
Validation loss: 2.6646838985253547

Epoch: 323| Step: 0
Training loss: 3.596714555093344
Validation loss: 2.6650167960955327

Epoch: 5| Step: 1
Training loss: 2.4173349464980625
Validation loss: 2.6660029876227966

Epoch: 5| Step: 2
Training loss: 2.640113826234091
Validation loss: 2.6657891124196826

Epoch: 5| Step: 3
Training loss: 2.899696426287418
Validation loss: 2.6687337691731443

Epoch: 5| Step: 4
Training loss: 2.979844574171321
Validation loss: 2.6727070151335086

Epoch: 5| Step: 5
Training loss: 2.643832453891602
Validation loss: 2.6854006596621063

Epoch: 5| Step: 6
Training loss: 3.731252601916558
Validation loss: 2.689798145649152

Epoch: 5| Step: 7
Training loss: 3.115786435948542
Validation loss: 2.6998551604458707

Epoch: 5| Step: 8
Training loss: 2.963440815707424
Validation loss: 2.700922493406951

Epoch: 5| Step: 9
Training loss: 2.5070361305253503
Validation loss: 2.697855082841734

Epoch: 5| Step: 10
Training loss: 3.196746578974559
Validation loss: 2.6990508470479617

Epoch: 324| Step: 0
Training loss: 2.9583024753161102
Validation loss: 2.6917804933074736

Epoch: 5| Step: 1
Training loss: 3.0419210214388186
Validation loss: 2.6786282400814905

Epoch: 5| Step: 2
Training loss: 2.5661969382573955
Validation loss: 2.6903716025294555

Epoch: 5| Step: 3
Training loss: 3.1508405805166606
Validation loss: 2.668167942080807

Epoch: 5| Step: 4
Training loss: 3.334272697330861
Validation loss: 2.6783626738347976

Epoch: 5| Step: 5
Training loss: 2.3320286940875334
Validation loss: 2.6633165572361155

Epoch: 5| Step: 6
Training loss: 3.2002625119298687
Validation loss: 2.662557996323986

Epoch: 5| Step: 7
Training loss: 3.1083613137902537
Validation loss: 2.6616383862837654

Epoch: 5| Step: 8
Training loss: 3.2215247184898055
Validation loss: 2.6646237995599162

Epoch: 5| Step: 9
Training loss: 3.0932308493551437
Validation loss: 2.6657935111482005

Epoch: 5| Step: 10
Training loss: 2.7087066882111857
Validation loss: 2.662039053081288

Epoch: 325| Step: 0
Training loss: 2.944893318925335
Validation loss: 2.66884540824302

Epoch: 5| Step: 1
Training loss: 3.267239842116444
Validation loss: 2.6634440337034384

Epoch: 5| Step: 2
Training loss: 3.2525598275079513
Validation loss: 2.6636673819512864

Epoch: 5| Step: 3
Training loss: 2.831685391057888
Validation loss: 2.6627832982130974

Epoch: 5| Step: 4
Training loss: 3.14304088080215
Validation loss: 2.6574539303346265

Epoch: 5| Step: 5
Training loss: 2.6638131570332586
Validation loss: 2.655969929995261

Epoch: 5| Step: 6
Training loss: 3.322546066297787
Validation loss: 2.6608280193010554

Epoch: 5| Step: 7
Training loss: 2.4821815644526675
Validation loss: 2.6676115591055547

Epoch: 5| Step: 8
Training loss: 3.1912015478069677
Validation loss: 2.6786923535812037

Epoch: 5| Step: 9
Training loss: 2.8067434102286257
Validation loss: 2.6710013152291205

Epoch: 5| Step: 10
Training loss: 2.8164959812552115
Validation loss: 2.6698864810865244

Epoch: 326| Step: 0
Training loss: 3.118426772130795
Validation loss: 2.6791375072144468

Epoch: 5| Step: 1
Training loss: 3.4959401698983337
Validation loss: 2.6870485352507414

Epoch: 5| Step: 2
Training loss: 2.4560821592337856
Validation loss: 2.673170366641374

Epoch: 5| Step: 3
Training loss: 2.889779456940169
Validation loss: 2.6677975916270587

Epoch: 5| Step: 4
Training loss: 2.4903801849162677
Validation loss: 2.662872860058741

Epoch: 5| Step: 5
Training loss: 3.6814217337946578
Validation loss: 2.6643311995322736

Epoch: 5| Step: 6
Training loss: 2.8740776904601555
Validation loss: 2.667206569847381

Epoch: 5| Step: 7
Training loss: 2.8631648395183946
Validation loss: 2.6587060025297724

Epoch: 5| Step: 8
Training loss: 2.853958586372958
Validation loss: 2.6632108057381267

Epoch: 5| Step: 9
Training loss: 3.1967152545353645
Validation loss: 2.657114772950024

Epoch: 5| Step: 10
Training loss: 2.7052669087441976
Validation loss: 2.661936803611764

Epoch: 327| Step: 0
Training loss: 3.1271136955669587
Validation loss: 2.663053133768394

Epoch: 5| Step: 1
Training loss: 3.516360600125816
Validation loss: 2.666021017647368

Epoch: 5| Step: 2
Training loss: 2.7640964572819615
Validation loss: 2.659373720153167

Epoch: 5| Step: 3
Training loss: 2.5029821728975654
Validation loss: 2.661938783690021

Epoch: 5| Step: 4
Training loss: 3.156499267404013
Validation loss: 2.6572394384306826

Epoch: 5| Step: 5
Training loss: 2.701025969232526
Validation loss: 2.6581586607243834

Epoch: 5| Step: 6
Training loss: 2.9706326588556626
Validation loss: 2.6601611302638077

Epoch: 5| Step: 7
Training loss: 3.229831028348029
Validation loss: 2.662395065776372

Epoch: 5| Step: 8
Training loss: 2.9727650044782528
Validation loss: 2.6621390943168604

Epoch: 5| Step: 9
Training loss: 2.537008446498549
Validation loss: 2.6693403763294543

Epoch: 5| Step: 10
Training loss: 3.268208043408871
Validation loss: 2.6680720001263567

Epoch: 328| Step: 0
Training loss: 2.900623741157849
Validation loss: 2.666108109122641

Epoch: 5| Step: 1
Training loss: 2.5410346720257984
Validation loss: 2.663694013709396

Epoch: 5| Step: 2
Training loss: 2.405767318071802
Validation loss: 2.6657557687828586

Epoch: 5| Step: 3
Training loss: 3.2376424161597885
Validation loss: 2.6679104652524956

Epoch: 5| Step: 4
Training loss: 2.70128414557896
Validation loss: 2.676413903933138

Epoch: 5| Step: 5
Training loss: 2.8904275362769885
Validation loss: 2.6680460327891473

Epoch: 5| Step: 6
Training loss: 3.355359751803952
Validation loss: 2.666762573942728

Epoch: 5| Step: 7
Training loss: 3.1774693655822817
Validation loss: 2.670336073067521

Epoch: 5| Step: 8
Training loss: 3.3550233556443305
Validation loss: 2.664994237066604

Epoch: 5| Step: 9
Training loss: 3.0155124149158663
Validation loss: 2.6615614886212366

Epoch: 5| Step: 10
Training loss: 3.097532945754834
Validation loss: 2.661340292874443

Epoch: 329| Step: 0
Training loss: 3.064926898576167
Validation loss: 2.657335826480333

Epoch: 5| Step: 1
Training loss: 2.6860707940651865
Validation loss: 2.6634939518857026

Epoch: 5| Step: 2
Training loss: 2.972344721788104
Validation loss: 2.664241655918863

Epoch: 5| Step: 3
Training loss: 2.841075435970248
Validation loss: 2.663623104175279

Epoch: 5| Step: 4
Training loss: 3.083001471178543
Validation loss: 2.6621063174382904

Epoch: 5| Step: 5
Training loss: 3.0960153319992005
Validation loss: 2.6684018387434576

Epoch: 5| Step: 6
Training loss: 3.6632301670319367
Validation loss: 2.6628853775084846

Epoch: 5| Step: 7
Training loss: 2.699451662826683
Validation loss: 2.6738377502791177

Epoch: 5| Step: 8
Training loss: 2.927014568421627
Validation loss: 2.6771371966169113

Epoch: 5| Step: 9
Training loss: 2.748564605636444
Validation loss: 2.676218017399895

Epoch: 5| Step: 10
Training loss: 2.8885370085043935
Validation loss: 2.671561821937963

Epoch: 330| Step: 0
Training loss: 3.4099630014867888
Validation loss: 2.6794753370792863

Epoch: 5| Step: 1
Training loss: 3.0613600497171034
Validation loss: 2.6588733967241573

Epoch: 5| Step: 2
Training loss: 3.073635487077457
Validation loss: 2.6578590301941145

Epoch: 5| Step: 3
Training loss: 2.8469592420087753
Validation loss: 2.657107705625413

Epoch: 5| Step: 4
Training loss: 2.5023098764976286
Validation loss: 2.6608633111474433

Epoch: 5| Step: 5
Training loss: 3.339881013361201
Validation loss: 2.655144104999247

Epoch: 5| Step: 6
Training loss: 2.4578436886505526
Validation loss: 2.6583575868639744

Epoch: 5| Step: 7
Training loss: 2.692045935807115
Validation loss: 2.6600947621493507

Epoch: 5| Step: 8
Training loss: 3.05385974488526
Validation loss: 2.659051715433765

Epoch: 5| Step: 9
Training loss: 3.5703330675864087
Validation loss: 2.660271448435786

Epoch: 5| Step: 10
Training loss: 2.6818873326007573
Validation loss: 2.659638989571137

Epoch: 331| Step: 0
Training loss: 2.7163045123020075
Validation loss: 2.658474005004911

Epoch: 5| Step: 1
Training loss: 3.0775561121667883
Validation loss: 2.6517181062126967

Epoch: 5| Step: 2
Training loss: 2.888134187354784
Validation loss: 2.6522027449597907

Epoch: 5| Step: 3
Training loss: 3.248598236613707
Validation loss: 2.656318015109074

Epoch: 5| Step: 4
Training loss: 2.9057585598122846
Validation loss: 2.6561351879190647

Epoch: 5| Step: 5
Training loss: 2.710625974141747
Validation loss: 2.6638862027795494

Epoch: 5| Step: 6
Training loss: 3.02736454125925
Validation loss: 2.6711117250845167

Epoch: 5| Step: 7
Training loss: 3.3868347640884817
Validation loss: 2.6748238514453595

Epoch: 5| Step: 8
Training loss: 2.7305958817864107
Validation loss: 2.670394252071775

Epoch: 5| Step: 9
Training loss: 3.0633842592983966
Validation loss: 2.665523359589307

Epoch: 5| Step: 10
Training loss: 3.0087121980302753
Validation loss: 2.6702534052627414

Epoch: 332| Step: 0
Training loss: 2.7195662226917205
Validation loss: 2.6753802552404626

Epoch: 5| Step: 1
Training loss: 3.113790319695483
Validation loss: 2.674775049486074

Epoch: 5| Step: 2
Training loss: 3.166629456418577
Validation loss: 2.6632304824323376

Epoch: 5| Step: 3
Training loss: 2.5959428456955047
Validation loss: 2.6595397902789153

Epoch: 5| Step: 4
Training loss: 3.0632816796276954
Validation loss: 2.6538189316270007

Epoch: 5| Step: 5
Training loss: 2.4795143033303764
Validation loss: 2.6511620548343897

Epoch: 5| Step: 6
Training loss: 3.0868190616807563
Validation loss: 2.652353229971221

Epoch: 5| Step: 7
Training loss: 2.6276988732945368
Validation loss: 2.6505460175262234

Epoch: 5| Step: 8
Training loss: 3.4033379662382877
Validation loss: 2.651540411988776

Epoch: 5| Step: 9
Training loss: 2.8780686960087163
Validation loss: 2.6557304795978642

Epoch: 5| Step: 10
Training loss: 3.6589993304397708
Validation loss: 2.6551151580335923

Epoch: 333| Step: 0
Training loss: 2.3824628729794486
Validation loss: 2.654600572565831

Epoch: 5| Step: 1
Training loss: 2.6253223221300774
Validation loss: 2.656555571282911

Epoch: 5| Step: 2
Training loss: 3.643645249393823
Validation loss: 2.661505893529318

Epoch: 5| Step: 3
Training loss: 3.09660146296264
Validation loss: 2.6655911448120184

Epoch: 5| Step: 4
Training loss: 2.648659035748578
Validation loss: 2.6675770436796613

Epoch: 5| Step: 5
Training loss: 2.9216572889520966
Validation loss: 2.6638557349754297

Epoch: 5| Step: 6
Training loss: 3.0311065325262714
Validation loss: 2.6729014968150664

Epoch: 5| Step: 7
Training loss: 3.3560033157023077
Validation loss: 2.664330563512749

Epoch: 5| Step: 8
Training loss: 2.823259752734185
Validation loss: 2.6622540673239627

Epoch: 5| Step: 9
Training loss: 3.2621260154609404
Validation loss: 2.6631314438740152

Epoch: 5| Step: 10
Training loss: 2.7623693409395744
Validation loss: 2.6567402010330805

Epoch: 334| Step: 0
Training loss: 3.0358603113780114
Validation loss: 2.657562338961332

Epoch: 5| Step: 1
Training loss: 3.589577018450324
Validation loss: 2.6494089137596544

Epoch: 5| Step: 2
Training loss: 3.069550941503156
Validation loss: 2.6516910564041147

Epoch: 5| Step: 3
Training loss: 2.9394029986901247
Validation loss: 2.6547170728975784

Epoch: 5| Step: 4
Training loss: 2.780774279424551
Validation loss: 2.649515120348623

Epoch: 5| Step: 5
Training loss: 2.8243111032077604
Validation loss: 2.6521166439129926

Epoch: 5| Step: 6
Training loss: 3.0588137180939134
Validation loss: 2.6459250747114393

Epoch: 5| Step: 7
Training loss: 2.2165058230601757
Validation loss: 2.652468314003473

Epoch: 5| Step: 8
Training loss: 2.879199899425542
Validation loss: 2.650488002048409

Epoch: 5| Step: 9
Training loss: 3.2919009322489794
Validation loss: 2.6505983765618075

Epoch: 5| Step: 10
Training loss: 2.953804704867448
Validation loss: 2.650911541012134

Epoch: 335| Step: 0
Training loss: 3.0449322106343186
Validation loss: 2.65958831802245

Epoch: 5| Step: 1
Training loss: 2.9526612255706346
Validation loss: 2.658080894675819

Epoch: 5| Step: 2
Training loss: 3.4541480848842556
Validation loss: 2.6639088385569845

Epoch: 5| Step: 3
Training loss: 3.3391158175105313
Validation loss: 2.666157681268711

Epoch: 5| Step: 4
Training loss: 2.6926040973570102
Validation loss: 2.6756723320535114

Epoch: 5| Step: 5
Training loss: 2.7929197507174734
Validation loss: 2.6819734806172844

Epoch: 5| Step: 6
Training loss: 2.7564757135747793
Validation loss: 2.6886338524735183

Epoch: 5| Step: 7
Training loss: 3.2463847373054633
Validation loss: 2.685203769397777

Epoch: 5| Step: 8
Training loss: 2.622909167346934
Validation loss: 2.6639349203235105

Epoch: 5| Step: 9
Training loss: 3.0055777831165456
Validation loss: 2.6590877404371636

Epoch: 5| Step: 10
Training loss: 2.7251559676585826
Validation loss: 2.651715850702908

Epoch: 336| Step: 0
Training loss: 3.0637161020172488
Validation loss: 2.6469404809183144

Epoch: 5| Step: 1
Training loss: 3.262274670766834
Validation loss: 2.649104350047065

Epoch: 5| Step: 2
Training loss: 3.102591010148989
Validation loss: 2.648061819750038

Epoch: 5| Step: 3
Training loss: 3.3575675892790526
Validation loss: 2.64931365977456

Epoch: 5| Step: 4
Training loss: 3.074012604021828
Validation loss: 2.648543149289408

Epoch: 5| Step: 5
Training loss: 3.1683543543257904
Validation loss: 2.650595758368614

Epoch: 5| Step: 6
Training loss: 2.777880223822264
Validation loss: 2.6454604398579846

Epoch: 5| Step: 7
Training loss: 2.847662613054448
Validation loss: 2.653058698760058

Epoch: 5| Step: 8
Training loss: 2.633749232063489
Validation loss: 2.6477140783572266

Epoch: 5| Step: 9
Training loss: 2.381902702368639
Validation loss: 2.6474999845284892

Epoch: 5| Step: 10
Training loss: 2.996606496928905
Validation loss: 2.6508905969015095

Epoch: 337| Step: 0
Training loss: 3.5924978977481263
Validation loss: 2.6547192819184846

Epoch: 5| Step: 1
Training loss: 3.0395397605849404
Validation loss: 2.659105507874737

Epoch: 5| Step: 2
Training loss: 2.9955971516413675
Validation loss: 2.6522993866093407

Epoch: 5| Step: 3
Training loss: 2.4796683394251264
Validation loss: 2.651653554175784

Epoch: 5| Step: 4
Training loss: 2.4833040628265657
Validation loss: 2.6486602543360873

Epoch: 5| Step: 5
Training loss: 2.646651844764672
Validation loss: 2.654787645257679

Epoch: 5| Step: 6
Training loss: 3.170034842555384
Validation loss: 2.655889981101099

Epoch: 5| Step: 7
Training loss: 2.522724818635414
Validation loss: 2.6553030209221866

Epoch: 5| Step: 8
Training loss: 3.2538140731523124
Validation loss: 2.658563025443893

Epoch: 5| Step: 9
Training loss: 3.018160845839304
Validation loss: 2.6624994949170104

Epoch: 5| Step: 10
Training loss: 3.3568442104577465
Validation loss: 2.6637826123635757

Epoch: 338| Step: 0
Training loss: 3.179540232404292
Validation loss: 2.6571559955803954

Epoch: 5| Step: 1
Training loss: 3.1824159655147968
Validation loss: 2.668177478245093

Epoch: 5| Step: 2
Training loss: 3.0736012014244705
Validation loss: 2.6672838266630556

Epoch: 5| Step: 3
Training loss: 2.8394867516537885
Validation loss: 2.664050719436274

Epoch: 5| Step: 4
Training loss: 3.151847261378257
Validation loss: 2.6621251509996053

Epoch: 5| Step: 5
Training loss: 2.568633670446777
Validation loss: 2.6645247002200847

Epoch: 5| Step: 6
Training loss: 3.4914615567825225
Validation loss: 2.651238660413384

Epoch: 5| Step: 7
Training loss: 3.018396082758946
Validation loss: 2.650096586003118

Epoch: 5| Step: 8
Training loss: 2.3849674673680674
Validation loss: 2.6506716472017686

Epoch: 5| Step: 9
Training loss: 2.834063622847442
Validation loss: 2.6487908480487925

Epoch: 5| Step: 10
Training loss: 2.8078365233619014
Validation loss: 2.6499909048065606

Epoch: 339| Step: 0
Training loss: 2.873695741118815
Validation loss: 2.6463050844821474

Epoch: 5| Step: 1
Training loss: 2.894694335296873
Validation loss: 2.6512917517647927

Epoch: 5| Step: 2
Training loss: 2.9253850243324173
Validation loss: 2.649646125704002

Epoch: 5| Step: 3
Training loss: 2.8361769225724993
Validation loss: 2.6564096141056646

Epoch: 5| Step: 4
Training loss: 3.147257164759946
Validation loss: 2.6574768765434755

Epoch: 5| Step: 5
Training loss: 3.258192008255298
Validation loss: 2.6543378352248586

Epoch: 5| Step: 6
Training loss: 2.82501403670073
Validation loss: 2.660288071800601

Epoch: 5| Step: 7
Training loss: 3.020649415479286
Validation loss: 2.6576250723879173

Epoch: 5| Step: 8
Training loss: 2.5303028359687354
Validation loss: 2.663131584419659

Epoch: 5| Step: 9
Training loss: 3.0770147034867468
Validation loss: 2.6656690072084994

Epoch: 5| Step: 10
Training loss: 3.3014861488450356
Validation loss: 2.65979981619598

Epoch: 340| Step: 0
Training loss: 3.0673971142415715
Validation loss: 2.668442341316988

Epoch: 5| Step: 1
Training loss: 3.4168589157973535
Validation loss: 2.6745593902911438

Epoch: 5| Step: 2
Training loss: 2.835462630266306
Validation loss: 2.6617647257182826

Epoch: 5| Step: 3
Training loss: 2.9544309927369645
Validation loss: 2.6686247691701435

Epoch: 5| Step: 4
Training loss: 3.0290842086154193
Validation loss: 2.65872591890975

Epoch: 5| Step: 5
Training loss: 2.87999689154987
Validation loss: 2.662178150431842

Epoch: 5| Step: 6
Training loss: 3.171605742352652
Validation loss: 2.6522929550256524

Epoch: 5| Step: 7
Training loss: 2.7087359984933363
Validation loss: 2.6504186630776077

Epoch: 5| Step: 8
Training loss: 2.904285382143535
Validation loss: 2.6494155507076176

Epoch: 5| Step: 9
Training loss: 2.5879353069550675
Validation loss: 2.6546809330545247

Epoch: 5| Step: 10
Training loss: 3.0704819338884652
Validation loss: 2.649020040283054

Epoch: 341| Step: 0
Training loss: 3.3687593194553083
Validation loss: 2.651706321080364

Epoch: 5| Step: 1
Training loss: 2.8510663162594927
Validation loss: 2.6510117149550783

Epoch: 5| Step: 2
Training loss: 2.7182607977954474
Validation loss: 2.652581810931878

Epoch: 5| Step: 3
Training loss: 3.1849765138344046
Validation loss: 2.655037801078064

Epoch: 5| Step: 4
Training loss: 2.80157399895899
Validation loss: 2.6521329926360124

Epoch: 5| Step: 5
Training loss: 3.2129905059037807
Validation loss: 2.6607571123948386

Epoch: 5| Step: 6
Training loss: 2.7112774814393052
Validation loss: 2.654579306030613

Epoch: 5| Step: 7
Training loss: 2.711884346985649
Validation loss: 2.656673977123694

Epoch: 5| Step: 8
Training loss: 3.1071020665490092
Validation loss: 2.6601705881587394

Epoch: 5| Step: 9
Training loss: 2.693883190712366
Validation loss: 2.659651325605047

Epoch: 5| Step: 10
Training loss: 3.3043202586191605
Validation loss: 2.656499027013329

Epoch: 342| Step: 0
Training loss: 2.669265275654783
Validation loss: 2.650898652720211

Epoch: 5| Step: 1
Training loss: 2.994467083576646
Validation loss: 2.6472710616139414

Epoch: 5| Step: 2
Training loss: 3.1851461358432593
Validation loss: 2.649410369070851

Epoch: 5| Step: 3
Training loss: 3.5440552379875836
Validation loss: 2.64266920880519

Epoch: 5| Step: 4
Training loss: 2.773941381108771
Validation loss: 2.6493488156760203

Epoch: 5| Step: 5
Training loss: 2.76623502566098
Validation loss: 2.642219890431531

Epoch: 5| Step: 6
Training loss: 2.8734534706555563
Validation loss: 2.641664135865298

Epoch: 5| Step: 7
Training loss: 2.9740602884447718
Validation loss: 2.642160991103634

Epoch: 5| Step: 8
Training loss: 2.8368496859627705
Validation loss: 2.643906104994409

Epoch: 5| Step: 9
Training loss: 2.9019096532490667
Validation loss: 2.6420415932938637

Epoch: 5| Step: 10
Training loss: 3.1315011112236135
Validation loss: 2.645634728431187

Epoch: 343| Step: 0
Training loss: 3.340633615709262
Validation loss: 2.6511466429424093

Epoch: 5| Step: 1
Training loss: 2.9035595982266496
Validation loss: 2.6619953520546207

Epoch: 5| Step: 2
Training loss: 3.087160587573837
Validation loss: 2.6531288577032317

Epoch: 5| Step: 3
Training loss: 2.744150529619581
Validation loss: 2.66623872802103

Epoch: 5| Step: 4
Training loss: 2.960519081686897
Validation loss: 2.6747352495150714

Epoch: 5| Step: 5
Training loss: 2.3257204477744717
Validation loss: 2.693854644793151

Epoch: 5| Step: 6
Training loss: 2.8147548537625413
Validation loss: 2.6850024000538926

Epoch: 5| Step: 7
Training loss: 2.970146412949279
Validation loss: 2.6881431273679253

Epoch: 5| Step: 8
Training loss: 3.325100379518566
Validation loss: 2.6869280646062914

Epoch: 5| Step: 9
Training loss: 2.8469408180509084
Validation loss: 2.681450814620109

Epoch: 5| Step: 10
Training loss: 3.2790262588887473
Validation loss: 2.6776336861378054

Epoch: 344| Step: 0
Training loss: 2.932663527512249
Validation loss: 2.6535479213261253

Epoch: 5| Step: 1
Training loss: 3.2086292146924564
Validation loss: 2.638022681057061

Epoch: 5| Step: 2
Training loss: 2.11960601618529
Validation loss: 2.6353228742556825

Epoch: 5| Step: 3
Training loss: 3.3969911501064245
Validation loss: 2.638017203964796

Epoch: 5| Step: 4
Training loss: 2.886525974883011
Validation loss: 2.6393377519972288

Epoch: 5| Step: 5
Training loss: 2.686504978239927
Validation loss: 2.6409311415021133

Epoch: 5| Step: 6
Training loss: 2.9754000418835655
Validation loss: 2.634249268657165

Epoch: 5| Step: 7
Training loss: 3.0794210271258278
Validation loss: 2.6359829770644176

Epoch: 5| Step: 8
Training loss: 3.185968217986951
Validation loss: 2.638650930895115

Epoch: 5| Step: 9
Training loss: 3.1687895702773075
Validation loss: 2.6479655375340894

Epoch: 5| Step: 10
Training loss: 2.9197742437595213
Validation loss: 2.644419135112203

Epoch: 345| Step: 0
Training loss: 2.454620294361176
Validation loss: 2.647811509301747

Epoch: 5| Step: 1
Training loss: 3.4123723715366068
Validation loss: 2.646746822603414

Epoch: 5| Step: 2
Training loss: 2.896829740135751
Validation loss: 2.641166259220209

Epoch: 5| Step: 3
Training loss: 3.3703277177250466
Validation loss: 2.647695293334775

Epoch: 5| Step: 4
Training loss: 3.1472664067832126
Validation loss: 2.637827204213603

Epoch: 5| Step: 5
Training loss: 3.192084213580042
Validation loss: 2.6444138147476

Epoch: 5| Step: 6
Training loss: 2.8162342288832427
Validation loss: 2.639333643311889

Epoch: 5| Step: 7
Training loss: 2.3567929317780143
Validation loss: 2.6409344682041183

Epoch: 5| Step: 8
Training loss: 2.608238658060244
Validation loss: 2.6500718994122834

Epoch: 5| Step: 9
Training loss: 2.6321837809324795
Validation loss: 2.6617250760155606

Epoch: 5| Step: 10
Training loss: 3.550452490968581
Validation loss: 2.6694683238197983

Epoch: 346| Step: 0
Training loss: 3.214956028995044
Validation loss: 2.679262868390692

Epoch: 5| Step: 1
Training loss: 2.640838253281082
Validation loss: 2.6882740126210067

Epoch: 5| Step: 2
Training loss: 3.228559637952415
Validation loss: 2.6662323762153823

Epoch: 5| Step: 3
Training loss: 3.0813612602527676
Validation loss: 2.6725734010685707

Epoch: 5| Step: 4
Training loss: 3.0924877327480647
Validation loss: 2.6613892304109594

Epoch: 5| Step: 5
Training loss: 2.2360645655282267
Validation loss: 2.658278270095484

Epoch: 5| Step: 6
Training loss: 2.846660424195115
Validation loss: 2.6639778543084125

Epoch: 5| Step: 7
Training loss: 3.231482202683054
Validation loss: 2.644776540604884

Epoch: 5| Step: 8
Training loss: 2.9414161388134734
Validation loss: 2.642625010899644

Epoch: 5| Step: 9
Training loss: 3.292110236175105
Validation loss: 2.6424439207915946

Epoch: 5| Step: 10
Training loss: 2.582248418911832
Validation loss: 2.6359351706486476

Epoch: 347| Step: 0
Training loss: 2.902296761585481
Validation loss: 2.6332753710782026

Epoch: 5| Step: 1
Training loss: 2.191033044270767
Validation loss: 2.6328170151682597

Epoch: 5| Step: 2
Training loss: 2.8256280319106475
Validation loss: 2.6326796768778005

Epoch: 5| Step: 3
Training loss: 3.3024753534406592
Validation loss: 2.637782770646007

Epoch: 5| Step: 4
Training loss: 3.3663513136617498
Validation loss: 2.6352713611030816

Epoch: 5| Step: 5
Training loss: 3.280169063723528
Validation loss: 2.640802545289156

Epoch: 5| Step: 6
Training loss: 2.990165485408283
Validation loss: 2.640657726050342

Epoch: 5| Step: 7
Training loss: 2.7704506707845367
Validation loss: 2.6403199464002043

Epoch: 5| Step: 8
Training loss: 2.950237335744234
Validation loss: 2.6472069763848265

Epoch: 5| Step: 9
Training loss: 2.9702422557633854
Validation loss: 2.646831196059315

Epoch: 5| Step: 10
Training loss: 2.949397888806144
Validation loss: 2.6448261752521094

Epoch: 348| Step: 0
Training loss: 3.239272680239847
Validation loss: 2.643829108533701

Epoch: 5| Step: 1
Training loss: 3.2463854717179608
Validation loss: 2.637601427784361

Epoch: 5| Step: 2
Training loss: 2.7493432734680057
Validation loss: 2.6483732310030517

Epoch: 5| Step: 3
Training loss: 2.871124475016295
Validation loss: 2.6416591078851726

Epoch: 5| Step: 4
Training loss: 3.1194521677343006
Validation loss: 2.6504367681649987

Epoch: 5| Step: 5
Training loss: 2.5882928269412653
Validation loss: 2.649880109301161

Epoch: 5| Step: 6
Training loss: 2.7897132093087365
Validation loss: 2.6518780665601187

Epoch: 5| Step: 7
Training loss: 2.816850984249657
Validation loss: 2.658268710956415

Epoch: 5| Step: 8
Training loss: 3.057377949958762
Validation loss: 2.6704476057923117

Epoch: 5| Step: 9
Training loss: 2.865757723431403
Validation loss: 2.6770344972295796

Epoch: 5| Step: 10
Training loss: 3.207165658343609
Validation loss: 2.67587816484903

Epoch: 349| Step: 0
Training loss: 2.506914494958729
Validation loss: 2.6965844285911884

Epoch: 5| Step: 1
Training loss: 3.09307715295123
Validation loss: 2.6930352738449677

Epoch: 5| Step: 2
Training loss: 2.9167883348065344
Validation loss: 2.6819923056212787

Epoch: 5| Step: 3
Training loss: 3.0864495347552374
Validation loss: 2.6452208134491704

Epoch: 5| Step: 4
Training loss: 3.0818867425921153
Validation loss: 2.6377501901868037

Epoch: 5| Step: 5
Training loss: 2.800963923882824
Validation loss: 2.6273274287497532

Epoch: 5| Step: 6
Training loss: 2.5993303683742544
Validation loss: 2.631227361959578

Epoch: 5| Step: 7
Training loss: 3.1008321445062648
Validation loss: 2.629207751590134

Epoch: 5| Step: 8
Training loss: 3.5329475036227884
Validation loss: 2.6305304698060765

Epoch: 5| Step: 9
Training loss: 3.231976638048549
Validation loss: 2.627384053435567

Epoch: 5| Step: 10
Training loss: 2.5592752029655115
Validation loss: 2.62958778282608

Epoch: 350| Step: 0
Training loss: 2.888027364289467
Validation loss: 2.632059583545314

Epoch: 5| Step: 1
Training loss: 2.8050707711932312
Validation loss: 2.6280365533706953

Epoch: 5| Step: 2
Training loss: 3.020138066401023
Validation loss: 2.629576129568252

Epoch: 5| Step: 3
Training loss: 2.9272465417144153
Validation loss: 2.6296743290483198

Epoch: 5| Step: 4
Training loss: 2.9497608217166476
Validation loss: 2.6313149785753316

Epoch: 5| Step: 5
Training loss: 3.6390281744419517
Validation loss: 2.630427457506174

Epoch: 5| Step: 6
Training loss: 2.7455558412813232
Validation loss: 2.632539836963597

Epoch: 5| Step: 7
Training loss: 2.787804413326094
Validation loss: 2.6371856210490923

Epoch: 5| Step: 8
Training loss: 2.765207205211998
Validation loss: 2.644547318926419

Epoch: 5| Step: 9
Training loss: 3.1056413326651553
Validation loss: 2.651742267020401

Epoch: 5| Step: 10
Training loss: 2.8388816326601876
Validation loss: 2.6560620824754486

Epoch: 351| Step: 0
Training loss: 2.6580947752991535
Validation loss: 2.66368182536527

Epoch: 5| Step: 1
Training loss: 2.794619369930461
Validation loss: 2.6600099487559663

Epoch: 5| Step: 2
Training loss: 3.3000727327596744
Validation loss: 2.662760114676051

Epoch: 5| Step: 3
Training loss: 2.6269634714596433
Validation loss: 2.6632068792378893

Epoch: 5| Step: 4
Training loss: 3.1564237339058057
Validation loss: 2.65052148794229

Epoch: 5| Step: 5
Training loss: 2.9296861979163773
Validation loss: 2.63972969117227

Epoch: 5| Step: 6
Training loss: 3.2413086217013833
Validation loss: 2.642073031656763

Epoch: 5| Step: 7
Training loss: 2.56227669091773
Validation loss: 2.63357650291677

Epoch: 5| Step: 8
Training loss: 3.554238360189834
Validation loss: 2.6296063238103513

Epoch: 5| Step: 9
Training loss: 2.846027845341637
Validation loss: 2.6309252089854893

Epoch: 5| Step: 10
Training loss: 2.682239262831288
Validation loss: 2.627428996557306

Epoch: 352| Step: 0
Training loss: 2.9298989181528534
Validation loss: 2.6254458197783035

Epoch: 5| Step: 1
Training loss: 3.287724093497783
Validation loss: 2.6254897180860315

Epoch: 5| Step: 2
Training loss: 2.7129807920693443
Validation loss: 2.6264894442750433

Epoch: 5| Step: 3
Training loss: 2.8123882695363185
Validation loss: 2.6297958987988688

Epoch: 5| Step: 4
Training loss: 2.9076124709754687
Validation loss: 2.6241469288673254

Epoch: 5| Step: 5
Training loss: 3.0641084456512675
Validation loss: 2.6288212553985724

Epoch: 5| Step: 6
Training loss: 2.9592824854987216
Validation loss: 2.633264481833534

Epoch: 5| Step: 7
Training loss: 3.022895863043203
Validation loss: 2.6365462183135935

Epoch: 5| Step: 8
Training loss: 2.9280623747847114
Validation loss: 2.6371158924546867

Epoch: 5| Step: 9
Training loss: 2.555471784029506
Validation loss: 2.642504778378897

Epoch: 5| Step: 10
Training loss: 3.401530785121444
Validation loss: 2.640791224018192

Epoch: 353| Step: 0
Training loss: 2.5017247925913457
Validation loss: 2.642670390380843

Epoch: 5| Step: 1
Training loss: 2.2812583609649866
Validation loss: 2.6437550577102567

Epoch: 5| Step: 2
Training loss: 3.445017553320736
Validation loss: 2.649174174372804

Epoch: 5| Step: 3
Training loss: 3.139361530679845
Validation loss: 2.6424246093303694

Epoch: 5| Step: 4
Training loss: 3.006076856928842
Validation loss: 2.6511381720689084

Epoch: 5| Step: 5
Training loss: 2.7805492075431513
Validation loss: 2.6570187039674944

Epoch: 5| Step: 6
Training loss: 2.853264454904519
Validation loss: 2.6533039044245483

Epoch: 5| Step: 7
Training loss: 2.5308973278621334
Validation loss: 2.655416360969274

Epoch: 5| Step: 8
Training loss: 3.127859104680924
Validation loss: 2.651729787847142

Epoch: 5| Step: 9
Training loss: 3.334116382812421
Validation loss: 2.648217511076786

Epoch: 5| Step: 10
Training loss: 3.3449855910191864
Validation loss: 2.6512188270311463

Epoch: 354| Step: 0
Training loss: 2.6869416654932103
Validation loss: 2.6407884601917138

Epoch: 5| Step: 1
Training loss: 2.998638161867094
Validation loss: 2.6438957501743547

Epoch: 5| Step: 2
Training loss: 2.4514621030868686
Validation loss: 2.648277632897341

Epoch: 5| Step: 3
Training loss: 2.827227370983588
Validation loss: 2.646540185870898

Epoch: 5| Step: 4
Training loss: 2.4863325360207336
Validation loss: 2.65760852256004

Epoch: 5| Step: 5
Training loss: 2.9096641585313407
Validation loss: 2.648712275594724

Epoch: 5| Step: 6
Training loss: 3.2119406365292447
Validation loss: 2.6541679875183863

Epoch: 5| Step: 7
Training loss: 2.886984187041562
Validation loss: 2.6480250241715266

Epoch: 5| Step: 8
Training loss: 3.6428328601444564
Validation loss: 2.6506333539046802

Epoch: 5| Step: 9
Training loss: 3.1163087146306303
Validation loss: 2.6426320480783327

Epoch: 5| Step: 10
Training loss: 3.1903604874171902
Validation loss: 2.633039959619323

Epoch: 355| Step: 0
Training loss: 3.4026636965219494
Validation loss: 2.639587017760281

Epoch: 5| Step: 1
Training loss: 2.687613994930874
Validation loss: 2.638270156795586

Epoch: 5| Step: 2
Training loss: 2.6602154919809853
Validation loss: 2.651131172940908

Epoch: 5| Step: 3
Training loss: 3.1702715950513074
Validation loss: 2.663735862114616

Epoch: 5| Step: 4
Training loss: 3.2724033807139974
Validation loss: 2.6807390360586774

Epoch: 5| Step: 5
Training loss: 2.8134840197532203
Validation loss: 2.682607452285202

Epoch: 5| Step: 6
Training loss: 2.990590438722791
Validation loss: 2.6773177355080824

Epoch: 5| Step: 7
Training loss: 3.105128009264426
Validation loss: 2.6849078655386083

Epoch: 5| Step: 8
Training loss: 2.746707679417647
Validation loss: 2.6784644867213685

Epoch: 5| Step: 9
Training loss: 2.9670768439945983
Validation loss: 2.6774684232739085

Epoch: 5| Step: 10
Training loss: 2.855172492860853
Validation loss: 2.6797877883429293

Epoch: 356| Step: 0
Training loss: 2.614845890879716
Validation loss: 2.674948873291029

Epoch: 5| Step: 1
Training loss: 3.1164320410337583
Validation loss: 2.6772854910891755

Epoch: 5| Step: 2
Training loss: 2.8208180658630684
Validation loss: 2.6747556398258534

Epoch: 5| Step: 3
Training loss: 3.2974252829137654
Validation loss: 2.6760794333097575

Epoch: 5| Step: 4
Training loss: 2.779483105337254
Validation loss: 2.6698664684010573

Epoch: 5| Step: 5
Training loss: 3.3664167544328745
Validation loss: 2.661372539751783

Epoch: 5| Step: 6
Training loss: 2.6600400924529373
Validation loss: 2.6553385783286507

Epoch: 5| Step: 7
Training loss: 2.993546538317919
Validation loss: 2.6454960229595117

Epoch: 5| Step: 8
Training loss: 3.1594964884143697
Validation loss: 2.624222544103581

Epoch: 5| Step: 9
Training loss: 2.8517471044697427
Validation loss: 2.636637162405087

Epoch: 5| Step: 10
Training loss: 3.080503522660703
Validation loss: 2.637602619405914

Epoch: 357| Step: 0
Training loss: 2.7315624486078534
Validation loss: 2.6359143681924513

Epoch: 5| Step: 1
Training loss: 2.9665700839604847
Validation loss: 2.638231508583016

Epoch: 5| Step: 2
Training loss: 3.009014890046327
Validation loss: 2.645383664044765

Epoch: 5| Step: 3
Training loss: 2.576892627597483
Validation loss: 2.664815624304839

Epoch: 5| Step: 4
Training loss: 3.0508148543183657
Validation loss: 2.683392493902095

Epoch: 5| Step: 5
Training loss: 3.0227661964689934
Validation loss: 2.6829887362877467

Epoch: 5| Step: 6
Training loss: 3.188937592291404
Validation loss: 2.6740001830236713

Epoch: 5| Step: 7
Training loss: 3.3226828338399126
Validation loss: 2.6541168401263455

Epoch: 5| Step: 8
Training loss: 2.435916777712883
Validation loss: 2.642374580298701

Epoch: 5| Step: 9
Training loss: 3.2021266963275354
Validation loss: 2.631202081322835

Epoch: 5| Step: 10
Training loss: 3.0356889451195417
Validation loss: 2.6358304895140803

Epoch: 358| Step: 0
Training loss: 2.641953715263337
Validation loss: 2.6304990942566278

Epoch: 5| Step: 1
Training loss: 3.1421430724051027
Validation loss: 2.622002641932788

Epoch: 5| Step: 2
Training loss: 2.9942207300826276
Validation loss: 2.6289546942402873

Epoch: 5| Step: 3
Training loss: 3.2191733665176048
Validation loss: 2.6206675011223233

Epoch: 5| Step: 4
Training loss: 3.138387917644766
Validation loss: 2.6230522406580934

Epoch: 5| Step: 5
Training loss: 2.7289012944929776
Validation loss: 2.625532384385667

Epoch: 5| Step: 6
Training loss: 3.1788508933763056
Validation loss: 2.6240593064094226

Epoch: 5| Step: 7
Training loss: 2.7241813514883915
Validation loss: 2.6167837052760374

Epoch: 5| Step: 8
Training loss: 3.167690881097535
Validation loss: 2.621176457136738

Epoch: 5| Step: 9
Training loss: 2.4040869366291333
Validation loss: 2.622929934157173

Epoch: 5| Step: 10
Training loss: 3.1608919058362086
Validation loss: 2.6184368478959974

Epoch: 359| Step: 0
Training loss: 3.119911323167489
Validation loss: 2.6228925602312634

Epoch: 5| Step: 1
Training loss: 2.9778410801240085
Validation loss: 2.622771225694047

Epoch: 5| Step: 2
Training loss: 2.3749391648381497
Validation loss: 2.6223025782516785

Epoch: 5| Step: 3
Training loss: 2.6577856673602347
Validation loss: 2.6227731649638892

Epoch: 5| Step: 4
Training loss: 3.2014697752632038
Validation loss: 2.629613278839301

Epoch: 5| Step: 5
Training loss: 3.2203902722425117
Validation loss: 2.6211708069379984

Epoch: 5| Step: 6
Training loss: 3.1232702427058996
Validation loss: 2.6241022871005115

Epoch: 5| Step: 7
Training loss: 3.4106563800013405
Validation loss: 2.624800113386395

Epoch: 5| Step: 8
Training loss: 2.906187323437898
Validation loss: 2.6210043352915524

Epoch: 5| Step: 9
Training loss: 2.55384369426676
Validation loss: 2.6187779909784292

Epoch: 5| Step: 10
Training loss: 2.808233373279808
Validation loss: 2.626610996486025

Epoch: 360| Step: 0
Training loss: 2.607248227627183
Validation loss: 2.631091362776609

Epoch: 5| Step: 1
Training loss: 2.9066342335679294
Validation loss: 2.6285694219016555

Epoch: 5| Step: 2
Training loss: 2.8392175458897446
Validation loss: 2.640594559914117

Epoch: 5| Step: 3
Training loss: 3.0592601532464836
Validation loss: 2.6419359033138443

Epoch: 5| Step: 4
Training loss: 3.4844082544219597
Validation loss: 2.658701869777865

Epoch: 5| Step: 5
Training loss: 2.8491190435537823
Validation loss: 2.6572920519648426

Epoch: 5| Step: 6
Training loss: 3.299700931522097
Validation loss: 2.6659789358609958

Epoch: 5| Step: 7
Training loss: 3.354435753937601
Validation loss: 2.6472890904194855

Epoch: 5| Step: 8
Training loss: 2.057949479279104
Validation loss: 2.654940492413356

Epoch: 5| Step: 9
Training loss: 2.5609500198104773
Validation loss: 2.6479913522887513

Epoch: 5| Step: 10
Training loss: 3.231391156948366
Validation loss: 2.6375727927427093

Epoch: 361| Step: 0
Training loss: 3.1954657557512958
Validation loss: 2.6268753895997627

Epoch: 5| Step: 1
Training loss: 2.4244139130221294
Validation loss: 2.6308653854000723

Epoch: 5| Step: 2
Training loss: 3.4273598664711113
Validation loss: 2.631821629077836

Epoch: 5| Step: 3
Training loss: 2.879280221321903
Validation loss: 2.6265034079121405

Epoch: 5| Step: 4
Training loss: 3.1675078295435557
Validation loss: 2.631054785873156

Epoch: 5| Step: 5
Training loss: 2.782083107974622
Validation loss: 2.6333973869263607

Epoch: 5| Step: 6
Training loss: 2.7970345733982547
Validation loss: 2.6344198984373124

Epoch: 5| Step: 7
Training loss: 3.324081471855159
Validation loss: 2.634083267345392

Epoch: 5| Step: 8
Training loss: 2.652519748337385
Validation loss: 2.634109441022563

Epoch: 5| Step: 9
Training loss: 2.6112813781343087
Validation loss: 2.6345548646186177

Epoch: 5| Step: 10
Training loss: 3.0504417474746717
Validation loss: 2.6349633011036238

Epoch: 362| Step: 0
Training loss: 2.859026444666735
Validation loss: 2.633536963250119

Epoch: 5| Step: 1
Training loss: 1.6887514630811835
Validation loss: 2.632602290238014

Epoch: 5| Step: 2
Training loss: 2.718187032707921
Validation loss: 2.639250646498458

Epoch: 5| Step: 3
Training loss: 2.961540382224574
Validation loss: 2.6405042628115822

Epoch: 5| Step: 4
Training loss: 3.169834175706523
Validation loss: 2.650117278101437

Epoch: 5| Step: 5
Training loss: 2.850657698383742
Validation loss: 2.64001433511548

Epoch: 5| Step: 6
Training loss: 2.9738071133748054
Validation loss: 2.647554687552118

Epoch: 5| Step: 7
Training loss: 3.1772409535482664
Validation loss: 2.6403824491607337

Epoch: 5| Step: 8
Training loss: 3.1536886567731863
Validation loss: 2.6372964939613315

Epoch: 5| Step: 9
Training loss: 3.7274042294516283
Validation loss: 2.6277669591154234

Epoch: 5| Step: 10
Training loss: 2.7071372007302994
Validation loss: 2.6428319227092443

Epoch: 363| Step: 0
Training loss: 3.1767516583190467
Validation loss: 2.6470085478305814

Epoch: 5| Step: 1
Training loss: 2.76784551240086
Validation loss: 2.6375337659296387

Epoch: 5| Step: 2
Training loss: 2.984616254871432
Validation loss: 2.6401434678555806

Epoch: 5| Step: 3
Training loss: 2.996383871780762
Validation loss: 2.637248239892945

Epoch: 5| Step: 4
Training loss: 2.820179774999791
Validation loss: 2.6435679005863535

Epoch: 5| Step: 5
Training loss: 2.760080242649082
Validation loss: 2.638754229374201

Epoch: 5| Step: 6
Training loss: 2.8515213636801695
Validation loss: 2.6448827083353907

Epoch: 5| Step: 7
Training loss: 3.187244779055448
Validation loss: 2.6486793219151212

Epoch: 5| Step: 8
Training loss: 2.681336365489235
Validation loss: 2.6711306477522814

Epoch: 5| Step: 9
Training loss: 3.3540027333511744
Validation loss: 2.6648651685450515

Epoch: 5| Step: 10
Training loss: 2.739277395902591
Validation loss: 2.6637237702047125

Epoch: 364| Step: 0
Training loss: 2.7009407876906226
Validation loss: 2.666736219893689

Epoch: 5| Step: 1
Training loss: 2.1965001921989065
Validation loss: 2.6604548181581906

Epoch: 5| Step: 2
Training loss: 3.0817403716506875
Validation loss: 2.66396704533341

Epoch: 5| Step: 3
Training loss: 3.3292419278673666
Validation loss: 2.6605956277120626

Epoch: 5| Step: 4
Training loss: 2.5941759242370424
Validation loss: 2.672598605952997

Epoch: 5| Step: 5
Training loss: 2.935445675910754
Validation loss: 2.672939257690586

Epoch: 5| Step: 6
Training loss: 2.9026547415504
Validation loss: 2.6601629680701526

Epoch: 5| Step: 7
Training loss: 2.939976399125849
Validation loss: 2.6509870223803604

Epoch: 5| Step: 8
Training loss: 2.631124436379461
Validation loss: 2.635866883435109

Epoch: 5| Step: 9
Training loss: 3.3521080729012405
Validation loss: 2.6323260190176345

Epoch: 5| Step: 10
Training loss: 3.5877444300304955
Validation loss: 2.6325205653266246

Epoch: 365| Step: 0
Training loss: 2.5936289379868214
Validation loss: 2.6335380583914274

Epoch: 5| Step: 1
Training loss: 3.046093962895126
Validation loss: 2.629221007524953

Epoch: 5| Step: 2
Training loss: 3.1832339592513548
Validation loss: 2.632614718878799

Epoch: 5| Step: 3
Training loss: 3.2035629345252246
Validation loss: 2.6328187347666434

Epoch: 5| Step: 4
Training loss: 2.1689248665881204
Validation loss: 2.6246867874413518

Epoch: 5| Step: 5
Training loss: 3.093459915278768
Validation loss: 2.6331624605180823

Epoch: 5| Step: 6
Training loss: 3.1808471064826955
Validation loss: 2.62230100035702

Epoch: 5| Step: 7
Training loss: 2.9273771815023704
Validation loss: 2.6233438100442874

Epoch: 5| Step: 8
Training loss: 3.2065117028345678
Validation loss: 2.624827257675125

Epoch: 5| Step: 9
Training loss: 2.721045916802518
Validation loss: 2.6288705262135412

Epoch: 5| Step: 10
Training loss: 2.907060571659518
Validation loss: 2.633693440211751

Epoch: 366| Step: 0
Training loss: 2.7392425808678573
Validation loss: 2.645674760746738

Epoch: 5| Step: 1
Training loss: 2.900924397169506
Validation loss: 2.6440979430265243

Epoch: 5| Step: 2
Training loss: 3.0539890281015496
Validation loss: 2.6476780283476264

Epoch: 5| Step: 3
Training loss: 3.068120042583589
Validation loss: 2.640028422400908

Epoch: 5| Step: 4
Training loss: 3.1690080586526856
Validation loss: 2.6499840032598136

Epoch: 5| Step: 5
Training loss: 2.6018540044373153
Validation loss: 2.6404587528957615

Epoch: 5| Step: 6
Training loss: 2.6893396512917005
Validation loss: 2.634938602131094

Epoch: 5| Step: 7
Training loss: 2.806046095748836
Validation loss: 2.644205817717205

Epoch: 5| Step: 8
Training loss: 3.336629255341033
Validation loss: 2.638397405336113

Epoch: 5| Step: 9
Training loss: 2.8181416195438396
Validation loss: 2.626396760777476

Epoch: 5| Step: 10
Training loss: 3.213461076827469
Validation loss: 2.634872589181664

Epoch: 367| Step: 0
Training loss: 3.1863236594113307
Validation loss: 2.634060791819844

Epoch: 5| Step: 1
Training loss: 2.999599906945192
Validation loss: 2.6325964347434936

Epoch: 5| Step: 2
Training loss: 2.607759626708512
Validation loss: 2.640851653725241

Epoch: 5| Step: 3
Training loss: 2.413934204247859
Validation loss: 2.6408519857261092

Epoch: 5| Step: 4
Training loss: 3.2822519861500483
Validation loss: 2.6474299214085475

Epoch: 5| Step: 5
Training loss: 2.8159020934261836
Validation loss: 2.6533509061108487

Epoch: 5| Step: 6
Training loss: 3.281136356383954
Validation loss: 2.6581513801395382

Epoch: 5| Step: 7
Training loss: 2.60149184122443
Validation loss: 2.6449239946352505

Epoch: 5| Step: 8
Training loss: 2.7702829392733785
Validation loss: 2.647202428623026

Epoch: 5| Step: 9
Training loss: 2.8651842816322306
Validation loss: 2.649259594969165

Epoch: 5| Step: 10
Training loss: 3.4628205354141355
Validation loss: 2.6396280557062273

Epoch: 368| Step: 0
Training loss: 2.157666611763627
Validation loss: 2.631983197999869

Epoch: 5| Step: 1
Training loss: 2.598739971602092
Validation loss: 2.6301457626192533

Epoch: 5| Step: 2
Training loss: 2.561214031303895
Validation loss: 2.618353632717724

Epoch: 5| Step: 3
Training loss: 2.812023376769223
Validation loss: 2.622300608327283

Epoch: 5| Step: 4
Training loss: 3.330259686216184
Validation loss: 2.6156855277702644

Epoch: 5| Step: 5
Training loss: 3.646344713949741
Validation loss: 2.632525860062134

Epoch: 5| Step: 6
Training loss: 3.0876061672227677
Validation loss: 2.641403609651127

Epoch: 5| Step: 7
Training loss: 2.9700266452197748
Validation loss: 2.646573057695461

Epoch: 5| Step: 8
Training loss: 2.98449275398621
Validation loss: 2.6467210267057726

Epoch: 5| Step: 9
Training loss: 3.2341197922129137
Validation loss: 2.6403415462507747

Epoch: 5| Step: 10
Training loss: 2.6618783896774634
Validation loss: 2.6308671793576144

Epoch: 369| Step: 0
Training loss: 2.248955908228203
Validation loss: 2.6224961124429944

Epoch: 5| Step: 1
Training loss: 2.3508200249559486
Validation loss: 2.6196725580509685

Epoch: 5| Step: 2
Training loss: 2.889992639604851
Validation loss: 2.610954301413964

Epoch: 5| Step: 3
Training loss: 2.988840008524648
Validation loss: 2.6178793254656267

Epoch: 5| Step: 4
Training loss: 3.0077773054962043
Validation loss: 2.624759065320712

Epoch: 5| Step: 5
Training loss: 2.9108959512412387
Validation loss: 2.616391839520281

Epoch: 5| Step: 6
Training loss: 3.31556387223856
Validation loss: 2.627497756748017

Epoch: 5| Step: 7
Training loss: 3.124974059950932
Validation loss: 2.6324738013551015

Epoch: 5| Step: 8
Training loss: 2.992492022842317
Validation loss: 2.626888336225628

Epoch: 5| Step: 9
Training loss: 3.4744658244833735
Validation loss: 2.631738699285738

Epoch: 5| Step: 10
Training loss: 2.798858365563034
Validation loss: 2.6289394671370805

Epoch: 370| Step: 0
Training loss: 3.0160217024227234
Validation loss: 2.6205370124546126

Epoch: 5| Step: 1
Training loss: 2.58077709308753
Validation loss: 2.6256262271048487

Epoch: 5| Step: 2
Training loss: 3.0327201502957317
Validation loss: 2.6185486071754047

Epoch: 5| Step: 3
Training loss: 3.07768161116959
Validation loss: 2.6203690701945863

Epoch: 5| Step: 4
Training loss: 2.8046682033034385
Validation loss: 2.621731247929029

Epoch: 5| Step: 5
Training loss: 3.28418941536063
Validation loss: 2.6241227543140515

Epoch: 5| Step: 6
Training loss: 3.399651111205013
Validation loss: 2.62891525181442

Epoch: 5| Step: 7
Training loss: 2.5470627791564846
Validation loss: 2.631846870644546

Epoch: 5| Step: 8
Training loss: 2.804986879314668
Validation loss: 2.6333861535619874

Epoch: 5| Step: 9
Training loss: 3.1757411602347383
Validation loss: 2.6307812638859334

Epoch: 5| Step: 10
Training loss: 2.231063843556127
Validation loss: 2.6347825318839893

Epoch: 371| Step: 0
Training loss: 2.7876388378378874
Validation loss: 2.6385207554312866

Epoch: 5| Step: 1
Training loss: 2.2827848731738087
Validation loss: 2.634877720597734

Epoch: 5| Step: 2
Training loss: 3.1615810883690014
Validation loss: 2.6282387289634315

Epoch: 5| Step: 3
Training loss: 2.9898159100562345
Validation loss: 2.6269771407859763

Epoch: 5| Step: 4
Training loss: 2.435702908556879
Validation loss: 2.6232004262192543

Epoch: 5| Step: 5
Training loss: 2.7756485842635006
Validation loss: 2.632176379803152

Epoch: 5| Step: 6
Training loss: 3.058615264232284
Validation loss: 2.6413560702249264

Epoch: 5| Step: 7
Training loss: 3.2603009643175103
Validation loss: 2.648603914161475

Epoch: 5| Step: 8
Training loss: 3.1855131950913456
Validation loss: 2.664196718918843

Epoch: 5| Step: 9
Training loss: 3.253045928902904
Validation loss: 2.656642445208503

Epoch: 5| Step: 10
Training loss: 2.8490047323201684
Validation loss: 2.657482858577723

Epoch: 372| Step: 0
Training loss: 3.3816608115932514
Validation loss: 2.6697668876492053

Epoch: 5| Step: 1
Training loss: 2.529417528492927
Validation loss: 2.6947800224307548

Epoch: 5| Step: 2
Training loss: 3.2587502865632065
Validation loss: 2.71806856563446

Epoch: 5| Step: 3
Training loss: 2.60364657485523
Validation loss: 2.67015113815133

Epoch: 5| Step: 4
Training loss: 2.5404605713735
Validation loss: 2.6711039471343234

Epoch: 5| Step: 5
Training loss: 2.8014710240660423
Validation loss: 2.675864075643126

Epoch: 5| Step: 6
Training loss: 2.7210313718109527
Validation loss: 2.657056237568529

Epoch: 5| Step: 7
Training loss: 2.728290349225187
Validation loss: 2.66094761273531

Epoch: 5| Step: 8
Training loss: 3.1752408214160415
Validation loss: 2.6240449213884403

Epoch: 5| Step: 9
Training loss: 3.5924199835905846
Validation loss: 2.624685476653867

Epoch: 5| Step: 10
Training loss: 2.7847831658099724
Validation loss: 2.622945292909413

Epoch: 373| Step: 0
Training loss: 3.085031728967758
Validation loss: 2.6206511136018986

Epoch: 5| Step: 1
Training loss: 2.885074048868773
Validation loss: 2.619423178458645

Epoch: 5| Step: 2
Training loss: 3.018286286746943
Validation loss: 2.621134490647728

Epoch: 5| Step: 3
Training loss: 2.866049392540784
Validation loss: 2.6162406284814743

Epoch: 5| Step: 4
Training loss: 2.625502492856622
Validation loss: 2.612953750560403

Epoch: 5| Step: 5
Training loss: 2.595529520330247
Validation loss: 2.6127209981228097

Epoch: 5| Step: 6
Training loss: 2.9625777479826243
Validation loss: 2.6173769264439635

Epoch: 5| Step: 7
Training loss: 3.5442893396586252
Validation loss: 2.621484030806067

Epoch: 5| Step: 8
Training loss: 3.0955014906238683
Validation loss: 2.641343468217271

Epoch: 5| Step: 9
Training loss: 2.8420431862757205
Validation loss: 2.654930766758168

Epoch: 5| Step: 10
Training loss: 2.686883367723744
Validation loss: 2.6697478266411037

Epoch: 374| Step: 0
Training loss: 2.8338549825625914
Validation loss: 2.6731792098080853

Epoch: 5| Step: 1
Training loss: 3.0561473119291738
Validation loss: 2.687378287510456

Epoch: 5| Step: 2
Training loss: 3.2812369210118804
Validation loss: 2.687301599801522

Epoch: 5| Step: 3
Training loss: 3.2142726534623502
Validation loss: 2.660472805803626

Epoch: 5| Step: 4
Training loss: 3.329750631119678
Validation loss: 2.657505616424336

Epoch: 5| Step: 5
Training loss: 2.765956535510898
Validation loss: 2.6311426849496513

Epoch: 5| Step: 6
Training loss: 2.973584545226085
Validation loss: 2.6243377432217208

Epoch: 5| Step: 7
Training loss: 2.8454810941500783
Validation loss: 2.61877301009956

Epoch: 5| Step: 8
Training loss: 2.5424697316036244
Validation loss: 2.6153051947610906

Epoch: 5| Step: 9
Training loss: 2.5216982490022466
Validation loss: 2.6192405077039513

Epoch: 5| Step: 10
Training loss: 2.8756640123566055
Validation loss: 2.619567417879271

Epoch: 375| Step: 0
Training loss: 3.0962116966912228
Validation loss: 2.6205539015689814

Epoch: 5| Step: 1
Training loss: 3.2709472215266917
Validation loss: 2.619352336928622

Epoch: 5| Step: 2
Training loss: 2.7181856293099194
Validation loss: 2.6212519693040335

Epoch: 5| Step: 3
Training loss: 3.1983398422591103
Validation loss: 2.619549228620255

Epoch: 5| Step: 4
Training loss: 3.106931406728073
Validation loss: 2.632660874654193

Epoch: 5| Step: 5
Training loss: 2.575847382603316
Validation loss: 2.6496290708080754

Epoch: 5| Step: 6
Training loss: 2.318497689804364
Validation loss: 2.6465606112995883

Epoch: 5| Step: 7
Training loss: 3.239116491961741
Validation loss: 2.6552907892342166

Epoch: 5| Step: 8
Training loss: 2.652163964359605
Validation loss: 2.655831373356288

Epoch: 5| Step: 9
Training loss: 3.112933705458187
Validation loss: 2.659584777045796

Epoch: 5| Step: 10
Training loss: 2.9477802330409792
Validation loss: 2.644753625728622

Epoch: 376| Step: 0
Training loss: 3.10361334116935
Validation loss: 2.635687276272193

Epoch: 5| Step: 1
Training loss: 2.75553337348022
Validation loss: 2.623984084109452

Epoch: 5| Step: 2
Training loss: 3.156727820760414
Validation loss: 2.613119316457985

Epoch: 5| Step: 3
Training loss: 2.7428595868593635
Validation loss: 2.612026360702055

Epoch: 5| Step: 4
Training loss: 2.804311573050091
Validation loss: 2.5976873965435057

Epoch: 5| Step: 5
Training loss: 3.068187181872679
Validation loss: 2.6030127651875175

Epoch: 5| Step: 6
Training loss: 2.711259542459849
Validation loss: 2.5985235209355286

Epoch: 5| Step: 7
Training loss: 2.7836965023222295
Validation loss: 2.601949521884456

Epoch: 5| Step: 8
Training loss: 3.1990533024412633
Validation loss: 2.596471157460666

Epoch: 5| Step: 9
Training loss: 3.1566364316153623
Validation loss: 2.6002023241520167

Epoch: 5| Step: 10
Training loss: 2.7835755644447007
Validation loss: 2.6079257808925584

Epoch: 377| Step: 0
Training loss: 2.622213610493084
Validation loss: 2.6181346342110037

Epoch: 5| Step: 1
Training loss: 3.12374944460201
Validation loss: 2.613952176830061

Epoch: 5| Step: 2
Training loss: 2.853929848603415
Validation loss: 2.625473395816789

Epoch: 5| Step: 3
Training loss: 3.150973905144776
Validation loss: 2.6354450530884357

Epoch: 5| Step: 4
Training loss: 2.7333600585685436
Validation loss: 2.6256937754805634

Epoch: 5| Step: 5
Training loss: 3.360625136440871
Validation loss: 2.611482563563549

Epoch: 5| Step: 6
Training loss: 2.6057734504295222
Validation loss: 2.609292682196405

Epoch: 5| Step: 7
Training loss: 3.282487617695937
Validation loss: 2.6051264097334195

Epoch: 5| Step: 8
Training loss: 3.330167188600044
Validation loss: 2.6023083862010425

Epoch: 5| Step: 9
Training loss: 2.538433853967686
Validation loss: 2.606202567086871

Epoch: 5| Step: 10
Training loss: 2.4910767570317516
Validation loss: 2.601236642438174

Epoch: 378| Step: 0
Training loss: 3.065433109666774
Validation loss: 2.603599235160132

Epoch: 5| Step: 1
Training loss: 2.9511704208198766
Validation loss: 2.6070753465101744

Epoch: 5| Step: 2
Training loss: 2.3693060632416145
Validation loss: 2.60417776060305

Epoch: 5| Step: 3
Training loss: 2.8433336225586268
Validation loss: 2.6139205875757123

Epoch: 5| Step: 4
Training loss: 2.8636679186603073
Validation loss: 2.6181745474842493

Epoch: 5| Step: 5
Training loss: 3.1595284836914845
Validation loss: 2.6218616184926318

Epoch: 5| Step: 6
Training loss: 2.8468205569240213
Validation loss: 2.634002055562061

Epoch: 5| Step: 7
Training loss: 3.3389127448723626
Validation loss: 2.6485958668500182

Epoch: 5| Step: 8
Training loss: 3.0740419213359567
Validation loss: 2.6575857762058

Epoch: 5| Step: 9
Training loss: 2.6421498968786166
Validation loss: 2.676138180060988

Epoch: 5| Step: 10
Training loss: 3.0906754446203974
Validation loss: 2.6615050921223644

Epoch: 379| Step: 0
Training loss: 2.428806059185959
Validation loss: 2.65105742278541

Epoch: 5| Step: 1
Training loss: 3.499769339454005
Validation loss: 2.6392001260123537

Epoch: 5| Step: 2
Training loss: 3.0065190692489088
Validation loss: 2.632515705885545

Epoch: 5| Step: 3
Training loss: 3.044429795569503
Validation loss: 2.6319188281880623

Epoch: 5| Step: 4
Training loss: 2.4531186826588143
Validation loss: 2.6432585758206013

Epoch: 5| Step: 5
Training loss: 2.7478673641784357
Validation loss: 2.6410990099847176

Epoch: 5| Step: 6
Training loss: 3.010796510872632
Validation loss: 2.6460203823769843

Epoch: 5| Step: 7
Training loss: 3.12908835958609
Validation loss: 2.6371871861494647

Epoch: 5| Step: 8
Training loss: 2.143118860520196
Validation loss: 2.635156777134929

Epoch: 5| Step: 9
Training loss: 3.0130186528775242
Validation loss: 2.6309449702605936

Epoch: 5| Step: 10
Training loss: 3.72139037185615
Validation loss: 2.6267417123961647

Epoch: 380| Step: 0
Training loss: 2.855113037330154
Validation loss: 2.6213773486545606

Epoch: 5| Step: 1
Training loss: 2.9272263425235447
Validation loss: 2.6186378942724113

Epoch: 5| Step: 2
Training loss: 3.3310244829233784
Validation loss: 2.6121486163542125

Epoch: 5| Step: 3
Training loss: 3.1560723283068
Validation loss: 2.606705394757521

Epoch: 5| Step: 4
Training loss: 2.360533373091971
Validation loss: 2.612068866109718

Epoch: 5| Step: 5
Training loss: 3.17067962822004
Validation loss: 2.609003122185396

Epoch: 5| Step: 6
Training loss: 3.1555696263992057
Validation loss: 2.6081437385571453

Epoch: 5| Step: 7
Training loss: 2.9141894765398804
Validation loss: 2.6182578222070205

Epoch: 5| Step: 8
Training loss: 2.5648760130959416
Validation loss: 2.61714800953477

Epoch: 5| Step: 9
Training loss: 2.712554537317162
Validation loss: 2.6291586928367527

Epoch: 5| Step: 10
Training loss: 2.9760511064140482
Validation loss: 2.631643556793171

Epoch: 381| Step: 0
Training loss: 2.9553111224651807
Validation loss: 2.631129109366188

Epoch: 5| Step: 1
Training loss: 3.2168429752977015
Validation loss: 2.6403203435221294

Epoch: 5| Step: 2
Training loss: 2.8066173491445254
Validation loss: 2.642293972635554

Epoch: 5| Step: 3
Training loss: 3.3437733872210735
Validation loss: 2.6483914701054396

Epoch: 5| Step: 4
Training loss: 3.220770340698699
Validation loss: 2.658221032404643

Epoch: 5| Step: 5
Training loss: 2.548821670699443
Validation loss: 2.650058174113911

Epoch: 5| Step: 6
Training loss: 2.696182508618713
Validation loss: 2.6328571615578213

Epoch: 5| Step: 7
Training loss: 3.205519809079165
Validation loss: 2.6383881744944695

Epoch: 5| Step: 8
Training loss: 3.241130463514012
Validation loss: 2.620629721238015

Epoch: 5| Step: 9
Training loss: 2.4866869263765414
Validation loss: 2.6134588116661224

Epoch: 5| Step: 10
Training loss: 2.0957149565719138
Validation loss: 2.6071837230403285

Epoch: 382| Step: 0
Training loss: 2.856917195264102
Validation loss: 2.6102169064696996

Epoch: 5| Step: 1
Training loss: 3.2539225162314764
Validation loss: 2.6106596602773298

Epoch: 5| Step: 2
Training loss: 3.4437782521828435
Validation loss: 2.610157943040311

Epoch: 5| Step: 3
Training loss: 2.9675465604090867
Validation loss: 2.6030528541912674

Epoch: 5| Step: 4
Training loss: 2.6879939135527957
Validation loss: 2.60122040796667

Epoch: 5| Step: 5
Training loss: 2.848635825546915
Validation loss: 2.5988627585598905

Epoch: 5| Step: 6
Training loss: 2.820042901084794
Validation loss: 2.60383315249789

Epoch: 5| Step: 7
Training loss: 2.8080607665896165
Validation loss: 2.607423579883836

Epoch: 5| Step: 8
Training loss: 2.658998212110041
Validation loss: 2.6119458067974284

Epoch: 5| Step: 9
Training loss: 2.9830744440992563
Validation loss: 2.6086529160087717

Epoch: 5| Step: 10
Training loss: 2.7516727561891003
Validation loss: 2.6062317809083413

Epoch: 383| Step: 0
Training loss: 2.7981603641759025
Validation loss: 2.617710367524361

Epoch: 5| Step: 1
Training loss: 2.6502327474912923
Validation loss: 2.613112021246375

Epoch: 5| Step: 2
Training loss: 3.160756736636554
Validation loss: 2.6223616909371468

Epoch: 5| Step: 3
Training loss: 3.042621323385
Validation loss: 2.6230754115743253

Epoch: 5| Step: 4
Training loss: 3.0690766387946264
Validation loss: 2.6343631417966833

Epoch: 5| Step: 5
Training loss: 3.150746296471908
Validation loss: 2.645605198723292

Epoch: 5| Step: 6
Training loss: 2.77177383599501
Validation loss: 2.6472026629840255

Epoch: 5| Step: 7
Training loss: 2.621146325210881
Validation loss: 2.66970719599168

Epoch: 5| Step: 8
Training loss: 3.090418090682833
Validation loss: 2.6956892927522684

Epoch: 5| Step: 9
Training loss: 2.7581114350311005
Validation loss: 2.706081518838795

Epoch: 5| Step: 10
Training loss: 2.9985942726041372
Validation loss: 2.7068031462461173

Epoch: 384| Step: 0
Training loss: 3.2225251512160034
Validation loss: 2.643549285389418

Epoch: 5| Step: 1
Training loss: 2.751451975970909
Validation loss: 2.617457293613666

Epoch: 5| Step: 2
Training loss: 2.9730543554259787
Validation loss: 2.6052997370281696

Epoch: 5| Step: 3
Training loss: 2.9298640897300254
Validation loss: 2.5999511371813884

Epoch: 5| Step: 4
Training loss: 3.062310816312669
Validation loss: 2.5897480503651136

Epoch: 5| Step: 5
Training loss: 2.612348495543887
Validation loss: 2.5957624582546845

Epoch: 5| Step: 6
Training loss: 2.4539431039981165
Validation loss: 2.5902309392779106

Epoch: 5| Step: 7
Training loss: 2.9429753995353933
Validation loss: 2.593808196831161

Epoch: 5| Step: 8
Training loss: 2.9337215065598437
Validation loss: 2.592912386737574

Epoch: 5| Step: 9
Training loss: 3.0315977860549994
Validation loss: 2.595742804437125

Epoch: 5| Step: 10
Training loss: 3.4338363544394226
Validation loss: 2.5929712222759083

Epoch: 385| Step: 0
Training loss: 2.538650620138654
Validation loss: 2.593091563627209

Epoch: 5| Step: 1
Training loss: 3.1194475819530507
Validation loss: 2.595389024099812

Epoch: 5| Step: 2
Training loss: 3.2437940179267404
Validation loss: 2.5954277926924454

Epoch: 5| Step: 3
Training loss: 2.772654076191385
Validation loss: 2.590855412133962

Epoch: 5| Step: 4
Training loss: 3.2578417733247163
Validation loss: 2.5966321714255347

Epoch: 5| Step: 5
Training loss: 2.9261718815182385
Validation loss: 2.610078583787142

Epoch: 5| Step: 6
Training loss: 2.7877631058992507
Validation loss: 2.620456421783809

Epoch: 5| Step: 7
Training loss: 3.3296356354661123
Validation loss: 2.6161234657139665

Epoch: 5| Step: 8
Training loss: 2.4017098931952163
Validation loss: 2.6239392002022703

Epoch: 5| Step: 9
Training loss: 2.5603965872299796
Validation loss: 2.628256927339865

Epoch: 5| Step: 10
Training loss: 3.1141633395928454
Validation loss: 2.651290461866222

Epoch: 386| Step: 0
Training loss: 3.247218775976256
Validation loss: 2.6404098886218472

Epoch: 5| Step: 1
Training loss: 2.751157083705846
Validation loss: 2.6292703137505358

Epoch: 5| Step: 2
Training loss: 2.2294660943501547
Validation loss: 2.6300902101415713

Epoch: 5| Step: 3
Training loss: 2.9463178704673822
Validation loss: 2.6278509907890513

Epoch: 5| Step: 4
Training loss: 3.771485892186386
Validation loss: 2.6280934066466433

Epoch: 5| Step: 5
Training loss: 2.914448975817144
Validation loss: 2.6457749149486927

Epoch: 5| Step: 6
Training loss: 2.808154160606908
Validation loss: 2.665927571756727

Epoch: 5| Step: 7
Training loss: 2.7069651938301518
Validation loss: 2.6538682706104293

Epoch: 5| Step: 8
Training loss: 2.180028854494133
Validation loss: 2.6487737411886614

Epoch: 5| Step: 9
Training loss: 3.3255361597977053
Validation loss: 2.6292918551950373

Epoch: 5| Step: 10
Training loss: 2.8330108421648745
Validation loss: 2.6264570892684795

Epoch: 387| Step: 0
Training loss: 3.251313310979855
Validation loss: 2.6147194316135796

Epoch: 5| Step: 1
Training loss: 3.0020563707237296
Validation loss: 2.6032263412123813

Epoch: 5| Step: 2
Training loss: 3.194183672521239
Validation loss: 2.6014780685360837

Epoch: 5| Step: 3
Training loss: 2.512077816085928
Validation loss: 2.6029762418490323

Epoch: 5| Step: 4
Training loss: 3.609129529920631
Validation loss: 2.5930432689779392

Epoch: 5| Step: 5
Training loss: 3.114266999339695
Validation loss: 2.5981932051881245

Epoch: 5| Step: 6
Training loss: 2.5633186335280653
Validation loss: 2.5953139763997592

Epoch: 5| Step: 7
Training loss: 3.049313865153565
Validation loss: 2.6006487485440046

Epoch: 5| Step: 8
Training loss: 2.4403284730411703
Validation loss: 2.5967149271055505

Epoch: 5| Step: 9
Training loss: 2.903305366752231
Validation loss: 2.6102366457697346

Epoch: 5| Step: 10
Training loss: 2.0800438533341583
Validation loss: 2.613783462307155

Epoch: 388| Step: 0
Training loss: 3.8096509199848105
Validation loss: 2.6495523238692322

Epoch: 5| Step: 1
Training loss: 2.5622665485015546
Validation loss: 2.656963345738413

Epoch: 5| Step: 2
Training loss: 2.5527991919252937
Validation loss: 2.7033351702917994

Epoch: 5| Step: 3
Training loss: 3.001821600689035
Validation loss: 2.70842305895377

Epoch: 5| Step: 4
Training loss: 2.655238778104523
Validation loss: 2.6575373252434797

Epoch: 5| Step: 5
Training loss: 2.4144982003406508
Validation loss: 2.6427094325252014

Epoch: 5| Step: 6
Training loss: 3.046440523910266
Validation loss: 2.624695226963128

Epoch: 5| Step: 7
Training loss: 2.6908578521597506
Validation loss: 2.6111193215482476

Epoch: 5| Step: 8
Training loss: 3.2210969238857756
Validation loss: 2.6099231476549267

Epoch: 5| Step: 9
Training loss: 3.5141485886398645
Validation loss: 2.6010298359316546

Epoch: 5| Step: 10
Training loss: 2.108778692659682
Validation loss: 2.6017494635812812

Epoch: 389| Step: 0
Training loss: 2.5654098922378177
Validation loss: 2.598657709055861

Epoch: 5| Step: 1
Training loss: 2.7742706336946856
Validation loss: 2.615108922681475

Epoch: 5| Step: 2
Training loss: 3.2084835727408443
Validation loss: 2.614925716233427

Epoch: 5| Step: 3
Training loss: 2.946756590712444
Validation loss: 2.6120664998090235

Epoch: 5| Step: 4
Training loss: 2.037550559323453
Validation loss: 2.6310746689456868

Epoch: 5| Step: 5
Training loss: 3.1788586935225336
Validation loss: 2.6418484526237678

Epoch: 5| Step: 6
Training loss: 3.32816540330889
Validation loss: 2.638690100520593

Epoch: 5| Step: 7
Training loss: 2.641315888983506
Validation loss: 2.6546680929998505

Epoch: 5| Step: 8
Training loss: 3.4390907074994663
Validation loss: 2.654696509842536

Epoch: 5| Step: 9
Training loss: 2.6753057572500736
Validation loss: 2.638315320643915

Epoch: 5| Step: 10
Training loss: 3.067054942332646
Validation loss: 2.6391263620345553

Epoch: 390| Step: 0
Training loss: 2.8690277762971466
Validation loss: 2.62351826434123

Epoch: 5| Step: 1
Training loss: 2.521796481246726
Validation loss: 2.6248309231874205

Epoch: 5| Step: 2
Training loss: 3.1818081768918964
Validation loss: 2.623992478506827

Epoch: 5| Step: 3
Training loss: 2.734884857599342
Validation loss: 2.6336532647132027

Epoch: 5| Step: 4
Training loss: 3.2013665559605258
Validation loss: 2.646026431488366

Epoch: 5| Step: 5
Training loss: 2.9304829649248676
Validation loss: 2.635301338333522

Epoch: 5| Step: 6
Training loss: 2.6207812786744786
Validation loss: 2.6360466271579366

Epoch: 5| Step: 7
Training loss: 3.5034312731128043
Validation loss: 2.634577882797183

Epoch: 5| Step: 8
Training loss: 2.7753066091149585
Validation loss: 2.6386691585035025

Epoch: 5| Step: 9
Training loss: 2.6032337399561705
Validation loss: 2.6253275845107846

Epoch: 5| Step: 10
Training loss: 2.893290182867144
Validation loss: 2.6155323861495843

Epoch: 391| Step: 0
Training loss: 2.662414578065942
Validation loss: 2.609909221040291

Epoch: 5| Step: 1
Training loss: 2.756668155981889
Validation loss: 2.6131811081241003

Epoch: 5| Step: 2
Training loss: 2.70881943864106
Validation loss: 2.608384030978485

Epoch: 5| Step: 3
Training loss: 3.110542116660934
Validation loss: 2.619060439669858

Epoch: 5| Step: 4
Training loss: 3.228361427238718
Validation loss: 2.621422155158899

Epoch: 5| Step: 5
Training loss: 2.3885958168977575
Validation loss: 2.626700712240171

Epoch: 5| Step: 6
Training loss: 2.814683956340102
Validation loss: 2.6309597774777385

Epoch: 5| Step: 7
Training loss: 2.9467455870932784
Validation loss: 2.6359103154436707

Epoch: 5| Step: 8
Training loss: 3.2103086723632335
Validation loss: 2.6488449698454826

Epoch: 5| Step: 9
Training loss: 2.810260474462496
Validation loss: 2.6680769120323564

Epoch: 5| Step: 10
Training loss: 3.2549688062916426
Validation loss: 2.6926790602659336

Epoch: 392| Step: 0
Training loss: 3.088379948431148
Validation loss: 2.673005187482619

Epoch: 5| Step: 1
Training loss: 2.777971542805858
Validation loss: 2.661931073318626

Epoch: 5| Step: 2
Training loss: 2.9076541256910935
Validation loss: 2.629365535292887

Epoch: 5| Step: 3
Training loss: 2.7958048046341206
Validation loss: 2.6058018780704924

Epoch: 5| Step: 4
Training loss: 3.636708260591747
Validation loss: 2.6099232301653292

Epoch: 5| Step: 5
Training loss: 2.833322038814996
Validation loss: 2.60100616899091

Epoch: 5| Step: 6
Training loss: 3.1061505798762754
Validation loss: 2.6075529845893

Epoch: 5| Step: 7
Training loss: 2.629228909375893
Validation loss: 2.6083731478985244

Epoch: 5| Step: 8
Training loss: 2.6303023419088296
Validation loss: 2.6069067278024365

Epoch: 5| Step: 9
Training loss: 2.343029267438051
Validation loss: 2.6137649993615977

Epoch: 5| Step: 10
Training loss: 3.144130287906973
Validation loss: 2.619484735297477

Epoch: 393| Step: 0
Training loss: 2.491388844680157
Validation loss: 2.6316220131671084

Epoch: 5| Step: 1
Training loss: 3.0822704304570236
Validation loss: 2.6291561605522027

Epoch: 5| Step: 2
Training loss: 3.0340882217868104
Validation loss: 2.6440730331763387

Epoch: 5| Step: 3
Training loss: 2.8951377490647263
Validation loss: 2.6362667915088256

Epoch: 5| Step: 4
Training loss: 2.419485673238044
Validation loss: 2.6324679017513275

Epoch: 5| Step: 5
Training loss: 3.268498812591958
Validation loss: 2.6318178710219997

Epoch: 5| Step: 6
Training loss: 2.9200549653510612
Validation loss: 2.6604843748008666

Epoch: 5| Step: 7
Training loss: 2.764193751796922
Validation loss: 2.646011867479621

Epoch: 5| Step: 8
Training loss: 3.0778560617760733
Validation loss: 2.666341778809308

Epoch: 5| Step: 9
Training loss: 2.8063196730088857
Validation loss: 2.6797288039833145

Epoch: 5| Step: 10
Training loss: 3.0482276457132156
Validation loss: 2.6679588085509365

Epoch: 394| Step: 0
Training loss: 2.75184179531618
Validation loss: 2.654691004380664

Epoch: 5| Step: 1
Training loss: 3.1075101081026992
Validation loss: 2.648007928822331

Epoch: 5| Step: 2
Training loss: 3.0938409348812166
Validation loss: 2.6260138080883593

Epoch: 5| Step: 3
Training loss: 3.191925566873841
Validation loss: 2.624384974531657

Epoch: 5| Step: 4
Training loss: 3.1320224441172355
Validation loss: 2.6079770173064154

Epoch: 5| Step: 5
Training loss: 2.893787530445576
Validation loss: 2.6077814048253574

Epoch: 5| Step: 6
Training loss: 2.982273820101287
Validation loss: 2.600136142160682

Epoch: 5| Step: 7
Training loss: 2.7546149457961038
Validation loss: 2.5968588680397438

Epoch: 5| Step: 8
Training loss: 2.9833263532105807
Validation loss: 2.5963174502595776

Epoch: 5| Step: 9
Training loss: 2.2976801492588868
Validation loss: 2.5993020859520946

Epoch: 5| Step: 10
Training loss: 2.6712127221683364
Validation loss: 2.606010341241383

Epoch: 395| Step: 0
Training loss: 2.6620687144386537
Validation loss: 2.6334967016456603

Epoch: 5| Step: 1
Training loss: 2.9689616880736307
Validation loss: 2.6643688495007476

Epoch: 5| Step: 2
Training loss: 3.406558241589996
Validation loss: 2.662610690588881

Epoch: 5| Step: 3
Training loss: 2.970868609532401
Validation loss: 2.6891720695882015

Epoch: 5| Step: 4
Training loss: 2.9945696319978583
Validation loss: 2.684800730099945

Epoch: 5| Step: 5
Training loss: 2.818942511300832
Validation loss: 2.6847488752834545

Epoch: 5| Step: 6
Training loss: 2.7579611935392347
Validation loss: 2.6757530896554047

Epoch: 5| Step: 7
Training loss: 3.196339337320391
Validation loss: 2.687802919876209

Epoch: 5| Step: 8
Training loss: 2.5146598149014463
Validation loss: 2.654677073125845

Epoch: 5| Step: 9
Training loss: 2.871396999822703
Validation loss: 2.637683182854645

Epoch: 5| Step: 10
Training loss: 2.5583989891880465
Validation loss: 2.603040032277344

Epoch: 396| Step: 0
Training loss: 2.638920792726994
Validation loss: 2.6007558965415827

Epoch: 5| Step: 1
Training loss: 2.751291665260436
Validation loss: 2.589360327509165

Epoch: 5| Step: 2
Training loss: 2.5654479027236854
Validation loss: 2.58790885350809

Epoch: 5| Step: 3
Training loss: 3.2213201539020533
Validation loss: 2.582186459882999

Epoch: 5| Step: 4
Training loss: 2.862114266471697
Validation loss: 2.58848320220753

Epoch: 5| Step: 5
Training loss: 3.266092951342488
Validation loss: 2.590242550815734

Epoch: 5| Step: 6
Training loss: 2.8097149941294908
Validation loss: 2.5982164892612727

Epoch: 5| Step: 7
Training loss: 3.1193980550859837
Validation loss: 2.6096225410123153

Epoch: 5| Step: 8
Training loss: 2.942550213822061
Validation loss: 2.6186211504201733

Epoch: 5| Step: 9
Training loss: 3.357912392814527
Validation loss: 2.6285653987909754

Epoch: 5| Step: 10
Training loss: 2.1963614676190373
Validation loss: 2.632892124348224

Epoch: 397| Step: 0
Training loss: 3.2048243039158524
Validation loss: 2.6551514932802873

Epoch: 5| Step: 1
Training loss: 3.15024077691129
Validation loss: 2.649281082259262

Epoch: 5| Step: 2
Training loss: 2.4099953967165217
Validation loss: 2.6567746266237786

Epoch: 5| Step: 3
Training loss: 2.924807622076992
Validation loss: 2.6419210586370396

Epoch: 5| Step: 4
Training loss: 2.4547864790786655
Validation loss: 2.6673869889300907

Epoch: 5| Step: 5
Training loss: 3.183987645781813
Validation loss: 2.6584110818652404

Epoch: 5| Step: 6
Training loss: 2.7217706145669793
Validation loss: 2.6356354064579555

Epoch: 5| Step: 7
Training loss: 3.1297149184688102
Validation loss: 2.6332228783708143

Epoch: 5| Step: 8
Training loss: 2.8162435413190026
Validation loss: 2.619689568213829

Epoch: 5| Step: 9
Training loss: 3.2009231070400017
Validation loss: 2.609458662134527

Epoch: 5| Step: 10
Training loss: 2.502944452106033
Validation loss: 2.593831260328431

Epoch: 398| Step: 0
Training loss: 2.752945016613272
Validation loss: 2.587117083382352

Epoch: 5| Step: 1
Training loss: 2.310469586586409
Validation loss: 2.597639393603345

Epoch: 5| Step: 2
Training loss: 2.7591488979930725
Validation loss: 2.602642766883421

Epoch: 5| Step: 3
Training loss: 2.62187099160944
Validation loss: 2.6068275675532697

Epoch: 5| Step: 4
Training loss: 2.69221845311256
Validation loss: 2.6379519055758163

Epoch: 5| Step: 5
Training loss: 3.1123466668411424
Validation loss: 2.657145703490097

Epoch: 5| Step: 6
Training loss: 2.840671591801534
Validation loss: 2.6726343620253337

Epoch: 5| Step: 7
Training loss: 3.4175815907961193
Validation loss: 2.7022357392918646

Epoch: 5| Step: 8
Training loss: 3.2767723412870073
Validation loss: 2.6604623323776795

Epoch: 5| Step: 9
Training loss: 3.2084933814880676
Validation loss: 2.619313017104991

Epoch: 5| Step: 10
Training loss: 3.001515800275621
Validation loss: 2.596860321209959

Epoch: 399| Step: 0
Training loss: 3.0681267254953357
Validation loss: 2.59821499244837

Epoch: 5| Step: 1
Training loss: 3.2042478500684006
Validation loss: 2.5938764319682206

Epoch: 5| Step: 2
Training loss: 3.2204170724621166
Validation loss: 2.5966463489357072

Epoch: 5| Step: 3
Training loss: 2.947643541459816
Validation loss: 2.5949935116571083

Epoch: 5| Step: 4
Training loss: 3.000275917080508
Validation loss: 2.5919312140462814

Epoch: 5| Step: 5
Training loss: 2.3445760669892812
Validation loss: 2.5961283856534596

Epoch: 5| Step: 6
Training loss: 2.8876571678555236
Validation loss: 2.6258864383206038

Epoch: 5| Step: 7
Training loss: 2.6934578084351557
Validation loss: 2.6161791658168174

Epoch: 5| Step: 8
Training loss: 2.771502096214926
Validation loss: 2.603667326932425

Epoch: 5| Step: 9
Training loss: 3.084744225135899
Validation loss: 2.6100350549025593

Epoch: 5| Step: 10
Training loss: 3.0010383716279603
Validation loss: 2.6135678661358472

Epoch: 400| Step: 0
Training loss: 3.062560100354952
Validation loss: 2.624715045398958

Epoch: 5| Step: 1
Training loss: 3.010184167949793
Validation loss: 2.6203940620510706

Epoch: 5| Step: 2
Training loss: 2.9566455020025173
Validation loss: 2.6321065253240774

Epoch: 5| Step: 3
Training loss: 3.1607864562532044
Validation loss: 2.6272039044057265

Epoch: 5| Step: 4
Training loss: 2.48173776439772
Validation loss: 2.629581064636141

Epoch: 5| Step: 5
Training loss: 2.968224890597016
Validation loss: 2.6445577729824956

Epoch: 5| Step: 6
Training loss: 2.8567020450865814
Validation loss: 2.6187029351389306

Epoch: 5| Step: 7
Training loss: 2.8373829754463933
Validation loss: 2.6095773324817877

Epoch: 5| Step: 8
Training loss: 3.0788570250085234
Validation loss: 2.6094681996597493

Epoch: 5| Step: 9
Training loss: 2.909600080558182
Validation loss: 2.6062264848885066

Epoch: 5| Step: 10
Training loss: 2.5635962583662475
Validation loss: 2.601141397444782

Testing loss: 2.8249757396215176
