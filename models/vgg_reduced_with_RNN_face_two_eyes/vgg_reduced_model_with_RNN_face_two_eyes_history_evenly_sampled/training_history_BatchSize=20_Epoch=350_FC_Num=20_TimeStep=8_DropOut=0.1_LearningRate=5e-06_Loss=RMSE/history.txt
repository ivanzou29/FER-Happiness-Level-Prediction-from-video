Epoch: 1| Step: 0
Training loss: 6.1351912434934155
Validation loss: 5.862983129321081

Epoch: 5| Step: 1
Training loss: 6.3119035193511674
Validation loss: 5.857205849188344

Epoch: 5| Step: 2
Training loss: 6.41872267378327
Validation loss: 5.852121364221528

Epoch: 5| Step: 3
Training loss: 6.134079723276645
Validation loss: 5.846915968893503

Epoch: 5| Step: 4
Training loss: 5.2141570021239145
Validation loss: 5.8421017516523195

Epoch: 5| Step: 5
Training loss: 5.7963702452499986
Validation loss: 5.837795324211923

Epoch: 5| Step: 6
Training loss: 5.561215198739781
Validation loss: 5.834108082643614

Epoch: 5| Step: 7
Training loss: 5.757153580745864
Validation loss: 5.830443684674519

Epoch: 5| Step: 8
Training loss: 6.206892968684657
Validation loss: 5.827039620696231

Epoch: 5| Step: 9
Training loss: 4.778004461031684
Validation loss: 5.82395290297521

Epoch: 5| Step: 10
Training loss: 6.115447399774939
Validation loss: 5.820670699319244

Epoch: 2| Step: 0
Training loss: 6.496906424662457
Validation loss: 5.817486230949286

Epoch: 5| Step: 1
Training loss: 5.807898227735268
Validation loss: 5.814378789149284

Epoch: 5| Step: 2
Training loss: 4.9598762398323135
Validation loss: 5.811155822065736

Epoch: 5| Step: 3
Training loss: 5.402294851041803
Validation loss: 5.807961362563049

Epoch: 5| Step: 4
Training loss: 6.295432405899224
Validation loss: 5.804438743218109

Epoch: 5| Step: 5
Training loss: 5.91393284926414
Validation loss: 5.801040582517902

Epoch: 5| Step: 6
Training loss: 5.879729943853415
Validation loss: 5.797132679986448

Epoch: 5| Step: 7
Training loss: 5.573229610414887
Validation loss: 5.793764199182207

Epoch: 5| Step: 8
Training loss: 5.846929490994077
Validation loss: 5.789755038832502

Epoch: 5| Step: 9
Training loss: 6.28918563058812
Validation loss: 5.785663113882568

Epoch: 5| Step: 10
Training loss: 5.478437290549594
Validation loss: 5.781140220817045

Epoch: 3| Step: 0
Training loss: 6.3795706127930965
Validation loss: 5.776809525797288

Epoch: 5| Step: 1
Training loss: 6.984622686376475
Validation loss: 5.771917398652818

Epoch: 5| Step: 2
Training loss: 5.588016747255017
Validation loss: 5.76676166040547

Epoch: 5| Step: 3
Training loss: 5.3861644036394045
Validation loss: 5.761668510294452

Epoch: 5| Step: 4
Training loss: 5.299857141260832
Validation loss: 5.756062208635732

Epoch: 5| Step: 5
Training loss: 5.353655819203656
Validation loss: 5.750379145937194

Epoch: 5| Step: 6
Training loss: 5.875365225619921
Validation loss: 5.744375135816954

Epoch: 5| Step: 7
Training loss: 5.97407398150738
Validation loss: 5.73780272392948

Epoch: 5| Step: 8
Training loss: 4.984193804565561
Validation loss: 5.731022746408582

Epoch: 5| Step: 9
Training loss: 6.080127376426765
Validation loss: 5.724016462952748

Epoch: 5| Step: 10
Training loss: 5.3814417362945415
Validation loss: 5.7163557526234525

Epoch: 4| Step: 0
Training loss: 4.914094521519774
Validation loss: 5.708336362694976

Epoch: 5| Step: 1
Training loss: 6.041226531033875
Validation loss: 5.700699863022837

Epoch: 5| Step: 2
Training loss: 6.983939411140844
Validation loss: 5.691888363216578

Epoch: 5| Step: 3
Training loss: 5.907530953499332
Validation loss: 5.682875386464815

Epoch: 5| Step: 4
Training loss: 5.151905425820777
Validation loss: 5.673261627935243

Epoch: 5| Step: 5
Training loss: 5.517305372130125
Validation loss: 5.663819045738879

Epoch: 5| Step: 6
Training loss: 6.8363470859437925
Validation loss: 5.654000117132451

Epoch: 5| Step: 7
Training loss: 5.59056878869257
Validation loss: 5.6427821847336705

Epoch: 5| Step: 8
Training loss: 4.497647412244878
Validation loss: 5.632077678102557

Epoch: 5| Step: 9
Training loss: 5.427933092518767
Validation loss: 5.620656243890425

Epoch: 5| Step: 10
Training loss: 5.246829392471805
Validation loss: 5.6091222597293475

Epoch: 5| Step: 0
Training loss: 5.846529539291544
Validation loss: 5.59672303398174

Epoch: 5| Step: 1
Training loss: 6.339588322315223
Validation loss: 5.584269145670646

Epoch: 5| Step: 2
Training loss: 6.800992152818242
Validation loss: 5.572283475745824

Epoch: 5| Step: 3
Training loss: 6.043907679460516
Validation loss: 5.55841596627789

Epoch: 5| Step: 4
Training loss: 5.4165637471129315
Validation loss: 5.544841266313985

Epoch: 5| Step: 5
Training loss: 5.4274117729786076
Validation loss: 5.531392940034384

Epoch: 5| Step: 6
Training loss: 4.4335479330644745
Validation loss: 5.517356900212254

Epoch: 5| Step: 7
Training loss: 5.209743013981449
Validation loss: 5.502805259185837

Epoch: 5| Step: 8
Training loss: 4.6500495743928925
Validation loss: 5.488213088630807

Epoch: 5| Step: 9
Training loss: 5.14223948811459
Validation loss: 5.473168514164695

Epoch: 5| Step: 10
Training loss: 5.583363357387305
Validation loss: 5.457572165650033

Epoch: 6| Step: 0
Training loss: 4.882733788428079
Validation loss: 5.441362053524613

Epoch: 5| Step: 1
Training loss: 5.1916035427380915
Validation loss: 5.42586471798291

Epoch: 5| Step: 2
Training loss: 5.284319826240741
Validation loss: 5.4086745406390255

Epoch: 5| Step: 3
Training loss: 5.4072038988654985
Validation loss: 5.390913493488898

Epoch: 5| Step: 4
Training loss: 5.093876936565414
Validation loss: 5.374084209581159

Epoch: 5| Step: 5
Training loss: 5.9425560555323775
Validation loss: 5.354946737377183

Epoch: 5| Step: 6
Training loss: 5.76020934943059
Validation loss: 5.336520228573904

Epoch: 5| Step: 7
Training loss: 5.701014632552365
Validation loss: 5.317045010867738

Epoch: 5| Step: 8
Training loss: 5.570316095337637
Validation loss: 5.298405894462167

Epoch: 5| Step: 9
Training loss: 5.296947017393899
Validation loss: 5.278362191656137

Epoch: 5| Step: 10
Training loss: 5.114036556729376
Validation loss: 5.25968457852768

Epoch: 7| Step: 0
Training loss: 4.92545597657196
Validation loss: 5.240981701074902

Epoch: 5| Step: 1
Training loss: 4.720698478548086
Validation loss: 5.2241273856597825

Epoch: 5| Step: 2
Training loss: 5.275083655105327
Validation loss: 5.2061268040245485

Epoch: 5| Step: 3
Training loss: 4.34217443639239
Validation loss: 5.18936933828761

Epoch: 5| Step: 4
Training loss: 5.7343078110420045
Validation loss: 5.172854638163174

Epoch: 5| Step: 5
Training loss: 5.132274953718041
Validation loss: 5.1569315102290885

Epoch: 5| Step: 6
Training loss: 5.160093227697565
Validation loss: 5.141494878354654

Epoch: 5| Step: 7
Training loss: 4.564263408017078
Validation loss: 5.123186484396564

Epoch: 5| Step: 8
Training loss: 5.682845338396666
Validation loss: 5.108379273888131

Epoch: 5| Step: 9
Training loss: 5.910459602674208
Validation loss: 5.091252816869594

Epoch: 5| Step: 10
Training loss: 5.723531089806914
Validation loss: 5.074372238160186

Epoch: 8| Step: 0
Training loss: 5.254034399575609
Validation loss: 5.054778688263181

Epoch: 5| Step: 1
Training loss: 5.805288784259775
Validation loss: 5.0360159486619755

Epoch: 5| Step: 2
Training loss: 4.9191953115756375
Validation loss: 5.015642036984331

Epoch: 5| Step: 3
Training loss: 5.413640081487203
Validation loss: 4.993277977986628

Epoch: 5| Step: 4
Training loss: 5.001318376298257
Validation loss: 4.972021589052242

Epoch: 5| Step: 5
Training loss: 4.654251386553834
Validation loss: 4.947077884096874

Epoch: 5| Step: 6
Training loss: 4.976163312151653
Validation loss: 4.923827641827443

Epoch: 5| Step: 7
Training loss: 4.961064566839716
Validation loss: 4.899445052675182

Epoch: 5| Step: 8
Training loss: 4.4775589770890285
Validation loss: 4.875494726513019

Epoch: 5| Step: 9
Training loss: 5.009386597808529
Validation loss: 4.855749068879727

Epoch: 5| Step: 10
Training loss: 4.557599715221222
Validation loss: 4.835382099818644

Epoch: 9| Step: 0
Training loss: 5.05052029790407
Validation loss: 4.818674065650899

Epoch: 5| Step: 1
Training loss: 4.645344296477119
Validation loss: 4.803447163580254

Epoch: 5| Step: 2
Training loss: 3.690505790884728
Validation loss: 4.785622962825306

Epoch: 5| Step: 3
Training loss: 5.619866974909089
Validation loss: 4.771056534025356

Epoch: 5| Step: 4
Training loss: 4.9137428555743545
Validation loss: 4.752315384377282

Epoch: 5| Step: 5
Training loss: 4.75914286036686
Validation loss: 4.735130643692889

Epoch: 5| Step: 6
Training loss: 5.078926656975711
Validation loss: 4.715969745198442

Epoch: 5| Step: 7
Training loss: 4.8782865743130595
Validation loss: 4.6976332640285445

Epoch: 5| Step: 8
Training loss: 4.098946338266015
Validation loss: 4.681889025891417

Epoch: 5| Step: 9
Training loss: 4.6800479909278385
Validation loss: 4.666093225595783

Epoch: 5| Step: 10
Training loss: 5.360647689915418
Validation loss: 4.652042407983168

Epoch: 10| Step: 0
Training loss: 5.206752303164497
Validation loss: 4.6372458458150385

Epoch: 5| Step: 1
Training loss: 4.532592364136523
Validation loss: 4.622108953835406

Epoch: 5| Step: 2
Training loss: 4.228456083587729
Validation loss: 4.608988957327605

Epoch: 5| Step: 3
Training loss: 4.159072949843994
Validation loss: 4.59624688305279

Epoch: 5| Step: 4
Training loss: 3.9055227594519493
Validation loss: 4.581895206984778

Epoch: 5| Step: 5
Training loss: 4.8185188999990896
Validation loss: 4.570987939474085

Epoch: 5| Step: 6
Training loss: 4.992741083963211
Validation loss: 4.5573849934340425

Epoch: 5| Step: 7
Training loss: 5.299786602978404
Validation loss: 4.545351827174936

Epoch: 5| Step: 8
Training loss: 4.752437969768163
Validation loss: 4.532982318222678

Epoch: 5| Step: 9
Training loss: 4.62367827628743
Validation loss: 4.519538714819035

Epoch: 5| Step: 10
Training loss: 4.622364633660845
Validation loss: 4.50671187655257

Epoch: 11| Step: 0
Training loss: 4.328144830871762
Validation loss: 4.495200474646283

Epoch: 5| Step: 1
Training loss: 5.304151370297911
Validation loss: 4.483770807064845

Epoch: 5| Step: 2
Training loss: 5.089879349813146
Validation loss: 4.4733655737610665

Epoch: 5| Step: 3
Training loss: 4.028975207182687
Validation loss: 4.4621770817588295

Epoch: 5| Step: 4
Training loss: 4.571427690131238
Validation loss: 4.451315020955856

Epoch: 5| Step: 5
Training loss: 4.363619143278649
Validation loss: 4.438851122648615

Epoch: 5| Step: 6
Training loss: 4.01573780658369
Validation loss: 4.430777028340491

Epoch: 5| Step: 7
Training loss: 3.2582338641529685
Validation loss: 4.421167124298287

Epoch: 5| Step: 8
Training loss: 5.35593546385626
Validation loss: 4.413201244712149

Epoch: 5| Step: 9
Training loss: 4.963258023345031
Validation loss: 4.40263766350293

Epoch: 5| Step: 10
Training loss: 4.342991604910406
Validation loss: 4.392379954779158

Epoch: 12| Step: 0
Training loss: 4.4221061942652815
Validation loss: 4.383037720526152

Epoch: 5| Step: 1
Training loss: 4.204203527545425
Validation loss: 4.373158427389266

Epoch: 5| Step: 2
Training loss: 4.099935270589337
Validation loss: 4.363063515435732

Epoch: 5| Step: 3
Training loss: 4.138503196774988
Validation loss: 4.352184384729141

Epoch: 5| Step: 4
Training loss: 4.846259273178757
Validation loss: 4.343536945393428

Epoch: 5| Step: 5
Training loss: 4.7333830244294655
Validation loss: 4.3345082506850465

Epoch: 5| Step: 6
Training loss: 4.573999414307991
Validation loss: 4.326250994351483

Epoch: 5| Step: 7
Training loss: 4.865953512500446
Validation loss: 4.319208820044383

Epoch: 5| Step: 8
Training loss: 4.375829345569574
Validation loss: 4.310299050588386

Epoch: 5| Step: 9
Training loss: 4.030155240232809
Validation loss: 4.305160297286304

Epoch: 5| Step: 10
Training loss: 4.67890916060865
Validation loss: 4.298887226059099

Epoch: 13| Step: 0
Training loss: 5.070008537691591
Validation loss: 4.291088010678986

Epoch: 5| Step: 1
Training loss: 4.4538464413548144
Validation loss: 4.286320154127947

Epoch: 5| Step: 2
Training loss: 4.101271613568968
Validation loss: 4.2782549039106685

Epoch: 5| Step: 3
Training loss: 3.8533329792308533
Validation loss: 4.2699966383427

Epoch: 5| Step: 4
Training loss: 4.672308962260347
Validation loss: 4.2650002508066365

Epoch: 5| Step: 5
Training loss: 4.94903761630852
Validation loss: 4.260916169469797

Epoch: 5| Step: 6
Training loss: 4.575177282014899
Validation loss: 4.252992939413041

Epoch: 5| Step: 7
Training loss: 3.6607187463819595
Validation loss: 4.250236478110201

Epoch: 5| Step: 8
Training loss: 4.571982367213732
Validation loss: 4.245501524410613

Epoch: 5| Step: 9
Training loss: 3.5353752953546396
Validation loss: 4.237972289127249

Epoch: 5| Step: 10
Training loss: 4.552579990880364
Validation loss: 4.232136854776601

Epoch: 14| Step: 0
Training loss: 3.60987024914154
Validation loss: 4.224434365028954

Epoch: 5| Step: 1
Training loss: 4.923744064757466
Validation loss: 4.219254687530808

Epoch: 5| Step: 2
Training loss: 4.156557917840822
Validation loss: 4.212852077328789

Epoch: 5| Step: 3
Training loss: 4.655495806553152
Validation loss: 4.20370913492409

Epoch: 5| Step: 4
Training loss: 4.228575165573885
Validation loss: 4.197954314126749

Epoch: 5| Step: 5
Training loss: 3.742322692340408
Validation loss: 4.187531046414798

Epoch: 5| Step: 6
Training loss: 4.704476095902079
Validation loss: 4.179776176989367

Epoch: 5| Step: 7
Training loss: 4.256222153179027
Validation loss: 4.174552306351024

Epoch: 5| Step: 8
Training loss: 4.910654605651456
Validation loss: 4.162735327637854

Epoch: 5| Step: 9
Training loss: 4.184221948925641
Validation loss: 4.150636909102462

Epoch: 5| Step: 10
Training loss: 3.8421863383709867
Validation loss: 4.142941421925728

Epoch: 15| Step: 0
Training loss: 3.728846204119587
Validation loss: 4.133049915807163

Epoch: 5| Step: 1
Training loss: 3.4604005418585886
Validation loss: 4.128433684022143

Epoch: 5| Step: 2
Training loss: 4.578487030400853
Validation loss: 4.117165316772414

Epoch: 5| Step: 3
Training loss: 4.319506054296091
Validation loss: 4.109569946541008

Epoch: 5| Step: 4
Training loss: 4.043847560737475
Validation loss: 4.099376237442937

Epoch: 5| Step: 5
Training loss: 5.193931912427954
Validation loss: 4.092599836988654

Epoch: 5| Step: 6
Training loss: 3.47616952110937
Validation loss: 4.083677176103273

Epoch: 5| Step: 7
Training loss: 4.262922947279643
Validation loss: 4.074924569608574

Epoch: 5| Step: 8
Training loss: 4.429244838442235
Validation loss: 4.063671415828994

Epoch: 5| Step: 9
Training loss: 4.026094910868749
Validation loss: 4.051554676728549

Epoch: 5| Step: 10
Training loss: 4.757315573713343
Validation loss: 4.042724437127576

Epoch: 16| Step: 0
Training loss: 4.22899575976477
Validation loss: 4.03470839893057

Epoch: 5| Step: 1
Training loss: 3.909624153083207
Validation loss: 4.02522675819338

Epoch: 5| Step: 2
Training loss: 3.8166031567038403
Validation loss: 4.019770816867029

Epoch: 5| Step: 3
Training loss: 4.410507417927528
Validation loss: 4.011497549852367

Epoch: 5| Step: 4
Training loss: 4.538511784510386
Validation loss: 4.003148773838231

Epoch: 5| Step: 5
Training loss: 4.380883756340981
Validation loss: 3.996130491918653

Epoch: 5| Step: 6
Training loss: 3.387453908008467
Validation loss: 3.989005748564122

Epoch: 5| Step: 7
Training loss: 3.7075418777827305
Validation loss: 3.984045777461415

Epoch: 5| Step: 8
Training loss: 4.0409396327134575
Validation loss: 3.9758282993455776

Epoch: 5| Step: 9
Training loss: 4.172644612050214
Validation loss: 3.9681904974674773

Epoch: 5| Step: 10
Training loss: 4.911970751647353
Validation loss: 3.958792024642685

Epoch: 17| Step: 0
Training loss: 4.554428276419427
Validation loss: 3.9511741718591344

Epoch: 5| Step: 1
Training loss: 5.236139438506429
Validation loss: 3.943406513322053

Epoch: 5| Step: 2
Training loss: 3.5208000918893902
Validation loss: 3.935622049192486

Epoch: 5| Step: 3
Training loss: 4.363686237989409
Validation loss: 3.9262446888744997

Epoch: 5| Step: 4
Training loss: 3.9857933960469754
Validation loss: 3.9187428808477165

Epoch: 5| Step: 5
Training loss: 2.8724722323225107
Validation loss: 3.9133568124440092

Epoch: 5| Step: 6
Training loss: 4.742816713623701
Validation loss: 3.9062133971109354

Epoch: 5| Step: 7
Training loss: 3.5577209273236017
Validation loss: 3.900488744842773

Epoch: 5| Step: 8
Training loss: 4.0895725513743
Validation loss: 3.8937466775598226

Epoch: 5| Step: 9
Training loss: 4.038008827294294
Validation loss: 3.887089524764222

Epoch: 5| Step: 10
Training loss: 3.1646408494381504
Validation loss: 3.8829082382216646

Epoch: 18| Step: 0
Training loss: 3.193995869050433
Validation loss: 3.8780083769556373

Epoch: 5| Step: 1
Training loss: 4.40021854204691
Validation loss: 3.8705620798809397

Epoch: 5| Step: 2
Training loss: 3.8335259154222325
Validation loss: 3.86476120029374

Epoch: 5| Step: 3
Training loss: 3.9285702643454674
Validation loss: 3.8606525053962812

Epoch: 5| Step: 4
Training loss: 4.441762032597382
Validation loss: 3.8544805933784927

Epoch: 5| Step: 5
Training loss: 4.099272053922539
Validation loss: 3.8475390564510024

Epoch: 5| Step: 6
Training loss: 3.8356614023202713
Validation loss: 3.8437910433756484

Epoch: 5| Step: 7
Training loss: 3.9870134780307707
Validation loss: 3.8375542627797543

Epoch: 5| Step: 8
Training loss: 3.545991090043649
Validation loss: 3.8298741891299923

Epoch: 5| Step: 9
Training loss: 4.336195049712971
Validation loss: 3.8237058988282557

Epoch: 5| Step: 10
Training loss: 4.418156114782483
Validation loss: 3.821594026021151

Epoch: 19| Step: 0
Training loss: 4.5574616086245765
Validation loss: 3.816398465844951

Epoch: 5| Step: 1
Training loss: 3.7360807856416622
Validation loss: 3.810311023064431

Epoch: 5| Step: 2
Training loss: 4.019519149717574
Validation loss: 3.8079159884366844

Epoch: 5| Step: 3
Training loss: 4.611583116163068
Validation loss: 3.8013435541974183

Epoch: 5| Step: 4
Training loss: 3.1113241402791494
Validation loss: 3.7964143847124254

Epoch: 5| Step: 5
Training loss: 3.865447791685851
Validation loss: 3.793732373977717

Epoch: 5| Step: 6
Training loss: 3.0117934795365544
Validation loss: 3.7892615244567924

Epoch: 5| Step: 7
Training loss: 4.660854853205202
Validation loss: 3.7825993667868536

Epoch: 5| Step: 8
Training loss: 3.8302317524805156
Validation loss: 3.778952130624569

Epoch: 5| Step: 9
Training loss: 4.18784114529813
Validation loss: 3.775935661799685

Epoch: 5| Step: 10
Training loss: 3.56180565743287
Validation loss: 3.774130006594811

Epoch: 20| Step: 0
Training loss: 3.733510703460158
Validation loss: 3.7679209993446037

Epoch: 5| Step: 1
Training loss: 3.9161271609739603
Validation loss: 3.7638844354041603

Epoch: 5| Step: 2
Training loss: 4.241554395667495
Validation loss: 3.761375164423226

Epoch: 5| Step: 3
Training loss: 4.58362694002173
Validation loss: 3.756764952886876

Epoch: 5| Step: 4
Training loss: 3.8140311996632112
Validation loss: 3.7542381688355504

Epoch: 5| Step: 5
Training loss: 3.6668869877137014
Validation loss: 3.7497419398397533

Epoch: 5| Step: 6
Training loss: 4.37954541185799
Validation loss: 3.7445159627604947

Epoch: 5| Step: 7
Training loss: 3.5043853806419647
Validation loss: 3.7399537388093007

Epoch: 5| Step: 8
Training loss: 3.7902037484752786
Validation loss: 3.7393296093673727

Epoch: 5| Step: 9
Training loss: 3.7366618412700148
Validation loss: 3.7381154794458578

Epoch: 5| Step: 10
Training loss: 3.667785054929948
Validation loss: 3.7309010804985703

Epoch: 21| Step: 0
Training loss: 3.4547778010374293
Validation loss: 3.7271291327323466

Epoch: 5| Step: 1
Training loss: 4.068409773376626
Validation loss: 3.72345726014791

Epoch: 5| Step: 2
Training loss: 3.872257369575332
Validation loss: 3.7230493970444094

Epoch: 5| Step: 3
Training loss: 3.256526995279463
Validation loss: 3.7204500777596357

Epoch: 5| Step: 4
Training loss: 4.370243211346293
Validation loss: 3.7158889236164523

Epoch: 5| Step: 5
Training loss: 4.200426334359508
Validation loss: 3.7152410938893947

Epoch: 5| Step: 6
Training loss: 4.113059129359962
Validation loss: 3.7131042475978253

Epoch: 5| Step: 7
Training loss: 3.192529338322485
Validation loss: 3.7073126869262794

Epoch: 5| Step: 8
Training loss: 4.420533748522476
Validation loss: 3.7045392967241435

Epoch: 5| Step: 9
Training loss: 3.947407564671834
Validation loss: 3.7032855969859213

Epoch: 5| Step: 10
Training loss: 3.704275218172615
Validation loss: 3.698274817910207

Epoch: 22| Step: 0
Training loss: 3.7172390729381957
Validation loss: 3.696072083394478

Epoch: 5| Step: 1
Training loss: 4.898492986191426
Validation loss: 3.694304456167881

Epoch: 5| Step: 2
Training loss: 4.05603216729585
Validation loss: 3.694499053775585

Epoch: 5| Step: 3
Training loss: 3.8289324473302297
Validation loss: 3.6897279888911285

Epoch: 5| Step: 4
Training loss: 3.222829955072331
Validation loss: 3.688283675374189

Epoch: 5| Step: 5
Training loss: 3.1761046522948675
Validation loss: 3.6857594365287096

Epoch: 5| Step: 6
Training loss: 4.262896548979894
Validation loss: 3.681401229747434

Epoch: 5| Step: 7
Training loss: 4.188105297466387
Validation loss: 3.6794488750803507

Epoch: 5| Step: 8
Training loss: 3.976479999758148
Validation loss: 3.6774380229975527

Epoch: 5| Step: 9
Training loss: 3.4902024056838883
Validation loss: 3.6750358694197116

Epoch: 5| Step: 10
Training loss: 3.354573211357726
Validation loss: 3.675314577931163

Epoch: 23| Step: 0
Training loss: 3.255308950267906
Validation loss: 3.6715188172438475

Epoch: 5| Step: 1
Training loss: 4.212916883900547
Validation loss: 3.668516397722989

Epoch: 5| Step: 2
Training loss: 4.100269280871585
Validation loss: 3.6681500218987955

Epoch: 5| Step: 3
Training loss: 3.585484960253985
Validation loss: 3.6659742682307215

Epoch: 5| Step: 4
Training loss: 4.562113079229916
Validation loss: 3.6635470800173677

Epoch: 5| Step: 5
Training loss: 3.090849470389718
Validation loss: 3.662989606354562

Epoch: 5| Step: 6
Training loss: 3.7210575926131466
Validation loss: 3.6608777183691603

Epoch: 5| Step: 7
Training loss: 4.193085091606086
Validation loss: 3.6578256559817173

Epoch: 5| Step: 8
Training loss: 3.5132195275373035
Validation loss: 3.6572942218118585

Epoch: 5| Step: 9
Training loss: 4.570221311523515
Validation loss: 3.6554033652269085

Epoch: 5| Step: 10
Training loss: 3.0817081876783705
Validation loss: 3.653646899398377

Epoch: 24| Step: 0
Training loss: 4.093884181961246
Validation loss: 3.6515229698893026

Epoch: 5| Step: 1
Training loss: 3.8235104521544563
Validation loss: 3.6510644598695516

Epoch: 5| Step: 2
Training loss: 3.185720208631113
Validation loss: 3.6481461087678375

Epoch: 5| Step: 3
Training loss: 4.026250059879259
Validation loss: 3.648445000271559

Epoch: 5| Step: 4
Training loss: 4.371824583535916
Validation loss: 3.645410105433037

Epoch: 5| Step: 5
Training loss: 3.956318044453968
Validation loss: 3.644546766032347

Epoch: 5| Step: 6
Training loss: 3.7118814331964978
Validation loss: 3.640971647917648

Epoch: 5| Step: 7
Training loss: 3.7292295624669767
Validation loss: 3.6401248190253064

Epoch: 5| Step: 8
Training loss: 4.044482374420978
Validation loss: 3.638772420504778

Epoch: 5| Step: 9
Training loss: 3.088085653382126
Validation loss: 3.633962806230538

Epoch: 5| Step: 10
Training loss: 3.9969638984582554
Validation loss: 3.635125142387626

Epoch: 25| Step: 0
Training loss: 3.4299245417888895
Validation loss: 3.6310021296491204

Epoch: 5| Step: 1
Training loss: 3.5283957229693854
Validation loss: 3.6303183227228315

Epoch: 5| Step: 2
Training loss: 4.075083332730899
Validation loss: 3.6265523017564987

Epoch: 5| Step: 3
Training loss: 3.681589076645092
Validation loss: 3.6265352312899464

Epoch: 5| Step: 4
Training loss: 4.156253441830694
Validation loss: 3.6244139574197165

Epoch: 5| Step: 5
Training loss: 3.838377881362365
Validation loss: 3.619367216799132

Epoch: 5| Step: 6
Training loss: 3.589290339637059
Validation loss: 3.6168779111205343

Epoch: 5| Step: 7
Training loss: 4.202625344226576
Validation loss: 3.6164440346981603

Epoch: 5| Step: 8
Training loss: 3.6361866366051103
Validation loss: 3.614899444209544

Epoch: 5| Step: 9
Training loss: 3.556291490792124
Validation loss: 3.6144657955768866

Epoch: 5| Step: 10
Training loss: 4.235074256507184
Validation loss: 3.6131679516483985

Epoch: 26| Step: 0
Training loss: 3.1673615011211114
Validation loss: 3.6114117744632592

Epoch: 5| Step: 1
Training loss: 4.342726552584501
Validation loss: 3.6071133327875677

Epoch: 5| Step: 2
Training loss: 2.949650249114639
Validation loss: 3.6058499338244197

Epoch: 5| Step: 3
Training loss: 3.6642186633832234
Validation loss: 3.6058042325702417

Epoch: 5| Step: 4
Training loss: 3.667918049519804
Validation loss: 3.604572285884315

Epoch: 5| Step: 5
Training loss: 4.184203943085124
Validation loss: 3.6005685018423117

Epoch: 5| Step: 6
Training loss: 4.211928440337447
Validation loss: 3.5998315915330252

Epoch: 5| Step: 7
Training loss: 4.202631698078868
Validation loss: 3.599364616410789

Epoch: 5| Step: 8
Training loss: 4.139444895584322
Validation loss: 3.601148439938714

Epoch: 5| Step: 9
Training loss: 3.3720554646447654
Validation loss: 3.5988981192255802

Epoch: 5| Step: 10
Training loss: 3.5729251042183914
Validation loss: 3.6011243066073053

Epoch: 27| Step: 0
Training loss: 3.1230603111030546
Validation loss: 3.59801404745345

Epoch: 5| Step: 1
Training loss: 3.90910710942337
Validation loss: 3.596460004907117

Epoch: 5| Step: 2
Training loss: 4.014691789894547
Validation loss: 3.5965835507521513

Epoch: 5| Step: 3
Training loss: 2.8531496412502118
Validation loss: 3.592928107157586

Epoch: 5| Step: 4
Training loss: 3.6694501946252056
Validation loss: 3.590983470445826

Epoch: 5| Step: 5
Training loss: 4.220646184831097
Validation loss: 3.588137030785075

Epoch: 5| Step: 6
Training loss: 3.728092926987392
Validation loss: 3.587871094096976

Epoch: 5| Step: 7
Training loss: 4.081584529982274
Validation loss: 3.5864533570238866

Epoch: 5| Step: 8
Training loss: 3.821575057579706
Validation loss: 3.586452823773941

Epoch: 5| Step: 9
Training loss: 4.4917098081613
Validation loss: 3.583954028787688

Epoch: 5| Step: 10
Training loss: 3.4231918797028706
Validation loss: 3.5836442629814913

Epoch: 28| Step: 0
Training loss: 4.0320876086723105
Validation loss: 3.582937438130806

Epoch: 5| Step: 1
Training loss: 3.7735317684427
Validation loss: 3.582853245512759

Epoch: 5| Step: 2
Training loss: 3.482204702198407
Validation loss: 3.5811926711748066

Epoch: 5| Step: 3
Training loss: 4.184208045688514
Validation loss: 3.5807301971642884

Epoch: 5| Step: 4
Training loss: 3.5602045527637216
Validation loss: 3.5783439598252595

Epoch: 5| Step: 5
Training loss: 3.829797994201731
Validation loss: 3.576607209175996

Epoch: 5| Step: 6
Training loss: 4.002449716017435
Validation loss: 3.574471597813108

Epoch: 5| Step: 7
Training loss: 3.80436739661828
Validation loss: 3.5741947360873625

Epoch: 5| Step: 8
Training loss: 4.277061473990632
Validation loss: 3.572930993607164

Epoch: 5| Step: 9
Training loss: 2.6139127826398116
Validation loss: 3.572178344632729

Epoch: 5| Step: 10
Training loss: 3.7579013235019536
Validation loss: 3.5731050992998754

Epoch: 29| Step: 0
Training loss: 4.03259586076025
Validation loss: 3.571249510323895

Epoch: 5| Step: 1
Training loss: 4.435676522419985
Validation loss: 3.569012918764085

Epoch: 5| Step: 2
Training loss: 3.625856101133288
Validation loss: 3.569329466149735

Epoch: 5| Step: 3
Training loss: 3.6114093282430066
Validation loss: 3.568519453493731

Epoch: 5| Step: 4
Training loss: 3.345272537555782
Validation loss: 3.56804677664716

Epoch: 5| Step: 5
Training loss: 3.819644050391593
Validation loss: 3.5699991779068503

Epoch: 5| Step: 6
Training loss: 3.7602159582169215
Validation loss: 3.5666123937706447

Epoch: 5| Step: 7
Training loss: 3.270769365661108
Validation loss: 3.5656385918332374

Epoch: 5| Step: 8
Training loss: 3.7839752968995963
Validation loss: 3.565121464641015

Epoch: 5| Step: 9
Training loss: 3.8795182743106715
Validation loss: 3.563244315691895

Epoch: 5| Step: 10
Training loss: 3.8020989543994523
Validation loss: 3.5634922544809746

Epoch: 30| Step: 0
Training loss: 3.928347653047414
Validation loss: 3.5634759452365445

Epoch: 5| Step: 1
Training loss: 4.231131011326613
Validation loss: 3.5627818950469345

Epoch: 5| Step: 2
Training loss: 3.5394389308118157
Validation loss: 3.5602117535804303

Epoch: 5| Step: 3
Training loss: 2.5852025765412217
Validation loss: 3.5593815013759103

Epoch: 5| Step: 4
Training loss: 3.5420693262123395
Validation loss: 3.560093449516772

Epoch: 5| Step: 5
Training loss: 3.7302993815855214
Validation loss: 3.558119120534126

Epoch: 5| Step: 6
Training loss: 5.148727941352359
Validation loss: 3.5574220650774944

Epoch: 5| Step: 7
Training loss: 3.4035324315173106
Validation loss: 3.5550624075902633

Epoch: 5| Step: 8
Training loss: 3.8955608143407976
Validation loss: 3.556826813879842

Epoch: 5| Step: 9
Training loss: 3.1408061264720675
Validation loss: 3.555416156091757

Epoch: 5| Step: 10
Training loss: 3.6941183148630397
Validation loss: 3.55330851014752

Epoch: 31| Step: 0
Training loss: 3.886927797456073
Validation loss: 3.5521972299258326

Epoch: 5| Step: 1
Training loss: 3.0839415457265877
Validation loss: 3.5512062938438507

Epoch: 5| Step: 2
Training loss: 3.7284264851101203
Validation loss: 3.550922044585995

Epoch: 5| Step: 3
Training loss: 3.9467430014144407
Validation loss: 3.5509187076632363

Epoch: 5| Step: 4
Training loss: 4.035171139478217
Validation loss: 3.5499100060894286

Epoch: 5| Step: 5
Training loss: 3.850677202784459
Validation loss: 3.5496430254672293

Epoch: 5| Step: 6
Training loss: 3.8701338208149374
Validation loss: 3.5478765741281935

Epoch: 5| Step: 7
Training loss: 3.538495487828522
Validation loss: 3.552436640473916

Epoch: 5| Step: 8
Training loss: 4.002793766942513
Validation loss: 3.551169197737667

Epoch: 5| Step: 9
Training loss: 3.694723263754342
Validation loss: 3.545867961995315

Epoch: 5| Step: 10
Training loss: 3.5507155812048423
Validation loss: 3.5464358194976264

Epoch: 32| Step: 0
Training loss: 3.840852218871733
Validation loss: 3.5491888599411525

Epoch: 5| Step: 1
Training loss: 3.6625299237692084
Validation loss: 3.547621969568429

Epoch: 5| Step: 2
Training loss: 3.1650488552282168
Validation loss: 3.547486621531674

Epoch: 5| Step: 3
Training loss: 3.8857432919309187
Validation loss: 3.547038397043643

Epoch: 5| Step: 4
Training loss: 4.375463624639336
Validation loss: 3.545648808565049

Epoch: 5| Step: 5
Training loss: 4.194367201025801
Validation loss: 3.5431991639524902

Epoch: 5| Step: 6
Training loss: 3.8129819971795604
Validation loss: 3.542846163097489

Epoch: 5| Step: 7
Training loss: 3.332295987523004
Validation loss: 3.54117650229822

Epoch: 5| Step: 8
Training loss: 3.5730952597303394
Validation loss: 3.5417499356310356

Epoch: 5| Step: 9
Training loss: 3.6744574373370105
Validation loss: 3.539752959042572

Epoch: 5| Step: 10
Training loss: 3.5597048049866467
Validation loss: 3.5416009138012794

Epoch: 33| Step: 0
Training loss: 3.1303616114371473
Validation loss: 3.5400593700172998

Epoch: 5| Step: 1
Training loss: 3.7165931409283037
Validation loss: 3.5400910150989424

Epoch: 5| Step: 2
Training loss: 3.981738126764722
Validation loss: 3.5394581104110197

Epoch: 5| Step: 3
Training loss: 3.3339910970842457
Validation loss: 3.539634062448839

Epoch: 5| Step: 4
Training loss: 4.1012039463814105
Validation loss: 3.537892658120592

Epoch: 5| Step: 5
Training loss: 4.078917678439985
Validation loss: 3.5375215125139112

Epoch: 5| Step: 6
Training loss: 4.0260605640963085
Validation loss: 3.5348742231874595

Epoch: 5| Step: 7
Training loss: 3.5851165563132077
Validation loss: 3.536192769640088

Epoch: 5| Step: 8
Training loss: 3.6176261883010037
Validation loss: 3.5364928402059084

Epoch: 5| Step: 9
Training loss: 3.9973233327182762
Validation loss: 3.5340460371544546

Epoch: 5| Step: 10
Training loss: 3.4235176776949388
Validation loss: 3.5327584190931747

Epoch: 34| Step: 0
Training loss: 4.255549005935538
Validation loss: 3.5321970635300897

Epoch: 5| Step: 1
Training loss: 3.2301534478081253
Validation loss: 3.5303489253416225

Epoch: 5| Step: 2
Training loss: 3.358906132114726
Validation loss: 3.5324238430481096

Epoch: 5| Step: 3
Training loss: 3.760700218661886
Validation loss: 3.531376676604117

Epoch: 5| Step: 4
Training loss: 3.227788881453126
Validation loss: 3.530096663047135

Epoch: 5| Step: 5
Training loss: 3.3686150801610704
Validation loss: 3.529889866181261

Epoch: 5| Step: 6
Training loss: 4.159936173756343
Validation loss: 3.5318192003193754

Epoch: 5| Step: 7
Training loss: 4.124048065393844
Validation loss: 3.5285755229323783

Epoch: 5| Step: 8
Training loss: 3.474744548602034
Validation loss: 3.529197072168373

Epoch: 5| Step: 9
Training loss: 3.4877532867007095
Validation loss: 3.5277560255496305

Epoch: 5| Step: 10
Training loss: 4.527276342250555
Validation loss: 3.526732009549707

Epoch: 35| Step: 0
Training loss: 4.403942613246849
Validation loss: 3.5263935684859997

Epoch: 5| Step: 1
Training loss: 3.9767466804105402
Validation loss: 3.5249748873159734

Epoch: 5| Step: 2
Training loss: 3.329171889153412
Validation loss: 3.525344221032242

Epoch: 5| Step: 3
Training loss: 3.0438511637769943
Validation loss: 3.5247855212921837

Epoch: 5| Step: 4
Training loss: 4.384381725607925
Validation loss: 3.523815291481526

Epoch: 5| Step: 5
Training loss: 3.9895495752777195
Validation loss: 3.5239246096180796

Epoch: 5| Step: 6
Training loss: 3.9037973257048915
Validation loss: 3.524650687739384

Epoch: 5| Step: 7
Training loss: 3.7269265179013695
Validation loss: 3.5230817368491265

Epoch: 5| Step: 8
Training loss: 3.7082727120119996
Validation loss: 3.522686020816466

Epoch: 5| Step: 9
Training loss: 2.9479356816805207
Validation loss: 3.5211249488798178

Epoch: 5| Step: 10
Training loss: 3.276506028168499
Validation loss: 3.5207320143704757

Epoch: 36| Step: 0
Training loss: 3.1351635261487334
Validation loss: 3.521280705285412

Epoch: 5| Step: 1
Training loss: 3.7107565745368896
Validation loss: 3.5208938432272663

Epoch: 5| Step: 2
Training loss: 3.9592321212026693
Validation loss: 3.5203054218850918

Epoch: 5| Step: 3
Training loss: 3.8327521560839046
Validation loss: 3.5193829962685275

Epoch: 5| Step: 4
Training loss: 3.413153555750077
Validation loss: 3.5197549867447555

Epoch: 5| Step: 5
Training loss: 3.8358324584252745
Validation loss: 3.517696519396685

Epoch: 5| Step: 6
Training loss: 4.093003998553842
Validation loss: 3.518087566024288

Epoch: 5| Step: 7
Training loss: 3.7973869826254196
Validation loss: 3.515959329876032

Epoch: 5| Step: 8
Training loss: 3.7509642315030978
Validation loss: 3.516220699326005

Epoch: 5| Step: 9
Training loss: 3.699257549336191
Validation loss: 3.515702696093221

Epoch: 5| Step: 10
Training loss: 3.7030343475191057
Validation loss: 3.5156131983915566

Epoch: 37| Step: 0
Training loss: 3.9485576313977284
Validation loss: 3.5133446170264304

Epoch: 5| Step: 1
Training loss: 4.022389692141877
Validation loss: 3.5136942304452385

Epoch: 5| Step: 2
Training loss: 3.6756216859794457
Validation loss: 3.5134827549373875

Epoch: 5| Step: 3
Training loss: 3.8493222420346234
Validation loss: 3.512186819259463

Epoch: 5| Step: 4
Training loss: 3.5713017468413653
Validation loss: 3.5119276578101677

Epoch: 5| Step: 5
Training loss: 3.540610137127137
Validation loss: 3.5117698630216405

Epoch: 5| Step: 6
Training loss: 3.787189705101496
Validation loss: 3.5109634321713727

Epoch: 5| Step: 7
Training loss: 4.059815444134091
Validation loss: 3.510764419937325

Epoch: 5| Step: 8
Training loss: 3.5168773539799494
Validation loss: 3.509658032366542

Epoch: 5| Step: 9
Training loss: 3.6122095116635116
Validation loss: 3.5078525350453766

Epoch: 5| Step: 10
Training loss: 3.228498639975361
Validation loss: 3.5086434046635646

Epoch: 38| Step: 0
Training loss: 4.191286111978153
Validation loss: 3.5084586805477715

Epoch: 5| Step: 1
Training loss: 2.932186108999157
Validation loss: 3.5086372773070162

Epoch: 5| Step: 2
Training loss: 3.240684068779704
Validation loss: 3.5071481087901084

Epoch: 5| Step: 3
Training loss: 4.144884675081632
Validation loss: 3.5070941623561

Epoch: 5| Step: 4
Training loss: 3.91644214771194
Validation loss: 3.5062274334847987

Epoch: 5| Step: 5
Training loss: 4.432111235135052
Validation loss: 3.506143194629416

Epoch: 5| Step: 6
Training loss: 3.062898103957598
Validation loss: 3.5070888634265174

Epoch: 5| Step: 7
Training loss: 3.2455789867116738
Validation loss: 3.5047238432320573

Epoch: 5| Step: 8
Training loss: 3.5903290761942994
Validation loss: 3.5051110374249683

Epoch: 5| Step: 9
Training loss: 3.1073299564598846
Validation loss: 3.5045790244596247

Epoch: 5| Step: 10
Training loss: 4.704366425067643
Validation loss: 3.504041197718767

Epoch: 39| Step: 0
Training loss: 3.519561462611375
Validation loss: 3.5039404033571677

Epoch: 5| Step: 1
Training loss: 4.207332277995278
Validation loss: 3.503227401249126

Epoch: 5| Step: 2
Training loss: 3.304789512268209
Validation loss: 3.501805118325916

Epoch: 5| Step: 3
Training loss: 2.859852902024127
Validation loss: 3.502113952012895

Epoch: 5| Step: 4
Training loss: 3.578595792623814
Validation loss: 3.5030537319937243

Epoch: 5| Step: 5
Training loss: 4.6564863516198844
Validation loss: 3.5020222952245748

Epoch: 5| Step: 6
Training loss: 4.241793619490647
Validation loss: 3.501897110230901

Epoch: 5| Step: 7
Training loss: 3.164975032376465
Validation loss: 3.5007947584874444

Epoch: 5| Step: 8
Training loss: 3.3947142802982464
Validation loss: 3.5003624053115314

Epoch: 5| Step: 9
Training loss: 3.895706473884302
Validation loss: 3.500255253122809

Epoch: 5| Step: 10
Training loss: 3.663652799755758
Validation loss: 3.5008710020607694

Epoch: 40| Step: 0
Training loss: 3.6809420704572373
Validation loss: 3.5003252508216223

Epoch: 5| Step: 1
Training loss: 4.142735357326694
Validation loss: 3.50003059508609

Epoch: 5| Step: 2
Training loss: 2.996676034060538
Validation loss: 3.500155148092556

Epoch: 5| Step: 3
Training loss: 3.4169109691333612
Validation loss: 3.4993737637632014

Epoch: 5| Step: 4
Training loss: 3.768044988124709
Validation loss: 3.4974832231658906

Epoch: 5| Step: 5
Training loss: 3.717948121881142
Validation loss: 3.4969343069455694

Epoch: 5| Step: 6
Training loss: 3.7282447456768435
Validation loss: 3.4983683311807723

Epoch: 5| Step: 7
Training loss: 3.646158229338659
Validation loss: 3.4970592576002026

Epoch: 5| Step: 8
Training loss: 3.336589954903156
Validation loss: 3.4959647741431827

Epoch: 5| Step: 9
Training loss: 4.503653632537711
Validation loss: 3.496041372372821

Epoch: 5| Step: 10
Training loss: 3.677570616914789
Validation loss: 3.4947318716939684

Epoch: 41| Step: 0
Training loss: 3.350882934820477
Validation loss: 3.495302904217357

Epoch: 5| Step: 1
Training loss: 3.4805545132706417
Validation loss: 3.4966095427998747

Epoch: 5| Step: 2
Training loss: 4.419775150845708
Validation loss: 3.4966678725670395

Epoch: 5| Step: 3
Training loss: 3.612351020460156
Validation loss: 3.4943101049061163

Epoch: 5| Step: 4
Training loss: 3.596247460368045
Validation loss: 3.4959140254984695

Epoch: 5| Step: 5
Training loss: 3.735657156617115
Validation loss: 3.4943132053580492

Epoch: 5| Step: 6
Training loss: 3.5838313680724814
Validation loss: 3.495897905514407

Epoch: 5| Step: 7
Training loss: 3.766205169177958
Validation loss: 3.4948899237395556

Epoch: 5| Step: 8
Training loss: 3.526110664868367
Validation loss: 3.493670721345339

Epoch: 5| Step: 9
Training loss: 3.463297226772377
Validation loss: 3.493222981135974

Epoch: 5| Step: 10
Training loss: 4.200934424222913
Validation loss: 3.4930808810392935

Epoch: 42| Step: 0
Training loss: 4.227592638874241
Validation loss: 3.492341253938953

Epoch: 5| Step: 1
Training loss: 3.941882041439785
Validation loss: 3.492367712840392

Epoch: 5| Step: 2
Training loss: 3.9485703114257014
Validation loss: 3.4933082815710947

Epoch: 5| Step: 3
Training loss: 3.72454190605679
Validation loss: 3.491520655402911

Epoch: 5| Step: 4
Training loss: 3.421060961740213
Validation loss: 3.490894476960617

Epoch: 5| Step: 5
Training loss: 2.0336887684744296
Validation loss: 3.4909423728498634

Epoch: 5| Step: 6
Training loss: 4.179878701088172
Validation loss: 3.491529704258516

Epoch: 5| Step: 7
Training loss: 3.9093130080860026
Validation loss: 3.4912199181331407

Epoch: 5| Step: 8
Training loss: 3.4369635423464207
Validation loss: 3.490435085138573

Epoch: 5| Step: 9
Training loss: 3.743907047601356
Validation loss: 3.4901270257192256

Epoch: 5| Step: 10
Training loss: 3.7126787136232
Validation loss: 3.490014858804811

Epoch: 43| Step: 0
Training loss: 3.785668180035849
Validation loss: 3.4898655274843104

Epoch: 5| Step: 1
Training loss: 3.5164696251023666
Validation loss: 3.488523387622519

Epoch: 5| Step: 2
Training loss: 3.5027062988517357
Validation loss: 3.4895787794474957

Epoch: 5| Step: 3
Training loss: 4.216139147986644
Validation loss: 3.4879666036907624

Epoch: 5| Step: 4
Training loss: 3.708387538785204
Validation loss: 3.4877417303715967

Epoch: 5| Step: 5
Training loss: 3.1955600633296144
Validation loss: 3.4865172613864135

Epoch: 5| Step: 6
Training loss: 3.9099530787469727
Validation loss: 3.4880985152938937

Epoch: 5| Step: 7
Training loss: 3.798090861739719
Validation loss: 3.4871052616560183

Epoch: 5| Step: 8
Training loss: 3.8679795195896323
Validation loss: 3.487148915475747

Epoch: 5| Step: 9
Training loss: 3.631057676386202
Validation loss: 3.4873523298204447

Epoch: 5| Step: 10
Training loss: 3.4641398819129634
Validation loss: 3.486288039851178

Epoch: 44| Step: 0
Training loss: 4.269983768476953
Validation loss: 3.4871160628642004

Epoch: 5| Step: 1
Training loss: 4.116576408189564
Validation loss: 3.4858417864252678

Epoch: 5| Step: 2
Training loss: 2.803418395679266
Validation loss: 3.4865779026269297

Epoch: 5| Step: 3
Training loss: 3.998866516686188
Validation loss: 3.4863429788601823

Epoch: 5| Step: 4
Training loss: 3.3316894928412797
Validation loss: 3.485936328646542

Epoch: 5| Step: 5
Training loss: 3.8190098201188944
Validation loss: 3.4853770755973246

Epoch: 5| Step: 6
Training loss: 4.119790689280989
Validation loss: 3.4843908922364686

Epoch: 5| Step: 7
Training loss: 2.87796564147672
Validation loss: 3.4842895191253747

Epoch: 5| Step: 8
Training loss: 2.690052151369449
Validation loss: 3.483018151551278

Epoch: 5| Step: 9
Training loss: 4.485861289381155
Validation loss: 3.4828271682278666

Epoch: 5| Step: 10
Training loss: 3.634103590719595
Validation loss: 3.4843055942222034

Epoch: 45| Step: 0
Training loss: 3.101998632404904
Validation loss: 3.48245911891189

Epoch: 5| Step: 1
Training loss: 2.767283141918952
Validation loss: 3.4837001310868434

Epoch: 5| Step: 2
Training loss: 3.673548929657318
Validation loss: 3.483235002054084

Epoch: 5| Step: 3
Training loss: 3.987236999639774
Validation loss: 3.483268845845333

Epoch: 5| Step: 4
Training loss: 3.4587676606659703
Validation loss: 3.4836712632429583

Epoch: 5| Step: 5
Training loss: 3.934564010527964
Validation loss: 3.483868077615719

Epoch: 5| Step: 6
Training loss: 3.553393721672726
Validation loss: 3.4825006011761435

Epoch: 5| Step: 7
Training loss: 3.191138042633241
Validation loss: 3.4831220795829756

Epoch: 5| Step: 8
Training loss: 3.4425486163527377
Validation loss: 3.4807175766857643

Epoch: 5| Step: 9
Training loss: 4.717380552331209
Validation loss: 3.480045323829327

Epoch: 5| Step: 10
Training loss: 4.512455550632665
Validation loss: 3.481057243175165

Epoch: 46| Step: 0
Training loss: 3.5706477101767446
Validation loss: 3.479776059511194

Epoch: 5| Step: 1
Training loss: 4.356036695733873
Validation loss: 3.4799882418464865

Epoch: 5| Step: 2
Training loss: 3.599671370023654
Validation loss: 3.479501736231613

Epoch: 5| Step: 3
Training loss: 3.6592456250731105
Validation loss: 3.479017840429674

Epoch: 5| Step: 4
Training loss: 3.6331527058443847
Validation loss: 3.480059615173715

Epoch: 5| Step: 5
Training loss: 3.626939714989345
Validation loss: 3.4792555783598456

Epoch: 5| Step: 6
Training loss: 3.765281186691899
Validation loss: 3.4792410921346506

Epoch: 5| Step: 7
Training loss: 3.1006273065645713
Validation loss: 3.478783652287373

Epoch: 5| Step: 8
Training loss: 4.182153277484812
Validation loss: 3.478719477104607

Epoch: 5| Step: 9
Training loss: 3.1755383012660414
Validation loss: 3.4774505325396228

Epoch: 5| Step: 10
Training loss: 3.8049543157935393
Validation loss: 3.4780021979917954

Epoch: 47| Step: 0
Training loss: 4.369321789521873
Validation loss: 3.4776754491357194

Epoch: 5| Step: 1
Training loss: 3.4215999126906134
Validation loss: 3.478152196386606

Epoch: 5| Step: 2
Training loss: 3.52984685787172
Validation loss: 3.476016383815254

Epoch: 5| Step: 3
Training loss: 3.118177060877621
Validation loss: 3.4777868309044258

Epoch: 5| Step: 4
Training loss: 3.7767616304700926
Validation loss: 3.4758698866144595

Epoch: 5| Step: 5
Training loss: 3.444791239709696
Validation loss: 3.475638548153661

Epoch: 5| Step: 6
Training loss: 3.2667773098275914
Validation loss: 3.476349058439784

Epoch: 5| Step: 7
Training loss: 4.321483818881032
Validation loss: 3.4748310935413484

Epoch: 5| Step: 8
Training loss: 4.309896152953475
Validation loss: 3.47441344842107

Epoch: 5| Step: 9
Training loss: 3.7277223713359864
Validation loss: 3.474953417297219

Epoch: 5| Step: 10
Training loss: 2.857461591380682
Validation loss: 3.4741093574028037

Epoch: 48| Step: 0
Training loss: 4.3008344683355855
Validation loss: 3.4739766607557354

Epoch: 5| Step: 1
Training loss: 3.99772889513155
Validation loss: 3.4740335123922867

Epoch: 5| Step: 2
Training loss: 3.7263434323712787
Validation loss: 3.4745512474799964

Epoch: 5| Step: 3
Training loss: 3.7529996954259386
Validation loss: 3.4726729355750376

Epoch: 5| Step: 4
Training loss: 3.5680629730312496
Validation loss: 3.471986018907613

Epoch: 5| Step: 5
Training loss: 3.1428110286500206
Validation loss: 3.4729493572757204

Epoch: 5| Step: 6
Training loss: 3.513926048903227
Validation loss: 3.472826726706643

Epoch: 5| Step: 7
Training loss: 3.4400677887203344
Validation loss: 3.4715969645535694

Epoch: 5| Step: 8
Training loss: 3.9079915551335467
Validation loss: 3.472956863020012

Epoch: 5| Step: 9
Training loss: 3.666760327847988
Validation loss: 3.472118125640368

Epoch: 5| Step: 10
Training loss: 3.3766653402714386
Validation loss: 3.4717439418615843

Epoch: 49| Step: 0
Training loss: 3.2301349951816514
Validation loss: 3.470774958130874

Epoch: 5| Step: 1
Training loss: 2.9049993305566644
Validation loss: 3.47035085153064

Epoch: 5| Step: 2
Training loss: 3.341055238743802
Validation loss: 3.470731876158249

Epoch: 5| Step: 3
Training loss: 2.7617159874455774
Validation loss: 3.471493039313818

Epoch: 5| Step: 4
Training loss: 4.139192844525947
Validation loss: 3.4699523410300364

Epoch: 5| Step: 5
Training loss: 3.82882845896288
Validation loss: 3.4707390247624637

Epoch: 5| Step: 6
Training loss: 3.0538806679025727
Validation loss: 3.4699848109039912

Epoch: 5| Step: 7
Training loss: 4.498589824550122
Validation loss: 3.469352268569243

Epoch: 5| Step: 8
Training loss: 4.810343073230612
Validation loss: 3.4715677804331757

Epoch: 5| Step: 9
Training loss: 2.8818485126589413
Validation loss: 3.4686764043487246

Epoch: 5| Step: 10
Training loss: 4.468563049247225
Validation loss: 3.4689439037388703

Epoch: 50| Step: 0
Training loss: 3.9593114882435683
Validation loss: 3.467337913185814

Epoch: 5| Step: 1
Training loss: 3.2670609087069638
Validation loss: 3.466494664318057

Epoch: 5| Step: 2
Training loss: 3.453280760415218
Validation loss: 3.4688477210939626

Epoch: 5| Step: 3
Training loss: 3.6841081440115815
Validation loss: 3.4675697019177427

Epoch: 5| Step: 4
Training loss: 3.81518422673125
Validation loss: 3.46828081260916

Epoch: 5| Step: 5
Training loss: 3.4516130131988003
Validation loss: 3.466780022119892

Epoch: 5| Step: 6
Training loss: 3.6084057055491754
Validation loss: 3.4671244006319837

Epoch: 5| Step: 7
Training loss: 3.527401067156132
Validation loss: 3.4665697735205048

Epoch: 5| Step: 8
Training loss: 3.8074765488822235
Validation loss: 3.467210076962907

Epoch: 5| Step: 9
Training loss: 3.8455356079008425
Validation loss: 3.466660798409404

Epoch: 5| Step: 10
Training loss: 4.100499536740086
Validation loss: 3.4671717405565285

Epoch: 51| Step: 0
Training loss: 3.4894137365017786
Validation loss: 3.466038516342123

Epoch: 5| Step: 1
Training loss: 3.8175781699660414
Validation loss: 3.4650384198287436

Epoch: 5| Step: 2
Training loss: 3.544792336863588
Validation loss: 3.465653868857109

Epoch: 5| Step: 3
Training loss: 3.85758195375915
Validation loss: 3.464849590771931

Epoch: 5| Step: 4
Training loss: 3.857081917377229
Validation loss: 3.4646125765633777

Epoch: 5| Step: 5
Training loss: 4.1126071997123645
Validation loss: 3.4627837895264606

Epoch: 5| Step: 6
Training loss: 2.987409237556301
Validation loss: 3.462964502036584

Epoch: 5| Step: 7
Training loss: 4.016209659985268
Validation loss: 3.4622544260152726

Epoch: 5| Step: 8
Training loss: 3.659085470289241
Validation loss: 3.464363171824285

Epoch: 5| Step: 9
Training loss: 3.5180030748224835
Validation loss: 3.462941671037947

Epoch: 5| Step: 10
Training loss: 3.4664036143587147
Validation loss: 3.4623559630030876

Epoch: 52| Step: 0
Training loss: 3.2754682191632596
Validation loss: 3.461735094727858

Epoch: 5| Step: 1
Training loss: 3.0986628201844355
Validation loss: 3.4624393731923706

Epoch: 5| Step: 2
Training loss: 3.842182863410302
Validation loss: 3.462777795720953

Epoch: 5| Step: 3
Training loss: 3.9487547106592493
Validation loss: 3.4625061105588566

Epoch: 5| Step: 4
Training loss: 3.8201569757613374
Validation loss: 3.461871584132922

Epoch: 5| Step: 5
Training loss: 3.753623356316724
Validation loss: 3.4619597512298017

Epoch: 5| Step: 6
Training loss: 3.839532166235126
Validation loss: 3.4628800177059036

Epoch: 5| Step: 7
Training loss: 3.8441243803481324
Validation loss: 3.461729824861693

Epoch: 5| Step: 8
Training loss: 3.4002906394601466
Validation loss: 3.461569058984474

Epoch: 5| Step: 9
Training loss: 3.7215586081803274
Validation loss: 3.4614739038112647

Epoch: 5| Step: 10
Training loss: 3.8450888186193164
Validation loss: 3.46078089007379

Epoch: 53| Step: 0
Training loss: 3.3708880771738783
Validation loss: 3.461000624937269

Epoch: 5| Step: 1
Training loss: 3.250715617108859
Validation loss: 3.4607121030238375

Epoch: 5| Step: 2
Training loss: 3.4893993879583465
Validation loss: 3.4582798703258524

Epoch: 5| Step: 3
Training loss: 3.109527890841061
Validation loss: 3.46081280893992

Epoch: 5| Step: 4
Training loss: 3.4763906372109266
Validation loss: 3.459317578893915

Epoch: 5| Step: 5
Training loss: 3.4093034689555894
Validation loss: 3.458084339637701

Epoch: 5| Step: 6
Training loss: 3.4956201669464178
Validation loss: 3.4601043221986014

Epoch: 5| Step: 7
Training loss: 4.191549591997897
Validation loss: 3.4580091365748853

Epoch: 5| Step: 8
Training loss: 4.418267062071634
Validation loss: 3.4592553473911534

Epoch: 5| Step: 9
Training loss: 3.959907232219053
Validation loss: 3.4580926234397538

Epoch: 5| Step: 10
Training loss: 4.07699861719493
Validation loss: 3.457482432062449

Epoch: 54| Step: 0
Training loss: 3.3629399745642163
Validation loss: 3.4558724846137445

Epoch: 5| Step: 1
Training loss: 3.412068847695066
Validation loss: 3.4571463090508634

Epoch: 5| Step: 2
Training loss: 4.004099175992228
Validation loss: 3.456804426559532

Epoch: 5| Step: 3
Training loss: 4.206998380428118
Validation loss: 3.4562344389611543

Epoch: 5| Step: 4
Training loss: 3.9028289462740373
Validation loss: 3.4561067572670296

Epoch: 5| Step: 5
Training loss: 3.061188864792595
Validation loss: 3.455926214329935

Epoch: 5| Step: 6
Training loss: 3.955206161122014
Validation loss: 3.4563702392075863

Epoch: 5| Step: 7
Training loss: 3.134469600021974
Validation loss: 3.456563855441785

Epoch: 5| Step: 8
Training loss: 2.6942335540023183
Validation loss: 3.4568662520282754

Epoch: 5| Step: 9
Training loss: 3.595902304284421
Validation loss: 3.4560466925597497

Epoch: 5| Step: 10
Training loss: 4.786050617949848
Validation loss: 3.4542909954261223

Epoch: 55| Step: 0
Training loss: 4.000790279522007
Validation loss: 3.4562224553267558

Epoch: 5| Step: 1
Training loss: 3.590315795015053
Validation loss: 3.456277194295641

Epoch: 5| Step: 2
Training loss: 3.1052722028997013
Validation loss: 3.4551361097112054

Epoch: 5| Step: 3
Training loss: 4.237664890738328
Validation loss: 3.454894168392128

Epoch: 5| Step: 4
Training loss: 2.96290575298956
Validation loss: 3.4544925768447357

Epoch: 5| Step: 5
Training loss: 3.8678913747452386
Validation loss: 3.4540543833737867

Epoch: 5| Step: 6
Training loss: 3.1957526988003386
Validation loss: 3.4522565912426035

Epoch: 5| Step: 7
Training loss: 3.4606605573980054
Validation loss: 3.4531978357655584

Epoch: 5| Step: 8
Training loss: 3.89351708953975
Validation loss: 3.451663114901093

Epoch: 5| Step: 9
Training loss: 3.9715140021839854
Validation loss: 3.4531745333578785

Epoch: 5| Step: 10
Training loss: 3.896585701220124
Validation loss: 3.4507503099651347

Epoch: 56| Step: 0
Training loss: 3.8634534282521056
Validation loss: 3.4514445845656754

Epoch: 5| Step: 1
Training loss: 4.414220648439027
Validation loss: 3.4514174435252083

Epoch: 5| Step: 2
Training loss: 2.978787449174311
Validation loss: 3.4512611488713407

Epoch: 5| Step: 3
Training loss: 3.94759407168125
Validation loss: 3.4506203287383594

Epoch: 5| Step: 4
Training loss: 3.7853106928792486
Validation loss: 3.4486649957767326

Epoch: 5| Step: 5
Training loss: 3.8716438279865226
Validation loss: 3.44898500401748

Epoch: 5| Step: 6
Training loss: 3.0710561691309914
Validation loss: 3.449943475912655

Epoch: 5| Step: 7
Training loss: 2.8662157620806923
Validation loss: 3.4501380175281002

Epoch: 5| Step: 8
Training loss: 3.1756686370139846
Validation loss: 3.449884702430214

Epoch: 5| Step: 9
Training loss: 3.6492034304180283
Validation loss: 3.448636716307129

Epoch: 5| Step: 10
Training loss: 4.44204865626756
Validation loss: 3.4501729513162673

Epoch: 57| Step: 0
Training loss: 4.157636138834116
Validation loss: 3.450325754060509

Epoch: 5| Step: 1
Training loss: 3.8050020624423357
Validation loss: 3.451086567127787

Epoch: 5| Step: 2
Training loss: 3.748993802183273
Validation loss: 3.4509434525674907

Epoch: 5| Step: 3
Training loss: 3.435590178806108
Validation loss: 3.4527696367158023

Epoch: 5| Step: 4
Training loss: 3.7695640127705103
Validation loss: 3.4508585104982075

Epoch: 5| Step: 5
Training loss: 4.036966691358584
Validation loss: 3.4489880188528192

Epoch: 5| Step: 6
Training loss: 3.111466054499194
Validation loss: 3.4470679642612025

Epoch: 5| Step: 7
Training loss: 3.5387337302450743
Validation loss: 3.4469574774842835

Epoch: 5| Step: 8
Training loss: 3.8529302864965698
Validation loss: 3.4461640534366125

Epoch: 5| Step: 9
Training loss: 2.664563173919207
Validation loss: 3.446858555651312

Epoch: 5| Step: 10
Training loss: 3.9872127226184153
Validation loss: 3.445362659095081

Epoch: 58| Step: 0
Training loss: 3.9449438546056914
Validation loss: 3.445966208991076

Epoch: 5| Step: 1
Training loss: 4.549358305902427
Validation loss: 3.445580883212022

Epoch: 5| Step: 2
Training loss: 3.576846098248998
Validation loss: 3.4451924798116758

Epoch: 5| Step: 3
Training loss: 4.036329514283488
Validation loss: 3.4452691011158185

Epoch: 5| Step: 4
Training loss: 2.868267967931912
Validation loss: 3.4450676571782974

Epoch: 5| Step: 5
Training loss: 3.413540239346419
Validation loss: 3.4446289152255694

Epoch: 5| Step: 6
Training loss: 4.17265809671018
Validation loss: 3.4442528883002113

Epoch: 5| Step: 7
Training loss: 3.232956284892645
Validation loss: 3.444131832268846

Epoch: 5| Step: 8
Training loss: 3.038241317145249
Validation loss: 3.443689163993065

Epoch: 5| Step: 9
Training loss: 3.9255457261828006
Validation loss: 3.4460040827414224

Epoch: 5| Step: 10
Training loss: 3.055786715539339
Validation loss: 3.4463991764592667

Epoch: 59| Step: 0
Training loss: 3.651351124722291
Validation loss: 3.4434240401876828

Epoch: 5| Step: 1
Training loss: 3.941910710485269
Validation loss: 3.4432332961316985

Epoch: 5| Step: 2
Training loss: 2.188724175283951
Validation loss: 3.443620224625305

Epoch: 5| Step: 3
Training loss: 2.9780514815103314
Validation loss: 3.4448624068257545

Epoch: 5| Step: 4
Training loss: 4.533214906005803
Validation loss: 3.445747716140881

Epoch: 5| Step: 5
Training loss: 4.0518177144809755
Validation loss: 3.4461921820986827

Epoch: 5| Step: 6
Training loss: 3.754325533662141
Validation loss: 3.4432193076000024

Epoch: 5| Step: 7
Training loss: 4.3223527778012985
Validation loss: 3.441447409170137

Epoch: 5| Step: 8
Training loss: 3.7245620060405518
Validation loss: 3.4408255844687194

Epoch: 5| Step: 9
Training loss: 3.590205426514984
Validation loss: 3.4412379758942047

Epoch: 5| Step: 10
Training loss: 2.741258860659423
Validation loss: 3.44093303316561

Epoch: 60| Step: 0
Training loss: 3.794213260727881
Validation loss: 3.4410794517220773

Epoch: 5| Step: 1
Training loss: 3.6049653566682607
Validation loss: 3.4403994938370523

Epoch: 5| Step: 2
Training loss: 4.298313413359115
Validation loss: 3.4413728214070773

Epoch: 5| Step: 3
Training loss: 3.8757532679680526
Validation loss: 3.439052576468933

Epoch: 5| Step: 4
Training loss: 3.4931486373104352
Validation loss: 3.4394138963287006

Epoch: 5| Step: 5
Training loss: 3.6212928495021592
Validation loss: 3.4414402369676234

Epoch: 5| Step: 6
Training loss: 3.5635881602489783
Validation loss: 3.439577695239793

Epoch: 5| Step: 7
Training loss: 3.3409606136956516
Validation loss: 3.4412219782365727

Epoch: 5| Step: 8
Training loss: 3.0798153955697694
Validation loss: 3.442743446265731

Epoch: 5| Step: 9
Training loss: 3.8569553218644366
Validation loss: 3.4457682252185236

Epoch: 5| Step: 10
Training loss: 3.5768018383307223
Validation loss: 3.444879495674871

Epoch: 61| Step: 0
Training loss: 3.2465385196573813
Validation loss: 3.4412196553889767

Epoch: 5| Step: 1
Training loss: 2.975649075265499
Validation loss: 3.4424357071810308

Epoch: 5| Step: 2
Training loss: 2.8945022560963527
Validation loss: 3.4389729093390913

Epoch: 5| Step: 3
Training loss: 3.572699418798755
Validation loss: 3.438499819874037

Epoch: 5| Step: 4
Training loss: 3.1119342029254735
Validation loss: 3.4385431580655643

Epoch: 5| Step: 5
Training loss: 3.5435898140793296
Validation loss: 3.4388006156841873

Epoch: 5| Step: 6
Training loss: 3.4286280496781143
Validation loss: 3.436782644229009

Epoch: 5| Step: 7
Training loss: 4.577984596156532
Validation loss: 3.436636481238814

Epoch: 5| Step: 8
Training loss: 3.91222321625114
Validation loss: 3.4367036540274154

Epoch: 5| Step: 9
Training loss: 4.344441530357309
Validation loss: 3.4362186598082802

Epoch: 5| Step: 10
Training loss: 4.256654130344158
Validation loss: 3.4376700097307515

Epoch: 62| Step: 0
Training loss: 3.212319626549898
Validation loss: 3.4359632649902903

Epoch: 5| Step: 1
Training loss: 3.1966825872932407
Validation loss: 3.4364428015979307

Epoch: 5| Step: 2
Training loss: 3.932268209155855
Validation loss: 3.4350666909004657

Epoch: 5| Step: 3
Training loss: 4.126396405229485
Validation loss: 3.4353037271850027

Epoch: 5| Step: 4
Training loss: 4.21422328394722
Validation loss: 3.4362723029167173

Epoch: 5| Step: 5
Training loss: 3.3925240116492468
Validation loss: 3.436583522661643

Epoch: 5| Step: 6
Training loss: 3.5372127726380236
Validation loss: 3.435389249371808

Epoch: 5| Step: 7
Training loss: 3.338474854243625
Validation loss: 3.4367351236632087

Epoch: 5| Step: 8
Training loss: 3.81226448207128
Validation loss: 3.437183934631432

Epoch: 5| Step: 9
Training loss: 3.9836415532040608
Validation loss: 3.4343120600050154

Epoch: 5| Step: 10
Training loss: 3.162246748241689
Validation loss: 3.4340936617734656

Epoch: 63| Step: 0
Training loss: 4.057535747716111
Validation loss: 3.4352414285710213

Epoch: 5| Step: 1
Training loss: 4.050493073765835
Validation loss: 3.4342160928616963

Epoch: 5| Step: 2
Training loss: 3.8583755743517125
Validation loss: 3.435853025495926

Epoch: 5| Step: 3
Training loss: 4.066555874258559
Validation loss: 3.435633920826998

Epoch: 5| Step: 4
Training loss: 3.69493672111538
Validation loss: 3.433319041609376

Epoch: 5| Step: 5
Training loss: 3.437688232816839
Validation loss: 3.4330535664973327

Epoch: 5| Step: 6
Training loss: 3.3751672773939108
Validation loss: 3.432936511079229

Epoch: 5| Step: 7
Training loss: 4.0803158308718075
Validation loss: 3.4323261795849516

Epoch: 5| Step: 8
Training loss: 2.9835814374623206
Validation loss: 3.4323683962034477

Epoch: 5| Step: 9
Training loss: 2.919479285541525
Validation loss: 3.4323003363826206

Epoch: 5| Step: 10
Training loss: 3.3363792966655126
Validation loss: 3.4321255356207594

Epoch: 64| Step: 0
Training loss: 4.232767510835109
Validation loss: 3.431811704892077

Epoch: 5| Step: 1
Training loss: 4.180190810087529
Validation loss: 3.432467439870481

Epoch: 5| Step: 2
Training loss: 3.0267475156306753
Validation loss: 3.4323332229442136

Epoch: 5| Step: 3
Training loss: 4.304768584053718
Validation loss: 3.4329887806437864

Epoch: 5| Step: 4
Training loss: 2.970106116303263
Validation loss: 3.4368029994349487

Epoch: 5| Step: 5
Training loss: 4.071551290015461
Validation loss: 3.435281388470762

Epoch: 5| Step: 6
Training loss: 3.5619035188008805
Validation loss: 3.4362797007684986

Epoch: 5| Step: 7
Training loss: 3.4712202194634263
Validation loss: 3.434266667831193

Epoch: 5| Step: 8
Training loss: 3.5894824355711004
Validation loss: 3.430706106777792

Epoch: 5| Step: 9
Training loss: 3.064149995961997
Validation loss: 3.4304499495665404

Epoch: 5| Step: 10
Training loss: 3.274690593052206
Validation loss: 3.4295711624208

Epoch: 65| Step: 0
Training loss: 3.27955525546453
Validation loss: 3.428343623099098

Epoch: 5| Step: 1
Training loss: 3.841520329554799
Validation loss: 3.426774640765671

Epoch: 5| Step: 2
Training loss: 3.9583633154018023
Validation loss: 3.4273582208864712

Epoch: 5| Step: 3
Training loss: 3.477379452160647
Validation loss: 3.428493682449357

Epoch: 5| Step: 4
Training loss: 3.6402568057929074
Validation loss: 3.4263466411852845

Epoch: 5| Step: 5
Training loss: 2.8749217147120123
Validation loss: 3.4260107514424307

Epoch: 5| Step: 6
Training loss: 3.488187064579186
Validation loss: 3.425986153651119

Epoch: 5| Step: 7
Training loss: 3.7007557174513726
Validation loss: 3.4264446977203544

Epoch: 5| Step: 8
Training loss: 4.788062335023665
Validation loss: 3.426370534568874

Epoch: 5| Step: 9
Training loss: 3.631372835113814
Validation loss: 3.4272825478232365

Epoch: 5| Step: 10
Training loss: 2.995255851707413
Validation loss: 3.4259717878965885

Epoch: 66| Step: 0
Training loss: 3.2212895125014844
Validation loss: 3.425767079451464

Epoch: 5| Step: 1
Training loss: 3.31482514163334
Validation loss: 3.426343720904673

Epoch: 5| Step: 2
Training loss: 3.5603392891523464
Validation loss: 3.42725705331336

Epoch: 5| Step: 3
Training loss: 3.6312822297811302
Validation loss: 3.427730992944273

Epoch: 5| Step: 4
Training loss: 3.480492999573561
Validation loss: 3.4259326076476286

Epoch: 5| Step: 5
Training loss: 3.18795189739586
Validation loss: 3.4274517636392536

Epoch: 5| Step: 6
Training loss: 3.9804189152915725
Validation loss: 3.4256871796891604

Epoch: 5| Step: 7
Training loss: 4.285298236452371
Validation loss: 3.426364638678343

Epoch: 5| Step: 8
Training loss: 4.076005055807196
Validation loss: 3.4257361339306764

Epoch: 5| Step: 9
Training loss: 3.8055753514006248
Validation loss: 3.4257887737771373

Epoch: 5| Step: 10
Training loss: 3.303513627301483
Validation loss: 3.4262978079002777

Epoch: 67| Step: 0
Training loss: 3.8851405941379085
Validation loss: 3.4257133107564757

Epoch: 5| Step: 1
Training loss: 3.165982339767582
Validation loss: 3.425783340854385

Epoch: 5| Step: 2
Training loss: 3.841482842957815
Validation loss: 3.425934827866229

Epoch: 5| Step: 3
Training loss: 3.305646896881207
Validation loss: 3.423099691427104

Epoch: 5| Step: 4
Training loss: 3.1640899280254087
Validation loss: 3.4238684756761186

Epoch: 5| Step: 5
Training loss: 3.5690175719423136
Validation loss: 3.422382300088068

Epoch: 5| Step: 6
Training loss: 3.552503917028857
Validation loss: 3.42308997937022

Epoch: 5| Step: 7
Training loss: 4.280488329329309
Validation loss: 3.423446479476649

Epoch: 5| Step: 8
Training loss: 4.489818286574631
Validation loss: 3.421795695632324

Epoch: 5| Step: 9
Training loss: 3.4321972260436775
Validation loss: 3.422139885232688

Epoch: 5| Step: 10
Training loss: 2.9577168283441067
Validation loss: 3.4211030888171265

Epoch: 68| Step: 0
Training loss: 3.4243375374209872
Validation loss: 3.422047216127675

Epoch: 5| Step: 1
Training loss: 3.166036861096654
Validation loss: 3.4217557588056677

Epoch: 5| Step: 2
Training loss: 3.7134161130306453
Validation loss: 3.4242735150109227

Epoch: 5| Step: 3
Training loss: 3.9692472611939413
Validation loss: 3.4229035007367226

Epoch: 5| Step: 4
Training loss: 3.5002183846053376
Validation loss: 3.4239560909383635

Epoch: 5| Step: 5
Training loss: 3.2787326420489227
Validation loss: 3.4243496700703195

Epoch: 5| Step: 6
Training loss: 4.097862216656888
Validation loss: 3.42505273930312

Epoch: 5| Step: 7
Training loss: 4.060440480433324
Validation loss: 3.4230811734885327

Epoch: 5| Step: 8
Training loss: 3.3875690523548974
Validation loss: 3.4228973022829523

Epoch: 5| Step: 9
Training loss: 3.4509074137318456
Validation loss: 3.4213186259272943

Epoch: 5| Step: 10
Training loss: 3.872954043816257
Validation loss: 3.419651708903446

Epoch: 69| Step: 0
Training loss: 3.2174795661994704
Validation loss: 3.419876452245341

Epoch: 5| Step: 1
Training loss: 3.947070525121846
Validation loss: 3.4194873813438624

Epoch: 5| Step: 2
Training loss: 3.7889346386287506
Validation loss: 3.4202232373064696

Epoch: 5| Step: 3
Training loss: 3.987054858578259
Validation loss: 3.4189236032439165

Epoch: 5| Step: 4
Training loss: 4.020804423226634
Validation loss: 3.4191230484757638

Epoch: 5| Step: 5
Training loss: 4.074630233744903
Validation loss: 3.4192199115925606

Epoch: 5| Step: 6
Training loss: 2.4997407778815797
Validation loss: 3.4183974055563215

Epoch: 5| Step: 7
Training loss: 3.005045780080706
Validation loss: 3.4187363949317313

Epoch: 5| Step: 8
Training loss: 3.2579071982545735
Validation loss: 3.417314753580178

Epoch: 5| Step: 9
Training loss: 4.061650113925277
Validation loss: 3.417310926100771

Epoch: 5| Step: 10
Training loss: 3.7768046833709854
Validation loss: 3.416847058167904

Epoch: 70| Step: 0
Training loss: 3.36836466381282
Validation loss: 3.4156632324279044

Epoch: 5| Step: 1
Training loss: 3.546759246416167
Validation loss: 3.4185160762094586

Epoch: 5| Step: 2
Training loss: 3.6149168859189627
Validation loss: 3.416655919868221

Epoch: 5| Step: 3
Training loss: 3.523779740385662
Validation loss: 3.4159003453082804

Epoch: 5| Step: 4
Training loss: 2.742592110630111
Validation loss: 3.415810645611709

Epoch: 5| Step: 5
Training loss: 3.791598951692232
Validation loss: 3.4169684033500314

Epoch: 5| Step: 6
Training loss: 3.7682785878063507
Validation loss: 3.4181653094283275

Epoch: 5| Step: 7
Training loss: 4.359927125374256
Validation loss: 3.414991088475045

Epoch: 5| Step: 8
Training loss: 3.7852506045144554
Validation loss: 3.4159483335812117

Epoch: 5| Step: 9
Training loss: 3.792269452706217
Validation loss: 3.4151042158910685

Epoch: 5| Step: 10
Training loss: 3.427924117789689
Validation loss: 3.4154604626711635

Epoch: 71| Step: 0
Training loss: 3.9569911220432625
Validation loss: 3.4164934562119225

Epoch: 5| Step: 1
Training loss: 4.572467941246878
Validation loss: 3.414930626400836

Epoch: 5| Step: 2
Training loss: 3.5094459315916433
Validation loss: 3.4146596134329155

Epoch: 5| Step: 3
Training loss: 4.099628915508457
Validation loss: 3.4144336107048203

Epoch: 5| Step: 4
Training loss: 3.3792205135196043
Validation loss: 3.4130174480947795

Epoch: 5| Step: 5
Training loss: 3.562332818642695
Validation loss: 3.414876401804933

Epoch: 5| Step: 6
Training loss: 3.5188774831116105
Validation loss: 3.4153552751334266

Epoch: 5| Step: 7
Training loss: 3.3104751444109493
Validation loss: 3.4116397727066876

Epoch: 5| Step: 8
Training loss: 3.864946058718569
Validation loss: 3.413090824289943

Epoch: 5| Step: 9
Training loss: 2.9138813524984144
Validation loss: 3.4124518858844137

Epoch: 5| Step: 10
Training loss: 2.775590775297487
Validation loss: 3.411526781397606

Epoch: 72| Step: 0
Training loss: 3.7087079548292645
Validation loss: 3.411517194202405

Epoch: 5| Step: 1
Training loss: 3.1024886509321186
Validation loss: 3.4106941986161288

Epoch: 5| Step: 2
Training loss: 3.343740588023407
Validation loss: 3.4119748726849446

Epoch: 5| Step: 3
Training loss: 3.627271006617004
Validation loss: 3.410923538178306

Epoch: 5| Step: 4
Training loss: 3.364473386371564
Validation loss: 3.412667809378482

Epoch: 5| Step: 5
Training loss: 3.4565452794459186
Validation loss: 3.412038661527561

Epoch: 5| Step: 6
Training loss: 3.0958894980372955
Validation loss: 3.4138233219959093

Epoch: 5| Step: 7
Training loss: 4.004528105291476
Validation loss: 3.4122094394675844

Epoch: 5| Step: 8
Training loss: 4.252862303032475
Validation loss: 3.411801785211799

Epoch: 5| Step: 9
Training loss: 4.346140251891479
Validation loss: 3.413146172368611

Epoch: 5| Step: 10
Training loss: 3.305542603012339
Validation loss: 3.4109302769922882

Epoch: 73| Step: 0
Training loss: 3.580336907373424
Validation loss: 3.4102137355829023

Epoch: 5| Step: 1
Training loss: 3.4180864935076776
Validation loss: 3.410626137736177

Epoch: 5| Step: 2
Training loss: 3.1495516866732585
Validation loss: 3.4096545955171798

Epoch: 5| Step: 3
Training loss: 3.7016821517059375
Validation loss: 3.4087642088534897

Epoch: 5| Step: 4
Training loss: 3.953581651690896
Validation loss: 3.408503764936132

Epoch: 5| Step: 5
Training loss: 3.989286141079037
Validation loss: 3.408335116493482

Epoch: 5| Step: 6
Training loss: 3.2177534319844727
Validation loss: 3.40760874190259

Epoch: 5| Step: 7
Training loss: 3.914254737747345
Validation loss: 3.4060558374013716

Epoch: 5| Step: 8
Training loss: 3.646387345137152
Validation loss: 3.408497000265078

Epoch: 5| Step: 9
Training loss: 3.974196893906753
Validation loss: 3.407095620606369

Epoch: 5| Step: 10
Training loss: 3.120220802270159
Validation loss: 3.407199424369622

Epoch: 74| Step: 0
Training loss: 3.9905649011876525
Validation loss: 3.4064062962682695

Epoch: 5| Step: 1
Training loss: 4.151760573538093
Validation loss: 3.4049612412505406

Epoch: 5| Step: 2
Training loss: 4.1781039366551385
Validation loss: 3.4061181836091303

Epoch: 5| Step: 3
Training loss: 3.871342686598865
Validation loss: 3.4058152179365764

Epoch: 5| Step: 4
Training loss: 3.2823760507370494
Validation loss: 3.4055202545757988

Epoch: 5| Step: 5
Training loss: 3.3567383821081394
Validation loss: 3.405365622034542

Epoch: 5| Step: 6
Training loss: 3.2202125855872485
Validation loss: 3.405434661309111

Epoch: 5| Step: 7
Training loss: 3.15116275943503
Validation loss: 3.406221519668007

Epoch: 5| Step: 8
Training loss: 3.8553025230123397
Validation loss: 3.4055406671606434

Epoch: 5| Step: 9
Training loss: 2.833345936765875
Validation loss: 3.40522085543801

Epoch: 5| Step: 10
Training loss: 3.7083944822834676
Validation loss: 3.4048048319648028

Epoch: 75| Step: 0
Training loss: 4.2830670809590545
Validation loss: 3.405020773585459

Epoch: 5| Step: 1
Training loss: 2.9691829967950834
Validation loss: 3.405744972959684

Epoch: 5| Step: 2
Training loss: 3.965532575631984
Validation loss: 3.405382613227622

Epoch: 5| Step: 3
Training loss: 4.192565132049186
Validation loss: 3.4068749388785178

Epoch: 5| Step: 4
Training loss: 3.808218380941208
Validation loss: 3.404203970196105

Epoch: 5| Step: 5
Training loss: 3.1254696302389338
Validation loss: 3.4032120830490724

Epoch: 5| Step: 6
Training loss: 3.9315593652339014
Validation loss: 3.403410574899132

Epoch: 5| Step: 7
Training loss: 3.0294166605205617
Validation loss: 3.4022801440861468

Epoch: 5| Step: 8
Training loss: 2.4669477427204898
Validation loss: 3.402086657673754

Epoch: 5| Step: 9
Training loss: 4.3020286033172495
Validation loss: 3.401461544512673

Epoch: 5| Step: 10
Training loss: 3.1490541521578597
Validation loss: 3.400133632299451

Epoch: 76| Step: 0
Training loss: 3.5356103763476825
Validation loss: 3.4027832609367823

Epoch: 5| Step: 1
Training loss: 3.9506889949540542
Validation loss: 3.4020354098946552

Epoch: 5| Step: 2
Training loss: 3.630190980159198
Validation loss: 3.399643319945107

Epoch: 5| Step: 3
Training loss: 3.556903927822315
Validation loss: 3.400309601186965

Epoch: 5| Step: 4
Training loss: 3.9684385643061018
Validation loss: 3.401678856712888

Epoch: 5| Step: 5
Training loss: 3.7145069182204806
Validation loss: 3.402514450959844

Epoch: 5| Step: 6
Training loss: 4.039018582782276
Validation loss: 3.4031426837993193

Epoch: 5| Step: 7
Training loss: 2.70527175595911
Validation loss: 3.4030033070039414

Epoch: 5| Step: 8
Training loss: 3.115939012197507
Validation loss: 3.4014543784399365

Epoch: 5| Step: 9
Training loss: 3.7747753606993193
Validation loss: 3.402764177382407

Epoch: 5| Step: 10
Training loss: 3.616933859054031
Validation loss: 3.402805865731811

Epoch: 77| Step: 0
Training loss: 3.2995043931502015
Validation loss: 3.4001041288433687

Epoch: 5| Step: 1
Training loss: 3.0361799283695428
Validation loss: 3.402600813859742

Epoch: 5| Step: 2
Training loss: 4.065772982930856
Validation loss: 3.400030891608679

Epoch: 5| Step: 3
Training loss: 3.571487200119535
Validation loss: 3.3999704816913394

Epoch: 5| Step: 4
Training loss: 3.9424517542584794
Validation loss: 3.398155865133898

Epoch: 5| Step: 5
Training loss: 3.57019830767364
Validation loss: 3.3979399489782627

Epoch: 5| Step: 6
Training loss: 4.110242164698549
Validation loss: 3.3980483372958243

Epoch: 5| Step: 7
Training loss: 3.8047536730641727
Validation loss: 3.3969468501127245

Epoch: 5| Step: 8
Training loss: 3.9341658751014172
Validation loss: 3.396715060409431

Epoch: 5| Step: 9
Training loss: 3.3652641308355107
Validation loss: 3.396388358009611

Epoch: 5| Step: 10
Training loss: 2.7005626021673885
Validation loss: 3.3969135802111907

Epoch: 78| Step: 0
Training loss: 4.533552124316164
Validation loss: 3.397699204455045

Epoch: 5| Step: 1
Training loss: 3.3431939348982334
Validation loss: 3.394814656624544

Epoch: 5| Step: 2
Training loss: 2.4456245783847645
Validation loss: 3.397341617406192

Epoch: 5| Step: 3
Training loss: 3.8686171846285866
Validation loss: 3.3977294983999946

Epoch: 5| Step: 4
Training loss: 3.5277200795926165
Validation loss: 3.400149450811673

Epoch: 5| Step: 5
Training loss: 2.6534993009880816
Validation loss: 3.3999763117573667

Epoch: 5| Step: 6
Training loss: 3.755896700526309
Validation loss: 3.399693073001015

Epoch: 5| Step: 7
Training loss: 3.7631051270790628
Validation loss: 3.397941652569024

Epoch: 5| Step: 8
Training loss: 3.5521263201993984
Validation loss: 3.3946846693267703

Epoch: 5| Step: 9
Training loss: 4.245193905484886
Validation loss: 3.3942247832961123

Epoch: 5| Step: 10
Training loss: 3.565087165355432
Validation loss: 3.3954057163162736

Epoch: 79| Step: 0
Training loss: 4.051744043157189
Validation loss: 3.394401531293848

Epoch: 5| Step: 1
Training loss: 3.3330279846206885
Validation loss: 3.3937198734043483

Epoch: 5| Step: 2
Training loss: 3.9053067708864364
Validation loss: 3.392668451037909

Epoch: 5| Step: 3
Training loss: 3.2893048919738774
Validation loss: 3.3941056175741107

Epoch: 5| Step: 4
Training loss: 3.3100497702461134
Validation loss: 3.393159200080331

Epoch: 5| Step: 5
Training loss: 3.669144024720958
Validation loss: 3.392746201110107

Epoch: 5| Step: 6
Training loss: 4.113564563931246
Validation loss: 3.3915168168151584

Epoch: 5| Step: 7
Training loss: 3.244681775399307
Validation loss: 3.392402312776551

Epoch: 5| Step: 8
Training loss: 3.831328752464404
Validation loss: 3.3916805025679024

Epoch: 5| Step: 9
Training loss: 2.735649117216844
Validation loss: 3.3936528522549243

Epoch: 5| Step: 10
Training loss: 4.0623875529059115
Validation loss: 3.3916187148644883

Epoch: 80| Step: 0
Training loss: 3.2379647941254093
Validation loss: 3.395005807328687

Epoch: 5| Step: 1
Training loss: 3.3414822312698433
Validation loss: 3.3909747220894633

Epoch: 5| Step: 2
Training loss: 3.835283460622909
Validation loss: 3.392089596991

Epoch: 5| Step: 3
Training loss: 4.012320854965176
Validation loss: 3.391929094785846

Epoch: 5| Step: 4
Training loss: 3.4107425006620997
Validation loss: 3.3909668398283084

Epoch: 5| Step: 5
Training loss: 3.8942988564533696
Validation loss: 3.3916186559062185

Epoch: 5| Step: 6
Training loss: 3.4961668550317584
Validation loss: 3.3916690482237324

Epoch: 5| Step: 7
Training loss: 3.68039549153635
Validation loss: 3.391255391525231

Epoch: 5| Step: 8
Training loss: 4.090092546679753
Validation loss: 3.388888456544177

Epoch: 5| Step: 9
Training loss: 3.511603874389861
Validation loss: 3.3898919802067744

Epoch: 5| Step: 10
Training loss: 2.9395501307706042
Validation loss: 3.3899375687820243

Epoch: 81| Step: 0
Training loss: 4.563846337234918
Validation loss: 3.3882790907880302

Epoch: 5| Step: 1
Training loss: 3.1326443063387552
Validation loss: 3.3889696497791877

Epoch: 5| Step: 2
Training loss: 4.015178967355325
Validation loss: 3.387304609878702

Epoch: 5| Step: 3
Training loss: 3.624788212344355
Validation loss: 3.387151283151743

Epoch: 5| Step: 4
Training loss: 3.975878103901391
Validation loss: 3.386089694359509

Epoch: 5| Step: 5
Training loss: 3.755057167400296
Validation loss: 3.3869579232766687

Epoch: 5| Step: 6
Training loss: 3.1024691315989616
Validation loss: 3.3864338611133857

Epoch: 5| Step: 7
Training loss: 3.267268447201592
Validation loss: 3.3869068333721044

Epoch: 5| Step: 8
Training loss: 2.9824747956482796
Validation loss: 3.3858989322220356

Epoch: 5| Step: 9
Training loss: 2.7720966375220817
Validation loss: 3.3859679595650687

Epoch: 5| Step: 10
Training loss: 4.144635485921196
Validation loss: 3.3855957761323614

Epoch: 82| Step: 0
Training loss: 3.769153002800564
Validation loss: 3.3853023952133174

Epoch: 5| Step: 1
Training loss: 3.9630742375988524
Validation loss: 3.386332159077442

Epoch: 5| Step: 2
Training loss: 2.8426919163422886
Validation loss: 3.386234268900955

Epoch: 5| Step: 3
Training loss: 2.9614139867989575
Validation loss: 3.3854938770258043

Epoch: 5| Step: 4
Training loss: 3.0947584570086506
Validation loss: 3.385217232836678

Epoch: 5| Step: 5
Training loss: 3.4849226311697734
Validation loss: 3.385267111580421

Epoch: 5| Step: 6
Training loss: 4.513599403423498
Validation loss: 3.3863504494835728

Epoch: 5| Step: 7
Training loss: 3.520961525895092
Validation loss: 3.385498729433759

Epoch: 5| Step: 8
Training loss: 4.018742282794763
Validation loss: 3.3857148605037923

Epoch: 5| Step: 9
Training loss: 3.4090774420269927
Validation loss: 3.3845371458718314

Epoch: 5| Step: 10
Training loss: 3.7659050928313222
Validation loss: 3.386909795982401

Epoch: 83| Step: 0
Training loss: 4.213247369863085
Validation loss: 3.385749597325798

Epoch: 5| Step: 1
Training loss: 3.7940067713410115
Validation loss: 3.384897995713303

Epoch: 5| Step: 2
Training loss: 3.36168644362309
Validation loss: 3.383639407188616

Epoch: 5| Step: 3
Training loss: 4.180232103465401
Validation loss: 3.383839003206484

Epoch: 5| Step: 4
Training loss: 3.1413145304744825
Validation loss: 3.382245276711135

Epoch: 5| Step: 5
Training loss: 3.487074007658526
Validation loss: 3.3811253997576767

Epoch: 5| Step: 6
Training loss: 3.528687889533548
Validation loss: 3.381712110386479

Epoch: 5| Step: 7
Training loss: 3.578669344212667
Validation loss: 3.381854949636483

Epoch: 5| Step: 8
Training loss: 3.1984547877811216
Validation loss: 3.3809020113420467

Epoch: 5| Step: 9
Training loss: 2.9364154517994225
Validation loss: 3.3818925142110716

Epoch: 5| Step: 10
Training loss: 4.041829266505462
Validation loss: 3.3808106801333926

Epoch: 84| Step: 0
Training loss: 2.6020651208643866
Validation loss: 3.381529349766086

Epoch: 5| Step: 1
Training loss: 3.5237943548934028
Validation loss: 3.3785194526014526

Epoch: 5| Step: 2
Training loss: 3.822349333004893
Validation loss: 3.3804158578200454

Epoch: 5| Step: 3
Training loss: 4.209274388210412
Validation loss: 3.380261554251954

Epoch: 5| Step: 4
Training loss: 3.61615766526721
Validation loss: 3.3799160755891213

Epoch: 5| Step: 5
Training loss: 3.7070668804679268
Validation loss: 3.378699058711478

Epoch: 5| Step: 6
Training loss: 3.338730368833195
Validation loss: 3.379007394843915

Epoch: 5| Step: 7
Training loss: 3.5244799507643454
Validation loss: 3.3796593131270507

Epoch: 5| Step: 8
Training loss: 3.83420450566792
Validation loss: 3.3793974333092147

Epoch: 5| Step: 9
Training loss: 3.7506883625208083
Validation loss: 3.3796128470676745

Epoch: 5| Step: 10
Training loss: 3.4364718199981086
Validation loss: 3.3787755459712963

Epoch: 85| Step: 0
Training loss: 3.75266018926491
Validation loss: 3.379147762895476

Epoch: 5| Step: 1
Training loss: 4.292778587121268
Validation loss: 3.3798249581866284

Epoch: 5| Step: 2
Training loss: 3.5663488911991386
Validation loss: 3.380631261284414

Epoch: 5| Step: 3
Training loss: 2.780976871409391
Validation loss: 3.3773177258192044

Epoch: 5| Step: 4
Training loss: 3.104349800869294
Validation loss: 3.379988482014467

Epoch: 5| Step: 5
Training loss: 3.563328964425797
Validation loss: 3.378925151156812

Epoch: 5| Step: 6
Training loss: 3.4701757851524464
Validation loss: 3.379881575386504

Epoch: 5| Step: 7
Training loss: 3.7560098174579273
Validation loss: 3.377817242829354

Epoch: 5| Step: 8
Training loss: 3.8345731029617895
Validation loss: 3.375863903930909

Epoch: 5| Step: 9
Training loss: 3.5832613265025466
Validation loss: 3.3763766988346133

Epoch: 5| Step: 10
Training loss: 3.688769623029759
Validation loss: 3.376194433024032

Epoch: 86| Step: 0
Training loss: 3.125326215883468
Validation loss: 3.3767287636132766

Epoch: 5| Step: 1
Training loss: 3.6462110632542726
Validation loss: 3.375787194259717

Epoch: 5| Step: 2
Training loss: 3.43470497941137
Validation loss: 3.3732916527748946

Epoch: 5| Step: 3
Training loss: 3.852056320753163
Validation loss: 3.374682581296004

Epoch: 5| Step: 4
Training loss: 3.526286189486204
Validation loss: 3.3753710246202764

Epoch: 5| Step: 5
Training loss: 3.4832234896143364
Validation loss: 3.3749861236493612

Epoch: 5| Step: 6
Training loss: 4.057711082134141
Validation loss: 3.374548693113925

Epoch: 5| Step: 7
Training loss: 3.893563627678161
Validation loss: 3.374085190308232

Epoch: 5| Step: 8
Training loss: 3.220355772183949
Validation loss: 3.3750592116035

Epoch: 5| Step: 9
Training loss: 3.5490191864329144
Validation loss: 3.375220945927936

Epoch: 5| Step: 10
Training loss: 3.6911040974636555
Validation loss: 3.3741843917914744

Epoch: 87| Step: 0
Training loss: 3.043898473482668
Validation loss: 3.374396172533529

Epoch: 5| Step: 1
Training loss: 3.739522921075106
Validation loss: 3.3751132586035086

Epoch: 5| Step: 2
Training loss: 3.686217650811307
Validation loss: 3.376511928268107

Epoch: 5| Step: 3
Training loss: 3.288187449706409
Validation loss: 3.374185026208412

Epoch: 5| Step: 4
Training loss: 3.978712658504672
Validation loss: 3.3740330294171814

Epoch: 5| Step: 5
Training loss: 3.233636449258655
Validation loss: 3.372760362300956

Epoch: 5| Step: 6
Training loss: 3.6591955856006386
Validation loss: 3.374976422019767

Epoch: 5| Step: 7
Training loss: 2.6725854654090617
Validation loss: 3.3738286086971256

Epoch: 5| Step: 8
Training loss: 4.703877841855444
Validation loss: 3.3738008098293477

Epoch: 5| Step: 9
Training loss: 3.8754955097989945
Validation loss: 3.37289719149996

Epoch: 5| Step: 10
Training loss: 3.169898558958074
Validation loss: 3.371109030998393

Epoch: 88| Step: 0
Training loss: 2.9247285505010905
Validation loss: 3.370493352093728

Epoch: 5| Step: 1
Training loss: 2.848542587007454
Validation loss: 3.371367620250738

Epoch: 5| Step: 2
Training loss: 3.9104947640057524
Validation loss: 3.370080842685876

Epoch: 5| Step: 3
Training loss: 3.7907329848995137
Validation loss: 3.370189691867503

Epoch: 5| Step: 4
Training loss: 3.678716251945657
Validation loss: 3.3698818376483786

Epoch: 5| Step: 5
Training loss: 4.110593897844102
Validation loss: 3.3722386049098376

Epoch: 5| Step: 6
Training loss: 4.109147330239719
Validation loss: 3.3708180382877684

Epoch: 5| Step: 7
Training loss: 3.55863073269065
Validation loss: 3.3713837942524076

Epoch: 5| Step: 8
Training loss: 3.440688163323065
Validation loss: 3.3687363583525625

Epoch: 5| Step: 9
Training loss: 3.249403678766017
Validation loss: 3.3691542514967154

Epoch: 5| Step: 10
Training loss: 3.6357403513626845
Validation loss: 3.369494332984592

Epoch: 89| Step: 0
Training loss: 3.366080754980167
Validation loss: 3.369144323060733

Epoch: 5| Step: 1
Training loss: 2.9169057112328223
Validation loss: 3.367735884005696

Epoch: 5| Step: 2
Training loss: 3.4991418603930984
Validation loss: 3.367582529591158

Epoch: 5| Step: 3
Training loss: 3.5634132686983073
Validation loss: 3.3693650975410354

Epoch: 5| Step: 4
Training loss: 4.1539610102388975
Validation loss: 3.3692355710431388

Epoch: 5| Step: 5
Training loss: 3.2507434874864467
Validation loss: 3.368538494617467

Epoch: 5| Step: 6
Training loss: 4.012944733403341
Validation loss: 3.3670957077088937

Epoch: 5| Step: 7
Training loss: 4.2152387912936735
Validation loss: 3.366573133319686

Epoch: 5| Step: 8
Training loss: 3.540143990901833
Validation loss: 3.366293618234021

Epoch: 5| Step: 9
Training loss: 3.3419803678254403
Validation loss: 3.365055732374618

Epoch: 5| Step: 10
Training loss: 3.3766328605724456
Validation loss: 3.3667273949277643

Epoch: 90| Step: 0
Training loss: 4.140926479664346
Validation loss: 3.3657979040046713

Epoch: 5| Step: 1
Training loss: 2.9575009495789266
Validation loss: 3.365781873776227

Epoch: 5| Step: 2
Training loss: 3.6961539925370874
Validation loss: 3.3668693158217806

Epoch: 5| Step: 3
Training loss: 3.66328132289334
Validation loss: 3.364736008685873

Epoch: 5| Step: 4
Training loss: 3.4085837952256224
Validation loss: 3.3644263539708175

Epoch: 5| Step: 5
Training loss: 3.346809769821998
Validation loss: 3.3645044061827414

Epoch: 5| Step: 6
Training loss: 3.5161764432968248
Validation loss: 3.3649479940080886

Epoch: 5| Step: 7
Training loss: 3.593309458392017
Validation loss: 3.364280084824133

Epoch: 5| Step: 8
Training loss: 3.8510689873827313
Validation loss: 3.3648159218849893

Epoch: 5| Step: 9
Training loss: 3.9009756872949377
Validation loss: 3.363687153924804

Epoch: 5| Step: 10
Training loss: 3.189853622043795
Validation loss: 3.364398004981123

Epoch: 91| Step: 0
Training loss: 3.1886645415012755
Validation loss: 3.3638950610200244

Epoch: 5| Step: 1
Training loss: 3.2507402604023268
Validation loss: 3.364085804351428

Epoch: 5| Step: 2
Training loss: 4.096211399598438
Validation loss: 3.3617912514414123

Epoch: 5| Step: 3
Training loss: 3.3516107302309903
Validation loss: 3.3628476119767514

Epoch: 5| Step: 4
Training loss: 3.954221309583106
Validation loss: 3.36200488955458

Epoch: 5| Step: 5
Training loss: 2.8448511025025818
Validation loss: 3.362540435029448

Epoch: 5| Step: 6
Training loss: 3.560313574450021
Validation loss: 3.362302006670954

Epoch: 5| Step: 7
Training loss: 4.129794484490827
Validation loss: 3.3604906622463475

Epoch: 5| Step: 8
Training loss: 3.531862864016972
Validation loss: 3.3606348306783667

Epoch: 5| Step: 9
Training loss: 3.8875762146964066
Validation loss: 3.361308610838555

Epoch: 5| Step: 10
Training loss: 3.382119898560627
Validation loss: 3.3607356207136894

Epoch: 92| Step: 0
Training loss: 4.393673093293631
Validation loss: 3.360903710280933

Epoch: 5| Step: 1
Training loss: 3.151037463140705
Validation loss: 3.361703170570932

Epoch: 5| Step: 2
Training loss: 4.147531643977291
Validation loss: 3.3615375232944142

Epoch: 5| Step: 3
Training loss: 3.5620056612461344
Validation loss: 3.361867913672617

Epoch: 5| Step: 4
Training loss: 3.028070571772441
Validation loss: 3.360018147333129

Epoch: 5| Step: 5
Training loss: 3.7805635443933223
Validation loss: 3.3602512995744167

Epoch: 5| Step: 6
Training loss: 3.6032184095755966
Validation loss: 3.3601240944067117

Epoch: 5| Step: 7
Training loss: 3.048379067115606
Validation loss: 3.359181009745536

Epoch: 5| Step: 8
Training loss: 3.9272552911294296
Validation loss: 3.359073038688576

Epoch: 5| Step: 9
Training loss: 2.839553755235077
Validation loss: 3.3590805561887054

Epoch: 5| Step: 10
Training loss: 3.586576915903777
Validation loss: 3.3590826427690073

Epoch: 93| Step: 0
Training loss: 3.9832282117648634
Validation loss: 3.358428098179788

Epoch: 5| Step: 1
Training loss: 3.4629217448721534
Validation loss: 3.359091475995473

Epoch: 5| Step: 2
Training loss: 3.9385909733800513
Validation loss: 3.359176795494375

Epoch: 5| Step: 3
Training loss: 3.3936845186495432
Validation loss: 3.357249173750845

Epoch: 5| Step: 4
Training loss: 3.4941359850968357
Validation loss: 3.3562999329395145

Epoch: 5| Step: 5
Training loss: 3.605692781078077
Validation loss: 3.3571825791246996

Epoch: 5| Step: 6
Training loss: 3.1551114285435116
Validation loss: 3.357872742912074

Epoch: 5| Step: 7
Training loss: 3.0241923806793256
Validation loss: 3.3550596083604187

Epoch: 5| Step: 8
Training loss: 3.5300744724792987
Validation loss: 3.3552771752640576

Epoch: 5| Step: 9
Training loss: 3.752902751253191
Validation loss: 3.3560160994931105

Epoch: 5| Step: 10
Training loss: 3.9812783568134433
Validation loss: 3.3565422406746084

Epoch: 94| Step: 0
Training loss: 3.706152599785323
Validation loss: 3.356683008196737

Epoch: 5| Step: 1
Training loss: 3.706943008449888
Validation loss: 3.3560708480949755

Epoch: 5| Step: 2
Training loss: 2.9633281789533874
Validation loss: 3.354939976884203

Epoch: 5| Step: 3
Training loss: 3.1401347067056413
Validation loss: 3.353764442556245

Epoch: 5| Step: 4
Training loss: 3.44054195016245
Validation loss: 3.3561200050411304

Epoch: 5| Step: 5
Training loss: 2.734692538761017
Validation loss: 3.356735531867869

Epoch: 5| Step: 6
Training loss: 4.168162776645987
Validation loss: 3.3547571271820393

Epoch: 5| Step: 7
Training loss: 3.3856961335471056
Validation loss: 3.3550749883674715

Epoch: 5| Step: 8
Training loss: 4.26265739083218
Validation loss: 3.353257557385405

Epoch: 5| Step: 9
Training loss: 3.4229553468128113
Validation loss: 3.3541878299788137

Epoch: 5| Step: 10
Training loss: 4.180123964141592
Validation loss: 3.3542032949997562

Epoch: 95| Step: 0
Training loss: 3.204226867216077
Validation loss: 3.3535621713367965

Epoch: 5| Step: 1
Training loss: 4.256856212493297
Validation loss: 3.3540174486347234

Epoch: 5| Step: 2
Training loss: 4.1941912127607175
Validation loss: 3.3531603951149496

Epoch: 5| Step: 3
Training loss: 2.790288404646286
Validation loss: 3.3516693560970197

Epoch: 5| Step: 4
Training loss: 3.2099325644756846
Validation loss: 3.3521317184281414

Epoch: 5| Step: 5
Training loss: 3.936126711705377
Validation loss: 3.350599924849529

Epoch: 5| Step: 6
Training loss: 3.667748652833082
Validation loss: 3.350910201598305

Epoch: 5| Step: 7
Training loss: 2.9656429696216975
Validation loss: 3.3509904429801676

Epoch: 5| Step: 8
Training loss: 2.894217902763501
Validation loss: 3.3518641956344566

Epoch: 5| Step: 9
Training loss: 3.393228261054097
Validation loss: 3.350309318608774

Epoch: 5| Step: 10
Training loss: 4.488689619830472
Validation loss: 3.3512089602577912

Epoch: 96| Step: 0
Training loss: 3.0173758528485504
Validation loss: 3.3491274742915103

Epoch: 5| Step: 1
Training loss: 3.272981525428443
Validation loss: 3.3517953134141343

Epoch: 5| Step: 2
Training loss: 4.049478407815778
Validation loss: 3.3509973298602342

Epoch: 5| Step: 3
Training loss: 4.032846297396276
Validation loss: 3.3534289459386954

Epoch: 5| Step: 4
Training loss: 3.8188066693735307
Validation loss: 3.3508763085927247

Epoch: 5| Step: 5
Training loss: 4.013318301032251
Validation loss: 3.3500234340729063

Epoch: 5| Step: 6
Training loss: 2.9166519891278755
Validation loss: 3.3494949065345656

Epoch: 5| Step: 7
Training loss: 3.2527298833019604
Validation loss: 3.348949754575405

Epoch: 5| Step: 8
Training loss: 3.410271047296363
Validation loss: 3.3485361185639215

Epoch: 5| Step: 9
Training loss: 3.467158046767503
Validation loss: 3.3500804577396077

Epoch: 5| Step: 10
Training loss: 3.8863849132306263
Validation loss: 3.347240069907435

Epoch: 97| Step: 0
Training loss: 3.709079253081504
Validation loss: 3.3474414939533927

Epoch: 5| Step: 1
Training loss: 3.990238916036941
Validation loss: 3.347098963458286

Epoch: 5| Step: 2
Training loss: 2.8723241544041707
Validation loss: 3.3474497084586403

Epoch: 5| Step: 3
Training loss: 3.654532526391056
Validation loss: 3.347643356938816

Epoch: 5| Step: 4
Training loss: 3.4688168081087496
Validation loss: 3.3465674200426836

Epoch: 5| Step: 5
Training loss: 3.514071922577963
Validation loss: 3.3462472491179662

Epoch: 5| Step: 6
Training loss: 3.5498993872770592
Validation loss: 3.3474849786774983

Epoch: 5| Step: 7
Training loss: 3.127080301227832
Validation loss: 3.347800709235481

Epoch: 5| Step: 8
Training loss: 4.009858380716012
Validation loss: 3.348668860326083

Epoch: 5| Step: 9
Training loss: 3.693209350056496
Validation loss: 3.351879948247144

Epoch: 5| Step: 10
Training loss: 3.572869318137699
Validation loss: 3.350625936833749

Epoch: 98| Step: 0
Training loss: 2.9659436262744916
Validation loss: 3.3474151455199093

Epoch: 5| Step: 1
Training loss: 3.0930831652911026
Validation loss: 3.3480887881743984

Epoch: 5| Step: 2
Training loss: 3.5203853675828594
Validation loss: 3.3453301771063524

Epoch: 5| Step: 3
Training loss: 3.3564677588717005
Validation loss: 3.344377413026975

Epoch: 5| Step: 4
Training loss: 3.1980562624869853
Validation loss: 3.345469486084229

Epoch: 5| Step: 5
Training loss: 4.381655834518824
Validation loss: 3.3432038207758854

Epoch: 5| Step: 6
Training loss: 3.7844255212487545
Validation loss: 3.3440800479865502

Epoch: 5| Step: 7
Training loss: 3.4084436195145824
Validation loss: 3.344151243283319

Epoch: 5| Step: 8
Training loss: 4.140476209738223
Validation loss: 3.343529906460074

Epoch: 5| Step: 9
Training loss: 3.7564533654634733
Validation loss: 3.344813384302078

Epoch: 5| Step: 10
Training loss: 3.3763413765951737
Validation loss: 3.3434130077429702

Epoch: 99| Step: 0
Training loss: 2.953749656209066
Validation loss: 3.342797368393775

Epoch: 5| Step: 1
Training loss: 3.9175734315768573
Validation loss: 3.343185522830701

Epoch: 5| Step: 2
Training loss: 3.956850731244557
Validation loss: 3.343299948139654

Epoch: 5| Step: 3
Training loss: 2.878396722846209
Validation loss: 3.342880094465108

Epoch: 5| Step: 4
Training loss: 3.7524399766689696
Validation loss: 3.3431026417462055

Epoch: 5| Step: 5
Training loss: 3.390613749261288
Validation loss: 3.342048498083777

Epoch: 5| Step: 6
Training loss: 3.703483081357187
Validation loss: 3.340920505549462

Epoch: 5| Step: 7
Training loss: 3.0634390500671893
Validation loss: 3.342554689349368

Epoch: 5| Step: 8
Training loss: 3.2752143207339457
Validation loss: 3.3415478123012297

Epoch: 5| Step: 9
Training loss: 3.760593329142999
Validation loss: 3.342874827420746

Epoch: 5| Step: 10
Training loss: 4.414228858175969
Validation loss: 3.342727379020245

Epoch: 100| Step: 0
Training loss: 3.1855386421663234
Validation loss: 3.3433438348525977

Epoch: 5| Step: 1
Training loss: 3.4383241532450204
Validation loss: 3.3428681078625857

Epoch: 5| Step: 2
Training loss: 3.72359964559547
Validation loss: 3.3454140543888817

Epoch: 5| Step: 3
Training loss: 3.213039332139887
Validation loss: 3.34407566138063

Epoch: 5| Step: 4
Training loss: 3.7909917265636475
Validation loss: 3.343936611730325

Epoch: 5| Step: 5
Training loss: 3.748312634085401
Validation loss: 3.343879112225076

Epoch: 5| Step: 6
Training loss: 3.318338970011572
Validation loss: 3.343156318912543

Epoch: 5| Step: 7
Training loss: 3.657250161597759
Validation loss: 3.3418535358023163

Epoch: 5| Step: 8
Training loss: 3.050596966715289
Validation loss: 3.3412635090720513

Epoch: 5| Step: 9
Training loss: 4.022905807177549
Validation loss: 3.340714723980309

Epoch: 5| Step: 10
Training loss: 3.9897808427783197
Validation loss: 3.338706490180902

Epoch: 101| Step: 0
Training loss: 4.097260113269722
Validation loss: 3.3381347298176545

Epoch: 5| Step: 1
Training loss: 3.845472120609289
Validation loss: 3.337383835400029

Epoch: 5| Step: 2
Training loss: 3.419430491004679
Validation loss: 3.3373328277321175

Epoch: 5| Step: 3
Training loss: 3.011056235901568
Validation loss: 3.3365936659906885

Epoch: 5| Step: 4
Training loss: 4.409593328292628
Validation loss: 3.336487371279992

Epoch: 5| Step: 5
Training loss: 2.903950427491342
Validation loss: 3.3357083616874563

Epoch: 5| Step: 6
Training loss: 3.0254479951387467
Validation loss: 3.337554220186473

Epoch: 5| Step: 7
Training loss: 3.649171416413209
Validation loss: 3.3370155505512282

Epoch: 5| Step: 8
Training loss: 3.7768205913568194
Validation loss: 3.33571348941306

Epoch: 5| Step: 9
Training loss: 3.8016515756653435
Validation loss: 3.336301222713177

Epoch: 5| Step: 10
Training loss: 2.75748569183926
Validation loss: 3.336554772358944

Epoch: 102| Step: 0
Training loss: 4.2651881179376465
Validation loss: 3.3355184581346458

Epoch: 5| Step: 1
Training loss: 2.82882513158043
Validation loss: 3.3364977311312902

Epoch: 5| Step: 2
Training loss: 3.640516680632755
Validation loss: 3.336819376870329

Epoch: 5| Step: 3
Training loss: 3.7308529640983816
Validation loss: 3.335642736555947

Epoch: 5| Step: 4
Training loss: 3.181995800559811
Validation loss: 3.334613013483461

Epoch: 5| Step: 5
Training loss: 3.6989880079996467
Validation loss: 3.3366084580526096

Epoch: 5| Step: 6
Training loss: 2.725031031860605
Validation loss: 3.3359035109712325

Epoch: 5| Step: 7
Training loss: 4.023822180867006
Validation loss: 3.3378116155706783

Epoch: 5| Step: 8
Training loss: 3.53439218262291
Validation loss: 3.338230603041284

Epoch: 5| Step: 9
Training loss: 3.632523063696716
Validation loss: 3.3375937327901966

Epoch: 5| Step: 10
Training loss: 3.6174135734815955
Validation loss: 3.33843620522403

Epoch: 103| Step: 0
Training loss: 3.214772998870237
Validation loss: 3.3367055713969944

Epoch: 5| Step: 1
Training loss: 4.23801302434658
Validation loss: 3.337020551812918

Epoch: 5| Step: 2
Training loss: 3.667051743025035
Validation loss: 3.3351328857998785

Epoch: 5| Step: 3
Training loss: 2.6740784956282138
Validation loss: 3.333950346066776

Epoch: 5| Step: 4
Training loss: 3.5645951919462453
Validation loss: 3.3331471857782495

Epoch: 5| Step: 5
Training loss: 3.4600470712800475
Validation loss: 3.3354040425730074

Epoch: 5| Step: 6
Training loss: 3.193384610230948
Validation loss: 3.3351756301281563

Epoch: 5| Step: 7
Training loss: 3.38327509512051
Validation loss: 3.333512260392895

Epoch: 5| Step: 8
Training loss: 2.8237511971966356
Validation loss: 3.3324340550680156

Epoch: 5| Step: 9
Training loss: 4.307900892699176
Validation loss: 3.332450404185879

Epoch: 5| Step: 10
Training loss: 4.2958736848215615
Validation loss: 3.3318921455062815

Epoch: 104| Step: 0
Training loss: 3.7883516569039877
Validation loss: 3.33120742090645

Epoch: 5| Step: 1
Training loss: 4.181567644447222
Validation loss: 3.3310386309147733

Epoch: 5| Step: 2
Training loss: 4.329332754689812
Validation loss: 3.33174553299077

Epoch: 5| Step: 3
Training loss: 3.377750265137684
Validation loss: 3.3342260993046926

Epoch: 5| Step: 4
Training loss: 4.081904621989296
Validation loss: 3.3302421254461914

Epoch: 5| Step: 5
Training loss: 3.188396253056371
Validation loss: 3.3291310945465464

Epoch: 5| Step: 6
Training loss: 3.4043823161430877
Validation loss: 3.3292516180032914

Epoch: 5| Step: 7
Training loss: 2.793513659693564
Validation loss: 3.3292786769270903

Epoch: 5| Step: 8
Training loss: 3.079293585928806
Validation loss: 3.330103654468585

Epoch: 5| Step: 9
Training loss: 2.314591158199274
Validation loss: 3.330159909141995

Epoch: 5| Step: 10
Training loss: 4.106984418573353
Validation loss: 3.330013922471592

Epoch: 105| Step: 0
Training loss: 3.5935126184762383
Validation loss: 3.3292246774459344

Epoch: 5| Step: 1
Training loss: 3.584635579249716
Validation loss: 3.3302758627965563

Epoch: 5| Step: 2
Training loss: 3.4719009522052655
Validation loss: 3.3304116001008683

Epoch: 5| Step: 3
Training loss: 3.6793042933009272
Validation loss: 3.3332873084879893

Epoch: 5| Step: 4
Training loss: 3.2386679056143506
Validation loss: 3.330592433451787

Epoch: 5| Step: 5
Training loss: 2.916206941249941
Validation loss: 3.32951603909946

Epoch: 5| Step: 6
Training loss: 3.6874954740852126
Validation loss: 3.328902992535176

Epoch: 5| Step: 7
Training loss: 3.38488269213847
Validation loss: 3.326667789765895

Epoch: 5| Step: 8
Training loss: 4.045789182653198
Validation loss: 3.3279131372682302

Epoch: 5| Step: 9
Training loss: 3.7352230114726175
Validation loss: 3.3262660082157844

Epoch: 5| Step: 10
Training loss: 3.6802637252432477
Validation loss: 3.3255704999283306

Epoch: 106| Step: 0
Training loss: 3.3659617589363773
Validation loss: 3.3256746097353456

Epoch: 5| Step: 1
Training loss: 3.341848670651713
Validation loss: 3.3257606338879926

Epoch: 5| Step: 2
Training loss: 4.036977794405663
Validation loss: 3.3248308050972657

Epoch: 5| Step: 3
Training loss: 3.0715244221226374
Validation loss: 3.323003650449645

Epoch: 5| Step: 4
Training loss: 4.220583368991705
Validation loss: 3.326074338481522

Epoch: 5| Step: 5
Training loss: 2.9455922446725378
Validation loss: 3.3243059470046243

Epoch: 5| Step: 6
Training loss: 3.584746651309845
Validation loss: 3.325834358075336

Epoch: 5| Step: 7
Training loss: 3.8470560138175407
Validation loss: 3.3244741974127963

Epoch: 5| Step: 8
Training loss: 3.7069962623480617
Validation loss: 3.3250435041649777

Epoch: 5| Step: 9
Training loss: 3.0201176990537464
Validation loss: 3.325379127774199

Epoch: 5| Step: 10
Training loss: 3.718273100206235
Validation loss: 3.323867810367954

Epoch: 107| Step: 0
Training loss: 3.544260145064286
Validation loss: 3.325144053097458

Epoch: 5| Step: 1
Training loss: 3.594859076484801
Validation loss: 3.322996558970867

Epoch: 5| Step: 2
Training loss: 3.6071953075000245
Validation loss: 3.32439319107639

Epoch: 5| Step: 3
Training loss: 4.121518833600975
Validation loss: 3.323606856788499

Epoch: 5| Step: 4
Training loss: 3.6974015571122556
Validation loss: 3.3238669017972002

Epoch: 5| Step: 5
Training loss: 3.6214548072928716
Validation loss: 3.3234691275700854

Epoch: 5| Step: 6
Training loss: 4.033436500133646
Validation loss: 3.3232815347015507

Epoch: 5| Step: 7
Training loss: 3.086016149363658
Validation loss: 3.3218084902210574

Epoch: 5| Step: 8
Training loss: 2.65766187058233
Validation loss: 3.3205640402475627

Epoch: 5| Step: 9
Training loss: 3.4633879586820404
Validation loss: 3.3230299162541135

Epoch: 5| Step: 10
Training loss: 3.379608539958706
Validation loss: 3.3221242796139934

Epoch: 108| Step: 0
Training loss: 3.302432614374645
Validation loss: 3.322169706982871

Epoch: 5| Step: 1
Training loss: 3.7019641199418607
Validation loss: 3.3208807060584875

Epoch: 5| Step: 2
Training loss: 3.3551319384037166
Validation loss: 3.319260526587659

Epoch: 5| Step: 3
Training loss: 3.9063765848630254
Validation loss: 3.3208365209387667

Epoch: 5| Step: 4
Training loss: 3.4846848149118657
Validation loss: 3.321681676742962

Epoch: 5| Step: 5
Training loss: 4.023545584106487
Validation loss: 3.320034157211205

Epoch: 5| Step: 6
Training loss: 3.1579138270018596
Validation loss: 3.321344132680576

Epoch: 5| Step: 7
Training loss: 3.7731550596694383
Validation loss: 3.3202248151421903

Epoch: 5| Step: 8
Training loss: 3.1638396008003133
Validation loss: 3.3202865477964654

Epoch: 5| Step: 9
Training loss: 3.608856824529903
Validation loss: 3.3206518396725184

Epoch: 5| Step: 10
Training loss: 3.421267381483866
Validation loss: 3.320070867655584

Epoch: 109| Step: 0
Training loss: 3.2988328950620485
Validation loss: 3.3205193274573315

Epoch: 5| Step: 1
Training loss: 3.5172625309564145
Validation loss: 3.3207839992005956

Epoch: 5| Step: 2
Training loss: 3.785138739357394
Validation loss: 3.318606236679184

Epoch: 5| Step: 3
Training loss: 3.950190363292635
Validation loss: 3.3192981500033314

Epoch: 5| Step: 4
Training loss: 3.237248862405168
Validation loss: 3.319255978198063

Epoch: 5| Step: 5
Training loss: 3.513508206044271
Validation loss: 3.317833995417763

Epoch: 5| Step: 6
Training loss: 3.463021987514769
Validation loss: 3.3177070300216434

Epoch: 5| Step: 7
Training loss: 4.006619221876634
Validation loss: 3.3179888888778803

Epoch: 5| Step: 8
Training loss: 3.44422435228238
Validation loss: 3.3181916937578113

Epoch: 5| Step: 9
Training loss: 3.626573944402451
Validation loss: 3.3185480943370997

Epoch: 5| Step: 10
Training loss: 2.938112235691735
Validation loss: 3.3172931135390016

Epoch: 110| Step: 0
Training loss: 2.8056990730499205
Validation loss: 3.316249161358655

Epoch: 5| Step: 1
Training loss: 3.965998739753096
Validation loss: 3.3167957275438416

Epoch: 5| Step: 2
Training loss: 3.3788276442717264
Validation loss: 3.3162427357251847

Epoch: 5| Step: 3
Training loss: 3.941713289034871
Validation loss: 3.316639212337386

Epoch: 5| Step: 4
Training loss: 3.668299455938337
Validation loss: 3.3157560088213422

Epoch: 5| Step: 5
Training loss: 3.8997224513353164
Validation loss: 3.3147827860839394

Epoch: 5| Step: 6
Training loss: 2.8157192879151505
Validation loss: 3.3151035057346703

Epoch: 5| Step: 7
Training loss: 3.2045906993394597
Validation loss: 3.315477714968184

Epoch: 5| Step: 8
Training loss: 4.429764788994493
Validation loss: 3.31385764256289

Epoch: 5| Step: 9
Training loss: 3.653810910197799
Validation loss: 3.3145117583901094

Epoch: 5| Step: 10
Training loss: 2.651837622284475
Validation loss: 3.314944681811531

Epoch: 111| Step: 0
Training loss: 2.4614358064446953
Validation loss: 3.313839459532323

Epoch: 5| Step: 1
Training loss: 3.9770168202298457
Validation loss: 3.3136480760010376

Epoch: 5| Step: 2
Training loss: 3.5923279975803584
Validation loss: 3.3136666941032504

Epoch: 5| Step: 3
Training loss: 3.8785083024955425
Validation loss: 3.313124113595882

Epoch: 5| Step: 4
Training loss: 3.3920697065694383
Validation loss: 3.313874049289392

Epoch: 5| Step: 5
Training loss: 3.394730433687957
Validation loss: 3.314725014426087

Epoch: 5| Step: 6
Training loss: 4.140928322100542
Validation loss: 3.3152889445774782

Epoch: 5| Step: 7
Training loss: 2.7187642064216657
Validation loss: 3.31522427778485

Epoch: 5| Step: 8
Training loss: 4.255910017912315
Validation loss: 3.315495991080486

Epoch: 5| Step: 9
Training loss: 3.2589283594179923
Validation loss: 3.316236161652262

Epoch: 5| Step: 10
Training loss: 3.4305833068082126
Validation loss: 3.314600336109814

Epoch: 112| Step: 0
Training loss: 3.3363076927024795
Validation loss: 3.31396762053993

Epoch: 5| Step: 1
Training loss: 3.774610001584601
Validation loss: 3.3118726554600837

Epoch: 5| Step: 2
Training loss: 3.5887833482979308
Validation loss: 3.311220119546838

Epoch: 5| Step: 3
Training loss: 3.611415533944201
Validation loss: 3.3119083370681768

Epoch: 5| Step: 4
Training loss: 4.020336430074768
Validation loss: 3.311366968835398

Epoch: 5| Step: 5
Training loss: 3.586837356457592
Validation loss: 3.310365374116829

Epoch: 5| Step: 6
Training loss: 3.026846764901686
Validation loss: 3.310510861990451

Epoch: 5| Step: 7
Training loss: 3.3994947170211467
Validation loss: 3.310024081459401

Epoch: 5| Step: 8
Training loss: 3.9499512246898947
Validation loss: 3.3105018077602884

Epoch: 5| Step: 9
Training loss: 3.086198163190113
Validation loss: 3.3094870892123804

Epoch: 5| Step: 10
Training loss: 3.4021444514138626
Validation loss: 3.308667675393007

Epoch: 113| Step: 0
Training loss: 4.285246605559473
Validation loss: 3.309776911189325

Epoch: 5| Step: 1
Training loss: 3.421701365903629
Validation loss: 3.310388216575214

Epoch: 5| Step: 2
Training loss: 3.1229934353815927
Validation loss: 3.308553299075037

Epoch: 5| Step: 3
Training loss: 4.48695729833917
Validation loss: 3.3081457519500326

Epoch: 5| Step: 4
Training loss: 2.748477167360492
Validation loss: 3.309303115537636

Epoch: 5| Step: 5
Training loss: 3.771420779055022
Validation loss: 3.30861291026169

Epoch: 5| Step: 6
Training loss: 3.0376370183236725
Validation loss: 3.308833759755043

Epoch: 5| Step: 7
Training loss: 4.00712285047743
Validation loss: 3.3083263656787913

Epoch: 5| Step: 8
Training loss: 2.447868595598203
Validation loss: 3.30807547272748

Epoch: 5| Step: 9
Training loss: 3.522876094236327
Validation loss: 3.3087435748950553

Epoch: 5| Step: 10
Training loss: 3.495366708184224
Validation loss: 3.308530516009955

Epoch: 114| Step: 0
Training loss: 3.988897531925662
Validation loss: 3.3083649046095527

Epoch: 5| Step: 1
Training loss: 3.8567890353119956
Validation loss: 3.308391439286581

Epoch: 5| Step: 2
Training loss: 3.85847777775298
Validation loss: 3.306379878008549

Epoch: 5| Step: 3
Training loss: 3.592713579745659
Validation loss: 3.3077768182002947

Epoch: 5| Step: 4
Training loss: 3.388409853432561
Validation loss: 3.3069254426874717

Epoch: 5| Step: 5
Training loss: 3.1953474196785376
Validation loss: 3.3068562259815186

Epoch: 5| Step: 6
Training loss: 3.2083612581168985
Validation loss: 3.305393653706241

Epoch: 5| Step: 7
Training loss: 3.6233299617757497
Validation loss: 3.3085605183674534

Epoch: 5| Step: 8
Training loss: 2.9792116246243525
Validation loss: 3.3086493607880487

Epoch: 5| Step: 9
Training loss: 2.522421239525019
Validation loss: 3.3071869636972075

Epoch: 5| Step: 10
Training loss: 4.437872642666675
Validation loss: 3.3083741491127836

Epoch: 115| Step: 0
Training loss: 3.1389638578601295
Validation loss: 3.306725007646376

Epoch: 5| Step: 1
Training loss: 3.717052296588485
Validation loss: 3.3052209975108897

Epoch: 5| Step: 2
Training loss: 3.0155623829719893
Validation loss: 3.305232408613491

Epoch: 5| Step: 3
Training loss: 3.4538973811841855
Validation loss: 3.3049718499374467

Epoch: 5| Step: 4
Training loss: 3.8188131623733845
Validation loss: 3.3040276481025606

Epoch: 5| Step: 5
Training loss: 3.708194144276363
Validation loss: 3.3039570081554066

Epoch: 5| Step: 6
Training loss: 4.7583139841161755
Validation loss: 3.3029985314759793

Epoch: 5| Step: 7
Training loss: 3.3323108694404278
Validation loss: 3.302974040573018

Epoch: 5| Step: 8
Training loss: 2.547519157719477
Validation loss: 3.3034533847439254

Epoch: 5| Step: 9
Training loss: 3.5545552323434606
Validation loss: 3.303035789836769

Epoch: 5| Step: 10
Training loss: 3.3637279608155826
Validation loss: 3.3016647772847705

Epoch: 116| Step: 0
Training loss: 3.087874565106877
Validation loss: 3.302623724876333

Epoch: 5| Step: 1
Training loss: 3.241337161409332
Validation loss: 3.303051963144046

Epoch: 5| Step: 2
Training loss: 3.416211881065489
Validation loss: 3.3034077698397377

Epoch: 5| Step: 3
Training loss: 3.3626097253530722
Validation loss: 3.303406292222319

Epoch: 5| Step: 4
Training loss: 3.373259342749209
Validation loss: 3.3038215139650395

Epoch: 5| Step: 5
Training loss: 3.5582695990281112
Validation loss: 3.302804657653341

Epoch: 5| Step: 6
Training loss: 5.096181838978815
Validation loss: 3.3033089713449546

Epoch: 5| Step: 7
Training loss: 2.812648684492162
Validation loss: 3.3017535956125195

Epoch: 5| Step: 8
Training loss: 3.9369964277596674
Validation loss: 3.3017556182594605

Epoch: 5| Step: 9
Training loss: 3.5996232842328255
Validation loss: 3.2998887757108757

Epoch: 5| Step: 10
Training loss: 2.6391709517153163
Validation loss: 3.299522647408813

Epoch: 117| Step: 0
Training loss: 3.77810790607886
Validation loss: 3.2996860066398104

Epoch: 5| Step: 1
Training loss: 3.8190573910428607
Validation loss: 3.2993238233028577

Epoch: 5| Step: 2
Training loss: 2.9391763651894856
Validation loss: 3.298593514609056

Epoch: 5| Step: 3
Training loss: 3.145640756805205
Validation loss: 3.299693828809336

Epoch: 5| Step: 4
Training loss: 3.592013395586078
Validation loss: 3.299458804458117

Epoch: 5| Step: 5
Training loss: 3.8112834803085627
Validation loss: 3.298320898571186

Epoch: 5| Step: 6
Training loss: 3.600715322422738
Validation loss: 3.298929494717122

Epoch: 5| Step: 7
Training loss: 3.673109780332467
Validation loss: 3.2981423035602626

Epoch: 5| Step: 8
Training loss: 3.3090818511255855
Validation loss: 3.29855436876791

Epoch: 5| Step: 9
Training loss: 3.5569411961990283
Validation loss: 3.297250920356527

Epoch: 5| Step: 10
Training loss: 3.503882978993585
Validation loss: 3.2975010213623563

Epoch: 118| Step: 0
Training loss: 3.9271462567834123
Validation loss: 3.298019670025756

Epoch: 5| Step: 1
Training loss: 4.005132005590096
Validation loss: 3.298873562319776

Epoch: 5| Step: 2
Training loss: 3.4576524424235666
Validation loss: 3.3016405358308787

Epoch: 5| Step: 3
Training loss: 3.7281260539178884
Validation loss: 3.299276406092934

Epoch: 5| Step: 4
Training loss: 4.165684368056762
Validation loss: 3.297788834613789

Epoch: 5| Step: 5
Training loss: 3.6806771472223643
Validation loss: 3.297882549753662

Epoch: 5| Step: 6
Training loss: 3.4045543124656303
Validation loss: 3.2964069963703833

Epoch: 5| Step: 7
Training loss: 2.9774751640712527
Validation loss: 3.296616402255527

Epoch: 5| Step: 8
Training loss: 2.6360492675819596
Validation loss: 3.296634152255173

Epoch: 5| Step: 9
Training loss: 2.495833453484619
Validation loss: 3.295212854322814

Epoch: 5| Step: 10
Training loss: 3.9359958742786896
Validation loss: 3.2948954753830946

Epoch: 119| Step: 0
Training loss: 3.515643446132163
Validation loss: 3.294318448141338

Epoch: 5| Step: 1
Training loss: 3.3312027002809192
Validation loss: 3.2967843418110836

Epoch: 5| Step: 2
Training loss: 3.7182955424122297
Validation loss: 3.294587062703265

Epoch: 5| Step: 3
Training loss: 3.2474905743069375
Validation loss: 3.293906152667919

Epoch: 5| Step: 4
Training loss: 4.35032737640058
Validation loss: 3.294885623517839

Epoch: 5| Step: 5
Training loss: 3.258707851990421
Validation loss: 3.294207250735464

Epoch: 5| Step: 6
Training loss: 3.6418880514654397
Validation loss: 3.2955423933722083

Epoch: 5| Step: 7
Training loss: 2.653863979628456
Validation loss: 3.2974451564753546

Epoch: 5| Step: 8
Training loss: 3.6293014787466764
Validation loss: 3.2970564286428035

Epoch: 5| Step: 9
Training loss: 3.0120559681711607
Validation loss: 3.2959767062465897

Epoch: 5| Step: 10
Training loss: 4.192875159441447
Validation loss: 3.299111397841705

Epoch: 120| Step: 0
Training loss: 3.95760070981092
Validation loss: 3.294704095566704

Epoch: 5| Step: 1
Training loss: 3.3977054202060484
Validation loss: 3.293417609903277

Epoch: 5| Step: 2
Training loss: 3.8021241625679463
Validation loss: 3.29334027595215

Epoch: 5| Step: 3
Training loss: 3.24192467049326
Validation loss: 3.2919940113332182

Epoch: 5| Step: 4
Training loss: 4.218249029861761
Validation loss: 3.291359854548485

Epoch: 5| Step: 5
Training loss: 3.201548118428686
Validation loss: 3.2913095621403214

Epoch: 5| Step: 6
Training loss: 3.567563657774099
Validation loss: 3.2910599316175135

Epoch: 5| Step: 7
Training loss: 3.9370663116428393
Validation loss: 3.291510549581242

Epoch: 5| Step: 8
Training loss: 2.7040628559267055
Validation loss: 3.290894808967199

Epoch: 5| Step: 9
Training loss: 3.770655773612029
Validation loss: 3.290661217583371

Epoch: 5| Step: 10
Training loss: 2.37006518004719
Validation loss: 3.2909040838496146

Epoch: 121| Step: 0
Training loss: 3.471137797239095
Validation loss: 3.290682012334063

Epoch: 5| Step: 1
Training loss: 3.853444473375373
Validation loss: 3.2900575235584792

Epoch: 5| Step: 2
Training loss: 4.097980904604954
Validation loss: 3.2900094351365303

Epoch: 5| Step: 3
Training loss: 3.935180707609002
Validation loss: 3.2913893887512997

Epoch: 5| Step: 4
Training loss: 3.7358133905681035
Validation loss: 3.2907683731823143

Epoch: 5| Step: 5
Training loss: 2.7725386761512265
Validation loss: 3.2900550628172622

Epoch: 5| Step: 6
Training loss: 2.9926719173805414
Validation loss: 3.288167217684915

Epoch: 5| Step: 7
Training loss: 2.996653279524601
Validation loss: 3.2882597771907025

Epoch: 5| Step: 8
Training loss: 3.607869680685889
Validation loss: 3.288194093890707

Epoch: 5| Step: 9
Training loss: 3.175947009050509
Validation loss: 3.287640915287532

Epoch: 5| Step: 10
Training loss: 3.870846398820511
Validation loss: 3.2880286916539787

Epoch: 122| Step: 0
Training loss: 4.0163841865792795
Validation loss: 3.28916306858661

Epoch: 5| Step: 1
Training loss: 3.2834620694193983
Validation loss: 3.288812019191571

Epoch: 5| Step: 2
Training loss: 3.8400158615579443
Validation loss: 3.2882281566242417

Epoch: 5| Step: 3
Training loss: 3.6744817043902174
Validation loss: 3.2879638692098587

Epoch: 5| Step: 4
Training loss: 3.309919395733074
Validation loss: 3.2875748999064345

Epoch: 5| Step: 5
Training loss: 3.1817050690795408
Validation loss: 3.2875228153009295

Epoch: 5| Step: 6
Training loss: 2.9377574402026148
Validation loss: 3.286707534392018

Epoch: 5| Step: 7
Training loss: 3.253733617775791
Validation loss: 3.2870340616077702

Epoch: 5| Step: 8
Training loss: 4.207060039000267
Validation loss: 3.2864832229312717

Epoch: 5| Step: 9
Training loss: 3.8804102629617563
Validation loss: 3.2865323832466613

Epoch: 5| Step: 10
Training loss: 2.711491948575308
Validation loss: 3.2849438511221307

Epoch: 123| Step: 0
Training loss: 3.0752883465801735
Validation loss: 3.286064500471533

Epoch: 5| Step: 1
Training loss: 3.1710110695175646
Validation loss: 3.286227459170701

Epoch: 5| Step: 2
Training loss: 3.803092606593825
Validation loss: 3.2860887780346255

Epoch: 5| Step: 3
Training loss: 3.2657403514876933
Validation loss: 3.2874295620511655

Epoch: 5| Step: 4
Training loss: 3.530057182389189
Validation loss: 3.288851064292484

Epoch: 5| Step: 5
Training loss: 3.794982061532185
Validation loss: 3.287377709875902

Epoch: 5| Step: 6
Training loss: 3.3368736222216615
Validation loss: 3.2854405689883173

Epoch: 5| Step: 7
Training loss: 3.4873622525264967
Validation loss: 3.286115435636145

Epoch: 5| Step: 8
Training loss: 3.4253321911176493
Validation loss: 3.2845716845117656

Epoch: 5| Step: 9
Training loss: 4.029996455264366
Validation loss: 3.2841476623236923

Epoch: 5| Step: 10
Training loss: 3.6673900728712017
Validation loss: 3.282827779479337

Epoch: 124| Step: 0
Training loss: 3.2689821062412214
Validation loss: 3.283133715823586

Epoch: 5| Step: 1
Training loss: 3.5491691261767246
Validation loss: 3.2832513599605804

Epoch: 5| Step: 2
Training loss: 3.033633052424953
Validation loss: 3.284492764649145

Epoch: 5| Step: 3
Training loss: 3.805102190607926
Validation loss: 3.2847867984773753

Epoch: 5| Step: 4
Training loss: 3.342665879806266
Validation loss: 3.2853432223489034

Epoch: 5| Step: 5
Training loss: 4.497398048080785
Validation loss: 3.286899329111245

Epoch: 5| Step: 6
Training loss: 3.7286624389966403
Validation loss: 3.2834456309700086

Epoch: 5| Step: 7
Training loss: 2.39780459922345
Validation loss: 3.283815601868597

Epoch: 5| Step: 8
Training loss: 3.763910180125872
Validation loss: 3.281742564868328

Epoch: 5| Step: 9
Training loss: 3.7754389981300287
Validation loss: 3.283184681620293

Epoch: 5| Step: 10
Training loss: 3.0004063966781316
Validation loss: 3.2820625373418437

Epoch: 125| Step: 0
Training loss: 3.2547694202795707
Validation loss: 3.2819086401158044

Epoch: 5| Step: 1
Training loss: 3.6208501279124645
Validation loss: 3.2806262336061764

Epoch: 5| Step: 2
Training loss: 3.2304964998430266
Validation loss: 3.280445122433772

Epoch: 5| Step: 3
Training loss: 3.3389485905183554
Validation loss: 3.281086469834341

Epoch: 5| Step: 4
Training loss: 4.200283749395921
Validation loss: 3.2806533786723886

Epoch: 5| Step: 5
Training loss: 4.000455115176277
Validation loss: 3.2801837444661968

Epoch: 5| Step: 6
Training loss: 4.266190599664531
Validation loss: 3.281572789157518

Epoch: 5| Step: 7
Training loss: 3.55703945950726
Validation loss: 3.2807864274306064

Epoch: 5| Step: 8
Training loss: 2.8312830706216516
Validation loss: 3.2786463191666146

Epoch: 5| Step: 9
Training loss: 2.9785223488653614
Validation loss: 3.279418495105683

Epoch: 5| Step: 10
Training loss: 2.941943277928607
Validation loss: 3.2795327063606905

Epoch: 126| Step: 0
Training loss: 3.3646536584517888
Validation loss: 3.2821442205457236

Epoch: 5| Step: 1
Training loss: 3.0917365718317678
Validation loss: 3.2818191042602405

Epoch: 5| Step: 2
Training loss: 3.3171073972182716
Validation loss: 3.2818757389802125

Epoch: 5| Step: 3
Training loss: 3.3247997883342277
Validation loss: 3.278502475487359

Epoch: 5| Step: 4
Training loss: 3.312535411717411
Validation loss: 3.27835884132569

Epoch: 5| Step: 5
Training loss: 3.932059268105025
Validation loss: 3.2780325636281336

Epoch: 5| Step: 6
Training loss: 4.589031676830857
Validation loss: 3.2774634198067183

Epoch: 5| Step: 7
Training loss: 3.8046096699800573
Validation loss: 3.2766775905019903

Epoch: 5| Step: 8
Training loss: 3.4402291301446053
Validation loss: 3.278655947721011

Epoch: 5| Step: 9
Training loss: 3.006961692269194
Validation loss: 3.277481121005324

Epoch: 5| Step: 10
Training loss: 3.061001157853245
Validation loss: 3.2781623419263775

Epoch: 127| Step: 0
Training loss: 4.328753153805048
Validation loss: 3.2758116329388414

Epoch: 5| Step: 1
Training loss: 3.1987551771318072
Validation loss: 3.277546513707339

Epoch: 5| Step: 2
Training loss: 3.182194801433825
Validation loss: 3.27748119296758

Epoch: 5| Step: 3
Training loss: 4.173232182829832
Validation loss: 3.278969798559442

Epoch: 5| Step: 4
Training loss: 3.8848947510276903
Validation loss: 3.2756931894243024

Epoch: 5| Step: 5
Training loss: 4.019108430294322
Validation loss: 3.276754606529406

Epoch: 5| Step: 6
Training loss: 2.710173749386111
Validation loss: 3.2752147731575247

Epoch: 5| Step: 7
Training loss: 3.0065698211647396
Validation loss: 3.2755048749528033

Epoch: 5| Step: 8
Training loss: 3.3960405688249633
Validation loss: 3.274185538073758

Epoch: 5| Step: 9
Training loss: 3.4633242125355883
Validation loss: 3.2739685835417873

Epoch: 5| Step: 10
Training loss: 2.6551000462017575
Validation loss: 3.274736465488172

Epoch: 128| Step: 0
Training loss: 3.535546044204272
Validation loss: 3.273355326197596

Epoch: 5| Step: 1
Training loss: 3.6142104485126065
Validation loss: 3.2739464830128218

Epoch: 5| Step: 2
Training loss: 3.1766959699444683
Validation loss: 3.273787469756314

Epoch: 5| Step: 3
Training loss: 3.579782027316488
Validation loss: 3.2732591763766057

Epoch: 5| Step: 4
Training loss: 3.1943935574518894
Validation loss: 3.2750853164107054

Epoch: 5| Step: 5
Training loss: 2.892134813419267
Validation loss: 3.2744466980377394

Epoch: 5| Step: 6
Training loss: 3.5215687331739334
Validation loss: 3.27287834549589

Epoch: 5| Step: 7
Training loss: 3.99180502655066
Validation loss: 3.271781698988825

Epoch: 5| Step: 8
Training loss: 3.094626254438989
Validation loss: 3.272127349462149

Epoch: 5| Step: 9
Training loss: 3.3869176891992288
Validation loss: 3.2720259971450365

Epoch: 5| Step: 10
Training loss: 4.484237190282305
Validation loss: 3.2727272648809786

Epoch: 129| Step: 0
Training loss: 2.3332519403521306
Validation loss: 3.272557929400918

Epoch: 5| Step: 1
Training loss: 3.933970610399723
Validation loss: 3.271205393161027

Epoch: 5| Step: 2
Training loss: 4.356293057156406
Validation loss: 3.2708212749906074

Epoch: 5| Step: 3
Training loss: 3.7880256413978635
Validation loss: 3.2735256142386624

Epoch: 5| Step: 4
Training loss: 3.2075410500424653
Validation loss: 3.2737249464092444

Epoch: 5| Step: 5
Training loss: 3.930492887383026
Validation loss: 3.277138425079205

Epoch: 5| Step: 6
Training loss: 3.579114485609343
Validation loss: 3.276873409891589

Epoch: 5| Step: 7
Training loss: 3.01211105938304
Validation loss: 3.274157435811425

Epoch: 5| Step: 8
Training loss: 2.628594707377049
Validation loss: 3.2759031986484692

Epoch: 5| Step: 9
Training loss: 4.42769258981717
Validation loss: 3.271134563239348

Epoch: 5| Step: 10
Training loss: 2.3935195254136485
Validation loss: 3.2717468906720613

Epoch: 130| Step: 0
Training loss: 3.682838985589027
Validation loss: 3.2694707827573666

Epoch: 5| Step: 1
Training loss: 3.1552983728413504
Validation loss: 3.2685463970724338

Epoch: 5| Step: 2
Training loss: 3.5766818538697667
Validation loss: 3.2698185082303604

Epoch: 5| Step: 3
Training loss: 3.3432581174331597
Validation loss: 3.2689328596247185

Epoch: 5| Step: 4
Training loss: 3.273952689405175
Validation loss: 3.2696023969245145

Epoch: 5| Step: 5
Training loss: 3.834131130182887
Validation loss: 3.268620031333632

Epoch: 5| Step: 6
Training loss: 3.483926787008988
Validation loss: 3.2682503091366617

Epoch: 5| Step: 7
Training loss: 3.468851586306313
Validation loss: 3.267355375118622

Epoch: 5| Step: 8
Training loss: 3.401180169097717
Validation loss: 3.2678604305594985

Epoch: 5| Step: 9
Training loss: 3.7459855526443393
Validation loss: 3.268037357477831

Epoch: 5| Step: 10
Training loss: 3.518202451448734
Validation loss: 3.2675051953555103

Epoch: 131| Step: 0
Training loss: 3.8121540350359426
Validation loss: 3.2678549594431097

Epoch: 5| Step: 1
Training loss: 3.1226907972038163
Validation loss: 3.267612716465915

Epoch: 5| Step: 2
Training loss: 3.7176043885587857
Validation loss: 3.2658469227813347

Epoch: 5| Step: 3
Training loss: 3.444147237308641
Validation loss: 3.269271820102766

Epoch: 5| Step: 4
Training loss: 4.433369177957821
Validation loss: 3.2665554581029075

Epoch: 5| Step: 5
Training loss: 3.753416412500084
Validation loss: 3.2673066434192206

Epoch: 5| Step: 6
Training loss: 3.422963147922591
Validation loss: 3.2683016701790164

Epoch: 5| Step: 7
Training loss: 3.2062254252244893
Validation loss: 3.267276853860205

Epoch: 5| Step: 8
Training loss: 2.923853566397328
Validation loss: 3.26548686174245

Epoch: 5| Step: 9
Training loss: 3.0054624418108675
Validation loss: 3.2672830054428714

Epoch: 5| Step: 10
Training loss: 3.3817362493879983
Validation loss: 3.2661953911875883

Epoch: 132| Step: 0
Training loss: 3.2930669260832044
Validation loss: 3.2648671240253373

Epoch: 5| Step: 1
Training loss: 3.014794428002552
Validation loss: 3.265393925227132

Epoch: 5| Step: 2
Training loss: 3.951142428369017
Validation loss: 3.265209079073249

Epoch: 5| Step: 3
Training loss: 3.5013430607068146
Validation loss: 3.2640153721761678

Epoch: 5| Step: 4
Training loss: 3.5527810821902257
Validation loss: 3.2637730892889767

Epoch: 5| Step: 5
Training loss: 3.764275653357231
Validation loss: 3.264765571447552

Epoch: 5| Step: 6
Training loss: 4.098011855994929
Validation loss: 3.2640901610984203

Epoch: 5| Step: 7
Training loss: 3.514236786465194
Validation loss: 3.263806698393447

Epoch: 5| Step: 8
Training loss: 3.0294835557606223
Validation loss: 3.26473071266821

Epoch: 5| Step: 9
Training loss: 3.521639278345684
Validation loss: 3.2639277897837076

Epoch: 5| Step: 10
Training loss: 2.956444706059593
Validation loss: 3.2646600265400054

Epoch: 133| Step: 0
Training loss: 2.7847914704305885
Validation loss: 3.2626299474404235

Epoch: 5| Step: 1
Training loss: 3.35851670767141
Validation loss: 3.2651199206936283

Epoch: 5| Step: 2
Training loss: 2.9245702378905145
Validation loss: 3.268476372317517

Epoch: 5| Step: 3
Training loss: 3.9684689640053787
Validation loss: 3.2653429376951193

Epoch: 5| Step: 4
Training loss: 3.9200685755901135
Validation loss: 3.2705854213909316

Epoch: 5| Step: 5
Training loss: 3.77652603024482
Validation loss: 3.2635772764616915

Epoch: 5| Step: 6
Training loss: 3.718371844899447
Validation loss: 3.261477810412003

Epoch: 5| Step: 7
Training loss: 3.756824641140087
Validation loss: 3.2613371139162997

Epoch: 5| Step: 8
Training loss: 3.5400410829735613
Validation loss: 3.26103362394647

Epoch: 5| Step: 9
Training loss: 3.382668296083813
Validation loss: 3.2607913600876244

Epoch: 5| Step: 10
Training loss: 3.0449846712675575
Validation loss: 3.2606141563523816

Epoch: 134| Step: 0
Training loss: 3.2927418333089453
Validation loss: 3.2629530213753726

Epoch: 5| Step: 1
Training loss: 3.009664386529411
Validation loss: 3.260394742665862

Epoch: 5| Step: 2
Training loss: 3.3132048522733153
Validation loss: 3.259841321446266

Epoch: 5| Step: 3
Training loss: 3.9282501807709562
Validation loss: 3.259235902014055

Epoch: 5| Step: 4
Training loss: 3.08002363022496
Validation loss: 3.258254219099496

Epoch: 5| Step: 5
Training loss: 4.41446239719239
Validation loss: 3.260428572159279

Epoch: 5| Step: 6
Training loss: 2.647233087126656
Validation loss: 3.260169090242034

Epoch: 5| Step: 7
Training loss: 3.8485214267613492
Validation loss: 3.2634595106938415

Epoch: 5| Step: 8
Training loss: 3.5950430492640852
Validation loss: 3.2659067820439875

Epoch: 5| Step: 9
Training loss: 2.9697630107616146
Validation loss: 3.265680401251607

Epoch: 5| Step: 10
Training loss: 4.029736848479459
Validation loss: 3.2657351421535163

Epoch: 135| Step: 0
Training loss: 2.644038865921909
Validation loss: 3.262918540790869

Epoch: 5| Step: 1
Training loss: 3.2909596967614188
Validation loss: 3.2624408757899044

Epoch: 5| Step: 2
Training loss: 3.7172764014267883
Validation loss: 3.2629632823548707

Epoch: 5| Step: 3
Training loss: 3.648589888663726
Validation loss: 3.260243656794789

Epoch: 5| Step: 4
Training loss: 3.480559308279304
Validation loss: 3.257934102185865

Epoch: 5| Step: 5
Training loss: 3.467288972556782
Validation loss: 3.2580724631007194

Epoch: 5| Step: 6
Training loss: 3.8820419314447285
Validation loss: 3.2575110292580485

Epoch: 5| Step: 7
Training loss: 3.527807938120583
Validation loss: 3.2568371245322756

Epoch: 5| Step: 8
Training loss: 3.0955822075655473
Validation loss: 3.256565914197863

Epoch: 5| Step: 9
Training loss: 3.4523187446940384
Validation loss: 3.256304575891217

Epoch: 5| Step: 10
Training loss: 4.110488798678632
Validation loss: 3.2557010721032276

Epoch: 136| Step: 0
Training loss: 3.0934033440472004
Validation loss: 3.2560290458803465

Epoch: 5| Step: 1
Training loss: 3.571758620134195
Validation loss: 3.2549741840770654

Epoch: 5| Step: 2
Training loss: 3.6469378442260894
Validation loss: 3.254736091994955

Epoch: 5| Step: 3
Training loss: 3.193190189277786
Validation loss: 3.2546065461466087

Epoch: 5| Step: 4
Training loss: 3.527220460885242
Validation loss: 3.2548183050320665

Epoch: 5| Step: 5
Training loss: 2.998659788224182
Validation loss: 3.254492674817355

Epoch: 5| Step: 6
Training loss: 3.0804073953577165
Validation loss: 3.2539082346327137

Epoch: 5| Step: 7
Training loss: 3.361160300729453
Validation loss: 3.254245931531757

Epoch: 5| Step: 8
Training loss: 4.141826412157127
Validation loss: 3.2538178187690847

Epoch: 5| Step: 9
Training loss: 4.192175006314662
Validation loss: 3.253393450935848

Epoch: 5| Step: 10
Training loss: 3.3572153645949587
Validation loss: 3.2522754686191315

Epoch: 137| Step: 0
Training loss: 3.4079868193358087
Validation loss: 3.252775327741477

Epoch: 5| Step: 1
Training loss: 3.3272913215485276
Validation loss: 3.251563794008256

Epoch: 5| Step: 2
Training loss: 3.2810904327830688
Validation loss: 3.25274171657182

Epoch: 5| Step: 3
Training loss: 3.3034254329043478
Validation loss: 3.2535621803778993

Epoch: 5| Step: 4
Training loss: 3.5647288260242713
Validation loss: 3.2541852464418994

Epoch: 5| Step: 5
Training loss: 3.5408082407900707
Validation loss: 3.2550154906546447

Epoch: 5| Step: 6
Training loss: 3.24249883788477
Validation loss: 3.2552776144551117

Epoch: 5| Step: 7
Training loss: 3.8444833443596287
Validation loss: 3.254040234808281

Epoch: 5| Step: 8
Training loss: 2.8370668458751314
Validation loss: 3.253072335576414

Epoch: 5| Step: 9
Training loss: 3.329805907816254
Validation loss: 3.25042302365824

Epoch: 5| Step: 10
Training loss: 4.62280344997065
Validation loss: 3.25125699941354

Epoch: 138| Step: 0
Training loss: 2.9372868562029413
Validation loss: 3.250582971656607

Epoch: 5| Step: 1
Training loss: 4.140512141003202
Validation loss: 3.2502236821745467

Epoch: 5| Step: 2
Training loss: 3.53837406965738
Validation loss: 3.2497992078851143

Epoch: 5| Step: 3
Training loss: 3.0189402644694
Validation loss: 3.2494638417231245

Epoch: 5| Step: 4
Training loss: 3.9051313095386138
Validation loss: 3.2506284476876997

Epoch: 5| Step: 5
Training loss: 3.0118241941050092
Validation loss: 3.2496233801575336

Epoch: 5| Step: 6
Training loss: 2.866417555372142
Validation loss: 3.2501046327166203

Epoch: 5| Step: 7
Training loss: 3.636615165767695
Validation loss: 3.24992498622049

Epoch: 5| Step: 8
Training loss: 3.877098991667162
Validation loss: 3.248477557114675

Epoch: 5| Step: 9
Training loss: 3.3114003209475125
Validation loss: 3.249304729395235

Epoch: 5| Step: 10
Training loss: 3.883355760850663
Validation loss: 3.24892305463758

Epoch: 139| Step: 0
Training loss: 3.105055372447776
Validation loss: 3.2485483886008106

Epoch: 5| Step: 1
Training loss: 3.6954442458428867
Validation loss: 3.2488110136698434

Epoch: 5| Step: 2
Training loss: 3.0588872970864514
Validation loss: 3.2491099477461316

Epoch: 5| Step: 3
Training loss: 3.997074965067229
Validation loss: 3.24981112913432

Epoch: 5| Step: 4
Training loss: 3.220149948704046
Validation loss: 3.247627264593054

Epoch: 5| Step: 5
Training loss: 3.488166286030737
Validation loss: 3.2482025296840473

Epoch: 5| Step: 6
Training loss: 3.606997941598498
Validation loss: 3.248907834943064

Epoch: 5| Step: 7
Training loss: 3.7698416626562743
Validation loss: 3.2509111163790796

Epoch: 5| Step: 8
Training loss: 2.4121441672592
Validation loss: 3.2482039637491846

Epoch: 5| Step: 9
Training loss: 3.801413504067434
Validation loss: 3.2471015917196433

Epoch: 5| Step: 10
Training loss: 3.9256007518362566
Validation loss: 3.251874862517986

Epoch: 140| Step: 0
Training loss: 3.210219402717893
Validation loss: 3.251131275764657

Epoch: 5| Step: 1
Training loss: 3.5583942244335343
Validation loss: 3.2518521608899884

Epoch: 5| Step: 2
Training loss: 3.37669612508905
Validation loss: 3.2489310321656926

Epoch: 5| Step: 3
Training loss: 3.3220783160656717
Validation loss: 3.25591465581315

Epoch: 5| Step: 4
Training loss: 3.3782594271158297
Validation loss: 3.253294214723391

Epoch: 5| Step: 5
Training loss: 4.110673706452855
Validation loss: 3.246607356185324

Epoch: 5| Step: 6
Training loss: 3.4974527626583276
Validation loss: 3.2454784009429685

Epoch: 5| Step: 7
Training loss: 3.9697622375011377
Validation loss: 3.2446288932130485

Epoch: 5| Step: 8
Training loss: 3.2214292467640413
Validation loss: 3.2441373344505897

Epoch: 5| Step: 9
Training loss: 3.5094741929558264
Validation loss: 3.244542837128303

Epoch: 5| Step: 10
Training loss: 2.93468259066615
Validation loss: 3.2447858543161563

Epoch: 141| Step: 0
Training loss: 3.1419459359649027
Validation loss: 3.244297252555868

Epoch: 5| Step: 1
Training loss: 3.6381697991723616
Validation loss: 3.2440992226279146

Epoch: 5| Step: 2
Training loss: 3.669106986306795
Validation loss: 3.244148693311878

Epoch: 5| Step: 3
Training loss: 3.9036498914837074
Validation loss: 3.2439496735730344

Epoch: 5| Step: 4
Training loss: 3.9839276230913474
Validation loss: 3.243116736406787

Epoch: 5| Step: 5
Training loss: 3.1126572044535394
Validation loss: 3.2434925373046637

Epoch: 5| Step: 6
Training loss: 2.5365296862290205
Validation loss: 3.2427709116582686

Epoch: 5| Step: 7
Training loss: 3.032877219844525
Validation loss: 3.2436885620143547

Epoch: 5| Step: 8
Training loss: 4.171113934193882
Validation loss: 3.241201416011922

Epoch: 5| Step: 9
Training loss: 3.357782598604649
Validation loss: 3.243505735295331

Epoch: 5| Step: 10
Training loss: 3.413740828175971
Validation loss: 3.243481885922694

Epoch: 142| Step: 0
Training loss: 3.2108630986190816
Validation loss: 3.243686159357543

Epoch: 5| Step: 1
Training loss: 3.3678508910473774
Validation loss: 3.243086968122148

Epoch: 5| Step: 2
Training loss: 4.16069492917964
Validation loss: 3.242670403228557

Epoch: 5| Step: 3
Training loss: 3.2907287291491616
Validation loss: 3.2430109802102502

Epoch: 5| Step: 4
Training loss: 3.4519817133979416
Validation loss: 3.2428119625880676

Epoch: 5| Step: 5
Training loss: 3.4677625745658496
Validation loss: 3.241399850759114

Epoch: 5| Step: 6
Training loss: 2.792523883522783
Validation loss: 3.243217793813517

Epoch: 5| Step: 7
Training loss: 3.877052624864568
Validation loss: 3.241370277089602

Epoch: 5| Step: 8
Training loss: 3.2949395306469764
Validation loss: 3.2407816976669928

Epoch: 5| Step: 9
Training loss: 3.544388357321281
Validation loss: 3.2389253828503004

Epoch: 5| Step: 10
Training loss: 3.6532053211737696
Validation loss: 3.2387922046592785

Epoch: 143| Step: 0
Training loss: 4.009577252942566
Validation loss: 3.237891050208148

Epoch: 5| Step: 1
Training loss: 3.143016606781283
Validation loss: 3.2395293987653795

Epoch: 5| Step: 2
Training loss: 3.803206075087828
Validation loss: 3.2386701283493284

Epoch: 5| Step: 3
Training loss: 3.4155820350003867
Validation loss: 3.2386110955368177

Epoch: 5| Step: 4
Training loss: 3.8326364519546545
Validation loss: 3.2398181127622494

Epoch: 5| Step: 5
Training loss: 2.9938316509285494
Validation loss: 3.239347396207834

Epoch: 5| Step: 6
Training loss: 3.0200340178133755
Validation loss: 3.2393932784670407

Epoch: 5| Step: 7
Training loss: 3.8564685580300933
Validation loss: 3.237497917855938

Epoch: 5| Step: 8
Training loss: 2.4366318550528114
Validation loss: 3.237939200093362

Epoch: 5| Step: 9
Training loss: 3.757070361033169
Validation loss: 3.2380412939451304

Epoch: 5| Step: 10
Training loss: 3.6664665485449506
Validation loss: 3.2359901498449712

Epoch: 144| Step: 0
Training loss: 3.7276293748883838
Validation loss: 3.2359896840151228

Epoch: 5| Step: 1
Training loss: 3.8526138201713764
Validation loss: 3.2364795399447477

Epoch: 5| Step: 2
Training loss: 3.140901619794783
Validation loss: 3.237382342443578

Epoch: 5| Step: 3
Training loss: 3.520143851461947
Validation loss: 3.236845344746734

Epoch: 5| Step: 4
Training loss: 3.380574038589201
Validation loss: 3.2378774492837668

Epoch: 5| Step: 5
Training loss: 3.8027375098295373
Validation loss: 3.2363671442354716

Epoch: 5| Step: 6
Training loss: 3.6834255920409267
Validation loss: 3.2356928210980547

Epoch: 5| Step: 7
Training loss: 3.3948533373967837
Validation loss: 3.235208754328841

Epoch: 5| Step: 8
Training loss: 3.135110901448286
Validation loss: 3.2358379403342763

Epoch: 5| Step: 9
Training loss: 3.7040043684107684
Validation loss: 3.2359876796784435

Epoch: 5| Step: 10
Training loss: 2.5230877991230787
Validation loss: 3.239221351188296

Epoch: 145| Step: 0
Training loss: 2.8369490235582426
Validation loss: 3.2388827471118837

Epoch: 5| Step: 1
Training loss: 2.650072791341392
Validation loss: 3.2422284934789007

Epoch: 5| Step: 2
Training loss: 3.3284136866340037
Validation loss: 3.2406207279602732

Epoch: 5| Step: 3
Training loss: 4.119789531850282
Validation loss: 3.24229054253269

Epoch: 5| Step: 4
Training loss: 3.2738805939857913
Validation loss: 3.23653995027319

Epoch: 5| Step: 5
Training loss: 4.161146449057977
Validation loss: 3.232945086536539

Epoch: 5| Step: 6
Training loss: 3.297315522905379
Validation loss: 3.233660117549336

Epoch: 5| Step: 7
Training loss: 3.217135719004884
Validation loss: 3.2341736262240994

Epoch: 5| Step: 8
Training loss: 3.066796850122596
Validation loss: 3.2336273256547754

Epoch: 5| Step: 9
Training loss: 4.363506369388426
Validation loss: 3.232709851826959

Epoch: 5| Step: 10
Training loss: 3.44872435053834
Validation loss: 3.2328523580265833

Epoch: 146| Step: 0
Training loss: 3.4768938571021533
Validation loss: 3.2340074888891452

Epoch: 5| Step: 1
Training loss: 2.644854797675546
Validation loss: 3.232098920373797

Epoch: 5| Step: 2
Training loss: 3.655191121459918
Validation loss: 3.231699030700241

Epoch: 5| Step: 3
Training loss: 3.5323724903762064
Validation loss: 3.2317968405841344

Epoch: 5| Step: 4
Training loss: 3.4282024531277826
Validation loss: 3.2304293309730934

Epoch: 5| Step: 5
Training loss: 3.3966592981659764
Validation loss: 3.2306910642422366

Epoch: 5| Step: 6
Training loss: 4.23498080378734
Validation loss: 3.230641927088759

Epoch: 5| Step: 7
Training loss: 3.6101255751138104
Validation loss: 3.2307338604577356

Epoch: 5| Step: 8
Training loss: 2.9507994199016134
Validation loss: 3.2293530466289186

Epoch: 5| Step: 9
Training loss: 3.7420064289031676
Validation loss: 3.2303056156552636

Epoch: 5| Step: 10
Training loss: 3.2486126212604507
Validation loss: 3.2294127535591413

Epoch: 147| Step: 0
Training loss: 3.4055448029600583
Validation loss: 3.229535707681823

Epoch: 5| Step: 1
Training loss: 3.623209544023412
Validation loss: 3.2321209279090426

Epoch: 5| Step: 2
Training loss: 3.866197370682183
Validation loss: 3.2301225298767733

Epoch: 5| Step: 3
Training loss: 4.02274104636665
Validation loss: 3.232876844080072

Epoch: 5| Step: 4
Training loss: 3.3325632795319824
Validation loss: 3.229400017147105

Epoch: 5| Step: 5
Training loss: 3.0237041819059107
Validation loss: 3.232156450892594

Epoch: 5| Step: 6
Training loss: 3.4981684660958656
Validation loss: 3.2307320655229064

Epoch: 5| Step: 7
Training loss: 2.783755684595423
Validation loss: 3.230551522677243

Epoch: 5| Step: 8
Training loss: 4.211804585545404
Validation loss: 3.228483916372115

Epoch: 5| Step: 9
Training loss: 2.9676673922934387
Validation loss: 3.228335412429814

Epoch: 5| Step: 10
Training loss: 3.058232506554717
Validation loss: 3.2268813341026816

Epoch: 148| Step: 0
Training loss: 3.0024813880311787
Validation loss: 3.227163593182305

Epoch: 5| Step: 1
Training loss: 3.7911946069209357
Validation loss: 3.2266904021021254

Epoch: 5| Step: 2
Training loss: 3.5913464013241887
Validation loss: 3.227793511871884

Epoch: 5| Step: 3
Training loss: 3.472821706943121
Validation loss: 3.2262602069595046

Epoch: 5| Step: 4
Training loss: 3.8688545718257505
Validation loss: 3.2269868181135077

Epoch: 5| Step: 5
Training loss: 3.6844518962468267
Validation loss: 3.226120478511566

Epoch: 5| Step: 6
Training loss: 3.5927439732754856
Validation loss: 3.2262423105497824

Epoch: 5| Step: 7
Training loss: 3.0371698207911764
Validation loss: 3.2258147505684205

Epoch: 5| Step: 8
Training loss: 2.9735399654532073
Validation loss: 3.2266541126135477

Epoch: 5| Step: 9
Training loss: 3.9166203895161615
Validation loss: 3.2254144156046594

Epoch: 5| Step: 10
Training loss: 2.9102596392603384
Validation loss: 3.2248362254219995

Epoch: 149| Step: 0
Training loss: 3.450586136493881
Validation loss: 3.2260979031855284

Epoch: 5| Step: 1
Training loss: 3.4260708937650435
Validation loss: 3.225036913542938

Epoch: 5| Step: 2
Training loss: 3.739079405144217
Validation loss: 3.226349689108246

Epoch: 5| Step: 3
Training loss: 2.786388151526854
Validation loss: 3.2237002263641084

Epoch: 5| Step: 4
Training loss: 3.1745379314454625
Validation loss: 3.2279575769026936

Epoch: 5| Step: 5
Training loss: 3.9140459315392837
Validation loss: 3.22717233468627

Epoch: 5| Step: 6
Training loss: 2.8531340984354006
Validation loss: 3.2278480804197147

Epoch: 5| Step: 7
Training loss: 4.29001360911098
Validation loss: 3.2258365577913084

Epoch: 5| Step: 8
Training loss: 3.8339364917969525
Validation loss: 3.226375735820138

Epoch: 5| Step: 9
Training loss: 3.047406272542143
Validation loss: 3.2284211477435965

Epoch: 5| Step: 10
Training loss: 3.2450731052339927
Validation loss: 3.225202780095182

Epoch: 150| Step: 0
Training loss: 3.5740114245709775
Validation loss: 3.225017441167186

Epoch: 5| Step: 1
Training loss: 3.5228025959721316
Validation loss: 3.2239254120104324

Epoch: 5| Step: 2
Training loss: 3.6647066310650924
Validation loss: 3.2229572345266537

Epoch: 5| Step: 3
Training loss: 3.817455010989035
Validation loss: 3.223890576038324

Epoch: 5| Step: 4
Training loss: 3.725415835115759
Validation loss: 3.224128919150462

Epoch: 5| Step: 5
Training loss: 3.408809435234987
Validation loss: 3.222566022507887

Epoch: 5| Step: 6
Training loss: 2.6343971260562515
Validation loss: 3.2214599377667628

Epoch: 5| Step: 7
Training loss: 3.36441315180197
Validation loss: 3.2221098871301823

Epoch: 5| Step: 8
Training loss: 3.491946628123361
Validation loss: 3.220895202290412

Epoch: 5| Step: 9
Training loss: 3.0141379687569296
Validation loss: 3.221700248730608

Epoch: 5| Step: 10
Training loss: 3.7430393467923553
Validation loss: 3.22104095637535

Epoch: 151| Step: 0
Training loss: 3.3009706341287512
Validation loss: 3.2206680233354192

Epoch: 5| Step: 1
Training loss: 3.571830443524042
Validation loss: 3.2205792493926944

Epoch: 5| Step: 2
Training loss: 4.05518421812977
Validation loss: 3.2203578594885958

Epoch: 5| Step: 3
Training loss: 3.8487503897210495
Validation loss: 3.219929935335326

Epoch: 5| Step: 4
Training loss: 2.679386933933925
Validation loss: 3.219024471277088

Epoch: 5| Step: 5
Training loss: 3.5277510330775037
Validation loss: 3.2200184724089733

Epoch: 5| Step: 6
Training loss: 3.4350630011187966
Validation loss: 3.2188100485651754

Epoch: 5| Step: 7
Training loss: 3.40085153014152
Validation loss: 3.2193642386712025

Epoch: 5| Step: 8
Training loss: 3.50241877220006
Validation loss: 3.2197792883727034

Epoch: 5| Step: 9
Training loss: 3.612183374171042
Validation loss: 3.218869492307678

Epoch: 5| Step: 10
Training loss: 2.830375155597459
Validation loss: 3.2192066496715817

Epoch: 152| Step: 0
Training loss: 3.7742413598506426
Validation loss: 3.2200185966094814

Epoch: 5| Step: 1
Training loss: 3.611509278345845
Validation loss: 3.217807856096873

Epoch: 5| Step: 2
Training loss: 3.2287548828088077
Validation loss: 3.216747659497424

Epoch: 5| Step: 3
Training loss: 2.9720628424324538
Validation loss: 3.2182661442122535

Epoch: 5| Step: 4
Training loss: 3.619974796776474
Validation loss: 3.2170910270078257

Epoch: 5| Step: 5
Training loss: 3.4712710455262332
Validation loss: 3.2158698674458153

Epoch: 5| Step: 6
Training loss: 3.632636084426157
Validation loss: 3.2176968023960355

Epoch: 5| Step: 7
Training loss: 3.306049904780687
Validation loss: 3.2181790310689884

Epoch: 5| Step: 8
Training loss: 3.8677267912323137
Validation loss: 3.220162779022768

Epoch: 5| Step: 9
Training loss: 3.383266638738914
Validation loss: 3.2222460596897577

Epoch: 5| Step: 10
Training loss: 3.010257034733269
Validation loss: 3.2253173349894095

Epoch: 153| Step: 0
Training loss: 2.4392148368031394
Validation loss: 3.222815641486856

Epoch: 5| Step: 1
Training loss: 4.3744380045012194
Validation loss: 3.2194243124096107

Epoch: 5| Step: 2
Training loss: 3.6634711009932235
Validation loss: 3.215673639352227

Epoch: 5| Step: 3
Training loss: 3.7185992042036347
Validation loss: 3.2159556720192604

Epoch: 5| Step: 4
Training loss: 4.270486485733107
Validation loss: 3.215155021484415

Epoch: 5| Step: 5
Training loss: 2.4552277706791905
Validation loss: 3.2149171653503417

Epoch: 5| Step: 6
Training loss: 3.152776185052575
Validation loss: 3.2146284439260264

Epoch: 5| Step: 7
Training loss: 2.741628214866977
Validation loss: 3.214085357002629

Epoch: 5| Step: 8
Training loss: 3.7746653326371975
Validation loss: 3.2144460315834014

Epoch: 5| Step: 9
Training loss: 2.4184148866804125
Validation loss: 3.2141598576733164

Epoch: 5| Step: 10
Training loss: 4.29334194237772
Validation loss: 3.213662116329148

Epoch: 154| Step: 0
Training loss: 3.2255710066733605
Validation loss: 3.215649454405775

Epoch: 5| Step: 1
Training loss: 3.5758185136556553
Validation loss: 3.215839874047746

Epoch: 5| Step: 2
Training loss: 3.50754075388979
Validation loss: 3.215824985662374

Epoch: 5| Step: 3
Training loss: 3.2393817573136854
Validation loss: 3.214938281771458

Epoch: 5| Step: 4
Training loss: 3.995029221906483
Validation loss: 3.212730766643483

Epoch: 5| Step: 5
Training loss: 3.016475103067207
Validation loss: 3.215368455299671

Epoch: 5| Step: 6
Training loss: 3.2246713337759654
Validation loss: 3.2133807072878735

Epoch: 5| Step: 7
Training loss: 3.4962420043199236
Validation loss: 3.2156984475481196

Epoch: 5| Step: 8
Training loss: 3.087019564048527
Validation loss: 3.213248754557596

Epoch: 5| Step: 9
Training loss: 3.739850614695627
Validation loss: 3.21222856282294

Epoch: 5| Step: 10
Training loss: 3.815129858284157
Validation loss: 3.212324461225487

Epoch: 155| Step: 0
Training loss: 3.241720216467335
Validation loss: 3.2118039560059954

Epoch: 5| Step: 1
Training loss: 3.5251138763430783
Validation loss: 3.212807837784025

Epoch: 5| Step: 2
Training loss: 3.950632387554767
Validation loss: 3.212559131365237

Epoch: 5| Step: 3
Training loss: 3.8487221417808
Validation loss: 3.2119584003158974

Epoch: 5| Step: 4
Training loss: 3.1847393572409612
Validation loss: 3.212876449859395

Epoch: 5| Step: 5
Training loss: 3.803304620668407
Validation loss: 3.21077173169058

Epoch: 5| Step: 6
Training loss: 2.6558380705120195
Validation loss: 3.2099494400900928

Epoch: 5| Step: 7
Training loss: 3.513280739677109
Validation loss: 3.211190310972615

Epoch: 5| Step: 8
Training loss: 3.672516722098986
Validation loss: 3.2104612553723064

Epoch: 5| Step: 9
Training loss: 3.090751659239512
Validation loss: 3.210217633047817

Epoch: 5| Step: 10
Training loss: 3.2654718244485115
Validation loss: 3.2087427066419507

Epoch: 156| Step: 0
Training loss: 3.006384413920265
Validation loss: 3.2089584299905765

Epoch: 5| Step: 1
Training loss: 3.1561714389201785
Validation loss: 3.2087699476918146

Epoch: 5| Step: 2
Training loss: 3.344998705853724
Validation loss: 3.209265059173579

Epoch: 5| Step: 3
Training loss: 3.9191528843296624
Validation loss: 3.2089815692805588

Epoch: 5| Step: 4
Training loss: 3.3047789793226494
Validation loss: 3.2103938765372138

Epoch: 5| Step: 5
Training loss: 3.4672620176513704
Validation loss: 3.2088846170650003

Epoch: 5| Step: 6
Training loss: 2.979003225969538
Validation loss: 3.2113951009241646

Epoch: 5| Step: 7
Training loss: 4.503927212589443
Validation loss: 3.21156715922154

Epoch: 5| Step: 8
Training loss: 2.47364399301658
Validation loss: 3.2107990912611397

Epoch: 5| Step: 9
Training loss: 3.949840523120023
Validation loss: 3.209992643814365

Epoch: 5| Step: 10
Training loss: 3.4090922685100273
Validation loss: 3.208321628194956

Epoch: 157| Step: 0
Training loss: 3.516025774682259
Validation loss: 3.207917099475827

Epoch: 5| Step: 1
Training loss: 2.728571984726843
Validation loss: 3.206873691283642

Epoch: 5| Step: 2
Training loss: 4.079381522630328
Validation loss: 3.2057007972397185

Epoch: 5| Step: 3
Training loss: 2.651206400511434
Validation loss: 3.2066154472726107

Epoch: 5| Step: 4
Training loss: 3.385959491737534
Validation loss: 3.2062011386241243

Epoch: 5| Step: 5
Training loss: 3.8583016698429238
Validation loss: 3.206183336542752

Epoch: 5| Step: 6
Training loss: 3.9729583535343607
Validation loss: 3.2072442396589915

Epoch: 5| Step: 7
Training loss: 3.5648199190559193
Validation loss: 3.206916522350264

Epoch: 5| Step: 8
Training loss: 3.780856908116963
Validation loss: 3.2076623921174505

Epoch: 5| Step: 9
Training loss: 2.959928234879969
Validation loss: 3.2069203387305865

Epoch: 5| Step: 10
Training loss: 3.0582116133108825
Validation loss: 3.205813367664868

Epoch: 158| Step: 0
Training loss: 3.147320797812912
Validation loss: 3.2044856541258535

Epoch: 5| Step: 1
Training loss: 3.311861228532697
Validation loss: 3.204515649795203

Epoch: 5| Step: 2
Training loss: 3.51857122099224
Validation loss: 3.2044591974788457

Epoch: 5| Step: 3
Training loss: 3.622459047242659
Validation loss: 3.203964335524551

Epoch: 5| Step: 4
Training loss: 3.394888873297053
Validation loss: 3.2047826272019617

Epoch: 5| Step: 5
Training loss: 3.5010149710236234
Validation loss: 3.2029796648406443

Epoch: 5| Step: 6
Training loss: 3.8446530157510233
Validation loss: 3.2037257021675485

Epoch: 5| Step: 7
Training loss: 3.3142459514656784
Validation loss: 3.2036623300241827

Epoch: 5| Step: 8
Training loss: 3.511379272210643
Validation loss: 3.210207834360563

Epoch: 5| Step: 9
Training loss: 3.428001319511097
Validation loss: 3.2156858011162384

Epoch: 5| Step: 10
Training loss: 3.24784838539632
Validation loss: 3.2079944492881562

Epoch: 159| Step: 0
Training loss: 3.301126784798852
Validation loss: 3.2076209488905665

Epoch: 5| Step: 1
Training loss: 3.998239725937765
Validation loss: 3.2076577070631824

Epoch: 5| Step: 2
Training loss: 3.424967722497029
Validation loss: 3.2124843621450925

Epoch: 5| Step: 3
Training loss: 3.773894793678982
Validation loss: 3.207573299787053

Epoch: 5| Step: 4
Training loss: 2.547656916314406
Validation loss: 3.20882158888425

Epoch: 5| Step: 5
Training loss: 3.474509466663682
Validation loss: 3.2101689220168343

Epoch: 5| Step: 6
Training loss: 3.359965143931201
Validation loss: 3.2039984023779837

Epoch: 5| Step: 7
Training loss: 3.0251581387129485
Validation loss: 3.2044927454621557

Epoch: 5| Step: 8
Training loss: 3.288240959879536
Validation loss: 3.20128016655425

Epoch: 5| Step: 9
Training loss: 3.1158227060046126
Validation loss: 3.2026492217936666

Epoch: 5| Step: 10
Training loss: 4.39279088802195
Validation loss: 3.200798182384996

Epoch: 160| Step: 0
Training loss: 3.990190637379602
Validation loss: 3.200545063179232

Epoch: 5| Step: 1
Training loss: 3.5819684171833814
Validation loss: 3.2015753966724

Epoch: 5| Step: 2
Training loss: 3.176073574674492
Validation loss: 3.2007746307188385

Epoch: 5| Step: 3
Training loss: 3.9022174009043753
Validation loss: 3.201075416641353

Epoch: 5| Step: 4
Training loss: 3.372150772597495
Validation loss: 3.201254091835795

Epoch: 5| Step: 5
Training loss: 4.0618778632700225
Validation loss: 3.20020649648125

Epoch: 5| Step: 6
Training loss: 3.122635671754421
Validation loss: 3.199788908764023

Epoch: 5| Step: 7
Training loss: 2.824057588951853
Validation loss: 3.1994746920405186

Epoch: 5| Step: 8
Training loss: 3.1387312764194597
Validation loss: 3.1998671376554246

Epoch: 5| Step: 9
Training loss: 3.0302575443206323
Validation loss: 3.1985311505359006

Epoch: 5| Step: 10
Training loss: 3.4717018008701497
Validation loss: 3.1992626868051413

Epoch: 161| Step: 0
Training loss: 3.4879791368158015
Validation loss: 3.1977431389944413

Epoch: 5| Step: 1
Training loss: 3.4449393487693247
Validation loss: 3.199801068409895

Epoch: 5| Step: 2
Training loss: 3.779770364598124
Validation loss: 3.1983908238643997

Epoch: 5| Step: 3
Training loss: 3.0966761458805827
Validation loss: 3.1999237022289604

Epoch: 5| Step: 4
Training loss: 3.843191835148291
Validation loss: 3.202740596312356

Epoch: 5| Step: 5
Training loss: 3.2097155248253975
Validation loss: 3.2000982270751845

Epoch: 5| Step: 6
Training loss: 3.39281115393196
Validation loss: 3.2005116276098953

Epoch: 5| Step: 7
Training loss: 3.4576339627322117
Validation loss: 3.2018501087652713

Epoch: 5| Step: 8
Training loss: 2.947437278850281
Validation loss: 3.1984426430552357

Epoch: 5| Step: 9
Training loss: 2.9269780765672926
Validation loss: 3.196095798413258

Epoch: 5| Step: 10
Training loss: 4.1730169097901495
Validation loss: 3.196745441804947

Epoch: 162| Step: 0
Training loss: 3.737168037701356
Validation loss: 3.1974081618708277

Epoch: 5| Step: 1
Training loss: 3.841773540695532
Validation loss: 3.1986492461986806

Epoch: 5| Step: 2
Training loss: 3.448625489794429
Validation loss: 3.1968792320862343

Epoch: 5| Step: 3
Training loss: 3.8187674614090352
Validation loss: 3.1976629324021233

Epoch: 5| Step: 4
Training loss: 2.867309567714043
Validation loss: 3.195059472566141

Epoch: 5| Step: 5
Training loss: 3.183468531854924
Validation loss: 3.1971084269731276

Epoch: 5| Step: 6
Training loss: 3.6007482969564353
Validation loss: 3.1961871806162296

Epoch: 5| Step: 7
Training loss: 3.040728663905268
Validation loss: 3.1972408966876804

Epoch: 5| Step: 8
Training loss: 3.8386941549101574
Validation loss: 3.195459695364108

Epoch: 5| Step: 9
Training loss: 2.882828875239315
Validation loss: 3.1971847120323815

Epoch: 5| Step: 10
Training loss: 3.3611567540568226
Validation loss: 3.1969216180762285

Epoch: 163| Step: 0
Training loss: 3.561289129768616
Validation loss: 3.196712575984844

Epoch: 5| Step: 1
Training loss: 2.8733066049853506
Validation loss: 3.194906141156887

Epoch: 5| Step: 2
Training loss: 3.4885163607077696
Validation loss: 3.192944178088789

Epoch: 5| Step: 3
Training loss: 3.286653411121475
Validation loss: 3.1939918092760604

Epoch: 5| Step: 4
Training loss: 3.248678378834452
Validation loss: 3.1948530015834997

Epoch: 5| Step: 5
Training loss: 3.674589282070411
Validation loss: 3.1950663055971047

Epoch: 5| Step: 6
Training loss: 3.2411359069727794
Validation loss: 3.192579792798705

Epoch: 5| Step: 7
Training loss: 3.410019355114909
Validation loss: 3.192414022053644

Epoch: 5| Step: 8
Training loss: 3.442604436571483
Validation loss: 3.1930293863732695

Epoch: 5| Step: 9
Training loss: 4.126920773062971
Validation loss: 3.191519919839116

Epoch: 5| Step: 10
Training loss: 3.3067425770147407
Validation loss: 3.1937201185385597

Epoch: 164| Step: 0
Training loss: 2.152756445447447
Validation loss: 3.190410820304668

Epoch: 5| Step: 1
Training loss: 3.5280509569289813
Validation loss: 3.191393683228514

Epoch: 5| Step: 2
Training loss: 2.934911195883475
Validation loss: 3.1915607905738264

Epoch: 5| Step: 3
Training loss: 4.056779795698925
Validation loss: 3.190000802484031

Epoch: 5| Step: 4
Training loss: 2.991972833408093
Validation loss: 3.1904607715234543

Epoch: 5| Step: 5
Training loss: 3.808933278135121
Validation loss: 3.190282989706793

Epoch: 5| Step: 6
Training loss: 3.010855742820826
Validation loss: 3.190751068374811

Epoch: 5| Step: 7
Training loss: 3.386128340035692
Validation loss: 3.1909823568233917

Epoch: 5| Step: 8
Training loss: 4.058813212154768
Validation loss: 3.1907576310287844

Epoch: 5| Step: 9
Training loss: 3.524878230595682
Validation loss: 3.191857245775389

Epoch: 5| Step: 10
Training loss: 3.93274328741522
Validation loss: 3.191128865006845

Epoch: 165| Step: 0
Training loss: 3.067107335508775
Validation loss: 3.1915557911040184

Epoch: 5| Step: 1
Training loss: 3.4970906290861254
Validation loss: 3.1926722287717126

Epoch: 5| Step: 2
Training loss: 3.301688346143317
Validation loss: 3.1910675146599976

Epoch: 5| Step: 3
Training loss: 3.7265866836626853
Validation loss: 3.1892650252812227

Epoch: 5| Step: 4
Training loss: 3.1572921090087447
Validation loss: 3.1888687794830357

Epoch: 5| Step: 5
Training loss: 3.8432093294314718
Validation loss: 3.1885731720433794

Epoch: 5| Step: 6
Training loss: 3.1799308814928318
Validation loss: 3.189954217831756

Epoch: 5| Step: 7
Training loss: 3.260888127536739
Validation loss: 3.189018050489527

Epoch: 5| Step: 8
Training loss: 3.870129878109713
Validation loss: 3.1887125905395455

Epoch: 5| Step: 9
Training loss: 3.6241601431454518
Validation loss: 3.1874182230371795

Epoch: 5| Step: 10
Training loss: 3.0683997799297043
Validation loss: 3.1876454554391

Epoch: 166| Step: 0
Training loss: 3.792123466614367
Validation loss: 3.1871151290645003

Epoch: 5| Step: 1
Training loss: 3.497939184289416
Validation loss: 3.1859092338061394

Epoch: 5| Step: 2
Training loss: 3.3564802605832584
Validation loss: 3.1871012696266066

Epoch: 5| Step: 3
Training loss: 3.2927222832771728
Validation loss: 3.1875129006157117

Epoch: 5| Step: 4
Training loss: 3.371424582504425
Validation loss: 3.188749539342667

Epoch: 5| Step: 5
Training loss: 3.075007530141155
Validation loss: 3.189470105756816

Epoch: 5| Step: 6
Training loss: 3.3472763433517416
Validation loss: 3.185570567415339

Epoch: 5| Step: 7
Training loss: 3.349549727284149
Validation loss: 3.18744684312166

Epoch: 5| Step: 8
Training loss: 3.725165595143748
Validation loss: 3.1862144346916317

Epoch: 5| Step: 9
Training loss: 3.8566447496464575
Validation loss: 3.1902690186723026

Epoch: 5| Step: 10
Training loss: 2.8690334271477753
Validation loss: 3.1935184546135087

Epoch: 167| Step: 0
Training loss: 3.925906354894047
Validation loss: 3.195936405902583

Epoch: 5| Step: 1
Training loss: 2.8409138044838382
Validation loss: 3.190157365520701

Epoch: 5| Step: 2
Training loss: 3.742638419425795
Validation loss: 3.1875005163473427

Epoch: 5| Step: 3
Training loss: 3.038504659649451
Validation loss: 3.1849301036118884

Epoch: 5| Step: 4
Training loss: 3.258503865676233
Validation loss: 3.1860190966184923

Epoch: 5| Step: 5
Training loss: 3.768700700883443
Validation loss: 3.185141626937108

Epoch: 5| Step: 6
Training loss: 3.9563826455874644
Validation loss: 3.1850795398898413

Epoch: 5| Step: 7
Training loss: 2.6187872253539894
Validation loss: 3.1853187057669947

Epoch: 5| Step: 8
Training loss: 3.252432719655586
Validation loss: 3.184042559283474

Epoch: 5| Step: 9
Training loss: 3.3983921793404086
Validation loss: 3.1833576500617875

Epoch: 5| Step: 10
Training loss: 3.6946353735542115
Validation loss: 3.184492615917292

Epoch: 168| Step: 0
Training loss: 3.3691932740451525
Validation loss: 3.18513903845829

Epoch: 5| Step: 1
Training loss: 3.8132577361992075
Validation loss: 3.1848936337079468

Epoch: 5| Step: 2
Training loss: 3.690341695042869
Validation loss: 3.1834214344620935

Epoch: 5| Step: 3
Training loss: 4.173226698304258
Validation loss: 3.182340844147652

Epoch: 5| Step: 4
Training loss: 2.789234829234926
Validation loss: 3.1836373113856262

Epoch: 5| Step: 5
Training loss: 3.17539174223824
Validation loss: 3.1842839043365485

Epoch: 5| Step: 6
Training loss: 3.4486763723214593
Validation loss: 3.187067166948127

Epoch: 5| Step: 7
Training loss: 3.795204580067513
Validation loss: 3.1859631196184326

Epoch: 5| Step: 8
Training loss: 3.4655590329715555
Validation loss: 3.1858905892927605

Epoch: 5| Step: 9
Training loss: 3.0634575728611315
Validation loss: 3.1851556301203114

Epoch: 5| Step: 10
Training loss: 2.463858381778012
Validation loss: 3.185483731921063

Epoch: 169| Step: 0
Training loss: 2.451026748069261
Validation loss: 3.182582898222962

Epoch: 5| Step: 1
Training loss: 3.2547546233289313
Validation loss: 3.1831994414512863

Epoch: 5| Step: 2
Training loss: 3.6869390028606968
Validation loss: 3.183431792340524

Epoch: 5| Step: 3
Training loss: 3.3629032502993637
Validation loss: 3.1806651441625333

Epoch: 5| Step: 4
Training loss: 3.640892837560871
Validation loss: 3.1831116360163194

Epoch: 5| Step: 5
Training loss: 3.9486104041986096
Validation loss: 3.181973957142084

Epoch: 5| Step: 6
Training loss: 3.644600330936936
Validation loss: 3.180255093547544

Epoch: 5| Step: 7
Training loss: 3.471464177778255
Validation loss: 3.1804030115927646

Epoch: 5| Step: 8
Training loss: 3.4097995287454816
Validation loss: 3.180204611211798

Epoch: 5| Step: 9
Training loss: 3.461235360789312
Validation loss: 3.1793676310540286

Epoch: 5| Step: 10
Training loss: 3.1027150354859634
Validation loss: 3.1785271147753518

Epoch: 170| Step: 0
Training loss: 3.2969664068341626
Validation loss: 3.180186552361001

Epoch: 5| Step: 1
Training loss: 2.8578268560734106
Validation loss: 3.17838020477363

Epoch: 5| Step: 2
Training loss: 2.8324622516860773
Validation loss: 3.178680096666905

Epoch: 5| Step: 3
Training loss: 2.895127208069331
Validation loss: 3.1802248061769447

Epoch: 5| Step: 4
Training loss: 3.6039981839411452
Validation loss: 3.1813068259989583

Epoch: 5| Step: 5
Training loss: 3.5419134315841116
Validation loss: 3.17918341811034

Epoch: 5| Step: 6
Training loss: 3.4699828560265487
Validation loss: 3.1809972584212973

Epoch: 5| Step: 7
Training loss: 3.942032158475137
Validation loss: 3.180900855607936

Epoch: 5| Step: 8
Training loss: 3.6049041140604317
Validation loss: 3.1772466533178054

Epoch: 5| Step: 9
Training loss: 4.015261147487114
Validation loss: 3.1797880884615854

Epoch: 5| Step: 10
Training loss: 3.3620347959770363
Validation loss: 3.178096792096069

Epoch: 171| Step: 0
Training loss: 3.1625554015844246
Validation loss: 3.1793926612577

Epoch: 5| Step: 1
Training loss: 3.6606317331396427
Validation loss: 3.177058855699117

Epoch: 5| Step: 2
Training loss: 3.4983006848003235
Validation loss: 3.176878427520901

Epoch: 5| Step: 3
Training loss: 3.9692609563201655
Validation loss: 3.1778773248488896

Epoch: 5| Step: 4
Training loss: 3.0549069689182216
Validation loss: 3.175915479462643

Epoch: 5| Step: 5
Training loss: 2.799764749317302
Validation loss: 3.179463888453158

Epoch: 5| Step: 6
Training loss: 3.411129457574216
Validation loss: 3.177488173269505

Epoch: 5| Step: 7
Training loss: 3.5247974689278885
Validation loss: 3.179952922755575

Epoch: 5| Step: 8
Training loss: 3.2546075291910976
Validation loss: 3.180107568472076

Epoch: 5| Step: 9
Training loss: 3.396692428665871
Validation loss: 3.1746949663396

Epoch: 5| Step: 10
Training loss: 3.8292519915140293
Validation loss: 3.1774922355733266

Epoch: 172| Step: 0
Training loss: 3.6015303273119
Validation loss: 3.1729637260524632

Epoch: 5| Step: 1
Training loss: 3.9011957047340937
Validation loss: 3.1735750099389977

Epoch: 5| Step: 2
Training loss: 2.835478774452578
Validation loss: 3.1730640283566354

Epoch: 5| Step: 3
Training loss: 3.4140887575863834
Validation loss: 3.173782556602672

Epoch: 5| Step: 4
Training loss: 3.266565506854453
Validation loss: 3.172448818875123

Epoch: 5| Step: 5
Training loss: 3.424064040556632
Validation loss: 3.171843821127183

Epoch: 5| Step: 6
Training loss: 2.8608948050729444
Validation loss: 3.173038461847303

Epoch: 5| Step: 7
Training loss: 3.451547944369348
Validation loss: 3.172208920282303

Epoch: 5| Step: 8
Training loss: 3.6667465432454347
Validation loss: 3.172552460239051

Epoch: 5| Step: 9
Training loss: 3.345110464966314
Validation loss: 3.172797099290249

Epoch: 5| Step: 10
Training loss: 3.776098983154257
Validation loss: 3.171663275719953

Epoch: 173| Step: 0
Training loss: 2.945989313451959
Validation loss: 3.1721292981076976

Epoch: 5| Step: 1
Training loss: 3.4801177287741187
Validation loss: 3.170695050390771

Epoch: 5| Step: 2
Training loss: 4.038927913467329
Validation loss: 3.170392849824095

Epoch: 5| Step: 3
Training loss: 3.2325915150916273
Validation loss: 3.1704842338010937

Epoch: 5| Step: 4
Training loss: 3.4667118717571883
Validation loss: 3.1713028104800847

Epoch: 5| Step: 5
Training loss: 3.0099340313751033
Validation loss: 3.1728358381167276

Epoch: 5| Step: 6
Training loss: 3.4169265989346806
Validation loss: 3.1703875695361043

Epoch: 5| Step: 7
Training loss: 3.6598345799403087
Validation loss: 3.1709197120424393

Epoch: 5| Step: 8
Training loss: 3.3416464775661523
Validation loss: 3.1702781143822016

Epoch: 5| Step: 9
Training loss: 3.2930982028046825
Validation loss: 3.1713878985596997

Epoch: 5| Step: 10
Training loss: 3.62311912937554
Validation loss: 3.1728812156904547

Epoch: 174| Step: 0
Training loss: 3.1610671947835156
Validation loss: 3.1699975567359884

Epoch: 5| Step: 1
Training loss: 3.6761073617459825
Validation loss: 3.1692653047289947

Epoch: 5| Step: 2
Training loss: 3.799207936106217
Validation loss: 3.171893231448472

Epoch: 5| Step: 3
Training loss: 3.831448851958718
Validation loss: 3.1697870293984485

Epoch: 5| Step: 4
Training loss: 3.207030952630163
Validation loss: 3.1711811628477653

Epoch: 5| Step: 5
Training loss: 3.04959657846441
Validation loss: 3.16860919469737

Epoch: 5| Step: 6
Training loss: 4.0102231990502935
Validation loss: 3.1688385403856687

Epoch: 5| Step: 7
Training loss: 3.1348100415467015
Validation loss: 3.169827749279142

Epoch: 5| Step: 8
Training loss: 3.279912185423841
Validation loss: 3.16916656154087

Epoch: 5| Step: 9
Training loss: 3.4530367602643355
Validation loss: 3.1683703542097237

Epoch: 5| Step: 10
Training loss: 2.631029379831054
Validation loss: 3.1681446459398463

Epoch: 175| Step: 0
Training loss: 3.8475469428477402
Validation loss: 3.1676751990788587

Epoch: 5| Step: 1
Training loss: 3.3427708698500216
Validation loss: 3.167588153844617

Epoch: 5| Step: 2
Training loss: 3.069419051382245
Validation loss: 3.1680177829682923

Epoch: 5| Step: 3
Training loss: 3.8188910775105445
Validation loss: 3.1669710646623455

Epoch: 5| Step: 4
Training loss: 3.4068919285640744
Validation loss: 3.1666906115193862

Epoch: 5| Step: 5
Training loss: 3.710878648793212
Validation loss: 3.1666926823849697

Epoch: 5| Step: 6
Training loss: 3.2857852655645905
Validation loss: 3.1680430371756696

Epoch: 5| Step: 7
Training loss: 2.797375767380822
Validation loss: 3.165688211885612

Epoch: 5| Step: 8
Training loss: 3.301518934533838
Validation loss: 3.1657514550308057

Epoch: 5| Step: 9
Training loss: 3.7672805629074992
Validation loss: 3.167187633848598

Epoch: 5| Step: 10
Training loss: 3.0096266786856063
Validation loss: 3.1661102810542525

Epoch: 176| Step: 0
Training loss: 2.984067891082384
Validation loss: 3.1668695299575083

Epoch: 5| Step: 1
Training loss: 3.5126585249237827
Validation loss: 3.165187896549946

Epoch: 5| Step: 2
Training loss: 3.2864909142734673
Validation loss: 3.1664803282268617

Epoch: 5| Step: 3
Training loss: 3.74036262630964
Validation loss: 3.168759399038968

Epoch: 5| Step: 4
Training loss: 3.5996741518266084
Validation loss: 3.1680671291522913

Epoch: 5| Step: 5
Training loss: 3.5743025306096103
Validation loss: 3.1675088525690427

Epoch: 5| Step: 6
Training loss: 3.289678447975829
Validation loss: 3.1678516154921574

Epoch: 5| Step: 7
Training loss: 3.224818314749991
Validation loss: 3.170836525942221

Epoch: 5| Step: 8
Training loss: 3.509149445293936
Validation loss: 3.1698728067848783

Epoch: 5| Step: 9
Training loss: 3.6953251457401226
Validation loss: 3.1658893731165105

Epoch: 5| Step: 10
Training loss: 2.9672330494257597
Validation loss: 3.1687054318286862

Epoch: 177| Step: 0
Training loss: 2.6901639111295608
Validation loss: 3.1700054441729866

Epoch: 5| Step: 1
Training loss: 3.6067585234540984
Validation loss: 3.173004544133926

Epoch: 5| Step: 2
Training loss: 3.1842284523557653
Validation loss: 3.1759096852815993

Epoch: 5| Step: 3
Training loss: 4.059056627388402
Validation loss: 3.1762796812108216

Epoch: 5| Step: 4
Training loss: 2.8924050288983194
Validation loss: 3.1687969631698554

Epoch: 5| Step: 5
Training loss: 3.578207356533791
Validation loss: 3.1649459887601803

Epoch: 5| Step: 6
Training loss: 3.269770277394293
Validation loss: 3.163745828933557

Epoch: 5| Step: 7
Training loss: 2.749448027268542
Validation loss: 3.1653786896654243

Epoch: 5| Step: 8
Training loss: 3.8203817724020537
Validation loss: 3.162112486608977

Epoch: 5| Step: 9
Training loss: 3.6932890112199384
Validation loss: 3.161306040457743

Epoch: 5| Step: 10
Training loss: 3.726010199671579
Validation loss: 3.160042734593147

Epoch: 178| Step: 0
Training loss: 2.74102167197076
Validation loss: 3.1605713838057623

Epoch: 5| Step: 1
Training loss: 3.7355011714320234
Validation loss: 3.1594818229926633

Epoch: 5| Step: 2
Training loss: 2.87172014319128
Validation loss: 3.1597452449459413

Epoch: 5| Step: 3
Training loss: 3.516797222106503
Validation loss: 3.160021698351386

Epoch: 5| Step: 4
Training loss: 3.4549877269212215
Validation loss: 3.161992443411954

Epoch: 5| Step: 5
Training loss: 3.994295821404158
Validation loss: 3.1622260995873086

Epoch: 5| Step: 6
Training loss: 2.986790663012834
Validation loss: 3.1611453146655935

Epoch: 5| Step: 7
Training loss: 3.4923330528426892
Validation loss: 3.160338614413479

Epoch: 5| Step: 8
Training loss: 3.2717596957375754
Validation loss: 3.1625905564939925

Epoch: 5| Step: 9
Training loss: 3.842135206489523
Validation loss: 3.159976898721336

Epoch: 5| Step: 10
Training loss: 3.3905880130561106
Validation loss: 3.1602298828333972

Epoch: 179| Step: 0
Training loss: 3.5050901456333636
Validation loss: 3.1584704514125628

Epoch: 5| Step: 1
Training loss: 3.522504661887274
Validation loss: 3.159880596959063

Epoch: 5| Step: 2
Training loss: 3.2874496746200053
Validation loss: 3.1588654843018844

Epoch: 5| Step: 3
Training loss: 3.09368249068152
Validation loss: 3.158280305944609

Epoch: 5| Step: 4
Training loss: 3.75669999814979
Validation loss: 3.159089123991717

Epoch: 5| Step: 5
Training loss: 3.307781529630715
Validation loss: 3.159575372512563

Epoch: 5| Step: 6
Training loss: 2.9313662182638685
Validation loss: 3.1585067288645567

Epoch: 5| Step: 7
Training loss: 3.73310440985128
Validation loss: 3.1594793157293997

Epoch: 5| Step: 8
Training loss: 3.4121068595261193
Validation loss: 3.1590245285512024

Epoch: 5| Step: 9
Training loss: 3.611412893221592
Validation loss: 3.1580752928032503

Epoch: 5| Step: 10
Training loss: 3.1999864041516446
Validation loss: 3.157025973154531

Epoch: 180| Step: 0
Training loss: 3.340232210824422
Validation loss: 3.15905630300554

Epoch: 5| Step: 1
Training loss: 2.932462390290998
Validation loss: 3.159277082572104

Epoch: 5| Step: 2
Training loss: 3.786310639926936
Validation loss: 3.160434106464511

Epoch: 5| Step: 3
Training loss: 2.9523810201343115
Validation loss: 3.160905868838112

Epoch: 5| Step: 4
Training loss: 2.949694866628306
Validation loss: 3.166094570154047

Epoch: 5| Step: 5
Training loss: 3.7784466400679553
Validation loss: 3.1633702792876615

Epoch: 5| Step: 6
Training loss: 2.9892239947245853
Validation loss: 3.176200574339622

Epoch: 5| Step: 7
Training loss: 3.6735220603669894
Validation loss: 3.1633979612995504

Epoch: 5| Step: 8
Training loss: 3.258212789922049
Validation loss: 3.1578686207807882

Epoch: 5| Step: 9
Training loss: 4.1303218843581915
Validation loss: 3.1558309914739437

Epoch: 5| Step: 10
Training loss: 3.463623520115765
Validation loss: 3.155759710168854

Epoch: 181| Step: 0
Training loss: 3.3873473467337707
Validation loss: 3.15689101604262

Epoch: 5| Step: 1
Training loss: 3.9270980524382577
Validation loss: 3.1560753532669907

Epoch: 5| Step: 2
Training loss: 3.2762635625378764
Validation loss: 3.1562395058084514

Epoch: 5| Step: 3
Training loss: 3.45573195701933
Validation loss: 3.156530742410162

Epoch: 5| Step: 4
Training loss: 3.4324395124269453
Validation loss: 3.1570031806511696

Epoch: 5| Step: 5
Training loss: 3.5857083781393992
Validation loss: 3.158582725508808

Epoch: 5| Step: 6
Training loss: 2.7519471471002763
Validation loss: 3.1576081721207605

Epoch: 5| Step: 7
Training loss: 4.008719001557388
Validation loss: 3.157910159221245

Epoch: 5| Step: 8
Training loss: 3.0219314333233176
Validation loss: 3.156657576503435

Epoch: 5| Step: 9
Training loss: 2.9594616596298957
Validation loss: 3.156112232529703

Epoch: 5| Step: 10
Training loss: 3.5257829865194177
Validation loss: 3.155946783403413

Epoch: 182| Step: 0
Training loss: 4.328593424984421
Validation loss: 3.157301446701519

Epoch: 5| Step: 1
Training loss: 3.137000578384419
Validation loss: 3.158215930988427

Epoch: 5| Step: 2
Training loss: 3.418098769848445
Validation loss: 3.155455614513273

Epoch: 5| Step: 3
Training loss: 3.657254203416908
Validation loss: 3.155344138308008

Epoch: 5| Step: 4
Training loss: 3.2516055909454
Validation loss: 3.15452514582377

Epoch: 5| Step: 5
Training loss: 2.815708618954644
Validation loss: 3.1572866168085483

Epoch: 5| Step: 6
Training loss: 3.5306558024689707
Validation loss: 3.1572648492836417

Epoch: 5| Step: 7
Training loss: 3.6423080548758873
Validation loss: 3.1568189750002733

Epoch: 5| Step: 8
Training loss: 3.311954237405237
Validation loss: 3.1592760357829555

Epoch: 5| Step: 9
Training loss: 3.150973602484586
Validation loss: 3.157704810290775

Epoch: 5| Step: 10
Training loss: 2.8649820686032172
Validation loss: 3.1582699646094508

Epoch: 183| Step: 0
Training loss: 2.9804085941668457
Validation loss: 3.1585804472269063

Epoch: 5| Step: 1
Training loss: 3.581630805042978
Validation loss: 3.1544477673485263

Epoch: 5| Step: 2
Training loss: 3.497101809975789
Validation loss: 3.1524784585778662

Epoch: 5| Step: 3
Training loss: 3.603525284751619
Validation loss: 3.1518906075768416

Epoch: 5| Step: 4
Training loss: 2.4178857249856445
Validation loss: 3.1503171389687092

Epoch: 5| Step: 5
Training loss: 3.8285335400624105
Validation loss: 3.1488718099546804

Epoch: 5| Step: 6
Training loss: 3.720411041890086
Validation loss: 3.1489933156086307

Epoch: 5| Step: 7
Training loss: 3.4831131502008446
Validation loss: 3.1508318143788876

Epoch: 5| Step: 8
Training loss: 3.6934710505409516
Validation loss: 3.1518746261146013

Epoch: 5| Step: 9
Training loss: 2.9824935015138365
Validation loss: 3.1491273192353098

Epoch: 5| Step: 10
Training loss: 3.390800366063676
Validation loss: 3.1493270717777864

Epoch: 184| Step: 0
Training loss: 3.374103144409455
Validation loss: 3.149132998250203

Epoch: 5| Step: 1
Training loss: 3.1358466545293084
Validation loss: 3.1504242621251044

Epoch: 5| Step: 2
Training loss: 2.891178222504145
Validation loss: 3.1480598163122546

Epoch: 5| Step: 3
Training loss: 3.5630566346161174
Validation loss: 3.1499057469848806

Epoch: 5| Step: 4
Training loss: 3.2578900737354455
Validation loss: 3.1503019571972146

Epoch: 5| Step: 5
Training loss: 3.560426610609483
Validation loss: 3.150935672098343

Epoch: 5| Step: 6
Training loss: 3.977384291236
Validation loss: 3.1518095920292195

Epoch: 5| Step: 7
Training loss: 3.4278535914542503
Validation loss: 3.149684393548787

Epoch: 5| Step: 8
Training loss: 3.0783891128859056
Validation loss: 3.1478980338691422

Epoch: 5| Step: 9
Training loss: 3.5557396976815467
Validation loss: 3.1471738973540577

Epoch: 5| Step: 10
Training loss: 3.4753199039006817
Validation loss: 3.1467260392406553

Epoch: 185| Step: 0
Training loss: 3.6959320903831054
Validation loss: 3.1455236612701123

Epoch: 5| Step: 1
Training loss: 3.5232964802537627
Validation loss: 3.1453787308049184

Epoch: 5| Step: 2
Training loss: 3.7956484473572223
Validation loss: 3.1452532106150413

Epoch: 5| Step: 3
Training loss: 2.96654597333361
Validation loss: 3.1442446647956834

Epoch: 5| Step: 4
Training loss: 3.2002827757825876
Validation loss: 3.1449149429967314

Epoch: 5| Step: 5
Training loss: 3.1929186968967245
Validation loss: 3.1447425249027354

Epoch: 5| Step: 6
Training loss: 3.169400908601782
Validation loss: 3.144322980861114

Epoch: 5| Step: 7
Training loss: 3.7339827199821105
Validation loss: 3.146019604459872

Epoch: 5| Step: 8
Training loss: 3.211495826610388
Validation loss: 3.1436281456767414

Epoch: 5| Step: 9
Training loss: 3.5448769474597897
Validation loss: 3.1438619500709946

Epoch: 5| Step: 10
Training loss: 3.2044508260286264
Validation loss: 3.1434960427058

Epoch: 186| Step: 0
Training loss: 2.636787198908991
Validation loss: 3.1429185985154837

Epoch: 5| Step: 1
Training loss: 3.5523683465324654
Validation loss: 3.14224938749795

Epoch: 5| Step: 2
Training loss: 3.788416479037137
Validation loss: 3.1421803093680967

Epoch: 5| Step: 3
Training loss: 2.7311501805551335
Validation loss: 3.14269193841154

Epoch: 5| Step: 4
Training loss: 3.9110136968830767
Validation loss: 3.141806399713944

Epoch: 5| Step: 5
Training loss: 3.0247657874367158
Validation loss: 3.144508781090416

Epoch: 5| Step: 6
Training loss: 3.487115987876347
Validation loss: 3.1443273346859595

Epoch: 5| Step: 7
Training loss: 3.5792868780895537
Validation loss: 3.1439143149465094

Epoch: 5| Step: 8
Training loss: 2.9450481103875976
Validation loss: 3.143729586186263

Epoch: 5| Step: 9
Training loss: 3.1063083881132902
Validation loss: 3.1455048800694176

Epoch: 5| Step: 10
Training loss: 4.341497042827045
Validation loss: 3.142238363556576

Epoch: 187| Step: 0
Training loss: 3.1601426698371684
Validation loss: 3.1455733065407125

Epoch: 5| Step: 1
Training loss: 3.2455069956124474
Validation loss: 3.141540354769206

Epoch: 5| Step: 2
Training loss: 3.7850756247863218
Validation loss: 3.1411091037491765

Epoch: 5| Step: 3
Training loss: 3.3132907715282607
Validation loss: 3.144316422391484

Epoch: 5| Step: 4
Training loss: 3.8620491184408197
Validation loss: 3.1448211350829784

Epoch: 5| Step: 5
Training loss: 2.9890022554921907
Validation loss: 3.143324864763592

Epoch: 5| Step: 6
Training loss: 3.5739085578769245
Validation loss: 3.1430060194648104

Epoch: 5| Step: 7
Training loss: 2.932821728423064
Validation loss: 3.13957451222512

Epoch: 5| Step: 8
Training loss: 3.579203747049143
Validation loss: 3.1408287100226713

Epoch: 5| Step: 9
Training loss: 3.7721935930946304
Validation loss: 3.138769319985266

Epoch: 5| Step: 10
Training loss: 2.8545048831183637
Validation loss: 3.1405479859645844

Epoch: 188| Step: 0
Training loss: 3.731485054625119
Validation loss: 3.137799645874194

Epoch: 5| Step: 1
Training loss: 2.8487083051039748
Validation loss: 3.141440302703599

Epoch: 5| Step: 2
Training loss: 3.2521710113755464
Validation loss: 3.139254430175071

Epoch: 5| Step: 3
Training loss: 3.2487545561455793
Validation loss: 3.1386542387875114

Epoch: 5| Step: 4
Training loss: 3.738811841916869
Validation loss: 3.138967412204249

Epoch: 5| Step: 5
Training loss: 3.3603551100224665
Validation loss: 3.1368834161248844

Epoch: 5| Step: 6
Training loss: 2.6213726230767183
Validation loss: 3.1383599578498496

Epoch: 5| Step: 7
Training loss: 3.391283806288905
Validation loss: 3.137842106859928

Epoch: 5| Step: 8
Training loss: 4.148042534311224
Validation loss: 3.1356464675571063

Epoch: 5| Step: 9
Training loss: 3.207337823634578
Validation loss: 3.1393590971748218

Epoch: 5| Step: 10
Training loss: 3.5279813509164915
Validation loss: 3.1358400946824023

Epoch: 189| Step: 0
Training loss: 3.3492630048230123
Validation loss: 3.136404848544727

Epoch: 5| Step: 1
Training loss: 3.2886875690956145
Validation loss: 3.135598697651416

Epoch: 5| Step: 2
Training loss: 2.6373931248421423
Validation loss: 3.1398522321095275

Epoch: 5| Step: 3
Training loss: 3.3527784298194967
Validation loss: 3.137543464140279

Epoch: 5| Step: 4
Training loss: 3.0056023738816173
Validation loss: 3.1368542472616547

Epoch: 5| Step: 5
Training loss: 3.3334398411583166
Validation loss: 3.136672429990548

Epoch: 5| Step: 6
Training loss: 3.133142468205718
Validation loss: 3.1363829213805343

Epoch: 5| Step: 7
Training loss: 3.8248344136218466
Validation loss: 3.139052221973465

Epoch: 5| Step: 8
Training loss: 4.363203657616375
Validation loss: 3.1376776405676

Epoch: 5| Step: 9
Training loss: 3.452325788849592
Validation loss: 3.1378451003740975

Epoch: 5| Step: 10
Training loss: 3.2617341001229367
Validation loss: 3.1370517641440516

Epoch: 190| Step: 0
Training loss: 3.2469385840291207
Validation loss: 3.1370769652686468

Epoch: 5| Step: 1
Training loss: 3.7335814586564
Validation loss: 3.1361868092413627

Epoch: 5| Step: 2
Training loss: 3.7046723171198135
Validation loss: 3.13353264532996

Epoch: 5| Step: 3
Training loss: 2.8275989022062187
Validation loss: 3.1328602501983673

Epoch: 5| Step: 4
Training loss: 3.4993157399101626
Validation loss: 3.1335894321159685

Epoch: 5| Step: 5
Training loss: 3.327485788774989
Validation loss: 3.1337130454166293

Epoch: 5| Step: 6
Training loss: 4.667085674185288
Validation loss: 3.1356564510059064

Epoch: 5| Step: 7
Training loss: 3.5513628157111627
Validation loss: 3.132235842030385

Epoch: 5| Step: 8
Training loss: 2.929884596234708
Validation loss: 3.1330473258980867

Epoch: 5| Step: 9
Training loss: 1.8801081693251154
Validation loss: 3.133690503847855

Epoch: 5| Step: 10
Training loss: 3.1694851596218254
Validation loss: 3.131662645422575

Epoch: 191| Step: 0
Training loss: 2.696622933534925
Validation loss: 3.1336612488155087

Epoch: 5| Step: 1
Training loss: 3.072656256207491
Validation loss: 3.131588963873938

Epoch: 5| Step: 2
Training loss: 3.273612006368089
Validation loss: 3.1348643191320527

Epoch: 5| Step: 3
Training loss: 3.472436818591009
Validation loss: 3.132172999284013

Epoch: 5| Step: 4
Training loss: 3.356411926796064
Validation loss: 3.1321048636523017

Epoch: 5| Step: 5
Training loss: 3.4928130884537785
Validation loss: 3.1350264822439042

Epoch: 5| Step: 6
Training loss: 2.6905097963345836
Validation loss: 3.134444912836088

Epoch: 5| Step: 7
Training loss: 3.7844781888317396
Validation loss: 3.1339779731893174

Epoch: 5| Step: 8
Training loss: 3.0443627588616877
Validation loss: 3.1370055773561694

Epoch: 5| Step: 9
Training loss: 4.241228364034254
Validation loss: 3.1367907410556284

Epoch: 5| Step: 10
Training loss: 3.8586156924408375
Validation loss: 3.1342376044498677

Epoch: 192| Step: 0
Training loss: 2.597098154333445
Validation loss: 3.13624146026792

Epoch: 5| Step: 1
Training loss: 4.0192591034722716
Validation loss: 3.1313375383048023

Epoch: 5| Step: 2
Training loss: 3.2993498999913973
Validation loss: 3.13434293300303

Epoch: 5| Step: 3
Training loss: 4.0351463236506655
Validation loss: 3.1301876808151183

Epoch: 5| Step: 4
Training loss: 3.220136621550427
Validation loss: 3.130530297890461

Epoch: 5| Step: 5
Training loss: 3.529484940686559
Validation loss: 3.133843602365467

Epoch: 5| Step: 6
Training loss: 3.202546602456514
Validation loss: 3.130492573489212

Epoch: 5| Step: 7
Training loss: 3.1969527159610633
Validation loss: 3.129735039491901

Epoch: 5| Step: 8
Training loss: 2.687631736897734
Validation loss: 3.1278679401195078

Epoch: 5| Step: 9
Training loss: 3.6897940531171853
Validation loss: 3.1281619492837844

Epoch: 5| Step: 10
Training loss: 3.4352155550604104
Validation loss: 3.129514828316659

Epoch: 193| Step: 0
Training loss: 3.6522581039423403
Validation loss: 3.1278686351510943

Epoch: 5| Step: 1
Training loss: 3.2055260567838495
Validation loss: 3.128621230950386

Epoch: 5| Step: 2
Training loss: 3.8808915665342014
Validation loss: 3.1270954563698123

Epoch: 5| Step: 3
Training loss: 3.5116224774327933
Validation loss: 3.1271684108805253

Epoch: 5| Step: 4
Training loss: 2.6297627792417795
Validation loss: 3.1295825730738724

Epoch: 5| Step: 5
Training loss: 3.5813084729066267
Validation loss: 3.128345542857359

Epoch: 5| Step: 6
Training loss: 3.8538039303104625
Validation loss: 3.1304475715639617

Epoch: 5| Step: 7
Training loss: 2.805417616656247
Validation loss: 3.13060642828842

Epoch: 5| Step: 8
Training loss: 3.3807019704475993
Validation loss: 3.134544228012865

Epoch: 5| Step: 9
Training loss: 3.2241481217749626
Validation loss: 3.130590094549037

Epoch: 5| Step: 10
Training loss: 3.2488486377967005
Validation loss: 3.1286228271713137

Epoch: 194| Step: 0
Training loss: 3.908495082368523
Validation loss: 3.1268091982042496

Epoch: 5| Step: 1
Training loss: 3.009441776663723
Validation loss: 3.126192050120275

Epoch: 5| Step: 2
Training loss: 3.6688426381361414
Validation loss: 3.1259665768402836

Epoch: 5| Step: 3
Training loss: 3.2034032189099086
Validation loss: 3.1273503609831907

Epoch: 5| Step: 4
Training loss: 3.1670671678219278
Validation loss: 3.1256232405162097

Epoch: 5| Step: 5
Training loss: 2.8884113805593423
Validation loss: 3.126355462569439

Epoch: 5| Step: 6
Training loss: 3.638790863761658
Validation loss: 3.1266967597018938

Epoch: 5| Step: 7
Training loss: 3.3937307452082406
Validation loss: 3.1275273577010143

Epoch: 5| Step: 8
Training loss: 2.951390640158539
Validation loss: 3.1264139106478215

Epoch: 5| Step: 9
Training loss: 3.8884114169115347
Validation loss: 3.1265060684147494

Epoch: 5| Step: 10
Training loss: 3.3257860731645934
Validation loss: 3.126782397514179

Epoch: 195| Step: 0
Training loss: 4.029651886929439
Validation loss: 3.1252041542882902

Epoch: 5| Step: 1
Training loss: 2.978782486764448
Validation loss: 3.124686893651504

Epoch: 5| Step: 2
Training loss: 4.0813952666947175
Validation loss: 3.123865017436515

Epoch: 5| Step: 3
Training loss: 3.5090908788141078
Validation loss: 3.123760678233434

Epoch: 5| Step: 4
Training loss: 2.3786291202174903
Validation loss: 3.1227451926700427

Epoch: 5| Step: 5
Training loss: 3.7030772274493025
Validation loss: 3.12239135806456

Epoch: 5| Step: 6
Training loss: 2.9492779252134524
Validation loss: 3.1225469810031745

Epoch: 5| Step: 7
Training loss: 3.040211124617989
Validation loss: 3.1217234040019677

Epoch: 5| Step: 8
Training loss: 3.243448255906839
Validation loss: 3.1232042826084547

Epoch: 5| Step: 9
Training loss: 3.5285300523219525
Validation loss: 3.123741595480217

Epoch: 5| Step: 10
Training loss: 3.367731108009803
Validation loss: 3.123434697740234

Epoch: 196| Step: 0
Training loss: 3.5533517193154562
Validation loss: 3.1245502911282372

Epoch: 5| Step: 1
Training loss: 3.507096045378397
Validation loss: 3.125606894679272

Epoch: 5| Step: 2
Training loss: 3.5767923730361497
Validation loss: 3.13325832949611

Epoch: 5| Step: 3
Training loss: 3.266030610370328
Validation loss: 3.134908046534078

Epoch: 5| Step: 4
Training loss: 2.709321873549883
Validation loss: 3.135574576139741

Epoch: 5| Step: 5
Training loss: 3.3546471261525284
Validation loss: 3.138876817642345

Epoch: 5| Step: 6
Training loss: 3.127474301215078
Validation loss: 3.129626285804448

Epoch: 5| Step: 7
Training loss: 2.696801523421046
Validation loss: 3.1331594972251304

Epoch: 5| Step: 8
Training loss: 4.022593111486193
Validation loss: 3.1289881182837593

Epoch: 5| Step: 9
Training loss: 3.7554182963020506
Validation loss: 3.121519351398071

Epoch: 5| Step: 10
Training loss: 3.3685147176757657
Validation loss: 3.121687950650078

Epoch: 197| Step: 0
Training loss: 3.3425487606626216
Validation loss: 3.119345724918379

Epoch: 5| Step: 1
Training loss: 3.2328073139250484
Validation loss: 3.1206337087921323

Epoch: 5| Step: 2
Training loss: 2.9965455511594246
Validation loss: 3.1198982744958412

Epoch: 5| Step: 3
Training loss: 3.5506305725558884
Validation loss: 3.1201546889705134

Epoch: 5| Step: 4
Training loss: 3.3195067381677674
Validation loss: 3.1196928361812626

Epoch: 5| Step: 5
Training loss: 3.981288297699554
Validation loss: 3.1194850668188923

Epoch: 5| Step: 6
Training loss: 2.6092191181334514
Validation loss: 3.11966873384996

Epoch: 5| Step: 7
Training loss: 3.41421026612788
Validation loss: 3.1192494566164743

Epoch: 5| Step: 8
Training loss: 3.3217318025803837
Validation loss: 3.119256698991722

Epoch: 5| Step: 9
Training loss: 4.015510527764058
Validation loss: 3.1191633752772505

Epoch: 5| Step: 10
Training loss: 3.103664502653555
Validation loss: 3.1169759151334344

Epoch: 198| Step: 0
Training loss: 3.3374271684907924
Validation loss: 3.117938950944709

Epoch: 5| Step: 1
Training loss: 2.966047803929551
Validation loss: 3.119402169205545

Epoch: 5| Step: 2
Training loss: 3.884280382079657
Validation loss: 3.1178744477175093

Epoch: 5| Step: 3
Training loss: 3.2766880839033696
Validation loss: 3.1171538019375067

Epoch: 5| Step: 4
Training loss: 3.450583510879248
Validation loss: 3.1163814494672617

Epoch: 5| Step: 5
Training loss: 3.1187486300723446
Validation loss: 3.116245108098768

Epoch: 5| Step: 6
Training loss: 3.7063575510305995
Validation loss: 3.118207786491955

Epoch: 5| Step: 7
Training loss: 3.411251211309445
Validation loss: 3.117694217398899

Epoch: 5| Step: 8
Training loss: 3.311559147643642
Validation loss: 3.120107485455535

Epoch: 5| Step: 9
Training loss: 3.4783589382962603
Validation loss: 3.11783732912276

Epoch: 5| Step: 10
Training loss: 3.0319079442103
Validation loss: 3.1214084947313827

Epoch: 199| Step: 0
Training loss: 2.920432974186168
Validation loss: 3.125488869769878

Epoch: 5| Step: 1
Training loss: 3.3405873681028346
Validation loss: 3.1245757424096117

Epoch: 5| Step: 2
Training loss: 2.8573649694756567
Validation loss: 3.129684228826629

Epoch: 5| Step: 3
Training loss: 3.9982665597466216
Validation loss: 3.126395831367925

Epoch: 5| Step: 4
Training loss: 2.933276284992452
Validation loss: 3.1254574397824793

Epoch: 5| Step: 5
Training loss: 3.421589599970312
Validation loss: 3.1295228693918835

Epoch: 5| Step: 6
Training loss: 3.7665491513400498
Validation loss: 3.119256547766627

Epoch: 5| Step: 7
Training loss: 2.9445420934771485
Validation loss: 3.1174177249831216

Epoch: 5| Step: 8
Training loss: 4.308724782685672
Validation loss: 3.113019021892213

Epoch: 5| Step: 9
Training loss: 2.873177157831665
Validation loss: 3.115221777459824

Epoch: 5| Step: 10
Training loss: 3.367630719180267
Validation loss: 3.1131967757563377

Epoch: 200| Step: 0
Training loss: 3.52381384080944
Validation loss: 3.112364297270725

Epoch: 5| Step: 1
Training loss: 3.8623862931881394
Validation loss: 3.1135539146234614

Epoch: 5| Step: 2
Training loss: 3.0109225753311346
Validation loss: 3.1146146206353142

Epoch: 5| Step: 3
Training loss: 3.9255784015534787
Validation loss: 3.114811375755491

Epoch: 5| Step: 4
Training loss: 3.1934883861554537
Validation loss: 3.113209331258853

Epoch: 5| Step: 5
Training loss: 3.0413782862689063
Validation loss: 3.1124935175941895

Epoch: 5| Step: 6
Training loss: 2.8688284935944113
Validation loss: 3.115897127329372

Epoch: 5| Step: 7
Training loss: 3.433187380407492
Validation loss: 3.114321862977303

Epoch: 5| Step: 8
Training loss: 3.022948232880735
Validation loss: 3.1130449479138145

Epoch: 5| Step: 9
Training loss: 3.677974877417405
Validation loss: 3.1124217264423324

Epoch: 5| Step: 10
Training loss: 3.3646601775441694
Validation loss: 3.112411687409964

Epoch: 201| Step: 0
Training loss: 2.730857286655706
Validation loss: 3.1124571873270077

Epoch: 5| Step: 1
Training loss: 3.842609515444367
Validation loss: 3.111937536056504

Epoch: 5| Step: 2
Training loss: 3.0921887398245524
Validation loss: 3.1118760233144704

Epoch: 5| Step: 3
Training loss: 3.661637339369632
Validation loss: 3.1125551087337766

Epoch: 5| Step: 4
Training loss: 3.5657119994453117
Validation loss: 3.1114627645316064

Epoch: 5| Step: 5
Training loss: 3.6510383435432376
Validation loss: 3.109772643004982

Epoch: 5| Step: 6
Training loss: 3.6621200520677686
Validation loss: 3.1107558351790776

Epoch: 5| Step: 7
Training loss: 3.098715448344615
Validation loss: 3.110229064885456

Epoch: 5| Step: 8
Training loss: 3.19473731499803
Validation loss: 3.1102148974544783

Epoch: 5| Step: 9
Training loss: 2.6727217732292123
Validation loss: 3.111065430667163

Epoch: 5| Step: 10
Training loss: 3.685508836995679
Validation loss: 3.1130545945589407

Epoch: 202| Step: 0
Training loss: 3.108078115858703
Validation loss: 3.1140260235181176

Epoch: 5| Step: 1
Training loss: 3.4534222919342232
Validation loss: 3.112012508318586

Epoch: 5| Step: 2
Training loss: 3.293065188478857
Validation loss: 3.112443642028406

Epoch: 5| Step: 3
Training loss: 3.9427916074128064
Validation loss: 3.1123717253483707

Epoch: 5| Step: 4
Training loss: 3.65134694577667
Validation loss: 3.113270383695883

Epoch: 5| Step: 5
Training loss: 3.498509362093066
Validation loss: 3.112484147608484

Epoch: 5| Step: 6
Training loss: 3.712835657634939
Validation loss: 3.1125195064724966

Epoch: 5| Step: 7
Training loss: 3.3060786067619983
Validation loss: 3.114486782283891

Epoch: 5| Step: 8
Training loss: 2.4346253487937846
Validation loss: 3.111968544054465

Epoch: 5| Step: 9
Training loss: 3.5177172051384615
Validation loss: 3.1118031551579644

Epoch: 5| Step: 10
Training loss: 2.786028325541396
Validation loss: 3.1114797317626675

Epoch: 203| Step: 0
Training loss: 3.8426498451376525
Validation loss: 3.111923422537047

Epoch: 5| Step: 1
Training loss: 3.043818892496297
Validation loss: 3.1136733453703846

Epoch: 5| Step: 2
Training loss: 3.53445977363139
Validation loss: 3.110167552148734

Epoch: 5| Step: 3
Training loss: 2.950843373665529
Validation loss: 3.1093147706091373

Epoch: 5| Step: 4
Training loss: 3.4039060594840147
Validation loss: 3.105453528941383

Epoch: 5| Step: 5
Training loss: 4.157551497130727
Validation loss: 3.1064545958922753

Epoch: 5| Step: 6
Training loss: 3.355569360576917
Validation loss: 3.10697724103884

Epoch: 5| Step: 7
Training loss: 3.0372004357329474
Validation loss: 3.106934390418046

Epoch: 5| Step: 8
Training loss: 3.456462921151183
Validation loss: 3.1051160576369408

Epoch: 5| Step: 9
Training loss: 2.429340300943968
Validation loss: 3.1070150314756337

Epoch: 5| Step: 10
Training loss: 3.4850790227745065
Validation loss: 3.108246888291446

Epoch: 204| Step: 0
Training loss: 3.0976068365285636
Validation loss: 3.104773329520671

Epoch: 5| Step: 1
Training loss: 3.9571469319220776
Validation loss: 3.1063963012746942

Epoch: 5| Step: 2
Training loss: 3.6312861691904303
Validation loss: 3.1096425692904406

Epoch: 5| Step: 3
Training loss: 3.707444130803892
Validation loss: 3.1053498044965036

Epoch: 5| Step: 4
Training loss: 3.0522929218357264
Validation loss: 3.107858587458947

Epoch: 5| Step: 5
Training loss: 3.0898360337885635
Validation loss: 3.106544692624428

Epoch: 5| Step: 6
Training loss: 3.7734670697113932
Validation loss: 3.1077036049616584

Epoch: 5| Step: 7
Training loss: 3.669520495737847
Validation loss: 3.105971039405455

Epoch: 5| Step: 8
Training loss: 3.4950540200616946
Validation loss: 3.107258300122479

Epoch: 5| Step: 9
Training loss: 2.1947822337648675
Validation loss: 3.1036002495816875

Epoch: 5| Step: 10
Training loss: 2.8638707239820795
Validation loss: 3.1061926902577586

Epoch: 205| Step: 0
Training loss: 3.4096145112185785
Validation loss: 3.1072849565192158

Epoch: 5| Step: 1
Training loss: 3.205486636538416
Validation loss: 3.1093943358193354

Epoch: 5| Step: 2
Training loss: 2.750827058054798
Validation loss: 3.1090619741826817

Epoch: 5| Step: 3
Training loss: 3.2140981891970575
Validation loss: 3.1045251674946908

Epoch: 5| Step: 4
Training loss: 4.137780475617852
Validation loss: 3.1034826772318813

Epoch: 5| Step: 5
Training loss: 3.308295983040418
Validation loss: 3.1036263641425803

Epoch: 5| Step: 6
Training loss: 2.9354419397620295
Validation loss: 3.103391651483994

Epoch: 5| Step: 7
Training loss: 3.614346997599314
Validation loss: 3.109123705861243

Epoch: 5| Step: 8
Training loss: 3.3134063344495512
Validation loss: 3.1051792250504353

Epoch: 5| Step: 9
Training loss: 3.1998075844612415
Validation loss: 3.1077697505145263

Epoch: 5| Step: 10
Training loss: 3.745214333200615
Validation loss: 3.107797058324806

Epoch: 206| Step: 0
Training loss: 3.468088310296486
Validation loss: 3.107290242558897

Epoch: 5| Step: 1
Training loss: 2.7653047192998956
Validation loss: 3.103021735262464

Epoch: 5| Step: 2
Training loss: 3.8459410586549487
Validation loss: 3.104487903328551

Epoch: 5| Step: 3
Training loss: 3.383966755570689
Validation loss: 3.103615419430064

Epoch: 5| Step: 4
Training loss: 3.7670690529744646
Validation loss: 3.102333296049044

Epoch: 5| Step: 5
Training loss: 3.4133420135963854
Validation loss: 3.1045972263006174

Epoch: 5| Step: 6
Training loss: 2.8027466245376913
Validation loss: 3.102925021647428

Epoch: 5| Step: 7
Training loss: 3.122951904532387
Validation loss: 3.1035494942735835

Epoch: 5| Step: 8
Training loss: 3.2625816071925784
Validation loss: 3.1013436742774596

Epoch: 5| Step: 9
Training loss: 3.2168045831343592
Validation loss: 3.1032008399920135

Epoch: 5| Step: 10
Training loss: 3.770585840579254
Validation loss: 3.100643604670211

Epoch: 207| Step: 0
Training loss: 3.670837645396465
Validation loss: 3.101839358558801

Epoch: 5| Step: 1
Training loss: 3.633958598823248
Validation loss: 3.107945026451837

Epoch: 5| Step: 2
Training loss: 3.482167592502255
Validation loss: 3.104253975950136

Epoch: 5| Step: 3
Training loss: 2.6635326406728503
Validation loss: 3.0987755114609135

Epoch: 5| Step: 4
Training loss: 3.4533335074740137
Validation loss: 3.102360300513011

Epoch: 5| Step: 5
Training loss: 3.593867159053237
Validation loss: 3.1000566187599397

Epoch: 5| Step: 6
Training loss: 2.8791473991606873
Validation loss: 3.101364377796896

Epoch: 5| Step: 7
Training loss: 4.149844633204516
Validation loss: 3.101079684435091

Epoch: 5| Step: 8
Training loss: 3.4357515917101695
Validation loss: 3.102671936784856

Epoch: 5| Step: 9
Training loss: 3.110354168709662
Validation loss: 3.1017174190655847

Epoch: 5| Step: 10
Training loss: 2.324292914225086
Validation loss: 3.0979914687961854

Epoch: 208| Step: 0
Training loss: 2.995297879545043
Validation loss: 3.0997598512049827

Epoch: 5| Step: 1
Training loss: 3.771563773601057
Validation loss: 3.098331972505477

Epoch: 5| Step: 2
Training loss: 3.6305940807127213
Validation loss: 3.0985091011597197

Epoch: 5| Step: 3
Training loss: 3.258745311503957
Validation loss: 3.096899230192705

Epoch: 5| Step: 4
Training loss: 3.4398168905449773
Validation loss: 3.0987271334420914

Epoch: 5| Step: 5
Training loss: 3.4354168215062044
Validation loss: 3.098180636719173

Epoch: 5| Step: 6
Training loss: 3.427440280741848
Validation loss: 3.0969325758098654

Epoch: 5| Step: 7
Training loss: 3.309097990234222
Validation loss: 3.0981800210840484

Epoch: 5| Step: 8
Training loss: 2.7378050298886056
Validation loss: 3.095995288272202

Epoch: 5| Step: 9
Training loss: 3.0063488854781677
Validation loss: 3.0952581709357534

Epoch: 5| Step: 10
Training loss: 3.7947860434308387
Validation loss: 3.09506817003837

Epoch: 209| Step: 0
Training loss: 3.6847074894123875
Validation loss: 3.0962682455912156

Epoch: 5| Step: 1
Training loss: 3.821802390930204
Validation loss: 3.095004818628109

Epoch: 5| Step: 2
Training loss: 3.2553184714440615
Validation loss: 3.096324886190235

Epoch: 5| Step: 3
Training loss: 2.9552136659265935
Validation loss: 3.093693220276909

Epoch: 5| Step: 4
Training loss: 3.807782365494219
Validation loss: 3.0948656742249785

Epoch: 5| Step: 5
Training loss: 3.0424280824836205
Validation loss: 3.0939826144525764

Epoch: 5| Step: 6
Training loss: 3.0747577044542997
Validation loss: 3.0971228505448605

Epoch: 5| Step: 7
Training loss: 3.2452677973908757
Validation loss: 3.099071713148046

Epoch: 5| Step: 8
Training loss: 2.8578667336767216
Validation loss: 3.0977747361652415

Epoch: 5| Step: 9
Training loss: 3.7944723934064575
Validation loss: 3.097065130234883

Epoch: 5| Step: 10
Training loss: 3.1296478802234304
Validation loss: 3.0997995557231754

Epoch: 210| Step: 0
Training loss: 3.791424013414948
Validation loss: 3.096829016304472

Epoch: 5| Step: 1
Training loss: 3.3018597708673467
Validation loss: 3.095562000369783

Epoch: 5| Step: 2
Training loss: 3.305612853877731
Validation loss: 3.0953791855062947

Epoch: 5| Step: 3
Training loss: 3.430187562535373
Validation loss: 3.092632021680034

Epoch: 5| Step: 4
Training loss: 3.1404297421617478
Validation loss: 3.0963873304860345

Epoch: 5| Step: 5
Training loss: 3.851040137348004
Validation loss: 3.0938673837185666

Epoch: 5| Step: 6
Training loss: 2.743709826338241
Validation loss: 3.0944164838903725

Epoch: 5| Step: 7
Training loss: 3.276052809526004
Validation loss: 3.0953888772674505

Epoch: 5| Step: 8
Training loss: 3.5548980985863725
Validation loss: 3.093395618482446

Epoch: 5| Step: 9
Training loss: 3.589636131484293
Validation loss: 3.0942201494344226

Epoch: 5| Step: 10
Training loss: 2.5344000160120954
Validation loss: 3.0928490798752586

Epoch: 211| Step: 0
Training loss: 3.389587243532545
Validation loss: 3.0931229182169315

Epoch: 5| Step: 1
Training loss: 3.1999473627052795
Validation loss: 3.092956011841656

Epoch: 5| Step: 2
Training loss: 3.3125308053365647
Validation loss: 3.0914119347407047

Epoch: 5| Step: 3
Training loss: 4.427389312342758
Validation loss: 3.092096875855989

Epoch: 5| Step: 4
Training loss: 3.827812836044637
Validation loss: 3.090815027323107

Epoch: 5| Step: 5
Training loss: 3.9733949647727624
Validation loss: 3.0914265880524034

Epoch: 5| Step: 6
Training loss: 2.505771269702583
Validation loss: 3.088942160326168

Epoch: 5| Step: 7
Training loss: 2.5942306073285475
Validation loss: 3.0900805470110617

Epoch: 5| Step: 8
Training loss: 2.923127747298494
Validation loss: 3.0900215543834197

Epoch: 5| Step: 9
Training loss: 3.1811972743013692
Validation loss: 3.0930535891740303

Epoch: 5| Step: 10
Training loss: 2.9452545403158243
Validation loss: 3.0912305015827206

Epoch: 212| Step: 0
Training loss: 3.569090252103627
Validation loss: 3.094049973879822

Epoch: 5| Step: 1
Training loss: 3.27731334140206
Validation loss: 3.089498798270798

Epoch: 5| Step: 2
Training loss: 3.534255377703923
Validation loss: 3.0911415624562677

Epoch: 5| Step: 3
Training loss: 3.663141781557464
Validation loss: 3.0859729179654116

Epoch: 5| Step: 4
Training loss: 3.0609659517844032
Validation loss: 3.0890384104375617

Epoch: 5| Step: 5
Training loss: 3.720987240013628
Validation loss: 3.08830105876495

Epoch: 5| Step: 6
Training loss: 3.41412465193892
Validation loss: 3.0881781281192984

Epoch: 5| Step: 7
Training loss: 3.2127294436203733
Validation loss: 3.088631628823871

Epoch: 5| Step: 8
Training loss: 3.036651517939826
Validation loss: 3.08720888941964

Epoch: 5| Step: 9
Training loss: 2.8616800658131343
Validation loss: 3.087914419125653

Epoch: 5| Step: 10
Training loss: 3.3808978787614645
Validation loss: 3.0898017022219744

Epoch: 213| Step: 0
Training loss: 2.9982654007288962
Validation loss: 3.0872072651426374

Epoch: 5| Step: 1
Training loss: 3.1932222949362497
Validation loss: 3.088439090286156

Epoch: 5| Step: 2
Training loss: 2.7480311715247394
Validation loss: 3.092147824953883

Epoch: 5| Step: 3
Training loss: 3.512024795044981
Validation loss: 3.089958802234734

Epoch: 5| Step: 4
Training loss: 2.6077751691830744
Validation loss: 3.08705994896545

Epoch: 5| Step: 5
Training loss: 3.451610112066926
Validation loss: 3.0858658187887986

Epoch: 5| Step: 6
Training loss: 3.7537635990471934
Validation loss: 3.0875544971965394

Epoch: 5| Step: 7
Training loss: 3.642937576517249
Validation loss: 3.0856066047543043

Epoch: 5| Step: 8
Training loss: 3.9082256966567708
Validation loss: 3.0872953286215217

Epoch: 5| Step: 9
Training loss: 2.8200814530262917
Validation loss: 3.0862335200172466

Epoch: 5| Step: 10
Training loss: 3.929464830646235
Validation loss: 3.0853647348759714

Epoch: 214| Step: 0
Training loss: 3.0568270397928137
Validation loss: 3.0829059556290637

Epoch: 5| Step: 1
Training loss: 3.552848860210428
Validation loss: 3.0856445555600347

Epoch: 5| Step: 2
Training loss: 3.950532568266842
Validation loss: 3.0870557734735433

Epoch: 5| Step: 3
Training loss: 3.454225942902986
Validation loss: 3.0871614927317657

Epoch: 5| Step: 4
Training loss: 2.741483766509463
Validation loss: 3.084259162485796

Epoch: 5| Step: 5
Training loss: 3.437877426234819
Validation loss: 3.0858203222380816

Epoch: 5| Step: 6
Training loss: 3.293889868298201
Validation loss: 3.0852101098140974

Epoch: 5| Step: 7
Training loss: 3.92443132107668
Validation loss: 3.0863277663610282

Epoch: 5| Step: 8
Training loss: 2.138927259830371
Validation loss: 3.0842867133654406

Epoch: 5| Step: 9
Training loss: 2.9726787070028875
Validation loss: 3.083632289779558

Epoch: 5| Step: 10
Training loss: 3.8948738154096683
Validation loss: 3.083483876613736

Epoch: 215| Step: 0
Training loss: 3.309547980293125
Validation loss: 3.0879760339340274

Epoch: 5| Step: 1
Training loss: 3.3311687753018306
Validation loss: 3.0876691382235606

Epoch: 5| Step: 2
Training loss: 3.35563884832431
Validation loss: 3.0898825050027763

Epoch: 5| Step: 3
Training loss: 3.596936877768211
Validation loss: 3.085727338175414

Epoch: 5| Step: 4
Training loss: 3.5943259399653114
Validation loss: 3.0900090730829066

Epoch: 5| Step: 5
Training loss: 3.138621284157847
Validation loss: 3.0884308326743364

Epoch: 5| Step: 6
Training loss: 3.5530402422536294
Validation loss: 3.0859936888836272

Epoch: 5| Step: 7
Training loss: 2.6967993132224577
Validation loss: 3.0847879948275176

Epoch: 5| Step: 8
Training loss: 3.398156586360435
Validation loss: 3.090152404228016

Epoch: 5| Step: 9
Training loss: 3.2341329143060062
Validation loss: 3.081249682636873

Epoch: 5| Step: 10
Training loss: 3.479512880806064
Validation loss: 3.0835910418922516

Epoch: 216| Step: 0
Training loss: 3.621239783707502
Validation loss: 3.085838217207136

Epoch: 5| Step: 1
Training loss: 2.877343922350151
Validation loss: 3.081784281333839

Epoch: 5| Step: 2
Training loss: 3.256310278980737
Validation loss: 3.0807071222775524

Epoch: 5| Step: 3
Training loss: 3.4026904624756646
Validation loss: 3.0787251771590984

Epoch: 5| Step: 4
Training loss: 3.2129537002262207
Validation loss: 3.076527504704819

Epoch: 5| Step: 5
Training loss: 3.6627101069779995
Validation loss: 3.0789243897842447

Epoch: 5| Step: 6
Training loss: 3.3898427034417318
Validation loss: 3.078263251301939

Epoch: 5| Step: 7
Training loss: 3.630565711463422
Validation loss: 3.077790212906584

Epoch: 5| Step: 8
Training loss: 3.2803077434757153
Validation loss: 3.0792451166286274

Epoch: 5| Step: 9
Training loss: 3.119306795188207
Validation loss: 3.0791273394937875

Epoch: 5| Step: 10
Training loss: 3.1737397824243514
Validation loss: 3.074483306851348

Epoch: 217| Step: 0
Training loss: 2.634760286115097
Validation loss: 3.079016924854363

Epoch: 5| Step: 1
Training loss: 3.243070110004303
Validation loss: 3.0781465301335373

Epoch: 5| Step: 2
Training loss: 3.499820704636112
Validation loss: 3.077122239028187

Epoch: 5| Step: 3
Training loss: 3.682881971180649
Validation loss: 3.0806266072678827

Epoch: 5| Step: 4
Training loss: 3.020934969189792
Validation loss: 3.0783107217024783

Epoch: 5| Step: 5
Training loss: 3.070029519899077
Validation loss: 3.0772881289250584

Epoch: 5| Step: 6
Training loss: 3.5045958725970974
Validation loss: 3.07739934867681

Epoch: 5| Step: 7
Training loss: 3.6684720767548016
Validation loss: 3.0748725291103884

Epoch: 5| Step: 8
Training loss: 3.856778155347153
Validation loss: 3.077296492247662

Epoch: 5| Step: 9
Training loss: 3.4906189401927454
Validation loss: 3.0768467758296745

Epoch: 5| Step: 10
Training loss: 2.719291633059283
Validation loss: 3.0743656950208007

Epoch: 218| Step: 0
Training loss: 3.517323130462903
Validation loss: 3.07612278563329

Epoch: 5| Step: 1
Training loss: 3.7677740399100785
Validation loss: 3.074672510326159

Epoch: 5| Step: 2
Training loss: 3.3750093248026563
Validation loss: 3.0733531866414885

Epoch: 5| Step: 3
Training loss: 2.773217936676488
Validation loss: 3.0735929239667725

Epoch: 5| Step: 4
Training loss: 2.951980449756507
Validation loss: 3.072100604643164

Epoch: 5| Step: 5
Training loss: 3.7097538716809972
Validation loss: 3.070503191158838

Epoch: 5| Step: 6
Training loss: 3.648975275501091
Validation loss: 3.0707081100434026

Epoch: 5| Step: 7
Training loss: 3.0719978812428956
Validation loss: 3.072658860182152

Epoch: 5| Step: 8
Training loss: 3.343654452946358
Validation loss: 3.0723755646686848

Epoch: 5| Step: 9
Training loss: 3.0972519907829876
Validation loss: 3.071497566382501

Epoch: 5| Step: 10
Training loss: 3.323463147866552
Validation loss: 3.075411834137044

Epoch: 219| Step: 0
Training loss: 3.221765087483981
Validation loss: 3.0712047162378378

Epoch: 5| Step: 1
Training loss: 2.9111059495364078
Validation loss: 3.072259964111191

Epoch: 5| Step: 2
Training loss: 2.8021778152211674
Validation loss: 3.0699513219352026

Epoch: 5| Step: 3
Training loss: 3.4213161621832335
Validation loss: 3.0742570807164427

Epoch: 5| Step: 4
Training loss: 3.2258364989819404
Validation loss: 3.0707432411522473

Epoch: 5| Step: 5
Training loss: 3.767761890444503
Validation loss: 3.0700299516219993

Epoch: 5| Step: 6
Training loss: 3.076434140605707
Validation loss: 3.073365137499637

Epoch: 5| Step: 7
Training loss: 3.8337010469846717
Validation loss: 3.07476795814028

Epoch: 5| Step: 8
Training loss: 3.554775765130122
Validation loss: 3.0765018600878733

Epoch: 5| Step: 9
Training loss: 3.365225023111643
Validation loss: 3.076292668692646

Epoch: 5| Step: 10
Training loss: 3.3762740097124326
Validation loss: 3.07298491693994

Epoch: 220| Step: 0
Training loss: 3.074454505731464
Validation loss: 3.0722822287673006

Epoch: 5| Step: 1
Training loss: 2.8552596697993025
Validation loss: 3.0690147832190062

Epoch: 5| Step: 2
Training loss: 2.3100550330406135
Validation loss: 3.0701265666787276

Epoch: 5| Step: 3
Training loss: 3.8690547249976777
Validation loss: 3.0683044264496186

Epoch: 5| Step: 4
Training loss: 3.022915422968189
Validation loss: 3.0678490172735953

Epoch: 5| Step: 5
Training loss: 3.44065767388763
Validation loss: 3.069856306428033

Epoch: 5| Step: 6
Training loss: 3.312020609012928
Validation loss: 3.0687316441862578

Epoch: 5| Step: 7
Training loss: 3.225501525679857
Validation loss: 3.0688072267255704

Epoch: 5| Step: 8
Training loss: 4.002639138295024
Validation loss: 3.0704782267924657

Epoch: 5| Step: 9
Training loss: 3.765948776318134
Validation loss: 3.070364678945717

Epoch: 5| Step: 10
Training loss: 3.4349436184227486
Validation loss: 3.068155898515756

Epoch: 221| Step: 0
Training loss: 3.147067166988979
Validation loss: 3.0689496017137894

Epoch: 5| Step: 1
Training loss: 4.0270003756079396
Validation loss: 3.0705590354610837

Epoch: 5| Step: 2
Training loss: 3.1481918352706906
Validation loss: 3.067222805966226

Epoch: 5| Step: 3
Training loss: 2.553091688183941
Validation loss: 3.0696317461872265

Epoch: 5| Step: 4
Training loss: 3.2021604993196893
Validation loss: 3.069631146540654

Epoch: 5| Step: 5
Training loss: 3.319762850874647
Validation loss: 3.073660802799003

Epoch: 5| Step: 6
Training loss: 3.3176701342401276
Validation loss: 3.0712437657057894

Epoch: 5| Step: 7
Training loss: 3.552617201673777
Validation loss: 3.070902234449301

Epoch: 5| Step: 8
Training loss: 2.956396158165978
Validation loss: 3.0726244610066424

Epoch: 5| Step: 9
Training loss: 3.733825004649286
Validation loss: 3.0720578700563252

Epoch: 5| Step: 10
Training loss: 3.468026162995908
Validation loss: 3.067990560175284

Epoch: 222| Step: 0
Training loss: 3.4809216548231308
Validation loss: 3.0724359040655433

Epoch: 5| Step: 1
Training loss: 3.715735359574217
Validation loss: 3.0653242474317173

Epoch: 5| Step: 2
Training loss: 2.96523261252994
Validation loss: 3.063254670443549

Epoch: 5| Step: 3
Training loss: 3.85633106115578
Validation loss: 3.063573639457348

Epoch: 5| Step: 4
Training loss: 2.7981252593005626
Validation loss: 3.0669110968053417

Epoch: 5| Step: 5
Training loss: 3.402949142466125
Validation loss: 3.065407594695526

Epoch: 5| Step: 6
Training loss: 3.3511709415795994
Validation loss: 3.0660759308942556

Epoch: 5| Step: 7
Training loss: 3.1976214509734553
Validation loss: 3.0624324815417245

Epoch: 5| Step: 8
Training loss: 2.6207482555106676
Validation loss: 3.0664883915773267

Epoch: 5| Step: 9
Training loss: 3.5041170428947113
Validation loss: 3.065588113424621

Epoch: 5| Step: 10
Training loss: 3.5664919522236245
Validation loss: 3.0675708576919534

Epoch: 223| Step: 0
Training loss: 3.5600840089293913
Validation loss: 3.070759689519486

Epoch: 5| Step: 1
Training loss: 3.0995816840681805
Validation loss: 3.070064072571807

Epoch: 5| Step: 2
Training loss: 3.753026503922927
Validation loss: 3.0727428094407916

Epoch: 5| Step: 3
Training loss: 3.401775956542156
Validation loss: 3.0668719361647234

Epoch: 5| Step: 4
Training loss: 3.8735597456537847
Validation loss: 3.0720692034168025

Epoch: 5| Step: 5
Training loss: 2.6718524240354244
Validation loss: 3.0786964939959027

Epoch: 5| Step: 6
Training loss: 3.3074103066298512
Validation loss: 3.0643314011211866

Epoch: 5| Step: 7
Training loss: 3.814641007397659
Validation loss: 3.0644810781433542

Epoch: 5| Step: 8
Training loss: 3.203007393515513
Validation loss: 3.0602153621540804

Epoch: 5| Step: 9
Training loss: 2.9406941680394794
Validation loss: 3.06083599001132

Epoch: 5| Step: 10
Training loss: 2.6099587889593043
Validation loss: 3.0612902802073663

Epoch: 224| Step: 0
Training loss: 3.608433588292932
Validation loss: 3.059485490662697

Epoch: 5| Step: 1
Training loss: 2.8049124199833506
Validation loss: 3.0627586551853443

Epoch: 5| Step: 2
Training loss: 3.3680045072656766
Validation loss: 3.061440120986278

Epoch: 5| Step: 3
Training loss: 3.2685355763465043
Validation loss: 3.060510194465199

Epoch: 5| Step: 4
Training loss: 3.8296371276107615
Validation loss: 3.058890198572779

Epoch: 5| Step: 5
Training loss: 2.7407276582357927
Validation loss: 3.0590506275426694

Epoch: 5| Step: 6
Training loss: 3.3811886878809645
Validation loss: 3.0608446537428264

Epoch: 5| Step: 7
Training loss: 3.593936550440042
Validation loss: 3.062168486789942

Epoch: 5| Step: 8
Training loss: 3.822474704456648
Validation loss: 3.063148470061047

Epoch: 5| Step: 9
Training loss: 2.178037942161784
Validation loss: 3.0614005914078084

Epoch: 5| Step: 10
Training loss: 3.649730771730392
Validation loss: 3.062593734475339

Epoch: 225| Step: 0
Training loss: 3.933278318332911
Validation loss: 3.059859332109346

Epoch: 5| Step: 1
Training loss: 3.6219090405000856
Validation loss: 3.0596964051087254

Epoch: 5| Step: 2
Training loss: 3.470494012323778
Validation loss: 3.0579809415397703

Epoch: 5| Step: 3
Training loss: 2.751670763354272
Validation loss: 3.0617430376981973

Epoch: 5| Step: 4
Training loss: 3.814365368374161
Validation loss: 3.0583224194751537

Epoch: 5| Step: 5
Training loss: 3.1030704858453526
Validation loss: 3.063700594866158

Epoch: 5| Step: 6
Training loss: 3.357689013014409
Validation loss: 3.0653196392175843

Epoch: 5| Step: 7
Training loss: 3.5421113277367575
Validation loss: 3.0647122092628383

Epoch: 5| Step: 8
Training loss: 2.8394825533817727
Validation loss: 3.0639759865743543

Epoch: 5| Step: 9
Training loss: 3.152708880940939
Validation loss: 3.062036652930448

Epoch: 5| Step: 10
Training loss: 2.5909621181567646
Validation loss: 3.0667839934263266

Epoch: 226| Step: 0
Training loss: 3.3323759770477257
Validation loss: 3.0613173846038424

Epoch: 5| Step: 1
Training loss: 3.6872462815753453
Validation loss: 3.0641195197652342

Epoch: 5| Step: 2
Training loss: 3.820199914065081
Validation loss: 3.0696495668281423

Epoch: 5| Step: 3
Training loss: 3.0004938037098285
Validation loss: 3.0661734456108567

Epoch: 5| Step: 4
Training loss: 3.3001259057272865
Validation loss: 3.0651203704008947

Epoch: 5| Step: 5
Training loss: 3.704502412893833
Validation loss: 3.0632580322726786

Epoch: 5| Step: 6
Training loss: 3.3688476435111205
Validation loss: 3.064387486731034

Epoch: 5| Step: 7
Training loss: 2.607533244637009
Validation loss: 3.057365919838456

Epoch: 5| Step: 8
Training loss: 3.0595865209632906
Validation loss: 3.0563684274092475

Epoch: 5| Step: 9
Training loss: 3.0282080419470025
Validation loss: 3.058341713428598

Epoch: 5| Step: 10
Training loss: 3.4472939811599335
Validation loss: 3.055854117411133

Epoch: 227| Step: 0
Training loss: 3.689114233459659
Validation loss: 3.058303489203028

Epoch: 5| Step: 1
Training loss: 2.9770946277344548
Validation loss: 3.055123545540145

Epoch: 5| Step: 2
Training loss: 3.275473459978561
Validation loss: 3.0571189887927765

Epoch: 5| Step: 3
Training loss: 3.7955368886538734
Validation loss: 3.0545070076528997

Epoch: 5| Step: 4
Training loss: 3.2154137070230964
Validation loss: 3.0546013415765025

Epoch: 5| Step: 5
Training loss: 4.3273541697101034
Validation loss: 3.056386341320446

Epoch: 5| Step: 6
Training loss: 3.160772727937094
Validation loss: 3.0536828219638927

Epoch: 5| Step: 7
Training loss: 2.712674334852334
Validation loss: 3.052178571464507

Epoch: 5| Step: 8
Training loss: 2.9528404785019275
Validation loss: 3.055108111414287

Epoch: 5| Step: 9
Training loss: 2.498391301418019
Validation loss: 3.054596522474271

Epoch: 5| Step: 10
Training loss: 3.5753137464165214
Validation loss: 3.0538748629632932

Epoch: 228| Step: 0
Training loss: 3.0799805910564078
Validation loss: 3.05540416065284

Epoch: 5| Step: 1
Training loss: 3.7262331259216483
Validation loss: 3.056210489892363

Epoch: 5| Step: 2
Training loss: 2.897763073541952
Validation loss: 3.0572638099070604

Epoch: 5| Step: 3
Training loss: 2.9612888741668972
Validation loss: 3.0565246817945595

Epoch: 5| Step: 4
Training loss: 2.9139774095318103
Validation loss: 3.060669824879245

Epoch: 5| Step: 5
Training loss: 3.7154827992248127
Validation loss: 3.059578068173256

Epoch: 5| Step: 6
Training loss: 3.5998682103935624
Validation loss: 3.0616275908392496

Epoch: 5| Step: 7
Training loss: 3.167138081312312
Validation loss: 3.073556537586457

Epoch: 5| Step: 8
Training loss: 3.39165400347271
Validation loss: 3.062921054366159

Epoch: 5| Step: 9
Training loss: 3.6627429139493977
Validation loss: 3.0569476150150092

Epoch: 5| Step: 10
Training loss: 3.2363468369913937
Validation loss: 3.0562789628072684

Epoch: 229| Step: 0
Training loss: 2.9626579017246266
Validation loss: 3.0567123709223014

Epoch: 5| Step: 1
Training loss: 3.3329455785923656
Validation loss: 3.0587040679301865

Epoch: 5| Step: 2
Training loss: 2.9218851181099876
Validation loss: 3.0546021137064217

Epoch: 5| Step: 3
Training loss: 3.8114829035604108
Validation loss: 3.0544078228788885

Epoch: 5| Step: 4
Training loss: 3.337926338768127
Validation loss: 3.0562815706697815

Epoch: 5| Step: 5
Training loss: 2.605605915353799
Validation loss: 3.0536017262072193

Epoch: 5| Step: 6
Training loss: 3.390552572716142
Validation loss: 3.0572233835847453

Epoch: 5| Step: 7
Training loss: 3.5955657352554367
Validation loss: 3.05450566981211

Epoch: 5| Step: 8
Training loss: 3.7060047653916954
Validation loss: 3.0567053393193233

Epoch: 5| Step: 9
Training loss: 3.0427051669980067
Validation loss: 3.052039377131955

Epoch: 5| Step: 10
Training loss: 3.618856419923966
Validation loss: 3.053227126127395

Epoch: 230| Step: 0
Training loss: 2.949714103681411
Validation loss: 3.051284755001995

Epoch: 5| Step: 1
Training loss: 3.614463093248237
Validation loss: 3.0493159224119504

Epoch: 5| Step: 2
Training loss: 3.4581017167689714
Validation loss: 3.0496396210761483

Epoch: 5| Step: 3
Training loss: 3.41197828839137
Validation loss: 3.0506056225493343

Epoch: 5| Step: 4
Training loss: 3.69784323749261
Validation loss: 3.052714243606829

Epoch: 5| Step: 5
Training loss: 3.399921663167231
Validation loss: 3.048876958451769

Epoch: 5| Step: 6
Training loss: 3.3966941132589277
Validation loss: 3.0524651078884433

Epoch: 5| Step: 7
Training loss: 3.3660247990311762
Validation loss: 3.0519501535489413

Epoch: 5| Step: 8
Training loss: 2.768453670858815
Validation loss: 3.04882704701602

Epoch: 5| Step: 9
Training loss: 2.9518027600089716
Validation loss: 3.049089234790762

Epoch: 5| Step: 10
Training loss: 3.3351874122405873
Validation loss: 3.052206107866293

Epoch: 231| Step: 0
Training loss: 2.900413970339548
Validation loss: 3.048620098984448

Epoch: 5| Step: 1
Training loss: 3.665386294294418
Validation loss: 3.05104348998826

Epoch: 5| Step: 2
Training loss: 3.0259248817131117
Validation loss: 3.0493496849596644

Epoch: 5| Step: 3
Training loss: 4.1407136727680935
Validation loss: 3.052078608811224

Epoch: 5| Step: 4
Training loss: 3.7090756534153884
Validation loss: 3.0507112805711087

Epoch: 5| Step: 5
Training loss: 3.640450010883034
Validation loss: 3.0470531006646215

Epoch: 5| Step: 6
Training loss: 2.9283195048313098
Validation loss: 3.0494477597660397

Epoch: 5| Step: 7
Training loss: 2.712549087853732
Validation loss: 3.047960088260173

Epoch: 5| Step: 8
Training loss: 3.5160096360770012
Validation loss: 3.0491879788131304

Epoch: 5| Step: 9
Training loss: 2.332316472232692
Validation loss: 3.046555984998682

Epoch: 5| Step: 10
Training loss: 3.4854269449766884
Validation loss: 3.0494072626128528

Epoch: 232| Step: 0
Training loss: 2.965483464520537
Validation loss: 3.050047882850036

Epoch: 5| Step: 1
Training loss: 3.2658120425744523
Validation loss: 3.0523152397493956

Epoch: 5| Step: 2
Training loss: 3.0897415857991426
Validation loss: 3.0548679808437793

Epoch: 5| Step: 3
Training loss: 3.808911620348839
Validation loss: 3.0546589142372147

Epoch: 5| Step: 4
Training loss: 3.591443059440946
Validation loss: 3.0530930076460656

Epoch: 5| Step: 5
Training loss: 3.011951165440444
Validation loss: 3.0490707827799173

Epoch: 5| Step: 6
Training loss: 3.4255870733613203
Validation loss: 3.049241835853982

Epoch: 5| Step: 7
Training loss: 3.4117931094931393
Validation loss: 3.047872470406898

Epoch: 5| Step: 8
Training loss: 3.6621417967314804
Validation loss: 3.0437088697540564

Epoch: 5| Step: 9
Training loss: 3.299581853788609
Validation loss: 3.0443101494055793

Epoch: 5| Step: 10
Training loss: 2.617895138854559
Validation loss: 3.045205543268041

Epoch: 233| Step: 0
Training loss: 3.7908826723128346
Validation loss: 3.045784121450054

Epoch: 5| Step: 1
Training loss: 3.4433071675618927
Validation loss: 3.0443652506178074

Epoch: 5| Step: 2
Training loss: 2.9078892832462113
Validation loss: 3.046483735655899

Epoch: 5| Step: 3
Training loss: 3.513915057246122
Validation loss: 3.0428131028746135

Epoch: 5| Step: 4
Training loss: 3.0865002082887667
Validation loss: 3.044005831411677

Epoch: 5| Step: 5
Training loss: 3.8183431405505264
Validation loss: 3.044767269054048

Epoch: 5| Step: 6
Training loss: 3.3945513374603435
Validation loss: 3.0437015545847586

Epoch: 5| Step: 7
Training loss: 2.8090885241184957
Validation loss: 3.0432594524094245

Epoch: 5| Step: 8
Training loss: 3.226642598411814
Validation loss: 3.0430479404145894

Epoch: 5| Step: 9
Training loss: 2.7052581837354683
Validation loss: 3.042090440516169

Epoch: 5| Step: 10
Training loss: 3.5599074718152073
Validation loss: 3.0464313126183993

Epoch: 234| Step: 0
Training loss: 3.193412831643548
Validation loss: 3.0442127293221914

Epoch: 5| Step: 1
Training loss: 3.725785724287652
Validation loss: 3.0441393042973264

Epoch: 5| Step: 2
Training loss: 4.041412791245552
Validation loss: 3.047447765397026

Epoch: 5| Step: 3
Training loss: 3.3857945783911623
Validation loss: 3.0473974410520226

Epoch: 5| Step: 4
Training loss: 3.1155922232752795
Validation loss: 3.0460523194634797

Epoch: 5| Step: 5
Training loss: 2.4900380973505856
Validation loss: 3.0438668192171003

Epoch: 5| Step: 6
Training loss: 3.1191508675767174
Validation loss: 3.044801035731389

Epoch: 5| Step: 7
Training loss: 3.2238774615586734
Validation loss: 3.0432191146782266

Epoch: 5| Step: 8
Training loss: 3.1388166544956957
Validation loss: 3.0477951187622967

Epoch: 5| Step: 9
Training loss: 3.6197189799450475
Validation loss: 3.044497872425882

Epoch: 5| Step: 10
Training loss: 3.0657233577274585
Validation loss: 3.0450113550374485

Epoch: 235| Step: 0
Training loss: 3.6259802446621485
Validation loss: 3.0418200626258898

Epoch: 5| Step: 1
Training loss: 3.590631475351469
Validation loss: 3.0422232120528614

Epoch: 5| Step: 2
Training loss: 3.838551797771499
Validation loss: 3.039363281961303

Epoch: 5| Step: 3
Training loss: 3.35033275033449
Validation loss: 3.037595812597449

Epoch: 5| Step: 4
Training loss: 2.8425240022288416
Validation loss: 3.040194365935013

Epoch: 5| Step: 5
Training loss: 2.0077585888463845
Validation loss: 3.0406226033528645

Epoch: 5| Step: 6
Training loss: 3.945029915235687
Validation loss: 3.0383725482793076

Epoch: 5| Step: 7
Training loss: 3.229306289771718
Validation loss: 3.0440211020182333

Epoch: 5| Step: 8
Training loss: 3.3412942870716105
Validation loss: 3.0431283283974264

Epoch: 5| Step: 9
Training loss: 2.9776626916569384
Validation loss: 3.0404162655379463

Epoch: 5| Step: 10
Training loss: 3.197556283796943
Validation loss: 3.0395124468078887

Epoch: 236| Step: 0
Training loss: 2.9804471516357824
Validation loss: 3.041066936738365

Epoch: 5| Step: 1
Training loss: 2.695721669859501
Validation loss: 3.042182745974771

Epoch: 5| Step: 2
Training loss: 3.712387412062649
Validation loss: 3.039884885416234

Epoch: 5| Step: 3
Training loss: 3.285996990599505
Validation loss: 3.0429546872895736

Epoch: 5| Step: 4
Training loss: 3.501180994510744
Validation loss: 3.0377817512860377

Epoch: 5| Step: 5
Training loss: 3.497709478467896
Validation loss: 3.03527499429724

Epoch: 5| Step: 6
Training loss: 3.343409155470474
Validation loss: 3.0367503515027257

Epoch: 5| Step: 7
Training loss: 2.919034015307038
Validation loss: 3.0360308404467418

Epoch: 5| Step: 8
Training loss: 2.748240775158874
Validation loss: 3.0336859687290914

Epoch: 5| Step: 9
Training loss: 3.9301964978119828
Validation loss: 3.0359547045295705

Epoch: 5| Step: 10
Training loss: 3.546463862718106
Validation loss: 3.0335991090428553

Epoch: 237| Step: 0
Training loss: 3.540415793531724
Validation loss: 3.0370607558239997

Epoch: 5| Step: 1
Training loss: 3.315039183326089
Validation loss: 3.0363035255259136

Epoch: 5| Step: 2
Training loss: 3.1301116336012926
Validation loss: 3.038172144904193

Epoch: 5| Step: 3
Training loss: 3.3573821078214974
Validation loss: 3.0416772715515297

Epoch: 5| Step: 4
Training loss: 3.431380078016297
Validation loss: 3.039608743141892

Epoch: 5| Step: 5
Training loss: 2.6420589368369916
Validation loss: 3.0400439350372985

Epoch: 5| Step: 6
Training loss: 3.5261799021247393
Validation loss: 3.0376487577685496

Epoch: 5| Step: 7
Training loss: 3.191476473274991
Validation loss: 3.0343348464242976

Epoch: 5| Step: 8
Training loss: 3.1956722737842043
Validation loss: 3.0358300696849483

Epoch: 5| Step: 9
Training loss: 3.4163693244381403
Validation loss: 3.0351847246617907

Epoch: 5| Step: 10
Training loss: 3.564720398797982
Validation loss: 3.033289144095631

Epoch: 238| Step: 0
Training loss: 3.1628824176189516
Validation loss: 3.0338873317651585

Epoch: 5| Step: 1
Training loss: 4.042016135506793
Validation loss: 3.033714176634409

Epoch: 5| Step: 2
Training loss: 2.5079784873149276
Validation loss: 3.0320927250147234

Epoch: 5| Step: 3
Training loss: 3.350576402411017
Validation loss: 3.0343329843141547

Epoch: 5| Step: 4
Training loss: 3.623972385368651
Validation loss: 3.0334384943819463

Epoch: 5| Step: 5
Training loss: 3.1762028375612337
Validation loss: 3.0320081837764694

Epoch: 5| Step: 6
Training loss: 3.33447676756272
Validation loss: 3.034022301765399

Epoch: 5| Step: 7
Training loss: 3.48312889363119
Validation loss: 3.0332966052345527

Epoch: 5| Step: 8
Training loss: 3.7053761782132613
Validation loss: 3.0342775547536482

Epoch: 5| Step: 9
Training loss: 2.6035550022223783
Validation loss: 3.0311799755408595

Epoch: 5| Step: 10
Training loss: 2.9796400605512563
Validation loss: 3.0358981460039565

Epoch: 239| Step: 0
Training loss: 3.3687010016620107
Validation loss: 3.033582345945848

Epoch: 5| Step: 1
Training loss: 3.363221135859402
Validation loss: 3.0364727683459356

Epoch: 5| Step: 2
Training loss: 3.144616318967716
Validation loss: 3.031713338880293

Epoch: 5| Step: 3
Training loss: 3.4987127116602346
Validation loss: 3.0346189552213683

Epoch: 5| Step: 4
Training loss: 3.844324828794027
Validation loss: 3.0326311216711055

Epoch: 5| Step: 5
Training loss: 3.1217246629412756
Validation loss: 3.0351492765727173

Epoch: 5| Step: 6
Training loss: 3.59009532026231
Validation loss: 3.0332861048679454

Epoch: 5| Step: 7
Training loss: 2.507989514719873
Validation loss: 3.0339953219342357

Epoch: 5| Step: 8
Training loss: 3.2814288862602976
Validation loss: 3.0344066914047976

Epoch: 5| Step: 9
Training loss: 3.4738829155112803
Validation loss: 3.0348097502764504

Epoch: 5| Step: 10
Training loss: 2.845877888797546
Validation loss: 3.0310447140442087

Epoch: 240| Step: 0
Training loss: 2.805722356523277
Validation loss: 3.0312564301324794

Epoch: 5| Step: 1
Training loss: 3.433362933528175
Validation loss: 3.0323600229355097

Epoch: 5| Step: 2
Training loss: 2.8116140029699626
Validation loss: 3.028749993491252

Epoch: 5| Step: 3
Training loss: 3.883485179328167
Validation loss: 3.029749609024317

Epoch: 5| Step: 4
Training loss: 3.098235144766786
Validation loss: 3.0313770693384496

Epoch: 5| Step: 5
Training loss: 3.4421553559605456
Validation loss: 3.02981980192356

Epoch: 5| Step: 6
Training loss: 2.67872330916187
Validation loss: 3.0334358263149785

Epoch: 5| Step: 7
Training loss: 3.1342421620479306
Validation loss: 3.0308203181760387

Epoch: 5| Step: 8
Training loss: 3.6504619462836
Validation loss: 3.0328607604423494

Epoch: 5| Step: 9
Training loss: 3.4077704999417784
Validation loss: 3.031711838771574

Epoch: 5| Step: 10
Training loss: 3.76707639463129
Validation loss: 3.030009751885115

Epoch: 241| Step: 0
Training loss: 3.7461114431526252
Validation loss: 3.0291663957543715

Epoch: 5| Step: 1
Training loss: 3.276134608920861
Validation loss: 3.0273929316997688

Epoch: 5| Step: 2
Training loss: 3.540405557537275
Validation loss: 3.0295619342852036

Epoch: 5| Step: 3
Training loss: 2.966363690653432
Validation loss: 3.028343942306127

Epoch: 5| Step: 4
Training loss: 2.255844472860681
Validation loss: 3.027559334670137

Epoch: 5| Step: 5
Training loss: 4.0739170156575195
Validation loss: 3.026704816607168

Epoch: 5| Step: 6
Training loss: 2.598500692455911
Validation loss: 3.029299759129053

Epoch: 5| Step: 7
Training loss: 3.1008462919726334
Validation loss: 3.0292435113468414

Epoch: 5| Step: 8
Training loss: 3.732354930554799
Validation loss: 3.029595713042201

Epoch: 5| Step: 9
Training loss: 3.1670662644551197
Validation loss: 3.02805682847555

Epoch: 5| Step: 10
Training loss: 3.4347449619726333
Validation loss: 3.03024412312309

Epoch: 242| Step: 0
Training loss: 3.4227727121802296
Validation loss: 3.0275964770778083

Epoch: 5| Step: 1
Training loss: 3.0710796145296033
Validation loss: 3.025588002724104

Epoch: 5| Step: 2
Training loss: 3.263991535998571
Validation loss: 3.0287513173156304

Epoch: 5| Step: 3
Training loss: 3.038278199025371
Validation loss: 3.026190187211196

Epoch: 5| Step: 4
Training loss: 3.697701518645886
Validation loss: 3.0267828740860163

Epoch: 5| Step: 5
Training loss: 3.53081543535623
Validation loss: 3.0273228976258952

Epoch: 5| Step: 6
Training loss: 3.0277310425148576
Validation loss: 3.026302842668902

Epoch: 5| Step: 7
Training loss: 3.4202723821846353
Validation loss: 3.028718524559548

Epoch: 5| Step: 8
Training loss: 3.679918026840426
Validation loss: 3.025755775866999

Epoch: 5| Step: 9
Training loss: 2.897234314791382
Validation loss: 3.027183895065218

Epoch: 5| Step: 10
Training loss: 3.0454264009332053
Validation loss: 3.0283800016799796

Epoch: 243| Step: 0
Training loss: 3.4917839892455076
Validation loss: 3.0253606786163156

Epoch: 5| Step: 1
Training loss: 2.9158385236428086
Validation loss: 3.027265232747071

Epoch: 5| Step: 2
Training loss: 3.7714765361939513
Validation loss: 3.0258927242522304

Epoch: 5| Step: 3
Training loss: 3.4774377299807333
Validation loss: 3.024263852030343

Epoch: 5| Step: 4
Training loss: 3.662431366052798
Validation loss: 3.028092003165091

Epoch: 5| Step: 5
Training loss: 2.8746987889936237
Validation loss: 3.0229072111056268

Epoch: 5| Step: 6
Training loss: 3.0221221980515702
Validation loss: 3.022266017367079

Epoch: 5| Step: 7
Training loss: 2.8641427735911926
Validation loss: 3.027315863812663

Epoch: 5| Step: 8
Training loss: 3.246289115379264
Validation loss: 3.0282324574088357

Epoch: 5| Step: 9
Training loss: 3.3215160387654863
Validation loss: 3.0245480066761643

Epoch: 5| Step: 10
Training loss: 3.4303246256073696
Validation loss: 3.0257075707430605

Epoch: 244| Step: 0
Training loss: 3.6681940336583745
Validation loss: 3.0247717575739377

Epoch: 5| Step: 1
Training loss: 2.8918494028475963
Validation loss: 3.0256501792598196

Epoch: 5| Step: 2
Training loss: 2.864759368111503
Validation loss: 3.0229857050153246

Epoch: 5| Step: 3
Training loss: 3.139370492168321
Validation loss: 3.0257036393319776

Epoch: 5| Step: 4
Training loss: 4.019559721109079
Validation loss: 3.0290357043774936

Epoch: 5| Step: 5
Training loss: 3.5290546175761364
Validation loss: 3.0264684652785365

Epoch: 5| Step: 6
Training loss: 2.858380754557535
Validation loss: 3.0299351619558803

Epoch: 5| Step: 7
Training loss: 3.7045469491490732
Validation loss: 3.02758021589923

Epoch: 5| Step: 8
Training loss: 3.1785616744429084
Validation loss: 3.026434639758425

Epoch: 5| Step: 9
Training loss: 2.8737214604139103
Validation loss: 3.0309200786025965

Epoch: 5| Step: 10
Training loss: 3.2139505696035497
Validation loss: 3.0262218383086497

Epoch: 245| Step: 0
Training loss: 3.115480495763442
Validation loss: 3.0227754154192534

Epoch: 5| Step: 1
Training loss: 3.283744227328416
Validation loss: 3.0245787527670003

Epoch: 5| Step: 2
Training loss: 3.349610513848203
Validation loss: 3.025804863067052

Epoch: 5| Step: 3
Training loss: 3.0469236712358585
Validation loss: 3.023569791667577

Epoch: 5| Step: 4
Training loss: 3.0637277750044136
Validation loss: 3.02232925382901

Epoch: 5| Step: 5
Training loss: 3.128605403081136
Validation loss: 3.025081678301562

Epoch: 5| Step: 6
Training loss: 3.4706157443628833
Validation loss: 3.0224343107997766

Epoch: 5| Step: 7
Training loss: 3.266410769605669
Validation loss: 3.020712328486228

Epoch: 5| Step: 8
Training loss: 3.509535198682443
Validation loss: 3.023291774225832

Epoch: 5| Step: 9
Training loss: 3.491292749259958
Validation loss: 3.022044071937542

Epoch: 5| Step: 10
Training loss: 3.4478540021074897
Validation loss: 3.0207570548322735

Epoch: 246| Step: 0
Training loss: 3.7468892228442785
Validation loss: 3.0230716010032537

Epoch: 5| Step: 1
Training loss: 4.060382467210361
Validation loss: 3.0237701539114297

Epoch: 5| Step: 2
Training loss: 3.211454252441928
Validation loss: 3.024559412110389

Epoch: 5| Step: 3
Training loss: 3.5529096580076263
Validation loss: 3.0388609846800816

Epoch: 5| Step: 4
Training loss: 2.7017972474621486
Validation loss: 3.028962473440199

Epoch: 5| Step: 5
Training loss: 3.3840528509192853
Validation loss: 3.0301789418223772

Epoch: 5| Step: 6
Training loss: 3.0337422930128786
Validation loss: 3.0225908750102075

Epoch: 5| Step: 7
Training loss: 3.0946635429150704
Validation loss: 3.0193815488850397

Epoch: 5| Step: 8
Training loss: 3.284092716241743
Validation loss: 3.019893582952018

Epoch: 5| Step: 9
Training loss: 2.7523777825630655
Validation loss: 3.0178855802287186

Epoch: 5| Step: 10
Training loss: 3.0970895640916445
Validation loss: 3.0204164267529547

Epoch: 247| Step: 0
Training loss: 2.8004105879968293
Validation loss: 3.018293718721849

Epoch: 5| Step: 1
Training loss: 3.7894216465583868
Validation loss: 3.017066364995467

Epoch: 5| Step: 2
Training loss: 2.9494602938131367
Validation loss: 3.0186717536249583

Epoch: 5| Step: 3
Training loss: 3.0260708009211386
Validation loss: 3.0191015829221626

Epoch: 5| Step: 4
Training loss: 3.347086017698901
Validation loss: 3.0193523181031896

Epoch: 5| Step: 5
Training loss: 3.34166802448299
Validation loss: 3.0206687506175296

Epoch: 5| Step: 6
Training loss: 2.8944918775261645
Validation loss: 3.025749489096127

Epoch: 5| Step: 7
Training loss: 3.390412073437381
Validation loss: 3.022746266647771

Epoch: 5| Step: 8
Training loss: 3.6193354842898104
Validation loss: 3.0258407002192667

Epoch: 5| Step: 9
Training loss: 3.786058379418913
Validation loss: 3.0296110901300413

Epoch: 5| Step: 10
Training loss: 3.0117735307315256
Validation loss: 3.0215874641152007

Epoch: 248| Step: 0
Training loss: 3.2275971238631573
Validation loss: 3.0205613881986384

Epoch: 5| Step: 1
Training loss: 3.8012824203478495
Validation loss: 3.0169746498243857

Epoch: 5| Step: 2
Training loss: 3.312835532415025
Validation loss: 3.0184206285478643

Epoch: 5| Step: 3
Training loss: 3.558008273521955
Validation loss: 3.0193038213983616

Epoch: 5| Step: 4
Training loss: 3.033236609652989
Validation loss: 3.01651023688501

Epoch: 5| Step: 5
Training loss: 3.664444828217209
Validation loss: 3.015284017474087

Epoch: 5| Step: 6
Training loss: 3.143180452784194
Validation loss: 3.0179425672163633

Epoch: 5| Step: 7
Training loss: 3.152365834514493
Validation loss: 3.016023400736944

Epoch: 5| Step: 8
Training loss: 2.9445453322618618
Validation loss: 3.015655459616191

Epoch: 5| Step: 9
Training loss: 3.4185667724604993
Validation loss: 3.0145592340427267

Epoch: 5| Step: 10
Training loss: 2.6674376108440403
Validation loss: 3.01504809390111

Epoch: 249| Step: 0
Training loss: 3.268318635037636
Validation loss: 3.0166908049944845

Epoch: 5| Step: 1
Training loss: 3.2795431874998626
Validation loss: 3.0177084129288434

Epoch: 5| Step: 2
Training loss: 3.548419095339765
Validation loss: 3.0141145754529757

Epoch: 5| Step: 3
Training loss: 3.484442055916562
Validation loss: 3.0255787957330975

Epoch: 5| Step: 4
Training loss: 3.4172440638001187
Validation loss: 3.0174728615729154

Epoch: 5| Step: 5
Training loss: 3.1396453999790905
Validation loss: 3.018567547483612

Epoch: 5| Step: 6
Training loss: 3.41466581482773
Validation loss: 3.0119474850391783

Epoch: 5| Step: 7
Training loss: 3.5756991629734953
Validation loss: 3.014466827719941

Epoch: 5| Step: 8
Training loss: 3.248981462946476
Validation loss: 3.0152531808573313

Epoch: 5| Step: 9
Training loss: 2.8354738975726645
Validation loss: 3.0187839185563328

Epoch: 5| Step: 10
Training loss: 2.7257117225655487
Validation loss: 3.0136660836322133

Epoch: 250| Step: 0
Training loss: 3.332623946681521
Validation loss: 3.0187612712166216

Epoch: 5| Step: 1
Training loss: 3.2287371606161672
Validation loss: 3.012342682018446

Epoch: 5| Step: 2
Training loss: 3.0001718154025836
Validation loss: 3.0150282006415963

Epoch: 5| Step: 3
Training loss: 3.5797485932457223
Validation loss: 3.0114727317461396

Epoch: 5| Step: 4
Training loss: 3.3072270584804446
Validation loss: 3.0119236729726393

Epoch: 5| Step: 5
Training loss: 2.967839794163971
Validation loss: 3.012589738901709

Epoch: 5| Step: 6
Training loss: 3.5947674181833404
Validation loss: 3.0129449662705854

Epoch: 5| Step: 7
Training loss: 3.7903089223287023
Validation loss: 3.0123205726266824

Epoch: 5| Step: 8
Training loss: 3.4773432508582687
Validation loss: 3.0118657728444362

Epoch: 5| Step: 9
Training loss: 2.7351772330426387
Validation loss: 3.0088456244977944

Epoch: 5| Step: 10
Training loss: 2.8586303074728368
Validation loss: 3.014085612549224

Epoch: 251| Step: 0
Training loss: 3.1568823454776513
Validation loss: 3.01052282939367

Epoch: 5| Step: 1
Training loss: 2.872423261210041
Validation loss: 3.0188417420454607

Epoch: 5| Step: 2
Training loss: 3.1293411619361806
Validation loss: 3.0137263880006935

Epoch: 5| Step: 3
Training loss: 2.5055774461739624
Validation loss: 3.025134488259238

Epoch: 5| Step: 4
Training loss: 3.436651367858914
Validation loss: 3.030783325239467

Epoch: 5| Step: 5
Training loss: 2.858095143202062
Validation loss: 3.030860978250141

Epoch: 5| Step: 6
Training loss: 3.660453010831697
Validation loss: 3.0233906790537386

Epoch: 5| Step: 7
Training loss: 3.588386314510059
Validation loss: 3.030739909941314

Epoch: 5| Step: 8
Training loss: 4.096891173586139
Validation loss: 3.017006239551305

Epoch: 5| Step: 9
Training loss: 2.8904590455951276
Validation loss: 3.0153543753709897

Epoch: 5| Step: 10
Training loss: 3.6359036328058507
Validation loss: 3.0101598871466195

Epoch: 252| Step: 0
Training loss: 3.2185685189944926
Validation loss: 3.012162389445674

Epoch: 5| Step: 1
Training loss: 3.2843356201830862
Validation loss: 3.007998962972493

Epoch: 5| Step: 2
Training loss: 3.8832981719252047
Validation loss: 3.01234212883883

Epoch: 5| Step: 3
Training loss: 3.2296997778760184
Validation loss: 3.012028949890562

Epoch: 5| Step: 4
Training loss: 2.7999824863976026
Validation loss: 3.0146151783852417

Epoch: 5| Step: 5
Training loss: 3.794573176409369
Validation loss: 3.0112058792495464

Epoch: 5| Step: 6
Training loss: 3.4752567882478402
Validation loss: 3.0166715514377422

Epoch: 5| Step: 7
Training loss: 2.9554416511053603
Validation loss: 3.010699777497136

Epoch: 5| Step: 8
Training loss: 3.0889312515586145
Validation loss: 3.020532259649492

Epoch: 5| Step: 9
Training loss: 3.386746909124572
Validation loss: 3.009330549893527

Epoch: 5| Step: 10
Training loss: 2.7042521513684985
Validation loss: 3.006956817278909

Epoch: 253| Step: 0
Training loss: 3.0471782826822253
Validation loss: 3.008158112491453

Epoch: 5| Step: 1
Training loss: 3.1273082600585087
Validation loss: 3.0107580014773774

Epoch: 5| Step: 2
Training loss: 4.0438617107166746
Validation loss: 3.010003049390564

Epoch: 5| Step: 3
Training loss: 3.34661343333346
Validation loss: 3.0110569136231233

Epoch: 5| Step: 4
Training loss: 3.579611123984028
Validation loss: 3.0086106735945903

Epoch: 5| Step: 5
Training loss: 2.9681225565363905
Validation loss: 3.009764117359331

Epoch: 5| Step: 6
Training loss: 2.898991863364321
Validation loss: 3.010504063508817

Epoch: 5| Step: 7
Training loss: 3.549364199587509
Validation loss: 3.009180937670619

Epoch: 5| Step: 8
Training loss: 3.723841411471236
Validation loss: 3.007974437823191

Epoch: 5| Step: 9
Training loss: 2.1608989190817716
Validation loss: 3.006517280296459

Epoch: 5| Step: 10
Training loss: 3.238222054928656
Validation loss: 3.0037494057716407

Epoch: 254| Step: 0
Training loss: 3.5240411685353137
Validation loss: 3.0077288914984566

Epoch: 5| Step: 1
Training loss: 3.0232930309072623
Validation loss: 3.0084176136580463

Epoch: 5| Step: 2
Training loss: 3.405893429632835
Validation loss: 3.0132549412367866

Epoch: 5| Step: 3
Training loss: 2.5696336957180645
Validation loss: 3.0106403023499246

Epoch: 5| Step: 4
Training loss: 3.527957698075358
Validation loss: 3.0142396174605444

Epoch: 5| Step: 5
Training loss: 3.030794089728145
Validation loss: 3.0121417647554427

Epoch: 5| Step: 6
Training loss: 3.0111585360738014
Validation loss: 3.0376027939117107

Epoch: 5| Step: 7
Training loss: 3.4743841654723027
Validation loss: 3.0550771707625235

Epoch: 5| Step: 8
Training loss: 3.3362200793757273
Validation loss: 3.097957161406047

Epoch: 5| Step: 9
Training loss: 3.5099354460341785
Validation loss: 3.100728864061956

Epoch: 5| Step: 10
Training loss: 3.834184234275996
Validation loss: 3.1054845959029582

Epoch: 255| Step: 0
Training loss: 3.7269066865588925
Validation loss: 3.1132615208282117

Epoch: 5| Step: 1
Training loss: 3.1524116669515307
Validation loss: 3.1116068763520013

Epoch: 5| Step: 2
Training loss: 3.787853811123893
Validation loss: 3.114386177195134

Epoch: 5| Step: 3
Training loss: 2.7129741131299396
Validation loss: 3.1078389715192287

Epoch: 5| Step: 4
Training loss: 3.296678582437681
Validation loss: 3.1030529942824763

Epoch: 5| Step: 5
Training loss: 3.196669162302432
Validation loss: 3.1005403179455526

Epoch: 5| Step: 6
Training loss: 2.745305736448742
Validation loss: 3.104752775893352

Epoch: 5| Step: 7
Training loss: 2.938381955470621
Validation loss: 3.1075607220006156

Epoch: 5| Step: 8
Training loss: 3.92010105333671
Validation loss: 3.1074506642641566

Epoch: 5| Step: 9
Training loss: 3.226798208277195
Validation loss: 3.1061663488457416

Epoch: 5| Step: 10
Training loss: 4.093391693974904
Validation loss: 3.104311666648498

Epoch: 256| Step: 0
Training loss: 3.2221642320902903
Validation loss: 3.1043920801948417

Epoch: 5| Step: 1
Training loss: 3.115314886792677
Validation loss: 3.09787911146427

Epoch: 5| Step: 2
Training loss: 4.033196504231854
Validation loss: 3.096849387419873

Epoch: 5| Step: 3
Training loss: 2.8162488747910692
Validation loss: 3.096023781360894

Epoch: 5| Step: 4
Training loss: 3.3389901481361974
Validation loss: 3.09695426078147

Epoch: 5| Step: 5
Training loss: 3.964505065583731
Validation loss: 3.0955196840869146

Epoch: 5| Step: 6
Training loss: 3.566946634255407
Validation loss: 3.0941162124651456

Epoch: 5| Step: 7
Training loss: 3.438762779641957
Validation loss: 3.095491948288638

Epoch: 5| Step: 8
Training loss: 3.2046886070245835
Validation loss: 3.093931424615801

Epoch: 5| Step: 9
Training loss: 2.759159699245617
Validation loss: 3.0949193079471016

Epoch: 5| Step: 10
Training loss: 3.145403211548595
Validation loss: 3.097004568734839

Epoch: 257| Step: 0
Training loss: 3.4803946301994815
Validation loss: 3.095354315755081

Epoch: 5| Step: 1
Training loss: 3.245450576981852
Validation loss: 3.096234698242568

Epoch: 5| Step: 2
Training loss: 3.8376585290825243
Validation loss: 3.0977974927364156

Epoch: 5| Step: 3
Training loss: 2.793019797118733
Validation loss: 3.0948032936606222

Epoch: 5| Step: 4
Training loss: 3.7838283607073744
Validation loss: 3.097525240421454

Epoch: 5| Step: 5
Training loss: 2.9827609665716786
Validation loss: 3.097014646120786

Epoch: 5| Step: 6
Training loss: 2.847370735161579
Validation loss: 3.093184246108931

Epoch: 5| Step: 7
Training loss: 3.1666219273133938
Validation loss: 3.0943330737573573

Epoch: 5| Step: 8
Training loss: 3.5874045701576223
Validation loss: 3.0931439577287527

Epoch: 5| Step: 9
Training loss: 3.6135392380449027
Validation loss: 3.094824561974276

Epoch: 5| Step: 10
Training loss: 3.3092456882417305
Validation loss: 3.092595350325009

Epoch: 258| Step: 0
Training loss: 3.164914466220408
Validation loss: 3.096813398468959

Epoch: 5| Step: 1
Training loss: 3.36141763730865
Validation loss: 3.091944557488298

Epoch: 5| Step: 2
Training loss: 3.0363977512359837
Validation loss: 3.0932605514098768

Epoch: 5| Step: 3
Training loss: 3.2977789773993127
Validation loss: 3.0904885389824157

Epoch: 5| Step: 4
Training loss: 2.8932733724097206
Validation loss: 3.0927665890118035

Epoch: 5| Step: 5
Training loss: 2.7274521739763147
Validation loss: 3.091877790640691

Epoch: 5| Step: 6
Training loss: 3.604471285668197
Validation loss: 3.093511188330949

Epoch: 5| Step: 7
Training loss: 3.573937243439502
Validation loss: 3.0886276546629046

Epoch: 5| Step: 8
Training loss: 3.2949188359036814
Validation loss: 3.087815488821809

Epoch: 5| Step: 9
Training loss: 4.33383628176172
Validation loss: 3.077968460382613

Epoch: 5| Step: 10
Training loss: 3.197601617625545
Validation loss: 3.0447065295175033

Epoch: 259| Step: 0
Training loss: 3.5226856452965842
Validation loss: 3.0038287894762488

Epoch: 5| Step: 1
Training loss: 3.6234053688878305
Validation loss: 3.005595301178539

Epoch: 5| Step: 2
Training loss: 2.4269277716515334
Validation loss: 3.0089473693436015

Epoch: 5| Step: 3
Training loss: 3.0828232901800523
Validation loss: 3.0050687133501603

Epoch: 5| Step: 4
Training loss: 4.0976534571606305
Validation loss: 2.9980071363627605

Epoch: 5| Step: 5
Training loss: 3.228045623778316
Validation loss: 3.000207078616329

Epoch: 5| Step: 6
Training loss: 2.6487817231133293
Validation loss: 2.995447757255774

Epoch: 5| Step: 7
Training loss: 3.413970876201888
Validation loss: 3.000679926065017

Epoch: 5| Step: 8
Training loss: 3.3644684259183446
Validation loss: 2.995640795558128

Epoch: 5| Step: 9
Training loss: 2.7514503295840567
Validation loss: 2.9930779129245373

Epoch: 5| Step: 10
Training loss: 3.4953446081099586
Validation loss: 2.9982925575714683

Epoch: 260| Step: 0
Training loss: 3.636185849785416
Validation loss: 2.994421544184896

Epoch: 5| Step: 1
Training loss: 3.6156309663530477
Validation loss: 2.994556912088776

Epoch: 5| Step: 2
Training loss: 3.356676446116905
Validation loss: 2.9946492042559254

Epoch: 5| Step: 3
Training loss: 3.7994167783799346
Validation loss: 2.9944083972877613

Epoch: 5| Step: 4
Training loss: 3.697172636302572
Validation loss: 2.9960035739506448

Epoch: 5| Step: 5
Training loss: 3.3200521209945792
Validation loss: 2.9946652478914815

Epoch: 5| Step: 6
Training loss: 3.2133830241032153
Validation loss: 2.994007752246676

Epoch: 5| Step: 7
Training loss: 2.3943132858269105
Validation loss: 2.9908878221173194

Epoch: 5| Step: 8
Training loss: 2.671099366156762
Validation loss: 2.99720965316177

Epoch: 5| Step: 9
Training loss: 3.244165318238352
Validation loss: 2.9930023357903477

Epoch: 5| Step: 10
Training loss: 2.5259875943928085
Validation loss: 2.9926586976923297

Epoch: 261| Step: 0
Training loss: 2.9529131455093416
Validation loss: 2.9924198286307013

Epoch: 5| Step: 1
Training loss: 3.574805573198273
Validation loss: 2.9960834683595365

Epoch: 5| Step: 2
Training loss: 3.9085832875134807
Validation loss: 2.9972240686410148

Epoch: 5| Step: 3
Training loss: 3.39251037775981
Validation loss: 2.9964842174420045

Epoch: 5| Step: 4
Training loss: 2.7959339967012653
Validation loss: 2.9968661548953137

Epoch: 5| Step: 5
Training loss: 3.4197150951639648
Validation loss: 2.995533847234289

Epoch: 5| Step: 6
Training loss: 3.285934301674992
Validation loss: 2.995699861629242

Epoch: 5| Step: 7
Training loss: 2.6857532768694683
Validation loss: 2.988033828824777

Epoch: 5| Step: 8
Training loss: 3.384693494975821
Validation loss: 2.9907488276676095

Epoch: 5| Step: 9
Training loss: 2.797838950669655
Validation loss: 2.987843096210829

Epoch: 5| Step: 10
Training loss: 3.532897294927888
Validation loss: 2.988891141260134

Epoch: 262| Step: 0
Training loss: 2.9554745647101965
Validation loss: 2.989730080739612

Epoch: 5| Step: 1
Training loss: 2.9772873043574393
Validation loss: 2.9908419582202455

Epoch: 5| Step: 2
Training loss: 3.3513613198106307
Validation loss: 2.9932240030933155

Epoch: 5| Step: 3
Training loss: 3.289636847213967
Validation loss: 2.9927908165654578

Epoch: 5| Step: 4
Training loss: 2.7314289025695837
Validation loss: 2.989422573486403

Epoch: 5| Step: 5
Training loss: 3.366821977287425
Validation loss: 2.9926549027606777

Epoch: 5| Step: 6
Training loss: 3.902886980066782
Validation loss: 2.991400401265302

Epoch: 5| Step: 7
Training loss: 3.8052926649510384
Validation loss: 2.989601707737894

Epoch: 5| Step: 8
Training loss: 2.9742408168446066
Validation loss: 2.9899169786004705

Epoch: 5| Step: 9
Training loss: 3.096663981156952
Validation loss: 2.990468849380281

Epoch: 5| Step: 10
Training loss: 3.36167367758246
Validation loss: 2.988417033301506

Epoch: 263| Step: 0
Training loss: 2.8300119080309836
Validation loss: 2.9832693933081162

Epoch: 5| Step: 1
Training loss: 3.7779001577663194
Validation loss: 2.9889834171054823

Epoch: 5| Step: 2
Training loss: 2.3983728853648714
Validation loss: 2.9875855372389397

Epoch: 5| Step: 3
Training loss: 3.5194066033005433
Validation loss: 2.989080390130247

Epoch: 5| Step: 4
Training loss: 3.191502321027593
Validation loss: 2.990587733285965

Epoch: 5| Step: 5
Training loss: 2.854988443915768
Validation loss: 2.9925802692690846

Epoch: 5| Step: 6
Training loss: 3.3060983662726526
Validation loss: 2.998522854997821

Epoch: 5| Step: 7
Training loss: 3.7690094107300114
Validation loss: 2.992416190174528

Epoch: 5| Step: 8
Training loss: 3.2394976016820434
Validation loss: 2.9948332108036615

Epoch: 5| Step: 9
Training loss: 3.440610553319608
Validation loss: 2.996144701613543

Epoch: 5| Step: 10
Training loss: 3.375378905325534
Validation loss: 2.9906714823942298

Epoch: 264| Step: 0
Training loss: 2.911922374633904
Validation loss: 2.995965976549225

Epoch: 5| Step: 1
Training loss: 3.190630852435178
Validation loss: 2.989774715790233

Epoch: 5| Step: 2
Training loss: 3.48696132861421
Validation loss: 2.99147195506036

Epoch: 5| Step: 3
Training loss: 3.6345751352220272
Validation loss: 2.9877305694121263

Epoch: 5| Step: 4
Training loss: 3.3214056392176867
Validation loss: 2.9867940808657476

Epoch: 5| Step: 5
Training loss: 3.3217981223741013
Validation loss: 2.9856110650088254

Epoch: 5| Step: 6
Training loss: 3.1172558769814973
Validation loss: 2.9853138180646077

Epoch: 5| Step: 7
Training loss: 3.3588328789046122
Validation loss: 2.9851750261099115

Epoch: 5| Step: 8
Training loss: 3.3165622490272004
Validation loss: 2.9840217737359493

Epoch: 5| Step: 9
Training loss: 2.768684203870886
Validation loss: 2.9829568713269263

Epoch: 5| Step: 10
Training loss: 3.3566942031119793
Validation loss: 2.988045563244844

Epoch: 265| Step: 0
Training loss: 3.2640967192437977
Validation loss: 2.9837959662869356

Epoch: 5| Step: 1
Training loss: 3.113209722408017
Validation loss: 2.9870668776320626

Epoch: 5| Step: 2
Training loss: 3.1864415823745684
Validation loss: 2.986675155824618

Epoch: 5| Step: 3
Training loss: 2.557821608651266
Validation loss: 2.985836656197607

Epoch: 5| Step: 4
Training loss: 3.055873162688201
Validation loss: 2.9870827010866896

Epoch: 5| Step: 5
Training loss: 3.4686611954602315
Validation loss: 2.9901858835869977

Epoch: 5| Step: 6
Training loss: 3.450962407869339
Validation loss: 2.991259237458856

Epoch: 5| Step: 7
Training loss: 3.686581642752429
Validation loss: 2.9914048439681844

Epoch: 5| Step: 8
Training loss: 3.635574439413475
Validation loss: 2.99374281797837

Epoch: 5| Step: 9
Training loss: 3.456482648693642
Validation loss: 2.9866991743402163

Epoch: 5| Step: 10
Training loss: 2.683521341960061
Validation loss: 2.9831076973618615

Epoch: 266| Step: 0
Training loss: 3.0956510617664614
Validation loss: 2.9865279324036753

Epoch: 5| Step: 1
Training loss: 2.987014482062691
Validation loss: 2.9854355306283926

Epoch: 5| Step: 2
Training loss: 3.0450094135809147
Validation loss: 2.9857364575634504

Epoch: 5| Step: 3
Training loss: 3.716385803102256
Validation loss: 2.9884124437519954

Epoch: 5| Step: 4
Training loss: 3.040704827667267
Validation loss: 2.989564885639975

Epoch: 5| Step: 5
Training loss: 2.7694735716071683
Validation loss: 2.9823454897127886

Epoch: 5| Step: 6
Training loss: 3.4286006517527263
Validation loss: 2.984961820262641

Epoch: 5| Step: 7
Training loss: 2.9384684488090045
Validation loss: 2.9819391239211384

Epoch: 5| Step: 8
Training loss: 3.5092510850315928
Validation loss: 2.993797922496918

Epoch: 5| Step: 9
Training loss: 3.328149356663368
Validation loss: 2.98372150214196

Epoch: 5| Step: 10
Training loss: 3.878855233370763
Validation loss: 2.9894812658933887

Epoch: 267| Step: 0
Training loss: 3.2641120581838714
Validation loss: 2.987630865054306

Epoch: 5| Step: 1
Training loss: 3.256332536994909
Validation loss: 2.981778022158115

Epoch: 5| Step: 2
Training loss: 3.1607887191567294
Validation loss: 2.9799188710816984

Epoch: 5| Step: 3
Training loss: 3.5866420610522156
Validation loss: 2.979493417912809

Epoch: 5| Step: 4
Training loss: 3.377688714437099
Validation loss: 2.9789506799659824

Epoch: 5| Step: 5
Training loss: 3.372421127087015
Validation loss: 2.9787468735284635

Epoch: 5| Step: 6
Training loss: 3.0347180535011167
Validation loss: 2.9792940129906893

Epoch: 5| Step: 7
Training loss: 2.7926056739258276
Validation loss: 2.9786391516558623

Epoch: 5| Step: 8
Training loss: 3.537645607906981
Validation loss: 2.978234074904113

Epoch: 5| Step: 9
Training loss: 3.135003976287024
Validation loss: 2.978934321919063

Epoch: 5| Step: 10
Training loss: 3.2256064857523667
Validation loss: 2.982008648882151

Epoch: 268| Step: 0
Training loss: 3.5126867604410075
Validation loss: 2.979924609313951

Epoch: 5| Step: 1
Training loss: 3.5955370896280052
Validation loss: 2.9779015116538394

Epoch: 5| Step: 2
Training loss: 3.0291849554700025
Validation loss: 2.9793651717474035

Epoch: 5| Step: 3
Training loss: 3.0013141932487972
Validation loss: 2.979565086431109

Epoch: 5| Step: 4
Training loss: 3.655887944480473
Validation loss: 2.977957384503558

Epoch: 5| Step: 5
Training loss: 2.6192241885788663
Validation loss: 2.9801290345870544

Epoch: 5| Step: 6
Training loss: 3.4354488842442237
Validation loss: 2.975848702889643

Epoch: 5| Step: 7
Training loss: 2.849248077517781
Validation loss: 2.981304644717205

Epoch: 5| Step: 8
Training loss: 3.2167181620321905
Validation loss: 2.9816020385637203

Epoch: 5| Step: 9
Training loss: 3.594855097157
Validation loss: 2.9823054266689883

Epoch: 5| Step: 10
Training loss: 3.059207625676471
Validation loss: 2.9843957555919203

Epoch: 269| Step: 0
Training loss: 3.6755542259362537
Validation loss: 2.987243237855154

Epoch: 5| Step: 1
Training loss: 3.4120442515787284
Validation loss: 3.001065958689473

Epoch: 5| Step: 2
Training loss: 3.1425107542110386
Validation loss: 2.9909751996079352

Epoch: 5| Step: 3
Training loss: 3.0590713927014734
Validation loss: 2.9993964258046537

Epoch: 5| Step: 4
Training loss: 2.9842201712025878
Validation loss: 2.9895028367206193

Epoch: 5| Step: 5
Training loss: 2.72669147525249
Validation loss: 2.9860262626376737

Epoch: 5| Step: 6
Training loss: 3.166015323777746
Validation loss: 2.9772905092430735

Epoch: 5| Step: 7
Training loss: 3.449193174584895
Validation loss: 2.9751698317687922

Epoch: 5| Step: 8
Training loss: 3.7299431076006373
Validation loss: 2.9756433684192194

Epoch: 5| Step: 9
Training loss: 2.275601959237596
Validation loss: 2.9746260791574266

Epoch: 5| Step: 10
Training loss: 3.9472697322622126
Validation loss: 2.9752637231127657

Epoch: 270| Step: 0
Training loss: 3.2338095645262697
Validation loss: 2.9757268213404395

Epoch: 5| Step: 1
Training loss: 3.2490347382486817
Validation loss: 2.9745155500500586

Epoch: 5| Step: 2
Training loss: 3.3186160073108026
Validation loss: 2.9760631551214467

Epoch: 5| Step: 3
Training loss: 3.2003346268215163
Validation loss: 2.97628480835006

Epoch: 5| Step: 4
Training loss: 3.2380500591289203
Validation loss: 2.975209012905449

Epoch: 5| Step: 5
Training loss: 3.460785115419954
Validation loss: 2.9723545300963368

Epoch: 5| Step: 6
Training loss: 3.567603086975042
Validation loss: 2.974193831693286

Epoch: 5| Step: 7
Training loss: 3.1951034216342613
Validation loss: 2.9739533536704927

Epoch: 5| Step: 8
Training loss: 3.1732149347555647
Validation loss: 2.9741477043268136

Epoch: 5| Step: 9
Training loss: 2.8411611993072867
Validation loss: 2.9751703582544646

Epoch: 5| Step: 10
Training loss: 3.293491887614381
Validation loss: 2.973380408048443

Epoch: 271| Step: 0
Training loss: 2.630458605854085
Validation loss: 2.97236411412426

Epoch: 5| Step: 1
Training loss: 3.069839712922665
Validation loss: 2.97308709388161

Epoch: 5| Step: 2
Training loss: 3.6411145581016435
Validation loss: 2.9746458909835543

Epoch: 5| Step: 3
Training loss: 3.0651759698582217
Validation loss: 2.977761238650448

Epoch: 5| Step: 4
Training loss: 3.6559275949599774
Validation loss: 2.9837878409382945

Epoch: 5| Step: 5
Training loss: 3.2435116189672404
Validation loss: 2.9831006400766618

Epoch: 5| Step: 6
Training loss: 3.295678522755823
Validation loss: 2.9844367904550073

Epoch: 5| Step: 7
Training loss: 3.514378305427181
Validation loss: 2.978623537246749

Epoch: 5| Step: 8
Training loss: 3.1583279860425253
Validation loss: 2.9761328802322216

Epoch: 5| Step: 9
Training loss: 3.08699500398074
Validation loss: 2.980369723095267

Epoch: 5| Step: 10
Training loss: 3.2446348949460346
Validation loss: 2.9742309095989077

Epoch: 272| Step: 0
Training loss: 2.8770601935058058
Validation loss: 2.9734015042177644

Epoch: 5| Step: 1
Training loss: 3.1214112083348704
Validation loss: 2.9769981383511506

Epoch: 5| Step: 2
Training loss: 2.9082211608532407
Validation loss: 2.971736262222112

Epoch: 5| Step: 3
Training loss: 3.110450596931993
Validation loss: 2.972969323607502

Epoch: 5| Step: 4
Training loss: 2.994019746673231
Validation loss: 2.9741040501501903

Epoch: 5| Step: 5
Training loss: 3.616996348131618
Validation loss: 2.973554094351224

Epoch: 5| Step: 6
Training loss: 3.3556071598163486
Validation loss: 2.9715830248779533

Epoch: 5| Step: 7
Training loss: 3.901838940110546
Validation loss: 2.9708526781444675

Epoch: 5| Step: 8
Training loss: 3.3825975310142544
Validation loss: 2.968024776112314

Epoch: 5| Step: 9
Training loss: 3.132324789616569
Validation loss: 2.9704653833095294

Epoch: 5| Step: 10
Training loss: 3.1784014526279374
Validation loss: 2.970193287775517

Epoch: 273| Step: 0
Training loss: 3.1814646710285706
Validation loss: 2.972296414621559

Epoch: 5| Step: 1
Training loss: 3.416924784764981
Validation loss: 2.9758736426943213

Epoch: 5| Step: 2
Training loss: 3.2853159100248046
Validation loss: 2.9759047374706475

Epoch: 5| Step: 3
Training loss: 2.8890419414112696
Validation loss: 2.9768450779994438

Epoch: 5| Step: 4
Training loss: 2.5790342634867747
Validation loss: 2.9714997549523394

Epoch: 5| Step: 5
Training loss: 3.4667052694763423
Validation loss: 2.9750917790216715

Epoch: 5| Step: 6
Training loss: 3.5733841719023776
Validation loss: 2.973579603446186

Epoch: 5| Step: 7
Training loss: 3.140847573056173
Validation loss: 2.973479057305565

Epoch: 5| Step: 8
Training loss: 4.147953558386856
Validation loss: 2.9735609311687914

Epoch: 5| Step: 9
Training loss: 3.0156528293728853
Validation loss: 2.974232424907983

Epoch: 5| Step: 10
Training loss: 2.5892858120020956
Validation loss: 2.9793857540086073

Epoch: 274| Step: 0
Training loss: 2.914277505996642
Validation loss: 2.9737876649305544

Epoch: 5| Step: 1
Training loss: 3.4201653098147116
Validation loss: 2.976986706568799

Epoch: 5| Step: 2
Training loss: 3.452282833089368
Validation loss: 2.9786265711409374

Epoch: 5| Step: 3
Training loss: 3.5852268154691935
Validation loss: 2.970301397079026

Epoch: 5| Step: 4
Training loss: 2.955616702098173
Validation loss: 2.9680962767336516

Epoch: 5| Step: 5
Training loss: 3.580377794076406
Validation loss: 2.965588202952149

Epoch: 5| Step: 6
Training loss: 2.4698616132695355
Validation loss: 2.9670986416398177

Epoch: 5| Step: 7
Training loss: 3.051062577057556
Validation loss: 2.964851705043906

Epoch: 5| Step: 8
Training loss: 3.291645693812776
Validation loss: 2.9662270888337594

Epoch: 5| Step: 9
Training loss: 3.3527771498258043
Validation loss: 2.967754861721924

Epoch: 5| Step: 10
Training loss: 3.5297691818722257
Validation loss: 2.9658958311478845

Epoch: 275| Step: 0
Training loss: 2.943323733817057
Validation loss: 2.9660077273238215

Epoch: 5| Step: 1
Training loss: 3.116547712480115
Validation loss: 2.967237272574498

Epoch: 5| Step: 2
Training loss: 3.1186796742309757
Validation loss: 2.9642874631028833

Epoch: 5| Step: 3
Training loss: 3.5420811728465766
Validation loss: 2.963678772294809

Epoch: 5| Step: 4
Training loss: 3.2298754662755846
Validation loss: 2.9645515049373974

Epoch: 5| Step: 5
Training loss: 3.3567132385063765
Validation loss: 2.967218389316143

Epoch: 5| Step: 6
Training loss: 3.2779290241612866
Validation loss: 2.966158348662895

Epoch: 5| Step: 7
Training loss: 3.2116426682049894
Validation loss: 2.9649847119455015

Epoch: 5| Step: 8
Training loss: 3.443800129326543
Validation loss: 2.967500868793365

Epoch: 5| Step: 9
Training loss: 3.2378055973235282
Validation loss: 2.9712133147817315

Epoch: 5| Step: 10
Training loss: 3.1427398696917
Validation loss: 2.9734441047801896

Epoch: 276| Step: 0
Training loss: 3.2239345535280535
Validation loss: 2.9696266697672744

Epoch: 5| Step: 1
Training loss: 3.809001630803263
Validation loss: 2.9794951060727732

Epoch: 5| Step: 2
Training loss: 3.7987786689422105
Validation loss: 2.9866263096262977

Epoch: 5| Step: 3
Training loss: 2.8242780117291253
Validation loss: 2.966821714619398

Epoch: 5| Step: 4
Training loss: 3.1086297603802198
Validation loss: 2.9685188881379365

Epoch: 5| Step: 5
Training loss: 3.456687229086752
Validation loss: 2.9635067503423365

Epoch: 5| Step: 6
Training loss: 3.0159021754197632
Validation loss: 2.962255466999614

Epoch: 5| Step: 7
Training loss: 3.347328624027872
Validation loss: 2.9630835002162565

Epoch: 5| Step: 8
Training loss: 2.96285618439525
Validation loss: 2.9647105050297724

Epoch: 5| Step: 9
Training loss: 2.780341439308223
Validation loss: 2.9665072645653785

Epoch: 5| Step: 10
Training loss: 3.186367207612846
Validation loss: 2.963738104269763

Epoch: 277| Step: 0
Training loss: 3.2538870528113932
Validation loss: 2.9642488580292228

Epoch: 5| Step: 1
Training loss: 3.8498324518778397
Validation loss: 2.9646507644712554

Epoch: 5| Step: 2
Training loss: 3.381245521077065
Validation loss: 2.962772773897657

Epoch: 5| Step: 3
Training loss: 2.669425064221214
Validation loss: 2.964099395489629

Epoch: 5| Step: 4
Training loss: 3.390285914469183
Validation loss: 2.964430428434845

Epoch: 5| Step: 5
Training loss: 2.618853684878698
Validation loss: 2.965277109702159

Epoch: 5| Step: 6
Training loss: 3.2538145127937135
Validation loss: 2.9639451691009246

Epoch: 5| Step: 7
Training loss: 3.3982193098510045
Validation loss: 2.961731051562994

Epoch: 5| Step: 8
Training loss: 2.776727921984484
Validation loss: 2.960431805474

Epoch: 5| Step: 9
Training loss: 2.938237036910195
Validation loss: 2.962919740514019

Epoch: 5| Step: 10
Training loss: 3.9536010696770933
Validation loss: 2.9640712291205342

Epoch: 278| Step: 0
Training loss: 2.636484545443386
Validation loss: 2.9663391064718168

Epoch: 5| Step: 1
Training loss: 3.567164262185453
Validation loss: 2.9635137574006456

Epoch: 5| Step: 2
Training loss: 3.0363138904971563
Validation loss: 2.964574405557939

Epoch: 5| Step: 3
Training loss: 3.6492537375724536
Validation loss: 2.9647851085623094

Epoch: 5| Step: 4
Training loss: 3.577672671583458
Validation loss: 2.9631317620479996

Epoch: 5| Step: 5
Training loss: 3.2130014881613804
Validation loss: 2.9698016667352056

Epoch: 5| Step: 6
Training loss: 2.8095603839273213
Validation loss: 2.965261155189373

Epoch: 5| Step: 7
Training loss: 3.148266354587666
Validation loss: 2.963324612918031

Epoch: 5| Step: 8
Training loss: 3.2501910226877375
Validation loss: 2.9613019282975745

Epoch: 5| Step: 9
Training loss: 3.318849200761466
Validation loss: 2.960928007993723

Epoch: 5| Step: 10
Training loss: 3.2690669998299886
Validation loss: 2.9625011071810166

Epoch: 279| Step: 0
Training loss: 3.0192191886773214
Validation loss: 2.9589010554995165

Epoch: 5| Step: 1
Training loss: 3.270696471118799
Validation loss: 2.960013833599807

Epoch: 5| Step: 2
Training loss: 2.9869412079150495
Validation loss: 2.963074651003748

Epoch: 5| Step: 3
Training loss: 3.2446303391291984
Validation loss: 2.9600633883001066

Epoch: 5| Step: 4
Training loss: 3.1490483981035657
Validation loss: 2.96034149051148

Epoch: 5| Step: 5
Training loss: 2.976500342813937
Validation loss: 2.9603591584867237

Epoch: 5| Step: 6
Training loss: 3.9208739929577363
Validation loss: 2.962376472296905

Epoch: 5| Step: 7
Training loss: 2.9216112639996594
Validation loss: 2.959199781688569

Epoch: 5| Step: 8
Training loss: 3.408042506064813
Validation loss: 2.960728540681836

Epoch: 5| Step: 9
Training loss: 3.265782694682351
Validation loss: 2.957864103377457

Epoch: 5| Step: 10
Training loss: 3.3420141830554297
Validation loss: 2.959956877191166

Epoch: 280| Step: 0
Training loss: 2.974711165311484
Validation loss: 2.9578399997898437

Epoch: 5| Step: 1
Training loss: 3.1429128332281993
Validation loss: 2.9577712103121545

Epoch: 5| Step: 2
Training loss: 3.2847993092074925
Validation loss: 2.957812504472354

Epoch: 5| Step: 3
Training loss: 3.156222806001352
Validation loss: 2.9570696996183456

Epoch: 5| Step: 4
Training loss: 3.174152477416631
Validation loss: 2.956625218390208

Epoch: 5| Step: 5
Training loss: 3.464781819750225
Validation loss: 2.962730358225094

Epoch: 5| Step: 6
Training loss: 3.473525325816254
Validation loss: 2.9621288009026276

Epoch: 5| Step: 7
Training loss: 3.627394575904551
Validation loss: 2.9581367843920567

Epoch: 5| Step: 8
Training loss: 3.1478461758597733
Validation loss: 2.9589277037511756

Epoch: 5| Step: 9
Training loss: 3.389628883685677
Validation loss: 2.961443589487877

Epoch: 5| Step: 10
Training loss: 2.530877921932446
Validation loss: 2.9604965792078057

Epoch: 281| Step: 0
Training loss: 3.4693388567955545
Validation loss: 2.9584755459656704

Epoch: 5| Step: 1
Training loss: 3.1888249953186585
Validation loss: 2.958841584941139

Epoch: 5| Step: 2
Training loss: 3.433714846058561
Validation loss: 2.9574316251720663

Epoch: 5| Step: 3
Training loss: 2.8781432508455334
Validation loss: 2.953810308097823

Epoch: 5| Step: 4
Training loss: 2.7626260996212633
Validation loss: 2.9561559121412992

Epoch: 5| Step: 5
Training loss: 3.487064298806552
Validation loss: 2.9570594938292682

Epoch: 5| Step: 6
Training loss: 2.9330999006965004
Validation loss: 2.9591072528377214

Epoch: 5| Step: 7
Training loss: 3.211659296961354
Validation loss: 2.957256396401747

Epoch: 5| Step: 8
Training loss: 3.206042342869548
Validation loss: 2.9567870654813064

Epoch: 5| Step: 9
Training loss: 3.3696300029545565
Validation loss: 2.959151180231651

Epoch: 5| Step: 10
Training loss: 3.555670633705477
Validation loss: 2.9573264600287086

Epoch: 282| Step: 0
Training loss: 3.651527158462505
Validation loss: 2.95872911448553

Epoch: 5| Step: 1
Training loss: 2.9044039205642633
Validation loss: 2.9549023888070174

Epoch: 5| Step: 2
Training loss: 3.1650545801937553
Validation loss: 2.9574444943541436

Epoch: 5| Step: 3
Training loss: 3.054415093102789
Validation loss: 2.956045539724968

Epoch: 5| Step: 4
Training loss: 3.515447179747719
Validation loss: 2.957322260869697

Epoch: 5| Step: 5
Training loss: 3.244263648376658
Validation loss: 2.9568157546941487

Epoch: 5| Step: 6
Training loss: 3.7118060250079283
Validation loss: 2.9556374826974925

Epoch: 5| Step: 7
Training loss: 3.1450889329814355
Validation loss: 2.956488048684595

Epoch: 5| Step: 8
Training loss: 3.120381719273238
Validation loss: 2.953412020047153

Epoch: 5| Step: 9
Training loss: 3.1266705434757536
Validation loss: 2.9563135982081783

Epoch: 5| Step: 10
Training loss: 2.6824638731160033
Validation loss: 2.9594847815474608

Epoch: 283| Step: 0
Training loss: 3.725258525095458
Validation loss: 2.9542387432185806

Epoch: 5| Step: 1
Training loss: 3.6863000501440983
Validation loss: 2.9554062493141524

Epoch: 5| Step: 2
Training loss: 3.1973996981949395
Validation loss: 2.95700457858887

Epoch: 5| Step: 3
Training loss: 2.748296036367921
Validation loss: 2.95318891485727

Epoch: 5| Step: 4
Training loss: 2.8848910811307578
Validation loss: 2.9561691571787305

Epoch: 5| Step: 5
Training loss: 3.4099154567586
Validation loss: 2.954894708032137

Epoch: 5| Step: 6
Training loss: 3.4042230577284474
Validation loss: 2.953289012018962

Epoch: 5| Step: 7
Training loss: 3.2881201619654847
Validation loss: 2.9531143100603856

Epoch: 5| Step: 8
Training loss: 2.773925050675951
Validation loss: 2.952125833874547

Epoch: 5| Step: 9
Training loss: 3.5611115811870526
Validation loss: 2.9557394285115595

Epoch: 5| Step: 10
Training loss: 2.4842510072487847
Validation loss: 2.956766989196092

Epoch: 284| Step: 0
Training loss: 3.483763636852192
Validation loss: 2.95426405723247

Epoch: 5| Step: 1
Training loss: 3.6782983316111006
Validation loss: 2.9565436758760963

Epoch: 5| Step: 2
Training loss: 3.1014408885261657
Validation loss: 2.95974988413616

Epoch: 5| Step: 3
Training loss: 3.56928744302727
Validation loss: 2.9653295357615588

Epoch: 5| Step: 4
Training loss: 2.8123130736221675
Validation loss: 2.960830106862108

Epoch: 5| Step: 5
Training loss: 2.667776254436978
Validation loss: 2.9702721398735656

Epoch: 5| Step: 6
Training loss: 3.2397210356627952
Validation loss: 2.9630017954051726

Epoch: 5| Step: 7
Training loss: 2.656529580156751
Validation loss: 2.957141140889516

Epoch: 5| Step: 8
Training loss: 3.2489528436217916
Validation loss: 2.956550477458017

Epoch: 5| Step: 9
Training loss: 3.2139142200201083
Validation loss: 2.949052672153798

Epoch: 5| Step: 10
Training loss: 3.6943555564672033
Validation loss: 2.953568134004144

Epoch: 285| Step: 0
Training loss: 3.4748539187237393
Validation loss: 2.9523168793831993

Epoch: 5| Step: 1
Training loss: 3.1252262796494
Validation loss: 2.950621973553961

Epoch: 5| Step: 2
Training loss: 3.230541519028126
Validation loss: 2.9505322949614308

Epoch: 5| Step: 3
Training loss: 2.9471578711042805
Validation loss: 2.950674055291093

Epoch: 5| Step: 4
Training loss: 3.69209300924007
Validation loss: 2.9504812864066894

Epoch: 5| Step: 5
Training loss: 2.3590267505430775
Validation loss: 2.951599671672462

Epoch: 5| Step: 6
Training loss: 3.3469208985786882
Validation loss: 2.949159523181044

Epoch: 5| Step: 7
Training loss: 3.040861171163932
Validation loss: 2.949260310810779

Epoch: 5| Step: 8
Training loss: 2.9192034089432077
Validation loss: 2.9494380129191007

Epoch: 5| Step: 9
Training loss: 3.7918568797485728
Validation loss: 2.9471672013020953

Epoch: 5| Step: 10
Training loss: 3.3720694640528905
Validation loss: 2.950475843681183

Epoch: 286| Step: 0
Training loss: 2.973565141881902
Validation loss: 2.9498412524586772

Epoch: 5| Step: 1
Training loss: 3.3081743319054877
Validation loss: 2.9482354154456942

Epoch: 5| Step: 2
Training loss: 2.9801807589401403
Validation loss: 2.94603700078373

Epoch: 5| Step: 3
Training loss: 3.3734439512317453
Validation loss: 2.9517809562364676

Epoch: 5| Step: 4
Training loss: 3.1332689366588293
Validation loss: 2.948458064231285

Epoch: 5| Step: 5
Training loss: 3.1919180974371932
Validation loss: 2.954966748456562

Epoch: 5| Step: 6
Training loss: 3.7875548204540004
Validation loss: 2.9530522010408444

Epoch: 5| Step: 7
Training loss: 3.28980846508402
Validation loss: 2.9507938635161097

Epoch: 5| Step: 8
Training loss: 2.886434621081403
Validation loss: 2.950333168400052

Epoch: 5| Step: 9
Training loss: 3.3043862063450744
Validation loss: 2.949185787441301

Epoch: 5| Step: 10
Training loss: 3.153076842954463
Validation loss: 2.948378321796213

Epoch: 287| Step: 0
Training loss: 2.8197561122051167
Validation loss: 2.9476437467150176

Epoch: 5| Step: 1
Training loss: 3.053315071428928
Validation loss: 2.947411496531306

Epoch: 5| Step: 2
Training loss: 2.569486630296785
Validation loss: 2.9491622335898118

Epoch: 5| Step: 3
Training loss: 4.255626320202147
Validation loss: 2.9449237492837033

Epoch: 5| Step: 4
Training loss: 2.8796680534645884
Validation loss: 2.950864045400317

Epoch: 5| Step: 5
Training loss: 3.0207308697039887
Validation loss: 2.9511778524198506

Epoch: 5| Step: 6
Training loss: 3.496504945921431
Validation loss: 2.9471160075018195

Epoch: 5| Step: 7
Training loss: 3.5917814751233212
Validation loss: 2.9565058385393725

Epoch: 5| Step: 8
Training loss: 3.2571625644403146
Validation loss: 2.950726060521888

Epoch: 5| Step: 9
Training loss: 2.959324379702529
Validation loss: 2.9461931470276395

Epoch: 5| Step: 10
Training loss: 3.222723277001827
Validation loss: 2.9453615387050633

Epoch: 288| Step: 0
Training loss: 3.5994799503234853
Validation loss: 2.9460458280766795

Epoch: 5| Step: 1
Training loss: 3.2072193308981563
Validation loss: 2.9428923419844026

Epoch: 5| Step: 2
Training loss: 3.6410357198579155
Validation loss: 2.9476961193738616

Epoch: 5| Step: 3
Training loss: 3.3486329548975617
Validation loss: 2.9478031787241465

Epoch: 5| Step: 4
Training loss: 3.1149095515411402
Validation loss: 2.944608214476452

Epoch: 5| Step: 5
Training loss: 2.01013927489614
Validation loss: 2.9423351739842007

Epoch: 5| Step: 6
Training loss: 2.9759544892984313
Validation loss: 2.942505773741351

Epoch: 5| Step: 7
Training loss: 3.9295649424073247
Validation loss: 2.943139021611091

Epoch: 5| Step: 8
Training loss: 3.322536307223351
Validation loss: 2.9410180864993136

Epoch: 5| Step: 9
Training loss: 2.4417807329981067
Validation loss: 2.9425074500144177

Epoch: 5| Step: 10
Training loss: 3.43764578770218
Validation loss: 2.941647481892088

Epoch: 289| Step: 0
Training loss: 3.7421432842915645
Validation loss: 2.9449233375236004

Epoch: 5| Step: 1
Training loss: 2.8442157741196388
Validation loss: 2.946048993852151

Epoch: 5| Step: 2
Training loss: 3.5213719845660334
Validation loss: 2.944300261119984

Epoch: 5| Step: 3
Training loss: 2.775198707683193
Validation loss: 2.9460971187896514

Epoch: 5| Step: 4
Training loss: 2.9796613447044575
Validation loss: 2.943819100605895

Epoch: 5| Step: 5
Training loss: 3.202738073286147
Validation loss: 2.9477813184078214

Epoch: 5| Step: 6
Training loss: 3.2056383646364575
Validation loss: 2.9508668967226317

Epoch: 5| Step: 7
Training loss: 3.0432940445112138
Validation loss: 2.94701499517262

Epoch: 5| Step: 8
Training loss: 2.9359708011640864
Validation loss: 2.9448558594501675

Epoch: 5| Step: 9
Training loss: 3.7376737828503486
Validation loss: 2.9401782343027016

Epoch: 5| Step: 10
Training loss: 3.2859245789800346
Validation loss: 2.945014493538094

Epoch: 290| Step: 0
Training loss: 3.073488568035391
Validation loss: 2.946171897799582

Epoch: 5| Step: 1
Training loss: 3.635980221735476
Validation loss: 2.9438174416259715

Epoch: 5| Step: 2
Training loss: 2.8465746590294643
Validation loss: 2.9391174044016006

Epoch: 5| Step: 3
Training loss: 3.666207862817354
Validation loss: 2.940098949169681

Epoch: 5| Step: 4
Training loss: 3.778492828713669
Validation loss: 2.9412052957629093

Epoch: 5| Step: 5
Training loss: 2.6060682347718966
Validation loss: 2.9448173879077895

Epoch: 5| Step: 6
Training loss: 2.5999407137933894
Validation loss: 2.9411179293199767

Epoch: 5| Step: 7
Training loss: 3.251336483155316
Validation loss: 2.9466120266065077

Epoch: 5| Step: 8
Training loss: 3.2928937403415652
Validation loss: 2.938888558491647

Epoch: 5| Step: 9
Training loss: 2.9800425133456834
Validation loss: 2.9450473008299842

Epoch: 5| Step: 10
Training loss: 3.4575405974083733
Validation loss: 2.9491054848642686

Epoch: 291| Step: 0
Training loss: 2.6189441763691694
Validation loss: 2.94750242860505

Epoch: 5| Step: 1
Training loss: 2.834067492643117
Validation loss: 2.945083544419237

Epoch: 5| Step: 2
Training loss: 3.086214695323364
Validation loss: 2.949518781011065

Epoch: 5| Step: 3
Training loss: 3.5967923762213525
Validation loss: 2.9410899752059723

Epoch: 5| Step: 4
Training loss: 2.989712560609859
Validation loss: 2.942318802313841

Epoch: 5| Step: 5
Training loss: 3.3170060512888893
Validation loss: 2.941642290372426

Epoch: 5| Step: 6
Training loss: 2.6920193664511674
Validation loss: 2.93963096472328

Epoch: 5| Step: 7
Training loss: 3.6633284429275133
Validation loss: 2.938319098801807

Epoch: 5| Step: 8
Training loss: 3.438935274979814
Validation loss: 2.936675351964733

Epoch: 5| Step: 9
Training loss: 3.8753540123462655
Validation loss: 2.9373949966392265

Epoch: 5| Step: 10
Training loss: 2.9760289953111374
Validation loss: 2.941825772830229

Epoch: 292| Step: 0
Training loss: 2.953079142542431
Validation loss: 2.942424422817747

Epoch: 5| Step: 1
Training loss: 2.9990278894260345
Validation loss: 2.942288702250472

Epoch: 5| Step: 2
Training loss: 3.3430149304293035
Validation loss: 2.9383941621279495

Epoch: 5| Step: 3
Training loss: 3.526888829632904
Validation loss: 2.937499531344636

Epoch: 5| Step: 4
Training loss: 3.696039817801999
Validation loss: 2.9398090413486826

Epoch: 5| Step: 5
Training loss: 3.170618870250056
Validation loss: 2.9391654273928403

Epoch: 5| Step: 6
Training loss: 3.0329308323128226
Validation loss: 2.941296940923466

Epoch: 5| Step: 7
Training loss: 3.0992486043097474
Validation loss: 2.937743868683499

Epoch: 5| Step: 8
Training loss: 3.4171360592836
Validation loss: 2.9439676020827203

Epoch: 5| Step: 9
Training loss: 3.0772217330508296
Validation loss: 2.940319564391451

Epoch: 5| Step: 10
Training loss: 2.899357981153907
Validation loss: 2.938351862192435

Epoch: 293| Step: 0
Training loss: 3.257323742984994
Validation loss: 2.9397372538717184

Epoch: 5| Step: 1
Training loss: 3.5937113884219927
Validation loss: 2.938627070023028

Epoch: 5| Step: 2
Training loss: 3.557438517378992
Validation loss: 2.9369803924508817

Epoch: 5| Step: 3
Training loss: 3.1724582380186908
Validation loss: 2.9396563216794847

Epoch: 5| Step: 4
Training loss: 2.6058331053216985
Validation loss: 2.9389111749514685

Epoch: 5| Step: 5
Training loss: 3.342787274246487
Validation loss: 2.934614287447495

Epoch: 5| Step: 6
Training loss: 3.3323552286076743
Validation loss: 2.9346893747763723

Epoch: 5| Step: 7
Training loss: 2.5950409767281974
Validation loss: 2.934805694580958

Epoch: 5| Step: 8
Training loss: 2.757389198214443
Validation loss: 2.936795967404464

Epoch: 5| Step: 9
Training loss: 3.5863491644832695
Validation loss: 2.940395823422333

Epoch: 5| Step: 10
Training loss: 3.342842050082797
Validation loss: 2.931138334511587

Epoch: 294| Step: 0
Training loss: 3.6041431903993293
Validation loss: 2.933302490453508

Epoch: 5| Step: 1
Training loss: 2.813012902857768
Validation loss: 2.9367539447440976

Epoch: 5| Step: 2
Training loss: 3.057959635785639
Validation loss: 2.9337171425359143

Epoch: 5| Step: 3
Training loss: 3.017717653277043
Validation loss: 2.9352293714426954

Epoch: 5| Step: 4
Training loss: 3.6312609568970613
Validation loss: 2.941347544835369

Epoch: 5| Step: 5
Training loss: 3.7068237632512555
Validation loss: 2.9361282153003643

Epoch: 5| Step: 6
Training loss: 3.169294538490246
Validation loss: 2.935585714304645

Epoch: 5| Step: 7
Training loss: 2.9637188492533215
Validation loss: 2.938716157548313

Epoch: 5| Step: 8
Training loss: 2.9045680932120472
Validation loss: 2.9400125596065094

Epoch: 5| Step: 9
Training loss: 3.216368451566977
Validation loss: 2.93215313594789

Epoch: 5| Step: 10
Training loss: 3.0989801144301956
Validation loss: 2.9343248346094364

Epoch: 295| Step: 0
Training loss: 3.7660595654979896
Validation loss: 2.9339297138163967

Epoch: 5| Step: 1
Training loss: 3.5016004445421487
Validation loss: 2.93288909964

Epoch: 5| Step: 2
Training loss: 3.08381707460637
Validation loss: 2.929709616081958

Epoch: 5| Step: 3
Training loss: 2.4849934318041202
Validation loss: 2.9330274123371045

Epoch: 5| Step: 4
Training loss: 2.8617208894788786
Validation loss: 2.9332427517291024

Epoch: 5| Step: 5
Training loss: 3.1965414729048156
Validation loss: 2.93445637275478

Epoch: 5| Step: 6
Training loss: 3.353294511902754
Validation loss: 2.9331592551393544

Epoch: 5| Step: 7
Training loss: 2.705821197579671
Validation loss: 2.9327002003792457

Epoch: 5| Step: 8
Training loss: 3.4237434476836377
Validation loss: 2.9315066176913915

Epoch: 5| Step: 9
Training loss: 3.5980559716188885
Validation loss: 2.9284503287415995

Epoch: 5| Step: 10
Training loss: 3.091883857549345
Validation loss: 2.932203970230704

Epoch: 296| Step: 0
Training loss: 3.096652740293901
Validation loss: 2.9378698086109614

Epoch: 5| Step: 1
Training loss: 2.399262624952436
Validation loss: 2.931828098151282

Epoch: 5| Step: 2
Training loss: 3.46662384031203
Validation loss: 2.929556004133428

Epoch: 5| Step: 3
Training loss: 3.310576978338428
Validation loss: 2.9344907351967175

Epoch: 5| Step: 4
Training loss: 3.4998831048245775
Validation loss: 2.932765527595422

Epoch: 5| Step: 5
Training loss: 3.500750461231003
Validation loss: 2.930853280181364

Epoch: 5| Step: 6
Training loss: 3.7629975455684397
Validation loss: 2.9299976183100345

Epoch: 5| Step: 7
Training loss: 3.127051328681228
Validation loss: 2.9326943487659327

Epoch: 5| Step: 8
Training loss: 2.994096510550344
Validation loss: 2.9310121928117554

Epoch: 5| Step: 9
Training loss: 2.6907221086547413
Validation loss: 2.9309220873990767

Epoch: 5| Step: 10
Training loss: 3.231373006519548
Validation loss: 2.9313669301514556

Epoch: 297| Step: 0
Training loss: 3.0121336971464037
Validation loss: 2.930875655125064

Epoch: 5| Step: 1
Training loss: 3.398203734327169
Validation loss: 2.927787828817025

Epoch: 5| Step: 2
Training loss: 2.6624276522983954
Validation loss: 2.9283086175308783

Epoch: 5| Step: 3
Training loss: 3.070205181857332
Validation loss: 2.927959696461116

Epoch: 5| Step: 4
Training loss: 3.703935365496064
Validation loss: 2.9290614355422115

Epoch: 5| Step: 5
Training loss: 3.7119488753382637
Validation loss: 2.9274315490983946

Epoch: 5| Step: 6
Training loss: 2.9966088838137135
Validation loss: 2.928936994344299

Epoch: 5| Step: 7
Training loss: 3.6152304180995363
Validation loss: 2.9269407101326776

Epoch: 5| Step: 8
Training loss: 2.509115575774702
Validation loss: 2.9299769341025925

Epoch: 5| Step: 9
Training loss: 3.5756915617336626
Validation loss: 2.926191647308963

Epoch: 5| Step: 10
Training loss: 2.6362823351219564
Validation loss: 2.9316117751185913

Epoch: 298| Step: 0
Training loss: 3.528770724217809
Validation loss: 2.9283239189214805

Epoch: 5| Step: 1
Training loss: 3.029611675696669
Validation loss: 2.929739253855152

Epoch: 5| Step: 2
Training loss: 3.332425772776776
Validation loss: 2.9255894417177655

Epoch: 5| Step: 3
Training loss: 3.97627506079117
Validation loss: 2.931739054030944

Epoch: 5| Step: 4
Training loss: 2.9248772359011537
Validation loss: 2.932921717403149

Epoch: 5| Step: 5
Training loss: 2.8009926092396924
Validation loss: 2.9325853478768455

Epoch: 5| Step: 6
Training loss: 3.0317619913838723
Validation loss: 2.9272084377825687

Epoch: 5| Step: 7
Training loss: 2.6585175652676107
Validation loss: 2.934263325632118

Epoch: 5| Step: 8
Training loss: 3.467521931222045
Validation loss: 2.930327727774221

Epoch: 5| Step: 9
Training loss: 2.70546193619084
Validation loss: 2.9341205976809794

Epoch: 5| Step: 10
Training loss: 3.618253414888602
Validation loss: 2.9386216384929402

Epoch: 299| Step: 0
Training loss: 2.7885949520301505
Validation loss: 2.934032319522035

Epoch: 5| Step: 1
Training loss: 3.2769471066035747
Validation loss: 2.929512786359085

Epoch: 5| Step: 2
Training loss: 2.525365228960424
Validation loss: 2.9263710647495134

Epoch: 5| Step: 3
Training loss: 2.9952128680816776
Validation loss: 2.9282671340589568

Epoch: 5| Step: 4
Training loss: 3.5184992590780535
Validation loss: 2.923508149138266

Epoch: 5| Step: 5
Training loss: 3.0392862350363523
Validation loss: 2.9214811069992086

Epoch: 5| Step: 6
Training loss: 3.1320139183426985
Validation loss: 2.9258968620076384

Epoch: 5| Step: 7
Training loss: 3.5330649243977623
Validation loss: 2.918893965378115

Epoch: 5| Step: 8
Training loss: 3.4503565949513417
Validation loss: 2.9216027349309033

Epoch: 5| Step: 9
Training loss: 3.314452117937752
Validation loss: 2.9220276242646612

Epoch: 5| Step: 10
Training loss: 3.577403166478073
Validation loss: 2.9187766504631165

Epoch: 300| Step: 0
Training loss: 2.3735334988454664
Validation loss: 2.9198102417668026

Epoch: 5| Step: 1
Training loss: 3.233945366524764
Validation loss: 2.9216827334584448

Epoch: 5| Step: 2
Training loss: 3.4904399826207917
Validation loss: 2.9208956797996377

Epoch: 5| Step: 3
Training loss: 3.196108991595441
Validation loss: 2.9242145831126645

Epoch: 5| Step: 4
Training loss: 2.727097073591533
Validation loss: 2.923166983142747

Epoch: 5| Step: 5
Training loss: 3.8420866802153975
Validation loss: 2.92559032150451

Epoch: 5| Step: 6
Training loss: 3.3040987396634067
Validation loss: 2.92518377050198

Epoch: 5| Step: 7
Training loss: 3.5592583078709583
Validation loss: 2.9235450841683606

Epoch: 5| Step: 8
Training loss: 3.5904561745949515
Validation loss: 2.9294215514090394

Epoch: 5| Step: 9
Training loss: 2.5361905331923107
Validation loss: 2.9220574522542213

Epoch: 5| Step: 10
Training loss: 3.059377986294747
Validation loss: 2.922670957114158

Epoch: 301| Step: 0
Training loss: 3.3568758872880973
Validation loss: 2.9282992797737672

Epoch: 5| Step: 1
Training loss: 3.494640470248175
Validation loss: 2.921463059990097

Epoch: 5| Step: 2
Training loss: 3.361873389642787
Validation loss: 2.9228083596162113

Epoch: 5| Step: 3
Training loss: 2.653841519963058
Validation loss: 2.9239734929145005

Epoch: 5| Step: 4
Training loss: 3.9031087222954834
Validation loss: 2.919242097730512

Epoch: 5| Step: 5
Training loss: 3.539809798610563
Validation loss: 2.915569794135529

Epoch: 5| Step: 6
Training loss: 3.1666930013531998
Validation loss: 2.9194955815674533

Epoch: 5| Step: 7
Training loss: 3.3080522438638003
Validation loss: 2.9187015191525374

Epoch: 5| Step: 8
Training loss: 2.781941617203629
Validation loss: 2.917362389159182

Epoch: 5| Step: 9
Training loss: 2.085256515384818
Validation loss: 2.920396677488843

Epoch: 5| Step: 10
Training loss: 3.211637917115928
Validation loss: 2.9181968530731037

Epoch: 302| Step: 0
Training loss: 3.6154729680942186
Validation loss: 2.9197344161829224

Epoch: 5| Step: 1
Training loss: 4.0205935602724505
Validation loss: 2.921011109539022

Epoch: 5| Step: 2
Training loss: 3.010742821014367
Validation loss: 2.9188981504355427

Epoch: 5| Step: 3
Training loss: 3.505147962725766
Validation loss: 2.9165836890820933

Epoch: 5| Step: 4
Training loss: 2.5493865939599365
Validation loss: 2.92035939363595

Epoch: 5| Step: 5
Training loss: 3.393837246554925
Validation loss: 2.9207505185708524

Epoch: 5| Step: 6
Training loss: 3.1632321622190758
Validation loss: 2.91886108370449

Epoch: 5| Step: 7
Training loss: 2.5212791826245344
Validation loss: 2.9180080859622217

Epoch: 5| Step: 8
Training loss: 2.8838198176060654
Validation loss: 2.922763461481053

Epoch: 5| Step: 9
Training loss: 3.0265258471741623
Validation loss: 2.9177373254098424

Epoch: 5| Step: 10
Training loss: 3.231761373935886
Validation loss: 2.9209844778477514

Epoch: 303| Step: 0
Training loss: 3.389014639545067
Validation loss: 2.9220848795580054

Epoch: 5| Step: 1
Training loss: 2.9757476251915262
Validation loss: 2.918318895478878

Epoch: 5| Step: 2
Training loss: 3.33464636373256
Validation loss: 2.9177039948908536

Epoch: 5| Step: 3
Training loss: 3.3119774172284817
Validation loss: 2.920280451810996

Epoch: 5| Step: 4
Training loss: 3.727380562806185
Validation loss: 2.9193928249881194

Epoch: 5| Step: 5
Training loss: 3.358189573279479
Validation loss: 2.9173191418938207

Epoch: 5| Step: 6
Training loss: 2.7530918080367397
Validation loss: 2.9140673720403116

Epoch: 5| Step: 7
Training loss: 2.8941325583637076
Validation loss: 2.9184464861985298

Epoch: 5| Step: 8
Training loss: 2.724200343120977
Validation loss: 2.9181283923965506

Epoch: 5| Step: 9
Training loss: 3.416167494122674
Validation loss: 2.9168753155263905

Epoch: 5| Step: 10
Training loss: 3.1386667096060483
Validation loss: 2.919278286716759

Epoch: 304| Step: 0
Training loss: 3.2356373263192992
Validation loss: 2.919798305990452

Epoch: 5| Step: 1
Training loss: 3.0141509411434746
Validation loss: 2.9154223311815017

Epoch: 5| Step: 2
Training loss: 3.2307627681346154
Validation loss: 2.9155032722097047

Epoch: 5| Step: 3
Training loss: 3.137077035548431
Validation loss: 2.9182549776748057

Epoch: 5| Step: 4
Training loss: 3.595590932609421
Validation loss: 2.917002914899337

Epoch: 5| Step: 5
Training loss: 2.9880690156455123
Validation loss: 2.919903284536987

Epoch: 5| Step: 6
Training loss: 3.3448778193444935
Validation loss: 2.9205857844090257

Epoch: 5| Step: 7
Training loss: 3.1570497009599094
Validation loss: 2.919607482352368

Epoch: 5| Step: 8
Training loss: 2.779424947225948
Validation loss: 2.920623467391346

Epoch: 5| Step: 9
Training loss: 3.5876927287472324
Validation loss: 2.9186959565585178

Epoch: 5| Step: 10
Training loss: 2.998742157773588
Validation loss: 2.921444505660087

Epoch: 305| Step: 0
Training loss: 3.039138126167805
Validation loss: 2.914039362535932

Epoch: 5| Step: 1
Training loss: 2.850925154855249
Validation loss: 2.91460828413261

Epoch: 5| Step: 2
Training loss: 2.946849958003935
Validation loss: 2.9166368919528676

Epoch: 5| Step: 3
Training loss: 3.244181633310575
Validation loss: 2.9143625138117106

Epoch: 5| Step: 4
Training loss: 2.9522674768734762
Validation loss: 2.9126438707229156

Epoch: 5| Step: 5
Training loss: 3.558497137606961
Validation loss: 2.9161570773319747

Epoch: 5| Step: 6
Training loss: 2.8672731475095286
Validation loss: 2.9161627537791044

Epoch: 5| Step: 7
Training loss: 3.5923298559069066
Validation loss: 2.9158068902975423

Epoch: 5| Step: 8
Training loss: 3.171395552155231
Validation loss: 2.9140661087240325

Epoch: 5| Step: 9
Training loss: 3.1075926613284883
Validation loss: 2.910982759277862

Epoch: 5| Step: 10
Training loss: 3.768723475424578
Validation loss: 2.9160303798838774

Epoch: 306| Step: 0
Training loss: 3.1208601423740983
Validation loss: 2.9124921173027056

Epoch: 5| Step: 1
Training loss: 3.240709818334241
Validation loss: 2.9139050261328743

Epoch: 5| Step: 2
Training loss: 2.661297658311684
Validation loss: 2.910950147561358

Epoch: 5| Step: 3
Training loss: 3.4527844567480233
Validation loss: 2.911821463821028

Epoch: 5| Step: 4
Training loss: 3.0616263875732717
Validation loss: 2.9138285357049973

Epoch: 5| Step: 5
Training loss: 3.720676724397806
Validation loss: 2.91073727205679

Epoch: 5| Step: 6
Training loss: 3.5023388541138685
Validation loss: 2.908664516772594

Epoch: 5| Step: 7
Training loss: 2.943127861612921
Validation loss: 2.9135229903478423

Epoch: 5| Step: 8
Training loss: 2.8890407860591347
Validation loss: 2.911649826937179

Epoch: 5| Step: 9
Training loss: 2.9529559374660033
Validation loss: 2.9129204204869334

Epoch: 5| Step: 10
Training loss: 3.4645580358875794
Validation loss: 2.910981602946444

Epoch: 307| Step: 0
Training loss: 2.7866635731249465
Validation loss: 2.912356372411136

Epoch: 5| Step: 1
Training loss: 3.308310396385594
Validation loss: 2.9184513438928485

Epoch: 5| Step: 2
Training loss: 2.6376888948748753
Validation loss: 2.9147702153090616

Epoch: 5| Step: 3
Training loss: 3.01777374719879
Validation loss: 2.917776161038053

Epoch: 5| Step: 4
Training loss: 3.2635541126457506
Validation loss: 2.917466923730339

Epoch: 5| Step: 5
Training loss: 2.605140768337013
Validation loss: 2.918762957311483

Epoch: 5| Step: 6
Training loss: 3.7309302878348056
Validation loss: 2.9230914261787655

Epoch: 5| Step: 7
Training loss: 3.0209813750373824
Validation loss: 2.9164522370535675

Epoch: 5| Step: 8
Training loss: 3.6135046647568116
Validation loss: 2.915542764537886

Epoch: 5| Step: 9
Training loss: 3.2530667434445126
Validation loss: 2.9108977848684834

Epoch: 5| Step: 10
Training loss: 3.7350640718615047
Validation loss: 2.911970130365148

Epoch: 308| Step: 0
Training loss: 3.1926250768429765
Validation loss: 2.907422766244932

Epoch: 5| Step: 1
Training loss: 3.0269105662860185
Validation loss: 2.9124497026000418

Epoch: 5| Step: 2
Training loss: 3.80246627481667
Validation loss: 2.9082122293293406

Epoch: 5| Step: 3
Training loss: 2.8494815287890805
Validation loss: 2.906790032274602

Epoch: 5| Step: 4
Training loss: 2.7083862788576063
Validation loss: 2.90763009433286

Epoch: 5| Step: 5
Training loss: 3.0727267104236073
Validation loss: 2.906786973673774

Epoch: 5| Step: 6
Training loss: 3.5618491665809815
Validation loss: 2.9092679372778236

Epoch: 5| Step: 7
Training loss: 2.883206637765016
Validation loss: 2.9068256751439825

Epoch: 5| Step: 8
Training loss: 3.300044990001675
Validation loss: 2.9074849321003855

Epoch: 5| Step: 9
Training loss: 3.369795282864092
Validation loss: 2.9106363765269414

Epoch: 5| Step: 10
Training loss: 3.214134536699938
Validation loss: 2.9066939141167767

Epoch: 309| Step: 0
Training loss: 3.216444949347434
Validation loss: 2.9050888951227334

Epoch: 5| Step: 1
Training loss: 2.9142348005885568
Validation loss: 2.9051552460611996

Epoch: 5| Step: 2
Training loss: 3.7150464248323556
Validation loss: 2.9061709616087827

Epoch: 5| Step: 3
Training loss: 2.7449382668034654
Validation loss: 2.908855161974153

Epoch: 5| Step: 4
Training loss: 3.201224605365738
Validation loss: 2.908972153472398

Epoch: 5| Step: 5
Training loss: 3.1289644652628974
Validation loss: 2.9074789927055606

Epoch: 5| Step: 6
Training loss: 2.877839717746636
Validation loss: 2.9187117738673973

Epoch: 5| Step: 7
Training loss: 2.9845544251834855
Validation loss: 2.9060537373651063

Epoch: 5| Step: 8
Training loss: 3.344472931761323
Validation loss: 2.9099963922580088

Epoch: 5| Step: 9
Training loss: 3.6006740045084844
Validation loss: 2.909343800373539

Epoch: 5| Step: 10
Training loss: 3.2300329871604303
Validation loss: 2.911027115205465

Epoch: 310| Step: 0
Training loss: 3.3390108553472038
Validation loss: 2.906740817338467

Epoch: 5| Step: 1
Training loss: 3.362740751248514
Validation loss: 2.908263798540698

Epoch: 5| Step: 2
Training loss: 3.3156714462205428
Validation loss: 2.91067601503984

Epoch: 5| Step: 3
Training loss: 2.644808192662856
Validation loss: 2.9134801999665667

Epoch: 5| Step: 4
Training loss: 2.5233160881383765
Validation loss: 2.9096434592958285

Epoch: 5| Step: 5
Training loss: 3.475298911212938
Validation loss: 2.9074022371039034

Epoch: 5| Step: 6
Training loss: 3.0149345595816124
Validation loss: 2.907169712550842

Epoch: 5| Step: 7
Training loss: 3.453440794162631
Validation loss: 2.9040557034947794

Epoch: 5| Step: 8
Training loss: 3.180720730804672
Validation loss: 2.9039178904109226

Epoch: 5| Step: 9
Training loss: 3.090523164033753
Validation loss: 2.9076157738201434

Epoch: 5| Step: 10
Training loss: 3.5504847235921093
Validation loss: 2.9033801106154415

Epoch: 311| Step: 0
Training loss: 3.0354372972054806
Validation loss: 2.9007017817598526

Epoch: 5| Step: 1
Training loss: 3.2142441701474933
Validation loss: 2.901294072424512

Epoch: 5| Step: 2
Training loss: 3.180612040707136
Validation loss: 2.9023406761138912

Epoch: 5| Step: 3
Training loss: 3.135948989307319
Validation loss: 2.9041353688316356

Epoch: 5| Step: 4
Training loss: 3.414146579431634
Validation loss: 2.904038214698853

Epoch: 5| Step: 5
Training loss: 3.8452406063125064
Validation loss: 2.903179770335968

Epoch: 5| Step: 6
Training loss: 2.5078224823655004
Validation loss: 2.9030601487245273

Epoch: 5| Step: 7
Training loss: 3.0786662134253078
Validation loss: 2.909424988930578

Epoch: 5| Step: 8
Training loss: 3.262472136513708
Validation loss: 2.906291466067708

Epoch: 5| Step: 9
Training loss: 2.7030464998875248
Validation loss: 2.9062048584035223

Epoch: 5| Step: 10
Training loss: 3.547542156374935
Validation loss: 2.9082727995446755

Epoch: 312| Step: 0
Training loss: 3.4207359055380193
Validation loss: 2.907404322473396

Epoch: 5| Step: 1
Training loss: 3.377191609069239
Validation loss: 2.9043904350458467

Epoch: 5| Step: 2
Training loss: 3.2730094975824082
Validation loss: 2.90935288527223

Epoch: 5| Step: 3
Training loss: 3.238078480297825
Validation loss: 2.90338720274105

Epoch: 5| Step: 4
Training loss: 3.1822679251343478
Validation loss: 2.905201440823711

Epoch: 5| Step: 5
Training loss: 3.519642886339931
Validation loss: 2.9012194144343897

Epoch: 5| Step: 6
Training loss: 3.384133167027458
Validation loss: 2.9027049902092448

Epoch: 5| Step: 7
Training loss: 2.644389431868292
Validation loss: 2.9029412719513874

Epoch: 5| Step: 8
Training loss: 3.4513585332144907
Validation loss: 2.9004949916705267

Epoch: 5| Step: 9
Training loss: 2.5226071529861955
Validation loss: 2.9029670580088522

Epoch: 5| Step: 10
Training loss: 2.768192457288839
Validation loss: 2.8987137618860634

Epoch: 313| Step: 0
Training loss: 3.463440964843427
Validation loss: 2.8996774435733115

Epoch: 5| Step: 1
Training loss: 3.3685334031604923
Validation loss: 2.8978785205870934

Epoch: 5| Step: 2
Training loss: 2.8474871214993214
Validation loss: 2.899682776534095

Epoch: 5| Step: 3
Training loss: 3.430799160715263
Validation loss: 2.903131292484167

Epoch: 5| Step: 4
Training loss: 2.557855351018626
Validation loss: 2.899926390967232

Epoch: 5| Step: 5
Training loss: 3.4909236933843495
Validation loss: 2.8990705996224144

Epoch: 5| Step: 6
Training loss: 2.8830652307070195
Validation loss: 2.9033821662034316

Epoch: 5| Step: 7
Training loss: 2.626546676560847
Validation loss: 2.89954334450024

Epoch: 5| Step: 8
Training loss: 3.2982169218050608
Validation loss: 2.9006267267135026

Epoch: 5| Step: 9
Training loss: 3.575179440990105
Validation loss: 2.8992799565502856

Epoch: 5| Step: 10
Training loss: 3.2951463262225946
Validation loss: 2.9018164726176843

Epoch: 314| Step: 0
Training loss: 3.8132476073635027
Validation loss: 2.904668860611856

Epoch: 5| Step: 1
Training loss: 3.534087534849624
Validation loss: 2.89917245563079

Epoch: 5| Step: 2
Training loss: 2.933205732546867
Validation loss: 2.8993271185320526

Epoch: 5| Step: 3
Training loss: 2.8047797312753278
Validation loss: 2.9000061821155616

Epoch: 5| Step: 4
Training loss: 3.1059585281030233
Validation loss: 2.899441309653017

Epoch: 5| Step: 5
Training loss: 2.7701212223671523
Validation loss: 2.898513416600362

Epoch: 5| Step: 6
Training loss: 2.967092593474621
Validation loss: 2.9000261509967644

Epoch: 5| Step: 7
Training loss: 3.523172237451086
Validation loss: 2.899068211134114

Epoch: 5| Step: 8
Training loss: 2.898960446790902
Validation loss: 2.8971277555903865

Epoch: 5| Step: 9
Training loss: 2.974857993703672
Validation loss: 2.899109904607447

Epoch: 5| Step: 10
Training loss: 3.561284979035558
Validation loss: 2.8960204770364153

Epoch: 315| Step: 0
Training loss: 3.393044026326125
Validation loss: 2.896598173709264

Epoch: 5| Step: 1
Training loss: 3.577757437538262
Validation loss: 2.8968554425384974

Epoch: 5| Step: 2
Training loss: 3.1484668815510246
Validation loss: 2.8992812351517303

Epoch: 5| Step: 3
Training loss: 3.0774832894114055
Validation loss: 2.8993801429027264

Epoch: 5| Step: 4
Training loss: 2.737460330344749
Validation loss: 2.905289601430706

Epoch: 5| Step: 5
Training loss: 3.365763422847646
Validation loss: 2.9033386365210716

Epoch: 5| Step: 6
Training loss: 2.627930231849163
Validation loss: 2.908396485379916

Epoch: 5| Step: 7
Training loss: 3.1548665857898492
Validation loss: 2.900371272939336

Epoch: 5| Step: 8
Training loss: 3.169792807273062
Validation loss: 2.899714606113643

Epoch: 5| Step: 9
Training loss: 3.3971035849718816
Validation loss: 2.903352829787517

Epoch: 5| Step: 10
Training loss: 3.232591810110119
Validation loss: 2.9036266877904193

Epoch: 316| Step: 0
Training loss: 2.8955700615146815
Validation loss: 2.8984813792450184

Epoch: 5| Step: 1
Training loss: 3.0699849427192554
Validation loss: 2.89678902539222

Epoch: 5| Step: 2
Training loss: 3.587825502522085
Validation loss: 2.897124089487001

Epoch: 5| Step: 3
Training loss: 3.420111632951203
Validation loss: 2.894216765421624

Epoch: 5| Step: 4
Training loss: 3.535821841476961
Validation loss: 2.895821048488898

Epoch: 5| Step: 5
Training loss: 3.9808606973982203
Validation loss: 2.8950837552796416

Epoch: 5| Step: 6
Training loss: 2.88899094042706
Validation loss: 2.8952509737950405

Epoch: 5| Step: 7
Training loss: 2.5101396927582824
Validation loss: 2.896030813834278

Epoch: 5| Step: 8
Training loss: 3.2496952500880485
Validation loss: 2.892497394196251

Epoch: 5| Step: 9
Training loss: 2.8688592428712347
Validation loss: 2.895602361273983

Epoch: 5| Step: 10
Training loss: 2.5884927070843577
Validation loss: 2.893208500778799

Epoch: 317| Step: 0
Training loss: 3.198836419032705
Validation loss: 2.893616215716184

Epoch: 5| Step: 1
Training loss: 3.689547342174772
Validation loss: 2.895265787570598

Epoch: 5| Step: 2
Training loss: 3.137172490386213
Validation loss: 2.8942554560531666

Epoch: 5| Step: 3
Training loss: 2.3352996057261346
Validation loss: 2.8968238125238144

Epoch: 5| Step: 4
Training loss: 3.3698099991753234
Validation loss: 2.895336385282341

Epoch: 5| Step: 5
Training loss: 2.8803511866392304
Validation loss: 2.8937546452112217

Epoch: 5| Step: 6
Training loss: 3.2762177161787815
Validation loss: 2.8976908124062595

Epoch: 5| Step: 7
Training loss: 2.619091286646123
Validation loss: 2.892548689644298

Epoch: 5| Step: 8
Training loss: 3.39900963889021
Validation loss: 2.8964840864616272

Epoch: 5| Step: 9
Training loss: 3.707689393672778
Validation loss: 2.8949265508132878

Epoch: 5| Step: 10
Training loss: 3.059149485801086
Validation loss: 2.893528518983976

Epoch: 318| Step: 0
Training loss: 3.1629353340478152
Validation loss: 2.8923315445653794

Epoch: 5| Step: 1
Training loss: 3.1704227524223247
Validation loss: 2.8966173297161073

Epoch: 5| Step: 2
Training loss: 2.9906770165522696
Validation loss: 2.895490848464105

Epoch: 5| Step: 3
Training loss: 2.6724700265172396
Validation loss: 2.894706676584748

Epoch: 5| Step: 4
Training loss: 3.313295664685102
Validation loss: 2.8967843632405694

Epoch: 5| Step: 5
Training loss: 3.055322293327019
Validation loss: 2.8950345423547947

Epoch: 5| Step: 6
Training loss: 3.4463770599242856
Validation loss: 2.9036368023881707

Epoch: 5| Step: 7
Training loss: 3.1841014621038193
Validation loss: 2.9008029830644904

Epoch: 5| Step: 8
Training loss: 3.2751147359303765
Validation loss: 2.8954658033093863

Epoch: 5| Step: 9
Training loss: 3.060057464010183
Validation loss: 2.8908536466383574

Epoch: 5| Step: 10
Training loss: 3.5879825918738573
Validation loss: 2.8902680233980385

Epoch: 319| Step: 0
Training loss: 3.6004370794934206
Validation loss: 2.8908243613324

Epoch: 5| Step: 1
Training loss: 2.820955409268559
Validation loss: 2.8944543087040207

Epoch: 5| Step: 2
Training loss: 3.4133747027790937
Validation loss: 2.890899765760146

Epoch: 5| Step: 3
Training loss: 3.117274844826955
Validation loss: 2.892275087454061

Epoch: 5| Step: 4
Training loss: 2.9247096382197513
Validation loss: 2.8885268942840305

Epoch: 5| Step: 5
Training loss: 3.0773453862809816
Validation loss: 2.8900202789600034

Epoch: 5| Step: 6
Training loss: 3.9964433593554323
Validation loss: 2.8888240029415932

Epoch: 5| Step: 7
Training loss: 2.545886544162141
Validation loss: 2.8926220807202645

Epoch: 5| Step: 8
Training loss: 3.2725240302314638
Validation loss: 2.8904295842245866

Epoch: 5| Step: 9
Training loss: 2.610635327443634
Validation loss: 2.8908871324254575

Epoch: 5| Step: 10
Training loss: 3.2926798520681193
Validation loss: 2.890822012145471

Epoch: 320| Step: 0
Training loss: 3.169769038983447
Validation loss: 2.8918141090720266

Epoch: 5| Step: 1
Training loss: 3.288258216362143
Validation loss: 2.8881986865404112

Epoch: 5| Step: 2
Training loss: 2.962424355358
Validation loss: 2.8923130240597743

Epoch: 5| Step: 3
Training loss: 2.9144483213713595
Validation loss: 2.889585369789666

Epoch: 5| Step: 4
Training loss: 2.9402796803006126
Validation loss: 2.887728112265473

Epoch: 5| Step: 5
Training loss: 3.4208082513358193
Validation loss: 2.889812593225286

Epoch: 5| Step: 6
Training loss: 3.492412653754422
Validation loss: 2.8909186074701645

Epoch: 5| Step: 7
Training loss: 3.4675120301096403
Validation loss: 2.897915964514347

Epoch: 5| Step: 8
Training loss: 2.9300390414087807
Validation loss: 2.892636769701688

Epoch: 5| Step: 9
Training loss: 3.298095332639909
Validation loss: 2.8940474630235147

Epoch: 5| Step: 10
Training loss: 2.9218142906042637
Validation loss: 2.892360474253055

Epoch: 321| Step: 0
Training loss: 3.3202014859658244
Validation loss: 2.8919935326523

Epoch: 5| Step: 1
Training loss: 3.0965889899698884
Validation loss: 2.8905470217026066

Epoch: 5| Step: 2
Training loss: 2.540525701442747
Validation loss: 2.886551210396994

Epoch: 5| Step: 3
Training loss: 3.6390956564310417
Validation loss: 2.8884005567354447

Epoch: 5| Step: 4
Training loss: 3.073678925364598
Validation loss: 2.8914352305817945

Epoch: 5| Step: 5
Training loss: 3.596363875117953
Validation loss: 2.886484791514028

Epoch: 5| Step: 6
Training loss: 2.759336142520192
Validation loss: 2.8879393345053086

Epoch: 5| Step: 7
Training loss: 3.354313075185419
Validation loss: 2.886222030983135

Epoch: 5| Step: 8
Training loss: 3.07644685030935
Validation loss: 2.8808217298447647

Epoch: 5| Step: 9
Training loss: 3.2134272443204646
Validation loss: 2.8836986230215476

Epoch: 5| Step: 10
Training loss: 3.06502304466757
Validation loss: 2.8905445392544173

Epoch: 322| Step: 0
Training loss: 2.8929674709481037
Validation loss: 2.879824493833311

Epoch: 5| Step: 1
Training loss: 3.287157245362215
Validation loss: 2.8849916871867913

Epoch: 5| Step: 2
Training loss: 2.8073523142721104
Validation loss: 2.890043033904378

Epoch: 5| Step: 3
Training loss: 2.2381427715398092
Validation loss: 2.8911976857534536

Epoch: 5| Step: 4
Training loss: 3.4514610458667
Validation loss: 2.889363338529291

Epoch: 5| Step: 5
Training loss: 3.2814546067159758
Validation loss: 2.8925198150170752

Epoch: 5| Step: 6
Training loss: 3.4236752029276376
Validation loss: 2.9015377150284296

Epoch: 5| Step: 7
Training loss: 2.8943305930576035
Validation loss: 2.9022161456569107

Epoch: 5| Step: 8
Training loss: 3.4541703104905688
Validation loss: 2.89987822030496

Epoch: 5| Step: 9
Training loss: 3.4766838824052253
Validation loss: 2.9013443561357724

Epoch: 5| Step: 10
Training loss: 3.484988308289015
Validation loss: 2.8990242028187034

Epoch: 323| Step: 0
Training loss: 3.463447986377983
Validation loss: 2.896260495985052

Epoch: 5| Step: 1
Training loss: 3.583585345846983
Validation loss: 2.8985092091858697

Epoch: 5| Step: 2
Training loss: 2.925813030482854
Validation loss: 2.893582262707508

Epoch: 5| Step: 3
Training loss: 2.5449001402084153
Validation loss: 2.8924818004691786

Epoch: 5| Step: 4
Training loss: 2.923001159041309
Validation loss: 2.888839321786657

Epoch: 5| Step: 5
Training loss: 3.024248985192601
Validation loss: 2.8866677443821493

Epoch: 5| Step: 6
Training loss: 3.452167775317125
Validation loss: 2.8832978591097667

Epoch: 5| Step: 7
Training loss: 2.866609686647461
Validation loss: 2.884663275401866

Epoch: 5| Step: 8
Training loss: 3.3441910497399285
Validation loss: 2.8793536086988327

Epoch: 5| Step: 9
Training loss: 3.1721890298769986
Validation loss: 2.8820611718498137

Epoch: 5| Step: 10
Training loss: 3.47252236828009
Validation loss: 2.879977751395838

Epoch: 324| Step: 0
Training loss: 2.9804293928635057
Validation loss: 2.8792096475122135

Epoch: 5| Step: 1
Training loss: 2.9885038405150075
Validation loss: 2.8809241758761277

Epoch: 5| Step: 2
Training loss: 3.6767242227466332
Validation loss: 2.877737096877813

Epoch: 5| Step: 3
Training loss: 2.1164937026274657
Validation loss: 2.878498759110014

Epoch: 5| Step: 4
Training loss: 2.479552476712628
Validation loss: 2.8817779910706296

Epoch: 5| Step: 5
Training loss: 3.135963738621078
Validation loss: 2.881080304227952

Epoch: 5| Step: 6
Training loss: 3.3253652386372408
Validation loss: 2.8829618434693485

Epoch: 5| Step: 7
Training loss: 3.9455078076657717
Validation loss: 2.8814805224553597

Epoch: 5| Step: 8
Training loss: 3.2327320883528095
Validation loss: 2.8786923051053632

Epoch: 5| Step: 9
Training loss: 3.4155225621504237
Validation loss: 2.8838367222847636

Epoch: 5| Step: 10
Training loss: 3.173505692756515
Validation loss: 2.8830304002740474

Epoch: 325| Step: 0
Training loss: 2.8612882956378924
Validation loss: 2.8888988481554505

Epoch: 5| Step: 1
Training loss: 2.965987194843907
Validation loss: 2.888332700775514

Epoch: 5| Step: 2
Training loss: 3.013187352191891
Validation loss: 2.890317432788379

Epoch: 5| Step: 3
Training loss: 3.513247215643952
Validation loss: 2.890628533332082

Epoch: 5| Step: 4
Training loss: 3.7101538543468524
Validation loss: 2.8988612240372564

Epoch: 5| Step: 5
Training loss: 3.2753926631441184
Validation loss: 2.8900388389961287

Epoch: 5| Step: 6
Training loss: 3.3768242038632077
Validation loss: 2.892748438617663

Epoch: 5| Step: 7
Training loss: 2.7729194264693158
Validation loss: 2.8813176750827076

Epoch: 5| Step: 8
Training loss: 3.45109311906107
Validation loss: 2.890366369471173

Epoch: 5| Step: 9
Training loss: 2.841031126695729
Validation loss: 2.882197254859336

Epoch: 5| Step: 10
Training loss: 2.862529078173473
Validation loss: 2.8809677870596464

Epoch: 326| Step: 0
Training loss: 2.9816631358768833
Validation loss: 2.881046777424223

Epoch: 5| Step: 1
Training loss: 3.4579086655777274
Validation loss: 2.875401606604962

Epoch: 5| Step: 2
Training loss: 3.7161490697207276
Validation loss: 2.877538060078717

Epoch: 5| Step: 3
Training loss: 3.8456990332555048
Validation loss: 2.8769180583872545

Epoch: 5| Step: 4
Training loss: 2.8661418951969773
Validation loss: 2.8765133891183097

Epoch: 5| Step: 5
Training loss: 2.722719035799782
Validation loss: 2.877442413017125

Epoch: 5| Step: 6
Training loss: 3.038014522977349
Validation loss: 2.8799749829972954

Epoch: 5| Step: 7
Training loss: 2.826033266539884
Validation loss: 2.8788165209289795

Epoch: 5| Step: 8
Training loss: 3.572554470792201
Validation loss: 2.8782898661616048

Epoch: 5| Step: 9
Training loss: 2.8982970005746544
Validation loss: 2.878654284288672

Epoch: 5| Step: 10
Training loss: 2.5420720032549564
Validation loss: 2.8760709921206815

Epoch: 327| Step: 0
Training loss: 3.0302536103524735
Validation loss: 2.879746596975023

Epoch: 5| Step: 1
Training loss: 3.4148037801867526
Validation loss: 2.8829101951459886

Epoch: 5| Step: 2
Training loss: 3.3874964189686447
Validation loss: 2.882854737149879

Epoch: 5| Step: 3
Training loss: 2.527755208549306
Validation loss: 2.8860073768056913

Epoch: 5| Step: 4
Training loss: 3.2782884584299175
Validation loss: 2.8834041212151975

Epoch: 5| Step: 5
Training loss: 2.7613611488887657
Validation loss: 2.891840817028297

Epoch: 5| Step: 6
Training loss: 2.935166426299068
Validation loss: 2.8873851371683186

Epoch: 5| Step: 7
Training loss: 2.5214366243481607
Validation loss: 2.8841090752159606

Epoch: 5| Step: 8
Training loss: 3.985405403489534
Validation loss: 2.8842918241350652

Epoch: 5| Step: 9
Training loss: 2.9407131396714683
Validation loss: 2.878851679292543

Epoch: 5| Step: 10
Training loss: 3.813438049981586
Validation loss: 2.8797645235074656

Epoch: 328| Step: 0
Training loss: 3.4696376455237155
Validation loss: 2.8778075535765884

Epoch: 5| Step: 1
Training loss: 3.5471071679848403
Validation loss: 2.8781676816089776

Epoch: 5| Step: 2
Training loss: 2.873744856475966
Validation loss: 2.8781930224727037

Epoch: 5| Step: 3
Training loss: 3.03305629121819
Validation loss: 2.8735500262158817

Epoch: 5| Step: 4
Training loss: 3.5951288646368056
Validation loss: 2.8766962168688934

Epoch: 5| Step: 5
Training loss: 2.6403640527847276
Validation loss: 2.8771979707559563

Epoch: 5| Step: 6
Training loss: 2.708444818011686
Validation loss: 2.877802500777824

Epoch: 5| Step: 7
Training loss: 3.6323501784951664
Validation loss: 2.8772152662911656

Epoch: 5| Step: 8
Training loss: 3.149016296344551
Validation loss: 2.880584701700372

Epoch: 5| Step: 9
Training loss: 3.288278953023966
Validation loss: 2.8798622650791152

Epoch: 5| Step: 10
Training loss: 2.542306371346895
Validation loss: 2.8791353339904897

Epoch: 329| Step: 0
Training loss: 2.8065239039860357
Validation loss: 2.8790496885275805

Epoch: 5| Step: 1
Training loss: 3.180971828207629
Validation loss: 2.8821342518104505

Epoch: 5| Step: 2
Training loss: 3.6437360707666193
Validation loss: 2.880859601031406

Epoch: 5| Step: 3
Training loss: 2.931653962432186
Validation loss: 2.885982676627468

Epoch: 5| Step: 4
Training loss: 3.124972991826649
Validation loss: 2.88018280132505

Epoch: 5| Step: 5
Training loss: 3.2546908931192555
Validation loss: 2.879327134826065

Epoch: 5| Step: 6
Training loss: 3.1519138274636944
Validation loss: 2.8817096962676825

Epoch: 5| Step: 7
Training loss: 3.469182167968523
Validation loss: 2.872341416809759

Epoch: 5| Step: 8
Training loss: 2.878136458151476
Validation loss: 2.878238478702371

Epoch: 5| Step: 9
Training loss: 3.1636195496757082
Validation loss: 2.8822869364980654

Epoch: 5| Step: 10
Training loss: 3.070644059854834
Validation loss: 2.874775089920419

Epoch: 330| Step: 0
Training loss: 3.377090795478523
Validation loss: 2.871828370895921

Epoch: 5| Step: 1
Training loss: 3.1504290697243538
Validation loss: 2.877109917931484

Epoch: 5| Step: 2
Training loss: 3.546179346100802
Validation loss: 2.877022574380494

Epoch: 5| Step: 3
Training loss: 2.129399625671073
Validation loss: 2.8735986872900225

Epoch: 5| Step: 4
Training loss: 2.5224446803095937
Validation loss: 2.8765034572123183

Epoch: 5| Step: 5
Training loss: 3.0782678251485405
Validation loss: 2.881574067094506

Epoch: 5| Step: 6
Training loss: 3.4908735632443215
Validation loss: 2.8767539323675284

Epoch: 5| Step: 7
Training loss: 3.823154009000695
Validation loss: 2.8773999356023308

Epoch: 5| Step: 8
Training loss: 2.9581403176825676
Validation loss: 2.871148894071117

Epoch: 5| Step: 9
Training loss: 3.202606605822088
Validation loss: 2.8694717737830118

Epoch: 5| Step: 10
Training loss: 3.1158141359028764
Validation loss: 2.867842717498417

Epoch: 331| Step: 0
Training loss: 3.4012857362214994
Validation loss: 2.8777604175323312

Epoch: 5| Step: 1
Training loss: 2.8809874839100376
Validation loss: 2.872145672845825

Epoch: 5| Step: 2
Training loss: 3.717336562360057
Validation loss: 2.871404253083126

Epoch: 5| Step: 3
Training loss: 3.4576840231600277
Validation loss: 2.8749217646486325

Epoch: 5| Step: 4
Training loss: 3.528722618177864
Validation loss: 2.8784161068617893

Epoch: 5| Step: 5
Training loss: 3.078088750480558
Validation loss: 2.8742760259001225

Epoch: 5| Step: 6
Training loss: 2.8191793178267344
Validation loss: 2.877799568155009

Epoch: 5| Step: 7
Training loss: 3.4762315228247904
Validation loss: 2.870640186933998

Epoch: 5| Step: 8
Training loss: 3.1463369172752746
Validation loss: 2.8677269677699746

Epoch: 5| Step: 9
Training loss: 2.3968525473924447
Validation loss: 2.868571446772431

Epoch: 5| Step: 10
Training loss: 2.4299750939807887
Validation loss: 2.8717894888065314

Epoch: 332| Step: 0
Training loss: 2.7988392842317222
Validation loss: 2.8698866082755434

Epoch: 5| Step: 1
Training loss: 3.2776549490492215
Validation loss: 2.867536955983652

Epoch: 5| Step: 2
Training loss: 3.81375751705923
Validation loss: 2.8711938582331986

Epoch: 5| Step: 3
Training loss: 3.451547806217662
Validation loss: 2.870565606911209

Epoch: 5| Step: 4
Training loss: 3.214967449492132
Validation loss: 2.8691673170623564

Epoch: 5| Step: 5
Training loss: 2.7874565736954606
Validation loss: 2.8663542636176675

Epoch: 5| Step: 6
Training loss: 2.9557786755329554
Validation loss: 2.8682904905579223

Epoch: 5| Step: 7
Training loss: 3.3813741326242313
Validation loss: 2.8669455344207697

Epoch: 5| Step: 8
Training loss: 3.4548283169125527
Validation loss: 2.8663827390877668

Epoch: 5| Step: 9
Training loss: 2.5915334031493154
Validation loss: 2.868170406872466

Epoch: 5| Step: 10
Training loss: 2.699866121999606
Validation loss: 2.868185205884545

Epoch: 333| Step: 0
Training loss: 3.4007566058972394
Validation loss: 2.866800143527257

Epoch: 5| Step: 1
Training loss: 3.201967355832183
Validation loss: 2.8679357183168483

Epoch: 5| Step: 2
Training loss: 1.927931878853164
Validation loss: 2.8666980378489364

Epoch: 5| Step: 3
Training loss: 3.3909492864976074
Validation loss: 2.874382304016968

Epoch: 5| Step: 4
Training loss: 3.3034853360656204
Validation loss: 2.873459126185448

Epoch: 5| Step: 5
Training loss: 3.380316890781764
Validation loss: 2.8745800102107935

Epoch: 5| Step: 6
Training loss: 3.2708234523615847
Validation loss: 2.872046286890439

Epoch: 5| Step: 7
Training loss: 3.7490571426184163
Validation loss: 2.8678238931321602

Epoch: 5| Step: 8
Training loss: 2.2768353112212196
Validation loss: 2.87333297551427

Epoch: 5| Step: 9
Training loss: 3.5524174746566044
Validation loss: 2.871999524030241

Epoch: 5| Step: 10
Training loss: 2.6951868000297203
Validation loss: 2.8691580379063817

Epoch: 334| Step: 0
Training loss: 3.4834637326985862
Validation loss: 2.8643500087425995

Epoch: 5| Step: 1
Training loss: 2.8590257775344465
Validation loss: 2.8638201448476592

Epoch: 5| Step: 2
Training loss: 2.9237942027925294
Validation loss: 2.86706766251011

Epoch: 5| Step: 3
Training loss: 3.521628852372826
Validation loss: 2.8685795079298644

Epoch: 5| Step: 4
Training loss: 3.4515117484385556
Validation loss: 2.8666135393367504

Epoch: 5| Step: 5
Training loss: 3.4106878366636018
Validation loss: 2.866264574502481

Epoch: 5| Step: 6
Training loss: 3.292461025786523
Validation loss: 2.862951768876359

Epoch: 5| Step: 7
Training loss: 3.053156710628887
Validation loss: 2.8646805210724064

Epoch: 5| Step: 8
Training loss: 2.472890737301754
Validation loss: 2.867484495196842

Epoch: 5| Step: 9
Training loss: 2.9592372068654083
Validation loss: 2.866079587540664

Epoch: 5| Step: 10
Training loss: 3.105143672794985
Validation loss: 2.8650507809368353

Epoch: 335| Step: 0
Training loss: 2.4832148692231524
Validation loss: 2.8650490852948334

Epoch: 5| Step: 1
Training loss: 3.862094924574084
Validation loss: 2.862856381772708

Epoch: 5| Step: 2
Training loss: 3.4230869881589947
Validation loss: 2.861910801900807

Epoch: 5| Step: 3
Training loss: 2.9747687113636916
Validation loss: 2.865674751118161

Epoch: 5| Step: 4
Training loss: 2.826221647529499
Validation loss: 2.8677512342818847

Epoch: 5| Step: 5
Training loss: 3.387397460511677
Validation loss: 2.8667688490214593

Epoch: 5| Step: 6
Training loss: 3.1896984522248317
Validation loss: 2.8665988931874296

Epoch: 5| Step: 7
Training loss: 3.28900798833984
Validation loss: 2.862682973306133

Epoch: 5| Step: 8
Training loss: 3.362455720858112
Validation loss: 2.861605289895715

Epoch: 5| Step: 9
Training loss: 2.7185839021303653
Validation loss: 2.865732619704726

Epoch: 5| Step: 10
Training loss: 2.90951633458355
Validation loss: 2.86503224380186

Epoch: 336| Step: 0
Training loss: 3.49311068832406
Validation loss: 2.8668720896375133

Epoch: 5| Step: 1
Training loss: 3.3133543820035594
Validation loss: 2.8644985785302803

Epoch: 5| Step: 2
Training loss: 3.088357097563809
Validation loss: 2.8674108451733504

Epoch: 5| Step: 3
Training loss: 3.344686074116255
Validation loss: 2.8649861919265973

Epoch: 5| Step: 4
Training loss: 3.22351506667346
Validation loss: 2.868558680247821

Epoch: 5| Step: 5
Training loss: 3.3463854519857272
Validation loss: 2.8740572344439133

Epoch: 5| Step: 6
Training loss: 3.0948943516659226
Validation loss: 2.860699506505757

Epoch: 5| Step: 7
Training loss: 3.6185753551236166
Validation loss: 2.864121349740165

Epoch: 5| Step: 8
Training loss: 2.9892686596299436
Validation loss: 2.8655258772949703

Epoch: 5| Step: 9
Training loss: 2.8135954524895324
Validation loss: 2.8619373284921523

Epoch: 5| Step: 10
Training loss: 1.8079541519310214
Validation loss: 2.8627412310253693

Epoch: 337| Step: 0
Training loss: 3.1575772355903284
Validation loss: 2.8613082838576256

Epoch: 5| Step: 1
Training loss: 3.10566451697217
Validation loss: 2.8650743086489934

Epoch: 5| Step: 2
Training loss: 3.016146441822828
Validation loss: 2.8597973680212174

Epoch: 5| Step: 3
Training loss: 3.0069572520894865
Validation loss: 2.8606807050352923

Epoch: 5| Step: 4
Training loss: 2.9759636223938495
Validation loss: 2.859998131566463

Epoch: 5| Step: 5
Training loss: 3.752584711042484
Validation loss: 2.8595714549794886

Epoch: 5| Step: 6
Training loss: 3.049065531175629
Validation loss: 2.8607171751153277

Epoch: 5| Step: 7
Training loss: 3.713384909440003
Validation loss: 2.8587127354340782

Epoch: 5| Step: 8
Training loss: 2.7039645440299496
Validation loss: 2.860442075140091

Epoch: 5| Step: 9
Training loss: 2.7061767110085095
Validation loss: 2.8593590131483415

Epoch: 5| Step: 10
Training loss: 3.3160273646662404
Validation loss: 2.861823810548967

Epoch: 338| Step: 0
Training loss: 2.774400656646598
Validation loss: 2.857083893788655

Epoch: 5| Step: 1
Training loss: 3.3641020407968534
Validation loss: 2.862829387295514

Epoch: 5| Step: 2
Training loss: 2.878055275932984
Validation loss: 2.860613527751895

Epoch: 5| Step: 3
Training loss: 2.6949524569873886
Validation loss: 2.862590672325571

Epoch: 5| Step: 4
Training loss: 3.239561189205785
Validation loss: 2.8626712860670214

Epoch: 5| Step: 5
Training loss: 3.206451921258113
Validation loss: 2.8630613864237886

Epoch: 5| Step: 6
Training loss: 3.2049232459436743
Validation loss: 2.859647993682443

Epoch: 5| Step: 7
Training loss: 3.0619204225770362
Validation loss: 2.86519547142808

Epoch: 5| Step: 8
Training loss: 3.4808205577666733
Validation loss: 2.858853019105973

Epoch: 5| Step: 9
Training loss: 3.2566653640208245
Validation loss: 2.8633678147705663

Epoch: 5| Step: 10
Training loss: 3.405828887386483
Validation loss: 2.865931042462989

Epoch: 339| Step: 0
Training loss: 3.111429273897262
Validation loss: 2.8639601801366195

Epoch: 5| Step: 1
Training loss: 2.9806328924534125
Validation loss: 2.8624617257402707

Epoch: 5| Step: 2
Training loss: 2.8027205942061033
Validation loss: 2.8636625454864735

Epoch: 5| Step: 3
Training loss: 3.019794960893034
Validation loss: 2.862317077979583

Epoch: 5| Step: 4
Training loss: 3.374426475113913
Validation loss: 2.8647912725038958

Epoch: 5| Step: 5
Training loss: 2.947207703725913
Validation loss: 2.860691932162738

Epoch: 5| Step: 6
Training loss: 3.481324780960516
Validation loss: 2.862715436365081

Epoch: 5| Step: 7
Training loss: 3.741366174833334
Validation loss: 2.8643704052019205

Epoch: 5| Step: 8
Training loss: 2.8481521907175638
Validation loss: 2.857423428029594

Epoch: 5| Step: 9
Training loss: 3.4094570356336846
Validation loss: 2.8558287945912837

Epoch: 5| Step: 10
Training loss: 2.7091205235422584
Validation loss: 2.856352205023773

Epoch: 340| Step: 0
Training loss: 3.29056165150584
Validation loss: 2.8581166472060593

Epoch: 5| Step: 1
Training loss: 2.6273476229981396
Validation loss: 2.8567648291825036

Epoch: 5| Step: 2
Training loss: 2.959194183465171
Validation loss: 2.8624473556905765

Epoch: 5| Step: 3
Training loss: 3.117998748994372
Validation loss: 2.8627978792382964

Epoch: 5| Step: 4
Training loss: 3.6190692134920406
Validation loss: 2.854131033860377

Epoch: 5| Step: 5
Training loss: 3.0513049664013985
Validation loss: 2.8624752117580594

Epoch: 5| Step: 6
Training loss: 3.4798466975328206
Validation loss: 2.862509649267366

Epoch: 5| Step: 7
Training loss: 3.1636848130098763
Validation loss: 2.858991547341686

Epoch: 5| Step: 8
Training loss: 2.98747914837699
Validation loss: 2.8596540216626356

Epoch: 5| Step: 9
Training loss: 3.5330749117318727
Validation loss: 2.85999289671164

Epoch: 5| Step: 10
Training loss: 2.5384291577885976
Validation loss: 2.85683789936687

Epoch: 341| Step: 0
Training loss: 3.1557718046919323
Validation loss: 2.86045988515224

Epoch: 5| Step: 1
Training loss: 2.690634828697976
Validation loss: 2.8579479260368714

Epoch: 5| Step: 2
Training loss: 3.27506348643029
Validation loss: 2.857533106030531

Epoch: 5| Step: 3
Training loss: 3.370809284465493
Validation loss: 2.8578670009967

Epoch: 5| Step: 4
Training loss: 3.4852375964223192
Validation loss: 2.8649308469112227

Epoch: 5| Step: 5
Training loss: 3.3418438193024316
Validation loss: 2.8581030311916176

Epoch: 5| Step: 6
Training loss: 2.8287393313690083
Validation loss: 2.8573397256190556

Epoch: 5| Step: 7
Training loss: 3.086013213568809
Validation loss: 2.85994554056043

Epoch: 5| Step: 8
Training loss: 3.3985042872388522
Validation loss: 2.8584289796912645

Epoch: 5| Step: 9
Training loss: 2.4561736971042336
Validation loss: 2.8627050625547636

Epoch: 5| Step: 10
Training loss: 3.3797373548861303
Validation loss: 2.8619455659909687

Epoch: 342| Step: 0
Training loss: 3.277758820976426
Validation loss: 2.861653758114434

Epoch: 5| Step: 1
Training loss: 3.0607243275274976
Validation loss: 2.86951542590388

Epoch: 5| Step: 2
Training loss: 3.2852405804890292
Validation loss: 2.8631573173621523

Epoch: 5| Step: 3
Training loss: 3.698127561474523
Validation loss: 2.862670901431967

Epoch: 5| Step: 4
Training loss: 3.191087536439915
Validation loss: 2.8628747588259893

Epoch: 5| Step: 5
Training loss: 3.1377551883098107
Validation loss: 2.8587901499438515

Epoch: 5| Step: 6
Training loss: 2.5771855347663912
Validation loss: 2.85590892011907

Epoch: 5| Step: 7
Training loss: 2.9993131169117384
Validation loss: 2.85114942686583

Epoch: 5| Step: 8
Training loss: 3.3843996055885035
Validation loss: 2.853263114351343

Epoch: 5| Step: 9
Training loss: 2.2999216232214144
Validation loss: 2.8503819009529106

Epoch: 5| Step: 10
Training loss: 3.537175296398754
Validation loss: 2.849905312689965

Epoch: 343| Step: 0
Training loss: 3.445256862061384
Validation loss: 2.8528220004180387

Epoch: 5| Step: 1
Training loss: 2.7616326778655473
Validation loss: 2.8537602043507517

Epoch: 5| Step: 2
Training loss: 3.714865314409019
Validation loss: 2.850029438394241

Epoch: 5| Step: 3
Training loss: 2.7408029913873153
Validation loss: 2.859903624827113

Epoch: 5| Step: 4
Training loss: 3.4642940459340825
Validation loss: 2.853197690637552

Epoch: 5| Step: 5
Training loss: 2.620406445870342
Validation loss: 2.8534309733062098

Epoch: 5| Step: 6
Training loss: 3.3115374048197777
Validation loss: 2.857866844910541

Epoch: 5| Step: 7
Training loss: 2.604939602904035
Validation loss: 2.86661242860374

Epoch: 5| Step: 8
Training loss: 3.3187786553649015
Validation loss: 2.8622051353852616

Epoch: 5| Step: 9
Training loss: 3.2736041406719014
Validation loss: 2.8509050209992557

Epoch: 5| Step: 10
Training loss: 3.1605366217409543
Validation loss: 2.8529490966757582

Epoch: 344| Step: 0
Training loss: 3.6499906252387904
Validation loss: 2.8486945991233603

Epoch: 5| Step: 1
Training loss: 2.862675663917781
Validation loss: 2.850102532842837

Epoch: 5| Step: 2
Training loss: 3.489089991678595
Validation loss: 2.8488721994049784

Epoch: 5| Step: 3
Training loss: 2.617441648982387
Validation loss: 2.8470981850673605

Epoch: 5| Step: 4
Training loss: 2.615466471508749
Validation loss: 2.84866836769044

Epoch: 5| Step: 5
Training loss: 3.2765801032252457
Validation loss: 2.8525539704675356

Epoch: 5| Step: 6
Training loss: 3.270053908344106
Validation loss: 2.848647891201957

Epoch: 5| Step: 7
Training loss: 3.2705113116769873
Validation loss: 2.8521310358350256

Epoch: 5| Step: 8
Training loss: 2.913733742503695
Validation loss: 2.847182632465845

Epoch: 5| Step: 9
Training loss: 2.871643927143356
Validation loss: 2.8488613886865415

Epoch: 5| Step: 10
Training loss: 3.6139263834968296
Validation loss: 2.846212237730867

Epoch: 345| Step: 0
Training loss: 3.5311886942445248
Validation loss: 2.845173824246792

Epoch: 5| Step: 1
Training loss: 3.2599911803143793
Validation loss: 2.847415321225622

Epoch: 5| Step: 2
Training loss: 2.970906648805709
Validation loss: 2.8487803958565174

Epoch: 5| Step: 3
Training loss: 3.4225289055305135
Validation loss: 2.851601526631346

Epoch: 5| Step: 4
Training loss: 2.4238441583562675
Validation loss: 2.8464019699022214

Epoch: 5| Step: 5
Training loss: 3.1074461201717574
Validation loss: 2.8519531575763897

Epoch: 5| Step: 6
Training loss: 3.1453442393339293
Validation loss: 2.8453219906657106

Epoch: 5| Step: 7
Training loss: 2.3539090536045784
Validation loss: 2.8513003235663157

Epoch: 5| Step: 8
Training loss: 3.9310870550739923
Validation loss: 2.851239608529418

Epoch: 5| Step: 9
Training loss: 3.24500036818586
Validation loss: 2.8545163141559726

Epoch: 5| Step: 10
Training loss: 2.7403883724212634
Validation loss: 2.8467656512235253

Epoch: 346| Step: 0
Training loss: 2.734799335796682
Validation loss: 2.8595738190811266

Epoch: 5| Step: 1
Training loss: 3.365695419212384
Validation loss: 2.8505129615717557

Epoch: 5| Step: 2
Training loss: 2.86195582252171
Validation loss: 2.8500982368721615

Epoch: 5| Step: 3
Training loss: 3.1370043784862798
Validation loss: 2.8580836636896247

Epoch: 5| Step: 4
Training loss: 2.9200290009613052
Validation loss: 2.8579064510514702

Epoch: 5| Step: 5
Training loss: 2.7347549610450383
Validation loss: 2.858174660746689

Epoch: 5| Step: 6
Training loss: 3.583654670205834
Validation loss: 2.8542804256721204

Epoch: 5| Step: 7
Training loss: 3.4935388873196125
Validation loss: 2.8538267183022716

Epoch: 5| Step: 8
Training loss: 3.336410881957165
Validation loss: 2.849136566227792

Epoch: 5| Step: 9
Training loss: 2.759946867113487
Validation loss: 2.8534269806296524

Epoch: 5| Step: 10
Training loss: 3.462380411995569
Validation loss: 2.8543143387267724

Epoch: 347| Step: 0
Training loss: 2.6769836842635013
Validation loss: 2.8457886822094918

Epoch: 5| Step: 1
Training loss: 3.806429047280401
Validation loss: 2.8482374871438694

Epoch: 5| Step: 2
Training loss: 2.977904970701108
Validation loss: 2.8463366172563327

Epoch: 5| Step: 3
Training loss: 3.1202784154842207
Validation loss: 2.8438928264678776

Epoch: 5| Step: 4
Training loss: 2.9558751455324637
Validation loss: 2.8490125302992633

Epoch: 5| Step: 5
Training loss: 3.101933762168427
Validation loss: 2.8421121699571836

Epoch: 5| Step: 6
Training loss: 3.241702712250057
Validation loss: 2.8426524138669436

Epoch: 5| Step: 7
Training loss: 2.893663613531533
Validation loss: 2.844852483065697

Epoch: 5| Step: 8
Training loss: 2.903968489757069
Validation loss: 2.844734398791451

Epoch: 5| Step: 9
Training loss: 3.0137481383132405
Validation loss: 2.845284406923537

Epoch: 5| Step: 10
Training loss: 3.754983642176772
Validation loss: 2.842324333264016

Epoch: 348| Step: 0
Training loss: 3.2671929934513386
Validation loss: 2.8466024713909253

Epoch: 5| Step: 1
Training loss: 3.0272286079413906
Validation loss: 2.8481311785511685

Epoch: 5| Step: 2
Training loss: 2.244353414594785
Validation loss: 2.84322077926895

Epoch: 5| Step: 3
Training loss: 3.405733261809877
Validation loss: 2.8448317601301056

Epoch: 5| Step: 4
Training loss: 3.193686670918416
Validation loss: 2.8498720272385736

Epoch: 5| Step: 5
Training loss: 2.7581147198514655
Validation loss: 2.84244006580408

Epoch: 5| Step: 6
Training loss: 3.461601796345149
Validation loss: 2.849907421241221

Epoch: 5| Step: 7
Training loss: 3.273389283328141
Validation loss: 2.8563805297988223

Epoch: 5| Step: 8
Training loss: 3.2084174372230696
Validation loss: 2.851860716977678

Epoch: 5| Step: 9
Training loss: 3.5264473723488754
Validation loss: 2.8470105871312197

Epoch: 5| Step: 10
Training loss: 2.896782003842057
Validation loss: 2.846207398157534

Epoch: 349| Step: 0
Training loss: 3.1876271540393404
Validation loss: 2.846762359729568

Epoch: 5| Step: 1
Training loss: 2.860186352293961
Validation loss: 2.846862220431554

Epoch: 5| Step: 2
Training loss: 3.0432583202241115
Validation loss: 2.8408393591174956

Epoch: 5| Step: 3
Training loss: 3.6755539664721586
Validation loss: 2.846713309264575

Epoch: 5| Step: 4
Training loss: 2.9946092809895206
Validation loss: 2.8404907215402098

Epoch: 5| Step: 5
Training loss: 3.406412663206803
Validation loss: 2.841589553138426

Epoch: 5| Step: 6
Training loss: 3.098226064296051
Validation loss: 2.842339471589132

Epoch: 5| Step: 7
Training loss: 3.0998015124857723
Validation loss: 2.8416998287300363

Epoch: 5| Step: 8
Training loss: 2.9667068678743065
Validation loss: 2.8420195066880884

Epoch: 5| Step: 9
Training loss: 2.9635491038644233
Validation loss: 2.847891510161751

Epoch: 5| Step: 10
Training loss: 3.0969859452684685
Validation loss: 2.8428937796524547

Epoch: 350| Step: 0
Training loss: 3.2876008108949106
Validation loss: 2.850328848302749

Epoch: 5| Step: 1
Training loss: 3.789136370695832
Validation loss: 2.8443652919292726

Epoch: 5| Step: 2
Training loss: 2.8439750163165316
Validation loss: 2.8432770806525096

Epoch: 5| Step: 3
Training loss: 3.628058097281654
Validation loss: 2.8399480308082974

Epoch: 5| Step: 4
Training loss: 2.9225146567545752
Validation loss: 2.8399222466745426

Epoch: 5| Step: 5
Training loss: 3.0863823292429573
Validation loss: 2.8409587869632382

Epoch: 5| Step: 6
Training loss: 3.0220680782645397
Validation loss: 2.842692874091484

Epoch: 5| Step: 7
Training loss: 3.537083761037159
Validation loss: 2.8385504085831017

Epoch: 5| Step: 8
Training loss: 2.4988955919330293
Validation loss: 2.8397731620742035

Epoch: 5| Step: 9
Training loss: 2.6359064503973926
Validation loss: 2.838350509765386

Epoch: 5| Step: 10
Training loss: 3.0247664180139466
Validation loss: 2.839200296088105

Testing loss: 3.040577384259645
