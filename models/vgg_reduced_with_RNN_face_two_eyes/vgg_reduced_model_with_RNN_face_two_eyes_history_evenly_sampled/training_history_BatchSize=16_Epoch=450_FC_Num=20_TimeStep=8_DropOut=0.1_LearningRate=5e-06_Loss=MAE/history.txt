Epoch: 1| Step: 0
Training loss: 4.820409297943115
Validation loss: 5.1827558291855675

Epoch: 6| Step: 1
Training loss: 5.788844108581543
Validation loss: 5.177726258513748

Epoch: 6| Step: 2
Training loss: 4.754116058349609
Validation loss: 5.173425556511007

Epoch: 6| Step: 3
Training loss: 4.541409492492676
Validation loss: 5.168506063440795

Epoch: 6| Step: 4
Training loss: 5.452068328857422
Validation loss: 5.163876584781113

Epoch: 6| Step: 5
Training loss: 5.773271083831787
Validation loss: 5.159096722961754

Epoch: 6| Step: 6
Training loss: 5.6635236740112305
Validation loss: 5.15438005488406

Epoch: 6| Step: 7
Training loss: 4.021617889404297
Validation loss: 5.149654075663577

Epoch: 6| Step: 8
Training loss: 4.217916488647461
Validation loss: 5.144576154729371

Epoch: 6| Step: 9
Training loss: 4.127682685852051
Validation loss: 5.139664532035909

Epoch: 6| Step: 10
Training loss: 5.092998504638672
Validation loss: 5.134626255240492

Epoch: 6| Step: 11
Training loss: 4.746662616729736
Validation loss: 5.1294363698651715

Epoch: 6| Step: 12
Training loss: 5.056849479675293
Validation loss: 5.123789566819386

Epoch: 6| Step: 13
Training loss: 5.43253755569458
Validation loss: 5.118225723184565

Epoch: 2| Step: 0
Training loss: 5.119318008422852
Validation loss: 5.112302113604802

Epoch: 6| Step: 1
Training loss: 4.700559616088867
Validation loss: 5.106071369622343

Epoch: 6| Step: 2
Training loss: 6.465778350830078
Validation loss: 5.099781918269332

Epoch: 6| Step: 3
Training loss: 3.590514659881592
Validation loss: 5.092605975366408

Epoch: 6| Step: 4
Training loss: 4.320178508758545
Validation loss: 5.085407400643954

Epoch: 6| Step: 5
Training loss: 4.2858662605285645
Validation loss: 5.078287709143854

Epoch: 6| Step: 6
Training loss: 5.857865333557129
Validation loss: 5.070635088028446

Epoch: 6| Step: 7
Training loss: 4.274603366851807
Validation loss: 5.062652105926185

Epoch: 6| Step: 8
Training loss: 4.681835651397705
Validation loss: 5.054218440927485

Epoch: 6| Step: 9
Training loss: 5.368001937866211
Validation loss: 5.045476872433898

Epoch: 6| Step: 10
Training loss: 5.573149681091309
Validation loss: 5.036480493442987

Epoch: 6| Step: 11
Training loss: 4.2510294914245605
Validation loss: 5.027080320542859

Epoch: 6| Step: 12
Training loss: 4.043745994567871
Validation loss: 5.016810360775199

Epoch: 6| Step: 13
Training loss: 6.002459526062012
Validation loss: 5.00596268971761

Epoch: 3| Step: 0
Training loss: 4.775981903076172
Validation loss: 4.994979499488749

Epoch: 6| Step: 1
Training loss: 6.298017501831055
Validation loss: 4.98287618801158

Epoch: 6| Step: 2
Training loss: 3.782515048980713
Validation loss: 4.971147521849601

Epoch: 6| Step: 3
Training loss: 4.917520523071289
Validation loss: 4.958193927682856

Epoch: 6| Step: 4
Training loss: 5.2007365226745605
Validation loss: 4.945416224900113

Epoch: 6| Step: 5
Training loss: 4.924692630767822
Validation loss: 4.931437020660729

Epoch: 6| Step: 6
Training loss: 4.5412373542785645
Validation loss: 4.9169624159413

Epoch: 6| Step: 7
Training loss: 4.172808647155762
Validation loss: 4.90203026289581

Epoch: 6| Step: 8
Training loss: 3.910705089569092
Validation loss: 4.886566233891313

Epoch: 6| Step: 9
Training loss: 5.218699932098389
Validation loss: 4.869554755508259

Epoch: 6| Step: 10
Training loss: 4.466584205627441
Validation loss: 4.852508575685563

Epoch: 6| Step: 11
Training loss: 5.296820640563965
Validation loss: 4.835017755467405

Epoch: 6| Step: 12
Training loss: 4.194446563720703
Validation loss: 4.817680522959719

Epoch: 6| Step: 13
Training loss: 3.571934700012207
Validation loss: 4.797027413563062

Epoch: 4| Step: 0
Training loss: 4.249579906463623
Validation loss: 4.7765182320789625

Epoch: 6| Step: 1
Training loss: 4.349983215332031
Validation loss: 4.757294024190595

Epoch: 6| Step: 2
Training loss: 4.8899126052856445
Validation loss: 4.735929104589647

Epoch: 6| Step: 3
Training loss: 4.719806671142578
Validation loss: 4.712981116387152

Epoch: 6| Step: 4
Training loss: 5.577667236328125
Validation loss: 4.691390227246028

Epoch: 6| Step: 5
Training loss: 4.656865119934082
Validation loss: 4.66767866380753

Epoch: 6| Step: 6
Training loss: 5.5651044845581055
Validation loss: 4.6433452995874545

Epoch: 6| Step: 7
Training loss: 3.70143723487854
Validation loss: 4.618444032566522

Epoch: 6| Step: 8
Training loss: 4.195350646972656
Validation loss: 4.592576067934754

Epoch: 6| Step: 9
Training loss: 3.9429006576538086
Validation loss: 4.567734169703658

Epoch: 6| Step: 10
Training loss: 4.343029022216797
Validation loss: 4.540543707468176

Epoch: 6| Step: 11
Training loss: 3.9326322078704834
Validation loss: 4.51527537069013

Epoch: 6| Step: 12
Training loss: 3.898678779602051
Validation loss: 4.485888424740042

Epoch: 6| Step: 13
Training loss: 3.36197566986084
Validation loss: 4.457767417353969

Epoch: 5| Step: 0
Training loss: 4.530857086181641
Validation loss: 4.429045697694184

Epoch: 6| Step: 1
Training loss: 3.8642868995666504
Validation loss: 4.401316109523978

Epoch: 6| Step: 2
Training loss: 6.081043243408203
Validation loss: 4.3725333367624595

Epoch: 6| Step: 3
Training loss: 2.3280560970306396
Validation loss: 4.341591230002782

Epoch: 6| Step: 4
Training loss: 3.948993444442749
Validation loss: 4.315223132410357

Epoch: 6| Step: 5
Training loss: 4.253354072570801
Validation loss: 4.285638855349633

Epoch: 6| Step: 6
Training loss: 3.9500598907470703
Validation loss: 4.257882266916255

Epoch: 6| Step: 7
Training loss: 3.6093411445617676
Validation loss: 4.229974705685851

Epoch: 6| Step: 8
Training loss: 4.82822847366333
Validation loss: 4.1988770731033815

Epoch: 6| Step: 9
Training loss: 3.1993248462677
Validation loss: 4.170530626850743

Epoch: 6| Step: 10
Training loss: 3.4796371459960938
Validation loss: 4.140660147513112

Epoch: 6| Step: 11
Training loss: 4.0458831787109375
Validation loss: 4.112170993640858

Epoch: 6| Step: 12
Training loss: 4.689988136291504
Validation loss: 4.0834640328602125

Epoch: 6| Step: 13
Training loss: 3.6405656337738037
Validation loss: 4.055847301278063

Epoch: 6| Step: 0
Training loss: 4.179984092712402
Validation loss: 4.027795212243193

Epoch: 6| Step: 1
Training loss: 2.5379810333251953
Validation loss: 4.000417514513898

Epoch: 6| Step: 2
Training loss: 4.302470684051514
Validation loss: 3.9758842247788624

Epoch: 6| Step: 3
Training loss: 4.129909515380859
Validation loss: 3.950060970039778

Epoch: 6| Step: 4
Training loss: 3.71417236328125
Validation loss: 3.9265513599559827

Epoch: 6| Step: 5
Training loss: 4.120563507080078
Validation loss: 3.901007939410466

Epoch: 6| Step: 6
Training loss: 4.705153942108154
Validation loss: 3.877021994642032

Epoch: 6| Step: 7
Training loss: 3.1089627742767334
Validation loss: 3.8526541853463776

Epoch: 6| Step: 8
Training loss: 4.735898017883301
Validation loss: 3.833678630090529

Epoch: 6| Step: 9
Training loss: 3.752652406692505
Validation loss: 3.811558469649284

Epoch: 6| Step: 10
Training loss: 3.9854259490966797
Validation loss: 3.7922606442564275

Epoch: 6| Step: 11
Training loss: 2.8550310134887695
Validation loss: 3.772332599086146

Epoch: 6| Step: 12
Training loss: 3.2553036212921143
Validation loss: 3.7562776688606507

Epoch: 6| Step: 13
Training loss: 2.4436330795288086
Validation loss: 3.740873921302057

Epoch: 7| Step: 0
Training loss: 3.504922389984131
Validation loss: 3.728333047641221

Epoch: 6| Step: 1
Training loss: 4.099820613861084
Validation loss: 3.7135331553797566

Epoch: 6| Step: 2
Training loss: 2.032371997833252
Validation loss: 3.699169558863486

Epoch: 6| Step: 3
Training loss: 3.422579765319824
Validation loss: 3.688867586915211

Epoch: 6| Step: 4
Training loss: 3.3667802810668945
Validation loss: 3.676230940767514

Epoch: 6| Step: 5
Training loss: 4.332546234130859
Validation loss: 3.6656416308495308

Epoch: 6| Step: 6
Training loss: 2.6103711128234863
Validation loss: 3.6533725543688704

Epoch: 6| Step: 7
Training loss: 4.39964485168457
Validation loss: 3.6425875950885076

Epoch: 6| Step: 8
Training loss: 3.0916690826416016
Validation loss: 3.631762417413855

Epoch: 6| Step: 9
Training loss: 2.9071877002716064
Validation loss: 3.6226530946711057

Epoch: 6| Step: 10
Training loss: 3.8824479579925537
Validation loss: 3.612083532476938

Epoch: 6| Step: 11
Training loss: 3.9988510608673096
Validation loss: 3.602516851117534

Epoch: 6| Step: 12
Training loss: 4.416886329650879
Validation loss: 3.592269156568794

Epoch: 6| Step: 13
Training loss: 3.9632861614227295
Validation loss: 3.585499422524565

Epoch: 8| Step: 0
Training loss: 4.236561298370361
Validation loss: 3.5760203202565513

Epoch: 6| Step: 1
Training loss: 2.560133457183838
Validation loss: 3.568609986253964

Epoch: 6| Step: 2
Training loss: 3.5484347343444824
Validation loss: 3.561971200409756

Epoch: 6| Step: 3
Training loss: 3.6183366775512695
Validation loss: 3.5539473256757184

Epoch: 6| Step: 4
Training loss: 3.0699000358581543
Validation loss: 3.545921723047892

Epoch: 6| Step: 5
Training loss: 3.4999794960021973
Validation loss: 3.5375388335156184

Epoch: 6| Step: 6
Training loss: 5.237382888793945
Validation loss: 3.5268131456067486

Epoch: 6| Step: 7
Training loss: 3.5818824768066406
Validation loss: 3.5209379657622306

Epoch: 6| Step: 8
Training loss: 4.547172546386719
Validation loss: 3.5098553729313675

Epoch: 6| Step: 9
Training loss: 2.287290573120117
Validation loss: 3.5029051457681963

Epoch: 6| Step: 10
Training loss: 2.2614798545837402
Validation loss: 3.4928589764461724

Epoch: 6| Step: 11
Training loss: 3.045377731323242
Validation loss: 3.483873046854491

Epoch: 6| Step: 12
Training loss: 3.9834721088409424
Validation loss: 3.4773480661453737

Epoch: 6| Step: 13
Training loss: 2.4505088329315186
Validation loss: 3.4689578856191328

Epoch: 9| Step: 0
Training loss: 3.6328930854797363
Validation loss: 3.4629617557730725

Epoch: 6| Step: 1
Training loss: 3.364259719848633
Validation loss: 3.4567172604222454

Epoch: 6| Step: 2
Training loss: 3.5076241493225098
Validation loss: 3.4492251898652766

Epoch: 6| Step: 3
Training loss: 2.2531936168670654
Validation loss: 3.4409368704724055

Epoch: 6| Step: 4
Training loss: 3.796276330947876
Validation loss: 3.43383950315496

Epoch: 6| Step: 5
Training loss: 3.1775307655334473
Validation loss: 3.4263581563067693

Epoch: 6| Step: 6
Training loss: 2.9396963119506836
Validation loss: 3.422916458499047

Epoch: 6| Step: 7
Training loss: 3.9043447971343994
Validation loss: 3.4186599946791127

Epoch: 6| Step: 8
Training loss: 3.8594717979431152
Validation loss: 3.413202860022104

Epoch: 6| Step: 9
Training loss: 2.5536386966705322
Validation loss: 3.4065509585924048

Epoch: 6| Step: 10
Training loss: 4.015677452087402
Validation loss: 3.4005604841375865

Epoch: 6| Step: 11
Training loss: 3.2233645915985107
Validation loss: 3.3948363796357186

Epoch: 6| Step: 12
Training loss: 3.776643991470337
Validation loss: 3.389165432222428

Epoch: 6| Step: 13
Training loss: 2.9449548721313477
Validation loss: 3.385777176067393

Epoch: 10| Step: 0
Training loss: 3.813720941543579
Validation loss: 3.3789598634166103

Epoch: 6| Step: 1
Training loss: 2.829072952270508
Validation loss: 3.374749880965038

Epoch: 6| Step: 2
Training loss: 3.0853683948516846
Validation loss: 3.3705035050710044

Epoch: 6| Step: 3
Training loss: 3.161067008972168
Validation loss: 3.364377091007848

Epoch: 6| Step: 4
Training loss: 3.5201797485351562
Validation loss: 3.3601445280095583

Epoch: 6| Step: 5
Training loss: 3.4538261890411377
Validation loss: 3.356523847067228

Epoch: 6| Step: 6
Training loss: 2.6178336143493652
Validation loss: 3.352304945709885

Epoch: 6| Step: 7
Training loss: 3.467001438140869
Validation loss: 3.3496169095398276

Epoch: 6| Step: 8
Training loss: 3.433310031890869
Validation loss: 3.344225593792495

Epoch: 6| Step: 9
Training loss: 2.8592958450317383
Validation loss: 3.3386841281767814

Epoch: 6| Step: 10
Training loss: 3.512777090072632
Validation loss: 3.3367826400264615

Epoch: 6| Step: 11
Training loss: 3.4842026233673096
Validation loss: 3.3284213671120266

Epoch: 6| Step: 12
Training loss: 4.174211025238037
Validation loss: 3.3258387914267917

Epoch: 6| Step: 13
Training loss: 2.646517753601074
Validation loss: 3.3195684853420464

Epoch: 11| Step: 0
Training loss: 3.824960470199585
Validation loss: 3.315190138355378

Epoch: 6| Step: 1
Training loss: 3.932387113571167
Validation loss: 3.3126467274081324

Epoch: 6| Step: 2
Training loss: 1.6661536693572998
Validation loss: 3.310557883272889

Epoch: 6| Step: 3
Training loss: 2.8220863342285156
Validation loss: 3.305167018726308

Epoch: 6| Step: 4
Training loss: 3.534231662750244
Validation loss: 3.299132793180404

Epoch: 6| Step: 5
Training loss: 3.3158810138702393
Validation loss: 3.295361752151161

Epoch: 6| Step: 6
Training loss: 2.8963658809661865
Validation loss: 3.290492352618966

Epoch: 6| Step: 7
Training loss: 3.6856210231781006
Validation loss: 3.289311942233834

Epoch: 6| Step: 8
Training loss: 3.516244411468506
Validation loss: 3.2836057729618524

Epoch: 6| Step: 9
Training loss: 2.5899431705474854
Validation loss: 3.2786673243327806

Epoch: 6| Step: 10
Training loss: 3.5468690395355225
Validation loss: 3.274259175023725

Epoch: 6| Step: 11
Training loss: 3.89618182182312
Validation loss: 3.2692627419707594

Epoch: 6| Step: 12
Training loss: 2.709177017211914
Validation loss: 3.2656007889778382

Epoch: 6| Step: 13
Training loss: 4.071843147277832
Validation loss: 3.2609027329311577

Epoch: 12| Step: 0
Training loss: 3.3288395404815674
Validation loss: 3.2589395533325853

Epoch: 6| Step: 1
Training loss: 2.9928009510040283
Validation loss: 3.257613043631277

Epoch: 6| Step: 2
Training loss: 3.5705103874206543
Validation loss: 3.2523360226743963

Epoch: 6| Step: 3
Training loss: 3.315279722213745
Validation loss: 3.2505674157091367

Epoch: 6| Step: 4
Training loss: 4.059329509735107
Validation loss: 3.2428678030608804

Epoch: 6| Step: 5
Training loss: 2.997138023376465
Validation loss: 3.235463450031896

Epoch: 6| Step: 6
Training loss: 3.2162458896636963
Validation loss: 3.2304847778812533

Epoch: 6| Step: 7
Training loss: 3.6116538047790527
Validation loss: 3.2326144479936167

Epoch: 6| Step: 8
Training loss: 2.8043689727783203
Validation loss: 3.2301264116840978

Epoch: 6| Step: 9
Training loss: 4.177935600280762
Validation loss: 3.22598849573443

Epoch: 6| Step: 10
Training loss: 3.8543665409088135
Validation loss: 3.2131294537616033

Epoch: 6| Step: 11
Training loss: 1.7827930450439453
Validation loss: 3.215732282207858

Epoch: 6| Step: 12
Training loss: 1.8454232215881348
Validation loss: 3.2140903293445544

Epoch: 6| Step: 13
Training loss: 3.7941911220550537
Validation loss: 3.21616038199394

Epoch: 13| Step: 0
Training loss: 3.3148183822631836
Validation loss: 3.2106317935451383

Epoch: 6| Step: 1
Training loss: 2.9093940258026123
Validation loss: 3.2062485423139346

Epoch: 6| Step: 2
Training loss: 2.9026637077331543
Validation loss: 3.199751612960651

Epoch: 6| Step: 3
Training loss: 3.2905654907226562
Validation loss: 3.1959278070798485

Epoch: 6| Step: 4
Training loss: 2.487823486328125
Validation loss: 3.19083740890667

Epoch: 6| Step: 5
Training loss: 3.364895820617676
Validation loss: 3.1918094901628393

Epoch: 6| Step: 6
Training loss: 3.0831077098846436
Validation loss: 3.194478437464724

Epoch: 6| Step: 7
Training loss: 3.379615545272827
Validation loss: 3.1898610822616087

Epoch: 6| Step: 8
Training loss: 3.9034323692321777
Validation loss: 3.1875875611459055

Epoch: 6| Step: 9
Training loss: 3.1731908321380615
Validation loss: 3.1802438459088727

Epoch: 6| Step: 10
Training loss: 2.3850016593933105
Validation loss: 3.1796480404433383

Epoch: 6| Step: 11
Training loss: 3.72000789642334
Validation loss: 3.1737441247509373

Epoch: 6| Step: 12
Training loss: 3.3509881496429443
Validation loss: 3.171222681640297

Epoch: 6| Step: 13
Training loss: 3.5066733360290527
Validation loss: 3.1696437199910483

Epoch: 14| Step: 0
Training loss: 3.835637092590332
Validation loss: 3.1653058323808896

Epoch: 6| Step: 1
Training loss: 2.2951793670654297
Validation loss: 3.161961865681474

Epoch: 6| Step: 2
Training loss: 2.990553140640259
Validation loss: 3.1635716512639034

Epoch: 6| Step: 3
Training loss: 2.7660677433013916
Validation loss: 3.1597230485690537

Epoch: 6| Step: 4
Training loss: 3.8249335289001465
Validation loss: 3.158495318505072

Epoch: 6| Step: 5
Training loss: 3.037463665008545
Validation loss: 3.1549279356515534

Epoch: 6| Step: 6
Training loss: 3.3856682777404785
Validation loss: 3.1491993063239643

Epoch: 6| Step: 7
Training loss: 1.9616681337356567
Validation loss: 3.1499347635494765

Epoch: 6| Step: 8
Training loss: 3.298544406890869
Validation loss: 3.1500622072527484

Epoch: 6| Step: 9
Training loss: 3.7570862770080566
Validation loss: 3.1453608312914447

Epoch: 6| Step: 10
Training loss: 2.921992540359497
Validation loss: 3.1409830431784354

Epoch: 6| Step: 11
Training loss: 3.494213104248047
Validation loss: 3.141859854421308

Epoch: 6| Step: 12
Training loss: 3.5387210845947266
Validation loss: 3.139638126537364

Epoch: 6| Step: 13
Training loss: 3.0702898502349854
Validation loss: 3.133027276685161

Epoch: 15| Step: 0
Training loss: 3.5532100200653076
Validation loss: 3.131925385485413

Epoch: 6| Step: 1
Training loss: 2.6653642654418945
Validation loss: 3.1234847089295745

Epoch: 6| Step: 2
Training loss: 2.9795827865600586
Validation loss: 3.1224968356470906

Epoch: 6| Step: 3
Training loss: 2.4516496658325195
Validation loss: 3.1179740172560497

Epoch: 6| Step: 4
Training loss: 3.4211456775665283
Validation loss: 3.1186516720761537

Epoch: 6| Step: 5
Training loss: 4.353456020355225
Validation loss: 3.1144179554395777

Epoch: 6| Step: 6
Training loss: 3.027353525161743
Validation loss: 3.114325043975666

Epoch: 6| Step: 7
Training loss: 3.295565605163574
Validation loss: 3.1110403127567743

Epoch: 6| Step: 8
Training loss: 1.855473518371582
Validation loss: 3.1122747851956274

Epoch: 6| Step: 9
Training loss: 3.4181509017944336
Validation loss: 3.111204206302602

Epoch: 6| Step: 10
Training loss: 3.669431686401367
Validation loss: 3.104790195342033

Epoch: 6| Step: 11
Training loss: 2.8664419651031494
Validation loss: 3.105788302677934

Epoch: 6| Step: 12
Training loss: 3.625549793243408
Validation loss: 3.0984550496583343

Epoch: 6| Step: 13
Training loss: 2.474020004272461
Validation loss: 3.1006731833181074

Epoch: 16| Step: 0
Training loss: 3.4384453296661377
Validation loss: 3.103048934731432

Epoch: 6| Step: 1
Training loss: 3.6877222061157227
Validation loss: 3.0987747279546594

Epoch: 6| Step: 2
Training loss: 3.2516684532165527
Validation loss: 3.0917782270780174

Epoch: 6| Step: 3
Training loss: 3.468709707260132
Validation loss: 3.087532156257219

Epoch: 6| Step: 4
Training loss: 2.4544525146484375
Validation loss: 3.08741864081352

Epoch: 6| Step: 5
Training loss: 3.012147903442383
Validation loss: 3.0868512302316646

Epoch: 6| Step: 6
Training loss: 3.2519707679748535
Validation loss: 3.0880886354754047

Epoch: 6| Step: 7
Training loss: 3.4279870986938477
Validation loss: 3.0886310479974233

Epoch: 6| Step: 8
Training loss: 3.099889039993286
Validation loss: 3.085259550361223

Epoch: 6| Step: 9
Training loss: 2.250011444091797
Validation loss: 3.0810599660360687

Epoch: 6| Step: 10
Training loss: 3.1930651664733887
Validation loss: 3.0826207924914617

Epoch: 6| Step: 11
Training loss: 3.7553744316101074
Validation loss: 3.076981029202861

Epoch: 6| Step: 12
Training loss: 2.9691874980926514
Validation loss: 3.0731631171318794

Epoch: 6| Step: 13
Training loss: 1.8521450757980347
Validation loss: 3.073466101000386

Epoch: 17| Step: 0
Training loss: 2.878366231918335
Validation loss: 3.078100730014104

Epoch: 6| Step: 1
Training loss: 3.2476789951324463
Validation loss: 3.0771619427588677

Epoch: 6| Step: 2
Training loss: 3.6880218982696533
Validation loss: 3.074669050913985

Epoch: 6| Step: 3
Training loss: 5.0359601974487305
Validation loss: 3.0739637472296275

Epoch: 6| Step: 4
Training loss: 2.307680606842041
Validation loss: 3.070204124655775

Epoch: 6| Step: 5
Training loss: 2.4524519443511963
Validation loss: 3.0736058911969586

Epoch: 6| Step: 6
Training loss: 3.3997321128845215
Validation loss: 3.0743395102921354

Epoch: 6| Step: 7
Training loss: 2.680811882019043
Validation loss: 3.0680737623604397

Epoch: 6| Step: 8
Training loss: 3.7627880573272705
Validation loss: 3.0653214044468378

Epoch: 6| Step: 9
Training loss: 2.413113832473755
Validation loss: 3.059893100492416

Epoch: 6| Step: 10
Training loss: 2.589165210723877
Validation loss: 3.0550280847857074

Epoch: 6| Step: 11
Training loss: 2.8164145946502686
Validation loss: 3.0533415297026276

Epoch: 6| Step: 12
Training loss: 3.161485195159912
Validation loss: 3.0501071714585826

Epoch: 6| Step: 13
Training loss: 3.0795462131500244
Validation loss: 3.0477835824412685

Epoch: 18| Step: 0
Training loss: 2.797379970550537
Validation loss: 3.0442810443139847

Epoch: 6| Step: 1
Training loss: 3.101202964782715
Validation loss: 3.0457555170982116

Epoch: 6| Step: 2
Training loss: 3.4012343883514404
Validation loss: 3.0447156301108738

Epoch: 6| Step: 3
Training loss: 4.336141109466553
Validation loss: 3.0377770495671097

Epoch: 6| Step: 4
Training loss: 2.8123838901519775
Validation loss: 3.0375053395507154

Epoch: 6| Step: 5
Training loss: 3.5102033615112305
Validation loss: 3.038859926244264

Epoch: 6| Step: 6
Training loss: 2.979597330093384
Validation loss: 3.0335692974828903

Epoch: 6| Step: 7
Training loss: 2.4198617935180664
Validation loss: 3.0346645180897047

Epoch: 6| Step: 8
Training loss: 3.1112074851989746
Validation loss: 3.03413071427294

Epoch: 6| Step: 9
Training loss: 3.1115000247955322
Validation loss: 3.0344253560548187

Epoch: 6| Step: 10
Training loss: 3.2987406253814697
Validation loss: 3.0286537575465378

Epoch: 6| Step: 11
Training loss: 3.0443115234375
Validation loss: 3.0304816897197435

Epoch: 6| Step: 12
Training loss: 2.415926933288574
Validation loss: 3.0279377327170423

Epoch: 6| Step: 13
Training loss: 2.6849489212036133
Validation loss: 3.0292899941885345

Epoch: 19| Step: 0
Training loss: 2.4570865631103516
Validation loss: 3.0270728988032185

Epoch: 6| Step: 1
Training loss: 2.9747259616851807
Validation loss: 3.021365927111718

Epoch: 6| Step: 2
Training loss: 4.242781639099121
Validation loss: 3.0209762793715282

Epoch: 6| Step: 3
Training loss: 3.394695281982422
Validation loss: 3.0191269664354223

Epoch: 6| Step: 4
Training loss: 3.1817574501037598
Validation loss: 3.0157564634917886

Epoch: 6| Step: 5
Training loss: 2.761244297027588
Validation loss: 3.016233105813303

Epoch: 6| Step: 6
Training loss: 2.56107497215271
Validation loss: 3.014173335926507

Epoch: 6| Step: 7
Training loss: 3.6944549083709717
Validation loss: 3.0139948552654636

Epoch: 6| Step: 8
Training loss: 2.3145864009857178
Validation loss: 3.0083494135128555

Epoch: 6| Step: 9
Training loss: 2.3014543056488037
Validation loss: 3.012230157852173

Epoch: 6| Step: 10
Training loss: 3.854414463043213
Validation loss: 3.007662982069036

Epoch: 6| Step: 11
Training loss: 2.8864481449127197
Validation loss: 3.003392093925066

Epoch: 6| Step: 12
Training loss: 3.2813198566436768
Validation loss: 3.00649461694943

Epoch: 6| Step: 13
Training loss: 3.082895040512085
Validation loss: 3.002215346982402

Epoch: 20| Step: 0
Training loss: 2.095057964324951
Validation loss: 3.0015811715074765

Epoch: 6| Step: 1
Training loss: 2.849425792694092
Validation loss: 2.9976096512168966

Epoch: 6| Step: 2
Training loss: 3.3672022819519043
Validation loss: 2.9971973178207234

Epoch: 6| Step: 3
Training loss: 2.904761552810669
Validation loss: 2.999248453365859

Epoch: 6| Step: 4
Training loss: 3.1997170448303223
Validation loss: 2.9979331262650026

Epoch: 6| Step: 5
Training loss: 2.7634403705596924
Validation loss: 3.0016055491662796

Epoch: 6| Step: 6
Training loss: 2.230999708175659
Validation loss: 3.001274029413859

Epoch: 6| Step: 7
Training loss: 3.917238473892212
Validation loss: 2.9936747935510453

Epoch: 6| Step: 8
Training loss: 3.9428932666778564
Validation loss: 2.9918157054531958

Epoch: 6| Step: 9
Training loss: 2.6659631729125977
Validation loss: 2.988085062273087

Epoch: 6| Step: 10
Training loss: 3.4137558937072754
Validation loss: 2.985435411494265

Epoch: 6| Step: 11
Training loss: 2.737880229949951
Validation loss: 2.9928051681928736

Epoch: 6| Step: 12
Training loss: 3.5201053619384766
Validation loss: 3.0219985746568248

Epoch: 6| Step: 13
Training loss: 3.4411070346832275
Validation loss: 2.9964448790396414

Epoch: 21| Step: 0
Training loss: 2.949939250946045
Validation loss: 2.9841919329858597

Epoch: 6| Step: 1
Training loss: 3.248852252960205
Validation loss: 2.990014191596739

Epoch: 6| Step: 2
Training loss: 3.38192081451416
Validation loss: 2.993537361903857

Epoch: 6| Step: 3
Training loss: 2.6266212463378906
Validation loss: 3.0049509104862007

Epoch: 6| Step: 4
Training loss: 3.3307361602783203
Validation loss: 3.018066801050658

Epoch: 6| Step: 5
Training loss: 2.949185371398926
Validation loss: 3.0252911044705297

Epoch: 6| Step: 6
Training loss: 3.129263162612915
Validation loss: 3.018743235577819

Epoch: 6| Step: 7
Training loss: 3.8739395141601562
Validation loss: 3.014503176494311

Epoch: 6| Step: 8
Training loss: 3.3684887886047363
Validation loss: 3.0071807651109594

Epoch: 6| Step: 9
Training loss: 2.5958199501037598
Validation loss: 2.998006428441694

Epoch: 6| Step: 10
Training loss: 3.1040444374084473
Validation loss: 2.992447281396517

Epoch: 6| Step: 11
Training loss: 3.11740779876709
Validation loss: 2.9828323497567126

Epoch: 6| Step: 12
Training loss: 2.324192523956299
Validation loss: 2.9784424228052937

Epoch: 6| Step: 13
Training loss: 2.7127130031585693
Validation loss: 2.9788159657550115

Epoch: 22| Step: 0
Training loss: 2.6065707206726074
Validation loss: 2.9736515732221704

Epoch: 6| Step: 1
Training loss: 2.64389967918396
Validation loss: 2.9726696988587737

Epoch: 6| Step: 2
Training loss: 3.3981852531433105
Validation loss: 2.9726840757554576

Epoch: 6| Step: 3
Training loss: 3.439540386199951
Validation loss: 2.973020568970711

Epoch: 6| Step: 4
Training loss: 2.387423276901245
Validation loss: 2.9781093751230547

Epoch: 6| Step: 5
Training loss: 2.6070761680603027
Validation loss: 2.9956567415627102

Epoch: 6| Step: 6
Training loss: 2.651259183883667
Validation loss: 2.9857727481472875

Epoch: 6| Step: 7
Training loss: 3.518427848815918
Validation loss: 2.965734674084571

Epoch: 6| Step: 8
Training loss: 3.592365026473999
Validation loss: 2.963276324733611

Epoch: 6| Step: 9
Training loss: 2.7894673347473145
Validation loss: 2.9625212684754403

Epoch: 6| Step: 10
Training loss: 2.9099795818328857
Validation loss: 2.9668047428131104

Epoch: 6| Step: 11
Training loss: 3.846925735473633
Validation loss: 2.9692549884960218

Epoch: 6| Step: 12
Training loss: 3.154574394226074
Validation loss: 2.973041831806142

Epoch: 6| Step: 13
Training loss: 3.1174256801605225
Validation loss: 2.975755840219477

Epoch: 23| Step: 0
Training loss: 2.9039368629455566
Validation loss: 2.98048980774418

Epoch: 6| Step: 1
Training loss: 3.52493953704834
Validation loss: 2.9780540389399373

Epoch: 6| Step: 2
Training loss: 3.3495521545410156
Validation loss: 2.968529209013908

Epoch: 6| Step: 3
Training loss: 3.091620445251465
Validation loss: 2.9664544520839566

Epoch: 6| Step: 4
Training loss: 3.398364543914795
Validation loss: 2.9607268251398557

Epoch: 6| Step: 5
Training loss: 3.5096824169158936
Validation loss: 2.952667923383815

Epoch: 6| Step: 6
Training loss: 3.0103423595428467
Validation loss: 2.9497552712758384

Epoch: 6| Step: 7
Training loss: 2.962738513946533
Validation loss: 2.9465073052273003

Epoch: 6| Step: 8
Training loss: 2.7907474040985107
Validation loss: 2.9466700758985294

Epoch: 6| Step: 9
Training loss: 2.3022923469543457
Validation loss: 2.9430560040217575

Epoch: 6| Step: 10
Training loss: 3.1319756507873535
Validation loss: 2.943153630020798

Epoch: 6| Step: 11
Training loss: 2.539522647857666
Validation loss: 2.941961355106805

Epoch: 6| Step: 12
Training loss: 3.205862045288086
Validation loss: 2.942896553265151

Epoch: 6| Step: 13
Training loss: 2.5498127937316895
Validation loss: 2.9447475094949045

Epoch: 24| Step: 0
Training loss: 2.7563085556030273
Validation loss: 2.9409008743942424

Epoch: 6| Step: 1
Training loss: 3.6271562576293945
Validation loss: 2.942589262480377

Epoch: 6| Step: 2
Training loss: 2.8938331604003906
Validation loss: 2.940430397628456

Epoch: 6| Step: 3
Training loss: 2.147076368331909
Validation loss: 2.9353268915607083

Epoch: 6| Step: 4
Training loss: 2.7430105209350586
Validation loss: 2.931502919043264

Epoch: 6| Step: 5
Training loss: 2.532151699066162
Validation loss: 2.9286424421495005

Epoch: 6| Step: 6
Training loss: 2.4746131896972656
Validation loss: 2.9270774779781217

Epoch: 6| Step: 7
Training loss: 3.0767695903778076
Validation loss: 2.9266783652767057

Epoch: 6| Step: 8
Training loss: 2.9292705059051514
Validation loss: 2.925035592048399

Epoch: 6| Step: 9
Training loss: 3.541760206222534
Validation loss: 2.9247801752500635

Epoch: 6| Step: 10
Training loss: 2.6804871559143066
Validation loss: 2.926050901412964

Epoch: 6| Step: 11
Training loss: 4.119321823120117
Validation loss: 2.9219462025550103

Epoch: 6| Step: 12
Training loss: 3.438063859939575
Validation loss: 2.9223426439428843

Epoch: 6| Step: 13
Training loss: 3.3754825592041016
Validation loss: 2.919428376741307

Epoch: 25| Step: 0
Training loss: 2.7230758666992188
Validation loss: 2.9200396665962796

Epoch: 6| Step: 1
Training loss: 2.894517660140991
Validation loss: 2.9194752823921943

Epoch: 6| Step: 2
Training loss: 3.471281051635742
Validation loss: 2.918236196682017

Epoch: 6| Step: 3
Training loss: 2.267974853515625
Validation loss: 2.916598912208311

Epoch: 6| Step: 4
Training loss: 3.245924949645996
Validation loss: 2.9168177779002855

Epoch: 6| Step: 5
Training loss: 3.4864325523376465
Validation loss: 2.913422164096627

Epoch: 6| Step: 6
Training loss: 2.728321075439453
Validation loss: 2.9141981345351025

Epoch: 6| Step: 7
Training loss: 2.8581318855285645
Validation loss: 2.912821331331807

Epoch: 6| Step: 8
Training loss: 2.8858823776245117
Validation loss: 2.915917747764177

Epoch: 6| Step: 9
Training loss: 4.0448102951049805
Validation loss: 2.915318509583832

Epoch: 6| Step: 10
Training loss: 2.5075109004974365
Validation loss: 2.916694241185342

Epoch: 6| Step: 11
Training loss: 3.487318992614746
Validation loss: 2.912136450890572

Epoch: 6| Step: 12
Training loss: 2.8817214965820312
Validation loss: 2.9089313245588735

Epoch: 6| Step: 13
Training loss: 2.1930220127105713
Validation loss: 2.9090775084751908

Epoch: 26| Step: 0
Training loss: 3.1527726650238037
Validation loss: 2.9051225749395226

Epoch: 6| Step: 1
Training loss: 3.267122268676758
Validation loss: 2.9026424320795203

Epoch: 6| Step: 2
Training loss: 3.2061514854431152
Validation loss: 2.9052194318463727

Epoch: 6| Step: 3
Training loss: 2.1921234130859375
Validation loss: 2.9049210240764003

Epoch: 6| Step: 4
Training loss: 3.3059701919555664
Validation loss: 2.9034035846751225

Epoch: 6| Step: 5
Training loss: 4.047702789306641
Validation loss: 2.9052077262632308

Epoch: 6| Step: 6
Training loss: 2.13280987739563
Validation loss: 2.8994527452735492

Epoch: 6| Step: 7
Training loss: 2.8694369792938232
Validation loss: 2.8998395806999615

Epoch: 6| Step: 8
Training loss: 3.9227731227874756
Validation loss: 2.897818755078059

Epoch: 6| Step: 9
Training loss: 1.7202372550964355
Validation loss: 2.897825312870805

Epoch: 6| Step: 10
Training loss: 3.0487844944000244
Validation loss: 2.898804949175927

Epoch: 6| Step: 11
Training loss: 2.4299285411834717
Validation loss: 2.8958335691882717

Epoch: 6| Step: 12
Training loss: 3.027090549468994
Validation loss: 2.8956562139654674

Epoch: 6| Step: 13
Training loss: 4.060523986816406
Validation loss: 2.8988758466577016

Epoch: 27| Step: 0
Training loss: 3.017810821533203
Validation loss: 2.8965639939872165

Epoch: 6| Step: 1
Training loss: 3.004673957824707
Validation loss: 2.8974812620429584

Epoch: 6| Step: 2
Training loss: 2.6226134300231934
Validation loss: 2.89762294420632

Epoch: 6| Step: 3
Training loss: 2.8133327960968018
Validation loss: 2.8942455732694237

Epoch: 6| Step: 4
Training loss: 2.950355052947998
Validation loss: 2.8904613807637203

Epoch: 6| Step: 5
Training loss: 3.08499813079834
Validation loss: 2.890275083562379

Epoch: 6| Step: 6
Training loss: 2.678950786590576
Validation loss: 2.8893035252889

Epoch: 6| Step: 7
Training loss: 2.969259738922119
Validation loss: 2.890042156301519

Epoch: 6| Step: 8
Training loss: 2.429842948913574
Validation loss: 2.887322812952021

Epoch: 6| Step: 9
Training loss: 3.0451292991638184
Validation loss: 2.8846441212520806

Epoch: 6| Step: 10
Training loss: 3.1835215091705322
Validation loss: 2.886058833009453

Epoch: 6| Step: 11
Training loss: 3.2969553470611572
Validation loss: 2.884390769466277

Epoch: 6| Step: 12
Training loss: 3.0433387756347656
Validation loss: 2.884577448650073

Epoch: 6| Step: 13
Training loss: 4.19987154006958
Validation loss: 2.8820267005633284

Epoch: 28| Step: 0
Training loss: 2.9382355213165283
Validation loss: 2.8816794221119215

Epoch: 6| Step: 1
Training loss: 2.4212799072265625
Validation loss: 2.8807234892281155

Epoch: 6| Step: 2
Training loss: 2.3234806060791016
Validation loss: 2.8835780492392917

Epoch: 6| Step: 3
Training loss: 3.496657371520996
Validation loss: 2.8853650323806272

Epoch: 6| Step: 4
Training loss: 2.619306802749634
Validation loss: 2.8822252006940943

Epoch: 6| Step: 5
Training loss: 2.649000883102417
Validation loss: 2.8792094594688824

Epoch: 6| Step: 6
Training loss: 4.231860160827637
Validation loss: 2.878290404555618

Epoch: 6| Step: 7
Training loss: 3.5400078296661377
Validation loss: 2.8778621637693016

Epoch: 6| Step: 8
Training loss: 3.3203415870666504
Validation loss: 2.8767403710273003

Epoch: 6| Step: 9
Training loss: 2.5580592155456543
Validation loss: 2.8762087539959977

Epoch: 6| Step: 10
Training loss: 3.1341140270233154
Validation loss: 2.8754888042326896

Epoch: 6| Step: 11
Training loss: 3.1123714447021484
Validation loss: 2.874469475079608

Epoch: 6| Step: 12
Training loss: 2.691627025604248
Validation loss: 2.8763761289658083

Epoch: 6| Step: 13
Training loss: 2.417123794555664
Validation loss: 2.8766723743049045

Epoch: 29| Step: 0
Training loss: 4.105961799621582
Validation loss: 2.8740489790516515

Epoch: 6| Step: 1
Training loss: 3.927682399749756
Validation loss: 2.871288581561017

Epoch: 6| Step: 2
Training loss: 3.425095558166504
Validation loss: 2.869958964727258

Epoch: 6| Step: 3
Training loss: 2.4827399253845215
Validation loss: 2.8689859656877417

Epoch: 6| Step: 4
Training loss: 2.8511404991149902
Validation loss: 2.8698432701890186

Epoch: 6| Step: 5
Training loss: 2.3452892303466797
Validation loss: 2.8695956968492076

Epoch: 6| Step: 6
Training loss: 2.524717330932617
Validation loss: 2.868477277858283

Epoch: 6| Step: 7
Training loss: 2.826920986175537
Validation loss: 2.8699286342948995

Epoch: 6| Step: 8
Training loss: 3.0268516540527344
Validation loss: 2.870822086129137

Epoch: 6| Step: 9
Training loss: 2.3539810180664062
Validation loss: 2.871642256295809

Epoch: 6| Step: 10
Training loss: 3.098065137863159
Validation loss: 2.866824701268186

Epoch: 6| Step: 11
Training loss: 3.3494646549224854
Validation loss: 2.863194634837489

Epoch: 6| Step: 12
Training loss: 2.028104782104492
Validation loss: 2.8628305107034664

Epoch: 6| Step: 13
Training loss: 3.450681447982788
Validation loss: 2.8624989883874052

Epoch: 30| Step: 0
Training loss: 3.6255686283111572
Validation loss: 2.862252148248816

Epoch: 6| Step: 1
Training loss: 3.105038642883301
Validation loss: 2.8622767412534325

Epoch: 6| Step: 2
Training loss: 2.9739396572113037
Validation loss: 2.861106490576139

Epoch: 6| Step: 3
Training loss: 2.0288522243499756
Validation loss: 2.8587997856960503

Epoch: 6| Step: 4
Training loss: 2.4240901470184326
Validation loss: 2.8591282470251924

Epoch: 6| Step: 5
Training loss: 2.6230554580688477
Validation loss: 2.8566679211073023

Epoch: 6| Step: 6
Training loss: 3.233332633972168
Validation loss: 2.8578918518558627

Epoch: 6| Step: 7
Training loss: 3.6264169216156006
Validation loss: 2.8558395165269093

Epoch: 6| Step: 8
Training loss: 2.676102876663208
Validation loss: 2.8565660215193227

Epoch: 6| Step: 9
Training loss: 2.554555892944336
Validation loss: 2.8555596387514504

Epoch: 6| Step: 10
Training loss: 3.078730344772339
Validation loss: 2.8553100811537875

Epoch: 6| Step: 11
Training loss: 3.4945735931396484
Validation loss: 2.855371464965164

Epoch: 6| Step: 12
Training loss: 2.9184112548828125
Validation loss: 2.8538441760565645

Epoch: 6| Step: 13
Training loss: 3.297769784927368
Validation loss: 2.852664529636342

Epoch: 31| Step: 0
Training loss: 2.734309673309326
Validation loss: 2.853530935061875

Epoch: 6| Step: 1
Training loss: 2.4234366416931152
Validation loss: 2.8504086540591334

Epoch: 6| Step: 2
Training loss: 3.052508592605591
Validation loss: 2.8503467908469577

Epoch: 6| Step: 3
Training loss: 2.78576922416687
Validation loss: 2.8523665730671217

Epoch: 6| Step: 4
Training loss: 3.5944204330444336
Validation loss: 2.850239138449392

Epoch: 6| Step: 5
Training loss: 2.8852157592773438
Validation loss: 2.848494368214761

Epoch: 6| Step: 6
Training loss: 3.2511279582977295
Validation loss: 2.8492152870342298

Epoch: 6| Step: 7
Training loss: 3.3726582527160645
Validation loss: 2.846511294764857

Epoch: 6| Step: 8
Training loss: 2.924618721008301
Validation loss: 2.8436028008819907

Epoch: 6| Step: 9
Training loss: 2.2965238094329834
Validation loss: 2.8461457221738753

Epoch: 6| Step: 10
Training loss: 2.9268417358398438
Validation loss: 2.844605645825786

Epoch: 6| Step: 11
Training loss: 2.669945001602173
Validation loss: 2.8422440687815347

Epoch: 6| Step: 12
Training loss: 3.2890055179595947
Validation loss: 2.8455737970208608

Epoch: 6| Step: 13
Training loss: 3.3601956367492676
Validation loss: 2.842558063486571

Epoch: 32| Step: 0
Training loss: 3.1319987773895264
Validation loss: 2.8423735198154243

Epoch: 6| Step: 1
Training loss: 2.665483236312866
Validation loss: 2.8430975637128277

Epoch: 6| Step: 2
Training loss: 2.9468088150024414
Validation loss: 2.8379089293941373

Epoch: 6| Step: 3
Training loss: 2.5652198791503906
Validation loss: 2.8396164832576627

Epoch: 6| Step: 4
Training loss: 2.7298781871795654
Validation loss: 2.8368510456495386

Epoch: 6| Step: 5
Training loss: 1.8722989559173584
Validation loss: 2.8382082446928947

Epoch: 6| Step: 6
Training loss: 3.3874123096466064
Validation loss: 2.838194085705665

Epoch: 6| Step: 7
Training loss: 4.127195358276367
Validation loss: 2.8379471840397006

Epoch: 6| Step: 8
Training loss: 2.724564552307129
Validation loss: 2.836932066948183

Epoch: 6| Step: 9
Training loss: 2.629807949066162
Validation loss: 2.836597196517452

Epoch: 6| Step: 10
Training loss: 3.5325515270233154
Validation loss: 2.8383311943341325

Epoch: 6| Step: 11
Training loss: 2.3049731254577637
Validation loss: 2.8405993164226575

Epoch: 6| Step: 12
Training loss: 3.996183395385742
Validation loss: 2.8388604733251754

Epoch: 6| Step: 13
Training loss: 2.484607696533203
Validation loss: 2.83489796679507

Epoch: 33| Step: 0
Training loss: 2.5446054935455322
Validation loss: 2.8322539508983655

Epoch: 6| Step: 1
Training loss: 2.1537299156188965
Validation loss: 2.833266201839652

Epoch: 6| Step: 2
Training loss: 3.528744697570801
Validation loss: 2.8330471541291926

Epoch: 6| Step: 3
Training loss: 3.3135759830474854
Validation loss: 2.8317593400196364

Epoch: 6| Step: 4
Training loss: 3.1092967987060547
Validation loss: 2.8342359886374524

Epoch: 6| Step: 5
Training loss: 4.186388969421387
Validation loss: 2.8307496629735476

Epoch: 6| Step: 6
Training loss: 2.8255763053894043
Validation loss: 2.8310893889396422

Epoch: 6| Step: 7
Training loss: 3.4080448150634766
Validation loss: 2.8295605900467082

Epoch: 6| Step: 8
Training loss: 2.6168317794799805
Validation loss: 2.8296208484198457

Epoch: 6| Step: 9
Training loss: 3.0267553329467773
Validation loss: 2.8273912655409945

Epoch: 6| Step: 10
Training loss: 3.48471999168396
Validation loss: 2.826982654551024

Epoch: 6| Step: 11
Training loss: 1.906001091003418
Validation loss: 2.8265292285591044

Epoch: 6| Step: 12
Training loss: 2.731630325317383
Validation loss: 2.826692409412835

Epoch: 6| Step: 13
Training loss: 2.034146547317505
Validation loss: 2.8267456921198035

Epoch: 34| Step: 0
Training loss: 2.733788013458252
Validation loss: 2.826678273498371

Epoch: 6| Step: 1
Training loss: 2.6186137199401855
Validation loss: 2.828791082546275

Epoch: 6| Step: 2
Training loss: 3.6010794639587402
Validation loss: 2.822780457876062

Epoch: 6| Step: 3
Training loss: 3.4190542697906494
Validation loss: 2.82607340556319

Epoch: 6| Step: 4
Training loss: 2.417591094970703
Validation loss: 2.824716785902618

Epoch: 6| Step: 5
Training loss: 2.3421435356140137
Validation loss: 2.824297135876071

Epoch: 6| Step: 6
Training loss: 3.6722846031188965
Validation loss: 2.8244285224586405

Epoch: 6| Step: 7
Training loss: 2.9101219177246094
Validation loss: 2.8236607864338863

Epoch: 6| Step: 8
Training loss: 2.5272977352142334
Validation loss: 2.8219177671658096

Epoch: 6| Step: 9
Training loss: 3.0930676460266113
Validation loss: 2.820210677321239

Epoch: 6| Step: 10
Training loss: 3.144225597381592
Validation loss: 2.8206373235230804

Epoch: 6| Step: 11
Training loss: 2.7770495414733887
Validation loss: 2.8212452165542112

Epoch: 6| Step: 12
Training loss: 2.6174778938293457
Validation loss: 2.81990546564902

Epoch: 6| Step: 13
Training loss: 3.5795979499816895
Validation loss: 2.816863326616185

Epoch: 35| Step: 0
Training loss: 2.6643357276916504
Validation loss: 2.818987023445868

Epoch: 6| Step: 1
Training loss: 3.8434195518493652
Validation loss: 2.818873108074229

Epoch: 6| Step: 2
Training loss: 3.487368583679199
Validation loss: 2.8186214482912453

Epoch: 6| Step: 3
Training loss: 3.211782455444336
Validation loss: 2.817804516002696

Epoch: 6| Step: 4
Training loss: 2.737423896789551
Validation loss: 2.8161223960179154

Epoch: 6| Step: 5
Training loss: 2.882739543914795
Validation loss: 2.8186279958294285

Epoch: 6| Step: 6
Training loss: 2.642563819885254
Validation loss: 2.8170771701361543

Epoch: 6| Step: 7
Training loss: 2.7538325786590576
Validation loss: 2.81514157531082

Epoch: 6| Step: 8
Training loss: 3.2042458057403564
Validation loss: 2.815454734269009

Epoch: 6| Step: 9
Training loss: 2.5585973262786865
Validation loss: 2.8163067474160144

Epoch: 6| Step: 10
Training loss: 3.148249387741089
Validation loss: 2.8149685577679704

Epoch: 6| Step: 11
Training loss: 2.543933629989624
Validation loss: 2.809876142009612

Epoch: 6| Step: 12
Training loss: 2.1302614212036133
Validation loss: 2.8111911230189826

Epoch: 6| Step: 13
Training loss: 3.5698535442352295
Validation loss: 2.8127416538935837

Epoch: 36| Step: 0
Training loss: 2.5107219219207764
Validation loss: 2.8119484993719284

Epoch: 6| Step: 1
Training loss: 2.9448776245117188
Validation loss: 2.8115518990383355

Epoch: 6| Step: 2
Training loss: 2.208935022354126
Validation loss: 2.8103570989383164

Epoch: 6| Step: 3
Training loss: 2.137789011001587
Validation loss: 2.811295565738473

Epoch: 6| Step: 4
Training loss: 2.4034759998321533
Validation loss: 2.807349225526215

Epoch: 6| Step: 5
Training loss: 3.084052085876465
Validation loss: 2.8090141204095658

Epoch: 6| Step: 6
Training loss: 3.2078633308410645
Validation loss: 2.8082162052072506

Epoch: 6| Step: 7
Training loss: 3.269113540649414
Validation loss: 2.8087220704683693

Epoch: 6| Step: 8
Training loss: 3.22660756111145
Validation loss: 2.8052846744496334

Epoch: 6| Step: 9
Training loss: 3.172107696533203
Validation loss: 2.8064230180555776

Epoch: 6| Step: 10
Training loss: 3.9454965591430664
Validation loss: 2.8060484445223244

Epoch: 6| Step: 11
Training loss: 3.1229124069213867
Validation loss: 2.807255268096924

Epoch: 6| Step: 12
Training loss: 2.8690545558929443
Validation loss: 2.8050636347904

Epoch: 6| Step: 13
Training loss: 2.922607183456421
Validation loss: 2.808758556201894

Epoch: 37| Step: 0
Training loss: 2.5130581855773926
Validation loss: 2.8125484938262613

Epoch: 6| Step: 1
Training loss: 3.1317193508148193
Validation loss: 2.8168112308748308

Epoch: 6| Step: 2
Training loss: 3.2089967727661133
Validation loss: 2.8067776977374987

Epoch: 6| Step: 3
Training loss: 3.143596887588501
Validation loss: 2.8022599886822444

Epoch: 6| Step: 4
Training loss: 3.400333881378174
Validation loss: 2.8019230417025986

Epoch: 6| Step: 5
Training loss: 2.5429935455322266
Validation loss: 2.802547820152775

Epoch: 6| Step: 6
Training loss: 2.9210205078125
Validation loss: 2.8023899037350892

Epoch: 6| Step: 7
Training loss: 2.453423500061035
Validation loss: 2.803905722915485

Epoch: 6| Step: 8
Training loss: 3.8648104667663574
Validation loss: 2.8025908598335842

Epoch: 6| Step: 9
Training loss: 2.9483089447021484
Validation loss: 2.8024822691435456

Epoch: 6| Step: 10
Training loss: 2.6052374839782715
Validation loss: 2.79881029487938

Epoch: 6| Step: 11
Training loss: 2.206584930419922
Validation loss: 2.797022581100464

Epoch: 6| Step: 12
Training loss: 3.1173651218414307
Validation loss: 2.79965538876031

Epoch: 6| Step: 13
Training loss: 3.0072896480560303
Validation loss: 2.796635917437974

Epoch: 38| Step: 0
Training loss: 2.9523255825042725
Validation loss: 2.7972102908677954

Epoch: 6| Step: 1
Training loss: 2.9430222511291504
Validation loss: 2.796929774745818

Epoch: 6| Step: 2
Training loss: 2.9227359294891357
Validation loss: 2.7989666154307704

Epoch: 6| Step: 3
Training loss: 3.1057586669921875
Validation loss: 2.8013301690419516

Epoch: 6| Step: 4
Training loss: 2.8010029792785645
Validation loss: 2.7945195244204615

Epoch: 6| Step: 5
Training loss: 3.6425490379333496
Validation loss: 2.797031887115971

Epoch: 6| Step: 6
Training loss: 3.1372504234313965
Validation loss: 2.796734397129346

Epoch: 6| Step: 7
Training loss: 2.7967679500579834
Validation loss: 2.7949711174093266

Epoch: 6| Step: 8
Training loss: 2.6990885734558105
Validation loss: 2.795038423230571

Epoch: 6| Step: 9
Training loss: 2.1216797828674316
Validation loss: 2.7908081598179315

Epoch: 6| Step: 10
Training loss: 3.335601806640625
Validation loss: 2.7942637346124135

Epoch: 6| Step: 11
Training loss: 3.204421043395996
Validation loss: 2.791807056755148

Epoch: 6| Step: 12
Training loss: 2.646904945373535
Validation loss: 2.7904567051959295

Epoch: 6| Step: 13
Training loss: 2.37420654296875
Validation loss: 2.79086148354315

Epoch: 39| Step: 0
Training loss: 3.0745859146118164
Validation loss: 2.7893132419996363

Epoch: 6| Step: 1
Training loss: 2.3617138862609863
Validation loss: 2.7928722827665267

Epoch: 6| Step: 2
Training loss: 3.2377049922943115
Validation loss: 2.793800107894405

Epoch: 6| Step: 3
Training loss: 3.9387340545654297
Validation loss: 2.7987199547470256

Epoch: 6| Step: 4
Training loss: 2.852341413497925
Validation loss: 2.792903887328281

Epoch: 6| Step: 5
Training loss: 3.156344175338745
Validation loss: 2.786450224538003

Epoch: 6| Step: 6
Training loss: 1.8840124607086182
Validation loss: 2.7879163372901177

Epoch: 6| Step: 7
Training loss: 2.603240966796875
Validation loss: 2.7872709535783335

Epoch: 6| Step: 8
Training loss: 3.03074312210083
Validation loss: 2.787000786873602

Epoch: 6| Step: 9
Training loss: 3.466919422149658
Validation loss: 2.7886076998966995

Epoch: 6| Step: 10
Training loss: 3.3211991786956787
Validation loss: 2.786664601295225

Epoch: 6| Step: 11
Training loss: 2.4061756134033203
Validation loss: 2.78789504625464

Epoch: 6| Step: 12
Training loss: 3.1032984256744385
Validation loss: 2.7860272238331456

Epoch: 6| Step: 13
Training loss: 2.0785367488861084
Validation loss: 2.7867028046679754

Epoch: 40| Step: 0
Training loss: 3.069185256958008
Validation loss: 2.786548847793251

Epoch: 6| Step: 1
Training loss: 3.0706076622009277
Validation loss: 2.782855426111529

Epoch: 6| Step: 2
Training loss: 2.310913324356079
Validation loss: 2.783010736588509

Epoch: 6| Step: 3
Training loss: 2.744603157043457
Validation loss: 2.7838334114320817

Epoch: 6| Step: 4
Training loss: 2.133333683013916
Validation loss: 2.783318752883583

Epoch: 6| Step: 5
Training loss: 3.210718870162964
Validation loss: 2.7830158792516237

Epoch: 6| Step: 6
Training loss: 3.3098859786987305
Validation loss: 2.780692249216059

Epoch: 6| Step: 7
Training loss: 2.4087307453155518
Validation loss: 2.7829362551371255

Epoch: 6| Step: 8
Training loss: 2.758279800415039
Validation loss: 2.781296691586894

Epoch: 6| Step: 9
Training loss: 3.137101411819458
Validation loss: 2.7807627698426605

Epoch: 6| Step: 10
Training loss: 2.4607064723968506
Validation loss: 2.780909953578826

Epoch: 6| Step: 11
Training loss: 3.106204032897949
Validation loss: 2.7789183021873556

Epoch: 6| Step: 12
Training loss: 3.837075710296631
Validation loss: 2.7796754298671598

Epoch: 6| Step: 13
Training loss: 3.513155460357666
Validation loss: 2.776049280679354

Epoch: 41| Step: 0
Training loss: 3.0707268714904785
Validation loss: 2.773851215198476

Epoch: 6| Step: 1
Training loss: 2.150404453277588
Validation loss: 2.773935710230181

Epoch: 6| Step: 2
Training loss: 3.116067886352539
Validation loss: 2.7741438265769713

Epoch: 6| Step: 3
Training loss: 3.307103157043457
Validation loss: 2.774165955922937

Epoch: 6| Step: 4
Training loss: 2.912775993347168
Validation loss: 2.772219027242353

Epoch: 6| Step: 5
Training loss: 2.366400718688965
Validation loss: 2.772372104788339

Epoch: 6| Step: 6
Training loss: 4.004420280456543
Validation loss: 2.7704594263466458

Epoch: 6| Step: 7
Training loss: 2.6007018089294434
Validation loss: 2.77211679181745

Epoch: 6| Step: 8
Training loss: 2.7477917671203613
Validation loss: 2.7711986726330173

Epoch: 6| Step: 9
Training loss: 2.837176561355591
Validation loss: 2.7733226488995295

Epoch: 6| Step: 10
Training loss: 2.6739773750305176
Validation loss: 2.770507025462325

Epoch: 6| Step: 11
Training loss: 3.5472657680511475
Validation loss: 2.769320482848793

Epoch: 6| Step: 12
Training loss: 2.2672786712646484
Validation loss: 2.7687461171098935

Epoch: 6| Step: 13
Training loss: 3.2638208866119385
Validation loss: 2.771274987087455

Epoch: 42| Step: 0
Training loss: 2.9958157539367676
Validation loss: 2.769778008102089

Epoch: 6| Step: 1
Training loss: 2.79124116897583
Validation loss: 2.7703076049845707

Epoch: 6| Step: 2
Training loss: 3.3764195442199707
Validation loss: 2.7670249785146406

Epoch: 6| Step: 3
Training loss: 2.632783889770508
Validation loss: 2.7657525706034836

Epoch: 6| Step: 4
Training loss: 3.2392988204956055
Validation loss: 2.76413131272921

Epoch: 6| Step: 5
Training loss: 2.814602851867676
Validation loss: 2.76164831653718

Epoch: 6| Step: 6
Training loss: 3.4331536293029785
Validation loss: 2.7599948042182514

Epoch: 6| Step: 7
Training loss: 2.784705400466919
Validation loss: 2.7613078240425355

Epoch: 6| Step: 8
Training loss: 1.9087594747543335
Validation loss: 2.7608541775775213

Epoch: 6| Step: 9
Training loss: 3.2228126525878906
Validation loss: 2.762260772848642

Epoch: 6| Step: 10
Training loss: 2.7473623752593994
Validation loss: 2.75828791177401

Epoch: 6| Step: 11
Training loss: 2.638575315475464
Validation loss: 2.7543721891218618

Epoch: 6| Step: 12
Training loss: 2.5179154872894287
Validation loss: 2.757608272696054

Epoch: 6| Step: 13
Training loss: 3.9671032428741455
Validation loss: 2.756430584897277

Epoch: 43| Step: 0
Training loss: 2.6626524925231934
Validation loss: 2.75598430889909

Epoch: 6| Step: 1
Training loss: 3.118082046508789
Validation loss: 2.7549476546625935

Epoch: 6| Step: 2
Training loss: 2.3166046142578125
Validation loss: 2.753424608579246

Epoch: 6| Step: 3
Training loss: 2.907864809036255
Validation loss: 2.7524400552113852

Epoch: 6| Step: 4
Training loss: 3.8429555892944336
Validation loss: 2.7512198494326685

Epoch: 6| Step: 5
Training loss: 2.9276247024536133
Validation loss: 2.7515942306928736

Epoch: 6| Step: 6
Training loss: 2.9642934799194336
Validation loss: 2.7516787872519544

Epoch: 6| Step: 7
Training loss: 2.969054698944092
Validation loss: 2.7497998770847114

Epoch: 6| Step: 8
Training loss: 2.9249422550201416
Validation loss: 2.747744378223214

Epoch: 6| Step: 9
Training loss: 3.030402183532715
Validation loss: 2.750322334228023

Epoch: 6| Step: 10
Training loss: 2.786494493484497
Validation loss: 2.7483611465782247

Epoch: 6| Step: 11
Training loss: 3.2497682571411133
Validation loss: 2.750862911183347

Epoch: 6| Step: 12
Training loss: 2.0327961444854736
Validation loss: 2.7485861342440367

Epoch: 6| Step: 13
Training loss: 2.5957489013671875
Validation loss: 2.751182174169889

Epoch: 44| Step: 0
Training loss: 2.9237442016601562
Validation loss: 2.7563077736926336

Epoch: 6| Step: 1
Training loss: 2.9673683643341064
Validation loss: 2.7509796029777935

Epoch: 6| Step: 2
Training loss: 2.7798290252685547
Validation loss: 2.7521127141932005

Epoch: 6| Step: 3
Training loss: 2.9513864517211914
Validation loss: 2.7530063916278142

Epoch: 6| Step: 4
Training loss: 2.480010747909546
Validation loss: 2.742607972955191

Epoch: 6| Step: 5
Training loss: 3.642561674118042
Validation loss: 2.745103613022835

Epoch: 6| Step: 6
Training loss: 3.230292320251465
Validation loss: 2.7416027950984176

Epoch: 6| Step: 7
Training loss: 3.0121827125549316
Validation loss: 2.7387078372381066

Epoch: 6| Step: 8
Training loss: 2.588392972946167
Validation loss: 2.7397690588428127

Epoch: 6| Step: 9
Training loss: 2.435027599334717
Validation loss: 2.7410717600135395

Epoch: 6| Step: 10
Training loss: 2.972429037094116
Validation loss: 2.738041848264715

Epoch: 6| Step: 11
Training loss: 3.349165439605713
Validation loss: 2.7390200809765886

Epoch: 6| Step: 12
Training loss: 2.7065329551696777
Validation loss: 2.737093822930449

Epoch: 6| Step: 13
Training loss: 2.0057244300842285
Validation loss: 2.7360334011816208

Epoch: 45| Step: 0
Training loss: 2.5348918437957764
Validation loss: 2.737761010405838

Epoch: 6| Step: 1
Training loss: 2.5939743518829346
Validation loss: 2.738623272988104

Epoch: 6| Step: 2
Training loss: 2.2016124725341797
Validation loss: 2.7457988031448854

Epoch: 6| Step: 3
Training loss: 3.1950950622558594
Validation loss: 2.750607511048676

Epoch: 6| Step: 4
Training loss: 2.2169084548950195
Validation loss: 2.740182594586444

Epoch: 6| Step: 5
Training loss: 3.931589365005493
Validation loss: 2.7400470061968734

Epoch: 6| Step: 6
Training loss: 3.604353904724121
Validation loss: 2.7355908962988083

Epoch: 6| Step: 7
Training loss: 2.779690742492676
Validation loss: 2.7317674800913823

Epoch: 6| Step: 8
Training loss: 3.5196521282196045
Validation loss: 2.730079253514608

Epoch: 6| Step: 9
Training loss: 2.3679587841033936
Validation loss: 2.7286011941971315

Epoch: 6| Step: 10
Training loss: 2.178759813308716
Validation loss: 2.7310906687090473

Epoch: 6| Step: 11
Training loss: 3.3985238075256348
Validation loss: 2.730134828116304

Epoch: 6| Step: 12
Training loss: 3.351264476776123
Validation loss: 2.73016087214152

Epoch: 6| Step: 13
Training loss: 2.1170449256896973
Validation loss: 2.731703363439088

Epoch: 46| Step: 0
Training loss: 3.1917481422424316
Validation loss: 2.7316478119101575

Epoch: 6| Step: 1
Training loss: 2.781367063522339
Validation loss: 2.734172769772109

Epoch: 6| Step: 2
Training loss: 2.7198362350463867
Validation loss: 2.74778998795376

Epoch: 6| Step: 3
Training loss: 3.0747764110565186
Validation loss: 2.7257328264174925

Epoch: 6| Step: 4
Training loss: 3.1964097023010254
Validation loss: 2.7231803017277874

Epoch: 6| Step: 5
Training loss: 2.837559700012207
Validation loss: 2.7260929999812955

Epoch: 6| Step: 6
Training loss: 2.260728120803833
Validation loss: 2.7330191955771497

Epoch: 6| Step: 7
Training loss: 3.3235440254211426
Validation loss: 2.7341190897008425

Epoch: 6| Step: 8
Training loss: 2.468998432159424
Validation loss: 2.7306725671214442

Epoch: 6| Step: 9
Training loss: 2.5504608154296875
Validation loss: 2.73424820874327

Epoch: 6| Step: 10
Training loss: 2.775541305541992
Validation loss: 2.7295865422935894

Epoch: 6| Step: 11
Training loss: 2.54042387008667
Validation loss: 2.7302390093444497

Epoch: 6| Step: 12
Training loss: 3.628966808319092
Validation loss: 2.727592881007861

Epoch: 6| Step: 13
Training loss: 2.985518455505371
Validation loss: 2.7236431055171515

Epoch: 47| Step: 0
Training loss: 2.6739742755889893
Validation loss: 2.72380906023005

Epoch: 6| Step: 1
Training loss: 2.487337589263916
Validation loss: 2.7228874929489626

Epoch: 6| Step: 2
Training loss: 2.886312961578369
Validation loss: 2.7209542951276227

Epoch: 6| Step: 3
Training loss: 2.319063663482666
Validation loss: 2.7213533078470538

Epoch: 6| Step: 4
Training loss: 2.567843437194824
Validation loss: 2.72052655425123

Epoch: 6| Step: 5
Training loss: 2.2662220001220703
Validation loss: 2.720332271309309

Epoch: 6| Step: 6
Training loss: 2.9668052196502686
Validation loss: 2.7207851948276645

Epoch: 6| Step: 7
Training loss: 3.077928066253662
Validation loss: 2.7233694189338276

Epoch: 6| Step: 8
Training loss: 2.4948320388793945
Validation loss: 2.7218314216982935

Epoch: 6| Step: 9
Training loss: 3.4666128158569336
Validation loss: 2.721228822585075

Epoch: 6| Step: 10
Training loss: 4.263786792755127
Validation loss: 2.7210812030300016

Epoch: 6| Step: 11
Training loss: 2.49674654006958
Validation loss: 2.714923092114028

Epoch: 6| Step: 12
Training loss: 3.364915132522583
Validation loss: 2.715628659853371

Epoch: 6| Step: 13
Training loss: 2.7773845195770264
Validation loss: 2.713477806378436

Epoch: 48| Step: 0
Training loss: 2.48244571685791
Validation loss: 2.71345539246836

Epoch: 6| Step: 1
Training loss: 3.6212351322174072
Validation loss: 2.712124809142082

Epoch: 6| Step: 2
Training loss: 3.3236846923828125
Validation loss: 2.7117154957145773

Epoch: 6| Step: 3
Training loss: 2.9584927558898926
Validation loss: 2.709953923379221

Epoch: 6| Step: 4
Training loss: 1.7287460565567017
Validation loss: 2.7134067960964736

Epoch: 6| Step: 5
Training loss: 3.1609582901000977
Validation loss: 2.7101400231802337

Epoch: 6| Step: 6
Training loss: 2.7060556411743164
Validation loss: 2.7101022043535785

Epoch: 6| Step: 7
Training loss: 2.8347582817077637
Validation loss: 2.708196360577819

Epoch: 6| Step: 8
Training loss: 2.3872148990631104
Validation loss: 2.7093954599031838

Epoch: 6| Step: 9
Training loss: 3.662181854248047
Validation loss: 2.707781853214387

Epoch: 6| Step: 10
Training loss: 2.854424476623535
Validation loss: 2.708828223648892

Epoch: 6| Step: 11
Training loss: 2.7553606033325195
Validation loss: 2.7063214855809368

Epoch: 6| Step: 12
Training loss: 2.8361363410949707
Validation loss: 2.706831952576996

Epoch: 6| Step: 13
Training loss: 2.6652467250823975
Validation loss: 2.7073350721789944

Epoch: 49| Step: 0
Training loss: 2.687572956085205
Validation loss: 2.7054568593220045

Epoch: 6| Step: 1
Training loss: 3.491626262664795
Validation loss: 2.7076717781764206

Epoch: 6| Step: 2
Training loss: 2.7010416984558105
Validation loss: 2.7062553154524935

Epoch: 6| Step: 3
Training loss: 3.1687912940979004
Validation loss: 2.710561695919242

Epoch: 6| Step: 4
Training loss: 3.1469478607177734
Validation loss: 2.7216104871483258

Epoch: 6| Step: 5
Training loss: 2.7811803817749023
Validation loss: 2.7272490480894684

Epoch: 6| Step: 6
Training loss: 2.9904160499572754
Validation loss: 2.722283835052162

Epoch: 6| Step: 7
Training loss: 2.965754508972168
Validation loss: 2.7108763828072497

Epoch: 6| Step: 8
Training loss: 3.1295886039733887
Validation loss: 2.7059422616035707

Epoch: 6| Step: 9
Training loss: 2.074836254119873
Validation loss: 2.702724664442001

Epoch: 6| Step: 10
Training loss: 2.3729658126831055
Validation loss: 2.704155422026111

Epoch: 6| Step: 11
Training loss: 2.7359795570373535
Validation loss: 2.704602215879707

Epoch: 6| Step: 12
Training loss: 2.7771780490875244
Validation loss: 2.7084027797945085

Epoch: 6| Step: 13
Training loss: 3.0895910263061523
Validation loss: 2.7110788053081882

Epoch: 50| Step: 0
Training loss: 2.0870213508605957
Validation loss: 2.713198046530447

Epoch: 6| Step: 1
Training loss: 2.3974790573120117
Validation loss: 2.709587558623283

Epoch: 6| Step: 2
Training loss: 2.6912670135498047
Validation loss: 2.708410314334336

Epoch: 6| Step: 3
Training loss: 2.9759278297424316
Validation loss: 2.704340898862449

Epoch: 6| Step: 4
Training loss: 3.7802963256835938
Validation loss: 2.7023460198474187

Epoch: 6| Step: 5
Training loss: 3.4557666778564453
Validation loss: 2.6970977731930312

Epoch: 6| Step: 6
Training loss: 2.406585216522217
Validation loss: 2.69709809108447

Epoch: 6| Step: 7
Training loss: 2.997452735900879
Validation loss: 2.6954347728401102

Epoch: 6| Step: 8
Training loss: 3.141849994659424
Validation loss: 2.697218894958496

Epoch: 6| Step: 9
Training loss: 2.5953564643859863
Validation loss: 2.6958040550190914

Epoch: 6| Step: 10
Training loss: 2.8474740982055664
Validation loss: 2.6948357089873283

Epoch: 6| Step: 11
Training loss: 3.066673755645752
Validation loss: 2.6947172046989523

Epoch: 6| Step: 12
Training loss: 2.5893325805664062
Validation loss: 2.6973780483327885

Epoch: 6| Step: 13
Training loss: 2.941100835800171
Validation loss: 2.6931950302534204

Epoch: 51| Step: 0
Training loss: 3.0353851318359375
Validation loss: 2.6987446636281986

Epoch: 6| Step: 1
Training loss: 2.317422866821289
Validation loss: 2.700106574643043

Epoch: 6| Step: 2
Training loss: 2.9086861610412598
Validation loss: 2.6964637874275126

Epoch: 6| Step: 3
Training loss: 3.2325520515441895
Validation loss: 2.6894818941752114

Epoch: 6| Step: 4
Training loss: 2.8577494621276855
Validation loss: 2.6852485800302155

Epoch: 6| Step: 5
Training loss: 2.232691526412964
Validation loss: 2.6858070255607687

Epoch: 6| Step: 6
Training loss: 2.4810242652893066
Validation loss: 2.684967415307158

Epoch: 6| Step: 7
Training loss: 2.2192962169647217
Validation loss: 2.683688845685733

Epoch: 6| Step: 8
Training loss: 3.576049327850342
Validation loss: 2.682942436587426

Epoch: 6| Step: 9
Training loss: 3.7613179683685303
Validation loss: 2.6785198796179985

Epoch: 6| Step: 10
Training loss: 2.4951324462890625
Validation loss: 2.680211582491475

Epoch: 6| Step: 11
Training loss: 2.568661689758301
Validation loss: 2.681664656567317

Epoch: 6| Step: 12
Training loss: 3.396509885787964
Validation loss: 2.6757464537056546

Epoch: 6| Step: 13
Training loss: 2.577239751815796
Validation loss: 2.6755178410519838

Epoch: 52| Step: 0
Training loss: 3.6015827655792236
Validation loss: 2.6717303029952513

Epoch: 6| Step: 1
Training loss: 2.608548641204834
Validation loss: 2.673010677419683

Epoch: 6| Step: 2
Training loss: 3.6211915016174316
Validation loss: 2.673149649814893

Epoch: 6| Step: 3
Training loss: 2.514753818511963
Validation loss: 2.672588107406452

Epoch: 6| Step: 4
Training loss: 2.7679593563079834
Validation loss: 2.6707710886514313

Epoch: 6| Step: 5
Training loss: 2.93953537940979
Validation loss: 2.669070182308074

Epoch: 6| Step: 6
Training loss: 1.7213095426559448
Validation loss: 2.6705472238602175

Epoch: 6| Step: 7
Training loss: 3.0431127548217773
Validation loss: 2.668205932904315

Epoch: 6| Step: 8
Training loss: 3.406752586364746
Validation loss: 2.671606650916479

Epoch: 6| Step: 9
Training loss: 2.5638318061828613
Validation loss: 2.668114387860862

Epoch: 6| Step: 10
Training loss: 2.496450424194336
Validation loss: 2.6712557551681355

Epoch: 6| Step: 11
Training loss: 2.7767252922058105
Validation loss: 2.6678441365559897

Epoch: 6| Step: 12
Training loss: 2.5774941444396973
Validation loss: 2.6716312259756108

Epoch: 6| Step: 13
Training loss: 3.197744607925415
Validation loss: 2.6726384649994555

Epoch: 53| Step: 0
Training loss: 3.1901021003723145
Validation loss: 2.6754173309572282

Epoch: 6| Step: 1
Training loss: 2.898679256439209
Validation loss: 2.673888603846232

Epoch: 6| Step: 2
Training loss: 2.757120132446289
Validation loss: 2.669698440900413

Epoch: 6| Step: 3
Training loss: 3.457429885864258
Validation loss: 2.6717180129020446

Epoch: 6| Step: 4
Training loss: 2.8451895713806152
Validation loss: 2.6671470877944783

Epoch: 6| Step: 5
Training loss: 2.850571870803833
Validation loss: 2.666123431216004

Epoch: 6| Step: 6
Training loss: 2.4416120052337646
Validation loss: 2.6702125175024873

Epoch: 6| Step: 7
Training loss: 2.7550041675567627
Validation loss: 2.6929465775848715

Epoch: 6| Step: 8
Training loss: 2.896057367324829
Validation loss: 2.689653750388853

Epoch: 6| Step: 9
Training loss: 2.57051944732666
Validation loss: 2.67316238598157

Epoch: 6| Step: 10
Training loss: 2.937591075897217
Validation loss: 2.6597175854508595

Epoch: 6| Step: 11
Training loss: 2.797947883605957
Validation loss: 2.6625163478236042

Epoch: 6| Step: 12
Training loss: 2.6205215454101562
Validation loss: 2.670296499806066

Epoch: 6| Step: 13
Training loss: 2.4319252967834473
Validation loss: 2.679400464539887

Epoch: 54| Step: 0
Training loss: 2.925487756729126
Validation loss: 2.6997019065323697

Epoch: 6| Step: 1
Training loss: 1.921644687652588
Validation loss: 2.7197147441166702

Epoch: 6| Step: 2
Training loss: 2.840435028076172
Validation loss: 2.722897352710847

Epoch: 6| Step: 3
Training loss: 2.24493408203125
Validation loss: 2.723599559517317

Epoch: 6| Step: 4
Training loss: 3.3976244926452637
Validation loss: 2.7146106330297326

Epoch: 6| Step: 5
Training loss: 3.1441357135772705
Validation loss: 2.695078065318446

Epoch: 6| Step: 6
Training loss: 3.230736494064331
Validation loss: 2.681177172609555

Epoch: 6| Step: 7
Training loss: 2.255229949951172
Validation loss: 2.6703166730942263

Epoch: 6| Step: 8
Training loss: 3.437004327774048
Validation loss: 2.6657991306756132

Epoch: 6| Step: 9
Training loss: 3.3810887336730957
Validation loss: 2.664772582310502

Epoch: 6| Step: 10
Training loss: 2.7811851501464844
Validation loss: 2.66357663882676

Epoch: 6| Step: 11
Training loss: 2.4522972106933594
Validation loss: 2.660285198560325

Epoch: 6| Step: 12
Training loss: 2.9681129455566406
Validation loss: 2.6604916152133735

Epoch: 6| Step: 13
Training loss: 2.723001003265381
Validation loss: 2.658114041051557

Epoch: 55| Step: 0
Training loss: 2.388759136199951
Validation loss: 2.6549214624589488

Epoch: 6| Step: 1
Training loss: 1.6720788478851318
Validation loss: 2.657102157992701

Epoch: 6| Step: 2
Training loss: 3.456467390060425
Validation loss: 2.6592873450248473

Epoch: 6| Step: 3
Training loss: 3.4389090538024902
Validation loss: 2.658209531537948

Epoch: 6| Step: 4
Training loss: 3.295487880706787
Validation loss: 2.6601722624994095

Epoch: 6| Step: 5
Training loss: 2.3623390197753906
Validation loss: 2.6599951085223945

Epoch: 6| Step: 6
Training loss: 2.7897520065307617
Validation loss: 2.660126575859644

Epoch: 6| Step: 7
Training loss: 2.9934988021850586
Validation loss: 2.660605445984871

Epoch: 6| Step: 8
Training loss: 2.8199868202209473
Validation loss: 2.658512435933595

Epoch: 6| Step: 9
Training loss: 3.3622350692749023
Validation loss: 2.6616252776115172

Epoch: 6| Step: 10
Training loss: 2.1217503547668457
Validation loss: 2.6606735234619467

Epoch: 6| Step: 11
Training loss: 3.0284860134124756
Validation loss: 2.6560945664682696

Epoch: 6| Step: 12
Training loss: 3.0164968967437744
Validation loss: 2.653346807725968

Epoch: 6| Step: 13
Training loss: 2.589448928833008
Validation loss: 2.6546195322467434

Epoch: 56| Step: 0
Training loss: 2.360150098800659
Validation loss: 2.652548349031838

Epoch: 6| Step: 1
Training loss: 3.135328769683838
Validation loss: 2.6494494202316448

Epoch: 6| Step: 2
Training loss: 2.1894397735595703
Validation loss: 2.652281063859181

Epoch: 6| Step: 3
Training loss: 3.3408868312835693
Validation loss: 2.649030336769678

Epoch: 6| Step: 4
Training loss: 2.918708324432373
Validation loss: 2.64987471026759

Epoch: 6| Step: 5
Training loss: 2.9901890754699707
Validation loss: 2.6476754578210975

Epoch: 6| Step: 6
Training loss: 2.746309518814087
Validation loss: 2.648841888673844

Epoch: 6| Step: 7
Training loss: 3.9154906272888184
Validation loss: 2.6512303352355957

Epoch: 6| Step: 8
Training loss: 1.625916600227356
Validation loss: 2.6483512822017876

Epoch: 6| Step: 9
Training loss: 2.7686877250671387
Validation loss: 2.6498038230403775

Epoch: 6| Step: 10
Training loss: 3.1006438732147217
Validation loss: 2.647725820541382

Epoch: 6| Step: 11
Training loss: 2.756214141845703
Validation loss: 2.646880626678467

Epoch: 6| Step: 12
Training loss: 2.929584503173828
Validation loss: 2.6457317285640265

Epoch: 6| Step: 13
Training loss: 2.4507641792297363
Validation loss: 2.6449025010549896

Epoch: 57| Step: 0
Training loss: 2.1368541717529297
Validation loss: 2.644518772761027

Epoch: 6| Step: 1
Training loss: 2.4689137935638428
Validation loss: 2.642893780944168

Epoch: 6| Step: 2
Training loss: 2.994802236557007
Validation loss: 2.6430546750304518

Epoch: 6| Step: 3
Training loss: 3.6209545135498047
Validation loss: 2.6448330187028453

Epoch: 6| Step: 4
Training loss: 2.5366029739379883
Validation loss: 2.6443681742555354

Epoch: 6| Step: 5
Training loss: 2.603903293609619
Validation loss: 2.6434683876652874

Epoch: 6| Step: 6
Training loss: 3.0305447578430176
Validation loss: 2.641577643732871

Epoch: 6| Step: 7
Training loss: 2.6456761360168457
Validation loss: 2.640800905484025

Epoch: 6| Step: 8
Training loss: 4.034695625305176
Validation loss: 2.6451989604580786

Epoch: 6| Step: 9
Training loss: 2.856808662414551
Validation loss: 2.6440303735835577

Epoch: 6| Step: 10
Training loss: 3.5929226875305176
Validation loss: 2.644179387759137

Epoch: 6| Step: 11
Training loss: 2.1417012214660645
Validation loss: 2.6464273160503757

Epoch: 6| Step: 12
Training loss: 2.3461263179779053
Validation loss: 2.6424045408925703

Epoch: 6| Step: 13
Training loss: 1.8203184604644775
Validation loss: 2.6427952627981863

Epoch: 58| Step: 0
Training loss: 2.7862601280212402
Validation loss: 2.640304785902782

Epoch: 6| Step: 1
Training loss: 2.5699222087860107
Validation loss: 2.6430553185042513

Epoch: 6| Step: 2
Training loss: 2.48732328414917
Validation loss: 2.6420378402997087

Epoch: 6| Step: 3
Training loss: 3.062431812286377
Validation loss: 2.6414083127052552

Epoch: 6| Step: 4
Training loss: 2.806474208831787
Validation loss: 2.637961692707513

Epoch: 6| Step: 5
Training loss: 3.289623260498047
Validation loss: 2.636505155153172

Epoch: 6| Step: 6
Training loss: 2.499830961227417
Validation loss: 2.636297451552524

Epoch: 6| Step: 7
Training loss: 2.7146973609924316
Validation loss: 2.6371147555689656

Epoch: 6| Step: 8
Training loss: 2.831547260284424
Validation loss: 2.637306405651954

Epoch: 6| Step: 9
Training loss: 2.1796674728393555
Validation loss: 2.634873418397801

Epoch: 6| Step: 10
Training loss: 2.716519355773926
Validation loss: 2.638069521996283

Epoch: 6| Step: 11
Training loss: 3.343238592147827
Validation loss: 2.6412243612350954

Epoch: 6| Step: 12
Training loss: 3.087374210357666
Validation loss: 2.643438059796569

Epoch: 6| Step: 13
Training loss: 2.9213056564331055
Validation loss: 2.6438703511350896

Epoch: 59| Step: 0
Training loss: 3.016052484512329
Validation loss: 2.646729125771471

Epoch: 6| Step: 1
Training loss: 2.33003568649292
Validation loss: 2.6461537422672397

Epoch: 6| Step: 2
Training loss: 2.3020410537719727
Validation loss: 2.645432669629333

Epoch: 6| Step: 3
Training loss: 2.532074451446533
Validation loss: 2.645197578655776

Epoch: 6| Step: 4
Training loss: 2.3430256843566895
Validation loss: 2.6375896981967393

Epoch: 6| Step: 5
Training loss: 3.2352263927459717
Validation loss: 2.6346615514447613

Epoch: 6| Step: 6
Training loss: 2.4902901649475098
Validation loss: 2.6327236877974642

Epoch: 6| Step: 7
Training loss: 2.765519142150879
Validation loss: 2.634928498216855

Epoch: 6| Step: 8
Training loss: 4.241161823272705
Validation loss: 2.635908503686228

Epoch: 6| Step: 9
Training loss: 2.652056932449341
Validation loss: 2.6351467793987644

Epoch: 6| Step: 10
Training loss: 2.2237801551818848
Validation loss: 2.6389177845370386

Epoch: 6| Step: 11
Training loss: 2.738913059234619
Validation loss: 2.640360865541684

Epoch: 6| Step: 12
Training loss: 3.703413724899292
Validation loss: 2.63996402166223

Epoch: 6| Step: 13
Training loss: 2.5038092136383057
Validation loss: 2.6407822280801754

Epoch: 60| Step: 0
Training loss: 3.0685205459594727
Validation loss: 2.6356924887626403

Epoch: 6| Step: 1
Training loss: 2.120133876800537
Validation loss: 2.631022181562198

Epoch: 6| Step: 2
Training loss: 2.826173782348633
Validation loss: 2.630693930451588

Epoch: 6| Step: 3
Training loss: 2.5450987815856934
Validation loss: 2.628837272685061

Epoch: 6| Step: 4
Training loss: 2.774313449859619
Validation loss: 2.6365428368250527

Epoch: 6| Step: 5
Training loss: 2.5228734016418457
Validation loss: 2.639836390813192

Epoch: 6| Step: 6
Training loss: 3.367783546447754
Validation loss: 2.651608495302098

Epoch: 6| Step: 7
Training loss: 2.726314067840576
Validation loss: 2.651325400157641

Epoch: 6| Step: 8
Training loss: 2.9862546920776367
Validation loss: 2.6473655623774373

Epoch: 6| Step: 9
Training loss: 3.3076868057250977
Validation loss: 2.6410483032144527

Epoch: 6| Step: 10
Training loss: 2.6208436489105225
Validation loss: 2.634664927759478

Epoch: 6| Step: 11
Training loss: 2.9033865928649902
Validation loss: 2.630125609777307

Epoch: 6| Step: 12
Training loss: 2.5958073139190674
Validation loss: 2.624444910275039

Epoch: 6| Step: 13
Training loss: 2.925239086151123
Validation loss: 2.6240342099179506

Epoch: 61| Step: 0
Training loss: 1.5410608053207397
Validation loss: 2.623640952571746

Epoch: 6| Step: 1
Training loss: 3.006161689758301
Validation loss: 2.6328613219722623

Epoch: 6| Step: 2
Training loss: 2.7937674522399902
Validation loss: 2.632685602352183

Epoch: 6| Step: 3
Training loss: 3.2080085277557373
Validation loss: 2.6300519820182555

Epoch: 6| Step: 4
Training loss: 3.058375358581543
Validation loss: 2.6303497514417096

Epoch: 6| Step: 5
Training loss: 3.0073165893554688
Validation loss: 2.627306781789308

Epoch: 6| Step: 6
Training loss: 2.5307836532592773
Validation loss: 2.625235390919511

Epoch: 6| Step: 7
Training loss: 2.9935054779052734
Validation loss: 2.627844584885464

Epoch: 6| Step: 8
Training loss: 3.4565370082855225
Validation loss: 2.6320845747506745

Epoch: 6| Step: 9
Training loss: 2.2463319301605225
Validation loss: 2.638026850197905

Epoch: 6| Step: 10
Training loss: 2.6891119480133057
Validation loss: 2.639041216142716

Epoch: 6| Step: 11
Training loss: 2.438477039337158
Validation loss: 2.6291722866796676

Epoch: 6| Step: 12
Training loss: 2.9372987747192383
Validation loss: 2.622721956622216

Epoch: 6| Step: 13
Training loss: 3.6177706718444824
Validation loss: 2.620529208132016

Epoch: 62| Step: 0
Training loss: 2.9354753494262695
Validation loss: 2.6206022847083306

Epoch: 6| Step: 1
Training loss: 3.0453431606292725
Validation loss: 2.6190921132282545

Epoch: 6| Step: 2
Training loss: 2.9935038089752197
Validation loss: 2.6199953171514694

Epoch: 6| Step: 3
Training loss: 2.5489330291748047
Validation loss: 2.6178217549477854

Epoch: 6| Step: 4
Training loss: 2.0770132541656494
Validation loss: 2.618097105333882

Epoch: 6| Step: 5
Training loss: 2.658097743988037
Validation loss: 2.617905716742239

Epoch: 6| Step: 6
Training loss: 2.747526168823242
Validation loss: 2.6176227715707596

Epoch: 6| Step: 7
Training loss: 2.925159215927124
Validation loss: 2.6175885072318454

Epoch: 6| Step: 8
Training loss: 2.804649829864502
Validation loss: 2.617332345695906

Epoch: 6| Step: 9
Training loss: 2.921426773071289
Validation loss: 2.617483610747963

Epoch: 6| Step: 10
Training loss: 3.289391040802002
Validation loss: 2.617118230430029

Epoch: 6| Step: 11
Training loss: 2.760758638381958
Validation loss: 2.616985039044452

Epoch: 6| Step: 12
Training loss: 2.5462660789489746
Validation loss: 2.6180937674737748

Epoch: 6| Step: 13
Training loss: 2.7722713947296143
Validation loss: 2.6189856349780993

Epoch: 63| Step: 0
Training loss: 2.892228364944458
Validation loss: 2.6148597219938874

Epoch: 6| Step: 1
Training loss: 2.1927294731140137
Validation loss: 2.618025738705871

Epoch: 6| Step: 2
Training loss: 2.759852409362793
Validation loss: 2.6173604944700837

Epoch: 6| Step: 3
Training loss: 2.609905242919922
Validation loss: 2.614368354120562

Epoch: 6| Step: 4
Training loss: 3.2325916290283203
Validation loss: 2.617634919381911

Epoch: 6| Step: 5
Training loss: 2.7245168685913086
Validation loss: 2.6191383125961467

Epoch: 6| Step: 6
Training loss: 2.6357932090759277
Validation loss: 2.624768316104848

Epoch: 6| Step: 7
Training loss: 1.959895133972168
Validation loss: 2.6230041365469656

Epoch: 6| Step: 8
Training loss: 3.8588764667510986
Validation loss: 2.6259075749304985

Epoch: 6| Step: 9
Training loss: 3.2545480728149414
Validation loss: 2.6250239162034887

Epoch: 6| Step: 10
Training loss: 3.1878275871276855
Validation loss: 2.6266947587331138

Epoch: 6| Step: 11
Training loss: 3.252127170562744
Validation loss: 2.6238757051447386

Epoch: 6| Step: 12
Training loss: 2.4430623054504395
Validation loss: 2.6199396348768667

Epoch: 6| Step: 13
Training loss: 1.451483964920044
Validation loss: 2.6109609834609495

Epoch: 64| Step: 0
Training loss: 2.9942660331726074
Validation loss: 2.611109615654074

Epoch: 6| Step: 1
Training loss: 2.6953608989715576
Validation loss: 2.6085398248446885

Epoch: 6| Step: 2
Training loss: 3.0670955181121826
Validation loss: 2.6113435811893915

Epoch: 6| Step: 3
Training loss: 2.690823793411255
Validation loss: 2.6094452181170062

Epoch: 6| Step: 4
Training loss: 2.5584664344787598
Validation loss: 2.608353591734363

Epoch: 6| Step: 5
Training loss: 3.1858179569244385
Validation loss: 2.610324567364108

Epoch: 6| Step: 6
Training loss: 2.2703232765197754
Validation loss: 2.606819796305831

Epoch: 6| Step: 7
Training loss: 2.6656200885772705
Validation loss: 2.6121928768773235

Epoch: 6| Step: 8
Training loss: 2.90407133102417
Validation loss: 2.6099292693599576

Epoch: 6| Step: 9
Training loss: 3.4856672286987305
Validation loss: 2.6094680024731542

Epoch: 6| Step: 10
Training loss: 2.0579657554626465
Validation loss: 2.6081703042471283

Epoch: 6| Step: 11
Training loss: 2.7458252906799316
Validation loss: 2.6112026399181736

Epoch: 6| Step: 12
Training loss: 2.653123617172241
Validation loss: 2.6069532978919243

Epoch: 6| Step: 13
Training loss: 3.1511449813842773
Validation loss: 2.6091815015321136

Epoch: 65| Step: 0
Training loss: 4.058016777038574
Validation loss: 2.6090691397267003

Epoch: 6| Step: 1
Training loss: 3.569735050201416
Validation loss: 2.6088683707739717

Epoch: 6| Step: 2
Training loss: 2.5230562686920166
Validation loss: 2.6098717053731284

Epoch: 6| Step: 3
Training loss: 2.430387258529663
Validation loss: 2.6101049864163963

Epoch: 6| Step: 4
Training loss: 2.350952625274658
Validation loss: 2.6089080046581965

Epoch: 6| Step: 5
Training loss: 2.4788761138916016
Validation loss: 2.606309390837146

Epoch: 6| Step: 6
Training loss: 3.204381227493286
Validation loss: 2.60917543595837

Epoch: 6| Step: 7
Training loss: 2.594059467315674
Validation loss: 2.6069183631609847

Epoch: 6| Step: 8
Training loss: 2.6788103580474854
Validation loss: 2.6052033106486

Epoch: 6| Step: 9
Training loss: 2.5957329273223877
Validation loss: 2.6057544754397486

Epoch: 6| Step: 10
Training loss: 2.278125047683716
Validation loss: 2.6038534461811023

Epoch: 6| Step: 11
Training loss: 2.778017520904541
Validation loss: 2.60469320256223

Epoch: 6| Step: 12
Training loss: 2.4726662635803223
Validation loss: 2.6062465047323577

Epoch: 6| Step: 13
Training loss: 3.007395029067993
Validation loss: 2.606723295745029

Epoch: 66| Step: 0
Training loss: 2.8840322494506836
Validation loss: 2.6093425161095074

Epoch: 6| Step: 1
Training loss: 2.760340690612793
Validation loss: 2.6040236232101277

Epoch: 6| Step: 2
Training loss: 2.89568829536438
Validation loss: 2.600336087647305

Epoch: 6| Step: 3
Training loss: 2.4597861766815186
Validation loss: 2.6027473506107124

Epoch: 6| Step: 4
Training loss: 3.236423969268799
Validation loss: 2.6015002278871435

Epoch: 6| Step: 5
Training loss: 2.0956220626831055
Validation loss: 2.5991761710054133

Epoch: 6| Step: 6
Training loss: 3.549912214279175
Validation loss: 2.600400483736428

Epoch: 6| Step: 7
Training loss: 2.5709996223449707
Validation loss: 2.604524807263446

Epoch: 6| Step: 8
Training loss: 2.5507476329803467
Validation loss: 2.601682707827578

Epoch: 6| Step: 9
Training loss: 2.8800535202026367
Validation loss: 2.604341686412852

Epoch: 6| Step: 10
Training loss: 3.121866464614868
Validation loss: 2.6026148360262633

Epoch: 6| Step: 11
Training loss: 2.427119255065918
Validation loss: 2.602656033731276

Epoch: 6| Step: 12
Training loss: 2.7082066535949707
Validation loss: 2.59833009781376

Epoch: 6| Step: 13
Training loss: 2.6393327713012695
Validation loss: 2.5996501702134327

Epoch: 67| Step: 0
Training loss: 1.4618757963180542
Validation loss: 2.6000764754510697

Epoch: 6| Step: 1
Training loss: 3.2664670944213867
Validation loss: 2.5985640659127185

Epoch: 6| Step: 2
Training loss: 3.336343765258789
Validation loss: 2.5999249822349957

Epoch: 6| Step: 3
Training loss: 2.861637592315674
Validation loss: 2.5977965759974655

Epoch: 6| Step: 4
Training loss: 3.429527759552002
Validation loss: 2.5971850720784997

Epoch: 6| Step: 5
Training loss: 2.6380772590637207
Validation loss: 2.5936843887452157

Epoch: 6| Step: 6
Training loss: 2.8646299839019775
Validation loss: 2.591521801487092

Epoch: 6| Step: 7
Training loss: 2.782592535018921
Validation loss: 2.5917725127230407

Epoch: 6| Step: 8
Training loss: 2.529177188873291
Validation loss: 2.593414270749656

Epoch: 6| Step: 9
Training loss: 2.410508871078491
Validation loss: 2.5919945778385287

Epoch: 6| Step: 10
Training loss: 2.758125066757202
Validation loss: 2.5930350647177747

Epoch: 6| Step: 11
Training loss: 2.6629250049591064
Validation loss: 2.5922699538610314

Epoch: 6| Step: 12
Training loss: 3.3264503479003906
Validation loss: 2.5918794703739945

Epoch: 6| Step: 13
Training loss: 2.2704222202301025
Validation loss: 2.59450428716598

Epoch: 68| Step: 0
Training loss: 2.1106693744659424
Validation loss: 2.593973098262664

Epoch: 6| Step: 1
Training loss: 2.707245349884033
Validation loss: 2.5970287066633984

Epoch: 6| Step: 2
Training loss: 3.238114833831787
Validation loss: 2.5968340455844836

Epoch: 6| Step: 3
Training loss: 3.1952261924743652
Validation loss: 2.5970425605773926

Epoch: 6| Step: 4
Training loss: 2.5787441730499268
Validation loss: 2.591877927062332

Epoch: 6| Step: 5
Training loss: 3.103933334350586
Validation loss: 2.595723952016523

Epoch: 6| Step: 6
Training loss: 1.977046012878418
Validation loss: 2.5907861776249383

Epoch: 6| Step: 7
Training loss: 3.2672924995422363
Validation loss: 2.5902722599685832

Epoch: 6| Step: 8
Training loss: 2.7954375743865967
Validation loss: 2.5886586558434272

Epoch: 6| Step: 9
Training loss: 2.7642040252685547
Validation loss: 2.5900803048123597

Epoch: 6| Step: 10
Training loss: 3.4182066917419434
Validation loss: 2.5894561621450607

Epoch: 6| Step: 11
Training loss: 2.417172431945801
Validation loss: 2.592566200481948

Epoch: 6| Step: 12
Training loss: 2.580496311187744
Validation loss: 2.590872162131853

Epoch: 6| Step: 13
Training loss: 2.4623172283172607
Validation loss: 2.591053032105969

Epoch: 69| Step: 0
Training loss: 2.6639018058776855
Validation loss: 2.5894441937887542

Epoch: 6| Step: 1
Training loss: 3.2277348041534424
Validation loss: 2.590662266618462

Epoch: 6| Step: 2
Training loss: 2.7722842693328857
Validation loss: 2.5885075266643236

Epoch: 6| Step: 3
Training loss: 3.107499122619629
Validation loss: 2.587673259037797

Epoch: 6| Step: 4
Training loss: 2.414846420288086
Validation loss: 2.5859534048265025

Epoch: 6| Step: 5
Training loss: 3.7635951042175293
Validation loss: 2.5947724362855316

Epoch: 6| Step: 6
Training loss: 2.0027389526367188
Validation loss: 2.6001171117187827

Epoch: 6| Step: 7
Training loss: 3.3512918949127197
Validation loss: 2.619552073940154

Epoch: 6| Step: 8
Training loss: 2.3379664421081543
Validation loss: 2.613760958435715

Epoch: 6| Step: 9
Training loss: 2.9387285709381104
Validation loss: 2.6159195566690094

Epoch: 6| Step: 10
Training loss: 2.2492527961730957
Validation loss: 2.6004162808900237

Epoch: 6| Step: 11
Training loss: 2.817392349243164
Validation loss: 2.592417227324619

Epoch: 6| Step: 12
Training loss: 2.351201295852661
Validation loss: 2.5900726292722966

Epoch: 6| Step: 13
Training loss: 2.7182857990264893
Validation loss: 2.586590423378893

Epoch: 70| Step: 0
Training loss: 2.740668773651123
Validation loss: 2.584227502986949

Epoch: 6| Step: 1
Training loss: 2.8201186656951904
Validation loss: 2.5828660149728098

Epoch: 6| Step: 2
Training loss: 2.1345396041870117
Validation loss: 2.5847837809593446

Epoch: 6| Step: 3
Training loss: 3.032971143722534
Validation loss: 2.586311786405502

Epoch: 6| Step: 4
Training loss: 3.0275182723999023
Validation loss: 2.5922428100339827

Epoch: 6| Step: 5
Training loss: 2.480964183807373
Validation loss: 2.5940023827296432

Epoch: 6| Step: 6
Training loss: 2.7213754653930664
Validation loss: 2.588885489330497

Epoch: 6| Step: 7
Training loss: 2.7678017616271973
Validation loss: 2.5959943443216305

Epoch: 6| Step: 8
Training loss: 3.025548219680786
Validation loss: 2.5915016538353375

Epoch: 6| Step: 9
Training loss: 2.795501470565796
Validation loss: 2.59250783663924

Epoch: 6| Step: 10
Training loss: 3.2336413860321045
Validation loss: 2.5918568154816986

Epoch: 6| Step: 11
Training loss: 2.639486074447632
Validation loss: 2.586778574092414

Epoch: 6| Step: 12
Training loss: 2.518934726715088
Validation loss: 2.586418071100789

Epoch: 6| Step: 13
Training loss: 2.890660285949707
Validation loss: 2.5807353347860356

Epoch: 71| Step: 0
Training loss: 2.757338523864746
Validation loss: 2.5814215624204246

Epoch: 6| Step: 1
Training loss: 3.040924310684204
Validation loss: 2.5817797222445087

Epoch: 6| Step: 2
Training loss: 2.5948803424835205
Validation loss: 2.5803393676716793

Epoch: 6| Step: 3
Training loss: 2.5612525939941406
Validation loss: 2.5794273371337564

Epoch: 6| Step: 4
Training loss: 1.874614953994751
Validation loss: 2.581399702256726

Epoch: 6| Step: 5
Training loss: 2.150970220565796
Validation loss: 2.5818990609979116

Epoch: 6| Step: 6
Training loss: 3.1243460178375244
Validation loss: 2.5850725122677383

Epoch: 6| Step: 7
Training loss: 2.8145298957824707
Validation loss: 2.583152853032594

Epoch: 6| Step: 8
Training loss: 3.5620334148406982
Validation loss: 2.5814113360579296

Epoch: 6| Step: 9
Training loss: 2.190279722213745
Validation loss: 2.5855654080708823

Epoch: 6| Step: 10
Training loss: 3.4832894802093506
Validation loss: 2.578955829784434

Epoch: 6| Step: 11
Training loss: 3.3284997940063477
Validation loss: 2.5783775237298783

Epoch: 6| Step: 12
Training loss: 2.612924098968506
Validation loss: 2.5756300110970773

Epoch: 6| Step: 13
Training loss: 2.456878185272217
Validation loss: 2.5783927748280187

Epoch: 72| Step: 0
Training loss: 2.885984420776367
Validation loss: 2.5772787499171432

Epoch: 6| Step: 1
Training loss: 3.6887805461883545
Validation loss: 2.576544548875542

Epoch: 6| Step: 2
Training loss: 2.5323686599731445
Validation loss: 2.573788417282925

Epoch: 6| Step: 3
Training loss: 2.8325772285461426
Validation loss: 2.5781791671629875

Epoch: 6| Step: 4
Training loss: 2.3889074325561523
Validation loss: 2.5759513711416595

Epoch: 6| Step: 5
Training loss: 2.263279914855957
Validation loss: 2.577667469619423

Epoch: 6| Step: 6
Training loss: 2.9852328300476074
Validation loss: 2.57248180912387

Epoch: 6| Step: 7
Training loss: 2.5576887130737305
Validation loss: 2.57474886473789

Epoch: 6| Step: 8
Training loss: 1.8049639463424683
Validation loss: 2.5744185627147718

Epoch: 6| Step: 9
Training loss: 3.041780471801758
Validation loss: 2.576745899774695

Epoch: 6| Step: 10
Training loss: 3.492860794067383
Validation loss: 2.576226270327004

Epoch: 6| Step: 11
Training loss: 2.683793544769287
Validation loss: 2.5787540969028266

Epoch: 6| Step: 12
Training loss: 2.4665403366088867
Validation loss: 2.5786721808936006

Epoch: 6| Step: 13
Training loss: 3.139695882797241
Validation loss: 2.583351883836972

Epoch: 73| Step: 0
Training loss: 2.6818039417266846
Validation loss: 2.585044548075686

Epoch: 6| Step: 1
Training loss: 3.0697970390319824
Validation loss: 2.5899281655588458

Epoch: 6| Step: 2
Training loss: 3.0045583248138428
Validation loss: 2.5906793763560634

Epoch: 6| Step: 3
Training loss: 2.1434991359710693
Validation loss: 2.5901614760839813

Epoch: 6| Step: 4
Training loss: 2.740567207336426
Validation loss: 2.586520302680231

Epoch: 6| Step: 5
Training loss: 2.64408016204834
Validation loss: 2.5753185979781614

Epoch: 6| Step: 6
Training loss: 2.0483016967773438
Validation loss: 2.573241956772343

Epoch: 6| Step: 7
Training loss: 2.8253300189971924
Validation loss: 2.571131537037511

Epoch: 6| Step: 8
Training loss: 2.761383295059204
Validation loss: 2.570719890697028

Epoch: 6| Step: 9
Training loss: 3.460585594177246
Validation loss: 2.573402202257546

Epoch: 6| Step: 10
Training loss: 2.9325387477874756
Validation loss: 2.5737361677231325

Epoch: 6| Step: 11
Training loss: 3.253654956817627
Validation loss: 2.572076815430836

Epoch: 6| Step: 12
Training loss: 2.6824779510498047
Validation loss: 2.5702369084922214

Epoch: 6| Step: 13
Training loss: 2.108323812484741
Validation loss: 2.5687713469228437

Epoch: 74| Step: 0
Training loss: 3.2063820362091064
Validation loss: 2.5696710489129506

Epoch: 6| Step: 1
Training loss: 1.8669137954711914
Validation loss: 2.5702117796867125

Epoch: 6| Step: 2
Training loss: 2.808922290802002
Validation loss: 2.5736877174787622

Epoch: 6| Step: 3
Training loss: 2.990926742553711
Validation loss: 2.5684083584816224

Epoch: 6| Step: 4
Training loss: 2.577669382095337
Validation loss: 2.5770234036189255

Epoch: 6| Step: 5
Training loss: 2.0863537788391113
Validation loss: 2.5788873036702475

Epoch: 6| Step: 6
Training loss: 3.024681806564331
Validation loss: 2.5796658198038735

Epoch: 6| Step: 7
Training loss: 2.9736194610595703
Validation loss: 2.5768303589154313

Epoch: 6| Step: 8
Training loss: 2.8503482341766357
Validation loss: 2.5730348761363695

Epoch: 6| Step: 9
Training loss: 3.2831225395202637
Validation loss: 2.5716027893045896

Epoch: 6| Step: 10
Training loss: 2.8629150390625
Validation loss: 2.569709582995343

Epoch: 6| Step: 11
Training loss: 3.167891502380371
Validation loss: 2.5664118720639135

Epoch: 6| Step: 12
Training loss: 2.6755151748657227
Validation loss: 2.569260084500877

Epoch: 6| Step: 13
Training loss: 1.6601413488388062
Validation loss: 2.5637069979021625

Epoch: 75| Step: 0
Training loss: 2.6106369495391846
Validation loss: 2.5669433583495436

Epoch: 6| Step: 1
Training loss: 2.5560123920440674
Validation loss: 2.5669392513972458

Epoch: 6| Step: 2
Training loss: 2.9565141201019287
Validation loss: 2.5659894584327616

Epoch: 6| Step: 3
Training loss: 2.980518102645874
Validation loss: 2.5665263334910073

Epoch: 6| Step: 4
Training loss: 3.0551586151123047
Validation loss: 2.563768397095383

Epoch: 6| Step: 5
Training loss: 3.2557034492492676
Validation loss: 2.564014078468405

Epoch: 6| Step: 6
Training loss: 2.7071373462677
Validation loss: 2.56681961910699

Epoch: 6| Step: 7
Training loss: 2.636957883834839
Validation loss: 2.56771017402731

Epoch: 6| Step: 8
Training loss: 2.188612461090088
Validation loss: 2.5687260063745643

Epoch: 6| Step: 9
Training loss: 3.4410548210144043
Validation loss: 2.566741592140608

Epoch: 6| Step: 10
Training loss: 2.841632127761841
Validation loss: 2.570677552171933

Epoch: 6| Step: 11
Training loss: 2.59942364692688
Validation loss: 2.5729242422247447

Epoch: 6| Step: 12
Training loss: 2.0461485385894775
Validation loss: 2.5680121273122807

Epoch: 6| Step: 13
Training loss: 2.521456718444824
Validation loss: 2.568567383673883

Epoch: 76| Step: 0
Training loss: 2.7698590755462646
Validation loss: 2.5685124858733146

Epoch: 6| Step: 1
Training loss: 2.6694793701171875
Validation loss: 2.5711021013157342

Epoch: 6| Step: 2
Training loss: 2.5449447631835938
Validation loss: 2.5668918137909262

Epoch: 6| Step: 3
Training loss: 2.7243247032165527
Validation loss: 2.572283911448653

Epoch: 6| Step: 4
Training loss: 2.8104324340820312
Validation loss: 2.5711939616869857

Epoch: 6| Step: 5
Training loss: 2.3560373783111572
Validation loss: 2.5746152708607335

Epoch: 6| Step: 6
Training loss: 2.4709830284118652
Validation loss: 2.5626988436586116

Epoch: 6| Step: 7
Training loss: 2.542452812194824
Validation loss: 2.562825979725007

Epoch: 6| Step: 8
Training loss: 2.1849093437194824
Validation loss: 2.563033714089342

Epoch: 6| Step: 9
Training loss: 2.9936392307281494
Validation loss: 2.5624792550199773

Epoch: 6| Step: 10
Training loss: 2.9831221103668213
Validation loss: 2.5660538006854314

Epoch: 6| Step: 11
Training loss: 2.7891652584075928
Validation loss: 2.5687449593697824

Epoch: 6| Step: 12
Training loss: 3.316026449203491
Validation loss: 2.575071470711821

Epoch: 6| Step: 13
Training loss: 3.8643672466278076
Validation loss: 2.570706944311819

Epoch: 77| Step: 0
Training loss: 1.9310548305511475
Validation loss: 2.563550956787602

Epoch: 6| Step: 1
Training loss: 2.88375186920166
Validation loss: 2.564933210290888

Epoch: 6| Step: 2
Training loss: 3.558316230773926
Validation loss: 2.56809893731148

Epoch: 6| Step: 3
Training loss: 2.7206997871398926
Validation loss: 2.5697114006165536

Epoch: 6| Step: 4
Training loss: 3.1081087589263916
Validation loss: 2.573434963021227

Epoch: 6| Step: 5
Training loss: 2.4447131156921387
Validation loss: 2.5790500384505077

Epoch: 6| Step: 6
Training loss: 3.037614345550537
Validation loss: 2.578743439848705

Epoch: 6| Step: 7
Training loss: 2.736328601837158
Validation loss: 2.576793747563516

Epoch: 6| Step: 8
Training loss: 2.8551864624023438
Validation loss: 2.5743897948213803

Epoch: 6| Step: 9
Training loss: 2.2809927463531494
Validation loss: 2.568906637930101

Epoch: 6| Step: 10
Training loss: 2.3772497177124023
Validation loss: 2.572361292377595

Epoch: 6| Step: 11
Training loss: 2.9867167472839355
Validation loss: 2.5652297978760092

Epoch: 6| Step: 12
Training loss: 2.9707283973693848
Validation loss: 2.5692253497339066

Epoch: 6| Step: 13
Training loss: 2.5189144611358643
Validation loss: 2.562249886092319

Epoch: 78| Step: 0
Training loss: 1.8753575086593628
Validation loss: 2.5614670015150502

Epoch: 6| Step: 1
Training loss: 3.3369641304016113
Validation loss: 2.5618813524964037

Epoch: 6| Step: 2
Training loss: 2.5229029655456543
Validation loss: 2.5603805690683346

Epoch: 6| Step: 3
Training loss: 2.6586709022521973
Validation loss: 2.5604607418019283

Epoch: 6| Step: 4
Training loss: 1.963194489479065
Validation loss: 2.5610131166314565

Epoch: 6| Step: 5
Training loss: 3.523798942565918
Validation loss: 2.560795940378661

Epoch: 6| Step: 6
Training loss: 2.6286046504974365
Validation loss: 2.5588687927492204

Epoch: 6| Step: 7
Training loss: 2.8661468029022217
Validation loss: 2.5573792457580566

Epoch: 6| Step: 8
Training loss: 3.864771842956543
Validation loss: 2.556977310488301

Epoch: 6| Step: 9
Training loss: 2.821636199951172
Validation loss: 2.55839346044807

Epoch: 6| Step: 10
Training loss: 2.2101144790649414
Validation loss: 2.557754644783594

Epoch: 6| Step: 11
Training loss: 2.7417831420898438
Validation loss: 2.5610403066040366

Epoch: 6| Step: 12
Training loss: 2.9627652168273926
Validation loss: 2.5628334040282876

Epoch: 6| Step: 13
Training loss: 2.207672357559204
Validation loss: 2.5621803601582847

Epoch: 79| Step: 0
Training loss: 2.803083896636963
Validation loss: 2.569117489681449

Epoch: 6| Step: 1
Training loss: 2.9526867866516113
Validation loss: 2.5682559192821546

Epoch: 6| Step: 2
Training loss: 3.368932008743286
Validation loss: 2.5617404214797483

Epoch: 6| Step: 3
Training loss: 2.9537882804870605
Validation loss: 2.557524517018308

Epoch: 6| Step: 4
Training loss: 2.8954148292541504
Validation loss: 2.553909588885564

Epoch: 6| Step: 5
Training loss: 3.5636448860168457
Validation loss: 2.5545954422284196

Epoch: 6| Step: 6
Training loss: 2.44295597076416
Validation loss: 2.556248939165505

Epoch: 6| Step: 7
Training loss: 2.3197379112243652
Validation loss: 2.554908211513232

Epoch: 6| Step: 8
Training loss: 2.454808235168457
Validation loss: 2.5532945330424974

Epoch: 6| Step: 9
Training loss: 2.728109836578369
Validation loss: 2.555519184758586

Epoch: 6| Step: 10
Training loss: 2.0221140384674072
Validation loss: 2.5565845607429423

Epoch: 6| Step: 11
Training loss: 2.897228717803955
Validation loss: 2.555077939905146

Epoch: 6| Step: 12
Training loss: 2.461242198944092
Validation loss: 2.5534071986393263

Epoch: 6| Step: 13
Training loss: 2.454923629760742
Validation loss: 2.5621843773831605

Epoch: 80| Step: 0
Training loss: 2.715977668762207
Validation loss: 2.556198081662578

Epoch: 6| Step: 1
Training loss: 3.063385486602783
Validation loss: 2.559457645621351

Epoch: 6| Step: 2
Training loss: 2.828413963317871
Validation loss: 2.5590773295330744

Epoch: 6| Step: 3
Training loss: 2.2975263595581055
Validation loss: 2.561255060216432

Epoch: 6| Step: 4
Training loss: 2.7536864280700684
Validation loss: 2.555057778153368

Epoch: 6| Step: 5
Training loss: 2.9272496700286865
Validation loss: 2.550752703861524

Epoch: 6| Step: 6
Training loss: 2.388315200805664
Validation loss: 2.5577871363650084

Epoch: 6| Step: 7
Training loss: 2.5364975929260254
Validation loss: 2.558277299327235

Epoch: 6| Step: 8
Training loss: 2.3973238468170166
Validation loss: 2.557137434200574

Epoch: 6| Step: 9
Training loss: 3.533740997314453
Validation loss: 2.5559911420268397

Epoch: 6| Step: 10
Training loss: 2.6051340103149414
Validation loss: 2.552147324367236

Epoch: 6| Step: 11
Training loss: 2.9513113498687744
Validation loss: 2.550562084362071

Epoch: 6| Step: 12
Training loss: 2.7192444801330566
Validation loss: 2.5494145654862925

Epoch: 6| Step: 13
Training loss: 2.51967453956604
Validation loss: 2.5476259646877164

Epoch: 81| Step: 0
Training loss: 2.7044155597686768
Validation loss: 2.548698781639017

Epoch: 6| Step: 1
Training loss: 3.2239866256713867
Validation loss: 2.549446185429891

Epoch: 6| Step: 2
Training loss: 3.112351894378662
Validation loss: 2.5501884414303686

Epoch: 6| Step: 3
Training loss: 2.436610698699951
Validation loss: 2.551101615352015

Epoch: 6| Step: 4
Training loss: 3.0140609741210938
Validation loss: 2.5502316208295923

Epoch: 6| Step: 5
Training loss: 2.961441993713379
Validation loss: 2.545112245826311

Epoch: 6| Step: 6
Training loss: 2.035508632659912
Validation loss: 2.5451837303817912

Epoch: 6| Step: 7
Training loss: 2.588541030883789
Validation loss: 2.5488011362732097

Epoch: 6| Step: 8
Training loss: 2.5017271041870117
Validation loss: 2.549278913005706

Epoch: 6| Step: 9
Training loss: 2.097230911254883
Validation loss: 2.5516142973335842

Epoch: 6| Step: 10
Training loss: 3.4363772869110107
Validation loss: 2.55446126896848

Epoch: 6| Step: 11
Training loss: 2.9305615425109863
Validation loss: 2.5570129732931814

Epoch: 6| Step: 12
Training loss: 2.2513179779052734
Validation loss: 2.5543819550544984

Epoch: 6| Step: 13
Training loss: 3.3359174728393555
Validation loss: 2.5534800098788355

Epoch: 82| Step: 0
Training loss: 2.6354379653930664
Validation loss: 2.554158692718834

Epoch: 6| Step: 1
Training loss: 2.5555620193481445
Validation loss: 2.5508786093804146

Epoch: 6| Step: 2
Training loss: 3.631540060043335
Validation loss: 2.5503327667072253

Epoch: 6| Step: 3
Training loss: 2.438831329345703
Validation loss: 2.54851391238551

Epoch: 6| Step: 4
Training loss: 2.706989049911499
Validation loss: 2.545046857608262

Epoch: 6| Step: 5
Training loss: 3.169179916381836
Validation loss: 2.546164248579292

Epoch: 6| Step: 6
Training loss: 2.3873860836029053
Validation loss: 2.5453948090153355

Epoch: 6| Step: 7
Training loss: 2.3620495796203613
Validation loss: 2.549427152961813

Epoch: 6| Step: 8
Training loss: 3.049251079559326
Validation loss: 2.553691529458569

Epoch: 6| Step: 9
Training loss: 2.863191604614258
Validation loss: 2.5533881956531155

Epoch: 6| Step: 10
Training loss: 2.275053024291992
Validation loss: 2.556967882699864

Epoch: 6| Step: 11
Training loss: 2.9711194038391113
Validation loss: 2.551271379634898

Epoch: 6| Step: 12
Training loss: 2.9680466651916504
Validation loss: 2.543605932625391

Epoch: 6| Step: 13
Training loss: 2.0082991123199463
Validation loss: 2.5430373222597185

Epoch: 83| Step: 0
Training loss: 2.79655122756958
Validation loss: 2.544491660210394

Epoch: 6| Step: 1
Training loss: 2.285707950592041
Validation loss: 2.5453012912504134

Epoch: 6| Step: 2
Training loss: 2.732212543487549
Validation loss: 2.5446830000928653

Epoch: 6| Step: 3
Training loss: 2.623310089111328
Validation loss: 2.549008277154738

Epoch: 6| Step: 4
Training loss: 3.1404318809509277
Validation loss: 2.5440667598478255

Epoch: 6| Step: 5
Training loss: 2.9086451530456543
Validation loss: 2.5456069361779

Epoch: 6| Step: 6
Training loss: 1.8246183395385742
Validation loss: 2.5463628922739336

Epoch: 6| Step: 7
Training loss: 2.5249924659729004
Validation loss: 2.54106927687122

Epoch: 6| Step: 8
Training loss: 3.828908920288086
Validation loss: 2.5446914729251655

Epoch: 6| Step: 9
Training loss: 3.0361742973327637
Validation loss: 2.547018761275917

Epoch: 6| Step: 10
Training loss: 2.5315775871276855
Validation loss: 2.543939011071318

Epoch: 6| Step: 11
Training loss: 2.7010140419006348
Validation loss: 2.543511385558754

Epoch: 6| Step: 12
Training loss: 2.2928991317749023
Validation loss: 2.544121111592939

Epoch: 6| Step: 13
Training loss: 3.3980770111083984
Validation loss: 2.5411661183962257

Epoch: 84| Step: 0
Training loss: 2.735224723815918
Validation loss: 2.542168535212035

Epoch: 6| Step: 1
Training loss: 3.256497859954834
Validation loss: 2.5416026730691232

Epoch: 6| Step: 2
Training loss: 2.828735828399658
Validation loss: 2.5419502155755156

Epoch: 6| Step: 3
Training loss: 1.8315765857696533
Validation loss: 2.5397112343900945

Epoch: 6| Step: 4
Training loss: 2.3882575035095215
Validation loss: 2.544018606985769

Epoch: 6| Step: 5
Training loss: 2.779291868209839
Validation loss: 2.542363169372723

Epoch: 6| Step: 6
Training loss: 3.19681978225708
Validation loss: 2.539815951419133

Epoch: 6| Step: 7
Training loss: 3.5872936248779297
Validation loss: 2.5410305300066547

Epoch: 6| Step: 8
Training loss: 2.565863609313965
Validation loss: 2.5411166837138515

Epoch: 6| Step: 9
Training loss: 2.743597984313965
Validation loss: 2.537923679556898

Epoch: 6| Step: 10
Training loss: 3.534156322479248
Validation loss: 2.5387459134542816

Epoch: 6| Step: 11
Training loss: 2.642059326171875
Validation loss: 2.538686235745748

Epoch: 6| Step: 12
Training loss: 1.7761286497116089
Validation loss: 2.5389109914020827

Epoch: 6| Step: 13
Training loss: 2.1672494411468506
Validation loss: 2.5414942182520384

Epoch: 85| Step: 0
Training loss: 2.5317254066467285
Validation loss: 2.5403041711417575

Epoch: 6| Step: 1
Training loss: 3.1717753410339355
Validation loss: 2.5501644931813723

Epoch: 6| Step: 2
Training loss: 2.68510103225708
Validation loss: 2.549335556645547

Epoch: 6| Step: 3
Training loss: 2.749629259109497
Validation loss: 2.5410882401210007

Epoch: 6| Step: 4
Training loss: 3.3690969944000244
Validation loss: 2.5417978097033758

Epoch: 6| Step: 5
Training loss: 3.075644016265869
Validation loss: 2.541814750240695

Epoch: 6| Step: 6
Training loss: 2.441433906555176
Validation loss: 2.5532520612080893

Epoch: 6| Step: 7
Training loss: 3.326936721801758
Validation loss: 2.5500192052574566

Epoch: 6| Step: 8
Training loss: 2.2033112049102783
Validation loss: 2.5441846232260428

Epoch: 6| Step: 9
Training loss: 2.310405731201172
Validation loss: 2.5413355827331543

Epoch: 6| Step: 10
Training loss: 2.6573379039764404
Validation loss: 2.5427231839908067

Epoch: 6| Step: 11
Training loss: 2.2231125831604004
Validation loss: 2.5377553560400523

Epoch: 6| Step: 12
Training loss: 2.5522236824035645
Validation loss: 2.541989844332459

Epoch: 6| Step: 13
Training loss: 3.0697076320648193
Validation loss: 2.5392308414623304

Epoch: 86| Step: 0
Training loss: 2.8291428089141846
Validation loss: 2.5352835424484743

Epoch: 6| Step: 1
Training loss: 2.49288010597229
Validation loss: 2.5365352348614763

Epoch: 6| Step: 2
Training loss: 2.270454168319702
Validation loss: 2.5351932407707296

Epoch: 6| Step: 3
Training loss: 2.490736246109009
Validation loss: 2.5404767836293867

Epoch: 6| Step: 4
Training loss: 2.7207999229431152
Validation loss: 2.5522374363355738

Epoch: 6| Step: 5
Training loss: 2.739931583404541
Validation loss: 2.554619130267892

Epoch: 6| Step: 6
Training loss: 3.7659871578216553
Validation loss: 2.56773357237539

Epoch: 6| Step: 7
Training loss: 2.592957019805908
Validation loss: 2.5831562703655613

Epoch: 6| Step: 8
Training loss: 2.5579965114593506
Validation loss: 2.5831324131258073

Epoch: 6| Step: 9
Training loss: 2.6408090591430664
Validation loss: 2.5643676942394626

Epoch: 6| Step: 10
Training loss: 2.4036881923675537
Validation loss: 2.5688536372236026

Epoch: 6| Step: 11
Training loss: 3.8453867435455322
Validation loss: 2.5601109330372145

Epoch: 6| Step: 12
Training loss: 2.183471918106079
Validation loss: 2.552215360826062

Epoch: 6| Step: 13
Training loss: 2.922006845474243
Validation loss: 2.541965316700679

Epoch: 87| Step: 0
Training loss: 2.8115782737731934
Validation loss: 2.5378939182527605

Epoch: 6| Step: 1
Training loss: 2.0782158374786377
Validation loss: 2.5427578674849642

Epoch: 6| Step: 2
Training loss: 2.5101981163024902
Validation loss: 2.542447587495209

Epoch: 6| Step: 3
Training loss: 2.5238728523254395
Validation loss: 2.542885349642846

Epoch: 6| Step: 4
Training loss: 1.8653864860534668
Validation loss: 2.5429697293107227

Epoch: 6| Step: 5
Training loss: 2.826850652694702
Validation loss: 2.5466223967972623

Epoch: 6| Step: 6
Training loss: 3.338139057159424
Validation loss: 2.5436804704768683

Epoch: 6| Step: 7
Training loss: 3.0383667945861816
Validation loss: 2.542364920339277

Epoch: 6| Step: 8
Training loss: 2.885143280029297
Validation loss: 2.5455465162954023

Epoch: 6| Step: 9
Training loss: 2.674618721008301
Validation loss: 2.54318134502698

Epoch: 6| Step: 10
Training loss: 2.7506422996520996
Validation loss: 2.543910139350481

Epoch: 6| Step: 11
Training loss: 2.2966365814208984
Validation loss: 2.5402947420715005

Epoch: 6| Step: 12
Training loss: 3.2876100540161133
Validation loss: 2.5457673816270727

Epoch: 6| Step: 13
Training loss: 3.975724935531616
Validation loss: 2.5466642918125277

Epoch: 88| Step: 0
Training loss: 2.709714412689209
Validation loss: 2.538650530640797

Epoch: 6| Step: 1
Training loss: 3.1566944122314453
Validation loss: 2.5352449596569104

Epoch: 6| Step: 2
Training loss: 1.6010730266571045
Validation loss: 2.5357801786033054

Epoch: 6| Step: 3
Training loss: 3.1426422595977783
Validation loss: 2.5366443485342045

Epoch: 6| Step: 4
Training loss: 2.580049991607666
Validation loss: 2.5361764174635693

Epoch: 6| Step: 5
Training loss: 2.9408581256866455
Validation loss: 2.5459159984383533

Epoch: 6| Step: 6
Training loss: 2.62947416305542
Validation loss: 2.54343557101424

Epoch: 6| Step: 7
Training loss: 2.563938617706299
Validation loss: 2.5397999568652083

Epoch: 6| Step: 8
Training loss: 3.0043787956237793
Validation loss: 2.542316872586486

Epoch: 6| Step: 9
Training loss: 2.8124189376831055
Validation loss: 2.5393104194312968

Epoch: 6| Step: 10
Training loss: 2.7848973274230957
Validation loss: 2.5380269968381493

Epoch: 6| Step: 11
Training loss: 3.0050911903381348
Validation loss: 2.533317922264017

Epoch: 6| Step: 12
Training loss: 2.4045166969299316
Validation loss: 2.5385849398951374

Epoch: 6| Step: 13
Training loss: 2.895886182785034
Validation loss: 2.5439965391671784

Epoch: 89| Step: 0
Training loss: 2.3798670768737793
Validation loss: 2.5396866106217906

Epoch: 6| Step: 1
Training loss: 3.217303514480591
Validation loss: 2.5392778124860538

Epoch: 6| Step: 2
Training loss: 2.1851582527160645
Validation loss: 2.5343296040770826

Epoch: 6| Step: 3
Training loss: 2.952301025390625
Validation loss: 2.5326812831304406

Epoch: 6| Step: 4
Training loss: 2.5503711700439453
Validation loss: 2.5364149283337336

Epoch: 6| Step: 5
Training loss: 2.864126682281494
Validation loss: 2.5321591797695366

Epoch: 6| Step: 6
Training loss: 3.7355384826660156
Validation loss: 2.5312907131769324

Epoch: 6| Step: 7
Training loss: 2.109933614730835
Validation loss: 2.532578122231268

Epoch: 6| Step: 8
Training loss: 3.0445780754089355
Validation loss: 2.5300603194903304

Epoch: 6| Step: 9
Training loss: 2.5706043243408203
Validation loss: 2.5266386821705806

Epoch: 6| Step: 10
Training loss: 3.1482186317443848
Validation loss: 2.5296333477061284

Epoch: 6| Step: 11
Training loss: 2.4500226974487305
Validation loss: 2.5360224836616108

Epoch: 6| Step: 12
Training loss: 2.189896583557129
Validation loss: 2.535423573627267

Epoch: 6| Step: 13
Training loss: 2.84326434135437
Validation loss: 2.544852679775607

Epoch: 90| Step: 0
Training loss: 3.6478021144866943
Validation loss: 2.5424653394247896

Epoch: 6| Step: 1
Training loss: 2.8981895446777344
Validation loss: 2.539704530469833

Epoch: 6| Step: 2
Training loss: 3.0041344165802
Validation loss: 2.5361500606741956

Epoch: 6| Step: 3
Training loss: 2.53035831451416
Validation loss: 2.530291900839857

Epoch: 6| Step: 4
Training loss: 2.0811264514923096
Validation loss: 2.5363859797036774

Epoch: 6| Step: 5
Training loss: 2.8018457889556885
Validation loss: 2.535978558242962

Epoch: 6| Step: 6
Training loss: 2.6900277137756348
Validation loss: 2.533832791031048

Epoch: 6| Step: 7
Training loss: 2.5169332027435303
Validation loss: 2.532239079475403

Epoch: 6| Step: 8
Training loss: 3.287438154220581
Validation loss: 2.5323703058304323

Epoch: 6| Step: 9
Training loss: 2.12306809425354
Validation loss: 2.529024685582807

Epoch: 6| Step: 10
Training loss: 2.7025256156921387
Validation loss: 2.529765216253137

Epoch: 6| Step: 11
Training loss: 2.4239566326141357
Validation loss: 2.529182259754468

Epoch: 6| Step: 12
Training loss: 2.605919122695923
Validation loss: 2.5246737387872513

Epoch: 6| Step: 13
Training loss: 2.9129011631011963
Validation loss: 2.524263398621672

Epoch: 91| Step: 0
Training loss: 2.9706778526306152
Validation loss: 2.5256970210741927

Epoch: 6| Step: 1
Training loss: 2.577070951461792
Validation loss: 2.526925527921287

Epoch: 6| Step: 2
Training loss: 2.2518725395202637
Validation loss: 2.521776250613633

Epoch: 6| Step: 3
Training loss: 3.0250442028045654
Validation loss: 2.5241018264524397

Epoch: 6| Step: 4
Training loss: 3.1590964794158936
Validation loss: 2.523755770857616

Epoch: 6| Step: 5
Training loss: 2.7733840942382812
Validation loss: 2.524964242853144

Epoch: 6| Step: 6
Training loss: 3.364945888519287
Validation loss: 2.528377039458162

Epoch: 6| Step: 7
Training loss: 2.494107723236084
Validation loss: 2.5251474201038318

Epoch: 6| Step: 8
Training loss: 2.3524017333984375
Validation loss: 2.52692949387335

Epoch: 6| Step: 9
Training loss: 3.427290201187134
Validation loss: 2.5231465575515584

Epoch: 6| Step: 10
Training loss: 2.072324275970459
Validation loss: 2.5299753809487946

Epoch: 6| Step: 11
Training loss: 2.5240681171417236
Validation loss: 2.536661240362352

Epoch: 6| Step: 12
Training loss: 2.657439708709717
Validation loss: 2.5362467150534354

Epoch: 6| Step: 13
Training loss: 2.2132465839385986
Validation loss: 2.5340647953812794

Epoch: 92| Step: 0
Training loss: 2.7358856201171875
Validation loss: 2.526698563688545

Epoch: 6| Step: 1
Training loss: 3.291536808013916
Validation loss: 2.528035176697598

Epoch: 6| Step: 2
Training loss: 2.5725245475769043
Validation loss: 2.526265941640382

Epoch: 6| Step: 3
Training loss: 2.4837121963500977
Validation loss: 2.523544196159609

Epoch: 6| Step: 4
Training loss: 3.2731409072875977
Validation loss: 2.521964280836044

Epoch: 6| Step: 5
Training loss: 2.8301308155059814
Validation loss: 2.528828195346299

Epoch: 6| Step: 6
Training loss: 3.2310118675231934
Validation loss: 2.5250980764307003

Epoch: 6| Step: 7
Training loss: 2.569985866546631
Validation loss: 2.526637613132436

Epoch: 6| Step: 8
Training loss: 2.835371494293213
Validation loss: 2.525618842853013

Epoch: 6| Step: 9
Training loss: 2.2381508350372314
Validation loss: 2.524713400871523

Epoch: 6| Step: 10
Training loss: 2.4484951496124268
Validation loss: 2.524695045204573

Epoch: 6| Step: 11
Training loss: 2.212526798248291
Validation loss: 2.5258810391990085

Epoch: 6| Step: 12
Training loss: 2.4677047729492188
Validation loss: 2.5281751976218274

Epoch: 6| Step: 13
Training loss: 2.978691816329956
Validation loss: 2.533265665013303

Epoch: 93| Step: 0
Training loss: 2.807133197784424
Validation loss: 2.5367243443765948

Epoch: 6| Step: 1
Training loss: 2.7015419006347656
Validation loss: 2.540223034479285

Epoch: 6| Step: 2
Training loss: 2.522145986557007
Validation loss: 2.536502376679451

Epoch: 6| Step: 3
Training loss: 3.070977210998535
Validation loss: 2.533168290251045

Epoch: 6| Step: 4
Training loss: 2.6663167476654053
Validation loss: 2.532922762696461

Epoch: 6| Step: 5
Training loss: 2.311354637145996
Validation loss: 2.5238923359942693

Epoch: 6| Step: 6
Training loss: 2.3881165981292725
Validation loss: 2.527220433758151

Epoch: 6| Step: 7
Training loss: 2.53348708152771
Validation loss: 2.524911465183381

Epoch: 6| Step: 8
Training loss: 2.336318254470825
Validation loss: 2.525333078958655

Epoch: 6| Step: 9
Training loss: 4.100436210632324
Validation loss: 2.5231838495500627

Epoch: 6| Step: 10
Training loss: 2.221330165863037
Validation loss: 2.5287600704418716

Epoch: 6| Step: 11
Training loss: 2.4249491691589355
Validation loss: 2.525360212531141

Epoch: 6| Step: 12
Training loss: 3.07273530960083
Validation loss: 2.5242346717465307

Epoch: 6| Step: 13
Training loss: 3.0199694633483887
Validation loss: 2.5253204299557592

Epoch: 94| Step: 0
Training loss: 2.465500593185425
Validation loss: 2.52935532857013

Epoch: 6| Step: 1
Training loss: 3.172274589538574
Validation loss: 2.5322620509773173

Epoch: 6| Step: 2
Training loss: 2.105715036392212
Validation loss: 2.5371615348323697

Epoch: 6| Step: 3
Training loss: 2.7162413597106934
Validation loss: 2.5399339955340148

Epoch: 6| Step: 4
Training loss: 2.6297638416290283
Validation loss: 2.533230968700942

Epoch: 6| Step: 5
Training loss: 2.4371280670166016
Validation loss: 2.53212385536522

Epoch: 6| Step: 6
Training loss: 2.577641487121582
Validation loss: 2.5286159412835234

Epoch: 6| Step: 7
Training loss: 2.836155891418457
Validation loss: 2.5311379842860724

Epoch: 6| Step: 8
Training loss: 2.7700161933898926
Validation loss: 2.533320447450043

Epoch: 6| Step: 9
Training loss: 2.1172807216644287
Validation loss: 2.525429412882815

Epoch: 6| Step: 10
Training loss: 2.9985551834106445
Validation loss: 2.52861031921961

Epoch: 6| Step: 11
Training loss: 3.6977908611297607
Validation loss: 2.526824907589984

Epoch: 6| Step: 12
Training loss: 2.8366761207580566
Validation loss: 2.5279271833358274

Epoch: 6| Step: 13
Training loss: 2.564736843109131
Validation loss: 2.523687695944181

Epoch: 95| Step: 0
Training loss: 2.0846595764160156
Validation loss: 2.5205371354215886

Epoch: 6| Step: 1
Training loss: 3.1960792541503906
Validation loss: 2.5232715657962266

Epoch: 6| Step: 2
Training loss: 2.82635760307312
Validation loss: 2.5176756099988054

Epoch: 6| Step: 3
Training loss: 4.019128322601318
Validation loss: 2.5198556184768677

Epoch: 6| Step: 4
Training loss: 2.781352996826172
Validation loss: 2.5237797434611986

Epoch: 6| Step: 5
Training loss: 3.0704102516174316
Validation loss: 2.523406849112562

Epoch: 6| Step: 6
Training loss: 2.9460012912750244
Validation loss: 2.522769806205585

Epoch: 6| Step: 7
Training loss: 2.4123454093933105
Validation loss: 2.52177736836095

Epoch: 6| Step: 8
Training loss: 2.38560152053833
Validation loss: 2.521387586029627

Epoch: 6| Step: 9
Training loss: 2.076450824737549
Validation loss: 2.52040700245929

Epoch: 6| Step: 10
Training loss: 3.4255175590515137
Validation loss: 2.5172600130881033

Epoch: 6| Step: 11
Training loss: 2.0535573959350586
Validation loss: 2.5200625158125356

Epoch: 6| Step: 12
Training loss: 2.1381518840789795
Validation loss: 2.518309156099955

Epoch: 6| Step: 13
Training loss: 2.344593048095703
Validation loss: 2.5206873416900635

Epoch: 96| Step: 0
Training loss: 2.6160354614257812
Validation loss: 2.5194572197493685

Epoch: 6| Step: 1
Training loss: 2.779679775238037
Validation loss: 2.518750721408475

Epoch: 6| Step: 2
Training loss: 3.0576510429382324
Validation loss: 2.517246410410891

Epoch: 6| Step: 3
Training loss: 2.0008487701416016
Validation loss: 2.5205014187802552

Epoch: 6| Step: 4
Training loss: 2.630453109741211
Validation loss: 2.5207169337939193

Epoch: 6| Step: 5
Training loss: 2.8441696166992188
Validation loss: 2.5196304603289534

Epoch: 6| Step: 6
Training loss: 2.783604621887207
Validation loss: 2.5167491820550736

Epoch: 6| Step: 7
Training loss: 1.9051289558410645
Validation loss: 2.516815816202471

Epoch: 6| Step: 8
Training loss: 3.148861885070801
Validation loss: 2.51660511314228

Epoch: 6| Step: 9
Training loss: 3.484294891357422
Validation loss: 2.515062483408118

Epoch: 6| Step: 10
Training loss: 2.907240629196167
Validation loss: 2.51452923077409

Epoch: 6| Step: 11
Training loss: 2.829582452774048
Validation loss: 2.5163108379610124

Epoch: 6| Step: 12
Training loss: 2.2568957805633545
Validation loss: 2.5149469221791914

Epoch: 6| Step: 13
Training loss: 2.6482598781585693
Validation loss: 2.516061754636867

Epoch: 97| Step: 0
Training loss: 2.7093961238861084
Validation loss: 2.522239885022563

Epoch: 6| Step: 1
Training loss: 1.8107495307922363
Validation loss: 2.524820068831085

Epoch: 6| Step: 2
Training loss: 2.815062999725342
Validation loss: 2.531625565662179

Epoch: 6| Step: 3
Training loss: 2.7598118782043457
Validation loss: 2.5369112465971257

Epoch: 6| Step: 4
Training loss: 3.2428817749023438
Validation loss: 2.527284647828789

Epoch: 6| Step: 5
Training loss: 2.4749770164489746
Validation loss: 2.535135207637664

Epoch: 6| Step: 6
Training loss: 3.964984178543091
Validation loss: 2.5317951069083264

Epoch: 6| Step: 7
Training loss: 1.8430556058883667
Validation loss: 2.5287236757175897

Epoch: 6| Step: 8
Training loss: 3.534759998321533
Validation loss: 2.5218600714078514

Epoch: 6| Step: 9
Training loss: 2.268669605255127
Validation loss: 2.5209889309380644

Epoch: 6| Step: 10
Training loss: 2.777322292327881
Validation loss: 2.5262577354267077

Epoch: 6| Step: 11
Training loss: 2.3956451416015625
Validation loss: 2.5247238195070656

Epoch: 6| Step: 12
Training loss: 2.4129090309143066
Validation loss: 2.5189472065177014

Epoch: 6| Step: 13
Training loss: 2.867345094680786
Validation loss: 2.5167906643241964

Epoch: 98| Step: 0
Training loss: 3.4279098510742188
Validation loss: 2.509790712787259

Epoch: 6| Step: 1
Training loss: 2.8170413970947266
Validation loss: 2.515203176006194

Epoch: 6| Step: 2
Training loss: 2.722327709197998
Validation loss: 2.511872517165317

Epoch: 6| Step: 3
Training loss: 1.9798133373260498
Validation loss: 2.5202313879484772

Epoch: 6| Step: 4
Training loss: 3.1518568992614746
Validation loss: 2.5210558188858854

Epoch: 6| Step: 5
Training loss: 3.062652111053467
Validation loss: 2.5182665778744604

Epoch: 6| Step: 6
Training loss: 2.802983045578003
Validation loss: 2.5129091470472273

Epoch: 6| Step: 7
Training loss: 2.9797065258026123
Validation loss: 2.511921032782524

Epoch: 6| Step: 8
Training loss: 2.5147790908813477
Validation loss: 2.5115837051022436

Epoch: 6| Step: 9
Training loss: 2.5117695331573486
Validation loss: 2.5142438001530145

Epoch: 6| Step: 10
Training loss: 2.7500252723693848
Validation loss: 2.5147761580764607

Epoch: 6| Step: 11
Training loss: 2.3276114463806152
Validation loss: 2.513649143198485

Epoch: 6| Step: 12
Training loss: 2.2346835136413574
Validation loss: 2.5156403844074537

Epoch: 6| Step: 13
Training loss: 2.4424266815185547
Validation loss: 2.514581000933083

Epoch: 99| Step: 0
Training loss: 1.8582358360290527
Validation loss: 2.5121497672091246

Epoch: 6| Step: 1
Training loss: 2.2953739166259766
Validation loss: 2.517697380435082

Epoch: 6| Step: 2
Training loss: 3.0657992362976074
Validation loss: 2.516739576093612

Epoch: 6| Step: 3
Training loss: 2.948917865753174
Validation loss: 2.5135355175182386

Epoch: 6| Step: 4
Training loss: 3.2636666297912598
Validation loss: 2.511914368598692

Epoch: 6| Step: 5
Training loss: 2.7218823432922363
Validation loss: 2.5096421177669237

Epoch: 6| Step: 6
Training loss: 2.692748546600342
Validation loss: 2.5093615413993917

Epoch: 6| Step: 7
Training loss: 3.0506362915039062
Validation loss: 2.510218540827433

Epoch: 6| Step: 8
Training loss: 3.0366103649139404
Validation loss: 2.509855039658085

Epoch: 6| Step: 9
Training loss: 2.5503249168395996
Validation loss: 2.5085360465511197

Epoch: 6| Step: 10
Training loss: 2.429121494293213
Validation loss: 2.5074662316230034

Epoch: 6| Step: 11
Training loss: 3.291217803955078
Validation loss: 2.5058594262728127

Epoch: 6| Step: 12
Training loss: 2.1429903507232666
Validation loss: 2.509220976983347

Epoch: 6| Step: 13
Training loss: 2.293520927429199
Validation loss: 2.507955192237772

Epoch: 100| Step: 0
Training loss: 2.7496719360351562
Validation loss: 2.5111782140629266

Epoch: 6| Step: 1
Training loss: 3.023996114730835
Validation loss: 2.5208449107344433

Epoch: 6| Step: 2
Training loss: 1.8814213275909424
Validation loss: 2.5202943496806647

Epoch: 6| Step: 3
Training loss: 3.137410879135132
Validation loss: 2.5204050617833293

Epoch: 6| Step: 4
Training loss: 2.5766279697418213
Validation loss: 2.5098027452345817

Epoch: 6| Step: 5
Training loss: 3.164264440536499
Validation loss: 2.506411939538935

Epoch: 6| Step: 6
Training loss: 2.567648410797119
Validation loss: 2.5042976435794624

Epoch: 6| Step: 7
Training loss: 3.2119407653808594
Validation loss: 2.5073134053137993

Epoch: 6| Step: 8
Training loss: 2.6303811073303223
Validation loss: 2.5084756471777476

Epoch: 6| Step: 9
Training loss: 2.2588181495666504
Validation loss: 2.505803010796988

Epoch: 6| Step: 10
Training loss: 2.878812551498413
Validation loss: 2.510632207316737

Epoch: 6| Step: 11
Training loss: 1.7784277200698853
Validation loss: 2.5123050315405733

Epoch: 6| Step: 12
Training loss: 2.995452880859375
Validation loss: 2.518702394218855

Epoch: 6| Step: 13
Training loss: 3.095022439956665
Validation loss: 2.5175109396698656

Epoch: 101| Step: 0
Training loss: 3.062957286834717
Validation loss: 2.5219390187212216

Epoch: 6| Step: 1
Training loss: 2.2186875343322754
Validation loss: 2.528891994107154

Epoch: 6| Step: 2
Training loss: 2.0773301124572754
Validation loss: 2.5204320056464082

Epoch: 6| Step: 3
Training loss: 2.1433823108673096
Validation loss: 2.5168485410751833

Epoch: 6| Step: 4
Training loss: 3.153419017791748
Validation loss: 2.5129051054677656

Epoch: 6| Step: 5
Training loss: 2.5138235092163086
Validation loss: 2.5093902311017438

Epoch: 6| Step: 6
Training loss: 2.7316431999206543
Validation loss: 2.510152942390852

Epoch: 6| Step: 7
Training loss: 2.816840171813965
Validation loss: 2.5112776935741468

Epoch: 6| Step: 8
Training loss: 3.4478702545166016
Validation loss: 2.5051892085741927

Epoch: 6| Step: 9
Training loss: 2.8436388969421387
Validation loss: 2.5070404878226658

Epoch: 6| Step: 10
Training loss: 2.7818918228149414
Validation loss: 2.50148440945533

Epoch: 6| Step: 11
Training loss: 2.605868339538574
Validation loss: 2.501508682004867

Epoch: 6| Step: 12
Training loss: 2.875863552093506
Validation loss: 2.502747474178191

Epoch: 6| Step: 13
Training loss: 2.4198966026306152
Validation loss: 2.5005226378799765

Epoch: 102| Step: 0
Training loss: 3.252232313156128
Validation loss: 2.5020240660636657

Epoch: 6| Step: 1
Training loss: 2.111732006072998
Validation loss: 2.4985530248252292

Epoch: 6| Step: 2
Training loss: 1.8895106315612793
Validation loss: 2.5012031857685377

Epoch: 6| Step: 3
Training loss: 2.049968957901001
Validation loss: 2.504903201133974

Epoch: 6| Step: 4
Training loss: 4.210141658782959
Validation loss: 2.50960018814251

Epoch: 6| Step: 5
Training loss: 3.0941548347473145
Validation loss: 2.521393278593658

Epoch: 6| Step: 6
Training loss: 2.4640555381774902
Validation loss: 2.5292846259250434

Epoch: 6| Step: 7
Training loss: 2.784717559814453
Validation loss: 2.5288476713242067

Epoch: 6| Step: 8
Training loss: 2.4606759548187256
Validation loss: 2.5324888665189027

Epoch: 6| Step: 9
Training loss: 2.789306640625
Validation loss: 2.539247651253977

Epoch: 6| Step: 10
Training loss: 2.328989028930664
Validation loss: 2.531608594361172

Epoch: 6| Step: 11
Training loss: 2.4027047157287598
Validation loss: 2.5292302357253207

Epoch: 6| Step: 12
Training loss: 3.3520824909210205
Validation loss: 2.5338277483499176

Epoch: 6| Step: 13
Training loss: 2.59629487991333
Validation loss: 2.5273055979000625

Epoch: 103| Step: 0
Training loss: 2.9420580863952637
Validation loss: 2.516002421737999

Epoch: 6| Step: 1
Training loss: 3.5602970123291016
Validation loss: 2.5149572536509526

Epoch: 6| Step: 2
Training loss: 3.0366299152374268
Validation loss: 2.509324404501146

Epoch: 6| Step: 3
Training loss: 2.315277099609375
Validation loss: 2.5049703377549366

Epoch: 6| Step: 4
Training loss: 2.1497554779052734
Validation loss: 2.5075648241145636

Epoch: 6| Step: 5
Training loss: 2.8504867553710938
Validation loss: 2.500947536960725

Epoch: 6| Step: 6
Training loss: 2.9808874130249023
Validation loss: 2.4997462354680544

Epoch: 6| Step: 7
Training loss: 3.1129651069641113
Validation loss: 2.502798495754119

Epoch: 6| Step: 8
Training loss: 2.5512747764587402
Validation loss: 2.5042771472725818

Epoch: 6| Step: 9
Training loss: 1.9615228176116943
Validation loss: 2.5031771454759824

Epoch: 6| Step: 10
Training loss: 3.184488534927368
Validation loss: 2.5046301375153246

Epoch: 6| Step: 11
Training loss: 1.7747610807418823
Validation loss: 2.5072205399954193

Epoch: 6| Step: 12
Training loss: 2.386732816696167
Validation loss: 2.509284260452435

Epoch: 6| Step: 13
Training loss: 3.1050758361816406
Validation loss: 2.509209071436236

Epoch: 104| Step: 0
Training loss: 3.094449281692505
Validation loss: 2.5091583164789344

Epoch: 6| Step: 1
Training loss: 2.5195045471191406
Validation loss: 2.508515845062912

Epoch: 6| Step: 2
Training loss: 3.205303430557251
Validation loss: 2.502728767292474

Epoch: 6| Step: 3
Training loss: 3.2495992183685303
Validation loss: 2.5002617220724783

Epoch: 6| Step: 4
Training loss: 2.816901206970215
Validation loss: 2.5032257136478218

Epoch: 6| Step: 5
Training loss: 2.761617660522461
Validation loss: 2.5097313696338284

Epoch: 6| Step: 6
Training loss: 2.3659379482269287
Validation loss: 2.512002550145631

Epoch: 6| Step: 7
Training loss: 2.2674622535705566
Validation loss: 2.5170616206302436

Epoch: 6| Step: 8
Training loss: 2.2947864532470703
Validation loss: 2.520153819873769

Epoch: 6| Step: 9
Training loss: 3.0903091430664062
Validation loss: 2.522085623074603

Epoch: 6| Step: 10
Training loss: 2.7520551681518555
Validation loss: 2.5149538593907512

Epoch: 6| Step: 11
Training loss: 2.7835874557495117
Validation loss: 2.5105586795396704

Epoch: 6| Step: 12
Training loss: 2.236332416534424
Validation loss: 2.5029773917249454

Epoch: 6| Step: 13
Training loss: 1.9526644945144653
Validation loss: 2.5063708187431417

Epoch: 105| Step: 0
Training loss: 3.0196993350982666
Validation loss: 2.5002079086918987

Epoch: 6| Step: 1
Training loss: 2.9018115997314453
Validation loss: 2.49577324621139

Epoch: 6| Step: 2
Training loss: 2.2975144386291504
Validation loss: 2.4973019887042303

Epoch: 6| Step: 3
Training loss: 2.271497964859009
Validation loss: 2.493062980713383

Epoch: 6| Step: 4
Training loss: 3.1856205463409424
Validation loss: 2.493787965466899

Epoch: 6| Step: 5
Training loss: 2.9237942695617676
Validation loss: 2.4935324550956808

Epoch: 6| Step: 6
Training loss: 3.4444737434387207
Validation loss: 2.4941986196784565

Epoch: 6| Step: 7
Training loss: 2.876601457595825
Validation loss: 2.496015953761275

Epoch: 6| Step: 8
Training loss: 3.0575404167175293
Validation loss: 2.4944927641140517

Epoch: 6| Step: 9
Training loss: 2.3748779296875
Validation loss: 2.4912124526116157

Epoch: 6| Step: 10
Training loss: 1.9291554689407349
Validation loss: 2.4915233042932328

Epoch: 6| Step: 11
Training loss: 2.216747522354126
Validation loss: 2.492703560859926

Epoch: 6| Step: 12
Training loss: 2.8211493492126465
Validation loss: 2.4912188027494695

Epoch: 6| Step: 13
Training loss: 2.0839338302612305
Validation loss: 2.4949004573206746

Epoch: 106| Step: 0
Training loss: 2.3964476585388184
Validation loss: 2.4941876242237706

Epoch: 6| Step: 1
Training loss: 2.2264175415039062
Validation loss: 2.4921053122448664

Epoch: 6| Step: 2
Training loss: 2.4177727699279785
Validation loss: 2.495854728965349

Epoch: 6| Step: 3
Training loss: 3.070662498474121
Validation loss: 2.5022555192311606

Epoch: 6| Step: 4
Training loss: 3.136765480041504
Validation loss: 2.5085506375117967

Epoch: 6| Step: 5
Training loss: 3.0324177742004395
Validation loss: 2.517705717394429

Epoch: 6| Step: 6
Training loss: 2.357936143875122
Validation loss: 2.5169915973499255

Epoch: 6| Step: 7
Training loss: 3.0108373165130615
Validation loss: 2.5236132068018757

Epoch: 6| Step: 8
Training loss: 2.8717637062072754
Validation loss: 2.51823942635649

Epoch: 6| Step: 9
Training loss: 2.9948654174804688
Validation loss: 2.511765782551099

Epoch: 6| Step: 10
Training loss: 2.711933135986328
Validation loss: 2.516579479299566

Epoch: 6| Step: 11
Training loss: 2.475083351135254
Validation loss: 2.504183820498887

Epoch: 6| Step: 12
Training loss: 2.4961423873901367
Validation loss: 2.4964160201370076

Epoch: 6| Step: 13
Training loss: 2.3651387691497803
Validation loss: 2.493428163630988

Epoch: 107| Step: 0
Training loss: 2.636232852935791
Validation loss: 2.493313948313395

Epoch: 6| Step: 1
Training loss: 2.652815818786621
Validation loss: 2.4879359301700386

Epoch: 6| Step: 2
Training loss: 3.3930044174194336
Validation loss: 2.4906930564552225

Epoch: 6| Step: 3
Training loss: 2.8188438415527344
Validation loss: 2.49417818233531

Epoch: 6| Step: 4
Training loss: 2.0227184295654297
Validation loss: 2.4945492026626424

Epoch: 6| Step: 5
Training loss: 2.3674001693725586
Validation loss: 2.4956075452989146

Epoch: 6| Step: 6
Training loss: 2.4375483989715576
Validation loss: 2.49471535733951

Epoch: 6| Step: 7
Training loss: 3.0289626121520996
Validation loss: 2.492144077054916

Epoch: 6| Step: 8
Training loss: 2.808262348175049
Validation loss: 2.4908944483726256

Epoch: 6| Step: 9
Training loss: 2.258476495742798
Validation loss: 2.4898868196754047

Epoch: 6| Step: 10
Training loss: 2.896463394165039
Validation loss: 2.4897937467021327

Epoch: 6| Step: 11
Training loss: 2.7455358505249023
Validation loss: 2.48819064581266

Epoch: 6| Step: 12
Training loss: 3.0140535831451416
Validation loss: 2.491823988576089

Epoch: 6| Step: 13
Training loss: 2.5648036003112793
Validation loss: 2.4959295129263275

Epoch: 108| Step: 0
Training loss: 2.189988136291504
Validation loss: 2.504170012730424

Epoch: 6| Step: 1
Training loss: 2.87955904006958
Validation loss: 2.512413147957094

Epoch: 6| Step: 2
Training loss: 2.5726728439331055
Validation loss: 2.509607063826694

Epoch: 6| Step: 3
Training loss: 3.1484484672546387
Validation loss: 2.508370094401862

Epoch: 6| Step: 4
Training loss: 2.6039302349090576
Validation loss: 2.505136784686837

Epoch: 6| Step: 5
Training loss: 2.5997161865234375
Validation loss: 2.5041569150904173

Epoch: 6| Step: 6
Training loss: 2.501500368118286
Validation loss: 2.500386696989818

Epoch: 6| Step: 7
Training loss: 3.445462226867676
Validation loss: 2.5013608496676207

Epoch: 6| Step: 8
Training loss: 3.2763521671295166
Validation loss: 2.503838046904533

Epoch: 6| Step: 9
Training loss: 2.64009428024292
Validation loss: 2.499524011406847

Epoch: 6| Step: 10
Training loss: 2.543989896774292
Validation loss: 2.4977032676819833

Epoch: 6| Step: 11
Training loss: 2.439523220062256
Validation loss: 2.4920455025088404

Epoch: 6| Step: 12
Training loss: 1.957598090171814
Validation loss: 2.492849378175633

Epoch: 6| Step: 13
Training loss: 3.0869131088256836
Validation loss: 2.4932966257936213

Epoch: 109| Step: 0
Training loss: 1.704866886138916
Validation loss: 2.487407156216201

Epoch: 6| Step: 1
Training loss: 2.742396354675293
Validation loss: 2.492758225369197

Epoch: 6| Step: 2
Training loss: 2.354079246520996
Validation loss: 2.490920559052498

Epoch: 6| Step: 3
Training loss: 2.5740671157836914
Validation loss: 2.4931759321561424

Epoch: 6| Step: 4
Training loss: 2.908250331878662
Validation loss: 2.4950793148368917

Epoch: 6| Step: 5
Training loss: 1.5279865264892578
Validation loss: 2.5015684481590026

Epoch: 6| Step: 6
Training loss: 2.4973526000976562
Validation loss: 2.499318520228068

Epoch: 6| Step: 7
Training loss: 2.9250447750091553
Validation loss: 2.4958230680035007

Epoch: 6| Step: 8
Training loss: 3.1880364418029785
Validation loss: 2.4986384453312045

Epoch: 6| Step: 9
Training loss: 2.6286439895629883
Validation loss: 2.500190337498983

Epoch: 6| Step: 10
Training loss: 3.043233871459961
Validation loss: 2.492420906661659

Epoch: 6| Step: 11
Training loss: 3.1591310501098633
Validation loss: 2.4913999598513366

Epoch: 6| Step: 12
Training loss: 3.0762298107147217
Validation loss: 2.496369377259285

Epoch: 6| Step: 13
Training loss: 3.6668193340301514
Validation loss: 2.505345126634003

Epoch: 110| Step: 0
Training loss: 2.53407621383667
Validation loss: 2.5023358560377553

Epoch: 6| Step: 1
Training loss: 1.7638969421386719
Validation loss: 2.5196747908028225

Epoch: 6| Step: 2
Training loss: 2.813340902328491
Validation loss: 2.5092329953306463

Epoch: 6| Step: 3
Training loss: 2.6676218509674072
Validation loss: 2.495693547751314

Epoch: 6| Step: 4
Training loss: 2.9097983837127686
Validation loss: 2.483650117792109

Epoch: 6| Step: 5
Training loss: 2.54658842086792
Validation loss: 2.4871783756440684

Epoch: 6| Step: 6
Training loss: 2.224048614501953
Validation loss: 2.4868121236883183

Epoch: 6| Step: 7
Training loss: 2.222370147705078
Validation loss: 2.4854240776390157

Epoch: 6| Step: 8
Training loss: 3.484487295150757
Validation loss: 2.4847980571049515

Epoch: 6| Step: 9
Training loss: 2.9820175170898438
Validation loss: 2.4869718679817776

Epoch: 6| Step: 10
Training loss: 2.192258834838867
Validation loss: 2.491386834011283

Epoch: 6| Step: 11
Training loss: 3.1905064582824707
Validation loss: 2.494121361804265

Epoch: 6| Step: 12
Training loss: 3.0383517742156982
Validation loss: 2.495719458467217

Epoch: 6| Step: 13
Training loss: 3.0395472049713135
Validation loss: 2.508014976337392

Epoch: 111| Step: 0
Training loss: 3.216707706451416
Validation loss: 2.513795957770399

Epoch: 6| Step: 1
Training loss: 2.1827149391174316
Validation loss: 2.5076544592457433

Epoch: 6| Step: 2
Training loss: 2.831263542175293
Validation loss: 2.4937243384699666

Epoch: 6| Step: 3
Training loss: 2.827768564224243
Validation loss: 2.491970077637703

Epoch: 6| Step: 4
Training loss: 2.8426566123962402
Validation loss: 2.486785529762186

Epoch: 6| Step: 5
Training loss: 2.6818628311157227
Validation loss: 2.481157374638383

Epoch: 6| Step: 6
Training loss: 3.7435009479522705
Validation loss: 2.4834742879354827

Epoch: 6| Step: 7
Training loss: 1.8908216953277588
Validation loss: 2.4840516095520346

Epoch: 6| Step: 8
Training loss: 2.1059162616729736
Validation loss: 2.48019713740195

Epoch: 6| Step: 9
Training loss: 2.549640417098999
Validation loss: 2.484637519364716

Epoch: 6| Step: 10
Training loss: 2.433134078979492
Validation loss: 2.4841265370768886

Epoch: 6| Step: 11
Training loss: 2.231013059616089
Validation loss: 2.479809540574269

Epoch: 6| Step: 12
Training loss: 3.281188488006592
Validation loss: 2.4840350484335296

Epoch: 6| Step: 13
Training loss: 2.8181166648864746
Validation loss: 2.482588486004901

Epoch: 112| Step: 0
Training loss: 2.9337539672851562
Validation loss: 2.4893072728187806

Epoch: 6| Step: 1
Training loss: 2.0017294883728027
Validation loss: 2.490071230037238

Epoch: 6| Step: 2
Training loss: 2.35723876953125
Validation loss: 2.4913915100918023

Epoch: 6| Step: 3
Training loss: 2.0654456615448
Validation loss: 2.490253266467843

Epoch: 6| Step: 4
Training loss: 2.961698055267334
Validation loss: 2.4911608349892402

Epoch: 6| Step: 5
Training loss: 3.149954319000244
Validation loss: 2.4864830150399158

Epoch: 6| Step: 6
Training loss: 3.3772242069244385
Validation loss: 2.484698041792839

Epoch: 6| Step: 7
Training loss: 2.8682775497436523
Validation loss: 2.479429045031148

Epoch: 6| Step: 8
Training loss: 2.7384140491485596
Validation loss: 2.481472348654142

Epoch: 6| Step: 9
Training loss: 2.133453845977783
Validation loss: 2.482419772814679

Epoch: 6| Step: 10
Training loss: 2.2694787979125977
Validation loss: 2.479773614996223

Epoch: 6| Step: 11
Training loss: 3.3030943870544434
Validation loss: 2.477686884582684

Epoch: 6| Step: 12
Training loss: 2.9050168991088867
Validation loss: 2.4815596226722962

Epoch: 6| Step: 13
Training loss: 2.2729430198669434
Validation loss: 2.4862020656626713

Epoch: 113| Step: 0
Training loss: 2.3382351398468018
Validation loss: 2.4886559209515973

Epoch: 6| Step: 1
Training loss: 2.9227490425109863
Validation loss: 2.490274465212258

Epoch: 6| Step: 2
Training loss: 2.91251802444458
Validation loss: 2.4919126213237806

Epoch: 6| Step: 3
Training loss: 3.3551955223083496
Validation loss: 2.4947793740098194

Epoch: 6| Step: 4
Training loss: 2.428798198699951
Validation loss: 2.4930784984301497

Epoch: 6| Step: 5
Training loss: 3.0625152587890625
Validation loss: 2.496082516126735

Epoch: 6| Step: 6
Training loss: 2.0490918159484863
Validation loss: 2.496194665149976

Epoch: 6| Step: 7
Training loss: 2.163145065307617
Validation loss: 2.4895825796229865

Epoch: 6| Step: 8
Training loss: 2.4842002391815186
Validation loss: 2.485754853935652

Epoch: 6| Step: 9
Training loss: 3.1236791610717773
Validation loss: 2.488581777900778

Epoch: 6| Step: 10
Training loss: 2.448486328125
Validation loss: 2.484999377240417

Epoch: 6| Step: 11
Training loss: 3.2910521030426025
Validation loss: 2.484927959339593

Epoch: 6| Step: 12
Training loss: 2.1567649841308594
Validation loss: 2.4845794682861655

Epoch: 6| Step: 13
Training loss: 3.079402446746826
Validation loss: 2.49197845689712

Epoch: 114| Step: 0
Training loss: 2.5612926483154297
Validation loss: 2.5025884669314147

Epoch: 6| Step: 1
Training loss: 3.5227038860321045
Validation loss: 2.5172570328558646

Epoch: 6| Step: 2
Training loss: 2.996434211730957
Validation loss: 2.5100866876622683

Epoch: 6| Step: 3
Training loss: 2.4678964614868164
Validation loss: 2.511126225994479

Epoch: 6| Step: 4
Training loss: 2.731790065765381
Validation loss: 2.4981452239457

Epoch: 6| Step: 5
Training loss: 2.686434268951416
Validation loss: 2.495554449737713

Epoch: 6| Step: 6
Training loss: 2.2049365043640137
Validation loss: 2.4854435356714393

Epoch: 6| Step: 7
Training loss: 2.3549089431762695
Validation loss: 2.489992154541836

Epoch: 6| Step: 8
Training loss: 3.318880319595337
Validation loss: 2.4853054477322485

Epoch: 6| Step: 9
Training loss: 2.8866944313049316
Validation loss: 2.4875233275915987

Epoch: 6| Step: 10
Training loss: 2.3267054557800293
Validation loss: 2.491725380702685

Epoch: 6| Step: 11
Training loss: 2.4579384326934814
Validation loss: 2.4920425876494376

Epoch: 6| Step: 12
Training loss: 2.3296897411346436
Validation loss: 2.4940553788215882

Epoch: 6| Step: 13
Training loss: 2.65160870552063
Validation loss: 2.49486526109839

Epoch: 115| Step: 0
Training loss: 3.021648406982422
Validation loss: 2.4971069725610877

Epoch: 6| Step: 1
Training loss: 2.5620336532592773
Validation loss: 2.495095294008973

Epoch: 6| Step: 2
Training loss: 2.5404715538024902
Validation loss: 2.498883047411519

Epoch: 6| Step: 3
Training loss: 2.6306276321411133
Validation loss: 2.4940925772472093

Epoch: 6| Step: 4
Training loss: 2.4191646575927734
Validation loss: 2.5042696742601294

Epoch: 6| Step: 5
Training loss: 2.006006956100464
Validation loss: 2.502062571946011

Epoch: 6| Step: 6
Training loss: 2.988025188446045
Validation loss: 2.4953259268114643

Epoch: 6| Step: 7
Training loss: 2.1611080169677734
Validation loss: 2.4886735741810133

Epoch: 6| Step: 8
Training loss: 3.552201271057129
Validation loss: 2.486251251671904

Epoch: 6| Step: 9
Training loss: 3.1556954383850098
Validation loss: 2.4847662243791806

Epoch: 6| Step: 10
Training loss: 2.449398994445801
Validation loss: 2.4780198656102663

Epoch: 6| Step: 11
Training loss: 2.773399591445923
Validation loss: 2.4781063115724953

Epoch: 6| Step: 12
Training loss: 2.547243595123291
Validation loss: 2.4760441113543767

Epoch: 6| Step: 13
Training loss: 2.5797924995422363
Validation loss: 2.4774782196167977

Epoch: 116| Step: 0
Training loss: 2.4823389053344727
Validation loss: 2.48081120111609

Epoch: 6| Step: 1
Training loss: 2.8457963466644287
Validation loss: 2.4857549692994807

Epoch: 6| Step: 2
Training loss: 2.5180623531341553
Validation loss: 2.4827038882881083

Epoch: 6| Step: 3
Training loss: 2.7497949600219727
Validation loss: 2.482886496410575

Epoch: 6| Step: 4
Training loss: 2.3193914890289307
Validation loss: 2.4869284552912556

Epoch: 6| Step: 5
Training loss: 2.48701548576355
Validation loss: 2.488880343334649

Epoch: 6| Step: 6
Training loss: 3.0931754112243652
Validation loss: 2.4858726993683846

Epoch: 6| Step: 7
Training loss: 2.2741925716400146
Validation loss: 2.4803617282580306

Epoch: 6| Step: 8
Training loss: 2.5038554668426514
Validation loss: 2.476560177341584

Epoch: 6| Step: 9
Training loss: 1.9936485290527344
Validation loss: 2.4777417593104865

Epoch: 6| Step: 10
Training loss: 2.818711280822754
Validation loss: 2.476033954210179

Epoch: 6| Step: 11
Training loss: 3.5177807807922363
Validation loss: 2.474126044140067

Epoch: 6| Step: 12
Training loss: 2.681006908416748
Validation loss: 2.4779034147980394

Epoch: 6| Step: 13
Training loss: 3.47515869140625
Validation loss: 2.473419548362814

Epoch: 117| Step: 0
Training loss: 2.6772537231445312
Validation loss: 2.473762330188546

Epoch: 6| Step: 1
Training loss: 2.292850971221924
Validation loss: 2.471484543174826

Epoch: 6| Step: 2
Training loss: 3.333055257797241
Validation loss: 2.4685023356509466

Epoch: 6| Step: 3
Training loss: 3.798301935195923
Validation loss: 2.469901018245246

Epoch: 6| Step: 4
Training loss: 2.4071857929229736
Validation loss: 2.4686682352455716

Epoch: 6| Step: 5
Training loss: 2.8575499057769775
Validation loss: 2.46838467608216

Epoch: 6| Step: 6
Training loss: 2.1514670848846436
Validation loss: 2.4698690265737553

Epoch: 6| Step: 7
Training loss: 1.8477946519851685
Validation loss: 2.46769279818381

Epoch: 6| Step: 8
Training loss: 2.554745674133301
Validation loss: 2.467469858866866

Epoch: 6| Step: 9
Training loss: 1.949559211730957
Validation loss: 2.470873994211997

Epoch: 6| Step: 10
Training loss: 3.0659546852111816
Validation loss: 2.466561640462568

Epoch: 6| Step: 11
Training loss: 2.4436988830566406
Validation loss: 2.470320378580401

Epoch: 6| Step: 12
Training loss: 3.368783950805664
Validation loss: 2.471159747851792

Epoch: 6| Step: 13
Training loss: 2.5388102531433105
Validation loss: 2.4691212587459113

Epoch: 118| Step: 0
Training loss: 3.5175323486328125
Validation loss: 2.4721663972382903

Epoch: 6| Step: 1
Training loss: 3.2408287525177
Validation loss: 2.473100867322696

Epoch: 6| Step: 2
Training loss: 2.875361680984497
Validation loss: 2.478273771142447

Epoch: 6| Step: 3
Training loss: 2.631683349609375
Validation loss: 2.4762885647435344

Epoch: 6| Step: 4
Training loss: 2.363924026489258
Validation loss: 2.4702306434672368

Epoch: 6| Step: 5
Training loss: 2.715681314468384
Validation loss: 2.4741863384041736

Epoch: 6| Step: 6
Training loss: 2.2704849243164062
Validation loss: 2.4743691823815785

Epoch: 6| Step: 7
Training loss: 2.324894428253174
Validation loss: 2.4689872316134873

Epoch: 6| Step: 8
Training loss: 2.7307565212249756
Validation loss: 2.4713538744116343

Epoch: 6| Step: 9
Training loss: 2.8782944679260254
Validation loss: 2.4690450776007866

Epoch: 6| Step: 10
Training loss: 1.6740832328796387
Validation loss: 2.47004932741965

Epoch: 6| Step: 11
Training loss: 2.6096715927124023
Validation loss: 2.4699718900906142

Epoch: 6| Step: 12
Training loss: 2.5584139823913574
Validation loss: 2.4727040772796958

Epoch: 6| Step: 13
Training loss: 3.1881797313690186
Validation loss: 2.475938985424657

Epoch: 119| Step: 0
Training loss: 2.56923770904541
Validation loss: 2.4889116569231917

Epoch: 6| Step: 1
Training loss: 2.742431163787842
Validation loss: 2.489828981379027

Epoch: 6| Step: 2
Training loss: 2.632631301879883
Validation loss: 2.4867244433331233

Epoch: 6| Step: 3
Training loss: 2.218801975250244
Validation loss: 2.476382509354622

Epoch: 6| Step: 4
Training loss: 2.407280206680298
Validation loss: 2.4730219200093257

Epoch: 6| Step: 5
Training loss: 2.4857497215270996
Validation loss: 2.4734054227029123

Epoch: 6| Step: 6
Training loss: 3.349982261657715
Validation loss: 2.470489901881064

Epoch: 6| Step: 7
Training loss: 3.272068977355957
Validation loss: 2.467224569730861

Epoch: 6| Step: 8
Training loss: 2.2854576110839844
Validation loss: 2.4673861098545853

Epoch: 6| Step: 9
Training loss: 2.784609317779541
Validation loss: 2.469684916157876

Epoch: 6| Step: 10
Training loss: 1.744605302810669
Validation loss: 2.468563272107032

Epoch: 6| Step: 11
Training loss: 3.075605869293213
Validation loss: 2.4757105381258073

Epoch: 6| Step: 12
Training loss: 3.123995780944824
Validation loss: 2.4843655555478987

Epoch: 6| Step: 13
Training loss: 2.8144218921661377
Validation loss: 2.4786523901006228

Epoch: 120| Step: 0
Training loss: 2.4149839878082275
Validation loss: 2.4814941344722623

Epoch: 6| Step: 1
Training loss: 2.699378728866577
Validation loss: 2.4721533380528933

Epoch: 6| Step: 2
Training loss: 3.5102365016937256
Validation loss: 2.4693909204134377

Epoch: 6| Step: 3
Training loss: 3.0831856727600098
Validation loss: 2.466243492659702

Epoch: 6| Step: 4
Training loss: 2.3139753341674805
Validation loss: 2.4692427086573776

Epoch: 6| Step: 5
Training loss: 2.179971933364868
Validation loss: 2.469472236530755

Epoch: 6| Step: 6
Training loss: 2.940441370010376
Validation loss: 2.470845309636926

Epoch: 6| Step: 7
Training loss: 1.9682503938674927
Validation loss: 2.4757403994119294

Epoch: 6| Step: 8
Training loss: 2.715751886367798
Validation loss: 2.483077185128325

Epoch: 6| Step: 9
Training loss: 2.2629895210266113
Validation loss: 2.4846508477323797

Epoch: 6| Step: 10
Training loss: 2.567142963409424
Validation loss: 2.4916553138404764

Epoch: 6| Step: 11
Training loss: 2.707303524017334
Validation loss: 2.501220746706891

Epoch: 6| Step: 12
Training loss: 2.890066146850586
Validation loss: 2.495391548320811

Epoch: 6| Step: 13
Training loss: 3.6748898029327393
Validation loss: 2.4958137927516812

Epoch: 121| Step: 0
Training loss: 2.5300216674804688
Validation loss: 2.478654625595257

Epoch: 6| Step: 1
Training loss: 3.0526256561279297
Validation loss: 2.4703504500850553

Epoch: 6| Step: 2
Training loss: 2.481959342956543
Validation loss: 2.4703273106646795

Epoch: 6| Step: 3
Training loss: 2.3344478607177734
Validation loss: 2.471488647563483

Epoch: 6| Step: 4
Training loss: 2.44431734085083
Validation loss: 2.4701639759925103

Epoch: 6| Step: 5
Training loss: 2.1005897521972656
Validation loss: 2.4710664928600354

Epoch: 6| Step: 6
Training loss: 2.7727413177490234
Validation loss: 2.4767354893428024

Epoch: 6| Step: 7
Training loss: 3.147892713546753
Validation loss: 2.4856418025109077

Epoch: 6| Step: 8
Training loss: 2.8386425971984863
Validation loss: 2.4854622143571095

Epoch: 6| Step: 9
Training loss: 2.7188825607299805
Validation loss: 2.4818629193049606

Epoch: 6| Step: 10
Training loss: 2.490933418273926
Validation loss: 2.4756885523437173

Epoch: 6| Step: 11
Training loss: 2.7235450744628906
Validation loss: 2.4724765644278577

Epoch: 6| Step: 12
Training loss: 3.0391669273376465
Validation loss: 2.465054855551771

Epoch: 6| Step: 13
Training loss: 2.688206911087036
Validation loss: 2.464674303608556

Epoch: 122| Step: 0
Training loss: 2.1613824367523193
Validation loss: 2.46516231823993

Epoch: 6| Step: 1
Training loss: 3.8765106201171875
Validation loss: 2.4636908449152464

Epoch: 6| Step: 2
Training loss: 2.307457447052002
Validation loss: 2.4611486901519117

Epoch: 6| Step: 3
Training loss: 3.010653495788574
Validation loss: 2.4582045949915403

Epoch: 6| Step: 4
Training loss: 2.5212316513061523
Validation loss: 2.463189476279802

Epoch: 6| Step: 5
Training loss: 2.43137788772583
Validation loss: 2.466245174407959

Epoch: 6| Step: 6
Training loss: 2.622068405151367
Validation loss: 2.4694425034266647

Epoch: 6| Step: 7
Training loss: 2.457247734069824
Validation loss: 2.4682007553756877

Epoch: 6| Step: 8
Training loss: 2.7198524475097656
Validation loss: 2.4690016508102417

Epoch: 6| Step: 9
Training loss: 3.065232753753662
Validation loss: 2.465336797057941

Epoch: 6| Step: 10
Training loss: 2.1745078563690186
Validation loss: 2.4657312336788384

Epoch: 6| Step: 11
Training loss: 2.802971363067627
Validation loss: 2.4674417280381724

Epoch: 6| Step: 12
Training loss: 2.2246317863464355
Validation loss: 2.46209043072116

Epoch: 6| Step: 13
Training loss: 3.118576765060425
Validation loss: 2.462908826848512

Epoch: 123| Step: 0
Training loss: 2.1997623443603516
Validation loss: 2.4628929553493375

Epoch: 6| Step: 1
Training loss: 2.476921558380127
Validation loss: 2.4633464069776636

Epoch: 6| Step: 2
Training loss: 1.715633511543274
Validation loss: 2.46147987919469

Epoch: 6| Step: 3
Training loss: 2.11151123046875
Validation loss: 2.4590221681902484

Epoch: 6| Step: 4
Training loss: 2.3504438400268555
Validation loss: 2.460292318815826

Epoch: 6| Step: 5
Training loss: 2.4371683597564697
Validation loss: 2.457947443890315

Epoch: 6| Step: 6
Training loss: 2.9297025203704834
Validation loss: 2.460776346986012

Epoch: 6| Step: 7
Training loss: 2.453763484954834
Validation loss: 2.4601080186905397

Epoch: 6| Step: 8
Training loss: 2.780092716217041
Validation loss: 2.460283858801729

Epoch: 6| Step: 9
Training loss: 3.7484545707702637
Validation loss: 2.462807070824408

Epoch: 6| Step: 10
Training loss: 3.1487293243408203
Validation loss: 2.459773886588312

Epoch: 6| Step: 11
Training loss: 2.7082557678222656
Validation loss: 2.458988389661235

Epoch: 6| Step: 12
Training loss: 2.4049177169799805
Validation loss: 2.4614181672373125

Epoch: 6| Step: 13
Training loss: 4.672719478607178
Validation loss: 2.4600618347044914

Epoch: 124| Step: 0
Training loss: 3.49442720413208
Validation loss: 2.4635332630526636

Epoch: 6| Step: 1
Training loss: 3.1280252933502197
Validation loss: 2.459480708645236

Epoch: 6| Step: 2
Training loss: 2.6875767707824707
Validation loss: 2.461486660024171

Epoch: 6| Step: 3
Training loss: 2.629302978515625
Validation loss: 2.458341416492257

Epoch: 6| Step: 4
Training loss: 2.8569438457489014
Validation loss: 2.463350495984477

Epoch: 6| Step: 5
Training loss: 2.4013419151306152
Validation loss: 2.459756633286835

Epoch: 6| Step: 6
Training loss: 2.299753189086914
Validation loss: 2.4610090050646054

Epoch: 6| Step: 7
Training loss: 2.8165552616119385
Validation loss: 2.456972478538431

Epoch: 6| Step: 8
Training loss: 2.5836644172668457
Validation loss: 2.4616225432324153

Epoch: 6| Step: 9
Training loss: 2.993645191192627
Validation loss: 2.4666177739379225

Epoch: 6| Step: 10
Training loss: 1.9489684104919434
Validation loss: 2.463786530238326

Epoch: 6| Step: 11
Training loss: 2.6257801055908203
Validation loss: 2.4742071141478834

Epoch: 6| Step: 12
Training loss: 1.9537849426269531
Validation loss: 2.4856360445740404

Epoch: 6| Step: 13
Training loss: 3.055008888244629
Validation loss: 2.4895964899370746

Epoch: 125| Step: 0
Training loss: 3.515885829925537
Validation loss: 2.4876873185557704

Epoch: 6| Step: 1
Training loss: 1.7885627746582031
Validation loss: 2.477998182337771

Epoch: 6| Step: 2
Training loss: 2.9233500957489014
Validation loss: 2.4644207262223765

Epoch: 6| Step: 3
Training loss: 2.074566125869751
Validation loss: 2.4630414926877586

Epoch: 6| Step: 4
Training loss: 2.7886362075805664
Validation loss: 2.4633676211039224

Epoch: 6| Step: 5
Training loss: 2.7381253242492676
Validation loss: 2.4677974344581686

Epoch: 6| Step: 6
Training loss: 2.869328498840332
Validation loss: 2.4735411879836873

Epoch: 6| Step: 7
Training loss: 3.070525646209717
Validation loss: 2.474955571595059

Epoch: 6| Step: 8
Training loss: 2.6315112113952637
Validation loss: 2.4745461274218816

Epoch: 6| Step: 9
Training loss: 2.9716410636901855
Validation loss: 2.473190633199548

Epoch: 6| Step: 10
Training loss: 2.8001585006713867
Validation loss: 2.472676936016288

Epoch: 6| Step: 11
Training loss: 2.071376323699951
Validation loss: 2.4759453009533625

Epoch: 6| Step: 12
Training loss: 2.909008026123047
Validation loss: 2.474108249910416

Epoch: 6| Step: 13
Training loss: 1.897026538848877
Validation loss: 2.480085749779978

Epoch: 126| Step: 0
Training loss: 3.0604681968688965
Validation loss: 2.473732275347556

Epoch: 6| Step: 1
Training loss: 2.7686586380004883
Validation loss: 2.4770391474487963

Epoch: 6| Step: 2
Training loss: 2.599792003631592
Validation loss: 2.4716026911171536

Epoch: 6| Step: 3
Training loss: 2.861063003540039
Validation loss: 2.4765824066695346

Epoch: 6| Step: 4
Training loss: 2.9424595832824707
Validation loss: 2.4761112043934483

Epoch: 6| Step: 5
Training loss: 2.460753917694092
Validation loss: 2.4799114247804046

Epoch: 6| Step: 6
Training loss: 2.56298828125
Validation loss: 2.478689762853807

Epoch: 6| Step: 7
Training loss: 2.147953987121582
Validation loss: 2.4859663927426903

Epoch: 6| Step: 8
Training loss: 3.281550884246826
Validation loss: 2.4882820549831597

Epoch: 6| Step: 9
Training loss: 2.767133951187134
Validation loss: 2.4877618102617163

Epoch: 6| Step: 10
Training loss: 2.177428722381592
Validation loss: 2.4968466322909117

Epoch: 6| Step: 11
Training loss: 2.2188057899475098
Validation loss: 2.4842938171919955

Epoch: 6| Step: 12
Training loss: 2.899700164794922
Validation loss: 2.473254995961343

Epoch: 6| Step: 13
Training loss: 2.4511523246765137
Validation loss: 2.4719098127016457

Epoch: 127| Step: 0
Training loss: 2.706164836883545
Validation loss: 2.461581822364561

Epoch: 6| Step: 1
Training loss: 2.1672005653381348
Validation loss: 2.471999309396231

Epoch: 6| Step: 2
Training loss: 3.5510072708129883
Validation loss: 2.4722399942336546

Epoch: 6| Step: 3
Training loss: 2.6230907440185547
Validation loss: 2.4713985740497546

Epoch: 6| Step: 4
Training loss: 3.1658668518066406
Validation loss: 2.4830390022646998

Epoch: 6| Step: 5
Training loss: 2.2236173152923584
Validation loss: 2.4816122106326524

Epoch: 6| Step: 6
Training loss: 2.5165443420410156
Validation loss: 2.4876711342924382

Epoch: 6| Step: 7
Training loss: 2.9433672428131104
Validation loss: 2.48427983765961

Epoch: 6| Step: 8
Training loss: 2.3242526054382324
Validation loss: 2.4739790808769966

Epoch: 6| Step: 9
Training loss: 2.6548287868499756
Validation loss: 2.4672036504232757

Epoch: 6| Step: 10
Training loss: 2.3935515880584717
Validation loss: 2.461673382789858

Epoch: 6| Step: 11
Training loss: 2.944049119949341
Validation loss: 2.4558074192334245

Epoch: 6| Step: 12
Training loss: 2.7216527462005615
Validation loss: 2.4546066766144126

Epoch: 6| Step: 13
Training loss: 2.4312779903411865
Validation loss: 2.449337297870267

Epoch: 128| Step: 0
Training loss: 2.0661580562591553
Validation loss: 2.4498575759190384

Epoch: 6| Step: 1
Training loss: 2.5592103004455566
Validation loss: 2.46382600004955

Epoch: 6| Step: 2
Training loss: 1.8256105184555054
Validation loss: 2.4733335561649774

Epoch: 6| Step: 3
Training loss: 3.024695873260498
Validation loss: 2.472198965728924

Epoch: 6| Step: 4
Training loss: 3.2079885005950928
Validation loss: 2.503477373430806

Epoch: 6| Step: 5
Training loss: 2.7673959732055664
Validation loss: 2.485179566567944

Epoch: 6| Step: 6
Training loss: 2.357504367828369
Validation loss: 2.4989662247319377

Epoch: 6| Step: 7
Training loss: 2.9075868129730225
Validation loss: 2.4849539661920197

Epoch: 6| Step: 8
Training loss: 3.3642587661743164
Validation loss: 2.4798557271239576

Epoch: 6| Step: 9
Training loss: 3.2337872982025146
Validation loss: 2.4693732056566464

Epoch: 6| Step: 10
Training loss: 3.407491683959961
Validation loss: 2.453460790777719

Epoch: 6| Step: 11
Training loss: 2.3916187286376953
Validation loss: 2.4466230356565086

Epoch: 6| Step: 12
Training loss: 2.299013614654541
Validation loss: 2.4434578546913723

Epoch: 6| Step: 13
Training loss: 1.3794586658477783
Validation loss: 2.4476760741203063

Epoch: 129| Step: 0
Training loss: 1.748496174812317
Validation loss: 2.4462485031415055

Epoch: 6| Step: 1
Training loss: 2.431581497192383
Validation loss: 2.444519181405344

Epoch: 6| Step: 2
Training loss: 2.165095806121826
Validation loss: 2.448074920203096

Epoch: 6| Step: 3
Training loss: 2.7094037532806396
Validation loss: 2.4496501440642984

Epoch: 6| Step: 4
Training loss: 2.486818313598633
Validation loss: 2.4486706538866927

Epoch: 6| Step: 5
Training loss: 2.5658459663391113
Validation loss: 2.449473432315293

Epoch: 6| Step: 6
Training loss: 2.5877866744995117
Validation loss: 2.4505471234680503

Epoch: 6| Step: 7
Training loss: 3.3375160694122314
Validation loss: 2.4473383695848527

Epoch: 6| Step: 8
Training loss: 2.5088186264038086
Validation loss: 2.4468845910923456

Epoch: 6| Step: 9
Training loss: 2.955066680908203
Validation loss: 2.4496928902082544

Epoch: 6| Step: 10
Training loss: 2.6421360969543457
Validation loss: 2.4474765946788173

Epoch: 6| Step: 11
Training loss: 3.1954360008239746
Validation loss: 2.4529065265450427

Epoch: 6| Step: 12
Training loss: 2.598250389099121
Validation loss: 2.466742541200371

Epoch: 6| Step: 13
Training loss: 3.838162660598755
Validation loss: 2.4652874418484267

Epoch: 130| Step: 0
Training loss: 2.8215537071228027
Validation loss: 2.447783318899011

Epoch: 6| Step: 1
Training loss: 2.9472293853759766
Validation loss: 2.4507684041095037

Epoch: 6| Step: 2
Training loss: 3.4891786575317383
Validation loss: 2.449890331555438

Epoch: 6| Step: 3
Training loss: 3.0284528732299805
Validation loss: 2.4630495399557133

Epoch: 6| Step: 4
Training loss: 2.2239294052124023
Validation loss: 2.4671307225381174

Epoch: 6| Step: 5
Training loss: 2.303931713104248
Validation loss: 2.4682501259670464

Epoch: 6| Step: 6
Training loss: 2.807796001434326
Validation loss: 2.465656142080984

Epoch: 6| Step: 7
Training loss: 2.0038697719573975
Validation loss: 2.4595892224260556

Epoch: 6| Step: 8
Training loss: 2.5108370780944824
Validation loss: 2.4556361526571293

Epoch: 6| Step: 9
Training loss: 1.8806822299957275
Validation loss: 2.458620097047539

Epoch: 6| Step: 10
Training loss: 3.02274227142334
Validation loss: 2.458079602128716

Epoch: 6| Step: 11
Training loss: 2.521230697631836
Validation loss: 2.4553551032979

Epoch: 6| Step: 12
Training loss: 3.2246828079223633
Validation loss: 2.453889436619256

Epoch: 6| Step: 13
Training loss: 2.333768367767334
Validation loss: 2.4548762382999545

Epoch: 131| Step: 0
Training loss: 2.088637351989746
Validation loss: 2.4534697455744587

Epoch: 6| Step: 1
Training loss: 2.535186290740967
Validation loss: 2.457259903671921

Epoch: 6| Step: 2
Training loss: 1.9049384593963623
Validation loss: 2.4567781750873854

Epoch: 6| Step: 3
Training loss: 3.0221245288848877
Validation loss: 2.454859782290715

Epoch: 6| Step: 4
Training loss: 2.7243733406066895
Validation loss: 2.450214329586234

Epoch: 6| Step: 5
Training loss: 2.6008026599884033
Validation loss: 2.4485734893429663

Epoch: 6| Step: 6
Training loss: 2.6898033618927
Validation loss: 2.450706369133406

Epoch: 6| Step: 7
Training loss: 2.5936875343322754
Validation loss: 2.4542467132691415

Epoch: 6| Step: 8
Training loss: 3.660799980163574
Validation loss: 2.460659195018071

Epoch: 6| Step: 9
Training loss: 3.2572312355041504
Validation loss: 2.4715302477600756

Epoch: 6| Step: 10
Training loss: 2.217252731323242
Validation loss: 2.486293210778185

Epoch: 6| Step: 11
Training loss: 2.7992944717407227
Validation loss: 2.4837566908969673

Epoch: 6| Step: 12
Training loss: 3.1183762550354004
Validation loss: 2.487521502279466

Epoch: 6| Step: 13
Training loss: 1.6894497871398926
Validation loss: 2.491019570699302

Epoch: 132| Step: 0
Training loss: 3.2124080657958984
Validation loss: 2.501295038448867

Epoch: 6| Step: 1
Training loss: 2.4529778957366943
Validation loss: 2.505535271859938

Epoch: 6| Step: 2
Training loss: 2.762610912322998
Validation loss: 2.5043075828142065

Epoch: 6| Step: 3
Training loss: 2.8310940265655518
Validation loss: 2.5026956066008537

Epoch: 6| Step: 4
Training loss: 2.838711977005005
Validation loss: 2.489504491129229

Epoch: 6| Step: 5
Training loss: 2.5348567962646484
Validation loss: 2.4869534969329834

Epoch: 6| Step: 6
Training loss: 2.5200772285461426
Validation loss: 2.4614339105544554

Epoch: 6| Step: 7
Training loss: 2.5311827659606934
Validation loss: 2.4463120993747505

Epoch: 6| Step: 8
Training loss: 2.758415460586548
Validation loss: 2.443012019639374

Epoch: 6| Step: 9
Training loss: 2.497142791748047
Validation loss: 2.437218217439549

Epoch: 6| Step: 10
Training loss: 2.8037185668945312
Validation loss: 2.4422580862558014

Epoch: 6| Step: 11
Training loss: 2.7431721687316895
Validation loss: 2.4468158470687045

Epoch: 6| Step: 12
Training loss: 2.0174808502197266
Validation loss: 2.4510688397192184

Epoch: 6| Step: 13
Training loss: 2.9009406566619873
Validation loss: 2.455840710670717

Epoch: 133| Step: 0
Training loss: 2.2735023498535156
Validation loss: 2.4565061343613492

Epoch: 6| Step: 1
Training loss: 2.673466205596924
Validation loss: 2.4590227296275478

Epoch: 6| Step: 2
Training loss: 2.5470166206359863
Validation loss: 2.456181323656472

Epoch: 6| Step: 3
Training loss: 2.8026490211486816
Validation loss: 2.4532943387185373

Epoch: 6| Step: 4
Training loss: 2.0796327590942383
Validation loss: 2.4468808789407053

Epoch: 6| Step: 5
Training loss: 2.9803884029388428
Validation loss: 2.4445357015055995

Epoch: 6| Step: 6
Training loss: 3.482067108154297
Validation loss: 2.441353469766596

Epoch: 6| Step: 7
Training loss: 2.2349085807800293
Validation loss: 2.4424124353675434

Epoch: 6| Step: 8
Training loss: 2.2871265411376953
Validation loss: 2.4347849251121603

Epoch: 6| Step: 9
Training loss: 2.1217617988586426
Validation loss: 2.44197521158444

Epoch: 6| Step: 10
Training loss: 3.275909662246704
Validation loss: 2.449485748044906

Epoch: 6| Step: 11
Training loss: 3.366584062576294
Validation loss: 2.462105425455237

Epoch: 6| Step: 12
Training loss: 2.75201153755188
Validation loss: 2.468696968529814

Epoch: 6| Step: 13
Training loss: 2.189241409301758
Validation loss: 2.4740315611644457

Epoch: 134| Step: 0
Training loss: 2.697112560272217
Validation loss: 2.477277760864586

Epoch: 6| Step: 1
Training loss: 2.5851755142211914
Validation loss: 2.4740326250753095

Epoch: 6| Step: 2
Training loss: 2.723644256591797
Validation loss: 2.484168683328936

Epoch: 6| Step: 3
Training loss: 2.2898683547973633
Validation loss: 2.4879277521564114

Epoch: 6| Step: 4
Training loss: 3.588092803955078
Validation loss: 2.4767710111474477

Epoch: 6| Step: 5
Training loss: 2.953789710998535
Validation loss: 2.4619956016540527

Epoch: 6| Step: 6
Training loss: 2.8181302547454834
Validation loss: 2.4611602598621

Epoch: 6| Step: 7
Training loss: 2.4763453006744385
Validation loss: 2.4629871050516763

Epoch: 6| Step: 8
Training loss: 3.398350954055786
Validation loss: 2.4605372387875795

Epoch: 6| Step: 9
Training loss: 2.0862960815429688
Validation loss: 2.4541853961124214

Epoch: 6| Step: 10
Training loss: 2.655302047729492
Validation loss: 2.4443479340563536

Epoch: 6| Step: 11
Training loss: 2.4116601943969727
Validation loss: 2.4413752145664667

Epoch: 6| Step: 12
Training loss: 1.848901391029358
Validation loss: 2.439752810744829

Epoch: 6| Step: 13
Training loss: 2.5966944694519043
Validation loss: 2.438823284641389

Epoch: 135| Step: 0
Training loss: 3.3484344482421875
Validation loss: 2.441127332307959

Epoch: 6| Step: 1
Training loss: 2.104487657546997
Validation loss: 2.436194322442496

Epoch: 6| Step: 2
Training loss: 2.733799934387207
Validation loss: 2.436375520562613

Epoch: 6| Step: 3
Training loss: 2.265030860900879
Validation loss: 2.438568271616454

Epoch: 6| Step: 4
Training loss: 3.731602668762207
Validation loss: 2.4401875413874143

Epoch: 6| Step: 5
Training loss: 2.3709776401519775
Validation loss: 2.4356685633300454

Epoch: 6| Step: 6
Training loss: 3.3840880393981934
Validation loss: 2.4386584784394953

Epoch: 6| Step: 7
Training loss: 2.535447359085083
Validation loss: 2.442159104090865

Epoch: 6| Step: 8
Training loss: 2.6191091537475586
Validation loss: 2.440915846055554

Epoch: 6| Step: 9
Training loss: 2.151848793029785
Validation loss: 2.4384762292267173

Epoch: 6| Step: 10
Training loss: 2.3592288494110107
Validation loss: 2.436229669919578

Epoch: 6| Step: 11
Training loss: 2.484419822692871
Validation loss: 2.440671584939444

Epoch: 6| Step: 12
Training loss: 2.4829049110412598
Validation loss: 2.4435594748425227

Epoch: 6| Step: 13
Training loss: 2.3719701766967773
Validation loss: 2.4457378874542894

Epoch: 136| Step: 0
Training loss: 3.2197439670562744
Validation loss: 2.453565247597233

Epoch: 6| Step: 1
Training loss: 2.1920907497406006
Validation loss: 2.448654597805392

Epoch: 6| Step: 2
Training loss: 2.176405429840088
Validation loss: 2.455861314650505

Epoch: 6| Step: 3
Training loss: 2.390821933746338
Validation loss: 2.4553865822412635

Epoch: 6| Step: 4
Training loss: 2.626060724258423
Validation loss: 2.457685875636275

Epoch: 6| Step: 5
Training loss: 3.1845712661743164
Validation loss: 2.448603081446822

Epoch: 6| Step: 6
Training loss: 2.2803239822387695
Validation loss: 2.4471626127919843

Epoch: 6| Step: 7
Training loss: 3.6092519760131836
Validation loss: 2.4566232235200944

Epoch: 6| Step: 8
Training loss: 2.1197943687438965
Validation loss: 2.4627940577845417

Epoch: 6| Step: 9
Training loss: 2.948385715484619
Validation loss: 2.4792735640720656

Epoch: 6| Step: 10
Training loss: 3.1539487838745117
Validation loss: 2.490537502432382

Epoch: 6| Step: 11
Training loss: 2.6333227157592773
Validation loss: 2.4823522388294177

Epoch: 6| Step: 12
Training loss: 2.384531259536743
Validation loss: 2.474135847501857

Epoch: 6| Step: 13
Training loss: 1.7969377040863037
Validation loss: 2.449078231729487

Epoch: 137| Step: 0
Training loss: 2.956754684448242
Validation loss: 2.444851863768793

Epoch: 6| Step: 1
Training loss: 2.804185628890991
Validation loss: 2.435291205683062

Epoch: 6| Step: 2
Training loss: 2.1172776222229004
Validation loss: 2.4368091706306703

Epoch: 6| Step: 3
Training loss: 1.7852116823196411
Validation loss: 2.436831294849355

Epoch: 6| Step: 4
Training loss: 3.0553908348083496
Validation loss: 2.4377713434157835

Epoch: 6| Step: 5
Training loss: 3.2040648460388184
Validation loss: 2.4367169769861365

Epoch: 6| Step: 6
Training loss: 2.2744483947753906
Validation loss: 2.434416445352698

Epoch: 6| Step: 7
Training loss: 3.1915459632873535
Validation loss: 2.4351988197654806

Epoch: 6| Step: 8
Training loss: 2.48575758934021
Validation loss: 2.4299299832313292

Epoch: 6| Step: 9
Training loss: 2.866481304168701
Validation loss: 2.435268517463438

Epoch: 6| Step: 10
Training loss: 2.624056339263916
Validation loss: 2.4346231388789352

Epoch: 6| Step: 11
Training loss: 2.268004894256592
Validation loss: 2.4341389594539518

Epoch: 6| Step: 12
Training loss: 2.799063205718994
Validation loss: 2.434563559870566

Epoch: 6| Step: 13
Training loss: 2.6467623710632324
Validation loss: 2.44270525568275

Epoch: 138| Step: 0
Training loss: 3.589616060256958
Validation loss: 2.4411296665027575

Epoch: 6| Step: 1
Training loss: 2.604897975921631
Validation loss: 2.4420150556871967

Epoch: 6| Step: 2
Training loss: 2.7073307037353516
Validation loss: 2.44633545414094

Epoch: 6| Step: 3
Training loss: 2.315605640411377
Validation loss: 2.4584272984535462

Epoch: 6| Step: 4
Training loss: 2.5409128665924072
Validation loss: 2.4564213829655803

Epoch: 6| Step: 5
Training loss: 2.9266085624694824
Validation loss: 2.453432700967276

Epoch: 6| Step: 6
Training loss: 3.0022315979003906
Validation loss: 2.4492979075319026

Epoch: 6| Step: 7
Training loss: 2.8729186058044434
Validation loss: 2.4461287606147026

Epoch: 6| Step: 8
Training loss: 2.072923421859741
Validation loss: 2.4468885467898462

Epoch: 6| Step: 9
Training loss: 2.0611801147460938
Validation loss: 2.4357087227606002

Epoch: 6| Step: 10
Training loss: 2.6430225372314453
Validation loss: 2.4349829125147995

Epoch: 6| Step: 11
Training loss: 2.7269668579101562
Validation loss: 2.4357694400254117

Epoch: 6| Step: 12
Training loss: 2.42956280708313
Validation loss: 2.4339801983166764

Epoch: 6| Step: 13
Training loss: 2.457350969314575
Validation loss: 2.4319975991402902

Epoch: 139| Step: 0
Training loss: 2.2679522037506104
Validation loss: 2.4306550307940413

Epoch: 6| Step: 1
Training loss: 2.165785074234009
Validation loss: 2.432100034529163

Epoch: 6| Step: 2
Training loss: 2.5684847831726074
Validation loss: 2.4370706747936945

Epoch: 6| Step: 3
Training loss: 2.574554920196533
Validation loss: 2.4369359452237367

Epoch: 6| Step: 4
Training loss: 2.7430262565612793
Validation loss: 2.43543904571123

Epoch: 6| Step: 5
Training loss: 3.1257948875427246
Validation loss: 2.4343036682375017

Epoch: 6| Step: 6
Training loss: 2.2853617668151855
Validation loss: 2.4354047749632146

Epoch: 6| Step: 7
Training loss: 3.0555419921875
Validation loss: 2.431406577428182

Epoch: 6| Step: 8
Training loss: 2.6531858444213867
Validation loss: 2.4338847488485356

Epoch: 6| Step: 9
Training loss: 3.429725170135498
Validation loss: 2.4363712700464393

Epoch: 6| Step: 10
Training loss: 2.5977981090545654
Validation loss: 2.433401302624774

Epoch: 6| Step: 11
Training loss: 2.2215769290924072
Validation loss: 2.438933595534294

Epoch: 6| Step: 12
Training loss: 2.7419328689575195
Validation loss: 2.439809404393678

Epoch: 6| Step: 13
Training loss: 2.531446695327759
Validation loss: 2.4465357385655886

Epoch: 140| Step: 0
Training loss: 2.8871240615844727
Validation loss: 2.4398773485614407

Epoch: 6| Step: 1
Training loss: 3.0411503314971924
Validation loss: 2.440737585867605

Epoch: 6| Step: 2
Training loss: 1.8913612365722656
Validation loss: 2.4376678543706096

Epoch: 6| Step: 3
Training loss: 2.831632614135742
Validation loss: 2.440690786607804

Epoch: 6| Step: 4
Training loss: 2.9981021881103516
Validation loss: 2.437489689037364

Epoch: 6| Step: 5
Training loss: 2.815103530883789
Validation loss: 2.434669997102471

Epoch: 6| Step: 6
Training loss: 2.405498504638672
Validation loss: 2.4337739098456597

Epoch: 6| Step: 7
Training loss: 2.510967254638672
Validation loss: 2.4347448605363087

Epoch: 6| Step: 8
Training loss: 2.255052089691162
Validation loss: 2.434032635022235

Epoch: 6| Step: 9
Training loss: 2.8738973140716553
Validation loss: 2.4294072607512116

Epoch: 6| Step: 10
Training loss: 3.5299575328826904
Validation loss: 2.4318958610616703

Epoch: 6| Step: 11
Training loss: 2.0911407470703125
Validation loss: 2.4351032318607455

Epoch: 6| Step: 12
Training loss: 2.238276481628418
Validation loss: 2.433310695873794

Epoch: 6| Step: 13
Training loss: 2.613358497619629
Validation loss: 2.4357841963409097

Epoch: 141| Step: 0
Training loss: 2.506938934326172
Validation loss: 2.433370039027224

Epoch: 6| Step: 1
Training loss: 2.461728572845459
Validation loss: 2.4405610048642723

Epoch: 6| Step: 2
Training loss: 2.688356876373291
Validation loss: 2.4451087700423373

Epoch: 6| Step: 3
Training loss: 3.4399280548095703
Validation loss: 2.440594527029222

Epoch: 6| Step: 4
Training loss: 2.6183581352233887
Validation loss: 2.442177826358426

Epoch: 6| Step: 5
Training loss: 2.3615798950195312
Validation loss: 2.4339521725972495

Epoch: 6| Step: 6
Training loss: 2.3505301475524902
Validation loss: 2.437136685976418

Epoch: 6| Step: 7
Training loss: 2.9530980587005615
Validation loss: 2.432127724411667

Epoch: 6| Step: 8
Training loss: 2.8217196464538574
Validation loss: 2.4400849188527753

Epoch: 6| Step: 9
Training loss: 2.1405186653137207
Validation loss: 2.437979475144417

Epoch: 6| Step: 10
Training loss: 3.4394633769989014
Validation loss: 2.4328198074012675

Epoch: 6| Step: 11
Training loss: 1.6483821868896484
Validation loss: 2.432630544067711

Epoch: 6| Step: 12
Training loss: 2.9867820739746094
Validation loss: 2.4302397825384654

Epoch: 6| Step: 13
Training loss: 2.4763095378875732
Validation loss: 2.429975160988428

Epoch: 142| Step: 0
Training loss: 2.7490861415863037
Validation loss: 2.4306343165777062

Epoch: 6| Step: 1
Training loss: 3.190805435180664
Validation loss: 2.42898831828948

Epoch: 6| Step: 2
Training loss: 2.8665618896484375
Validation loss: 2.4298432924414195

Epoch: 6| Step: 3
Training loss: 2.1116104125976562
Validation loss: 2.4290801684061685

Epoch: 6| Step: 4
Training loss: 3.2968497276306152
Validation loss: 2.434609679765599

Epoch: 6| Step: 5
Training loss: 2.463265895843506
Validation loss: 2.4382467167351836

Epoch: 6| Step: 6
Training loss: 2.855936050415039
Validation loss: 2.441202663606213

Epoch: 6| Step: 7
Training loss: 2.6998350620269775
Validation loss: 2.4308880349641204

Epoch: 6| Step: 8
Training loss: 2.5286431312561035
Validation loss: 2.4304998587536555

Epoch: 6| Step: 9
Training loss: 2.3672289848327637
Validation loss: 2.443641121669482

Epoch: 6| Step: 10
Training loss: 2.0570857524871826
Validation loss: 2.4469189848951114

Epoch: 6| Step: 11
Training loss: 2.380702495574951
Validation loss: 2.442086619715537

Epoch: 6| Step: 12
Training loss: 3.2005717754364014
Validation loss: 2.4443044662475586

Epoch: 6| Step: 13
Training loss: 1.9576358795166016
Validation loss: 2.4416622859175487

Epoch: 143| Step: 0
Training loss: 2.856257438659668
Validation loss: 2.437052721618324

Epoch: 6| Step: 1
Training loss: 3.0339808464050293
Validation loss: 2.4273963794913342

Epoch: 6| Step: 2
Training loss: 2.673600435256958
Validation loss: 2.426015838499992

Epoch: 6| Step: 3
Training loss: 2.916931390762329
Validation loss: 2.418734485103238

Epoch: 6| Step: 4
Training loss: 3.271116256713867
Validation loss: 2.42035255124492

Epoch: 6| Step: 5
Training loss: 2.5988943576812744
Validation loss: 2.420175503658992

Epoch: 6| Step: 6
Training loss: 2.9721765518188477
Validation loss: 2.418931104803598

Epoch: 6| Step: 7
Training loss: 2.632540702819824
Validation loss: 2.4205856477060625

Epoch: 6| Step: 8
Training loss: 3.267971992492676
Validation loss: 2.4204809281133834

Epoch: 6| Step: 9
Training loss: 2.228318691253662
Validation loss: 2.4204759008140972

Epoch: 6| Step: 10
Training loss: 1.7406868934631348
Validation loss: 2.4213295008546565

Epoch: 6| Step: 11
Training loss: 2.34969425201416
Validation loss: 2.4217554369280414

Epoch: 6| Step: 12
Training loss: 1.9865665435791016
Validation loss: 2.4215920253466536

Epoch: 6| Step: 13
Training loss: 2.2445428371429443
Validation loss: 2.429382598528298

Epoch: 144| Step: 0
Training loss: 2.3051369190216064
Validation loss: 2.4282659433221303

Epoch: 6| Step: 1
Training loss: 2.4376869201660156
Validation loss: 2.426093396320138

Epoch: 6| Step: 2
Training loss: 3.088069438934326
Validation loss: 2.4365185409463863

Epoch: 6| Step: 3
Training loss: 2.865816593170166
Validation loss: 2.4471055717878443

Epoch: 6| Step: 4
Training loss: 2.3382909297943115
Validation loss: 2.4510892514259583

Epoch: 6| Step: 5
Training loss: 2.6398603916168213
Validation loss: 2.446645095784177

Epoch: 6| Step: 6
Training loss: 3.1095404624938965
Validation loss: 2.4391395481683875

Epoch: 6| Step: 7
Training loss: 2.8100223541259766
Validation loss: 2.4399372326430453

Epoch: 6| Step: 8
Training loss: 2.284377336502075
Validation loss: 2.4355220948496172

Epoch: 6| Step: 9
Training loss: 3.0990262031555176
Validation loss: 2.4355467083633586

Epoch: 6| Step: 10
Training loss: 2.2960853576660156
Validation loss: 2.430499053770496

Epoch: 6| Step: 11
Training loss: 2.3333160877227783
Validation loss: 2.4269139279601393

Epoch: 6| Step: 12
Training loss: 2.1913094520568848
Validation loss: 2.4290516863587084

Epoch: 6| Step: 13
Training loss: 3.5676662921905518
Validation loss: 2.4250710420711066

Epoch: 145| Step: 0
Training loss: 2.2257962226867676
Validation loss: 2.4301407516643567

Epoch: 6| Step: 1
Training loss: 2.9039244651794434
Validation loss: 2.426327477219284

Epoch: 6| Step: 2
Training loss: 3.1414225101470947
Validation loss: 2.4305130409938034

Epoch: 6| Step: 3
Training loss: 2.7088189125061035
Validation loss: 2.4314730346843763

Epoch: 6| Step: 4
Training loss: 3.0614657402038574
Validation loss: 2.435836092118294

Epoch: 6| Step: 5
Training loss: 2.8080430030822754
Validation loss: 2.435147408516176

Epoch: 6| Step: 6
Training loss: 2.3231873512268066
Validation loss: 2.447068629726287

Epoch: 6| Step: 7
Training loss: 3.0678939819335938
Validation loss: 2.445668794775522

Epoch: 6| Step: 8
Training loss: 2.2505009174346924
Validation loss: 2.4422922749673166

Epoch: 6| Step: 9
Training loss: 2.3622214794158936
Validation loss: 2.4460094564704487

Epoch: 6| Step: 10
Training loss: 2.6101222038269043
Validation loss: 2.4509102272731003

Epoch: 6| Step: 11
Training loss: 2.591096878051758
Validation loss: 2.4473557433774396

Epoch: 6| Step: 12
Training loss: 2.247570514678955
Validation loss: 2.450835843240061

Epoch: 6| Step: 13
Training loss: 2.656399965286255
Validation loss: 2.44195713919978

Epoch: 146| Step: 0
Training loss: 2.295867681503296
Validation loss: 2.433956000112718

Epoch: 6| Step: 1
Training loss: 2.1019740104675293
Validation loss: 2.4335984914533553

Epoch: 6| Step: 2
Training loss: 2.6797237396240234
Validation loss: 2.425649557062375

Epoch: 6| Step: 3
Training loss: 3.078803062438965
Validation loss: 2.424934697407548

Epoch: 6| Step: 4
Training loss: 2.7211740016937256
Validation loss: 2.420959967438893

Epoch: 6| Step: 5
Training loss: 2.4578921794891357
Validation loss: 2.421119523304765

Epoch: 6| Step: 6
Training loss: 3.1607842445373535
Validation loss: 2.422958266350531

Epoch: 6| Step: 7
Training loss: 2.582432985305786
Validation loss: 2.425137681345786

Epoch: 6| Step: 8
Training loss: 2.2709784507751465
Validation loss: 2.424146822703782

Epoch: 6| Step: 9
Training loss: 3.760697364807129
Validation loss: 2.425626862433649

Epoch: 6| Step: 10
Training loss: 2.293579339981079
Validation loss: 2.423119391164472

Epoch: 6| Step: 11
Training loss: 2.6253573894500732
Validation loss: 2.432732351364628

Epoch: 6| Step: 12
Training loss: 2.303128719329834
Validation loss: 2.4393733445034234

Epoch: 6| Step: 13
Training loss: 2.515376091003418
Validation loss: 2.4361508943701304

Epoch: 147| Step: 0
Training loss: 2.519382953643799
Validation loss: 2.4386504029714935

Epoch: 6| Step: 1
Training loss: 2.6724226474761963
Validation loss: 2.4319724882802656

Epoch: 6| Step: 2
Training loss: 2.13936710357666
Validation loss: 2.4308561048200055

Epoch: 6| Step: 3
Training loss: 1.750550627708435
Validation loss: 2.4241807396693895

Epoch: 6| Step: 4
Training loss: 3.027050256729126
Validation loss: 2.430217973647579

Epoch: 6| Step: 5
Training loss: 2.342043876647949
Validation loss: 2.42238720258077

Epoch: 6| Step: 6
Training loss: 2.637505531311035
Validation loss: 2.4260203094892603

Epoch: 6| Step: 7
Training loss: 3.1166958808898926
Validation loss: 2.428045544573056

Epoch: 6| Step: 8
Training loss: 2.319519519805908
Validation loss: 2.4346919777572795

Epoch: 6| Step: 9
Training loss: 3.235013961791992
Validation loss: 2.4338992705909153

Epoch: 6| Step: 10
Training loss: 2.797199010848999
Validation loss: 2.4311498365094586

Epoch: 6| Step: 11
Training loss: 2.7275266647338867
Validation loss: 2.4325873979958157

Epoch: 6| Step: 12
Training loss: 2.8246920108795166
Validation loss: 2.4229406823394117

Epoch: 6| Step: 13
Training loss: 2.82076096534729
Validation loss: 2.419408325226076

Epoch: 148| Step: 0
Training loss: 1.590128779411316
Validation loss: 2.4204081976285545

Epoch: 6| Step: 1
Training loss: 1.91666579246521
Validation loss: 2.4163842149960097

Epoch: 6| Step: 2
Training loss: 3.0938799381256104
Validation loss: 2.4243287886342695

Epoch: 6| Step: 3
Training loss: 2.3675131797790527
Validation loss: 2.4244438063713813

Epoch: 6| Step: 4
Training loss: 2.656782627105713
Validation loss: 2.4220681241763535

Epoch: 6| Step: 5
Training loss: 2.678891181945801
Validation loss: 2.4267681285899174

Epoch: 6| Step: 6
Training loss: 2.829277992248535
Validation loss: 2.4242042700449624

Epoch: 6| Step: 7
Training loss: 3.0851457118988037
Validation loss: 2.4287545655363347

Epoch: 6| Step: 8
Training loss: 2.421322822570801
Validation loss: 2.4293700007982153

Epoch: 6| Step: 9
Training loss: 2.1035661697387695
Validation loss: 2.4312626495156238

Epoch: 6| Step: 10
Training loss: 3.90151309967041
Validation loss: 2.42754348375464

Epoch: 6| Step: 11
Training loss: 2.8230957984924316
Validation loss: 2.4328099732757895

Epoch: 6| Step: 12
Training loss: 3.2195897102355957
Validation loss: 2.427490060047437

Epoch: 6| Step: 13
Training loss: 1.5889695882797241
Validation loss: 2.4260739382877143

Epoch: 149| Step: 0
Training loss: 2.8304409980773926
Validation loss: 2.4430651536551853

Epoch: 6| Step: 1
Training loss: 2.675417423248291
Validation loss: 2.4444563709279543

Epoch: 6| Step: 2
Training loss: 2.104621171951294
Validation loss: 2.4361414909362793

Epoch: 6| Step: 3
Training loss: 2.9614787101745605
Validation loss: 2.44425271659769

Epoch: 6| Step: 4
Training loss: 2.479246139526367
Validation loss: 2.439859285149523

Epoch: 6| Step: 5
Training loss: 1.6271085739135742
Validation loss: 2.4371246496836343

Epoch: 6| Step: 6
Training loss: 2.521974563598633
Validation loss: 2.4323916819787796

Epoch: 6| Step: 7
Training loss: 2.8000435829162598
Validation loss: 2.430962126742127

Epoch: 6| Step: 8
Training loss: 2.9990525245666504
Validation loss: 2.430039164840534

Epoch: 6| Step: 9
Training loss: 2.5938587188720703
Validation loss: 2.432861097397343

Epoch: 6| Step: 10
Training loss: 2.342693328857422
Validation loss: 2.4324024774694957

Epoch: 6| Step: 11
Training loss: 3.0692548751831055
Validation loss: 2.430701614708029

Epoch: 6| Step: 12
Training loss: 2.342726230621338
Validation loss: 2.4301133566005255

Epoch: 6| Step: 13
Training loss: 4.196665287017822
Validation loss: 2.4196266692171813

Epoch: 150| Step: 0
Training loss: 2.5727808475494385
Validation loss: 2.4151035406256236

Epoch: 6| Step: 1
Training loss: 2.9169154167175293
Validation loss: 2.4165947386013564

Epoch: 6| Step: 2
Training loss: 3.153031349182129
Validation loss: 2.414260551493655

Epoch: 6| Step: 3
Training loss: 1.5894943475723267
Validation loss: 2.4166569325231735

Epoch: 6| Step: 4
Training loss: 2.774498701095581
Validation loss: 2.412036129223403

Epoch: 6| Step: 5
Training loss: 2.533812999725342
Validation loss: 2.4142695703814105

Epoch: 6| Step: 6
Training loss: 2.0374341011047363
Validation loss: 2.429204325522146

Epoch: 6| Step: 7
Training loss: 2.6245410442352295
Validation loss: 2.4329293286928566

Epoch: 6| Step: 8
Training loss: 3.330723762512207
Validation loss: 2.429938654745779

Epoch: 6| Step: 9
Training loss: 2.6690468788146973
Validation loss: 2.4245956431153

Epoch: 6| Step: 10
Training loss: 2.619346857070923
Validation loss: 2.415400584538778

Epoch: 6| Step: 11
Training loss: 2.59220027923584
Validation loss: 2.4138879570909726

Epoch: 6| Step: 12
Training loss: 2.132847309112549
Validation loss: 2.417864073989212

Epoch: 6| Step: 13
Training loss: 3.6953675746917725
Validation loss: 2.427239320611441

Epoch: 151| Step: 0
Training loss: 2.9205610752105713
Validation loss: 2.4386913186760357

Epoch: 6| Step: 1
Training loss: 2.682696580886841
Validation loss: 2.443578317601194

Epoch: 6| Step: 2
Training loss: 1.8137683868408203
Validation loss: 2.453092569945961

Epoch: 6| Step: 3
Training loss: 1.9507076740264893
Validation loss: 2.4556263826226674

Epoch: 6| Step: 4
Training loss: 3.235025405883789
Validation loss: 2.449641348213278

Epoch: 6| Step: 5
Training loss: 2.647355079650879
Validation loss: 2.443560000388853

Epoch: 6| Step: 6
Training loss: 2.9032862186431885
Validation loss: 2.4337894878079815

Epoch: 6| Step: 7
Training loss: 3.0642685890197754
Validation loss: 2.4294573722347135

Epoch: 6| Step: 8
Training loss: 3.4674601554870605
Validation loss: 2.4191397005511868

Epoch: 6| Step: 9
Training loss: 1.6470649242401123
Validation loss: 2.418385395439722

Epoch: 6| Step: 10
Training loss: 2.681529998779297
Validation loss: 2.4139648688736783

Epoch: 6| Step: 11
Training loss: 2.4804630279541016
Validation loss: 2.4110654810423493

Epoch: 6| Step: 12
Training loss: 2.646409034729004
Validation loss: 2.412734946896953

Epoch: 6| Step: 13
Training loss: 2.6382076740264893
Validation loss: 2.4083726944461947

Epoch: 152| Step: 0
Training loss: 2.2011220455169678
Validation loss: 2.417012914534538

Epoch: 6| Step: 1
Training loss: 2.7528676986694336
Validation loss: 2.4139610105945217

Epoch: 6| Step: 2
Training loss: 2.3922061920166016
Validation loss: 2.4147377655070317

Epoch: 6| Step: 3
Training loss: 3.7347607612609863
Validation loss: 2.410571752055999

Epoch: 6| Step: 4
Training loss: 2.7688117027282715
Validation loss: 2.4087620319858676

Epoch: 6| Step: 5
Training loss: 2.2211403846740723
Validation loss: 2.4027334131220335

Epoch: 6| Step: 6
Training loss: 2.6346793174743652
Validation loss: 2.411895659662062

Epoch: 6| Step: 7
Training loss: 2.6887459754943848
Validation loss: 2.403862435330627

Epoch: 6| Step: 8
Training loss: 2.8608951568603516
Validation loss: 2.4135384956995645

Epoch: 6| Step: 9
Training loss: 2.056933641433716
Validation loss: 2.4037587027395926

Epoch: 6| Step: 10
Training loss: 2.2455697059631348
Validation loss: 2.404027049259473

Epoch: 6| Step: 11
Training loss: 2.9155898094177246
Validation loss: 2.4077511064467894

Epoch: 6| Step: 12
Training loss: 3.0330820083618164
Validation loss: 2.4072656170014413

Epoch: 6| Step: 13
Training loss: 2.106018304824829
Validation loss: 2.4106708188210764

Epoch: 153| Step: 0
Training loss: 2.5795669555664062
Validation loss: 2.412174683745189

Epoch: 6| Step: 1
Training loss: 2.936371326446533
Validation loss: 2.4101859138857935

Epoch: 6| Step: 2
Training loss: 2.6423792839050293
Validation loss: 2.4177225533352105

Epoch: 6| Step: 3
Training loss: 2.502537488937378
Validation loss: 2.4081725856309295

Epoch: 6| Step: 4
Training loss: 2.6222832202911377
Validation loss: 2.428312122180898

Epoch: 6| Step: 5
Training loss: 2.195369243621826
Validation loss: 2.4197993586140294

Epoch: 6| Step: 6
Training loss: 2.734822988510132
Validation loss: 2.4179874004856234

Epoch: 6| Step: 7
Training loss: 2.420165538787842
Validation loss: 2.4144173617004068

Epoch: 6| Step: 8
Training loss: 1.8676546812057495
Validation loss: 2.4243488875768517

Epoch: 6| Step: 9
Training loss: 2.8683834075927734
Validation loss: 2.4216221917060112

Epoch: 6| Step: 10
Training loss: 3.107926845550537
Validation loss: 2.410748294604722

Epoch: 6| Step: 11
Training loss: 2.4312806129455566
Validation loss: 2.414220509990569

Epoch: 6| Step: 12
Training loss: 3.125183582305908
Validation loss: 2.4129182292569067

Epoch: 6| Step: 13
Training loss: 2.8901212215423584
Validation loss: 2.4092356107568227

Epoch: 154| Step: 0
Training loss: 1.996941089630127
Validation loss: 2.4070448619063183

Epoch: 6| Step: 1
Training loss: 2.541790008544922
Validation loss: 2.404972848071847

Epoch: 6| Step: 2
Training loss: 3.3070058822631836
Validation loss: 2.405039520673854

Epoch: 6| Step: 3
Training loss: 2.934098720550537
Validation loss: 2.4088388642957135

Epoch: 6| Step: 4
Training loss: 2.408702850341797
Validation loss: 2.405130778589556

Epoch: 6| Step: 5
Training loss: 2.7792091369628906
Validation loss: 2.4166641850625314

Epoch: 6| Step: 6
Training loss: 2.7608156204223633
Validation loss: 2.41554222952935

Epoch: 6| Step: 7
Training loss: 3.0895724296569824
Validation loss: 2.425804171510922

Epoch: 6| Step: 8
Training loss: 2.0630455017089844
Validation loss: 2.4239739141156598

Epoch: 6| Step: 9
Training loss: 2.4975619316101074
Validation loss: 2.4206321957290813

Epoch: 6| Step: 10
Training loss: 2.5967390537261963
Validation loss: 2.4206273632664836

Epoch: 6| Step: 11
Training loss: 2.5118961334228516
Validation loss: 2.408873486262496

Epoch: 6| Step: 12
Training loss: 2.938689947128296
Validation loss: 2.4114356989501626

Epoch: 6| Step: 13
Training loss: 2.082428455352783
Validation loss: 2.4162368338595153

Epoch: 155| Step: 0
Training loss: 2.3922204971313477
Validation loss: 2.423450513552594

Epoch: 6| Step: 1
Training loss: 2.7424869537353516
Validation loss: 2.439022764082878

Epoch: 6| Step: 2
Training loss: 2.282872200012207
Validation loss: 2.4522466839000745

Epoch: 6| Step: 3
Training loss: 2.7947425842285156
Validation loss: 2.4632743456030406

Epoch: 6| Step: 4
Training loss: 2.862891435623169
Validation loss: 2.4514118061270764

Epoch: 6| Step: 5
Training loss: 2.5792412757873535
Validation loss: 2.450041873480684

Epoch: 6| Step: 6
Training loss: 1.6021225452423096
Validation loss: 2.432522637869722

Epoch: 6| Step: 7
Training loss: 2.266720771789551
Validation loss: 2.435997352805189

Epoch: 6| Step: 8
Training loss: 2.8436264991760254
Validation loss: 2.4291598873753704

Epoch: 6| Step: 9
Training loss: 3.7586588859558105
Validation loss: 2.4186071042091615

Epoch: 6| Step: 10
Training loss: 2.7770400047302246
Validation loss: 2.4248041491354666

Epoch: 6| Step: 11
Training loss: 2.6944665908813477
Validation loss: 2.4251134472508586

Epoch: 6| Step: 12
Training loss: 3.21464204788208
Validation loss: 2.4182014478150236

Epoch: 6| Step: 13
Training loss: 1.5245487689971924
Validation loss: 2.408250783079414

Epoch: 156| Step: 0
Training loss: 2.975832223892212
Validation loss: 2.401163706215479

Epoch: 6| Step: 1
Training loss: 3.313096523284912
Validation loss: 2.400015092665149

Epoch: 6| Step: 2
Training loss: 2.6564345359802246
Validation loss: 2.3979208007935555

Epoch: 6| Step: 3
Training loss: 2.416555881500244
Validation loss: 2.3932132156946326

Epoch: 6| Step: 4
Training loss: 2.721228837966919
Validation loss: 2.399265181633734

Epoch: 6| Step: 5
Training loss: 2.4057960510253906
Validation loss: 2.4107261985860844

Epoch: 6| Step: 6
Training loss: 2.7573533058166504
Validation loss: 2.4038095269151913

Epoch: 6| Step: 7
Training loss: 2.80553936958313
Validation loss: 2.4046383109143985

Epoch: 6| Step: 8
Training loss: 2.0613980293273926
Validation loss: 2.411149537691506

Epoch: 6| Step: 9
Training loss: 1.9708727598190308
Validation loss: 2.40190649801685

Epoch: 6| Step: 10
Training loss: 2.3659920692443848
Validation loss: 2.3982150631566204

Epoch: 6| Step: 11
Training loss: 2.82788348197937
Validation loss: 2.402428691105176

Epoch: 6| Step: 12
Training loss: 2.71338152885437
Validation loss: 2.3975150456992527

Epoch: 6| Step: 13
Training loss: 2.774510145187378
Validation loss: 2.3984580039978027

Epoch: 157| Step: 0
Training loss: 2.6798758506774902
Validation loss: 2.3976415844373804

Epoch: 6| Step: 1
Training loss: 2.7672057151794434
Validation loss: 2.3979520643911054

Epoch: 6| Step: 2
Training loss: 2.773409366607666
Validation loss: 2.3979965973925847

Epoch: 6| Step: 3
Training loss: 2.5103821754455566
Validation loss: 2.3977678001567884

Epoch: 6| Step: 4
Training loss: 2.2151033878326416
Validation loss: 2.3929535804256314

Epoch: 6| Step: 5
Training loss: 2.781363010406494
Validation loss: 2.398711658293201

Epoch: 6| Step: 6
Training loss: 2.756269931793213
Validation loss: 2.4007467326297554

Epoch: 6| Step: 7
Training loss: 3.0330417156219482
Validation loss: 2.39923071604903

Epoch: 6| Step: 8
Training loss: 2.420103073120117
Validation loss: 2.3992354767296904

Epoch: 6| Step: 9
Training loss: 2.242745876312256
Validation loss: 2.4048513597057712

Epoch: 6| Step: 10
Training loss: 2.3891396522521973
Validation loss: 2.409954047972156

Epoch: 6| Step: 11
Training loss: 2.6309432983398438
Validation loss: 2.4271510262643137

Epoch: 6| Step: 12
Training loss: 2.579698085784912
Validation loss: 2.409557778348205

Epoch: 6| Step: 13
Training loss: 3.258894681930542
Validation loss: 2.4200282789045766

Epoch: 158| Step: 0
Training loss: 2.608435869216919
Validation loss: 2.4166590654721825

Epoch: 6| Step: 1
Training loss: 2.4026222229003906
Validation loss: 2.416176588304581

Epoch: 6| Step: 2
Training loss: 3.3118038177490234
Validation loss: 2.415040672466319

Epoch: 6| Step: 3
Training loss: 2.0212631225585938
Validation loss: 2.4051187525513353

Epoch: 6| Step: 4
Training loss: 2.5470495223999023
Validation loss: 2.3996732722046556

Epoch: 6| Step: 5
Training loss: 2.357571601867676
Validation loss: 2.402496619891095

Epoch: 6| Step: 6
Training loss: 2.7164504528045654
Validation loss: 2.3967036918927263

Epoch: 6| Step: 7
Training loss: 3.313016414642334
Validation loss: 2.397067641699186

Epoch: 6| Step: 8
Training loss: 2.1284871101379395
Validation loss: 2.391339102099019

Epoch: 6| Step: 9
Training loss: 2.6705379486083984
Validation loss: 2.3978812797095186

Epoch: 6| Step: 10
Training loss: 2.93277907371521
Validation loss: 2.395944910664712

Epoch: 6| Step: 11
Training loss: 2.4320948123931885
Validation loss: 2.3961968063026347

Epoch: 6| Step: 12
Training loss: 2.7406082153320312
Validation loss: 2.399917338484077

Epoch: 6| Step: 13
Training loss: 2.444974660873413
Validation loss: 2.3972366086898313

Epoch: 159| Step: 0
Training loss: 2.800745964050293
Validation loss: 2.404828207467192

Epoch: 6| Step: 1
Training loss: 1.813133955001831
Validation loss: 2.399959397572343

Epoch: 6| Step: 2
Training loss: 2.7065649032592773
Validation loss: 2.4005915708439325

Epoch: 6| Step: 3
Training loss: 2.7589621543884277
Validation loss: 2.402147041854038

Epoch: 6| Step: 4
Training loss: 1.8184492588043213
Validation loss: 2.4151939961218063

Epoch: 6| Step: 5
Training loss: 3.282297372817993
Validation loss: 2.403633448385423

Epoch: 6| Step: 6
Training loss: 2.1063671112060547
Validation loss: 2.401710130835092

Epoch: 6| Step: 7
Training loss: 2.4775400161743164
Validation loss: 2.4010354831654537

Epoch: 6| Step: 8
Training loss: 2.9666833877563477
Validation loss: 2.3906490264400357

Epoch: 6| Step: 9
Training loss: 2.911504030227661
Validation loss: 2.394807720697054

Epoch: 6| Step: 10
Training loss: 2.6827826499938965
Validation loss: 2.3957242196606052

Epoch: 6| Step: 11
Training loss: 3.3540706634521484
Validation loss: 2.4042025176427697

Epoch: 6| Step: 12
Training loss: 2.4717795848846436
Validation loss: 2.396533771227765

Epoch: 6| Step: 13
Training loss: 2.5064306259155273
Validation loss: 2.396020204790177

Epoch: 160| Step: 0
Training loss: 2.683608293533325
Validation loss: 2.391759580181491

Epoch: 6| Step: 1
Training loss: 2.2104172706604004
Validation loss: 2.4024756852016655

Epoch: 6| Step: 2
Training loss: 2.687389373779297
Validation loss: 2.402107410533454

Epoch: 6| Step: 3
Training loss: 2.8984391689300537
Validation loss: 2.40505390526146

Epoch: 6| Step: 4
Training loss: 2.8908185958862305
Validation loss: 2.4055626212909655

Epoch: 6| Step: 5
Training loss: 2.3138856887817383
Validation loss: 2.4046278102423555

Epoch: 6| Step: 6
Training loss: 3.4308745861053467
Validation loss: 2.4074191713845856

Epoch: 6| Step: 7
Training loss: 2.8870739936828613
Validation loss: 2.4045697284001175

Epoch: 6| Step: 8
Training loss: 2.293642044067383
Validation loss: 2.4038155591616066

Epoch: 6| Step: 9
Training loss: 2.3071951866149902
Validation loss: 2.4075817267100015

Epoch: 6| Step: 10
Training loss: 2.0754928588867188
Validation loss: 2.405127425347605

Epoch: 6| Step: 11
Training loss: 2.9642608165740967
Validation loss: 2.405008105821507

Epoch: 6| Step: 12
Training loss: 2.728005886077881
Validation loss: 2.395581537677396

Epoch: 6| Step: 13
Training loss: 2.013953924179077
Validation loss: 2.4080633271125054

Epoch: 161| Step: 0
Training loss: 2.494868755340576
Validation loss: 2.401163738260987

Epoch: 6| Step: 1
Training loss: 2.638092041015625
Validation loss: 2.4014463168318554

Epoch: 6| Step: 2
Training loss: 2.5756561756134033
Validation loss: 2.3994657531861336

Epoch: 6| Step: 3
Training loss: 2.0648140907287598
Validation loss: 2.407282731866324

Epoch: 6| Step: 4
Training loss: 2.7644901275634766
Validation loss: 2.409982027546052

Epoch: 6| Step: 5
Training loss: 2.2405171394348145
Validation loss: 2.4075059711292224

Epoch: 6| Step: 6
Training loss: 3.3547425270080566
Validation loss: 2.4098709103881673

Epoch: 6| Step: 7
Training loss: 3.112204074859619
Validation loss: 2.4081917116718907

Epoch: 6| Step: 8
Training loss: 2.2629213333129883
Validation loss: 2.4013989253710677

Epoch: 6| Step: 9
Training loss: 2.818650960922241
Validation loss: 2.4082588457292124

Epoch: 6| Step: 10
Training loss: 1.5863600969314575
Validation loss: 2.4088517106989378

Epoch: 6| Step: 11
Training loss: 2.7109785079956055
Validation loss: 2.4070747667743313

Epoch: 6| Step: 12
Training loss: 3.3543806076049805
Validation loss: 2.405207105862197

Epoch: 6| Step: 13
Training loss: 2.434846878051758
Validation loss: 2.400757740902644

Epoch: 162| Step: 0
Training loss: 1.3292227983474731
Validation loss: 2.3991230815969486

Epoch: 6| Step: 1
Training loss: 3.3115546703338623
Validation loss: 2.3955544553777224

Epoch: 6| Step: 2
Training loss: 2.783831834793091
Validation loss: 2.3966869231193297

Epoch: 6| Step: 3
Training loss: 2.16506290435791
Validation loss: 2.394269007508473

Epoch: 6| Step: 4
Training loss: 2.76638126373291
Validation loss: 2.392415846547773

Epoch: 6| Step: 5
Training loss: 2.9034652709960938
Validation loss: 2.3905042550897084

Epoch: 6| Step: 6
Training loss: 2.1531758308410645
Validation loss: 2.3941696997611754

Epoch: 6| Step: 7
Training loss: 2.8575687408447266
Validation loss: 2.393938118411649

Epoch: 6| Step: 8
Training loss: 2.162445545196533
Validation loss: 2.3989446009359052

Epoch: 6| Step: 9
Training loss: 2.4621500968933105
Validation loss: 2.399445374806722

Epoch: 6| Step: 10
Training loss: 2.6668787002563477
Validation loss: 2.3982308936375443

Epoch: 6| Step: 11
Training loss: 3.0490150451660156
Validation loss: 2.404917206815494

Epoch: 6| Step: 12
Training loss: 2.6819729804992676
Validation loss: 2.4058494260234218

Epoch: 6| Step: 13
Training loss: 3.6745355129241943
Validation loss: 2.4078917798175605

Epoch: 163| Step: 0
Training loss: 3.047116756439209
Validation loss: 2.4029775383651897

Epoch: 6| Step: 1
Training loss: 2.793278694152832
Validation loss: 2.407168972876764

Epoch: 6| Step: 2
Training loss: 2.7359728813171387
Validation loss: 2.4009934279226486

Epoch: 6| Step: 3
Training loss: 2.5182816982269287
Validation loss: 2.39293768072641

Epoch: 6| Step: 4
Training loss: 1.9246736764907837
Validation loss: 2.397964517275492

Epoch: 6| Step: 5
Training loss: 2.4724082946777344
Validation loss: 2.399632118081534

Epoch: 6| Step: 6
Training loss: 3.3796610832214355
Validation loss: 2.4031962758751324

Epoch: 6| Step: 7
Training loss: 2.370405673980713
Validation loss: 2.3957558857497347

Epoch: 6| Step: 8
Training loss: 2.6711347103118896
Validation loss: 2.3959467590496106

Epoch: 6| Step: 9
Training loss: 3.4476256370544434
Validation loss: 2.4041373575887373

Epoch: 6| Step: 10
Training loss: 1.792741298675537
Validation loss: 2.4034633508292575

Epoch: 6| Step: 11
Training loss: 2.4767584800720215
Validation loss: 2.4050402846387637

Epoch: 6| Step: 12
Training loss: 2.4586637020111084
Validation loss: 2.4009369368194253

Epoch: 6| Step: 13
Training loss: 2.3667519092559814
Validation loss: 2.3984146118164062

Epoch: 164| Step: 0
Training loss: 3.1865811347961426
Validation loss: 2.4054597680286696

Epoch: 6| Step: 1
Training loss: 2.5443952083587646
Validation loss: 2.3982832277974775

Epoch: 6| Step: 2
Training loss: 2.395663022994995
Validation loss: 2.4028457416001188

Epoch: 6| Step: 3
Training loss: 2.1087756156921387
Validation loss: 2.424253304799398

Epoch: 6| Step: 4
Training loss: 2.5249195098876953
Validation loss: 2.4167173934239212

Epoch: 6| Step: 5
Training loss: 1.4148733615875244
Validation loss: 2.4242975724640714

Epoch: 6| Step: 6
Training loss: 2.900404930114746
Validation loss: 2.397306009005475

Epoch: 6| Step: 7
Training loss: 3.0186386108398438
Validation loss: 2.3925784569914623

Epoch: 6| Step: 8
Training loss: 3.0246224403381348
Validation loss: 2.395860231050881

Epoch: 6| Step: 9
Training loss: 2.5026631355285645
Validation loss: 2.394353305139849

Epoch: 6| Step: 10
Training loss: 3.1027565002441406
Validation loss: 2.397155591236648

Epoch: 6| Step: 11
Training loss: 3.26033091545105
Validation loss: 2.3990646331541

Epoch: 6| Step: 12
Training loss: 2.438823699951172
Validation loss: 2.4011653187454387

Epoch: 6| Step: 13
Training loss: 1.786041259765625
Validation loss: 2.4000429850752636

Epoch: 165| Step: 0
Training loss: 3.100142240524292
Validation loss: 2.3986647436695714

Epoch: 6| Step: 1
Training loss: 2.793140411376953
Validation loss: 2.394831324136385

Epoch: 6| Step: 2
Training loss: 2.504035472869873
Validation loss: 2.4028318594860774

Epoch: 6| Step: 3
Training loss: 2.8923912048339844
Validation loss: 2.3881998446679886

Epoch: 6| Step: 4
Training loss: 3.506232261657715
Validation loss: 2.386164939531716

Epoch: 6| Step: 5
Training loss: 2.546602249145508
Validation loss: 2.3884212945097234

Epoch: 6| Step: 6
Training loss: 2.4866232872009277
Validation loss: 2.3854010284587903

Epoch: 6| Step: 7
Training loss: 2.3900275230407715
Validation loss: 2.389951523914132

Epoch: 6| Step: 8
Training loss: 2.7694809436798096
Validation loss: 2.3911128992675454

Epoch: 6| Step: 9
Training loss: 1.563041090965271
Validation loss: 2.3932204631067093

Epoch: 6| Step: 10
Training loss: 2.7432539463043213
Validation loss: 2.3932460200402046

Epoch: 6| Step: 11
Training loss: 2.1949915885925293
Validation loss: 2.396489102353332

Epoch: 6| Step: 12
Training loss: 2.5105133056640625
Validation loss: 2.3956066690465456

Epoch: 6| Step: 13
Training loss: 2.3379483222961426
Validation loss: 2.3897483195027998

Epoch: 166| Step: 0
Training loss: 3.130371332168579
Validation loss: 2.3997629098994757

Epoch: 6| Step: 1
Training loss: 2.6375646591186523
Validation loss: 2.3921386144494496

Epoch: 6| Step: 2
Training loss: 2.4776735305786133
Validation loss: 2.3951965608904437

Epoch: 6| Step: 3
Training loss: 2.580232620239258
Validation loss: 2.388444504430217

Epoch: 6| Step: 4
Training loss: 3.0630388259887695
Validation loss: 2.3786311713598107

Epoch: 6| Step: 5
Training loss: 2.047940254211426
Validation loss: 2.3850753461160967

Epoch: 6| Step: 6
Training loss: 2.735586643218994
Validation loss: 2.38706624379722

Epoch: 6| Step: 7
Training loss: 2.645228147506714
Validation loss: 2.3909824509774484

Epoch: 6| Step: 8
Training loss: 2.3242263793945312
Validation loss: 2.3998075146828928

Epoch: 6| Step: 9
Training loss: 3.1459856033325195
Validation loss: 2.4138732456391856

Epoch: 6| Step: 10
Training loss: 2.5686721801757812
Validation loss: 2.415488548176263

Epoch: 6| Step: 11
Training loss: 2.130352020263672
Validation loss: 2.4157472938619633

Epoch: 6| Step: 12
Training loss: 1.968384027481079
Validation loss: 2.409815557541386

Epoch: 6| Step: 13
Training loss: 3.5062193870544434
Validation loss: 2.419092769263893

Epoch: 167| Step: 0
Training loss: 2.637943744659424
Validation loss: 2.4070198279555126

Epoch: 6| Step: 1
Training loss: 2.255610942840576
Validation loss: 2.4001861861957017

Epoch: 6| Step: 2
Training loss: 3.1181459426879883
Validation loss: 2.39660656580361

Epoch: 6| Step: 3
Training loss: 2.1809778213500977
Validation loss: 2.384830485108078

Epoch: 6| Step: 4
Training loss: 2.4728031158447266
Validation loss: 2.3898704641608783

Epoch: 6| Step: 5
Training loss: 2.4929256439208984
Validation loss: 2.400740208164338

Epoch: 6| Step: 6
Training loss: 2.4688878059387207
Validation loss: 2.407270441773117

Epoch: 6| Step: 7
Training loss: 1.698470950126648
Validation loss: 2.405654068916075

Epoch: 6| Step: 8
Training loss: 2.43019437789917
Validation loss: 2.408334944837837

Epoch: 6| Step: 9
Training loss: 2.969648838043213
Validation loss: 2.4071005928900933

Epoch: 6| Step: 10
Training loss: 3.3190865516662598
Validation loss: 2.3953601519266763

Epoch: 6| Step: 11
Training loss: 2.6532392501831055
Validation loss: 2.393585774206346

Epoch: 6| Step: 12
Training loss: 3.2535927295684814
Validation loss: 2.392618570276486

Epoch: 6| Step: 13
Training loss: 2.6798903942108154
Validation loss: 2.386922328702865

Epoch: 168| Step: 0
Training loss: 2.149271249771118
Validation loss: 2.390591126616283

Epoch: 6| Step: 1
Training loss: 3.2018251419067383
Validation loss: 2.3891101319302797

Epoch: 6| Step: 2
Training loss: 2.8634824752807617
Validation loss: 2.4006826493047897

Epoch: 6| Step: 3
Training loss: 2.487173080444336
Validation loss: 2.3896935268114974

Epoch: 6| Step: 4
Training loss: 3.358889102935791
Validation loss: 2.393717873481012

Epoch: 6| Step: 5
Training loss: 2.549168586730957
Validation loss: 2.390703780676729

Epoch: 6| Step: 6
Training loss: 3.0535776615142822
Validation loss: 2.384086646059508

Epoch: 6| Step: 7
Training loss: 2.6192479133605957
Validation loss: 2.3788811852855067

Epoch: 6| Step: 8
Training loss: 2.4529550075531006
Validation loss: 2.3787695336085495

Epoch: 6| Step: 9
Training loss: 2.0460774898529053
Validation loss: 2.3862268129984536

Epoch: 6| Step: 10
Training loss: 2.276170253753662
Validation loss: 2.384383714327248

Epoch: 6| Step: 11
Training loss: 2.275390148162842
Validation loss: 2.387469555741997

Epoch: 6| Step: 12
Training loss: 2.998227596282959
Validation loss: 2.3853259035336074

Epoch: 6| Step: 13
Training loss: 1.9028849601745605
Validation loss: 2.3828547821250012

Epoch: 169| Step: 0
Training loss: 2.7930402755737305
Validation loss: 2.3896027585511566

Epoch: 6| Step: 1
Training loss: 2.9574148654937744
Validation loss: 2.384085116847869

Epoch: 6| Step: 2
Training loss: 2.00636625289917
Validation loss: 2.3931188147555114

Epoch: 6| Step: 3
Training loss: 2.722069501876831
Validation loss: 2.38571584609247

Epoch: 6| Step: 4
Training loss: 2.3093814849853516
Validation loss: 2.387631650893919

Epoch: 6| Step: 5
Training loss: 2.7999258041381836
Validation loss: 2.3879260452844764

Epoch: 6| Step: 6
Training loss: 2.736236572265625
Validation loss: 2.3896459430776615

Epoch: 6| Step: 7
Training loss: 3.315213203430176
Validation loss: 2.3825132616104616

Epoch: 6| Step: 8
Training loss: 2.1575067043304443
Validation loss: 2.3863114746668006

Epoch: 6| Step: 9
Training loss: 2.4391865730285645
Validation loss: 2.3807344462281916

Epoch: 6| Step: 10
Training loss: 2.87166166305542
Validation loss: 2.3884690320619972

Epoch: 6| Step: 11
Training loss: 3.2196693420410156
Validation loss: 2.3936147805183166

Epoch: 6| Step: 12
Training loss: 2.328449249267578
Validation loss: 2.3885554754605858

Epoch: 6| Step: 13
Training loss: 1.289275884628296
Validation loss: 2.3893824469658638

Epoch: 170| Step: 0
Training loss: 1.9636955261230469
Validation loss: 2.3882756515215804

Epoch: 6| Step: 1
Training loss: 2.5392394065856934
Validation loss: 2.380908194408622

Epoch: 6| Step: 2
Training loss: 2.723127841949463
Validation loss: 2.386333801413095

Epoch: 6| Step: 3
Training loss: 2.925337076187134
Validation loss: 2.384849081757248

Epoch: 6| Step: 4
Training loss: 2.476146936416626
Validation loss: 2.3824214217483357

Epoch: 6| Step: 5
Training loss: 2.1870293617248535
Validation loss: 2.3812595054667485

Epoch: 6| Step: 6
Training loss: 2.400346517562866
Validation loss: 2.3926266034444175

Epoch: 6| Step: 7
Training loss: 2.1362459659576416
Validation loss: 2.3876217539592455

Epoch: 6| Step: 8
Training loss: 2.974485397338867
Validation loss: 2.4019873039696806

Epoch: 6| Step: 9
Training loss: 2.6133108139038086
Validation loss: 2.4048600863384944

Epoch: 6| Step: 10
Training loss: 3.313150405883789
Validation loss: 2.4076386626048754

Epoch: 6| Step: 11
Training loss: 2.8758585453033447
Validation loss: 2.3985213823215936

Epoch: 6| Step: 12
Training loss: 2.718675374984741
Validation loss: 2.389501522946101

Epoch: 6| Step: 13
Training loss: 2.7933449745178223
Validation loss: 2.395908066021499

Epoch: 171| Step: 0
Training loss: 3.0461390018463135
Validation loss: 2.3876657921780824

Epoch: 6| Step: 1
Training loss: 2.8654415607452393
Validation loss: 2.3841953764679613

Epoch: 6| Step: 2
Training loss: 2.645977020263672
Validation loss: 2.375807841618856

Epoch: 6| Step: 3
Training loss: 2.0168752670288086
Validation loss: 2.3737757846873295

Epoch: 6| Step: 4
Training loss: 1.756927251815796
Validation loss: 2.3745596024297897

Epoch: 6| Step: 5
Training loss: 2.076443672180176
Validation loss: 2.3743072350819907

Epoch: 6| Step: 6
Training loss: 2.559699535369873
Validation loss: 2.3739626228168444

Epoch: 6| Step: 7
Training loss: 2.684004783630371
Validation loss: 2.378551165262858

Epoch: 6| Step: 8
Training loss: 2.727640151977539
Validation loss: 2.374723711321431

Epoch: 6| Step: 9
Training loss: 2.868098258972168
Validation loss: 2.378950857347058

Epoch: 6| Step: 10
Training loss: 2.844890594482422
Validation loss: 2.376509643370105

Epoch: 6| Step: 11
Training loss: 3.148613691329956
Validation loss: 2.3762773903467322

Epoch: 6| Step: 12
Training loss: 2.4138364791870117
Validation loss: 2.3852871284689954

Epoch: 6| Step: 13
Training loss: 2.9107906818389893
Validation loss: 2.381623601400724

Epoch: 172| Step: 0
Training loss: 3.215494155883789
Validation loss: 2.3786604199358212

Epoch: 6| Step: 1
Training loss: 2.532249927520752
Validation loss: 2.385491865937428

Epoch: 6| Step: 2
Training loss: 2.620664358139038
Validation loss: 2.3920279395195747

Epoch: 6| Step: 3
Training loss: 3.0975937843322754
Validation loss: 2.3958846317824496

Epoch: 6| Step: 4
Training loss: 2.251389980316162
Validation loss: 2.3897223831504903

Epoch: 6| Step: 5
Training loss: 2.779808282852173
Validation loss: 2.3909206851836173

Epoch: 6| Step: 6
Training loss: 2.1672985553741455
Validation loss: 2.3828565869280087

Epoch: 6| Step: 7
Training loss: 2.3034534454345703
Validation loss: 2.384454329808553

Epoch: 6| Step: 8
Training loss: 3.109011650085449
Validation loss: 2.381653106340798

Epoch: 6| Step: 9
Training loss: 2.9408955574035645
Validation loss: 2.370547520217075

Epoch: 6| Step: 10
Training loss: 2.1623334884643555
Validation loss: 2.3735315210075787

Epoch: 6| Step: 11
Training loss: 2.0408051013946533
Validation loss: 2.368656232792844

Epoch: 6| Step: 12
Training loss: 2.642202615737915
Validation loss: 2.3775027413522043

Epoch: 6| Step: 13
Training loss: 2.429340362548828
Validation loss: 2.3804789896934264

Epoch: 173| Step: 0
Training loss: 2.4108786582946777
Validation loss: 2.387952853274602

Epoch: 6| Step: 1
Training loss: 2.961261034011841
Validation loss: 2.396586864225326

Epoch: 6| Step: 2
Training loss: 3.2272891998291016
Validation loss: 2.409312617394232

Epoch: 6| Step: 3
Training loss: 2.2149689197540283
Validation loss: 2.4173694400377173

Epoch: 6| Step: 4
Training loss: 2.5242974758148193
Validation loss: 2.412600081454041

Epoch: 6| Step: 5
Training loss: 2.774078845977783
Validation loss: 2.401612207453738

Epoch: 6| Step: 6
Training loss: 2.709750175476074
Validation loss: 2.397662542199576

Epoch: 6| Step: 7
Training loss: 2.3772783279418945
Validation loss: 2.3835903188233734

Epoch: 6| Step: 8
Training loss: 2.0054404735565186
Validation loss: 2.3846482974226757

Epoch: 6| Step: 9
Training loss: 2.383882522583008
Validation loss: 2.379400048204648

Epoch: 6| Step: 10
Training loss: 2.7466492652893066
Validation loss: 2.374623119190175

Epoch: 6| Step: 11
Training loss: 2.885538101196289
Validation loss: 2.378208503928236

Epoch: 6| Step: 12
Training loss: 2.916749954223633
Validation loss: 2.3768257479513846

Epoch: 6| Step: 13
Training loss: 1.991526484489441
Validation loss: 2.378161004794541

Epoch: 174| Step: 0
Training loss: 2.0758848190307617
Validation loss: 2.387231065380958

Epoch: 6| Step: 1
Training loss: 2.730093479156494
Validation loss: 2.3798560250189995

Epoch: 6| Step: 2
Training loss: 2.5804507732391357
Validation loss: 2.382106973278907

Epoch: 6| Step: 3
Training loss: 2.9737484455108643
Validation loss: 2.374146076940721

Epoch: 6| Step: 4
Training loss: 2.68648099899292
Validation loss: 2.3824486835028535

Epoch: 6| Step: 5
Training loss: 2.9177966117858887
Validation loss: 2.3834565172913256

Epoch: 6| Step: 6
Training loss: 2.5400538444519043
Validation loss: 2.383539963794011

Epoch: 6| Step: 7
Training loss: 2.9014785289764404
Validation loss: 2.374095796256937

Epoch: 6| Step: 8
Training loss: 2.2327985763549805
Validation loss: 2.378368377685547

Epoch: 6| Step: 9
Training loss: 2.3723480701446533
Validation loss: 2.3865048141889673

Epoch: 6| Step: 10
Training loss: 2.3844635486602783
Validation loss: 2.382716714694936

Epoch: 6| Step: 11
Training loss: 2.5525269508361816
Validation loss: 2.3825557103721042

Epoch: 6| Step: 12
Training loss: 2.570807456970215
Validation loss: 2.3763848709803757

Epoch: 6| Step: 13
Training loss: 2.9496569633483887
Validation loss: 2.3792494958446873

Epoch: 175| Step: 0
Training loss: 1.7145500183105469
Validation loss: 2.382509687895416

Epoch: 6| Step: 1
Training loss: 2.9986045360565186
Validation loss: 2.385618325202696

Epoch: 6| Step: 2
Training loss: 2.75732421875
Validation loss: 2.3888532141203522

Epoch: 6| Step: 3
Training loss: 2.338075876235962
Validation loss: 2.385942998752799

Epoch: 6| Step: 4
Training loss: 2.694509506225586
Validation loss: 2.3954347666873725

Epoch: 6| Step: 5
Training loss: 2.916255474090576
Validation loss: 2.3969079320148756

Epoch: 6| Step: 6
Training loss: 3.5566258430480957
Validation loss: 2.3989836118554555

Epoch: 6| Step: 7
Training loss: 2.2162721157073975
Validation loss: 2.3942476395637757

Epoch: 6| Step: 8
Training loss: 2.349921464920044
Validation loss: 2.3991616028611378

Epoch: 6| Step: 9
Training loss: 2.3642401695251465
Validation loss: 2.4001981109701176

Epoch: 6| Step: 10
Training loss: 2.661564350128174
Validation loss: 2.3971367779598443

Epoch: 6| Step: 11
Training loss: 2.6486165523529053
Validation loss: 2.4021709247301986

Epoch: 6| Step: 12
Training loss: 2.5781264305114746
Validation loss: 2.3977710482894734

Epoch: 6| Step: 13
Training loss: 2.582601308822632
Validation loss: 2.3831579095573834

Epoch: 176| Step: 0
Training loss: 3.074195384979248
Validation loss: 2.3803902492728284

Epoch: 6| Step: 1
Training loss: 2.0865843296051025
Validation loss: 2.3710035149769118

Epoch: 6| Step: 2
Training loss: 2.3659541606903076
Validation loss: 2.3745085090719242

Epoch: 6| Step: 3
Training loss: 3.1558775901794434
Validation loss: 2.374720383715886

Epoch: 6| Step: 4
Training loss: 2.6905765533447266
Validation loss: 2.385920663033762

Epoch: 6| Step: 5
Training loss: 3.3466224670410156
Validation loss: 2.381947696849864

Epoch: 6| Step: 6
Training loss: 3.1680312156677246
Validation loss: 2.3886156697427072

Epoch: 6| Step: 7
Training loss: 2.8702778816223145
Validation loss: 2.401708415759507

Epoch: 6| Step: 8
Training loss: 2.7692344188690186
Validation loss: 2.391581061065838

Epoch: 6| Step: 9
Training loss: 1.968302607536316
Validation loss: 2.375340724504122

Epoch: 6| Step: 10
Training loss: 1.8352049589157104
Validation loss: 2.37300972015627

Epoch: 6| Step: 11
Training loss: 2.039449691772461
Validation loss: 2.378431407354211

Epoch: 6| Step: 12
Training loss: 2.746281147003174
Validation loss: 2.38342982979231

Epoch: 6| Step: 13
Training loss: 2.0911779403686523
Validation loss: 2.3824399158518803

Epoch: 177| Step: 0
Training loss: 3.6402533054351807
Validation loss: 2.3918548758311937

Epoch: 6| Step: 1
Training loss: 1.9772189855575562
Validation loss: 2.395801659553282

Epoch: 6| Step: 2
Training loss: 2.7752842903137207
Validation loss: 2.404835667661441

Epoch: 6| Step: 3
Training loss: 2.6605424880981445
Validation loss: 2.4331315948117163

Epoch: 6| Step: 4
Training loss: 3.10788631439209
Validation loss: 2.4283959532296784

Epoch: 6| Step: 5
Training loss: 2.8303334712982178
Validation loss: 2.4224250124346827

Epoch: 6| Step: 6
Training loss: 2.123910427093506
Validation loss: 2.4394004908941125

Epoch: 6| Step: 7
Training loss: 2.2465431690216064
Validation loss: 2.4186141362754245

Epoch: 6| Step: 8
Training loss: 2.5729823112487793
Validation loss: 2.4156248518215713

Epoch: 6| Step: 9
Training loss: 3.231865167617798
Validation loss: 2.4050142944500013

Epoch: 6| Step: 10
Training loss: 1.8287112712860107
Validation loss: 2.3853402765848304

Epoch: 6| Step: 11
Training loss: 2.8080625534057617
Validation loss: 2.375851115872783

Epoch: 6| Step: 12
Training loss: 2.1962995529174805
Validation loss: 2.366843843972811

Epoch: 6| Step: 13
Training loss: 2.3881635665893555
Validation loss: 2.361591213492937

Epoch: 178| Step: 0
Training loss: 2.973235607147217
Validation loss: 2.357881628057008

Epoch: 6| Step: 1
Training loss: 2.927027702331543
Validation loss: 2.363985753828479

Epoch: 6| Step: 2
Training loss: 2.533287763595581
Validation loss: 2.3588504175986014

Epoch: 6| Step: 3
Training loss: 2.331894874572754
Validation loss: 2.3638147025979976

Epoch: 6| Step: 4
Training loss: 2.799006462097168
Validation loss: 2.356197282832156

Epoch: 6| Step: 5
Training loss: 2.8607921600341797
Validation loss: 2.3571099363347536

Epoch: 6| Step: 6
Training loss: 2.6685006618499756
Validation loss: 2.3592404345030427

Epoch: 6| Step: 7
Training loss: 2.122467041015625
Validation loss: 2.360029146235476

Epoch: 6| Step: 8
Training loss: 2.859266519546509
Validation loss: 2.360772014946066

Epoch: 6| Step: 9
Training loss: 2.4688961505889893
Validation loss: 2.3639712205497165

Epoch: 6| Step: 10
Training loss: 2.6627986431121826
Validation loss: 2.358338463690973

Epoch: 6| Step: 11
Training loss: 2.3653669357299805
Validation loss: 2.3600422131117953

Epoch: 6| Step: 12
Training loss: 2.669579029083252
Validation loss: 2.3583200157329602

Epoch: 6| Step: 13
Training loss: 1.8754106760025024
Validation loss: 2.358895758146881

Epoch: 179| Step: 0
Training loss: 2.3515467643737793
Validation loss: 2.3686630238768873

Epoch: 6| Step: 1
Training loss: 2.7367520332336426
Validation loss: 2.3734643920775382

Epoch: 6| Step: 2
Training loss: 2.5140926837921143
Validation loss: 2.382175971102971

Epoch: 6| Step: 3
Training loss: 3.3580820560455322
Validation loss: 2.3946555929799236

Epoch: 6| Step: 4
Training loss: 2.541179656982422
Validation loss: 2.3979072263163905

Epoch: 6| Step: 5
Training loss: 2.245601177215576
Validation loss: 2.3893060556022068

Epoch: 6| Step: 6
Training loss: 2.9383575916290283
Validation loss: 2.3913728344825005

Epoch: 6| Step: 7
Training loss: 2.5808587074279785
Validation loss: 2.3855154129766647

Epoch: 6| Step: 8
Training loss: 2.2364721298217773
Validation loss: 2.3852238783272366

Epoch: 6| Step: 9
Training loss: 2.2725019454956055
Validation loss: 2.3845653482662734

Epoch: 6| Step: 10
Training loss: 2.1916699409484863
Validation loss: 2.3757524336538007

Epoch: 6| Step: 11
Training loss: 2.7817511558532715
Validation loss: 2.3757918906468216

Epoch: 6| Step: 12
Training loss: 2.888245105743408
Validation loss: 2.3846795558929443

Epoch: 6| Step: 13
Training loss: 2.915100574493408
Validation loss: 2.381727657010478

Epoch: 180| Step: 0
Training loss: 2.3040754795074463
Validation loss: 2.3792700280425367

Epoch: 6| Step: 1
Training loss: 2.492908000946045
Validation loss: 2.3830997738786923

Epoch: 6| Step: 2
Training loss: 2.39913272857666
Validation loss: 2.3933741943810576

Epoch: 6| Step: 3
Training loss: 3.048475742340088
Validation loss: 2.3958722596527426

Epoch: 6| Step: 4
Training loss: 2.1103551387786865
Validation loss: 2.398263064763879

Epoch: 6| Step: 5
Training loss: 2.4995744228363037
Validation loss: 2.39780754427756

Epoch: 6| Step: 6
Training loss: 2.2490642070770264
Validation loss: 2.3814790710326164

Epoch: 6| Step: 7
Training loss: 2.7745449542999268
Validation loss: 2.389403304746074

Epoch: 6| Step: 8
Training loss: 2.8148274421691895
Validation loss: 2.3846156058772916

Epoch: 6| Step: 9
Training loss: 2.6065428256988525
Validation loss: 2.376663646390361

Epoch: 6| Step: 10
Training loss: 2.644005298614502
Validation loss: 2.3671609740103445

Epoch: 6| Step: 11
Training loss: 3.150609254837036
Validation loss: 2.365849356497488

Epoch: 6| Step: 12
Training loss: 2.648922920227051
Validation loss: 2.3656667381204586

Epoch: 6| Step: 13
Training loss: 2.5453238487243652
Validation loss: 2.365005163736241

Epoch: 181| Step: 0
Training loss: 2.634232997894287
Validation loss: 2.365198281503493

Epoch: 6| Step: 1
Training loss: 3.567866086959839
Validation loss: 2.3670992235983572

Epoch: 6| Step: 2
Training loss: 3.2600181102752686
Validation loss: 2.3676780757083686

Epoch: 6| Step: 3
Training loss: 2.7147536277770996
Validation loss: 2.3718897578536824

Epoch: 6| Step: 4
Training loss: 2.7672958374023438
Validation loss: 2.364135080768216

Epoch: 6| Step: 5
Training loss: 2.9297871589660645
Validation loss: 2.3672047994470082

Epoch: 6| Step: 6
Training loss: 1.602264404296875
Validation loss: 2.3629674603862147

Epoch: 6| Step: 7
Training loss: 2.2226409912109375
Validation loss: 2.3672441359489196

Epoch: 6| Step: 8
Training loss: 2.9226787090301514
Validation loss: 2.3745879204042497

Epoch: 6| Step: 9
Training loss: 2.2743802070617676
Validation loss: 2.3792902602944324

Epoch: 6| Step: 10
Training loss: 2.5899658203125
Validation loss: 2.3951472108082106

Epoch: 6| Step: 11
Training loss: 2.1547751426696777
Validation loss: 2.3976190141452256

Epoch: 6| Step: 12
Training loss: 2.5344977378845215
Validation loss: 2.392431866738104

Epoch: 6| Step: 13
Training loss: 1.8864256143569946
Validation loss: 2.3984246253967285

Epoch: 182| Step: 0
Training loss: 2.249932289123535
Validation loss: 2.3927147926822787

Epoch: 6| Step: 1
Training loss: 2.1093599796295166
Validation loss: 2.376217160173642

Epoch: 6| Step: 2
Training loss: 1.932830810546875
Validation loss: 2.37051074991944

Epoch: 6| Step: 3
Training loss: 3.487515926361084
Validation loss: 2.377515241663943

Epoch: 6| Step: 4
Training loss: 2.4270708560943604
Validation loss: 2.3760150504368607

Epoch: 6| Step: 5
Training loss: 2.051835536956787
Validation loss: 2.3760696226550686

Epoch: 6| Step: 6
Training loss: 2.0653018951416016
Validation loss: 2.373177728345317

Epoch: 6| Step: 7
Training loss: 3.2678656578063965
Validation loss: 2.3847821015183643

Epoch: 6| Step: 8
Training loss: 2.5359272956848145
Validation loss: 2.381355659936064

Epoch: 6| Step: 9
Training loss: 4.063176155090332
Validation loss: 2.3813920367148613

Epoch: 6| Step: 10
Training loss: 2.4524874687194824
Validation loss: 2.377502609324712

Epoch: 6| Step: 11
Training loss: 2.768726348876953
Validation loss: 2.3703620126170497

Epoch: 6| Step: 12
Training loss: 2.51499605178833
Validation loss: 2.3578003709034254

Epoch: 6| Step: 13
Training loss: 2.2103397846221924
Validation loss: 2.355700162149245

Epoch: 183| Step: 0
Training loss: 2.5194077491760254
Validation loss: 2.356796795322049

Epoch: 6| Step: 1
Training loss: 1.9624162912368774
Validation loss: 2.3493487347838697

Epoch: 6| Step: 2
Training loss: 3.0018701553344727
Validation loss: 2.353127476989582

Epoch: 6| Step: 3
Training loss: 2.8530263900756836
Validation loss: 2.3469392817507506

Epoch: 6| Step: 4
Training loss: 2.4973275661468506
Validation loss: 2.3569110901125017

Epoch: 6| Step: 5
Training loss: 2.569972515106201
Validation loss: 2.3508448421314196

Epoch: 6| Step: 6
Training loss: 1.9895944595336914
Validation loss: 2.3501069891837334

Epoch: 6| Step: 7
Training loss: 2.728510618209839
Validation loss: 2.351667074746983

Epoch: 6| Step: 8
Training loss: 2.648395538330078
Validation loss: 2.359805458335466

Epoch: 6| Step: 9
Training loss: 2.3711090087890625
Validation loss: 2.352539562409924

Epoch: 6| Step: 10
Training loss: 2.8987607955932617
Validation loss: 2.3581237100785777

Epoch: 6| Step: 11
Training loss: 2.6985011100769043
Validation loss: 2.349497277249572

Epoch: 6| Step: 12
Training loss: 2.566415786743164
Validation loss: 2.361542450484409

Epoch: 6| Step: 13
Training loss: 3.234109878540039
Validation loss: 2.3712474505106607

Epoch: 184| Step: 0
Training loss: 2.4931068420410156
Validation loss: 2.4017167270824475

Epoch: 6| Step: 1
Training loss: 1.3914381265640259
Validation loss: 2.4266012202027025

Epoch: 6| Step: 2
Training loss: 2.5317559242248535
Validation loss: 2.4401982727871148

Epoch: 6| Step: 3
Training loss: 2.3604013919830322
Validation loss: 2.4379302378623717

Epoch: 6| Step: 4
Training loss: 2.095745086669922
Validation loss: 2.4044832145014117

Epoch: 6| Step: 5
Training loss: 2.666895866394043
Validation loss: 2.395838265777916

Epoch: 6| Step: 6
Training loss: 2.977296829223633
Validation loss: 2.372395884606146

Epoch: 6| Step: 7
Training loss: 2.928262233734131
Validation loss: 2.3671692827696442

Epoch: 6| Step: 8
Training loss: 3.1363461017608643
Validation loss: 2.359061038622292

Epoch: 6| Step: 9
Training loss: 3.1576924324035645
Validation loss: 2.363561976340509

Epoch: 6| Step: 10
Training loss: 1.9351155757904053
Validation loss: 2.3565149307250977

Epoch: 6| Step: 11
Training loss: 3.0780882835388184
Validation loss: 2.360391401475476

Epoch: 6| Step: 12
Training loss: 2.8577613830566406
Validation loss: 2.357868412489532

Epoch: 6| Step: 13
Training loss: 3.2574291229248047
Validation loss: 2.3581947126696186

Epoch: 185| Step: 0
Training loss: 2.1311373710632324
Validation loss: 2.3481963834454938

Epoch: 6| Step: 1
Training loss: 2.4530422687530518
Validation loss: 2.352404261148104

Epoch: 6| Step: 2
Training loss: 2.8039662837982178
Validation loss: 2.3442410653637302

Epoch: 6| Step: 3
Training loss: 2.3364381790161133
Validation loss: 2.345439649397327

Epoch: 6| Step: 4
Training loss: 2.9362852573394775
Validation loss: 2.346852117969144

Epoch: 6| Step: 5
Training loss: 1.8644118309020996
Validation loss: 2.3436793768277733

Epoch: 6| Step: 6
Training loss: 2.356914520263672
Validation loss: 2.3462654749552407

Epoch: 6| Step: 7
Training loss: 2.9483120441436768
Validation loss: 2.348470223847256

Epoch: 6| Step: 8
Training loss: 2.8130924701690674
Validation loss: 2.3494753350493727

Epoch: 6| Step: 9
Training loss: 3.891489028930664
Validation loss: 2.3444312874988844

Epoch: 6| Step: 10
Training loss: 2.2759926319122314
Validation loss: 2.353346376008885

Epoch: 6| Step: 11
Training loss: 2.0085155963897705
Validation loss: 2.3585986014335387

Epoch: 6| Step: 12
Training loss: 2.616058826446533
Validation loss: 2.3524759431039133

Epoch: 6| Step: 13
Training loss: 3.060363531112671
Validation loss: 2.3655526843122257

Epoch: 186| Step: 0
Training loss: 2.565152168273926
Validation loss: 2.3630728619073027

Epoch: 6| Step: 1
Training loss: 2.9856550693511963
Validation loss: 2.367864288309569

Epoch: 6| Step: 2
Training loss: 2.8487038612365723
Validation loss: 2.362187126631378

Epoch: 6| Step: 3
Training loss: 2.043009042739868
Validation loss: 2.3667892204817904

Epoch: 6| Step: 4
Training loss: 2.0732531547546387
Validation loss: 2.362910141227066

Epoch: 6| Step: 5
Training loss: 3.1084482669830322
Validation loss: 2.363571023428312

Epoch: 6| Step: 6
Training loss: 3.1287193298339844
Validation loss: 2.3608680694333968

Epoch: 6| Step: 7
Training loss: 2.0191144943237305
Validation loss: 2.3657714782222623

Epoch: 6| Step: 8
Training loss: 2.4189915657043457
Validation loss: 2.355417569478353

Epoch: 6| Step: 9
Training loss: 2.610865354537964
Validation loss: 2.3594577209923857

Epoch: 6| Step: 10
Training loss: 2.6105117797851562
Validation loss: 2.3590482050372708

Epoch: 6| Step: 11
Training loss: 2.117955207824707
Validation loss: 2.358586347231301

Epoch: 6| Step: 12
Training loss: 2.902592658996582
Validation loss: 2.3526093049715926

Epoch: 6| Step: 13
Training loss: 2.8376779556274414
Validation loss: 2.3600478172302246

Epoch: 187| Step: 0
Training loss: 2.5064682960510254
Validation loss: 2.3560598229849212

Epoch: 6| Step: 1
Training loss: 2.6595230102539062
Validation loss: 2.35402427693849

Epoch: 6| Step: 2
Training loss: 2.881503105163574
Validation loss: 2.357423738766742

Epoch: 6| Step: 3
Training loss: 3.2372539043426514
Validation loss: 2.364158440661687

Epoch: 6| Step: 4
Training loss: 3.290764808654785
Validation loss: 2.3591884387436735

Epoch: 6| Step: 5
Training loss: 2.412611484527588
Validation loss: 2.360735026738977

Epoch: 6| Step: 6
Training loss: 1.8538622856140137
Validation loss: 2.359674938263432

Epoch: 6| Step: 7
Training loss: 2.738953113555908
Validation loss: 2.364389229846257

Epoch: 6| Step: 8
Training loss: 1.8497848510742188
Validation loss: 2.363652616418818

Epoch: 6| Step: 9
Training loss: 2.136169672012329
Validation loss: 2.36704687405658

Epoch: 6| Step: 10
Training loss: 2.338887929916382
Validation loss: 2.380873062277353

Epoch: 6| Step: 11
Training loss: 2.322545289993286
Validation loss: 2.377813723779494

Epoch: 6| Step: 12
Training loss: 3.308527708053589
Validation loss: 2.383361190877935

Epoch: 6| Step: 13
Training loss: 2.441389322280884
Validation loss: 2.376733849125524

Epoch: 188| Step: 0
Training loss: 2.3277416229248047
Validation loss: 2.3801436065345682

Epoch: 6| Step: 1
Training loss: 2.5068488121032715
Validation loss: 2.370597823973625

Epoch: 6| Step: 2
Training loss: 2.844264507293701
Validation loss: 2.377856275086762

Epoch: 6| Step: 3
Training loss: 2.583693027496338
Validation loss: 2.3678621066513883

Epoch: 6| Step: 4
Training loss: 1.7946192026138306
Validation loss: 2.371964713578583

Epoch: 6| Step: 5
Training loss: 2.408046245574951
Validation loss: 2.3699777536494757

Epoch: 6| Step: 6
Training loss: 2.685931921005249
Validation loss: 2.3811850906700216

Epoch: 6| Step: 7
Training loss: 2.7292633056640625
Validation loss: 2.3688302065736506

Epoch: 6| Step: 8
Training loss: 2.6885573863983154
Validation loss: 2.370485242976937

Epoch: 6| Step: 9
Training loss: 2.5314431190490723
Validation loss: 2.373614077926964

Epoch: 6| Step: 10
Training loss: 2.726949691772461
Validation loss: 2.3614555456305064

Epoch: 6| Step: 11
Training loss: 2.547306776046753
Validation loss: 2.361338274453276

Epoch: 6| Step: 12
Training loss: 2.7497758865356445
Validation loss: 2.361428819676881

Epoch: 6| Step: 13
Training loss: 3.0431935787200928
Validation loss: 2.3582243099007556

Epoch: 189| Step: 0
Training loss: 2.587636947631836
Validation loss: 2.3529099674635034

Epoch: 6| Step: 1
Training loss: 2.6000003814697266
Validation loss: 2.3620426706088486

Epoch: 6| Step: 2
Training loss: 2.6989643573760986
Validation loss: 2.3570537541502263

Epoch: 6| Step: 3
Training loss: 2.617981433868408
Validation loss: 2.360462675812424

Epoch: 6| Step: 4
Training loss: 2.5013604164123535
Validation loss: 2.3575636686817294

Epoch: 6| Step: 5
Training loss: 2.5997729301452637
Validation loss: 2.3550329118646602

Epoch: 6| Step: 6
Training loss: 2.5571036338806152
Validation loss: 2.3535870185462375

Epoch: 6| Step: 7
Training loss: 2.467362403869629
Validation loss: 2.3541199571342877

Epoch: 6| Step: 8
Training loss: 2.2269225120544434
Validation loss: 2.350129199284379

Epoch: 6| Step: 9
Training loss: 2.9323229789733887
Validation loss: 2.3611583632807576

Epoch: 6| Step: 10
Training loss: 2.3784937858581543
Validation loss: 2.3645995278512277

Epoch: 6| Step: 11
Training loss: 2.3034207820892334
Validation loss: 2.3671573259497203

Epoch: 6| Step: 12
Training loss: 3.0981338024139404
Validation loss: 2.375469692291752

Epoch: 6| Step: 13
Training loss: 2.2123119831085205
Validation loss: 2.3768048068528533

Epoch: 190| Step: 0
Training loss: 2.183936357498169
Validation loss: 2.378912671919792

Epoch: 6| Step: 1
Training loss: 2.0696499347686768
Validation loss: 2.3894483543211416

Epoch: 6| Step: 2
Training loss: 3.1507887840270996
Validation loss: 2.4007083036566295

Epoch: 6| Step: 3
Training loss: 2.6622262001037598
Validation loss: 2.3872163398291475

Epoch: 6| Step: 4
Training loss: 2.844614267349243
Validation loss: 2.4184299489503265

Epoch: 6| Step: 5
Training loss: 2.2796595096588135
Validation loss: 2.398377856900615

Epoch: 6| Step: 6
Training loss: 2.0884475708007812
Validation loss: 2.409748992612285

Epoch: 6| Step: 7
Training loss: 2.272613763809204
Validation loss: 2.4126633726140505

Epoch: 6| Step: 8
Training loss: 2.4347453117370605
Validation loss: 2.3997627304446314

Epoch: 6| Step: 9
Training loss: 2.4079928398132324
Validation loss: 2.397244063756799

Epoch: 6| Step: 10
Training loss: 3.342871904373169
Validation loss: 2.3872120072764735

Epoch: 6| Step: 11
Training loss: 3.146878480911255
Validation loss: 2.367425436614662

Epoch: 6| Step: 12
Training loss: 2.6830081939697266
Validation loss: 2.374991586131434

Epoch: 6| Step: 13
Training loss: 2.473310947418213
Validation loss: 2.358619487413796

Epoch: 191| Step: 0
Training loss: 1.9100849628448486
Validation loss: 2.358918600184943

Epoch: 6| Step: 1
Training loss: 2.2476019859313965
Validation loss: 2.3621641282112367

Epoch: 6| Step: 2
Training loss: 3.7399604320526123
Validation loss: 2.3690710683022775

Epoch: 6| Step: 3
Training loss: 2.950169086456299
Validation loss: 2.3612304169644593

Epoch: 6| Step: 4
Training loss: 2.6471128463745117
Validation loss: 2.3647566277493715

Epoch: 6| Step: 5
Training loss: 2.301638126373291
Validation loss: 2.36087029980075

Epoch: 6| Step: 6
Training loss: 2.7013745307922363
Validation loss: 2.365200989989824

Epoch: 6| Step: 7
Training loss: 2.336979389190674
Validation loss: 2.366282475891934

Epoch: 6| Step: 8
Training loss: 2.251208543777466
Validation loss: 2.360835306106075

Epoch: 6| Step: 9
Training loss: 2.3364181518554688
Validation loss: 2.3535388105659076

Epoch: 6| Step: 10
Training loss: 2.552156686782837
Validation loss: 2.366552891269807

Epoch: 6| Step: 11
Training loss: 2.406805992126465
Validation loss: 2.3746636657304663

Epoch: 6| Step: 12
Training loss: 3.2663214206695557
Validation loss: 2.3857024792701966

Epoch: 6| Step: 13
Training loss: 2.2075817584991455
Validation loss: 2.369034654350691

Epoch: 192| Step: 0
Training loss: 3.0677356719970703
Validation loss: 2.3549802892951557

Epoch: 6| Step: 1
Training loss: 2.85265851020813
Validation loss: 2.355298735762155

Epoch: 6| Step: 2
Training loss: 2.8339483737945557
Validation loss: 2.3558596180331324

Epoch: 6| Step: 3
Training loss: 1.54854416847229
Validation loss: 2.3498373851981214

Epoch: 6| Step: 4
Training loss: 2.4723918437957764
Validation loss: 2.3531443995814167

Epoch: 6| Step: 5
Training loss: 2.971547842025757
Validation loss: 2.3503407022004486

Epoch: 6| Step: 6
Training loss: 2.936582565307617
Validation loss: 2.3520837932504635

Epoch: 6| Step: 7
Training loss: 2.6702804565429688
Validation loss: 2.3450378166731967

Epoch: 6| Step: 8
Training loss: 2.4644298553466797
Validation loss: 2.3467143915032826

Epoch: 6| Step: 9
Training loss: 2.0248632431030273
Validation loss: 2.352019690698193

Epoch: 6| Step: 10
Training loss: 3.0171070098876953
Validation loss: 2.3548846667812717

Epoch: 6| Step: 11
Training loss: 2.66603422164917
Validation loss: 2.3548796561456498

Epoch: 6| Step: 12
Training loss: 1.9272472858428955
Validation loss: 2.3582810842862694

Epoch: 6| Step: 13
Training loss: 2.3140134811401367
Validation loss: 2.3774577674045356

Epoch: 193| Step: 0
Training loss: 2.0399556159973145
Validation loss: 2.3727952357261413

Epoch: 6| Step: 1
Training loss: 3.1529765129089355
Validation loss: 2.3679391953252975

Epoch: 6| Step: 2
Training loss: 2.710472583770752
Validation loss: 2.367352798420896

Epoch: 6| Step: 3
Training loss: 2.119961977005005
Validation loss: 2.350723515274704

Epoch: 6| Step: 4
Training loss: 2.6453192234039307
Validation loss: 2.3473863652957383

Epoch: 6| Step: 5
Training loss: 2.5703125
Validation loss: 2.3424374570128736

Epoch: 6| Step: 6
Training loss: 2.619252920150757
Validation loss: 2.343785716641334

Epoch: 6| Step: 7
Training loss: 2.612109899520874
Validation loss: 2.3443360123583066

Epoch: 6| Step: 8
Training loss: 2.8190956115722656
Validation loss: 2.3362705540913407

Epoch: 6| Step: 9
Training loss: 2.0957443714141846
Validation loss: 2.3368372481356383

Epoch: 6| Step: 10
Training loss: 2.9783544540405273
Validation loss: 2.3410393115012877

Epoch: 6| Step: 11
Training loss: 2.9788198471069336
Validation loss: 2.3442924240584015

Epoch: 6| Step: 12
Training loss: 2.2635436058044434
Validation loss: 2.342904685645975

Epoch: 6| Step: 13
Training loss: 2.0890591144561768
Validation loss: 2.3441195334157636

Epoch: 194| Step: 0
Training loss: 2.586174726486206
Validation loss: 2.338220383531304

Epoch: 6| Step: 1
Training loss: 3.378711223602295
Validation loss: 2.337173928496658

Epoch: 6| Step: 2
Training loss: 2.806748390197754
Validation loss: 2.3469289810426774

Epoch: 6| Step: 3
Training loss: 2.532729148864746
Validation loss: 2.335538212971021

Epoch: 6| Step: 4
Training loss: 2.149794816970825
Validation loss: 2.3316731734942366

Epoch: 6| Step: 5
Training loss: 2.531399965286255
Validation loss: 2.3386846614140335

Epoch: 6| Step: 6
Training loss: 2.1872329711914062
Validation loss: 2.3417498398852605

Epoch: 6| Step: 7
Training loss: 3.0543103218078613
Validation loss: 2.346320762429186

Epoch: 6| Step: 8
Training loss: 2.835951566696167
Validation loss: 2.355197657820999

Epoch: 6| Step: 9
Training loss: 2.4033889770507812
Validation loss: 2.348770837629995

Epoch: 6| Step: 10
Training loss: 2.3892245292663574
Validation loss: 2.343919705319148

Epoch: 6| Step: 11
Training loss: 2.0357794761657715
Validation loss: 2.3496851126352944

Epoch: 6| Step: 12
Training loss: 2.3020901679992676
Validation loss: 2.3614145043075725

Epoch: 6| Step: 13
Training loss: 3.048921823501587
Validation loss: 2.3565161048725085

Epoch: 195| Step: 0
Training loss: 2.686084747314453
Validation loss: 2.3691213361678587

Epoch: 6| Step: 1
Training loss: 2.8686318397521973
Validation loss: 2.353923974498626

Epoch: 6| Step: 2
Training loss: 2.2098703384399414
Validation loss: 2.361311812554636

Epoch: 6| Step: 3
Training loss: 2.2642858028411865
Validation loss: 2.3543625147111955

Epoch: 6| Step: 4
Training loss: 2.6239771842956543
Validation loss: 2.348249179060741

Epoch: 6| Step: 5
Training loss: 2.8358750343322754
Validation loss: 2.3503183408450057

Epoch: 6| Step: 6
Training loss: 2.3432440757751465
Validation loss: 2.3564927219062723

Epoch: 6| Step: 7
Training loss: 2.6791324615478516
Validation loss: 2.36040755497512

Epoch: 6| Step: 8
Training loss: 2.650564670562744
Validation loss: 2.362629782768988

Epoch: 6| Step: 9
Training loss: 2.651350498199463
Validation loss: 2.3567680722923687

Epoch: 6| Step: 10
Training loss: 2.652653455734253
Validation loss: 2.369403011055403

Epoch: 6| Step: 11
Training loss: 1.9207639694213867
Validation loss: 2.3621286807521695

Epoch: 6| Step: 12
Training loss: 2.8333725929260254
Validation loss: 2.3533766179956417

Epoch: 6| Step: 13
Training loss: 2.9594767093658447
Validation loss: 2.3601060118726505

Epoch: 196| Step: 0
Training loss: 1.7445396184921265
Validation loss: 2.353734959838211

Epoch: 6| Step: 1
Training loss: 3.268284320831299
Validation loss: 2.3390452784876667

Epoch: 6| Step: 2
Training loss: 1.9502507448196411
Validation loss: 2.337116615746611

Epoch: 6| Step: 3
Training loss: 2.4042563438415527
Validation loss: 2.332541492677504

Epoch: 6| Step: 4
Training loss: 3.148000717163086
Validation loss: 2.3326261453731085

Epoch: 6| Step: 5
Training loss: 2.2722432613372803
Validation loss: 2.3325869626896356

Epoch: 6| Step: 6
Training loss: 2.2202870845794678
Validation loss: 2.330277991551225

Epoch: 6| Step: 7
Training loss: 2.736588478088379
Validation loss: 2.330575712265507

Epoch: 6| Step: 8
Training loss: 2.9208590984344482
Validation loss: 2.3339903559736026

Epoch: 6| Step: 9
Training loss: 2.498075008392334
Validation loss: 2.333880291190199

Epoch: 6| Step: 10
Training loss: 2.7278566360473633
Validation loss: 2.343695212435979

Epoch: 6| Step: 11
Training loss: 2.213994026184082
Validation loss: 2.343217690785726

Epoch: 6| Step: 12
Training loss: 2.9188268184661865
Validation loss: 2.3336624201907905

Epoch: 6| Step: 13
Training loss: 3.14563250541687
Validation loss: 2.336731272359048

Epoch: 197| Step: 0
Training loss: 3.518674850463867
Validation loss: 2.34609132171959

Epoch: 6| Step: 1
Training loss: 1.823197603225708
Validation loss: 2.34587594514252

Epoch: 6| Step: 2
Training loss: 2.3330585956573486
Validation loss: 2.3423418127080446

Epoch: 6| Step: 3
Training loss: 3.007781982421875
Validation loss: 2.3569559435690604

Epoch: 6| Step: 4
Training loss: 2.6962270736694336
Validation loss: 2.354588347096597

Epoch: 6| Step: 5
Training loss: 2.533114433288574
Validation loss: 2.3563460124436246

Epoch: 6| Step: 6
Training loss: 1.2928822040557861
Validation loss: 2.3604648523433234

Epoch: 6| Step: 7
Training loss: 1.773569107055664
Validation loss: 2.3789616220740863

Epoch: 6| Step: 8
Training loss: 2.8786206245422363
Validation loss: 2.381619325248144

Epoch: 6| Step: 9
Training loss: 2.7508997917175293
Validation loss: 2.366407117535991

Epoch: 6| Step: 10
Training loss: 2.189020872116089
Validation loss: 2.364847816446776

Epoch: 6| Step: 11
Training loss: 3.0411078929901123
Validation loss: 2.3570800186485372

Epoch: 6| Step: 12
Training loss: 3.051924705505371
Validation loss: 2.3560346121429117

Epoch: 6| Step: 13
Training loss: 3.420409679412842
Validation loss: 2.3541958203879734

Epoch: 198| Step: 0
Training loss: 2.1278934478759766
Validation loss: 2.3466421891284246

Epoch: 6| Step: 1
Training loss: 2.584953546524048
Validation loss: 2.3576276533065306

Epoch: 6| Step: 2
Training loss: 2.1831698417663574
Validation loss: 2.349189002026794

Epoch: 6| Step: 3
Training loss: 2.7295801639556885
Validation loss: 2.3587728469602522

Epoch: 6| Step: 4
Training loss: 2.4349803924560547
Validation loss: 2.3578957844805974

Epoch: 6| Step: 5
Training loss: 2.503135919570923
Validation loss: 2.3567140692023822

Epoch: 6| Step: 6
Training loss: 3.0619680881500244
Validation loss: 2.3595612536194506

Epoch: 6| Step: 7
Training loss: 2.091684579849243
Validation loss: 2.357191413961431

Epoch: 6| Step: 8
Training loss: 3.3369481563568115
Validation loss: 2.3606900579185894

Epoch: 6| Step: 9
Training loss: 2.060072422027588
Validation loss: 2.3519895256206556

Epoch: 6| Step: 10
Training loss: 1.8281433582305908
Validation loss: 2.363692009320823

Epoch: 6| Step: 11
Training loss: 2.8192086219787598
Validation loss: 2.361358706669141

Epoch: 6| Step: 12
Training loss: 3.489488124847412
Validation loss: 2.3638638142616517

Epoch: 6| Step: 13
Training loss: 2.7569355964660645
Validation loss: 2.37027330552378

Epoch: 199| Step: 0
Training loss: 3.1895933151245117
Validation loss: 2.3647740220510833

Epoch: 6| Step: 1
Training loss: 2.4113595485687256
Validation loss: 2.3562791552594913

Epoch: 6| Step: 2
Training loss: 2.8321032524108887
Validation loss: 2.3597800449658464

Epoch: 6| Step: 3
Training loss: 2.2179574966430664
Validation loss: 2.342756571308259

Epoch: 6| Step: 4
Training loss: 2.638432025909424
Validation loss: 2.3391915675132506

Epoch: 6| Step: 5
Training loss: 2.901554584503174
Validation loss: 2.3379937910264537

Epoch: 6| Step: 6
Training loss: 2.2738747596740723
Validation loss: 2.338799020295502

Epoch: 6| Step: 7
Training loss: 2.738938331604004
Validation loss: 2.339833733856037

Epoch: 6| Step: 8
Training loss: 2.008897066116333
Validation loss: 2.3440799456770702

Epoch: 6| Step: 9
Training loss: 2.435673236846924
Validation loss: 2.337009045385545

Epoch: 6| Step: 10
Training loss: 2.490651845932007
Validation loss: 2.345965839201404

Epoch: 6| Step: 11
Training loss: 2.4670727252960205
Validation loss: 2.3425585839056198

Epoch: 6| Step: 12
Training loss: 2.5273208618164062
Validation loss: 2.349232207062424

Epoch: 6| Step: 13
Training loss: 2.9758925437927246
Validation loss: 2.3550590494627595

Epoch: 200| Step: 0
Training loss: 1.9938231706619263
Validation loss: 2.3590101388192948

Epoch: 6| Step: 1
Training loss: 3.6390886306762695
Validation loss: 2.3680714304729173

Epoch: 6| Step: 2
Training loss: 2.0653915405273438
Validation loss: 2.3600217039867113

Epoch: 6| Step: 3
Training loss: 2.4907569885253906
Validation loss: 2.3477100608169392

Epoch: 6| Step: 4
Training loss: 1.9561097621917725
Validation loss: 2.354493050165074

Epoch: 6| Step: 5
Training loss: 2.1002252101898193
Validation loss: 2.3440264963334605

Epoch: 6| Step: 6
Training loss: 2.6189870834350586
Validation loss: 2.343529050068189

Epoch: 6| Step: 7
Training loss: 2.886892795562744
Validation loss: 2.3465770162561888

Epoch: 6| Step: 8
Training loss: 2.819427490234375
Validation loss: 2.3374511118858092

Epoch: 6| Step: 9
Training loss: 2.7196617126464844
Validation loss: 2.3478312082188104

Epoch: 6| Step: 10
Training loss: 2.6980912685394287
Validation loss: 2.352676683856595

Epoch: 6| Step: 11
Training loss: 2.8895437717437744
Validation loss: 2.3489155794984553

Epoch: 6| Step: 12
Training loss: 2.4717278480529785
Validation loss: 2.3543122148001068

Epoch: 6| Step: 13
Training loss: 2.4262914657592773
Validation loss: 2.345747786183511

Epoch: 201| Step: 0
Training loss: 2.2115726470947266
Validation loss: 2.3469292758613505

Epoch: 6| Step: 1
Training loss: 3.3452553749084473
Validation loss: 2.3495193732682096

Epoch: 6| Step: 2
Training loss: 2.7528581619262695
Validation loss: 2.344569577965685

Epoch: 6| Step: 3
Training loss: 2.933624267578125
Validation loss: 2.3424240030268186

Epoch: 6| Step: 4
Training loss: 2.943439483642578
Validation loss: 2.3444292776046263

Epoch: 6| Step: 5
Training loss: 2.7356677055358887
Validation loss: 2.3391801631578835

Epoch: 6| Step: 6
Training loss: 2.604858875274658
Validation loss: 2.344108711006821

Epoch: 6| Step: 7
Training loss: 2.0353446006774902
Validation loss: 2.3379264928961314

Epoch: 6| Step: 8
Training loss: 2.37680721282959
Validation loss: 2.345783131096953

Epoch: 6| Step: 9
Training loss: 2.075399398803711
Validation loss: 2.3463260268652313

Epoch: 6| Step: 10
Training loss: 2.264373302459717
Validation loss: 2.3556743873062955

Epoch: 6| Step: 11
Training loss: 2.43505859375
Validation loss: 2.343364659176078

Epoch: 6| Step: 12
Training loss: 2.4495224952697754
Validation loss: 2.349637016173332

Epoch: 6| Step: 13
Training loss: 2.6382107734680176
Validation loss: 2.3445368095110823

Epoch: 202| Step: 0
Training loss: 2.3919591903686523
Validation loss: 2.340991017638996

Epoch: 6| Step: 1
Training loss: 2.700403928756714
Validation loss: 2.3475867522660123

Epoch: 6| Step: 2
Training loss: 2.5525457859039307
Validation loss: 2.347073419119722

Epoch: 6| Step: 3
Training loss: 1.9934003353118896
Validation loss: 2.343654256995006

Epoch: 6| Step: 4
Training loss: 2.3233273029327393
Validation loss: 2.351218379953856

Epoch: 6| Step: 5
Training loss: 2.7590458393096924
Validation loss: 2.3577032960871214

Epoch: 6| Step: 6
Training loss: 2.590217113494873
Validation loss: 2.362448187284572

Epoch: 6| Step: 7
Training loss: 2.2112534046173096
Validation loss: 2.355110058220484

Epoch: 6| Step: 8
Training loss: 2.548733711242676
Validation loss: 2.355515556950723

Epoch: 6| Step: 9
Training loss: 2.257079839706421
Validation loss: 2.3490297461068756

Epoch: 6| Step: 10
Training loss: 2.535529613494873
Validation loss: 2.346960049803539

Epoch: 6| Step: 11
Training loss: 3.2543272972106934
Validation loss: 2.3434152449330976

Epoch: 6| Step: 12
Training loss: 2.694045305252075
Validation loss: 2.3425760653711136

Epoch: 6| Step: 13
Training loss: 3.156975507736206
Validation loss: 2.342506939365018

Epoch: 203| Step: 0
Training loss: 2.579735517501831
Validation loss: 2.3466450937332644

Epoch: 6| Step: 1
Training loss: 2.116434335708618
Validation loss: 2.341132438311013

Epoch: 6| Step: 2
Training loss: 2.251649856567383
Validation loss: 2.3440315851601223

Epoch: 6| Step: 3
Training loss: 2.9963197708129883
Validation loss: 2.336000383541148

Epoch: 6| Step: 4
Training loss: 2.7054901123046875
Validation loss: 2.3397346337636313

Epoch: 6| Step: 5
Training loss: 2.893726348876953
Validation loss: 2.340814858354548

Epoch: 6| Step: 6
Training loss: 3.0399293899536133
Validation loss: 2.3415336711432344

Epoch: 6| Step: 7
Training loss: 1.8167190551757812
Validation loss: 2.346213863741967

Epoch: 6| Step: 8
Training loss: 2.991030693054199
Validation loss: 2.331561862781484

Epoch: 6| Step: 9
Training loss: 3.04347825050354
Validation loss: 2.3387563946426555

Epoch: 6| Step: 10
Training loss: 2.214726448059082
Validation loss: 2.3301916122436523

Epoch: 6| Step: 11
Training loss: 2.052579879760742
Validation loss: 2.3320273712117183

Epoch: 6| Step: 12
Training loss: 3.0843710899353027
Validation loss: 2.3287547506311888

Epoch: 6| Step: 13
Training loss: 1.5956130027770996
Validation loss: 2.3316126074842227

Epoch: 204| Step: 0
Training loss: 2.082005500793457
Validation loss: 2.3344891122592393

Epoch: 6| Step: 1
Training loss: 2.2181036472320557
Validation loss: 2.3284375923936085

Epoch: 6| Step: 2
Training loss: 2.3767127990722656
Validation loss: 2.3353376004003708

Epoch: 6| Step: 3
Training loss: 2.5854039192199707
Validation loss: 2.340407230520761

Epoch: 6| Step: 4
Training loss: 2.8715944290161133
Validation loss: 2.3421531031208653

Epoch: 6| Step: 5
Training loss: 2.9628262519836426
Validation loss: 2.344501467161281

Epoch: 6| Step: 6
Training loss: 2.698551654815674
Validation loss: 2.345542061713434

Epoch: 6| Step: 7
Training loss: 2.0961618423461914
Validation loss: 2.3460724840882006

Epoch: 6| Step: 8
Training loss: 2.5887675285339355
Validation loss: 2.340554080983644

Epoch: 6| Step: 9
Training loss: 2.2512497901916504
Validation loss: 2.3546249776758175

Epoch: 6| Step: 10
Training loss: 2.8535428047180176
Validation loss: 2.347986328986383

Epoch: 6| Step: 11
Training loss: 2.6435818672180176
Validation loss: 2.34211221561637

Epoch: 6| Step: 12
Training loss: 3.0049962997436523
Validation loss: 2.3504898599399033

Epoch: 6| Step: 13
Training loss: 2.3190391063690186
Validation loss: 2.336524442959857

Epoch: 205| Step: 0
Training loss: 1.7250137329101562
Validation loss: 2.342541210113033

Epoch: 6| Step: 1
Training loss: 2.4614951610565186
Validation loss: 2.3484278366129887

Epoch: 6| Step: 2
Training loss: 3.105191230773926
Validation loss: 2.353084420645109

Epoch: 6| Step: 3
Training loss: 2.903812885284424
Validation loss: 2.351892166240241

Epoch: 6| Step: 4
Training loss: 3.0347607135772705
Validation loss: 2.3492661394098753

Epoch: 6| Step: 5
Training loss: 2.09055495262146
Validation loss: 2.3523153361453804

Epoch: 6| Step: 6
Training loss: 3.1364974975585938
Validation loss: 2.363123886046871

Epoch: 6| Step: 7
Training loss: 2.3015146255493164
Validation loss: 2.352783556907408

Epoch: 6| Step: 8
Training loss: 2.533949851989746
Validation loss: 2.3451758315486293

Epoch: 6| Step: 9
Training loss: 2.8282928466796875
Validation loss: 2.349429743264311

Epoch: 6| Step: 10
Training loss: 3.1415977478027344
Validation loss: 2.3427969691573933

Epoch: 6| Step: 11
Training loss: 1.660200834274292
Validation loss: 2.3276983614890807

Epoch: 6| Step: 12
Training loss: 2.368319034576416
Validation loss: 2.332324572788772

Epoch: 6| Step: 13
Training loss: 2.26330304145813
Validation loss: 2.327529917481125

Epoch: 206| Step: 0
Training loss: 2.3660428524017334
Validation loss: 2.3370332076985347

Epoch: 6| Step: 1
Training loss: 2.8083877563476562
Validation loss: 2.3447115985296105

Epoch: 6| Step: 2
Training loss: 3.264691114425659
Validation loss: 2.350115949107755

Epoch: 6| Step: 3
Training loss: 2.2100114822387695
Validation loss: 2.3592116422550653

Epoch: 6| Step: 4
Training loss: 1.9935650825500488
Validation loss: 2.3653126788395706

Epoch: 6| Step: 5
Training loss: 2.3575940132141113
Validation loss: 2.3579045880225395

Epoch: 6| Step: 6
Training loss: 2.5788488388061523
Validation loss: 2.3487372936741

Epoch: 6| Step: 7
Training loss: 3.0144011974334717
Validation loss: 2.3425064574005785

Epoch: 6| Step: 8
Training loss: 2.926380157470703
Validation loss: 2.340774679696688

Epoch: 6| Step: 9
Training loss: 2.3707432746887207
Validation loss: 2.328218365228304

Epoch: 6| Step: 10
Training loss: 2.411342144012451
Validation loss: 2.339804305825182

Epoch: 6| Step: 11
Training loss: 2.12507963180542
Validation loss: 2.3565045915624148

Epoch: 6| Step: 12
Training loss: 2.3992600440979004
Validation loss: 2.3715770116416355

Epoch: 6| Step: 13
Training loss: 3.419206380844116
Validation loss: 2.3736096915378364

Epoch: 207| Step: 0
Training loss: 2.455183744430542
Validation loss: 2.3857182700146913

Epoch: 6| Step: 1
Training loss: 2.6040284633636475
Validation loss: 2.375503078583748

Epoch: 6| Step: 2
Training loss: 3.13867449760437
Validation loss: 2.374149263546031

Epoch: 6| Step: 3
Training loss: 2.4345686435699463
Validation loss: 2.3743241089646534

Epoch: 6| Step: 4
Training loss: 3.0836338996887207
Validation loss: 2.365465546167025

Epoch: 6| Step: 5
Training loss: 2.769831657409668
Validation loss: 2.359279727423063

Epoch: 6| Step: 6
Training loss: 2.627744674682617
Validation loss: 2.3516654276078746

Epoch: 6| Step: 7
Training loss: 2.065824270248413
Validation loss: 2.3455630886939263

Epoch: 6| Step: 8
Training loss: 2.665189027786255
Validation loss: 2.333189631021151

Epoch: 6| Step: 9
Training loss: 2.713444471359253
Validation loss: 2.3402736263890422

Epoch: 6| Step: 10
Training loss: 2.2311291694641113
Validation loss: 2.3300601320882

Epoch: 6| Step: 11
Training loss: 2.887735366821289
Validation loss: 2.333588295085456

Epoch: 6| Step: 12
Training loss: 1.9312419891357422
Validation loss: 2.3336745769746843

Epoch: 6| Step: 13
Training loss: 1.7607465982437134
Validation loss: 2.3304719591653473

Epoch: 208| Step: 0
Training loss: 2.4394755363464355
Validation loss: 2.335793049104752

Epoch: 6| Step: 1
Training loss: 2.709563732147217
Validation loss: 2.330441540287387

Epoch: 6| Step: 2
Training loss: 3.0017600059509277
Validation loss: 2.32345018335568

Epoch: 6| Step: 3
Training loss: 2.5415313243865967
Validation loss: 2.3246715658454487

Epoch: 6| Step: 4
Training loss: 2.5898427963256836
Validation loss: 2.3303669011721047

Epoch: 6| Step: 5
Training loss: 3.1154613494873047
Validation loss: 2.334052662695608

Epoch: 6| Step: 6
Training loss: 2.436636447906494
Validation loss: 2.32778569575279

Epoch: 6| Step: 7
Training loss: 2.0087125301361084
Validation loss: 2.340850476295717

Epoch: 6| Step: 8
Training loss: 2.824334144592285
Validation loss: 2.330925577430315

Epoch: 6| Step: 9
Training loss: 2.4284534454345703
Validation loss: 2.331999760802074

Epoch: 6| Step: 10
Training loss: 1.9240573644638062
Validation loss: 2.3240023248939106

Epoch: 6| Step: 11
Training loss: 2.8898019790649414
Validation loss: 2.3384658751949186

Epoch: 6| Step: 12
Training loss: 1.957948923110962
Validation loss: 2.338356053957375

Epoch: 6| Step: 13
Training loss: 2.901146173477173
Validation loss: 2.3483501070289203

Epoch: 209| Step: 0
Training loss: 2.0008511543273926
Validation loss: 2.343025066519296

Epoch: 6| Step: 1
Training loss: 2.876500129699707
Validation loss: 2.368290916565926

Epoch: 6| Step: 2
Training loss: 2.6138713359832764
Validation loss: 2.3594712698331444

Epoch: 6| Step: 3
Training loss: 2.6416664123535156
Validation loss: 2.372319330451309

Epoch: 6| Step: 4
Training loss: 3.060312271118164
Validation loss: 2.376053689628519

Epoch: 6| Step: 5
Training loss: 2.2766056060791016
Validation loss: 2.358977856174592

Epoch: 6| Step: 6
Training loss: 2.8805034160614014
Validation loss: 2.3560257983464066

Epoch: 6| Step: 7
Training loss: 2.9949827194213867
Validation loss: 2.3532785292594665

Epoch: 6| Step: 8
Training loss: 2.632009506225586
Validation loss: 2.3594404548727055

Epoch: 6| Step: 9
Training loss: 2.280759334564209
Validation loss: 2.3492452354841333

Epoch: 6| Step: 10
Training loss: 2.6544227600097656
Validation loss: 2.341434035249936

Epoch: 6| Step: 11
Training loss: 2.03302001953125
Validation loss: 2.337324106565086

Epoch: 6| Step: 12
Training loss: 2.1595592498779297
Validation loss: 2.3486674754850325

Epoch: 6| Step: 13
Training loss: 2.594200611114502
Validation loss: 2.3454794063363025

Epoch: 210| Step: 0
Training loss: 2.5812106132507324
Validation loss: 2.3484338996230916

Epoch: 6| Step: 1
Training loss: 2.5002431869506836
Validation loss: 2.357062875583608

Epoch: 6| Step: 2
Training loss: 2.616123676300049
Validation loss: 2.35617950911163

Epoch: 6| Step: 3
Training loss: 2.5736513137817383
Validation loss: 2.3553356406509236

Epoch: 6| Step: 4
Training loss: 2.0655713081359863
Validation loss: 2.361360672981508

Epoch: 6| Step: 5
Training loss: 2.5737032890319824
Validation loss: 2.356283756994432

Epoch: 6| Step: 6
Training loss: 2.796942710876465
Validation loss: 2.361941035075854

Epoch: 6| Step: 7
Training loss: 2.896442174911499
Validation loss: 2.361058845314928

Epoch: 6| Step: 8
Training loss: 2.1386280059814453
Validation loss: 2.356561804330477

Epoch: 6| Step: 9
Training loss: 2.6960296630859375
Validation loss: 2.3519726812198596

Epoch: 6| Step: 10
Training loss: 2.640376091003418
Validation loss: 2.336764174122964

Epoch: 6| Step: 11
Training loss: 2.1064393520355225
Validation loss: 2.3326340490771877

Epoch: 6| Step: 12
Training loss: 3.0162110328674316
Validation loss: 2.328925963371031

Epoch: 6| Step: 13
Training loss: 2.471554756164551
Validation loss: 2.3221628999197357

Epoch: 211| Step: 0
Training loss: 3.536764621734619
Validation loss: 2.3203143535121793

Epoch: 6| Step: 1
Training loss: 2.467322587966919
Validation loss: 2.325354517147105

Epoch: 6| Step: 2
Training loss: 1.6725043058395386
Validation loss: 2.3159528855354554

Epoch: 6| Step: 3
Training loss: 2.127047538757324
Validation loss: 2.3085377703430834

Epoch: 6| Step: 4
Training loss: 2.852876663208008
Validation loss: 2.310460279064794

Epoch: 6| Step: 5
Training loss: 2.507495880126953
Validation loss: 2.311005905110349

Epoch: 6| Step: 6
Training loss: 1.8245328664779663
Validation loss: 2.3082373757516184

Epoch: 6| Step: 7
Training loss: 2.27362060546875
Validation loss: 2.308501382027903

Epoch: 6| Step: 8
Training loss: 2.958796501159668
Validation loss: 2.3077748360172397

Epoch: 6| Step: 9
Training loss: 2.922173023223877
Validation loss: 2.3054882890434674

Epoch: 6| Step: 10
Training loss: 3.034459114074707
Validation loss: 2.3199342373878724

Epoch: 6| Step: 11
Training loss: 2.106001853942871
Validation loss: 2.3169931057960755

Epoch: 6| Step: 12
Training loss: 3.08294415473938
Validation loss: 2.317515516793856

Epoch: 6| Step: 13
Training loss: 2.0655887126922607
Validation loss: 2.321541873357629

Epoch: 212| Step: 0
Training loss: 2.3469574451446533
Validation loss: 2.329111276134368

Epoch: 6| Step: 1
Training loss: 3.167710781097412
Validation loss: 2.335306377821071

Epoch: 6| Step: 2
Training loss: 2.5692296028137207
Validation loss: 2.329436807222264

Epoch: 6| Step: 3
Training loss: 1.9356343746185303
Validation loss: 2.3304750662977978

Epoch: 6| Step: 4
Training loss: 3.2997541427612305
Validation loss: 2.343372811553299

Epoch: 6| Step: 5
Training loss: 2.8014087677001953
Validation loss: 2.34860489701712

Epoch: 6| Step: 6
Training loss: 1.997172236442566
Validation loss: 2.352245674338392

Epoch: 6| Step: 7
Training loss: 1.8477015495300293
Validation loss: 2.3463169554228425

Epoch: 6| Step: 8
Training loss: 2.656862735748291
Validation loss: 2.3445956476273073

Epoch: 6| Step: 9
Training loss: 2.494518756866455
Validation loss: 2.343425989151001

Epoch: 6| Step: 10
Training loss: 2.366908550262451
Validation loss: 2.3512215281045563

Epoch: 6| Step: 11
Training loss: 2.215409278869629
Validation loss: 2.3569881762227705

Epoch: 6| Step: 12
Training loss: 2.8246700763702393
Validation loss: 2.354523810007239

Epoch: 6| Step: 13
Training loss: 3.306105375289917
Validation loss: 2.36050739724149

Epoch: 213| Step: 0
Training loss: 2.871795654296875
Validation loss: 2.3561320535598265

Epoch: 6| Step: 1
Training loss: 2.4471569061279297
Validation loss: 2.3408784020331597

Epoch: 6| Step: 2
Training loss: 2.348200798034668
Validation loss: 2.3345185864356255

Epoch: 6| Step: 3
Training loss: 1.7411835193634033
Validation loss: 2.3303361400481193

Epoch: 6| Step: 4
Training loss: 2.2905163764953613
Validation loss: 2.3272274104497765

Epoch: 6| Step: 5
Training loss: 2.2800965309143066
Validation loss: 2.3286907365245204

Epoch: 6| Step: 6
Training loss: 2.063530206680298
Validation loss: 2.3252135297303558

Epoch: 6| Step: 7
Training loss: 3.166696071624756
Validation loss: 2.318506638209025

Epoch: 6| Step: 8
Training loss: 2.7960383892059326
Validation loss: 2.316042048956758

Epoch: 6| Step: 9
Training loss: 2.479201078414917
Validation loss: 2.3196248059631674

Epoch: 6| Step: 10
Training loss: 3.0615341663360596
Validation loss: 2.3140637848966863

Epoch: 6| Step: 11
Training loss: 2.2912118434906006
Validation loss: 2.3097830587817776

Epoch: 6| Step: 12
Training loss: 2.7016448974609375
Validation loss: 2.3169260435206915

Epoch: 6| Step: 13
Training loss: 3.0871047973632812
Validation loss: 2.323462114539198

Epoch: 214| Step: 0
Training loss: 3.166893243789673
Validation loss: 2.3194285490179576

Epoch: 6| Step: 1
Training loss: 2.281221866607666
Validation loss: 2.314733023284584

Epoch: 6| Step: 2
Training loss: 2.5505008697509766
Validation loss: 2.326449366026027

Epoch: 6| Step: 3
Training loss: 2.865156412124634
Validation loss: 2.3323592165464997

Epoch: 6| Step: 4
Training loss: 2.863499641418457
Validation loss: 2.3309099315315165

Epoch: 6| Step: 5
Training loss: 2.3611092567443848
Validation loss: 2.3313839781668877

Epoch: 6| Step: 6
Training loss: 2.316932201385498
Validation loss: 2.328637825545444

Epoch: 6| Step: 7
Training loss: 2.4537246227264404
Validation loss: 2.337608233574898

Epoch: 6| Step: 8
Training loss: 1.3727598190307617
Validation loss: 2.3254283012882357

Epoch: 6| Step: 9
Training loss: 2.3602657318115234
Validation loss: 2.326397644576206

Epoch: 6| Step: 10
Training loss: 2.850442409515381
Validation loss: 2.3229935476856847

Epoch: 6| Step: 11
Training loss: 2.9071621894836426
Validation loss: 2.3227062584251486

Epoch: 6| Step: 12
Training loss: 1.882903814315796
Validation loss: 2.324946317621457

Epoch: 6| Step: 13
Training loss: 3.7601983547210693
Validation loss: 2.320646580829415

Epoch: 215| Step: 0
Training loss: 2.6736655235290527
Validation loss: 2.315739893144177

Epoch: 6| Step: 1
Training loss: 2.313629627227783
Validation loss: 2.3085695107777915

Epoch: 6| Step: 2
Training loss: 1.8527816534042358
Validation loss: 2.313769425115278

Epoch: 6| Step: 3
Training loss: 2.234800338745117
Validation loss: 2.3139657128241753

Epoch: 6| Step: 4
Training loss: 2.4446468353271484
Validation loss: 2.3059369005182737

Epoch: 6| Step: 5
Training loss: 2.790210008621216
Validation loss: 2.316312172079599

Epoch: 6| Step: 6
Training loss: 2.5392472743988037
Validation loss: 2.308804517151207

Epoch: 6| Step: 7
Training loss: 2.368894577026367
Validation loss: 2.303146245659039

Epoch: 6| Step: 8
Training loss: 2.962773084640503
Validation loss: 2.2987622304629256

Epoch: 6| Step: 9
Training loss: 2.8131699562072754
Validation loss: 2.2983421407720095

Epoch: 6| Step: 10
Training loss: 3.2066516876220703
Validation loss: 2.305965592784266

Epoch: 6| Step: 11
Training loss: 2.593316078186035
Validation loss: 2.304417371749878

Epoch: 6| Step: 12
Training loss: 1.4742655754089355
Validation loss: 2.309869873908258

Epoch: 6| Step: 13
Training loss: 3.5535244941711426
Validation loss: 2.302394308069701

Epoch: 216| Step: 0
Training loss: 1.8705387115478516
Validation loss: 2.314492512774724

Epoch: 6| Step: 1
Training loss: 2.0809104442596436
Validation loss: 2.3196315944835706

Epoch: 6| Step: 2
Training loss: 2.9903173446655273
Validation loss: 2.322964314491518

Epoch: 6| Step: 3
Training loss: 2.4969406127929688
Validation loss: 2.330183791857894

Epoch: 6| Step: 4
Training loss: 1.9739100933074951
Validation loss: 2.3209409816290743

Epoch: 6| Step: 5
Training loss: 2.072354555130005
Validation loss: 2.317535069680983

Epoch: 6| Step: 6
Training loss: 2.6682355403900146
Validation loss: 2.309832465264105

Epoch: 6| Step: 7
Training loss: 1.695069670677185
Validation loss: 2.3049988541551816

Epoch: 6| Step: 8
Training loss: 3.20572566986084
Validation loss: 2.302878734886005

Epoch: 6| Step: 9
Training loss: 2.5845863819122314
Validation loss: 2.2994321059155207

Epoch: 6| Step: 10
Training loss: 2.5302820205688477
Validation loss: 2.3072061192604805

Epoch: 6| Step: 11
Training loss: 2.824770450592041
Validation loss: 2.298813701957785

Epoch: 6| Step: 12
Training loss: 3.5169525146484375
Validation loss: 2.3016467491785684

Epoch: 6| Step: 13
Training loss: 3.2904458045959473
Validation loss: 2.3019125641033216

Epoch: 217| Step: 0
Training loss: 2.20682430267334
Validation loss: 2.3097953950205157

Epoch: 6| Step: 1
Training loss: 2.2556350231170654
Validation loss: 2.309345288943219

Epoch: 6| Step: 2
Training loss: 2.665449857711792
Validation loss: 2.304547426521137

Epoch: 6| Step: 3
Training loss: 2.2598164081573486
Validation loss: 2.3136911648575977

Epoch: 6| Step: 4
Training loss: 2.1151366233825684
Validation loss: 2.320967574273386

Epoch: 6| Step: 5
Training loss: 1.8894152641296387
Validation loss: 2.321723384241904

Epoch: 6| Step: 6
Training loss: 2.6213912963867188
Validation loss: 2.327210316094019

Epoch: 6| Step: 7
Training loss: 2.518355369567871
Validation loss: 2.326717879182549

Epoch: 6| Step: 8
Training loss: 2.6965172290802
Validation loss: 2.330536170672345

Epoch: 6| Step: 9
Training loss: 3.4239501953125
Validation loss: 2.322234671602967

Epoch: 6| Step: 10
Training loss: 2.9305763244628906
Validation loss: 2.3185616923916723

Epoch: 6| Step: 11
Training loss: 1.8723669052124023
Validation loss: 2.3210494697734876

Epoch: 6| Step: 12
Training loss: 3.050056219100952
Validation loss: 2.321314714288199

Epoch: 6| Step: 13
Training loss: 3.1578192710876465
Validation loss: 2.3206364723943893

Epoch: 218| Step: 0
Training loss: 2.433621644973755
Validation loss: 2.327902760556949

Epoch: 6| Step: 1
Training loss: 2.4149723052978516
Validation loss: 2.3468769468286985

Epoch: 6| Step: 2
Training loss: 2.93472957611084
Validation loss: 2.3522441387176514

Epoch: 6| Step: 3
Training loss: 2.5432050228118896
Validation loss: 2.333368029645694

Epoch: 6| Step: 4
Training loss: 2.539445161819458
Validation loss: 2.3389542359177784

Epoch: 6| Step: 5
Training loss: 2.5592284202575684
Validation loss: 2.339269330424647

Epoch: 6| Step: 6
Training loss: 2.389965057373047
Validation loss: 2.3258261424238964

Epoch: 6| Step: 7
Training loss: 2.494006633758545
Validation loss: 2.323418660830426

Epoch: 6| Step: 8
Training loss: 2.0939104557037354
Validation loss: 2.3136443002249605

Epoch: 6| Step: 9
Training loss: 2.4529614448547363
Validation loss: 2.315046146351804

Epoch: 6| Step: 10
Training loss: 2.8552470207214355
Validation loss: 2.3147985742938135

Epoch: 6| Step: 11
Training loss: 2.197890520095825
Validation loss: 2.3214137515714093

Epoch: 6| Step: 12
Training loss: 2.740845203399658
Validation loss: 2.322774553811678

Epoch: 6| Step: 13
Training loss: 2.895392656326294
Validation loss: 2.319759061259608

Epoch: 219| Step: 0
Training loss: 2.437166690826416
Validation loss: 2.3236159445137106

Epoch: 6| Step: 1
Training loss: 2.802877426147461
Validation loss: 2.3259992650760117

Epoch: 6| Step: 2
Training loss: 2.222717046737671
Validation loss: 2.32647535621479

Epoch: 6| Step: 3
Training loss: 2.811042547225952
Validation loss: 2.324274975766418

Epoch: 6| Step: 4
Training loss: 1.8379197120666504
Validation loss: 2.3252401223746677

Epoch: 6| Step: 5
Training loss: 3.1155266761779785
Validation loss: 2.3282941874637397

Epoch: 6| Step: 6
Training loss: 1.9718539714813232
Validation loss: 2.322216151863016

Epoch: 6| Step: 7
Training loss: 2.8281197547912598
Validation loss: 2.3193082578720583

Epoch: 6| Step: 8
Training loss: 2.4999582767486572
Validation loss: 2.3269828006785405

Epoch: 6| Step: 9
Training loss: 2.30195951461792
Validation loss: 2.3181314417110976

Epoch: 6| Step: 10
Training loss: 2.9890642166137695
Validation loss: 2.3165702127641246

Epoch: 6| Step: 11
Training loss: 2.4752368927001953
Validation loss: 2.325632717019768

Epoch: 6| Step: 12
Training loss: 2.9563255310058594
Validation loss: 2.326558123352707

Epoch: 6| Step: 13
Training loss: 1.7836146354675293
Validation loss: 2.335550444100493

Epoch: 220| Step: 0
Training loss: 2.8830928802490234
Validation loss: 2.316165460053311

Epoch: 6| Step: 1
Training loss: 2.3530967235565186
Validation loss: 2.317038038725494

Epoch: 6| Step: 2
Training loss: 3.180725574493408
Validation loss: 2.330144336146693

Epoch: 6| Step: 3
Training loss: 2.700303792953491
Validation loss: 2.327215148556617

Epoch: 6| Step: 4
Training loss: 1.9019386768341064
Validation loss: 2.3313550487641366

Epoch: 6| Step: 5
Training loss: 2.540029287338257
Validation loss: 2.329520663907451

Epoch: 6| Step: 6
Training loss: 3.1427929401397705
Validation loss: 2.3314766217303533

Epoch: 6| Step: 7
Training loss: 2.1925535202026367
Validation loss: 2.31693200654881

Epoch: 6| Step: 8
Training loss: 2.8095898628234863
Validation loss: 2.300375726915175

Epoch: 6| Step: 9
Training loss: 2.121826648712158
Validation loss: 2.311201613436463

Epoch: 6| Step: 10
Training loss: 1.7952232360839844
Validation loss: 2.2957240073911604

Epoch: 6| Step: 11
Training loss: 2.318815231323242
Validation loss: 2.3039974422865015

Epoch: 6| Step: 12
Training loss: 3.310110330581665
Validation loss: 2.316525705399052

Epoch: 6| Step: 13
Training loss: 1.5991052389144897
Validation loss: 2.3059496264303885

Epoch: 221| Step: 0
Training loss: 2.7311830520629883
Validation loss: 2.303075862187211

Epoch: 6| Step: 1
Training loss: 2.3990674018859863
Validation loss: 2.3132102412562214

Epoch: 6| Step: 2
Training loss: 2.7590341567993164
Validation loss: 2.3095119896755425

Epoch: 6| Step: 3
Training loss: 1.9579999446868896
Validation loss: 2.3232019011692335

Epoch: 6| Step: 4
Training loss: 1.6234242916107178
Validation loss: 2.318023527822187

Epoch: 6| Step: 5
Training loss: 1.799473524093628
Validation loss: 2.3140589857614167

Epoch: 6| Step: 6
Training loss: 3.0185728073120117
Validation loss: 2.313484928941214

Epoch: 6| Step: 7
Training loss: 2.9470443725585938
Validation loss: 2.317121369864351

Epoch: 6| Step: 8
Training loss: 3.1642842292785645
Validation loss: 2.308429286044131

Epoch: 6| Step: 9
Training loss: 2.7065041065216064
Validation loss: 2.3074729506687452

Epoch: 6| Step: 10
Training loss: 3.0518410205841064
Validation loss: 2.3067502360190115

Epoch: 6| Step: 11
Training loss: 1.9093186855316162
Validation loss: 2.311765273412069

Epoch: 6| Step: 12
Training loss: 2.606782913208008
Validation loss: 2.297777106685023

Epoch: 6| Step: 13
Training loss: 2.6592438220977783
Validation loss: 2.2965888054140153

Epoch: 222| Step: 0
Training loss: 2.6041338443756104
Validation loss: 2.292497586178523

Epoch: 6| Step: 1
Training loss: 2.546043634414673
Validation loss: 2.3045052277144564

Epoch: 6| Step: 2
Training loss: 2.835452079772949
Validation loss: 2.301529222919095

Epoch: 6| Step: 3
Training loss: 1.9684252738952637
Validation loss: 2.294444917350687

Epoch: 6| Step: 4
Training loss: 2.826744556427002
Validation loss: 2.2953692072181293

Epoch: 6| Step: 5
Training loss: 3.1135854721069336
Validation loss: 2.30559814617198

Epoch: 6| Step: 6
Training loss: 1.9581971168518066
Validation loss: 2.2918482339510353

Epoch: 6| Step: 7
Training loss: 2.721278667449951
Validation loss: 2.3032440062492125

Epoch: 6| Step: 8
Training loss: 2.5899038314819336
Validation loss: 2.3043406496765795

Epoch: 6| Step: 9
Training loss: 2.7967031002044678
Validation loss: 2.2892534553363757

Epoch: 6| Step: 10
Training loss: 2.2524168491363525
Validation loss: 2.289080583921043

Epoch: 6| Step: 11
Training loss: 2.2022616863250732
Validation loss: 2.285802197712724

Epoch: 6| Step: 12
Training loss: 2.484544277191162
Validation loss: 2.280448013736356

Epoch: 6| Step: 13
Training loss: 2.41274356842041
Validation loss: 2.2837344356762466

Epoch: 223| Step: 0
Training loss: 2.5474295616149902
Validation loss: 2.2762647085292365

Epoch: 6| Step: 1
Training loss: 3.0667357444763184
Validation loss: 2.2741969221381733

Epoch: 6| Step: 2
Training loss: 2.7874984741210938
Validation loss: 2.2829897660081104

Epoch: 6| Step: 3
Training loss: 2.3791868686676025
Validation loss: 2.289563504598474

Epoch: 6| Step: 4
Training loss: 2.658238410949707
Validation loss: 2.280000389263194

Epoch: 6| Step: 5
Training loss: 3.198592185974121
Validation loss: 2.2815400015923286

Epoch: 6| Step: 6
Training loss: 2.5398080348968506
Validation loss: 2.283000356407576

Epoch: 6| Step: 7
Training loss: 1.8688805103302002
Validation loss: 2.288531131641839

Epoch: 6| Step: 8
Training loss: 2.043323516845703
Validation loss: 2.295741167119754

Epoch: 6| Step: 9
Training loss: 2.2937769889831543
Validation loss: 2.2961736417585805

Epoch: 6| Step: 10
Training loss: 2.7844088077545166
Validation loss: 2.3069456700355775

Epoch: 6| Step: 11
Training loss: 1.92051362991333
Validation loss: 2.310702636677732

Epoch: 6| Step: 12
Training loss: 2.279686212539673
Validation loss: 2.310417318856844

Epoch: 6| Step: 13
Training loss: 3.1506049633026123
Validation loss: 2.3176774158272693

Epoch: 224| Step: 0
Training loss: 2.532801628112793
Validation loss: 2.3108636640733287

Epoch: 6| Step: 1
Training loss: 3.0550522804260254
Validation loss: 2.302081028620402

Epoch: 6| Step: 2
Training loss: 2.637786865234375
Validation loss: 2.303907422609227

Epoch: 6| Step: 3
Training loss: 2.411952495574951
Validation loss: 2.318074390452395

Epoch: 6| Step: 4
Training loss: 2.4362971782684326
Validation loss: 2.3328208846430623

Epoch: 6| Step: 5
Training loss: 3.0177268981933594
Validation loss: 2.3197879637441328

Epoch: 6| Step: 6
Training loss: 2.5720341205596924
Validation loss: 2.319216861519762

Epoch: 6| Step: 7
Training loss: 2.441272258758545
Validation loss: 2.3030833198178198

Epoch: 6| Step: 8
Training loss: 2.487137794494629
Validation loss: 2.2968154568826

Epoch: 6| Step: 9
Training loss: 2.129523277282715
Validation loss: 2.2943478656071488

Epoch: 6| Step: 10
Training loss: 2.1693172454833984
Validation loss: 2.2978356089643253

Epoch: 6| Step: 11
Training loss: 2.416464328765869
Validation loss: 2.313415683725829

Epoch: 6| Step: 12
Training loss: 1.8485249280929565
Validation loss: 2.324825104846749

Epoch: 6| Step: 13
Training loss: 3.604987144470215
Validation loss: 2.3401189388767367

Epoch: 225| Step: 0
Training loss: 3.3077125549316406
Validation loss: 2.3371744937794183

Epoch: 6| Step: 1
Training loss: 2.7979941368103027
Validation loss: 2.323598764275992

Epoch: 6| Step: 2
Training loss: 1.8244502544403076
Validation loss: 2.325291141386955

Epoch: 6| Step: 3
Training loss: 2.116616725921631
Validation loss: 2.300385782795568

Epoch: 6| Step: 4
Training loss: 2.593078136444092
Validation loss: 2.2939745610760105

Epoch: 6| Step: 5
Training loss: 2.7402210235595703
Validation loss: 2.2984141534374607

Epoch: 6| Step: 6
Training loss: 2.8207859992980957
Validation loss: 2.316488130118257

Epoch: 6| Step: 7
Training loss: 2.957045793533325
Validation loss: 2.3214298537982407

Epoch: 6| Step: 8
Training loss: 1.876343011856079
Validation loss: 2.3324503052619194

Epoch: 6| Step: 9
Training loss: 2.200261116027832
Validation loss: 2.3439294881718133

Epoch: 6| Step: 10
Training loss: 2.6305384635925293
Validation loss: 2.3267781106374597

Epoch: 6| Step: 11
Training loss: 2.8495380878448486
Validation loss: 2.3322588730883855

Epoch: 6| Step: 12
Training loss: 2.4846761226654053
Validation loss: 2.3112856316310104

Epoch: 6| Step: 13
Training loss: 1.7396771907806396
Validation loss: 2.3259474103168776

Epoch: 226| Step: 0
Training loss: 3.035348415374756
Validation loss: 2.3053446508223012

Epoch: 6| Step: 1
Training loss: 2.9444522857666016
Validation loss: 2.31147264921537

Epoch: 6| Step: 2
Training loss: 2.354170799255371
Validation loss: 2.294728971296741

Epoch: 6| Step: 3
Training loss: 1.83392333984375
Validation loss: 2.2990631313734156

Epoch: 6| Step: 4
Training loss: 3.031059741973877
Validation loss: 2.3043418494603967

Epoch: 6| Step: 5
Training loss: 2.8738009929656982
Validation loss: 2.29071036974589

Epoch: 6| Step: 6
Training loss: 1.9167249202728271
Validation loss: 2.278621215974131

Epoch: 6| Step: 7
Training loss: 2.2992465496063232
Validation loss: 2.271647963472592

Epoch: 6| Step: 8
Training loss: 1.8741133213043213
Validation loss: 2.269168148758591

Epoch: 6| Step: 9
Training loss: 3.068140983581543
Validation loss: 2.267881288323351

Epoch: 6| Step: 10
Training loss: 2.781017780303955
Validation loss: 2.268358486954884

Epoch: 6| Step: 11
Training loss: 1.7068119049072266
Validation loss: 2.2684493962154595

Epoch: 6| Step: 12
Training loss: 3.0574965476989746
Validation loss: 2.277318036684426

Epoch: 6| Step: 13
Training loss: 2.480012893676758
Validation loss: 2.268792195986676

Epoch: 227| Step: 0
Training loss: 2.8045156002044678
Validation loss: 2.2876116332187446

Epoch: 6| Step: 1
Training loss: 3.283949375152588
Validation loss: 2.3069603776419036

Epoch: 6| Step: 2
Training loss: 2.223893642425537
Validation loss: 2.3180615107218423

Epoch: 6| Step: 3
Training loss: 2.040395498275757
Validation loss: 2.3239597069319857

Epoch: 6| Step: 4
Training loss: 2.9319982528686523
Validation loss: 2.343275982846496

Epoch: 6| Step: 5
Training loss: 2.572904109954834
Validation loss: 2.345362606868949

Epoch: 6| Step: 6
Training loss: 2.575223445892334
Validation loss: 2.3481038539640364

Epoch: 6| Step: 7
Training loss: 1.9167702198028564
Validation loss: 2.3423348703692035

Epoch: 6| Step: 8
Training loss: 2.4488420486450195
Validation loss: 2.3245716556426017

Epoch: 6| Step: 9
Training loss: 3.005922794342041
Validation loss: 2.2989236693228445

Epoch: 6| Step: 10
Training loss: 1.7605881690979004
Validation loss: 2.277755557849843

Epoch: 6| Step: 11
Training loss: 2.6117703914642334
Validation loss: 2.2736470673673894

Epoch: 6| Step: 12
Training loss: 2.942182779312134
Validation loss: 2.2810690736257904

Epoch: 6| Step: 13
Training loss: 2.1392297744750977
Validation loss: 2.2894057663538123

Epoch: 228| Step: 0
Training loss: 1.5966873168945312
Validation loss: 2.291534228991437

Epoch: 6| Step: 1
Training loss: 2.7657053470611572
Validation loss: 2.302554443318357

Epoch: 6| Step: 2
Training loss: 2.4293248653411865
Validation loss: 2.3030228512261504

Epoch: 6| Step: 3
Training loss: 2.4097635746002197
Validation loss: 2.3074459439964703

Epoch: 6| Step: 4
Training loss: 3.032538890838623
Validation loss: 2.306088924407959

Epoch: 6| Step: 5
Training loss: 2.685056686401367
Validation loss: 2.296910447459067

Epoch: 6| Step: 6
Training loss: 2.2405571937561035
Validation loss: 2.2906504856642855

Epoch: 6| Step: 7
Training loss: 2.1569063663482666
Validation loss: 2.2821559572732575

Epoch: 6| Step: 8
Training loss: 2.975825071334839
Validation loss: 2.288214486132386

Epoch: 6| Step: 9
Training loss: 2.6460115909576416
Validation loss: 2.294722718577231

Epoch: 6| Step: 10
Training loss: 2.1422348022460938
Validation loss: 2.290998174298194

Epoch: 6| Step: 11
Training loss: 2.488819122314453
Validation loss: 2.2827841107563307

Epoch: 6| Step: 12
Training loss: 2.8924014568328857
Validation loss: 2.2871159430473083

Epoch: 6| Step: 13
Training loss: 3.061023473739624
Validation loss: 2.285226919317758

Epoch: 229| Step: 0
Training loss: 2.0410642623901367
Validation loss: 2.284885065529936

Epoch: 6| Step: 1
Training loss: 3.390491008758545
Validation loss: 2.2900784015655518

Epoch: 6| Step: 2
Training loss: 1.7729052305221558
Validation loss: 2.282628574678975

Epoch: 6| Step: 3
Training loss: 2.2125320434570312
Validation loss: 2.287051672576576

Epoch: 6| Step: 4
Training loss: 2.055752992630005
Validation loss: 2.2894285878827496

Epoch: 6| Step: 5
Training loss: 2.691389560699463
Validation loss: 2.291417398760396

Epoch: 6| Step: 6
Training loss: 2.877396583557129
Validation loss: 2.2954179151083833

Epoch: 6| Step: 7
Training loss: 2.5980687141418457
Validation loss: 2.2967237721207323

Epoch: 6| Step: 8
Training loss: 2.560574531555176
Validation loss: 2.299537435654671

Epoch: 6| Step: 9
Training loss: 1.7552928924560547
Validation loss: 2.3039896924008607

Epoch: 6| Step: 10
Training loss: 2.997847080230713
Validation loss: 2.3036087123296594

Epoch: 6| Step: 11
Training loss: 2.6599977016448975
Validation loss: 2.2937913146070255

Epoch: 6| Step: 12
Training loss: 2.948451280593872
Validation loss: 2.3079575261762066

Epoch: 6| Step: 13
Training loss: 2.4927749633789062
Validation loss: 2.3016466274056384

Epoch: 230| Step: 0
Training loss: 2.7345619201660156
Validation loss: 2.3078423494933755

Epoch: 6| Step: 1
Training loss: 2.585826873779297
Validation loss: 2.3115734284923923

Epoch: 6| Step: 2
Training loss: 2.3249154090881348
Validation loss: 2.307101862404936

Epoch: 6| Step: 3
Training loss: 2.024505376815796
Validation loss: 2.3127790856105026

Epoch: 6| Step: 4
Training loss: 2.539315938949585
Validation loss: 2.303726619289767

Epoch: 6| Step: 5
Training loss: 1.9034745693206787
Validation loss: 2.2938503091053297

Epoch: 6| Step: 6
Training loss: 2.7488255500793457
Validation loss: 2.295042427637244

Epoch: 6| Step: 7
Training loss: 2.7797372341156006
Validation loss: 2.2922972197173745

Epoch: 6| Step: 8
Training loss: 2.6209592819213867
Validation loss: 2.2767964857880787

Epoch: 6| Step: 9
Training loss: 2.476990222930908
Validation loss: 2.2815791406939105

Epoch: 6| Step: 10
Training loss: 2.899972438812256
Validation loss: 2.2975452228259017

Epoch: 6| Step: 11
Training loss: 2.871762752532959
Validation loss: 2.298854758662562

Epoch: 6| Step: 12
Training loss: 2.3291258811950684
Validation loss: 2.2989584348535024

Epoch: 6| Step: 13
Training loss: 2.1385414600372314
Validation loss: 2.2940474556338404

Epoch: 231| Step: 0
Training loss: 2.3825623989105225
Validation loss: 2.29351701787723

Epoch: 6| Step: 1
Training loss: 2.9730634689331055
Validation loss: 2.288020923573484

Epoch: 6| Step: 2
Training loss: 2.8407440185546875
Validation loss: 2.2833216344156573

Epoch: 6| Step: 3
Training loss: 2.8238022327423096
Validation loss: 2.2769381692332606

Epoch: 6| Step: 4
Training loss: 2.7326719760894775
Validation loss: 2.27851507740636

Epoch: 6| Step: 5
Training loss: 2.7831780910491943
Validation loss: 2.282387461713565

Epoch: 6| Step: 6
Training loss: 2.563861846923828
Validation loss: 2.2871556025679394

Epoch: 6| Step: 7
Training loss: 2.6466622352600098
Validation loss: 2.2785639186059274

Epoch: 6| Step: 8
Training loss: 2.230088710784912
Validation loss: 2.2809532483418784

Epoch: 6| Step: 9
Training loss: 2.6554317474365234
Validation loss: 2.274118423461914

Epoch: 6| Step: 10
Training loss: 2.1849026679992676
Validation loss: 2.2786811987559

Epoch: 6| Step: 11
Training loss: 2.0562312602996826
Validation loss: 2.2819481331815004

Epoch: 6| Step: 12
Training loss: 2.276097536087036
Validation loss: 2.2933023668104604

Epoch: 6| Step: 13
Training loss: 1.4872902631759644
Validation loss: 2.2936403648827666

Epoch: 232| Step: 0
Training loss: 2.228135347366333
Validation loss: 2.3026511412794872

Epoch: 6| Step: 1
Training loss: 2.0996665954589844
Validation loss: 2.3210358722235567

Epoch: 6| Step: 2
Training loss: 1.9022845029830933
Validation loss: 2.3186588030989452

Epoch: 6| Step: 3
Training loss: 2.6234190464019775
Validation loss: 2.3361976146698

Epoch: 6| Step: 4
Training loss: 3.1272501945495605
Validation loss: 2.3359243792872273

Epoch: 6| Step: 5
Training loss: 2.167377471923828
Validation loss: 2.3528751250236266

Epoch: 6| Step: 6
Training loss: 2.844040870666504
Validation loss: 2.335211915354575

Epoch: 6| Step: 7
Training loss: 2.7376275062561035
Validation loss: 2.3181992089876564

Epoch: 6| Step: 8
Training loss: 2.497185230255127
Validation loss: 2.310430630560844

Epoch: 6| Step: 9
Training loss: 2.9895262718200684
Validation loss: 2.3018773063536613

Epoch: 6| Step: 10
Training loss: 2.570622205734253
Validation loss: 2.2990150810569845

Epoch: 6| Step: 11
Training loss: 2.392599582672119
Validation loss: 2.303515934175061

Epoch: 6| Step: 12
Training loss: 2.4302706718444824
Validation loss: 2.2860854876938688

Epoch: 6| Step: 13
Training loss: 2.7281203269958496
Validation loss: 2.2822304566701255

Epoch: 233| Step: 0
Training loss: 2.826563835144043
Validation loss: 2.2868603544850505

Epoch: 6| Step: 1
Training loss: 2.942702293395996
Validation loss: 2.2736547672620384

Epoch: 6| Step: 2
Training loss: 2.5364460945129395
Validation loss: 2.2694590501887824

Epoch: 6| Step: 3
Training loss: 2.7310256958007812
Validation loss: 2.2764032297236945

Epoch: 6| Step: 4
Training loss: 2.809360980987549
Validation loss: 2.270155352930869

Epoch: 6| Step: 5
Training loss: 2.6959104537963867
Validation loss: 2.2803133610756166

Epoch: 6| Step: 6
Training loss: 2.1615490913391113
Validation loss: 2.271592805462499

Epoch: 6| Step: 7
Training loss: 3.1457152366638184
Validation loss: 2.2726545487680743

Epoch: 6| Step: 8
Training loss: 2.48036789894104
Validation loss: 2.273465438555646

Epoch: 6| Step: 9
Training loss: 2.260043144226074
Validation loss: 2.275258082215504

Epoch: 6| Step: 10
Training loss: 2.294088840484619
Validation loss: 2.27389814904941

Epoch: 6| Step: 11
Training loss: 1.1528886556625366
Validation loss: 2.272746939812937

Epoch: 6| Step: 12
Training loss: 2.7973814010620117
Validation loss: 2.279029797482234

Epoch: 6| Step: 13
Training loss: 1.868827223777771
Validation loss: 2.2761282690109743

Epoch: 234| Step: 0
Training loss: 1.8069617748260498
Validation loss: 2.278258446724184

Epoch: 6| Step: 1
Training loss: 2.7332773208618164
Validation loss: 2.2841693227009108

Epoch: 6| Step: 2
Training loss: 2.1864938735961914
Validation loss: 2.2747603231860745

Epoch: 6| Step: 3
Training loss: 2.1215779781341553
Validation loss: 2.273132710046666

Epoch: 6| Step: 4
Training loss: 3.075981378555298
Validation loss: 2.274127782032054

Epoch: 6| Step: 5
Training loss: 2.7496120929718018
Validation loss: 2.2727961873495452

Epoch: 6| Step: 6
Training loss: 2.378995895385742
Validation loss: 2.288025786799769

Epoch: 6| Step: 7
Training loss: 2.6580605506896973
Validation loss: 2.2801979536651285

Epoch: 6| Step: 8
Training loss: 2.1821510791778564
Validation loss: 2.288626729801137

Epoch: 6| Step: 9
Training loss: 2.736018180847168
Validation loss: 2.2958804727882467

Epoch: 6| Step: 10
Training loss: 2.8375158309936523
Validation loss: 2.2985607424089984

Epoch: 6| Step: 11
Training loss: 2.377436399459839
Validation loss: 2.299417522645766

Epoch: 6| Step: 12
Training loss: 2.492180109024048
Validation loss: 2.3016568537681334

Epoch: 6| Step: 13
Training loss: 2.873196601867676
Validation loss: 2.3051383341512373

Epoch: 235| Step: 0
Training loss: 2.83237886428833
Validation loss: 2.3049513011850338

Epoch: 6| Step: 1
Training loss: 2.3676400184631348
Validation loss: 2.305287784145724

Epoch: 6| Step: 2
Training loss: 2.566798210144043
Validation loss: 2.29868681200089

Epoch: 6| Step: 3
Training loss: 1.9700684547424316
Validation loss: 2.285272449575445

Epoch: 6| Step: 4
Training loss: 3.1646487712860107
Validation loss: 2.285134220636019

Epoch: 6| Step: 5
Training loss: 3.200397491455078
Validation loss: 2.286396967467441

Epoch: 6| Step: 6
Training loss: 1.9552148580551147
Validation loss: 2.2763892399367465

Epoch: 6| Step: 7
Training loss: 2.4294774532318115
Validation loss: 2.2703921717982136

Epoch: 6| Step: 8
Training loss: 2.0574967861175537
Validation loss: 2.267363089387135

Epoch: 6| Step: 9
Training loss: 2.927213668823242
Validation loss: 2.2648432203518447

Epoch: 6| Step: 10
Training loss: 2.5617268085479736
Validation loss: 2.2636372684150614

Epoch: 6| Step: 11
Training loss: 2.6984171867370605
Validation loss: 2.279335227063907

Epoch: 6| Step: 12
Training loss: 2.1619033813476562
Validation loss: 2.290374481549827

Epoch: 6| Step: 13
Training loss: 1.795217752456665
Validation loss: 2.290249525859792

Epoch: 236| Step: 0
Training loss: 3.066345453262329
Validation loss: 2.2980431818193003

Epoch: 6| Step: 1
Training loss: 1.9867016077041626
Validation loss: 2.2976058375450874

Epoch: 6| Step: 2
Training loss: 2.6553430557250977
Validation loss: 2.3032295857706377

Epoch: 6| Step: 3
Training loss: 2.3813557624816895
Validation loss: 2.2998834258766583

Epoch: 6| Step: 4
Training loss: 2.4886016845703125
Validation loss: 2.2990215709132533

Epoch: 6| Step: 5
Training loss: 2.8039870262145996
Validation loss: 2.2887884032341743

Epoch: 6| Step: 6
Training loss: 2.4995245933532715
Validation loss: 2.2809053544075257

Epoch: 6| Step: 7
Training loss: 2.2213401794433594
Validation loss: 2.277818300390756

Epoch: 6| Step: 8
Training loss: 2.5962185859680176
Validation loss: 2.281863607386107

Epoch: 6| Step: 9
Training loss: 1.9020154476165771
Validation loss: 2.277484260579591

Epoch: 6| Step: 10
Training loss: 2.253469467163086
Validation loss: 2.2873770113914245

Epoch: 6| Step: 11
Training loss: 2.4949934482574463
Validation loss: 2.3058671130928943

Epoch: 6| Step: 12
Training loss: 2.768002510070801
Validation loss: 2.323035124809511

Epoch: 6| Step: 13
Training loss: 3.3729474544525146
Validation loss: 2.314516213632399

Epoch: 237| Step: 0
Training loss: 3.0263147354125977
Validation loss: 2.3084828725425144

Epoch: 6| Step: 1
Training loss: 2.680202007293701
Validation loss: 2.3176912940958494

Epoch: 6| Step: 2
Training loss: 2.4070444107055664
Validation loss: 2.3048412120470436

Epoch: 6| Step: 3
Training loss: 2.3488411903381348
Validation loss: 2.2923396582244546

Epoch: 6| Step: 4
Training loss: 2.5504891872406006
Validation loss: 2.2753396675150883

Epoch: 6| Step: 5
Training loss: 2.1778411865234375
Validation loss: 2.277564864004812

Epoch: 6| Step: 6
Training loss: 2.494112968444824
Validation loss: 2.2713325997834564

Epoch: 6| Step: 7
Training loss: 2.731205463409424
Validation loss: 2.2746560547941472

Epoch: 6| Step: 8
Training loss: 2.1997604370117188
Validation loss: 2.267686608017132

Epoch: 6| Step: 9
Training loss: 2.254682779312134
Validation loss: 2.275338647186115

Epoch: 6| Step: 10
Training loss: 2.288970470428467
Validation loss: 2.2752258290526686

Epoch: 6| Step: 11
Training loss: 2.771332263946533
Validation loss: 2.2822764445376653

Epoch: 6| Step: 12
Training loss: 2.6652486324310303
Validation loss: 2.2809243253482285

Epoch: 6| Step: 13
Training loss: 2.1739630699157715
Validation loss: 2.290542766612063

Epoch: 238| Step: 0
Training loss: 2.392810106277466
Validation loss: 2.2869921756047074

Epoch: 6| Step: 1
Training loss: 2.845517158508301
Validation loss: 2.280313079075147

Epoch: 6| Step: 2
Training loss: 2.271641254425049
Validation loss: 2.28770516380187

Epoch: 6| Step: 3
Training loss: 1.6830130815505981
Validation loss: 2.293525698364422

Epoch: 6| Step: 4
Training loss: 2.3744683265686035
Validation loss: 2.286462107012349

Epoch: 6| Step: 5
Training loss: 2.5235066413879395
Validation loss: 2.2881050417500157

Epoch: 6| Step: 6
Training loss: 2.6499786376953125
Validation loss: 2.290579370273057

Epoch: 6| Step: 7
Training loss: 3.111363410949707
Validation loss: 2.30050064158696

Epoch: 6| Step: 8
Training loss: 2.8327016830444336
Validation loss: 2.297779416525236

Epoch: 6| Step: 9
Training loss: 2.472464084625244
Validation loss: 2.2935300898808304

Epoch: 6| Step: 10
Training loss: 1.8548851013183594
Validation loss: 2.3040915202069026

Epoch: 6| Step: 11
Training loss: 2.5673341751098633
Validation loss: 2.3022661773107385

Epoch: 6| Step: 12
Training loss: 2.6623733043670654
Validation loss: 2.3057062689976027

Epoch: 6| Step: 13
Training loss: 2.6222176551818848
Validation loss: 2.305812430638139

Epoch: 239| Step: 0
Training loss: 2.2485477924346924
Validation loss: 2.2963148624666276

Epoch: 6| Step: 1
Training loss: 2.816688299179077
Validation loss: 2.2949539205079437

Epoch: 6| Step: 2
Training loss: 2.891497850418091
Validation loss: 2.2874779957596973

Epoch: 6| Step: 3
Training loss: 2.642954111099243
Validation loss: 2.2862061377494567

Epoch: 6| Step: 4
Training loss: 2.5151758193969727
Validation loss: 2.2763600016152985

Epoch: 6| Step: 5
Training loss: 2.3874804973602295
Validation loss: 2.2648750761503815

Epoch: 6| Step: 6
Training loss: 2.677032709121704
Validation loss: 2.264389843069097

Epoch: 6| Step: 7
Training loss: 2.340871810913086
Validation loss: 2.258372078659714

Epoch: 6| Step: 8
Training loss: 3.205075263977051
Validation loss: 2.2491519810051046

Epoch: 6| Step: 9
Training loss: 2.06801176071167
Validation loss: 2.2483326978580926

Epoch: 6| Step: 10
Training loss: 2.7976231575012207
Validation loss: 2.243774929354268

Epoch: 6| Step: 11
Training loss: 1.9060930013656616
Validation loss: 2.2569577642666396

Epoch: 6| Step: 12
Training loss: 2.3267152309417725
Validation loss: 2.2495238832248154

Epoch: 6| Step: 13
Training loss: 1.7620309591293335
Validation loss: 2.253343184789022

Epoch: 240| Step: 0
Training loss: 2.0819926261901855
Validation loss: 2.259540432242937

Epoch: 6| Step: 1
Training loss: 2.863070249557495
Validation loss: 2.2609732766305246

Epoch: 6| Step: 2
Training loss: 2.5091099739074707
Validation loss: 2.2601864658376223

Epoch: 6| Step: 3
Training loss: 2.8640544414520264
Validation loss: 2.2740543247551046

Epoch: 6| Step: 4
Training loss: 3.151301622390747
Validation loss: 2.2660850196756344

Epoch: 6| Step: 5
Training loss: 2.3225371837615967
Validation loss: 2.2657133430562992

Epoch: 6| Step: 6
Training loss: 1.9016984701156616
Validation loss: 2.257935708568942

Epoch: 6| Step: 7
Training loss: 2.4237136840820312
Validation loss: 2.2470545332918883

Epoch: 6| Step: 8
Training loss: 2.4301090240478516
Validation loss: 2.250211913098571

Epoch: 6| Step: 9
Training loss: 2.402825117111206
Validation loss: 2.2537257799538235

Epoch: 6| Step: 10
Training loss: 2.558102607727051
Validation loss: 2.2452749539447088

Epoch: 6| Step: 11
Training loss: 3.0621471405029297
Validation loss: 2.2366896137114494

Epoch: 6| Step: 12
Training loss: 1.918655276298523
Validation loss: 2.2507268203202115

Epoch: 6| Step: 13
Training loss: 2.425212860107422
Validation loss: 2.2486530042463735

Epoch: 241| Step: 0
Training loss: 2.3996996879577637
Validation loss: 2.252713026538972

Epoch: 6| Step: 1
Training loss: 2.4552783966064453
Validation loss: 2.2557418936042377

Epoch: 6| Step: 2
Training loss: 2.619112014770508
Validation loss: 2.2709120499190463

Epoch: 6| Step: 3
Training loss: 2.2503442764282227
Validation loss: 2.2713300053791334

Epoch: 6| Step: 4
Training loss: 3.0056300163269043
Validation loss: 2.268883551320722

Epoch: 6| Step: 5
Training loss: 2.366069793701172
Validation loss: 2.271767025352806

Epoch: 6| Step: 6
Training loss: 2.871516227722168
Validation loss: 2.2805330932781263

Epoch: 6| Step: 7
Training loss: 2.7717909812927246
Validation loss: 2.289400128908055

Epoch: 6| Step: 8
Training loss: 1.9137372970581055
Validation loss: 2.2870230238924742

Epoch: 6| Step: 9
Training loss: 2.643688917160034
Validation loss: 2.2778909719118507

Epoch: 6| Step: 10
Training loss: 2.745492458343506
Validation loss: 2.274917164156514

Epoch: 6| Step: 11
Training loss: 2.595735549926758
Validation loss: 2.273185374916241

Epoch: 6| Step: 12
Training loss: 1.8376052379608154
Validation loss: 2.2755599329548497

Epoch: 6| Step: 13
Training loss: 2.2420129776000977
Validation loss: 2.2595591673287014

Epoch: 242| Step: 0
Training loss: 2.474270820617676
Validation loss: 2.272234711595761

Epoch: 6| Step: 1
Training loss: 2.3415231704711914
Validation loss: 2.2816804314172394

Epoch: 6| Step: 2
Training loss: 2.7539710998535156
Validation loss: 2.291216517007479

Epoch: 6| Step: 3
Training loss: 1.9214411973953247
Validation loss: 2.2999544374404417

Epoch: 6| Step: 4
Training loss: 1.580111026763916
Validation loss: 2.2903891712106685

Epoch: 6| Step: 5
Training loss: 2.6354832649230957
Validation loss: 2.307643111034106

Epoch: 6| Step: 6
Training loss: 2.6346209049224854
Validation loss: 2.2934185048585296

Epoch: 6| Step: 7
Training loss: 2.767390489578247
Validation loss: 2.2798373160823697

Epoch: 6| Step: 8
Training loss: 2.6325225830078125
Validation loss: 2.2801574481430875

Epoch: 6| Step: 9
Training loss: 2.472257614135742
Validation loss: 2.2609878150365685

Epoch: 6| Step: 10
Training loss: 2.679795980453491
Validation loss: 2.264905701401413

Epoch: 6| Step: 11
Training loss: 2.4037365913391113
Validation loss: 2.261592367643951

Epoch: 6| Step: 12
Training loss: 2.7634382247924805
Validation loss: 2.2608526445204213

Epoch: 6| Step: 13
Training loss: 3.0436208248138428
Validation loss: 2.258900555231238

Epoch: 243| Step: 0
Training loss: 2.0696158409118652
Validation loss: 2.2627656511081162

Epoch: 6| Step: 1
Training loss: 2.641394853591919
Validation loss: 2.277578869173604

Epoch: 6| Step: 2
Training loss: 2.428863286972046
Validation loss: 2.2693666386347946

Epoch: 6| Step: 3
Training loss: 3.3318991661071777
Validation loss: 2.2692641340276247

Epoch: 6| Step: 4
Training loss: 3.2561070919036865
Validation loss: 2.266731433970954

Epoch: 6| Step: 5
Training loss: 2.4873361587524414
Validation loss: 2.274492891885901

Epoch: 6| Step: 6
Training loss: 2.9496121406555176
Validation loss: 2.27452879054572

Epoch: 6| Step: 7
Training loss: 2.330085277557373
Validation loss: 2.262329702736229

Epoch: 6| Step: 8
Training loss: 2.5708799362182617
Validation loss: 2.274005461764592

Epoch: 6| Step: 9
Training loss: 2.4582786560058594
Validation loss: 2.266162624923132

Epoch: 6| Step: 10
Training loss: 1.3882323503494263
Validation loss: 2.2636018081377913

Epoch: 6| Step: 11
Training loss: 2.3530068397521973
Validation loss: 2.26789431418142

Epoch: 6| Step: 12
Training loss: 2.1638078689575195
Validation loss: 2.2670789252045336

Epoch: 6| Step: 13
Training loss: 1.8497276306152344
Validation loss: 2.2553978761037192

Epoch: 244| Step: 0
Training loss: 2.3705201148986816
Validation loss: 2.2770605343644337

Epoch: 6| Step: 1
Training loss: 2.4695205688476562
Validation loss: 2.282181975662067

Epoch: 6| Step: 2
Training loss: 1.9768779277801514
Validation loss: 2.2849739238780034

Epoch: 6| Step: 3
Training loss: 2.4634954929351807
Validation loss: 2.2804021732781523

Epoch: 6| Step: 4
Training loss: 2.3293139934539795
Validation loss: 2.2752451999213106

Epoch: 6| Step: 5
Training loss: 2.5487616062164307
Validation loss: 2.263911049853089

Epoch: 6| Step: 6
Training loss: 3.0932750701904297
Validation loss: 2.257986173834852

Epoch: 6| Step: 7
Training loss: 2.846083879470825
Validation loss: 2.2690425957402875

Epoch: 6| Step: 8
Training loss: 3.044387102127075
Validation loss: 2.2741424524655907

Epoch: 6| Step: 9
Training loss: 2.8308706283569336
Validation loss: 2.259266743095972

Epoch: 6| Step: 10
Training loss: 1.801459550857544
Validation loss: 2.2668003702676423

Epoch: 6| Step: 11
Training loss: 2.040952682495117
Validation loss: 2.2642802038500385

Epoch: 6| Step: 12
Training loss: 2.0967960357666016
Validation loss: 2.2821222941080728

Epoch: 6| Step: 13
Training loss: 3.01322340965271
Validation loss: 2.2997822325716735

Epoch: 245| Step: 0
Training loss: 3.020531177520752
Validation loss: 2.2970280980551117

Epoch: 6| Step: 1
Training loss: 2.3817458152770996
Validation loss: 2.288082456076017

Epoch: 6| Step: 2
Training loss: 2.2362418174743652
Validation loss: 2.292354222266905

Epoch: 6| Step: 3
Training loss: 2.3106675148010254
Validation loss: 2.291429602971641

Epoch: 6| Step: 4
Training loss: 2.6231136322021484
Validation loss: 2.2996508152254167

Epoch: 6| Step: 5
Training loss: 2.7489187717437744
Validation loss: 2.30156772880144

Epoch: 6| Step: 6
Training loss: 2.869668483734131
Validation loss: 2.303467668512816

Epoch: 6| Step: 7
Training loss: 2.0636632442474365
Validation loss: 2.292703572139945

Epoch: 6| Step: 8
Training loss: 3.1726062297821045
Validation loss: 2.295863310496012

Epoch: 6| Step: 9
Training loss: 2.8278391361236572
Validation loss: 2.290448614346084

Epoch: 6| Step: 10
Training loss: 2.241225242614746
Validation loss: 2.2847923309572282

Epoch: 6| Step: 11
Training loss: 2.0040512084960938
Validation loss: 2.2790137644737

Epoch: 6| Step: 12
Training loss: 2.3692867755889893
Validation loss: 2.270377764137842

Epoch: 6| Step: 13
Training loss: 1.0865999460220337
Validation loss: 2.2766829921353247

Epoch: 246| Step: 0
Training loss: 2.101210832595825
Validation loss: 2.2761683079504196

Epoch: 6| Step: 1
Training loss: 2.7447738647460938
Validation loss: 2.2744966450557915

Epoch: 6| Step: 2
Training loss: 2.382009506225586
Validation loss: 2.272610023457517

Epoch: 6| Step: 3
Training loss: 2.9414539337158203
Validation loss: 2.2621428761430966

Epoch: 6| Step: 4
Training loss: 2.4178953170776367
Validation loss: 2.276491836834979

Epoch: 6| Step: 5
Training loss: 2.240739583969116
Validation loss: 2.2777628462801696

Epoch: 6| Step: 6
Training loss: 2.155898094177246
Validation loss: 2.2849541223177345

Epoch: 6| Step: 7
Training loss: 3.002929210662842
Validation loss: 2.2655225364110803

Epoch: 6| Step: 8
Training loss: 2.5628342628479004
Validation loss: 2.2610808085369807

Epoch: 6| Step: 9
Training loss: 2.9670817852020264
Validation loss: 2.261960644875803

Epoch: 6| Step: 10
Training loss: 2.0223138332366943
Validation loss: 2.257691203906972

Epoch: 6| Step: 11
Training loss: 2.612489700317383
Validation loss: 2.2568657500769502

Epoch: 6| Step: 12
Training loss: 2.2934248447418213
Validation loss: 2.2517859833214873

Epoch: 6| Step: 13
Training loss: 1.8191494941711426
Validation loss: 2.2555660893840175

Epoch: 247| Step: 0
Training loss: 2.09071683883667
Validation loss: 2.2577904449996127

Epoch: 6| Step: 1
Training loss: 2.210205316543579
Validation loss: 2.2570741138150616

Epoch: 6| Step: 2
Training loss: 1.8529468774795532
Validation loss: 2.263287240459073

Epoch: 6| Step: 3
Training loss: 2.3563015460968018
Validation loss: 2.262157483767438

Epoch: 6| Step: 4
Training loss: 1.8454524278640747
Validation loss: 2.254350298194475

Epoch: 6| Step: 5
Training loss: 3.1403918266296387
Validation loss: 2.2658609651750132

Epoch: 6| Step: 6
Training loss: 2.2087059020996094
Validation loss: 2.277477095204015

Epoch: 6| Step: 7
Training loss: 2.845418691635132
Validation loss: 2.2744249066998883

Epoch: 6| Step: 8
Training loss: 2.706211566925049
Validation loss: 2.281490789946689

Epoch: 6| Step: 9
Training loss: 2.3604061603546143
Validation loss: 2.2658991826477872

Epoch: 6| Step: 10
Training loss: 2.3602235317230225
Validation loss: 2.2652417511068363

Epoch: 6| Step: 11
Training loss: 2.9838321208953857
Validation loss: 2.2671323489117365

Epoch: 6| Step: 12
Training loss: 2.7053122520446777
Validation loss: 2.2693009684162755

Epoch: 6| Step: 13
Training loss: 2.9281821250915527
Validation loss: 2.256969298085859

Epoch: 248| Step: 0
Training loss: 2.9517722129821777
Validation loss: 2.263130226442891

Epoch: 6| Step: 1
Training loss: 2.887862205505371
Validation loss: 2.2555972171086136

Epoch: 6| Step: 2
Training loss: 2.294647693634033
Validation loss: 2.2445084318037956

Epoch: 6| Step: 3
Training loss: 2.2869701385498047
Validation loss: 2.2412278498372724

Epoch: 6| Step: 4
Training loss: 2.2812342643737793
Validation loss: 2.2553988579780824

Epoch: 6| Step: 5
Training loss: 1.8066778182983398
Validation loss: 2.235918034789383

Epoch: 6| Step: 6
Training loss: 2.5472331047058105
Validation loss: 2.2392788958805863

Epoch: 6| Step: 7
Training loss: 2.496917247772217
Validation loss: 2.245892878501646

Epoch: 6| Step: 8
Training loss: 2.73063325881958
Validation loss: 2.249406886357133

Epoch: 6| Step: 9
Training loss: 2.271052598953247
Validation loss: 2.2516718756768013

Epoch: 6| Step: 10
Training loss: 2.240196704864502
Validation loss: 2.2491397575665544

Epoch: 6| Step: 11
Training loss: 2.298745632171631
Validation loss: 2.251672713987289

Epoch: 6| Step: 12
Training loss: 2.327028512954712
Validation loss: 2.254082695130379

Epoch: 6| Step: 13
Training loss: 3.3235654830932617
Validation loss: 2.246418747850644

Epoch: 249| Step: 0
Training loss: 3.1920671463012695
Validation loss: 2.2577175299326577

Epoch: 6| Step: 1
Training loss: 2.234247922897339
Validation loss: 2.2615837127931657

Epoch: 6| Step: 2
Training loss: 2.6694867610931396
Validation loss: 2.2640965728349585

Epoch: 6| Step: 3
Training loss: 2.193300247192383
Validation loss: 2.253059246206796

Epoch: 6| Step: 4
Training loss: 2.1666784286499023
Validation loss: 2.2617235491352696

Epoch: 6| Step: 5
Training loss: 2.047156810760498
Validation loss: 2.2639276596807663

Epoch: 6| Step: 6
Training loss: 2.975640058517456
Validation loss: 2.273774749489241

Epoch: 6| Step: 7
Training loss: 2.6298208236694336
Validation loss: 2.275987858413368

Epoch: 6| Step: 8
Training loss: 1.6500461101531982
Validation loss: 2.2744845472356325

Epoch: 6| Step: 9
Training loss: 2.0356640815734863
Validation loss: 2.2799572111457906

Epoch: 6| Step: 10
Training loss: 2.7888617515563965
Validation loss: 2.2820900614543627

Epoch: 6| Step: 11
Training loss: 2.797487258911133
Validation loss: 2.277971875283026

Epoch: 6| Step: 12
Training loss: 2.2744460105895996
Validation loss: 2.2756987643498245

Epoch: 6| Step: 13
Training loss: 2.8948960304260254
Validation loss: 2.2782225403734433

Epoch: 250| Step: 0
Training loss: 2.980591058731079
Validation loss: 2.275652498327276

Epoch: 6| Step: 1
Training loss: 2.1280763149261475
Validation loss: 2.2671572700623543

Epoch: 6| Step: 2
Training loss: 2.1433634757995605
Validation loss: 2.258146401374571

Epoch: 6| Step: 3
Training loss: 2.268801212310791
Validation loss: 2.270744646749189

Epoch: 6| Step: 4
Training loss: 2.9891295433044434
Validation loss: 2.2683926705391175

Epoch: 6| Step: 5
Training loss: 2.4337501525878906
Validation loss: 2.2431957837074035

Epoch: 6| Step: 6
Training loss: 2.8439745903015137
Validation loss: 2.2451059100448445

Epoch: 6| Step: 7
Training loss: 1.9367432594299316
Validation loss: 2.239253500456451

Epoch: 6| Step: 8
Training loss: 1.919782280921936
Validation loss: 2.236866153696532

Epoch: 6| Step: 9
Training loss: 2.424140453338623
Validation loss: 2.2453432749676447

Epoch: 6| Step: 10
Training loss: 1.8532297611236572
Validation loss: 2.2321086647689983

Epoch: 6| Step: 11
Training loss: 3.568208694458008
Validation loss: 2.233523779017951

Epoch: 6| Step: 12
Training loss: 2.832712411880493
Validation loss: 2.236899975807436

Epoch: 6| Step: 13
Training loss: 1.9227286577224731
Validation loss: 2.2475017886007986

Epoch: 251| Step: 0
Training loss: 3.027961492538452
Validation loss: 2.242137993535688

Epoch: 6| Step: 1
Training loss: 2.6274352073669434
Validation loss: 2.2477863860386673

Epoch: 6| Step: 2
Training loss: 2.1256356239318848
Validation loss: 2.246050009163477

Epoch: 6| Step: 3
Training loss: 1.526951789855957
Validation loss: 2.239990818885065

Epoch: 6| Step: 4
Training loss: 2.1368632316589355
Validation loss: 2.243244037833265

Epoch: 6| Step: 5
Training loss: 3.089829444885254
Validation loss: 2.2484371149411766

Epoch: 6| Step: 6
Training loss: 2.760120391845703
Validation loss: 2.259148156771096

Epoch: 6| Step: 7
Training loss: 1.6502149105072021
Validation loss: 2.2541961195648357

Epoch: 6| Step: 8
Training loss: 3.1128876209259033
Validation loss: 2.244233241645239

Epoch: 6| Step: 9
Training loss: 2.511136054992676
Validation loss: 2.2481791050203386

Epoch: 6| Step: 10
Training loss: 2.564314126968384
Validation loss: 2.2414122627627466

Epoch: 6| Step: 11
Training loss: 2.5404977798461914
Validation loss: 2.240712786233553

Epoch: 6| Step: 12
Training loss: 2.1827893257141113
Validation loss: 2.236958101231565

Epoch: 6| Step: 13
Training loss: 2.4946506023406982
Validation loss: 2.232836781009551

Epoch: 252| Step: 0
Training loss: 1.7283461093902588
Validation loss: 2.231888576220441

Epoch: 6| Step: 1
Training loss: 3.1351561546325684
Validation loss: 2.246754812937911

Epoch: 6| Step: 2
Training loss: 2.7156360149383545
Validation loss: 2.2592235072966544

Epoch: 6| Step: 3
Training loss: 2.75063157081604
Validation loss: 2.282045441289102

Epoch: 6| Step: 4
Training loss: 2.7361035346984863
Validation loss: 2.275355677450857

Epoch: 6| Step: 5
Training loss: 2.0070197582244873
Validation loss: 2.2831729201860327

Epoch: 6| Step: 6
Training loss: 1.9536325931549072
Validation loss: 2.2830751954868274

Epoch: 6| Step: 7
Training loss: 2.798750877380371
Validation loss: 2.267978081139185

Epoch: 6| Step: 8
Training loss: 1.525848150253296
Validation loss: 2.2745045795235583

Epoch: 6| Step: 9
Training loss: 2.821333885192871
Validation loss: 2.260433325203516

Epoch: 6| Step: 10
Training loss: 2.8827342987060547
Validation loss: 2.2588998681755474

Epoch: 6| Step: 11
Training loss: 2.2037999629974365
Validation loss: 2.267076897364791

Epoch: 6| Step: 12
Training loss: 2.533663272857666
Validation loss: 2.266692905015843

Epoch: 6| Step: 13
Training loss: 2.976357936859131
Validation loss: 2.2677221144399335

Epoch: 253| Step: 0
Training loss: 2.1887569427490234
Validation loss: 2.275877260392712

Epoch: 6| Step: 1
Training loss: 2.090092182159424
Validation loss: 2.2661459753590245

Epoch: 6| Step: 2
Training loss: 1.5385888814926147
Validation loss: 2.2616517184883036

Epoch: 6| Step: 3
Training loss: 2.2300195693969727
Validation loss: 2.254617214202881

Epoch: 6| Step: 4
Training loss: 2.8021886348724365
Validation loss: 2.2342493239269463

Epoch: 6| Step: 5
Training loss: 2.142756223678589
Validation loss: 2.229824314835251

Epoch: 6| Step: 6
Training loss: 1.9272346496582031
Validation loss: 2.2294551787837857

Epoch: 6| Step: 7
Training loss: 3.332711696624756
Validation loss: 2.2294444550750074

Epoch: 6| Step: 8
Training loss: 2.0749452114105225
Validation loss: 2.2355417102895756

Epoch: 6| Step: 9
Training loss: 2.8432328701019287
Validation loss: 2.2387776579908145

Epoch: 6| Step: 10
Training loss: 3.141171932220459
Validation loss: 2.2422321996381207

Epoch: 6| Step: 11
Training loss: 2.8460092544555664
Validation loss: 2.243373493994436

Epoch: 6| Step: 12
Training loss: 2.6667656898498535
Validation loss: 2.2404023908799693

Epoch: 6| Step: 13
Training loss: 2.6856861114501953
Validation loss: 2.251505961982153

Epoch: 254| Step: 0
Training loss: 2.262483596801758
Validation loss: 2.2456784914898615

Epoch: 6| Step: 1
Training loss: 2.844053030014038
Validation loss: 2.256113306168587

Epoch: 6| Step: 2
Training loss: 2.828603506088257
Validation loss: 2.248864545617052

Epoch: 6| Step: 3
Training loss: 2.7462329864501953
Validation loss: 2.257924541350334

Epoch: 6| Step: 4
Training loss: 1.9161977767944336
Validation loss: 2.2550878076143164

Epoch: 6| Step: 5
Training loss: 2.3575620651245117
Validation loss: 2.2510183626605618

Epoch: 6| Step: 6
Training loss: 2.1807608604431152
Validation loss: 2.2558769590111187

Epoch: 6| Step: 7
Training loss: 2.5248217582702637
Validation loss: 2.2669642176679385

Epoch: 6| Step: 8
Training loss: 1.8699660301208496
Validation loss: 2.2703982783902075

Epoch: 6| Step: 9
Training loss: 2.4731786251068115
Validation loss: 2.261177629552862

Epoch: 6| Step: 10
Training loss: 2.3666749000549316
Validation loss: 2.2614263360218336

Epoch: 6| Step: 11
Training loss: 2.647447347640991
Validation loss: 2.259827454884847

Epoch: 6| Step: 12
Training loss: 2.2787861824035645
Validation loss: 2.270106651449716

Epoch: 6| Step: 13
Training loss: 3.284886360168457
Validation loss: 2.2879354248764696

Epoch: 255| Step: 0
Training loss: 1.9976153373718262
Validation loss: 2.2814331234142347

Epoch: 6| Step: 1
Training loss: 2.0533061027526855
Validation loss: 2.2716202633355254

Epoch: 6| Step: 2
Training loss: 2.9773783683776855
Validation loss: 2.2753407314259517

Epoch: 6| Step: 3
Training loss: 1.837759256362915
Validation loss: 2.270228914035264

Epoch: 6| Step: 4
Training loss: 2.593470573425293
Validation loss: 2.2673439787280176

Epoch: 6| Step: 5
Training loss: 2.509695053100586
Validation loss: 2.2581776726630425

Epoch: 6| Step: 6
Training loss: 3.0610153675079346
Validation loss: 2.255358842111403

Epoch: 6| Step: 7
Training loss: 2.8011631965637207
Validation loss: 2.2521658712817776

Epoch: 6| Step: 8
Training loss: 1.8831603527069092
Validation loss: 2.251757683292512

Epoch: 6| Step: 9
Training loss: 2.1270885467529297
Validation loss: 2.257419240090155

Epoch: 6| Step: 10
Training loss: 3.016305923461914
Validation loss: 2.254298507526357

Epoch: 6| Step: 11
Training loss: 2.373302936553955
Validation loss: 2.2423076398911013

Epoch: 6| Step: 12
Training loss: 2.604769706726074
Validation loss: 2.2577791393444104

Epoch: 6| Step: 13
Training loss: 2.4934489727020264
Validation loss: 2.236112703559219

Epoch: 256| Step: 0
Training loss: 1.9452913999557495
Validation loss: 2.2369016652466147

Epoch: 6| Step: 1
Training loss: 2.2726855278015137
Validation loss: 2.2357149034418087

Epoch: 6| Step: 2
Training loss: 2.0813443660736084
Validation loss: 2.240637933054278

Epoch: 6| Step: 3
Training loss: 2.3835203647613525
Validation loss: 2.2465206115476546

Epoch: 6| Step: 4
Training loss: 3.0110745429992676
Validation loss: 2.2369705938523814

Epoch: 6| Step: 5
Training loss: 3.121295213699341
Validation loss: 2.2411604542886057

Epoch: 6| Step: 6
Training loss: 3.006330728530884
Validation loss: 2.2367844658513225

Epoch: 6| Step: 7
Training loss: 1.7826831340789795
Validation loss: 2.257534985901207

Epoch: 6| Step: 8
Training loss: 2.112260341644287
Validation loss: 2.243957027312248

Epoch: 6| Step: 9
Training loss: 2.5055348873138428
Validation loss: 2.247366561684557

Epoch: 6| Step: 10
Training loss: 3.1036014556884766
Validation loss: 2.2441718219428934

Epoch: 6| Step: 11
Training loss: 2.311769962310791
Validation loss: 2.238003833319551

Epoch: 6| Step: 12
Training loss: 2.028886318206787
Validation loss: 2.2477402481981503

Epoch: 6| Step: 13
Training loss: 2.36163330078125
Validation loss: 2.2455995787856398

Epoch: 257| Step: 0
Training loss: 2.7769370079040527
Validation loss: 2.249022723526083

Epoch: 6| Step: 1
Training loss: 2.5103509426116943
Validation loss: 2.261180522621319

Epoch: 6| Step: 2
Training loss: 2.6009738445281982
Validation loss: 2.251822981783139

Epoch: 6| Step: 3
Training loss: 1.3913969993591309
Validation loss: 2.2670025364045174

Epoch: 6| Step: 4
Training loss: 2.427781105041504
Validation loss: 2.2728474383713095

Epoch: 6| Step: 5
Training loss: 2.057727813720703
Validation loss: 2.2731523436884724

Epoch: 6| Step: 6
Training loss: 2.521092176437378
Validation loss: 2.2775149883762484

Epoch: 6| Step: 7
Training loss: 2.663313865661621
Validation loss: 2.272469392386816

Epoch: 6| Step: 8
Training loss: 2.402785301208496
Validation loss: 2.274487877404818

Epoch: 6| Step: 9
Training loss: 1.940015196800232
Validation loss: 2.262726089005829

Epoch: 6| Step: 10
Training loss: 2.828012466430664
Validation loss: 2.2615877248907603

Epoch: 6| Step: 11
Training loss: 2.8168466091156006
Validation loss: 2.2612434561534593

Epoch: 6| Step: 12
Training loss: 2.4940097332000732
Validation loss: 2.2546023758508826

Epoch: 6| Step: 13
Training loss: 2.9531543254852295
Validation loss: 2.244486537030948

Epoch: 258| Step: 0
Training loss: 2.2013473510742188
Validation loss: 2.240093446546985

Epoch: 6| Step: 1
Training loss: 3.063460111618042
Validation loss: 2.230313460032145

Epoch: 6| Step: 2
Training loss: 2.3434627056121826
Validation loss: 2.22004577677737

Epoch: 6| Step: 3
Training loss: 2.2680861949920654
Validation loss: 2.222089704646859

Epoch: 6| Step: 4
Training loss: 2.033236026763916
Validation loss: 2.211872741740237

Epoch: 6| Step: 5
Training loss: 1.7247251272201538
Validation loss: 2.2184702529702136

Epoch: 6| Step: 6
Training loss: 2.0634875297546387
Validation loss: 2.213218555655531

Epoch: 6| Step: 7
Training loss: 2.744492530822754
Validation loss: 2.2179120215036536

Epoch: 6| Step: 8
Training loss: 2.368283748626709
Validation loss: 2.211683977034784

Epoch: 6| Step: 9
Training loss: 2.9124464988708496
Validation loss: 2.2144293400549118

Epoch: 6| Step: 10
Training loss: 2.0448617935180664
Validation loss: 2.2193014749916653

Epoch: 6| Step: 11
Training loss: 2.697671413421631
Validation loss: 2.2221588344984156

Epoch: 6| Step: 12
Training loss: 2.8281238079071045
Validation loss: 2.238978175706761

Epoch: 6| Step: 13
Training loss: 3.236801862716675
Validation loss: 2.2397922777360484

Epoch: 259| Step: 0
Training loss: 3.1876320838928223
Validation loss: 2.238077591824275

Epoch: 6| Step: 1
Training loss: 2.6014938354492188
Validation loss: 2.23300487508056

Epoch: 6| Step: 2
Training loss: 3.0264217853546143
Validation loss: 2.2338726123174033

Epoch: 6| Step: 3
Training loss: 2.6289784908294678
Validation loss: 2.2317222856706187

Epoch: 6| Step: 4
Training loss: 2.2986679077148438
Validation loss: 2.2206797907429356

Epoch: 6| Step: 5
Training loss: 1.660519003868103
Validation loss: 2.2284855611862673

Epoch: 6| Step: 6
Training loss: 1.6947027444839478
Validation loss: 2.2422806011733187

Epoch: 6| Step: 7
Training loss: 2.5103063583374023
Validation loss: 2.2413028875986734

Epoch: 6| Step: 8
Training loss: 2.3337783813476562
Validation loss: 2.253931586460401

Epoch: 6| Step: 9
Training loss: 2.2516326904296875
Validation loss: 2.2544838843807096

Epoch: 6| Step: 10
Training loss: 2.304765224456787
Validation loss: 2.254132309267598

Epoch: 6| Step: 11
Training loss: 3.4862582683563232
Validation loss: 2.248482299107377

Epoch: 6| Step: 12
Training loss: 2.080235004425049
Validation loss: 2.235490579758921

Epoch: 6| Step: 13
Training loss: 1.8153806924819946
Validation loss: 2.2505988203069216

Epoch: 260| Step: 0
Training loss: 2.6739277839660645
Validation loss: 2.2444323211587887

Epoch: 6| Step: 1
Training loss: 2.455659866333008
Validation loss: 2.2471119511512017

Epoch: 6| Step: 2
Training loss: 2.1693673133850098
Validation loss: 2.240557066855892

Epoch: 6| Step: 3
Training loss: 1.993343472480774
Validation loss: 2.2438528307022585

Epoch: 6| Step: 4
Training loss: 2.0715417861938477
Validation loss: 2.243350675029139

Epoch: 6| Step: 5
Training loss: 1.8571033477783203
Validation loss: 2.2552155512635426

Epoch: 6| Step: 6
Training loss: 3.64383602142334
Validation loss: 2.243371812246179

Epoch: 6| Step: 7
Training loss: 2.5380663871765137
Validation loss: 2.2359294942630235

Epoch: 6| Step: 8
Training loss: 2.353822946548462
Validation loss: 2.237193089659496

Epoch: 6| Step: 9
Training loss: 2.2628841400146484
Validation loss: 2.2438060442606607

Epoch: 6| Step: 10
Training loss: 2.655705213546753
Validation loss: 2.2548106203797045

Epoch: 6| Step: 11
Training loss: 2.7865123748779297
Validation loss: 2.255953909248434

Epoch: 6| Step: 12
Training loss: 2.7054481506347656
Validation loss: 2.2575400260186966

Epoch: 6| Step: 13
Training loss: 1.5208470821380615
Validation loss: 2.2647635808555027

Epoch: 261| Step: 0
Training loss: 2.193399429321289
Validation loss: 2.250938210436093

Epoch: 6| Step: 1
Training loss: 2.9117817878723145
Validation loss: 2.2633324643617034

Epoch: 6| Step: 2
Training loss: 2.6429758071899414
Validation loss: 2.247730093617593

Epoch: 6| Step: 3
Training loss: 2.005110740661621
Validation loss: 2.244141940147646

Epoch: 6| Step: 4
Training loss: 2.229234457015991
Validation loss: 2.25060099171054

Epoch: 6| Step: 5
Training loss: 2.801051616668701
Validation loss: 2.252415774970926

Epoch: 6| Step: 6
Training loss: 3.053351402282715
Validation loss: 2.2533142259044032

Epoch: 6| Step: 7
Training loss: 2.2316315174102783
Validation loss: 2.2605489992326304

Epoch: 6| Step: 8
Training loss: 2.7981836795806885
Validation loss: 2.265218911632415

Epoch: 6| Step: 9
Training loss: 2.549511432647705
Validation loss: 2.246724395341771

Epoch: 6| Step: 10
Training loss: 2.087573528289795
Validation loss: 2.241422671143727

Epoch: 6| Step: 11
Training loss: 1.7875161170959473
Validation loss: 2.2385468124061503

Epoch: 6| Step: 12
Training loss: 2.6569409370422363
Validation loss: 2.235517737685993

Epoch: 6| Step: 13
Training loss: 2.1002132892608643
Validation loss: 2.223722706558884

Epoch: 262| Step: 0
Training loss: 2.040097951889038
Validation loss: 2.229103470361361

Epoch: 6| Step: 1
Training loss: 2.9530856609344482
Validation loss: 2.2392718253597135

Epoch: 6| Step: 2
Training loss: 2.3759090900421143
Validation loss: 2.232822584849532

Epoch: 6| Step: 3
Training loss: 2.5326554775238037
Validation loss: 2.2342184282118276

Epoch: 6| Step: 4
Training loss: 2.3997697830200195
Validation loss: 2.229148009771942

Epoch: 6| Step: 5
Training loss: 1.9556035995483398
Validation loss: 2.2405353412833264

Epoch: 6| Step: 6
Training loss: 2.7722747325897217
Validation loss: 2.236704329008697

Epoch: 6| Step: 7
Training loss: 2.111426830291748
Validation loss: 2.2292054417312785

Epoch: 6| Step: 8
Training loss: 2.005237102508545
Validation loss: 2.23799164577197

Epoch: 6| Step: 9
Training loss: 2.2876062393188477
Validation loss: 2.2253428274585354

Epoch: 6| Step: 10
Training loss: 2.77169132232666
Validation loss: 2.240342213261512

Epoch: 6| Step: 11
Training loss: 3.2197320461273193
Validation loss: 2.2444798587470927

Epoch: 6| Step: 12
Training loss: 2.302600860595703
Validation loss: 2.2335735777372956

Epoch: 6| Step: 13
Training loss: 2.185300588607788
Validation loss: 2.2272417596591416

Epoch: 263| Step: 0
Training loss: 2.1554226875305176
Validation loss: 2.2263590879337762

Epoch: 6| Step: 1
Training loss: 2.960237979888916
Validation loss: 2.227923413758637

Epoch: 6| Step: 2
Training loss: 2.9224185943603516
Validation loss: 2.234175741031606

Epoch: 6| Step: 3
Training loss: 2.8741273880004883
Validation loss: 2.2288253486797376

Epoch: 6| Step: 4
Training loss: 2.460585594177246
Validation loss: 2.2441394175252607

Epoch: 6| Step: 5
Training loss: 2.655571937561035
Validation loss: 2.25436221912343

Epoch: 6| Step: 6
Training loss: 2.1090967655181885
Validation loss: 2.238990222254107

Epoch: 6| Step: 7
Training loss: 3.0695743560791016
Validation loss: 2.2307918507565736

Epoch: 6| Step: 8
Training loss: 1.8088431358337402
Validation loss: 2.238447409804149

Epoch: 6| Step: 9
Training loss: 1.2151771783828735
Validation loss: 2.2268978805952173

Epoch: 6| Step: 10
Training loss: 3.0054197311401367
Validation loss: 2.240053317880118

Epoch: 6| Step: 11
Training loss: 2.1237003803253174
Validation loss: 2.233591159184774

Epoch: 6| Step: 12
Training loss: 2.125394105911255
Validation loss: 2.227407702835657

Epoch: 6| Step: 13
Training loss: 2.783940315246582
Validation loss: 2.236479631034277

Epoch: 264| Step: 0
Training loss: 2.2630865573883057
Validation loss: 2.2398061278045818

Epoch: 6| Step: 1
Training loss: 2.7172367572784424
Validation loss: 2.2550396944886897

Epoch: 6| Step: 2
Training loss: 1.6711217164993286
Validation loss: 2.2593523520295338

Epoch: 6| Step: 3
Training loss: 2.447054862976074
Validation loss: 2.2763287764723583

Epoch: 6| Step: 4
Training loss: 2.8856639862060547
Validation loss: 2.2725044476088656

Epoch: 6| Step: 5
Training loss: 3.123511791229248
Validation loss: 2.2546597475646646

Epoch: 6| Step: 6
Training loss: 2.804668664932251
Validation loss: 2.254983296958349

Epoch: 6| Step: 7
Training loss: 2.9002089500427246
Validation loss: 2.237633310338502

Epoch: 6| Step: 8
Training loss: 1.8723833560943604
Validation loss: 2.241504605098437

Epoch: 6| Step: 9
Training loss: 2.2836837768554688
Validation loss: 2.2289795055184314

Epoch: 6| Step: 10
Training loss: 2.042241096496582
Validation loss: 2.2320307595755464

Epoch: 6| Step: 11
Training loss: 2.5334205627441406
Validation loss: 2.2231946478607836

Epoch: 6| Step: 12
Training loss: 1.8891029357910156
Validation loss: 2.219545582289337

Epoch: 6| Step: 13
Training loss: 2.7701706886291504
Validation loss: 2.230897393277896

Epoch: 265| Step: 0
Training loss: 2.196345806121826
Validation loss: 2.2508722402716197

Epoch: 6| Step: 1
Training loss: 1.9185363054275513
Validation loss: 2.2505312171033633

Epoch: 6| Step: 2
Training loss: 2.375732898712158
Validation loss: 2.264539898082774

Epoch: 6| Step: 3
Training loss: 2.87874698638916
Validation loss: 2.254380133844191

Epoch: 6| Step: 4
Training loss: 2.564100742340088
Validation loss: 2.2467949159683718

Epoch: 6| Step: 5
Training loss: 2.237705945968628
Validation loss: 2.2339648251892417

Epoch: 6| Step: 6
Training loss: 2.4040184020996094
Validation loss: 2.2327080157495316

Epoch: 6| Step: 7
Training loss: 3.2353763580322266
Validation loss: 2.2329838045181765

Epoch: 6| Step: 8
Training loss: 2.8371479511260986
Validation loss: 2.223144272322296

Epoch: 6| Step: 9
Training loss: 2.532850742340088
Validation loss: 2.2251722684470554

Epoch: 6| Step: 10
Training loss: 2.342355251312256
Validation loss: 2.238041921328473

Epoch: 6| Step: 11
Training loss: 2.2847914695739746
Validation loss: 2.2293015680005475

Epoch: 6| Step: 12
Training loss: 1.8478317260742188
Validation loss: 2.235545281440981

Epoch: 6| Step: 13
Training loss: 2.195610761642456
Validation loss: 2.25604723986759

Epoch: 266| Step: 0
Training loss: 3.0731592178344727
Validation loss: 2.2490875067249423

Epoch: 6| Step: 1
Training loss: 2.620022773742676
Validation loss: 2.254686135117726

Epoch: 6| Step: 2
Training loss: 2.6547141075134277
Validation loss: 2.2576072369852374

Epoch: 6| Step: 3
Training loss: 2.6946768760681152
Validation loss: 2.2809942717193277

Epoch: 6| Step: 4
Training loss: 1.6116735935211182
Validation loss: 2.294403273572204

Epoch: 6| Step: 5
Training loss: 2.2679011821746826
Validation loss: 2.297014562032556

Epoch: 6| Step: 6
Training loss: 1.9205584526062012
Validation loss: 2.3090521289456274

Epoch: 6| Step: 7
Training loss: 2.6651012897491455
Validation loss: 2.287986715634664

Epoch: 6| Step: 8
Training loss: 2.1297607421875
Validation loss: 2.2834860278714086

Epoch: 6| Step: 9
Training loss: 2.010432243347168
Validation loss: 2.2735093819197787

Epoch: 6| Step: 10
Training loss: 2.9038186073303223
Validation loss: 2.279353677585561

Epoch: 6| Step: 11
Training loss: 2.496997594833374
Validation loss: 2.247696997016989

Epoch: 6| Step: 12
Training loss: 2.2511839866638184
Validation loss: 2.2431266051466747

Epoch: 6| Step: 13
Training loss: 3.0359017848968506
Validation loss: 2.244967414486793

Epoch: 267| Step: 0
Training loss: 1.8613886833190918
Validation loss: 2.2372006934176207

Epoch: 6| Step: 1
Training loss: 2.512613296508789
Validation loss: 2.242547409508818

Epoch: 6| Step: 2
Training loss: 2.739668846130371
Validation loss: 2.236466899994881

Epoch: 6| Step: 3
Training loss: 2.543447971343994
Validation loss: 2.2403648168809953

Epoch: 6| Step: 4
Training loss: 3.3497166633605957
Validation loss: 2.2234113857310307

Epoch: 6| Step: 5
Training loss: 2.2015538215637207
Validation loss: 2.2286922136942544

Epoch: 6| Step: 6
Training loss: 1.6231391429901123
Validation loss: 2.23176178368189

Epoch: 6| Step: 7
Training loss: 2.84334135055542
Validation loss: 2.2213996969243532

Epoch: 6| Step: 8
Training loss: 1.9843640327453613
Validation loss: 2.215661559053647

Epoch: 6| Step: 9
Training loss: 2.3717970848083496
Validation loss: 2.2079985833937124

Epoch: 6| Step: 10
Training loss: 2.072812557220459
Validation loss: 2.2112297601597284

Epoch: 6| Step: 11
Training loss: 2.8726234436035156
Validation loss: 2.208592116191823

Epoch: 6| Step: 12
Training loss: 2.7084462642669678
Validation loss: 2.214350441450714

Epoch: 6| Step: 13
Training loss: 2.5956854820251465
Validation loss: 2.2160849289227555

Epoch: 268| Step: 0
Training loss: 3.0370612144470215
Validation loss: 2.2230482614168556

Epoch: 6| Step: 1
Training loss: 2.333205223083496
Validation loss: 2.2162835367264284

Epoch: 6| Step: 2
Training loss: 2.510310411453247
Validation loss: 2.2309097756621656

Epoch: 6| Step: 3
Training loss: 2.466301918029785
Validation loss: 2.2487881991171066

Epoch: 6| Step: 4
Training loss: 2.0408427715301514
Validation loss: 2.2501305072538313

Epoch: 6| Step: 5
Training loss: 1.826675534248352
Validation loss: 2.251120965967896

Epoch: 6| Step: 6
Training loss: 2.1460318565368652
Validation loss: 2.2357338346460813

Epoch: 6| Step: 7
Training loss: 2.30094838142395
Validation loss: 2.234805186589559

Epoch: 6| Step: 8
Training loss: 3.0406250953674316
Validation loss: 2.2291899701600433

Epoch: 6| Step: 9
Training loss: 2.673293113708496
Validation loss: 2.2196651940704673

Epoch: 6| Step: 10
Training loss: 2.480058193206787
Validation loss: 2.2214549113345403

Epoch: 6| Step: 11
Training loss: 2.6406006813049316
Validation loss: 2.214031634792205

Epoch: 6| Step: 12
Training loss: 2.2655744552612305
Validation loss: 2.2152195463898363

Epoch: 6| Step: 13
Training loss: 2.134338855743408
Validation loss: 2.2153828913165676

Epoch: 269| Step: 0
Training loss: 2.0175228118896484
Validation loss: 2.2212901730691232

Epoch: 6| Step: 1
Training loss: 2.9013071060180664
Validation loss: 2.2249367173000048

Epoch: 6| Step: 2
Training loss: 1.3930227756500244
Validation loss: 2.2203239753682125

Epoch: 6| Step: 3
Training loss: 1.9207189083099365
Validation loss: 2.2353458558359454

Epoch: 6| Step: 4
Training loss: 2.9203176498413086
Validation loss: 2.248848448517502

Epoch: 6| Step: 5
Training loss: 2.8564109802246094
Validation loss: 2.257681174944806

Epoch: 6| Step: 6
Training loss: 2.0467233657836914
Validation loss: 2.2547132917629775

Epoch: 6| Step: 7
Training loss: 2.159497022628784
Validation loss: 2.252105025834935

Epoch: 6| Step: 8
Training loss: 2.5886497497558594
Validation loss: 2.25577123190767

Epoch: 6| Step: 9
Training loss: 2.823476552963257
Validation loss: 2.2525571059155207

Epoch: 6| Step: 10
Training loss: 2.5851693153381348
Validation loss: 2.2339156109799623

Epoch: 6| Step: 11
Training loss: 2.421156167984009
Validation loss: 2.230628393029654

Epoch: 6| Step: 12
Training loss: 2.3341684341430664
Validation loss: 2.23516740850223

Epoch: 6| Step: 13
Training loss: 3.4083337783813477
Validation loss: 2.239330768585205

Epoch: 270| Step: 0
Training loss: 2.531853675842285
Validation loss: 2.2542088339405675

Epoch: 6| Step: 1
Training loss: 1.7545807361602783
Validation loss: 2.2473898036505586

Epoch: 6| Step: 2
Training loss: 2.9719996452331543
Validation loss: 2.2430533939792263

Epoch: 6| Step: 3
Training loss: 2.1279397010803223
Validation loss: 2.227638175410609

Epoch: 6| Step: 4
Training loss: 2.6650476455688477
Validation loss: 2.233089436766922

Epoch: 6| Step: 5
Training loss: 2.6717662811279297
Validation loss: 2.209918878411734

Epoch: 6| Step: 6
Training loss: 2.23736834526062
Validation loss: 2.215648335795249

Epoch: 6| Step: 7
Training loss: 2.5696868896484375
Validation loss: 2.2068543946871193

Epoch: 6| Step: 8
Training loss: 2.7312159538269043
Validation loss: 2.198057802774573

Epoch: 6| Step: 9
Training loss: 2.924558639526367
Validation loss: 2.211037471730222

Epoch: 6| Step: 10
Training loss: 1.7437496185302734
Validation loss: 2.1996469856590353

Epoch: 6| Step: 11
Training loss: 2.365438938140869
Validation loss: 2.2092783386989305

Epoch: 6| Step: 12
Training loss: 2.2349259853363037
Validation loss: 2.198697525967834

Epoch: 6| Step: 13
Training loss: 2.4164068698883057
Validation loss: 2.215964118639628

Epoch: 271| Step: 0
Training loss: 2.027465581893921
Validation loss: 2.2185948433414584

Epoch: 6| Step: 1
Training loss: 2.8441243171691895
Validation loss: 2.206204245167394

Epoch: 6| Step: 2
Training loss: 2.839204788208008
Validation loss: 2.2234426057466896

Epoch: 6| Step: 3
Training loss: 2.5006461143493652
Validation loss: 2.2267145469624507

Epoch: 6| Step: 4
Training loss: 2.3462698459625244
Validation loss: 2.2349528933084137

Epoch: 6| Step: 5
Training loss: 2.4434895515441895
Validation loss: 2.2397889116758942

Epoch: 6| Step: 6
Training loss: 2.200915575027466
Validation loss: 2.2393089904580066

Epoch: 6| Step: 7
Training loss: 2.315005302429199
Validation loss: 2.2352453559957524

Epoch: 6| Step: 8
Training loss: 1.9417715072631836
Validation loss: 2.2413387772857503

Epoch: 6| Step: 9
Training loss: 2.489206552505493
Validation loss: 2.248002993163242

Epoch: 6| Step: 10
Training loss: 2.8217692375183105
Validation loss: 2.2437485661557925

Epoch: 6| Step: 11
Training loss: 2.227172374725342
Validation loss: 2.2577134101621565

Epoch: 6| Step: 12
Training loss: 2.261014461517334
Validation loss: 2.2549170627388904

Epoch: 6| Step: 13
Training loss: 2.94956636428833
Validation loss: 2.25019008369856

Epoch: 272| Step: 0
Training loss: 2.379472255706787
Validation loss: 2.2319571254073933

Epoch: 6| Step: 1
Training loss: 2.6860432624816895
Validation loss: 2.24151966392353

Epoch: 6| Step: 2
Training loss: 2.1987195014953613
Validation loss: 2.2334268272563977

Epoch: 6| Step: 3
Training loss: 1.9775524139404297
Validation loss: 2.2166202375965733

Epoch: 6| Step: 4
Training loss: 2.734553575515747
Validation loss: 2.2252773418221423

Epoch: 6| Step: 5
Training loss: 2.345405101776123
Validation loss: 2.226678377838545

Epoch: 6| Step: 6
Training loss: 2.5496368408203125
Validation loss: 2.2520000229599657

Epoch: 6| Step: 7
Training loss: 2.6445770263671875
Validation loss: 2.249720124788182

Epoch: 6| Step: 8
Training loss: 2.7256321907043457
Validation loss: 2.2657220209798505

Epoch: 6| Step: 9
Training loss: 2.5271291732788086
Validation loss: 2.245384923873409

Epoch: 6| Step: 10
Training loss: 2.946242332458496
Validation loss: 2.2509337676468717

Epoch: 6| Step: 11
Training loss: 2.4464447498321533
Validation loss: 2.2414764281242125

Epoch: 6| Step: 12
Training loss: 1.8523352146148682
Validation loss: 2.2412148726883756

Epoch: 6| Step: 13
Training loss: 1.7625935077667236
Validation loss: 2.2209613015574794

Epoch: 273| Step: 0
Training loss: 1.8513858318328857
Validation loss: 2.1985232983866045

Epoch: 6| Step: 1
Training loss: 2.306151866912842
Validation loss: 2.199437772074053

Epoch: 6| Step: 2
Training loss: 2.20523738861084
Validation loss: 2.199704735509811

Epoch: 6| Step: 3
Training loss: 2.4397342205047607
Validation loss: 2.1942298809687295

Epoch: 6| Step: 4
Training loss: 2.260999917984009
Validation loss: 2.1892404761365665

Epoch: 6| Step: 5
Training loss: 2.4193930625915527
Validation loss: 2.191824238787415

Epoch: 6| Step: 6
Training loss: 2.887655735015869
Validation loss: 2.19148503580401

Epoch: 6| Step: 7
Training loss: 2.669593572616577
Validation loss: 2.190232046188847

Epoch: 6| Step: 8
Training loss: 2.130305290222168
Validation loss: 2.20102273520603

Epoch: 6| Step: 9
Training loss: 2.679583787918091
Validation loss: 2.1981416235687914

Epoch: 6| Step: 10
Training loss: 2.5362186431884766
Validation loss: 2.1967743083994877

Epoch: 6| Step: 11
Training loss: 2.523247718811035
Validation loss: 2.201726000796082

Epoch: 6| Step: 12
Training loss: 2.946150302886963
Validation loss: 2.211180120386103

Epoch: 6| Step: 13
Training loss: 1.8739514350891113
Validation loss: 2.205939649253763

Epoch: 274| Step: 0
Training loss: 2.900214195251465
Validation loss: 2.2192769896599556

Epoch: 6| Step: 1
Training loss: 2.6667282581329346
Validation loss: 2.2356057487508303

Epoch: 6| Step: 2
Training loss: 2.854104518890381
Validation loss: 2.25647723033864

Epoch: 6| Step: 3
Training loss: 2.0623176097869873
Validation loss: 2.2394763064640824

Epoch: 6| Step: 4
Training loss: 2.038684606552124
Validation loss: 2.2354156330067623

Epoch: 6| Step: 5
Training loss: 2.0760326385498047
Validation loss: 2.2389940715605214

Epoch: 6| Step: 6
Training loss: 2.7343828678131104
Validation loss: 2.2375535785510974

Epoch: 6| Step: 7
Training loss: 2.058347702026367
Validation loss: 2.2242442177188013

Epoch: 6| Step: 8
Training loss: 2.6177501678466797
Validation loss: 2.2285947671500583

Epoch: 6| Step: 9
Training loss: 2.4483327865600586
Validation loss: 2.2270939478310208

Epoch: 6| Step: 10
Training loss: 1.8346281051635742
Validation loss: 2.220605755365023

Epoch: 6| Step: 11
Training loss: 2.350879669189453
Validation loss: 2.2147498117980136

Epoch: 6| Step: 12
Training loss: 3.2350900173187256
Validation loss: 2.2216074671796573

Epoch: 6| Step: 13
Training loss: 1.6958590745925903
Validation loss: 2.2256020038358626

Epoch: 275| Step: 0
Training loss: 2.5639965534210205
Validation loss: 2.228377926734186

Epoch: 6| Step: 1
Training loss: 2.778394937515259
Validation loss: 2.2369920515245005

Epoch: 6| Step: 2
Training loss: 2.941089630126953
Validation loss: 2.2391154766082764

Epoch: 6| Step: 3
Training loss: 1.4263241291046143
Validation loss: 2.2514877550063597

Epoch: 6| Step: 4
Training loss: 2.9037232398986816
Validation loss: 2.2596879953979165

Epoch: 6| Step: 5
Training loss: 2.756770133972168
Validation loss: 2.2611583804571502

Epoch: 6| Step: 6
Training loss: 2.0384345054626465
Validation loss: 2.256418958786995

Epoch: 6| Step: 7
Training loss: 2.305050849914551
Validation loss: 2.2785340842380317

Epoch: 6| Step: 8
Training loss: 1.8829833269119263
Validation loss: 2.252540995997767

Epoch: 6| Step: 9
Training loss: 2.467458486557007
Validation loss: 2.2536837183019167

Epoch: 6| Step: 10
Training loss: 2.680011034011841
Validation loss: 2.2402998452545493

Epoch: 6| Step: 11
Training loss: 2.7560741901397705
Validation loss: 2.235564108817808

Epoch: 6| Step: 12
Training loss: 2.1896767616271973
Validation loss: 2.2468789751811693

Epoch: 6| Step: 13
Training loss: 2.02597975730896
Validation loss: 2.267337627308343

Epoch: 276| Step: 0
Training loss: 2.7116293907165527
Validation loss: 2.252246026069887

Epoch: 6| Step: 1
Training loss: 2.128908395767212
Validation loss: 2.2493106190876295

Epoch: 6| Step: 2
Training loss: 2.580148696899414
Validation loss: 2.2459102010214202

Epoch: 6| Step: 3
Training loss: 1.9823933839797974
Validation loss: 2.2334757953561764

Epoch: 6| Step: 4
Training loss: 1.9531607627868652
Validation loss: 2.222404464598625

Epoch: 6| Step: 5
Training loss: 2.1337618827819824
Validation loss: 2.2235284441260883

Epoch: 6| Step: 6
Training loss: 2.8907816410064697
Validation loss: 2.216250155561714

Epoch: 6| Step: 7
Training loss: 2.1750030517578125
Validation loss: 2.2119828577964538

Epoch: 6| Step: 8
Training loss: 2.362922430038452
Validation loss: 2.199915493688276

Epoch: 6| Step: 9
Training loss: 2.125094413757324
Validation loss: 2.197800374800159

Epoch: 6| Step: 10
Training loss: 2.844752788543701
Validation loss: 2.210487360595375

Epoch: 6| Step: 11
Training loss: 2.8324408531188965
Validation loss: 2.208011422106015

Epoch: 6| Step: 12
Training loss: 2.6335601806640625
Validation loss: 2.215485370287331

Epoch: 6| Step: 13
Training loss: 2.3190488815307617
Validation loss: 2.212145520794776

Epoch: 277| Step: 0
Training loss: 1.8181945085525513
Validation loss: 2.214981563629643

Epoch: 6| Step: 1
Training loss: 2.651202917098999
Validation loss: 2.2082934123213573

Epoch: 6| Step: 2
Training loss: 2.1070547103881836
Validation loss: 2.2080918717127975

Epoch: 6| Step: 3
Training loss: 2.85030198097229
Validation loss: 2.2114776013999857

Epoch: 6| Step: 4
Training loss: 2.755650043487549
Validation loss: 2.219632738380022

Epoch: 6| Step: 5
Training loss: 2.4644289016723633
Validation loss: 2.21605529580065

Epoch: 6| Step: 6
Training loss: 2.4957916736602783
Validation loss: 2.2255690687446186

Epoch: 6| Step: 7
Training loss: 2.111295223236084
Validation loss: 2.2239446883560507

Epoch: 6| Step: 8
Training loss: 2.763747453689575
Validation loss: 2.2207971106293383

Epoch: 6| Step: 9
Training loss: 2.283923864364624
Validation loss: 2.230133257886415

Epoch: 6| Step: 10
Training loss: 2.302232503890991
Validation loss: 2.2103847842062674

Epoch: 6| Step: 11
Training loss: 2.1006569862365723
Validation loss: 2.2217694174858833

Epoch: 6| Step: 12
Training loss: 2.143576145172119
Validation loss: 2.223502605192123

Epoch: 6| Step: 13
Training loss: 3.013538122177124
Validation loss: 2.2360736746941843

Epoch: 278| Step: 0
Training loss: 2.586806535720825
Validation loss: 2.2511074107180358

Epoch: 6| Step: 1
Training loss: 2.0372774600982666
Validation loss: 2.2415565649668374

Epoch: 6| Step: 2
Training loss: 2.404189348220825
Validation loss: 2.2351367550511516

Epoch: 6| Step: 3
Training loss: 2.8046555519104004
Validation loss: 2.2312391496473745

Epoch: 6| Step: 4
Training loss: 2.818990468978882
Validation loss: 2.2430674901572605

Epoch: 6| Step: 5
Training loss: 2.7633752822875977
Validation loss: 2.2471727273797475

Epoch: 6| Step: 6
Training loss: 1.6602671146392822
Validation loss: 2.2569618096915622

Epoch: 6| Step: 7
Training loss: 1.9923815727233887
Validation loss: 2.256496480716172

Epoch: 6| Step: 8
Training loss: 2.3752269744873047
Validation loss: 2.250574137574883

Epoch: 6| Step: 9
Training loss: 2.264730930328369
Validation loss: 2.2424589331432054

Epoch: 6| Step: 10
Training loss: 2.893904447555542
Validation loss: 2.2373391941029537

Epoch: 6| Step: 11
Training loss: 2.137735605239868
Validation loss: 2.228418573256462

Epoch: 6| Step: 12
Training loss: 2.788041114807129
Validation loss: 2.2045225789470058

Epoch: 6| Step: 13
Training loss: 1.9888877868652344
Validation loss: 2.192944763809122

Epoch: 279| Step: 0
Training loss: 2.707224130630493
Validation loss: 2.20100139546138

Epoch: 6| Step: 1
Training loss: 1.9646457433700562
Validation loss: 2.2139697267163183

Epoch: 6| Step: 2
Training loss: 2.4890642166137695
Validation loss: 2.20231464088604

Epoch: 6| Step: 3
Training loss: 1.9992051124572754
Validation loss: 2.2004023303267775

Epoch: 6| Step: 4
Training loss: 2.7029623985290527
Validation loss: 2.2063646649801605

Epoch: 6| Step: 5
Training loss: 1.488701343536377
Validation loss: 2.2048667220659155

Epoch: 6| Step: 6
Training loss: 1.9329006671905518
Validation loss: 2.20102031512927

Epoch: 6| Step: 7
Training loss: 2.0645806789398193
Validation loss: 2.22669792303475

Epoch: 6| Step: 8
Training loss: 2.167292356491089
Validation loss: 2.2269124523285897

Epoch: 6| Step: 9
Training loss: 2.1940112113952637
Validation loss: 2.2186771592786236

Epoch: 6| Step: 10
Training loss: 3.2213940620422363
Validation loss: 2.214754566069572

Epoch: 6| Step: 11
Training loss: 2.9361658096313477
Validation loss: 2.2191359471249323

Epoch: 6| Step: 12
Training loss: 2.567234516143799
Validation loss: 2.227555746673256

Epoch: 6| Step: 13
Training loss: 3.3550710678100586
Validation loss: 2.222746455541221

Epoch: 280| Step: 0
Training loss: 2.4125397205352783
Validation loss: 2.2168215782411638

Epoch: 6| Step: 1
Training loss: 2.656142234802246
Validation loss: 2.2039848809601157

Epoch: 6| Step: 2
Training loss: 1.7012189626693726
Validation loss: 2.2083191461460565

Epoch: 6| Step: 3
Training loss: 3.2873620986938477
Validation loss: 2.2116125245248117

Epoch: 6| Step: 4
Training loss: 2.711099147796631
Validation loss: 2.2073064901495494

Epoch: 6| Step: 5
Training loss: 2.1595144271850586
Validation loss: 2.226801633834839

Epoch: 6| Step: 6
Training loss: 2.188121795654297
Validation loss: 2.204126363159508

Epoch: 6| Step: 7
Training loss: 2.8193931579589844
Validation loss: 2.20585544647709

Epoch: 6| Step: 8
Training loss: 2.070998430252075
Validation loss: 2.206853538431147

Epoch: 6| Step: 9
Training loss: 2.5204620361328125
Validation loss: 2.1987119772100963

Epoch: 6| Step: 10
Training loss: 2.190150260925293
Validation loss: 2.2002460392572547

Epoch: 6| Step: 11
Training loss: 2.2300806045532227
Validation loss: 2.207944708485757

Epoch: 6| Step: 12
Training loss: 2.320068836212158
Validation loss: 2.207347510963358

Epoch: 6| Step: 13
Training loss: 2.0924737453460693
Validation loss: 2.2134453455607095

Epoch: 281| Step: 0
Training loss: 2.5039820671081543
Validation loss: 2.2015513681596324

Epoch: 6| Step: 1
Training loss: 1.9848045110702515
Validation loss: 2.2060521956413024

Epoch: 6| Step: 2
Training loss: 2.153510093688965
Validation loss: 2.2222425091651177

Epoch: 6| Step: 3
Training loss: 2.884636640548706
Validation loss: 2.2195213840853785

Epoch: 6| Step: 4
Training loss: 2.726917028427124
Validation loss: 2.2074666305254866

Epoch: 6| Step: 5
Training loss: 2.155611515045166
Validation loss: 2.206235901001961

Epoch: 6| Step: 6
Training loss: 2.535560369491577
Validation loss: 2.2074437013236423

Epoch: 6| Step: 7
Training loss: 2.7695727348327637
Validation loss: 2.2170035326352684

Epoch: 6| Step: 8
Training loss: 1.7768574953079224
Validation loss: 2.204824077185764

Epoch: 6| Step: 9
Training loss: 2.756603479385376
Validation loss: 2.2170487988379692

Epoch: 6| Step: 10
Training loss: 2.007418394088745
Validation loss: 2.2163351043578117

Epoch: 6| Step: 11
Training loss: 1.6306902170181274
Validation loss: 2.2190289292284238

Epoch: 6| Step: 12
Training loss: 3.0242276191711426
Validation loss: 2.221099353605701

Epoch: 6| Step: 13
Training loss: 2.7409582138061523
Validation loss: 2.2206193067694224

Epoch: 282| Step: 0
Training loss: 2.82478666305542
Validation loss: 2.219085708741219

Epoch: 6| Step: 1
Training loss: 1.96139657497406
Validation loss: 2.2131630143811627

Epoch: 6| Step: 2
Training loss: 2.455264091491699
Validation loss: 2.216355654501146

Epoch: 6| Step: 3
Training loss: 2.700852394104004
Validation loss: 2.1990100235067387

Epoch: 6| Step: 4
Training loss: 2.3130760192871094
Validation loss: 2.194203358824535

Epoch: 6| Step: 5
Training loss: 2.3039040565490723
Validation loss: 2.2056000001968874

Epoch: 6| Step: 6
Training loss: 2.7140607833862305
Validation loss: 2.213053305943807

Epoch: 6| Step: 7
Training loss: 2.3327744007110596
Validation loss: 2.1975502224378687

Epoch: 6| Step: 8
Training loss: 2.015883207321167
Validation loss: 2.207749800015521

Epoch: 6| Step: 9
Training loss: 2.5862953662872314
Validation loss: 2.202945219573154

Epoch: 6| Step: 10
Training loss: 2.6000638008117676
Validation loss: 2.218434838838475

Epoch: 6| Step: 11
Training loss: 1.8568978309631348
Validation loss: 2.213656361385058

Epoch: 6| Step: 12
Training loss: 2.2467308044433594
Validation loss: 2.2156898360098563

Epoch: 6| Step: 13
Training loss: 2.4408435821533203
Validation loss: 2.214679359107889

Epoch: 283| Step: 0
Training loss: 2.7095353603363037
Validation loss: 2.220114146509478

Epoch: 6| Step: 1
Training loss: 2.553154945373535
Validation loss: 2.2162077734547276

Epoch: 6| Step: 2
Training loss: 2.5874826908111572
Validation loss: 2.21104157868252

Epoch: 6| Step: 3
Training loss: 2.6161744594573975
Validation loss: 2.2270978189283803

Epoch: 6| Step: 4
Training loss: 2.3826634883880615
Validation loss: 2.2268775816886657

Epoch: 6| Step: 5
Training loss: 2.7240238189697266
Validation loss: 2.232596151290401

Epoch: 6| Step: 6
Training loss: 2.081855058670044
Validation loss: 2.226557611137308

Epoch: 6| Step: 7
Training loss: 2.191514253616333
Validation loss: 2.2253542933412778

Epoch: 6| Step: 8
Training loss: 2.4162027835845947
Validation loss: 2.220233540381155

Epoch: 6| Step: 9
Training loss: 2.359795093536377
Validation loss: 2.214270496881136

Epoch: 6| Step: 10
Training loss: 2.4181923866271973
Validation loss: 2.232059601814516

Epoch: 6| Step: 11
Training loss: 1.9329333305358887
Validation loss: 2.2252025399156796

Epoch: 6| Step: 12
Training loss: 2.2017688751220703
Validation loss: 2.226955767600767

Epoch: 6| Step: 13
Training loss: 2.1571247577667236
Validation loss: 2.228349049886068

Epoch: 284| Step: 0
Training loss: 2.6225674152374268
Validation loss: 2.237345690368324

Epoch: 6| Step: 1
Training loss: 2.063875198364258
Validation loss: 2.2286192499181277

Epoch: 6| Step: 2
Training loss: 2.38494873046875
Validation loss: 2.252583590886926

Epoch: 6| Step: 3
Training loss: 2.8308522701263428
Validation loss: 2.230799716006043

Epoch: 6| Step: 4
Training loss: 2.273918628692627
Validation loss: 2.2208562243369316

Epoch: 6| Step: 5
Training loss: 2.2053050994873047
Validation loss: 2.208484149748279

Epoch: 6| Step: 6
Training loss: 1.6107816696166992
Validation loss: 2.2036775209570445

Epoch: 6| Step: 7
Training loss: 2.2232069969177246
Validation loss: 2.1900080711610856

Epoch: 6| Step: 8
Training loss: 2.028534412384033
Validation loss: 2.1990633972229494

Epoch: 6| Step: 9
Training loss: 2.754746198654175
Validation loss: 2.2030264305812057

Epoch: 6| Step: 10
Training loss: 3.296814441680908
Validation loss: 2.2003546837837464

Epoch: 6| Step: 11
Training loss: 2.247954845428467
Validation loss: 2.1969897952131046

Epoch: 6| Step: 12
Training loss: 2.3095474243164062
Validation loss: 2.2119000855312554

Epoch: 6| Step: 13
Training loss: 2.828801155090332
Validation loss: 2.2118257758437947

Epoch: 285| Step: 0
Training loss: 2.489396095275879
Validation loss: 2.218379302691388

Epoch: 6| Step: 1
Training loss: 2.035308361053467
Validation loss: 2.2318231034022507

Epoch: 6| Step: 2
Training loss: 3.2013144493103027
Validation loss: 2.2381529602953183

Epoch: 6| Step: 3
Training loss: 1.9269812107086182
Validation loss: 2.240605769618865

Epoch: 6| Step: 4
Training loss: 2.4135477542877197
Validation loss: 2.2457802372594036

Epoch: 6| Step: 5
Training loss: 2.7577266693115234
Validation loss: 2.2394939058570453

Epoch: 6| Step: 6
Training loss: 2.539041519165039
Validation loss: 2.23404832296474

Epoch: 6| Step: 7
Training loss: 2.373826503753662
Validation loss: 2.2185966404535438

Epoch: 6| Step: 8
Training loss: 1.915712594985962
Validation loss: 2.2054513987674507

Epoch: 6| Step: 9
Training loss: 2.1779441833496094
Validation loss: 2.1965849130384383

Epoch: 6| Step: 10
Training loss: 2.95426607131958
Validation loss: 2.2004387122328564

Epoch: 6| Step: 11
Training loss: 2.333144426345825
Validation loss: 2.210863874804589

Epoch: 6| Step: 12
Training loss: 2.282480478286743
Validation loss: 2.2051657348550777

Epoch: 6| Step: 13
Training loss: 1.527100920677185
Validation loss: 2.2141285788628364

Epoch: 286| Step: 0
Training loss: 2.4383883476257324
Validation loss: 2.2142011888565554

Epoch: 6| Step: 1
Training loss: 2.3715691566467285
Validation loss: 2.210436374910416

Epoch: 6| Step: 2
Training loss: 1.849501609802246
Validation loss: 2.204978335288263

Epoch: 6| Step: 3
Training loss: 2.5827882289886475
Validation loss: 2.2038518062201877

Epoch: 6| Step: 4
Training loss: 2.54970645904541
Validation loss: 2.2109092563711186

Epoch: 6| Step: 5
Training loss: 2.2325592041015625
Validation loss: 2.2121191281144337

Epoch: 6| Step: 6
Training loss: 2.6827898025512695
Validation loss: 2.2186370049753497

Epoch: 6| Step: 7
Training loss: 1.6516954898834229
Validation loss: 2.215315144549134

Epoch: 6| Step: 8
Training loss: 1.9224579334259033
Validation loss: 2.219047074676842

Epoch: 6| Step: 9
Training loss: 2.380746841430664
Validation loss: 2.224994679932953

Epoch: 6| Step: 10
Training loss: 3.026592254638672
Validation loss: 2.2258468186983498

Epoch: 6| Step: 11
Training loss: 2.554056167602539
Validation loss: 2.220934296167025

Epoch: 6| Step: 12
Training loss: 2.256171703338623
Validation loss: 2.210317852676556

Epoch: 6| Step: 13
Training loss: 3.094876766204834
Validation loss: 2.214471467079655

Epoch: 287| Step: 0
Training loss: 2.9510674476623535
Validation loss: 2.204189387700891

Epoch: 6| Step: 1
Training loss: 1.9891259670257568
Validation loss: 2.2183052288588656

Epoch: 6| Step: 2
Training loss: 2.5612330436706543
Validation loss: 2.2233287467751452

Epoch: 6| Step: 3
Training loss: 1.977596402168274
Validation loss: 2.2173823541210544

Epoch: 6| Step: 4
Training loss: 2.2123422622680664
Validation loss: 2.226874618120091

Epoch: 6| Step: 5
Training loss: 2.227454662322998
Validation loss: 2.2129442409802507

Epoch: 6| Step: 6
Training loss: 2.1371355056762695
Validation loss: 2.2118908205339984

Epoch: 6| Step: 7
Training loss: 2.3261561393737793
Validation loss: 2.1945617096398466

Epoch: 6| Step: 8
Training loss: 1.9899111986160278
Validation loss: 2.199099656074278

Epoch: 6| Step: 9
Training loss: 2.2362451553344727
Validation loss: 2.1940764457948747

Epoch: 6| Step: 10
Training loss: 2.490546703338623
Validation loss: 2.1970396913507932

Epoch: 6| Step: 11
Training loss: 2.328744888305664
Validation loss: 2.182352581331807

Epoch: 6| Step: 12
Training loss: 2.884354829788208
Validation loss: 2.1961977763842513

Epoch: 6| Step: 13
Training loss: 3.4366464614868164
Validation loss: 2.182954490825694

Epoch: 288| Step: 0
Training loss: 2.182840585708618
Validation loss: 2.201665529640772

Epoch: 6| Step: 1
Training loss: 2.3204848766326904
Validation loss: 2.2064604861761934

Epoch: 6| Step: 2
Training loss: 2.471622943878174
Validation loss: 2.228108754722021

Epoch: 6| Step: 3
Training loss: 2.9639668464660645
Validation loss: 2.224771563724805

Epoch: 6| Step: 4
Training loss: 2.983074426651001
Validation loss: 2.237669221816524

Epoch: 6| Step: 5
Training loss: 2.4139933586120605
Validation loss: 2.2493310795035413

Epoch: 6| Step: 6
Training loss: 1.8855397701263428
Validation loss: 2.225058033902158

Epoch: 6| Step: 7
Training loss: 2.1441588401794434
Validation loss: 2.2229143740028463

Epoch: 6| Step: 8
Training loss: 2.1645498275756836
Validation loss: 2.2130247546780493

Epoch: 6| Step: 9
Training loss: 2.6636524200439453
Validation loss: 2.2162335457340365

Epoch: 6| Step: 10
Training loss: 2.0700669288635254
Validation loss: 2.2059976798231884

Epoch: 6| Step: 11
Training loss: 2.2188234329223633
Validation loss: 2.206224351800898

Epoch: 6| Step: 12
Training loss: 2.577716827392578
Validation loss: 2.206788347613427

Epoch: 6| Step: 13
Training loss: 2.101964235305786
Validation loss: 2.2073685789621003

Epoch: 289| Step: 0
Training loss: 2.603306293487549
Validation loss: 2.20841714643663

Epoch: 6| Step: 1
Training loss: 2.571958065032959
Validation loss: 2.2173842178877963

Epoch: 6| Step: 2
Training loss: 2.2722909450531006
Validation loss: 2.2063032965506277

Epoch: 6| Step: 3
Training loss: 2.362855911254883
Validation loss: 2.2167191095249628

Epoch: 6| Step: 4
Training loss: 2.090852737426758
Validation loss: 2.206733226776123

Epoch: 6| Step: 5
Training loss: 2.2582015991210938
Validation loss: 2.2249571084976196

Epoch: 6| Step: 6
Training loss: 2.6005799770355225
Validation loss: 2.2317024482193815

Epoch: 6| Step: 7
Training loss: 2.357409715652466
Validation loss: 2.2099463285938388

Epoch: 6| Step: 8
Training loss: 2.2488584518432617
Validation loss: 2.211478664029029

Epoch: 6| Step: 9
Training loss: 1.8661327362060547
Validation loss: 2.216181080828431

Epoch: 6| Step: 10
Training loss: 2.583343029022217
Validation loss: 2.217104570839995

Epoch: 6| Step: 11
Training loss: 2.1832308769226074
Validation loss: 2.2290736988026607

Epoch: 6| Step: 12
Training loss: 2.995248317718506
Validation loss: 2.228139069772536

Epoch: 6| Step: 13
Training loss: 2.0262269973754883
Validation loss: 2.241111675898234

Epoch: 290| Step: 0
Training loss: 2.503984212875366
Validation loss: 2.2540243338513117

Epoch: 6| Step: 1
Training loss: 3.3849897384643555
Validation loss: 2.240464843729491

Epoch: 6| Step: 2
Training loss: 2.182471513748169
Validation loss: 2.254897521388146

Epoch: 6| Step: 3
Training loss: 2.179177761077881
Validation loss: 2.2591888699480283

Epoch: 6| Step: 4
Training loss: 2.5610742568969727
Validation loss: 2.240931328906808

Epoch: 6| Step: 5
Training loss: 2.9495716094970703
Validation loss: 2.2377374454211165

Epoch: 6| Step: 6
Training loss: 2.5500996112823486
Validation loss: 2.227812090227681

Epoch: 6| Step: 7
Training loss: 2.2887306213378906
Validation loss: 2.213341730897145

Epoch: 6| Step: 8
Training loss: 2.076507568359375
Validation loss: 2.212730912752049

Epoch: 6| Step: 9
Training loss: 1.6726795434951782
Validation loss: 2.211219770933992

Epoch: 6| Step: 10
Training loss: 2.543881416320801
Validation loss: 2.2021788884234685

Epoch: 6| Step: 11
Training loss: 1.8991429805755615
Validation loss: 2.205424629231935

Epoch: 6| Step: 12
Training loss: 2.118112325668335
Validation loss: 2.193985880062144

Epoch: 6| Step: 13
Training loss: 2.6221299171447754
Validation loss: 2.2029709585251345

Epoch: 291| Step: 0
Training loss: 2.0827691555023193
Validation loss: 2.1959749319220103

Epoch: 6| Step: 1
Training loss: 2.119288921356201
Validation loss: 2.21630629416435

Epoch: 6| Step: 2
Training loss: 2.6501197814941406
Validation loss: 2.2051500658835135

Epoch: 6| Step: 3
Training loss: 2.33442759513855
Validation loss: 2.243727460984261

Epoch: 6| Step: 4
Training loss: 2.9805455207824707
Validation loss: 2.2812009396091586

Epoch: 6| Step: 5
Training loss: 2.6275312900543213
Validation loss: 2.2567049585362917

Epoch: 6| Step: 6
Training loss: 2.159980058670044
Validation loss: 2.2434257538087907

Epoch: 6| Step: 7
Training loss: 2.538923978805542
Validation loss: 2.2354611901826758

Epoch: 6| Step: 8
Training loss: 2.658289909362793
Validation loss: 2.211625793928741

Epoch: 6| Step: 9
Training loss: 2.6306042671203613
Validation loss: 2.1979386524487565

Epoch: 6| Step: 10
Training loss: 2.160419464111328
Validation loss: 2.197392232956425

Epoch: 6| Step: 11
Training loss: 2.122218370437622
Validation loss: 2.2040312674737748

Epoch: 6| Step: 12
Training loss: 2.0509419441223145
Validation loss: 2.2035118790083033

Epoch: 6| Step: 13
Training loss: 1.9807133674621582
Validation loss: 2.2011987034992506

Epoch: 292| Step: 0
Training loss: 2.426459550857544
Validation loss: 2.2080348947996735

Epoch: 6| Step: 1
Training loss: 2.3929662704467773
Validation loss: 2.221861116347774

Epoch: 6| Step: 2
Training loss: 2.255183219909668
Validation loss: 2.2209798828248055

Epoch: 6| Step: 3
Training loss: 2.22314453125
Validation loss: 2.220727418058662

Epoch: 6| Step: 4
Training loss: 2.242671012878418
Validation loss: 2.2165858719938543

Epoch: 6| Step: 5
Training loss: 2.667038917541504
Validation loss: 2.2209964183069046

Epoch: 6| Step: 6
Training loss: 2.6089577674865723
Validation loss: 2.206400704640214

Epoch: 6| Step: 7
Training loss: 1.7221364974975586
Validation loss: 2.207707271781019

Epoch: 6| Step: 8
Training loss: 2.0012588500976562
Validation loss: 2.2095674853171072

Epoch: 6| Step: 9
Training loss: 2.6992249488830566
Validation loss: 2.2041051477514286

Epoch: 6| Step: 10
Training loss: 2.061326265335083
Validation loss: 2.2100993164124025

Epoch: 6| Step: 11
Training loss: 2.400989532470703
Validation loss: 2.228626528093892

Epoch: 6| Step: 12
Training loss: 2.8755764961242676
Validation loss: 2.212493778556906

Epoch: 6| Step: 13
Training loss: 2.9587700366973877
Validation loss: 2.2350994515162643

Epoch: 293| Step: 0
Training loss: 2.266721725463867
Validation loss: 2.2476897752413185

Epoch: 6| Step: 1
Training loss: 2.1656882762908936
Validation loss: 2.243168318143455

Epoch: 6| Step: 2
Training loss: 2.6692898273468018
Validation loss: 2.235725066995108

Epoch: 6| Step: 3
Training loss: 2.0549373626708984
Validation loss: 2.2314872075152654

Epoch: 6| Step: 4
Training loss: 2.6100330352783203
Validation loss: 2.210837059123542

Epoch: 6| Step: 5
Training loss: 1.7548433542251587
Validation loss: 2.201156803356704

Epoch: 6| Step: 6
Training loss: 2.4613590240478516
Validation loss: 2.1997247793341197

Epoch: 6| Step: 7
Training loss: 2.6475658416748047
Validation loss: 2.200093966658397

Epoch: 6| Step: 8
Training loss: 2.0992393493652344
Validation loss: 2.1869379422997914

Epoch: 6| Step: 9
Training loss: 2.6144909858703613
Validation loss: 2.1954896603861163

Epoch: 6| Step: 10
Training loss: 2.8703134059906006
Validation loss: 2.189027444008858

Epoch: 6| Step: 11
Training loss: 2.264387845993042
Validation loss: 2.187383795297274

Epoch: 6| Step: 12
Training loss: 2.480785846710205
Validation loss: 2.1866965319520686

Epoch: 6| Step: 13
Training loss: 2.4034414291381836
Validation loss: 2.1858915949380524

Epoch: 294| Step: 0
Training loss: 1.7501153945922852
Validation loss: 2.188847004726369

Epoch: 6| Step: 1
Training loss: 2.260824203491211
Validation loss: 2.190878565593432

Epoch: 6| Step: 2
Training loss: 2.0893454551696777
Validation loss: 2.1998904776829544

Epoch: 6| Step: 3
Training loss: 2.3556206226348877
Validation loss: 2.1958271688030613

Epoch: 6| Step: 4
Training loss: 2.1223549842834473
Validation loss: 2.1935984267983386

Epoch: 6| Step: 5
Training loss: 2.329591751098633
Validation loss: 2.2000331622298046

Epoch: 6| Step: 6
Training loss: 1.9750679731369019
Validation loss: 2.2150787999553065

Epoch: 6| Step: 7
Training loss: 2.887169599533081
Validation loss: 2.254168495055168

Epoch: 6| Step: 8
Training loss: 2.4838056564331055
Validation loss: 2.2577092750098116

Epoch: 6| Step: 9
Training loss: 1.9463125467300415
Validation loss: 2.2553815405855895

Epoch: 6| Step: 10
Training loss: 2.82132625579834
Validation loss: 2.2548981199982348

Epoch: 6| Step: 11
Training loss: 2.432187080383301
Validation loss: 2.2326053445057203

Epoch: 6| Step: 12
Training loss: 3.352311134338379
Validation loss: 2.2086492315415414

Epoch: 6| Step: 13
Training loss: 2.5773849487304688
Validation loss: 2.215881580947548

Epoch: 295| Step: 0
Training loss: 2.4660191535949707
Validation loss: 2.2162246345191874

Epoch: 6| Step: 1
Training loss: 2.378415584564209
Validation loss: 2.2016541842491395

Epoch: 6| Step: 2
Training loss: 3.205991268157959
Validation loss: 2.218095492291194

Epoch: 6| Step: 3
Training loss: 2.312591791152954
Validation loss: 2.2305687678757535

Epoch: 6| Step: 4
Training loss: 1.7598979473114014
Validation loss: 2.2273904431250786

Epoch: 6| Step: 5
Training loss: 2.4478964805603027
Validation loss: 2.2330840018487748

Epoch: 6| Step: 6
Training loss: 2.370399236679077
Validation loss: 2.218878892160231

Epoch: 6| Step: 7
Training loss: 2.9227852821350098
Validation loss: 2.2127743126243673

Epoch: 6| Step: 8
Training loss: 2.9411303997039795
Validation loss: 2.2072156962528022

Epoch: 6| Step: 9
Training loss: 2.3410239219665527
Validation loss: 2.19966390568723

Epoch: 6| Step: 10
Training loss: 2.4744017124176025
Validation loss: 2.201240890769548

Epoch: 6| Step: 11
Training loss: 1.734708547592163
Validation loss: 2.2038709425157115

Epoch: 6| Step: 12
Training loss: 1.809594988822937
Validation loss: 2.1987261208154822

Epoch: 6| Step: 13
Training loss: 1.9341130256652832
Validation loss: 2.207793653652232

Epoch: 296| Step: 0
Training loss: 2.4055886268615723
Validation loss: 2.2080258259209256

Epoch: 6| Step: 1
Training loss: 2.9462945461273193
Validation loss: 2.2020925603887087

Epoch: 6| Step: 2
Training loss: 2.3004236221313477
Validation loss: 2.1981522062773347

Epoch: 6| Step: 3
Training loss: 1.8894197940826416
Validation loss: 2.1854385304194626

Epoch: 6| Step: 4
Training loss: 1.8156062364578247
Validation loss: 2.182971892818328

Epoch: 6| Step: 5
Training loss: 2.399646282196045
Validation loss: 2.1781858449341147

Epoch: 6| Step: 6
Training loss: 1.7538909912109375
Validation loss: 2.1769505213665705

Epoch: 6| Step: 7
Training loss: 2.7383859157562256
Validation loss: 2.1651766530929075

Epoch: 6| Step: 8
Training loss: 2.6495323181152344
Validation loss: 2.1705282170285463

Epoch: 6| Step: 9
Training loss: 2.4084315299987793
Validation loss: 2.1792017900815575

Epoch: 6| Step: 10
Training loss: 2.4950461387634277
Validation loss: 2.1817331390996135

Epoch: 6| Step: 11
Training loss: 2.3613548278808594
Validation loss: 2.187752944166942

Epoch: 6| Step: 12
Training loss: 2.3224501609802246
Validation loss: 2.18580263404436

Epoch: 6| Step: 13
Training loss: 2.9280598163604736
Validation loss: 2.1895238225178053

Epoch: 297| Step: 0
Training loss: 1.5066289901733398
Validation loss: 2.187238741946477

Epoch: 6| Step: 1
Training loss: 2.6089437007904053
Validation loss: 2.1925081565815914

Epoch: 6| Step: 2
Training loss: 2.34383225440979
Validation loss: 2.1944271761883973

Epoch: 6| Step: 3
Training loss: 2.6708173751831055
Validation loss: 2.1985243789611326

Epoch: 6| Step: 4
Training loss: 2.1062607765197754
Validation loss: 2.19581114861273

Epoch: 6| Step: 5
Training loss: 1.951430320739746
Validation loss: 2.190939877622871

Epoch: 6| Step: 6
Training loss: 3.0528345108032227
Validation loss: 2.191232072409763

Epoch: 6| Step: 7
Training loss: 1.903180718421936
Validation loss: 2.205673039600413

Epoch: 6| Step: 8
Training loss: 2.51710844039917
Validation loss: 2.1950596686332458

Epoch: 6| Step: 9
Training loss: 2.44800066947937
Validation loss: 2.209504665866975

Epoch: 6| Step: 10
Training loss: 2.3200430870056152
Validation loss: 2.204143217814866

Epoch: 6| Step: 11
Training loss: 2.5964457988739014
Validation loss: 2.2018165665288127

Epoch: 6| Step: 12
Training loss: 2.5262060165405273
Validation loss: 2.2001956252641577

Epoch: 6| Step: 13
Training loss: 2.673877716064453
Validation loss: 2.204550894357825

Epoch: 298| Step: 0
Training loss: 2.483987808227539
Validation loss: 2.222167206066911

Epoch: 6| Step: 1
Training loss: 2.8927531242370605
Validation loss: 2.212526131701726

Epoch: 6| Step: 2
Training loss: 1.4856114387512207
Validation loss: 2.2058845002164125

Epoch: 6| Step: 3
Training loss: 2.7873551845550537
Validation loss: 2.202749857338526

Epoch: 6| Step: 4
Training loss: 2.0787510871887207
Validation loss: 2.1923427299786638

Epoch: 6| Step: 5
Training loss: 2.31190824508667
Validation loss: 2.191118819739229

Epoch: 6| Step: 6
Training loss: 1.780371904373169
Validation loss: 2.1907689494471394

Epoch: 6| Step: 7
Training loss: 2.5673060417175293
Validation loss: 2.1990297007304367

Epoch: 6| Step: 8
Training loss: 2.2880585193634033
Validation loss: 2.195613456028764

Epoch: 6| Step: 9
Training loss: 2.8387556076049805
Validation loss: 2.196934799994192

Epoch: 6| Step: 10
Training loss: 1.6680374145507812
Validation loss: 2.193192817831552

Epoch: 6| Step: 11
Training loss: 2.9988675117492676
Validation loss: 2.199937210288099

Epoch: 6| Step: 12
Training loss: 2.482032060623169
Validation loss: 2.1897013187408447

Epoch: 6| Step: 13
Training loss: 2.2404897212982178
Validation loss: 2.1886919954771638

Epoch: 299| Step: 0
Training loss: 2.3546338081359863
Validation loss: 2.1864443594409573

Epoch: 6| Step: 1
Training loss: 2.5705628395080566
Validation loss: 2.190493187596721

Epoch: 6| Step: 2
Training loss: 1.9119248390197754
Validation loss: 2.198920173029746

Epoch: 6| Step: 3
Training loss: 2.5560779571533203
Validation loss: 2.192998880981117

Epoch: 6| Step: 4
Training loss: 2.532630443572998
Validation loss: 2.1908347196476434

Epoch: 6| Step: 5
Training loss: 2.2650513648986816
Validation loss: 2.1991603797481907

Epoch: 6| Step: 6
Training loss: 2.428088903427124
Validation loss: 2.2091513423509497

Epoch: 6| Step: 7
Training loss: 2.0477261543273926
Validation loss: 2.2190182529469973

Epoch: 6| Step: 8
Training loss: 2.0781216621398926
Validation loss: 2.210374770625945

Epoch: 6| Step: 9
Training loss: 2.8693556785583496
Validation loss: 2.2215323217453493

Epoch: 6| Step: 10
Training loss: 2.1794826984405518
Validation loss: 2.2087658682177143

Epoch: 6| Step: 11
Training loss: 2.3071818351745605
Validation loss: 2.2062430074138026

Epoch: 6| Step: 12
Training loss: 2.753518581390381
Validation loss: 2.1971405475370345

Epoch: 6| Step: 13
Training loss: 2.0872223377227783
Validation loss: 2.187350816624139

Epoch: 300| Step: 0
Training loss: 2.215970516204834
Validation loss: 2.1891092254269506

Epoch: 6| Step: 1
Training loss: 2.6610450744628906
Validation loss: 2.195785863425142

Epoch: 6| Step: 2
Training loss: 2.9963669776916504
Validation loss: 2.2123442388349965

Epoch: 6| Step: 3
Training loss: 1.9949955940246582
Validation loss: 2.196582648061937

Epoch: 6| Step: 4
Training loss: 2.491199254989624
Validation loss: 2.200771918860815

Epoch: 6| Step: 5
Training loss: 2.5715672969818115
Validation loss: 2.197006170467664

Epoch: 6| Step: 6
Training loss: 1.597389817237854
Validation loss: 2.1864096067285024

Epoch: 6| Step: 7
Training loss: 2.8760886192321777
Validation loss: 2.19195524466935

Epoch: 6| Step: 8
Training loss: 2.3202953338623047
Validation loss: 2.1867911354187997

Epoch: 6| Step: 9
Training loss: 2.2740273475646973
Validation loss: 2.184250247093939

Epoch: 6| Step: 10
Training loss: 2.4083166122436523
Validation loss: 2.18800845197452

Epoch: 6| Step: 11
Training loss: 2.1283066272735596
Validation loss: 2.2060861356796755

Epoch: 6| Step: 12
Training loss: 2.099097490310669
Validation loss: 2.2152738673712618

Epoch: 6| Step: 13
Training loss: 2.3412046432495117
Validation loss: 2.228724502748059

Epoch: 301| Step: 0
Training loss: 2.2506344318389893
Validation loss: 2.2710076737147507

Epoch: 6| Step: 1
Training loss: 2.857600688934326
Validation loss: 2.2667231457207793

Epoch: 6| Step: 2
Training loss: 2.8189120292663574
Validation loss: 2.2656097463382188

Epoch: 6| Step: 3
Training loss: 3.044635772705078
Validation loss: 2.2754656755796043

Epoch: 6| Step: 4
Training loss: 2.5218610763549805
Validation loss: 2.2650675337801696

Epoch: 6| Step: 5
Training loss: 2.484868049621582
Validation loss: 2.247774559964416

Epoch: 6| Step: 6
Training loss: 1.9062519073486328
Validation loss: 2.2243477272731003

Epoch: 6| Step: 7
Training loss: 1.957589864730835
Validation loss: 2.199349021398893

Epoch: 6| Step: 8
Training loss: 3.150007486343384
Validation loss: 2.1879523108082433

Epoch: 6| Step: 9
Training loss: 1.9510852098464966
Validation loss: 2.2076074961693055

Epoch: 6| Step: 10
Training loss: 2.6459312438964844
Validation loss: 2.213754246311803

Epoch: 6| Step: 11
Training loss: 2.058908700942993
Validation loss: 2.239928845436342

Epoch: 6| Step: 12
Training loss: 1.5119651556015015
Validation loss: 2.232031724786246

Epoch: 6| Step: 13
Training loss: 2.2447452545166016
Validation loss: 2.2220335570714806

Epoch: 302| Step: 0
Training loss: 2.3281006813049316
Validation loss: 2.2214968537771576

Epoch: 6| Step: 1
Training loss: 2.450669527053833
Validation loss: 2.229618037900617

Epoch: 6| Step: 2
Training loss: 2.456005096435547
Validation loss: 2.2024737019692697

Epoch: 6| Step: 3
Training loss: 2.1594362258911133
Validation loss: 2.1919644314755677

Epoch: 6| Step: 4
Training loss: 1.6948552131652832
Validation loss: 2.2000980607924925

Epoch: 6| Step: 5
Training loss: 2.722780227661133
Validation loss: 2.2014206878600584

Epoch: 6| Step: 6
Training loss: 2.6651077270507812
Validation loss: 2.225434467356692

Epoch: 6| Step: 7
Training loss: 1.9244587421417236
Validation loss: 2.235085469420238

Epoch: 6| Step: 8
Training loss: 2.6104259490966797
Validation loss: 2.2149764107119654

Epoch: 6| Step: 9
Training loss: 2.8179850578308105
Validation loss: 2.221001548151816

Epoch: 6| Step: 10
Training loss: 2.002871036529541
Validation loss: 2.215081981433335

Epoch: 6| Step: 11
Training loss: 2.4792966842651367
Validation loss: 2.200303126406926

Epoch: 6| Step: 12
Training loss: 2.3585710525512695
Validation loss: 2.192244984770334

Epoch: 6| Step: 13
Training loss: 2.56198787689209
Validation loss: 2.1831564569985993

Epoch: 303| Step: 0
Training loss: 1.945538878440857
Validation loss: 2.1849324062306392

Epoch: 6| Step: 1
Training loss: 2.42857027053833
Validation loss: 2.1912671673682427

Epoch: 6| Step: 2
Training loss: 2.2627902030944824
Validation loss: 2.187990293707899

Epoch: 6| Step: 3
Training loss: 2.1160807609558105
Validation loss: 2.185843119057276

Epoch: 6| Step: 4
Training loss: 2.8128201961517334
Validation loss: 2.199154048837641

Epoch: 6| Step: 5
Training loss: 2.437696695327759
Validation loss: 2.193708191635788

Epoch: 6| Step: 6
Training loss: 2.4941205978393555
Validation loss: 2.192227722496115

Epoch: 6| Step: 7
Training loss: 2.518447160720825
Validation loss: 2.185623541955025

Epoch: 6| Step: 8
Training loss: 1.9313180446624756
Validation loss: 2.178903377184304

Epoch: 6| Step: 9
Training loss: 2.999889850616455
Validation loss: 2.179950939711704

Epoch: 6| Step: 10
Training loss: 2.1662869453430176
Validation loss: 2.1953247490749566

Epoch: 6| Step: 11
Training loss: 1.916288137435913
Validation loss: 2.2170037556720037

Epoch: 6| Step: 12
Training loss: 2.904970645904541
Validation loss: 2.21242416802273

Epoch: 6| Step: 13
Training loss: 1.570253849029541
Validation loss: 2.2223134143378145

Epoch: 304| Step: 0
Training loss: 2.2590904235839844
Validation loss: 2.2383654245766262

Epoch: 6| Step: 1
Training loss: 2.163939952850342
Validation loss: 2.2271986135872464

Epoch: 6| Step: 2
Training loss: 2.389174461364746
Validation loss: 2.2333407248220136

Epoch: 6| Step: 3
Training loss: 1.1959190368652344
Validation loss: 2.229849958932528

Epoch: 6| Step: 4
Training loss: 2.851809024810791
Validation loss: 2.2404333929861746

Epoch: 6| Step: 5
Training loss: 1.9719207286834717
Validation loss: 2.2222831941420034

Epoch: 6| Step: 6
Training loss: 2.3147101402282715
Validation loss: 2.222129650013421

Epoch: 6| Step: 7
Training loss: 3.859678268432617
Validation loss: 2.212136303224871

Epoch: 6| Step: 8
Training loss: 2.463827133178711
Validation loss: 2.211233949148527

Epoch: 6| Step: 9
Training loss: 1.6190829277038574
Validation loss: 2.201807406640822

Epoch: 6| Step: 10
Training loss: 1.9067251682281494
Validation loss: 2.2190269193341656

Epoch: 6| Step: 11
Training loss: 2.55033016204834
Validation loss: 2.2094921117187827

Epoch: 6| Step: 12
Training loss: 2.859957695007324
Validation loss: 2.2176917470911497

Epoch: 6| Step: 13
Training loss: 2.4042294025421143
Validation loss: 2.2197309847800963

Epoch: 305| Step: 0
Training loss: 2.147036075592041
Validation loss: 2.2060527698968047

Epoch: 6| Step: 1
Training loss: 2.18649959564209
Validation loss: 2.2224317622441117

Epoch: 6| Step: 2
Training loss: 2.264251232147217
Validation loss: 2.2129602611705823

Epoch: 6| Step: 3
Training loss: 2.12013578414917
Validation loss: 2.2114515637838714

Epoch: 6| Step: 4
Training loss: 3.182244062423706
Validation loss: 2.226931546324043

Epoch: 6| Step: 5
Training loss: 2.3114123344421387
Validation loss: 2.2277512473444783

Epoch: 6| Step: 6
Training loss: 2.489234209060669
Validation loss: 2.2435661297972485

Epoch: 6| Step: 7
Training loss: 2.2157812118530273
Validation loss: 2.2250527310115036

Epoch: 6| Step: 8
Training loss: 2.5761704444885254
Validation loss: 2.210774783165224

Epoch: 6| Step: 9
Training loss: 2.29782772064209
Validation loss: 2.2073190186613347

Epoch: 6| Step: 10
Training loss: 1.639064073562622
Validation loss: 2.2036892521765923

Epoch: 6| Step: 11
Training loss: 2.222080707550049
Validation loss: 2.200592520416424

Epoch: 6| Step: 12
Training loss: 2.51210355758667
Validation loss: 2.1988316120639926

Epoch: 6| Step: 13
Training loss: 2.9967689514160156
Validation loss: 2.2083556088068153

Epoch: 306| Step: 0
Training loss: 1.870636224746704
Validation loss: 2.221065944240939

Epoch: 6| Step: 1
Training loss: 2.282583475112915
Validation loss: 2.198801596959432

Epoch: 6| Step: 2
Training loss: 1.9842796325683594
Validation loss: 2.216042459651988

Epoch: 6| Step: 3
Training loss: 2.6736791133880615
Validation loss: 2.204920745665027

Epoch: 6| Step: 4
Training loss: 2.9747066497802734
Validation loss: 2.1879092288273636

Epoch: 6| Step: 5
Training loss: 2.618922710418701
Validation loss: 2.194398154494583

Epoch: 6| Step: 6
Training loss: 2.5210702419281006
Validation loss: 2.2006626385514454

Epoch: 6| Step: 7
Training loss: 2.1564950942993164
Validation loss: 2.1912283717945056

Epoch: 6| Step: 8
Training loss: 2.344324827194214
Validation loss: 2.1953923163875455

Epoch: 6| Step: 9
Training loss: 2.1982579231262207
Validation loss: 2.1957896806860484

Epoch: 6| Step: 10
Training loss: 1.7856589555740356
Validation loss: 2.196268214974352

Epoch: 6| Step: 11
Training loss: 2.249008893966675
Validation loss: 2.1757572235599643

Epoch: 6| Step: 12
Training loss: 2.3862366676330566
Validation loss: 2.1885868234019124

Epoch: 6| Step: 13
Training loss: 3.373422861099243
Validation loss: 2.199575185775757

Epoch: 307| Step: 0
Training loss: 2.0294103622436523
Validation loss: 2.195006965309061

Epoch: 6| Step: 1
Training loss: 2.3346190452575684
Validation loss: 2.1895530582756124

Epoch: 6| Step: 2
Training loss: 2.991490125656128
Validation loss: 2.197228265065019

Epoch: 6| Step: 3
Training loss: 2.39852237701416
Validation loss: 2.181759677907472

Epoch: 6| Step: 4
Training loss: 2.289895534515381
Validation loss: 2.197070324292747

Epoch: 6| Step: 5
Training loss: 2.5980489253997803
Validation loss: 2.210380966945361

Epoch: 6| Step: 6
Training loss: 2.2296438217163086
Validation loss: 2.225030706774804

Epoch: 6| Step: 7
Training loss: 1.8843753337860107
Validation loss: 2.217748777840727

Epoch: 6| Step: 8
Training loss: 2.119246006011963
Validation loss: 2.2254323600440897

Epoch: 6| Step: 9
Training loss: 2.676129102706909
Validation loss: 2.2037961342001475

Epoch: 6| Step: 10
Training loss: 2.476898670196533
Validation loss: 2.178232328866118

Epoch: 6| Step: 11
Training loss: 2.2150003910064697
Validation loss: 2.1752865160665205

Epoch: 6| Step: 12
Training loss: 1.980852484703064
Validation loss: 2.171983060016427

Epoch: 6| Step: 13
Training loss: 2.8943076133728027
Validation loss: 2.1646286851616314

Epoch: 308| Step: 0
Training loss: 1.698886513710022
Validation loss: 2.172626918362033

Epoch: 6| Step: 1
Training loss: 1.9648661613464355
Validation loss: 2.1747318749786704

Epoch: 6| Step: 2
Training loss: 2.166790246963501
Validation loss: 2.1765339810361146

Epoch: 6| Step: 3
Training loss: 2.113215923309326
Validation loss: 2.2020196889036443

Epoch: 6| Step: 4
Training loss: 2.6255903244018555
Validation loss: 2.1971083789743404

Epoch: 6| Step: 5
Training loss: 2.531379222869873
Validation loss: 2.1995998659441547

Epoch: 6| Step: 6
Training loss: 2.0326244831085205
Validation loss: 2.195565469803349

Epoch: 6| Step: 7
Training loss: 3.037363052368164
Validation loss: 2.189905256353399

Epoch: 6| Step: 8
Training loss: 2.4414477348327637
Validation loss: 2.2006815172010854

Epoch: 6| Step: 9
Training loss: 2.2403788566589355
Validation loss: 2.208473651639877

Epoch: 6| Step: 10
Training loss: 1.8927348852157593
Validation loss: 2.2127891022671937

Epoch: 6| Step: 11
Training loss: 2.518540382385254
Validation loss: 2.2156474795392764

Epoch: 6| Step: 12
Training loss: 2.7335562705993652
Validation loss: 2.2140009018682663

Epoch: 6| Step: 13
Training loss: 3.255218029022217
Validation loss: 2.2393483179871754

Epoch: 309| Step: 0
Training loss: 1.9861338138580322
Validation loss: 2.2227689630241803

Epoch: 6| Step: 1
Training loss: 2.758974552154541
Validation loss: 2.2132307790940806

Epoch: 6| Step: 2
Training loss: 2.095003843307495
Validation loss: 2.211524922360656

Epoch: 6| Step: 3
Training loss: 2.8638243675231934
Validation loss: 2.2249778675776657

Epoch: 6| Step: 4
Training loss: 1.4404606819152832
Validation loss: 2.1991157518920077

Epoch: 6| Step: 5
Training loss: 2.0993659496307373
Validation loss: 2.195592067574942

Epoch: 6| Step: 6
Training loss: 2.820617198944092
Validation loss: 2.185376831280288

Epoch: 6| Step: 7
Training loss: 1.9217034578323364
Validation loss: 2.195733929193148

Epoch: 6| Step: 8
Training loss: 2.1846985816955566
Validation loss: 2.18658507767544

Epoch: 6| Step: 9
Training loss: 2.465730667114258
Validation loss: 2.1856426705596266

Epoch: 6| Step: 10
Training loss: 2.1107356548309326
Validation loss: 2.180081340574449

Epoch: 6| Step: 11
Training loss: 1.9952105283737183
Validation loss: 2.1774144685396584

Epoch: 6| Step: 12
Training loss: 3.223984479904175
Validation loss: 2.168516864058792

Epoch: 6| Step: 13
Training loss: 3.242121458053589
Validation loss: 2.178819437180796

Epoch: 310| Step: 0
Training loss: 2.011289119720459
Validation loss: 2.1856539172510945

Epoch: 6| Step: 1
Training loss: 2.693676233291626
Validation loss: 2.1916525620286182

Epoch: 6| Step: 2
Training loss: 3.198610782623291
Validation loss: 2.196738955795124

Epoch: 6| Step: 3
Training loss: 1.8247359991073608
Validation loss: 2.2100329424745295

Epoch: 6| Step: 4
Training loss: 1.7749648094177246
Validation loss: 2.2184299961213143

Epoch: 6| Step: 5
Training loss: 2.9819176197052
Validation loss: 2.2185143193890973

Epoch: 6| Step: 6
Training loss: 2.042762517929077
Validation loss: 2.2116085098635767

Epoch: 6| Step: 7
Training loss: 1.711696982383728
Validation loss: 2.2027869532185216

Epoch: 6| Step: 8
Training loss: 2.902942419052124
Validation loss: 2.2043083611355034

Epoch: 6| Step: 9
Training loss: 1.8409655094146729
Validation loss: 2.187759207141015

Epoch: 6| Step: 10
Training loss: 3.047245979309082
Validation loss: 2.180918565360449

Epoch: 6| Step: 11
Training loss: 2.7221593856811523
Validation loss: 2.160711787080252

Epoch: 6| Step: 12
Training loss: 1.441649317741394
Validation loss: 2.174519028714908

Epoch: 6| Step: 13
Training loss: 2.819143056869507
Validation loss: 2.1827722262310725

Epoch: 311| Step: 0
Training loss: 2.5648000240325928
Validation loss: 2.18155974213795

Epoch: 6| Step: 1
Training loss: 1.8388657569885254
Validation loss: 2.1872482889442035

Epoch: 6| Step: 2
Training loss: 1.81666100025177
Validation loss: 2.188485199405301

Epoch: 6| Step: 3
Training loss: 2.8049445152282715
Validation loss: 2.1856554221081477

Epoch: 6| Step: 4
Training loss: 2.636479377746582
Validation loss: 2.1722138389464347

Epoch: 6| Step: 5
Training loss: 2.2540063858032227
Validation loss: 2.1819974799310007

Epoch: 6| Step: 6
Training loss: 2.4972140789031982
Validation loss: 2.1900681013702066

Epoch: 6| Step: 7
Training loss: 2.1717777252197266
Validation loss: 2.202417681294103

Epoch: 6| Step: 8
Training loss: 2.738475799560547
Validation loss: 2.2023303777940813

Epoch: 6| Step: 9
Training loss: 2.1042189598083496
Validation loss: 2.1978019668209936

Epoch: 6| Step: 10
Training loss: 2.343273162841797
Validation loss: 2.2090976199796124

Epoch: 6| Step: 11
Training loss: 1.8828176259994507
Validation loss: 2.2039429731266473

Epoch: 6| Step: 12
Training loss: 2.3241024017333984
Validation loss: 2.1920243001753286

Epoch: 6| Step: 13
Training loss: 2.9869232177734375
Validation loss: 2.205287920531406

Epoch: 312| Step: 0
Training loss: 2.7634477615356445
Validation loss: 2.194895739196449

Epoch: 6| Step: 1
Training loss: 2.7751009464263916
Validation loss: 2.1935374198421353

Epoch: 6| Step: 2
Training loss: 2.5919628143310547
Validation loss: 2.1830269854555846

Epoch: 6| Step: 3
Training loss: 2.407759189605713
Validation loss: 2.1807935981340307

Epoch: 6| Step: 4
Training loss: 2.845930337905884
Validation loss: 2.197550824893418

Epoch: 6| Step: 5
Training loss: 1.2249459028244019
Validation loss: 2.1885014182777813

Epoch: 6| Step: 6
Training loss: 2.235226631164551
Validation loss: 2.193509317213489

Epoch: 6| Step: 7
Training loss: 2.263993978500366
Validation loss: 2.1786702807231615

Epoch: 6| Step: 8
Training loss: 2.533003807067871
Validation loss: 2.1726266863525554

Epoch: 6| Step: 9
Training loss: 1.923184871673584
Validation loss: 2.1867777147600727

Epoch: 6| Step: 10
Training loss: 2.7563841342926025
Validation loss: 2.1884103782715334

Epoch: 6| Step: 11
Training loss: 1.9035212993621826
Validation loss: 2.17380843880356

Epoch: 6| Step: 12
Training loss: 2.2250983715057373
Validation loss: 2.1825773844154934

Epoch: 6| Step: 13
Training loss: 2.0146026611328125
Validation loss: 2.1885047266560216

Epoch: 313| Step: 0
Training loss: 2.5453248023986816
Validation loss: 2.1763973261720393

Epoch: 6| Step: 1
Training loss: 1.8199868202209473
Validation loss: 2.180049934694844

Epoch: 6| Step: 2
Training loss: 1.9534392356872559
Validation loss: 2.1691137077987834

Epoch: 6| Step: 3
Training loss: 2.2894234657287598
Validation loss: 2.1713568651547996

Epoch: 6| Step: 4
Training loss: 2.5174803733825684
Validation loss: 2.1664992045330744

Epoch: 6| Step: 5
Training loss: 2.6663742065429688
Validation loss: 2.1806922356287637

Epoch: 6| Step: 6
Training loss: 2.1282339096069336
Validation loss: 2.1698799825483754

Epoch: 6| Step: 7
Training loss: 2.7226812839508057
Validation loss: 2.1828021259718042

Epoch: 6| Step: 8
Training loss: 2.213181734085083
Validation loss: 2.184391056337664

Epoch: 6| Step: 9
Training loss: 2.1629040241241455
Validation loss: 2.1833504861400974

Epoch: 6| Step: 10
Training loss: 2.5055365562438965
Validation loss: 2.179115254391906

Epoch: 6| Step: 11
Training loss: 1.9149106740951538
Validation loss: 2.1850708940977692

Epoch: 6| Step: 12
Training loss: 2.820247173309326
Validation loss: 2.1761683930632887

Epoch: 6| Step: 13
Training loss: 2.1365854740142822
Validation loss: 2.172323170528617

Epoch: 314| Step: 0
Training loss: 2.332385778427124
Validation loss: 2.1717255897419427

Epoch: 6| Step: 1
Training loss: 2.9767823219299316
Validation loss: 2.189877140906549

Epoch: 6| Step: 2
Training loss: 2.327143907546997
Validation loss: 2.1842653597554853

Epoch: 6| Step: 3
Training loss: 2.1662662029266357
Validation loss: 2.1937815117579635

Epoch: 6| Step: 4
Training loss: 2.4891653060913086
Validation loss: 2.1901154056672127

Epoch: 6| Step: 5
Training loss: 1.4573099613189697
Validation loss: 2.172876368286789

Epoch: 6| Step: 6
Training loss: 2.5738837718963623
Validation loss: 2.166348875209849

Epoch: 6| Step: 7
Training loss: 2.154059886932373
Validation loss: 2.1631818625234787

Epoch: 6| Step: 8
Training loss: 1.8283318281173706
Validation loss: 2.1613917837860765

Epoch: 6| Step: 9
Training loss: 3.203561782836914
Validation loss: 2.159897328704916

Epoch: 6| Step: 10
Training loss: 2.174661159515381
Validation loss: 2.152442552710092

Epoch: 6| Step: 11
Training loss: 2.1419568061828613
Validation loss: 2.162252269765382

Epoch: 6| Step: 12
Training loss: 1.955762267112732
Validation loss: 2.1598583498308734

Epoch: 6| Step: 13
Training loss: 3.1435112953186035
Validation loss: 2.186288506753983

Epoch: 315| Step: 0
Training loss: 2.2729763984680176
Validation loss: 2.1840699590662473

Epoch: 6| Step: 1
Training loss: 2.741353750228882
Validation loss: 2.1899084532132713

Epoch: 6| Step: 2
Training loss: 2.86673641204834
Validation loss: 2.199428427603937

Epoch: 6| Step: 3
Training loss: 2.258479118347168
Validation loss: 2.1963303012232624

Epoch: 6| Step: 4
Training loss: 2.0788345336914062
Validation loss: 2.2027363213159705

Epoch: 6| Step: 5
Training loss: 2.1424427032470703
Validation loss: 2.200641591061828

Epoch: 6| Step: 6
Training loss: 2.2375895977020264
Validation loss: 2.1895459339182866

Epoch: 6| Step: 7
Training loss: 2.6138052940368652
Validation loss: 2.192718691723321

Epoch: 6| Step: 8
Training loss: 2.177304983139038
Validation loss: 2.182397042551348

Epoch: 6| Step: 9
Training loss: 1.6773337125778198
Validation loss: 2.175804095883523

Epoch: 6| Step: 10
Training loss: 1.9643105268478394
Validation loss: 2.2014627290028397

Epoch: 6| Step: 11
Training loss: 2.690613031387329
Validation loss: 2.1803464248616207

Epoch: 6| Step: 12
Training loss: 2.0839056968688965
Validation loss: 2.188091387030899

Epoch: 6| Step: 13
Training loss: 3.0534417629241943
Validation loss: 2.188620380176011

Epoch: 316| Step: 0
Training loss: 2.8878817558288574
Validation loss: 2.208031012165931

Epoch: 6| Step: 1
Training loss: 1.6181241273880005
Validation loss: 2.2128560030332176

Epoch: 6| Step: 2
Training loss: 2.094924211502075
Validation loss: 2.215889423124252

Epoch: 6| Step: 3
Training loss: 2.2591183185577393
Validation loss: 2.2004285473977365

Epoch: 6| Step: 4
Training loss: 2.3263800144195557
Validation loss: 2.1980615687626663

Epoch: 6| Step: 5
Training loss: 2.1854262351989746
Validation loss: 2.217256776748165

Epoch: 6| Step: 6
Training loss: 2.3340020179748535
Validation loss: 2.2368537687486216

Epoch: 6| Step: 7
Training loss: 2.1901259422302246
Validation loss: 2.223507732473394

Epoch: 6| Step: 8
Training loss: 2.4165918827056885
Validation loss: 2.231756817909979

Epoch: 6| Step: 9
Training loss: 2.536637544631958
Validation loss: 2.2162917967765563

Epoch: 6| Step: 10
Training loss: 2.3770694732666016
Validation loss: 2.2025950006259385

Epoch: 6| Step: 11
Training loss: 2.548694133758545
Validation loss: 2.20378646286585

Epoch: 6| Step: 12
Training loss: 2.1296277046203613
Validation loss: 2.2010817245770524

Epoch: 6| Step: 13
Training loss: 3.141822576522827
Validation loss: 2.18755393515351

Epoch: 317| Step: 0
Training loss: 2.712891101837158
Validation loss: 2.1876671365512315

Epoch: 6| Step: 1
Training loss: 1.9657913446426392
Validation loss: 2.183351147559381

Epoch: 6| Step: 2
Training loss: 2.5346665382385254
Validation loss: 2.1730270334469375

Epoch: 6| Step: 3
Training loss: 2.3017706871032715
Validation loss: 2.177665105430029

Epoch: 6| Step: 4
Training loss: 2.8194193840026855
Validation loss: 2.154009762630668

Epoch: 6| Step: 5
Training loss: 1.5577728748321533
Validation loss: 2.1578853053431355

Epoch: 6| Step: 6
Training loss: 2.8482613563537598
Validation loss: 2.1601961646028744

Epoch: 6| Step: 7
Training loss: 1.6976103782653809
Validation loss: 2.1489903157757175

Epoch: 6| Step: 8
Training loss: 1.976686954498291
Validation loss: 2.142967385630454

Epoch: 6| Step: 9
Training loss: 2.292405843734741
Validation loss: 2.154176878672774

Epoch: 6| Step: 10
Training loss: 1.9477061033248901
Validation loss: 2.163383489014

Epoch: 6| Step: 11
Training loss: 3.009167432785034
Validation loss: 2.1662052626250894

Epoch: 6| Step: 12
Training loss: 2.395895004272461
Validation loss: 2.1614471840602096

Epoch: 6| Step: 13
Training loss: 2.342921018600464
Validation loss: 2.165312602955808

Epoch: 318| Step: 0
Training loss: 2.119593620300293
Validation loss: 2.1722094294845418

Epoch: 6| Step: 1
Training loss: 2.741671562194824
Validation loss: 2.160621799448485

Epoch: 6| Step: 2
Training loss: 2.6731128692626953
Validation loss: 2.1709982656663462

Epoch: 6| Step: 3
Training loss: 1.7970033884048462
Validation loss: 2.1744557196094143

Epoch: 6| Step: 4
Training loss: 2.6947665214538574
Validation loss: 2.169233011943038

Epoch: 6| Step: 5
Training loss: 2.38723087310791
Validation loss: 2.175868462490779

Epoch: 6| Step: 6
Training loss: 2.1147711277008057
Validation loss: 2.1710974324134087

Epoch: 6| Step: 7
Training loss: 2.3260064125061035
Validation loss: 2.1741543892891175

Epoch: 6| Step: 8
Training loss: 2.449664354324341
Validation loss: 2.1798472096843104

Epoch: 6| Step: 9
Training loss: 2.518082618713379
Validation loss: 2.169339367138442

Epoch: 6| Step: 10
Training loss: 2.1333794593811035
Validation loss: 2.1822972720669163

Epoch: 6| Step: 11
Training loss: 1.7626055479049683
Validation loss: 2.19102450852753

Epoch: 6| Step: 12
Training loss: 1.683830976486206
Validation loss: 2.180251802167585

Epoch: 6| Step: 13
Training loss: 3.415374994277954
Validation loss: 2.1863711957008607

Epoch: 319| Step: 0
Training loss: 2.1263444423675537
Validation loss: 2.1885359300080167

Epoch: 6| Step: 1
Training loss: 2.0945816040039062
Validation loss: 2.187333840195851

Epoch: 6| Step: 2
Training loss: 2.1152944564819336
Validation loss: 2.2002960123041624

Epoch: 6| Step: 3
Training loss: 2.315311908721924
Validation loss: 2.2068664181616997

Epoch: 6| Step: 4
Training loss: 2.322854995727539
Validation loss: 2.2105003761988815

Epoch: 6| Step: 5
Training loss: 2.802591562271118
Validation loss: 2.1925866193668817

Epoch: 6| Step: 6
Training loss: 1.3880391120910645
Validation loss: 2.1882320886017173

Epoch: 6| Step: 7
Training loss: 3.4163057804107666
Validation loss: 2.1863420983796478

Epoch: 6| Step: 8
Training loss: 2.318389415740967
Validation loss: 2.1830070634042062

Epoch: 6| Step: 9
Training loss: 2.403463840484619
Validation loss: 2.1813442886516614

Epoch: 6| Step: 10
Training loss: 2.1461167335510254
Validation loss: 2.1779234409332275

Epoch: 6| Step: 11
Training loss: 2.75569486618042
Validation loss: 2.190945871414677

Epoch: 6| Step: 12
Training loss: 1.8259682655334473
Validation loss: 2.186254010405592

Epoch: 6| Step: 13
Training loss: 2.376253128051758
Validation loss: 2.178486244652861

Epoch: 320| Step: 0
Training loss: 2.15531063079834
Validation loss: 2.1730833707317228

Epoch: 6| Step: 1
Training loss: 2.0072193145751953
Validation loss: 2.1809743591534194

Epoch: 6| Step: 2
Training loss: 1.9233969449996948
Validation loss: 2.182460751584781

Epoch: 6| Step: 3
Training loss: 1.9060838222503662
Validation loss: 2.1875494193005305

Epoch: 6| Step: 4
Training loss: 2.544382333755493
Validation loss: 2.1838296485203568

Epoch: 6| Step: 5
Training loss: 2.624248743057251
Validation loss: 2.1746740661641604

Epoch: 6| Step: 6
Training loss: 2.772254228591919
Validation loss: 2.188337859287057

Epoch: 6| Step: 7
Training loss: 2.8492565155029297
Validation loss: 2.1608615562479985

Epoch: 6| Step: 8
Training loss: 2.2849788665771484
Validation loss: 2.18117505504239

Epoch: 6| Step: 9
Training loss: 1.728358268737793
Validation loss: 2.1727440895572787

Epoch: 6| Step: 10
Training loss: 2.579378604888916
Validation loss: 2.1942813780999955

Epoch: 6| Step: 11
Training loss: 2.4771595001220703
Validation loss: 2.1760250419698735

Epoch: 6| Step: 12
Training loss: 2.256476640701294
Validation loss: 2.176642915253998

Epoch: 6| Step: 13
Training loss: 2.2795774936676025
Validation loss: 2.155551761709234

Epoch: 321| Step: 0
Training loss: 2.2111945152282715
Validation loss: 2.1640826643154187

Epoch: 6| Step: 1
Training loss: 2.1682050228118896
Validation loss: 2.1547257490055536

Epoch: 6| Step: 2
Training loss: 2.6166529655456543
Validation loss: 2.1591212621299167

Epoch: 6| Step: 3
Training loss: 2.308619499206543
Validation loss: 2.1647585579144057

Epoch: 6| Step: 4
Training loss: 2.1833853721618652
Validation loss: 2.1720395985470025

Epoch: 6| Step: 5
Training loss: 2.403195858001709
Validation loss: 2.159094701531113

Epoch: 6| Step: 6
Training loss: 1.8172872066497803
Validation loss: 2.1768723303271877

Epoch: 6| Step: 7
Training loss: 2.982553720474243
Validation loss: 2.1860909487611506

Epoch: 6| Step: 8
Training loss: 3.215590000152588
Validation loss: 2.1887915544612433

Epoch: 6| Step: 9
Training loss: 1.852782964706421
Validation loss: 2.208422214754166

Epoch: 6| Step: 10
Training loss: 2.421571969985962
Validation loss: 2.209251085917155

Epoch: 6| Step: 11
Training loss: 2.0924534797668457
Validation loss: 2.2310708415123726

Epoch: 6| Step: 12
Training loss: 1.7578814029693604
Validation loss: 2.2131620017431115

Epoch: 6| Step: 13
Training loss: 2.442669630050659
Validation loss: 2.2039671456941994

Epoch: 322| Step: 0
Training loss: 1.5407034158706665
Validation loss: 2.201566452621132

Epoch: 6| Step: 1
Training loss: 2.7001075744628906
Validation loss: 2.2149120094955608

Epoch: 6| Step: 2
Training loss: 2.1564831733703613
Validation loss: 2.2107540689488894

Epoch: 6| Step: 3
Training loss: 2.5863871574401855
Validation loss: 2.1825562561711958

Epoch: 6| Step: 4
Training loss: 2.504646062850952
Validation loss: 2.188589742106776

Epoch: 6| Step: 5
Training loss: 1.421525239944458
Validation loss: 2.168663263320923

Epoch: 6| Step: 6
Training loss: 2.511627197265625
Validation loss: 2.168130613142444

Epoch: 6| Step: 7
Training loss: 2.567399024963379
Validation loss: 2.1881468244778213

Epoch: 6| Step: 8
Training loss: 2.460934638977051
Validation loss: 2.1878167352368756

Epoch: 6| Step: 9
Training loss: 2.7252824306488037
Validation loss: 2.1737302285368725

Epoch: 6| Step: 10
Training loss: 2.2430758476257324
Validation loss: 2.177813999114498

Epoch: 6| Step: 11
Training loss: 2.6159043312072754
Validation loss: 2.172928444800838

Epoch: 6| Step: 12
Training loss: 2.1667890548706055
Validation loss: 2.1710299497009604

Epoch: 6| Step: 13
Training loss: 1.809252381324768
Validation loss: 2.149839916536885

Epoch: 323| Step: 0
Training loss: 1.9583702087402344
Validation loss: 2.1709453187963015

Epoch: 6| Step: 1
Training loss: 1.9472010135650635
Validation loss: 2.181096830675679

Epoch: 6| Step: 2
Training loss: 2.8997154235839844
Validation loss: 2.188534034195767

Epoch: 6| Step: 3
Training loss: 2.4472758769989014
Validation loss: 2.1841555282633793

Epoch: 6| Step: 4
Training loss: 2.73099422454834
Validation loss: 2.177084199843868

Epoch: 6| Step: 5
Training loss: 1.9230067729949951
Validation loss: 2.1890898648128716

Epoch: 6| Step: 6
Training loss: 1.8890514373779297
Validation loss: 2.1919891654804187

Epoch: 6| Step: 7
Training loss: 2.4912667274475098
Validation loss: 2.2137544539666947

Epoch: 6| Step: 8
Training loss: 2.1104354858398438
Validation loss: 2.2195671373798

Epoch: 6| Step: 9
Training loss: 2.5391182899475098
Validation loss: 2.21644692010777

Epoch: 6| Step: 10
Training loss: 2.3154492378234863
Validation loss: 2.230972897621893

Epoch: 6| Step: 11
Training loss: 2.5284359455108643
Validation loss: 2.21858569370803

Epoch: 6| Step: 12
Training loss: 2.3521933555603027
Validation loss: 2.202592513894522

Epoch: 6| Step: 13
Training loss: 2.247972249984741
Validation loss: 2.1913483604308097

Epoch: 324| Step: 0
Training loss: 2.373683214187622
Validation loss: 2.1764428679661085

Epoch: 6| Step: 1
Training loss: 1.5689828395843506
Validation loss: 2.1638905335498113

Epoch: 6| Step: 2
Training loss: 2.7335381507873535
Validation loss: 2.173664653173057

Epoch: 6| Step: 3
Training loss: 2.8558366298675537
Validation loss: 2.1934906282732562

Epoch: 6| Step: 4
Training loss: 2.6501338481903076
Validation loss: 2.1602462440408687

Epoch: 6| Step: 5
Training loss: 3.0973141193389893
Validation loss: 2.1673627643175024

Epoch: 6| Step: 6
Training loss: 1.8874045610427856
Validation loss: 2.157126224169167

Epoch: 6| Step: 7
Training loss: 1.8718883991241455
Validation loss: 2.1607229748079853

Epoch: 6| Step: 8
Training loss: 2.1345582008361816
Validation loss: 2.144673021890784

Epoch: 6| Step: 9
Training loss: 1.8004649877548218
Validation loss: 2.1367287238438926

Epoch: 6| Step: 10
Training loss: 2.9547064304351807
Validation loss: 2.1515981920303835

Epoch: 6| Step: 11
Training loss: 2.2658729553222656
Validation loss: 2.1604344434635614

Epoch: 6| Step: 12
Training loss: 1.778287410736084
Validation loss: 2.1594506925152195

Epoch: 6| Step: 13
Training loss: 2.34023380279541
Validation loss: 2.1959374489322787

Epoch: 325| Step: 0
Training loss: 1.7216079235076904
Validation loss: 2.20764002748715

Epoch: 6| Step: 1
Training loss: 1.6098542213439941
Validation loss: 2.1930138782788346

Epoch: 6| Step: 2
Training loss: 2.295088052749634
Validation loss: 2.184769420213597

Epoch: 6| Step: 3
Training loss: 2.9140818119049072
Validation loss: 2.16425327075425

Epoch: 6| Step: 4
Training loss: 2.462447166442871
Validation loss: 2.1717077634667836

Epoch: 6| Step: 5
Training loss: 2.0214967727661133
Validation loss: 2.165587071449526

Epoch: 6| Step: 6
Training loss: 2.5233917236328125
Validation loss: 2.1463355120792182

Epoch: 6| Step: 7
Training loss: 2.249903678894043
Validation loss: 2.1447050673987276

Epoch: 6| Step: 8
Training loss: 2.5836081504821777
Validation loss: 2.1625988932066065

Epoch: 6| Step: 9
Training loss: 2.343738079071045
Validation loss: 2.157227385428644

Epoch: 6| Step: 10
Training loss: 2.464315891265869
Validation loss: 2.1578403544682327

Epoch: 6| Step: 11
Training loss: 2.4484875202178955
Validation loss: 2.1588922803119948

Epoch: 6| Step: 12
Training loss: 2.412288188934326
Validation loss: 2.162427697130429

Epoch: 6| Step: 13
Training loss: 2.355839967727661
Validation loss: 2.1802746095964984

Epoch: 326| Step: 0
Training loss: 2.1905088424682617
Validation loss: 2.1872383856004283

Epoch: 6| Step: 1
Training loss: 2.2912421226501465
Validation loss: 2.1815232564044256

Epoch: 6| Step: 2
Training loss: 2.404414176940918
Validation loss: 2.2014671525647564

Epoch: 6| Step: 3
Training loss: 1.7667851448059082
Validation loss: 2.1802544619447444

Epoch: 6| Step: 4
Training loss: 2.3759524822235107
Validation loss: 2.1858519764356714

Epoch: 6| Step: 5
Training loss: 2.4642200469970703
Validation loss: 2.1937810964481805

Epoch: 6| Step: 6
Training loss: 2.0091583728790283
Validation loss: 2.201718523938169

Epoch: 6| Step: 7
Training loss: 2.370899200439453
Validation loss: 2.204976661230928

Epoch: 6| Step: 8
Training loss: 2.705190896987915
Validation loss: 2.193084764224227

Epoch: 6| Step: 9
Training loss: 2.176650285720825
Validation loss: 2.197801620729508

Epoch: 6| Step: 10
Training loss: 2.3081226348876953
Validation loss: 2.199605611062819

Epoch: 6| Step: 11
Training loss: 2.3485777378082275
Validation loss: 2.187503537824077

Epoch: 6| Step: 12
Training loss: 2.3183393478393555
Validation loss: 2.1957365825612056

Epoch: 6| Step: 13
Training loss: 2.4568586349487305
Validation loss: 2.202279567718506

Epoch: 327| Step: 0
Training loss: 2.487976551055908
Validation loss: 2.1883794761473134

Epoch: 6| Step: 1
Training loss: 2.2610180377960205
Validation loss: 2.19538713014254

Epoch: 6| Step: 2
Training loss: 3.225036144256592
Validation loss: 2.181777133736559

Epoch: 6| Step: 3
Training loss: 1.9284839630126953
Validation loss: 2.1870857669461157

Epoch: 6| Step: 4
Training loss: 2.0370686054229736
Validation loss: 2.19528954516175

Epoch: 6| Step: 5
Training loss: 2.737762212753296
Validation loss: 2.1699446862743748

Epoch: 6| Step: 6
Training loss: 2.196263551712036
Validation loss: 2.1693860638526177

Epoch: 6| Step: 7
Training loss: 2.115145206451416
Validation loss: 2.16294446299153

Epoch: 6| Step: 8
Training loss: 1.9896936416625977
Validation loss: 2.171287162329561

Epoch: 6| Step: 9
Training loss: 2.009632110595703
Validation loss: 2.165271798769633

Epoch: 6| Step: 10
Training loss: 1.7002627849578857
Validation loss: 2.163834821793341

Epoch: 6| Step: 11
Training loss: 2.4863390922546387
Validation loss: 2.1674327773432576

Epoch: 6| Step: 12
Training loss: 2.4291272163391113
Validation loss: 2.1719769277880268

Epoch: 6| Step: 13
Training loss: 2.544719696044922
Validation loss: 2.160948412392729

Epoch: 328| Step: 0
Training loss: 1.4421865940093994
Validation loss: 2.1703191341892367

Epoch: 6| Step: 1
Training loss: 1.918642520904541
Validation loss: 2.1650080988484044

Epoch: 6| Step: 2
Training loss: 2.2020909786224365
Validation loss: 2.1616800318482103

Epoch: 6| Step: 3
Training loss: 2.4990644454956055
Validation loss: 2.1553687036678357

Epoch: 6| Step: 4
Training loss: 2.3587429523468018
Validation loss: 2.1507126541547876

Epoch: 6| Step: 5
Training loss: 2.693808078765869
Validation loss: 2.1482427222754366

Epoch: 6| Step: 6
Training loss: 2.4463083744049072
Validation loss: 2.138868393436555

Epoch: 6| Step: 7
Training loss: 1.8768540620803833
Validation loss: 2.152228593826294

Epoch: 6| Step: 8
Training loss: 2.871192455291748
Validation loss: 2.144544300212655

Epoch: 6| Step: 9
Training loss: 2.023162364959717
Validation loss: 2.1463263188638995

Epoch: 6| Step: 10
Training loss: 1.9411053657531738
Validation loss: 2.1447445859191236

Epoch: 6| Step: 11
Training loss: 2.3194503784179688
Validation loss: 2.143647540000177

Epoch: 6| Step: 12
Training loss: 3.06314754486084
Validation loss: 2.157845054903338

Epoch: 6| Step: 13
Training loss: 2.6050968170166016
Validation loss: 2.146477778752645

Epoch: 329| Step: 0
Training loss: 2.4234137535095215
Validation loss: 2.1518894292974986

Epoch: 6| Step: 1
Training loss: 2.388749599456787
Validation loss: 2.1612967393731557

Epoch: 6| Step: 2
Training loss: 2.171739101409912
Validation loss: 2.1688123569693616

Epoch: 6| Step: 3
Training loss: 2.3263797760009766
Validation loss: 2.174879684243151

Epoch: 6| Step: 4
Training loss: 1.7855830192565918
Validation loss: 2.167011517350392

Epoch: 6| Step: 5
Training loss: 2.581646203994751
Validation loss: 2.177723487218221

Epoch: 6| Step: 6
Training loss: 2.8847131729125977
Validation loss: 2.183282914982047

Epoch: 6| Step: 7
Training loss: 2.32871675491333
Validation loss: 2.184593213501797

Epoch: 6| Step: 8
Training loss: 1.615087628364563
Validation loss: 2.1869870206361175

Epoch: 6| Step: 9
Training loss: 2.667841911315918
Validation loss: 2.1955664901323217

Epoch: 6| Step: 10
Training loss: 2.583915948867798
Validation loss: 2.2056814265507523

Epoch: 6| Step: 11
Training loss: 2.3011996746063232
Validation loss: 2.1979430285833215

Epoch: 6| Step: 12
Training loss: 1.7455801963806152
Validation loss: 2.198834729451005

Epoch: 6| Step: 13
Training loss: 1.802593469619751
Validation loss: 2.1822810967763266

Epoch: 330| Step: 0
Training loss: 2.606912612915039
Validation loss: 2.1863807888441187

Epoch: 6| Step: 1
Training loss: 1.9398638010025024
Validation loss: 2.1779898648620932

Epoch: 6| Step: 2
Training loss: 2.010063648223877
Validation loss: 2.1829535166422525

Epoch: 6| Step: 3
Training loss: 2.127926826477051
Validation loss: 2.2026284330634662

Epoch: 6| Step: 4
Training loss: 1.725318193435669
Validation loss: 2.186321707182033

Epoch: 6| Step: 5
Training loss: 1.8122787475585938
Validation loss: 2.1874717563711186

Epoch: 6| Step: 6
Training loss: 2.8471827507019043
Validation loss: 2.2036213874816895

Epoch: 6| Step: 7
Training loss: 2.191861629486084
Validation loss: 2.200743165067447

Epoch: 6| Step: 8
Training loss: 2.3393588066101074
Validation loss: 2.186463991800944

Epoch: 6| Step: 9
Training loss: 2.9047536849975586
Validation loss: 2.187839433711062

Epoch: 6| Step: 10
Training loss: 2.808688163757324
Validation loss: 2.2063531311609412

Epoch: 6| Step: 11
Training loss: 1.79296875
Validation loss: 2.1944463304294053

Epoch: 6| Step: 12
Training loss: 2.6426150798797607
Validation loss: 2.18567414950299

Epoch: 6| Step: 13
Training loss: 2.2986605167388916
Validation loss: 2.1991431892559095

Epoch: 331| Step: 0
Training loss: 2.4887118339538574
Validation loss: 2.1879574073258268

Epoch: 6| Step: 1
Training loss: 2.333062171936035
Validation loss: 2.188819432771334

Epoch: 6| Step: 2
Training loss: 1.4399629831314087
Validation loss: 2.1730409745247132

Epoch: 6| Step: 3
Training loss: 2.0929901599884033
Validation loss: 2.1487391148844073

Epoch: 6| Step: 4
Training loss: 2.2310450077056885
Validation loss: 2.1405223595198763

Epoch: 6| Step: 5
Training loss: 2.041407823562622
Validation loss: 2.1333092797187065

Epoch: 6| Step: 6
Training loss: 2.4091062545776367
Validation loss: 2.132481216102518

Epoch: 6| Step: 7
Training loss: 2.3901515007019043
Validation loss: 2.123012650397516

Epoch: 6| Step: 8
Training loss: 3.0216593742370605
Validation loss: 2.140500786483929

Epoch: 6| Step: 9
Training loss: 1.6452202796936035
Validation loss: 2.1431762890149186

Epoch: 6| Step: 10
Training loss: 2.6404237747192383
Validation loss: 2.1408927927735033

Epoch: 6| Step: 11
Training loss: 2.6243162155151367
Validation loss: 2.144206359822263

Epoch: 6| Step: 12
Training loss: 2.535874843597412
Validation loss: 2.1363744863899807

Epoch: 6| Step: 13
Training loss: 2.2876930236816406
Validation loss: 2.134270332192862

Epoch: 332| Step: 0
Training loss: 2.7954883575439453
Validation loss: 2.1573737026542745

Epoch: 6| Step: 1
Training loss: 2.574154853820801
Validation loss: 2.1845336780753186

Epoch: 6| Step: 2
Training loss: 2.2992444038391113
Validation loss: 2.187744217534219

Epoch: 6| Step: 3
Training loss: 1.457502841949463
Validation loss: 2.198398925924814

Epoch: 6| Step: 4
Training loss: 1.781578779220581
Validation loss: 2.20626312686551

Epoch: 6| Step: 5
Training loss: 1.783485770225525
Validation loss: 2.1962010591260848

Epoch: 6| Step: 6
Training loss: 2.3875370025634766
Validation loss: 2.1866007158833165

Epoch: 6| Step: 7
Training loss: 2.3272886276245117
Validation loss: 2.1837620837714082

Epoch: 6| Step: 8
Training loss: 2.2001047134399414
Validation loss: 2.1760950037228164

Epoch: 6| Step: 9
Training loss: 3.0267422199249268
Validation loss: 2.1725394418162685

Epoch: 6| Step: 10
Training loss: 2.1291329860687256
Validation loss: 2.162419362734723

Epoch: 6| Step: 11
Training loss: 2.374791145324707
Validation loss: 2.1640601901597876

Epoch: 6| Step: 12
Training loss: 2.4787111282348633
Validation loss: 2.1697766755216863

Epoch: 6| Step: 13
Training loss: 2.2493765354156494
Validation loss: 2.15406390928453

Epoch: 333| Step: 0
Training loss: 1.9236444234848022
Validation loss: 2.1506179891606814

Epoch: 6| Step: 1
Training loss: 1.932680368423462
Validation loss: 2.1485730755713677

Epoch: 6| Step: 2
Training loss: 2.2004642486572266
Validation loss: 2.1490380687098347

Epoch: 6| Step: 3
Training loss: 2.7581071853637695
Validation loss: 2.1528812326410764

Epoch: 6| Step: 4
Training loss: 2.522374153137207
Validation loss: 2.1564368996568906

Epoch: 6| Step: 5
Training loss: 2.499652862548828
Validation loss: 2.16664517823086

Epoch: 6| Step: 6
Training loss: 2.2645812034606934
Validation loss: 2.1605267550355647

Epoch: 6| Step: 7
Training loss: 2.1130776405334473
Validation loss: 2.15299274716326

Epoch: 6| Step: 8
Training loss: 2.484851837158203
Validation loss: 2.1397157279394006

Epoch: 6| Step: 9
Training loss: 2.3500452041625977
Validation loss: 2.14363601387188

Epoch: 6| Step: 10
Training loss: 2.426992177963257
Validation loss: 2.129867731883962

Epoch: 6| Step: 11
Training loss: 1.810685157775879
Validation loss: 2.1394660754870345

Epoch: 6| Step: 12
Training loss: 1.8083314895629883
Validation loss: 2.1351204046639065

Epoch: 6| Step: 13
Training loss: 3.0890352725982666
Validation loss: 2.1516511055731002

Epoch: 334| Step: 0
Training loss: 1.2241384983062744
Validation loss: 2.1462203982055827

Epoch: 6| Step: 1
Training loss: 2.473578691482544
Validation loss: 2.1378197541800876

Epoch: 6| Step: 2
Training loss: 2.2903120517730713
Validation loss: 2.155780018016856

Epoch: 6| Step: 3
Training loss: 2.5962743759155273
Validation loss: 2.1610726746179725

Epoch: 6| Step: 4
Training loss: 2.6234564781188965
Validation loss: 2.1521988171403126

Epoch: 6| Step: 5
Training loss: 2.350203514099121
Validation loss: 2.150923370033182

Epoch: 6| Step: 6
Training loss: 1.8166522979736328
Validation loss: 2.149880696368474

Epoch: 6| Step: 7
Training loss: 2.1140689849853516
Validation loss: 2.1438906320961575

Epoch: 6| Step: 8
Training loss: 2.652751922607422
Validation loss: 2.1441830742743706

Epoch: 6| Step: 9
Training loss: 2.454646587371826
Validation loss: 2.1518777262779976

Epoch: 6| Step: 10
Training loss: 2.1981794834136963
Validation loss: 2.147175763242988

Epoch: 6| Step: 11
Training loss: 2.0888028144836426
Validation loss: 2.1393218783922094

Epoch: 6| Step: 12
Training loss: 2.6009459495544434
Validation loss: 2.135472218195597

Epoch: 6| Step: 13
Training loss: 2.6542181968688965
Validation loss: 2.12565629969361

Epoch: 335| Step: 0
Training loss: 2.0645480155944824
Validation loss: 2.142055097446647

Epoch: 6| Step: 1
Training loss: 2.188444137573242
Validation loss: 2.1236939635328067

Epoch: 6| Step: 2
Training loss: 2.0378077030181885
Validation loss: 2.1422738464929725

Epoch: 6| Step: 3
Training loss: 2.901916265487671
Validation loss: 2.1426017976576284

Epoch: 6| Step: 4
Training loss: 2.509446620941162
Validation loss: 2.1561469237009683

Epoch: 6| Step: 5
Training loss: 2.5450751781463623
Validation loss: 2.172978570384364

Epoch: 6| Step: 6
Training loss: 1.8294644355773926
Validation loss: 2.1504055735885457

Epoch: 6| Step: 7
Training loss: 2.854671001434326
Validation loss: 2.161024478174025

Epoch: 6| Step: 8
Training loss: 3.0026299953460693
Validation loss: 2.150292528572903

Epoch: 6| Step: 9
Training loss: 1.8255667686462402
Validation loss: 2.1637515970455703

Epoch: 6| Step: 10
Training loss: 1.7566044330596924
Validation loss: 2.178287516358078

Epoch: 6| Step: 11
Training loss: 2.0779504776000977
Validation loss: 2.185802267443749

Epoch: 6| Step: 12
Training loss: 1.968266248703003
Validation loss: 2.189342967925533

Epoch: 6| Step: 13
Training loss: 2.1223015785217285
Validation loss: 2.180904608900829

Epoch: 336| Step: 0
Training loss: 2.0974249839782715
Validation loss: 2.189080335760629

Epoch: 6| Step: 1
Training loss: 2.2306268215179443
Validation loss: 2.1966460084402435

Epoch: 6| Step: 2
Training loss: 2.1370432376861572
Validation loss: 2.1749758464033886

Epoch: 6| Step: 3
Training loss: 2.7259058952331543
Validation loss: 2.1574754535510974

Epoch: 6| Step: 4
Training loss: 2.3471899032592773
Validation loss: 2.1636864613461237

Epoch: 6| Step: 5
Training loss: 1.7983192205429077
Validation loss: 2.168253937075215

Epoch: 6| Step: 6
Training loss: 2.518768310546875
Validation loss: 2.1787613002202844

Epoch: 6| Step: 7
Training loss: 2.4392147064208984
Validation loss: 2.1539812036739883

Epoch: 6| Step: 8
Training loss: 2.433032512664795
Validation loss: 2.159622000109765

Epoch: 6| Step: 9
Training loss: 2.5837411880493164
Validation loss: 2.141773957078175

Epoch: 6| Step: 10
Training loss: 2.484229326248169
Validation loss: 2.1589771239988265

Epoch: 6| Step: 11
Training loss: 1.287548542022705
Validation loss: 2.161913876892418

Epoch: 6| Step: 12
Training loss: 2.2140774726867676
Validation loss: 2.152878676691363

Epoch: 6| Step: 13
Training loss: 2.4347448348999023
Validation loss: 2.1374734986212944

Epoch: 337| Step: 0
Training loss: 1.9161376953125
Validation loss: 2.1549977615315425

Epoch: 6| Step: 1
Training loss: 2.262819766998291
Validation loss: 2.1770290328610327

Epoch: 6| Step: 2
Training loss: 2.3760056495666504
Validation loss: 2.1705281196102018

Epoch: 6| Step: 3
Training loss: 2.2489891052246094
Validation loss: 2.196757995954124

Epoch: 6| Step: 4
Training loss: 1.9190703630447388
Validation loss: 2.185757424241753

Epoch: 6| Step: 5
Training loss: 2.563997507095337
Validation loss: 2.1764007153049594

Epoch: 6| Step: 6
Training loss: 2.3427326679229736
Validation loss: 2.1518453859513804

Epoch: 6| Step: 7
Training loss: 2.342197895050049
Validation loss: 2.157886278244757

Epoch: 6| Step: 8
Training loss: 1.358320713043213
Validation loss: 2.1638073241838844

Epoch: 6| Step: 9
Training loss: 2.3179073333740234
Validation loss: 2.1334553636530393

Epoch: 6| Step: 10
Training loss: 2.7497944831848145
Validation loss: 2.1380748312960387

Epoch: 6| Step: 11
Training loss: 2.43860125541687
Validation loss: 2.147569807626868

Epoch: 6| Step: 12
Training loss: 2.7434685230255127
Validation loss: 2.1389117215269353

Epoch: 6| Step: 13
Training loss: 1.8065060377120972
Validation loss: 2.1419990139622844

Epoch: 338| Step: 0
Training loss: 2.4768307209014893
Validation loss: 2.1445488493929625

Epoch: 6| Step: 1
Training loss: 2.2950053215026855
Validation loss: 2.146380166853628

Epoch: 6| Step: 2
Training loss: 2.7213902473449707
Validation loss: 2.1406082978812595

Epoch: 6| Step: 3
Training loss: 1.5412249565124512
Validation loss: 2.1429485223626576

Epoch: 6| Step: 4
Training loss: 2.236691474914551
Validation loss: 2.1495540975242533

Epoch: 6| Step: 5
Training loss: 2.626685619354248
Validation loss: 2.1382124629071964

Epoch: 6| Step: 6
Training loss: 2.3260347843170166
Validation loss: 2.1696189808589157

Epoch: 6| Step: 7
Training loss: 2.0827817916870117
Validation loss: 2.153730405274258

Epoch: 6| Step: 8
Training loss: 1.9509379863739014
Validation loss: 2.1482827304511942

Epoch: 6| Step: 9
Training loss: 2.241014003753662
Validation loss: 2.146499174897389

Epoch: 6| Step: 10
Training loss: 2.7855398654937744
Validation loss: 2.146678747669343

Epoch: 6| Step: 11
Training loss: 1.9062718152999878
Validation loss: 2.1505597470909037

Epoch: 6| Step: 12
Training loss: 1.8741964101791382
Validation loss: 2.1453441496818297

Epoch: 6| Step: 13
Training loss: 2.7947380542755127
Validation loss: 2.1385464899001585

Epoch: 339| Step: 0
Training loss: 1.9672770500183105
Validation loss: 2.135361102319533

Epoch: 6| Step: 1
Training loss: 1.7691500186920166
Validation loss: 2.1378285948948195

Epoch: 6| Step: 2
Training loss: 2.972522020339966
Validation loss: 2.135714882163591

Epoch: 6| Step: 3
Training loss: 2.369333267211914
Validation loss: 2.1336497824679137

Epoch: 6| Step: 4
Training loss: 2.068725824356079
Validation loss: 2.1298559314461163

Epoch: 6| Step: 5
Training loss: 2.4435768127441406
Validation loss: 2.1263481775919595

Epoch: 6| Step: 6
Training loss: 2.112443447113037
Validation loss: 2.142016769737326

Epoch: 6| Step: 7
Training loss: 2.1805765628814697
Validation loss: 2.1539333046123548

Epoch: 6| Step: 8
Training loss: 2.461918830871582
Validation loss: 2.1488124632066294

Epoch: 6| Step: 9
Training loss: 1.9569828510284424
Validation loss: 2.1571243834751908

Epoch: 6| Step: 10
Training loss: 2.491421699523926
Validation loss: 2.145664544515712

Epoch: 6| Step: 11
Training loss: 2.0332770347595215
Validation loss: 2.145694166101435

Epoch: 6| Step: 12
Training loss: 2.5112507343292236
Validation loss: 2.1595275658433155

Epoch: 6| Step: 13
Training loss: 2.168658971786499
Validation loss: 2.1641840152843024

Epoch: 340| Step: 0
Training loss: 2.639859199523926
Validation loss: 2.1656746569500176

Epoch: 6| Step: 1
Training loss: 2.225661516189575
Validation loss: 2.1780437192609234

Epoch: 6| Step: 2
Training loss: 2.9673783779144287
Validation loss: 2.1809400743053806

Epoch: 6| Step: 3
Training loss: 2.2653262615203857
Validation loss: 2.170868371122627

Epoch: 6| Step: 4
Training loss: 3.1085386276245117
Validation loss: 2.171050315262169

Epoch: 6| Step: 5
Training loss: 1.622739315032959
Validation loss: 2.1566732570689213

Epoch: 6| Step: 6
Training loss: 1.7789983749389648
Validation loss: 2.131657194065791

Epoch: 6| Step: 7
Training loss: 2.385558605194092
Validation loss: 2.1335229053292224

Epoch: 6| Step: 8
Training loss: 1.8744983673095703
Validation loss: 2.1220913266622894

Epoch: 6| Step: 9
Training loss: 1.7760419845581055
Validation loss: 2.106402809901904

Epoch: 6| Step: 10
Training loss: 2.3150219917297363
Validation loss: 2.1128242451657533

Epoch: 6| Step: 11
Training loss: 2.3641018867492676
Validation loss: 2.1311830846212243

Epoch: 6| Step: 12
Training loss: 2.1301345825195312
Validation loss: 2.128023147583008

Epoch: 6| Step: 13
Training loss: 2.090815544128418
Validation loss: 2.117114428550966

Epoch: 341| Step: 0
Training loss: 1.3961175680160522
Validation loss: 2.146207146747138

Epoch: 6| Step: 1
Training loss: 2.5168750286102295
Validation loss: 2.13430271866501

Epoch: 6| Step: 2
Training loss: 2.217052459716797
Validation loss: 2.1431667266353482

Epoch: 6| Step: 3
Training loss: 2.6995849609375
Validation loss: 2.1379949815811647

Epoch: 6| Step: 4
Training loss: 2.0913286209106445
Validation loss: 2.141181613809319

Epoch: 6| Step: 5
Training loss: 1.8929176330566406
Validation loss: 2.143653528664702

Epoch: 6| Step: 6
Training loss: 2.075303554534912
Validation loss: 2.157708029593191

Epoch: 6| Step: 7
Training loss: 2.5179710388183594
Validation loss: 2.1607466564383557

Epoch: 6| Step: 8
Training loss: 3.114151954650879
Validation loss: 2.1676081252354447

Epoch: 6| Step: 9
Training loss: 1.9988818168640137
Validation loss: 2.159599209344515

Epoch: 6| Step: 10
Training loss: 3.134366035461426
Validation loss: 2.1692852768846738

Epoch: 6| Step: 11
Training loss: 2.2600162029266357
Validation loss: 2.1601489256787043

Epoch: 6| Step: 12
Training loss: 1.7943987846374512
Validation loss: 2.160321468948036

Epoch: 6| Step: 13
Training loss: 1.5983816385269165
Validation loss: 2.157524593414799

Epoch: 342| Step: 0
Training loss: 2.279585838317871
Validation loss: 2.132002358795494

Epoch: 6| Step: 1
Training loss: 2.3733410835266113
Validation loss: 2.131073526156846

Epoch: 6| Step: 2
Training loss: 1.4956634044647217
Validation loss: 2.1261419532119588

Epoch: 6| Step: 3
Training loss: 2.241802215576172
Validation loss: 2.1427457832521006

Epoch: 6| Step: 4
Training loss: 2.352452278137207
Validation loss: 2.132804475804811

Epoch: 6| Step: 5
Training loss: 2.505709171295166
Validation loss: 2.137767417456514

Epoch: 6| Step: 6
Training loss: 2.229919672012329
Validation loss: 2.128362553094023

Epoch: 6| Step: 7
Training loss: 2.367002248764038
Validation loss: 2.1458622537633425

Epoch: 6| Step: 8
Training loss: 2.198762893676758
Validation loss: 2.1358528009024997

Epoch: 6| Step: 9
Training loss: 2.4999053478240967
Validation loss: 2.147752264494537

Epoch: 6| Step: 10
Training loss: 1.8619301319122314
Validation loss: 2.1497269984214538

Epoch: 6| Step: 11
Training loss: 2.6863865852355957
Validation loss: 2.14592924938407

Epoch: 6| Step: 12
Training loss: 2.0910730361938477
Validation loss: 2.1571186947566208

Epoch: 6| Step: 13
Training loss: 2.3153369426727295
Validation loss: 2.1687177381207867

Epoch: 343| Step: 0
Training loss: 2.462538242340088
Validation loss: 2.1806275254936627

Epoch: 6| Step: 1
Training loss: 2.0007426738739014
Validation loss: 2.172371905337098

Epoch: 6| Step: 2
Training loss: 1.616065502166748
Validation loss: 2.172370465852881

Epoch: 6| Step: 3
Training loss: 1.620527982711792
Validation loss: 2.1428221066792807

Epoch: 6| Step: 4
Training loss: 3.2008700370788574
Validation loss: 2.14746109900936

Epoch: 6| Step: 5
Training loss: 1.9927785396575928
Validation loss: 2.1400211241937455

Epoch: 6| Step: 6
Training loss: 2.0810647010803223
Validation loss: 2.137132106288787

Epoch: 6| Step: 7
Training loss: 2.067725896835327
Validation loss: 2.138436007243331

Epoch: 6| Step: 8
Training loss: 2.465203285217285
Validation loss: 2.1541254853689544

Epoch: 6| Step: 9
Training loss: 2.72467041015625
Validation loss: 2.140692885204028

Epoch: 6| Step: 10
Training loss: 2.253997802734375
Validation loss: 2.1461560623620146

Epoch: 6| Step: 11
Training loss: 2.3512516021728516
Validation loss: 2.148138028319164

Epoch: 6| Step: 12
Training loss: 2.1576859951019287
Validation loss: 2.1607636943940194

Epoch: 6| Step: 13
Training loss: 2.678927421569824
Validation loss: 2.1598417823032667

Epoch: 344| Step: 0
Training loss: 2.0745058059692383
Validation loss: 2.1582579587095525

Epoch: 6| Step: 1
Training loss: 2.0443780422210693
Validation loss: 2.168144508074689

Epoch: 6| Step: 2
Training loss: 1.62477707862854
Validation loss: 2.157974421337087

Epoch: 6| Step: 3
Training loss: 1.8529754877090454
Validation loss: 2.153377914941439

Epoch: 6| Step: 4
Training loss: 1.8101813793182373
Validation loss: 2.153732151113531

Epoch: 6| Step: 5
Training loss: 2.826871395111084
Validation loss: 2.1525212718594458

Epoch: 6| Step: 6
Training loss: 2.864960193634033
Validation loss: 2.140738594916559

Epoch: 6| Step: 7
Training loss: 3.0587687492370605
Validation loss: 2.1526624130946335

Epoch: 6| Step: 8
Training loss: 1.877274751663208
Validation loss: 2.1429449589021745

Epoch: 6| Step: 9
Training loss: 2.138052463531494
Validation loss: 2.160849134127299

Epoch: 6| Step: 10
Training loss: 2.134298324584961
Validation loss: 2.1500511412979453

Epoch: 6| Step: 11
Training loss: 2.318659782409668
Validation loss: 2.1503448768328597

Epoch: 6| Step: 12
Training loss: 1.9637309312820435
Validation loss: 2.141150978303725

Epoch: 6| Step: 13
Training loss: 2.9181294441223145
Validation loss: 2.1288466966280373

Epoch: 345| Step: 0
Training loss: 1.9247969388961792
Validation loss: 2.1240996878634215

Epoch: 6| Step: 1
Training loss: 2.0247883796691895
Validation loss: 2.1439853445176156

Epoch: 6| Step: 2
Training loss: 1.81943678855896
Validation loss: 2.1430081808438866

Epoch: 6| Step: 3
Training loss: 2.4458682537078857
Validation loss: 2.149522063552692

Epoch: 6| Step: 4
Training loss: 2.851255416870117
Validation loss: 2.152979903323676

Epoch: 6| Step: 5
Training loss: 1.8232648372650146
Validation loss: 2.172468464861634

Epoch: 6| Step: 6
Training loss: 1.9206358194351196
Validation loss: 2.1546150843302407

Epoch: 6| Step: 7
Training loss: 2.1630377769470215
Validation loss: 2.1487755557542205

Epoch: 6| Step: 8
Training loss: 2.808757781982422
Validation loss: 2.145199680841097

Epoch: 6| Step: 9
Training loss: 2.43827223777771
Validation loss: 2.1542950778879146

Epoch: 6| Step: 10
Training loss: 3.3216984272003174
Validation loss: 2.1460011287402083

Epoch: 6| Step: 11
Training loss: 2.320169448852539
Validation loss: 2.139774860874299

Epoch: 6| Step: 12
Training loss: 1.333350419998169
Validation loss: 2.127745223301713

Epoch: 6| Step: 13
Training loss: 2.123757839202881
Validation loss: 2.1476835063708726

Epoch: 346| Step: 0
Training loss: 2.373206377029419
Validation loss: 2.1349725979630665

Epoch: 6| Step: 1
Training loss: 2.578521728515625
Validation loss: 2.1325510868462185

Epoch: 6| Step: 2
Training loss: 2.022969961166382
Validation loss: 2.1314820858740036

Epoch: 6| Step: 3
Training loss: 2.179741859436035
Validation loss: 2.1373673023716098

Epoch: 6| Step: 4
Training loss: 2.2940635681152344
Validation loss: 2.138659429806535

Epoch: 6| Step: 5
Training loss: 2.053948402404785
Validation loss: 2.1356871410082747

Epoch: 6| Step: 6
Training loss: 1.7548210620880127
Validation loss: 2.1280014348286453

Epoch: 6| Step: 7
Training loss: 2.017559289932251
Validation loss: 2.1445210941376223

Epoch: 6| Step: 8
Training loss: 1.9237720966339111
Validation loss: 2.1350876951730378

Epoch: 6| Step: 9
Training loss: 2.637927770614624
Validation loss: 2.1246891739547893

Epoch: 6| Step: 10
Training loss: 2.6132407188415527
Validation loss: 2.1325454993914534

Epoch: 6| Step: 11
Training loss: 2.575798273086548
Validation loss: 2.1269910002267487

Epoch: 6| Step: 12
Training loss: 2.0660500526428223
Validation loss: 2.1381800610532045

Epoch: 6| Step: 13
Training loss: 1.9605857133865356
Validation loss: 2.1304980926616217

Epoch: 347| Step: 0
Training loss: 1.81790292263031
Validation loss: 2.138377030690511

Epoch: 6| Step: 1
Training loss: 2.632002353668213
Validation loss: 2.1395185762836086

Epoch: 6| Step: 2
Training loss: 2.7452635765075684
Validation loss: 2.1591682100808747

Epoch: 6| Step: 3
Training loss: 2.2856247425079346
Validation loss: 2.157135658366706

Epoch: 6| Step: 4
Training loss: 1.959648847579956
Validation loss: 2.1350214865899857

Epoch: 6| Step: 5
Training loss: 2.3786134719848633
Validation loss: 2.12555528712529

Epoch: 6| Step: 6
Training loss: 1.3796405792236328
Validation loss: 2.129461219233851

Epoch: 6| Step: 7
Training loss: 2.4419047832489014
Validation loss: 2.1298843635025846

Epoch: 6| Step: 8
Training loss: 2.166774272918701
Validation loss: 2.1322799139125372

Epoch: 6| Step: 9
Training loss: 1.9867961406707764
Validation loss: 2.127008761129072

Epoch: 6| Step: 10
Training loss: 2.294922351837158
Validation loss: 2.116017738978068

Epoch: 6| Step: 11
Training loss: 2.3953590393066406
Validation loss: 2.1289778755557154

Epoch: 6| Step: 12
Training loss: 2.218371868133545
Validation loss: 2.13098229131391

Epoch: 6| Step: 13
Training loss: 2.984576463699341
Validation loss: 2.130899408812164

Epoch: 348| Step: 0
Training loss: 2.489344596862793
Validation loss: 2.1558382434229695

Epoch: 6| Step: 1
Training loss: 1.1924785375595093
Validation loss: 2.1499232143484135

Epoch: 6| Step: 2
Training loss: 2.798326015472412
Validation loss: 2.143634425696506

Epoch: 6| Step: 3
Training loss: 2.4486708641052246
Validation loss: 2.1451416233534455

Epoch: 6| Step: 4
Training loss: 1.841124415397644
Validation loss: 2.139769979702529

Epoch: 6| Step: 5
Training loss: 2.21415376663208
Validation loss: 2.123655198722757

Epoch: 6| Step: 6
Training loss: 2.0205118656158447
Validation loss: 2.117276563439318

Epoch: 6| Step: 7
Training loss: 2.5096869468688965
Validation loss: 2.1230936434961136

Epoch: 6| Step: 8
Training loss: 2.2127442359924316
Validation loss: 2.1114542638101885

Epoch: 6| Step: 9
Training loss: 1.8151955604553223
Validation loss: 2.123728867500059

Epoch: 6| Step: 10
Training loss: 2.7067363262176514
Validation loss: 2.132956841940521

Epoch: 6| Step: 11
Training loss: 2.747190237045288
Validation loss: 2.1388423314658542

Epoch: 6| Step: 12
Training loss: 1.788529634475708
Validation loss: 2.1567056922502417

Epoch: 6| Step: 13
Training loss: 2.688392162322998
Validation loss: 2.165503668528731

Epoch: 349| Step: 0
Training loss: 2.3081581592559814
Validation loss: 2.1489590637145506

Epoch: 6| Step: 1
Training loss: 2.763540506362915
Validation loss: 2.167770119123561

Epoch: 6| Step: 2
Training loss: 1.9748762845993042
Validation loss: 2.1424859159736225

Epoch: 6| Step: 3
Training loss: 2.004542827606201
Validation loss: 2.1528344974722913

Epoch: 6| Step: 4
Training loss: 1.8708140850067139
Validation loss: 2.147527389628913

Epoch: 6| Step: 5
Training loss: 1.4796992540359497
Validation loss: 2.1388026847634265

Epoch: 6| Step: 6
Training loss: 2.480703830718994
Validation loss: 2.128863355164887

Epoch: 6| Step: 7
Training loss: 2.360792636871338
Validation loss: 2.1183620845117876

Epoch: 6| Step: 8
Training loss: 2.8139984607696533
Validation loss: 2.1270301854738625

Epoch: 6| Step: 9
Training loss: 2.6265463829040527
Validation loss: 2.1319023486106627

Epoch: 6| Step: 10
Training loss: 1.7838529348373413
Validation loss: 2.124290535526891

Epoch: 6| Step: 11
Training loss: 2.1571335792541504
Validation loss: 2.113656372152349

Epoch: 6| Step: 12
Training loss: 2.4677138328552246
Validation loss: 2.1337593293959096

Epoch: 6| Step: 13
Training loss: 2.156937599182129
Validation loss: 2.114761601212204

Epoch: 350| Step: 0
Training loss: 3.204928159713745
Validation loss: 2.1169137518893004

Epoch: 6| Step: 1
Training loss: 2.187069892883301
Validation loss: 2.127281673492924

Epoch: 6| Step: 2
Training loss: 2.2812933921813965
Validation loss: 2.136621102210014

Epoch: 6| Step: 3
Training loss: 2.1181533336639404
Validation loss: 2.1226979276185394

Epoch: 6| Step: 4
Training loss: 2.0622198581695557
Validation loss: 2.1405814514365247

Epoch: 6| Step: 5
Training loss: 2.0745556354522705
Validation loss: 2.1413243765472085

Epoch: 6| Step: 6
Training loss: 1.9926042556762695
Validation loss: 2.155962218520462

Epoch: 6| Step: 7
Training loss: 2.5589113235473633
Validation loss: 2.153602551388484

Epoch: 6| Step: 8
Training loss: 1.7406120300292969
Validation loss: 2.1568537251923674

Epoch: 6| Step: 9
Training loss: 1.9506890773773193
Validation loss: 2.154273925289031

Epoch: 6| Step: 10
Training loss: 2.2453980445861816
Validation loss: 2.158548003883772

Epoch: 6| Step: 11
Training loss: 2.1349592208862305
Validation loss: 2.149666163229173

Epoch: 6| Step: 12
Training loss: 2.303330183029175
Validation loss: 2.14982916590988

Epoch: 6| Step: 13
Training loss: 2.1716439723968506
Validation loss: 2.146834094037292

Epoch: 351| Step: 0
Training loss: 2.322086811065674
Validation loss: 2.153401552989919

Epoch: 6| Step: 1
Training loss: 1.6795369386672974
Validation loss: 2.1594727705883723

Epoch: 6| Step: 2
Training loss: 2.71012544631958
Validation loss: 2.1508488552544707

Epoch: 6| Step: 3
Training loss: 2.089006185531616
Validation loss: 2.138562487017724

Epoch: 6| Step: 4
Training loss: 2.1438722610473633
Validation loss: 2.1172159179564445

Epoch: 6| Step: 5
Training loss: 2.625795841217041
Validation loss: 2.141834023178265

Epoch: 6| Step: 6
Training loss: 1.4878368377685547
Validation loss: 2.1551755051459036

Epoch: 6| Step: 7
Training loss: 1.8331506252288818
Validation loss: 2.155367201374423

Epoch: 6| Step: 8
Training loss: 2.7431185245513916
Validation loss: 2.14894667748482

Epoch: 6| Step: 9
Training loss: 2.8236942291259766
Validation loss: 2.1345239377790883

Epoch: 6| Step: 10
Training loss: 1.9282844066619873
Validation loss: 2.140971529868341

Epoch: 6| Step: 11
Training loss: 2.1924123764038086
Validation loss: 2.1205553803392636

Epoch: 6| Step: 12
Training loss: 2.6078872680664062
Validation loss: 2.118011273363585

Epoch: 6| Step: 13
Training loss: 1.690041422843933
Validation loss: 2.113519932634087

Epoch: 352| Step: 0
Training loss: 2.005669355392456
Validation loss: 2.119153097111692

Epoch: 6| Step: 1
Training loss: 2.919673204421997
Validation loss: 2.1264827635980423

Epoch: 6| Step: 2
Training loss: 2.0763015747070312
Validation loss: 2.133581748572729

Epoch: 6| Step: 3
Training loss: 2.3976054191589355
Validation loss: 2.1273943429352133

Epoch: 6| Step: 4
Training loss: 2.1845171451568604
Validation loss: 2.133149823834819

Epoch: 6| Step: 5
Training loss: 1.7510453462600708
Validation loss: 2.1304568001019057

Epoch: 6| Step: 6
Training loss: 2.709620952606201
Validation loss: 2.1469146615715435

Epoch: 6| Step: 7
Training loss: 2.1763992309570312
Validation loss: 2.1505661779834377

Epoch: 6| Step: 8
Training loss: 2.076357364654541
Validation loss: 2.147646216936009

Epoch: 6| Step: 9
Training loss: 1.219619870185852
Validation loss: 2.145930051803589

Epoch: 6| Step: 10
Training loss: 1.9271256923675537
Validation loss: 2.1643334639969694

Epoch: 6| Step: 11
Training loss: 3.1200156211853027
Validation loss: 2.146842369469263

Epoch: 6| Step: 12
Training loss: 1.9219145774841309
Validation loss: 2.1644911971143497

Epoch: 6| Step: 13
Training loss: 2.9036030769348145
Validation loss: 2.131861173978416

Epoch: 353| Step: 0
Training loss: 2.4035773277282715
Validation loss: 2.1327516776259228

Epoch: 6| Step: 1
Training loss: 1.879235863685608
Validation loss: 2.136528197155204

Epoch: 6| Step: 2
Training loss: 2.2365782260894775
Validation loss: 2.127873807825068

Epoch: 6| Step: 3
Training loss: 1.6766467094421387
Validation loss: 2.1141647061994

Epoch: 6| Step: 4
Training loss: 2.103461742401123
Validation loss: 2.1130990264236287

Epoch: 6| Step: 5
Training loss: 2.481762170791626
Validation loss: 2.1217336834117932

Epoch: 6| Step: 6
Training loss: 2.2575955390930176
Validation loss: 2.1217435329191145

Epoch: 6| Step: 7
Training loss: 1.6138415336608887
Validation loss: 2.124861345496229

Epoch: 6| Step: 8
Training loss: 2.071312189102173
Validation loss: 2.1270655355145855

Epoch: 6| Step: 9
Training loss: 2.3224036693573
Validation loss: 2.137137902680264

Epoch: 6| Step: 10
Training loss: 2.4546122550964355
Validation loss: 2.151449736728463

Epoch: 6| Step: 11
Training loss: 2.797490119934082
Validation loss: 2.138518279598605

Epoch: 6| Step: 12
Training loss: 2.876634359359741
Validation loss: 2.1389443720540693

Epoch: 6| Step: 13
Training loss: 1.6373543739318848
Validation loss: 2.14682283196398

Epoch: 354| Step: 0
Training loss: 2.558138847351074
Validation loss: 2.1423517452773226

Epoch: 6| Step: 1
Training loss: 1.604246735572815
Validation loss: 2.1390418839711014

Epoch: 6| Step: 2
Training loss: 1.8359322547912598
Validation loss: 2.12609871356718

Epoch: 6| Step: 3
Training loss: 1.9761736392974854
Validation loss: 2.1260250127443703

Epoch: 6| Step: 4
Training loss: 1.6228606700897217
Validation loss: 2.1344444033920125

Epoch: 6| Step: 5
Training loss: 2.3553125858306885
Validation loss: 2.111501052815427

Epoch: 6| Step: 6
Training loss: 3.2658755779266357
Validation loss: 2.1491311647558726

Epoch: 6| Step: 7
Training loss: 2.367839813232422
Validation loss: 2.136922603012413

Epoch: 6| Step: 8
Training loss: 2.973769187927246
Validation loss: 2.1403861327837874

Epoch: 6| Step: 9
Training loss: 2.6274235248565674
Validation loss: 2.145354576008294

Epoch: 6| Step: 10
Training loss: 1.8445167541503906
Validation loss: 2.129390319188436

Epoch: 6| Step: 11
Training loss: 2.3245797157287598
Validation loss: 2.123625002881532

Epoch: 6| Step: 12
Training loss: 1.8641152381896973
Validation loss: 2.121716832601896

Epoch: 6| Step: 13
Training loss: 1.376255750656128
Validation loss: 2.1282489889411518

Epoch: 355| Step: 0
Training loss: 1.516218662261963
Validation loss: 2.1336002324217107

Epoch: 6| Step: 1
Training loss: 2.420982837677002
Validation loss: 2.128175502182335

Epoch: 6| Step: 2
Training loss: 2.4134182929992676
Validation loss: 2.137153988243431

Epoch: 6| Step: 3
Training loss: 2.0418484210968018
Validation loss: 2.1398055976436985

Epoch: 6| Step: 4
Training loss: 3.2279999256134033
Validation loss: 2.1442771752675376

Epoch: 6| Step: 5
Training loss: 1.5411378145217896
Validation loss: 2.146412022652165

Epoch: 6| Step: 6
Training loss: 2.0573816299438477
Validation loss: 2.1600177800783547

Epoch: 6| Step: 7
Training loss: 2.143033027648926
Validation loss: 2.1705398316024453

Epoch: 6| Step: 8
Training loss: 2.7997350692749023
Validation loss: 2.171825547372141

Epoch: 6| Step: 9
Training loss: 2.966373920440674
Validation loss: 2.1549018839354157

Epoch: 6| Step: 10
Training loss: 1.587328314781189
Validation loss: 2.1563882776485976

Epoch: 6| Step: 11
Training loss: 1.8401143550872803
Validation loss: 2.145707581632881

Epoch: 6| Step: 12
Training loss: 2.123626232147217
Validation loss: 2.127532894893359

Epoch: 6| Step: 13
Training loss: 2.5998005867004395
Validation loss: 2.112356680695729

Epoch: 356| Step: 0
Training loss: 2.0449764728546143
Validation loss: 2.1212692773470314

Epoch: 6| Step: 1
Training loss: 1.9356465339660645
Validation loss: 2.113249930002356

Epoch: 6| Step: 2
Training loss: 2.723520040512085
Validation loss: 2.1013220856266637

Epoch: 6| Step: 3
Training loss: 1.8630695343017578
Validation loss: 2.1098672933475946

Epoch: 6| Step: 4
Training loss: 2.0573103427886963
Validation loss: 2.1120532994629233

Epoch: 6| Step: 5
Training loss: 2.300929069519043
Validation loss: 2.1059859247617823

Epoch: 6| Step: 6
Training loss: 2.315497398376465
Validation loss: 2.125397700135426

Epoch: 6| Step: 7
Training loss: 2.5176315307617188
Validation loss: 2.1298634993132723

Epoch: 6| Step: 8
Training loss: 2.783874750137329
Validation loss: 2.150237362871888

Epoch: 6| Step: 9
Training loss: 1.8000214099884033
Validation loss: 2.148437676891204

Epoch: 6| Step: 10
Training loss: 1.8776357173919678
Validation loss: 2.162138086493297

Epoch: 6| Step: 11
Training loss: 2.451554536819458
Validation loss: 2.161737585580477

Epoch: 6| Step: 12
Training loss: 2.2045130729675293
Validation loss: 2.159672070575017

Epoch: 6| Step: 13
Training loss: 2.313762664794922
Validation loss: 2.1423492380367812

Epoch: 357| Step: 0
Training loss: 2.041703701019287
Validation loss: 2.1363754195551716

Epoch: 6| Step: 1
Training loss: 2.391447067260742
Validation loss: 2.133543755418511

Epoch: 6| Step: 2
Training loss: 2.8019065856933594
Validation loss: 2.1411422798710484

Epoch: 6| Step: 3
Training loss: 2.409940004348755
Validation loss: 2.14781488526252

Epoch: 6| Step: 4
Training loss: 2.6851844787597656
Validation loss: 2.1501156219872097

Epoch: 6| Step: 5
Training loss: 2.487528085708618
Validation loss: 2.145817861762098

Epoch: 6| Step: 6
Training loss: 2.2898154258728027
Validation loss: 2.141938142879035

Epoch: 6| Step: 7
Training loss: 2.1403141021728516
Validation loss: 2.1230609801507767

Epoch: 6| Step: 8
Training loss: 2.0322518348693848
Validation loss: 2.1217156328180784

Epoch: 6| Step: 9
Training loss: 2.2932097911834717
Validation loss: 2.126325656008977

Epoch: 6| Step: 10
Training loss: 2.1714539527893066
Validation loss: 2.131211111622472

Epoch: 6| Step: 11
Training loss: 1.5968801975250244
Validation loss: 2.1386352072479906

Epoch: 6| Step: 12
Training loss: 1.9895668029785156
Validation loss: 2.143540831022365

Epoch: 6| Step: 13
Training loss: 1.7839088439941406
Validation loss: 2.147983771498485

Epoch: 358| Step: 0
Training loss: 1.6545772552490234
Validation loss: 2.129142108783927

Epoch: 6| Step: 1
Training loss: 1.7064056396484375
Validation loss: 2.118111166902768

Epoch: 6| Step: 2
Training loss: 2.4832777976989746
Validation loss: 2.107120221660983

Epoch: 6| Step: 3
Training loss: 2.0524797439575195
Validation loss: 2.1227426772476523

Epoch: 6| Step: 4
Training loss: 1.9698998928070068
Validation loss: 2.113536783443984

Epoch: 6| Step: 5
Training loss: 1.775740623474121
Validation loss: 2.1218407436083724

Epoch: 6| Step: 6
Training loss: 2.666368246078491
Validation loss: 2.116744049133793

Epoch: 6| Step: 7
Training loss: 2.2748429775238037
Validation loss: 2.1145758680118028

Epoch: 6| Step: 8
Training loss: 2.0387372970581055
Validation loss: 2.128863493601481

Epoch: 6| Step: 9
Training loss: 2.211995840072632
Validation loss: 2.123944362004598

Epoch: 6| Step: 10
Training loss: 2.420551300048828
Validation loss: 2.1230130375072522

Epoch: 6| Step: 11
Training loss: 2.932703971862793
Validation loss: 2.132886209795552

Epoch: 6| Step: 12
Training loss: 2.082674026489258
Validation loss: 2.1374441974906513

Epoch: 6| Step: 13
Training loss: 2.723163604736328
Validation loss: 2.1280990672367874

Epoch: 359| Step: 0
Training loss: 1.8860728740692139
Validation loss: 2.144909042184071

Epoch: 6| Step: 1
Training loss: 2.5645804405212402
Validation loss: 2.1338975096261628

Epoch: 6| Step: 2
Training loss: 1.8371999263763428
Validation loss: 2.1464578695194696

Epoch: 6| Step: 3
Training loss: 2.4736764430999756
Validation loss: 2.1552727401897473

Epoch: 6| Step: 4
Training loss: 1.5684064626693726
Validation loss: 2.137836407589656

Epoch: 6| Step: 5
Training loss: 1.914089560508728
Validation loss: 2.142037376280754

Epoch: 6| Step: 6
Training loss: 2.0245113372802734
Validation loss: 2.1345392286136584

Epoch: 6| Step: 7
Training loss: 2.9135854244232178
Validation loss: 2.1293984177292034

Epoch: 6| Step: 8
Training loss: 1.8927395343780518
Validation loss: 2.1292555716729935

Epoch: 6| Step: 9
Training loss: 1.902031660079956
Validation loss: 2.121036947414439

Epoch: 6| Step: 10
Training loss: 1.7279378175735474
Validation loss: 2.1193779207045034

Epoch: 6| Step: 11
Training loss: 3.4291601181030273
Validation loss: 2.119857749631328

Epoch: 6| Step: 12
Training loss: 2.5176868438720703
Validation loss: 2.125048069543736

Epoch: 6| Step: 13
Training loss: 1.9922362565994263
Validation loss: 2.1039446271875852

Epoch: 360| Step: 0
Training loss: 2.0548949241638184
Validation loss: 2.1208973161635862

Epoch: 6| Step: 1
Training loss: 2.1261534690856934
Validation loss: 2.125322543164735

Epoch: 6| Step: 2
Training loss: 3.0317869186401367
Validation loss: 2.118843460595736

Epoch: 6| Step: 3
Training loss: 2.223799705505371
Validation loss: 2.147711133444181

Epoch: 6| Step: 4
Training loss: 2.7165236473083496
Validation loss: 2.148401468030868

Epoch: 6| Step: 5
Training loss: 2.201850414276123
Validation loss: 2.14265428819964

Epoch: 6| Step: 6
Training loss: 1.9246515035629272
Validation loss: 2.1411697685077624

Epoch: 6| Step: 7
Training loss: 2.113034725189209
Validation loss: 2.1507156177233626

Epoch: 6| Step: 8
Training loss: 1.7027084827423096
Validation loss: 2.1410404687286704

Epoch: 6| Step: 9
Training loss: 1.5280309915542603
Validation loss: 2.1289767757538827

Epoch: 6| Step: 10
Training loss: 2.062345504760742
Validation loss: 2.1146450914362425

Epoch: 6| Step: 11
Training loss: 2.285109758377075
Validation loss: 2.1152392100262385

Epoch: 6| Step: 12
Training loss: 2.5022308826446533
Validation loss: 2.1137988246897215

Epoch: 6| Step: 13
Training loss: 2.101661205291748
Validation loss: 2.114979831121301

Epoch: 361| Step: 0
Training loss: 1.8997009992599487
Validation loss: 2.1228305114212858

Epoch: 6| Step: 1
Training loss: 2.606733798980713
Validation loss: 2.121603983704762

Epoch: 6| Step: 2
Training loss: 2.695913314819336
Validation loss: 2.123984921363092

Epoch: 6| Step: 3
Training loss: 1.5060205459594727
Validation loss: 2.1327963362457933

Epoch: 6| Step: 4
Training loss: 2.4627678394317627
Validation loss: 2.1369120074856665

Epoch: 6| Step: 5
Training loss: 1.6750426292419434
Validation loss: 2.1414838221765335

Epoch: 6| Step: 6
Training loss: 2.234001636505127
Validation loss: 2.1457008315670874

Epoch: 6| Step: 7
Training loss: 2.039717197418213
Validation loss: 2.1613411211198374

Epoch: 6| Step: 8
Training loss: 2.740741491317749
Validation loss: 2.1506275041129

Epoch: 6| Step: 9
Training loss: 2.236994743347168
Validation loss: 2.144719580168365

Epoch: 6| Step: 10
Training loss: 2.3114418983459473
Validation loss: 2.1493552243837746

Epoch: 6| Step: 11
Training loss: 1.8650200366973877
Validation loss: 2.1623567201757945

Epoch: 6| Step: 12
Training loss: 2.3436875343322754
Validation loss: 2.1590260690258396

Epoch: 6| Step: 13
Training loss: 1.8496956825256348
Validation loss: 2.1511390273289015

Epoch: 362| Step: 0
Training loss: 2.3583574295043945
Validation loss: 2.1372811768644597

Epoch: 6| Step: 1
Training loss: 2.1831588745117188
Validation loss: 2.130292579691897

Epoch: 6| Step: 2
Training loss: 2.248025417327881
Validation loss: 2.1258891910635014

Epoch: 6| Step: 3
Training loss: 1.617353916168213
Validation loss: 2.1052411948480914

Epoch: 6| Step: 4
Training loss: 2.524479866027832
Validation loss: 2.1196203693266837

Epoch: 6| Step: 5
Training loss: 1.9296684265136719
Validation loss: 2.117678447436261

Epoch: 6| Step: 6
Training loss: 2.2283053398132324
Validation loss: 2.105364199607603

Epoch: 6| Step: 7
Training loss: 2.776486873626709
Validation loss: 2.101151809897474

Epoch: 6| Step: 8
Training loss: 1.8275114297866821
Validation loss: 2.110643717550462

Epoch: 6| Step: 9
Training loss: 1.8153674602508545
Validation loss: 2.113204812490812

Epoch: 6| Step: 10
Training loss: 2.6213297843933105
Validation loss: 2.1224677255076747

Epoch: 6| Step: 11
Training loss: 2.549056053161621
Validation loss: 2.126588829102055

Epoch: 6| Step: 12
Training loss: 1.847947597503662
Validation loss: 2.152044084764296

Epoch: 6| Step: 13
Training loss: 2.3105459213256836
Validation loss: 2.148566581869638

Epoch: 363| Step: 0
Training loss: 2.267859697341919
Validation loss: 2.166940660886867

Epoch: 6| Step: 1
Training loss: 2.469027519226074
Validation loss: 2.1830109575743317

Epoch: 6| Step: 2
Training loss: 2.0322203636169434
Validation loss: 2.170725526348237

Epoch: 6| Step: 3
Training loss: 1.917517900466919
Validation loss: 2.1549250707831433

Epoch: 6| Step: 4
Training loss: 2.1224400997161865
Validation loss: 2.127853769128041

Epoch: 6| Step: 5
Training loss: 2.115624189376831
Validation loss: 2.134536914927985

Epoch: 6| Step: 6
Training loss: 2.1449508666992188
Validation loss: 2.125397002825173

Epoch: 6| Step: 7
Training loss: 3.0796396732330322
Validation loss: 2.1212328787772887

Epoch: 6| Step: 8
Training loss: 2.982957601547241
Validation loss: 2.129080162253431

Epoch: 6| Step: 9
Training loss: 1.2773728370666504
Validation loss: 2.13209242077284

Epoch: 6| Step: 10
Training loss: 1.9596951007843018
Validation loss: 2.1192104534436296

Epoch: 6| Step: 11
Training loss: 2.2489824295043945
Validation loss: 2.101864996776786

Epoch: 6| Step: 12
Training loss: 2.147454023361206
Validation loss: 2.0971265685173774

Epoch: 6| Step: 13
Training loss: 2.4467499256134033
Validation loss: 2.1066482092744563

Epoch: 364| Step: 0
Training loss: 1.847556710243225
Validation loss: 2.1267019984542683

Epoch: 6| Step: 1
Training loss: 2.784698247909546
Validation loss: 2.1450713142271964

Epoch: 6| Step: 2
Training loss: 2.7571825981140137
Validation loss: 2.154560955621863

Epoch: 6| Step: 3
Training loss: 1.5818376541137695
Validation loss: 2.149547461540468

Epoch: 6| Step: 4
Training loss: 1.9000422954559326
Validation loss: 2.1411476699254846

Epoch: 6| Step: 5
Training loss: 1.579614520072937
Validation loss: 2.1291553589605514

Epoch: 6| Step: 6
Training loss: 2.9402520656585693
Validation loss: 2.1087980808750277

Epoch: 6| Step: 7
Training loss: 2.5819125175476074
Validation loss: 2.1046678891745945

Epoch: 6| Step: 8
Training loss: 1.5352394580841064
Validation loss: 2.1111990046757523

Epoch: 6| Step: 9
Training loss: 2.2620487213134766
Validation loss: 2.093873467496646

Epoch: 6| Step: 10
Training loss: 1.7865924835205078
Validation loss: 2.103398792205318

Epoch: 6| Step: 11
Training loss: 2.692871570587158
Validation loss: 2.1030218960136495

Epoch: 6| Step: 12
Training loss: 2.4232401847839355
Validation loss: 2.0962471346701346

Epoch: 6| Step: 13
Training loss: 1.9130641222000122
Validation loss: 2.11498180256095

Epoch: 365| Step: 0
Training loss: 2.203841209411621
Validation loss: 2.122584263483683

Epoch: 6| Step: 1
Training loss: 2.1273584365844727
Validation loss: 2.1196652843106176

Epoch: 6| Step: 2
Training loss: 2.0885937213897705
Validation loss: 2.123331607029002

Epoch: 6| Step: 3
Training loss: 2.1770925521850586
Validation loss: 2.1244634453968336

Epoch: 6| Step: 4
Training loss: 2.257087230682373
Validation loss: 2.129296450204747

Epoch: 6| Step: 5
Training loss: 1.4986317157745361
Validation loss: 2.1443326755236556

Epoch: 6| Step: 6
Training loss: 2.3377275466918945
Validation loss: 2.1507447509355444

Epoch: 6| Step: 7
Training loss: 2.4727580547332764
Validation loss: 2.1522181803180325

Epoch: 6| Step: 8
Training loss: 2.0333194732666016
Validation loss: 2.1429383677821003

Epoch: 6| Step: 9
Training loss: 1.4425239562988281
Validation loss: 2.141370798951836

Epoch: 6| Step: 10
Training loss: 2.6959352493286133
Validation loss: 2.1532486613078783

Epoch: 6| Step: 11
Training loss: 2.9060544967651367
Validation loss: 2.1182792673828783

Epoch: 6| Step: 12
Training loss: 2.4796557426452637
Validation loss: 2.1102275617661013

Epoch: 6| Step: 13
Training loss: 1.9478721618652344
Validation loss: 2.114145121266765

Epoch: 366| Step: 0
Training loss: 1.4046305418014526
Validation loss: 2.115678478312749

Epoch: 6| Step: 1
Training loss: 2.5702109336853027
Validation loss: 2.108054348217544

Epoch: 6| Step: 2
Training loss: 2.1816563606262207
Validation loss: 2.1118543122404363

Epoch: 6| Step: 3
Training loss: 2.0038764476776123
Validation loss: 2.12123933915169

Epoch: 6| Step: 4
Training loss: 2.1207876205444336
Validation loss: 2.122838612525694

Epoch: 6| Step: 5
Training loss: 2.596785545349121
Validation loss: 2.1238389745835335

Epoch: 6| Step: 6
Training loss: 1.7954185009002686
Validation loss: 2.145228798671435

Epoch: 6| Step: 7
Training loss: 2.273837089538574
Validation loss: 2.1516034192936395

Epoch: 6| Step: 8
Training loss: 2.5082201957702637
Validation loss: 2.13841748750338

Epoch: 6| Step: 9
Training loss: 2.1606597900390625
Validation loss: 2.1451651357835337

Epoch: 6| Step: 10
Training loss: 2.572037935256958
Validation loss: 2.1533955361253474

Epoch: 6| Step: 11
Training loss: 2.0365102291107178
Validation loss: 2.156515241951071

Epoch: 6| Step: 12
Training loss: 1.577714443206787
Validation loss: 2.1525703399412093

Epoch: 6| Step: 13
Training loss: 3.2356271743774414
Validation loss: 2.1337619302093342

Epoch: 367| Step: 0
Training loss: 2.504258871078491
Validation loss: 2.1171140299048474

Epoch: 6| Step: 1
Training loss: 1.7515814304351807
Validation loss: 2.124780853589376

Epoch: 6| Step: 2
Training loss: 2.463042736053467
Validation loss: 2.1202146571169616

Epoch: 6| Step: 3
Training loss: 1.8479750156402588
Validation loss: 2.1108716457120833

Epoch: 6| Step: 4
Training loss: 2.1238434314727783
Validation loss: 2.1068463248591267

Epoch: 6| Step: 5
Training loss: 1.746157169342041
Validation loss: 2.1007381818627797

Epoch: 6| Step: 6
Training loss: 1.5563751459121704
Validation loss: 2.103974078291206

Epoch: 6| Step: 7
Training loss: 2.032338857650757
Validation loss: 2.100624274182063

Epoch: 6| Step: 8
Training loss: 2.6881322860717773
Validation loss: 2.102804591578822

Epoch: 6| Step: 9
Training loss: 2.991018533706665
Validation loss: 2.1126097197173745

Epoch: 6| Step: 10
Training loss: 2.329517364501953
Validation loss: 2.1076267534686672

Epoch: 6| Step: 11
Training loss: 2.6001906394958496
Validation loss: 2.108171591194727

Epoch: 6| Step: 12
Training loss: 1.778855562210083
Validation loss: 2.1185799721748597

Epoch: 6| Step: 13
Training loss: 2.1501946449279785
Validation loss: 2.1257340908050537

Epoch: 368| Step: 0
Training loss: 1.6622930765151978
Validation loss: 2.129321713601389

Epoch: 6| Step: 1
Training loss: 2.2379088401794434
Validation loss: 2.139749583377633

Epoch: 6| Step: 2
Training loss: 1.5433290004730225
Validation loss: 2.1398845923844205

Epoch: 6| Step: 3
Training loss: 2.491010904312134
Validation loss: 2.1500133545167985

Epoch: 6| Step: 4
Training loss: 2.0330357551574707
Validation loss: 2.1723682547128327

Epoch: 6| Step: 5
Training loss: 2.735521078109741
Validation loss: 2.1557224283936205

Epoch: 6| Step: 6
Training loss: 2.5196533203125
Validation loss: 2.1515899242893344

Epoch: 6| Step: 7
Training loss: 1.996009111404419
Validation loss: 2.144988138188598

Epoch: 6| Step: 8
Training loss: 2.475980520248413
Validation loss: 2.1344421884065032

Epoch: 6| Step: 9
Training loss: 2.438988208770752
Validation loss: 2.120808473197363

Epoch: 6| Step: 10
Training loss: 2.259817123413086
Validation loss: 2.1352232053715694

Epoch: 6| Step: 11
Training loss: 1.9830927848815918
Validation loss: 2.1323051106545234

Epoch: 6| Step: 12
Training loss: 2.3431339263916016
Validation loss: 2.1270327875691075

Epoch: 6| Step: 13
Training loss: 1.5986499786376953
Validation loss: 2.123277897475868

Epoch: 369| Step: 0
Training loss: 2.8096187114715576
Validation loss: 2.1113328344078472

Epoch: 6| Step: 1
Training loss: 1.8657599687576294
Validation loss: 2.113695785563479

Epoch: 6| Step: 2
Training loss: 1.9218883514404297
Validation loss: 2.1084177981140795

Epoch: 6| Step: 3
Training loss: 2.076615810394287
Validation loss: 2.1133536074751165

Epoch: 6| Step: 4
Training loss: 2.1880016326904297
Validation loss: 2.1236421497919227

Epoch: 6| Step: 5
Training loss: 2.992537498474121
Validation loss: 2.1219403602743663

Epoch: 6| Step: 6
Training loss: 1.9248521327972412
Validation loss: 2.133099215005034

Epoch: 6| Step: 7
Training loss: 1.7571858167648315
Validation loss: 2.1290115899937128

Epoch: 6| Step: 8
Training loss: 2.2595372200012207
Validation loss: 2.156015189745093

Epoch: 6| Step: 9
Training loss: 1.5742982625961304
Validation loss: 2.1434737508014967

Epoch: 6| Step: 10
Training loss: 2.3284482955932617
Validation loss: 2.1401141869124545

Epoch: 6| Step: 11
Training loss: 2.0717639923095703
Validation loss: 2.1319393803996425

Epoch: 6| Step: 12
Training loss: 2.2359490394592285
Validation loss: 2.133563527496912

Epoch: 6| Step: 13
Training loss: 2.778157949447632
Validation loss: 2.136395746661771

Epoch: 370| Step: 0
Training loss: 2.2126119136810303
Validation loss: 2.127052809602471

Epoch: 6| Step: 1
Training loss: 2.640700340270996
Validation loss: 2.1109903909826793

Epoch: 6| Step: 2
Training loss: 1.8474397659301758
Validation loss: 2.1048663867417203

Epoch: 6| Step: 3
Training loss: 1.531876802444458
Validation loss: 2.1132828215117097

Epoch: 6| Step: 4
Training loss: 2.2920475006103516
Validation loss: 2.1135820675921697

Epoch: 6| Step: 5
Training loss: 2.1379799842834473
Validation loss: 2.088539238898985

Epoch: 6| Step: 6
Training loss: 2.035208225250244
Validation loss: 2.0810468594233194

Epoch: 6| Step: 7
Training loss: 2.5277111530303955
Validation loss: 2.0859828559301232

Epoch: 6| Step: 8
Training loss: 2.8085391521453857
Validation loss: 2.077203240445865

Epoch: 6| Step: 9
Training loss: 2.182507038116455
Validation loss: 2.06469375600097

Epoch: 6| Step: 10
Training loss: 2.6348013877868652
Validation loss: 2.0727853826297227

Epoch: 6| Step: 11
Training loss: 1.876980185508728
Validation loss: 2.081985560796594

Epoch: 6| Step: 12
Training loss: 1.4812085628509521
Validation loss: 2.097669509149367

Epoch: 6| Step: 13
Training loss: 2.4812047481536865
Validation loss: 2.114666638835784

Epoch: 371| Step: 0
Training loss: 2.5962793827056885
Validation loss: 2.109206961047265

Epoch: 6| Step: 1
Training loss: 2.6155953407287598
Validation loss: 2.1414110570825557

Epoch: 6| Step: 2
Training loss: 2.78601336479187
Validation loss: 2.1167402100819412

Epoch: 6| Step: 3
Training loss: 2.584115505218506
Validation loss: 2.1263414275261665

Epoch: 6| Step: 4
Training loss: 1.5563387870788574
Validation loss: 2.1343320556866225

Epoch: 6| Step: 5
Training loss: 1.7008432149887085
Validation loss: 2.143720797313157

Epoch: 6| Step: 6
Training loss: 2.798687696456909
Validation loss: 2.1504964879764024

Epoch: 6| Step: 7
Training loss: 2.161069393157959
Validation loss: 2.1510068396086335

Epoch: 6| Step: 8
Training loss: 1.7994107007980347
Validation loss: 2.1570383041135726

Epoch: 6| Step: 9
Training loss: 1.958296298980713
Validation loss: 2.1559310869504045

Epoch: 6| Step: 10
Training loss: 1.7109864950180054
Validation loss: 2.138314406077067

Epoch: 6| Step: 11
Training loss: 1.9855917692184448
Validation loss: 2.159124484626196

Epoch: 6| Step: 12
Training loss: 2.4301438331604004
Validation loss: 2.1564336528060255

Epoch: 6| Step: 13
Training loss: 1.4465546607971191
Validation loss: 2.1571230426911385

Epoch: 372| Step: 0
Training loss: 1.5519518852233887
Validation loss: 2.1523641399157944

Epoch: 6| Step: 1
Training loss: 2.5736684799194336
Validation loss: 2.129209428705195

Epoch: 6| Step: 2
Training loss: 1.7765276432037354
Validation loss: 2.12837782982857

Epoch: 6| Step: 3
Training loss: 1.4053277969360352
Validation loss: 2.1335697007435623

Epoch: 6| Step: 4
Training loss: 2.0923237800598145
Validation loss: 2.1280246575673423

Epoch: 6| Step: 5
Training loss: 2.027708053588867
Validation loss: 2.1322939049813057

Epoch: 6| Step: 6
Training loss: 2.4559764862060547
Validation loss: 2.1280731936936736

Epoch: 6| Step: 7
Training loss: 2.054962396621704
Validation loss: 2.146916630447552

Epoch: 6| Step: 8
Training loss: 2.6072661876678467
Validation loss: 2.154902324881605

Epoch: 6| Step: 9
Training loss: 2.155001640319824
Validation loss: 2.14417544744348

Epoch: 6| Step: 10
Training loss: 2.6897740364074707
Validation loss: 2.1344463568861767

Epoch: 6| Step: 11
Training loss: 2.3794007301330566
Validation loss: 2.117937077758133

Epoch: 6| Step: 12
Training loss: 2.7006137371063232
Validation loss: 2.118822210578508

Epoch: 6| Step: 13
Training loss: 1.3750711679458618
Validation loss: 2.098779268162225

Epoch: 373| Step: 0
Training loss: 2.6191940307617188
Validation loss: 2.100110730817241

Epoch: 6| Step: 1
Training loss: 1.7563165426254272
Validation loss: 2.092921790256295

Epoch: 6| Step: 2
Training loss: 2.52087140083313
Validation loss: 2.0928888782378166

Epoch: 6| Step: 3
Training loss: 1.788975715637207
Validation loss: 2.0898841299036497

Epoch: 6| Step: 4
Training loss: 1.8631528615951538
Validation loss: 2.0943781919376825

Epoch: 6| Step: 5
Training loss: 2.3320021629333496
Validation loss: 2.087374766667684

Epoch: 6| Step: 6
Training loss: 2.0001726150512695
Validation loss: 2.1014503073948685

Epoch: 6| Step: 7
Training loss: 1.9626280069351196
Validation loss: 2.1035483998637043

Epoch: 6| Step: 8
Training loss: 2.541367292404175
Validation loss: 2.081964268479296

Epoch: 6| Step: 9
Training loss: 1.8073203563690186
Validation loss: 2.1086148062059955

Epoch: 6| Step: 10
Training loss: 2.377715826034546
Validation loss: 2.093654922259751

Epoch: 6| Step: 11
Training loss: 2.597670078277588
Validation loss: 2.084610839043894

Epoch: 6| Step: 12
Training loss: 1.3314526081085205
Validation loss: 2.087094710719201

Epoch: 6| Step: 13
Training loss: 3.0728673934936523
Validation loss: 2.0873344431641283

Epoch: 374| Step: 0
Training loss: 2.13455867767334
Validation loss: 2.0951187072261686

Epoch: 6| Step: 1
Training loss: 2.1282293796539307
Validation loss: 2.0850244722058697

Epoch: 6| Step: 2
Training loss: 2.321713924407959
Validation loss: 2.0964414432484615

Epoch: 6| Step: 3
Training loss: 2.1191563606262207
Validation loss: 2.0737737878676383

Epoch: 6| Step: 4
Training loss: 2.3898520469665527
Validation loss: 2.088648506390151

Epoch: 6| Step: 5
Training loss: 1.897919774055481
Validation loss: 2.105508563339069

Epoch: 6| Step: 6
Training loss: 2.036675453186035
Validation loss: 2.1159953737771637

Epoch: 6| Step: 7
Training loss: 2.3669047355651855
Validation loss: 2.116531797634658

Epoch: 6| Step: 8
Training loss: 2.013881206512451
Validation loss: 2.1115786478083622

Epoch: 6| Step: 9
Training loss: 1.7282569408416748
Validation loss: 2.1237231377632386

Epoch: 6| Step: 10
Training loss: 2.576676368713379
Validation loss: 2.1090293674058813

Epoch: 6| Step: 11
Training loss: 2.412196636199951
Validation loss: 2.1014658097297914

Epoch: 6| Step: 12
Training loss: 1.8417233228683472
Validation loss: 2.1096166744027087

Epoch: 6| Step: 13
Training loss: 2.2926862239837646
Validation loss: 2.081630887523774

Epoch: 375| Step: 0
Training loss: 2.1757731437683105
Validation loss: 2.076793909072876

Epoch: 6| Step: 1
Training loss: 2.4719901084899902
Validation loss: 2.0796886926056235

Epoch: 6| Step: 2
Training loss: 2.0918917655944824
Validation loss: 2.0877194917330177

Epoch: 6| Step: 3
Training loss: 1.652367115020752
Validation loss: 2.106189097127607

Epoch: 6| Step: 4
Training loss: 2.404944896697998
Validation loss: 2.082313778579876

Epoch: 6| Step: 5
Training loss: 1.9380950927734375
Validation loss: 2.101746743725192

Epoch: 6| Step: 6
Training loss: 1.5956225395202637
Validation loss: 2.107956688891175

Epoch: 6| Step: 7
Training loss: 2.698617696762085
Validation loss: 2.115785014244818

Epoch: 6| Step: 8
Training loss: 2.505124807357788
Validation loss: 2.127253391409433

Epoch: 6| Step: 9
Training loss: 2.5875911712646484
Validation loss: 2.150786346004855

Epoch: 6| Step: 10
Training loss: 1.9050039052963257
Validation loss: 2.180507318947905

Epoch: 6| Step: 11
Training loss: 2.2534751892089844
Validation loss: 2.203946336623161

Epoch: 6| Step: 12
Training loss: 2.029721260070801
Validation loss: 2.2284188988388225

Epoch: 6| Step: 13
Training loss: 2.0902833938598633
Validation loss: 2.2244110902150473

Epoch: 376| Step: 0
Training loss: 1.9593548774719238
Validation loss: 2.1953039464130195

Epoch: 6| Step: 1
Training loss: 2.461386203765869
Validation loss: 2.1774756216233775

Epoch: 6| Step: 2
Training loss: 2.3514819145202637
Validation loss: 2.1432234548753306

Epoch: 6| Step: 3
Training loss: 2.0662841796875
Validation loss: 2.1347900282952095

Epoch: 6| Step: 4
Training loss: 2.769188642501831
Validation loss: 2.124249622385989

Epoch: 6| Step: 5
Training loss: 1.9643855094909668
Validation loss: 2.1046020677012782

Epoch: 6| Step: 6
Training loss: 2.247178554534912
Validation loss: 2.122221856988886

Epoch: 6| Step: 7
Training loss: 2.6561145782470703
Validation loss: 2.1054171208412416

Epoch: 6| Step: 8
Training loss: 1.6114493608474731
Validation loss: 2.0970039944494925

Epoch: 6| Step: 9
Training loss: 1.4074527025222778
Validation loss: 2.099601412332186

Epoch: 6| Step: 10
Training loss: 1.2742819786071777
Validation loss: 2.08871905778044

Epoch: 6| Step: 11
Training loss: 3.2306783199310303
Validation loss: 2.103123095727736

Epoch: 6| Step: 12
Training loss: 2.4979467391967773
Validation loss: 2.110651195690196

Epoch: 6| Step: 13
Training loss: 1.7326598167419434
Validation loss: 2.1173673675906275

Epoch: 377| Step: 0
Training loss: 1.8283370733261108
Validation loss: 2.136508055912551

Epoch: 6| Step: 1
Training loss: 2.0028650760650635
Validation loss: 2.1581824646201184

Epoch: 6| Step: 2
Training loss: 3.147749662399292
Validation loss: 2.1523260301159275

Epoch: 6| Step: 3
Training loss: 2.132707118988037
Validation loss: 2.1583540849788214

Epoch: 6| Step: 4
Training loss: 2.601590156555176
Validation loss: 2.1477005943175285

Epoch: 6| Step: 5
Training loss: 1.9850375652313232
Validation loss: 2.1397397825794835

Epoch: 6| Step: 6
Training loss: 1.8981527090072632
Validation loss: 2.136602229969476

Epoch: 6| Step: 7
Training loss: 1.4257216453552246
Validation loss: 2.1283203760782876

Epoch: 6| Step: 8
Training loss: 2.3126492500305176
Validation loss: 2.129671686439104

Epoch: 6| Step: 9
Training loss: 2.493048667907715
Validation loss: 2.126303329262682

Epoch: 6| Step: 10
Training loss: 1.9183766841888428
Validation loss: 2.108918771948866

Epoch: 6| Step: 11
Training loss: 2.3694300651550293
Validation loss: 2.1020543780378116

Epoch: 6| Step: 12
Training loss: 1.9249317646026611
Validation loss: 2.1027758506036576

Epoch: 6| Step: 13
Training loss: 2.7277276515960693
Validation loss: 2.1002911265178392

Epoch: 378| Step: 0
Training loss: 1.9945316314697266
Validation loss: 2.103857563387963

Epoch: 6| Step: 1
Training loss: 2.42050838470459
Validation loss: 2.105096237633818

Epoch: 6| Step: 2
Training loss: 1.5608563423156738
Validation loss: 2.1101814521256315

Epoch: 6| Step: 3
Training loss: 2.578670024871826
Validation loss: 2.114132131299665

Epoch: 6| Step: 4
Training loss: 1.8841681480407715
Validation loss: 2.1119591343787407

Epoch: 6| Step: 5
Training loss: 2.5020532608032227
Validation loss: 2.1126858752260924

Epoch: 6| Step: 6
Training loss: 1.6879554986953735
Validation loss: 2.142178899498396

Epoch: 6| Step: 7
Training loss: 2.2257957458496094
Validation loss: 2.1546267412042104

Epoch: 6| Step: 8
Training loss: 2.0404610633850098
Validation loss: 2.1485530894289733

Epoch: 6| Step: 9
Training loss: 2.556403160095215
Validation loss: 2.1492971784325055

Epoch: 6| Step: 10
Training loss: 1.822742223739624
Validation loss: 2.147063188655402

Epoch: 6| Step: 11
Training loss: 2.1262729167938232
Validation loss: 2.155393236426897

Epoch: 6| Step: 12
Training loss: 2.4967613220214844
Validation loss: 2.1572982444558093

Epoch: 6| Step: 13
Training loss: 2.3822414875030518
Validation loss: 2.143717478680354

Epoch: 379| Step: 0
Training loss: 2.013794422149658
Validation loss: 2.140367083652045

Epoch: 6| Step: 1
Training loss: 2.2256789207458496
Validation loss: 2.127831893582498

Epoch: 6| Step: 2
Training loss: 2.416367530822754
Validation loss: 2.1052558242633777

Epoch: 6| Step: 3
Training loss: 1.761444330215454
Validation loss: 2.0997430111772273

Epoch: 6| Step: 4
Training loss: 1.81337308883667
Validation loss: 2.0936828223607873

Epoch: 6| Step: 5
Training loss: 2.37538743019104
Validation loss: 2.1045736805085213

Epoch: 6| Step: 6
Training loss: 2.0503385066986084
Validation loss: 2.1109111808961436

Epoch: 6| Step: 7
Training loss: 2.2402913570404053
Validation loss: 2.107674393602597

Epoch: 6| Step: 8
Training loss: 1.6988142728805542
Validation loss: 2.1294964898017144

Epoch: 6| Step: 9
Training loss: 1.799497127532959
Validation loss: 2.1282707363046627

Epoch: 6| Step: 10
Training loss: 2.5127925872802734
Validation loss: 2.1244371808985227

Epoch: 6| Step: 11
Training loss: 3.062425374984741
Validation loss: 2.122077626566733

Epoch: 6| Step: 12
Training loss: 2.3539836406707764
Validation loss: 2.112327984584275

Epoch: 6| Step: 13
Training loss: 1.2872425317764282
Validation loss: 2.1137773554812194

Epoch: 380| Step: 0
Training loss: 2.4922900199890137
Validation loss: 2.1185929877783662

Epoch: 6| Step: 1
Training loss: 2.313507318496704
Validation loss: 2.1016044360335155

Epoch: 6| Step: 2
Training loss: 1.685468077659607
Validation loss: 2.1097179946079048

Epoch: 6| Step: 3
Training loss: 2.000617265701294
Validation loss: 2.103132729889244

Epoch: 6| Step: 4
Training loss: 2.6374926567077637
Validation loss: 2.098235043146277

Epoch: 6| Step: 5
Training loss: 2.474832057952881
Validation loss: 2.0876083245841404

Epoch: 6| Step: 6
Training loss: 2.2833895683288574
Validation loss: 2.074637786034615

Epoch: 6| Step: 7
Training loss: 2.103823184967041
Validation loss: 2.0849243594754125

Epoch: 6| Step: 8
Training loss: 2.0731239318847656
Validation loss: 2.063267247651213

Epoch: 6| Step: 9
Training loss: 2.019120216369629
Validation loss: 2.0624970748860347

Epoch: 6| Step: 10
Training loss: 2.858384609222412
Validation loss: 2.0776496548806467

Epoch: 6| Step: 11
Training loss: 1.6178877353668213
Validation loss: 2.0801003338188253

Epoch: 6| Step: 12
Training loss: 2.019993543624878
Validation loss: 2.0726123945687407

Epoch: 6| Step: 13
Training loss: 1.352004885673523
Validation loss: 2.082608089652113

Epoch: 381| Step: 0
Training loss: 2.4965782165527344
Validation loss: 2.100890487752935

Epoch: 6| Step: 1
Training loss: 1.890941858291626
Validation loss: 2.0926321321918118

Epoch: 6| Step: 2
Training loss: 1.8216278553009033
Validation loss: 2.1105770193120486

Epoch: 6| Step: 3
Training loss: 2.086864709854126
Validation loss: 2.1092827755917787

Epoch: 6| Step: 4
Training loss: 1.5932111740112305
Validation loss: 2.106766164943736

Epoch: 6| Step: 5
Training loss: 1.8930903673171997
Validation loss: 2.1117897918147426

Epoch: 6| Step: 6
Training loss: 3.300161600112915
Validation loss: 2.1190156065007693

Epoch: 6| Step: 7
Training loss: 1.8668978214263916
Validation loss: 2.122367503822491

Epoch: 6| Step: 8
Training loss: 1.7590768337249756
Validation loss: 2.1072259474826116

Epoch: 6| Step: 9
Training loss: 2.1531646251678467
Validation loss: 2.1278892922145065

Epoch: 6| Step: 10
Training loss: 2.688446044921875
Validation loss: 2.122705977450135

Epoch: 6| Step: 11
Training loss: 1.6191835403442383
Validation loss: 2.1244046098442486

Epoch: 6| Step: 12
Training loss: 2.8811941146850586
Validation loss: 2.1309409679905063

Epoch: 6| Step: 13
Training loss: 1.6706767082214355
Validation loss: 2.126099576232254

Epoch: 382| Step: 0
Training loss: 2.0674686431884766
Validation loss: 2.110051998528101

Epoch: 6| Step: 1
Training loss: 1.7382104396820068
Validation loss: 2.1079174036620767

Epoch: 6| Step: 2
Training loss: 1.4778265953063965
Validation loss: 2.0909117421796246

Epoch: 6| Step: 3
Training loss: 2.4246320724487305
Validation loss: 2.0933489568771853

Epoch: 6| Step: 4
Training loss: 2.591977596282959
Validation loss: 2.0894864912955993

Epoch: 6| Step: 5
Training loss: 2.2449913024902344
Validation loss: 2.0914849235165502

Epoch: 6| Step: 6
Training loss: 2.9392669200897217
Validation loss: 2.0927259281117427

Epoch: 6| Step: 7
Training loss: 2.1730129718780518
Validation loss: 2.093256829887308

Epoch: 6| Step: 8
Training loss: 2.1809897422790527
Validation loss: 2.1124983602954495

Epoch: 6| Step: 9
Training loss: 2.185203790664673
Validation loss: 2.1077261381251837

Epoch: 6| Step: 10
Training loss: 2.312936305999756
Validation loss: 2.1075972280194684

Epoch: 6| Step: 11
Training loss: 1.9982414245605469
Validation loss: 2.100206328976539

Epoch: 6| Step: 12
Training loss: 0.9301585555076599
Validation loss: 2.1002123266138057

Epoch: 6| Step: 13
Training loss: 3.098524332046509
Validation loss: 2.0958664776176534

Epoch: 383| Step: 0
Training loss: 2.0053181648254395
Validation loss: 2.0862915285172

Epoch: 6| Step: 1
Training loss: 1.8547546863555908
Validation loss: 2.092412164134364

Epoch: 6| Step: 2
Training loss: 2.533254623413086
Validation loss: 2.1033632934734388

Epoch: 6| Step: 3
Training loss: 3.0745859146118164
Validation loss: 2.081659973308604

Epoch: 6| Step: 4
Training loss: 2.0116772651672363
Validation loss: 2.08433138555096

Epoch: 6| Step: 5
Training loss: 2.1319355964660645
Validation loss: 2.087092209887761

Epoch: 6| Step: 6
Training loss: 2.2807703018188477
Validation loss: 2.0843040353508404

Epoch: 6| Step: 7
Training loss: 2.189610481262207
Validation loss: 2.0922927138625935

Epoch: 6| Step: 8
Training loss: 1.9962928295135498
Validation loss: 2.105868762539279

Epoch: 6| Step: 9
Training loss: 1.6188558340072632
Validation loss: 2.1389990750179497

Epoch: 6| Step: 10
Training loss: 2.192267894744873
Validation loss: 2.1357462124157975

Epoch: 6| Step: 11
Training loss: 1.9130284786224365
Validation loss: 2.1463525090166318

Epoch: 6| Step: 12
Training loss: 2.0331790447235107
Validation loss: 2.149686005807692

Epoch: 6| Step: 13
Training loss: 2.1195836067199707
Validation loss: 2.131327900835263

Epoch: 384| Step: 0
Training loss: 1.8923975229263306
Validation loss: 2.101075680025162

Epoch: 6| Step: 1
Training loss: 1.9535467624664307
Validation loss: 2.0875316614745767

Epoch: 6| Step: 2
Training loss: 2.6410131454467773
Validation loss: 2.080525787927771

Epoch: 6| Step: 3
Training loss: 2.0444679260253906
Validation loss: 2.0873948066465315

Epoch: 6| Step: 4
Training loss: 1.677666187286377
Validation loss: 2.095362660705402

Epoch: 6| Step: 5
Training loss: 2.0113284587860107
Validation loss: 2.1127152955660256

Epoch: 6| Step: 6
Training loss: 2.3135528564453125
Validation loss: 2.102733858170048

Epoch: 6| Step: 7
Training loss: 2.342609405517578
Validation loss: 2.1071785393581597

Epoch: 6| Step: 8
Training loss: 1.8844058513641357
Validation loss: 2.107490998442455

Epoch: 6| Step: 9
Training loss: 1.9985218048095703
Validation loss: 2.1165236683302027

Epoch: 6| Step: 10
Training loss: 2.284501791000366
Validation loss: 2.1619212640229093

Epoch: 6| Step: 11
Training loss: 2.634213924407959
Validation loss: 2.167536207424697

Epoch: 6| Step: 12
Training loss: 2.6787707805633545
Validation loss: 2.1686338301627868

Epoch: 6| Step: 13
Training loss: 1.772287368774414
Validation loss: 2.1886009862346034

Epoch: 385| Step: 0
Training loss: 2.4653255939483643
Validation loss: 2.1950056322159304

Epoch: 6| Step: 1
Training loss: 2.5061964988708496
Validation loss: 2.202499007665983

Epoch: 6| Step: 2
Training loss: 2.023280143737793
Validation loss: 2.170126945741715

Epoch: 6| Step: 3
Training loss: 2.4729502201080322
Validation loss: 2.1618171302221154

Epoch: 6| Step: 4
Training loss: 2.040592908859253
Validation loss: 2.1411813817998415

Epoch: 6| Step: 5
Training loss: 2.415235996246338
Validation loss: 2.1073069700630764

Epoch: 6| Step: 6
Training loss: 1.9841361045837402
Validation loss: 2.0910312180878012

Epoch: 6| Step: 7
Training loss: 2.178499221801758
Validation loss: 2.080098073969605

Epoch: 6| Step: 8
Training loss: 2.4341378211975098
Validation loss: 2.059398397322624

Epoch: 6| Step: 9
Training loss: 2.043287754058838
Validation loss: 2.062335793690015

Epoch: 6| Step: 10
Training loss: 1.446578860282898
Validation loss: 2.0614724941151117

Epoch: 6| Step: 11
Training loss: 2.171603202819824
Validation loss: 2.0504330242833784

Epoch: 6| Step: 12
Training loss: 2.0379245281219482
Validation loss: 2.0626788113706853

Epoch: 6| Step: 13
Training loss: 1.7688723802566528
Validation loss: 2.068850555727559

Epoch: 386| Step: 0
Training loss: 2.0115697383880615
Validation loss: 2.0868598517551216

Epoch: 6| Step: 1
Training loss: 2.181906223297119
Validation loss: 2.0913596101986465

Epoch: 6| Step: 2
Training loss: 1.9188134670257568
Validation loss: 2.112299511509557

Epoch: 6| Step: 3
Training loss: 2.752558946609497
Validation loss: 2.1078533100825485

Epoch: 6| Step: 4
Training loss: 1.3499717712402344
Validation loss: 2.09619410832723

Epoch: 6| Step: 5
Training loss: 2.57710862159729
Validation loss: 2.0824543019776702

Epoch: 6| Step: 6
Training loss: 2.150817632675171
Validation loss: 2.0862865960726173

Epoch: 6| Step: 7
Training loss: 2.1316616535186768
Validation loss: 2.0849884274185344

Epoch: 6| Step: 8
Training loss: 2.073504686355591
Validation loss: 2.070307686764707

Epoch: 6| Step: 9
Training loss: 2.200857162475586
Validation loss: 2.0672431556127404

Epoch: 6| Step: 10
Training loss: 2.1142985820770264
Validation loss: 2.079155163098407

Epoch: 6| Step: 11
Training loss: 1.7957266569137573
Validation loss: 2.07725602580655

Epoch: 6| Step: 12
Training loss: 2.497671127319336
Validation loss: 2.080883390160017

Epoch: 6| Step: 13
Training loss: 2.0770621299743652
Validation loss: 2.0694649322058565

Epoch: 387| Step: 0
Training loss: 1.44660484790802
Validation loss: 2.0858430170243785

Epoch: 6| Step: 1
Training loss: 2.0266711711883545
Validation loss: 2.0839550008055983

Epoch: 6| Step: 2
Training loss: 1.7651292085647583
Validation loss: 2.1059444335199173

Epoch: 6| Step: 3
Training loss: 2.6319580078125
Validation loss: 2.114252177617883

Epoch: 6| Step: 4
Training loss: 1.8333258628845215
Validation loss: 2.1295514029841267

Epoch: 6| Step: 5
Training loss: 2.2928667068481445
Validation loss: 2.159990040204858

Epoch: 6| Step: 6
Training loss: 2.034759998321533
Validation loss: 2.159379525851178

Epoch: 6| Step: 7
Training loss: 1.9962174892425537
Validation loss: 2.167491369349982

Epoch: 6| Step: 8
Training loss: 2.5979788303375244
Validation loss: 2.1436318864104567

Epoch: 6| Step: 9
Training loss: 2.341932535171509
Validation loss: 2.1433196529265373

Epoch: 6| Step: 10
Training loss: 2.3405065536499023
Validation loss: 2.121266599624388

Epoch: 6| Step: 11
Training loss: 1.810791015625
Validation loss: 2.0873068404454056

Epoch: 6| Step: 12
Training loss: 1.9974716901779175
Validation loss: 2.085827104506954

Epoch: 6| Step: 13
Training loss: 3.2301113605499268
Validation loss: 2.0814065420499412

Epoch: 388| Step: 0
Training loss: 1.99173903465271
Validation loss: 2.0732045865827993

Epoch: 6| Step: 1
Training loss: 2.370401382446289
Validation loss: 2.0781134930990075

Epoch: 6| Step: 2
Training loss: 1.729229211807251
Validation loss: 2.0746946847566994

Epoch: 6| Step: 3
Training loss: 2.168071746826172
Validation loss: 2.08332037156628

Epoch: 6| Step: 4
Training loss: 2.0222740173339844
Validation loss: 2.098017656674949

Epoch: 6| Step: 5
Training loss: 2.693477153778076
Validation loss: 2.0778494086316837

Epoch: 6| Step: 6
Training loss: 1.8982036113739014
Validation loss: 2.0884288228968138

Epoch: 6| Step: 7
Training loss: 2.1607604026794434
Validation loss: 2.088487732794977

Epoch: 6| Step: 8
Training loss: 1.8857142925262451
Validation loss: 2.0836756639583136

Epoch: 6| Step: 9
Training loss: 2.420501708984375
Validation loss: 2.095777891015494

Epoch: 6| Step: 10
Training loss: 2.134719133377075
Validation loss: 2.075468606846307

Epoch: 6| Step: 11
Training loss: 1.735318660736084
Validation loss: 2.0853562201223066

Epoch: 6| Step: 12
Training loss: 2.108536720275879
Validation loss: 2.0795633536513134

Epoch: 6| Step: 13
Training loss: 2.539982557296753
Validation loss: 2.0995624757582143

Epoch: 389| Step: 0
Training loss: 2.7292962074279785
Validation loss: 2.095384531123664

Epoch: 6| Step: 1
Training loss: 1.992964267730713
Validation loss: 2.091081807690282

Epoch: 6| Step: 2
Training loss: 1.6946816444396973
Validation loss: 2.0949004311715402

Epoch: 6| Step: 3
Training loss: 1.799475908279419
Validation loss: 2.0767171793086554

Epoch: 6| Step: 4
Training loss: 2.196939468383789
Validation loss: 2.086513711560157

Epoch: 6| Step: 5
Training loss: 2.7079925537109375
Validation loss: 2.072497157640355

Epoch: 6| Step: 6
Training loss: 2.0353903770446777
Validation loss: 2.0879818931702645

Epoch: 6| Step: 7
Training loss: 2.013580799102783
Validation loss: 2.0710019860216367

Epoch: 6| Step: 8
Training loss: 1.9703174829483032
Validation loss: 2.072110117122691

Epoch: 6| Step: 9
Training loss: 2.3451406955718994
Validation loss: 2.1025801063865743

Epoch: 6| Step: 10
Training loss: 1.8651357889175415
Validation loss: 2.0847465991973877

Epoch: 6| Step: 11
Training loss: 1.985160231590271
Validation loss: 2.1165486304990706

Epoch: 6| Step: 12
Training loss: 2.5386672019958496
Validation loss: 2.1216468734125935

Epoch: 6| Step: 13
Training loss: 1.8434691429138184
Validation loss: 2.124017741090508

Epoch: 390| Step: 0
Training loss: 1.948505163192749
Validation loss: 2.1107721380008164

Epoch: 6| Step: 1
Training loss: 1.790886640548706
Validation loss: 2.1134305179760022

Epoch: 6| Step: 2
Training loss: 1.8760861158370972
Validation loss: 2.1052927458158104

Epoch: 6| Step: 3
Training loss: 2.1292238235473633
Validation loss: 2.1113719530003046

Epoch: 6| Step: 4
Training loss: 2.5247364044189453
Validation loss: 2.106163022338703

Epoch: 6| Step: 5
Training loss: 1.8000138998031616
Validation loss: 2.1090214329381145

Epoch: 6| Step: 6
Training loss: 2.2870540618896484
Validation loss: 2.1088220483513287

Epoch: 6| Step: 7
Training loss: 2.9425241947174072
Validation loss: 2.093932085139777

Epoch: 6| Step: 8
Training loss: 2.3131556510925293
Validation loss: 2.1096080195519233

Epoch: 6| Step: 9
Training loss: 1.732332468032837
Validation loss: 2.0927567405085408

Epoch: 6| Step: 10
Training loss: 2.455796718597412
Validation loss: 2.1085770001975437

Epoch: 6| Step: 11
Training loss: 2.0728375911712646
Validation loss: 2.123213839787309

Epoch: 6| Step: 12
Training loss: 1.747546911239624
Validation loss: 2.1345315825554634

Epoch: 6| Step: 13
Training loss: 2.034855842590332
Validation loss: 2.1470385418143323

Epoch: 391| Step: 0
Training loss: 2.401327133178711
Validation loss: 2.1300577476460445

Epoch: 6| Step: 1
Training loss: 2.5657758712768555
Validation loss: 2.1323391981022333

Epoch: 6| Step: 2
Training loss: 2.0014140605926514
Validation loss: 2.118039587492584

Epoch: 6| Step: 3
Training loss: 2.306621789932251
Validation loss: 2.1162995676840506

Epoch: 6| Step: 4
Training loss: 2.066958427429199
Validation loss: 2.108945869630383

Epoch: 6| Step: 5
Training loss: 2.110043525695801
Validation loss: 2.108896291384133

Epoch: 6| Step: 6
Training loss: 1.7546972036361694
Validation loss: 2.114263191018053

Epoch: 6| Step: 7
Training loss: 3.0984888076782227
Validation loss: 2.113879744724561

Epoch: 6| Step: 8
Training loss: 1.9350355863571167
Validation loss: 2.1116989120360343

Epoch: 6| Step: 9
Training loss: 1.9957001209259033
Validation loss: 2.0965305066877797

Epoch: 6| Step: 10
Training loss: 2.188910484313965
Validation loss: 2.1031577330763622

Epoch: 6| Step: 11
Training loss: 1.8220120668411255
Validation loss: 2.0888255257760324

Epoch: 6| Step: 12
Training loss: 1.3527849912643433
Validation loss: 2.072706781407838

Epoch: 6| Step: 13
Training loss: 1.8639131784439087
Validation loss: 2.0799701316382295

Epoch: 392| Step: 0
Training loss: 3.0239644050598145
Validation loss: 2.083955180260443

Epoch: 6| Step: 1
Training loss: 1.8484352827072144
Validation loss: 2.0824252815656763

Epoch: 6| Step: 2
Training loss: 2.0349247455596924
Validation loss: 2.0889137265502766

Epoch: 6| Step: 3
Training loss: 1.8246725797653198
Validation loss: 2.083546312906409

Epoch: 6| Step: 4
Training loss: 1.3033592700958252
Validation loss: 2.0856754920815908

Epoch: 6| Step: 5
Training loss: 2.465768814086914
Validation loss: 2.0709350403919013

Epoch: 6| Step: 6
Training loss: 1.901464819908142
Validation loss: 2.0748518487458587

Epoch: 6| Step: 7
Training loss: 2.0644304752349854
Validation loss: 2.080210179410955

Epoch: 6| Step: 8
Training loss: 2.551082134246826
Validation loss: 2.07530657193994

Epoch: 6| Step: 9
Training loss: 2.0262398719787598
Validation loss: 2.077419311769547

Epoch: 6| Step: 10
Training loss: 2.0078792572021484
Validation loss: 2.071952034068364

Epoch: 6| Step: 11
Training loss: 2.385115385055542
Validation loss: 2.081506900889899

Epoch: 6| Step: 12
Training loss: 2.3627912998199463
Validation loss: 2.0839419954566547

Epoch: 6| Step: 13
Training loss: 1.533957600593567
Validation loss: 2.0929580580803657

Epoch: 393| Step: 0
Training loss: 2.049531936645508
Validation loss: 2.0981225198315037

Epoch: 6| Step: 1
Training loss: 1.7917277812957764
Validation loss: 2.106012753261033

Epoch: 6| Step: 2
Training loss: 1.7196383476257324
Validation loss: 2.1110650788071337

Epoch: 6| Step: 3
Training loss: 2.3516805171966553
Validation loss: 2.1097007682246547

Epoch: 6| Step: 4
Training loss: 2.552830696105957
Validation loss: 2.100211110166324

Epoch: 6| Step: 5
Training loss: 1.2436943054199219
Validation loss: 2.104548731157857

Epoch: 6| Step: 6
Training loss: 1.770389437675476
Validation loss: 2.081944381037066

Epoch: 6| Step: 7
Training loss: 1.9567922353744507
Validation loss: 2.084608800949589

Epoch: 6| Step: 8
Training loss: 2.769251823425293
Validation loss: 2.08848330795124

Epoch: 6| Step: 9
Training loss: 2.1363332271575928
Validation loss: 2.0911812090104624

Epoch: 6| Step: 10
Training loss: 2.6629319190979004
Validation loss: 2.10244914280471

Epoch: 6| Step: 11
Training loss: 2.131512403488159
Validation loss: 2.112150920334683

Epoch: 6| Step: 12
Training loss: 2.077877998352051
Validation loss: 2.118861739353467

Epoch: 6| Step: 13
Training loss: 2.443889617919922
Validation loss: 2.124357069692304

Epoch: 394| Step: 0
Training loss: 2.20088529586792
Validation loss: 2.1272314210091867

Epoch: 6| Step: 1
Training loss: 1.6829602718353271
Validation loss: 2.1292279394724036

Epoch: 6| Step: 2
Training loss: 2.534044027328491
Validation loss: 2.136299043573359

Epoch: 6| Step: 3
Training loss: 2.3893890380859375
Validation loss: 2.117360245796942

Epoch: 6| Step: 4
Training loss: 2.0174801349639893
Validation loss: 2.1077359030323644

Epoch: 6| Step: 5
Training loss: 2.038801670074463
Validation loss: 2.1117542072009017

Epoch: 6| Step: 6
Training loss: 2.4496982097625732
Validation loss: 2.0780209110629175

Epoch: 6| Step: 7
Training loss: 2.2327260971069336
Validation loss: 2.0835976613465177

Epoch: 6| Step: 8
Training loss: 2.2537283897399902
Validation loss: 2.072418782018846

Epoch: 6| Step: 9
Training loss: 1.8168103694915771
Validation loss: 2.0756331131022465

Epoch: 6| Step: 10
Training loss: 2.2474558353424072
Validation loss: 2.076143640343861

Epoch: 6| Step: 11
Training loss: 1.3441455364227295
Validation loss: 2.0810063244194112

Epoch: 6| Step: 12
Training loss: 2.1564154624938965
Validation loss: 2.0803217246968257

Epoch: 6| Step: 13
Training loss: 2.2922885417938232
Validation loss: 2.086485675586167

Epoch: 395| Step: 0
Training loss: 1.792288064956665
Validation loss: 2.088171584631807

Epoch: 6| Step: 1
Training loss: 1.6444257497787476
Validation loss: 2.0914926093111754

Epoch: 6| Step: 2
Training loss: 2.214449882507324
Validation loss: 2.096087021212424

Epoch: 6| Step: 3
Training loss: 2.0252089500427246
Validation loss: 2.1071142073600524

Epoch: 6| Step: 4
Training loss: 1.7598506212234497
Validation loss: 2.105662288204316

Epoch: 6| Step: 5
Training loss: 2.1900546550750732
Validation loss: 2.093736470386546

Epoch: 6| Step: 6
Training loss: 2.0604405403137207
Validation loss: 2.097160526501235

Epoch: 6| Step: 7
Training loss: 2.3744349479675293
Validation loss: 2.09631803471555

Epoch: 6| Step: 8
Training loss: 2.2021641731262207
Validation loss: 2.0714936076953845

Epoch: 6| Step: 9
Training loss: 1.94600510597229
Validation loss: 2.075590136230633

Epoch: 6| Step: 10
Training loss: 2.3126277923583984
Validation loss: 2.0605411811541487

Epoch: 6| Step: 11
Training loss: 2.4885334968566895
Validation loss: 2.0643411182588145

Epoch: 6| Step: 12
Training loss: 2.2046189308166504
Validation loss: 2.0666230622158257

Epoch: 6| Step: 13
Training loss: 2.3442270755767822
Validation loss: 2.069016864222865

Epoch: 396| Step: 0
Training loss: 1.5598526000976562
Validation loss: 2.091950588328864

Epoch: 6| Step: 1
Training loss: 1.8560072183609009
Validation loss: 2.0869561728610786

Epoch: 6| Step: 2
Training loss: 1.1573082208633423
Validation loss: 2.0890284789505826

Epoch: 6| Step: 3
Training loss: 2.398052215576172
Validation loss: 2.099591109060472

Epoch: 6| Step: 4
Training loss: 1.974076271057129
Validation loss: 2.1063829647597445

Epoch: 6| Step: 5
Training loss: 2.399986505508423
Validation loss: 2.1200095043387464

Epoch: 6| Step: 6
Training loss: 2.1534440517425537
Validation loss: 2.104223088551593

Epoch: 6| Step: 7
Training loss: 1.9115967750549316
Validation loss: 2.1125976013880905

Epoch: 6| Step: 8
Training loss: 2.776951789855957
Validation loss: 2.1186755626432356

Epoch: 6| Step: 9
Training loss: 2.2142205238342285
Validation loss: 2.1069791022167412

Epoch: 6| Step: 10
Training loss: 2.949497699737549
Validation loss: 2.107479526150611

Epoch: 6| Step: 11
Training loss: 1.9783687591552734
Validation loss: 2.1198596800527265

Epoch: 6| Step: 12
Training loss: 1.7349051237106323
Validation loss: 2.0992546504543674

Epoch: 6| Step: 13
Training loss: 2.325110912322998
Validation loss: 2.0928447682370424

Epoch: 397| Step: 0
Training loss: 1.5643551349639893
Validation loss: 2.094585123882499

Epoch: 6| Step: 1
Training loss: 2.0814037322998047
Validation loss: 2.0995523493777037

Epoch: 6| Step: 2
Training loss: 2.0789475440979004
Validation loss: 2.096926563529558

Epoch: 6| Step: 3
Training loss: 2.0170609951019287
Validation loss: 2.1129021234409784

Epoch: 6| Step: 4
Training loss: 2.632658004760742
Validation loss: 2.1271371687612226

Epoch: 6| Step: 5
Training loss: 2.7172982692718506
Validation loss: 2.1149698854774557

Epoch: 6| Step: 6
Training loss: 1.5180013179779053
Validation loss: 2.103625529555864

Epoch: 6| Step: 7
Training loss: 2.2325515747070312
Validation loss: 2.1060633146634666

Epoch: 6| Step: 8
Training loss: 1.7572894096374512
Validation loss: 2.1224427377024004

Epoch: 6| Step: 9
Training loss: 1.7709437608718872
Validation loss: 2.1449820328784246

Epoch: 6| Step: 10
Training loss: 2.3023500442504883
Validation loss: 2.1230879881048716

Epoch: 6| Step: 11
Training loss: 1.9804617166519165
Validation loss: 2.1307601992801954

Epoch: 6| Step: 12
Training loss: 2.6284873485565186
Validation loss: 2.0945135393450336

Epoch: 6| Step: 13
Training loss: 2.4497554302215576
Validation loss: 2.0876874334068707

Epoch: 398| Step: 0
Training loss: 1.4893035888671875
Validation loss: 2.0937496385266705

Epoch: 6| Step: 1
Training loss: 2.307582378387451
Validation loss: 2.0779488022609423

Epoch: 6| Step: 2
Training loss: 1.9419591426849365
Validation loss: 2.084219555700979

Epoch: 6| Step: 3
Training loss: 1.8367762565612793
Validation loss: 2.093769388814126

Epoch: 6| Step: 4
Training loss: 3.0007591247558594
Validation loss: 2.08976924034857

Epoch: 6| Step: 5
Training loss: 1.961237907409668
Validation loss: 2.070990026638072

Epoch: 6| Step: 6
Training loss: 2.3560633659362793
Validation loss: 2.0715579371298514

Epoch: 6| Step: 7
Training loss: 1.7642250061035156
Validation loss: 2.0659147308718775

Epoch: 6| Step: 8
Training loss: 2.056311845779419
Validation loss: 2.077845870807607

Epoch: 6| Step: 9
Training loss: 1.9528913497924805
Validation loss: 2.072275738562307

Epoch: 6| Step: 10
Training loss: 2.981755018234253
Validation loss: 2.082705295214089

Epoch: 6| Step: 11
Training loss: 2.0954647064208984
Validation loss: 2.0887069163783902

Epoch: 6| Step: 12
Training loss: 1.7529642581939697
Validation loss: 2.1052873237158662

Epoch: 6| Step: 13
Training loss: 1.7602810859680176
Validation loss: 2.1138122658575735

Epoch: 399| Step: 0
Training loss: 2.1845502853393555
Validation loss: 2.096768538157145

Epoch: 6| Step: 1
Training loss: 2.3437790870666504
Validation loss: 2.103018383825979

Epoch: 6| Step: 2
Training loss: 1.9518332481384277
Validation loss: 2.105829122245953

Epoch: 6| Step: 3
Training loss: 1.884777307510376
Validation loss: 2.1108086852617163

Epoch: 6| Step: 4
Training loss: 2.6422219276428223
Validation loss: 2.081247506603118

Epoch: 6| Step: 5
Training loss: 2.456295967102051
Validation loss: 2.084454922265904

Epoch: 6| Step: 6
Training loss: 2.048375368118286
Validation loss: 2.082271582336836

Epoch: 6| Step: 7
Training loss: 1.519296407699585
Validation loss: 2.0713178342388523

Epoch: 6| Step: 8
Training loss: 1.7486363649368286
Validation loss: 2.097698452652142

Epoch: 6| Step: 9
Training loss: 1.8869240283966064
Validation loss: 2.0774284383302093

Epoch: 6| Step: 10
Training loss: 2.028015613555908
Validation loss: 2.0855644133783158

Epoch: 6| Step: 11
Training loss: 2.3143391609191895
Validation loss: 2.0878552159955426

Epoch: 6| Step: 12
Training loss: 2.3708906173706055
Validation loss: 2.0920076024147773

Epoch: 6| Step: 13
Training loss: 2.0182766914367676
Validation loss: 2.118987444908388

Epoch: 400| Step: 0
Training loss: 2.447211742401123
Validation loss: 2.1196896299239127

Epoch: 6| Step: 1
Training loss: 2.449474334716797
Validation loss: 2.109969669772733

Epoch: 6| Step: 2
Training loss: 2.055152416229248
Validation loss: 2.0996831155592397

Epoch: 6| Step: 3
Training loss: 1.3541977405548096
Validation loss: 2.1001059163001274

Epoch: 6| Step: 4
Training loss: 2.388127088546753
Validation loss: 2.087204356347361

Epoch: 6| Step: 5
Training loss: 2.3460023403167725
Validation loss: 2.0958470324034333

Epoch: 6| Step: 6
Training loss: 1.932822823524475
Validation loss: 2.0782780429368377

Epoch: 6| Step: 7
Training loss: 2.2996726036071777
Validation loss: 2.072956068541414

Epoch: 6| Step: 8
Training loss: 2.3345818519592285
Validation loss: 2.0829333541213826

Epoch: 6| Step: 9
Training loss: 1.639394760131836
Validation loss: 2.079013180989091

Epoch: 6| Step: 10
Training loss: 2.4034388065338135
Validation loss: 2.076373166935418

Epoch: 6| Step: 11
Training loss: 1.6755144596099854
Validation loss: 2.0836711814326625

Epoch: 6| Step: 12
Training loss: 1.8810937404632568
Validation loss: 2.092356966387841

Epoch: 6| Step: 13
Training loss: 1.8226865530014038
Validation loss: 2.084949328053382

Epoch: 401| Step: 0
Training loss: 2.033769130706787
Validation loss: 2.0910913585334696

Epoch: 6| Step: 1
Training loss: 1.785758376121521
Validation loss: 2.1054342126333587

Epoch: 6| Step: 2
Training loss: 1.2546566724777222
Validation loss: 2.1031221830716698

Epoch: 6| Step: 3
Training loss: 2.249101400375366
Validation loss: 2.114528389387233

Epoch: 6| Step: 4
Training loss: 1.6899442672729492
Validation loss: 2.0926431276464976

Epoch: 6| Step: 5
Training loss: 1.8293747901916504
Validation loss: 2.0951730333348757

Epoch: 6| Step: 6
Training loss: 2.367358684539795
Validation loss: 2.0867667300726778

Epoch: 6| Step: 7
Training loss: 2.4688820838928223
Validation loss: 2.0762482779000395

Epoch: 6| Step: 8
Training loss: 2.4511523246765137
Validation loss: 2.0684410679724907

Epoch: 6| Step: 9
Training loss: 2.619992733001709
Validation loss: 2.052664210719447

Epoch: 6| Step: 10
Training loss: 2.0414037704467773
Validation loss: 2.0634547766818794

Epoch: 6| Step: 11
Training loss: 1.7892512083053589
Validation loss: 2.0564058519178823

Epoch: 6| Step: 12
Training loss: 2.5800695419311523
Validation loss: 2.0597164566798876

Epoch: 6| Step: 13
Training loss: 1.9687644243240356
Validation loss: 2.0684866674484743

Epoch: 402| Step: 0
Training loss: 1.5609203577041626
Validation loss: 2.0620779183603104

Epoch: 6| Step: 1
Training loss: 2.1566884517669678
Validation loss: 2.0668910395714546

Epoch: 6| Step: 2
Training loss: 1.84038507938385
Validation loss: 2.0837215274892826

Epoch: 6| Step: 3
Training loss: 2.209482431411743
Validation loss: 2.1041748831349034

Epoch: 6| Step: 4
Training loss: 2.6503660678863525
Validation loss: 2.0945348419168943

Epoch: 6| Step: 5
Training loss: 1.8563249111175537
Validation loss: 2.086429783093032

Epoch: 6| Step: 6
Training loss: 2.6353073120117188
Validation loss: 2.089628388804774

Epoch: 6| Step: 7
Training loss: 1.6520395278930664
Validation loss: 2.0899036725362143

Epoch: 6| Step: 8
Training loss: 1.7553437948226929
Validation loss: 2.1262735961585917

Epoch: 6| Step: 9
Training loss: 2.212956666946411
Validation loss: 2.098456423769715

Epoch: 6| Step: 10
Training loss: 2.7175042629241943
Validation loss: 2.1027182045803277

Epoch: 6| Step: 11
Training loss: 1.7270853519439697
Validation loss: 2.1054507916973484

Epoch: 6| Step: 12
Training loss: 2.286344051361084
Validation loss: 2.0841057069839968

Epoch: 6| Step: 13
Training loss: 2.0172691345214844
Validation loss: 2.1013649509799097

Epoch: 403| Step: 0
Training loss: 2.3521840572357178
Validation loss: 2.09667024817518

Epoch: 6| Step: 1
Training loss: 1.3480212688446045
Validation loss: 2.1055805836954424

Epoch: 6| Step: 2
Training loss: 2.740095615386963
Validation loss: 2.093988803125197

Epoch: 6| Step: 3
Training loss: 2.661355972290039
Validation loss: 2.080171095427646

Epoch: 6| Step: 4
Training loss: 1.9196441173553467
Validation loss: 2.1065709360184206

Epoch: 6| Step: 5
Training loss: 1.9957455396652222
Validation loss: 2.0767092602227324

Epoch: 6| Step: 6
Training loss: 1.6992076635360718
Validation loss: 2.072382219376103

Epoch: 6| Step: 7
Training loss: 2.0573298931121826
Validation loss: 2.056329099080896

Epoch: 6| Step: 8
Training loss: 2.6865670680999756
Validation loss: 2.058441185182141

Epoch: 6| Step: 9
Training loss: 1.7563278675079346
Validation loss: 2.0625054887546006

Epoch: 6| Step: 10
Training loss: 2.03731632232666
Validation loss: 2.0490749343749015

Epoch: 6| Step: 11
Training loss: 1.8795990943908691
Validation loss: 2.068384160277664

Epoch: 6| Step: 12
Training loss: 1.9571311473846436
Validation loss: 2.069462419838034

Epoch: 6| Step: 13
Training loss: 2.2947802543640137
Validation loss: 2.076137404288015

Epoch: 404| Step: 0
Training loss: 2.0104103088378906
Validation loss: 2.0817454066327823

Epoch: 6| Step: 1
Training loss: 1.848773717880249
Validation loss: 2.08612088746922

Epoch: 6| Step: 2
Training loss: 2.723707914352417
Validation loss: 2.084173822915682

Epoch: 6| Step: 3
Training loss: 1.7281382083892822
Validation loss: 2.1057543754577637

Epoch: 6| Step: 4
Training loss: 2.3733749389648438
Validation loss: 2.1076780185904553

Epoch: 6| Step: 5
Training loss: 1.9107247591018677
Validation loss: 2.109683789232726

Epoch: 6| Step: 6
Training loss: 1.7873337268829346
Validation loss: 2.1038259254988803

Epoch: 6| Step: 7
Training loss: 2.3641576766967773
Validation loss: 2.0916342914745374

Epoch: 6| Step: 8
Training loss: 2.315547466278076
Validation loss: 2.0945434313948437

Epoch: 6| Step: 9
Training loss: 1.726772665977478
Validation loss: 2.0857698225205943

Epoch: 6| Step: 10
Training loss: 1.9951975345611572
Validation loss: 2.0860391637330413

Epoch: 6| Step: 11
Training loss: 2.5895655155181885
Validation loss: 2.0846877174992717

Epoch: 6| Step: 12
Training loss: 1.905753254890442
Validation loss: 2.0712286426175024

Epoch: 6| Step: 13
Training loss: 1.8560973405838013
Validation loss: 2.067489698369016

Epoch: 405| Step: 0
Training loss: 1.3820841312408447
Validation loss: 2.0569063899337605

Epoch: 6| Step: 1
Training loss: 1.9585367441177368
Validation loss: 2.062630452135558

Epoch: 6| Step: 2
Training loss: 2.9827189445495605
Validation loss: 2.0569850783194266

Epoch: 6| Step: 3
Training loss: 2.2717957496643066
Validation loss: 2.0684455569072435

Epoch: 6| Step: 4
Training loss: 2.1826155185699463
Validation loss: 2.084680588014664

Epoch: 6| Step: 5
Training loss: 1.1149702072143555
Validation loss: 2.0701055988188712

Epoch: 6| Step: 6
Training loss: 2.0453085899353027
Validation loss: 2.0699347167886715

Epoch: 6| Step: 7
Training loss: 1.8416225910186768
Validation loss: 2.0804991132469586

Epoch: 6| Step: 8
Training loss: 2.246662139892578
Validation loss: 2.065890799286545

Epoch: 6| Step: 9
Training loss: 1.7756414413452148
Validation loss: 2.0649850445408977

Epoch: 6| Step: 10
Training loss: 2.1007437705993652
Validation loss: 2.0808880726496377

Epoch: 6| Step: 11
Training loss: 2.3686227798461914
Validation loss: 2.055771658497472

Epoch: 6| Step: 12
Training loss: 2.9241676330566406
Validation loss: 2.0725753820070656

Epoch: 6| Step: 13
Training loss: 1.8215289115905762
Validation loss: 2.06379166213415

Epoch: 406| Step: 0
Training loss: 1.9504528045654297
Validation loss: 2.0635403304971676

Epoch: 6| Step: 1
Training loss: 2.2328996658325195
Validation loss: 2.09352586859016

Epoch: 6| Step: 2
Training loss: 1.7752118110656738
Validation loss: 2.1001518875040035

Epoch: 6| Step: 3
Training loss: 1.6895750761032104
Validation loss: 2.1187889998958958

Epoch: 6| Step: 4
Training loss: 3.074647903442383
Validation loss: 2.112918984505438

Epoch: 6| Step: 5
Training loss: 1.742557168006897
Validation loss: 2.1080279568190217

Epoch: 6| Step: 6
Training loss: 2.414724349975586
Validation loss: 2.115149264694542

Epoch: 6| Step: 7
Training loss: 2.0807552337646484
Validation loss: 2.1076036473756194

Epoch: 6| Step: 8
Training loss: 1.0650272369384766
Validation loss: 2.1280551482272405

Epoch: 6| Step: 9
Training loss: 2.732917547225952
Validation loss: 2.150234986377019

Epoch: 6| Step: 10
Training loss: 1.696748971939087
Validation loss: 2.1351083273528726

Epoch: 6| Step: 11
Training loss: 1.918816089630127
Validation loss: 2.104903572349138

Epoch: 6| Step: 12
Training loss: 2.48024320602417
Validation loss: 2.098359805281444

Epoch: 6| Step: 13
Training loss: 2.341108798980713
Validation loss: 2.0851330885323147

Epoch: 407| Step: 0
Training loss: 1.813278317451477
Validation loss: 2.0801392088654223

Epoch: 6| Step: 1
Training loss: 2.0115373134613037
Validation loss: 2.0595459322775564

Epoch: 6| Step: 2
Training loss: 2.235450267791748
Validation loss: 2.0503008891177434

Epoch: 6| Step: 3
Training loss: 2.802572727203369
Validation loss: 2.062550398611253

Epoch: 6| Step: 4
Training loss: 2.07250714302063
Validation loss: 2.05456942383961

Epoch: 6| Step: 5
Training loss: 1.4884063005447388
Validation loss: 2.0676777798642396

Epoch: 6| Step: 6
Training loss: 2.5523111820220947
Validation loss: 2.061408563326764

Epoch: 6| Step: 7
Training loss: 1.8770325183868408
Validation loss: 2.088143220511816

Epoch: 6| Step: 8
Training loss: 2.4382236003875732
Validation loss: 2.067149217410754

Epoch: 6| Step: 9
Training loss: 2.3322551250457764
Validation loss: 2.0800242244556384

Epoch: 6| Step: 10
Training loss: 1.550260305404663
Validation loss: 2.083376410186932

Epoch: 6| Step: 11
Training loss: 2.4971251487731934
Validation loss: 2.1013992678734565

Epoch: 6| Step: 12
Training loss: 1.879268765449524
Validation loss: 2.1105246402884044

Epoch: 6| Step: 13
Training loss: 1.4033856391906738
Validation loss: 2.099829319984682

Epoch: 408| Step: 0
Training loss: 1.500884771347046
Validation loss: 2.0927866428129134

Epoch: 6| Step: 1
Training loss: 1.5678030252456665
Validation loss: 2.0895303833869194

Epoch: 6| Step: 2
Training loss: 2.913670063018799
Validation loss: 2.0819223926913355

Epoch: 6| Step: 3
Training loss: 1.3273975849151611
Validation loss: 2.083069521893737

Epoch: 6| Step: 4
Training loss: 2.2319507598876953
Validation loss: 2.0777029324603338

Epoch: 6| Step: 5
Training loss: 2.3465688228607178
Validation loss: 2.07166552030912

Epoch: 6| Step: 6
Training loss: 2.540264129638672
Validation loss: 2.080386269477106

Epoch: 6| Step: 7
Training loss: 2.08359956741333
Validation loss: 2.079782796162431

Epoch: 6| Step: 8
Training loss: 2.0373640060424805
Validation loss: 2.0789743059424945

Epoch: 6| Step: 9
Training loss: 2.369507312774658
Validation loss: 2.0816665285377094

Epoch: 6| Step: 10
Training loss: 1.4507205486297607
Validation loss: 2.0763283006606565

Epoch: 6| Step: 11
Training loss: 1.9627728462219238
Validation loss: 2.0815186039094002

Epoch: 6| Step: 12
Training loss: 2.1298835277557373
Validation loss: 2.1069858484370734

Epoch: 6| Step: 13
Training loss: 2.7446060180664062
Validation loss: 2.1087775794408654

Epoch: 409| Step: 0
Training loss: 1.10099458694458
Validation loss: 2.119615638127891

Epoch: 6| Step: 1
Training loss: 2.1347861289978027
Validation loss: 2.119019248152292

Epoch: 6| Step: 2
Training loss: 2.737421751022339
Validation loss: 2.1414365768432617

Epoch: 6| Step: 3
Training loss: 2.6274242401123047
Validation loss: 2.117399743808213

Epoch: 6| Step: 4
Training loss: 2.2552385330200195
Validation loss: 2.1023158399007653

Epoch: 6| Step: 5
Training loss: 2.000176429748535
Validation loss: 2.1111838586868776

Epoch: 6| Step: 6
Training loss: 2.137845993041992
Validation loss: 2.106627513003606

Epoch: 6| Step: 7
Training loss: 1.7769253253936768
Validation loss: 2.104406649066556

Epoch: 6| Step: 8
Training loss: 1.8566170930862427
Validation loss: 2.1028214603342037

Epoch: 6| Step: 9
Training loss: 2.45094895362854
Validation loss: 2.0999184423877346

Epoch: 6| Step: 10
Training loss: 2.3672823905944824
Validation loss: 2.1020867670736005

Epoch: 6| Step: 11
Training loss: 1.5021553039550781
Validation loss: 2.0684914204382125

Epoch: 6| Step: 12
Training loss: 1.824098825454712
Validation loss: 2.0657721155433246

Epoch: 6| Step: 13
Training loss: 2.2109744548797607
Validation loss: 2.0556616039686304

Epoch: 410| Step: 0
Training loss: 2.3753631114959717
Validation loss: 2.043107371176443

Epoch: 6| Step: 1
Training loss: 1.9489046335220337
Validation loss: 2.0626170494223155

Epoch: 6| Step: 2
Training loss: 1.7589203119277954
Validation loss: 2.059922077322519

Epoch: 6| Step: 3
Training loss: 1.6845338344573975
Validation loss: 2.068976212573308

Epoch: 6| Step: 4
Training loss: 1.6803369522094727
Validation loss: 2.0742537693310807

Epoch: 6| Step: 5
Training loss: 2.0079751014709473
Validation loss: 2.072364462319241

Epoch: 6| Step: 6
Training loss: 2.0029330253601074
Validation loss: 2.0934250277857624

Epoch: 6| Step: 7
Training loss: 2.3385438919067383
Validation loss: 2.0802247524261475

Epoch: 6| Step: 8
Training loss: 1.351663589477539
Validation loss: 2.0922858509966122

Epoch: 6| Step: 9
Training loss: 2.6124329566955566
Validation loss: 2.0937921334338445

Epoch: 6| Step: 10
Training loss: 2.2872507572174072
Validation loss: 2.0832192641432568

Epoch: 6| Step: 11
Training loss: 2.6077072620391846
Validation loss: 2.0675229385334957

Epoch: 6| Step: 12
Training loss: 1.8949670791625977
Validation loss: 2.0750536431548414

Epoch: 6| Step: 13
Training loss: 2.640145778656006
Validation loss: 2.081631370770034

Epoch: 411| Step: 0
Training loss: 1.8965489864349365
Validation loss: 2.0998790135947605

Epoch: 6| Step: 1
Training loss: 2.0542736053466797
Validation loss: 2.1017900141336585

Epoch: 6| Step: 2
Training loss: 2.445206642150879
Validation loss: 2.098941531232608

Epoch: 6| Step: 3
Training loss: 2.0918657779693604
Validation loss: 2.1357403993606567

Epoch: 6| Step: 4
Training loss: 1.8715153932571411
Validation loss: 2.121533909151631

Epoch: 6| Step: 5
Training loss: 1.7187782526016235
Validation loss: 2.110170010597475

Epoch: 6| Step: 6
Training loss: 2.7489280700683594
Validation loss: 2.1335930670461347

Epoch: 6| Step: 7
Training loss: 1.7382771968841553
Validation loss: 2.1527609004769275

Epoch: 6| Step: 8
Training loss: 1.4103362560272217
Validation loss: 2.1485200620466665

Epoch: 6| Step: 9
Training loss: 2.551656723022461
Validation loss: 2.130644054823024

Epoch: 6| Step: 10
Training loss: 2.3629307746887207
Validation loss: 2.1580859102228636

Epoch: 6| Step: 11
Training loss: 1.7486224174499512
Validation loss: 2.1283724538741575

Epoch: 6| Step: 12
Training loss: 2.2947041988372803
Validation loss: 2.121273763718144

Epoch: 6| Step: 13
Training loss: 1.847689151763916
Validation loss: 2.111731941981982

Epoch: 412| Step: 0
Training loss: 2.153200387954712
Validation loss: 2.084915289314844

Epoch: 6| Step: 1
Training loss: 1.705984354019165
Validation loss: 2.0863211770211496

Epoch: 6| Step: 2
Training loss: 2.745306968688965
Validation loss: 2.078440717471543

Epoch: 6| Step: 3
Training loss: 2.4433016777038574
Validation loss: 2.070859711657288

Epoch: 6| Step: 4
Training loss: 1.9431517124176025
Validation loss: 2.0616554060289936

Epoch: 6| Step: 5
Training loss: 1.9247026443481445
Validation loss: 2.062028128613708

Epoch: 6| Step: 6
Training loss: 2.0615456104278564
Validation loss: 2.0621901507018716

Epoch: 6| Step: 7
Training loss: 2.141718864440918
Validation loss: 2.0574831014038413

Epoch: 6| Step: 8
Training loss: 2.046794891357422
Validation loss: 2.0589762631283013

Epoch: 6| Step: 9
Training loss: 2.4040274620056152
Validation loss: 2.0612595888876144

Epoch: 6| Step: 10
Training loss: 1.7172530889511108
Validation loss: 2.074637289970152

Epoch: 6| Step: 11
Training loss: 1.3389581441879272
Validation loss: 2.0796816092665478

Epoch: 6| Step: 12
Training loss: 2.1321732997894287
Validation loss: 2.0815317246221725

Epoch: 6| Step: 13
Training loss: 2.308573007583618
Validation loss: 2.0757581931288525

Epoch: 413| Step: 0
Training loss: 1.9918544292449951
Validation loss: 2.0677137708151214

Epoch: 6| Step: 1
Training loss: 2.788560390472412
Validation loss: 2.0720013162141204

Epoch: 6| Step: 2
Training loss: 1.8392550945281982
Validation loss: 2.0757197128829135

Epoch: 6| Step: 3
Training loss: 1.4321341514587402
Validation loss: 2.0659324892105593

Epoch: 6| Step: 4
Training loss: 2.265934705734253
Validation loss: 2.0563612766163324

Epoch: 6| Step: 5
Training loss: 2.1334071159362793
Validation loss: 2.0723295416883243

Epoch: 6| Step: 6
Training loss: 1.823047399520874
Validation loss: 2.073677014279109

Epoch: 6| Step: 7
Training loss: 2.3221802711486816
Validation loss: 2.087918230282363

Epoch: 6| Step: 8
Training loss: 2.034243583679199
Validation loss: 2.0769232434611165

Epoch: 6| Step: 9
Training loss: 1.9113035202026367
Validation loss: 2.0739015994533414

Epoch: 6| Step: 10
Training loss: 1.7281169891357422
Validation loss: 2.0657395598708943

Epoch: 6| Step: 11
Training loss: 1.870241641998291
Validation loss: 2.0528567337220713

Epoch: 6| Step: 12
Training loss: 2.3757472038269043
Validation loss: 2.056751251220703

Epoch: 6| Step: 13
Training loss: 2.3680078983306885
Validation loss: 2.0517435137943556

Epoch: 414| Step: 0
Training loss: 1.8488428592681885
Validation loss: 2.0725177923838296

Epoch: 6| Step: 1
Training loss: 2.0870866775512695
Validation loss: 2.0798089324787097

Epoch: 6| Step: 2
Training loss: 1.8059297800064087
Validation loss: 2.078194724616184

Epoch: 6| Step: 3
Training loss: 2.0468807220458984
Validation loss: 2.076248412491173

Epoch: 6| Step: 4
Training loss: 2.5134057998657227
Validation loss: 2.0770829672454507

Epoch: 6| Step: 5
Training loss: 2.2782301902770996
Validation loss: 2.0960343755701536

Epoch: 6| Step: 6
Training loss: 1.7021148204803467
Validation loss: 2.130392905204527

Epoch: 6| Step: 7
Training loss: 2.669381856918335
Validation loss: 2.1121606339690504

Epoch: 6| Step: 8
Training loss: 1.673641562461853
Validation loss: 2.0986578490144465

Epoch: 6| Step: 9
Training loss: 2.2753093242645264
Validation loss: 2.1167284109259166

Epoch: 6| Step: 10
Training loss: 1.9364030361175537
Validation loss: 2.114049724353257

Epoch: 6| Step: 11
Training loss: 1.9476473331451416
Validation loss: 2.1137388008897022

Epoch: 6| Step: 12
Training loss: 1.8609099388122559
Validation loss: 2.0986064480197046

Epoch: 6| Step: 13
Training loss: 2.092512845993042
Validation loss: 2.1079229590713338

Epoch: 415| Step: 0
Training loss: 1.960551142692566
Validation loss: 2.097335610338437

Epoch: 6| Step: 1
Training loss: 1.9490046501159668
Validation loss: 2.095448152993315

Epoch: 6| Step: 2
Training loss: 2.163208484649658
Validation loss: 2.106558140888009

Epoch: 6| Step: 3
Training loss: 3.0522964000701904
Validation loss: 2.1032083931789605

Epoch: 6| Step: 4
Training loss: 2.720858335494995
Validation loss: 2.095525287812756

Epoch: 6| Step: 5
Training loss: 1.4193198680877686
Validation loss: 2.1142540260027816

Epoch: 6| Step: 6
Training loss: 2.5315656661987305
Validation loss: 2.134425646515303

Epoch: 6| Step: 7
Training loss: 1.4605910778045654
Validation loss: 2.111317383345737

Epoch: 6| Step: 8
Training loss: 2.233031749725342
Validation loss: 2.105705125357515

Epoch: 6| Step: 9
Training loss: 2.348836898803711
Validation loss: 2.076973766408941

Epoch: 6| Step: 10
Training loss: 1.9853718280792236
Validation loss: 2.0731657679362963

Epoch: 6| Step: 11
Training loss: 1.248782753944397
Validation loss: 2.0577246501881588

Epoch: 6| Step: 12
Training loss: 1.8023557662963867
Validation loss: 2.0600906213124595

Epoch: 6| Step: 13
Training loss: 1.6767433881759644
Validation loss: 2.048713969927962

Epoch: 416| Step: 0
Training loss: 2.0270795822143555
Validation loss: 2.0530871063150387

Epoch: 6| Step: 1
Training loss: 1.8689677715301514
Validation loss: 2.045668284098307

Epoch: 6| Step: 2
Training loss: 1.7420680522918701
Validation loss: 2.028628033976401

Epoch: 6| Step: 3
Training loss: 1.458923578262329
Validation loss: 2.0430857853222917

Epoch: 6| Step: 4
Training loss: 1.88503098487854
Validation loss: 2.067185944126498

Epoch: 6| Step: 5
Training loss: 2.219945192337036
Validation loss: 2.0778328757132254

Epoch: 6| Step: 6
Training loss: 2.7325034141540527
Validation loss: 2.0809664162256385

Epoch: 6| Step: 7
Training loss: 1.996346116065979
Validation loss: 2.079785006020659

Epoch: 6| Step: 8
Training loss: 2.1188454627990723
Validation loss: 2.071636794715799

Epoch: 6| Step: 9
Training loss: 1.9959408044815063
Validation loss: 2.0851884400972756

Epoch: 6| Step: 10
Training loss: 2.8373186588287354
Validation loss: 2.0701671723396546

Epoch: 6| Step: 11
Training loss: 2.045635461807251
Validation loss: 2.082305221147435

Epoch: 6| Step: 12
Training loss: 1.5654700994491577
Validation loss: 2.072548770135449

Epoch: 6| Step: 13
Training loss: 2.412808418273926
Validation loss: 2.0712645079499934

Epoch: 417| Step: 0
Training loss: 2.9263648986816406
Validation loss: 2.06721931119119

Epoch: 6| Step: 1
Training loss: 1.5265271663665771
Validation loss: 2.0629765654122956

Epoch: 6| Step: 2
Training loss: 2.0193867683410645
Validation loss: 2.0899858192730973

Epoch: 6| Step: 3
Training loss: 1.7144324779510498
Validation loss: 2.0897372717498452

Epoch: 6| Step: 4
Training loss: 2.4685606956481934
Validation loss: 2.0856370002992692

Epoch: 6| Step: 5
Training loss: 2.105956792831421
Validation loss: 2.1087377097017024

Epoch: 6| Step: 6
Training loss: 2.1236276626586914
Validation loss: 2.081365693000055

Epoch: 6| Step: 7
Training loss: 2.092958927154541
Validation loss: 2.088405970604189

Epoch: 6| Step: 8
Training loss: 2.4991607666015625
Validation loss: 2.080340898165139

Epoch: 6| Step: 9
Training loss: 2.5393426418304443
Validation loss: 2.0797779842089583

Epoch: 6| Step: 10
Training loss: 0.8343958854675293
Validation loss: 2.071970180798602

Epoch: 6| Step: 11
Training loss: 1.9352655410766602
Validation loss: 2.0930332201783375

Epoch: 6| Step: 12
Training loss: 1.6191647052764893
Validation loss: 2.0854171732420563

Epoch: 6| Step: 13
Training loss: 2.332963228225708
Validation loss: 2.0838858824904247

Epoch: 418| Step: 0
Training loss: 2.2943825721740723
Validation loss: 2.079799343180913

Epoch: 6| Step: 1
Training loss: 1.3138628005981445
Validation loss: 2.086049995114726

Epoch: 6| Step: 2
Training loss: 2.487079620361328
Validation loss: 2.0974842976498347

Epoch: 6| Step: 3
Training loss: 2.023270845413208
Validation loss: 2.0888225327255907

Epoch: 6| Step: 4
Training loss: 2.53645658493042
Validation loss: 2.085107223961943

Epoch: 6| Step: 5
Training loss: 1.780102014541626
Validation loss: 2.077531127519505

Epoch: 6| Step: 6
Training loss: 2.1574079990386963
Validation loss: 2.06594628800628

Epoch: 6| Step: 7
Training loss: 1.5576437711715698
Validation loss: 2.0772548362772953

Epoch: 6| Step: 8
Training loss: 2.0236806869506836
Validation loss: 2.078436097791118

Epoch: 6| Step: 9
Training loss: 1.9466540813446045
Validation loss: 2.0551079216823784

Epoch: 6| Step: 10
Training loss: 2.264188289642334
Validation loss: 2.0573167057447534

Epoch: 6| Step: 11
Training loss: 2.4937210083007812
Validation loss: 2.060496573807091

Epoch: 6| Step: 12
Training loss: 1.9686198234558105
Validation loss: 2.0539015416176087

Epoch: 6| Step: 13
Training loss: 1.6898094415664673
Validation loss: 2.0498974964182866

Epoch: 419| Step: 0
Training loss: 2.0408895015716553
Validation loss: 2.066592453628458

Epoch: 6| Step: 1
Training loss: 2.2012147903442383
Validation loss: 2.079084869354002

Epoch: 6| Step: 2
Training loss: 2.0679233074188232
Validation loss: 2.0685492843709965

Epoch: 6| Step: 3
Training loss: 1.7968165874481201
Validation loss: 2.0706443222620154

Epoch: 6| Step: 4
Training loss: 2.795304536819458
Validation loss: 2.0740192654312297

Epoch: 6| Step: 5
Training loss: 2.1166462898254395
Validation loss: 2.075910199073053

Epoch: 6| Step: 6
Training loss: 2.2064638137817383
Validation loss: 2.0975232816511586

Epoch: 6| Step: 7
Training loss: 2.2926979064941406
Validation loss: 2.091557712965114

Epoch: 6| Step: 8
Training loss: 1.872025728225708
Validation loss: 2.0940879955086658

Epoch: 6| Step: 9
Training loss: 1.7554194927215576
Validation loss: 2.0953678905322985

Epoch: 6| Step: 10
Training loss: 1.9012129306793213
Validation loss: 2.091322365627494

Epoch: 6| Step: 11
Training loss: 1.5409880876541138
Validation loss: 2.0957311955831384

Epoch: 6| Step: 12
Training loss: 1.4121325016021729
Validation loss: 2.0858810665786907

Epoch: 6| Step: 13
Training loss: 3.0474445819854736
Validation loss: 2.0710869296904533

Epoch: 420| Step: 0
Training loss: 2.5086052417755127
Validation loss: 2.0803827008893414

Epoch: 6| Step: 1
Training loss: 1.3645440340042114
Validation loss: 2.0611148342009513

Epoch: 6| Step: 2
Training loss: 2.0479230880737305
Validation loss: 2.0922248440404094

Epoch: 6| Step: 3
Training loss: 1.8487634658813477
Validation loss: 2.0735797138624292

Epoch: 6| Step: 4
Training loss: 2.2601120471954346
Validation loss: 2.0706991482806463

Epoch: 6| Step: 5
Training loss: 1.7113258838653564
Validation loss: 2.083486286542749

Epoch: 6| Step: 6
Training loss: 2.271872043609619
Validation loss: 2.08534881120087

Epoch: 6| Step: 7
Training loss: 2.515810489654541
Validation loss: 2.081715714546942

Epoch: 6| Step: 8
Training loss: 1.1197125911712646
Validation loss: 2.0700067371450444

Epoch: 6| Step: 9
Training loss: 1.7013423442840576
Validation loss: 2.0782565647555935

Epoch: 6| Step: 10
Training loss: 1.7967500686645508
Validation loss: 2.080917368653

Epoch: 6| Step: 11
Training loss: 2.417543411254883
Validation loss: 2.0957101057934504

Epoch: 6| Step: 12
Training loss: 2.352912664413452
Validation loss: 2.1022999337924424

Epoch: 6| Step: 13
Training loss: 3.1878769397735596
Validation loss: 2.1051492152675504

Epoch: 421| Step: 0
Training loss: 1.985396146774292
Validation loss: 2.0902099224828903

Epoch: 6| Step: 1
Training loss: 1.5004191398620605
Validation loss: 2.0633950874369633

Epoch: 6| Step: 2
Training loss: 1.7571154832839966
Validation loss: 2.0717878777493715

Epoch: 6| Step: 3
Training loss: 2.2195465564727783
Validation loss: 2.0517984051858225

Epoch: 6| Step: 4
Training loss: 2.850031852722168
Validation loss: 2.0602356541541313

Epoch: 6| Step: 5
Training loss: 2.002814769744873
Validation loss: 2.043121219963156

Epoch: 6| Step: 6
Training loss: 2.381074905395508
Validation loss: 2.046275049127558

Epoch: 6| Step: 7
Training loss: 2.2298507690429688
Validation loss: 2.0298649918648506

Epoch: 6| Step: 8
Training loss: 2.155872344970703
Validation loss: 2.036031294894475

Epoch: 6| Step: 9
Training loss: 2.169624090194702
Validation loss: 2.0358515567676996

Epoch: 6| Step: 10
Training loss: 2.33545184135437
Validation loss: 2.027318703230991

Epoch: 6| Step: 11
Training loss: 1.6063501834869385
Validation loss: 2.0231347250682052

Epoch: 6| Step: 12
Training loss: 1.4325180053710938
Validation loss: 2.049458558841418

Epoch: 6| Step: 13
Training loss: 1.8828794956207275
Validation loss: 2.0467414727774997

Epoch: 422| Step: 0
Training loss: 2.0878758430480957
Validation loss: 2.08842755645834

Epoch: 6| Step: 1
Training loss: 2.3181514739990234
Validation loss: 2.073482277572796

Epoch: 6| Step: 2
Training loss: 2.299078941345215
Validation loss: 2.0611280959139586

Epoch: 6| Step: 3
Training loss: 2.115403890609741
Validation loss: 2.073642670467336

Epoch: 6| Step: 4
Training loss: 1.2573559284210205
Validation loss: 2.0735202630360923

Epoch: 6| Step: 5
Training loss: 1.5844919681549072
Validation loss: 2.060972813637026

Epoch: 6| Step: 6
Training loss: 1.5754468441009521
Validation loss: 2.0661232843193957

Epoch: 6| Step: 7
Training loss: 1.8809564113616943
Validation loss: 2.058606852767288

Epoch: 6| Step: 8
Training loss: 2.3542325496673584
Validation loss: 2.064734976778748

Epoch: 6| Step: 9
Training loss: 2.6436080932617188
Validation loss: 2.0616138391597296

Epoch: 6| Step: 10
Training loss: 2.075758695602417
Validation loss: 2.0728843442855345

Epoch: 6| Step: 11
Training loss: 1.8549063205718994
Validation loss: 2.0807787244037916

Epoch: 6| Step: 12
Training loss: 2.5611977577209473
Validation loss: 2.05869343075701

Epoch: 6| Step: 13
Training loss: 1.8565737009048462
Validation loss: 2.0826344797688146

Epoch: 423| Step: 0
Training loss: 2.1027164459228516
Validation loss: 2.0858945000556206

Epoch: 6| Step: 1
Training loss: 2.020312786102295
Validation loss: 2.0851698306299027

Epoch: 6| Step: 2
Training loss: 1.7592544555664062
Validation loss: 2.075667009558729

Epoch: 6| Step: 3
Training loss: 2.52366304397583
Validation loss: 2.077445314776513

Epoch: 6| Step: 4
Training loss: 1.5971513986587524
Validation loss: 2.0795664607837634

Epoch: 6| Step: 5
Training loss: 2.0549705028533936
Validation loss: 2.098205015223513

Epoch: 6| Step: 6
Training loss: 2.425152063369751
Validation loss: 2.094929643856582

Epoch: 6| Step: 7
Training loss: 1.8746931552886963
Validation loss: 2.093357450218611

Epoch: 6| Step: 8
Training loss: 1.9454755783081055
Validation loss: 2.0835661477940057

Epoch: 6| Step: 9
Training loss: 2.57615327835083
Validation loss: 2.086852149296832

Epoch: 6| Step: 10
Training loss: 1.6045944690704346
Validation loss: 2.066809711917754

Epoch: 6| Step: 11
Training loss: 2.1124250888824463
Validation loss: 2.076263807153189

Epoch: 6| Step: 12
Training loss: 2.0807912349700928
Validation loss: 2.076520806999617

Epoch: 6| Step: 13
Training loss: 1.7465623617172241
Validation loss: 2.077222154986474

Epoch: 424| Step: 0
Training loss: 1.9054102897644043
Validation loss: 2.0950439053197063

Epoch: 6| Step: 1
Training loss: 2.0045289993286133
Validation loss: 2.0933411275186846

Epoch: 6| Step: 2
Training loss: 1.7661912441253662
Validation loss: 2.0904060768824753

Epoch: 6| Step: 3
Training loss: 1.9810107946395874
Validation loss: 2.0864778052094164

Epoch: 6| Step: 4
Training loss: 2.2634639739990234
Validation loss: 2.0712413967296643

Epoch: 6| Step: 5
Training loss: 1.241856336593628
Validation loss: 2.0769427668663765

Epoch: 6| Step: 6
Training loss: 1.8732876777648926
Validation loss: 2.0652415419137604

Epoch: 6| Step: 7
Training loss: 2.955127000808716
Validation loss: 2.058862292638389

Epoch: 6| Step: 8
Training loss: 1.707850694656372
Validation loss: 2.0592175529849146

Epoch: 6| Step: 9
Training loss: 2.0107526779174805
Validation loss: 2.0446095620432208

Epoch: 6| Step: 10
Training loss: 1.761413335800171
Validation loss: 2.0641110071571926

Epoch: 6| Step: 11
Training loss: 2.0528926849365234
Validation loss: 2.066799607328189

Epoch: 6| Step: 12
Training loss: 2.491647243499756
Validation loss: 2.0646523480774253

Epoch: 6| Step: 13
Training loss: 2.773989677429199
Validation loss: 2.059836692707513

Epoch: 425| Step: 0
Training loss: 2.133183002471924
Validation loss: 2.069223327021445

Epoch: 6| Step: 1
Training loss: 1.9617855548858643
Validation loss: 2.0426663070596676

Epoch: 6| Step: 2
Training loss: 2.527723789215088
Validation loss: 2.0537198307693645

Epoch: 6| Step: 3
Training loss: 1.6866130828857422
Validation loss: 2.0426554269688104

Epoch: 6| Step: 4
Training loss: 2.2891743183135986
Validation loss: 2.0591674466286936

Epoch: 6| Step: 5
Training loss: 2.49613094329834
Validation loss: 2.0659617813684608

Epoch: 6| Step: 6
Training loss: 1.7935328483581543
Validation loss: 2.0706096285132953

Epoch: 6| Step: 7
Training loss: 1.8844085931777954
Validation loss: 2.0650939274859685

Epoch: 6| Step: 8
Training loss: 1.773047924041748
Validation loss: 2.0536393119442846

Epoch: 6| Step: 9
Training loss: 2.1526238918304443
Validation loss: 2.0646235417294245

Epoch: 6| Step: 10
Training loss: 1.7182952165603638
Validation loss: 2.0396644146211687

Epoch: 6| Step: 11
Training loss: 2.31308913230896
Validation loss: 2.0481733686180523

Epoch: 6| Step: 12
Training loss: 1.7318614721298218
Validation loss: 2.0587225947328793

Epoch: 6| Step: 13
Training loss: 1.7351683378219604
Validation loss: 2.0507964677708124

Epoch: 426| Step: 0
Training loss: 2.0213382244110107
Validation loss: 2.0564291195202897

Epoch: 6| Step: 1
Training loss: 2.2110769748687744
Validation loss: 2.0593218649587324

Epoch: 6| Step: 2
Training loss: 1.5134811401367188
Validation loss: 2.052144945308726

Epoch: 6| Step: 3
Training loss: 2.6080801486968994
Validation loss: 2.0613295032132055

Epoch: 6| Step: 4
Training loss: 2.6305971145629883
Validation loss: 2.0740068907378824

Epoch: 6| Step: 5
Training loss: 1.6932084560394287
Validation loss: 2.074571554378797

Epoch: 6| Step: 6
Training loss: 2.8088202476501465
Validation loss: 2.0531669919208815

Epoch: 6| Step: 7
Training loss: 1.3505537509918213
Validation loss: 2.068650637903521

Epoch: 6| Step: 8
Training loss: 1.5272982120513916
Validation loss: 2.0890512440794256

Epoch: 6| Step: 9
Training loss: 1.9470778703689575
Validation loss: 2.067828675752045

Epoch: 6| Step: 10
Training loss: 2.306253671646118
Validation loss: 2.082664256454796

Epoch: 6| Step: 11
Training loss: 2.1534130573272705
Validation loss: 2.0704774472021286

Epoch: 6| Step: 12
Training loss: 1.2364025115966797
Validation loss: 2.082464122003125

Epoch: 6| Step: 13
Training loss: 2.473742961883545
Validation loss: 2.093064013347831

Epoch: 427| Step: 0
Training loss: 1.5483957529067993
Validation loss: 2.0811050553475656

Epoch: 6| Step: 1
Training loss: 2.4622597694396973
Validation loss: 2.0982109910698346

Epoch: 6| Step: 2
Training loss: 1.5185108184814453
Validation loss: 2.0923107324108

Epoch: 6| Step: 3
Training loss: 1.9992709159851074
Validation loss: 2.0971747726522465

Epoch: 6| Step: 4
Training loss: 2.4987125396728516
Validation loss: 2.097707517685429

Epoch: 6| Step: 5
Training loss: 1.7856333255767822
Validation loss: 2.092947503571869

Epoch: 6| Step: 6
Training loss: 2.3196027278900146
Validation loss: 2.0979478205403974

Epoch: 6| Step: 7
Training loss: 1.5836577415466309
Validation loss: 2.1023580489620084

Epoch: 6| Step: 8
Training loss: 2.646054983139038
Validation loss: 2.1116973200151996

Epoch: 6| Step: 9
Training loss: 1.8650380373001099
Validation loss: 2.124775594280612

Epoch: 6| Step: 10
Training loss: 2.4106574058532715
Validation loss: 2.130783962947066

Epoch: 6| Step: 11
Training loss: 2.19398832321167
Validation loss: 2.124215610565678

Epoch: 6| Step: 12
Training loss: 1.927939772605896
Validation loss: 2.118406084276015

Epoch: 6| Step: 13
Training loss: 1.5008254051208496
Validation loss: 2.1131183280739734

Epoch: 428| Step: 0
Training loss: 1.8939037322998047
Validation loss: 2.0803132544281664

Epoch: 6| Step: 1
Training loss: 2.3195056915283203
Validation loss: 2.054471723494991

Epoch: 6| Step: 2
Training loss: 2.661309242248535
Validation loss: 2.0595874760740545

Epoch: 6| Step: 3
Training loss: 2.838137149810791
Validation loss: 2.0600711671254968

Epoch: 6| Step: 4
Training loss: 2.5215671062469482
Validation loss: 2.0326327585404917

Epoch: 6| Step: 5
Training loss: 1.5974355936050415
Validation loss: 2.0338926379398634

Epoch: 6| Step: 6
Training loss: 1.8227653503417969
Validation loss: 2.0333216754339074

Epoch: 6| Step: 7
Training loss: 1.2479045391082764
Validation loss: 2.021320619890767

Epoch: 6| Step: 8
Training loss: 2.4382174015045166
Validation loss: 2.0258956134960218

Epoch: 6| Step: 9
Training loss: 1.6525118350982666
Validation loss: 2.0381768762424426

Epoch: 6| Step: 10
Training loss: 2.3015213012695312
Validation loss: 2.030033347427204

Epoch: 6| Step: 11
Training loss: 1.2030487060546875
Validation loss: 2.043250263378184

Epoch: 6| Step: 12
Training loss: 2.322160482406616
Validation loss: 2.071874959494478

Epoch: 6| Step: 13
Training loss: 1.415234923362732
Validation loss: 2.0787373870931645

Epoch: 429| Step: 0
Training loss: 2.5669496059417725
Validation loss: 2.0901184338395313

Epoch: 6| Step: 1
Training loss: 1.894728422164917
Validation loss: 2.094257834137127

Epoch: 6| Step: 2
Training loss: 1.8444623947143555
Validation loss: 2.10949315691507

Epoch: 6| Step: 3
Training loss: 2.711094856262207
Validation loss: 2.0946153697147163

Epoch: 6| Step: 4
Training loss: 2.650146007537842
Validation loss: 2.089843121908044

Epoch: 6| Step: 5
Training loss: 1.488415002822876
Validation loss: 2.10274366922276

Epoch: 6| Step: 6
Training loss: 2.183061122894287
Validation loss: 2.1111052741286573

Epoch: 6| Step: 7
Training loss: 1.2175624370574951
Validation loss: 2.1147019350400535

Epoch: 6| Step: 8
Training loss: 2.114205837249756
Validation loss: 2.094753001325874

Epoch: 6| Step: 9
Training loss: 2.0130832195281982
Validation loss: 2.0979703869870914

Epoch: 6| Step: 10
Training loss: 1.8179078102111816
Validation loss: 2.0939918705212173

Epoch: 6| Step: 11
Training loss: 1.83768630027771
Validation loss: 2.0874083195963213

Epoch: 6| Step: 12
Training loss: 2.413459062576294
Validation loss: 2.0933848273369575

Epoch: 6| Step: 13
Training loss: 1.223103404045105
Validation loss: 2.10942962092738

Epoch: 430| Step: 0
Training loss: 1.8009669780731201
Validation loss: 2.1033400502256168

Epoch: 6| Step: 1
Training loss: 2.423943519592285
Validation loss: 2.0781088054821057

Epoch: 6| Step: 2
Training loss: 1.1773332357406616
Validation loss: 2.0593410794452955

Epoch: 6| Step: 3
Training loss: 1.8958185911178589
Validation loss: 2.0626352397344445

Epoch: 6| Step: 4
Training loss: 2.190913677215576
Validation loss: 2.0669392180699173

Epoch: 6| Step: 5
Training loss: 1.984266757965088
Validation loss: 2.0822915248973395

Epoch: 6| Step: 6
Training loss: 1.697769045829773
Validation loss: 2.0744132418786325

Epoch: 6| Step: 7
Training loss: 2.0460364818573
Validation loss: 2.067595984346123

Epoch: 6| Step: 8
Training loss: 2.076101541519165
Validation loss: 2.0748269865589757

Epoch: 6| Step: 9
Training loss: 2.1281204223632812
Validation loss: 2.065170931559737

Epoch: 6| Step: 10
Training loss: 2.5046467781066895
Validation loss: 2.086352567518911

Epoch: 6| Step: 11
Training loss: 2.6448824405670166
Validation loss: 2.0965463935687976

Epoch: 6| Step: 12
Training loss: 1.4377102851867676
Validation loss: 2.097487131754557

Epoch: 6| Step: 13
Training loss: 2.8872785568237305
Validation loss: 2.1034719559454147

Epoch: 431| Step: 0
Training loss: 2.3476462364196777
Validation loss: 2.0911487994655484

Epoch: 6| Step: 1
Training loss: 2.1806201934814453
Validation loss: 2.0734339760195826

Epoch: 6| Step: 2
Training loss: 2.004852294921875
Validation loss: 2.0719081240315593

Epoch: 6| Step: 3
Training loss: 2.4823765754699707
Validation loss: 2.0553322440834454

Epoch: 6| Step: 4
Training loss: 2.0276641845703125
Validation loss: 2.0601155527176394

Epoch: 6| Step: 5
Training loss: 1.5632548332214355
Validation loss: 2.0533993000625284

Epoch: 6| Step: 6
Training loss: 2.1479997634887695
Validation loss: 2.0442588278042373

Epoch: 6| Step: 7
Training loss: 2.246061325073242
Validation loss: 2.033450527857709

Epoch: 6| Step: 8
Training loss: 2.2705836296081543
Validation loss: 2.0481797905378443

Epoch: 6| Step: 9
Training loss: 1.9024841785430908
Validation loss: 2.046932976732972

Epoch: 6| Step: 10
Training loss: 1.5906586647033691
Validation loss: 2.0526232398966306

Epoch: 6| Step: 11
Training loss: 2.038210391998291
Validation loss: 2.062987240411902

Epoch: 6| Step: 12
Training loss: 2.042539119720459
Validation loss: 2.084630876459101

Epoch: 6| Step: 13
Training loss: 0.9326445460319519
Validation loss: 2.088769611491952

Epoch: 432| Step: 0
Training loss: 2.040609121322632
Validation loss: 2.0837875104719594

Epoch: 6| Step: 1
Training loss: 1.549994707107544
Validation loss: 2.0956707257096485

Epoch: 6| Step: 2
Training loss: 1.4782514572143555
Validation loss: 2.097650084444272

Epoch: 6| Step: 3
Training loss: 1.5460095405578613
Validation loss: 2.097024053655645

Epoch: 6| Step: 4
Training loss: 1.6828935146331787
Validation loss: 2.096629855453327

Epoch: 6| Step: 5
Training loss: 2.694795608520508
Validation loss: 2.0943438904259795

Epoch: 6| Step: 6
Training loss: 1.119201421737671
Validation loss: 2.105290623121364

Epoch: 6| Step: 7
Training loss: 1.7501766681671143
Validation loss: 2.0973677609556463

Epoch: 6| Step: 8
Training loss: 2.3806333541870117
Validation loss: 2.1210276208898073

Epoch: 6| Step: 9
Training loss: 1.4840898513793945
Validation loss: 2.110509216144521

Epoch: 6| Step: 10
Training loss: 2.603092670440674
Validation loss: 2.1073379888329455

Epoch: 6| Step: 11
Training loss: 2.1811041831970215
Validation loss: 2.0963981766854562

Epoch: 6| Step: 12
Training loss: 3.606018304824829
Validation loss: 2.09447048043692

Epoch: 6| Step: 13
Training loss: 2.091360330581665
Validation loss: 2.0773763272070114

Epoch: 433| Step: 0
Training loss: 1.9441077709197998
Validation loss: 2.088400061412524

Epoch: 6| Step: 1
Training loss: 1.575979471206665
Validation loss: 2.0703442737620366

Epoch: 6| Step: 2
Training loss: 1.8491309881210327
Validation loss: 2.0633265138954244

Epoch: 6| Step: 3
Training loss: 2.3822717666625977
Validation loss: 2.06207888613465

Epoch: 6| Step: 4
Training loss: 2.739511489868164
Validation loss: 2.0618868386873634

Epoch: 6| Step: 5
Training loss: 1.8774306774139404
Validation loss: 2.0485753654151835

Epoch: 6| Step: 6
Training loss: 2.4280853271484375
Validation loss: 2.0477506191499772

Epoch: 6| Step: 7
Training loss: 1.364572525024414
Validation loss: 2.0286817678841214

Epoch: 6| Step: 8
Training loss: 2.1198086738586426
Validation loss: 2.0347472595912155

Epoch: 6| Step: 9
Training loss: 1.7730664014816284
Validation loss: 2.0296366599298294

Epoch: 6| Step: 10
Training loss: 1.3402206897735596
Validation loss: 2.0317376249579975

Epoch: 6| Step: 11
Training loss: 2.2003986835479736
Validation loss: 2.0218004283084663

Epoch: 6| Step: 12
Training loss: 1.7775040864944458
Validation loss: 2.0250879359501663

Epoch: 6| Step: 13
Training loss: 3.148453712463379
Validation loss: 2.02760814082238

Epoch: 434| Step: 0
Training loss: 2.2538537979125977
Validation loss: 2.050635422429731

Epoch: 6| Step: 1
Training loss: 2.4151530265808105
Validation loss: 2.048832357570689

Epoch: 6| Step: 2
Training loss: 2.229722023010254
Validation loss: 2.0601340596393873

Epoch: 6| Step: 3
Training loss: 2.0229434967041016
Validation loss: 2.0736973465129895

Epoch: 6| Step: 4
Training loss: 1.850714921951294
Validation loss: 2.086417249453965

Epoch: 6| Step: 5
Training loss: 2.1212518215179443
Validation loss: 2.100093618515999

Epoch: 6| Step: 6
Training loss: 1.5383882522583008
Validation loss: 2.09395016906082

Epoch: 6| Step: 7
Training loss: 2.037342071533203
Validation loss: 2.094148776864493

Epoch: 6| Step: 8
Training loss: 2.131460428237915
Validation loss: 2.087842736192929

Epoch: 6| Step: 9
Training loss: 1.017993688583374
Validation loss: 2.089804505789152

Epoch: 6| Step: 10
Training loss: 2.1557321548461914
Validation loss: 2.0973224665528987

Epoch: 6| Step: 11
Training loss: 1.8116917610168457
Validation loss: 2.0732683212526384

Epoch: 6| Step: 12
Training loss: 2.7654733657836914
Validation loss: 2.089707889864522

Epoch: 6| Step: 13
Training loss: 1.4471455812454224
Validation loss: 2.0727724977718887

Epoch: 435| Step: 0
Training loss: 1.625549077987671
Validation loss: 2.067423342376627

Epoch: 6| Step: 1
Training loss: 1.8610786199569702
Validation loss: 2.0688228607177734

Epoch: 6| Step: 2
Training loss: 2.3854641914367676
Validation loss: 2.0543132225672402

Epoch: 6| Step: 3
Training loss: 2.0337917804718018
Validation loss: 2.0540683936047297

Epoch: 6| Step: 4
Training loss: 1.7989622354507446
Validation loss: 2.060082698381075

Epoch: 6| Step: 5
Training loss: 2.059018135070801
Validation loss: 2.052628986297115

Epoch: 6| Step: 6
Training loss: 2.195526361465454
Validation loss: 2.0608205295378164

Epoch: 6| Step: 7
Training loss: 1.8586151599884033
Validation loss: 2.053653040239888

Epoch: 6| Step: 8
Training loss: 1.2245278358459473
Validation loss: 2.082155994189683

Epoch: 6| Step: 9
Training loss: 1.939892292022705
Validation loss: 2.0858066056364324

Epoch: 6| Step: 10
Training loss: 1.9817100763320923
Validation loss: 2.085902822914944

Epoch: 6| Step: 11
Training loss: 2.6362454891204834
Validation loss: 2.080575580238014

Epoch: 6| Step: 12
Training loss: 1.962044596672058
Validation loss: 2.0719114657371276

Epoch: 6| Step: 13
Training loss: 2.670797348022461
Validation loss: 2.0651055535962506

Epoch: 436| Step: 0
Training loss: 2.6003496646881104
Validation loss: 2.0702133742711877

Epoch: 6| Step: 1
Training loss: 2.5387496948242188
Validation loss: 2.075493581833378

Epoch: 6| Step: 2
Training loss: 2.0920495986938477
Validation loss: 2.0693816138852026

Epoch: 6| Step: 3
Training loss: 0.9782861471176147
Validation loss: 2.084773693033444

Epoch: 6| Step: 4
Training loss: 2.4670615196228027
Validation loss: 2.0540767254367953

Epoch: 6| Step: 5
Training loss: 2.087362289428711
Validation loss: 2.0624212372687554

Epoch: 6| Step: 6
Training loss: 2.4607901573181152
Validation loss: 2.0719901951410438

Epoch: 6| Step: 7
Training loss: 2.002117395401001
Validation loss: 2.077773282604833

Epoch: 6| Step: 8
Training loss: 2.017171859741211
Validation loss: 2.070931339776644

Epoch: 6| Step: 9
Training loss: 1.4183974266052246
Validation loss: 2.0667402718656804

Epoch: 6| Step: 10
Training loss: 2.149000883102417
Validation loss: 2.083429523693618

Epoch: 6| Step: 11
Training loss: 1.9078305959701538
Validation loss: 2.093038817887665

Epoch: 6| Step: 12
Training loss: 1.329569697380066
Validation loss: 2.080424157522058

Epoch: 6| Step: 13
Training loss: 1.6466950178146362
Validation loss: 2.0924470296470066

Epoch: 437| Step: 0
Training loss: 2.0335540771484375
Validation loss: 2.0951613508244997

Epoch: 6| Step: 1
Training loss: 2.0598936080932617
Validation loss: 2.074573552736672

Epoch: 6| Step: 2
Training loss: 2.2252421379089355
Validation loss: 2.069559471581572

Epoch: 6| Step: 3
Training loss: 1.99239981174469
Validation loss: 2.0619775761840162

Epoch: 6| Step: 4
Training loss: 1.8433996438980103
Validation loss: 2.0529458394614597

Epoch: 6| Step: 5
Training loss: 1.9396716356277466
Validation loss: 2.053896318199814

Epoch: 6| Step: 6
Training loss: 2.2847208976745605
Validation loss: 2.051237001213976

Epoch: 6| Step: 7
Training loss: 1.6907356977462769
Validation loss: 2.0555271487082205

Epoch: 6| Step: 8
Training loss: 1.8116729259490967
Validation loss: 2.051821293369416

Epoch: 6| Step: 9
Training loss: 1.7711586952209473
Validation loss: 2.0719635307147937

Epoch: 6| Step: 10
Training loss: 2.8198156356811523
Validation loss: 2.0680257607531805

Epoch: 6| Step: 11
Training loss: 1.6852428913116455
Validation loss: 2.078686098898611

Epoch: 6| Step: 12
Training loss: 1.8076186180114746
Validation loss: 2.0989635298329015

Epoch: 6| Step: 13
Training loss: 1.8400895595550537
Validation loss: 2.0906480563584195

Epoch: 438| Step: 0
Training loss: 2.304527759552002
Validation loss: 2.1059814832543813

Epoch: 6| Step: 1
Training loss: 1.7815542221069336
Validation loss: 2.0989928014816774

Epoch: 6| Step: 2
Training loss: 2.2329471111297607
Validation loss: 2.0784779492244927

Epoch: 6| Step: 3
Training loss: 1.9301559925079346
Validation loss: 2.0965043088441253

Epoch: 6| Step: 4
Training loss: 1.5489373207092285
Validation loss: 2.0873279584351407

Epoch: 6| Step: 5
Training loss: 2.2388951778411865
Validation loss: 2.083893883612848

Epoch: 6| Step: 6
Training loss: 1.7565357685089111
Validation loss: 2.0824685212104552

Epoch: 6| Step: 7
Training loss: 2.405141830444336
Validation loss: 2.0790710705582813

Epoch: 6| Step: 8
Training loss: 2.413726568222046
Validation loss: 2.063094772318358

Epoch: 6| Step: 9
Training loss: 1.8245761394500732
Validation loss: 2.0625478375342583

Epoch: 6| Step: 10
Training loss: 2.2235987186431885
Validation loss: 2.0611712548040573

Epoch: 6| Step: 11
Training loss: 1.8187031745910645
Validation loss: 2.060327124852006

Epoch: 6| Step: 12
Training loss: 1.3499016761779785
Validation loss: 2.0505669347701536

Epoch: 6| Step: 13
Training loss: 2.232396125793457
Validation loss: 2.0476628400946177

Epoch: 439| Step: 0
Training loss: 1.6508744955062866
Validation loss: 2.0696065861691713

Epoch: 6| Step: 1
Training loss: 2.6052660942077637
Validation loss: 2.0729554442949194

Epoch: 6| Step: 2
Training loss: 2.064044952392578
Validation loss: 2.0882657010068177

Epoch: 6| Step: 3
Training loss: 1.7038681507110596
Validation loss: 2.108314339832593

Epoch: 6| Step: 4
Training loss: 1.7240887880325317
Validation loss: 2.1287936831033356

Epoch: 6| Step: 5
Training loss: 2.021772861480713
Validation loss: 2.119664151181457

Epoch: 6| Step: 6
Training loss: 2.566485643386841
Validation loss: 2.1233955672992173

Epoch: 6| Step: 7
Training loss: 1.2540075778961182
Validation loss: 2.1285494835146013

Epoch: 6| Step: 8
Training loss: 2.568700075149536
Validation loss: 2.129295023538733

Epoch: 6| Step: 9
Training loss: 2.5546202659606934
Validation loss: 2.1304733394294657

Epoch: 6| Step: 10
Training loss: 1.5958101749420166
Validation loss: 2.1021027872639317

Epoch: 6| Step: 11
Training loss: 1.52797269821167
Validation loss: 2.0967274570977814

Epoch: 6| Step: 12
Training loss: 1.7691560983657837
Validation loss: 2.090595619652861

Epoch: 6| Step: 13
Training loss: 2.5949854850769043
Validation loss: 2.0685657788348455

Epoch: 440| Step: 0
Training loss: 1.9641802310943604
Validation loss: 2.0585391547090266

Epoch: 6| Step: 1
Training loss: 2.2419192790985107
Validation loss: 2.0416154630722536

Epoch: 6| Step: 2
Training loss: 1.69315767288208
Validation loss: 2.028731323057605

Epoch: 6| Step: 3
Training loss: 2.5994465351104736
Validation loss: 2.040216061376756

Epoch: 6| Step: 4
Training loss: 2.0844621658325195
Validation loss: 2.0509272672796763

Epoch: 6| Step: 5
Training loss: 2.366356134414673
Validation loss: 2.0528645130895797

Epoch: 6| Step: 6
Training loss: 1.901464819908142
Validation loss: 2.048454879432596

Epoch: 6| Step: 7
Training loss: 2.0449278354644775
Validation loss: 2.0321307720676547

Epoch: 6| Step: 8
Training loss: 1.6118229627609253
Validation loss: 2.0396419648201234

Epoch: 6| Step: 9
Training loss: 1.7837523221969604
Validation loss: 2.0401585858355284

Epoch: 6| Step: 10
Training loss: 1.6875157356262207
Validation loss: 2.0305450757344565

Epoch: 6| Step: 11
Training loss: 1.7466068267822266
Validation loss: 2.031870444615682

Epoch: 6| Step: 12
Training loss: 2.367363452911377
Validation loss: 2.0406308507406585

Epoch: 6| Step: 13
Training loss: 1.6012916564941406
Validation loss: 2.0274390917952343

Epoch: 441| Step: 0
Training loss: 2.5129826068878174
Validation loss: 2.0226431482581684

Epoch: 6| Step: 1
Training loss: 1.6644127368927002
Validation loss: 2.0452921621261106

Epoch: 6| Step: 2
Training loss: 2.41361665725708
Validation loss: 2.068823996410575

Epoch: 6| Step: 3
Training loss: 2.5464985370635986
Validation loss: 2.0569064309520106

Epoch: 6| Step: 4
Training loss: 2.65346622467041
Validation loss: 2.06317316075807

Epoch: 6| Step: 5
Training loss: 1.164380669593811
Validation loss: 2.082652297071231

Epoch: 6| Step: 6
Training loss: 1.5405209064483643
Validation loss: 2.1013988038545013

Epoch: 6| Step: 7
Training loss: 1.624546766281128
Validation loss: 2.0893280941952943

Epoch: 6| Step: 8
Training loss: 1.8302911520004272
Validation loss: 2.1022590168060793

Epoch: 6| Step: 9
Training loss: 2.0841357707977295
Validation loss: 2.105523281199958

Epoch: 6| Step: 10
Training loss: 2.1375787258148193
Validation loss: 2.1184269920472176

Epoch: 6| Step: 11
Training loss: 1.630934238433838
Validation loss: 2.110089709681849

Epoch: 6| Step: 12
Training loss: 1.9421415328979492
Validation loss: 2.1020789966788342

Epoch: 6| Step: 13
Training loss: 2.0625250339508057
Validation loss: 2.0969452704152753

Epoch: 442| Step: 0
Training loss: 2.9014830589294434
Validation loss: 2.0874665783297632

Epoch: 6| Step: 1
Training loss: 1.975342869758606
Validation loss: 2.080118046011976

Epoch: 6| Step: 2
Training loss: 1.458383560180664
Validation loss: 2.0609629974570325

Epoch: 6| Step: 3
Training loss: 2.204697608947754
Validation loss: 2.0596661490778767

Epoch: 6| Step: 4
Training loss: 2.0445191860198975
Validation loss: 2.048502608012128

Epoch: 6| Step: 5
Training loss: 1.7008554935455322
Validation loss: 2.0438740766176613

Epoch: 6| Step: 6
Training loss: 2.04718017578125
Validation loss: 2.037807792745611

Epoch: 6| Step: 7
Training loss: 1.6431474685668945
Validation loss: 2.0519697794350247

Epoch: 6| Step: 8
Training loss: 1.6894140243530273
Validation loss: 2.037209073702494

Epoch: 6| Step: 9
Training loss: 1.7860534191131592
Validation loss: 2.042556380712858

Epoch: 6| Step: 10
Training loss: 2.5406785011291504
Validation loss: 2.0511321047300934

Epoch: 6| Step: 11
Training loss: 2.1484506130218506
Validation loss: 2.0468334497944003

Epoch: 6| Step: 12
Training loss: 1.26004958152771
Validation loss: 2.05519962310791

Epoch: 6| Step: 13
Training loss: 2.7401649951934814
Validation loss: 2.0663037735928773

Epoch: 443| Step: 0
Training loss: 2.33780574798584
Validation loss: 2.068848548396941

Epoch: 6| Step: 1
Training loss: 1.5395030975341797
Validation loss: 2.058530790831453

Epoch: 6| Step: 2
Training loss: 2.2311434745788574
Validation loss: 2.0647439495209725

Epoch: 6| Step: 3
Training loss: 1.9258205890655518
Validation loss: 2.0649877543090494

Epoch: 6| Step: 4
Training loss: 1.689314365386963
Validation loss: 2.049453003432161

Epoch: 6| Step: 5
Training loss: 1.633162021636963
Validation loss: 2.045652906099955

Epoch: 6| Step: 6
Training loss: 2.5828745365142822
Validation loss: 2.061332966691704

Epoch: 6| Step: 7
Training loss: 1.5814436674118042
Validation loss: 2.056312443107687

Epoch: 6| Step: 8
Training loss: 1.5914897918701172
Validation loss: 2.040413195087064

Epoch: 6| Step: 9
Training loss: 1.8889524936676025
Validation loss: 2.0374138739801224

Epoch: 6| Step: 10
Training loss: 2.4962899684906006
Validation loss: 2.0436803064038678

Epoch: 6| Step: 11
Training loss: 2.1368167400360107
Validation loss: 2.0424694502225487

Epoch: 6| Step: 12
Training loss: 2.0373482704162598
Validation loss: 2.051158933229344

Epoch: 6| Step: 13
Training loss: 1.903533935546875
Validation loss: 2.053991481822024

Epoch: 444| Step: 0
Training loss: 1.8792647123336792
Validation loss: 2.042321667876295

Epoch: 6| Step: 1
Training loss: 1.3650020360946655
Validation loss: 2.0643312572151102

Epoch: 6| Step: 2
Training loss: 2.3787403106689453
Validation loss: 2.0546480301887757

Epoch: 6| Step: 3
Training loss: 2.282414197921753
Validation loss: 2.0658815022437804

Epoch: 6| Step: 4
Training loss: 1.8448002338409424
Validation loss: 2.0723773253861295

Epoch: 6| Step: 5
Training loss: 1.753944993019104
Validation loss: 2.0721326566511586

Epoch: 6| Step: 6
Training loss: 2.2788045406341553
Validation loss: 2.059678716044272

Epoch: 6| Step: 7
Training loss: 1.493579387664795
Validation loss: 2.062101996073159

Epoch: 6| Step: 8
Training loss: 1.408966302871704
Validation loss: 2.0601637901798373

Epoch: 6| Step: 9
Training loss: 2.0416178703308105
Validation loss: 2.053579963663573

Epoch: 6| Step: 10
Training loss: 1.8849151134490967
Validation loss: 2.0452658130276586

Epoch: 6| Step: 11
Training loss: 2.3444571495056152
Validation loss: 2.0348004128343318

Epoch: 6| Step: 12
Training loss: 2.2992053031921387
Validation loss: 2.062128541290119

Epoch: 6| Step: 13
Training loss: 2.510610818862915
Validation loss: 2.0525284992751254

Epoch: 445| Step: 0
Training loss: 1.829703450202942
Validation loss: 2.0595676796410674

Epoch: 6| Step: 1
Training loss: 1.3322731256484985
Validation loss: 2.0626375418837353

Epoch: 6| Step: 2
Training loss: 1.2947036027908325
Validation loss: 2.0487154478667886

Epoch: 6| Step: 3
Training loss: 2.0022687911987305
Validation loss: 2.043914556503296

Epoch: 6| Step: 4
Training loss: 2.079329490661621
Validation loss: 2.0426840730892715

Epoch: 6| Step: 5
Training loss: 2.080751895904541
Validation loss: 2.0524545074791036

Epoch: 6| Step: 6
Training loss: 2.1486892700195312
Validation loss: 2.0637490416085846

Epoch: 6| Step: 7
Training loss: 2.6901347637176514
Validation loss: 2.0469772328612623

Epoch: 6| Step: 8
Training loss: 1.7304811477661133
Validation loss: 2.0563992325977614

Epoch: 6| Step: 9
Training loss: 1.9636101722717285
Validation loss: 2.0535970503284084

Epoch: 6| Step: 10
Training loss: 2.3378584384918213
Validation loss: 2.0565234256047074

Epoch: 6| Step: 11
Training loss: 2.198557138442993
Validation loss: 2.0536575804474535

Epoch: 6| Step: 12
Training loss: 1.874990701675415
Validation loss: 2.058368476488257

Epoch: 6| Step: 13
Training loss: 2.080754280090332
Validation loss: 2.0465729249420987

Epoch: 446| Step: 0
Training loss: 2.2526912689208984
Validation loss: 2.062906893350745

Epoch: 6| Step: 1
Training loss: 1.938049554824829
Validation loss: 2.056028396852555

Epoch: 6| Step: 2
Training loss: 1.8304576873779297
Validation loss: 2.0432249551178305

Epoch: 6| Step: 3
Training loss: 1.5467448234558105
Validation loss: 2.0475540507224297

Epoch: 6| Step: 4
Training loss: 1.551253080368042
Validation loss: 2.0498803405351538

Epoch: 6| Step: 5
Training loss: 1.7314821481704712
Validation loss: 2.0748829226340018

Epoch: 6| Step: 6
Training loss: 2.54263973236084
Validation loss: 2.0616499711108465

Epoch: 6| Step: 7
Training loss: 2.0937557220458984
Validation loss: 2.0591727431102465

Epoch: 6| Step: 8
Training loss: 2.3620309829711914
Validation loss: 2.0480046913187993

Epoch: 6| Step: 9
Training loss: 1.9303984642028809
Validation loss: 2.0367249647776284

Epoch: 6| Step: 10
Training loss: 2.0229272842407227
Validation loss: 2.0366882252436813

Epoch: 6| Step: 11
Training loss: 1.9333070516586304
Validation loss: 2.0201483670101372

Epoch: 6| Step: 12
Training loss: 1.7783302068710327
Validation loss: 2.0432987802772113

Epoch: 6| Step: 13
Training loss: 1.9946637153625488
Validation loss: 2.0312772361181115

Epoch: 447| Step: 0
Training loss: 2.03757905960083
Validation loss: 2.033927866207656

Epoch: 6| Step: 1
Training loss: 2.1757922172546387
Validation loss: 2.046124340385519

Epoch: 6| Step: 2
Training loss: 2.086247444152832
Validation loss: 2.0519350062134447

Epoch: 6| Step: 3
Training loss: 1.6462721824645996
Validation loss: 2.0596288173429427

Epoch: 6| Step: 4
Training loss: 2.5370864868164062
Validation loss: 2.053543557402908

Epoch: 6| Step: 5
Training loss: 2.4508237838745117
Validation loss: 2.058518600720231

Epoch: 6| Step: 6
Training loss: 2.7557730674743652
Validation loss: 2.0724497636159263

Epoch: 6| Step: 7
Training loss: 2.132869243621826
Validation loss: 2.0831280446821645

Epoch: 6| Step: 8
Training loss: 1.5842374563217163
Validation loss: 2.0877678163589968

Epoch: 6| Step: 9
Training loss: 2.128291130065918
Validation loss: 2.082009248836066

Epoch: 6| Step: 10
Training loss: 1.7777724266052246
Validation loss: 2.0625512510217647

Epoch: 6| Step: 11
Training loss: 1.2521705627441406
Validation loss: 2.0440991450381536

Epoch: 6| Step: 12
Training loss: 1.667104959487915
Validation loss: 2.038071584957902

Epoch: 6| Step: 13
Training loss: 1.3345943689346313
Validation loss: 2.020143525574797

Epoch: 448| Step: 0
Training loss: 1.2609220743179321
Validation loss: 2.045542411906745

Epoch: 6| Step: 1
Training loss: 1.7900199890136719
Validation loss: 2.0357967345945296

Epoch: 6| Step: 2
Training loss: 1.9114947319030762
Validation loss: 2.0541055894667104

Epoch: 6| Step: 3
Training loss: 1.8312387466430664
Validation loss: 2.0281514942005114

Epoch: 6| Step: 4
Training loss: 2.10803484916687
Validation loss: 2.052643895149231

Epoch: 6| Step: 5
Training loss: 1.5042710304260254
Validation loss: 2.062490979830424

Epoch: 6| Step: 6
Training loss: 1.9064826965332031
Validation loss: 2.0555983666450746

Epoch: 6| Step: 7
Training loss: 1.8553094863891602
Validation loss: 2.0487863299667195

Epoch: 6| Step: 8
Training loss: 2.00209903717041
Validation loss: 2.0668748014716694

Epoch: 6| Step: 9
Training loss: 2.4030590057373047
Validation loss: 2.056204269009252

Epoch: 6| Step: 10
Training loss: 2.336334466934204
Validation loss: 2.047070541689473

Epoch: 6| Step: 11
Training loss: 2.1620278358459473
Validation loss: 2.048152167309997

Epoch: 6| Step: 12
Training loss: 2.4998536109924316
Validation loss: 2.0483206651544057

Epoch: 6| Step: 13
Training loss: 1.7636709213256836
Validation loss: 2.050193258511123

Epoch: 449| Step: 0
Training loss: 2.0556435585021973
Validation loss: 2.0284650915412494

Epoch: 6| Step: 1
Training loss: 2.2862935066223145
Validation loss: 2.0350164239124586

Epoch: 6| Step: 2
Training loss: 1.8400392532348633
Validation loss: 2.0382511667025986

Epoch: 6| Step: 3
Training loss: 1.7553870677947998
Validation loss: 2.0220616966165523

Epoch: 6| Step: 4
Training loss: 1.940325379371643
Validation loss: 2.0205258092572613

Epoch: 6| Step: 5
Training loss: 2.1118054389953613
Validation loss: 2.025795857111613

Epoch: 6| Step: 6
Training loss: 1.6748321056365967
Validation loss: 2.0243136344417447

Epoch: 6| Step: 7
Training loss: 2.1893386840820312
Validation loss: 2.051359745763963

Epoch: 6| Step: 8
Training loss: 2.63256573677063
Validation loss: 2.048824853794549

Epoch: 6| Step: 9
Training loss: 1.9010908603668213
Validation loss: 2.070575793584188

Epoch: 6| Step: 10
Training loss: 1.579439401626587
Validation loss: 2.047880836712417

Epoch: 6| Step: 11
Training loss: 1.5644679069519043
Validation loss: 2.0626169455948697

Epoch: 6| Step: 12
Training loss: 1.6917041540145874
Validation loss: 2.0514655267038653

Epoch: 6| Step: 13
Training loss: 2.420344352722168
Validation loss: 2.0379175627103416

Epoch: 450| Step: 0
Training loss: 2.3201704025268555
Validation loss: 2.0473876704451857

Epoch: 6| Step: 1
Training loss: 2.0081868171691895
Validation loss: 2.0560152594761183

Epoch: 6| Step: 2
Training loss: 2.4278464317321777
Validation loss: 2.0435385742495136

Epoch: 6| Step: 3
Training loss: 1.913590908050537
Validation loss: 2.053188116319718

Epoch: 6| Step: 4
Training loss: 2.320868968963623
Validation loss: 2.072446859011086

Epoch: 6| Step: 5
Training loss: 1.6471493244171143
Validation loss: 2.0662816288650676

Epoch: 6| Step: 6
Training loss: 1.3210731744766235
Validation loss: 2.0722311363425305

Epoch: 6| Step: 7
Training loss: 1.231484055519104
Validation loss: 2.067493164411155

Epoch: 6| Step: 8
Training loss: 2.5793519020080566
Validation loss: 2.056173852694932

Epoch: 6| Step: 9
Training loss: 1.8211069107055664
Validation loss: 2.0607394710663827

Epoch: 6| Step: 10
Training loss: 2.0536227226257324
Validation loss: 2.046443808463312

Epoch: 6| Step: 11
Training loss: 2.1379432678222656
Validation loss: 2.0538008110497588

Epoch: 6| Step: 12
Training loss: 1.8530139923095703
Validation loss: 2.047042126296669

Epoch: 6| Step: 13
Training loss: 1.396328091621399
Validation loss: 2.063508182443598

Testing loss: 2.1892810185750324
