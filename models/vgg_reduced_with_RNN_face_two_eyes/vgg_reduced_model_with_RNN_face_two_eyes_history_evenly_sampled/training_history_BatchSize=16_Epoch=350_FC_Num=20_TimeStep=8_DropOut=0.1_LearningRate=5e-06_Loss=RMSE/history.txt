Epoch: 1| Step: 0
Training loss: 4.982751085507578
Validation loss: 5.764860000901962

Epoch: 6| Step: 1
Training loss: 6.451991686007399
Validation loss: 5.760100200022527

Epoch: 6| Step: 2
Training loss: 6.158509435273722
Validation loss: 5.755682788543299

Epoch: 6| Step: 3
Training loss: 5.457989029059422
Validation loss: 5.751271974354492

Epoch: 6| Step: 4
Training loss: 5.146482892551969
Validation loss: 5.746196162762829

Epoch: 6| Step: 5
Training loss: 5.783731783608794
Validation loss: 5.741493903008509

Epoch: 6| Step: 6
Training loss: 6.176746001100367
Validation loss: 5.736621746594206

Epoch: 6| Step: 7
Training loss: 5.855412397056215
Validation loss: 5.73185005179276

Epoch: 6| Step: 8
Training loss: 6.056591497503109
Validation loss: 5.726255640796183

Epoch: 6| Step: 9
Training loss: 5.896786166817309
Validation loss: 5.721089507285271

Epoch: 6| Step: 10
Training loss: 5.09941263743445
Validation loss: 5.715630001021814

Epoch: 6| Step: 11
Training loss: 5.291261291996518
Validation loss: 5.709964796006287

Epoch: 6| Step: 12
Training loss: 6.361889691113367
Validation loss: 5.703911708592184

Epoch: 6| Step: 13
Training loss: 5.831920379995213
Validation loss: 5.697942214005397

Epoch: 2| Step: 0
Training loss: 6.613638871015784
Validation loss: 5.691663092660729

Epoch: 6| Step: 1
Training loss: 5.182488652100494
Validation loss: 5.685501116992141

Epoch: 6| Step: 2
Training loss: 5.054538447498083
Validation loss: 5.678308772801225

Epoch: 6| Step: 3
Training loss: 5.654444285103518
Validation loss: 5.67095254906559

Epoch: 6| Step: 4
Training loss: 5.753983817577976
Validation loss: 5.664133145546294

Epoch: 6| Step: 5
Training loss: 6.230962828176178
Validation loss: 5.656781216236722

Epoch: 6| Step: 6
Training loss: 4.618036750366369
Validation loss: 5.647760834214515

Epoch: 6| Step: 7
Training loss: 5.659405413018779
Validation loss: 5.639750973130229

Epoch: 6| Step: 8
Training loss: 6.9978361872589545
Validation loss: 5.631816695946094

Epoch: 6| Step: 9
Training loss: 5.093484134405585
Validation loss: 5.6220659577381085

Epoch: 6| Step: 10
Training loss: 6.299136378116243
Validation loss: 5.612803365045144

Epoch: 6| Step: 11
Training loss: 5.4025202768519875
Validation loss: 5.602720306439197

Epoch: 6| Step: 12
Training loss: 4.730458266658491
Validation loss: 5.592930159713762

Epoch: 6| Step: 13
Training loss: 5.722869223319435
Validation loss: 5.582793161743135

Epoch: 3| Step: 0
Training loss: 4.696789298224274
Validation loss: 5.571948367220777

Epoch: 6| Step: 1
Training loss: 6.3481922850592625
Validation loss: 5.560204013983549

Epoch: 6| Step: 2
Training loss: 5.215907984805429
Validation loss: 5.549028499042636

Epoch: 6| Step: 3
Training loss: 5.782780625081026
Validation loss: 5.537143628938159

Epoch: 6| Step: 4
Training loss: 5.781624116906876
Validation loss: 5.524829619737257

Epoch: 6| Step: 5
Training loss: 6.01682243814767
Validation loss: 5.511047481012299

Epoch: 6| Step: 6
Training loss: 4.191077227445948
Validation loss: 5.4974278152729426

Epoch: 6| Step: 7
Training loss: 5.615636194862241
Validation loss: 5.484447546898252

Epoch: 6| Step: 8
Training loss: 5.304990240118629
Validation loss: 5.469912362746153

Epoch: 6| Step: 9
Training loss: 6.237599392330291
Validation loss: 5.454923362900044

Epoch: 6| Step: 10
Training loss: 5.503777333923153
Validation loss: 5.438160112364133

Epoch: 6| Step: 11
Training loss: 6.325849863485643
Validation loss: 5.421200293623155

Epoch: 6| Step: 12
Training loss: 4.618558367107734
Validation loss: 5.4040135201999835

Epoch: 6| Step: 13
Training loss: 5.046242311106586
Validation loss: 5.387332650249208

Epoch: 4| Step: 0
Training loss: 5.53297905917663
Validation loss: 5.367623890647815

Epoch: 6| Step: 1
Training loss: 5.020549887521854
Validation loss: 5.348550304802997

Epoch: 6| Step: 2
Training loss: 4.552001160928213
Validation loss: 5.327876294169425

Epoch: 6| Step: 3
Training loss: 6.089957127913482
Validation loss: 5.305944217015101

Epoch: 6| Step: 4
Training loss: 5.647318664584568
Validation loss: 5.285636115912572

Epoch: 6| Step: 5
Training loss: 4.480307831406248
Validation loss: 5.26144547012429

Epoch: 6| Step: 6
Training loss: 5.2561001532896166
Validation loss: 5.235665304992286

Epoch: 6| Step: 7
Training loss: 4.845296108460463
Validation loss: 5.212762573456101

Epoch: 6| Step: 8
Training loss: 4.775726319041916
Validation loss: 5.186939247247207

Epoch: 6| Step: 9
Training loss: 5.553779195141689
Validation loss: 5.161165046581533

Epoch: 6| Step: 10
Training loss: 4.934797875498194
Validation loss: 5.133486564521607

Epoch: 6| Step: 11
Training loss: 6.2002752181465075
Validation loss: 5.104642267359266

Epoch: 6| Step: 12
Training loss: 5.372446562588696
Validation loss: 5.074193811853074

Epoch: 6| Step: 13
Training loss: 5.122240765901891
Validation loss: 5.045137379108408

Epoch: 5| Step: 0
Training loss: 3.195045366756141
Validation loss: 5.012217709649759

Epoch: 6| Step: 1
Training loss: 5.83366364043442
Validation loss: 4.981484961076556

Epoch: 6| Step: 2
Training loss: 5.0402278055448155
Validation loss: 4.94966956840431

Epoch: 6| Step: 3
Training loss: 5.535040122612983
Validation loss: 4.917936732854632

Epoch: 6| Step: 4
Training loss: 5.0224346387910055
Validation loss: 4.887674836671136

Epoch: 6| Step: 5
Training loss: 5.190344340931669
Validation loss: 4.85433521248368

Epoch: 6| Step: 6
Training loss: 4.944214709560891
Validation loss: 4.824709746216537

Epoch: 6| Step: 7
Training loss: 5.117902726137825
Validation loss: 4.794814052630538

Epoch: 6| Step: 8
Training loss: 5.104746550751772
Validation loss: 4.765065320047397

Epoch: 6| Step: 9
Training loss: 5.267039304338564
Validation loss: 4.734657502535831

Epoch: 6| Step: 10
Training loss: 3.1840406607327143
Validation loss: 4.704119098829416

Epoch: 6| Step: 11
Training loss: 5.274336945863988
Validation loss: 4.675700654235026

Epoch: 6| Step: 12
Training loss: 4.198386999748618
Validation loss: 4.64401705732272

Epoch: 6| Step: 13
Training loss: 4.503644103521241
Validation loss: 4.6147378826971375

Epoch: 6| Step: 0
Training loss: 5.46406956520311
Validation loss: 4.587152067459573

Epoch: 6| Step: 1
Training loss: 3.147904798248424
Validation loss: 4.556493226127291

Epoch: 6| Step: 2
Training loss: 4.8025947789416685
Validation loss: 4.530432117327643

Epoch: 6| Step: 3
Training loss: 3.7868394130829626
Validation loss: 4.50777224876069

Epoch: 6| Step: 4
Training loss: 4.149527943431676
Validation loss: 4.485759921288115

Epoch: 6| Step: 5
Training loss: 5.2981304830091
Validation loss: 4.465353396248592

Epoch: 6| Step: 6
Training loss: 5.679033958058126
Validation loss: 4.44569470387931

Epoch: 6| Step: 7
Training loss: 3.174383965750161
Validation loss: 4.419995277011382

Epoch: 6| Step: 8
Training loss: 4.443887760478923
Validation loss: 4.40091186184445

Epoch: 6| Step: 9
Training loss: 5.098038816164326
Validation loss: 4.381422089209645

Epoch: 6| Step: 10
Training loss: 4.8400088721580214
Validation loss: 4.361190593653482

Epoch: 6| Step: 11
Training loss: 3.7635948438536313
Validation loss: 4.338731587742684

Epoch: 6| Step: 12
Training loss: 4.075683798492342
Validation loss: 4.318214467093953

Epoch: 6| Step: 13
Training loss: 5.11556734251831
Validation loss: 4.298911110995849

Epoch: 7| Step: 0
Training loss: 3.9044840979138096
Validation loss: 4.277377657686388

Epoch: 6| Step: 1
Training loss: 4.0128855582411065
Validation loss: 4.257811033277437

Epoch: 6| Step: 2
Training loss: 4.617570632039116
Validation loss: 4.235190288040554

Epoch: 6| Step: 3
Training loss: 4.239502902131067
Validation loss: 4.21430625454653

Epoch: 6| Step: 4
Training loss: 5.079953847360091
Validation loss: 4.195140341420403

Epoch: 6| Step: 5
Training loss: 3.663963723223812
Validation loss: 4.172841077788192

Epoch: 6| Step: 6
Training loss: 3.583027109472089
Validation loss: 4.153061023234424

Epoch: 6| Step: 7
Training loss: 4.025324525248783
Validation loss: 4.134200432463921

Epoch: 6| Step: 8
Training loss: 4.931593440368334
Validation loss: 4.1157954299729145

Epoch: 6| Step: 9
Training loss: 4.852075325465306
Validation loss: 4.098055618944623

Epoch: 6| Step: 10
Training loss: 3.9193499822218083
Validation loss: 4.081390133625491

Epoch: 6| Step: 11
Training loss: 3.552280826988697
Validation loss: 4.063979166865999

Epoch: 6| Step: 12
Training loss: 4.71524301527665
Validation loss: 4.045474392666493

Epoch: 6| Step: 13
Training loss: 4.478521161548039
Validation loss: 4.031776411023032

Epoch: 8| Step: 0
Training loss: 4.542856229797436
Validation loss: 4.014599603075414

Epoch: 6| Step: 1
Training loss: 3.3717350178564818
Validation loss: 3.9997767724537687

Epoch: 6| Step: 2
Training loss: 5.311547048031961
Validation loss: 3.9832924639980125

Epoch: 6| Step: 3
Training loss: 3.870562812432496
Validation loss: 3.968809040002828

Epoch: 6| Step: 4
Training loss: 2.879009436488214
Validation loss: 3.9551633117568326

Epoch: 6| Step: 5
Training loss: 3.893571955496885
Validation loss: 3.941041264499844

Epoch: 6| Step: 6
Training loss: 3.9584124640870666
Validation loss: 3.9277904064683278

Epoch: 6| Step: 7
Training loss: 4.39054398105576
Validation loss: 3.9184864732573317

Epoch: 6| Step: 8
Training loss: 3.7689870174646902
Validation loss: 3.907768234703717

Epoch: 6| Step: 9
Training loss: 4.875225746601101
Validation loss: 3.8935053061107365

Epoch: 6| Step: 10
Training loss: 2.851156629131471
Validation loss: 3.883383941707918

Epoch: 6| Step: 11
Training loss: 4.208519859083105
Validation loss: 3.8744857438909057

Epoch: 6| Step: 12
Training loss: 4.682001576615255
Validation loss: 3.8636162761902844

Epoch: 6| Step: 13
Training loss: 3.4993740611987207
Validation loss: 3.8551665379636346

Epoch: 9| Step: 0
Training loss: 3.7921852064656227
Validation loss: 3.8443718290594897

Epoch: 6| Step: 1
Training loss: 3.093692046884601
Validation loss: 3.8366019441215826

Epoch: 6| Step: 2
Training loss: 3.548963965092475
Validation loss: 3.8243146103346093

Epoch: 6| Step: 3
Training loss: 3.218219157767898
Validation loss: 3.819049132999588

Epoch: 6| Step: 4
Training loss: 4.3109871242386655
Validation loss: 3.80876477922137

Epoch: 6| Step: 5
Training loss: 5.050129033319231
Validation loss: 3.7973174284661484

Epoch: 6| Step: 6
Training loss: 4.370869021395776
Validation loss: 3.7896670550272806

Epoch: 6| Step: 7
Training loss: 4.42299786117471
Validation loss: 3.7771950708058104

Epoch: 6| Step: 8
Training loss: 3.6406301080888923
Validation loss: 3.7652449482653303

Epoch: 6| Step: 9
Training loss: 3.140602984754539
Validation loss: 3.7534892990813966

Epoch: 6| Step: 10
Training loss: 4.373569581659828
Validation loss: 3.747689044372499

Epoch: 6| Step: 11
Training loss: 3.9216272040274514
Validation loss: 3.737786008190271

Epoch: 6| Step: 12
Training loss: 3.454535839076555
Validation loss: 3.728292616565191

Epoch: 6| Step: 13
Training loss: 4.778213833468998
Validation loss: 3.7205807832691136

Epoch: 10| Step: 0
Training loss: 3.1585020585565955
Validation loss: 3.712003194206191

Epoch: 6| Step: 1
Training loss: 4.050590782874471
Validation loss: 3.7052815927675886

Epoch: 6| Step: 2
Training loss: 3.781788685156759
Validation loss: 3.695990069779749

Epoch: 6| Step: 3
Training loss: 3.2576923302458263
Validation loss: 3.6861053215345905

Epoch: 6| Step: 4
Training loss: 4.033791857000739
Validation loss: 3.6810904378051212

Epoch: 6| Step: 5
Training loss: 3.9031421963364052
Validation loss: 3.670868509484963

Epoch: 6| Step: 6
Training loss: 4.189036528675087
Validation loss: 3.6675621619082643

Epoch: 6| Step: 7
Training loss: 3.163287183172381
Validation loss: 3.65897683142467

Epoch: 6| Step: 8
Training loss: 4.739506625159074
Validation loss: 3.6527791846670965

Epoch: 6| Step: 9
Training loss: 4.764749815578328
Validation loss: 3.6479822241764377

Epoch: 6| Step: 10
Training loss: 3.6846060307538546
Validation loss: 3.6389820219302678

Epoch: 6| Step: 11
Training loss: 3.3756107201615864
Validation loss: 3.630587009604866

Epoch: 6| Step: 12
Training loss: 4.014987286349223
Validation loss: 3.6220684779253958

Epoch: 6| Step: 13
Training loss: 2.8115888179214243
Validation loss: 3.6040612743037714

Epoch: 11| Step: 0
Training loss: 3.077780147540867
Validation loss: 3.580362589965564

Epoch: 6| Step: 1
Training loss: 4.426922939611309
Validation loss: 3.5604896277328164

Epoch: 6| Step: 2
Training loss: 4.433197514645317
Validation loss: 3.556648069455475

Epoch: 6| Step: 3
Training loss: 3.7318815581813998
Validation loss: 3.5479677284375777

Epoch: 6| Step: 4
Training loss: 3.439150188737171
Validation loss: 3.539677054685119

Epoch: 6| Step: 5
Training loss: 3.715314287776743
Validation loss: 3.5334802775979024

Epoch: 6| Step: 6
Training loss: 4.376655047581152
Validation loss: 3.531049807840893

Epoch: 6| Step: 7
Training loss: 2.9020604936221743
Validation loss: 3.527827516684823

Epoch: 6| Step: 8
Training loss: 4.092043688484021
Validation loss: 3.520615689596089

Epoch: 6| Step: 9
Training loss: 2.976034763440778
Validation loss: 3.5159874207654047

Epoch: 6| Step: 10
Training loss: 3.9742762020600972
Validation loss: 3.5058854744840873

Epoch: 6| Step: 11
Training loss: 3.7298260040199827
Validation loss: 3.5039106896625967

Epoch: 6| Step: 12
Training loss: 3.7690320568912683
Validation loss: 3.502181630879999

Epoch: 6| Step: 13
Training loss: 2.7585654811226354
Validation loss: 3.5017343170723083

Epoch: 12| Step: 0
Training loss: 3.819636185582334
Validation loss: 3.49358129031447

Epoch: 6| Step: 1
Training loss: 4.141289654054555
Validation loss: 3.4884520272563235

Epoch: 6| Step: 2
Training loss: 4.5340479137983465
Validation loss: 3.486233326467648

Epoch: 6| Step: 3
Training loss: 4.551985866920239
Validation loss: 3.481618368257884

Epoch: 6| Step: 4
Training loss: 2.8382041427172404
Validation loss: 3.4690568901455094

Epoch: 6| Step: 5
Training loss: 3.5967018277980642
Validation loss: 3.466729569475762

Epoch: 6| Step: 6
Training loss: 3.62862806619268
Validation loss: 3.4622557840079056

Epoch: 6| Step: 7
Training loss: 3.006833717318115
Validation loss: 3.460548827384815

Epoch: 6| Step: 8
Training loss: 3.029691629864385
Validation loss: 3.4538579677102366

Epoch: 6| Step: 9
Training loss: 3.530990591057725
Validation loss: 3.4536437954921233

Epoch: 6| Step: 10
Training loss: 3.689832176175806
Validation loss: 3.44608713660565

Epoch: 6| Step: 11
Training loss: 3.728967302559073
Validation loss: 3.4405274350582467

Epoch: 6| Step: 12
Training loss: 3.6903603015523347
Validation loss: 3.4383188117079926

Epoch: 6| Step: 13
Training loss: 3.010572717619312
Validation loss: 3.4300243361682528

Epoch: 13| Step: 0
Training loss: 3.6672437965028015
Validation loss: 3.426962131112831

Epoch: 6| Step: 1
Training loss: 3.5512809108099166
Validation loss: 3.4249699276223007

Epoch: 6| Step: 2
Training loss: 4.322405068638591
Validation loss: 3.422881161983939

Epoch: 6| Step: 3
Training loss: 4.095907792856549
Validation loss: 3.4210100461624187

Epoch: 6| Step: 4
Training loss: 4.062719251144859
Validation loss: 3.412162448962809

Epoch: 6| Step: 5
Training loss: 3.3980679015076842
Validation loss: 3.4104405531663544

Epoch: 6| Step: 6
Training loss: 3.0125881577884597
Validation loss: 3.406549902458639

Epoch: 6| Step: 7
Training loss: 3.512561192098276
Validation loss: 3.4046682233933505

Epoch: 6| Step: 8
Training loss: 3.7543892921771387
Validation loss: 3.4021865542618133

Epoch: 6| Step: 9
Training loss: 3.8753059020354232
Validation loss: 3.4027691904986073

Epoch: 6| Step: 10
Training loss: 3.496904912007624
Validation loss: 3.3972152584677136

Epoch: 6| Step: 11
Training loss: 3.1546450018322902
Validation loss: 3.395875815895781

Epoch: 6| Step: 12
Training loss: 2.8268515739001607
Validation loss: 3.387469148504835

Epoch: 6| Step: 13
Training loss: 3.964514928252006
Validation loss: 3.3855803651570375

Epoch: 14| Step: 0
Training loss: 3.1465669664924634
Validation loss: 3.380237643621703

Epoch: 6| Step: 1
Training loss: 3.865868175755523
Validation loss: 3.3792616305018504

Epoch: 6| Step: 2
Training loss: 3.0624470608865098
Validation loss: 3.3757135889427206

Epoch: 6| Step: 3
Training loss: 3.6989809179337207
Validation loss: 3.373214045569375

Epoch: 6| Step: 4
Training loss: 2.8893482584770998
Validation loss: 3.367313676245017

Epoch: 6| Step: 5
Training loss: 2.8044759941576682
Validation loss: 3.364713184702314

Epoch: 6| Step: 6
Training loss: 3.546107272105332
Validation loss: 3.3623979494365295

Epoch: 6| Step: 7
Training loss: 3.90553521292248
Validation loss: 3.359952383558529

Epoch: 6| Step: 8
Training loss: 3.3805033707350125
Validation loss: 3.3600181839563685

Epoch: 6| Step: 9
Training loss: 3.47759445819049
Validation loss: 3.355362989818524

Epoch: 6| Step: 10
Training loss: 4.177681414753144
Validation loss: 3.354423854483141

Epoch: 6| Step: 11
Training loss: 3.3442907163564315
Validation loss: 3.3519695476633102

Epoch: 6| Step: 12
Training loss: 4.676616189420968
Validation loss: 3.3480697175285608

Epoch: 6| Step: 13
Training loss: 4.083893069355356
Validation loss: 3.350602857587091

Epoch: 15| Step: 0
Training loss: 2.744140625
Validation loss: 3.3467328017267626

Epoch: 6| Step: 1
Training loss: 4.285940899988398
Validation loss: 3.3456994607967596

Epoch: 6| Step: 2
Training loss: 3.149336390757335
Validation loss: 3.3468963997080343

Epoch: 6| Step: 3
Training loss: 3.8354624902797916
Validation loss: 3.351586677159441

Epoch: 6| Step: 4
Training loss: 4.017884327630008
Validation loss: 3.338524769408514

Epoch: 6| Step: 5
Training loss: 3.422317545940748
Validation loss: 3.335353264423796

Epoch: 6| Step: 6
Training loss: 3.845835050428895
Validation loss: 3.3314655228926275

Epoch: 6| Step: 7
Training loss: 2.965610651236774
Validation loss: 3.3307411040785433

Epoch: 6| Step: 8
Training loss: 2.405121674979014
Validation loss: 3.331535807339374

Epoch: 6| Step: 9
Training loss: 4.478251566299559
Validation loss: 3.3281097927860115

Epoch: 6| Step: 10
Training loss: 3.411238211404875
Validation loss: 3.328267128860903

Epoch: 6| Step: 11
Training loss: 3.4900067580193177
Validation loss: 3.3199441376103165

Epoch: 6| Step: 12
Training loss: 4.065096216318232
Validation loss: 3.3169867107362045

Epoch: 6| Step: 13
Training loss: 2.8313482473813103
Validation loss: 3.312529017576144

Epoch: 16| Step: 0
Training loss: 4.058953248184471
Validation loss: 3.309772092610783

Epoch: 6| Step: 1
Training loss: 4.023226063922555
Validation loss: 3.305877230126771

Epoch: 6| Step: 2
Training loss: 4.069933619227345
Validation loss: 3.3005109755579616

Epoch: 6| Step: 3
Training loss: 3.307294678373793
Validation loss: 3.2976538830566215

Epoch: 6| Step: 4
Training loss: 3.8325864368304035
Validation loss: 3.2960129301723726

Epoch: 6| Step: 5
Training loss: 3.7177609963756244
Validation loss: 3.293978361588402

Epoch: 6| Step: 6
Training loss: 3.126764790988683
Validation loss: 3.2954347480973656

Epoch: 6| Step: 7
Training loss: 2.334846573553323
Validation loss: 3.2891937511050635

Epoch: 6| Step: 8
Training loss: 3.915865362999307
Validation loss: 3.2850848608861525

Epoch: 6| Step: 9
Training loss: 3.2124305094168233
Validation loss: 3.283232335915647

Epoch: 6| Step: 10
Training loss: 3.3799935592499715
Validation loss: 3.2827646145745675

Epoch: 6| Step: 11
Training loss: 3.7516902928827878
Validation loss: 3.278955854354169

Epoch: 6| Step: 12
Training loss: 3.2816635597825217
Validation loss: 3.2754143328268546

Epoch: 6| Step: 13
Training loss: 2.7508492458946048
Validation loss: 3.271332072528578

Epoch: 17| Step: 0
Training loss: 3.2902618178801815
Validation loss: 3.2709752330223796

Epoch: 6| Step: 1
Training loss: 3.977601640650625
Validation loss: 3.2689151509575005

Epoch: 6| Step: 2
Training loss: 4.318698574704003
Validation loss: 3.266386390521651

Epoch: 6| Step: 3
Training loss: 4.01500225062325
Validation loss: 3.2645922727134127

Epoch: 6| Step: 4
Training loss: 3.5631388041321386
Validation loss: 3.2594156189362926

Epoch: 6| Step: 5
Training loss: 3.068965237716136
Validation loss: 3.2587929943495064

Epoch: 6| Step: 6
Training loss: 2.9472842307543106
Validation loss: 3.255195475235022

Epoch: 6| Step: 7
Training loss: 3.151585975903749
Validation loss: 3.2543782512288764

Epoch: 6| Step: 8
Training loss: 2.6693570949603274
Validation loss: 3.2521808602049864

Epoch: 6| Step: 9
Training loss: 3.775809796109179
Validation loss: 3.252604415206383

Epoch: 6| Step: 10
Training loss: 2.9307909705736095
Validation loss: 3.250006337313472

Epoch: 6| Step: 11
Training loss: 3.235990701235318
Validation loss: 3.249239734044519

Epoch: 6| Step: 12
Training loss: 3.387895179586253
Validation loss: 3.2433314349727485

Epoch: 6| Step: 13
Training loss: 4.801957112913215
Validation loss: 3.2402726841873637

Epoch: 18| Step: 0
Training loss: 3.20852756325164
Validation loss: 3.239155319317542

Epoch: 6| Step: 1
Training loss: 3.608275539179094
Validation loss: 3.2383562722527133

Epoch: 6| Step: 2
Training loss: 3.0936340926835646
Validation loss: 3.2373956825426453

Epoch: 6| Step: 3
Training loss: 3.154573807502754
Validation loss: 3.2325690682293686

Epoch: 6| Step: 4
Training loss: 4.119632812729643
Validation loss: 3.2289658520063043

Epoch: 6| Step: 5
Training loss: 2.987416899095924
Validation loss: 3.22676816232865

Epoch: 6| Step: 6
Training loss: 3.8951215994857304
Validation loss: 3.2293244645183297

Epoch: 6| Step: 7
Training loss: 3.7717626420600157
Validation loss: 3.2230618097565173

Epoch: 6| Step: 8
Training loss: 3.4252027242767076
Validation loss: 3.223172685765622

Epoch: 6| Step: 9
Training loss: 3.579466455862183
Validation loss: 3.2214387208497803

Epoch: 6| Step: 10
Training loss: 3.2993205613712364
Validation loss: 3.215053844294141

Epoch: 6| Step: 11
Training loss: 2.37362530726823
Validation loss: 3.2109185808502296

Epoch: 6| Step: 12
Training loss: 4.185970197765631
Validation loss: 3.2102904091262396

Epoch: 6| Step: 13
Training loss: 3.64110997452956
Validation loss: 3.20941191257036

Epoch: 19| Step: 0
Training loss: 3.304722129694445
Validation loss: 3.207916004625754

Epoch: 6| Step: 1
Training loss: 3.5627512257652643
Validation loss: 3.2056308103913365

Epoch: 6| Step: 2
Training loss: 3.5128773442461343
Validation loss: 3.199235986633637

Epoch: 6| Step: 3
Training loss: 3.3144726907200934
Validation loss: 3.198502795546533

Epoch: 6| Step: 4
Training loss: 3.929956749248566
Validation loss: 3.1914533211323928

Epoch: 6| Step: 5
Training loss: 3.3735023283814
Validation loss: 3.1925857365969974

Epoch: 6| Step: 6
Training loss: 3.3311079385035582
Validation loss: 3.18606082727229

Epoch: 6| Step: 7
Training loss: 4.480815471613333
Validation loss: 3.186118666879593

Epoch: 6| Step: 8
Training loss: 3.7109617854879686
Validation loss: 3.1835770020282514

Epoch: 6| Step: 9
Training loss: 2.7580581858183963
Validation loss: 3.1817272092436224

Epoch: 6| Step: 10
Training loss: 2.9929137780247577
Validation loss: 3.181550684731413

Epoch: 6| Step: 11
Training loss: 3.714576880078033
Validation loss: 3.184220369083778

Epoch: 6| Step: 12
Training loss: 3.203854361511364
Validation loss: 3.175591429826586

Epoch: 6| Step: 13
Training loss: 1.9572195849528853
Validation loss: 3.171789989648665

Epoch: 20| Step: 0
Training loss: 3.044052303270893
Validation loss: 3.170155631688706

Epoch: 6| Step: 1
Training loss: 3.7724330031081337
Validation loss: 3.166972820451989

Epoch: 6| Step: 2
Training loss: 2.091240702971538
Validation loss: 3.161180246829608

Epoch: 6| Step: 3
Training loss: 3.8339709428891044
Validation loss: 3.1582996946391924

Epoch: 6| Step: 4
Training loss: 3.9130481616282426
Validation loss: 3.157322898119133

Epoch: 6| Step: 5
Training loss: 2.8167853027580034
Validation loss: 3.1581409872950625

Epoch: 6| Step: 6
Training loss: 4.339592789914209
Validation loss: 3.1511028389962177

Epoch: 6| Step: 7
Training loss: 3.4276027730256784
Validation loss: 3.148315725350965

Epoch: 6| Step: 8
Training loss: 3.5322075279847236
Validation loss: 3.147110909753536

Epoch: 6| Step: 9
Training loss: 2.872684873469971
Validation loss: 3.143602855171787

Epoch: 6| Step: 10
Training loss: 3.360019497814827
Validation loss: 3.139922576358909

Epoch: 6| Step: 11
Training loss: 2.626097858276168
Validation loss: 3.1465245523614107

Epoch: 6| Step: 12
Training loss: 4.035023423969484
Validation loss: 3.143302002272843

Epoch: 6| Step: 13
Training loss: 3.5455602149955343
Validation loss: 3.137998567254625

Epoch: 21| Step: 0
Training loss: 3.9626441905264334
Validation loss: 3.132865909602619

Epoch: 6| Step: 1
Training loss: 3.51398154946153
Validation loss: 3.130556552220018

Epoch: 6| Step: 2
Training loss: 2.8948768481478417
Validation loss: 3.1284097523361947

Epoch: 6| Step: 3
Training loss: 3.218120328181542
Validation loss: 3.125682859568987

Epoch: 6| Step: 4
Training loss: 3.1974237084850095
Validation loss: 3.1278243987054664

Epoch: 6| Step: 5
Training loss: 3.8329077912905296
Validation loss: 3.126205503867547

Epoch: 6| Step: 6
Training loss: 3.2681317359211457
Validation loss: 3.122316940454791

Epoch: 6| Step: 7
Training loss: 3.519661582371087
Validation loss: 3.1186719915519596

Epoch: 6| Step: 8
Training loss: 3.129976506251684
Validation loss: 3.117328007470725

Epoch: 6| Step: 9
Training loss: 2.6709283412117104
Validation loss: 3.112589882010271

Epoch: 6| Step: 10
Training loss: 3.5321038488239487
Validation loss: 3.1076449947205917

Epoch: 6| Step: 11
Training loss: 3.1982327945949858
Validation loss: 3.1093440320975194

Epoch: 6| Step: 12
Training loss: 3.453237954618219
Validation loss: 3.1070834623509915

Epoch: 6| Step: 13
Training loss: 4.231365866039612
Validation loss: 3.104176749982284

Epoch: 22| Step: 0
Training loss: 3.6884411402852995
Validation loss: 3.103631599418589

Epoch: 6| Step: 1
Training loss: 3.369718445695319
Validation loss: 3.094374081521128

Epoch: 6| Step: 2
Training loss: 2.808381349811531
Validation loss: 3.0942067405469027

Epoch: 6| Step: 3
Training loss: 3.0933467717810563
Validation loss: 3.0931650194752867

Epoch: 6| Step: 4
Training loss: 3.6765130801269734
Validation loss: 3.0929489896958393

Epoch: 6| Step: 5
Training loss: 3.017753679915583
Validation loss: 3.092266106002425

Epoch: 6| Step: 6
Training loss: 2.6300391013716227
Validation loss: 3.087229273359043

Epoch: 6| Step: 7
Training loss: 3.086490938802124
Validation loss: 3.088211315542553

Epoch: 6| Step: 8
Training loss: 4.0197184438462665
Validation loss: 3.083823583839734

Epoch: 6| Step: 9
Training loss: 3.9092081084636976
Validation loss: 3.078385808387634

Epoch: 6| Step: 10
Training loss: 3.329059594970513
Validation loss: 3.0746975323544117

Epoch: 6| Step: 11
Training loss: 3.880291924653637
Validation loss: 3.074899175288051

Epoch: 6| Step: 12
Training loss: 2.286100378380827
Validation loss: 3.07408043605918

Epoch: 6| Step: 13
Training loss: 4.09426713545475
Validation loss: 3.068636336942006

Epoch: 23| Step: 0
Training loss: 3.42905581833204
Validation loss: 3.062857962928065

Epoch: 6| Step: 1
Training loss: 3.0070352714355093
Validation loss: 3.060378759113045

Epoch: 6| Step: 2
Training loss: 2.438561917339998
Validation loss: 3.057961833938699

Epoch: 6| Step: 3
Training loss: 3.726168885626225
Validation loss: 3.0537179071578042

Epoch: 6| Step: 4
Training loss: 3.1277584871096624
Validation loss: 3.0559378160805206

Epoch: 6| Step: 5
Training loss: 3.04743036930689
Validation loss: 3.0565345143704286

Epoch: 6| Step: 6
Training loss: 3.4562477042826916
Validation loss: 3.0535795696552084

Epoch: 6| Step: 7
Training loss: 3.3594221244877884
Validation loss: 3.0549005054870064

Epoch: 6| Step: 8
Training loss: 3.6841282057349067
Validation loss: 3.0605073028912155

Epoch: 6| Step: 9
Training loss: 3.6656136879254535
Validation loss: 3.052930861578498

Epoch: 6| Step: 10
Training loss: 4.122789426397976
Validation loss: 3.04360062029911

Epoch: 6| Step: 11
Training loss: 3.196611583369052
Validation loss: 3.0404749255183368

Epoch: 6| Step: 12
Training loss: 3.1574787731771
Validation loss: 3.038198904539117

Epoch: 6| Step: 13
Training loss: 2.6805988686004554
Validation loss: 3.034834130366563

Epoch: 24| Step: 0
Training loss: 2.712674246961731
Validation loss: 3.0373603880880493

Epoch: 6| Step: 1
Training loss: 4.0712327264706865
Validation loss: 3.0364743522193782

Epoch: 6| Step: 2
Training loss: 3.1690715558925437
Validation loss: 3.0318592974311067

Epoch: 6| Step: 3
Training loss: 2.7827871125491312
Validation loss: 3.0324696441598107

Epoch: 6| Step: 4
Training loss: 4.009909276530562
Validation loss: 3.0299499044382685

Epoch: 6| Step: 5
Training loss: 2.646736071114602
Validation loss: 3.0305573535053627

Epoch: 6| Step: 6
Training loss: 3.702449302352001
Validation loss: 3.0297183095543367

Epoch: 6| Step: 7
Training loss: 3.626504125622462
Validation loss: 3.0276966070605713

Epoch: 6| Step: 8
Training loss: 3.26154360729249
Validation loss: 3.025264121118364

Epoch: 6| Step: 9
Training loss: 3.208470197128123
Validation loss: 3.020414208065815

Epoch: 6| Step: 10
Training loss: 3.6269936176724547
Validation loss: 3.017946492597781

Epoch: 6| Step: 11
Training loss: 2.7497941720402324
Validation loss: 3.0164950071816268

Epoch: 6| Step: 12
Training loss: 3.6814618864105806
Validation loss: 3.0097151825105932

Epoch: 6| Step: 13
Training loss: 1.9463236681765756
Validation loss: 3.0120010512868918

Epoch: 25| Step: 0
Training loss: 3.270113693733949
Validation loss: 3.012642852932235

Epoch: 6| Step: 1
Training loss: 2.7008327400876198
Validation loss: 3.005316987505307

Epoch: 6| Step: 2
Training loss: 2.987575552396025
Validation loss: 3.0096866934592015

Epoch: 6| Step: 3
Training loss: 2.9543628822951327
Validation loss: 3.0065889825187773

Epoch: 6| Step: 4
Training loss: 3.5892789145203947
Validation loss: 3.0032308538686205

Epoch: 6| Step: 5
Training loss: 3.585523394441174
Validation loss: 2.999123867514692

Epoch: 6| Step: 6
Training loss: 2.840128174696708
Validation loss: 2.9995483721619705

Epoch: 6| Step: 7
Training loss: 3.648721883991537
Validation loss: 2.9996192752070665

Epoch: 6| Step: 8
Training loss: 3.7817151752945675
Validation loss: 2.99995267482059

Epoch: 6| Step: 9
Training loss: 3.552787524513102
Validation loss: 2.995289485835986

Epoch: 6| Step: 10
Training loss: 3.5215580361818923
Validation loss: 2.996282621804816

Epoch: 6| Step: 11
Training loss: 2.979297572818933
Validation loss: 2.9923276981655724

Epoch: 6| Step: 12
Training loss: 3.4752784672317536
Validation loss: 2.993830068471785

Epoch: 6| Step: 13
Training loss: 2.728301010484106
Validation loss: 2.98985940685339

Epoch: 26| Step: 0
Training loss: 2.8999564003133327
Validation loss: 2.9886934004080743

Epoch: 6| Step: 1
Training loss: 3.623514068176155
Validation loss: 2.986701529658486

Epoch: 6| Step: 2
Training loss: 3.471950394904532
Validation loss: 2.9845080610962404

Epoch: 6| Step: 3
Training loss: 2.720768409487957
Validation loss: 2.982494402335575

Epoch: 6| Step: 4
Training loss: 2.76367498067405
Validation loss: 2.9788101146998196

Epoch: 6| Step: 5
Training loss: 3.442361064869247
Validation loss: 2.978885151712293

Epoch: 6| Step: 6
Training loss: 3.2516988568950564
Validation loss: 2.9867184202574553

Epoch: 6| Step: 7
Training loss: 3.4162007145932884
Validation loss: 2.9834349601949266

Epoch: 6| Step: 8
Training loss: 3.8090192821171867
Validation loss: 2.980028683615972

Epoch: 6| Step: 9
Training loss: 3.2385911965756957
Validation loss: 2.9722878377921638

Epoch: 6| Step: 10
Training loss: 2.3527799477455233
Validation loss: 2.9684395066969285

Epoch: 6| Step: 11
Training loss: 3.213146776928033
Validation loss: 2.9678811132179064

Epoch: 6| Step: 12
Training loss: 3.6987001403975235
Validation loss: 2.965827046130421

Epoch: 6| Step: 13
Training loss: 3.8420074979201573
Validation loss: 2.972291811392689

Epoch: 27| Step: 0
Training loss: 3.1045921767969005
Validation loss: 2.977435416066743

Epoch: 6| Step: 1
Training loss: 3.4546922260115798
Validation loss: 2.9666859332218682

Epoch: 6| Step: 2
Training loss: 2.4669308297581094
Validation loss: 2.9623537476708215

Epoch: 6| Step: 3
Training loss: 3.159846607782852
Validation loss: 2.9619533038712

Epoch: 6| Step: 4
Training loss: 3.723916960088499
Validation loss: 2.9645916989460903

Epoch: 6| Step: 5
Training loss: 2.9353776122816924
Validation loss: 2.9721561737997146

Epoch: 6| Step: 6
Training loss: 3.926707417568627
Validation loss: 2.9688897264604592

Epoch: 6| Step: 7
Training loss: 3.330203844309432
Validation loss: 2.954602218152639

Epoch: 6| Step: 8
Training loss: 3.2748945903558324
Validation loss: 2.9521013664641798

Epoch: 6| Step: 9
Training loss: 3.0844299497028658
Validation loss: 2.958806153647781

Epoch: 6| Step: 10
Training loss: 2.8857241763926083
Validation loss: 2.951534662734452

Epoch: 6| Step: 11
Training loss: 3.984068136927095
Validation loss: 2.9516087533191038

Epoch: 6| Step: 12
Training loss: 2.5171645293084524
Validation loss: 2.9471152376569094

Epoch: 6| Step: 13
Training loss: 3.480896723301485
Validation loss: 2.947347195443671

Epoch: 28| Step: 0
Training loss: 3.1792009810916055
Validation loss: 2.944913229796135

Epoch: 6| Step: 1
Training loss: 3.5602083029508806
Validation loss: 2.944055592779456

Epoch: 6| Step: 2
Training loss: 3.639654595052814
Validation loss: 2.9478012532556277

Epoch: 6| Step: 3
Training loss: 3.1811199289047867
Validation loss: 2.947208864111022

Epoch: 6| Step: 4
Training loss: 3.428135548995278
Validation loss: 2.9432099587337155

Epoch: 6| Step: 5
Training loss: 3.260194488527846
Validation loss: 2.937769568298529

Epoch: 6| Step: 6
Training loss: 2.3548845417528588
Validation loss: 2.9384373722928183

Epoch: 6| Step: 7
Training loss: 3.3163838200434075
Validation loss: 2.9405827697823095

Epoch: 6| Step: 8
Training loss: 3.148659823687331
Validation loss: 2.9509398573181995

Epoch: 6| Step: 9
Training loss: 2.770141534322429
Validation loss: 2.9395693103723866

Epoch: 6| Step: 10
Training loss: 3.0997607477215454
Validation loss: 2.941853778338818

Epoch: 6| Step: 11
Training loss: 3.341502066828939
Validation loss: 2.9457920667932593

Epoch: 6| Step: 12
Training loss: 3.3305506217212275
Validation loss: 2.941196778189314

Epoch: 6| Step: 13
Training loss: 3.789766289543184
Validation loss: 2.9318318013053792

Epoch: 29| Step: 0
Training loss: 3.0891152546709266
Validation loss: 2.9296680141881106

Epoch: 6| Step: 1
Training loss: 3.351988723080405
Validation loss: 2.9307224043319717

Epoch: 6| Step: 2
Training loss: 3.0349837441928167
Validation loss: 2.923938056447074

Epoch: 6| Step: 3
Training loss: 2.9882956111787267
Validation loss: 2.926967937524696

Epoch: 6| Step: 4
Training loss: 2.781341722668985
Validation loss: 2.9275493963858423

Epoch: 6| Step: 5
Training loss: 2.6451745201758428
Validation loss: 2.9250301312203284

Epoch: 6| Step: 6
Training loss: 3.229407287164566
Validation loss: 2.9320488644187406

Epoch: 6| Step: 7
Training loss: 3.28256010513304
Validation loss: 2.93087238898873

Epoch: 6| Step: 8
Training loss: 3.3892415823784448
Validation loss: 2.9282269509814434

Epoch: 6| Step: 9
Training loss: 4.044020187101152
Validation loss: 2.9282629755238547

Epoch: 6| Step: 10
Training loss: 3.3685576092025076
Validation loss: 2.9231271789896693

Epoch: 6| Step: 11
Training loss: 3.6566231040017287
Validation loss: 2.9172102713102457

Epoch: 6| Step: 12
Training loss: 2.451267389511061
Validation loss: 2.918972146353986

Epoch: 6| Step: 13
Training loss: 3.952896413112214
Validation loss: 2.9175797520132347

Epoch: 30| Step: 0
Training loss: 4.281637132502453
Validation loss: 2.919015961951172

Epoch: 6| Step: 1
Training loss: 3.6422003092432145
Validation loss: 2.9155116933804655

Epoch: 6| Step: 2
Training loss: 2.7039805034239297
Validation loss: 2.911709796486929

Epoch: 6| Step: 3
Training loss: 2.9622938124614944
Validation loss: 2.9089929323935535

Epoch: 6| Step: 4
Training loss: 3.214812601895734
Validation loss: 2.9075960660271813

Epoch: 6| Step: 5
Training loss: 2.647533971552335
Validation loss: 2.9127546687517794

Epoch: 6| Step: 6
Training loss: 3.8398680894765223
Validation loss: 2.914768297923467

Epoch: 6| Step: 7
Training loss: 3.0474989032195747
Validation loss: 2.910546163516316

Epoch: 6| Step: 8
Training loss: 3.2408756405642194
Validation loss: 2.909616787876307

Epoch: 6| Step: 9
Training loss: 2.9041484494689205
Validation loss: 2.906818360339257

Epoch: 6| Step: 10
Training loss: 2.547292476208923
Validation loss: 2.9110664930083963

Epoch: 6| Step: 11
Training loss: 3.526211274808962
Validation loss: 2.91197507369537

Epoch: 6| Step: 12
Training loss: 3.4061993236446777
Validation loss: 2.904386686311285

Epoch: 6| Step: 13
Training loss: 1.96289038207399
Validation loss: 2.9005637836913176

Epoch: 31| Step: 0
Training loss: 2.6994174823390176
Validation loss: 2.8992119378543224

Epoch: 6| Step: 1
Training loss: 3.456326204808425
Validation loss: 2.8972835956474463

Epoch: 6| Step: 2
Training loss: 2.9231018102026582
Validation loss: 2.89647422126426

Epoch: 6| Step: 3
Training loss: 4.159155955518992
Validation loss: 2.8958704100529857

Epoch: 6| Step: 4
Training loss: 3.0004856988012687
Validation loss: 2.8910996366399386

Epoch: 6| Step: 5
Training loss: 3.028313226823781
Validation loss: 2.8946375266119175

Epoch: 6| Step: 6
Training loss: 3.123795544253004
Validation loss: 2.8881789438924534

Epoch: 6| Step: 7
Training loss: 2.9567479107463046
Validation loss: 2.889326891090221

Epoch: 6| Step: 8
Training loss: 2.9871567149830227
Validation loss: 2.886170057277187

Epoch: 6| Step: 9
Training loss: 2.786755716492007
Validation loss: 2.886662249721484

Epoch: 6| Step: 10
Training loss: 3.462317473630633
Validation loss: 2.8939410451504495

Epoch: 6| Step: 11
Training loss: 3.392838138154231
Validation loss: 2.902080325578035

Epoch: 6| Step: 12
Training loss: 3.1898409157431384
Validation loss: 2.9003976855442914

Epoch: 6| Step: 13
Training loss: 3.610727824549177
Validation loss: 2.9022852643419714

Epoch: 32| Step: 0
Training loss: 3.475180224678159
Validation loss: 2.8827458286765557

Epoch: 6| Step: 1
Training loss: 3.5861336315763457
Validation loss: 2.8875761041519046

Epoch: 6| Step: 2
Training loss: 2.993303772993478
Validation loss: 2.8847437464433527

Epoch: 6| Step: 3
Training loss: 3.0772412575753982
Validation loss: 2.8866039356918307

Epoch: 6| Step: 4
Training loss: 3.062971117800729
Validation loss: 2.8931855332570984

Epoch: 6| Step: 5
Training loss: 3.115400294366781
Validation loss: 2.8975251459030025

Epoch: 6| Step: 6
Training loss: 4.159336636177908
Validation loss: 2.9052461356244055

Epoch: 6| Step: 7
Training loss: 3.5026935022393673
Validation loss: 2.9089164018131144

Epoch: 6| Step: 8
Training loss: 3.4340227052252352
Validation loss: 2.8951085726219272

Epoch: 6| Step: 9
Training loss: 3.130995073429741
Validation loss: 2.8961298441002223

Epoch: 6| Step: 10
Training loss: 2.487304879208375
Validation loss: 2.90286281377597

Epoch: 6| Step: 11
Training loss: 2.8953398322901234
Validation loss: 2.901928632845912

Epoch: 6| Step: 12
Training loss: 2.8714537933261317
Validation loss: 2.8925637290816653

Epoch: 6| Step: 13
Training loss: 2.4287147659989428
Validation loss: 2.8928693320519665

Epoch: 33| Step: 0
Training loss: 3.5100526856818273
Validation loss: 2.8888320182343468

Epoch: 6| Step: 1
Training loss: 2.550314423866888
Validation loss: 2.8875812179762512

Epoch: 6| Step: 2
Training loss: 3.5532741545519992
Validation loss: 2.8821875044246164

Epoch: 6| Step: 3
Training loss: 2.8018257183409947
Validation loss: 2.8807133567850656

Epoch: 6| Step: 4
Training loss: 2.514623975912577
Validation loss: 2.8829266587553235

Epoch: 6| Step: 5
Training loss: 3.2898406424379765
Validation loss: 2.8797995100585414

Epoch: 6| Step: 6
Training loss: 3.1802390180286753
Validation loss: 2.8772970566993075

Epoch: 6| Step: 7
Training loss: 3.2888864936762614
Validation loss: 2.875870107961305

Epoch: 6| Step: 8
Training loss: 3.6736508234894623
Validation loss: 2.8789560583030225

Epoch: 6| Step: 9
Training loss: 3.6639672370678538
Validation loss: 2.875688164642871

Epoch: 6| Step: 10
Training loss: 3.641041089294135
Validation loss: 2.876833097248387

Epoch: 6| Step: 11
Training loss: 3.2487406124553253
Validation loss: 2.871320592164332

Epoch: 6| Step: 12
Training loss: 2.1921396371261728
Validation loss: 2.875838264967467

Epoch: 6| Step: 13
Training loss: 3.26479712400714
Validation loss: 2.8761060993673686

Epoch: 34| Step: 0
Training loss: 3.426814724831968
Validation loss: 2.8741883509431156

Epoch: 6| Step: 1
Training loss: 2.637732371719947
Validation loss: 2.874972566685063

Epoch: 6| Step: 2
Training loss: 3.0267227815756086
Validation loss: 2.8725325476635986

Epoch: 6| Step: 3
Training loss: 3.1437995011848168
Validation loss: 2.87137133559745

Epoch: 6| Step: 4
Training loss: 3.850779115192969
Validation loss: 2.8721216326925507

Epoch: 6| Step: 5
Training loss: 2.9127560875419514
Validation loss: 2.869030299701776

Epoch: 6| Step: 6
Training loss: 2.81919107306103
Validation loss: 2.877438216221399

Epoch: 6| Step: 7
Training loss: 3.581829169344102
Validation loss: 2.8846766985068775

Epoch: 6| Step: 8
Training loss: 2.7110083842835606
Validation loss: 2.872863189459636

Epoch: 6| Step: 9
Training loss: 3.776305694118866
Validation loss: 2.864947344043336

Epoch: 6| Step: 10
Training loss: 3.834207241675799
Validation loss: 2.860435876742298

Epoch: 6| Step: 11
Training loss: 2.9441885587078276
Validation loss: 2.860697632637386

Epoch: 6| Step: 12
Training loss: 2.8633974892205263
Validation loss: 2.8593428056476755

Epoch: 6| Step: 13
Training loss: 2.155323437627999
Validation loss: 2.8607357218402765

Epoch: 35| Step: 0
Training loss: 3.066731701727965
Validation loss: 2.85631916882115

Epoch: 6| Step: 1
Training loss: 2.565363795636241
Validation loss: 2.856416770274296

Epoch: 6| Step: 2
Training loss: 3.017131211848719
Validation loss: 2.8553984729206876

Epoch: 6| Step: 3
Training loss: 3.815200099671983
Validation loss: 2.8542916294733436

Epoch: 6| Step: 4
Training loss: 2.5993068871605245
Validation loss: 2.8562040372537587

Epoch: 6| Step: 5
Training loss: 3.0505974356436263
Validation loss: 2.856639114226718

Epoch: 6| Step: 6
Training loss: 3.585516744957293
Validation loss: 2.854245204457259

Epoch: 6| Step: 7
Training loss: 3.168909048569471
Validation loss: 2.8537380269995545

Epoch: 6| Step: 8
Training loss: 2.6667924692361438
Validation loss: 2.8490823944166044

Epoch: 6| Step: 9
Training loss: 3.1014748664217637
Validation loss: 2.8509314800399683

Epoch: 6| Step: 10
Training loss: 3.41138526119956
Validation loss: 2.855960624976626

Epoch: 6| Step: 11
Training loss: 3.572095429968693
Validation loss: 2.8603971525843406

Epoch: 6| Step: 12
Training loss: 3.333819322126352
Validation loss: 2.861112482169025

Epoch: 6| Step: 13
Training loss: 3.288786887901185
Validation loss: 2.861064877527952

Epoch: 36| Step: 0
Training loss: 2.8463893840503913
Validation loss: 2.864783470940931

Epoch: 6| Step: 1
Training loss: 3.384470614758398
Validation loss: 2.8753219877170095

Epoch: 6| Step: 2
Training loss: 3.1427036068309375
Validation loss: 2.8573664193577195

Epoch: 6| Step: 3
Training loss: 2.661287982861338
Validation loss: 2.846354511925476

Epoch: 6| Step: 4
Training loss: 2.7984617197084516
Validation loss: 2.8461408718801264

Epoch: 6| Step: 5
Training loss: 2.9016579065367756
Validation loss: 2.849243378965014

Epoch: 6| Step: 6
Training loss: 3.2621827303788233
Validation loss: 2.8564129163967986

Epoch: 6| Step: 7
Training loss: 3.089332123462153
Validation loss: 2.852739495708588

Epoch: 6| Step: 8
Training loss: 3.2447317412809302
Validation loss: 2.8477806780846406

Epoch: 6| Step: 9
Training loss: 3.0222105548047513
Validation loss: 2.847000690975695

Epoch: 6| Step: 10
Training loss: 3.8582860978093407
Validation loss: 2.8547230860715223

Epoch: 6| Step: 11
Training loss: 3.5856749993279737
Validation loss: 2.857905324375938

Epoch: 6| Step: 12
Training loss: 2.978779605361379
Validation loss: 2.870260187263015

Epoch: 6| Step: 13
Training loss: 3.7674451046129356
Validation loss: 2.865342174861197

Epoch: 37| Step: 0
Training loss: 3.0415066890363933
Validation loss: 2.859672125249549

Epoch: 6| Step: 1
Training loss: 2.9613495794117135
Validation loss: 2.852576053672451

Epoch: 6| Step: 2
Training loss: 3.65423789453338
Validation loss: 2.84794287673382

Epoch: 6| Step: 3
Training loss: 2.3070868981790675
Validation loss: 2.846540799665806

Epoch: 6| Step: 4
Training loss: 2.8515885861392434
Validation loss: 2.8521962629034925

Epoch: 6| Step: 5
Training loss: 3.142643066645644
Validation loss: 2.852470266271262

Epoch: 6| Step: 6
Training loss: 3.074917123809736
Validation loss: 2.852819160735633

Epoch: 6| Step: 7
Training loss: 3.486277792003612
Validation loss: 2.85153709868927

Epoch: 6| Step: 8
Training loss: 2.7406509311193057
Validation loss: 2.8494284701716026

Epoch: 6| Step: 9
Training loss: 3.1802276227565764
Validation loss: 2.8433089213405323

Epoch: 6| Step: 10
Training loss: 3.524862808912607
Validation loss: 2.8404718684362202

Epoch: 6| Step: 11
Training loss: 3.6175496062256585
Validation loss: 2.836079409199231

Epoch: 6| Step: 12
Training loss: 3.533417163310269
Validation loss: 2.8355082570653996

Epoch: 6| Step: 13
Training loss: 2.982306757355907
Validation loss: 2.8355726251810496

Epoch: 38| Step: 0
Training loss: 3.4391994090301368
Validation loss: 2.8386994354817463

Epoch: 6| Step: 1
Training loss: 2.3564262911064033
Validation loss: 2.836887987819833

Epoch: 6| Step: 2
Training loss: 3.792348667613257
Validation loss: 2.8467392561265688

Epoch: 6| Step: 3
Training loss: 1.848089639108035
Validation loss: 2.845204811148404

Epoch: 6| Step: 4
Training loss: 3.537328703813894
Validation loss: 2.8627809819650865

Epoch: 6| Step: 5
Training loss: 3.2697476733552557
Validation loss: 2.8406186429853784

Epoch: 6| Step: 6
Training loss: 3.4064904924240706
Validation loss: 2.838889463864092

Epoch: 6| Step: 7
Training loss: 2.900522638778047
Validation loss: 2.8404321960930528

Epoch: 6| Step: 8
Training loss: 2.775813157134156
Validation loss: 2.8329867785007705

Epoch: 6| Step: 9
Training loss: 3.9607232090393603
Validation loss: 2.8298709429253397

Epoch: 6| Step: 10
Training loss: 3.1375772291914386
Validation loss: 2.8308925056073346

Epoch: 6| Step: 11
Training loss: 3.2530692353173283
Validation loss: 2.827932665456823

Epoch: 6| Step: 12
Training loss: 3.135380707763762
Validation loss: 2.8308344962527707

Epoch: 6| Step: 13
Training loss: 2.498798081439683
Validation loss: 2.8290420248391284

Epoch: 39| Step: 0
Training loss: 3.9029194786137937
Validation loss: 2.826218975237717

Epoch: 6| Step: 1
Training loss: 3.40221607130732
Validation loss: 2.8291392769509316

Epoch: 6| Step: 2
Training loss: 3.0253154432536395
Validation loss: 2.8295874097493465

Epoch: 6| Step: 3
Training loss: 3.474313209781623
Validation loss: 2.8279820588902367

Epoch: 6| Step: 4
Training loss: 2.5606478068160325
Validation loss: 2.826756611049605

Epoch: 6| Step: 5
Training loss: 2.7573259913305574
Validation loss: 2.832225690424882

Epoch: 6| Step: 6
Training loss: 2.8465758316175114
Validation loss: 2.837429640215967

Epoch: 6| Step: 7
Training loss: 3.2062587388423336
Validation loss: 2.8392413960238883

Epoch: 6| Step: 8
Training loss: 3.3524730663654205
Validation loss: 2.856920558511543

Epoch: 6| Step: 9
Training loss: 3.263821774777944
Validation loss: 2.859969682166348

Epoch: 6| Step: 10
Training loss: 2.8695158690329343
Validation loss: 2.8416189967089185

Epoch: 6| Step: 11
Training loss: 2.1725328944693265
Validation loss: 2.833743866115184

Epoch: 6| Step: 12
Training loss: 3.8261986693086185
Validation loss: 2.8308683125473393

Epoch: 6| Step: 13
Training loss: 2.8831135248914688
Validation loss: 2.825111202425661

Epoch: 40| Step: 0
Training loss: 2.709666017172888
Validation loss: 2.8215312345322423

Epoch: 6| Step: 1
Training loss: 3.6132056315989356
Validation loss: 2.822374244913496

Epoch: 6| Step: 2
Training loss: 2.973037675205021
Validation loss: 2.8211475833872854

Epoch: 6| Step: 3
Training loss: 3.243768439856065
Validation loss: 2.8246169758876536

Epoch: 6| Step: 4
Training loss: 2.9400925254534997
Validation loss: 2.8234075382769728

Epoch: 6| Step: 5
Training loss: 3.312913688882545
Validation loss: 2.821427696860745

Epoch: 6| Step: 6
Training loss: 3.539299356985008
Validation loss: 2.8190161762672727

Epoch: 6| Step: 7
Training loss: 2.998592046320057
Validation loss: 2.8179297343257277

Epoch: 6| Step: 8
Training loss: 2.5650199037192345
Validation loss: 2.817610755216329

Epoch: 6| Step: 9
Training loss: 3.320760396031174
Validation loss: 2.8162246496955423

Epoch: 6| Step: 10
Training loss: 3.8140603296382345
Validation loss: 2.817386408568408

Epoch: 6| Step: 11
Training loss: 2.490721268271153
Validation loss: 2.8158003244431606

Epoch: 6| Step: 12
Training loss: 2.9639317010585855
Validation loss: 2.8151421937048147

Epoch: 6| Step: 13
Training loss: 3.3742304737040194
Validation loss: 2.815594703110966

Epoch: 41| Step: 0
Training loss: 3.5682216005918375
Validation loss: 2.815303525454449

Epoch: 6| Step: 1
Training loss: 2.838906827531124
Validation loss: 2.817774180123849

Epoch: 6| Step: 2
Training loss: 3.434792301834025
Validation loss: 2.817884958296692

Epoch: 6| Step: 3
Training loss: 3.1885948544768263
Validation loss: 2.8259100971598654

Epoch: 6| Step: 4
Training loss: 3.127955603038131
Validation loss: 2.819235956562695

Epoch: 6| Step: 5
Training loss: 2.825255313240107
Validation loss: 2.814904185993922

Epoch: 6| Step: 6
Training loss: 2.7327996647894874
Validation loss: 2.814309682601749

Epoch: 6| Step: 7
Training loss: 2.5764085083997337
Validation loss: 2.8151829546029234

Epoch: 6| Step: 8
Training loss: 2.5584874254804446
Validation loss: 2.8123614332914024

Epoch: 6| Step: 9
Training loss: 3.238540399763208
Validation loss: 2.8104062808751844

Epoch: 6| Step: 10
Training loss: 3.539569742596905
Validation loss: 2.8091101285751967

Epoch: 6| Step: 11
Training loss: 3.028776280269048
Validation loss: 2.812757781508124

Epoch: 6| Step: 12
Training loss: 3.339447676167475
Validation loss: 2.814089505721501

Epoch: 6| Step: 13
Training loss: 4.077240478938629
Validation loss: 2.814024527767167

Epoch: 42| Step: 0
Training loss: 3.0554991129276345
Validation loss: 2.816489580556772

Epoch: 6| Step: 1
Training loss: 2.4704029971489985
Validation loss: 2.814811724516741

Epoch: 6| Step: 2
Training loss: 3.268449501827448
Validation loss: 2.8148720658975317

Epoch: 6| Step: 3
Training loss: 2.7284379427862198
Validation loss: 2.821251239472746

Epoch: 6| Step: 4
Training loss: 3.925238151371571
Validation loss: 2.8406354762493478

Epoch: 6| Step: 5
Training loss: 2.884579992810793
Validation loss: 2.8361305029441826

Epoch: 6| Step: 6
Training loss: 3.7990170311723013
Validation loss: 2.8220924085556587

Epoch: 6| Step: 7
Training loss: 3.679646809670855
Validation loss: 2.816077866393854

Epoch: 6| Step: 8
Training loss: 3.1631944760823774
Validation loss: 2.810225768872938

Epoch: 6| Step: 9
Training loss: 3.752288882767585
Validation loss: 2.8132983716421323

Epoch: 6| Step: 10
Training loss: 2.2332227176582813
Validation loss: 2.810993307832913

Epoch: 6| Step: 11
Training loss: 3.0929359366846025
Validation loss: 2.813066525297081

Epoch: 6| Step: 12
Training loss: 2.762955147372614
Validation loss: 2.8114839293100906

Epoch: 6| Step: 13
Training loss: 2.140633910223244
Validation loss: 2.820129164960426

Epoch: 43| Step: 0
Training loss: 3.1829424420041477
Validation loss: 2.813318397376572

Epoch: 6| Step: 1
Training loss: 3.215117691994566
Validation loss: 2.8126080892158156

Epoch: 6| Step: 2
Training loss: 2.696314351848533
Validation loss: 2.8132008817500638

Epoch: 6| Step: 3
Training loss: 2.4024475571449093
Validation loss: 2.8133998456799643

Epoch: 6| Step: 4
Training loss: 3.266049590183393
Validation loss: 2.8136866993062073

Epoch: 6| Step: 5
Training loss: 3.5271704410462545
Validation loss: 2.8160442493820774

Epoch: 6| Step: 6
Training loss: 3.3142170324631794
Validation loss: 2.815979938329519

Epoch: 6| Step: 7
Training loss: 2.877177367629143
Validation loss: 2.816191985722247

Epoch: 6| Step: 8
Training loss: 3.067414524967396
Validation loss: 2.8151428074903646

Epoch: 6| Step: 9
Training loss: 3.3684794697746723
Validation loss: 2.8146802721136246

Epoch: 6| Step: 10
Training loss: 2.4546741040870153
Validation loss: 2.810910908775507

Epoch: 6| Step: 11
Training loss: 3.532912276629284
Validation loss: 2.8117095000422743

Epoch: 6| Step: 12
Training loss: 3.4101926052257414
Validation loss: 2.812421716035823

Epoch: 6| Step: 13
Training loss: 3.5478193059536944
Validation loss: 2.809831652838318

Epoch: 44| Step: 0
Training loss: 2.9488698184519366
Validation loss: 2.812434109334127

Epoch: 6| Step: 1
Training loss: 3.2101981618210393
Validation loss: 2.8111555051099595

Epoch: 6| Step: 2
Training loss: 3.318456799905178
Validation loss: 2.809724913031662

Epoch: 6| Step: 3
Training loss: 3.283841807951979
Validation loss: 2.8064678226088158

Epoch: 6| Step: 4
Training loss: 3.111401688160481
Validation loss: 2.8081362708262754

Epoch: 6| Step: 5
Training loss: 3.0543331321186966
Validation loss: 2.807482867908142

Epoch: 6| Step: 6
Training loss: 3.464121849780188
Validation loss: 2.8078977021360974

Epoch: 6| Step: 7
Training loss: 3.570841743759049
Validation loss: 2.807344025251782

Epoch: 6| Step: 8
Training loss: 3.346571685410797
Validation loss: 2.8076009707631244

Epoch: 6| Step: 9
Training loss: 3.5234234253460572
Validation loss: 2.811752661218405

Epoch: 6| Step: 10
Training loss: 3.048983269995572
Validation loss: 2.806161240620766

Epoch: 6| Step: 11
Training loss: 2.506072108930853
Validation loss: 2.804210536250195

Epoch: 6| Step: 12
Training loss: 2.642668255201466
Validation loss: 2.8039287530634707

Epoch: 6| Step: 13
Training loss: 2.1552545212199448
Validation loss: 2.8072738109622497

Epoch: 45| Step: 0
Training loss: 3.533522288350261
Validation loss: 2.809620745932048

Epoch: 6| Step: 1
Training loss: 2.8868893791017367
Validation loss: 2.80972475974561

Epoch: 6| Step: 2
Training loss: 3.1621895980790304
Validation loss: 2.8071039499193238

Epoch: 6| Step: 3
Training loss: 3.182679364468202
Validation loss: 2.8065896593756974

Epoch: 6| Step: 4
Training loss: 2.805305519125064
Validation loss: 2.8109556764206753

Epoch: 6| Step: 5
Training loss: 2.719802302019901
Validation loss: 2.8090040440143222

Epoch: 6| Step: 6
Training loss: 3.0557121256007505
Validation loss: 2.8125301710399606

Epoch: 6| Step: 7
Training loss: 3.623141766151222
Validation loss: 2.807449799971686

Epoch: 6| Step: 8
Training loss: 3.4830013013470933
Validation loss: 2.804677494728308

Epoch: 6| Step: 9
Training loss: 2.7068554489497196
Validation loss: 2.802258902107114

Epoch: 6| Step: 10
Training loss: 2.654379062348579
Validation loss: 2.7988608908619668

Epoch: 6| Step: 11
Training loss: 3.1820857121344353
Validation loss: 2.7960070511436803

Epoch: 6| Step: 12
Training loss: 3.626343839759964
Validation loss: 2.8002419457302707

Epoch: 6| Step: 13
Training loss: 2.839940632213045
Validation loss: 2.7991312962500134

Epoch: 46| Step: 0
Training loss: 3.1808414099409785
Validation loss: 2.7981448429938376

Epoch: 6| Step: 1
Training loss: 2.4199639440640572
Validation loss: 2.798580220669802

Epoch: 6| Step: 2
Training loss: 3.2090521333381954
Validation loss: 2.8030069858973707

Epoch: 6| Step: 3
Training loss: 2.8174208931026974
Validation loss: 2.803767205688087

Epoch: 6| Step: 4
Training loss: 3.849004116310858
Validation loss: 2.812500535971751

Epoch: 6| Step: 5
Training loss: 2.8935387025482364
Validation loss: 2.8064482522335448

Epoch: 6| Step: 6
Training loss: 2.9744243802249803
Validation loss: 2.803835971711222

Epoch: 6| Step: 7
Training loss: 3.2959425633620265
Validation loss: 2.796753365181653

Epoch: 6| Step: 8
Training loss: 3.239192305308761
Validation loss: 2.794167957515228

Epoch: 6| Step: 9
Training loss: 3.4601672415473703
Validation loss: 2.7964479403715545

Epoch: 6| Step: 10
Training loss: 3.2226180750579845
Validation loss: 2.794527842710385

Epoch: 6| Step: 11
Training loss: 3.208135937319642
Validation loss: 2.7933537640143697

Epoch: 6| Step: 12
Training loss: 3.131311375669383
Validation loss: 2.794223293044569

Epoch: 6| Step: 13
Training loss: 2.269706364768202
Validation loss: 2.7941361467966934

Epoch: 47| Step: 0
Training loss: 2.5795198308659715
Validation loss: 2.7926177595046298

Epoch: 6| Step: 1
Training loss: 3.267554922072804
Validation loss: 2.7932963040299597

Epoch: 6| Step: 2
Training loss: 3.685109026058191
Validation loss: 2.7899952980240346

Epoch: 6| Step: 3
Training loss: 2.684973482821495
Validation loss: 2.7897941833956366

Epoch: 6| Step: 4
Training loss: 2.9215920051164486
Validation loss: 2.808635816268054

Epoch: 6| Step: 5
Training loss: 3.110683146817203
Validation loss: 2.827186214276739

Epoch: 6| Step: 6
Training loss: 3.0152801158335056
Validation loss: 2.8219476983384038

Epoch: 6| Step: 7
Training loss: 3.8072682739596777
Validation loss: 2.8180799927011924

Epoch: 6| Step: 8
Training loss: 3.382463749975373
Validation loss: 2.798432576926196

Epoch: 6| Step: 9
Training loss: 3.1894718129906425
Validation loss: 2.7922290476755722

Epoch: 6| Step: 10
Training loss: 3.0591861156100664
Validation loss: 2.7926707610121393

Epoch: 6| Step: 11
Training loss: 2.5357411419618696
Validation loss: 2.7911439723732028

Epoch: 6| Step: 12
Training loss: 2.6144088342398306
Validation loss: 2.8001364270021494

Epoch: 6| Step: 13
Training loss: 4.009080117517218
Validation loss: 2.8106269423959906

Epoch: 48| Step: 0
Training loss: 3.061486835656404
Validation loss: 2.807829178021203

Epoch: 6| Step: 1
Training loss: 3.542715313814923
Validation loss: 2.8073328706044376

Epoch: 6| Step: 2
Training loss: 2.631563609229111
Validation loss: 2.7989382369992177

Epoch: 6| Step: 3
Training loss: 2.719945973392679
Validation loss: 2.7984632358357127

Epoch: 6| Step: 4
Training loss: 2.2393587458172624
Validation loss: 2.799409485293389

Epoch: 6| Step: 5
Training loss: 2.701744035542162
Validation loss: 2.801615868659532

Epoch: 6| Step: 6
Training loss: 3.7426557466949912
Validation loss: 2.79788249441338

Epoch: 6| Step: 7
Training loss: 3.8459013834037266
Validation loss: 2.7994035253968095

Epoch: 6| Step: 8
Training loss: 3.0945049867428027
Validation loss: 2.79180468232029

Epoch: 6| Step: 9
Training loss: 3.483951423113664
Validation loss: 2.7876024968735167

Epoch: 6| Step: 10
Training loss: 3.338510276103319
Validation loss: 2.783801225991315

Epoch: 6| Step: 11
Training loss: 2.2888268880049436
Validation loss: 2.7828208236199976

Epoch: 6| Step: 12
Training loss: 3.5944337940664255
Validation loss: 2.780841461406456

Epoch: 6| Step: 13
Training loss: 2.7405649802792147
Validation loss: 2.7835006401139832

Epoch: 49| Step: 0
Training loss: 3.317384968583712
Validation loss: 2.78281913038381

Epoch: 6| Step: 1
Training loss: 2.8766884199655625
Validation loss: 2.7916772413964166

Epoch: 6| Step: 2
Training loss: 3.8384397468165896
Validation loss: 2.80947187016861

Epoch: 6| Step: 3
Training loss: 3.7963335569529413
Validation loss: 2.7947915179674796

Epoch: 6| Step: 4
Training loss: 3.11619181015949
Validation loss: 2.7844764344528024

Epoch: 6| Step: 5
Training loss: 3.075231906240673
Validation loss: 2.7761097502782994

Epoch: 6| Step: 6
Training loss: 3.0136690269550703
Validation loss: 2.7721709573172597

Epoch: 6| Step: 7
Training loss: 2.2618024477847696
Validation loss: 2.774666373933966

Epoch: 6| Step: 8
Training loss: 2.9771087225402426
Validation loss: 2.773069301291781

Epoch: 6| Step: 9
Training loss: 3.0426318235528087
Validation loss: 2.7729983855522073

Epoch: 6| Step: 10
Training loss: 3.451013255940316
Validation loss: 2.7681983362057583

Epoch: 6| Step: 11
Training loss: 2.3264054470200506
Validation loss: 2.768836109727241

Epoch: 6| Step: 12
Training loss: 3.0874339664208654
Validation loss: 2.7704399699993267

Epoch: 6| Step: 13
Training loss: 2.843352740699689
Validation loss: 2.771847545697163

Epoch: 50| Step: 0
Training loss: 3.3900036220474923
Validation loss: 2.7830407375017887

Epoch: 6| Step: 1
Training loss: 3.535360593843776
Validation loss: 2.785165404936228

Epoch: 6| Step: 2
Training loss: 3.4657908696622024
Validation loss: 2.788670015281675

Epoch: 6| Step: 3
Training loss: 2.6068685223049184
Validation loss: 2.7901168755479753

Epoch: 6| Step: 4
Training loss: 3.107290671579984
Validation loss: 2.7868857153247193

Epoch: 6| Step: 5
Training loss: 3.4081376471145775
Validation loss: 2.788843393731647

Epoch: 6| Step: 6
Training loss: 2.7167152595464685
Validation loss: 2.777258257189508

Epoch: 6| Step: 7
Training loss: 2.702595476974737
Validation loss: 2.7765611596793014

Epoch: 6| Step: 8
Training loss: 3.531486840871841
Validation loss: 2.774017869469256

Epoch: 6| Step: 9
Training loss: 2.841846541662203
Validation loss: 2.771578674092726

Epoch: 6| Step: 10
Training loss: 2.8273149036159704
Validation loss: 2.7656592650898233

Epoch: 6| Step: 11
Training loss: 3.89804631718793
Validation loss: 2.7695117537083016

Epoch: 6| Step: 12
Training loss: 2.240362507914761
Validation loss: 2.7623646570238267

Epoch: 6| Step: 13
Training loss: 2.306143401041972
Validation loss: 2.768443857818327

Epoch: 51| Step: 0
Training loss: 2.8922409901755186
Validation loss: 2.768420255262374

Epoch: 6| Step: 1
Training loss: 2.992674307403475
Validation loss: 2.7695513469026416

Epoch: 6| Step: 2
Training loss: 2.378022930345916
Validation loss: 2.7665289890425617

Epoch: 6| Step: 3
Training loss: 3.5066909866311593
Validation loss: 2.766179427741967

Epoch: 6| Step: 4
Training loss: 3.5114220482192415
Validation loss: 2.7672509091247157

Epoch: 6| Step: 5
Training loss: 2.7428557622287317
Validation loss: 2.7662888875990146

Epoch: 6| Step: 6
Training loss: 3.1450385969792576
Validation loss: 2.7674221778454955

Epoch: 6| Step: 7
Training loss: 3.1155337581455496
Validation loss: 2.76657473710036

Epoch: 6| Step: 8
Training loss: 3.3524938325306075
Validation loss: 2.7683025645144963

Epoch: 6| Step: 9
Training loss: 2.934256690812118
Validation loss: 2.7624012353455063

Epoch: 6| Step: 10
Training loss: 3.521864850927452
Validation loss: 2.7626745709038016

Epoch: 6| Step: 11
Training loss: 2.805462063489534
Validation loss: 2.7631403600166347

Epoch: 6| Step: 12
Training loss: 3.386333228039326
Validation loss: 2.766196226510909

Epoch: 6| Step: 13
Training loss: 2.6876656237289573
Validation loss: 2.7698505134919613

Epoch: 52| Step: 0
Training loss: 2.6488540906917493
Validation loss: 2.77843931264677

Epoch: 6| Step: 1
Training loss: 3.0338180518013185
Validation loss: 2.8139543826888467

Epoch: 6| Step: 2
Training loss: 3.303608891926438
Validation loss: 2.8413519580907973

Epoch: 6| Step: 3
Training loss: 2.2848410364528933
Validation loss: 2.835533501800624

Epoch: 6| Step: 4
Training loss: 2.6826522930390926
Validation loss: 2.820779588516673

Epoch: 6| Step: 5
Training loss: 3.088485708689344
Validation loss: 2.8247887941802894

Epoch: 6| Step: 6
Training loss: 3.1413362371445315
Validation loss: 2.8013218396479975

Epoch: 6| Step: 7
Training loss: 2.9439619696690076
Validation loss: 2.800416796583381

Epoch: 6| Step: 8
Training loss: 3.528260172171165
Validation loss: 2.7790682223157375

Epoch: 6| Step: 9
Training loss: 3.445523002577621
Validation loss: 2.7626899758595576

Epoch: 6| Step: 10
Training loss: 2.9272818899630533
Validation loss: 2.76022877687388

Epoch: 6| Step: 11
Training loss: 3.2741150803424994
Validation loss: 2.764379895085263

Epoch: 6| Step: 12
Training loss: 3.356547598546911
Validation loss: 2.753060895280497

Epoch: 6| Step: 13
Training loss: 3.7784815971004098
Validation loss: 2.7552859812600006

Epoch: 53| Step: 0
Training loss: 3.8736269579460245
Validation loss: 2.7587550038710877

Epoch: 6| Step: 1
Training loss: 3.079905038831193
Validation loss: 2.7611041305196364

Epoch: 6| Step: 2
Training loss: 2.6354374237650378
Validation loss: 2.767641437696254

Epoch: 6| Step: 3
Training loss: 3.205944179056091
Validation loss: 2.7705370491481562

Epoch: 6| Step: 4
Training loss: 2.786283246300218
Validation loss: 2.7773974454280324

Epoch: 6| Step: 5
Training loss: 3.4025312650142414
Validation loss: 2.7723626237234273

Epoch: 6| Step: 6
Training loss: 2.65650220683412
Validation loss: 2.770128933301921

Epoch: 6| Step: 7
Training loss: 3.166857429246358
Validation loss: 2.7756608674399685

Epoch: 6| Step: 8
Training loss: 3.0449140449506444
Validation loss: 2.7773469391526966

Epoch: 6| Step: 9
Training loss: 2.223843168780356
Validation loss: 2.785128659826193

Epoch: 6| Step: 10
Training loss: 4.0750114862011
Validation loss: 2.8060501722877866

Epoch: 6| Step: 11
Training loss: 2.7280203957620266
Validation loss: 2.7682908302627003

Epoch: 6| Step: 12
Training loss: 3.229768578001193
Validation loss: 2.7595571234192726

Epoch: 6| Step: 13
Training loss: 2.5275373193115658
Validation loss: 2.7622569544686

Epoch: 54| Step: 0
Training loss: 3.5944830105452086
Validation loss: 2.761852806687597

Epoch: 6| Step: 1
Training loss: 2.957600587890088
Validation loss: 2.7666773994416523

Epoch: 6| Step: 2
Training loss: 2.95825202364511
Validation loss: 2.766083077055832

Epoch: 6| Step: 3
Training loss: 3.538729822552019
Validation loss: 2.7803226190851484

Epoch: 6| Step: 4
Training loss: 3.0524986600755755
Validation loss: 2.7768307998161466

Epoch: 6| Step: 5
Training loss: 2.9703955657276575
Validation loss: 2.7736257015224384

Epoch: 6| Step: 6
Training loss: 3.115168555828976
Validation loss: 2.7685022595741584

Epoch: 6| Step: 7
Training loss: 2.8486430233683127
Validation loss: 2.7688481981346964

Epoch: 6| Step: 8
Training loss: 3.0029306402437514
Validation loss: 2.76500357182538

Epoch: 6| Step: 9
Training loss: 3.4318698899830777
Validation loss: 2.7670434375984154

Epoch: 6| Step: 10
Training loss: 2.631070157607997
Validation loss: 2.766622711098839

Epoch: 6| Step: 11
Training loss: 3.332449239471591
Validation loss: 2.7605845512715694

Epoch: 6| Step: 12
Training loss: 3.0323748516980773
Validation loss: 2.759117821740673

Epoch: 6| Step: 13
Training loss: 2.4289905983753517
Validation loss: 2.7587330496740234

Epoch: 55| Step: 0
Training loss: 2.585082866587457
Validation loss: 2.759657303574441

Epoch: 6| Step: 1
Training loss: 3.5996700453548245
Validation loss: 2.763513519957767

Epoch: 6| Step: 2
Training loss: 3.320570848175275
Validation loss: 2.7596813563776568

Epoch: 6| Step: 3
Training loss: 2.2264043383724315
Validation loss: 2.767926911337219

Epoch: 6| Step: 4
Training loss: 2.2469974192666893
Validation loss: 2.7769824520596824

Epoch: 6| Step: 5
Training loss: 3.305491248252361
Validation loss: 2.7877013638615926

Epoch: 6| Step: 6
Training loss: 3.7174046751626193
Validation loss: 2.793112798249414

Epoch: 6| Step: 7
Training loss: 3.604407124224882
Validation loss: 2.778731658333122

Epoch: 6| Step: 8
Training loss: 2.9741592116693116
Validation loss: 2.762378537056979

Epoch: 6| Step: 9
Training loss: 2.894506045088894
Validation loss: 2.7596883403092853

Epoch: 6| Step: 10
Training loss: 2.7502833133757343
Validation loss: 2.7545076382540685

Epoch: 6| Step: 11
Training loss: 3.2100190197152405
Validation loss: 2.7546303641817516

Epoch: 6| Step: 12
Training loss: 3.153059905243198
Validation loss: 2.7514657750206237

Epoch: 6| Step: 13
Training loss: 3.3345060828630064
Validation loss: 2.7483513897450464

Epoch: 56| Step: 0
Training loss: 3.352488712118263
Validation loss: 2.746177787698582

Epoch: 6| Step: 1
Training loss: 3.047247135227042
Validation loss: 2.7445763608212492

Epoch: 6| Step: 2
Training loss: 2.9437943246667118
Validation loss: 2.746328901586018

Epoch: 6| Step: 3
Training loss: 3.0890359123911124
Validation loss: 2.7475915058911853

Epoch: 6| Step: 4
Training loss: 3.386840114156897
Validation loss: 2.7458727294056593

Epoch: 6| Step: 5
Training loss: 2.5994200719955516
Validation loss: 2.7441741877079036

Epoch: 6| Step: 6
Training loss: 3.47637774373011
Validation loss: 2.748785017142553

Epoch: 6| Step: 7
Training loss: 2.677690123033099
Validation loss: 2.7438014697034188

Epoch: 6| Step: 8
Training loss: 2.9773340702024655
Validation loss: 2.743356219189635

Epoch: 6| Step: 9
Training loss: 3.2712867244398027
Validation loss: 2.7409911449838678

Epoch: 6| Step: 10
Training loss: 2.880202520455444
Validation loss: 2.743122720231437

Epoch: 6| Step: 11
Training loss: 3.617372050840115
Validation loss: 2.745014659279774

Epoch: 6| Step: 12
Training loss: 2.7730426346052854
Validation loss: 2.7421800835163848

Epoch: 6| Step: 13
Training loss: 2.76696201915751
Validation loss: 2.744873259237378

Epoch: 57| Step: 0
Training loss: 2.847324681699925
Validation loss: 2.746582907239257

Epoch: 6| Step: 1
Training loss: 3.3609592694189794
Validation loss: 2.7465488241906857

Epoch: 6| Step: 2
Training loss: 3.3970025200934124
Validation loss: 2.750725086562841

Epoch: 6| Step: 3
Training loss: 3.0493584317685496
Validation loss: 2.746147912694042

Epoch: 6| Step: 4
Training loss: 3.021209447838723
Validation loss: 2.7448766981279986

Epoch: 6| Step: 5
Training loss: 3.1530293566410594
Validation loss: 2.74513144424521

Epoch: 6| Step: 6
Training loss: 3.2488724146313803
Validation loss: 2.7406829127047465

Epoch: 6| Step: 7
Training loss: 2.7067764404505
Validation loss: 2.7426405116082457

Epoch: 6| Step: 8
Training loss: 2.9454857246598234
Validation loss: 2.741959443069101

Epoch: 6| Step: 9
Training loss: 2.574900141881549
Validation loss: 2.740316078627953

Epoch: 6| Step: 10
Training loss: 2.9425438939064135
Validation loss: 2.7446529371037007

Epoch: 6| Step: 11
Training loss: 2.9140112823812494
Validation loss: 2.758013578308067

Epoch: 6| Step: 12
Training loss: 3.546321203883783
Validation loss: 2.7580242557330106

Epoch: 6| Step: 13
Training loss: 3.2737668402064988
Validation loss: 2.7542951439746157

Epoch: 58| Step: 0
Training loss: 2.172763670097365
Validation loss: 2.7459715892157712

Epoch: 6| Step: 1
Training loss: 3.083516313089389
Validation loss: 2.7446806702827615

Epoch: 6| Step: 2
Training loss: 3.6856039312703963
Validation loss: 2.741920509846412

Epoch: 6| Step: 3
Training loss: 3.084202841424867
Validation loss: 2.736107513926195

Epoch: 6| Step: 4
Training loss: 2.5211583287940598
Validation loss: 2.734369704655971

Epoch: 6| Step: 5
Training loss: 3.0266392829541306
Validation loss: 2.735408065354136

Epoch: 6| Step: 6
Training loss: 3.209709433836372
Validation loss: 2.7285257648570256

Epoch: 6| Step: 7
Training loss: 2.7495774898205863
Validation loss: 2.7336929619192625

Epoch: 6| Step: 8
Training loss: 2.815461866794943
Validation loss: 2.737085917878756

Epoch: 6| Step: 9
Training loss: 3.1375339156669604
Validation loss: 2.7446590196247707

Epoch: 6| Step: 10
Training loss: 3.29734169788999
Validation loss: 2.746929149865551

Epoch: 6| Step: 11
Training loss: 3.485999579669798
Validation loss: 2.7456401559500625

Epoch: 6| Step: 12
Training loss: 3.153186784636094
Validation loss: 2.747143133116836

Epoch: 6| Step: 13
Training loss: 3.498949710751662
Validation loss: 2.7316661443068337

Epoch: 59| Step: 0
Training loss: 3.486168917058053
Validation loss: 2.7345445430948914

Epoch: 6| Step: 1
Training loss: 2.9286596504241427
Validation loss: 2.736968544207178

Epoch: 6| Step: 2
Training loss: 3.876728779718042
Validation loss: 2.731398655066477

Epoch: 6| Step: 3
Training loss: 3.2587084372986315
Validation loss: 2.7347622270533103

Epoch: 6| Step: 4
Training loss: 2.7106343300456306
Validation loss: 2.731572930977507

Epoch: 6| Step: 5
Training loss: 2.9997587106945276
Validation loss: 2.732016000261127

Epoch: 6| Step: 6
Training loss: 2.3834514824274677
Validation loss: 2.73312275375753

Epoch: 6| Step: 7
Training loss: 2.9697914304613877
Validation loss: 2.733239692291505

Epoch: 6| Step: 8
Training loss: 3.094886802119284
Validation loss: 2.7355760852830553

Epoch: 6| Step: 9
Training loss: 3.1233800122312467
Validation loss: 2.736372630698442

Epoch: 6| Step: 10
Training loss: 3.1201508091889596
Validation loss: 2.730548641819895

Epoch: 6| Step: 11
Training loss: 2.7047103907312318
Validation loss: 2.7298089700722867

Epoch: 6| Step: 12
Training loss: 2.9685890555674694
Validation loss: 2.7350187916691353

Epoch: 6| Step: 13
Training loss: 3.161488632903266
Validation loss: 2.7308404432335482

Epoch: 60| Step: 0
Training loss: 3.346928876911562
Validation loss: 2.7361820954301552

Epoch: 6| Step: 1
Training loss: 3.2804660405554125
Validation loss: 2.737852311792491

Epoch: 6| Step: 2
Training loss: 2.871785232419475
Validation loss: 2.747762657411877

Epoch: 6| Step: 3
Training loss: 2.7753103890253663
Validation loss: 2.739083627766348

Epoch: 6| Step: 4
Training loss: 3.10420679326759
Validation loss: 2.733405378851832

Epoch: 6| Step: 5
Training loss: 3.0821703358489145
Validation loss: 2.729504795791229

Epoch: 6| Step: 6
Training loss: 3.34267786253231
Validation loss: 2.7292263882723593

Epoch: 6| Step: 7
Training loss: 3.3046935602227236
Validation loss: 2.7336744460534246

Epoch: 6| Step: 8
Training loss: 2.9807693509842537
Validation loss: 2.7323933263833013

Epoch: 6| Step: 9
Training loss: 2.8674555764918654
Validation loss: 2.725746179027059

Epoch: 6| Step: 10
Training loss: 2.968613470853195
Validation loss: 2.720665422577085

Epoch: 6| Step: 11
Training loss: 2.804643805968404
Validation loss: 2.723142750541047

Epoch: 6| Step: 12
Training loss: 2.932197167255492
Validation loss: 2.7240456855903967

Epoch: 6| Step: 13
Training loss: 3.269003694510626
Validation loss: 2.7219661727280977

Epoch: 61| Step: 0
Training loss: 3.074065809311113
Validation loss: 2.721425294287574

Epoch: 6| Step: 1
Training loss: 3.353894540556152
Validation loss: 2.7204762373259017

Epoch: 6| Step: 2
Training loss: 3.309481703179028
Validation loss: 2.7217237762132567

Epoch: 6| Step: 3
Training loss: 2.6241638123331286
Validation loss: 2.71999975665922

Epoch: 6| Step: 4
Training loss: 2.720596563329519
Validation loss: 2.720473701461015

Epoch: 6| Step: 5
Training loss: 3.138437904510578
Validation loss: 2.722537515995861

Epoch: 6| Step: 6
Training loss: 3.472161067847962
Validation loss: 2.720226934292296

Epoch: 6| Step: 7
Training loss: 3.161505072979806
Validation loss: 2.7201058591611065

Epoch: 6| Step: 8
Training loss: 2.945140884216044
Validation loss: 2.717573102347475

Epoch: 6| Step: 9
Training loss: 3.198926006333085
Validation loss: 2.7224940920834158

Epoch: 6| Step: 10
Training loss: 3.225557110594394
Validation loss: 2.7174150364585388

Epoch: 6| Step: 11
Training loss: 2.1685640634648253
Validation loss: 2.7167876066879284

Epoch: 6| Step: 12
Training loss: 2.725739013134715
Validation loss: 2.7178823491333612

Epoch: 6| Step: 13
Training loss: 3.687827532171679
Validation loss: 2.7199057014588175

Epoch: 62| Step: 0
Training loss: 3.38114708481173
Validation loss: 2.7219633585262697

Epoch: 6| Step: 1
Training loss: 2.2148487017002627
Validation loss: 2.7187339585165406

Epoch: 6| Step: 2
Training loss: 3.415764356110446
Validation loss: 2.7172942827621673

Epoch: 6| Step: 3
Training loss: 3.2315056646203844
Validation loss: 2.7152006417403003

Epoch: 6| Step: 4
Training loss: 3.3419030338193796
Validation loss: 2.715378267518965

Epoch: 6| Step: 5
Training loss: 2.576196677643113
Validation loss: 2.7172084356342325

Epoch: 6| Step: 6
Training loss: 2.5670168076348725
Validation loss: 2.7128548485813337

Epoch: 6| Step: 7
Training loss: 3.1692677573338264
Validation loss: 2.715891837710785

Epoch: 6| Step: 8
Training loss: 3.3772157530539535
Validation loss: 2.7140441137113482

Epoch: 6| Step: 9
Training loss: 2.847732270825983
Validation loss: 2.717930933584293

Epoch: 6| Step: 10
Training loss: 2.3630417379276203
Validation loss: 2.7160936805855007

Epoch: 6| Step: 11
Training loss: 3.51482521284565
Validation loss: 2.7156623267853766

Epoch: 6| Step: 12
Training loss: 3.150327356676387
Validation loss: 2.7149028552976584

Epoch: 6| Step: 13
Training loss: 3.383951959913792
Validation loss: 2.7240533594324354

Epoch: 63| Step: 0
Training loss: 3.1162608210516938
Validation loss: 2.726078720982303

Epoch: 6| Step: 1
Training loss: 2.5369501805449186
Validation loss: 2.7333170898454067

Epoch: 6| Step: 2
Training loss: 2.915788318438829
Validation loss: 2.73736433426372

Epoch: 6| Step: 3
Training loss: 3.4153229156678777
Validation loss: 2.7237725795793004

Epoch: 6| Step: 4
Training loss: 3.06591419718523
Validation loss: 2.723361674400401

Epoch: 6| Step: 5
Training loss: 3.2839867214440885
Validation loss: 2.7207024927358434

Epoch: 6| Step: 6
Training loss: 3.4902301397655475
Validation loss: 2.71981872837207

Epoch: 6| Step: 7
Training loss: 2.9538892937682797
Validation loss: 2.723988601653495

Epoch: 6| Step: 8
Training loss: 2.538645830444905
Validation loss: 2.7403996199467664

Epoch: 6| Step: 9
Training loss: 2.731815208072224
Validation loss: 2.761491158606429

Epoch: 6| Step: 10
Training loss: 3.5320744185076247
Validation loss: 2.767841098947395

Epoch: 6| Step: 11
Training loss: 2.9148939649294667
Validation loss: 2.741279602505937

Epoch: 6| Step: 12
Training loss: 2.7872748964022214
Validation loss: 2.729902791125577

Epoch: 6| Step: 13
Training loss: 3.6339255319879205
Validation loss: 2.7215785106835

Epoch: 64| Step: 0
Training loss: 2.91828510249652
Validation loss: 2.7109960691730577

Epoch: 6| Step: 1
Training loss: 3.15499974028621
Validation loss: 2.720487799935168

Epoch: 6| Step: 2
Training loss: 3.422799878131543
Validation loss: 2.719762196683606

Epoch: 6| Step: 3
Training loss: 2.305282464252534
Validation loss: 2.720646928297945

Epoch: 6| Step: 4
Training loss: 3.049801091446407
Validation loss: 2.725156437083666

Epoch: 6| Step: 5
Training loss: 3.016335833482665
Validation loss: 2.7272235954964037

Epoch: 6| Step: 6
Training loss: 2.957002223891556
Validation loss: 2.719918900863609

Epoch: 6| Step: 7
Training loss: 3.7368531244623076
Validation loss: 2.7242956503017464

Epoch: 6| Step: 8
Training loss: 2.918801716054313
Validation loss: 2.7205424036227295

Epoch: 6| Step: 9
Training loss: 3.257136505761324
Validation loss: 2.715111181012865

Epoch: 6| Step: 10
Training loss: 2.530116828362108
Validation loss: 2.718124634555944

Epoch: 6| Step: 11
Training loss: 3.090718180579578
Validation loss: 2.7148765030227335

Epoch: 6| Step: 12
Training loss: 2.930165813818762
Validation loss: 2.7173909491689914

Epoch: 6| Step: 13
Training loss: 3.299708012465542
Validation loss: 2.7181517692840576

Epoch: 65| Step: 0
Training loss: 3.0063212872021454
Validation loss: 2.728932605868128

Epoch: 6| Step: 1
Training loss: 3.358205618374307
Validation loss: 2.7296391347203084

Epoch: 6| Step: 2
Training loss: 2.709448941639664
Validation loss: 2.7353922565189763

Epoch: 6| Step: 3
Training loss: 3.548789965225493
Validation loss: 2.7362036515421795

Epoch: 6| Step: 4
Training loss: 3.246183355129847
Validation loss: 2.7425773097433157

Epoch: 6| Step: 5
Training loss: 2.30398331568558
Validation loss: 2.7343306511770518

Epoch: 6| Step: 6
Training loss: 3.037076090050727
Validation loss: 2.7207175190992285

Epoch: 6| Step: 7
Training loss: 2.910408900001847
Validation loss: 2.7121820810840016

Epoch: 6| Step: 8
Training loss: 3.281157283381297
Validation loss: 2.713229879820922

Epoch: 6| Step: 9
Training loss: 3.2608873963905096
Validation loss: 2.7101593428003112

Epoch: 6| Step: 10
Training loss: 3.0288151666083163
Validation loss: 2.7084391539340937

Epoch: 6| Step: 11
Training loss: 3.2341211191685675
Validation loss: 2.7118967544861405

Epoch: 6| Step: 12
Training loss: 2.6172051728064694
Validation loss: 2.7088724405958966

Epoch: 6| Step: 13
Training loss: 2.7541842272992656
Validation loss: 2.7060002376897443

Epoch: 66| Step: 0
Training loss: 3.0507190419593924
Validation loss: 2.7114193438368472

Epoch: 6| Step: 1
Training loss: 3.0869741509396116
Validation loss: 2.715963920779936

Epoch: 6| Step: 2
Training loss: 3.4133910472530515
Validation loss: 2.713662177656632

Epoch: 6| Step: 3
Training loss: 2.8775916650192706
Validation loss: 2.715879873237024

Epoch: 6| Step: 4
Training loss: 2.844903732843259
Validation loss: 2.711901253313629

Epoch: 6| Step: 5
Training loss: 3.2423806006595974
Validation loss: 2.714794606032316

Epoch: 6| Step: 6
Training loss: 2.2089135709253904
Validation loss: 2.714067783920031

Epoch: 6| Step: 7
Training loss: 3.1439584530227966
Validation loss: 2.7107750240881674

Epoch: 6| Step: 8
Training loss: 2.818192718294604
Validation loss: 2.7108875400201873

Epoch: 6| Step: 9
Training loss: 3.2423725121346387
Validation loss: 2.7160610583381963

Epoch: 6| Step: 10
Training loss: 3.361756797821668
Validation loss: 2.715362256155009

Epoch: 6| Step: 11
Training loss: 2.6662697695371627
Validation loss: 2.7183015477317265

Epoch: 6| Step: 12
Training loss: 2.889823678785648
Validation loss: 2.713199169588769

Epoch: 6| Step: 13
Training loss: 3.7763106186770323
Validation loss: 2.709114957400192

Epoch: 67| Step: 0
Training loss: 3.2018701095588384
Validation loss: 2.712566173387652

Epoch: 6| Step: 1
Training loss: 2.786482956441781
Validation loss: 2.7098475486818994

Epoch: 6| Step: 2
Training loss: 3.5755283312106534
Validation loss: 2.713961673955307

Epoch: 6| Step: 3
Training loss: 2.9428360542779815
Validation loss: 2.7098093962672363

Epoch: 6| Step: 4
Training loss: 2.9572813464973717
Validation loss: 2.714643421514943

Epoch: 6| Step: 5
Training loss: 3.062945119467635
Validation loss: 2.723725432575444

Epoch: 6| Step: 6
Training loss: 2.804713512076886
Validation loss: 2.7266614459771286

Epoch: 6| Step: 7
Training loss: 3.696414194546391
Validation loss: 2.7315491562408116

Epoch: 6| Step: 8
Training loss: 2.899894903185963
Validation loss: 2.7194035618770678

Epoch: 6| Step: 9
Training loss: 3.1453897192885423
Validation loss: 2.712791033104891

Epoch: 6| Step: 10
Training loss: 2.154573092559554
Validation loss: 2.7026581938195777

Epoch: 6| Step: 11
Training loss: 2.7361688451813095
Validation loss: 2.7000176800992515

Epoch: 6| Step: 12
Training loss: 3.4080367695342666
Validation loss: 2.6998813668792927

Epoch: 6| Step: 13
Training loss: 2.8630434278364927
Validation loss: 2.698531077332626

Epoch: 68| Step: 0
Training loss: 3.457786072476181
Validation loss: 2.6982283043824986

Epoch: 6| Step: 1
Training loss: 3.623389840151874
Validation loss: 2.6995907953863885

Epoch: 6| Step: 2
Training loss: 3.1700998233998603
Validation loss: 2.702562677563612

Epoch: 6| Step: 3
Training loss: 2.738504746223141
Validation loss: 2.700128460558519

Epoch: 6| Step: 4
Training loss: 2.9591928943648758
Validation loss: 2.706766204911164

Epoch: 6| Step: 5
Training loss: 2.843282472514094
Validation loss: 2.7055316221949286

Epoch: 6| Step: 6
Training loss: 2.7324319966083084
Validation loss: 2.710673744785398

Epoch: 6| Step: 7
Training loss: 2.6372496571986757
Validation loss: 2.720624643970988

Epoch: 6| Step: 8
Training loss: 3.2006361805817947
Validation loss: 2.7192018091299963

Epoch: 6| Step: 9
Training loss: 2.8507224321766125
Validation loss: 2.7111311767669832

Epoch: 6| Step: 10
Training loss: 3.212324376630698
Validation loss: 2.707665994620058

Epoch: 6| Step: 11
Training loss: 2.806614460886223
Validation loss: 2.7167494649201918

Epoch: 6| Step: 12
Training loss: 2.962432886321145
Validation loss: 2.7228823007258627

Epoch: 6| Step: 13
Training loss: 3.146484981183989
Validation loss: 2.7154038974007086

Epoch: 69| Step: 0
Training loss: 2.557233748909888
Validation loss: 2.721674940152202

Epoch: 6| Step: 1
Training loss: 3.164920492755524
Validation loss: 2.745189822724579

Epoch: 6| Step: 2
Training loss: 3.235660758127621
Validation loss: 2.7507627665482053

Epoch: 6| Step: 3
Training loss: 3.111940791746046
Validation loss: 2.7097627929807424

Epoch: 6| Step: 4
Training loss: 3.4134307206933534
Validation loss: 2.7009265596577383

Epoch: 6| Step: 5
Training loss: 3.059832442688904
Validation loss: 2.694949816246966

Epoch: 6| Step: 6
Training loss: 2.4210317805023025
Validation loss: 2.698626333493214

Epoch: 6| Step: 7
Training loss: 2.7624546133602346
Validation loss: 2.7028647107851236

Epoch: 6| Step: 8
Training loss: 3.20408057868967
Validation loss: 2.7087223527693505

Epoch: 6| Step: 9
Training loss: 3.187114019024684
Validation loss: 2.72255221490159

Epoch: 6| Step: 10
Training loss: 3.3079869458126634
Validation loss: 2.718951006511928

Epoch: 6| Step: 11
Training loss: 3.5827958051290056
Validation loss: 2.7130585067651563

Epoch: 6| Step: 12
Training loss: 2.5970342594159357
Validation loss: 2.7135623306534096

Epoch: 6| Step: 13
Training loss: 2.775816592789484
Validation loss: 2.712353793066053

Epoch: 70| Step: 0
Training loss: 2.99545945835329
Validation loss: 2.7095140705726743

Epoch: 6| Step: 1
Training loss: 2.4686118944386073
Validation loss: 2.715283015554995

Epoch: 6| Step: 2
Training loss: 2.9786336106242293
Validation loss: 2.7151757114728796

Epoch: 6| Step: 3
Training loss: 3.0365412827814695
Validation loss: 2.7075482905347976

Epoch: 6| Step: 4
Training loss: 3.400834844978842
Validation loss: 2.7026624803708224

Epoch: 6| Step: 5
Training loss: 3.4229058929354297
Validation loss: 2.70635498304772

Epoch: 6| Step: 6
Training loss: 2.9872697302527236
Validation loss: 2.708010791727979

Epoch: 6| Step: 7
Training loss: 3.194050658644185
Validation loss: 2.7098561785004485

Epoch: 6| Step: 8
Training loss: 3.542655283257694
Validation loss: 2.7060814875758266

Epoch: 6| Step: 9
Training loss: 2.667593218846868
Validation loss: 2.7125525563827106

Epoch: 6| Step: 10
Training loss: 2.6197630095131093
Validation loss: 2.709775908395942

Epoch: 6| Step: 11
Training loss: 3.199256160829417
Validation loss: 2.717458093418953

Epoch: 6| Step: 12
Training loss: 2.8340353563535534
Validation loss: 2.7148699458397267

Epoch: 6| Step: 13
Training loss: 2.9025604454666234
Validation loss: 2.7156666409551766

Epoch: 71| Step: 0
Training loss: 2.917527662079073
Validation loss: 2.7082202316660724

Epoch: 6| Step: 1
Training loss: 3.0653892434214747
Validation loss: 2.703200335012698

Epoch: 6| Step: 2
Training loss: 2.944072270014256
Validation loss: 2.697579030182168

Epoch: 6| Step: 3
Training loss: 3.0503560843303092
Validation loss: 2.6978275002277603

Epoch: 6| Step: 4
Training loss: 2.9859113483491426
Validation loss: 2.6970964959571915

Epoch: 6| Step: 5
Training loss: 3.673636805142641
Validation loss: 2.69401857129657

Epoch: 6| Step: 6
Training loss: 2.8554842801069644
Validation loss: 2.6946773057010653

Epoch: 6| Step: 7
Training loss: 2.696098235222472
Validation loss: 2.696986388475843

Epoch: 6| Step: 8
Training loss: 3.1450601263317983
Validation loss: 2.690190295830473

Epoch: 6| Step: 9
Training loss: 3.374846419619427
Validation loss: 2.6924318885070053

Epoch: 6| Step: 10
Training loss: 3.3802160293342585
Validation loss: 2.6969502366307525

Epoch: 6| Step: 11
Training loss: 2.1997952019128704
Validation loss: 2.698614283921914

Epoch: 6| Step: 12
Training loss: 3.536782311200576
Validation loss: 2.693841452814299

Epoch: 6| Step: 13
Training loss: 1.5239789734088236
Validation loss: 2.700421290608468

Epoch: 72| Step: 0
Training loss: 3.2978441883893717
Validation loss: 2.708475521573755

Epoch: 6| Step: 1
Training loss: 2.961238634402491
Validation loss: 2.723929219161006

Epoch: 6| Step: 2
Training loss: 3.124883115489863
Validation loss: 2.741806753153944

Epoch: 6| Step: 3
Training loss: 2.6756892947246875
Validation loss: 2.7417613632295854

Epoch: 6| Step: 4
Training loss: 2.999229173177626
Validation loss: 2.7443045352216426

Epoch: 6| Step: 5
Training loss: 2.4021814803237493
Validation loss: 2.73559304761574

Epoch: 6| Step: 6
Training loss: 3.296132948832895
Validation loss: 2.7204483850883205

Epoch: 6| Step: 7
Training loss: 2.305860628169393
Validation loss: 2.7113694778318957

Epoch: 6| Step: 8
Training loss: 3.417841655003098
Validation loss: 2.703441972349778

Epoch: 6| Step: 9
Training loss: 2.6958838700319125
Validation loss: 2.697644322146826

Epoch: 6| Step: 10
Training loss: 3.3498095216260815
Validation loss: 2.706634098860071

Epoch: 6| Step: 11
Training loss: 3.146571967375611
Validation loss: 2.6973307572742313

Epoch: 6| Step: 12
Training loss: 3.4854357007303665
Validation loss: 2.694702466519843

Epoch: 6| Step: 13
Training loss: 3.302819700396562
Validation loss: 2.693460277410441

Epoch: 73| Step: 0
Training loss: 2.556758123135571
Validation loss: 2.6938726501888093

Epoch: 6| Step: 1
Training loss: 3.4093862671495483
Validation loss: 2.69835925291703

Epoch: 6| Step: 2
Training loss: 3.7128345017703954
Validation loss: 2.701527484981531

Epoch: 6| Step: 3
Training loss: 3.2929418162265955
Validation loss: 2.7003033191511885

Epoch: 6| Step: 4
Training loss: 2.873825828610439
Validation loss: 2.702450506583117

Epoch: 6| Step: 5
Training loss: 2.3618075733599304
Validation loss: 2.6998596802880424

Epoch: 6| Step: 6
Training loss: 2.7267118484123807
Validation loss: 2.7007361758612225

Epoch: 6| Step: 7
Training loss: 3.1397676578744758
Validation loss: 2.7008116339845873

Epoch: 6| Step: 8
Training loss: 2.614778873583626
Validation loss: 2.703946077737827

Epoch: 6| Step: 9
Training loss: 3.137977964918331
Validation loss: 2.694802290255189

Epoch: 6| Step: 10
Training loss: 2.86252757896231
Validation loss: 2.6996697872231707

Epoch: 6| Step: 11
Training loss: 2.9764724677779952
Validation loss: 2.6996134100294995

Epoch: 6| Step: 12
Training loss: 3.462570735057391
Validation loss: 2.6953227105526145

Epoch: 6| Step: 13
Training loss: 2.960951832759258
Validation loss: 2.693207916251382

Epoch: 74| Step: 0
Training loss: 2.394016328741618
Validation loss: 2.6964255107358137

Epoch: 6| Step: 1
Training loss: 3.1371510589000047
Validation loss: 2.698471208725201

Epoch: 6| Step: 2
Training loss: 2.9996712822430514
Validation loss: 2.698698047944063

Epoch: 6| Step: 3
Training loss: 3.1369428162693604
Validation loss: 2.7000931283939416

Epoch: 6| Step: 4
Training loss: 3.526093896265839
Validation loss: 2.7023598439623613

Epoch: 6| Step: 5
Training loss: 2.7422174088023494
Validation loss: 2.7039082791380604

Epoch: 6| Step: 6
Training loss: 2.993103524571322
Validation loss: 2.7007335654562454

Epoch: 6| Step: 7
Training loss: 3.227063451861284
Validation loss: 2.700375067388547

Epoch: 6| Step: 8
Training loss: 2.2782574189976903
Validation loss: 2.697721325936465

Epoch: 6| Step: 9
Training loss: 2.7278948919513786
Validation loss: 2.699344289757149

Epoch: 6| Step: 10
Training loss: 3.0775936074666723
Validation loss: 2.6940079913351482

Epoch: 6| Step: 11
Training loss: 3.612161328765211
Validation loss: 2.6923197182232705

Epoch: 6| Step: 12
Training loss: 3.3358831825569095
Validation loss: 2.6869287267626047

Epoch: 6| Step: 13
Training loss: 2.707913429769763
Validation loss: 2.6875812282625713

Epoch: 75| Step: 0
Training loss: 2.8782347021412886
Validation loss: 2.6864412611366446

Epoch: 6| Step: 1
Training loss: 2.7874119252886636
Validation loss: 2.683518264849739

Epoch: 6| Step: 2
Training loss: 2.753013000634948
Validation loss: 2.692118596418788

Epoch: 6| Step: 3
Training loss: 3.3071297353115194
Validation loss: 2.6874802300846157

Epoch: 6| Step: 4
Training loss: 3.3047250154859356
Validation loss: 2.6866171307939823

Epoch: 6| Step: 5
Training loss: 3.2554404865133795
Validation loss: 2.6803899149535155

Epoch: 6| Step: 6
Training loss: 2.2857421123990633
Validation loss: 2.6821627072854937

Epoch: 6| Step: 7
Training loss: 3.194801047134849
Validation loss: 2.6851865785009177

Epoch: 6| Step: 8
Training loss: 3.088164556852532
Validation loss: 2.6874798475627437

Epoch: 6| Step: 9
Training loss: 3.4309049283416955
Validation loss: 2.694687764113565

Epoch: 6| Step: 10
Training loss: 2.8899507303228975
Validation loss: 2.6912366622326735

Epoch: 6| Step: 11
Training loss: 2.709740278178539
Validation loss: 2.6936357363775523

Epoch: 6| Step: 12
Training loss: 3.4539982998948147
Validation loss: 2.6888129472482034

Epoch: 6| Step: 13
Training loss: 2.4985248982194883
Validation loss: 2.701069168806226

Epoch: 76| Step: 0
Training loss: 2.819269637361239
Validation loss: 2.707304900463323

Epoch: 6| Step: 1
Training loss: 2.13189140803348
Validation loss: 2.7038774175220994

Epoch: 6| Step: 2
Training loss: 3.2381607971981166
Validation loss: 2.7110259863876887

Epoch: 6| Step: 3
Training loss: 3.657974618922759
Validation loss: 2.7018843423695817

Epoch: 6| Step: 4
Training loss: 3.01641740418975
Validation loss: 2.697699641937248

Epoch: 6| Step: 5
Training loss: 2.9514216601977052
Validation loss: 2.6956075850703543

Epoch: 6| Step: 6
Training loss: 3.126141454130851
Validation loss: 2.688160780011444

Epoch: 6| Step: 7
Training loss: 2.9868454220048233
Validation loss: 2.6856274015373844

Epoch: 6| Step: 8
Training loss: 2.5168247560611303
Validation loss: 2.6850399568542658

Epoch: 6| Step: 9
Training loss: 3.2530230620698646
Validation loss: 2.688699902288747

Epoch: 6| Step: 10
Training loss: 2.9397241815951
Validation loss: 2.687130659651235

Epoch: 6| Step: 11
Training loss: 3.567129506773033
Validation loss: 2.6849693771335876

Epoch: 6| Step: 12
Training loss: 2.4924468380874525
Validation loss: 2.6876143659871863

Epoch: 6| Step: 13
Training loss: 3.5809147383258346
Validation loss: 2.685612405076294

Epoch: 77| Step: 0
Training loss: 2.783148042903403
Validation loss: 2.6867662703115403

Epoch: 6| Step: 1
Training loss: 3.428405661208664
Validation loss: 2.6849138036431093

Epoch: 6| Step: 2
Training loss: 3.002626540847001
Validation loss: 2.68709618696159

Epoch: 6| Step: 3
Training loss: 2.8613011277523306
Validation loss: 2.6889310405070557

Epoch: 6| Step: 4
Training loss: 3.6048142985054006
Validation loss: 2.687923440964002

Epoch: 6| Step: 5
Training loss: 3.7761556814234605
Validation loss: 2.690506226019453

Epoch: 6| Step: 6
Training loss: 2.636004858507417
Validation loss: 2.695682415954883

Epoch: 6| Step: 7
Training loss: 2.379160399242192
Validation loss: 2.6936734135936367

Epoch: 6| Step: 8
Training loss: 2.6584051028840654
Validation loss: 2.7066218443563526

Epoch: 6| Step: 9
Training loss: 2.8410005797479903
Validation loss: 2.7139182885261666

Epoch: 6| Step: 10
Training loss: 3.03787671174646
Validation loss: 2.715664616033881

Epoch: 6| Step: 11
Training loss: 3.4395268793554434
Validation loss: 2.728617322526908

Epoch: 6| Step: 12
Training loss: 2.972010057270597
Validation loss: 2.7292852816668534

Epoch: 6| Step: 13
Training loss: 2.361788897997883
Validation loss: 2.7324380040672187

Epoch: 78| Step: 0
Training loss: 3.5345187292041227
Validation loss: 2.7267087514085464

Epoch: 6| Step: 1
Training loss: 2.867228910474543
Validation loss: 2.7222033689693057

Epoch: 6| Step: 2
Training loss: 3.2056820966961346
Validation loss: 2.703132708574844

Epoch: 6| Step: 3
Training loss: 3.1763754801339052
Validation loss: 2.6862851025149856

Epoch: 6| Step: 4
Training loss: 3.028648282435775
Validation loss: 2.6817751915981365

Epoch: 6| Step: 5
Training loss: 3.0453966515678808
Validation loss: 2.678712437185425

Epoch: 6| Step: 6
Training loss: 2.833788349041884
Validation loss: 2.6828628831824406

Epoch: 6| Step: 7
Training loss: 2.174558011451066
Validation loss: 2.6797518694180043

Epoch: 6| Step: 8
Training loss: 2.8935202455868687
Validation loss: 2.677171358008657

Epoch: 6| Step: 9
Training loss: 3.066142349064068
Validation loss: 2.6789619561137763

Epoch: 6| Step: 10
Training loss: 3.4320721862421757
Validation loss: 2.685858719217236

Epoch: 6| Step: 11
Training loss: 3.2939289543860792
Validation loss: 2.687264220570999

Epoch: 6| Step: 12
Training loss: 2.651950902596561
Validation loss: 2.6868081715510543

Epoch: 6| Step: 13
Training loss: 2.8249759740567355
Validation loss: 2.6906340845599788

Epoch: 79| Step: 0
Training loss: 2.656843500589976
Validation loss: 2.692213288152737

Epoch: 6| Step: 1
Training loss: 2.715770886961477
Validation loss: 2.6903041729550976

Epoch: 6| Step: 2
Training loss: 3.6093512199906574
Validation loss: 2.6899206864515084

Epoch: 6| Step: 3
Training loss: 3.0383447422211667
Validation loss: 2.691860180043134

Epoch: 6| Step: 4
Training loss: 3.044028023118346
Validation loss: 2.689759826080038

Epoch: 6| Step: 5
Training loss: 3.2729316994370183
Validation loss: 2.693132734843258

Epoch: 6| Step: 6
Training loss: 3.301262561986524
Validation loss: 2.687427318493544

Epoch: 6| Step: 7
Training loss: 2.261722544928811
Validation loss: 2.6837783040466467

Epoch: 6| Step: 8
Training loss: 2.986687687845276
Validation loss: 2.6863379096784894

Epoch: 6| Step: 9
Training loss: 3.2973817553370566
Validation loss: 2.68078598037201

Epoch: 6| Step: 10
Training loss: 3.106504409165556
Validation loss: 2.6784269487487236

Epoch: 6| Step: 11
Training loss: 3.335301644611305
Validation loss: 2.676833245989472

Epoch: 6| Step: 12
Training loss: 2.806259267405137
Validation loss: 2.6762687107950662

Epoch: 6| Step: 13
Training loss: 2.0900789788030205
Validation loss: 2.67693059680355

Epoch: 80| Step: 0
Training loss: 3.151935158570913
Validation loss: 2.6769617135338466

Epoch: 6| Step: 1
Training loss: 2.209563242704481
Validation loss: 2.675467305560819

Epoch: 6| Step: 2
Training loss: 3.1013300349752915
Validation loss: 2.674826819712088

Epoch: 6| Step: 3
Training loss: 2.5721073087432473
Validation loss: 2.6759357261393886

Epoch: 6| Step: 4
Training loss: 2.907081567072012
Validation loss: 2.6727493727405114

Epoch: 6| Step: 5
Training loss: 2.7352802630947677
Validation loss: 2.679131701754837

Epoch: 6| Step: 6
Training loss: 3.313961066708563
Validation loss: 2.6746975192666587

Epoch: 6| Step: 7
Training loss: 3.5881627975835895
Validation loss: 2.6770654106920766

Epoch: 6| Step: 8
Training loss: 3.1918540089523724
Validation loss: 2.6748384109681793

Epoch: 6| Step: 9
Training loss: 3.0052276205218567
Validation loss: 2.6757604574388605

Epoch: 6| Step: 10
Training loss: 2.4906542614757914
Validation loss: 2.6695537787941084

Epoch: 6| Step: 11
Training loss: 3.7139871052819613
Validation loss: 2.676272517550568

Epoch: 6| Step: 12
Training loss: 2.9208888057242564
Validation loss: 2.6737303074180367

Epoch: 6| Step: 13
Training loss: 2.8822613114244144
Validation loss: 2.677923828454036

Epoch: 81| Step: 0
Training loss: 3.0799511754513356
Validation loss: 2.682275142712366

Epoch: 6| Step: 1
Training loss: 2.518438341723059
Validation loss: 2.690198639925174

Epoch: 6| Step: 2
Training loss: 3.365058101702262
Validation loss: 2.697200445529809

Epoch: 6| Step: 3
Training loss: 3.324084053941545
Validation loss: 2.691967942098641

Epoch: 6| Step: 4
Training loss: 3.244158263046573
Validation loss: 2.690679119306587

Epoch: 6| Step: 5
Training loss: 3.1403741688936204
Validation loss: 2.691334526520477

Epoch: 6| Step: 6
Training loss: 2.867815411489205
Validation loss: 2.6792566029589913

Epoch: 6| Step: 7
Training loss: 2.135942000612486
Validation loss: 2.6831987009633966

Epoch: 6| Step: 8
Training loss: 3.285727361688599
Validation loss: 2.6923010492248505

Epoch: 6| Step: 9
Training loss: 3.6414499289629183
Validation loss: 2.686127089005371

Epoch: 6| Step: 10
Training loss: 2.5399288636105832
Validation loss: 2.695013379748621

Epoch: 6| Step: 11
Training loss: 3.071822321800039
Validation loss: 2.6928033759400023

Epoch: 6| Step: 12
Training loss: 2.3104228408038443
Validation loss: 2.693089464126076

Epoch: 6| Step: 13
Training loss: 3.410818134059324
Validation loss: 2.68473601097063

Epoch: 82| Step: 0
Training loss: 2.486426891633648
Validation loss: 2.6782111461677482

Epoch: 6| Step: 1
Training loss: 2.8529108073629055
Validation loss: 2.676442132037544

Epoch: 6| Step: 2
Training loss: 3.480866586058909
Validation loss: 2.6775661502516868

Epoch: 6| Step: 3
Training loss: 2.578065536275654
Validation loss: 2.672562137642929

Epoch: 6| Step: 4
Training loss: 3.469872370414764
Validation loss: 2.678284908621916

Epoch: 6| Step: 5
Training loss: 2.11794050838788
Validation loss: 2.6737091345508626

Epoch: 6| Step: 6
Training loss: 2.75917948703059
Validation loss: 2.6801063805509795

Epoch: 6| Step: 7
Training loss: 3.5840894803218992
Validation loss: 2.676318303563059

Epoch: 6| Step: 8
Training loss: 2.9581217802099924
Validation loss: 2.6777535285096254

Epoch: 6| Step: 9
Training loss: 2.6630531703498432
Validation loss: 2.6710857066773444

Epoch: 6| Step: 10
Training loss: 3.6772862595423734
Validation loss: 2.6725972237001203

Epoch: 6| Step: 11
Training loss: 3.142253700139446
Validation loss: 2.6699235428549417

Epoch: 6| Step: 12
Training loss: 2.8898317640498936
Validation loss: 2.6692754129670138

Epoch: 6| Step: 13
Training loss: 3.0951738260045416
Validation loss: 2.6667212787030006

Epoch: 83| Step: 0
Training loss: 2.7752858195156915
Validation loss: 2.6689295066940995

Epoch: 6| Step: 1
Training loss: 2.2962425554930443
Validation loss: 2.672435710059299

Epoch: 6| Step: 2
Training loss: 3.15564593587161
Validation loss: 2.6753126327624797

Epoch: 6| Step: 3
Training loss: 2.5864926574944977
Validation loss: 2.6693085205555005

Epoch: 6| Step: 4
Training loss: 2.982502454707118
Validation loss: 2.674247977976214

Epoch: 6| Step: 5
Training loss: 2.941854293358121
Validation loss: 2.6818561105144196

Epoch: 6| Step: 6
Training loss: 3.3611890995726403
Validation loss: 2.6864075611728464

Epoch: 6| Step: 7
Training loss: 2.8325410370913677
Validation loss: 2.6995967515247616

Epoch: 6| Step: 8
Training loss: 2.9540604013144787
Validation loss: 2.7157904716991808

Epoch: 6| Step: 9
Training loss: 3.482716803008257
Validation loss: 2.712142144748215

Epoch: 6| Step: 10
Training loss: 3.597229575039596
Validation loss: 2.701036385978622

Epoch: 6| Step: 11
Training loss: 2.9403289808082462
Validation loss: 2.680933845426427

Epoch: 6| Step: 12
Training loss: 3.105269438867402
Validation loss: 2.6767584886650426

Epoch: 6| Step: 13
Training loss: 2.710179555511777
Validation loss: 2.672750097878483

Epoch: 84| Step: 0
Training loss: 3.8286689216181577
Validation loss: 2.66730879223035

Epoch: 6| Step: 1
Training loss: 3.358930691457424
Validation loss: 2.6683563828601855

Epoch: 6| Step: 2
Training loss: 2.308011415621923
Validation loss: 2.6687193737543127

Epoch: 6| Step: 3
Training loss: 2.522770749279048
Validation loss: 2.668942148464671

Epoch: 6| Step: 4
Training loss: 3.674947938096169
Validation loss: 2.6669663644114396

Epoch: 6| Step: 5
Training loss: 3.4397362111107253
Validation loss: 2.6696440766761054

Epoch: 6| Step: 6
Training loss: 2.25908416522359
Validation loss: 2.6719593264346946

Epoch: 6| Step: 7
Training loss: 2.8478960268565205
Validation loss: 2.6754453429802108

Epoch: 6| Step: 8
Training loss: 2.781322521164318
Validation loss: 2.6746918115198337

Epoch: 6| Step: 9
Training loss: 2.3412305387308274
Validation loss: 2.678941782511982

Epoch: 6| Step: 10
Training loss: 2.6754968199649536
Validation loss: 2.6807321515121454

Epoch: 6| Step: 11
Training loss: 2.841658273574501
Validation loss: 2.682367529763478

Epoch: 6| Step: 12
Training loss: 3.566030125249507
Validation loss: 2.6873383908665684

Epoch: 6| Step: 13
Training loss: 3.020347257947958
Validation loss: 2.6881749544948277

Epoch: 85| Step: 0
Training loss: 2.8367342079390694
Validation loss: 2.698613267438746

Epoch: 6| Step: 1
Training loss: 2.987653918271621
Validation loss: 2.69239423866949

Epoch: 6| Step: 2
Training loss: 3.1901189479355687
Validation loss: 2.681988364559224

Epoch: 6| Step: 3
Training loss: 3.0697869003840528
Validation loss: 2.6780022876615193

Epoch: 6| Step: 4
Training loss: 3.0252210299866418
Validation loss: 2.666962766423291

Epoch: 6| Step: 5
Training loss: 2.814625763214478
Validation loss: 2.6668261190651745

Epoch: 6| Step: 6
Training loss: 3.286796749885979
Validation loss: 2.6667854515917346

Epoch: 6| Step: 7
Training loss: 2.830042742079538
Validation loss: 2.664976345353529

Epoch: 6| Step: 8
Training loss: 2.7285174599861852
Validation loss: 2.6613263338125464

Epoch: 6| Step: 9
Training loss: 3.2991698174502933
Validation loss: 2.66515334864833

Epoch: 6| Step: 10
Training loss: 3.358931827145228
Validation loss: 2.665258420938023

Epoch: 6| Step: 11
Training loss: 2.9562156691382473
Validation loss: 2.6640229287626456

Epoch: 6| Step: 12
Training loss: 2.81700714092548
Validation loss: 2.663963401913683

Epoch: 6| Step: 13
Training loss: 2.6300155317188754
Validation loss: 2.6650362035760304

Epoch: 86| Step: 0
Training loss: 2.914293868056145
Validation loss: 2.6681139672289733

Epoch: 6| Step: 1
Training loss: 3.345039475554448
Validation loss: 2.669097981872779

Epoch: 6| Step: 2
Training loss: 3.1143588662461674
Validation loss: 2.66041537153036

Epoch: 6| Step: 3
Training loss: 2.393509066336446
Validation loss: 2.661173599109726

Epoch: 6| Step: 4
Training loss: 2.947490827628659
Validation loss: 2.663146241556816

Epoch: 6| Step: 5
Training loss: 3.355816611043149
Validation loss: 2.663517691136476

Epoch: 6| Step: 6
Training loss: 2.6845413600544084
Validation loss: 2.6689327984974303

Epoch: 6| Step: 7
Training loss: 2.7980657845017536
Validation loss: 2.683933356279408

Epoch: 6| Step: 8
Training loss: 3.1227726437214414
Validation loss: 2.700731079399124

Epoch: 6| Step: 9
Training loss: 3.544743372098415
Validation loss: 2.6969693582339267

Epoch: 6| Step: 10
Training loss: 2.5187558422541483
Validation loss: 2.6973048558641612

Epoch: 6| Step: 11
Training loss: 2.964864014567604
Validation loss: 2.676764333750351

Epoch: 6| Step: 12
Training loss: 3.3112001567817497
Validation loss: 2.6721611644493772

Epoch: 6| Step: 13
Training loss: 2.817326960018307
Validation loss: 2.664799625647612

Epoch: 87| Step: 0
Training loss: 3.3675851255219547
Validation loss: 2.6619182427141745

Epoch: 6| Step: 1
Training loss: 2.751310383100699
Validation loss: 2.657882418524314

Epoch: 6| Step: 2
Training loss: 2.8657580562139873
Validation loss: 2.6600514532333115

Epoch: 6| Step: 3
Training loss: 2.9525221759373554
Validation loss: 2.660362841929344

Epoch: 6| Step: 4
Training loss: 2.9602687754905856
Validation loss: 2.6636825779952105

Epoch: 6| Step: 5
Training loss: 3.2909723024318414
Validation loss: 2.663294167658855

Epoch: 6| Step: 6
Training loss: 2.842622973785611
Validation loss: 2.660705994351719

Epoch: 6| Step: 7
Training loss: 2.7516841933002056
Validation loss: 2.659118840364691

Epoch: 6| Step: 8
Training loss: 2.56124158523689
Validation loss: 2.6606996514989363

Epoch: 6| Step: 9
Training loss: 2.655997320386385
Validation loss: 2.663152524675042

Epoch: 6| Step: 10
Training loss: 2.5526196805000874
Validation loss: 2.667327180578829

Epoch: 6| Step: 11
Training loss: 3.440020798686826
Validation loss: 2.6705486894302983

Epoch: 6| Step: 12
Training loss: 3.539687078406382
Validation loss: 2.6718572474342497

Epoch: 6| Step: 13
Training loss: 3.4807783646307677
Validation loss: 2.663338151545175

Epoch: 88| Step: 0
Training loss: 3.184269633248573
Validation loss: 2.663948319103838

Epoch: 6| Step: 1
Training loss: 2.698973538291991
Validation loss: 2.671367620836368

Epoch: 6| Step: 2
Training loss: 2.6319675617885894
Validation loss: 2.670497664736625

Epoch: 6| Step: 3
Training loss: 2.414404193682912
Validation loss: 2.6674164158997544

Epoch: 6| Step: 4
Training loss: 3.750916941118521
Validation loss: 2.672074628126125

Epoch: 6| Step: 5
Training loss: 3.082855462511075
Validation loss: 2.670301630299991

Epoch: 6| Step: 6
Training loss: 3.2878051674192452
Validation loss: 2.666154135074494

Epoch: 6| Step: 7
Training loss: 3.3781281562105834
Validation loss: 2.6661167372462047

Epoch: 6| Step: 8
Training loss: 2.5643227769971677
Validation loss: 2.666439445362068

Epoch: 6| Step: 9
Training loss: 3.170624585158225
Validation loss: 2.6636732191903962

Epoch: 6| Step: 10
Training loss: 2.8351076030998867
Validation loss: 2.6673487193518373

Epoch: 6| Step: 11
Training loss: 2.957153962787759
Validation loss: 2.6664774712876014

Epoch: 6| Step: 12
Training loss: 2.9255481825769167
Validation loss: 2.666891456430435

Epoch: 6| Step: 13
Training loss: 2.740409513764522
Validation loss: 2.6729075047532236

Epoch: 89| Step: 0
Training loss: 2.810453899825947
Validation loss: 2.669532935807535

Epoch: 6| Step: 1
Training loss: 3.1283886656409154
Validation loss: 2.660134342670725

Epoch: 6| Step: 2
Training loss: 2.672420066872808
Validation loss: 2.6701333789249504

Epoch: 6| Step: 3
Training loss: 2.428224374512387
Validation loss: 2.6636377509080944

Epoch: 6| Step: 4
Training loss: 2.708408550293913
Validation loss: 2.6654833935836724

Epoch: 6| Step: 5
Training loss: 2.654590941273386
Validation loss: 2.676544082153253

Epoch: 6| Step: 6
Training loss: 3.162994882816465
Validation loss: 2.680573258839267

Epoch: 6| Step: 7
Training loss: 3.322542908953312
Validation loss: 2.687751947084528

Epoch: 6| Step: 8
Training loss: 3.018966009969
Validation loss: 2.6788270835930676

Epoch: 6| Step: 9
Training loss: 3.6961658613467225
Validation loss: 2.69590535562569

Epoch: 6| Step: 10
Training loss: 2.6107091177150616
Validation loss: 2.6904712715550962

Epoch: 6| Step: 11
Training loss: 2.6796488856433394
Validation loss: 2.6753234083557826

Epoch: 6| Step: 12
Training loss: 3.7909416651402186
Validation loss: 2.667674621762904

Epoch: 6| Step: 13
Training loss: 2.8347387381166023
Validation loss: 2.6611875878731186

Epoch: 90| Step: 0
Training loss: 2.270242024933933
Validation loss: 2.662357059539273

Epoch: 6| Step: 1
Training loss: 3.2192943816328436
Validation loss: 2.668921049997189

Epoch: 6| Step: 2
Training loss: 2.3204659048418375
Validation loss: 2.6705155386579857

Epoch: 6| Step: 3
Training loss: 2.838724747566035
Validation loss: 2.66883302825389

Epoch: 6| Step: 4
Training loss: 3.5917257163968093
Validation loss: 2.6678851084530626

Epoch: 6| Step: 5
Training loss: 2.7516127972227205
Validation loss: 2.6699543139675583

Epoch: 6| Step: 6
Training loss: 3.2876736207086785
Validation loss: 2.6691426701945025

Epoch: 6| Step: 7
Training loss: 2.6783276546903116
Validation loss: 2.6668760902581377

Epoch: 6| Step: 8
Training loss: 3.0763814412742767
Validation loss: 2.6674210945062122

Epoch: 6| Step: 9
Training loss: 2.893654055889545
Validation loss: 2.6681632772746795

Epoch: 6| Step: 10
Training loss: 3.307654525595646
Validation loss: 2.66444583933097

Epoch: 6| Step: 11
Training loss: 3.13797234251089
Validation loss: 2.660404493154519

Epoch: 6| Step: 12
Training loss: 3.1563208543737113
Validation loss: 2.6649572010201736

Epoch: 6| Step: 13
Training loss: 3.343649604217112
Validation loss: 2.6572761527248496

Epoch: 91| Step: 0
Training loss: 3.2470946897581183
Validation loss: 2.6607208883859004

Epoch: 6| Step: 1
Training loss: 2.237734529788032
Validation loss: 2.6619372812961473

Epoch: 6| Step: 2
Training loss: 2.6673794230958916
Validation loss: 2.6651890170357926

Epoch: 6| Step: 3
Training loss: 2.94078707922296
Validation loss: 2.6677398566637587

Epoch: 6| Step: 4
Training loss: 2.399193262569155
Validation loss: 2.674177824751701

Epoch: 6| Step: 5
Training loss: 3.5036370589704653
Validation loss: 2.690120364895634

Epoch: 6| Step: 6
Training loss: 3.521540975089371
Validation loss: 2.693249550694221

Epoch: 6| Step: 7
Training loss: 2.3186983087335507
Validation loss: 2.6901151339634746

Epoch: 6| Step: 8
Training loss: 3.5858251350433816
Validation loss: 2.699848722506352

Epoch: 6| Step: 9
Training loss: 2.8674349561130525
Validation loss: 2.6741027678996314

Epoch: 6| Step: 10
Training loss: 2.8064320698490106
Validation loss: 2.656281862785627

Epoch: 6| Step: 11
Training loss: 3.129813797259763
Validation loss: 2.6566828259872275

Epoch: 6| Step: 12
Training loss: 2.946173018565316
Validation loss: 2.6541657447153315

Epoch: 6| Step: 13
Training loss: 3.6567591125245382
Validation loss: 2.6609807873273033

Epoch: 92| Step: 0
Training loss: 2.5067296052024903
Validation loss: 2.658548062426915

Epoch: 6| Step: 1
Training loss: 3.3978139020176106
Validation loss: 2.657013811177838

Epoch: 6| Step: 2
Training loss: 2.845308317027403
Validation loss: 2.6646508460419756

Epoch: 6| Step: 3
Training loss: 2.4861206063977797
Validation loss: 2.665961163265901

Epoch: 6| Step: 4
Training loss: 3.2048838182836348
Validation loss: 2.670598734960455

Epoch: 6| Step: 5
Training loss: 2.957077852433717
Validation loss: 2.6631643746707594

Epoch: 6| Step: 6
Training loss: 3.2098461069075097
Validation loss: 2.663082228376645

Epoch: 6| Step: 7
Training loss: 2.389731545634148
Validation loss: 2.65815736644251

Epoch: 6| Step: 8
Training loss: 2.9753412259380605
Validation loss: 2.6574698757809245

Epoch: 6| Step: 9
Training loss: 2.9683461767907993
Validation loss: 2.6596280029536183

Epoch: 6| Step: 10
Training loss: 3.6165491451266374
Validation loss: 2.6649380036399037

Epoch: 6| Step: 11
Training loss: 3.120479518525496
Validation loss: 2.6619497704009834

Epoch: 6| Step: 12
Training loss: 3.167295109144496
Validation loss: 2.6743730794655964

Epoch: 6| Step: 13
Training loss: 3.2093996695189735
Validation loss: 2.6576321561824345

Epoch: 93| Step: 0
Training loss: 3.1605824865612844
Validation loss: 2.654638027367131

Epoch: 6| Step: 1
Training loss: 3.1172073860777023
Validation loss: 2.648387824618212

Epoch: 6| Step: 2
Training loss: 2.8691040618415675
Validation loss: 2.6521814408318742

Epoch: 6| Step: 3
Training loss: 3.293907095186686
Validation loss: 2.6477935818433394

Epoch: 6| Step: 4
Training loss: 3.095598689583041
Validation loss: 2.648836427734113

Epoch: 6| Step: 5
Training loss: 2.463878509096313
Validation loss: 2.6472442123433506

Epoch: 6| Step: 6
Training loss: 2.878021145581892
Validation loss: 2.6481681907263392

Epoch: 6| Step: 7
Training loss: 2.7023266622196624
Validation loss: 2.6492220418703862

Epoch: 6| Step: 8
Training loss: 3.2881717880275914
Validation loss: 2.652880419811161

Epoch: 6| Step: 9
Training loss: 2.610435407428696
Validation loss: 2.6524318424482964

Epoch: 6| Step: 10
Training loss: 3.0411570570635678
Validation loss: 2.6489285951382717

Epoch: 6| Step: 11
Training loss: 2.8830022155033403
Validation loss: 2.6619727491221568

Epoch: 6| Step: 12
Training loss: 3.3030693114466585
Validation loss: 2.667772504747411

Epoch: 6| Step: 13
Training loss: 3.0614759328950005
Validation loss: 2.670239586883157

Epoch: 94| Step: 0
Training loss: 2.4066356993855313
Validation loss: 2.6810301265091265

Epoch: 6| Step: 1
Training loss: 2.545363650618827
Validation loss: 2.6968627789482755

Epoch: 6| Step: 2
Training loss: 2.6337515856969373
Validation loss: 2.702490335702015

Epoch: 6| Step: 3
Training loss: 3.0432501725209558
Validation loss: 2.7103298038427686

Epoch: 6| Step: 4
Training loss: 2.775791941868305
Validation loss: 2.693021855094467

Epoch: 6| Step: 5
Training loss: 3.302255154701176
Validation loss: 2.6857395277382468

Epoch: 6| Step: 6
Training loss: 3.1318950118181275
Validation loss: 2.6741592869826962

Epoch: 6| Step: 7
Training loss: 2.9528036598689305
Validation loss: 2.67207624186932

Epoch: 6| Step: 8
Training loss: 2.7179902867809598
Validation loss: 2.665272631614736

Epoch: 6| Step: 9
Training loss: 3.2463919345407706
Validation loss: 2.660752094479841

Epoch: 6| Step: 10
Training loss: 2.5653988328464297
Validation loss: 2.66306425450587

Epoch: 6| Step: 11
Training loss: 3.839048906798279
Validation loss: 2.665097980469282

Epoch: 6| Step: 12
Training loss: 3.465242416687279
Validation loss: 2.6618558252390354

Epoch: 6| Step: 13
Training loss: 3.0280894683863364
Validation loss: 2.656044608372323

Epoch: 95| Step: 0
Training loss: 2.7428400290329953
Validation loss: 2.656560230416064

Epoch: 6| Step: 1
Training loss: 2.972477069121415
Validation loss: 2.653144717056564

Epoch: 6| Step: 2
Training loss: 2.5460901279663655
Validation loss: 2.6546735482924

Epoch: 6| Step: 3
Training loss: 3.1175668433027925
Validation loss: 2.655506550682871

Epoch: 6| Step: 4
Training loss: 2.9043720699957984
Validation loss: 2.6632709616163335

Epoch: 6| Step: 5
Training loss: 2.8378274468191194
Validation loss: 2.658382952570326

Epoch: 6| Step: 6
Training loss: 2.8876677361191736
Validation loss: 2.662991789821462

Epoch: 6| Step: 7
Training loss: 3.076338196148551
Validation loss: 2.6665840075228315

Epoch: 6| Step: 8
Training loss: 3.1325750475004837
Validation loss: 2.6739586218128975

Epoch: 6| Step: 9
Training loss: 2.944644761219151
Validation loss: 2.6743764431733013

Epoch: 6| Step: 10
Training loss: 2.8942890760913023
Validation loss: 2.6696453663493513

Epoch: 6| Step: 11
Training loss: 3.5800941079839625
Validation loss: 2.6805079728295462

Epoch: 6| Step: 12
Training loss: 3.0636494873193874
Validation loss: 2.6738779298602844

Epoch: 6| Step: 13
Training loss: 3.1427099794141795
Validation loss: 2.6729128029301377

Epoch: 96| Step: 0
Training loss: 2.3741176371556887
Validation loss: 2.668439362105511

Epoch: 6| Step: 1
Training loss: 3.2044125830074113
Validation loss: 2.6727358607751595

Epoch: 6| Step: 2
Training loss: 3.007232530834095
Validation loss: 2.672442344500143

Epoch: 6| Step: 3
Training loss: 2.912323870265356
Validation loss: 2.67302839341572

Epoch: 6| Step: 4
Training loss: 3.2712386218329716
Validation loss: 2.6740694243878305

Epoch: 6| Step: 5
Training loss: 2.7966909507845945
Validation loss: 2.657702978620036

Epoch: 6| Step: 6
Training loss: 3.07104576614845
Validation loss: 2.6567734175477753

Epoch: 6| Step: 7
Training loss: 2.781204737605714
Validation loss: 2.6601769332367162

Epoch: 6| Step: 8
Training loss: 3.019496192087071
Validation loss: 2.661386058355723

Epoch: 6| Step: 9
Training loss: 2.7881564851243144
Validation loss: 2.6613092314296067

Epoch: 6| Step: 10
Training loss: 3.152935591756381
Validation loss: 2.660615528019904

Epoch: 6| Step: 11
Training loss: 3.0767222659899893
Validation loss: 2.662034876388934

Epoch: 6| Step: 12
Training loss: 3.1790493411458622
Validation loss: 2.6671907691164907

Epoch: 6| Step: 13
Training loss: 2.9959810675925587
Validation loss: 2.6604589780589323

Epoch: 97| Step: 0
Training loss: 2.845794613427245
Validation loss: 2.6645664076165843

Epoch: 6| Step: 1
Training loss: 2.8895423305016217
Validation loss: 2.659083556216785

Epoch: 6| Step: 2
Training loss: 3.159156594051993
Validation loss: 2.65484779500368

Epoch: 6| Step: 3
Training loss: 3.1858136072994134
Validation loss: 2.6488730262193547

Epoch: 6| Step: 4
Training loss: 3.443150263520693
Validation loss: 2.651426887886305

Epoch: 6| Step: 5
Training loss: 3.2255414404760816
Validation loss: 2.6473982561510665

Epoch: 6| Step: 6
Training loss: 2.302498298172213
Validation loss: 2.654559203054065

Epoch: 6| Step: 7
Training loss: 3.5339656953728027
Validation loss: 2.652653829362662

Epoch: 6| Step: 8
Training loss: 3.0711452917462463
Validation loss: 2.6504521938572356

Epoch: 6| Step: 9
Training loss: 1.9756398818249925
Validation loss: 2.6535772592718225

Epoch: 6| Step: 10
Training loss: 3.1069235794790875
Validation loss: 2.651450481854042

Epoch: 6| Step: 11
Training loss: 2.7779977192165606
Validation loss: 2.6557379927047085

Epoch: 6| Step: 12
Training loss: 2.838307296923217
Validation loss: 2.657809907085875

Epoch: 6| Step: 13
Training loss: 3.0019536015268815
Validation loss: 2.678327736050578

Epoch: 98| Step: 0
Training loss: 2.5325295310826417
Validation loss: 2.6798953116838176

Epoch: 6| Step: 1
Training loss: 2.732126063162571
Validation loss: 2.67754495601389

Epoch: 6| Step: 2
Training loss: 2.7321445632487578
Validation loss: 2.6930732212449304

Epoch: 6| Step: 3
Training loss: 2.679782520978374
Validation loss: 2.696842940781641

Epoch: 6| Step: 4
Training loss: 3.4756907538107424
Validation loss: 2.6992565439867287

Epoch: 6| Step: 5
Training loss: 2.4957167172028227
Validation loss: 2.6888427461155873

Epoch: 6| Step: 6
Training loss: 3.0322521951915773
Validation loss: 2.6874410551741788

Epoch: 6| Step: 7
Training loss: 2.9519441049964747
Validation loss: 2.710043520716277

Epoch: 6| Step: 8
Training loss: 2.8095749797656318
Validation loss: 2.7020745788544227

Epoch: 6| Step: 9
Training loss: 3.6001850398510062
Validation loss: 2.7011292892381857

Epoch: 6| Step: 10
Training loss: 3.0942052641075164
Validation loss: 2.6885167950680917

Epoch: 6| Step: 11
Training loss: 2.9095933613027793
Validation loss: 2.665409449026347

Epoch: 6| Step: 12
Training loss: 3.2128662850521805
Validation loss: 2.6490357035851

Epoch: 6| Step: 13
Training loss: 3.4757659342439733
Validation loss: 2.6475155299736914

Epoch: 99| Step: 0
Training loss: 3.1252575577456163
Validation loss: 2.650413282211735

Epoch: 6| Step: 1
Training loss: 2.3334134860123057
Validation loss: 2.6540755133027165

Epoch: 6| Step: 2
Training loss: 3.0780334459040573
Validation loss: 2.6599798567616246

Epoch: 6| Step: 3
Training loss: 2.862411304415732
Validation loss: 2.666900665517226

Epoch: 6| Step: 4
Training loss: 3.6331500809212445
Validation loss: 2.6838172219741487

Epoch: 6| Step: 5
Training loss: 2.491912252598815
Validation loss: 2.681958035488925

Epoch: 6| Step: 6
Training loss: 3.019091575363306
Validation loss: 2.6697340815052693

Epoch: 6| Step: 7
Training loss: 3.3657896322152454
Validation loss: 2.6624738420134224

Epoch: 6| Step: 8
Training loss: 3.2948606583765687
Validation loss: 2.6599739902142834

Epoch: 6| Step: 9
Training loss: 2.679902360048461
Validation loss: 2.6462648243516758

Epoch: 6| Step: 10
Training loss: 2.6909176586457586
Validation loss: 2.64589554630615

Epoch: 6| Step: 11
Training loss: 3.2453724120500422
Validation loss: 2.6436496631506117

Epoch: 6| Step: 12
Training loss: 2.8841627313571796
Validation loss: 2.641342253048229

Epoch: 6| Step: 13
Training loss: 2.6855676490673783
Validation loss: 2.63996981114727

Epoch: 100| Step: 0
Training loss: 3.325133075775863
Validation loss: 2.640735423674876

Epoch: 6| Step: 1
Training loss: 2.9687202853673273
Validation loss: 2.638325957779379

Epoch: 6| Step: 2
Training loss: 3.3962485092771963
Validation loss: 2.639890575077105

Epoch: 6| Step: 3
Training loss: 3.0603349779071496
Validation loss: 2.645188356101494

Epoch: 6| Step: 4
Training loss: 2.5020584215315758
Validation loss: 2.6567641617777316

Epoch: 6| Step: 5
Training loss: 3.0210977022092393
Validation loss: 2.684081272401072

Epoch: 6| Step: 6
Training loss: 3.1813876318996868
Validation loss: 2.7149679780401668

Epoch: 6| Step: 7
Training loss: 3.132085777715822
Validation loss: 2.7413246768337762

Epoch: 6| Step: 8
Training loss: 2.783877984930239
Validation loss: 2.727368513358362

Epoch: 6| Step: 9
Training loss: 2.7156289261942095
Validation loss: 2.707211946822022

Epoch: 6| Step: 10
Training loss: 3.197614293087645
Validation loss: 2.69181700220332

Epoch: 6| Step: 11
Training loss: 3.052698604986772
Validation loss: 2.665062169457645

Epoch: 6| Step: 12
Training loss: 2.7938983783959843
Validation loss: 2.6805160314526666

Epoch: 6| Step: 13
Training loss: 2.6172940816101176
Validation loss: 2.6674735812190327

Epoch: 101| Step: 0
Training loss: 2.6175589682158837
Validation loss: 2.65829659650458

Epoch: 6| Step: 1
Training loss: 2.9365502303296336
Validation loss: 2.657145774403628

Epoch: 6| Step: 2
Training loss: 3.219041385238837
Validation loss: 2.654889872653343

Epoch: 6| Step: 3
Training loss: 3.473526698591804
Validation loss: 2.645094659806724

Epoch: 6| Step: 4
Training loss: 3.342302811369093
Validation loss: 2.6518615727057147

Epoch: 6| Step: 5
Training loss: 2.7795247073694007
Validation loss: 2.648297942314159

Epoch: 6| Step: 6
Training loss: 2.9025404030470963
Validation loss: 2.656119304918597

Epoch: 6| Step: 7
Training loss: 3.1355692846386813
Validation loss: 2.65320035014162

Epoch: 6| Step: 8
Training loss: 2.4979636481933265
Validation loss: 2.664503764975714

Epoch: 6| Step: 9
Training loss: 3.007634145229485
Validation loss: 2.6663462256616004

Epoch: 6| Step: 10
Training loss: 3.30421130489745
Validation loss: 2.6466406463472643

Epoch: 6| Step: 11
Training loss: 2.8277515143686442
Validation loss: 2.648041143538328

Epoch: 6| Step: 12
Training loss: 3.1248290968892403
Validation loss: 2.646836552244625

Epoch: 6| Step: 13
Training loss: 2.3486504758301496
Validation loss: 2.649859847806724

Epoch: 102| Step: 0
Training loss: 2.6013586749170914
Validation loss: 2.653086699944629

Epoch: 6| Step: 1
Training loss: 3.386128480856447
Validation loss: 2.6512492427979657

Epoch: 6| Step: 2
Training loss: 2.8621039370597994
Validation loss: 2.6482216263081932

Epoch: 6| Step: 3
Training loss: 3.2554205659981075
Validation loss: 2.646751915500618

Epoch: 6| Step: 4
Training loss: 3.8401180569064546
Validation loss: 2.641868925000552

Epoch: 6| Step: 5
Training loss: 3.4275631245059723
Validation loss: 2.6419713204078974

Epoch: 6| Step: 6
Training loss: 2.884641155225618
Validation loss: 2.640622413664569

Epoch: 6| Step: 7
Training loss: 2.5203980839879283
Validation loss: 2.6455326870370515

Epoch: 6| Step: 8
Training loss: 2.826054779558498
Validation loss: 2.64764758753172

Epoch: 6| Step: 9
Training loss: 2.752190584397799
Validation loss: 2.654371643908795

Epoch: 6| Step: 10
Training loss: 3.049900528583339
Validation loss: 2.6543731756961333

Epoch: 6| Step: 11
Training loss: 2.7017164143479473
Validation loss: 2.672253762061614

Epoch: 6| Step: 12
Training loss: 2.4849683904652244
Validation loss: 2.6814694664226857

Epoch: 6| Step: 13
Training loss: 2.6624148467152
Validation loss: 2.678348312461114

Epoch: 103| Step: 0
Training loss: 3.1185556721967975
Validation loss: 2.684817460357472

Epoch: 6| Step: 1
Training loss: 3.291443314197614
Validation loss: 2.6780707870515594

Epoch: 6| Step: 2
Training loss: 3.322838538197084
Validation loss: 2.6680391462377457

Epoch: 6| Step: 3
Training loss: 3.435490246122258
Validation loss: 2.658850542595332

Epoch: 6| Step: 4
Training loss: 2.759690204731779
Validation loss: 2.6452356628679277

Epoch: 6| Step: 5
Training loss: 2.483519208808835
Validation loss: 2.6421903652505687

Epoch: 6| Step: 6
Training loss: 3.212337884634584
Validation loss: 2.6339733317519167

Epoch: 6| Step: 7
Training loss: 2.8436973483063643
Validation loss: 2.6341321205132546

Epoch: 6| Step: 8
Training loss: 2.6321089622413676
Validation loss: 2.633240360316851

Epoch: 6| Step: 9
Training loss: 2.7405313125656106
Validation loss: 2.6354657746201036

Epoch: 6| Step: 10
Training loss: 3.3190522079660183
Validation loss: 2.632973888357489

Epoch: 6| Step: 11
Training loss: 2.953796471848887
Validation loss: 2.640782236474923

Epoch: 6| Step: 12
Training loss: 3.098204209494666
Validation loss: 2.6428328393925793

Epoch: 6| Step: 13
Training loss: 1.9476895803452607
Validation loss: 2.636114337881031

Epoch: 104| Step: 0
Training loss: 2.9335163781824116
Validation loss: 2.638021211689209

Epoch: 6| Step: 1
Training loss: 3.064102998939551
Validation loss: 2.6352395711495977

Epoch: 6| Step: 2
Training loss: 3.6885366760639573
Validation loss: 2.6369280677273395

Epoch: 6| Step: 3
Training loss: 2.7030893665236237
Validation loss: 2.6373674065925536

Epoch: 6| Step: 4
Training loss: 3.040123918416987
Validation loss: 2.634622480371581

Epoch: 6| Step: 5
Training loss: 2.737086842333799
Validation loss: 2.6339760521180606

Epoch: 6| Step: 6
Training loss: 3.0630800904486533
Validation loss: 2.6364840573131896

Epoch: 6| Step: 7
Training loss: 2.9374756507676008
Validation loss: 2.6344533861598687

Epoch: 6| Step: 8
Training loss: 2.799849478899212
Validation loss: 2.636233580148442

Epoch: 6| Step: 9
Training loss: 2.588936441100308
Validation loss: 2.6333380274135654

Epoch: 6| Step: 10
Training loss: 2.915112671809318
Validation loss: 2.636184387629055

Epoch: 6| Step: 11
Training loss: 3.455197364039121
Validation loss: 2.6387658838757106

Epoch: 6| Step: 12
Training loss: 3.0164480716757267
Validation loss: 2.636934656367771

Epoch: 6| Step: 13
Training loss: 2.2230876376594684
Validation loss: 2.636957643078816

Epoch: 105| Step: 0
Training loss: 3.182113134659109
Validation loss: 2.6376845143969647

Epoch: 6| Step: 1
Training loss: 2.441638465518855
Validation loss: 2.641065031395737

Epoch: 6| Step: 2
Training loss: 2.882130281107256
Validation loss: 2.6392523220796305

Epoch: 6| Step: 3
Training loss: 2.836975075989761
Validation loss: 2.635845132148619

Epoch: 6| Step: 4
Training loss: 2.818219028713867
Validation loss: 2.6420140281399775

Epoch: 6| Step: 5
Training loss: 3.2201022668556334
Validation loss: 2.6335134317171223

Epoch: 6| Step: 6
Training loss: 2.3622556368279843
Validation loss: 2.6359286116049545

Epoch: 6| Step: 7
Training loss: 2.7207047023618003
Validation loss: 2.6400597361657887

Epoch: 6| Step: 8
Training loss: 2.794048308761084
Validation loss: 2.633554441651032

Epoch: 6| Step: 9
Training loss: 3.0940884491718768
Validation loss: 2.635023581347214

Epoch: 6| Step: 10
Training loss: 3.0842804528058174
Validation loss: 2.6328372656562156

Epoch: 6| Step: 11
Training loss: 3.2827169862893686
Validation loss: 2.6301953692600515

Epoch: 6| Step: 12
Training loss: 3.6883608572913027
Validation loss: 2.63555985505621

Epoch: 6| Step: 13
Training loss: 3.058292690772759
Validation loss: 2.634132852389031

Epoch: 106| Step: 0
Training loss: 3.363226523491308
Validation loss: 2.6353058823129567

Epoch: 6| Step: 1
Training loss: 2.698216562774179
Validation loss: 2.630694815474505

Epoch: 6| Step: 2
Training loss: 2.998038922526098
Validation loss: 2.636854234357045

Epoch: 6| Step: 3
Training loss: 2.81202397026709
Validation loss: 2.632359998412218

Epoch: 6| Step: 4
Training loss: 2.5923833348832632
Validation loss: 2.631416112862904

Epoch: 6| Step: 5
Training loss: 3.0855193422187543
Validation loss: 2.636019981581792

Epoch: 6| Step: 6
Training loss: 3.129939486128863
Validation loss: 2.6393636443382764

Epoch: 6| Step: 7
Training loss: 2.4303552623752314
Validation loss: 2.645008601669703

Epoch: 6| Step: 8
Training loss: 3.0918943446417657
Validation loss: 2.63500554645393

Epoch: 6| Step: 9
Training loss: 2.678428598864698
Validation loss: 2.6325443024474615

Epoch: 6| Step: 10
Training loss: 3.300605290705658
Validation loss: 2.638305404466858

Epoch: 6| Step: 11
Training loss: 2.739979868766173
Validation loss: 2.640157147595392

Epoch: 6| Step: 12
Training loss: 2.998343487210457
Validation loss: 2.6356406988267933

Epoch: 6| Step: 13
Training loss: 3.7952160134738344
Validation loss: 2.6388779999602403

Epoch: 107| Step: 0
Training loss: 3.03932671268738
Validation loss: 2.6353784983410464

Epoch: 6| Step: 1
Training loss: 3.0514482655509636
Validation loss: 2.636476884122575

Epoch: 6| Step: 2
Training loss: 2.731219929195696
Validation loss: 2.6404533604712017

Epoch: 6| Step: 3
Training loss: 2.5343297425167335
Validation loss: 2.634963987993666

Epoch: 6| Step: 4
Training loss: 2.72931320340601
Validation loss: 2.6448071807023883

Epoch: 6| Step: 5
Training loss: 3.346382032147275
Validation loss: 2.639260456161173

Epoch: 6| Step: 6
Training loss: 3.4967723677968374
Validation loss: 2.644382293694448

Epoch: 6| Step: 7
Training loss: 3.239018152782595
Validation loss: 2.635057368347011

Epoch: 6| Step: 8
Training loss: 3.1303658765774065
Validation loss: 2.6355384718420884

Epoch: 6| Step: 9
Training loss: 2.6434614308103006
Validation loss: 2.6357436561930685

Epoch: 6| Step: 10
Training loss: 2.9679882477684445
Validation loss: 2.640233898671203

Epoch: 6| Step: 11
Training loss: 2.720941822017463
Validation loss: 2.6340135130747306

Epoch: 6| Step: 12
Training loss: 2.8437164640021195
Validation loss: 2.633731580718971

Epoch: 6| Step: 13
Training loss: 2.7570408938491364
Validation loss: 2.6309292148457066

Epoch: 108| Step: 0
Training loss: 2.3836152272364917
Validation loss: 2.6288053653540606

Epoch: 6| Step: 1
Training loss: 3.0385867337265373
Validation loss: 2.631630237076287

Epoch: 6| Step: 2
Training loss: 3.456854829758675
Validation loss: 2.632294844071185

Epoch: 6| Step: 3
Training loss: 2.9627615511396006
Validation loss: 2.641062844442869

Epoch: 6| Step: 4
Training loss: 3.3715303741630165
Validation loss: 2.6447306195359492

Epoch: 6| Step: 5
Training loss: 2.4252304950775607
Validation loss: 2.650729911568688

Epoch: 6| Step: 6
Training loss: 3.026450693628488
Validation loss: 2.6565191992686916

Epoch: 6| Step: 7
Training loss: 2.8809902976076938
Validation loss: 2.6488723739064715

Epoch: 6| Step: 8
Training loss: 3.375360822816444
Validation loss: 2.64746485539816

Epoch: 6| Step: 9
Training loss: 2.766882400451097
Validation loss: 2.645664302383345

Epoch: 6| Step: 10
Training loss: 2.7001969018417564
Validation loss: 2.6474980701491133

Epoch: 6| Step: 11
Training loss: 2.6077420727434957
Validation loss: 2.637431408195758

Epoch: 6| Step: 12
Training loss: 3.33063265750382
Validation loss: 2.630843448542748

Epoch: 6| Step: 13
Training loss: 2.810037764298887
Validation loss: 2.6289103618173333

Epoch: 109| Step: 0
Training loss: 3.0675884713469985
Validation loss: 2.623675606552159

Epoch: 6| Step: 1
Training loss: 2.4716127432533406
Validation loss: 2.6245726077778353

Epoch: 6| Step: 2
Training loss: 2.7657648255944696
Validation loss: 2.6300774956692123

Epoch: 6| Step: 3
Training loss: 2.910491637290811
Validation loss: 2.6265914300198405

Epoch: 6| Step: 4
Training loss: 2.5151091810913613
Validation loss: 2.6260043594554343

Epoch: 6| Step: 5
Training loss: 2.9601805028780155
Validation loss: 2.6321199828843116

Epoch: 6| Step: 6
Training loss: 2.7696076935412797
Validation loss: 2.634446018167587

Epoch: 6| Step: 7
Training loss: 3.0691372318256347
Validation loss: 2.6365711151684597

Epoch: 6| Step: 8
Training loss: 3.300662789109501
Validation loss: 2.630636959103757

Epoch: 6| Step: 9
Training loss: 2.748466150634361
Validation loss: 2.6270586761032835

Epoch: 6| Step: 10
Training loss: 3.0631615060539024
Validation loss: 2.6311167633484316

Epoch: 6| Step: 11
Training loss: 3.359501326204025
Validation loss: 2.6240302021594255

Epoch: 6| Step: 12
Training loss: 3.3114029129221025
Validation loss: 2.6252134786154055

Epoch: 6| Step: 13
Training loss: 2.964440842343032
Validation loss: 2.62931715809851

Epoch: 110| Step: 0
Training loss: 3.0061693335355626
Validation loss: 2.6272168094048696

Epoch: 6| Step: 1
Training loss: 2.6757429356860003
Validation loss: 2.630820465902514

Epoch: 6| Step: 2
Training loss: 2.591810029491627
Validation loss: 2.624790206705919

Epoch: 6| Step: 3
Training loss: 2.7466115015780055
Validation loss: 2.6316893896255182

Epoch: 6| Step: 4
Training loss: 2.8474331992119866
Validation loss: 2.6348377022928062

Epoch: 6| Step: 5
Training loss: 3.2167000770480842
Validation loss: 2.6326349090870025

Epoch: 6| Step: 6
Training loss: 3.1777397770006326
Validation loss: 2.6509695012857133

Epoch: 6| Step: 7
Training loss: 2.610253191977132
Validation loss: 2.6514611591141795

Epoch: 6| Step: 8
Training loss: 3.4878344959925416
Validation loss: 2.6655217505349116

Epoch: 6| Step: 9
Training loss: 3.2328402061252337
Validation loss: 2.65226889492625

Epoch: 6| Step: 10
Training loss: 3.51464789481449
Validation loss: 2.6394005606640865

Epoch: 6| Step: 11
Training loss: 2.407251125001461
Validation loss: 2.6294216939205426

Epoch: 6| Step: 12
Training loss: 2.9291213645705754
Validation loss: 2.6300530412889223

Epoch: 6| Step: 13
Training loss: 2.598408663206034
Validation loss: 2.6264411458771306

Epoch: 111| Step: 0
Training loss: 3.3443725576803534
Validation loss: 2.6234713438104316

Epoch: 6| Step: 1
Training loss: 2.7731111576267025
Validation loss: 2.6207600096487202

Epoch: 6| Step: 2
Training loss: 3.0828856237664857
Validation loss: 2.6175463055059502

Epoch: 6| Step: 3
Training loss: 3.5195889653460037
Validation loss: 2.615994163526492

Epoch: 6| Step: 4
Training loss: 2.886986003888053
Validation loss: 2.6186529835214287

Epoch: 6| Step: 5
Training loss: 2.8267803894714376
Validation loss: 2.6172106846367287

Epoch: 6| Step: 6
Training loss: 2.7582060881554065
Validation loss: 2.616638026979826

Epoch: 6| Step: 7
Training loss: 2.3620543771116127
Validation loss: 2.615937019852305

Epoch: 6| Step: 8
Training loss: 3.094279850756845
Validation loss: 2.6197766126809614

Epoch: 6| Step: 9
Training loss: 2.7616801603176
Validation loss: 2.6216508514070376

Epoch: 6| Step: 10
Training loss: 2.6157869605597983
Validation loss: 2.6175765944415907

Epoch: 6| Step: 11
Training loss: 2.6989549875085297
Validation loss: 2.6171018456352346

Epoch: 6| Step: 12
Training loss: 2.960943941698138
Validation loss: 2.6214407969270477

Epoch: 6| Step: 13
Training loss: 4.084027108142641
Validation loss: 2.619028713321623

Epoch: 112| Step: 0
Training loss: 2.91643732168311
Validation loss: 2.6205115044419642

Epoch: 6| Step: 1
Training loss: 3.520020716562864
Validation loss: 2.620089123100177

Epoch: 6| Step: 2
Training loss: 2.7255822635791254
Validation loss: 2.6184636288304204

Epoch: 6| Step: 3
Training loss: 3.2596111500995812
Validation loss: 2.620067485934946

Epoch: 6| Step: 4
Training loss: 3.330315813548131
Validation loss: 2.627784185168965

Epoch: 6| Step: 5
Training loss: 3.0811611634731815
Validation loss: 2.6183357130941554

Epoch: 6| Step: 6
Training loss: 3.1456816849356284
Validation loss: 2.615768612702965

Epoch: 6| Step: 7
Training loss: 3.0368496799139657
Validation loss: 2.6346929911071846

Epoch: 6| Step: 8
Training loss: 3.062997271589807
Validation loss: 2.6105023859775853

Epoch: 6| Step: 9
Training loss: 3.063508782355669
Validation loss: 2.614228285322117

Epoch: 6| Step: 10
Training loss: 2.299875596040617
Validation loss: 2.616247726829909

Epoch: 6| Step: 11
Training loss: 2.63663058663369
Validation loss: 2.6138664321388374

Epoch: 6| Step: 12
Training loss: 2.562106497719788
Validation loss: 2.6140709256302648

Epoch: 6| Step: 13
Training loss: 2.2982298300131996
Validation loss: 2.614037038021541

Epoch: 113| Step: 0
Training loss: 3.0477251480712684
Validation loss: 2.612900252076572

Epoch: 6| Step: 1
Training loss: 2.6913831291811228
Validation loss: 2.622456210199076

Epoch: 6| Step: 2
Training loss: 3.6336499633246513
Validation loss: 2.627770932717564

Epoch: 6| Step: 3
Training loss: 2.926792352044276
Validation loss: 2.6179746225044376

Epoch: 6| Step: 4
Training loss: 2.799174551544335
Validation loss: 2.6338144555489147

Epoch: 6| Step: 5
Training loss: 3.3186517848192927
Validation loss: 2.633712198561525

Epoch: 6| Step: 6
Training loss: 3.1221083423063063
Validation loss: 2.6380276061544476

Epoch: 6| Step: 7
Training loss: 2.5546287039894042
Validation loss: 2.650673572829432

Epoch: 6| Step: 8
Training loss: 2.918654028154
Validation loss: 2.62928140479377

Epoch: 6| Step: 9
Training loss: 3.4049318895515888
Validation loss: 2.625054318344101

Epoch: 6| Step: 10
Training loss: 2.6553648427513905
Validation loss: 2.6229916716121147

Epoch: 6| Step: 11
Training loss: 2.3039840400527143
Validation loss: 2.620423995221055

Epoch: 6| Step: 12
Training loss: 2.5353067174145196
Validation loss: 2.612937569756491

Epoch: 6| Step: 13
Training loss: 3.3995473167648864
Validation loss: 2.613421826124183

Epoch: 114| Step: 0
Training loss: 3.284212210383865
Validation loss: 2.6074762281930277

Epoch: 6| Step: 1
Training loss: 2.6546534508581026
Validation loss: 2.6132535413813303

Epoch: 6| Step: 2
Training loss: 2.8100624541812103
Validation loss: 2.6094588262022618

Epoch: 6| Step: 3
Training loss: 2.657338895319458
Validation loss: 2.610574492894097

Epoch: 6| Step: 4
Training loss: 3.3053456906786156
Validation loss: 2.617914402112531

Epoch: 6| Step: 5
Training loss: 3.4643741534578054
Validation loss: 2.608076060509887

Epoch: 6| Step: 6
Training loss: 2.6511411117358383
Validation loss: 2.606893336765534

Epoch: 6| Step: 7
Training loss: 3.1546285260050766
Validation loss: 2.6061306441528953

Epoch: 6| Step: 8
Training loss: 2.614029074556079
Validation loss: 2.605298089795139

Epoch: 6| Step: 9
Training loss: 2.1735269315572303
Validation loss: 2.608309052486789

Epoch: 6| Step: 10
Training loss: 2.7447850458305365
Validation loss: 2.6054621772322224

Epoch: 6| Step: 11
Training loss: 3.3356957805886926
Validation loss: 2.6082027907697367

Epoch: 6| Step: 12
Training loss: 3.2740812920397633
Validation loss: 2.604789099028316

Epoch: 6| Step: 13
Training loss: 2.9161490571447697
Validation loss: 2.6113354330491125

Epoch: 115| Step: 0
Training loss: 3.187080804524013
Validation loss: 2.611676483353634

Epoch: 6| Step: 1
Training loss: 3.6540405901244917
Validation loss: 2.6146165856858024

Epoch: 6| Step: 2
Training loss: 2.8089288715878244
Validation loss: 2.6227726703720196

Epoch: 6| Step: 3
Training loss: 3.2238918085994586
Validation loss: 2.6335035032998935

Epoch: 6| Step: 4
Training loss: 2.8293095421049967
Validation loss: 2.6238794977492366

Epoch: 6| Step: 5
Training loss: 2.478251269516148
Validation loss: 2.6244492810113282

Epoch: 6| Step: 6
Training loss: 3.1980001995761755
Validation loss: 2.620559544293314

Epoch: 6| Step: 7
Training loss: 2.1093171288357757
Validation loss: 2.6226471553840804

Epoch: 6| Step: 8
Training loss: 2.7845949781799297
Validation loss: 2.624038445953908

Epoch: 6| Step: 9
Training loss: 3.0372632346477593
Validation loss: 2.634498274367115

Epoch: 6| Step: 10
Training loss: 3.1427465456539325
Validation loss: 2.6251348166899198

Epoch: 6| Step: 11
Training loss: 2.7465769531203055
Validation loss: 2.6193433262286203

Epoch: 6| Step: 12
Training loss: 2.271417408527593
Validation loss: 2.620631944807658

Epoch: 6| Step: 13
Training loss: 3.8010809565561026
Validation loss: 2.605526888754423

Epoch: 116| Step: 0
Training loss: 3.3888412916944
Validation loss: 2.6088218807655226

Epoch: 6| Step: 1
Training loss: 2.8850809905056987
Validation loss: 2.60483075606148

Epoch: 6| Step: 2
Training loss: 2.9233079956012156
Validation loss: 2.6024330853140873

Epoch: 6| Step: 3
Training loss: 3.292398749599931
Validation loss: 2.6034260684033463

Epoch: 6| Step: 4
Training loss: 2.7413819262778136
Validation loss: 2.605286212761519

Epoch: 6| Step: 5
Training loss: 2.0313696019100536
Validation loss: 2.6020356770071795

Epoch: 6| Step: 6
Training loss: 3.1323013459438664
Validation loss: 2.603961975584952

Epoch: 6| Step: 7
Training loss: 2.5436453907894614
Validation loss: 2.6024120830300306

Epoch: 6| Step: 8
Training loss: 2.968515005347808
Validation loss: 2.606731094910278

Epoch: 6| Step: 9
Training loss: 2.77228636156733
Validation loss: 2.6013497640050547

Epoch: 6| Step: 10
Training loss: 3.4572064199087675
Validation loss: 2.604144951186342

Epoch: 6| Step: 11
Training loss: 2.531859995492184
Validation loss: 2.6028575079115357

Epoch: 6| Step: 12
Training loss: 3.0766864648955514
Validation loss: 2.6092881941140313

Epoch: 6| Step: 13
Training loss: 3.5089430314725996
Validation loss: 2.60727163043796

Epoch: 117| Step: 0
Training loss: 3.304763973424418
Validation loss: 2.604429655188243

Epoch: 6| Step: 1
Training loss: 2.931270568385076
Validation loss: 2.614091106564472

Epoch: 6| Step: 2
Training loss: 2.9876227956139427
Validation loss: 2.6094637639485536

Epoch: 6| Step: 3
Training loss: 2.679612851006749
Validation loss: 2.611115187114722

Epoch: 6| Step: 4
Training loss: 3.0176359597006264
Validation loss: 2.6083507024469834

Epoch: 6| Step: 5
Training loss: 2.535300510810256
Validation loss: 2.610198439904099

Epoch: 6| Step: 6
Training loss: 2.392788475287668
Validation loss: 2.614836838669396

Epoch: 6| Step: 7
Training loss: 2.457938167902408
Validation loss: 2.6125942211075097

Epoch: 6| Step: 8
Training loss: 2.965927549149952
Validation loss: 2.610260394018261

Epoch: 6| Step: 9
Training loss: 3.597126576949399
Validation loss: 2.6064724345049712

Epoch: 6| Step: 10
Training loss: 3.2249941212208713
Validation loss: 2.6062699829525307

Epoch: 6| Step: 11
Training loss: 2.714968452059565
Validation loss: 2.606293487008966

Epoch: 6| Step: 12
Training loss: 3.443264791711826
Validation loss: 2.6046528138902567

Epoch: 6| Step: 13
Training loss: 2.4714374642090076
Validation loss: 2.602165583142279

Epoch: 118| Step: 0
Training loss: 2.693019787443368
Validation loss: 2.6043405277091836

Epoch: 6| Step: 1
Training loss: 3.2051444781941787
Validation loss: 2.6056099424297856

Epoch: 6| Step: 2
Training loss: 2.9651165058989988
Validation loss: 2.613946801319026

Epoch: 6| Step: 3
Training loss: 3.3140453836375823
Validation loss: 2.6179441393846754

Epoch: 6| Step: 4
Training loss: 2.9312206274972596
Validation loss: 2.6278224504668146

Epoch: 6| Step: 5
Training loss: 2.815805315516351
Validation loss: 2.640039340068242

Epoch: 6| Step: 6
Training loss: 3.3872479615990523
Validation loss: 2.6471451073668963

Epoch: 6| Step: 7
Training loss: 2.710647875350889
Validation loss: 2.6367813410407517

Epoch: 6| Step: 8
Training loss: 2.5483759102550514
Validation loss: 2.6353082024535768

Epoch: 6| Step: 9
Training loss: 2.9938749729264957
Validation loss: 2.6228049476719586

Epoch: 6| Step: 10
Training loss: 3.3752158767041065
Validation loss: 2.606589661268992

Epoch: 6| Step: 11
Training loss: 2.8321023024492047
Validation loss: 2.6110642940679316

Epoch: 6| Step: 12
Training loss: 2.4718143421933916
Validation loss: 2.5984477636289367

Epoch: 6| Step: 13
Training loss: 2.682751119330271
Validation loss: 2.6045540489922367

Epoch: 119| Step: 0
Training loss: 2.850279135168425
Validation loss: 2.6036558107118717

Epoch: 6| Step: 1
Training loss: 2.600353246313899
Validation loss: 2.605548581238217

Epoch: 6| Step: 2
Training loss: 3.4755986967225057
Validation loss: 2.5996403038709786

Epoch: 6| Step: 3
Training loss: 3.030035188426535
Validation loss: 2.605533154375403

Epoch: 6| Step: 4
Training loss: 2.785749160981465
Validation loss: 2.613537259030448

Epoch: 6| Step: 5
Training loss: 2.8290243668273747
Validation loss: 2.611758964547273

Epoch: 6| Step: 6
Training loss: 3.4564329847353195
Validation loss: 2.600824351565911

Epoch: 6| Step: 7
Training loss: 2.4515077155698064
Validation loss: 2.6026584571307

Epoch: 6| Step: 8
Training loss: 3.190336274506748
Validation loss: 2.6060419929333305

Epoch: 6| Step: 9
Training loss: 3.002788836889833
Validation loss: 2.6089140674232327

Epoch: 6| Step: 10
Training loss: 2.841387427547981
Validation loss: 2.6178338824952716

Epoch: 6| Step: 11
Training loss: 2.752165721860422
Validation loss: 2.6114880668567584

Epoch: 6| Step: 12
Training loss: 2.5045569849307445
Validation loss: 2.6223642747526763

Epoch: 6| Step: 13
Training loss: 3.3077701412726848
Validation loss: 2.6232426420912613

Epoch: 120| Step: 0
Training loss: 3.8839615593372163
Validation loss: 2.623966931786627

Epoch: 6| Step: 1
Training loss: 2.93813138628803
Validation loss: 2.61771423985023

Epoch: 6| Step: 2
Training loss: 2.5568021369199454
Validation loss: 2.609457648254641

Epoch: 6| Step: 3
Training loss: 3.0315655416267533
Validation loss: 2.596639854539889

Epoch: 6| Step: 4
Training loss: 2.71434189802834
Validation loss: 2.598910368993142

Epoch: 6| Step: 5
Training loss: 2.711803814546485
Validation loss: 2.5956951260276604

Epoch: 6| Step: 6
Training loss: 2.5463683203583893
Validation loss: 2.597295210028834

Epoch: 6| Step: 7
Training loss: 2.680669576781669
Validation loss: 2.5968275921051656

Epoch: 6| Step: 8
Training loss: 2.767342416744569
Validation loss: 2.593006884022189

Epoch: 6| Step: 9
Training loss: 2.6854115732961983
Validation loss: 2.5946575484148746

Epoch: 6| Step: 10
Training loss: 2.9670755583190687
Validation loss: 2.593726177676974

Epoch: 6| Step: 11
Training loss: 3.475899691030996
Validation loss: 2.6001240749192642

Epoch: 6| Step: 12
Training loss: 3.238777444738655
Validation loss: 2.601443716319153

Epoch: 6| Step: 13
Training loss: 2.664487743278627
Validation loss: 2.6090944377702203

Epoch: 121| Step: 0
Training loss: 3.171345483337099
Validation loss: 2.609925223183669

Epoch: 6| Step: 1
Training loss: 2.862013303201975
Validation loss: 2.6049717380219644

Epoch: 6| Step: 2
Training loss: 2.785985109068981
Validation loss: 2.6157963417229166

Epoch: 6| Step: 3
Training loss: 2.98196041831567
Validation loss: 2.625504776744318

Epoch: 6| Step: 4
Training loss: 3.194640893470254
Validation loss: 2.613584813036762

Epoch: 6| Step: 5
Training loss: 2.4253906328640884
Validation loss: 2.6161949385268137

Epoch: 6| Step: 6
Training loss: 3.083406516229044
Validation loss: 2.6275931996076474

Epoch: 6| Step: 7
Training loss: 3.0722305480157464
Validation loss: 2.6282257831370357

Epoch: 6| Step: 8
Training loss: 3.1381057580032397
Validation loss: 2.621093984739305

Epoch: 6| Step: 9
Training loss: 2.6998217912424836
Validation loss: 2.612928866106538

Epoch: 6| Step: 10
Training loss: 3.1371350991875055
Validation loss: 2.610186359269805

Epoch: 6| Step: 11
Training loss: 2.9421278839635274
Validation loss: 2.6102837108952395

Epoch: 6| Step: 12
Training loss: 2.4034050310774093
Validation loss: 2.6023384771583222

Epoch: 6| Step: 13
Training loss: 3.1240973122517257
Validation loss: 2.601056137207993

Epoch: 122| Step: 0
Training loss: 3.3733109380207322
Validation loss: 2.596331795372983

Epoch: 6| Step: 1
Training loss: 3.5565259936994504
Validation loss: 2.602838447415493

Epoch: 6| Step: 2
Training loss: 2.6991108101269643
Validation loss: 2.604249297441049

Epoch: 6| Step: 3
Training loss: 2.149683587500074
Validation loss: 2.6026418557449302

Epoch: 6| Step: 4
Training loss: 2.4245745964131062
Validation loss: 2.5998922702756198

Epoch: 6| Step: 5
Training loss: 2.4979850278211737
Validation loss: 2.6051062577608364

Epoch: 6| Step: 6
Training loss: 2.6921564615135285
Validation loss: 2.618250119791868

Epoch: 6| Step: 7
Training loss: 3.1773668673377586
Validation loss: 2.633119063021319

Epoch: 6| Step: 8
Training loss: 3.11105730562761
Validation loss: 2.633832466477522

Epoch: 6| Step: 9
Training loss: 3.0353064383288464
Validation loss: 2.6580063998586976

Epoch: 6| Step: 10
Training loss: 2.9799113021041754
Validation loss: 2.6430449145091215

Epoch: 6| Step: 11
Training loss: 3.199103533820839
Validation loss: 2.6325583186907604

Epoch: 6| Step: 12
Training loss: 3.4242340735080217
Validation loss: 2.6227294626226834

Epoch: 6| Step: 13
Training loss: 2.4366317572052094
Validation loss: 2.6195671164549386

Epoch: 123| Step: 0
Training loss: 2.281643036728577
Validation loss: 2.6138479266244996

Epoch: 6| Step: 1
Training loss: 2.567338980107952
Validation loss: 2.6119802063952653

Epoch: 6| Step: 2
Training loss: 3.182523994684974
Validation loss: 2.6168545800945338

Epoch: 6| Step: 3
Training loss: 2.8237410651847044
Validation loss: 2.638434234129467

Epoch: 6| Step: 4
Training loss: 2.7880002518028464
Validation loss: 2.6669057026243133

Epoch: 6| Step: 5
Training loss: 3.497547925575748
Validation loss: 2.68680517644611

Epoch: 6| Step: 6
Training loss: 3.6190196725774966
Validation loss: 2.667906710946967

Epoch: 6| Step: 7
Training loss: 3.1481482133886125
Validation loss: 2.621443545945853

Epoch: 6| Step: 8
Training loss: 2.4794989184257794
Validation loss: 2.6059688102937097

Epoch: 6| Step: 9
Training loss: 3.1884789553015525
Validation loss: 2.5950040537079966

Epoch: 6| Step: 10
Training loss: 3.4186101518721608
Validation loss: 2.594548151647705

Epoch: 6| Step: 11
Training loss: 2.688969853349587
Validation loss: 2.5950689479742817

Epoch: 6| Step: 12
Training loss: 2.457204160685978
Validation loss: 2.5936746370130797

Epoch: 6| Step: 13
Training loss: 2.778295597978828
Validation loss: 2.589369857878145

Epoch: 124| Step: 0
Training loss: 3.4258534892522445
Validation loss: 2.596021509316631

Epoch: 6| Step: 1
Training loss: 3.1071924572072276
Validation loss: 2.6021734577943487

Epoch: 6| Step: 2
Training loss: 3.3433174495249984
Validation loss: 2.6065615589175413

Epoch: 6| Step: 3
Training loss: 3.2104071483103764
Validation loss: 2.6215643004268485

Epoch: 6| Step: 4
Training loss: 2.600485455601966
Validation loss: 2.6211372350974624

Epoch: 6| Step: 5
Training loss: 2.76725402097266
Validation loss: 2.614928286808339

Epoch: 6| Step: 6
Training loss: 2.7259181444468594
Validation loss: 2.608944615763046

Epoch: 6| Step: 7
Training loss: 2.6973264384889504
Validation loss: 2.600295107235216

Epoch: 6| Step: 8
Training loss: 2.4301151009760216
Validation loss: 2.5969962759024767

Epoch: 6| Step: 9
Training loss: 2.9133149279864865
Validation loss: 2.58931759585778

Epoch: 6| Step: 10
Training loss: 2.8199755184653026
Validation loss: 2.5873752115872777

Epoch: 6| Step: 11
Training loss: 3.0739100687824155
Validation loss: 2.5972843377334573

Epoch: 6| Step: 12
Training loss: 2.8922657202267783
Validation loss: 2.5923180806617467

Epoch: 6| Step: 13
Training loss: 3.449021054020851
Validation loss: 2.6066845488482384

Epoch: 125| Step: 0
Training loss: 2.5602075510527995
Validation loss: 2.601572231038147

Epoch: 6| Step: 1
Training loss: 3.5567468064874936
Validation loss: 2.6029591894385486

Epoch: 6| Step: 2
Training loss: 3.0175809693554556
Validation loss: 2.5958680095485445

Epoch: 6| Step: 3
Training loss: 2.1430140619497475
Validation loss: 2.6057923733657953

Epoch: 6| Step: 4
Training loss: 2.8971240417028565
Validation loss: 2.6054215782163066

Epoch: 6| Step: 5
Training loss: 2.6991083368223308
Validation loss: 2.6188236358672263

Epoch: 6| Step: 6
Training loss: 2.7737507388030997
Validation loss: 2.599252183631231

Epoch: 6| Step: 7
Training loss: 3.2758040511295063
Validation loss: 2.607346923901234

Epoch: 6| Step: 8
Training loss: 3.457403923680236
Validation loss: 2.5969261246832516

Epoch: 6| Step: 9
Training loss: 2.907550479781988
Validation loss: 2.5919806618968617

Epoch: 6| Step: 10
Training loss: 2.2275810187576557
Validation loss: 2.6042645999993077

Epoch: 6| Step: 11
Training loss: 3.5475971310244256
Validation loss: 2.6026295469714187

Epoch: 6| Step: 12
Training loss: 2.785781255203513
Validation loss: 2.606220482588529

Epoch: 6| Step: 13
Training loss: 2.9519728577769406
Validation loss: 2.611477504960756

Epoch: 126| Step: 0
Training loss: 2.5923875654480653
Validation loss: 2.6065800158420176

Epoch: 6| Step: 1
Training loss: 2.9667084751683546
Validation loss: 2.6066881543094644

Epoch: 6| Step: 2
Training loss: 3.129510599698926
Validation loss: 2.6103616133483727

Epoch: 6| Step: 3
Training loss: 3.2745759937032455
Validation loss: 2.6102707614654586

Epoch: 6| Step: 4
Training loss: 2.1313901077709603
Validation loss: 2.607335679575726

Epoch: 6| Step: 5
Training loss: 3.0165444983373306
Validation loss: 2.602149471951554

Epoch: 6| Step: 6
Training loss: 2.5934858991990843
Validation loss: 2.609484775300499

Epoch: 6| Step: 7
Training loss: 3.500564802102058
Validation loss: 2.6089033752232615

Epoch: 6| Step: 8
Training loss: 2.7023523361982793
Validation loss: 2.603818799482931

Epoch: 6| Step: 9
Training loss: 2.7231178713309694
Validation loss: 2.6035506558885384

Epoch: 6| Step: 10
Training loss: 2.9934786807018363
Validation loss: 2.603327204773081

Epoch: 6| Step: 11
Training loss: 3.002924129822093
Validation loss: 2.5984638610204756

Epoch: 6| Step: 12
Training loss: 2.6469837801399954
Validation loss: 2.609379606812102

Epoch: 6| Step: 13
Training loss: 3.819920806463318
Validation loss: 2.6089476609475413

Epoch: 127| Step: 0
Training loss: 2.8088591852089637
Validation loss: 2.608924424498232

Epoch: 6| Step: 1
Training loss: 2.923345022609514
Validation loss: 2.598819810271106

Epoch: 6| Step: 2
Training loss: 2.846729101468638
Validation loss: 2.5963185423394175

Epoch: 6| Step: 3
Training loss: 3.105871325616079
Validation loss: 2.5967938793039753

Epoch: 6| Step: 4
Training loss: 2.975071010222973
Validation loss: 2.592026732194114

Epoch: 6| Step: 5
Training loss: 3.0202324806818632
Validation loss: 2.588466254381818

Epoch: 6| Step: 6
Training loss: 3.0138772435898433
Validation loss: 2.5897967400602124

Epoch: 6| Step: 7
Training loss: 2.582626389607746
Validation loss: 2.5887317823283373

Epoch: 6| Step: 8
Training loss: 2.8463575544043387
Validation loss: 2.591438028069368

Epoch: 6| Step: 9
Training loss: 3.079974088683684
Validation loss: 2.5882000276279507

Epoch: 6| Step: 10
Training loss: 3.301106851082034
Validation loss: 2.5855211096745307

Epoch: 6| Step: 11
Training loss: 2.7813204638523845
Validation loss: 2.5971249524568765

Epoch: 6| Step: 12
Training loss: 2.8411682482335516
Validation loss: 2.5911317833696645

Epoch: 6| Step: 13
Training loss: 2.9505707528093583
Validation loss: 2.5961038934144978

Epoch: 128| Step: 0
Training loss: 2.2410738103134187
Validation loss: 2.603423652888855

Epoch: 6| Step: 1
Training loss: 2.5576340600877687
Validation loss: 2.623982255158975

Epoch: 6| Step: 2
Training loss: 3.0890873153067973
Validation loss: 2.6374556114257364

Epoch: 6| Step: 3
Training loss: 2.997138088798652
Validation loss: 2.6767164224460496

Epoch: 6| Step: 4
Training loss: 3.1397843635525953
Validation loss: 2.661023325809504

Epoch: 6| Step: 5
Training loss: 3.1939506333369274
Validation loss: 2.6160944152698264

Epoch: 6| Step: 6
Training loss: 2.9879874689638606
Validation loss: 2.604791042828053

Epoch: 6| Step: 7
Training loss: 2.5646572801685763
Validation loss: 2.592092058036683

Epoch: 6| Step: 8
Training loss: 2.6260557322344225
Validation loss: 2.585412954489225

Epoch: 6| Step: 9
Training loss: 3.787753730559084
Validation loss: 2.589484098787584

Epoch: 6| Step: 10
Training loss: 3.032974853572371
Validation loss: 2.5825457286956417

Epoch: 6| Step: 11
Training loss: 2.8359549866024243
Validation loss: 2.588134179599078

Epoch: 6| Step: 12
Training loss: 3.2022957077201064
Validation loss: 2.5811873519172934

Epoch: 6| Step: 13
Training loss: 2.90108893108846
Validation loss: 2.5815579476063704

Epoch: 129| Step: 0
Training loss: 2.9187788445233918
Validation loss: 2.585770495059758

Epoch: 6| Step: 1
Training loss: 2.661712952818294
Validation loss: 2.5835910202842434

Epoch: 6| Step: 2
Training loss: 2.7854923082997676
Validation loss: 2.5924457364973392

Epoch: 6| Step: 3
Training loss: 3.1931195556928715
Validation loss: 2.596588461555981

Epoch: 6| Step: 4
Training loss: 3.0377605561955248
Validation loss: 2.591773286956885

Epoch: 6| Step: 5
Training loss: 3.1699883623842164
Validation loss: 2.598832063104158

Epoch: 6| Step: 6
Training loss: 2.4597499343495204
Validation loss: 2.5945237022950387

Epoch: 6| Step: 7
Training loss: 3.735769609980977
Validation loss: 2.5974348106006144

Epoch: 6| Step: 8
Training loss: 2.841622028018869
Validation loss: 2.6016801332476014

Epoch: 6| Step: 9
Training loss: 3.248588548958579
Validation loss: 2.5972989696708164

Epoch: 6| Step: 10
Training loss: 2.1039723473388854
Validation loss: 2.592521333968505

Epoch: 6| Step: 11
Training loss: 2.6942947013992886
Validation loss: 2.602141852641055

Epoch: 6| Step: 12
Training loss: 2.7165341171349398
Validation loss: 2.621178016147367

Epoch: 6| Step: 13
Training loss: 3.12289831059825
Validation loss: 2.6168533946997106

Epoch: 130| Step: 0
Training loss: 2.9422060017300304
Validation loss: 2.6255707674493656

Epoch: 6| Step: 1
Training loss: 3.5087908291726
Validation loss: 2.6245525699535444

Epoch: 6| Step: 2
Training loss: 2.454297799804358
Validation loss: 2.6415837161496794

Epoch: 6| Step: 3
Training loss: 3.5424973953442094
Validation loss: 2.6324921847005607

Epoch: 6| Step: 4
Training loss: 2.298506177009745
Validation loss: 2.6054147839370936

Epoch: 6| Step: 5
Training loss: 3.1010489627204296
Validation loss: 2.5910438201325467

Epoch: 6| Step: 6
Training loss: 3.0062556213199456
Validation loss: 2.5804146034938245

Epoch: 6| Step: 7
Training loss: 3.044532383934947
Validation loss: 2.58217393644912

Epoch: 6| Step: 8
Training loss: 2.8515777169435594
Validation loss: 2.579659337962908

Epoch: 6| Step: 9
Training loss: 3.225129850863627
Validation loss: 2.578327198620101

Epoch: 6| Step: 10
Training loss: 3.3467732959898817
Validation loss: 2.582765201837055

Epoch: 6| Step: 11
Training loss: 2.625694183113735
Validation loss: 2.584756890320888

Epoch: 6| Step: 12
Training loss: 2.6567234290587196
Validation loss: 2.5851781944946777

Epoch: 6| Step: 13
Training loss: 1.1878569217154418
Validation loss: 2.586892047265757

Epoch: 131| Step: 0
Training loss: 2.262021164779067
Validation loss: 2.5863558017591664

Epoch: 6| Step: 1
Training loss: 3.0392542290701674
Validation loss: 2.587827600387713

Epoch: 6| Step: 2
Training loss: 2.9953231914809026
Validation loss: 2.5939473752752003

Epoch: 6| Step: 3
Training loss: 2.700278045325001
Validation loss: 2.593319497011313

Epoch: 6| Step: 4
Training loss: 2.41743465804719
Validation loss: 2.5873893437109685

Epoch: 6| Step: 5
Training loss: 3.0134794676913375
Validation loss: 2.59513748385959

Epoch: 6| Step: 6
Training loss: 3.20994444849545
Validation loss: 2.597778696398229

Epoch: 6| Step: 7
Training loss: 2.484138333546035
Validation loss: 2.6064333954492955

Epoch: 6| Step: 8
Training loss: 2.963938136249253
Validation loss: 2.6088124440593488

Epoch: 6| Step: 9
Training loss: 3.060418492042477
Validation loss: 2.6300218754658737

Epoch: 6| Step: 10
Training loss: 3.0174529707055786
Validation loss: 2.627518275567459

Epoch: 6| Step: 11
Training loss: 3.4758784274756116
Validation loss: 2.6516511110501124

Epoch: 6| Step: 12
Training loss: 2.877620995013482
Validation loss: 2.63391586956543

Epoch: 6| Step: 13
Training loss: 3.7943796505724388
Validation loss: 2.616963894701194

Epoch: 132| Step: 0
Training loss: 2.3297403351327133
Validation loss: 2.597052355633274

Epoch: 6| Step: 1
Training loss: 2.854952868658813
Validation loss: 2.5858244953497085

Epoch: 6| Step: 2
Training loss: 2.5210086246631964
Validation loss: 2.584364036091107

Epoch: 6| Step: 3
Training loss: 3.158999614506644
Validation loss: 2.577290616417814

Epoch: 6| Step: 4
Training loss: 3.1983481912299276
Validation loss: 2.5796008149711342

Epoch: 6| Step: 5
Training loss: 2.809305368818676
Validation loss: 2.580576255702629

Epoch: 6| Step: 6
Training loss: 2.2597560239437895
Validation loss: 2.5789922056819394

Epoch: 6| Step: 7
Training loss: 3.209610193655118
Validation loss: 2.5834354323562594

Epoch: 6| Step: 8
Training loss: 3.0841290933429324
Validation loss: 2.5834218392773027

Epoch: 6| Step: 9
Training loss: 2.9862767097233527
Validation loss: 2.58080081640111

Epoch: 6| Step: 10
Training loss: 3.6389735327688744
Validation loss: 2.586156825072526

Epoch: 6| Step: 11
Training loss: 2.3166861919796937
Validation loss: 2.58122100237747

Epoch: 6| Step: 12
Training loss: 3.3252889521965736
Validation loss: 2.587635120139153

Epoch: 6| Step: 13
Training loss: 3.253758824410125
Validation loss: 2.580733884547548

Epoch: 133| Step: 0
Training loss: 3.116835189451885
Validation loss: 2.5866575662116436

Epoch: 6| Step: 1
Training loss: 3.0500643739004136
Validation loss: 2.598099458978956

Epoch: 6| Step: 2
Training loss: 3.3817399154809396
Validation loss: 2.5912677754543783

Epoch: 6| Step: 3
Training loss: 3.137899858139892
Validation loss: 2.5826245035745954

Epoch: 6| Step: 4
Training loss: 2.230398627947655
Validation loss: 2.573472644017458

Epoch: 6| Step: 5
Training loss: 2.5598418242046734
Validation loss: 2.5732927366808065

Epoch: 6| Step: 6
Training loss: 2.42103473484312
Validation loss: 2.575455016822892

Epoch: 6| Step: 7
Training loss: 2.9327168582692003
Validation loss: 2.5766991752937556

Epoch: 6| Step: 8
Training loss: 3.2803981583538824
Validation loss: 2.5776734991849897

Epoch: 6| Step: 9
Training loss: 3.0105817456946364
Validation loss: 2.5806343681484036

Epoch: 6| Step: 10
Training loss: 2.8409592904944243
Validation loss: 2.5756300243379813

Epoch: 6| Step: 11
Training loss: 2.8955409133331433
Validation loss: 2.574499784987183

Epoch: 6| Step: 12
Training loss: 3.25379209100652
Validation loss: 2.578825501518257

Epoch: 6| Step: 13
Training loss: 2.7737597640950007
Validation loss: 2.5793967999674408

Epoch: 134| Step: 0
Training loss: 3.2262512500262432
Validation loss: 2.577321000459396

Epoch: 6| Step: 1
Training loss: 2.6229650693451645
Validation loss: 2.587371695140665

Epoch: 6| Step: 2
Training loss: 3.091701715755668
Validation loss: 2.5925508908252946

Epoch: 6| Step: 3
Training loss: 3.271515858057467
Validation loss: 2.583936692937011

Epoch: 6| Step: 4
Training loss: 3.0609061316946486
Validation loss: 2.5913829892608584

Epoch: 6| Step: 5
Training loss: 2.4587739668096456
Validation loss: 2.594884521273614

Epoch: 6| Step: 6
Training loss: 2.72067788708682
Validation loss: 2.5869918204132736

Epoch: 6| Step: 7
Training loss: 2.7988553841135917
Validation loss: 2.5888754011633432

Epoch: 6| Step: 8
Training loss: 3.4896102372835704
Validation loss: 2.5840403382931303

Epoch: 6| Step: 9
Training loss: 2.9570959126949945
Validation loss: 2.584572721670294

Epoch: 6| Step: 10
Training loss: 3.364025924065634
Validation loss: 2.5904026821927677

Epoch: 6| Step: 11
Training loss: 2.3543101129180255
Validation loss: 2.594648225197438

Epoch: 6| Step: 12
Training loss: 2.4597441186641706
Validation loss: 2.5932205575090532

Epoch: 6| Step: 13
Training loss: 2.6714203207851726
Validation loss: 2.598574751342939

Epoch: 135| Step: 0
Training loss: 2.80432381569844
Validation loss: 2.608249524992123

Epoch: 6| Step: 1
Training loss: 2.6449854135381523
Validation loss: 2.61184215083023

Epoch: 6| Step: 2
Training loss: 3.0863185212758757
Validation loss: 2.6215824825500307

Epoch: 6| Step: 3
Training loss: 2.7652104816032286
Validation loss: 2.6422070907287876

Epoch: 6| Step: 4
Training loss: 2.8506120325758313
Validation loss: 2.67630044923791

Epoch: 6| Step: 5
Training loss: 3.046248934076034
Validation loss: 2.699070920689692

Epoch: 6| Step: 6
Training loss: 3.17024978568145
Validation loss: 2.6817988980755922

Epoch: 6| Step: 7
Training loss: 3.2559900103141635
Validation loss: 2.6631018858051734

Epoch: 6| Step: 8
Training loss: 3.3852719007008587
Validation loss: 2.610415025877219

Epoch: 6| Step: 9
Training loss: 2.50318657921948
Validation loss: 2.5860013885432775

Epoch: 6| Step: 10
Training loss: 3.0721724993832615
Validation loss: 2.5813684668868313

Epoch: 6| Step: 11
Training loss: 2.568089785043149
Validation loss: 2.575715481256933

Epoch: 6| Step: 12
Training loss: 2.916176527710811
Validation loss: 2.577419450211273

Epoch: 6| Step: 13
Training loss: 2.9975128990576656
Validation loss: 2.580003644470543

Epoch: 136| Step: 0
Training loss: 2.235266127647326
Validation loss: 2.5811397721333345

Epoch: 6| Step: 1
Training loss: 2.8023791151152238
Validation loss: 2.5846608515761598

Epoch: 6| Step: 2
Training loss: 3.345063138859131
Validation loss: 2.589112063196693

Epoch: 6| Step: 3
Training loss: 3.092969083003108
Validation loss: 2.5889046713797925

Epoch: 6| Step: 4
Training loss: 2.868586144515423
Validation loss: 2.5918739196674916

Epoch: 6| Step: 5
Training loss: 2.5119575636128095
Validation loss: 2.5849039547588943

Epoch: 6| Step: 6
Training loss: 2.7977795550016107
Validation loss: 2.5842627022290134

Epoch: 6| Step: 7
Training loss: 3.326957103712984
Validation loss: 2.586161712145216

Epoch: 6| Step: 8
Training loss: 2.3718783291880046
Validation loss: 2.591130513981607

Epoch: 6| Step: 9
Training loss: 3.1036523653206944
Validation loss: 2.5879730886337082

Epoch: 6| Step: 10
Training loss: 3.0662809115506753
Validation loss: 2.589380809937639

Epoch: 6| Step: 11
Training loss: 2.785634731372442
Validation loss: 2.585377437876361

Epoch: 6| Step: 12
Training loss: 3.2628991829170664
Validation loss: 2.6020281556418614

Epoch: 6| Step: 13
Training loss: 3.6644225767151566
Validation loss: 2.602657876960644

Epoch: 137| Step: 0
Training loss: 2.962977690351054
Validation loss: 2.5956099920866453

Epoch: 6| Step: 1
Training loss: 2.8443849294946406
Validation loss: 2.5990625695494334

Epoch: 6| Step: 2
Training loss: 2.953296959124154
Validation loss: 2.592764499059426

Epoch: 6| Step: 3
Training loss: 3.6280139363955954
Validation loss: 2.592217751996954

Epoch: 6| Step: 4
Training loss: 2.8223189299410274
Validation loss: 2.5879249659322485

Epoch: 6| Step: 5
Training loss: 3.0305187483791194
Validation loss: 2.5913521864078777

Epoch: 6| Step: 6
Training loss: 2.799677462393234
Validation loss: 2.577312424210519

Epoch: 6| Step: 7
Training loss: 3.025654928386002
Validation loss: 2.5775686897487273

Epoch: 6| Step: 8
Training loss: 2.6704887675706384
Validation loss: 2.574933138747005

Epoch: 6| Step: 9
Training loss: 2.9310843024362643
Validation loss: 2.577685059877968

Epoch: 6| Step: 10
Training loss: 3.43935455233003
Validation loss: 2.574796257038814

Epoch: 6| Step: 11
Training loss: 2.402200437163314
Validation loss: 2.5764364023259745

Epoch: 6| Step: 12
Training loss: 2.664503044328545
Validation loss: 2.574835124115022

Epoch: 6| Step: 13
Training loss: 2.4485531135143725
Validation loss: 2.576281043552743

Epoch: 138| Step: 0
Training loss: 2.6215044089336086
Validation loss: 2.5796110870010924

Epoch: 6| Step: 1
Training loss: 2.2600253655689655
Validation loss: 2.5771816124866094

Epoch: 6| Step: 2
Training loss: 3.0030965718363754
Validation loss: 2.5806676880624946

Epoch: 6| Step: 3
Training loss: 2.523650263742289
Validation loss: 2.5813721464397146

Epoch: 6| Step: 4
Training loss: 3.5313905671085686
Validation loss: 2.5912714874492817

Epoch: 6| Step: 5
Training loss: 2.926935556466692
Validation loss: 2.591874576434456

Epoch: 6| Step: 6
Training loss: 3.9277030530047723
Validation loss: 2.5850985265599786

Epoch: 6| Step: 7
Training loss: 2.241419324973029
Validation loss: 2.5858763877855533

Epoch: 6| Step: 8
Training loss: 3.666344946416428
Validation loss: 2.5915407017293575

Epoch: 6| Step: 9
Training loss: 2.46777691555948
Validation loss: 2.5933710249625412

Epoch: 6| Step: 10
Training loss: 2.9525384875574123
Validation loss: 2.5776010447623574

Epoch: 6| Step: 11
Training loss: 3.0649423008228145
Validation loss: 2.578033580880713

Epoch: 6| Step: 12
Training loss: 2.3611235549698573
Validation loss: 2.583300926396888

Epoch: 6| Step: 13
Training loss: 2.629685262405976
Validation loss: 2.5746992961283137

Epoch: 139| Step: 0
Training loss: 2.830371280753474
Validation loss: 2.583143279527065

Epoch: 6| Step: 1
Training loss: 2.414929478091498
Validation loss: 2.5804069356532393

Epoch: 6| Step: 2
Training loss: 2.924947011092713
Validation loss: 2.58291060452055

Epoch: 6| Step: 3
Training loss: 3.213523695703313
Validation loss: 2.584394675233977

Epoch: 6| Step: 4
Training loss: 2.626727580204908
Validation loss: 2.583714849647088

Epoch: 6| Step: 5
Training loss: 3.3239559513483186
Validation loss: 2.6000213980681623

Epoch: 6| Step: 6
Training loss: 3.425999494188475
Validation loss: 2.5958912068319226

Epoch: 6| Step: 7
Training loss: 2.8442895398412227
Validation loss: 2.603364915709647

Epoch: 6| Step: 8
Training loss: 2.916740598195713
Validation loss: 2.6042120560823063

Epoch: 6| Step: 9
Training loss: 3.0973086456725003
Validation loss: 2.594768921517482

Epoch: 6| Step: 10
Training loss: 2.6473790757297246
Validation loss: 2.600601905333606

Epoch: 6| Step: 11
Training loss: 3.179333266413085
Validation loss: 2.60036017310938

Epoch: 6| Step: 12
Training loss: 2.684816928497114
Validation loss: 2.598192828268197

Epoch: 6| Step: 13
Training loss: 2.2842839589483273
Validation loss: 2.593630993442215

Epoch: 140| Step: 0
Training loss: 3.068044353706614
Validation loss: 2.5816612485536963

Epoch: 6| Step: 1
Training loss: 3.0434690561214595
Validation loss: 2.5899882866087816

Epoch: 6| Step: 2
Training loss: 2.6902565237490306
Validation loss: 2.5785640090451003

Epoch: 6| Step: 3
Training loss: 3.13252816372546
Validation loss: 2.5823151149415757

Epoch: 6| Step: 4
Training loss: 2.5049174583373994
Validation loss: 2.579301421391006

Epoch: 6| Step: 5
Training loss: 2.9458253449399585
Validation loss: 2.5810633774569665

Epoch: 6| Step: 6
Training loss: 2.9495045908665696
Validation loss: 2.5829126615577125

Epoch: 6| Step: 7
Training loss: 2.667468804674869
Validation loss: 2.590353320013224

Epoch: 6| Step: 8
Training loss: 3.497076175687978
Validation loss: 2.582249368022684

Epoch: 6| Step: 9
Training loss: 2.3855802876912353
Validation loss: 2.582907204574473

Epoch: 6| Step: 10
Training loss: 3.0292098268340197
Validation loss: 2.5873630739308195

Epoch: 6| Step: 11
Training loss: 2.901584613245367
Validation loss: 2.588595462904526

Epoch: 6| Step: 12
Training loss: 2.877090191861724
Validation loss: 2.5909163752445252

Epoch: 6| Step: 13
Training loss: 2.920037329186943
Validation loss: 2.5909939734673078

Epoch: 141| Step: 0
Training loss: 3.733150520844197
Validation loss: 2.5947590054019507

Epoch: 6| Step: 1
Training loss: 2.571192072028974
Validation loss: 2.6001055672372266

Epoch: 6| Step: 2
Training loss: 2.991921037009369
Validation loss: 2.6132343183238578

Epoch: 6| Step: 3
Training loss: 2.3080973599821863
Validation loss: 2.596329937069121

Epoch: 6| Step: 4
Training loss: 2.598229274790792
Validation loss: 2.610568845281557

Epoch: 6| Step: 5
Training loss: 2.5778937033734213
Validation loss: 2.6315888776251795

Epoch: 6| Step: 6
Training loss: 2.8082949249931333
Validation loss: 2.620803290951283

Epoch: 6| Step: 7
Training loss: 2.948528123038034
Validation loss: 2.6256647572061365

Epoch: 6| Step: 8
Training loss: 2.7375267828759027
Validation loss: 2.609815753243198

Epoch: 6| Step: 9
Training loss: 3.3869345837096727
Validation loss: 2.6149649784995677

Epoch: 6| Step: 10
Training loss: 2.8028334756271103
Validation loss: 2.5893748774953247

Epoch: 6| Step: 11
Training loss: 3.4477888623356283
Validation loss: 2.58330677851096

Epoch: 6| Step: 12
Training loss: 3.227926266250002
Validation loss: 2.57550911394882

Epoch: 6| Step: 13
Training loss: 1.7607683887531596
Validation loss: 2.565003689391454

Epoch: 142| Step: 0
Training loss: 2.458559564644317
Validation loss: 2.5643547492905094

Epoch: 6| Step: 1
Training loss: 2.9965466650618935
Validation loss: 2.5658570176695017

Epoch: 6| Step: 2
Training loss: 2.6705776879788607
Validation loss: 2.5688757884562086

Epoch: 6| Step: 3
Training loss: 3.297696124325823
Validation loss: 2.565339525834394

Epoch: 6| Step: 4
Training loss: 2.787272415792261
Validation loss: 2.5672501087745974

Epoch: 6| Step: 5
Training loss: 2.9948922226098267
Validation loss: 2.5750800593708205

Epoch: 6| Step: 6
Training loss: 2.8923249066241703
Validation loss: 2.567637501076826

Epoch: 6| Step: 7
Training loss: 2.412419818870009
Validation loss: 2.571059499106712

Epoch: 6| Step: 8
Training loss: 2.818307433307313
Validation loss: 2.5639856125393687

Epoch: 6| Step: 9
Training loss: 3.2744759526193237
Validation loss: 2.5665895796717977

Epoch: 6| Step: 10
Training loss: 2.978294209239502
Validation loss: 2.5658137746902874

Epoch: 6| Step: 11
Training loss: 2.713518656354249
Validation loss: 2.566328845334365

Epoch: 6| Step: 12
Training loss: 3.3994345419161918
Validation loss: 2.5658439819063603

Epoch: 6| Step: 13
Training loss: 3.387523164001319
Validation loss: 2.56403487943636

Epoch: 143| Step: 0
Training loss: 2.3287661904771952
Validation loss: 2.5659452468731727

Epoch: 6| Step: 1
Training loss: 3.196457636671362
Validation loss: 2.5656166072426054

Epoch: 6| Step: 2
Training loss: 3.087852791464543
Validation loss: 2.5771037525551814

Epoch: 6| Step: 3
Training loss: 2.7193181989765662
Validation loss: 2.586962956163772

Epoch: 6| Step: 4
Training loss: 2.8344771563406352
Validation loss: 2.621715883042419

Epoch: 6| Step: 5
Training loss: 3.2280971765934745
Validation loss: 2.615832653720296

Epoch: 6| Step: 6
Training loss: 2.9614080291744314
Validation loss: 2.6416691250173563

Epoch: 6| Step: 7
Training loss: 2.8564276174665593
Validation loss: 2.6237413853106797

Epoch: 6| Step: 8
Training loss: 2.773838927539784
Validation loss: 2.6015986982923516

Epoch: 6| Step: 9
Training loss: 2.359946983679419
Validation loss: 2.5944125597716092

Epoch: 6| Step: 10
Training loss: 3.146659557312946
Validation loss: 2.5821677859058014

Epoch: 6| Step: 11
Training loss: 3.3739878231658724
Validation loss: 2.579144784470513

Epoch: 6| Step: 12
Training loss: 2.9617224787610894
Validation loss: 2.5777918545987237

Epoch: 6| Step: 13
Training loss: 2.855460066462515
Validation loss: 2.5846345054620934

Epoch: 144| Step: 0
Training loss: 3.149361978735996
Validation loss: 2.5762531225692222

Epoch: 6| Step: 1
Training loss: 2.90072188107296
Validation loss: 2.5764234952160727

Epoch: 6| Step: 2
Training loss: 2.8317399499970297
Validation loss: 2.580568476083626

Epoch: 6| Step: 3
Training loss: 2.4890072420719123
Validation loss: 2.5823714638565587

Epoch: 6| Step: 4
Training loss: 2.9848648388292394
Validation loss: 2.582472270348189

Epoch: 6| Step: 5
Training loss: 2.5717340961482593
Validation loss: 2.583791633254375

Epoch: 6| Step: 6
Training loss: 3.2489469729599265
Validation loss: 2.590459672631627

Epoch: 6| Step: 7
Training loss: 2.491031773374132
Validation loss: 2.588311408194974

Epoch: 6| Step: 8
Training loss: 2.6606126749417682
Validation loss: 2.596341568726025

Epoch: 6| Step: 9
Training loss: 3.1016744213905807
Validation loss: 2.602634342041517

Epoch: 6| Step: 10
Training loss: 2.7865229994260887
Validation loss: 2.5943429839607526

Epoch: 6| Step: 11
Training loss: 3.172713145497601
Validation loss: 2.597016238095787

Epoch: 6| Step: 12
Training loss: 3.000277824253127
Validation loss: 2.586746886716443

Epoch: 6| Step: 13
Training loss: 3.4288748992856495
Validation loss: 2.585592548950471

Epoch: 145| Step: 0
Training loss: 2.6130757842667496
Validation loss: 2.582333568949532

Epoch: 6| Step: 1
Training loss: 2.8272070475088382
Validation loss: 2.576925786975307

Epoch: 6| Step: 2
Training loss: 2.7558810032483154
Validation loss: 2.5768913750717433

Epoch: 6| Step: 3
Training loss: 3.3075118024158456
Validation loss: 2.571095618327645

Epoch: 6| Step: 4
Training loss: 3.0131231019718925
Validation loss: 2.573723692909021

Epoch: 6| Step: 5
Training loss: 2.8092806722825685
Validation loss: 2.571548429577772

Epoch: 6| Step: 6
Training loss: 2.7410736865020584
Validation loss: 2.5618033513872125

Epoch: 6| Step: 7
Training loss: 2.91626139050355
Validation loss: 2.572190493667331

Epoch: 6| Step: 8
Training loss: 3.1120109694809757
Validation loss: 2.5785109225208407

Epoch: 6| Step: 9
Training loss: 2.771688936304243
Validation loss: 2.583305822841889

Epoch: 6| Step: 10
Training loss: 2.506982778982291
Validation loss: 2.5883766901338188

Epoch: 6| Step: 11
Training loss: 3.685333003159585
Validation loss: 2.578373648099909

Epoch: 6| Step: 12
Training loss: 2.8570977820519294
Validation loss: 2.5884316086478503

Epoch: 6| Step: 13
Training loss: 2.2940419689486613
Validation loss: 2.594921842160701

Epoch: 146| Step: 0
Training loss: 2.812216002642759
Validation loss: 2.5887577302367855

Epoch: 6| Step: 1
Training loss: 2.436982026451429
Validation loss: 2.600987091971002

Epoch: 6| Step: 2
Training loss: 2.930947157582264
Validation loss: 2.593055104211226

Epoch: 6| Step: 3
Training loss: 3.12025885461835
Validation loss: 2.600442431585082

Epoch: 6| Step: 4
Training loss: 3.1055929674940557
Validation loss: 2.595962762661735

Epoch: 6| Step: 5
Training loss: 2.9583306827443745
Validation loss: 2.597851944956221

Epoch: 6| Step: 6
Training loss: 3.487039547948942
Validation loss: 2.6013863476278365

Epoch: 6| Step: 7
Training loss: 2.8980038053646866
Validation loss: 2.5922849302748947

Epoch: 6| Step: 8
Training loss: 2.780375653964882
Validation loss: 2.590525350711625

Epoch: 6| Step: 9
Training loss: 2.7644988100018617
Validation loss: 2.60121252106665

Epoch: 6| Step: 10
Training loss: 2.8991283816925315
Validation loss: 2.5964399874410127

Epoch: 6| Step: 11
Training loss: 2.4962188737100575
Validation loss: 2.6063471122522586

Epoch: 6| Step: 12
Training loss: 3.108406874644927
Validation loss: 2.6026303990130737

Epoch: 6| Step: 13
Training loss: 2.365259071177067
Validation loss: 2.610614794750967

Epoch: 147| Step: 0
Training loss: 2.9010892598182183
Validation loss: 2.601363629024085

Epoch: 6| Step: 1
Training loss: 2.8785368683696717
Validation loss: 2.596286542037309

Epoch: 6| Step: 2
Training loss: 2.7825562056548243
Validation loss: 2.613885679970943

Epoch: 6| Step: 3
Training loss: 2.6953739767388867
Validation loss: 2.5982176940124946

Epoch: 6| Step: 4
Training loss: 3.2985974192195737
Validation loss: 2.59592150055819

Epoch: 6| Step: 5
Training loss: 2.6102629652590053
Validation loss: 2.603896420310381

Epoch: 6| Step: 6
Training loss: 3.087793955535379
Validation loss: 2.596158037222311

Epoch: 6| Step: 7
Training loss: 2.7901502352774306
Validation loss: 2.585054878526178

Epoch: 6| Step: 8
Training loss: 2.8944488801960833
Validation loss: 2.58542206014117

Epoch: 6| Step: 9
Training loss: 2.598950515358174
Validation loss: 2.58649980675676

Epoch: 6| Step: 10
Training loss: 2.859753359583467
Validation loss: 2.5915880371417037

Epoch: 6| Step: 11
Training loss: 3.209198492409605
Validation loss: 2.5852062466703414

Epoch: 6| Step: 12
Training loss: 2.6260994924624472
Validation loss: 2.595445741083476

Epoch: 6| Step: 13
Training loss: 3.5740638574275945
Validation loss: 2.585742318133782

Epoch: 148| Step: 0
Training loss: 3.096066773051867
Validation loss: 2.601053998421987

Epoch: 6| Step: 1
Training loss: 3.225751650252456
Validation loss: 2.5856615987616145

Epoch: 6| Step: 2
Training loss: 2.8933969764331375
Validation loss: 2.5980387107975464

Epoch: 6| Step: 3
Training loss: 2.491562911545181
Validation loss: 2.595983445807251

Epoch: 6| Step: 4
Training loss: 2.7468120129408264
Validation loss: 2.5959789070638783

Epoch: 6| Step: 5
Training loss: 2.559497004059165
Validation loss: 2.594342591658958

Epoch: 6| Step: 6
Training loss: 2.7662569175388945
Validation loss: 2.596291571980089

Epoch: 6| Step: 7
Training loss: 2.8774862734204563
Validation loss: 2.5974068727282975

Epoch: 6| Step: 8
Training loss: 2.8899439653818333
Validation loss: 2.589831946615878

Epoch: 6| Step: 9
Training loss: 2.7201526575165027
Validation loss: 2.5814772652267832

Epoch: 6| Step: 10
Training loss: 2.96477041040715
Validation loss: 2.597326886002082

Epoch: 6| Step: 11
Training loss: 3.553353732219304
Validation loss: 2.5955322404929557

Epoch: 6| Step: 12
Training loss: 3.106855589016164
Validation loss: 2.591380095573172

Epoch: 6| Step: 13
Training loss: 2.044591430664613
Validation loss: 2.588590284308456

Epoch: 149| Step: 0
Training loss: 1.8389833548343797
Validation loss: 2.584032596882307

Epoch: 6| Step: 1
Training loss: 3.0296834456764388
Validation loss: 2.5849435212813603

Epoch: 6| Step: 2
Training loss: 2.872670432297735
Validation loss: 2.5853155816020705

Epoch: 6| Step: 3
Training loss: 3.3292082693646043
Validation loss: 2.5915470437019117

Epoch: 6| Step: 4
Training loss: 3.1482911939680234
Validation loss: 2.595406140076662

Epoch: 6| Step: 5
Training loss: 2.8358418261990943
Validation loss: 2.600030814422871

Epoch: 6| Step: 6
Training loss: 3.106602031324623
Validation loss: 2.600829348090144

Epoch: 6| Step: 7
Training loss: 3.1002618863634868
Validation loss: 2.6003919044191077

Epoch: 6| Step: 8
Training loss: 2.9735367582495313
Validation loss: 2.584517574354132

Epoch: 6| Step: 9
Training loss: 3.0283236191432286
Validation loss: 2.58451294306473

Epoch: 6| Step: 10
Training loss: 2.4346269156451443
Validation loss: 2.5751713145497046

Epoch: 6| Step: 11
Training loss: 2.3673432050302363
Validation loss: 2.5688361431085354

Epoch: 6| Step: 12
Training loss: 3.104998398195305
Validation loss: 2.568598363967773

Epoch: 6| Step: 13
Training loss: 3.266923126222361
Validation loss: 2.571636930062006

Epoch: 150| Step: 0
Training loss: 2.5953426756646176
Validation loss: 2.5846776845016577

Epoch: 6| Step: 1
Training loss: 3.1014581081396875
Validation loss: 2.587583559207003

Epoch: 6| Step: 2
Training loss: 3.2182720533160762
Validation loss: 2.5860902608351517

Epoch: 6| Step: 3
Training loss: 3.461386347957867
Validation loss: 2.6015359584700146

Epoch: 6| Step: 4
Training loss: 2.5098555849332165
Validation loss: 2.6175352891237424

Epoch: 6| Step: 5
Training loss: 1.7904679554082703
Validation loss: 2.625922430177137

Epoch: 6| Step: 6
Training loss: 3.6323486031935412
Validation loss: 2.636310821783658

Epoch: 6| Step: 7
Training loss: 3.0109309688827874
Validation loss: 2.625534211279896

Epoch: 6| Step: 8
Training loss: 2.745321716049957
Validation loss: 2.62582451996522

Epoch: 6| Step: 9
Training loss: 3.271601414650815
Validation loss: 2.59610317945523

Epoch: 6| Step: 10
Training loss: 2.8356970482817427
Validation loss: 2.596977610688444

Epoch: 6| Step: 11
Training loss: 2.605867689894544
Validation loss: 2.5841451769152575

Epoch: 6| Step: 12
Training loss: 2.705021540191122
Validation loss: 2.5727384187584015

Epoch: 6| Step: 13
Training loss: 2.1921854248907118
Validation loss: 2.5787264811200687

Epoch: 151| Step: 0
Training loss: 2.808791024995403
Validation loss: 2.5665417802096875

Epoch: 6| Step: 1
Training loss: 3.0237789306265874
Validation loss: 2.5692414656349967

Epoch: 6| Step: 2
Training loss: 3.1326943848525537
Validation loss: 2.568608778805753

Epoch: 6| Step: 3
Training loss: 3.245899548097996
Validation loss: 2.5633057268744563

Epoch: 6| Step: 4
Training loss: 2.681839504215957
Validation loss: 2.5580639192035064

Epoch: 6| Step: 5
Training loss: 2.555041554032825
Validation loss: 2.5613741648764736

Epoch: 6| Step: 6
Training loss: 3.4141678084623814
Validation loss: 2.5631175323815314

Epoch: 6| Step: 7
Training loss: 3.5048462150238198
Validation loss: 2.571166739523012

Epoch: 6| Step: 8
Training loss: 2.4439320918386915
Validation loss: 2.5729254830843606

Epoch: 6| Step: 9
Training loss: 3.138334435374802
Validation loss: 2.586478411442717

Epoch: 6| Step: 10
Training loss: 2.8055195118904273
Validation loss: 2.587407852683233

Epoch: 6| Step: 11
Training loss: 1.796136986476319
Validation loss: 2.5909642999043023

Epoch: 6| Step: 12
Training loss: 2.9446868636745838
Validation loss: 2.5820568958974923

Epoch: 6| Step: 13
Training loss: 2.4011278005998
Validation loss: 2.5870789849839877

Epoch: 152| Step: 0
Training loss: 3.282762160861666
Validation loss: 2.6014377630976004

Epoch: 6| Step: 1
Training loss: 3.0754323887953965
Validation loss: 2.5972026307060587

Epoch: 6| Step: 2
Training loss: 2.135680788655054
Validation loss: 2.599341307067853

Epoch: 6| Step: 3
Training loss: 2.5629446062642582
Validation loss: 2.5966589941037035

Epoch: 6| Step: 4
Training loss: 3.028996839489552
Validation loss: 2.596484729616849

Epoch: 6| Step: 5
Training loss: 2.5603912795080577
Validation loss: 2.6051195763053547

Epoch: 6| Step: 6
Training loss: 2.4119568564192404
Validation loss: 2.6096878812261726

Epoch: 6| Step: 7
Training loss: 2.593463744028313
Validation loss: 2.6280894832813986

Epoch: 6| Step: 8
Training loss: 3.5521247093199757
Validation loss: 2.608894043955863

Epoch: 6| Step: 9
Training loss: 2.632217385245698
Validation loss: 2.589047162208469

Epoch: 6| Step: 10
Training loss: 2.652941539518591
Validation loss: 2.581025457881514

Epoch: 6| Step: 11
Training loss: 3.1980913013071692
Validation loss: 2.5760299607579578

Epoch: 6| Step: 12
Training loss: 3.0913175017271155
Validation loss: 2.570879894568956

Epoch: 6| Step: 13
Training loss: 3.76927849905554
Validation loss: 2.5678051212673427

Epoch: 153| Step: 0
Training loss: 2.5166338680563745
Validation loss: 2.561102746552368

Epoch: 6| Step: 1
Training loss: 2.958310373423135
Validation loss: 2.560051927927527

Epoch: 6| Step: 2
Training loss: 2.6855525568121714
Validation loss: 2.555419527986906

Epoch: 6| Step: 3
Training loss: 3.229494697562904
Validation loss: 2.554948201204788

Epoch: 6| Step: 4
Training loss: 2.6312182209333903
Validation loss: 2.552333832719536

Epoch: 6| Step: 5
Training loss: 3.072804922022573
Validation loss: 2.556534587271431

Epoch: 6| Step: 6
Training loss: 2.847712177412904
Validation loss: 2.5526365118017074

Epoch: 6| Step: 7
Training loss: 3.1185646934728624
Validation loss: 2.553041852634705

Epoch: 6| Step: 8
Training loss: 2.061318261269512
Validation loss: 2.5572438250717853

Epoch: 6| Step: 9
Training loss: 3.3991145720109563
Validation loss: 2.5602312657004473

Epoch: 6| Step: 10
Training loss: 2.925046128129362
Validation loss: 2.561390199001826

Epoch: 6| Step: 11
Training loss: 2.7600058675786547
Validation loss: 2.5594378207175463

Epoch: 6| Step: 12
Training loss: 3.067192064418885
Validation loss: 2.558449257474273

Epoch: 6| Step: 13
Training loss: 3.333996531950961
Validation loss: 2.5595365206255267

Epoch: 154| Step: 0
Training loss: 3.0773326802883854
Validation loss: 2.57335586622095

Epoch: 6| Step: 1
Training loss: 3.223259886648143
Validation loss: 2.564820882069909

Epoch: 6| Step: 2
Training loss: 3.1428964476171237
Validation loss: 2.5680739285128182

Epoch: 6| Step: 3
Training loss: 2.8224502027931893
Validation loss: 2.5761411470161977

Epoch: 6| Step: 4
Training loss: 3.2963991228496625
Validation loss: 2.570269230244208

Epoch: 6| Step: 5
Training loss: 3.042665831310259
Validation loss: 2.55902475927061

Epoch: 6| Step: 6
Training loss: 2.780698828785655
Validation loss: 2.563760344955414

Epoch: 6| Step: 7
Training loss: 2.6510254585255284
Validation loss: 2.5659323903983973

Epoch: 6| Step: 8
Training loss: 2.964944428153103
Validation loss: 2.564517769697246

Epoch: 6| Step: 9
Training loss: 2.511273049400204
Validation loss: 2.566966129873769

Epoch: 6| Step: 10
Training loss: 2.829215329575237
Validation loss: 2.5687001171717303

Epoch: 6| Step: 11
Training loss: 2.475929732969524
Validation loss: 2.5693677386543317

Epoch: 6| Step: 12
Training loss: 3.159633069766026
Validation loss: 2.566665812847676

Epoch: 6| Step: 13
Training loss: 2.0033739955835554
Validation loss: 2.5735625586025703

Epoch: 155| Step: 0
Training loss: 2.3980186668286674
Validation loss: 2.5785137262563604

Epoch: 6| Step: 1
Training loss: 2.9367028636051087
Validation loss: 2.587011502065367

Epoch: 6| Step: 2
Training loss: 3.0466990884715477
Validation loss: 2.6046999759747944

Epoch: 6| Step: 3
Training loss: 3.145760204820983
Validation loss: 2.615712581407164

Epoch: 6| Step: 4
Training loss: 2.7745345404037693
Validation loss: 2.6214446412495898

Epoch: 6| Step: 5
Training loss: 2.645810965696289
Validation loss: 2.627524519969533

Epoch: 6| Step: 6
Training loss: 3.154058621032924
Validation loss: 2.6299341611818234

Epoch: 6| Step: 7
Training loss: 3.3138649485482654
Validation loss: 2.617100290073862

Epoch: 6| Step: 8
Training loss: 2.4449464566661487
Validation loss: 2.607672846681225

Epoch: 6| Step: 9
Training loss: 3.2472764854657945
Validation loss: 2.603797234367349

Epoch: 6| Step: 10
Training loss: 3.030150538566847
Validation loss: 2.5871153651167322

Epoch: 6| Step: 11
Training loss: 2.8075219073506634
Validation loss: 2.579273845697289

Epoch: 6| Step: 12
Training loss: 2.641380427724269
Validation loss: 2.576372924871834

Epoch: 6| Step: 13
Training loss: 2.783886120966387
Validation loss: 2.5674344306327344

Epoch: 156| Step: 0
Training loss: 2.953281943374277
Validation loss: 2.5643215723174295

Epoch: 6| Step: 1
Training loss: 3.0204776598377783
Validation loss: 2.561637135877205

Epoch: 6| Step: 2
Training loss: 1.8616540229229124
Validation loss: 2.55904479025847

Epoch: 6| Step: 3
Training loss: 2.6466304949859825
Validation loss: 2.560335056630335

Epoch: 6| Step: 4
Training loss: 2.6290114496503394
Validation loss: 2.5662235126213617

Epoch: 6| Step: 5
Training loss: 3.2336329101786627
Validation loss: 2.564175825886666

Epoch: 6| Step: 6
Training loss: 2.6210204340179324
Validation loss: 2.5683431707749333

Epoch: 6| Step: 7
Training loss: 2.6552461410191284
Validation loss: 2.573657346995694

Epoch: 6| Step: 8
Training loss: 3.059104438328252
Validation loss: 2.5821696127030864

Epoch: 6| Step: 9
Training loss: 3.473966507947341
Validation loss: 2.579120511153523

Epoch: 6| Step: 10
Training loss: 3.5551490567877746
Validation loss: 2.5814010324856205

Epoch: 6| Step: 11
Training loss: 2.680481640110137
Validation loss: 2.580113942098583

Epoch: 6| Step: 12
Training loss: 2.835442113563618
Validation loss: 2.5740231934484026

Epoch: 6| Step: 13
Training loss: 3.13007705252384
Validation loss: 2.5647971169007437

Epoch: 157| Step: 0
Training loss: 2.683457550190712
Validation loss: 2.5666473595567307

Epoch: 6| Step: 1
Training loss: 2.3921155085279926
Validation loss: 2.563326345485114

Epoch: 6| Step: 2
Training loss: 2.953384953113023
Validation loss: 2.5622389005334196

Epoch: 6| Step: 3
Training loss: 3.077282785517284
Validation loss: 2.5575077941388917

Epoch: 6| Step: 4
Training loss: 2.9437526953942013
Validation loss: 2.5633058308880425

Epoch: 6| Step: 5
Training loss: 3.040058668975885
Validation loss: 2.5644859823760164

Epoch: 6| Step: 6
Training loss: 3.0827971499138718
Validation loss: 2.56598453625251

Epoch: 6| Step: 7
Training loss: 2.889862124840204
Validation loss: 2.5821039107289656

Epoch: 6| Step: 8
Training loss: 3.1500287069798847
Validation loss: 2.58640752593474

Epoch: 6| Step: 9
Training loss: 2.7476927007795977
Validation loss: 2.590772914573895

Epoch: 6| Step: 10
Training loss: 2.5529647758196603
Validation loss: 2.60498111778396

Epoch: 6| Step: 11
Training loss: 2.6662140601231163
Validation loss: 2.6129104025186556

Epoch: 6| Step: 12
Training loss: 3.3543969464281567
Validation loss: 2.5966192338863068

Epoch: 6| Step: 13
Training loss: 2.7318804015571154
Validation loss: 2.61089428141965

Epoch: 158| Step: 0
Training loss: 3.020167590916385
Validation loss: 2.5991898093144608

Epoch: 6| Step: 1
Training loss: 3.2542705354871235
Validation loss: 2.5857625347622823

Epoch: 6| Step: 2
Training loss: 2.7421829788735876
Validation loss: 2.578849386929758

Epoch: 6| Step: 3
Training loss: 3.3532144525689067
Validation loss: 2.5926050534594283

Epoch: 6| Step: 4
Training loss: 2.9474257924297063
Validation loss: 2.5904492991310355

Epoch: 6| Step: 5
Training loss: 2.3736759309627615
Validation loss: 2.59081678192863

Epoch: 6| Step: 6
Training loss: 2.557603950364275
Validation loss: 2.5859423597286617

Epoch: 6| Step: 7
Training loss: 3.4490390268508464
Validation loss: 2.5890794876488634

Epoch: 6| Step: 8
Training loss: 2.4959646081126974
Validation loss: 2.58869689256784

Epoch: 6| Step: 9
Training loss: 2.5764654193306837
Validation loss: 2.5802306405676316

Epoch: 6| Step: 10
Training loss: 2.5494826371685924
Validation loss: 2.564656547459037

Epoch: 6| Step: 11
Training loss: 2.9600480890233953
Validation loss: 2.5552208100345517

Epoch: 6| Step: 12
Training loss: 2.858768086044686
Validation loss: 2.5550153700716605

Epoch: 6| Step: 13
Training loss: 3.0960518336725418
Validation loss: 2.549605951218751

Epoch: 159| Step: 0
Training loss: 3.306773580186602
Validation loss: 2.5557333471376453

Epoch: 6| Step: 1
Training loss: 2.481797710858907
Validation loss: 2.561259568002059

Epoch: 6| Step: 2
Training loss: 2.886849076525686
Validation loss: 2.5787762925189877

Epoch: 6| Step: 3
Training loss: 2.5423016823211806
Validation loss: 2.589871075558308

Epoch: 6| Step: 4
Training loss: 2.4982548344524402
Validation loss: 2.609262898398561

Epoch: 6| Step: 5
Training loss: 2.499429065360927
Validation loss: 2.6323172226752587

Epoch: 6| Step: 6
Training loss: 3.0018543234594945
Validation loss: 2.6515801511409025

Epoch: 6| Step: 7
Training loss: 3.2828863514178623
Validation loss: 2.652187617500006

Epoch: 6| Step: 8
Training loss: 3.255965992555471
Validation loss: 2.64601045486727

Epoch: 6| Step: 9
Training loss: 3.432432010696882
Validation loss: 2.6340621105943396

Epoch: 6| Step: 10
Training loss: 2.625605377145732
Validation loss: 2.592645907557829

Epoch: 6| Step: 11
Training loss: 2.323997987152121
Validation loss: 2.583505103453796

Epoch: 6| Step: 12
Training loss: 3.5025099882300648
Validation loss: 2.572663703816156

Epoch: 6| Step: 13
Training loss: 2.3546256459091426
Validation loss: 2.5572827900011794

Epoch: 160| Step: 0
Training loss: 2.9270922750062676
Validation loss: 2.544203037029551

Epoch: 6| Step: 1
Training loss: 3.3021370354907544
Validation loss: 2.5486986355500623

Epoch: 6| Step: 2
Training loss: 2.7566269874100278
Validation loss: 2.5464173391497726

Epoch: 6| Step: 3
Training loss: 3.14811898033077
Validation loss: 2.5642740914892714

Epoch: 6| Step: 4
Training loss: 2.388674569927701
Validation loss: 2.5581027193122035

Epoch: 6| Step: 5
Training loss: 2.649614910720021
Validation loss: 2.5642375172655894

Epoch: 6| Step: 6
Training loss: 2.85641509732951
Validation loss: 2.555431521419507

Epoch: 6| Step: 7
Training loss: 2.6361314811852976
Validation loss: 2.5628475330709994

Epoch: 6| Step: 8
Training loss: 3.187307763380157
Validation loss: 2.5652729211072423

Epoch: 6| Step: 9
Training loss: 3.1102683159483817
Validation loss: 2.550357462225857

Epoch: 6| Step: 10
Training loss: 2.058921947050303
Validation loss: 2.5473959232967283

Epoch: 6| Step: 11
Training loss: 3.0878900073133475
Validation loss: 2.543032043585743

Epoch: 6| Step: 12
Training loss: 3.120043524169559
Validation loss: 2.5405727209606237

Epoch: 6| Step: 13
Training loss: 3.411312436000365
Validation loss: 2.5451977031571973

Epoch: 161| Step: 0
Training loss: 2.473124527544348
Validation loss: 2.5427143601086173

Epoch: 6| Step: 1
Training loss: 3.007559629437392
Validation loss: 2.540904058963753

Epoch: 6| Step: 2
Training loss: 2.356261769880045
Validation loss: 2.5451764320437182

Epoch: 6| Step: 3
Training loss: 3.0385537788185455
Validation loss: 2.543577649543195

Epoch: 6| Step: 4
Training loss: 2.669454091301974
Validation loss: 2.542672313549611

Epoch: 6| Step: 5
Training loss: 2.799217394041414
Validation loss: 2.545536444697798

Epoch: 6| Step: 6
Training loss: 3.2491062109045883
Validation loss: 2.5495767109759044

Epoch: 6| Step: 7
Training loss: 3.1952063955583974
Validation loss: 2.548423959907552

Epoch: 6| Step: 8
Training loss: 3.525675196270866
Validation loss: 2.5592814556050403

Epoch: 6| Step: 9
Training loss: 3.1064844545730317
Validation loss: 2.560002876794132

Epoch: 6| Step: 10
Training loss: 2.475424134875067
Validation loss: 2.5614575492390856

Epoch: 6| Step: 11
Training loss: 2.5205123528872315
Validation loss: 2.564803492016945

Epoch: 6| Step: 12
Training loss: 3.1254473556749764
Validation loss: 2.5678783592503502

Epoch: 6| Step: 13
Training loss: 2.7212884386998675
Validation loss: 2.567773966686852

Epoch: 162| Step: 0
Training loss: 3.244269674491502
Validation loss: 2.5761282936579524

Epoch: 6| Step: 1
Training loss: 2.7450894816115636
Validation loss: 2.5560288595837277

Epoch: 6| Step: 2
Training loss: 2.9551705839488887
Validation loss: 2.5730643573559764

Epoch: 6| Step: 3
Training loss: 2.7466391053097774
Validation loss: 2.5821347474581597

Epoch: 6| Step: 4
Training loss: 3.119153772181904
Validation loss: 2.5770151423656915

Epoch: 6| Step: 5
Training loss: 2.7186300317011836
Validation loss: 2.5705721431315816

Epoch: 6| Step: 6
Training loss: 2.713964701434926
Validation loss: 2.5819214711625365

Epoch: 6| Step: 7
Training loss: 3.226705257037881
Validation loss: 2.5723175418078945

Epoch: 6| Step: 8
Training loss: 3.1055903572887966
Validation loss: 2.572381169663251

Epoch: 6| Step: 9
Training loss: 2.972945771924738
Validation loss: 2.568070925703805

Epoch: 6| Step: 10
Training loss: 2.675997136449493
Validation loss: 2.574691942837327

Epoch: 6| Step: 11
Training loss: 2.568860510609233
Validation loss: 2.5711116117693535

Epoch: 6| Step: 12
Training loss: 2.627103779950439
Validation loss: 2.56462259668814

Epoch: 6| Step: 13
Training loss: 2.916056505595055
Validation loss: 2.55857922937299

Epoch: 163| Step: 0
Training loss: 2.790614703288631
Validation loss: 2.5619634591319898

Epoch: 6| Step: 1
Training loss: 3.282211889332346
Validation loss: 2.5602078594657907

Epoch: 6| Step: 2
Training loss: 3.2289926461531517
Validation loss: 2.558826508150713

Epoch: 6| Step: 3
Training loss: 2.6586638309950836
Validation loss: 2.561288151390497

Epoch: 6| Step: 4
Training loss: 3.0964992137373892
Validation loss: 2.5649296476892336

Epoch: 6| Step: 5
Training loss: 2.8803531732177947
Validation loss: 2.561639468699257

Epoch: 6| Step: 6
Training loss: 2.558642204932399
Validation loss: 2.5548968626190436

Epoch: 6| Step: 7
Training loss: 2.8546298317181606
Validation loss: 2.563848288340479

Epoch: 6| Step: 8
Training loss: 2.216614891346281
Validation loss: 2.5575171605284246

Epoch: 6| Step: 9
Training loss: 2.6764977157243814
Validation loss: 2.5626418892039258

Epoch: 6| Step: 10
Training loss: 3.4024023320336942
Validation loss: 2.5779054888227915

Epoch: 6| Step: 11
Training loss: 2.761490484621534
Validation loss: 2.5800124522378707

Epoch: 6| Step: 12
Training loss: 3.025646890877448
Validation loss: 2.58367281941416

Epoch: 6| Step: 13
Training loss: 2.600195356512431
Validation loss: 2.595334560010145

Epoch: 164| Step: 0
Training loss: 2.9304126706677605
Validation loss: 2.605404660870986

Epoch: 6| Step: 1
Training loss: 3.0473818626381304
Validation loss: 2.6483445062433075

Epoch: 6| Step: 2
Training loss: 2.7247558554374596
Validation loss: 2.648280630917811

Epoch: 6| Step: 3
Training loss: 3.0198800698523613
Validation loss: 2.6841488325156004

Epoch: 6| Step: 4
Training loss: 2.778039343492842
Validation loss: 2.645424410014315

Epoch: 6| Step: 5
Training loss: 2.314282735355081
Validation loss: 2.6266886274711596

Epoch: 6| Step: 6
Training loss: 2.5825573360729095
Validation loss: 2.6180468330518343

Epoch: 6| Step: 7
Training loss: 3.5510847341772402
Validation loss: 2.6245457494980498

Epoch: 6| Step: 8
Training loss: 2.7385863217185444
Validation loss: 2.597800431871254

Epoch: 6| Step: 9
Training loss: 2.9786609851825094
Validation loss: 2.5754852114947733

Epoch: 6| Step: 10
Training loss: 2.8305840523778274
Validation loss: 2.568254787374761

Epoch: 6| Step: 11
Training loss: 3.1406918039381417
Validation loss: 2.5543259107026706

Epoch: 6| Step: 12
Training loss: 3.236373947086217
Validation loss: 2.5490030874486433

Epoch: 6| Step: 13
Training loss: 1.9991608885978
Validation loss: 2.5497716932178034

Epoch: 165| Step: 0
Training loss: 3.201248438014402
Validation loss: 2.5571425664108522

Epoch: 6| Step: 1
Training loss: 2.5660292349953995
Validation loss: 2.5624577088346476

Epoch: 6| Step: 2
Training loss: 2.4579500018032805
Validation loss: 2.5670930680698643

Epoch: 6| Step: 3
Training loss: 3.1908683183422033
Validation loss: 2.584764891404888

Epoch: 6| Step: 4
Training loss: 3.0438389445944547
Validation loss: 2.5685264140992703

Epoch: 6| Step: 5
Training loss: 3.0050897337960647
Validation loss: 2.573908938626095

Epoch: 6| Step: 6
Training loss: 2.830026566882844
Validation loss: 2.5678326833461798

Epoch: 6| Step: 7
Training loss: 2.4554529503299753
Validation loss: 2.5735092194832627

Epoch: 6| Step: 8
Training loss: 2.933810575271885
Validation loss: 2.564405588125035

Epoch: 6| Step: 9
Training loss: 3.3297172641721655
Validation loss: 2.565614775653681

Epoch: 6| Step: 10
Training loss: 2.8044390130011423
Validation loss: 2.562224872825039

Epoch: 6| Step: 11
Training loss: 2.8023839645116446
Validation loss: 2.5603813058472693

Epoch: 6| Step: 12
Training loss: 3.028352276566636
Validation loss: 2.5605431124566618

Epoch: 6| Step: 13
Training loss: 3.327508287197372
Validation loss: 2.5543735513574357

Epoch: 166| Step: 0
Training loss: 3.0346526878260685
Validation loss: 2.5551606236565143

Epoch: 6| Step: 1
Training loss: 3.046503445394056
Validation loss: 2.560967980597932

Epoch: 6| Step: 2
Training loss: 3.072228530300931
Validation loss: 2.5630737125657284

Epoch: 6| Step: 3
Training loss: 3.0330108561989686
Validation loss: 2.557986005533054

Epoch: 6| Step: 4
Training loss: 2.87603691309769
Validation loss: 2.573167247077535

Epoch: 6| Step: 5
Training loss: 2.8309379624630515
Validation loss: 2.5719619387203574

Epoch: 6| Step: 6
Training loss: 2.9777070495720848
Validation loss: 2.5773940197663077

Epoch: 6| Step: 7
Training loss: 2.6962614738492574
Validation loss: 2.587163293795658

Epoch: 6| Step: 8
Training loss: 2.9527797598088017
Validation loss: 2.6179653480511034

Epoch: 6| Step: 9
Training loss: 2.8651611485189488
Validation loss: 2.6288570646962905

Epoch: 6| Step: 10
Training loss: 2.639337711201803
Validation loss: 2.6533045339082926

Epoch: 6| Step: 11
Training loss: 2.687429382815867
Validation loss: 2.6447933602303517

Epoch: 6| Step: 12
Training loss: 2.506596350579804
Validation loss: 2.629936411002425

Epoch: 6| Step: 13
Training loss: 3.357823781118352
Validation loss: 2.616544790730051

Epoch: 167| Step: 0
Training loss: 2.7047351605972345
Validation loss: 2.615881723265661

Epoch: 6| Step: 1
Training loss: 3.0801498027388234
Validation loss: 2.5980023869218654

Epoch: 6| Step: 2
Training loss: 3.1880987764322133
Validation loss: 2.5952885118830324

Epoch: 6| Step: 3
Training loss: 2.736656937049486
Validation loss: 2.592232236496112

Epoch: 6| Step: 4
Training loss: 2.898097097967148
Validation loss: 2.607753962185895

Epoch: 6| Step: 5
Training loss: 3.081481497775116
Validation loss: 2.5994558504047167

Epoch: 6| Step: 6
Training loss: 2.7572588054071234
Validation loss: 2.6025875010780326

Epoch: 6| Step: 7
Training loss: 2.1324768920218866
Validation loss: 2.5967796394160088

Epoch: 6| Step: 8
Training loss: 3.1425851047739455
Validation loss: 2.5957304352949424

Epoch: 6| Step: 9
Training loss: 2.6251135302016473
Validation loss: 2.5863456199549364

Epoch: 6| Step: 10
Training loss: 2.181828148414505
Validation loss: 2.5565647968300502

Epoch: 6| Step: 11
Training loss: 3.247514507916166
Validation loss: 2.548010768079523

Epoch: 6| Step: 12
Training loss: 3.2633065932999616
Validation loss: 2.5386631623678944

Epoch: 6| Step: 13
Training loss: 3.1605773569762774
Validation loss: 2.538574210166069

Epoch: 168| Step: 0
Training loss: 2.506652944236422
Validation loss: 2.540718582287073

Epoch: 6| Step: 1
Training loss: 2.4923269776923154
Validation loss: 2.53995054808415

Epoch: 6| Step: 2
Training loss: 2.919423752975658
Validation loss: 2.538692337453863

Epoch: 6| Step: 3
Training loss: 2.6889575288311844
Validation loss: 2.5485090113256006

Epoch: 6| Step: 4
Training loss: 3.191239799725271
Validation loss: 2.5448013581979128

Epoch: 6| Step: 5
Training loss: 2.733547412428336
Validation loss: 2.54083497533977

Epoch: 6| Step: 6
Training loss: 2.720627936360102
Validation loss: 2.5430409592414045

Epoch: 6| Step: 7
Training loss: 3.36299640720889
Validation loss: 2.5402769606166564

Epoch: 6| Step: 8
Training loss: 3.3971372725965527
Validation loss: 2.5508702001364343

Epoch: 6| Step: 9
Training loss: 3.130406395120033
Validation loss: 2.5528492551500874

Epoch: 6| Step: 10
Training loss: 3.1208459328438263
Validation loss: 2.5525299793101213

Epoch: 6| Step: 11
Training loss: 2.7992208009712867
Validation loss: 2.550572253139297

Epoch: 6| Step: 12
Training loss: 2.4730152996375114
Validation loss: 2.558640732060259

Epoch: 6| Step: 13
Training loss: 2.670196452110779
Validation loss: 2.5554245992444478

Epoch: 169| Step: 0
Training loss: 3.076379736280831
Validation loss: 2.5677130571670643

Epoch: 6| Step: 1
Training loss: 2.387551519826674
Validation loss: 2.5786441850735358

Epoch: 6| Step: 2
Training loss: 3.467777150140578
Validation loss: 2.5697313804978386

Epoch: 6| Step: 3
Training loss: 2.901613207709346
Validation loss: 2.585520015017113

Epoch: 6| Step: 4
Training loss: 2.4555231508885353
Validation loss: 2.5932481925007127

Epoch: 6| Step: 5
Training loss: 3.142742600768873
Validation loss: 2.6080434392250584

Epoch: 6| Step: 6
Training loss: 3.6207055271596302
Validation loss: 2.6062838552404743

Epoch: 6| Step: 7
Training loss: 2.624557094447862
Validation loss: 2.6026857614223786

Epoch: 6| Step: 8
Training loss: 2.79142690929046
Validation loss: 2.587198727429837

Epoch: 6| Step: 9
Training loss: 2.6787767113632373
Validation loss: 2.5819406870655555

Epoch: 6| Step: 10
Training loss: 2.673020948088907
Validation loss: 2.5712015705326716

Epoch: 6| Step: 11
Training loss: 2.8632804173238044
Validation loss: 2.569776026039384

Epoch: 6| Step: 12
Training loss: 2.7397047144080435
Validation loss: 2.5651924505803656

Epoch: 6| Step: 13
Training loss: 2.5542960610733334
Validation loss: 2.563365923031631

Epoch: 170| Step: 0
Training loss: 3.171980080954508
Validation loss: 2.558040451045542

Epoch: 6| Step: 1
Training loss: 3.1238477489966012
Validation loss: 2.5553667221046457

Epoch: 6| Step: 2
Training loss: 3.262466290179205
Validation loss: 2.55003258533316

Epoch: 6| Step: 3
Training loss: 2.4985251844906786
Validation loss: 2.551697355561004

Epoch: 6| Step: 4
Training loss: 2.826571042884582
Validation loss: 2.5478170185161213

Epoch: 6| Step: 5
Training loss: 2.505656518849721
Validation loss: 2.548632273906963

Epoch: 6| Step: 6
Training loss: 2.843512724315171
Validation loss: 2.5560198046825806

Epoch: 6| Step: 7
Training loss: 3.1652204490410827
Validation loss: 2.5650381773226982

Epoch: 6| Step: 8
Training loss: 2.2593865105426776
Validation loss: 2.5777079245163725

Epoch: 6| Step: 9
Training loss: 3.247930601496693
Validation loss: 2.586019384514484

Epoch: 6| Step: 10
Training loss: 2.3970063254376766
Validation loss: 2.5951583385543153

Epoch: 6| Step: 11
Training loss: 2.6722612603716094
Validation loss: 2.59912530101849

Epoch: 6| Step: 12
Training loss: 3.1937634133730985
Validation loss: 2.606944414494056

Epoch: 6| Step: 13
Training loss: 2.7182753576118452
Validation loss: 2.612909175598144

Epoch: 171| Step: 0
Training loss: 2.897143463237889
Validation loss: 2.6151494360057805

Epoch: 6| Step: 1
Training loss: 3.183632392882805
Validation loss: 2.6007739875638904

Epoch: 6| Step: 2
Training loss: 2.888910723465136
Validation loss: 2.6026289815702124

Epoch: 6| Step: 3
Training loss: 2.8256316601278804
Validation loss: 2.5876316634894567

Epoch: 6| Step: 4
Training loss: 2.8322949096017624
Validation loss: 2.580680432882942

Epoch: 6| Step: 5
Training loss: 2.855795699369632
Validation loss: 2.57398740314669

Epoch: 6| Step: 6
Training loss: 2.4822845300936565
Validation loss: 2.5609389862066445

Epoch: 6| Step: 7
Training loss: 3.0794154526515736
Validation loss: 2.559960213901287

Epoch: 6| Step: 8
Training loss: 3.209289721996809
Validation loss: 2.560813823250407

Epoch: 6| Step: 9
Training loss: 2.4849869076481794
Validation loss: 2.5611746527278196

Epoch: 6| Step: 10
Training loss: 3.0775359698749294
Validation loss: 2.558839855680598

Epoch: 6| Step: 11
Training loss: 2.196191360654792
Validation loss: 2.563067759742411

Epoch: 6| Step: 12
Training loss: 2.9677090074550248
Validation loss: 2.573368156615531

Epoch: 6| Step: 13
Training loss: 3.275705503228927
Validation loss: 2.5668015820405814

Epoch: 172| Step: 0
Training loss: 2.728962101925851
Validation loss: 2.570808239907418

Epoch: 6| Step: 1
Training loss: 2.1767602221414433
Validation loss: 2.563990772839778

Epoch: 6| Step: 2
Training loss: 2.66664924218525
Validation loss: 2.576331491813786

Epoch: 6| Step: 3
Training loss: 3.0041376825875314
Validation loss: 2.5808148593636013

Epoch: 6| Step: 4
Training loss: 2.786159425669206
Validation loss: 2.5856172671743742

Epoch: 6| Step: 5
Training loss: 2.138753476611042
Validation loss: 2.577559586191461

Epoch: 6| Step: 6
Training loss: 3.3665578302095907
Validation loss: 2.5932368069672727

Epoch: 6| Step: 7
Training loss: 2.8503135977091443
Validation loss: 2.6017315744430687

Epoch: 6| Step: 8
Training loss: 2.9528792344617534
Validation loss: 2.591568456524062

Epoch: 6| Step: 9
Training loss: 2.9553220941920904
Validation loss: 2.601681254608516

Epoch: 6| Step: 10
Training loss: 2.8637348559947817
Validation loss: 2.6093113860590242

Epoch: 6| Step: 11
Training loss: 3.5710581996152153
Validation loss: 2.6005101860549074

Epoch: 6| Step: 12
Training loss: 2.84046629073103
Validation loss: 2.5925937481635244

Epoch: 6| Step: 13
Training loss: 2.813700525703819
Validation loss: 2.5954566645413157

Epoch: 173| Step: 0
Training loss: 3.252163387065138
Validation loss: 2.5836597663768335

Epoch: 6| Step: 1
Training loss: 2.7014933165235098
Validation loss: 2.5764868619727572

Epoch: 6| Step: 2
Training loss: 2.377398735160167
Validation loss: 2.5683038046826687

Epoch: 6| Step: 3
Training loss: 2.8684353724462537
Validation loss: 2.5527171777817763

Epoch: 6| Step: 4
Training loss: 2.7834520516422594
Validation loss: 2.5406773987253395

Epoch: 6| Step: 5
Training loss: 3.3893697498244997
Validation loss: 2.537568299357217

Epoch: 6| Step: 6
Training loss: 2.863068743179917
Validation loss: 2.531772409216717

Epoch: 6| Step: 7
Training loss: 2.5784649249153175
Validation loss: 2.5309478911676893

Epoch: 6| Step: 8
Training loss: 2.927215102590846
Validation loss: 2.53563663450181

Epoch: 6| Step: 9
Training loss: 3.3599353411674713
Validation loss: 2.536858051722244

Epoch: 6| Step: 10
Training loss: 2.0845383655863277
Validation loss: 2.533052675331348

Epoch: 6| Step: 11
Training loss: 2.85501783909878
Validation loss: 2.5401013673381816

Epoch: 6| Step: 12
Training loss: 3.1232273414673575
Validation loss: 2.5450077989450977

Epoch: 6| Step: 13
Training loss: 2.8350367941646857
Validation loss: 2.5469159464536366

Epoch: 174| Step: 0
Training loss: 2.827599745389965
Validation loss: 2.5504938970146447

Epoch: 6| Step: 1
Training loss: 2.855240297376338
Validation loss: 2.5518938514495964

Epoch: 6| Step: 2
Training loss: 2.494957893796043
Validation loss: 2.5590516856105125

Epoch: 6| Step: 3
Training loss: 3.1129156302425387
Validation loss: 2.5711743940401464

Epoch: 6| Step: 4
Training loss: 3.1615981312510724
Validation loss: 2.567348272685505

Epoch: 6| Step: 5
Training loss: 2.829367686018476
Validation loss: 2.5738880591708

Epoch: 6| Step: 6
Training loss: 3.301579449994203
Validation loss: 2.5876843320660545

Epoch: 6| Step: 7
Training loss: 2.2297058404116057
Validation loss: 2.585045385801895

Epoch: 6| Step: 8
Training loss: 3.006739040893669
Validation loss: 2.575751723299347

Epoch: 6| Step: 9
Training loss: 2.946257502886574
Validation loss: 2.586472854935933

Epoch: 6| Step: 10
Training loss: 3.0806936013153834
Validation loss: 2.580491711812452

Epoch: 6| Step: 11
Training loss: 2.7706011815922165
Validation loss: 2.5833767120842293

Epoch: 6| Step: 12
Training loss: 2.6764684087156314
Validation loss: 2.5901635869770923

Epoch: 6| Step: 13
Training loss: 2.329538824913589
Validation loss: 2.5728058206781195

Epoch: 175| Step: 0
Training loss: 2.313347120033246
Validation loss: 2.5660801510501905

Epoch: 6| Step: 1
Training loss: 2.6780945962005767
Validation loss: 2.5604987334515346

Epoch: 6| Step: 2
Training loss: 2.887453060676884
Validation loss: 2.5465302280855355

Epoch: 6| Step: 3
Training loss: 2.3569523581608807
Validation loss: 2.534811409818535

Epoch: 6| Step: 4
Training loss: 2.8501846119835283
Validation loss: 2.543056157317782

Epoch: 6| Step: 5
Training loss: 3.024862106585188
Validation loss: 2.540160982025237

Epoch: 6| Step: 6
Training loss: 3.100007789355921
Validation loss: 2.5428507437419974

Epoch: 6| Step: 7
Training loss: 3.05732305056804
Validation loss: 2.540245404839662

Epoch: 6| Step: 8
Training loss: 3.339535633174058
Validation loss: 2.536047839331017

Epoch: 6| Step: 9
Training loss: 2.482507735717645
Validation loss: 2.5443790112314724

Epoch: 6| Step: 10
Training loss: 3.296407802075315
Validation loss: 2.548621699982062

Epoch: 6| Step: 11
Training loss: 2.427694601161268
Validation loss: 2.552732486465084

Epoch: 6| Step: 12
Training loss: 3.1626282255089113
Validation loss: 2.5891993653072722

Epoch: 6| Step: 13
Training loss: 2.6892984272354754
Validation loss: 2.5787576077651204

Epoch: 176| Step: 0
Training loss: 2.047132170151774
Validation loss: 2.604606749399162

Epoch: 6| Step: 1
Training loss: 3.07887979151003
Validation loss: 2.616667271254703

Epoch: 6| Step: 2
Training loss: 3.032672980674778
Validation loss: 2.6256553849394324

Epoch: 6| Step: 3
Training loss: 2.5875195967812123
Validation loss: 2.6356101612940948

Epoch: 6| Step: 4
Training loss: 2.5391509524857474
Validation loss: 2.6330682866331863

Epoch: 6| Step: 5
Training loss: 3.3190908540736292
Validation loss: 2.6109274586737747

Epoch: 6| Step: 6
Training loss: 3.1581517901285534
Validation loss: 2.6117831112120147

Epoch: 6| Step: 7
Training loss: 2.83441558438721
Validation loss: 2.588032293019548

Epoch: 6| Step: 8
Training loss: 2.6392020279547284
Validation loss: 2.5991803169247785

Epoch: 6| Step: 9
Training loss: 2.744829692734006
Validation loss: 2.5894423324837272

Epoch: 6| Step: 10
Training loss: 3.1246883999922135
Validation loss: 2.592798981099368

Epoch: 6| Step: 11
Training loss: 2.410880055858813
Validation loss: 2.5854092935777593

Epoch: 6| Step: 12
Training loss: 3.204367494345547
Validation loss: 2.5836140469858404

Epoch: 6| Step: 13
Training loss: 3.194809554607279
Validation loss: 2.565378873457291

Epoch: 177| Step: 0
Training loss: 2.8466619317628075
Validation loss: 2.5584013760671733

Epoch: 6| Step: 1
Training loss: 2.9453456886910767
Validation loss: 2.557742940881853

Epoch: 6| Step: 2
Training loss: 3.21296453419929
Validation loss: 2.5444014688660075

Epoch: 6| Step: 3
Training loss: 2.6143026821887174
Validation loss: 2.551050552694836

Epoch: 6| Step: 4
Training loss: 2.499463596018607
Validation loss: 2.534719469765033

Epoch: 6| Step: 5
Training loss: 3.134379843863094
Validation loss: 2.5416836555621916

Epoch: 6| Step: 6
Training loss: 2.12539321402876
Validation loss: 2.535108547538339

Epoch: 6| Step: 7
Training loss: 3.3943354261518546
Validation loss: 2.5415492539206217

Epoch: 6| Step: 8
Training loss: 2.485572957968107
Validation loss: 2.5431639908880124

Epoch: 6| Step: 9
Training loss: 3.1766638473653006
Validation loss: 2.5477249485774713

Epoch: 6| Step: 10
Training loss: 2.755388183108111
Validation loss: 2.561672095960334

Epoch: 6| Step: 11
Training loss: 2.164376687058296
Validation loss: 2.563816322730381

Epoch: 6| Step: 12
Training loss: 3.2623971564792664
Validation loss: 2.5796962430984984

Epoch: 6| Step: 13
Training loss: 3.10166412110167
Validation loss: 2.5945942672583713

Epoch: 178| Step: 0
Training loss: 3.342011044103339
Validation loss: 2.6197855401801817

Epoch: 6| Step: 1
Training loss: 3.3933474251005484
Validation loss: 2.611391165577373

Epoch: 6| Step: 2
Training loss: 2.6404071243962086
Validation loss: 2.591374511983424

Epoch: 6| Step: 3
Training loss: 2.7766909147244108
Validation loss: 2.5893665411632294

Epoch: 6| Step: 4
Training loss: 2.849738721415434
Validation loss: 2.558554035508847

Epoch: 6| Step: 5
Training loss: 3.038439218500427
Validation loss: 2.5544840433844813

Epoch: 6| Step: 6
Training loss: 2.5318766630605616
Validation loss: 2.5460721135778073

Epoch: 6| Step: 7
Training loss: 2.871712172980321
Validation loss: 2.5324991947561473

Epoch: 6| Step: 8
Training loss: 2.3608383794107404
Validation loss: 2.5261453515709538

Epoch: 6| Step: 9
Training loss: 3.1039462598002605
Validation loss: 2.522025878237935

Epoch: 6| Step: 10
Training loss: 3.103357367444691
Validation loss: 2.5235328515340916

Epoch: 6| Step: 11
Training loss: 2.6826067001865446
Validation loss: 2.534182044586174

Epoch: 6| Step: 12
Training loss: 2.8404088776377048
Validation loss: 2.5337514585964147

Epoch: 6| Step: 13
Training loss: 2.070345205372568
Validation loss: 2.5334087460448735

Epoch: 179| Step: 0
Training loss: 2.630243876503476
Validation loss: 2.5358029114403156

Epoch: 6| Step: 1
Training loss: 3.1482469676180442
Validation loss: 2.5453751908668405

Epoch: 6| Step: 2
Training loss: 2.6043162391941705
Validation loss: 2.5633471249483626

Epoch: 6| Step: 3
Training loss: 3.0465283318909346
Validation loss: 2.5730287938377288

Epoch: 6| Step: 4
Training loss: 2.853836950112881
Validation loss: 2.584660386390344

Epoch: 6| Step: 5
Training loss: 3.1873584790695695
Validation loss: 2.595824265084388

Epoch: 6| Step: 6
Training loss: 2.9798887395890454
Validation loss: 2.6082180308162792

Epoch: 6| Step: 7
Training loss: 3.3533043236612095
Validation loss: 2.6285267132196974

Epoch: 6| Step: 8
Training loss: 2.248011876288704
Validation loss: 2.6138190598005875

Epoch: 6| Step: 9
Training loss: 2.228299611059233
Validation loss: 2.6047368904851878

Epoch: 6| Step: 10
Training loss: 3.3877480954467565
Validation loss: 2.6034492318229376

Epoch: 6| Step: 11
Training loss: 3.097170393604699
Validation loss: 2.5706160281008796

Epoch: 6| Step: 12
Training loss: 2.1338815769417994
Validation loss: 2.5669814359733643

Epoch: 6| Step: 13
Training loss: 2.831099658199655
Validation loss: 2.555402060913823

Epoch: 180| Step: 0
Training loss: 2.4603497484513435
Validation loss: 2.5584330486000253

Epoch: 6| Step: 1
Training loss: 2.9216079997911013
Validation loss: 2.5480763058087397

Epoch: 6| Step: 2
Training loss: 2.6585311967483984
Validation loss: 2.5557203670690862

Epoch: 6| Step: 3
Training loss: 3.173032953273349
Validation loss: 2.552947959736697

Epoch: 6| Step: 4
Training loss: 2.854226401787555
Validation loss: 2.5495636241492328

Epoch: 6| Step: 5
Training loss: 2.9959427100435003
Validation loss: 2.5504692831729665

Epoch: 6| Step: 6
Training loss: 2.959903103556988
Validation loss: 2.5523075335937238

Epoch: 6| Step: 7
Training loss: 2.769615096745151
Validation loss: 2.5578600917124126

Epoch: 6| Step: 8
Training loss: 2.775682856766979
Validation loss: 2.562467027117397

Epoch: 6| Step: 9
Training loss: 3.316730173419889
Validation loss: 2.5605547184533557

Epoch: 6| Step: 10
Training loss: 2.90330963697373
Validation loss: 2.587495885529372

Epoch: 6| Step: 11
Training loss: 2.977960053206089
Validation loss: 2.575710183205484

Epoch: 6| Step: 12
Training loss: 2.3907436765247883
Validation loss: 2.559244470449192

Epoch: 6| Step: 13
Training loss: 2.777357914240649
Validation loss: 2.5729337720504555

Epoch: 181| Step: 0
Training loss: 3.1242540613627128
Validation loss: 2.5748575685102413

Epoch: 6| Step: 1
Training loss: 2.5679794900853516
Validation loss: 2.552891881225773

Epoch: 6| Step: 2
Training loss: 2.4724708234494575
Validation loss: 2.571982229777456

Epoch: 6| Step: 3
Training loss: 2.8168516613704613
Validation loss: 2.572743889338707

Epoch: 6| Step: 4
Training loss: 2.252546564736488
Validation loss: 2.569896840056498

Epoch: 6| Step: 5
Training loss: 2.707758642014336
Validation loss: 2.5667791685782064

Epoch: 6| Step: 6
Training loss: 3.1647616897223676
Validation loss: 2.558197455208038

Epoch: 6| Step: 7
Training loss: 3.1221349170767247
Validation loss: 2.5561653672580658

Epoch: 6| Step: 8
Training loss: 2.799128386529221
Validation loss: 2.547336105055822

Epoch: 6| Step: 9
Training loss: 3.390185490262477
Validation loss: 2.5526110252771326

Epoch: 6| Step: 10
Training loss: 3.449147553103319
Validation loss: 2.556224192109376

Epoch: 6| Step: 11
Training loss: 2.950179957703752
Validation loss: 2.560052573831613

Epoch: 6| Step: 12
Training loss: 2.401877257172087
Validation loss: 2.5602126018115183

Epoch: 6| Step: 13
Training loss: 1.7322459857336463
Validation loss: 2.559515579014711

Epoch: 182| Step: 0
Training loss: 2.8492167818791185
Validation loss: 2.5649378645445866

Epoch: 6| Step: 1
Training loss: 2.7265083722969425
Validation loss: 2.5720003517479935

Epoch: 6| Step: 2
Training loss: 2.513356862636825
Validation loss: 2.571473482663159

Epoch: 6| Step: 3
Training loss: 2.782892320913586
Validation loss: 2.5714342771503635

Epoch: 6| Step: 4
Training loss: 2.540975090952644
Validation loss: 2.571649755027362

Epoch: 6| Step: 5
Training loss: 3.2311715741850184
Validation loss: 2.5718392749392898

Epoch: 6| Step: 6
Training loss: 2.8166095803098212
Validation loss: 2.5738052737453136

Epoch: 6| Step: 7
Training loss: 2.8738860584520975
Validation loss: 2.5667253778670784

Epoch: 6| Step: 8
Training loss: 2.8609234728800037
Validation loss: 2.5708075358757023

Epoch: 6| Step: 9
Training loss: 3.113598279713766
Validation loss: 2.5629548300196245

Epoch: 6| Step: 10
Training loss: 2.7812829176422795
Validation loss: 2.563387357238856

Epoch: 6| Step: 11
Training loss: 2.6372036410336244
Validation loss: 2.550503376107347

Epoch: 6| Step: 12
Training loss: 3.101583869918115
Validation loss: 2.557666770519186

Epoch: 6| Step: 13
Training loss: 2.910246039931925
Validation loss: 2.5595882288834515

Epoch: 183| Step: 0
Training loss: 3.2958953993041553
Validation loss: 2.574072951449242

Epoch: 6| Step: 1
Training loss: 2.5601146109078567
Validation loss: 2.5607248676196646

Epoch: 6| Step: 2
Training loss: 2.6008803931120905
Validation loss: 2.568139358530001

Epoch: 6| Step: 3
Training loss: 1.7162236459907727
Validation loss: 2.5567420288773848

Epoch: 6| Step: 4
Training loss: 2.8012481257761346
Validation loss: 2.558395737537626

Epoch: 6| Step: 5
Training loss: 2.9973997927500635
Validation loss: 2.549943716066237

Epoch: 6| Step: 6
Training loss: 2.4881999962204415
Validation loss: 2.5490208241580867

Epoch: 6| Step: 7
Training loss: 3.194471626350376
Validation loss: 2.5539272522213885

Epoch: 6| Step: 8
Training loss: 3.214743630019428
Validation loss: 2.5624103155281404

Epoch: 6| Step: 9
Training loss: 2.8694936017132773
Validation loss: 2.5752219881305205

Epoch: 6| Step: 10
Training loss: 2.816343690386376
Validation loss: 2.5827309203451962

Epoch: 6| Step: 11
Training loss: 3.0614952463315284
Validation loss: 2.5909223605570735

Epoch: 6| Step: 12
Training loss: 2.9951044510855707
Validation loss: 2.5990452073844295

Epoch: 6| Step: 13
Training loss: 3.1219253673442577
Validation loss: 2.5946626803199693

Epoch: 184| Step: 0
Training loss: 2.638491880657751
Validation loss: 2.5791974056926965

Epoch: 6| Step: 1
Training loss: 1.9459704163626543
Validation loss: 2.5710092300862826

Epoch: 6| Step: 2
Training loss: 2.968177820580324
Validation loss: 2.573251345185547

Epoch: 6| Step: 3
Training loss: 2.7886017063437967
Validation loss: 2.5830903605567475

Epoch: 6| Step: 4
Training loss: 3.02400994611043
Validation loss: 2.588342909850446

Epoch: 6| Step: 5
Training loss: 2.666950886202996
Validation loss: 2.602594621888685

Epoch: 6| Step: 6
Training loss: 3.4354191811118437
Validation loss: 2.624972753974239

Epoch: 6| Step: 7
Training loss: 2.9602816617831897
Validation loss: 2.629350287168724

Epoch: 6| Step: 8
Training loss: 2.5943598202725617
Validation loss: 2.6077083152400804

Epoch: 6| Step: 9
Training loss: 3.2783851833021718
Validation loss: 2.5756203366262387

Epoch: 6| Step: 10
Training loss: 3.061523904754749
Validation loss: 2.566022972822353

Epoch: 6| Step: 11
Training loss: 2.7953876824287653
Validation loss: 2.556807065061

Epoch: 6| Step: 12
Training loss: 2.8636371136398764
Validation loss: 2.5449651758008303

Epoch: 6| Step: 13
Training loss: 2.552694400629055
Validation loss: 2.5522698808655706

Epoch: 185| Step: 0
Training loss: 3.2613598289141272
Validation loss: 2.5450302036874533

Epoch: 6| Step: 1
Training loss: 2.7574698691913735
Validation loss: 2.542929095943308

Epoch: 6| Step: 2
Training loss: 2.857055890939594
Validation loss: 2.5375525430666412

Epoch: 6| Step: 3
Training loss: 3.532001516668009
Validation loss: 2.5389145280933083

Epoch: 6| Step: 4
Training loss: 2.9386680391046514
Validation loss: 2.5374090574140675

Epoch: 6| Step: 5
Training loss: 2.1816856495745602
Validation loss: 2.5426806507268194

Epoch: 6| Step: 6
Training loss: 2.857440732005875
Validation loss: 2.5425297384462597

Epoch: 6| Step: 7
Training loss: 3.144190041173505
Validation loss: 2.544167278155327

Epoch: 6| Step: 8
Training loss: 2.775537861429213
Validation loss: 2.5484618022441974

Epoch: 6| Step: 9
Training loss: 2.4285956870398167
Validation loss: 2.5482400195171446

Epoch: 6| Step: 10
Training loss: 3.0332395965289605
Validation loss: 2.5622853625166515

Epoch: 6| Step: 11
Training loss: 2.361176567167638
Validation loss: 2.5607434947376273

Epoch: 6| Step: 12
Training loss: 2.4513625112620723
Validation loss: 2.567232489521048

Epoch: 6| Step: 13
Training loss: 3.1146812976412956
Validation loss: 2.5793323641807375

Epoch: 186| Step: 0
Training loss: 3.0521509121822374
Validation loss: 2.5850597885081044

Epoch: 6| Step: 1
Training loss: 2.664921865266153
Validation loss: 2.5905702217594833

Epoch: 6| Step: 2
Training loss: 3.4955724231592966
Validation loss: 2.605368375731944

Epoch: 6| Step: 3
Training loss: 2.5434805125109947
Validation loss: 2.617998297622927

Epoch: 6| Step: 4
Training loss: 2.4141812094725634
Validation loss: 2.598987536190564

Epoch: 6| Step: 5
Training loss: 2.003696363734284
Validation loss: 2.5812048888267687

Epoch: 6| Step: 6
Training loss: 2.898350305608098
Validation loss: 2.5593781281630346

Epoch: 6| Step: 7
Training loss: 2.905531271384657
Validation loss: 2.547783887808628

Epoch: 6| Step: 8
Training loss: 3.1220771853908555
Validation loss: 2.54228651805365

Epoch: 6| Step: 9
Training loss: 2.963115766567608
Validation loss: 2.535186188468881

Epoch: 6| Step: 10
Training loss: 3.398469771308702
Validation loss: 2.5372429741438918

Epoch: 6| Step: 11
Training loss: 2.859504571699239
Validation loss: 2.535029283138292

Epoch: 6| Step: 12
Training loss: 2.6197397114409444
Validation loss: 2.5384550967475263

Epoch: 6| Step: 13
Training loss: 2.6846870072286317
Validation loss: 2.5406764229851797

Epoch: 187| Step: 0
Training loss: 2.140886388259616
Validation loss: 2.5407262124990573

Epoch: 6| Step: 1
Training loss: 2.4174050704795573
Validation loss: 2.5380710955101824

Epoch: 6| Step: 2
Training loss: 3.1811230767192646
Validation loss: 2.5417738575340123

Epoch: 6| Step: 3
Training loss: 3.1356136898013953
Validation loss: 2.540880209333724

Epoch: 6| Step: 4
Training loss: 3.156060241433708
Validation loss: 2.566462162073239

Epoch: 6| Step: 5
Training loss: 3.0154475817102164
Validation loss: 2.575931093647371

Epoch: 6| Step: 6
Training loss: 2.789823967770849
Validation loss: 2.5884973173876813

Epoch: 6| Step: 7
Training loss: 2.8550285281812013
Validation loss: 2.5892951980919054

Epoch: 6| Step: 8
Training loss: 2.980414833791084
Validation loss: 2.608590647559033

Epoch: 6| Step: 9
Training loss: 1.4324933644086129
Validation loss: 2.5759128052592746

Epoch: 6| Step: 10
Training loss: 3.300685036966847
Validation loss: 2.566924298794781

Epoch: 6| Step: 11
Training loss: 2.657661691162525
Validation loss: 2.572944449323359

Epoch: 6| Step: 12
Training loss: 3.356320149915748
Validation loss: 2.560720314437039

Epoch: 6| Step: 13
Training loss: 3.0818601302107496
Validation loss: 2.5464125258077983

Epoch: 188| Step: 0
Training loss: 3.035300782836053
Validation loss: 2.5613190755810757

Epoch: 6| Step: 1
Training loss: 2.3250209930456602
Validation loss: 2.563642525749639

Epoch: 6| Step: 2
Training loss: 2.5292854691767443
Validation loss: 2.564798750163444

Epoch: 6| Step: 3
Training loss: 2.67401956077731
Validation loss: 2.5736350281033933

Epoch: 6| Step: 4
Training loss: 2.542458759974898
Validation loss: 2.578412959877243

Epoch: 6| Step: 5
Training loss: 3.450671675162044
Validation loss: 2.5791547889468442

Epoch: 6| Step: 6
Training loss: 2.8165104565012378
Validation loss: 2.573035987484204

Epoch: 6| Step: 7
Training loss: 3.3506474168252085
Validation loss: 2.573963305291567

Epoch: 6| Step: 8
Training loss: 2.598187981586146
Validation loss: 2.57688372062401

Epoch: 6| Step: 9
Training loss: 2.769228381987301
Validation loss: 2.576693376823147

Epoch: 6| Step: 10
Training loss: 2.364406651913497
Validation loss: 2.5785563088575936

Epoch: 6| Step: 11
Training loss: 3.199224562866743
Validation loss: 2.5765666160898117

Epoch: 6| Step: 12
Training loss: 3.129968279595564
Validation loss: 2.5778530540491214

Epoch: 6| Step: 13
Training loss: 2.835153855012422
Validation loss: 2.565104830620876

Epoch: 189| Step: 0
Training loss: 3.2734552715247007
Validation loss: 2.5555785219198768

Epoch: 6| Step: 1
Training loss: 2.604854757319912
Validation loss: 2.5489418797420167

Epoch: 6| Step: 2
Training loss: 2.716331985156226
Validation loss: 2.537536667464351

Epoch: 6| Step: 3
Training loss: 3.2227777261669526
Validation loss: 2.5320066371685517

Epoch: 6| Step: 4
Training loss: 2.9129612045873787
Validation loss: 2.5458120562254694

Epoch: 6| Step: 5
Training loss: 3.049222227891624
Validation loss: 2.530010847295156

Epoch: 6| Step: 6
Training loss: 2.8894004083630627
Validation loss: 2.533174075942702

Epoch: 6| Step: 7
Training loss: 3.1157422073341494
Validation loss: 2.5422138013205933

Epoch: 6| Step: 8
Training loss: 2.048658453040515
Validation loss: 2.5663403562382956

Epoch: 6| Step: 9
Training loss: 2.1204912935351214
Validation loss: 2.5712451630946758

Epoch: 6| Step: 10
Training loss: 2.5119588924008722
Validation loss: 2.583259186158594

Epoch: 6| Step: 11
Training loss: 2.6758703509343955
Validation loss: 2.6272101544340214

Epoch: 6| Step: 12
Training loss: 3.5980742602061464
Validation loss: 2.633750844954793

Epoch: 6| Step: 13
Training loss: 2.8067395877048686
Validation loss: 2.6214565008170867

Epoch: 190| Step: 0
Training loss: 2.47186179754346
Validation loss: 2.643333854806624

Epoch: 6| Step: 1
Training loss: 3.3003302091057103
Validation loss: 2.656322928482522

Epoch: 6| Step: 2
Training loss: 2.962688481898069
Validation loss: 2.670768471724168

Epoch: 6| Step: 3
Training loss: 2.7554498769721096
Validation loss: 2.700079196875916

Epoch: 6| Step: 4
Training loss: 3.121549761596559
Validation loss: 2.697016514326394

Epoch: 6| Step: 5
Training loss: 2.7411380509436323
Validation loss: 2.697770722952591

Epoch: 6| Step: 6
Training loss: 3.3525976614271413
Validation loss: 2.7176722869415064

Epoch: 6| Step: 7
Training loss: 3.1014837836358664
Validation loss: 2.69042770075687

Epoch: 6| Step: 8
Training loss: 2.979337425051008
Validation loss: 2.6518018458522468

Epoch: 6| Step: 9
Training loss: 2.7286614588633347
Validation loss: 2.6273958686304617

Epoch: 6| Step: 10
Training loss: 2.3631457581575654
Validation loss: 2.5955816671504954

Epoch: 6| Step: 11
Training loss: 2.792963969620035
Validation loss: 2.571232795750101

Epoch: 6| Step: 12
Training loss: 3.123387034906852
Validation loss: 2.565811877297961

Epoch: 6| Step: 13
Training loss: 2.350075286308581
Validation loss: 2.5644921573324204

Epoch: 191| Step: 0
Training loss: 3.0087320086484475
Validation loss: 2.5605505083821325

Epoch: 6| Step: 1
Training loss: 2.999855673815109
Validation loss: 2.5533848145914746

Epoch: 6| Step: 2
Training loss: 2.7503964398472562
Validation loss: 2.559263045234189

Epoch: 6| Step: 3
Training loss: 3.076485909069966
Validation loss: 2.555555817418429

Epoch: 6| Step: 4
Training loss: 2.8862788338788357
Validation loss: 2.5593398662603075

Epoch: 6| Step: 5
Training loss: 2.8818867341867622
Validation loss: 2.5657118700471555

Epoch: 6| Step: 6
Training loss: 2.986903851775443
Validation loss: 2.5623419788217907

Epoch: 6| Step: 7
Training loss: 2.710806807739932
Validation loss: 2.579662659208222

Epoch: 6| Step: 8
Training loss: 2.8639246697774987
Validation loss: 2.575065048308921

Epoch: 6| Step: 9
Training loss: 2.849388150575769
Validation loss: 2.5801765520185285

Epoch: 6| Step: 10
Training loss: 2.8179130174304015
Validation loss: 2.5826960865005972

Epoch: 6| Step: 11
Training loss: 3.000357924408444
Validation loss: 2.583628389205004

Epoch: 6| Step: 12
Training loss: 2.6467866957165382
Validation loss: 2.581545539298142

Epoch: 6| Step: 13
Training loss: 3.0185218298316827
Validation loss: 2.5678607702647818

Epoch: 192| Step: 0
Training loss: 3.46962761301703
Validation loss: 2.5692488135713023

Epoch: 6| Step: 1
Training loss: 3.652601851049139
Validation loss: 2.5533787699026256

Epoch: 6| Step: 2
Training loss: 2.6914953651678863
Validation loss: 2.5599081025594073

Epoch: 6| Step: 3
Training loss: 2.5609397790420383
Validation loss: 2.5528410787192075

Epoch: 6| Step: 4
Training loss: 2.729171073463512
Validation loss: 2.549546210471173

Epoch: 6| Step: 5
Training loss: 2.447277315664415
Validation loss: 2.5395022997234724

Epoch: 6| Step: 6
Training loss: 3.2551402011099055
Validation loss: 2.54999119931817

Epoch: 6| Step: 7
Training loss: 2.2835177293744473
Validation loss: 2.562738764114218

Epoch: 6| Step: 8
Training loss: 3.1644166347922336
Validation loss: 2.5824592519439182

Epoch: 6| Step: 9
Training loss: 2.850382019674039
Validation loss: 2.591513185045381

Epoch: 6| Step: 10
Training loss: 2.611230339096798
Validation loss: 2.6012154264841474

Epoch: 6| Step: 11
Training loss: 2.5139215044560173
Validation loss: 2.6130698722621926

Epoch: 6| Step: 12
Training loss: 2.347895909928168
Validation loss: 2.6194726133232753

Epoch: 6| Step: 13
Training loss: 2.610738341008379
Validation loss: 2.615920661498506

Epoch: 193| Step: 0
Training loss: 3.0653489543665553
Validation loss: 2.596500972470003

Epoch: 6| Step: 1
Training loss: 2.523796126920475
Validation loss: 2.5685764223060326

Epoch: 6| Step: 2
Training loss: 2.9849435953660985
Validation loss: 2.5746276377363864

Epoch: 6| Step: 3
Training loss: 2.709784886595671
Validation loss: 2.5735008566618123

Epoch: 6| Step: 4
Training loss: 2.4275411957094475
Validation loss: 2.548063211276002

Epoch: 6| Step: 5
Training loss: 2.3023049663568838
Validation loss: 2.5583407314116475

Epoch: 6| Step: 6
Training loss: 2.372629086486857
Validation loss: 2.5328267922666563

Epoch: 6| Step: 7
Training loss: 2.9108844844394786
Validation loss: 2.515424449959252

Epoch: 6| Step: 8
Training loss: 2.9164904586607143
Validation loss: 2.516677981539122

Epoch: 6| Step: 9
Training loss: 3.233544874317292
Validation loss: 2.52910836469467

Epoch: 6| Step: 10
Training loss: 3.243306529871036
Validation loss: 2.531032136114444

Epoch: 6| Step: 11
Training loss: 2.681314224861127
Validation loss: 2.533976013824068

Epoch: 6| Step: 12
Training loss: 3.1207253784196083
Validation loss: 2.5366102004163484

Epoch: 6| Step: 13
Training loss: 3.190576900825775
Validation loss: 2.5367364646074573

Epoch: 194| Step: 0
Training loss: 2.9565290581449175
Validation loss: 2.535565619786984

Epoch: 6| Step: 1
Training loss: 3.470820453401613
Validation loss: 2.528127954082963

Epoch: 6| Step: 2
Training loss: 2.828337181941396
Validation loss: 2.5257910724777743

Epoch: 6| Step: 3
Training loss: 3.069167683256217
Validation loss: 2.5419738919393917

Epoch: 6| Step: 4
Training loss: 2.1701585312696134
Validation loss: 2.5227170384515327

Epoch: 6| Step: 5
Training loss: 2.1657208310016487
Validation loss: 2.5251392734649873

Epoch: 6| Step: 6
Training loss: 2.286952898648861
Validation loss: 2.5515670933968546

Epoch: 6| Step: 7
Training loss: 2.855293070219886
Validation loss: 2.564610022473653

Epoch: 6| Step: 8
Training loss: 2.4208773619368014
Validation loss: 2.579902786236776

Epoch: 6| Step: 9
Training loss: 2.972023534422323
Validation loss: 2.626336608555989

Epoch: 6| Step: 10
Training loss: 3.3527656298605804
Validation loss: 2.64981114625295

Epoch: 6| Step: 11
Training loss: 3.2803570213469144
Validation loss: 2.618936905214157

Epoch: 6| Step: 12
Training loss: 2.9054600452150123
Validation loss: 2.6059505467768984

Epoch: 6| Step: 13
Training loss: 2.742438236956396
Validation loss: 2.607265478137527

Epoch: 195| Step: 0
Training loss: 2.929339172000938
Validation loss: 2.5538303763377614

Epoch: 6| Step: 1
Training loss: 3.0264311565520736
Validation loss: 2.559117527623056

Epoch: 6| Step: 2
Training loss: 2.6505304129611
Validation loss: 2.562456710373739

Epoch: 6| Step: 3
Training loss: 2.6743115475039168
Validation loss: 2.5492858126269304

Epoch: 6| Step: 4
Training loss: 2.715358504200771
Validation loss: 2.5592681088756994

Epoch: 6| Step: 5
Training loss: 2.9485276378767833
Validation loss: 2.5621929650054764

Epoch: 6| Step: 6
Training loss: 2.9453507074361998
Validation loss: 2.570076739724554

Epoch: 6| Step: 7
Training loss: 2.5907501889892908
Validation loss: 2.5688913825644026

Epoch: 6| Step: 8
Training loss: 2.882943995508375
Validation loss: 2.5621270999658328

Epoch: 6| Step: 9
Training loss: 2.8394969954114555
Validation loss: 2.547680414713916

Epoch: 6| Step: 10
Training loss: 3.2919183143965873
Validation loss: 2.5450443080374368

Epoch: 6| Step: 11
Training loss: 2.9514898385130355
Validation loss: 2.5386086819883187

Epoch: 6| Step: 12
Training loss: 3.020650994070403
Validation loss: 2.550692060066109

Epoch: 6| Step: 13
Training loss: 1.7353918857644586
Validation loss: 2.539857319885977

Epoch: 196| Step: 0
Training loss: 2.328590090590776
Validation loss: 2.5506967638197686

Epoch: 6| Step: 1
Training loss: 2.82603740042676
Validation loss: 2.5611933146108834

Epoch: 6| Step: 2
Training loss: 2.8170989688581756
Validation loss: 2.5662070181865015

Epoch: 6| Step: 3
Training loss: 3.2017634777846693
Validation loss: 2.5871053458415934

Epoch: 6| Step: 4
Training loss: 2.9512272948862384
Validation loss: 2.6081889822572495

Epoch: 6| Step: 5
Training loss: 3.3876785625396666
Validation loss: 2.6253929830411664

Epoch: 6| Step: 6
Training loss: 3.63163597169824
Validation loss: 2.619419482868735

Epoch: 6| Step: 7
Training loss: 2.5297918947296134
Validation loss: 2.5750144433216717

Epoch: 6| Step: 8
Training loss: 2.1198551502766168
Validation loss: 2.5616708660156027

Epoch: 6| Step: 9
Training loss: 2.662741504157444
Validation loss: 2.554224744128197

Epoch: 6| Step: 10
Training loss: 2.7452344350294537
Validation loss: 2.5462861000876957

Epoch: 6| Step: 11
Training loss: 3.175319211036897
Validation loss: 2.5377642971711594

Epoch: 6| Step: 12
Training loss: 2.098911925403104
Validation loss: 2.5239340721761727

Epoch: 6| Step: 13
Training loss: 2.738743371646439
Validation loss: 2.5237061935848915

Epoch: 197| Step: 0
Training loss: 2.8204070099188026
Validation loss: 2.528435423851721

Epoch: 6| Step: 1
Training loss: 2.832730921114031
Validation loss: 2.5371717699697385

Epoch: 6| Step: 2
Training loss: 3.0312525169126148
Validation loss: 2.5254365700979733

Epoch: 6| Step: 3
Training loss: 3.0972661546025213
Validation loss: 2.5209639279911396

Epoch: 6| Step: 4
Training loss: 2.832666954513946
Validation loss: 2.5090135385547616

Epoch: 6| Step: 5
Training loss: 3.2020014583434215
Validation loss: 2.5215802680628787

Epoch: 6| Step: 6
Training loss: 2.912820259790282
Validation loss: 2.5370921324984006

Epoch: 6| Step: 7
Training loss: 3.146105335594123
Validation loss: 2.5390095376926927

Epoch: 6| Step: 8
Training loss: 2.743188832796895
Validation loss: 2.5489708899090524

Epoch: 6| Step: 9
Training loss: 2.6532589396713706
Validation loss: 2.5431181261408553

Epoch: 6| Step: 10
Training loss: 2.829359933565716
Validation loss: 2.5472675531551827

Epoch: 6| Step: 11
Training loss: 1.8111655485842983
Validation loss: 2.5664136639911845

Epoch: 6| Step: 12
Training loss: 2.62355564889691
Validation loss: 2.560079450306943

Epoch: 6| Step: 13
Training loss: 2.625946146887121
Validation loss: 2.570365162405404

Epoch: 198| Step: 0
Training loss: 2.5394761907577106
Validation loss: 2.5745549786021935

Epoch: 6| Step: 1
Training loss: 2.251979169339313
Validation loss: 2.5973532139179483

Epoch: 6| Step: 2
Training loss: 2.556071521898602
Validation loss: 2.6242613527157013

Epoch: 6| Step: 3
Training loss: 2.842631696537243
Validation loss: 2.6226817997513567

Epoch: 6| Step: 4
Training loss: 2.572161904852922
Validation loss: 2.6059750940353843

Epoch: 6| Step: 5
Training loss: 3.190508152300737
Validation loss: 2.5862725272612788

Epoch: 6| Step: 6
Training loss: 2.8968513035139396
Validation loss: 2.5935512663773688

Epoch: 6| Step: 7
Training loss: 3.0214638589114395
Validation loss: 2.549696075018541

Epoch: 6| Step: 8
Training loss: 3.1681490657492137
Validation loss: 2.548258488399148

Epoch: 6| Step: 9
Training loss: 2.2687232570280536
Validation loss: 2.532330516209532

Epoch: 6| Step: 10
Training loss: 2.821503448527485
Validation loss: 2.541048218441138

Epoch: 6| Step: 11
Training loss: 3.3911914264416696
Validation loss: 2.53024862037125

Epoch: 6| Step: 12
Training loss: 2.866475112932098
Validation loss: 2.5288541802255833

Epoch: 6| Step: 13
Training loss: 2.9244257762697012
Validation loss: 2.5381601340267834

Epoch: 199| Step: 0
Training loss: 2.7138005948896176
Validation loss: 2.5408475088044535

Epoch: 6| Step: 1
Training loss: 3.5256075720989433
Validation loss: 2.545728897558197

Epoch: 6| Step: 2
Training loss: 2.7596369859825907
Validation loss: 2.5443600048587838

Epoch: 6| Step: 3
Training loss: 2.7855386993069966
Validation loss: 2.5532100002881717

Epoch: 6| Step: 4
Training loss: 3.0441442528028397
Validation loss: 2.554462202281261

Epoch: 6| Step: 5
Training loss: 2.5783498954939668
Validation loss: 2.5452319402314507

Epoch: 6| Step: 6
Training loss: 3.1108459367214896
Validation loss: 2.5532657846499998

Epoch: 6| Step: 7
Training loss: 2.767189143916481
Validation loss: 2.5569165265015523

Epoch: 6| Step: 8
Training loss: 2.367025539787406
Validation loss: 2.560283338422787

Epoch: 6| Step: 9
Training loss: 3.0597496917672093
Validation loss: 2.5615800055929965

Epoch: 6| Step: 10
Training loss: 2.6408411422843554
Validation loss: 2.558653887684098

Epoch: 6| Step: 11
Training loss: 2.5437102518561248
Validation loss: 2.5565186029152316

Epoch: 6| Step: 12
Training loss: 2.537317327679767
Validation loss: 2.5480331524536566

Epoch: 6| Step: 13
Training loss: 2.911536382312573
Validation loss: 2.5413519904744084

Epoch: 200| Step: 0
Training loss: 2.7895114227515063
Validation loss: 2.5443047305558792

Epoch: 6| Step: 1
Training loss: 2.7323449146484013
Validation loss: 2.547924763287456

Epoch: 6| Step: 2
Training loss: 3.462344467030111
Validation loss: 2.552335255996429

Epoch: 6| Step: 3
Training loss: 2.8922248330944913
Validation loss: 2.5437814161171666

Epoch: 6| Step: 4
Training loss: 2.8127360774672043
Validation loss: 2.528448964766662

Epoch: 6| Step: 5
Training loss: 2.59363482116137
Validation loss: 2.5520197100532536

Epoch: 6| Step: 6
Training loss: 2.2890904135190135
Validation loss: 2.5470368292191274

Epoch: 6| Step: 7
Training loss: 3.1981096406217064
Validation loss: 2.558587012727884

Epoch: 6| Step: 8
Training loss: 2.4601239509679136
Validation loss: 2.541027118407511

Epoch: 6| Step: 9
Training loss: 3.372477401080811
Validation loss: 2.547436874963129

Epoch: 6| Step: 10
Training loss: 2.406733972008087
Validation loss: 2.558871686089938

Epoch: 6| Step: 11
Training loss: 2.460201092696267
Validation loss: 2.5628516563432826

Epoch: 6| Step: 12
Training loss: 2.9571808911938726
Validation loss: 2.5488186663311185

Epoch: 6| Step: 13
Training loss: 2.492031654579359
Validation loss: 2.546836453625558

Epoch: 201| Step: 0
Training loss: 2.4421546704409796
Validation loss: 2.548826840578393

Epoch: 6| Step: 1
Training loss: 2.5726500667772263
Validation loss: 2.5483827640555807

Epoch: 6| Step: 2
Training loss: 3.120679080616002
Validation loss: 2.5554300677643003

Epoch: 6| Step: 3
Training loss: 2.49440348770211
Validation loss: 2.540917906740381

Epoch: 6| Step: 4
Training loss: 2.635050560974651
Validation loss: 2.549369760308255

Epoch: 6| Step: 5
Training loss: 3.201109014502551
Validation loss: 2.5477471915707364

Epoch: 6| Step: 6
Training loss: 2.8922292845441904
Validation loss: 2.5476404656957405

Epoch: 6| Step: 7
Training loss: 2.8797329630499706
Validation loss: 2.550197026930967

Epoch: 6| Step: 8
Training loss: 2.688328282666256
Validation loss: 2.5451719165174

Epoch: 6| Step: 9
Training loss: 2.6387715352605867
Validation loss: 2.5490418107535726

Epoch: 6| Step: 10
Training loss: 3.3583156601004585
Validation loss: 2.552577524928929

Epoch: 6| Step: 11
Training loss: 2.586182366616561
Validation loss: 2.5643947558343463

Epoch: 6| Step: 12
Training loss: 2.656411917744196
Validation loss: 2.573547288655564

Epoch: 6| Step: 13
Training loss: 3.117229719521418
Validation loss: 2.5703952253728275

Epoch: 202| Step: 0
Training loss: 3.1129609712628836
Validation loss: 2.5743275721674443

Epoch: 6| Step: 1
Training loss: 2.4024745502374367
Validation loss: 2.5970971148986726

Epoch: 6| Step: 2
Training loss: 2.9133065805436216
Validation loss: 2.621573576816536

Epoch: 6| Step: 3
Training loss: 2.907916175924962
Validation loss: 2.6038344954429715

Epoch: 6| Step: 4
Training loss: 3.1980306168093207
Validation loss: 2.6363065625153803

Epoch: 6| Step: 5
Training loss: 2.788127154631852
Validation loss: 2.593925856573774

Epoch: 6| Step: 6
Training loss: 3.009134056768898
Validation loss: 2.5656661525758957

Epoch: 6| Step: 7
Training loss: 2.795589044835628
Validation loss: 2.5467750262447066

Epoch: 6| Step: 8
Training loss: 3.1468521556763767
Validation loss: 2.528882154662625

Epoch: 6| Step: 9
Training loss: 2.631006997093718
Validation loss: 2.522414077358398

Epoch: 6| Step: 10
Training loss: 2.591341026021251
Validation loss: 2.506424918259391

Epoch: 6| Step: 11
Training loss: 2.146389182481723
Validation loss: 2.5060845492577997

Epoch: 6| Step: 12
Training loss: 2.7426414005405864
Validation loss: 2.5061576954126314

Epoch: 6| Step: 13
Training loss: 3.1330092979509914
Validation loss: 2.5020723070432767

Epoch: 203| Step: 0
Training loss: 2.5893771526558833
Validation loss: 2.5046537277146137

Epoch: 6| Step: 1
Training loss: 3.1977559565981553
Validation loss: 2.504666795355162

Epoch: 6| Step: 2
Training loss: 2.6982265476100746
Validation loss: 2.506373032745637

Epoch: 6| Step: 3
Training loss: 3.4734157765782117
Validation loss: 2.5123392642942393

Epoch: 6| Step: 4
Training loss: 2.164443991186907
Validation loss: 2.5282764711043337

Epoch: 6| Step: 5
Training loss: 2.86558284083713
Validation loss: 2.548163368906315

Epoch: 6| Step: 6
Training loss: 2.6820154337940294
Validation loss: 2.5524421019490573

Epoch: 6| Step: 7
Training loss: 3.0660796750858594
Validation loss: 2.5644054236740996

Epoch: 6| Step: 8
Training loss: 2.935893491990722
Validation loss: 2.548551903634208

Epoch: 6| Step: 9
Training loss: 2.6781433817033444
Validation loss: 2.584203338070258

Epoch: 6| Step: 10
Training loss: 2.729424141733434
Validation loss: 2.572860154854056

Epoch: 6| Step: 11
Training loss: 2.7340807947193557
Validation loss: 2.600958646203797

Epoch: 6| Step: 12
Training loss: 2.4932485014037806
Validation loss: 2.578937880416419

Epoch: 6| Step: 13
Training loss: 2.9418730954224235
Validation loss: 2.579969621404594

Epoch: 204| Step: 0
Training loss: 2.7671514059649747
Validation loss: 2.5545662205808655

Epoch: 6| Step: 1
Training loss: 2.9712234633259333
Validation loss: 2.5352664166852628

Epoch: 6| Step: 2
Training loss: 2.9218263673049965
Validation loss: 2.5440256494345586

Epoch: 6| Step: 3
Training loss: 3.0097412266816086
Validation loss: 2.5509759773694594

Epoch: 6| Step: 4
Training loss: 2.450424359997138
Validation loss: 2.5316770551110137

Epoch: 6| Step: 5
Training loss: 2.5966812483835566
Validation loss: 2.519612390805141

Epoch: 6| Step: 6
Training loss: 2.94655965207972
Validation loss: 2.52432412883677

Epoch: 6| Step: 7
Training loss: 3.362372617896778
Validation loss: 2.517214148369615

Epoch: 6| Step: 8
Training loss: 1.9230281192749035
Validation loss: 2.527759341396907

Epoch: 6| Step: 9
Training loss: 3.0621308084723946
Validation loss: 2.5218487955961706

Epoch: 6| Step: 10
Training loss: 3.0784021243133672
Validation loss: 2.524839902968416

Epoch: 6| Step: 11
Training loss: 2.659115849743286
Validation loss: 2.549630933864847

Epoch: 6| Step: 12
Training loss: 2.29170798062162
Validation loss: 2.5371678868749403

Epoch: 6| Step: 13
Training loss: 3.3710861117562656
Validation loss: 2.5488502135306046

Epoch: 205| Step: 0
Training loss: 3.1859758510404763
Validation loss: 2.554890777858616

Epoch: 6| Step: 1
Training loss: 2.6038406066219957
Validation loss: 2.554562781405047

Epoch: 6| Step: 2
Training loss: 2.6568393726602895
Validation loss: 2.582411827627395

Epoch: 6| Step: 3
Training loss: 3.2434561947339757
Validation loss: 2.5885189733234513

Epoch: 6| Step: 4
Training loss: 2.22159823425547
Validation loss: 2.603241312001614

Epoch: 6| Step: 5
Training loss: 2.6396372375363577
Validation loss: 2.588860461674164

Epoch: 6| Step: 6
Training loss: 2.6801255649359494
Validation loss: 2.5753828454045835

Epoch: 6| Step: 7
Training loss: 3.118118032515329
Validation loss: 2.575374066599002

Epoch: 6| Step: 8
Training loss: 2.5818805506324987
Validation loss: 2.5354415804025123

Epoch: 6| Step: 9
Training loss: 3.182209486246226
Validation loss: 2.521363649966594

Epoch: 6| Step: 10
Training loss: 2.4784472300514406
Validation loss: 2.5115574694828733

Epoch: 6| Step: 11
Training loss: 2.884527921084254
Validation loss: 2.4985188382919024

Epoch: 6| Step: 12
Training loss: 2.4832584583165684
Validation loss: 2.511938827830413

Epoch: 6| Step: 13
Training loss: 3.585351833811683
Validation loss: 2.510723107734992

Epoch: 206| Step: 0
Training loss: 2.0456460073239144
Validation loss: 2.5137354381420556

Epoch: 6| Step: 1
Training loss: 2.7959905323419463
Validation loss: 2.5076348798309014

Epoch: 6| Step: 2
Training loss: 2.5915761823487338
Validation loss: 2.5104675789896747

Epoch: 6| Step: 3
Training loss: 2.896115753526559
Validation loss: 2.527611457312456

Epoch: 6| Step: 4
Training loss: 2.901476970638406
Validation loss: 2.5236337003149645

Epoch: 6| Step: 5
Training loss: 2.6064198829665264
Validation loss: 2.53012190879203

Epoch: 6| Step: 6
Training loss: 2.635278469478005
Validation loss: 2.5270072942682438

Epoch: 6| Step: 7
Training loss: 3.121850982970758
Validation loss: 2.5373060266162177

Epoch: 6| Step: 8
Training loss: 2.767045857591655
Validation loss: 2.5507227689884777

Epoch: 6| Step: 9
Training loss: 3.1045837292849927
Validation loss: 2.560959101325708

Epoch: 6| Step: 10
Training loss: 2.608311236433167
Validation loss: 2.5767766136725876

Epoch: 6| Step: 11
Training loss: 3.350230559201066
Validation loss: 2.5771697043568906

Epoch: 6| Step: 12
Training loss: 2.836505759397591
Validation loss: 2.5615655529353494

Epoch: 6| Step: 13
Training loss: 3.3388876098472386
Validation loss: 2.5402082182128347

Epoch: 207| Step: 0
Training loss: 2.847288508276819
Validation loss: 2.542083611895442

Epoch: 6| Step: 1
Training loss: 2.8581146631110226
Validation loss: 2.5338725596385756

Epoch: 6| Step: 2
Training loss: 2.7790393401741977
Validation loss: 2.5423542584091807

Epoch: 6| Step: 3
Training loss: 2.586253720221372
Validation loss: 2.5314289162968606

Epoch: 6| Step: 4
Training loss: 2.4609265524000046
Validation loss: 2.5387141173140018

Epoch: 6| Step: 5
Training loss: 2.8961979112810288
Validation loss: 2.5464146239065273

Epoch: 6| Step: 6
Training loss: 2.5791915999169257
Validation loss: 2.544411225567849

Epoch: 6| Step: 7
Training loss: 2.5084385550936217
Validation loss: 2.5309150339464783

Epoch: 6| Step: 8
Training loss: 3.349376614771854
Validation loss: 2.5350219816399755

Epoch: 6| Step: 9
Training loss: 3.4406122164094657
Validation loss: 2.5328849435603393

Epoch: 6| Step: 10
Training loss: 2.2154088182533327
Validation loss: 2.5523445218410625

Epoch: 6| Step: 11
Training loss: 3.2575762546423332
Validation loss: 2.543894394816189

Epoch: 6| Step: 12
Training loss: 2.681989476239454
Validation loss: 2.546814658167784

Epoch: 6| Step: 13
Training loss: 2.8983942321673624
Validation loss: 2.5560002244022995

Epoch: 208| Step: 0
Training loss: 3.0354545770676453
Validation loss: 2.546738378888137

Epoch: 6| Step: 1
Training loss: 2.8661906408991755
Validation loss: 2.5556375889930054

Epoch: 6| Step: 2
Training loss: 3.335643603491194
Validation loss: 2.558647447147992

Epoch: 6| Step: 3
Training loss: 2.4006867936058742
Validation loss: 2.556482231614362

Epoch: 6| Step: 4
Training loss: 2.463654002773043
Validation loss: 2.562912418323153

Epoch: 6| Step: 5
Training loss: 3.1361457424843997
Validation loss: 2.533983349699088

Epoch: 6| Step: 6
Training loss: 3.0043492579602247
Validation loss: 2.531034234301701

Epoch: 6| Step: 7
Training loss: 2.8959092786604925
Validation loss: 2.5438831925068053

Epoch: 6| Step: 8
Training loss: 2.946812902708507
Validation loss: 2.540809459226289

Epoch: 6| Step: 9
Training loss: 2.518108303216384
Validation loss: 2.5430531461380683

Epoch: 6| Step: 10
Training loss: 2.7152317126681846
Validation loss: 2.535732505963803

Epoch: 6| Step: 11
Training loss: 2.524385728806177
Validation loss: 2.5362227863389863

Epoch: 6| Step: 12
Training loss: 2.4966734689060472
Validation loss: 2.5508971145658093

Epoch: 6| Step: 13
Training loss: 2.774269172728022
Validation loss: 2.554182023866744

Epoch: 209| Step: 0
Training loss: 2.8710580421355183
Validation loss: 2.54393060345468

Epoch: 6| Step: 1
Training loss: 3.15559063057666
Validation loss: 2.5446664190269375

Epoch: 6| Step: 2
Training loss: 2.651387509993478
Validation loss: 2.542365480564224

Epoch: 6| Step: 3
Training loss: 3.2498039773366765
Validation loss: 2.5344160690612503

Epoch: 6| Step: 4
Training loss: 3.112724915003633
Validation loss: 2.5274582759386015

Epoch: 6| Step: 5
Training loss: 2.1858709536519503
Validation loss: 2.5322517550784154

Epoch: 6| Step: 6
Training loss: 3.394471267855048
Validation loss: 2.5245618657952558

Epoch: 6| Step: 7
Training loss: 2.123599656897952
Validation loss: 2.528259540499037

Epoch: 6| Step: 8
Training loss: 3.0563406215096416
Validation loss: 2.5249550948104083

Epoch: 6| Step: 9
Training loss: 2.260139295960759
Validation loss: 2.5262751730259736

Epoch: 6| Step: 10
Training loss: 3.197384337480013
Validation loss: 2.5547898674594096

Epoch: 6| Step: 11
Training loss: 2.594795935367078
Validation loss: 2.5362788483024152

Epoch: 6| Step: 12
Training loss: 2.205955040425996
Validation loss: 2.531330129655798

Epoch: 6| Step: 13
Training loss: 2.6948913245149693
Validation loss: 2.5402153958080844

Epoch: 210| Step: 0
Training loss: 2.816434016203283
Validation loss: 2.5457746135608184

Epoch: 6| Step: 1
Training loss: 3.8582739861842135
Validation loss: 2.5549654004639373

Epoch: 6| Step: 2
Training loss: 2.1989002166493963
Validation loss: 2.5799799307191815

Epoch: 6| Step: 3
Training loss: 2.6208047494304973
Validation loss: 2.5816963401440196

Epoch: 6| Step: 4
Training loss: 2.790745929690787
Validation loss: 2.5914086682479267

Epoch: 6| Step: 5
Training loss: 2.849374093375425
Validation loss: 2.6076184287670716

Epoch: 6| Step: 6
Training loss: 2.8650333305404008
Validation loss: 2.6090913858789757

Epoch: 6| Step: 7
Training loss: 2.7107143695040774
Validation loss: 2.571466105193376

Epoch: 6| Step: 8
Training loss: 2.6236973209553964
Validation loss: 2.5556777831540556

Epoch: 6| Step: 9
Training loss: 3.054937562195197
Validation loss: 2.5407652198592574

Epoch: 6| Step: 10
Training loss: 2.653855175462271
Validation loss: 2.5408161225596984

Epoch: 6| Step: 11
Training loss: 2.5782280178873314
Validation loss: 2.5341969255388297

Epoch: 6| Step: 12
Training loss: 2.7045877721461418
Validation loss: 2.5121082918679365

Epoch: 6| Step: 13
Training loss: 2.506031295099936
Validation loss: 2.5079853421387206

Epoch: 211| Step: 0
Training loss: 2.4865462693665945
Validation loss: 2.512647505011588

Epoch: 6| Step: 1
Training loss: 2.122845848132662
Validation loss: 2.5057670259032827

Epoch: 6| Step: 2
Training loss: 2.6540167901457385
Validation loss: 2.513168105364022

Epoch: 6| Step: 3
Training loss: 2.856313264843152
Validation loss: 2.5276826914409147

Epoch: 6| Step: 4
Training loss: 2.55449057470417
Validation loss: 2.5241701588992984

Epoch: 6| Step: 5
Training loss: 2.8125116136099195
Validation loss: 2.5397576836076543

Epoch: 6| Step: 6
Training loss: 2.6206303512333013
Validation loss: 2.5611389090966075

Epoch: 6| Step: 7
Training loss: 3.4143921018671786
Validation loss: 2.554923243460071

Epoch: 6| Step: 8
Training loss: 2.480418767951149
Validation loss: 2.5546930594093866

Epoch: 6| Step: 9
Training loss: 3.043791477304582
Validation loss: 2.5427801744880316

Epoch: 6| Step: 10
Training loss: 2.9811836475209947
Validation loss: 2.551145969512781

Epoch: 6| Step: 11
Training loss: 3.4580356668957233
Validation loss: 2.540749823430388

Epoch: 6| Step: 12
Training loss: 2.698159480613536
Validation loss: 2.5424482107914095

Epoch: 6| Step: 13
Training loss: 2.9515664160698942
Validation loss: 2.5527300917746905

Epoch: 212| Step: 0
Training loss: 2.865452046307441
Validation loss: 2.5669531546720603

Epoch: 6| Step: 1
Training loss: 3.1426891926068867
Validation loss: 2.581123652116166

Epoch: 6| Step: 2
Training loss: 2.9385391994404206
Validation loss: 2.568364126250256

Epoch: 6| Step: 3
Training loss: 2.411550752147233
Validation loss: 2.5665632258510214

Epoch: 6| Step: 4
Training loss: 2.4275852934038156
Validation loss: 2.5671796979424806

Epoch: 6| Step: 5
Training loss: 2.3588523033125184
Validation loss: 2.548273327391914

Epoch: 6| Step: 6
Training loss: 3.4878179535123763
Validation loss: 2.57176323598764

Epoch: 6| Step: 7
Training loss: 2.03563276046384
Validation loss: 2.559432821517017

Epoch: 6| Step: 8
Training loss: 2.882287119724082
Validation loss: 2.5498714248120784

Epoch: 6| Step: 9
Training loss: 3.126178824290586
Validation loss: 2.5534625679640284

Epoch: 6| Step: 10
Training loss: 2.9719234169787616
Validation loss: 2.5447751565172436

Epoch: 6| Step: 11
Training loss: 2.7683870994801936
Validation loss: 2.544140005850442

Epoch: 6| Step: 12
Training loss: 2.732583816234031
Validation loss: 2.54298426505854

Epoch: 6| Step: 13
Training loss: 2.7815421304620136
Validation loss: 2.5288596443635334

Epoch: 213| Step: 0
Training loss: 2.482183965752266
Validation loss: 2.5461330534720545

Epoch: 6| Step: 1
Training loss: 2.568269514825352
Validation loss: 2.545945740433195

Epoch: 6| Step: 2
Training loss: 2.585705242502466
Validation loss: 2.5379308791694672

Epoch: 6| Step: 3
Training loss: 3.1481630570135533
Validation loss: 2.5458235632239004

Epoch: 6| Step: 4
Training loss: 2.9467939703471493
Validation loss: 2.538980262251223

Epoch: 6| Step: 5
Training loss: 3.2394769943463735
Validation loss: 2.5502974415337722

Epoch: 6| Step: 6
Training loss: 2.8275538758289525
Validation loss: 2.534619869207761

Epoch: 6| Step: 7
Training loss: 2.038404336577972
Validation loss: 2.515044056409822

Epoch: 6| Step: 8
Training loss: 2.645805558987515
Validation loss: 2.5336153885612025

Epoch: 6| Step: 9
Training loss: 2.48997614699739
Validation loss: 2.536137410835947

Epoch: 6| Step: 10
Training loss: 2.7501038618414992
Validation loss: 2.5348896469342472

Epoch: 6| Step: 11
Training loss: 3.024819228390503
Validation loss: 2.5359750892805653

Epoch: 6| Step: 12
Training loss: 2.9089015227139705
Validation loss: 2.540761773605955

Epoch: 6| Step: 13
Training loss: 3.596608758082511
Validation loss: 2.5407392066105507

Epoch: 214| Step: 0
Training loss: 2.906797131955585
Validation loss: 2.5499682801887915

Epoch: 6| Step: 1
Training loss: 2.221555413763271
Validation loss: 2.5705629240413517

Epoch: 6| Step: 2
Training loss: 2.7615616253260824
Validation loss: 2.590160306909961

Epoch: 6| Step: 3
Training loss: 2.1110759517463475
Validation loss: 2.5849575139692202

Epoch: 6| Step: 4
Training loss: 2.812050507972289
Validation loss: 2.5949098514418374

Epoch: 6| Step: 5
Training loss: 3.058945286062266
Validation loss: 2.589806124298294

Epoch: 6| Step: 6
Training loss: 2.5649289970163127
Validation loss: 2.5865080165395824

Epoch: 6| Step: 7
Training loss: 2.572216129044012
Validation loss: 2.613096860758291

Epoch: 6| Step: 8
Training loss: 2.7321705678750896
Validation loss: 2.5986111204913045

Epoch: 6| Step: 9
Training loss: 3.1849468702259554
Validation loss: 2.609450841888001

Epoch: 6| Step: 10
Training loss: 3.50586454343282
Validation loss: 2.597043647115883

Epoch: 6| Step: 11
Training loss: 3.2345362821163635
Validation loss: 2.554317140823214

Epoch: 6| Step: 12
Training loss: 2.454295468364132
Validation loss: 2.543824527718307

Epoch: 6| Step: 13
Training loss: 2.477417807192409
Validation loss: 2.53128010417822

Epoch: 215| Step: 0
Training loss: 3.2034298635407956
Validation loss: 2.513369856467554

Epoch: 6| Step: 1
Training loss: 3.164131220318546
Validation loss: 2.5048975277260395

Epoch: 6| Step: 2
Training loss: 2.67862985274767
Validation loss: 2.4974329433250086

Epoch: 6| Step: 3
Training loss: 2.4664442666633764
Validation loss: 2.4935094949475665

Epoch: 6| Step: 4
Training loss: 3.174587649504226
Validation loss: 2.4903855970722417

Epoch: 6| Step: 5
Training loss: 3.144776290918302
Validation loss: 2.4923744940299852

Epoch: 6| Step: 6
Training loss: 2.5965828190668585
Validation loss: 2.494609066601317

Epoch: 6| Step: 7
Training loss: 2.4715992384304855
Validation loss: 2.494491153833356

Epoch: 6| Step: 8
Training loss: 2.3062908220684206
Validation loss: 2.5015083336382444

Epoch: 6| Step: 9
Training loss: 2.414245401015241
Validation loss: 2.5085502293076014

Epoch: 6| Step: 10
Training loss: 3.068968811314207
Validation loss: 2.5132072323918493

Epoch: 6| Step: 11
Training loss: 2.6290486312785166
Validation loss: 2.536477684777144

Epoch: 6| Step: 12
Training loss: 3.1338321234673967
Validation loss: 2.540524285677179

Epoch: 6| Step: 13
Training loss: 2.5997195202588474
Validation loss: 2.551095901000051

Epoch: 216| Step: 0
Training loss: 2.3625943281123223
Validation loss: 2.578985486906447

Epoch: 6| Step: 1
Training loss: 3.1357377776070674
Validation loss: 2.575793700647325

Epoch: 6| Step: 2
Training loss: 2.849584442092346
Validation loss: 2.56616631061442

Epoch: 6| Step: 3
Training loss: 2.6068076106680493
Validation loss: 2.5635135145986223

Epoch: 6| Step: 4
Training loss: 2.6212221844697647
Validation loss: 2.5487621137423715

Epoch: 6| Step: 5
Training loss: 2.737215495893495
Validation loss: 2.563305055786699

Epoch: 6| Step: 6
Training loss: 2.3077184369979906
Validation loss: 2.552180122179165

Epoch: 6| Step: 7
Training loss: 3.0418158368325123
Validation loss: 2.5473836228243

Epoch: 6| Step: 8
Training loss: 3.204358268204531
Validation loss: 2.546655738703823

Epoch: 6| Step: 9
Training loss: 3.3475967099248685
Validation loss: 2.5441807222410526

Epoch: 6| Step: 10
Training loss: 2.656006925344056
Validation loss: 2.53981517051282

Epoch: 6| Step: 11
Training loss: 2.492135743946076
Validation loss: 2.518354340226488

Epoch: 6| Step: 12
Training loss: 2.766228044356392
Validation loss: 2.524101941702011

Epoch: 6| Step: 13
Training loss: 2.4788353535648566
Validation loss: 2.524246558529432

Epoch: 217| Step: 0
Training loss: 2.739549895301273
Validation loss: 2.5159777607524343

Epoch: 6| Step: 1
Training loss: 2.651114761953655
Validation loss: 2.5166240754815825

Epoch: 6| Step: 2
Training loss: 2.814451769604115
Validation loss: 2.5104201247921143

Epoch: 6| Step: 3
Training loss: 2.5292915962782754
Validation loss: 2.5232346549492393

Epoch: 6| Step: 4
Training loss: 3.1511143363370593
Validation loss: 2.52201401158286

Epoch: 6| Step: 5
Training loss: 2.5563693328834898
Validation loss: 2.5163141019000794

Epoch: 6| Step: 6
Training loss: 2.0285479840702654
Validation loss: 2.532924433006388

Epoch: 6| Step: 7
Training loss: 2.485003697720699
Validation loss: 2.5185623848595045

Epoch: 6| Step: 8
Training loss: 2.532740119026933
Validation loss: 2.520947657079016

Epoch: 6| Step: 9
Training loss: 3.165377421361555
Validation loss: 2.5313540586297822

Epoch: 6| Step: 10
Training loss: 2.99283730246376
Validation loss: 2.536606595403389

Epoch: 6| Step: 11
Training loss: 3.348359825240876
Validation loss: 2.541989786221481

Epoch: 6| Step: 12
Training loss: 2.682657358863766
Validation loss: 2.550065654655003

Epoch: 6| Step: 13
Training loss: 3.0153351481390964
Validation loss: 2.5564957533351405

Epoch: 218| Step: 0
Training loss: 2.71251551188591
Validation loss: 2.557010699776594

Epoch: 6| Step: 1
Training loss: 2.480163843833859
Validation loss: 2.5840227452263838

Epoch: 6| Step: 2
Training loss: 2.802891233088856
Validation loss: 2.6125051366574286

Epoch: 6| Step: 3
Training loss: 3.038422112548057
Validation loss: 2.5870677060777427

Epoch: 6| Step: 4
Training loss: 2.9129296112827867
Validation loss: 2.5932342440537686

Epoch: 6| Step: 5
Training loss: 3.056662464977886
Validation loss: 2.573583392884091

Epoch: 6| Step: 6
Training loss: 2.574543725486071
Validation loss: 2.554592094033514

Epoch: 6| Step: 7
Training loss: 2.4077517294471034
Validation loss: 2.5250705555216584

Epoch: 6| Step: 8
Training loss: 2.5926106719743993
Validation loss: 2.5186689239964166

Epoch: 6| Step: 9
Training loss: 2.9979110438488754
Validation loss: 2.5087273840887283

Epoch: 6| Step: 10
Training loss: 2.437276194152405
Validation loss: 2.4982213943424254

Epoch: 6| Step: 11
Training loss: 2.8215768785455713
Validation loss: 2.497155139816336

Epoch: 6| Step: 12
Training loss: 2.923358887227621
Validation loss: 2.4978431216335366

Epoch: 6| Step: 13
Training loss: 3.472920153516374
Validation loss: 2.492183575617615

Epoch: 219| Step: 0
Training loss: 2.023908287865443
Validation loss: 2.493204099846692

Epoch: 6| Step: 1
Training loss: 2.8378287910503786
Validation loss: 2.5067773516966625

Epoch: 6| Step: 2
Training loss: 2.554989671480985
Validation loss: 2.5068338839980426

Epoch: 6| Step: 3
Training loss: 2.0947321395977623
Validation loss: 2.5153015118279662

Epoch: 6| Step: 4
Training loss: 2.928938055183741
Validation loss: 2.507236220653856

Epoch: 6| Step: 5
Training loss: 2.8800962310184635
Validation loss: 2.531626073969058

Epoch: 6| Step: 6
Training loss: 3.3376334745884484
Validation loss: 2.5514281834328387

Epoch: 6| Step: 7
Training loss: 3.3494670159252924
Validation loss: 2.55721169169101

Epoch: 6| Step: 8
Training loss: 3.1718918372397944
Validation loss: 2.564739072428024

Epoch: 6| Step: 9
Training loss: 2.524862070376572
Validation loss: 2.5784491739471345

Epoch: 6| Step: 10
Training loss: 2.612101700641579
Validation loss: 2.5858785331765937

Epoch: 6| Step: 11
Training loss: 2.520954623076125
Validation loss: 2.564103636940589

Epoch: 6| Step: 12
Training loss: 2.8801058336521437
Validation loss: 2.5294519193602696

Epoch: 6| Step: 13
Training loss: 3.0260221094406647
Validation loss: 2.534650258033355

Epoch: 220| Step: 0
Training loss: 2.953383338568031
Validation loss: 2.553305752083493

Epoch: 6| Step: 1
Training loss: 3.1554020412993853
Validation loss: 2.5389499747281916

Epoch: 6| Step: 2
Training loss: 2.4863728101959564
Validation loss: 2.553559311726995

Epoch: 6| Step: 3
Training loss: 2.6239678306352188
Validation loss: 2.55124527357741

Epoch: 6| Step: 4
Training loss: 2.3546038758959082
Validation loss: 2.5610787867212483

Epoch: 6| Step: 5
Training loss: 3.3031837884007627
Validation loss: 2.5982696753876042

Epoch: 6| Step: 6
Training loss: 2.4575212290284467
Validation loss: 2.583235032880513

Epoch: 6| Step: 7
Training loss: 2.91811287765289
Validation loss: 2.561174844912676

Epoch: 6| Step: 8
Training loss: 2.7737344072478685
Validation loss: 2.5374212264001845

Epoch: 6| Step: 9
Training loss: 2.496940457246366
Validation loss: 2.551929188121207

Epoch: 6| Step: 10
Training loss: 2.734276644436431
Validation loss: 2.5356871548646325

Epoch: 6| Step: 11
Training loss: 3.039377230549864
Validation loss: 2.545822815023868

Epoch: 6| Step: 12
Training loss: 2.561763750700735
Validation loss: 2.5450195382407776

Epoch: 6| Step: 13
Training loss: 2.8269431663929194
Validation loss: 2.531330182319538

Epoch: 221| Step: 0
Training loss: 3.04000188827456
Validation loss: 2.5226577107116754

Epoch: 6| Step: 1
Training loss: 2.933734509460096
Validation loss: 2.55486230652617

Epoch: 6| Step: 2
Training loss: 2.8769156666561773
Validation loss: 2.555598772523809

Epoch: 6| Step: 3
Training loss: 2.4340153752940776
Validation loss: 2.5384621510401075

Epoch: 6| Step: 4
Training loss: 2.679820332696475
Validation loss: 2.520173863106816

Epoch: 6| Step: 5
Training loss: 2.267622810074628
Validation loss: 2.5345585199921024

Epoch: 6| Step: 6
Training loss: 3.0278627012360753
Validation loss: 2.523583233253688

Epoch: 6| Step: 7
Training loss: 2.56204759279308
Validation loss: 2.5341963044049596

Epoch: 6| Step: 8
Training loss: 2.61463580642468
Validation loss: 2.537821339801484

Epoch: 6| Step: 9
Training loss: 2.7762771897785825
Validation loss: 2.538262850891049

Epoch: 6| Step: 10
Training loss: 2.9120126013535543
Validation loss: 2.536907302779367

Epoch: 6| Step: 11
Training loss: 3.136148327258519
Validation loss: 2.5795640167974354

Epoch: 6| Step: 12
Training loss: 2.811504866130267
Validation loss: 2.5586827376401837

Epoch: 6| Step: 13
Training loss: 2.4003433458779573
Validation loss: 2.5431432823988294

Epoch: 222| Step: 0
Training loss: 2.347483395323767
Validation loss: 2.525466479643629

Epoch: 6| Step: 1
Training loss: 2.4797915037250653
Validation loss: 2.521679803152973

Epoch: 6| Step: 2
Training loss: 3.1996992446709203
Validation loss: 2.5460976222608362

Epoch: 6| Step: 3
Training loss: 2.725323677088184
Validation loss: 2.550182492672814

Epoch: 6| Step: 4
Training loss: 2.9321238242175984
Validation loss: 2.5438707233795217

Epoch: 6| Step: 5
Training loss: 2.8054050388394542
Validation loss: 2.521910456027856

Epoch: 6| Step: 6
Training loss: 3.1559393701567635
Validation loss: 2.505966664936189

Epoch: 6| Step: 7
Training loss: 2.600577686395566
Validation loss: 2.5150539427979313

Epoch: 6| Step: 8
Training loss: 3.067006124146438
Validation loss: 2.519276323114299

Epoch: 6| Step: 9
Training loss: 2.6268352269373043
Validation loss: 2.523729934289588

Epoch: 6| Step: 10
Training loss: 2.3494289516009217
Validation loss: 2.510801627808903

Epoch: 6| Step: 11
Training loss: 2.4132581438642244
Validation loss: 2.514500291591962

Epoch: 6| Step: 12
Training loss: 3.112047283539071
Validation loss: 2.5140871445208695

Epoch: 6| Step: 13
Training loss: 2.4505093959713053
Validation loss: 2.5129376498356697

Epoch: 223| Step: 0
Training loss: 1.9101895132464537
Validation loss: 2.543372634906376

Epoch: 6| Step: 1
Training loss: 3.0301779198106518
Validation loss: 2.581006643399169

Epoch: 6| Step: 2
Training loss: 2.8305724286878533
Validation loss: 2.607988931235613

Epoch: 6| Step: 3
Training loss: 3.0729686323179353
Validation loss: 2.6290345612193806

Epoch: 6| Step: 4
Training loss: 2.5163983406196038
Validation loss: 2.611145538868785

Epoch: 6| Step: 5
Training loss: 2.786503320253572
Validation loss: 2.6009524602431764

Epoch: 6| Step: 6
Training loss: 2.7249066153107533
Validation loss: 2.5337122602883975

Epoch: 6| Step: 7
Training loss: 2.3436323009183755
Validation loss: 2.5024224583558485

Epoch: 6| Step: 8
Training loss: 3.488633636753687
Validation loss: 2.4852374553283623

Epoch: 6| Step: 9
Training loss: 2.5140203250740147
Validation loss: 2.4796559723092235

Epoch: 6| Step: 10
Training loss: 3.000242859229144
Validation loss: 2.486453515370023

Epoch: 6| Step: 11
Training loss: 3.1996742082691014
Validation loss: 2.4856300055391802

Epoch: 6| Step: 12
Training loss: 2.5361328125
Validation loss: 2.484429190966856

Epoch: 6| Step: 13
Training loss: 3.194450131471151
Validation loss: 2.4987326096147884

Epoch: 224| Step: 0
Training loss: 3.197383740945906
Validation loss: 2.4999194224508217

Epoch: 6| Step: 1
Training loss: 3.0164169299478276
Validation loss: 2.5097502661879427

Epoch: 6| Step: 2
Training loss: 2.2944811328769776
Validation loss: 2.5001231399070547

Epoch: 6| Step: 3
Training loss: 2.891329952574303
Validation loss: 2.512303306485324

Epoch: 6| Step: 4
Training loss: 2.5474089080427174
Validation loss: 2.5108520648672354

Epoch: 6| Step: 5
Training loss: 3.4147617488206254
Validation loss: 2.5142429055474436

Epoch: 6| Step: 6
Training loss: 2.6578045054948474
Validation loss: 2.5277296810930068

Epoch: 6| Step: 7
Training loss: 2.701215565756337
Validation loss: 2.5392114557410776

Epoch: 6| Step: 8
Training loss: 2.75900718164287
Validation loss: 2.552607973144053

Epoch: 6| Step: 9
Training loss: 2.5165594983387933
Validation loss: 2.5598801056444214

Epoch: 6| Step: 10
Training loss: 2.6456136136673973
Validation loss: 2.5674102622842634

Epoch: 6| Step: 11
Training loss: 3.3024271275625945
Validation loss: 2.586387612452803

Epoch: 6| Step: 12
Training loss: 2.684999056341762
Validation loss: 2.5804895679036903

Epoch: 6| Step: 13
Training loss: 2.7752544630073364
Validation loss: 2.5569196090849298

Epoch: 225| Step: 0
Training loss: 2.7358259438647208
Validation loss: 2.52967071488111

Epoch: 6| Step: 1
Training loss: 2.916037210025604
Validation loss: 2.5166018793130385

Epoch: 6| Step: 2
Training loss: 2.7693512377863447
Validation loss: 2.5157179858902814

Epoch: 6| Step: 3
Training loss: 2.682629807772007
Validation loss: 2.506029915088371

Epoch: 6| Step: 4
Training loss: 2.54828197722729
Validation loss: 2.5072276316672872

Epoch: 6| Step: 5
Training loss: 2.9873543292806555
Validation loss: 2.510969802019026

Epoch: 6| Step: 6
Training loss: 2.3055746149197076
Validation loss: 2.5170402212198746

Epoch: 6| Step: 7
Training loss: 2.6567026089287484
Validation loss: 2.5176024642018953

Epoch: 6| Step: 8
Training loss: 3.036127629709713
Validation loss: 2.52897342855202

Epoch: 6| Step: 9
Training loss: 2.4968830705304588
Validation loss: 2.514906054724379

Epoch: 6| Step: 10
Training loss: 3.05549536751702
Validation loss: 2.5318435070370096

Epoch: 6| Step: 11
Training loss: 2.9825921450351687
Validation loss: 2.5274663742222554

Epoch: 6| Step: 12
Training loss: 2.8546984843025536
Validation loss: 2.5449667865340997

Epoch: 6| Step: 13
Training loss: 3.3028931853081
Validation loss: 2.540110145927888

Epoch: 226| Step: 0
Training loss: 2.855806719482775
Validation loss: 2.5711949415748596

Epoch: 6| Step: 1
Training loss: 2.266954860411174
Validation loss: 2.588546728825484

Epoch: 6| Step: 2
Training loss: 3.0110594031416995
Validation loss: 2.6205969534483136

Epoch: 6| Step: 3
Training loss: 2.713896354197353
Validation loss: 2.63265060511772

Epoch: 6| Step: 4
Training loss: 2.981621395625304
Validation loss: 2.6385901612512694

Epoch: 6| Step: 5
Training loss: 2.6461160663917234
Validation loss: 2.607169603814577

Epoch: 6| Step: 6
Training loss: 2.483099171993604
Validation loss: 2.599100515961374

Epoch: 6| Step: 7
Training loss: 2.629745916124602
Validation loss: 2.5552398394627263

Epoch: 6| Step: 8
Training loss: 2.96536383006425
Validation loss: 2.561845629337937

Epoch: 6| Step: 9
Training loss: 3.04224971948604
Validation loss: 2.5407223398817678

Epoch: 6| Step: 10
Training loss: 2.788513471489114
Validation loss: 2.51565196795369

Epoch: 6| Step: 11
Training loss: 2.8429084622583742
Validation loss: 2.495915114071103

Epoch: 6| Step: 12
Training loss: 2.6305978215962273
Validation loss: 2.4848698526728863

Epoch: 6| Step: 13
Training loss: 2.2822067135823842
Validation loss: 2.4767583892046914

Epoch: 227| Step: 0
Training loss: 2.9092837670728366
Validation loss: 2.4782578817468295

Epoch: 6| Step: 1
Training loss: 2.7585278844843204
Validation loss: 2.4774801057194553

Epoch: 6| Step: 2
Training loss: 2.6126936407284216
Validation loss: 2.4791516491159444

Epoch: 6| Step: 3
Training loss: 2.5709326091704536
Validation loss: 2.4787546837361436

Epoch: 6| Step: 4
Training loss: 2.7090546943322398
Validation loss: 2.4872506859606736

Epoch: 6| Step: 5
Training loss: 2.9099869851676683
Validation loss: 2.486723112327672

Epoch: 6| Step: 6
Training loss: 3.0993379932001206
Validation loss: 2.4903018501690246

Epoch: 6| Step: 7
Training loss: 2.6729041008320658
Validation loss: 2.505791182110407

Epoch: 6| Step: 8
Training loss: 2.717285989793785
Validation loss: 2.5006590292453033

Epoch: 6| Step: 9
Training loss: 2.952437063349041
Validation loss: 2.5036609844307374

Epoch: 6| Step: 10
Training loss: 3.3809078924883824
Validation loss: 2.5138095681240964

Epoch: 6| Step: 11
Training loss: 2.7584290072011197
Validation loss: 2.52251826673715

Epoch: 6| Step: 12
Training loss: 2.545952190948163
Validation loss: 2.540692778439552

Epoch: 6| Step: 13
Training loss: 2.9991574693775327
Validation loss: 2.54015756270639

Epoch: 228| Step: 0
Training loss: 2.4125895033920384
Validation loss: 2.5340333607605245

Epoch: 6| Step: 1
Training loss: 2.7231192721870707
Validation loss: 2.543898855167817

Epoch: 6| Step: 2
Training loss: 3.066574811250827
Validation loss: 2.5387574341214267

Epoch: 6| Step: 3
Training loss: 2.969934488209767
Validation loss: 2.5360843722795687

Epoch: 6| Step: 4
Training loss: 2.7773605753929522
Validation loss: 2.526021386485785

Epoch: 6| Step: 5
Training loss: 2.987022623523696
Validation loss: 2.5163399886563456

Epoch: 6| Step: 6
Training loss: 2.7616314692106583
Validation loss: 2.521173935364358

Epoch: 6| Step: 7
Training loss: 2.8509943984079342
Validation loss: 2.5189821484856014

Epoch: 6| Step: 8
Training loss: 3.470781985510237
Validation loss: 2.512119637912337

Epoch: 6| Step: 9
Training loss: 2.843374038828275
Validation loss: 2.529729634933386

Epoch: 6| Step: 10
Training loss: 2.3438181549335257
Validation loss: 2.5480117490601257

Epoch: 6| Step: 11
Training loss: 1.8286241029386063
Validation loss: 2.571175392106938

Epoch: 6| Step: 12
Training loss: 2.734866114517703
Validation loss: 2.5816553946955696

Epoch: 6| Step: 13
Training loss: 3.0454168498528533
Validation loss: 2.5758518533121864

Epoch: 229| Step: 0
Training loss: 2.832877197200137
Validation loss: 2.603064159365845

Epoch: 6| Step: 1
Training loss: 3.618173551353954
Validation loss: 2.569708023882521

Epoch: 6| Step: 2
Training loss: 2.785193658392931
Validation loss: 2.560718855775018

Epoch: 6| Step: 3
Training loss: 2.3163687846095398
Validation loss: 2.5189897239384043

Epoch: 6| Step: 4
Training loss: 3.0123713042441813
Validation loss: 2.523242167342351

Epoch: 6| Step: 5
Training loss: 3.230964373539432
Validation loss: 2.497101132624108

Epoch: 6| Step: 6
Training loss: 2.6238637008856225
Validation loss: 2.495762674432347

Epoch: 6| Step: 7
Training loss: 3.0807013404258075
Validation loss: 2.476409679658965

Epoch: 6| Step: 8
Training loss: 2.72736222308155
Validation loss: 2.50008821639421

Epoch: 6| Step: 9
Training loss: 2.393662063138773
Validation loss: 2.4996879505941805

Epoch: 6| Step: 10
Training loss: 2.9482387910401933
Validation loss: 2.50182961814571

Epoch: 6| Step: 11
Training loss: 2.5179002790997744
Validation loss: 2.502250734954219

Epoch: 6| Step: 12
Training loss: 1.822094875566359
Validation loss: 2.5042410614470967

Epoch: 6| Step: 13
Training loss: 2.716783097079325
Validation loss: 2.4973456483901084

Epoch: 230| Step: 0
Training loss: 3.435605168457976
Validation loss: 2.5194727345290384

Epoch: 6| Step: 1
Training loss: 2.9322085507110986
Validation loss: 2.53322395421583

Epoch: 6| Step: 2
Training loss: 2.332180510429572
Validation loss: 2.5258746693379366

Epoch: 6| Step: 3
Training loss: 2.738768268978694
Validation loss: 2.592345165541281

Epoch: 6| Step: 4
Training loss: 2.4030095860182508
Validation loss: 2.589714879948964

Epoch: 6| Step: 5
Training loss: 2.736093384437347
Validation loss: 2.584754701350119

Epoch: 6| Step: 6
Training loss: 2.7610459863908177
Validation loss: 2.627214198160253

Epoch: 6| Step: 7
Training loss: 2.9945871476813952
Validation loss: 2.6239306043677124

Epoch: 6| Step: 8
Training loss: 2.729885841330285
Validation loss: 2.615711337669315

Epoch: 6| Step: 9
Training loss: 2.6274545183972906
Validation loss: 2.61033830011359

Epoch: 6| Step: 10
Training loss: 2.6674126733931183
Validation loss: 2.5902240804095156

Epoch: 6| Step: 11
Training loss: 2.6841287981844166
Validation loss: 2.555375030907074

Epoch: 6| Step: 12
Training loss: 2.7343962750288413
Validation loss: 2.5427004223003316

Epoch: 6| Step: 13
Training loss: 2.7901273345602533
Validation loss: 2.5172438857285955

Epoch: 231| Step: 0
Training loss: 2.8263026314668127
Validation loss: 2.503465410263033

Epoch: 6| Step: 1
Training loss: 2.4208901648708996
Validation loss: 2.49133626116518

Epoch: 6| Step: 2
Training loss: 2.5298827446465095
Validation loss: 2.4838455811441627

Epoch: 6| Step: 3
Training loss: 3.2030675371179527
Validation loss: 2.477760469024346

Epoch: 6| Step: 4
Training loss: 2.605680397050545
Validation loss: 2.476558489783475

Epoch: 6| Step: 5
Training loss: 3.0218968766376237
Validation loss: 2.4831140927118613

Epoch: 6| Step: 6
Training loss: 3.466298929908437
Validation loss: 2.476830628385858

Epoch: 6| Step: 7
Training loss: 2.732705876586148
Validation loss: 2.4854066398744368

Epoch: 6| Step: 8
Training loss: 2.263310164088154
Validation loss: 2.4854168009369655

Epoch: 6| Step: 9
Training loss: 2.4048876187720998
Validation loss: 2.482920643477207

Epoch: 6| Step: 10
Training loss: 2.5449411738403906
Validation loss: 2.4905403869603298

Epoch: 6| Step: 11
Training loss: 2.8136211280001278
Validation loss: 2.4942610282923554

Epoch: 6| Step: 12
Training loss: 3.063438738758771
Validation loss: 2.5192820207059268

Epoch: 6| Step: 13
Training loss: 2.7034470912016677
Validation loss: 2.515494540238093

Epoch: 232| Step: 0
Training loss: 2.4392394681630654
Validation loss: 2.5632502800313905

Epoch: 6| Step: 1
Training loss: 2.9014316116416894
Validation loss: 2.5948536028990183

Epoch: 6| Step: 2
Training loss: 2.1912206343376672
Validation loss: 2.666765562718087

Epoch: 6| Step: 3
Training loss: 2.5086287361492414
Validation loss: 2.624629859396346

Epoch: 6| Step: 4
Training loss: 2.9973644759821725
Validation loss: 2.6282947058579436

Epoch: 6| Step: 5
Training loss: 2.758022743402418
Validation loss: 2.6324024861598923

Epoch: 6| Step: 6
Training loss: 2.924300385624112
Validation loss: 2.6214327669591295

Epoch: 6| Step: 7
Training loss: 2.32035092922459
Validation loss: 2.648617532781766

Epoch: 6| Step: 8
Training loss: 2.928496339878728
Validation loss: 2.6072834394316784

Epoch: 6| Step: 9
Training loss: 3.247330082419182
Validation loss: 2.5592620645594324

Epoch: 6| Step: 10
Training loss: 2.7366700050745623
Validation loss: 2.5092642168539454

Epoch: 6| Step: 11
Training loss: 2.9600870727928976
Validation loss: 2.4942733826064285

Epoch: 6| Step: 12
Training loss: 3.0391638574638664
Validation loss: 2.4889117750323217

Epoch: 6| Step: 13
Training loss: 2.6797536057751272
Validation loss: 2.4973157120709804

Epoch: 233| Step: 0
Training loss: 3.02730153700408
Validation loss: 2.5121667002838777

Epoch: 6| Step: 1
Training loss: 2.64157647140348
Validation loss: 2.5161363605127507

Epoch: 6| Step: 2
Training loss: 2.881780506869062
Validation loss: 2.5218837491623356

Epoch: 6| Step: 3
Training loss: 3.122583294040794
Validation loss: 2.5267392175489953

Epoch: 6| Step: 4
Training loss: 2.8612581316097865
Validation loss: 2.532089547903391

Epoch: 6| Step: 5
Training loss: 3.0819781822209635
Validation loss: 2.528951932782196

Epoch: 6| Step: 6
Training loss: 2.232865470540868
Validation loss: 2.534890253739438

Epoch: 6| Step: 7
Training loss: 2.620409266414455
Validation loss: 2.539501668782679

Epoch: 6| Step: 8
Training loss: 3.302711563437632
Validation loss: 2.5361241919875455

Epoch: 6| Step: 9
Training loss: 2.6368386474476098
Validation loss: 2.5340199457971173

Epoch: 6| Step: 10
Training loss: 2.6164527886649322
Validation loss: 2.5228107527066874

Epoch: 6| Step: 11
Training loss: 2.652401728270268
Validation loss: 2.5306084276957757

Epoch: 6| Step: 12
Training loss: 2.921927058934212
Validation loss: 2.5358262972726546

Epoch: 6| Step: 13
Training loss: 2.7558391308057826
Validation loss: 2.5296703733556507

Epoch: 234| Step: 0
Training loss: 3.565001830626201
Validation loss: 2.5429361821829315

Epoch: 6| Step: 1
Training loss: 2.8010248692752335
Validation loss: 2.5742924080135516

Epoch: 6| Step: 2
Training loss: 2.1972049687808384
Validation loss: 2.583271510813152

Epoch: 6| Step: 3
Training loss: 3.27310929212139
Validation loss: 2.6009642792000727

Epoch: 6| Step: 4
Training loss: 2.527763886000174
Validation loss: 2.6256760070064176

Epoch: 6| Step: 5
Training loss: 2.234137462447385
Validation loss: 2.601533894971487

Epoch: 6| Step: 6
Training loss: 2.009861713036443
Validation loss: 2.5969279983554077

Epoch: 6| Step: 7
Training loss: 2.833143639291763
Validation loss: 2.5994137581075205

Epoch: 6| Step: 8
Training loss: 2.2011146842614733
Validation loss: 2.5935309048593873

Epoch: 6| Step: 9
Training loss: 3.2538256503560605
Validation loss: 2.5708406810010973

Epoch: 6| Step: 10
Training loss: 3.1359006354004553
Validation loss: 2.5452637816770927

Epoch: 6| Step: 11
Training loss: 3.1825496154897115
Validation loss: 2.5280153771457576

Epoch: 6| Step: 12
Training loss: 2.538467666200653
Validation loss: 2.5177452941812954

Epoch: 6| Step: 13
Training loss: 2.8798137668160018
Validation loss: 2.519807072904765

Epoch: 235| Step: 0
Training loss: 2.9972260684213676
Validation loss: 2.515566791117533

Epoch: 6| Step: 1
Training loss: 2.5085271369693456
Validation loss: 2.5033914542590714

Epoch: 6| Step: 2
Training loss: 2.7362182507997277
Validation loss: 2.491285766527905

Epoch: 6| Step: 3
Training loss: 2.9508750458248443
Validation loss: 2.4983161208325138

Epoch: 6| Step: 4
Training loss: 2.973188435341073
Validation loss: 2.4943674820314032

Epoch: 6| Step: 5
Training loss: 2.895325504115258
Validation loss: 2.526167765291468

Epoch: 6| Step: 6
Training loss: 2.482015677052922
Validation loss: 2.5119214615397354

Epoch: 6| Step: 7
Training loss: 3.0779064120217416
Validation loss: 2.525329307396277

Epoch: 6| Step: 8
Training loss: 2.4310338255185653
Validation loss: 2.5263003097747774

Epoch: 6| Step: 9
Training loss: 2.623441415116988
Validation loss: 2.525543875953077

Epoch: 6| Step: 10
Training loss: 2.2742233753321117
Validation loss: 2.5248808453042395

Epoch: 6| Step: 11
Training loss: 2.9940385396715543
Validation loss: 2.530916876466103

Epoch: 6| Step: 12
Training loss: 2.587106860973318
Validation loss: 2.5129137235157852

Epoch: 6| Step: 13
Training loss: 3.1676904295030988
Validation loss: 2.539132025613196

Epoch: 236| Step: 0
Training loss: 2.5490667355684495
Validation loss: 2.574350350610748

Epoch: 6| Step: 1
Training loss: 2.678543780956179
Validation loss: 2.6115505970395536

Epoch: 6| Step: 2
Training loss: 2.3051443907885756
Validation loss: 2.6343426548821576

Epoch: 6| Step: 3
Training loss: 2.560649296554741
Validation loss: 2.623384746374447

Epoch: 6| Step: 4
Training loss: 2.662030113198925
Validation loss: 2.6152781545545944

Epoch: 6| Step: 5
Training loss: 3.3138065280647173
Validation loss: 2.5869261923531974

Epoch: 6| Step: 6
Training loss: 3.40435626382506
Validation loss: 2.5776961510928356

Epoch: 6| Step: 7
Training loss: 2.5741531757344114
Validation loss: 2.5348109198081135

Epoch: 6| Step: 8
Training loss: 2.6869771581884927
Validation loss: 2.5054914868641593

Epoch: 6| Step: 9
Training loss: 2.3301548653409645
Validation loss: 2.4997860458045817

Epoch: 6| Step: 10
Training loss: 2.921866677012294
Validation loss: 2.499382447293177

Epoch: 6| Step: 11
Training loss: 2.942679201955272
Validation loss: 2.484658787774628

Epoch: 6| Step: 12
Training loss: 3.1252984476627015
Validation loss: 2.4888871593800164

Epoch: 6| Step: 13
Training loss: 1.8661569600505976
Validation loss: 2.490863618276691

Epoch: 237| Step: 0
Training loss: 2.762148897807808
Validation loss: 2.4913850075339354

Epoch: 6| Step: 1
Training loss: 3.159835138969872
Validation loss: 2.4993258438922226

Epoch: 6| Step: 2
Training loss: 2.9386811823800834
Validation loss: 2.488214267133016

Epoch: 6| Step: 3
Training loss: 2.720429701802855
Validation loss: 2.506644625299578

Epoch: 6| Step: 4
Training loss: 2.5766511345510765
Validation loss: 2.5097657097816892

Epoch: 6| Step: 5
Training loss: 2.8831778607503895
Validation loss: 2.514724906716846

Epoch: 6| Step: 6
Training loss: 2.791718060224421
Validation loss: 2.513147273137981

Epoch: 6| Step: 7
Training loss: 2.3051333238682976
Validation loss: 2.5075215218866003

Epoch: 6| Step: 8
Training loss: 2.909658422708896
Validation loss: 2.5031287089073753

Epoch: 6| Step: 9
Training loss: 2.7407414027758343
Validation loss: 2.5116564116928766

Epoch: 6| Step: 10
Training loss: 2.521750343768226
Validation loss: 2.525928683471683

Epoch: 6| Step: 11
Training loss: 3.0445748278812856
Validation loss: 2.5131454012690426

Epoch: 6| Step: 12
Training loss: 1.9167238378982017
Validation loss: 2.5246745703255717

Epoch: 6| Step: 13
Training loss: 2.8398664177117166
Validation loss: 2.54066399159895

Epoch: 238| Step: 0
Training loss: 2.3950267484441463
Validation loss: 2.5206321901153297

Epoch: 6| Step: 1
Training loss: 2.9951286502266794
Validation loss: 2.5222693590212533

Epoch: 6| Step: 2
Training loss: 2.5216838778429285
Validation loss: 2.5196619952371795

Epoch: 6| Step: 3
Training loss: 2.418621412698537
Validation loss: 2.527021107617959

Epoch: 6| Step: 4
Training loss: 2.2277946409167
Validation loss: 2.5174519060390286

Epoch: 6| Step: 5
Training loss: 2.9988358146088885
Validation loss: 2.5215318959901634

Epoch: 6| Step: 6
Training loss: 2.812338930392177
Validation loss: 2.5030097830340656

Epoch: 6| Step: 7
Training loss: 2.4513720426860135
Validation loss: 2.51230356567564

Epoch: 6| Step: 8
Training loss: 2.9277304661414867
Validation loss: 2.5232012908752304

Epoch: 6| Step: 9
Training loss: 2.7791048842792363
Validation loss: 2.523563771079413

Epoch: 6| Step: 10
Training loss: 2.6210455399697303
Validation loss: 2.5058228249468684

Epoch: 6| Step: 11
Training loss: 3.1942662249252556
Validation loss: 2.5191849421193213

Epoch: 6| Step: 12
Training loss: 2.851523537565581
Validation loss: 2.5207168347429794

Epoch: 6| Step: 13
Training loss: 2.8433473742169295
Validation loss: 2.521533653863272

Epoch: 239| Step: 0
Training loss: 2.7963916211678916
Validation loss: 2.5227762326904277

Epoch: 6| Step: 1
Training loss: 2.7709742823343118
Validation loss: 2.5471128705847823

Epoch: 6| Step: 2
Training loss: 2.2067127639396524
Validation loss: 2.5385415380003065

Epoch: 6| Step: 3
Training loss: 2.720725733765089
Validation loss: 2.575156034231601

Epoch: 6| Step: 4
Training loss: 2.7493859385771224
Validation loss: 2.5917748290341116

Epoch: 6| Step: 5
Training loss: 2.6536541989500027
Validation loss: 2.6393936916460086

Epoch: 6| Step: 6
Training loss: 2.9401113387843396
Validation loss: 2.702111878443821

Epoch: 6| Step: 7
Training loss: 2.882812665406923
Validation loss: 2.6333278710142625

Epoch: 6| Step: 8
Training loss: 3.1153410603303415
Validation loss: 2.585915543866029

Epoch: 6| Step: 9
Training loss: 2.3002927096323615
Validation loss: 2.5379627162535314

Epoch: 6| Step: 10
Training loss: 2.7161127212178755
Validation loss: 2.5273193220241272

Epoch: 6| Step: 11
Training loss: 2.669364597565557
Validation loss: 2.4883436680470976

Epoch: 6| Step: 12
Training loss: 3.030588923463963
Validation loss: 2.480800846662084

Epoch: 6| Step: 13
Training loss: 2.731219056257509
Validation loss: 2.477917613435845

Epoch: 240| Step: 0
Training loss: 2.7070079103374707
Validation loss: 2.468722624579589

Epoch: 6| Step: 1
Training loss: 2.6701507358649232
Validation loss: 2.464742658156873

Epoch: 6| Step: 2
Training loss: 2.985395965894835
Validation loss: 2.4770415737394087

Epoch: 6| Step: 3
Training loss: 3.057915974202961
Validation loss: 2.4751413007723015

Epoch: 6| Step: 4
Training loss: 2.6304502671773253
Validation loss: 2.476608596320486

Epoch: 6| Step: 5
Training loss: 2.9451685700803214
Validation loss: 2.4793850320092954

Epoch: 6| Step: 6
Training loss: 2.816018679719438
Validation loss: 2.4802914352674033

Epoch: 6| Step: 7
Training loss: 2.4476993112584235
Validation loss: 2.5085245125478277

Epoch: 6| Step: 8
Training loss: 2.9332255654334536
Validation loss: 2.5040530360008124

Epoch: 6| Step: 9
Training loss: 2.92831054881276
Validation loss: 2.5500684032076557

Epoch: 6| Step: 10
Training loss: 2.4940375752620185
Validation loss: 2.5676254118960613

Epoch: 6| Step: 11
Training loss: 2.611295073591789
Validation loss: 2.566007447202973

Epoch: 6| Step: 12
Training loss: 2.9978537829716028
Validation loss: 2.586697467161607

Epoch: 6| Step: 13
Training loss: 1.7860202159399585
Validation loss: 2.596359075357577

Epoch: 241| Step: 0
Training loss: 2.894383476902248
Validation loss: 2.620961240219243

Epoch: 6| Step: 1
Training loss: 2.428417990349283
Validation loss: 2.6269113591232403

Epoch: 6| Step: 2
Training loss: 2.16853294935431
Validation loss: 2.6352881762165703

Epoch: 6| Step: 3
Training loss: 1.9327481357031089
Validation loss: 2.632198746752991

Epoch: 6| Step: 4
Training loss: 2.4260140766449285
Validation loss: 2.6242126811578665

Epoch: 6| Step: 5
Training loss: 2.186219848983258
Validation loss: 2.6126274798056754

Epoch: 6| Step: 6
Training loss: 3.014976471260334
Validation loss: 2.5917813039679864

Epoch: 6| Step: 7
Training loss: 3.2965533203552635
Validation loss: 2.5868930075560472

Epoch: 6| Step: 8
Training loss: 3.4010897404698825
Validation loss: 2.548483641960014

Epoch: 6| Step: 9
Training loss: 2.819580574904304
Validation loss: 2.5128598438289798

Epoch: 6| Step: 10
Training loss: 2.6593810533035542
Validation loss: 2.48651202946817

Epoch: 6| Step: 11
Training loss: 3.099502763555248
Validation loss: 2.472389271966871

Epoch: 6| Step: 12
Training loss: 2.885291876085516
Validation loss: 2.4608622575759678

Epoch: 6| Step: 13
Training loss: 3.10358998789922
Validation loss: 2.461198482031851

Epoch: 242| Step: 0
Training loss: 2.969644993844438
Validation loss: 2.4547097771064026

Epoch: 6| Step: 1
Training loss: 2.7834353487274774
Validation loss: 2.456327076111522

Epoch: 6| Step: 2
Training loss: 2.7943861132635197
Validation loss: 2.4661140414290137

Epoch: 6| Step: 3
Training loss: 3.093086248537786
Validation loss: 2.4691381734714533

Epoch: 6| Step: 4
Training loss: 2.639664514784095
Validation loss: 2.468372202354326

Epoch: 6| Step: 5
Training loss: 1.908718074788909
Validation loss: 2.471255717101742

Epoch: 6| Step: 6
Training loss: 2.3859065745209995
Validation loss: 2.466887170397195

Epoch: 6| Step: 7
Training loss: 2.557380027306255
Validation loss: 2.471257705765678

Epoch: 6| Step: 8
Training loss: 2.5747734710900683
Validation loss: 2.483155462856094

Epoch: 6| Step: 9
Training loss: 3.330657997991532
Validation loss: 2.4859432492927964

Epoch: 6| Step: 10
Training loss: 2.7585009183040303
Validation loss: 2.5000382184624637

Epoch: 6| Step: 11
Training loss: 2.9125943410107915
Validation loss: 2.495722178905367

Epoch: 6| Step: 12
Training loss: 2.7731587874370547
Validation loss: 2.5003216167430327

Epoch: 6| Step: 13
Training loss: 2.957725695320194
Validation loss: 2.5122637918945605

Epoch: 243| Step: 0
Training loss: 2.6612818013052
Validation loss: 2.536301989181029

Epoch: 6| Step: 1
Training loss: 2.697557128357877
Validation loss: 2.5683425319466684

Epoch: 6| Step: 2
Training loss: 2.82404509415433
Validation loss: 2.5534938534816907

Epoch: 6| Step: 3
Training loss: 2.6757538954178863
Validation loss: 2.556563531336883

Epoch: 6| Step: 4
Training loss: 2.8939534587478986
Validation loss: 2.557241157414043

Epoch: 6| Step: 5
Training loss: 3.2505786087255153
Validation loss: 2.568440224909535

Epoch: 6| Step: 6
Training loss: 2.4282697361996597
Validation loss: 2.5319540436523047

Epoch: 6| Step: 7
Training loss: 2.6211292247389792
Validation loss: 2.5286693779527756

Epoch: 6| Step: 8
Training loss: 2.5686063814505267
Validation loss: 2.516381100870738

Epoch: 6| Step: 9
Training loss: 2.195215623557543
Validation loss: 2.5289986028515794

Epoch: 6| Step: 10
Training loss: 2.508441026304244
Validation loss: 2.5032338054416274

Epoch: 6| Step: 11
Training loss: 2.6255196556528078
Validation loss: 2.513614281784825

Epoch: 6| Step: 12
Training loss: 3.0208198985535484
Validation loss: 2.5170214107242797

Epoch: 6| Step: 13
Training loss: 3.1181048809663308
Validation loss: 2.510376445652471

Epoch: 244| Step: 0
Training loss: 2.989362294247643
Validation loss: 2.516931890251751

Epoch: 6| Step: 1
Training loss: 2.7357972724049278
Validation loss: 2.5378445135878196

Epoch: 6| Step: 2
Training loss: 3.195676302543743
Validation loss: 2.5615279612319597

Epoch: 6| Step: 3
Training loss: 3.2867078167529704
Validation loss: 2.5296968135730573

Epoch: 6| Step: 4
Training loss: 2.7166938460536985
Validation loss: 2.5561597568927756

Epoch: 6| Step: 5
Training loss: 2.2040851205357055
Validation loss: 2.534688993775503

Epoch: 6| Step: 6
Training loss: 2.897712555166258
Validation loss: 2.5150668228716233

Epoch: 6| Step: 7
Training loss: 2.117689009949026
Validation loss: 2.521727257429872

Epoch: 6| Step: 8
Training loss: 2.5475836394021996
Validation loss: 2.507671614070544

Epoch: 6| Step: 9
Training loss: 2.3715313125914155
Validation loss: 2.525474836062123

Epoch: 6| Step: 10
Training loss: 2.5019399745336486
Validation loss: 2.5264600560583936

Epoch: 6| Step: 11
Training loss: 2.940352333391769
Validation loss: 2.5371046743483836

Epoch: 6| Step: 12
Training loss: 2.7579487450852995
Validation loss: 2.5508727553636863

Epoch: 6| Step: 13
Training loss: 2.435050711916385
Validation loss: 2.5631809125305947

Epoch: 245| Step: 0
Training loss: 2.4016747512345993
Validation loss: 2.5731821835294513

Epoch: 6| Step: 1
Training loss: 2.653938813861798
Validation loss: 2.6058375718082463

Epoch: 6| Step: 2
Training loss: 2.9805316243470577
Validation loss: 2.610188336372561

Epoch: 6| Step: 3
Training loss: 2.458351059758129
Validation loss: 2.5604070614627474

Epoch: 6| Step: 4
Training loss: 3.5935403513916575
Validation loss: 2.5444869081320967

Epoch: 6| Step: 5
Training loss: 2.4089630487251754
Validation loss: 2.5199482275040546

Epoch: 6| Step: 6
Training loss: 2.617069526404749
Validation loss: 2.518997081575766

Epoch: 6| Step: 7
Training loss: 2.1845556880238024
Validation loss: 2.5064869458501065

Epoch: 6| Step: 8
Training loss: 3.0106596711141957
Validation loss: 2.5021930427867787

Epoch: 6| Step: 9
Training loss: 2.9976183656511157
Validation loss: 2.4776604329335816

Epoch: 6| Step: 10
Training loss: 2.7711131497164625
Validation loss: 2.4810395302134647

Epoch: 6| Step: 11
Training loss: 2.5415888498202777
Validation loss: 2.4883262699877724

Epoch: 6| Step: 12
Training loss: 2.685490766459323
Validation loss: 2.4908427219844294

Epoch: 6| Step: 13
Training loss: 2.617695500051056
Validation loss: 2.49134590411474

Epoch: 246| Step: 0
Training loss: 3.115356213330588
Validation loss: 2.5020923452008486

Epoch: 6| Step: 1
Training loss: 2.17341460401705
Validation loss: 2.529151567269862

Epoch: 6| Step: 2
Training loss: 3.097956254437228
Validation loss: 2.5481511742555023

Epoch: 6| Step: 3
Training loss: 1.6308810843661727
Validation loss: 2.5772438708859644

Epoch: 6| Step: 4
Training loss: 2.9139900096232454
Validation loss: 2.615993737232052

Epoch: 6| Step: 5
Training loss: 2.5613975014016797
Validation loss: 2.6327004138457735

Epoch: 6| Step: 6
Training loss: 2.938337003893479
Validation loss: 2.635076320321488

Epoch: 6| Step: 7
Training loss: 2.7670879912618425
Validation loss: 2.6240065316371077

Epoch: 6| Step: 8
Training loss: 2.9007641278867826
Validation loss: 2.5902796555258756

Epoch: 6| Step: 9
Training loss: 3.256599767720796
Validation loss: 2.550285123390914

Epoch: 6| Step: 10
Training loss: 2.922897731060776
Validation loss: 2.5079943936257774

Epoch: 6| Step: 11
Training loss: 2.654140846769622
Validation loss: 2.489784893317613

Epoch: 6| Step: 12
Training loss: 2.3216240769108567
Validation loss: 2.476871387238234

Epoch: 6| Step: 13
Training loss: 2.5449363959857694
Validation loss: 2.467880532058097

Epoch: 247| Step: 0
Training loss: 2.8953128227978944
Validation loss: 2.459249417195286

Epoch: 6| Step: 1
Training loss: 2.531550542626362
Validation loss: 2.4600197326404976

Epoch: 6| Step: 2
Training loss: 3.0834809001629835
Validation loss: 2.4601515783802905

Epoch: 6| Step: 3
Training loss: 2.772326523605239
Validation loss: 2.4673742155325384

Epoch: 6| Step: 4
Training loss: 2.7405564546440764
Validation loss: 2.4662398296051466

Epoch: 6| Step: 5
Training loss: 2.805485688861901
Validation loss: 2.464362015796931

Epoch: 6| Step: 6
Training loss: 2.34853068742363
Validation loss: 2.469723917608077

Epoch: 6| Step: 7
Training loss: 2.5953462583584384
Validation loss: 2.464559979421274

Epoch: 6| Step: 8
Training loss: 2.7955066594286904
Validation loss: 2.463555746726156

Epoch: 6| Step: 9
Training loss: 2.417270047948862
Validation loss: 2.4692620322356333

Epoch: 6| Step: 10
Training loss: 3.1942739874285513
Validation loss: 2.4755790954846093

Epoch: 6| Step: 11
Training loss: 2.64964730416839
Validation loss: 2.4720375774731362

Epoch: 6| Step: 12
Training loss: 2.9584028925351844
Validation loss: 2.4799965298263174

Epoch: 6| Step: 13
Training loss: 2.6750612055826464
Validation loss: 2.4976437652708086

Epoch: 248| Step: 0
Training loss: 2.901767514349905
Validation loss: 2.497329142499533

Epoch: 6| Step: 1
Training loss: 2.668174099035914
Validation loss: 2.509436714840573

Epoch: 6| Step: 2
Training loss: 3.106888893785492
Validation loss: 2.5000160329571233

Epoch: 6| Step: 3
Training loss: 2.025408164438581
Validation loss: 2.539923155811325

Epoch: 6| Step: 4
Training loss: 2.542982438339215
Validation loss: 2.548549705193981

Epoch: 6| Step: 5
Training loss: 2.801461322104163
Validation loss: 2.5778473456890123

Epoch: 6| Step: 6
Training loss: 2.6107544136802727
Validation loss: 2.6192654887958824

Epoch: 6| Step: 7
Training loss: 2.486821535450851
Validation loss: 2.651183815832359

Epoch: 6| Step: 8
Training loss: 2.665438389031924
Validation loss: 2.642198773605504

Epoch: 6| Step: 9
Training loss: 2.7841582790850894
Validation loss: 2.645756246968113

Epoch: 6| Step: 10
Training loss: 3.3945413639809052
Validation loss: 2.585988686304106

Epoch: 6| Step: 11
Training loss: 2.9231799470452753
Validation loss: 2.5425809385542215

Epoch: 6| Step: 12
Training loss: 2.706512269312746
Validation loss: 2.515013962775835

Epoch: 6| Step: 13
Training loss: 2.2252801783030023
Validation loss: 2.5028304679076223

Epoch: 249| Step: 0
Training loss: 2.960607827386222
Validation loss: 2.4837871415046457

Epoch: 6| Step: 1
Training loss: 2.8859789652755086
Validation loss: 2.476983915408778

Epoch: 6| Step: 2
Training loss: 2.6513990200091846
Validation loss: 2.472662348427803

Epoch: 6| Step: 3
Training loss: 2.9140981718032815
Validation loss: 2.467254917017777

Epoch: 6| Step: 4
Training loss: 2.844931891351824
Validation loss: 2.464885158453291

Epoch: 6| Step: 5
Training loss: 2.389386024299991
Validation loss: 2.473505656996176

Epoch: 6| Step: 6
Training loss: 2.7019460234880293
Validation loss: 2.459092615446767

Epoch: 6| Step: 7
Training loss: 2.8004265937086243
Validation loss: 2.4615876296966004

Epoch: 6| Step: 8
Training loss: 2.27623081657961
Validation loss: 2.4760470987678023

Epoch: 6| Step: 9
Training loss: 2.596343432945988
Validation loss: 2.474838106278462

Epoch: 6| Step: 10
Training loss: 2.949946231675315
Validation loss: 2.487577063400001

Epoch: 6| Step: 11
Training loss: 3.0321422718759377
Validation loss: 2.51245897912937

Epoch: 6| Step: 12
Training loss: 2.543336809421762
Validation loss: 2.509446115586486

Epoch: 6| Step: 13
Training loss: 2.3704672273190064
Validation loss: 2.538156762514478

Epoch: 250| Step: 0
Training loss: 2.697363473939093
Validation loss: 2.5335437303013113

Epoch: 6| Step: 1
Training loss: 2.8449099344434816
Validation loss: 2.573428545762672

Epoch: 6| Step: 2
Training loss: 2.9410109944635816
Validation loss: 2.618980655179002

Epoch: 6| Step: 3
Training loss: 2.5296654156574423
Validation loss: 2.6539604245841275

Epoch: 6| Step: 4
Training loss: 2.884293173376339
Validation loss: 2.6498918106475413

Epoch: 6| Step: 5
Training loss: 2.569908226244821
Validation loss: 2.6240189824288085

Epoch: 6| Step: 6
Training loss: 2.3593790420598655
Validation loss: 2.5921782144207386

Epoch: 6| Step: 7
Training loss: 2.7218669694153563
Validation loss: 2.5587717772902563

Epoch: 6| Step: 8
Training loss: 2.60655260776371
Validation loss: 2.551379064975987

Epoch: 6| Step: 9
Training loss: 2.522608948728107
Validation loss: 2.5192123899407863

Epoch: 6| Step: 10
Training loss: 2.9926813181264045
Validation loss: 2.5208571146534227

Epoch: 6| Step: 11
Training loss: 2.696885686435501
Validation loss: 2.490089191770496

Epoch: 6| Step: 12
Training loss: 2.4632596156231608
Validation loss: 2.486133569341865

Epoch: 6| Step: 13
Training loss: 3.0853780891295735
Validation loss: 2.472975463096334

Epoch: 251| Step: 0
Training loss: 2.805529199818447
Validation loss: 2.490655282545246

Epoch: 6| Step: 1
Training loss: 3.178005964212361
Validation loss: 2.476302946720546

Epoch: 6| Step: 2
Training loss: 2.856110256791603
Validation loss: 2.491082220674399

Epoch: 6| Step: 3
Training loss: 2.7125350246717184
Validation loss: 2.499220033205428

Epoch: 6| Step: 4
Training loss: 2.2545310068576496
Validation loss: 2.5380174519121255

Epoch: 6| Step: 5
Training loss: 2.410389695693919
Validation loss: 2.5504917223617722

Epoch: 6| Step: 6
Training loss: 2.4553869230768095
Validation loss: 2.5429017226495363

Epoch: 6| Step: 7
Training loss: 2.4011483544556302
Validation loss: 2.5581238939657447

Epoch: 6| Step: 8
Training loss: 2.9578077538921246
Validation loss: 2.564224341299435

Epoch: 6| Step: 9
Training loss: 3.1082792412054285
Validation loss: 2.5782868643693275

Epoch: 6| Step: 10
Training loss: 2.494108888428664
Validation loss: 2.569240137536173

Epoch: 6| Step: 11
Training loss: 3.27630198565897
Validation loss: 2.576507170129547

Epoch: 6| Step: 12
Training loss: 2.547703426875321
Validation loss: 2.5577935638409337

Epoch: 6| Step: 13
Training loss: 2.318926464676679
Validation loss: 2.5529793554928526

Epoch: 252| Step: 0
Training loss: 2.4868117564045717
Validation loss: 2.508386766421066

Epoch: 6| Step: 1
Training loss: 2.777985446372747
Validation loss: 2.5065839097246694

Epoch: 6| Step: 2
Training loss: 3.116572498660074
Validation loss: 2.4874139155906505

Epoch: 6| Step: 3
Training loss: 2.447768078345792
Validation loss: 2.485578351196375

Epoch: 6| Step: 4
Training loss: 3.092569916041982
Validation loss: 2.4743092412519196

Epoch: 6| Step: 5
Training loss: 2.726567309356208
Validation loss: 2.482001479986546

Epoch: 6| Step: 6
Training loss: 2.6188657020373567
Validation loss: 2.481607155390405

Epoch: 6| Step: 7
Training loss: 2.7512367241975455
Validation loss: 2.4766504514006575

Epoch: 6| Step: 8
Training loss: 2.446373462553527
Validation loss: 2.4923400575045034

Epoch: 6| Step: 9
Training loss: 2.711302279244879
Validation loss: 2.473682026915015

Epoch: 6| Step: 10
Training loss: 2.7461627718199506
Validation loss: 2.480122803146078

Epoch: 6| Step: 11
Training loss: 2.3732409739293048
Validation loss: 2.478625406929406

Epoch: 6| Step: 12
Training loss: 2.8480103825904957
Validation loss: 2.5086441743842234

Epoch: 6| Step: 13
Training loss: 2.5979182749368257
Validation loss: 2.488485089861846

Epoch: 253| Step: 0
Training loss: 2.8636139680281176
Validation loss: 2.5022204567214947

Epoch: 6| Step: 1
Training loss: 2.802074522172388
Validation loss: 2.5086379375817276

Epoch: 6| Step: 2
Training loss: 2.548886587122874
Validation loss: 2.4877464278728763

Epoch: 6| Step: 3
Training loss: 2.5177122188396615
Validation loss: 2.5139353377000067

Epoch: 6| Step: 4
Training loss: 2.8007232787704726
Validation loss: 2.5162039500563758

Epoch: 6| Step: 5
Training loss: 2.5993233056877427
Validation loss: 2.525275703777488

Epoch: 6| Step: 6
Training loss: 2.460048163648074
Validation loss: 2.505283118123466

Epoch: 6| Step: 7
Training loss: 2.946095977110667
Validation loss: 2.4852415784205433

Epoch: 6| Step: 8
Training loss: 2.3169720683976456
Validation loss: 2.481685262537229

Epoch: 6| Step: 9
Training loss: 3.1052877121464153
Validation loss: 2.476227949117501

Epoch: 6| Step: 10
Training loss: 3.322501289132057
Validation loss: 2.477970475492421

Epoch: 6| Step: 11
Training loss: 2.458726646727455
Validation loss: 2.477265445282493

Epoch: 6| Step: 12
Training loss: 2.420387845131812
Validation loss: 2.4951679056414804

Epoch: 6| Step: 13
Training loss: 2.2726533461598413
Validation loss: 2.4776691544228533

Epoch: 254| Step: 0
Training loss: 2.4085262480911727
Validation loss: 2.474063721221756

Epoch: 6| Step: 1
Training loss: 3.128684961158864
Validation loss: 2.486624158482015

Epoch: 6| Step: 2
Training loss: 2.504624286122817
Validation loss: 2.481447538881159

Epoch: 6| Step: 3
Training loss: 2.7952559915868522
Validation loss: 2.5068947295292983

Epoch: 6| Step: 4
Training loss: 2.684896760799175
Validation loss: 2.519327595887129

Epoch: 6| Step: 5
Training loss: 3.0822159744427955
Validation loss: 2.5107708589495727

Epoch: 6| Step: 6
Training loss: 2.8865588483284523
Validation loss: 2.526411116823658

Epoch: 6| Step: 7
Training loss: 2.452305942522258
Validation loss: 2.5107257421112594

Epoch: 6| Step: 8
Training loss: 2.6330725657441745
Validation loss: 2.507997491874317

Epoch: 6| Step: 9
Training loss: 2.27330923865667
Validation loss: 2.5127654115682505

Epoch: 6| Step: 10
Training loss: 2.387292870928683
Validation loss: 2.5062837743019064

Epoch: 6| Step: 11
Training loss: 2.724337218990314
Validation loss: 2.4924679261279166

Epoch: 6| Step: 12
Training loss: 2.759184325943312
Validation loss: 2.4954841230456615

Epoch: 6| Step: 13
Training loss: 2.8221355263050367
Validation loss: 2.5118162273739992

Epoch: 255| Step: 0
Training loss: 2.573555057622245
Validation loss: 2.5337414215561243

Epoch: 6| Step: 1
Training loss: 2.9065830491080598
Validation loss: 2.573344821054171

Epoch: 6| Step: 2
Training loss: 2.989236756194216
Validation loss: 2.615160393817442

Epoch: 6| Step: 3
Training loss: 2.1337406807658534
Validation loss: 2.6108154404236883

Epoch: 6| Step: 4
Training loss: 2.9925511390695214
Validation loss: 2.5801441209989675

Epoch: 6| Step: 5
Training loss: 2.5519016953790397
Validation loss: 2.579078911007637

Epoch: 6| Step: 6
Training loss: 2.6302586516045947
Validation loss: 2.56462786966299

Epoch: 6| Step: 7
Training loss: 2.907512103618905
Validation loss: 2.534213983393519

Epoch: 6| Step: 8
Training loss: 2.4157878549415317
Validation loss: 2.5261081623797037

Epoch: 6| Step: 9
Training loss: 3.082606427535789
Validation loss: 2.5007811628224417

Epoch: 6| Step: 10
Training loss: 2.5673543958226723
Validation loss: 2.4826868097134196

Epoch: 6| Step: 11
Training loss: 2.6696202094461126
Validation loss: 2.481927190149733

Epoch: 6| Step: 12
Training loss: 2.5372467591147267
Validation loss: 2.4866861191454737

Epoch: 6| Step: 13
Training loss: 2.6117885186601217
Validation loss: 2.4797387921426033

Epoch: 256| Step: 0
Training loss: 2.707657734651856
Validation loss: 2.487889639521049

Epoch: 6| Step: 1
Training loss: 2.5379429623181977
Validation loss: 2.491821803312708

Epoch: 6| Step: 2
Training loss: 2.259147064825629
Validation loss: 2.4693226978803233

Epoch: 6| Step: 3
Training loss: 3.0303957020432026
Validation loss: 2.4858420966185606

Epoch: 6| Step: 4
Training loss: 2.7758995625743097
Validation loss: 2.492322237837799

Epoch: 6| Step: 5
Training loss: 2.7794385004048854
Validation loss: 2.520884921560398

Epoch: 6| Step: 6
Training loss: 2.8492775319225148
Validation loss: 2.5436504159787545

Epoch: 6| Step: 7
Training loss: 2.1032372363950276
Validation loss: 2.5801467977658326

Epoch: 6| Step: 8
Training loss: 2.8268057765408843
Validation loss: 2.561773429768673

Epoch: 6| Step: 9
Training loss: 2.489006858917386
Validation loss: 2.582985000731383

Epoch: 6| Step: 10
Training loss: 3.277253832850993
Validation loss: 2.58589242364825

Epoch: 6| Step: 11
Training loss: 2.54188920177716
Validation loss: 2.5641495832308157

Epoch: 6| Step: 12
Training loss: 2.5734956735915895
Validation loss: 2.5136869783396576

Epoch: 6| Step: 13
Training loss: 2.9672406023606115
Validation loss: 2.48733732512263

Epoch: 257| Step: 0
Training loss: 3.0463115464584276
Validation loss: 2.4641676349035895

Epoch: 6| Step: 1
Training loss: 3.1285877232335637
Validation loss: 2.4754278745571727

Epoch: 6| Step: 2
Training loss: 2.453311305655537
Validation loss: 2.4712350948632262

Epoch: 6| Step: 3
Training loss: 2.6332335545754186
Validation loss: 2.485131905140519

Epoch: 6| Step: 4
Training loss: 2.7369341400440157
Validation loss: 2.491740658814788

Epoch: 6| Step: 5
Training loss: 2.5554877378154255
Validation loss: 2.4936142407412905

Epoch: 6| Step: 6
Training loss: 2.230744941032784
Validation loss: 2.520788840343025

Epoch: 6| Step: 7
Training loss: 2.941096761969766
Validation loss: 2.5403578353912217

Epoch: 6| Step: 8
Training loss: 3.0453017648083938
Validation loss: 2.565423302947548

Epoch: 6| Step: 9
Training loss: 2.420573223100998
Validation loss: 2.504530688753789

Epoch: 6| Step: 10
Training loss: 2.600249362871759
Validation loss: 2.4750275256201872

Epoch: 6| Step: 11
Training loss: 2.845150613133437
Validation loss: 2.4785440000282923

Epoch: 6| Step: 12
Training loss: 2.484085737938644
Validation loss: 2.475591219933032

Epoch: 6| Step: 13
Training loss: 2.871928357115358
Validation loss: 2.4537807675217476

Epoch: 258| Step: 0
Training loss: 2.323149209007991
Validation loss: 2.4531010640360438

Epoch: 6| Step: 1
Training loss: 2.7739742135827563
Validation loss: 2.458376132376312

Epoch: 6| Step: 2
Training loss: 3.1636459264740266
Validation loss: 2.454159615319879

Epoch: 6| Step: 3
Training loss: 2.785465688756723
Validation loss: 2.466568695152583

Epoch: 6| Step: 4
Training loss: 2.6582402570767116
Validation loss: 2.460638558545342

Epoch: 6| Step: 5
Training loss: 2.670252257014095
Validation loss: 2.4659463589297506

Epoch: 6| Step: 6
Training loss: 3.0917499897740077
Validation loss: 2.4779556489865273

Epoch: 6| Step: 7
Training loss: 2.2590436383778014
Validation loss: 2.473786151552619

Epoch: 6| Step: 8
Training loss: 2.794838446245649
Validation loss: 2.505645984564886

Epoch: 6| Step: 9
Training loss: 3.0101284078285118
Validation loss: 2.5373519630800065

Epoch: 6| Step: 10
Training loss: 2.611802211458319
Validation loss: 2.516330203088301

Epoch: 6| Step: 11
Training loss: 2.4878102669755573
Validation loss: 2.521135483114571

Epoch: 6| Step: 12
Training loss: 2.491003921383191
Validation loss: 2.5057530421858756

Epoch: 6| Step: 13
Training loss: 2.5779149750212325
Validation loss: 2.517546415051714

Epoch: 259| Step: 0
Training loss: 2.489605944755586
Validation loss: 2.502206956238876

Epoch: 6| Step: 1
Training loss: 2.5180163656828523
Validation loss: 2.527187476666616

Epoch: 6| Step: 2
Training loss: 2.651709411903156
Validation loss: 2.5102988482542545

Epoch: 6| Step: 3
Training loss: 3.0797444841985935
Validation loss: 2.551949815268964

Epoch: 6| Step: 4
Training loss: 2.4471107184238923
Validation loss: 2.551788417174148

Epoch: 6| Step: 5
Training loss: 2.3010193680499764
Validation loss: 2.5384372230921053

Epoch: 6| Step: 6
Training loss: 2.6452386943797985
Validation loss: 2.489855842300083

Epoch: 6| Step: 7
Training loss: 3.0820580156176978
Validation loss: 2.4512668707729195

Epoch: 6| Step: 8
Training loss: 2.550015531754409
Validation loss: 2.4581332729297345

Epoch: 6| Step: 9
Training loss: 2.4700230080772343
Validation loss: 2.4758961601074083

Epoch: 6| Step: 10
Training loss: 2.235383133104931
Validation loss: 2.466287368309944

Epoch: 6| Step: 11
Training loss: 2.7075838568074464
Validation loss: 2.4685111334619765

Epoch: 6| Step: 12
Training loss: 3.2123396659055827
Validation loss: 2.494675808913639

Epoch: 6| Step: 13
Training loss: 3.3360399860300105
Validation loss: 2.4820918564321137

Epoch: 260| Step: 0
Training loss: 2.931378092945997
Validation loss: 2.52187803355954

Epoch: 6| Step: 1
Training loss: 2.61570009695739
Validation loss: 2.5354502376138703

Epoch: 6| Step: 2
Training loss: 2.4493574623361942
Validation loss: 2.5744718670906734

Epoch: 6| Step: 3
Training loss: 2.4985051454281533
Validation loss: 2.5984164772206624

Epoch: 6| Step: 4
Training loss: 2.919582507975074
Validation loss: 2.628933130529816

Epoch: 6| Step: 5
Training loss: 3.224589116144341
Validation loss: 2.6000115350162907

Epoch: 6| Step: 6
Training loss: 2.306667085474818
Validation loss: 2.5070904804818506

Epoch: 6| Step: 7
Training loss: 2.8992579859157903
Validation loss: 2.4760273654510985

Epoch: 6| Step: 8
Training loss: 2.290737958051085
Validation loss: 2.4679363847237745

Epoch: 6| Step: 9
Training loss: 2.7779427055563986
Validation loss: 2.451113955369842

Epoch: 6| Step: 10
Training loss: 2.5917092993399464
Validation loss: 2.4474128049242245

Epoch: 6| Step: 11
Training loss: 3.094120042036781
Validation loss: 2.4561429082615995

Epoch: 6| Step: 12
Training loss: 2.718646869676522
Validation loss: 2.4552177509384436

Epoch: 6| Step: 13
Training loss: 2.5675462487205265
Validation loss: 2.457202964002132

Epoch: 261| Step: 0
Training loss: 2.69799750561666
Validation loss: 2.4547742654494664

Epoch: 6| Step: 1
Training loss: 3.020691721436027
Validation loss: 2.4629794617063956

Epoch: 6| Step: 2
Training loss: 3.35535563055106
Validation loss: 2.4513187565935355

Epoch: 6| Step: 3
Training loss: 2.6675180526451445
Validation loss: 2.4630765271362836

Epoch: 6| Step: 4
Training loss: 2.119476319897316
Validation loss: 2.482300687801091

Epoch: 6| Step: 5
Training loss: 2.842921712789726
Validation loss: 2.5028717897382844

Epoch: 6| Step: 6
Training loss: 2.9497388368510595
Validation loss: 2.5205026781096027

Epoch: 6| Step: 7
Training loss: 2.5589713946312997
Validation loss: 2.538475943463615

Epoch: 6| Step: 8
Training loss: 2.684740113195844
Validation loss: 2.5438311236945714

Epoch: 6| Step: 9
Training loss: 2.8325337983528165
Validation loss: 2.519855041633452

Epoch: 6| Step: 10
Training loss: 2.7184390186165683
Validation loss: 2.506519540302157

Epoch: 6| Step: 11
Training loss: 1.8904329943300386
Validation loss: 2.505023478664319

Epoch: 6| Step: 12
Training loss: 2.6253828950191216
Validation loss: 2.5029637591424145

Epoch: 6| Step: 13
Training loss: 2.7568337754319807
Validation loss: 2.4787076365005483

Epoch: 262| Step: 0
Training loss: 2.6415169016585995
Validation loss: 2.4629393847751815

Epoch: 6| Step: 1
Training loss: 2.6214870379540565
Validation loss: 2.4694926960838424

Epoch: 6| Step: 2
Training loss: 2.848824804176729
Validation loss: 2.46639481115935

Epoch: 6| Step: 3
Training loss: 2.113040480233627
Validation loss: 2.4585442623738545

Epoch: 6| Step: 4
Training loss: 2.78213701140872
Validation loss: 2.4752770120642538

Epoch: 6| Step: 5
Training loss: 2.990135824123062
Validation loss: 2.4687421738093067

Epoch: 6| Step: 6
Training loss: 2.624896456174919
Validation loss: 2.4834606169692965

Epoch: 6| Step: 7
Training loss: 2.9329864239019194
Validation loss: 2.4859326392062737

Epoch: 6| Step: 8
Training loss: 2.9221994148527948
Validation loss: 2.5391880647392457

Epoch: 6| Step: 9
Training loss: 2.763353093501888
Validation loss: 2.593747186047673

Epoch: 6| Step: 10
Training loss: 2.5371435807692233
Validation loss: 2.6209974117035357

Epoch: 6| Step: 11
Training loss: 3.073769833507363
Validation loss: 2.656239141240566

Epoch: 6| Step: 12
Training loss: 2.4627944963830815
Validation loss: 2.606347007989127

Epoch: 6| Step: 13
Training loss: 2.4343015764987372
Validation loss: 2.5802028502555574

Epoch: 263| Step: 0
Training loss: 2.885267747325174
Validation loss: 2.534212160468495

Epoch: 6| Step: 1
Training loss: 2.77808088132414
Validation loss: 2.497607296172195

Epoch: 6| Step: 2
Training loss: 2.6661959967887277
Validation loss: 2.5021440500168532

Epoch: 6| Step: 3
Training loss: 2.362590796123607
Validation loss: 2.4897908962486

Epoch: 6| Step: 4
Training loss: 2.779063447544387
Validation loss: 2.4877082879933443

Epoch: 6| Step: 5
Training loss: 2.7703522190402983
Validation loss: 2.482978939861704

Epoch: 6| Step: 6
Training loss: 2.6624007873676128
Validation loss: 2.490281834496954

Epoch: 6| Step: 7
Training loss: 2.8369058264187674
Validation loss: 2.4754705827553227

Epoch: 6| Step: 8
Training loss: 2.4623374226922916
Validation loss: 2.455599275179775

Epoch: 6| Step: 9
Training loss: 2.4872303035353815
Validation loss: 2.4884778228110918

Epoch: 6| Step: 10
Training loss: 2.696754666823111
Validation loss: 2.489735882911812

Epoch: 6| Step: 11
Training loss: 2.408868925032211
Validation loss: 2.4989057586751287

Epoch: 6| Step: 12
Training loss: 2.774588332699932
Validation loss: 2.504884289348469

Epoch: 6| Step: 13
Training loss: 2.7785749107588384
Validation loss: 2.5417238031020792

Epoch: 264| Step: 0
Training loss: 3.1910234312741155
Validation loss: 2.5438733032734753

Epoch: 6| Step: 1
Training loss: 2.352802849307859
Validation loss: 2.565782273199834

Epoch: 6| Step: 2
Training loss: 2.3700347999239044
Validation loss: 2.578445403722576

Epoch: 6| Step: 3
Training loss: 2.254945194906353
Validation loss: 2.5569269618509307

Epoch: 6| Step: 4
Training loss: 2.6296736573496977
Validation loss: 2.5253817566674366

Epoch: 6| Step: 5
Training loss: 2.43915061815945
Validation loss: 2.549525823305218

Epoch: 6| Step: 6
Training loss: 2.8882311006896955
Validation loss: 2.5197046913227474

Epoch: 6| Step: 7
Training loss: 3.065055092694492
Validation loss: 2.493240023607458

Epoch: 6| Step: 8
Training loss: 2.9808277398891367
Validation loss: 2.50691103642888

Epoch: 6| Step: 9
Training loss: 2.4999350539354546
Validation loss: 2.5080600396952457

Epoch: 6| Step: 10
Training loss: 2.625559066093524
Validation loss: 2.4723060840909783

Epoch: 6| Step: 11
Training loss: 3.100348016216127
Validation loss: 2.4772058175893252

Epoch: 6| Step: 12
Training loss: 2.1910262976930737
Validation loss: 2.4963213342965593

Epoch: 6| Step: 13
Training loss: 2.490331837859905
Validation loss: 2.487819016772375

Epoch: 265| Step: 0
Training loss: 2.6389765362377657
Validation loss: 2.484892742899003

Epoch: 6| Step: 1
Training loss: 2.7238458691654577
Validation loss: 2.504555171127793

Epoch: 6| Step: 2
Training loss: 2.538958456401948
Validation loss: 2.4925726817507665

Epoch: 6| Step: 3
Training loss: 2.934910383529723
Validation loss: 2.5063607973984903

Epoch: 6| Step: 4
Training loss: 2.2230778781979184
Validation loss: 2.532113908598162

Epoch: 6| Step: 5
Training loss: 2.6866231863070484
Validation loss: 2.5343181661342498

Epoch: 6| Step: 6
Training loss: 2.826726999973494
Validation loss: 2.5319045504385524

Epoch: 6| Step: 7
Training loss: 2.4205569710838146
Validation loss: 2.5299544255347177

Epoch: 6| Step: 8
Training loss: 2.8682498470955715
Validation loss: 2.5365600835053366

Epoch: 6| Step: 9
Training loss: 2.5169640998992984
Validation loss: 2.5268828154971494

Epoch: 6| Step: 10
Training loss: 2.6573952393863034
Validation loss: 2.5122512025662154

Epoch: 6| Step: 11
Training loss: 2.4065875522610845
Validation loss: 2.512355484834422

Epoch: 6| Step: 12
Training loss: 2.7889814605479675
Validation loss: 2.497006453470594

Epoch: 6| Step: 13
Training loss: 3.1794544481354903
Validation loss: 2.503840284105864

Epoch: 266| Step: 0
Training loss: 2.992095706816545
Validation loss: 2.480111400652289

Epoch: 6| Step: 1
Training loss: 2.87524479362906
Validation loss: 2.4687819192613403

Epoch: 6| Step: 2
Training loss: 2.7206808665748694
Validation loss: 2.4980737730778446

Epoch: 6| Step: 3
Training loss: 2.752623173922643
Validation loss: 2.500222028081603

Epoch: 6| Step: 4
Training loss: 2.5291884704689034
Validation loss: 2.4777950574800647

Epoch: 6| Step: 5
Training loss: 2.117878818607811
Validation loss: 2.4711511901746808

Epoch: 6| Step: 6
Training loss: 2.595314013936005
Validation loss: 2.4791537689786227

Epoch: 6| Step: 7
Training loss: 3.1522136599938704
Validation loss: 2.4866887367175496

Epoch: 6| Step: 8
Training loss: 2.8692308675286484
Validation loss: 2.4873261948200027

Epoch: 6| Step: 9
Training loss: 2.6323055152745147
Validation loss: 2.4759810719368995

Epoch: 6| Step: 10
Training loss: 2.5979425028780945
Validation loss: 2.471254085296493

Epoch: 6| Step: 11
Training loss: 2.4577048732233835
Validation loss: 2.486319129710466

Epoch: 6| Step: 12
Training loss: 2.267168453249594
Validation loss: 2.4707036988014788

Epoch: 6| Step: 13
Training loss: 2.2385211170283466
Validation loss: 2.496500859715003

Epoch: 267| Step: 0
Training loss: 1.746342788448369
Validation loss: 2.491055705069268

Epoch: 6| Step: 1
Training loss: 2.5148926610773517
Validation loss: 2.4994626011123735

Epoch: 6| Step: 2
Training loss: 2.626386730296983
Validation loss: 2.4788934921304984

Epoch: 6| Step: 3
Training loss: 2.3426728888906494
Validation loss: 2.504180540460991

Epoch: 6| Step: 4
Training loss: 2.575911988170555
Validation loss: 2.5126396579137054

Epoch: 6| Step: 5
Training loss: 3.1072805433663544
Validation loss: 2.487741385595978

Epoch: 6| Step: 6
Training loss: 2.7824824313614203
Validation loss: 2.4773980206355337

Epoch: 6| Step: 7
Training loss: 3.04861807237051
Validation loss: 2.4727269263509517

Epoch: 6| Step: 8
Training loss: 3.3589859138322877
Validation loss: 2.474907758014554

Epoch: 6| Step: 9
Training loss: 2.3634989488444806
Validation loss: 2.4880055591170445

Epoch: 6| Step: 10
Training loss: 2.268423732700551
Validation loss: 2.5094820397599973

Epoch: 6| Step: 11
Training loss: 2.679669171595938
Validation loss: 2.5264024966255407

Epoch: 6| Step: 12
Training loss: 2.516525960192979
Validation loss: 2.544090783965942

Epoch: 6| Step: 13
Training loss: 2.692039293492712
Validation loss: 2.530570328509138

Epoch: 268| Step: 0
Training loss: 2.8041802162723517
Validation loss: 2.5327416170831256

Epoch: 6| Step: 1
Training loss: 2.4860852191033773
Validation loss: 2.5133696320672483

Epoch: 6| Step: 2
Training loss: 2.0378393253408773
Validation loss: 2.4938692250108003

Epoch: 6| Step: 3
Training loss: 2.927336133219591
Validation loss: 2.493100401620042

Epoch: 6| Step: 4
Training loss: 2.5764540372450617
Validation loss: 2.4840364489282267

Epoch: 6| Step: 5
Training loss: 3.0887642191085285
Validation loss: 2.481863491012979

Epoch: 6| Step: 6
Training loss: 2.627613764513153
Validation loss: 2.4565573823463476

Epoch: 6| Step: 7
Training loss: 2.8580672812207157
Validation loss: 2.4669890150579676

Epoch: 6| Step: 8
Training loss: 2.454487027651336
Validation loss: 2.4756086391446805

Epoch: 6| Step: 9
Training loss: 2.3649283226071223
Validation loss: 2.482505436966824

Epoch: 6| Step: 10
Training loss: 2.937411854821552
Validation loss: 2.4952454177543775

Epoch: 6| Step: 11
Training loss: 2.3584686963848793
Validation loss: 2.4940106439326892

Epoch: 6| Step: 12
Training loss: 2.459546280244201
Validation loss: 2.514084160846669

Epoch: 6| Step: 13
Training loss: 3.0290454831516587
Validation loss: 2.5108384959299173

Epoch: 269| Step: 0
Training loss: 2.961726181757525
Validation loss: 2.5029031560573984

Epoch: 6| Step: 1
Training loss: 2.8860055664495237
Validation loss: 2.516636531899057

Epoch: 6| Step: 2
Training loss: 2.8461332290679895
Validation loss: 2.502731407763504

Epoch: 6| Step: 3
Training loss: 2.8244301280250683
Validation loss: 2.4955442313706686

Epoch: 6| Step: 4
Training loss: 1.4644039053186786
Validation loss: 2.5393639422649392

Epoch: 6| Step: 5
Training loss: 1.7839018506733193
Validation loss: 2.570612741042507

Epoch: 6| Step: 6
Training loss: 2.9487469226259972
Validation loss: 2.5743732896792104

Epoch: 6| Step: 7
Training loss: 2.4280542115407777
Validation loss: 2.5825203889337907

Epoch: 6| Step: 8
Training loss: 2.736412117844555
Validation loss: 2.5793939902345513

Epoch: 6| Step: 9
Training loss: 3.054885116389947
Validation loss: 2.575180993995461

Epoch: 6| Step: 10
Training loss: 2.8245160591369904
Validation loss: 2.5430490668760335

Epoch: 6| Step: 11
Training loss: 2.2602226302957362
Validation loss: 2.497634410428123

Epoch: 6| Step: 12
Training loss: 2.934548701303535
Validation loss: 2.480262947927442

Epoch: 6| Step: 13
Training loss: 2.5647474528235987
Validation loss: 2.4564888331295243

Epoch: 270| Step: 0
Training loss: 1.9497175476723017
Validation loss: 2.4590813020492974

Epoch: 6| Step: 1
Training loss: 2.627607594473008
Validation loss: 2.446172766364732

Epoch: 6| Step: 2
Training loss: 2.9802660391930913
Validation loss: 2.4320855966531276

Epoch: 6| Step: 3
Training loss: 2.8633453653398813
Validation loss: 2.447715955965667

Epoch: 6| Step: 4
Training loss: 3.0590135619956222
Validation loss: 2.4464078366794

Epoch: 6| Step: 5
Training loss: 2.6321701941611364
Validation loss: 2.4720189508457135

Epoch: 6| Step: 6
Training loss: 2.3895768005583333
Validation loss: 2.491103988679224

Epoch: 6| Step: 7
Training loss: 2.892242803719796
Validation loss: 2.509356454615134

Epoch: 6| Step: 8
Training loss: 2.9530701001428024
Validation loss: 2.543918447970886

Epoch: 6| Step: 9
Training loss: 2.5156705864039703
Validation loss: 2.524658724426804

Epoch: 6| Step: 10
Training loss: 2.680532605781765
Validation loss: 2.554001739363755

Epoch: 6| Step: 11
Training loss: 2.473629342674234
Validation loss: 2.546936052542979

Epoch: 6| Step: 12
Training loss: 2.490044225277023
Validation loss: 2.497256798211134

Epoch: 6| Step: 13
Training loss: 1.9928094827917169
Validation loss: 2.46979592243015

Epoch: 271| Step: 0
Training loss: 2.1447295772933233
Validation loss: 2.470872724747165

Epoch: 6| Step: 1
Training loss: 2.4937112867366786
Validation loss: 2.464968041915017

Epoch: 6| Step: 2
Training loss: 2.600519927931499
Validation loss: 2.464565692204963

Epoch: 6| Step: 3
Training loss: 2.2911155269139125
Validation loss: 2.472435533192075

Epoch: 6| Step: 4
Training loss: 2.6936727207365836
Validation loss: 2.4752972951001566

Epoch: 6| Step: 5
Training loss: 2.766537273399262
Validation loss: 2.472146057340441

Epoch: 6| Step: 6
Training loss: 3.037383490945675
Validation loss: 2.4742048163862735

Epoch: 6| Step: 7
Training loss: 2.7799484979538085
Validation loss: 2.4924571021046567

Epoch: 6| Step: 8
Training loss: 2.880465412681142
Validation loss: 2.4937322628231273

Epoch: 6| Step: 9
Training loss: 3.2216795394911304
Validation loss: 2.508547187949662

Epoch: 6| Step: 10
Training loss: 2.304564598815209
Validation loss: 2.5425610884131933

Epoch: 6| Step: 11
Training loss: 2.2468767741783893
Validation loss: 2.5414334968060155

Epoch: 6| Step: 12
Training loss: 2.733795802217169
Validation loss: 2.5539367311184775

Epoch: 6| Step: 13
Training loss: 2.921253321804497
Validation loss: 2.5234340661478663

Epoch: 272| Step: 0
Training loss: 3.0779632680782063
Validation loss: 2.5511643329466756

Epoch: 6| Step: 1
Training loss: 2.6194940679853986
Validation loss: 2.511825763122965

Epoch: 6| Step: 2
Training loss: 2.890999764557561
Validation loss: 2.5126584292819283

Epoch: 6| Step: 3
Training loss: 2.4693116140763016
Validation loss: 2.506354310451373

Epoch: 6| Step: 4
Training loss: 2.5509759381758386
Validation loss: 2.5056386199521166

Epoch: 6| Step: 5
Training loss: 2.7903177978656726
Validation loss: 2.5465678519207593

Epoch: 6| Step: 6
Training loss: 2.725065153550456
Validation loss: 2.542994541842471

Epoch: 6| Step: 7
Training loss: 2.79417007326244
Validation loss: 2.5593261081427414

Epoch: 6| Step: 8
Training loss: 2.603872379205152
Validation loss: 2.543025701595917

Epoch: 6| Step: 9
Training loss: 2.5090998022452102
Validation loss: 2.5300796823479175

Epoch: 6| Step: 10
Training loss: 2.467408793733926
Validation loss: 2.5325297173430004

Epoch: 6| Step: 11
Training loss: 3.1024551452296003
Validation loss: 2.499966610921397

Epoch: 6| Step: 12
Training loss: 2.0640700173367437
Validation loss: 2.504973811554149

Epoch: 6| Step: 13
Training loss: 1.6814292925562135
Validation loss: 2.4794751481469195

Epoch: 273| Step: 0
Training loss: 2.7490695766554327
Validation loss: 2.46711847972658

Epoch: 6| Step: 1
Training loss: 2.7916435031973714
Validation loss: 2.465213562042724

Epoch: 6| Step: 2
Training loss: 2.579076602906014
Validation loss: 2.4511823688513363

Epoch: 6| Step: 3
Training loss: 2.817271106429337
Validation loss: 2.4718890116700902

Epoch: 6| Step: 4
Training loss: 2.5105188330494936
Validation loss: 2.474347650349208

Epoch: 6| Step: 5
Training loss: 2.8556020055902493
Validation loss: 2.466719991506109

Epoch: 6| Step: 6
Training loss: 2.8978909288182586
Validation loss: 2.493658869394075

Epoch: 6| Step: 7
Training loss: 2.3269443462488635
Validation loss: 2.5031814246629995

Epoch: 6| Step: 8
Training loss: 2.3354365089065876
Validation loss: 2.4930158127057003

Epoch: 6| Step: 9
Training loss: 2.403454630732044
Validation loss: 2.5017061349119545

Epoch: 6| Step: 10
Training loss: 2.475245176559694
Validation loss: 2.478648499623313

Epoch: 6| Step: 11
Training loss: 2.8399303900555957
Validation loss: 2.4815189566163594

Epoch: 6| Step: 12
Training loss: 2.7931358020682
Validation loss: 2.477408541544479

Epoch: 6| Step: 13
Training loss: 2.218714001860538
Validation loss: 2.477146576554686

Epoch: 274| Step: 0
Training loss: 2.8080179741113
Validation loss: 2.4555106893109446

Epoch: 6| Step: 1
Training loss: 1.7556127729360178
Validation loss: 2.4533141855955707

Epoch: 6| Step: 2
Training loss: 2.8844001347365222
Validation loss: 2.4479695888882373

Epoch: 6| Step: 3
Training loss: 2.3723737350646217
Validation loss: 2.45991793710143

Epoch: 6| Step: 4
Training loss: 2.5163057721130655
Validation loss: 2.4596474418245644

Epoch: 6| Step: 5
Training loss: 2.415380519324254
Validation loss: 2.496019005540993

Epoch: 6| Step: 6
Training loss: 2.529686715854573
Validation loss: 2.521590595478816

Epoch: 6| Step: 7
Training loss: 2.859704670896723
Validation loss: 2.4782764687238106

Epoch: 6| Step: 8
Training loss: 2.703097745724915
Validation loss: 2.4980852875422888

Epoch: 6| Step: 9
Training loss: 3.049416132839318
Validation loss: 2.498739167647199

Epoch: 6| Step: 10
Training loss: 2.9432495339698717
Validation loss: 2.487869084061575

Epoch: 6| Step: 11
Training loss: 2.029087970103189
Validation loss: 2.4771579419850323

Epoch: 6| Step: 12
Training loss: 3.0231488703679856
Validation loss: 2.485873202393609

Epoch: 6| Step: 13
Training loss: 2.4732927464379384
Validation loss: 2.4799748705561004

Epoch: 275| Step: 0
Training loss: 2.063881151547938
Validation loss: 2.4596237006626303

Epoch: 6| Step: 1
Training loss: 3.0070530316541917
Validation loss: 2.466429838605858

Epoch: 6| Step: 2
Training loss: 3.1831108241848836
Validation loss: 2.492504337227326

Epoch: 6| Step: 3
Training loss: 2.5849895295571166
Validation loss: 2.478577723202322

Epoch: 6| Step: 4
Training loss: 2.2697087807742924
Validation loss: 2.4658564085558683

Epoch: 6| Step: 5
Training loss: 2.1095784407103153
Validation loss: 2.4997113071411667

Epoch: 6| Step: 6
Training loss: 2.9757093273153186
Validation loss: 2.493778816891609

Epoch: 6| Step: 7
Training loss: 2.574296825654712
Validation loss: 2.479154865102029

Epoch: 6| Step: 8
Training loss: 2.831245681725718
Validation loss: 2.4728881403721497

Epoch: 6| Step: 9
Training loss: 2.624113023859168
Validation loss: 2.452339972146993

Epoch: 6| Step: 10
Training loss: 2.8369091880874646
Validation loss: 2.4743886604242102

Epoch: 6| Step: 11
Training loss: 2.3448833522781074
Validation loss: 2.4862968877790745

Epoch: 6| Step: 12
Training loss: 2.5683641092815206
Validation loss: 2.4868312536363764

Epoch: 6| Step: 13
Training loss: 2.038871785449301
Validation loss: 2.477464719565238

Epoch: 276| Step: 0
Training loss: 1.7548758836205032
Validation loss: 2.5184545748961247

Epoch: 6| Step: 1
Training loss: 2.611570063177562
Validation loss: 2.505984556375708

Epoch: 6| Step: 2
Training loss: 2.874055790305925
Validation loss: 2.494844535291257

Epoch: 6| Step: 3
Training loss: 3.062974542714387
Validation loss: 2.5069920426987404

Epoch: 6| Step: 4
Training loss: 2.890021843745168
Validation loss: 2.4937218837739787

Epoch: 6| Step: 5
Training loss: 2.180681009051651
Validation loss: 2.4582097836067884

Epoch: 6| Step: 6
Training loss: 2.690011026863272
Validation loss: 2.458172225748172

Epoch: 6| Step: 7
Training loss: 2.742109509524618
Validation loss: 2.4418069752615867

Epoch: 6| Step: 8
Training loss: 3.1020396751950763
Validation loss: 2.4307672223471752

Epoch: 6| Step: 9
Training loss: 2.28183582047633
Validation loss: 2.458427640824235

Epoch: 6| Step: 10
Training loss: 2.6949600652733183
Validation loss: 2.4630082764535306

Epoch: 6| Step: 11
Training loss: 2.4665126077982027
Validation loss: 2.453507089469329

Epoch: 6| Step: 12
Training loss: 2.0332957603026536
Validation loss: 2.5098441469391655

Epoch: 6| Step: 13
Training loss: 2.5777642199919777
Validation loss: 2.5205285655831378

Epoch: 277| Step: 0
Training loss: 2.9432268524205827
Validation loss: 2.5329979983726627

Epoch: 6| Step: 1
Training loss: 2.8171466166427805
Validation loss: 2.5268881509926406

Epoch: 6| Step: 2
Training loss: 2.08915159938488
Validation loss: 2.4858291672187907

Epoch: 6| Step: 3
Training loss: 2.54439550359191
Validation loss: 2.4913980428996108

Epoch: 6| Step: 4
Training loss: 3.244923221050115
Validation loss: 2.4719551633577836

Epoch: 6| Step: 5
Training loss: 2.1298138564892137
Validation loss: 2.4785161483785947

Epoch: 6| Step: 6
Training loss: 2.805831293419358
Validation loss: 2.4728658025181396

Epoch: 6| Step: 7
Training loss: 2.563784393719657
Validation loss: 2.480331414771098

Epoch: 6| Step: 8
Training loss: 2.596047176984539
Validation loss: 2.470118746409668

Epoch: 6| Step: 9
Training loss: 2.3593944018242
Validation loss: 2.4823107469407106

Epoch: 6| Step: 10
Training loss: 1.9420123928982873
Validation loss: 2.4929923327574444

Epoch: 6| Step: 11
Training loss: 2.6645646950370874
Validation loss: 2.477790157391973

Epoch: 6| Step: 12
Training loss: 2.9083933156412662
Validation loss: 2.4857773313763287

Epoch: 6| Step: 13
Training loss: 2.828594358497145
Validation loss: 2.4691585894772365

Epoch: 278| Step: 0
Training loss: 2.718169051616191
Validation loss: 2.4823800991581733

Epoch: 6| Step: 1
Training loss: 2.2900133469038564
Validation loss: 2.512004511656902

Epoch: 6| Step: 2
Training loss: 3.013463327704021
Validation loss: 2.519228057412353

Epoch: 6| Step: 3
Training loss: 2.1169655321042504
Validation loss: 2.4980649514433315

Epoch: 6| Step: 4
Training loss: 2.483591111989644
Validation loss: 2.5230336489795304

Epoch: 6| Step: 5
Training loss: 2.6986109798752254
Validation loss: 2.481268271093818

Epoch: 6| Step: 6
Training loss: 2.369027609146151
Validation loss: 2.5243284754942965

Epoch: 6| Step: 7
Training loss: 2.66241135427273
Validation loss: 2.5106785230501014

Epoch: 6| Step: 8
Training loss: 3.1067266639624407
Validation loss: 2.506304791436446

Epoch: 6| Step: 9
Training loss: 2.3137561376357323
Validation loss: 2.509555823426743

Epoch: 6| Step: 10
Training loss: 2.608181252072898
Validation loss: 2.5261486731495313

Epoch: 6| Step: 11
Training loss: 2.7933221340030805
Validation loss: 2.483950258149943

Epoch: 6| Step: 12
Training loss: 2.76839097496009
Validation loss: 2.469016276119995

Epoch: 6| Step: 13
Training loss: 2.4747908841039368
Validation loss: 2.4636487301247794

Epoch: 279| Step: 0
Training loss: 2.3846424517740044
Validation loss: 2.4539552214731577

Epoch: 6| Step: 1
Training loss: 2.656861358298863
Validation loss: 2.431401810489484

Epoch: 6| Step: 2
Training loss: 3.2422351511935044
Validation loss: 2.4525198565308926

Epoch: 6| Step: 3
Training loss: 2.3332638957272906
Validation loss: 2.4526344102943836

Epoch: 6| Step: 4
Training loss: 2.322631807067136
Validation loss: 2.4668778199896813

Epoch: 6| Step: 5
Training loss: 2.7083356612757923
Validation loss: 2.4878108574409676

Epoch: 6| Step: 6
Training loss: 3.174282569628631
Validation loss: 2.4893221004793062

Epoch: 6| Step: 7
Training loss: 2.4868197138667134
Validation loss: 2.468144986634728

Epoch: 6| Step: 8
Training loss: 2.709151765455203
Validation loss: 2.4635317778664745

Epoch: 6| Step: 9
Training loss: 2.43756641395274
Validation loss: 2.461790310989864

Epoch: 6| Step: 10
Training loss: 2.318649158187199
Validation loss: 2.4634110382009595

Epoch: 6| Step: 11
Training loss: 2.8289470004918433
Validation loss: 2.4615888856948756

Epoch: 6| Step: 12
Training loss: 2.5181403054013427
Validation loss: 2.462893987128028

Epoch: 6| Step: 13
Training loss: 2.524379306458032
Validation loss: 2.4894723430257772

Epoch: 280| Step: 0
Training loss: 2.4210558090363694
Validation loss: 2.4874021038559495

Epoch: 6| Step: 1
Training loss: 2.8073461146314727
Validation loss: 2.4921506321640146

Epoch: 6| Step: 2
Training loss: 2.6399742091970957
Validation loss: 2.459326390380993

Epoch: 6| Step: 3
Training loss: 1.8744881249125673
Validation loss: 2.4640392480930466

Epoch: 6| Step: 4
Training loss: 2.8676552871655097
Validation loss: 2.4734128223440424

Epoch: 6| Step: 5
Training loss: 2.114416131485806
Validation loss: 2.462347716953169

Epoch: 6| Step: 6
Training loss: 2.745911072560108
Validation loss: 2.4704898743333237

Epoch: 6| Step: 7
Training loss: 2.9737875511360916
Validation loss: 2.4688393828604327

Epoch: 6| Step: 8
Training loss: 3.2823775034561935
Validation loss: 2.456837693621781

Epoch: 6| Step: 9
Training loss: 2.2020921382770124
Validation loss: 2.4776492488125443

Epoch: 6| Step: 10
Training loss: 2.0403570399401545
Validation loss: 2.474844302917767

Epoch: 6| Step: 11
Training loss: 2.5995074796016895
Validation loss: 2.4781825620988744

Epoch: 6| Step: 12
Training loss: 2.9057370625345498
Validation loss: 2.497239083437169

Epoch: 6| Step: 13
Training loss: 2.591621260740997
Validation loss: 2.5477419158582117

Epoch: 281| Step: 0
Training loss: 2.8442955751337773
Validation loss: 2.551874682544643

Epoch: 6| Step: 1
Training loss: 2.9004761140599697
Validation loss: 2.5997035539083746

Epoch: 6| Step: 2
Training loss: 2.1355445885528277
Validation loss: 2.5608675909738383

Epoch: 6| Step: 3
Training loss: 2.789350735171845
Validation loss: 2.5192930871647228

Epoch: 6| Step: 4
Training loss: 2.4653933920338416
Validation loss: 2.513301584810248

Epoch: 6| Step: 5
Training loss: 2.2908744020505485
Validation loss: 2.484231252414161

Epoch: 6| Step: 6
Training loss: 2.213684316788311
Validation loss: 2.5022404096805486

Epoch: 6| Step: 7
Training loss: 2.675023861359744
Validation loss: 2.4746743527530586

Epoch: 6| Step: 8
Training loss: 2.579835821147289
Validation loss: 2.484157027195707

Epoch: 6| Step: 9
Training loss: 2.5903295921436444
Validation loss: 2.5339235228991286

Epoch: 6| Step: 10
Training loss: 3.0179676187243056
Validation loss: 2.5774385335727885

Epoch: 6| Step: 11
Training loss: 2.5262569584814365
Validation loss: 2.541174367038399

Epoch: 6| Step: 12
Training loss: 2.5890329510067898
Validation loss: 2.504781372009473

Epoch: 6| Step: 13
Training loss: 2.71582329731722
Validation loss: 2.4464731327749467

Epoch: 282| Step: 0
Training loss: 3.0549516100258627
Validation loss: 2.4261321241952123

Epoch: 6| Step: 1
Training loss: 2.569926595270403
Validation loss: 2.437325484762614

Epoch: 6| Step: 2
Training loss: 2.7818650840663115
Validation loss: 2.428459284111275

Epoch: 6| Step: 3
Training loss: 2.79240588938867
Validation loss: 2.426972810046505

Epoch: 6| Step: 4
Training loss: 2.725802865001447
Validation loss: 2.4326112921938394

Epoch: 6| Step: 5
Training loss: 2.227157566794847
Validation loss: 2.422213454716883

Epoch: 6| Step: 6
Training loss: 3.0085377004707468
Validation loss: 2.441909122647156

Epoch: 6| Step: 7
Training loss: 2.8329401491402604
Validation loss: 2.4651767702124907

Epoch: 6| Step: 8
Training loss: 2.5817992875192983
Validation loss: 2.484433415492907

Epoch: 6| Step: 9
Training loss: 1.9220619420878224
Validation loss: 2.4873508022146975

Epoch: 6| Step: 10
Training loss: 2.8487866412120857
Validation loss: 2.48066015043645

Epoch: 6| Step: 11
Training loss: 2.5600937501311254
Validation loss: 2.4718859417988472

Epoch: 6| Step: 12
Training loss: 2.3267676986065475
Validation loss: 2.4520990449525737

Epoch: 6| Step: 13
Training loss: 2.461712911847697
Validation loss: 2.464555665699105

Epoch: 283| Step: 0
Training loss: 2.523322985622433
Validation loss: 2.44837020376436

Epoch: 6| Step: 1
Training loss: 1.8495534306316297
Validation loss: 2.4439378919152204

Epoch: 6| Step: 2
Training loss: 1.9204031417722454
Validation loss: 2.4509476806284254

Epoch: 6| Step: 3
Training loss: 3.015292292608344
Validation loss: 2.446111573744263

Epoch: 6| Step: 4
Training loss: 2.7561751305754925
Validation loss: 2.466885817331249

Epoch: 6| Step: 5
Training loss: 2.717794491586613
Validation loss: 2.4600183153541963

Epoch: 6| Step: 6
Training loss: 2.543589245264791
Validation loss: 2.4596862659164134

Epoch: 6| Step: 7
Training loss: 3.2551838540746245
Validation loss: 2.4959404851925537

Epoch: 6| Step: 8
Training loss: 2.883330673334148
Validation loss: 2.5220305724330023

Epoch: 6| Step: 9
Training loss: 1.8138121755026646
Validation loss: 2.546226998317691

Epoch: 6| Step: 10
Training loss: 2.824682595980633
Validation loss: 2.5467601513429536

Epoch: 6| Step: 11
Training loss: 2.669226331882598
Validation loss: 2.5671777016974855

Epoch: 6| Step: 12
Training loss: 2.6036793570749084
Validation loss: 2.5661861759662914

Epoch: 6| Step: 13
Training loss: 2.8772831019924388
Validation loss: 2.518935789495231

Epoch: 284| Step: 0
Training loss: 2.529784732149284
Validation loss: 2.4529951395756058

Epoch: 6| Step: 1
Training loss: 2.4121788601770615
Validation loss: 2.4381260642392455

Epoch: 6| Step: 2
Training loss: 2.9724586210587103
Validation loss: 2.437541553236731

Epoch: 6| Step: 3
Training loss: 2.5569311899199305
Validation loss: 2.441625296793013

Epoch: 6| Step: 4
Training loss: 2.856086382363627
Validation loss: 2.444311387913024

Epoch: 6| Step: 5
Training loss: 2.9589547234487927
Validation loss: 2.4382209521480562

Epoch: 6| Step: 6
Training loss: 2.591913239339792
Validation loss: 2.4469757404668773

Epoch: 6| Step: 7
Training loss: 2.3771232349770126
Validation loss: 2.4396290322380536

Epoch: 6| Step: 8
Training loss: 2.818634294727599
Validation loss: 2.4343614136645315

Epoch: 6| Step: 9
Training loss: 2.9497680960846244
Validation loss: 2.4520280260011607

Epoch: 6| Step: 10
Training loss: 2.4866712982127783
Validation loss: 2.4455573800590042

Epoch: 6| Step: 11
Training loss: 2.6639984212647305
Validation loss: 2.4598017808893826

Epoch: 6| Step: 12
Training loss: 2.5847048861426534
Validation loss: 2.4837688713521717

Epoch: 6| Step: 13
Training loss: 1.9829960635132222
Validation loss: 2.4780485234632716

Epoch: 285| Step: 0
Training loss: 1.7985851608361583
Validation loss: 2.5137834574620537

Epoch: 6| Step: 1
Training loss: 2.5418883576146505
Validation loss: 2.5789798158447135

Epoch: 6| Step: 2
Training loss: 2.6163092662734524
Validation loss: 2.587259054357122

Epoch: 6| Step: 3
Training loss: 2.399437115146687
Validation loss: 2.5832836319677153

Epoch: 6| Step: 4
Training loss: 2.749902550097763
Validation loss: 2.556232431933402

Epoch: 6| Step: 5
Training loss: 3.0199951762988237
Validation loss: 2.5240278285939715

Epoch: 6| Step: 6
Training loss: 2.705636329759337
Validation loss: 2.49562799393559

Epoch: 6| Step: 7
Training loss: 2.360706686152355
Validation loss: 2.4528771881347553

Epoch: 6| Step: 8
Training loss: 2.7692901118962663
Validation loss: 2.472070851181016

Epoch: 6| Step: 9
Training loss: 2.936915562705359
Validation loss: 2.4666520926314646

Epoch: 6| Step: 10
Training loss: 2.785695070682531
Validation loss: 2.4663655500389043

Epoch: 6| Step: 11
Training loss: 2.1087923728787574
Validation loss: 2.468858066705049

Epoch: 6| Step: 12
Training loss: 2.802278381895466
Validation loss: 2.4636905634448283

Epoch: 6| Step: 13
Training loss: 2.928897679993797
Validation loss: 2.4755923890879274

Epoch: 286| Step: 0
Training loss: 2.3895613354770955
Validation loss: 2.4732634187013396

Epoch: 6| Step: 1
Training loss: 2.2447194547315794
Validation loss: 2.455594210740445

Epoch: 6| Step: 2
Training loss: 2.405329045014178
Validation loss: 2.4434484507199525

Epoch: 6| Step: 3
Training loss: 3.0128961579627984
Validation loss: 2.4495150327411

Epoch: 6| Step: 4
Training loss: 2.5551315061763415
Validation loss: 2.4589574882533944

Epoch: 6| Step: 5
Training loss: 2.6432725624067532
Validation loss: 2.47291603363784

Epoch: 6| Step: 6
Training loss: 2.718400077663104
Validation loss: 2.523417019745866

Epoch: 6| Step: 7
Training loss: 2.7916408556603742
Validation loss: 2.5667477088996407

Epoch: 6| Step: 8
Training loss: 3.10399925924076
Validation loss: 2.5450312573360683

Epoch: 6| Step: 9
Training loss: 2.1576748991232195
Validation loss: 2.536432592608326

Epoch: 6| Step: 10
Training loss: 2.8273969524571387
Validation loss: 2.553902690040024

Epoch: 6| Step: 11
Training loss: 2.9786984446966893
Validation loss: 2.519799268451011

Epoch: 6| Step: 12
Training loss: 2.412457670324683
Validation loss: 2.5051930717689195

Epoch: 6| Step: 13
Training loss: 1.679421479206985
Validation loss: 2.4902742257610186

Epoch: 287| Step: 0
Training loss: 3.134565134262266
Validation loss: 2.47609679529904

Epoch: 6| Step: 1
Training loss: 2.5245578983140193
Validation loss: 2.4659603344662746

Epoch: 6| Step: 2
Training loss: 2.5601110720380618
Validation loss: 2.4342618257107564

Epoch: 6| Step: 3
Training loss: 2.99337450193147
Validation loss: 2.4351255490898205

Epoch: 6| Step: 4
Training loss: 2.2479135588116828
Validation loss: 2.450352337297109

Epoch: 6| Step: 5
Training loss: 2.5784229453192373
Validation loss: 2.4313020707296475

Epoch: 6| Step: 6
Training loss: 2.621709850688808
Validation loss: 2.447926338576403

Epoch: 6| Step: 7
Training loss: 2.544270874981341
Validation loss: 2.4558201360660212

Epoch: 6| Step: 8
Training loss: 2.4344911834062
Validation loss: 2.4449385621450013

Epoch: 6| Step: 9
Training loss: 1.6604444545333565
Validation loss: 2.4522915452311773

Epoch: 6| Step: 10
Training loss: 2.7295702764433396
Validation loss: 2.4690956298498983

Epoch: 6| Step: 11
Training loss: 2.699706015653069
Validation loss: 2.4650792019717587

Epoch: 6| Step: 12
Training loss: 2.6227992687257484
Validation loss: 2.4875895622109825

Epoch: 6| Step: 13
Training loss: 2.958671568397884
Validation loss: 2.5097869122643317

Epoch: 288| Step: 0
Training loss: 2.4506275074057484
Validation loss: 2.511067623935916

Epoch: 6| Step: 1
Training loss: 2.761287758095453
Validation loss: 2.500445020711111

Epoch: 6| Step: 2
Training loss: 2.8019387209043534
Validation loss: 2.4591181162709512

Epoch: 6| Step: 3
Training loss: 2.0932676983928764
Validation loss: 2.434585317926743

Epoch: 6| Step: 4
Training loss: 2.5430435661877304
Validation loss: 2.4341227639323457

Epoch: 6| Step: 5
Training loss: 2.348882827616634
Validation loss: 2.434430914509758

Epoch: 6| Step: 6
Training loss: 3.031007108100453
Validation loss: 2.4502623030677575

Epoch: 6| Step: 7
Training loss: 2.845608449812798
Validation loss: 2.4473878975783543

Epoch: 6| Step: 8
Training loss: 2.422609869922961
Validation loss: 2.4447313850276613

Epoch: 6| Step: 9
Training loss: 2.9690089062678893
Validation loss: 2.4762294156205695

Epoch: 6| Step: 10
Training loss: 2.3545033261998034
Validation loss: 2.467326429697107

Epoch: 6| Step: 11
Training loss: 2.6986326252024164
Validation loss: 2.502652094645854

Epoch: 6| Step: 12
Training loss: 2.397945589697035
Validation loss: 2.5123784879033044

Epoch: 6| Step: 13
Training loss: 2.737012887753635
Validation loss: 2.5912228353585935

Epoch: 289| Step: 0
Training loss: 2.2107156702913713
Validation loss: 2.6123317790933904

Epoch: 6| Step: 1
Training loss: 2.798961521757804
Validation loss: 2.621932338447598

Epoch: 6| Step: 2
Training loss: 2.1883933286827
Validation loss: 2.572806927720132

Epoch: 6| Step: 3
Training loss: 2.6695078575531643
Validation loss: 2.544166239263719

Epoch: 6| Step: 4
Training loss: 2.959694312007952
Validation loss: 2.52220176024084

Epoch: 6| Step: 5
Training loss: 2.553215139191578
Validation loss: 2.4511708437584847

Epoch: 6| Step: 6
Training loss: 2.2767768795579313
Validation loss: 2.4265149707240026

Epoch: 6| Step: 7
Training loss: 2.628082282300907
Validation loss: 2.445001505798793

Epoch: 6| Step: 8
Training loss: 2.6998781318005274
Validation loss: 2.44133537993576

Epoch: 6| Step: 9
Training loss: 3.1491569662504117
Validation loss: 2.4642132754158492

Epoch: 6| Step: 10
Training loss: 2.635751052168772
Validation loss: 2.4807975253368233

Epoch: 6| Step: 11
Training loss: 2.1421209523933555
Validation loss: 2.465541833507705

Epoch: 6| Step: 12
Training loss: 2.2999649542750764
Validation loss: 2.4844482085006425

Epoch: 6| Step: 13
Training loss: 3.1893336687768272
Validation loss: 2.472102887785113

Epoch: 290| Step: 0
Training loss: 2.2644783012039515
Validation loss: 2.4663881879131493

Epoch: 6| Step: 1
Training loss: 2.5277050296622785
Validation loss: 2.449623969986441

Epoch: 6| Step: 2
Training loss: 2.2147358863037243
Validation loss: 2.4365520464025012

Epoch: 6| Step: 3
Training loss: 2.3418249744196147
Validation loss: 2.451872884968875

Epoch: 6| Step: 4
Training loss: 2.7687393153826183
Validation loss: 2.434395939500238

Epoch: 6| Step: 5
Training loss: 2.4882268255920126
Validation loss: 2.4196935551256904

Epoch: 6| Step: 6
Training loss: 2.983815724959834
Validation loss: 2.4294606582235265

Epoch: 6| Step: 7
Training loss: 2.6794828553645167
Validation loss: 2.4502529232220733

Epoch: 6| Step: 8
Training loss: 2.0262241101596548
Validation loss: 2.4421476728281064

Epoch: 6| Step: 9
Training loss: 2.419865420516576
Validation loss: 2.4212150455221217

Epoch: 6| Step: 10
Training loss: 2.646990085158101
Validation loss: 2.4279904463177755

Epoch: 6| Step: 11
Training loss: 3.2507561024209055
Validation loss: 2.458890553166725

Epoch: 6| Step: 12
Training loss: 2.2793077535623
Validation loss: 2.4971049353205865

Epoch: 6| Step: 13
Training loss: 2.8781975918208738
Validation loss: 2.53777068665604

Epoch: 291| Step: 0
Training loss: 2.5485956663333007
Validation loss: 2.5731775228715974

Epoch: 6| Step: 1
Training loss: 2.3154315409498065
Validation loss: 2.5853078459930563

Epoch: 6| Step: 2
Training loss: 2.6315860778310443
Validation loss: 2.5955567860297815

Epoch: 6| Step: 3
Training loss: 2.812702765043335
Validation loss: 2.550262950784882

Epoch: 6| Step: 4
Training loss: 2.754343071240283
Validation loss: 2.470086588068177

Epoch: 6| Step: 5
Training loss: 2.736380490136212
Validation loss: 2.468346826216335

Epoch: 6| Step: 6
Training loss: 2.8668475456245517
Validation loss: 2.4741669045023236

Epoch: 6| Step: 7
Training loss: 2.3185808803854915
Validation loss: 2.452753483422758

Epoch: 6| Step: 8
Training loss: 2.6735367097176743
Validation loss: 2.448772292580045

Epoch: 6| Step: 9
Training loss: 2.674607513725711
Validation loss: 2.4459863173561818

Epoch: 6| Step: 10
Training loss: 2.1771006119573255
Validation loss: 2.4720230088718744

Epoch: 6| Step: 11
Training loss: 2.7838594860648187
Validation loss: 2.45578251504103

Epoch: 6| Step: 12
Training loss: 2.4900706517870357
Validation loss: 2.4691752177523596

Epoch: 6| Step: 13
Training loss: 2.2934064561068537
Validation loss: 2.4803561194669883

Epoch: 292| Step: 0
Training loss: 2.7603477517408512
Validation loss: 2.5150452306689033

Epoch: 6| Step: 1
Training loss: 2.630440478262182
Validation loss: 2.5156907536886264

Epoch: 6| Step: 2
Training loss: 2.3753106767336014
Validation loss: 2.5196377522397464

Epoch: 6| Step: 3
Training loss: 2.361216855641954
Validation loss: 2.4967754344110906

Epoch: 6| Step: 4
Training loss: 1.6849765984243072
Validation loss: 2.4915819075547816

Epoch: 6| Step: 5
Training loss: 2.5859537268184236
Validation loss: 2.4819242845345495

Epoch: 6| Step: 6
Training loss: 2.903470258436614
Validation loss: 2.458809637692126

Epoch: 6| Step: 7
Training loss: 2.6279113610123708
Validation loss: 2.4501517692705486

Epoch: 6| Step: 8
Training loss: 2.4445541229592167
Validation loss: 2.46048137228955

Epoch: 6| Step: 9
Training loss: 2.735852000645063
Validation loss: 2.457516356322918

Epoch: 6| Step: 10
Training loss: 2.800446345311974
Validation loss: 2.460887477540202

Epoch: 6| Step: 11
Training loss: 2.8295469976938366
Validation loss: 2.4624464589831043

Epoch: 6| Step: 12
Training loss: 2.0307419361601062
Validation loss: 2.4722586688964223

Epoch: 6| Step: 13
Training loss: 3.19376789244774
Validation loss: 2.469993496209099

Epoch: 293| Step: 0
Training loss: 2.620605605217646
Validation loss: 2.4563636195533025

Epoch: 6| Step: 1
Training loss: 2.302174585067213
Validation loss: 2.460125516689359

Epoch: 6| Step: 2
Training loss: 2.559685068130502
Validation loss: 2.477265079974362

Epoch: 6| Step: 3
Training loss: 2.691161389555407
Validation loss: 2.486840426447065

Epoch: 6| Step: 4
Training loss: 2.2800657778169198
Validation loss: 2.4698092461230665

Epoch: 6| Step: 5
Training loss: 2.6057394135908
Validation loss: 2.4626460621151147

Epoch: 6| Step: 6
Training loss: 2.097103450968435
Validation loss: 2.4670013698139104

Epoch: 6| Step: 7
Training loss: 2.364890617760612
Validation loss: 2.4476484788451622

Epoch: 6| Step: 8
Training loss: 2.18420478037512
Validation loss: 2.5236061349957346

Epoch: 6| Step: 9
Training loss: 2.6126657168746874
Validation loss: 2.5329400966319127

Epoch: 6| Step: 10
Training loss: 3.135832360847262
Validation loss: 2.5487815072223565

Epoch: 6| Step: 11
Training loss: 2.6924631288743583
Validation loss: 2.572732600399843

Epoch: 6| Step: 12
Training loss: 3.0099840920366945
Validation loss: 2.509808419981049

Epoch: 6| Step: 13
Training loss: 3.0154739895500398
Validation loss: 2.494035988171896

Epoch: 294| Step: 0
Training loss: 3.0360927634360046
Validation loss: 2.443077156287779

Epoch: 6| Step: 1
Training loss: 2.555074493307645
Validation loss: 2.405381265218047

Epoch: 6| Step: 2
Training loss: 2.6464342851578952
Validation loss: 2.4114447758333224

Epoch: 6| Step: 3
Training loss: 2.846896935052879
Validation loss: 2.412151435776616

Epoch: 6| Step: 4
Training loss: 1.7374878176255206
Validation loss: 2.4247199617089885

Epoch: 6| Step: 5
Training loss: 2.3269284649039017
Validation loss: 2.453838183322027

Epoch: 6| Step: 6
Training loss: 2.8321073535033197
Validation loss: 2.4354230594981816

Epoch: 6| Step: 7
Training loss: 2.4395377615546905
Validation loss: 2.4499073630928834

Epoch: 6| Step: 8
Training loss: 2.8433319455225763
Validation loss: 2.468585348291592

Epoch: 6| Step: 9
Training loss: 2.1472399894151457
Validation loss: 2.4704926730231502

Epoch: 6| Step: 10
Training loss: 2.251221431231073
Validation loss: 2.517219111240378

Epoch: 6| Step: 11
Training loss: 2.3678972546221817
Validation loss: 2.5220033301224394

Epoch: 6| Step: 12
Training loss: 3.000424990750822
Validation loss: 2.501669602061551

Epoch: 6| Step: 13
Training loss: 2.871451800590641
Validation loss: 2.4797231977271506

Epoch: 295| Step: 0
Training loss: 2.5107383891210087
Validation loss: 2.436759945767799

Epoch: 6| Step: 1
Training loss: 2.46504435501274
Validation loss: 2.4751725037387535

Epoch: 6| Step: 2
Training loss: 3.036299128254697
Validation loss: 2.4382353205455747

Epoch: 6| Step: 3
Training loss: 2.4045358472449596
Validation loss: 2.423073411312416

Epoch: 6| Step: 4
Training loss: 1.9820798080805389
Validation loss: 2.437614383543154

Epoch: 6| Step: 5
Training loss: 2.2068547271082566
Validation loss: 2.4269069660540272

Epoch: 6| Step: 6
Training loss: 1.7557066786314255
Validation loss: 2.4131852265145004

Epoch: 6| Step: 7
Training loss: 3.1836857132998126
Validation loss: 2.4363649437448744

Epoch: 6| Step: 8
Training loss: 2.947968193835
Validation loss: 2.440130225592578

Epoch: 6| Step: 9
Training loss: 2.0463503099578166
Validation loss: 2.4459449563218914

Epoch: 6| Step: 10
Training loss: 3.032704427170265
Validation loss: 2.43191178130269

Epoch: 6| Step: 11
Training loss: 2.5788129408861806
Validation loss: 2.4535771100863553

Epoch: 6| Step: 12
Training loss: 2.644491581358684
Validation loss: 2.4606312311337755

Epoch: 6| Step: 13
Training loss: 2.394562912400272
Validation loss: 2.5261734473399735

Epoch: 296| Step: 0
Training loss: 2.8131360500400895
Validation loss: 2.570005749963797

Epoch: 6| Step: 1
Training loss: 2.4899613054938112
Validation loss: 2.5826470266910198

Epoch: 6| Step: 2
Training loss: 2.0528299616110055
Validation loss: 2.575253005819186

Epoch: 6| Step: 3
Training loss: 2.385402085261082
Validation loss: 2.5000683693099637

Epoch: 6| Step: 4
Training loss: 3.1632341218859032
Validation loss: 2.4770644183211914

Epoch: 6| Step: 5
Training loss: 1.9072793776489345
Validation loss: 2.4582557391363133

Epoch: 6| Step: 6
Training loss: 2.7228450408675755
Validation loss: 2.4301182784718294

Epoch: 6| Step: 7
Training loss: 2.292102448615404
Validation loss: 2.4383442465524956

Epoch: 6| Step: 8
Training loss: 2.5007863715327026
Validation loss: 2.4247208836687384

Epoch: 6| Step: 9
Training loss: 3.0512368305301845
Validation loss: 2.450358719312982

Epoch: 6| Step: 10
Training loss: 2.466794555373019
Validation loss: 2.434080038017304

Epoch: 6| Step: 11
Training loss: 3.252112508997682
Validation loss: 2.454973639210169

Epoch: 6| Step: 12
Training loss: 2.875201010933233
Validation loss: 2.465605698534695

Epoch: 6| Step: 13
Training loss: 2.7875113995921965
Validation loss: 2.4689043670987307

Epoch: 297| Step: 0
Training loss: 2.698956224231394
Validation loss: 2.5009056563321694

Epoch: 6| Step: 1
Training loss: 2.5788783966658912
Validation loss: 2.50211360246037

Epoch: 6| Step: 2
Training loss: 2.7066791079694075
Validation loss: 2.5763816241522064

Epoch: 6| Step: 3
Training loss: 2.2566076317544943
Validation loss: 2.614855389147073

Epoch: 6| Step: 4
Training loss: 2.455911984857797
Validation loss: 2.572291778875747

Epoch: 6| Step: 5
Training loss: 2.64362007344908
Validation loss: 2.5502199600887723

Epoch: 6| Step: 6
Training loss: 3.0275099185746477
Validation loss: 2.521834708919933

Epoch: 6| Step: 7
Training loss: 2.729339671778746
Validation loss: 2.5121687861642785

Epoch: 6| Step: 8
Training loss: 2.600562650982393
Validation loss: 2.5022816879801297

Epoch: 6| Step: 9
Training loss: 2.772086402718971
Validation loss: 2.4914268752233575

Epoch: 6| Step: 10
Training loss: 1.8946365799086584
Validation loss: 2.4803592925483273

Epoch: 6| Step: 11
Training loss: 2.255375375060209
Validation loss: 2.484705438590472

Epoch: 6| Step: 12
Training loss: 2.9149391144402235
Validation loss: 2.482622050964393

Epoch: 6| Step: 13
Training loss: 2.438939574209059
Validation loss: 2.471946296220114

Epoch: 298| Step: 0
Training loss: 2.652505097236014
Validation loss: 2.4424265782035874

Epoch: 6| Step: 1
Training loss: 2.57744557068832
Validation loss: 2.437152251918183

Epoch: 6| Step: 2
Training loss: 2.479285250694055
Validation loss: 2.4373972776195894

Epoch: 6| Step: 3
Training loss: 2.4665896463827495
Validation loss: 2.4180283626321066

Epoch: 6| Step: 4
Training loss: 2.233083498441279
Validation loss: 2.4177758974247436

Epoch: 6| Step: 5
Training loss: 3.1551130909910916
Validation loss: 2.4246314667433935

Epoch: 6| Step: 6
Training loss: 2.4564413991033867
Validation loss: 2.43503371953753

Epoch: 6| Step: 7
Training loss: 1.950809723902534
Validation loss: 2.445210455996698

Epoch: 6| Step: 8
Training loss: 2.424716980139508
Validation loss: 2.4362402322255843

Epoch: 6| Step: 9
Training loss: 3.0055984076427946
Validation loss: 2.4497606365210203

Epoch: 6| Step: 10
Training loss: 2.7970398582588993
Validation loss: 2.4236112279759032

Epoch: 6| Step: 11
Training loss: 2.535161328420857
Validation loss: 2.44750740297265

Epoch: 6| Step: 12
Training loss: 2.575338441403101
Validation loss: 2.4414277437309915

Epoch: 6| Step: 13
Training loss: 2.4004269776412266
Validation loss: 2.4517097725212995

Epoch: 299| Step: 0
Training loss: 2.657349213191753
Validation loss: 2.454090682601298

Epoch: 6| Step: 1
Training loss: 2.7247727430580806
Validation loss: 2.4997312001341694

Epoch: 6| Step: 2
Training loss: 2.4500730931803383
Validation loss: 2.497809376315787

Epoch: 6| Step: 3
Training loss: 2.6705860799126824
Validation loss: 2.5131664681299064

Epoch: 6| Step: 4
Training loss: 2.0668357590236948
Validation loss: 2.547781618773081

Epoch: 6| Step: 5
Training loss: 2.7647422631774043
Validation loss: 2.573503192676019

Epoch: 6| Step: 6
Training loss: 2.4647365734176896
Validation loss: 2.5529853102496767

Epoch: 6| Step: 7
Training loss: 2.9313885035866467
Validation loss: 2.524758250862477

Epoch: 6| Step: 8
Training loss: 2.005592633037024
Validation loss: 2.4768935295744314

Epoch: 6| Step: 9
Training loss: 2.4990331687603615
Validation loss: 2.4497398678683764

Epoch: 6| Step: 10
Training loss: 3.0684024217719608
Validation loss: 2.444903361015342

Epoch: 6| Step: 11
Training loss: 2.850993227637204
Validation loss: 2.43388414135883

Epoch: 6| Step: 12
Training loss: 1.9530364970182463
Validation loss: 2.427141918658494

Epoch: 6| Step: 13
Training loss: 2.2084410899041216
Validation loss: 2.4200967538144034

Epoch: 300| Step: 0
Training loss: 2.6039278658414045
Validation loss: 2.4398814984135275

Epoch: 6| Step: 1
Training loss: 2.559126237976195
Validation loss: 2.436059597183501

Epoch: 6| Step: 2
Training loss: 2.559117014718071
Validation loss: 2.4469532037793456

Epoch: 6| Step: 3
Training loss: 2.4753332125684877
Validation loss: 2.4532747021173384

Epoch: 6| Step: 4
Training loss: 2.448487776560825
Validation loss: 2.4786496311359967

Epoch: 6| Step: 5
Training loss: 2.6342204599540686
Validation loss: 2.489922149857242

Epoch: 6| Step: 6
Training loss: 2.5992305717509003
Validation loss: 2.440353420923099

Epoch: 6| Step: 7
Training loss: 2.8074847115485086
Validation loss: 2.458409184293249

Epoch: 6| Step: 8
Training loss: 2.584841031880919
Validation loss: 2.431238795601897

Epoch: 6| Step: 9
Training loss: 2.490602665014885
Validation loss: 2.440645467506314

Epoch: 6| Step: 10
Training loss: 2.650114085782643
Validation loss: 2.448311753987491

Epoch: 6| Step: 11
Training loss: 2.747088017628689
Validation loss: 2.4374082236185988

Epoch: 6| Step: 12
Training loss: 2.2428747313541333
Validation loss: 2.4362511118675

Epoch: 6| Step: 13
Training loss: 2.6282035716101717
Validation loss: 2.449393103936386

Epoch: 301| Step: 0
Training loss: 2.5499952428436785
Validation loss: 2.509905110498691

Epoch: 6| Step: 1
Training loss: 2.186114608210355
Validation loss: 2.5483699376855307

Epoch: 6| Step: 2
Training loss: 2.61040015269965
Validation loss: 2.590576236570262

Epoch: 6| Step: 3
Training loss: 3.136709324880765
Validation loss: 2.6143153498226988

Epoch: 6| Step: 4
Training loss: 2.6818357703656366
Validation loss: 2.5531877727550767

Epoch: 6| Step: 5
Training loss: 2.547156944349034
Validation loss: 2.501436643147717

Epoch: 6| Step: 6
Training loss: 2.788921534291055
Validation loss: 2.4714268587542976

Epoch: 6| Step: 7
Training loss: 2.381471950970508
Validation loss: 2.464980516002899

Epoch: 6| Step: 8
Training loss: 2.1042207264014583
Validation loss: 2.449942342687895

Epoch: 6| Step: 9
Training loss: 2.722518063600023
Validation loss: 2.416624753784471

Epoch: 6| Step: 10
Training loss: 2.692787912005732
Validation loss: 2.4140677312150522

Epoch: 6| Step: 11
Training loss: 2.4724095900989744
Validation loss: 2.432706696599992

Epoch: 6| Step: 12
Training loss: 2.646780300135211
Validation loss: 2.426556246158824

Epoch: 6| Step: 13
Training loss: 2.7374814943010346
Validation loss: 2.4452140982520767

Epoch: 302| Step: 0
Training loss: 2.9695648681214974
Validation loss: 2.476893768664627

Epoch: 6| Step: 1
Training loss: 2.6202418482154752
Validation loss: 2.454409585168322

Epoch: 6| Step: 2
Training loss: 2.7324608778879584
Validation loss: 2.496966825144318

Epoch: 6| Step: 3
Training loss: 2.443611504027837
Validation loss: 2.490615960775853

Epoch: 6| Step: 4
Training loss: 2.8971813183980744
Validation loss: 2.487076896590281

Epoch: 6| Step: 5
Training loss: 2.364260333570785
Validation loss: 2.488305545048922

Epoch: 6| Step: 6
Training loss: 1.9490122714412332
Validation loss: 2.513449780462217

Epoch: 6| Step: 7
Training loss: 1.859325889131168
Validation loss: 2.522649148825171

Epoch: 6| Step: 8
Training loss: 2.45050667175244
Validation loss: 2.542447069355435

Epoch: 6| Step: 9
Training loss: 2.4276827179867277
Validation loss: 2.512565939298229

Epoch: 6| Step: 10
Training loss: 2.031474761265313
Validation loss: 2.522418359212407

Epoch: 6| Step: 11
Training loss: 2.808357579006801
Validation loss: 2.546929146534393

Epoch: 6| Step: 12
Training loss: 2.8038735231289613
Validation loss: 2.5634978957765675

Epoch: 6| Step: 13
Training loss: 3.4204048238381883
Validation loss: 2.550343049507703

Epoch: 303| Step: 0
Training loss: 2.3685077472903924
Validation loss: 2.527918735355653

Epoch: 6| Step: 1
Training loss: 2.2799032756299176
Validation loss: 2.4869490265315126

Epoch: 6| Step: 2
Training loss: 2.327753229348146
Validation loss: 2.4890170413318664

Epoch: 6| Step: 3
Training loss: 1.7543074185163496
Validation loss: 2.462255100373514

Epoch: 6| Step: 4
Training loss: 2.4968039109824907
Validation loss: 2.4506009453305446

Epoch: 6| Step: 5
Training loss: 2.3176515265085986
Validation loss: 2.446897560499356

Epoch: 6| Step: 6
Training loss: 3.0793677595149047
Validation loss: 2.448859716258183

Epoch: 6| Step: 7
Training loss: 2.5375215050298134
Validation loss: 2.439166261762831

Epoch: 6| Step: 8
Training loss: 2.742092902570612
Validation loss: 2.434743955959005

Epoch: 6| Step: 9
Training loss: 2.5173039490505547
Validation loss: 2.4197611792955454

Epoch: 6| Step: 10
Training loss: 2.3204764876552275
Validation loss: 2.434559436930095

Epoch: 6| Step: 11
Training loss: 2.909554848198063
Validation loss: 2.4414852988294697

Epoch: 6| Step: 12
Training loss: 2.916076782157575
Validation loss: 2.4270288023900006

Epoch: 6| Step: 13
Training loss: 2.6498559624735623
Validation loss: 2.4323667060702285

Epoch: 304| Step: 0
Training loss: 2.1590201233937107
Validation loss: 2.4436769912917473

Epoch: 6| Step: 1
Training loss: 2.6717861227679562
Validation loss: 2.48681997365129

Epoch: 6| Step: 2
Training loss: 2.387256318284028
Validation loss: 2.5099589228752746

Epoch: 6| Step: 3
Training loss: 2.4166266887471246
Validation loss: 2.483361132581033

Epoch: 6| Step: 4
Training loss: 2.4152019490535186
Validation loss: 2.4787755464466055

Epoch: 6| Step: 5
Training loss: 2.9004585232477584
Validation loss: 2.450008699787993

Epoch: 6| Step: 6
Training loss: 2.294100896204557
Validation loss: 2.4375413670801467

Epoch: 6| Step: 7
Training loss: 2.248904703362757
Validation loss: 2.4348453551811344

Epoch: 6| Step: 8
Training loss: 2.596680605666912
Validation loss: 2.410188569771146

Epoch: 6| Step: 9
Training loss: 2.9772397369738326
Validation loss: 2.424807523060406

Epoch: 6| Step: 10
Training loss: 2.192986719093864
Validation loss: 2.426520500498168

Epoch: 6| Step: 11
Training loss: 2.451108747786467
Validation loss: 2.4294493165811857

Epoch: 6| Step: 12
Training loss: 2.886054307094892
Validation loss: 2.4410640836753577

Epoch: 6| Step: 13
Training loss: 2.7123864778592
Validation loss: 2.459076660226071

Epoch: 305| Step: 0
Training loss: 2.2285791734064806
Validation loss: 2.515261612183539

Epoch: 6| Step: 1
Training loss: 2.575189294616357
Validation loss: 2.5333232949332722

Epoch: 6| Step: 2
Training loss: 2.8775470894839
Validation loss: 2.5876372175078983

Epoch: 6| Step: 3
Training loss: 2.4833804845067253
Validation loss: 2.574443519700014

Epoch: 6| Step: 4
Training loss: 2.693099022468003
Validation loss: 2.566421595399701

Epoch: 6| Step: 5
Training loss: 2.1829891015976446
Validation loss: 2.530828722706016

Epoch: 6| Step: 6
Training loss: 2.9292932677459786
Validation loss: 2.4848001293975894

Epoch: 6| Step: 7
Training loss: 2.5180210052474603
Validation loss: 2.4746819773384874

Epoch: 6| Step: 8
Training loss: 3.0593234345217835
Validation loss: 2.432058134253506

Epoch: 6| Step: 9
Training loss: 2.452068806110694
Validation loss: 2.416361931359543

Epoch: 6| Step: 10
Training loss: 2.259499523482723
Validation loss: 2.3932755390676066

Epoch: 6| Step: 11
Training loss: 1.7717673886300205
Validation loss: 2.4079025404719245

Epoch: 6| Step: 12
Training loss: 2.5573184030744724
Validation loss: 2.4056672220347948

Epoch: 6| Step: 13
Training loss: 2.4086831411872947
Validation loss: 2.4101425922800797

Epoch: 306| Step: 0
Training loss: 2.5308289354286337
Validation loss: 2.403594305326301

Epoch: 6| Step: 1
Training loss: 2.567806796545403
Validation loss: 2.385884698811561

Epoch: 6| Step: 2
Training loss: 2.1873734573820096
Validation loss: 2.398073449429811

Epoch: 6| Step: 3
Training loss: 2.6710598243060697
Validation loss: 2.418878009971394

Epoch: 6| Step: 4
Training loss: 2.2399423237595943
Validation loss: 2.430716767792718

Epoch: 6| Step: 5
Training loss: 2.868129980698511
Validation loss: 2.4328862960712536

Epoch: 6| Step: 6
Training loss: 2.783224712087336
Validation loss: 2.461257779866092

Epoch: 6| Step: 7
Training loss: 2.1009004251958574
Validation loss: 2.4829583695607926

Epoch: 6| Step: 8
Training loss: 2.5320669668962967
Validation loss: 2.4999799625044927

Epoch: 6| Step: 9
Training loss: 2.00166882985189
Validation loss: 2.477953070814561

Epoch: 6| Step: 10
Training loss: 2.501400936515903
Validation loss: 2.500485179336021

Epoch: 6| Step: 11
Training loss: 2.956401319441709
Validation loss: 2.508637095004157

Epoch: 6| Step: 12
Training loss: 2.1953360668288533
Validation loss: 2.4579094413038653

Epoch: 6| Step: 13
Training loss: 3.055948528874924
Validation loss: 2.454581907656355

Epoch: 307| Step: 0
Training loss: 2.3082819436018744
Validation loss: 2.4343374711816517

Epoch: 6| Step: 1
Training loss: 2.5878609594408175
Validation loss: 2.40906928319439

Epoch: 6| Step: 2
Training loss: 2.5800263762789175
Validation loss: 2.422728296034103

Epoch: 6| Step: 3
Training loss: 2.740443356974496
Validation loss: 2.4448575970064854

Epoch: 6| Step: 4
Training loss: 2.1716644404593373
Validation loss: 2.4195678137283365

Epoch: 6| Step: 5
Training loss: 2.2748569108168457
Validation loss: 2.4139109332058077

Epoch: 6| Step: 6
Training loss: 2.342414170100392
Validation loss: 2.417919454440356

Epoch: 6| Step: 7
Training loss: 2.6699059799156517
Validation loss: 2.410880942703387

Epoch: 6| Step: 8
Training loss: 2.5137136080937355
Validation loss: 2.4103310385806607

Epoch: 6| Step: 9
Training loss: 2.6251928167825818
Validation loss: 2.423430182650479

Epoch: 6| Step: 10
Training loss: 2.155986714529178
Validation loss: 2.4162977069225473

Epoch: 6| Step: 11
Training loss: 2.781575558928223
Validation loss: 2.4206495981771363

Epoch: 6| Step: 12
Training loss: 2.8244064922902665
Validation loss: 2.4061741970796984

Epoch: 6| Step: 13
Training loss: 2.477555421888736
Validation loss: 2.4230809877241763

Epoch: 308| Step: 0
Training loss: 2.251052398397156
Validation loss: 2.4448885405495755

Epoch: 6| Step: 1
Training loss: 2.0317476103223995
Validation loss: 2.502828169385089

Epoch: 6| Step: 2
Training loss: 1.9230879390841193
Validation loss: 2.5478198167864208

Epoch: 6| Step: 3
Training loss: 2.286600292436215
Validation loss: 2.52239589692983

Epoch: 6| Step: 4
Training loss: 2.9798738578366306
Validation loss: 2.5751942234084524

Epoch: 6| Step: 5
Training loss: 2.971894215422402
Validation loss: 2.5698061757069035

Epoch: 6| Step: 6
Training loss: 1.7755841945966517
Validation loss: 2.5041924066534333

Epoch: 6| Step: 7
Training loss: 2.79102954901071
Validation loss: 2.469903978662885

Epoch: 6| Step: 8
Training loss: 2.717940988423541
Validation loss: 2.425213322899638

Epoch: 6| Step: 9
Training loss: 2.535448712846717
Validation loss: 2.395828063730773

Epoch: 6| Step: 10
Training loss: 2.38822926672808
Validation loss: 2.3851030201477372

Epoch: 6| Step: 11
Training loss: 2.8218933915967837
Validation loss: 2.4027229896138143

Epoch: 6| Step: 12
Training loss: 2.5670057551665337
Validation loss: 2.3663164424162213

Epoch: 6| Step: 13
Training loss: 3.021788154624381
Validation loss: 2.4010390329554503

Epoch: 309| Step: 0
Training loss: 2.666055331091683
Validation loss: 2.3924533609051704

Epoch: 6| Step: 1
Training loss: 2.651263594316003
Validation loss: 2.4018196538051884

Epoch: 6| Step: 2
Training loss: 2.7148875720103045
Validation loss: 2.4057904014833222

Epoch: 6| Step: 3
Training loss: 2.5673259788308127
Validation loss: 2.4452737071736284

Epoch: 6| Step: 4
Training loss: 2.5462681333994515
Validation loss: 2.454975984626032

Epoch: 6| Step: 5
Training loss: 2.440760949875021
Validation loss: 2.5166002035651642

Epoch: 6| Step: 6
Training loss: 2.3157023346171393
Validation loss: 2.578705015346402

Epoch: 6| Step: 7
Training loss: 2.3519175315334246
Validation loss: 2.6077079514926873

Epoch: 6| Step: 8
Training loss: 2.4287680698572687
Validation loss: 2.6053663064128996

Epoch: 6| Step: 9
Training loss: 2.218829086398598
Validation loss: 2.580308123980788

Epoch: 6| Step: 10
Training loss: 2.894035018825022
Validation loss: 2.5113920055624583

Epoch: 6| Step: 11
Training loss: 2.8854558141005993
Validation loss: 2.4469307611769273

Epoch: 6| Step: 12
Training loss: 2.1563313786726837
Validation loss: 2.42560146371575

Epoch: 6| Step: 13
Training loss: 2.717977567539457
Validation loss: 2.3850949522701685

Epoch: 310| Step: 0
Training loss: 2.489176494816101
Validation loss: 2.3938101880741915

Epoch: 6| Step: 1
Training loss: 2.830540758101951
Validation loss: 2.398914017925055

Epoch: 6| Step: 2
Training loss: 2.381910810118809
Validation loss: 2.3985971820725327

Epoch: 6| Step: 3
Training loss: 2.576577941959298
Validation loss: 2.3928481956143415

Epoch: 6| Step: 4
Training loss: 2.5111045264361236
Validation loss: 2.41693660330351

Epoch: 6| Step: 5
Training loss: 2.6326799217824868
Validation loss: 2.434965029743305

Epoch: 6| Step: 6
Training loss: 2.3510731539619862
Validation loss: 2.454959135384385

Epoch: 6| Step: 7
Training loss: 1.7011199487760706
Validation loss: 2.4834610784009175

Epoch: 6| Step: 8
Training loss: 2.197141815088214
Validation loss: 2.5008590657892884

Epoch: 6| Step: 9
Training loss: 2.7298691600145126
Validation loss: 2.50630462368467

Epoch: 6| Step: 10
Training loss: 2.8077263905393024
Validation loss: 2.546832932543107

Epoch: 6| Step: 11
Training loss: 2.1931808820265193
Validation loss: 2.5604759984876035

Epoch: 6| Step: 12
Training loss: 2.595204416650619
Validation loss: 2.526326094711764

Epoch: 6| Step: 13
Training loss: 2.8820559948598024
Validation loss: 2.4624760196564024

Epoch: 311| Step: 0
Training loss: 2.2996093667057713
Validation loss: 2.433993015625531

Epoch: 6| Step: 1
Training loss: 2.344403391996415
Validation loss: 2.4337867464480545

Epoch: 6| Step: 2
Training loss: 2.4581234298146244
Validation loss: 2.405916258764524

Epoch: 6| Step: 3
Training loss: 2.312047140782638
Validation loss: 2.427048501019101

Epoch: 6| Step: 4
Training loss: 2.6751191371163476
Validation loss: 2.400319390895503

Epoch: 6| Step: 5
Training loss: 2.527718234729126
Validation loss: 2.4042778920387504

Epoch: 6| Step: 6
Training loss: 2.6476682372847553
Validation loss: 2.3951986883856775

Epoch: 6| Step: 7
Training loss: 2.686296237780155
Validation loss: 2.4018026803586725

Epoch: 6| Step: 8
Training loss: 2.4482205682506764
Validation loss: 2.410843298309971

Epoch: 6| Step: 9
Training loss: 2.9454656505482406
Validation loss: 2.413568707643476

Epoch: 6| Step: 10
Training loss: 2.4165121445637756
Validation loss: 2.428921161398268

Epoch: 6| Step: 11
Training loss: 2.4118401133872753
Validation loss: 2.4135289988381667

Epoch: 6| Step: 12
Training loss: 2.3994944477084625
Validation loss: 2.436953329495976

Epoch: 6| Step: 13
Training loss: 2.1675234225546443
Validation loss: 2.455988020897192

Epoch: 312| Step: 0
Training loss: 2.8276916509110106
Validation loss: 2.430126927948832

Epoch: 6| Step: 1
Training loss: 2.234974173923598
Validation loss: 2.44538320762648

Epoch: 6| Step: 2
Training loss: 2.428034180031376
Validation loss: 2.4534894856520264

Epoch: 6| Step: 3
Training loss: 2.6322547933161857
Validation loss: 2.444542944680219

Epoch: 6| Step: 4
Training loss: 2.9757726227026096
Validation loss: 2.4202415427784936

Epoch: 6| Step: 5
Training loss: 2.692139192171013
Validation loss: 2.4247486437971997

Epoch: 6| Step: 6
Training loss: 2.6631939050927267
Validation loss: 2.452899696522733

Epoch: 6| Step: 7
Training loss: 2.0776638580593785
Validation loss: 2.4719045632058685

Epoch: 6| Step: 8
Training loss: 2.4429763505925397
Validation loss: 2.515090262887133

Epoch: 6| Step: 9
Training loss: 2.0265870786189626
Validation loss: 2.514541780014097

Epoch: 6| Step: 10
Training loss: 2.328985682389837
Validation loss: 2.529765620688631

Epoch: 6| Step: 11
Training loss: 2.4683119952687402
Validation loss: 2.5336148188891654

Epoch: 6| Step: 12
Training loss: 2.4607303592758822
Validation loss: 2.5106184012930126

Epoch: 6| Step: 13
Training loss: 2.296911330162828
Validation loss: 2.4463425042587197

Epoch: 313| Step: 0
Training loss: 2.2135242655949
Validation loss: 2.390563940471786

Epoch: 6| Step: 1
Training loss: 2.746989943667496
Validation loss: 2.3908421069782615

Epoch: 6| Step: 2
Training loss: 2.3839696857137977
Validation loss: 2.384813856868168

Epoch: 6| Step: 3
Training loss: 3.3057755647276763
Validation loss: 2.390620176999576

Epoch: 6| Step: 4
Training loss: 2.27622243714757
Validation loss: 2.4080547036891677

Epoch: 6| Step: 5
Training loss: 3.0875315737943874
Validation loss: 2.4127585533350104

Epoch: 6| Step: 6
Training loss: 1.9555077018927502
Validation loss: 2.3996197335154057

Epoch: 6| Step: 7
Training loss: 2.0654902888937543
Validation loss: 2.394421119956384

Epoch: 6| Step: 8
Training loss: 2.271208099331444
Validation loss: 2.404307790428076

Epoch: 6| Step: 9
Training loss: 2.388139916587793
Validation loss: 2.4060797128350297

Epoch: 6| Step: 10
Training loss: 2.419895667672355
Validation loss: 2.4438833703376948

Epoch: 6| Step: 11
Training loss: 2.210585495388467
Validation loss: 2.4561217818070795

Epoch: 6| Step: 12
Training loss: 3.248257536717387
Validation loss: 2.516234145606155

Epoch: 6| Step: 13
Training loss: 2.269486707555584
Validation loss: 2.571341867416716

Epoch: 314| Step: 0
Training loss: 3.105700137556971
Validation loss: 2.644683263022586

Epoch: 6| Step: 1
Training loss: 2.623988183611339
Validation loss: 2.5557007238067326

Epoch: 6| Step: 2
Training loss: 2.37504055590887
Validation loss: 2.488169892167179

Epoch: 6| Step: 3
Training loss: 2.758038476433531
Validation loss: 2.426388206123153

Epoch: 6| Step: 4
Training loss: 1.7737576367977985
Validation loss: 2.3944515450610107

Epoch: 6| Step: 5
Training loss: 2.3991013394156337
Validation loss: 2.4015905651365834

Epoch: 6| Step: 6
Training loss: 2.322703353142458
Validation loss: 2.3873349705313376

Epoch: 6| Step: 7
Training loss: 3.099632912097544
Validation loss: 2.4132057562873506

Epoch: 6| Step: 8
Training loss: 2.762054379800053
Validation loss: 2.4049219686525665

Epoch: 6| Step: 9
Training loss: 2.576670195744488
Validation loss: 2.4020004964986468

Epoch: 6| Step: 10
Training loss: 2.06945149493741
Validation loss: 2.4064977193679153

Epoch: 6| Step: 11
Training loss: 2.7563633555935767
Validation loss: 2.415127903642433

Epoch: 6| Step: 12
Training loss: 2.9365667930475032
Validation loss: 2.4442445226788796

Epoch: 6| Step: 13
Training loss: 2.110226268658824
Validation loss: 2.4792034869942445

Epoch: 315| Step: 0
Training loss: 2.3840308904758687
Validation loss: 2.5190694869290313

Epoch: 6| Step: 1
Training loss: 2.2809083238547387
Validation loss: 2.5527340506199994

Epoch: 6| Step: 2
Training loss: 2.0322176462442556
Validation loss: 2.5719700035301623

Epoch: 6| Step: 3
Training loss: 2.736789095467546
Validation loss: 2.548449001420976

Epoch: 6| Step: 4
Training loss: 2.9445939136050727
Validation loss: 2.4900174957937726

Epoch: 6| Step: 5
Training loss: 2.7859115111571735
Validation loss: 2.454551887401922

Epoch: 6| Step: 6
Training loss: 3.3409686062618644
Validation loss: 2.401281246139099

Epoch: 6| Step: 7
Training loss: 2.7374015407187513
Validation loss: 2.3974039551719293

Epoch: 6| Step: 8
Training loss: 2.638308982262819
Validation loss: 2.4084477955815653

Epoch: 6| Step: 9
Training loss: 2.601367198498151
Validation loss: 2.407061641985703

Epoch: 6| Step: 10
Training loss: 1.8032484385849763
Validation loss: 2.3807651405865804

Epoch: 6| Step: 11
Training loss: 2.0507998511061176
Validation loss: 2.382358514636398

Epoch: 6| Step: 12
Training loss: 2.2208310965216027
Validation loss: 2.4029144353598797

Epoch: 6| Step: 13
Training loss: 2.2161462038953554
Validation loss: 2.405363713660369

Epoch: 316| Step: 0
Training loss: 2.563202180256196
Validation loss: 2.4596328446538367

Epoch: 6| Step: 1
Training loss: 2.763503645774241
Validation loss: 2.4623255776017716

Epoch: 6| Step: 2
Training loss: 2.3555441570705957
Validation loss: 2.5129194508362227

Epoch: 6| Step: 3
Training loss: 2.653635870428478
Validation loss: 2.4961633200910147

Epoch: 6| Step: 4
Training loss: 2.4855217356401944
Validation loss: 2.507989512675494

Epoch: 6| Step: 5
Training loss: 2.7502747311776594
Validation loss: 2.509565975585489

Epoch: 6| Step: 6
Training loss: 2.225643784899817
Validation loss: 2.4742769166816307

Epoch: 6| Step: 7
Training loss: 1.8303884204491558
Validation loss: 2.449136299705087

Epoch: 6| Step: 8
Training loss: 2.6909841087379585
Validation loss: 2.4419550133010888

Epoch: 6| Step: 9
Training loss: 2.5731257200575963
Validation loss: 2.452550911413989

Epoch: 6| Step: 10
Training loss: 2.644990461364738
Validation loss: 2.46732141426592

Epoch: 6| Step: 11
Training loss: 2.691656048481157
Validation loss: 2.4563421740648117

Epoch: 6| Step: 12
Training loss: 2.60511047553692
Validation loss: 2.457471881876219

Epoch: 6| Step: 13
Training loss: 1.254850038330525
Validation loss: 2.449560926377551

Epoch: 317| Step: 0
Training loss: 2.4285124362865105
Validation loss: 2.4422349085121193

Epoch: 6| Step: 1
Training loss: 2.493396143079648
Validation loss: 2.428107870929474

Epoch: 6| Step: 2
Training loss: 2.675498156642974
Validation loss: 2.4357529967016047

Epoch: 6| Step: 3
Training loss: 2.7635683505345354
Validation loss: 2.443684617125591

Epoch: 6| Step: 4
Training loss: 2.4232575438907515
Validation loss: 2.4648754166657754

Epoch: 6| Step: 5
Training loss: 2.012333629673638
Validation loss: 2.4365825940749466

Epoch: 6| Step: 6
Training loss: 1.60127508794471
Validation loss: 2.4534261955026198

Epoch: 6| Step: 7
Training loss: 3.1724483178560647
Validation loss: 2.4318903594850068

Epoch: 6| Step: 8
Training loss: 2.279090800118132
Validation loss: 2.4132764910390674

Epoch: 6| Step: 9
Training loss: 2.6243367038302843
Validation loss: 2.4307116051039164

Epoch: 6| Step: 10
Training loss: 2.0971372164690862
Validation loss: 2.4431298886553066

Epoch: 6| Step: 11
Training loss: 2.7466656671293843
Validation loss: 2.4707261620389143

Epoch: 6| Step: 12
Training loss: 2.5902068054821443
Validation loss: 2.479308096316689

Epoch: 6| Step: 13
Training loss: 1.940874545013459
Validation loss: 2.5087855237832883

Epoch: 318| Step: 0
Training loss: 2.434284828484577
Validation loss: 2.5171188884820372

Epoch: 6| Step: 1
Training loss: 2.5299187444371785
Validation loss: 2.5367508131483127

Epoch: 6| Step: 2
Training loss: 2.000059722962357
Validation loss: 2.5287980489567987

Epoch: 6| Step: 3
Training loss: 2.7130428351153797
Validation loss: 2.4889891843057863

Epoch: 6| Step: 4
Training loss: 2.3473919864135215
Validation loss: 2.444686371784878

Epoch: 6| Step: 5
Training loss: 2.2210850852665804
Validation loss: 2.402768727111494

Epoch: 6| Step: 6
Training loss: 2.6494048835885047
Validation loss: 2.4038591678289194

Epoch: 6| Step: 7
Training loss: 2.8493767709427416
Validation loss: 2.3990494762127526

Epoch: 6| Step: 8
Training loss: 2.162216556032412
Validation loss: 2.403734802626707

Epoch: 6| Step: 9
Training loss: 2.6014325450251286
Validation loss: 2.406934239481385

Epoch: 6| Step: 10
Training loss: 2.700499477810907
Validation loss: 2.4061269186626486

Epoch: 6| Step: 11
Training loss: 2.7189188937639717
Validation loss: 2.416851966049533

Epoch: 6| Step: 12
Training loss: 2.159962209088377
Validation loss: 2.4350247895422004

Epoch: 6| Step: 13
Training loss: 2.1584620531893983
Validation loss: 2.4305165713612302

Epoch: 319| Step: 0
Training loss: 2.715010779203089
Validation loss: 2.4187662359228375

Epoch: 6| Step: 1
Training loss: 2.326044164013636
Validation loss: 2.4168892076550135

Epoch: 6| Step: 2
Training loss: 2.328938898768183
Validation loss: 2.4067071726216143

Epoch: 6| Step: 3
Training loss: 2.7309790749685834
Validation loss: 2.4298918778269565

Epoch: 6| Step: 4
Training loss: 2.45383914344454
Validation loss: 2.45197904087964

Epoch: 6| Step: 5
Training loss: 2.615507491923435
Validation loss: 2.444727071971716

Epoch: 6| Step: 6
Training loss: 2.611718866848636
Validation loss: 2.4720331948719054

Epoch: 6| Step: 7
Training loss: 2.4736432219480937
Validation loss: 2.5261089154040977

Epoch: 6| Step: 8
Training loss: 2.088094560389314
Validation loss: 2.5474747017723898

Epoch: 6| Step: 9
Training loss: 2.58846636431723
Validation loss: 2.5415376287176668

Epoch: 6| Step: 10
Training loss: 2.215820097303317
Validation loss: 2.536055376442848

Epoch: 6| Step: 11
Training loss: 2.5100083289445174
Validation loss: 2.528151046870438

Epoch: 6| Step: 12
Training loss: 2.579164607509927
Validation loss: 2.5136266914137244

Epoch: 6| Step: 13
Training loss: 2.433579446373996
Validation loss: 2.436040019830618

Epoch: 320| Step: 0
Training loss: 2.618117437690965
Validation loss: 2.389091161567796

Epoch: 6| Step: 1
Training loss: 2.1441994776947606
Validation loss: 2.3597855086192614

Epoch: 6| Step: 2
Training loss: 2.7965200188266564
Validation loss: 2.3651871756990848

Epoch: 6| Step: 3
Training loss: 2.6833522638004625
Validation loss: 2.3630911292039527

Epoch: 6| Step: 4
Training loss: 2.0714080790741622
Validation loss: 2.369990333434264

Epoch: 6| Step: 5
Training loss: 2.566033137356515
Validation loss: 2.374472079623775

Epoch: 6| Step: 6
Training loss: 3.1718524499852667
Validation loss: 2.3722587788908482

Epoch: 6| Step: 7
Training loss: 2.949091988169833
Validation loss: 2.3660271079259645

Epoch: 6| Step: 8
Training loss: 2.174721259309933
Validation loss: 2.3787004068002635

Epoch: 6| Step: 9
Training loss: 2.2134251702264285
Validation loss: 2.378326509716585

Epoch: 6| Step: 10
Training loss: 2.7939385711044586
Validation loss: 2.36866557562049

Epoch: 6| Step: 11
Training loss: 1.9400621516310146
Validation loss: 2.394147497199415

Epoch: 6| Step: 12
Training loss: 2.356212492221828
Validation loss: 2.420531999744743

Epoch: 6| Step: 13
Training loss: 2.276243385669833
Validation loss: 2.4534729334032668

Epoch: 321| Step: 0
Training loss: 2.236594638185812
Validation loss: 2.4793546978802947

Epoch: 6| Step: 1
Training loss: 2.460782872746346
Validation loss: 2.5239649593819578

Epoch: 6| Step: 2
Training loss: 2.1935945895973443
Validation loss: 2.5547500376406806

Epoch: 6| Step: 3
Training loss: 2.918703203826797
Validation loss: 2.5629307424627448

Epoch: 6| Step: 4
Training loss: 3.0436863573380393
Validation loss: 2.489605966380074

Epoch: 6| Step: 5
Training loss: 2.6791534336489047
Validation loss: 2.4415755821653256

Epoch: 6| Step: 6
Training loss: 2.605206935373262
Validation loss: 2.437575639634949

Epoch: 6| Step: 7
Training loss: 2.0332286880747708
Validation loss: 2.420001995326872

Epoch: 6| Step: 8
Training loss: 3.111529806512611
Validation loss: 2.4138780451653754

Epoch: 6| Step: 9
Training loss: 2.2766656667652234
Validation loss: 2.402115806839143

Epoch: 6| Step: 10
Training loss: 2.19156236823438
Validation loss: 2.4148676859186993

Epoch: 6| Step: 11
Training loss: 2.033500481077634
Validation loss: 2.4355094287009136

Epoch: 6| Step: 12
Training loss: 2.3295135453569933
Validation loss: 2.469305994290418

Epoch: 6| Step: 13
Training loss: 2.5357705710628875
Validation loss: 2.4957825362399575

Epoch: 322| Step: 0
Training loss: 2.2903540811447916
Validation loss: 2.5038586095048423

Epoch: 6| Step: 1
Training loss: 2.9563026084815878
Validation loss: 2.473065091301727

Epoch: 6| Step: 2
Training loss: 2.95169597947916
Validation loss: 2.4312753839852417

Epoch: 6| Step: 3
Training loss: 1.9261430319284212
Validation loss: 2.408408022037248

Epoch: 6| Step: 4
Training loss: 2.3359187198764304
Validation loss: 2.42549404764976

Epoch: 6| Step: 5
Training loss: 2.831236587054752
Validation loss: 2.4091553511012798

Epoch: 6| Step: 6
Training loss: 2.715441916454068
Validation loss: 2.4097833675214164

Epoch: 6| Step: 7
Training loss: 2.483138634476002
Validation loss: 2.4105624264859697

Epoch: 6| Step: 8
Training loss: 2.6621404521468786
Validation loss: 2.4277600309714304

Epoch: 6| Step: 9
Training loss: 1.941159146277491
Validation loss: 2.460280996463422

Epoch: 6| Step: 10
Training loss: 2.6004427312828176
Validation loss: 2.465802507038743

Epoch: 6| Step: 11
Training loss: 2.325672060729461
Validation loss: 2.521059875424421

Epoch: 6| Step: 12
Training loss: 1.9891055333950454
Validation loss: 2.5190304738555684

Epoch: 6| Step: 13
Training loss: 2.215904345207201
Validation loss: 2.51003228908757

Epoch: 323| Step: 0
Training loss: 2.798917397608013
Validation loss: 2.487053235847365

Epoch: 6| Step: 1
Training loss: 2.4153604814163843
Validation loss: 2.471491842382232

Epoch: 6| Step: 2
Training loss: 2.9544732785245538
Validation loss: 2.4591584327002165

Epoch: 6| Step: 3
Training loss: 2.3278490965526095
Validation loss: 2.440599877332159

Epoch: 6| Step: 4
Training loss: 2.737018636944574
Validation loss: 2.3793594448908846

Epoch: 6| Step: 5
Training loss: 2.7438487702060015
Validation loss: 2.3640296580178233

Epoch: 6| Step: 6
Training loss: 2.2507666235477988
Validation loss: 2.3816853682154044

Epoch: 6| Step: 7
Training loss: 2.625104629611218
Validation loss: 2.3616067161919787

Epoch: 6| Step: 8
Training loss: 2.187564303951621
Validation loss: 2.37073870728707

Epoch: 6| Step: 9
Training loss: 2.5759245758861606
Validation loss: 2.416832608079827

Epoch: 6| Step: 10
Training loss: 2.365192743717793
Validation loss: 2.454549488314151

Epoch: 6| Step: 11
Training loss: 1.747496585433309
Validation loss: 2.471413740872455

Epoch: 6| Step: 12
Training loss: 2.217199616671272
Validation loss: 2.5047157643677944

Epoch: 6| Step: 13
Training loss: 2.0157016473435534
Validation loss: 2.5192738523561458

Epoch: 324| Step: 0
Training loss: 2.1756956676040438
Validation loss: 2.5187505831715606

Epoch: 6| Step: 1
Training loss: 2.9365607850135826
Validation loss: 2.4737438733722588

Epoch: 6| Step: 2
Training loss: 2.214301041141326
Validation loss: 2.451613503522427

Epoch: 6| Step: 3
Training loss: 2.3600014366533464
Validation loss: 2.4049132445137835

Epoch: 6| Step: 4
Training loss: 2.6480881902294007
Validation loss: 2.3920799555431365

Epoch: 6| Step: 5
Training loss: 1.8852843840614633
Validation loss: 2.376600750426719

Epoch: 6| Step: 6
Training loss: 2.4570555086863854
Validation loss: 2.3701012190262056

Epoch: 6| Step: 7
Training loss: 2.3282119427518437
Validation loss: 2.3991812585295484

Epoch: 6| Step: 8
Training loss: 2.3933120287032863
Validation loss: 2.3986279197341895

Epoch: 6| Step: 9
Training loss: 2.414864218707483
Validation loss: 2.4188904970566782

Epoch: 6| Step: 10
Training loss: 3.173287213521958
Validation loss: 2.48241423184565

Epoch: 6| Step: 11
Training loss: 1.9896254876216408
Validation loss: 2.497758856529657

Epoch: 6| Step: 12
Training loss: 2.381423094858634
Validation loss: 2.5428924113072813

Epoch: 6| Step: 13
Training loss: 2.9786121590401686
Validation loss: 2.5190047012544663

Epoch: 325| Step: 0
Training loss: 2.7497494323324796
Validation loss: 2.4946878549369615

Epoch: 6| Step: 1
Training loss: 2.2978880847341934
Validation loss: 2.4482513949427256

Epoch: 6| Step: 2
Training loss: 2.4304607179092708
Validation loss: 2.4341277097980067

Epoch: 6| Step: 3
Training loss: 2.8499063777604188
Validation loss: 2.4032306316313803

Epoch: 6| Step: 4
Training loss: 1.8420825465673138
Validation loss: 2.397471810268964

Epoch: 6| Step: 5
Training loss: 1.8418265832829033
Validation loss: 2.410350369527722

Epoch: 6| Step: 6
Training loss: 2.6388529412570634
Validation loss: 2.4328131766930214

Epoch: 6| Step: 7
Training loss: 2.402580237185027
Validation loss: 2.396692644255421

Epoch: 6| Step: 8
Training loss: 2.5002698752650114
Validation loss: 2.4395267095143973

Epoch: 6| Step: 9
Training loss: 2.3516069072193044
Validation loss: 2.4374090114088864

Epoch: 6| Step: 10
Training loss: 2.4010419093950417
Validation loss: 2.466861922396914

Epoch: 6| Step: 11
Training loss: 2.4829364186326175
Validation loss: 2.4608514794497167

Epoch: 6| Step: 12
Training loss: 3.0237808229752807
Validation loss: 2.4711463516072643

Epoch: 6| Step: 13
Training loss: 1.3305982113457921
Validation loss: 2.434507834173876

Epoch: 326| Step: 0
Training loss: 2.434699087642944
Validation loss: 2.4521730957641936

Epoch: 6| Step: 1
Training loss: 2.1424697389546545
Validation loss: 2.4361953977808795

Epoch: 6| Step: 2
Training loss: 2.90922082805964
Validation loss: 2.4491563773910365

Epoch: 6| Step: 3
Training loss: 2.508901579439684
Validation loss: 2.472635164067116

Epoch: 6| Step: 4
Training loss: 2.1201454136119104
Validation loss: 2.4542117742516516

Epoch: 6| Step: 5
Training loss: 2.7965783329480427
Validation loss: 2.4021746042569787

Epoch: 6| Step: 6
Training loss: 2.082850082298779
Validation loss: 2.4095460881866417

Epoch: 6| Step: 7
Training loss: 2.3759689362290266
Validation loss: 2.4257125402213284

Epoch: 6| Step: 8
Training loss: 2.302454807695363
Validation loss: 2.419810540101738

Epoch: 6| Step: 9
Training loss: 2.3644352893166105
Validation loss: 2.453314057064212

Epoch: 6| Step: 10
Training loss: 2.448583785253378
Validation loss: 2.424303597616957

Epoch: 6| Step: 11
Training loss: 2.562088072627605
Validation loss: 2.4498007092883256

Epoch: 6| Step: 12
Training loss: 2.265374215814465
Validation loss: 2.455834538246294

Epoch: 6| Step: 13
Training loss: 3.0174283184901944
Validation loss: 2.4345597444120184

Epoch: 327| Step: 0
Training loss: 2.132337244761421
Validation loss: 2.3962333951539696

Epoch: 6| Step: 1
Training loss: 2.722700384102481
Validation loss: 2.386508005441097

Epoch: 6| Step: 2
Training loss: 2.3687820351882762
Validation loss: 2.367145532678487

Epoch: 6| Step: 3
Training loss: 2.8754950387428027
Validation loss: 2.36258820816539

Epoch: 6| Step: 4
Training loss: 2.3861902528999375
Validation loss: 2.3824168166716353

Epoch: 6| Step: 5
Training loss: 2.2857895715269843
Validation loss: 2.3736992692110177

Epoch: 6| Step: 6
Training loss: 2.211224540706209
Validation loss: 2.384920504883256

Epoch: 6| Step: 7
Training loss: 2.4734190235905773
Validation loss: 2.369372873354145

Epoch: 6| Step: 8
Training loss: 1.792631495718894
Validation loss: 2.3777509612858343

Epoch: 6| Step: 9
Training loss: 2.226578990139046
Validation loss: 2.423558497210147

Epoch: 6| Step: 10
Training loss: 2.709596065667503
Validation loss: 2.443502589351319

Epoch: 6| Step: 11
Training loss: 2.5683946498290537
Validation loss: 2.459420268554293

Epoch: 6| Step: 12
Training loss: 2.7388525351931037
Validation loss: 2.4858902247048875

Epoch: 6| Step: 13
Training loss: 2.233964148675157
Validation loss: 2.5059599785034514

Epoch: 328| Step: 0
Training loss: 1.886977910472997
Validation loss: 2.547377932734982

Epoch: 6| Step: 1
Training loss: 2.8107422316085136
Validation loss: 2.556267946314025

Epoch: 6| Step: 2
Training loss: 2.3754001079634137
Validation loss: 2.5060368437822054

Epoch: 6| Step: 3
Training loss: 2.9026499775360177
Validation loss: 2.4957058399868077

Epoch: 6| Step: 4
Training loss: 2.8476971072600517
Validation loss: 2.422420191324159

Epoch: 6| Step: 5
Training loss: 2.239608823645969
Validation loss: 2.374178886415673

Epoch: 6| Step: 6
Training loss: 2.2448550847441053
Validation loss: 2.3644267519111257

Epoch: 6| Step: 7
Training loss: 2.652943965994484
Validation loss: 2.3871003312769234

Epoch: 6| Step: 8
Training loss: 2.6216721102720064
Validation loss: 2.353982902089568

Epoch: 6| Step: 9
Training loss: 2.579782034368143
Validation loss: 2.349507925232404

Epoch: 6| Step: 10
Training loss: 2.1676467243943014
Validation loss: 2.3525625929978706

Epoch: 6| Step: 11
Training loss: 2.139821925196467
Validation loss: 2.3633380917973126

Epoch: 6| Step: 12
Training loss: 2.3982936555055825
Validation loss: 2.3809226161587613

Epoch: 6| Step: 13
Training loss: 1.99864997599179
Validation loss: 2.394139196383913

Epoch: 329| Step: 0
Training loss: 2.3883035396076115
Validation loss: 2.4355121602213257

Epoch: 6| Step: 1
Training loss: 2.5422688588990217
Validation loss: 2.434065867849944

Epoch: 6| Step: 2
Training loss: 2.2367052851307294
Validation loss: 2.385205658022173

Epoch: 6| Step: 3
Training loss: 2.520283904507599
Validation loss: 2.356920654959121

Epoch: 6| Step: 4
Training loss: 2.9376749838797833
Validation loss: 2.380363407784152

Epoch: 6| Step: 5
Training loss: 2.06420746842142
Validation loss: 2.3853416819773736

Epoch: 6| Step: 6
Training loss: 2.3945617176003156
Validation loss: 2.37464351601676

Epoch: 6| Step: 7
Training loss: 2.485184447660093
Validation loss: 2.4047242057392424

Epoch: 6| Step: 8
Training loss: 2.332271697717197
Validation loss: 2.4483433219197557

Epoch: 6| Step: 9
Training loss: 2.378860949255663
Validation loss: 2.4984364234592467

Epoch: 6| Step: 10
Training loss: 2.3620685082432047
Validation loss: 2.5053043554725916

Epoch: 6| Step: 11
Training loss: 2.1873381418564595
Validation loss: 2.542591330903833

Epoch: 6| Step: 12
Training loss: 2.763754346715579
Validation loss: 2.5885912281229695

Epoch: 6| Step: 13
Training loss: 2.427982431200494
Validation loss: 2.537615210011403

Epoch: 330| Step: 0
Training loss: 2.5898349123152378
Validation loss: 2.5160212703072258

Epoch: 6| Step: 1
Training loss: 1.9294566275058238
Validation loss: 2.4498570369306365

Epoch: 6| Step: 2
Training loss: 2.6193793840128157
Validation loss: 2.3892248724982297

Epoch: 6| Step: 3
Training loss: 2.365513174823009
Validation loss: 2.384451299003616

Epoch: 6| Step: 4
Training loss: 2.271982048272684
Validation loss: 2.383034711186753

Epoch: 6| Step: 5
Training loss: 2.7105637878162994
Validation loss: 2.3764758487179285

Epoch: 6| Step: 6
Training loss: 2.2689565433192396
Validation loss: 2.3713112224383712

Epoch: 6| Step: 7
Training loss: 2.5596301127481125
Validation loss: 2.3693482941732067

Epoch: 6| Step: 8
Training loss: 2.538824545640632
Validation loss: 2.3951857363498577

Epoch: 6| Step: 9
Training loss: 2.451388576700865
Validation loss: 2.3927464298522243

Epoch: 6| Step: 10
Training loss: 2.43147501553896
Validation loss: 2.4007419723642704

Epoch: 6| Step: 11
Training loss: 2.5846666053920866
Validation loss: 2.391272861158794

Epoch: 6| Step: 12
Training loss: 2.4468198767600082
Validation loss: 2.3744614535112136

Epoch: 6| Step: 13
Training loss: 2.6664384108447217
Validation loss: 2.3773433499702565

Epoch: 331| Step: 0
Training loss: 2.6851952894856237
Validation loss: 2.458911167378328

Epoch: 6| Step: 1
Training loss: 2.7050735418508105
Validation loss: 2.5355454791430647

Epoch: 6| Step: 2
Training loss: 2.5810197704434428
Validation loss: 2.59079817114666

Epoch: 6| Step: 3
Training loss: 3.0759162530201083
Validation loss: 2.65847865595427

Epoch: 6| Step: 4
Training loss: 2.3581843119021397
Validation loss: 2.6624766574706626

Epoch: 6| Step: 5
Training loss: 1.5783636837988135
Validation loss: 2.5541330818267793

Epoch: 6| Step: 6
Training loss: 2.6908901921283466
Validation loss: 2.505032359712416

Epoch: 6| Step: 7
Training loss: 2.5418725060665746
Validation loss: 2.494458351850465

Epoch: 6| Step: 8
Training loss: 1.9166962856270864
Validation loss: 2.4579093244859904

Epoch: 6| Step: 9
Training loss: 1.7933449610199645
Validation loss: 2.430679296653444

Epoch: 6| Step: 10
Training loss: 2.305722382521632
Validation loss: 2.419479051908383

Epoch: 6| Step: 11
Training loss: 2.078465369322614
Validation loss: 2.4248657824145194

Epoch: 6| Step: 12
Training loss: 2.389135258067561
Validation loss: 2.425390160384538

Epoch: 6| Step: 13
Training loss: 3.2139376618393602
Validation loss: 2.391950285661798

Epoch: 332| Step: 0
Training loss: 2.7372915354047667
Validation loss: 2.3686526614110015

Epoch: 6| Step: 1
Training loss: 2.9013030906332866
Validation loss: 2.402475938512498

Epoch: 6| Step: 2
Training loss: 2.0780719951093873
Validation loss: 2.3957066235378366

Epoch: 6| Step: 3
Training loss: 2.6348048971429177
Validation loss: 2.400607410513658

Epoch: 6| Step: 4
Training loss: 2.617192145955531
Validation loss: 2.4102425003301566

Epoch: 6| Step: 5
Training loss: 2.0556092026156563
Validation loss: 2.4097083917427193

Epoch: 6| Step: 6
Training loss: 2.0769763726408987
Validation loss: 2.4178053850258854

Epoch: 6| Step: 7
Training loss: 1.9562449446055261
Validation loss: 2.431747509160334

Epoch: 6| Step: 8
Training loss: 2.8292355543541237
Validation loss: 2.428395084022168

Epoch: 6| Step: 9
Training loss: 1.8637975461281977
Validation loss: 2.4231740240443935

Epoch: 6| Step: 10
Training loss: 2.139381325857543
Validation loss: 2.43755775721895

Epoch: 6| Step: 11
Training loss: 2.2285193694849674
Validation loss: 2.4282772795065735

Epoch: 6| Step: 12
Training loss: 2.4186984980814747
Validation loss: 2.4305376946593373

Epoch: 6| Step: 13
Training loss: 3.158318927366337
Validation loss: 2.4401097332352277

Epoch: 333| Step: 0
Training loss: 2.2122518454143196
Validation loss: 2.4911387283825452

Epoch: 6| Step: 1
Training loss: 2.5523352570008586
Validation loss: 2.519246404186707

Epoch: 6| Step: 2
Training loss: 2.3603110572328707
Validation loss: 2.5648604785347326

Epoch: 6| Step: 3
Training loss: 2.3652055456670977
Validation loss: 2.5647228053463316

Epoch: 6| Step: 4
Training loss: 2.06906285988707
Validation loss: 2.5254635642296988

Epoch: 6| Step: 5
Training loss: 2.8272791488025915
Validation loss: 2.547197461546245

Epoch: 6| Step: 6
Training loss: 2.174796684671793
Validation loss: 2.4681212352866617

Epoch: 6| Step: 7
Training loss: 2.2519764166998
Validation loss: 2.385661507082641

Epoch: 6| Step: 8
Training loss: 2.1146199891870485
Validation loss: 2.3762828253104606

Epoch: 6| Step: 9
Training loss: 2.251264428786701
Validation loss: 2.36653166730659

Epoch: 6| Step: 10
Training loss: 2.548854877433837
Validation loss: 2.3824870274089256

Epoch: 6| Step: 11
Training loss: 2.730875969946717
Validation loss: 2.3714517145889804

Epoch: 6| Step: 12
Training loss: 2.815327134714146
Validation loss: 2.3749452626732324

Epoch: 6| Step: 13
Training loss: 2.7606308668029778
Validation loss: 2.378203332313323

Epoch: 334| Step: 0
Training loss: 1.8664455455988178
Validation loss: 2.3621922388610916

Epoch: 6| Step: 1
Training loss: 2.563955498414815
Validation loss: 2.353021718616719

Epoch: 6| Step: 2
Training loss: 2.334587600198478
Validation loss: 2.382752729339014

Epoch: 6| Step: 3
Training loss: 2.2372535356712557
Validation loss: 2.3740727698444504

Epoch: 6| Step: 4
Training loss: 2.2099191861458767
Validation loss: 2.3730843616709816

Epoch: 6| Step: 5
Training loss: 2.7515566494915795
Validation loss: 2.4391068094400805

Epoch: 6| Step: 6
Training loss: 2.885974834636433
Validation loss: 2.4894271141161837

Epoch: 6| Step: 7
Training loss: 3.084701870156431
Validation loss: 2.61880772823363

Epoch: 6| Step: 8
Training loss: 1.9879433095512926
Validation loss: 2.6285023039063855

Epoch: 6| Step: 9
Training loss: 2.9486654204641156
Validation loss: 2.5961618202355092

Epoch: 6| Step: 10
Training loss: 2.085197174482482
Validation loss: 2.506646823162512

Epoch: 6| Step: 11
Training loss: 2.5491513803636234
Validation loss: 2.4325037345987823

Epoch: 6| Step: 12
Training loss: 2.165070116700494
Validation loss: 2.400275983161841

Epoch: 6| Step: 13
Training loss: 1.841237247109517
Validation loss: 2.35289913629061

Epoch: 335| Step: 0
Training loss: 2.494548193745306
Validation loss: 2.3647580281250247

Epoch: 6| Step: 1
Training loss: 2.547502873262801
Validation loss: 2.366086838447636

Epoch: 6| Step: 2
Training loss: 2.9649716074518495
Validation loss: 2.363080207818147

Epoch: 6| Step: 3
Training loss: 2.0185583490154864
Validation loss: 2.3341006461772222

Epoch: 6| Step: 4
Training loss: 2.3817114115151945
Validation loss: 2.322590643979156

Epoch: 6| Step: 5
Training loss: 2.7087494652733937
Validation loss: 2.3285736105444923

Epoch: 6| Step: 6
Training loss: 2.13938232884223
Validation loss: 2.346454565540615

Epoch: 6| Step: 7
Training loss: 1.7366643693778183
Validation loss: 2.3456736392161113

Epoch: 6| Step: 8
Training loss: 2.6325728763009857
Validation loss: 2.3769039980429696

Epoch: 6| Step: 9
Training loss: 1.7851255318233716
Validation loss: 2.403744578364969

Epoch: 6| Step: 10
Training loss: 2.085356099115839
Validation loss: 2.4336828839880775

Epoch: 6| Step: 11
Training loss: 3.087330795779085
Validation loss: 2.4625114484793307

Epoch: 6| Step: 12
Training loss: 2.2212379368511908
Validation loss: 2.4796017493975238

Epoch: 6| Step: 13
Training loss: 2.7925062957118962
Validation loss: 2.567701969755781

Epoch: 336| Step: 0
Training loss: 2.9589099232588953
Validation loss: 2.5771420640736102

Epoch: 6| Step: 1
Training loss: 2.403481513317125
Validation loss: 2.5682259970312113

Epoch: 6| Step: 2
Training loss: 2.417151687445546
Validation loss: 2.4911387016258435

Epoch: 6| Step: 3
Training loss: 2.200942561501117
Validation loss: 2.442988530858906

Epoch: 6| Step: 4
Training loss: 2.5386740988988565
Validation loss: 2.4295659088402988

Epoch: 6| Step: 5
Training loss: 1.9051474212314268
Validation loss: 2.3991805084086475

Epoch: 6| Step: 6
Training loss: 2.0787728812678243
Validation loss: 2.3983228043512637

Epoch: 6| Step: 7
Training loss: 2.440121048441774
Validation loss: 2.3838364570121504

Epoch: 6| Step: 8
Training loss: 2.529619327448891
Validation loss: 2.376209842489094

Epoch: 6| Step: 9
Training loss: 2.204475043297659
Validation loss: 2.369066987676486

Epoch: 6| Step: 10
Training loss: 2.0172370555886436
Validation loss: 2.383430853404016

Epoch: 6| Step: 11
Training loss: 1.8583194076404057
Validation loss: 2.3978756931401857

Epoch: 6| Step: 12
Training loss: 3.1155276360789794
Validation loss: 2.400197084215389

Epoch: 6| Step: 13
Training loss: 3.2455782521166845
Validation loss: 2.404755663039456

Epoch: 337| Step: 0
Training loss: 2.3022970960515825
Validation loss: 2.4225510044448026

Epoch: 6| Step: 1
Training loss: 1.7631355222045253
Validation loss: 2.458058454671172

Epoch: 6| Step: 2
Training loss: 2.5232980412073287
Validation loss: 2.5110575717748436

Epoch: 6| Step: 3
Training loss: 1.8159301133761343
Validation loss: 2.538525570118439

Epoch: 6| Step: 4
Training loss: 2.5868034641561795
Validation loss: 2.51935834928122

Epoch: 6| Step: 5
Training loss: 2.31972498792913
Validation loss: 2.5315771211827744

Epoch: 6| Step: 6
Training loss: 2.278325754119091
Validation loss: 2.5177432261578616

Epoch: 6| Step: 7
Training loss: 2.4925643970737386
Validation loss: 2.479317509967244

Epoch: 6| Step: 8
Training loss: 2.3175124410647174
Validation loss: 2.410139556511572

Epoch: 6| Step: 9
Training loss: 2.8450875961682804
Validation loss: 2.392432781640821

Epoch: 6| Step: 10
Training loss: 2.933840318418344
Validation loss: 2.3912840300831784

Epoch: 6| Step: 11
Training loss: 2.419978229645467
Validation loss: 2.374486302042831

Epoch: 6| Step: 12
Training loss: 2.7487326215790544
Validation loss: 2.351738269578904

Epoch: 6| Step: 13
Training loss: 2.236292623046531
Validation loss: 2.371953799300001

Epoch: 338| Step: 0
Training loss: 2.5121374181772773
Validation loss: 2.3484835699585735

Epoch: 6| Step: 1
Training loss: 2.7185562766324205
Validation loss: 2.3658922793689046

Epoch: 6| Step: 2
Training loss: 2.3956935233634837
Validation loss: 2.376449376945465

Epoch: 6| Step: 3
Training loss: 2.4983602868531203
Validation loss: 2.3935393530851474

Epoch: 6| Step: 4
Training loss: 2.7737399084140546
Validation loss: 2.413952144844685

Epoch: 6| Step: 5
Training loss: 1.9813590371726653
Validation loss: 2.409265002353577

Epoch: 6| Step: 6
Training loss: 2.35180754034373
Validation loss: 2.4276060910757

Epoch: 6| Step: 7
Training loss: 2.224208725376404
Validation loss: 2.443872091432959

Epoch: 6| Step: 8
Training loss: 2.112360670923633
Validation loss: 2.443000532669621

Epoch: 6| Step: 9
Training loss: 2.456840471341909
Validation loss: 2.4320942644316834

Epoch: 6| Step: 10
Training loss: 2.244919869876867
Validation loss: 2.4357313760611983

Epoch: 6| Step: 11
Training loss: 2.218661239352985
Validation loss: 2.4341524821566263

Epoch: 6| Step: 12
Training loss: 1.8051281015477645
Validation loss: 2.42406789928638

Epoch: 6| Step: 13
Training loss: 3.1405516658590695
Validation loss: 2.4320891067751265

Epoch: 339| Step: 0
Training loss: 2.407734400666492
Validation loss: 2.40962794723927

Epoch: 6| Step: 1
Training loss: 1.887169256979653
Validation loss: 2.4079564839031677

Epoch: 6| Step: 2
Training loss: 2.492187117334414
Validation loss: 2.4068802033733943

Epoch: 6| Step: 3
Training loss: 2.5668244507416733
Validation loss: 2.3674729828024383

Epoch: 6| Step: 4
Training loss: 2.5480837147792443
Validation loss: 2.3926097184205433

Epoch: 6| Step: 5
Training loss: 2.43148374242915
Validation loss: 2.381988929616872

Epoch: 6| Step: 6
Training loss: 2.412742772512191
Validation loss: 2.3638227742201066

Epoch: 6| Step: 7
Training loss: 2.6529147582668626
Validation loss: 2.350314451965709

Epoch: 6| Step: 8
Training loss: 2.249614894546862
Validation loss: 2.340715375709934

Epoch: 6| Step: 9
Training loss: 2.5599056229480177
Validation loss: 2.3691617506910845

Epoch: 6| Step: 10
Training loss: 2.326757451812068
Validation loss: 2.358790481094545

Epoch: 6| Step: 11
Training loss: 2.166288037106491
Validation loss: 2.3595504472761233

Epoch: 6| Step: 12
Training loss: 2.066698021291973
Validation loss: 2.416039600495915

Epoch: 6| Step: 13
Training loss: 2.7183701699304716
Validation loss: 2.396284593954488

Epoch: 340| Step: 0
Training loss: 2.4289240480926093
Validation loss: 2.4314777241784

Epoch: 6| Step: 1
Training loss: 3.0612049089181803
Validation loss: 2.453540487526375

Epoch: 6| Step: 2
Training loss: 2.4762470995189427
Validation loss: 2.4520455990129446

Epoch: 6| Step: 3
Training loss: 2.833741065214431
Validation loss: 2.453317582791896

Epoch: 6| Step: 4
Training loss: 2.2844595083320565
Validation loss: 2.4285492652584226

Epoch: 6| Step: 5
Training loss: 2.1239248809749403
Validation loss: 2.4037370817872175

Epoch: 6| Step: 6
Training loss: 2.0153347072480963
Validation loss: 2.3721196606060926

Epoch: 6| Step: 7
Training loss: 2.5648553769571123
Validation loss: 2.3676769804138833

Epoch: 6| Step: 8
Training loss: 2.120109090697344
Validation loss: 2.350580045860878

Epoch: 6| Step: 9
Training loss: 2.1772017986670735
Validation loss: 2.3638005325402003

Epoch: 6| Step: 10
Training loss: 2.0689863456028452
Validation loss: 2.3544806491451373

Epoch: 6| Step: 11
Training loss: 2.38081290971886
Validation loss: 2.388563600464345

Epoch: 6| Step: 12
Training loss: 2.490567820046999
Validation loss: 2.3847838086804303

Epoch: 6| Step: 13
Training loss: 2.5889253901180975
Validation loss: 2.39300340085269

Epoch: 341| Step: 0
Training loss: 2.231253303931432
Validation loss: 2.4663122396696164

Epoch: 6| Step: 1
Training loss: 2.4441193908773755
Validation loss: 2.5020936413179045

Epoch: 6| Step: 2
Training loss: 2.447935702202556
Validation loss: 2.5121792981995688

Epoch: 6| Step: 3
Training loss: 1.9552334810433936
Validation loss: 2.5391791173817597

Epoch: 6| Step: 4
Training loss: 2.092680131093378
Validation loss: 2.523943706375927

Epoch: 6| Step: 5
Training loss: 2.2822115191256453
Validation loss: 2.554748742147638

Epoch: 6| Step: 6
Training loss: 2.7860868592589147
Validation loss: 2.4885174925731453

Epoch: 6| Step: 7
Training loss: 2.2171117617767906
Validation loss: 2.4518366802877196

Epoch: 6| Step: 8
Training loss: 2.876370310747693
Validation loss: 2.438479607146301

Epoch: 6| Step: 9
Training loss: 2.0578299160323894
Validation loss: 2.4172428509998287

Epoch: 6| Step: 10
Training loss: 2.391733747686857
Validation loss: 2.3923925430686803

Epoch: 6| Step: 11
Training loss: 1.9731673079103311
Validation loss: 2.3949703707949452

Epoch: 6| Step: 12
Training loss: 2.8935571593918734
Validation loss: 2.3761633553370527

Epoch: 6| Step: 13
Training loss: 2.1164575423414322
Validation loss: 2.401611875068298

Epoch: 342| Step: 0
Training loss: 2.0662785221999798
Validation loss: 2.385624506579092

Epoch: 6| Step: 1
Training loss: 2.4790534840454357
Validation loss: 2.422316645307838

Epoch: 6| Step: 2
Training loss: 2.4844102197225926
Validation loss: 2.4664058706519674

Epoch: 6| Step: 3
Training loss: 2.347205094896337
Validation loss: 2.501758397992942

Epoch: 6| Step: 4
Training loss: 2.6867913487313135
Validation loss: 2.532209126788804

Epoch: 6| Step: 5
Training loss: 2.145434691303475
Validation loss: 2.484355866331487

Epoch: 6| Step: 6
Training loss: 2.8858388506970347
Validation loss: 2.4443166309544204

Epoch: 6| Step: 7
Training loss: 2.4275300974998393
Validation loss: 2.4632615493383083

Epoch: 6| Step: 8
Training loss: 1.9843818484210687
Validation loss: 2.447062245642307

Epoch: 6| Step: 9
Training loss: 2.12000045560436
Validation loss: 2.477464352216922

Epoch: 6| Step: 10
Training loss: 2.6032036997243035
Validation loss: 2.475906152595957

Epoch: 6| Step: 11
Training loss: 2.7755140670395146
Validation loss: 2.4448438458260964

Epoch: 6| Step: 12
Training loss: 1.682665646519984
Validation loss: 2.403534214172433

Epoch: 6| Step: 13
Training loss: 2.309972980390788
Validation loss: 2.3456844197836615

Epoch: 343| Step: 0
Training loss: 2.6615093447779
Validation loss: 2.368837382456253

Epoch: 6| Step: 1
Training loss: 2.6014955987433
Validation loss: 2.3514308454470787

Epoch: 6| Step: 2
Training loss: 2.6358547123072036
Validation loss: 2.361042376954838

Epoch: 6| Step: 3
Training loss: 2.5487334602870724
Validation loss: 2.3732409112760973

Epoch: 6| Step: 4
Training loss: 2.656126490694732
Validation loss: 2.3720988033454073

Epoch: 6| Step: 5
Training loss: 2.6997592677421753
Validation loss: 2.3713619247231095

Epoch: 6| Step: 6
Training loss: 2.0885813670455886
Validation loss: 2.383280899055646

Epoch: 6| Step: 7
Training loss: 2.563275847796997
Validation loss: 2.384826194446374

Epoch: 6| Step: 8
Training loss: 1.966626429819688
Validation loss: 2.4086650953559197

Epoch: 6| Step: 9
Training loss: 2.49285535324351
Validation loss: 2.4195175589938254

Epoch: 6| Step: 10
Training loss: 2.705122369617858
Validation loss: 2.467261829914023

Epoch: 6| Step: 11
Training loss: 1.8946873551383916
Validation loss: 2.4995057109593755

Epoch: 6| Step: 12
Training loss: 1.955590606806405
Validation loss: 2.536209862082939

Epoch: 6| Step: 13
Training loss: 1.6637137320654607
Validation loss: 2.570903196662143

Epoch: 344| Step: 0
Training loss: 2.4794614173208886
Validation loss: 2.586194630750424

Epoch: 6| Step: 1
Training loss: 2.4472903701736795
Validation loss: 2.531232596048542

Epoch: 6| Step: 2
Training loss: 2.1450094721658344
Validation loss: 2.4657057755790044

Epoch: 6| Step: 3
Training loss: 2.608326592807368
Validation loss: 2.4204527352850507

Epoch: 6| Step: 4
Training loss: 2.2266897064813937
Validation loss: 2.4059789638389857

Epoch: 6| Step: 5
Training loss: 1.8854419502825144
Validation loss: 2.3879325305461165

Epoch: 6| Step: 6
Training loss: 2.5925829916226264
Validation loss: 2.3877307181844576

Epoch: 6| Step: 7
Training loss: 1.9968041874563496
Validation loss: 2.358189384420975

Epoch: 6| Step: 8
Training loss: 2.7608853691978203
Validation loss: 2.3485223814746408

Epoch: 6| Step: 9
Training loss: 2.173798731410665
Validation loss: 2.3623114419532203

Epoch: 6| Step: 10
Training loss: 2.506548126069153
Validation loss: 2.3529756280800553

Epoch: 6| Step: 11
Training loss: 2.1538351053436617
Validation loss: 2.3545800467824693

Epoch: 6| Step: 12
Training loss: 2.6734193499164722
Validation loss: 2.3695020666160143

Epoch: 6| Step: 13
Training loss: 2.6820438801406663
Validation loss: 2.4047031579290814

Epoch: 345| Step: 0
Training loss: 2.588857978105083
Validation loss: 2.416098084003684

Epoch: 6| Step: 1
Training loss: 2.5348135271277
Validation loss: 2.48739375660871

Epoch: 6| Step: 2
Training loss: 2.3754248991897584
Validation loss: 2.562224869323105

Epoch: 6| Step: 3
Training loss: 2.324105601401551
Validation loss: 2.5982057244241665

Epoch: 6| Step: 4
Training loss: 2.723977686349501
Validation loss: 2.626337194232709

Epoch: 6| Step: 5
Training loss: 2.8061701434015474
Validation loss: 2.6084469087965285

Epoch: 6| Step: 6
Training loss: 1.9898834667877574
Validation loss: 2.4838473213073313

Epoch: 6| Step: 7
Training loss: 2.2910870136868806
Validation loss: 2.432157434032752

Epoch: 6| Step: 8
Training loss: 2.6313504197627675
Validation loss: 2.3654563270395124

Epoch: 6| Step: 9
Training loss: 2.27899874034276
Validation loss: 2.346952982929304

Epoch: 6| Step: 10
Training loss: 2.137199166527253
Validation loss: 2.335098206365983

Epoch: 6| Step: 11
Training loss: 2.1066055767440752
Validation loss: 2.354541435833675

Epoch: 6| Step: 12
Training loss: 2.1712843276995915
Validation loss: 2.358037354141846

Epoch: 6| Step: 13
Training loss: 2.398774163788889
Validation loss: 2.351587710417292

Epoch: 346| Step: 0
Training loss: 1.6460287565590808
Validation loss: 2.3631936979402983

Epoch: 6| Step: 1
Training loss: 1.7536144396157838
Validation loss: 2.380652330905605

Epoch: 6| Step: 2
Training loss: 2.377878552774124
Validation loss: 2.406597145970452

Epoch: 6| Step: 3
Training loss: 2.627300162950597
Validation loss: 2.4068016620585984

Epoch: 6| Step: 4
Training loss: 2.906162383696933
Validation loss: 2.459835033554651

Epoch: 6| Step: 5
Training loss: 2.1709116164411038
Validation loss: 2.464107958684571

Epoch: 6| Step: 6
Training loss: 2.2670756990088843
Validation loss: 2.510584744978825

Epoch: 6| Step: 7
Training loss: 2.607773157809232
Validation loss: 2.5035369115854724

Epoch: 6| Step: 8
Training loss: 2.4365210890519746
Validation loss: 2.4899663803404715

Epoch: 6| Step: 9
Training loss: 2.1800146370142643
Validation loss: 2.4690539317171716

Epoch: 6| Step: 10
Training loss: 2.1800755527948006
Validation loss: 2.3921033918077383

Epoch: 6| Step: 11
Training loss: 2.553091968336707
Validation loss: 2.382558239988533

Epoch: 6| Step: 12
Training loss: 2.844524236228822
Validation loss: 2.3680820075280344

Epoch: 6| Step: 13
Training loss: 2.148641014863673
Validation loss: 2.355399187462433

Epoch: 347| Step: 0
Training loss: 1.8909912385177783
Validation loss: 2.3441874893580854

Epoch: 6| Step: 1
Training loss: 2.327668420452907
Validation loss: 2.3433817228887617

Epoch: 6| Step: 2
Training loss: 2.410282076081407
Validation loss: 2.356155428470002

Epoch: 6| Step: 3
Training loss: 2.297182023684446
Validation loss: 2.3790891835538797

Epoch: 6| Step: 4
Training loss: 2.6044878850557356
Validation loss: 2.4192242377419353

Epoch: 6| Step: 5
Training loss: 2.298899582211676
Validation loss: 2.436562368588402

Epoch: 6| Step: 6
Training loss: 2.620778458530734
Validation loss: 2.5051351004451385

Epoch: 6| Step: 7
Training loss: 2.358316146015132
Validation loss: 2.5232713536003133

Epoch: 6| Step: 8
Training loss: 2.530004218327922
Validation loss: 2.547786511032571

Epoch: 6| Step: 9
Training loss: 2.4541573265774446
Validation loss: 2.5115461658114944

Epoch: 6| Step: 10
Training loss: 2.2008281666200196
Validation loss: 2.433383373510711

Epoch: 6| Step: 11
Training loss: 2.4349950977565915
Validation loss: 2.4604638730724986

Epoch: 6| Step: 12
Training loss: 2.2672737173542847
Validation loss: 2.4441588512843206

Epoch: 6| Step: 13
Training loss: 2.4163895042473125
Validation loss: 2.4156381337002304

Epoch: 348| Step: 0
Training loss: 1.6330033332244063
Validation loss: 2.3821451114227656

Epoch: 6| Step: 1
Training loss: 2.212841171425838
Validation loss: 2.390647933649424

Epoch: 6| Step: 2
Training loss: 2.137695535561318
Validation loss: 2.388595943545215

Epoch: 6| Step: 3
Training loss: 2.431289390107584
Validation loss: 2.40437590703905

Epoch: 6| Step: 4
Training loss: 2.4086463192459453
Validation loss: 2.3824558119524037

Epoch: 6| Step: 5
Training loss: 2.539321369766225
Validation loss: 2.4030961440584955

Epoch: 6| Step: 6
Training loss: 2.774448092452335
Validation loss: 2.3904376405940204

Epoch: 6| Step: 7
Training loss: 1.890956250641352
Validation loss: 2.393129399276025

Epoch: 6| Step: 8
Training loss: 2.4426799411926607
Validation loss: 2.385334384966279

Epoch: 6| Step: 9
Training loss: 2.851540426926556
Validation loss: 2.4187941576616505

Epoch: 6| Step: 10
Training loss: 2.2700406945567844
Validation loss: 2.396408387269561

Epoch: 6| Step: 11
Training loss: 2.3966133064339297
Validation loss: 2.437933345586078

Epoch: 6| Step: 12
Training loss: 2.5099562754375135
Validation loss: 2.484068822977766

Epoch: 6| Step: 13
Training loss: 1.8721850563508375
Validation loss: 2.4837662847641635

Epoch: 349| Step: 0
Training loss: 2.3170097298316996
Validation loss: 2.508866123128558

Epoch: 6| Step: 1
Training loss: 2.2300276712659457
Validation loss: 2.5058271648204022

Epoch: 6| Step: 2
Training loss: 2.1933895934444414
Validation loss: 2.5146052110610326

Epoch: 6| Step: 3
Training loss: 2.5709127635421902
Validation loss: 2.540628735372388

Epoch: 6| Step: 4
Training loss: 2.658472903742229
Validation loss: 2.5233235322185363

Epoch: 6| Step: 5
Training loss: 2.637662772267812
Validation loss: 2.4598031149233477

Epoch: 6| Step: 6
Training loss: 2.2980926815164255
Validation loss: 2.4309167953477266

Epoch: 6| Step: 7
Training loss: 1.4671509337007256
Validation loss: 2.328702021687546

Epoch: 6| Step: 8
Training loss: 2.194200009871272
Validation loss: 2.318459669950925

Epoch: 6| Step: 9
Training loss: 2.2642826707775674
Validation loss: 2.334319098363437

Epoch: 6| Step: 10
Training loss: 2.5187470391116475
Validation loss: 2.3046713106654995

Epoch: 6| Step: 11
Training loss: 2.385470649297209
Validation loss: 2.30982378880958

Epoch: 6| Step: 12
Training loss: 2.279319364278244
Validation loss: 2.304963651686422

Epoch: 6| Step: 13
Training loss: 2.632346092137488
Validation loss: 2.32638644338361

Epoch: 350| Step: 0
Training loss: 2.2280555403959004
Validation loss: 2.3482763416634453

Epoch: 6| Step: 1
Training loss: 2.254503194211523
Validation loss: 2.356876186875333

Epoch: 6| Step: 2
Training loss: 1.7849223778781107
Validation loss: 2.382073898869151

Epoch: 6| Step: 3
Training loss: 1.8893043382196981
Validation loss: 2.401585726262349

Epoch: 6| Step: 4
Training loss: 2.5152947819223535
Validation loss: 2.427153479160876

Epoch: 6| Step: 5
Training loss: 1.8086840481389865
Validation loss: 2.473546821984497

Epoch: 6| Step: 6
Training loss: 2.250261291590852
Validation loss: 2.500728642506717

Epoch: 6| Step: 7
Training loss: 2.0666847546103795
Validation loss: 2.5404183250402363

Epoch: 6| Step: 8
Training loss: 2.4034568130933383
Validation loss: 2.5835710506114977

Epoch: 6| Step: 9
Training loss: 2.876434465881542
Validation loss: 2.6119928646815262

Epoch: 6| Step: 10
Training loss: 2.3655597390529626
Validation loss: 2.6167798599842516

Epoch: 6| Step: 11
Training loss: 2.3417022915050056
Validation loss: 2.6028213990269817

Epoch: 6| Step: 12
Training loss: 3.083856967760895
Validation loss: 2.5152463175087614

Epoch: 6| Step: 13
Training loss: 3.0914754501668575
Validation loss: 2.434670424851361

Testing loss: 2.6059056531017846
