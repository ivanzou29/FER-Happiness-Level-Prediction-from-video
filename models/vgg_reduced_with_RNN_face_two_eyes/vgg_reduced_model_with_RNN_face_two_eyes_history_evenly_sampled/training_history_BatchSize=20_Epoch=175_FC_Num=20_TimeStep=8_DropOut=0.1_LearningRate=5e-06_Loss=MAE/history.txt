Epoch: 1| Step: 0
Training loss: 4.945952892303467
Validation loss: 5.178219303008048

Epoch: 5| Step: 1
Training loss: 4.9515299797058105
Validation loss: 5.1717747513965895

Epoch: 5| Step: 2
Training loss: 5.323977470397949
Validation loss: 5.1659025581934115

Epoch: 5| Step: 3
Training loss: 4.559042930603027
Validation loss: 5.160611788431804

Epoch: 5| Step: 4
Training loss: 5.136302471160889
Validation loss: 5.15507451949581

Epoch: 5| Step: 5
Training loss: 4.423131942749023
Validation loss: 5.149864191650062

Epoch: 5| Step: 6
Training loss: 4.962340354919434
Validation loss: 5.144500224821029

Epoch: 5| Step: 7
Training loss: 5.043025016784668
Validation loss: 5.1389329612896

Epoch: 5| Step: 8
Training loss: 5.419644355773926
Validation loss: 5.13359276453654

Epoch: 5| Step: 9
Training loss: 4.281814098358154
Validation loss: 5.127648886813913

Epoch: 5| Step: 10
Training loss: 5.426571369171143
Validation loss: 5.12195986060686

Epoch: 2| Step: 0
Training loss: 4.543704986572266
Validation loss: 5.115883073499126

Epoch: 5| Step: 1
Training loss: 5.376192092895508
Validation loss: 5.108947456523937

Epoch: 5| Step: 2
Training loss: 4.12811279296875
Validation loss: 5.1020107371832735

Epoch: 5| Step: 3
Training loss: 5.824313163757324
Validation loss: 5.094276166731311

Epoch: 5| Step: 4
Training loss: 4.083302021026611
Validation loss: 5.08688695456392

Epoch: 5| Step: 5
Training loss: 4.207912445068359
Validation loss: 5.079080940574728

Epoch: 5| Step: 6
Training loss: 5.122908592224121
Validation loss: 5.070448049934962

Epoch: 5| Step: 7
Training loss: 5.096083641052246
Validation loss: 5.061910167817147

Epoch: 5| Step: 8
Training loss: 5.355108737945557
Validation loss: 5.0525251152694866

Epoch: 5| Step: 9
Training loss: 4.573749542236328
Validation loss: 5.042671936814503

Epoch: 5| Step: 10
Training loss: 5.345983028411865
Validation loss: 5.03194728461645

Epoch: 3| Step: 0
Training loss: 5.067572593688965
Validation loss: 5.021663542716734

Epoch: 5| Step: 1
Training loss: 4.018007755279541
Validation loss: 5.010197290810206

Epoch: 5| Step: 2
Training loss: 5.1830902099609375
Validation loss: 4.9980212898664576

Epoch: 5| Step: 3
Training loss: 5.559737205505371
Validation loss: 4.985225008380029

Epoch: 5| Step: 4
Training loss: 4.06203556060791
Validation loss: 4.97283693539199

Epoch: 5| Step: 5
Training loss: 3.5584628582000732
Validation loss: 4.95880465866417

Epoch: 5| Step: 6
Training loss: 5.726414203643799
Validation loss: 4.945241466645272

Epoch: 5| Step: 7
Training loss: 4.724799156188965
Validation loss: 4.930353426164197

Epoch: 5| Step: 8
Training loss: 5.279690742492676
Validation loss: 4.914932722686439

Epoch: 5| Step: 9
Training loss: 4.864663600921631
Validation loss: 4.898968645321426

Epoch: 5| Step: 10
Training loss: 4.1105852127075195
Validation loss: 4.881985387494487

Epoch: 4| Step: 0
Training loss: 5.319834232330322
Validation loss: 4.864333347607684

Epoch: 5| Step: 1
Training loss: 4.513953685760498
Validation loss: 4.847403746779247

Epoch: 5| Step: 2
Training loss: 4.307027339935303
Validation loss: 4.82738713295229

Epoch: 5| Step: 3
Training loss: 3.704470157623291
Validation loss: 4.808754664595409

Epoch: 5| Step: 4
Training loss: 5.361269474029541
Validation loss: 4.787460029766124

Epoch: 5| Step: 5
Training loss: 5.133430480957031
Validation loss: 4.766686665114536

Epoch: 5| Step: 6
Training loss: 3.216938018798828
Validation loss: 4.74452579662364

Epoch: 5| Step: 7
Training loss: 4.077630996704102
Validation loss: 4.721614250572779

Epoch: 5| Step: 8
Training loss: 4.921841621398926
Validation loss: 4.699617667864728

Epoch: 5| Step: 9
Training loss: 5.092625617980957
Validation loss: 4.676101776861375

Epoch: 5| Step: 10
Training loss: 4.353742599487305
Validation loss: 4.6517755651986725

Epoch: 5| Step: 0
Training loss: 3.4417800903320312
Validation loss: 4.626286404107207

Epoch: 5| Step: 1
Training loss: 4.629739761352539
Validation loss: 4.6010943792199575

Epoch: 5| Step: 2
Training loss: 4.348751068115234
Validation loss: 4.574703380625735

Epoch: 5| Step: 3
Training loss: 4.347256660461426
Validation loss: 4.548654228128413

Epoch: 5| Step: 4
Training loss: 3.56449818611145
Validation loss: 4.523188744821856

Epoch: 5| Step: 5
Training loss: 3.727233409881592
Validation loss: 4.493351915831207

Epoch: 5| Step: 6
Training loss: 4.253050804138184
Validation loss: 4.466567890618437

Epoch: 5| Step: 7
Training loss: 4.4396772384643555
Validation loss: 4.439425124916979

Epoch: 5| Step: 8
Training loss: 4.94024658203125
Validation loss: 4.411405486445273

Epoch: 5| Step: 9
Training loss: 5.508025169372559
Validation loss: 4.38226439363213

Epoch: 5| Step: 10
Training loss: 3.8052117824554443
Validation loss: 4.355269196212933

Epoch: 6| Step: 0
Training loss: 4.0045270919799805
Validation loss: 4.329021028293076

Epoch: 5| Step: 1
Training loss: 2.915574312210083
Validation loss: 4.302259573372462

Epoch: 5| Step: 2
Training loss: 4.868995666503906
Validation loss: 4.276967392172865

Epoch: 5| Step: 3
Training loss: 3.4406933784484863
Validation loss: 4.252286998174524

Epoch: 5| Step: 4
Training loss: 4.063467979431152
Validation loss: 4.228432719425489

Epoch: 5| Step: 5
Training loss: 4.7073493003845215
Validation loss: 4.204484924193351

Epoch: 5| Step: 6
Training loss: 3.7479476928710938
Validation loss: 4.181679479537472

Epoch: 5| Step: 7
Training loss: 3.5220837593078613
Validation loss: 4.1577438077619

Epoch: 5| Step: 8
Training loss: 4.3544464111328125
Validation loss: 4.137542911755141

Epoch: 5| Step: 9
Training loss: 4.48660945892334
Validation loss: 4.1141654394006215

Epoch: 5| Step: 10
Training loss: 4.073215961456299
Validation loss: 4.092163931938909

Epoch: 7| Step: 0
Training loss: 3.148876190185547
Validation loss: 4.07035275941254

Epoch: 5| Step: 1
Training loss: 3.9121317863464355
Validation loss: 4.049164720760879

Epoch: 5| Step: 2
Training loss: 4.660386562347412
Validation loss: 4.029525479962749

Epoch: 5| Step: 3
Training loss: 3.9188644886016846
Validation loss: 4.008560124263968

Epoch: 5| Step: 4
Training loss: 3.3976619243621826
Validation loss: 3.9894555717386226

Epoch: 5| Step: 5
Training loss: 3.2835800647735596
Validation loss: 3.9693440724444646

Epoch: 5| Step: 6
Training loss: 4.127793788909912
Validation loss: 3.9506037773624545

Epoch: 5| Step: 7
Training loss: 3.4705681800842285
Validation loss: 3.9323797149042927

Epoch: 5| Step: 8
Training loss: 3.8070132732391357
Validation loss: 3.913964463818458

Epoch: 5| Step: 9
Training loss: 4.553078651428223
Validation loss: 3.895542939503988

Epoch: 5| Step: 10
Training loss: 3.716017484664917
Validation loss: 3.8792478679328837

Epoch: 8| Step: 0
Training loss: 3.527925491333008
Validation loss: 3.859139334770941

Epoch: 5| Step: 1
Training loss: 2.924966335296631
Validation loss: 3.840252773736113

Epoch: 5| Step: 2
Training loss: 3.983905792236328
Validation loss: 3.822788300052766

Epoch: 5| Step: 3
Training loss: 3.556727170944214
Validation loss: 3.8059864454371954

Epoch: 5| Step: 4
Training loss: 3.010180950164795
Validation loss: 3.7861787298674225

Epoch: 5| Step: 5
Training loss: 4.060829162597656
Validation loss: 3.7703829939647386

Epoch: 5| Step: 6
Training loss: 3.9232559204101562
Validation loss: 3.7542070881012948

Epoch: 5| Step: 7
Training loss: 3.692521333694458
Validation loss: 3.735302132944907

Epoch: 5| Step: 8
Training loss: 3.3434195518493652
Validation loss: 3.7144789131738807

Epoch: 5| Step: 9
Training loss: 4.027441024780273
Validation loss: 3.695728353274766

Epoch: 5| Step: 10
Training loss: 4.19579553604126
Validation loss: 3.67425706566021

Epoch: 9| Step: 0
Training loss: 3.0375521183013916
Validation loss: 3.6549566330448275

Epoch: 5| Step: 1
Training loss: 4.377593040466309
Validation loss: 3.633337897639121

Epoch: 5| Step: 2
Training loss: 3.9381890296936035
Validation loss: 3.614892159738848

Epoch: 5| Step: 3
Training loss: 3.0694122314453125
Validation loss: 3.5943939044911373

Epoch: 5| Step: 4
Training loss: 3.964313507080078
Validation loss: 3.5799986777767057

Epoch: 5| Step: 5
Training loss: 4.385324001312256
Validation loss: 3.561164435519967

Epoch: 5| Step: 6
Training loss: 2.811570644378662
Validation loss: 3.5480907501712924

Epoch: 5| Step: 7
Training loss: 2.6235058307647705
Validation loss: 3.533103471161217

Epoch: 5| Step: 8
Training loss: 3.4999442100524902
Validation loss: 3.522202891688193

Epoch: 5| Step: 9
Training loss: 3.6038460731506348
Validation loss: 3.510644664046585

Epoch: 5| Step: 10
Training loss: 2.9913887977600098
Validation loss: 3.4972266381786716

Epoch: 10| Step: 0
Training loss: 3.5034127235412598
Validation loss: 3.48574226133285

Epoch: 5| Step: 1
Training loss: 3.3446567058563232
Validation loss: 3.476480724991009

Epoch: 5| Step: 2
Training loss: 4.352412700653076
Validation loss: 3.4652873880119732

Epoch: 5| Step: 3
Training loss: 2.543225049972534
Validation loss: 3.45549335018281

Epoch: 5| Step: 4
Training loss: 4.341064453125
Validation loss: 3.4453929880613923

Epoch: 5| Step: 5
Training loss: 2.6528871059417725
Validation loss: 3.436073395513719

Epoch: 5| Step: 6
Training loss: 4.382031440734863
Validation loss: 3.4229612863191994

Epoch: 5| Step: 7
Training loss: 2.6224381923675537
Validation loss: 3.413320077362881

Epoch: 5| Step: 8
Training loss: 3.2374470233917236
Validation loss: 3.407290550970262

Epoch: 5| Step: 9
Training loss: 3.364276885986328
Validation loss: 3.3975399668498705

Epoch: 5| Step: 10
Training loss: 2.674849510192871
Validation loss: 3.3875241817966586

Epoch: 11| Step: 0
Training loss: 2.75752592086792
Validation loss: 3.3776804913756666

Epoch: 5| Step: 1
Training loss: 3.930049180984497
Validation loss: 3.3716476707048315

Epoch: 5| Step: 2
Training loss: 4.2101240158081055
Validation loss: 3.3610530002142793

Epoch: 5| Step: 3
Training loss: 3.2088019847869873
Validation loss: 3.3554219327947146

Epoch: 5| Step: 4
Training loss: 3.5791549682617188
Validation loss: 3.345001592431017

Epoch: 5| Step: 5
Training loss: 2.2126879692077637
Validation loss: 3.3366451827428674

Epoch: 5| Step: 6
Training loss: 3.598607301712036
Validation loss: 3.327901094190536

Epoch: 5| Step: 7
Training loss: 3.542182207107544
Validation loss: 3.3211207953832482

Epoch: 5| Step: 8
Training loss: 2.7260265350341797
Validation loss: 3.314698544881677

Epoch: 5| Step: 9
Training loss: 3.6514155864715576
Validation loss: 3.308945422531456

Epoch: 5| Step: 10
Training loss: 2.8190712928771973
Validation loss: 3.2997943227009108

Epoch: 12| Step: 0
Training loss: 3.893319606781006
Validation loss: 3.2949290737029044

Epoch: 5| Step: 1
Training loss: 2.967858076095581
Validation loss: 3.289106179309148

Epoch: 5| Step: 2
Training loss: 3.4322357177734375
Validation loss: 3.286412972275929

Epoch: 5| Step: 3
Training loss: 2.728020191192627
Validation loss: 3.2787465562102613

Epoch: 5| Step: 4
Training loss: 3.5288162231445312
Validation loss: 3.269434275165681

Epoch: 5| Step: 5
Training loss: 2.9459328651428223
Validation loss: 3.2657532230500252

Epoch: 5| Step: 6
Training loss: 3.2725963592529297
Validation loss: 3.2570646603902182

Epoch: 5| Step: 7
Training loss: 3.3999733924865723
Validation loss: 3.254467966736004

Epoch: 5| Step: 8
Training loss: 3.8988921642303467
Validation loss: 3.2506679437493764

Epoch: 5| Step: 9
Training loss: 2.807190418243408
Validation loss: 3.2439380281714985

Epoch: 5| Step: 10
Training loss: 2.7161130905151367
Validation loss: 3.2393280229260846

Epoch: 13| Step: 0
Training loss: 2.4062695503234863
Validation loss: 3.235102971394857

Epoch: 5| Step: 1
Training loss: 2.9669628143310547
Validation loss: 3.2292804256562264

Epoch: 5| Step: 2
Training loss: 3.0051493644714355
Validation loss: 3.225370724995931

Epoch: 5| Step: 3
Training loss: 2.6067988872528076
Validation loss: 3.2218291477490495

Epoch: 5| Step: 4
Training loss: 3.749701738357544
Validation loss: 3.217260693991056

Epoch: 5| Step: 5
Training loss: 3.119194984436035
Validation loss: 3.212811585395567

Epoch: 5| Step: 6
Training loss: 3.605994701385498
Validation loss: 3.208630766919864

Epoch: 5| Step: 7
Training loss: 3.6273083686828613
Validation loss: 3.2066128151391142

Epoch: 5| Step: 8
Training loss: 3.433065891265869
Validation loss: 3.203331039797875

Epoch: 5| Step: 9
Training loss: 3.373584747314453
Validation loss: 3.2001698119665987

Epoch: 5| Step: 10
Training loss: 3.410372257232666
Validation loss: 3.1993301555674565

Epoch: 14| Step: 0
Training loss: 2.7614223957061768
Validation loss: 3.193583106481901

Epoch: 5| Step: 1
Training loss: 3.2542831897735596
Validation loss: 3.188570189219649

Epoch: 5| Step: 2
Training loss: 3.4738974571228027
Validation loss: 3.1857040876983316

Epoch: 5| Step: 3
Training loss: 3.573911190032959
Validation loss: 3.181121392916608

Epoch: 5| Step: 4
Training loss: 3.08624267578125
Validation loss: 3.177745896001016

Epoch: 5| Step: 5
Training loss: 4.090139865875244
Validation loss: 3.17400606729651

Epoch: 5| Step: 6
Training loss: 2.270775556564331
Validation loss: 3.168905122305757

Epoch: 5| Step: 7
Training loss: 3.7723541259765625
Validation loss: 3.165323667628791

Epoch: 5| Step: 8
Training loss: 2.9429829120635986
Validation loss: 3.1654308380619174

Epoch: 5| Step: 9
Training loss: 2.7985081672668457
Validation loss: 3.1611508118209017

Epoch: 5| Step: 10
Training loss: 2.8859119415283203
Validation loss: 3.1538369399245068

Epoch: 15| Step: 0
Training loss: 2.9529690742492676
Validation loss: 3.1524247200258317

Epoch: 5| Step: 1
Training loss: 2.831285238265991
Validation loss: 3.1468916554604807

Epoch: 5| Step: 2
Training loss: 4.2870659828186035
Validation loss: 3.1446061647066506

Epoch: 5| Step: 3
Training loss: 3.146944522857666
Validation loss: 3.141629067800378

Epoch: 5| Step: 4
Training loss: 3.2086691856384277
Validation loss: 3.1369749217905025

Epoch: 5| Step: 5
Training loss: 2.2867372035980225
Validation loss: 3.133932936576105

Epoch: 5| Step: 6
Training loss: 3.0807249546051025
Validation loss: 3.130281927765057

Epoch: 5| Step: 7
Training loss: 2.6730315685272217
Validation loss: 3.130163082512476

Epoch: 5| Step: 8
Training loss: 3.7643375396728516
Validation loss: 3.1258652287144817

Epoch: 5| Step: 9
Training loss: 3.5986716747283936
Validation loss: 3.1210468405036518

Epoch: 5| Step: 10
Training loss: 2.7590346336364746
Validation loss: 3.116828195510372

Epoch: 16| Step: 0
Training loss: 3.404326915740967
Validation loss: 3.114402655632265

Epoch: 5| Step: 1
Training loss: 2.4280548095703125
Validation loss: 3.109997631401144

Epoch: 5| Step: 2
Training loss: 2.9742605686187744
Validation loss: 3.107443460854151

Epoch: 5| Step: 3
Training loss: 3.40032696723938
Validation loss: 3.10720665736865

Epoch: 5| Step: 4
Training loss: 3.3329176902770996
Validation loss: 3.106209188379267

Epoch: 5| Step: 5
Training loss: 3.349487781524658
Validation loss: 3.1026622274870514

Epoch: 5| Step: 6
Training loss: 2.7756967544555664
Validation loss: 3.101146938980267

Epoch: 5| Step: 7
Training loss: 2.918175220489502
Validation loss: 3.0881952367803103

Epoch: 5| Step: 8
Training loss: 3.109287977218628
Validation loss: 3.0846935600362797

Epoch: 5| Step: 9
Training loss: 3.537015914916992
Validation loss: 3.084171341311547

Epoch: 5| Step: 10
Training loss: 3.1272103786468506
Validation loss: 3.0795865238353772

Epoch: 17| Step: 0
Training loss: 2.6339919567108154
Validation loss: 3.070032955497824

Epoch: 5| Step: 1
Training loss: 2.8180747032165527
Validation loss: 3.066619550028155

Epoch: 5| Step: 2
Training loss: 3.1122872829437256
Validation loss: 3.0628625141677035

Epoch: 5| Step: 3
Training loss: 2.9741272926330566
Validation loss: 3.055380513591151

Epoch: 5| Step: 4
Training loss: 2.9633727073669434
Validation loss: 3.053471742137786

Epoch: 5| Step: 5
Training loss: 3.4313271045684814
Validation loss: 3.0453491672392814

Epoch: 5| Step: 6
Training loss: 3.3169639110565186
Validation loss: 3.0377106743474163

Epoch: 5| Step: 7
Training loss: 3.61735200881958
Validation loss: 3.026372540381647

Epoch: 5| Step: 8
Training loss: 3.0872559547424316
Validation loss: 3.025745173936249

Epoch: 5| Step: 9
Training loss: 3.6175060272216797
Validation loss: 3.022838184910436

Epoch: 5| Step: 10
Training loss: 2.3091487884521484
Validation loss: 3.016181171581309

Epoch: 18| Step: 0
Training loss: 3.847688674926758
Validation loss: 3.014065545092347

Epoch: 5| Step: 1
Training loss: 3.2559826374053955
Validation loss: 3.0093917231405936

Epoch: 5| Step: 2
Training loss: 2.7721285820007324
Validation loss: 3.0012350543852775

Epoch: 5| Step: 3
Training loss: 2.5145699977874756
Validation loss: 2.9979877702651487

Epoch: 5| Step: 4
Training loss: 3.3558623790740967
Validation loss: 2.995744543690835

Epoch: 5| Step: 5
Training loss: 2.8432679176330566
Validation loss: 2.993258209638698

Epoch: 5| Step: 6
Training loss: 3.9583988189697266
Validation loss: 2.9903864450352167

Epoch: 5| Step: 7
Training loss: 2.468904733657837
Validation loss: 2.98899253209432

Epoch: 5| Step: 8
Training loss: 3.437878131866455
Validation loss: 2.9826017041360178

Epoch: 5| Step: 9
Training loss: 2.742978572845459
Validation loss: 2.9734965498729418

Epoch: 5| Step: 10
Training loss: 2.3160953521728516
Validation loss: 2.9713002789405083

Epoch: 19| Step: 0
Training loss: 2.7674460411071777
Validation loss: 2.9717614753271944

Epoch: 5| Step: 1
Training loss: 3.016641139984131
Validation loss: 2.970565547225296

Epoch: 5| Step: 2
Training loss: 3.448040008544922
Validation loss: 2.9637604118675314

Epoch: 5| Step: 3
Training loss: 3.0429956912994385
Validation loss: 2.9599081675211587

Epoch: 5| Step: 4
Training loss: 4.152735710144043
Validation loss: 2.95479400696293

Epoch: 5| Step: 5
Training loss: 2.6991257667541504
Validation loss: 2.9521382701012397

Epoch: 5| Step: 6
Training loss: 3.0263705253601074
Validation loss: 2.9489245799279984

Epoch: 5| Step: 7
Training loss: 3.4807639122009277
Validation loss: 2.9468484335048224

Epoch: 5| Step: 8
Training loss: 2.5244598388671875
Validation loss: 2.9465910388577368

Epoch: 5| Step: 9
Training loss: 2.7796292304992676
Validation loss: 2.9452311428644324

Epoch: 5| Step: 10
Training loss: 2.242997884750366
Validation loss: 2.941243956165929

Epoch: 20| Step: 0
Training loss: 2.5298619270324707
Validation loss: 2.942565779532156

Epoch: 5| Step: 1
Training loss: 3.4498672485351562
Validation loss: 2.9323490755532378

Epoch: 5| Step: 2
Training loss: 2.3889365196228027
Validation loss: 2.933104089511338

Epoch: 5| Step: 3
Training loss: 2.5688695907592773
Validation loss: 2.930676732012021

Epoch: 5| Step: 4
Training loss: 3.4170966148376465
Validation loss: 2.931714129704301

Epoch: 5| Step: 5
Training loss: 3.5962581634521484
Validation loss: 2.9272289301759455

Epoch: 5| Step: 6
Training loss: 3.624685764312744
Validation loss: 2.9233207446272655

Epoch: 5| Step: 7
Training loss: 3.1513798236846924
Validation loss: 2.9204063876982658

Epoch: 5| Step: 8
Training loss: 2.916999101638794
Validation loss: 2.9184110395369993

Epoch: 5| Step: 9
Training loss: 2.430098295211792
Validation loss: 2.9154572563786663

Epoch: 5| Step: 10
Training loss: 3.1282951831817627
Validation loss: 2.9137780179259596

Epoch: 21| Step: 0
Training loss: 3.0248491764068604
Validation loss: 2.90787677098346

Epoch: 5| Step: 1
Training loss: 4.100511074066162
Validation loss: 2.904334363117013

Epoch: 5| Step: 2
Training loss: 2.4067862033843994
Validation loss: 2.900158792413691

Epoch: 5| Step: 3
Training loss: 2.257145881652832
Validation loss: 2.8982007349691083

Epoch: 5| Step: 4
Training loss: 2.4515221118927
Validation loss: 2.8975730865232405

Epoch: 5| Step: 5
Training loss: 2.830148220062256
Validation loss: 2.8922028669746975

Epoch: 5| Step: 6
Training loss: 3.400193452835083
Validation loss: 2.895795729852492

Epoch: 5| Step: 7
Training loss: 2.9561750888824463
Validation loss: 2.897132691516671

Epoch: 5| Step: 8
Training loss: 3.2528960704803467
Validation loss: 2.896138511678224

Epoch: 5| Step: 9
Training loss: 3.521652936935425
Validation loss: 2.8879448367703344

Epoch: 5| Step: 10
Training loss: 2.6333744525909424
Validation loss: 2.882040777514058

Epoch: 22| Step: 0
Training loss: 2.9410557746887207
Validation loss: 2.8758612576351372

Epoch: 5| Step: 1
Training loss: 2.6197288036346436
Validation loss: 2.873390523336267

Epoch: 5| Step: 2
Training loss: 3.0130233764648438
Validation loss: 2.8733970016561527

Epoch: 5| Step: 3
Training loss: 2.973907947540283
Validation loss: 2.872148052338631

Epoch: 5| Step: 4
Training loss: 2.5883982181549072
Validation loss: 2.867348640195785

Epoch: 5| Step: 5
Training loss: 2.8607006072998047
Validation loss: 2.860002138281381

Epoch: 5| Step: 6
Training loss: 2.9142675399780273
Validation loss: 2.860877336994294

Epoch: 5| Step: 7
Training loss: 3.8580589294433594
Validation loss: 2.8556529680887857

Epoch: 5| Step: 8
Training loss: 2.441013813018799
Validation loss: 2.854846974854828

Epoch: 5| Step: 9
Training loss: 2.987954616546631
Validation loss: 2.85345063670989

Epoch: 5| Step: 10
Training loss: 3.549102783203125
Validation loss: 2.8525313151779996

Epoch: 23| Step: 0
Training loss: 1.8980324268341064
Validation loss: 2.8490577692626626

Epoch: 5| Step: 1
Training loss: 2.738722324371338
Validation loss: 2.851405733375139

Epoch: 5| Step: 2
Training loss: 2.398707628250122
Validation loss: 2.8465176013208207

Epoch: 5| Step: 3
Training loss: 3.172098398208618
Validation loss: 2.847658605985744

Epoch: 5| Step: 4
Training loss: 3.0210342407226562
Validation loss: 2.845531899441955

Epoch: 5| Step: 5
Training loss: 2.2627384662628174
Validation loss: 2.842262052720593

Epoch: 5| Step: 6
Training loss: 3.5767319202423096
Validation loss: 2.8387185322341097

Epoch: 5| Step: 7
Training loss: 3.9345593452453613
Validation loss: 2.840429964885917

Epoch: 5| Step: 8
Training loss: 2.662109851837158
Validation loss: 2.838705106448102

Epoch: 5| Step: 9
Training loss: 3.752713441848755
Validation loss: 2.8360137785634687

Epoch: 5| Step: 10
Training loss: 3.03957462310791
Validation loss: 2.8281336189598165

Epoch: 24| Step: 0
Training loss: 2.8413736820220947
Validation loss: 2.8266936373966995

Epoch: 5| Step: 1
Training loss: 3.2303261756896973
Validation loss: 2.8239991716159287

Epoch: 5| Step: 2
Training loss: 2.6629364490509033
Validation loss: 2.8266498427237234

Epoch: 5| Step: 3
Training loss: 1.7402414083480835
Validation loss: 2.8191952551564863

Epoch: 5| Step: 4
Training loss: 3.8812546730041504
Validation loss: 2.8193564414978027

Epoch: 5| Step: 5
Training loss: 2.738879680633545
Validation loss: 2.822902541006765

Epoch: 5| Step: 6
Training loss: 3.8641762733459473
Validation loss: 2.825084865734141

Epoch: 5| Step: 7
Training loss: 2.9437079429626465
Validation loss: 2.812276468482069

Epoch: 5| Step: 8
Training loss: 2.3951191902160645
Validation loss: 2.814265481887325

Epoch: 5| Step: 9
Training loss: 3.2052390575408936
Validation loss: 2.808588368918306

Epoch: 5| Step: 10
Training loss: 2.805504083633423
Validation loss: 2.809652569473431

Epoch: 25| Step: 0
Training loss: 3.001251220703125
Validation loss: 2.797070457089332

Epoch: 5| Step: 1
Training loss: 3.3753204345703125
Validation loss: 2.7998265092090895

Epoch: 5| Step: 2
Training loss: 2.3633949756622314
Validation loss: 2.7983219149292156

Epoch: 5| Step: 3
Training loss: 3.158170461654663
Validation loss: 2.8034303547233663

Epoch: 5| Step: 4
Training loss: 2.844306707382202
Validation loss: 2.7998267809549966

Epoch: 5| Step: 5
Training loss: 3.613060712814331
Validation loss: 2.7968657350027435

Epoch: 5| Step: 6
Training loss: 2.3091213703155518
Validation loss: 2.7946537745896207

Epoch: 5| Step: 7
Training loss: 2.633208990097046
Validation loss: 2.792511850275019

Epoch: 5| Step: 8
Training loss: 3.4354407787323
Validation loss: 2.7878580554839103

Epoch: 5| Step: 9
Training loss: 3.240293025970459
Validation loss: 2.785132574778731

Epoch: 5| Step: 10
Training loss: 2.08069109916687
Validation loss: 2.7828473250071206

Epoch: 26| Step: 0
Training loss: 3.7383675575256348
Validation loss: 2.7844851632272043

Epoch: 5| Step: 1
Training loss: 2.440683364868164
Validation loss: 2.781635343387563

Epoch: 5| Step: 2
Training loss: 2.7515082359313965
Validation loss: 2.779684328263806

Epoch: 5| Step: 3
Training loss: 2.9884393215179443
Validation loss: 2.778042639455488

Epoch: 5| Step: 4
Training loss: 3.234168529510498
Validation loss: 2.771912605531754

Epoch: 5| Step: 5
Training loss: 3.354133129119873
Validation loss: 2.7712018925656556

Epoch: 5| Step: 6
Training loss: 2.865999698638916
Validation loss: 2.7729223569234214

Epoch: 5| Step: 7
Training loss: 2.425605058670044
Validation loss: 2.7672303261295443

Epoch: 5| Step: 8
Training loss: 3.197885036468506
Validation loss: 2.770382329981814

Epoch: 5| Step: 9
Training loss: 2.384457588195801
Validation loss: 2.7654005712078464

Epoch: 5| Step: 10
Training loss: 2.5328872203826904
Validation loss: 2.7621224669999975

Epoch: 27| Step: 0
Training loss: 2.4143052101135254
Validation loss: 2.764790783646286

Epoch: 5| Step: 1
Training loss: 3.091477155685425
Validation loss: 2.786623480499432

Epoch: 5| Step: 2
Training loss: 2.7760169506073
Validation loss: 2.772254877193

Epoch: 5| Step: 3
Training loss: 2.0252323150634766
Validation loss: 2.764972861095141

Epoch: 5| Step: 4
Training loss: 3.1124441623687744
Validation loss: 2.7559822836229877

Epoch: 5| Step: 5
Training loss: 2.118018627166748
Validation loss: 2.7550841915991997

Epoch: 5| Step: 6
Training loss: 2.86055064201355
Validation loss: 2.7560211330331783

Epoch: 5| Step: 7
Training loss: 3.10125994682312
Validation loss: 2.7548481674604517

Epoch: 5| Step: 8
Training loss: 3.3886325359344482
Validation loss: 2.7556714268140894

Epoch: 5| Step: 9
Training loss: 3.8203511238098145
Validation loss: 2.7488060484650316

Epoch: 5| Step: 10
Training loss: 3.2129173278808594
Validation loss: 2.747434154633553

Epoch: 28| Step: 0
Training loss: 2.994532346725464
Validation loss: 2.746073612602808

Epoch: 5| Step: 1
Training loss: 2.6554274559020996
Validation loss: 2.7469557946728123

Epoch: 5| Step: 2
Training loss: 2.2873592376708984
Validation loss: 2.7440648591646584

Epoch: 5| Step: 3
Training loss: 2.9138503074645996
Validation loss: 2.7465708101949384

Epoch: 5| Step: 4
Training loss: 3.4003653526306152
Validation loss: 2.748203851843393

Epoch: 5| Step: 5
Training loss: 2.348018169403076
Validation loss: 2.746196118734216

Epoch: 5| Step: 6
Training loss: 3.4020092487335205
Validation loss: 2.75092064949774

Epoch: 5| Step: 7
Training loss: 2.897876024246216
Validation loss: 2.7527417444413707

Epoch: 5| Step: 8
Training loss: 3.229602336883545
Validation loss: 2.7498432641388266

Epoch: 5| Step: 9
Training loss: 2.9579148292541504
Validation loss: 2.73419625143851

Epoch: 5| Step: 10
Training loss: 2.6888890266418457
Validation loss: 2.729914293494276

Epoch: 29| Step: 0
Training loss: 3.595816135406494
Validation loss: 2.7290383923438286

Epoch: 5| Step: 1
Training loss: 2.85612416267395
Validation loss: 2.7354467402222338

Epoch: 5| Step: 2
Training loss: 3.3378658294677734
Validation loss: 2.7331796615354476

Epoch: 5| Step: 3
Training loss: 2.3322062492370605
Validation loss: 2.730063881925357

Epoch: 5| Step: 4
Training loss: 2.4363749027252197
Validation loss: 2.729547236555366

Epoch: 5| Step: 5
Training loss: 2.81312894821167
Validation loss: 2.7316880867045414

Epoch: 5| Step: 6
Training loss: 2.867666244506836
Validation loss: 2.7297539095724783

Epoch: 5| Step: 7
Training loss: 2.6688404083251953
Validation loss: 2.723290181929065

Epoch: 5| Step: 8
Training loss: 2.3808181285858154
Validation loss: 2.7167085114345757

Epoch: 5| Step: 9
Training loss: 3.3329124450683594
Validation loss: 2.714968386516776

Epoch: 5| Step: 10
Training loss: 3.1035659313201904
Validation loss: 2.7121765536646687

Epoch: 30| Step: 0
Training loss: 3.082501173019409
Validation loss: 2.7117069511003393

Epoch: 5| Step: 1
Training loss: 2.0736868381500244
Validation loss: 2.7053366784126527

Epoch: 5| Step: 2
Training loss: 3.207897186279297
Validation loss: 2.7039584216251167

Epoch: 5| Step: 3
Training loss: 2.4262545108795166
Validation loss: 2.7063449710927983

Epoch: 5| Step: 4
Training loss: 3.303218126296997
Validation loss: 2.704790130738289

Epoch: 5| Step: 5
Training loss: 3.0174946784973145
Validation loss: 2.709562042708038

Epoch: 5| Step: 6
Training loss: 3.2448277473449707
Validation loss: 2.7049299850258777

Epoch: 5| Step: 7
Training loss: 2.925449848175049
Validation loss: 2.702421639555244

Epoch: 5| Step: 8
Training loss: 2.651205062866211
Validation loss: 2.696622745965117

Epoch: 5| Step: 9
Training loss: 2.5525565147399902
Validation loss: 2.6916362457377936

Epoch: 5| Step: 10
Training loss: 3.018634080886841
Validation loss: 2.684677993097613

Epoch: 31| Step: 0
Training loss: 2.8775031566619873
Validation loss: 2.6880393899897093

Epoch: 5| Step: 1
Training loss: 3.7555274963378906
Validation loss: 2.688157455895537

Epoch: 5| Step: 2
Training loss: 2.9184343814849854
Validation loss: 2.6869444257469586

Epoch: 5| Step: 3
Training loss: 3.214181423187256
Validation loss: 2.6868808910410893

Epoch: 5| Step: 4
Training loss: 2.2778220176696777
Validation loss: 2.681373160372498

Epoch: 5| Step: 5
Training loss: 1.9624515771865845
Validation loss: 2.6780838222913843

Epoch: 5| Step: 6
Training loss: 2.8207271099090576
Validation loss: 2.6843051218217417

Epoch: 5| Step: 7
Training loss: 3.2260329723358154
Validation loss: 2.691436982923938

Epoch: 5| Step: 8
Training loss: 2.5571377277374268
Validation loss: 2.6894294933606218

Epoch: 5| Step: 9
Training loss: 2.669938564300537
Validation loss: 2.6866476074341805

Epoch: 5| Step: 10
Training loss: 3.0951788425445557
Validation loss: 2.7016555186240905

Epoch: 32| Step: 0
Training loss: 3.168355941772461
Validation loss: 2.6944176663634596

Epoch: 5| Step: 1
Training loss: 2.6544101238250732
Validation loss: 2.6784796099508963

Epoch: 5| Step: 2
Training loss: 3.586392879486084
Validation loss: 2.6661542000309115

Epoch: 5| Step: 3
Training loss: 2.47282338142395
Validation loss: 2.666011707757109

Epoch: 5| Step: 4
Training loss: 3.0638773441314697
Validation loss: 2.6670727088887203

Epoch: 5| Step: 5
Training loss: 2.8049190044403076
Validation loss: 2.670738479142548

Epoch: 5| Step: 6
Training loss: 2.517667055130005
Validation loss: 2.67012519221152

Epoch: 5| Step: 7
Training loss: 2.8720879554748535
Validation loss: 2.670844908683531

Epoch: 5| Step: 8
Training loss: 2.9508891105651855
Validation loss: 2.667558762335008

Epoch: 5| Step: 9
Training loss: 3.074964761734009
Validation loss: 2.661805775857741

Epoch: 5| Step: 10
Training loss: 1.9700251817703247
Validation loss: 2.662161342559322

Epoch: 33| Step: 0
Training loss: 3.774925708770752
Validation loss: 2.660627944495088

Epoch: 5| Step: 1
Training loss: 2.0243077278137207
Validation loss: 2.657591409580682

Epoch: 5| Step: 2
Training loss: 2.07411789894104
Validation loss: 2.670825094305059

Epoch: 5| Step: 3
Training loss: 2.682966470718384
Validation loss: 2.6980501451799945

Epoch: 5| Step: 4
Training loss: 3.006075382232666
Validation loss: 2.7028144969735095

Epoch: 5| Step: 5
Training loss: 2.6081483364105225
Validation loss: 2.68217727445787

Epoch: 5| Step: 6
Training loss: 2.7033627033233643
Validation loss: 2.6535097296519945

Epoch: 5| Step: 7
Training loss: 3.5821032524108887
Validation loss: 2.6483376872154976

Epoch: 5| Step: 8
Training loss: 2.7277615070343018
Validation loss: 2.644206572604436

Epoch: 5| Step: 9
Training loss: 3.2767269611358643
Validation loss: 2.6489623797837125

Epoch: 5| Step: 10
Training loss: 2.823676824569702
Validation loss: 2.6502606586743425

Epoch: 34| Step: 0
Training loss: 2.8246536254882812
Validation loss: 2.6486947715923352

Epoch: 5| Step: 1
Training loss: 4.251086235046387
Validation loss: 2.6493164903374127

Epoch: 5| Step: 2
Training loss: 2.354051113128662
Validation loss: 2.642027452427854

Epoch: 5| Step: 3
Training loss: 2.4171700477600098
Validation loss: 2.63613978252616

Epoch: 5| Step: 4
Training loss: 3.3716042041778564
Validation loss: 2.632927853574035

Epoch: 5| Step: 5
Training loss: 2.1743037700653076
Validation loss: 2.633485658194429

Epoch: 5| Step: 6
Training loss: 2.5531938076019287
Validation loss: 2.633492903042865

Epoch: 5| Step: 7
Training loss: 2.6880416870117188
Validation loss: 2.6365200140142955

Epoch: 5| Step: 8
Training loss: 3.0444436073303223
Validation loss: 2.639568980022143

Epoch: 5| Step: 9
Training loss: 3.2754509449005127
Validation loss: 2.6337709426879883

Epoch: 5| Step: 10
Training loss: 2.003586769104004
Validation loss: 2.63774218866902

Epoch: 35| Step: 0
Training loss: 2.612110137939453
Validation loss: 2.644948938841461

Epoch: 5| Step: 1
Training loss: 2.246431350708008
Validation loss: 2.64123970718794

Epoch: 5| Step: 2
Training loss: 3.115872859954834
Validation loss: 2.647835526415097

Epoch: 5| Step: 3
Training loss: 2.979780673980713
Validation loss: 2.644816626784622

Epoch: 5| Step: 4
Training loss: 2.546142101287842
Validation loss: 2.6465052891803045

Epoch: 5| Step: 5
Training loss: 3.074446201324463
Validation loss: 2.63548158830212

Epoch: 5| Step: 6
Training loss: 2.7386794090270996
Validation loss: 2.629129684099587

Epoch: 5| Step: 7
Training loss: 3.378530979156494
Validation loss: 2.6238325411273586

Epoch: 5| Step: 8
Training loss: 2.7188305854797363
Validation loss: 2.6175287051867415

Epoch: 5| Step: 9
Training loss: 2.697693109512329
Validation loss: 2.617724403258293

Epoch: 5| Step: 10
Training loss: 2.7693912982940674
Validation loss: 2.6163284035139185

Epoch: 36| Step: 0
Training loss: 2.930459499359131
Validation loss: 2.6200744003377934

Epoch: 5| Step: 1
Training loss: 3.0821986198425293
Validation loss: 2.618379956932478

Epoch: 5| Step: 2
Training loss: 2.383164405822754
Validation loss: 2.6107335039364394

Epoch: 5| Step: 3
Training loss: 2.963932514190674
Validation loss: 2.6154631004538587

Epoch: 5| Step: 4
Training loss: 2.6871562004089355
Validation loss: 2.6145828564961753

Epoch: 5| Step: 5
Training loss: 3.3964104652404785
Validation loss: 2.610094872854089

Epoch: 5| Step: 6
Training loss: 2.947983503341675
Validation loss: 2.609989268805391

Epoch: 5| Step: 7
Training loss: 3.0911972522735596
Validation loss: 2.609784669773553

Epoch: 5| Step: 8
Training loss: 2.615823268890381
Validation loss: 2.628468103306268

Epoch: 5| Step: 9
Training loss: 2.1440696716308594
Validation loss: 2.6521207824830086

Epoch: 5| Step: 10
Training loss: 2.513277769088745
Validation loss: 2.6623721020196074

Epoch: 37| Step: 0
Training loss: 2.6920595169067383
Validation loss: 2.6791158158292054

Epoch: 5| Step: 1
Training loss: 2.9405906200408936
Validation loss: 2.6495557292815177

Epoch: 5| Step: 2
Training loss: 2.1878960132598877
Validation loss: 2.607092034432196

Epoch: 5| Step: 3
Training loss: 3.0291011333465576
Validation loss: 2.5958542644336657

Epoch: 5| Step: 4
Training loss: 2.893587589263916
Validation loss: 2.5945187025172736

Epoch: 5| Step: 5
Training loss: 2.9170069694519043
Validation loss: 2.5936914567024476

Epoch: 5| Step: 6
Training loss: 2.945403575897217
Validation loss: 2.596911132976573

Epoch: 5| Step: 7
Training loss: 2.9581375122070312
Validation loss: 2.5915182098265617

Epoch: 5| Step: 8
Training loss: 2.8709654808044434
Validation loss: 2.594735937733804

Epoch: 5| Step: 9
Training loss: 2.60966420173645
Validation loss: 2.592903285898188

Epoch: 5| Step: 10
Training loss: 2.712960720062256
Validation loss: 2.5959539567270586

Epoch: 38| Step: 0
Training loss: 2.8077406883239746
Validation loss: 2.590228331986294

Epoch: 5| Step: 1
Training loss: 2.803884983062744
Validation loss: 2.5925441557361233

Epoch: 5| Step: 2
Training loss: 2.1414618492126465
Validation loss: 2.5897918208952873

Epoch: 5| Step: 3
Training loss: 3.582685947418213
Validation loss: 2.5923733993243148

Epoch: 5| Step: 4
Training loss: 3.0129952430725098
Validation loss: 2.5881160407937984

Epoch: 5| Step: 5
Training loss: 2.416504383087158
Validation loss: 2.5880242137498755

Epoch: 5| Step: 6
Training loss: 3.371619701385498
Validation loss: 2.586051348716982

Epoch: 5| Step: 7
Training loss: 2.1778571605682373
Validation loss: 2.5825207848702707

Epoch: 5| Step: 8
Training loss: 2.9847652912139893
Validation loss: 2.5884987026132564

Epoch: 5| Step: 9
Training loss: 2.141204833984375
Validation loss: 2.58529592329456

Epoch: 5| Step: 10
Training loss: 3.283390998840332
Validation loss: 2.5915639272300144

Epoch: 39| Step: 0
Training loss: 3.0735347270965576
Validation loss: 2.604508956273397

Epoch: 5| Step: 1
Training loss: 2.5599827766418457
Validation loss: 2.593926268239175

Epoch: 5| Step: 2
Training loss: 2.9343457221984863
Validation loss: 2.586248452945422

Epoch: 5| Step: 3
Training loss: 3.252934694290161
Validation loss: 2.5862529072710263

Epoch: 5| Step: 4
Training loss: 3.2183051109313965
Validation loss: 2.5765920595456193

Epoch: 5| Step: 5
Training loss: 2.5262246131896973
Validation loss: 2.572860792119016

Epoch: 5| Step: 6
Training loss: 2.4075727462768555
Validation loss: 2.573172915366388

Epoch: 5| Step: 7
Training loss: 2.8426780700683594
Validation loss: 2.579681201647687

Epoch: 5| Step: 8
Training loss: 2.8342552185058594
Validation loss: 2.590119161913472

Epoch: 5| Step: 9
Training loss: 2.4994640350341797
Validation loss: 2.6010045441248084

Epoch: 5| Step: 10
Training loss: 2.4207141399383545
Validation loss: 2.5934912876416276

Epoch: 40| Step: 0
Training loss: 1.9378163814544678
Validation loss: 2.5839649784949517

Epoch: 5| Step: 1
Training loss: 3.038370132446289
Validation loss: 2.5697344503095074

Epoch: 5| Step: 2
Training loss: 3.052797317504883
Validation loss: 2.5708663155955653

Epoch: 5| Step: 3
Training loss: 2.8482067584991455
Validation loss: 2.5801700622804704

Epoch: 5| Step: 4
Training loss: 3.1716971397399902
Validation loss: 2.5858426811874553

Epoch: 5| Step: 5
Training loss: 2.5657591819763184
Validation loss: 2.573368531401439

Epoch: 5| Step: 6
Training loss: 2.2306153774261475
Validation loss: 2.569552424133465

Epoch: 5| Step: 7
Training loss: 2.613560199737549
Validation loss: 2.563469450960877

Epoch: 5| Step: 8
Training loss: 2.7317440509796143
Validation loss: 2.5660734663727465

Epoch: 5| Step: 9
Training loss: 3.2037034034729004
Validation loss: 2.572500039172429

Epoch: 5| Step: 10
Training loss: 3.3123950958251953
Validation loss: 2.5917546800387803

Epoch: 41| Step: 0
Training loss: 2.8506972789764404
Validation loss: 2.5806711848064134

Epoch: 5| Step: 1
Training loss: 2.9041829109191895
Validation loss: 2.589322090148926

Epoch: 5| Step: 2
Training loss: 2.793233871459961
Validation loss: 2.5892006966375534

Epoch: 5| Step: 3
Training loss: 2.550729990005493
Validation loss: 2.5887411537990777

Epoch: 5| Step: 4
Training loss: 2.7358028888702393
Validation loss: 2.579196406948951

Epoch: 5| Step: 5
Training loss: 2.8308990001678467
Validation loss: 2.565281762871691

Epoch: 5| Step: 6
Training loss: 3.008110761642456
Validation loss: 2.5578749359294934

Epoch: 5| Step: 7
Training loss: 2.085087537765503
Validation loss: 2.5609791586475987

Epoch: 5| Step: 8
Training loss: 2.732893466949463
Validation loss: 2.5631519645772953

Epoch: 5| Step: 9
Training loss: 3.4273293018341064
Validation loss: 2.560483970949727

Epoch: 5| Step: 10
Training loss: 2.503971576690674
Validation loss: 2.5610995549027638

Epoch: 42| Step: 0
Training loss: 2.291646718978882
Validation loss: 2.558261363737045

Epoch: 5| Step: 1
Training loss: 2.9742379188537598
Validation loss: 2.557749327792916

Epoch: 5| Step: 2
Training loss: 3.235631227493286
Validation loss: 2.5565140939527944

Epoch: 5| Step: 3
Training loss: 2.32743239402771
Validation loss: 2.555501284137849

Epoch: 5| Step: 4
Training loss: 2.8419549465179443
Validation loss: 2.568286852170062

Epoch: 5| Step: 5
Training loss: 2.636237621307373
Validation loss: 2.590319833447856

Epoch: 5| Step: 6
Training loss: 2.5457260608673096
Validation loss: 2.5890843022254204

Epoch: 5| Step: 7
Training loss: 3.290966749191284
Validation loss: 2.575457437064058

Epoch: 5| Step: 8
Training loss: 2.588568925857544
Validation loss: 2.584250524479856

Epoch: 5| Step: 9
Training loss: 2.1551570892333984
Validation loss: 2.568865765807449

Epoch: 5| Step: 10
Training loss: 3.615670680999756
Validation loss: 2.5602741908001643

Epoch: 43| Step: 0
Training loss: 3.2305855751037598
Validation loss: 2.553366355998542

Epoch: 5| Step: 1
Training loss: 2.810263156890869
Validation loss: 2.5467734695762716

Epoch: 5| Step: 2
Training loss: 2.543447256088257
Validation loss: 2.5455964713968258

Epoch: 5| Step: 3
Training loss: 2.9060146808624268
Validation loss: 2.54383022041731

Epoch: 5| Step: 4
Training loss: 2.7782182693481445
Validation loss: 2.5456900596618652

Epoch: 5| Step: 5
Training loss: 2.166285991668701
Validation loss: 2.5448745566029705

Epoch: 5| Step: 6
Training loss: 3.1824262142181396
Validation loss: 2.5491739575580885

Epoch: 5| Step: 7
Training loss: 1.8417549133300781
Validation loss: 2.5432442939409645

Epoch: 5| Step: 8
Training loss: 2.8308348655700684
Validation loss: 2.554950144983107

Epoch: 5| Step: 9
Training loss: 2.5368218421936035
Validation loss: 2.554513123727614

Epoch: 5| Step: 10
Training loss: 3.6080591678619385
Validation loss: 2.5436692007126345

Epoch: 44| Step: 0
Training loss: 2.8715317249298096
Validation loss: 2.539737609124953

Epoch: 5| Step: 1
Training loss: 2.038405656814575
Validation loss: 2.5391990343729653

Epoch: 5| Step: 2
Training loss: 2.3373961448669434
Validation loss: 2.549380676720732

Epoch: 5| Step: 3
Training loss: 2.2800087928771973
Validation loss: 2.5526169423134095

Epoch: 5| Step: 4
Training loss: 3.6163952350616455
Validation loss: 2.569139990755307

Epoch: 5| Step: 5
Training loss: 1.8340343236923218
Validation loss: 2.564534789772444

Epoch: 5| Step: 6
Training loss: 2.8762354850769043
Validation loss: 2.563525712618264

Epoch: 5| Step: 7
Training loss: 2.6149606704711914
Validation loss: 2.5587670341614754

Epoch: 5| Step: 8
Training loss: 2.903890371322632
Validation loss: 2.539522458148259

Epoch: 5| Step: 9
Training loss: 3.2377326488494873
Validation loss: 2.532369200901319

Epoch: 5| Step: 10
Training loss: 3.804816246032715
Validation loss: 2.5384795101740028

Epoch: 45| Step: 0
Training loss: 3.2718632221221924
Validation loss: 2.537411892285911

Epoch: 5| Step: 1
Training loss: 2.305527687072754
Validation loss: 2.5332796932548605

Epoch: 5| Step: 2
Training loss: 3.3638319969177246
Validation loss: 2.5346340851117204

Epoch: 5| Step: 3
Training loss: 2.5545177459716797
Validation loss: 2.5368395390049105

Epoch: 5| Step: 4
Training loss: 2.070512294769287
Validation loss: 2.536399377289639

Epoch: 5| Step: 5
Training loss: 3.263671398162842
Validation loss: 2.531207437156349

Epoch: 5| Step: 6
Training loss: 2.9529640674591064
Validation loss: 2.531496109501008

Epoch: 5| Step: 7
Training loss: 2.9820151329040527
Validation loss: 2.530811627705892

Epoch: 5| Step: 8
Training loss: 2.772186756134033
Validation loss: 2.5307573144153883

Epoch: 5| Step: 9
Training loss: 2.5995934009552
Validation loss: 2.5307102100823515

Epoch: 5| Step: 10
Training loss: 2.000462770462036
Validation loss: 2.533352815976707

Epoch: 46| Step: 0
Training loss: 2.8660073280334473
Validation loss: 2.535279607260099

Epoch: 5| Step: 1
Training loss: 2.411175012588501
Validation loss: 2.5350549092856784

Epoch: 5| Step: 2
Training loss: 2.6350512504577637
Validation loss: 2.5313236303226923

Epoch: 5| Step: 3
Training loss: 2.5384373664855957
Validation loss: 2.5227833524827035

Epoch: 5| Step: 4
Training loss: 1.8981282711029053
Validation loss: 2.523434408249394

Epoch: 5| Step: 5
Training loss: 2.979783296585083
Validation loss: 2.529016561405633

Epoch: 5| Step: 6
Training loss: 2.3378348350524902
Validation loss: 2.5272395380081667

Epoch: 5| Step: 7
Training loss: 2.926164388656616
Validation loss: 2.5413425865993706

Epoch: 5| Step: 8
Training loss: 3.331958293914795
Validation loss: 2.544096380151728

Epoch: 5| Step: 9
Training loss: 3.1732373237609863
Validation loss: 2.5583322560915382

Epoch: 5| Step: 10
Training loss: 3.114171266555786
Validation loss: 2.576882234183691

Epoch: 47| Step: 0
Training loss: 2.051607131958008
Validation loss: 2.5521965821584067

Epoch: 5| Step: 1
Training loss: 2.9749202728271484
Validation loss: 2.5296795034921296

Epoch: 5| Step: 2
Training loss: 2.8341898918151855
Validation loss: 2.523155535421064

Epoch: 5| Step: 3
Training loss: 2.8620452880859375
Validation loss: 2.5263824616709063

Epoch: 5| Step: 4
Training loss: 2.8583176136016846
Validation loss: 2.5191308862419537

Epoch: 5| Step: 5
Training loss: 2.9085700511932373
Validation loss: 2.524073464896089

Epoch: 5| Step: 6
Training loss: 2.588606357574463
Validation loss: 2.523854717131584

Epoch: 5| Step: 7
Training loss: 2.749417781829834
Validation loss: 2.5239772694085234

Epoch: 5| Step: 8
Training loss: 2.705388307571411
Validation loss: 2.524816979644119

Epoch: 5| Step: 9
Training loss: 2.3481643199920654
Validation loss: 2.5287284158891246

Epoch: 5| Step: 10
Training loss: 3.284181594848633
Validation loss: 2.526280521064676

Epoch: 48| Step: 0
Training loss: 3.1449737548828125
Validation loss: 2.5324594179789224

Epoch: 5| Step: 1
Training loss: 1.9180923700332642
Validation loss: 2.5329768657684326

Epoch: 5| Step: 2
Training loss: 2.570648670196533
Validation loss: 2.5326478276201474

Epoch: 5| Step: 3
Training loss: 2.4727442264556885
Validation loss: 2.5331241725593485

Epoch: 5| Step: 4
Training loss: 2.5563254356384277
Validation loss: 2.5350036826185

Epoch: 5| Step: 5
Training loss: 2.8024818897247314
Validation loss: 2.5428083942782496

Epoch: 5| Step: 6
Training loss: 3.10048246383667
Validation loss: 2.545693564158614

Epoch: 5| Step: 7
Training loss: 3.397037982940674
Validation loss: 2.55596992533694

Epoch: 5| Step: 8
Training loss: 2.7339365482330322
Validation loss: 2.5573690988684215

Epoch: 5| Step: 9
Training loss: 2.7396810054779053
Validation loss: 2.544332483763336

Epoch: 5| Step: 10
Training loss: 2.5940728187561035
Validation loss: 2.5293949239997455

Epoch: 49| Step: 0
Training loss: 2.383173704147339
Validation loss: 2.525157695175499

Epoch: 5| Step: 1
Training loss: 2.418179988861084
Validation loss: 2.519611015114733

Epoch: 5| Step: 2
Training loss: 3.0731406211853027
Validation loss: 2.517207448200513

Epoch: 5| Step: 3
Training loss: 2.7665553092956543
Validation loss: 2.5133061896088305

Epoch: 5| Step: 4
Training loss: 2.552727460861206
Validation loss: 2.5198812818014495

Epoch: 5| Step: 5
Training loss: 3.3550639152526855
Validation loss: 2.5297548822177354

Epoch: 5| Step: 6
Training loss: 2.265479564666748
Validation loss: 2.536438226699829

Epoch: 5| Step: 7
Training loss: 2.8842086791992188
Validation loss: 2.5351266681507068

Epoch: 5| Step: 8
Training loss: 2.4916675090789795
Validation loss: 2.5253355938901185

Epoch: 5| Step: 9
Training loss: 3.2287039756774902
Validation loss: 2.5151256104951263

Epoch: 5| Step: 10
Training loss: 2.5970044136047363
Validation loss: 2.5122238436052875

Epoch: 50| Step: 0
Training loss: 2.940865993499756
Validation loss: 2.5234144067251556

Epoch: 5| Step: 1
Training loss: 2.5250964164733887
Validation loss: 2.5306016501560005

Epoch: 5| Step: 2
Training loss: 2.089735746383667
Validation loss: 2.5355513352219776

Epoch: 5| Step: 3
Training loss: 2.130812406539917
Validation loss: 2.5498321184548

Epoch: 5| Step: 4
Training loss: 3.2864761352539062
Validation loss: 2.5445157045959146

Epoch: 5| Step: 5
Training loss: 3.275146007537842
Validation loss: 2.521197239557902

Epoch: 5| Step: 6
Training loss: 2.8644394874572754
Validation loss: 2.5110798804990706

Epoch: 5| Step: 7
Training loss: 3.013585329055786
Validation loss: 2.508400965762395

Epoch: 5| Step: 8
Training loss: 2.480846643447876
Validation loss: 2.511735225236544

Epoch: 5| Step: 9
Training loss: 2.9207911491394043
Validation loss: 2.507612077138757

Epoch: 5| Step: 10
Training loss: 2.351264238357544
Validation loss: 2.5175423724676973

Epoch: 51| Step: 0
Training loss: 2.8185670375823975
Validation loss: 2.5209951323847615

Epoch: 5| Step: 1
Training loss: 2.5481269359588623
Validation loss: 2.518604686183314

Epoch: 5| Step: 2
Training loss: 2.6980860233306885
Validation loss: 2.512873634215324

Epoch: 5| Step: 3
Training loss: 2.529510736465454
Validation loss: 2.512769865733321

Epoch: 5| Step: 4
Training loss: 2.3094897270202637
Validation loss: 2.514630115160378

Epoch: 5| Step: 5
Training loss: 2.810580015182495
Validation loss: 2.514216443543793

Epoch: 5| Step: 6
Training loss: 2.7257931232452393
Validation loss: 2.5161657243646602

Epoch: 5| Step: 7
Training loss: 2.7396674156188965
Validation loss: 2.5103888280930056

Epoch: 5| Step: 8
Training loss: 3.5372567176818848
Validation loss: 2.5100301465680523

Epoch: 5| Step: 9
Training loss: 2.382830858230591
Validation loss: 2.5167554347745833

Epoch: 5| Step: 10
Training loss: 2.9955074787139893
Validation loss: 2.5327789834750596

Epoch: 52| Step: 0
Training loss: 2.7130274772644043
Validation loss: 2.5333105851245183

Epoch: 5| Step: 1
Training loss: 2.611182689666748
Validation loss: 2.522116004779775

Epoch: 5| Step: 2
Training loss: 3.0901074409484863
Validation loss: 2.5080190627805647

Epoch: 5| Step: 3
Training loss: 3.3663437366485596
Validation loss: 2.5035073859717256

Epoch: 5| Step: 4
Training loss: 2.41133451461792
Validation loss: 2.505606274450979

Epoch: 5| Step: 5
Training loss: 2.7124340534210205
Validation loss: 2.5046666770853023

Epoch: 5| Step: 6
Training loss: 2.5610437393188477
Validation loss: 2.506987025660853

Epoch: 5| Step: 7
Training loss: 2.7219507694244385
Validation loss: 2.5064164746192192

Epoch: 5| Step: 8
Training loss: 2.1899657249450684
Validation loss: 2.5026791557188957

Epoch: 5| Step: 9
Training loss: 3.027740001678467
Validation loss: 2.502678589154315

Epoch: 5| Step: 10
Training loss: 2.5750539302825928
Validation loss: 2.5040877121751026

Epoch: 53| Step: 0
Training loss: 2.8079421520233154
Validation loss: 2.5021320824982016

Epoch: 5| Step: 1
Training loss: 1.9042108058929443
Validation loss: 2.499090010120023

Epoch: 5| Step: 2
Training loss: 3.425093173980713
Validation loss: 2.499995664883685

Epoch: 5| Step: 3
Training loss: 2.3629627227783203
Validation loss: 2.49870906337615

Epoch: 5| Step: 4
Training loss: 2.886136531829834
Validation loss: 2.499006594381025

Epoch: 5| Step: 5
Training loss: 3.15350079536438
Validation loss: 2.502942116029801

Epoch: 5| Step: 6
Training loss: 2.668217897415161
Validation loss: 2.507155672196419

Epoch: 5| Step: 7
Training loss: 2.7079052925109863
Validation loss: 2.5115420613237607

Epoch: 5| Step: 8
Training loss: 2.2094531059265137
Validation loss: 2.5103986263275146

Epoch: 5| Step: 9
Training loss: 3.0297741889953613
Validation loss: 2.508549718446629

Epoch: 5| Step: 10
Training loss: 2.777907371520996
Validation loss: 2.5119666848131406

Epoch: 54| Step: 0
Training loss: 2.462280750274658
Validation loss: 2.5076844538411787

Epoch: 5| Step: 1
Training loss: 3.5004467964172363
Validation loss: 2.5090268440144037

Epoch: 5| Step: 2
Training loss: 2.880052089691162
Validation loss: 2.505668068444857

Epoch: 5| Step: 3
Training loss: 2.7581260204315186
Validation loss: 2.5070815676002094

Epoch: 5| Step: 4
Training loss: 2.6775784492492676
Validation loss: 2.501141901939146

Epoch: 5| Step: 5
Training loss: 3.104022264480591
Validation loss: 2.501924809589181

Epoch: 5| Step: 6
Training loss: 2.8514480590820312
Validation loss: 2.5000536108529694

Epoch: 5| Step: 7
Training loss: 2.1502685546875
Validation loss: 2.5071519984993884

Epoch: 5| Step: 8
Training loss: 2.7710378170013428
Validation loss: 2.5013055673209568

Epoch: 5| Step: 9
Training loss: 2.452098846435547
Validation loss: 2.5055851897885724

Epoch: 5| Step: 10
Training loss: 2.227642774581909
Validation loss: 2.5002377084506455

Epoch: 55| Step: 0
Training loss: 2.167203664779663
Validation loss: 2.4956101345759567

Epoch: 5| Step: 1
Training loss: 3.0791029930114746
Validation loss: 2.497910907191615

Epoch: 5| Step: 2
Training loss: 3.4696221351623535
Validation loss: 2.491905189329578

Epoch: 5| Step: 3
Training loss: 2.5148608684539795
Validation loss: 2.5008534898040113

Epoch: 5| Step: 4
Training loss: 2.156580924987793
Validation loss: 2.500198453985235

Epoch: 5| Step: 5
Training loss: 2.5017874240875244
Validation loss: 2.5012839994122906

Epoch: 5| Step: 6
Training loss: 3.101715564727783
Validation loss: 2.5029696674757105

Epoch: 5| Step: 7
Training loss: 2.0549709796905518
Validation loss: 2.4977239152436614

Epoch: 5| Step: 8
Training loss: 3.2298424243927
Validation loss: 2.498136164039694

Epoch: 5| Step: 9
Training loss: 3.075950860977173
Validation loss: 2.4946460980241016

Epoch: 5| Step: 10
Training loss: 2.528883934020996
Validation loss: 2.5003153559982136

Epoch: 56| Step: 0
Training loss: 2.059213399887085
Validation loss: 2.5078652110151065

Epoch: 5| Step: 1
Training loss: 3.1191704273223877
Validation loss: 2.52048312464068

Epoch: 5| Step: 2
Training loss: 2.597090482711792
Validation loss: 2.5236028368755052

Epoch: 5| Step: 3
Training loss: 2.4795689582824707
Validation loss: 2.5203977374620337

Epoch: 5| Step: 4
Training loss: 2.9218242168426514
Validation loss: 2.5101545446662494

Epoch: 5| Step: 5
Training loss: 2.898813247680664
Validation loss: 2.505857288196523

Epoch: 5| Step: 6
Training loss: 2.863903760910034
Validation loss: 2.4963158304973314

Epoch: 5| Step: 7
Training loss: 2.790780544281006
Validation loss: 2.49931534131368

Epoch: 5| Step: 8
Training loss: 2.7797369956970215
Validation loss: 2.4945287473740114

Epoch: 5| Step: 9
Training loss: 3.2046210765838623
Validation loss: 2.5019614260683776

Epoch: 5| Step: 10
Training loss: 2.195686101913452
Validation loss: 2.4979340901938816

Epoch: 57| Step: 0
Training loss: 2.5039114952087402
Validation loss: 2.4989379862303376

Epoch: 5| Step: 1
Training loss: 2.504218339920044
Validation loss: 2.5067933169744347

Epoch: 5| Step: 2
Training loss: 2.8874592781066895
Validation loss: 2.5014414633474042

Epoch: 5| Step: 3
Training loss: 2.6210670471191406
Validation loss: 2.5061783688042754

Epoch: 5| Step: 4
Training loss: 2.7150120735168457
Validation loss: 2.500673278685539

Epoch: 5| Step: 5
Training loss: 2.6085314750671387
Validation loss: 2.504742019919939

Epoch: 5| Step: 6
Training loss: 2.9918129444122314
Validation loss: 2.522171307635564

Epoch: 5| Step: 7
Training loss: 3.3414409160614014
Validation loss: 2.539130787695608

Epoch: 5| Step: 8
Training loss: 2.7902932167053223
Validation loss: 2.5305159758496028

Epoch: 5| Step: 9
Training loss: 2.4177086353302
Validation loss: 2.522582754012077

Epoch: 5| Step: 10
Training loss: 2.624673843383789
Validation loss: 2.50420045339933

Epoch: 58| Step: 0
Training loss: 2.2898449897766113
Validation loss: 2.5051054698164745

Epoch: 5| Step: 1
Training loss: 3.2980079650878906
Validation loss: 2.503017158918483

Epoch: 5| Step: 2
Training loss: 2.2799525260925293
Validation loss: 2.5012399227388444

Epoch: 5| Step: 3
Training loss: 2.6091361045837402
Validation loss: 2.50175876514886

Epoch: 5| Step: 4
Training loss: 2.80857515335083
Validation loss: 2.5004373212014475

Epoch: 5| Step: 5
Training loss: 2.250483274459839
Validation loss: 2.4953091259925597

Epoch: 5| Step: 6
Training loss: 2.581343650817871
Validation loss: 2.4960379882525374

Epoch: 5| Step: 7
Training loss: 2.415412187576294
Validation loss: 2.4940082821794736

Epoch: 5| Step: 8
Training loss: 3.236560344696045
Validation loss: 2.5104967137818694

Epoch: 5| Step: 9
Training loss: 2.829075336456299
Validation loss: 2.515331842566049

Epoch: 5| Step: 10
Training loss: 3.323993444442749
Validation loss: 2.5346184110128753

Epoch: 59| Step: 0
Training loss: 3.185434103012085
Validation loss: 2.53020038143281

Epoch: 5| Step: 1
Training loss: 2.6276819705963135
Validation loss: 2.5162097305379887

Epoch: 5| Step: 2
Training loss: 3.498844861984253
Validation loss: 2.5091647755715156

Epoch: 5| Step: 3
Training loss: 3.024181604385376
Validation loss: 2.499303904912805

Epoch: 5| Step: 4
Training loss: 2.2602334022521973
Validation loss: 2.4973181883494058

Epoch: 5| Step: 5
Training loss: 2.761871099472046
Validation loss: 2.4912690013967533

Epoch: 5| Step: 6
Training loss: 2.431852102279663
Validation loss: 2.492951857146396

Epoch: 5| Step: 7
Training loss: 2.4083638191223145
Validation loss: 2.4957196635584675

Epoch: 5| Step: 8
Training loss: 2.0714974403381348
Validation loss: 2.503467285504905

Epoch: 5| Step: 9
Training loss: 3.022874355316162
Validation loss: 2.501561987784601

Epoch: 5| Step: 10
Training loss: 2.4555225372314453
Validation loss: 2.502780524633264

Epoch: 60| Step: 0
Training loss: 2.2220261096954346
Validation loss: 2.5067249087877173

Epoch: 5| Step: 1
Training loss: 1.9694503545761108
Validation loss: 2.52346327740659

Epoch: 5| Step: 2
Training loss: 2.4003868103027344
Validation loss: 2.526739976739371

Epoch: 5| Step: 3
Training loss: 3.113485336303711
Validation loss: 2.503809175183696

Epoch: 5| Step: 4
Training loss: 2.9606752395629883
Validation loss: 2.495785520922753

Epoch: 5| Step: 5
Training loss: 2.9067795276641846
Validation loss: 2.495107912248181

Epoch: 5| Step: 6
Training loss: 3.159195899963379
Validation loss: 2.4865013886523504

Epoch: 5| Step: 7
Training loss: 2.643915891647339
Validation loss: 2.487620525462653

Epoch: 5| Step: 8
Training loss: 2.637336254119873
Validation loss: 2.4857150816148326

Epoch: 5| Step: 9
Training loss: 2.6921281814575195
Validation loss: 2.486273524581745

Epoch: 5| Step: 10
Training loss: 3.1753878593444824
Validation loss: 2.4858143380893174

Epoch: 61| Step: 0
Training loss: 2.653797149658203
Validation loss: 2.4809630968237437

Epoch: 5| Step: 1
Training loss: 2.0502421855926514
Validation loss: 2.4810370886197655

Epoch: 5| Step: 2
Training loss: 2.788839101791382
Validation loss: 2.478279306042579

Epoch: 5| Step: 3
Training loss: 2.361240863800049
Validation loss: 2.484744971798312

Epoch: 5| Step: 4
Training loss: 2.778778314590454
Validation loss: 2.4795420272375948

Epoch: 5| Step: 5
Training loss: 2.186992645263672
Validation loss: 2.4820108516241914

Epoch: 5| Step: 6
Training loss: 2.5757107734680176
Validation loss: 2.4876111809925368

Epoch: 5| Step: 7
Training loss: 3.0023951530456543
Validation loss: 2.485625923320811

Epoch: 5| Step: 8
Training loss: 2.5388712882995605
Validation loss: 2.489718242358136

Epoch: 5| Step: 9
Training loss: 3.5035438537597656
Validation loss: 2.4938114458514797

Epoch: 5| Step: 10
Training loss: 3.4121744632720947
Validation loss: 2.4928272744660736

Epoch: 62| Step: 0
Training loss: 2.676926374435425
Validation loss: 2.496131661117718

Epoch: 5| Step: 1
Training loss: 3.107996702194214
Validation loss: 2.5081923443783998

Epoch: 5| Step: 2
Training loss: 2.4861838817596436
Validation loss: 2.515293259774485

Epoch: 5| Step: 3
Training loss: 2.1943233013153076
Validation loss: 2.506237112065797

Epoch: 5| Step: 4
Training loss: 2.291027545928955
Validation loss: 2.4923572745374454

Epoch: 5| Step: 5
Training loss: 2.9456043243408203
Validation loss: 2.4882367041803177

Epoch: 5| Step: 6
Training loss: 3.4282546043395996
Validation loss: 2.490111474067934

Epoch: 5| Step: 7
Training loss: 3.331242799758911
Validation loss: 2.4979661510836695

Epoch: 5| Step: 8
Training loss: 2.4104020595550537
Validation loss: 2.485268513361613

Epoch: 5| Step: 9
Training loss: 2.586596965789795
Validation loss: 2.4841136650372575

Epoch: 5| Step: 10
Training loss: 2.2572944164276123
Validation loss: 2.4841401679541475

Epoch: 63| Step: 0
Training loss: 2.1389260292053223
Validation loss: 2.4765070740894606

Epoch: 5| Step: 1
Training loss: 3.065708637237549
Validation loss: 2.476789284777898

Epoch: 5| Step: 2
Training loss: 3.158484697341919
Validation loss: 2.484250012264457

Epoch: 5| Step: 3
Training loss: 2.843186616897583
Validation loss: 2.487471152377385

Epoch: 5| Step: 4
Training loss: 2.935122013092041
Validation loss: 2.4956264752213673

Epoch: 5| Step: 5
Training loss: 2.3514180183410645
Validation loss: 2.4888942344214326

Epoch: 5| Step: 6
Training loss: 2.3656296730041504
Validation loss: 2.4890773168174167

Epoch: 5| Step: 7
Training loss: 2.2856619358062744
Validation loss: 2.4834646999195056

Epoch: 5| Step: 8
Training loss: 2.8127408027648926
Validation loss: 2.4890528314857074

Epoch: 5| Step: 9
Training loss: 2.598917007446289
Validation loss: 2.489580995293074

Epoch: 5| Step: 10
Training loss: 3.1518075466156006
Validation loss: 2.4869770029539704

Epoch: 64| Step: 0
Training loss: 2.5342283248901367
Validation loss: 2.4882535754993396

Epoch: 5| Step: 1
Training loss: 2.266512393951416
Validation loss: 2.4862037845837173

Epoch: 5| Step: 2
Training loss: 2.623837471008301
Validation loss: 2.483315298634191

Epoch: 5| Step: 3
Training loss: 2.3476760387420654
Validation loss: 2.4791236103221936

Epoch: 5| Step: 4
Training loss: 3.189873218536377
Validation loss: 2.479187642374346

Epoch: 5| Step: 5
Training loss: 2.8467297554016113
Validation loss: 2.4760347668842604

Epoch: 5| Step: 6
Training loss: 2.5755157470703125
Validation loss: 2.472397929878645

Epoch: 5| Step: 7
Training loss: 2.5214157104492188
Validation loss: 2.4767127165230374

Epoch: 5| Step: 8
Training loss: 3.0118706226348877
Validation loss: 2.4827114946098736

Epoch: 5| Step: 9
Training loss: 2.9685511589050293
Validation loss: 2.478559781146306

Epoch: 5| Step: 10
Training loss: 2.783640146255493
Validation loss: 2.484565119589529

Epoch: 65| Step: 0
Training loss: 2.408043622970581
Validation loss: 2.486450982350175

Epoch: 5| Step: 1
Training loss: 2.488452196121216
Validation loss: 2.4860768036175798

Epoch: 5| Step: 2
Training loss: 2.5117077827453613
Validation loss: 2.4832889392811763

Epoch: 5| Step: 3
Training loss: 3.176060914993286
Validation loss: 2.4831746906362553

Epoch: 5| Step: 4
Training loss: 2.4737002849578857
Validation loss: 2.482462598431495

Epoch: 5| Step: 5
Training loss: 2.0627799034118652
Validation loss: 2.4807588438833914

Epoch: 5| Step: 6
Training loss: 3.311738967895508
Validation loss: 2.478604019329112

Epoch: 5| Step: 7
Training loss: 2.894040584564209
Validation loss: 2.4777630400914017

Epoch: 5| Step: 8
Training loss: 3.15643572807312
Validation loss: 2.476120538609002

Epoch: 5| Step: 9
Training loss: 2.6210875511169434
Validation loss: 2.4726213255236225

Epoch: 5| Step: 10
Training loss: 2.467710256576538
Validation loss: 2.472939973236412

Epoch: 66| Step: 0
Training loss: 3.08709979057312
Validation loss: 2.470495826454573

Epoch: 5| Step: 1
Training loss: 2.4213550090789795
Validation loss: 2.473004089888706

Epoch: 5| Step: 2
Training loss: 3.0236175060272217
Validation loss: 2.4782663314573226

Epoch: 5| Step: 3
Training loss: 2.3626387119293213
Validation loss: 2.476861256425099

Epoch: 5| Step: 4
Training loss: 1.9912517070770264
Validation loss: 2.473483185614309

Epoch: 5| Step: 5
Training loss: 2.689962387084961
Validation loss: 2.4720109970338884

Epoch: 5| Step: 6
Training loss: 2.819854974746704
Validation loss: 2.4704985003317557

Epoch: 5| Step: 7
Training loss: 2.4602808952331543
Validation loss: 2.474559719844531

Epoch: 5| Step: 8
Training loss: 3.0849199295043945
Validation loss: 2.4716325703487603

Epoch: 5| Step: 9
Training loss: 2.3887064456939697
Validation loss: 2.4720370666955107

Epoch: 5| Step: 10
Training loss: 3.363279342651367
Validation loss: 2.470805706516389

Epoch: 67| Step: 0
Training loss: 3.025088310241699
Validation loss: 2.470590745249102

Epoch: 5| Step: 1
Training loss: 2.9735546112060547
Validation loss: 2.4696052971706597

Epoch: 5| Step: 2
Training loss: 2.9075112342834473
Validation loss: 2.4712027631780153

Epoch: 5| Step: 3
Training loss: 2.930739641189575
Validation loss: 2.4740600483391875

Epoch: 5| Step: 4
Training loss: 2.307934522628784
Validation loss: 2.467130978902181

Epoch: 5| Step: 5
Training loss: 3.3101603984832764
Validation loss: 2.4701812574940343

Epoch: 5| Step: 6
Training loss: 2.407148599624634
Validation loss: 2.47196529757592

Epoch: 5| Step: 7
Training loss: 2.5280489921569824
Validation loss: 2.472431790444159

Epoch: 5| Step: 8
Training loss: 2.67537260055542
Validation loss: 2.4769608897547566

Epoch: 5| Step: 9
Training loss: 2.3560447692871094
Validation loss: 2.477578540002146

Epoch: 5| Step: 10
Training loss: 2.147507905960083
Validation loss: 2.489110400599818

Epoch: 68| Step: 0
Training loss: 2.935901165008545
Validation loss: 2.4917289877450592

Epoch: 5| Step: 1
Training loss: 2.9510295391082764
Validation loss: 2.503226572467435

Epoch: 5| Step: 2
Training loss: 3.241198778152466
Validation loss: 2.497751356453024

Epoch: 5| Step: 3
Training loss: 2.7776401042938232
Validation loss: 2.5022649457377772

Epoch: 5| Step: 4
Training loss: 2.53180193901062
Validation loss: 2.4965174403241885

Epoch: 5| Step: 5
Training loss: 2.3560702800750732
Validation loss: 2.4854970106514553

Epoch: 5| Step: 6
Training loss: 2.7786669731140137
Validation loss: 2.4894437405370895

Epoch: 5| Step: 7
Training loss: 2.6530120372772217
Validation loss: 2.484757800256052

Epoch: 5| Step: 8
Training loss: 2.097261667251587
Validation loss: 2.4826694867944203

Epoch: 5| Step: 9
Training loss: 2.784174919128418
Validation loss: 2.4784273742347636

Epoch: 5| Step: 10
Training loss: 2.5209646224975586
Validation loss: 2.475588898504934

Epoch: 69| Step: 0
Training loss: 3.071007251739502
Validation loss: 2.4737146823636946

Epoch: 5| Step: 1
Training loss: 2.039783239364624
Validation loss: 2.4683137478366977

Epoch: 5| Step: 2
Training loss: 1.8509314060211182
Validation loss: 2.4732792633835987

Epoch: 5| Step: 3
Training loss: 3.0406947135925293
Validation loss: 2.4720231691996255

Epoch: 5| Step: 4
Training loss: 2.844092845916748
Validation loss: 2.471170799706572

Epoch: 5| Step: 5
Training loss: 3.474134922027588
Validation loss: 2.472021334914751

Epoch: 5| Step: 6
Training loss: 3.165699005126953
Validation loss: 2.469870034084525

Epoch: 5| Step: 7
Training loss: 2.5127158164978027
Validation loss: 2.4744545490511003

Epoch: 5| Step: 8
Training loss: 2.601031541824341
Validation loss: 2.483572119025774

Epoch: 5| Step: 9
Training loss: 2.6110446453094482
Validation loss: 2.4922989747857534

Epoch: 5| Step: 10
Training loss: 2.363666534423828
Validation loss: 2.4799053566430205

Epoch: 70| Step: 0
Training loss: 2.729534864425659
Validation loss: 2.4712483139448267

Epoch: 5| Step: 1
Training loss: 3.039153814315796
Validation loss: 2.469648448369836

Epoch: 5| Step: 2
Training loss: 2.498241424560547
Validation loss: 2.4634237955975276

Epoch: 5| Step: 3
Training loss: 2.3673605918884277
Validation loss: 2.4627871641548733

Epoch: 5| Step: 4
Training loss: 2.007693290710449
Validation loss: 2.461350243578675

Epoch: 5| Step: 5
Training loss: 3.2226080894470215
Validation loss: 2.4616850268456245

Epoch: 5| Step: 6
Training loss: 2.6313390731811523
Validation loss: 2.4609144554343274

Epoch: 5| Step: 7
Training loss: 2.513489007949829
Validation loss: 2.466251265618109

Epoch: 5| Step: 8
Training loss: 2.8632748126983643
Validation loss: 2.4698446617331555

Epoch: 5| Step: 9
Training loss: 2.874267101287842
Validation loss: 2.4777468250643824

Epoch: 5| Step: 10
Training loss: 2.871770143508911
Validation loss: 2.4815985156643774

Epoch: 71| Step: 0
Training loss: 2.810652732849121
Validation loss: 2.4827962447238225

Epoch: 5| Step: 1
Training loss: 2.362077236175537
Validation loss: 2.4849618070869037

Epoch: 5| Step: 2
Training loss: 2.6995043754577637
Validation loss: 2.475364782476938

Epoch: 5| Step: 3
Training loss: 3.0252914428710938
Validation loss: 2.4827908597966677

Epoch: 5| Step: 4
Training loss: 3.200230836868286
Validation loss: 2.4933020017480336

Epoch: 5| Step: 5
Training loss: 2.0760302543640137
Validation loss: 2.493256461235785

Epoch: 5| Step: 6
Training loss: 3.5579516887664795
Validation loss: 2.4965355934635287

Epoch: 5| Step: 7
Training loss: 1.793696641921997
Validation loss: 2.4925122235410955

Epoch: 5| Step: 8
Training loss: 3.5574679374694824
Validation loss: 2.484722845015987

Epoch: 5| Step: 9
Training loss: 2.501944065093994
Validation loss: 2.475701762783912

Epoch: 5| Step: 10
Training loss: 1.9577540159225464
Validation loss: 2.477398549356768

Epoch: 72| Step: 0
Training loss: 2.5997700691223145
Validation loss: 2.466503140746906

Epoch: 5| Step: 1
Training loss: 2.835507869720459
Validation loss: 2.4683643464119203

Epoch: 5| Step: 2
Training loss: 2.6436991691589355
Validation loss: 2.4627635863519486

Epoch: 5| Step: 3
Training loss: 2.6093955039978027
Validation loss: 2.4633862023712485

Epoch: 5| Step: 4
Training loss: 2.8652143478393555
Validation loss: 2.464383566251365

Epoch: 5| Step: 5
Training loss: 3.4751389026641846
Validation loss: 2.463775393783405

Epoch: 5| Step: 6
Training loss: 3.090230941772461
Validation loss: 2.4644036139211347

Epoch: 5| Step: 7
Training loss: 1.4894425868988037
Validation loss: 2.4633038787431616

Epoch: 5| Step: 8
Training loss: 2.447331428527832
Validation loss: 2.465466458310363

Epoch: 5| Step: 9
Training loss: 2.8457014560699463
Validation loss: 2.4633448764842045

Epoch: 5| Step: 10
Training loss: 2.645542621612549
Validation loss: 2.4669856050963044

Epoch: 73| Step: 0
Training loss: 2.3608896732330322
Validation loss: 2.4668159741227345

Epoch: 5| Step: 1
Training loss: 2.958649158477783
Validation loss: 2.472728790775422

Epoch: 5| Step: 2
Training loss: 2.3292396068573
Validation loss: 2.469651596520537

Epoch: 5| Step: 3
Training loss: 2.752321243286133
Validation loss: 2.4800574292418776

Epoch: 5| Step: 4
Training loss: 3.1380317211151123
Validation loss: 2.477650955159177

Epoch: 5| Step: 5
Training loss: 2.5751850605010986
Validation loss: 2.4813680494985273

Epoch: 5| Step: 6
Training loss: 2.2467377185821533
Validation loss: 2.4770293338324434

Epoch: 5| Step: 7
Training loss: 2.547524929046631
Validation loss: 2.4779261389086322

Epoch: 5| Step: 8
Training loss: 2.3822948932647705
Validation loss: 2.4761739751344085

Epoch: 5| Step: 9
Training loss: 3.464552402496338
Validation loss: 2.477072059467275

Epoch: 5| Step: 10
Training loss: 2.741161584854126
Validation loss: 2.472257742317774

Epoch: 74| Step: 0
Training loss: 2.7971150875091553
Validation loss: 2.4684722192825808

Epoch: 5| Step: 1
Training loss: 2.503469944000244
Validation loss: 2.458959020594115

Epoch: 5| Step: 2
Training loss: 2.945810079574585
Validation loss: 2.4538925386244252

Epoch: 5| Step: 3
Training loss: 2.4053940773010254
Validation loss: 2.4615142883793

Epoch: 5| Step: 4
Training loss: 2.65527606010437
Validation loss: 2.4595490424863753

Epoch: 5| Step: 5
Training loss: 2.3268165588378906
Validation loss: 2.4655296059064966

Epoch: 5| Step: 6
Training loss: 2.5479512214660645
Validation loss: 2.4615372278357066

Epoch: 5| Step: 7
Training loss: 2.381606101989746
Validation loss: 2.4697903920245428

Epoch: 5| Step: 8
Training loss: 2.7689225673675537
Validation loss: 2.4614610543815036

Epoch: 5| Step: 9
Training loss: 3.134459972381592
Validation loss: 2.466196229380946

Epoch: 5| Step: 10
Training loss: 3.2003226280212402
Validation loss: 2.4626638812403523

Epoch: 75| Step: 0
Training loss: 2.1496057510375977
Validation loss: 2.469695024592902

Epoch: 5| Step: 1
Training loss: 3.218533992767334
Validation loss: 2.469377266463413

Epoch: 5| Step: 2
Training loss: 3.265625
Validation loss: 2.4803456619221675

Epoch: 5| Step: 3
Training loss: 2.8036346435546875
Validation loss: 2.487299567909651

Epoch: 5| Step: 4
Training loss: 3.396070957183838
Validation loss: 2.4820189065830682

Epoch: 5| Step: 5
Training loss: 2.7136096954345703
Validation loss: 2.4862468370827298

Epoch: 5| Step: 6
Training loss: 2.5729472637176514
Validation loss: 2.4826135314920896

Epoch: 5| Step: 7
Training loss: 2.7254319190979004
Validation loss: 2.468888210993941

Epoch: 5| Step: 8
Training loss: 1.964979887008667
Validation loss: 2.470386794818345

Epoch: 5| Step: 9
Training loss: 2.0786819458007812
Validation loss: 2.473151381297778

Epoch: 5| Step: 10
Training loss: 2.634275436401367
Validation loss: 2.4637664979504

Epoch: 76| Step: 0
Training loss: 2.680673122406006
Validation loss: 2.4587872976897867

Epoch: 5| Step: 1
Training loss: 2.531437635421753
Validation loss: 2.46023605972208

Epoch: 5| Step: 2
Training loss: 2.578885316848755
Validation loss: 2.4596772168272283

Epoch: 5| Step: 3
Training loss: 3.2497386932373047
Validation loss: 2.4591708465289046

Epoch: 5| Step: 4
Training loss: 2.7994384765625
Validation loss: 2.4578924768714496

Epoch: 5| Step: 5
Training loss: 2.754545211791992
Validation loss: 2.449530952720232

Epoch: 5| Step: 6
Training loss: 2.380230665206909
Validation loss: 2.45480118772035

Epoch: 5| Step: 7
Training loss: 2.061521530151367
Validation loss: 2.4553884690807712

Epoch: 5| Step: 8
Training loss: 3.0055301189422607
Validation loss: 2.45900313315853

Epoch: 5| Step: 9
Training loss: 2.797694444656372
Validation loss: 2.4566232491565008

Epoch: 5| Step: 10
Training loss: 2.6146371364593506
Validation loss: 2.4598348268898587

Epoch: 77| Step: 0
Training loss: 2.8889193534851074
Validation loss: 2.4545585647706063

Epoch: 5| Step: 1
Training loss: 2.7727012634277344
Validation loss: 2.45605073436614

Epoch: 5| Step: 2
Training loss: 2.251080274581909
Validation loss: 2.449478615996658

Epoch: 5| Step: 3
Training loss: 2.780358076095581
Validation loss: 2.450991348553729

Epoch: 5| Step: 4
Training loss: 2.8851351737976074
Validation loss: 2.4460718606107976

Epoch: 5| Step: 5
Training loss: 2.869582176208496
Validation loss: 2.4410826493335027

Epoch: 5| Step: 6
Training loss: 3.007887363433838
Validation loss: 2.445632475678639

Epoch: 5| Step: 7
Training loss: 2.49543833732605
Validation loss: 2.442746795633788

Epoch: 5| Step: 8
Training loss: 2.536886215209961
Validation loss: 2.446641222123177

Epoch: 5| Step: 9
Training loss: 2.3082687854766846
Validation loss: 2.4494503787768784

Epoch: 5| Step: 10
Training loss: 2.675551176071167
Validation loss: 2.4478638402877317

Epoch: 78| Step: 0
Training loss: 2.976215124130249
Validation loss: 2.453236932395607

Epoch: 5| Step: 1
Training loss: 2.813997745513916
Validation loss: 2.4513812372761388

Epoch: 5| Step: 2
Training loss: 3.0393946170806885
Validation loss: 2.4573871063929733

Epoch: 5| Step: 3
Training loss: 3.3109664916992188
Validation loss: 2.4534574836812992

Epoch: 5| Step: 4
Training loss: 2.4722399711608887
Validation loss: 2.4543961709545505

Epoch: 5| Step: 5
Training loss: 2.3630001544952393
Validation loss: 2.451742454241681

Epoch: 5| Step: 6
Training loss: 2.4710278511047363
Validation loss: 2.454575515562488

Epoch: 5| Step: 7
Training loss: 2.6878905296325684
Validation loss: 2.4481781298114407

Epoch: 5| Step: 8
Training loss: 2.364152193069458
Validation loss: 2.441610638813306

Epoch: 5| Step: 9
Training loss: 2.240316390991211
Validation loss: 2.4437136227084744

Epoch: 5| Step: 10
Training loss: 2.662182331085205
Validation loss: 2.451721501606767

Epoch: 79| Step: 0
Training loss: 3.0703673362731934
Validation loss: 2.4435547808165192

Epoch: 5| Step: 1
Training loss: 2.368208408355713
Validation loss: 2.4520862589600267

Epoch: 5| Step: 2
Training loss: 2.8385589122772217
Validation loss: 2.4491625088517384

Epoch: 5| Step: 3
Training loss: 2.284238338470459
Validation loss: 2.4564558588048464

Epoch: 5| Step: 4
Training loss: 2.959782123565674
Validation loss: 2.453221074996456

Epoch: 5| Step: 5
Training loss: 3.0125739574432373
Validation loss: 2.455154444581719

Epoch: 5| Step: 6
Training loss: 2.9359140396118164
Validation loss: 2.4502460930937078

Epoch: 5| Step: 7
Training loss: 2.3264074325561523
Validation loss: 2.451086210948165

Epoch: 5| Step: 8
Training loss: 2.5976459980010986
Validation loss: 2.4565684257015103

Epoch: 5| Step: 9
Training loss: 2.3566155433654785
Validation loss: 2.4522369446293

Epoch: 5| Step: 10
Training loss: 2.629897356033325
Validation loss: 2.4542642101164787

Epoch: 80| Step: 0
Training loss: 2.468050479888916
Validation loss: 2.442053948679278

Epoch: 5| Step: 1
Training loss: 2.845276355743408
Validation loss: 2.4457619279943486

Epoch: 5| Step: 2
Training loss: 2.2979912757873535
Validation loss: 2.4411739354492514

Epoch: 5| Step: 3
Training loss: 2.980985403060913
Validation loss: 2.4364339972055085

Epoch: 5| Step: 4
Training loss: 3.4007911682128906
Validation loss: 2.4399323001984627

Epoch: 5| Step: 5
Training loss: 2.358060598373413
Validation loss: 2.4392668508714244

Epoch: 5| Step: 6
Training loss: 2.7123608589172363
Validation loss: 2.443149733287032

Epoch: 5| Step: 7
Training loss: 2.921023368835449
Validation loss: 2.4390469751050396

Epoch: 5| Step: 8
Training loss: 2.6029725074768066
Validation loss: 2.4377721278898177

Epoch: 5| Step: 9
Training loss: 2.465623378753662
Validation loss: 2.4440590412386003

Epoch: 5| Step: 10
Training loss: 2.208075761795044
Validation loss: 2.4427609110391266

Epoch: 81| Step: 0
Training loss: 2.3273911476135254
Validation loss: 2.454069706701463

Epoch: 5| Step: 1
Training loss: 2.336350917816162
Validation loss: 2.4555751508282078

Epoch: 5| Step: 2
Training loss: 2.7635366916656494
Validation loss: 2.4629365398037817

Epoch: 5| Step: 3
Training loss: 3.1743004322052
Validation loss: 2.4803734722957818

Epoch: 5| Step: 4
Training loss: 2.4341812133789062
Validation loss: 2.4894070856032835

Epoch: 5| Step: 5
Training loss: 2.620837450027466
Validation loss: 2.4842961962505052

Epoch: 5| Step: 6
Training loss: 3.7149786949157715
Validation loss: 2.4814129337187736

Epoch: 5| Step: 7
Training loss: 2.41943621635437
Validation loss: 2.4775883895094677

Epoch: 5| Step: 8
Training loss: 2.235870122909546
Validation loss: 2.456645709212108

Epoch: 5| Step: 9
Training loss: 2.4715981483459473
Validation loss: 2.447868808623283

Epoch: 5| Step: 10
Training loss: 2.7564382553100586
Validation loss: 2.438545011704968

Epoch: 82| Step: 0
Training loss: 2.349691867828369
Validation loss: 2.4459236104001283

Epoch: 5| Step: 1
Training loss: 2.9762494564056396
Validation loss: 2.4482405031881025

Epoch: 5| Step: 2
Training loss: 2.421445369720459
Validation loss: 2.441796552750372

Epoch: 5| Step: 3
Training loss: 2.125443696975708
Validation loss: 2.442611466171921

Epoch: 5| Step: 4
Training loss: 2.990469217300415
Validation loss: 2.4334399982165267

Epoch: 5| Step: 5
Training loss: 3.302492141723633
Validation loss: 2.433092765910651

Epoch: 5| Step: 6
Training loss: 3.0331263542175293
Validation loss: 2.434006529469644

Epoch: 5| Step: 7
Training loss: 2.365029811859131
Validation loss: 2.427815491153348

Epoch: 5| Step: 8
Training loss: 2.6426939964294434
Validation loss: 2.4281694812159382

Epoch: 5| Step: 9
Training loss: 2.666672706604004
Validation loss: 2.4321173724307807

Epoch: 5| Step: 10
Training loss: 2.388212203979492
Validation loss: 2.4309237798055015

Epoch: 83| Step: 0
Training loss: 2.6639211177825928
Validation loss: 2.4310724017440632

Epoch: 5| Step: 1
Training loss: 3.28169584274292
Validation loss: 2.4336786552142073

Epoch: 5| Step: 2
Training loss: 3.7000975608825684
Validation loss: 2.430072174277357

Epoch: 5| Step: 3
Training loss: 2.6145119667053223
Validation loss: 2.443518248937463

Epoch: 5| Step: 4
Training loss: 2.0029053688049316
Validation loss: 2.440320594336397

Epoch: 5| Step: 5
Training loss: 2.4003779888153076
Validation loss: 2.443794523516009

Epoch: 5| Step: 6
Training loss: 2.874387264251709
Validation loss: 2.463006688702491

Epoch: 5| Step: 7
Training loss: 2.6704750061035156
Validation loss: 2.468827406565348

Epoch: 5| Step: 8
Training loss: 1.9759418964385986
Validation loss: 2.467206803701257

Epoch: 5| Step: 9
Training loss: 2.8563849925994873
Validation loss: 2.4666104111620175

Epoch: 5| Step: 10
Training loss: 2.239856004714966
Validation loss: 2.4514923890431723

Epoch: 84| Step: 0
Training loss: 2.854645252227783
Validation loss: 2.443500006070701

Epoch: 5| Step: 1
Training loss: 2.4015557765960693
Validation loss: 2.438336323666316

Epoch: 5| Step: 2
Training loss: 2.69205904006958
Validation loss: 2.435972782873338

Epoch: 5| Step: 3
Training loss: 2.9564476013183594
Validation loss: 2.431807307786839

Epoch: 5| Step: 4
Training loss: 2.5836291313171387
Validation loss: 2.4301166842060704

Epoch: 5| Step: 5
Training loss: 2.4743614196777344
Validation loss: 2.438777777456468

Epoch: 5| Step: 6
Training loss: 3.2449653148651123
Validation loss: 2.438387473424276

Epoch: 5| Step: 7
Training loss: 2.4322509765625
Validation loss: 2.4396646202251477

Epoch: 5| Step: 8
Training loss: 2.5503687858581543
Validation loss: 2.4386378103686916

Epoch: 5| Step: 9
Training loss: 1.8407621383666992
Validation loss: 2.44777012384066

Epoch: 5| Step: 10
Training loss: 3.3425605297088623
Validation loss: 2.4489185412724814

Epoch: 85| Step: 0
Training loss: 2.262420892715454
Validation loss: 2.464778079781481

Epoch: 5| Step: 1
Training loss: 2.040668249130249
Validation loss: 2.4716527667096866

Epoch: 5| Step: 2
Training loss: 2.677229642868042
Validation loss: 2.465054573551301

Epoch: 5| Step: 3
Training loss: 3.281625747680664
Validation loss: 2.4597702974914224

Epoch: 5| Step: 4
Training loss: 2.119582414627075
Validation loss: 2.4596678672298307

Epoch: 5| Step: 5
Training loss: 2.8887276649475098
Validation loss: 2.4562626743829377

Epoch: 5| Step: 6
Training loss: 2.854438066482544
Validation loss: 2.4416811132943756

Epoch: 5| Step: 7
Training loss: 2.6295933723449707
Validation loss: 2.437016915249568

Epoch: 5| Step: 8
Training loss: 3.0939762592315674
Validation loss: 2.434170353797174

Epoch: 5| Step: 9
Training loss: 2.5863349437713623
Validation loss: 2.4270779932698896

Epoch: 5| Step: 10
Training loss: 2.9155359268188477
Validation loss: 2.421247895045947

Epoch: 86| Step: 0
Training loss: 2.403778553009033
Validation loss: 2.4189221679523425

Epoch: 5| Step: 1
Training loss: 3.4713127613067627
Validation loss: 2.422071058263061

Epoch: 5| Step: 2
Training loss: 1.5945066213607788
Validation loss: 2.418145728367631

Epoch: 5| Step: 3
Training loss: 2.4352729320526123
Validation loss: 2.4224263596278366

Epoch: 5| Step: 4
Training loss: 2.445549964904785
Validation loss: 2.4267186669893164

Epoch: 5| Step: 5
Training loss: 3.003704786300659
Validation loss: 2.42525226582763

Epoch: 5| Step: 6
Training loss: 3.3551783561706543
Validation loss: 2.438515647765129

Epoch: 5| Step: 7
Training loss: 2.8596367835998535
Validation loss: 2.4386020911637174

Epoch: 5| Step: 8
Training loss: 2.8854126930236816
Validation loss: 2.439611998937463

Epoch: 5| Step: 9
Training loss: 2.176732063293457
Validation loss: 2.4426851785311134

Epoch: 5| Step: 10
Training loss: 2.6344738006591797
Validation loss: 2.4446019049613708

Epoch: 87| Step: 0
Training loss: 2.350170135498047
Validation loss: 2.4420980099708802

Epoch: 5| Step: 1
Training loss: 2.6767704486846924
Validation loss: 2.4402534820700206

Epoch: 5| Step: 2
Training loss: 2.905738353729248
Validation loss: 2.4337558156700543

Epoch: 5| Step: 3
Training loss: 2.6298348903656006
Validation loss: 2.4211773257101736

Epoch: 5| Step: 4
Training loss: 2.314138889312744
Validation loss: 2.4236903831522953

Epoch: 5| Step: 5
Training loss: 2.79772686958313
Validation loss: 2.418508116916944

Epoch: 5| Step: 6
Training loss: 2.8847899436950684
Validation loss: 2.4189584819219445

Epoch: 5| Step: 7
Training loss: 2.9481654167175293
Validation loss: 2.415100371965798

Epoch: 5| Step: 8
Training loss: 2.460526704788208
Validation loss: 2.417801446812127

Epoch: 5| Step: 9
Training loss: 2.993276596069336
Validation loss: 2.418570133947557

Epoch: 5| Step: 10
Training loss: 2.1480698585510254
Validation loss: 2.415844537878549

Epoch: 88| Step: 0
Training loss: 2.853976011276245
Validation loss: 2.4156686490581882

Epoch: 5| Step: 1
Training loss: 3.021533489227295
Validation loss: 2.415246111090465

Epoch: 5| Step: 2
Training loss: 2.6268887519836426
Validation loss: 2.4146744153832875

Epoch: 5| Step: 3
Training loss: 2.6706490516662598
Validation loss: 2.4139787471422585

Epoch: 5| Step: 4
Training loss: 2.2995309829711914
Validation loss: 2.415475037790114

Epoch: 5| Step: 5
Training loss: 2.233692169189453
Validation loss: 2.417593394556353

Epoch: 5| Step: 6
Training loss: 2.763904571533203
Validation loss: 2.4157179914494997

Epoch: 5| Step: 7
Training loss: 3.0696494579315186
Validation loss: 2.4146246064093804

Epoch: 5| Step: 8
Training loss: 2.719858169555664
Validation loss: 2.418656249200144

Epoch: 5| Step: 9
Training loss: 2.340668201446533
Validation loss: 2.414784974949334

Epoch: 5| Step: 10
Training loss: 2.633185386657715
Validation loss: 2.4203179523509037

Epoch: 89| Step: 0
Training loss: 2.530264377593994
Validation loss: 2.428985949485533

Epoch: 5| Step: 1
Training loss: 2.353353977203369
Validation loss: 2.440802671576059

Epoch: 5| Step: 2
Training loss: 3.4221243858337402
Validation loss: 2.449359445161717

Epoch: 5| Step: 3
Training loss: 2.941755771636963
Validation loss: 2.451795244729647

Epoch: 5| Step: 4
Training loss: 2.073983669281006
Validation loss: 2.445332375905847

Epoch: 5| Step: 5
Training loss: 2.3231661319732666
Validation loss: 2.4454045141896894

Epoch: 5| Step: 6
Training loss: 2.3404107093811035
Validation loss: 2.448493988283219

Epoch: 5| Step: 7
Training loss: 2.511970043182373
Validation loss: 2.4458205699920654

Epoch: 5| Step: 8
Training loss: 2.990692377090454
Validation loss: 2.447469416485038

Epoch: 5| Step: 9
Training loss: 2.986908435821533
Validation loss: 2.4503057541385775

Epoch: 5| Step: 10
Training loss: 2.7367002964019775
Validation loss: 2.432127070683305

Epoch: 90| Step: 0
Training loss: 3.6175529956817627
Validation loss: 2.429501582217473

Epoch: 5| Step: 1
Training loss: 2.764268398284912
Validation loss: 2.419375006870557

Epoch: 5| Step: 2
Training loss: 2.655025005340576
Validation loss: 2.418143892800936

Epoch: 5| Step: 3
Training loss: 2.7979893684387207
Validation loss: 2.4176109401128625

Epoch: 5| Step: 4
Training loss: 2.4694952964782715
Validation loss: 2.4169039572438886

Epoch: 5| Step: 5
Training loss: 2.895000696182251
Validation loss: 2.419005188890683

Epoch: 5| Step: 6
Training loss: 2.7226600646972656
Validation loss: 2.410466568444365

Epoch: 5| Step: 7
Training loss: 1.9248034954071045
Validation loss: 2.4097733625801663

Epoch: 5| Step: 8
Training loss: 3.175414562225342
Validation loss: 2.405698650626726

Epoch: 5| Step: 9
Training loss: 1.6276590824127197
Validation loss: 2.4086080212746896

Epoch: 5| Step: 10
Training loss: 2.5148115158081055
Validation loss: 2.406504358014753

Epoch: 91| Step: 0
Training loss: 2.5353806018829346
Validation loss: 2.417672562342818

Epoch: 5| Step: 1
Training loss: 2.3679795265197754
Validation loss: 2.4245100175180743

Epoch: 5| Step: 2
Training loss: 3.2339236736297607
Validation loss: 2.435419044186992

Epoch: 5| Step: 3
Training loss: 2.8842709064483643
Validation loss: 2.449667510165963

Epoch: 5| Step: 4
Training loss: 2.7467474937438965
Validation loss: 2.4453532311224166

Epoch: 5| Step: 5
Training loss: 2.669980525970459
Validation loss: 2.420510002361831

Epoch: 5| Step: 6
Training loss: 2.4220852851867676
Validation loss: 2.4179794967815442

Epoch: 5| Step: 7
Training loss: 2.8339061737060547
Validation loss: 2.4192387903890302

Epoch: 5| Step: 8
Training loss: 2.4423248767852783
Validation loss: 2.4222102677950295

Epoch: 5| Step: 9
Training loss: 2.1530275344848633
Validation loss: 2.4293309206603677

Epoch: 5| Step: 10
Training loss: 2.9071991443634033
Validation loss: 2.4368907815666607

Epoch: 92| Step: 0
Training loss: 2.0710935592651367
Validation loss: 2.4465426501407417

Epoch: 5| Step: 1
Training loss: 2.5937983989715576
Validation loss: 2.4492490650505148

Epoch: 5| Step: 2
Training loss: 2.1257777214050293
Validation loss: 2.440878014410696

Epoch: 5| Step: 3
Training loss: 2.9043986797332764
Validation loss: 2.423256561320315

Epoch: 5| Step: 4
Training loss: 3.591416120529175
Validation loss: 2.4273725273788616

Epoch: 5| Step: 5
Training loss: 2.7920517921447754
Validation loss: 2.4202814512355353

Epoch: 5| Step: 6
Training loss: 2.561241388320923
Validation loss: 2.4211227304192

Epoch: 5| Step: 7
Training loss: 3.055626392364502
Validation loss: 2.424624178999214

Epoch: 5| Step: 8
Training loss: 3.407128095626831
Validation loss: 2.424709630268876

Epoch: 5| Step: 9
Training loss: 1.7243818044662476
Validation loss: 2.431188693610571

Epoch: 5| Step: 10
Training loss: 2.3380587100982666
Validation loss: 2.424454096824892

Epoch: 93| Step: 0
Training loss: 2.533304214477539
Validation loss: 2.41844113667806

Epoch: 5| Step: 1
Training loss: 2.597764492034912
Validation loss: 2.422896239065355

Epoch: 5| Step: 2
Training loss: 2.254666566848755
Validation loss: 2.4178060382925053

Epoch: 5| Step: 3
Training loss: 2.275547504425049
Validation loss: 2.4199724838297856

Epoch: 5| Step: 4
Training loss: 2.6254982948303223
Validation loss: 2.417917507950978

Epoch: 5| Step: 5
Training loss: 3.524862289428711
Validation loss: 2.42069492032451

Epoch: 5| Step: 6
Training loss: 2.538621187210083
Validation loss: 2.4302001204541934

Epoch: 5| Step: 7
Training loss: 2.374342441558838
Validation loss: 2.4192622579554075

Epoch: 5| Step: 8
Training loss: 2.984382152557373
Validation loss: 2.4136416014804634

Epoch: 5| Step: 9
Training loss: 2.253946304321289
Validation loss: 2.4128113254424064

Epoch: 5| Step: 10
Training loss: 3.240384340286255
Validation loss: 2.4112925811480452

Epoch: 94| Step: 0
Training loss: 3.293024778366089
Validation loss: 2.4026329209727626

Epoch: 5| Step: 1
Training loss: 2.627796173095703
Validation loss: 2.4047522852497716

Epoch: 5| Step: 2
Training loss: 2.743551731109619
Validation loss: 2.405346555094565

Epoch: 5| Step: 3
Training loss: 2.552145481109619
Validation loss: 2.4078623376866823

Epoch: 5| Step: 4
Training loss: 2.7637219429016113
Validation loss: 2.41086648612894

Epoch: 5| Step: 5
Training loss: 2.864083766937256
Validation loss: 2.4124956541163947

Epoch: 5| Step: 6
Training loss: 2.1481664180755615
Validation loss: 2.4090421815072336

Epoch: 5| Step: 7
Training loss: 2.6417670249938965
Validation loss: 2.4179899871990247

Epoch: 5| Step: 8
Training loss: 2.1359317302703857
Validation loss: 2.4233023248692995

Epoch: 5| Step: 9
Training loss: 2.66774845123291
Validation loss: 2.4221632198620866

Epoch: 5| Step: 10
Training loss: 2.699127197265625
Validation loss: 2.4261475891195317

Epoch: 95| Step: 0
Training loss: 2.724412441253662
Validation loss: 2.423123518625895

Epoch: 5| Step: 1
Training loss: 2.7254703044891357
Validation loss: 2.4291013902233494

Epoch: 5| Step: 2
Training loss: 2.9314889907836914
Validation loss: 2.428526693774808

Epoch: 5| Step: 3
Training loss: 2.590974807739258
Validation loss: 2.4196810747987483

Epoch: 5| Step: 4
Training loss: 2.313594341278076
Validation loss: 2.4078861231444986

Epoch: 5| Step: 5
Training loss: 2.6483147144317627
Validation loss: 2.408011314689472

Epoch: 5| Step: 6
Training loss: 2.4124107360839844
Validation loss: 2.41390323638916

Epoch: 5| Step: 7
Training loss: 2.9377832412719727
Validation loss: 2.406571603590442

Epoch: 5| Step: 8
Training loss: 2.395576000213623
Validation loss: 2.403200122617906

Epoch: 5| Step: 9
Training loss: 2.6041550636291504
Validation loss: 2.406487662305114

Epoch: 5| Step: 10
Training loss: 2.8630683422088623
Validation loss: 2.411022142697406

Epoch: 96| Step: 0
Training loss: 2.5244688987731934
Validation loss: 2.407941567000522

Epoch: 5| Step: 1
Training loss: 2.583615779876709
Validation loss: 2.4191185684614283

Epoch: 5| Step: 2
Training loss: 2.5340263843536377
Validation loss: 2.4203911212182816

Epoch: 5| Step: 3
Training loss: 2.8795716762542725
Validation loss: 2.425968813639815

Epoch: 5| Step: 4
Training loss: 2.7388107776641846
Validation loss: 2.4298609789981636

Epoch: 5| Step: 5
Training loss: 2.343888998031616
Validation loss: 2.4437703612030193

Epoch: 5| Step: 6
Training loss: 2.7538702487945557
Validation loss: 2.4605005453991633

Epoch: 5| Step: 7
Training loss: 2.735063076019287
Validation loss: 2.471444163271176

Epoch: 5| Step: 8
Training loss: 2.558755397796631
Validation loss: 2.4646809049831924

Epoch: 5| Step: 9
Training loss: 2.219146966934204
Validation loss: 2.443842262350103

Epoch: 5| Step: 10
Training loss: 3.4346442222595215
Validation loss: 2.4201313910945768

Epoch: 97| Step: 0
Training loss: 2.41261625289917
Validation loss: 2.4118639371728383

Epoch: 5| Step: 1
Training loss: 2.947694778442383
Validation loss: 2.4054952590696272

Epoch: 5| Step: 2
Training loss: 2.0470986366271973
Validation loss: 2.4025990988618586

Epoch: 5| Step: 3
Training loss: 2.436760187149048
Validation loss: 2.4075257060348347

Epoch: 5| Step: 4
Training loss: 2.849139928817749
Validation loss: 2.408102276504681

Epoch: 5| Step: 5
Training loss: 2.817138671875
Validation loss: 2.416555740500009

Epoch: 5| Step: 6
Training loss: 2.8577306270599365
Validation loss: 2.422696618623631

Epoch: 5| Step: 7
Training loss: 3.5152480602264404
Validation loss: 2.4261703798847813

Epoch: 5| Step: 8
Training loss: 2.362316608428955
Validation loss: 2.430997017891176

Epoch: 5| Step: 9
Training loss: 2.5269577503204346
Validation loss: 2.4318041545088573

Epoch: 5| Step: 10
Training loss: 2.4338884353637695
Validation loss: 2.439487712357634

Epoch: 98| Step: 0
Training loss: 2.766353130340576
Validation loss: 2.4254401165951966

Epoch: 5| Step: 1
Training loss: 2.317188262939453
Validation loss: 2.4353354900113997

Epoch: 5| Step: 2
Training loss: 2.9094626903533936
Validation loss: 2.4328099604575866

Epoch: 5| Step: 3
Training loss: 2.755145311355591
Validation loss: 2.429220107293898

Epoch: 5| Step: 4
Training loss: 2.953519105911255
Validation loss: 2.4341747760772705

Epoch: 5| Step: 5
Training loss: 3.0998599529266357
Validation loss: 2.441877631730931

Epoch: 5| Step: 6
Training loss: 2.8237571716308594
Validation loss: 2.427878459294637

Epoch: 5| Step: 7
Training loss: 2.6426520347595215
Validation loss: 2.430271115354312

Epoch: 5| Step: 8
Training loss: 2.145928144454956
Validation loss: 2.420448577532204

Epoch: 5| Step: 9
Training loss: 2.247438430786133
Validation loss: 2.4138103377434517

Epoch: 5| Step: 10
Training loss: 2.3584024906158447
Validation loss: 2.4142094632630706

Epoch: 99| Step: 0
Training loss: 2.6513915061950684
Validation loss: 2.424619916946657

Epoch: 5| Step: 1
Training loss: 2.4887547492980957
Validation loss: 2.4279597523391887

Epoch: 5| Step: 2
Training loss: 2.519200563430786
Validation loss: 2.435304408432335

Epoch: 5| Step: 3
Training loss: 2.2483768463134766
Validation loss: 2.459485012997863

Epoch: 5| Step: 4
Training loss: 2.3550381660461426
Validation loss: 2.4668365704116

Epoch: 5| Step: 5
Training loss: 2.486304521560669
Validation loss: 2.4528172400689896

Epoch: 5| Step: 6
Training loss: 2.8219971656799316
Validation loss: 2.427849510664581

Epoch: 5| Step: 7
Training loss: 2.532494068145752
Validation loss: 2.429510224250055

Epoch: 5| Step: 8
Training loss: 3.469923734664917
Validation loss: 2.410492868833644

Epoch: 5| Step: 9
Training loss: 1.9331495761871338
Validation loss: 2.407980631756526

Epoch: 5| Step: 10
Training loss: 3.643495798110962
Validation loss: 2.399432518148935

Epoch: 100| Step: 0
Training loss: 3.1118197441101074
Validation loss: 2.392544836126348

Epoch: 5| Step: 1
Training loss: 1.7366241216659546
Validation loss: 2.3963558443130983

Epoch: 5| Step: 2
Training loss: 1.7683963775634766
Validation loss: 2.3935107466995076

Epoch: 5| Step: 3
Training loss: 2.6469459533691406
Validation loss: 2.396157190363894

Epoch: 5| Step: 4
Training loss: 3.237968921661377
Validation loss: 2.3930248060534076

Epoch: 5| Step: 5
Training loss: 2.777726650238037
Validation loss: 2.3979384181320027

Epoch: 5| Step: 6
Training loss: 2.7053675651550293
Validation loss: 2.39338497448993

Epoch: 5| Step: 7
Training loss: 3.0127041339874268
Validation loss: 2.395415457346106

Epoch: 5| Step: 8
Training loss: 2.630028486251831
Validation loss: 2.398543224539808

Epoch: 5| Step: 9
Training loss: 2.6073174476623535
Validation loss: 2.396734704253494

Epoch: 5| Step: 10
Training loss: 2.8913562297821045
Validation loss: 2.4023819123545

Epoch: 101| Step: 0
Training loss: 2.9920475482940674
Validation loss: 2.403818198429641

Epoch: 5| Step: 1
Training loss: 2.4991092681884766
Validation loss: 2.4034603795697613

Epoch: 5| Step: 2
Training loss: 3.1380789279937744
Validation loss: 2.407216400228521

Epoch: 5| Step: 3
Training loss: 2.5360841751098633
Validation loss: 2.4103428907291864

Epoch: 5| Step: 4
Training loss: 2.145566701889038
Validation loss: 2.400532107199392

Epoch: 5| Step: 5
Training loss: 3.1309597492218018
Validation loss: 2.396103351346908

Epoch: 5| Step: 6
Training loss: 2.3955581188201904
Validation loss: 2.3934433844781693

Epoch: 5| Step: 7
Training loss: 2.3508543968200684
Validation loss: 2.393290101840932

Epoch: 5| Step: 8
Training loss: 3.211322069168091
Validation loss: 2.3973179042980237

Epoch: 5| Step: 9
Training loss: 2.187302827835083
Validation loss: 2.39749994585591

Epoch: 5| Step: 10
Training loss: 2.431596279144287
Validation loss: 2.3933508729421966

Epoch: 102| Step: 0
Training loss: 2.9266364574432373
Validation loss: 2.3932225422192643

Epoch: 5| Step: 1
Training loss: 3.183502435684204
Validation loss: 2.3957439032934045

Epoch: 5| Step: 2
Training loss: 2.0110042095184326
Validation loss: 2.3953951763850387

Epoch: 5| Step: 3
Training loss: 2.024793863296509
Validation loss: 2.3986206926325315

Epoch: 5| Step: 4
Training loss: 3.0901472568511963
Validation loss: 2.394657399064751

Epoch: 5| Step: 5
Training loss: 2.845848560333252
Validation loss: 2.3986311548499653

Epoch: 5| Step: 6
Training loss: 3.202468156814575
Validation loss: 2.4085037041735906

Epoch: 5| Step: 7
Training loss: 2.636845827102661
Validation loss: 2.411238642149074

Epoch: 5| Step: 8
Training loss: 2.3996150493621826
Validation loss: 2.411503968700286

Epoch: 5| Step: 9
Training loss: 2.193380832672119
Validation loss: 2.401469620325232

Epoch: 5| Step: 10
Training loss: 2.3623263835906982
Validation loss: 2.39886732767987

Epoch: 103| Step: 0
Training loss: 2.880270004272461
Validation loss: 2.392516577115623

Epoch: 5| Step: 1
Training loss: 2.4608311653137207
Validation loss: 2.4014266921627905

Epoch: 5| Step: 2
Training loss: 2.4146647453308105
Validation loss: 2.397557120169363

Epoch: 5| Step: 3
Training loss: 3.4194893836975098
Validation loss: 2.406465712413993

Epoch: 5| Step: 4
Training loss: 2.68668794631958
Validation loss: 2.409029596595354

Epoch: 5| Step: 5
Training loss: 2.1801371574401855
Validation loss: 2.4122648008408083

Epoch: 5| Step: 6
Training loss: 2.3780570030212402
Validation loss: 2.4124264383828766

Epoch: 5| Step: 7
Training loss: 3.2485244274139404
Validation loss: 2.420176559878934

Epoch: 5| Step: 8
Training loss: 2.416121482849121
Validation loss: 2.4149787477267686

Epoch: 5| Step: 9
Training loss: 2.0661826133728027
Validation loss: 2.413775569649153

Epoch: 5| Step: 10
Training loss: 2.8134801387786865
Validation loss: 2.4056854453138126

Epoch: 104| Step: 0
Training loss: 3.4980034828186035
Validation loss: 2.4038884742285616

Epoch: 5| Step: 1
Training loss: 2.8811488151550293
Validation loss: 2.407498936499319

Epoch: 5| Step: 2
Training loss: 2.1513190269470215
Validation loss: 2.4026426294798493

Epoch: 5| Step: 3
Training loss: 3.0514519214630127
Validation loss: 2.4114902122046358

Epoch: 5| Step: 4
Training loss: 2.772066116333008
Validation loss: 2.4157410360151723

Epoch: 5| Step: 5
Training loss: 2.301024913787842
Validation loss: 2.417649708768373

Epoch: 5| Step: 6
Training loss: 2.764838933944702
Validation loss: 2.422891655275899

Epoch: 5| Step: 7
Training loss: 2.3922295570373535
Validation loss: 2.4266302508692585

Epoch: 5| Step: 8
Training loss: 2.431880474090576
Validation loss: 2.420755035133772

Epoch: 5| Step: 9
Training loss: 2.7238974571228027
Validation loss: 2.4285891184242825

Epoch: 5| Step: 10
Training loss: 1.8390973806381226
Validation loss: 2.4180787481287473

Epoch: 105| Step: 0
Training loss: 2.809886932373047
Validation loss: 2.4158831488701606

Epoch: 5| Step: 1
Training loss: 3.2772083282470703
Validation loss: 2.4121211805651264

Epoch: 5| Step: 2
Training loss: 1.976625680923462
Validation loss: 2.4210384840606363

Epoch: 5| Step: 3
Training loss: 2.545114278793335
Validation loss: 2.44096419888158

Epoch: 5| Step: 4
Training loss: 2.4210522174835205
Validation loss: 2.4315267660284556

Epoch: 5| Step: 5
Training loss: 2.680102825164795
Validation loss: 2.4205029241500364

Epoch: 5| Step: 6
Training loss: 2.9179940223693848
Validation loss: 2.4279092358004664

Epoch: 5| Step: 7
Training loss: 2.809904098510742
Validation loss: 2.414206652231114

Epoch: 5| Step: 8
Training loss: 2.7401719093322754
Validation loss: 2.407176381798201

Epoch: 5| Step: 9
Training loss: 2.349246025085449
Validation loss: 2.3985408826540877

Epoch: 5| Step: 10
Training loss: 2.2124483585357666
Validation loss: 2.392186282783426

Epoch: 106| Step: 0
Training loss: 2.4440534114837646
Validation loss: 2.3961580902017574

Epoch: 5| Step: 1
Training loss: 2.8228113651275635
Validation loss: 2.3872909058806715

Epoch: 5| Step: 2
Training loss: 2.5339808464050293
Validation loss: 2.385642713116061

Epoch: 5| Step: 3
Training loss: 2.982363224029541
Validation loss: 2.3918326465032433

Epoch: 5| Step: 4
Training loss: 2.2796618938446045
Validation loss: 2.3888028180727394

Epoch: 5| Step: 5
Training loss: 1.8826663494110107
Validation loss: 2.40102114728702

Epoch: 5| Step: 6
Training loss: 3.114168167114258
Validation loss: 2.404181803426435

Epoch: 5| Step: 7
Training loss: 2.705805778503418
Validation loss: 2.412319416640907

Epoch: 5| Step: 8
Training loss: 2.3644838333129883
Validation loss: 2.424786062650783

Epoch: 5| Step: 9
Training loss: 2.468585968017578
Validation loss: 2.4139552885486233

Epoch: 5| Step: 10
Training loss: 3.437868118286133
Validation loss: 2.408012431154969

Epoch: 107| Step: 0
Training loss: 2.567927837371826
Validation loss: 2.4061120376792005

Epoch: 5| Step: 1
Training loss: 2.4870493412017822
Validation loss: 2.39983989602776

Epoch: 5| Step: 2
Training loss: 2.439326047897339
Validation loss: 2.38727544969128

Epoch: 5| Step: 3
Training loss: 2.894324541091919
Validation loss: 2.3943885269985405

Epoch: 5| Step: 4
Training loss: 2.8555452823638916
Validation loss: 2.3930106098933885

Epoch: 5| Step: 5
Training loss: 2.4614293575286865
Validation loss: 2.385544246242892

Epoch: 5| Step: 6
Training loss: 2.865288257598877
Validation loss: 2.387605349222819

Epoch: 5| Step: 7
Training loss: 2.8791584968566895
Validation loss: 2.386286186915572

Epoch: 5| Step: 8
Training loss: 2.4190714359283447
Validation loss: 2.3884209073999876

Epoch: 5| Step: 9
Training loss: 2.444012403488159
Validation loss: 2.3944949411576792

Epoch: 5| Step: 10
Training loss: 2.484743595123291
Validation loss: 2.398529698771815

Epoch: 108| Step: 0
Training loss: 2.6586461067199707
Validation loss: 2.4029993831470446

Epoch: 5| Step: 1
Training loss: 3.1834425926208496
Validation loss: 2.40659140258707

Epoch: 5| Step: 2
Training loss: 3.212015151977539
Validation loss: 2.412117455595283

Epoch: 5| Step: 3
Training loss: 2.071782350540161
Validation loss: 2.4070755948302565

Epoch: 5| Step: 4
Training loss: 1.9034147262573242
Validation loss: 2.419015681871804

Epoch: 5| Step: 5
Training loss: 2.5875468254089355
Validation loss: 2.4176728981797413

Epoch: 5| Step: 6
Training loss: 3.0924198627471924
Validation loss: 2.42427566230938

Epoch: 5| Step: 7
Training loss: 2.7728159427642822
Validation loss: 2.4101641460131575

Epoch: 5| Step: 8
Training loss: 2.773369789123535
Validation loss: 2.4049080315456597

Epoch: 5| Step: 9
Training loss: 1.9578348398208618
Validation loss: 2.4009183760612243

Epoch: 5| Step: 10
Training loss: 2.6635074615478516
Validation loss: 2.399619763897311

Epoch: 109| Step: 0
Training loss: 2.358851671218872
Validation loss: 2.40175050304782

Epoch: 5| Step: 1
Training loss: 3.599180221557617
Validation loss: 2.401975021567396

Epoch: 5| Step: 2
Training loss: 2.8411200046539307
Validation loss: 2.3930344555967595

Epoch: 5| Step: 3
Training loss: 2.5678791999816895
Validation loss: 2.3931385804248113

Epoch: 5| Step: 4
Training loss: 2.51749587059021
Validation loss: 2.3971413822584253

Epoch: 5| Step: 5
Training loss: 2.3692660331726074
Validation loss: 2.4012714534677486

Epoch: 5| Step: 6
Training loss: 2.650660991668701
Validation loss: 2.395834881772277

Epoch: 5| Step: 7
Training loss: 3.3406853675842285
Validation loss: 2.4048786958058677

Epoch: 5| Step: 8
Training loss: 1.3055357933044434
Validation loss: 2.4073193547546223

Epoch: 5| Step: 9
Training loss: 2.579317808151245
Validation loss: 2.4061063694697555

Epoch: 5| Step: 10
Training loss: 2.6814167499542236
Validation loss: 2.396540459766183

Epoch: 110| Step: 0
Training loss: 3.100461006164551
Validation loss: 2.405080895270071

Epoch: 5| Step: 1
Training loss: 3.118645191192627
Validation loss: 2.399157685618247

Epoch: 5| Step: 2
Training loss: 2.6231772899627686
Validation loss: 2.3883096479600474

Epoch: 5| Step: 3
Training loss: 2.467986583709717
Validation loss: 2.392424529598605

Epoch: 5| Step: 4
Training loss: 2.280752420425415
Validation loss: 2.3926733386132026

Epoch: 5| Step: 5
Training loss: 2.098081588745117
Validation loss: 2.3943053855690906

Epoch: 5| Step: 6
Training loss: 2.32903790473938
Validation loss: 2.392587149015037

Epoch: 5| Step: 7
Training loss: 2.911367654800415
Validation loss: 2.3916700578504995

Epoch: 5| Step: 8
Training loss: 2.292534112930298
Validation loss: 2.396013347051477

Epoch: 5| Step: 9
Training loss: 2.6061863899230957
Validation loss: 2.3922774048261743

Epoch: 5| Step: 10
Training loss: 3.039872407913208
Validation loss: 2.4028624770461873

Epoch: 111| Step: 0
Training loss: 2.1978211402893066
Validation loss: 2.3985143989645024

Epoch: 5| Step: 1
Training loss: 2.7901511192321777
Validation loss: 2.398400893775366

Epoch: 5| Step: 2
Training loss: 2.5456607341766357
Validation loss: 2.397446160675377

Epoch: 5| Step: 3
Training loss: 3.4288182258605957
Validation loss: 2.395115654955628

Epoch: 5| Step: 4
Training loss: 3.0091781616210938
Validation loss: 2.401247178354571

Epoch: 5| Step: 5
Training loss: 2.552426815032959
Validation loss: 2.3934425346312986

Epoch: 5| Step: 6
Training loss: 2.653184652328491
Validation loss: 2.399974779416156

Epoch: 5| Step: 7
Training loss: 2.2818219661712646
Validation loss: 2.3986742522126887

Epoch: 5| Step: 8
Training loss: 2.508248805999756
Validation loss: 2.3955834193896224

Epoch: 5| Step: 9
Training loss: 2.165276288986206
Validation loss: 2.3919164980611494

Epoch: 5| Step: 10
Training loss: 2.608020544052124
Validation loss: 2.3965677240843415

Epoch: 112| Step: 0
Training loss: 2.586517095565796
Validation loss: 2.4015019427063646

Epoch: 5| Step: 1
Training loss: 3.148223876953125
Validation loss: 2.4036242038972917

Epoch: 5| Step: 2
Training loss: 2.6729397773742676
Validation loss: 2.404164280942691

Epoch: 5| Step: 3
Training loss: 2.6454594135284424
Validation loss: 2.4097552837864047

Epoch: 5| Step: 4
Training loss: 3.080853223800659
Validation loss: 2.4016144250028875

Epoch: 5| Step: 5
Training loss: 2.2832882404327393
Validation loss: 2.4063483720184653

Epoch: 5| Step: 6
Training loss: 2.156738042831421
Validation loss: 2.401998560915711

Epoch: 5| Step: 7
Training loss: 2.635344982147217
Validation loss: 2.4008703641994025

Epoch: 5| Step: 8
Training loss: 2.3839824199676514
Validation loss: 2.398916075306554

Epoch: 5| Step: 9
Training loss: 2.447819232940674
Validation loss: 2.400478950110815

Epoch: 5| Step: 10
Training loss: 2.6586403846740723
Validation loss: 2.3999854800521687

Epoch: 113| Step: 0
Training loss: 2.6394197940826416
Validation loss: 2.4079922860668552

Epoch: 5| Step: 1
Training loss: 3.2245891094207764
Validation loss: 2.409197420202276

Epoch: 5| Step: 2
Training loss: 2.2430176734924316
Validation loss: 2.402917697865476

Epoch: 5| Step: 3
Training loss: 2.319899797439575
Validation loss: 2.392899964445381

Epoch: 5| Step: 4
Training loss: 2.7121376991271973
Validation loss: 2.3938421587790213

Epoch: 5| Step: 5
Training loss: 2.5186285972595215
Validation loss: 2.3968924424981557

Epoch: 5| Step: 6
Training loss: 2.6873619556427
Validation loss: 2.3973577535280617

Epoch: 5| Step: 7
Training loss: 2.432690143585205
Validation loss: 2.3928636299666537

Epoch: 5| Step: 8
Training loss: 2.5867786407470703
Validation loss: 2.391353153413342

Epoch: 5| Step: 9
Training loss: 2.062182903289795
Validation loss: 2.3986396661368747

Epoch: 5| Step: 10
Training loss: 3.365097999572754
Validation loss: 2.392912082774665

Epoch: 114| Step: 0
Training loss: 2.7171101570129395
Validation loss: 2.402435710353236

Epoch: 5| Step: 1
Training loss: 2.614760398864746
Validation loss: 2.3995875286799606

Epoch: 5| Step: 2
Training loss: 2.6097183227539062
Validation loss: 2.404058858912478

Epoch: 5| Step: 3
Training loss: 2.6902756690979004
Validation loss: 2.3899914218533422

Epoch: 5| Step: 4
Training loss: 1.7918323278427124
Validation loss: 2.402807069081132

Epoch: 5| Step: 5
Training loss: 2.2916152477264404
Validation loss: 2.404137860062302

Epoch: 5| Step: 6
Training loss: 2.3667640686035156
Validation loss: 2.4100020598339778

Epoch: 5| Step: 7
Training loss: 2.5558884143829346
Validation loss: 2.402388390674386

Epoch: 5| Step: 8
Training loss: 3.883455276489258
Validation loss: 2.400733901608375

Epoch: 5| Step: 9
Training loss: 2.2895636558532715
Validation loss: 2.4062272938348914

Epoch: 5| Step: 10
Training loss: 2.959589958190918
Validation loss: 2.4014978998450824

Epoch: 115| Step: 0
Training loss: 3.2381348609924316
Validation loss: 2.398248621212539

Epoch: 5| Step: 1
Training loss: 2.2353463172912598
Validation loss: 2.391257204035277

Epoch: 5| Step: 2
Training loss: 3.0371322631835938
Validation loss: 2.3883360508949525

Epoch: 5| Step: 3
Training loss: 2.26094388961792
Validation loss: 2.385583116162208

Epoch: 5| Step: 4
Training loss: 2.744877338409424
Validation loss: 2.38929235294301

Epoch: 5| Step: 5
Training loss: 2.8605847358703613
Validation loss: 2.38671370731887

Epoch: 5| Step: 6
Training loss: 2.365647077560425
Validation loss: 2.3872349082782702

Epoch: 5| Step: 7
Training loss: 2.6895174980163574
Validation loss: 2.3953246352493123

Epoch: 5| Step: 8
Training loss: 2.337631940841675
Validation loss: 2.395956734175323

Epoch: 5| Step: 9
Training loss: 2.5221786499023438
Validation loss: 2.4009857459734847

Epoch: 5| Step: 10
Training loss: 2.345726251602173
Validation loss: 2.393815876335226

Epoch: 116| Step: 0
Training loss: 2.8272523880004883
Validation loss: 2.3958601413234586

Epoch: 5| Step: 1
Training loss: 2.4564898014068604
Validation loss: 2.3841892750032487

Epoch: 5| Step: 2
Training loss: 3.0580625534057617
Validation loss: 2.3864250644560783

Epoch: 5| Step: 3
Training loss: 2.512989044189453
Validation loss: 2.3787064039579002

Epoch: 5| Step: 4
Training loss: 2.7934536933898926
Validation loss: 2.3788570434816423

Epoch: 5| Step: 5
Training loss: 2.6055097579956055
Validation loss: 2.372842393895631

Epoch: 5| Step: 6
Training loss: 2.1883935928344727
Validation loss: 2.366691748301188

Epoch: 5| Step: 7
Training loss: 2.6365737915039062
Validation loss: 2.3686205417879167

Epoch: 5| Step: 8
Training loss: 2.1958165168762207
Validation loss: 2.367923213589576

Epoch: 5| Step: 9
Training loss: 2.6573281288146973
Validation loss: 2.3610467346765662

Epoch: 5| Step: 10
Training loss: 2.755647897720337
Validation loss: 2.365087580937211

Epoch: 117| Step: 0
Training loss: 2.7078402042388916
Validation loss: 2.3664738311562488

Epoch: 5| Step: 1
Training loss: 2.770097017288208
Validation loss: 2.365309456343292

Epoch: 5| Step: 2
Training loss: 2.886672258377075
Validation loss: 2.359610783156528

Epoch: 5| Step: 3
Training loss: 2.4795806407928467
Validation loss: 2.3635425054898827

Epoch: 5| Step: 4
Training loss: 2.6323394775390625
Validation loss: 2.3780498555911485

Epoch: 5| Step: 5
Training loss: 2.2859625816345215
Validation loss: 2.3870882065065446

Epoch: 5| Step: 6
Training loss: 3.031564950942993
Validation loss: 2.4026441317732616

Epoch: 5| Step: 7
Training loss: 2.444112539291382
Validation loss: 2.406185427019673

Epoch: 5| Step: 8
Training loss: 2.2838051319122314
Validation loss: 2.4102480821712042

Epoch: 5| Step: 9
Training loss: 2.44504451751709
Validation loss: 2.413331001035629

Epoch: 5| Step: 10
Training loss: 2.644791603088379
Validation loss: 2.4095384997706257

Epoch: 118| Step: 0
Training loss: 2.407027006149292
Validation loss: 2.4136496282392934

Epoch: 5| Step: 1
Training loss: 2.8139431476593018
Validation loss: 2.399098978247694

Epoch: 5| Step: 2
Training loss: 2.4559144973754883
Validation loss: 2.3960945247322

Epoch: 5| Step: 3
Training loss: 2.151580333709717
Validation loss: 2.392949709328272

Epoch: 5| Step: 4
Training loss: 2.6319034099578857
Validation loss: 2.3899768321744856

Epoch: 5| Step: 5
Training loss: 2.2223286628723145
Validation loss: 2.3850635431146108

Epoch: 5| Step: 6
Training loss: 3.1121902465820312
Validation loss: 2.3749894121641755

Epoch: 5| Step: 7
Training loss: 2.5842533111572266
Validation loss: 2.374508947454473

Epoch: 5| Step: 8
Training loss: 2.697988986968994
Validation loss: 2.381142859817833

Epoch: 5| Step: 9
Training loss: 2.5508265495300293
Validation loss: 2.37512307782327

Epoch: 5| Step: 10
Training loss: 3.0424575805664062
Validation loss: 2.3788467991736626

Epoch: 119| Step: 0
Training loss: 2.756366729736328
Validation loss: 2.3807848115121164

Epoch: 5| Step: 1
Training loss: 1.9192129373550415
Validation loss: 2.364695172156057

Epoch: 5| Step: 2
Training loss: 2.877389669418335
Validation loss: 2.368940266229773

Epoch: 5| Step: 3
Training loss: 2.0045056343078613
Validation loss: 2.3711040071261826

Epoch: 5| Step: 4
Training loss: 2.6419034004211426
Validation loss: 2.3733504459422123

Epoch: 5| Step: 5
Training loss: 3.2125048637390137
Validation loss: 2.365882114697528

Epoch: 5| Step: 6
Training loss: 2.2330775260925293
Validation loss: 2.3738799556609123

Epoch: 5| Step: 7
Training loss: 2.661510944366455
Validation loss: 2.3782910429021364

Epoch: 5| Step: 8
Training loss: 3.699202060699463
Validation loss: 2.3803957393092494

Epoch: 5| Step: 9
Training loss: 2.661055326461792
Validation loss: 2.3817817062459965

Epoch: 5| Step: 10
Training loss: 1.8058359622955322
Validation loss: 2.381990478884789

Epoch: 120| Step: 0
Training loss: 2.1003756523132324
Validation loss: 2.391798678264823

Epoch: 5| Step: 1
Training loss: 1.8664791584014893
Validation loss: 2.395468055561025

Epoch: 5| Step: 2
Training loss: 3.391056537628174
Validation loss: 2.395316808454452

Epoch: 5| Step: 3
Training loss: 2.853759765625
Validation loss: 2.4017765522003174

Epoch: 5| Step: 4
Training loss: 2.453795909881592
Validation loss: 2.395497880956178

Epoch: 5| Step: 5
Training loss: 2.791750431060791
Validation loss: 2.384267532697288

Epoch: 5| Step: 6
Training loss: 3.1398308277130127
Validation loss: 2.382461381214921

Epoch: 5| Step: 7
Training loss: 2.7259697914123535
Validation loss: 2.381065466070688

Epoch: 5| Step: 8
Training loss: 1.9746173620224
Validation loss: 2.377352874766114

Epoch: 5| Step: 9
Training loss: 2.6896252632141113
Validation loss: 2.367772122865082

Epoch: 5| Step: 10
Training loss: 2.6519858837127686
Validation loss: 2.3680658596818165

Epoch: 121| Step: 0
Training loss: 2.8964855670928955
Validation loss: 2.3630698855205248

Epoch: 5| Step: 1
Training loss: 2.003100872039795
Validation loss: 2.372479572091051

Epoch: 5| Step: 2
Training loss: 2.4843978881835938
Validation loss: 2.367483167238133

Epoch: 5| Step: 3
Training loss: 2.815703868865967
Validation loss: 2.371604291341638

Epoch: 5| Step: 4
Training loss: 2.250626802444458
Validation loss: 2.3643188989290627

Epoch: 5| Step: 5
Training loss: 2.3701138496398926
Validation loss: 2.362797260284424

Epoch: 5| Step: 6
Training loss: 3.0303826332092285
Validation loss: 2.3686322601892615

Epoch: 5| Step: 7
Training loss: 3.0359439849853516
Validation loss: 2.370881900992445

Epoch: 5| Step: 8
Training loss: 2.562293767929077
Validation loss: 2.374236963128531

Epoch: 5| Step: 9
Training loss: 2.5255656242370605
Validation loss: 2.3728896674289497

Epoch: 5| Step: 10
Training loss: 2.585999011993408
Validation loss: 2.381532246066678

Epoch: 122| Step: 0
Training loss: 2.394792079925537
Validation loss: 2.383727596652123

Epoch: 5| Step: 1
Training loss: 2.675380229949951
Validation loss: 2.389637913755191

Epoch: 5| Step: 2
Training loss: 2.225919723510742
Validation loss: 2.4048950390149186

Epoch: 5| Step: 3
Training loss: 2.0748419761657715
Validation loss: 2.40714330057944

Epoch: 5| Step: 4
Training loss: 2.6880970001220703
Validation loss: 2.406517267227173

Epoch: 5| Step: 5
Training loss: 2.3742306232452393
Validation loss: 2.4152868845129527

Epoch: 5| Step: 6
Training loss: 3.2535452842712402
Validation loss: 2.4103256092276624

Epoch: 5| Step: 7
Training loss: 2.264570951461792
Validation loss: 2.409381910036969

Epoch: 5| Step: 8
Training loss: 2.810807228088379
Validation loss: 2.4033995238683556

Epoch: 5| Step: 9
Training loss: 3.0493710041046143
Validation loss: 2.3933591996469805

Epoch: 5| Step: 10
Training loss: 2.75639009475708
Validation loss: 2.3844025570859193

Epoch: 123| Step: 0
Training loss: 2.7424330711364746
Validation loss: 2.3741535166258454

Epoch: 5| Step: 1
Training loss: 1.8610212802886963
Validation loss: 2.3617383613381335

Epoch: 5| Step: 2
Training loss: 3.045433759689331
Validation loss: 2.356198159597253

Epoch: 5| Step: 3
Training loss: 3.0088086128234863
Validation loss: 2.352234717338316

Epoch: 5| Step: 4
Training loss: 2.285701274871826
Validation loss: 2.3499082185888804

Epoch: 5| Step: 5
Training loss: 2.2609105110168457
Validation loss: 2.34643720042321

Epoch: 5| Step: 6
Training loss: 2.60317325592041
Validation loss: 2.350403985669536

Epoch: 5| Step: 7
Training loss: 3.2140350341796875
Validation loss: 2.3509180340715634

Epoch: 5| Step: 8
Training loss: 1.5294866561889648
Validation loss: 2.356127405679354

Epoch: 5| Step: 9
Training loss: 3.2096176147460938
Validation loss: 2.369996783553913

Epoch: 5| Step: 10
Training loss: 2.8321330547332764
Validation loss: 2.373325199209234

Epoch: 124| Step: 0
Training loss: 2.417280435562134
Validation loss: 2.3793493035019084

Epoch: 5| Step: 1
Training loss: 3.0049941539764404
Validation loss: 2.393506791002007

Epoch: 5| Step: 2
Training loss: 2.4272029399871826
Validation loss: 2.388526698594452

Epoch: 5| Step: 3
Training loss: 2.266732692718506
Validation loss: 2.3791044899212417

Epoch: 5| Step: 4
Training loss: 2.5300018787384033
Validation loss: 2.373091246492119

Epoch: 5| Step: 5
Training loss: 2.6812353134155273
Validation loss: 2.3653324573270735

Epoch: 5| Step: 6
Training loss: 2.6612770557403564
Validation loss: 2.3531817197799683

Epoch: 5| Step: 7
Training loss: 2.891087770462036
Validation loss: 2.3446985752351823

Epoch: 5| Step: 8
Training loss: 2.7980520725250244
Validation loss: 2.339905354284471

Epoch: 5| Step: 9
Training loss: 2.7721636295318604
Validation loss: 2.343267022922475

Epoch: 5| Step: 10
Training loss: 2.176692008972168
Validation loss: 2.337898228758125

Epoch: 125| Step: 0
Training loss: 3.087144374847412
Validation loss: 2.3377247202780937

Epoch: 5| Step: 1
Training loss: 3.2260868549346924
Validation loss: 2.338161358269312

Epoch: 5| Step: 2
Training loss: 2.121492862701416
Validation loss: 2.334853054374777

Epoch: 5| Step: 3
Training loss: 2.8963212966918945
Validation loss: 2.3385181683366016

Epoch: 5| Step: 4
Training loss: 2.311689853668213
Validation loss: 2.3389542269450363

Epoch: 5| Step: 5
Training loss: 2.5510783195495605
Validation loss: 2.337545556406821

Epoch: 5| Step: 6
Training loss: 1.9978997707366943
Validation loss: 2.339450151689591

Epoch: 5| Step: 7
Training loss: 2.5910675525665283
Validation loss: 2.3399976427837084

Epoch: 5| Step: 8
Training loss: 2.48836350440979
Validation loss: 2.3456128694677867

Epoch: 5| Step: 9
Training loss: 2.6795499324798584
Validation loss: 2.354385681049798

Epoch: 5| Step: 10
Training loss: 2.7840662002563477
Validation loss: 2.356666818741829

Epoch: 126| Step: 0
Training loss: 2.1980135440826416
Validation loss: 2.3552909307582404

Epoch: 5| Step: 1
Training loss: 1.981972098350525
Validation loss: 2.346719003492786

Epoch: 5| Step: 2
Training loss: 2.9863719940185547
Validation loss: 2.3440284241912184

Epoch: 5| Step: 3
Training loss: 2.6521267890930176
Validation loss: 2.3408495341577837

Epoch: 5| Step: 4
Training loss: 2.532435655593872
Validation loss: 2.3453303255060667

Epoch: 5| Step: 5
Training loss: 2.844578981399536
Validation loss: 2.3452024972566994

Epoch: 5| Step: 6
Training loss: 2.7425930500030518
Validation loss: 2.338705829394761

Epoch: 5| Step: 7
Training loss: 2.8105502128601074
Validation loss: 2.3403408527374268

Epoch: 5| Step: 8
Training loss: 2.549931049346924
Validation loss: 2.3453963751434

Epoch: 5| Step: 9
Training loss: 2.6518428325653076
Validation loss: 2.3466709121581046

Epoch: 5| Step: 10
Training loss: 2.516434669494629
Validation loss: 2.349660279930279

Epoch: 127| Step: 0
Training loss: 2.7743968963623047
Validation loss: 2.3527038994655816

Epoch: 5| Step: 1
Training loss: 2.109647512435913
Validation loss: 2.352256219874146

Epoch: 5| Step: 2
Training loss: 2.67887020111084
Validation loss: 2.362388631348969

Epoch: 5| Step: 3
Training loss: 2.988953113555908
Validation loss: 2.366957244052682

Epoch: 5| Step: 4
Training loss: 3.051029682159424
Validation loss: 2.374380273203696

Epoch: 5| Step: 5
Training loss: 2.925623893737793
Validation loss: 2.371869679420225

Epoch: 5| Step: 6
Training loss: 1.927035927772522
Validation loss: 2.377696475675029

Epoch: 5| Step: 7
Training loss: 2.2392578125
Validation loss: 2.3780511784297165

Epoch: 5| Step: 8
Training loss: 2.2827565670013428
Validation loss: 2.385945935403147

Epoch: 5| Step: 9
Training loss: 2.538313865661621
Validation loss: 2.3847325745449273

Epoch: 5| Step: 10
Training loss: 2.9880640506744385
Validation loss: 2.387174249977194

Epoch: 128| Step: 0
Training loss: 3.1275475025177
Validation loss: 2.378625444186631

Epoch: 5| Step: 1
Training loss: 2.509536027908325
Validation loss: 2.3726473854434107

Epoch: 5| Step: 2
Training loss: 2.2959370613098145
Validation loss: 2.3686502236191944

Epoch: 5| Step: 3
Training loss: 2.693647861480713
Validation loss: 2.37126342199182

Epoch: 5| Step: 4
Training loss: 2.988149642944336
Validation loss: 2.379375970491799

Epoch: 5| Step: 5
Training loss: 2.2160141468048096
Validation loss: 2.3704703700157905

Epoch: 5| Step: 6
Training loss: 2.2489094734191895
Validation loss: 2.3848769690400813

Epoch: 5| Step: 7
Training loss: 3.1025657653808594
Validation loss: 2.3754038298001854

Epoch: 5| Step: 8
Training loss: 2.5163350105285645
Validation loss: 2.3754053705482074

Epoch: 5| Step: 9
Training loss: 2.682281970977783
Validation loss: 2.3647923008088143

Epoch: 5| Step: 10
Training loss: 1.962494134902954
Validation loss: 2.3704443234269337

Epoch: 129| Step: 0
Training loss: 2.193784713745117
Validation loss: 2.3613409637123026

Epoch: 5| Step: 1
Training loss: 2.838468074798584
Validation loss: 2.3568390979561755

Epoch: 5| Step: 2
Training loss: 2.68000864982605
Validation loss: 2.3470980351971042

Epoch: 5| Step: 3
Training loss: 3.457695484161377
Validation loss: 2.345712310524397

Epoch: 5| Step: 4
Training loss: 2.4198155403137207
Validation loss: 2.351367850457468

Epoch: 5| Step: 5
Training loss: 1.9580920934677124
Validation loss: 2.3436363102287374

Epoch: 5| Step: 6
Training loss: 2.534637928009033
Validation loss: 2.3474748493522726

Epoch: 5| Step: 7
Training loss: 2.0882601737976074
Validation loss: 2.347539883787914

Epoch: 5| Step: 8
Training loss: 2.5601043701171875
Validation loss: 2.3438109685015935

Epoch: 5| Step: 9
Training loss: 3.3545734882354736
Validation loss: 2.347780599389025

Epoch: 5| Step: 10
Training loss: 2.4081788063049316
Validation loss: 2.349558855897637

Epoch: 130| Step: 0
Training loss: 2.309741258621216
Validation loss: 2.348215497950072

Epoch: 5| Step: 1
Training loss: 2.835933208465576
Validation loss: 2.3493713281487905

Epoch: 5| Step: 2
Training loss: 3.6516921520233154
Validation loss: 2.343649579632667

Epoch: 5| Step: 3
Training loss: 2.8090639114379883
Validation loss: 2.3394163872606013

Epoch: 5| Step: 4
Training loss: 2.3365325927734375
Validation loss: 2.335527991735807

Epoch: 5| Step: 5
Training loss: 2.2774853706359863
Validation loss: 2.339043519830191

Epoch: 5| Step: 6
Training loss: 2.5671346187591553
Validation loss: 2.3337247845947102

Epoch: 5| Step: 7
Training loss: 2.330233097076416
Validation loss: 2.337617101207856

Epoch: 5| Step: 8
Training loss: 2.332807779312134
Validation loss: 2.341183372723159

Epoch: 5| Step: 9
Training loss: 2.7550346851348877
Validation loss: 2.3540137121754308

Epoch: 5| Step: 10
Training loss: 2.2026023864746094
Validation loss: 2.3584026444342827

Epoch: 131| Step: 0
Training loss: 3.100367784500122
Validation loss: 2.364124882605768

Epoch: 5| Step: 1
Training loss: 1.8026773929595947
Validation loss: 2.3747804369977725

Epoch: 5| Step: 2
Training loss: 2.459862232208252
Validation loss: 2.3710002232623357

Epoch: 5| Step: 3
Training loss: 2.8871757984161377
Validation loss: 2.3844280883830082

Epoch: 5| Step: 4
Training loss: 2.3122711181640625
Validation loss: 2.368465592784266

Epoch: 5| Step: 5
Training loss: 1.7998870611190796
Validation loss: 2.359632638192946

Epoch: 5| Step: 6
Training loss: 2.2402873039245605
Validation loss: 2.360477662855579

Epoch: 5| Step: 7
Training loss: 2.4258065223693848
Validation loss: 2.3561893201643422

Epoch: 5| Step: 8
Training loss: 3.3323779106140137
Validation loss: 2.360792326670821

Epoch: 5| Step: 9
Training loss: 2.8747425079345703
Validation loss: 2.3592489868082027

Epoch: 5| Step: 10
Training loss: 3.39290452003479
Validation loss: 2.3648426173835673

Epoch: 132| Step: 0
Training loss: 2.9071784019470215
Validation loss: 2.356324306098364

Epoch: 5| Step: 1
Training loss: 2.489372730255127
Validation loss: 2.3597663166702434

Epoch: 5| Step: 2
Training loss: 2.587460994720459
Validation loss: 2.348204505059027

Epoch: 5| Step: 3
Training loss: 2.781970262527466
Validation loss: 2.3536808926572084

Epoch: 5| Step: 4
Training loss: 2.30320405960083
Validation loss: 2.35169025903107

Epoch: 5| Step: 5
Training loss: 2.25907564163208
Validation loss: 2.3418671136261313

Epoch: 5| Step: 6
Training loss: 3.239123821258545
Validation loss: 2.3364808533781316

Epoch: 5| Step: 7
Training loss: 2.435372829437256
Validation loss: 2.337238460458735

Epoch: 5| Step: 8
Training loss: 2.44389009475708
Validation loss: 2.3376847415842037

Epoch: 5| Step: 9
Training loss: 2.5438954830169678
Validation loss: 2.3327984476602204

Epoch: 5| Step: 10
Training loss: 2.403712511062622
Validation loss: 2.340254678521105

Epoch: 133| Step: 0
Training loss: 2.5282211303710938
Validation loss: 2.336753514505202

Epoch: 5| Step: 1
Training loss: 2.1936488151550293
Validation loss: 2.3415606996064544

Epoch: 5| Step: 2
Training loss: 2.63171648979187
Validation loss: 2.3417986849302888

Epoch: 5| Step: 3
Training loss: 1.8713115453720093
Validation loss: 2.3464238515464206

Epoch: 5| Step: 4
Training loss: 3.349522829055786
Validation loss: 2.3587304866442116

Epoch: 5| Step: 5
Training loss: 2.2254955768585205
Validation loss: 2.349465024086737

Epoch: 5| Step: 6
Training loss: 2.8165199756622314
Validation loss: 2.34721456291855

Epoch: 5| Step: 7
Training loss: 2.147726058959961
Validation loss: 2.3508667458770094

Epoch: 5| Step: 8
Training loss: 2.5757603645324707
Validation loss: 2.346892923437139

Epoch: 5| Step: 9
Training loss: 2.527348279953003
Validation loss: 2.3459037683343373

Epoch: 5| Step: 10
Training loss: 3.6629762649536133
Validation loss: 2.3430859863117175

Epoch: 134| Step: 0
Training loss: 2.6099939346313477
Validation loss: 2.3386941391934633

Epoch: 5| Step: 1
Training loss: 2.4535398483276367
Validation loss: 2.348538878143475

Epoch: 5| Step: 2
Training loss: 2.187370777130127
Validation loss: 2.3498328347359934

Epoch: 5| Step: 3
Training loss: 2.338911533355713
Validation loss: 2.3397199159027426

Epoch: 5| Step: 4
Training loss: 2.899034023284912
Validation loss: 2.3420271950383342

Epoch: 5| Step: 5
Training loss: 2.464688539505005
Validation loss: 2.3486145927060034

Epoch: 5| Step: 6
Training loss: 2.8886733055114746
Validation loss: 2.3468994735389628

Epoch: 5| Step: 7
Training loss: 2.876316547393799
Validation loss: 2.349360309621339

Epoch: 5| Step: 8
Training loss: 2.2792131900787354
Validation loss: 2.353013043762535

Epoch: 5| Step: 9
Training loss: 2.9080193042755127
Validation loss: 2.3495597224081717

Epoch: 5| Step: 10
Training loss: 2.3451766967773438
Validation loss: 2.3611352776968353

Epoch: 135| Step: 0
Training loss: 2.5457465648651123
Validation loss: 2.359087098029352

Epoch: 5| Step: 1
Training loss: 3.0030088424682617
Validation loss: 2.353618303934733

Epoch: 5| Step: 2
Training loss: 1.7773256301879883
Validation loss: 2.348307039148064

Epoch: 5| Step: 3
Training loss: 2.0932228565216064
Validation loss: 2.3594692035387923

Epoch: 5| Step: 4
Training loss: 2.435372829437256
Validation loss: 2.3527169125054472

Epoch: 5| Step: 5
Training loss: 2.124152421951294
Validation loss: 2.3522007619180987

Epoch: 5| Step: 6
Training loss: 2.4943645000457764
Validation loss: 2.354200017067694

Epoch: 5| Step: 7
Training loss: 2.5014331340789795
Validation loss: 2.351921227670485

Epoch: 5| Step: 8
Training loss: 3.388126850128174
Validation loss: 2.347120855444221

Epoch: 5| Step: 9
Training loss: 2.850414752960205
Validation loss: 2.3524641477933494

Epoch: 5| Step: 10
Training loss: 3.199753522872925
Validation loss: 2.3412942706897693

Epoch: 136| Step: 0
Training loss: 2.3098461627960205
Validation loss: 2.341686353888563

Epoch: 5| Step: 1
Training loss: 2.651837110519409
Validation loss: 2.335450815898116

Epoch: 5| Step: 2
Training loss: 3.0667004585266113
Validation loss: 2.328569345576789

Epoch: 5| Step: 3
Training loss: 1.964938759803772
Validation loss: 2.327638622253172

Epoch: 5| Step: 4
Training loss: 2.7937088012695312
Validation loss: 2.330942410294728

Epoch: 5| Step: 5
Training loss: 3.5531582832336426
Validation loss: 2.3308172405406995

Epoch: 5| Step: 6
Training loss: 2.4236226081848145
Validation loss: 2.3315261717765563

Epoch: 5| Step: 7
Training loss: 2.4459340572357178
Validation loss: 2.3310129257940475

Epoch: 5| Step: 8
Training loss: 2.3932530879974365
Validation loss: 2.3292976989541003

Epoch: 5| Step: 9
Training loss: 2.3892569541931152
Validation loss: 2.330371295252154

Epoch: 5| Step: 10
Training loss: 2.4247806072235107
Validation loss: 2.3391320654141006

Epoch: 137| Step: 0
Training loss: 3.160311460494995
Validation loss: 2.354251751335718

Epoch: 5| Step: 1
Training loss: 2.323021650314331
Validation loss: 2.3678146305904595

Epoch: 5| Step: 2
Training loss: 2.4592113494873047
Validation loss: 2.375579918584516

Epoch: 5| Step: 3
Training loss: 2.9334988594055176
Validation loss: 2.3761315730310257

Epoch: 5| Step: 4
Training loss: 1.8591045141220093
Validation loss: 2.3779248294009956

Epoch: 5| Step: 5
Training loss: 3.0325794219970703
Validation loss: 2.37800661722819

Epoch: 5| Step: 6
Training loss: 2.442091941833496
Validation loss: 2.365019957224528

Epoch: 5| Step: 7
Training loss: 2.14019775390625
Validation loss: 2.379092190855293

Epoch: 5| Step: 8
Training loss: 2.905526638031006
Validation loss: 2.3633145568191365

Epoch: 5| Step: 9
Training loss: 2.401406764984131
Validation loss: 2.3594388782337146

Epoch: 5| Step: 10
Training loss: 2.8150081634521484
Validation loss: 2.3651488416938373

Epoch: 138| Step: 0
Training loss: 2.98268461227417
Validation loss: 2.3674972595707064

Epoch: 5| Step: 1
Training loss: 2.128016233444214
Validation loss: 2.359830210285802

Epoch: 5| Step: 2
Training loss: 2.58552885055542
Validation loss: 2.3588321952409643

Epoch: 5| Step: 3
Training loss: 2.841998338699341
Validation loss: 2.3502109666024484

Epoch: 5| Step: 4
Training loss: 2.7885055541992188
Validation loss: 2.350315260630782

Epoch: 5| Step: 5
Training loss: 2.0367114543914795
Validation loss: 2.3382219550430134

Epoch: 5| Step: 6
Training loss: 2.874228000640869
Validation loss: 2.3391866414777693

Epoch: 5| Step: 7
Training loss: 2.806922435760498
Validation loss: 2.328274521776425

Epoch: 5| Step: 8
Training loss: 1.896040678024292
Validation loss: 2.3345330710052163

Epoch: 5| Step: 9
Training loss: 3.0918078422546387
Validation loss: 2.337260923077983

Epoch: 5| Step: 10
Training loss: 2.261241912841797
Validation loss: 2.3445015209977345

Epoch: 139| Step: 0
Training loss: 2.9089436531066895
Validation loss: 2.3470310523945797

Epoch: 5| Step: 1
Training loss: 3.3774521350860596
Validation loss: 2.3430202750749487

Epoch: 5| Step: 2
Training loss: 1.8065927028656006
Validation loss: 2.3447597898462766

Epoch: 5| Step: 3
Training loss: 2.144110679626465
Validation loss: 2.348465258075345

Epoch: 5| Step: 4
Training loss: 2.6793549060821533
Validation loss: 2.337465424691477

Epoch: 5| Step: 5
Training loss: 2.7929699420928955
Validation loss: 2.339254189563054

Epoch: 5| Step: 6
Training loss: 2.5013840198516846
Validation loss: 2.3356673871317217

Epoch: 5| Step: 7
Training loss: 2.115626573562622
Validation loss: 2.3386882146199546

Epoch: 5| Step: 8
Training loss: 2.911226749420166
Validation loss: 2.3371119063387633

Epoch: 5| Step: 9
Training loss: 2.369762659072876
Validation loss: 2.3336761715591594

Epoch: 5| Step: 10
Training loss: 2.67889404296875
Validation loss: 2.3393657412580264

Epoch: 140| Step: 0
Training loss: 1.9743404388427734
Validation loss: 2.3323779708595684

Epoch: 5| Step: 1
Training loss: 2.371002435684204
Validation loss: 2.3380478146255657

Epoch: 5| Step: 2
Training loss: 2.3368124961853027
Validation loss: 2.3432940129310853

Epoch: 5| Step: 3
Training loss: 3.5406367778778076
Validation loss: 2.3433805076024865

Epoch: 5| Step: 4
Training loss: 2.1517279148101807
Validation loss: 2.3419908913232947

Epoch: 5| Step: 5
Training loss: 2.0055689811706543
Validation loss: 2.345621665318807

Epoch: 5| Step: 6
Training loss: 3.2724833488464355
Validation loss: 2.3389618448031846

Epoch: 5| Step: 7
Training loss: 2.609989643096924
Validation loss: 2.329237361108103

Epoch: 5| Step: 8
Training loss: 2.23701810836792
Validation loss: 2.327252226491128

Epoch: 5| Step: 9
Training loss: 3.011824369430542
Validation loss: 2.327889114297846

Epoch: 5| Step: 10
Training loss: 2.74300479888916
Validation loss: 2.3297830089446037

Epoch: 141| Step: 0
Training loss: 2.814760446548462
Validation loss: 2.3305980595209266

Epoch: 5| Step: 1
Training loss: 1.7316579818725586
Validation loss: 2.334994234064574

Epoch: 5| Step: 2
Training loss: 2.4179089069366455
Validation loss: 2.331048280962052

Epoch: 5| Step: 3
Training loss: 2.852097988128662
Validation loss: 2.3296409012168966

Epoch: 5| Step: 4
Training loss: 2.521812677383423
Validation loss: 2.3361096433413926

Epoch: 5| Step: 5
Training loss: 2.049328565597534
Validation loss: 2.3261124139191

Epoch: 5| Step: 6
Training loss: 2.9586315155029297
Validation loss: 2.32938390649775

Epoch: 5| Step: 7
Training loss: 3.176875591278076
Validation loss: 2.332130306510515

Epoch: 5| Step: 8
Training loss: 3.114525556564331
Validation loss: 2.3329845346430296

Epoch: 5| Step: 9
Training loss: 1.7696565389633179
Validation loss: 2.341474179298647

Epoch: 5| Step: 10
Training loss: 2.959446907043457
Validation loss: 2.344939749727967

Epoch: 142| Step: 0
Training loss: 2.4163708686828613
Validation loss: 2.345524511029643

Epoch: 5| Step: 1
Training loss: 2.7884104251861572
Validation loss: 2.349099523277693

Epoch: 5| Step: 2
Training loss: 2.92706298828125
Validation loss: 2.351777522794662

Epoch: 5| Step: 3
Training loss: 2.6933560371398926
Validation loss: 2.3489215630356983

Epoch: 5| Step: 4
Training loss: 2.171639919281006
Validation loss: 2.361674137012933

Epoch: 5| Step: 5
Training loss: 3.0023562908172607
Validation loss: 2.3545840811985794

Epoch: 5| Step: 6
Training loss: 2.8712871074676514
Validation loss: 2.337223724652362

Epoch: 5| Step: 7
Training loss: 1.82871413230896
Validation loss: 2.3278578942821873

Epoch: 5| Step: 8
Training loss: 2.669710159301758
Validation loss: 2.3354088285917878

Epoch: 5| Step: 9
Training loss: 2.678637981414795
Validation loss: 2.3356229233485397

Epoch: 5| Step: 10
Training loss: 2.2345592975616455
Validation loss: 2.3307709027362127

Epoch: 143| Step: 0
Training loss: 2.9842448234558105
Validation loss: 2.3448299413086264

Epoch: 5| Step: 1
Training loss: 2.4664199352264404
Validation loss: 2.33929116495194

Epoch: 5| Step: 2
Training loss: 2.4772791862487793
Validation loss: 2.3439313493749148

Epoch: 5| Step: 3
Training loss: 2.653437376022339
Validation loss: 2.3393703558111705

Epoch: 5| Step: 4
Training loss: 2.605879545211792
Validation loss: 2.3251334569787465

Epoch: 5| Step: 5
Training loss: 2.901273488998413
Validation loss: 2.3252796178222983

Epoch: 5| Step: 6
Training loss: 2.496978282928467
Validation loss: 2.314072491020285

Epoch: 5| Step: 7
Training loss: 2.149380922317505
Validation loss: 2.306843155173845

Epoch: 5| Step: 8
Training loss: 2.685805082321167
Validation loss: 2.306918333935481

Epoch: 5| Step: 9
Training loss: 2.415062665939331
Validation loss: 2.2984019710171606

Epoch: 5| Step: 10
Training loss: 2.5442731380462646
Validation loss: 2.301236037285097

Epoch: 144| Step: 0
Training loss: 1.881749153137207
Validation loss: 2.3077431699281097

Epoch: 5| Step: 1
Training loss: 3.1745569705963135
Validation loss: 2.299774549340689

Epoch: 5| Step: 2
Training loss: 2.8336565494537354
Validation loss: 2.30441023970163

Epoch: 5| Step: 3
Training loss: 1.9103015661239624
Validation loss: 2.3048995438442437

Epoch: 5| Step: 4
Training loss: 2.859006643295288
Validation loss: 2.302981215138589

Epoch: 5| Step: 5
Training loss: 3.0259969234466553
Validation loss: 2.3053935163764545

Epoch: 5| Step: 6
Training loss: 3.0097107887268066
Validation loss: 2.3132024670159943

Epoch: 5| Step: 7
Training loss: 2.752251386642456
Validation loss: 2.313421613426619

Epoch: 5| Step: 8
Training loss: 2.089060068130493
Validation loss: 2.3139175522711968

Epoch: 5| Step: 9
Training loss: 2.1170895099639893
Validation loss: 2.3260010314244095

Epoch: 5| Step: 10
Training loss: 2.758101224899292
Validation loss: 2.333356652208554

Epoch: 145| Step: 0
Training loss: 3.073493242263794
Validation loss: 2.335639992067891

Epoch: 5| Step: 1
Training loss: 2.4730677604675293
Validation loss: 2.349167628954816

Epoch: 5| Step: 2
Training loss: 2.7481849193573
Validation loss: 2.3445548319047496

Epoch: 5| Step: 3
Training loss: 1.6605085134506226
Validation loss: 2.338593864953646

Epoch: 5| Step: 4
Training loss: 2.7717015743255615
Validation loss: 2.325419259327714

Epoch: 5| Step: 5
Training loss: 3.227003574371338
Validation loss: 2.3214926309483026

Epoch: 5| Step: 6
Training loss: 2.5604586601257324
Validation loss: 2.3239332347787838

Epoch: 5| Step: 7
Training loss: 2.7500338554382324
Validation loss: 2.315410696050172

Epoch: 5| Step: 8
Training loss: 2.459662914276123
Validation loss: 2.3121199736031155

Epoch: 5| Step: 9
Training loss: 1.9892107248306274
Validation loss: 2.30538922227839

Epoch: 5| Step: 10
Training loss: 2.536010503768921
Validation loss: 2.3100981661068496

Epoch: 146| Step: 0
Training loss: 2.0655622482299805
Validation loss: 2.3120469508632535

Epoch: 5| Step: 1
Training loss: 2.4833266735076904
Validation loss: 2.310207182361234

Epoch: 5| Step: 2
Training loss: 3.3661231994628906
Validation loss: 2.3132941415232997

Epoch: 5| Step: 3
Training loss: 2.9929912090301514
Validation loss: 2.311662332985991

Epoch: 5| Step: 4
Training loss: 2.50714111328125
Validation loss: 2.308076886720555

Epoch: 5| Step: 5
Training loss: 2.2210237979888916
Validation loss: 2.3142782283085648

Epoch: 5| Step: 6
Training loss: 2.772355318069458
Validation loss: 2.3151263575400076

Epoch: 5| Step: 7
Training loss: 2.440551280975342
Validation loss: 2.320251254625218

Epoch: 5| Step: 8
Training loss: 2.2631053924560547
Validation loss: 2.326129958193789

Epoch: 5| Step: 9
Training loss: 2.481382369995117
Validation loss: 2.318837214541692

Epoch: 5| Step: 10
Training loss: 2.7306041717529297
Validation loss: 2.3285303141481135

Epoch: 147| Step: 0
Training loss: 2.517075300216675
Validation loss: 2.335286360914989

Epoch: 5| Step: 1
Training loss: 2.77722430229187
Validation loss: 2.3562766839099187

Epoch: 5| Step: 2
Training loss: 2.401404619216919
Validation loss: 2.3613036524864937

Epoch: 5| Step: 3
Training loss: 2.5619797706604004
Validation loss: 2.3663224674040273

Epoch: 5| Step: 4
Training loss: 2.3525521755218506
Validation loss: 2.372199909661406

Epoch: 5| Step: 5
Training loss: 2.32466459274292
Validation loss: 2.3688847352099676

Epoch: 5| Step: 6
Training loss: 1.8275823593139648
Validation loss: 2.365702303506995

Epoch: 5| Step: 7
Training loss: 2.465669870376587
Validation loss: 2.34722642232013

Epoch: 5| Step: 8
Training loss: 3.0598292350769043
Validation loss: 2.3531345628922984

Epoch: 5| Step: 9
Training loss: 3.1574482917785645
Validation loss: 2.3383465454142582

Epoch: 5| Step: 10
Training loss: 2.863524913787842
Validation loss: 2.3411139903529996

Epoch: 148| Step: 0
Training loss: 2.360760450363159
Validation loss: 2.3376248036661456

Epoch: 5| Step: 1
Training loss: 2.5744078159332275
Validation loss: 2.3255540504250476

Epoch: 5| Step: 2
Training loss: 2.8069326877593994
Validation loss: 2.329372185532765

Epoch: 5| Step: 3
Training loss: 2.1014883518218994
Validation loss: 2.3255653945348596

Epoch: 5| Step: 4
Training loss: 2.9325666427612305
Validation loss: 2.325274654614028

Epoch: 5| Step: 5
Training loss: 2.2953264713287354
Validation loss: 2.326741959459038

Epoch: 5| Step: 6
Training loss: 2.9382052421569824
Validation loss: 2.321800240906336

Epoch: 5| Step: 7
Training loss: 2.532817840576172
Validation loss: 2.322052396753783

Epoch: 5| Step: 8
Training loss: 3.073305130004883
Validation loss: 2.3123794037808656

Epoch: 5| Step: 9
Training loss: 2.111726760864258
Validation loss: 2.318951993860224

Epoch: 5| Step: 10
Training loss: 2.3760809898376465
Validation loss: 2.3266852850555093

Epoch: 149| Step: 0
Training loss: 3.1393802165985107
Validation loss: 2.325868550167289

Epoch: 5| Step: 1
Training loss: 2.5819904804229736
Validation loss: 2.3206380362151773

Epoch: 5| Step: 2
Training loss: 2.3239452838897705
Validation loss: 2.3137440194365797

Epoch: 5| Step: 3
Training loss: 2.6688246726989746
Validation loss: 2.313210864220896

Epoch: 5| Step: 4
Training loss: 1.9350321292877197
Validation loss: 2.317576395568027

Epoch: 5| Step: 5
Training loss: 2.694270372390747
Validation loss: 2.3173509079922914

Epoch: 5| Step: 6
Training loss: 2.639277935028076
Validation loss: 2.3225680115402385

Epoch: 5| Step: 7
Training loss: 2.6491408348083496
Validation loss: 2.3219325234813075

Epoch: 5| Step: 8
Training loss: 3.1709861755371094
Validation loss: 2.325045031885947

Epoch: 5| Step: 9
Training loss: 2.0540809631347656
Validation loss: 2.3258164159713255

Epoch: 5| Step: 10
Training loss: 2.1776304244995117
Validation loss: 2.330975991423412

Epoch: 150| Step: 0
Training loss: 2.3117358684539795
Validation loss: 2.3397523126294537

Epoch: 5| Step: 1
Training loss: 2.883784532546997
Validation loss: 2.3320540740925777

Epoch: 5| Step: 2
Training loss: 2.534282922744751
Validation loss: 2.3353146122347925

Epoch: 5| Step: 3
Training loss: 2.4113218784332275
Validation loss: 2.3336139776373424

Epoch: 5| Step: 4
Training loss: 2.225458860397339
Validation loss: 2.327994474800684

Epoch: 5| Step: 5
Training loss: 2.1869614124298096
Validation loss: 2.3304272287635395

Epoch: 5| Step: 6
Training loss: 2.0610384941101074
Validation loss: 2.3249199839048487

Epoch: 5| Step: 7
Training loss: 2.775420904159546
Validation loss: 2.3225743924417803

Epoch: 5| Step: 8
Training loss: 2.5601820945739746
Validation loss: 2.321284647910826

Epoch: 5| Step: 9
Training loss: 3.3495850563049316
Validation loss: 2.328061242257395

Epoch: 5| Step: 10
Training loss: 2.8543589115142822
Validation loss: 2.327569871820429

Epoch: 151| Step: 0
Training loss: 2.55460524559021
Validation loss: 2.3227565775635424

Epoch: 5| Step: 1
Training loss: 2.9153060913085938
Validation loss: 2.333655067669448

Epoch: 5| Step: 2
Training loss: 1.838754653930664
Validation loss: 2.3277025120232695

Epoch: 5| Step: 3
Training loss: 2.4262619018554688
Validation loss: 2.323533614476522

Epoch: 5| Step: 4
Training loss: 2.8682613372802734
Validation loss: 2.3186561048671765

Epoch: 5| Step: 5
Training loss: 2.855292797088623
Validation loss: 2.3219687079870575

Epoch: 5| Step: 6
Training loss: 2.5772600173950195
Validation loss: 2.324674326886413

Epoch: 5| Step: 7
Training loss: 2.320213794708252
Validation loss: 2.328822294871012

Epoch: 5| Step: 8
Training loss: 2.7631607055664062
Validation loss: 2.329020256637245

Epoch: 5| Step: 9
Training loss: 3.0148391723632812
Validation loss: 2.3324711694512317

Epoch: 5| Step: 10
Training loss: 1.8560501337051392
Validation loss: 2.323850534295523

Epoch: 152| Step: 0
Training loss: 2.0620479583740234
Validation loss: 2.3342542584224413

Epoch: 5| Step: 1
Training loss: 2.836611032485962
Validation loss: 2.3306159870598906

Epoch: 5| Step: 2
Training loss: 2.215200901031494
Validation loss: 2.323466512464708

Epoch: 5| Step: 3
Training loss: 1.9804341793060303
Validation loss: 2.33589966066422

Epoch: 5| Step: 4
Training loss: 2.647585391998291
Validation loss: 2.3301615279207946

Epoch: 5| Step: 5
Training loss: 2.3510215282440186
Validation loss: 2.338635008822205

Epoch: 5| Step: 6
Training loss: 2.8326563835144043
Validation loss: 2.33593963807629

Epoch: 5| Step: 7
Training loss: 2.359687566757202
Validation loss: 2.3327635257474837

Epoch: 5| Step: 8
Training loss: 2.7946887016296387
Validation loss: 2.3286937667477514

Epoch: 5| Step: 9
Training loss: 3.055795669555664
Validation loss: 2.3273627399116434

Epoch: 5| Step: 10
Training loss: 2.9201226234436035
Validation loss: 2.327442502462736

Epoch: 153| Step: 0
Training loss: 2.5867209434509277
Validation loss: 2.3173574196395053

Epoch: 5| Step: 1
Training loss: 2.713045835494995
Validation loss: 2.3153378707106396

Epoch: 5| Step: 2
Training loss: 2.3622403144836426
Validation loss: 2.302758918013624

Epoch: 5| Step: 3
Training loss: 2.7856791019439697
Validation loss: 2.303647623267225

Epoch: 5| Step: 4
Training loss: 2.806396961212158
Validation loss: 2.301811049061437

Epoch: 5| Step: 5
Training loss: 1.5390199422836304
Validation loss: 2.300846927909441

Epoch: 5| Step: 6
Training loss: 2.9733738899230957
Validation loss: 2.300953716360113

Epoch: 5| Step: 7
Training loss: 2.5895283222198486
Validation loss: 2.3033046594230075

Epoch: 5| Step: 8
Training loss: 2.4325647354125977
Validation loss: 2.308438044722362

Epoch: 5| Step: 9
Training loss: 2.7543091773986816
Validation loss: 2.302850284884053

Epoch: 5| Step: 10
Training loss: 2.4814438819885254
Validation loss: 2.3152453130291355

Epoch: 154| Step: 0
Training loss: 2.329241991043091
Validation loss: 2.32806138325763

Epoch: 5| Step: 1
Training loss: 3.7815921306610107
Validation loss: 2.3264606588630268

Epoch: 5| Step: 2
Training loss: 2.546323299407959
Validation loss: 2.341308655277375

Epoch: 5| Step: 3
Training loss: 2.8022561073303223
Validation loss: 2.340974202720068

Epoch: 5| Step: 4
Training loss: 2.150118589401245
Validation loss: 2.3568452994028726

Epoch: 5| Step: 5
Training loss: 2.3499808311462402
Validation loss: 2.381384772639121

Epoch: 5| Step: 6
Training loss: 2.506037712097168
Validation loss: 2.411664198803645

Epoch: 5| Step: 7
Training loss: 2.3839244842529297
Validation loss: 2.4122974077860513

Epoch: 5| Step: 8
Training loss: 2.129610061645508
Validation loss: 2.4190164817276822

Epoch: 5| Step: 9
Training loss: 3.089531421661377
Validation loss: 2.408976721507247

Epoch: 5| Step: 10
Training loss: 2.1857082843780518
Validation loss: 2.365745054778232

Epoch: 155| Step: 0
Training loss: 2.5858874320983887
Validation loss: 2.3357532024383545

Epoch: 5| Step: 1
Training loss: 2.6725635528564453
Validation loss: 2.3155462664942585

Epoch: 5| Step: 2
Training loss: 2.03741192817688
Validation loss: 2.3037888003933813

Epoch: 5| Step: 3
Training loss: 2.372798204421997
Validation loss: 2.3005485047576246

Epoch: 5| Step: 4
Training loss: 2.4241950511932373
Validation loss: 2.306453656124812

Epoch: 5| Step: 5
Training loss: 3.3767669200897217
Validation loss: 2.304227682851976

Epoch: 5| Step: 6
Training loss: 3.0786960124969482
Validation loss: 2.306497650761758

Epoch: 5| Step: 7
Training loss: 3.059220790863037
Validation loss: 2.3068089690259708

Epoch: 5| Step: 8
Training loss: 1.9717891216278076
Validation loss: 2.309758681122975

Epoch: 5| Step: 9
Training loss: 2.3254387378692627
Validation loss: 2.304408919426703

Epoch: 5| Step: 10
Training loss: 2.547645092010498
Validation loss: 2.30831661019274

Epoch: 156| Step: 0
Training loss: 3.055572509765625
Validation loss: 2.3086137335787535

Epoch: 5| Step: 1
Training loss: 2.8678107261657715
Validation loss: 2.306675628949237

Epoch: 5| Step: 2
Training loss: 2.9938743114471436
Validation loss: 2.307458254598802

Epoch: 5| Step: 3
Training loss: 2.3431708812713623
Validation loss: 2.3089216550191245

Epoch: 5| Step: 4
Training loss: 2.2549643516540527
Validation loss: 2.3029173163957495

Epoch: 5| Step: 5
Training loss: 3.0185999870300293
Validation loss: 2.3052296766670803

Epoch: 5| Step: 6
Training loss: 2.4502334594726562
Validation loss: 2.3040242554039083

Epoch: 5| Step: 7
Training loss: 2.0884182453155518
Validation loss: 2.308397880164526

Epoch: 5| Step: 8
Training loss: 2.0956249237060547
Validation loss: 2.3050230215954524

Epoch: 5| Step: 9
Training loss: 2.419555425643921
Validation loss: 2.3145724855443484

Epoch: 5| Step: 10
Training loss: 2.690608024597168
Validation loss: 2.326383706062071

Epoch: 157| Step: 0
Training loss: 2.2942099571228027
Validation loss: 2.317935847466992

Epoch: 5| Step: 1
Training loss: 2.7414629459381104
Validation loss: 2.3188692754314792

Epoch: 5| Step: 2
Training loss: 2.2312114238739014
Validation loss: 2.323923995417933

Epoch: 5| Step: 3
Training loss: 2.4424076080322266
Validation loss: 2.3331550551999

Epoch: 5| Step: 4
Training loss: 2.6966166496276855
Validation loss: 2.3354712737503873

Epoch: 5| Step: 5
Training loss: 2.6533637046813965
Validation loss: 2.3357511951077368

Epoch: 5| Step: 6
Training loss: 3.0073399543762207
Validation loss: 2.3359539406273955

Epoch: 5| Step: 7
Training loss: 2.42324161529541
Validation loss: 2.327749175410117

Epoch: 5| Step: 8
Training loss: 2.4238619804382324
Validation loss: 2.322530036331505

Epoch: 5| Step: 9
Training loss: 2.9233555793762207
Validation loss: 2.31833989133117

Epoch: 5| Step: 10
Training loss: 2.2348999977111816
Validation loss: 2.3205940441418718

Epoch: 158| Step: 0
Training loss: 2.3431265354156494
Validation loss: 2.3200973054414153

Epoch: 5| Step: 1
Training loss: 2.12579083442688
Validation loss: 2.3162600096835884

Epoch: 5| Step: 2
Training loss: 2.5248188972473145
Validation loss: 2.312936131672193

Epoch: 5| Step: 3
Training loss: 2.3696377277374268
Validation loss: 2.318092792264877

Epoch: 5| Step: 4
Training loss: 2.9748928546905518
Validation loss: 2.315801170564467

Epoch: 5| Step: 5
Training loss: 1.9371696710586548
Validation loss: 2.3115333228982906

Epoch: 5| Step: 6
Training loss: 2.8040034770965576
Validation loss: 2.3117299413168304

Epoch: 5| Step: 7
Training loss: 3.0879132747650146
Validation loss: 2.3034237584760113

Epoch: 5| Step: 8
Training loss: 2.3079094886779785
Validation loss: 2.30977052257907

Epoch: 5| Step: 9
Training loss: 2.950507402420044
Validation loss: 2.325676792411394

Epoch: 5| Step: 10
Training loss: 2.6269030570983887
Validation loss: 2.313677631398683

Epoch: 159| Step: 0
Training loss: 2.1364572048187256
Validation loss: 2.306032270513555

Epoch: 5| Step: 1
Training loss: 1.8543345928192139
Validation loss: 2.314486870201685

Epoch: 5| Step: 2
Training loss: 3.008990526199341
Validation loss: 2.3109073433824765

Epoch: 5| Step: 3
Training loss: 2.690354824066162
Validation loss: 2.311288860536391

Epoch: 5| Step: 4
Training loss: 2.7652721405029297
Validation loss: 2.307877298324339

Epoch: 5| Step: 5
Training loss: 2.599635601043701
Validation loss: 2.2995998167222544

Epoch: 5| Step: 6
Training loss: 2.8171756267547607
Validation loss: 2.307570803549982

Epoch: 5| Step: 7
Training loss: 2.3127596378326416
Validation loss: 2.3097199406675113

Epoch: 5| Step: 8
Training loss: 3.0877525806427
Validation loss: 2.312027395412486

Epoch: 5| Step: 9
Training loss: 2.534475326538086
Validation loss: 2.309316537713492

Epoch: 5| Step: 10
Training loss: 2.26567006111145
Validation loss: 2.309345542743642

Epoch: 160| Step: 0
Training loss: 2.619124412536621
Validation loss: 2.3076047012882848

Epoch: 5| Step: 1
Training loss: 2.432337522506714
Validation loss: 2.3068424065907798

Epoch: 5| Step: 2
Training loss: 2.227358818054199
Validation loss: 2.303041640148368

Epoch: 5| Step: 3
Training loss: 2.719156265258789
Validation loss: 2.304242290476317

Epoch: 5| Step: 4
Training loss: 2.7653017044067383
Validation loss: 2.3013693286526586

Epoch: 5| Step: 5
Training loss: 2.924792528152466
Validation loss: 2.3061965588600404

Epoch: 5| Step: 6
Training loss: 2.1254494190216064
Validation loss: 2.311320580461974

Epoch: 5| Step: 7
Training loss: 3.644057035446167
Validation loss: 2.309230387851756

Epoch: 5| Step: 8
Training loss: 2.1755130290985107
Validation loss: 2.3040841215400287

Epoch: 5| Step: 9
Training loss: 2.2250609397888184
Validation loss: 2.3010439936832716

Epoch: 5| Step: 10
Training loss: 2.0569491386413574
Validation loss: 2.298143150985882

Epoch: 161| Step: 0
Training loss: 2.7004733085632324
Validation loss: 2.3059537667100147

Epoch: 5| Step: 1
Training loss: 2.889915943145752
Validation loss: 2.2999618181618313

Epoch: 5| Step: 2
Training loss: 2.3936729431152344
Validation loss: 2.2887773539430354

Epoch: 5| Step: 3
Training loss: 2.9273242950439453
Validation loss: 2.309863341751919

Epoch: 5| Step: 4
Training loss: 2.9819188117980957
Validation loss: 2.3069979260044713

Epoch: 5| Step: 5
Training loss: 2.620105028152466
Validation loss: 2.3137069440657094

Epoch: 5| Step: 6
Training loss: 2.1282267570495605
Validation loss: 2.319581142035864

Epoch: 5| Step: 7
Training loss: 2.103677272796631
Validation loss: 2.3150345586961314

Epoch: 5| Step: 8
Training loss: 2.666883945465088
Validation loss: 2.3189009722842964

Epoch: 5| Step: 9
Training loss: 2.1605279445648193
Validation loss: 2.3178838760622087

Epoch: 5| Step: 10
Training loss: 2.3945770263671875
Validation loss: 2.3222114578370125

Epoch: 162| Step: 0
Training loss: 2.660757303237915
Validation loss: 2.308080409162788

Epoch: 5| Step: 1
Training loss: 2.0250773429870605
Validation loss: 2.3138634748356317

Epoch: 5| Step: 2
Training loss: 2.4279983043670654
Validation loss: 2.3140663100827124

Epoch: 5| Step: 3
Training loss: 2.4543769359588623
Validation loss: 2.297628777001494

Epoch: 5| Step: 4
Training loss: 2.790048122406006
Validation loss: 2.3046040509336736

Epoch: 5| Step: 5
Training loss: 2.217961311340332
Validation loss: 2.297732449346973

Epoch: 5| Step: 6
Training loss: 2.518554925918579
Validation loss: 2.2870605530277377

Epoch: 5| Step: 7
Training loss: 2.826198101043701
Validation loss: 2.2909103285881782

Epoch: 5| Step: 8
Training loss: 2.935934543609619
Validation loss: 2.2993350900629514

Epoch: 5| Step: 9
Training loss: 2.287166118621826
Validation loss: 2.2981277358147407

Epoch: 5| Step: 10
Training loss: 2.7607908248901367
Validation loss: 2.305133710625351

Epoch: 163| Step: 0
Training loss: 2.3568384647369385
Validation loss: 2.30672743756284

Epoch: 5| Step: 1
Training loss: 3.076540231704712
Validation loss: 2.302051116061467

Epoch: 5| Step: 2
Training loss: 2.558723211288452
Validation loss: 2.3010188020685667

Epoch: 5| Step: 3
Training loss: 3.138267755508423
Validation loss: 2.2974142951350056

Epoch: 5| Step: 4
Training loss: 2.3072128295898438
Validation loss: 2.295857121867518

Epoch: 5| Step: 5
Training loss: 2.385450839996338
Validation loss: 2.298461898680656

Epoch: 5| Step: 6
Training loss: 2.2162368297576904
Validation loss: 2.297810067412674

Epoch: 5| Step: 7
Training loss: 1.9095675945281982
Validation loss: 2.3018452967366865

Epoch: 5| Step: 8
Training loss: 2.7942728996276855
Validation loss: 2.3109642638955066

Epoch: 5| Step: 9
Training loss: 2.197580575942993
Validation loss: 2.330328392726119

Epoch: 5| Step: 10
Training loss: 3.1443090438842773
Validation loss: 2.3317789108522478

Epoch: 164| Step: 0
Training loss: 2.117701768875122
Validation loss: 2.3307137438046035

Epoch: 5| Step: 1
Training loss: 2.9540257453918457
Validation loss: 2.324819034145724

Epoch: 5| Step: 2
Training loss: 2.847196102142334
Validation loss: 2.297147612417898

Epoch: 5| Step: 3
Training loss: 2.1000137329101562
Validation loss: 2.2918872230796405

Epoch: 5| Step: 4
Training loss: 3.0698132514953613
Validation loss: 2.286546427716491

Epoch: 5| Step: 5
Training loss: 2.4047279357910156
Validation loss: 2.2988091438047347

Epoch: 5| Step: 6
Training loss: 2.648998737335205
Validation loss: 2.3049085832411245

Epoch: 5| Step: 7
Training loss: 2.3546547889709473
Validation loss: 2.303347131257416

Epoch: 5| Step: 8
Training loss: 2.5962491035461426
Validation loss: 2.3124586202765025

Epoch: 5| Step: 9
Training loss: 2.308281660079956
Validation loss: 2.319979635618066

Epoch: 5| Step: 10
Training loss: 2.720541000366211
Validation loss: 2.322223191620201

Epoch: 165| Step: 0
Training loss: 2.312464475631714
Validation loss: 2.3244934979305474

Epoch: 5| Step: 1
Training loss: 2.021789073944092
Validation loss: 2.323576342674994

Epoch: 5| Step: 2
Training loss: 2.8559727668762207
Validation loss: 2.3178815046946206

Epoch: 5| Step: 3
Training loss: 2.2606008052825928
Validation loss: 2.32411713241249

Epoch: 5| Step: 4
Training loss: 1.936497688293457
Validation loss: 2.333162825594666

Epoch: 5| Step: 5
Training loss: 2.5619354248046875
Validation loss: 2.3349312249050347

Epoch: 5| Step: 6
Training loss: 2.3814761638641357
Validation loss: 2.331515810822928

Epoch: 5| Step: 7
Training loss: 2.991886615753174
Validation loss: 2.3320289286234046

Epoch: 5| Step: 8
Training loss: 2.889599561691284
Validation loss: 2.3285314370227117

Epoch: 5| Step: 9
Training loss: 3.2251086235046387
Validation loss: 2.3222480499616234

Epoch: 5| Step: 10
Training loss: 2.6644463539123535
Validation loss: 2.308671589820616

Epoch: 166| Step: 0
Training loss: 3.062901258468628
Validation loss: 2.3026370848378828

Epoch: 5| Step: 1
Training loss: 2.7917227745056152
Validation loss: 2.2998478848447084

Epoch: 5| Step: 2
Training loss: 2.408226490020752
Validation loss: 2.304391409761162

Epoch: 5| Step: 3
Training loss: 2.717461109161377
Validation loss: 2.307640811448456

Epoch: 5| Step: 4
Training loss: 3.172483444213867
Validation loss: 2.303089808392268

Epoch: 5| Step: 5
Training loss: 1.8644390106201172
Validation loss: 2.3020141457998626

Epoch: 5| Step: 6
Training loss: 2.2564520835876465
Validation loss: 2.305265398435695

Epoch: 5| Step: 7
Training loss: 1.9924719333648682
Validation loss: 2.3042096373855427

Epoch: 5| Step: 8
Training loss: 1.7133500576019287
Validation loss: 2.301611328637728

Epoch: 5| Step: 9
Training loss: 3.2930972576141357
Validation loss: 2.2964505636563866

Epoch: 5| Step: 10
Training loss: 2.609677314758301
Validation loss: 2.287689562766783

Epoch: 167| Step: 0
Training loss: 2.5361907482147217
Validation loss: 2.282714246421732

Epoch: 5| Step: 1
Training loss: 2.2365479469299316
Validation loss: 2.2878125841899584

Epoch: 5| Step: 2
Training loss: 2.878983974456787
Validation loss: 2.280572168288692

Epoch: 5| Step: 3
Training loss: 2.587398052215576
Validation loss: 2.2851051156238844

Epoch: 5| Step: 4
Training loss: 2.450608730316162
Validation loss: 2.2855163261454594

Epoch: 5| Step: 5
Training loss: 2.1548495292663574
Validation loss: 2.2881996016348563

Epoch: 5| Step: 6
Training loss: 2.920778751373291
Validation loss: 2.2902230985703005

Epoch: 5| Step: 7
Training loss: 2.4487507343292236
Validation loss: 2.296082312060941

Epoch: 5| Step: 8
Training loss: 3.164088487625122
Validation loss: 2.2988140647129347

Epoch: 5| Step: 9
Training loss: 2.02892804145813
Validation loss: 2.2971811525283323

Epoch: 5| Step: 10
Training loss: 2.45708966255188
Validation loss: 2.3001851779158398

Epoch: 168| Step: 0
Training loss: 2.9340291023254395
Validation loss: 2.302867934268008

Epoch: 5| Step: 1
Training loss: 2.30104398727417
Validation loss: 2.300399434181952

Epoch: 5| Step: 2
Training loss: 2.0223381519317627
Validation loss: 2.30287084784559

Epoch: 5| Step: 3
Training loss: 2.6425089836120605
Validation loss: 2.299007531135313

Epoch: 5| Step: 4
Training loss: 2.3832974433898926
Validation loss: 2.303157698723578

Epoch: 5| Step: 5
Training loss: 2.2737700939178467
Validation loss: 2.315002574715563

Epoch: 5| Step: 6
Training loss: 1.868914246559143
Validation loss: 2.317195964115922

Epoch: 5| Step: 7
Training loss: 3.0480568408966064
Validation loss: 2.3051631091743388

Epoch: 5| Step: 8
Training loss: 2.6151809692382812
Validation loss: 2.3169952233632407

Epoch: 5| Step: 9
Training loss: 3.3238539695739746
Validation loss: 2.3225394474562777

Epoch: 5| Step: 10
Training loss: 2.51981520652771
Validation loss: 2.312043523275724

Epoch: 169| Step: 0
Training loss: 2.3950653076171875
Validation loss: 2.309947867547312

Epoch: 5| Step: 1
Training loss: 2.2903823852539062
Validation loss: 2.3108163392671974

Epoch: 5| Step: 2
Training loss: 2.591351270675659
Validation loss: 2.29964542388916

Epoch: 5| Step: 3
Training loss: 2.9319581985473633
Validation loss: 2.295785132274833

Epoch: 5| Step: 4
Training loss: 2.191753387451172
Validation loss: 2.298634503477363

Epoch: 5| Step: 5
Training loss: 2.2375240325927734
Validation loss: 2.282857515478647

Epoch: 5| Step: 6
Training loss: 2.84496808052063
Validation loss: 2.2870423998883975

Epoch: 5| Step: 7
Training loss: 2.4132680892944336
Validation loss: 2.278679810544496

Epoch: 5| Step: 8
Training loss: 2.6901466846466064
Validation loss: 2.2771100023741364

Epoch: 5| Step: 9
Training loss: 2.6295790672302246
Validation loss: 2.271829464102304

Epoch: 5| Step: 10
Training loss: 2.7086853981018066
Validation loss: 2.2761267885085075

Epoch: 170| Step: 0
Training loss: 2.976842164993286
Validation loss: 2.272673140289963

Epoch: 5| Step: 1
Training loss: 2.737300395965576
Validation loss: 2.274328993212792

Epoch: 5| Step: 2
Training loss: 2.6477959156036377
Validation loss: 2.2702753005489225

Epoch: 5| Step: 3
Training loss: 2.198856830596924
Validation loss: 2.2742143625854165

Epoch: 5| Step: 4
Training loss: 1.9570376873016357
Validation loss: 2.2710394269676617

Epoch: 5| Step: 5
Training loss: 2.85014271736145
Validation loss: 2.272385399828675

Epoch: 5| Step: 6
Training loss: 3.1918349266052246
Validation loss: 2.2755295563769597

Epoch: 5| Step: 7
Training loss: 2.7410190105438232
Validation loss: 2.283817570696595

Epoch: 5| Step: 8
Training loss: 1.430545687675476
Validation loss: 2.2853323951844247

Epoch: 5| Step: 9
Training loss: 2.5510458946228027
Validation loss: 2.2903889366375503

Epoch: 5| Step: 10
Training loss: 2.64825177192688
Validation loss: 2.2885058874725015

Epoch: 171| Step: 0
Training loss: 3.0511155128479004
Validation loss: 2.2839753371413036

Epoch: 5| Step: 1
Training loss: 2.7395875453948975
Validation loss: 2.2916703736910256

Epoch: 5| Step: 2
Training loss: 2.4930367469787598
Validation loss: 2.2994122889734085

Epoch: 5| Step: 3
Training loss: 2.684927463531494
Validation loss: 2.3099891088342153

Epoch: 5| Step: 4
Training loss: 2.194096326828003
Validation loss: 2.31378996756769

Epoch: 5| Step: 5
Training loss: 2.427022933959961
Validation loss: 2.312895997878044

Epoch: 5| Step: 6
Training loss: 3.1511635780334473
Validation loss: 2.323377316997897

Epoch: 5| Step: 7
Training loss: 2.1743524074554443
Validation loss: 2.3223405832885415

Epoch: 5| Step: 8
Training loss: 2.0279784202575684
Validation loss: 2.314853637449203

Epoch: 5| Step: 9
Training loss: 2.2008960247039795
Validation loss: 2.3136304040108957

Epoch: 5| Step: 10
Training loss: 2.728607416152954
Validation loss: 2.311243187996649

Epoch: 172| Step: 0
Training loss: 2.23140549659729
Validation loss: 2.3101550994380826

Epoch: 5| Step: 1
Training loss: 2.4355826377868652
Validation loss: 2.299766145726686

Epoch: 5| Step: 2
Training loss: 2.528769016265869
Validation loss: 2.2879349698302565

Epoch: 5| Step: 3
Training loss: 2.1573598384857178
Validation loss: 2.2986807284816617

Epoch: 5| Step: 4
Training loss: 1.8586612939834595
Validation loss: 2.2917719989694576

Epoch: 5| Step: 5
Training loss: 3.0210800170898438
Validation loss: 2.2832846795358965

Epoch: 5| Step: 6
Training loss: 3.011040449142456
Validation loss: 2.291180085110408

Epoch: 5| Step: 7
Training loss: 3.020836591720581
Validation loss: 2.2878201559025753

Epoch: 5| Step: 8
Training loss: 2.5251784324645996
Validation loss: 2.295352651226905

Epoch: 5| Step: 9
Training loss: 2.411963939666748
Validation loss: 2.2789461766519854

Epoch: 5| Step: 10
Training loss: 2.593306541442871
Validation loss: 2.280114007252519

Epoch: 173| Step: 0
Training loss: 2.1037840843200684
Validation loss: 2.280583180407042

Epoch: 5| Step: 1
Training loss: 2.3837220668792725
Validation loss: 2.2902902121184976

Epoch: 5| Step: 2
Training loss: 2.794363021850586
Validation loss: 2.277953355543075

Epoch: 5| Step: 3
Training loss: 2.7675671577453613
Validation loss: 2.273555750487953

Epoch: 5| Step: 4
Training loss: 2.676884889602661
Validation loss: 2.2821057483714116

Epoch: 5| Step: 5
Training loss: 2.4794394969940186
Validation loss: 2.2799623576543664

Epoch: 5| Step: 6
Training loss: 2.7491455078125
Validation loss: 2.286647983776626

Epoch: 5| Step: 7
Training loss: 2.745893955230713
Validation loss: 2.2811889827892347

Epoch: 5| Step: 8
Training loss: 2.323578357696533
Validation loss: 2.2791440871454056

Epoch: 5| Step: 9
Training loss: 1.7591785192489624
Validation loss: 2.2849987065920265

Epoch: 5| Step: 10
Training loss: 2.9757232666015625
Validation loss: 2.291899452927292

Epoch: 174| Step: 0
Training loss: 2.65834379196167
Validation loss: 2.2920502360149095

Epoch: 5| Step: 1
Training loss: 2.3943448066711426
Validation loss: 2.292364501184033

Epoch: 5| Step: 2
Training loss: 2.8598082065582275
Validation loss: 2.2911183782803115

Epoch: 5| Step: 3
Training loss: 2.1055779457092285
Validation loss: 2.277145137069046

Epoch: 5| Step: 4
Training loss: 2.514907121658325
Validation loss: 2.27908137536818

Epoch: 5| Step: 5
Training loss: 2.0241568088531494
Validation loss: 2.2836630703300558

Epoch: 5| Step: 6
Training loss: 3.171067237854004
Validation loss: 2.2806489800894134

Epoch: 5| Step: 7
Training loss: 2.542675495147705
Validation loss: 2.285891625189012

Epoch: 5| Step: 8
Training loss: 2.785707473754883
Validation loss: 2.276065811034172

Epoch: 5| Step: 9
Training loss: 2.196077346801758
Validation loss: 2.2807709222198813

Epoch: 5| Step: 10
Training loss: 2.484431505203247
Validation loss: 2.2743721700483754

Epoch: 175| Step: 0
Training loss: 2.440114974975586
Validation loss: 2.283995227147174

Epoch: 5| Step: 1
Training loss: 2.779711961746216
Validation loss: 2.2868362395994124

Epoch: 5| Step: 2
Training loss: 1.9566516876220703
Validation loss: 2.2891706497438493

Epoch: 5| Step: 3
Training loss: 2.5393550395965576
Validation loss: 2.2963401732906217

Epoch: 5| Step: 4
Training loss: 2.2519257068634033
Validation loss: 2.2912410946302515

Epoch: 5| Step: 5
Training loss: 2.6777615547180176
Validation loss: 2.300525385846374

Epoch: 5| Step: 6
Training loss: 2.6667237281799316
Validation loss: 2.298811299826509

Epoch: 5| Step: 7
Training loss: 2.4420957565307617
Validation loss: 2.299548227299926

Epoch: 5| Step: 8
Training loss: 2.7319319248199463
Validation loss: 2.301415697220833

Epoch: 5| Step: 9
Training loss: 2.8128883838653564
Validation loss: 2.2996273527863207

Epoch: 5| Step: 10
Training loss: 2.3652892112731934
Validation loss: 2.297464783473681

Testing loss: 2.470190829700894
