Epoch: 1| Step: 0
Training loss: 6.24655086712625
Validation loss: 5.906415590524918

Epoch: 5| Step: 1
Training loss: 5.2841278000305465
Validation loss: 5.905020812964523

Epoch: 5| Step: 2
Training loss: 6.107002129204108
Validation loss: 5.903702706319784

Epoch: 5| Step: 3
Training loss: 5.60738530906094
Validation loss: 5.9022893257249125

Epoch: 5| Step: 4
Training loss: 6.775990780388371
Validation loss: 5.9010108706778155

Epoch: 5| Step: 5
Training loss: 5.680027003156922
Validation loss: 5.899671931493851

Epoch: 5| Step: 6
Training loss: 6.420085574141273
Validation loss: 5.898189312090184

Epoch: 5| Step: 7
Training loss: 6.235750969123589
Validation loss: 5.896769171895387

Epoch: 5| Step: 8
Training loss: 5.90029429332154
Validation loss: 5.895239071052115

Epoch: 5| Step: 9
Training loss: 6.199287668961577
Validation loss: 5.8935962809327815

Epoch: 5| Step: 10
Training loss: 5.580145803754783
Validation loss: 5.891961004394902

Epoch: 5| Step: 11
Training loss: 5.9300622231112134
Validation loss: 5.8902531244218315

Epoch: 2| Step: 0
Training loss: 6.655057271915883
Validation loss: 5.8884977417225395

Epoch: 5| Step: 1
Training loss: 5.9237508495207045
Validation loss: 5.886658247797308

Epoch: 5| Step: 2
Training loss: 6.396143239949154
Validation loss: 5.884624659718114

Epoch: 5| Step: 3
Training loss: 6.1658587914604785
Validation loss: 5.8826275070709375

Epoch: 5| Step: 4
Training loss: 5.610479304599898
Validation loss: 5.880537831952421

Epoch: 5| Step: 5
Training loss: 5.52580312009669
Validation loss: 5.878301849219632

Epoch: 5| Step: 6
Training loss: 5.5914603720680365
Validation loss: 5.876141673955093

Epoch: 5| Step: 7
Training loss: 6.539278926936619
Validation loss: 5.873734831702805

Epoch: 5| Step: 8
Training loss: 6.022147628084466
Validation loss: 5.871327327668169

Epoch: 5| Step: 9
Training loss: 5.700818575255532
Validation loss: 5.868707716426931

Epoch: 5| Step: 10
Training loss: 5.95068629818726
Validation loss: 5.8659966788852085

Epoch: 5| Step: 11
Training loss: 4.438859972954438
Validation loss: 5.863189337355421

Epoch: 3| Step: 0
Training loss: 6.177328361124439
Validation loss: 5.8603253013557675

Epoch: 5| Step: 1
Training loss: 5.946172865021892
Validation loss: 5.857112091511994

Epoch: 5| Step: 2
Training loss: 5.0806153749216865
Validation loss: 5.853955297851355

Epoch: 5| Step: 3
Training loss: 6.525721788495112
Validation loss: 5.8505618398891

Epoch: 5| Step: 4
Training loss: 6.065075514056765
Validation loss: 5.846961160823839

Epoch: 5| Step: 5
Training loss: 6.1126984047235124
Validation loss: 5.84325146376029

Epoch: 5| Step: 6
Training loss: 5.4791547922602835
Validation loss: 5.8392215052782905

Epoch: 5| Step: 7
Training loss: 5.419736588893704
Validation loss: 5.835088250169227

Epoch: 5| Step: 8
Training loss: 6.384817903292397
Validation loss: 5.830822188427745

Epoch: 5| Step: 9
Training loss: 6.355418931312118
Validation loss: 5.826390319337039

Epoch: 5| Step: 10
Training loss: 5.781271774663385
Validation loss: 5.82161939998033

Epoch: 5| Step: 11
Training loss: 6.095833916011147
Validation loss: 5.816669663954056

Epoch: 4| Step: 0
Training loss: 5.894432233885065
Validation loss: 5.811338014571382

Epoch: 5| Step: 1
Training loss: 5.617827695991626
Validation loss: 5.806093630072654

Epoch: 5| Step: 2
Training loss: 5.844773146874713
Validation loss: 5.800564382761316

Epoch: 5| Step: 3
Training loss: 6.471800743572221
Validation loss: 5.794801997723496

Epoch: 5| Step: 4
Training loss: 6.04933451625876
Validation loss: 5.788915813336246

Epoch: 5| Step: 5
Training loss: 5.744314617179545
Validation loss: 5.782941478001073

Epoch: 5| Step: 6
Training loss: 5.957072233465578
Validation loss: 5.776330624763212

Epoch: 5| Step: 7
Training loss: 6.011241237025578
Validation loss: 5.770103045732897

Epoch: 5| Step: 8
Training loss: 6.001979183558791
Validation loss: 5.763377956995717

Epoch: 5| Step: 9
Training loss: 5.684903065468182
Validation loss: 5.7567230532781375

Epoch: 5| Step: 10
Training loss: 5.4833346953385504
Validation loss: 5.749486381977082

Epoch: 5| Step: 11
Training loss: 6.135091137197454
Validation loss: 5.742459321454366

Epoch: 5| Step: 0
Training loss: 5.767869465952704
Validation loss: 5.7352351375978285

Epoch: 5| Step: 1
Training loss: 6.511787876432727
Validation loss: 5.728033441539195

Epoch: 5| Step: 2
Training loss: 6.241682392638716
Validation loss: 5.720185056362726

Epoch: 5| Step: 3
Training loss: 5.226967378224439
Validation loss: 5.712603881247552

Epoch: 5| Step: 4
Training loss: 5.9191395422935065
Validation loss: 5.704563778061794

Epoch: 5| Step: 5
Training loss: 4.9545101310864315
Validation loss: 5.6967203277945915

Epoch: 5| Step: 6
Training loss: 6.035537381776075
Validation loss: 5.689013856063279

Epoch: 5| Step: 7
Training loss: 6.301705677497226
Validation loss: 5.680816468224101

Epoch: 5| Step: 8
Training loss: 6.1611302584843735
Validation loss: 5.6726107369748355

Epoch: 5| Step: 9
Training loss: 4.9751315612266644
Validation loss: 5.664464047985709

Epoch: 5| Step: 10
Training loss: 5.979845529047513
Validation loss: 5.6558978426006465

Epoch: 5| Step: 11
Training loss: 3.3944558156085423
Validation loss: 5.647836916182353

Epoch: 6| Step: 0
Training loss: 5.366875651932478
Validation loss: 5.639799401050372

Epoch: 5| Step: 1
Training loss: 6.053351036975757
Validation loss: 5.632187976685803

Epoch: 5| Step: 2
Training loss: 5.167564601189878
Validation loss: 5.62428650039581

Epoch: 5| Step: 3
Training loss: 5.763481920370319
Validation loss: 5.616912891677099

Epoch: 5| Step: 4
Training loss: 5.927537772172131
Validation loss: 5.609038524400399

Epoch: 5| Step: 5
Training loss: 5.925216657966834
Validation loss: 5.601492377231992

Epoch: 5| Step: 6
Training loss: 6.249829404410053
Validation loss: 5.593768306254689

Epoch: 5| Step: 7
Training loss: 6.075896572937944
Validation loss: 5.586753910042788

Epoch: 5| Step: 8
Training loss: 5.9110859444129495
Validation loss: 5.579024576263259

Epoch: 5| Step: 9
Training loss: 5.2949728462020085
Validation loss: 5.572233035739605

Epoch: 5| Step: 10
Training loss: 5.504205309808974
Validation loss: 5.565076081474766

Epoch: 5| Step: 11
Training loss: 2.839666599798338
Validation loss: 5.557551193493441

Epoch: 7| Step: 0
Training loss: 5.560578603757826
Validation loss: 5.55128855739329

Epoch: 5| Step: 1
Training loss: 5.823953808003947
Validation loss: 5.544348615104039

Epoch: 5| Step: 2
Training loss: 5.849506011711988
Validation loss: 5.537753453995158

Epoch: 5| Step: 3
Training loss: 5.485171181468692
Validation loss: 5.531065612708181

Epoch: 5| Step: 4
Training loss: 4.523103111965789
Validation loss: 5.52433260256944

Epoch: 5| Step: 5
Training loss: 5.562682931013704
Validation loss: 5.51781708236475

Epoch: 5| Step: 6
Training loss: 5.352963184910652
Validation loss: 5.511481366721933

Epoch: 5| Step: 7
Training loss: 6.79067745688796
Validation loss: 5.504877608033268

Epoch: 5| Step: 8
Training loss: 5.610625316292235
Validation loss: 5.498271916302668

Epoch: 5| Step: 9
Training loss: 5.958545209767708
Validation loss: 5.492031451523037

Epoch: 5| Step: 10
Training loss: 5.436237583282177
Validation loss: 5.485576545113355

Epoch: 5| Step: 11
Training loss: 4.535809767997865
Validation loss: 5.479254909235105

Epoch: 8| Step: 0
Training loss: 5.375092793927837
Validation loss: 5.473308349212391

Epoch: 5| Step: 1
Training loss: 6.45248978931398
Validation loss: 5.467427905897705

Epoch: 5| Step: 2
Training loss: 4.94997712717648
Validation loss: 5.461110641216018

Epoch: 5| Step: 3
Training loss: 5.804172251694788
Validation loss: 5.455628651957769

Epoch: 5| Step: 4
Training loss: 5.8111931757160065
Validation loss: 5.4496807454011895

Epoch: 5| Step: 5
Training loss: 5.454967285953264
Validation loss: 5.444024961340056

Epoch: 5| Step: 6
Training loss: 5.464748815294058
Validation loss: 5.438624853951805

Epoch: 5| Step: 7
Training loss: 5.217425698014936
Validation loss: 5.433059128568554

Epoch: 5| Step: 8
Training loss: 5.653088439519525
Validation loss: 5.427353611205865

Epoch: 5| Step: 9
Training loss: 5.881079592045048
Validation loss: 5.422014613923712

Epoch: 5| Step: 10
Training loss: 4.926748617899002
Validation loss: 5.416833481298498

Epoch: 5| Step: 11
Training loss: 5.807280791633128
Validation loss: 5.411343279274199

Epoch: 9| Step: 0
Training loss: 4.604837130007584
Validation loss: 5.4059712920626835

Epoch: 5| Step: 1
Training loss: 5.865520865359926
Validation loss: 5.400289781765947

Epoch: 5| Step: 2
Training loss: 5.507076046453408
Validation loss: 5.395115044798727

Epoch: 5| Step: 3
Training loss: 5.832404725775973
Validation loss: 5.3899021861933045

Epoch: 5| Step: 4
Training loss: 5.563083918065892
Validation loss: 5.38393726602729

Epoch: 5| Step: 5
Training loss: 5.390986422157066
Validation loss: 5.378636372097611

Epoch: 5| Step: 6
Training loss: 5.885227796736709
Validation loss: 5.372937494271853

Epoch: 5| Step: 7
Training loss: 5.681330761896742
Validation loss: 5.367531415127514

Epoch: 5| Step: 8
Training loss: 6.261580457962907
Validation loss: 5.3619391532641325

Epoch: 5| Step: 9
Training loss: 5.097015644614534
Validation loss: 5.356596379336245

Epoch: 5| Step: 10
Training loss: 4.671578184159277
Validation loss: 5.3510715602846455

Epoch: 5| Step: 11
Training loss: 4.937562000513121
Validation loss: 5.346036462747708

Epoch: 10| Step: 0
Training loss: 4.7474169483925435
Validation loss: 5.340660972169012

Epoch: 5| Step: 1
Training loss: 5.7375492800256325
Validation loss: 5.335590937741313

Epoch: 5| Step: 2
Training loss: 5.633163800970937
Validation loss: 5.330482058504046

Epoch: 5| Step: 3
Training loss: 5.65849874907309
Validation loss: 5.32499754432538

Epoch: 5| Step: 4
Training loss: 5.548917152686893
Validation loss: 5.319742090957666

Epoch: 5| Step: 5
Training loss: 5.992268030851462
Validation loss: 5.314569832986423

Epoch: 5| Step: 6
Training loss: 5.2891355253105905
Validation loss: 5.308685915729104

Epoch: 5| Step: 7
Training loss: 4.61958511504354
Validation loss: 5.303096032499056

Epoch: 5| Step: 8
Training loss: 5.428926746671715
Validation loss: 5.297056639491117

Epoch: 5| Step: 9
Training loss: 5.7148243922689925
Validation loss: 5.290774595605805

Epoch: 5| Step: 10
Training loss: 5.400615953707814
Validation loss: 5.28414717893201

Epoch: 5| Step: 11
Training loss: 4.639505064974583
Validation loss: 5.277356316932456

Epoch: 11| Step: 0
Training loss: 5.32490563107539
Validation loss: 5.271236534930671

Epoch: 5| Step: 1
Training loss: 5.134103644566819
Validation loss: 5.264430671876682

Epoch: 5| Step: 2
Training loss: 6.541181833884115
Validation loss: 5.258110993949808

Epoch: 5| Step: 3
Training loss: 4.567940799215944
Validation loss: 5.251511371382196

Epoch: 5| Step: 4
Training loss: 5.351563925638496
Validation loss: 5.2452138398116785

Epoch: 5| Step: 5
Training loss: 5.455175675483845
Validation loss: 5.238271062292498

Epoch: 5| Step: 6
Training loss: 4.026463231975088
Validation loss: 5.231972852053189

Epoch: 5| Step: 7
Training loss: 5.288097028641416
Validation loss: 5.225395136893956

Epoch: 5| Step: 8
Training loss: 5.056240780589748
Validation loss: 5.218753365460374

Epoch: 5| Step: 9
Training loss: 5.633203924073343
Validation loss: 5.212600313070633

Epoch: 5| Step: 10
Training loss: 6.302716520252832
Validation loss: 5.205394482854529

Epoch: 5| Step: 11
Training loss: 4.3767990772896885
Validation loss: 5.198453438461815

Epoch: 12| Step: 0
Training loss: 6.199297206793227
Validation loss: 5.192104211354089

Epoch: 5| Step: 1
Training loss: 5.050880000424335
Validation loss: 5.186019264826341

Epoch: 5| Step: 2
Training loss: 5.083197211438964
Validation loss: 5.1792674865280155

Epoch: 5| Step: 3
Training loss: 5.726219760271162
Validation loss: 5.173413580836583

Epoch: 5| Step: 4
Training loss: 4.414108087084839
Validation loss: 5.166975868366113

Epoch: 5| Step: 5
Training loss: 5.481772476401426
Validation loss: 5.160987742733137

Epoch: 5| Step: 6
Training loss: 5.590936560609131
Validation loss: 5.155580573505414

Epoch: 5| Step: 7
Training loss: 5.09548621046798
Validation loss: 5.150018614207581

Epoch: 5| Step: 8
Training loss: 5.12614911850565
Validation loss: 5.144560400345113

Epoch: 5| Step: 9
Training loss: 5.100809833331423
Validation loss: 5.139056406068731

Epoch: 5| Step: 10
Training loss: 5.4283608990911105
Validation loss: 5.133319096215227

Epoch: 5| Step: 11
Training loss: 3.047104107972719
Validation loss: 5.127941156036816

Epoch: 13| Step: 0
Training loss: 5.276457107119462
Validation loss: 5.1231584651931055

Epoch: 5| Step: 1
Training loss: 4.800798135204745
Validation loss: 5.117720077794153

Epoch: 5| Step: 2
Training loss: 4.3585808143348554
Validation loss: 5.112900624826578

Epoch: 5| Step: 3
Training loss: 6.067558773527854
Validation loss: 5.107586142121171

Epoch: 5| Step: 4
Training loss: 5.3609716411538555
Validation loss: 5.102359991749154

Epoch: 5| Step: 5
Training loss: 4.847496306726348
Validation loss: 5.097880001687149

Epoch: 5| Step: 6
Training loss: 5.528475997934803
Validation loss: 5.092867355480386

Epoch: 5| Step: 7
Training loss: 5.542132174030481
Validation loss: 5.088909251726677

Epoch: 5| Step: 8
Training loss: 4.905944231552229
Validation loss: 5.083327538325441

Epoch: 5| Step: 9
Training loss: 5.618920665011855
Validation loss: 5.077983114754608

Epoch: 5| Step: 10
Training loss: 4.875567672151872
Validation loss: 5.073146895785561

Epoch: 5| Step: 11
Training loss: 5.35922659176352
Validation loss: 5.068273925060929

Epoch: 14| Step: 0
Training loss: 4.9004293526145055
Validation loss: 5.063144752668906

Epoch: 5| Step: 1
Training loss: 5.303622019399403
Validation loss: 5.0579193254796895

Epoch: 5| Step: 2
Training loss: 5.656740620447564
Validation loss: 5.053146473294984

Epoch: 5| Step: 3
Training loss: 5.270910491177578
Validation loss: 5.047420271479495

Epoch: 5| Step: 4
Training loss: 5.321459048687714
Validation loss: 5.041913888192648

Epoch: 5| Step: 5
Training loss: 4.989450005626129
Validation loss: 5.036617937948398

Epoch: 5| Step: 6
Training loss: 5.115489602321557
Validation loss: 5.031545373685186

Epoch: 5| Step: 7
Training loss: 5.481695058363847
Validation loss: 5.026618183915718

Epoch: 5| Step: 8
Training loss: 4.404962229745381
Validation loss: 5.021035671773715

Epoch: 5| Step: 9
Training loss: 5.276591577017715
Validation loss: 5.0159116447197

Epoch: 5| Step: 10
Training loss: 5.211716715189417
Validation loss: 5.010483845070722

Epoch: 5| Step: 11
Training loss: 3.6149062013394513
Validation loss: 5.006740866038021

Epoch: 15| Step: 0
Training loss: 5.677331574871698
Validation loss: 5.000807982964644

Epoch: 5| Step: 1
Training loss: 5.906421800163388
Validation loss: 4.99577279211951

Epoch: 5| Step: 2
Training loss: 5.001655304609946
Validation loss: 4.991051653621269

Epoch: 5| Step: 3
Training loss: 5.300917081842474
Validation loss: 4.985895959196318

Epoch: 5| Step: 4
Training loss: 4.8775888073773235
Validation loss: 4.9804958766622365

Epoch: 5| Step: 5
Training loss: 5.519487363258823
Validation loss: 4.97569295252106

Epoch: 5| Step: 6
Training loss: 5.342632868484155
Validation loss: 4.9697770870551645

Epoch: 5| Step: 7
Training loss: 4.2028579343446975
Validation loss: 4.9651574636730915

Epoch: 5| Step: 8
Training loss: 4.7158946309698395
Validation loss: 4.961603779742898

Epoch: 5| Step: 9
Training loss: 4.667508844041337
Validation loss: 4.956740887622163

Epoch: 5| Step: 10
Training loss: 4.656333973786616
Validation loss: 4.950700690065657

Epoch: 5| Step: 11
Training loss: 5.109770313333986
Validation loss: 4.946119362172252

Epoch: 16| Step: 0
Training loss: 5.256260545064575
Validation loss: 4.941136095706157

Epoch: 5| Step: 1
Training loss: 5.377955489116651
Validation loss: 4.936010047385089

Epoch: 5| Step: 2
Training loss: 5.210873444719682
Validation loss: 4.931788839498766

Epoch: 5| Step: 3
Training loss: 5.015589253425965
Validation loss: 4.926440867124199

Epoch: 5| Step: 4
Training loss: 5.32244068662779
Validation loss: 4.9220093885371226

Epoch: 5| Step: 5
Training loss: 4.244439919842699
Validation loss: 4.916593675017715

Epoch: 5| Step: 6
Training loss: 3.9016568454736693
Validation loss: 4.912566555177389

Epoch: 5| Step: 7
Training loss: 5.177197993011074
Validation loss: 4.909034246755618

Epoch: 5| Step: 8
Training loss: 5.1566838862191835
Validation loss: 4.903743306016919

Epoch: 5| Step: 9
Training loss: 5.273418330404973
Validation loss: 4.899008637005834

Epoch: 5| Step: 10
Training loss: 5.0827197137074505
Validation loss: 4.8928106703223575

Epoch: 5| Step: 11
Training loss: 6.046952279161386
Validation loss: 4.887120731204272

Epoch: 17| Step: 0
Training loss: 5.116151195162025
Validation loss: 4.882397573516241

Epoch: 5| Step: 1
Training loss: 5.56935366046299
Validation loss: 4.877321798933172

Epoch: 5| Step: 2
Training loss: 5.1857138626596875
Validation loss: 4.872556595738663

Epoch: 5| Step: 3
Training loss: 3.5314471434529433
Validation loss: 4.8674348918320165

Epoch: 5| Step: 4
Training loss: 5.172101249240725
Validation loss: 4.863497785167517

Epoch: 5| Step: 5
Training loss: 4.3472677573086465
Validation loss: 4.858724814335718

Epoch: 5| Step: 6
Training loss: 5.049651619253558
Validation loss: 4.854179172199606

Epoch: 5| Step: 7
Training loss: 4.5337244052127685
Validation loss: 4.849013555303114

Epoch: 5| Step: 8
Training loss: 4.956679167091463
Validation loss: 4.843996062232784

Epoch: 5| Step: 9
Training loss: 5.598349954834627
Validation loss: 4.8390286395266076

Epoch: 5| Step: 10
Training loss: 5.37749015434779
Validation loss: 4.832671525742701

Epoch: 5| Step: 11
Training loss: 5.052772123699347
Validation loss: 4.829151394249127

Epoch: 18| Step: 0
Training loss: 4.590896654498461
Validation loss: 4.824109371453719

Epoch: 5| Step: 1
Training loss: 4.65188209427571
Validation loss: 4.821460490314516

Epoch: 5| Step: 2
Training loss: 5.6258183201957905
Validation loss: 4.814794785948337

Epoch: 5| Step: 3
Training loss: 4.518166430767924
Validation loss: 4.810281593152257

Epoch: 5| Step: 4
Training loss: 3.9309519256004437
Validation loss: 4.805713244272228

Epoch: 5| Step: 5
Training loss: 4.757812099112257
Validation loss: 4.802104092082117

Epoch: 5| Step: 6
Training loss: 4.987393891011284
Validation loss: 4.797594130432302

Epoch: 5| Step: 7
Training loss: 5.848876988792746
Validation loss: 4.7924526841479995

Epoch: 5| Step: 8
Training loss: 4.878048457168941
Validation loss: 4.7867403607995875

Epoch: 5| Step: 9
Training loss: 4.405242588321657
Validation loss: 4.783105527568256

Epoch: 5| Step: 10
Training loss: 5.561884470969188
Validation loss: 4.778867148559046

Epoch: 5| Step: 11
Training loss: 5.400290672108467
Validation loss: 4.7733045685401345

Epoch: 19| Step: 0
Training loss: 4.992834297032794
Validation loss: 4.76803982114111

Epoch: 5| Step: 1
Training loss: 5.27704773700253
Validation loss: 4.7637489920496385

Epoch: 5| Step: 2
Training loss: 5.006252575515294
Validation loss: 4.759593027038151

Epoch: 5| Step: 3
Training loss: 4.315456095932151
Validation loss: 4.754126814001793

Epoch: 5| Step: 4
Training loss: 4.208686864122734
Validation loss: 4.749718975654974

Epoch: 5| Step: 5
Training loss: 5.178536633905487
Validation loss: 4.744497860278507

Epoch: 5| Step: 6
Training loss: 5.354529857068161
Validation loss: 4.740618610147266

Epoch: 5| Step: 7
Training loss: 4.804564038683077
Validation loss: 4.73539767325145

Epoch: 5| Step: 8
Training loss: 4.47272661312011
Validation loss: 4.731126537417052

Epoch: 5| Step: 9
Training loss: 5.583681731480296
Validation loss: 4.726550175254033

Epoch: 5| Step: 10
Training loss: 4.348366020511595
Validation loss: 4.721555233892838

Epoch: 5| Step: 11
Training loss: 3.8239500362452055
Validation loss: 4.716764516568074

Epoch: 20| Step: 0
Training loss: 4.51713140895541
Validation loss: 4.712288093018551

Epoch: 5| Step: 1
Training loss: 4.896101253023511
Validation loss: 4.707771650361412

Epoch: 5| Step: 2
Training loss: 4.711981561206951
Validation loss: 4.702456700357028

Epoch: 5| Step: 3
Training loss: 5.161051046685563
Validation loss: 4.698335948878861

Epoch: 5| Step: 4
Training loss: 4.900452316583082
Validation loss: 4.6933766551393505

Epoch: 5| Step: 5
Training loss: 5.239110825495228
Validation loss: 4.688910242507145

Epoch: 5| Step: 6
Training loss: 4.268225467564685
Validation loss: 4.683732837502689

Epoch: 5| Step: 7
Training loss: 4.4559822419393145
Validation loss: 4.679181673949246

Epoch: 5| Step: 8
Training loss: 4.79207945441606
Validation loss: 4.674489441190034

Epoch: 5| Step: 9
Training loss: 4.69934173194747
Validation loss: 4.669801734688252

Epoch: 5| Step: 10
Training loss: 5.378891534168777
Validation loss: 4.664651523629478

Epoch: 5| Step: 11
Training loss: 3.860360579573013
Validation loss: 4.659597861684542

Epoch: 21| Step: 0
Training loss: 5.308721657307494
Validation loss: 4.6550900339337735

Epoch: 5| Step: 1
Training loss: 4.292189828533906
Validation loss: 4.65067124324502

Epoch: 5| Step: 2
Training loss: 5.014358693400294
Validation loss: 4.645744804713477

Epoch: 5| Step: 3
Training loss: 5.43187870298081
Validation loss: 4.640443068340713

Epoch: 5| Step: 4
Training loss: 4.56774642505081
Validation loss: 4.635377616574967

Epoch: 5| Step: 5
Training loss: 4.615633578799365
Validation loss: 4.630975300016179

Epoch: 5| Step: 6
Training loss: 4.887405457033458
Validation loss: 4.625709273105787

Epoch: 5| Step: 7
Training loss: 5.062739237089312
Validation loss: 4.620979124933292

Epoch: 5| Step: 8
Training loss: 4.751943491821309
Validation loss: 4.615244973700955

Epoch: 5| Step: 9
Training loss: 4.67760450465594
Validation loss: 4.610672818684394

Epoch: 5| Step: 10
Training loss: 3.5611351477224558
Validation loss: 4.60566923671983

Epoch: 5| Step: 11
Training loss: 4.248522782250182
Validation loss: 4.600602231651045

Epoch: 22| Step: 0
Training loss: 4.742163367422121
Validation loss: 4.596499011933687

Epoch: 5| Step: 1
Training loss: 5.6054505457565895
Validation loss: 4.59160952535384

Epoch: 5| Step: 2
Training loss: 4.607196668139533
Validation loss: 4.586111885320787

Epoch: 5| Step: 3
Training loss: 4.82951734891659
Validation loss: 4.5810952993574405

Epoch: 5| Step: 4
Training loss: 4.661693898079286
Validation loss: 4.57573019325638

Epoch: 5| Step: 5
Training loss: 5.022520844875313
Validation loss: 4.5709813685455085

Epoch: 5| Step: 6
Training loss: 3.7782346193677885
Validation loss: 4.566707813235356

Epoch: 5| Step: 7
Training loss: 4.509845136533801
Validation loss: 4.561503149025722

Epoch: 5| Step: 8
Training loss: 4.904638523855007
Validation loss: 4.557441659548032

Epoch: 5| Step: 9
Training loss: 5.074970850367525
Validation loss: 4.551489368623402

Epoch: 5| Step: 10
Training loss: 4.02675810143782
Validation loss: 4.547095076051394

Epoch: 5| Step: 11
Training loss: 2.664006207450302
Validation loss: 4.543012238871363

Epoch: 23| Step: 0
Training loss: 4.276116181938984
Validation loss: 4.537287975293255

Epoch: 5| Step: 1
Training loss: 5.057807348682984
Validation loss: 4.532553772422376

Epoch: 5| Step: 2
Training loss: 5.252813765946476
Validation loss: 4.5280164208479485

Epoch: 5| Step: 3
Training loss: 4.46115341599293
Validation loss: 4.52373759713273

Epoch: 5| Step: 4
Training loss: 4.7850091654690745
Validation loss: 4.51912693335185

Epoch: 5| Step: 5
Training loss: 4.701934968058114
Validation loss: 4.513652859247049

Epoch: 5| Step: 6
Training loss: 4.9289588933876365
Validation loss: 4.508730318368276

Epoch: 5| Step: 7
Training loss: 4.141656250560002
Validation loss: 4.504887099380818

Epoch: 5| Step: 8
Training loss: 4.470339192401085
Validation loss: 4.499644238926145

Epoch: 5| Step: 9
Training loss: 4.5813158392240965
Validation loss: 4.494991928654865

Epoch: 5| Step: 10
Training loss: 4.6609800750496415
Validation loss: 4.489884999961178

Epoch: 5| Step: 11
Training loss: 2.201762975549477
Validation loss: 4.485698920991742

Epoch: 24| Step: 0
Training loss: 4.03791128608855
Validation loss: 4.481459455148451

Epoch: 5| Step: 1
Training loss: 4.756640761335405
Validation loss: 4.477192517607906

Epoch: 5| Step: 2
Training loss: 4.710904907316254
Validation loss: 4.472331494753028

Epoch: 5| Step: 3
Training loss: 4.895382648042127
Validation loss: 4.466815387446721

Epoch: 5| Step: 4
Training loss: 4.715081614235988
Validation loss: 4.462641099538775

Epoch: 5| Step: 5
Training loss: 5.310111193166209
Validation loss: 4.458609441722125

Epoch: 5| Step: 6
Training loss: 5.43681067997342
Validation loss: 4.453219612410374

Epoch: 5| Step: 7
Training loss: 3.776421356404552
Validation loss: 4.44794374170334

Epoch: 5| Step: 8
Training loss: 4.432002355843479
Validation loss: 4.4434045452574695

Epoch: 5| Step: 9
Training loss: 4.075067887004019
Validation loss: 4.4392970704267825

Epoch: 5| Step: 10
Training loss: 4.10515700008676
Validation loss: 4.43474544405304

Epoch: 5| Step: 11
Training loss: 4.054551550436433
Validation loss: 4.430016982503105

Epoch: 25| Step: 0
Training loss: 4.8921642867018535
Validation loss: 4.424921314164909

Epoch: 5| Step: 1
Training loss: 4.518760780332165
Validation loss: 4.419651676717805

Epoch: 5| Step: 2
Training loss: 4.106163017013577
Validation loss: 4.415320644161908

Epoch: 5| Step: 3
Training loss: 4.062641317403858
Validation loss: 4.410710649358318

Epoch: 5| Step: 4
Training loss: 4.407865620387329
Validation loss: 4.405724221281758

Epoch: 5| Step: 5
Training loss: 4.736833292969655
Validation loss: 4.400666696800329

Epoch: 5| Step: 6
Training loss: 4.388821594645199
Validation loss: 4.396316866322343

Epoch: 5| Step: 7
Training loss: 5.022587112423226
Validation loss: 4.391904194336128

Epoch: 5| Step: 8
Training loss: 3.7841868699528614
Validation loss: 4.38634562073151

Epoch: 5| Step: 9
Training loss: 5.0317022463911645
Validation loss: 4.381953385866732

Epoch: 5| Step: 10
Training loss: 4.707776579670777
Validation loss: 4.377099323682281

Epoch: 5| Step: 11
Training loss: 4.465491754293811
Validation loss: 4.372517880737084

Epoch: 26| Step: 0
Training loss: 3.817405421516253
Validation loss: 4.367933060681005

Epoch: 5| Step: 1
Training loss: 4.551559080521373
Validation loss: 4.363108140590189

Epoch: 5| Step: 2
Training loss: 4.766682091712447
Validation loss: 4.358714355579726

Epoch: 5| Step: 3
Training loss: 4.5793923976937885
Validation loss: 4.3538842756089995

Epoch: 5| Step: 4
Training loss: 4.69092160277684
Validation loss: 4.348988975675833

Epoch: 5| Step: 5
Training loss: 4.821585068357825
Validation loss: 4.3443413750394475

Epoch: 5| Step: 6
Training loss: 4.8958283552861435
Validation loss: 4.3397601119851235

Epoch: 5| Step: 7
Training loss: 4.053798100235825
Validation loss: 4.334745015158404

Epoch: 5| Step: 8
Training loss: 4.336286321132161
Validation loss: 4.329311102745337

Epoch: 5| Step: 9
Training loss: 4.535601611288007
Validation loss: 4.324884957784575

Epoch: 5| Step: 10
Training loss: 4.332423310214689
Validation loss: 4.32008787540405

Epoch: 5| Step: 11
Training loss: 2.654989145260333
Validation loss: 4.315278517293947

Epoch: 27| Step: 0
Training loss: 4.5724842095871505
Validation loss: 4.310858538500044

Epoch: 5| Step: 1
Training loss: 3.4577098115824123
Validation loss: 4.305597434130761

Epoch: 5| Step: 2
Training loss: 4.536065430238231
Validation loss: 4.3008656090718596

Epoch: 5| Step: 3
Training loss: 4.573222272504951
Validation loss: 4.296345339410822

Epoch: 5| Step: 4
Training loss: 5.231188906149937
Validation loss: 4.292125833200518

Epoch: 5| Step: 5
Training loss: 4.588229852560968
Validation loss: 4.287241305303198

Epoch: 5| Step: 6
Training loss: 4.296936700551327
Validation loss: 4.281874636633969

Epoch: 5| Step: 7
Training loss: 4.571017949361366
Validation loss: 4.277339458027956

Epoch: 5| Step: 8
Training loss: 4.001912136808156
Validation loss: 4.272272717208209

Epoch: 5| Step: 9
Training loss: 4.669587969359702
Validation loss: 4.267467319845353

Epoch: 5| Step: 10
Training loss: 4.255591584980775
Validation loss: 4.262385953941796

Epoch: 5| Step: 11
Training loss: 1.5979331972675477
Validation loss: 4.257777931936319

Epoch: 28| Step: 0
Training loss: 4.2540770777510915
Validation loss: 4.253085848674569

Epoch: 5| Step: 1
Training loss: 3.750051243749812
Validation loss: 4.2486024222912615

Epoch: 5| Step: 2
Training loss: 3.8551630055441763
Validation loss: 4.244334287126581

Epoch: 5| Step: 3
Training loss: 4.284738720258087
Validation loss: 4.240467900903788

Epoch: 5| Step: 4
Training loss: 4.577241884013834
Validation loss: 4.235188494026348

Epoch: 5| Step: 5
Training loss: 4.87427691452313
Validation loss: 4.230589818234766

Epoch: 5| Step: 6
Training loss: 4.666470977676605
Validation loss: 4.225593178395162

Epoch: 5| Step: 7
Training loss: 3.9303766636002506
Validation loss: 4.221228217807788

Epoch: 5| Step: 8
Training loss: 4.654325356278258
Validation loss: 4.2165170812020705

Epoch: 5| Step: 9
Training loss: 4.358309051465481
Validation loss: 4.2119504598437505

Epoch: 5| Step: 10
Training loss: 4.470600945274544
Validation loss: 4.2075520945403

Epoch: 5| Step: 11
Training loss: 5.001800975697482
Validation loss: 4.2025432822263955

Epoch: 29| Step: 0
Training loss: 3.9092153051556253
Validation loss: 4.19773909648374

Epoch: 5| Step: 1
Training loss: 4.524923815006857
Validation loss: 4.192964788455986

Epoch: 5| Step: 2
Training loss: 4.0058700881286535
Validation loss: 4.18772407425668

Epoch: 5| Step: 3
Training loss: 5.136727104615354
Validation loss: 4.183071465990613

Epoch: 5| Step: 4
Training loss: 3.5831026993687516
Validation loss: 4.177601240716903

Epoch: 5| Step: 5
Training loss: 4.556306580661843
Validation loss: 4.172832517240452

Epoch: 5| Step: 6
Training loss: 4.852927883490378
Validation loss: 4.167663086322425

Epoch: 5| Step: 7
Training loss: 3.822492917280702
Validation loss: 4.163361662764992

Epoch: 5| Step: 8
Training loss: 4.792997800059682
Validation loss: 4.1577687225464635

Epoch: 5| Step: 9
Training loss: 4.132102169727227
Validation loss: 4.152964160752607

Epoch: 5| Step: 10
Training loss: 3.9342114475909233
Validation loss: 4.1483053604220945

Epoch: 5| Step: 11
Training loss: 3.225103237658399
Validation loss: 4.144100472428961

Epoch: 30| Step: 0
Training loss: 4.349169965456367
Validation loss: 4.139527704485538

Epoch: 5| Step: 1
Training loss: 3.962492327276557
Validation loss: 4.134511861460513

Epoch: 5| Step: 2
Training loss: 4.251562168018983
Validation loss: 4.129814074613192

Epoch: 5| Step: 3
Training loss: 4.337897879960727
Validation loss: 4.125527194078869

Epoch: 5| Step: 4
Training loss: 4.926185101282696
Validation loss: 4.120472128028696

Epoch: 5| Step: 5
Training loss: 3.53742265920037
Validation loss: 4.115721642497132

Epoch: 5| Step: 6
Training loss: 4.138019245676353
Validation loss: 4.111288792655348

Epoch: 5| Step: 7
Training loss: 3.5115115366597798
Validation loss: 4.106813060065258

Epoch: 5| Step: 8
Training loss: 4.643402604140699
Validation loss: 4.101897840566581

Epoch: 5| Step: 9
Training loss: 4.118680100723377
Validation loss: 4.097169394430913

Epoch: 5| Step: 10
Training loss: 4.473323162614959
Validation loss: 4.092362447783346

Epoch: 5| Step: 11
Training loss: 5.379497686710919
Validation loss: 4.087645947284059

Epoch: 31| Step: 0
Training loss: 3.9952552788328797
Validation loss: 4.083024790194125

Epoch: 5| Step: 1
Training loss: 4.565372973411104
Validation loss: 4.078200645281113

Epoch: 5| Step: 2
Training loss: 3.491629536749197
Validation loss: 4.0724956590798325

Epoch: 5| Step: 3
Training loss: 4.361188395167038
Validation loss: 4.068035985211413

Epoch: 5| Step: 4
Training loss: 4.4509010517106695
Validation loss: 4.062828657109682

Epoch: 5| Step: 5
Training loss: 4.419121521866582
Validation loss: 4.058092328042936

Epoch: 5| Step: 6
Training loss: 3.678874385596105
Validation loss: 4.052616715159507

Epoch: 5| Step: 7
Training loss: 4.186961125104312
Validation loss: 4.0482355528500875

Epoch: 5| Step: 8
Training loss: 3.6406373117918163
Validation loss: 4.043114755055048

Epoch: 5| Step: 9
Training loss: 4.134426789597325
Validation loss: 4.038484828425358

Epoch: 5| Step: 10
Training loss: 4.944461212891756
Validation loss: 4.033126404211909

Epoch: 5| Step: 11
Training loss: 4.115634806396109
Validation loss: 4.028298078379296

Epoch: 32| Step: 0
Training loss: 4.11915081198361
Validation loss: 4.02351539314201

Epoch: 5| Step: 1
Training loss: 3.7954116324634497
Validation loss: 4.018181952814921

Epoch: 5| Step: 2
Training loss: 4.396209748891652
Validation loss: 4.01341232611509

Epoch: 5| Step: 3
Training loss: 3.7771642379947066
Validation loss: 4.00839418053128

Epoch: 5| Step: 4
Training loss: 4.174144570435655
Validation loss: 4.0044599891400985

Epoch: 5| Step: 5
Training loss: 4.447383565767033
Validation loss: 3.9982704705107652

Epoch: 5| Step: 6
Training loss: 3.8300360444367323
Validation loss: 3.9934558781993674

Epoch: 5| Step: 7
Training loss: 4.316290474974485
Validation loss: 3.9886966380653615

Epoch: 5| Step: 8
Training loss: 3.6759013724892777
Validation loss: 3.9842130889906215

Epoch: 5| Step: 9
Training loss: 4.121478340318774
Validation loss: 3.9790796333634573

Epoch: 5| Step: 10
Training loss: 4.555553007254366
Validation loss: 3.974322509410998

Epoch: 5| Step: 11
Training loss: 4.703662930264865
Validation loss: 3.9696008365955673

Epoch: 33| Step: 0
Training loss: 4.4705887859450435
Validation loss: 3.9641691489001727

Epoch: 5| Step: 1
Training loss: 3.858817118118767
Validation loss: 3.9589106774492637

Epoch: 5| Step: 2
Training loss: 3.6306500305269083
Validation loss: 3.9541147171697344

Epoch: 5| Step: 3
Training loss: 4.075078418187788
Validation loss: 3.948992201045148

Epoch: 5| Step: 4
Training loss: 4.415103323776142
Validation loss: 3.944100504119496

Epoch: 5| Step: 5
Training loss: 3.521236569640006
Validation loss: 3.939171138739638

Epoch: 5| Step: 6
Training loss: 3.681451524487106
Validation loss: 3.934381117650599

Epoch: 5| Step: 7
Training loss: 4.191784616761151
Validation loss: 3.930254269043404

Epoch: 5| Step: 8
Training loss: 4.188433642711143
Validation loss: 3.9253474462412457

Epoch: 5| Step: 9
Training loss: 4.374273403321612
Validation loss: 3.921036913157652

Epoch: 5| Step: 10
Training loss: 4.26798705492139
Validation loss: 3.915869411868674

Epoch: 5| Step: 11
Training loss: 4.012962557076389
Validation loss: 3.9105878827361367

Epoch: 34| Step: 0
Training loss: 4.3506713173791045
Validation loss: 3.905578123167328

Epoch: 5| Step: 1
Training loss: 3.8516076880351844
Validation loss: 3.8999787662205194

Epoch: 5| Step: 2
Training loss: 3.8038184957514214
Validation loss: 3.8959183641153827

Epoch: 5| Step: 3
Training loss: 4.357399988739298
Validation loss: 3.890788630219675

Epoch: 5| Step: 4
Training loss: 3.7138951772216373
Validation loss: 3.885921689195504

Epoch: 5| Step: 5
Training loss: 4.037853657731405
Validation loss: 3.8811257815997626

Epoch: 5| Step: 6
Training loss: 3.85773584560843
Validation loss: 3.876074887982262

Epoch: 5| Step: 7
Training loss: 3.916939475656604
Validation loss: 3.8714993312837906

Epoch: 5| Step: 8
Training loss: 4.203841251196195
Validation loss: 3.8668763597468647

Epoch: 5| Step: 9
Training loss: 3.8531088674784564
Validation loss: 3.8623128306563834

Epoch: 5| Step: 10
Training loss: 3.9818377625366765
Validation loss: 3.857350728469346

Epoch: 5| Step: 11
Training loss: 4.851538714904961
Validation loss: 3.852475360558049

Epoch: 35| Step: 0
Training loss: 4.156051286808668
Validation loss: 3.847812991491682

Epoch: 5| Step: 1
Training loss: 4.1754884536906935
Validation loss: 3.843534179252331

Epoch: 5| Step: 2
Training loss: 3.3034723451108396
Validation loss: 3.837920200276007

Epoch: 5| Step: 3
Training loss: 3.4046422681390514
Validation loss: 3.83359579901611

Epoch: 5| Step: 4
Training loss: 4.382034096637848
Validation loss: 3.829483564475459

Epoch: 5| Step: 5
Training loss: 4.170435739342047
Validation loss: 3.825045373227811

Epoch: 5| Step: 6
Training loss: 3.7047854535665095
Validation loss: 3.820426835193485

Epoch: 5| Step: 7
Training loss: 3.706186952102928
Validation loss: 3.8158418100688745

Epoch: 5| Step: 8
Training loss: 3.996389309122774
Validation loss: 3.8107732030725257

Epoch: 5| Step: 9
Training loss: 4.443406163902006
Validation loss: 3.806410326971374

Epoch: 5| Step: 10
Training loss: 3.8584341531740414
Validation loss: 3.801881213455102

Epoch: 5| Step: 11
Training loss: 4.2986502014804016
Validation loss: 3.7972421664818263

Epoch: 36| Step: 0
Training loss: 3.241652405485999
Validation loss: 3.792678172344226

Epoch: 5| Step: 1
Training loss: 4.297978152070891
Validation loss: 3.788493944227106

Epoch: 5| Step: 2
Training loss: 4.250295740945334
Validation loss: 3.7838153071376053

Epoch: 5| Step: 3
Training loss: 3.999046211969643
Validation loss: 3.7788456873377942

Epoch: 5| Step: 4
Training loss: 3.3139551673209438
Validation loss: 3.7745757719324144

Epoch: 5| Step: 5
Training loss: 3.613709064622573
Validation loss: 3.7696891527589442

Epoch: 5| Step: 6
Training loss: 3.8877020584044084
Validation loss: 3.7650896644216245

Epoch: 5| Step: 7
Training loss: 4.373466222845234
Validation loss: 3.7612265650757712

Epoch: 5| Step: 8
Training loss: 3.1206167379339043
Validation loss: 3.756261139195704

Epoch: 5| Step: 9
Training loss: 3.6443470277662997
Validation loss: 3.751926107605555

Epoch: 5| Step: 10
Training loss: 4.8929496334749505
Validation loss: 3.747247777386216

Epoch: 5| Step: 11
Training loss: 3.516269200961145
Validation loss: 3.7424656732072616

Epoch: 37| Step: 0
Training loss: 3.819532818012692
Validation loss: 3.737921691844095

Epoch: 5| Step: 1
Training loss: 3.928614323864875
Validation loss: 3.733541946386998

Epoch: 5| Step: 2
Training loss: 3.918968308982802
Validation loss: 3.729369310737278

Epoch: 5| Step: 3
Training loss: 3.424857455440721
Validation loss: 3.725246284970952

Epoch: 5| Step: 4
Training loss: 3.7591055630015315
Validation loss: 3.720378102601718

Epoch: 5| Step: 5
Training loss: 4.358159815371432
Validation loss: 3.7163263431683724

Epoch: 5| Step: 6
Training loss: 3.3261189750546
Validation loss: 3.711452675914209

Epoch: 5| Step: 7
Training loss: 3.8898774313555484
Validation loss: 3.7069782592287526

Epoch: 5| Step: 8
Training loss: 4.268376284056377
Validation loss: 3.702600170989579

Epoch: 5| Step: 9
Training loss: 3.6420176711515255
Validation loss: 3.6978845711331583

Epoch: 5| Step: 10
Training loss: 3.8256788262274855
Validation loss: 3.69346702145804

Epoch: 5| Step: 11
Training loss: 4.226868454441461
Validation loss: 3.689133573216649

Epoch: 38| Step: 0
Training loss: 3.4824980055124852
Validation loss: 3.684056765008552

Epoch: 5| Step: 1
Training loss: 3.931789192618036
Validation loss: 3.6795789482589636

Epoch: 5| Step: 2
Training loss: 3.8927998419827867
Validation loss: 3.6754699640085953

Epoch: 5| Step: 3
Training loss: 4.219905214736737
Validation loss: 3.6708561721564688

Epoch: 5| Step: 4
Training loss: 3.162832364797423
Validation loss: 3.665916255904223

Epoch: 5| Step: 5
Training loss: 3.4217572475012945
Validation loss: 3.661847467847989

Epoch: 5| Step: 6
Training loss: 3.9970976313429354
Validation loss: 3.657193086723044

Epoch: 5| Step: 7
Training loss: 4.011147225294565
Validation loss: 3.6526335358192554

Epoch: 5| Step: 8
Training loss: 3.7304337265208005
Validation loss: 3.6481714253741733

Epoch: 5| Step: 9
Training loss: 3.7430892845305967
Validation loss: 3.643850782951595

Epoch: 5| Step: 10
Training loss: 3.7937909697531014
Validation loss: 3.6393611553369256

Epoch: 5| Step: 11
Training loss: 4.962051578891742
Validation loss: 3.6350645051407366

Epoch: 39| Step: 0
Training loss: 3.5345119837650723
Validation loss: 3.6304580879862076

Epoch: 5| Step: 1
Training loss: 3.5952247579081185
Validation loss: 3.6256428017102795

Epoch: 5| Step: 2
Training loss: 3.5573123840056415
Validation loss: 3.621513767566851

Epoch: 5| Step: 3
Training loss: 4.237100660023765
Validation loss: 3.6166372793881747

Epoch: 5| Step: 4
Training loss: 4.240627500776482
Validation loss: 3.612210991242341

Epoch: 5| Step: 5
Training loss: 3.6642168415154566
Validation loss: 3.60752558150356

Epoch: 5| Step: 6
Training loss: 3.828457191222968
Validation loss: 3.6028664546070632

Epoch: 5| Step: 7
Training loss: 3.804663687441524
Validation loss: 3.5986212238071684

Epoch: 5| Step: 8
Training loss: 3.5599021139510403
Validation loss: 3.593836020393843

Epoch: 5| Step: 9
Training loss: 3.4663327704313405
Validation loss: 3.589466798823902

Epoch: 5| Step: 10
Training loss: 3.481654041341044
Validation loss: 3.5848664378935378

Epoch: 5| Step: 11
Training loss: 4.328731783531958
Validation loss: 3.5807716209900375

Epoch: 40| Step: 0
Training loss: 3.7655690295859867
Validation loss: 3.5761753306570947

Epoch: 5| Step: 1
Training loss: 3.6744885821889834
Validation loss: 3.5716202036217353

Epoch: 5| Step: 2
Training loss: 3.6875196553369167
Validation loss: 3.567077634804102

Epoch: 5| Step: 3
Training loss: 3.886430800616545
Validation loss: 3.5628823248068753

Epoch: 5| Step: 4
Training loss: 4.058705832261919
Validation loss: 3.55872928990764

Epoch: 5| Step: 5
Training loss: 3.873062387686407
Validation loss: 3.5541224662891495

Epoch: 5| Step: 6
Training loss: 3.726467939092785
Validation loss: 3.5495520920327763

Epoch: 5| Step: 7
Training loss: 3.606662408000056
Validation loss: 3.545308746161056

Epoch: 5| Step: 8
Training loss: 3.2705581128092946
Validation loss: 3.5407741300865005

Epoch: 5| Step: 9
Training loss: 3.7876892747576667
Validation loss: 3.5363335266712514

Epoch: 5| Step: 10
Training loss: 3.153117674562926
Validation loss: 3.5319287033286977

Epoch: 5| Step: 11
Training loss: 3.8686741293029314
Validation loss: 3.527970529761352

Epoch: 41| Step: 0
Training loss: 3.2381817074190993
Validation loss: 3.5235861375446893

Epoch: 5| Step: 1
Training loss: 4.0228102704358095
Validation loss: 3.519752402348609

Epoch: 5| Step: 2
Training loss: 3.7841510835612486
Validation loss: 3.515274355320793

Epoch: 5| Step: 3
Training loss: 3.3363687205281805
Validation loss: 3.5110017456822487

Epoch: 5| Step: 4
Training loss: 3.0895144049547416
Validation loss: 3.5068390705573034

Epoch: 5| Step: 5
Training loss: 4.202238194958488
Validation loss: 3.5026951528688546

Epoch: 5| Step: 6
Training loss: 3.495783445769952
Validation loss: 3.498496794329469

Epoch: 5| Step: 7
Training loss: 3.598616116820158
Validation loss: 3.494312467662033

Epoch: 5| Step: 8
Training loss: 3.5905836669030236
Validation loss: 3.4900275711529902

Epoch: 5| Step: 9
Training loss: 3.957073908102371
Validation loss: 3.4858815481499423

Epoch: 5| Step: 10
Training loss: 3.265188525658704
Validation loss: 3.4816919554185652

Epoch: 5| Step: 11
Training loss: 4.878467793611604
Validation loss: 3.4772817374906198

Epoch: 42| Step: 0
Training loss: 3.1695172045111826
Validation loss: 3.473039260528115

Epoch: 5| Step: 1
Training loss: 3.701421418244874
Validation loss: 3.4684111226285776

Epoch: 5| Step: 2
Training loss: 3.522490718875351
Validation loss: 3.4643253768678552

Epoch: 5| Step: 3
Training loss: 3.486290785645632
Validation loss: 3.4600625464219688

Epoch: 5| Step: 4
Training loss: 3.586725418526664
Validation loss: 3.4554085524085907

Epoch: 5| Step: 5
Training loss: 3.317741134377607
Validation loss: 3.451203048729335

Epoch: 5| Step: 6
Training loss: 3.4014555059593232
Validation loss: 3.447170036510757

Epoch: 5| Step: 7
Training loss: 3.6486319708610053
Validation loss: 3.4431309789251494

Epoch: 5| Step: 8
Training loss: 3.764518353581005
Validation loss: 3.4391757521814736

Epoch: 5| Step: 9
Training loss: 3.863752222618962
Validation loss: 3.434867411455628

Epoch: 5| Step: 10
Training loss: 3.6266601970091314
Validation loss: 3.430502091676287

Epoch: 5| Step: 11
Training loss: 4.992054921092623
Validation loss: 3.426434520228079

Epoch: 43| Step: 0
Training loss: 3.1587698669171127
Validation loss: 3.4216318261821903

Epoch: 5| Step: 1
Training loss: 2.9943078399369054
Validation loss: 3.4176338540359894

Epoch: 5| Step: 2
Training loss: 4.095700097981118
Validation loss: 3.4137510889462037

Epoch: 5| Step: 3
Training loss: 3.50912675259756
Validation loss: 3.4094682941207273

Epoch: 5| Step: 4
Training loss: 3.997033330362753
Validation loss: 3.405199583051487

Epoch: 5| Step: 5
Training loss: 3.6716516305064646
Validation loss: 3.4012173387725038

Epoch: 5| Step: 6
Training loss: 3.0602217004285697
Validation loss: 3.397103213587352

Epoch: 5| Step: 7
Training loss: 3.873141673779943
Validation loss: 3.3924762635137373

Epoch: 5| Step: 8
Training loss: 2.8193860844009673
Validation loss: 3.388905741218884

Epoch: 5| Step: 9
Training loss: 3.6233102214348683
Validation loss: 3.385228064736592

Epoch: 5| Step: 10
Training loss: 3.8020366230364164
Validation loss: 3.381009802803993

Epoch: 5| Step: 11
Training loss: 3.8762802962294307
Validation loss: 3.377561897870208

Epoch: 44| Step: 0
Training loss: 3.7551760237843035
Validation loss: 3.37315671528779

Epoch: 5| Step: 1
Training loss: 3.495108046710246
Validation loss: 3.3686444994390055

Epoch: 5| Step: 2
Training loss: 3.5828213584713864
Validation loss: 3.364284387934767

Epoch: 5| Step: 3
Training loss: 3.831136212051585
Validation loss: 3.360363488073158

Epoch: 5| Step: 4
Training loss: 3.378001114993592
Validation loss: 3.3563479010843924

Epoch: 5| Step: 5
Training loss: 3.012442851810604
Validation loss: 3.352109939931128

Epoch: 5| Step: 6
Training loss: 3.52277186972392
Validation loss: 3.3482502751913894

Epoch: 5| Step: 7
Training loss: 3.9720531744802257
Validation loss: 3.3443377682333804

Epoch: 5| Step: 8
Training loss: 3.696843352387916
Validation loss: 3.3406269367284964

Epoch: 5| Step: 9
Training loss: 3.4103546609215063
Validation loss: 3.336798676611489

Epoch: 5| Step: 10
Training loss: 2.9285333012880237
Validation loss: 3.3326090303915987

Epoch: 5| Step: 11
Training loss: 1.2349819670839417
Validation loss: 3.32903813355502

Epoch: 45| Step: 0
Training loss: 2.7360785708829565
Validation loss: 3.325055110924023

Epoch: 5| Step: 1
Training loss: 3.4521014737788507
Validation loss: 3.321876504586119

Epoch: 5| Step: 2
Training loss: 3.695709529782858
Validation loss: 3.31859904039902

Epoch: 5| Step: 3
Training loss: 3.54914440536474
Validation loss: 3.3151869942066168

Epoch: 5| Step: 4
Training loss: 3.6882398477374645
Validation loss: 3.3113531910557072

Epoch: 5| Step: 5
Training loss: 3.6009216400409
Validation loss: 3.3078908823006796

Epoch: 5| Step: 6
Training loss: 2.991947015007584
Validation loss: 3.3047161777415375

Epoch: 5| Step: 7
Training loss: 3.284864052059862
Validation loss: 3.3008275888414356

Epoch: 5| Step: 8
Training loss: 3.7135181970197975
Validation loss: 3.297296939986315

Epoch: 5| Step: 9
Training loss: 3.4166756761633708
Validation loss: 3.29386623848231

Epoch: 5| Step: 10
Training loss: 3.6696352356959845
Validation loss: 3.290336941883606

Epoch: 5| Step: 11
Training loss: 3.381765155012936
Validation loss: 3.2869025331736585

Epoch: 46| Step: 0
Training loss: 3.0705671908517416
Validation loss: 3.2832490251015347

Epoch: 5| Step: 1
Training loss: 3.726905790947387
Validation loss: 3.2795517174714575

Epoch: 5| Step: 2
Training loss: 3.3738925671073647
Validation loss: 3.276153627230117

Epoch: 5| Step: 3
Training loss: 3.6810604700802196
Validation loss: 3.2725252292972895

Epoch: 5| Step: 4
Training loss: 3.468112371452302
Validation loss: 3.26876495143955

Epoch: 5| Step: 5
Training loss: 2.995704436591022
Validation loss: 3.2649927576752935

Epoch: 5| Step: 6
Training loss: 2.570024839496432
Validation loss: 3.2616010907360806

Epoch: 5| Step: 7
Training loss: 3.612584656248151
Validation loss: 3.2583836116635263

Epoch: 5| Step: 8
Training loss: 3.275235431158591
Validation loss: 3.254783448019669

Epoch: 5| Step: 9
Training loss: 3.4878143989196206
Validation loss: 3.251522068479278

Epoch: 5| Step: 10
Training loss: 3.877586608942613
Validation loss: 3.248168245709935

Epoch: 5| Step: 11
Training loss: 3.9315039378329257
Validation loss: 3.2447684865320525

Epoch: 47| Step: 0
Training loss: 3.25051611690284
Validation loss: 3.2410162897635355

Epoch: 5| Step: 1
Training loss: 2.9411118399306866
Validation loss: 3.2376335916732253

Epoch: 5| Step: 2
Training loss: 3.420006507510413
Validation loss: 3.234532178908104

Epoch: 5| Step: 3
Training loss: 3.03900601449756
Validation loss: 3.230828606129211

Epoch: 5| Step: 4
Training loss: 3.232476603341454
Validation loss: 3.22768189330132

Epoch: 5| Step: 5
Training loss: 3.262646352474242
Validation loss: 3.22450433933934

Epoch: 5| Step: 6
Training loss: 4.278313959600681
Validation loss: 3.220796545558011

Epoch: 5| Step: 7
Training loss: 3.4002839082101812
Validation loss: 3.2172869718346484

Epoch: 5| Step: 8
Training loss: 3.600732273224765
Validation loss: 3.2142592277646593

Epoch: 5| Step: 9
Training loss: 3.696787114521578
Validation loss: 3.210423245052964

Epoch: 5| Step: 10
Training loss: 2.477794064219748
Validation loss: 3.207190140672885

Epoch: 5| Step: 11
Training loss: 3.8497291519211916
Validation loss: 3.203935610538902

Epoch: 48| Step: 0
Training loss: 2.852601413378392
Validation loss: 3.200086333928166

Epoch: 5| Step: 1
Training loss: 3.4562214910562745
Validation loss: 3.1969731250866733

Epoch: 5| Step: 2
Training loss: 3.120429091168824
Validation loss: 3.193817494668956

Epoch: 5| Step: 3
Training loss: 3.6562925156949833
Validation loss: 3.1905553610260635

Epoch: 5| Step: 4
Training loss: 3.5598549643986495
Validation loss: 3.187460911579687

Epoch: 5| Step: 5
Training loss: 3.227453815298185
Validation loss: 3.1839141622055855

Epoch: 5| Step: 6
Training loss: 3.1429797402535136
Validation loss: 3.1807901812074775

Epoch: 5| Step: 7
Training loss: 3.0271685937232204
Validation loss: 3.1776347270738814

Epoch: 5| Step: 8
Training loss: 3.716190515190311
Validation loss: 3.1746307860485934

Epoch: 5| Step: 9
Training loss: 3.474597161085545
Validation loss: 3.1710518456323595

Epoch: 5| Step: 10
Training loss: 3.358639658800273
Validation loss: 3.1678114921400384

Epoch: 5| Step: 11
Training loss: 2.6064712906161374
Validation loss: 3.1646787286677487

Epoch: 49| Step: 0
Training loss: 3.6273630266993986
Validation loss: 3.1615315773956683

Epoch: 5| Step: 1
Training loss: 3.1739624370618946
Validation loss: 3.1585646316075575

Epoch: 5| Step: 2
Training loss: 3.855331959563614
Validation loss: 3.155831233655904

Epoch: 5| Step: 3
Training loss: 3.395861120441855
Validation loss: 3.1526563222366812

Epoch: 5| Step: 4
Training loss: 3.4448189241299674
Validation loss: 3.149615071508501

Epoch: 5| Step: 5
Training loss: 3.5782137530784444
Validation loss: 3.1463472544436257

Epoch: 5| Step: 6
Training loss: 2.713135018267586
Validation loss: 3.143232733791111

Epoch: 5| Step: 7
Training loss: 3.0412820198327077
Validation loss: 3.1400120328360823

Epoch: 5| Step: 8
Training loss: 3.5585812883546213
Validation loss: 3.136891861853991

Epoch: 5| Step: 9
Training loss: 2.870365055539624
Validation loss: 3.1338117659489257

Epoch: 5| Step: 10
Training loss: 2.8643127498567087
Validation loss: 3.1308735422570217

Epoch: 5| Step: 11
Training loss: 2.386672099105506
Validation loss: 3.1282384177983587

Epoch: 50| Step: 0
Training loss: 3.445504042648935
Validation loss: 3.125293253808305

Epoch: 5| Step: 1
Training loss: 2.288747407754444
Validation loss: 3.12231217824541

Epoch: 5| Step: 2
Training loss: 2.7720765979141646
Validation loss: 3.119693863895435

Epoch: 5| Step: 3
Training loss: 2.9697366781416834
Validation loss: 3.1172521993986404

Epoch: 5| Step: 4
Training loss: 3.5393739946388516
Validation loss: 3.114938174588892

Epoch: 5| Step: 5
Training loss: 2.6442068512375023
Validation loss: 3.1123245026366915

Epoch: 5| Step: 6
Training loss: 3.314332131474178
Validation loss: 3.109842520858286

Epoch: 5| Step: 7
Training loss: 3.5332768117834363
Validation loss: 3.10749344310749

Epoch: 5| Step: 8
Training loss: 3.868885384256829
Validation loss: 3.10468232055703

Epoch: 5| Step: 9
Training loss: 3.1961825429088395
Validation loss: 3.1021729420276496

Epoch: 5| Step: 10
Training loss: 3.7445086645045706
Validation loss: 3.0992235193134934

Epoch: 5| Step: 11
Training loss: 3.6532931639094177
Validation loss: 3.096426393753596

Epoch: 51| Step: 0
Training loss: 3.188506023744059
Validation loss: 3.093209672232571

Epoch: 5| Step: 1
Training loss: 3.1683659428004143
Validation loss: 3.0903446291480248

Epoch: 5| Step: 2
Training loss: 2.6725825215116465
Validation loss: 3.0870386340083282

Epoch: 5| Step: 3
Training loss: 3.186414346747792
Validation loss: 3.0841128624726575

Epoch: 5| Step: 4
Training loss: 2.9569014365805053
Validation loss: 3.081190432113942

Epoch: 5| Step: 5
Training loss: 3.4652510858364396
Validation loss: 3.0782270140291446

Epoch: 5| Step: 6
Training loss: 3.5365760270517566
Validation loss: 3.0755797802312017

Epoch: 5| Step: 7
Training loss: 3.2519337696496065
Validation loss: 3.0728010425258976

Epoch: 5| Step: 8
Training loss: 3.480589037185569
Validation loss: 3.0697288379036585

Epoch: 5| Step: 9
Training loss: 3.055938854644378
Validation loss: 3.067076047406644

Epoch: 5| Step: 10
Training loss: 3.287348719840194
Validation loss: 3.064207574112918

Epoch: 5| Step: 11
Training loss: 3.5609672327545314
Validation loss: 3.061095269138731

Epoch: 52| Step: 0
Training loss: 2.7675262640143594
Validation loss: 3.0586056958741112

Epoch: 5| Step: 1
Training loss: 3.4001397440746226
Validation loss: 3.0555912836953

Epoch: 5| Step: 2
Training loss: 3.1312420873484887
Validation loss: 3.0526920705358758

Epoch: 5| Step: 3
Training loss: 3.2622850486129074
Validation loss: 3.0497911338737067

Epoch: 5| Step: 4
Training loss: 3.120542780784154
Validation loss: 3.0467061248668483

Epoch: 5| Step: 5
Training loss: 2.907001685279486
Validation loss: 3.0436824929481774

Epoch: 5| Step: 6
Training loss: 2.6365680114608914
Validation loss: 3.041296921208813

Epoch: 5| Step: 7
Training loss: 3.733466129552421
Validation loss: 3.038826711835293

Epoch: 5| Step: 8
Training loss: 3.3167182407171194
Validation loss: 3.035943589111965

Epoch: 5| Step: 9
Training loss: 3.231109444901872
Validation loss: 3.033112520697522

Epoch: 5| Step: 10
Training loss: 3.38588372554423
Validation loss: 3.030348627368737

Epoch: 5| Step: 11
Training loss: 3.232518202161765
Validation loss: 3.027769171243698

Epoch: 53| Step: 0
Training loss: 3.2121509941306057
Validation loss: 3.0251363602687085

Epoch: 5| Step: 1
Training loss: 2.7470661465707837
Validation loss: 3.0226208703573545

Epoch: 5| Step: 2
Training loss: 3.5087544083576074
Validation loss: 3.020237990063982

Epoch: 5| Step: 3
Training loss: 3.4341294843892767
Validation loss: 3.017486590629814

Epoch: 5| Step: 4
Training loss: 2.6782265286691467
Validation loss: 3.0147358006689884

Epoch: 5| Step: 5
Training loss: 3.204455885382463
Validation loss: 3.012227175059793

Epoch: 5| Step: 6
Training loss: 2.9455096839042363
Validation loss: 3.0099490879459188

Epoch: 5| Step: 7
Training loss: 3.0608824525861498
Validation loss: 3.0076589437813506

Epoch: 5| Step: 8
Training loss: 2.9601598840783314
Validation loss: 3.0056364833194382

Epoch: 5| Step: 9
Training loss: 3.3918245364727024
Validation loss: 3.003288787625405

Epoch: 5| Step: 10
Training loss: 3.3094298332073535
Validation loss: 3.000556880869254

Epoch: 5| Step: 11
Training loss: 3.7537378120542075
Validation loss: 2.99839269111923

Epoch: 54| Step: 0
Training loss: 3.3372824322939687
Validation loss: 2.995563037326195

Epoch: 5| Step: 1
Training loss: 2.9036119855381908
Validation loss: 2.992938735055974

Epoch: 5| Step: 2
Training loss: 3.5263190486710103
Validation loss: 2.9904011373199504

Epoch: 5| Step: 3
Training loss: 2.346964450152482
Validation loss: 2.987608218394413

Epoch: 5| Step: 4
Training loss: 2.4731172972494835
Validation loss: 2.984930502701792

Epoch: 5| Step: 5
Training loss: 3.7276208042599452
Validation loss: 2.982661046345636

Epoch: 5| Step: 6
Training loss: 2.779875769412273
Validation loss: 2.9802946287317114

Epoch: 5| Step: 7
Training loss: 2.951804536959394
Validation loss: 2.9778179781655165

Epoch: 5| Step: 8
Training loss: 3.2602146723924497
Validation loss: 2.975161171669284

Epoch: 5| Step: 9
Training loss: 3.576520268435478
Validation loss: 2.9729631209581235

Epoch: 5| Step: 10
Training loss: 3.1387004364366313
Validation loss: 2.9704634991772423

Epoch: 5| Step: 11
Training loss: 3.3018155796669424
Validation loss: 2.9681449842499825

Epoch: 55| Step: 0
Training loss: 2.843542238128699
Validation loss: 2.965504599037521

Epoch: 5| Step: 1
Training loss: 3.013275496200674
Validation loss: 2.9631872395371057

Epoch: 5| Step: 2
Training loss: 2.8933537980277357
Validation loss: 2.9606880378145806

Epoch: 5| Step: 3
Training loss: 3.4482305716138253
Validation loss: 2.9583778825727767

Epoch: 5| Step: 4
Training loss: 3.0637612373211334
Validation loss: 2.9560497373369987

Epoch: 5| Step: 5
Training loss: 2.941315790130415
Validation loss: 2.9537899472999056

Epoch: 5| Step: 6
Training loss: 2.771964012187619
Validation loss: 2.9512652843746845

Epoch: 5| Step: 7
Training loss: 3.5454001700404225
Validation loss: 2.949018149048314

Epoch: 5| Step: 8
Training loss: 2.701429596119982
Validation loss: 2.946652452487091

Epoch: 5| Step: 9
Training loss: 3.671018849656216
Validation loss: 2.9442810627055396

Epoch: 5| Step: 10
Training loss: 3.031942072252072
Validation loss: 2.9419907913182746

Epoch: 5| Step: 11
Training loss: 2.8936606473701563
Validation loss: 2.939491942562336

Epoch: 56| Step: 0
Training loss: 3.159017426039695
Validation loss: 2.9373399914118297

Epoch: 5| Step: 1
Training loss: 3.1279763353140426
Validation loss: 2.9352885403544158

Epoch: 5| Step: 2
Training loss: 2.7821789165365707
Validation loss: 2.9328320729695436

Epoch: 5| Step: 3
Training loss: 3.310271035014557
Validation loss: 2.930408541641315

Epoch: 5| Step: 4
Training loss: 2.8143367279994935
Validation loss: 2.9279939664917936

Epoch: 5| Step: 5
Training loss: 2.922827580662975
Validation loss: 2.925924069323087

Epoch: 5| Step: 6
Training loss: 3.2376512528955272
Validation loss: 2.9235146625664994

Epoch: 5| Step: 7
Training loss: 2.9558067457238146
Validation loss: 2.92135861707541

Epoch: 5| Step: 8
Training loss: 3.260091227091653
Validation loss: 2.91904370765421

Epoch: 5| Step: 9
Training loss: 3.038139771953519
Validation loss: 2.9168805293740605

Epoch: 5| Step: 10
Training loss: 3.162377028656531
Validation loss: 2.9150352967885973

Epoch: 5| Step: 11
Training loss: 2.8137861913643847
Validation loss: 2.9128802290063303

Epoch: 57| Step: 0
Training loss: 2.798190611955551
Validation loss: 2.9109901718313145

Epoch: 5| Step: 1
Training loss: 2.625967846420083
Validation loss: 2.909199930039301

Epoch: 5| Step: 2
Training loss: 3.55155051850741
Validation loss: 2.9070741790551535

Epoch: 5| Step: 3
Training loss: 2.9482658008743003
Validation loss: 2.9054202669370195

Epoch: 5| Step: 4
Training loss: 2.4638459956542564
Validation loss: 2.903024798067997

Epoch: 5| Step: 5
Training loss: 3.309953106320396
Validation loss: 2.9015234176805627

Epoch: 5| Step: 6
Training loss: 2.949927157779672
Validation loss: 2.8997049088354108

Epoch: 5| Step: 7
Training loss: 2.9265722369323806
Validation loss: 2.897669975883864

Epoch: 5| Step: 8
Training loss: 3.071867958906764
Validation loss: 2.8986783677309194

Epoch: 5| Step: 9
Training loss: 3.509800540875643
Validation loss: 2.8980372204765237

Epoch: 5| Step: 10
Training loss: 3.0705752660697976
Validation loss: 2.8916751294374077

Epoch: 5| Step: 11
Training loss: 3.3770785112638757
Validation loss: 2.8898756275892157

Epoch: 58| Step: 0
Training loss: 3.626582622348984
Validation loss: 2.888676104951951

Epoch: 5| Step: 1
Training loss: 2.332733917445805
Validation loss: 2.8888444004291047

Epoch: 5| Step: 2
Training loss: 3.3324573955402372
Validation loss: 2.890992754662908

Epoch: 5| Step: 3
Training loss: 3.104570059626124
Validation loss: 2.884141861877719

Epoch: 5| Step: 4
Training loss: 3.1883771100971425
Validation loss: 2.8819820651825037

Epoch: 5| Step: 5
Training loss: 2.773519853255752
Validation loss: 2.8796424217787244

Epoch: 5| Step: 6
Training loss: 3.0449553873837343
Validation loss: 2.876930514693731

Epoch: 5| Step: 7
Training loss: 3.346806920318178
Validation loss: 2.874586002976932

Epoch: 5| Step: 8
Training loss: 3.0541450038278697
Validation loss: 2.872386864342381

Epoch: 5| Step: 9
Training loss: 2.69202574312051
Validation loss: 2.869740048940663

Epoch: 5| Step: 10
Training loss: 2.6920264516383936
Validation loss: 2.868219316413793

Epoch: 5| Step: 11
Training loss: 2.1036861991614235
Validation loss: 2.8660489176805677

Epoch: 59| Step: 0
Training loss: 3.249902723763932
Validation loss: 2.8649676787576555

Epoch: 5| Step: 1
Training loss: 2.971879293637228
Validation loss: 2.8624815854197947

Epoch: 5| Step: 2
Training loss: 2.7112653462603085
Validation loss: 2.8612551249109193

Epoch: 5| Step: 3
Training loss: 3.4147866046411766
Validation loss: 2.860011063028604

Epoch: 5| Step: 4
Training loss: 3.3747223633905445
Validation loss: 2.857520539150697

Epoch: 5| Step: 5
Training loss: 3.031324090740386
Validation loss: 2.8568774782697326

Epoch: 5| Step: 6
Training loss: 2.862044292307149
Validation loss: 2.8555803464138303

Epoch: 5| Step: 7
Training loss: 3.218889103818755
Validation loss: 2.8529823112948938

Epoch: 5| Step: 8
Training loss: 2.588574220592084
Validation loss: 2.851389523489732

Epoch: 5| Step: 9
Training loss: 2.887930113889947
Validation loss: 2.8485325187644652

Epoch: 5| Step: 10
Training loss: 2.7460095323479132
Validation loss: 2.847216271701787

Epoch: 5| Step: 11
Training loss: 1.8463424302029867
Validation loss: 2.8450421726685606

Epoch: 60| Step: 0
Training loss: 3.1750368791976475
Validation loss: 2.8442961793608568

Epoch: 5| Step: 1
Training loss: 3.371536738528597
Validation loss: 2.8425649891729323

Epoch: 5| Step: 2
Training loss: 3.456844346333493
Validation loss: 2.8412657915496906

Epoch: 5| Step: 3
Training loss: 2.8400281088069317
Validation loss: 2.839853681138561

Epoch: 5| Step: 4
Training loss: 2.9095786116633335
Validation loss: 2.8381152063058104

Epoch: 5| Step: 5
Training loss: 2.5216500296572306
Validation loss: 2.83656967795369

Epoch: 5| Step: 6
Training loss: 2.8504522801292334
Validation loss: 2.834369502680844

Epoch: 5| Step: 7
Training loss: 2.9986763259214224
Validation loss: 2.8334088572552925

Epoch: 5| Step: 8
Training loss: 3.0212077117094216
Validation loss: 2.8319549234562342

Epoch: 5| Step: 9
Training loss: 2.754865070922799
Validation loss: 2.82931145567672

Epoch: 5| Step: 10
Training loss: 2.8782830773762926
Validation loss: 2.827866480973916

Epoch: 5| Step: 11
Training loss: 2.1552534149995983
Validation loss: 2.8249738184241733

Epoch: 61| Step: 0
Training loss: 3.1426224311280073
Validation loss: 2.8235253326541017

Epoch: 5| Step: 1
Training loss: 2.9108027412153166
Validation loss: 2.8225395870445382

Epoch: 5| Step: 2
Training loss: 2.1310085171010638
Validation loss: 2.820927849561477

Epoch: 5| Step: 3
Training loss: 3.095283821662483
Validation loss: 2.8201679076434063

Epoch: 5| Step: 4
Training loss: 3.049198301668481
Validation loss: 2.817601853554618

Epoch: 5| Step: 5
Training loss: 3.3623133384201083
Validation loss: 2.816237181352005

Epoch: 5| Step: 6
Training loss: 3.0637033395003863
Validation loss: 2.814467233079348

Epoch: 5| Step: 7
Training loss: 3.1833663765622013
Validation loss: 2.8137602207942134

Epoch: 5| Step: 8
Training loss: 3.1858772186069215
Validation loss: 2.8118794463049652

Epoch: 5| Step: 9
Training loss: 2.6345267219339386
Validation loss: 2.8098228428611223

Epoch: 5| Step: 10
Training loss: 2.6844806121904776
Validation loss: 2.8088807059789107

Epoch: 5| Step: 11
Training loss: 2.423717757547176
Validation loss: 2.807129001799904

Epoch: 62| Step: 0
Training loss: 2.736350256144889
Validation loss: 2.805681999796273

Epoch: 5| Step: 1
Training loss: 3.1640240702237974
Validation loss: 2.8044958553878674

Epoch: 5| Step: 2
Training loss: 3.3179111548469047
Validation loss: 2.8050621193395213

Epoch: 5| Step: 3
Training loss: 2.6163975676480495
Validation loss: 2.8021717849346937

Epoch: 5| Step: 4
Training loss: 3.0764611099143493
Validation loss: 2.8005927965508643

Epoch: 5| Step: 5
Training loss: 3.2277746994637107
Validation loss: 2.798637268274417

Epoch: 5| Step: 6
Training loss: 2.9710474059316954
Validation loss: 2.7990780293110995

Epoch: 5| Step: 7
Training loss: 2.735699839484473
Validation loss: 2.7961112885281723

Epoch: 5| Step: 8
Training loss: 2.522995759546902
Validation loss: 2.7948613083606118

Epoch: 5| Step: 9
Training loss: 3.0597724445977557
Validation loss: 2.793932366588386

Epoch: 5| Step: 10
Training loss: 2.698946418770262
Validation loss: 2.7944089293092715

Epoch: 5| Step: 11
Training loss: 3.361899771172712
Validation loss: 2.804608899133504

Epoch: 63| Step: 0
Training loss: 2.824112295252274
Validation loss: 2.7877764082973644

Epoch: 5| Step: 1
Training loss: 3.004861389619361
Validation loss: 2.7884519284476537

Epoch: 5| Step: 2
Training loss: 2.742129507293871
Validation loss: 2.7909389384763648

Epoch: 5| Step: 3
Training loss: 2.910420696353148
Validation loss: 2.806725964612586

Epoch: 5| Step: 4
Training loss: 2.9366819175933285
Validation loss: 2.7907600615063535

Epoch: 5| Step: 5
Training loss: 2.633077364766177
Validation loss: 2.7856919788595813

Epoch: 5| Step: 6
Training loss: 2.9743371689922165
Validation loss: 2.7833157200931757

Epoch: 5| Step: 7
Training loss: 3.224988946230375
Validation loss: 2.780281998558964

Epoch: 5| Step: 8
Training loss: 2.8505867738843413
Validation loss: 2.7789187715877635

Epoch: 5| Step: 9
Training loss: 3.0601623332528254
Validation loss: 2.775396384175728

Epoch: 5| Step: 10
Training loss: 2.9538875180719706
Validation loss: 2.7738169343392514

Epoch: 5| Step: 11
Training loss: 3.1065134654383373
Validation loss: 2.7732004771787873

Epoch: 64| Step: 0
Training loss: 2.763534014063733
Validation loss: 2.770879932719202

Epoch: 5| Step: 1
Training loss: 3.130851455269147
Validation loss: 2.770247161978303

Epoch: 5| Step: 2
Training loss: 3.126973253956137
Validation loss: 2.7681994336392446

Epoch: 5| Step: 3
Training loss: 2.76218679042047
Validation loss: 2.7638691215085145

Epoch: 5| Step: 4
Training loss: 3.088040719193715
Validation loss: 2.763492020325091

Epoch: 5| Step: 5
Training loss: 2.923720648961953
Validation loss: 2.761478566503681

Epoch: 5| Step: 6
Training loss: 2.990187651445463
Validation loss: 2.7611807191629745

Epoch: 5| Step: 7
Training loss: 3.22730133981757
Validation loss: 2.7573385434740945

Epoch: 5| Step: 8
Training loss: 2.732532861621933
Validation loss: 2.7563594055375877

Epoch: 5| Step: 9
Training loss: 2.919299290858917
Validation loss: 2.755941193769882

Epoch: 5| Step: 10
Training loss: 2.488577880425557
Validation loss: 2.753523541635429

Epoch: 5| Step: 11
Training loss: 0.7662883920681693
Validation loss: 2.7534961620560594

Epoch: 65| Step: 0
Training loss: 2.4260979044909323
Validation loss: 2.751777594594946

Epoch: 5| Step: 1
Training loss: 3.362996265419512
Validation loss: 2.752217078201763

Epoch: 5| Step: 2
Training loss: 2.750343127951887
Validation loss: 2.7521809613807937

Epoch: 5| Step: 3
Training loss: 3.045253224233911
Validation loss: 2.750964378552939

Epoch: 5| Step: 4
Training loss: 3.032906777568895
Validation loss: 2.7541402803004433

Epoch: 5| Step: 5
Training loss: 2.851141744429093
Validation loss: 2.752653355491277

Epoch: 5| Step: 6
Training loss: 3.0470593518948275
Validation loss: 2.749654459196435

Epoch: 5| Step: 7
Training loss: 2.924247716688367
Validation loss: 2.7432057880085976

Epoch: 5| Step: 8
Training loss: 2.546325530709596
Validation loss: 2.742083135432018

Epoch: 5| Step: 9
Training loss: 2.9756393002168657
Validation loss: 2.7421574495848056

Epoch: 5| Step: 10
Training loss: 2.687034921547671
Validation loss: 2.7404854900268525

Epoch: 5| Step: 11
Training loss: 2.8943861128318398
Validation loss: 2.7402593494164487

Epoch: 66| Step: 0
Training loss: 3.076374311295399
Validation loss: 2.7392884640896864

Epoch: 5| Step: 1
Training loss: 2.9687220521916404
Validation loss: 2.7372432923687264

Epoch: 5| Step: 2
Training loss: 3.377568292047379
Validation loss: 2.7348889185834326

Epoch: 5| Step: 3
Training loss: 2.3558601319936914
Validation loss: 2.7313919580436035

Epoch: 5| Step: 4
Training loss: 2.647938819230339
Validation loss: 2.73041208742331

Epoch: 5| Step: 5
Training loss: 2.845161842073799
Validation loss: 2.7258310293220744

Epoch: 5| Step: 6
Training loss: 2.880230168310986
Validation loss: 2.729806342155484

Epoch: 5| Step: 7
Training loss: 3.0159948250703406
Validation loss: 2.726188014563395

Epoch: 5| Step: 8
Training loss: 2.851741753783718
Validation loss: 2.724474660443927

Epoch: 5| Step: 9
Training loss: 2.8382597523722235
Validation loss: 2.7243460725101936

Epoch: 5| Step: 10
Training loss: 2.779639045417379
Validation loss: 2.724812205431891

Epoch: 5| Step: 11
Training loss: 2.2679057250166896
Validation loss: 2.72339435498716

Epoch: 67| Step: 0
Training loss: 2.668180175267943
Validation loss: 2.723736056758537

Epoch: 5| Step: 1
Training loss: 3.231184560677575
Validation loss: 2.7222099394477928

Epoch: 5| Step: 2
Training loss: 2.9310846278019533
Validation loss: 2.7211558231674235

Epoch: 5| Step: 3
Training loss: 2.906414888688122
Validation loss: 2.719461685879228

Epoch: 5| Step: 4
Training loss: 2.5632754757440295
Validation loss: 2.7194689972855484

Epoch: 5| Step: 5
Training loss: 2.597461205524133
Validation loss: 2.7185287020128563

Epoch: 5| Step: 6
Training loss: 2.969466273583718
Validation loss: 2.717174146406262

Epoch: 5| Step: 7
Training loss: 3.1192214945782175
Validation loss: 2.713994569867183

Epoch: 5| Step: 8
Training loss: 2.7528507888492113
Validation loss: 2.7110292014260473

Epoch: 5| Step: 9
Training loss: 2.8080397949604965
Validation loss: 2.7114529151779325

Epoch: 5| Step: 10
Training loss: 2.8215701186698006
Validation loss: 2.707281180950161

Epoch: 5| Step: 11
Training loss: 2.657878600862234
Validation loss: 2.7084577103934664

Epoch: 68| Step: 0
Training loss: 2.6236755117717125
Validation loss: 2.70490587331036

Epoch: 5| Step: 1
Training loss: 3.195833270998427
Validation loss: 2.7050536263615457

Epoch: 5| Step: 2
Training loss: 2.9695892753843145
Validation loss: 2.7086960341824353

Epoch: 5| Step: 3
Training loss: 2.9508209120812094
Validation loss: 2.7196602229412035

Epoch: 5| Step: 4
Training loss: 3.0722007477852715
Validation loss: 2.7563147687906904

Epoch: 5| Step: 5
Training loss: 2.8394941405974596
Validation loss: 2.7602277091269016

Epoch: 5| Step: 6
Training loss: 2.9541244833821527
Validation loss: 2.7545824487785042

Epoch: 5| Step: 7
Training loss: 2.680164617208371
Validation loss: 2.7228010295099616

Epoch: 5| Step: 8
Training loss: 2.4936677847481845
Validation loss: 2.7077267823443543

Epoch: 5| Step: 9
Training loss: 2.9336174812830076
Validation loss: 2.6996178780467215

Epoch: 5| Step: 10
Training loss: 2.7648091810166724
Validation loss: 2.69933190041896

Epoch: 5| Step: 11
Training loss: 2.5989622576014386
Validation loss: 2.702129776162635

Epoch: 69| Step: 0
Training loss: 2.780277210657784
Validation loss: 2.7101375634538982

Epoch: 5| Step: 1
Training loss: 2.823591444909499
Validation loss: 2.7046717957133097

Epoch: 5| Step: 2
Training loss: 3.124526178678546
Validation loss: 2.7063150710813018

Epoch: 5| Step: 3
Training loss: 2.7477485803922024
Validation loss: 2.7008932231495986

Epoch: 5| Step: 4
Training loss: 3.0042138704849655
Validation loss: 2.697699539304179

Epoch: 5| Step: 5
Training loss: 2.6672391773618935
Validation loss: 2.6910160891057715

Epoch: 5| Step: 6
Training loss: 2.8548990873817766
Validation loss: 2.6870121513087684

Epoch: 5| Step: 7
Training loss: 3.087411108552026
Validation loss: 2.6850654827186093

Epoch: 5| Step: 8
Training loss: 2.8601356703583916
Validation loss: 2.684195138769805

Epoch: 5| Step: 9
Training loss: 2.801572892637279
Validation loss: 2.6838590369589674

Epoch: 5| Step: 10
Training loss: 2.565451805969077
Validation loss: 2.6848693806886503

Epoch: 5| Step: 11
Training loss: 1.782090373649304
Validation loss: 2.6845346473645852

Epoch: 70| Step: 0
Training loss: 2.503520965689517
Validation loss: 2.685511651935204

Epoch: 5| Step: 1
Training loss: 3.0988928694448905
Validation loss: 2.684013126629947

Epoch: 5| Step: 2
Training loss: 3.0189014088824986
Validation loss: 2.6831472211371237

Epoch: 5| Step: 3
Training loss: 2.818311070948886
Validation loss: 2.6820078554586

Epoch: 5| Step: 4
Training loss: 2.299953758770047
Validation loss: 2.6822654179643615

Epoch: 5| Step: 5
Training loss: 3.381792932380692
Validation loss: 2.6800033709400477

Epoch: 5| Step: 6
Training loss: 2.701858135438129
Validation loss: 2.6768671361603005

Epoch: 5| Step: 7
Training loss: 2.5790345408214765
Validation loss: 2.674996253929011

Epoch: 5| Step: 8
Training loss: 3.0954489618652565
Validation loss: 2.67242718171849

Epoch: 5| Step: 9
Training loss: 2.8996799818587538
Validation loss: 2.668334366194386

Epoch: 5| Step: 10
Training loss: 2.558298527815289
Validation loss: 2.6692898087486103

Epoch: 5| Step: 11
Training loss: 2.008576244157779
Validation loss: 2.667957843927645

Epoch: 71| Step: 0
Training loss: 2.830608815732085
Validation loss: 2.66736066748106

Epoch: 5| Step: 1
Training loss: 2.404317500926962
Validation loss: 2.6670668731330114

Epoch: 5| Step: 2
Training loss: 2.326622189895506
Validation loss: 2.6639729071772593

Epoch: 5| Step: 3
Training loss: 3.1355882937750423
Validation loss: 2.6617164013905152

Epoch: 5| Step: 4
Training loss: 2.968261196652878
Validation loss: 2.666463733690179

Epoch: 5| Step: 5
Training loss: 2.832937287718784
Validation loss: 2.666093255520874

Epoch: 5| Step: 6
Training loss: 2.596540214175738
Validation loss: 2.6620595530388544

Epoch: 5| Step: 7
Training loss: 3.0680724846982192
Validation loss: 2.660090131493445

Epoch: 5| Step: 8
Training loss: 3.075990198008145
Validation loss: 2.657403672949569

Epoch: 5| Step: 9
Training loss: 2.885492170059826
Validation loss: 2.6568503430679926

Epoch: 5| Step: 10
Training loss: 2.360613466314935
Validation loss: 2.654846804372378

Epoch: 5| Step: 11
Training loss: 3.489139327464577
Validation loss: 2.6537012101304867

Epoch: 72| Step: 0
Training loss: 2.763794287676546
Validation loss: 2.653415465283833

Epoch: 5| Step: 1
Training loss: 2.9212667066612994
Validation loss: 2.6528084937215293

Epoch: 5| Step: 2
Training loss: 3.013493867018823
Validation loss: 2.6539671943201806

Epoch: 5| Step: 3
Training loss: 2.6127719354326495
Validation loss: 2.6530156995577436

Epoch: 5| Step: 4
Training loss: 3.1829425918143173
Validation loss: 2.653994470267391

Epoch: 5| Step: 5
Training loss: 2.660655956415298
Validation loss: 2.6527700030183508

Epoch: 5| Step: 6
Training loss: 2.359677326967046
Validation loss: 2.6515329251787705

Epoch: 5| Step: 7
Training loss: 2.7408188232643997
Validation loss: 2.6507512641137883

Epoch: 5| Step: 8
Training loss: 2.8814488936020415
Validation loss: 2.649015440470922

Epoch: 5| Step: 9
Training loss: 2.329919929602074
Validation loss: 2.64820268878505

Epoch: 5| Step: 10
Training loss: 2.9994002378482603
Validation loss: 2.6478745716529644

Epoch: 5| Step: 11
Training loss: 3.2837841602257765
Validation loss: 2.6459072257909915

Epoch: 73| Step: 0
Training loss: 3.1892955435084365
Validation loss: 2.6437208360426667

Epoch: 5| Step: 1
Training loss: 2.379274236470858
Validation loss: 2.643156809200106

Epoch: 5| Step: 2
Training loss: 2.590024639734134
Validation loss: 2.6399919251357

Epoch: 5| Step: 3
Training loss: 2.3223294826034144
Validation loss: 2.638771719729474

Epoch: 5| Step: 4
Training loss: 3.080078434626649
Validation loss: 2.6381479529543825

Epoch: 5| Step: 5
Training loss: 2.8267659668154774
Validation loss: 2.636513562165944

Epoch: 5| Step: 6
Training loss: 2.492162435280012
Validation loss: 2.632248600188695

Epoch: 5| Step: 7
Training loss: 2.998909275139069
Validation loss: 2.6368364774065043

Epoch: 5| Step: 8
Training loss: 2.68628984751021
Validation loss: 2.6360631848339873

Epoch: 5| Step: 9
Training loss: 2.5339308305978183
Validation loss: 2.6379779738132565

Epoch: 5| Step: 10
Training loss: 3.210908393078232
Validation loss: 2.639426849281117

Epoch: 5| Step: 11
Training loss: 2.923276514119547
Validation loss: 2.635828684588552

Epoch: 74| Step: 0
Training loss: 2.5560301072880174
Validation loss: 2.632148772209192

Epoch: 5| Step: 1
Training loss: 2.7673996226397657
Validation loss: 2.629091578427477

Epoch: 5| Step: 2
Training loss: 3.4294690733851465
Validation loss: 2.6289535072315213

Epoch: 5| Step: 3
Training loss: 2.4926934281788418
Validation loss: 2.6300128234615925

Epoch: 5| Step: 4
Training loss: 2.861199302507505
Validation loss: 2.63385997879949

Epoch: 5| Step: 5
Training loss: 2.8942782025017157
Validation loss: 2.6349341411913763

Epoch: 5| Step: 6
Training loss: 2.9380184284252886
Validation loss: 2.6382646375831023

Epoch: 5| Step: 7
Training loss: 2.592849759057951
Validation loss: 2.643172523129636

Epoch: 5| Step: 8
Training loss: 2.6816276444400877
Validation loss: 2.6425407465292783

Epoch: 5| Step: 9
Training loss: 2.8514524673762414
Validation loss: 2.64398999218338

Epoch: 5| Step: 10
Training loss: 2.2572457945392945
Validation loss: 2.644066462202537

Epoch: 5| Step: 11
Training loss: 3.048306955175077
Validation loss: 2.6392696370846305

Epoch: 75| Step: 0
Training loss: 2.685218996319857
Validation loss: 2.633718336657618

Epoch: 5| Step: 1
Training loss: 2.5973810724196342
Validation loss: 2.630799083023575

Epoch: 5| Step: 2
Training loss: 2.72907646166018
Validation loss: 2.623754446147964

Epoch: 5| Step: 3
Training loss: 2.7459230546277213
Validation loss: 2.620302762229749

Epoch: 5| Step: 4
Training loss: 2.4926957237051184
Validation loss: 2.6193829452077395

Epoch: 5| Step: 5
Training loss: 2.7504383084650117
Validation loss: 2.618356020629015

Epoch: 5| Step: 6
Training loss: 2.631636903275209
Validation loss: 2.6200803720241077

Epoch: 5| Step: 7
Training loss: 2.9246289335758284
Validation loss: 2.6185020751250483

Epoch: 5| Step: 8
Training loss: 3.0786806176344355
Validation loss: 2.617903673104436

Epoch: 5| Step: 9
Training loss: 2.382930264924145
Validation loss: 2.616257288722617

Epoch: 5| Step: 10
Training loss: 3.055703855056096
Validation loss: 2.6182106333594506

Epoch: 5| Step: 11
Training loss: 3.6224443042546226
Validation loss: 2.6142352633666923

Epoch: 76| Step: 0
Training loss: 3.3172719879100145
Validation loss: 2.61459133759954

Epoch: 5| Step: 1
Training loss: 2.067217777460087
Validation loss: 2.6131073343123417

Epoch: 5| Step: 2
Training loss: 2.8913926213666583
Validation loss: 2.612999270307534

Epoch: 5| Step: 3
Training loss: 2.9572363597127356
Validation loss: 2.6118147212881415

Epoch: 5| Step: 4
Training loss: 2.2242394894221555
Validation loss: 2.6150044574480744

Epoch: 5| Step: 5
Training loss: 2.7147025311742117
Validation loss: 2.613553088636946

Epoch: 5| Step: 6
Training loss: 2.6610642730565783
Validation loss: 2.6148034885826044

Epoch: 5| Step: 7
Training loss: 2.6349949153728036
Validation loss: 2.6122763792031214

Epoch: 5| Step: 8
Training loss: 3.028484065731428
Validation loss: 2.6124141263765597

Epoch: 5| Step: 9
Training loss: 2.8939386293960085
Validation loss: 2.6094844056605355

Epoch: 5| Step: 10
Training loss: 2.6019557163126548
Validation loss: 2.6102454852162054

Epoch: 5| Step: 11
Training loss: 3.0069120570301653
Validation loss: 2.6075888133810716

Epoch: 77| Step: 0
Training loss: 2.4398560508102802
Validation loss: 2.601237734054299

Epoch: 5| Step: 1
Training loss: 2.509513777034357
Validation loss: 2.603322068899095

Epoch: 5| Step: 2
Training loss: 2.453736733134973
Validation loss: 2.605970964352225

Epoch: 5| Step: 3
Training loss: 2.3863421203832313
Validation loss: 2.6058750321951885

Epoch: 5| Step: 4
Training loss: 3.0103877153071443
Validation loss: 2.6173637862166674

Epoch: 5| Step: 5
Training loss: 3.3117199825096493
Validation loss: 2.6120604441894373

Epoch: 5| Step: 6
Training loss: 2.785991356244066
Validation loss: 2.6064203917883115

Epoch: 5| Step: 7
Training loss: 2.710834951962178
Validation loss: 2.601714800862453

Epoch: 5| Step: 8
Training loss: 2.810441174882183
Validation loss: 2.599965423421319

Epoch: 5| Step: 9
Training loss: 3.0914347298568092
Validation loss: 2.599346075903703

Epoch: 5| Step: 10
Training loss: 2.541523277949108
Validation loss: 2.598878218359495

Epoch: 5| Step: 11
Training loss: 2.746504990238953
Validation loss: 2.6008894797276967

Epoch: 78| Step: 0
Training loss: 2.818282900253162
Validation loss: 2.5991039324527176

Epoch: 5| Step: 1
Training loss: 3.1113842170673522
Validation loss: 2.597430475122666

Epoch: 5| Step: 2
Training loss: 3.030888486718193
Validation loss: 2.594790257734674

Epoch: 5| Step: 3
Training loss: 2.441307615195037
Validation loss: 2.594611159000283

Epoch: 5| Step: 4
Training loss: 2.4736734862057728
Validation loss: 2.593614115085528

Epoch: 5| Step: 5
Training loss: 2.889616919342728
Validation loss: 2.5916360682084614

Epoch: 5| Step: 6
Training loss: 2.5869077032233556
Validation loss: 2.5888151693376327

Epoch: 5| Step: 7
Training loss: 2.4386453138570348
Validation loss: 2.589929056656571

Epoch: 5| Step: 8
Training loss: 2.593851478154186
Validation loss: 2.5878514316877825

Epoch: 5| Step: 9
Training loss: 2.7679408662852083
Validation loss: 2.5884812473995518

Epoch: 5| Step: 10
Training loss: 2.8106572366112323
Validation loss: 2.5900013886697155

Epoch: 5| Step: 11
Training loss: 2.5635149736705567
Validation loss: 2.5878869513719502

Epoch: 79| Step: 0
Training loss: 2.6411941185892247
Validation loss: 2.5869473140428063

Epoch: 5| Step: 1
Training loss: 2.6731979931686976
Validation loss: 2.5854086781782315

Epoch: 5| Step: 2
Training loss: 2.730602168369515
Validation loss: 2.586424006770618

Epoch: 5| Step: 3
Training loss: 2.8161010576830763
Validation loss: 2.582682182684472

Epoch: 5| Step: 4
Training loss: 2.5849647190482825
Validation loss: 2.585242282653638

Epoch: 5| Step: 5
Training loss: 2.941860128494385
Validation loss: 2.586789796483953

Epoch: 5| Step: 6
Training loss: 2.3450562969355597
Validation loss: 2.5878239115627064

Epoch: 5| Step: 7
Training loss: 2.730852397549107
Validation loss: 2.5922172184444525

Epoch: 5| Step: 8
Training loss: 2.782610014242658
Validation loss: 2.601383218325153

Epoch: 5| Step: 9
Training loss: 3.191855353479255
Validation loss: 2.619703618738392

Epoch: 5| Step: 10
Training loss: 2.5617659843350435
Validation loss: 2.6080399408158663

Epoch: 5| Step: 11
Training loss: 2.610344620969072
Validation loss: 2.6043469303047466

Epoch: 80| Step: 0
Training loss: 2.8987061409471884
Validation loss: 2.6044994764651532

Epoch: 5| Step: 1
Training loss: 2.8326940563287546
Validation loss: 2.590698496225032

Epoch: 5| Step: 2
Training loss: 2.3899521223563793
Validation loss: 2.585776774471924

Epoch: 5| Step: 3
Training loss: 2.8916144249967215
Validation loss: 2.584146284555874

Epoch: 5| Step: 4
Training loss: 2.6677971668837217
Validation loss: 2.5817003062079884

Epoch: 5| Step: 5
Training loss: 2.4916679773571775
Validation loss: 2.581654084899203

Epoch: 5| Step: 6
Training loss: 2.533208960274216
Validation loss: 2.581161956732646

Epoch: 5| Step: 7
Training loss: 2.8939402771055267
Validation loss: 2.58377624888406

Epoch: 5| Step: 8
Training loss: 2.8436416773024695
Validation loss: 2.5766545041978746

Epoch: 5| Step: 9
Training loss: 2.9731871523083386
Validation loss: 2.5768909930462973

Epoch: 5| Step: 10
Training loss: 2.6509322847735266
Validation loss: 2.576310659916326

Epoch: 5| Step: 11
Training loss: 2.0499365820030566
Validation loss: 2.57208478789662

Epoch: 81| Step: 0
Training loss: 2.734131807684255
Validation loss: 2.5730753410822165

Epoch: 5| Step: 1
Training loss: 2.465024043772586
Validation loss: 2.5744121056327796

Epoch: 5| Step: 2
Training loss: 2.5342605960109257
Validation loss: 2.576333866805702

Epoch: 5| Step: 3
Training loss: 2.820737431603753
Validation loss: 2.5754273721974092

Epoch: 5| Step: 4
Training loss: 2.705254217813107
Validation loss: 2.5757634029709253

Epoch: 5| Step: 5
Training loss: 3.2594967520367444
Validation loss: 2.5738145224332927

Epoch: 5| Step: 6
Training loss: 2.966657844987533
Validation loss: 2.5744931774670095

Epoch: 5| Step: 7
Training loss: 2.1341671397029773
Validation loss: 2.574758117157397

Epoch: 5| Step: 8
Training loss: 2.3612153410500922
Validation loss: 2.572097359582017

Epoch: 5| Step: 9
Training loss: 3.106242840334587
Validation loss: 2.570694633144869

Epoch: 5| Step: 10
Training loss: 2.7781467054997386
Validation loss: 2.56977525563303

Epoch: 5| Step: 11
Training loss: 0.5854616649026928
Validation loss: 2.566176165636401

Epoch: 82| Step: 0
Training loss: 2.2376563246690817
Validation loss: 2.568264184693834

Epoch: 5| Step: 1
Training loss: 2.9685015122671774
Validation loss: 2.5651413516271706

Epoch: 5| Step: 2
Training loss: 3.454516790581382
Validation loss: 2.566764299488546

Epoch: 5| Step: 3
Training loss: 2.68930117552555
Validation loss: 2.5647751973201562

Epoch: 5| Step: 4
Training loss: 2.5771457546345924
Validation loss: 2.567311983037162

Epoch: 5| Step: 5
Training loss: 2.8084659043290534
Validation loss: 2.567366580517632

Epoch: 5| Step: 6
Training loss: 2.576543982111338
Validation loss: 2.572714710160248

Epoch: 5| Step: 7
Training loss: 1.8100984382205803
Validation loss: 2.5649318475821716

Epoch: 5| Step: 8
Training loss: 2.7511238922653525
Validation loss: 2.566382324323991

Epoch: 5| Step: 9
Training loss: 2.5673004404161746
Validation loss: 2.563262039169939

Epoch: 5| Step: 10
Training loss: 2.99545945835329
Validation loss: 2.5603511530847

Epoch: 5| Step: 11
Training loss: 2.701254842701763
Validation loss: 2.561451976737726

Epoch: 83| Step: 0
Training loss: 2.933939297537654
Validation loss: 2.56235598337779

Epoch: 5| Step: 1
Training loss: 2.841151800711729
Validation loss: 2.5667177279355693

Epoch: 5| Step: 2
Training loss: 2.724185639933129
Validation loss: 2.5678066766152985

Epoch: 5| Step: 3
Training loss: 2.7068611741136768
Validation loss: 2.5680338257986133

Epoch: 5| Step: 4
Training loss: 2.670735434068501
Validation loss: 2.57003375303366

Epoch: 5| Step: 5
Training loss: 2.929435210491234
Validation loss: 2.5697182506583323

Epoch: 5| Step: 6
Training loss: 2.543838656893296
Validation loss: 2.568118046589995

Epoch: 5| Step: 7
Training loss: 2.6443976364302904
Validation loss: 2.568093672668302

Epoch: 5| Step: 8
Training loss: 2.9442680793900933
Validation loss: 2.5640885848648525

Epoch: 5| Step: 9
Training loss: 2.1821721180025855
Validation loss: 2.5629594088654333

Epoch: 5| Step: 10
Training loss: 2.498156440008288
Validation loss: 2.562623108255927

Epoch: 5| Step: 11
Training loss: 2.5334839558579887
Validation loss: 2.5602283332989875

Epoch: 84| Step: 0
Training loss: 2.463533999624009
Validation loss: 2.5588698065929614

Epoch: 5| Step: 1
Training loss: 2.509332404244251
Validation loss: 2.5597990540960085

Epoch: 5| Step: 2
Training loss: 2.509766764955967
Validation loss: 2.5548326488016735

Epoch: 5| Step: 3
Training loss: 2.2318008640424716
Validation loss: 2.554427474901406

Epoch: 5| Step: 4
Training loss: 2.435546875
Validation loss: 2.553883744003819

Epoch: 5| Step: 5
Training loss: 3.0397123215733433
Validation loss: 2.5532333326137784

Epoch: 5| Step: 6
Training loss: 2.501394264525599
Validation loss: 2.551710204011119

Epoch: 5| Step: 7
Training loss: 2.990916965945423
Validation loss: 2.5511474346531604

Epoch: 5| Step: 8
Training loss: 2.7270745176479294
Validation loss: 2.553316963882447

Epoch: 5| Step: 9
Training loss: 3.033488282937603
Validation loss: 2.5480626268497923

Epoch: 5| Step: 10
Training loss: 2.923829429692428
Validation loss: 2.5456024103171546

Epoch: 5| Step: 11
Training loss: 2.981116628162677
Validation loss: 2.545716601493113

Epoch: 85| Step: 0
Training loss: 2.502131888251707
Validation loss: 2.5474689508766524

Epoch: 5| Step: 1
Training loss: 2.6087387131509416
Validation loss: 2.5493462319764357

Epoch: 5| Step: 2
Training loss: 2.869937419940121
Validation loss: 2.5500633978286706

Epoch: 5| Step: 3
Training loss: 2.2122584194902983
Validation loss: 2.550046689410155

Epoch: 5| Step: 4
Training loss: 2.4674872536991894
Validation loss: 2.5520490209387794

Epoch: 5| Step: 5
Training loss: 2.7234967766426332
Validation loss: 2.5537330757771586

Epoch: 5| Step: 6
Training loss: 2.6604270853203538
Validation loss: 2.553170857354244

Epoch: 5| Step: 7
Training loss: 2.8270547432930844
Validation loss: 2.554273317069625

Epoch: 5| Step: 8
Training loss: 3.2720208573644256
Validation loss: 2.551709195693506

Epoch: 5| Step: 9
Training loss: 2.8607649629777137
Validation loss: 2.551487449574762

Epoch: 5| Step: 10
Training loss: 2.3945879034960442
Validation loss: 2.5483159433669265

Epoch: 5| Step: 11
Training loss: 2.4587352768923125
Validation loss: 2.5479523967900355

Epoch: 86| Step: 0
Training loss: 2.1199233055637103
Validation loss: 2.545762741673096

Epoch: 5| Step: 1
Training loss: 2.55652181583902
Validation loss: 2.5448671317000824

Epoch: 5| Step: 2
Training loss: 2.4359794177546665
Validation loss: 2.5434356471785065

Epoch: 5| Step: 3
Training loss: 2.7516453762451527
Validation loss: 2.542429533325448

Epoch: 5| Step: 4
Training loss: 2.3288378552231603
Validation loss: 2.5404665854952557

Epoch: 5| Step: 5
Training loss: 3.2291971676934432
Validation loss: 2.544785561061743

Epoch: 5| Step: 6
Training loss: 2.73619010626225
Validation loss: 2.542200674700073

Epoch: 5| Step: 7
Training loss: 2.9229129029021137
Validation loss: 2.540233216961749

Epoch: 5| Step: 8
Training loss: 2.663045918549009
Validation loss: 2.5415488213177637

Epoch: 5| Step: 9
Training loss: 2.496899303179547
Validation loss: 2.5399818829518597

Epoch: 5| Step: 10
Training loss: 2.9270403079381113
Validation loss: 2.539852352043674

Epoch: 5| Step: 11
Training loss: 3.0486423159667524
Validation loss: 2.5340572653461684

Epoch: 87| Step: 0
Training loss: 2.7472317373918616
Validation loss: 2.5359544756202275

Epoch: 5| Step: 1
Training loss: 2.6632220153398256
Validation loss: 2.5364607406907664

Epoch: 5| Step: 2
Training loss: 3.0065829848029866
Validation loss: 2.536642562682347

Epoch: 5| Step: 3
Training loss: 2.6715458895900603
Validation loss: 2.538081142826598

Epoch: 5| Step: 4
Training loss: 2.7236116284695173
Validation loss: 2.539165917271135

Epoch: 5| Step: 5
Training loss: 2.6210765582230064
Validation loss: 2.539872643752205

Epoch: 5| Step: 6
Training loss: 2.443865655762261
Validation loss: 2.5403289922778836

Epoch: 5| Step: 7
Training loss: 2.570410729476281
Validation loss: 2.5400190576266426

Epoch: 5| Step: 8
Training loss: 2.640084115335601
Validation loss: 2.537927594981518

Epoch: 5| Step: 9
Training loss: 2.6131285207962374
Validation loss: 2.5369161209692126

Epoch: 5| Step: 10
Training loss: 2.669460075307074
Validation loss: 2.5356510739407656

Epoch: 5| Step: 11
Training loss: 2.7818278023241207
Validation loss: 2.533606441002169

Epoch: 88| Step: 0
Training loss: 2.94507806386284
Validation loss: 2.531177931807507

Epoch: 5| Step: 1
Training loss: 3.235656484414227
Validation loss: 2.5307238506840433

Epoch: 5| Step: 2
Training loss: 2.3496134338597527
Validation loss: 2.535235015319541

Epoch: 5| Step: 3
Training loss: 2.4849789443169796
Validation loss: 2.5331202101048427

Epoch: 5| Step: 4
Training loss: 2.87159593822353
Validation loss: 2.5397529289335607

Epoch: 5| Step: 5
Training loss: 2.2780314694475705
Validation loss: 2.533496095632131

Epoch: 5| Step: 6
Training loss: 1.9996927144500805
Validation loss: 2.5326035534385394

Epoch: 5| Step: 7
Training loss: 2.7036819325281316
Validation loss: 2.530285396373446

Epoch: 5| Step: 8
Training loss: 2.702078203143973
Validation loss: 2.529031715584366

Epoch: 5| Step: 9
Training loss: 2.6855683592890633
Validation loss: 2.530060853791695

Epoch: 5| Step: 10
Training loss: 2.762611083131874
Validation loss: 2.526475819249097

Epoch: 5| Step: 11
Training loss: 3.142098911275281
Validation loss: 2.530344251581328

Epoch: 89| Step: 0
Training loss: 2.359948398058272
Validation loss: 2.5283286304614547

Epoch: 5| Step: 1
Training loss: 2.6483698023243054
Validation loss: 2.5298143483450697

Epoch: 5| Step: 2
Training loss: 2.768224927313433
Validation loss: 2.5286256309406787

Epoch: 5| Step: 3
Training loss: 2.912800451670598
Validation loss: 2.529084739478864

Epoch: 5| Step: 4
Training loss: 2.774462873008686
Validation loss: 2.5269861494048813

Epoch: 5| Step: 5
Training loss: 2.3750765938705447
Validation loss: 2.5231797565991076

Epoch: 5| Step: 6
Training loss: 2.5411948302848226
Validation loss: 2.5243814511778266

Epoch: 5| Step: 7
Training loss: 2.57315768658695
Validation loss: 2.5268288804773156

Epoch: 5| Step: 8
Training loss: 2.7610932198841787
Validation loss: 2.5248369955885375

Epoch: 5| Step: 9
Training loss: 3.017716231164066
Validation loss: 2.523026353156387

Epoch: 5| Step: 10
Training loss: 2.3845196721294752
Validation loss: 2.5263100995983008

Epoch: 5| Step: 11
Training loss: 2.654529867268994
Validation loss: 2.521185857514521

Epoch: 90| Step: 0
Training loss: 2.529648639269727
Validation loss: 2.522345220885208

Epoch: 5| Step: 1
Training loss: 2.5394801339222832
Validation loss: 2.52176321365693

Epoch: 5| Step: 2
Training loss: 2.966462870537953
Validation loss: 2.5249466138175243

Epoch: 5| Step: 3
Training loss: 2.455611991042012
Validation loss: 2.5212531029274414

Epoch: 5| Step: 4
Training loss: 2.5727147526349072
Validation loss: 2.5233479809703354

Epoch: 5| Step: 5
Training loss: 2.554976140786166
Validation loss: 2.5212153875597356

Epoch: 5| Step: 6
Training loss: 2.792458056729983
Validation loss: 2.523031967850606

Epoch: 5| Step: 7
Training loss: 2.2766883914780407
Validation loss: 2.5226576577398556

Epoch: 5| Step: 8
Training loss: 2.868377521742696
Validation loss: 2.524062237796421

Epoch: 5| Step: 9
Training loss: 2.7213345224258587
Validation loss: 2.5193971267999156

Epoch: 5| Step: 10
Training loss: 2.6465057259574625
Validation loss: 2.5203105381774518

Epoch: 5| Step: 11
Training loss: 3.4537855526298515
Validation loss: 2.519752335027887

Epoch: 91| Step: 0
Training loss: 2.5817096180931234
Validation loss: 2.5160977095182484

Epoch: 5| Step: 1
Training loss: 2.6682234233432256
Validation loss: 2.524851797337242

Epoch: 5| Step: 2
Training loss: 2.9817819564589656
Validation loss: 2.5208750135480673

Epoch: 5| Step: 3
Training loss: 2.9895151021971187
Validation loss: 2.5210460475888508

Epoch: 5| Step: 4
Training loss: 2.2610870164258627
Validation loss: 2.5253659921041205

Epoch: 5| Step: 5
Training loss: 2.288577917058165
Validation loss: 2.5170086003637664

Epoch: 5| Step: 6
Training loss: 2.6015796374423816
Validation loss: 2.5205733083703716

Epoch: 5| Step: 7
Training loss: 2.400452602942747
Validation loss: 2.51921644585208

Epoch: 5| Step: 8
Training loss: 2.5250932204157435
Validation loss: 2.5165950650225146

Epoch: 5| Step: 9
Training loss: 2.913410185346556
Validation loss: 2.5181853137032726

Epoch: 5| Step: 10
Training loss: 2.8794926909168317
Validation loss: 2.519849909855324

Epoch: 5| Step: 11
Training loss: 2.071340284204295
Validation loss: 2.516525312794995

Epoch: 92| Step: 0
Training loss: 2.217493265479354
Validation loss: 2.5182006792247478

Epoch: 5| Step: 1
Training loss: 2.6964117047838885
Validation loss: 2.516594536065529

Epoch: 5| Step: 2
Training loss: 2.680560178428797
Validation loss: 2.5148811089485275

Epoch: 5| Step: 3
Training loss: 2.2124915171315136
Validation loss: 2.515469125692798

Epoch: 5| Step: 4
Training loss: 2.7482707915892473
Validation loss: 2.5176116767504126

Epoch: 5| Step: 5
Training loss: 2.769815836544297
Validation loss: 2.517609265837474

Epoch: 5| Step: 6
Training loss: 2.6873982432418795
Validation loss: 2.517628817446221

Epoch: 5| Step: 7
Training loss: 2.6841018839798134
Validation loss: 2.5197958203571007

Epoch: 5| Step: 8
Training loss: 3.0365684493672904
Validation loss: 2.510026000453081

Epoch: 5| Step: 9
Training loss: 2.36535190633616
Validation loss: 2.5191741729756574

Epoch: 5| Step: 10
Training loss: 2.9612883910962977
Validation loss: 2.5151350835618227

Epoch: 5| Step: 11
Training loss: 1.5005857595502954
Validation loss: 2.5162668850605887

Epoch: 93| Step: 0
Training loss: 2.630314578689673
Validation loss: 2.512315085076508

Epoch: 5| Step: 1
Training loss: 2.8948058539929775
Validation loss: 2.512160104721716

Epoch: 5| Step: 2
Training loss: 2.9615519749107317
Validation loss: 2.518956401215192

Epoch: 5| Step: 3
Training loss: 2.9479652823133957
Validation loss: 2.5108450185143227

Epoch: 5| Step: 4
Training loss: 2.427064909203363
Validation loss: 2.512584325536179

Epoch: 5| Step: 5
Training loss: 2.2296514132599516
Validation loss: 2.516938086003967

Epoch: 5| Step: 6
Training loss: 2.4812127867245426
Validation loss: 2.5138627389621444

Epoch: 5| Step: 7
Training loss: 2.928040226998743
Validation loss: 2.5143573086304496

Epoch: 5| Step: 8
Training loss: 2.166657032089331
Validation loss: 2.514300497235951

Epoch: 5| Step: 9
Training loss: 2.8407801956066536
Validation loss: 2.5130087751715275

Epoch: 5| Step: 10
Training loss: 2.5435687176266857
Validation loss: 2.508300785210493

Epoch: 5| Step: 11
Training loss: 2.378420123962917
Validation loss: 2.512766056619148

Epoch: 94| Step: 0
Training loss: 2.9255271567005297
Validation loss: 2.510107374858208

Epoch: 5| Step: 1
Training loss: 2.5236776609667095
Validation loss: 2.5096816468197294

Epoch: 5| Step: 2
Training loss: 2.757066577178076
Validation loss: 2.5118245151493146

Epoch: 5| Step: 3
Training loss: 2.769857842002868
Validation loss: 2.512015922847475

Epoch: 5| Step: 4
Training loss: 2.2396479989112352
Validation loss: 2.5110398834060983

Epoch: 5| Step: 5
Training loss: 2.756555027421303
Validation loss: 2.5042751157596084

Epoch: 5| Step: 6
Training loss: 2.611723796395719
Validation loss: 2.506839642721979

Epoch: 5| Step: 7
Training loss: 2.913239145422224
Validation loss: 2.5121047542551076

Epoch: 5| Step: 8
Training loss: 2.284454081323701
Validation loss: 2.509278555188886

Epoch: 5| Step: 9
Training loss: 2.155502521489526
Validation loss: 2.5123749860024644

Epoch: 5| Step: 10
Training loss: 2.8602251967221664
Validation loss: 2.510923043039099

Epoch: 5| Step: 11
Training loss: 2.4408159442602146
Validation loss: 2.5117541499038576

Epoch: 95| Step: 0
Training loss: 2.607041646258208
Validation loss: 2.5064414208894554

Epoch: 5| Step: 1
Training loss: 2.657376218911325
Validation loss: 2.5109678404675604

Epoch: 5| Step: 2
Training loss: 2.9114782415720475
Validation loss: 2.517963578197862

Epoch: 5| Step: 3
Training loss: 2.3659037013896547
Validation loss: 2.5177793262106944

Epoch: 5| Step: 4
Training loss: 2.3706654597037256
Validation loss: 2.5050571433038815

Epoch: 5| Step: 5
Training loss: 2.369230591024188
Validation loss: 2.506851334940027

Epoch: 5| Step: 6
Training loss: 2.825766407128992
Validation loss: 2.5090611954799384

Epoch: 5| Step: 7
Training loss: 2.654070689463717
Validation loss: 2.5077776287502576

Epoch: 5| Step: 8
Training loss: 2.7694284611016164
Validation loss: 2.506269540813622

Epoch: 5| Step: 9
Training loss: 2.653759046441218
Validation loss: 2.5049899965075095

Epoch: 5| Step: 10
Training loss: 2.769022691787313
Validation loss: 2.5048730048172905

Epoch: 5| Step: 11
Training loss: 2.9429436423595496
Validation loss: 2.5057578340068125

Epoch: 96| Step: 0
Training loss: 2.8143159725700904
Validation loss: 2.5061326624926163

Epoch: 5| Step: 1
Training loss: 2.5477490007864394
Validation loss: 2.506148058307629

Epoch: 5| Step: 2
Training loss: 2.344413561665287
Validation loss: 2.508283271849728

Epoch: 5| Step: 3
Training loss: 2.8179720733428386
Validation loss: 2.5076865425049406

Epoch: 5| Step: 4
Training loss: 2.397965872552763
Validation loss: 2.5080970234359814

Epoch: 5| Step: 5
Training loss: 2.4842981290620654
Validation loss: 2.5065514155746276

Epoch: 5| Step: 6
Training loss: 3.061437928680265
Validation loss: 2.505793026734332

Epoch: 5| Step: 7
Training loss: 2.6322123129240236
Validation loss: 2.5056613993567995

Epoch: 5| Step: 8
Training loss: 2.3906657894868335
Validation loss: 2.506089296841006

Epoch: 5| Step: 9
Training loss: 2.449713308726634
Validation loss: 2.5018589141999468

Epoch: 5| Step: 10
Training loss: 2.8634101453550906
Validation loss: 2.5078687691243458

Epoch: 5| Step: 11
Training loss: 2.764577376228206
Validation loss: 2.5032705014691365

Epoch: 97| Step: 0
Training loss: 2.8434300504679726
Validation loss: 2.505491507712036

Epoch: 5| Step: 1
Training loss: 2.531990319768351
Validation loss: 2.505379951821722

Epoch: 5| Step: 2
Training loss: 2.3738533062624825
Validation loss: 2.5010983239974487

Epoch: 5| Step: 3
Training loss: 2.6423217017473295
Validation loss: 2.5059069626239823

Epoch: 5| Step: 4
Training loss: 2.63703774112084
Validation loss: 2.498701954663254

Epoch: 5| Step: 5
Training loss: 2.6010602403211074
Validation loss: 2.505985307390871

Epoch: 5| Step: 6
Training loss: 2.476956020342102
Validation loss: 2.5033003797618285

Epoch: 5| Step: 7
Training loss: 2.9635082348019988
Validation loss: 2.502465085793707

Epoch: 5| Step: 8
Training loss: 2.792813554199949
Validation loss: 2.503433032059023

Epoch: 5| Step: 9
Training loss: 2.4707149942587923
Validation loss: 2.503611804711596

Epoch: 5| Step: 10
Training loss: 2.505975067964517
Validation loss: 2.5004747893571517

Epoch: 5| Step: 11
Training loss: 2.157382833364831
Validation loss: 2.50026653776296

Epoch: 98| Step: 0
Training loss: 2.4908611152182685
Validation loss: 2.507916952396074

Epoch: 5| Step: 1
Training loss: 2.8802109638406743
Validation loss: 2.513438971063447

Epoch: 5| Step: 2
Training loss: 2.533947860903966
Validation loss: 2.5163875158702744

Epoch: 5| Step: 3
Training loss: 2.9904006921721464
Validation loss: 2.5188559324518294

Epoch: 5| Step: 4
Training loss: 2.5372012784668097
Validation loss: 2.5198757635945794

Epoch: 5| Step: 5
Training loss: 2.700920308411586
Validation loss: 2.5169285897403215

Epoch: 5| Step: 6
Training loss: 2.255113935954399
Validation loss: 2.5164334911256425

Epoch: 5| Step: 7
Training loss: 2.7783529216012526
Validation loss: 2.507712274055863

Epoch: 5| Step: 8
Training loss: 2.641594342064993
Validation loss: 2.503547682457449

Epoch: 5| Step: 9
Training loss: 2.4439803812453884
Validation loss: 2.5035428017978254

Epoch: 5| Step: 10
Training loss: 2.5699827220350797
Validation loss: 2.499158968125515

Epoch: 5| Step: 11
Training loss: 2.946641859781554
Validation loss: 2.499934143947405

Epoch: 99| Step: 0
Training loss: 2.5618495580857514
Validation loss: 2.4999827265142693

Epoch: 5| Step: 1
Training loss: 2.4209378305840947
Validation loss: 2.497918601641145

Epoch: 5| Step: 2
Training loss: 2.4817296945712086
Validation loss: 2.499023133397503

Epoch: 5| Step: 3
Training loss: 2.458799274922443
Validation loss: 2.499231057327047

Epoch: 5| Step: 4
Training loss: 2.461777219861845
Validation loss: 2.500283658306651

Epoch: 5| Step: 5
Training loss: 2.8788926681964226
Validation loss: 2.5011826578861354

Epoch: 5| Step: 6
Training loss: 3.157536461650575
Validation loss: 2.4943004488240597

Epoch: 5| Step: 7
Training loss: 2.574221713769159
Validation loss: 2.495744982308853

Epoch: 5| Step: 8
Training loss: 2.753153120367084
Validation loss: 2.4956629326104047

Epoch: 5| Step: 9
Training loss: 2.802822842680424
Validation loss: 2.498431023356123

Epoch: 5| Step: 10
Training loss: 2.2325155350335772
Validation loss: 2.4962900708382083

Epoch: 5| Step: 11
Training loss: 1.6714782244022441
Validation loss: 2.49815863905352

Epoch: 100| Step: 0
Training loss: 2.366896910504307
Validation loss: 2.494891140148597

Epoch: 5| Step: 1
Training loss: 2.335925966572437
Validation loss: 2.5022168582562707

Epoch: 5| Step: 2
Training loss: 2.3721587603158154
Validation loss: 2.4925255660758134

Epoch: 5| Step: 3
Training loss: 2.9730543554259787
Validation loss: 2.5021371448668868

Epoch: 5| Step: 4
Training loss: 2.225126425762415
Validation loss: 2.5000863815324976

Epoch: 5| Step: 5
Training loss: 2.6234538656591044
Validation loss: 2.497571110997012

Epoch: 5| Step: 6
Training loss: 2.4690227116482273
Validation loss: 2.4927820475086215

Epoch: 5| Step: 7
Training loss: 3.2127503709413663
Validation loss: 2.492789149033723

Epoch: 5| Step: 8
Training loss: 2.9330615336755463
Validation loss: 2.496660975011323

Epoch: 5| Step: 9
Training loss: 2.27052849872969
Validation loss: 2.500268651514776

Epoch: 5| Step: 10
Training loss: 2.8039783654514308
Validation loss: 2.4919729030777944

Epoch: 5| Step: 11
Training loss: 2.2438057300160223
Validation loss: 2.4993913982604146

Epoch: 101| Step: 0
Training loss: 2.4090265875616352
Validation loss: 2.4919570449578377

Epoch: 5| Step: 1
Training loss: 2.5365296862290205
Validation loss: 2.5005261920462867

Epoch: 5| Step: 2
Training loss: 2.3622631055145598
Validation loss: 2.513795538890833

Epoch: 5| Step: 3
Training loss: 2.9863238138151518
Validation loss: 2.5387578654327836

Epoch: 5| Step: 4
Training loss: 2.6271215675550477
Validation loss: 2.5801286791099165

Epoch: 5| Step: 5
Training loss: 3.037847987206006
Validation loss: 2.5781097141930154

Epoch: 5| Step: 6
Training loss: 2.519567870827612
Validation loss: 2.5849852023386743

Epoch: 5| Step: 7
Training loss: 2.5840670456352117
Validation loss: 2.583147458854833

Epoch: 5| Step: 8
Training loss: 2.9015417210210304
Validation loss: 2.5523433293362774

Epoch: 5| Step: 9
Training loss: 2.4211072135420464
Validation loss: 2.5266866797742487

Epoch: 5| Step: 10
Training loss: 2.8976738841532543
Validation loss: 2.511908781576373

Epoch: 5| Step: 11
Training loss: 1.9014663709605275
Validation loss: 2.503874470573058

Epoch: 102| Step: 0
Training loss: 2.5532324143859952
Validation loss: 2.499681047120548

Epoch: 5| Step: 1
Training loss: 2.8549142865410326
Validation loss: 2.498841080665049

Epoch: 5| Step: 2
Training loss: 2.514041662989269
Validation loss: 2.5018568970883517

Epoch: 5| Step: 3
Training loss: 2.5315295406503844
Validation loss: 2.501487567517179

Epoch: 5| Step: 4
Training loss: 2.769648066587205
Validation loss: 2.5040789746456196

Epoch: 5| Step: 5
Training loss: 2.981860154770002
Validation loss: 2.504198685111834

Epoch: 5| Step: 6
Training loss: 2.781033711113523
Validation loss: 2.5115331261814786

Epoch: 5| Step: 7
Training loss: 2.938609623835951
Validation loss: 2.516933618107164

Epoch: 5| Step: 8
Training loss: 2.3858231332844917
Validation loss: 2.5066066984369844

Epoch: 5| Step: 9
Training loss: 2.400497694863387
Validation loss: 2.5053888614083744

Epoch: 5| Step: 10
Training loss: 2.048402871218194
Validation loss: 2.494557588037802

Epoch: 5| Step: 11
Training loss: 3.1010056002903683
Validation loss: 2.4918711151546917

Epoch: 103| Step: 0
Training loss: 2.4197067891765642
Validation loss: 2.4969628521897365

Epoch: 5| Step: 1
Training loss: 2.6965072858539756
Validation loss: 2.493863386350618

Epoch: 5| Step: 2
Training loss: 2.7314170314946353
Validation loss: 2.4919040761921973

Epoch: 5| Step: 3
Training loss: 2.6077607238274023
Validation loss: 2.484022871289947

Epoch: 5| Step: 4
Training loss: 2.6821045943025883
Validation loss: 2.487255266185598

Epoch: 5| Step: 5
Training loss: 2.1675783097883548
Validation loss: 2.4845251641785624

Epoch: 5| Step: 6
Training loss: 2.7884095867589203
Validation loss: 2.4891806174343776

Epoch: 5| Step: 7
Training loss: 2.776222227903165
Validation loss: 2.493177813103432

Epoch: 5| Step: 8
Training loss: 2.6589575936392307
Validation loss: 2.488004372611297

Epoch: 5| Step: 9
Training loss: 2.4843916982413474
Validation loss: 2.491035218959613

Epoch: 5| Step: 10
Training loss: 2.48747185159217
Validation loss: 2.4907472847690144

Epoch: 5| Step: 11
Training loss: 3.118777985533256
Validation loss: 2.4922235540096014

Epoch: 104| Step: 0
Training loss: 2.469011993026807
Validation loss: 2.489831885429356

Epoch: 5| Step: 1
Training loss: 2.475536049485001
Validation loss: 2.4890990358150873

Epoch: 5| Step: 2
Training loss: 2.4020076857800405
Validation loss: 2.4910884574351067

Epoch: 5| Step: 3
Training loss: 2.2169076496964673
Validation loss: 2.4912807644726

Epoch: 5| Step: 4
Training loss: 2.4520513043598102
Validation loss: 2.4914329008230256

Epoch: 5| Step: 5
Training loss: 2.93358448499494
Validation loss: 2.487548001463604

Epoch: 5| Step: 6
Training loss: 2.64276812561823
Validation loss: 2.4915026976517005

Epoch: 5| Step: 7
Training loss: 2.479404106844348
Validation loss: 2.4912011477702856

Epoch: 5| Step: 8
Training loss: 2.937730820697827
Validation loss: 2.4861360382331665

Epoch: 5| Step: 9
Training loss: 2.934501578593971
Validation loss: 2.484295062012649

Epoch: 5| Step: 10
Training loss: 2.677470811244888
Validation loss: 2.488545601864164

Epoch: 5| Step: 11
Training loss: 2.44927365182186
Validation loss: 2.481818068949781

Epoch: 105| Step: 0
Training loss: 2.634822994707603
Validation loss: 2.482696930148306

Epoch: 5| Step: 1
Training loss: 2.83144760957993
Validation loss: 2.4771796820286087

Epoch: 5| Step: 2
Training loss: 2.295581790923508
Validation loss: 2.482200914859201

Epoch: 5| Step: 3
Training loss: 2.491868145131714
Validation loss: 2.4754377352101495

Epoch: 5| Step: 4
Training loss: 2.29483034641281
Validation loss: 2.4852574218827463

Epoch: 5| Step: 5
Training loss: 2.790032995295512
Validation loss: 2.4846362450434394

Epoch: 5| Step: 6
Training loss: 2.448565966480342
Validation loss: 2.47758811628462

Epoch: 5| Step: 7
Training loss: 2.772467473134248
Validation loss: 2.474634320445232

Epoch: 5| Step: 8
Training loss: 2.4274054601392447
Validation loss: 2.481844354896784

Epoch: 5| Step: 9
Training loss: 2.8906949421436976
Validation loss: 2.4832561420651595

Epoch: 5| Step: 10
Training loss: 2.60013199617875
Validation loss: 2.483663489062684

Epoch: 5| Step: 11
Training loss: 2.6822793509685154
Validation loss: 2.483196182805346

Epoch: 106| Step: 0
Training loss: 2.8603567303747273
Validation loss: 2.4844060092166385

Epoch: 5| Step: 1
Training loss: 2.889189492586505
Validation loss: 2.489781748208456

Epoch: 5| Step: 2
Training loss: 2.30948359707716
Validation loss: 2.4927860824685473

Epoch: 5| Step: 3
Training loss: 2.489965231319492
Validation loss: 2.494130293133435

Epoch: 5| Step: 4
Training loss: 2.9842601174816354
Validation loss: 2.4949218235560364

Epoch: 5| Step: 5
Training loss: 2.7593159238338756
Validation loss: 2.4978022849583073

Epoch: 5| Step: 6
Training loss: 2.468190383257615
Validation loss: 2.500635610683627

Epoch: 5| Step: 7
Training loss: 2.4186853878252834
Validation loss: 2.502321353668814

Epoch: 5| Step: 8
Training loss: 2.7398168853495632
Validation loss: 2.5041085695603535

Epoch: 5| Step: 9
Training loss: 2.7578155258205337
Validation loss: 2.5026370008989485

Epoch: 5| Step: 10
Training loss: 2.1688524249512784
Validation loss: 2.4990293963113936

Epoch: 5| Step: 11
Training loss: 2.0267393060055987
Validation loss: 2.499834090926568

Epoch: 107| Step: 0
Training loss: 3.083339244390097
Validation loss: 2.4952984429880942

Epoch: 5| Step: 1
Training loss: 2.367848118421885
Validation loss: 2.495924789210395

Epoch: 5| Step: 2
Training loss: 2.8174467029963237
Validation loss: 2.492271892270714

Epoch: 5| Step: 3
Training loss: 2.4663777603181143
Validation loss: 2.4941255971783933

Epoch: 5| Step: 4
Training loss: 2.6984863170809112
Validation loss: 2.489167658900687

Epoch: 5| Step: 5
Training loss: 2.744861049366319
Validation loss: 2.488551270402655

Epoch: 5| Step: 6
Training loss: 2.1629840904352657
Validation loss: 2.4875808840050335

Epoch: 5| Step: 7
Training loss: 2.3749035263544847
Validation loss: 2.48619545110384

Epoch: 5| Step: 8
Training loss: 2.4464035768793377
Validation loss: 2.4846676348234062

Epoch: 5| Step: 9
Training loss: 2.7779823566972297
Validation loss: 2.4850571893357825

Epoch: 5| Step: 10
Training loss: 2.742457102159273
Validation loss: 2.478150459325534

Epoch: 5| Step: 11
Training loss: 1.9061360559647564
Validation loss: 2.479013195149424

Epoch: 108| Step: 0
Training loss: 2.310262267512055
Validation loss: 2.476635997014564

Epoch: 5| Step: 1
Training loss: 2.5936214920749
Validation loss: 2.4809551613143763

Epoch: 5| Step: 2
Training loss: 2.9061786273683117
Validation loss: 2.4763540787947482

Epoch: 5| Step: 3
Training loss: 2.393993423076828
Validation loss: 2.4736665627272587

Epoch: 5| Step: 4
Training loss: 2.6883815827585527
Validation loss: 2.4869539562498733

Epoch: 5| Step: 5
Training loss: 2.2393626851055446
Validation loss: 2.4763786616720083

Epoch: 5| Step: 6
Training loss: 2.7728162472657782
Validation loss: 2.480165377910727

Epoch: 5| Step: 7
Training loss: 2.7853904507948086
Validation loss: 2.475792051985707

Epoch: 5| Step: 8
Training loss: 2.6684376875585483
Validation loss: 2.4801646729564615

Epoch: 5| Step: 9
Training loss: 2.4251901886283656
Validation loss: 2.4805368088724262

Epoch: 5| Step: 10
Training loss: 2.6553676261625285
Validation loss: 2.482949833785776

Epoch: 5| Step: 11
Training loss: 2.644342277683237
Validation loss: 2.476843845018443

Epoch: 109| Step: 0
Training loss: 2.178378898457323
Validation loss: 2.466044722313446

Epoch: 5| Step: 1
Training loss: 2.638008039819412
Validation loss: 2.4880518705239414

Epoch: 5| Step: 2
Training loss: 2.48458256844046
Validation loss: 2.4916312614421825

Epoch: 5| Step: 3
Training loss: 2.594788125269395
Validation loss: 2.497751748927422

Epoch: 5| Step: 4
Training loss: 2.728234333237687
Validation loss: 2.5007269954625624

Epoch: 5| Step: 5
Training loss: 2.664814146621703
Validation loss: 2.495184177960064

Epoch: 5| Step: 6
Training loss: 2.5301659228834295
Validation loss: 2.4908104922001497

Epoch: 5| Step: 7
Training loss: 2.509557004340054
Validation loss: 2.492258068907248

Epoch: 5| Step: 8
Training loss: 3.1609282617438685
Validation loss: 2.4770768691401814

Epoch: 5| Step: 9
Training loss: 2.705137088284502
Validation loss: 2.471558184923614

Epoch: 5| Step: 10
Training loss: 2.377415482776745
Validation loss: 2.472175326390713

Epoch: 5| Step: 11
Training loss: 2.736177558759051
Validation loss: 2.480499960234927

Epoch: 110| Step: 0
Training loss: 2.5942240821798745
Validation loss: 2.4830366524400493

Epoch: 5| Step: 1
Training loss: 2.0701119955605827
Validation loss: 2.4839617067524387

Epoch: 5| Step: 2
Training loss: 2.4607556472677863
Validation loss: 2.486584958028634

Epoch: 5| Step: 3
Training loss: 2.5683516701702396
Validation loss: 2.4872727279097564

Epoch: 5| Step: 4
Training loss: 2.3773460846988823
Validation loss: 2.4849004569670603

Epoch: 5| Step: 5
Training loss: 2.442080473308866
Validation loss: 2.487728386846513

Epoch: 5| Step: 6
Training loss: 2.984818510483903
Validation loss: 2.4834836304443018

Epoch: 5| Step: 7
Training loss: 2.50272773704881
Validation loss: 2.4822734045033785

Epoch: 5| Step: 8
Training loss: 3.013830095490192
Validation loss: 2.479579599969876

Epoch: 5| Step: 9
Training loss: 3.0035138214895745
Validation loss: 2.4839805153880095

Epoch: 5| Step: 10
Training loss: 2.515487572369541
Validation loss: 2.4817481098288896

Epoch: 5| Step: 11
Training loss: 1.369290418498112
Validation loss: 2.4828490483238905

Epoch: 111| Step: 0
Training loss: 2.358197859612413
Validation loss: 2.477644939513467

Epoch: 5| Step: 1
Training loss: 2.5651487291728525
Validation loss: 2.47516751236255

Epoch: 5| Step: 2
Training loss: 2.5369742389073235
Validation loss: 2.4761980793461995

Epoch: 5| Step: 3
Training loss: 2.3403647834560135
Validation loss: 2.4731709053664246

Epoch: 5| Step: 4
Training loss: 2.9142637617956666
Validation loss: 2.4634995419944636

Epoch: 5| Step: 5
Training loss: 2.564772458905603
Validation loss: 2.468388450480694

Epoch: 5| Step: 6
Training loss: 2.903300275326081
Validation loss: 2.4775140139815037

Epoch: 5| Step: 7
Training loss: 2.817023136974215
Validation loss: 2.4754439634885532

Epoch: 5| Step: 8
Training loss: 2.141934627685865
Validation loss: 2.4700658406042257

Epoch: 5| Step: 9
Training loss: 2.6117811245192466
Validation loss: 2.478833778589146

Epoch: 5| Step: 10
Training loss: 2.6716156772341453
Validation loss: 2.4752058892395454

Epoch: 5| Step: 11
Training loss: 1.9483916031755402
Validation loss: 2.475691155700021

Epoch: 112| Step: 0
Training loss: 2.688432930766542
Validation loss: 2.4793172811923836

Epoch: 5| Step: 1
Training loss: 2.6154091330065197
Validation loss: 2.4786199934007214

Epoch: 5| Step: 2
Training loss: 2.3235909776207424
Validation loss: 2.481317490077014

Epoch: 5| Step: 3
Training loss: 2.6281945907686897
Validation loss: 2.4810769043960006

Epoch: 5| Step: 4
Training loss: 2.4537932828096913
Validation loss: 2.4751160064637134

Epoch: 5| Step: 5
Training loss: 2.321085380505726
Validation loss: 2.4786142821099704

Epoch: 5| Step: 6
Training loss: 2.8420113079536002
Validation loss: 2.4690042718889256

Epoch: 5| Step: 7
Training loss: 2.1294079110771174
Validation loss: 2.4764129320742434

Epoch: 5| Step: 8
Training loss: 2.5615212036541917
Validation loss: 2.4791902386054963

Epoch: 5| Step: 9
Training loss: 3.176137080791924
Validation loss: 2.4815151140228133

Epoch: 5| Step: 10
Training loss: 2.158723821873362
Validation loss: 2.4783514442906585

Epoch: 5| Step: 11
Training loss: 3.951011122687655
Validation loss: 2.4771025958219957

Epoch: 113| Step: 0
Training loss: 2.2979125709070645
Validation loss: 2.4764573549238906

Epoch: 5| Step: 1
Training loss: 3.1825316359991995
Validation loss: 2.472786797988871

Epoch: 5| Step: 2
Training loss: 1.9227003480766998
Validation loss: 2.4695611538595537

Epoch: 5| Step: 3
Training loss: 2.560583095454394
Validation loss: 2.469250761019049

Epoch: 5| Step: 4
Training loss: 2.279198965602759
Validation loss: 2.469505214664545

Epoch: 5| Step: 5
Training loss: 2.569149693488585
Validation loss: 2.469277377878617

Epoch: 5| Step: 6
Training loss: 2.620363773397053
Validation loss: 2.4690397551261074

Epoch: 5| Step: 7
Training loss: 2.6233360829837773
Validation loss: 2.474944106347468

Epoch: 5| Step: 8
Training loss: 2.4709738843117472
Validation loss: 2.471223175843575

Epoch: 5| Step: 9
Training loss: 2.7633332493240963
Validation loss: 2.4734988311213213

Epoch: 5| Step: 10
Training loss: 2.7994477783336027
Validation loss: 2.4726647913716477

Epoch: 5| Step: 11
Training loss: 3.2683961053085793
Validation loss: 2.4714783147266606

Epoch: 114| Step: 0
Training loss: 2.39610520078089
Validation loss: 2.474998975361827

Epoch: 5| Step: 1
Training loss: 2.105119722273529
Validation loss: 2.4770618139946556

Epoch: 5| Step: 2
Training loss: 2.1023440131021065
Validation loss: 2.478579845753791

Epoch: 5| Step: 3
Training loss: 2.1624006921093195
Validation loss: 2.4801228199432943

Epoch: 5| Step: 4
Training loss: 3.006159499108793
Validation loss: 2.481132206334799

Epoch: 5| Step: 5
Training loss: 3.2252842031234965
Validation loss: 2.4821179691895248

Epoch: 5| Step: 6
Training loss: 2.9036430233427173
Validation loss: 2.4800275715646336

Epoch: 5| Step: 7
Training loss: 2.6644545459617692
Validation loss: 2.479013006807115

Epoch: 5| Step: 8
Training loss: 2.2901781507601626
Validation loss: 2.4774377401441265

Epoch: 5| Step: 9
Training loss: 2.7033201819718107
Validation loss: 2.481953274297801

Epoch: 5| Step: 10
Training loss: 2.6630903243282993
Validation loss: 2.4785223585778313

Epoch: 5| Step: 11
Training loss: 1.917071348121199
Validation loss: 2.4768669430664816

Epoch: 115| Step: 0
Training loss: 2.436587921084333
Validation loss: 2.468935742211441

Epoch: 5| Step: 1
Training loss: 2.2048932277579767
Validation loss: 2.471320371460382

Epoch: 5| Step: 2
Training loss: 2.459730645606951
Validation loss: 2.4987302436480143

Epoch: 5| Step: 3
Training loss: 3.577275471015928
Validation loss: 2.513374146972052

Epoch: 5| Step: 4
Training loss: 2.616315189575525
Validation loss: 2.5244489361182216

Epoch: 5| Step: 5
Training loss: 2.935941566842081
Validation loss: 2.518512726959673

Epoch: 5| Step: 6
Training loss: 2.159822462344453
Validation loss: 2.503559050786265

Epoch: 5| Step: 7
Training loss: 2.581552342772488
Validation loss: 2.4923934811539965

Epoch: 5| Step: 8
Training loss: 2.196922933345873
Validation loss: 2.478355015730614

Epoch: 5| Step: 9
Training loss: 2.7496587368154093
Validation loss: 2.476593645142666

Epoch: 5| Step: 10
Training loss: 2.861164304450723
Validation loss: 2.473425630471496

Epoch: 5| Step: 11
Training loss: 2.393136294904402
Validation loss: 2.4760778135347437

Epoch: 116| Step: 0
Training loss: 2.670240292541042
Validation loss: 2.4766887307713787

Epoch: 5| Step: 1
Training loss: 2.3846924416749924
Validation loss: 2.474943335684032

Epoch: 5| Step: 2
Training loss: 2.653601728727314
Validation loss: 2.4810610406960385

Epoch: 5| Step: 3
Training loss: 2.8753630367448584
Validation loss: 2.483767749138691

Epoch: 5| Step: 4
Training loss: 2.697174932569692
Validation loss: 2.4848162021376066

Epoch: 5| Step: 5
Training loss: 2.5403507661794014
Validation loss: 2.48600307036855

Epoch: 5| Step: 6
Training loss: 2.6155218944942162
Validation loss: 2.487198119319979

Epoch: 5| Step: 7
Training loss: 2.7949623942020514
Validation loss: 2.4947062074894104

Epoch: 5| Step: 8
Training loss: 2.628164382258484
Validation loss: 2.4926720868568055

Epoch: 5| Step: 9
Training loss: 2.294420033228309
Validation loss: 2.4847259793384344

Epoch: 5| Step: 10
Training loss: 2.561636709543988
Validation loss: 2.4868952246009184

Epoch: 5| Step: 11
Training loss: 2.4861551301020253
Validation loss: 2.4884245355653123

Epoch: 117| Step: 0
Training loss: 2.7344982882361983
Validation loss: 2.484756268529293

Epoch: 5| Step: 1
Training loss: 2.0457436732931247
Validation loss: 2.482445797528586

Epoch: 5| Step: 2
Training loss: 3.0166077272618295
Validation loss: 2.484355222675288

Epoch: 5| Step: 3
Training loss: 2.2815900575284758
Validation loss: 2.4824510157945916

Epoch: 5| Step: 4
Training loss: 2.997929653398504
Validation loss: 2.4813497825948843

Epoch: 5| Step: 5
Training loss: 2.3591583354573324
Validation loss: 2.4814936485421897

Epoch: 5| Step: 6
Training loss: 2.6550241671107053
Validation loss: 2.4804708926374337

Epoch: 5| Step: 7
Training loss: 2.161126744830219
Validation loss: 2.4777229269926857

Epoch: 5| Step: 8
Training loss: 2.5685719449224456
Validation loss: 2.4765956046121107

Epoch: 5| Step: 9
Training loss: 2.472801168091127
Validation loss: 2.4793121985721283

Epoch: 5| Step: 10
Training loss: 2.975842967135744
Validation loss: 2.4765299645501955

Epoch: 5| Step: 11
Training loss: 2.962952263026874
Validation loss: 2.4738114015548147

Epoch: 118| Step: 0
Training loss: 2.0976140818983766
Validation loss: 2.474669943742939

Epoch: 5| Step: 1
Training loss: 2.258814500268837
Validation loss: 2.4718560987699143

Epoch: 5| Step: 2
Training loss: 2.8857507799152957
Validation loss: 2.4726090429218064

Epoch: 5| Step: 3
Training loss: 2.6375392061185092
Validation loss: 2.466266545876479

Epoch: 5| Step: 4
Training loss: 2.526681049611297
Validation loss: 2.46994951538277

Epoch: 5| Step: 5
Training loss: 2.7621922282698406
Validation loss: 2.466570805821953

Epoch: 5| Step: 6
Training loss: 2.7920126819158617
Validation loss: 2.468822421850592

Epoch: 5| Step: 7
Training loss: 2.6910440896121206
Validation loss: 2.4710882758691897

Epoch: 5| Step: 8
Training loss: 2.245647671396894
Validation loss: 2.4716152794186885

Epoch: 5| Step: 9
Training loss: 2.6987738014857214
Validation loss: 2.4736574947081076

Epoch: 5| Step: 10
Training loss: 2.7262294970357526
Validation loss: 2.4707974140736377

Epoch: 5| Step: 11
Training loss: 2.2351590361539455
Validation loss: 2.4765391905256253

Epoch: 119| Step: 0
Training loss: 2.850364621579518
Validation loss: 2.4700154791281306

Epoch: 5| Step: 1
Training loss: 2.6702052023967173
Validation loss: 2.4700860339727035

Epoch: 5| Step: 2
Training loss: 2.2759012721660343
Validation loss: 2.4700654746205215

Epoch: 5| Step: 3
Training loss: 2.6672364063393865
Validation loss: 2.4680809772345955

Epoch: 5| Step: 4
Training loss: 2.3673496505545937
Validation loss: 2.472108218752929

Epoch: 5| Step: 5
Training loss: 2.828214022252217
Validation loss: 2.4709894147618154

Epoch: 5| Step: 6
Training loss: 2.3206201214563125
Validation loss: 2.467680043329018

Epoch: 5| Step: 7
Training loss: 2.7438076699698097
Validation loss: 2.476574814502092

Epoch: 5| Step: 8
Training loss: 2.5104628013919768
Validation loss: 2.4696785190706505

Epoch: 5| Step: 9
Training loss: 2.561154454219171
Validation loss: 2.4700869428916006

Epoch: 5| Step: 10
Training loss: 2.604711694267507
Validation loss: 2.4745279773952986

Epoch: 5| Step: 11
Training loss: 1.8419272254294077
Validation loss: 2.471934735058242

Epoch: 120| Step: 0
Training loss: 2.2702591429686856
Validation loss: 2.470058814511992

Epoch: 5| Step: 1
Training loss: 3.2793018188802816
Validation loss: 2.4740032165203703

Epoch: 5| Step: 2
Training loss: 2.568052463542241
Validation loss: 2.4772034346198457

Epoch: 5| Step: 3
Training loss: 2.351901717448584
Validation loss: 2.479442442186756

Epoch: 5| Step: 4
Training loss: 1.9427483139492205
Validation loss: 2.479772467019847

Epoch: 5| Step: 5
Training loss: 2.942948179119937
Validation loss: 2.4747933166594316

Epoch: 5| Step: 6
Training loss: 2.3302077635444784
Validation loss: 2.477261497778598

Epoch: 5| Step: 7
Training loss: 2.8802353005184385
Validation loss: 2.478167363863404

Epoch: 5| Step: 8
Training loss: 2.2959742434183426
Validation loss: 2.4734925055718353

Epoch: 5| Step: 9
Training loss: 2.5730516859038257
Validation loss: 2.4715554396922026

Epoch: 5| Step: 10
Training loss: 2.6839026394111496
Validation loss: 2.471999321683489

Epoch: 5| Step: 11
Training loss: 2.536891161408298
Validation loss: 2.4666126108905067

Epoch: 121| Step: 0
Training loss: 2.754351554201253
Validation loss: 2.465101914707372

Epoch: 5| Step: 1
Training loss: 2.7132711342783105
Validation loss: 2.4605987113793093

Epoch: 5| Step: 2
Training loss: 2.656332306428183
Validation loss: 2.4639706120585974

Epoch: 5| Step: 3
Training loss: 2.4903546233222174
Validation loss: 2.4607338795866216

Epoch: 5| Step: 4
Training loss: 2.85054629260073
Validation loss: 2.4580700472022086

Epoch: 5| Step: 5
Training loss: 2.5592526584770554
Validation loss: 2.4605662797557444

Epoch: 5| Step: 6
Training loss: 2.4912201250565587
Validation loss: 2.461335169234147

Epoch: 5| Step: 7
Training loss: 2.5226961824405545
Validation loss: 2.4626360203763427

Epoch: 5| Step: 8
Training loss: 2.5006040796969873
Validation loss: 2.460466261053519

Epoch: 5| Step: 9
Training loss: 2.201060091715751
Validation loss: 2.4618195502118505

Epoch: 5| Step: 10
Training loss: 2.5277274782348735
Validation loss: 2.4597012194825703

Epoch: 5| Step: 11
Training loss: 2.1057657517142143
Validation loss: 2.459554245139334

Epoch: 122| Step: 0
Training loss: 2.3701518920319202
Validation loss: 2.4688064029543924

Epoch: 5| Step: 1
Training loss: 2.6580885863170063
Validation loss: 2.4637736170304674

Epoch: 5| Step: 2
Training loss: 2.6642868529236607
Validation loss: 2.461521888657156

Epoch: 5| Step: 3
Training loss: 2.355207994998962
Validation loss: 2.462735083698034

Epoch: 5| Step: 4
Training loss: 2.592090489444524
Validation loss: 2.4600936835659337

Epoch: 5| Step: 5
Training loss: 2.4547365568565835
Validation loss: 2.469527858404759

Epoch: 5| Step: 6
Training loss: 2.401370166033635
Validation loss: 2.464275433635394

Epoch: 5| Step: 7
Training loss: 2.796124320277448
Validation loss: 2.4694696616828224

Epoch: 5| Step: 8
Training loss: 2.875501174366684
Validation loss: 2.4668604826711436

Epoch: 5| Step: 9
Training loss: 2.554357758219533
Validation loss: 2.4745374155759614

Epoch: 5| Step: 10
Training loss: 2.433308837279602
Validation loss: 2.471096452809425

Epoch: 5| Step: 11
Training loss: 2.591964934706448
Validation loss: 2.477110965458071

Epoch: 123| Step: 0
Training loss: 2.561069926852262
Validation loss: 2.4744318552431617

Epoch: 5| Step: 1
Training loss: 2.6180653480551266
Validation loss: 2.4781024248747294

Epoch: 5| Step: 2
Training loss: 2.4866970894241986
Validation loss: 2.4762275621738183

Epoch: 5| Step: 3
Training loss: 2.4421495938669406
Validation loss: 2.4762840956873298

Epoch: 5| Step: 4
Training loss: 2.646082908894237
Validation loss: 2.474778861785482

Epoch: 5| Step: 5
Training loss: 2.6294196932553024
Validation loss: 2.476406333163239

Epoch: 5| Step: 6
Training loss: 2.485130818874565
Validation loss: 2.4684590156101396

Epoch: 5| Step: 7
Training loss: 2.35104962709426
Validation loss: 2.4713595798595276

Epoch: 5| Step: 8
Training loss: 2.7405635883405957
Validation loss: 2.4711656622483793

Epoch: 5| Step: 9
Training loss: 2.4798595731724467
Validation loss: 2.4664875641014463

Epoch: 5| Step: 10
Training loss: 2.711122006340578
Validation loss: 2.4695771397019053

Epoch: 5| Step: 11
Training loss: 2.8195404094865424
Validation loss: 2.461942364637064

Epoch: 124| Step: 0
Training loss: 2.7327337080260734
Validation loss: 2.4682615376367703

Epoch: 5| Step: 1
Training loss: 2.5598438732401223
Validation loss: 2.4572572103889994

Epoch: 5| Step: 2
Training loss: 2.5231645277025043
Validation loss: 2.4658510272942658

Epoch: 5| Step: 3
Training loss: 2.5743189605518464
Validation loss: 2.4679008142053527

Epoch: 5| Step: 4
Training loss: 2.591558886757446
Validation loss: 2.468014712226198

Epoch: 5| Step: 5
Training loss: 2.4111598072418072
Validation loss: 2.4634261450319714

Epoch: 5| Step: 6
Training loss: 2.247629930688851
Validation loss: 2.4653179923584814

Epoch: 5| Step: 7
Training loss: 2.64880998630836
Validation loss: 2.4586225369164865

Epoch: 5| Step: 8
Training loss: 2.627988567280977
Validation loss: 2.465167758319424

Epoch: 5| Step: 9
Training loss: 2.4972859909728458
Validation loss: 2.46915761182088

Epoch: 5| Step: 10
Training loss: 2.717938005931952
Validation loss: 2.4641956458668437

Epoch: 5| Step: 11
Training loss: 2.6681326373185996
Validation loss: 2.4633145835904497

Epoch: 125| Step: 0
Training loss: 2.401645664420632
Validation loss: 2.4689124935127453

Epoch: 5| Step: 1
Training loss: 2.523598680574656
Validation loss: 2.4729297099027923

Epoch: 5| Step: 2
Training loss: 3.2441090232600636
Validation loss: 2.4723339784796305

Epoch: 5| Step: 3
Training loss: 2.432107486871778
Validation loss: 2.464644906174261

Epoch: 5| Step: 4
Training loss: 2.3042337261832557
Validation loss: 2.467934598542536

Epoch: 5| Step: 5
Training loss: 2.0864337230899928
Validation loss: 2.4726899894513674

Epoch: 5| Step: 6
Training loss: 2.2527383459329706
Validation loss: 2.47091264602797

Epoch: 5| Step: 7
Training loss: 2.3051961046650966
Validation loss: 2.4778620041182156

Epoch: 5| Step: 8
Training loss: 2.6008700345607476
Validation loss: 2.4765654121646548

Epoch: 5| Step: 9
Training loss: 2.680166307384991
Validation loss: 2.474161225414963

Epoch: 5| Step: 10
Training loss: 2.9698982026093597
Validation loss: 2.474296002014609

Epoch: 5| Step: 11
Training loss: 2.929042246650945
Validation loss: 2.471524582759827

Epoch: 126| Step: 0
Training loss: 2.3459212355013688
Validation loss: 2.4661525872583496

Epoch: 5| Step: 1
Training loss: 2.810381027534875
Validation loss: 2.4670094136474834

Epoch: 5| Step: 2
Training loss: 2.7570382130838413
Validation loss: 2.457958165868348

Epoch: 5| Step: 3
Training loss: 2.586230489031289
Validation loss: 2.458623591491336

Epoch: 5| Step: 4
Training loss: 2.1495838782801573
Validation loss: 2.449678749963921

Epoch: 5| Step: 5
Training loss: 2.8769276003407764
Validation loss: 2.4597011831338595

Epoch: 5| Step: 6
Training loss: 2.3286879710087396
Validation loss: 2.460836915074821

Epoch: 5| Step: 7
Training loss: 2.3174528745532554
Validation loss: 2.45579932157456

Epoch: 5| Step: 8
Training loss: 2.171790361470468
Validation loss: 2.454499647179202

Epoch: 5| Step: 9
Training loss: 3.001205520014292
Validation loss: 2.4557375471202025

Epoch: 5| Step: 10
Training loss: 2.6772837186594503
Validation loss: 2.4640585993459947

Epoch: 5| Step: 11
Training loss: 2.8618815124530927
Validation loss: 2.458104500114856

Epoch: 127| Step: 0
Training loss: 2.412723009149242
Validation loss: 2.466965271675564

Epoch: 5| Step: 1
Training loss: 2.5956502181402716
Validation loss: 2.4738595153079572

Epoch: 5| Step: 2
Training loss: 2.1434158732102797
Validation loss: 2.478890268695274

Epoch: 5| Step: 3
Training loss: 2.406852844817827
Validation loss: 2.4855200769719503

Epoch: 5| Step: 4
Training loss: 2.757143193364211
Validation loss: 2.4853045366056445

Epoch: 5| Step: 5
Training loss: 2.9096344960133096
Validation loss: 2.480188901639009

Epoch: 5| Step: 6
Training loss: 2.8877025780894394
Validation loss: 2.4898102642257753

Epoch: 5| Step: 7
Training loss: 2.4022368616655347
Validation loss: 2.488438360263667

Epoch: 5| Step: 8
Training loss: 2.6702454712001376
Validation loss: 2.485365552182099

Epoch: 5| Step: 9
Training loss: 2.3738746988769264
Validation loss: 2.49208017993118

Epoch: 5| Step: 10
Training loss: 3.0445579130215585
Validation loss: 2.4884998299387413

Epoch: 5| Step: 11
Training loss: 1.492411332044518
Validation loss: 2.4858260905206864

Epoch: 128| Step: 0
Training loss: 2.1468321194871
Validation loss: 2.48868584250488

Epoch: 5| Step: 1
Training loss: 2.3674568048260745
Validation loss: 2.4847914868457055

Epoch: 5| Step: 2
Training loss: 2.198542163908706
Validation loss: 2.4815655343533924

Epoch: 5| Step: 3
Training loss: 2.5498152535028593
Validation loss: 2.4852353371734868

Epoch: 5| Step: 4
Training loss: 3.0074337411178913
Validation loss: 2.480821991846388

Epoch: 5| Step: 5
Training loss: 2.8119777618440494
Validation loss: 2.4837423154753333

Epoch: 5| Step: 6
Training loss: 2.2437326244648426
Validation loss: 2.481169385905683

Epoch: 5| Step: 7
Training loss: 2.7270512620998906
Validation loss: 2.4785077290550737

Epoch: 5| Step: 8
Training loss: 2.7154088152665152
Validation loss: 2.4753227700947193

Epoch: 5| Step: 9
Training loss: 2.5781970389734066
Validation loss: 2.4666898114712317

Epoch: 5| Step: 10
Training loss: 2.8711890795185675
Validation loss: 2.462178457312681

Epoch: 5| Step: 11
Training loss: 2.989431521363694
Validation loss: 2.462676125406631

Epoch: 129| Step: 0
Training loss: 2.514620752274783
Validation loss: 2.4554694447287324

Epoch: 5| Step: 1
Training loss: 2.6069921703799035
Validation loss: 2.458698602522855

Epoch: 5| Step: 2
Training loss: 2.458444258778903
Validation loss: 2.4571858545936855

Epoch: 5| Step: 3
Training loss: 2.2763550380413657
Validation loss: 2.4593602853388954

Epoch: 5| Step: 4
Training loss: 2.8965564803693584
Validation loss: 2.4598164220028256

Epoch: 5| Step: 5
Training loss: 2.691736652263583
Validation loss: 2.4507939162538586

Epoch: 5| Step: 6
Training loss: 2.6756552562147955
Validation loss: 2.459964842551558

Epoch: 5| Step: 7
Training loss: 2.3616344420451707
Validation loss: 2.459233952815476

Epoch: 5| Step: 8
Training loss: 2.314107078725585
Validation loss: 2.459144556768499

Epoch: 5| Step: 9
Training loss: 2.6202380265882343
Validation loss: 2.4647569958492457

Epoch: 5| Step: 10
Training loss: 2.571965297814895
Validation loss: 2.4603905246539863

Epoch: 5| Step: 11
Training loss: 3.0452488398858595
Validation loss: 2.466669799721077

Epoch: 130| Step: 0
Training loss: 2.4379019772583588
Validation loss: 2.4697159877162047

Epoch: 5| Step: 1
Training loss: 3.0010709440495176
Validation loss: 2.470763395476486

Epoch: 5| Step: 2
Training loss: 2.3262937371325485
Validation loss: 2.469313975592061

Epoch: 5| Step: 3
Training loss: 2.7243571721872204
Validation loss: 2.4687894987012773

Epoch: 5| Step: 4
Training loss: 2.289413581458482
Validation loss: 2.467875378033771

Epoch: 5| Step: 5
Training loss: 2.1170395239887165
Validation loss: 2.4654460922654824

Epoch: 5| Step: 6
Training loss: 2.346600134711968
Validation loss: 2.459115159988268

Epoch: 5| Step: 7
Training loss: 2.623430055081753
Validation loss: 2.461568087567079

Epoch: 5| Step: 8
Training loss: 2.7094368862665212
Validation loss: 2.4604644159199833

Epoch: 5| Step: 9
Training loss: 2.9113750593711085
Validation loss: 2.458048267862622

Epoch: 5| Step: 10
Training loss: 2.453927850248673
Validation loss: 2.453771971573275

Epoch: 5| Step: 11
Training loss: 3.1121629647388
Validation loss: 2.461760307694874

Epoch: 131| Step: 0
Training loss: 2.6906844501373963
Validation loss: 2.46738049390701

Epoch: 5| Step: 1
Training loss: 2.524761691036819
Validation loss: 2.4599971811477412

Epoch: 5| Step: 2
Training loss: 2.5675518202264858
Validation loss: 2.465333776032023

Epoch: 5| Step: 3
Training loss: 2.6480821579291725
Validation loss: 2.465878861238951

Epoch: 5| Step: 4
Training loss: 2.227777624671954
Validation loss: 2.466131235795825

Epoch: 5| Step: 5
Training loss: 2.747388640239152
Validation loss: 2.4649310290506063

Epoch: 5| Step: 6
Training loss: 3.0465673046756976
Validation loss: 2.463383818093158

Epoch: 5| Step: 7
Training loss: 2.1117268202638404
Validation loss: 2.462468517734777

Epoch: 5| Step: 8
Training loss: 2.5915323911597037
Validation loss: 2.4628983290025186

Epoch: 5| Step: 9
Training loss: 2.617256732992865
Validation loss: 2.470351158674441

Epoch: 5| Step: 10
Training loss: 2.1994071595165186
Validation loss: 2.468273897578036

Epoch: 5| Step: 11
Training loss: 2.4892403806642482
Validation loss: 2.4621405531994998

Epoch: 132| Step: 0
Training loss: 2.3436083941596944
Validation loss: 2.46790545942819

Epoch: 5| Step: 1
Training loss: 2.390872418932993
Validation loss: 2.466308162761926

Epoch: 5| Step: 2
Training loss: 2.3264656041593277
Validation loss: 2.4598519408503123

Epoch: 5| Step: 3
Training loss: 2.3074420567074387
Validation loss: 2.462251471872878

Epoch: 5| Step: 4
Training loss: 2.9146309060465008
Validation loss: 2.4655418918658016

Epoch: 5| Step: 5
Training loss: 2.320652792281564
Validation loss: 2.4675401789477256

Epoch: 5| Step: 6
Training loss: 2.173155043764315
Validation loss: 2.465009704903461

Epoch: 5| Step: 7
Training loss: 2.67491405384642
Validation loss: 2.4620768740247496

Epoch: 5| Step: 8
Training loss: 2.7014844910725233
Validation loss: 2.4571239977516286

Epoch: 5| Step: 9
Training loss: 2.60809751750728
Validation loss: 2.45827492076098

Epoch: 5| Step: 10
Training loss: 3.1257149450720356
Validation loss: 2.4580510968840503

Epoch: 5| Step: 11
Training loss: 2.5277670928766516
Validation loss: 2.4617116124340113

Epoch: 133| Step: 0
Training loss: 2.6579986202101504
Validation loss: 2.4547627119216995

Epoch: 5| Step: 1
Training loss: 2.8427866886607167
Validation loss: 2.449328398290815

Epoch: 5| Step: 2
Training loss: 2.6745185490091745
Validation loss: 2.4528932806185053

Epoch: 5| Step: 3
Training loss: 2.5955980450419864
Validation loss: 2.4566623671617847

Epoch: 5| Step: 4
Training loss: 2.448915599697327
Validation loss: 2.458837852728265

Epoch: 5| Step: 5
Training loss: 2.7439691999113722
Validation loss: 2.4539907996910175

Epoch: 5| Step: 6
Training loss: 2.7000253358288013
Validation loss: 2.4536393106322993

Epoch: 5| Step: 7
Training loss: 1.85666677246687
Validation loss: 2.4559227181807795

Epoch: 5| Step: 8
Training loss: 2.4660103964482034
Validation loss: 2.450609780513789

Epoch: 5| Step: 9
Training loss: 2.803986783278113
Validation loss: 2.452507569025604

Epoch: 5| Step: 10
Training loss: 2.424264037151517
Validation loss: 2.451974129061426

Epoch: 5| Step: 11
Training loss: 1.4551070447262422
Validation loss: 2.4612554879593134

Epoch: 134| Step: 0
Training loss: 2.4516259734067645
Validation loss: 2.4621173553280977

Epoch: 5| Step: 1
Training loss: 2.923786700712733
Validation loss: 2.4649560119890177

Epoch: 5| Step: 2
Training loss: 2.420343517796725
Validation loss: 2.4632036664097234

Epoch: 5| Step: 3
Training loss: 2.6138254918963897
Validation loss: 2.4714544749562783

Epoch: 5| Step: 4
Training loss: 2.420833142051317
Validation loss: 2.4754389993272015

Epoch: 5| Step: 5
Training loss: 2.4494724172739404
Validation loss: 2.479886104207707

Epoch: 5| Step: 6
Training loss: 2.2931669237323518
Validation loss: 2.4696891583734737

Epoch: 5| Step: 7
Training loss: 2.003203449111626
Validation loss: 2.480029646487337

Epoch: 5| Step: 8
Training loss: 2.50281842624831
Validation loss: 2.477227660183602

Epoch: 5| Step: 9
Training loss: 3.136600781950427
Validation loss: 2.477721828425118

Epoch: 5| Step: 10
Training loss: 2.6042037249153602
Validation loss: 2.4745546940575784

Epoch: 5| Step: 11
Training loss: 3.2189159165368664
Validation loss: 2.4672399481879355

Epoch: 135| Step: 0
Training loss: 2.528404425985925
Validation loss: 2.473477067146947

Epoch: 5| Step: 1
Training loss: 2.838437158369753
Validation loss: 2.472955019770486

Epoch: 5| Step: 2
Training loss: 2.4673823177639416
Validation loss: 2.460428845350943

Epoch: 5| Step: 3
Training loss: 2.7970990991586113
Validation loss: 2.460913323985033

Epoch: 5| Step: 4
Training loss: 2.2042015096966794
Validation loss: 2.458577880711186

Epoch: 5| Step: 5
Training loss: 2.382138216263758
Validation loss: 2.4572430040802806

Epoch: 5| Step: 6
Training loss: 2.651978862309976
Validation loss: 2.4530777714064502

Epoch: 5| Step: 7
Training loss: 2.694368501185059
Validation loss: 2.4561400543403327

Epoch: 5| Step: 8
Training loss: 2.2158157933652682
Validation loss: 2.455006305268239

Epoch: 5| Step: 9
Training loss: 2.7878435821220147
Validation loss: 2.4527744642103064

Epoch: 5| Step: 10
Training loss: 2.5967120067798786
Validation loss: 2.4512053589984513

Epoch: 5| Step: 11
Training loss: 0.8326773127610057
Validation loss: 2.455271326604857

Epoch: 136| Step: 0
Training loss: 2.5158872289992944
Validation loss: 2.452228090609752

Epoch: 5| Step: 1
Training loss: 2.977208024962543
Validation loss: 2.4534027201577455

Epoch: 5| Step: 2
Training loss: 2.823699101381523
Validation loss: 2.4555605604287125

Epoch: 5| Step: 3
Training loss: 2.4260614451389313
Validation loss: 2.452488531169459

Epoch: 5| Step: 4
Training loss: 2.561045163901443
Validation loss: 2.4517201047394446

Epoch: 5| Step: 5
Training loss: 2.442786035881151
Validation loss: 2.45187750357329

Epoch: 5| Step: 6
Training loss: 2.2038503764851174
Validation loss: 2.463022085861583

Epoch: 5| Step: 7
Training loss: 2.754586729563928
Validation loss: 2.472385277145305

Epoch: 5| Step: 8
Training loss: 2.1282715017387996
Validation loss: 2.47691165055342

Epoch: 5| Step: 9
Training loss: 3.2798771483977176
Validation loss: 2.483129509032725

Epoch: 5| Step: 10
Training loss: 2.131335742825381
Validation loss: 2.478246695796278

Epoch: 5| Step: 11
Training loss: 2.411762611081761
Validation loss: 2.484589137639323

Epoch: 137| Step: 0
Training loss: 2.609390624222263
Validation loss: 2.4788800135283138

Epoch: 5| Step: 1
Training loss: 2.8143150406900777
Validation loss: 2.480445989869794

Epoch: 5| Step: 2
Training loss: 2.418853647145398
Validation loss: 2.482518896272368

Epoch: 5| Step: 3
Training loss: 2.9785415598256133
Validation loss: 2.4744292376558246

Epoch: 5| Step: 4
Training loss: 2.5082972168038475
Validation loss: 2.476124043766705

Epoch: 5| Step: 5
Training loss: 2.3586744064080434
Validation loss: 2.4723464787851945

Epoch: 5| Step: 6
Training loss: 2.170841108175207
Validation loss: 2.4726130525452596

Epoch: 5| Step: 7
Training loss: 2.5183549367641596
Validation loss: 2.4665585420619376

Epoch: 5| Step: 8
Training loss: 2.3986774535785655
Validation loss: 2.464561921868033

Epoch: 5| Step: 9
Training loss: 2.324208594548454
Validation loss: 2.4591180806954998

Epoch: 5| Step: 10
Training loss: 3.033085847197492
Validation loss: 2.4675416886654564

Epoch: 5| Step: 11
Training loss: 2.6866228313356535
Validation loss: 2.4586154013521724

Epoch: 138| Step: 0
Training loss: 2.2594664960092095
Validation loss: 2.4591908265968074

Epoch: 5| Step: 1
Training loss: 2.458673216605547
Validation loss: 2.458114138761156

Epoch: 5| Step: 2
Training loss: 2.211168149098491
Validation loss: 2.4527529659134717

Epoch: 5| Step: 3
Training loss: 2.547760323952087
Validation loss: 2.4523142995663036

Epoch: 5| Step: 4
Training loss: 2.74766510763251
Validation loss: 2.455406826515705

Epoch: 5| Step: 5
Training loss: 2.4889148043331577
Validation loss: 2.4574170843193004

Epoch: 5| Step: 6
Training loss: 2.7437689152719473
Validation loss: 2.4583628189344524

Epoch: 5| Step: 7
Training loss: 2.703737575380769
Validation loss: 2.4591348009706775

Epoch: 5| Step: 8
Training loss: 2.694910787970698
Validation loss: 2.453385215775196

Epoch: 5| Step: 9
Training loss: 2.903353652737008
Validation loss: 2.455688910425729

Epoch: 5| Step: 10
Training loss: 2.27835777569124
Validation loss: 2.4558810001386138

Epoch: 5| Step: 11
Training loss: 2.839312434177851
Validation loss: 2.4551182280557566

Epoch: 139| Step: 0
Training loss: 3.1334850321902685
Validation loss: 2.465989686291833

Epoch: 5| Step: 1
Training loss: 2.7291010977364434
Validation loss: 2.4638312668915443

Epoch: 5| Step: 2
Training loss: 2.464069033113961
Validation loss: 2.4640469499999225

Epoch: 5| Step: 3
Training loss: 2.6714323692207356
Validation loss: 2.4669751897955217

Epoch: 5| Step: 4
Training loss: 2.5654782921202215
Validation loss: 2.468332585324576

Epoch: 5| Step: 5
Training loss: 2.732201109905393
Validation loss: 2.4684083356115183

Epoch: 5| Step: 6
Training loss: 1.9947067787162704
Validation loss: 2.4747321929601847

Epoch: 5| Step: 7
Training loss: 2.4733668747998503
Validation loss: 2.4694400700124075

Epoch: 5| Step: 8
Training loss: 1.7927368280014377
Validation loss: 2.469109963679956

Epoch: 5| Step: 9
Training loss: 2.559183533229004
Validation loss: 2.4692447826462596

Epoch: 5| Step: 10
Training loss: 2.5033601114675386
Validation loss: 2.468374650323063

Epoch: 5| Step: 11
Training loss: 3.325690010007483
Validation loss: 2.462463640373816

Epoch: 140| Step: 0
Training loss: 2.669670221486485
Validation loss: 2.4660408248753836

Epoch: 5| Step: 1
Training loss: 2.5820303266237947
Validation loss: 2.4648252346433606

Epoch: 5| Step: 2
Training loss: 2.3584226997975595
Validation loss: 2.4648985718093113

Epoch: 5| Step: 3
Training loss: 2.045963929068118
Validation loss: 2.4660871445716146

Epoch: 5| Step: 4
Training loss: 2.4497840630484977
Validation loss: 2.459347533218454

Epoch: 5| Step: 5
Training loss: 2.437439355340336
Validation loss: 2.4644211428478684

Epoch: 5| Step: 6
Training loss: 2.4982303077809562
Validation loss: 2.460233682572972

Epoch: 5| Step: 7
Training loss: 3.0162920436466223
Validation loss: 2.460920846468975

Epoch: 5| Step: 8
Training loss: 2.6171700092699126
Validation loss: 2.4690825222304205

Epoch: 5| Step: 9
Training loss: 2.7263004209813553
Validation loss: 2.4732461379362403

Epoch: 5| Step: 10
Training loss: 2.3073838834797704
Validation loss: 2.4702587225584054

Epoch: 5| Step: 11
Training loss: 3.646545311572391
Validation loss: 2.471134181359724

Epoch: 141| Step: 0
Training loss: 2.5133743169294807
Validation loss: 2.469767549918039

Epoch: 5| Step: 1
Training loss: 2.3796405629809674
Validation loss: 2.465531980067685

Epoch: 5| Step: 2
Training loss: 2.6457417589895713
Validation loss: 2.46103223991693

Epoch: 5| Step: 3
Training loss: 2.6688398109350597
Validation loss: 2.4605677776031207

Epoch: 5| Step: 4
Training loss: 2.771446007321193
Validation loss: 2.464219309950054

Epoch: 5| Step: 5
Training loss: 2.303377561554023
Validation loss: 2.4625190577600597

Epoch: 5| Step: 6
Training loss: 3.032464010429199
Validation loss: 2.463888818638583

Epoch: 5| Step: 7
Training loss: 2.6817620702084097
Validation loss: 2.463665397929479

Epoch: 5| Step: 8
Training loss: 2.2178598686922855
Validation loss: 2.463920089712163

Epoch: 5| Step: 9
Training loss: 2.568655482871352
Validation loss: 2.469492309771768

Epoch: 5| Step: 10
Training loss: 2.1718490928367156
Validation loss: 2.464492526978668

Epoch: 5| Step: 11
Training loss: 2.4024941001922855
Validation loss: 2.4583424646132546

Epoch: 142| Step: 0
Training loss: 2.7687821121592497
Validation loss: 2.466755876479819

Epoch: 5| Step: 1
Training loss: 2.481136778739381
Validation loss: 2.4660604691090087

Epoch: 5| Step: 2
Training loss: 2.6221576015498615
Validation loss: 2.4741900740385954

Epoch: 5| Step: 3
Training loss: 2.901669902796057
Validation loss: 2.4618988722610378

Epoch: 5| Step: 4
Training loss: 2.252716120471817
Validation loss: 2.4732951162021335

Epoch: 5| Step: 5
Training loss: 2.4234890389388375
Validation loss: 2.467347313969722

Epoch: 5| Step: 6
Training loss: 2.387322132615175
Validation loss: 2.480226143414283

Epoch: 5| Step: 7
Training loss: 2.7221429633801075
Validation loss: 2.4720357464858216

Epoch: 5| Step: 8
Training loss: 2.545165254515024
Validation loss: 2.4756173657912175

Epoch: 5| Step: 9
Training loss: 2.711210297592386
Validation loss: 2.472576491609788

Epoch: 5| Step: 10
Training loss: 2.2891214512860154
Validation loss: 2.468785631751603

Epoch: 5| Step: 11
Training loss: 2.834492801459958
Validation loss: 2.471713074541922

Epoch: 143| Step: 0
Training loss: 2.241678532376373
Validation loss: 2.4708079239201877

Epoch: 5| Step: 1
Training loss: 2.463317108135275
Validation loss: 2.4726034864889783

Epoch: 5| Step: 2
Training loss: 2.014396233797378
Validation loss: 2.469442222218991

Epoch: 5| Step: 3
Training loss: 2.970068548419718
Validation loss: 2.467402537120669

Epoch: 5| Step: 4
Training loss: 2.567812924579438
Validation loss: 2.4702057107793154

Epoch: 5| Step: 5
Training loss: 2.921569155429331
Validation loss: 2.4656274459497967

Epoch: 5| Step: 6
Training loss: 2.575353068617884
Validation loss: 2.464698823516128

Epoch: 5| Step: 7
Training loss: 2.6983801150335993
Validation loss: 2.464377873601487

Epoch: 5| Step: 8
Training loss: 2.4636677446961275
Validation loss: 2.458574619952151

Epoch: 5| Step: 9
Training loss: 2.4411252768006215
Validation loss: 2.4621491693807895

Epoch: 5| Step: 10
Training loss: 2.6515067441402427
Validation loss: 2.465234676097726

Epoch: 5| Step: 11
Training loss: 2.2189309489649323
Validation loss: 2.456624084763122

Epoch: 144| Step: 0
Training loss: 2.273308085005864
Validation loss: 2.4617156963032842

Epoch: 5| Step: 1
Training loss: 2.585321358751197
Validation loss: 2.456988165982555

Epoch: 5| Step: 2
Training loss: 2.905123420496601
Validation loss: 2.4577592863775917

Epoch: 5| Step: 3
Training loss: 3.0481969850920585
Validation loss: 2.465053245157658

Epoch: 5| Step: 4
Training loss: 2.2085476417437886
Validation loss: 2.470738726574265

Epoch: 5| Step: 5
Training loss: 2.0048214493775443
Validation loss: 2.4684831418698114

Epoch: 5| Step: 6
Training loss: 2.575349735842077
Validation loss: 2.4674473315450465

Epoch: 5| Step: 7
Training loss: 2.9326911685744164
Validation loss: 2.4664560557248385

Epoch: 5| Step: 8
Training loss: 2.4520938917357835
Validation loss: 2.471484625333843

Epoch: 5| Step: 9
Training loss: 2.333570525057312
Validation loss: 2.468581769337779

Epoch: 5| Step: 10
Training loss: 2.6571967737672426
Validation loss: 2.472949130694961

Epoch: 5| Step: 11
Training loss: 1.267509000095414
Validation loss: 2.4709381112391866

Epoch: 145| Step: 0
Training loss: 2.1515224433666273
Validation loss: 2.4707047192313336

Epoch: 5| Step: 1
Training loss: 2.836606621949111
Validation loss: 2.47523393103436

Epoch: 5| Step: 2
Training loss: 2.442358993786296
Validation loss: 2.467403849641882

Epoch: 5| Step: 3
Training loss: 2.37190426292009
Validation loss: 2.464530332440947

Epoch: 5| Step: 4
Training loss: 2.906449834044514
Validation loss: 2.462695705718241

Epoch: 5| Step: 5
Training loss: 2.3291830436481096
Validation loss: 2.4573705870495606

Epoch: 5| Step: 6
Training loss: 2.798875402356064
Validation loss: 2.4584597471568976

Epoch: 5| Step: 7
Training loss: 2.0153407406525177
Validation loss: 2.453492467129508

Epoch: 5| Step: 8
Training loss: 2.572803716200901
Validation loss: 2.461520361122155

Epoch: 5| Step: 9
Training loss: 2.8951179846668773
Validation loss: 2.4560863657147762

Epoch: 5| Step: 10
Training loss: 2.375960005433217
Validation loss: 2.458539975635559

Epoch: 5| Step: 11
Training loss: 3.1879792694604783
Validation loss: 2.4661192014733904

Epoch: 146| Step: 0
Training loss: 2.6172229365896196
Validation loss: 2.466732955591763

Epoch: 5| Step: 1
Training loss: 2.8583470565718554
Validation loss: 2.471108020681364

Epoch: 5| Step: 2
Training loss: 2.868020251172019
Validation loss: 2.4702196213539733

Epoch: 5| Step: 3
Training loss: 2.359647924540716
Validation loss: 2.4745607158048846

Epoch: 5| Step: 4
Training loss: 1.9579633674428873
Validation loss: 2.4732812871902254

Epoch: 5| Step: 5
Training loss: 2.6633383921868408
Validation loss: 2.469288763176825

Epoch: 5| Step: 6
Training loss: 2.8141954186209266
Validation loss: 2.468359091347651

Epoch: 5| Step: 7
Training loss: 2.7007199210656805
Validation loss: 2.477279667550292

Epoch: 5| Step: 8
Training loss: 2.3764058018175493
Validation loss: 2.468725260679009

Epoch: 5| Step: 9
Training loss: 2.4825061030471325
Validation loss: 2.466185017925341

Epoch: 5| Step: 10
Training loss: 2.2556347755818558
Validation loss: 2.4607330196946697

Epoch: 5| Step: 11
Training loss: 2.453763744997849
Validation loss: 2.456846196858051

Epoch: 147| Step: 0
Training loss: 2.360504284338284
Validation loss: 2.4553494461566463

Epoch: 5| Step: 1
Training loss: 2.3771192230894207
Validation loss: 2.452303309419591

Epoch: 5| Step: 2
Training loss: 2.3539716476638732
Validation loss: 2.453373380101789

Epoch: 5| Step: 3
Training loss: 2.350496677911614
Validation loss: 2.443879350424319

Epoch: 5| Step: 4
Training loss: 3.100111614802112
Validation loss: 2.452550735804325

Epoch: 5| Step: 5
Training loss: 3.095749796326027
Validation loss: 2.446366445569989

Epoch: 5| Step: 6
Training loss: 2.2463371344018737
Validation loss: 2.4500552345556685

Epoch: 5| Step: 7
Training loss: 2.6046665678230125
Validation loss: 2.4493724079188124

Epoch: 5| Step: 8
Training loss: 2.5366161592378615
Validation loss: 2.4503036075731184

Epoch: 5| Step: 9
Training loss: 2.4245330990297935
Validation loss: 2.452066958709553

Epoch: 5| Step: 10
Training loss: 2.507755171931633
Validation loss: 2.4498828370923498

Epoch: 5| Step: 11
Training loss: 1.897517731072331
Validation loss: 2.4539828977017395

Epoch: 148| Step: 0
Training loss: 2.596302844388118
Validation loss: 2.4564804163205944

Epoch: 5| Step: 1
Training loss: 2.267197687926692
Validation loss: 2.464055982833884

Epoch: 5| Step: 2
Training loss: 2.3125381466580253
Validation loss: 2.4623334003705994

Epoch: 5| Step: 3
Training loss: 2.8863706882202247
Validation loss: 2.4717931863304385

Epoch: 5| Step: 4
Training loss: 2.315709026835313
Validation loss: 2.479264122519378

Epoch: 5| Step: 5
Training loss: 2.9088762783939317
Validation loss: 2.473712002721167

Epoch: 5| Step: 6
Training loss: 2.6829655563071557
Validation loss: 2.467823450235611

Epoch: 5| Step: 7
Training loss: 2.661812019113607
Validation loss: 2.47553714500964

Epoch: 5| Step: 8
Training loss: 2.55738832455535
Validation loss: 2.4710023198764604

Epoch: 5| Step: 9
Training loss: 2.6058903800527684
Validation loss: 2.468658353013855

Epoch: 5| Step: 10
Training loss: 2.0432317794198367
Validation loss: 2.4706445217093114

Epoch: 5| Step: 11
Training loss: 3.0721824329168745
Validation loss: 2.4633883427873022

Epoch: 149| Step: 0
Training loss: 2.501779304559198
Validation loss: 2.4668114088631565

Epoch: 5| Step: 1
Training loss: 2.456281538510894
Validation loss: 2.4671885626711902

Epoch: 5| Step: 2
Training loss: 2.69956868576674
Validation loss: 2.463790910517613

Epoch: 5| Step: 3
Training loss: 2.988089282283735
Validation loss: 2.4629065048992524

Epoch: 5| Step: 4
Training loss: 2.182654764078101
Validation loss: 2.458016724053143

Epoch: 5| Step: 5
Training loss: 3.223556041525639
Validation loss: 2.456801997629952

Epoch: 5| Step: 6
Training loss: 2.459804698045529
Validation loss: 2.4546116315164195

Epoch: 5| Step: 7
Training loss: 2.5705658112437626
Validation loss: 2.4473441908743685

Epoch: 5| Step: 8
Training loss: 2.6757225308623287
Validation loss: 2.4483536282934506

Epoch: 5| Step: 9
Training loss: 2.227584550753487
Validation loss: 2.4462198457043547

Epoch: 5| Step: 10
Training loss: 1.92816342851871
Validation loss: 2.4505182212845398

Epoch: 5| Step: 11
Training loss: 2.553261828637277
Validation loss: 2.449883792028568

Epoch: 150| Step: 0
Training loss: 2.5774746161172017
Validation loss: 2.456725533635023

Epoch: 5| Step: 1
Training loss: 2.3424941703862268
Validation loss: 2.4584089216368032

Epoch: 5| Step: 2
Training loss: 2.5366108957476667
Validation loss: 2.464123825796954

Epoch: 5| Step: 3
Training loss: 2.830034149017805
Validation loss: 2.475308819972634

Epoch: 5| Step: 4
Training loss: 2.6250709342455028
Validation loss: 2.4750041129980365

Epoch: 5| Step: 5
Training loss: 2.4945899600447574
Validation loss: 2.471114748313693

Epoch: 5| Step: 6
Training loss: 2.137777843598708
Validation loss: 2.483051575340786

Epoch: 5| Step: 7
Training loss: 2.738353690197303
Validation loss: 2.4756710923175316

Epoch: 5| Step: 8
Training loss: 2.833771353878003
Validation loss: 2.4870719586116152

Epoch: 5| Step: 9
Training loss: 2.4409855106209712
Validation loss: 2.482900109734929

Epoch: 5| Step: 10
Training loss: 2.4291601068616426
Validation loss: 2.4828074926346253

Epoch: 5| Step: 11
Training loss: 2.781169418710642
Validation loss: 2.4819526899274686

Epoch: 151| Step: 0
Training loss: 2.2941889205206163
Validation loss: 2.46187825866029

Epoch: 5| Step: 1
Training loss: 2.372432525607844
Validation loss: 2.457276094060381

Epoch: 5| Step: 2
Training loss: 2.433614029654417
Validation loss: 2.452086777686004

Epoch: 5| Step: 3
Training loss: 2.8278000787214936
Validation loss: 2.4542798079903543

Epoch: 5| Step: 4
Training loss: 2.200267805792243
Validation loss: 2.4584439355140386

Epoch: 5| Step: 5
Training loss: 2.6196161189838185
Validation loss: 2.451288917047122

Epoch: 5| Step: 6
Training loss: 2.442920136097641
Validation loss: 2.4521229635151336

Epoch: 5| Step: 7
Training loss: 2.899762038629423
Validation loss: 2.4571760384615224

Epoch: 5| Step: 8
Training loss: 2.8548052182535115
Validation loss: 2.448120402251539

Epoch: 5| Step: 9
Training loss: 2.407318868666345
Validation loss: 2.4562729907233845

Epoch: 5| Step: 10
Training loss: 2.656249102424021
Validation loss: 2.4585395028790873

Epoch: 5| Step: 11
Training loss: 1.6090970586376108
Validation loss: 2.457019555206041

Epoch: 152| Step: 0
Training loss: 2.637569849617046
Validation loss: 2.4627087995109593

Epoch: 5| Step: 1
Training loss: 2.003631751461602
Validation loss: 2.4589005774898998

Epoch: 5| Step: 2
Training loss: 2.403250174368921
Validation loss: 2.4548403256291893

Epoch: 5| Step: 3
Training loss: 2.8237464689289253
Validation loss: 2.4593616405255085

Epoch: 5| Step: 4
Training loss: 2.777414227113224
Validation loss: 2.4617613003950716

Epoch: 5| Step: 5
Training loss: 2.777955751015853
Validation loss: 2.4648377367561936

Epoch: 5| Step: 6
Training loss: 2.357224754050232
Validation loss: 2.455163728106228

Epoch: 5| Step: 7
Training loss: 2.576350023011345
Validation loss: 2.4585318700718433

Epoch: 5| Step: 8
Training loss: 2.061030124205389
Validation loss: 2.460703343145559

Epoch: 5| Step: 9
Training loss: 2.2229575437334503
Validation loss: 2.455285870025428

Epoch: 5| Step: 10
Training loss: 3.0053391629218646
Validation loss: 2.4599950469265672

Epoch: 5| Step: 11
Training loss: 2.6996132856276387
Validation loss: 2.456736144116875

Epoch: 153| Step: 0
Training loss: 2.419291046901282
Validation loss: 2.4613926380854414

Epoch: 5| Step: 1
Training loss: 2.2818252674242845
Validation loss: 2.4670614431404716

Epoch: 5| Step: 2
Training loss: 2.101980288361409
Validation loss: 2.4678333045250307

Epoch: 5| Step: 3
Training loss: 2.6471502275829715
Validation loss: 2.467925463171353

Epoch: 5| Step: 4
Training loss: 2.550515504228663
Validation loss: 2.4631123030847575

Epoch: 5| Step: 5
Training loss: 2.689447451428293
Validation loss: 2.465123708295441

Epoch: 5| Step: 6
Training loss: 2.3669071849873986
Validation loss: 2.466648422530296

Epoch: 5| Step: 7
Training loss: 2.685591352614639
Validation loss: 2.473834046035942

Epoch: 5| Step: 8
Training loss: 2.9533082612511214
Validation loss: 2.463287866004603

Epoch: 5| Step: 9
Training loss: 2.557442209405613
Validation loss: 2.462586600173481

Epoch: 5| Step: 10
Training loss: 2.675504840023059
Validation loss: 2.4657940289698623

Epoch: 5| Step: 11
Training loss: 1.9010879162601455
Validation loss: 2.470708259506821

Epoch: 154| Step: 0
Training loss: 2.6089404995012333
Validation loss: 2.4632229158572194

Epoch: 5| Step: 1
Training loss: 2.1778941006096826
Validation loss: 2.46363735752412

Epoch: 5| Step: 2
Training loss: 2.7645091591385067
Validation loss: 2.4698900576176146

Epoch: 5| Step: 3
Training loss: 2.7103157319830675
Validation loss: 2.4679608955028876

Epoch: 5| Step: 4
Training loss: 2.41448022876259
Validation loss: 2.4743414264343437

Epoch: 5| Step: 5
Training loss: 2.4998954751098315
Validation loss: 2.4706483656452813

Epoch: 5| Step: 6
Training loss: 2.8582991780575
Validation loss: 2.472924678428503

Epoch: 5| Step: 7
Training loss: 2.572571663113202
Validation loss: 2.4702032897924324

Epoch: 5| Step: 8
Training loss: 2.397269296853093
Validation loss: 2.4642978230896935

Epoch: 5| Step: 9
Training loss: 2.7592292582990483
Validation loss: 2.4590411595016315

Epoch: 5| Step: 10
Training loss: 2.2888341796328255
Validation loss: 2.451568352599297

Epoch: 5| Step: 11
Training loss: 1.4807302601323054
Validation loss: 2.455241393874329

Epoch: 155| Step: 0
Training loss: 2.0979690176509846
Validation loss: 2.467315093854788

Epoch: 5| Step: 1
Training loss: 2.7015039070266353
Validation loss: 2.477637806609824

Epoch: 5| Step: 2
Training loss: 2.637584222108754
Validation loss: 2.4829363626193

Epoch: 5| Step: 3
Training loss: 2.5920166290420887
Validation loss: 2.4696009131210754

Epoch: 5| Step: 4
Training loss: 2.257392712279455
Validation loss: 2.469612992826583

Epoch: 5| Step: 5
Training loss: 2.691575442284914
Validation loss: 2.4521425754280064

Epoch: 5| Step: 6
Training loss: 2.279416013348147
Validation loss: 2.4557906001886014

Epoch: 5| Step: 7
Training loss: 2.7064691045221467
Validation loss: 2.4624849772438826

Epoch: 5| Step: 8
Training loss: 2.641837298862227
Validation loss: 2.459265646630053

Epoch: 5| Step: 9
Training loss: 2.8223492567085424
Validation loss: 2.4662820737454254

Epoch: 5| Step: 10
Training loss: 2.8809889735150214
Validation loss: 2.4677030761896774

Epoch: 5| Step: 11
Training loss: 1.956392286689698
Validation loss: 2.459783778134481

Epoch: 156| Step: 0
Training loss: 2.222111372037313
Validation loss: 2.467755085019322

Epoch: 5| Step: 1
Training loss: 2.76041158039896
Validation loss: 2.4676804096665075

Epoch: 5| Step: 2
Training loss: 2.689764975735766
Validation loss: 2.462948759372514

Epoch: 5| Step: 3
Training loss: 2.565645845539935
Validation loss: 2.469706712117334

Epoch: 5| Step: 4
Training loss: 1.988636037653116
Validation loss: 2.460707533652633

Epoch: 5| Step: 5
Training loss: 2.6199119848653623
Validation loss: 2.4633793498487173

Epoch: 5| Step: 6
Training loss: 2.642609161172143
Validation loss: 2.4592826264453973

Epoch: 5| Step: 7
Training loss: 2.710568801476742
Validation loss: 2.457414541585767

Epoch: 5| Step: 8
Training loss: 2.914757530636527
Validation loss: 2.4541047239555196

Epoch: 5| Step: 9
Training loss: 2.3954759635316547
Validation loss: 2.45154311571791

Epoch: 5| Step: 10
Training loss: 2.3181038051200935
Validation loss: 2.452602144473939

Epoch: 5| Step: 11
Training loss: 2.0345959615175526
Validation loss: 2.4511950731129595

Epoch: 157| Step: 0
Training loss: 2.5610514012086067
Validation loss: 2.4521048382572608

Epoch: 5| Step: 1
Training loss: 2.651229152282733
Validation loss: 2.4629171290876117

Epoch: 5| Step: 2
Training loss: 2.5088918864560115
Validation loss: 2.4683089888486407

Epoch: 5| Step: 3
Training loss: 1.8677982624258687
Validation loss: 2.4612990381196833

Epoch: 5| Step: 4
Training loss: 3.081367450201157
Validation loss: 2.472109902493785

Epoch: 5| Step: 5
Training loss: 1.9151739513584116
Validation loss: 2.4749367188060583

Epoch: 5| Step: 6
Training loss: 2.4183161028461337
Validation loss: 2.474153259361364

Epoch: 5| Step: 7
Training loss: 3.0104203449653584
Validation loss: 2.467829774214268

Epoch: 5| Step: 8
Training loss: 2.899201737078721
Validation loss: 2.4708362447990604

Epoch: 5| Step: 9
Training loss: 2.86016684652375
Validation loss: 2.4666299609941453

Epoch: 5| Step: 10
Training loss: 1.8357440603088184
Validation loss: 2.46358952801742

Epoch: 5| Step: 11
Training loss: 1.672297272876153
Validation loss: 2.4620546096294302

Epoch: 158| Step: 0
Training loss: 2.2470182158305194
Validation loss: 2.4538440743833774

Epoch: 5| Step: 1
Training loss: 2.3959050927956396
Validation loss: 2.452630756585344

Epoch: 5| Step: 2
Training loss: 2.806903187065132
Validation loss: 2.452261110525428

Epoch: 5| Step: 3
Training loss: 2.739590276170256
Validation loss: 2.4496212496231693

Epoch: 5| Step: 4
Training loss: 2.27900208803611
Validation loss: 2.4507760912559498

Epoch: 5| Step: 5
Training loss: 2.4411411965496175
Validation loss: 2.4444788526391594

Epoch: 5| Step: 6
Training loss: 2.557095200915803
Validation loss: 2.4531977292434166

Epoch: 5| Step: 7
Training loss: 2.94372645407167
Validation loss: 2.4504484124719976

Epoch: 5| Step: 8
Training loss: 2.2846135465006436
Validation loss: 2.4516291340025935

Epoch: 5| Step: 9
Training loss: 2.5579932986090403
Validation loss: 2.457007888658627

Epoch: 5| Step: 10
Training loss: 2.5066477129436078
Validation loss: 2.4579130772574507

Epoch: 5| Step: 11
Training loss: 2.2417321357478963
Validation loss: 2.45936502747895

Epoch: 159| Step: 0
Training loss: 2.656328536723842
Validation loss: 2.457578803235141

Epoch: 5| Step: 1
Training loss: 2.8652859652606626
Validation loss: 2.458253803960306

Epoch: 5| Step: 2
Training loss: 1.81639660248194
Validation loss: 2.462843206535534

Epoch: 5| Step: 3
Training loss: 2.6815747435632225
Validation loss: 2.468007314005761

Epoch: 5| Step: 4
Training loss: 2.7895121919782957
Validation loss: 2.462413216205744

Epoch: 5| Step: 5
Training loss: 2.12518175133241
Validation loss: 2.471725863343541

Epoch: 5| Step: 6
Training loss: 2.313296515953248
Validation loss: 2.471368210125902

Epoch: 5| Step: 7
Training loss: 2.5342886311481565
Validation loss: 2.4711416264994677

Epoch: 5| Step: 8
Training loss: 2.4954471138585936
Validation loss: 2.4743161769194897

Epoch: 5| Step: 9
Training loss: 2.2919048069996593
Validation loss: 2.472595921202805

Epoch: 5| Step: 10
Training loss: 3.029469547232628
Validation loss: 2.467164427778431

Epoch: 5| Step: 11
Training loss: 3.0500836032603176
Validation loss: 2.469801972387965

Epoch: 160| Step: 0
Training loss: 2.323982701215854
Validation loss: 2.4565885111576073

Epoch: 5| Step: 1
Training loss: 2.3282140932381274
Validation loss: 2.4570638617052976

Epoch: 5| Step: 2
Training loss: 2.920790363889966
Validation loss: 2.459282983935194

Epoch: 5| Step: 3
Training loss: 2.191748063735916
Validation loss: 2.46674895976234

Epoch: 5| Step: 4
Training loss: 2.883147098796442
Validation loss: 2.4648083111471824

Epoch: 5| Step: 5
Training loss: 2.4038007086346145
Validation loss: 2.4640357521426033

Epoch: 5| Step: 6
Training loss: 2.573445645419619
Validation loss: 2.453000099906292

Epoch: 5| Step: 7
Training loss: 2.4974336803592943
Validation loss: 2.454506523539912

Epoch: 5| Step: 8
Training loss: 2.6394943435067817
Validation loss: 2.457078946393061

Epoch: 5| Step: 9
Training loss: 2.391353620805587
Validation loss: 2.451384909239058

Epoch: 5| Step: 10
Training loss: 2.872478208401111
Validation loss: 2.4534986539416823

Epoch: 5| Step: 11
Training loss: 2.4771897156514076
Validation loss: 2.453110107652042

Epoch: 161| Step: 0
Training loss: 2.96161911499227
Validation loss: 2.446299364952784

Epoch: 5| Step: 1
Training loss: 3.00670399241599
Validation loss: 2.461747773811607

Epoch: 5| Step: 2
Training loss: 2.435003126639801
Validation loss: 2.4693723047168223

Epoch: 5| Step: 3
Training loss: 2.6198228918885493
Validation loss: 2.4694135353636573

Epoch: 5| Step: 4
Training loss: 2.1701844586144334
Validation loss: 2.470172082174345

Epoch: 5| Step: 5
Training loss: 2.519034497874762
Validation loss: 2.471258880471929

Epoch: 5| Step: 6
Training loss: 2.4409315944839984
Validation loss: 2.4756943979273704

Epoch: 5| Step: 7
Training loss: 2.442730597833107
Validation loss: 2.4788816505908327

Epoch: 5| Step: 8
Training loss: 2.1881224700294215
Validation loss: 2.472136203261163

Epoch: 5| Step: 9
Training loss: 2.248457591886266
Validation loss: 2.464904175837356

Epoch: 5| Step: 10
Training loss: 2.460119299128069
Validation loss: 2.4681566225461826

Epoch: 5| Step: 11
Training loss: 3.8598431137301246
Validation loss: 2.4586669216009343

Epoch: 162| Step: 0
Training loss: 2.506979545518948
Validation loss: 2.470367810963007

Epoch: 5| Step: 1
Training loss: 2.290310984655382
Validation loss: 2.468427415688658

Epoch: 5| Step: 2
Training loss: 2.6546640486015365
Validation loss: 2.4722448592334243

Epoch: 5| Step: 3
Training loss: 2.1368359075085004
Validation loss: 2.473593768647382

Epoch: 5| Step: 4
Training loss: 1.772747964449257
Validation loss: 2.4668453208775203

Epoch: 5| Step: 5
Training loss: 2.7591396520873057
Validation loss: 2.4728109262147187

Epoch: 5| Step: 6
Training loss: 2.8622813645202974
Validation loss: 2.466206242037323

Epoch: 5| Step: 7
Training loss: 2.417774395996811
Validation loss: 2.4632691534398465

Epoch: 5| Step: 8
Training loss: 2.6331752447970516
Validation loss: 2.4561113617705232

Epoch: 5| Step: 9
Training loss: 2.9979492171594555
Validation loss: 2.4464471234230416

Epoch: 5| Step: 10
Training loss: 2.9146479205232234
Validation loss: 2.4529392998257435

Epoch: 5| Step: 11
Training loss: 1.7570569936749965
Validation loss: 2.446383261120127

Epoch: 163| Step: 0
Training loss: 2.7034011435166874
Validation loss: 2.4515317938854833

Epoch: 5| Step: 1
Training loss: 2.0654066007870475
Validation loss: 2.451115572866623

Epoch: 5| Step: 2
Training loss: 2.4480658194912324
Validation loss: 2.452808481194427

Epoch: 5| Step: 3
Training loss: 2.2097502307514096
Validation loss: 2.453117241006879

Epoch: 5| Step: 4
Training loss: 2.824371629220395
Validation loss: 2.455860795140532

Epoch: 5| Step: 5
Training loss: 2.7114369924386668
Validation loss: 2.4553196640787296

Epoch: 5| Step: 6
Training loss: 2.803109152588547
Validation loss: 2.4567652297035236

Epoch: 5| Step: 7
Training loss: 2.364049058511647
Validation loss: 2.4453969459455656

Epoch: 5| Step: 8
Training loss: 2.99380568928379
Validation loss: 2.4550399231043896

Epoch: 5| Step: 9
Training loss: 2.403929644381869
Validation loss: 2.456003338963986

Epoch: 5| Step: 10
Training loss: 2.2032757430213716
Validation loss: 2.4621687014319233

Epoch: 5| Step: 11
Training loss: 2.020798659928422
Validation loss: 2.457809490760599

Epoch: 164| Step: 0
Training loss: 2.0519848588529874
Validation loss: 2.4641135575530613

Epoch: 5| Step: 1
Training loss: 2.728069162398175
Validation loss: 2.4683708591901348

Epoch: 5| Step: 2
Training loss: 2.416805548349456
Validation loss: 2.475120485629081

Epoch: 5| Step: 3
Training loss: 2.531909809537135
Validation loss: 2.4670067197292984

Epoch: 5| Step: 4
Training loss: 2.00011932493923
Validation loss: 2.4706932198347284

Epoch: 5| Step: 5
Training loss: 2.419525286402634
Validation loss: 2.464299774195629

Epoch: 5| Step: 6
Training loss: 2.6484747689924752
Validation loss: 2.4659238928262845

Epoch: 5| Step: 7
Training loss: 2.7154492917300135
Validation loss: 2.463709308708223

Epoch: 5| Step: 8
Training loss: 2.7720999917770643
Validation loss: 2.4635381772511926

Epoch: 5| Step: 9
Training loss: 2.4479792377239717
Validation loss: 2.4635707552417707

Epoch: 5| Step: 10
Training loss: 2.9346309204951764
Validation loss: 2.457001423616816

Epoch: 5| Step: 11
Training loss: 2.5904022121000594
Validation loss: 2.453821459996192

Epoch: 165| Step: 0
Training loss: 2.6916365614901263
Validation loss: 2.4544156722689743

Epoch: 5| Step: 1
Training loss: 2.815082466448845
Validation loss: 2.4577120154732817

Epoch: 5| Step: 2
Training loss: 2.4343242987664855
Validation loss: 2.449651474069569

Epoch: 5| Step: 3
Training loss: 2.633701253692448
Validation loss: 2.4484632544673333

Epoch: 5| Step: 4
Training loss: 2.489254172896025
Validation loss: 2.4554050241070566

Epoch: 5| Step: 5
Training loss: 2.7882200192146454
Validation loss: 2.4515375480087123

Epoch: 5| Step: 6
Training loss: 2.405640264766446
Validation loss: 2.459590733076654

Epoch: 5| Step: 7
Training loss: 2.7773583434589346
Validation loss: 2.4463573900580142

Epoch: 5| Step: 8
Training loss: 2.4338227925046105
Validation loss: 2.4534533376105205

Epoch: 5| Step: 9
Training loss: 2.211541083343891
Validation loss: 2.4508153243204704

Epoch: 5| Step: 10
Training loss: 1.9220835874921045
Validation loss: 2.454847824232183

Epoch: 5| Step: 11
Training loss: 2.7197418157673705
Validation loss: 2.4541000647539657

Epoch: 166| Step: 0
Training loss: 2.6085142440538607
Validation loss: 2.4588001799331467

Epoch: 5| Step: 1
Training loss: 2.2211889911402842
Validation loss: 2.456414263007536

Epoch: 5| Step: 2
Training loss: 2.353200652386933
Validation loss: 2.4607999087021972

Epoch: 5| Step: 3
Training loss: 2.411353409024507
Validation loss: 2.4642593126185854

Epoch: 5| Step: 4
Training loss: 2.8048373636569663
Validation loss: 2.4653330547481493

Epoch: 5| Step: 5
Training loss: 2.8409267286273328
Validation loss: 2.4691898300207926

Epoch: 5| Step: 6
Training loss: 2.413953661394085
Validation loss: 2.470979235352808

Epoch: 5| Step: 7
Training loss: 2.8290312774428634
Validation loss: 2.4688291094373924

Epoch: 5| Step: 8
Training loss: 1.899086421372088
Validation loss: 2.4616978716976297

Epoch: 5| Step: 9
Training loss: 2.551051641039484
Validation loss: 2.4608331849933203

Epoch: 5| Step: 10
Training loss: 3.003326796659694
Validation loss: 2.4596326527429375

Epoch: 5| Step: 11
Training loss: 1.3633258014383849
Validation loss: 2.4580597698351667

Epoch: 167| Step: 0
Training loss: 2.284127184658731
Validation loss: 2.4562789298918837

Epoch: 5| Step: 1
Training loss: 2.7098915214927066
Validation loss: 2.456012391269077

Epoch: 5| Step: 2
Training loss: 2.521261310239964
Validation loss: 2.4504774105320566

Epoch: 5| Step: 3
Training loss: 2.6223916309756135
Validation loss: 2.447164019408398

Epoch: 5| Step: 4
Training loss: 2.8641509313505376
Validation loss: 2.4516014624425773

Epoch: 5| Step: 5
Training loss: 2.001265125682123
Validation loss: 2.4561933171184394

Epoch: 5| Step: 6
Training loss: 2.6148451614490047
Validation loss: 2.450146010323361

Epoch: 5| Step: 7
Training loss: 2.396720147135264
Validation loss: 2.452081446186421

Epoch: 5| Step: 8
Training loss: 2.7981347172108064
Validation loss: 2.4495874560363027

Epoch: 5| Step: 9
Training loss: 2.3177955411013116
Validation loss: 2.4503776246296662

Epoch: 5| Step: 10
Training loss: 2.3897556893522105
Validation loss: 2.446848836623326

Epoch: 5| Step: 11
Training loss: 3.084419746422192
Validation loss: 2.4527223220094054

Epoch: 168| Step: 0
Training loss: 2.7601671405990924
Validation loss: 2.4594252607484335

Epoch: 5| Step: 1
Training loss: 2.7851085685511334
Validation loss: 2.4665043270543037

Epoch: 5| Step: 2
Training loss: 2.5593761849313306
Validation loss: 2.4746204106005267

Epoch: 5| Step: 3
Training loss: 2.803490088257363
Validation loss: 2.4756945463956

Epoch: 5| Step: 4
Training loss: 2.1740010784816786
Validation loss: 2.4772209631883464

Epoch: 5| Step: 5
Training loss: 3.012045678034273
Validation loss: 2.479262796242593

Epoch: 5| Step: 6
Training loss: 2.995318574854462
Validation loss: 2.4887573329703185

Epoch: 5| Step: 7
Training loss: 2.3082324679632396
Validation loss: 2.4885586394833896

Epoch: 5| Step: 8
Training loss: 2.1918596692795944
Validation loss: 2.490635108368837

Epoch: 5| Step: 9
Training loss: 2.401682097336673
Validation loss: 2.4859203274891204

Epoch: 5| Step: 10
Training loss: 2.264768872794788
Validation loss: 2.483759809896048

Epoch: 5| Step: 11
Training loss: 2.510721486264814
Validation loss: 2.4833751641874424

Epoch: 169| Step: 0
Training loss: 2.7409533035436833
Validation loss: 2.483551580697661

Epoch: 5| Step: 1
Training loss: 2.0232166773659657
Validation loss: 2.4803227419195375

Epoch: 5| Step: 2
Training loss: 2.492349075293518
Validation loss: 2.4727508964724643

Epoch: 5| Step: 3
Training loss: 2.807731655275245
Validation loss: 2.4749843972610184

Epoch: 5| Step: 4
Training loss: 2.7829534050525537
Validation loss: 2.4673347339824137

Epoch: 5| Step: 5
Training loss: 2.1901886901390677
Validation loss: 2.4674492076914016

Epoch: 5| Step: 6
Training loss: 2.4151698662072403
Validation loss: 2.463634744596925

Epoch: 5| Step: 7
Training loss: 2.6094734949950236
Validation loss: 2.4666409034178303

Epoch: 5| Step: 8
Training loss: 2.6686521132516505
Validation loss: 2.4619522868518877

Epoch: 5| Step: 9
Training loss: 2.5557797398113506
Validation loss: 2.4520247719533956

Epoch: 5| Step: 10
Training loss: 2.842973204774608
Validation loss: 2.452420179997523

Epoch: 5| Step: 11
Training loss: 1.8560036621016514
Validation loss: 2.455267656850682

Epoch: 170| Step: 0
Training loss: 2.930316989663765
Validation loss: 2.45395109112793

Epoch: 5| Step: 1
Training loss: 2.2951439802761295
Validation loss: 2.4560847559277095

Epoch: 5| Step: 2
Training loss: 2.1851050208929417
Validation loss: 2.4520427195432832

Epoch: 5| Step: 3
Training loss: 2.199641293846394
Validation loss: 2.4511999728959473

Epoch: 5| Step: 4
Training loss: 2.1523018779247165
Validation loss: 2.459355842098861

Epoch: 5| Step: 5
Training loss: 2.295975801047956
Validation loss: 2.456090151541508

Epoch: 5| Step: 6
Training loss: 3.035720831599511
Validation loss: 2.451733698802679

Epoch: 5| Step: 7
Training loss: 2.5614140698451955
Validation loss: 2.4523554443262023

Epoch: 5| Step: 8
Training loss: 2.254156194675492
Validation loss: 2.4560217104973723

Epoch: 5| Step: 9
Training loss: 2.873091022455681
Validation loss: 2.4499642283559457

Epoch: 5| Step: 10
Training loss: 2.7771441552917704
Validation loss: 2.4546189021564655

Epoch: 5| Step: 11
Training loss: 2.66839140508563
Validation loss: 2.4553628643596754

Epoch: 171| Step: 0
Training loss: 2.5750170846020484
Validation loss: 2.4509790960243016

Epoch: 5| Step: 1
Training loss: 2.282413656183057
Validation loss: 2.456678695735527

Epoch: 5| Step: 2
Training loss: 2.5443682357484527
Validation loss: 2.455583628079988

Epoch: 5| Step: 3
Training loss: 2.628158848529797
Validation loss: 2.4618966872315715

Epoch: 5| Step: 4
Training loss: 2.466432473517842
Validation loss: 2.4649747238385022

Epoch: 5| Step: 5
Training loss: 2.8261188114565363
Validation loss: 2.459870336140512

Epoch: 5| Step: 6
Training loss: 2.6765797558265545
Validation loss: 2.4623767216801946

Epoch: 5| Step: 7
Training loss: 2.431881420055455
Validation loss: 2.463774371027425

Epoch: 5| Step: 8
Training loss: 2.614538964937418
Validation loss: 2.4593792336478786

Epoch: 5| Step: 9
Training loss: 2.4666285030746273
Validation loss: 2.456172253200893

Epoch: 5| Step: 10
Training loss: 2.341505985471483
Validation loss: 2.46539918230476

Epoch: 5| Step: 11
Training loss: 1.1059291676091267
Validation loss: 2.461419033189355

Epoch: 172| Step: 0
Training loss: 2.3312924746819186
Validation loss: 2.4625562400011205

Epoch: 5| Step: 1
Training loss: 2.339571674303153
Validation loss: 2.4520939241459856

Epoch: 5| Step: 2
Training loss: 2.4049248948137287
Validation loss: 2.455531662853029

Epoch: 5| Step: 3
Training loss: 2.348748839876986
Validation loss: 2.4516816033501114

Epoch: 5| Step: 4
Training loss: 2.3164347603444146
Validation loss: 2.453293699388392

Epoch: 5| Step: 5
Training loss: 2.5428181734053434
Validation loss: 2.4594757663711433

Epoch: 5| Step: 6
Training loss: 2.1204617227824802
Validation loss: 2.4526055468376287

Epoch: 5| Step: 7
Training loss: 2.9421734259010996
Validation loss: 2.4572127153413605

Epoch: 5| Step: 8
Training loss: 3.0748848684203653
Validation loss: 2.452828176727529

Epoch: 5| Step: 9
Training loss: 2.251333689132239
Validation loss: 2.4548824235337814

Epoch: 5| Step: 10
Training loss: 2.6883030068787286
Validation loss: 2.4569380155743645

Epoch: 5| Step: 11
Training loss: 3.0729292185036727
Validation loss: 2.4601886689791974

Epoch: 173| Step: 0
Training loss: 2.3762195868956395
Validation loss: 2.4541192742895253

Epoch: 5| Step: 1
Training loss: 2.1256538955801734
Validation loss: 2.455348171696643

Epoch: 5| Step: 2
Training loss: 2.4784792633635933
Validation loss: 2.452240527312802

Epoch: 5| Step: 3
Training loss: 3.1723076285738143
Validation loss: 2.4517467984650287

Epoch: 5| Step: 4
Training loss: 2.6855870913181965
Validation loss: 2.453899390903211

Epoch: 5| Step: 5
Training loss: 2.4093959109812717
Validation loss: 2.4556298800502723

Epoch: 5| Step: 6
Training loss: 2.15003602640885
Validation loss: 2.4530285291877574

Epoch: 5| Step: 7
Training loss: 2.4749963664018564
Validation loss: 2.4501231590767363

Epoch: 5| Step: 8
Training loss: 2.6667349826486104
Validation loss: 2.4482182756576734

Epoch: 5| Step: 9
Training loss: 2.3493695854171297
Validation loss: 2.45978660919849

Epoch: 5| Step: 10
Training loss: 2.6961497899844065
Validation loss: 2.453312200542926

Epoch: 5| Step: 11
Training loss: 2.2637302236467267
Validation loss: 2.4533424726498243

Epoch: 174| Step: 0
Training loss: 3.0428027987984185
Validation loss: 2.4528306310641868

Epoch: 5| Step: 1
Training loss: 2.2213723173365163
Validation loss: 2.4491315194414085

Epoch: 5| Step: 2
Training loss: 2.3944225193248174
Validation loss: 2.451175019970177

Epoch: 5| Step: 3
Training loss: 2.283223382943171
Validation loss: 2.4488433193218757

Epoch: 5| Step: 4
Training loss: 2.847287001040883
Validation loss: 2.4484533465630745

Epoch: 5| Step: 5
Training loss: 1.8530230334888935
Validation loss: 2.4483695598752258

Epoch: 5| Step: 6
Training loss: 2.4981509046091888
Validation loss: 2.4521617942212335

Epoch: 5| Step: 7
Training loss: 2.4812183599112245
Validation loss: 2.4520611612640413

Epoch: 5| Step: 8
Training loss: 2.4217269359981652
Validation loss: 2.4581129708098013

Epoch: 5| Step: 9
Training loss: 2.616858344944117
Validation loss: 2.4615217453877314

Epoch: 5| Step: 10
Training loss: 2.8476939257731426
Validation loss: 2.4568446765245575

Epoch: 5| Step: 11
Training loss: 2.706297495647648
Validation loss: 2.4650820633535164

Epoch: 175| Step: 0
Training loss: 2.742477010458441
Validation loss: 2.457245146755893

Epoch: 5| Step: 1
Training loss: 2.3684223844290218
Validation loss: 2.457522021324654

Epoch: 5| Step: 2
Training loss: 2.342404806020632
Validation loss: 2.444418685920662

Epoch: 5| Step: 3
Training loss: 2.6278924900400673
Validation loss: 2.459132191338695

Epoch: 5| Step: 4
Training loss: 2.547801966566445
Validation loss: 2.4451738344633958

Epoch: 5| Step: 5
Training loss: 2.3358503344549164
Validation loss: 2.449833287353934

Epoch: 5| Step: 6
Training loss: 2.401620846041454
Validation loss: 2.4493544630692115

Epoch: 5| Step: 7
Training loss: 2.681735487869412
Validation loss: 2.4444099564419295

Epoch: 5| Step: 8
Training loss: 2.8260006170575873
Validation loss: 2.4504077079895454

Epoch: 5| Step: 9
Training loss: 2.3559260138016485
Validation loss: 2.4452658131848017

Epoch: 5| Step: 10
Training loss: 2.48903214698958
Validation loss: 2.449969000847299

Epoch: 5| Step: 11
Training loss: 2.505586105276973
Validation loss: 2.4571079187606286

Epoch: 176| Step: 0
Training loss: 2.24276311311087
Validation loss: 2.456044672698477

Epoch: 5| Step: 1
Training loss: 2.4212177984629952
Validation loss: 2.4579776948486356

Epoch: 5| Step: 2
Training loss: 2.8405079228915673
Validation loss: 2.453639488776133

Epoch: 5| Step: 3
Training loss: 2.2252036783668334
Validation loss: 2.4595034462760577

Epoch: 5| Step: 4
Training loss: 2.4287241899706284
Validation loss: 2.4583471076924264

Epoch: 5| Step: 5
Training loss: 2.4917537108392067
Validation loss: 2.461209838168829

Epoch: 5| Step: 6
Training loss: 2.7496250070310992
Validation loss: 2.4646778806564225

Epoch: 5| Step: 7
Training loss: 2.039436510650759
Validation loss: 2.468131619680657

Epoch: 5| Step: 8
Training loss: 3.0282067822257397
Validation loss: 2.4631311317850857

Epoch: 5| Step: 9
Training loss: 2.7072837458621013
Validation loss: 2.461937901846639

Epoch: 5| Step: 10
Training loss: 2.5808205124862282
Validation loss: 2.4684515301838963

Epoch: 5| Step: 11
Training loss: 0.9618519099725459
Validation loss: 2.462026801044266

Epoch: 177| Step: 0
Training loss: 2.5209425174828235
Validation loss: 2.4636597689062065

Epoch: 5| Step: 1
Training loss: 2.5515493547950103
Validation loss: 2.4598450390473263

Epoch: 5| Step: 2
Training loss: 2.504677307146242
Validation loss: 2.4617105470756955

Epoch: 5| Step: 3
Training loss: 2.885343272977668
Validation loss: 2.457962728841417

Epoch: 5| Step: 4
Training loss: 2.250881234423961
Validation loss: 2.449462389755033

Epoch: 5| Step: 5
Training loss: 2.4356191176259516
Validation loss: 2.461153735394374

Epoch: 5| Step: 6
Training loss: 2.6262927732111927
Validation loss: 2.454747459218386

Epoch: 5| Step: 7
Training loss: 2.555902687858966
Validation loss: 2.4617616898078443

Epoch: 5| Step: 8
Training loss: 2.3205453261370996
Validation loss: 2.45254114415261

Epoch: 5| Step: 9
Training loss: 2.2899932531399014
Validation loss: 2.4627297752506916

Epoch: 5| Step: 10
Training loss: 2.5195389148684284
Validation loss: 2.4566968195974255

Epoch: 5| Step: 11
Training loss: 2.46045488741843
Validation loss: 2.455031716963457

Epoch: 178| Step: 0
Training loss: 2.7423317374091902
Validation loss: 2.4523402657696263

Epoch: 5| Step: 1
Training loss: 2.4590122987890286
Validation loss: 2.4613067915011633

Epoch: 5| Step: 2
Training loss: 2.458727810346956
Validation loss: 2.4517266181487454

Epoch: 5| Step: 3
Training loss: 2.5621922936262655
Validation loss: 2.461886252327266

Epoch: 5| Step: 4
Training loss: 2.2311905796890295
Validation loss: 2.4690188148875274

Epoch: 5| Step: 5
Training loss: 2.63493383957904
Validation loss: 2.4740312839928813

Epoch: 5| Step: 6
Training loss: 2.3850489392647667
Validation loss: 2.4763950588129013

Epoch: 5| Step: 7
Training loss: 2.59251558275239
Validation loss: 2.4763756269354325

Epoch: 5| Step: 8
Training loss: 1.9226436783535747
Validation loss: 2.4697187510817264

Epoch: 5| Step: 9
Training loss: 2.887107399676719
Validation loss: 2.4826966620587028

Epoch: 5| Step: 10
Training loss: 2.697328825036865
Validation loss: 2.4782293027564273

Epoch: 5| Step: 11
Training loss: 3.334552414812055
Validation loss: 2.4693545434249766

Epoch: 179| Step: 0
Training loss: 2.2195053963798617
Validation loss: 2.469742157106148

Epoch: 5| Step: 1
Training loss: 2.083999247618556
Validation loss: 2.466604366729316

Epoch: 5| Step: 2
Training loss: 2.484495819800705
Validation loss: 2.468180115832128

Epoch: 5| Step: 3
Training loss: 2.610315393267937
Validation loss: 2.4609206506868833

Epoch: 5| Step: 4
Training loss: 2.9290381767413183
Validation loss: 2.463235212356191

Epoch: 5| Step: 5
Training loss: 2.3023085908305405
Validation loss: 2.4627819879315975

Epoch: 5| Step: 6
Training loss: 2.363652274271627
Validation loss: 2.462992114225467

Epoch: 5| Step: 7
Training loss: 2.546478615087346
Validation loss: 2.456625779116612

Epoch: 5| Step: 8
Training loss: 2.583909083370204
Validation loss: 2.458153078911566

Epoch: 5| Step: 9
Training loss: 2.526244028906393
Validation loss: 2.4594464987638123

Epoch: 5| Step: 10
Training loss: 2.668470745976307
Validation loss: 2.4629200069682557

Epoch: 5| Step: 11
Training loss: 3.278894359975166
Validation loss: 2.464653449110496

Epoch: 180| Step: 0
Training loss: 1.9069946585601911
Validation loss: 2.459208697650673

Epoch: 5| Step: 1
Training loss: 2.8819577156792877
Validation loss: 2.4660940732159933

Epoch: 5| Step: 2
Training loss: 2.320658340111866
Validation loss: 2.465801421744625

Epoch: 5| Step: 3
Training loss: 2.7956001317133228
Validation loss: 2.4616418587393007

Epoch: 5| Step: 4
Training loss: 2.373297030603458
Validation loss: 2.472476818129041

Epoch: 5| Step: 5
Training loss: 2.178834591053414
Validation loss: 2.475469057031383

Epoch: 5| Step: 6
Training loss: 2.3346131311825604
Validation loss: 2.47082748803728

Epoch: 5| Step: 7
Training loss: 2.703409168984364
Validation loss: 2.4709872035983373

Epoch: 5| Step: 8
Training loss: 2.4889700758082736
Validation loss: 2.4712368957758675

Epoch: 5| Step: 9
Training loss: 2.7342077585574156
Validation loss: 2.470306276156334

Epoch: 5| Step: 10
Training loss: 2.4788463182535225
Validation loss: 2.467707498361605

Epoch: 5| Step: 11
Training loss: 3.89106888900711
Validation loss: 2.464479757074263

Epoch: 181| Step: 0
Training loss: 2.2566237966878377
Validation loss: 2.466839497757512

Epoch: 5| Step: 1
Training loss: 2.30681354284781
Validation loss: 2.4673546175399017

Epoch: 5| Step: 2
Training loss: 2.6631828936730177
Validation loss: 2.4674663868450186

Epoch: 5| Step: 3
Training loss: 2.745315550019204
Validation loss: 2.463375954300139

Epoch: 5| Step: 4
Training loss: 2.2477326094750483
Validation loss: 2.4658197081914484

Epoch: 5| Step: 5
Training loss: 3.112820963415783
Validation loss: 2.465549374038231

Epoch: 5| Step: 6
Training loss: 2.283017662484633
Validation loss: 2.4668665513895154

Epoch: 5| Step: 7
Training loss: 2.3172070822013726
Validation loss: 2.4710940045543457

Epoch: 5| Step: 8
Training loss: 2.5425681928193624
Validation loss: 2.4701692348617272

Epoch: 5| Step: 9
Training loss: 2.396037836607161
Validation loss: 2.470441013751726

Epoch: 5| Step: 10
Training loss: 2.700121671972771
Validation loss: 2.460316501961261

Epoch: 5| Step: 11
Training loss: 2.056217566701079
Validation loss: 2.4633656547096705

Epoch: 182| Step: 0
Training loss: 2.201482607039606
Validation loss: 2.4639451312823692

Epoch: 5| Step: 1
Training loss: 2.925236364742483
Validation loss: 2.4595494468181744

Epoch: 5| Step: 2
Training loss: 2.7050522124774234
Validation loss: 2.4626869361459276

Epoch: 5| Step: 3
Training loss: 2.606211680764088
Validation loss: 2.4580748564940875

Epoch: 5| Step: 4
Training loss: 1.9133091903895656
Validation loss: 2.4698417679944504

Epoch: 5| Step: 5
Training loss: 2.6654487649991414
Validation loss: 2.466146903489286

Epoch: 5| Step: 6
Training loss: 2.4429777169009665
Validation loss: 2.4613894133430985

Epoch: 5| Step: 7
Training loss: 2.3767099749813356
Validation loss: 2.463095361769557

Epoch: 5| Step: 8
Training loss: 2.632755267599377
Validation loss: 2.4659018726520237

Epoch: 5| Step: 9
Training loss: 2.400838935772248
Validation loss: 2.467032700414044

Epoch: 5| Step: 10
Training loss: 2.657940046422183
Validation loss: 2.464839042582503

Epoch: 5| Step: 11
Training loss: 2.3345222396069047
Validation loss: 2.4704627401343044

Epoch: 183| Step: 0
Training loss: 2.6877595643072136
Validation loss: 2.4643661108782995

Epoch: 5| Step: 1
Training loss: 2.6722399367575607
Validation loss: 2.4690617835262656

Epoch: 5| Step: 2
Training loss: 2.4076381493976746
Validation loss: 2.4703112265036458

Epoch: 5| Step: 3
Training loss: 2.680988852136607
Validation loss: 2.4625841192539606

Epoch: 5| Step: 4
Training loss: 3.026317082716886
Validation loss: 2.4613416551812293

Epoch: 5| Step: 5
Training loss: 2.3616652330902568
Validation loss: 2.461968780074952

Epoch: 5| Step: 6
Training loss: 2.200098000857895
Validation loss: 2.4628586309474008

Epoch: 5| Step: 7
Training loss: 2.542847426841384
Validation loss: 2.46676463360027

Epoch: 5| Step: 8
Training loss: 2.350869111396561
Validation loss: 2.461010926781053

Epoch: 5| Step: 9
Training loss: 2.038706313553368
Validation loss: 2.4634933238430983

Epoch: 5| Step: 10
Training loss: 2.5695700457234376
Validation loss: 2.4659044509482335

Epoch: 5| Step: 11
Training loss: 1.4696105708486011
Validation loss: 2.4589894612577607

Epoch: 184| Step: 0
Training loss: 2.293977739633513
Validation loss: 2.471255877636879

Epoch: 5| Step: 1
Training loss: 2.7600183931373614
Validation loss: 2.4652966860522154

Epoch: 5| Step: 2
Training loss: 2.6190705314889047
Validation loss: 2.4657752548482343

Epoch: 5| Step: 3
Training loss: 2.7746228760846376
Validation loss: 2.4815424880459562

Epoch: 5| Step: 4
Training loss: 2.015518777103536
Validation loss: 2.4749978454818082

Epoch: 5| Step: 5
Training loss: 2.8687073216141306
Validation loss: 2.4744435942050806

Epoch: 5| Step: 6
Training loss: 2.630970749341927
Validation loss: 2.4687021870550243

Epoch: 5| Step: 7
Training loss: 1.9859384100046782
Validation loss: 2.4647122452321866

Epoch: 5| Step: 8
Training loss: 2.5868513906857262
Validation loss: 2.4675154415879077

Epoch: 5| Step: 9
Training loss: 2.2188165144285654
Validation loss: 2.4708064322805727

Epoch: 5| Step: 10
Training loss: 2.5693919843754007
Validation loss: 2.4713060972619076

Epoch: 5| Step: 11
Training loss: 2.690771551272552
Validation loss: 2.4683518350200995

Epoch: 185| Step: 0
Training loss: 3.265184874740686
Validation loss: 2.46808912388801

Epoch: 5| Step: 1
Training loss: 2.509147882694243
Validation loss: 2.4610107693537944

Epoch: 5| Step: 2
Training loss: 2.4338848007323772
Validation loss: 2.4618897467742364

Epoch: 5| Step: 3
Training loss: 2.4245081215893736
Validation loss: 2.4647061953926444

Epoch: 5| Step: 4
Training loss: 2.732991855116487
Validation loss: 2.460317147998868

Epoch: 5| Step: 5
Training loss: 2.821524827084376
Validation loss: 2.4551487004371526

Epoch: 5| Step: 6
Training loss: 2.555163511206327
Validation loss: 2.459303395102607

Epoch: 5| Step: 7
Training loss: 1.8893235195867908
Validation loss: 2.4578468735852357

Epoch: 5| Step: 8
Training loss: 2.0878607067109245
Validation loss: 2.4615935909310593

Epoch: 5| Step: 9
Training loss: 2.738134099949124
Validation loss: 2.455902875552727

Epoch: 5| Step: 10
Training loss: 1.9832185394126867
Validation loss: 2.45056643968899

Epoch: 5| Step: 11
Training loss: 2.7308712554834726
Validation loss: 2.455387918353732

Epoch: 186| Step: 0
Training loss: 2.675232857524739
Validation loss: 2.4533910262884557

Epoch: 5| Step: 1
Training loss: 2.5639324371434453
Validation loss: 2.4582718879219

Epoch: 5| Step: 2
Training loss: 2.374440478621718
Validation loss: 2.46318938953818

Epoch: 5| Step: 3
Training loss: 2.5871875887623226
Validation loss: 2.464908923432591

Epoch: 5| Step: 4
Training loss: 1.8509123743256028
Validation loss: 2.4634977999458583

Epoch: 5| Step: 5
Training loss: 2.5301192783991917
Validation loss: 2.4612924511569365

Epoch: 5| Step: 6
Training loss: 2.0637775279288064
Validation loss: 2.464100015661473

Epoch: 5| Step: 7
Training loss: 2.6396066180383664
Validation loss: 2.456847769755276

Epoch: 5| Step: 8
Training loss: 1.9782954523733565
Validation loss: 2.4581362933596096

Epoch: 5| Step: 9
Training loss: 3.0187216557974774
Validation loss: 2.4548703239504253

Epoch: 5| Step: 10
Training loss: 2.7748980907251193
Validation loss: 2.462603668025233

Epoch: 5| Step: 11
Training loss: 3.5624714900431984
Validation loss: 2.4624987983055218

Epoch: 187| Step: 0
Training loss: 2.2220723167826835
Validation loss: 2.4633441238291733

Epoch: 5| Step: 1
Training loss: 3.028444387876625
Validation loss: 2.464232403709682

Epoch: 5| Step: 2
Training loss: 2.867347983044887
Validation loss: 2.458696069195435

Epoch: 5| Step: 3
Training loss: 2.124742828963872
Validation loss: 2.46288563956982

Epoch: 5| Step: 4
Training loss: 2.2917125581712434
Validation loss: 2.462681050753069

Epoch: 5| Step: 5
Training loss: 2.310905628616482
Validation loss: 2.4548851226634714

Epoch: 5| Step: 6
Training loss: 2.5690467755850697
Validation loss: 2.464197851030366

Epoch: 5| Step: 7
Training loss: 1.999788928815089
Validation loss: 2.4635396450644675

Epoch: 5| Step: 8
Training loss: 2.623738757904961
Validation loss: 2.46190148904816

Epoch: 5| Step: 9
Training loss: 2.90582994276162
Validation loss: 2.4571245314251606

Epoch: 5| Step: 10
Training loss: 2.5642567637122733
Validation loss: 2.4618697847800317

Epoch: 5| Step: 11
Training loss: 1.4673884147578735
Validation loss: 2.464332338086889

Epoch: 188| Step: 0
Training loss: 2.7688238749755762
Validation loss: 2.4648122568833997

Epoch: 5| Step: 1
Training loss: 2.389765666023989
Validation loss: 2.4665998197424486

Epoch: 5| Step: 2
Training loss: 2.3324852378517087
Validation loss: 2.4591639753365944

Epoch: 5| Step: 3
Training loss: 2.4193856520382555
Validation loss: 2.4630262804902157

Epoch: 5| Step: 4
Training loss: 2.4016807075353013
Validation loss: 2.4593110739879536

Epoch: 5| Step: 5
Training loss: 2.9349167198830233
Validation loss: 2.4691019571892796

Epoch: 5| Step: 6
Training loss: 2.845594206370455
Validation loss: 2.4604689500202648

Epoch: 5| Step: 7
Training loss: 2.131866357003538
Validation loss: 2.4681225635255397

Epoch: 5| Step: 8
Training loss: 2.202830842854032
Validation loss: 2.4687352079439253

Epoch: 5| Step: 9
Training loss: 2.4294631707257053
Validation loss: 2.4660055059504034

Epoch: 5| Step: 10
Training loss: 2.2631578363724403
Validation loss: 2.464141274053583

Epoch: 5| Step: 11
Training loss: 3.250056339655899
Validation loss: 2.4651077983503566

Epoch: 189| Step: 0
Training loss: 2.9589531119429315
Validation loss: 2.4595840163318536

Epoch: 5| Step: 1
Training loss: 2.677408300088595
Validation loss: 2.4583476289775303

Epoch: 5| Step: 2
Training loss: 2.2943451112002156
Validation loss: 2.4651656386491685

Epoch: 5| Step: 3
Training loss: 2.457172335165889
Validation loss: 2.463412222307718

Epoch: 5| Step: 4
Training loss: 2.0075949465672656
Validation loss: 2.465096687925079

Epoch: 5| Step: 5
Training loss: 2.6068563583830597
Validation loss: 2.460409364089228

Epoch: 5| Step: 6
Training loss: 2.5068689395409964
Validation loss: 2.4623822003312914

Epoch: 5| Step: 7
Training loss: 2.780461746125539
Validation loss: 2.4608930028697165

Epoch: 5| Step: 8
Training loss: 2.2433034000789793
Validation loss: 2.4559074585243765

Epoch: 5| Step: 9
Training loss: 2.386828430952101
Validation loss: 2.459597833500101

Epoch: 5| Step: 10
Training loss: 2.58658649333441
Validation loss: 2.461686689385366

Epoch: 5| Step: 11
Training loss: 1.8683249867389233
Validation loss: 2.4706161302773535

Epoch: 190| Step: 0
Training loss: 2.4193146985323484
Validation loss: 2.4625359566479053

Epoch: 5| Step: 1
Training loss: 2.28461552930909
Validation loss: 2.4635179987624696

Epoch: 5| Step: 2
Training loss: 2.5537149520463185
Validation loss: 2.469628254281461

Epoch: 5| Step: 3
Training loss: 2.8967765717311997
Validation loss: 2.4620434914784304

Epoch: 5| Step: 4
Training loss: 2.1579500213930634
Validation loss: 2.4608970941526502

Epoch: 5| Step: 5
Training loss: 3.154881246662383
Validation loss: 2.4607364915570464

Epoch: 5| Step: 6
Training loss: 2.6678440852382788
Validation loss: 2.460394501700656

Epoch: 5| Step: 7
Training loss: 1.995455466266482
Validation loss: 2.461293040432508

Epoch: 5| Step: 8
Training loss: 2.250084451574004
Validation loss: 2.4623136315927554

Epoch: 5| Step: 9
Training loss: 2.3758176098957433
Validation loss: 2.463294750095568

Epoch: 5| Step: 10
Training loss: 2.411019490616129
Validation loss: 2.4587686659714163

Epoch: 5| Step: 11
Training loss: 2.7876904957088984
Validation loss: 2.4608074658467456

Epoch: 191| Step: 0
Training loss: 2.0880214839283124
Validation loss: 2.4686554878589386

Epoch: 5| Step: 1
Training loss: 2.5966888691545083
Validation loss: 2.45654492803718

Epoch: 5| Step: 2
Training loss: 2.9710753318663112
Validation loss: 2.4625931393005986

Epoch: 5| Step: 3
Training loss: 2.5360309050087833
Validation loss: 2.455349154851561

Epoch: 5| Step: 4
Training loss: 2.344469799137665
Validation loss: 2.4613930457184026

Epoch: 5| Step: 5
Training loss: 2.1453110019042363
Validation loss: 2.464055273270799

Epoch: 5| Step: 6
Training loss: 2.1051462241374113
Validation loss: 2.461764593251396

Epoch: 5| Step: 7
Training loss: 2.147956045130804
Validation loss: 2.459903701736258

Epoch: 5| Step: 8
Training loss: 2.579919179197559
Validation loss: 2.4576929350700394

Epoch: 5| Step: 9
Training loss: 2.918387223433669
Validation loss: 2.4626012597347184

Epoch: 5| Step: 10
Training loss: 2.5867079771157995
Validation loss: 2.4631422631756514

Epoch: 5| Step: 11
Training loss: 3.409859520935525
Validation loss: 2.4683783448610153

Epoch: 192| Step: 0
Training loss: 2.108646182142956
Validation loss: 2.468214395423464

Epoch: 5| Step: 1
Training loss: 2.265849240485591
Validation loss: 2.465614045331928

Epoch: 5| Step: 2
Training loss: 2.1002647051419587
Validation loss: 2.462400661439943

Epoch: 5| Step: 3
Training loss: 2.3733723735098637
Validation loss: 2.465775307222592

Epoch: 5| Step: 4
Training loss: 2.431969849387043
Validation loss: 2.462971584392087

Epoch: 5| Step: 5
Training loss: 2.5001948280712463
Validation loss: 2.470024359424644

Epoch: 5| Step: 6
Training loss: 2.5530623653577775
Validation loss: 2.4629783886996344

Epoch: 5| Step: 7
Training loss: 2.651556198661119
Validation loss: 2.4696697380916786

Epoch: 5| Step: 8
Training loss: 2.841164891604178
Validation loss: 2.4643788531540385

Epoch: 5| Step: 9
Training loss: 2.529755798888117
Validation loss: 2.4686805819960442

Epoch: 5| Step: 10
Training loss: 3.044662846282685
Validation loss: 2.4716318066321477

Epoch: 5| Step: 11
Training loss: 2.370328223440969
Validation loss: 2.4772548129052008

Epoch: 193| Step: 0
Training loss: 2.8802477171115455
Validation loss: 2.4731895068624037

Epoch: 5| Step: 1
Training loss: 2.4487964320782725
Validation loss: 2.4755261857285045

Epoch: 5| Step: 2
Training loss: 2.3308558481124857
Validation loss: 2.4721875060307354

Epoch: 5| Step: 3
Training loss: 2.9413024965101027
Validation loss: 2.468598622698908

Epoch: 5| Step: 4
Training loss: 2.6653577950146876
Validation loss: 2.4711421370454856

Epoch: 5| Step: 5
Training loss: 2.7550432604043116
Validation loss: 2.4730146970871347

Epoch: 5| Step: 6
Training loss: 2.5000625602523994
Validation loss: 2.4700714831812864

Epoch: 5| Step: 7
Training loss: 2.627194894775932
Validation loss: 2.4718829086119323

Epoch: 5| Step: 8
Training loss: 2.282415223067065
Validation loss: 2.4686041921702238

Epoch: 5| Step: 9
Training loss: 2.348838977925045
Validation loss: 2.4634074778769732

Epoch: 5| Step: 10
Training loss: 2.3342024569597437
Validation loss: 2.466188127637739

Epoch: 5| Step: 11
Training loss: 2.2903564753704257
Validation loss: 2.4583146746514632

Epoch: 194| Step: 0
Training loss: 2.4598004333059
Validation loss: 2.4545263187709323

Epoch: 5| Step: 1
Training loss: 2.47340417912993
Validation loss: 2.4570001783160014

Epoch: 5| Step: 2
Training loss: 2.621623728991236
Validation loss: 2.4578226267514465

Epoch: 5| Step: 3
Training loss: 2.9959094452153696
Validation loss: 2.459731013128376

Epoch: 5| Step: 4
Training loss: 2.762422938588185
Validation loss: 2.4571303816115075

Epoch: 5| Step: 5
Training loss: 2.148928388521623
Validation loss: 2.456670648730332

Epoch: 5| Step: 6
Training loss: 2.6332283031265478
Validation loss: 2.4549572089662015

Epoch: 5| Step: 7
Training loss: 2.9222437987923042
Validation loss: 2.462837615969097

Epoch: 5| Step: 8
Training loss: 2.3383455144665075
Validation loss: 2.464933443125234

Epoch: 5| Step: 9
Training loss: 2.275584881394056
Validation loss: 2.461612011544446

Epoch: 5| Step: 10
Training loss: 2.0636630391515367
Validation loss: 2.4590045199933783

Epoch: 5| Step: 11
Training loss: 1.2131402439140369
Validation loss: 2.4587341658006894

Epoch: 195| Step: 0
Training loss: 2.694785954002771
Validation loss: 2.466073512809801

Epoch: 5| Step: 1
Training loss: 2.2264950390684866
Validation loss: 2.464353840177827

Epoch: 5| Step: 2
Training loss: 2.6898810019283217
Validation loss: 2.4643160884445057

Epoch: 5| Step: 3
Training loss: 2.5942394300386833
Validation loss: 2.4638658005202365

Epoch: 5| Step: 4
Training loss: 2.455674905403366
Validation loss: 2.4672926975570086

Epoch: 5| Step: 5
Training loss: 2.6828071074301056
Validation loss: 2.4655051092243037

Epoch: 5| Step: 6
Training loss: 2.3016865476080666
Validation loss: 2.4670201731837498

Epoch: 5| Step: 7
Training loss: 2.2606587668531812
Validation loss: 2.4671250520436776

Epoch: 5| Step: 8
Training loss: 2.8884356481440325
Validation loss: 2.470449639184671

Epoch: 5| Step: 9
Training loss: 2.221090023052404
Validation loss: 2.468349235132713

Epoch: 5| Step: 10
Training loss: 1.9968506932458252
Validation loss: 2.4732867617691

Epoch: 5| Step: 11
Training loss: 3.4871473017813988
Validation loss: 2.4700836651515288

Epoch: 196| Step: 0
Training loss: 2.176532389698854
Validation loss: 2.4655102041907915

Epoch: 5| Step: 1
Training loss: 2.4874579536296566
Validation loss: 2.4668272876853132

Epoch: 5| Step: 2
Training loss: 1.9917387812286396
Validation loss: 2.4676564104203376

Epoch: 5| Step: 3
Training loss: 2.6372501996241238
Validation loss: 2.4643752413040185

Epoch: 5| Step: 4
Training loss: 2.399820631000184
Validation loss: 2.4659961176982463

Epoch: 5| Step: 5
Training loss: 2.400053591924586
Validation loss: 2.4671074155050783

Epoch: 5| Step: 6
Training loss: 2.870395788355941
Validation loss: 2.467380642875507

Epoch: 5| Step: 7
Training loss: 2.5884482189685567
Validation loss: 2.4751390985614226

Epoch: 5| Step: 8
Training loss: 2.67078024761351
Validation loss: 2.467047804682024

Epoch: 5| Step: 9
Training loss: 2.1353538938150405
Validation loss: 2.468766558466883

Epoch: 5| Step: 10
Training loss: 2.668578763734662
Validation loss: 2.4700991207638543

Epoch: 5| Step: 11
Training loss: 3.833280369489464
Validation loss: 2.466521438278758

Epoch: 197| Step: 0
Training loss: 2.067383389119251
Validation loss: 2.468283609204518

Epoch: 5| Step: 1
Training loss: 2.989361975224964
Validation loss: 2.470758064071329

Epoch: 5| Step: 2
Training loss: 2.3033243576993754
Validation loss: 2.4710218301912836

Epoch: 5| Step: 3
Training loss: 2.4469224791225916
Validation loss: 2.487756291481915

Epoch: 5| Step: 4
Training loss: 2.64410568261555
Validation loss: 2.4642486418100176

Epoch: 5| Step: 5
Training loss: 2.686964114677465
Validation loss: 2.477786859578603

Epoch: 5| Step: 6
Training loss: 2.554620304448852
Validation loss: 2.4742030527981846

Epoch: 5| Step: 7
Training loss: 2.2296590053392316
Validation loss: 2.4608234560744906

Epoch: 5| Step: 8
Training loss: 2.386000404952623
Validation loss: 2.4594986640121057

Epoch: 5| Step: 9
Training loss: 2.314581063512953
Validation loss: 2.4616097758151727

Epoch: 5| Step: 10
Training loss: 2.561718333047389
Validation loss: 2.4616200060760107

Epoch: 5| Step: 11
Training loss: 3.034236420001879
Validation loss: 2.461745437320838

Epoch: 198| Step: 0
Training loss: 1.8616674700296707
Validation loss: 2.4631272156208626

Epoch: 5| Step: 1
Training loss: 3.042445636097447
Validation loss: 2.4795806736761703

Epoch: 5| Step: 2
Training loss: 2.9679522596977073
Validation loss: 2.4819044468801987

Epoch: 5| Step: 3
Training loss: 2.17305959327181
Validation loss: 2.475603401277981

Epoch: 5| Step: 4
Training loss: 2.62458452842319
Validation loss: 2.483650441746169

Epoch: 5| Step: 5
Training loss: 2.262579719445687
Validation loss: 2.477613737419161

Epoch: 5| Step: 6
Training loss: 2.209707720144358
Validation loss: 2.4714122011038637

Epoch: 5| Step: 7
Training loss: 2.5516831583810284
Validation loss: 2.469772931728689

Epoch: 5| Step: 8
Training loss: 2.3452835152377
Validation loss: 2.4718422536694376

Epoch: 5| Step: 9
Training loss: 2.4445246685716073
Validation loss: 2.469412429076628

Epoch: 5| Step: 10
Training loss: 2.8320874859718304
Validation loss: 2.476090491528563

Epoch: 5| Step: 11
Training loss: 2.5334963779517676
Validation loss: 2.4733665655346417

Epoch: 199| Step: 0
Training loss: 2.2764160988886766
Validation loss: 2.475105763754024

Epoch: 5| Step: 1
Training loss: 2.4561050682891867
Validation loss: 2.4726222810827516

Epoch: 5| Step: 2
Training loss: 2.4113776328725187
Validation loss: 2.4872630864331207

Epoch: 5| Step: 3
Training loss: 3.065150456928403
Validation loss: 2.4736499527253164

Epoch: 5| Step: 4
Training loss: 2.7520014675380433
Validation loss: 2.4818032246917907

Epoch: 5| Step: 5
Training loss: 2.4478050909924933
Validation loss: 2.470047778640452

Epoch: 5| Step: 6
Training loss: 2.154451477092203
Validation loss: 2.474365202256516

Epoch: 5| Step: 7
Training loss: 2.431724356929357
Validation loss: 2.466344719949903

Epoch: 5| Step: 8
Training loss: 2.1552094975931286
Validation loss: 2.4767804736814942

Epoch: 5| Step: 9
Training loss: 2.7913035730737787
Validation loss: 2.472238470201522

Epoch: 5| Step: 10
Training loss: 2.412588317519494
Validation loss: 2.475497336623577

Epoch: 5| Step: 11
Training loss: 2.3103904380949185
Validation loss: 2.4744502023650274

Epoch: 200| Step: 0
Training loss: 2.3890521291903135
Validation loss: 2.4726251215529667

Epoch: 5| Step: 1
Training loss: 2.5172921100382335
Validation loss: 2.478011568767779

Epoch: 5| Step: 2
Training loss: 2.114396849679206
Validation loss: 2.4763822239224904

Epoch: 5| Step: 3
Training loss: 2.623436780228553
Validation loss: 2.481222747986183

Epoch: 5| Step: 4
Training loss: 1.9072860028779879
Validation loss: 2.475502240473448

Epoch: 5| Step: 5
Training loss: 2.454366479154114
Validation loss: 2.4764639035563385

Epoch: 5| Step: 6
Training loss: 2.8814992006649276
Validation loss: 2.4704443071024045

Epoch: 5| Step: 7
Training loss: 3.2605106880517067
Validation loss: 2.483887486638617

Epoch: 5| Step: 8
Training loss: 2.5752691924484745
Validation loss: 2.4755776810868904

Epoch: 5| Step: 9
Training loss: 2.054063709559883
Validation loss: 2.471661556945564

Epoch: 5| Step: 10
Training loss: 2.122450926520055
Validation loss: 2.4744779114802657

Epoch: 5| Step: 11
Training loss: 2.7592330602340347
Validation loss: 2.4722998886076692

Epoch: 201| Step: 0
Training loss: 2.4150436037285448
Validation loss: 2.475047758393016

Epoch: 5| Step: 1
Training loss: 2.5631315802094594
Validation loss: 2.475904696255776

Epoch: 5| Step: 2
Training loss: 2.495984285488545
Validation loss: 2.4759271370271545

Epoch: 5| Step: 3
Training loss: 2.5498269415081145
Validation loss: 2.471572300911654

Epoch: 5| Step: 4
Training loss: 2.632085592286944
Validation loss: 2.479322634260078

Epoch: 5| Step: 5
Training loss: 2.833698660541534
Validation loss: 2.483165334506294

Epoch: 5| Step: 6
Training loss: 2.24320466366445
Validation loss: 2.4764235986050607

Epoch: 5| Step: 7
Training loss: 2.8359253938274662
Validation loss: 2.472494199403362

Epoch: 5| Step: 8
Training loss: 1.8217446256024072
Validation loss: 2.4663662367192947

Epoch: 5| Step: 9
Training loss: 2.414589734819126
Validation loss: 2.472039063832757

Epoch: 5| Step: 10
Training loss: 2.520401867809248
Validation loss: 2.473013154557501

Epoch: 5| Step: 11
Training loss: 1.1120382765247407
Validation loss: 2.470006916529383

Epoch: 202| Step: 0
Training loss: 2.3012314568082792
Validation loss: 2.4686008239293185

Epoch: 5| Step: 1
Training loss: 2.642960097174444
Validation loss: 2.4738286489661525

Epoch: 5| Step: 2
Training loss: 2.1423900594735668
Validation loss: 2.470086275278638

Epoch: 5| Step: 3
Training loss: 2.3204380605100354
Validation loss: 2.4678983426534162

Epoch: 5| Step: 4
Training loss: 2.99585405606958
Validation loss: 2.4738294882434033

Epoch: 5| Step: 5
Training loss: 2.696376336276573
Validation loss: 2.4744543736063576

Epoch: 5| Step: 6
Training loss: 2.4746689160777975
Validation loss: 2.4614238278659264

Epoch: 5| Step: 7
Training loss: 2.6099449037897084
Validation loss: 2.4683081738546098

Epoch: 5| Step: 8
Training loss: 2.4734264457874926
Validation loss: 2.474068441784985

Epoch: 5| Step: 9
Training loss: 2.1150271947388437
Validation loss: 2.482793096422925

Epoch: 5| Step: 10
Training loss: 2.5710542762158015
Validation loss: 2.4864283858883502

Epoch: 5| Step: 11
Training loss: 1.5961492094692025
Validation loss: 2.486482546022166

Epoch: 203| Step: 0
Training loss: 2.702426180612102
Validation loss: 2.5096057568803998

Epoch: 5| Step: 1
Training loss: 2.686135411363536
Validation loss: 2.512007946334913

Epoch: 5| Step: 2
Training loss: 2.438305257173647
Validation loss: 2.5017665582045807

Epoch: 5| Step: 3
Training loss: 2.589878548090598
Validation loss: 2.4901177971174357

Epoch: 5| Step: 4
Training loss: 2.2540156240387166
Validation loss: 2.4849155405787977

Epoch: 5| Step: 5
Training loss: 2.0979315152695595
Validation loss: 2.476658330882366

Epoch: 5| Step: 6
Training loss: 2.9548962644903334
Validation loss: 2.46852318812325

Epoch: 5| Step: 7
Training loss: 2.3165328456000043
Validation loss: 2.4694373988599456

Epoch: 5| Step: 8
Training loss: 2.5522559490345644
Validation loss: 2.4778307927297107

Epoch: 5| Step: 9
Training loss: 2.066643915768984
Validation loss: 2.4729129523421056

Epoch: 5| Step: 10
Training loss: 2.464950728475325
Validation loss: 2.473834150443426

Epoch: 5| Step: 11
Training loss: 3.105006537438235
Validation loss: 2.4716965197378507

Epoch: 204| Step: 0
Training loss: 2.297338944893019
Validation loss: 2.4765530775594917

Epoch: 5| Step: 1
Training loss: 2.6127664603548055
Validation loss: 2.4751058841623

Epoch: 5| Step: 2
Training loss: 2.6691961411361205
Validation loss: 2.4706917301362523

Epoch: 5| Step: 3
Training loss: 2.29566788905184
Validation loss: 2.480195578604154

Epoch: 5| Step: 4
Training loss: 2.5733611511874734
Validation loss: 2.472750163291098

Epoch: 5| Step: 5
Training loss: 2.430668084097969
Validation loss: 2.4778905771281567

Epoch: 5| Step: 6
Training loss: 2.4909945416048047
Validation loss: 2.4792436913671634

Epoch: 5| Step: 7
Training loss: 2.5686160347340397
Validation loss: 2.4804068850514454

Epoch: 5| Step: 8
Training loss: 2.227069890618383
Validation loss: 2.4814720948030167

Epoch: 5| Step: 9
Training loss: 2.6091735213839575
Validation loss: 2.470737594746014

Epoch: 5| Step: 10
Training loss: 2.422136354188184
Validation loss: 2.480178896171087

Epoch: 5| Step: 11
Training loss: 2.1013741674731876
Validation loss: 2.4789358934549015

Epoch: 205| Step: 0
Training loss: 2.3760175031152158
Validation loss: 2.475514672612323

Epoch: 5| Step: 1
Training loss: 2.426823930971766
Validation loss: 2.4850845803067

Epoch: 5| Step: 2
Training loss: 2.2421787806750104
Validation loss: 2.489043058777241

Epoch: 5| Step: 3
Training loss: 2.7732046110131647
Validation loss: 2.4834131862188924

Epoch: 5| Step: 4
Training loss: 2.4983031236155155
Validation loss: 2.485811861652872

Epoch: 5| Step: 5
Training loss: 2.5526945874266365
Validation loss: 2.491249812914581

Epoch: 5| Step: 6
Training loss: 2.019602200647108
Validation loss: 2.4897375870378715

Epoch: 5| Step: 7
Training loss: 2.4105250047115967
Validation loss: 2.4787766940612355

Epoch: 5| Step: 8
Training loss: 2.1339175536970876
Validation loss: 2.488891079689757

Epoch: 5| Step: 9
Training loss: 2.893731834404038
Validation loss: 2.4745788451903055

Epoch: 5| Step: 10
Training loss: 2.4745023323398034
Validation loss: 2.479553594501174

Epoch: 5| Step: 11
Training loss: 3.052623158562707
Validation loss: 2.4792273070561825

Epoch: 206| Step: 0
Training loss: 2.2205258636720653
Validation loss: 2.4722266645129674

Epoch: 5| Step: 1
Training loss: 2.3869092400135905
Validation loss: 2.4745018626329585

Epoch: 5| Step: 2
Training loss: 2.4264728831724036
Validation loss: 2.47262922757345

Epoch: 5| Step: 3
Training loss: 2.1445609335590823
Validation loss: 2.484640031349229

Epoch: 5| Step: 4
Training loss: 2.4377022683755216
Validation loss: 2.474040969003922

Epoch: 5| Step: 5
Training loss: 2.9333990161940138
Validation loss: 2.476187231310397

Epoch: 5| Step: 6
Training loss: 2.082267017864256
Validation loss: 2.4804350442673866

Epoch: 5| Step: 7
Training loss: 2.6825413757432455
Validation loss: 2.4872479851056633

Epoch: 5| Step: 8
Training loss: 2.8096673900286366
Validation loss: 2.4875641472690737

Epoch: 5| Step: 9
Training loss: 2.9383141221406355
Validation loss: 2.485472982322316

Epoch: 5| Step: 10
Training loss: 2.126473084531248
Validation loss: 2.484884141937003

Epoch: 5| Step: 11
Training loss: 1.5796650840610214
Validation loss: 2.489061134563103

Epoch: 207| Step: 0
Training loss: 2.605572425346647
Validation loss: 2.482291337489593

Epoch: 5| Step: 1
Training loss: 2.4032670394529907
Validation loss: 2.4859369274356933

Epoch: 5| Step: 2
Training loss: 2.407839361656115
Validation loss: 2.4815650739897843

Epoch: 5| Step: 3
Training loss: 2.441719315865004
Validation loss: 2.473922935366448

Epoch: 5| Step: 4
Training loss: 2.1269162457704387
Validation loss: 2.48146159409295

Epoch: 5| Step: 5
Training loss: 2.8199017931023236
Validation loss: 2.4791147296070686

Epoch: 5| Step: 6
Training loss: 2.164845128852243
Validation loss: 2.4790209732735473

Epoch: 5| Step: 7
Training loss: 2.805081055637917
Validation loss: 2.4671675000176334

Epoch: 5| Step: 8
Training loss: 2.6338712561331232
Validation loss: 2.475606487121163

Epoch: 5| Step: 9
Training loss: 2.000103590189888
Validation loss: 2.4792483493961894

Epoch: 5| Step: 10
Training loss: 2.571733632611611
Validation loss: 2.474395341255591

Epoch: 5| Step: 11
Training loss: 2.739237097459552
Validation loss: 2.48239797625179

Epoch: 208| Step: 0
Training loss: 2.295044980906907
Validation loss: 2.479585345094412

Epoch: 5| Step: 1
Training loss: 2.8644560814538815
Validation loss: 2.4985440584369187

Epoch: 5| Step: 2
Training loss: 1.916559700123365
Validation loss: 2.4836338625157848

Epoch: 5| Step: 3
Training loss: 2.544078578863021
Validation loss: 2.4817341537940623

Epoch: 5| Step: 4
Training loss: 2.43145648305029
Validation loss: 2.480263328556678

Epoch: 5| Step: 5
Training loss: 2.429630389262979
Validation loss: 2.4857044421622505

Epoch: 5| Step: 6
Training loss: 2.87508342456026
Validation loss: 2.483665804934204

Epoch: 5| Step: 7
Training loss: 2.1742466115040213
Validation loss: 2.4857779765980244

Epoch: 5| Step: 8
Training loss: 2.141592210991895
Validation loss: 2.4878567024530085

Epoch: 5| Step: 9
Training loss: 2.7239825002693543
Validation loss: 2.4866639315289274

Epoch: 5| Step: 10
Training loss: 2.4728973897832334
Validation loss: 2.4907250134192003

Epoch: 5| Step: 11
Training loss: 2.5947298703874284
Validation loss: 2.486729959248327

Epoch: 209| Step: 0
Training loss: 2.847844791319277
Validation loss: 2.4864774680603285

Epoch: 5| Step: 1
Training loss: 2.5106312724674456
Validation loss: 2.5084501151108314

Epoch: 5| Step: 2
Training loss: 2.4885625515542196
Validation loss: 2.512414447314741

Epoch: 5| Step: 3
Training loss: 2.7199732341571394
Validation loss: 2.5250292777891454

Epoch: 5| Step: 4
Training loss: 2.596899579203823
Validation loss: 2.4991103615947186

Epoch: 5| Step: 5
Training loss: 2.344523798045055
Validation loss: 2.4905531854937575

Epoch: 5| Step: 6
Training loss: 2.374700627783266
Validation loss: 2.4773969357645047

Epoch: 5| Step: 7
Training loss: 2.25357090192378
Validation loss: 2.4677981420824437

Epoch: 5| Step: 8
Training loss: 2.6790509148999884
Validation loss: 2.480572067071465

Epoch: 5| Step: 9
Training loss: 2.293794707400487
Validation loss: 2.4804215193930146

Epoch: 5| Step: 10
Training loss: 2.0425193978069047
Validation loss: 2.470283265557125

Epoch: 5| Step: 11
Training loss: 3.150647166544391
Validation loss: 2.477644606725277

Epoch: 210| Step: 0
Training loss: 2.890956055525235
Validation loss: 2.467725621736275

Epoch: 5| Step: 1
Training loss: 2.633645489053475
Validation loss: 2.4669565595628753

Epoch: 5| Step: 2
Training loss: 2.328933063545953
Validation loss: 2.472671179301996

Epoch: 5| Step: 3
Training loss: 2.044325660569671
Validation loss: 2.4784685776225506

Epoch: 5| Step: 4
Training loss: 2.714530915822574
Validation loss: 2.4800459173461147

Epoch: 5| Step: 5
Training loss: 1.9071913099180566
Validation loss: 2.4841104042654454

Epoch: 5| Step: 6
Training loss: 2.4843865160405265
Validation loss: 2.4994035724629318

Epoch: 5| Step: 7
Training loss: 1.9131682506259733
Validation loss: 2.5081035290656253

Epoch: 5| Step: 8
Training loss: 3.0362963014341235
Validation loss: 2.4974138632485827

Epoch: 5| Step: 9
Training loss: 2.5404461186533767
Validation loss: 2.4979365774087054

Epoch: 5| Step: 10
Training loss: 2.2213392596324133
Validation loss: 2.512920373018779

Epoch: 5| Step: 11
Training loss: 3.2260313174104627
Validation loss: 2.487885320394959

Epoch: 211| Step: 0
Training loss: 2.3117434320811348
Validation loss: 2.4974826854656764

Epoch: 5| Step: 1
Training loss: 2.8529216714797188
Validation loss: 2.4892339235109553

Epoch: 5| Step: 2
Training loss: 2.1780476845109287
Validation loss: 2.4896100546920445

Epoch: 5| Step: 3
Training loss: 2.661603044033345
Validation loss: 2.4917097939285484

Epoch: 5| Step: 4
Training loss: 2.306051594126408
Validation loss: 2.4875550140993825

Epoch: 5| Step: 5
Training loss: 1.9475075467199736
Validation loss: 2.4889772281220632

Epoch: 5| Step: 6
Training loss: 2.737037365285857
Validation loss: 2.4888129192799084

Epoch: 5| Step: 7
Training loss: 2.8050722161174884
Validation loss: 2.47555678812556

Epoch: 5| Step: 8
Training loss: 1.8873447935447458
Validation loss: 2.486144359476997

Epoch: 5| Step: 9
Training loss: 2.5119559500835025
Validation loss: 2.4920616696120934

Epoch: 5| Step: 10
Training loss: 2.1930747794410053
Validation loss: 2.483479064360614

Epoch: 5| Step: 11
Training loss: 3.717846800809516
Validation loss: 2.4909083791905062

Epoch: 212| Step: 0
Training loss: 2.431981907683134
Validation loss: 2.4939334258562718

Epoch: 5| Step: 1
Training loss: 2.4336995550334315
Validation loss: 2.5118240089173405

Epoch: 5| Step: 2
Training loss: 2.7292329231742
Validation loss: 2.5297865581379715

Epoch: 5| Step: 3
Training loss: 2.8986026686008417
Validation loss: 2.5091075266943568

Epoch: 5| Step: 4
Training loss: 2.0172796037775464
Validation loss: 2.4960954613398663

Epoch: 5| Step: 5
Training loss: 2.6909205824843276
Validation loss: 2.5226656281442734

Epoch: 5| Step: 6
Training loss: 2.5177937512210455
Validation loss: 2.497879551624238

Epoch: 5| Step: 7
Training loss: 1.620305101603996
Validation loss: 2.502995175008356

Epoch: 5| Step: 8
Training loss: 2.4960392093818817
Validation loss: 2.4961808915267065

Epoch: 5| Step: 9
Training loss: 2.4464836850287925
Validation loss: 2.5045444232691727

Epoch: 5| Step: 10
Training loss: 2.3735634323975305
Validation loss: 2.4864594214354043

Epoch: 5| Step: 11
Training loss: 2.1925639801955557
Validation loss: 2.495521639039982

Epoch: 213| Step: 0
Training loss: 2.7729287983900996
Validation loss: 2.4872999067676194

Epoch: 5| Step: 1
Training loss: 2.158459954493617
Validation loss: 2.4887454459766443

Epoch: 5| Step: 2
Training loss: 2.5427079074290937
Validation loss: 2.49371954485813

Epoch: 5| Step: 3
Training loss: 2.5093482713237822
Validation loss: 2.485418232621251

Epoch: 5| Step: 4
Training loss: 2.1633043854848104
Validation loss: 2.4966443349563576

Epoch: 5| Step: 5
Training loss: 2.07799741883985
Validation loss: 2.5035533725803143

Epoch: 5| Step: 6
Training loss: 2.4973386904504076
Validation loss: 2.502400584810594

Epoch: 5| Step: 7
Training loss: 2.085206435890591
Validation loss: 2.4971566064131614

Epoch: 5| Step: 8
Training loss: 2.896762086052446
Validation loss: 2.504976929401649

Epoch: 5| Step: 9
Training loss: 2.5743034013134816
Validation loss: 2.490481618936569

Epoch: 5| Step: 10
Training loss: 2.584075626252762
Validation loss: 2.4888080935465346

Epoch: 5| Step: 11
Training loss: 1.8314356374551155
Validation loss: 2.4854039394652876

Epoch: 214| Step: 0
Training loss: 2.0064463439124793
Validation loss: 2.484868666346377

Epoch: 5| Step: 1
Training loss: 2.450250678959194
Validation loss: 2.489042811326844

Epoch: 5| Step: 2
Training loss: 2.612545440132633
Validation loss: 2.4947269062298942

Epoch: 5| Step: 3
Training loss: 2.068044665549682
Validation loss: 2.489237291768533

Epoch: 5| Step: 4
Training loss: 2.109574598123135
Validation loss: 2.5053998228924086

Epoch: 5| Step: 5
Training loss: 2.4886215671908616
Validation loss: 2.4956174305451464

Epoch: 5| Step: 6
Training loss: 2.169896054393237
Validation loss: 2.501947320062324

Epoch: 5| Step: 7
Training loss: 3.089098892422042
Validation loss: 2.500582964797387

Epoch: 5| Step: 8
Training loss: 2.166401504527912
Validation loss: 2.489201070788071

Epoch: 5| Step: 9
Training loss: 2.964764298692521
Validation loss: 2.4951750209249677

Epoch: 5| Step: 10
Training loss: 2.6758323942990843
Validation loss: 2.4897630452423565

Epoch: 5| Step: 11
Training loss: 1.6189142858141787
Validation loss: 2.4878561114832483

Epoch: 215| Step: 0
Training loss: 2.2581459511957713
Validation loss: 2.488211424689757

Epoch: 5| Step: 1
Training loss: 2.5757404744163632
Validation loss: 2.486020101329405

Epoch: 5| Step: 2
Training loss: 1.9740114901052697
Validation loss: 2.4925623724405352

Epoch: 5| Step: 3
Training loss: 2.041074264633102
Validation loss: 2.481440636576501

Epoch: 5| Step: 4
Training loss: 2.7033945291023413
Validation loss: 2.500925631825654

Epoch: 5| Step: 5
Training loss: 2.2348326101067464
Validation loss: 2.4890404405911473

Epoch: 5| Step: 6
Training loss: 2.352681752236611
Validation loss: 2.4934143108165

Epoch: 5| Step: 7
Training loss: 2.997701400086745
Validation loss: 2.496905768359663

Epoch: 5| Step: 8
Training loss: 2.5762276806112094
Validation loss: 2.5129875589384834

Epoch: 5| Step: 9
Training loss: 2.423951175833772
Validation loss: 2.5128086863625096

Epoch: 5| Step: 10
Training loss: 2.6011960799693195
Validation loss: 2.5187273068663907

Epoch: 5| Step: 11
Training loss: 2.7252492283231327
Validation loss: 2.5324551849002557

Epoch: 216| Step: 0
Training loss: 2.2711974968980067
Validation loss: 2.5275792951059115

Epoch: 5| Step: 1
Training loss: 2.2056843926855714
Validation loss: 2.5108653033040444

Epoch: 5| Step: 2
Training loss: 2.9458633838579447
Validation loss: 2.501379911743281

Epoch: 5| Step: 3
Training loss: 2.2100768014672676
Validation loss: 2.490390396715702

Epoch: 5| Step: 4
Training loss: 2.6675313699981706
Validation loss: 2.4819693324204986

Epoch: 5| Step: 5
Training loss: 2.5040957279492906
Validation loss: 2.474939683057189

Epoch: 5| Step: 6
Training loss: 2.338099879028166
Validation loss: 2.4780575183854032

Epoch: 5| Step: 7
Training loss: 3.1506462584695702
Validation loss: 2.477863816250983

Epoch: 5| Step: 8
Training loss: 2.431425104969647
Validation loss: 2.482125249308842

Epoch: 5| Step: 9
Training loss: 2.06405014970017
Validation loss: 2.48117752561894

Epoch: 5| Step: 10
Training loss: 2.2105264989355677
Validation loss: 2.4957446320320726

Epoch: 5| Step: 11
Training loss: 2.421676430714249
Validation loss: 2.48855268753526

Epoch: 217| Step: 0
Training loss: 2.3326746374173775
Validation loss: 2.497244639720963

Epoch: 5| Step: 1
Training loss: 2.8339507234390755
Validation loss: 2.4999308218921517

Epoch: 5| Step: 2
Training loss: 2.463561968622301
Validation loss: 2.5044481203927034

Epoch: 5| Step: 3
Training loss: 2.1797813477360495
Validation loss: 2.498168427366092

Epoch: 5| Step: 4
Training loss: 2.388863806136976
Validation loss: 2.5126748764327878

Epoch: 5| Step: 5
Training loss: 2.1870579954183853
Validation loss: 2.5155300493664035

Epoch: 5| Step: 6
Training loss: 2.983701779791335
Validation loss: 2.5096363633014738

Epoch: 5| Step: 7
Training loss: 2.2962911473607317
Validation loss: 2.516330797686175

Epoch: 5| Step: 8
Training loss: 2.4281379689541644
Validation loss: 2.512937093074131

Epoch: 5| Step: 9
Training loss: 2.279323652906113
Validation loss: 2.499555985439497

Epoch: 5| Step: 10
Training loss: 2.4109153603150966
Validation loss: 2.498477201800421

Epoch: 5| Step: 11
Training loss: 1.4681756540185702
Validation loss: 2.4964198027387328

Epoch: 218| Step: 0
Training loss: 2.330668039781237
Validation loss: 2.487334661723767

Epoch: 5| Step: 1
Training loss: 1.8706201897790957
Validation loss: 2.4876775243725726

Epoch: 5| Step: 2
Training loss: 2.617203806356618
Validation loss: 2.4877649646963573

Epoch: 5| Step: 3
Training loss: 2.5450119974569287
Validation loss: 2.4862076739401484

Epoch: 5| Step: 4
Training loss: 2.7137759077679546
Validation loss: 2.4906620431312714

Epoch: 5| Step: 5
Training loss: 2.8314487884325428
Validation loss: 2.490233952142019

Epoch: 5| Step: 6
Training loss: 2.266472703918722
Validation loss: 2.491934565162383

Epoch: 5| Step: 7
Training loss: 2.244059243316051
Validation loss: 2.4873900761429786

Epoch: 5| Step: 8
Training loss: 2.4024283045333217
Validation loss: 2.5016219798190105

Epoch: 5| Step: 9
Training loss: 2.6442643767668694
Validation loss: 2.501710735553848

Epoch: 5| Step: 10
Training loss: 2.663537474325494
Validation loss: 2.498430395126181

Epoch: 5| Step: 11
Training loss: 1.392867091775652
Validation loss: 2.5084806445472925

Epoch: 219| Step: 0
Training loss: 2.4547302436628007
Validation loss: 2.515622812274116

Epoch: 5| Step: 1
Training loss: 2.510357002615089
Validation loss: 2.5111524063053654

Epoch: 5| Step: 2
Training loss: 2.5377099763030695
Validation loss: 2.4921209153036976

Epoch: 5| Step: 3
Training loss: 2.344501629152584
Validation loss: 2.4973808874187537

Epoch: 5| Step: 4
Training loss: 2.6942045284135485
Validation loss: 2.4901291050819427

Epoch: 5| Step: 5
Training loss: 2.413953661394085
Validation loss: 2.4821249371326406

Epoch: 5| Step: 6
Training loss: 2.2161301740428567
Validation loss: 2.4784531060628803

Epoch: 5| Step: 7
Training loss: 2.5904075503688713
Validation loss: 2.479575681739232

Epoch: 5| Step: 8
Training loss: 2.361003086635797
Validation loss: 2.4728309244226123

Epoch: 5| Step: 9
Training loss: 2.5357758362973377
Validation loss: 2.47738123295663

Epoch: 5| Step: 10
Training loss: 2.6299887889724642
Validation loss: 2.4786608818502094

Epoch: 5| Step: 11
Training loss: 1.5076048713000132
Validation loss: 2.4812595218312397

Epoch: 220| Step: 0
Training loss: 2.343762613898348
Validation loss: 2.4865593654102556

Epoch: 5| Step: 1
Training loss: 2.1702263152420063
Validation loss: 2.5030409517437104

Epoch: 5| Step: 2
Training loss: 2.241426345346862
Validation loss: 2.5114091095965154

Epoch: 5| Step: 3
Training loss: 2.6684965669961183
Validation loss: 2.525887118196587

Epoch: 5| Step: 4
Training loss: 2.7400497406948534
Validation loss: 2.527915382890033

Epoch: 5| Step: 5
Training loss: 2.832130756603155
Validation loss: 2.5391324429782047

Epoch: 5| Step: 6
Training loss: 2.1752087372335347
Validation loss: 2.52683509216447

Epoch: 5| Step: 7
Training loss: 2.4521399786107088
Validation loss: 2.5201235762450627

Epoch: 5| Step: 8
Training loss: 2.3993592122088403
Validation loss: 2.5098457689761426

Epoch: 5| Step: 9
Training loss: 2.4260544676802636
Validation loss: 2.505925876114607

Epoch: 5| Step: 10
Training loss: 2.0641003959694193
Validation loss: 2.5024142568712726

Epoch: 5| Step: 11
Training loss: 2.850434882463558
Validation loss: 2.507084959823269

Epoch: 221| Step: 0
Training loss: 2.0219902842936293
Validation loss: 2.4932518761910596

Epoch: 5| Step: 1
Training loss: 2.067593037219804
Validation loss: 2.4933954697552774

Epoch: 5| Step: 2
Training loss: 2.3007433229179783
Validation loss: 2.4829087639038625

Epoch: 5| Step: 3
Training loss: 2.222902629585123
Validation loss: 2.481880058828421

Epoch: 5| Step: 4
Training loss: 2.2231427617257675
Validation loss: 2.483430466949769

Epoch: 5| Step: 5
Training loss: 2.7584813849446994
Validation loss: 2.4752988509649576

Epoch: 5| Step: 6
Training loss: 2.970484979509031
Validation loss: 2.4730578794923943

Epoch: 5| Step: 7
Training loss: 2.4783638260621657
Validation loss: 2.473657326037817

Epoch: 5| Step: 8
Training loss: 2.8071925629985546
Validation loss: 2.4759446264842717

Epoch: 5| Step: 9
Training loss: 3.0145359741230866
Validation loss: 2.4707274022373418

Epoch: 5| Step: 10
Training loss: 2.1247864784227
Validation loss: 2.4652329574385043

Epoch: 5| Step: 11
Training loss: 2.00320404420481
Validation loss: 2.4717738549219654

Epoch: 222| Step: 0
Training loss: 2.3865667066827982
Validation loss: 2.497129598487385

Epoch: 5| Step: 1
Training loss: 2.3560923799366207
Validation loss: 2.5233739150060357

Epoch: 5| Step: 2
Training loss: 2.4851507739067005
Validation loss: 2.5103340148510345

Epoch: 5| Step: 3
Training loss: 2.3818568580274864
Validation loss: 2.532148217537534

Epoch: 5| Step: 4
Training loss: 2.4953094348637834
Validation loss: 2.512531554401952

Epoch: 5| Step: 5
Training loss: 2.266138268571164
Validation loss: 2.489351957468165

Epoch: 5| Step: 6
Training loss: 2.3821461230411067
Validation loss: 2.489945203160304

Epoch: 5| Step: 7
Training loss: 2.1684071690359072
Validation loss: 2.4863541954573574

Epoch: 5| Step: 8
Training loss: 2.71917256546277
Validation loss: 2.485017689361141

Epoch: 5| Step: 9
Training loss: 2.550725168076059
Validation loss: 2.480165558154683

Epoch: 5| Step: 10
Training loss: 2.9642603605568216
Validation loss: 2.4906200693672798

Epoch: 5| Step: 11
Training loss: 2.2032376524348636
Validation loss: 2.486400785980137

Epoch: 223| Step: 0
Training loss: 2.2628668471881035
Validation loss: 2.482964433134932

Epoch: 5| Step: 1
Training loss: 2.7171541989585295
Validation loss: 2.487952146220203

Epoch: 5| Step: 2
Training loss: 2.207443549880591
Validation loss: 2.4750219059947653

Epoch: 5| Step: 3
Training loss: 2.6489698387033145
Validation loss: 2.483715733639093

Epoch: 5| Step: 4
Training loss: 2.400636342247048
Validation loss: 2.4964447789520743

Epoch: 5| Step: 5
Training loss: 2.76444102661021
Validation loss: 2.4904352962245353

Epoch: 5| Step: 6
Training loss: 2.3337117183510254
Validation loss: 2.5088585863370785

Epoch: 5| Step: 7
Training loss: 2.249750547356215
Validation loss: 2.5094490059358927

Epoch: 5| Step: 8
Training loss: 2.2917198406177093
Validation loss: 2.509707945718735

Epoch: 5| Step: 9
Training loss: 2.31449247560166
Validation loss: 2.5195605214707917

Epoch: 5| Step: 10
Training loss: 2.7845728879880425
Validation loss: 2.513844063015548

Epoch: 5| Step: 11
Training loss: 1.7680431449769545
Validation loss: 2.5281549338009555

Epoch: 224| Step: 0
Training loss: 1.8170329007669295
Validation loss: 2.4999000926717754

Epoch: 5| Step: 1
Training loss: 3.1022422679786628
Validation loss: 2.5166401285915434

Epoch: 5| Step: 2
Training loss: 2.92674624492
Validation loss: 2.506834530703055

Epoch: 5| Step: 3
Training loss: 2.8002222586021275
Validation loss: 2.5133634416071557

Epoch: 5| Step: 4
Training loss: 2.163030385150084
Validation loss: 2.5058073086481873

Epoch: 5| Step: 5
Training loss: 2.2758839870511567
Validation loss: 2.4879564924720166

Epoch: 5| Step: 6
Training loss: 2.228623891569244
Validation loss: 2.483599995743941

Epoch: 5| Step: 7
Training loss: 2.4190487029087855
Validation loss: 2.486139434662584

Epoch: 5| Step: 8
Training loss: 2.1501007854880543
Validation loss: 2.478915455589991

Epoch: 5| Step: 9
Training loss: 2.212107857473433
Validation loss: 2.4844232870403617

Epoch: 5| Step: 10
Training loss: 2.2952058916672473
Validation loss: 2.474590727974944

Epoch: 5| Step: 11
Training loss: 2.8428059782146495
Validation loss: 2.476069564779857

Epoch: 225| Step: 0
Training loss: 2.0393265008844152
Validation loss: 2.49156849347723

Epoch: 5| Step: 1
Training loss: 2.135234645125939
Validation loss: 2.479360213591828

Epoch: 5| Step: 2
Training loss: 2.583148477975112
Validation loss: 2.4765156200957867

Epoch: 5| Step: 3
Training loss: 2.355218826623751
Validation loss: 2.4815741651544525

Epoch: 5| Step: 4
Training loss: 2.5268069232202697
Validation loss: 2.485692360725966

Epoch: 5| Step: 5
Training loss: 2.8027767377569384
Validation loss: 2.4834590678952333

Epoch: 5| Step: 6
Training loss: 2.483286109151006
Validation loss: 2.4966034784159903

Epoch: 5| Step: 7
Training loss: 1.7452218355759517
Validation loss: 2.5058376780101113

Epoch: 5| Step: 8
Training loss: 2.6721008383802456
Validation loss: 2.5078981806774134

Epoch: 5| Step: 9
Training loss: 2.9390920017998665
Validation loss: 2.5118342521850914

Epoch: 5| Step: 10
Training loss: 2.4084638839589174
Validation loss: 2.5240332743599563

Epoch: 5| Step: 11
Training loss: 1.9407516389029327
Validation loss: 2.533981866287927

Epoch: 226| Step: 0
Training loss: 2.307457762194208
Validation loss: 2.5175826469954905

Epoch: 5| Step: 1
Training loss: 3.0375943204576
Validation loss: 2.5185284297028425

Epoch: 5| Step: 2
Training loss: 2.1915730295617775
Validation loss: 2.504003748034505

Epoch: 5| Step: 3
Training loss: 2.3577032166289795
Validation loss: 2.514506334159915

Epoch: 5| Step: 4
Training loss: 2.813763821947948
Validation loss: 2.492190776571673

Epoch: 5| Step: 5
Training loss: 2.4503819382019625
Validation loss: 2.490752527521098

Epoch: 5| Step: 6
Training loss: 2.886555214096609
Validation loss: 2.496436515917995

Epoch: 5| Step: 7
Training loss: 2.3896619066015488
Validation loss: 2.493062614093258

Epoch: 5| Step: 8
Training loss: 1.980178841885149
Validation loss: 2.4948685155724664

Epoch: 5| Step: 9
Training loss: 2.23124197736735
Validation loss: 2.504865465606053

Epoch: 5| Step: 10
Training loss: 2.1112846490016706
Validation loss: 2.5112368179172786

Epoch: 5| Step: 11
Training loss: 1.4807077179745285
Validation loss: 2.5106855040098646

Epoch: 227| Step: 0
Training loss: 2.7413251341382967
Validation loss: 2.5169222865064724

Epoch: 5| Step: 1
Training loss: 2.494544848588101
Validation loss: 2.528454304181448

Epoch: 5| Step: 2
Training loss: 3.008924878010215
Validation loss: 2.5167823640700187

Epoch: 5| Step: 3
Training loss: 2.3495791362741425
Validation loss: 2.521056694717533

Epoch: 5| Step: 4
Training loss: 2.012748617607441
Validation loss: 2.520688818632796

Epoch: 5| Step: 5
Training loss: 1.900841340958607
Validation loss: 2.5351595063034327

Epoch: 5| Step: 6
Training loss: 2.4358188015424616
Validation loss: 2.53701729199911

Epoch: 5| Step: 7
Training loss: 2.3543327970598216
Validation loss: 2.523181729104586

Epoch: 5| Step: 8
Training loss: 1.949478040432093
Validation loss: 2.527317225824599

Epoch: 5| Step: 9
Training loss: 2.5464979957559195
Validation loss: 2.5223197193517732

Epoch: 5| Step: 10
Training loss: 2.4485989749247308
Validation loss: 2.520388837250674

Epoch: 5| Step: 11
Training loss: 3.0680943987173728
Validation loss: 2.5195636954177565

Epoch: 228| Step: 0
Training loss: 2.8892258015637813
Validation loss: 2.5203363201846978

Epoch: 5| Step: 1
Training loss: 2.2570814381291537
Validation loss: 2.5262043471240396

Epoch: 5| Step: 2
Training loss: 2.5480780071372506
Validation loss: 2.5496068317892946

Epoch: 5| Step: 3
Training loss: 2.704068057981312
Validation loss: 2.554990639622781

Epoch: 5| Step: 4
Training loss: 2.627269218174888
Validation loss: 2.5541487620557435

Epoch: 5| Step: 5
Training loss: 2.180599773738863
Validation loss: 2.5531410996525947

Epoch: 5| Step: 6
Training loss: 1.8699042694557149
Validation loss: 2.5399268806438466

Epoch: 5| Step: 7
Training loss: 2.3571365550398697
Validation loss: 2.541557697920275

Epoch: 5| Step: 8
Training loss: 2.1465032574948575
Validation loss: 2.5409257126660143

Epoch: 5| Step: 9
Training loss: 1.9364538752556002
Validation loss: 2.5315666275420847

Epoch: 5| Step: 10
Training loss: 2.959807892570951
Validation loss: 2.518108307161451

Epoch: 5| Step: 11
Training loss: 2.1761875286919046
Validation loss: 2.503071213778158

Epoch: 229| Step: 0
Training loss: 2.125291243397642
Validation loss: 2.5052927218451093

Epoch: 5| Step: 1
Training loss: 2.263045322181821
Validation loss: 2.5035687108491866

Epoch: 5| Step: 2
Training loss: 2.1025288568754865
Validation loss: 2.504676605124763

Epoch: 5| Step: 3
Training loss: 2.3390487313741284
Validation loss: 2.503652332620985

Epoch: 5| Step: 4
Training loss: 2.4587922934001036
Validation loss: 2.5077907387016083

Epoch: 5| Step: 5
Training loss: 2.5282164869506163
Validation loss: 2.519129880335182

Epoch: 5| Step: 6
Training loss: 2.937022718248833
Validation loss: 2.5138677102338995

Epoch: 5| Step: 7
Training loss: 2.8198858979320347
Validation loss: 2.526326721205487

Epoch: 5| Step: 8
Training loss: 1.9292314739615621
Validation loss: 2.529244032299209

Epoch: 5| Step: 9
Training loss: 2.6122288430870686
Validation loss: 2.5302202775426452

Epoch: 5| Step: 10
Training loss: 2.3629597090467644
Validation loss: 2.532967898923821

Epoch: 5| Step: 11
Training loss: 1.3605536689336768
Validation loss: 2.538014869727295

Epoch: 230| Step: 0
Training loss: 2.3210803472901707
Validation loss: 2.521829362351535

Epoch: 5| Step: 1
Training loss: 2.4431105379509486
Validation loss: 2.5160879021204927

Epoch: 5| Step: 2
Training loss: 2.2885690619441315
Validation loss: 2.5196009702671343

Epoch: 5| Step: 3
Training loss: 1.9083328749588107
Validation loss: 2.505734082501752

Epoch: 5| Step: 4
Training loss: 2.2961212789956122
Validation loss: 2.5087105122632543

Epoch: 5| Step: 5
Training loss: 2.464422174786336
Validation loss: 2.494294008752852

Epoch: 5| Step: 6
Training loss: 2.444340619377258
Validation loss: 2.50341935365759

Epoch: 5| Step: 7
Training loss: 2.804943444944942
Validation loss: 2.4958032867860482

Epoch: 5| Step: 8
Training loss: 2.320835350031179
Validation loss: 2.4967913023567596

Epoch: 5| Step: 9
Training loss: 2.7472786009064563
Validation loss: 2.5055886665260667

Epoch: 5| Step: 10
Training loss: 2.3799463262836857
Validation loss: 2.5097560263918974

Epoch: 5| Step: 11
Training loss: 2.668512470475682
Validation loss: 2.518497659176366

Epoch: 231| Step: 0
Training loss: 2.324115962472407
Validation loss: 2.5452483741858227

Epoch: 5| Step: 1
Training loss: 2.495593479032904
Validation loss: 2.5385898404461

Epoch: 5| Step: 2
Training loss: 2.9571038140246184
Validation loss: 2.547343298797296

Epoch: 5| Step: 3
Training loss: 2.1825063109770917
Validation loss: 2.5354530384105622

Epoch: 5| Step: 4
Training loss: 2.4492787136299974
Validation loss: 2.524429826914732

Epoch: 5| Step: 5
Training loss: 2.220610577240952
Validation loss: 2.5191645431783014

Epoch: 5| Step: 6
Training loss: 2.203050003398553
Validation loss: 2.51387705208841

Epoch: 5| Step: 7
Training loss: 2.011476728084248
Validation loss: 2.4915328007931956

Epoch: 5| Step: 8
Training loss: 2.155092453887361
Validation loss: 2.501091373166268

Epoch: 5| Step: 9
Training loss: 3.0143287521316804
Validation loss: 2.506945502761472

Epoch: 5| Step: 10
Training loss: 2.4607542908303723
Validation loss: 2.4980675699203445

Epoch: 5| Step: 11
Training loss: 2.1596186763995195
Validation loss: 2.4991926101441657

Epoch: 232| Step: 0
Training loss: 2.272088558438891
Validation loss: 2.497860418125981

Epoch: 5| Step: 1
Training loss: 2.720316293221885
Validation loss: 2.500356835489243

Epoch: 5| Step: 2
Training loss: 1.8301570065168746
Validation loss: 2.498055959868446

Epoch: 5| Step: 3
Training loss: 2.580373996862486
Validation loss: 2.493157627462492

Epoch: 5| Step: 4
Training loss: 1.9143886988863008
Validation loss: 2.4949512722644034

Epoch: 5| Step: 5
Training loss: 2.510126870129135
Validation loss: 2.503277180364025

Epoch: 5| Step: 6
Training loss: 2.6439844915769113
Validation loss: 2.5111663966442586

Epoch: 5| Step: 7
Training loss: 2.570701871094038
Validation loss: 2.5132054961091153

Epoch: 5| Step: 8
Training loss: 2.5384299091778355
Validation loss: 2.505375713115392

Epoch: 5| Step: 9
Training loss: 2.0052782979542
Validation loss: 2.5153305521120672

Epoch: 5| Step: 10
Training loss: 2.869301497361975
Validation loss: 2.5185499660866286

Epoch: 5| Step: 11
Training loss: 1.3677363574645054
Validation loss: 2.5276285293089376

Epoch: 233| Step: 0
Training loss: 2.759951963835944
Validation loss: 2.538745484735483

Epoch: 5| Step: 1
Training loss: 2.171096772105669
Validation loss: 2.5207626783436834

Epoch: 5| Step: 2
Training loss: 2.5683784977306168
Validation loss: 2.5266207958597815

Epoch: 5| Step: 3
Training loss: 2.477501724196372
Validation loss: 2.5302359331483286

Epoch: 5| Step: 4
Training loss: 2.7842916936432016
Validation loss: 2.527636767012805

Epoch: 5| Step: 5
Training loss: 2.1247215088508282
Validation loss: 2.5228066457945655

Epoch: 5| Step: 6
Training loss: 2.241301251754646
Validation loss: 2.5268095966297177

Epoch: 5| Step: 7
Training loss: 2.15844460081504
Validation loss: 2.524320796225002

Epoch: 5| Step: 8
Training loss: 2.7115454967634354
Validation loss: 2.5179223159988844

Epoch: 5| Step: 9
Training loss: 2.593108959723029
Validation loss: 2.514736828284451

Epoch: 5| Step: 10
Training loss: 1.6148544658126331
Validation loss: 2.510927668015942

Epoch: 5| Step: 11
Training loss: 1.1852612724870484
Validation loss: 2.5132857873156484

Epoch: 234| Step: 0
Training loss: 2.7792156365773324
Validation loss: 2.505184206512654

Epoch: 5| Step: 1
Training loss: 2.13699333476918
Validation loss: 2.5049823069502812

Epoch: 5| Step: 2
Training loss: 2.160135941642783
Validation loss: 2.500713004321417

Epoch: 5| Step: 3
Training loss: 2.281523074175316
Validation loss: 2.508514876359758

Epoch: 5| Step: 4
Training loss: 2.681630934039982
Validation loss: 2.513142579181711

Epoch: 5| Step: 5
Training loss: 2.2991178811255057
Validation loss: 2.5182537615474767

Epoch: 5| Step: 6
Training loss: 2.168243115908887
Validation loss: 2.5142018417268104

Epoch: 5| Step: 7
Training loss: 2.6155065803656536
Validation loss: 2.517905652720024

Epoch: 5| Step: 8
Training loss: 2.1186923488999314
Validation loss: 2.5260803744047577

Epoch: 5| Step: 9
Training loss: 2.17679110912735
Validation loss: 2.515084182861042

Epoch: 5| Step: 10
Training loss: 2.8731934220251607
Validation loss: 2.514155023554402

Epoch: 5| Step: 11
Training loss: 1.6720405567945036
Validation loss: 2.5353816147269588

Epoch: 235| Step: 0
Training loss: 1.9743099117629803
Validation loss: 2.5400338569459686

Epoch: 5| Step: 1
Training loss: 2.3497097282509927
Validation loss: 2.541084374629797

Epoch: 5| Step: 2
Training loss: 3.125002746580824
Validation loss: 2.544752394916709

Epoch: 5| Step: 3
Training loss: 2.5211251355307867
Validation loss: 2.537678812018792

Epoch: 5| Step: 4
Training loss: 2.3242899394953622
Validation loss: 2.540708636212825

Epoch: 5| Step: 5
Training loss: 2.474385264183391
Validation loss: 2.5325323318195014

Epoch: 5| Step: 6
Training loss: 2.0804593162308413
Validation loss: 2.543641086967976

Epoch: 5| Step: 7
Training loss: 2.727240448096016
Validation loss: 2.5393176610821393

Epoch: 5| Step: 8
Training loss: 2.4729133942305763
Validation loss: 2.529867399030279

Epoch: 5| Step: 9
Training loss: 1.8035406126225115
Validation loss: 2.5354495473990117

Epoch: 5| Step: 10
Training loss: 2.1141553047826167
Validation loss: 2.536096383862482

Epoch: 5| Step: 11
Training loss: 2.4537399395946813
Validation loss: 2.5331327202590894

Epoch: 236| Step: 0
Training loss: 2.7338524891392817
Validation loss: 2.5529254782451836

Epoch: 5| Step: 1
Training loss: 2.85399016416976
Validation loss: 2.533407559426327

Epoch: 5| Step: 2
Training loss: 2.289589466460474
Validation loss: 2.5297437511188097

Epoch: 5| Step: 3
Training loss: 2.404330987014306
Validation loss: 2.5553503858287745

Epoch: 5| Step: 4
Training loss: 2.872842061764068
Validation loss: 2.5674043260062085

Epoch: 5| Step: 5
Training loss: 2.4143602502398505
Validation loss: 2.574420621961171

Epoch: 5| Step: 6
Training loss: 2.7116224319642095
Validation loss: 2.573283101190299

Epoch: 5| Step: 7
Training loss: 2.045037296393427
Validation loss: 2.59807914025971

Epoch: 5| Step: 8
Training loss: 2.006794593552227
Validation loss: 2.5622216011411743

Epoch: 5| Step: 9
Training loss: 2.07051977883357
Validation loss: 2.5171737799970084

Epoch: 5| Step: 10
Training loss: 2.0416652393984833
Validation loss: 2.51051503037557

Epoch: 5| Step: 11
Training loss: 0.9474559474759403
Validation loss: 2.494973151521831

Epoch: 237| Step: 0
Training loss: 2.9889267965920046
Validation loss: 2.495528048077767

Epoch: 5| Step: 1
Training loss: 1.8291089922850303
Validation loss: 2.49764688136277

Epoch: 5| Step: 2
Training loss: 2.287377059217644
Validation loss: 2.4961264960857785

Epoch: 5| Step: 3
Training loss: 2.5476576649820704
Validation loss: 2.495216271112136

Epoch: 5| Step: 4
Training loss: 2.5787175277906584
Validation loss: 2.4904761382783027

Epoch: 5| Step: 5
Training loss: 2.4614474298077202
Validation loss: 2.4897782809385225

Epoch: 5| Step: 6
Training loss: 2.6330774553136775
Validation loss: 2.4879481253814926

Epoch: 5| Step: 7
Training loss: 2.578605283447761
Validation loss: 2.485520916298188

Epoch: 5| Step: 8
Training loss: 2.302314182864418
Validation loss: 2.4929511156995616

Epoch: 5| Step: 9
Training loss: 2.5758651539237705
Validation loss: 2.487628104475154

Epoch: 5| Step: 10
Training loss: 2.2545519454294887
Validation loss: 2.503297554256523

Epoch: 5| Step: 11
Training loss: 3.212185285418842
Validation loss: 2.5005709115461627

Epoch: 238| Step: 0
Training loss: 2.507922208769007
Validation loss: 2.5009874062859776

Epoch: 5| Step: 1
Training loss: 1.9831861403953122
Validation loss: 2.51589316761205

Epoch: 5| Step: 2
Training loss: 2.530511442214733
Validation loss: 2.539974885995366

Epoch: 5| Step: 3
Training loss: 2.53990126620655
Validation loss: 2.538608803928971

Epoch: 5| Step: 4
Training loss: 2.6656016269388076
Validation loss: 2.5735357880713705

Epoch: 5| Step: 5
Training loss: 2.5594856396656227
Validation loss: 2.5723558476217323

Epoch: 5| Step: 6
Training loss: 2.3561059396755932
Validation loss: 2.565669689029326

Epoch: 5| Step: 7
Training loss: 2.6726430045710954
Validation loss: 2.532846563456503

Epoch: 5| Step: 8
Training loss: 2.50907756710149
Validation loss: 2.5288082087692594

Epoch: 5| Step: 9
Training loss: 2.1993569691453616
Validation loss: 2.5033270770579747

Epoch: 5| Step: 10
Training loss: 1.8450176601029917
Validation loss: 2.5098668930265005

Epoch: 5| Step: 11
Training loss: 2.9592873194755835
Validation loss: 2.4986405888683945

Epoch: 239| Step: 0
Training loss: 2.350320278824871
Validation loss: 2.4996278207627607

Epoch: 5| Step: 1
Training loss: 2.673794330302549
Validation loss: 2.490571022964462

Epoch: 5| Step: 2
Training loss: 2.203913770660799
Validation loss: 2.4803604823235856

Epoch: 5| Step: 3
Training loss: 2.272346785513878
Validation loss: 2.4914041202759756

Epoch: 5| Step: 4
Training loss: 2.0921632818026867
Validation loss: 2.4961832475213632

Epoch: 5| Step: 5
Training loss: 2.697217980916331
Validation loss: 2.489836892712138

Epoch: 5| Step: 6
Training loss: 2.4939298368922795
Validation loss: 2.4932947598965267

Epoch: 5| Step: 7
Training loss: 2.2551400495121845
Validation loss: 2.500693105939569

Epoch: 5| Step: 8
Training loss: 2.97148536350138
Validation loss: 2.503957899635109

Epoch: 5| Step: 9
Training loss: 2.1144677742888067
Validation loss: 2.5067357279918223

Epoch: 5| Step: 10
Training loss: 2.537798194088663
Validation loss: 2.505644537580819

Epoch: 5| Step: 11
Training loss: 2.1985950839155395
Validation loss: 2.5131822418926686

Epoch: 240| Step: 0
Training loss: 1.3817752029497476
Validation loss: 2.5088702255906057

Epoch: 5| Step: 1
Training loss: 2.6355031920290504
Validation loss: 2.517061763080161

Epoch: 5| Step: 2
Training loss: 2.6976833365345736
Validation loss: 2.5067931507056893

Epoch: 5| Step: 3
Training loss: 2.0340732614382278
Validation loss: 2.5041130365372095

Epoch: 5| Step: 4
Training loss: 2.5286658011583407
Validation loss: 2.506989840281122

Epoch: 5| Step: 5
Training loss: 2.1715145772558424
Validation loss: 2.5043460223688316

Epoch: 5| Step: 6
Training loss: 2.236347101789026
Validation loss: 2.5021354178079815

Epoch: 5| Step: 7
Training loss: 2.441882570722183
Validation loss: 2.5075257316617976

Epoch: 5| Step: 8
Training loss: 2.4513951902755804
Validation loss: 2.506454690421098

Epoch: 5| Step: 9
Training loss: 2.6988385563465362
Validation loss: 2.516570683542624

Epoch: 5| Step: 10
Training loss: 2.736964454696029
Validation loss: 2.513456523595139

Epoch: 5| Step: 11
Training loss: 3.371591613004578
Validation loss: 2.5201028456402157

Epoch: 241| Step: 0
Training loss: 2.451619554953465
Validation loss: 2.5238673864571

Epoch: 5| Step: 1
Training loss: 2.462044118905817
Validation loss: 2.536227888778932

Epoch: 5| Step: 2
Training loss: 2.6100114057737454
Validation loss: 2.520596837281255

Epoch: 5| Step: 3
Training loss: 2.038082545030418
Validation loss: 2.51867403337062

Epoch: 5| Step: 4
Training loss: 2.911292510977325
Validation loss: 2.526472024864513

Epoch: 5| Step: 5
Training loss: 2.891078604084489
Validation loss: 2.5231577833350087

Epoch: 5| Step: 6
Training loss: 2.1419203799682975
Validation loss: 2.5241196599063276

Epoch: 5| Step: 7
Training loss: 1.9860957337016094
Validation loss: 2.523630317903456

Epoch: 5| Step: 8
Training loss: 2.28870688530623
Validation loss: 2.529158905861609

Epoch: 5| Step: 9
Training loss: 1.5886557449486192
Validation loss: 2.532451709369749

Epoch: 5| Step: 10
Training loss: 2.4808696272705317
Validation loss: 2.524042007900257

Epoch: 5| Step: 11
Training loss: 2.5800942038555577
Validation loss: 2.5182273191480093

Epoch: 242| Step: 0
Training loss: 2.680455934543377
Validation loss: 2.511099067052392

Epoch: 5| Step: 1
Training loss: 2.4240407796646184
Validation loss: 2.50866157204831

Epoch: 5| Step: 2
Training loss: 2.1540366713396106
Validation loss: 2.5093173882255355

Epoch: 5| Step: 3
Training loss: 2.4779716838730543
Validation loss: 2.5135537223247515

Epoch: 5| Step: 4
Training loss: 2.6767963794934584
Validation loss: 2.5096552011859865

Epoch: 5| Step: 5
Training loss: 2.6933754857544803
Validation loss: 2.50880417275398

Epoch: 5| Step: 6
Training loss: 2.217873628571297
Validation loss: 2.507593551378959

Epoch: 5| Step: 7
Training loss: 1.8218462462470864
Validation loss: 2.505591176230456

Epoch: 5| Step: 8
Training loss: 2.3656574000126516
Validation loss: 2.504194138948004

Epoch: 5| Step: 9
Training loss: 2.495417686925469
Validation loss: 2.509682759105657

Epoch: 5| Step: 10
Training loss: 1.9013134557403653
Validation loss: 2.529834516375418

Epoch: 5| Step: 11
Training loss: 3.306569242298393
Validation loss: 2.561806964974415

Epoch: 243| Step: 0
Training loss: 3.1262616471748936
Validation loss: 2.595079667167597

Epoch: 5| Step: 1
Training loss: 2.5833852106443453
Validation loss: 2.6617276017549703

Epoch: 5| Step: 2
Training loss: 2.708912821665644
Validation loss: 2.6202499084943365

Epoch: 5| Step: 3
Training loss: 2.229024710249985
Validation loss: 2.5914834778573232

Epoch: 5| Step: 4
Training loss: 2.4543079998293047
Validation loss: 2.5762309582663776

Epoch: 5| Step: 5
Training loss: 2.1123954340770736
Validation loss: 2.5572786557448635

Epoch: 5| Step: 6
Training loss: 2.499385185936378
Validation loss: 2.55211639512633

Epoch: 5| Step: 7
Training loss: 2.4323676435760335
Validation loss: 2.536300569415263

Epoch: 5| Step: 8
Training loss: 2.868744720919537
Validation loss: 2.5303066285347797

Epoch: 5| Step: 9
Training loss: 1.6963742355020015
Validation loss: 2.534664805878246

Epoch: 5| Step: 10
Training loss: 2.1366825972432837
Validation loss: 2.5171091981150506

Epoch: 5| Step: 11
Training loss: 1.640330551609181
Validation loss: 2.5140536160941354

Epoch: 244| Step: 0
Training loss: 2.6195059001730194
Validation loss: 2.5317935477747637

Epoch: 5| Step: 1
Training loss: 2.4408893984156372
Validation loss: 2.542636644560565

Epoch: 5| Step: 2
Training loss: 2.306036292618469
Validation loss: 2.5653302488403487

Epoch: 5| Step: 3
Training loss: 2.354108173915258
Validation loss: 2.5688951752934797

Epoch: 5| Step: 4
Training loss: 2.778042347282467
Validation loss: 2.576681114228652

Epoch: 5| Step: 5
Training loss: 2.2229281562524927
Validation loss: 2.5817766011101653

Epoch: 5| Step: 6
Training loss: 2.518388450552936
Validation loss: 2.6025680950709242

Epoch: 5| Step: 7
Training loss: 2.1832532804921616
Validation loss: 2.5770338388828313

Epoch: 5| Step: 8
Training loss: 2.445283542254408
Validation loss: 2.547562945077736

Epoch: 5| Step: 9
Training loss: 2.5104890129670983
Validation loss: 2.541104967294705

Epoch: 5| Step: 10
Training loss: 1.9702260372784568
Validation loss: 2.5354750696778456

Epoch: 5| Step: 11
Training loss: 2.7157082039012534
Validation loss: 2.522904382062048

Epoch: 245| Step: 0
Training loss: 2.5791930789447624
Validation loss: 2.526213977612892

Epoch: 5| Step: 1
Training loss: 2.1421530066230514
Validation loss: 2.509484768402923

Epoch: 5| Step: 2
Training loss: 2.667856328558857
Validation loss: 2.493549799710785

Epoch: 5| Step: 3
Training loss: 2.812977644309758
Validation loss: 2.5013509358698007

Epoch: 5| Step: 4
Training loss: 1.8320700960575407
Validation loss: 2.4981160277338414

Epoch: 5| Step: 5
Training loss: 2.172693880338957
Validation loss: 2.504259422814369

Epoch: 5| Step: 6
Training loss: 2.353338743028916
Validation loss: 2.501405575127246

Epoch: 5| Step: 7
Training loss: 2.587766340618193
Validation loss: 2.517722240867813

Epoch: 5| Step: 8
Training loss: 2.2229960471807524
Validation loss: 2.5228418212066233

Epoch: 5| Step: 9
Training loss: 2.517629073924439
Validation loss: 2.5405577966264157

Epoch: 5| Step: 10
Training loss: 2.3119583526542944
Validation loss: 2.5354363669259863

Epoch: 5| Step: 11
Training loss: 2.704395326450272
Validation loss: 2.5485892894017397

Epoch: 246| Step: 0
Training loss: 1.9770294964625117
Validation loss: 2.5520795173356987

Epoch: 5| Step: 1
Training loss: 2.3157686382022606
Validation loss: 2.57463375638139

Epoch: 5| Step: 2
Training loss: 2.0572841467096215
Validation loss: 2.5572222035304173

Epoch: 5| Step: 3
Training loss: 2.4757115198669757
Validation loss: 2.5389198771792305

Epoch: 5| Step: 4
Training loss: 2.133481322559665
Validation loss: 2.5350802958297334

Epoch: 5| Step: 5
Training loss: 3.0232277336590823
Validation loss: 2.5300209884313265

Epoch: 5| Step: 6
Training loss: 2.6019730344250305
Validation loss: 2.5266212440822264

Epoch: 5| Step: 7
Training loss: 1.9415243254892984
Validation loss: 2.501854709235157

Epoch: 5| Step: 8
Training loss: 2.4607193138645407
Validation loss: 2.5016678650726285

Epoch: 5| Step: 9
Training loss: 2.8356358391342527
Validation loss: 2.489832523808598

Epoch: 5| Step: 10
Training loss: 2.6104013400428316
Validation loss: 2.5013916354388175

Epoch: 5| Step: 11
Training loss: 1.4497813651896607
Validation loss: 2.4997604016883908

Epoch: 247| Step: 0
Training loss: 2.5052178290828895
Validation loss: 2.503899328784631

Epoch: 5| Step: 1
Training loss: 2.101036601579796
Validation loss: 2.5103035000399503

Epoch: 5| Step: 2
Training loss: 2.353078359924364
Validation loss: 2.5263001666907035

Epoch: 5| Step: 3
Training loss: 2.3086940272413057
Validation loss: 2.5361542855657224

Epoch: 5| Step: 4
Training loss: 2.4883435299922705
Validation loss: 2.5301861862672843

Epoch: 5| Step: 5
Training loss: 2.3067487389327583
Validation loss: 2.533193423042552

Epoch: 5| Step: 6
Training loss: 2.494408457929991
Validation loss: 2.566792072498127

Epoch: 5| Step: 7
Training loss: 2.5090799426604344
Validation loss: 2.552140691981964

Epoch: 5| Step: 8
Training loss: 2.829151789120943
Validation loss: 2.518724810251087

Epoch: 5| Step: 9
Training loss: 1.9398289495941314
Validation loss: 2.5337259404564976

Epoch: 5| Step: 10
Training loss: 2.248985273639506
Validation loss: 2.543412833398261

Epoch: 5| Step: 11
Training loss: 1.734081759020189
Validation loss: 2.533577959166534

Epoch: 248| Step: 0
Training loss: 1.7071938164510527
Validation loss: 2.5276476339808944

Epoch: 5| Step: 1
Training loss: 1.913720672601971
Validation loss: 2.526671511331743

Epoch: 5| Step: 2
Training loss: 2.9570465692201435
Validation loss: 2.525887542951719

Epoch: 5| Step: 3
Training loss: 3.19013135418368
Validation loss: 2.5247148719484556

Epoch: 5| Step: 4
Training loss: 1.8998818887841307
Validation loss: 2.5246576876618736

Epoch: 5| Step: 5
Training loss: 2.284748895316165
Validation loss: 2.526072870959744

Epoch: 5| Step: 6
Training loss: 2.2854179036900093
Validation loss: 2.5171700702539743

Epoch: 5| Step: 7
Training loss: 2.352192436325592
Validation loss: 2.530854445425819

Epoch: 5| Step: 8
Training loss: 2.4079126335973235
Validation loss: 2.521691417984428

Epoch: 5| Step: 9
Training loss: 1.607481944930514
Validation loss: 2.5197311558632425

Epoch: 5| Step: 10
Training loss: 2.838563318199152
Validation loss: 2.5324859898171193

Epoch: 5| Step: 11
Training loss: 3.1987566678274706
Validation loss: 2.51828155278995

Epoch: 249| Step: 0
Training loss: 2.4975207433135065
Validation loss: 2.5573358253556195

Epoch: 5| Step: 1
Training loss: 2.5839760708837654
Validation loss: 2.578079662502342

Epoch: 5| Step: 2
Training loss: 2.4848012498551544
Validation loss: 2.6081447746952646

Epoch: 5| Step: 3
Training loss: 2.3507969012362206
Validation loss: 2.6181315337392714

Epoch: 5| Step: 4
Training loss: 2.183619299450818
Validation loss: 2.601256194998657

Epoch: 5| Step: 5
Training loss: 1.8677381397882253
Validation loss: 2.5699386672668543

Epoch: 5| Step: 6
Training loss: 2.695858488206278
Validation loss: 2.5361545597554627

Epoch: 5| Step: 7
Training loss: 2.4795279573532514
Validation loss: 2.5049569221226573

Epoch: 5| Step: 8
Training loss: 2.370204098761876
Validation loss: 2.5060033362907554

Epoch: 5| Step: 9
Training loss: 2.368449161318126
Validation loss: 2.5064732747814618

Epoch: 5| Step: 10
Training loss: 2.6293039913758434
Validation loss: 2.493302987523036

Epoch: 5| Step: 11
Training loss: 1.7311187281228124
Validation loss: 2.4879844125167914

Epoch: 250| Step: 0
Training loss: 3.2212673084058996
Validation loss: 2.493074974603092

Epoch: 5| Step: 1
Training loss: 1.5907080548080164
Validation loss: 2.4892539134942226

Epoch: 5| Step: 2
Training loss: 1.8190364703799948
Validation loss: 2.4810496934037034

Epoch: 5| Step: 3
Training loss: 2.264157786973771
Validation loss: 2.4998464457719924

Epoch: 5| Step: 4
Training loss: 2.2052054896371627
Validation loss: 2.490645574391389

Epoch: 5| Step: 5
Training loss: 2.5566646845816927
Validation loss: 2.4866615864899555

Epoch: 5| Step: 6
Training loss: 2.5268616489205824
Validation loss: 2.5021741115821223

Epoch: 5| Step: 7
Training loss: 2.469501043109013
Validation loss: 2.4925323893433173

Epoch: 5| Step: 8
Training loss: 2.6891923056287426
Validation loss: 2.4982045521308422

Epoch: 5| Step: 9
Training loss: 2.714933237480854
Validation loss: 2.5035719090380226

Epoch: 5| Step: 10
Training loss: 2.2182671464790245
Validation loss: 2.5093894785474835

Epoch: 5| Step: 11
Training loss: 1.9950384347602566
Validation loss: 2.530322709579823

Epoch: 251| Step: 0
Training loss: 2.7998565466781185
Validation loss: 2.527218221527462

Epoch: 5| Step: 1
Training loss: 2.691612025396225
Validation loss: 2.562974029208753

Epoch: 5| Step: 2
Training loss: 2.6293161421259597
Validation loss: 2.6012077700663667

Epoch: 5| Step: 3
Training loss: 2.2443487404519624
Validation loss: 2.5895042561318515

Epoch: 5| Step: 4
Training loss: 2.630406488690645
Validation loss: 2.5970771889869164

Epoch: 5| Step: 5
Training loss: 2.3047018794241567
Validation loss: 2.5992703655022718

Epoch: 5| Step: 6
Training loss: 1.493724490789843
Validation loss: 2.5955477884052915

Epoch: 5| Step: 7
Training loss: 2.087889254706052
Validation loss: 2.5866655417803237

Epoch: 5| Step: 8
Training loss: 2.49863444226648
Validation loss: 2.5686345676991

Epoch: 5| Step: 9
Training loss: 2.7392235194488883
Validation loss: 2.5352346156409964

Epoch: 5| Step: 10
Training loss: 1.9095441777626911
Validation loss: 2.514010632068616

Epoch: 5| Step: 11
Training loss: 1.833604994789364
Validation loss: 2.5102386226805895

Epoch: 252| Step: 0
Training loss: 2.315991832593573
Validation loss: 2.502698526710683

Epoch: 5| Step: 1
Training loss: 2.338075201895619
Validation loss: 2.496929671477158

Epoch: 5| Step: 2
Training loss: 2.8500656588837967
Validation loss: 2.4956057155496807

Epoch: 5| Step: 3
Training loss: 1.9462567837302307
Validation loss: 2.4960630571192626

Epoch: 5| Step: 4
Training loss: 2.334832686121251
Validation loss: 2.507057165319222

Epoch: 5| Step: 5
Training loss: 2.27686505005825
Validation loss: 2.511067168981039

Epoch: 5| Step: 6
Training loss: 2.1744934325216607
Validation loss: 2.5103503385991126

Epoch: 5| Step: 7
Training loss: 2.330069427601905
Validation loss: 2.5233848337950717

Epoch: 5| Step: 8
Training loss: 2.5833703520388744
Validation loss: 2.5209191553360952

Epoch: 5| Step: 9
Training loss: 2.8748598479234837
Validation loss: 2.5315170304219494

Epoch: 5| Step: 10
Training loss: 2.2109260693581505
Validation loss: 2.544173260590794

Epoch: 5| Step: 11
Training loss: 1.6466269289980022
Validation loss: 2.541243347238069

Epoch: 253| Step: 0
Training loss: 2.687647083604598
Validation loss: 2.5369254758464885

Epoch: 5| Step: 1
Training loss: 2.370216270107802
Validation loss: 2.5359530849765273

Epoch: 5| Step: 2
Training loss: 2.2563149524754746
Validation loss: 2.540808420727454

Epoch: 5| Step: 3
Training loss: 2.2502265392276035
Validation loss: 2.537840920051055

Epoch: 5| Step: 4
Training loss: 2.0062917449506026
Validation loss: 2.53322933656989

Epoch: 5| Step: 5
Training loss: 3.0833792983744384
Validation loss: 2.527450920871108

Epoch: 5| Step: 6
Training loss: 1.7139928005516878
Validation loss: 2.533234007094943

Epoch: 5| Step: 7
Training loss: 2.452980280209451
Validation loss: 2.5295458893216147

Epoch: 5| Step: 8
Training loss: 2.1171689191052154
Validation loss: 2.5307582369684813

Epoch: 5| Step: 9
Training loss: 2.3536331337365763
Validation loss: 2.5263699872041085

Epoch: 5| Step: 10
Training loss: 2.3573626089665987
Validation loss: 2.5376637092798418

Epoch: 5| Step: 11
Training loss: 1.9919195855198604
Validation loss: 2.5330026508535295

Epoch: 254| Step: 0
Training loss: 2.0095160118921127
Validation loss: 2.5489224159465307

Epoch: 5| Step: 1
Training loss: 1.9549028773463857
Validation loss: 2.5675178493286657

Epoch: 5| Step: 2
Training loss: 2.1405768841535817
Validation loss: 2.5624894320262306

Epoch: 5| Step: 3
Training loss: 2.5587471253528484
Validation loss: 2.566738999315661

Epoch: 5| Step: 4
Training loss: 2.3834209728355673
Validation loss: 2.5732407977047953

Epoch: 5| Step: 5
Training loss: 2.7860270418934596
Validation loss: 2.545029687439765

Epoch: 5| Step: 6
Training loss: 2.142820248967413
Validation loss: 2.5137494600618866

Epoch: 5| Step: 7
Training loss: 2.7148284692128404
Validation loss: 2.520018427468595

Epoch: 5| Step: 8
Training loss: 2.618868524240864
Validation loss: 2.519959926362283

Epoch: 5| Step: 9
Training loss: 1.8031970718762809
Validation loss: 2.5101596250886344

Epoch: 5| Step: 10
Training loss: 2.644530979534006
Validation loss: 2.5108158986545273

Epoch: 5| Step: 11
Training loss: 3.0223946756670426
Validation loss: 2.5133982887167434

Epoch: 255| Step: 0
Training loss: 2.082406130137087
Validation loss: 2.508901118152707

Epoch: 5| Step: 1
Training loss: 2.0989554305013143
Validation loss: 2.5152512345744027

Epoch: 5| Step: 2
Training loss: 3.058081573047009
Validation loss: 2.508089614721215

Epoch: 5| Step: 3
Training loss: 2.751604998995242
Validation loss: 2.511030673419137

Epoch: 5| Step: 4
Training loss: 2.525478045845259
Validation loss: 2.5125908729226114

Epoch: 5| Step: 5
Training loss: 2.345358029914125
Validation loss: 2.5267336746324527

Epoch: 5| Step: 6
Training loss: 1.8973911368763683
Validation loss: 2.5340681910257854

Epoch: 5| Step: 7
Training loss: 2.5719314624618828
Validation loss: 2.544630588774398

Epoch: 5| Step: 8
Training loss: 2.347261163913946
Validation loss: 2.538843221732528

Epoch: 5| Step: 9
Training loss: 2.0875883392098946
Validation loss: 2.5491244517764593

Epoch: 5| Step: 10
Training loss: 2.4110471788281447
Validation loss: 2.5258780764014217

Epoch: 5| Step: 11
Training loss: 1.0366451280406803
Validation loss: 2.5179277704517897

Epoch: 256| Step: 0
Training loss: 1.9541274893059202
Validation loss: 2.5198002082729345

Epoch: 5| Step: 1
Training loss: 2.1323261754520733
Validation loss: 2.5092488985217902

Epoch: 5| Step: 2
Training loss: 2.4108321912885646
Validation loss: 2.516840062788982

Epoch: 5| Step: 3
Training loss: 1.895631954131308
Validation loss: 2.517803244221608

Epoch: 5| Step: 4
Training loss: 2.5908831643749686
Validation loss: 2.5408000927939507

Epoch: 5| Step: 5
Training loss: 2.4759401327608117
Validation loss: 2.5439389942015067

Epoch: 5| Step: 6
Training loss: 1.997884764298944
Validation loss: 2.562481054375556

Epoch: 5| Step: 7
Training loss: 2.0275039168577544
Validation loss: 2.560219711558629

Epoch: 5| Step: 8
Training loss: 2.7177688757597362
Validation loss: 2.5721954668267943

Epoch: 5| Step: 9
Training loss: 2.5100302708840774
Validation loss: 2.570152428463169

Epoch: 5| Step: 10
Training loss: 2.337274787375601
Validation loss: 2.5526681476496402

Epoch: 5| Step: 11
Training loss: 4.573409324066564
Validation loss: 2.5571039652778107

Epoch: 257| Step: 0
Training loss: 2.5377167407146755
Validation loss: 2.54040850834858

Epoch: 5| Step: 1
Training loss: 2.362870614182604
Validation loss: 2.5287829982957235

Epoch: 5| Step: 2
Training loss: 2.352192132245121
Validation loss: 2.513142974467946

Epoch: 5| Step: 3
Training loss: 2.6354703533348434
Validation loss: 2.4999447697260746

Epoch: 5| Step: 4
Training loss: 2.232118761205043
Validation loss: 2.5045079357869118

Epoch: 5| Step: 5
Training loss: 2.25308334163931
Validation loss: 2.509839764599606

Epoch: 5| Step: 6
Training loss: 2.3451520667965533
Validation loss: 2.525764848675717

Epoch: 5| Step: 7
Training loss: 2.113051424909082
Validation loss: 2.5253526036192513

Epoch: 5| Step: 8
Training loss: 1.938892110489747
Validation loss: 2.5414514307180136

Epoch: 5| Step: 9
Training loss: 2.637626615983437
Validation loss: 2.5595050809762228

Epoch: 5| Step: 10
Training loss: 2.4171558301610374
Validation loss: 2.5673408548402508

Epoch: 5| Step: 11
Training loss: 1.8549579117928
Validation loss: 2.578869783347245

Epoch: 258| Step: 0
Training loss: 2.07302298984026
Validation loss: 2.5883720477975873

Epoch: 5| Step: 1
Training loss: 2.1567596717759994
Validation loss: 2.6303863137839123

Epoch: 5| Step: 2
Training loss: 2.0145819279042194
Validation loss: 2.6387372689999404

Epoch: 5| Step: 3
Training loss: 1.9082888971455219
Validation loss: 2.60140288496238

Epoch: 5| Step: 4
Training loss: 2.773476269947987
Validation loss: 2.6209531121914504

Epoch: 5| Step: 5
Training loss: 2.6921476054542817
Validation loss: 2.597901579857168

Epoch: 5| Step: 6
Training loss: 1.9077996380846516
Validation loss: 2.5852978963157813

Epoch: 5| Step: 7
Training loss: 2.3883863950675055
Validation loss: 2.561746998381343

Epoch: 5| Step: 8
Training loss: 2.711348884435997
Validation loss: 2.5511177662757727

Epoch: 5| Step: 9
Training loss: 2.6757356291731367
Validation loss: 2.5369648058949577

Epoch: 5| Step: 10
Training loss: 2.2673189342003797
Validation loss: 2.529391664277772

Epoch: 5| Step: 11
Training loss: 2.8593830045994517
Validation loss: 2.54132230307114

Epoch: 259| Step: 0
Training loss: 2.2563205528323738
Validation loss: 2.5543943970008094

Epoch: 5| Step: 1
Training loss: 2.2068317154339976
Validation loss: 2.5826373752271468

Epoch: 5| Step: 2
Training loss: 2.774168879824262
Validation loss: 2.5941256170724736

Epoch: 5| Step: 3
Training loss: 2.1817843288266205
Validation loss: 2.6213476870041306

Epoch: 5| Step: 4
Training loss: 1.9978223508570792
Validation loss: 2.623326930218419

Epoch: 5| Step: 5
Training loss: 2.002999797841984
Validation loss: 2.6239346317756884

Epoch: 5| Step: 6
Training loss: 2.236048145342263
Validation loss: 2.6225295892954756

Epoch: 5| Step: 7
Training loss: 2.831477417559586
Validation loss: 2.5798488710494434

Epoch: 5| Step: 8
Training loss: 2.5285221990237323
Validation loss: 2.552978453366066

Epoch: 5| Step: 9
Training loss: 2.6608722636211053
Validation loss: 2.549422971023655

Epoch: 5| Step: 10
Training loss: 1.9952037641251152
Validation loss: 2.5333353761509976

Epoch: 5| Step: 11
Training loss: 3.112275117770183
Validation loss: 2.5240988716003976

Epoch: 260| Step: 0
Training loss: 2.6158256061881775
Validation loss: 2.523800039477063

Epoch: 5| Step: 1
Training loss: 2.1863820080083505
Validation loss: 2.525193553137837

Epoch: 5| Step: 2
Training loss: 2.099307413787754
Validation loss: 2.522827157297299

Epoch: 5| Step: 3
Training loss: 2.1973725017409933
Validation loss: 2.5298346695198934

Epoch: 5| Step: 4
Training loss: 2.2838514988418592
Validation loss: 2.5282793548830234

Epoch: 5| Step: 5
Training loss: 2.0249146478820474
Validation loss: 2.5533176447491774

Epoch: 5| Step: 6
Training loss: 2.0347902404503113
Validation loss: 2.5458444487916454

Epoch: 5| Step: 7
Training loss: 2.3879903599338426
Validation loss: 2.5539088058886765

Epoch: 5| Step: 8
Training loss: 1.8926023121519455
Validation loss: 2.5569369399622355

Epoch: 5| Step: 9
Training loss: 2.568325399311872
Validation loss: 2.556345686330266

Epoch: 5| Step: 10
Training loss: 2.9078891192657
Validation loss: 2.561211867004372

Epoch: 5| Step: 11
Training loss: 3.311501694441668
Validation loss: 2.566224926446538

Epoch: 261| Step: 0
Training loss: 2.548914742002861
Validation loss: 2.5531025207351696

Epoch: 5| Step: 1
Training loss: 2.413000274335685
Validation loss: 2.6190890222482577

Epoch: 5| Step: 2
Training loss: 2.4736039935216705
Validation loss: 2.633406020370506

Epoch: 5| Step: 3
Training loss: 3.0242158740460363
Validation loss: 2.6328557932508003

Epoch: 5| Step: 4
Training loss: 2.458917569926275
Validation loss: 2.585934031043362

Epoch: 5| Step: 5
Training loss: 2.4603664159421053
Validation loss: 2.5909586789322985

Epoch: 5| Step: 6
Training loss: 1.9562423242777915
Validation loss: 2.5527975458385885

Epoch: 5| Step: 7
Training loss: 1.809011654121981
Validation loss: 2.54869900470161

Epoch: 5| Step: 8
Training loss: 1.3499936386241091
Validation loss: 2.541612829096778

Epoch: 5| Step: 9
Training loss: 2.319263156752807
Validation loss: 2.510918679173753

Epoch: 5| Step: 10
Training loss: 2.529401975826729
Validation loss: 2.501871120072818

Epoch: 5| Step: 11
Training loss: 2.139262190220231
Validation loss: 2.488949680425616

Epoch: 262| Step: 0
Training loss: 1.9093023158347535
Validation loss: 2.4842876962800706

Epoch: 5| Step: 1
Training loss: 2.4128517645506764
Validation loss: 2.481149414867943

Epoch: 5| Step: 2
Training loss: 2.3203660335851484
Validation loss: 2.4868596306212707

Epoch: 5| Step: 3
Training loss: 1.9663800098000601
Validation loss: 2.4795434542576014

Epoch: 5| Step: 4
Training loss: 2.4051215758494826
Validation loss: 2.488270656257727

Epoch: 5| Step: 5
Training loss: 2.1892394643044124
Validation loss: 2.483943141933568

Epoch: 5| Step: 6
Training loss: 2.128555128907423
Validation loss: 2.479699082999528

Epoch: 5| Step: 7
Training loss: 2.3249322901885083
Validation loss: 2.476839407072233

Epoch: 5| Step: 8
Training loss: 2.4075779408864153
Validation loss: 2.4998331133453267

Epoch: 5| Step: 9
Training loss: 2.7631913161586956
Validation loss: 2.512245645031688

Epoch: 5| Step: 10
Training loss: 3.0502238332193357
Validation loss: 2.5215956596639617

Epoch: 5| Step: 11
Training loss: 2.9820601987845254
Validation loss: 2.5377792676079047

Epoch: 263| Step: 0
Training loss: 2.1144365406918784
Validation loss: 2.5514429859048544

Epoch: 5| Step: 1
Training loss: 1.9255144967499502
Validation loss: 2.57428084758288

Epoch: 5| Step: 2
Training loss: 2.585541663169651
Validation loss: 2.5728389185125136

Epoch: 5| Step: 3
Training loss: 2.365056454103667
Validation loss: 2.563828461244787

Epoch: 5| Step: 4
Training loss: 2.554835790594111
Validation loss: 2.5601214247705704

Epoch: 5| Step: 5
Training loss: 2.349625407455173
Validation loss: 2.5550627165547835

Epoch: 5| Step: 6
Training loss: 2.5658839142750876
Validation loss: 2.5245299243225054

Epoch: 5| Step: 7
Training loss: 2.4187292526893005
Validation loss: 2.5349334634579934

Epoch: 5| Step: 8
Training loss: 2.1046929283610165
Validation loss: 2.5143115719829523

Epoch: 5| Step: 9
Training loss: 2.2051184543270064
Validation loss: 2.517614809750029

Epoch: 5| Step: 10
Training loss: 2.7922176178010716
Validation loss: 2.5158999551449677

Epoch: 5| Step: 11
Training loss: 1.994021958604236
Validation loss: 2.5213924817695927

Epoch: 264| Step: 0
Training loss: 2.1612750117375357
Validation loss: 2.522093022032368

Epoch: 5| Step: 1
Training loss: 2.629044369020996
Validation loss: 2.5459066863244013

Epoch: 5| Step: 2
Training loss: 2.0181949998157993
Validation loss: 2.566994876797761

Epoch: 5| Step: 3
Training loss: 2.936103651249204
Validation loss: 2.598799623575536

Epoch: 5| Step: 4
Training loss: 2.440168631620493
Validation loss: 2.6028029889516815

Epoch: 5| Step: 5
Training loss: 1.7820728476091519
Validation loss: 2.6150575957450095

Epoch: 5| Step: 6
Training loss: 2.196711084537114
Validation loss: 2.5960311165761003

Epoch: 5| Step: 7
Training loss: 2.941728835128879
Validation loss: 2.568741589862703

Epoch: 5| Step: 8
Training loss: 1.4587611342971938
Validation loss: 2.5582735361158346

Epoch: 5| Step: 9
Training loss: 2.5631154879635587
Validation loss: 2.5490559189925723

Epoch: 5| Step: 10
Training loss: 2.0359438142949378
Validation loss: 2.5431945415366

Epoch: 5| Step: 11
Training loss: 2.4312406525027668
Validation loss: 2.5317984446014163

Epoch: 265| Step: 0
Training loss: 2.598831255194314
Validation loss: 2.526037266652054

Epoch: 5| Step: 1
Training loss: 2.521964289751974
Validation loss: 2.508247325907578

Epoch: 5| Step: 2
Training loss: 2.556621507729089
Validation loss: 2.4910170059555203

Epoch: 5| Step: 3
Training loss: 2.032691678701628
Validation loss: 2.5078184577340314

Epoch: 5| Step: 4
Training loss: 1.7726994125471112
Validation loss: 2.4901122657906405

Epoch: 5| Step: 5
Training loss: 2.4638653489452613
Validation loss: 2.4898119439753894

Epoch: 5| Step: 6
Training loss: 1.879749259663459
Validation loss: 2.4921454741981446

Epoch: 5| Step: 7
Training loss: 2.3459281464066684
Validation loss: 2.504107569845081

Epoch: 5| Step: 8
Training loss: 2.553882063607894
Validation loss: 2.4992739576828624

Epoch: 5| Step: 9
Training loss: 2.4325936652064275
Validation loss: 2.5155077881290304

Epoch: 5| Step: 10
Training loss: 2.571878066588343
Validation loss: 2.517116055381401

Epoch: 5| Step: 11
Training loss: 1.5932896267045138
Validation loss: 2.53701488778023

Epoch: 266| Step: 0
Training loss: 2.151566657655864
Validation loss: 2.556753332394567

Epoch: 5| Step: 1
Training loss: 2.2464233156654343
Validation loss: 2.549147541790797

Epoch: 5| Step: 2
Training loss: 2.4011891637638634
Validation loss: 2.5769411663560313

Epoch: 5| Step: 3
Training loss: 2.293346679319686
Validation loss: 2.561518725479219

Epoch: 5| Step: 4
Training loss: 1.8527090651190665
Validation loss: 2.585470735618287

Epoch: 5| Step: 5
Training loss: 2.5919570240943806
Validation loss: 2.5550793999479846

Epoch: 5| Step: 6
Training loss: 2.1521626307996335
Validation loss: 2.6208251345515823

Epoch: 5| Step: 7
Training loss: 2.5484039772209828
Validation loss: 2.606409079532228

Epoch: 5| Step: 8
Training loss: 2.2902695529662314
Validation loss: 2.6113995713717433

Epoch: 5| Step: 9
Training loss: 2.5473650127432057
Validation loss: 2.5844655568049197

Epoch: 5| Step: 10
Training loss: 2.1805199568232556
Validation loss: 2.565347264319524

Epoch: 5| Step: 11
Training loss: 3.226270759453655
Validation loss: 2.5489980044211826

Epoch: 267| Step: 0
Training loss: 1.8369237969488879
Validation loss: 2.5228932820335483

Epoch: 5| Step: 1
Training loss: 2.398734307329731
Validation loss: 2.5186177256064797

Epoch: 5| Step: 2
Training loss: 2.266224538467546
Validation loss: 2.5020149773231513

Epoch: 5| Step: 3
Training loss: 2.3736022048266245
Validation loss: 2.504473673005786

Epoch: 5| Step: 4
Training loss: 2.2016698482162202
Validation loss: 2.5013786011641455

Epoch: 5| Step: 5
Training loss: 2.0986115679546504
Validation loss: 2.5259306827559986

Epoch: 5| Step: 6
Training loss: 2.756493531278856
Validation loss: 2.530065730413362

Epoch: 5| Step: 7
Training loss: 2.5936399689281533
Validation loss: 2.530611942860854

Epoch: 5| Step: 8
Training loss: 2.6950166844009
Validation loss: 2.565253321511503

Epoch: 5| Step: 9
Training loss: 2.421982301365442
Validation loss: 2.5594175880934826

Epoch: 5| Step: 10
Training loss: 1.8291233955542585
Validation loss: 2.576123117366773

Epoch: 5| Step: 11
Training loss: 2.3101686634069494
Validation loss: 2.5725266950005055

Epoch: 268| Step: 0
Training loss: 2.414054401470538
Validation loss: 2.5756602402241535

Epoch: 5| Step: 1
Training loss: 2.230181085906218
Validation loss: 2.5822501616369427

Epoch: 5| Step: 2
Training loss: 1.9685649482103114
Validation loss: 2.556609096968969

Epoch: 5| Step: 3
Training loss: 2.7672095635523744
Validation loss: 2.5418936140849753

Epoch: 5| Step: 4
Training loss: 1.8500642791097202
Validation loss: 2.5357064393163258

Epoch: 5| Step: 5
Training loss: 2.8308099467880186
Validation loss: 2.53246783955681

Epoch: 5| Step: 6
Training loss: 2.1417369321386825
Validation loss: 2.525975642701491

Epoch: 5| Step: 7
Training loss: 2.0745087329297287
Validation loss: 2.52567939651263

Epoch: 5| Step: 8
Training loss: 2.3861725677028613
Validation loss: 2.5314264589191393

Epoch: 5| Step: 9
Training loss: 2.7501151320892174
Validation loss: 2.5316707316368707

Epoch: 5| Step: 10
Training loss: 1.6680663033395993
Validation loss: 2.5326508268246917

Epoch: 5| Step: 11
Training loss: 3.0288165835100367
Validation loss: 2.532806745864259

Epoch: 269| Step: 0
Training loss: 2.27703499377689
Validation loss: 2.5151655792513887

Epoch: 5| Step: 1
Training loss: 2.6856785301535777
Validation loss: 2.538917662573198

Epoch: 5| Step: 2
Training loss: 1.9865271844585706
Validation loss: 2.5487967497744632

Epoch: 5| Step: 3
Training loss: 2.280914909103538
Validation loss: 2.5578077511596717

Epoch: 5| Step: 4
Training loss: 2.712690946125167
Validation loss: 2.5411863902496967

Epoch: 5| Step: 5
Training loss: 2.035295770881835
Validation loss: 2.5687431213150678

Epoch: 5| Step: 6
Training loss: 1.724871329332332
Validation loss: 2.6179804231828725

Epoch: 5| Step: 7
Training loss: 2.3420403921030455
Validation loss: 2.6107449885009175

Epoch: 5| Step: 8
Training loss: 2.643181640999516
Validation loss: 2.6084120186057387

Epoch: 5| Step: 9
Training loss: 2.473008551064904
Validation loss: 2.609618809439736

Epoch: 5| Step: 10
Training loss: 2.080443386907394
Validation loss: 2.5863847950746246

Epoch: 5| Step: 11
Training loss: 1.9854731487340422
Validation loss: 2.5677934997444924

Epoch: 270| Step: 0
Training loss: 2.034497760403034
Validation loss: 2.540507722019151

Epoch: 5| Step: 1
Training loss: 2.322440869879294
Validation loss: 2.5234927475494175

Epoch: 5| Step: 2
Training loss: 2.062015129662849
Validation loss: 2.523895773202181

Epoch: 5| Step: 3
Training loss: 2.126595851572196
Validation loss: 2.4971569942844707

Epoch: 5| Step: 4
Training loss: 1.9610942762707133
Validation loss: 2.4961659834413963

Epoch: 5| Step: 5
Training loss: 2.588805852312374
Validation loss: 2.50127877670198

Epoch: 5| Step: 6
Training loss: 2.5694443184334204
Validation loss: 2.522333523688753

Epoch: 5| Step: 7
Training loss: 2.545961461898513
Validation loss: 2.516756952215725

Epoch: 5| Step: 8
Training loss: 2.839622604385899
Validation loss: 2.5125895167926435

Epoch: 5| Step: 9
Training loss: 2.2479164224883172
Validation loss: 2.55131571507366

Epoch: 5| Step: 10
Training loss: 2.2430827516758
Validation loss: 2.5542475820318797

Epoch: 5| Step: 11
Training loss: 1.275055588651095
Validation loss: 2.5713065987469625

Epoch: 271| Step: 0
Training loss: 2.749033931624064
Validation loss: 2.5849864359425383

Epoch: 5| Step: 1
Training loss: 2.6860328928111485
Validation loss: 2.5758317477508212

Epoch: 5| Step: 2
Training loss: 2.223590245633141
Validation loss: 2.5631413742605296

Epoch: 5| Step: 3
Training loss: 1.8307105145288787
Validation loss: 2.5549536244624758

Epoch: 5| Step: 4
Training loss: 1.852408686561127
Validation loss: 2.5593794686414673

Epoch: 5| Step: 5
Training loss: 2.521227267252198
Validation loss: 2.545756747867477

Epoch: 5| Step: 6
Training loss: 2.114775913532975
Validation loss: 2.5597353536002583

Epoch: 5| Step: 7
Training loss: 2.355140473373618
Validation loss: 2.5515576009241974

Epoch: 5| Step: 8
Training loss: 2.0142660365162883
Validation loss: 2.569042699926475

Epoch: 5| Step: 9
Training loss: 2.5085615423909555
Validation loss: 2.62049424146444

Epoch: 5| Step: 10
Training loss: 2.220348588192489
Validation loss: 2.610221618850742

Epoch: 5| Step: 11
Training loss: 2.8544751485550304
Validation loss: 2.5911399048908343

Epoch: 272| Step: 0
Training loss: 2.1045128062360012
Validation loss: 2.6035920513713533

Epoch: 5| Step: 1
Training loss: 2.000693439432045
Validation loss: 2.5816917253915386

Epoch: 5| Step: 2
Training loss: 2.751584896795827
Validation loss: 2.5772514327499154

Epoch: 5| Step: 3
Training loss: 1.8120573095138703
Validation loss: 2.5693346538513913

Epoch: 5| Step: 4
Training loss: 2.1469385084950696
Validation loss: 2.5473259095681375

Epoch: 5| Step: 5
Training loss: 2.8107194138426643
Validation loss: 2.548082981831398

Epoch: 5| Step: 6
Training loss: 3.198227278114103
Validation loss: 2.528951668962429

Epoch: 5| Step: 7
Training loss: 2.328232730702717
Validation loss: 2.543750953205502

Epoch: 5| Step: 8
Training loss: 1.8750202177865054
Validation loss: 2.5475602349549606

Epoch: 5| Step: 9
Training loss: 1.704359394669302
Validation loss: 2.536471385778621

Epoch: 5| Step: 10
Training loss: 2.205482033700697
Validation loss: 2.5627829193924874

Epoch: 5| Step: 11
Training loss: 2.2854427321091397
Validation loss: 2.5542448517769056

Epoch: 273| Step: 0
Training loss: 2.4891707478828122
Validation loss: 2.5419886351248047

Epoch: 5| Step: 1
Training loss: 2.0111258512674515
Validation loss: 2.5305034317477486

Epoch: 5| Step: 2
Training loss: 2.248146883465903
Validation loss: 2.5161997215603162

Epoch: 5| Step: 3
Training loss: 2.823339301609305
Validation loss: 2.5090075405523717

Epoch: 5| Step: 4
Training loss: 2.1154912368207026
Validation loss: 2.50297449701657

Epoch: 5| Step: 5
Training loss: 2.1752979556796093
Validation loss: 2.5192157991455075

Epoch: 5| Step: 6
Training loss: 2.586302117863832
Validation loss: 2.509862127563929

Epoch: 5| Step: 7
Training loss: 2.3441578828023495
Validation loss: 2.53383727360446

Epoch: 5| Step: 8
Training loss: 2.148633580363296
Validation loss: 2.509396184702785

Epoch: 5| Step: 9
Training loss: 2.1623555967595056
Validation loss: 2.541423634859467

Epoch: 5| Step: 10
Training loss: 2.100699435421678
Validation loss: 2.5607641667655034

Epoch: 5| Step: 11
Training loss: 2.3752888955538247
Validation loss: 2.554130769625675

Epoch: 274| Step: 0
Training loss: 2.2935281880161957
Validation loss: 2.573726219097024

Epoch: 5| Step: 1
Training loss: 2.9949403056976585
Validation loss: 2.5814751523016715

Epoch: 5| Step: 2
Training loss: 2.0906396794053257
Validation loss: 2.5964861383188693

Epoch: 5| Step: 3
Training loss: 2.0750506613188495
Validation loss: 2.577732815438292

Epoch: 5| Step: 4
Training loss: 2.090997965435423
Validation loss: 2.5789858950882136

Epoch: 5| Step: 5
Training loss: 2.3783455424361857
Validation loss: 2.574350391315701

Epoch: 5| Step: 6
Training loss: 2.4050129274270664
Validation loss: 2.583514077775214

Epoch: 5| Step: 7
Training loss: 1.8491435285062985
Validation loss: 2.5621975976172955

Epoch: 5| Step: 8
Training loss: 2.484333829718569
Validation loss: 2.552580066269547

Epoch: 5| Step: 9
Training loss: 2.003797264184216
Validation loss: 2.5242931383735

Epoch: 5| Step: 10
Training loss: 2.589413061909588
Validation loss: 2.509894064697943

Epoch: 5| Step: 11
Training loss: 1.0423248246295693
Validation loss: 2.5246017691247657

Epoch: 275| Step: 0
Training loss: 2.6510458735724285
Validation loss: 2.515201667248721

Epoch: 5| Step: 1
Training loss: 2.684421816896114
Validation loss: 2.5265924082762847

Epoch: 5| Step: 2
Training loss: 1.9942999915276727
Validation loss: 2.532306470295485

Epoch: 5| Step: 3
Training loss: 1.9912761922623516
Validation loss: 2.520345291205019

Epoch: 5| Step: 4
Training loss: 2.329849116797793
Validation loss: 2.5359881603032783

Epoch: 5| Step: 5
Training loss: 1.826003318800318
Validation loss: 2.5647205911550346

Epoch: 5| Step: 6
Training loss: 1.490633489876488
Validation loss: 2.5624379328832627

Epoch: 5| Step: 7
Training loss: 2.222396862267297
Validation loss: 2.58729342881518

Epoch: 5| Step: 8
Training loss: 2.7419344793459013
Validation loss: 2.606535487772678

Epoch: 5| Step: 9
Training loss: 2.6531888489066597
Validation loss: 2.613764445932203

Epoch: 5| Step: 10
Training loss: 2.4474070782892556
Validation loss: 2.61849826613393

Epoch: 5| Step: 11
Training loss: 1.210712978098694
Validation loss: 2.6076675889802994

Epoch: 276| Step: 0
Training loss: 2.165448127338451
Validation loss: 2.5862449662970968

Epoch: 5| Step: 1
Training loss: 1.7908398990265189
Validation loss: 2.5823774427904667

Epoch: 5| Step: 2
Training loss: 1.9750086289229392
Validation loss: 2.541562802636697

Epoch: 5| Step: 3
Training loss: 2.5024546969921446
Validation loss: 2.541330953741844

Epoch: 5| Step: 4
Training loss: 2.7484131482874257
Validation loss: 2.5500894283059243

Epoch: 5| Step: 5
Training loss: 2.790774207488857
Validation loss: 2.5256476432529764

Epoch: 5| Step: 6
Training loss: 2.4150829935917892
Validation loss: 2.532055555896099

Epoch: 5| Step: 7
Training loss: 1.904905439117483
Validation loss: 2.5633468953595666

Epoch: 5| Step: 8
Training loss: 2.637084573870101
Validation loss: 2.55192027187372

Epoch: 5| Step: 9
Training loss: 2.0670594190851914
Validation loss: 2.5658427161189414

Epoch: 5| Step: 10
Training loss: 1.8923015884541925
Validation loss: 2.579436167213637

Epoch: 5| Step: 11
Training loss: 3.1191487273395864
Validation loss: 2.57827129141622

Epoch: 277| Step: 0
Training loss: 2.0580778398390147
Validation loss: 2.5640590119866036

Epoch: 5| Step: 1
Training loss: 2.4957428925886944
Validation loss: 2.554492944975468

Epoch: 5| Step: 2
Training loss: 2.4118742175668126
Validation loss: 2.537776453089197

Epoch: 5| Step: 3
Training loss: 2.865142841606264
Validation loss: 2.5210393093753702

Epoch: 5| Step: 4
Training loss: 1.938913506524959
Validation loss: 2.5364490028434283

Epoch: 5| Step: 5
Training loss: 2.068917895185559
Validation loss: 2.5191469239451787

Epoch: 5| Step: 6
Training loss: 2.143689933802834
Validation loss: 2.5324633559086056

Epoch: 5| Step: 7
Training loss: 1.9487773877189682
Validation loss: 2.5300407582418853

Epoch: 5| Step: 8
Training loss: 1.7818256585693255
Validation loss: 2.531285407364222

Epoch: 5| Step: 9
Training loss: 2.963706782366586
Validation loss: 2.551299918205202

Epoch: 5| Step: 10
Training loss: 2.7390719808010746
Validation loss: 2.548389581244988

Epoch: 5| Step: 11
Training loss: 1.2766172810523497
Validation loss: 2.584232613463134

Epoch: 278| Step: 0
Training loss: 1.9322110867899978
Validation loss: 2.5656516651064227

Epoch: 5| Step: 1
Training loss: 2.6843527174569943
Validation loss: 2.5933571521818264

Epoch: 5| Step: 2
Training loss: 2.6856226019152825
Validation loss: 2.599832805582462

Epoch: 5| Step: 3
Training loss: 2.3625574942561234
Validation loss: 2.607870776220709

Epoch: 5| Step: 4
Training loss: 2.4888865454791405
Validation loss: 2.582539203059432

Epoch: 5| Step: 5
Training loss: 2.2208813383581263
Validation loss: 2.5916371299884067

Epoch: 5| Step: 6
Training loss: 2.2955583184972292
Validation loss: 2.5747406063474565

Epoch: 5| Step: 7
Training loss: 2.2684491675308456
Validation loss: 2.562714366165088

Epoch: 5| Step: 8
Training loss: 1.7047046719952796
Validation loss: 2.537328787447358

Epoch: 5| Step: 9
Training loss: 1.9313762858066004
Validation loss: 2.5396969868109744

Epoch: 5| Step: 10
Training loss: 2.5357984014640107
Validation loss: 2.5202787724583637

Epoch: 5| Step: 11
Training loss: 3.0513884151433097
Validation loss: 2.522398609824382

Epoch: 279| Step: 0
Training loss: 2.270199596855794
Validation loss: 2.5388320896557417

Epoch: 5| Step: 1
Training loss: 2.1508298558716104
Validation loss: 2.5499747278170415

Epoch: 5| Step: 2
Training loss: 1.5039076767951836
Validation loss: 2.551804528609879

Epoch: 5| Step: 3
Training loss: 1.819624152622863
Validation loss: 2.563503100061052

Epoch: 5| Step: 4
Training loss: 2.487444726531146
Validation loss: 2.5840960627701413

Epoch: 5| Step: 5
Training loss: 2.729699371609041
Validation loss: 2.605949750173784

Epoch: 5| Step: 6
Training loss: 2.299449489887301
Validation loss: 2.6197533285522283

Epoch: 5| Step: 7
Training loss: 2.2937267291892076
Validation loss: 2.614185401123604

Epoch: 5| Step: 8
Training loss: 1.9167604699884393
Validation loss: 2.6118543727547383

Epoch: 5| Step: 9
Training loss: 2.9865874233405356
Validation loss: 2.637492464304881

Epoch: 5| Step: 10
Training loss: 2.4060888855735905
Validation loss: 2.6002293665901997

Epoch: 5| Step: 11
Training loss: 2.172421393514282
Validation loss: 2.593494785728922

Epoch: 280| Step: 0
Training loss: 1.8940631720814396
Validation loss: 2.535233918162601

Epoch: 5| Step: 1
Training loss: 2.8594048503714258
Validation loss: 2.49164531554023

Epoch: 5| Step: 2
Training loss: 1.6786220276229826
Validation loss: 2.4996959541127923

Epoch: 5| Step: 3
Training loss: 2.763118146548328
Validation loss: 2.476926221321921

Epoch: 5| Step: 4
Training loss: 2.3077728825954305
Validation loss: 2.4950633322520543

Epoch: 5| Step: 5
Training loss: 2.496917922852963
Validation loss: 2.480283418875576

Epoch: 5| Step: 6
Training loss: 2.0706346944898084
Validation loss: 2.4973317848454673

Epoch: 5| Step: 7
Training loss: 2.1879390820839597
Validation loss: 2.48600026915992

Epoch: 5| Step: 8
Training loss: 2.6068858992376875
Validation loss: 2.500178604898592

Epoch: 5| Step: 9
Training loss: 2.2675543626958015
Validation loss: 2.5021622327444573

Epoch: 5| Step: 10
Training loss: 2.3194358531110053
Validation loss: 2.5016131163826816

Epoch: 5| Step: 11
Training loss: 2.441032197907915
Validation loss: 2.5512004233313585

Epoch: 281| Step: 0
Training loss: 1.8643840988811857
Validation loss: 2.5718964331325944

Epoch: 5| Step: 1
Training loss: 2.65243579553098
Validation loss: 2.5675150345216946

Epoch: 5| Step: 2
Training loss: 2.917442182345539
Validation loss: 2.5660778282594654

Epoch: 5| Step: 3
Training loss: 2.4108465309805935
Validation loss: 2.5686578536077564

Epoch: 5| Step: 4
Training loss: 2.380701850017246
Validation loss: 2.581200318324048

Epoch: 5| Step: 5
Training loss: 2.5300502995251777
Validation loss: 2.5820506023503174

Epoch: 5| Step: 6
Training loss: 1.6336595446318438
Validation loss: 2.567150722154314

Epoch: 5| Step: 7
Training loss: 2.2735524361517685
Validation loss: 2.5669188585072527

Epoch: 5| Step: 8
Training loss: 2.118512404181562
Validation loss: 2.5497767450425006

Epoch: 5| Step: 9
Training loss: 1.6823910978082643
Validation loss: 2.5701168298884127

Epoch: 5| Step: 10
Training loss: 2.3394223758793307
Validation loss: 2.5632362412928282

Epoch: 5| Step: 11
Training loss: 2.1674060538060687
Validation loss: 2.58450414034344

Epoch: 282| Step: 0
Training loss: 2.0904827531396464
Validation loss: 2.5593405102155273

Epoch: 5| Step: 1
Training loss: 2.581409188966156
Validation loss: 2.5625307926405783

Epoch: 5| Step: 2
Training loss: 2.277666386410803
Validation loss: 2.570120409094229

Epoch: 5| Step: 3
Training loss: 1.975581653267877
Validation loss: 2.5402841631844604

Epoch: 5| Step: 4
Training loss: 2.7750096123331285
Validation loss: 2.5369508148991997

Epoch: 5| Step: 5
Training loss: 2.540461791404552
Validation loss: 2.5376391289689733

Epoch: 5| Step: 6
Training loss: 1.7923972688016916
Validation loss: 2.5380611460053357

Epoch: 5| Step: 7
Training loss: 1.984286689295103
Validation loss: 2.5498793732404454

Epoch: 5| Step: 8
Training loss: 2.441398242174367
Validation loss: 2.5588967102684177

Epoch: 5| Step: 9
Training loss: 2.4134238179071055
Validation loss: 2.5700860469665217

Epoch: 5| Step: 10
Training loss: 1.9796322592816387
Validation loss: 2.5832749842135105

Epoch: 5| Step: 11
Training loss: 3.0072043064079494
Validation loss: 2.606593120562634

Epoch: 283| Step: 0
Training loss: 1.693699222943759
Validation loss: 2.636060908635324

Epoch: 5| Step: 1
Training loss: 2.1334241053025385
Validation loss: 2.6046007303248753

Epoch: 5| Step: 2
Training loss: 2.079602512196533
Validation loss: 2.611716987836728

Epoch: 5| Step: 3
Training loss: 2.1993105718439496
Validation loss: 2.6019679145982537

Epoch: 5| Step: 4
Training loss: 2.889379779564999
Validation loss: 2.5952332288749353

Epoch: 5| Step: 5
Training loss: 2.5597454245468962
Validation loss: 2.58663633263841

Epoch: 5| Step: 6
Training loss: 2.4633198181869043
Validation loss: 2.563004889797478

Epoch: 5| Step: 7
Training loss: 2.231459415983877
Validation loss: 2.5283565584946244

Epoch: 5| Step: 8
Training loss: 2.2528233298407696
Validation loss: 2.5151391379576116

Epoch: 5| Step: 9
Training loss: 2.5029825539127617
Validation loss: 2.487151244170422

Epoch: 5| Step: 10
Training loss: 2.06848513011092
Validation loss: 2.5017498409245396

Epoch: 5| Step: 11
Training loss: 1.897932636962875
Validation loss: 2.501878980004001

Epoch: 284| Step: 0
Training loss: 1.9679277913252096
Validation loss: 2.489618679551205

Epoch: 5| Step: 1
Training loss: 2.063109336777391
Validation loss: 2.488230358902871

Epoch: 5| Step: 2
Training loss: 2.259666025246717
Validation loss: 2.503529818403302

Epoch: 5| Step: 3
Training loss: 1.8579851614089573
Validation loss: 2.508998178587316

Epoch: 5| Step: 4
Training loss: 2.171116209239998
Validation loss: 2.5219249778689345

Epoch: 5| Step: 5
Training loss: 2.611767340324197
Validation loss: 2.544762462698752

Epoch: 5| Step: 6
Training loss: 2.4283807803903183
Validation loss: 2.5416243867536488

Epoch: 5| Step: 7
Training loss: 2.5527605261189183
Validation loss: 2.558980272911222

Epoch: 5| Step: 8
Training loss: 1.8780736525842776
Validation loss: 2.5641848367397073

Epoch: 5| Step: 9
Training loss: 2.8331072848035657
Validation loss: 2.568411606328849

Epoch: 5| Step: 10
Training loss: 2.2979810478019895
Validation loss: 2.584488984515301

Epoch: 5| Step: 11
Training loss: 1.8445869098103316
Validation loss: 2.5528088660682644

Epoch: 285| Step: 0
Training loss: 2.0783456097291
Validation loss: 2.568935063850986

Epoch: 5| Step: 1
Training loss: 2.2833424208337236
Validation loss: 2.576823566906375

Epoch: 5| Step: 2
Training loss: 2.3711707716974426
Validation loss: 2.589910208116462

Epoch: 5| Step: 3
Training loss: 2.186752736657832
Validation loss: 2.567077026497721

Epoch: 5| Step: 4
Training loss: 2.259324778398331
Validation loss: 2.59490193597607

Epoch: 5| Step: 5
Training loss: 2.220687020678744
Validation loss: 2.6044427814334123

Epoch: 5| Step: 6
Training loss: 2.207383605376877
Validation loss: 2.6060166285719384

Epoch: 5| Step: 7
Training loss: 1.9963320237174171
Validation loss: 2.6093350557783883

Epoch: 5| Step: 8
Training loss: 2.82402989770446
Validation loss: 2.5660659897367357

Epoch: 5| Step: 9
Training loss: 2.4503008871796994
Validation loss: 2.5405338113020495

Epoch: 5| Step: 10
Training loss: 1.938857249202487
Validation loss: 2.519935516334691

Epoch: 5| Step: 11
Training loss: 2.070024347945315
Validation loss: 2.517553652419259

Epoch: 286| Step: 0
Training loss: 2.3999786892580572
Validation loss: 2.5308391214023387

Epoch: 5| Step: 1
Training loss: 2.4954477826484953
Validation loss: 2.503244396859357

Epoch: 5| Step: 2
Training loss: 2.535128882779143
Validation loss: 2.5051042901294647

Epoch: 5| Step: 3
Training loss: 1.877655183801811
Validation loss: 2.5097854554101664

Epoch: 5| Step: 4
Training loss: 1.6589202947525963
Validation loss: 2.5136813717109177

Epoch: 5| Step: 5
Training loss: 2.741525684276032
Validation loss: 2.5308330569258226

Epoch: 5| Step: 6
Training loss: 2.3363406238562803
Validation loss: 2.5328293453270585

Epoch: 5| Step: 7
Training loss: 2.085721808436763
Validation loss: 2.5376221351795896

Epoch: 5| Step: 8
Training loss: 2.383476590028189
Validation loss: 2.5483810480922067

Epoch: 5| Step: 9
Training loss: 2.3207971342906073
Validation loss: 2.561375093885126

Epoch: 5| Step: 10
Training loss: 2.0334384573146735
Validation loss: 2.5881006004511735

Epoch: 5| Step: 11
Training loss: 3.0978020228448586
Validation loss: 2.6133933924708064

Epoch: 287| Step: 0
Training loss: 2.781306748400602
Validation loss: 2.6388017842210956

Epoch: 5| Step: 1
Training loss: 2.710636177136697
Validation loss: 2.690541154660475

Epoch: 5| Step: 2
Training loss: 2.065350729873775
Validation loss: 2.7119754779268725

Epoch: 5| Step: 3
Training loss: 2.5157541751275363
Validation loss: 2.699099713363002

Epoch: 5| Step: 4
Training loss: 2.3692873463558723
Validation loss: 2.6644747742278243

Epoch: 5| Step: 5
Training loss: 1.7145048949360049
Validation loss: 2.6148597348281846

Epoch: 5| Step: 6
Training loss: 2.641920686014977
Validation loss: 2.5514199555995867

Epoch: 5| Step: 7
Training loss: 2.400794843342883
Validation loss: 2.5083805561901085

Epoch: 5| Step: 8
Training loss: 2.080292109555262
Validation loss: 2.486111583804388

Epoch: 5| Step: 9
Training loss: 1.9548945840966514
Validation loss: 2.480279986390433

Epoch: 5| Step: 10
Training loss: 2.4993407333860063
Validation loss: 2.4896678484586454

Epoch: 5| Step: 11
Training loss: 1.092725546488843
Validation loss: 2.497861372617

Epoch: 288| Step: 0
Training loss: 2.607295778347243
Validation loss: 2.494226468649483

Epoch: 5| Step: 1
Training loss: 1.8126202905134812
Validation loss: 2.4912753653235877

Epoch: 5| Step: 2
Training loss: 2.1419088036279885
Validation loss: 2.50826278399321

Epoch: 5| Step: 3
Training loss: 2.2617708243006662
Validation loss: 2.4943741281090976

Epoch: 5| Step: 4
Training loss: 2.7805745879885464
Validation loss: 2.5106535611163436

Epoch: 5| Step: 5
Training loss: 2.3428525096402226
Validation loss: 2.5102488882473106

Epoch: 5| Step: 6
Training loss: 1.8981787736829088
Validation loss: 2.5253132402365224

Epoch: 5| Step: 7
Training loss: 2.3993274143644507
Validation loss: 2.5510187939051625

Epoch: 5| Step: 8
Training loss: 2.2088916600583297
Validation loss: 2.552940576305549

Epoch: 5| Step: 9
Training loss: 1.8443733713264991
Validation loss: 2.5520224557479554

Epoch: 5| Step: 10
Training loss: 2.9288332087784976
Validation loss: 2.5627519805421

Epoch: 5| Step: 11
Training loss: 3.6480908770368017
Validation loss: 2.57043694423898

Epoch: 289| Step: 0
Training loss: 2.705931336844902
Validation loss: 2.6158759555420863

Epoch: 5| Step: 1
Training loss: 1.8380814391431646
Validation loss: 2.591001935378549

Epoch: 5| Step: 2
Training loss: 1.903687427516868
Validation loss: 2.6247154906661794

Epoch: 5| Step: 3
Training loss: 2.043298873341127
Validation loss: 2.590399481601989

Epoch: 5| Step: 4
Training loss: 2.0560453736311795
Validation loss: 2.5842815563709243

Epoch: 5| Step: 5
Training loss: 2.3239147853034128
Validation loss: 2.571885127391011

Epoch: 5| Step: 6
Training loss: 2.532841876528533
Validation loss: 2.561704232935884

Epoch: 5| Step: 7
Training loss: 2.6030090709210216
Validation loss: 2.554521428892241

Epoch: 5| Step: 8
Training loss: 1.871341250939783
Validation loss: 2.564744683392767

Epoch: 5| Step: 9
Training loss: 2.5424626985137344
Validation loss: 2.5519977334646744

Epoch: 5| Step: 10
Training loss: 2.467001573491764
Validation loss: 2.555160330938244

Epoch: 5| Step: 11
Training loss: 3.5051120482205778
Validation loss: 2.5602697770021283

Epoch: 290| Step: 0
Training loss: 2.6254742511858953
Validation loss: 2.5470834151416253

Epoch: 5| Step: 1
Training loss: 2.613936041436964
Validation loss: 2.538097804766969

Epoch: 5| Step: 2
Training loss: 2.7299662770294915
Validation loss: 2.544809248670025

Epoch: 5| Step: 3
Training loss: 2.102937836842492
Validation loss: 2.546706948850099

Epoch: 5| Step: 4
Training loss: 2.4379649574696716
Validation loss: 2.5492105014491044

Epoch: 5| Step: 5
Training loss: 2.5263546359794025
Validation loss: 2.554440921000969

Epoch: 5| Step: 6
Training loss: 2.3209788589007774
Validation loss: 2.553029154982736

Epoch: 5| Step: 7
Training loss: 1.7713368616228111
Validation loss: 2.5462942026752637

Epoch: 5| Step: 8
Training loss: 2.298481800889399
Validation loss: 2.5455111809128246

Epoch: 5| Step: 9
Training loss: 1.8484571467151159
Validation loss: 2.5434238126287814

Epoch: 5| Step: 10
Training loss: 1.7513577099064332
Validation loss: 2.539877712742753

Epoch: 5| Step: 11
Training loss: 1.5822581940811102
Validation loss: 2.5440303932259756

Epoch: 291| Step: 0
Training loss: 1.955943279169446
Validation loss: 2.5365244088519003

Epoch: 5| Step: 1
Training loss: 1.8071812166292425
Validation loss: 2.560026964235606

Epoch: 5| Step: 2
Training loss: 1.6466106398056262
Validation loss: 2.5405431587234837

Epoch: 5| Step: 3
Training loss: 2.0671193960076604
Validation loss: 2.5370547372183014

Epoch: 5| Step: 4
Training loss: 2.6741018552247966
Validation loss: 2.548773247333876

Epoch: 5| Step: 5
Training loss: 1.9808612863346748
Validation loss: 2.53997834340948

Epoch: 5| Step: 6
Training loss: 2.9601795363749885
Validation loss: 2.56166764829125

Epoch: 5| Step: 7
Training loss: 2.1651483008357224
Validation loss: 2.5447636221111876

Epoch: 5| Step: 8
Training loss: 2.214092254977151
Validation loss: 2.559263162183886

Epoch: 5| Step: 9
Training loss: 2.463055961316978
Validation loss: 2.563285621919152

Epoch: 5| Step: 10
Training loss: 2.4107245914299495
Validation loss: 2.5722585536557387

Epoch: 5| Step: 11
Training loss: 3.2348924305880074
Validation loss: 2.579405129634679

Epoch: 292| Step: 0
Training loss: 2.4348336332539757
Validation loss: 2.5917289052299624

Epoch: 5| Step: 1
Training loss: 2.475974605830654
Validation loss: 2.590597592474582

Epoch: 5| Step: 2
Training loss: 1.5971229614521867
Validation loss: 2.610588050649604

Epoch: 5| Step: 3
Training loss: 2.11638657175958
Validation loss: 2.6232639127325

Epoch: 5| Step: 4
Training loss: 2.5523089146988114
Validation loss: 2.5909047894845205

Epoch: 5| Step: 5
Training loss: 2.4844097398932146
Validation loss: 2.563537562053256

Epoch: 5| Step: 6
Training loss: 2.183585451823454
Validation loss: 2.549735715204255

Epoch: 5| Step: 7
Training loss: 2.3489260674831187
Validation loss: 2.535682850805324

Epoch: 5| Step: 8
Training loss: 2.010911976045404
Validation loss: 2.5280638921179412

Epoch: 5| Step: 9
Training loss: 2.0274518228585485
Validation loss: 2.520602362799335

Epoch: 5| Step: 10
Training loss: 2.5079967395450993
Validation loss: 2.5080638692177275

Epoch: 5| Step: 11
Training loss: 2.2156716066093733
Validation loss: 2.5158452279183607

Epoch: 293| Step: 0
Training loss: 2.261659506119047
Validation loss: 2.516759391575406

Epoch: 5| Step: 1
Training loss: 2.28040256175493
Validation loss: 2.5157359515377906

Epoch: 5| Step: 2
Training loss: 2.5225835246840824
Validation loss: 2.512209127046522

Epoch: 5| Step: 3
Training loss: 2.438090228488223
Validation loss: 2.5216612966782432

Epoch: 5| Step: 4
Training loss: 2.0019700361328416
Validation loss: 2.536001557273467

Epoch: 5| Step: 5
Training loss: 2.2348010317246825
Validation loss: 2.559934079624107

Epoch: 5| Step: 6
Training loss: 2.267702399897198
Validation loss: 2.5686627865114846

Epoch: 5| Step: 7
Training loss: 2.3638097250991645
Validation loss: 2.583315150648137

Epoch: 5| Step: 8
Training loss: 1.9668782131191855
Validation loss: 2.6066672958457007

Epoch: 5| Step: 9
Training loss: 2.1939482335787996
Validation loss: 2.613643740843362

Epoch: 5| Step: 10
Training loss: 2.161689310869463
Validation loss: 2.653564554204473

Epoch: 5| Step: 11
Training loss: 1.6187025703934357
Validation loss: 2.6525659444679084

Epoch: 294| Step: 0
Training loss: 2.2584753416487526
Validation loss: 2.6741505761186004

Epoch: 5| Step: 1
Training loss: 2.967331396774909
Validation loss: 2.6327750017493563

Epoch: 5| Step: 2
Training loss: 2.2081312291014004
Validation loss: 2.59891081226965

Epoch: 5| Step: 3
Training loss: 2.452335886777076
Validation loss: 2.5834658663090524

Epoch: 5| Step: 4
Training loss: 2.148622705973129
Validation loss: 2.5604587426283647

Epoch: 5| Step: 5
Training loss: 2.487329992877752
Validation loss: 2.5545136512142204

Epoch: 5| Step: 6
Training loss: 1.7298317591496488
Validation loss: 2.5435277204380915

Epoch: 5| Step: 7
Training loss: 1.981082979015486
Validation loss: 2.528356711728621

Epoch: 5| Step: 8
Training loss: 2.5277839760710163
Validation loss: 2.5314825641873733

Epoch: 5| Step: 9
Training loss: 2.009639161397139
Validation loss: 2.5372681013794622

Epoch: 5| Step: 10
Training loss: 1.700528747010523
Validation loss: 2.5412118627298153

Epoch: 5| Step: 11
Training loss: 2.319855307802494
Validation loss: 2.537563084693559

Epoch: 295| Step: 0
Training loss: 1.8810866427546735
Validation loss: 2.5222120035438773

Epoch: 5| Step: 1
Training loss: 2.6852853210700345
Validation loss: 2.5476085370994603

Epoch: 5| Step: 2
Training loss: 2.3754499912606506
Validation loss: 2.5652188206075186

Epoch: 5| Step: 3
Training loss: 1.3989442301494004
Validation loss: 2.596430806387451

Epoch: 5| Step: 4
Training loss: 2.403345212532275
Validation loss: 2.588759980439589

Epoch: 5| Step: 5
Training loss: 2.0588865126264246
Validation loss: 2.6099009031481133

Epoch: 5| Step: 6
Training loss: 2.295527679349599
Validation loss: 2.6314556123040282

Epoch: 5| Step: 7
Training loss: 2.066616458693124
Validation loss: 2.6212707285439674

Epoch: 5| Step: 8
Training loss: 2.8142443863432423
Validation loss: 2.5937103743379644

Epoch: 5| Step: 9
Training loss: 1.6699317262593198
Validation loss: 2.5897118528600553

Epoch: 5| Step: 10
Training loss: 2.640483423534588
Validation loss: 2.58703249349071

Epoch: 5| Step: 11
Training loss: 1.8266146689112186
Validation loss: 2.5697984925483404

Epoch: 296| Step: 0
Training loss: 1.7679453768599025
Validation loss: 2.576807926411307

Epoch: 5| Step: 1
Training loss: 2.211662362369277
Validation loss: 2.566415272875388

Epoch: 5| Step: 2
Training loss: 2.1197271563737305
Validation loss: 2.551027629767466

Epoch: 5| Step: 3
Training loss: 2.30523757835577
Validation loss: 2.5606773919333876

Epoch: 5| Step: 4
Training loss: 1.6653179035897259
Validation loss: 2.5827999730853524

Epoch: 5| Step: 5
Training loss: 2.037227813701009
Validation loss: 2.5936827899850234

Epoch: 5| Step: 6
Training loss: 2.295384137286724
Validation loss: 2.5846238847886864

Epoch: 5| Step: 7
Training loss: 2.24814985289635
Validation loss: 2.591985918407837

Epoch: 5| Step: 8
Training loss: 2.1828216661767326
Validation loss: 2.5991372420832755

Epoch: 5| Step: 9
Training loss: 2.3703135380400044
Validation loss: 2.610516732381633

Epoch: 5| Step: 10
Training loss: 2.6163524605070547
Validation loss: 2.618237864445286

Epoch: 5| Step: 11
Training loss: 3.837854345407405
Validation loss: 2.5646249055527273

Epoch: 297| Step: 0
Training loss: 2.949241547149059
Validation loss: 2.5361264081484105

Epoch: 5| Step: 1
Training loss: 2.399323936449654
Validation loss: 2.540101469652628

Epoch: 5| Step: 2
Training loss: 1.891576984425057
Validation loss: 2.5385545427895635

Epoch: 5| Step: 3
Training loss: 2.3839918876228303
Validation loss: 2.5645993867232773

Epoch: 5| Step: 4
Training loss: 2.1407856010836603
Validation loss: 2.5689234782513775

Epoch: 5| Step: 5
Training loss: 1.742167519767015
Validation loss: 2.543324816221031

Epoch: 5| Step: 6
Training loss: 1.2681257243598536
Validation loss: 2.568166488153897

Epoch: 5| Step: 7
Training loss: 2.7878274186462844
Validation loss: 2.569525690054356

Epoch: 5| Step: 8
Training loss: 1.7896278520878317
Validation loss: 2.579592323819514

Epoch: 5| Step: 9
Training loss: 2.6733820719410244
Validation loss: 2.602313417311167

Epoch: 5| Step: 10
Training loss: 2.025305515366141
Validation loss: 2.589307546366963

Epoch: 5| Step: 11
Training loss: 1.807485417983881
Validation loss: 2.597094925964161

Epoch: 298| Step: 0
Training loss: 1.9768373200319787
Validation loss: 2.5700325663676513

Epoch: 5| Step: 1
Training loss: 1.9104120438192909
Validation loss: 2.568741732952988

Epoch: 5| Step: 2
Training loss: 2.261777570681043
Validation loss: 2.5692008879646018

Epoch: 5| Step: 3
Training loss: 1.4554420784079536
Validation loss: 2.5688518791693338

Epoch: 5| Step: 4
Training loss: 2.5904054334704862
Validation loss: 2.5334141078942034

Epoch: 5| Step: 5
Training loss: 1.8916677326529885
Validation loss: 2.5723668539316584

Epoch: 5| Step: 6
Training loss: 2.9507216912385195
Validation loss: 2.599374991268113

Epoch: 5| Step: 7
Training loss: 1.8443764091235537
Validation loss: 2.61357058836857

Epoch: 5| Step: 8
Training loss: 2.0055409209309505
Validation loss: 2.6247636749214616

Epoch: 5| Step: 9
Training loss: 2.0878052082913663
Validation loss: 2.624399139118853

Epoch: 5| Step: 10
Training loss: 2.9176348759480075
Validation loss: 2.6120261583953504

Epoch: 5| Step: 11
Training loss: 3.5437869438385134
Validation loss: 2.616673550981427

Epoch: 299| Step: 0
Training loss: 2.9935443082798634
Validation loss: 2.5874044784630197

Epoch: 5| Step: 1
Training loss: 2.5794962617448136
Validation loss: 2.544163198286488

Epoch: 5| Step: 2
Training loss: 1.8406751175745957
Validation loss: 2.5379576680598794

Epoch: 5| Step: 3
Training loss: 2.184008291130956
Validation loss: 2.518425825632916

Epoch: 5| Step: 4
Training loss: 2.242652552422294
Validation loss: 2.526428727190685

Epoch: 5| Step: 5
Training loss: 1.573936796850994
Validation loss: 2.529743499795762

Epoch: 5| Step: 6
Training loss: 1.9439486583005217
Validation loss: 2.5384222680868036

Epoch: 5| Step: 7
Training loss: 2.467853141798775
Validation loss: 2.5489778847380418

Epoch: 5| Step: 8
Training loss: 2.0048620015739798
Validation loss: 2.5590803697951023

Epoch: 5| Step: 9
Training loss: 2.1117867704748594
Validation loss: 2.5576934900174444

Epoch: 5| Step: 10
Training loss: 2.0773191108404454
Validation loss: 2.5794825823129828

Epoch: 5| Step: 11
Training loss: 3.4869367137752905
Validation loss: 2.5863525157478002

Epoch: 300| Step: 0
Training loss: 2.641984307559449
Validation loss: 2.6253756564659145

Epoch: 5| Step: 1
Training loss: 1.731548446105311
Validation loss: 2.6049257062347566

Epoch: 5| Step: 2
Training loss: 2.2183400164856275
Validation loss: 2.6162303825587037

Epoch: 5| Step: 3
Training loss: 2.2006860313630554
Validation loss: 2.6025107205048283

Epoch: 5| Step: 4
Training loss: 1.6597573911947892
Validation loss: 2.6047091694651106

Epoch: 5| Step: 5
Training loss: 1.5518458481261712
Validation loss: 2.5787521447231185

Epoch: 5| Step: 6
Training loss: 2.3940922146392034
Validation loss: 2.5672134376433733

Epoch: 5| Step: 7
Training loss: 2.3043204322357047
Validation loss: 2.5593781567104994

Epoch: 5| Step: 8
Training loss: 1.9509807565620902
Validation loss: 2.546960505510949

Epoch: 5| Step: 9
Training loss: 2.8116228219235295
Validation loss: 2.529072515682385

Epoch: 5| Step: 10
Training loss: 2.6384525730308392
Validation loss: 2.5402212286615873

Epoch: 5| Step: 11
Training loss: 1.818390384004025
Validation loss: 2.541068686171472

Epoch: 301| Step: 0
Training loss: 2.2056886083003397
Validation loss: 2.583664187784334

Epoch: 5| Step: 1
Training loss: 2.13205557446217
Validation loss: 2.6207033142280824

Epoch: 5| Step: 2
Training loss: 1.757533954167566
Validation loss: 2.6701101270685603

Epoch: 5| Step: 3
Training loss: 2.5480445095708015
Validation loss: 2.670553501504337

Epoch: 5| Step: 4
Training loss: 2.08407532512261
Validation loss: 2.6550420033819506

Epoch: 5| Step: 5
Training loss: 1.8218085563151352
Validation loss: 2.6047852595274716

Epoch: 5| Step: 6
Training loss: 2.459587477699324
Validation loss: 2.5606793510721553

Epoch: 5| Step: 7
Training loss: 2.4170636037428914
Validation loss: 2.5326870383006233

Epoch: 5| Step: 8
Training loss: 2.01735287911039
Validation loss: 2.504392179013394

Epoch: 5| Step: 9
Training loss: 2.4429239423282274
Validation loss: 2.5123415106197897

Epoch: 5| Step: 10
Training loss: 2.9047767432561185
Validation loss: 2.5219527128993744

Epoch: 5| Step: 11
Training loss: 1.922144118904647
Validation loss: 2.5246255319983257

Epoch: 302| Step: 0
Training loss: 2.586307464595445
Validation loss: 2.519248694216838

Epoch: 5| Step: 1
Training loss: 2.190961224796553
Validation loss: 2.5469138994737235

Epoch: 5| Step: 2
Training loss: 2.5033773497442215
Validation loss: 2.591205614764562

Epoch: 5| Step: 3
Training loss: 1.7569451799085416
Validation loss: 2.57022074078584

Epoch: 5| Step: 4
Training loss: 2.2435277462172993
Validation loss: 2.60289572919283

Epoch: 5| Step: 5
Training loss: 1.301311213128161
Validation loss: 2.567183428664567

Epoch: 5| Step: 6
Training loss: 2.590519283332613
Validation loss: 2.577708181729969

Epoch: 5| Step: 7
Training loss: 2.8346933205046145
Validation loss: 2.5754291773970874

Epoch: 5| Step: 8
Training loss: 2.1808608530494946
Validation loss: 2.5651495501897474

Epoch: 5| Step: 9
Training loss: 2.055954459149848
Validation loss: 2.558223850991279

Epoch: 5| Step: 10
Training loss: 1.9997672899283025
Validation loss: 2.5451866162485635

Epoch: 5| Step: 11
Training loss: 1.5227172714070585
Validation loss: 2.541963338474506

Epoch: 303| Step: 0
Training loss: 2.236623313112219
Validation loss: 2.542520857675095

Epoch: 5| Step: 1
Training loss: 1.5154603691746413
Validation loss: 2.520907827858181

Epoch: 5| Step: 2
Training loss: 1.9615572979541915
Validation loss: 2.5502432800629244

Epoch: 5| Step: 3
Training loss: 2.6897851853943457
Validation loss: 2.5574887129210455

Epoch: 5| Step: 4
Training loss: 1.8070104272073957
Validation loss: 2.5868417324861874

Epoch: 5| Step: 5
Training loss: 1.8470144306356457
Validation loss: 2.5752558801727865

Epoch: 5| Step: 6
Training loss: 1.9740907797419012
Validation loss: 2.582614238442782

Epoch: 5| Step: 7
Training loss: 2.4650714364059456
Validation loss: 2.5820893450889595

Epoch: 5| Step: 8
Training loss: 2.6756125738064327
Validation loss: 2.5531915684787645

Epoch: 5| Step: 9
Training loss: 2.434082178175146
Validation loss: 2.5904893794374315

Epoch: 5| Step: 10
Training loss: 2.5407913660287096
Validation loss: 2.5672618962763063

Epoch: 5| Step: 11
Training loss: 1.3485092780501606
Validation loss: 2.582984132904564

Epoch: 304| Step: 0
Training loss: 2.8896642789570843
Validation loss: 2.570130593956076

Epoch: 5| Step: 1
Training loss: 1.9715103295849186
Validation loss: 2.5684938770268486

Epoch: 5| Step: 2
Training loss: 2.8505171858679805
Validation loss: 2.581677076371272

Epoch: 5| Step: 3
Training loss: 1.8775916943464335
Validation loss: 2.60825762933389

Epoch: 5| Step: 4
Training loss: 2.786810299519473
Validation loss: 2.6290782817386704

Epoch: 5| Step: 5
Training loss: 1.6306959241632142
Validation loss: 2.6408185568151645

Epoch: 5| Step: 6
Training loss: 2.0179053130832427
Validation loss: 2.6046767625318514

Epoch: 5| Step: 7
Training loss: 2.482606366232759
Validation loss: 2.5935590168143827

Epoch: 5| Step: 8
Training loss: 2.3724034822566105
Validation loss: 2.5604258105427977

Epoch: 5| Step: 9
Training loss: 1.5816663533174602
Validation loss: 2.563538325458836

Epoch: 5| Step: 10
Training loss: 1.5260408507812542
Validation loss: 2.529277189710839

Epoch: 5| Step: 11
Training loss: 1.9926997704196479
Validation loss: 2.530380990733597

Epoch: 305| Step: 0
Training loss: 2.188325017936037
Validation loss: 2.535116993777002

Epoch: 5| Step: 1
Training loss: 2.266390125384298
Validation loss: 2.5374076145247892

Epoch: 5| Step: 2
Training loss: 1.9094475365578765
Validation loss: 2.547129109349502

Epoch: 5| Step: 3
Training loss: 1.8994499615020133
Validation loss: 2.553465085081154

Epoch: 5| Step: 4
Training loss: 2.0637813402611616
Validation loss: 2.547572030792049

Epoch: 5| Step: 5
Training loss: 2.12182480945133
Validation loss: 2.556464624138885

Epoch: 5| Step: 6
Training loss: 2.392438612003876
Validation loss: 2.5656881000164082

Epoch: 5| Step: 7
Training loss: 2.3391711457629434
Validation loss: 2.5803438637448814

Epoch: 5| Step: 8
Training loss: 2.3872990628513056
Validation loss: 2.5897640409712848

Epoch: 5| Step: 9
Training loss: 2.0822334692339255
Validation loss: 2.6337888399641964

Epoch: 5| Step: 10
Training loss: 2.852214916269261
Validation loss: 2.634707775192544

Epoch: 5| Step: 11
Training loss: 1.1999584985550102
Validation loss: 2.631525515601575

Epoch: 306| Step: 0
Training loss: 2.233646407412316
Validation loss: 2.613688613472364

Epoch: 5| Step: 1
Training loss: 1.6727841481144128
Validation loss: 2.585799944427767

Epoch: 5| Step: 2
Training loss: 2.2205133013087455
Validation loss: 2.550222015221582

Epoch: 5| Step: 3
Training loss: 2.6759698731703763
Validation loss: 2.5430013651594785

Epoch: 5| Step: 4
Training loss: 1.4706980995203813
Validation loss: 2.5131865899692123

Epoch: 5| Step: 5
Training loss: 1.8453638158473644
Validation loss: 2.5095646244609755

Epoch: 5| Step: 6
Training loss: 2.3338333911023548
Validation loss: 2.516470085975819

Epoch: 5| Step: 7
Training loss: 2.83517571929024
Validation loss: 2.5139491084709262

Epoch: 5| Step: 8
Training loss: 2.2997703727867282
Validation loss: 2.5055045642043603

Epoch: 5| Step: 9
Training loss: 2.321406251150289
Validation loss: 2.506183205917085

Epoch: 5| Step: 10
Training loss: 2.3245253416810563
Validation loss: 2.523006111016913

Epoch: 5| Step: 11
Training loss: 1.7254476270528736
Validation loss: 2.531937462657631

Epoch: 307| Step: 0
Training loss: 2.357479824817206
Validation loss: 2.5308124454474954

Epoch: 5| Step: 1
Training loss: 1.980783952839208
Validation loss: 2.575449775098699

Epoch: 5| Step: 2
Training loss: 1.9447726684143634
Validation loss: 2.5815072040017726

Epoch: 5| Step: 3
Training loss: 2.293109843967411
Validation loss: 2.609051290294505

Epoch: 5| Step: 4
Training loss: 2.304441897996709
Validation loss: 2.607473259084973

Epoch: 5| Step: 5
Training loss: 2.426691004487841
Validation loss: 2.5754149093420327

Epoch: 5| Step: 6
Training loss: 1.993819581733918
Validation loss: 2.5536672827914053

Epoch: 5| Step: 7
Training loss: 2.179951204051292
Validation loss: 2.5286227748040817

Epoch: 5| Step: 8
Training loss: 2.9259171702615654
Validation loss: 2.516512041099619

Epoch: 5| Step: 9
Training loss: 2.517623391939338
Validation loss: 2.5010678315505293

Epoch: 5| Step: 10
Training loss: 1.859567007200711
Validation loss: 2.505254897056965

Epoch: 5| Step: 11
Training loss: 2.0112157100127646
Validation loss: 2.486288295605627

Epoch: 308| Step: 0
Training loss: 2.5919335680678346
Validation loss: 2.5078659012318933

Epoch: 5| Step: 1
Training loss: 2.4601860715694626
Validation loss: 2.507182470943677

Epoch: 5| Step: 2
Training loss: 2.8619873120808412
Validation loss: 2.516847593759647

Epoch: 5| Step: 3
Training loss: 1.3242516527617492
Validation loss: 2.5592708400324855

Epoch: 5| Step: 4
Training loss: 1.9125279094180505
Validation loss: 2.5993985674090028

Epoch: 5| Step: 5
Training loss: 1.8408575484256193
Validation loss: 2.6748654062808064

Epoch: 5| Step: 6
Training loss: 2.173347248586717
Validation loss: 2.6380770916728227

Epoch: 5| Step: 7
Training loss: 2.2870015836442503
Validation loss: 2.6308141306588264

Epoch: 5| Step: 8
Training loss: 2.279127622987092
Validation loss: 2.569487384202506

Epoch: 5| Step: 9
Training loss: 2.2548172562471276
Validation loss: 2.562476514693156

Epoch: 5| Step: 10
Training loss: 2.2965246439383282
Validation loss: 2.560108134617203

Epoch: 5| Step: 11
Training loss: 2.7833051482123166
Validation loss: 2.5106240393963053

Epoch: 309| Step: 0
Training loss: 1.9372004000459928
Validation loss: 2.5237080573667896

Epoch: 5| Step: 1
Training loss: 2.3052268221585313
Validation loss: 2.4925179377043984

Epoch: 5| Step: 2
Training loss: 2.3213096043211836
Validation loss: 2.504226108698177

Epoch: 5| Step: 3
Training loss: 2.9325916595313326
Validation loss: 2.5264907057640453

Epoch: 5| Step: 4
Training loss: 2.3725635680032493
Validation loss: 2.512236860596792

Epoch: 5| Step: 5
Training loss: 2.3340121598764587
Validation loss: 2.524120128251271

Epoch: 5| Step: 6
Training loss: 1.9784357293915948
Validation loss: 2.5522083148066246

Epoch: 5| Step: 7
Training loss: 1.7823099696878504
Validation loss: 2.577881899845301

Epoch: 5| Step: 8
Training loss: 1.8297164380450714
Validation loss: 2.5808490772791495

Epoch: 5| Step: 9
Training loss: 1.8102162541769966
Validation loss: 2.613490493068672

Epoch: 5| Step: 10
Training loss: 2.5996212976928885
Validation loss: 2.6145474759463556

Epoch: 5| Step: 11
Training loss: 1.74169463297949
Validation loss: 2.6227258848949986

Epoch: 310| Step: 0
Training loss: 2.231776293492324
Validation loss: 2.609128472109445

Epoch: 5| Step: 1
Training loss: 2.5717825816202358
Validation loss: 2.593701042341372

Epoch: 5| Step: 2
Training loss: 2.1723248132586703
Validation loss: 2.55843558951018

Epoch: 5| Step: 3
Training loss: 1.444509582191975
Validation loss: 2.56704108342507

Epoch: 5| Step: 4
Training loss: 1.6877792974976815
Validation loss: 2.559631265426086

Epoch: 5| Step: 5
Training loss: 2.520604577732568
Validation loss: 2.5349292545742395

Epoch: 5| Step: 6
Training loss: 2.4110402568049505
Validation loss: 2.516287769653835

Epoch: 5| Step: 7
Training loss: 1.8196975258589174
Validation loss: 2.5478547986790927

Epoch: 5| Step: 8
Training loss: 2.330477351787574
Validation loss: 2.5414683519967447

Epoch: 5| Step: 9
Training loss: 2.2183328155738615
Validation loss: 2.531369379156232

Epoch: 5| Step: 10
Training loss: 2.137840632016711
Validation loss: 2.550430188013597

Epoch: 5| Step: 11
Training loss: 2.670201362989071
Validation loss: 2.5478728705193

Epoch: 311| Step: 0
Training loss: 2.113132661965218
Validation loss: 2.5634479746359813

Epoch: 5| Step: 1
Training loss: 2.463217608461197
Validation loss: 2.5926984087666085

Epoch: 5| Step: 2
Training loss: 2.0501085903901184
Validation loss: 2.5760401840812426

Epoch: 5| Step: 3
Training loss: 2.0469455852422827
Validation loss: 2.56907307773484

Epoch: 5| Step: 4
Training loss: 2.566456508289523
Validation loss: 2.581112562096731

Epoch: 5| Step: 5
Training loss: 2.2296695914347926
Validation loss: 2.582725389276623

Epoch: 5| Step: 6
Training loss: 2.2592595620957097
Validation loss: 2.5705724544149224

Epoch: 5| Step: 7
Training loss: 1.834438994816932
Validation loss: 2.5777388119687084

Epoch: 5| Step: 8
Training loss: 1.8006068081054314
Validation loss: 2.594210074498944

Epoch: 5| Step: 9
Training loss: 2.808878962395964
Validation loss: 2.545928572503323

Epoch: 5| Step: 10
Training loss: 1.5377872043723724
Validation loss: 2.5263721066409697

Epoch: 5| Step: 11
Training loss: 2.648684329793576
Validation loss: 2.5512920878750154

Epoch: 312| Step: 0
Training loss: 1.956303444031783
Validation loss: 2.545609547903528

Epoch: 5| Step: 1
Training loss: 2.250057007809161
Validation loss: 2.537484282020533

Epoch: 5| Step: 2
Training loss: 2.3518437315610714
Validation loss: 2.5620470596492297

Epoch: 5| Step: 3
Training loss: 2.719768289626043
Validation loss: 2.593577333241282

Epoch: 5| Step: 4
Training loss: 1.4911703267841154
Validation loss: 2.594286652471906

Epoch: 5| Step: 5
Training loss: 2.3742911636240165
Validation loss: 2.605158236872404

Epoch: 5| Step: 6
Training loss: 1.781515871249754
Validation loss: 2.605041617593718

Epoch: 5| Step: 7
Training loss: 2.456434410879642
Validation loss: 2.625198530833697

Epoch: 5| Step: 8
Training loss: 1.4089386562695827
Validation loss: 2.620303945085743

Epoch: 5| Step: 9
Training loss: 1.9213825618403253
Validation loss: 2.620408773577665

Epoch: 5| Step: 10
Training loss: 2.9792412346175343
Validation loss: 2.5864821568248533

Epoch: 5| Step: 11
Training loss: 1.3930765466491473
Validation loss: 2.5922441055957304

Epoch: 313| Step: 0
Training loss: 2.1858712808696588
Validation loss: 2.55150689731991

Epoch: 5| Step: 1
Training loss: 2.2279748553050553
Validation loss: 2.5518187690672867

Epoch: 5| Step: 2
Training loss: 1.7812635187004136
Validation loss: 2.5315914120035785

Epoch: 5| Step: 3
Training loss: 2.197880556313135
Validation loss: 2.5181918544168145

Epoch: 5| Step: 4
Training loss: 2.380613719606001
Validation loss: 2.535181179619598

Epoch: 5| Step: 5
Training loss: 2.2970596550654587
Validation loss: 2.532495482661344

Epoch: 5| Step: 6
Training loss: 2.1874520432801243
Validation loss: 2.5612333470143396

Epoch: 5| Step: 7
Training loss: 2.114702969879664
Validation loss: 2.5923203469347196

Epoch: 5| Step: 8
Training loss: 1.9537373307708754
Validation loss: 2.617147227115031

Epoch: 5| Step: 9
Training loss: 3.036793781332034
Validation loss: 2.6237252106994102

Epoch: 5| Step: 10
Training loss: 1.5967721894793272
Validation loss: 2.6463132983628643

Epoch: 5| Step: 11
Training loss: 1.2953339118246168
Validation loss: 2.6219673804284374

Epoch: 314| Step: 0
Training loss: 1.8034729276464851
Validation loss: 2.640282633179034

Epoch: 5| Step: 1
Training loss: 2.1613992215694955
Validation loss: 2.633602665203632

Epoch: 5| Step: 2
Training loss: 1.9291717828582526
Validation loss: 2.591389516493315

Epoch: 5| Step: 3
Training loss: 2.389032768628358
Validation loss: 2.5598653647290215

Epoch: 5| Step: 4
Training loss: 2.3295489571284924
Validation loss: 2.55052549083789

Epoch: 5| Step: 5
Training loss: 1.7894208124487259
Validation loss: 2.5666548261637696

Epoch: 5| Step: 6
Training loss: 2.611151906860396
Validation loss: 2.565799608534472

Epoch: 5| Step: 7
Training loss: 2.490245098016129
Validation loss: 2.5979464758412183

Epoch: 5| Step: 8
Training loss: 1.6541481356539687
Validation loss: 2.58678145913003

Epoch: 5| Step: 9
Training loss: 2.501472421009532
Validation loss: 2.60178550321938

Epoch: 5| Step: 10
Training loss: 2.1325727055488413
Validation loss: 2.6306316954060094

Epoch: 5| Step: 11
Training loss: 2.098049020490897
Validation loss: 2.638338543713458

Epoch: 315| Step: 0
Training loss: 3.0649489906634093
Validation loss: 2.6159940475205117

Epoch: 5| Step: 1
Training loss: 1.619821807809858
Validation loss: 2.601628521300131

Epoch: 5| Step: 2
Training loss: 2.4250076215171994
Validation loss: 2.582008342477789

Epoch: 5| Step: 3
Training loss: 2.4223175628906053
Validation loss: 2.5630001805003153

Epoch: 5| Step: 4
Training loss: 1.5383343208422786
Validation loss: 2.5820434885509265

Epoch: 5| Step: 5
Training loss: 2.0148070102402325
Validation loss: 2.588520197072531

Epoch: 5| Step: 6
Training loss: 2.382697130755993
Validation loss: 2.5823207852556993

Epoch: 5| Step: 7
Training loss: 1.8486812401830028
Validation loss: 2.6013568342476225

Epoch: 5| Step: 8
Training loss: 1.7020791018311636
Validation loss: 2.6032665617187116

Epoch: 5| Step: 9
Training loss: 1.6445370490545024
Validation loss: 2.6080987744597715

Epoch: 5| Step: 10
Training loss: 2.7100956293948535
Validation loss: 2.606075485021855

Epoch: 5| Step: 11
Training loss: 1.5083828968876063
Validation loss: 2.618859249649364

Epoch: 316| Step: 0
Training loss: 2.3710857058141963
Validation loss: 2.621210811026739

Epoch: 5| Step: 1
Training loss: 2.155323437627999
Validation loss: 2.649209475465884

Epoch: 5| Step: 2
Training loss: 1.5374088601492386
Validation loss: 2.6640312364520646

Epoch: 5| Step: 3
Training loss: 1.8988429762858454
Validation loss: 2.6870736663718606

Epoch: 5| Step: 4
Training loss: 2.0473628736696172
Validation loss: 2.6863802676761086

Epoch: 5| Step: 5
Training loss: 1.8887907225525182
Validation loss: 2.6408051047517223

Epoch: 5| Step: 6
Training loss: 2.322021984926117
Validation loss: 2.583154611916976

Epoch: 5| Step: 7
Training loss: 2.6119401395752946
Validation loss: 2.535058378692312

Epoch: 5| Step: 8
Training loss: 2.9710414676244
Validation loss: 2.4879750373261142

Epoch: 5| Step: 9
Training loss: 2.252054971474599
Validation loss: 2.5128918405477814

Epoch: 5| Step: 10
Training loss: 1.8572324060501981
Validation loss: 2.4911233629131373

Epoch: 5| Step: 11
Training loss: 1.5552851616018606
Validation loss: 2.499697074816161

Epoch: 317| Step: 0
Training loss: 2.6536145768400905
Validation loss: 2.486497236495378

Epoch: 5| Step: 1
Training loss: 2.1559394944570607
Validation loss: 2.501822177101572

Epoch: 5| Step: 2
Training loss: 1.9381286462616043
Validation loss: 2.5234252960886283

Epoch: 5| Step: 3
Training loss: 1.7510295291852898
Validation loss: 2.540064968870195

Epoch: 5| Step: 4
Training loss: 2.1171146394361577
Validation loss: 2.545039112028474

Epoch: 5| Step: 5
Training loss: 2.0442625657094626
Validation loss: 2.5476402700999827

Epoch: 5| Step: 6
Training loss: 2.2566767281101856
Validation loss: 2.5540617352370196

Epoch: 5| Step: 7
Training loss: 1.4901536592195206
Validation loss: 2.5615320393394496

Epoch: 5| Step: 8
Training loss: 2.6299867945872597
Validation loss: 2.576476785943245

Epoch: 5| Step: 9
Training loss: 2.089073424214437
Validation loss: 2.5745637977905576

Epoch: 5| Step: 10
Training loss: 2.4554445028245735
Validation loss: 2.5640881896838725

Epoch: 5| Step: 11
Training loss: 3.206675575968314
Validation loss: 2.5580882148138957

Epoch: 318| Step: 0
Training loss: 2.450929473198438
Validation loss: 2.585548004674216

Epoch: 5| Step: 1
Training loss: 2.684752190660499
Validation loss: 2.575916558166329

Epoch: 5| Step: 2
Training loss: 1.897866936488202
Validation loss: 2.5474134433792543

Epoch: 5| Step: 3
Training loss: 1.5855400451828834
Validation loss: 2.5409952720474003

Epoch: 5| Step: 4
Training loss: 2.3753801342770626
Validation loss: 2.539909778958186

Epoch: 5| Step: 5
Training loss: 3.121304272174866
Validation loss: 2.5481302253470584

Epoch: 5| Step: 6
Training loss: 2.192034354267863
Validation loss: 2.564198818608554

Epoch: 5| Step: 7
Training loss: 1.9124882043212947
Validation loss: 2.580435863550561

Epoch: 5| Step: 8
Training loss: 1.7147358575825307
Validation loss: 2.5640767565293503

Epoch: 5| Step: 9
Training loss: 1.1859312235750312
Validation loss: 2.6000455360979435

Epoch: 5| Step: 10
Training loss: 1.6998337608287244
Validation loss: 2.5703419893345183

Epoch: 5| Step: 11
Training loss: 2.932920741917371
Validation loss: 2.607522876321565

Epoch: 319| Step: 0
Training loss: 2.6590888616914135
Validation loss: 2.5876913740118654

Epoch: 5| Step: 1
Training loss: 1.8058713522680354
Validation loss: 2.558185111845614

Epoch: 5| Step: 2
Training loss: 1.7505971026147003
Validation loss: 2.58017165894998

Epoch: 5| Step: 3
Training loss: 1.7668262547562081
Validation loss: 2.577536544688733

Epoch: 5| Step: 4
Training loss: 2.32171547342972
Validation loss: 2.5687431870592143

Epoch: 5| Step: 5
Training loss: 2.267429448789271
Validation loss: 2.5529561723525003

Epoch: 5| Step: 6
Training loss: 1.9415048616413764
Validation loss: 2.550605530306592

Epoch: 5| Step: 7
Training loss: 2.0029958698232027
Validation loss: 2.5597374842200193

Epoch: 5| Step: 8
Training loss: 2.153929968790843
Validation loss: 2.5697331940011425

Epoch: 5| Step: 9
Training loss: 2.5337664493277137
Validation loss: 2.545665652772096

Epoch: 5| Step: 10
Training loss: 2.342253245219225
Validation loss: 2.5471285165312954

Epoch: 5| Step: 11
Training loss: 1.1153692641580486
Validation loss: 2.5510599082480465

Epoch: 320| Step: 0
Training loss: 2.3110863772417747
Validation loss: 2.544235000175807

Epoch: 5| Step: 1
Training loss: 1.9228868379549016
Validation loss: 2.5574187514561495

Epoch: 5| Step: 2
Training loss: 2.1281612667628957
Validation loss: 2.5814489072466937

Epoch: 5| Step: 3
Training loss: 2.067339796250341
Validation loss: 2.5968234608321787

Epoch: 5| Step: 4
Training loss: 1.9286399808941326
Validation loss: 2.6209879482877114

Epoch: 5| Step: 5
Training loss: 1.74242396097093
Validation loss: 2.625510268343662

Epoch: 5| Step: 6
Training loss: 2.739500636797457
Validation loss: 2.6430696724312925

Epoch: 5| Step: 7
Training loss: 2.0655806682405986
Validation loss: 2.639357381080321

Epoch: 5| Step: 8
Training loss: 2.238861168636407
Validation loss: 2.636938595495789

Epoch: 5| Step: 9
Training loss: 2.0032874745194227
Validation loss: 2.5830735388736237

Epoch: 5| Step: 10
Training loss: 2.1173215028366648
Validation loss: 2.5635287383083045

Epoch: 5| Step: 11
Training loss: 3.2196339995130367
Validation loss: 2.528182482606221

Epoch: 321| Step: 0
Training loss: 2.2156126379790004
Validation loss: 2.5559869663550954

Epoch: 5| Step: 1
Training loss: 2.1971052458830496
Validation loss: 2.5468793022571883

Epoch: 5| Step: 2
Training loss: 2.1488025701903695
Validation loss: 2.584381455532931

Epoch: 5| Step: 3
Training loss: 1.9412274345466887
Validation loss: 2.600488095287859

Epoch: 5| Step: 4
Training loss: 2.081941241238622
Validation loss: 2.6297900304754216

Epoch: 5| Step: 5
Training loss: 1.8251328720425677
Validation loss: 2.64666340915622

Epoch: 5| Step: 6
Training loss: 1.9320058139926788
Validation loss: 2.6012940903165087

Epoch: 5| Step: 7
Training loss: 2.1191339870647767
Validation loss: 2.6063784717818863

Epoch: 5| Step: 8
Training loss: 2.5788676723864077
Validation loss: 2.6157904886680687

Epoch: 5| Step: 9
Training loss: 2.3263836178949213
Validation loss: 2.5999943318977685

Epoch: 5| Step: 10
Training loss: 1.828260107020032
Validation loss: 2.6156126151936787

Epoch: 5| Step: 11
Training loss: 3.434526440489629
Validation loss: 2.6256904715747558

Epoch: 322| Step: 0
Training loss: 1.8918574075980445
Validation loss: 2.6214576389004924

Epoch: 5| Step: 1
Training loss: 2.107344490730527
Validation loss: 2.6051584999863184

Epoch: 5| Step: 2
Training loss: 2.0378230628640877
Validation loss: 2.6079194316878813

Epoch: 5| Step: 3
Training loss: 1.8953150435491164
Validation loss: 2.61145746961188

Epoch: 5| Step: 4
Training loss: 2.601299009067665
Validation loss: 2.6326269014557924

Epoch: 5| Step: 5
Training loss: 2.226309992877723
Validation loss: 2.6277594896929757

Epoch: 5| Step: 6
Training loss: 1.6648493952411547
Validation loss: 2.633112832738564

Epoch: 5| Step: 7
Training loss: 2.5945776113097136
Validation loss: 2.6147198559097324

Epoch: 5| Step: 8
Training loss: 2.04389422079897
Validation loss: 2.6143964090184304

Epoch: 5| Step: 9
Training loss: 1.7135085901780276
Validation loss: 2.6279102004817267

Epoch: 5| Step: 10
Training loss: 2.4081666917357585
Validation loss: 2.62795527556895

Epoch: 5| Step: 11
Training loss: 1.7907420441353448
Validation loss: 2.625848178980959

Epoch: 323| Step: 0
Training loss: 1.7837544285719924
Validation loss: 2.5958805411094095

Epoch: 5| Step: 1
Training loss: 2.0714873812928993
Validation loss: 2.591847656641746

Epoch: 5| Step: 2
Training loss: 1.8208466757046187
Validation loss: 2.583156902046395

Epoch: 5| Step: 3
Training loss: 2.145823049674963
Validation loss: 2.563822265566228

Epoch: 5| Step: 4
Training loss: 1.5480260708508546
Validation loss: 2.5699197184977924

Epoch: 5| Step: 5
Training loss: 2.157452344843282
Validation loss: 2.5553768658851923

Epoch: 5| Step: 6
Training loss: 2.0711934068921862
Validation loss: 2.5621843376191333

Epoch: 5| Step: 7
Training loss: 1.8910318362512943
Validation loss: 2.5631292237404586

Epoch: 5| Step: 8
Training loss: 2.8611269727182878
Validation loss: 2.572696542525703

Epoch: 5| Step: 9
Training loss: 2.6240557834348026
Validation loss: 2.5819823490808114

Epoch: 5| Step: 10
Training loss: 2.0693058661615766
Validation loss: 2.5916768333464613

Epoch: 5| Step: 11
Training loss: 2.133415611985136
Validation loss: 2.605731121618857

Epoch: 324| Step: 0
Training loss: 2.4679515851309346
Validation loss: 2.5767024344404117

Epoch: 5| Step: 1
Training loss: 1.7809358955639802
Validation loss: 2.5785753800772353

Epoch: 5| Step: 2
Training loss: 1.9516486729944258
Validation loss: 2.5423146240111465

Epoch: 5| Step: 3
Training loss: 1.9191511747480616
Validation loss: 2.536817546111499

Epoch: 5| Step: 4
Training loss: 1.789918719636018
Validation loss: 2.514455238994464

Epoch: 5| Step: 5
Training loss: 1.869932511177677
Validation loss: 2.537260631019932

Epoch: 5| Step: 6
Training loss: 2.5591704905199926
Validation loss: 2.5624816165047557

Epoch: 5| Step: 7
Training loss: 2.305947996798807
Validation loss: 2.583480362912451

Epoch: 5| Step: 8
Training loss: 2.0366445652979475
Validation loss: 2.6541448965532224

Epoch: 5| Step: 9
Training loss: 2.569193030993462
Validation loss: 2.6338084909346975

Epoch: 5| Step: 10
Training loss: 2.3312853158520666
Validation loss: 2.623828743953536

Epoch: 5| Step: 11
Training loss: 1.6169754110388244
Validation loss: 2.615345865864019

Epoch: 325| Step: 0
Training loss: 2.3035014575964405
Validation loss: 2.6142068923742987

Epoch: 5| Step: 1
Training loss: 2.4681068258613776
Validation loss: 2.6492873022190317

Epoch: 5| Step: 2
Training loss: 2.110932065108254
Validation loss: 2.628548968647817

Epoch: 5| Step: 3
Training loss: 1.3967396322793821
Validation loss: 2.6324612036934876

Epoch: 5| Step: 4
Training loss: 2.4617564942696624
Validation loss: 2.591139207125423

Epoch: 5| Step: 5
Training loss: 2.0542431485044537
Validation loss: 2.6138462620976712

Epoch: 5| Step: 6
Training loss: 2.2744414220190516
Validation loss: 2.5632671045379847

Epoch: 5| Step: 7
Training loss: 2.1577208657665174
Validation loss: 2.5595021894350825

Epoch: 5| Step: 8
Training loss: 1.6132700922028271
Validation loss: 2.5513092203414556

Epoch: 5| Step: 9
Training loss: 2.3460455270562743
Validation loss: 2.5593755833054943

Epoch: 5| Step: 10
Training loss: 1.905215936572249
Validation loss: 2.5551681844048124

Epoch: 5| Step: 11
Training loss: 2.155711009896948
Validation loss: 2.540819172713907

Epoch: 326| Step: 0
Training loss: 2.0974240307696137
Validation loss: 2.5299938248130514

Epoch: 5| Step: 1
Training loss: 2.3033298437567784
Validation loss: 2.4932817948551484

Epoch: 5| Step: 2
Training loss: 2.131567063896462
Validation loss: 2.504556691416163

Epoch: 5| Step: 3
Training loss: 2.060721121557335
Validation loss: 2.4970417620305105

Epoch: 5| Step: 4
Training loss: 2.0560173111717446
Validation loss: 2.4884678617454603

Epoch: 5| Step: 5
Training loss: 2.453145506949268
Validation loss: 2.501920903852308

Epoch: 5| Step: 6
Training loss: 1.5965164707766661
Validation loss: 2.5192134173710894

Epoch: 5| Step: 7
Training loss: 1.8902197159105907
Validation loss: 2.542551954795711

Epoch: 5| Step: 8
Training loss: 2.045283973209318
Validation loss: 2.552548291546291

Epoch: 5| Step: 9
Training loss: 2.828353788279034
Validation loss: 2.584531484415185

Epoch: 5| Step: 10
Training loss: 2.2777966004914596
Validation loss: 2.6112856655810823

Epoch: 5| Step: 11
Training loss: 1.8144374883694503
Validation loss: 2.6438888753814527

Epoch: 327| Step: 0
Training loss: 2.4854167937166536
Validation loss: 2.6333568021678144

Epoch: 5| Step: 1
Training loss: 2.027864187248808
Validation loss: 2.6191581917025966

Epoch: 5| Step: 2
Training loss: 1.8721586951782803
Validation loss: 2.6163610814226894

Epoch: 5| Step: 3
Training loss: 1.7538468450668456
Validation loss: 2.556723122932884

Epoch: 5| Step: 4
Training loss: 1.7101050315635242
Validation loss: 2.5609835561009406

Epoch: 5| Step: 5
Training loss: 1.4812299638511728
Validation loss: 2.5516142874743735

Epoch: 5| Step: 6
Training loss: 2.7349875499713954
Validation loss: 2.5428336283875774

Epoch: 5| Step: 7
Training loss: 2.318768022575154
Validation loss: 2.550916139503182

Epoch: 5| Step: 8
Training loss: 2.285101995883728
Validation loss: 2.568216418021459

Epoch: 5| Step: 9
Training loss: 2.164740941536336
Validation loss: 2.610659353651059

Epoch: 5| Step: 10
Training loss: 2.7069530393193153
Validation loss: 2.66684540631378

Epoch: 5| Step: 11
Training loss: 1.5595941607443993
Validation loss: 2.66213420540081

Epoch: 328| Step: 0
Training loss: 1.6874656673753563
Validation loss: 2.6636880180741294

Epoch: 5| Step: 1
Training loss: 1.7920913045221487
Validation loss: 2.6671585930641677

Epoch: 5| Step: 2
Training loss: 1.8556503688867907
Validation loss: 2.63159201582165

Epoch: 5| Step: 3
Training loss: 2.391440757245778
Validation loss: 2.645659085540881

Epoch: 5| Step: 4
Training loss: 2.1355102022356482
Validation loss: 2.6129262746777115

Epoch: 5| Step: 5
Training loss: 1.847289357443303
Validation loss: 2.61217860597947

Epoch: 5| Step: 6
Training loss: 2.157618212947842
Validation loss: 2.642621825900751

Epoch: 5| Step: 7
Training loss: 2.4138628929600623
Validation loss: 2.6193981342754955

Epoch: 5| Step: 8
Training loss: 2.568095541047252
Validation loss: 2.6138364908121923

Epoch: 5| Step: 9
Training loss: 2.557226663191923
Validation loss: 2.606364727620649

Epoch: 5| Step: 10
Training loss: 1.734746394902282
Validation loss: 2.602639697946083

Epoch: 5| Step: 11
Training loss: 1.5200480781028811
Validation loss: 2.5971250521546976

Epoch: 329| Step: 0
Training loss: 2.004705377559972
Validation loss: 2.5922396218683845

Epoch: 5| Step: 1
Training loss: 1.8691528702576945
Validation loss: 2.580523502278307

Epoch: 5| Step: 2
Training loss: 2.7560474485678443
Validation loss: 2.56827774981812

Epoch: 5| Step: 3
Training loss: 2.1117194816088496
Validation loss: 2.597035276911973

Epoch: 5| Step: 4
Training loss: 2.3449579813431916
Validation loss: 2.579408634330993

Epoch: 5| Step: 5
Training loss: 2.3030625644124703
Validation loss: 2.5609499887779075

Epoch: 5| Step: 6
Training loss: 2.681175864023929
Validation loss: 2.547564048623306

Epoch: 5| Step: 7
Training loss: 1.3557588558143439
Validation loss: 2.5643104538715256

Epoch: 5| Step: 8
Training loss: 1.3754852912390958
Validation loss: 2.563945959318647

Epoch: 5| Step: 9
Training loss: 1.8001251680511678
Validation loss: 2.593384762981732

Epoch: 5| Step: 10
Training loss: 2.4015838165429204
Validation loss: 2.5828851277685847

Epoch: 5| Step: 11
Training loss: 1.5477093074663895
Validation loss: 2.5850856949297074

Epoch: 330| Step: 0
Training loss: 2.398409367995897
Validation loss: 2.608190404664701

Epoch: 5| Step: 1
Training loss: 2.264473247455121
Validation loss: 2.5867613933016522

Epoch: 5| Step: 2
Training loss: 2.3298067508829914
Validation loss: 2.5796731211775468

Epoch: 5| Step: 3
Training loss: 2.1545310424919673
Validation loss: 2.566254414364003

Epoch: 5| Step: 4
Training loss: 1.6355559012394232
Validation loss: 2.582997478423572

Epoch: 5| Step: 5
Training loss: 2.5722023182046914
Validation loss: 2.57336027874535

Epoch: 5| Step: 6
Training loss: 1.8761021871369907
Validation loss: 2.5562230355131583

Epoch: 5| Step: 7
Training loss: 1.79447059645097
Validation loss: 2.5555497016240767

Epoch: 5| Step: 8
Training loss: 2.4029397364761835
Validation loss: 2.5508558876758607

Epoch: 5| Step: 9
Training loss: 1.8013139379564496
Validation loss: 2.561320832171192

Epoch: 5| Step: 10
Training loss: 1.4432918135299893
Validation loss: 2.5532089702847096

Epoch: 5| Step: 11
Training loss: 3.270220721433728
Validation loss: 2.577816572910223

Epoch: 331| Step: 0
Training loss: 1.7243147497930185
Validation loss: 2.6019143638898354

Epoch: 5| Step: 1
Training loss: 2.1691552566812478
Validation loss: 2.6070773655515893

Epoch: 5| Step: 2
Training loss: 1.8287469180974851
Validation loss: 2.6122867381587396

Epoch: 5| Step: 3
Training loss: 1.4535078959373582
Validation loss: 2.5935271446975054

Epoch: 5| Step: 4
Training loss: 1.5828634451587722
Validation loss: 2.5782704283416273

Epoch: 5| Step: 5
Training loss: 2.7208287852912814
Validation loss: 2.55298996735188

Epoch: 5| Step: 6
Training loss: 2.5883248824918907
Validation loss: 2.541591581944864

Epoch: 5| Step: 7
Training loss: 2.0997065747849892
Validation loss: 2.5416817638595046

Epoch: 5| Step: 8
Training loss: 1.7921194421139615
Validation loss: 2.5292963133508164

Epoch: 5| Step: 9
Training loss: 2.3388542413850995
Validation loss: 2.5380096130519707

Epoch: 5| Step: 10
Training loss: 2.121771547832185
Validation loss: 2.5193172354082507

Epoch: 5| Step: 11
Training loss: 3.7351017328627054
Validation loss: 2.503344432627999

Epoch: 332| Step: 0
Training loss: 2.0278092807198087
Validation loss: 2.532635800008445

Epoch: 5| Step: 1
Training loss: 2.2599555276191623
Validation loss: 2.555284482866018

Epoch: 5| Step: 2
Training loss: 2.095076638870688
Validation loss: 2.575796347224728

Epoch: 5| Step: 3
Training loss: 2.376371489604267
Validation loss: 2.5515443167785117

Epoch: 5| Step: 4
Training loss: 2.3573744420650105
Validation loss: 2.5787959295075913

Epoch: 5| Step: 5
Training loss: 2.153535544090379
Validation loss: 2.5983084909080594

Epoch: 5| Step: 6
Training loss: 2.2697238019718498
Validation loss: 2.6092447640512457

Epoch: 5| Step: 7
Training loss: 2.089782828040173
Validation loss: 2.5985586793024

Epoch: 5| Step: 8
Training loss: 1.9770858132199758
Validation loss: 2.6043761486993544

Epoch: 5| Step: 9
Training loss: 1.2942476890945658
Validation loss: 2.554752632889581

Epoch: 5| Step: 10
Training loss: 2.1245894315933453
Validation loss: 2.5553125789157614

Epoch: 5| Step: 11
Training loss: 0.6808527899646374
Validation loss: 2.558603235280555

Epoch: 333| Step: 0
Training loss: 2.365005847528499
Validation loss: 2.5617402586441664

Epoch: 5| Step: 1
Training loss: 1.922401046091304
Validation loss: 2.5351339220690923

Epoch: 5| Step: 2
Training loss: 2.037246421527142
Validation loss: 2.5427641700845123

Epoch: 5| Step: 3
Training loss: 1.5784639806495453
Validation loss: 2.578883261868495

Epoch: 5| Step: 4
Training loss: 2.302983575461717
Validation loss: 2.595185912656728

Epoch: 5| Step: 5
Training loss: 2.060018491569411
Validation loss: 2.5574433669540975

Epoch: 5| Step: 6
Training loss: 2.2627883516626484
Validation loss: 2.5664667309157285

Epoch: 5| Step: 7
Training loss: 2.371149857436965
Validation loss: 2.5877016087247013

Epoch: 5| Step: 8
Training loss: 1.8506059066782088
Validation loss: 2.637026661919748

Epoch: 5| Step: 9
Training loss: 1.6377400054929478
Validation loss: 2.619965804716506

Epoch: 5| Step: 10
Training loss: 2.3803173571658873
Validation loss: 2.621746324997062

Epoch: 5| Step: 11
Training loss: 2.420216835648239
Validation loss: 2.645804015820693

Epoch: 334| Step: 0
Training loss: 2.049159864073336
Validation loss: 2.623568856194277

Epoch: 5| Step: 1
Training loss: 1.9572217776205107
Validation loss: 2.5771661343195187

Epoch: 5| Step: 2
Training loss: 2.0014288090079186
Validation loss: 2.564531343017284

Epoch: 5| Step: 3
Training loss: 1.9566408784500235
Validation loss: 2.5719273797870232

Epoch: 5| Step: 4
Training loss: 2.1600317479378885
Validation loss: 2.581355592755412

Epoch: 5| Step: 5
Training loss: 1.734987855148683
Validation loss: 2.581615381804777

Epoch: 5| Step: 6
Training loss: 2.1714914106655447
Validation loss: 2.5795331866057025

Epoch: 5| Step: 7
Training loss: 2.7887289237778097
Validation loss: 2.576851067655106

Epoch: 5| Step: 8
Training loss: 1.4910639182652974
Validation loss: 2.5831522237193987

Epoch: 5| Step: 9
Training loss: 2.48268069667041
Validation loss: 2.606050509312455

Epoch: 5| Step: 10
Training loss: 2.1935168759192685
Validation loss: 2.601604396417797

Epoch: 5| Step: 11
Training loss: 2.195927543959571
Validation loss: 2.5776925851411803

Epoch: 335| Step: 0
Training loss: 1.8190800501703086
Validation loss: 2.5863510331322033

Epoch: 5| Step: 1
Training loss: 1.395089302280971
Validation loss: 2.5859942665284854

Epoch: 5| Step: 2
Training loss: 2.4827187253361025
Validation loss: 2.571549880103078

Epoch: 5| Step: 3
Training loss: 2.25686509473809
Validation loss: 2.569409614762235

Epoch: 5| Step: 4
Training loss: 2.0713158821121396
Validation loss: 2.5958221002604085

Epoch: 5| Step: 5
Training loss: 2.284730737960802
Validation loss: 2.6151656468700026

Epoch: 5| Step: 6
Training loss: 1.5589504359638866
Validation loss: 2.6150770835687114

Epoch: 5| Step: 7
Training loss: 2.0156494848848965
Validation loss: 2.6521497383004924

Epoch: 5| Step: 8
Training loss: 2.2196629754695665
Validation loss: 2.6478191580377852

Epoch: 5| Step: 9
Training loss: 2.1323995225318
Validation loss: 2.6478466961607645

Epoch: 5| Step: 10
Training loss: 2.4799202380120726
Validation loss: 2.63324188821093

Epoch: 5| Step: 11
Training loss: 1.9824071423213334
Validation loss: 2.6405071593405878

Epoch: 336| Step: 0
Training loss: 1.952187274891935
Validation loss: 2.7075539983740353

Epoch: 5| Step: 1
Training loss: 2.003016343048658
Validation loss: 2.7276315861192355

Epoch: 5| Step: 2
Training loss: 2.529827990056091
Validation loss: 2.7585332539206395

Epoch: 5| Step: 3
Training loss: 2.2199654272325753
Validation loss: 2.7081188275903467

Epoch: 5| Step: 4
Training loss: 1.7455138197094726
Validation loss: 2.713301522922174

Epoch: 5| Step: 5
Training loss: 2.290801029285155
Validation loss: 2.7155455855334654

Epoch: 5| Step: 6
Training loss: 2.0460359440663844
Validation loss: 2.6613842878598417

Epoch: 5| Step: 7
Training loss: 1.8275305930941534
Validation loss: 2.6133776705392466

Epoch: 5| Step: 8
Training loss: 2.384182795505931
Validation loss: 2.56911780469172

Epoch: 5| Step: 9
Training loss: 2.230723778997757
Validation loss: 2.5620256155422454

Epoch: 5| Step: 10
Training loss: 2.275635590689724
Validation loss: 2.5796706257820268

Epoch: 5| Step: 11
Training loss: 1.1789377621634882
Validation loss: 2.5621697670507912

Epoch: 337| Step: 0
Training loss: 2.6417566165792477
Validation loss: 2.566217180368309

Epoch: 5| Step: 1
Training loss: 2.3399157887165325
Validation loss: 2.5362044187084383

Epoch: 5| Step: 2
Training loss: 1.8203636456945982
Validation loss: 2.5654074100746422

Epoch: 5| Step: 3
Training loss: 2.4116133330413954
Validation loss: 2.556238906886025

Epoch: 5| Step: 4
Training loss: 1.945724566222236
Validation loss: 2.5857974895210383

Epoch: 5| Step: 5
Training loss: 2.0023077525081887
Validation loss: 2.6006616019628526

Epoch: 5| Step: 6
Training loss: 1.7133642953210024
Validation loss: 2.6115547486989366

Epoch: 5| Step: 7
Training loss: 1.9586418057706156
Validation loss: 2.6256379079013366

Epoch: 5| Step: 8
Training loss: 1.9038063395649003
Validation loss: 2.585803705540127

Epoch: 5| Step: 9
Training loss: 1.9224219435582024
Validation loss: 2.5830691353742385

Epoch: 5| Step: 10
Training loss: 2.253925925025152
Validation loss: 2.5666535798787815

Epoch: 5| Step: 11
Training loss: 2.25631252212759
Validation loss: 2.557918830359472

Epoch: 338| Step: 0
Training loss: 1.6959618234656204
Validation loss: 2.55135447675571

Epoch: 5| Step: 1
Training loss: 2.135832161527866
Validation loss: 2.5404736397525656

Epoch: 5| Step: 2
Training loss: 2.034756729244209
Validation loss: 2.5661975847376843

Epoch: 5| Step: 3
Training loss: 2.033967298681799
Validation loss: 2.5905755027180786

Epoch: 5| Step: 4
Training loss: 2.3533607273650694
Validation loss: 2.5986492716026572

Epoch: 5| Step: 5
Training loss: 2.330822092828616
Validation loss: 2.6197524677678405

Epoch: 5| Step: 6
Training loss: 2.650538148759105
Validation loss: 2.5925246527041343

Epoch: 5| Step: 7
Training loss: 2.3038598595026962
Validation loss: 2.619678738829039

Epoch: 5| Step: 8
Training loss: 1.3396001655545478
Validation loss: 2.586483746907048

Epoch: 5| Step: 9
Training loss: 1.707635558683025
Validation loss: 2.609940709296865

Epoch: 5| Step: 10
Training loss: 2.0747329448141905
Validation loss: 2.575891193623268

Epoch: 5| Step: 11
Training loss: 1.2554871287778038
Validation loss: 2.5401699839555447

Epoch: 339| Step: 0
Training loss: 2.599263776567469
Validation loss: 2.5221561804556605

Epoch: 5| Step: 1
Training loss: 1.9902407240836535
Validation loss: 2.5092606487957196

Epoch: 5| Step: 2
Training loss: 2.0018309318653635
Validation loss: 2.544293544411528

Epoch: 5| Step: 3
Training loss: 1.422856421845254
Validation loss: 2.5475843724937084

Epoch: 5| Step: 4
Training loss: 2.173175888716406
Validation loss: 2.546261512650419

Epoch: 5| Step: 5
Training loss: 2.0841382442683414
Validation loss: 2.586910829101631

Epoch: 5| Step: 6
Training loss: 2.0547141882029814
Validation loss: 2.591346255016112

Epoch: 5| Step: 7
Training loss: 1.425852316561501
Validation loss: 2.620720629752785

Epoch: 5| Step: 8
Training loss: 1.8288879106816924
Validation loss: 2.647234850865926

Epoch: 5| Step: 9
Training loss: 2.771402649484345
Validation loss: 2.603225069843536

Epoch: 5| Step: 10
Training loss: 2.023213849171654
Validation loss: 2.6055031678358582

Epoch: 5| Step: 11
Training loss: 1.8754784291551632
Validation loss: 2.6205144811558996

Epoch: 340| Step: 0
Training loss: 2.2565351522637753
Validation loss: 2.6113836129911885

Epoch: 5| Step: 1
Training loss: 2.339748068558346
Validation loss: 2.603497550197626

Epoch: 5| Step: 2
Training loss: 2.279815118053142
Validation loss: 2.586293022249026

Epoch: 5| Step: 3
Training loss: 1.7346042103564443
Validation loss: 2.5841842539460576

Epoch: 5| Step: 4
Training loss: 1.7726668645440935
Validation loss: 2.5556134112145017

Epoch: 5| Step: 5
Training loss: 1.54053531408893
Validation loss: 2.583297888194741

Epoch: 5| Step: 6
Training loss: 2.0265137842303913
Validation loss: 2.55749662527096

Epoch: 5| Step: 7
Training loss: 2.38115677137925
Validation loss: 2.5494834788165512

Epoch: 5| Step: 8
Training loss: 1.8049316241133926
Validation loss: 2.554238403385338

Epoch: 5| Step: 9
Training loss: 2.501030900119887
Validation loss: 2.5772705453939437

Epoch: 5| Step: 10
Training loss: 1.815861183339245
Validation loss: 2.5951176220544743

Epoch: 5| Step: 11
Training loss: 2.0920493207774014
Validation loss: 2.6188406282946968

Epoch: 341| Step: 0
Training loss: 2.2573818337235503
Validation loss: 2.636640360102574

Epoch: 5| Step: 1
Training loss: 1.8233477782049792
Validation loss: 2.6513975850066975

Epoch: 5| Step: 2
Training loss: 2.0007122678829714
Validation loss: 2.644327727787644

Epoch: 5| Step: 3
Training loss: 2.305368924023765
Validation loss: 2.591723688506162

Epoch: 5| Step: 4
Training loss: 1.8454910721646895
Validation loss: 2.5370992925109292

Epoch: 5| Step: 5
Training loss: 2.176926919042541
Validation loss: 2.484515268136739

Epoch: 5| Step: 6
Training loss: 2.2593964297385014
Validation loss: 2.496035026452522

Epoch: 5| Step: 7
Training loss: 2.5836187840746434
Validation loss: 2.4843447821356865

Epoch: 5| Step: 8
Training loss: 1.914513048356174
Validation loss: 2.4925672626443007

Epoch: 5| Step: 9
Training loss: 1.6182453178857812
Validation loss: 2.5205923561639025

Epoch: 5| Step: 10
Training loss: 2.0749058851476754
Validation loss: 2.5055938028931

Epoch: 5| Step: 11
Training loss: 1.791494457337442
Validation loss: 2.5381536412355

Epoch: 342| Step: 0
Training loss: 2.8356249087903094
Validation loss: 2.5247208921000635

Epoch: 5| Step: 1
Training loss: 2.123166246751873
Validation loss: 2.560793253987079

Epoch: 5| Step: 2
Training loss: 1.9117533553981854
Validation loss: 2.5585978267724556

Epoch: 5| Step: 3
Training loss: 1.9252792230202942
Validation loss: 2.580338081164374

Epoch: 5| Step: 4
Training loss: 2.198657003044111
Validation loss: 2.6139035702747

Epoch: 5| Step: 5
Training loss: 1.8406030987147368
Validation loss: 2.6152742784991845

Epoch: 5| Step: 6
Training loss: 1.7329155907608853
Validation loss: 2.6083456986462257

Epoch: 5| Step: 7
Training loss: 2.227178548615838
Validation loss: 2.6143991144539296

Epoch: 5| Step: 8
Training loss: 1.6312769920483698
Validation loss: 2.56855248715174

Epoch: 5| Step: 9
Training loss: 2.3056626148211254
Validation loss: 2.518981581865038

Epoch: 5| Step: 10
Training loss: 1.838026246469781
Validation loss: 2.547022462254048

Epoch: 5| Step: 11
Training loss: 1.7007871208037024
Validation loss: 2.5203890776820383

Epoch: 343| Step: 0
Training loss: 1.9930877446651891
Validation loss: 2.529036745419254

Epoch: 5| Step: 1
Training loss: 2.2028611478332674
Validation loss: 2.5534026971932895

Epoch: 5| Step: 2
Training loss: 2.5472743183532263
Validation loss: 2.570849295916428

Epoch: 5| Step: 3
Training loss: 1.8955280631082743
Validation loss: 2.541947585095746

Epoch: 5| Step: 4
Training loss: 2.2999104275054583
Validation loss: 2.5514129549685527

Epoch: 5| Step: 5
Training loss: 1.629417577025553
Validation loss: 2.556452690582311

Epoch: 5| Step: 6
Training loss: 2.1495299734832907
Validation loss: 2.5823442247301482

Epoch: 5| Step: 7
Training loss: 2.2967284279073175
Validation loss: 2.5794095393891574

Epoch: 5| Step: 8
Training loss: 2.130495258833635
Validation loss: 2.5853321715346245

Epoch: 5| Step: 9
Training loss: 1.3769800061787667
Validation loss: 2.606144551980593

Epoch: 5| Step: 10
Training loss: 1.8721057170132855
Validation loss: 2.588297409619734

Epoch: 5| Step: 11
Training loss: 2.7237792579231406
Validation loss: 2.5835829942308446

Epoch: 344| Step: 0
Training loss: 1.6975553241191979
Validation loss: 2.548928569894823

Epoch: 5| Step: 1
Training loss: 2.011875302047209
Validation loss: 2.579117863141486

Epoch: 5| Step: 2
Training loss: 2.64859755490968
Validation loss: 2.5707083400180135

Epoch: 5| Step: 3
Training loss: 1.683625046158148
Validation loss: 2.5787463046411245

Epoch: 5| Step: 4
Training loss: 1.6846954210788962
Validation loss: 2.5840495959850203

Epoch: 5| Step: 5
Training loss: 2.037794047475244
Validation loss: 2.5750154411445525

Epoch: 5| Step: 6
Training loss: 2.032360770886791
Validation loss: 2.612232509103122

Epoch: 5| Step: 7
Training loss: 2.238066711263304
Validation loss: 2.61274331851884

Epoch: 5| Step: 8
Training loss: 2.1349565956295615
Validation loss: 2.6331435277495103

Epoch: 5| Step: 9
Training loss: 1.8386042929151187
Validation loss: 2.5993507117087304

Epoch: 5| Step: 10
Training loss: 2.5528648477380567
Validation loss: 2.6111581005666014

Epoch: 5| Step: 11
Training loss: 0.5450009797901131
Validation loss: 2.5821517823865334

Epoch: 345| Step: 0
Training loss: 2.4073788855838383
Validation loss: 2.5607391060242364

Epoch: 5| Step: 1
Training loss: 2.117394468882222
Validation loss: 2.5435561963109863

Epoch: 5| Step: 2
Training loss: 2.473030050024952
Validation loss: 2.545737611299877

Epoch: 5| Step: 3
Training loss: 1.7664398068695506
Validation loss: 2.5632954386347784

Epoch: 5| Step: 4
Training loss: 1.383898981718522
Validation loss: 2.55862271241547

Epoch: 5| Step: 5
Training loss: 1.4079393200586754
Validation loss: 2.5458865324560724

Epoch: 5| Step: 6
Training loss: 1.7262833313482877
Validation loss: 2.5386051372492524

Epoch: 5| Step: 7
Training loss: 2.1742550549781186
Validation loss: 2.537076582291692

Epoch: 5| Step: 8
Training loss: 2.7976947627310236
Validation loss: 2.5898005739413343

Epoch: 5| Step: 9
Training loss: 1.823488926754784
Validation loss: 2.6089032902239775

Epoch: 5| Step: 10
Training loss: 2.061246895865838
Validation loss: 2.6365885836649467

Epoch: 5| Step: 11
Training loss: 2.341957729437004
Validation loss: 2.6937958804159736

Epoch: 346| Step: 0
Training loss: 1.7612898276965143
Validation loss: 2.607202832645069

Epoch: 5| Step: 1
Training loss: 2.10952147928909
Validation loss: 2.5181113764221634

Epoch: 5| Step: 2
Training loss: 2.0651661373299173
Validation loss: 2.5133856763836357

Epoch: 5| Step: 3
Training loss: 2.0744493144424903
Validation loss: 2.474834505161009

Epoch: 5| Step: 4
Training loss: 2.1130498452687028
Validation loss: 2.4569421093998343

Epoch: 5| Step: 5
Training loss: 1.8227845134970435
Validation loss: 2.479426275546382

Epoch: 5| Step: 6
Training loss: 2.6631204052419712
Validation loss: 2.4604972566675753

Epoch: 5| Step: 7
Training loss: 2.0983800225470737
Validation loss: 2.472691170605054

Epoch: 5| Step: 8
Training loss: 2.535396429360922
Validation loss: 2.4776371009363967

Epoch: 5| Step: 9
Training loss: 2.4164930040071555
Validation loss: 2.4776407495866093

Epoch: 5| Step: 10
Training loss: 2.164993911981282
Validation loss: 2.4898774772652272

Epoch: 5| Step: 11
Training loss: 2.125936189757906
Validation loss: 2.5248398245312678

Epoch: 347| Step: 0
Training loss: 1.6048067310465928
Validation loss: 2.513651996208891

Epoch: 5| Step: 1
Training loss: 1.724105744143652
Validation loss: 2.5280480757029604

Epoch: 5| Step: 2
Training loss: 2.5253794847612947
Validation loss: 2.534298434749216

Epoch: 5| Step: 3
Training loss: 1.9937043044255853
Validation loss: 2.5209937018359048

Epoch: 5| Step: 4
Training loss: 2.019704785444923
Validation loss: 2.600703077439185

Epoch: 5| Step: 5
Training loss: 2.1833515612979437
Validation loss: 2.5566382780906993

Epoch: 5| Step: 6
Training loss: 1.8641072807464918
Validation loss: 2.5125596540717123

Epoch: 5| Step: 7
Training loss: 2.3070023630144165
Validation loss: 2.4821779624989135

Epoch: 5| Step: 8
Training loss: 2.647897040661807
Validation loss: 2.4927864491016196

Epoch: 5| Step: 9
Training loss: 2.1871053067125383
Validation loss: 2.485230996155972

Epoch: 5| Step: 10
Training loss: 2.14985870518041
Validation loss: 2.4886123460898895

Epoch: 5| Step: 11
Training loss: 3.0331117870483992
Validation loss: 2.499900329112971

Epoch: 348| Step: 0
Training loss: 1.5983249598586418
Validation loss: 2.5340188584839063

Epoch: 5| Step: 1
Training loss: 2.5182418954416432
Validation loss: 2.5224888911158594

Epoch: 5| Step: 2
Training loss: 2.428842771822745
Validation loss: 2.529588956918269

Epoch: 5| Step: 3
Training loss: 1.5061046039480284
Validation loss: 2.5322655771518114

Epoch: 5| Step: 4
Training loss: 2.0954698928785516
Validation loss: 2.561654327379819

Epoch: 5| Step: 5
Training loss: 1.8604178189070815
Validation loss: 2.5280357683023977

Epoch: 5| Step: 6
Training loss: 1.9233617846711202
Validation loss: 2.526146307806481

Epoch: 5| Step: 7
Training loss: 2.075512383865395
Validation loss: 2.4820734275217626

Epoch: 5| Step: 8
Training loss: 2.0847099206696895
Validation loss: 2.511506620934673

Epoch: 5| Step: 9
Training loss: 1.5266996230326042
Validation loss: 2.498676172068757

Epoch: 5| Step: 10
Training loss: 2.776285262212393
Validation loss: 2.502315231988071

Epoch: 5| Step: 11
Training loss: 3.4249661910344464
Validation loss: 2.489645128533968

Epoch: 349| Step: 0
Training loss: 1.4601241514903802
Validation loss: 2.5561500508013633

Epoch: 5| Step: 1
Training loss: 2.3152285793818237
Validation loss: 2.6345242860366924

Epoch: 5| Step: 2
Training loss: 1.9922924537687718
Validation loss: 2.7644436319197276

Epoch: 5| Step: 3
Training loss: 2.543135255205576
Validation loss: 2.885001067701833

Epoch: 5| Step: 4
Training loss: 2.614232823762248
Validation loss: 2.844677819164965

Epoch: 5| Step: 5
Training loss: 2.420964223591836
Validation loss: 2.7643302932954685

Epoch: 5| Step: 6
Training loss: 2.197365774627352
Validation loss: 2.7235057167881243

Epoch: 5| Step: 7
Training loss: 1.9433184595449429
Validation loss: 2.660921786745918

Epoch: 5| Step: 8
Training loss: 2.480567653816834
Validation loss: 2.6165485114454103

Epoch: 5| Step: 9
Training loss: 1.8506760547607777
Validation loss: 2.6110284709929252

Epoch: 5| Step: 10
Training loss: 1.8825760688965227
Validation loss: 2.569983885531489

Epoch: 5| Step: 11
Training loss: 3.336044131144894
Validation loss: 2.5849969926468592

Epoch: 350| Step: 0
Training loss: 2.3737277588648547
Validation loss: 2.5935595645471348

Epoch: 5| Step: 1
Training loss: 2.322444668245198
Validation loss: 2.5917163137809798

Epoch: 5| Step: 2
Training loss: 2.1560424483655356
Validation loss: 2.5733218601157164

Epoch: 5| Step: 3
Training loss: 2.156508057120874
Validation loss: 2.544961725539244

Epoch: 5| Step: 4
Training loss: 1.8012740315323967
Validation loss: 2.56452139932782

Epoch: 5| Step: 5
Training loss: 2.239572947869876
Validation loss: 2.585710663464881

Epoch: 5| Step: 6
Training loss: 1.7465049720254364
Validation loss: 2.5858631488295334

Epoch: 5| Step: 7
Training loss: 2.6013950603317086
Validation loss: 2.6398634141511543

Epoch: 5| Step: 8
Training loss: 1.8543530774082264
Validation loss: 2.6166379550909626

Epoch: 5| Step: 9
Training loss: 1.6660701478933642
Validation loss: 2.6444260704502356

Epoch: 5| Step: 10
Training loss: 2.2250435985622685
Validation loss: 2.663437245102003

Epoch: 5| Step: 11
Training loss: 1.0382293573389993
Validation loss: 2.7115243941554534

Epoch: 351| Step: 0
Training loss: 1.8131882906271637
Validation loss: 2.7190910140103477

Epoch: 5| Step: 1
Training loss: 2.134452217459019
Validation loss: 2.6801942470361744

Epoch: 5| Step: 2
Training loss: 2.366307161006515
Validation loss: 2.637048232602936

Epoch: 5| Step: 3
Training loss: 2.0887273640892823
Validation loss: 2.600933197401702

Epoch: 5| Step: 4
Training loss: 2.390411467147296
Validation loss: 2.5820470204451236

Epoch: 5| Step: 5
Training loss: 1.74923355484729
Validation loss: 2.5399210842706634

Epoch: 5| Step: 6
Training loss: 2.0026182679340034
Validation loss: 2.514080290082409

Epoch: 5| Step: 7
Training loss: 2.4046506644656795
Validation loss: 2.5199876830201156

Epoch: 5| Step: 8
Training loss: 1.7137739107229357
Validation loss: 2.5207861168172694

Epoch: 5| Step: 9
Training loss: 2.0826647512196725
Validation loss: 2.5471346631133662

Epoch: 5| Step: 10
Training loss: 2.3641196537105618
Validation loss: 2.596605487063182

Epoch: 5| Step: 11
Training loss: 2.2613848767561735
Validation loss: 2.6626765318002343

Epoch: 352| Step: 0
Training loss: 1.668470249229724
Validation loss: 2.6568021611785446

Epoch: 5| Step: 1
Training loss: 2.4610919237883873
Validation loss: 2.684788927798279

Epoch: 5| Step: 2
Training loss: 1.5782457815349875
Validation loss: 2.640668360788652

Epoch: 5| Step: 3
Training loss: 2.4840704773258793
Validation loss: 2.646759961032953

Epoch: 5| Step: 4
Training loss: 1.7658457660222373
Validation loss: 2.62730925272015

Epoch: 5| Step: 5
Training loss: 2.3642630563242135
Validation loss: 2.5929410891021534

Epoch: 5| Step: 6
Training loss: 2.145431024065378
Validation loss: 2.539318963816723

Epoch: 5| Step: 7
Training loss: 2.320068552056744
Validation loss: 2.5264862822842145

Epoch: 5| Step: 8
Training loss: 2.0840023365337137
Validation loss: 2.525028860758148

Epoch: 5| Step: 9
Training loss: 1.4746785735005448
Validation loss: 2.5180941522191658

Epoch: 5| Step: 10
Training loss: 2.1931147859367583
Validation loss: 2.5189084251692098

Epoch: 5| Step: 11
Training loss: 2.491998073350581
Validation loss: 2.50623776360725

Epoch: 353| Step: 0
Training loss: 2.4294684700812934
Validation loss: 2.533731852941481

Epoch: 5| Step: 1
Training loss: 2.0894039083358655
Validation loss: 2.587048813279369

Epoch: 5| Step: 2
Training loss: 1.8701363106887798
Validation loss: 2.629533221531401

Epoch: 5| Step: 3
Training loss: 2.102548587704852
Validation loss: 2.736951591335849

Epoch: 5| Step: 4
Training loss: 1.8891747326952837
Validation loss: 2.7438483212638296

Epoch: 5| Step: 5
Training loss: 2.266071354536326
Validation loss: 2.727073778165354

Epoch: 5| Step: 6
Training loss: 2.5089495686601264
Validation loss: 2.695214521313451

Epoch: 5| Step: 7
Training loss: 2.2909984539198267
Validation loss: 2.632674586214699

Epoch: 5| Step: 8
Training loss: 2.172804270026066
Validation loss: 2.5846359765398907

Epoch: 5| Step: 9
Training loss: 2.17092578371356
Validation loss: 2.5262040089355238

Epoch: 5| Step: 10
Training loss: 1.9274884871993745
Validation loss: 2.528067153627233

Epoch: 5| Step: 11
Training loss: 1.414607496247182
Validation loss: 2.525541501161594

Epoch: 354| Step: 0
Training loss: 1.92874017234568
Validation loss: 2.515483765359343

Epoch: 5| Step: 1
Training loss: 3.168245540996536
Validation loss: 2.5135457546444875

Epoch: 5| Step: 2
Training loss: 2.0822320952170656
Validation loss: 2.520519167394038

Epoch: 5| Step: 3
Training loss: 2.0344585020680475
Validation loss: 2.515364578146493

Epoch: 5| Step: 4
Training loss: 1.9821732689329936
Validation loss: 2.516198173920322

Epoch: 5| Step: 5
Training loss: 2.012565242112604
Validation loss: 2.5380552475196487

Epoch: 5| Step: 6
Training loss: 1.8956294386774324
Validation loss: 2.554159850712488

Epoch: 5| Step: 7
Training loss: 2.125825048610206
Validation loss: 2.6083817637967606

Epoch: 5| Step: 8
Training loss: 2.29608732458191
Validation loss: 2.66241436538526

Epoch: 5| Step: 9
Training loss: 2.5088337277675428
Validation loss: 2.691821789232948

Epoch: 5| Step: 10
Training loss: 2.051438348039464
Validation loss: 2.691313824591502

Epoch: 5| Step: 11
Training loss: 1.953476042671625
Validation loss: 2.69299160459135

Epoch: 355| Step: 0
Training loss: 1.9605516152819573
Validation loss: 2.6609946230784227

Epoch: 5| Step: 1
Training loss: 2.46480128618954
Validation loss: 2.6474033575997353

Epoch: 5| Step: 2
Training loss: 1.6186477776142232
Validation loss: 2.6519990340262733

Epoch: 5| Step: 3
Training loss: 2.196793352023385
Validation loss: 2.6320723899825977

Epoch: 5| Step: 4
Training loss: 2.0410510192430458
Validation loss: 2.603070468339041

Epoch: 5| Step: 5
Training loss: 2.2620249592005264
Validation loss: 2.5902569701512697

Epoch: 5| Step: 6
Training loss: 2.4964314741207034
Validation loss: 2.595800160205749

Epoch: 5| Step: 7
Training loss: 1.459998497113016
Validation loss: 2.5519758565160755

Epoch: 5| Step: 8
Training loss: 1.4059317758566174
Validation loss: 2.5555980160256446

Epoch: 5| Step: 9
Training loss: 2.1217635697108084
Validation loss: 2.553796883201106

Epoch: 5| Step: 10
Training loss: 2.419354708681821
Validation loss: 2.5652087982577174

Epoch: 5| Step: 11
Training loss: 1.2057821483245386
Validation loss: 2.5735001050525264

Epoch: 356| Step: 0
Training loss: 1.616559777544208
Validation loss: 2.546452110769996

Epoch: 5| Step: 1
Training loss: 2.528054752010446
Validation loss: 2.5522037782597957

Epoch: 5| Step: 2
Training loss: 1.7864961166019335
Validation loss: 2.562709679592498

Epoch: 5| Step: 3
Training loss: 2.25737771464501
Validation loss: 2.572375898379864

Epoch: 5| Step: 4
Training loss: 1.5379444069308275
Validation loss: 2.5650125684052236

Epoch: 5| Step: 5
Training loss: 2.1542789461940943
Validation loss: 2.593413200878992

Epoch: 5| Step: 6
Training loss: 2.5548174063874836
Validation loss: 2.5865143807635333

Epoch: 5| Step: 7
Training loss: 2.0070280331191985
Validation loss: 2.622703126381039

Epoch: 5| Step: 8
Training loss: 2.5054867616820222
Validation loss: 2.6601082026791385

Epoch: 5| Step: 9
Training loss: 1.5981779482547367
Validation loss: 2.6750152196777988

Epoch: 5| Step: 10
Training loss: 1.8421684205909046
Validation loss: 2.633207697124706

Epoch: 5| Step: 11
Training loss: 2.834252900140198
Validation loss: 2.64182944733889

Epoch: 357| Step: 0
Training loss: 1.638134473811833
Validation loss: 2.592365308921075

Epoch: 5| Step: 1
Training loss: 2.522885099718058
Validation loss: 2.5718097287590576

Epoch: 5| Step: 2
Training loss: 1.9948505031052777
Validation loss: 2.5464819739456668

Epoch: 5| Step: 3
Training loss: 1.9808379361499444
Validation loss: 2.5145849601363195

Epoch: 5| Step: 4
Training loss: 2.0890644082037144
Validation loss: 2.505419634329783

Epoch: 5| Step: 5
Training loss: 2.1580539841709685
Validation loss: 2.502697236668865

Epoch: 5| Step: 6
Training loss: 2.112489562601342
Validation loss: 2.512391482329844

Epoch: 5| Step: 7
Training loss: 2.231009235802397
Validation loss: 2.514327622970109

Epoch: 5| Step: 8
Training loss: 1.7913198431098825
Validation loss: 2.5367100464758

Epoch: 5| Step: 9
Training loss: 2.7037063590878123
Validation loss: 2.533154889355601

Epoch: 5| Step: 10
Training loss: 1.7131135245282938
Validation loss: 2.5786882421039006

Epoch: 5| Step: 11
Training loss: 1.626663017281884
Validation loss: 2.6008559328087593

Epoch: 358| Step: 0
Training loss: 1.8995475506394945
Validation loss: 2.638082900200534

Epoch: 5| Step: 1
Training loss: 1.9211506913082037
Validation loss: 2.6237295156742118

Epoch: 5| Step: 2
Training loss: 2.3485211446946006
Validation loss: 2.6244531508423887

Epoch: 5| Step: 3
Training loss: 2.2640066746791945
Validation loss: 2.61179906212109

Epoch: 5| Step: 4
Training loss: 2.194337241321375
Validation loss: 2.6026921936369756

Epoch: 5| Step: 5
Training loss: 1.8702349194950112
Validation loss: 2.58644572677541

Epoch: 5| Step: 6
Training loss: 2.177545404146968
Validation loss: 2.5663414399718074

Epoch: 5| Step: 7
Training loss: 2.147754574520056
Validation loss: 2.5485516667399164

Epoch: 5| Step: 8
Training loss: 2.1999093253783153
Validation loss: 2.556116262604511

Epoch: 5| Step: 9
Training loss: 2.016613976391876
Validation loss: 2.548271092997241

Epoch: 5| Step: 10
Training loss: 1.4821245500940794
Validation loss: 2.56208669616864

Epoch: 5| Step: 11
Training loss: 1.0177525464192156
Validation loss: 2.5536749385632875

Epoch: 359| Step: 0
Training loss: 2.799356734089963
Validation loss: 2.5395701424212045

Epoch: 5| Step: 1
Training loss: 1.2978465565971697
Validation loss: 2.5490433057665896

Epoch: 5| Step: 2
Training loss: 2.2788298846799746
Validation loss: 2.569857846044345

Epoch: 5| Step: 3
Training loss: 1.8944625999361304
Validation loss: 2.586147676284061

Epoch: 5| Step: 4
Training loss: 1.9483027628035885
Validation loss: 2.5913495173821937

Epoch: 5| Step: 5
Training loss: 1.772590401285122
Validation loss: 2.5965007497004184

Epoch: 5| Step: 6
Training loss: 2.1550026201909325
Validation loss: 2.5857547818387747

Epoch: 5| Step: 7
Training loss: 1.9661670877347834
Validation loss: 2.6240477992049533

Epoch: 5| Step: 8
Training loss: 2.133655199962989
Validation loss: 2.5865856291937526

Epoch: 5| Step: 9
Training loss: 1.4161109208235363
Validation loss: 2.6114574581997387

Epoch: 5| Step: 10
Training loss: 1.400694065391293
Validation loss: 2.615507981885611

Epoch: 5| Step: 11
Training loss: 3.478000574893915
Validation loss: 2.6101497634461515

Epoch: 360| Step: 0
Training loss: 2.2633036329580123
Validation loss: 2.613645998556298

Epoch: 5| Step: 1
Training loss: 1.8691776794140915
Validation loss: 2.6383437247462256

Epoch: 5| Step: 2
Training loss: 1.7403726062611613
Validation loss: 2.6350498032070706

Epoch: 5| Step: 3
Training loss: 2.272335139170869
Validation loss: 2.689759890057637

Epoch: 5| Step: 4
Training loss: 2.1827823448419252
Validation loss: 2.6325674424041168

Epoch: 5| Step: 5
Training loss: 1.8657096217403228
Validation loss: 2.6171147957947074

Epoch: 5| Step: 6
Training loss: 1.886497026450743
Validation loss: 2.564056520766951

Epoch: 5| Step: 7
Training loss: 1.436618866593636
Validation loss: 2.5494538845929706

Epoch: 5| Step: 8
Training loss: 2.6660378032502416
Validation loss: 2.566333465860161

Epoch: 5| Step: 9
Training loss: 2.14284539446562
Validation loss: 2.551550791445497

Epoch: 5| Step: 10
Training loss: 2.0187309051649907
Validation loss: 2.529125896158762

Epoch: 5| Step: 11
Training loss: 1.4398841988837394
Validation loss: 2.5462779572015912

Epoch: 361| Step: 0
Training loss: 1.506199027817478
Validation loss: 2.550780687239596

Epoch: 5| Step: 1
Training loss: 2.3965323271613497
Validation loss: 2.5190175994189086

Epoch: 5| Step: 2
Training loss: 1.6264565615642101
Validation loss: 2.521919147998432

Epoch: 5| Step: 3
Training loss: 2.175683942224853
Validation loss: 2.5573890820275924

Epoch: 5| Step: 4
Training loss: 2.2582066597784674
Validation loss: 2.5286379708280156

Epoch: 5| Step: 5
Training loss: 2.5023614221211465
Validation loss: 2.514545540787689

Epoch: 5| Step: 6
Training loss: 1.8060399392021784
Validation loss: 2.5520639315016878

Epoch: 5| Step: 7
Training loss: 1.9182568118191834
Validation loss: 2.552042693508716

Epoch: 5| Step: 8
Training loss: 2.559846853652392
Validation loss: 2.609918457818284

Epoch: 5| Step: 9
Training loss: 1.7401394288335075
Validation loss: 2.594736237293144

Epoch: 5| Step: 10
Training loss: 1.347431462655732
Validation loss: 2.56627112371091

Epoch: 5| Step: 11
Training loss: 0.8919919883706088
Validation loss: 2.5704782813195415

Epoch: 362| Step: 0
Training loss: 1.879198904106337
Validation loss: 2.539417312479864

Epoch: 5| Step: 1
Training loss: 2.023439620911654
Validation loss: 2.546370477767848

Epoch: 5| Step: 2
Training loss: 1.3698406960109686
Validation loss: 2.5254414517155093

Epoch: 5| Step: 3
Training loss: 2.3870061273707934
Validation loss: 2.5351624177721543

Epoch: 5| Step: 4
Training loss: 2.4756896589773
Validation loss: 2.5099844633054706

Epoch: 5| Step: 5
Training loss: 1.693977357589204
Validation loss: 2.545257542319133

Epoch: 5| Step: 6
Training loss: 1.6106751014575982
Validation loss: 2.5384562428820443

Epoch: 5| Step: 7
Training loss: 1.6791563391860904
Validation loss: 2.549281568860918

Epoch: 5| Step: 8
Training loss: 2.3642484340930783
Validation loss: 2.577223942055219

Epoch: 5| Step: 9
Training loss: 1.3572924655181025
Validation loss: 2.586763021615825

Epoch: 5| Step: 10
Training loss: 2.7402293286103747
Validation loss: 2.5788312387790957

Epoch: 5| Step: 11
Training loss: 0.9127526312408512
Validation loss: 2.5690944533500653

Epoch: 363| Step: 0
Training loss: 2.1061623303197012
Validation loss: 2.58200675733437

Epoch: 5| Step: 1
Training loss: 1.9721159846686183
Validation loss: 2.58043137855428

Epoch: 5| Step: 2
Training loss: 2.1445990657680207
Validation loss: 2.5629786959179586

Epoch: 5| Step: 3
Training loss: 1.698000837552748
Validation loss: 2.590652040494598

Epoch: 5| Step: 4
Training loss: 2.1431482299008504
Validation loss: 2.5319521954326483

Epoch: 5| Step: 5
Training loss: 1.863478676115364
Validation loss: 2.542389615743775

Epoch: 5| Step: 6
Training loss: 2.083648339934188
Validation loss: 2.5733500564810887

Epoch: 5| Step: 7
Training loss: 1.471348351211083
Validation loss: 2.557601262533747

Epoch: 5| Step: 8
Training loss: 2.503259917586733
Validation loss: 2.5569687048277827

Epoch: 5| Step: 9
Training loss: 2.0506394110175865
Validation loss: 2.5828143811166155

Epoch: 5| Step: 10
Training loss: 1.758622453371444
Validation loss: 2.5750546562233563

Epoch: 5| Step: 11
Training loss: 1.67110446749938
Validation loss: 2.60256567506621

Epoch: 364| Step: 0
Training loss: 1.4526794735042134
Validation loss: 2.6518128603019337

Epoch: 5| Step: 1
Training loss: 2.33338600053839
Validation loss: 2.643166697598612

Epoch: 5| Step: 2
Training loss: 1.6977124081560118
Validation loss: 2.6368447921202876

Epoch: 5| Step: 3
Training loss: 1.6345104533386638
Validation loss: 2.633845789657607

Epoch: 5| Step: 4
Training loss: 1.9544932951227876
Validation loss: 2.6090949359375766

Epoch: 5| Step: 5
Training loss: 1.8301894440071498
Validation loss: 2.590599440788694

Epoch: 5| Step: 6
Training loss: 1.9309648000747728
Validation loss: 2.5919507040192307

Epoch: 5| Step: 7
Training loss: 1.5894554470042483
Validation loss: 2.619010138811138

Epoch: 5| Step: 8
Training loss: 1.869684632477816
Validation loss: 2.6039906073501937

Epoch: 5| Step: 9
Training loss: 2.091642429267106
Validation loss: 2.5741349024761475

Epoch: 5| Step: 10
Training loss: 2.7406752021741387
Validation loss: 2.560551662523036

Epoch: 5| Step: 11
Training loss: 3.3382745994039182
Validation loss: 2.5886975144892905

Epoch: 365| Step: 0
Training loss: 2.080361790187002
Validation loss: 2.657544183540222

Epoch: 5| Step: 1
Training loss: 2.036908996616699
Validation loss: 2.69969593693673

Epoch: 5| Step: 2
Training loss: 1.964211576474638
Validation loss: 2.717697286869719

Epoch: 5| Step: 3
Training loss: 2.403452646765511
Validation loss: 2.675182425882968

Epoch: 5| Step: 4
Training loss: 2.3825406279006898
Validation loss: 2.6638858098925087

Epoch: 5| Step: 5
Training loss: 2.009466299115637
Validation loss: 2.6332020494977315

Epoch: 5| Step: 6
Training loss: 1.4527411005039348
Validation loss: 2.580534019495553

Epoch: 5| Step: 7
Training loss: 1.8685122463079178
Validation loss: 2.5783875572525248

Epoch: 5| Step: 8
Training loss: 2.1474209686764785
Validation loss: 2.5604977965531357

Epoch: 5| Step: 9
Training loss: 1.953712314039678
Validation loss: 2.5329654712517335

Epoch: 5| Step: 10
Training loss: 2.001549954639341
Validation loss: 2.5196928381544947

Epoch: 5| Step: 11
Training loss: 0.9433080686908574
Validation loss: 2.524956819586841

Epoch: 366| Step: 0
Training loss: 2.4954001070336096
Validation loss: 2.522029669019678

Epoch: 5| Step: 1
Training loss: 1.7519421018936245
Validation loss: 2.531547352315001

Epoch: 5| Step: 2
Training loss: 1.9760704785144985
Validation loss: 2.5350614235124738

Epoch: 5| Step: 3
Training loss: 1.702080992841415
Validation loss: 2.505864580188161

Epoch: 5| Step: 4
Training loss: 1.7163516564210102
Validation loss: 2.5133633961532293

Epoch: 5| Step: 5
Training loss: 3.120603596915512
Validation loss: 2.532064964040949

Epoch: 5| Step: 6
Training loss: 1.8545457973836899
Validation loss: 2.563234315113265

Epoch: 5| Step: 7
Training loss: 1.9256031503400401
Validation loss: 2.626332342263193

Epoch: 5| Step: 8
Training loss: 1.737195719689022
Validation loss: 2.6751643117013724

Epoch: 5| Step: 9
Training loss: 1.8807564426987695
Validation loss: 2.717217969220872

Epoch: 5| Step: 10
Training loss: 1.746009227234534
Validation loss: 2.714823463419034

Epoch: 5| Step: 11
Training loss: 1.9187578182496077
Validation loss: 2.7335097915011657

Epoch: 367| Step: 0
Training loss: 1.9552244575606554
Validation loss: 2.608270689381649

Epoch: 5| Step: 1
Training loss: 1.7638742324473833
Validation loss: 2.548862512583074

Epoch: 5| Step: 2
Training loss: 2.191116939493509
Validation loss: 2.5013997093475933

Epoch: 5| Step: 3
Training loss: 2.0327632255944974
Validation loss: 2.4688544995689004

Epoch: 5| Step: 4
Training loss: 2.5125171110415083
Validation loss: 2.4677410317333583

Epoch: 5| Step: 5
Training loss: 2.607579144367554
Validation loss: 2.4697365620446994

Epoch: 5| Step: 6
Training loss: 2.175249291526294
Validation loss: 2.4710633669897026

Epoch: 5| Step: 7
Training loss: 1.9028647334083661
Validation loss: 2.4623650865662996

Epoch: 5| Step: 8
Training loss: 1.6191271515620431
Validation loss: 2.4885742238596156

Epoch: 5| Step: 9
Training loss: 1.490929037952416
Validation loss: 2.484240126397565

Epoch: 5| Step: 10
Training loss: 1.8882995049032596
Validation loss: 2.529390205222601

Epoch: 5| Step: 11
Training loss: 2.206896860537836
Validation loss: 2.5519751013298038

Epoch: 368| Step: 0
Training loss: 1.8728223234466732
Validation loss: 2.5703114989799554

Epoch: 5| Step: 1
Training loss: 2.029301104573311
Validation loss: 2.5895952208090898

Epoch: 5| Step: 2
Training loss: 1.9850522184830226
Validation loss: 2.5674690356889998

Epoch: 5| Step: 3
Training loss: 2.171856667420661
Validation loss: 2.586248285032736

Epoch: 5| Step: 4
Training loss: 1.890381221975661
Validation loss: 2.5617613503172496

Epoch: 5| Step: 5
Training loss: 2.1128089362877382
Validation loss: 2.5444749784742915

Epoch: 5| Step: 6
Training loss: 1.832103215412562
Validation loss: 2.53352133174649

Epoch: 5| Step: 7
Training loss: 2.0430842817326904
Validation loss: 2.5529922436829073

Epoch: 5| Step: 8
Training loss: 1.6181197865425365
Validation loss: 2.5340639023003284

Epoch: 5| Step: 9
Training loss: 2.016401392721351
Validation loss: 2.55238840394726

Epoch: 5| Step: 10
Training loss: 2.1997992120495318
Validation loss: 2.5556080838404913

Epoch: 5| Step: 11
Training loss: 2.0114904774159044
Validation loss: 2.560238518710921

Epoch: 369| Step: 0
Training loss: 1.936255947766364
Validation loss: 2.608146644854108

Epoch: 5| Step: 1
Training loss: 2.1794668653384375
Validation loss: 2.6025912510432643

Epoch: 5| Step: 2
Training loss: 2.26371611057404
Validation loss: 2.561431239324687

Epoch: 5| Step: 3
Training loss: 2.089298925951871
Validation loss: 2.5573816859813308

Epoch: 5| Step: 4
Training loss: 2.2438590700634817
Validation loss: 2.5806811867471082

Epoch: 5| Step: 5
Training loss: 1.4986599658587743
Validation loss: 2.5872567049383717

Epoch: 5| Step: 6
Training loss: 2.3938963205422783
Validation loss: 2.5763630828581805

Epoch: 5| Step: 7
Training loss: 1.5157778161472724
Validation loss: 2.6240136624679335

Epoch: 5| Step: 8
Training loss: 1.6792326555309027
Validation loss: 2.6310340164471664

Epoch: 5| Step: 9
Training loss: 1.6100848956263976
Validation loss: 2.6740257797582023

Epoch: 5| Step: 10
Training loss: 2.0366827279356103
Validation loss: 2.6387741893525174

Epoch: 5| Step: 11
Training loss: 0.7652363861353542
Validation loss: 2.680219328722223

Epoch: 370| Step: 0
Training loss: 1.5760653813156484
Validation loss: 2.6438772161911928

Epoch: 5| Step: 1
Training loss: 1.9235653770448315
Validation loss: 2.6639006967341423

Epoch: 5| Step: 2
Training loss: 1.5774441751798114
Validation loss: 2.6220639551370986

Epoch: 5| Step: 3
Training loss: 2.197771426158367
Validation loss: 2.644143114104292

Epoch: 5| Step: 4
Training loss: 1.6927869416593144
Validation loss: 2.6031531167162387

Epoch: 5| Step: 5
Training loss: 1.3349055716161484
Validation loss: 2.584444377510711

Epoch: 5| Step: 6
Training loss: 2.2038157577354256
Validation loss: 2.584400177186827

Epoch: 5| Step: 7
Training loss: 1.8936217336997285
Validation loss: 2.592984515528474

Epoch: 5| Step: 8
Training loss: 2.3035787728024633
Validation loss: 2.566955151591033

Epoch: 5| Step: 9
Training loss: 2.354132480429383
Validation loss: 2.581442584534474

Epoch: 5| Step: 10
Training loss: 2.1700494352765767
Validation loss: 2.561194897746699

Epoch: 5| Step: 11
Training loss: 1.4219585855250372
Validation loss: 2.578261431542401

Epoch: 371| Step: 0
Training loss: 1.807917227386343
Validation loss: 2.5687870496319487

Epoch: 5| Step: 1
Training loss: 1.9563180076794826
Validation loss: 2.5673400171117455

Epoch: 5| Step: 2
Training loss: 2.2102991267624494
Validation loss: 2.602752489758512

Epoch: 5| Step: 3
Training loss: 1.3947260103543797
Validation loss: 2.6151186495097973

Epoch: 5| Step: 4
Training loss: 1.8358246464234462
Validation loss: 2.6055014196937503

Epoch: 5| Step: 5
Training loss: 1.856020811169789
Validation loss: 2.6034569052818326

Epoch: 5| Step: 6
Training loss: 1.611813373903729
Validation loss: 2.6116486121841618

Epoch: 5| Step: 7
Training loss: 2.071583483686528
Validation loss: 2.6197519823914974

Epoch: 5| Step: 8
Training loss: 2.4273098906729826
Validation loss: 2.632693732324986

Epoch: 5| Step: 9
Training loss: 1.84562219512964
Validation loss: 2.604251071833645

Epoch: 5| Step: 10
Training loss: 2.1189585805304025
Validation loss: 2.576574221357461

Epoch: 5| Step: 11
Training loss: 1.9891485634619106
Validation loss: 2.56658190973302

Epoch: 372| Step: 0
Training loss: 1.968615936074345
Validation loss: 2.6250078640169088

Epoch: 5| Step: 1
Training loss: 1.539293688145595
Validation loss: 2.5890372023941763

Epoch: 5| Step: 2
Training loss: 1.410287317329685
Validation loss: 2.589079171040529

Epoch: 5| Step: 3
Training loss: 2.303986316633653
Validation loss: 2.5732914668364533

Epoch: 5| Step: 4
Training loss: 2.5880284456225673
Validation loss: 2.587447141638789

Epoch: 5| Step: 5
Training loss: 2.085165845463708
Validation loss: 2.5827679220430793

Epoch: 5| Step: 6
Training loss: 2.0915759741991606
Validation loss: 2.580217360099698

Epoch: 5| Step: 7
Training loss: 1.7039151240016728
Validation loss: 2.6524668399524955

Epoch: 5| Step: 8
Training loss: 1.8435871892909819
Validation loss: 2.5774073054569904

Epoch: 5| Step: 9
Training loss: 2.0530913792939067
Validation loss: 2.6038254755941708

Epoch: 5| Step: 10
Training loss: 1.8376562635968123
Validation loss: 2.5568275315341764

Epoch: 5| Step: 11
Training loss: 1.5629888151406852
Validation loss: 2.538667884874786

Epoch: 373| Step: 0
Training loss: 1.3105393251750213
Validation loss: 2.5552047843509316

Epoch: 5| Step: 1
Training loss: 1.6005242680881968
Validation loss: 2.538771087356057

Epoch: 5| Step: 2
Training loss: 1.87505353215411
Validation loss: 2.5396941235675246

Epoch: 5| Step: 3
Training loss: 1.4279631341401566
Validation loss: 2.531093937964713

Epoch: 5| Step: 4
Training loss: 2.5074138383904447
Validation loss: 2.5619731532056855

Epoch: 5| Step: 5
Training loss: 2.2258460247325895
Validation loss: 2.578289639388976

Epoch: 5| Step: 6
Training loss: 2.3704970990130834
Validation loss: 2.5998185338980937

Epoch: 5| Step: 7
Training loss: 2.172812170464556
Validation loss: 2.617120109943078

Epoch: 5| Step: 8
Training loss: 2.1756797780562898
Validation loss: 2.6270890702969747

Epoch: 5| Step: 9
Training loss: 1.5831008874357329
Validation loss: 2.639456379393368

Epoch: 5| Step: 10
Training loss: 2.1016068577959834
Validation loss: 2.63361464901122

Epoch: 5| Step: 11
Training loss: 2.1131408983257027
Validation loss: 2.6428094289466446

Epoch: 374| Step: 0
Training loss: 2.3543046443868607
Validation loss: 2.6238217320661765

Epoch: 5| Step: 1
Training loss: 2.466734534266451
Validation loss: 2.575248809324364

Epoch: 5| Step: 2
Training loss: 1.7515584954140286
Validation loss: 2.549847664209729

Epoch: 5| Step: 3
Training loss: 2.3658211670827316
Validation loss: 2.5497494100722164

Epoch: 5| Step: 4
Training loss: 1.3948810897244341
Validation loss: 2.5358434528454374

Epoch: 5| Step: 5
Training loss: 2.2259967285913658
Validation loss: 2.5499297001442

Epoch: 5| Step: 6
Training loss: 1.5984010336138463
Validation loss: 2.531294198297876

Epoch: 5| Step: 7
Training loss: 2.102622293188318
Validation loss: 2.5350851549584434

Epoch: 5| Step: 8
Training loss: 1.603398828748285
Validation loss: 2.5574120974233625

Epoch: 5| Step: 9
Training loss: 1.8604453075748872
Validation loss: 2.573959715742612

Epoch: 5| Step: 10
Training loss: 1.7042975632716206
Validation loss: 2.612847053102563

Epoch: 5| Step: 11
Training loss: 1.2808458109396588
Validation loss: 2.6491821240032856

Epoch: 375| Step: 0
Training loss: 2.446962135293237
Validation loss: 2.7061490726518858

Epoch: 5| Step: 1
Training loss: 2.3920697602462435
Validation loss: 2.6977957191506565

Epoch: 5| Step: 2
Training loss: 1.9654677141634
Validation loss: 2.7248205068950853

Epoch: 5| Step: 3
Training loss: 1.7407771675809114
Validation loss: 2.6782642640620304

Epoch: 5| Step: 4
Training loss: 1.8397531669331293
Validation loss: 2.6185673468658335

Epoch: 5| Step: 5
Training loss: 1.3995757771536268
Validation loss: 2.5881540186014504

Epoch: 5| Step: 6
Training loss: 1.1864395928291318
Validation loss: 2.5731931272748487

Epoch: 5| Step: 7
Training loss: 1.9654681387264346
Validation loss: 2.545978169813858

Epoch: 5| Step: 8
Training loss: 2.579269062858818
Validation loss: 2.5751594943122247

Epoch: 5| Step: 9
Training loss: 1.7331201636229372
Validation loss: 2.555953368391764

Epoch: 5| Step: 10
Training loss: 1.6888912258773385
Validation loss: 2.578737286388266

Epoch: 5| Step: 11
Training loss: 3.0615981973527635
Validation loss: 2.6021306025719366

Epoch: 376| Step: 0
Training loss: 2.533400952122721
Validation loss: 2.602758142388654

Epoch: 5| Step: 1
Training loss: 1.818583965260442
Validation loss: 2.6374673604828853

Epoch: 5| Step: 2
Training loss: 1.5988273525539072
Validation loss: 2.6506432525544805

Epoch: 5| Step: 3
Training loss: 1.8085229583793254
Validation loss: 2.663515278985501

Epoch: 5| Step: 4
Training loss: 1.8745079030551812
Validation loss: 2.639029617210109

Epoch: 5| Step: 5
Training loss: 1.9826481431640044
Validation loss: 2.5695965783441923

Epoch: 5| Step: 6
Training loss: 1.6405903403844508
Validation loss: 2.5528395771432497

Epoch: 5| Step: 7
Training loss: 1.9943755457012753
Validation loss: 2.5501201721310753

Epoch: 5| Step: 8
Training loss: 1.9526467920431279
Validation loss: 2.486571806188337

Epoch: 5| Step: 9
Training loss: 1.9373816792445384
Validation loss: 2.52506339541252

Epoch: 5| Step: 10
Training loss: 2.269958876014631
Validation loss: 2.532477516835195

Epoch: 5| Step: 11
Training loss: 0.9534805135110973
Validation loss: 2.5244990380629675

Epoch: 377| Step: 0
Training loss: 1.7728648332429247
Validation loss: 2.5044331385546656

Epoch: 5| Step: 1
Training loss: 1.471023504410434
Validation loss: 2.528576844384446

Epoch: 5| Step: 2
Training loss: 2.2976982042826832
Validation loss: 2.578445499419932

Epoch: 5| Step: 3
Training loss: 1.4297306908925977
Validation loss: 2.564120718298737

Epoch: 5| Step: 4
Training loss: 2.446383793075997
Validation loss: 2.5805952664207794

Epoch: 5| Step: 5
Training loss: 2.1048178719495825
Validation loss: 2.5820899221859355

Epoch: 5| Step: 6
Training loss: 2.1680494688661245
Validation loss: 2.5691784073739456

Epoch: 5| Step: 7
Training loss: 1.9465124267173617
Validation loss: 2.567277691665929

Epoch: 5| Step: 8
Training loss: 1.8813601388722605
Validation loss: 2.553767021929724

Epoch: 5| Step: 9
Training loss: 2.153399255391089
Validation loss: 2.594782256195225

Epoch: 5| Step: 10
Training loss: 1.4734748973125582
Validation loss: 2.5537765815423223

Epoch: 5| Step: 11
Training loss: 0.729655419896308
Validation loss: 2.5299631466147807

Epoch: 378| Step: 0
Training loss: 1.6634511048331948
Validation loss: 2.5414673669773706

Epoch: 5| Step: 1
Training loss: 2.175745307995325
Validation loss: 2.537725067022955

Epoch: 5| Step: 2
Training loss: 1.7748754108384688
Validation loss: 2.557236374971428

Epoch: 5| Step: 3
Training loss: 1.7426466400967813
Validation loss: 2.540043642283643

Epoch: 5| Step: 4
Training loss: 1.614534127090624
Validation loss: 2.610377178263872

Epoch: 5| Step: 5
Training loss: 1.8596172655778997
Validation loss: 2.5959135170722636

Epoch: 5| Step: 6
Training loss: 1.7643325261115923
Validation loss: 2.597028915642609

Epoch: 5| Step: 7
Training loss: 1.838584776923162
Validation loss: 2.617724372115349

Epoch: 5| Step: 8
Training loss: 2.310201998048991
Validation loss: 2.623557038544

Epoch: 5| Step: 9
Training loss: 1.7736755076943609
Validation loss: 2.6053050274288214

Epoch: 5| Step: 10
Training loss: 2.3097619007479913
Validation loss: 2.6000438492390763

Epoch: 5| Step: 11
Training loss: 2.6490739715892992
Validation loss: 2.5793507446104993

Epoch: 379| Step: 0
Training loss: 1.9133555449659707
Validation loss: 2.59046075604745

Epoch: 5| Step: 1
Training loss: 1.9325603150976889
Validation loss: 2.58991504492423

Epoch: 5| Step: 2
Training loss: 1.7398394169644278
Validation loss: 2.577885610852621

Epoch: 5| Step: 3
Training loss: 2.257942380766356
Validation loss: 2.586072674279096

Epoch: 5| Step: 4
Training loss: 1.532104409516981
Validation loss: 2.5776946276946253

Epoch: 5| Step: 5
Training loss: 1.580044777875473
Validation loss: 2.5615144827139966

Epoch: 5| Step: 6
Training loss: 1.8665038577105564
Validation loss: 2.596520055421746

Epoch: 5| Step: 7
Training loss: 2.417994485203565
Validation loss: 2.5648057573633922

Epoch: 5| Step: 8
Training loss: 2.199012109727463
Validation loss: 2.5648576427574965

Epoch: 5| Step: 9
Training loss: 1.8969324998766126
Validation loss: 2.577176692220402

Epoch: 5| Step: 10
Training loss: 1.5367798894405365
Validation loss: 2.53904763241841

Epoch: 5| Step: 11
Training loss: 1.3675255057904503
Validation loss: 2.600336356750228

Epoch: 380| Step: 0
Training loss: 1.9806470922343637
Validation loss: 2.606432281419641

Epoch: 5| Step: 1
Training loss: 1.93046720868261
Validation loss: 2.6121942590683176

Epoch: 5| Step: 2
Training loss: 1.4984958577650909
Validation loss: 2.628794497211427

Epoch: 5| Step: 3
Training loss: 2.152559965319637
Validation loss: 2.6012275182292335

Epoch: 5| Step: 4
Training loss: 1.7790669900933658
Validation loss: 2.5836335432035114

Epoch: 5| Step: 5
Training loss: 1.968781122839626
Validation loss: 2.615103990202407

Epoch: 5| Step: 6
Training loss: 1.6201721513195748
Validation loss: 2.5753598884512314

Epoch: 5| Step: 7
Training loss: 1.6564493599153918
Validation loss: 2.5668350937519024

Epoch: 5| Step: 8
Training loss: 1.5278432668270956
Validation loss: 2.570318212377197

Epoch: 5| Step: 9
Training loss: 2.2804615278087184
Validation loss: 2.5497660581014077

Epoch: 5| Step: 10
Training loss: 2.399075004025294
Validation loss: 2.539528190748489

Epoch: 5| Step: 11
Training loss: 1.4855079744087072
Validation loss: 2.5272855127966314

Epoch: 381| Step: 0
Training loss: 2.1814115535512313
Validation loss: 2.553551828789988

Epoch: 5| Step: 1
Training loss: 2.312140668839952
Validation loss: 2.5575542075632547

Epoch: 5| Step: 2
Training loss: 1.3514553314233666
Validation loss: 2.5767484708456827

Epoch: 5| Step: 3
Training loss: 2.0537768764675945
Validation loss: 2.6313667289593385

Epoch: 5| Step: 4
Training loss: 1.922062376238728
Validation loss: 2.636187835742417

Epoch: 5| Step: 5
Training loss: 1.8684538692734116
Validation loss: 2.6705080368862886

Epoch: 5| Step: 6
Training loss: 1.764994348295419
Validation loss: 2.6733513410021983

Epoch: 5| Step: 7
Training loss: 1.8572171295950244
Validation loss: 2.663964240834132

Epoch: 5| Step: 8
Training loss: 2.1067098098674966
Validation loss: 2.630105276575282

Epoch: 5| Step: 9
Training loss: 1.8211372700862483
Validation loss: 2.5783972394141967

Epoch: 5| Step: 10
Training loss: 1.875500040134154
Validation loss: 2.5480302870071734

Epoch: 5| Step: 11
Training loss: 1.1444436518245615
Validation loss: 2.5847525133693283

Epoch: 382| Step: 0
Training loss: 2.2665763173141715
Validation loss: 2.565399483400184

Epoch: 5| Step: 1
Training loss: 2.403656490766567
Validation loss: 2.5543516990221735

Epoch: 5| Step: 2
Training loss: 1.7578314886127164
Validation loss: 2.5455347837175726

Epoch: 5| Step: 3
Training loss: 1.4428657234724511
Validation loss: 2.570656456779977

Epoch: 5| Step: 4
Training loss: 2.4217383561502706
Validation loss: 2.558221513300845

Epoch: 5| Step: 5
Training loss: 1.557747670989361
Validation loss: 2.6062684097371673

Epoch: 5| Step: 6
Training loss: 1.7851948473073698
Validation loss: 2.6337592500784615

Epoch: 5| Step: 7
Training loss: 1.8226312759068464
Validation loss: 2.6318158339450375

Epoch: 5| Step: 8
Training loss: 2.1523487347166075
Validation loss: 2.6617658378990012

Epoch: 5| Step: 9
Training loss: 1.593997861250492
Validation loss: 2.638867713330174

Epoch: 5| Step: 10
Training loss: 1.9276825531677548
Validation loss: 2.616279917252943

Epoch: 5| Step: 11
Training loss: 2.900542695140095
Validation loss: 2.5798830299821134

Epoch: 383| Step: 0
Training loss: 2.9023792372493995
Validation loss: 2.5554367117844836

Epoch: 5| Step: 1
Training loss: 1.2686284537889008
Validation loss: 2.563746990169232

Epoch: 5| Step: 2
Training loss: 1.1227943733635615
Validation loss: 2.5810168876097928

Epoch: 5| Step: 3
Training loss: 2.135939991411655
Validation loss: 2.576046346518007

Epoch: 5| Step: 4
Training loss: 2.2646002194764385
Validation loss: 2.551685716185006

Epoch: 5| Step: 5
Training loss: 2.0631426185796293
Validation loss: 2.5719708945101787

Epoch: 5| Step: 6
Training loss: 1.7450045403582684
Validation loss: 2.554175789356794

Epoch: 5| Step: 7
Training loss: 1.3639281740938245
Validation loss: 2.5872818678286817

Epoch: 5| Step: 8
Training loss: 1.6503615879009945
Validation loss: 2.5875287303158805

Epoch: 5| Step: 9
Training loss: 1.4783074296633636
Validation loss: 2.6313341670947916

Epoch: 5| Step: 10
Training loss: 2.0679726099454556
Validation loss: 2.629490039806334

Epoch: 5| Step: 11
Training loss: 1.336290190246654
Validation loss: 2.637646938889277

Epoch: 384| Step: 0
Training loss: 2.275923899754371
Validation loss: 2.620808865888327

Epoch: 5| Step: 1
Training loss: 1.4887036302393248
Validation loss: 2.624871708747354

Epoch: 5| Step: 2
Training loss: 2.0999593185844034
Validation loss: 2.593165573093244

Epoch: 5| Step: 3
Training loss: 1.7550112635367874
Validation loss: 2.594341949721667

Epoch: 5| Step: 4
Training loss: 2.2829397553805
Validation loss: 2.548067307223395

Epoch: 5| Step: 5
Training loss: 1.2180806791835943
Validation loss: 2.588600174660323

Epoch: 5| Step: 6
Training loss: 1.87833755991386
Validation loss: 2.5737933905835964

Epoch: 5| Step: 7
Training loss: 2.2218741329744045
Validation loss: 2.5676812576094137

Epoch: 5| Step: 8
Training loss: 1.9472174451983753
Validation loss: 2.5777709717861668

Epoch: 5| Step: 9
Training loss: 1.7767845531714508
Validation loss: 2.612941349202718

Epoch: 5| Step: 10
Training loss: 1.5649131450987561
Validation loss: 2.609029865092011

Epoch: 5| Step: 11
Training loss: 1.4213920024431597
Validation loss: 2.60686194876397

Epoch: 385| Step: 0
Training loss: 2.2889886525190737
Validation loss: 2.5543958164950817

Epoch: 5| Step: 1
Training loss: 1.6293518774150018
Validation loss: 2.5570241350493963

Epoch: 5| Step: 2
Training loss: 1.64827644320684
Validation loss: 2.576695741532173

Epoch: 5| Step: 3
Training loss: 1.7091210882816874
Validation loss: 2.5546235359420275

Epoch: 5| Step: 4
Training loss: 2.084255840778803
Validation loss: 2.5736858412539654

Epoch: 5| Step: 5
Training loss: 2.254384748682614
Validation loss: 2.563319490010499

Epoch: 5| Step: 6
Training loss: 1.6237568868794978
Validation loss: 2.6065137217446055

Epoch: 5| Step: 7
Training loss: 2.1974403142363954
Validation loss: 2.5651006411352313

Epoch: 5| Step: 8
Training loss: 2.304071065932576
Validation loss: 2.594399382408438

Epoch: 5| Step: 9
Training loss: 1.7143667335324861
Validation loss: 2.656001064379079

Epoch: 5| Step: 10
Training loss: 1.6194694010383952
Validation loss: 2.665883144119207

Epoch: 5| Step: 11
Training loss: 1.289460600444454
Validation loss: 2.7282890129237436

Epoch: 386| Step: 0
Training loss: 2.2578508314422985
Validation loss: 2.688152766240642

Epoch: 5| Step: 1
Training loss: 1.8353649788837343
Validation loss: 2.669656352914111

Epoch: 5| Step: 2
Training loss: 2.0529213628708107
Validation loss: 2.6344645379757257

Epoch: 5| Step: 3
Training loss: 1.6930298798161227
Validation loss: 2.5972420192469454

Epoch: 5| Step: 4
Training loss: 1.8044162562918953
Validation loss: 2.5650206899211283

Epoch: 5| Step: 5
Training loss: 1.7984965429879953
Validation loss: 2.592909726609641

Epoch: 5| Step: 6
Training loss: 1.495520977606486
Validation loss: 2.550519827609532

Epoch: 5| Step: 7
Training loss: 2.236001656369601
Validation loss: 2.5310684146818434

Epoch: 5| Step: 8
Training loss: 1.6185775900677668
Validation loss: 2.5758618989428244

Epoch: 5| Step: 9
Training loss: 2.224071514695071
Validation loss: 2.582968045116646

Epoch: 5| Step: 10
Training loss: 1.887772859972727
Validation loss: 2.5882566257990014

Epoch: 5| Step: 11
Training loss: 1.510969819252851
Validation loss: 2.5882250722063436

Epoch: 387| Step: 0
Training loss: 1.817707342313334
Validation loss: 2.605535518738198

Epoch: 5| Step: 1
Training loss: 1.8607794322185076
Validation loss: 2.61568450662549

Epoch: 5| Step: 2
Training loss: 1.907935726050857
Validation loss: 2.6192028541767565

Epoch: 5| Step: 3
Training loss: 1.907731402998742
Validation loss: 2.6410805386402396

Epoch: 5| Step: 4
Training loss: 2.0862671095213354
Validation loss: 2.659274451315735

Epoch: 5| Step: 5
Training loss: 2.1364904417703063
Validation loss: 2.6306789386349516

Epoch: 5| Step: 6
Training loss: 1.5336090911082374
Validation loss: 2.607230624496447

Epoch: 5| Step: 7
Training loss: 2.548968338306924
Validation loss: 2.593506027911621

Epoch: 5| Step: 8
Training loss: 1.6883828714652813
Validation loss: 2.579047664111405

Epoch: 5| Step: 9
Training loss: 1.565864145741482
Validation loss: 2.5983956243184307

Epoch: 5| Step: 10
Training loss: 1.3977473170132406
Validation loss: 2.528215559636914

Epoch: 5| Step: 11
Training loss: 1.627658137126018
Validation loss: 2.5869361508805166

Epoch: 388| Step: 0
Training loss: 1.480363102266056
Validation loss: 2.553443345199479

Epoch: 5| Step: 1
Training loss: 1.9721410097346543
Validation loss: 2.558342713132763

Epoch: 5| Step: 2
Training loss: 1.6823064923494322
Validation loss: 2.562571605984481

Epoch: 5| Step: 3
Training loss: 2.591413157617461
Validation loss: 2.5677366983782695

Epoch: 5| Step: 4
Training loss: 2.1749771248502423
Validation loss: 2.57810287466092

Epoch: 5| Step: 5
Training loss: 1.7986996218563391
Validation loss: 2.5935739625994527

Epoch: 5| Step: 6
Training loss: 2.02489686868156
Validation loss: 2.6374677597353378

Epoch: 5| Step: 7
Training loss: 2.0002043142862083
Validation loss: 2.6015352738400135

Epoch: 5| Step: 8
Training loss: 1.4637982108551237
Validation loss: 2.627284274683864

Epoch: 5| Step: 9
Training loss: 1.836108715109032
Validation loss: 2.5875077910927944

Epoch: 5| Step: 10
Training loss: 1.2931835998709382
Validation loss: 2.601421092699019

Epoch: 5| Step: 11
Training loss: 0.9526347478536282
Validation loss: 2.559930439608726

Epoch: 389| Step: 0
Training loss: 1.8055474020292936
Validation loss: 2.5945121112758165

Epoch: 5| Step: 1
Training loss: 1.477705013942428
Validation loss: 2.5784710353245055

Epoch: 5| Step: 2
Training loss: 2.0326227098047043
Validation loss: 2.5774319690207865

Epoch: 5| Step: 3
Training loss: 1.6176151318382865
Validation loss: 2.5722119309583604

Epoch: 5| Step: 4
Training loss: 1.416378085345065
Validation loss: 2.569518620835102

Epoch: 5| Step: 5
Training loss: 1.5733144732869675
Validation loss: 2.540820275278673

Epoch: 5| Step: 6
Training loss: 2.4385832311408637
Validation loss: 2.540737390006884

Epoch: 5| Step: 7
Training loss: 1.6626460534668486
Validation loss: 2.5433814148047307

Epoch: 5| Step: 8
Training loss: 2.04476015750383
Validation loss: 2.561301028424562

Epoch: 5| Step: 9
Training loss: 1.7814752536696252
Validation loss: 2.548773407135613

Epoch: 5| Step: 10
Training loss: 2.537888569513222
Validation loss: 2.5740516658541215

Epoch: 5| Step: 11
Training loss: 0.9858854301232703
Validation loss: 2.5758869552481727

Epoch: 390| Step: 0
Training loss: 1.5717652845675554
Validation loss: 2.619385527924352

Epoch: 5| Step: 1
Training loss: 2.3393556216245255
Validation loss: 2.63422515129212

Epoch: 5| Step: 2
Training loss: 1.7070979404297824
Validation loss: 2.6090838865731003

Epoch: 5| Step: 3
Training loss: 2.067154343296603
Validation loss: 2.629663922209276

Epoch: 5| Step: 4
Training loss: 1.9488069332436375
Validation loss: 2.6203053364573345

Epoch: 5| Step: 5
Training loss: 1.8914996559370647
Validation loss: 2.6152897041437377

Epoch: 5| Step: 6
Training loss: 1.7144434294358026
Validation loss: 2.614927350293878

Epoch: 5| Step: 7
Training loss: 1.551824569466544
Validation loss: 2.5841956711791525

Epoch: 5| Step: 8
Training loss: 2.213151880988183
Validation loss: 2.5892432174890896

Epoch: 5| Step: 9
Training loss: 1.611254881147829
Validation loss: 2.6122872135136466

Epoch: 5| Step: 10
Training loss: 1.582314171629986
Validation loss: 2.6176402521192

Epoch: 5| Step: 11
Training loss: 1.9380445022866808
Validation loss: 2.5924645038088783

Epoch: 391| Step: 0
Training loss: 1.7535366696976962
Validation loss: 2.6300587425875612

Epoch: 5| Step: 1
Training loss: 1.9873367794360604
Validation loss: 2.6325941061266573

Epoch: 5| Step: 2
Training loss: 1.644040720943481
Validation loss: 2.654837932369628

Epoch: 5| Step: 3
Training loss: 2.1152764172659917
Validation loss: 2.661183409603565

Epoch: 5| Step: 4
Training loss: 2.748996031168893
Validation loss: 2.626111122770381

Epoch: 5| Step: 5
Training loss: 1.0878149584989265
Validation loss: 2.6332225725464697

Epoch: 5| Step: 6
Training loss: 1.6370021237899621
Validation loss: 2.6225258505498408

Epoch: 5| Step: 7
Training loss: 1.7790213579908196
Validation loss: 2.620817197336599

Epoch: 5| Step: 8
Training loss: 1.6562153074841668
Validation loss: 2.618275263567513

Epoch: 5| Step: 9
Training loss: 1.6414746218952554
Validation loss: 2.6432615055805684

Epoch: 5| Step: 10
Training loss: 2.0359079799429565
Validation loss: 2.59091051013934

Epoch: 5| Step: 11
Training loss: 0.8098569576504596
Validation loss: 2.5802119891977933

Epoch: 392| Step: 0
Training loss: 2.136897831025264
Validation loss: 2.5834158062588335

Epoch: 5| Step: 1
Training loss: 1.40895151682191
Validation loss: 2.5543731822732387

Epoch: 5| Step: 2
Training loss: 2.087193257529092
Validation loss: 2.5957968728172034

Epoch: 5| Step: 3
Training loss: 2.0366946682459246
Validation loss: 2.6052569027267394

Epoch: 5| Step: 4
Training loss: 1.8486423562715875
Validation loss: 2.624096718794035

Epoch: 5| Step: 5
Training loss: 1.6227631946451015
Validation loss: 2.637039779146302

Epoch: 5| Step: 6
Training loss: 1.8891518899042137
Validation loss: 2.6341722073225693

Epoch: 5| Step: 7
Training loss: 2.0968392199947177
Validation loss: 2.6446249272383344

Epoch: 5| Step: 8
Training loss: 1.4714625855957417
Validation loss: 2.617879789277758

Epoch: 5| Step: 9
Training loss: 1.2894048525173827
Validation loss: 2.6385704414454247

Epoch: 5| Step: 10
Training loss: 2.4349600445173625
Validation loss: 2.623196644695725

Epoch: 5| Step: 11
Training loss: 0.42018027228772603
Validation loss: 2.5546384606432726

Epoch: 393| Step: 0
Training loss: 1.7012869339408625
Validation loss: 2.5819133244919565

Epoch: 5| Step: 1
Training loss: 3.088142013209561
Validation loss: 2.5771740633495273

Epoch: 5| Step: 2
Training loss: 1.8253256729295897
Validation loss: 2.5975157506132938

Epoch: 5| Step: 3
Training loss: 1.8941434168308269
Validation loss: 2.590431779528261

Epoch: 5| Step: 4
Training loss: 2.3394717014637005
Validation loss: 2.657892702818588

Epoch: 5| Step: 5
Training loss: 1.7043942962438243
Validation loss: 2.6600412090893055

Epoch: 5| Step: 6
Training loss: 1.757723115131901
Validation loss: 2.6238290960618564

Epoch: 5| Step: 7
Training loss: 1.315086359589632
Validation loss: 2.595787060377739

Epoch: 5| Step: 8
Training loss: 1.364110568708233
Validation loss: 2.5848536376050713

Epoch: 5| Step: 9
Training loss: 1.8757571916733407
Validation loss: 2.523705687704624

Epoch: 5| Step: 10
Training loss: 1.5656601039582982
Validation loss: 2.519438051377802

Epoch: 5| Step: 11
Training loss: 1.240993958002793
Validation loss: 2.5255366079370525

Epoch: 394| Step: 0
Training loss: 1.7478462999234594
Validation loss: 2.491551699798166

Epoch: 5| Step: 1
Training loss: 1.684957425516328
Validation loss: 2.501721848164748

Epoch: 5| Step: 2
Training loss: 1.688335776871736
Validation loss: 2.4987134325037066

Epoch: 5| Step: 3
Training loss: 2.089228059860483
Validation loss: 2.5198598681888615

Epoch: 5| Step: 4
Training loss: 1.719953011935498
Validation loss: 2.526857583848249

Epoch: 5| Step: 5
Training loss: 2.2569008012774154
Validation loss: 2.5434938348665805

Epoch: 5| Step: 6
Training loss: 2.1105794223137604
Validation loss: 2.5483859286380897

Epoch: 5| Step: 7
Training loss: 1.7842952730502435
Validation loss: 2.5732977169253597

Epoch: 5| Step: 8
Training loss: 1.675238461387392
Validation loss: 2.630012362642084

Epoch: 5| Step: 9
Training loss: 2.0069433327407427
Validation loss: 2.6800020513360634

Epoch: 5| Step: 10
Training loss: 2.001432859226168
Validation loss: 2.725217157571286

Epoch: 5| Step: 11
Training loss: 1.2691173641741973
Validation loss: 2.6982053408348694

Epoch: 395| Step: 0
Training loss: 1.5941559517648716
Validation loss: 2.744739576613934

Epoch: 5| Step: 1
Training loss: 1.5791267765747503
Validation loss: 2.6946798715502256

Epoch: 5| Step: 2
Training loss: 1.9090495579852687
Validation loss: 2.6612429870756746

Epoch: 5| Step: 3
Training loss: 1.5637640608316232
Validation loss: 2.6083641111875697

Epoch: 5| Step: 4
Training loss: 2.3080874434885588
Validation loss: 2.56673890449276

Epoch: 5| Step: 5
Training loss: 2.193798805845925
Validation loss: 2.5376035401402888

Epoch: 5| Step: 6
Training loss: 2.0465311242035837
Validation loss: 2.5317775565092595

Epoch: 5| Step: 7
Training loss: 1.921889080213126
Validation loss: 2.5304959787126906

Epoch: 5| Step: 8
Training loss: 2.13788401405599
Validation loss: 2.5073455542201737

Epoch: 5| Step: 9
Training loss: 2.0273403395548746
Validation loss: 2.553440221146154

Epoch: 5| Step: 10
Training loss: 2.033969291395183
Validation loss: 2.578174571321735

Epoch: 5| Step: 11
Training loss: 1.4068843682280983
Validation loss: 2.6163956046682837

Epoch: 396| Step: 0
Training loss: 2.0877245845021952
Validation loss: 2.6704547148531694

Epoch: 5| Step: 1
Training loss: 1.8224486558586408
Validation loss: 2.7303019387622087

Epoch: 5| Step: 2
Training loss: 1.6483165099953991
Validation loss: 2.715143477180122

Epoch: 5| Step: 3
Training loss: 1.913437472687191
Validation loss: 2.6806892917281955

Epoch: 5| Step: 4
Training loss: 1.7575041097753015
Validation loss: 2.622970595094512

Epoch: 5| Step: 5
Training loss: 2.176825062400496
Validation loss: 2.6014916617493076

Epoch: 5| Step: 6
Training loss: 2.1795021990147783
Validation loss: 2.555694226174529

Epoch: 5| Step: 7
Training loss: 2.1157511100202693
Validation loss: 2.5515478422230955

Epoch: 5| Step: 8
Training loss: 1.6475476217840086
Validation loss: 2.52742554946429

Epoch: 5| Step: 9
Training loss: 2.1991130471447606
Validation loss: 2.53498861329746

Epoch: 5| Step: 10
Training loss: 1.684103408461017
Validation loss: 2.5417965063690158

Epoch: 5| Step: 11
Training loss: 0.903657559512054
Validation loss: 2.5139099142753762

Epoch: 397| Step: 0
Training loss: 1.820612281050355
Validation loss: 2.5651113532622434

Epoch: 5| Step: 1
Training loss: 2.018572522561206
Validation loss: 2.565412196271689

Epoch: 5| Step: 2
Training loss: 1.6041294275230291
Validation loss: 2.56651022210319

Epoch: 5| Step: 3
Training loss: 1.9641947043997425
Validation loss: 2.5828450277241433

Epoch: 5| Step: 4
Training loss: 1.4659777511636178
Validation loss: 2.5748869974531643

Epoch: 5| Step: 5
Training loss: 1.3108653379455075
Validation loss: 2.6087817052484357

Epoch: 5| Step: 6
Training loss: 2.128651566976453
Validation loss: 2.5651576015632047

Epoch: 5| Step: 7
Training loss: 1.756767810223675
Validation loss: 2.5715750904511334

Epoch: 5| Step: 8
Training loss: 1.900470038045597
Validation loss: 2.609507079598293

Epoch: 5| Step: 9
Training loss: 2.5489457961941904
Validation loss: 2.5787704083770318

Epoch: 5| Step: 10
Training loss: 1.467370948251027
Validation loss: 2.5464748973214606

Epoch: 5| Step: 11
Training loss: 1.63834884424069
Validation loss: 2.592040356427599

Epoch: 398| Step: 0
Training loss: 1.856426690423105
Validation loss: 2.54641923551441

Epoch: 5| Step: 1
Training loss: 1.5371570700936967
Validation loss: 2.550880469144568

Epoch: 5| Step: 2
Training loss: 1.7151169266058601
Validation loss: 2.5726937449688787

Epoch: 5| Step: 3
Training loss: 1.2032356706721492
Validation loss: 2.5700892551486203

Epoch: 5| Step: 4
Training loss: 1.921909549061443
Validation loss: 2.6024790687159043

Epoch: 5| Step: 5
Training loss: 2.830079472912032
Validation loss: 2.590643485493773

Epoch: 5| Step: 6
Training loss: 1.2381654318187467
Validation loss: 2.613076225262903

Epoch: 5| Step: 7
Training loss: 2.3018490656298822
Validation loss: 2.593462204190945

Epoch: 5| Step: 8
Training loss: 1.5068436113756718
Validation loss: 2.6324660868511636

Epoch: 5| Step: 9
Training loss: 1.8037335405239827
Validation loss: 2.6539785209654756

Epoch: 5| Step: 10
Training loss: 1.570097116151526
Validation loss: 2.676614792092697

Epoch: 5| Step: 11
Training loss: 1.0345135114883544
Validation loss: 2.650003122381854

Epoch: 399| Step: 0
Training loss: 1.6585986920290758
Validation loss: 2.6517180883271787

Epoch: 5| Step: 1
Training loss: 1.69724918967697
Validation loss: 2.6039920684776185

Epoch: 5| Step: 2
Training loss: 1.4216886964248665
Validation loss: 2.607684983445599

Epoch: 5| Step: 3
Training loss: 1.6419168381720495
Validation loss: 2.582166159409794

Epoch: 5| Step: 4
Training loss: 2.0728095201056522
Validation loss: 2.5718774949251344

Epoch: 5| Step: 5
Training loss: 1.5576534637723194
Validation loss: 2.5634615807473917

Epoch: 5| Step: 6
Training loss: 1.6440705947662195
Validation loss: 2.5925008262907627

Epoch: 5| Step: 7
Training loss: 2.0299958098419992
Validation loss: 2.563993817172181

Epoch: 5| Step: 8
Training loss: 2.200746158297062
Validation loss: 2.5827603832786097

Epoch: 5| Step: 9
Training loss: 2.370489052802562
Validation loss: 2.5802655167622066

Epoch: 5| Step: 10
Training loss: 1.9528321924069794
Validation loss: 2.60581873307033

Epoch: 5| Step: 11
Training loss: 1.3782778596766079
Validation loss: 2.5961848477652687

Epoch: 400| Step: 0
Training loss: 2.027847374486711
Validation loss: 2.632052122165242

Epoch: 5| Step: 1
Training loss: 1.7603926647589063
Validation loss: 2.6542111669030746

Epoch: 5| Step: 2
Training loss: 1.8261594720919052
Validation loss: 2.6438122085935816

Epoch: 5| Step: 3
Training loss: 1.6537786795853384
Validation loss: 2.5896336972307448

Epoch: 5| Step: 4
Training loss: 1.508393487029378
Validation loss: 2.6051754879371285

Epoch: 5| Step: 5
Training loss: 1.6736069024518052
Validation loss: 2.5809048991544783

Epoch: 5| Step: 6
Training loss: 2.268440759354039
Validation loss: 2.559427054795362

Epoch: 5| Step: 7
Training loss: 1.8816447455337513
Validation loss: 2.570866688326988

Epoch: 5| Step: 8
Training loss: 2.1467971365633596
Validation loss: 2.580575652934494

Epoch: 5| Step: 9
Training loss: 1.9383738608263157
Validation loss: 2.578056789227963

Epoch: 5| Step: 10
Training loss: 1.3904705604775487
Validation loss: 2.5607146541079375

Epoch: 5| Step: 11
Training loss: 1.7544660121031477
Validation loss: 2.6053527089385673

Epoch: 401| Step: 0
Training loss: 1.708769099164376
Validation loss: 2.5891880453884824

Epoch: 5| Step: 1
Training loss: 1.9359832487327413
Validation loss: 2.601828182580271

Epoch: 5| Step: 2
Training loss: 1.4650708645551365
Validation loss: 2.58451561766265

Epoch: 5| Step: 3
Training loss: 1.793325816650426
Validation loss: 2.6382630335245083

Epoch: 5| Step: 4
Training loss: 2.1869317542836786
Validation loss: 2.6035971947130783

Epoch: 5| Step: 5
Training loss: 1.6639558283325817
Validation loss: 2.6114577282870766

Epoch: 5| Step: 6
Training loss: 1.63726309598682
Validation loss: 2.5678595652481357

Epoch: 5| Step: 7
Training loss: 1.5288264499865467
Validation loss: 2.6297310361471253

Epoch: 5| Step: 8
Training loss: 1.8178895206014443
Validation loss: 2.5875201649885966

Epoch: 5| Step: 9
Training loss: 2.3490256379515966
Validation loss: 2.6164460531605123

Epoch: 5| Step: 10
Training loss: 1.8516260450058006
Validation loss: 2.594241107269247

Epoch: 5| Step: 11
Training loss: 1.1923331235487826
Validation loss: 2.581575812312501

Epoch: 402| Step: 0
Training loss: 1.6433124148344476
Validation loss: 2.573356924086819

Epoch: 5| Step: 1
Training loss: 1.2760523529643282
Validation loss: 2.5915339321437276

Epoch: 5| Step: 2
Training loss: 2.7844328081186025
Validation loss: 2.569679054655541

Epoch: 5| Step: 3
Training loss: 1.4979755727816093
Validation loss: 2.558555261065219

Epoch: 5| Step: 4
Training loss: 1.3129328513512364
Validation loss: 2.572492979019712

Epoch: 5| Step: 5
Training loss: 1.979145397942018
Validation loss: 2.5622595387348026

Epoch: 5| Step: 6
Training loss: 1.8541274834539538
Validation loss: 2.583584305405981

Epoch: 5| Step: 7
Training loss: 1.5260537399838596
Validation loss: 2.588910175754649

Epoch: 5| Step: 8
Training loss: 1.5910089894921322
Validation loss: 2.57261095791962

Epoch: 5| Step: 9
Training loss: 1.8848423443137334
Validation loss: 2.5853275528601003

Epoch: 5| Step: 10
Training loss: 1.8656142242478266
Validation loss: 2.6120470608032313

Epoch: 5| Step: 11
Training loss: 3.157672674753707
Validation loss: 2.6105561771443044

Epoch: 403| Step: 0
Training loss: 1.7118281306423968
Validation loss: 2.562476134770609

Epoch: 5| Step: 1
Training loss: 1.2150597089059718
Validation loss: 2.5807346160451337

Epoch: 5| Step: 2
Training loss: 1.269340195584848
Validation loss: 2.5437095371749145

Epoch: 5| Step: 3
Training loss: 2.2223745479298986
Validation loss: 2.5264157375472354

Epoch: 5| Step: 4
Training loss: 2.5136960613091945
Validation loss: 2.532010619556059

Epoch: 5| Step: 5
Training loss: 1.7922113019564951
Validation loss: 2.50625529918919

Epoch: 5| Step: 6
Training loss: 2.1691844933688724
Validation loss: 2.5295009614161317

Epoch: 5| Step: 7
Training loss: 1.8965762083721307
Validation loss: 2.5592351522032053

Epoch: 5| Step: 8
Training loss: 1.2624805618904815
Validation loss: 2.566325451078803

Epoch: 5| Step: 9
Training loss: 1.7871133773008463
Validation loss: 2.5560662051955965

Epoch: 5| Step: 10
Training loss: 1.957046965575934
Validation loss: 2.634638661425978

Epoch: 5| Step: 11
Training loss: 0.955759628323235
Validation loss: 2.6713371590672685

Epoch: 404| Step: 0
Training loss: 2.0861999118065087
Validation loss: 2.6990762719892487

Epoch: 5| Step: 1
Training loss: 2.3215058722568624
Validation loss: 2.714373215257475

Epoch: 5| Step: 2
Training loss: 2.145349676444941
Validation loss: 2.690115487640184

Epoch: 5| Step: 3
Training loss: 1.9148752783456322
Validation loss: 2.6559088282173287

Epoch: 5| Step: 4
Training loss: 1.2971255049001007
Validation loss: 2.6073128209543084

Epoch: 5| Step: 5
Training loss: 1.9715784735583521
Validation loss: 2.6145486082124205

Epoch: 5| Step: 6
Training loss: 2.2217000771729194
Validation loss: 2.610513035415391

Epoch: 5| Step: 7
Training loss: 1.6669951909847722
Validation loss: 2.575872099669122

Epoch: 5| Step: 8
Training loss: 1.8089487209443234
Validation loss: 2.5768081249540504

Epoch: 5| Step: 9
Training loss: 1.3879262905117393
Validation loss: 2.566652550338552

Epoch: 5| Step: 10
Training loss: 1.3338286056164663
Validation loss: 2.591741153565551

Epoch: 5| Step: 11
Training loss: 0.6604314828488288
Validation loss: 2.579925986960749

Epoch: 405| Step: 0
Training loss: 1.633365592183851
Validation loss: 2.6040500474884847

Epoch: 5| Step: 1
Training loss: 1.1762891920575655
Validation loss: 2.6112902706791146

Epoch: 5| Step: 2
Training loss: 2.2440354444591044
Validation loss: 2.5947267271287564

Epoch: 5| Step: 3
Training loss: 1.930772854523644
Validation loss: 2.5872380577099543

Epoch: 5| Step: 4
Training loss: 2.1740622724231655
Validation loss: 2.616912823587376

Epoch: 5| Step: 5
Training loss: 1.4861149277841077
Validation loss: 2.5830089547455826

Epoch: 5| Step: 6
Training loss: 2.082780599385591
Validation loss: 2.6160710358956507

Epoch: 5| Step: 7
Training loss: 1.35802616418064
Validation loss: 2.622077181313988

Epoch: 5| Step: 8
Training loss: 1.7811941171546828
Validation loss: 2.63741833483562

Epoch: 5| Step: 9
Training loss: 2.0607859106760977
Validation loss: 2.6644879334237923

Epoch: 5| Step: 10
Training loss: 1.341801983464052
Validation loss: 2.643111478443668

Epoch: 5| Step: 11
Training loss: 1.027012876888622
Validation loss: 2.65879188163255

Epoch: 406| Step: 0
Training loss: 1.6515729111674422
Validation loss: 2.6508597378363596

Epoch: 5| Step: 1
Training loss: 1.627139956587624
Validation loss: 2.6046135836805373

Epoch: 5| Step: 2
Training loss: 1.7527897260889729
Validation loss: 2.59876639753792

Epoch: 5| Step: 3
Training loss: 1.983200266191527
Validation loss: 2.568743020765193

Epoch: 5| Step: 4
Training loss: 1.82622951477802
Validation loss: 2.5595556804768047

Epoch: 5| Step: 5
Training loss: 1.8004117574215062
Validation loss: 2.5720718202642767

Epoch: 5| Step: 6
Training loss: 1.9818971437427964
Validation loss: 2.6023886765383404

Epoch: 5| Step: 7
Training loss: 1.6071051729416317
Validation loss: 2.5991068946000953

Epoch: 5| Step: 8
Training loss: 1.6682946916285037
Validation loss: 2.5396026623631576

Epoch: 5| Step: 9
Training loss: 1.507334420899026
Validation loss: 2.5440176594136763

Epoch: 5| Step: 10
Training loss: 2.059297560768385
Validation loss: 2.5555111396311405

Epoch: 5| Step: 11
Training loss: 2.0728012385091907
Validation loss: 2.5540171141243975

Epoch: 407| Step: 0
Training loss: 2.251699865149626
Validation loss: 2.5467573033384725

Epoch: 5| Step: 1
Training loss: 1.6699496439805561
Validation loss: 2.599693616060538

Epoch: 5| Step: 2
Training loss: 1.7020066815613826
Validation loss: 2.6137533706991145

Epoch: 5| Step: 3
Training loss: 1.9544969546649793
Validation loss: 2.625603850483134

Epoch: 5| Step: 4
Training loss: 1.463283430058148
Validation loss: 2.59717335048691

Epoch: 5| Step: 5
Training loss: 1.3687878642658438
Validation loss: 2.6185578246150127

Epoch: 5| Step: 6
Training loss: 1.5136034353227321
Validation loss: 2.5908626126851364

Epoch: 5| Step: 7
Training loss: 1.6735810461373277
Validation loss: 2.5818594655628693

Epoch: 5| Step: 8
Training loss: 1.5701283209290091
Validation loss: 2.5373119481878232

Epoch: 5| Step: 9
Training loss: 2.220567415598274
Validation loss: 2.5679852695473393

Epoch: 5| Step: 10
Training loss: 2.082537104721427
Validation loss: 2.6026966459984466

Epoch: 5| Step: 11
Training loss: 2.01314137349995
Validation loss: 2.5933437259027814

Epoch: 408| Step: 0
Training loss: 1.6819532859157555
Validation loss: 2.59954558766419

Epoch: 5| Step: 1
Training loss: 1.6369057050099485
Validation loss: 2.6307735679281543

Epoch: 5| Step: 2
Training loss: 1.8455203980109478
Validation loss: 2.685962431227731

Epoch: 5| Step: 3
Training loss: 2.0659055626067757
Validation loss: 2.6508907220183286

Epoch: 5| Step: 4
Training loss: 1.51834232525862
Validation loss: 2.670659080440874

Epoch: 5| Step: 5
Training loss: 1.6034872259303856
Validation loss: 2.715921059241465

Epoch: 5| Step: 6
Training loss: 1.6817928869983667
Validation loss: 2.67082986970301

Epoch: 5| Step: 7
Training loss: 1.2221960597176225
Validation loss: 2.6295393719416347

Epoch: 5| Step: 8
Training loss: 1.354543716561632
Validation loss: 2.6230210799830433

Epoch: 5| Step: 9
Training loss: 1.9745645791546544
Validation loss: 2.5872903686720043

Epoch: 5| Step: 10
Training loss: 2.4956275850889753
Validation loss: 2.5718902105389176

Epoch: 5| Step: 11
Training loss: 2.5201382164667945
Validation loss: 2.5509239924061267

Epoch: 409| Step: 0
Training loss: 1.8116414897939175
Validation loss: 2.6074849858069653

Epoch: 5| Step: 1
Training loss: 1.213613543476106
Validation loss: 2.5661906437761326

Epoch: 5| Step: 2
Training loss: 1.467888518572563
Validation loss: 2.6045492132862225

Epoch: 5| Step: 3
Training loss: 1.668475393496228
Validation loss: 2.6178361876403704

Epoch: 5| Step: 4
Training loss: 1.815982104587187
Validation loss: 2.6605875951114895

Epoch: 5| Step: 5
Training loss: 1.3640365475767136
Validation loss: 2.6354275591377654

Epoch: 5| Step: 6
Training loss: 1.8132968334890878
Validation loss: 2.66885061290279

Epoch: 5| Step: 7
Training loss: 1.4278371541697306
Validation loss: 2.65986020704415

Epoch: 5| Step: 8
Training loss: 1.554249227272346
Validation loss: 2.6285674739853806

Epoch: 5| Step: 9
Training loss: 2.277751591643044
Validation loss: 2.629567989293919

Epoch: 5| Step: 10
Training loss: 2.5440034182423594
Validation loss: 2.582317357604234

Epoch: 5| Step: 11
Training loss: 3.3730338692207282
Validation loss: 2.616108234359876

Epoch: 410| Step: 0
Training loss: 1.7959070667020118
Validation loss: 2.605363488156139

Epoch: 5| Step: 1
Training loss: 2.0733797204735547
Validation loss: 2.582640463962561

Epoch: 5| Step: 2
Training loss: 1.488915496006421
Validation loss: 2.5317584418018617

Epoch: 5| Step: 3
Training loss: 1.5784611107981095
Validation loss: 2.591247239676473

Epoch: 5| Step: 4
Training loss: 1.5860083052139935
Validation loss: 2.5607763614817753

Epoch: 5| Step: 5
Training loss: 1.7900847467148426
Validation loss: 2.5397471282519186

Epoch: 5| Step: 6
Training loss: 1.7478329319802348
Validation loss: 2.5620208191411633

Epoch: 5| Step: 7
Training loss: 2.0881840755688836
Validation loss: 2.5469748393579468

Epoch: 5| Step: 8
Training loss: 2.222790115696374
Validation loss: 2.543299128590714

Epoch: 5| Step: 9
Training loss: 2.176990440126876
Validation loss: 2.5300204033839333

Epoch: 5| Step: 10
Training loss: 1.365855499996961
Validation loss: 2.5346662089866485

Epoch: 5| Step: 11
Training loss: 0.5084258263765387
Validation loss: 2.530213650137313

Epoch: 411| Step: 0
Training loss: 1.4781049311688856
Validation loss: 2.507703037982634

Epoch: 5| Step: 1
Training loss: 1.5291071319771001
Validation loss: 2.5352702573152452

Epoch: 5| Step: 2
Training loss: 1.992232976656186
Validation loss: 2.5287019950583063

Epoch: 5| Step: 3
Training loss: 2.044404963731795
Validation loss: 2.5755720117393595

Epoch: 5| Step: 4
Training loss: 2.2539982768663998
Validation loss: 2.5388877378132344

Epoch: 5| Step: 5
Training loss: 1.3479556870548863
Validation loss: 2.519186109614406

Epoch: 5| Step: 6
Training loss: 1.7875559764713815
Validation loss: 2.5429169024032374

Epoch: 5| Step: 7
Training loss: 1.915048897818637
Validation loss: 2.548724211112865

Epoch: 5| Step: 8
Training loss: 1.8900552947417693
Validation loss: 2.5594562930594247

Epoch: 5| Step: 9
Training loss: 2.025105617264907
Validation loss: 2.578348019134167

Epoch: 5| Step: 10
Training loss: 1.694234901076121
Validation loss: 2.6016122146912033

Epoch: 5| Step: 11
Training loss: 1.322101577206519
Validation loss: 2.647893003832726

Epoch: 412| Step: 0
Training loss: 2.283310886838897
Validation loss: 2.6281622844323818

Epoch: 5| Step: 1
Training loss: 1.7391238795550823
Validation loss: 2.6120840237311773

Epoch: 5| Step: 2
Training loss: 1.8275818629265947
Validation loss: 2.632508725414204

Epoch: 5| Step: 3
Training loss: 2.13425684499922
Validation loss: 2.589236948340199

Epoch: 5| Step: 4
Training loss: 1.47381691765385
Validation loss: 2.635171073406684

Epoch: 5| Step: 5
Training loss: 1.5259333584034167
Validation loss: 2.645704872036525

Epoch: 5| Step: 6
Training loss: 1.986772365649146
Validation loss: 2.6338222050376094

Epoch: 5| Step: 7
Training loss: 1.8762111566780961
Validation loss: 2.662831039549213

Epoch: 5| Step: 8
Training loss: 1.1429267547047244
Validation loss: 2.6657426780553144

Epoch: 5| Step: 9
Training loss: 1.0845416861613049
Validation loss: 2.6329529099420608

Epoch: 5| Step: 10
Training loss: 1.7540126844706498
Validation loss: 2.6576842531079836

Epoch: 5| Step: 11
Training loss: 1.9156987883901153
Validation loss: 2.6601906623425693

Epoch: 413| Step: 0
Training loss: 1.7791575137520101
Validation loss: 2.661641151335385

Epoch: 5| Step: 1
Training loss: 1.8226259780901048
Validation loss: 2.6164792559159995

Epoch: 5| Step: 2
Training loss: 2.1277458178004336
Validation loss: 2.622393869792629

Epoch: 5| Step: 3
Training loss: 1.2089504551481545
Validation loss: 2.6135055415329083

Epoch: 5| Step: 4
Training loss: 1.8875607967058932
Validation loss: 2.620116364749908

Epoch: 5| Step: 5
Training loss: 2.2813735301394633
Validation loss: 2.658983850756943

Epoch: 5| Step: 6
Training loss: 1.643015618410829
Validation loss: 2.622581465261603

Epoch: 5| Step: 7
Training loss: 1.2113048857545101
Validation loss: 2.662648356099733

Epoch: 5| Step: 8
Training loss: 1.8839636484960027
Validation loss: 2.647482546994056

Epoch: 5| Step: 9
Training loss: 2.1758407502454005
Validation loss: 2.6408569113715163

Epoch: 5| Step: 10
Training loss: 1.2277761395809317
Validation loss: 2.6716508083463815

Epoch: 5| Step: 11
Training loss: 0.9222560353731805
Validation loss: 2.6729181941308773

Epoch: 414| Step: 0
Training loss: 1.178090460799683
Validation loss: 2.689707688358183

Epoch: 5| Step: 1
Training loss: 1.6073200476318987
Validation loss: 2.6896225620327336

Epoch: 5| Step: 2
Training loss: 1.937464375322215
Validation loss: 2.6585391110464567

Epoch: 5| Step: 3
Training loss: 1.7080729991759473
Validation loss: 2.6682501905572207

Epoch: 5| Step: 4
Training loss: 1.6582955019036598
Validation loss: 2.637450791452819

Epoch: 5| Step: 5
Training loss: 1.3836856822268948
Validation loss: 2.612150159406845

Epoch: 5| Step: 6
Training loss: 2.249142165369167
Validation loss: 2.602025144601895

Epoch: 5| Step: 7
Training loss: 1.7315606317129695
Validation loss: 2.6168702497880303

Epoch: 5| Step: 8
Training loss: 1.891751733903379
Validation loss: 2.6332603379335198

Epoch: 5| Step: 9
Training loss: 1.2716618427236779
Validation loss: 2.6095151844553786

Epoch: 5| Step: 10
Training loss: 2.302019754167605
Validation loss: 2.6009298171953876

Epoch: 5| Step: 11
Training loss: 1.4963991336547742
Validation loss: 2.6294249031959804

Epoch: 415| Step: 0
Training loss: 2.2145457664406387
Validation loss: 2.65550137984529

Epoch: 5| Step: 1
Training loss: 2.005108626888164
Validation loss: 2.642248726648043

Epoch: 5| Step: 2
Training loss: 1.6009706473581558
Validation loss: 2.6358691243015016

Epoch: 5| Step: 3
Training loss: 2.149736601197646
Validation loss: 2.642809267313108

Epoch: 5| Step: 4
Training loss: 1.4546106598879789
Validation loss: 2.5914260073807487

Epoch: 5| Step: 5
Training loss: 1.715630631012005
Validation loss: 2.6408545715940175

Epoch: 5| Step: 6
Training loss: 1.1765935886120837
Validation loss: 2.6120162928266843

Epoch: 5| Step: 7
Training loss: 1.48560362714223
Validation loss: 2.5802171444938153

Epoch: 5| Step: 8
Training loss: 2.0381884108162915
Validation loss: 2.5988612007128387

Epoch: 5| Step: 9
Training loss: 1.653786176197894
Validation loss: 2.600755220701016

Epoch: 5| Step: 10
Training loss: 1.2283686078379739
Validation loss: 2.616633813088895

Epoch: 5| Step: 11
Training loss: 1.3858296727636594
Validation loss: 2.6055935415630676

Epoch: 416| Step: 0
Training loss: 1.638019927670987
Validation loss: 2.5713850062138848

Epoch: 5| Step: 1
Training loss: 1.401202829538549
Validation loss: 2.5762721676761955

Epoch: 5| Step: 2
Training loss: 2.080346433143016
Validation loss: 2.608834444807805

Epoch: 5| Step: 3
Training loss: 1.8539907893514795
Validation loss: 2.600184135610702

Epoch: 5| Step: 4
Training loss: 2.2735537994106707
Validation loss: 2.599750044007253

Epoch: 5| Step: 5
Training loss: 1.4321507979968886
Validation loss: 2.635101293206975

Epoch: 5| Step: 6
Training loss: 1.2901367797343346
Validation loss: 2.63534088679189

Epoch: 5| Step: 7
Training loss: 1.6987748892717263
Validation loss: 2.651354306015842

Epoch: 5| Step: 8
Training loss: 1.9503572307946595
Validation loss: 2.6400617115317018

Epoch: 5| Step: 9
Training loss: 1.3304601448394557
Validation loss: 2.66166034287681

Epoch: 5| Step: 10
Training loss: 1.9641763755786046
Validation loss: 2.681937315907403

Epoch: 5| Step: 11
Training loss: 1.6132431949440622
Validation loss: 2.6466287627486706

Epoch: 417| Step: 0
Training loss: 2.006548294280876
Validation loss: 2.667275077485975

Epoch: 5| Step: 1
Training loss: 1.705981597470202
Validation loss: 2.620430443144659

Epoch: 5| Step: 2
Training loss: 1.5217053861312269
Validation loss: 2.6138662454219124

Epoch: 5| Step: 3
Training loss: 1.4665330428606107
Validation loss: 2.596113556656122

Epoch: 5| Step: 4
Training loss: 1.4643106940262118
Validation loss: 2.590777003173955

Epoch: 5| Step: 5
Training loss: 1.8767186870897306
Validation loss: 2.6177664956126945

Epoch: 5| Step: 6
Training loss: 1.2705395729030091
Validation loss: 2.6458059532270704

Epoch: 5| Step: 7
Training loss: 1.198929593393309
Validation loss: 2.649015639226908

Epoch: 5| Step: 8
Training loss: 1.4778135136814396
Validation loss: 2.6151354701945433

Epoch: 5| Step: 9
Training loss: 1.9800046117324297
Validation loss: 2.6462232209840146

Epoch: 5| Step: 10
Training loss: 2.194686202991683
Validation loss: 2.6247390057227276

Epoch: 5| Step: 11
Training loss: 2.799348132001778
Validation loss: 2.6281637472410297

Epoch: 418| Step: 0
Training loss: 1.4284918115773042
Validation loss: 2.634179655519937

Epoch: 5| Step: 1
Training loss: 1.8834604121970162
Validation loss: 2.6014761351950337

Epoch: 5| Step: 2
Training loss: 2.089275304188487
Validation loss: 2.59848543858077

Epoch: 5| Step: 3
Training loss: 2.04071772833499
Validation loss: 2.579164010500015

Epoch: 5| Step: 4
Training loss: 1.8646618348828368
Validation loss: 2.5645121761049574

Epoch: 5| Step: 5
Training loss: 1.9307839680061618
Validation loss: 2.556619432797183

Epoch: 5| Step: 6
Training loss: 1.7472516685933082
Validation loss: 2.52236983602043

Epoch: 5| Step: 7
Training loss: 2.0166012078162523
Validation loss: 2.531025582243408

Epoch: 5| Step: 8
Training loss: 1.8119502055839916
Validation loss: 2.5283101203077485

Epoch: 5| Step: 9
Training loss: 1.3935910429352438
Validation loss: 2.5478000794065103

Epoch: 5| Step: 10
Training loss: 2.0426333208591028
Validation loss: 2.5550699482417443

Epoch: 5| Step: 11
Training loss: 0.8879230404402337
Validation loss: 2.530341181454904

Epoch: 419| Step: 0
Training loss: 1.1813331897647963
Validation loss: 2.5564046216056866

Epoch: 5| Step: 1
Training loss: 1.68611801920437
Validation loss: 2.5480722215089573

Epoch: 5| Step: 2
Training loss: 1.962762538090017
Validation loss: 2.5522932134987975

Epoch: 5| Step: 3
Training loss: 2.3636215091118506
Validation loss: 2.5457490936479226

Epoch: 5| Step: 4
Training loss: 1.3970223197655856
Validation loss: 2.5599685353342228

Epoch: 5| Step: 5
Training loss: 1.735587787167426
Validation loss: 2.5813509361784934

Epoch: 5| Step: 6
Training loss: 1.7425170039437787
Validation loss: 2.563561673159282

Epoch: 5| Step: 7
Training loss: 1.6866840933224911
Validation loss: 2.5882401217175066

Epoch: 5| Step: 8
Training loss: 2.217695388529207
Validation loss: 2.5687117147570433

Epoch: 5| Step: 9
Training loss: 1.6471642372313886
Validation loss: 2.532992269641994

Epoch: 5| Step: 10
Training loss: 2.2364853716209203
Validation loss: 2.5590386661474454

Epoch: 5| Step: 11
Training loss: 2.3891506261146276
Validation loss: 2.5422974778207696

Epoch: 420| Step: 0
Training loss: 1.416147791515183
Validation loss: 2.5307542978784285

Epoch: 5| Step: 1
Training loss: 2.122600547107384
Validation loss: 2.5831075744016534

Epoch: 5| Step: 2
Training loss: 1.747700065435295
Validation loss: 2.6160217193947206

Epoch: 5| Step: 3
Training loss: 2.4077181610103136
Validation loss: 2.6079702117448367

Epoch: 5| Step: 4
Training loss: 1.7048777389319771
Validation loss: 2.625172851563287

Epoch: 5| Step: 5
Training loss: 1.6833588686350225
Validation loss: 2.6302792013963514

Epoch: 5| Step: 6
Training loss: 1.6478899728933516
Validation loss: 2.6286029536800726

Epoch: 5| Step: 7
Training loss: 1.5135286915645865
Validation loss: 2.5613635458413744

Epoch: 5| Step: 8
Training loss: 1.7466432530287432
Validation loss: 2.5614065884615695

Epoch: 5| Step: 9
Training loss: 2.363779768895022
Validation loss: 2.5120490960887194

Epoch: 5| Step: 10
Training loss: 1.800202183494604
Validation loss: 2.4981353322568536

Epoch: 5| Step: 11
Training loss: 1.4671509337007256
Validation loss: 2.5144066199908557

Epoch: 421| Step: 0
Training loss: 1.300702204321607
Validation loss: 2.5276827164796103

Epoch: 5| Step: 1
Training loss: 1.6825955788613567
Validation loss: 2.5423370412693047

Epoch: 5| Step: 2
Training loss: 2.0142530163253163
Validation loss: 2.5817485314050397

Epoch: 5| Step: 3
Training loss: 1.7943367985160392
Validation loss: 2.6036047990565225

Epoch: 5| Step: 4
Training loss: 1.7958077619934403
Validation loss: 2.5970705619743613

Epoch: 5| Step: 5
Training loss: 2.3209731063895367
Validation loss: 2.587295820869371

Epoch: 5| Step: 6
Training loss: 1.3676386497547883
Validation loss: 2.6321797766163253

Epoch: 5| Step: 7
Training loss: 2.0827150063043556
Validation loss: 2.600399150531659

Epoch: 5| Step: 8
Training loss: 1.5303918419013807
Validation loss: 2.5742046759089945

Epoch: 5| Step: 9
Training loss: 1.465092589541342
Validation loss: 2.568654040317787

Epoch: 5| Step: 10
Training loss: 1.6186259041722615
Validation loss: 2.544548696275228

Epoch: 5| Step: 11
Training loss: 1.8291679081083472
Validation loss: 2.5603754571547594

Epoch: 422| Step: 0
Training loss: 2.069587897407113
Validation loss: 2.507143864371393

Epoch: 5| Step: 1
Training loss: 1.7375363929285335
Validation loss: 2.480568180444274

Epoch: 5| Step: 2
Training loss: 1.4540584396413831
Validation loss: 2.4768947374454426

Epoch: 5| Step: 3
Training loss: 1.80905896788605
Validation loss: 2.5060532124000447

Epoch: 5| Step: 4
Training loss: 1.800349914130227
Validation loss: 2.4925503003316463

Epoch: 5| Step: 5
Training loss: 1.7956889343032931
Validation loss: 2.50333192440718

Epoch: 5| Step: 6
Training loss: 1.999094102259959
Validation loss: 2.509585608373079

Epoch: 5| Step: 7
Training loss: 1.752103767170026
Validation loss: 2.509364561896113

Epoch: 5| Step: 8
Training loss: 1.7100411074421122
Validation loss: 2.5378914034791706

Epoch: 5| Step: 9
Training loss: 1.9835781389773772
Validation loss: 2.6018830102899093

Epoch: 5| Step: 10
Training loss: 1.5856387603968631
Validation loss: 2.6222769487108923

Epoch: 5| Step: 11
Training loss: 2.198179497454051
Validation loss: 2.595069480693488

Epoch: 423| Step: 0
Training loss: 1.618552548653483
Validation loss: 2.5375476680782008

Epoch: 5| Step: 1
Training loss: 2.31443942424083
Validation loss: 2.527374554327955

Epoch: 5| Step: 2
Training loss: 1.5031241625111362
Validation loss: 2.559823972690086

Epoch: 5| Step: 3
Training loss: 1.6868785844265146
Validation loss: 2.5717438670950803

Epoch: 5| Step: 4
Training loss: 2.252342911639737
Validation loss: 2.561906034358098

Epoch: 5| Step: 5
Training loss: 1.538023157200886
Validation loss: 2.6032585518883127

Epoch: 5| Step: 6
Training loss: 1.4942155407842495
Validation loss: 2.588727009289111

Epoch: 5| Step: 7
Training loss: 1.8164200977084715
Validation loss: 2.5982404735477043

Epoch: 5| Step: 8
Training loss: 2.7716754312504754
Validation loss: 2.6195339179734107

Epoch: 5| Step: 9
Training loss: 1.5950125387051692
Validation loss: 2.63744423763634

Epoch: 5| Step: 10
Training loss: 1.6529271604132578
Validation loss: 2.650395310204979

Epoch: 5| Step: 11
Training loss: 2.063876646281379
Validation loss: 2.687397696152122

Epoch: 424| Step: 0
Training loss: 1.3854299224372324
Validation loss: 2.787674965663156

Epoch: 5| Step: 1
Training loss: 1.7375781062292401
Validation loss: 2.8512248322690183

Epoch: 5| Step: 2
Training loss: 2.5693256373617657
Validation loss: 2.852528123792174

Epoch: 5| Step: 3
Training loss: 2.0824313181969107
Validation loss: 2.763611080008724

Epoch: 5| Step: 4
Training loss: 2.2570348542192256
Validation loss: 2.696816777425578

Epoch: 5| Step: 5
Training loss: 2.3404588097931
Validation loss: 2.633724469750782

Epoch: 5| Step: 6
Training loss: 1.3282139467860175
Validation loss: 2.53991927730142

Epoch: 5| Step: 7
Training loss: 1.3276562480605516
Validation loss: 2.4771877746979696

Epoch: 5| Step: 8
Training loss: 1.7396532452025322
Validation loss: 2.485915344286608

Epoch: 5| Step: 9
Training loss: 2.2310825445344067
Validation loss: 2.448686782279876

Epoch: 5| Step: 10
Training loss: 2.491523295416682
Validation loss: 2.4423967920569556

Epoch: 5| Step: 11
Training loss: 1.3122175457706255
Validation loss: 2.420199633060551

Epoch: 425| Step: 0
Training loss: 2.3654277038943876
Validation loss: 2.41357551732621

Epoch: 5| Step: 1
Training loss: 1.511463074662466
Validation loss: 2.4158610215058256

Epoch: 5| Step: 2
Training loss: 1.8528351735622368
Validation loss: 2.4295605322729004

Epoch: 5| Step: 3
Training loss: 1.7384605058117755
Validation loss: 2.4008176861857446

Epoch: 5| Step: 4
Training loss: 1.670908853753696
Validation loss: 2.414998573614769

Epoch: 5| Step: 5
Training loss: 2.413790097962937
Validation loss: 2.439751461489214

Epoch: 5| Step: 6
Training loss: 2.0510008485477056
Validation loss: 2.4648710834742826

Epoch: 5| Step: 7
Training loss: 1.6474255533720479
Validation loss: 2.5006558154132663

Epoch: 5| Step: 8
Training loss: 1.7118200525474243
Validation loss: 2.5115132344174604

Epoch: 5| Step: 9
Training loss: 1.848342606727904
Validation loss: 2.5553838420505266

Epoch: 5| Step: 10
Training loss: 1.842885348060864
Validation loss: 2.5897241356692904

Epoch: 5| Step: 11
Training loss: 1.843951068841309
Validation loss: 2.6454103286898762

Epoch: 426| Step: 0
Training loss: 2.1286962563074683
Validation loss: 2.641852362591191

Epoch: 5| Step: 1
Training loss: 2.300465586434119
Validation loss: 2.6490191043288713

Epoch: 5| Step: 2
Training loss: 1.9466376636034182
Validation loss: 2.6294669223691685

Epoch: 5| Step: 3
Training loss: 1.7762324956881077
Validation loss: 2.6097125312890745

Epoch: 5| Step: 4
Training loss: 1.3988361323259806
Validation loss: 2.612316997178211

Epoch: 5| Step: 5
Training loss: 1.3186263654707036
Validation loss: 2.5667905302060747

Epoch: 5| Step: 6
Training loss: 1.4981458648641888
Validation loss: 2.541983023221641

Epoch: 5| Step: 7
Training loss: 2.361177475937795
Validation loss: 2.5678021463482006

Epoch: 5| Step: 8
Training loss: 1.613820722405733
Validation loss: 2.5362104899257356

Epoch: 5| Step: 9
Training loss: 1.9931428899766575
Validation loss: 2.565052552196085

Epoch: 5| Step: 10
Training loss: 1.3870626963284094
Validation loss: 2.549886572876972

Epoch: 5| Step: 11
Training loss: 1.2189362212497459
Validation loss: 2.518350159750653

Epoch: 427| Step: 0
Training loss: 1.8300187173521956
Validation loss: 2.5292220999368604

Epoch: 5| Step: 1
Training loss: 1.8201457589857626
Validation loss: 2.5551431504239996

Epoch: 5| Step: 2
Training loss: 1.1707883246969295
Validation loss: 2.5680450556549412

Epoch: 5| Step: 3
Training loss: 1.3197911152867363
Validation loss: 2.5636046323725266

Epoch: 5| Step: 4
Training loss: 1.6672748489164058
Validation loss: 2.6288629805096466

Epoch: 5| Step: 5
Training loss: 2.3333131471396515
Validation loss: 2.674289084975134

Epoch: 5| Step: 6
Training loss: 2.1110659003296575
Validation loss: 2.6851673722742047

Epoch: 5| Step: 7
Training loss: 1.8038874582639322
Validation loss: 2.711629051953062

Epoch: 5| Step: 8
Training loss: 2.10629816651099
Validation loss: 2.734061635544437

Epoch: 5| Step: 9
Training loss: 1.9849215378135845
Validation loss: 2.70928925125902

Epoch: 5| Step: 10
Training loss: 1.5510367464081876
Validation loss: 2.6835223063028777

Epoch: 5| Step: 11
Training loss: 1.0845827942440311
Validation loss: 2.632492555370473

Epoch: 428| Step: 0
Training loss: 2.0324044101660483
Validation loss: 2.567483908934966

Epoch: 5| Step: 1
Training loss: 1.4853676939921612
Validation loss: 2.500472981692244

Epoch: 5| Step: 2
Training loss: 2.0042648143356425
Validation loss: 2.534995839550058

Epoch: 5| Step: 3
Training loss: 1.7207379029101075
Validation loss: 2.500457324478441

Epoch: 5| Step: 4
Training loss: 1.8898699174751201
Validation loss: 2.519876352968434

Epoch: 5| Step: 5
Training loss: 1.753941389041965
Validation loss: 2.475439729705648

Epoch: 5| Step: 6
Training loss: 1.2932073367249652
Validation loss: 2.5213747835462272

Epoch: 5| Step: 7
Training loss: 1.7420444857482624
Validation loss: 2.5261715622895773

Epoch: 5| Step: 8
Training loss: 1.968276981265248
Validation loss: 2.524765609966431

Epoch: 5| Step: 9
Training loss: 1.8411403873548309
Validation loss: 2.582021581465278

Epoch: 5| Step: 10
Training loss: 1.2407927930540215
Validation loss: 2.5513076725835897

Epoch: 5| Step: 11
Training loss: 2.008625266778577
Validation loss: 2.608460804888595

Epoch: 429| Step: 0
Training loss: 2.148406760255941
Validation loss: 2.6505499285670613

Epoch: 5| Step: 1
Training loss: 1.9154658564165998
Validation loss: 2.642227803740084

Epoch: 5| Step: 2
Training loss: 1.4832528942600074
Validation loss: 2.6006932185744107

Epoch: 5| Step: 3
Training loss: 1.7176771803838324
Validation loss: 2.61378132093975

Epoch: 5| Step: 4
Training loss: 1.5410584031659487
Validation loss: 2.570231014146585

Epoch: 5| Step: 5
Training loss: 1.9145319771615454
Validation loss: 2.587497709184207

Epoch: 5| Step: 6
Training loss: 1.8402414722180258
Validation loss: 2.563000335539043

Epoch: 5| Step: 7
Training loss: 1.6877982264598357
Validation loss: 2.5466160671860325

Epoch: 5| Step: 8
Training loss: 1.5636968987564117
Validation loss: 2.5130962432984436

Epoch: 5| Step: 9
Training loss: 1.3890635264063542
Validation loss: 2.4884980934153136

Epoch: 5| Step: 10
Training loss: 1.8113833308984901
Validation loss: 2.4983967746535107

Epoch: 5| Step: 11
Training loss: 1.3789669380125078
Validation loss: 2.52861484674914

Epoch: 430| Step: 0
Training loss: 1.0591394348205376
Validation loss: 2.5124252021941733

Epoch: 5| Step: 1
Training loss: 2.362862138391994
Validation loss: 2.4815196016539116

Epoch: 5| Step: 2
Training loss: 1.782613266052099
Validation loss: 2.5073949519713397

Epoch: 5| Step: 3
Training loss: 1.6919883801081557
Validation loss: 2.5444262654602756

Epoch: 5| Step: 4
Training loss: 1.4291716098236515
Validation loss: 2.5240473684449523

Epoch: 5| Step: 5
Training loss: 1.9864919589283423
Validation loss: 2.546025694298176

Epoch: 5| Step: 6
Training loss: 1.64450399416992
Validation loss: 2.5538578552814033

Epoch: 5| Step: 7
Training loss: 1.2073230082163258
Validation loss: 2.590654851252934

Epoch: 5| Step: 8
Training loss: 2.1832449810215437
Validation loss: 2.6103764095282194

Epoch: 5| Step: 9
Training loss: 1.5120394265569825
Validation loss: 2.5877299363253385

Epoch: 5| Step: 10
Training loss: 1.3170028376074412
Validation loss: 2.584559802559581

Epoch: 5| Step: 11
Training loss: 1.7201027141996057
Validation loss: 2.582799315375653

Epoch: 431| Step: 0
Training loss: 1.741058736622141
Validation loss: 2.572116543353414

Epoch: 5| Step: 1
Training loss: 1.6675528157347133
Validation loss: 2.5862672754936518

Epoch: 5| Step: 2
Training loss: 1.6193148124696275
Validation loss: 2.5554127145033068

Epoch: 5| Step: 3
Training loss: 1.4527163187224459
Validation loss: 2.5858031715316576

Epoch: 5| Step: 4
Training loss: 1.966500222980827
Validation loss: 2.546084880159872

Epoch: 5| Step: 5
Training loss: 1.9537992000425515
Validation loss: 2.6031709668488507

Epoch: 5| Step: 6
Training loss: 1.5174346816759778
Validation loss: 2.607960266077541

Epoch: 5| Step: 7
Training loss: 2.031174174140613
Validation loss: 2.60455236376146

Epoch: 5| Step: 8
Training loss: 1.320165411526485
Validation loss: 2.609718364882809

Epoch: 5| Step: 9
Training loss: 1.0685203193906725
Validation loss: 2.6265487454198135

Epoch: 5| Step: 10
Training loss: 1.7150362988514773
Validation loss: 2.6046232484468446

Epoch: 5| Step: 11
Training loss: 2.0046136808295247
Validation loss: 2.5664046513491003

Epoch: 432| Step: 0
Training loss: 1.563932829977918
Validation loss: 2.5802219263200508

Epoch: 5| Step: 1
Training loss: 1.656999526378907
Validation loss: 2.514370220311586

Epoch: 5| Step: 2
Training loss: 1.2778711192734362
Validation loss: 2.5758053449206275

Epoch: 5| Step: 3
Training loss: 1.6164211355476235
Validation loss: 2.5731296502634136

Epoch: 5| Step: 4
Training loss: 1.8592830603172203
Validation loss: 2.591719970482056

Epoch: 5| Step: 5
Training loss: 1.6547339356330357
Validation loss: 2.5876082932113627

Epoch: 5| Step: 6
Training loss: 2.214672586598868
Validation loss: 2.6215118381753895

Epoch: 5| Step: 7
Training loss: 1.7327288814694775
Validation loss: 2.6680730982677066

Epoch: 5| Step: 8
Training loss: 1.609518692860837
Validation loss: 2.657789651786348

Epoch: 5| Step: 9
Training loss: 1.7606045398870729
Validation loss: 2.65149245086258

Epoch: 5| Step: 10
Training loss: 1.629118615081669
Validation loss: 2.6652500380797024

Epoch: 5| Step: 11
Training loss: 2.4944714451522456
Validation loss: 2.608966540348806

Epoch: 433| Step: 0
Training loss: 1.302902279489637
Validation loss: 2.615226515781178

Epoch: 5| Step: 1
Training loss: 1.7941558830597455
Validation loss: 2.582567421881477

Epoch: 5| Step: 2
Training loss: 1.5739817097726945
Validation loss: 2.6078887445279957

Epoch: 5| Step: 3
Training loss: 1.2284967029854885
Validation loss: 2.616663068922773

Epoch: 5| Step: 4
Training loss: 1.4216729324459143
Validation loss: 2.588605426461047

Epoch: 5| Step: 5
Training loss: 1.6945053499598284
Validation loss: 2.602586626735902

Epoch: 5| Step: 6
Training loss: 1.3310884512007621
Validation loss: 2.5900359276632545

Epoch: 5| Step: 7
Training loss: 1.6686156400960555
Validation loss: 2.6163167919023707

Epoch: 5| Step: 8
Training loss: 1.7165616756418478
Validation loss: 2.6315981236708628

Epoch: 5| Step: 9
Training loss: 2.656268400240727
Validation loss: 2.6491855176399155

Epoch: 5| Step: 10
Training loss: 1.6884452856640852
Validation loss: 2.6358597173183385

Epoch: 5| Step: 11
Training loss: 1.4084995502746103
Validation loss: 2.646169510958072

Epoch: 434| Step: 0
Training loss: 1.4803585927437823
Validation loss: 2.6462133440071582

Epoch: 5| Step: 1
Training loss: 2.378474254251495
Validation loss: 2.6694655941257572

Epoch: 5| Step: 2
Training loss: 1.8619160319119514
Validation loss: 2.650342977869046

Epoch: 5| Step: 3
Training loss: 1.6263141453471033
Validation loss: 2.5946858184758774

Epoch: 5| Step: 4
Training loss: 1.714641098526447
Validation loss: 2.5823743383529014

Epoch: 5| Step: 5
Training loss: 1.8021781617133186
Validation loss: 2.534551261263308

Epoch: 5| Step: 6
Training loss: 1.4425975146463812
Validation loss: 2.5880159897099033

Epoch: 5| Step: 7
Training loss: 1.7336552131556628
Validation loss: 2.5687209538397755

Epoch: 5| Step: 8
Training loss: 1.7150630593453782
Validation loss: 2.541409085984851

Epoch: 5| Step: 9
Training loss: 1.3636299277645014
Validation loss: 2.578547063631137

Epoch: 5| Step: 10
Training loss: 1.2053515651109605
Validation loss: 2.567153013016686

Epoch: 5| Step: 11
Training loss: 1.5721949591068272
Validation loss: 2.5603446657524054

Epoch: 435| Step: 0
Training loss: 1.7548807066669683
Validation loss: 2.5827081228813458

Epoch: 5| Step: 1
Training loss: 1.499325282619014
Validation loss: 2.5798537536751214

Epoch: 5| Step: 2
Training loss: 1.6372888705593
Validation loss: 2.6103958561872767

Epoch: 5| Step: 3
Training loss: 1.5971048984652385
Validation loss: 2.590200665229225

Epoch: 5| Step: 4
Training loss: 2.0024014598970656
Validation loss: 2.5938435886151483

Epoch: 5| Step: 5
Training loss: 1.6915434678164711
Validation loss: 2.6318100851908905

Epoch: 5| Step: 6
Training loss: 0.9553969149593432
Validation loss: 2.586727509540891

Epoch: 5| Step: 7
Training loss: 1.794104388913614
Validation loss: 2.5441845957660227

Epoch: 5| Step: 8
Training loss: 1.7041447237773695
Validation loss: 2.553872580241647

Epoch: 5| Step: 9
Training loss: 1.147242021171737
Validation loss: 2.548348377040754

Epoch: 5| Step: 10
Training loss: 2.2746927787508837
Validation loss: 2.566542652285155

Epoch: 5| Step: 11
Training loss: 1.5958573116297181
Validation loss: 2.5563696204491015

Epoch: 436| Step: 0
Training loss: 1.1374433901607202
Validation loss: 2.562656560627656

Epoch: 5| Step: 1
Training loss: 1.254127269054251
Validation loss: 2.605111989422628

Epoch: 5| Step: 2
Training loss: 1.3243054386897448
Validation loss: 2.6050693638609874

Epoch: 5| Step: 3
Training loss: 1.6368692187789426
Validation loss: 2.674153982647321

Epoch: 5| Step: 4
Training loss: 1.46694941432305
Validation loss: 2.5885107600147066

Epoch: 5| Step: 5
Training loss: 1.625541083411315
Validation loss: 2.5840618787979963

Epoch: 5| Step: 6
Training loss: 2.4455150971259605
Validation loss: 2.550791130416763

Epoch: 5| Step: 7
Training loss: 1.200473787236845
Validation loss: 2.5789247139469387

Epoch: 5| Step: 8
Training loss: 2.0672333473663245
Validation loss: 2.5723221409873713

Epoch: 5| Step: 9
Training loss: 1.3528405910367913
Validation loss: 2.5617396905354757

Epoch: 5| Step: 10
Training loss: 2.0562707870963206
Validation loss: 2.56444671196195

Epoch: 5| Step: 11
Training loss: 2.032595614240637
Validation loss: 2.5699148247293486

Epoch: 437| Step: 0
Training loss: 1.7696710998648244
Validation loss: 2.5450971908472697

Epoch: 5| Step: 1
Training loss: 1.8180613206902
Validation loss: 2.513225204511661

Epoch: 5| Step: 2
Training loss: 1.974650547643516
Validation loss: 2.5569915064430826

Epoch: 5| Step: 3
Training loss: 1.9328816036863248
Validation loss: 2.5540484329994397

Epoch: 5| Step: 4
Training loss: 1.582169967032837
Validation loss: 2.572614039385546

Epoch: 5| Step: 5
Training loss: 1.959922071678829
Validation loss: 2.559336461796711

Epoch: 5| Step: 6
Training loss: 1.132301741587091
Validation loss: 2.6092546286772613

Epoch: 5| Step: 7
Training loss: 1.3784391136047562
Validation loss: 2.595199130355524

Epoch: 5| Step: 8
Training loss: 2.2736498546723527
Validation loss: 2.6167872355305835

Epoch: 5| Step: 9
Training loss: 1.249782400264854
Validation loss: 2.632299386423131

Epoch: 5| Step: 10
Training loss: 1.2128910181410393
Validation loss: 2.6268461789433317

Epoch: 5| Step: 11
Training loss: 1.2739849668990229
Validation loss: 2.641719963536892

Epoch: 438| Step: 0
Training loss: 1.4229557834385065
Validation loss: 2.653678082740294

Epoch: 5| Step: 1
Training loss: 1.400622701102553
Validation loss: 2.664115293693792

Epoch: 5| Step: 2
Training loss: 1.8342537159117158
Validation loss: 2.697638240768457

Epoch: 5| Step: 3
Training loss: 1.388519536285824
Validation loss: 2.698056649414549

Epoch: 5| Step: 4
Training loss: 1.8525202724567635
Validation loss: 2.658081171478841

Epoch: 5| Step: 5
Training loss: 1.3524908945478709
Validation loss: 2.632246694317766

Epoch: 5| Step: 6
Training loss: 1.6278557260024473
Validation loss: 2.6097895698379574

Epoch: 5| Step: 7
Training loss: 1.3849358501106879
Validation loss: 2.578628171119205

Epoch: 5| Step: 8
Training loss: 2.0629052428739088
Validation loss: 2.5774077063044207

Epoch: 5| Step: 9
Training loss: 1.395288512909062
Validation loss: 2.5755708681240757

Epoch: 5| Step: 10
Training loss: 2.3600932663737395
Validation loss: 2.574055988296893

Epoch: 5| Step: 11
Training loss: 1.3133401452451023
Validation loss: 2.5421708667400895

Epoch: 439| Step: 0
Training loss: 1.725297283042626
Validation loss: 2.569789195487993

Epoch: 5| Step: 1
Training loss: 1.498298156432847
Validation loss: 2.605172117048404

Epoch: 5| Step: 2
Training loss: 1.496652683002987
Validation loss: 2.6409772491262347

Epoch: 5| Step: 3
Training loss: 1.4993951690703875
Validation loss: 2.6634087119239456

Epoch: 5| Step: 4
Training loss: 1.5588678487051308
Validation loss: 2.6670843122679453

Epoch: 5| Step: 5
Training loss: 1.539072879039797
Validation loss: 2.6485559292611316

Epoch: 5| Step: 6
Training loss: 1.8131218205305413
Validation loss: 2.6291173705624784

Epoch: 5| Step: 7
Training loss: 1.8429002905174183
Validation loss: 2.5968875139518692

Epoch: 5| Step: 8
Training loss: 1.1926160329672137
Validation loss: 2.5875741095687537

Epoch: 5| Step: 9
Training loss: 2.2095752199088636
Validation loss: 2.564630874629044

Epoch: 5| Step: 10
Training loss: 1.8201794227777424
Validation loss: 2.534947759502587

Epoch: 5| Step: 11
Training loss: 1.1463689534771682
Validation loss: 2.5181390351054014

Epoch: 440| Step: 0
Training loss: 1.429471859537883
Validation loss: 2.5026959525804258

Epoch: 5| Step: 1
Training loss: 1.0396795520071636
Validation loss: 2.524836539180234

Epoch: 5| Step: 2
Training loss: 1.8879266193604352
Validation loss: 2.5297494647844836

Epoch: 5| Step: 3
Training loss: 1.7493422498291618
Validation loss: 2.5705027717575883

Epoch: 5| Step: 4
Training loss: 1.564347433837206
Validation loss: 2.589661363074141

Epoch: 5| Step: 5
Training loss: 1.9836413010813196
Validation loss: 2.634497928428644

Epoch: 5| Step: 6
Training loss: 1.8369970632455908
Validation loss: 2.612864538552887

Epoch: 5| Step: 7
Training loss: 1.8188142299780856
Validation loss: 2.6135679086822505

Epoch: 5| Step: 8
Training loss: 1.8609926255626812
Validation loss: 2.582775945418235

Epoch: 5| Step: 9
Training loss: 1.4120591446211894
Validation loss: 2.6210864730711205

Epoch: 5| Step: 10
Training loss: 1.2670453425771646
Validation loss: 2.558148904038347

Epoch: 5| Step: 11
Training loss: 1.2378613936493013
Validation loss: 2.524114445135335

Epoch: 441| Step: 0
Training loss: 1.5525658474040682
Validation loss: 2.5361759973843907

Epoch: 5| Step: 1
Training loss: 1.4787290310763572
Validation loss: 2.5247284507145342

Epoch: 5| Step: 2
Training loss: 2.125492936349859
Validation loss: 2.5212358016832765

Epoch: 5| Step: 3
Training loss: 1.3118767848191244
Validation loss: 2.5226594928253174

Epoch: 5| Step: 4
Training loss: 1.2334626121467829
Validation loss: 2.526700945811845

Epoch: 5| Step: 5
Training loss: 1.6659310465873558
Validation loss: 2.4975887750447088

Epoch: 5| Step: 6
Training loss: 1.6625578619273953
Validation loss: 2.545829148661103

Epoch: 5| Step: 7
Training loss: 1.4930482947988677
Validation loss: 2.589001452920142

Epoch: 5| Step: 8
Training loss: 1.7041517889714919
Validation loss: 2.611392689688727

Epoch: 5| Step: 9
Training loss: 1.938203929879583
Validation loss: 2.6365477895060683

Epoch: 5| Step: 10
Training loss: 1.559544552928896
Validation loss: 2.6777348164772063

Epoch: 5| Step: 11
Training loss: 1.4452026325428855
Validation loss: 2.679627852522102

Epoch: 442| Step: 0
Training loss: 1.3489574398003445
Validation loss: 2.6475000363338803

Epoch: 5| Step: 1
Training loss: 1.971826662175429
Validation loss: 2.615446397858413

Epoch: 5| Step: 2
Training loss: 1.2010471186165366
Validation loss: 2.598870871581414

Epoch: 5| Step: 3
Training loss: 1.5607410448566865
Validation loss: 2.6003063097886496

Epoch: 5| Step: 4
Training loss: 1.8059817210610523
Validation loss: 2.5883896333397454

Epoch: 5| Step: 5
Training loss: 1.7038450906123934
Validation loss: 2.532781488902169

Epoch: 5| Step: 6
Training loss: 1.9049977426190154
Validation loss: 2.567638354995375

Epoch: 5| Step: 7
Training loss: 1.7225226871673989
Validation loss: 2.6032265275845634

Epoch: 5| Step: 8
Training loss: 1.0214018633396533
Validation loss: 2.5806542984578953

Epoch: 5| Step: 9
Training loss: 1.4203350405273587
Validation loss: 2.53834346664854

Epoch: 5| Step: 10
Training loss: 1.4791852475284282
Validation loss: 2.4970043652553238

Epoch: 5| Step: 11
Training loss: 1.4009112423834191
Validation loss: 2.5383318353482807

Epoch: 443| Step: 0
Training loss: 2.013687858925105
Validation loss: 2.5184603956088805

Epoch: 5| Step: 1
Training loss: 1.66923599881283
Validation loss: 2.5318060644843112

Epoch: 5| Step: 2
Training loss: 1.5775264700287464
Validation loss: 2.565346985505117

Epoch: 5| Step: 3
Training loss: 1.1868835656217065
Validation loss: 2.6007032340500635

Epoch: 5| Step: 4
Training loss: 1.175469189164215
Validation loss: 2.574960012418627

Epoch: 5| Step: 5
Training loss: 1.4157243942162714
Validation loss: 2.5820704162366486

Epoch: 5| Step: 6
Training loss: 1.92001761646931
Validation loss: 2.6233462657290594

Epoch: 5| Step: 7
Training loss: 1.513681640593498
Validation loss: 2.5789401644118004

Epoch: 5| Step: 8
Training loss: 1.688590297983128
Validation loss: 2.6147351594489123

Epoch: 5| Step: 9
Training loss: 1.56402704006245
Validation loss: 2.571872423339888

Epoch: 5| Step: 10
Training loss: 1.6642904349376497
Validation loss: 2.5762800454737245

Epoch: 5| Step: 11
Training loss: 1.5981011925312565
Validation loss: 2.541096917898901

Epoch: 444| Step: 0
Training loss: 2.2405866164746437
Validation loss: 2.5854564980034302

Epoch: 5| Step: 1
Training loss: 1.727150105043439
Validation loss: 2.584283305413073

Epoch: 5| Step: 2
Training loss: 0.8304744716673268
Validation loss: 2.56306662536367

Epoch: 5| Step: 3
Training loss: 1.7297517483709712
Validation loss: 2.582913442809576

Epoch: 5| Step: 4
Training loss: 1.5377297609672131
Validation loss: 2.6010459868293747

Epoch: 5| Step: 5
Training loss: 1.254235150230113
Validation loss: 2.6059930799017392

Epoch: 5| Step: 6
Training loss: 1.8339340641811297
Validation loss: 2.595659832082689

Epoch: 5| Step: 7
Training loss: 1.577746581984027
Validation loss: 2.6735437509932938

Epoch: 5| Step: 8
Training loss: 1.6676447462087047
Validation loss: 2.7010990702135227

Epoch: 5| Step: 9
Training loss: 1.008391871736657
Validation loss: 2.6806304762773885

Epoch: 5| Step: 10
Training loss: 1.518825730056566
Validation loss: 2.698525880398167

Epoch: 5| Step: 11
Training loss: 1.3470809814420008
Validation loss: 2.643575708883238

Epoch: 445| Step: 0
Training loss: 1.8524527039455623
Validation loss: 2.6038262462638757

Epoch: 5| Step: 1
Training loss: 1.457265471994904
Validation loss: 2.5993740740529288

Epoch: 5| Step: 2
Training loss: 1.433481903286599
Validation loss: 2.622416909419464

Epoch: 5| Step: 3
Training loss: 2.034728138827885
Validation loss: 2.580984956836425

Epoch: 5| Step: 4
Training loss: 1.4070390395012944
Validation loss: 2.6020099953812035

Epoch: 5| Step: 5
Training loss: 1.5390277994184551
Validation loss: 2.638054900531523

Epoch: 5| Step: 6
Training loss: 1.668788806592647
Validation loss: 2.6244422323801664

Epoch: 5| Step: 7
Training loss: 1.417357762380695
Validation loss: 2.6283509271121948

Epoch: 5| Step: 8
Training loss: 1.4290743487526096
Validation loss: 2.612983814033284

Epoch: 5| Step: 9
Training loss: 1.8316681914920494
Validation loss: 2.64173923963344

Epoch: 5| Step: 10
Training loss: 1.375700078819291
Validation loss: 2.6541447505814624

Epoch: 5| Step: 11
Training loss: 0.9617169328264907
Validation loss: 2.5812505117820743

Epoch: 446| Step: 0
Training loss: 1.3292694546328896
Validation loss: 2.617674627566509

Epoch: 5| Step: 1
Training loss: 1.8411693292725564
Validation loss: 2.545982855970332

Epoch: 5| Step: 2
Training loss: 1.216681363178135
Validation loss: 2.5828545354832944

Epoch: 5| Step: 3
Training loss: 2.1648588953001204
Validation loss: 2.5820729727940144

Epoch: 5| Step: 4
Training loss: 1.9506229090412035
Validation loss: 2.626411357542351

Epoch: 5| Step: 5
Training loss: 1.0188883073218777
Validation loss: 2.5961634043891633

Epoch: 5| Step: 6
Training loss: 1.4927473366170085
Validation loss: 2.6295566103919326

Epoch: 5| Step: 7
Training loss: 1.6137304535028456
Validation loss: 2.654293532810348

Epoch: 5| Step: 8
Training loss: 1.5615919908048483
Validation loss: 2.666748180981355

Epoch: 5| Step: 9
Training loss: 1.0314585157032246
Validation loss: 2.685816041346494

Epoch: 5| Step: 10
Training loss: 1.5453561589598943
Validation loss: 2.7032970785300066

Epoch: 5| Step: 11
Training loss: 1.9084458758000329
Validation loss: 2.652387046554216

Epoch: 447| Step: 0
Training loss: 1.105028260158767
Validation loss: 2.698444853571812

Epoch: 5| Step: 1
Training loss: 1.6112275803147786
Validation loss: 2.7157198473452078

Epoch: 5| Step: 2
Training loss: 1.9005831927662973
Validation loss: 2.689091521687807

Epoch: 5| Step: 3
Training loss: 1.5277408171527431
Validation loss: 2.6655799071838446

Epoch: 5| Step: 4
Training loss: 1.6359627008546516
Validation loss: 2.630629184151915

Epoch: 5| Step: 5
Training loss: 1.8850250539961306
Validation loss: 2.6154496833386904

Epoch: 5| Step: 6
Training loss: 1.4374263578708155
Validation loss: 2.5780280393612554

Epoch: 5| Step: 7
Training loss: 1.720640841687234
Validation loss: 2.552355982690133

Epoch: 5| Step: 8
Training loss: 1.98056758355615
Validation loss: 2.5577878736065096

Epoch: 5| Step: 9
Training loss: 1.4927402291502807
Validation loss: 2.547153204172728

Epoch: 5| Step: 10
Training loss: 1.4981583574931547
Validation loss: 2.5652400618183657

Epoch: 5| Step: 11
Training loss: 2.5785355674505293
Validation loss: 2.621168091009201

Epoch: 448| Step: 0
Training loss: 1.8002602574496311
Validation loss: 2.611504730666578

Epoch: 5| Step: 1
Training loss: 1.9346900375268237
Validation loss: 2.63793931755408

Epoch: 5| Step: 2
Training loss: 1.2128256566927105
Validation loss: 2.672697736248449

Epoch: 5| Step: 3
Training loss: 1.889637586774402
Validation loss: 2.713526084450019

Epoch: 5| Step: 4
Training loss: 1.3786076987074405
Validation loss: 2.7312068241818244

Epoch: 5| Step: 5
Training loss: 1.4035320719501916
Validation loss: 2.7545397126873516

Epoch: 5| Step: 6
Training loss: 1.7304917585853976
Validation loss: 2.696951470114179

Epoch: 5| Step: 7
Training loss: 1.5369284303987114
Validation loss: 2.72975741367665

Epoch: 5| Step: 8
Training loss: 2.0747030666185053
Validation loss: 2.6796948587596456

Epoch: 5| Step: 9
Training loss: 1.2666418441214142
Validation loss: 2.613559698562379

Epoch: 5| Step: 10
Training loss: 1.6925067801177722
Validation loss: 2.5995690285073625

Epoch: 5| Step: 11
Training loss: 1.508414983207924
Validation loss: 2.592162389405602

Epoch: 449| Step: 0
Training loss: 1.9993534831313955
Validation loss: 2.4995239042896826

Epoch: 5| Step: 1
Training loss: 1.8700528046603437
Validation loss: 2.5444262791251937

Epoch: 5| Step: 2
Training loss: 1.229886065377775
Validation loss: 2.4898086842227283

Epoch: 5| Step: 3
Training loss: 1.3727463112446179
Validation loss: 2.5212527443740527

Epoch: 5| Step: 4
Training loss: 1.8730603039591267
Validation loss: 2.5530686221674204

Epoch: 5| Step: 5
Training loss: 2.017267784926204
Validation loss: 2.566097095744917

Epoch: 5| Step: 6
Training loss: 1.2678299052806965
Validation loss: 2.6101615123967856

Epoch: 5| Step: 7
Training loss: 1.7181832506193104
Validation loss: 2.6050404297143537

Epoch: 5| Step: 8
Training loss: 1.5770630993504622
Validation loss: 2.691053587937879

Epoch: 5| Step: 9
Training loss: 1.1123505566979899
Validation loss: 2.6667424889056983

Epoch: 5| Step: 10
Training loss: 1.681369453923
Validation loss: 2.6567272393342396

Epoch: 5| Step: 11
Training loss: 2.2475969409509724
Validation loss: 2.6759646313425005

Epoch: 450| Step: 0
Training loss: 1.6910324564638275
Validation loss: 2.6151931907596087

Epoch: 5| Step: 1
Training loss: 1.7260668289047962
Validation loss: 2.54675074237161

Epoch: 5| Step: 2
Training loss: 1.1905882982419425
Validation loss: 2.5559677392560904

Epoch: 5| Step: 3
Training loss: 1.3926995479941002
Validation loss: 2.5590021055070533

Epoch: 5| Step: 4
Training loss: 1.3272072706732747
Validation loss: 2.5758823292794064

Epoch: 5| Step: 5
Training loss: 1.4612144982795303
Validation loss: 2.5411388964492203

Epoch: 5| Step: 6
Training loss: 1.493928941678631
Validation loss: 2.591232429987068

Epoch: 5| Step: 7
Training loss: 2.178755366044651
Validation loss: 2.5680643315907727

Epoch: 5| Step: 8
Training loss: 1.6244866220446466
Validation loss: 2.567347175522031

Epoch: 5| Step: 9
Training loss: 1.460638495053592
Validation loss: 2.6062443887907834

Epoch: 5| Step: 10
Training loss: 1.4023601987931342
Validation loss: 2.6580668873925815

Epoch: 5| Step: 11
Training loss: 2.3971175248892376
Validation loss: 2.707125043322128

Epoch: 451| Step: 0
Training loss: 2.0630716629784027
Validation loss: 2.7599335097686617

Epoch: 5| Step: 1
Training loss: 1.6219136933578748
Validation loss: 2.7183001061971206

Epoch: 5| Step: 2
Training loss: 1.9509168425747536
Validation loss: 2.782419462469368

Epoch: 5| Step: 3
Training loss: 1.5705093336341114
Validation loss: 2.793565315610955

Epoch: 5| Step: 4
Training loss: 1.6303269299480376
Validation loss: 2.7664665371447406

Epoch: 5| Step: 5
Training loss: 1.745301273757224
Validation loss: 2.724478288457242

Epoch: 5| Step: 6
Training loss: 1.5547138767784447
Validation loss: 2.663767540079001

Epoch: 5| Step: 7
Training loss: 1.3727437928823105
Validation loss: 2.5972872785137113

Epoch: 5| Step: 8
Training loss: 1.6540047884252533
Validation loss: 2.593377917767818

Epoch: 5| Step: 9
Training loss: 1.7093131659166572
Validation loss: 2.579625985521006

Epoch: 5| Step: 10
Training loss: 1.4302078717539637
Validation loss: 2.5376722236654965

Epoch: 5| Step: 11
Training loss: 2.376483955565101
Validation loss: 2.595472881973784

Epoch: 452| Step: 0
Training loss: 2.1854034185841362
Validation loss: 2.609768691220762

Epoch: 5| Step: 1
Training loss: 1.3603889367089759
Validation loss: 2.6306000836401484

Epoch: 5| Step: 2
Training loss: 1.8797949832364311
Validation loss: 2.6545429054893694

Epoch: 5| Step: 3
Training loss: 1.3082847116429779
Validation loss: 2.7384810399749226

Epoch: 5| Step: 4
Training loss: 1.6418247014514127
Validation loss: 2.7659820067592085

Epoch: 5| Step: 5
Training loss: 1.4300763377908117
Validation loss: 2.8020706188286875

Epoch: 5| Step: 6
Training loss: 2.060411841139689
Validation loss: 2.808152133565191

Epoch: 5| Step: 7
Training loss: 1.3777637881975344
Validation loss: 2.7879649049729225

Epoch: 5| Step: 8
Training loss: 1.3227758958466602
Validation loss: 2.732388343268991

Epoch: 5| Step: 9
Training loss: 1.2446714313915108
Validation loss: 2.743845258317697

Epoch: 5| Step: 10
Training loss: 1.580919944483233
Validation loss: 2.627861111834299

Epoch: 5| Step: 11
Training loss: 1.1109078790978462
Validation loss: 2.6253267947637497

Epoch: 453| Step: 0
Training loss: 1.5272830258369015
Validation loss: 2.614174656382025

Epoch: 5| Step: 1
Training loss: 1.1310560618704955
Validation loss: 2.596586488043737

Epoch: 5| Step: 2
Training loss: 1.0046113502986744
Validation loss: 2.5893406022021703

Epoch: 5| Step: 3
Training loss: 1.5984018539973552
Validation loss: 2.6098715068044

Epoch: 5| Step: 4
Training loss: 1.2139627874757593
Validation loss: 2.616458643300122

Epoch: 5| Step: 5
Training loss: 1.5243553331145756
Validation loss: 2.603855625014885

Epoch: 5| Step: 6
Training loss: 1.5172323768335192
Validation loss: 2.642174091451721

Epoch: 5| Step: 7
Training loss: 2.1679203612280027
Validation loss: 2.69061000655867

Epoch: 5| Step: 8
Training loss: 1.6549842604381388
Validation loss: 2.6856798876565238

Epoch: 5| Step: 9
Training loss: 1.747404216930064
Validation loss: 2.657690405652981

Epoch: 5| Step: 10
Training loss: 1.278892161874885
Validation loss: 2.6689767138944727

Epoch: 5| Step: 11
Training loss: 2.035802932472714
Validation loss: 2.6394663494012733

Epoch: 454| Step: 0
Training loss: 1.2479988291869417
Validation loss: 2.6258747217743523

Epoch: 5| Step: 1
Training loss: 2.1848601625157924
Validation loss: 2.5985861316164236

Epoch: 5| Step: 2
Training loss: 1.2392444895455779
Validation loss: 2.6339435845594523

Epoch: 5| Step: 3
Training loss: 1.4765644376227367
Validation loss: 2.6125861908111596

Epoch: 5| Step: 4
Training loss: 1.1877046208016109
Validation loss: 2.5793839800393106

Epoch: 5| Step: 5
Training loss: 1.6391280838434015
Validation loss: 2.557357186425311

Epoch: 5| Step: 6
Training loss: 1.3736387363600626
Validation loss: 2.5342701370865695

Epoch: 5| Step: 7
Training loss: 1.4769667622023153
Validation loss: 2.612405197729318

Epoch: 5| Step: 8
Training loss: 1.4815571591245387
Validation loss: 2.651399338482216

Epoch: 5| Step: 9
Training loss: 1.5526514571020795
Validation loss: 2.5787538705495665

Epoch: 5| Step: 10
Training loss: 1.4595995809856053
Validation loss: 2.59188667454178

Epoch: 5| Step: 11
Training loss: 1.2246728421302828
Validation loss: 2.584307265249306

Epoch: 455| Step: 0
Training loss: 1.0018346169864967
Validation loss: 2.661784326902334

Epoch: 5| Step: 1
Training loss: 1.3694628283333015
Validation loss: 2.664407724514645

Epoch: 5| Step: 2
Training loss: 1.4805805898811908
Validation loss: 2.6155004976084086

Epoch: 5| Step: 3
Training loss: 1.4916746846130948
Validation loss: 2.6845610391663186

Epoch: 5| Step: 4
Training loss: 1.8746699996464613
Validation loss: 2.639494975798288

Epoch: 5| Step: 5
Training loss: 1.1859270017458279
Validation loss: 2.603004388201719

Epoch: 5| Step: 6
Training loss: 1.8493065591197344
Validation loss: 2.6584350088659465

Epoch: 5| Step: 7
Training loss: 1.6663367978130135
Validation loss: 2.6238818095518672

Epoch: 5| Step: 8
Training loss: 1.3471702252127487
Validation loss: 2.5831553426050045

Epoch: 5| Step: 9
Training loss: 1.4257498123674506
Validation loss: 2.640956571930885

Epoch: 5| Step: 10
Training loss: 1.1783817466833246
Validation loss: 2.6252536499755603

Epoch: 5| Step: 11
Training loss: 1.3158791502710196
Validation loss: 2.6625977868344135

Epoch: 456| Step: 0
Training loss: 1.201016944880062
Validation loss: 2.682382487021811

Epoch: 5| Step: 1
Training loss: 1.4272819250922602
Validation loss: 2.697284389967377

Epoch: 5| Step: 2
Training loss: 1.553295336464613
Validation loss: 2.733507120366577

Epoch: 5| Step: 3
Training loss: 1.4182742291577526
Validation loss: 2.7339986814671526

Epoch: 5| Step: 4
Training loss: 1.7113025571945897
Validation loss: 2.7208900871219

Epoch: 5| Step: 5
Training loss: 1.9366000146388564
Validation loss: 2.6840346065405307

Epoch: 5| Step: 6
Training loss: 1.2788047717642868
Validation loss: 2.7124026697103107

Epoch: 5| Step: 7
Training loss: 1.2409949185976668
Validation loss: 2.703036352773079

Epoch: 5| Step: 8
Training loss: 1.3623026748697051
Validation loss: 2.706713839037275

Epoch: 5| Step: 9
Training loss: 1.4611631005050278
Validation loss: 2.6490681365358424

Epoch: 5| Step: 10
Training loss: 1.5799061760629152
Validation loss: 2.617117642661248

Epoch: 5| Step: 11
Training loss: 1.6019136369550173
Validation loss: 2.668662182645805

Epoch: 457| Step: 0
Training loss: 1.2085555245014263
Validation loss: 2.650428057682447

Epoch: 5| Step: 1
Training loss: 1.1265114062358697
Validation loss: 2.5931141085337353

Epoch: 5| Step: 2
Training loss: 1.232323934348098
Validation loss: 2.6146475466154433

Epoch: 5| Step: 3
Training loss: 1.380137037439111
Validation loss: 2.651120082892093

Epoch: 5| Step: 4
Training loss: 1.1009380653936454
Validation loss: 2.6467452855548457

Epoch: 5| Step: 5
Training loss: 1.1042390595702283
Validation loss: 2.6183735641405383

Epoch: 5| Step: 6
Training loss: 1.7933924886928003
Validation loss: 2.6533161716010008

Epoch: 5| Step: 7
Training loss: 1.5479607672931692
Validation loss: 2.6495331155003625

Epoch: 5| Step: 8
Training loss: 1.9505676617028334
Validation loss: 2.6817497977649687

Epoch: 5| Step: 9
Training loss: 1.810460159546072
Validation loss: 2.6621561435799643

Epoch: 5| Step: 10
Training loss: 1.1337366478080113
Validation loss: 2.632176474277496

Epoch: 5| Step: 11
Training loss: 1.5451091358687241
Validation loss: 2.640631222388406

Epoch: 458| Step: 0
Training loss: 1.5070469943935214
Validation loss: 2.659179439070689

Epoch: 5| Step: 1
Training loss: 1.5335467494111141
Validation loss: 2.72022784103368

Epoch: 5| Step: 2
Training loss: 1.648673885806812
Validation loss: 2.704927982428133

Epoch: 5| Step: 3
Training loss: 1.3519920151745588
Validation loss: 2.618639509985343

Epoch: 5| Step: 4
Training loss: 1.7564122705396283
Validation loss: 2.664920910967268

Epoch: 5| Step: 5
Training loss: 1.3440906181667032
Validation loss: 2.623263802911631

Epoch: 5| Step: 6
Training loss: 1.7454045448176736
Validation loss: 2.6376955045765675

Epoch: 5| Step: 7
Training loss: 1.6108602688440596
Validation loss: 2.606797534807144

Epoch: 5| Step: 8
Training loss: 1.222822817830309
Validation loss: 2.6262396958064413

Epoch: 5| Step: 9
Training loss: 1.038384180298636
Validation loss: 2.6279789960042166

Epoch: 5| Step: 10
Training loss: 1.125135625505321
Validation loss: 2.6705296161228094

Epoch: 5| Step: 11
Training loss: 1.8825078060803926
Validation loss: 2.65767694554059

Epoch: 459| Step: 0
Training loss: 1.4744745256015612
Validation loss: 2.688282483060052

Epoch: 5| Step: 1
Training loss: 1.5760793741492762
Validation loss: 2.8394971703386904

Epoch: 5| Step: 2
Training loss: 2.028871757910388
Validation loss: 2.8431788349512503

Epoch: 5| Step: 3
Training loss: 1.6762940660298493
Validation loss: 2.733366898489539

Epoch: 5| Step: 4
Training loss: 1.5036365614013776
Validation loss: 2.677527892955549

Epoch: 5| Step: 5
Training loss: 1.6212306688695934
Validation loss: 2.6309877329861413

Epoch: 5| Step: 6
Training loss: 0.9738510331123075
Validation loss: 2.54223737146079

Epoch: 5| Step: 7
Training loss: 1.384221883534072
Validation loss: 2.5450589291177246

Epoch: 5| Step: 8
Training loss: 1.897479596637701
Validation loss: 2.486397601662966

Epoch: 5| Step: 9
Training loss: 2.0516110439905453
Validation loss: 2.5539623479554607

Epoch: 5| Step: 10
Training loss: 1.4374886387915082
Validation loss: 2.5149391574148683

Epoch: 5| Step: 11
Training loss: 1.3613241844174944
Validation loss: 2.5540453252444775

Epoch: 460| Step: 0
Training loss: 1.7150874562110214
Validation loss: 2.6241646527423645

Epoch: 5| Step: 1
Training loss: 1.0769317768735864
Validation loss: 2.6255882489620523

Epoch: 5| Step: 2
Training loss: 1.3996213026121416
Validation loss: 2.6729936879023195

Epoch: 5| Step: 3
Training loss: 1.478158562502981
Validation loss: 2.703985025969874

Epoch: 5| Step: 4
Training loss: 1.5431954132862262
Validation loss: 2.7003496140902503

Epoch: 5| Step: 5
Training loss: 1.4067803548382127
Validation loss: 2.7142370630149046

Epoch: 5| Step: 6
Training loss: 1.7428123140600036
Validation loss: 2.69833981326666

Epoch: 5| Step: 7
Training loss: 1.2936372901361441
Validation loss: 2.7082441474217234

Epoch: 5| Step: 8
Training loss: 1.44437035448028
Validation loss: 2.6790913103065113

Epoch: 5| Step: 9
Training loss: 0.895804718950434
Validation loss: 2.6961218019726756

Epoch: 5| Step: 10
Training loss: 2.37412868377877
Validation loss: 2.6444138238362425

Epoch: 5| Step: 11
Training loss: 1.1620323860888193
Validation loss: 2.6231612168512033

Epoch: 461| Step: 0
Training loss: 1.4377846643298349
Validation loss: 2.647009127722801

Epoch: 5| Step: 1
Training loss: 2.129462773087459
Validation loss: 2.632546857644463

Epoch: 5| Step: 2
Training loss: 0.9536053119566679
Validation loss: 2.615212909286565

Epoch: 5| Step: 3
Training loss: 1.223367551165657
Validation loss: 2.63160918420227

Epoch: 5| Step: 4
Training loss: 1.4970489719410145
Validation loss: 2.5852470647916164

Epoch: 5| Step: 5
Training loss: 1.2310912480130984
Validation loss: 2.633203675502464

Epoch: 5| Step: 6
Training loss: 1.415346268924627
Validation loss: 2.673562255154276

Epoch: 5| Step: 7
Training loss: 1.5125741830083552
Validation loss: 2.656593521194917

Epoch: 5| Step: 8
Training loss: 1.5018784364303028
Validation loss: 2.6706522733422227

Epoch: 5| Step: 9
Training loss: 1.5575730272687918
Validation loss: 2.69563896671471

Epoch: 5| Step: 10
Training loss: 1.6600488246493614
Validation loss: 2.6161577125100894

Epoch: 5| Step: 11
Training loss: 1.5243094272125053
Validation loss: 2.6010804555493654

Epoch: 462| Step: 0
Training loss: 1.495596382195708
Validation loss: 2.6249534322755794

Epoch: 5| Step: 1
Training loss: 1.4465513126833178
Validation loss: 2.636657107539236

Epoch: 5| Step: 2
Training loss: 1.0358094080102744
Validation loss: 2.5842346662238844

Epoch: 5| Step: 3
Training loss: 1.3069346372259154
Validation loss: 2.6665167555295404

Epoch: 5| Step: 4
Training loss: 1.609737392475103
Validation loss: 2.670117787538335

Epoch: 5| Step: 5
Training loss: 1.5938781985912789
Validation loss: 2.6640786984306386

Epoch: 5| Step: 6
Training loss: 1.3216209023110046
Validation loss: 2.6468737326374647

Epoch: 5| Step: 7
Training loss: 1.3490066176012518
Validation loss: 2.6786939189545036

Epoch: 5| Step: 8
Training loss: 1.2531943038079205
Validation loss: 2.6784057109523207

Epoch: 5| Step: 9
Training loss: 1.9549472090479028
Validation loss: 2.6993912541885714

Epoch: 5| Step: 10
Training loss: 1.4123349253651734
Validation loss: 2.637270427493477

Epoch: 5| Step: 11
Training loss: 0.6709157172452879
Validation loss: 2.6646664439212318

Epoch: 463| Step: 0
Training loss: 1.4028165227535334
Validation loss: 2.6189496764637594

Epoch: 5| Step: 1
Training loss: 1.2874887743710506
Validation loss: 2.623705419840469

Epoch: 5| Step: 2
Training loss: 1.425097324996321
Validation loss: 2.6377180151001816

Epoch: 5| Step: 3
Training loss: 1.5711396728966773
Validation loss: 2.5703139995968667

Epoch: 5| Step: 4
Training loss: 1.2768370763792456
Validation loss: 2.631488512423993

Epoch: 5| Step: 5
Training loss: 1.3183161071458889
Validation loss: 2.6949309959023195

Epoch: 5| Step: 6
Training loss: 1.307145595622116
Validation loss: 2.7128319950236

Epoch: 5| Step: 7
Training loss: 1.7916942047250248
Validation loss: 2.7692078337439594

Epoch: 5| Step: 8
Training loss: 1.352866805817948
Validation loss: 2.7104511869159165

Epoch: 5| Step: 9
Training loss: 1.7341389538397334
Validation loss: 2.779591687477293

Epoch: 5| Step: 10
Training loss: 1.2268514596523934
Validation loss: 2.748114009598355

Epoch: 5| Step: 11
Training loss: 2.601678519196508
Validation loss: 2.6987453621557522

Epoch: 464| Step: 0
Training loss: 1.0132284205068485
Validation loss: 2.7111184960296852

Epoch: 5| Step: 1
Training loss: 1.3527325984052008
Validation loss: 2.6349477551822593

Epoch: 5| Step: 2
Training loss: 1.8219763228702655
Validation loss: 2.6197270005564044

Epoch: 5| Step: 3
Training loss: 1.0706017096503146
Validation loss: 2.6543111718891925

Epoch: 5| Step: 4
Training loss: 1.0172410871743875
Validation loss: 2.6246657650709198

Epoch: 5| Step: 5
Training loss: 1.5071335286682743
Validation loss: 2.6280594322017765

Epoch: 5| Step: 6
Training loss: 2.2232745606157382
Validation loss: 2.677884198538952

Epoch: 5| Step: 7
Training loss: 1.3429652739386098
Validation loss: 2.6446856965906975

Epoch: 5| Step: 8
Training loss: 0.8634260582623131
Validation loss: 2.6858864124551727

Epoch: 5| Step: 9
Training loss: 1.4060913844194127
Validation loss: 2.691171326740155

Epoch: 5| Step: 10
Training loss: 1.2828458756113768
Validation loss: 2.7014685022237215

Epoch: 5| Step: 11
Training loss: 1.3428288784719427
Validation loss: 2.701459720819401

Epoch: 465| Step: 0
Training loss: 1.474237619995902
Validation loss: 2.673822421988997

Epoch: 5| Step: 1
Training loss: 1.3619043343033947
Validation loss: 2.7060832702749797

Epoch: 5| Step: 2
Training loss: 1.12562019419134
Validation loss: 2.623307480959359

Epoch: 5| Step: 3
Training loss: 1.0689328622816083
Validation loss: 2.6334259627796315

Epoch: 5| Step: 4
Training loss: 1.9061755806826581
Validation loss: 2.638322379277668

Epoch: 5| Step: 5
Training loss: 1.03355185495184
Validation loss: 2.59960583639537

Epoch: 5| Step: 6
Training loss: 1.4474397418140976
Validation loss: 2.5559437974873296

Epoch: 5| Step: 7
Training loss: 1.768230372687384
Validation loss: 2.6001866457042615

Epoch: 5| Step: 8
Training loss: 1.6926384857634393
Validation loss: 2.616323451800119

Epoch: 5| Step: 9
Training loss: 1.2307627493201667
Validation loss: 2.5854466098175477

Epoch: 5| Step: 10
Training loss: 1.1729806389084818
Validation loss: 2.6775570585129476

Epoch: 5| Step: 11
Training loss: 1.43769727265502
Validation loss: 2.6824583958530717

Epoch: 466| Step: 0
Training loss: 1.9793631874360753
Validation loss: 2.6715077525197777

Epoch: 5| Step: 1
Training loss: 1.393621837385529
Validation loss: 2.6582641669296816

Epoch: 5| Step: 2
Training loss: 1.2293800018007104
Validation loss: 2.6831752556289126

Epoch: 5| Step: 3
Training loss: 1.5426096824341138
Validation loss: 2.71483406412789

Epoch: 5| Step: 4
Training loss: 1.7420139653974214
Validation loss: 2.6717546075240004

Epoch: 5| Step: 5
Training loss: 1.2053804930186274
Validation loss: 2.66892809024246

Epoch: 5| Step: 6
Training loss: 1.0595360535036131
Validation loss: 2.6582905616926773

Epoch: 5| Step: 7
Training loss: 1.3681798330918788
Validation loss: 2.6595628910353817

Epoch: 5| Step: 8
Training loss: 1.2204953436444266
Validation loss: 2.681214304481145

Epoch: 5| Step: 9
Training loss: 1.4685110344165362
Validation loss: 2.67241743132694

Epoch: 5| Step: 10
Training loss: 1.0502262280485937
Validation loss: 2.7116248389017055

Epoch: 5| Step: 11
Training loss: 1.3090811661486559
Validation loss: 2.721460040404227

Epoch: 467| Step: 0
Training loss: 1.2799649190565743
Validation loss: 2.720760482691011

Epoch: 5| Step: 1
Training loss: 1.6017188019194766
Validation loss: 2.742234395378786

Epoch: 5| Step: 2
Training loss: 1.6376512734230435
Validation loss: 2.692910721119259

Epoch: 5| Step: 3
Training loss: 1.5034228055652545
Validation loss: 2.70631026611297

Epoch: 5| Step: 4
Training loss: 1.2038428901966562
Validation loss: 2.726400379655042

Epoch: 5| Step: 5
Training loss: 1.5814433194525155
Validation loss: 2.708804791325735

Epoch: 5| Step: 6
Training loss: 1.1389469710842093
Validation loss: 2.712746752079283

Epoch: 5| Step: 7
Training loss: 1.3120381587224694
Validation loss: 2.640725363379706

Epoch: 5| Step: 8
Training loss: 1.4209720133710633
Validation loss: 2.6526494137984344

Epoch: 5| Step: 9
Training loss: 1.158649223578979
Validation loss: 2.7278679361375886

Epoch: 5| Step: 10
Training loss: 0.9643176725682632
Validation loss: 2.676306026631902

Epoch: 5| Step: 11
Training loss: 1.4688965744577993
Validation loss: 2.6542781017950436

Epoch: 468| Step: 0
Training loss: 1.670157860929926
Validation loss: 2.6110900260590264

Epoch: 5| Step: 1
Training loss: 1.4434092594348173
Validation loss: 2.59216136999682

Epoch: 5| Step: 2
Training loss: 1.3202879412471866
Validation loss: 2.5924488235592116

Epoch: 5| Step: 3
Training loss: 1.469957058597248
Validation loss: 2.6145662152665916

Epoch: 5| Step: 4
Training loss: 1.1762387725748278
Validation loss: 2.633861679831836

Epoch: 5| Step: 5
Training loss: 1.650482644670239
Validation loss: 2.652118364289037

Epoch: 5| Step: 6
Training loss: 1.233166984775291
Validation loss: 2.6490129916459466

Epoch: 5| Step: 7
Training loss: 1.6483327100088536
Validation loss: 2.7008564641453026

Epoch: 5| Step: 8
Training loss: 1.2160146289874052
Validation loss: 2.7242390443618287

Epoch: 5| Step: 9
Training loss: 1.3284642403369402
Validation loss: 2.7771017055852893

Epoch: 5| Step: 10
Training loss: 1.2679777059279898
Validation loss: 2.712000540413517

Epoch: 5| Step: 11
Training loss: 1.5587280521514857
Validation loss: 2.7039688571903735

Epoch: 469| Step: 0
Training loss: 1.572653472640214
Validation loss: 2.6783446607269084

Epoch: 5| Step: 1
Training loss: 0.9896038990226111
Validation loss: 2.6257137206289602

Epoch: 5| Step: 2
Training loss: 1.1524986550908713
Validation loss: 2.57050436785978

Epoch: 5| Step: 3
Training loss: 1.2993433339204006
Validation loss: 2.591276433263652

Epoch: 5| Step: 4
Training loss: 1.5465711815452212
Validation loss: 2.5835996011183853

Epoch: 5| Step: 5
Training loss: 1.3532780690646338
Validation loss: 2.5990247138241385

Epoch: 5| Step: 6
Training loss: 1.6683034806656354
Validation loss: 2.682890443108439

Epoch: 5| Step: 7
Training loss: 1.4268832194041026
Validation loss: 2.657174256284399

Epoch: 5| Step: 8
Training loss: 1.0817427267734159
Validation loss: 2.729557454665827

Epoch: 5| Step: 9
Training loss: 1.4778048823953447
Validation loss: 2.75196951542475

Epoch: 5| Step: 10
Training loss: 1.3984959339741478
Validation loss: 2.721032580245693

Epoch: 5| Step: 11
Training loss: 1.1817862933198258
Validation loss: 2.72900820531738

Epoch: 470| Step: 0
Training loss: 1.0310029398583012
Validation loss: 2.750896697802924

Epoch: 5| Step: 1
Training loss: 1.2959682557904262
Validation loss: 2.694717691735974

Epoch: 5| Step: 2
Training loss: 1.033483629422765
Validation loss: 2.6946013134313764

Epoch: 5| Step: 3
Training loss: 1.511357621619667
Validation loss: 2.5821347853100955

Epoch: 5| Step: 4
Training loss: 1.3039108980254839
Validation loss: 2.5763600521467445

Epoch: 5| Step: 5
Training loss: 1.503448099476811
Validation loss: 2.6102758668484314

Epoch: 5| Step: 6
Training loss: 1.3562815754814177
Validation loss: 2.594650273176034

Epoch: 5| Step: 7
Training loss: 1.2862506137620298
Validation loss: 2.6133032979828665

Epoch: 5| Step: 8
Training loss: 1.3536178748411523
Validation loss: 2.6093316712275074

Epoch: 5| Step: 9
Training loss: 1.7883950533471478
Validation loss: 2.6088392274905705

Epoch: 5| Step: 10
Training loss: 1.5987788129630505
Validation loss: 2.636152463784463

Epoch: 5| Step: 11
Training loss: 1.0111060920236772
Validation loss: 2.6720909120646628

Epoch: 471| Step: 0
Training loss: 1.8348430211954945
Validation loss: 2.709537676041784

Epoch: 5| Step: 1
Training loss: 1.1849138810456605
Validation loss: 2.6833025956219756

Epoch: 5| Step: 2
Training loss: 1.8590526782283112
Validation loss: 2.691857811741763

Epoch: 5| Step: 3
Training loss: 0.9235086352322049
Validation loss: 2.6747745597176036

Epoch: 5| Step: 4
Training loss: 1.273712549754041
Validation loss: 2.66392847508968

Epoch: 5| Step: 5
Training loss: 0.8086637015192695
Validation loss: 2.6094307769783565

Epoch: 5| Step: 6
Training loss: 1.1047150971285173
Validation loss: 2.621859033692842

Epoch: 5| Step: 7
Training loss: 1.2591520959367475
Validation loss: 2.6688767131350697

Epoch: 5| Step: 8
Training loss: 1.4375076293742852
Validation loss: 2.6972352435228415

Epoch: 5| Step: 9
Training loss: 1.1004112125267822
Validation loss: 2.6515650366862986

Epoch: 5| Step: 10
Training loss: 1.446553372914497
Validation loss: 2.657255984527465

Epoch: 5| Step: 11
Training loss: 1.375288196185157
Validation loss: 2.658606471306752

Epoch: 472| Step: 0
Training loss: 1.1869897750150569
Validation loss: 2.723872656900163

Epoch: 5| Step: 1
Training loss: 1.6264734190660686
Validation loss: 2.671811699814547

Epoch: 5| Step: 2
Training loss: 1.1406351898992344
Validation loss: 2.6600814039518665

Epoch: 5| Step: 3
Training loss: 1.7408053128385814
Validation loss: 2.6755259445425774

Epoch: 5| Step: 4
Training loss: 0.997654249746398
Validation loss: 2.7349540896517155

Epoch: 5| Step: 5
Training loss: 1.1444625052680213
Validation loss: 2.6745243248227055

Epoch: 5| Step: 6
Training loss: 1.0085234980268867
Validation loss: 2.733761862176882

Epoch: 5| Step: 7
Training loss: 1.2369694545431502
Validation loss: 2.7214345284358514

Epoch: 5| Step: 8
Training loss: 1.4814496577783176
Validation loss: 2.6886971306195444

Epoch: 5| Step: 9
Training loss: 1.5705434145460218
Validation loss: 2.671459894486007

Epoch: 5| Step: 10
Training loss: 1.3825806245524188
Validation loss: 2.6166759655315452

Epoch: 5| Step: 11
Training loss: 1.3149510612374142
Validation loss: 2.638788720929102

Epoch: 473| Step: 0
Training loss: 1.404116304590548
Validation loss: 2.661889928970098

Epoch: 5| Step: 1
Training loss: 1.6696837138283505
Validation loss: 2.6656678845144928

Epoch: 5| Step: 2
Training loss: 1.2393201447090025
Validation loss: 2.6594699640946446

Epoch: 5| Step: 3
Training loss: 1.2835906443729548
Validation loss: 2.737008506891069

Epoch: 5| Step: 4
Training loss: 1.0354573513662517
Validation loss: 2.7475325286751535

Epoch: 5| Step: 5
Training loss: 1.6632299355277578
Validation loss: 2.793005573590157

Epoch: 5| Step: 6
Training loss: 1.258250189975396
Validation loss: 2.766709160095417

Epoch: 5| Step: 7
Training loss: 1.1265374380596394
Validation loss: 2.7633354027118764

Epoch: 5| Step: 8
Training loss: 1.7934089735214813
Validation loss: 2.704929980319574

Epoch: 5| Step: 9
Training loss: 1.1820355220498127
Validation loss: 2.7218500893143083

Epoch: 5| Step: 10
Training loss: 1.2491842469108
Validation loss: 2.7066419944515645

Epoch: 5| Step: 11
Training loss: 1.1533268759570596
Validation loss: 2.6835512271716033

Epoch: 474| Step: 0
Training loss: 1.4451491804895538
Validation loss: 2.719216763413602

Epoch: 5| Step: 1
Training loss: 0.977858667402324
Validation loss: 2.667262434842558

Epoch: 5| Step: 2
Training loss: 1.4354706413112914
Validation loss: 2.6902120789520256

Epoch: 5| Step: 3
Training loss: 1.0787412568375658
Validation loss: 2.7281233865821264

Epoch: 5| Step: 4
Training loss: 1.6820422323234276
Validation loss: 2.6951848041305184

Epoch: 5| Step: 5
Training loss: 1.4482096734644607
Validation loss: 2.6945993078818193

Epoch: 5| Step: 6
Training loss: 1.0876867901219365
Validation loss: 2.667435759909232

Epoch: 5| Step: 7
Training loss: 1.4701258931130907
Validation loss: 2.6504284587306532

Epoch: 5| Step: 8
Training loss: 1.1421721951859145
Validation loss: 2.6959793961197036

Epoch: 5| Step: 9
Training loss: 1.4989109059196573
Validation loss: 2.704002105768501

Epoch: 5| Step: 10
Training loss: 0.8431239808050264
Validation loss: 2.680948555724904

Epoch: 5| Step: 11
Training loss: 0.9759594695751238
Validation loss: 2.73528342279603

Epoch: 475| Step: 0
Training loss: 1.6451921380949368
Validation loss: 2.7330885267728164

Epoch: 5| Step: 1
Training loss: 1.3154825201377494
Validation loss: 2.708710267662043

Epoch: 5| Step: 2
Training loss: 1.1671577623452447
Validation loss: 2.694184786999838

Epoch: 5| Step: 3
Training loss: 0.9972368151772634
Validation loss: 2.7050707141026455

Epoch: 5| Step: 4
Training loss: 0.9783961666688661
Validation loss: 2.683103058443384

Epoch: 5| Step: 5
Training loss: 1.4736281205918516
Validation loss: 2.6849049525779765

Epoch: 5| Step: 6
Training loss: 1.0559973036377612
Validation loss: 2.644960579893868

Epoch: 5| Step: 7
Training loss: 1.8808440369231172
Validation loss: 2.7061294844518846

Epoch: 5| Step: 8
Training loss: 1.212091007271755
Validation loss: 2.73816562758572

Epoch: 5| Step: 9
Training loss: 1.2216262134829745
Validation loss: 2.7447029922223596

Epoch: 5| Step: 10
Training loss: 1.359956945621363
Validation loss: 2.745730398204284

Epoch: 5| Step: 11
Training loss: 0.9825987760865804
Validation loss: 2.7942215037309652

Epoch: 476| Step: 0
Training loss: 1.1539243041984801
Validation loss: 2.747607953649799

Epoch: 5| Step: 1
Training loss: 1.4190151252558783
Validation loss: 2.6713530976983844

Epoch: 5| Step: 2
Training loss: 1.1893741474960406
Validation loss: 2.7215938602488703

Epoch: 5| Step: 3
Training loss: 1.005403819206941
Validation loss: 2.647488220441991

Epoch: 5| Step: 4
Training loss: 1.1062181177232575
Validation loss: 2.692317824881738

Epoch: 5| Step: 5
Training loss: 1.4849713382459566
Validation loss: 2.668027256277132

Epoch: 5| Step: 6
Training loss: 1.3344019491793213
Validation loss: 2.7098476883419473

Epoch: 5| Step: 7
Training loss: 1.1750903967315547
Validation loss: 2.77470857748212

Epoch: 5| Step: 8
Training loss: 1.19809105750904
Validation loss: 2.7554916039112074

Epoch: 5| Step: 9
Training loss: 1.3935765008749585
Validation loss: 2.753568970427807

Epoch: 5| Step: 10
Training loss: 1.6360399390850744
Validation loss: 2.7407733861116914

Epoch: 5| Step: 11
Training loss: 1.277906801210343
Validation loss: 2.777898140259935

Epoch: 477| Step: 0
Training loss: 1.0979794606752706
Validation loss: 2.762906320531722

Epoch: 5| Step: 1
Training loss: 1.6718978880269248
Validation loss: 2.7664745376606064

Epoch: 5| Step: 2
Training loss: 1.2407566682911915
Validation loss: 2.735773513646184

Epoch: 5| Step: 3
Training loss: 1.5127992538884025
Validation loss: 2.7765334888288606

Epoch: 5| Step: 4
Training loss: 1.4180639145708862
Validation loss: 2.7236848709713626

Epoch: 5| Step: 5
Training loss: 1.1195922792335433
Validation loss: 2.7484935405628232

Epoch: 5| Step: 6
Training loss: 1.2302020071428497
Validation loss: 2.756064248980254

Epoch: 5| Step: 7
Training loss: 1.014602204812465
Validation loss: 2.767577164819623

Epoch: 5| Step: 8
Training loss: 1.2547157027897875
Validation loss: 2.750052200529978

Epoch: 5| Step: 9
Training loss: 0.9440317226066393
Validation loss: 2.7489440725828036

Epoch: 5| Step: 10
Training loss: 1.1575150657315998
Validation loss: 2.737606573135129

Epoch: 5| Step: 11
Training loss: 1.258671342954866
Validation loss: 2.7187540741228586

Epoch: 478| Step: 0
Training loss: 1.113762681163174
Validation loss: 2.75400947034667

Epoch: 5| Step: 1
Training loss: 1.2516096241969563
Validation loss: 2.7627939220353697

Epoch: 5| Step: 2
Training loss: 0.77667767536018
Validation loss: 2.787318067928632

Epoch: 5| Step: 3
Training loss: 1.759782357088705
Validation loss: 2.782375550847326

Epoch: 5| Step: 4
Training loss: 1.4103739985102632
Validation loss: 2.7316499628188984

Epoch: 5| Step: 5
Training loss: 0.8711088033838045
Validation loss: 2.7281621122803643

Epoch: 5| Step: 6
Training loss: 0.9092756603816579
Validation loss: 2.695385685908423

Epoch: 5| Step: 7
Training loss: 1.1446990843740483
Validation loss: 2.6927478733270975

Epoch: 5| Step: 8
Training loss: 1.2664617903977504
Validation loss: 2.7046455670945644

Epoch: 5| Step: 9
Training loss: 1.376248443145287
Validation loss: 2.660885102761717

Epoch: 5| Step: 10
Training loss: 1.312462306616717
Validation loss: 2.6445986458827058

Epoch: 5| Step: 11
Training loss: 1.5332898935439583
Validation loss: 2.699121347409851

Epoch: 479| Step: 0
Training loss: 0.912605297858757
Validation loss: 2.742685781710458

Epoch: 5| Step: 1
Training loss: 1.232732670161077
Validation loss: 2.7982499491968977

Epoch: 5| Step: 2
Training loss: 1.1306509507776956
Validation loss: 2.7869323838228985

Epoch: 5| Step: 3
Training loss: 1.8718375557289237
Validation loss: 2.767024639728553

Epoch: 5| Step: 4
Training loss: 1.2952782786304249
Validation loss: 2.720371037115783

Epoch: 5| Step: 5
Training loss: 1.2009246819929063
Validation loss: 2.6762398282742272

Epoch: 5| Step: 6
Training loss: 1.4219699869811324
Validation loss: 2.660113664343154

Epoch: 5| Step: 7
Training loss: 1.1744208085250027
Validation loss: 2.7144055275836694

Epoch: 5| Step: 8
Training loss: 1.175084056282583
Validation loss: 2.713782196709056

Epoch: 5| Step: 9
Training loss: 1.3842167163200523
Validation loss: 2.708278220178358

Epoch: 5| Step: 10
Training loss: 1.324140608290865
Validation loss: 2.7338994947878605

Epoch: 5| Step: 11
Training loss: 0.7686536790625114
Validation loss: 2.724562613793538

Epoch: 480| Step: 0
Training loss: 1.239164212106216
Validation loss: 2.7751704680575786

Epoch: 5| Step: 1
Training loss: 1.4158916971632058
Validation loss: 2.778211598428657

Epoch: 5| Step: 2
Training loss: 0.8923420332977449
Validation loss: 2.7969006940346968

Epoch: 5| Step: 3
Training loss: 1.2877093987408295
Validation loss: 2.8347553244751382

Epoch: 5| Step: 4
Training loss: 1.444727846407813
Validation loss: 2.8081138494414386

Epoch: 5| Step: 5
Training loss: 1.4904851340007133
Validation loss: 2.812891385431888

Epoch: 5| Step: 6
Training loss: 1.1737580492680064
Validation loss: 2.6879131605765765

Epoch: 5| Step: 7
Training loss: 1.2843777231897597
Validation loss: 2.718300943084208

Epoch: 5| Step: 8
Training loss: 1.1193533224267735
Validation loss: 2.7087367466495404

Epoch: 5| Step: 9
Training loss: 1.0817536917319976
Validation loss: 2.7046868694325985

Epoch: 5| Step: 10
Training loss: 1.2570454882946873
Validation loss: 2.6733441691603135

Epoch: 5| Step: 11
Training loss: 0.6719128797631715
Validation loss: 2.6842327773017827

Epoch: 481| Step: 0
Training loss: 1.2938371951440208
Validation loss: 2.7045532341622507

Epoch: 5| Step: 1
Training loss: 1.0675354732363895
Validation loss: 2.700965709822169

Epoch: 5| Step: 2
Training loss: 1.4304089002938267
Validation loss: 2.6847900211908087

Epoch: 5| Step: 3
Training loss: 1.1691234073715757
Validation loss: 2.744580582253982

Epoch: 5| Step: 4
Training loss: 0.8648543028975912
Validation loss: 2.7685139145671687

Epoch: 5| Step: 5
Training loss: 1.840285327184135
Validation loss: 2.8279563790313227

Epoch: 5| Step: 6
Training loss: 1.2045658450911754
Validation loss: 2.8084985171298236

Epoch: 5| Step: 7
Training loss: 1.489329852253515
Validation loss: 2.776219154156781

Epoch: 5| Step: 8
Training loss: 1.1720232043328966
Validation loss: 2.7969944535928852

Epoch: 5| Step: 9
Training loss: 1.3759712776856903
Validation loss: 2.7638511249117808

Epoch: 5| Step: 10
Training loss: 1.1608322691427604
Validation loss: 2.7374447004112246

Epoch: 5| Step: 11
Training loss: 1.5094420171356309
Validation loss: 2.724400458307722

Epoch: 482| Step: 0
Training loss: 1.2465135590649383
Validation loss: 2.7168988981820075

Epoch: 5| Step: 1
Training loss: 1.0081594298810306
Validation loss: 2.6864867961884946

Epoch: 5| Step: 2
Training loss: 0.9813736467149262
Validation loss: 2.748473164404907

Epoch: 5| Step: 3
Training loss: 1.1445522892290858
Validation loss: 2.692921323241498

Epoch: 5| Step: 4
Training loss: 1.1902454662400905
Validation loss: 2.6859379487095536

Epoch: 5| Step: 5
Training loss: 1.1031457872026145
Validation loss: 2.7570249281238124

Epoch: 5| Step: 6
Training loss: 1.5136101297890419
Validation loss: 2.7232543346786446

Epoch: 5| Step: 7
Training loss: 1.5734822180718722
Validation loss: 2.7026105512473886

Epoch: 5| Step: 8
Training loss: 0.9437552306680799
Validation loss: 2.6852602534074546

Epoch: 5| Step: 9
Training loss: 0.8096095536940496
Validation loss: 2.655128563906979

Epoch: 5| Step: 10
Training loss: 1.4238180780252523
Validation loss: 2.669545918998274

Epoch: 5| Step: 11
Training loss: 1.0402294289173744
Validation loss: 2.707105675023319

Epoch: 483| Step: 0
Training loss: 1.2899497013488115
Validation loss: 2.7199845233353046

Epoch: 5| Step: 1
Training loss: 1.075341820154994
Validation loss: 2.738830522200545

Epoch: 5| Step: 2
Training loss: 0.8833101945821483
Validation loss: 2.7685448701876205

Epoch: 5| Step: 3
Training loss: 1.0762917785865007
Validation loss: 2.7416983636417114

Epoch: 5| Step: 4
Training loss: 1.4848093300890053
Validation loss: 2.755371681423779

Epoch: 5| Step: 5
Training loss: 0.8539352607510627
Validation loss: 2.6909450842743428

Epoch: 5| Step: 6
Training loss: 1.4538054975050154
Validation loss: 2.776348588496315

Epoch: 5| Step: 7
Training loss: 1.50568346314643
Validation loss: 2.73153854572875

Epoch: 5| Step: 8
Training loss: 0.8823096269373099
Validation loss: 2.722867547934534

Epoch: 5| Step: 9
Training loss: 1.20725072945458
Validation loss: 2.7137463316123154

Epoch: 5| Step: 10
Training loss: 1.0379520304773344
Validation loss: 2.6912978934376106

Epoch: 5| Step: 11
Training loss: 1.3789640852170448
Validation loss: 2.714072852150649

Epoch: 484| Step: 0
Training loss: 0.931364038384727
Validation loss: 2.740409502889387

Epoch: 5| Step: 1
Training loss: 1.221437669622943
Validation loss: 2.742648347709829

Epoch: 5| Step: 2
Training loss: 1.1330103208201419
Validation loss: 2.785197193046336

Epoch: 5| Step: 3
Training loss: 1.300638047775674
Validation loss: 2.809396150768918

Epoch: 5| Step: 4
Training loss: 0.8544545890165651
Validation loss: 2.8127604964382567

Epoch: 5| Step: 5
Training loss: 1.3668430003330703
Validation loss: 2.822488035526377

Epoch: 5| Step: 6
Training loss: 1.4603463675230672
Validation loss: 2.7517485406048694

Epoch: 5| Step: 7
Training loss: 1.2240770755822292
Validation loss: 2.748540458464002

Epoch: 5| Step: 8
Training loss: 1.2345890873545207
Validation loss: 2.736367239208513

Epoch: 5| Step: 9
Training loss: 1.2101151165703918
Validation loss: 2.731967981944213

Epoch: 5| Step: 10
Training loss: 1.4430720929954524
Validation loss: 2.756104297780315

Epoch: 5| Step: 11
Training loss: 0.6993203116026748
Validation loss: 2.7358423564698957

Epoch: 485| Step: 0
Training loss: 1.1796136795087688
Validation loss: 2.7213141126590163

Epoch: 5| Step: 1
Training loss: 1.2361080220835137
Validation loss: 2.7708766056687764

Epoch: 5| Step: 2
Training loss: 1.459350458302287
Validation loss: 2.7235951494558335

Epoch: 5| Step: 3
Training loss: 1.0193753762773654
Validation loss: 2.7337317772856666

Epoch: 5| Step: 4
Training loss: 0.935377579504624
Validation loss: 2.727842870123611

Epoch: 5| Step: 5
Training loss: 0.8537462913577848
Validation loss: 2.7754783929686915

Epoch: 5| Step: 6
Training loss: 1.0572784247610514
Validation loss: 2.7460206077678295

Epoch: 5| Step: 7
Training loss: 1.2523163314740162
Validation loss: 2.735847861206573

Epoch: 5| Step: 8
Training loss: 1.3065326001683748
Validation loss: 2.728214579535656

Epoch: 5| Step: 9
Training loss: 1.3938974174234209
Validation loss: 2.717751403638861

Epoch: 5| Step: 10
Training loss: 1.2386919176975764
Validation loss: 2.7732700171964857

Epoch: 5| Step: 11
Training loss: 0.9476235883325111
Validation loss: 2.7527482792937246

Epoch: 486| Step: 0
Training loss: 1.308067238630998
Validation loss: 2.729845800906479

Epoch: 5| Step: 1
Training loss: 0.6015138482571125
Validation loss: 2.7772608555523144

Epoch: 5| Step: 2
Training loss: 1.0650644769090036
Validation loss: 2.8212808265799096

Epoch: 5| Step: 3
Training loss: 1.2587117363001714
Validation loss: 2.834611065815021

Epoch: 5| Step: 4
Training loss: 1.0732873381262773
Validation loss: 2.8009792951281436

Epoch: 5| Step: 5
Training loss: 1.094509460537289
Validation loss: 2.7829283461535312

Epoch: 5| Step: 6
Training loss: 1.1192303633203862
Validation loss: 2.7975359265415665

Epoch: 5| Step: 7
Training loss: 1.4573727941210894
Validation loss: 2.6981010717656844

Epoch: 5| Step: 8
Training loss: 0.9265833088434271
Validation loss: 2.7347304776141748

Epoch: 5| Step: 9
Training loss: 1.8973061915194531
Validation loss: 2.718385942426763

Epoch: 5| Step: 10
Training loss: 0.9245513278933698
Validation loss: 2.7699267056186816

Epoch: 5| Step: 11
Training loss: 0.8055672142310547
Validation loss: 2.758004604201131

Epoch: 487| Step: 0
Training loss: 0.9511714676811083
Validation loss: 2.797104256040877

Epoch: 5| Step: 1
Training loss: 1.1347132554174022
Validation loss: 2.721529121189857

Epoch: 5| Step: 2
Training loss: 1.058019897775004
Validation loss: 2.7622263728280503

Epoch: 5| Step: 3
Training loss: 1.069531678003932
Validation loss: 2.787198352885973

Epoch: 5| Step: 4
Training loss: 1.1009990793375017
Validation loss: 2.739279281704339

Epoch: 5| Step: 5
Training loss: 1.2821349367640138
Validation loss: 2.751850834703645

Epoch: 5| Step: 6
Training loss: 1.543844163007426
Validation loss: 2.6793354830101666

Epoch: 5| Step: 7
Training loss: 1.3907627508966496
Validation loss: 2.6990646671641128

Epoch: 5| Step: 8
Training loss: 0.8525196960277066
Validation loss: 2.7251367566734204

Epoch: 5| Step: 9
Training loss: 1.0733627515418074
Validation loss: 2.7278099048509072

Epoch: 5| Step: 10
Training loss: 1.411646005838851
Validation loss: 2.674437794029514

Epoch: 5| Step: 11
Training loss: 1.1736432785250597
Validation loss: 2.7461427672466883

Epoch: 488| Step: 0
Training loss: 1.0331079911564407
Validation loss: 2.7711393550636525

Epoch: 5| Step: 1
Training loss: 1.3839860236200887
Validation loss: 2.7225307324382286

Epoch: 5| Step: 2
Training loss: 1.2217134978740951
Validation loss: 2.7718153781205723

Epoch: 5| Step: 3
Training loss: 1.273756209668118
Validation loss: 2.7112153870029445

Epoch: 5| Step: 4
Training loss: 0.8735040410717496
Validation loss: 2.715766541333809

Epoch: 5| Step: 5
Training loss: 1.1603200263845963
Validation loss: 2.7581719838709158

Epoch: 5| Step: 6
Training loss: 1.0846887447929219
Validation loss: 2.7240085974019403

Epoch: 5| Step: 7
Training loss: 1.2471530441766399
Validation loss: 2.719740573885774

Epoch: 5| Step: 8
Training loss: 1.0270193770009763
Validation loss: 2.755677705432191

Epoch: 5| Step: 9
Training loss: 1.2416614882256651
Validation loss: 2.7415654599043227

Epoch: 5| Step: 10
Training loss: 1.132633747598775
Validation loss: 2.7624451231935914

Epoch: 5| Step: 11
Training loss: 0.700759745324234
Validation loss: 2.778235745162549

Epoch: 489| Step: 0
Training loss: 1.273328015822314
Validation loss: 2.7339295596652833

Epoch: 5| Step: 1
Training loss: 1.1488089966178643
Validation loss: 2.752303603600743

Epoch: 5| Step: 2
Training loss: 1.0765231852003587
Validation loss: 2.722944801689168

Epoch: 5| Step: 3
Training loss: 1.0208410275746718
Validation loss: 2.740506014385049

Epoch: 5| Step: 4
Training loss: 1.1692133877356095
Validation loss: 2.729539632185856

Epoch: 5| Step: 5
Training loss: 1.2722633425042371
Validation loss: 2.7263887308122516

Epoch: 5| Step: 6
Training loss: 1.424827361106218
Validation loss: 2.701329375387536

Epoch: 5| Step: 7
Training loss: 1.249978542143705
Validation loss: 2.7855868726686883

Epoch: 5| Step: 8
Training loss: 0.9104678230549336
Validation loss: 2.775149258617541

Epoch: 5| Step: 9
Training loss: 1.21192129226729
Validation loss: 2.7764414248368228

Epoch: 5| Step: 10
Training loss: 0.977737178028827
Validation loss: 2.8284853324572774

Epoch: 5| Step: 11
Training loss: 1.3383045308080657
Validation loss: 2.8661813971639725

Epoch: 490| Step: 0
Training loss: 0.7993822111471105
Validation loss: 2.864942870840944

Epoch: 5| Step: 1
Training loss: 1.3009013902324666
Validation loss: 2.8955091316687596

Epoch: 5| Step: 2
Training loss: 0.9685590617378601
Validation loss: 2.779436137896119

Epoch: 5| Step: 3
Training loss: 0.8802611694429021
Validation loss: 2.803649107985285

Epoch: 5| Step: 4
Training loss: 1.1339625867326646
Validation loss: 2.79380191211417

Epoch: 5| Step: 5
Training loss: 1.2482379892368474
Validation loss: 2.7450073466292406

Epoch: 5| Step: 6
Training loss: 1.0979950405766228
Validation loss: 2.721371764106375

Epoch: 5| Step: 7
Training loss: 1.3486555292314228
Validation loss: 2.7242944460198877

Epoch: 5| Step: 8
Training loss: 1.2145323032152269
Validation loss: 2.7592500176643604

Epoch: 5| Step: 9
Training loss: 1.0570727467761756
Validation loss: 2.7488507954584764

Epoch: 5| Step: 10
Training loss: 0.9531444172366564
Validation loss: 2.8137356657456465

Epoch: 5| Step: 11
Training loss: 1.4059107053246431
Validation loss: 2.7696585076727223

Epoch: 491| Step: 0
Training loss: 1.1470689469246031
Validation loss: 2.729269602098662

Epoch: 5| Step: 1
Training loss: 1.40541573255372
Validation loss: 2.7664590572878396

Epoch: 5| Step: 2
Training loss: 1.256091628838618
Validation loss: 2.7506056158464376

Epoch: 5| Step: 3
Training loss: 1.215724368312138
Validation loss: 2.796145566019815

Epoch: 5| Step: 4
Training loss: 1.1577490291109505
Validation loss: 2.7578203707286413

Epoch: 5| Step: 5
Training loss: 1.0320472525454012
Validation loss: 2.739425037558615

Epoch: 5| Step: 6
Training loss: 1.2592266497072506
Validation loss: 2.787597292754563

Epoch: 5| Step: 7
Training loss: 0.9212428042727313
Validation loss: 2.7585494341910297

Epoch: 5| Step: 8
Training loss: 0.9216128154276699
Validation loss: 2.7631616847132583

Epoch: 5| Step: 9
Training loss: 1.0689993271928173
Validation loss: 2.800173283363685

Epoch: 5| Step: 10
Training loss: 0.9026637645195362
Validation loss: 2.7560772898648342

Epoch: 5| Step: 11
Training loss: 1.26154045049804
Validation loss: 2.8049195210465094

Epoch: 492| Step: 0
Training loss: 0.9996343480605997
Validation loss: 2.7901172655909097

Epoch: 5| Step: 1
Training loss: 1.4023249207829087
Validation loss: 2.7735048276940493

Epoch: 5| Step: 2
Training loss: 1.1836943127304005
Validation loss: 2.870913413822088

Epoch: 5| Step: 3
Training loss: 1.2786160819741819
Validation loss: 2.7962939193316423

Epoch: 5| Step: 4
Training loss: 1.1721562365982685
Validation loss: 2.8749507592310533

Epoch: 5| Step: 5
Training loss: 1.1639962913578636
Validation loss: 2.8345098518780865

Epoch: 5| Step: 6
Training loss: 0.9632798775742802
Validation loss: 2.8146092594137633

Epoch: 5| Step: 7
Training loss: 0.8820685906695592
Validation loss: 2.833678488651492

Epoch: 5| Step: 8
Training loss: 1.2884012086629897
Validation loss: 2.8149146699366314

Epoch: 5| Step: 9
Training loss: 0.9617810152475398
Validation loss: 2.832011858994319

Epoch: 5| Step: 10
Training loss: 0.9837413746747715
Validation loss: 2.859122124418281

Epoch: 5| Step: 11
Training loss: 1.3824441279042847
Validation loss: 2.832155366129032

Epoch: 493| Step: 0
Training loss: 0.8387560876321242
Validation loss: 2.806431344197278

Epoch: 5| Step: 1
Training loss: 1.267418332600812
Validation loss: 2.821417978452534

Epoch: 5| Step: 2
Training loss: 0.9343352625125272
Validation loss: 2.8156907808139744

Epoch: 5| Step: 3
Training loss: 1.0866345151482228
Validation loss: 2.784076886357018

Epoch: 5| Step: 4
Training loss: 1.1058355471012251
Validation loss: 2.817392709980223

Epoch: 5| Step: 5
Training loss: 1.6351487088018142
Validation loss: 2.8199859845769084

Epoch: 5| Step: 6
Training loss: 1.10270972067244
Validation loss: 2.7789814569668625

Epoch: 5| Step: 7
Training loss: 1.2507232481012993
Validation loss: 2.82173903677399

Epoch: 5| Step: 8
Training loss: 0.7932831465116338
Validation loss: 2.8306099598387378

Epoch: 5| Step: 9
Training loss: 1.0281073339735924
Validation loss: 2.835665781754892

Epoch: 5| Step: 10
Training loss: 1.0182214266717826
Validation loss: 2.7928074894658423

Epoch: 5| Step: 11
Training loss: 0.2669789504235015
Validation loss: 2.765002854192271

Epoch: 494| Step: 0
Training loss: 1.1747485216370523
Validation loss: 2.767046112492236

Epoch: 5| Step: 1
Training loss: 1.2683866534928492
Validation loss: 2.760943824287314

Epoch: 5| Step: 2
Training loss: 1.3211675730449066
Validation loss: 2.7349401307803225

Epoch: 5| Step: 3
Training loss: 1.108438284405586
Validation loss: 2.698492199892442

Epoch: 5| Step: 4
Training loss: 1.0124887607091937
Validation loss: 2.7562662135690386

Epoch: 5| Step: 5
Training loss: 0.9943386098076108
Validation loss: 2.761808786898426

Epoch: 5| Step: 6
Training loss: 1.0171836044307245
Validation loss: 2.776935305922568

Epoch: 5| Step: 7
Training loss: 0.8783224243654425
Validation loss: 2.7468517084041966

Epoch: 5| Step: 8
Training loss: 1.2441140356171896
Validation loss: 2.7366586286362478

Epoch: 5| Step: 9
Training loss: 1.10253289949977
Validation loss: 2.7597105034688862

Epoch: 5| Step: 10
Training loss: 0.7328818135941094
Validation loss: 2.8149909291649187

Epoch: 5| Step: 11
Training loss: 0.5342560317806181
Validation loss: 2.7832560252019882

Epoch: 495| Step: 0
Training loss: 0.989896095776549
Validation loss: 2.7995144237101997

Epoch: 5| Step: 1
Training loss: 1.2251406160730762
Validation loss: 2.8192872731530345

Epoch: 5| Step: 2
Training loss: 1.2175441547509933
Validation loss: 2.7673317228155736

Epoch: 5| Step: 3
Training loss: 1.0330621230139567
Validation loss: 2.776083759229694

Epoch: 5| Step: 4
Training loss: 0.9452874361609032
Validation loss: 2.7588342029400628

Epoch: 5| Step: 5
Training loss: 1.4109496529056833
Validation loss: 2.770734718307918

Epoch: 5| Step: 6
Training loss: 1.0126078465799089
Validation loss: 2.7363380760503855

Epoch: 5| Step: 7
Training loss: 0.9721742837682577
Validation loss: 2.726948227145074

Epoch: 5| Step: 8
Training loss: 1.144567547635953
Validation loss: 2.735850689823552

Epoch: 5| Step: 9
Training loss: 1.1266715559110325
Validation loss: 2.732300223713917

Epoch: 5| Step: 10
Training loss: 1.0038124367189183
Validation loss: 2.767080175615012

Epoch: 5| Step: 11
Training loss: 1.2228106806424939
Validation loss: 2.740491996794282

Epoch: 496| Step: 0
Training loss: 1.07868793552124
Validation loss: 2.792522371629961

Epoch: 5| Step: 1
Training loss: 1.2798575766869875
Validation loss: 2.803473525988914

Epoch: 5| Step: 2
Training loss: 1.142490898780549
Validation loss: 2.760434997545713

Epoch: 5| Step: 3
Training loss: 0.7603178395539674
Validation loss: 2.811803724498178

Epoch: 5| Step: 4
Training loss: 1.0656984656283592
Validation loss: 2.833499266636753

Epoch: 5| Step: 5
Training loss: 1.4406784411797544
Validation loss: 2.8362768511385883

Epoch: 5| Step: 6
Training loss: 1.4487565529702255
Validation loss: 2.8262776616669147

Epoch: 5| Step: 7
Training loss: 0.9933652120846985
Validation loss: 2.8853872770518065

Epoch: 5| Step: 8
Training loss: 0.9545081062152524
Validation loss: 2.897833049087948

Epoch: 5| Step: 9
Training loss: 0.7328391958876561
Validation loss: 2.8103352127449734

Epoch: 5| Step: 10
Training loss: 1.1454892364322615
Validation loss: 2.8662298475916512

Epoch: 5| Step: 11
Training loss: 0.7182143329935504
Validation loss: 2.827802123296178

Epoch: 497| Step: 0
Training loss: 1.0203472394418285
Validation loss: 2.7590320905469343

Epoch: 5| Step: 1
Training loss: 0.9446736218199332
Validation loss: 2.76824404023781

Epoch: 5| Step: 2
Training loss: 1.3374155802244079
Validation loss: 2.84311858003643

Epoch: 5| Step: 3
Training loss: 1.7310666672348998
Validation loss: 2.803994535025451

Epoch: 5| Step: 4
Training loss: 1.1155589044049097
Validation loss: 2.829507711039712

Epoch: 5| Step: 5
Training loss: 0.9852340219823889
Validation loss: 2.8224468133441136

Epoch: 5| Step: 6
Training loss: 1.3314005681527639
Validation loss: 2.7501134704530337

Epoch: 5| Step: 7
Training loss: 0.9948651983969561
Validation loss: 2.71876345371703

Epoch: 5| Step: 8
Training loss: 0.9286451506955384
Validation loss: 2.745443785409925

Epoch: 5| Step: 9
Training loss: 0.9307148490249941
Validation loss: 2.701643374195761

Epoch: 5| Step: 10
Training loss: 1.1855639184672513
Validation loss: 2.763639434156764

Epoch: 5| Step: 11
Training loss: 0.8071163520367418
Validation loss: 2.700008194080917

Epoch: 498| Step: 0
Training loss: 1.2026951505008021
Validation loss: 2.782096087599957

Epoch: 5| Step: 1
Training loss: 1.5966643073131568
Validation loss: 2.802527620529378

Epoch: 5| Step: 2
Training loss: 0.6383631482104436
Validation loss: 2.8084237441178845

Epoch: 5| Step: 3
Training loss: 1.3403124642811275
Validation loss: 2.8529144113293188

Epoch: 5| Step: 4
Training loss: 0.8839191825720365
Validation loss: 2.7908267541669054

Epoch: 5| Step: 5
Training loss: 1.1628404385440445
Validation loss: 2.7876053145889155

Epoch: 5| Step: 6
Training loss: 0.9358702799455247
Validation loss: 2.770857026899947

Epoch: 5| Step: 7
Training loss: 0.8938755147337949
Validation loss: 2.7808352386160196

Epoch: 5| Step: 8
Training loss: 0.9738903871930813
Validation loss: 2.7934927317696205

Epoch: 5| Step: 9
Training loss: 1.118521580739867
Validation loss: 2.800730454300381

Epoch: 5| Step: 10
Training loss: 1.0694209931569785
Validation loss: 2.7642438712238273

Epoch: 5| Step: 11
Training loss: 1.153636091318897
Validation loss: 2.7576523537105477

Epoch: 499| Step: 0
Training loss: 1.128388124250375
Validation loss: 2.816809506763375

Epoch: 5| Step: 1
Training loss: 1.0310292441163857
Validation loss: 2.858064750827719

Epoch: 5| Step: 2
Training loss: 1.5064246555229153
Validation loss: 2.835138402752849

Epoch: 5| Step: 3
Training loss: 1.3332548366725707
Validation loss: 2.8017256956408123

Epoch: 5| Step: 4
Training loss: 0.9294676961635998
Validation loss: 2.7370918328167817

Epoch: 5| Step: 5
Training loss: 1.0045590782850113
Validation loss: 2.7658041772074764

Epoch: 5| Step: 6
Training loss: 1.0075126024314671
Validation loss: 2.7359300424128135

Epoch: 5| Step: 7
Training loss: 0.870571818319197
Validation loss: 2.750062725045369

Epoch: 5| Step: 8
Training loss: 1.0304949337031
Validation loss: 2.7378509263168325

Epoch: 5| Step: 9
Training loss: 1.102101836502903
Validation loss: 2.74189629235691

Epoch: 5| Step: 10
Training loss: 0.9519707929734983
Validation loss: 2.8081383935091173

Epoch: 5| Step: 11
Training loss: 1.423990959829931
Validation loss: 2.7961678951921107

Epoch: 500| Step: 0
Training loss: 1.1600671599118655
Validation loss: 2.8343045741496744

Epoch: 5| Step: 1
Training loss: 1.1344690772524946
Validation loss: 2.950871376342505

Epoch: 5| Step: 2
Training loss: 1.144165501400622
Validation loss: 3.0589847209256202

Epoch: 5| Step: 3
Training loss: 1.4476209196667769
Validation loss: 3.03735485331883

Epoch: 5| Step: 4
Training loss: 1.3758416201047146
Validation loss: 3.016353558700354

Epoch: 5| Step: 5
Training loss: 1.1422848577793328
Validation loss: 2.9316879631217394

Epoch: 5| Step: 6
Training loss: 1.2944066099896365
Validation loss: 2.8358869872135295

Epoch: 5| Step: 7
Training loss: 1.1268076678834773
Validation loss: 2.748537888680579

Epoch: 5| Step: 8
Training loss: 1.1833350777053513
Validation loss: 2.774277974324366

Epoch: 5| Step: 9
Training loss: 1.3810999119890122
Validation loss: 2.715619107771533

Epoch: 5| Step: 10
Training loss: 1.0372574120452327
Validation loss: 2.7334091587908076

Epoch: 5| Step: 11
Training loss: 1.475296204130918
Validation loss: 2.7355348288898047

Epoch: 501| Step: 0
Training loss: 0.9943247926170254
Validation loss: 2.7538150095874196

Epoch: 5| Step: 1
Training loss: 1.2503731647429555
Validation loss: 2.7476090889315246

Epoch: 5| Step: 2
Training loss: 0.6955239049586485
Validation loss: 2.7730819330947205

Epoch: 5| Step: 3
Training loss: 1.0156811625284285
Validation loss: 2.814950024210301

Epoch: 5| Step: 4
Training loss: 0.9071464708533038
Validation loss: 2.8146950809442597

Epoch: 5| Step: 5
Training loss: 0.8548797251780913
Validation loss: 2.7615941697168433

Epoch: 5| Step: 6
Training loss: 1.3959007057138422
Validation loss: 2.73652885258052

Epoch: 5| Step: 7
Training loss: 1.1169895450235945
Validation loss: 2.7161180720948064

Epoch: 5| Step: 8
Training loss: 1.3078923409541123
Validation loss: 2.7561957507514627

Epoch: 5| Step: 9
Training loss: 0.7811097209874941
Validation loss: 2.770642038544362

Epoch: 5| Step: 10
Training loss: 0.716102117880353
Validation loss: 2.7735677554208436

Epoch: 5| Step: 11
Training loss: 0.6641135476631101
Validation loss: 2.779064827348987

Epoch: 502| Step: 0
Training loss: 0.9554060858500926
Validation loss: 2.761654872416342

Epoch: 5| Step: 1
Training loss: 1.4709966804783319
Validation loss: 2.747761013596068

Epoch: 5| Step: 2
Training loss: 0.9891378437289666
Validation loss: 2.7037668476764387

Epoch: 5| Step: 3
Training loss: 1.1907575498474137
Validation loss: 2.746346622579423

Epoch: 5| Step: 4
Training loss: 0.9571049875929968
Validation loss: 2.705915311860497

Epoch: 5| Step: 5
Training loss: 0.9981137606012466
Validation loss: 2.7074325873194613

Epoch: 5| Step: 6
Training loss: 0.9930023992015824
Validation loss: 2.7540915208184438

Epoch: 5| Step: 7
Training loss: 1.0170126605038214
Validation loss: 2.77863185322518

Epoch: 5| Step: 8
Training loss: 0.860445396337785
Validation loss: 2.769517720076885

Epoch: 5| Step: 9
Training loss: 1.1514996039141008
Validation loss: 2.7806340796448943

Epoch: 5| Step: 10
Training loss: 0.6689926687588728
Validation loss: 2.851395167488221

Epoch: 5| Step: 11
Training loss: 0.7720895059884028
Validation loss: 2.9123597202708744

Epoch: 503| Step: 0
Training loss: 1.2560984145228662
Validation loss: 2.9194463302216236

Epoch: 5| Step: 1
Training loss: 0.9914571221468403
Validation loss: 2.9301137317439556

Epoch: 5| Step: 2
Training loss: 0.9623341528947716
Validation loss: 2.8621873661267108

Epoch: 5| Step: 3
Training loss: 0.8467980536382198
Validation loss: 2.8284898315371887

Epoch: 5| Step: 4
Training loss: 1.1597208047174152
Validation loss: 2.8318855546327897

Epoch: 5| Step: 5
Training loss: 0.7435459754700003
Validation loss: 2.7972358030460738

Epoch: 5| Step: 6
Training loss: 1.1409719279226886
Validation loss: 2.8310565858562415

Epoch: 5| Step: 7
Training loss: 0.9273765114683099
Validation loss: 2.771546359329001

Epoch: 5| Step: 8
Training loss: 1.6085304340427697
Validation loss: 2.786386953610181

Epoch: 5| Step: 9
Training loss: 1.0470172159187727
Validation loss: 2.8183278914552647

Epoch: 5| Step: 10
Training loss: 0.8943411279391517
Validation loss: 2.78849838421794

Epoch: 5| Step: 11
Training loss: 1.3517928175299547
Validation loss: 2.7874372717580576

Epoch: 504| Step: 0
Training loss: 0.8911620411531362
Validation loss: 2.8593051081941834

Epoch: 5| Step: 1
Training loss: 0.9394236855444481
Validation loss: 2.9368240478289023

Epoch: 5| Step: 2
Training loss: 1.4070326428615658
Validation loss: 2.918352434635739

Epoch: 5| Step: 3
Training loss: 1.0553633043544088
Validation loss: 2.8612102740324064

Epoch: 5| Step: 4
Training loss: 0.8203045799236336
Validation loss: 2.83995089532147

Epoch: 5| Step: 5
Training loss: 0.9080804229213129
Validation loss: 2.9175578776668387

Epoch: 5| Step: 6
Training loss: 1.0760414889182541
Validation loss: 2.806274701684475

Epoch: 5| Step: 7
Training loss: 1.1646705421910242
Validation loss: 2.774940681539495

Epoch: 5| Step: 8
Training loss: 1.087829368962418
Validation loss: 2.783068744471517

Epoch: 5| Step: 9
Training loss: 0.8578725338688771
Validation loss: 2.8081896990447466

Epoch: 5| Step: 10
Training loss: 1.0787579986346452
Validation loss: 2.7321215181143663

Epoch: 5| Step: 11
Training loss: 1.764288337246659
Validation loss: 2.801900727704675

Epoch: 505| Step: 0
Training loss: 0.799122688434515
Validation loss: 2.84031545996962

Epoch: 5| Step: 1
Training loss: 1.2440387678146552
Validation loss: 2.832298729202502

Epoch: 5| Step: 2
Training loss: 0.9869755499110053
Validation loss: 2.884340269100759

Epoch: 5| Step: 3
Training loss: 1.2620809407220432
Validation loss: 2.9058274813097995

Epoch: 5| Step: 4
Training loss: 0.9458371117526191
Validation loss: 2.8533728997066032

Epoch: 5| Step: 5
Training loss: 1.16824036568886
Validation loss: 2.8947852671468874

Epoch: 5| Step: 6
Training loss: 0.7200653231313555
Validation loss: 2.866515105883679

Epoch: 5| Step: 7
Training loss: 0.7096809769216845
Validation loss: 2.870239476725356

Epoch: 5| Step: 8
Training loss: 1.5215174386149906
Validation loss: 2.8214524942387555

Epoch: 5| Step: 9
Training loss: 1.192314877086129
Validation loss: 2.7794416813893115

Epoch: 5| Step: 10
Training loss: 0.9430253600516106
Validation loss: 2.7867035422174413

Epoch: 5| Step: 11
Training loss: 0.6373156224819905
Validation loss: 2.765237942782365

Epoch: 506| Step: 0
Training loss: 1.3195430161091015
Validation loss: 2.7742999531277293

Epoch: 5| Step: 1
Training loss: 1.238667232392849
Validation loss: 2.747256170884207

Epoch: 5| Step: 2
Training loss: 0.9749219007268145
Validation loss: 2.809337975410446

Epoch: 5| Step: 3
Training loss: 0.8364195102472158
Validation loss: 2.808964778637458

Epoch: 5| Step: 4
Training loss: 0.7597520527939022
Validation loss: 2.8418945330677086

Epoch: 5| Step: 5
Training loss: 1.0975565474764601
Validation loss: 2.8773280475874015

Epoch: 5| Step: 6
Training loss: 1.1067459761876233
Validation loss: 2.8965106842019126

Epoch: 5| Step: 7
Training loss: 0.9025847868573224
Validation loss: 2.849677078317814

Epoch: 5| Step: 8
Training loss: 1.0299962832559728
Validation loss: 2.8420363632263252

Epoch: 5| Step: 9
Training loss: 1.0866068142710088
Validation loss: 2.853196272668374

Epoch: 5| Step: 10
Training loss: 1.2073662055469645
Validation loss: 2.8009568588982114

Epoch: 5| Step: 11
Training loss: 0.721372546754829
Validation loss: 2.793454385431801

Epoch: 507| Step: 0
Training loss: 0.9251850316847685
Validation loss: 2.8470619184962533

Epoch: 5| Step: 1
Training loss: 0.8408451940596616
Validation loss: 2.8635925429066136

Epoch: 5| Step: 2
Training loss: 0.9595588160066258
Validation loss: 2.848237782820023

Epoch: 5| Step: 3
Training loss: 0.9052163510393667
Validation loss: 2.7842806330943475

Epoch: 5| Step: 4
Training loss: 1.6039933528001376
Validation loss: 2.8495197486857995

Epoch: 5| Step: 5
Training loss: 0.7226854060709395
Validation loss: 2.842890606091273

Epoch: 5| Step: 6
Training loss: 1.1490803690359452
Validation loss: 2.824634857266775

Epoch: 5| Step: 7
Training loss: 0.9636009954109293
Validation loss: 2.859073386761408

Epoch: 5| Step: 8
Training loss: 0.8610231028125583
Validation loss: 2.811050119029445

Epoch: 5| Step: 9
Training loss: 1.0063083868680098
Validation loss: 2.849380023765277

Epoch: 5| Step: 10
Training loss: 0.9894718943975639
Validation loss: 2.8147717802227885

Epoch: 5| Step: 11
Training loss: 0.3101430462541824
Validation loss: 2.873088819939704

Epoch: 508| Step: 0
Training loss: 0.848694688233498
Validation loss: 2.7927421068831193

Epoch: 5| Step: 1
Training loss: 0.8281669606068622
Validation loss: 2.8292949322055634

Epoch: 5| Step: 2
Training loss: 1.0836732710061423
Validation loss: 2.836731810851809

Epoch: 5| Step: 3
Training loss: 0.7693862003778588
Validation loss: 2.7785060719905434

Epoch: 5| Step: 4
Training loss: 1.104147293112792
Validation loss: 2.8119866679760936

Epoch: 5| Step: 5
Training loss: 0.7839939757378401
Validation loss: 2.8282267374809416

Epoch: 5| Step: 6
Training loss: 0.7950287918059414
Validation loss: 2.8104960437213617

Epoch: 5| Step: 7
Training loss: 1.0045395571646591
Validation loss: 2.8095020351747646

Epoch: 5| Step: 8
Training loss: 0.9323574163740405
Validation loss: 2.782915127671874

Epoch: 5| Step: 9
Training loss: 1.402361856412749
Validation loss: 2.8382747711323297

Epoch: 5| Step: 10
Training loss: 0.9376294364585219
Validation loss: 2.84225833812234

Epoch: 5| Step: 11
Training loss: 1.1475772360445649
Validation loss: 2.8819049864420703

Epoch: 509| Step: 0
Training loss: 0.8647882073269728
Validation loss: 2.8221848490594197

Epoch: 5| Step: 1
Training loss: 1.0576116080942686
Validation loss: 2.782985195974949

Epoch: 5| Step: 2
Training loss: 0.8092081067257619
Validation loss: 2.7722599448918563

Epoch: 5| Step: 3
Training loss: 0.9976264979049283
Validation loss: 2.7784365128551975

Epoch: 5| Step: 4
Training loss: 0.9124003564959327
Validation loss: 2.752409529624045

Epoch: 5| Step: 5
Training loss: 0.9548998707312504
Validation loss: 2.784051298769145

Epoch: 5| Step: 6
Training loss: 1.240297907606244
Validation loss: 2.7976282195933218

Epoch: 5| Step: 7
Training loss: 1.1356277211334598
Validation loss: 2.801774257267278

Epoch: 5| Step: 8
Training loss: 1.4452290278894204
Validation loss: 2.9578729839962112

Epoch: 5| Step: 9
Training loss: 0.9671627700922627
Validation loss: 2.8647570343528215

Epoch: 5| Step: 10
Training loss: 1.0789072267388433
Validation loss: 2.8427282111587813

Epoch: 5| Step: 11
Training loss: 0.5671996512044069
Validation loss: 2.8310375741645557

Epoch: 510| Step: 0
Training loss: 0.9155548172961142
Validation loss: 2.777290586954421

Epoch: 5| Step: 1
Training loss: 1.0428625045552686
Validation loss: 2.76732564531418

Epoch: 5| Step: 2
Training loss: 0.9968403131554953
Validation loss: 2.764563027925143

Epoch: 5| Step: 3
Training loss: 1.1486858696206026
Validation loss: 2.752308198336668

Epoch: 5| Step: 4
Training loss: 0.7451972968358079
Validation loss: 2.7704431335551205

Epoch: 5| Step: 5
Training loss: 1.2744072340274437
Validation loss: 2.7140176517907677

Epoch: 5| Step: 6
Training loss: 1.508555016990872
Validation loss: 2.775129019112139

Epoch: 5| Step: 7
Training loss: 0.7791995415577528
Validation loss: 2.844740695047418

Epoch: 5| Step: 8
Training loss: 0.8108726122700287
Validation loss: 2.868412078535316

Epoch: 5| Step: 9
Training loss: 0.9693297527976024
Validation loss: 2.857438621723975

Epoch: 5| Step: 10
Training loss: 0.7315408926880751
Validation loss: 2.86328757139222

Epoch: 5| Step: 11
Training loss: 1.017979870235573
Validation loss: 2.8565653110088722

Epoch: 511| Step: 0
Training loss: 0.7499388828806888
Validation loss: 2.8432745972820523

Epoch: 5| Step: 1
Training loss: 0.8998789957611948
Validation loss: 2.837076769226551

Epoch: 5| Step: 2
Training loss: 1.363363881052602
Validation loss: 2.8570646356904796

Epoch: 5| Step: 3
Training loss: 1.48363396066307
Validation loss: 2.8747102308060586

Epoch: 5| Step: 4
Training loss: 1.0422388730405654
Validation loss: 2.815058688708914

Epoch: 5| Step: 5
Training loss: 1.0546531389078606
Validation loss: 2.837364377269043

Epoch: 5| Step: 6
Training loss: 0.8466013307843472
Validation loss: 2.866037389298177

Epoch: 5| Step: 7
Training loss: 0.8692877141381196
Validation loss: 2.8923899271459343

Epoch: 5| Step: 8
Training loss: 1.158140595727894
Validation loss: 2.8659873446280297

Epoch: 5| Step: 9
Training loss: 1.2207257810397538
Validation loss: 2.9273304455979705

Epoch: 5| Step: 10
Training loss: 1.5393030588590861
Validation loss: 2.895420811221482

Epoch: 5| Step: 11
Training loss: 0.5495347873204032
Validation loss: 2.8591484890353205

Epoch: 512| Step: 0
Training loss: 1.013878303339029
Validation loss: 2.8019399086267223

Epoch: 5| Step: 1
Training loss: 0.9062638446144977
Validation loss: 2.724818242862177

Epoch: 5| Step: 2
Training loss: 1.0162462535193195
Validation loss: 2.735874789231127

Epoch: 5| Step: 3
Training loss: 0.8540161899666889
Validation loss: 2.7058721265331305

Epoch: 5| Step: 4
Training loss: 0.9268111282946611
Validation loss: 2.7265814240390056

Epoch: 5| Step: 5
Training loss: 1.5840928196973263
Validation loss: 2.682759861993477

Epoch: 5| Step: 6
Training loss: 1.053395928643599
Validation loss: 2.7197456546389556

Epoch: 5| Step: 7
Training loss: 1.022869680585459
Validation loss: 2.724754491881487

Epoch: 5| Step: 8
Training loss: 1.153889488971448
Validation loss: 2.750615098105194

Epoch: 5| Step: 9
Training loss: 0.7578648421311323
Validation loss: 2.836382078802825

Epoch: 5| Step: 10
Training loss: 0.8913753761608468
Validation loss: 2.8149847957534746

Epoch: 5| Step: 11
Training loss: 0.8316586873685281
Validation loss: 2.899985113598993

Epoch: 513| Step: 0
Training loss: 0.6970167597461919
Validation loss: 2.9256988805797657

Epoch: 5| Step: 1
Training loss: 0.9087108874397837
Validation loss: 2.8288758055811507

Epoch: 5| Step: 2
Training loss: 1.1501292010996447
Validation loss: 2.9195036691763563

Epoch: 5| Step: 3
Training loss: 0.6864257786449998
Validation loss: 2.8058133075098795

Epoch: 5| Step: 4
Training loss: 1.2145279845008938
Validation loss: 2.844695108861622

Epoch: 5| Step: 5
Training loss: 0.6341812495619765
Validation loss: 2.8261417228252

Epoch: 5| Step: 6
Training loss: 0.9468859983504193
Validation loss: 2.7641505641217137

Epoch: 5| Step: 7
Training loss: 1.386596201464959
Validation loss: 2.8511317376285694

Epoch: 5| Step: 8
Training loss: 1.8589044183800774
Validation loss: 2.7976439713563104

Epoch: 5| Step: 9
Training loss: 1.1889802841656558
Validation loss: 2.794181130217554

Epoch: 5| Step: 10
Training loss: 1.1863304200965101
Validation loss: 2.800394429655537

Epoch: 5| Step: 11
Training loss: 1.0088716013433678
Validation loss: 2.8064078011214755

Epoch: 514| Step: 0
Training loss: 0.9819923811984083
Validation loss: 2.837975416953611

Epoch: 5| Step: 1
Training loss: 1.0297385033810569
Validation loss: 2.8693225924941257

Epoch: 5| Step: 2
Training loss: 1.5028894727654603
Validation loss: 2.896686803252447

Epoch: 5| Step: 3
Training loss: 0.8601591867228726
Validation loss: 2.889257767527161

Epoch: 5| Step: 4
Training loss: 1.0869510778000548
Validation loss: 2.8287092206091486

Epoch: 5| Step: 5
Training loss: 0.697747798436463
Validation loss: 2.822272432488456

Epoch: 5| Step: 6
Training loss: 1.189500128157145
Validation loss: 2.7915645137050653

Epoch: 5| Step: 7
Training loss: 0.758593992003413
Validation loss: 2.7595025126342154

Epoch: 5| Step: 8
Training loss: 0.9454475810742299
Validation loss: 2.79211196028742

Epoch: 5| Step: 9
Training loss: 1.1661133078292487
Validation loss: 2.7373176762207723

Epoch: 5| Step: 10
Training loss: 1.0226809202151683
Validation loss: 2.7762605617791185

Epoch: 5| Step: 11
Training loss: 1.1289651188796364
Validation loss: 2.7650740877576365

Epoch: 515| Step: 0
Training loss: 0.8253497639411288
Validation loss: 2.7279288685703804

Epoch: 5| Step: 1
Training loss: 1.0545474489261937
Validation loss: 2.7784520516339697

Epoch: 5| Step: 2
Training loss: 1.0356090203239732
Validation loss: 2.7742668899660696

Epoch: 5| Step: 3
Training loss: 0.6742825288984542
Validation loss: 2.80787290785166

Epoch: 5| Step: 4
Training loss: 1.357067034331372
Validation loss: 2.871205173328511

Epoch: 5| Step: 5
Training loss: 0.839907550606237
Validation loss: 2.871987122099729

Epoch: 5| Step: 6
Training loss: 0.8740115713667266
Validation loss: 2.9480330822786556

Epoch: 5| Step: 7
Training loss: 1.2747373908871222
Validation loss: 2.9168023702296293

Epoch: 5| Step: 8
Training loss: 0.9671411382998382
Validation loss: 2.8418378549529058

Epoch: 5| Step: 9
Training loss: 0.9274992634855158
Validation loss: 2.867151414330573

Epoch: 5| Step: 10
Training loss: 0.8468387722698356
Validation loss: 2.788711247912283

Epoch: 5| Step: 11
Training loss: 1.2364727978180343
Validation loss: 2.7424109459359407

Epoch: 516| Step: 0
Training loss: 0.7500557481391765
Validation loss: 2.771031940245149

Epoch: 5| Step: 1
Training loss: 0.763253411963565
Validation loss: 2.7531318531679956

Epoch: 5| Step: 2
Training loss: 1.0311590212369026
Validation loss: 2.751941032013089

Epoch: 5| Step: 3
Training loss: 1.0429300022428385
Validation loss: 2.756096432964231

Epoch: 5| Step: 4
Training loss: 1.114545566002157
Validation loss: 2.810645940509083

Epoch: 5| Step: 5
Training loss: 0.6776460045797986
Validation loss: 2.824745160820602

Epoch: 5| Step: 6
Training loss: 0.7244779565299646
Validation loss: 2.8463748967194418

Epoch: 5| Step: 7
Training loss: 0.6403314336506619
Validation loss: 2.779515239745164

Epoch: 5| Step: 8
Training loss: 1.3330606638732854
Validation loss: 2.8328012476376903

Epoch: 5| Step: 9
Training loss: 0.9248429384145834
Validation loss: 2.79250281299915

Epoch: 5| Step: 10
Training loss: 1.0621949487230262
Validation loss: 2.864429488241259

Epoch: 5| Step: 11
Training loss: 0.6889136908430656
Validation loss: 2.7610292198894406

Epoch: 517| Step: 0
Training loss: 1.0573114603128477
Validation loss: 2.778785449414083

Epoch: 5| Step: 1
Training loss: 1.286361314870723
Validation loss: 2.8251960438809687

Epoch: 5| Step: 2
Training loss: 1.001831047250537
Validation loss: 2.768051243420492

Epoch: 5| Step: 3
Training loss: 0.6142831624293313
Validation loss: 2.8285501346731574

Epoch: 5| Step: 4
Training loss: 0.9210692941979748
Validation loss: 2.780222320712023

Epoch: 5| Step: 5
Training loss: 0.8116356213237595
Validation loss: 2.7931608618619745

Epoch: 5| Step: 6
Training loss: 0.8297394544064052
Validation loss: 2.788738769777656

Epoch: 5| Step: 7
Training loss: 0.9007058739866312
Validation loss: 2.8243499064120385

Epoch: 5| Step: 8
Training loss: 1.0680898713506557
Validation loss: 2.8601801247717376

Epoch: 5| Step: 9
Training loss: 1.1528707559973383
Validation loss: 2.8350285561338335

Epoch: 5| Step: 10
Training loss: 1.0268094954491112
Validation loss: 2.792456996601406

Epoch: 5| Step: 11
Training loss: 0.7585862132836377
Validation loss: 2.8649952551861806

Epoch: 518| Step: 0
Training loss: 0.8231136995552177
Validation loss: 2.8266219259903362

Epoch: 5| Step: 1
Training loss: 0.9104176420181834
Validation loss: 2.7873224659480322

Epoch: 5| Step: 2
Training loss: 0.7629505858562762
Validation loss: 2.775128951097988

Epoch: 5| Step: 3
Training loss: 0.670229827121966
Validation loss: 2.825137979378639

Epoch: 5| Step: 4
Training loss: 1.0593595092901187
Validation loss: 2.811069644029282

Epoch: 5| Step: 5
Training loss: 1.0333591047785426
Validation loss: 2.823377537614003

Epoch: 5| Step: 6
Training loss: 1.1920748476172867
Validation loss: 2.8216605201060148

Epoch: 5| Step: 7
Training loss: 0.9966154938630443
Validation loss: 2.8331745654856877

Epoch: 5| Step: 8
Training loss: 0.8841261078762738
Validation loss: 2.83291030044465

Epoch: 5| Step: 9
Training loss: 0.9190049187587734
Validation loss: 2.8435115819064296

Epoch: 5| Step: 10
Training loss: 0.8417718091450109
Validation loss: 2.8447945182131362

Epoch: 5| Step: 11
Training loss: 2.2825012955761146
Validation loss: 2.849747408442732

Epoch: 519| Step: 0
Training loss: 1.0947495389189514
Validation loss: 2.7919740412770526

Epoch: 5| Step: 1
Training loss: 1.2735152893646324
Validation loss: 2.831111855185747

Epoch: 5| Step: 2
Training loss: 0.6452783358492085
Validation loss: 2.8076376457021848

Epoch: 5| Step: 3
Training loss: 0.7678718684295779
Validation loss: 2.792000872738701

Epoch: 5| Step: 4
Training loss: 0.8390499533171607
Validation loss: 2.837219939646033

Epoch: 5| Step: 5
Training loss: 1.0786705848043487
Validation loss: 2.746204632636277

Epoch: 5| Step: 6
Training loss: 0.8143865983536713
Validation loss: 2.8263119493916444

Epoch: 5| Step: 7
Training loss: 0.886155172044486
Validation loss: 2.7551540316523018

Epoch: 5| Step: 8
Training loss: 0.8704961257708127
Validation loss: 2.7323633005454924

Epoch: 5| Step: 9
Training loss: 1.3119644707369922
Validation loss: 2.735985762865593

Epoch: 5| Step: 10
Training loss: 1.1634908719133013
Validation loss: 2.7309880670086337

Epoch: 5| Step: 11
Training loss: 0.7004226464495297
Validation loss: 2.7500625155307823

Epoch: 520| Step: 0
Training loss: 1.1298499996923528
Validation loss: 2.8291653639200964

Epoch: 5| Step: 1
Training loss: 1.0721900232341521
Validation loss: 2.8201619369599134

Epoch: 5| Step: 2
Training loss: 1.1633321019542338
Validation loss: 2.762750870689987

Epoch: 5| Step: 3
Training loss: 0.9404051590332178
Validation loss: 2.7620379970691338

Epoch: 5| Step: 4
Training loss: 0.9324945339216537
Validation loss: 2.7730082112502674

Epoch: 5| Step: 5
Training loss: 0.9087457491999593
Validation loss: 2.769119845503521

Epoch: 5| Step: 6
Training loss: 1.0336712820394351
Validation loss: 2.8067745989964594

Epoch: 5| Step: 7
Training loss: 0.9831499924244609
Validation loss: 2.781048231628413

Epoch: 5| Step: 8
Training loss: 0.9138350244460413
Validation loss: 2.7717644852573162

Epoch: 5| Step: 9
Training loss: 0.9042646101598417
Validation loss: 2.7718228829468425

Epoch: 5| Step: 10
Training loss: 0.8469354403841419
Validation loss: 2.772850185765733

Epoch: 5| Step: 11
Training loss: 1.4606928493034064
Validation loss: 2.7663974724836553

Epoch: 521| Step: 0
Training loss: 1.2911894850015582
Validation loss: 2.8520165417255248

Epoch: 5| Step: 1
Training loss: 1.155536070352704
Validation loss: 2.8396339601372924

Epoch: 5| Step: 2
Training loss: 0.8577701148173733
Validation loss: 2.8467047993952055

Epoch: 5| Step: 3
Training loss: 0.8254599964978171
Validation loss: 2.870795374999073

Epoch: 5| Step: 4
Training loss: 1.099569587597511
Validation loss: 2.8831267112408754

Epoch: 5| Step: 5
Training loss: 0.5441397245882996
Validation loss: 2.823682777265458

Epoch: 5| Step: 6
Training loss: 1.1778606391394824
Validation loss: 2.814571659610765

Epoch: 5| Step: 7
Training loss: 0.932899184807875
Validation loss: 2.8580658213788754

Epoch: 5| Step: 8
Training loss: 0.8189862747556076
Validation loss: 2.8145656170535704

Epoch: 5| Step: 9
Training loss: 0.8575260733374538
Validation loss: 2.839671249082874

Epoch: 5| Step: 10
Training loss: 0.7719055957367493
Validation loss: 2.8747982873505658

Epoch: 5| Step: 11
Training loss: 0.8845871499030611
Validation loss: 2.792155067698084

Epoch: 522| Step: 0
Training loss: 0.8520639675398882
Validation loss: 2.9205653541570205

Epoch: 5| Step: 1
Training loss: 0.8651522560847288
Validation loss: 2.87054634325339

Epoch: 5| Step: 2
Training loss: 0.8561640313422119
Validation loss: 2.9036954091491363

Epoch: 5| Step: 3
Training loss: 1.1007658329920318
Validation loss: 2.9299445687997263

Epoch: 5| Step: 4
Training loss: 0.9389019973361472
Validation loss: 2.867059917885616

Epoch: 5| Step: 5
Training loss: 1.0844987078633048
Validation loss: 2.861891658695875

Epoch: 5| Step: 6
Training loss: 0.7766842368666623
Validation loss: 2.886330922202381

Epoch: 5| Step: 7
Training loss: 1.1194068365718761
Validation loss: 2.7785369234391877

Epoch: 5| Step: 8
Training loss: 0.9126777919897426
Validation loss: 2.800423628118219

Epoch: 5| Step: 9
Training loss: 0.6742345938473017
Validation loss: 2.8355967454439406

Epoch: 5| Step: 10
Training loss: 1.0592719013830068
Validation loss: 2.8136685522270715

Epoch: 5| Step: 11
Training loss: 0.8344687634193686
Validation loss: 2.7469820129762446

Epoch: 523| Step: 0
Training loss: 0.7426255389091053
Validation loss: 2.7926986279165416

Epoch: 5| Step: 1
Training loss: 1.0142161060487438
Validation loss: 2.8164181825876202

Epoch: 5| Step: 2
Training loss: 1.012628095082694
Validation loss: 2.8439226657023453

Epoch: 5| Step: 3
Training loss: 0.8981707633085458
Validation loss: 2.8413090517671176

Epoch: 5| Step: 4
Training loss: 0.747737212864731
Validation loss: 2.83269834532149

Epoch: 5| Step: 5
Training loss: 0.873889695489372
Validation loss: 2.7338872201997106

Epoch: 5| Step: 6
Training loss: 0.9493394625794948
Validation loss: 2.7907186234031194

Epoch: 5| Step: 7
Training loss: 1.0697098309133184
Validation loss: 2.791520318897257

Epoch: 5| Step: 8
Training loss: 1.027564079532647
Validation loss: 2.836469549567136

Epoch: 5| Step: 9
Training loss: 0.7100197454178364
Validation loss: 2.847230859422893

Epoch: 5| Step: 10
Training loss: 0.996244591156218
Validation loss: 2.945812644957791

Epoch: 5| Step: 11
Training loss: 1.369229519253311
Validation loss: 2.9559700698259994

Epoch: 524| Step: 0
Training loss: 0.8559115931478447
Validation loss: 2.935334273012912

Epoch: 5| Step: 1
Training loss: 1.0713181609076567
Validation loss: 2.9211599525607674

Epoch: 5| Step: 2
Training loss: 0.8971621874324754
Validation loss: 2.855607317733873

Epoch: 5| Step: 3
Training loss: 0.821567592496241
Validation loss: 2.819095493410142

Epoch: 5| Step: 4
Training loss: 0.8306022874010253
Validation loss: 2.848034275884948

Epoch: 5| Step: 5
Training loss: 0.8049741808381813
Validation loss: 2.84004127833429

Epoch: 5| Step: 6
Training loss: 0.8931681145952118
Validation loss: 2.844780658312776

Epoch: 5| Step: 7
Training loss: 0.6484232291983741
Validation loss: 2.8539350524724325

Epoch: 5| Step: 8
Training loss: 1.1525846585109443
Validation loss: 2.8701319876392324

Epoch: 5| Step: 9
Training loss: 1.0509009310836652
Validation loss: 2.834206854344554

Epoch: 5| Step: 10
Training loss: 1.0258747229656497
Validation loss: 2.899665092718523

Epoch: 5| Step: 11
Training loss: 0.588945171702561
Validation loss: 2.875666689626852

Epoch: 525| Step: 0
Training loss: 0.4637667256035666
Validation loss: 2.872491253362829

Epoch: 5| Step: 1
Training loss: 0.7711179998076692
Validation loss: 2.9002434381713766

Epoch: 5| Step: 2
Training loss: 0.902953565225291
Validation loss: 2.82794495882385

Epoch: 5| Step: 3
Training loss: 0.6806560061619711
Validation loss: 2.8623928272113024

Epoch: 5| Step: 4
Training loss: 1.0667957530789254
Validation loss: 2.8634953681160544

Epoch: 5| Step: 5
Training loss: 0.7964311373337559
Validation loss: 2.8298509435074477

Epoch: 5| Step: 6
Training loss: 0.8257603262828189
Validation loss: 2.8424508547217995

Epoch: 5| Step: 7
Training loss: 0.9130605439107632
Validation loss: 2.759223098145161

Epoch: 5| Step: 8
Training loss: 0.9758384156413742
Validation loss: 2.8413416267341414

Epoch: 5| Step: 9
Training loss: 0.8697310595992572
Validation loss: 2.7900166486712807

Epoch: 5| Step: 10
Training loss: 1.0931352249984658
Validation loss: 2.8655102126144154

Epoch: 5| Step: 11
Training loss: 1.9987488647992104
Validation loss: 2.8141589076027747

Epoch: 526| Step: 0
Training loss: 0.662812481367155
Validation loss: 2.9307431162995994

Epoch: 5| Step: 1
Training loss: 0.9468164381796066
Validation loss: 2.870970009280297

Epoch: 5| Step: 2
Training loss: 1.0089808352855423
Validation loss: 2.904188443562442

Epoch: 5| Step: 3
Training loss: 0.92484773980769
Validation loss: 2.90427832564395

Epoch: 5| Step: 4
Training loss: 0.7133388416651001
Validation loss: 2.8680219103081765

Epoch: 5| Step: 5
Training loss: 1.008125079273805
Validation loss: 2.9374665129896904

Epoch: 5| Step: 6
Training loss: 0.879355320117188
Validation loss: 2.849460921278222

Epoch: 5| Step: 7
Training loss: 1.1135971959503541
Validation loss: 2.8147499480346454

Epoch: 5| Step: 8
Training loss: 0.9052437424547485
Validation loss: 2.8377576824430726

Epoch: 5| Step: 9
Training loss: 0.7638194534263684
Validation loss: 2.864502944974295

Epoch: 5| Step: 10
Training loss: 0.9905363145474864
Validation loss: 2.8207047912595553

Epoch: 5| Step: 11
Training loss: 0.7312644663626898
Validation loss: 2.8388872210418303

Epoch: 527| Step: 0
Training loss: 0.8404541636171228
Validation loss: 2.834310472981301

Epoch: 5| Step: 1
Training loss: 0.960510903546284
Validation loss: 2.867939302173254

Epoch: 5| Step: 2
Training loss: 0.9798147444400337
Validation loss: 2.891326846585669

Epoch: 5| Step: 3
Training loss: 0.8286227403864002
Validation loss: 2.859641238187756

Epoch: 5| Step: 4
Training loss: 0.7196660216915932
Validation loss: 2.8431921785604906

Epoch: 5| Step: 5
Training loss: 0.958635752409819
Validation loss: 2.867050819014878

Epoch: 5| Step: 6
Training loss: 0.9077041403727815
Validation loss: 2.742403902171476

Epoch: 5| Step: 7
Training loss: 0.8251468802239568
Validation loss: 2.7393085622364537

Epoch: 5| Step: 8
Training loss: 1.1717298290615554
Validation loss: 2.7860863921635755

Epoch: 5| Step: 9
Training loss: 0.7767585583655191
Validation loss: 2.787558505380887

Epoch: 5| Step: 10
Training loss: 0.8316480085296905
Validation loss: 2.7882174860022135

Epoch: 5| Step: 11
Training loss: 0.9834891678020145
Validation loss: 2.783287359379552

Epoch: 528| Step: 0
Training loss: 0.6903277676691217
Validation loss: 2.82471331236022

Epoch: 5| Step: 1
Training loss: 0.6613646062893296
Validation loss: 2.809751661889903

Epoch: 5| Step: 2
Training loss: 0.8531047259705916
Validation loss: 2.8056362994748225

Epoch: 5| Step: 3
Training loss: 0.8460611902454916
Validation loss: 2.839861705780983

Epoch: 5| Step: 4
Training loss: 0.7312625101437652
Validation loss: 2.8740073335477034

Epoch: 5| Step: 5
Training loss: 1.093698173384978
Validation loss: 2.904462897235738

Epoch: 5| Step: 6
Training loss: 0.9804866530771009
Validation loss: 2.9046139846481034

Epoch: 5| Step: 7
Training loss: 0.8324376935811852
Validation loss: 2.894941337800383

Epoch: 5| Step: 8
Training loss: 0.7653421930648745
Validation loss: 2.872818724051048

Epoch: 5| Step: 9
Training loss: 1.0109921943219842
Validation loss: 2.8432612750230866

Epoch: 5| Step: 10
Training loss: 1.2251616818911257
Validation loss: 2.811949086097563

Epoch: 5| Step: 11
Training loss: 0.5348574507282172
Validation loss: 2.8004776822502695

Epoch: 529| Step: 0
Training loss: 0.7191702401995879
Validation loss: 2.8267840126953248

Epoch: 5| Step: 1
Training loss: 1.231811856103553
Validation loss: 2.756750448038527

Epoch: 5| Step: 2
Training loss: 0.9015353325993318
Validation loss: 2.7901555224965264

Epoch: 5| Step: 3
Training loss: 0.9124243639600024
Validation loss: 2.847963139550847

Epoch: 5| Step: 4
Training loss: 0.7867529656130375
Validation loss: 2.8337708946425813

Epoch: 5| Step: 5
Training loss: 0.86669921875
Validation loss: 2.973237684668667

Epoch: 5| Step: 6
Training loss: 0.9411776253179521
Validation loss: 2.964359818586638

Epoch: 5| Step: 7
Training loss: 0.8458708493286056
Validation loss: 2.9901787710968786

Epoch: 5| Step: 8
Training loss: 0.8904585766483087
Validation loss: 2.9128073170000595

Epoch: 5| Step: 9
Training loss: 0.8577494071729364
Validation loss: 2.8982510022590766

Epoch: 5| Step: 10
Training loss: 0.7083968573490312
Validation loss: 2.846006409998422

Epoch: 5| Step: 11
Training loss: 1.369627296052418
Validation loss: 2.8844231204409794

Epoch: 530| Step: 0
Training loss: 0.8931328116329581
Validation loss: 2.8219270778115826

Epoch: 5| Step: 1
Training loss: 0.9228172013278959
Validation loss: 2.83242624444098

Epoch: 5| Step: 2
Training loss: 1.175974123524112
Validation loss: 2.809276701155484

Epoch: 5| Step: 3
Training loss: 1.1825121983388907
Validation loss: 2.8626695945007703

Epoch: 5| Step: 4
Training loss: 0.5663547887115215
Validation loss: 2.8278334767691993

Epoch: 5| Step: 5
Training loss: 0.7317382470383809
Validation loss: 2.847367441666021

Epoch: 5| Step: 6
Training loss: 0.7958299478655269
Validation loss: 2.8880748050050595

Epoch: 5| Step: 7
Training loss: 0.6633506325242355
Validation loss: 2.9032929358553337

Epoch: 5| Step: 8
Training loss: 0.8406143556509446
Validation loss: 2.8474163133996355

Epoch: 5| Step: 9
Training loss: 0.8234680517562194
Validation loss: 2.9278248337573993

Epoch: 5| Step: 10
Training loss: 0.8189345275620006
Validation loss: 2.9113900762937988

Epoch: 5| Step: 11
Training loss: 0.9564560387734191
Validation loss: 2.8776205876544982

Epoch: 531| Step: 0
Training loss: 1.0933461124751067
Validation loss: 2.902638354950881

Epoch: 5| Step: 1
Training loss: 0.9606820984390047
Validation loss: 2.9245361340693217

Epoch: 5| Step: 2
Training loss: 0.8598748574027337
Validation loss: 2.9036283905919507

Epoch: 5| Step: 3
Training loss: 0.764250865098478
Validation loss: 2.8998021411813917

Epoch: 5| Step: 4
Training loss: 0.7869878253843331
Validation loss: 2.857423627204905

Epoch: 5| Step: 5
Training loss: 0.8968472546263373
Validation loss: 2.773796994904387

Epoch: 5| Step: 6
Training loss: 0.7879595838411125
Validation loss: 2.816151519698158

Epoch: 5| Step: 7
Training loss: 1.0860308600163147
Validation loss: 2.830369525840504

Epoch: 5| Step: 8
Training loss: 0.9776439324679544
Validation loss: 2.7891469207154373

Epoch: 5| Step: 9
Training loss: 0.8194058448694775
Validation loss: 2.8312375344176743

Epoch: 5| Step: 10
Training loss: 1.0360451390658056
Validation loss: 2.8321641877641928

Epoch: 5| Step: 11
Training loss: 0.8910877297278497
Validation loss: 2.89565633443281

Epoch: 532| Step: 0
Training loss: 0.879982962714342
Validation loss: 3.023320043813973

Epoch: 5| Step: 1
Training loss: 1.0887351464923707
Validation loss: 3.0545584674975332

Epoch: 5| Step: 2
Training loss: 1.2006554959031877
Validation loss: 3.0781073142122923

Epoch: 5| Step: 3
Training loss: 1.3433556088824334
Validation loss: 3.0676363961939317

Epoch: 5| Step: 4
Training loss: 0.7188408006450789
Validation loss: 2.9260552264875224

Epoch: 5| Step: 5
Training loss: 1.0236640854068741
Validation loss: 2.8966379362879326

Epoch: 5| Step: 6
Training loss: 0.8442476712218189
Validation loss: 2.7973235674548373

Epoch: 5| Step: 7
Training loss: 0.9449333502461804
Validation loss: 2.8254283180853537

Epoch: 5| Step: 8
Training loss: 0.8735752768176122
Validation loss: 2.792444381751948

Epoch: 5| Step: 9
Training loss: 1.3597893357504112
Validation loss: 2.8326747680554796

Epoch: 5| Step: 10
Training loss: 0.9556112849047838
Validation loss: 2.8547362202490696

Epoch: 5| Step: 11
Training loss: 1.7918777637174308
Validation loss: 2.856304396063362

Epoch: 533| Step: 0
Training loss: 1.027145018411398
Validation loss: 2.990193418840668

Epoch: 5| Step: 1
Training loss: 1.0367462614501188
Validation loss: 2.9760181433193407

Epoch: 5| Step: 2
Training loss: 1.173268316392967
Validation loss: 3.003007487294605

Epoch: 5| Step: 3
Training loss: 0.8292405154698141
Validation loss: 2.956255086527475

Epoch: 5| Step: 4
Training loss: 0.9669034032219089
Validation loss: 2.8924325223342318

Epoch: 5| Step: 5
Training loss: 1.0400400367696434
Validation loss: 2.882847610852527

Epoch: 5| Step: 6
Training loss: 0.7152549519852459
Validation loss: 2.8149154569251955

Epoch: 5| Step: 7
Training loss: 0.9223777240775501
Validation loss: 2.8110659864152012

Epoch: 5| Step: 8
Training loss: 0.7797687220648079
Validation loss: 2.784539024582345

Epoch: 5| Step: 9
Training loss: 1.193366467443889
Validation loss: 2.832094076928605

Epoch: 5| Step: 10
Training loss: 1.2488798367625518
Validation loss: 2.7874494388368296

Epoch: 5| Step: 11
Training loss: 0.9217366906848456
Validation loss: 2.8265960065782743

Epoch: 534| Step: 0
Training loss: 0.9585751594662114
Validation loss: 2.833313364538247

Epoch: 5| Step: 1
Training loss: 0.7429812553628912
Validation loss: 2.8642108027661286

Epoch: 5| Step: 2
Training loss: 1.0042942944749094
Validation loss: 2.9335947083303595

Epoch: 5| Step: 3
Training loss: 0.9737476522199463
Validation loss: 2.9341805383816064

Epoch: 5| Step: 4
Training loss: 1.0183778281930533
Validation loss: 2.8583518283920335

Epoch: 5| Step: 5
Training loss: 0.9378253690045741
Validation loss: 2.9419125293903976

Epoch: 5| Step: 6
Training loss: 0.8900375771358402
Validation loss: 2.8499673222458646

Epoch: 5| Step: 7
Training loss: 0.7101827115037876
Validation loss: 2.8542500063755374

Epoch: 5| Step: 8
Training loss: 0.9515839610318345
Validation loss: 2.8269848922835874

Epoch: 5| Step: 9
Training loss: 1.2773338107501062
Validation loss: 2.8426941493989695

Epoch: 5| Step: 10
Training loss: 0.9717678317629073
Validation loss: 2.84491790292122

Epoch: 5| Step: 11
Training loss: 1.1605656989852284
Validation loss: 2.86709636158795

Epoch: 535| Step: 0
Training loss: 0.8036287991162036
Validation loss: 2.8532395156379833

Epoch: 5| Step: 1
Training loss: 1.3011425536077743
Validation loss: 2.8853318492298867

Epoch: 5| Step: 2
Training loss: 0.8168207603840768
Validation loss: 2.9357318358824336

Epoch: 5| Step: 3
Training loss: 1.0700434882693879
Validation loss: 2.9260129781647275

Epoch: 5| Step: 4
Training loss: 0.9297237549452477
Validation loss: 2.8486170288248487

Epoch: 5| Step: 5
Training loss: 1.0054555730541659
Validation loss: 2.823203333883442

Epoch: 5| Step: 6
Training loss: 0.8058490702589228
Validation loss: 2.763731698151435

Epoch: 5| Step: 7
Training loss: 0.7970533732320431
Validation loss: 2.7937242708721097

Epoch: 5| Step: 8
Training loss: 1.3114251322201043
Validation loss: 2.820836530136108

Epoch: 5| Step: 9
Training loss: 0.8028925162145826
Validation loss: 2.8092057255945635

Epoch: 5| Step: 10
Training loss: 0.858179648229735
Validation loss: 2.858168880905194

Epoch: 5| Step: 11
Training loss: 1.4754069009518915
Validation loss: 2.909998264334075

Epoch: 536| Step: 0
Training loss: 1.0147609850205963
Validation loss: 2.968045730041019

Epoch: 5| Step: 1
Training loss: 1.2151528115583787
Validation loss: 2.967088850302206

Epoch: 5| Step: 2
Training loss: 1.0163611458484052
Validation loss: 2.9996848801839424

Epoch: 5| Step: 3
Training loss: 0.6974380664606065
Validation loss: 2.9577417129077213

Epoch: 5| Step: 4
Training loss: 0.5969816402219205
Validation loss: 2.9298175562495214

Epoch: 5| Step: 5
Training loss: 1.238521901521857
Validation loss: 2.9509847040106374

Epoch: 5| Step: 6
Training loss: 0.7238365226377873
Validation loss: 2.9658542932986465

Epoch: 5| Step: 7
Training loss: 1.016949889854929
Validation loss: 2.9383741052221883

Epoch: 5| Step: 8
Training loss: 1.1269311754016311
Validation loss: 2.907565622373641

Epoch: 5| Step: 9
Training loss: 0.915350308404188
Validation loss: 2.9166195570456352

Epoch: 5| Step: 10
Training loss: 0.8420009144485836
Validation loss: 2.9530755531705952

Epoch: 5| Step: 11
Training loss: 0.498894213762141
Validation loss: 2.9040009262939073

Epoch: 537| Step: 0
Training loss: 0.9369286385540126
Validation loss: 2.9304914058174623

Epoch: 5| Step: 1
Training loss: 0.9513886065764987
Validation loss: 2.9846938630302073

Epoch: 5| Step: 2
Training loss: 0.7549766097329748
Validation loss: 2.9487279218273277

Epoch: 5| Step: 3
Training loss: 0.7601013226477888
Validation loss: 2.9219928656483787

Epoch: 5| Step: 4
Training loss: 0.935628071170269
Validation loss: 2.922049505289169

Epoch: 5| Step: 5
Training loss: 0.7852191804936378
Validation loss: 2.850233421470864

Epoch: 5| Step: 6
Training loss: 0.6945381996656702
Validation loss: 2.83883856640956

Epoch: 5| Step: 7
Training loss: 1.0414780382394686
Validation loss: 2.816309432977101

Epoch: 5| Step: 8
Training loss: 1.0890040837606287
Validation loss: 2.823301508432142

Epoch: 5| Step: 9
Training loss: 0.9639008273638299
Validation loss: 2.7539607951216274

Epoch: 5| Step: 10
Training loss: 0.6516549591401435
Validation loss: 2.7589952708009418

Epoch: 5| Step: 11
Training loss: 0.9934352328264706
Validation loss: 2.8656279283437187

Epoch: 538| Step: 0
Training loss: 0.6612695189193011
Validation loss: 2.8200232057146435

Epoch: 5| Step: 1
Training loss: 0.6788791804738956
Validation loss: 2.85411961834595

Epoch: 5| Step: 2
Training loss: 0.7569386664781519
Validation loss: 2.8193417478492058

Epoch: 5| Step: 3
Training loss: 1.0071484055892868
Validation loss: 2.960118746727585

Epoch: 5| Step: 4
Training loss: 0.8567758963917451
Validation loss: 2.9608494721196585

Epoch: 5| Step: 5
Training loss: 0.805482971184263
Validation loss: 2.993379894811671

Epoch: 5| Step: 6
Training loss: 0.8444462481975811
Validation loss: 2.9967278278320144

Epoch: 5| Step: 7
Training loss: 0.5900463741471992
Validation loss: 2.9702790522142815

Epoch: 5| Step: 8
Training loss: 1.3883458437514327
Validation loss: 2.8841173411658243

Epoch: 5| Step: 9
Training loss: 0.9921484211111748
Validation loss: 2.8506040817577176

Epoch: 5| Step: 10
Training loss: 1.0385934445027911
Validation loss: 2.8500685170509445

Epoch: 5| Step: 11
Training loss: 0.3202869125939066
Validation loss: 2.8763532356260058

Epoch: 539| Step: 0
Training loss: 0.8960829690086807
Validation loss: 2.873781056390477

Epoch: 5| Step: 1
Training loss: 0.6829650167355757
Validation loss: 2.88212267057751

Epoch: 5| Step: 2
Training loss: 1.0668279910778973
Validation loss: 2.8851409096356924

Epoch: 5| Step: 3
Training loss: 0.7272792275365861
Validation loss: 2.8223799245671914

Epoch: 5| Step: 4
Training loss: 0.7457991412830192
Validation loss: 2.852902523446036

Epoch: 5| Step: 5
Training loss: 0.7567769082952952
Validation loss: 2.8887035410265014

Epoch: 5| Step: 6
Training loss: 0.856983881069904
Validation loss: 2.9079926403725174

Epoch: 5| Step: 7
Training loss: 0.9029839296611304
Validation loss: 2.9078262764701575

Epoch: 5| Step: 8
Training loss: 0.8403067089035892
Validation loss: 2.8568539649368683

Epoch: 5| Step: 9
Training loss: 0.8170413964335118
Validation loss: 2.847423182867197

Epoch: 5| Step: 10
Training loss: 0.7170595524502141
Validation loss: 2.8827717510262167

Epoch: 5| Step: 11
Training loss: 0.7616299308443192
Validation loss: 2.846392341885938

Epoch: 540| Step: 0
Training loss: 0.9542085085916245
Validation loss: 2.8324602736055002

Epoch: 5| Step: 1
Training loss: 0.6000885927836587
Validation loss: 2.853871366209513

Epoch: 5| Step: 2
Training loss: 0.8510088039171407
Validation loss: 2.851391035524991

Epoch: 5| Step: 3
Training loss: 0.759363887061918
Validation loss: 2.8836432813153965

Epoch: 5| Step: 4
Training loss: 1.018658670181408
Validation loss: 2.8764408032646207

Epoch: 5| Step: 5
Training loss: 0.8326236961731368
Validation loss: 2.883579532888307

Epoch: 5| Step: 6
Training loss: 1.0680675491587786
Validation loss: 2.9736227234751196

Epoch: 5| Step: 7
Training loss: 1.1689637707724478
Validation loss: 2.968700974042878

Epoch: 5| Step: 8
Training loss: 1.0328921334965655
Validation loss: 3.0071739113381835

Epoch: 5| Step: 9
Training loss: 0.9661699824986708
Validation loss: 2.9392351409756285

Epoch: 5| Step: 10
Training loss: 0.7910455768707243
Validation loss: 2.951363685849358

Epoch: 5| Step: 11
Training loss: 1.622441551907331
Validation loss: 2.919728298000883

Epoch: 541| Step: 0
Training loss: 0.7898228447295451
Validation loss: 2.8596451810614445

Epoch: 5| Step: 1
Training loss: 1.291860330071134
Validation loss: 2.775352651366264

Epoch: 5| Step: 2
Training loss: 1.2446340783042793
Validation loss: 2.8086983736842495

Epoch: 5| Step: 3
Training loss: 1.0901910918831106
Validation loss: 2.755144754312

Epoch: 5| Step: 4
Training loss: 1.098929810116165
Validation loss: 2.767055195553959

Epoch: 5| Step: 5
Training loss: 1.2402938227786249
Validation loss: 2.7233578376842646

Epoch: 5| Step: 6
Training loss: 0.8912353097633234
Validation loss: 2.8322974770474554

Epoch: 5| Step: 7
Training loss: 0.7017721725170993
Validation loss: 2.923744161381735

Epoch: 5| Step: 8
Training loss: 1.0948885849659633
Validation loss: 2.929845186864204

Epoch: 5| Step: 9
Training loss: 1.0023325894954227
Validation loss: 2.9322599993136924

Epoch: 5| Step: 10
Training loss: 0.8646560699629249
Validation loss: 2.9452949746012704

Epoch: 5| Step: 11
Training loss: 1.0756459690601319
Validation loss: 2.888604504442523

Epoch: 542| Step: 0
Training loss: 0.8226600117973256
Validation loss: 2.9031605929467323

Epoch: 5| Step: 1
Training loss: 0.7645184051912817
Validation loss: 2.8213198475155594

Epoch: 5| Step: 2
Training loss: 0.9603576771679383
Validation loss: 2.813971911378513

Epoch: 5| Step: 3
Training loss: 1.0237138098536955
Validation loss: 2.8218917616652286

Epoch: 5| Step: 4
Training loss: 0.8353356663794892
Validation loss: 2.853863457540715

Epoch: 5| Step: 5
Training loss: 0.7219538806572419
Validation loss: 2.8443583232558676

Epoch: 5| Step: 6
Training loss: 1.0788423114589452
Validation loss: 2.8338720017633623

Epoch: 5| Step: 7
Training loss: 1.0174523566899092
Validation loss: 2.8378959177890684

Epoch: 5| Step: 8
Training loss: 0.882045649097585
Validation loss: 2.8755540970339295

Epoch: 5| Step: 9
Training loss: 0.7328613183652308
Validation loss: 2.9363836778070795

Epoch: 5| Step: 10
Training loss: 0.902146949609924
Validation loss: 2.960927558956049

Epoch: 5| Step: 11
Training loss: 0.5950853740525557
Validation loss: 2.947299513001605

Epoch: 543| Step: 0
Training loss: 0.6611221064682575
Validation loss: 2.9742670194067244

Epoch: 5| Step: 1
Training loss: 0.8052902926786606
Validation loss: 2.9238299936999117

Epoch: 5| Step: 2
Training loss: 0.8629519149406268
Validation loss: 2.9784878188539414

Epoch: 5| Step: 3
Training loss: 0.9240212107655544
Validation loss: 2.9235798321125697

Epoch: 5| Step: 4
Training loss: 0.9969513137450579
Validation loss: 2.895643273755702

Epoch: 5| Step: 5
Training loss: 0.8106847071368305
Validation loss: 2.9412474874379537

Epoch: 5| Step: 6
Training loss: 0.8725402864265798
Validation loss: 2.9024212066596777

Epoch: 5| Step: 7
Training loss: 0.7566931411408117
Validation loss: 2.837327306592547

Epoch: 5| Step: 8
Training loss: 0.896625582475844
Validation loss: 2.828482967013095

Epoch: 5| Step: 9
Training loss: 0.5948355939670201
Validation loss: 2.8656250510290286

Epoch: 5| Step: 10
Training loss: 1.0756574394658585
Validation loss: 2.8110773091007455

Epoch: 5| Step: 11
Training loss: 0.9085133340662188
Validation loss: 2.845298471264346

Epoch: 544| Step: 0
Training loss: 0.7131132849383814
Validation loss: 2.859315065544426

Epoch: 5| Step: 1
Training loss: 0.6380295396068064
Validation loss: 2.8113100996274847

Epoch: 5| Step: 2
Training loss: 0.8436223039424319
Validation loss: 2.8923902568643634

Epoch: 5| Step: 3
Training loss: 0.7970931932511182
Validation loss: 2.9314857423359615

Epoch: 5| Step: 4
Training loss: 0.7220923208112849
Validation loss: 2.8998347133910394

Epoch: 5| Step: 5
Training loss: 1.0178277410596457
Validation loss: 2.9530027926016595

Epoch: 5| Step: 6
Training loss: 0.8350637272255526
Validation loss: 2.8990852543832006

Epoch: 5| Step: 7
Training loss: 1.0403322764677208
Validation loss: 2.8695183997139564

Epoch: 5| Step: 8
Training loss: 0.7640271543350671
Validation loss: 2.9212562463465344

Epoch: 5| Step: 9
Training loss: 0.7202089677991235
Validation loss: 2.9131668187012307

Epoch: 5| Step: 10
Training loss: 1.0137692443300457
Validation loss: 2.8454312151199317

Epoch: 5| Step: 11
Training loss: 0.9048014277535463
Validation loss: 2.8792222814437705

Epoch: 545| Step: 0
Training loss: 0.7520696376353092
Validation loss: 2.870508479455498

Epoch: 5| Step: 1
Training loss: 0.6957472609967383
Validation loss: 2.863298552262651

Epoch: 5| Step: 2
Training loss: 0.6233879758051549
Validation loss: 2.867795957609254

Epoch: 5| Step: 3
Training loss: 0.9557109210830591
Validation loss: 2.858310796734091

Epoch: 5| Step: 4
Training loss: 0.8502865602797904
Validation loss: 2.8644461697193524

Epoch: 5| Step: 5
Training loss: 0.7937184815644586
Validation loss: 2.8291990302645433

Epoch: 5| Step: 6
Training loss: 0.7999213090580346
Validation loss: 2.836747088089841

Epoch: 5| Step: 7
Training loss: 0.825549384905979
Validation loss: 2.9042980379650847

Epoch: 5| Step: 8
Training loss: 0.8242874840013529
Validation loss: 2.9121503104307633

Epoch: 5| Step: 9
Training loss: 0.7637453556075662
Validation loss: 2.9038530740495134

Epoch: 5| Step: 10
Training loss: 0.9409132176879597
Validation loss: 2.9330193862742573

Epoch: 5| Step: 11
Training loss: 0.9607142057180751
Validation loss: 2.9292666120195685

Epoch: 546| Step: 0
Training loss: 0.6757047532726106
Validation loss: 2.817696581314785

Epoch: 5| Step: 1
Training loss: 0.612953414277851
Validation loss: 2.866526937313702

Epoch: 5| Step: 2
Training loss: 0.8355759525099273
Validation loss: 2.908745944959226

Epoch: 5| Step: 3
Training loss: 1.0542100744143474
Validation loss: 2.9130520675315124

Epoch: 5| Step: 4
Training loss: 0.8030335919799215
Validation loss: 2.940071505603646

Epoch: 5| Step: 5
Training loss: 0.8364497959054396
Validation loss: 2.8707248130647303

Epoch: 5| Step: 6
Training loss: 0.8654388806047004
Validation loss: 2.865653154989892

Epoch: 5| Step: 7
Training loss: 0.7571237324538256
Validation loss: 2.8867757100777682

Epoch: 5| Step: 8
Training loss: 0.7809534272901048
Validation loss: 2.8852671654504647

Epoch: 5| Step: 9
Training loss: 0.791157085814993
Validation loss: 2.890853137387131

Epoch: 5| Step: 10
Training loss: 0.8917206165594308
Validation loss: 2.9829208799281717

Epoch: 5| Step: 11
Training loss: 0.7850363720528252
Validation loss: 2.876140938224236

Epoch: 547| Step: 0
Training loss: 0.5828876978656655
Validation loss: 2.9276490643342132

Epoch: 5| Step: 1
Training loss: 0.7551478701536388
Validation loss: 2.860349162630268

Epoch: 5| Step: 2
Training loss: 0.8760119444847101
Validation loss: 2.8933810936117936

Epoch: 5| Step: 3
Training loss: 0.8790132245554266
Validation loss: 2.9097622256891373

Epoch: 5| Step: 4
Training loss: 0.8304972947849997
Validation loss: 2.847750710593855

Epoch: 5| Step: 5
Training loss: 0.8582883032927886
Validation loss: 2.879669333318023

Epoch: 5| Step: 6
Training loss: 0.8917986849324946
Validation loss: 2.8852834286322304

Epoch: 5| Step: 7
Training loss: 0.8956818489512391
Validation loss: 2.9484823726547393

Epoch: 5| Step: 8
Training loss: 0.7307086897301355
Validation loss: 2.92457572707398

Epoch: 5| Step: 9
Training loss: 0.7688106512939514
Validation loss: 2.863301189053072

Epoch: 5| Step: 10
Training loss: 0.7233120803376915
Validation loss: 2.894407756194197

Epoch: 5| Step: 11
Training loss: 0.775512032408741
Validation loss: 2.844153330220532

Epoch: 548| Step: 0
Training loss: 0.7411086824872348
Validation loss: 2.8733709702733656

Epoch: 5| Step: 1
Training loss: 0.7019314702620508
Validation loss: 2.9389754675052955

Epoch: 5| Step: 2
Training loss: 0.6786929779969848
Validation loss: 2.885072251477918

Epoch: 5| Step: 3
Training loss: 1.033323111534834
Validation loss: 2.853356933358745

Epoch: 5| Step: 4
Training loss: 0.5286739385741311
Validation loss: 2.860981422224665

Epoch: 5| Step: 5
Training loss: 0.8306360860275659
Validation loss: 2.842105421377432

Epoch: 5| Step: 6
Training loss: 0.8281613827756447
Validation loss: 2.8575948270447347

Epoch: 5| Step: 7
Training loss: 0.8889265429117778
Validation loss: 2.926179683024589

Epoch: 5| Step: 8
Training loss: 0.8577768203736048
Validation loss: 2.8203794589420013

Epoch: 5| Step: 9
Training loss: 0.7220098130148382
Validation loss: 2.8467491634346787

Epoch: 5| Step: 10
Training loss: 0.5306455595618758
Validation loss: 2.8269748210579575

Epoch: 5| Step: 11
Training loss: 0.9461261935857158
Validation loss: 2.8857214464882714

Epoch: 549| Step: 0
Training loss: 0.44911826295203156
Validation loss: 2.900301610606095

Epoch: 5| Step: 1
Training loss: 0.6864446429294565
Validation loss: 2.91350518386652

Epoch: 5| Step: 2
Training loss: 0.6934394252934316
Validation loss: 2.880065015339356

Epoch: 5| Step: 3
Training loss: 0.7713061549364116
Validation loss: 2.8575361450180976

Epoch: 5| Step: 4
Training loss: 0.675123787938008
Validation loss: 2.9045741605816757

Epoch: 5| Step: 5
Training loss: 0.6061151561020305
Validation loss: 2.9350384584763347

Epoch: 5| Step: 6
Training loss: 0.7754182594429178
Validation loss: 2.919899519172405

Epoch: 5| Step: 7
Training loss: 0.9166747367388057
Validation loss: 2.930371000455795

Epoch: 5| Step: 8
Training loss: 0.9308900828865208
Validation loss: 2.91958312724422

Epoch: 5| Step: 9
Training loss: 0.5896118415527187
Validation loss: 2.948240384815967

Epoch: 5| Step: 10
Training loss: 0.6168813308189987
Validation loss: 2.8696412406493166

Epoch: 5| Step: 11
Training loss: 0.34293889673948674
Validation loss: 2.818313841475074

Epoch: 550| Step: 0
Training loss: 0.6007071023929178
Validation loss: 2.921024093212307

Epoch: 5| Step: 1
Training loss: 0.8329547896509618
Validation loss: 2.87546635383653

Epoch: 5| Step: 2
Training loss: 0.6683151729911648
Validation loss: 2.8582433396306888

Epoch: 5| Step: 3
Training loss: 0.6693677695958624
Validation loss: 2.9097111781924068

Epoch: 5| Step: 4
Training loss: 0.6122607104313637
Validation loss: 2.8798402904063147

Epoch: 5| Step: 5
Training loss: 0.7977252612771554
Validation loss: 2.925092105828161

Epoch: 5| Step: 6
Training loss: 0.7743765399785159
Validation loss: 2.955791544431085

Epoch: 5| Step: 7
Training loss: 0.9514199937869904
Validation loss: 2.979885159174219

Epoch: 5| Step: 8
Training loss: 0.9344786277131321
Validation loss: 2.9561917731402616

Epoch: 5| Step: 9
Training loss: 0.6731249471184472
Validation loss: 2.8815642241383967

Epoch: 5| Step: 10
Training loss: 0.8474996747379185
Validation loss: 2.8864010441157575

Epoch: 5| Step: 11
Training loss: 0.4528734232248332
Validation loss: 2.852436778197902

Testing loss: 2.39055298262547
