Epoch: 1| Step: 0
Training loss: 5.792287349700928
Validation loss: 5.258459349473317

Epoch: 5| Step: 1
Training loss: 5.045128345489502
Validation loss: 5.2567907472451525

Epoch: 5| Step: 2
Training loss: 5.878988742828369
Validation loss: 5.255095859368642

Epoch: 5| Step: 3
Training loss: 6.026574611663818
Validation loss: 5.253304084142049

Epoch: 5| Step: 4
Training loss: 5.204535007476807
Validation loss: 5.251608033974965

Epoch: 5| Step: 5
Training loss: 4.350330352783203
Validation loss: 5.249800324440002

Epoch: 5| Step: 6
Training loss: 5.295771598815918
Validation loss: 5.248129606246948

Epoch: 5| Step: 7
Training loss: 4.950242519378662
Validation loss: 5.246303200721741

Epoch: 5| Step: 8
Training loss: 6.3776655197143555
Validation loss: 5.244493464628856

Epoch: 5| Step: 9
Training loss: 4.222466468811035
Validation loss: 5.242633819580078

Epoch: 5| Step: 10
Training loss: 5.038682460784912
Validation loss: 5.24074649810791

Epoch: 5| Step: 11
Training loss: 6.955854892730713
Validation loss: 5.238810996214549

Epoch: 2| Step: 0
Training loss: 4.74025821685791
Validation loss: 5.236774345239003

Epoch: 5| Step: 1
Training loss: 6.163434028625488
Validation loss: 5.234588344891866

Epoch: 5| Step: 2
Training loss: 3.5736184120178223
Validation loss: 5.232405285040538

Epoch: 5| Step: 3
Training loss: 4.687409400939941
Validation loss: 5.230096836884816

Epoch: 5| Step: 4
Training loss: 4.702976226806641
Validation loss: 5.227672696113586

Epoch: 5| Step: 5
Training loss: 5.157186985015869
Validation loss: 5.225226918856303

Epoch: 5| Step: 6
Training loss: 5.7415571212768555
Validation loss: 5.2223765552043915

Epoch: 5| Step: 7
Training loss: 6.553829193115234
Validation loss: 5.219487289587657

Epoch: 5| Step: 8
Training loss: 5.730140686035156
Validation loss: 5.216405789057414

Epoch: 5| Step: 9
Training loss: 5.056222438812256
Validation loss: 5.213143150011699

Epoch: 5| Step: 10
Training loss: 5.758735656738281
Validation loss: 5.209804991881053

Epoch: 5| Step: 11
Training loss: 7.1210174560546875
Validation loss: 5.206376294294993

Epoch: 3| Step: 0
Training loss: 4.974592685699463
Validation loss: 5.20248144865036

Epoch: 5| Step: 1
Training loss: 5.392873287200928
Validation loss: 5.198681811491649

Epoch: 5| Step: 2
Training loss: 4.940438747406006
Validation loss: 5.194570640722911

Epoch: 5| Step: 3
Training loss: 6.30337381362915
Validation loss: 5.190112451712291

Epoch: 5| Step: 4
Training loss: 5.964571475982666
Validation loss: 5.1855937242507935

Epoch: 5| Step: 5
Training loss: 4.494950294494629
Validation loss: 5.180716514587402

Epoch: 5| Step: 6
Training loss: 5.671746253967285
Validation loss: 5.175378680229187

Epoch: 5| Step: 7
Training loss: 5.490782260894775
Validation loss: 5.17028288046519

Epoch: 5| Step: 8
Training loss: 4.661032676696777
Validation loss: 5.164497911930084

Epoch: 5| Step: 9
Training loss: 5.296424388885498
Validation loss: 5.158648312091827

Epoch: 5| Step: 10
Training loss: 4.962069034576416
Validation loss: 5.152374068895976

Epoch: 5| Step: 11
Training loss: 3.211000442504883
Validation loss: 5.145638525485992

Epoch: 4| Step: 0
Training loss: 4.885288238525391
Validation loss: 5.138872007528941

Epoch: 5| Step: 1
Training loss: 4.654463291168213
Validation loss: 5.131923496723175

Epoch: 5| Step: 2
Training loss: 4.854921817779541
Validation loss: 5.1242749492327375

Epoch: 5| Step: 3
Training loss: 5.28124475479126
Validation loss: 5.116414884726207

Epoch: 5| Step: 4
Training loss: 5.2896928787231445
Validation loss: 5.108126282691956

Epoch: 5| Step: 5
Training loss: 5.6363525390625
Validation loss: 5.099697748819987

Epoch: 5| Step: 6
Training loss: 5.988951206207275
Validation loss: 5.090845604737599

Epoch: 5| Step: 7
Training loss: 5.461208820343018
Validation loss: 5.081841588020325

Epoch: 5| Step: 8
Training loss: 4.108795642852783
Validation loss: 5.072680771350861

Epoch: 5| Step: 9
Training loss: 5.233494281768799
Validation loss: 5.062748809655507

Epoch: 5| Step: 10
Training loss: 5.417605876922607
Validation loss: 5.052795330683391

Epoch: 5| Step: 11
Training loss: 5.485740661621094
Validation loss: 5.043084839979808

Epoch: 5| Step: 0
Training loss: 4.92932653427124
Validation loss: 5.032598912715912

Epoch: 5| Step: 1
Training loss: 4.942965984344482
Validation loss: 5.0218291481335955

Epoch: 5| Step: 2
Training loss: 4.91496467590332
Validation loss: 5.011480927467346

Epoch: 5| Step: 3
Training loss: 4.593429088592529
Validation loss: 5.000677525997162

Epoch: 5| Step: 4
Training loss: 4.678310394287109
Validation loss: 4.989820301532745

Epoch: 5| Step: 5
Training loss: 4.794087886810303
Validation loss: 4.979325691858928

Epoch: 5| Step: 6
Training loss: 5.577056407928467
Validation loss: 4.968387166659038

Epoch: 5| Step: 7
Training loss: 4.601699352264404
Validation loss: 4.9576897621154785

Epoch: 5| Step: 8
Training loss: 5.7285566329956055
Validation loss: 4.94697231054306

Epoch: 5| Step: 9
Training loss: 5.615131378173828
Validation loss: 4.9361313581466675

Epoch: 5| Step: 10
Training loss: 5.318772315979004
Validation loss: 4.925197581450145

Epoch: 5| Step: 11
Training loss: 4.801413059234619
Validation loss: 4.914616306622823

Epoch: 6| Step: 0
Training loss: 5.110304832458496
Validation loss: 4.903932531674703

Epoch: 5| Step: 1
Training loss: 5.758923530578613
Validation loss: 4.893461505572001

Epoch: 5| Step: 2
Training loss: 5.029903411865234
Validation loss: 4.88292811314265

Epoch: 5| Step: 3
Training loss: 5.7409443855285645
Validation loss: 4.872161487738292

Epoch: 5| Step: 4
Training loss: 4.5951313972473145
Validation loss: 4.861567636330922

Epoch: 5| Step: 5
Training loss: 4.188361167907715
Validation loss: 4.850282549858093

Epoch: 5| Step: 6
Training loss: 5.510979175567627
Validation loss: 4.839754402637482

Epoch: 5| Step: 7
Training loss: 4.851778984069824
Validation loss: 4.829300979773204

Epoch: 5| Step: 8
Training loss: 4.611698627471924
Validation loss: 4.818767646948497

Epoch: 5| Step: 9
Training loss: 4.5719404220581055
Validation loss: 4.808233221371968

Epoch: 5| Step: 10
Training loss: 4.382245063781738
Validation loss: 4.797863662242889

Epoch: 5| Step: 11
Training loss: 4.743800640106201
Validation loss: 4.787994623184204

Epoch: 7| Step: 0
Training loss: 4.975320816040039
Validation loss: 4.777550309896469

Epoch: 5| Step: 1
Training loss: 5.683571815490723
Validation loss: 4.7677827676137285

Epoch: 5| Step: 2
Training loss: 5.1546502113342285
Validation loss: 4.757634560267131

Epoch: 5| Step: 3
Training loss: 4.089957237243652
Validation loss: 4.747724413871765

Epoch: 5| Step: 4
Training loss: 5.254881858825684
Validation loss: 4.737850924332936

Epoch: 5| Step: 5
Training loss: 4.468705177307129
Validation loss: 4.728071570396423

Epoch: 5| Step: 6
Training loss: 4.535377502441406
Validation loss: 4.718483328819275

Epoch: 5| Step: 7
Training loss: 3.644577741622925
Validation loss: 4.708508392175038

Epoch: 5| Step: 8
Training loss: 4.195825099945068
Validation loss: 4.699255873759587

Epoch: 5| Step: 9
Training loss: 4.871874809265137
Validation loss: 4.689810951550801

Epoch: 5| Step: 10
Training loss: 6.047589302062988
Validation loss: 4.680213312307994

Epoch: 5| Step: 11
Training loss: 5.28739070892334
Validation loss: 4.671132524808248

Epoch: 8| Step: 0
Training loss: 4.890261650085449
Validation loss: 4.661705156167348

Epoch: 5| Step: 1
Training loss: 4.303536891937256
Validation loss: 4.6521599888801575

Epoch: 5| Step: 2
Training loss: 3.979802370071411
Validation loss: 4.643098811308543

Epoch: 5| Step: 3
Training loss: 5.120570182800293
Validation loss: 4.63396938641866

Epoch: 5| Step: 4
Training loss: 4.894771575927734
Validation loss: 4.624271094799042

Epoch: 5| Step: 5
Training loss: 5.006606578826904
Validation loss: 4.615149994691213

Epoch: 5| Step: 6
Training loss: 4.039342403411865
Validation loss: 4.606303691864014

Epoch: 5| Step: 7
Training loss: 5.152959823608398
Validation loss: 4.596917192141215

Epoch: 5| Step: 8
Training loss: 5.230864524841309
Validation loss: 4.5875614285469055

Epoch: 5| Step: 9
Training loss: 3.6253037452697754
Validation loss: 4.577769796053569

Epoch: 5| Step: 10
Training loss: 5.7487711906433105
Validation loss: 4.568830529848735

Epoch: 5| Step: 11
Training loss: 3.919548749923706
Validation loss: 4.559581647316615

Epoch: 9| Step: 0
Training loss: 4.929902076721191
Validation loss: 4.549886325995128

Epoch: 5| Step: 1
Training loss: 5.9553632736206055
Validation loss: 4.540554980436961

Epoch: 5| Step: 2
Training loss: 4.314062595367432
Validation loss: 4.5309116542339325

Epoch: 5| Step: 3
Training loss: 3.7851309776306152
Validation loss: 4.5212202072143555

Epoch: 5| Step: 4
Training loss: 4.132228374481201
Validation loss: 4.510948300361633

Epoch: 5| Step: 5
Training loss: 3.9759323596954346
Validation loss: 4.50163459777832

Epoch: 5| Step: 6
Training loss: 5.115644931793213
Validation loss: 4.492055942614873

Epoch: 5| Step: 7
Training loss: 4.652529716491699
Validation loss: 4.48282265663147

Epoch: 5| Step: 8
Training loss: 4.456521034240723
Validation loss: 4.472570796807607

Epoch: 5| Step: 9
Training loss: 4.727336883544922
Validation loss: 4.463254739840825

Epoch: 5| Step: 10
Training loss: 4.916708469390869
Validation loss: 4.454318513472875

Epoch: 5| Step: 11
Training loss: 3.197664737701416
Validation loss: 4.445081532001495

Epoch: 10| Step: 0
Training loss: 5.218993663787842
Validation loss: 4.4366379380226135

Epoch: 5| Step: 1
Training loss: 3.7727673053741455
Validation loss: 4.427948673566182

Epoch: 5| Step: 2
Training loss: 4.927454948425293
Validation loss: 4.4195208350817365

Epoch: 5| Step: 3
Training loss: 4.701085567474365
Validation loss: 4.410928706328074

Epoch: 5| Step: 4
Training loss: 4.458244323730469
Validation loss: 4.402557760477066

Epoch: 5| Step: 5
Training loss: 5.457700252532959
Validation loss: 4.393638650576274

Epoch: 5| Step: 6
Training loss: 4.902454376220703
Validation loss: 4.385070323944092

Epoch: 5| Step: 7
Training loss: 4.924025535583496
Validation loss: 4.3773051997025805

Epoch: 5| Step: 8
Training loss: 3.188096284866333
Validation loss: 4.369741241137187

Epoch: 5| Step: 9
Training loss: 4.3292236328125
Validation loss: 4.362067520618439

Epoch: 5| Step: 10
Training loss: 3.5493712425231934
Validation loss: 4.354928861061732

Epoch: 5| Step: 11
Training loss: 5.538867950439453
Validation loss: 4.348056395848592

Epoch: 11| Step: 0
Training loss: 5.260268211364746
Validation loss: 4.3415983120600385

Epoch: 5| Step: 1
Training loss: 3.625342845916748
Validation loss: 4.335658381382625

Epoch: 5| Step: 2
Training loss: 4.4778733253479
Validation loss: 4.329823434352875

Epoch: 5| Step: 3
Training loss: 3.9136557579040527
Validation loss: 4.3238358994325

Epoch: 5| Step: 4
Training loss: 4.870847225189209
Validation loss: 4.317740986744563

Epoch: 5| Step: 5
Training loss: 4.137868404388428
Validation loss: 4.3115140199661255

Epoch: 5| Step: 6
Training loss: 4.507248878479004
Validation loss: 4.304401050011317

Epoch: 5| Step: 7
Training loss: 4.240610599517822
Validation loss: 4.298187295595805

Epoch: 5| Step: 8
Training loss: 4.697449684143066
Validation loss: 4.292021572589874

Epoch: 5| Step: 9
Training loss: 3.639634609222412
Validation loss: 4.285805900891622

Epoch: 5| Step: 10
Training loss: 5.673618316650391
Validation loss: 4.279726058244705

Epoch: 5| Step: 11
Training loss: 3.159424304962158
Validation loss: 4.273964107036591

Epoch: 12| Step: 0
Training loss: 4.95071268081665
Validation loss: 4.2679252823193865

Epoch: 5| Step: 1
Training loss: 4.42215633392334
Validation loss: 4.261963446935018

Epoch: 5| Step: 2
Training loss: 4.637266159057617
Validation loss: 4.255466749270757

Epoch: 5| Step: 3
Training loss: 3.998922348022461
Validation loss: 4.249898264805476

Epoch: 5| Step: 4
Training loss: 4.553980827331543
Validation loss: 4.24430775642395

Epoch: 5| Step: 5
Training loss: 3.9773898124694824
Validation loss: 4.2381075620651245

Epoch: 5| Step: 6
Training loss: 3.5406253337860107
Validation loss: 4.232370585203171

Epoch: 5| Step: 7
Training loss: 4.882277011871338
Validation loss: 4.226957003275554

Epoch: 5| Step: 8
Training loss: 3.939307451248169
Validation loss: 4.2214439908663435

Epoch: 5| Step: 9
Training loss: 4.8262457847595215
Validation loss: 4.2153655886650085

Epoch: 5| Step: 10
Training loss: 4.542160987854004
Validation loss: 4.209803183873494

Epoch: 5| Step: 11
Training loss: 3.3181564807891846
Validation loss: 4.204926351706187

Epoch: 13| Step: 0
Training loss: 4.291055202484131
Validation loss: 4.202818661928177

Epoch: 5| Step: 1
Training loss: 3.567134141921997
Validation loss: 4.198057532310486

Epoch: 5| Step: 2
Training loss: 4.045774459838867
Validation loss: 4.1893204053243

Epoch: 5| Step: 3
Training loss: 4.379574775695801
Validation loss: 4.1827205916245775

Epoch: 5| Step: 4
Training loss: 4.2446184158325195
Validation loss: 4.178051739931107

Epoch: 5| Step: 5
Training loss: 4.007531642913818
Validation loss: 4.1729516585667925

Epoch: 5| Step: 6
Training loss: 4.474185943603516
Validation loss: 4.1688538789749146

Epoch: 5| Step: 7
Training loss: 4.9109883308410645
Validation loss: 4.163103292385737

Epoch: 5| Step: 8
Training loss: 4.026291847229004
Validation loss: 4.157822032769521

Epoch: 5| Step: 9
Training loss: 4.566577911376953
Validation loss: 4.152026732762654

Epoch: 5| Step: 10
Training loss: 4.969074726104736
Validation loss: 4.14720219373703

Epoch: 5| Step: 11
Training loss: 3.9642953872680664
Validation loss: 4.142534653345744

Epoch: 14| Step: 0
Training loss: 3.3099656105041504
Validation loss: 4.138971904913585

Epoch: 5| Step: 1
Training loss: 4.8441033363342285
Validation loss: 4.132738649845123

Epoch: 5| Step: 2
Training loss: 3.390200138092041
Validation loss: 4.1267379721005755

Epoch: 5| Step: 3
Training loss: 4.088189125061035
Validation loss: 4.1217913428942365

Epoch: 5| Step: 4
Training loss: 4.765571594238281
Validation loss: 4.117411941289902

Epoch: 5| Step: 5
Training loss: 3.9251015186309814
Validation loss: 4.11172150572141

Epoch: 5| Step: 6
Training loss: 5.463125228881836
Validation loss: 4.106374988953273

Epoch: 5| Step: 7
Training loss: 4.881131172180176
Validation loss: 4.1009441415468855

Epoch: 5| Step: 8
Training loss: 4.360030174255371
Validation loss: 4.096266855796178

Epoch: 5| Step: 9
Training loss: 4.133160591125488
Validation loss: 4.090556204319

Epoch: 5| Step: 10
Training loss: 4.109460830688477
Validation loss: 4.084771593411763

Epoch: 5| Step: 11
Training loss: 1.843425989151001
Validation loss: 4.079961498578389

Epoch: 15| Step: 0
Training loss: 3.507770538330078
Validation loss: 4.075214982032776

Epoch: 5| Step: 1
Training loss: 3.6111977100372314
Validation loss: 4.070243418216705

Epoch: 5| Step: 2
Training loss: 4.742367744445801
Validation loss: 4.0652129252751665

Epoch: 5| Step: 3
Training loss: 3.506760358810425
Validation loss: 4.059754361708959

Epoch: 5| Step: 4
Training loss: 4.136504173278809
Validation loss: 4.054122964541118

Epoch: 5| Step: 5
Training loss: 5.5224609375
Validation loss: 4.0489604870478315

Epoch: 5| Step: 6
Training loss: 4.251086235046387
Validation loss: 4.044524470965068

Epoch: 5| Step: 7
Training loss: 4.608512878417969
Validation loss: 4.039190222819646

Epoch: 5| Step: 8
Training loss: 4.132019996643066
Validation loss: 4.033843368291855

Epoch: 5| Step: 9
Training loss: 4.873150825500488
Validation loss: 4.02766998608907

Epoch: 5| Step: 10
Training loss: 3.64404559135437
Validation loss: 4.023837208747864

Epoch: 5| Step: 11
Training loss: 2.172821283340454
Validation loss: 4.018287032842636

Epoch: 16| Step: 0
Training loss: 4.379467010498047
Validation loss: 4.013658821582794

Epoch: 5| Step: 1
Training loss: 4.332479000091553
Validation loss: 4.008529037237167

Epoch: 5| Step: 2
Training loss: 3.439317226409912
Validation loss: 4.003189106782277

Epoch: 5| Step: 3
Training loss: 3.7897868156433105
Validation loss: 3.997501313686371

Epoch: 5| Step: 4
Training loss: 4.048895835876465
Validation loss: 3.991828978061676

Epoch: 5| Step: 5
Training loss: 4.384186744689941
Validation loss: 3.987573762734731

Epoch: 5| Step: 6
Training loss: 4.358928680419922
Validation loss: 3.983811527490616

Epoch: 5| Step: 7
Training loss: 3.6773135662078857
Validation loss: 3.976755460103353

Epoch: 5| Step: 8
Training loss: 3.9418957233428955
Validation loss: 3.9702327450116477

Epoch: 5| Step: 9
Training loss: 4.006970405578613
Validation loss: 3.9654612044493356

Epoch: 5| Step: 10
Training loss: 4.6275954246521
Validation loss: 3.960753470659256

Epoch: 5| Step: 11
Training loss: 6.610864639282227
Validation loss: 3.9560170272986093

Epoch: 17| Step: 0
Training loss: 3.7869155406951904
Validation loss: 3.95130862792333

Epoch: 5| Step: 1
Training loss: 3.6607131958007812
Validation loss: 3.94613254070282

Epoch: 5| Step: 2
Training loss: 4.692195415496826
Validation loss: 3.9406508008639016

Epoch: 5| Step: 3
Training loss: 4.229502201080322
Validation loss: 3.9358633756637573

Epoch: 5| Step: 4
Training loss: 3.675053834915161
Validation loss: 3.9303408364454904

Epoch: 5| Step: 5
Training loss: 3.265611171722412
Validation loss: 3.9257587095101676

Epoch: 5| Step: 6
Training loss: 4.181002616882324
Validation loss: 3.9185474812984467

Epoch: 5| Step: 7
Training loss: 4.683270454406738
Validation loss: 3.914031912883123

Epoch: 5| Step: 8
Training loss: 4.978449821472168
Validation loss: 3.9089657366275787

Epoch: 5| Step: 9
Training loss: 3.94868803024292
Validation loss: 3.9041490952173867

Epoch: 5| Step: 10
Training loss: 3.6385796070098877
Validation loss: 3.8989077707131705

Epoch: 5| Step: 11
Training loss: 4.436450958251953
Validation loss: 3.893982102473577

Epoch: 18| Step: 0
Training loss: 4.12813663482666
Validation loss: 3.8885222375392914

Epoch: 5| Step: 1
Training loss: 3.370527744293213
Validation loss: 3.8834159870942435

Epoch: 5| Step: 2
Training loss: 4.3069047927856445
Validation loss: 3.8792977035045624

Epoch: 5| Step: 3
Training loss: 3.022209644317627
Validation loss: 3.8722875813643136

Epoch: 5| Step: 4
Training loss: 3.261488437652588
Validation loss: 3.8670184214909873

Epoch: 5| Step: 5
Training loss: 3.666996717453003
Validation loss: 3.8622197012106576

Epoch: 5| Step: 6
Training loss: 3.809286594390869
Validation loss: 3.857662538687388

Epoch: 5| Step: 7
Training loss: 4.805769443511963
Validation loss: 3.8527980148792267

Epoch: 5| Step: 8
Training loss: 5.053248405456543
Validation loss: 3.8471348583698273

Epoch: 5| Step: 9
Training loss: 4.665220737457275
Validation loss: 3.8414778212706246

Epoch: 5| Step: 10
Training loss: 4.170861721038818
Validation loss: 3.835866997639338

Epoch: 5| Step: 11
Training loss: 3.4848718643188477
Validation loss: 3.8310047388076782

Epoch: 19| Step: 0
Training loss: 4.656688690185547
Validation loss: 3.8260336220264435

Epoch: 5| Step: 1
Training loss: 3.331993579864502
Validation loss: 3.822279284397761

Epoch: 5| Step: 2
Training loss: 3.3108153343200684
Validation loss: 3.816340684890747

Epoch: 5| Step: 3
Training loss: 4.2798261642456055
Validation loss: 3.8107860883076987

Epoch: 5| Step: 4
Training loss: 4.616422653198242
Validation loss: 3.806121031443278

Epoch: 5| Step: 5
Training loss: 4.049233913421631
Validation loss: 3.801081657409668

Epoch: 5| Step: 6
Training loss: 3.846059799194336
Validation loss: 3.7959814965724945

Epoch: 5| Step: 7
Training loss: 4.7482805252075195
Validation loss: 3.791838506857554

Epoch: 5| Step: 8
Training loss: 3.737971544265747
Validation loss: 3.785868306954702

Epoch: 5| Step: 9
Training loss: 4.150900840759277
Validation loss: 3.779740661382675

Epoch: 5| Step: 10
Training loss: 2.6379923820495605
Validation loss: 3.7752667168776193

Epoch: 5| Step: 11
Training loss: 4.798370838165283
Validation loss: 3.769880563020706

Epoch: 20| Step: 0
Training loss: 4.117136478424072
Validation loss: 3.765458901723226

Epoch: 5| Step: 1
Training loss: 4.584155082702637
Validation loss: 3.7613907555739083

Epoch: 5| Step: 2
Training loss: 3.2248635292053223
Validation loss: 3.7542799611886344

Epoch: 5| Step: 3
Training loss: 3.6315505504608154
Validation loss: 3.7497014701366425

Epoch: 5| Step: 4
Training loss: 2.9039244651794434
Validation loss: 3.7453572154045105

Epoch: 5| Step: 5
Training loss: 4.666991233825684
Validation loss: 3.7414327263832092

Epoch: 5| Step: 6
Training loss: 4.627448081970215
Validation loss: 3.7369244595368705

Epoch: 5| Step: 7
Training loss: 3.4342103004455566
Validation loss: 3.731071263551712

Epoch: 5| Step: 8
Training loss: 4.413212299346924
Validation loss: 3.725642681121826

Epoch: 5| Step: 9
Training loss: 3.665264844894409
Validation loss: 3.7202923397223153

Epoch: 5| Step: 10
Training loss: 3.9352850914001465
Validation loss: 3.7153243521849313

Epoch: 5| Step: 11
Training loss: 2.4114012718200684
Validation loss: 3.7114071547985077

Epoch: 21| Step: 0
Training loss: 4.146560192108154
Validation loss: 3.714857429265976

Epoch: 5| Step: 1
Training loss: 4.040297508239746
Validation loss: 3.703614354133606

Epoch: 5| Step: 2
Training loss: 2.9109206199645996
Validation loss: 3.6971522668997445

Epoch: 5| Step: 3
Training loss: 4.148463249206543
Validation loss: 3.6936522920926413

Epoch: 5| Step: 4
Training loss: 3.7564525604248047
Validation loss: 3.6929392317930856

Epoch: 5| Step: 5
Training loss: 3.7578799724578857
Validation loss: 3.68914928038915

Epoch: 5| Step: 6
Training loss: 4.241246223449707
Validation loss: 3.6857226490974426

Epoch: 5| Step: 7
Training loss: 3.290435791015625
Validation loss: 3.678724338610967

Epoch: 5| Step: 8
Training loss: 3.6749138832092285
Validation loss: 3.6736369033654532

Epoch: 5| Step: 9
Training loss: 4.223979473114014
Validation loss: 3.668320526679357

Epoch: 5| Step: 10
Training loss: 4.314682960510254
Validation loss: 3.6633611619472504

Epoch: 5| Step: 11
Training loss: 3.0166029930114746
Validation loss: 3.658660044272741

Epoch: 22| Step: 0
Training loss: 3.290776491165161
Validation loss: 3.654915362596512

Epoch: 5| Step: 1
Training loss: 4.287163734436035
Validation loss: 3.650677373011907

Epoch: 5| Step: 2
Training loss: 3.816539764404297
Validation loss: 3.6445132394631705

Epoch: 5| Step: 3
Training loss: 4.277483940124512
Validation loss: 3.638652741909027

Epoch: 5| Step: 4
Training loss: 3.1017234325408936
Validation loss: 3.6347974141438804

Epoch: 5| Step: 5
Training loss: 4.114056587219238
Validation loss: 3.6299892365932465

Epoch: 5| Step: 6
Training loss: 4.349432945251465
Validation loss: 3.6257815758387246

Epoch: 5| Step: 7
Training loss: 3.969589948654175
Validation loss: 3.6194557547569275

Epoch: 5| Step: 8
Training loss: 2.749659776687622
Validation loss: 3.6151223480701447

Epoch: 5| Step: 9
Training loss: 4.020404815673828
Validation loss: 3.611182530721029

Epoch: 5| Step: 10
Training loss: 3.658064365386963
Validation loss: 3.6052549878756204

Epoch: 5| Step: 11
Training loss: 4.2333173751831055
Validation loss: 3.599713842074076

Epoch: 23| Step: 0
Training loss: 3.797916889190674
Validation loss: 3.5955856442451477

Epoch: 5| Step: 1
Training loss: 3.4473156929016113
Validation loss: 3.5911643902460733

Epoch: 5| Step: 2
Training loss: 3.703413486480713
Validation loss: 3.5861703753471375

Epoch: 5| Step: 3
Training loss: 3.059152364730835
Validation loss: 3.5815592110157013

Epoch: 5| Step: 4
Training loss: 4.207607269287109
Validation loss: 3.577022284269333

Epoch: 5| Step: 5
Training loss: 4.403858184814453
Validation loss: 3.572863588730494

Epoch: 5| Step: 6
Training loss: 3.8218376636505127
Validation loss: 3.566226293643316

Epoch: 5| Step: 7
Training loss: 4.120582103729248
Validation loss: 3.560436596473058

Epoch: 5| Step: 8
Training loss: 4.466921329498291
Validation loss: 3.5559148291746774

Epoch: 5| Step: 9
Training loss: 2.834517002105713
Validation loss: 3.5520830949147544

Epoch: 5| Step: 10
Training loss: 3.682534694671631
Validation loss: 3.547839949528376

Epoch: 5| Step: 11
Training loss: 1.4778486490249634
Validation loss: 3.5415346324443817

Epoch: 24| Step: 0
Training loss: 3.0836684703826904
Validation loss: 3.537195165952047

Epoch: 5| Step: 1
Training loss: 3.2673346996307373
Validation loss: 3.531820386648178

Epoch: 5| Step: 2
Training loss: 3.7678050994873047
Validation loss: 3.527686377366384

Epoch: 5| Step: 3
Training loss: 4.261080265045166
Validation loss: 3.521953205267588

Epoch: 5| Step: 4
Training loss: 3.9151809215545654
Validation loss: 3.5173925161361694

Epoch: 5| Step: 5
Training loss: 3.979998826980591
Validation loss: 3.512650022904078

Epoch: 5| Step: 6
Training loss: 3.6245930194854736
Validation loss: 3.5071550210316977

Epoch: 5| Step: 7
Training loss: 3.6699516773223877
Validation loss: 3.5023647248744965

Epoch: 5| Step: 8
Training loss: 3.5550103187561035
Validation loss: 3.496949851512909

Epoch: 5| Step: 9
Training loss: 3.4964396953582764
Validation loss: 3.4928638339042664

Epoch: 5| Step: 10
Training loss: 3.65250825881958
Validation loss: 3.4880273838837943

Epoch: 5| Step: 11
Training loss: 4.6714582443237305
Validation loss: 3.483186533053716

Epoch: 25| Step: 0
Training loss: 3.2918853759765625
Validation loss: 3.4783563812573752

Epoch: 5| Step: 1
Training loss: 3.407870054244995
Validation loss: 3.473964273929596

Epoch: 5| Step: 2
Training loss: 3.521087646484375
Validation loss: 3.4689992566903434

Epoch: 5| Step: 3
Training loss: 3.341531276702881
Validation loss: 3.464812139670054

Epoch: 5| Step: 4
Training loss: 3.9395694732666016
Validation loss: 3.4597613414128623

Epoch: 5| Step: 5
Training loss: 3.466585159301758
Validation loss: 3.455179284016291

Epoch: 5| Step: 6
Training loss: 4.417031288146973
Validation loss: 3.450185696283976

Epoch: 5| Step: 7
Training loss: 3.826819896697998
Validation loss: 3.445300579071045

Epoch: 5| Step: 8
Training loss: 3.2056655883789062
Validation loss: 3.440594047307968

Epoch: 5| Step: 9
Training loss: 4.490630149841309
Validation loss: 3.436413119236628

Epoch: 5| Step: 10
Training loss: 3.189757823944092
Validation loss: 3.4318228562672934

Epoch: 5| Step: 11
Training loss: 2.2687594890594482
Validation loss: 3.427255163590113

Epoch: 26| Step: 0
Training loss: 3.353119373321533
Validation loss: 3.424851566553116

Epoch: 5| Step: 1
Training loss: 3.590552806854248
Validation loss: 3.434345861275991

Epoch: 5| Step: 2
Training loss: 4.009390830993652
Validation loss: 3.417145073413849

Epoch: 5| Step: 3
Training loss: 3.682575225830078
Validation loss: 3.4079050521055856

Epoch: 5| Step: 4
Training loss: 3.0229554176330566
Validation loss: 3.404254823923111

Epoch: 5| Step: 5
Training loss: 4.1333746910095215
Validation loss: 3.4016291300455728

Epoch: 5| Step: 6
Training loss: 2.9679651260375977
Validation loss: 3.398927648862203

Epoch: 5| Step: 7
Training loss: 3.027310371398926
Validation loss: 3.395672619342804

Epoch: 5| Step: 8
Training loss: 4.044580459594727
Validation loss: 3.3891414801279702

Epoch: 5| Step: 9
Training loss: 4.112750053405762
Validation loss: 3.383547027905782

Epoch: 5| Step: 10
Training loss: 3.2072837352752686
Validation loss: 3.3774326145648956

Epoch: 5| Step: 11
Training loss: 4.1520843505859375
Validation loss: 3.372324585914612

Epoch: 27| Step: 0
Training loss: 4.112843036651611
Validation loss: 3.3681027392546334

Epoch: 5| Step: 1
Training loss: 3.618588924407959
Validation loss: 3.3625095983346305

Epoch: 5| Step: 2
Training loss: 4.374756813049316
Validation loss: 3.356767922639847

Epoch: 5| Step: 3
Training loss: 2.6683971881866455
Validation loss: 3.3494795163472495

Epoch: 5| Step: 4
Training loss: 3.6097171306610107
Validation loss: 3.343567738930384

Epoch: 5| Step: 5
Training loss: 2.8517894744873047
Validation loss: 3.337662547826767

Epoch: 5| Step: 6
Training loss: 3.713139772415161
Validation loss: 3.33335879445076

Epoch: 5| Step: 7
Training loss: 3.3511109352111816
Validation loss: 3.3291493952274323

Epoch: 5| Step: 8
Training loss: 3.267002582550049
Validation loss: 3.3233097891012826

Epoch: 5| Step: 9
Training loss: 3.979583263397217
Validation loss: 3.3194214502970376

Epoch: 5| Step: 10
Training loss: 3.133972644805908
Validation loss: 3.3139313459396362

Epoch: 5| Step: 11
Training loss: 3.262892246246338
Validation loss: 3.3091019888718924

Epoch: 28| Step: 0
Training loss: 4.643082141876221
Validation loss: 3.3037595053513846

Epoch: 5| Step: 1
Training loss: 3.343740463256836
Validation loss: 3.2988475461800895

Epoch: 5| Step: 2
Training loss: 4.402132034301758
Validation loss: 3.294250011444092

Epoch: 5| Step: 3
Training loss: 2.5990684032440186
Validation loss: 3.289813299973806

Epoch: 5| Step: 4
Training loss: 3.4673218727111816
Validation loss: 3.2846768697102866

Epoch: 5| Step: 5
Training loss: 3.4131405353546143
Validation loss: 3.280527561903

Epoch: 5| Step: 6
Training loss: 3.0694518089294434
Validation loss: 3.275405834118525

Epoch: 5| Step: 7
Training loss: 2.591531276702881
Validation loss: 3.2709874510765076

Epoch: 5| Step: 8
Training loss: 3.5296578407287598
Validation loss: 3.2663006683190665

Epoch: 5| Step: 9
Training loss: 4.045633792877197
Validation loss: 3.262541949748993

Epoch: 5| Step: 10
Training loss: 2.984816789627075
Validation loss: 3.2572316924730935

Epoch: 5| Step: 11
Training loss: 3.1386613845825195
Validation loss: 3.2536313235759735

Epoch: 29| Step: 0
Training loss: 2.915257215499878
Validation loss: 3.2484462559223175

Epoch: 5| Step: 1
Training loss: 3.142550230026245
Validation loss: 3.2446987132231393

Epoch: 5| Step: 2
Training loss: 3.2627453804016113
Validation loss: 3.2403616309165955

Epoch: 5| Step: 3
Training loss: 4.270452976226807
Validation loss: 3.2365434964497886

Epoch: 5| Step: 4
Training loss: 3.3951568603515625
Validation loss: 3.2321004072825112

Epoch: 5| Step: 5
Training loss: 3.905095338821411
Validation loss: 3.227258195479711

Epoch: 5| Step: 6
Training loss: 2.9911985397338867
Validation loss: 3.2224441468715668

Epoch: 5| Step: 7
Training loss: 3.217360734939575
Validation loss: 3.2181913753350577

Epoch: 5| Step: 8
Training loss: 3.5818400382995605
Validation loss: 3.2136584520339966

Epoch: 5| Step: 9
Training loss: 3.5133814811706543
Validation loss: 3.2093314627806344

Epoch: 5| Step: 10
Training loss: 3.2830467224121094
Validation loss: 3.2048382659753165

Epoch: 5| Step: 11
Training loss: 3.2696619033813477
Validation loss: 3.2010957101980844

Epoch: 30| Step: 0
Training loss: 3.3797199726104736
Validation loss: 3.1959140400091806

Epoch: 5| Step: 1
Training loss: 3.2790799140930176
Validation loss: 3.191400110721588

Epoch: 5| Step: 2
Training loss: 3.4369189739227295
Validation loss: 3.1875641345977783

Epoch: 5| Step: 3
Training loss: 3.4424099922180176
Validation loss: 3.182737171649933

Epoch: 5| Step: 4
Training loss: 3.6341488361358643
Validation loss: 3.1789661745230355

Epoch: 5| Step: 5
Training loss: 2.9491593837738037
Validation loss: 3.174805055061976

Epoch: 5| Step: 6
Training loss: 3.062589168548584
Validation loss: 3.1705840031305947

Epoch: 5| Step: 7
Training loss: 3.1850085258483887
Validation loss: 3.1664456824461618

Epoch: 5| Step: 8
Training loss: 4.138155937194824
Validation loss: 3.160617689291636

Epoch: 5| Step: 9
Training loss: 3.1985514163970947
Validation loss: 3.156585385402044

Epoch: 5| Step: 10
Training loss: 3.2118847370147705
Validation loss: 3.1526434421539307

Epoch: 5| Step: 11
Training loss: 3.404599666595459
Validation loss: 3.148334721724192

Epoch: 31| Step: 0
Training loss: 2.594010591506958
Validation loss: 3.1440515518188477

Epoch: 5| Step: 1
Training loss: 3.804180145263672
Validation loss: 3.140131652355194

Epoch: 5| Step: 2
Training loss: 3.405569553375244
Validation loss: 3.1357706586519876

Epoch: 5| Step: 3
Training loss: 3.481013774871826
Validation loss: 3.132274051507314

Epoch: 5| Step: 4
Training loss: 2.3684239387512207
Validation loss: 3.1273708740870156

Epoch: 5| Step: 5
Training loss: 4.1023688316345215
Validation loss: 3.1247919499874115

Epoch: 5| Step: 6
Training loss: 3.212099075317383
Validation loss: 3.1195102433363595

Epoch: 5| Step: 7
Training loss: 2.981259822845459
Validation loss: 3.1158663233121238

Epoch: 5| Step: 8
Training loss: 3.590510845184326
Validation loss: 3.1115390956401825

Epoch: 5| Step: 9
Training loss: 3.798388957977295
Validation loss: 3.1063666343688965

Epoch: 5| Step: 10
Training loss: 2.8977203369140625
Validation loss: 3.1023037830988565

Epoch: 5| Step: 11
Training loss: 4.165645122528076
Validation loss: 3.09890944759051

Epoch: 32| Step: 0
Training loss: 3.5648365020751953
Validation loss: 3.0944239795207977

Epoch: 5| Step: 1
Training loss: 2.872328519821167
Validation loss: 3.0911846458911896

Epoch: 5| Step: 2
Training loss: 2.8100061416625977
Validation loss: 3.0881656606992087

Epoch: 5| Step: 3
Training loss: 3.057041883468628
Validation loss: 3.0831855634848275

Epoch: 5| Step: 4
Training loss: 3.402125597000122
Validation loss: 3.078945795694987

Epoch: 5| Step: 5
Training loss: 3.787543773651123
Validation loss: 3.0758473873138428

Epoch: 5| Step: 6
Training loss: 3.048964738845825
Validation loss: 3.0722029507160187

Epoch: 5| Step: 7
Training loss: 3.0498626232147217
Validation loss: 3.067533085743586

Epoch: 5| Step: 8
Training loss: 3.4442572593688965
Validation loss: 3.063869466384252

Epoch: 5| Step: 9
Training loss: 2.8157646656036377
Validation loss: 3.060122768084208

Epoch: 5| Step: 10
Training loss: 3.743332624435425
Validation loss: 3.0558993915716806

Epoch: 5| Step: 11
Training loss: 4.788625240325928
Validation loss: 3.052537073691686

Epoch: 33| Step: 0
Training loss: 3.5088889598846436
Validation loss: 3.0488279660542807

Epoch: 5| Step: 1
Training loss: 2.2565975189208984
Validation loss: 3.0457138121128082

Epoch: 5| Step: 2
Training loss: 4.033926486968994
Validation loss: 3.0408175587654114

Epoch: 5| Step: 3
Training loss: 3.3582165241241455
Validation loss: 3.0378847817579904

Epoch: 5| Step: 4
Training loss: 2.690092086791992
Validation loss: 3.03460701306661

Epoch: 5| Step: 5
Training loss: 3.093803644180298
Validation loss: 3.0308215816815696

Epoch: 5| Step: 6
Training loss: 3.071110486984253
Validation loss: 3.027741571267446

Epoch: 5| Step: 7
Training loss: 3.082808017730713
Validation loss: 3.0220106542110443

Epoch: 5| Step: 8
Training loss: 3.588271379470825
Validation loss: 3.018803060054779

Epoch: 5| Step: 9
Training loss: 3.5823211669921875
Validation loss: 3.0158713459968567

Epoch: 5| Step: 10
Training loss: 3.1182861328125
Validation loss: 3.012774964173635

Epoch: 5| Step: 11
Training loss: 3.350043773651123
Validation loss: 3.0086886286735535

Epoch: 34| Step: 0
Training loss: 2.6222386360168457
Validation loss: 3.004023462533951

Epoch: 5| Step: 1
Training loss: 3.62565279006958
Validation loss: 2.999648869037628

Epoch: 5| Step: 2
Training loss: 3.0287375450134277
Validation loss: 2.9958644111951194

Epoch: 5| Step: 3
Training loss: 2.9577016830444336
Validation loss: 2.9917285641034446

Epoch: 5| Step: 4
Training loss: 3.748861312866211
Validation loss: 2.9896192053953805

Epoch: 5| Step: 5
Training loss: 2.6062464714050293
Validation loss: 2.985462009906769

Epoch: 5| Step: 6
Training loss: 3.4016048908233643
Validation loss: 2.9835616747538247

Epoch: 5| Step: 7
Training loss: 3.8355910778045654
Validation loss: 2.9814080198605857

Epoch: 5| Step: 8
Training loss: 3.668781280517578
Validation loss: 2.978307028611501

Epoch: 5| Step: 9
Training loss: 3.045189619064331
Validation loss: 2.9706498185793557

Epoch: 5| Step: 10
Training loss: 2.5699009895324707
Validation loss: 2.965179294347763

Epoch: 5| Step: 11
Training loss: 2.4082999229431152
Validation loss: 2.962524006764094

Epoch: 35| Step: 0
Training loss: 3.3140742778778076
Validation loss: 2.9598379333813987

Epoch: 5| Step: 1
Training loss: 3.4664158821105957
Validation loss: 2.95479683081309

Epoch: 5| Step: 2
Training loss: 3.3322105407714844
Validation loss: 2.950374573469162

Epoch: 5| Step: 3
Training loss: 2.661958932876587
Validation loss: 2.9476407567660012

Epoch: 5| Step: 4
Training loss: 2.751744031906128
Validation loss: 2.9431516925493875

Epoch: 5| Step: 5
Training loss: 2.9878528118133545
Validation loss: 2.940402021010717

Epoch: 5| Step: 6
Training loss: 3.337207794189453
Validation loss: 2.9372150202592215

Epoch: 5| Step: 7
Training loss: 3.3894801139831543
Validation loss: 2.933299243450165

Epoch: 5| Step: 8
Training loss: 2.6972224712371826
Validation loss: 2.9298156996568046

Epoch: 5| Step: 9
Training loss: 3.1315369606018066
Validation loss: 2.926630119482676

Epoch: 5| Step: 10
Training loss: 3.537022352218628
Validation loss: 2.922238657871882

Epoch: 5| Step: 11
Training loss: 2.8628528118133545
Validation loss: 2.918380548556646

Epoch: 36| Step: 0
Training loss: 3.723592758178711
Validation loss: 2.915384203195572

Epoch: 5| Step: 1
Training loss: 3.2702651023864746
Validation loss: 2.9124164481957755

Epoch: 5| Step: 2
Training loss: 3.191209554672241
Validation loss: 2.907988558212916

Epoch: 5| Step: 3
Training loss: 3.1248233318328857
Validation loss: 2.9049174388249717

Epoch: 5| Step: 4
Training loss: 2.4991772174835205
Validation loss: 2.902236352364222

Epoch: 5| Step: 5
Training loss: 2.475637912750244
Validation loss: 2.8986077507336936

Epoch: 5| Step: 6
Training loss: 2.8222219944000244
Validation loss: 2.8959542214870453

Epoch: 5| Step: 7
Training loss: 3.5281264781951904
Validation loss: 2.8951402703921

Epoch: 5| Step: 8
Training loss: 3.4223270416259766
Validation loss: 2.889619459708532

Epoch: 5| Step: 9
Training loss: 2.984771966934204
Validation loss: 2.886705309152603

Epoch: 5| Step: 10
Training loss: 3.3544394969940186
Validation loss: 2.882800499598185

Epoch: 5| Step: 11
Training loss: 1.7796095609664917
Validation loss: 2.880464404821396

Epoch: 37| Step: 0
Training loss: 3.4825947284698486
Validation loss: 2.8802541295687356

Epoch: 5| Step: 1
Training loss: 3.608177900314331
Validation loss: 2.898183375597

Epoch: 5| Step: 2
Training loss: 3.15053653717041
Validation loss: 2.8735846678415933

Epoch: 5| Step: 3
Training loss: 3.0699024200439453
Validation loss: 2.8669122060139975

Epoch: 5| Step: 4
Training loss: 3.155078411102295
Validation loss: 2.8662081162134805

Epoch: 5| Step: 5
Training loss: 2.541710138320923
Validation loss: 2.8660396138827005

Epoch: 5| Step: 6
Training loss: 3.0098397731781006
Validation loss: 2.8637864192326865

Epoch: 5| Step: 7
Training loss: 2.9538655281066895
Validation loss: 2.8598125874996185

Epoch: 5| Step: 8
Training loss: 2.8380093574523926
Validation loss: 2.8523040215174356

Epoch: 5| Step: 9
Training loss: 2.954529285430908
Validation loss: 2.8477031886577606

Epoch: 5| Step: 10
Training loss: 3.191870927810669
Validation loss: 2.844896157582601

Epoch: 5| Step: 11
Training loss: 2.4645371437072754
Validation loss: 2.843357026576996

Epoch: 38| Step: 0
Training loss: 2.987107515335083
Validation loss: 2.8426087896029153

Epoch: 5| Step: 1
Training loss: 3.563434600830078
Validation loss: 2.8430325388908386

Epoch: 5| Step: 2
Training loss: 2.4468791484832764
Validation loss: 2.841783086458842

Epoch: 5| Step: 3
Training loss: 2.6331725120544434
Validation loss: 2.8410079379876456

Epoch: 5| Step: 4
Training loss: 2.425058364868164
Validation loss: 2.8445057471593223

Epoch: 5| Step: 5
Training loss: 3.006563901901245
Validation loss: 2.838734805583954

Epoch: 5| Step: 6
Training loss: 3.128572702407837
Validation loss: 2.8343372344970703

Epoch: 5| Step: 7
Training loss: 3.3399899005889893
Validation loss: 2.8266133467356362

Epoch: 5| Step: 8
Training loss: 3.471782684326172
Validation loss: 2.819060355424881

Epoch: 5| Step: 9
Training loss: 2.9449410438537598
Validation loss: 2.8156810899575553

Epoch: 5| Step: 10
Training loss: 3.1672420501708984
Validation loss: 2.811473528544108

Epoch: 5| Step: 11
Training loss: 4.531817436218262
Validation loss: 2.807385424772898

Epoch: 39| Step: 0
Training loss: 3.2034084796905518
Validation loss: 2.8044857482115426

Epoch: 5| Step: 1
Training loss: 2.622853994369507
Validation loss: 2.8008682628472648

Epoch: 5| Step: 2
Training loss: 3.4748001098632812
Validation loss: 2.798194646835327

Epoch: 5| Step: 3
Training loss: 3.3639914989471436
Validation loss: 2.7955378790696463

Epoch: 5| Step: 4
Training loss: 3.835636615753174
Validation loss: 2.792230357726415

Epoch: 5| Step: 5
Training loss: 2.7854037284851074
Validation loss: 2.789388875166575

Epoch: 5| Step: 6
Training loss: 2.8511619567871094
Validation loss: 2.785392254590988

Epoch: 5| Step: 7
Training loss: 2.4714953899383545
Validation loss: 2.781036764383316

Epoch: 5| Step: 8
Training loss: 2.378483772277832
Validation loss: 2.7772269745667777

Epoch: 5| Step: 9
Training loss: 3.3891937732696533
Validation loss: 2.773686478535334

Epoch: 5| Step: 10
Training loss: 2.7371819019317627
Validation loss: 2.769870767990748

Epoch: 5| Step: 11
Training loss: 2.3945152759552
Validation loss: 2.766372670729955

Epoch: 40| Step: 0
Training loss: 3.2132468223571777
Validation loss: 2.7642469803492227

Epoch: 5| Step: 1
Training loss: 2.8525969982147217
Validation loss: 2.7612763742605844

Epoch: 5| Step: 2
Training loss: 2.8905222415924072
Validation loss: 2.758823255697886

Epoch: 5| Step: 3
Training loss: 2.54040789604187
Validation loss: 2.7547322611014047

Epoch: 5| Step: 4
Training loss: 2.877680778503418
Validation loss: 2.7523696422576904

Epoch: 5| Step: 5
Training loss: 3.166512966156006
Validation loss: 2.7498270173867545

Epoch: 5| Step: 6
Training loss: 2.7453408241271973
Validation loss: 2.7470493415991464

Epoch: 5| Step: 7
Training loss: 3.1882283687591553
Validation loss: 2.7441510260105133

Epoch: 5| Step: 8
Training loss: 3.339327573776245
Validation loss: 2.7409665286540985

Epoch: 5| Step: 9
Training loss: 2.731947422027588
Validation loss: 2.739321122566859

Epoch: 5| Step: 10
Training loss: 3.046940803527832
Validation loss: 2.7357779244581857

Epoch: 5| Step: 11
Training loss: 2.9092955589294434
Validation loss: 2.731160322825114

Epoch: 41| Step: 0
Training loss: 3.1361286640167236
Validation loss: 2.7300005654493966

Epoch: 5| Step: 1
Training loss: 2.736128330230713
Validation loss: 2.7264592349529266

Epoch: 5| Step: 2
Training loss: 3.2954514026641846
Validation loss: 2.724229951699575

Epoch: 5| Step: 3
Training loss: 2.504882335662842
Validation loss: 2.7207382122675576

Epoch: 5| Step: 4
Training loss: 2.1341094970703125
Validation loss: 2.7178848485151925

Epoch: 5| Step: 5
Training loss: 3.349189043045044
Validation loss: 2.715261787176132

Epoch: 5| Step: 6
Training loss: 3.2362945079803467
Validation loss: 2.7124145229657493

Epoch: 5| Step: 7
Training loss: 3.085604190826416
Validation loss: 2.709071308374405

Epoch: 5| Step: 8
Training loss: 3.018341064453125
Validation loss: 2.706928461790085

Epoch: 5| Step: 9
Training loss: 2.9453699588775635
Validation loss: 2.70484126607577

Epoch: 5| Step: 10
Training loss: 2.9785873889923096
Validation loss: 2.700957715511322

Epoch: 5| Step: 11
Training loss: 1.6541662216186523
Validation loss: 2.6981968382994332

Epoch: 42| Step: 0
Training loss: 2.248703718185425
Validation loss: 2.6952483852704368

Epoch: 5| Step: 1
Training loss: 3.055756092071533
Validation loss: 2.6935203969478607

Epoch: 5| Step: 2
Training loss: 3.234236478805542
Validation loss: 2.68814480304718

Epoch: 5| Step: 3
Training loss: 2.223862648010254
Validation loss: 2.686103274424871

Epoch: 5| Step: 4
Training loss: 3.56433367729187
Validation loss: 2.6829480032126107

Epoch: 5| Step: 5
Training loss: 3.1929633617401123
Validation loss: 2.6782891849676767

Epoch: 5| Step: 6
Training loss: 2.7177014350891113
Validation loss: 2.6779860158761344

Epoch: 5| Step: 7
Training loss: 2.947486162185669
Validation loss: 2.674075444539388

Epoch: 5| Step: 8
Training loss: 2.863433361053467
Validation loss: 2.6718129913012185

Epoch: 5| Step: 9
Training loss: 2.5604987144470215
Validation loss: 2.669264023502668

Epoch: 5| Step: 10
Training loss: 3.1634695529937744
Validation loss: 2.667490561803182

Epoch: 5| Step: 11
Training loss: 2.7875657081604004
Validation loss: 2.6649133463700614

Epoch: 43| Step: 0
Training loss: 3.0561954975128174
Validation loss: 2.662801514069239

Epoch: 5| Step: 1
Training loss: 3.374119997024536
Validation loss: 2.6605608264605203

Epoch: 5| Step: 2
Training loss: 2.4120125770568848
Validation loss: 2.6564393639564514

Epoch: 5| Step: 3
Training loss: 3.08050274848938
Validation loss: 2.652935653924942

Epoch: 5| Step: 4
Training loss: 2.235551357269287
Validation loss: 2.6489021281401315

Epoch: 5| Step: 5
Training loss: 2.3430960178375244
Validation loss: 2.64639405409495

Epoch: 5| Step: 6
Training loss: 2.673544406890869
Validation loss: 2.642748902241389

Epoch: 5| Step: 7
Training loss: 3.3209309577941895
Validation loss: 2.639061907927195

Epoch: 5| Step: 8
Training loss: 2.5969443321228027
Validation loss: 2.6326499780019126

Epoch: 5| Step: 9
Training loss: 2.6117796897888184
Validation loss: 2.632964720328649

Epoch: 5| Step: 10
Training loss: 3.3908133506774902
Validation loss: 2.629393527905146

Epoch: 5| Step: 11
Training loss: 4.219354629516602
Validation loss: 2.62732395529747

Epoch: 44| Step: 0
Training loss: 2.5649161338806152
Validation loss: 2.621521274248759

Epoch: 5| Step: 1
Training loss: 3.0832505226135254
Validation loss: 2.6184733708699546

Epoch: 5| Step: 2
Training loss: 2.86155366897583
Validation loss: 2.614363511403402

Epoch: 5| Step: 3
Training loss: 2.714385986328125
Validation loss: 2.611677199602127

Epoch: 5| Step: 4
Training loss: 2.8694798946380615
Validation loss: 2.6091044743855796

Epoch: 5| Step: 5
Training loss: 3.2414822578430176
Validation loss: 2.6059568524360657

Epoch: 5| Step: 6
Training loss: 2.8155477046966553
Validation loss: 2.6019840439160666

Epoch: 5| Step: 7
Training loss: 2.9968903064727783
Validation loss: 2.6012829641501107

Epoch: 5| Step: 8
Training loss: 2.3571839332580566
Validation loss: 2.595950722694397

Epoch: 5| Step: 9
Training loss: 2.899848699569702
Validation loss: 2.5941501359144845

Epoch: 5| Step: 10
Training loss: 2.405853509902954
Validation loss: 2.592020163933436

Epoch: 5| Step: 11
Training loss: 3.350741147994995
Validation loss: 2.5882351398468018

Epoch: 45| Step: 0
Training loss: 2.3209004402160645
Validation loss: 2.58365269502004

Epoch: 5| Step: 1
Training loss: 3.464282512664795
Validation loss: 2.5812228322029114

Epoch: 5| Step: 2
Training loss: 2.9500911235809326
Validation loss: 2.5779781440893808

Epoch: 5| Step: 3
Training loss: 3.1570534706115723
Validation loss: 2.574375589688619

Epoch: 5| Step: 4
Training loss: 3.055011749267578
Validation loss: 2.5728154381116233

Epoch: 5| Step: 5
Training loss: 2.773257255554199
Validation loss: 2.5681668668985367

Epoch: 5| Step: 6
Training loss: 2.2383856773376465
Validation loss: 2.565233608086904

Epoch: 5| Step: 7
Training loss: 2.6198692321777344
Validation loss: 2.565268556276957

Epoch: 5| Step: 8
Training loss: 2.7362568378448486
Validation loss: 2.5612751841545105

Epoch: 5| Step: 9
Training loss: 2.5554044246673584
Validation loss: 2.5579916735490165

Epoch: 5| Step: 10
Training loss: 2.4727654457092285
Validation loss: 2.5550150871276855

Epoch: 5| Step: 11
Training loss: 3.5153465270996094
Validation loss: 2.552632451057434

Epoch: 46| Step: 0
Training loss: 2.4857189655303955
Validation loss: 2.5513326028982797

Epoch: 5| Step: 1
Training loss: 2.6946518421173096
Validation loss: 2.5497220853964486

Epoch: 5| Step: 2
Training loss: 2.956892967224121
Validation loss: 2.5486282209555307

Epoch: 5| Step: 3
Training loss: 3.1614670753479004
Validation loss: 2.5493934899568558

Epoch: 5| Step: 4
Training loss: 2.5287060737609863
Validation loss: 2.5452307363351188

Epoch: 5| Step: 5
Training loss: 2.6116604804992676
Validation loss: 2.542416036128998

Epoch: 5| Step: 6
Training loss: 2.9207730293273926
Validation loss: 2.54085307319959

Epoch: 5| Step: 7
Training loss: 3.1841816902160645
Validation loss: 2.535465141137441

Epoch: 5| Step: 8
Training loss: 2.157477855682373
Validation loss: 2.5355602403481803

Epoch: 5| Step: 9
Training loss: 3.469949722290039
Validation loss: 2.530186573664347

Epoch: 5| Step: 10
Training loss: 2.131075143814087
Validation loss: 2.529864023129145

Epoch: 5| Step: 11
Training loss: 1.7878303527832031
Validation loss: 2.5242402156194053

Epoch: 47| Step: 0
Training loss: 2.965721607208252
Validation loss: 2.5234407087167106

Epoch: 5| Step: 1
Training loss: 2.1810178756713867
Validation loss: 2.518567035595576

Epoch: 5| Step: 2
Training loss: 2.9342098236083984
Validation loss: 2.5164182782173157

Epoch: 5| Step: 3
Training loss: 2.8022806644439697
Validation loss: 2.514646699031194

Epoch: 5| Step: 4
Training loss: 3.169994592666626
Validation loss: 2.511362850666046

Epoch: 5| Step: 5
Training loss: 2.3578858375549316
Validation loss: 2.506299684445063

Epoch: 5| Step: 6
Training loss: 3.0435190200805664
Validation loss: 2.504842529694239

Epoch: 5| Step: 7
Training loss: 2.7571234703063965
Validation loss: 2.5023924311002097

Epoch: 5| Step: 8
Training loss: 2.047039747238159
Validation loss: 2.497170478105545

Epoch: 5| Step: 9
Training loss: 3.051109790802002
Validation loss: 2.4972772200902305

Epoch: 5| Step: 10
Training loss: 2.581082820892334
Validation loss: 2.4931404491265616

Epoch: 5| Step: 11
Training loss: 1.8880399465560913
Validation loss: 2.489804983139038

Epoch: 48| Step: 0
Training loss: 2.8000006675720215
Validation loss: 2.4887283643086753

Epoch: 5| Step: 1
Training loss: 2.7200779914855957
Validation loss: 2.4851687053839364

Epoch: 5| Step: 2
Training loss: 2.9009547233581543
Validation loss: 2.482752879460653

Epoch: 5| Step: 3
Training loss: 2.375603199005127
Validation loss: 2.478169769048691

Epoch: 5| Step: 4
Training loss: 3.0906779766082764
Validation loss: 2.476093744238218

Epoch: 5| Step: 5
Training loss: 2.913745880126953
Validation loss: 2.4740463197231293

Epoch: 5| Step: 6
Training loss: 2.8506064414978027
Validation loss: 2.471770683924357

Epoch: 5| Step: 7
Training loss: 1.9908397197723389
Validation loss: 2.4694149692853293

Epoch: 5| Step: 8
Training loss: 2.9313178062438965
Validation loss: 2.466399153073629

Epoch: 5| Step: 9
Training loss: 2.3494515419006348
Validation loss: 2.4626521915197372

Epoch: 5| Step: 10
Training loss: 2.3811841011047363
Validation loss: 2.4597798387209573

Epoch: 5| Step: 11
Training loss: 2.793435573577881
Validation loss: 2.4530776540438333

Epoch: 49| Step: 0
Training loss: 2.447700023651123
Validation loss: 2.449215531349182

Epoch: 5| Step: 1
Training loss: 2.663365364074707
Validation loss: 2.4547727555036545

Epoch: 5| Step: 2
Training loss: 2.67402982711792
Validation loss: 2.4439344902833304

Epoch: 5| Step: 3
Training loss: 2.9483447074890137
Validation loss: 2.444085697333018

Epoch: 5| Step: 4
Training loss: 2.5478861331939697
Validation loss: 2.4415576060613

Epoch: 5| Step: 5
Training loss: 2.798799991607666
Validation loss: 2.4430883626143136

Epoch: 5| Step: 6
Training loss: 2.267285108566284
Validation loss: 2.44620418548584

Epoch: 5| Step: 7
Training loss: 2.654470205307007
Validation loss: 2.4409867922465005

Epoch: 5| Step: 8
Training loss: 3.1204051971435547
Validation loss: 2.44103134671847

Epoch: 5| Step: 9
Training loss: 2.4744374752044678
Validation loss: 2.4394564827283225

Epoch: 5| Step: 10
Training loss: 2.4031405448913574
Validation loss: 2.4355505406856537

Epoch: 5| Step: 11
Training loss: 2.631585121154785
Validation loss: 2.432800849278768

Epoch: 50| Step: 0
Training loss: 2.7690858840942383
Validation loss: 2.426204433043798

Epoch: 5| Step: 1
Training loss: 2.743251323699951
Validation loss: 2.4246126214663186

Epoch: 5| Step: 2
Training loss: 2.4450793266296387
Validation loss: 2.420421525835991

Epoch: 5| Step: 3
Training loss: 2.701875925064087
Validation loss: 2.418227324883143

Epoch: 5| Step: 4
Training loss: 3.0521416664123535
Validation loss: 2.413637494047483

Epoch: 5| Step: 5
Training loss: 2.02972149848938
Validation loss: 2.411215345064799

Epoch: 5| Step: 6
Training loss: 2.457022190093994
Validation loss: 2.408823291460673

Epoch: 5| Step: 7
Training loss: 2.2484378814697266
Validation loss: 2.40584988395373

Epoch: 5| Step: 8
Training loss: 2.0633704662323
Validation loss: 2.403040796518326

Epoch: 5| Step: 9
Training loss: 2.7679550647735596
Validation loss: 2.40235443909963

Epoch: 5| Step: 10
Training loss: 2.9432661533355713
Validation loss: 2.3979560236136117

Epoch: 5| Step: 11
Training loss: 4.301056861877441
Validation loss: 2.393283784389496

Epoch: 51| Step: 0
Training loss: 2.7505125999450684
Validation loss: 2.396936093767484

Epoch: 5| Step: 1
Training loss: 2.454195737838745
Validation loss: 2.3935367663701377

Epoch: 5| Step: 2
Training loss: 3.134580135345459
Validation loss: 2.3907898664474487

Epoch: 5| Step: 3
Training loss: 2.7841858863830566
Validation loss: 2.388991673787435

Epoch: 5| Step: 4
Training loss: 2.5740559101104736
Validation loss: 2.3876381317774453

Epoch: 5| Step: 5
Training loss: 2.291109085083008
Validation loss: 2.3834356367588043

Epoch: 5| Step: 6
Training loss: 2.8808300495147705
Validation loss: 2.3845915297667184

Epoch: 5| Step: 7
Training loss: 2.5316123962402344
Validation loss: 2.378803014755249

Epoch: 5| Step: 8
Training loss: 2.2375762462615967
Validation loss: 2.3766503632068634

Epoch: 5| Step: 9
Training loss: 2.212921619415283
Validation loss: 2.3715038945277533

Epoch: 5| Step: 10
Training loss: 2.2363648414611816
Validation loss: 2.369954744974772

Epoch: 5| Step: 11
Training loss: 3.1771883964538574
Validation loss: 2.3664990266164145

Epoch: 52| Step: 0
Training loss: 2.880082845687866
Validation loss: 2.35860376060009

Epoch: 5| Step: 1
Training loss: 2.871819019317627
Validation loss: 2.3562756280104318

Epoch: 5| Step: 2
Training loss: 2.3157432079315186
Validation loss: 2.354611580570539

Epoch: 5| Step: 3
Training loss: 1.7462494373321533
Validation loss: 2.351843665043513

Epoch: 5| Step: 4
Training loss: 2.79948091506958
Validation loss: 2.346513440211614

Epoch: 5| Step: 5
Training loss: 2.5529022216796875
Validation loss: 2.345725287993749

Epoch: 5| Step: 6
Training loss: 3.0646042823791504
Validation loss: 2.3416911164919534

Epoch: 5| Step: 7
Training loss: 2.544858932495117
Validation loss: 2.3387530545393624

Epoch: 5| Step: 8
Training loss: 2.5890426635742188
Validation loss: 2.343953311443329

Epoch: 5| Step: 9
Training loss: 2.020101547241211
Validation loss: 2.334169030189514

Epoch: 5| Step: 10
Training loss: 2.2873222827911377
Validation loss: 2.339826832214991

Epoch: 5| Step: 11
Training loss: 3.036242723464966
Validation loss: 2.3428353468577066

Epoch: 53| Step: 0
Training loss: 2.4521262645721436
Validation loss: 2.3262530118227005

Epoch: 5| Step: 1
Training loss: 2.0514838695526123
Validation loss: 2.325860540072123

Epoch: 5| Step: 2
Training loss: 2.6572368144989014
Validation loss: 2.3276232182979584

Epoch: 5| Step: 3
Training loss: 3.0090107917785645
Validation loss: 2.327335774898529

Epoch: 5| Step: 4
Training loss: 2.12558913230896
Validation loss: 2.3267362117767334

Epoch: 5| Step: 5
Training loss: 2.1826815605163574
Validation loss: 2.327618251244227

Epoch: 5| Step: 6
Training loss: 2.170278549194336
Validation loss: 2.3289010922114053

Epoch: 5| Step: 7
Training loss: 2.6378540992736816
Validation loss: 2.3300992250442505

Epoch: 5| Step: 8
Training loss: 2.1261208057403564
Validation loss: 2.323539823293686

Epoch: 5| Step: 9
Training loss: 3.1529018878936768
Validation loss: 2.3195138971010842

Epoch: 5| Step: 10
Training loss: 2.6162238121032715
Validation loss: 2.3127960364023843

Epoch: 5| Step: 11
Training loss: 3.9425101280212402
Validation loss: 2.308571308851242

Epoch: 54| Step: 0
Training loss: 2.7327675819396973
Validation loss: 2.303662051757177

Epoch: 5| Step: 1
Training loss: 2.955976963043213
Validation loss: 2.3018804291884103

Epoch: 5| Step: 2
Training loss: 2.4161171913146973
Validation loss: 2.2969284454981485

Epoch: 5| Step: 3
Training loss: 2.710109233856201
Validation loss: 2.300277218222618

Epoch: 5| Step: 4
Training loss: 2.2343552112579346
Validation loss: 2.293747971455256

Epoch: 5| Step: 5
Training loss: 1.963181495666504
Validation loss: 2.300164431333542

Epoch: 5| Step: 6
Training loss: 2.6292002201080322
Validation loss: 2.3098836044470468

Epoch: 5| Step: 7
Training loss: 1.8330535888671875
Validation loss: 2.2932259837786355

Epoch: 5| Step: 8
Training loss: 1.967092514038086
Validation loss: 2.2839428385098777

Epoch: 5| Step: 9
Training loss: 2.9170632362365723
Validation loss: 2.2780149579048157

Epoch: 5| Step: 10
Training loss: 2.7001383304595947
Validation loss: 2.279712746540705

Epoch: 5| Step: 11
Training loss: 2.4390413761138916
Validation loss: 2.2799633840719857

Epoch: 55| Step: 0
Training loss: 2.186779499053955
Validation loss: 2.2822912832101188

Epoch: 5| Step: 1
Training loss: 2.0134851932525635
Validation loss: 2.288290078441302

Epoch: 5| Step: 2
Training loss: 2.124053955078125
Validation loss: 2.2930020689964294

Epoch: 5| Step: 3
Training loss: 2.7002665996551514
Validation loss: 2.2943926751613617

Epoch: 5| Step: 4
Training loss: 2.2487144470214844
Validation loss: 2.287153402964274

Epoch: 5| Step: 5
Training loss: 2.3134655952453613
Validation loss: 2.2830424308776855

Epoch: 5| Step: 6
Training loss: 2.8266937732696533
Validation loss: 2.276115655899048

Epoch: 5| Step: 7
Training loss: 2.6291301250457764
Validation loss: 2.273034304380417

Epoch: 5| Step: 8
Training loss: 2.891597270965576
Validation loss: 2.2655653059482574

Epoch: 5| Step: 9
Training loss: 2.6115193367004395
Validation loss: 2.2607417702674866

Epoch: 5| Step: 10
Training loss: 2.421870231628418
Validation loss: 2.258135070403417

Epoch: 5| Step: 11
Training loss: 1.6845004558563232
Validation loss: 2.2561944822470346

Epoch: 56| Step: 0
Training loss: 2.1207947731018066
Validation loss: 2.251765792568525

Epoch: 5| Step: 1
Training loss: 2.2480216026306152
Validation loss: 2.246957093477249

Epoch: 5| Step: 2
Training loss: 3.0298850536346436
Validation loss: 2.24599489569664

Epoch: 5| Step: 3
Training loss: 2.6048331260681152
Validation loss: 2.245654344558716

Epoch: 5| Step: 4
Training loss: 2.642913341522217
Validation loss: 2.238778462012609

Epoch: 5| Step: 5
Training loss: 2.2389743328094482
Validation loss: 2.2351377407709756

Epoch: 5| Step: 6
Training loss: 2.0870883464813232
Validation loss: 2.231260299682617

Epoch: 5| Step: 7
Training loss: 2.36745023727417
Validation loss: 2.2268033574024835

Epoch: 5| Step: 8
Training loss: 2.0446274280548096
Validation loss: 2.222838039199511

Epoch: 5| Step: 9
Training loss: 2.459376573562622
Validation loss: 2.2234355757633844

Epoch: 5| Step: 10
Training loss: 2.6218817234039307
Validation loss: 2.2238010366757712

Epoch: 5| Step: 11
Training loss: 2.061488628387451
Validation loss: 2.220890313386917

Epoch: 57| Step: 0
Training loss: 2.2171101570129395
Validation loss: 2.214911033709844

Epoch: 5| Step: 1
Training loss: 2.447084426879883
Validation loss: 2.211430827776591

Epoch: 5| Step: 2
Training loss: 2.821448802947998
Validation loss: 2.211589733759562

Epoch: 5| Step: 3
Training loss: 2.066953182220459
Validation loss: 2.211969703435898

Epoch: 5| Step: 4
Training loss: 2.4976096153259277
Validation loss: 2.211997300386429

Epoch: 5| Step: 5
Training loss: 2.5657734870910645
Validation loss: 2.2078904112180076

Epoch: 5| Step: 6
Training loss: 2.179572582244873
Validation loss: 2.2093942562739053

Epoch: 5| Step: 7
Training loss: 2.6846272945404053
Validation loss: 2.199533060193062

Epoch: 5| Step: 8
Training loss: 2.190398693084717
Validation loss: 2.205379217863083

Epoch: 5| Step: 9
Training loss: 1.956010103225708
Validation loss: 2.2106856256723404

Epoch: 5| Step: 10
Training loss: 2.2997093200683594
Validation loss: 2.20445524652799

Epoch: 5| Step: 11
Training loss: 3.5412702560424805
Validation loss: 2.204948455095291

Epoch: 58| Step: 0
Training loss: 2.2357077598571777
Validation loss: 2.1965938806533813

Epoch: 5| Step: 1
Training loss: 2.4222986698150635
Validation loss: 2.1978676319122314

Epoch: 5| Step: 2
Training loss: 2.006819486618042
Validation loss: 2.198805386821429

Epoch: 5| Step: 3
Training loss: 2.721161365509033
Validation loss: 2.199788769086202

Epoch: 5| Step: 4
Training loss: 2.700345754623413
Validation loss: 2.200688118735949

Epoch: 5| Step: 5
Training loss: 2.410378932952881
Validation loss: 2.205329974492391

Epoch: 5| Step: 6
Training loss: 2.2213845252990723
Validation loss: 2.2055510679880777

Epoch: 5| Step: 7
Training loss: 2.4496047496795654
Validation loss: 2.2075820565223694

Epoch: 5| Step: 8
Training loss: 2.216620683670044
Validation loss: 2.2032959163188934

Epoch: 5| Step: 9
Training loss: 2.3148605823516846
Validation loss: 2.200876370072365

Epoch: 5| Step: 10
Training loss: 2.092228651046753
Validation loss: 2.1964598645766578

Epoch: 5| Step: 11
Training loss: 3.340597152709961
Validation loss: 2.1935290346542993

Epoch: 59| Step: 0
Training loss: 2.3731093406677246
Validation loss: 2.18728968501091

Epoch: 5| Step: 1
Training loss: 2.2054526805877686
Validation loss: 2.188304384549459

Epoch: 5| Step: 2
Training loss: 1.7201392650604248
Validation loss: 2.1852885584036508

Epoch: 5| Step: 3
Training loss: 2.5696208477020264
Validation loss: 2.1796117275953293

Epoch: 5| Step: 4
Training loss: 2.640532970428467
Validation loss: 2.1734001686175666

Epoch: 5| Step: 5
Training loss: 2.508788585662842
Validation loss: 2.1712226619323096

Epoch: 5| Step: 6
Training loss: 2.188776731491089
Validation loss: 2.1678979992866516

Epoch: 5| Step: 7
Training loss: 2.297377109527588
Validation loss: 2.1693161775668464

Epoch: 5| Step: 8
Training loss: 2.3487634658813477
Validation loss: 2.166364183028539

Epoch: 5| Step: 9
Training loss: 2.30645751953125
Validation loss: 2.1641620695590973

Epoch: 5| Step: 10
Training loss: 2.5934014320373535
Validation loss: 2.161505182584127

Epoch: 5| Step: 11
Training loss: 2.443258762359619
Validation loss: 2.165127525726954

Epoch: 60| Step: 0
Training loss: 2.3258883953094482
Validation loss: 2.1577333261569343

Epoch: 5| Step: 1
Training loss: 2.6572611331939697
Validation loss: 2.1662111033995948

Epoch: 5| Step: 2
Training loss: 2.276732921600342
Validation loss: 2.178259784976641

Epoch: 5| Step: 3
Training loss: 2.6195998191833496
Validation loss: 2.1914279013872147

Epoch: 5| Step: 4
Training loss: 2.235452890396118
Validation loss: 2.168742537498474

Epoch: 5| Step: 5
Training loss: 2.1550819873809814
Validation loss: 2.1507936070362725

Epoch: 5| Step: 6
Training loss: 2.4762892723083496
Validation loss: 2.149320046106974

Epoch: 5| Step: 7
Training loss: 2.0717101097106934
Validation loss: 2.147809570034345

Epoch: 5| Step: 8
Training loss: 1.8979781866073608
Validation loss: 2.150735149780909

Epoch: 5| Step: 9
Training loss: 2.623302936553955
Validation loss: 2.1510679622491202

Epoch: 5| Step: 10
Training loss: 2.4101080894470215
Validation loss: 2.153258115053177

Epoch: 5| Step: 11
Training loss: 2.9407875537872314
Validation loss: 2.146898011366526

Epoch: 61| Step: 0
Training loss: 2.2660727500915527
Validation loss: 2.147608528534571

Epoch: 5| Step: 1
Training loss: 2.3961987495422363
Validation loss: 2.1485339601834617

Epoch: 5| Step: 2
Training loss: 2.315186023712158
Validation loss: 2.1509088228146234

Epoch: 5| Step: 3
Training loss: 2.0195045471191406
Validation loss: 2.149306520819664

Epoch: 5| Step: 4
Training loss: 2.695033550262451
Validation loss: 2.149528736869494

Epoch: 5| Step: 5
Training loss: 2.693387985229492
Validation loss: 2.1491090059280396

Epoch: 5| Step: 6
Training loss: 2.120943546295166
Validation loss: 2.1481487403313317

Epoch: 5| Step: 7
Training loss: 2.6556477546691895
Validation loss: 2.1510519683361053

Epoch: 5| Step: 8
Training loss: 1.473647117614746
Validation loss: 2.1430848936239877

Epoch: 5| Step: 9
Training loss: 2.1739883422851562
Validation loss: 2.13872067630291

Epoch: 5| Step: 10
Training loss: 2.8519527912139893
Validation loss: 2.1360491762558618

Epoch: 5| Step: 11
Training loss: 1.8996126651763916
Validation loss: 2.133112688859304

Epoch: 62| Step: 0
Training loss: 1.863985300064087
Validation loss: 2.1272848397493362

Epoch: 5| Step: 1
Training loss: 2.0799813270568848
Validation loss: 2.129436840613683

Epoch: 5| Step: 2
Training loss: 2.3114676475524902
Validation loss: 2.1288840075333915

Epoch: 5| Step: 3
Training loss: 2.087014675140381
Validation loss: 2.1236866364876428

Epoch: 5| Step: 4
Training loss: 2.1825225353240967
Validation loss: 2.127763494849205

Epoch: 5| Step: 5
Training loss: 2.2117772102355957
Validation loss: 2.129211222132047

Epoch: 5| Step: 6
Training loss: 2.1424813270568848
Validation loss: 2.130149409174919

Epoch: 5| Step: 7
Training loss: 2.089144229888916
Validation loss: 2.1276123970746994

Epoch: 5| Step: 8
Training loss: 2.8344249725341797
Validation loss: 2.1247296581665673

Epoch: 5| Step: 9
Training loss: 2.8204169273376465
Validation loss: 2.1190888583660126

Epoch: 5| Step: 10
Training loss: 2.5155577659606934
Validation loss: 2.119966914256414

Epoch: 5| Step: 11
Training loss: 3.410106658935547
Validation loss: 2.1205311516920724

Epoch: 63| Step: 0
Training loss: 1.8511078357696533
Validation loss: 2.1222969790299735

Epoch: 5| Step: 1
Training loss: 1.4723317623138428
Validation loss: 2.125514884789785

Epoch: 5| Step: 2
Training loss: 2.328883647918701
Validation loss: 2.1311586846907935

Epoch: 5| Step: 3
Training loss: 1.896615982055664
Validation loss: 2.1357424557209015

Epoch: 5| Step: 4
Training loss: 2.186225175857544
Validation loss: 2.1412458966175714

Epoch: 5| Step: 5
Training loss: 2.716808319091797
Validation loss: 2.1535469442605972

Epoch: 5| Step: 6
Training loss: 2.6699986457824707
Validation loss: 2.1585192481676736

Epoch: 5| Step: 7
Training loss: 2.3790974617004395
Validation loss: 2.164768268664678

Epoch: 5| Step: 8
Training loss: 2.614168643951416
Validation loss: 2.164742092291514

Epoch: 5| Step: 9
Training loss: 2.625401020050049
Validation loss: 2.1608457465966544

Epoch: 5| Step: 10
Training loss: 2.7695796489715576
Validation loss: 2.149187887708346

Epoch: 5| Step: 11
Training loss: 2.6765220165252686
Validation loss: 2.1367821097373962

Epoch: 64| Step: 0
Training loss: 2.773210048675537
Validation loss: 2.1256744414567947

Epoch: 5| Step: 1
Training loss: 2.353477954864502
Validation loss: 2.1180575837691626

Epoch: 5| Step: 2
Training loss: 2.630119800567627
Validation loss: 2.1132425715525947

Epoch: 5| Step: 3
Training loss: 2.2362937927246094
Validation loss: 2.1068875839312873

Epoch: 5| Step: 4
Training loss: 2.398301601409912
Validation loss: 2.11727137863636

Epoch: 5| Step: 5
Training loss: 2.6129403114318848
Validation loss: 2.129009932279587

Epoch: 5| Step: 6
Training loss: 2.3322277069091797
Validation loss: 2.12483357389768

Epoch: 5| Step: 7
Training loss: 2.020291805267334
Validation loss: 2.105868791540464

Epoch: 5| Step: 8
Training loss: 2.147930145263672
Validation loss: 2.0978590150674186

Epoch: 5| Step: 9
Training loss: 1.7588062286376953
Validation loss: 2.1000938018163047

Epoch: 5| Step: 10
Training loss: 2.0290801525115967
Validation loss: 2.0940164029598236

Epoch: 5| Step: 11
Training loss: 2.939101219177246
Validation loss: 2.101158380508423

Epoch: 65| Step: 0
Training loss: 2.0226569175720215
Validation loss: 2.0919391413529715

Epoch: 5| Step: 1
Training loss: 2.8952279090881348
Validation loss: 2.087762807806333

Epoch: 5| Step: 2
Training loss: 2.470960855484009
Validation loss: 2.0893352329730988

Epoch: 5| Step: 3
Training loss: 2.17803955078125
Validation loss: 2.0945662955443063

Epoch: 5| Step: 4
Training loss: 2.4244544506073
Validation loss: 2.089002644022306

Epoch: 5| Step: 5
Training loss: 1.8938062191009521
Validation loss: 2.0935689210891724

Epoch: 5| Step: 6
Training loss: 2.4281487464904785
Validation loss: 2.0910044610500336

Epoch: 5| Step: 7
Training loss: 2.1832571029663086
Validation loss: 2.0862196882565818

Epoch: 5| Step: 8
Training loss: 2.29809832572937
Validation loss: 2.085649609565735

Epoch: 5| Step: 9
Training loss: 2.601266384124756
Validation loss: 2.084697504838308

Epoch: 5| Step: 10
Training loss: 1.860555648803711
Validation loss: 2.0814183255036673

Epoch: 5| Step: 11
Training loss: 0.9221646785736084
Validation loss: 2.077156995733579

Epoch: 66| Step: 0
Training loss: 1.9801746606826782
Validation loss: 2.0821985006332397

Epoch: 5| Step: 1
Training loss: 3.0009589195251465
Validation loss: 2.0877160082260766

Epoch: 5| Step: 2
Training loss: 2.2383456230163574
Validation loss: 2.0864162345727286

Epoch: 5| Step: 3
Training loss: 2.5402169227600098
Validation loss: 2.082641527056694

Epoch: 5| Step: 4
Training loss: 1.8660993576049805
Validation loss: 2.072598839799563

Epoch: 5| Step: 5
Training loss: 1.777012586593628
Validation loss: 2.0781595508257547

Epoch: 5| Step: 6
Training loss: 2.5561089515686035
Validation loss: 2.0804409980773926

Epoch: 5| Step: 7
Training loss: 2.3471150398254395
Validation loss: 2.0872119764486947

Epoch: 5| Step: 8
Training loss: 2.4881672859191895
Validation loss: 2.086801196138064

Epoch: 5| Step: 9
Training loss: 2.4370198249816895
Validation loss: 2.0798734774192176

Epoch: 5| Step: 10
Training loss: 1.7590019702911377
Validation loss: 2.0853520979483924

Epoch: 5| Step: 11
Training loss: 2.7324137687683105
Validation loss: 2.0734039346377053

Epoch: 67| Step: 0
Training loss: 2.7315266132354736
Validation loss: 2.0800612717866898

Epoch: 5| Step: 1
Training loss: 2.03269624710083
Validation loss: 2.075607215364774

Epoch: 5| Step: 2
Training loss: 2.1395962238311768
Validation loss: 2.0784948468208313

Epoch: 5| Step: 3
Training loss: 2.24086332321167
Validation loss: 2.074053461352984

Epoch: 5| Step: 4
Training loss: 2.7000091075897217
Validation loss: 2.07083893318971

Epoch: 5| Step: 5
Training loss: 2.3132472038269043
Validation loss: 2.0659432311852775

Epoch: 5| Step: 6
Training loss: 2.2553417682647705
Validation loss: 2.064513439933459

Epoch: 5| Step: 7
Training loss: 2.4494211673736572
Validation loss: 2.061438058813413

Epoch: 5| Step: 8
Training loss: 1.6343250274658203
Validation loss: 2.0610868285099664

Epoch: 5| Step: 9
Training loss: 2.2277090549468994
Validation loss: 2.0655452807744346

Epoch: 5| Step: 10
Training loss: 2.2148823738098145
Validation loss: 2.0643696039915085

Epoch: 5| Step: 11
Training loss: 1.7001447677612305
Validation loss: 2.0622496902942657

Epoch: 68| Step: 0
Training loss: 1.9371055364608765
Validation loss: 2.0580127984285355

Epoch: 5| Step: 1
Training loss: 2.7358624935150146
Validation loss: 2.0594544361035028

Epoch: 5| Step: 2
Training loss: 1.6226780414581299
Validation loss: 2.0597973565260568

Epoch: 5| Step: 3
Training loss: 2.441319704055786
Validation loss: 2.0574368437131247

Epoch: 5| Step: 4
Training loss: 1.874773621559143
Validation loss: 2.06048192580541

Epoch: 5| Step: 5
Training loss: 2.6761391162872314
Validation loss: 2.0595605423053107

Epoch: 5| Step: 6
Training loss: 1.9617458581924438
Validation loss: 2.0552306473255157

Epoch: 5| Step: 7
Training loss: 2.7622437477111816
Validation loss: 2.0510836293299994

Epoch: 5| Step: 8
Training loss: 2.0430595874786377
Validation loss: 2.0578400790691376

Epoch: 5| Step: 9
Training loss: 2.5748019218444824
Validation loss: 2.046828086177508

Epoch: 5| Step: 10
Training loss: 1.9233745336532593
Validation loss: 2.050961678226789

Epoch: 5| Step: 11
Training loss: 2.9860007762908936
Validation loss: 2.0532048443953195

Epoch: 69| Step: 0
Training loss: 2.227501153945923
Validation loss: 2.058694303035736

Epoch: 5| Step: 1
Training loss: 2.107332944869995
Validation loss: 2.0492434352636337

Epoch: 5| Step: 2
Training loss: 2.0820343494415283
Validation loss: 2.0565843085447946

Epoch: 5| Step: 3
Training loss: 2.0544750690460205
Validation loss: 2.0563392490148544

Epoch: 5| Step: 4
Training loss: 1.8657505512237549
Validation loss: 2.050265207886696

Epoch: 5| Step: 5
Training loss: 2.2720556259155273
Validation loss: 2.0447485794623694

Epoch: 5| Step: 6
Training loss: 2.205296039581299
Validation loss: 2.0498433858156204

Epoch: 5| Step: 7
Training loss: 2.7217166423797607
Validation loss: 2.0517810036738715

Epoch: 5| Step: 8
Training loss: 2.617628574371338
Validation loss: 2.0580145021279654

Epoch: 5| Step: 9
Training loss: 2.2638161182403564
Validation loss: 2.0543566942214966

Epoch: 5| Step: 10
Training loss: 2.3203911781311035
Validation loss: 2.062822570403417

Epoch: 5| Step: 11
Training loss: 1.8838802576065063
Validation loss: 2.0601498087247214

Epoch: 70| Step: 0
Training loss: 2.509273052215576
Validation loss: 2.0578429301579795

Epoch: 5| Step: 1
Training loss: 2.1940908432006836
Validation loss: 2.0589390943447747

Epoch: 5| Step: 2
Training loss: 2.465184450149536
Validation loss: 2.05871319770813

Epoch: 5| Step: 3
Training loss: 2.275744676589966
Validation loss: 2.054178828994433

Epoch: 5| Step: 4
Training loss: 2.076596736907959
Validation loss: 2.044800082842509

Epoch: 5| Step: 5
Training loss: 1.9159492254257202
Validation loss: 2.0460677643616996

Epoch: 5| Step: 6
Training loss: 2.107074022293091
Validation loss: 2.0368575900793076

Epoch: 5| Step: 7
Training loss: 2.475587844848633
Validation loss: 2.048702364166578

Epoch: 5| Step: 8
Training loss: 1.7730404138565063
Validation loss: 2.0369935234387717

Epoch: 5| Step: 9
Training loss: 2.206861972808838
Validation loss: 2.043355549375216

Epoch: 5| Step: 10
Training loss: 2.553412914276123
Validation loss: 2.0453438659509025

Epoch: 5| Step: 11
Training loss: 2.338202476501465
Validation loss: 2.04156323770682

Epoch: 71| Step: 0
Training loss: 1.918626070022583
Validation loss: 2.038580521941185

Epoch: 5| Step: 1
Training loss: 2.292922258377075
Validation loss: 2.036442374189695

Epoch: 5| Step: 2
Training loss: 1.864372968673706
Validation loss: 2.037261888384819

Epoch: 5| Step: 3
Training loss: 1.942009687423706
Validation loss: 2.0447254876295724

Epoch: 5| Step: 4
Training loss: 2.1470742225646973
Validation loss: 2.0381586949030557

Epoch: 5| Step: 5
Training loss: 2.350003242492676
Validation loss: 2.042480712135633

Epoch: 5| Step: 6
Training loss: 2.139524459838867
Validation loss: 2.048616945743561

Epoch: 5| Step: 7
Training loss: 2.534707546234131
Validation loss: 2.045317694544792

Epoch: 5| Step: 8
Training loss: 2.692979574203491
Validation loss: 2.0498200356960297

Epoch: 5| Step: 9
Training loss: 2.309033155441284
Validation loss: 2.0549345364173255

Epoch: 5| Step: 10
Training loss: 2.399170398712158
Validation loss: 2.0460643817981086

Epoch: 5| Step: 11
Training loss: 2.1133227348327637
Validation loss: 2.037622630596161

Epoch: 72| Step: 0
Training loss: 2.2370080947875977
Validation loss: 2.0379559993743896

Epoch: 5| Step: 1
Training loss: 2.417172908782959
Validation loss: 2.03702919681867

Epoch: 5| Step: 2
Training loss: 2.6646838188171387
Validation loss: 2.039591819047928

Epoch: 5| Step: 3
Training loss: 2.3453774452209473
Validation loss: 2.0388325651486716

Epoch: 5| Step: 4
Training loss: 1.756230115890503
Validation loss: 2.035468508799871

Epoch: 5| Step: 5
Training loss: 2.13335919380188
Validation loss: 2.0410602738459906

Epoch: 5| Step: 6
Training loss: 1.988629698753357
Validation loss: 2.0380659699440002

Epoch: 5| Step: 7
Training loss: 1.84076726436615
Validation loss: 2.0455907583236694

Epoch: 5| Step: 8
Training loss: 2.1904194355010986
Validation loss: 2.050269400080045

Epoch: 5| Step: 9
Training loss: 2.1180906295776367
Validation loss: 2.059349164366722

Epoch: 5| Step: 10
Training loss: 2.776318073272705
Validation loss: 2.075047438343366

Epoch: 5| Step: 11
Training loss: 3.133749008178711
Validation loss: 2.059605518976847

Epoch: 73| Step: 0
Training loss: 2.703326463699341
Validation loss: 2.075542335708936

Epoch: 5| Step: 1
Training loss: 2.3347315788269043
Validation loss: 2.094973703225454

Epoch: 5| Step: 2
Training loss: 2.12313175201416
Validation loss: 2.0853230009476342

Epoch: 5| Step: 3
Training loss: 2.348823070526123
Validation loss: 2.067482680082321

Epoch: 5| Step: 4
Training loss: 2.2263994216918945
Validation loss: 2.0410401125748954

Epoch: 5| Step: 5
Training loss: 2.259794235229492
Validation loss: 2.04130091269811

Epoch: 5| Step: 6
Training loss: 2.103991985321045
Validation loss: 2.0387934297323227

Epoch: 5| Step: 7
Training loss: 1.9767577648162842
Validation loss: 2.046884074807167

Epoch: 5| Step: 8
Training loss: 2.4264864921569824
Validation loss: 2.058888445297877

Epoch: 5| Step: 9
Training loss: 2.264845371246338
Validation loss: 2.0619906038045883

Epoch: 5| Step: 10
Training loss: 2.4766387939453125
Validation loss: 2.0676529308160148

Epoch: 5| Step: 11
Training loss: 0.8435643911361694
Validation loss: 2.0672447234392166

Epoch: 74| Step: 0
Training loss: 2.091593027114868
Validation loss: 2.0696106602748237

Epoch: 5| Step: 1
Training loss: 2.5735340118408203
Validation loss: 2.06951313217481

Epoch: 5| Step: 2
Training loss: 2.0355753898620605
Validation loss: 2.0631449222564697

Epoch: 5| Step: 3
Training loss: 2.6090145111083984
Validation loss: 2.0565598756074905

Epoch: 5| Step: 4
Training loss: 2.4422237873077393
Validation loss: 2.0532038658857346

Epoch: 5| Step: 5
Training loss: 2.495213270187378
Validation loss: 2.051895002524058

Epoch: 5| Step: 6
Training loss: 1.8445003032684326
Validation loss: 2.052736774086952

Epoch: 5| Step: 7
Training loss: 2.106774091720581
Validation loss: 2.048625633120537

Epoch: 5| Step: 8
Training loss: 2.3450920581817627
Validation loss: 2.0442500015099845

Epoch: 5| Step: 9
Training loss: 1.8772990703582764
Validation loss: 2.043924550215403

Epoch: 5| Step: 10
Training loss: 2.15864634513855
Validation loss: 2.040638600786527

Epoch: 5| Step: 11
Training loss: 2.9024009704589844
Validation loss: 2.030746206641197

Epoch: 75| Step: 0
Training loss: 2.1964383125305176
Validation loss: 2.0300455689430237

Epoch: 5| Step: 1
Training loss: 2.280457019805908
Validation loss: 2.0316435992717743

Epoch: 5| Step: 2
Training loss: 2.6392390727996826
Validation loss: 2.0268283685048423

Epoch: 5| Step: 3
Training loss: 2.1168372631073
Validation loss: 2.0232431292533875

Epoch: 5| Step: 4
Training loss: 1.944605827331543
Validation loss: 2.0328844636678696

Epoch: 5| Step: 5
Training loss: 2.2848262786865234
Validation loss: 2.022107263406118

Epoch: 5| Step: 6
Training loss: 2.773559808731079
Validation loss: 2.0220464567343392

Epoch: 5| Step: 7
Training loss: 1.9912989139556885
Validation loss: 2.0147943099339805

Epoch: 5| Step: 8
Training loss: 2.5135397911071777
Validation loss: 2.023193488518397

Epoch: 5| Step: 9
Training loss: 2.420854091644287
Validation loss: 2.0265122652053833

Epoch: 5| Step: 10
Training loss: 1.3048827648162842
Validation loss: 2.0206063836812973

Epoch: 5| Step: 11
Training loss: 1.3018913269042969
Validation loss: 2.0328550338745117

Epoch: 76| Step: 0
Training loss: 2.072828531265259
Validation loss: 2.02635328968366

Epoch: 5| Step: 1
Training loss: 2.5121164321899414
Validation loss: 2.0366605867942176

Epoch: 5| Step: 2
Training loss: 2.3318889141082764
Validation loss: 2.0501963595549264

Epoch: 5| Step: 3
Training loss: 2.1303234100341797
Validation loss: 2.0417835066715875

Epoch: 5| Step: 4
Training loss: 2.6094343662261963
Validation loss: 2.0362954487403235

Epoch: 5| Step: 5
Training loss: 2.161763906478882
Validation loss: 2.0192210574944816

Epoch: 5| Step: 6
Training loss: 2.015389919281006
Validation loss: 2.0279426276683807

Epoch: 5| Step: 7
Training loss: 2.3418309688568115
Validation loss: 2.017642085750898

Epoch: 5| Step: 8
Training loss: 2.1133205890655518
Validation loss: 2.013374924659729

Epoch: 5| Step: 9
Training loss: 2.1340603828430176
Validation loss: 2.019473041097323

Epoch: 5| Step: 10
Training loss: 1.9499953985214233
Validation loss: 2.021498287717501

Epoch: 5| Step: 11
Training loss: 1.8776209354400635
Validation loss: 2.0247966746489205

Epoch: 77| Step: 0
Training loss: 2.0915849208831787
Validation loss: 2.0264162520567575

Epoch: 5| Step: 1
Training loss: 2.1684679985046387
Validation loss: 2.021624277035395

Epoch: 5| Step: 2
Training loss: 2.301492691040039
Validation loss: 2.0238407254219055

Epoch: 5| Step: 3
Training loss: 2.2992565631866455
Validation loss: 2.0118299076954522

Epoch: 5| Step: 4
Training loss: 2.4239048957824707
Validation loss: 2.0123590230941772

Epoch: 5| Step: 5
Training loss: 2.4834625720977783
Validation loss: 2.011381889382998

Epoch: 5| Step: 6
Training loss: 1.7157655954360962
Validation loss: 2.0120341976483664

Epoch: 5| Step: 7
Training loss: 1.903507947921753
Validation loss: 2.0149095406134925

Epoch: 5| Step: 8
Training loss: 2.1908726692199707
Validation loss: 2.01367324590683

Epoch: 5| Step: 9
Training loss: 2.251608371734619
Validation loss: 2.006804679830869

Epoch: 5| Step: 10
Training loss: 2.311938762664795
Validation loss: 2.0108452339967093

Epoch: 5| Step: 11
Training loss: 2.593679904937744
Validation loss: 2.015457491079966

Epoch: 78| Step: 0
Training loss: 2.133354902267456
Validation loss: 2.008170038461685

Epoch: 5| Step: 1
Training loss: 2.2670857906341553
Validation loss: 2.021928315361341

Epoch: 5| Step: 2
Training loss: 2.0985958576202393
Validation loss: 2.0245274752378464

Epoch: 5| Step: 3
Training loss: 2.424915075302124
Validation loss: 2.0384601950645447

Epoch: 5| Step: 4
Training loss: 2.0424931049346924
Validation loss: 2.038804883758227

Epoch: 5| Step: 5
Training loss: 2.6118569374084473
Validation loss: 2.046503633260727

Epoch: 5| Step: 6
Training loss: 3.0049359798431396
Validation loss: 2.0501339534918466

Epoch: 5| Step: 7
Training loss: 2.7118663787841797
Validation loss: 2.0496705919504166

Epoch: 5| Step: 8
Training loss: 1.5754222869873047
Validation loss: 2.0520721723635993

Epoch: 5| Step: 9
Training loss: 1.791532278060913
Validation loss: 2.046212360262871

Epoch: 5| Step: 10
Training loss: 2.0199291706085205
Validation loss: 2.0502479573090873

Epoch: 5| Step: 11
Training loss: 1.9011774063110352
Validation loss: 2.0490713665882745

Epoch: 79| Step: 0
Training loss: 2.278592348098755
Validation loss: 2.0431646605332694

Epoch: 5| Step: 1
Training loss: 2.4777188301086426
Validation loss: 2.04625304043293

Epoch: 5| Step: 2
Training loss: 2.4484875202178955
Validation loss: 2.0393053889274597

Epoch: 5| Step: 3
Training loss: 1.9909509420394897
Validation loss: 2.0399913986523948

Epoch: 5| Step: 4
Training loss: 1.9936240911483765
Validation loss: 2.0331883082787194

Epoch: 5| Step: 5
Training loss: 2.3493270874023438
Validation loss: 2.034853458404541

Epoch: 5| Step: 6
Training loss: 2.0980632305145264
Validation loss: 2.028567746281624

Epoch: 5| Step: 7
Training loss: 2.7636847496032715
Validation loss: 2.026351268092791

Epoch: 5| Step: 8
Training loss: 2.0846595764160156
Validation loss: 2.029558772842089

Epoch: 5| Step: 9
Training loss: 1.9581981897354126
Validation loss: 2.0270882546901703

Epoch: 5| Step: 10
Training loss: 1.9229412078857422
Validation loss: 2.0154655625422797

Epoch: 5| Step: 11
Training loss: 1.9021358489990234
Validation loss: 2.0263364166021347

Epoch: 80| Step: 0
Training loss: 1.7173433303833008
Validation loss: 2.027256394426028

Epoch: 5| Step: 1
Training loss: 2.3080267906188965
Validation loss: 2.0382342835267386

Epoch: 5| Step: 2
Training loss: 1.837440848350525
Validation loss: 2.0364880164464316

Epoch: 5| Step: 3
Training loss: 2.9897522926330566
Validation loss: 2.0288721273342767

Epoch: 5| Step: 4
Training loss: 2.2055556774139404
Validation loss: 2.024789666136106

Epoch: 5| Step: 5
Training loss: 2.259878635406494
Validation loss: 2.0239368975162506

Epoch: 5| Step: 6
Training loss: 2.5764057636260986
Validation loss: 2.031449327866236

Epoch: 5| Step: 7
Training loss: 2.258513927459717
Validation loss: 2.029524803161621

Epoch: 5| Step: 8
Training loss: 2.497668743133545
Validation loss: 2.0144537339607873

Epoch: 5| Step: 9
Training loss: 1.5665794610977173
Validation loss: 2.0107978930075965

Epoch: 5| Step: 10
Training loss: 2.0146536827087402
Validation loss: 2.0232459902763367

Epoch: 5| Step: 11
Training loss: 2.0654468536376953
Validation loss: 2.035905415813128

Epoch: 81| Step: 0
Training loss: 2.415480136871338
Validation loss: 2.0332512855529785

Epoch: 5| Step: 1
Training loss: 2.140981674194336
Validation loss: 2.036465972661972

Epoch: 5| Step: 2
Training loss: 2.0243759155273438
Validation loss: 2.0317078630129495

Epoch: 5| Step: 3
Training loss: 2.913503885269165
Validation loss: 2.0302268713712692

Epoch: 5| Step: 4
Training loss: 2.241581439971924
Validation loss: 2.02309517065684

Epoch: 5| Step: 5
Training loss: 2.4573845863342285
Validation loss: 2.0296523422002792

Epoch: 5| Step: 6
Training loss: 2.3655269145965576
Validation loss: 2.02393967906634

Epoch: 5| Step: 7
Training loss: 2.223649501800537
Validation loss: 2.014266481002172

Epoch: 5| Step: 8
Training loss: 1.8735281229019165
Validation loss: 2.0084900557994843

Epoch: 5| Step: 9
Training loss: 1.936353325843811
Validation loss: 2.0052387913068137

Epoch: 5| Step: 10
Training loss: 1.5733437538146973
Validation loss: 2.0064915120601654

Epoch: 5| Step: 11
Training loss: 2.678626537322998
Validation loss: 2.001323476433754

Epoch: 82| Step: 0
Training loss: 1.9782224893569946
Validation loss: 2.0054818491141

Epoch: 5| Step: 1
Training loss: 2.0502591133117676
Validation loss: 2.029221142331759

Epoch: 5| Step: 2
Training loss: 1.8596389293670654
Validation loss: 2.043422723809878

Epoch: 5| Step: 3
Training loss: 2.5964620113372803
Validation loss: 2.032484163840612

Epoch: 5| Step: 4
Training loss: 2.13942289352417
Validation loss: 2.037616784373919

Epoch: 5| Step: 5
Training loss: 2.319270610809326
Validation loss: 2.014272982875506

Epoch: 5| Step: 6
Training loss: 2.798740863800049
Validation loss: 2.003428816795349

Epoch: 5| Step: 7
Training loss: 2.116049289703369
Validation loss: 1.9979300250609715

Epoch: 5| Step: 8
Training loss: 2.1693005561828613
Validation loss: 2.0090064654747644

Epoch: 5| Step: 9
Training loss: 1.8473927974700928
Validation loss: 2.0152374605337777

Epoch: 5| Step: 10
Training loss: 2.4130101203918457
Validation loss: 2.0190342317024865

Epoch: 5| Step: 11
Training loss: 1.8728245496749878
Validation loss: 2.0360686083634696

Epoch: 83| Step: 0
Training loss: 1.898362159729004
Validation loss: 2.030372286836306

Epoch: 5| Step: 1
Training loss: 2.096553325653076
Validation loss: 2.032523880402247

Epoch: 5| Step: 2
Training loss: 2.2136409282684326
Validation loss: 2.0301723082860312

Epoch: 5| Step: 3
Training loss: 2.131629467010498
Validation loss: 2.0269155303637185

Epoch: 5| Step: 4
Training loss: 1.9261112213134766
Validation loss: 2.0257859379053116

Epoch: 5| Step: 5
Training loss: 1.9533100128173828
Validation loss: 2.020257994532585

Epoch: 5| Step: 6
Training loss: 2.2208571434020996
Validation loss: 2.0295164386431375

Epoch: 5| Step: 7
Training loss: 3.066110849380493
Validation loss: 2.021339366833369

Epoch: 5| Step: 8
Training loss: 2.3432326316833496
Validation loss: 2.017277806997299

Epoch: 5| Step: 9
Training loss: 1.8282842636108398
Validation loss: 2.0153101682662964

Epoch: 5| Step: 10
Training loss: 2.4943509101867676
Validation loss: 2.011837050318718

Epoch: 5| Step: 11
Training loss: 2.6031665802001953
Validation loss: 2.0064778178930283

Epoch: 84| Step: 0
Training loss: 2.2494688034057617
Validation loss: 2.008576641480128

Epoch: 5| Step: 1
Training loss: 2.1993260383605957
Validation loss: 2.007903645435969

Epoch: 5| Step: 2
Training loss: 1.9453563690185547
Validation loss: 2.0063386211792626

Epoch: 5| Step: 3
Training loss: 2.216360092163086
Validation loss: 2.0046228915452957

Epoch: 5| Step: 4
Training loss: 2.4455151557922363
Validation loss: 2.006777043143908

Epoch: 5| Step: 5
Training loss: 2.454723834991455
Validation loss: 2.0017071763674417

Epoch: 5| Step: 6
Training loss: 1.7070391178131104
Validation loss: 2.004721999168396

Epoch: 5| Step: 7
Training loss: 2.6877126693725586
Validation loss: 2.0090581128994622

Epoch: 5| Step: 8
Training loss: 1.9448449611663818
Validation loss: 2.017185479402542

Epoch: 5| Step: 9
Training loss: 2.2300868034362793
Validation loss: 2.0307664573192596

Epoch: 5| Step: 10
Training loss: 1.9177058935165405
Validation loss: 2.028449147939682

Epoch: 5| Step: 11
Training loss: 1.9481054544448853
Validation loss: 2.0211707750956216

Epoch: 85| Step: 0
Training loss: 2.4016690254211426
Validation loss: 2.0381966729958854

Epoch: 5| Step: 1
Training loss: 2.7578938007354736
Validation loss: 2.0508943498134613

Epoch: 5| Step: 2
Training loss: 2.675238847732544
Validation loss: 2.061156695087751

Epoch: 5| Step: 3
Training loss: 1.9780166149139404
Validation loss: 2.0480971237023673

Epoch: 5| Step: 4
Training loss: 2.0435421466827393
Validation loss: 2.0308263848225274

Epoch: 5| Step: 5
Training loss: 2.2737984657287598
Validation loss: 2.00554329653581

Epoch: 5| Step: 6
Training loss: 2.326406717300415
Validation loss: 1.9986072331666946

Epoch: 5| Step: 7
Training loss: 1.516261339187622
Validation loss: 2.000184287627538

Epoch: 5| Step: 8
Training loss: 2.3117034435272217
Validation loss: 1.9963954587777455

Epoch: 5| Step: 9
Training loss: 1.9711809158325195
Validation loss: 2.0092632273832955

Epoch: 5| Step: 10
Training loss: 2.0221920013427734
Validation loss: 2.020061194896698

Epoch: 5| Step: 11
Training loss: 2.5368294715881348
Validation loss: 2.012507210175196

Epoch: 86| Step: 0
Training loss: 2.076106548309326
Validation loss: 2.021894191702207

Epoch: 5| Step: 1
Training loss: 2.0425314903259277
Validation loss: 2.019819368918737

Epoch: 5| Step: 2
Training loss: 1.9870933294296265
Validation loss: 2.016555647055308

Epoch: 5| Step: 3
Training loss: 2.3754801750183105
Validation loss: 2.0087979485591254

Epoch: 5| Step: 4
Training loss: 2.462860345840454
Validation loss: 1.9974230627218883

Epoch: 5| Step: 5
Training loss: 1.9717305898666382
Validation loss: 1.996822213133176

Epoch: 5| Step: 6
Training loss: 2.0333619117736816
Validation loss: 1.9991428206364315

Epoch: 5| Step: 7
Training loss: 2.2643280029296875
Validation loss: 2.005044847726822

Epoch: 5| Step: 8
Training loss: 2.6697258949279785
Validation loss: 2.0164183725913367

Epoch: 5| Step: 9
Training loss: 2.5641369819641113
Validation loss: 2.013045941789945

Epoch: 5| Step: 10
Training loss: 1.7133281230926514
Validation loss: 1.995192547639211

Epoch: 5| Step: 11
Training loss: 2.0490660667419434
Validation loss: 2.003620520234108

Epoch: 87| Step: 0
Training loss: 2.243838310241699
Validation loss: 2.0144503166278205

Epoch: 5| Step: 1
Training loss: 2.4457943439483643
Validation loss: 2.0101726949214935

Epoch: 5| Step: 2
Training loss: 2.025278091430664
Validation loss: 2.005635291337967

Epoch: 5| Step: 3
Training loss: 1.8932945728302002
Validation loss: 2.013208051522573

Epoch: 5| Step: 4
Training loss: 2.2165679931640625
Validation loss: 2.013568232456843

Epoch: 5| Step: 5
Training loss: 2.0200061798095703
Validation loss: 2.0270623614390693

Epoch: 5| Step: 6
Training loss: 2.651531934738159
Validation loss: 2.00424025952816

Epoch: 5| Step: 7
Training loss: 1.8692619800567627
Validation loss: 2.0029591222604117

Epoch: 5| Step: 8
Training loss: 1.799698829650879
Validation loss: 1.9993024071057637

Epoch: 5| Step: 9
Training loss: 2.202183485031128
Validation loss: 2.004040539264679

Epoch: 5| Step: 10
Training loss: 2.3796074390411377
Validation loss: 2.013555963834127

Epoch: 5| Step: 11
Training loss: 2.5141725540161133
Validation loss: 2.000261311729749

Epoch: 88| Step: 0
Training loss: 2.2773830890655518
Validation loss: 1.9933638870716095

Epoch: 5| Step: 1
Training loss: 2.2106423377990723
Validation loss: 1.9961810857057571

Epoch: 5| Step: 2
Training loss: 2.7746105194091797
Validation loss: 1.9981245199839275

Epoch: 5| Step: 3
Training loss: 2.3317692279815674
Validation loss: 1.9999428192774455

Epoch: 5| Step: 4
Training loss: 2.218569278717041
Validation loss: 1.9977893233299255

Epoch: 5| Step: 5
Training loss: 1.5788735151290894
Validation loss: 2.000932311018308

Epoch: 5| Step: 6
Training loss: 1.7672332525253296
Validation loss: 2.0012958347797394

Epoch: 5| Step: 7
Training loss: 2.4561944007873535
Validation loss: 2.0005146314700446

Epoch: 5| Step: 8
Training loss: 2.1232452392578125
Validation loss: 2.003347525993983

Epoch: 5| Step: 9
Training loss: 1.9563499689102173
Validation loss: 2.006441960732142

Epoch: 5| Step: 10
Training loss: 2.2674546241760254
Validation loss: 2.005961462855339

Epoch: 5| Step: 11
Training loss: 1.4549869298934937
Validation loss: 2.0028151323397956

Epoch: 89| Step: 0
Training loss: 2.1530821323394775
Validation loss: 2.0157395750284195

Epoch: 5| Step: 1
Training loss: 2.2767581939697266
Validation loss: 2.010015810529391

Epoch: 5| Step: 2
Training loss: 2.226410388946533
Validation loss: 2.0087659806013107

Epoch: 5| Step: 3
Training loss: 2.012618064880371
Validation loss: 2.0085409382979074

Epoch: 5| Step: 4
Training loss: 1.5022099018096924
Validation loss: 2.004815881450971

Epoch: 5| Step: 5
Training loss: 2.576965808868408
Validation loss: 1.9965986609458923

Epoch: 5| Step: 6
Training loss: 1.9341213703155518
Validation loss: 1.991451953848203

Epoch: 5| Step: 7
Training loss: 1.9322704076766968
Validation loss: 1.9919526775677998

Epoch: 5| Step: 8
Training loss: 2.114943504333496
Validation loss: 1.9895728379487991

Epoch: 5| Step: 9
Training loss: 2.569272994995117
Validation loss: 1.9898102929194768

Epoch: 5| Step: 10
Training loss: 2.4270541667938232
Validation loss: 1.996255914370219

Epoch: 5| Step: 11
Training loss: 2.0360238552093506
Validation loss: 1.9948909034331639

Epoch: 90| Step: 0
Training loss: 1.7642638683319092
Validation loss: 1.9901141971349716

Epoch: 5| Step: 1
Training loss: 1.9596036672592163
Validation loss: 1.9935052047173183

Epoch: 5| Step: 2
Training loss: 1.7781095504760742
Validation loss: 1.9832390050093334

Epoch: 5| Step: 3
Training loss: 1.5506677627563477
Validation loss: 1.993427539865176

Epoch: 5| Step: 4
Training loss: 2.261399030685425
Validation loss: 1.996226782600085

Epoch: 5| Step: 5
Training loss: 2.5179378986358643
Validation loss: 1.994739477833112

Epoch: 5| Step: 6
Training loss: 1.9784313440322876
Validation loss: 1.9910874515771866

Epoch: 5| Step: 7
Training loss: 2.4492762088775635
Validation loss: 1.9979407787322998

Epoch: 5| Step: 8
Training loss: 2.6055824756622314
Validation loss: 1.991785705089569

Epoch: 5| Step: 9
Training loss: 2.268453598022461
Validation loss: 1.9987048904101055

Epoch: 5| Step: 10
Training loss: 2.5392322540283203
Validation loss: 1.9927705824375153

Epoch: 5| Step: 11
Training loss: 1.9443343877792358
Validation loss: 1.9836507191260655

Epoch: 91| Step: 0
Training loss: 1.6190446615219116
Validation loss: 1.9906278997659683

Epoch: 5| Step: 1
Training loss: 2.3554115295410156
Validation loss: 1.985901748140653

Epoch: 5| Step: 2
Training loss: 1.9417941570281982
Validation loss: 1.990162655711174

Epoch: 5| Step: 3
Training loss: 2.337449312210083
Validation loss: 1.9875049789746602

Epoch: 5| Step: 4
Training loss: 1.7947022914886475
Validation loss: 1.992997368176778

Epoch: 5| Step: 5
Training loss: 2.199376106262207
Validation loss: 1.9924941062927246

Epoch: 5| Step: 6
Training loss: 3.0982367992401123
Validation loss: 1.9987431267897289

Epoch: 5| Step: 7
Training loss: 2.0002472400665283
Validation loss: 1.9947989632685978

Epoch: 5| Step: 8
Training loss: 2.353865623474121
Validation loss: 1.9879602392514546

Epoch: 5| Step: 9
Training loss: 1.8086302280426025
Validation loss: 1.9912520398696263

Epoch: 5| Step: 10
Training loss: 1.9064604043960571
Validation loss: 1.990435630083084

Epoch: 5| Step: 11
Training loss: 2.7140157222747803
Validation loss: 1.9911500960588455

Epoch: 92| Step: 0
Training loss: 2.44047212600708
Validation loss: 2.001173267761866

Epoch: 5| Step: 1
Training loss: 2.25523042678833
Validation loss: 2.024777258435885

Epoch: 5| Step: 2
Training loss: 2.426701307296753
Validation loss: 2.0379732151826224

Epoch: 5| Step: 3
Training loss: 2.033482074737549
Validation loss: 2.0149879107872644

Epoch: 5| Step: 4
Training loss: 2.033092975616455
Validation loss: 2.0150005519390106

Epoch: 5| Step: 5
Training loss: 1.8067989349365234
Validation loss: 2.015295217434565

Epoch: 5| Step: 6
Training loss: 2.3272271156311035
Validation loss: 1.998653958241145

Epoch: 5| Step: 7
Training loss: 3.083470106124878
Validation loss: 2.00309681892395

Epoch: 5| Step: 8
Training loss: 1.9926459789276123
Validation loss: 1.9997220784425735

Epoch: 5| Step: 9
Training loss: 1.6961952447891235
Validation loss: 1.9894274522860844

Epoch: 5| Step: 10
Training loss: 1.683617353439331
Validation loss: 1.9882727364699047

Epoch: 5| Step: 11
Training loss: 1.3152564764022827
Validation loss: 1.998976210753123

Epoch: 93| Step: 0
Training loss: 2.4888224601745605
Validation loss: 1.9941057165463765

Epoch: 5| Step: 1
Training loss: 2.0303609371185303
Validation loss: 1.9926488200823467

Epoch: 5| Step: 2
Training loss: 2.2319905757904053
Validation loss: 1.992441475391388

Epoch: 5| Step: 3
Training loss: 1.926811933517456
Validation loss: 1.998954916993777

Epoch: 5| Step: 4
Training loss: 1.9583733081817627
Validation loss: 2.002597898244858

Epoch: 5| Step: 5
Training loss: 2.3311455249786377
Validation loss: 2.0074863135814667

Epoch: 5| Step: 6
Training loss: 1.900583267211914
Validation loss: 2.0066586385170617

Epoch: 5| Step: 7
Training loss: 1.7915241718292236
Validation loss: 2.006244500478109

Epoch: 5| Step: 8
Training loss: 2.1356868743896484
Validation loss: 2.006456270813942

Epoch: 5| Step: 9
Training loss: 2.5466222763061523
Validation loss: 2.0091665436824164

Epoch: 5| Step: 10
Training loss: 1.9037611484527588
Validation loss: 2.0136756151914597

Epoch: 5| Step: 11
Training loss: 2.9511473178863525
Validation loss: 2.0011079013347626

Epoch: 94| Step: 0
Training loss: 2.330754041671753
Validation loss: 1.9849179685115814

Epoch: 5| Step: 1
Training loss: 2.059109926223755
Validation loss: 2.0032409777243934

Epoch: 5| Step: 2
Training loss: 2.911362409591675
Validation loss: 1.9952084173758824

Epoch: 5| Step: 3
Training loss: 1.7581981420516968
Validation loss: 2.0051214347283044

Epoch: 5| Step: 4
Training loss: 2.1762423515319824
Validation loss: 2.0132817228635154

Epoch: 5| Step: 5
Training loss: 1.9286876916885376
Validation loss: 2.0130112767219543

Epoch: 5| Step: 6
Training loss: 2.199725389480591
Validation loss: 2.0097979555527368

Epoch: 5| Step: 7
Training loss: 2.4423160552978516
Validation loss: 2.00944392879804

Epoch: 5| Step: 8
Training loss: 2.069096088409424
Validation loss: 2.013137857119242

Epoch: 5| Step: 9
Training loss: 2.09197998046875
Validation loss: 2.0115203857421875

Epoch: 5| Step: 10
Training loss: 2.1804816722869873
Validation loss: 2.0064518253008523

Epoch: 5| Step: 11
Training loss: 0.9045699238777161
Validation loss: 1.9991192867358525

Epoch: 95| Step: 0
Training loss: 1.7825053930282593
Validation loss: 1.9946352243423462

Epoch: 5| Step: 1
Training loss: 2.0152041912078857
Validation loss: 1.9985164999961853

Epoch: 5| Step: 2
Training loss: 2.0103259086608887
Validation loss: 2.00092605749766

Epoch: 5| Step: 3
Training loss: 1.6782385110855103
Validation loss: 2.0153763939936957

Epoch: 5| Step: 4
Training loss: 2.0179686546325684
Validation loss: 2.0204512178897858

Epoch: 5| Step: 5
Training loss: 2.0430245399475098
Validation loss: 2.0342616587877274

Epoch: 5| Step: 6
Training loss: 2.8227927684783936
Validation loss: 2.0540204644203186

Epoch: 5| Step: 7
Training loss: 1.9897587299346924
Validation loss: 2.043506994843483

Epoch: 5| Step: 8
Training loss: 2.2560482025146484
Validation loss: 2.0241880814234414

Epoch: 5| Step: 9
Training loss: 2.4519190788269043
Validation loss: 2.0008535335461297

Epoch: 5| Step: 10
Training loss: 2.385312795639038
Validation loss: 2.011111502846082

Epoch: 5| Step: 11
Training loss: 3.252354621887207
Validation loss: 1.9927541762590408

Epoch: 96| Step: 0
Training loss: 2.44880747795105
Validation loss: 1.9921516180038452

Epoch: 5| Step: 1
Training loss: 2.1451587677001953
Validation loss: 2.0095598697662354

Epoch: 5| Step: 2
Training loss: 2.348689317703247
Validation loss: 2.025553211569786

Epoch: 5| Step: 3
Training loss: 2.1341331005096436
Validation loss: 2.0270328323046365

Epoch: 5| Step: 4
Training loss: 2.1808104515075684
Validation loss: 2.0390759110450745

Epoch: 5| Step: 5
Training loss: 1.9847652912139893
Validation loss: 2.034004290898641

Epoch: 5| Step: 6
Training loss: 2.20332670211792
Validation loss: 2.030940314133962

Epoch: 5| Step: 7
Training loss: 2.1331706047058105
Validation loss: 2.0357280323902764

Epoch: 5| Step: 8
Training loss: 2.5605852603912354
Validation loss: 2.035718704263369

Epoch: 5| Step: 9
Training loss: 2.185579299926758
Validation loss: 2.0318498611450195

Epoch: 5| Step: 10
Training loss: 1.966962218284607
Validation loss: 2.0286444326241813

Epoch: 5| Step: 11
Training loss: 1.2360414266586304
Validation loss: 2.0167144536972046

Epoch: 97| Step: 0
Training loss: 2.339287519454956
Validation loss: 2.021427477399508

Epoch: 5| Step: 1
Training loss: 1.8004369735717773
Validation loss: 2.0193495005369186

Epoch: 5| Step: 2
Training loss: 2.425534248352051
Validation loss: 2.008682057261467

Epoch: 5| Step: 3
Training loss: 1.8147026300430298
Validation loss: 2.007738302151362

Epoch: 5| Step: 4
Training loss: 2.219156265258789
Validation loss: 2.0023294488588967

Epoch: 5| Step: 5
Training loss: 2.6511378288269043
Validation loss: 2.0032911747694016

Epoch: 5| Step: 6
Training loss: 1.9250106811523438
Validation loss: 2.010030413667361

Epoch: 5| Step: 7
Training loss: 2.2365524768829346
Validation loss: 1.9987670928239822

Epoch: 5| Step: 8
Training loss: 2.136948347091675
Validation loss: 2.0117872456709542

Epoch: 5| Step: 9
Training loss: 2.165548801422119
Validation loss: 2.0171047250429788

Epoch: 5| Step: 10
Training loss: 1.9780772924423218
Validation loss: 2.0244430601596832

Epoch: 5| Step: 11
Training loss: 2.432969808578491
Validation loss: 2.030006468296051

Epoch: 98| Step: 0
Training loss: 2.401869535446167
Validation loss: 2.0276392797629037

Epoch: 5| Step: 1
Training loss: 2.046659231185913
Validation loss: 2.0384672582149506

Epoch: 5| Step: 2
Training loss: 2.054978132247925
Validation loss: 2.03209658463796

Epoch: 5| Step: 3
Training loss: 1.9758708477020264
Validation loss: 2.028518244624138

Epoch: 5| Step: 4
Training loss: 2.2403342723846436
Validation loss: 2.000736966729164

Epoch: 5| Step: 5
Training loss: 1.6774485111236572
Validation loss: 1.996788114309311

Epoch: 5| Step: 6
Training loss: 1.8978989124298096
Validation loss: 1.9958029836416245

Epoch: 5| Step: 7
Training loss: 1.9454562664031982
Validation loss: 1.9965649247169495

Epoch: 5| Step: 8
Training loss: 2.417011260986328
Validation loss: 2.0004781931638718

Epoch: 5| Step: 9
Training loss: 2.244873523712158
Validation loss: 1.9966917683680852

Epoch: 5| Step: 10
Training loss: 2.532614231109619
Validation loss: 2.001312787334124

Epoch: 5| Step: 11
Training loss: 3.0365242958068848
Validation loss: 2.0009954273700714

Epoch: 99| Step: 0
Training loss: 2.2676947116851807
Validation loss: 1.9969841639200847

Epoch: 5| Step: 1
Training loss: 2.449092388153076
Validation loss: 1.993887836734454

Epoch: 5| Step: 2
Training loss: 2.0612339973449707
Validation loss: 1.99460572997729

Epoch: 5| Step: 3
Training loss: 2.1682021617889404
Validation loss: 1.9944144537051518

Epoch: 5| Step: 4
Training loss: 1.7182165384292603
Validation loss: 1.9850416133801143

Epoch: 5| Step: 5
Training loss: 1.6239131689071655
Validation loss: 1.9877020219961803

Epoch: 5| Step: 6
Training loss: 1.9898706674575806
Validation loss: 1.9857917328675587

Epoch: 5| Step: 7
Training loss: 2.020034074783325
Validation loss: 1.9901474962631862

Epoch: 5| Step: 8
Training loss: 2.5890913009643555
Validation loss: 2.0018055588006973

Epoch: 5| Step: 9
Training loss: 2.5460422039031982
Validation loss: 2.012345001101494

Epoch: 5| Step: 10
Training loss: 2.012568712234497
Validation loss: 2.009897619485855

Epoch: 5| Step: 11
Training loss: 3.335507392883301
Validation loss: 1.992849240700404

Epoch: 100| Step: 0
Training loss: 1.9302842617034912
Validation loss: 1.9984870950380962

Epoch: 5| Step: 1
Training loss: 1.7185790538787842
Validation loss: 1.9907401750485103

Epoch: 5| Step: 2
Training loss: 1.8824987411499023
Validation loss: 1.9873368789752324

Epoch: 5| Step: 3
Training loss: 2.064924955368042
Validation loss: 2.0038180698951087

Epoch: 5| Step: 4
Training loss: 2.418470859527588
Validation loss: 2.007922127842903

Epoch: 5| Step: 5
Training loss: 1.930410385131836
Validation loss: 2.0116975406805673

Epoch: 5| Step: 6
Training loss: 2.3039305210113525
Validation loss: 2.014039397239685

Epoch: 5| Step: 7
Training loss: 2.6757707595825195
Validation loss: 2.005281219879786

Epoch: 5| Step: 8
Training loss: 2.4119863510131836
Validation loss: 1.9938624799251556

Epoch: 5| Step: 9
Training loss: 2.1992435455322266
Validation loss: 1.9958495795726776

Epoch: 5| Step: 10
Training loss: 2.050901174545288
Validation loss: 2.002315873901049

Epoch: 5| Step: 11
Training loss: 0.9473838806152344
Validation loss: 1.9879342863957088

Epoch: 101| Step: 0
Training loss: 2.069784641265869
Validation loss: 2.00105090936025

Epoch: 5| Step: 1
Training loss: 1.8336957693099976
Validation loss: 1.9896571238835652

Epoch: 5| Step: 2
Training loss: 2.2947940826416016
Validation loss: 1.9975133687257767

Epoch: 5| Step: 3
Training loss: 2.0118343830108643
Validation loss: 2.0032935589551926

Epoch: 5| Step: 4
Training loss: 1.7161052227020264
Validation loss: 1.9985426465670268

Epoch: 5| Step: 5
Training loss: 2.4843955039978027
Validation loss: 1.9927965203921

Epoch: 5| Step: 6
Training loss: 2.22883939743042
Validation loss: 2.007838855187098

Epoch: 5| Step: 7
Training loss: 1.8135093450546265
Validation loss: 2.0149583717187247

Epoch: 5| Step: 8
Training loss: 2.1922061443328857
Validation loss: 2.0205747485160828

Epoch: 5| Step: 9
Training loss: 2.6086907386779785
Validation loss: 2.0276942203442254

Epoch: 5| Step: 10
Training loss: 2.0164923667907715
Validation loss: 2.0253331462542215

Epoch: 5| Step: 11
Training loss: 1.9440701007843018
Validation loss: 2.0281264632940292

Epoch: 102| Step: 0
Training loss: 2.0397849082946777
Validation loss: 2.0196113934119544

Epoch: 5| Step: 1
Training loss: 2.550725221633911
Validation loss: 2.0231713205575943

Epoch: 5| Step: 2
Training loss: 2.085766315460205
Validation loss: 2.020130902528763

Epoch: 5| Step: 3
Training loss: 1.8878326416015625
Validation loss: 2.0047806849082312

Epoch: 5| Step: 4
Training loss: 1.711592435836792
Validation loss: 2.001069501042366

Epoch: 5| Step: 5
Training loss: 2.429715394973755
Validation loss: 2.0112159798542657

Epoch: 5| Step: 6
Training loss: 1.9732720851898193
Validation loss: 2.003144641717275

Epoch: 5| Step: 7
Training loss: 1.8438024520874023
Validation loss: 2.0041440228621163

Epoch: 5| Step: 8
Training loss: 2.343944549560547
Validation loss: 2.0071337719758353

Epoch: 5| Step: 9
Training loss: 2.1370463371276855
Validation loss: 1.9903741379578908

Epoch: 5| Step: 10
Training loss: 2.1833927631378174
Validation loss: 1.9893837074438732

Epoch: 5| Step: 11
Training loss: 1.9178991317749023
Validation loss: 1.998727098107338

Epoch: 103| Step: 0
Training loss: 2.098649263381958
Validation loss: 1.9851262072722118

Epoch: 5| Step: 1
Training loss: 1.969011902809143
Validation loss: 1.9843974262475967

Epoch: 5| Step: 2
Training loss: 2.0075931549072266
Validation loss: 1.9903993159532547

Epoch: 5| Step: 3
Training loss: 2.2546143531799316
Validation loss: 1.9954868257045746

Epoch: 5| Step: 4
Training loss: 2.1595025062561035
Validation loss: 1.9922905266284943

Epoch: 5| Step: 5
Training loss: 2.135125160217285
Validation loss: 1.9891747583945592

Epoch: 5| Step: 6
Training loss: 2.1957814693450928
Validation loss: 1.995258207122485

Epoch: 5| Step: 7
Training loss: 2.3686509132385254
Validation loss: 1.995172490676244

Epoch: 5| Step: 8
Training loss: 1.9115883111953735
Validation loss: 1.9932248294353485

Epoch: 5| Step: 9
Training loss: 2.1325840950012207
Validation loss: 1.9916112273931503

Epoch: 5| Step: 10
Training loss: 2.2430129051208496
Validation loss: 2.0006067554155984

Epoch: 5| Step: 11
Training loss: 1.8837469816207886
Validation loss: 2.0006044656038284

Epoch: 104| Step: 0
Training loss: 2.7818362712860107
Validation loss: 2.022532323996226

Epoch: 5| Step: 1
Training loss: 2.4335644245147705
Validation loss: 2.011848439772924

Epoch: 5| Step: 2
Training loss: 2.197995662689209
Validation loss: 2.021807183821996

Epoch: 5| Step: 3
Training loss: 1.8725051879882812
Validation loss: 2.019482374191284

Epoch: 5| Step: 4
Training loss: 2.1427388191223145
Validation loss: 2.0115448584159217

Epoch: 5| Step: 5
Training loss: 2.438587188720703
Validation loss: 2.022415647904078

Epoch: 5| Step: 6
Training loss: 1.8506050109863281
Validation loss: 2.0084106673796973

Epoch: 5| Step: 7
Training loss: 1.81387197971344
Validation loss: 2.001750499010086

Epoch: 5| Step: 8
Training loss: 1.617092490196228
Validation loss: 2.002566710114479

Epoch: 5| Step: 9
Training loss: 2.733018398284912
Validation loss: 1.9911511490742366

Epoch: 5| Step: 10
Training loss: 1.611860990524292
Validation loss: 2.0017776439587274

Epoch: 5| Step: 11
Training loss: 1.6207646131515503
Validation loss: 1.9985465208689372

Epoch: 105| Step: 0
Training loss: 2.3750851154327393
Validation loss: 1.9979829291502635

Epoch: 5| Step: 1
Training loss: 2.2525546550750732
Validation loss: 2.020616978406906

Epoch: 5| Step: 2
Training loss: 1.745338797569275
Validation loss: 2.00754048426946

Epoch: 5| Step: 3
Training loss: 2.2674312591552734
Validation loss: 2.0151290595531464

Epoch: 5| Step: 4
Training loss: 1.7868191003799438
Validation loss: 2.0202218691507974

Epoch: 5| Step: 5
Training loss: 2.3166699409484863
Validation loss: 2.0144797414541245

Epoch: 5| Step: 6
Training loss: 2.1680402755737305
Validation loss: 2.0189670572678247

Epoch: 5| Step: 7
Training loss: 1.9817945957183838
Validation loss: 2.0106935451428094

Epoch: 5| Step: 8
Training loss: 2.5227694511413574
Validation loss: 2.003386288881302

Epoch: 5| Step: 9
Training loss: 2.2613742351531982
Validation loss: 1.9977515538533528

Epoch: 5| Step: 10
Training loss: 2.3924973011016846
Validation loss: 1.9962500284115474

Epoch: 5| Step: 11
Training loss: 1.3090161085128784
Validation loss: 1.9848083555698395

Epoch: 106| Step: 0
Training loss: 1.7312129735946655
Validation loss: 1.9867446223894756

Epoch: 5| Step: 1
Training loss: 2.3086466789245605
Validation loss: 1.9881262282530467

Epoch: 5| Step: 2
Training loss: 1.961061716079712
Validation loss: 1.9896606902281444

Epoch: 5| Step: 3
Training loss: 2.001943588256836
Validation loss: 1.9872091213862102

Epoch: 5| Step: 4
Training loss: 1.901017189025879
Validation loss: 1.9876252263784409

Epoch: 5| Step: 5
Training loss: 2.6818466186523438
Validation loss: 1.9972855697075527

Epoch: 5| Step: 6
Training loss: 2.411417245864868
Validation loss: 2.0013149976730347

Epoch: 5| Step: 7
Training loss: 2.5633111000061035
Validation loss: 1.9926265974839528

Epoch: 5| Step: 8
Training loss: 1.8412166833877563
Validation loss: 1.994546761115392

Epoch: 5| Step: 9
Training loss: 2.343705654144287
Validation loss: 2.0197830200195312

Epoch: 5| Step: 10
Training loss: 1.2812961339950562
Validation loss: 2.0119504183530807

Epoch: 5| Step: 11
Training loss: 3.3493170738220215
Validation loss: 2.0173532168070474

Epoch: 107| Step: 0
Training loss: 1.9077911376953125
Validation loss: 2.0062464276949563

Epoch: 5| Step: 1
Training loss: 2.4564201831817627
Validation loss: 2.0214379131793976

Epoch: 5| Step: 2
Training loss: 2.2009201049804688
Validation loss: 2.0110381841659546

Epoch: 5| Step: 3
Training loss: 2.441852331161499
Validation loss: 1.9899401118357976

Epoch: 5| Step: 4
Training loss: 2.1770834922790527
Validation loss: 1.9881843775510788

Epoch: 5| Step: 5
Training loss: 2.0309176445007324
Validation loss: 1.9905946751435597

Epoch: 5| Step: 6
Training loss: 2.2092678546905518
Validation loss: 1.988092248638471

Epoch: 5| Step: 7
Training loss: 1.8409168720245361
Validation loss: 1.9911041657129924

Epoch: 5| Step: 8
Training loss: 2.0969691276550293
Validation loss: 1.9900178362925847

Epoch: 5| Step: 9
Training loss: 1.7514524459838867
Validation loss: 1.9909631709257762

Epoch: 5| Step: 10
Training loss: 2.4618287086486816
Validation loss: 1.990536426504453

Epoch: 5| Step: 11
Training loss: 1.6895380020141602
Validation loss: 1.9945180416107178

Epoch: 108| Step: 0
Training loss: 2.25136137008667
Validation loss: 1.9925564676523209

Epoch: 5| Step: 1
Training loss: 1.8999416828155518
Validation loss: 2.008059208591779

Epoch: 5| Step: 2
Training loss: 2.3515000343322754
Validation loss: 1.99790254731973

Epoch: 5| Step: 3
Training loss: 2.3097035884857178
Validation loss: 2.0054905166228614

Epoch: 5| Step: 4
Training loss: 2.027251720428467
Validation loss: 2.0160418152809143

Epoch: 5| Step: 5
Training loss: 1.922594428062439
Validation loss: 2.0119858334461846

Epoch: 5| Step: 6
Training loss: 1.843979835510254
Validation loss: 2.010322540998459

Epoch: 5| Step: 7
Training loss: 2.2597594261169434
Validation loss: 2.0081114023923874

Epoch: 5| Step: 8
Training loss: 2.1795082092285156
Validation loss: 2.0082242687543235

Epoch: 5| Step: 9
Training loss: 2.1806998252868652
Validation loss: 1.9959391951560974

Epoch: 5| Step: 10
Training loss: 2.257824420928955
Validation loss: 1.9903599073489506

Epoch: 5| Step: 11
Training loss: 1.593127727508545
Validation loss: 1.9886088718970616

Epoch: 109| Step: 0
Training loss: 1.6863219738006592
Validation loss: 1.9965315560499828

Epoch: 5| Step: 1
Training loss: 2.011417865753174
Validation loss: 2.000465840101242

Epoch: 5| Step: 2
Training loss: 2.475963592529297
Validation loss: 2.0004830062389374

Epoch: 5| Step: 3
Training loss: 3.0917954444885254
Validation loss: 2.001643642783165

Epoch: 5| Step: 4
Training loss: 1.8436710834503174
Validation loss: 2.0048504074414573

Epoch: 5| Step: 5
Training loss: 1.9620611667633057
Validation loss: 2.0191012968619666

Epoch: 5| Step: 6
Training loss: 1.464561104774475
Validation loss: 2.019990469018618

Epoch: 5| Step: 7
Training loss: 2.145167827606201
Validation loss: 2.025369400779406

Epoch: 5| Step: 8
Training loss: 1.8249568939208984
Validation loss: 2.015488420923551

Epoch: 5| Step: 9
Training loss: 2.5339269638061523
Validation loss: 2.019994373122851

Epoch: 5| Step: 10
Training loss: 2.2734363079071045
Validation loss: 2.006640156110128

Epoch: 5| Step: 11
Training loss: 1.5822786092758179
Validation loss: 2.0178186694780984

Epoch: 110| Step: 0
Training loss: 2.2637789249420166
Validation loss: 2.008736198147138

Epoch: 5| Step: 1
Training loss: 1.5033812522888184
Validation loss: 1.995034784078598

Epoch: 5| Step: 2
Training loss: 2.494603395462036
Validation loss: 2.0085249692201614

Epoch: 5| Step: 3
Training loss: 2.048941135406494
Validation loss: 2.0132122139135995

Epoch: 5| Step: 4
Training loss: 2.2061705589294434
Validation loss: 2.007329454024633

Epoch: 5| Step: 5
Training loss: 2.132664442062378
Validation loss: 1.9964234083890915

Epoch: 5| Step: 6
Training loss: 2.189876079559326
Validation loss: 1.9923354436953862

Epoch: 5| Step: 7
Training loss: 2.2951138019561768
Validation loss: 2.000044579307238

Epoch: 5| Step: 8
Training loss: 1.9469658136367798
Validation loss: 1.9958860377470653

Epoch: 5| Step: 9
Training loss: 1.5354712009429932
Validation loss: 1.9994285603364308

Epoch: 5| Step: 10
Training loss: 2.235605001449585
Validation loss: 1.9911367346843083

Epoch: 5| Step: 11
Training loss: 3.519317626953125
Validation loss: 1.992187316219012

Epoch: 111| Step: 0
Training loss: 2.2010269165039062
Validation loss: 1.994520977139473

Epoch: 5| Step: 1
Training loss: 2.398486375808716
Validation loss: 2.001650889714559

Epoch: 5| Step: 2
Training loss: 2.1828408241271973
Validation loss: 2.0008413890997567

Epoch: 5| Step: 3
Training loss: 2.785039186477661
Validation loss: 2.0095094541708627

Epoch: 5| Step: 4
Training loss: 2.125941276550293
Validation loss: 1.9996654639641445

Epoch: 5| Step: 5
Training loss: 1.673412561416626
Validation loss: 2.0010478595892587

Epoch: 5| Step: 6
Training loss: 1.8759410381317139
Validation loss: 2.0010563681523004

Epoch: 5| Step: 7
Training loss: 2.059553623199463
Validation loss: 2.003667692343394

Epoch: 5| Step: 8
Training loss: 2.1983516216278076
Validation loss: 2.0199689914782843

Epoch: 5| Step: 9
Training loss: 1.9378635883331299
Validation loss: 2.023734152317047

Epoch: 5| Step: 10
Training loss: 1.7731895446777344
Validation loss: 2.0308320124944053

Epoch: 5| Step: 11
Training loss: 1.7969623804092407
Validation loss: 2.000267371535301

Epoch: 112| Step: 0
Training loss: 2.3292860984802246
Validation loss: 1.9977800746758778

Epoch: 5| Step: 1
Training loss: 2.6785998344421387
Validation loss: 1.9976412306229274

Epoch: 5| Step: 2
Training loss: 2.0882980823516846
Validation loss: 2.007809360822042

Epoch: 5| Step: 3
Training loss: 2.135418176651001
Validation loss: 1.9889267534017563

Epoch: 5| Step: 4
Training loss: 2.666527509689331
Validation loss: 1.990211933851242

Epoch: 5| Step: 5
Training loss: 2.0340216159820557
Validation loss: 1.9996538211901982

Epoch: 5| Step: 6
Training loss: 1.9541857242584229
Validation loss: 1.9992027978102367

Epoch: 5| Step: 7
Training loss: 1.5552042722702026
Validation loss: 2.0038311978181205

Epoch: 5| Step: 8
Training loss: 1.96733820438385
Validation loss: 2.0104149679342904

Epoch: 5| Step: 9
Training loss: 1.7536556720733643
Validation loss: 2.0225788404544196

Epoch: 5| Step: 10
Training loss: 1.9983787536621094
Validation loss: 2.011887719233831

Epoch: 5| Step: 11
Training loss: 1.5381510257720947
Validation loss: 2.0211704125006995

Epoch: 113| Step: 0
Training loss: 1.9228318929672241
Validation loss: 2.0197915037473044

Epoch: 5| Step: 1
Training loss: 2.1886024475097656
Validation loss: 2.014035165309906

Epoch: 5| Step: 2
Training loss: 2.0044145584106445
Validation loss: 2.0042645186185837

Epoch: 5| Step: 3
Training loss: 2.157632350921631
Validation loss: 1.9981900453567505

Epoch: 5| Step: 4
Training loss: 2.0200724601745605
Validation loss: 1.9987948338190715

Epoch: 5| Step: 5
Training loss: 1.9870647192001343
Validation loss: 2.0015538533528647

Epoch: 5| Step: 6
Training loss: 2.0529379844665527
Validation loss: 1.9876019457976024

Epoch: 5| Step: 7
Training loss: 2.359668731689453
Validation loss: 1.9884405384461086

Epoch: 5| Step: 8
Training loss: 2.1065516471862793
Validation loss: 1.989469051361084

Epoch: 5| Step: 9
Training loss: 2.1341843605041504
Validation loss: 1.9933606038490932

Epoch: 5| Step: 10
Training loss: 2.3309874534606934
Validation loss: 1.99994295835495

Epoch: 5| Step: 11
Training loss: 1.7350845336914062
Validation loss: 1.9992354114850361

Epoch: 114| Step: 0
Training loss: 1.752805471420288
Validation loss: 2.0078554848829904

Epoch: 5| Step: 1
Training loss: 2.265242338180542
Validation loss: 2.001585309704145

Epoch: 5| Step: 2
Training loss: 2.3807244300842285
Validation loss: 2.0200364540020623

Epoch: 5| Step: 3
Training loss: 2.483461856842041
Validation loss: 2.026619498928388

Epoch: 5| Step: 4
Training loss: 1.9550081491470337
Validation loss: 2.0335936496655145

Epoch: 5| Step: 5
Training loss: 2.4982378482818604
Validation loss: 2.0359868903954825

Epoch: 5| Step: 6
Training loss: 2.024263620376587
Validation loss: 2.013862202564875

Epoch: 5| Step: 7
Training loss: 1.8951714038848877
Validation loss: 2.0088308652242026

Epoch: 5| Step: 8
Training loss: 2.0299248695373535
Validation loss: 2.013046686848005

Epoch: 5| Step: 9
Training loss: 1.9859497547149658
Validation loss: 1.997922311226527

Epoch: 5| Step: 10
Training loss: 1.7548768520355225
Validation loss: 1.9977319985628128

Epoch: 5| Step: 11
Training loss: 2.512855052947998
Validation loss: 1.9949994285901387

Epoch: 115| Step: 0
Training loss: 1.998395323753357
Validation loss: 1.996163343389829

Epoch: 5| Step: 1
Training loss: 2.4364781379699707
Validation loss: 1.9887765149275463

Epoch: 5| Step: 2
Training loss: 1.813879370689392
Validation loss: 1.9963611116011937

Epoch: 5| Step: 3
Training loss: 1.9049152135849
Validation loss: 2.0024355749289193

Epoch: 5| Step: 4
Training loss: 2.2433807849884033
Validation loss: 1.99323866267999

Epoch: 5| Step: 5
Training loss: 2.042783260345459
Validation loss: 2.003529225786527

Epoch: 5| Step: 6
Training loss: 1.6300239562988281
Validation loss: 2.002803400158882

Epoch: 5| Step: 7
Training loss: 2.0880610942840576
Validation loss: 2.0166041354338327

Epoch: 5| Step: 8
Training loss: 2.301335096359253
Validation loss: 2.028484965364138

Epoch: 5| Step: 9
Training loss: 1.9340025186538696
Validation loss: 2.0433755417664847

Epoch: 5| Step: 10
Training loss: 2.4802327156066895
Validation loss: 2.036229262749354

Epoch: 5| Step: 11
Training loss: 2.6789402961730957
Validation loss: 2.0268033842245736

Epoch: 116| Step: 0
Training loss: 1.9035720825195312
Validation loss: 2.025789588689804

Epoch: 5| Step: 1
Training loss: 2.3393282890319824
Validation loss: 1.9925346871217091

Epoch: 5| Step: 2
Training loss: 1.8596206903457642
Validation loss: 1.9926348974307377

Epoch: 5| Step: 3
Training loss: 2.213148593902588
Validation loss: 1.9911238451798756

Epoch: 5| Step: 4
Training loss: 2.2911627292633057
Validation loss: 1.990410476922989

Epoch: 5| Step: 5
Training loss: 2.1557862758636475
Validation loss: 1.996584450205167

Epoch: 5| Step: 6
Training loss: 2.0610556602478027
Validation loss: 1.9979793230692546

Epoch: 5| Step: 7
Training loss: 2.3545470237731934
Validation loss: 2.0034823467334113

Epoch: 5| Step: 8
Training loss: 2.1004281044006348
Validation loss: 1.9982017874717712

Epoch: 5| Step: 9
Training loss: 2.3923048973083496
Validation loss: 1.991591344277064

Epoch: 5| Step: 10
Training loss: 1.6856123208999634
Validation loss: 1.986840416987737

Epoch: 5| Step: 11
Training loss: 1.8925238847732544
Validation loss: 1.9946006834506989

Epoch: 117| Step: 0
Training loss: 2.1349496841430664
Validation loss: 1.9823054472605388

Epoch: 5| Step: 1
Training loss: 1.900821328163147
Validation loss: 1.9895374129215877

Epoch: 5| Step: 2
Training loss: 2.043940782546997
Validation loss: 1.9988677700360615

Epoch: 5| Step: 3
Training loss: 2.08528208732605
Validation loss: 2.0158981730540595

Epoch: 5| Step: 4
Training loss: 2.3339133262634277
Validation loss: 2.0183033595482507

Epoch: 5| Step: 5
Training loss: 2.4401919841766357
Validation loss: 2.0167932212352753

Epoch: 5| Step: 6
Training loss: 1.4713948965072632
Validation loss: 2.02005872130394

Epoch: 5| Step: 7
Training loss: 1.734062910079956
Validation loss: 2.001295328140259

Epoch: 5| Step: 8
Training loss: 2.4562034606933594
Validation loss: 2.0033962478240332

Epoch: 5| Step: 9
Training loss: 1.874151587486267
Validation loss: 2.0074365784724555

Epoch: 5| Step: 10
Training loss: 2.3122851848602295
Validation loss: 2.013051306207975

Epoch: 5| Step: 11
Training loss: 2.901620864868164
Validation loss: 2.0063882768154144

Epoch: 118| Step: 0
Training loss: 2.2827115058898926
Validation loss: 2.017765522003174

Epoch: 5| Step: 1
Training loss: 2.1148746013641357
Validation loss: 2.0076939165592194

Epoch: 5| Step: 2
Training loss: 2.798778533935547
Validation loss: 1.998625288407008

Epoch: 5| Step: 3
Training loss: 2.2394416332244873
Validation loss: 1.9975569347540538

Epoch: 5| Step: 4
Training loss: 2.4397757053375244
Validation loss: 1.997441291809082

Epoch: 5| Step: 5
Training loss: 1.969927191734314
Validation loss: 1.9928639928499858

Epoch: 5| Step: 6
Training loss: 1.7486366033554077
Validation loss: 1.9997887810071309

Epoch: 5| Step: 7
Training loss: 1.9038022756576538
Validation loss: 2.0022292733192444

Epoch: 5| Step: 8
Training loss: 1.9574133157730103
Validation loss: 1.9954903523127239

Epoch: 5| Step: 9
Training loss: 2.1417109966278076
Validation loss: 1.9936971614758174

Epoch: 5| Step: 10
Training loss: 1.5983242988586426
Validation loss: 2.0101742148399353

Epoch: 5| Step: 11
Training loss: 1.1466671228408813
Validation loss: 2.015731150905291

Epoch: 119| Step: 0
Training loss: 2.6028130054473877
Validation loss: 2.0106884638468423

Epoch: 5| Step: 1
Training loss: 2.460771083831787
Validation loss: 2.0088701993227005

Epoch: 5| Step: 2
Training loss: 2.196843147277832
Validation loss: 2.001947119832039

Epoch: 5| Step: 3
Training loss: 2.470400333404541
Validation loss: 2.0021636386712394

Epoch: 5| Step: 4
Training loss: 2.0940299034118652
Validation loss: 2.004130313793818

Epoch: 5| Step: 5
Training loss: 1.976191759109497
Validation loss: 2.001534581184387

Epoch: 5| Step: 6
Training loss: 1.8165661096572876
Validation loss: 2.009972741206487

Epoch: 5| Step: 7
Training loss: 1.9824073314666748
Validation loss: 2.0100078334410987

Epoch: 5| Step: 8
Training loss: 1.956521987915039
Validation loss: 2.0100247661272683

Epoch: 5| Step: 9
Training loss: 1.9043827056884766
Validation loss: 2.0076785882314048

Epoch: 5| Step: 10
Training loss: 1.8889888525009155
Validation loss: 2.0117780417203903

Epoch: 5| Step: 11
Training loss: 1.9255858659744263
Validation loss: 1.99916077653567

Epoch: 120| Step: 0
Training loss: 2.3129453659057617
Validation loss: 2.0135327031215033

Epoch: 5| Step: 1
Training loss: 1.642695665359497
Validation loss: 2.0092953393856683

Epoch: 5| Step: 2
Training loss: 2.197533130645752
Validation loss: 2.0271090219418206

Epoch: 5| Step: 3
Training loss: 2.6150639057159424
Validation loss: 2.0506998151540756

Epoch: 5| Step: 4
Training loss: 1.8677610158920288
Validation loss: 2.0854385644197464

Epoch: 5| Step: 5
Training loss: 1.9715306758880615
Validation loss: 2.103261282046636

Epoch: 5| Step: 6
Training loss: 2.206068277359009
Validation loss: 2.056545997659365

Epoch: 5| Step: 7
Training loss: 2.020766496658325
Validation loss: 2.0336287766695023

Epoch: 5| Step: 8
Training loss: 1.8886678218841553
Validation loss: 2.0333772003650665

Epoch: 5| Step: 9
Training loss: 2.4086644649505615
Validation loss: 2.0146739184856415

Epoch: 5| Step: 10
Training loss: 1.9610525369644165
Validation loss: 2.0141703138748803

Epoch: 5| Step: 11
Training loss: 2.4211604595184326
Validation loss: 2.010170037547747

Epoch: 121| Step: 0
Training loss: 2.3799190521240234
Validation loss: 2.00862288971742

Epoch: 5| Step: 1
Training loss: 1.7405792474746704
Validation loss: 2.01712566614151

Epoch: 5| Step: 2
Training loss: 2.3934080600738525
Validation loss: 2.008586754401525

Epoch: 5| Step: 3
Training loss: 1.7691380977630615
Validation loss: 2.0132563511530557

Epoch: 5| Step: 4
Training loss: 1.8084547519683838
Validation loss: 2.009101912379265

Epoch: 5| Step: 5
Training loss: 2.2469983100891113
Validation loss: 2.004819224278132

Epoch: 5| Step: 6
Training loss: 2.2755398750305176
Validation loss: 2.008914053440094

Epoch: 5| Step: 7
Training loss: 2.2178900241851807
Validation loss: 1.9999067982037861

Epoch: 5| Step: 8
Training loss: 1.8327080011367798
Validation loss: 2.007721245288849

Epoch: 5| Step: 9
Training loss: 2.304202079772949
Validation loss: 1.99516923725605

Epoch: 5| Step: 10
Training loss: 2.14197039604187
Validation loss: 1.9926321307818096

Epoch: 5| Step: 11
Training loss: 2.969632148742676
Validation loss: 1.9938989132642746

Epoch: 122| Step: 0
Training loss: 2.1366219520568848
Validation loss: 1.9974810232718785

Epoch: 5| Step: 1
Training loss: 1.9751203060150146
Validation loss: 2.0088057766358056

Epoch: 5| Step: 2
Training loss: 1.9527193307876587
Validation loss: 2.0125097831090293

Epoch: 5| Step: 3
Training loss: 2.058807849884033
Validation loss: 2.038442383209864

Epoch: 5| Step: 4
Training loss: 2.2936654090881348
Validation loss: 2.045980582634608

Epoch: 5| Step: 5
Training loss: 1.692724585533142
Validation loss: 2.0517145693302155

Epoch: 5| Step: 6
Training loss: 2.315199136734009
Validation loss: 2.0548251618941626

Epoch: 5| Step: 7
Training loss: 1.7343820333480835
Validation loss: 2.0459514558315277

Epoch: 5| Step: 8
Training loss: 2.489471912384033
Validation loss: 2.035287171602249

Epoch: 5| Step: 9
Training loss: 2.099020004272461
Validation loss: 2.0446924964586892

Epoch: 5| Step: 10
Training loss: 2.3668270111083984
Validation loss: 2.039566626151403

Epoch: 5| Step: 11
Training loss: 1.892823576927185
Validation loss: 2.01967845360438

Epoch: 123| Step: 0
Training loss: 2.077604293823242
Validation loss: 2.016962746779124

Epoch: 5| Step: 1
Training loss: 2.715085983276367
Validation loss: 2.0159606337547302

Epoch: 5| Step: 2
Training loss: 2.157463550567627
Validation loss: 2.016575038433075

Epoch: 5| Step: 3
Training loss: 1.828089714050293
Validation loss: 2.036900962392489

Epoch: 5| Step: 4
Training loss: 2.1883606910705566
Validation loss: 2.0482597847779593

Epoch: 5| Step: 5
Training loss: 2.6517937183380127
Validation loss: 2.0447096278270087

Epoch: 5| Step: 6
Training loss: 1.6779844760894775
Validation loss: 2.055630087852478

Epoch: 5| Step: 7
Training loss: 2.2468082904815674
Validation loss: 2.0583826899528503

Epoch: 5| Step: 8
Training loss: 2.102175712585449
Validation loss: 2.0582398573557534

Epoch: 5| Step: 9
Training loss: 2.33536696434021
Validation loss: 2.047015363971392

Epoch: 5| Step: 10
Training loss: 2.1773681640625
Validation loss: 2.045356889565786

Epoch: 5| Step: 11
Training loss: 1.3546185493469238
Validation loss: 2.032894750436147

Epoch: 124| Step: 0
Training loss: 2.2496466636657715
Validation loss: 2.01607054968675

Epoch: 5| Step: 1
Training loss: 1.974595308303833
Validation loss: 2.0125074237585068

Epoch: 5| Step: 2
Training loss: 2.4385812282562256
Validation loss: 2.0130457083384194

Epoch: 5| Step: 3
Training loss: 1.4902172088623047
Validation loss: 2.001933753490448

Epoch: 5| Step: 4
Training loss: 2.249227523803711
Validation loss: 2.009088625510534

Epoch: 5| Step: 5
Training loss: 1.9031760692596436
Validation loss: 2.0048608581225076

Epoch: 5| Step: 6
Training loss: 2.5952415466308594
Validation loss: 2.0153548816839852

Epoch: 5| Step: 7
Training loss: 2.1200904846191406
Validation loss: 2.0247879276672998

Epoch: 5| Step: 8
Training loss: 1.8214813470840454
Validation loss: 2.0504938761393228

Epoch: 5| Step: 9
Training loss: 2.03044056892395
Validation loss: 2.05075574417909

Epoch: 5| Step: 10
Training loss: 2.1050143241882324
Validation loss: 2.0596804370482764

Epoch: 5| Step: 11
Training loss: 1.0747134685516357
Validation loss: 2.054976761341095

Epoch: 125| Step: 0
Training loss: 2.067894458770752
Validation loss: 2.067086641987165

Epoch: 5| Step: 1
Training loss: 1.9538767337799072
Validation loss: 2.085841496785482

Epoch: 5| Step: 2
Training loss: 1.7736504077911377
Validation loss: 2.0639823426802955

Epoch: 5| Step: 3
Training loss: 2.1796698570251465
Validation loss: 2.042661130428314

Epoch: 5| Step: 4
Training loss: 2.2996954917907715
Validation loss: 2.031788910428683

Epoch: 5| Step: 5
Training loss: 1.8396167755126953
Validation loss: 2.023817186554273

Epoch: 5| Step: 6
Training loss: 2.1043713092803955
Validation loss: 2.0146120190620422

Epoch: 5| Step: 7
Training loss: 1.905921220779419
Validation loss: 2.0159342288970947

Epoch: 5| Step: 8
Training loss: 2.706778049468994
Validation loss: 2.020114481449127

Epoch: 5| Step: 9
Training loss: 2.3532090187072754
Validation loss: 2.014433890581131

Epoch: 5| Step: 10
Training loss: 2.0887198448181152
Validation loss: 2.021253153681755

Epoch: 5| Step: 11
Training loss: 2.211078643798828
Validation loss: 2.023134777943293

Epoch: 126| Step: 0
Training loss: 2.1697840690612793
Validation loss: 2.032031148672104

Epoch: 5| Step: 1
Training loss: 2.0809273719787598
Validation loss: 2.0158186703920364

Epoch: 5| Step: 2
Training loss: 1.9524362087249756
Validation loss: 2.0210165033737817

Epoch: 5| Step: 3
Training loss: 2.600641965866089
Validation loss: 2.0225000083446503

Epoch: 5| Step: 4
Training loss: 2.000760793685913
Validation loss: 2.0246445337931314

Epoch: 5| Step: 5
Training loss: 2.3404223918914795
Validation loss: 2.0105262249708176

Epoch: 5| Step: 6
Training loss: 1.782549262046814
Validation loss: 2.019838879505793

Epoch: 5| Step: 7
Training loss: 2.3468525409698486
Validation loss: 2.0085111210743585

Epoch: 5| Step: 8
Training loss: 1.6965560913085938
Validation loss: 2.01518481473128

Epoch: 5| Step: 9
Training loss: 1.6963253021240234
Validation loss: 2.0309138049681983

Epoch: 5| Step: 10
Training loss: 2.6667075157165527
Validation loss: 2.042741353313128

Epoch: 5| Step: 11
Training loss: 1.8207231760025024
Validation loss: 2.066792239745458

Epoch: 127| Step: 0
Training loss: 2.5817580223083496
Validation loss: 2.068688839673996

Epoch: 5| Step: 1
Training loss: 1.9849185943603516
Validation loss: 2.0605179568131766

Epoch: 5| Step: 2
Training loss: 2.168684959411621
Validation loss: 2.044499064485232

Epoch: 5| Step: 3
Training loss: 2.119591236114502
Validation loss: 2.0303590397040048

Epoch: 5| Step: 4
Training loss: 1.748726487159729
Validation loss: 2.027125229438146

Epoch: 5| Step: 5
Training loss: 1.6338367462158203
Validation loss: 2.0191230128208795

Epoch: 5| Step: 6
Training loss: 2.1704049110412598
Validation loss: 2.024632583061854

Epoch: 5| Step: 7
Training loss: 2.099224328994751
Validation loss: 2.0295074383417764

Epoch: 5| Step: 8
Training loss: 1.830457329750061
Validation loss: 2.0288971861203513

Epoch: 5| Step: 9
Training loss: 2.2536587715148926
Validation loss: 2.0428073406219482

Epoch: 5| Step: 10
Training loss: 2.294726848602295
Validation loss: 2.04345832268397

Epoch: 5| Step: 11
Training loss: 2.6633739471435547
Validation loss: 2.049925754467646

Epoch: 128| Step: 0
Training loss: 2.351841449737549
Validation loss: 2.05355196694533

Epoch: 5| Step: 1
Training loss: 1.8084598779678345
Validation loss: 2.0545846968889236

Epoch: 5| Step: 2
Training loss: 2.0308966636657715
Validation loss: 2.0463651220003762

Epoch: 5| Step: 3
Training loss: 1.9544662237167358
Validation loss: 2.0432183841864267

Epoch: 5| Step: 4
Training loss: 2.4982757568359375
Validation loss: 2.0206540673971176

Epoch: 5| Step: 5
Training loss: 2.4304287433624268
Validation loss: 2.019872630635897

Epoch: 5| Step: 6
Training loss: 2.099975824356079
Validation loss: 2.014148622751236

Epoch: 5| Step: 7
Training loss: 1.6791841983795166
Validation loss: 2.0143516610066095

Epoch: 5| Step: 8
Training loss: 2.1925933361053467
Validation loss: 2.018492857615153

Epoch: 5| Step: 9
Training loss: 1.7504870891571045
Validation loss: 2.024635930856069

Epoch: 5| Step: 10
Training loss: 2.0082080364227295
Validation loss: 2.025664816300074

Epoch: 5| Step: 11
Training loss: 2.19881534576416
Validation loss: 2.034828926126162

Epoch: 129| Step: 0
Training loss: 1.6268866062164307
Validation loss: 2.0426082611083984

Epoch: 5| Step: 1
Training loss: 2.583590030670166
Validation loss: 2.0558705081542334

Epoch: 5| Step: 2
Training loss: 1.7943025827407837
Validation loss: 2.056191603342692

Epoch: 5| Step: 3
Training loss: 2.1692233085632324
Validation loss: 2.0577888637781143

Epoch: 5| Step: 4
Training loss: 2.2350685596466064
Validation loss: 2.069032698869705

Epoch: 5| Step: 5
Training loss: 2.2695279121398926
Validation loss: 2.0617878784736

Epoch: 5| Step: 6
Training loss: 1.8739439249038696
Validation loss: 2.0562493006388345

Epoch: 5| Step: 7
Training loss: 1.665026068687439
Validation loss: 2.0524604817231498

Epoch: 5| Step: 8
Training loss: 2.1468632221221924
Validation loss: 2.044655924042066

Epoch: 5| Step: 9
Training loss: 2.339067220687866
Validation loss: 2.040111482143402

Epoch: 5| Step: 10
Training loss: 1.8957675695419312
Validation loss: 2.0350912113984427

Epoch: 5| Step: 11
Training loss: 2.492762565612793
Validation loss: 2.0152206420898438

Epoch: 130| Step: 0
Training loss: 1.7992002964019775
Validation loss: 2.0064732134342194

Epoch: 5| Step: 1
Training loss: 2.119715929031372
Validation loss: 2.0175609091917672

Epoch: 5| Step: 2
Training loss: 2.3494515419006348
Validation loss: 2.018267591794332

Epoch: 5| Step: 3
Training loss: 2.2900567054748535
Validation loss: 2.0115846743186316

Epoch: 5| Step: 4
Training loss: 1.6030709743499756
Validation loss: 2.0155817419290543

Epoch: 5| Step: 5
Training loss: 2.2225794792175293
Validation loss: 2.0077751874923706

Epoch: 5| Step: 6
Training loss: 2.146562337875366
Validation loss: 2.014344091216723

Epoch: 5| Step: 7
Training loss: 2.6086456775665283
Validation loss: 2.0121067613363266

Epoch: 5| Step: 8
Training loss: 1.9462913274765015
Validation loss: 2.013670434554418

Epoch: 5| Step: 9
Training loss: 1.8511463403701782
Validation loss: 2.0127128710349402

Epoch: 5| Step: 10
Training loss: 2.0984253883361816
Validation loss: 2.0280325214068093

Epoch: 5| Step: 11
Training loss: 1.4509499073028564
Validation loss: 2.0325701435407004

Epoch: 131| Step: 0
Training loss: 1.930797815322876
Validation loss: 2.0487736662228904

Epoch: 5| Step: 1
Training loss: 1.8528251647949219
Validation loss: 2.0418007522821426

Epoch: 5| Step: 2
Training loss: 1.9386354684829712
Validation loss: 2.0613639702399573

Epoch: 5| Step: 3
Training loss: 1.8139164447784424
Validation loss: 2.044098456700643

Epoch: 5| Step: 4
Training loss: 1.9165232181549072
Validation loss: 2.033173238237699

Epoch: 5| Step: 5
Training loss: 2.045466899871826
Validation loss: 2.037312299013138

Epoch: 5| Step: 6
Training loss: 1.6976954936981201
Validation loss: 2.020697404940923

Epoch: 5| Step: 7
Training loss: 1.8310165405273438
Validation loss: 2.012990112106005

Epoch: 5| Step: 8
Training loss: 2.654646396636963
Validation loss: 2.0162682930628457

Epoch: 5| Step: 9
Training loss: 1.8190767765045166
Validation loss: 2.0157884856065116

Epoch: 5| Step: 10
Training loss: 2.955247402191162
Validation loss: 2.0162070790926614

Epoch: 5| Step: 11
Training loss: 2.3450522422790527
Validation loss: 2.0174501637617746

Epoch: 132| Step: 0
Training loss: 1.6222854852676392
Validation loss: 2.018693750103315

Epoch: 5| Step: 1
Training loss: 2.0298357009887695
Validation loss: 2.027199005087217

Epoch: 5| Step: 2
Training loss: 2.177245616912842
Validation loss: 2.026181702812513

Epoch: 5| Step: 3
Training loss: 1.8188985586166382
Validation loss: 2.031069075067838

Epoch: 5| Step: 4
Training loss: 1.958664894104004
Validation loss: 2.0392747819423676

Epoch: 5| Step: 5
Training loss: 1.6995818614959717
Validation loss: 2.033813307682673

Epoch: 5| Step: 6
Training loss: 2.4717211723327637
Validation loss: 2.034515365958214

Epoch: 5| Step: 7
Training loss: 1.7735754251480103
Validation loss: 2.046206459403038

Epoch: 5| Step: 8
Training loss: 2.051694393157959
Validation loss: 2.033967539668083

Epoch: 5| Step: 9
Training loss: 2.3737380504608154
Validation loss: 2.029892901579539

Epoch: 5| Step: 10
Training loss: 2.4985783100128174
Validation loss: 2.0399795323610306

Epoch: 5| Step: 11
Training loss: 1.7585811614990234
Validation loss: 2.031541715065638

Epoch: 133| Step: 0
Training loss: 2.174339771270752
Validation loss: 2.0384876181681952

Epoch: 5| Step: 1
Training loss: 1.9260905981063843
Validation loss: 2.026509935657183

Epoch: 5| Step: 2
Training loss: 1.8722072839736938
Validation loss: 2.040922313928604

Epoch: 5| Step: 3
Training loss: 1.9827913045883179
Validation loss: 2.04365066687266

Epoch: 5| Step: 4
Training loss: 2.2770962715148926
Validation loss: 2.032867436607679

Epoch: 5| Step: 5
Training loss: 2.213435649871826
Validation loss: 2.0256282836198807

Epoch: 5| Step: 6
Training loss: 1.864139199256897
Validation loss: 2.0269043693939843

Epoch: 5| Step: 7
Training loss: 2.125622272491455
Validation loss: 2.0299043506383896

Epoch: 5| Step: 8
Training loss: 1.895420789718628
Validation loss: 2.0291213939587274

Epoch: 5| Step: 9
Training loss: 1.8998310565948486
Validation loss: 2.045482963323593

Epoch: 5| Step: 10
Training loss: 2.0313520431518555
Validation loss: 2.047591278950373

Epoch: 5| Step: 11
Training loss: 3.0368337631225586
Validation loss: 2.0513076335191727

Epoch: 134| Step: 0
Training loss: 2.380967617034912
Validation loss: 2.039861078063647

Epoch: 5| Step: 1
Training loss: 1.814840316772461
Validation loss: 2.0283402850230536

Epoch: 5| Step: 2
Training loss: 2.332031726837158
Validation loss: 2.0154791126648584

Epoch: 5| Step: 3
Training loss: 1.9841201305389404
Validation loss: 2.021253431836764

Epoch: 5| Step: 4
Training loss: 1.8155415058135986
Validation loss: 2.0174247523148856

Epoch: 5| Step: 5
Training loss: 2.1514172554016113
Validation loss: 2.0160227368275323

Epoch: 5| Step: 6
Training loss: 2.5995888710021973
Validation loss: 2.013229727745056

Epoch: 5| Step: 7
Training loss: 1.6152318716049194
Validation loss: 2.020098939538002

Epoch: 5| Step: 8
Training loss: 1.9995689392089844
Validation loss: 2.021134967605273

Epoch: 5| Step: 9
Training loss: 2.018472194671631
Validation loss: 2.0369506826003394

Epoch: 5| Step: 10
Training loss: 1.8518593311309814
Validation loss: 2.05796351035436

Epoch: 5| Step: 11
Training loss: 2.554880142211914
Validation loss: 2.051421364148458

Epoch: 135| Step: 0
Training loss: 2.1047816276550293
Validation loss: 2.056209921836853

Epoch: 5| Step: 1
Training loss: 2.061234951019287
Validation loss: 2.046415090560913

Epoch: 5| Step: 2
Training loss: 1.8878380060195923
Validation loss: 2.0358885874350867

Epoch: 5| Step: 3
Training loss: 1.467594861984253
Validation loss: 2.0329182545344033

Epoch: 5| Step: 4
Training loss: 2.088682174682617
Validation loss: 2.0327967504660287

Epoch: 5| Step: 5
Training loss: 1.8138574361801147
Validation loss: 2.0322999954223633

Epoch: 5| Step: 6
Training loss: 1.7824112176895142
Validation loss: 2.0378342966238656

Epoch: 5| Step: 7
Training loss: 2.5976333618164062
Validation loss: 2.0323361406723657

Epoch: 5| Step: 8
Training loss: 2.6757562160491943
Validation loss: 2.0521509448687234

Epoch: 5| Step: 9
Training loss: 2.0453429222106934
Validation loss: 2.040358950694402

Epoch: 5| Step: 10
Training loss: 1.8280445337295532
Validation loss: 2.054108425974846

Epoch: 5| Step: 11
Training loss: 2.172314167022705
Validation loss: 2.0457979490359626

Epoch: 136| Step: 0
Training loss: 2.0393319129943848
Validation loss: 2.052916705608368

Epoch: 5| Step: 1
Training loss: 2.172715902328491
Validation loss: 2.0458947171767554

Epoch: 5| Step: 2
Training loss: 2.5960633754730225
Validation loss: 2.0468672017256417

Epoch: 5| Step: 3
Training loss: 2.13356351852417
Validation loss: 2.0551041662693024

Epoch: 5| Step: 4
Training loss: 1.7522971630096436
Validation loss: 2.0592311372359595

Epoch: 5| Step: 5
Training loss: 2.1828701496124268
Validation loss: 2.06129785378774

Epoch: 5| Step: 6
Training loss: 1.2987180948257446
Validation loss: 2.048889329036077

Epoch: 5| Step: 7
Training loss: 1.71871817111969
Validation loss: 2.0620123942693076

Epoch: 5| Step: 8
Training loss: 2.019465923309326
Validation loss: 2.051509196559588

Epoch: 5| Step: 9
Training loss: 2.3590445518493652
Validation loss: 2.064786876241366

Epoch: 5| Step: 10
Training loss: 1.8574192523956299
Validation loss: 2.071251685420672

Epoch: 5| Step: 11
Training loss: 2.631783962249756
Validation loss: 2.0749528457721076

Epoch: 137| Step: 0
Training loss: 2.1246800422668457
Validation loss: 2.073100979129473

Epoch: 5| Step: 1
Training loss: 2.4858226776123047
Validation loss: 2.075892368952433

Epoch: 5| Step: 2
Training loss: 2.029711961746216
Validation loss: 2.0770237743854523

Epoch: 5| Step: 3
Training loss: 2.128279209136963
Validation loss: 2.0879554450511932

Epoch: 5| Step: 4
Training loss: 2.0697789192199707
Validation loss: 2.0745488852262497

Epoch: 5| Step: 5
Training loss: 1.5802764892578125
Validation loss: 2.0487718184789023

Epoch: 5| Step: 6
Training loss: 2.4380850791931152
Validation loss: 2.0654613176981607

Epoch: 5| Step: 7
Training loss: 2.1669864654541016
Validation loss: 2.043381397922834

Epoch: 5| Step: 8
Training loss: 2.0792288780212402
Validation loss: 2.040623893340429

Epoch: 5| Step: 9
Training loss: 1.8661701679229736
Validation loss: 2.059362838665644

Epoch: 5| Step: 10
Training loss: 1.6445605754852295
Validation loss: 2.04398483534654

Epoch: 5| Step: 11
Training loss: 2.6827754974365234
Validation loss: 2.037017434835434

Epoch: 138| Step: 0
Training loss: 1.96164071559906
Validation loss: 2.047869419058164

Epoch: 5| Step: 1
Training loss: 1.637044906616211
Validation loss: 2.067709187666575

Epoch: 5| Step: 2
Training loss: 2.1578288078308105
Validation loss: 2.064276933670044

Epoch: 5| Step: 3
Training loss: 1.624715805053711
Validation loss: 2.078319971760114

Epoch: 5| Step: 4
Training loss: 2.0119402408599854
Validation loss: 2.0921666771173477

Epoch: 5| Step: 5
Training loss: 2.273045778274536
Validation loss: 2.0852002104123435

Epoch: 5| Step: 6
Training loss: 2.340771436691284
Validation loss: 2.069833815097809

Epoch: 5| Step: 7
Training loss: 2.20762300491333
Validation loss: 2.0816223124663034

Epoch: 5| Step: 8
Training loss: 2.403722047805786
Validation loss: 2.0832377870877585

Epoch: 5| Step: 9
Training loss: 1.9294116497039795
Validation loss: 2.0713827461004257

Epoch: 5| Step: 10
Training loss: 1.9639571905136108
Validation loss: 2.0461391607920327

Epoch: 5| Step: 11
Training loss: 1.1117961406707764
Validation loss: 2.0376194963852563

Epoch: 139| Step: 0
Training loss: 1.7960777282714844
Validation loss: 2.0507184018691382

Epoch: 5| Step: 1
Training loss: 1.860587477684021
Validation loss: 2.041726882259051

Epoch: 5| Step: 2
Training loss: 1.833433747291565
Validation loss: 2.050686314702034

Epoch: 5| Step: 3
Training loss: 2.0963847637176514
Validation loss: 2.0495676348606744

Epoch: 5| Step: 4
Training loss: 2.221644163131714
Validation loss: 2.0425499429305396

Epoch: 5| Step: 5
Training loss: 2.1971068382263184
Validation loss: 2.0548672328392663

Epoch: 5| Step: 6
Training loss: 1.8820898532867432
Validation loss: 2.0573061108589172

Epoch: 5| Step: 7
Training loss: 2.2923693656921387
Validation loss: 2.078894476095835

Epoch: 5| Step: 8
Training loss: 1.7493650913238525
Validation loss: 2.0719525714715323

Epoch: 5| Step: 9
Training loss: 2.156667470932007
Validation loss: 2.0835632234811783

Epoch: 5| Step: 10
Training loss: 2.218146800994873
Validation loss: 2.0819309701522193

Epoch: 5| Step: 11
Training loss: 1.4976966381072998
Validation loss: 2.0789873550335565

Epoch: 140| Step: 0
Training loss: 2.069079875946045
Validation loss: 2.075171152750651

Epoch: 5| Step: 1
Training loss: 1.7829192876815796
Validation loss: 2.0688996811707816

Epoch: 5| Step: 2
Training loss: 2.129666566848755
Validation loss: 2.0720654179652533

Epoch: 5| Step: 3
Training loss: 2.1994569301605225
Validation loss: 2.0552810430526733

Epoch: 5| Step: 4
Training loss: 1.490839958190918
Validation loss: 2.060116504629453

Epoch: 5| Step: 5
Training loss: 1.9052759408950806
Validation loss: 2.0552989741166434

Epoch: 5| Step: 6
Training loss: 1.7504100799560547
Validation loss: 2.0554240296284356

Epoch: 5| Step: 7
Training loss: 1.8020645380020142
Validation loss: 2.0563109318415322

Epoch: 5| Step: 8
Training loss: 1.9900871515274048
Validation loss: 2.0642819007237754

Epoch: 5| Step: 9
Training loss: 2.4332947731018066
Validation loss: 2.0649503767490387

Epoch: 5| Step: 10
Training loss: 2.2439656257629395
Validation loss: 2.071920429666837

Epoch: 5| Step: 11
Training loss: 3.585437297821045
Validation loss: 2.0704455276330314

Epoch: 141| Step: 0
Training loss: 2.2260146141052246
Validation loss: 2.0575448324282966

Epoch: 5| Step: 1
Training loss: 1.8402713537216187
Validation loss: 2.0669794281323752

Epoch: 5| Step: 2
Training loss: 1.7383458614349365
Validation loss: 2.0645740777254105

Epoch: 5| Step: 3
Training loss: 1.6410629749298096
Validation loss: 2.0654598822196326

Epoch: 5| Step: 4
Training loss: 2.474977970123291
Validation loss: 2.0668557981650033

Epoch: 5| Step: 5
Training loss: 2.568673849105835
Validation loss: 2.061283270517985

Epoch: 5| Step: 6
Training loss: 2.162050247192383
Validation loss: 2.06910606722037

Epoch: 5| Step: 7
Training loss: 2.130462408065796
Validation loss: 2.0623390525579453

Epoch: 5| Step: 8
Training loss: 1.8203413486480713
Validation loss: 2.069368064403534

Epoch: 5| Step: 9
Training loss: 1.793116569519043
Validation loss: 2.0768709977467856

Epoch: 5| Step: 10
Training loss: 1.729671835899353
Validation loss: 2.0675354301929474

Epoch: 5| Step: 11
Training loss: 1.7964719533920288
Validation loss: 2.0812440365552902

Epoch: 142| Step: 0
Training loss: 1.9030437469482422
Validation loss: 2.0701042811075845

Epoch: 5| Step: 1
Training loss: 1.7966550588607788
Validation loss: 2.0529329081376395

Epoch: 5| Step: 2
Training loss: 1.9970401525497437
Validation loss: 2.033018375436465

Epoch: 5| Step: 3
Training loss: 2.2131993770599365
Validation loss: 2.03761055568854

Epoch: 5| Step: 4
Training loss: 1.4444260597229004
Validation loss: 2.0322186003128686

Epoch: 5| Step: 5
Training loss: 2.177161693572998
Validation loss: 2.033660501241684

Epoch: 5| Step: 6
Training loss: 1.817051887512207
Validation loss: 2.0256421913703284

Epoch: 5| Step: 7
Training loss: 2.280900716781616
Validation loss: 2.036160280307134

Epoch: 5| Step: 8
Training loss: 2.0872950553894043
Validation loss: 2.045548831423124

Epoch: 5| Step: 9
Training loss: 2.052572250366211
Validation loss: 2.0539714694023132

Epoch: 5| Step: 10
Training loss: 2.504228353500366
Validation loss: 2.0529932032028833

Epoch: 5| Step: 11
Training loss: 1.5770981311798096
Validation loss: 2.0616664588451385

Epoch: 143| Step: 0
Training loss: 1.7297500371932983
Validation loss: 2.084261044859886

Epoch: 5| Step: 1
Training loss: 2.3923888206481934
Validation loss: 2.1059509168068566

Epoch: 5| Step: 2
Training loss: 2.4239845275878906
Validation loss: 2.0970557977755866

Epoch: 5| Step: 3
Training loss: 2.316765785217285
Validation loss: 2.093094433347384

Epoch: 5| Step: 4
Training loss: 1.5656789541244507
Validation loss: 2.0816918214162192

Epoch: 5| Step: 5
Training loss: 2.1888928413391113
Validation loss: 2.0878526270389557

Epoch: 5| Step: 6
Training loss: 2.292386531829834
Validation loss: 2.0741652299960456

Epoch: 5| Step: 7
Training loss: 1.880099892616272
Validation loss: 2.0840432246526084

Epoch: 5| Step: 8
Training loss: 2.1030120849609375
Validation loss: 2.077692205707232

Epoch: 5| Step: 9
Training loss: 1.8770545721054077
Validation loss: 2.0773239930470786

Epoch: 5| Step: 10
Training loss: 1.7763019800186157
Validation loss: 2.054610848426819

Epoch: 5| Step: 11
Training loss: 1.2238367795944214
Validation loss: 2.049608806769053

Epoch: 144| Step: 0
Training loss: 1.9504497051239014
Validation loss: 2.0554378628730774

Epoch: 5| Step: 1
Training loss: 1.791052222251892
Validation loss: 2.037817825873693

Epoch: 5| Step: 2
Training loss: 2.2081172466278076
Validation loss: 2.038361445069313

Epoch: 5| Step: 3
Training loss: 2.1217703819274902
Validation loss: 2.0477035641670227

Epoch: 5| Step: 4
Training loss: 2.1285462379455566
Validation loss: 2.040445248285929

Epoch: 5| Step: 5
Training loss: 2.2733259201049805
Validation loss: 2.0599165161450705

Epoch: 5| Step: 6
Training loss: 2.1854300498962402
Validation loss: 2.059958517551422

Epoch: 5| Step: 7
Training loss: 1.839514136314392
Validation loss: 2.0576657007137933

Epoch: 5| Step: 8
Training loss: 2.2344577312469482
Validation loss: 2.0708828369776406

Epoch: 5| Step: 9
Training loss: 2.0766031742095947
Validation loss: 2.070465217034022

Epoch: 5| Step: 10
Training loss: 1.6802139282226562
Validation loss: 2.074789802233378

Epoch: 5| Step: 11
Training loss: 1.0963187217712402
Validation loss: 2.068708057204882

Epoch: 145| Step: 0
Training loss: 2.0943331718444824
Validation loss: 2.077811986207962

Epoch: 5| Step: 1
Training loss: 2.2652790546417236
Validation loss: 2.078624685605367

Epoch: 5| Step: 2
Training loss: 2.0440785884857178
Validation loss: 2.0799983044465384

Epoch: 5| Step: 3
Training loss: 2.0129213333129883
Validation loss: 2.069256698091825

Epoch: 5| Step: 4
Training loss: 1.849737524986267
Validation loss: 2.075021763642629

Epoch: 5| Step: 5
Training loss: 1.9638293981552124
Validation loss: 2.0537097454071045

Epoch: 5| Step: 6
Training loss: 1.4114700555801392
Validation loss: 2.0588195820649466

Epoch: 5| Step: 7
Training loss: 2.243387222290039
Validation loss: 2.058719903230667

Epoch: 5| Step: 8
Training loss: 2.1697189807891846
Validation loss: 2.058835277954737

Epoch: 5| Step: 9
Training loss: 2.192380428314209
Validation loss: 2.0546908924976983

Epoch: 5| Step: 10
Training loss: 1.8241183757781982
Validation loss: 2.0663735071818032

Epoch: 5| Step: 11
Training loss: 1.8902480602264404
Validation loss: 2.0583538711071014

Epoch: 146| Step: 0
Training loss: 2.1654164791107178
Validation loss: 2.0431053886810937

Epoch: 5| Step: 1
Training loss: 1.8368380069732666
Validation loss: 2.0471090277036033

Epoch: 5| Step: 2
Training loss: 2.380465269088745
Validation loss: 2.047428751985232

Epoch: 5| Step: 3
Training loss: 2.1049420833587646
Validation loss: 2.0365296453237534

Epoch: 5| Step: 4
Training loss: 1.7193756103515625
Validation loss: 2.032795712351799

Epoch: 5| Step: 5
Training loss: 2.4187324047088623
Validation loss: 2.0460263192653656

Epoch: 5| Step: 6
Training loss: 2.0390753746032715
Validation loss: 2.040897245208422

Epoch: 5| Step: 7
Training loss: 2.3435888290405273
Validation loss: 2.0553648471832275

Epoch: 5| Step: 8
Training loss: 1.971408486366272
Validation loss: 2.0430765450000763

Epoch: 5| Step: 9
Training loss: 1.937888741493225
Validation loss: 2.049204553167025

Epoch: 5| Step: 10
Training loss: 1.310517430305481
Validation loss: 2.0552848279476166

Epoch: 5| Step: 11
Training loss: 2.417092800140381
Validation loss: 2.06671974559625

Epoch: 147| Step: 0
Training loss: 1.703291654586792
Validation loss: 2.0884716312090554

Epoch: 5| Step: 1
Training loss: 2.177125930786133
Validation loss: 2.1147298316160836

Epoch: 5| Step: 2
Training loss: 1.8942304849624634
Validation loss: 2.1014816413323083

Epoch: 5| Step: 3
Training loss: 2.188934803009033
Validation loss: 2.0990232775608697

Epoch: 5| Step: 4
Training loss: 2.033261775970459
Validation loss: 2.0839066753784814

Epoch: 5| Step: 5
Training loss: 1.7672703266143799
Validation loss: 2.082229658961296

Epoch: 5| Step: 6
Training loss: 2.1318106651306152
Validation loss: 2.068576176961263

Epoch: 5| Step: 7
Training loss: 1.8132550716400146
Validation loss: 2.056724190711975

Epoch: 5| Step: 8
Training loss: 1.9504668712615967
Validation loss: 2.0432252138853073

Epoch: 5| Step: 9
Training loss: 1.9430458545684814
Validation loss: 2.033452123403549

Epoch: 5| Step: 10
Training loss: 2.4294636249542236
Validation loss: 2.0334581385056176

Epoch: 5| Step: 11
Training loss: 3.634633779525757
Validation loss: 2.0377320498228073

Epoch: 148| Step: 0
Training loss: 2.37753963470459
Validation loss: 2.032011240720749

Epoch: 5| Step: 1
Training loss: 2.220689535140991
Validation loss: 2.02401269475619

Epoch: 5| Step: 2
Training loss: 1.8915281295776367
Validation loss: 2.0272161960601807

Epoch: 5| Step: 3
Training loss: 1.7659145593643188
Validation loss: 2.0312517484029136

Epoch: 5| Step: 4
Training loss: 2.3295369148254395
Validation loss: 2.0269921769698462

Epoch: 5| Step: 5
Training loss: 1.7285583019256592
Validation loss: 2.042086144288381

Epoch: 5| Step: 6
Training loss: 2.303736448287964
Validation loss: 2.0390422691901526

Epoch: 5| Step: 7
Training loss: 1.8120019435882568
Validation loss: 2.0505249152580896

Epoch: 5| Step: 8
Training loss: 1.7631504535675049
Validation loss: 2.0532036423683167

Epoch: 5| Step: 9
Training loss: 2.2693774700164795
Validation loss: 2.0637421210606894

Epoch: 5| Step: 10
Training loss: 2.0414586067199707
Validation loss: 2.0649774273236594

Epoch: 5| Step: 11
Training loss: 1.7746386528015137
Validation loss: 2.0642006446917853

Epoch: 149| Step: 0
Training loss: 2.0830986499786377
Validation loss: 2.0678101032972336

Epoch: 5| Step: 1
Training loss: 2.154636859893799
Validation loss: 2.074067771434784

Epoch: 5| Step: 2
Training loss: 2.5270495414733887
Validation loss: 2.065747564037641

Epoch: 5| Step: 3
Training loss: 1.6621730327606201
Validation loss: 2.0535864531993866

Epoch: 5| Step: 4
Training loss: 1.6936126947402954
Validation loss: 2.0474201291799545

Epoch: 5| Step: 5
Training loss: 2.2576985359191895
Validation loss: 2.0416011015574136

Epoch: 5| Step: 6
Training loss: 2.4270405769348145
Validation loss: 2.0364347845315933

Epoch: 5| Step: 7
Training loss: 2.208456516265869
Validation loss: 2.0341711590687432

Epoch: 5| Step: 8
Training loss: 1.7310740947723389
Validation loss: 2.040839503208796

Epoch: 5| Step: 9
Training loss: 2.008192300796509
Validation loss: 2.0397973308960595

Epoch: 5| Step: 10
Training loss: 1.6226593255996704
Validation loss: 2.0385794788599014

Epoch: 5| Step: 11
Training loss: 1.412284016609192
Validation loss: 2.039837062358856

Epoch: 150| Step: 0
Training loss: 2.161135196685791
Validation loss: 2.0284979194402695

Epoch: 5| Step: 1
Training loss: 2.2041544914245605
Validation loss: 2.0154902587334314

Epoch: 5| Step: 2
Training loss: 2.0634562969207764
Validation loss: 2.029201770822207

Epoch: 5| Step: 3
Training loss: 2.5481724739074707
Validation loss: 2.0289348711570105

Epoch: 5| Step: 4
Training loss: 2.021780490875244
Validation loss: 2.0319449404875436

Epoch: 5| Step: 5
Training loss: 1.8023769855499268
Validation loss: 2.0328008780876794

Epoch: 5| Step: 6
Training loss: 2.109945297241211
Validation loss: 2.035127873222033

Epoch: 5| Step: 7
Training loss: 2.204430103302002
Validation loss: 2.02745129664739

Epoch: 5| Step: 8
Training loss: 1.9550994634628296
Validation loss: 2.0239319652318954

Epoch: 5| Step: 9
Training loss: 1.824141263961792
Validation loss: 2.031277825435003

Epoch: 5| Step: 10
Training loss: 1.935819387435913
Validation loss: 2.0228231648604074

Epoch: 5| Step: 11
Training loss: 3.3943347930908203
Validation loss: 2.0271748850742974

Epoch: 151| Step: 0
Training loss: 1.8670780658721924
Validation loss: 2.0178867280483246

Epoch: 5| Step: 1
Training loss: 2.0833446979522705
Validation loss: 2.040990208586057

Epoch: 5| Step: 2
Training loss: 1.664207100868225
Validation loss: 2.0485453506310782

Epoch: 5| Step: 3
Training loss: 1.8289391994476318
Validation loss: 2.055855005979538

Epoch: 5| Step: 4
Training loss: 2.2495739459991455
Validation loss: 2.0567602813243866

Epoch: 5| Step: 5
Training loss: 2.1552891731262207
Validation loss: 2.0536819299062095

Epoch: 5| Step: 6
Training loss: 2.4621663093566895
Validation loss: 2.0856329003969827

Epoch: 5| Step: 7
Training loss: 2.3995487689971924
Validation loss: 2.065785974264145

Epoch: 5| Step: 8
Training loss: 1.9394067525863647
Validation loss: 2.0659589171409607

Epoch: 5| Step: 9
Training loss: 2.0619444847106934
Validation loss: 2.063585956891378

Epoch: 5| Step: 10
Training loss: 2.0547385215759277
Validation loss: 2.044041097164154

Epoch: 5| Step: 11
Training loss: 1.2330501079559326
Validation loss: 2.0492218236128488

Epoch: 152| Step: 0
Training loss: 1.854928731918335
Validation loss: 2.0526845455169678

Epoch: 5| Step: 1
Training loss: 1.9005699157714844
Validation loss: 2.059633652369181

Epoch: 5| Step: 2
Training loss: 1.1652560234069824
Validation loss: 2.062384749452273

Epoch: 5| Step: 3
Training loss: 2.2332100868225098
Validation loss: 2.0719832678635917

Epoch: 5| Step: 4
Training loss: 1.9553959369659424
Validation loss: 2.1013162781794867

Epoch: 5| Step: 5
Training loss: 2.340688705444336
Validation loss: 2.0967952758073807

Epoch: 5| Step: 6
Training loss: 2.530938148498535
Validation loss: 2.111119528611501

Epoch: 5| Step: 7
Training loss: 2.253507137298584
Validation loss: 2.099018002549807

Epoch: 5| Step: 8
Training loss: 1.7695232629776
Validation loss: 2.1039421260356903

Epoch: 5| Step: 9
Training loss: 2.4786295890808105
Validation loss: 2.0962397158145905

Epoch: 5| Step: 10
Training loss: 1.7896509170532227
Validation loss: 2.0927067597707114

Epoch: 5| Step: 11
Training loss: 2.1045541763305664
Validation loss: 2.091014956434568

Epoch: 153| Step: 0
Training loss: 1.9402990341186523
Validation loss: 2.058531805872917

Epoch: 5| Step: 1
Training loss: 2.891160011291504
Validation loss: 2.044203738371531

Epoch: 5| Step: 2
Training loss: 1.5572073459625244
Validation loss: 2.0298184802134833

Epoch: 5| Step: 3
Training loss: 1.8930305242538452
Validation loss: 2.0389449695746102

Epoch: 5| Step: 4
Training loss: 2.1740450859069824
Validation loss: 2.0505725791056952

Epoch: 5| Step: 5
Training loss: 1.9935939311981201
Validation loss: 2.047262355685234

Epoch: 5| Step: 6
Training loss: 2.6106042861938477
Validation loss: 2.053320974111557

Epoch: 5| Step: 7
Training loss: 1.6374717950820923
Validation loss: 2.0550259252389274

Epoch: 5| Step: 8
Training loss: 2.0675511360168457
Validation loss: 2.054074764251709

Epoch: 5| Step: 9
Training loss: 2.335357904434204
Validation loss: 2.0555908381938934

Epoch: 5| Step: 10
Training loss: 2.2443737983703613
Validation loss: 2.05267541607221

Epoch: 5| Step: 11
Training loss: 1.464816689491272
Validation loss: 2.0554144084453583

Epoch: 154| Step: 0
Training loss: 2.4602160453796387
Validation loss: 2.0472280383110046

Epoch: 5| Step: 1
Training loss: 1.6976016759872437
Validation loss: 2.0447842180728912

Epoch: 5| Step: 2
Training loss: 2.6277506351470947
Validation loss: 2.0349334875742593

Epoch: 5| Step: 3
Training loss: 2.0374228954315186
Validation loss: 2.041728044549624

Epoch: 5| Step: 4
Training loss: 1.4906628131866455
Validation loss: 2.041093726952871

Epoch: 5| Step: 5
Training loss: 2.222781181335449
Validation loss: 2.052863667408625

Epoch: 5| Step: 6
Training loss: 2.0165865421295166
Validation loss: 2.076236938436826

Epoch: 5| Step: 7
Training loss: 1.9676450490951538
Validation loss: 2.0607623954614005

Epoch: 5| Step: 8
Training loss: 2.5311055183410645
Validation loss: 2.069843982656797

Epoch: 5| Step: 9
Training loss: 2.2231457233428955
Validation loss: 2.0647727151711783

Epoch: 5| Step: 10
Training loss: 1.6979248523712158
Validation loss: 2.0693353911240897

Epoch: 5| Step: 11
Training loss: 1.408095121383667
Validation loss: 2.058064435919126

Epoch: 155| Step: 0
Training loss: 1.378143072128296
Validation loss: 2.0728204995393753

Epoch: 5| Step: 1
Training loss: 1.706444501876831
Validation loss: 2.0621476024389267

Epoch: 5| Step: 2
Training loss: 1.9009284973144531
Validation loss: 2.062816063563029

Epoch: 5| Step: 3
Training loss: 2.268465757369995
Validation loss: 2.068558101852735

Epoch: 5| Step: 4
Training loss: 2.7174010276794434
Validation loss: 2.0515870600938797

Epoch: 5| Step: 5
Training loss: 2.2018539905548096
Validation loss: 2.0897667656342187

Epoch: 5| Step: 6
Training loss: 1.742868423461914
Validation loss: 2.073037172357241

Epoch: 5| Step: 7
Training loss: 2.2846455574035645
Validation loss: 2.0642279187838235

Epoch: 5| Step: 8
Training loss: 2.235651969909668
Validation loss: 2.052918866276741

Epoch: 5| Step: 9
Training loss: 1.7265437841415405
Validation loss: 2.075760210553805

Epoch: 5| Step: 10
Training loss: 2.1929752826690674
Validation loss: 2.063653826713562

Epoch: 5| Step: 11
Training loss: 1.1745705604553223
Validation loss: 2.0745495657126107

Epoch: 156| Step: 0
Training loss: 2.3063175678253174
Validation loss: 2.075583045681318

Epoch: 5| Step: 1
Training loss: 2.8240485191345215
Validation loss: 2.078158458073934

Epoch: 5| Step: 2
Training loss: 1.8633496761322021
Validation loss: 2.093708644310633

Epoch: 5| Step: 3
Training loss: 2.4867444038391113
Validation loss: 2.1072544356187186

Epoch: 5| Step: 4
Training loss: 1.7049850225448608
Validation loss: 2.118342399597168

Epoch: 5| Step: 5
Training loss: 1.798479437828064
Validation loss: 2.113735556602478

Epoch: 5| Step: 6
Training loss: 1.6988747119903564
Validation loss: 2.114290182789167

Epoch: 5| Step: 7
Training loss: 2.1046836376190186
Validation loss: 2.111258109410604

Epoch: 5| Step: 8
Training loss: 1.6679855585098267
Validation loss: 2.1038023630777993

Epoch: 5| Step: 9
Training loss: 2.011289596557617
Validation loss: 2.107623895009359

Epoch: 5| Step: 10
Training loss: 1.559844732284546
Validation loss: 2.113621085882187

Epoch: 5| Step: 11
Training loss: 1.430172324180603
Validation loss: 2.0851943542559943

Epoch: 157| Step: 0
Training loss: 2.309044361114502
Validation loss: 2.0961180925369263

Epoch: 5| Step: 1
Training loss: 1.7499967813491821
Validation loss: 2.0926257918278375

Epoch: 5| Step: 2
Training loss: 2.0938198566436768
Validation loss: 2.101426442464193

Epoch: 5| Step: 3
Training loss: 1.8795864582061768
Validation loss: 2.0842165797948837

Epoch: 5| Step: 4
Training loss: 2.1975290775299072
Validation loss: 2.0783402025699615

Epoch: 5| Step: 5
Training loss: 1.3816149234771729
Validation loss: 2.07368965446949

Epoch: 5| Step: 6
Training loss: 1.6657207012176514
Validation loss: 2.0728034426768622

Epoch: 5| Step: 7
Training loss: 2.2896764278411865
Validation loss: 2.0551426659027734

Epoch: 5| Step: 8
Training loss: 2.641892910003662
Validation loss: 2.063516596953074

Epoch: 5| Step: 9
Training loss: 1.6978759765625
Validation loss: 2.067980815966924

Epoch: 5| Step: 10
Training loss: 1.623774766921997
Validation loss: 2.0625834862391152

Epoch: 5| Step: 11
Training loss: 3.50736665725708
Validation loss: 2.07465198636055

Epoch: 158| Step: 0
Training loss: 1.6227874755859375
Validation loss: 2.0615628014008203

Epoch: 5| Step: 1
Training loss: 1.8104743957519531
Validation loss: 2.0661238680283227

Epoch: 5| Step: 2
Training loss: 1.8369286060333252
Validation loss: 2.064408908287684

Epoch: 5| Step: 3
Training loss: 2.2263643741607666
Validation loss: 2.0668246994415918

Epoch: 5| Step: 4
Training loss: 2.0732834339141846
Validation loss: 2.078173736731211

Epoch: 5| Step: 5
Training loss: 2.475907802581787
Validation loss: 2.0649814357360206

Epoch: 5| Step: 6
Training loss: 2.1200385093688965
Validation loss: 2.06963745256265

Epoch: 5| Step: 7
Training loss: 1.7608535289764404
Validation loss: 2.063740303119024

Epoch: 5| Step: 8
Training loss: 2.2661375999450684
Validation loss: 2.070738529165586

Epoch: 5| Step: 9
Training loss: 1.5615695714950562
Validation loss: 2.047511691848437

Epoch: 5| Step: 10
Training loss: 1.9274622201919556
Validation loss: 2.064328283071518

Epoch: 5| Step: 11
Training loss: 2.043938636779785
Validation loss: 2.0610864063103995

Epoch: 159| Step: 0
Training loss: 2.288515567779541
Validation loss: 2.0572922180096307

Epoch: 5| Step: 1
Training loss: 1.5538990497589111
Validation loss: 2.075188477834066

Epoch: 5| Step: 2
Training loss: 2.03364896774292
Validation loss: 2.077912598848343

Epoch: 5| Step: 3
Training loss: 1.4209144115447998
Validation loss: 2.073106656471888

Epoch: 5| Step: 4
Training loss: 1.9417545795440674
Validation loss: 2.066982641816139

Epoch: 5| Step: 5
Training loss: 2.2382633686065674
Validation loss: 2.073852241039276

Epoch: 5| Step: 6
Training loss: 2.157341480255127
Validation loss: 2.0905907650788627

Epoch: 5| Step: 7
Training loss: 2.0045604705810547
Validation loss: 2.074680412809054

Epoch: 5| Step: 8
Training loss: 2.158374071121216
Validation loss: 2.087421943744024

Epoch: 5| Step: 9
Training loss: 1.9673007726669312
Validation loss: 2.091631347934405

Epoch: 5| Step: 10
Training loss: 2.067786455154419
Validation loss: 2.0774945467710495

Epoch: 5| Step: 11
Training loss: 1.0631146430969238
Validation loss: 2.07394610842069

Epoch: 160| Step: 0
Training loss: 1.8973045349121094
Validation loss: 2.0980198681354523

Epoch: 5| Step: 1
Training loss: 1.9501914978027344
Validation loss: 2.0802245140075684

Epoch: 5| Step: 2
Training loss: 2.209754467010498
Validation loss: 2.087204242746035

Epoch: 5| Step: 3
Training loss: 2.159492254257202
Validation loss: 2.1241416235764823

Epoch: 5| Step: 4
Training loss: 2.069070339202881
Validation loss: 2.1003324588139853

Epoch: 5| Step: 5
Training loss: 2.2941701412200928
Validation loss: 2.1072215537230172

Epoch: 5| Step: 6
Training loss: 1.7968480587005615
Validation loss: 2.1333895921707153

Epoch: 5| Step: 7
Training loss: 1.8043044805526733
Validation loss: 2.1165406157573066

Epoch: 5| Step: 8
Training loss: 1.38677179813385
Validation loss: 2.1251417100429535

Epoch: 5| Step: 9
Training loss: 1.950096845626831
Validation loss: 2.121376340587934

Epoch: 5| Step: 10
Training loss: 2.162013292312622
Validation loss: 2.1181528766949973

Epoch: 5| Step: 11
Training loss: 2.3864526748657227
Validation loss: 2.10699629286925

Epoch: 161| Step: 0
Training loss: 1.9481112957000732
Validation loss: 2.1262050767739615

Epoch: 5| Step: 1
Training loss: 2.1783080101013184
Validation loss: 2.0983147273461022

Epoch: 5| Step: 2
Training loss: 2.1271965503692627
Validation loss: 2.0956090092658997

Epoch: 5| Step: 3
Training loss: 2.2762794494628906
Validation loss: 2.0943750888109207

Epoch: 5| Step: 4
Training loss: 1.7564609050750732
Validation loss: 2.100141684214274

Epoch: 5| Step: 5
Training loss: 1.7456995248794556
Validation loss: 2.081979885697365

Epoch: 5| Step: 6
Training loss: 1.856760025024414
Validation loss: 2.0901623467604318

Epoch: 5| Step: 7
Training loss: 2.3292903900146484
Validation loss: 2.0945165157318115

Epoch: 5| Step: 8
Training loss: 1.4682122468948364
Validation loss: 2.091906319061915

Epoch: 5| Step: 9
Training loss: 2.1419737339019775
Validation loss: 2.1185980290174484

Epoch: 5| Step: 10
Training loss: 2.1254067420959473
Validation loss: 2.112261633078257

Epoch: 5| Step: 11
Training loss: 1.9838666915893555
Validation loss: 2.1138503352801004

Epoch: 162| Step: 0
Training loss: 1.5425869226455688
Validation loss: 2.11630542576313

Epoch: 5| Step: 1
Training loss: 1.8592742681503296
Validation loss: 2.111653079589208

Epoch: 5| Step: 2
Training loss: 1.501835584640503
Validation loss: 2.129544441898664

Epoch: 5| Step: 3
Training loss: 2.3554348945617676
Validation loss: 2.1312459806601205

Epoch: 5| Step: 4
Training loss: 1.9631837606430054
Validation loss: 2.1144093523422876

Epoch: 5| Step: 5
Training loss: 2.2843098640441895
Validation loss: 2.095399414499601

Epoch: 5| Step: 6
Training loss: 2.213108539581299
Validation loss: 2.097889934976896

Epoch: 5| Step: 7
Training loss: 1.9915740489959717
Validation loss: 2.0773167411486306

Epoch: 5| Step: 8
Training loss: 1.790367841720581
Validation loss: 2.0722957203785577

Epoch: 5| Step: 9
Training loss: 1.9302173852920532
Validation loss: 2.0774984459082284

Epoch: 5| Step: 10
Training loss: 2.4045567512512207
Validation loss: 2.0693966895341873

Epoch: 5| Step: 11
Training loss: 2.332798480987549
Validation loss: 2.057460288206736

Epoch: 163| Step: 0
Training loss: 2.474472999572754
Validation loss: 2.067182386914889

Epoch: 5| Step: 1
Training loss: 1.9086625576019287
Validation loss: 2.088470866282781

Epoch: 5| Step: 2
Training loss: 2.644573211669922
Validation loss: 2.1037267794211707

Epoch: 5| Step: 3
Training loss: 1.7072654962539673
Validation loss: 2.1072123050689697

Epoch: 5| Step: 4
Training loss: 1.9798877239227295
Validation loss: 2.1343520979086557

Epoch: 5| Step: 5
Training loss: 2.081024169921875
Validation loss: 2.13433575630188

Epoch: 5| Step: 6
Training loss: 1.5856066942214966
Validation loss: 2.1256247957547507

Epoch: 5| Step: 7
Training loss: 2.02433443069458
Validation loss: 2.132927437623342

Epoch: 5| Step: 8
Training loss: 1.654730200767517
Validation loss: 2.160478353500366

Epoch: 5| Step: 9
Training loss: 1.9601242542266846
Validation loss: 2.132460633913676

Epoch: 5| Step: 10
Training loss: 1.9512336254119873
Validation loss: 2.1262332697709403

Epoch: 5| Step: 11
Training loss: 1.2604774236679077
Validation loss: 2.1117281864086785

Epoch: 164| Step: 0
Training loss: 2.2079062461853027
Validation loss: 2.098488306005796

Epoch: 5| Step: 1
Training loss: 2.0034289360046387
Validation loss: 2.086888531843821

Epoch: 5| Step: 2
Training loss: 1.536004900932312
Validation loss: 2.0847718020280204

Epoch: 5| Step: 3
Training loss: 1.8124802112579346
Validation loss: 2.1048231472571692

Epoch: 5| Step: 4
Training loss: 1.728727102279663
Validation loss: 2.089978108803431

Epoch: 5| Step: 5
Training loss: 2.3092751502990723
Validation loss: 2.0817834387222924

Epoch: 5| Step: 6
Training loss: 2.134294033050537
Validation loss: 2.0832503139972687

Epoch: 5| Step: 7
Training loss: 2.1997084617614746
Validation loss: 2.0932343949874244

Epoch: 5| Step: 8
Training loss: 1.910875916481018
Validation loss: 2.081967070698738

Epoch: 5| Step: 9
Training loss: 2.013056755065918
Validation loss: 2.085312301913897

Epoch: 5| Step: 10
Training loss: 1.8729994297027588
Validation loss: 2.082874576250712

Epoch: 5| Step: 11
Training loss: 1.8296024799346924
Validation loss: 2.0905127425988517

Epoch: 165| Step: 0
Training loss: 1.7475169897079468
Validation loss: 2.104621877272924

Epoch: 5| Step: 1
Training loss: 2.1085469722747803
Validation loss: 2.127601663271586

Epoch: 5| Step: 2
Training loss: 2.087189197540283
Validation loss: 2.1192784706751504

Epoch: 5| Step: 3
Training loss: 1.762799859046936
Validation loss: 2.129765043656031

Epoch: 5| Step: 4
Training loss: 2.4656670093536377
Validation loss: 2.1346404751141868

Epoch: 5| Step: 5
Training loss: 2.209463596343994
Validation loss: 2.152030572295189

Epoch: 5| Step: 6
Training loss: 2.3348228931427
Validation loss: 2.124472831686338

Epoch: 5| Step: 7
Training loss: 1.5435632467269897
Validation loss: 2.1231782039006553

Epoch: 5| Step: 8
Training loss: 2.6581802368164062
Validation loss: 2.0977949798107147

Epoch: 5| Step: 9
Training loss: 1.9353536367416382
Validation loss: 2.0929157187541327

Epoch: 5| Step: 10
Training loss: 1.7767120599746704
Validation loss: 2.0736247052749

Epoch: 5| Step: 11
Training loss: 2.3614306449890137
Validation loss: 2.074895958105723

Epoch: 166| Step: 0
Training loss: 1.966570258140564
Validation loss: 2.0673347413539886

Epoch: 5| Step: 1
Training loss: 1.9834518432617188
Validation loss: 2.059682627518972

Epoch: 5| Step: 2
Training loss: 1.8310943841934204
Validation loss: 2.0418038417895636

Epoch: 5| Step: 3
Training loss: 2.2187507152557373
Validation loss: 2.0416692346334457

Epoch: 5| Step: 4
Training loss: 1.7352046966552734
Validation loss: 2.053244044383367

Epoch: 5| Step: 5
Training loss: 2.4831700325012207
Validation loss: 2.0495523313681283

Epoch: 5| Step: 6
Training loss: 2.154078483581543
Validation loss: 2.0487047731876373

Epoch: 5| Step: 7
Training loss: 2.0095009803771973
Validation loss: 2.049077639977137

Epoch: 5| Step: 8
Training loss: 1.7539606094360352
Validation loss: 2.0596083998680115

Epoch: 5| Step: 9
Training loss: 2.20167875289917
Validation loss: 2.05944287776947

Epoch: 5| Step: 10
Training loss: 2.077509641647339
Validation loss: 2.0635384370883307

Epoch: 5| Step: 11
Training loss: 2.391439437866211
Validation loss: 2.0704393088817596

Epoch: 167| Step: 0
Training loss: 1.3090028762817383
Validation loss: 2.0821455270051956

Epoch: 5| Step: 1
Training loss: 2.4718804359436035
Validation loss: 2.0837859561045966

Epoch: 5| Step: 2
Training loss: 1.721716284751892
Validation loss: 2.096721569697062

Epoch: 5| Step: 3
Training loss: 2.5277607440948486
Validation loss: 2.114254434903463

Epoch: 5| Step: 4
Training loss: 2.0405056476593018
Validation loss: 2.1242027382055917

Epoch: 5| Step: 5
Training loss: 2.245337724685669
Validation loss: 2.1273920635382333

Epoch: 5| Step: 6
Training loss: 2.3837525844573975
Validation loss: 2.1273063321908317

Epoch: 5| Step: 7
Training loss: 1.9493248462677002
Validation loss: 2.147248218456904

Epoch: 5| Step: 8
Training loss: 1.9141525030136108
Validation loss: 2.1173710028330484

Epoch: 5| Step: 9
Training loss: 1.9659103155136108
Validation loss: 2.126335327823957

Epoch: 5| Step: 10
Training loss: 1.5731284618377686
Validation loss: 2.1203971256812415

Epoch: 5| Step: 11
Training loss: 1.762583613395691
Validation loss: 2.1046366890271506

Epoch: 168| Step: 0
Training loss: 1.6072851419448853
Validation loss: 2.10114678243796

Epoch: 5| Step: 1
Training loss: 1.8419004678726196
Validation loss: 2.0708601425091424

Epoch: 5| Step: 2
Training loss: 2.024852752685547
Validation loss: 2.0588276286919913

Epoch: 5| Step: 3
Training loss: 2.4767239093780518
Validation loss: 2.0570589154958725

Epoch: 5| Step: 4
Training loss: 1.7493349313735962
Validation loss: 2.0521132300297418

Epoch: 5| Step: 5
Training loss: 1.8530864715576172
Validation loss: 2.050836185614268

Epoch: 5| Step: 6
Training loss: 2.2181003093719482
Validation loss: 2.0513901114463806

Epoch: 5| Step: 7
Training loss: 1.5392831563949585
Validation loss: 2.079233373204867

Epoch: 5| Step: 8
Training loss: 2.1234943866729736
Validation loss: 2.073415368795395

Epoch: 5| Step: 9
Training loss: 2.3666727542877197
Validation loss: 2.0873415718475976

Epoch: 5| Step: 10
Training loss: 1.9365402460098267
Validation loss: 2.077022214730581

Epoch: 5| Step: 11
Training loss: 2.297884702682495
Validation loss: 2.0965834160645804

Epoch: 169| Step: 0
Training loss: 2.046037197113037
Validation loss: 2.120562121272087

Epoch: 5| Step: 1
Training loss: 1.6914316415786743
Validation loss: 2.1445603470007577

Epoch: 5| Step: 2
Training loss: 2.573507308959961
Validation loss: 2.123666743437449

Epoch: 5| Step: 3
Training loss: 2.094048500061035
Validation loss: 2.1335780719916024

Epoch: 5| Step: 4
Training loss: 2.0462520122528076
Validation loss: 2.139583095908165

Epoch: 5| Step: 5
Training loss: 2.3413403034210205
Validation loss: 2.162768468260765

Epoch: 5| Step: 6
Training loss: 1.821584701538086
Validation loss: 2.1513644804557166

Epoch: 5| Step: 7
Training loss: 1.704109787940979
Validation loss: 2.1328557233015695

Epoch: 5| Step: 8
Training loss: 2.1102423667907715
Validation loss: 2.12005423506101

Epoch: 5| Step: 9
Training loss: 1.7504634857177734
Validation loss: 2.124857634305954

Epoch: 5| Step: 10
Training loss: 1.8592989444732666
Validation loss: 2.099316497643789

Epoch: 5| Step: 11
Training loss: 1.6065399646759033
Validation loss: 2.0856983959674835

Epoch: 170| Step: 0
Training loss: 2.5730655193328857
Validation loss: 2.060137003660202

Epoch: 5| Step: 1
Training loss: 1.4671136140823364
Validation loss: 2.052292615175247

Epoch: 5| Step: 2
Training loss: 2.0396952629089355
Validation loss: 2.052006463209788

Epoch: 5| Step: 3
Training loss: 2.0617496967315674
Validation loss: 2.052093659838041

Epoch: 5| Step: 4
Training loss: 1.991236925125122
Validation loss: 2.050240988532702

Epoch: 5| Step: 5
Training loss: 1.901307463645935
Validation loss: 2.0568469564119973

Epoch: 5| Step: 6
Training loss: 2.755518913269043
Validation loss: 2.057287593682607

Epoch: 5| Step: 7
Training loss: 1.78564453125
Validation loss: 2.063865900039673

Epoch: 5| Step: 8
Training loss: 1.7699549198150635
Validation loss: 2.0671576211849847

Epoch: 5| Step: 9
Training loss: 1.7016994953155518
Validation loss: 2.055716782808304

Epoch: 5| Step: 10
Training loss: 2.23669171333313
Validation loss: 2.0677688916524253

Epoch: 5| Step: 11
Training loss: 1.402022123336792
Validation loss: 2.0799720138311386

Epoch: 171| Step: 0
Training loss: 1.9110186100006104
Validation loss: 2.0894662737846375

Epoch: 5| Step: 1
Training loss: 2.6494617462158203
Validation loss: 2.1024282624324164

Epoch: 5| Step: 2
Training loss: 2.294497013092041
Validation loss: 2.1138354738553367

Epoch: 5| Step: 3
Training loss: 1.5828458070755005
Validation loss: 2.125856637954712

Epoch: 5| Step: 4
Training loss: 1.6243221759796143
Validation loss: 2.1161908159653344

Epoch: 5| Step: 5
Training loss: 1.995080590248108
Validation loss: 2.1146598706642785

Epoch: 5| Step: 6
Training loss: 1.8667423725128174
Validation loss: 2.1187816808621087

Epoch: 5| Step: 7
Training loss: 1.9454705715179443
Validation loss: 2.1046259999275208

Epoch: 5| Step: 8
Training loss: 2.0494601726531982
Validation loss: 2.0996032853921256

Epoch: 5| Step: 9
Training loss: 1.7546749114990234
Validation loss: 2.0828449775775275

Epoch: 5| Step: 10
Training loss: 2.202714204788208
Validation loss: 2.0981044520934424

Epoch: 5| Step: 11
Training loss: 1.5096725225448608
Validation loss: 2.0905696551005044

Epoch: 172| Step: 0
Training loss: 2.1218154430389404
Validation loss: 2.1010285218556723

Epoch: 5| Step: 1
Training loss: 1.7709484100341797
Validation loss: 2.1020008524258933

Epoch: 5| Step: 2
Training loss: 1.8856828212738037
Validation loss: 2.0996111383040748

Epoch: 5| Step: 3
Training loss: 1.9153902530670166
Validation loss: 2.1202427248160043

Epoch: 5| Step: 4
Training loss: 2.096200704574585
Validation loss: 2.09347794453303

Epoch: 5| Step: 5
Training loss: 1.968396544456482
Validation loss: 2.1230317850907645

Epoch: 5| Step: 6
Training loss: 1.7401177883148193
Validation loss: 2.100537712375323

Epoch: 5| Step: 7
Training loss: 1.9232609272003174
Validation loss: 2.098913053671519

Epoch: 5| Step: 8
Training loss: 2.1326916217803955
Validation loss: 2.111110582947731

Epoch: 5| Step: 9
Training loss: 2.323279857635498
Validation loss: 2.0994471112887063

Epoch: 5| Step: 10
Training loss: 1.6635860204696655
Validation loss: 2.114726106325785

Epoch: 5| Step: 11
Training loss: 1.9925258159637451
Validation loss: 2.102946092685064

Epoch: 173| Step: 0
Training loss: 2.075766086578369
Validation loss: 2.104155952731768

Epoch: 5| Step: 1
Training loss: 2.173769474029541
Validation loss: 2.093649377425512

Epoch: 5| Step: 2
Training loss: 2.2001101970672607
Validation loss: 2.1012099186579385

Epoch: 5| Step: 3
Training loss: 1.7932144403457642
Validation loss: 2.1067055761814117

Epoch: 5| Step: 4
Training loss: 1.748297929763794
Validation loss: 2.1020640631516776

Epoch: 5| Step: 5
Training loss: 1.6114908456802368
Validation loss: 2.1053538819154105

Epoch: 5| Step: 6
Training loss: 1.3728362321853638
Validation loss: 2.109793876608213

Epoch: 5| Step: 7
Training loss: 1.7411937713623047
Validation loss: 2.1070340325435004

Epoch: 5| Step: 8
Training loss: 1.7014614343643188
Validation loss: 2.0942003478606543

Epoch: 5| Step: 9
Training loss: 2.5559277534484863
Validation loss: 2.094578435023626

Epoch: 5| Step: 10
Training loss: 2.300935983657837
Validation loss: 2.102916826804479

Epoch: 5| Step: 11
Training loss: 2.026000738143921
Validation loss: 2.1272445023059845

Epoch: 174| Step: 0
Training loss: 2.4434657096862793
Validation loss: 2.1436246434847512

Epoch: 5| Step: 1
Training loss: 1.8388175964355469
Validation loss: 2.154214416941007

Epoch: 5| Step: 2
Training loss: 1.6959911584854126
Validation loss: 2.177724232276281

Epoch: 5| Step: 3
Training loss: 1.9707990884780884
Validation loss: 2.196308344602585

Epoch: 5| Step: 4
Training loss: 3.037870407104492
Validation loss: 2.2069897949695587

Epoch: 5| Step: 5
Training loss: 1.7450950145721436
Validation loss: 2.2189085384209952

Epoch: 5| Step: 6
Training loss: 1.581284523010254
Validation loss: 2.1719945768515267

Epoch: 5| Step: 7
Training loss: 2.3198482990264893
Validation loss: 2.1476935346921286

Epoch: 5| Step: 8
Training loss: 1.5321401357650757
Validation loss: 2.1134868363539376

Epoch: 5| Step: 9
Training loss: 1.6982303857803345
Validation loss: 2.083707054456075

Epoch: 5| Step: 10
Training loss: 2.455841302871704
Validation loss: 2.0850443740685782

Epoch: 5| Step: 11
Training loss: 1.9585288763046265
Validation loss: 2.069128543138504

Epoch: 175| Step: 0
Training loss: 1.5607229471206665
Validation loss: 2.074010948340098

Epoch: 5| Step: 1
Training loss: 1.8286094665527344
Validation loss: 2.063624491294225

Epoch: 5| Step: 2
Training loss: 2.3756210803985596
Validation loss: 2.0805929402510324

Epoch: 5| Step: 3
Training loss: 2.449831485748291
Validation loss: 2.074002022544543

Epoch: 5| Step: 4
Training loss: 2.1364402770996094
Validation loss: 2.082437495390574

Epoch: 5| Step: 5
Training loss: 2.338310718536377
Validation loss: 2.078500891725222

Epoch: 5| Step: 6
Training loss: 1.7433300018310547
Validation loss: 2.1021902710199356

Epoch: 5| Step: 7
Training loss: 1.7451709508895874
Validation loss: 2.1230900386969247

Epoch: 5| Step: 8
Training loss: 2.1928317546844482
Validation loss: 2.13024831811587

Epoch: 5| Step: 9
Training loss: 2.028270959854126
Validation loss: 2.128428185979525

Epoch: 5| Step: 10
Training loss: 1.743556261062622
Validation loss: 2.148127555847168

Epoch: 5| Step: 11
Training loss: 1.9149962663650513
Validation loss: 2.159452810883522

Epoch: 176| Step: 0
Training loss: 1.7775583267211914
Validation loss: 2.1469332724809647

Epoch: 5| Step: 1
Training loss: 2.3687503337860107
Validation loss: 2.1433407167593637

Epoch: 5| Step: 2
Training loss: 2.1071295738220215
Validation loss: 2.1620389372110367

Epoch: 5| Step: 3
Training loss: 1.9045072793960571
Validation loss: 2.1549958338340125

Epoch: 5| Step: 4
Training loss: 2.7711567878723145
Validation loss: 2.1436683535575867

Epoch: 5| Step: 5
Training loss: 2.032829761505127
Validation loss: 2.118735899527868

Epoch: 5| Step: 6
Training loss: 1.8907642364501953
Validation loss: 2.1001642098029456

Epoch: 5| Step: 7
Training loss: 2.098459243774414
Validation loss: 2.100290169318517

Epoch: 5| Step: 8
Training loss: 1.5524113178253174
Validation loss: 2.0892765124638877

Epoch: 5| Step: 9
Training loss: 2.16874623298645
Validation loss: 2.084325984120369

Epoch: 5| Step: 10
Training loss: 1.5144178867340088
Validation loss: 2.0765064706405005

Epoch: 5| Step: 11
Training loss: 1.0512914657592773
Validation loss: 2.0754319032033286

Epoch: 177| Step: 0
Training loss: 2.145747184753418
Validation loss: 2.0769961376984916

Epoch: 5| Step: 1
Training loss: 2.146911859512329
Validation loss: 2.079644496242205

Epoch: 5| Step: 2
Training loss: 1.9668951034545898
Validation loss: 2.074090083440145

Epoch: 5| Step: 3
Training loss: 1.7319828271865845
Validation loss: 2.075359140833219

Epoch: 5| Step: 4
Training loss: 1.5694122314453125
Validation loss: 2.078126539786657

Epoch: 5| Step: 5
Training loss: 1.9042234420776367
Validation loss: 2.093694498141607

Epoch: 5| Step: 6
Training loss: 2.2137374877929688
Validation loss: 2.0948092291752496

Epoch: 5| Step: 7
Training loss: 2.3149452209472656
Validation loss: 2.1229247401158013

Epoch: 5| Step: 8
Training loss: 1.9171730279922485
Validation loss: 2.1264638106028237

Epoch: 5| Step: 9
Training loss: 1.7622363567352295
Validation loss: 2.1133115589618683

Epoch: 5| Step: 10
Training loss: 2.2282016277313232
Validation loss: 2.1230650544166565

Epoch: 5| Step: 11
Training loss: 1.2732548713684082
Validation loss: 2.133863151073456

Epoch: 178| Step: 0
Training loss: 1.4197638034820557
Validation loss: 2.123342593510946

Epoch: 5| Step: 1
Training loss: 1.540553331375122
Validation loss: 2.125504121184349

Epoch: 5| Step: 2
Training loss: 2.119062662124634
Validation loss: 2.130417679746946

Epoch: 5| Step: 3
Training loss: 1.8258545398712158
Validation loss: 2.1088484028975167

Epoch: 5| Step: 4
Training loss: 2.195389747619629
Validation loss: 2.1104483902454376

Epoch: 5| Step: 5
Training loss: 2.419562816619873
Validation loss: 2.1015120645364127

Epoch: 5| Step: 6
Training loss: 2.066415309906006
Validation loss: 2.0935781498750052

Epoch: 5| Step: 7
Training loss: 2.1339378356933594
Validation loss: 2.0916527658700943

Epoch: 5| Step: 8
Training loss: 2.074650287628174
Validation loss: 2.0983850906292596

Epoch: 5| Step: 9
Training loss: 1.6946537494659424
Validation loss: 2.108952139814695

Epoch: 5| Step: 10
Training loss: 1.9683873653411865
Validation loss: 2.1167961061000824

Epoch: 5| Step: 11
Training loss: 1.8881300687789917
Validation loss: 2.1096362471580505

Epoch: 179| Step: 0
Training loss: 1.8653331995010376
Validation loss: 2.119785120089849

Epoch: 5| Step: 1
Training loss: 1.8754374980926514
Validation loss: 2.1316651900609336

Epoch: 5| Step: 2
Training loss: 1.7335164546966553
Validation loss: 2.1318010042111077

Epoch: 5| Step: 3
Training loss: 2.2467899322509766
Validation loss: 2.1473783552646637

Epoch: 5| Step: 4
Training loss: 1.8506200313568115
Validation loss: 2.152786836028099

Epoch: 5| Step: 5
Training loss: 2.0156655311584473
Validation loss: 2.144391934076945

Epoch: 5| Step: 6
Training loss: 2.492126941680908
Validation loss: 2.1493905435005822

Epoch: 5| Step: 7
Training loss: 2.1996397972106934
Validation loss: 2.128757198651632

Epoch: 5| Step: 8
Training loss: 1.5809636116027832
Validation loss: 2.1387864450613656

Epoch: 5| Step: 9
Training loss: 1.6587917804718018
Validation loss: 2.1355084826548896

Epoch: 5| Step: 10
Training loss: 2.062255859375
Validation loss: 2.1313240826129913

Epoch: 5| Step: 11
Training loss: 1.4651761054992676
Validation loss: 2.124525770545006

Epoch: 180| Step: 0
Training loss: 2.4418041706085205
Validation loss: 2.132655143737793

Epoch: 5| Step: 1
Training loss: 2.5460736751556396
Validation loss: 2.1331971983114877

Epoch: 5| Step: 2
Training loss: 1.9445968866348267
Validation loss: 2.135710602005323

Epoch: 5| Step: 3
Training loss: 1.8076664209365845
Validation loss: 2.1307297547658286

Epoch: 5| Step: 4
Training loss: 1.8375015258789062
Validation loss: 2.1333814611037574

Epoch: 5| Step: 5
Training loss: 1.901242971420288
Validation loss: 2.14228285352389

Epoch: 5| Step: 6
Training loss: 1.3070080280303955
Validation loss: 2.14137335618337

Epoch: 5| Step: 7
Training loss: 1.7457765340805054
Validation loss: 2.144706810514132

Epoch: 5| Step: 8
Training loss: 1.8578898906707764
Validation loss: 2.1313091814517975

Epoch: 5| Step: 9
Training loss: 1.9274625778198242
Validation loss: 2.1377712140480676

Epoch: 5| Step: 10
Training loss: 2.110718011856079
Validation loss: 2.118900423248609

Epoch: 5| Step: 11
Training loss: 1.584376573562622
Validation loss: 2.110563268264135

Epoch: 181| Step: 0
Training loss: 1.7945644855499268
Validation loss: 2.102877363562584

Epoch: 5| Step: 1
Training loss: 2.271390914916992
Validation loss: 2.0847181926170983

Epoch: 5| Step: 2
Training loss: 2.143972158432007
Validation loss: 2.073865219950676

Epoch: 5| Step: 3
Training loss: 1.6441795825958252
Validation loss: 2.059354523817698

Epoch: 5| Step: 4
Training loss: 1.9435592889785767
Validation loss: 2.064058944582939

Epoch: 5| Step: 5
Training loss: 2.1867833137512207
Validation loss: 2.0650527824958167

Epoch: 5| Step: 6
Training loss: 1.9193891286849976
Validation loss: 2.0655685712893805

Epoch: 5| Step: 7
Training loss: 2.1249072551727295
Validation loss: 2.0765540103117623

Epoch: 5| Step: 8
Training loss: 2.386643886566162
Validation loss: 2.0862868577241898

Epoch: 5| Step: 9
Training loss: 2.058361530303955
Validation loss: 2.0896868109703064

Epoch: 5| Step: 10
Training loss: 1.1830865144729614
Validation loss: 2.087898557384809

Epoch: 5| Step: 11
Training loss: 3.037604808807373
Validation loss: 2.108762800693512

Epoch: 182| Step: 0
Training loss: 2.395120143890381
Validation loss: 2.1356099446614585

Epoch: 5| Step: 1
Training loss: 2.3357348442077637
Validation loss: 2.135873337586721

Epoch: 5| Step: 2
Training loss: 1.5629816055297852
Validation loss: 2.1200098792711892

Epoch: 5| Step: 3
Training loss: 2.0290966033935547
Validation loss: 2.1357515255610147

Epoch: 5| Step: 4
Training loss: 1.876924753189087
Validation loss: 2.1280616174141564

Epoch: 5| Step: 5
Training loss: 1.7758338451385498
Validation loss: 2.134578227996826

Epoch: 5| Step: 6
Training loss: 2.2665913105010986
Validation loss: 2.1349927484989166

Epoch: 5| Step: 7
Training loss: 1.9356575012207031
Validation loss: 2.137905324498812

Epoch: 5| Step: 8
Training loss: 1.9185184240341187
Validation loss: 2.132151340444883

Epoch: 5| Step: 9
Training loss: 1.9917341470718384
Validation loss: 2.1507606705029807

Epoch: 5| Step: 10
Training loss: 1.6917139291763306
Validation loss: 2.142951026558876

Epoch: 5| Step: 11
Training loss: 1.8487045764923096
Validation loss: 2.1333642105261483

Epoch: 183| Step: 0
Training loss: 2.037261724472046
Validation loss: 2.1060594419638314

Epoch: 5| Step: 1
Training loss: 2.576242446899414
Validation loss: 2.0905686219533286

Epoch: 5| Step: 2
Training loss: 1.5798269510269165
Validation loss: 2.0825727035601935

Epoch: 5| Step: 3
Training loss: 2.1813628673553467
Validation loss: 2.0816483000914254

Epoch: 5| Step: 4
Training loss: 1.7791608572006226
Validation loss: 2.0775970121224723

Epoch: 5| Step: 5
Training loss: 1.78571355342865
Validation loss: 2.0718907664219537

Epoch: 5| Step: 6
Training loss: 1.9344907999038696
Validation loss: 2.0945212841033936

Epoch: 5| Step: 7
Training loss: 2.08835506439209
Validation loss: 2.0927638858556747

Epoch: 5| Step: 8
Training loss: 1.9275974035263062
Validation loss: 2.0923732618490853

Epoch: 5| Step: 9
Training loss: 2.0001511573791504
Validation loss: 2.0924710631370544

Epoch: 5| Step: 10
Training loss: 1.629569411277771
Validation loss: 2.112776497999827

Epoch: 5| Step: 11
Training loss: 1.9241132736206055
Validation loss: 2.108995705842972

Epoch: 184| Step: 0
Training loss: 1.515773892402649
Validation loss: 2.1181922554969788

Epoch: 5| Step: 1
Training loss: 1.449092149734497
Validation loss: 2.1203979700803757

Epoch: 5| Step: 2
Training loss: 2.0635430812835693
Validation loss: 2.119389240940412

Epoch: 5| Step: 3
Training loss: 2.409151554107666
Validation loss: 2.123723735411962

Epoch: 5| Step: 4
Training loss: 1.7760356664657593
Validation loss: 2.1306167989969254

Epoch: 5| Step: 5
Training loss: 1.631568193435669
Validation loss: 2.153429319461187

Epoch: 5| Step: 6
Training loss: 2.6474239826202393
Validation loss: 2.1419895191987357

Epoch: 5| Step: 7
Training loss: 1.9571985006332397
Validation loss: 2.1300176481405892

Epoch: 5| Step: 8
Training loss: 2.047203540802002
Validation loss: 2.122152174512545

Epoch: 5| Step: 9
Training loss: 1.7212917804718018
Validation loss: 2.116522709528605

Epoch: 5| Step: 10
Training loss: 2.1217641830444336
Validation loss: 2.1296413987874985

Epoch: 5| Step: 11
Training loss: 1.6066491603851318
Validation loss: 2.127499043941498

Epoch: 185| Step: 0
Training loss: 1.8963706493377686
Validation loss: 2.1054002791643143

Epoch: 5| Step: 1
Training loss: 1.4980323314666748
Validation loss: 2.107897942264875

Epoch: 5| Step: 2
Training loss: 2.096968173980713
Validation loss: 2.1220006247361503

Epoch: 5| Step: 3
Training loss: 1.8127483129501343
Validation loss: 2.1246541142463684

Epoch: 5| Step: 4
Training loss: 1.879838228225708
Validation loss: 2.11715234319369

Epoch: 5| Step: 5
Training loss: 1.7703269720077515
Validation loss: 2.123575657606125

Epoch: 5| Step: 6
Training loss: 1.95528244972229
Validation loss: 2.1301561097304025

Epoch: 5| Step: 7
Training loss: 2.43589448928833
Validation loss: 2.1214792927106223

Epoch: 5| Step: 8
Training loss: 2.1752638816833496
Validation loss: 2.130871201554934

Epoch: 5| Step: 9
Training loss: 1.3914990425109863
Validation loss: 2.1303450961907706

Epoch: 5| Step: 10
Training loss: 2.111572742462158
Validation loss: 2.1366136372089386

Epoch: 5| Step: 11
Training loss: 1.9211654663085938
Validation loss: 2.129006798068682

Epoch: 186| Step: 0
Training loss: 1.952884316444397
Validation loss: 2.1308549294869104

Epoch: 5| Step: 1
Training loss: 2.058629035949707
Validation loss: 2.1345428874095282

Epoch: 5| Step: 2
Training loss: 1.7000678777694702
Validation loss: 2.128494828939438

Epoch: 5| Step: 3
Training loss: 2.1537327766418457
Validation loss: 2.1420723497867584

Epoch: 5| Step: 4
Training loss: 2.0198423862457275
Validation loss: 2.129527121782303

Epoch: 5| Step: 5
Training loss: 1.7383629083633423
Validation loss: 2.1352607955535254

Epoch: 5| Step: 6
Training loss: 2.0842692852020264
Validation loss: 2.1246904184420905

Epoch: 5| Step: 7
Training loss: 1.623888373374939
Validation loss: 2.1298230985800424

Epoch: 5| Step: 8
Training loss: 1.3878203630447388
Validation loss: 2.1536763409773507

Epoch: 5| Step: 9
Training loss: 2.369467258453369
Validation loss: 2.1305303474267325

Epoch: 5| Step: 10
Training loss: 2.1354012489318848
Validation loss: 2.142554094394048

Epoch: 5| Step: 11
Training loss: 1.485235571861267
Validation loss: 2.1217526644468307

Epoch: 187| Step: 0
Training loss: 1.5314868688583374
Validation loss: 2.1306866258382797

Epoch: 5| Step: 1
Training loss: 1.7707111835479736
Validation loss: 2.131238356232643

Epoch: 5| Step: 2
Training loss: 1.9191055297851562
Validation loss: 2.1194828699032464

Epoch: 5| Step: 3
Training loss: 1.9755157232284546
Validation loss: 2.1214610934257507

Epoch: 5| Step: 4
Training loss: 1.3178088665008545
Validation loss: 2.116258184115092

Epoch: 5| Step: 5
Training loss: 1.64543879032135
Validation loss: 2.1235810418923697

Epoch: 5| Step: 6
Training loss: 2.263075828552246
Validation loss: 2.1315106650193534

Epoch: 5| Step: 7
Training loss: 2.6765592098236084
Validation loss: 2.1116119573513665

Epoch: 5| Step: 8
Training loss: 1.6930687427520752
Validation loss: 2.1062146623929343

Epoch: 5| Step: 9
Training loss: 1.7915681600570679
Validation loss: 2.1260792215665183

Epoch: 5| Step: 10
Training loss: 2.513129472732544
Validation loss: 2.1266562044620514

Epoch: 5| Step: 11
Training loss: 2.1463608741760254
Validation loss: 2.128014326095581

Epoch: 188| Step: 0
Training loss: 2.2115728855133057
Validation loss: 2.1347342878580093

Epoch: 5| Step: 1
Training loss: 2.0676321983337402
Validation loss: 2.1500199735164642

Epoch: 5| Step: 2
Training loss: 1.7248064279556274
Validation loss: 2.1367026468118033

Epoch: 5| Step: 3
Training loss: 1.9239215850830078
Validation loss: 2.1425167123476663

Epoch: 5| Step: 4
Training loss: 1.8106098175048828
Validation loss: 2.1438406805197396

Epoch: 5| Step: 5
Training loss: 2.309898853302002
Validation loss: 2.1561853090922036

Epoch: 5| Step: 6
Training loss: 1.5887407064437866
Validation loss: 2.1465100149313607

Epoch: 5| Step: 7
Training loss: 2.203859329223633
Validation loss: 2.142757068077723

Epoch: 5| Step: 8
Training loss: 1.9185326099395752
Validation loss: 2.1480210423469543

Epoch: 5| Step: 9
Training loss: 1.644287109375
Validation loss: 2.1493331839640937

Epoch: 5| Step: 10
Training loss: 1.540116310119629
Validation loss: 2.147114505370458

Epoch: 5| Step: 11
Training loss: 1.8721845149993896
Validation loss: 2.172771761814753

Epoch: 189| Step: 0
Training loss: 1.7050174474716187
Validation loss: 2.1561341087023416

Epoch: 5| Step: 1
Training loss: 2.1256418228149414
Validation loss: 2.1716162810722985

Epoch: 5| Step: 2
Training loss: 1.4815475940704346
Validation loss: 2.168704017996788

Epoch: 5| Step: 3
Training loss: 1.927231788635254
Validation loss: 2.1393612573544183

Epoch: 5| Step: 4
Training loss: 1.8913934230804443
Validation loss: 2.1293794562419257

Epoch: 5| Step: 5
Training loss: 1.9482940435409546
Validation loss: 2.1295827279488244

Epoch: 5| Step: 6
Training loss: 2.2257578372955322
Validation loss: 2.1130539625883102

Epoch: 5| Step: 7
Training loss: 2.2310454845428467
Validation loss: 2.1203793585300446

Epoch: 5| Step: 8
Training loss: 1.8622477054595947
Validation loss: 2.1200799643993378

Epoch: 5| Step: 9
Training loss: 1.7510449886322021
Validation loss: 2.1265071431795755

Epoch: 5| Step: 10
Training loss: 1.9312206506729126
Validation loss: 2.127453843752543

Epoch: 5| Step: 11
Training loss: 2.037731409072876
Validation loss: 2.1320018420616784

Epoch: 190| Step: 0
Training loss: 1.9156423807144165
Validation loss: 2.1333443075418472

Epoch: 5| Step: 1
Training loss: 1.314387559890747
Validation loss: 2.143658399581909

Epoch: 5| Step: 2
Training loss: 2.2490837574005127
Validation loss: 2.1281868120034537

Epoch: 5| Step: 3
Training loss: 2.101783037185669
Validation loss: 2.143302688995997

Epoch: 5| Step: 4
Training loss: 1.853017807006836
Validation loss: 2.1407980819543204

Epoch: 5| Step: 5
Training loss: 2.392315149307251
Validation loss: 2.1492092659076056

Epoch: 5| Step: 6
Training loss: 1.7080910205841064
Validation loss: 2.1372930109500885

Epoch: 5| Step: 7
Training loss: 1.6403656005859375
Validation loss: 2.125398129224777

Epoch: 5| Step: 8
Training loss: 2.0873990058898926
Validation loss: 2.129469042023023

Epoch: 5| Step: 9
Training loss: 1.5982561111450195
Validation loss: 2.1288223564624786

Epoch: 5| Step: 10
Training loss: 2.3089795112609863
Validation loss: 2.1289605100949607

Epoch: 5| Step: 11
Training loss: 1.1905382871627808
Validation loss: 2.1378612716992698

Epoch: 191| Step: 0
Training loss: 1.9194583892822266
Validation loss: 2.1389757295449576

Epoch: 5| Step: 1
Training loss: 2.106691360473633
Validation loss: 2.1442332714796066

Epoch: 5| Step: 2
Training loss: 1.7172664403915405
Validation loss: 2.150046706199646

Epoch: 5| Step: 3
Training loss: 1.2713242769241333
Validation loss: 2.1395135819911957

Epoch: 5| Step: 4
Training loss: 1.975968360900879
Validation loss: 2.1358021398385367

Epoch: 5| Step: 5
Training loss: 2.098832368850708
Validation loss: 2.1346519539753595

Epoch: 5| Step: 6
Training loss: 1.9686050415039062
Validation loss: 2.1176613867282867

Epoch: 5| Step: 7
Training loss: 1.989004373550415
Validation loss: 2.1428699592749276

Epoch: 5| Step: 8
Training loss: 1.9503434896469116
Validation loss: 2.1404679864645004

Epoch: 5| Step: 9
Training loss: 1.9004234075546265
Validation loss: 2.1342161893844604

Epoch: 5| Step: 10
Training loss: 1.8066520690917969
Validation loss: 2.141164710124334

Epoch: 5| Step: 11
Training loss: 3.136580467224121
Validation loss: 2.1416843632857003

Epoch: 192| Step: 0
Training loss: 2.4483044147491455
Validation loss: 2.1389653086662292

Epoch: 5| Step: 1
Training loss: 1.776373267173767
Validation loss: 2.137931356827418

Epoch: 5| Step: 2
Training loss: 1.745428442955017
Validation loss: 2.1310593585173288

Epoch: 5| Step: 3
Training loss: 1.9164527654647827
Validation loss: 2.1368586321671805

Epoch: 5| Step: 4
Training loss: 1.6109907627105713
Validation loss: 2.1355091681083045

Epoch: 5| Step: 5
Training loss: 1.7267299890518188
Validation loss: 2.174516946077347

Epoch: 5| Step: 6
Training loss: 1.7947219610214233
Validation loss: 2.1536202232042947

Epoch: 5| Step: 7
Training loss: 1.921234130859375
Validation loss: 2.1742106775442758

Epoch: 5| Step: 8
Training loss: 2.0631136894226074
Validation loss: 2.1868258168299994

Epoch: 5| Step: 9
Training loss: 2.2224724292755127
Validation loss: 2.1663604776064553

Epoch: 5| Step: 10
Training loss: 2.070992946624756
Validation loss: 2.1716918448607125

Epoch: 5| Step: 11
Training loss: 0.6037340760231018
Validation loss: 2.1624388992786407

Epoch: 193| Step: 0
Training loss: 1.6284414529800415
Validation loss: 2.1477703154087067

Epoch: 5| Step: 1
Training loss: 2.229004144668579
Validation loss: 2.1083955814441047

Epoch: 5| Step: 2
Training loss: 1.716463327407837
Validation loss: 2.1020749360322952

Epoch: 5| Step: 3
Training loss: 1.8954322338104248
Validation loss: 2.097884143392245

Epoch: 5| Step: 4
Training loss: 2.3632073402404785
Validation loss: 2.0994518399238586

Epoch: 5| Step: 5
Training loss: 1.6815427541732788
Validation loss: 2.0951406757036843

Epoch: 5| Step: 6
Training loss: 1.3515875339508057
Validation loss: 2.1107115944226584

Epoch: 5| Step: 7
Training loss: 2.2206358909606934
Validation loss: 2.117504343390465

Epoch: 5| Step: 8
Training loss: 1.7756210565567017
Validation loss: 2.1207158317168555

Epoch: 5| Step: 9
Training loss: 2.677553653717041
Validation loss: 2.1308490335941315

Epoch: 5| Step: 10
Training loss: 1.8072268962860107
Validation loss: 2.122953563928604

Epoch: 5| Step: 11
Training loss: 1.7183279991149902
Validation loss: 2.1364477574825287

Epoch: 194| Step: 0
Training loss: 2.0545496940612793
Validation loss: 2.1554790486892066

Epoch: 5| Step: 1
Training loss: 1.8665164709091187
Validation loss: 2.148599535226822

Epoch: 5| Step: 2
Training loss: 2.3310160636901855
Validation loss: 2.1730892956256866

Epoch: 5| Step: 3
Training loss: 2.035402774810791
Validation loss: 2.1476266185442605

Epoch: 5| Step: 4
Training loss: 2.2095584869384766
Validation loss: 2.1489782631397247

Epoch: 5| Step: 5
Training loss: 1.5084588527679443
Validation loss: 2.158176471789678

Epoch: 5| Step: 6
Training loss: 1.4443728923797607
Validation loss: 2.156646654009819

Epoch: 5| Step: 7
Training loss: 1.8854938745498657
Validation loss: 2.16203565398852

Epoch: 5| Step: 8
Training loss: 2.1884593963623047
Validation loss: 2.14911658068498

Epoch: 5| Step: 9
Training loss: 1.3536736965179443
Validation loss: 2.1543397357066474

Epoch: 5| Step: 10
Training loss: 2.0504729747772217
Validation loss: 2.133384292324384

Epoch: 5| Step: 11
Training loss: 1.224930763244629
Validation loss: 2.123574808239937

Epoch: 195| Step: 0
Training loss: 1.7207081317901611
Validation loss: 2.1413999646902084

Epoch: 5| Step: 1
Training loss: 1.4266520738601685
Validation loss: 2.156426211198171

Epoch: 5| Step: 2
Training loss: 1.9123636484146118
Validation loss: 2.13093601167202

Epoch: 5| Step: 3
Training loss: 1.7664756774902344
Validation loss: 2.1515802343686423

Epoch: 5| Step: 4
Training loss: 2.131286859512329
Validation loss: 2.139294902483622

Epoch: 5| Step: 5
Training loss: 2.174438714981079
Validation loss: 2.151256034771601

Epoch: 5| Step: 6
Training loss: 1.95111882686615
Validation loss: 2.156508540113767

Epoch: 5| Step: 7
Training loss: 2.265556812286377
Validation loss: 2.137347017725309

Epoch: 5| Step: 8
Training loss: 1.670159101486206
Validation loss: 2.145928055047989

Epoch: 5| Step: 9
Training loss: 2.387985944747925
Validation loss: 2.1466389993826547

Epoch: 5| Step: 10
Training loss: 1.680265188217163
Validation loss: 2.163274422287941

Epoch: 5| Step: 11
Training loss: 0.9493312835693359
Validation loss: 2.146691838900248

Epoch: 196| Step: 0
Training loss: 1.6273845434188843
Validation loss: 2.151261513431867

Epoch: 5| Step: 1
Training loss: 1.8531185388565063
Validation loss: 2.150765046477318

Epoch: 5| Step: 2
Training loss: 2.439786672592163
Validation loss: 2.162238279978434

Epoch: 5| Step: 3
Training loss: 1.7982393503189087
Validation loss: 2.1615194280942283

Epoch: 5| Step: 4
Training loss: 2.0438246726989746
Validation loss: 2.1502872904141745

Epoch: 5| Step: 5
Training loss: 2.16208815574646
Validation loss: 2.1507917046546936

Epoch: 5| Step: 6
Training loss: 1.4713995456695557
Validation loss: 2.152223452925682

Epoch: 5| Step: 7
Training loss: 2.1066555976867676
Validation loss: 2.1303795327742896

Epoch: 5| Step: 8
Training loss: 1.8534730672836304
Validation loss: 2.108868951598803

Epoch: 5| Step: 9
Training loss: 1.8569343090057373
Validation loss: 2.1028105368216834

Epoch: 5| Step: 10
Training loss: 2.0516257286071777
Validation loss: 2.1078268736600876

Epoch: 5| Step: 11
Training loss: 2.4751243591308594
Validation loss: 2.075371747215589

Epoch: 197| Step: 0
Training loss: 2.267916202545166
Validation loss: 2.084080840150515

Epoch: 5| Step: 1
Training loss: 1.7364391088485718
Validation loss: 2.089338938395182

Epoch: 5| Step: 2
Training loss: 2.088592290878296
Validation loss: 2.0746116439501443

Epoch: 5| Step: 3
Training loss: 1.9404313564300537
Validation loss: 2.069852352142334

Epoch: 5| Step: 4
Training loss: 1.9141731262207031
Validation loss: 2.0923213064670563

Epoch: 5| Step: 5
Training loss: 2.123711109161377
Validation loss: 2.088298976421356

Epoch: 5| Step: 6
Training loss: 1.5599044561386108
Validation loss: 2.1026738633712134

Epoch: 5| Step: 7
Training loss: 2.0255517959594727
Validation loss: 2.1171968579292297

Epoch: 5| Step: 8
Training loss: 1.8494523763656616
Validation loss: 2.1081215093533197

Epoch: 5| Step: 9
Training loss: 1.827549934387207
Validation loss: 2.107417086760203

Epoch: 5| Step: 10
Training loss: 1.8469321727752686
Validation loss: 2.104250743985176

Epoch: 5| Step: 11
Training loss: 1.6439621448516846
Validation loss: 2.1206920593976974

Epoch: 198| Step: 0
Training loss: 1.7176933288574219
Validation loss: 2.1491614083449044

Epoch: 5| Step: 1
Training loss: 1.9039103984832764
Validation loss: 2.13555446267128

Epoch: 5| Step: 2
Training loss: 2.243206024169922
Validation loss: 2.1536386956771216

Epoch: 5| Step: 3
Training loss: 1.4321260452270508
Validation loss: 2.1341884434223175

Epoch: 5| Step: 4
Training loss: 1.9427191019058228
Validation loss: 2.1368580559889474

Epoch: 5| Step: 5
Training loss: 1.7928411960601807
Validation loss: 2.118497704466184

Epoch: 5| Step: 6
Training loss: 1.5282820463180542
Validation loss: 2.119896481434504

Epoch: 5| Step: 7
Training loss: 1.9335018396377563
Validation loss: 2.1155196726322174

Epoch: 5| Step: 8
Training loss: 1.9634008407592773
Validation loss: 2.1110702802737555

Epoch: 5| Step: 9
Training loss: 2.081973075866699
Validation loss: 2.102948486804962

Epoch: 5| Step: 10
Training loss: 2.6772332191467285
Validation loss: 2.09702305495739

Epoch: 5| Step: 11
Training loss: 2.0469183921813965
Validation loss: 2.1026712507009506

Epoch: 199| Step: 0
Training loss: 1.6386255025863647
Validation loss: 2.106538082162539

Epoch: 5| Step: 1
Training loss: 2.0868072509765625
Validation loss: 2.1143463402986526

Epoch: 5| Step: 2
Training loss: 1.9759823083877563
Validation loss: 2.118792543808619

Epoch: 5| Step: 3
Training loss: 1.8812358379364014
Validation loss: 2.111712063352267

Epoch: 5| Step: 4
Training loss: 2.469858169555664
Validation loss: 2.1099337289730706

Epoch: 5| Step: 5
Training loss: 1.8294684886932373
Validation loss: 2.12783682346344

Epoch: 5| Step: 6
Training loss: 1.5586074590682983
Validation loss: 2.1577326357364655

Epoch: 5| Step: 7
Training loss: 1.80472731590271
Validation loss: 2.1486902882655463

Epoch: 5| Step: 8
Training loss: 2.042215347290039
Validation loss: 2.1355970799922943

Epoch: 5| Step: 9
Training loss: 1.7524465322494507
Validation loss: 2.14975439508756

Epoch: 5| Step: 10
Training loss: 2.108440399169922
Validation loss: 2.1533507655064263

Epoch: 5| Step: 11
Training loss: 1.3347785472869873
Validation loss: 2.118196353316307

Epoch: 200| Step: 0
Training loss: 1.4553563594818115
Validation loss: 2.1409004231293998

Epoch: 5| Step: 1
Training loss: 1.7646710872650146
Validation loss: 2.131887525320053

Epoch: 5| Step: 2
Training loss: 1.6992313861846924
Validation loss: 2.1448679069677987

Epoch: 5| Step: 3
Training loss: 1.2390966415405273
Validation loss: 2.143757313489914

Epoch: 5| Step: 4
Training loss: 1.9709068536758423
Validation loss: 2.15508671104908

Epoch: 5| Step: 5
Training loss: 2.2818713188171387
Validation loss: 2.176596373319626

Epoch: 5| Step: 6
Training loss: 1.2127496004104614
Validation loss: 2.151855861147245

Epoch: 5| Step: 7
Training loss: 2.000609874725342
Validation loss: 2.1594200829664865

Epoch: 5| Step: 8
Training loss: 2.4592156410217285
Validation loss: 2.1576645175615945

Epoch: 5| Step: 9
Training loss: 2.4398691654205322
Validation loss: 2.139421984553337

Epoch: 5| Step: 10
Training loss: 2.3121390342712402
Validation loss: 2.134466752409935

Epoch: 5| Step: 11
Training loss: 1.8150036334991455
Validation loss: 2.132347916563352

Epoch: 201| Step: 0
Training loss: 1.8646240234375
Validation loss: 2.125292122364044

Epoch: 5| Step: 1
Training loss: 2.0873732566833496
Validation loss: 2.1112235536177955

Epoch: 5| Step: 2
Training loss: 2.4918859004974365
Validation loss: 2.1235850552717843

Epoch: 5| Step: 3
Training loss: 1.831551194190979
Validation loss: 2.128224566578865

Epoch: 5| Step: 4
Training loss: 2.2539384365081787
Validation loss: 2.133573810259501

Epoch: 5| Step: 5
Training loss: 1.61709725856781
Validation loss: 2.1460210581620536

Epoch: 5| Step: 6
Training loss: 1.969515085220337
Validation loss: 2.1619593799114227

Epoch: 5| Step: 7
Training loss: 2.1119542121887207
Validation loss: 2.1590461979309716

Epoch: 5| Step: 8
Training loss: 1.5415436029434204
Validation loss: 2.1757127940654755

Epoch: 5| Step: 9
Training loss: 1.8328981399536133
Validation loss: 2.174489453434944

Epoch: 5| Step: 10
Training loss: 1.65398371219635
Validation loss: 2.1728737453619638

Epoch: 5| Step: 11
Training loss: 0.6715422868728638
Validation loss: 2.1739068577686944

Epoch: 202| Step: 0
Training loss: 1.9230505228042603
Validation loss: 2.1896286557118096

Epoch: 5| Step: 1
Training loss: 2.0671749114990234
Validation loss: 2.1633818993965783

Epoch: 5| Step: 2
Training loss: 1.528275728225708
Validation loss: 2.1793610056241355

Epoch: 5| Step: 3
Training loss: 1.665400743484497
Validation loss: 2.1828074802954993

Epoch: 5| Step: 4
Training loss: 1.775750756263733
Validation loss: 2.1655310789744058

Epoch: 5| Step: 5
Training loss: 1.562787652015686
Validation loss: 2.1615497916936874

Epoch: 5| Step: 6
Training loss: 2.3617842197418213
Validation loss: 2.1547069946924844

Epoch: 5| Step: 7
Training loss: 1.7882356643676758
Validation loss: 2.165434484680494

Epoch: 5| Step: 8
Training loss: 1.4622304439544678
Validation loss: 2.1598737935225167

Epoch: 5| Step: 9
Training loss: 2.1219098567962646
Validation loss: 2.1554325173298516

Epoch: 5| Step: 10
Training loss: 2.4575133323669434
Validation loss: 2.1741931388775506

Epoch: 5| Step: 11
Training loss: 2.5517044067382812
Validation loss: 2.165816898147265

Epoch: 203| Step: 0
Training loss: 1.837712049484253
Validation loss: 2.1909243563810983

Epoch: 5| Step: 1
Training loss: 1.7885282039642334
Validation loss: 2.179553379615148

Epoch: 5| Step: 2
Training loss: 1.3587970733642578
Validation loss: 2.188358575105667

Epoch: 5| Step: 3
Training loss: 1.9044854640960693
Validation loss: 2.176602452993393

Epoch: 5| Step: 4
Training loss: 2.6320831775665283
Validation loss: 2.1549285550912223

Epoch: 5| Step: 5
Training loss: 2.0635275840759277
Validation loss: 2.1741758783658347

Epoch: 5| Step: 6
Training loss: 1.6067928075790405
Validation loss: 2.1687901665767035

Epoch: 5| Step: 7
Training loss: 1.3224098682403564
Validation loss: 2.1736677338679633

Epoch: 5| Step: 8
Training loss: 2.1302032470703125
Validation loss: 2.186310827732086

Epoch: 5| Step: 9
Training loss: 2.020845890045166
Validation loss: 2.1800208588441214

Epoch: 5| Step: 10
Training loss: 2.128845691680908
Validation loss: 2.1650769809881845

Epoch: 5| Step: 11
Training loss: 1.4281105995178223
Validation loss: 2.150121440490087

Epoch: 204| Step: 0
Training loss: 1.3982436656951904
Validation loss: 2.1473972549041114

Epoch: 5| Step: 1
Training loss: 1.6644420623779297
Validation loss: 2.1354365845521293

Epoch: 5| Step: 2
Training loss: 1.5503032207489014
Validation loss: 2.1341113249460855

Epoch: 5| Step: 3
Training loss: 1.9699985980987549
Validation loss: 2.1306889355182648

Epoch: 5| Step: 4
Training loss: 2.434544563293457
Validation loss: 2.1459129800399146

Epoch: 5| Step: 5
Training loss: 1.7639878988265991
Validation loss: 2.1516657074292502

Epoch: 5| Step: 6
Training loss: 2.2595105171203613
Validation loss: 2.144897624850273

Epoch: 5| Step: 7
Training loss: 2.226450204849243
Validation loss: 2.1528948644797006

Epoch: 5| Step: 8
Training loss: 2.2047717571258545
Validation loss: 2.1812418550252914

Epoch: 5| Step: 9
Training loss: 1.5246315002441406
Validation loss: 2.181821624437968

Epoch: 5| Step: 10
Training loss: 2.1534790992736816
Validation loss: 2.1757102658351264

Epoch: 5| Step: 11
Training loss: 0.8080803155899048
Validation loss: 2.1619298507769904

Epoch: 205| Step: 0
Training loss: 2.227102279663086
Validation loss: 2.1602777242660522

Epoch: 5| Step: 1
Training loss: 2.228733777999878
Validation loss: 2.1590321511030197

Epoch: 5| Step: 2
Training loss: 1.6212761402130127
Validation loss: 2.175729582707087

Epoch: 5| Step: 3
Training loss: 1.9744317531585693
Validation loss: 2.1767942756414413

Epoch: 5| Step: 4
Training loss: 1.584222435951233
Validation loss: 2.1537340879440308

Epoch: 5| Step: 5
Training loss: 2.171675682067871
Validation loss: 2.147042840719223

Epoch: 5| Step: 6
Training loss: 2.083022117614746
Validation loss: 2.1448840349912643

Epoch: 5| Step: 7
Training loss: 2.2635698318481445
Validation loss: 2.1447686354319253

Epoch: 5| Step: 8
Training loss: 1.6813360452651978
Validation loss: 2.14359379808108

Epoch: 5| Step: 9
Training loss: 1.1823818683624268
Validation loss: 2.1417312920093536

Epoch: 5| Step: 10
Training loss: 1.9792426824569702
Validation loss: 2.147103895743688

Epoch: 5| Step: 11
Training loss: 1.0138976573944092
Validation loss: 2.1479621529579163

Epoch: 206| Step: 0
Training loss: 1.6132252216339111
Validation loss: 2.1574761271476746

Epoch: 5| Step: 1
Training loss: 1.6076656579971313
Validation loss: 2.170187289516131

Epoch: 5| Step: 2
Training loss: 2.7398204803466797
Validation loss: 2.172601376970609

Epoch: 5| Step: 3
Training loss: 1.6916062831878662
Validation loss: 2.1651109606027603

Epoch: 5| Step: 4
Training loss: 1.6535253524780273
Validation loss: 2.177728603283564

Epoch: 5| Step: 5
Training loss: 2.324554443359375
Validation loss: 2.200565814971924

Epoch: 5| Step: 6
Training loss: 2.450155019760132
Validation loss: 2.1800941228866577

Epoch: 5| Step: 7
Training loss: 1.7847459316253662
Validation loss: 2.1763663440942764

Epoch: 5| Step: 8
Training loss: 1.8185555934906006
Validation loss: 2.1845382153987885

Epoch: 5| Step: 9
Training loss: 1.6319191455841064
Validation loss: 2.201440672079722

Epoch: 5| Step: 10
Training loss: 1.8218380212783813
Validation loss: 2.1821873784065247

Epoch: 5| Step: 11
Training loss: 2.008622407913208
Validation loss: 2.155390053987503

Epoch: 207| Step: 0
Training loss: 1.7693440914154053
Validation loss: 2.1364865005016327

Epoch: 5| Step: 1
Training loss: 2.1120052337646484
Validation loss: 2.153957257668177

Epoch: 5| Step: 2
Training loss: 1.907017707824707
Validation loss: 2.137770265340805

Epoch: 5| Step: 3
Training loss: 1.9540693759918213
Validation loss: 2.125095089276632

Epoch: 5| Step: 4
Training loss: 2.1228713989257812
Validation loss: 2.141557534535726

Epoch: 5| Step: 5
Training loss: 1.8417816162109375
Validation loss: 2.1521840691566467

Epoch: 5| Step: 6
Training loss: 1.7862889766693115
Validation loss: 2.161820650100708

Epoch: 5| Step: 7
Training loss: 1.6276394128799438
Validation loss: 2.1795335660378137

Epoch: 5| Step: 8
Training loss: 1.629996657371521
Validation loss: 2.153988872965177

Epoch: 5| Step: 9
Training loss: 2.246577024459839
Validation loss: 2.1569098085165024

Epoch: 5| Step: 10
Training loss: 1.7188751697540283
Validation loss: 2.1889848013718924

Epoch: 5| Step: 11
Training loss: 2.312077760696411
Validation loss: 2.1845530768235526

Epoch: 208| Step: 0
Training loss: 2.0512070655822754
Validation loss: 2.1805172016223273

Epoch: 5| Step: 1
Training loss: 1.8127892017364502
Validation loss: 2.1798576513926187

Epoch: 5| Step: 2
Training loss: 1.8101394176483154
Validation loss: 2.1698899269104004

Epoch: 5| Step: 3
Training loss: 1.8071086406707764
Validation loss: 2.167888546983401

Epoch: 5| Step: 4
Training loss: 2.1741034984588623
Validation loss: 2.1607877810796103

Epoch: 5| Step: 5
Training loss: 1.5538691282272339
Validation loss: 2.1475915859142938

Epoch: 5| Step: 6
Training loss: 1.9149420261383057
Validation loss: 2.157587707042694

Epoch: 5| Step: 7
Training loss: 2.093385696411133
Validation loss: 2.1702768405278525

Epoch: 5| Step: 8
Training loss: 1.8585017919540405
Validation loss: 2.1692194640636444

Epoch: 5| Step: 9
Training loss: 1.9611831903457642
Validation loss: 2.182271038492521

Epoch: 5| Step: 10
Training loss: 1.930479645729065
Validation loss: 2.1856449792782464

Epoch: 5| Step: 11
Training loss: 0.8351112008094788
Validation loss: 2.1688041985034943

Epoch: 209| Step: 0
Training loss: 1.516592264175415
Validation loss: 2.1714451909065247

Epoch: 5| Step: 1
Training loss: 1.610563039779663
Validation loss: 2.1636536767085395

Epoch: 5| Step: 2
Training loss: 1.9239301681518555
Validation loss: 2.142747720082601

Epoch: 5| Step: 3
Training loss: 1.449952483177185
Validation loss: 2.157534137368202

Epoch: 5| Step: 4
Training loss: 2.1989986896514893
Validation loss: 2.148904487490654

Epoch: 5| Step: 5
Training loss: 1.8863162994384766
Validation loss: 2.146646206577619

Epoch: 5| Step: 6
Training loss: 2.1754260063171387
Validation loss: 2.1264647046724954

Epoch: 5| Step: 7
Training loss: 2.1927032470703125
Validation loss: 2.142786448200544

Epoch: 5| Step: 8
Training loss: 1.9156506061553955
Validation loss: 2.1512294511000314

Epoch: 5| Step: 9
Training loss: 1.441713571548462
Validation loss: 2.1362315515677133

Epoch: 5| Step: 10
Training loss: 2.2294297218322754
Validation loss: 2.148398066560427

Epoch: 5| Step: 11
Training loss: 2.4136874675750732
Validation loss: 2.1470470329125724

Epoch: 210| Step: 0
Training loss: 2.3179047107696533
Validation loss: 2.157823532819748

Epoch: 5| Step: 1
Training loss: 1.9550014734268188
Validation loss: 2.1714941511551538

Epoch: 5| Step: 2
Training loss: 2.4394893646240234
Validation loss: 2.1760920137166977

Epoch: 5| Step: 3
Training loss: 1.6541643142700195
Validation loss: 2.1778503954410553

Epoch: 5| Step: 4
Training loss: 1.9038482904434204
Validation loss: 2.16467913488547

Epoch: 5| Step: 5
Training loss: 1.6535476446151733
Validation loss: 2.192782700061798

Epoch: 5| Step: 6
Training loss: 1.2458248138427734
Validation loss: 2.1668236205975213

Epoch: 5| Step: 7
Training loss: 1.5633624792099
Validation loss: 2.1742202192544937

Epoch: 5| Step: 8
Training loss: 2.273764133453369
Validation loss: 2.177183379729589

Epoch: 5| Step: 9
Training loss: 1.8103446960449219
Validation loss: 2.1818151026964188

Epoch: 5| Step: 10
Training loss: 1.4202057123184204
Validation loss: 2.1705190340677896

Epoch: 5| Step: 11
Training loss: 2.0169289112091064
Validation loss: 2.1806896179914474

Epoch: 211| Step: 0
Training loss: 2.208833694458008
Validation loss: 2.184598977367083

Epoch: 5| Step: 1
Training loss: 1.9022786617279053
Validation loss: 2.193348611394564

Epoch: 5| Step: 2
Training loss: 1.8918540477752686
Validation loss: 2.1744466672341027

Epoch: 5| Step: 3
Training loss: 1.8490276336669922
Validation loss: 2.156895875930786

Epoch: 5| Step: 4
Training loss: 1.6356531381607056
Validation loss: 2.149077355861664

Epoch: 5| Step: 5
Training loss: 1.2261537313461304
Validation loss: 2.1497599681218467

Epoch: 5| Step: 6
Training loss: 2.123626708984375
Validation loss: 2.134884476661682

Epoch: 5| Step: 7
Training loss: 1.6038827896118164
Validation loss: 2.142254481712977

Epoch: 5| Step: 8
Training loss: 1.7011150121688843
Validation loss: 2.133031735817591

Epoch: 5| Step: 9
Training loss: 2.0110726356506348
Validation loss: 2.15969709555308

Epoch: 5| Step: 10
Training loss: 2.1013081073760986
Validation loss: 2.1430239429076514

Epoch: 5| Step: 11
Training loss: 2.4778695106506348
Validation loss: 2.1485965301593146

Epoch: 212| Step: 0
Training loss: 1.6833484172821045
Validation loss: 2.1880830824375153

Epoch: 5| Step: 1
Training loss: 2.284540891647339
Validation loss: 2.161499430735906

Epoch: 5| Step: 2
Training loss: 1.7862297296524048
Validation loss: 2.1765975703795752

Epoch: 5| Step: 3
Training loss: 1.7357778549194336
Validation loss: 2.176837826768557

Epoch: 5| Step: 4
Training loss: 1.8926187753677368
Validation loss: 2.162304843465487

Epoch: 5| Step: 5
Training loss: 1.1177051067352295
Validation loss: 2.163285772005717

Epoch: 5| Step: 6
Training loss: 1.7696599960327148
Validation loss: 2.1859437425931296

Epoch: 5| Step: 7
Training loss: 2.3639800548553467
Validation loss: 2.1916979302962623

Epoch: 5| Step: 8
Training loss: 1.6251834630966187
Validation loss: 2.2013059904177985

Epoch: 5| Step: 9
Training loss: 2.124359607696533
Validation loss: 2.166976829369863

Epoch: 5| Step: 10
Training loss: 1.7735035419464111
Validation loss: 2.186225672562917

Epoch: 5| Step: 11
Training loss: 3.0539870262145996
Validation loss: 2.1944960951805115

Epoch: 213| Step: 0
Training loss: 1.5391353368759155
Validation loss: 2.177697012821833

Epoch: 5| Step: 1
Training loss: 2.303928852081299
Validation loss: 2.1750364353259406

Epoch: 5| Step: 2
Training loss: 2.040649890899658
Validation loss: 2.1612370709578195

Epoch: 5| Step: 3
Training loss: 1.3066984415054321
Validation loss: 2.154713531335195

Epoch: 5| Step: 4
Training loss: 1.8109184503555298
Validation loss: 2.1556895077228546

Epoch: 5| Step: 5
Training loss: 2.211469888687134
Validation loss: 2.1363710463047028

Epoch: 5| Step: 6
Training loss: 1.9793860912322998
Validation loss: 2.155375430981318

Epoch: 5| Step: 7
Training loss: 2.1783230304718018
Validation loss: 2.154784401257833

Epoch: 5| Step: 8
Training loss: 1.6998544931411743
Validation loss: 2.1454119930664697

Epoch: 5| Step: 9
Training loss: 1.7962567806243896
Validation loss: 2.166707376639048

Epoch: 5| Step: 10
Training loss: 1.7897441387176514
Validation loss: 2.151655981938044

Epoch: 5| Step: 11
Training loss: 2.27974009513855
Validation loss: 2.1901174982388816

Epoch: 214| Step: 0
Training loss: 1.6606954336166382
Validation loss: 2.1730919579664865

Epoch: 5| Step: 1
Training loss: 1.7477216720581055
Validation loss: 2.1737309396266937

Epoch: 5| Step: 2
Training loss: 2.228524923324585
Validation loss: 2.1925101975599923

Epoch: 5| Step: 3
Training loss: 1.7692617177963257
Validation loss: 2.17373721798261

Epoch: 5| Step: 4
Training loss: 2.1390748023986816
Validation loss: 2.1811166803042092

Epoch: 5| Step: 5
Training loss: 2.2179489135742188
Validation loss: 2.2039961318174996

Epoch: 5| Step: 6
Training loss: 1.6163256168365479
Validation loss: 2.1883270343144736

Epoch: 5| Step: 7
Training loss: 1.4182087182998657
Validation loss: 2.1850654979546866

Epoch: 5| Step: 8
Training loss: 2.4824461936950684
Validation loss: 2.193634351094564

Epoch: 5| Step: 9
Training loss: 1.408217191696167
Validation loss: 2.190443138281504

Epoch: 5| Step: 10
Training loss: 1.802013635635376
Validation loss: 2.1869584967692695

Epoch: 5| Step: 11
Training loss: 1.9270298480987549
Validation loss: 2.178436522682508

Epoch: 215| Step: 0
Training loss: 1.8082149028778076
Validation loss: 2.168445269266764

Epoch: 5| Step: 1
Training loss: 1.9072215557098389
Validation loss: 2.165727068980535

Epoch: 5| Step: 2
Training loss: 1.862910509109497
Validation loss: 2.1492576201756797

Epoch: 5| Step: 3
Training loss: 1.9263334274291992
Validation loss: 2.1756393065055213

Epoch: 5| Step: 4
Training loss: 1.7994657754898071
Validation loss: 2.1617917716503143

Epoch: 5| Step: 5
Training loss: 1.5816385746002197
Validation loss: 2.1905994415283203

Epoch: 5| Step: 6
Training loss: 1.9514544010162354
Validation loss: 2.1906845768292746

Epoch: 5| Step: 7
Training loss: 2.079885482788086
Validation loss: 2.2177632600069046

Epoch: 5| Step: 8
Training loss: 1.5551592111587524
Validation loss: 2.193728595972061

Epoch: 5| Step: 9
Training loss: 2.4076273441314697
Validation loss: 2.2044796347618103

Epoch: 5| Step: 10
Training loss: 1.8116306066513062
Validation loss: 2.206402267018954

Epoch: 5| Step: 11
Training loss: 1.2504191398620605
Validation loss: 2.2079403499762216

Epoch: 216| Step: 0
Training loss: 2.3997631072998047
Validation loss: 2.195856879154841

Epoch: 5| Step: 1
Training loss: 1.7642247676849365
Validation loss: 2.196429967880249

Epoch: 5| Step: 2
Training loss: 1.4736578464508057
Validation loss: 2.1897817800442376

Epoch: 5| Step: 3
Training loss: 2.1200993061065674
Validation loss: 2.1415059020121894

Epoch: 5| Step: 4
Training loss: 1.8126623630523682
Validation loss: 2.1449769685665765

Epoch: 5| Step: 5
Training loss: 1.8771629333496094
Validation loss: 2.144010439515114

Epoch: 5| Step: 6
Training loss: 1.6724615097045898
Validation loss: 2.1307264268398285

Epoch: 5| Step: 7
Training loss: 2.4891865253448486
Validation loss: 2.1319620609283447

Epoch: 5| Step: 8
Training loss: 2.0971455574035645
Validation loss: 2.127868726849556

Epoch: 5| Step: 9
Training loss: 1.1320984363555908
Validation loss: 2.1319307635227838

Epoch: 5| Step: 10
Training loss: 2.0914812088012695
Validation loss: 2.1515122602383294

Epoch: 5| Step: 11
Training loss: 1.353021264076233
Validation loss: 2.13609712322553

Epoch: 217| Step: 0
Training loss: 2.024672031402588
Validation loss: 2.137396812438965

Epoch: 5| Step: 1
Training loss: 1.8370797634124756
Validation loss: 2.141743630170822

Epoch: 5| Step: 2
Training loss: 2.2142653465270996
Validation loss: 2.1454400022824607

Epoch: 5| Step: 3
Training loss: 1.7945610284805298
Validation loss: 2.1504772355159125

Epoch: 5| Step: 4
Training loss: 1.6079542636871338
Validation loss: 2.162073090672493

Epoch: 5| Step: 5
Training loss: 1.8800771236419678
Validation loss: 2.181642005840937

Epoch: 5| Step: 6
Training loss: 1.5059020519256592
Validation loss: 2.2044254541397095

Epoch: 5| Step: 7
Training loss: 2.2651901245117188
Validation loss: 2.1945966879526773

Epoch: 5| Step: 8
Training loss: 2.18730092048645
Validation loss: 2.2031357834736505

Epoch: 5| Step: 9
Training loss: 1.9267631769180298
Validation loss: 2.212882027029991

Epoch: 5| Step: 10
Training loss: 1.5713016986846924
Validation loss: 2.1796756386756897

Epoch: 5| Step: 11
Training loss: 0.5207973122596741
Validation loss: 2.1894061863422394

Epoch: 218| Step: 0
Training loss: 1.7582671642303467
Validation loss: 2.182330916325251

Epoch: 5| Step: 1
Training loss: 1.5376907587051392
Validation loss: 2.1890325347582498

Epoch: 5| Step: 2
Training loss: 1.7063701152801514
Validation loss: 2.1858679205179214

Epoch: 5| Step: 3
Training loss: 1.4613009691238403
Validation loss: 2.179838647445043

Epoch: 5| Step: 4
Training loss: 1.8753341436386108
Validation loss: 2.1785454750061035

Epoch: 5| Step: 5
Training loss: 2.158545732498169
Validation loss: 2.183830032745997

Epoch: 5| Step: 6
Training loss: 2.087120532989502
Validation loss: 2.1851997474829354

Epoch: 5| Step: 7
Training loss: 2.638824462890625
Validation loss: 2.1818134685357413

Epoch: 5| Step: 8
Training loss: 1.544171929359436
Validation loss: 2.177493760983149

Epoch: 5| Step: 9
Training loss: 2.024923801422119
Validation loss: 2.1749196151892343

Epoch: 5| Step: 10
Training loss: 1.6342300176620483
Validation loss: 2.168255935112635

Epoch: 5| Step: 11
Training loss: 2.296532154083252
Validation loss: 2.154772857824961

Epoch: 219| Step: 0
Training loss: 1.982201337814331
Validation loss: 2.163657784461975

Epoch: 5| Step: 1
Training loss: 1.9708116054534912
Validation loss: 2.167425110936165

Epoch: 5| Step: 2
Training loss: 1.9546031951904297
Validation loss: 2.1581216752529144

Epoch: 5| Step: 3
Training loss: 1.6948343515396118
Validation loss: 2.142057398955027

Epoch: 5| Step: 4
Training loss: 1.6086511611938477
Validation loss: 2.144642328222593

Epoch: 5| Step: 5
Training loss: 2.305222511291504
Validation loss: 2.1501650710900626

Epoch: 5| Step: 6
Training loss: 2.2087388038635254
Validation loss: 2.1503746658563614

Epoch: 5| Step: 7
Training loss: 2.149481773376465
Validation loss: 2.139863063891729

Epoch: 5| Step: 8
Training loss: 1.7607215642929077
Validation loss: 2.133504624168078

Epoch: 5| Step: 9
Training loss: 1.7565959692001343
Validation loss: 2.1430893490711846

Epoch: 5| Step: 10
Training loss: 1.4001586437225342
Validation loss: 2.16662568350633

Epoch: 5| Step: 11
Training loss: 0.6667629480361938
Validation loss: 2.173091550668081

Epoch: 220| Step: 0
Training loss: 1.6570112705230713
Validation loss: 2.1861844807863235

Epoch: 5| Step: 1
Training loss: 1.5558944940567017
Validation loss: 2.197309821844101

Epoch: 5| Step: 2
Training loss: 1.4864184856414795
Validation loss: 2.1858118176460266

Epoch: 5| Step: 3
Training loss: 2.036564588546753
Validation loss: 2.182246466477712

Epoch: 5| Step: 4
Training loss: 2.053494930267334
Validation loss: 2.194277346134186

Epoch: 5| Step: 5
Training loss: 1.94734787940979
Validation loss: 2.205209255218506

Epoch: 5| Step: 6
Training loss: 2.643345594406128
Validation loss: 2.2016006658474603

Epoch: 5| Step: 7
Training loss: 1.5990638732910156
Validation loss: 2.202916443347931

Epoch: 5| Step: 8
Training loss: 1.6311219930648804
Validation loss: 2.178297976652781

Epoch: 5| Step: 9
Training loss: 2.1138741970062256
Validation loss: 2.197334791223208

Epoch: 5| Step: 10
Training loss: 2.190103054046631
Validation loss: 2.164445176720619

Epoch: 5| Step: 11
Training loss: 0.8911612033843994
Validation loss: 2.133058006564776

Epoch: 221| Step: 0
Training loss: 1.5905214548110962
Validation loss: 2.126678238312403

Epoch: 5| Step: 1
Training loss: 1.6159210205078125
Validation loss: 2.1271112859249115

Epoch: 5| Step: 2
Training loss: 2.1990485191345215
Validation loss: 2.121849929292997

Epoch: 5| Step: 3
Training loss: 1.5180902481079102
Validation loss: 2.1288760950167975

Epoch: 5| Step: 4
Training loss: 2.443556308746338
Validation loss: 2.125725671648979

Epoch: 5| Step: 5
Training loss: 2.1649956703186035
Validation loss: 2.132388547062874

Epoch: 5| Step: 6
Training loss: 1.4346330165863037
Validation loss: 2.1522718916336694

Epoch: 5| Step: 7
Training loss: 2.4199795722961426
Validation loss: 2.143410086631775

Epoch: 5| Step: 8
Training loss: 2.028627395629883
Validation loss: 2.157371242841085

Epoch: 5| Step: 9
Training loss: 1.913456678390503
Validation loss: 2.162584885954857

Epoch: 5| Step: 10
Training loss: 2.142411708831787
Validation loss: 2.1697622388601303

Epoch: 5| Step: 11
Training loss: 1.6947362422943115
Validation loss: 2.174287607272466

Epoch: 222| Step: 0
Training loss: 1.6513586044311523
Validation loss: 2.1859147449334464

Epoch: 5| Step: 1
Training loss: 1.3567477464675903
Validation loss: 2.180164327224096

Epoch: 5| Step: 2
Training loss: 1.5190401077270508
Validation loss: 2.1856423020362854

Epoch: 5| Step: 3
Training loss: 1.773850679397583
Validation loss: 2.168570950627327

Epoch: 5| Step: 4
Training loss: 2.2152063846588135
Validation loss: 2.1845235526561737

Epoch: 5| Step: 5
Training loss: 2.359463930130005
Validation loss: 2.18972410261631

Epoch: 5| Step: 6
Training loss: 2.393885850906372
Validation loss: 2.1953478306531906

Epoch: 5| Step: 7
Training loss: 2.4701340198516846
Validation loss: 2.1887862235307693

Epoch: 5| Step: 8
Training loss: 1.8654603958129883
Validation loss: 2.1882266451915107

Epoch: 5| Step: 9
Training loss: 1.913522481918335
Validation loss: 2.178470323483149

Epoch: 5| Step: 10
Training loss: 1.6130062341690063
Validation loss: 2.1714530885219574

Epoch: 5| Step: 11
Training loss: 3.0482490062713623
Validation loss: 2.1674649119377136

Epoch: 223| Step: 0
Training loss: 1.7309716939926147
Validation loss: 2.159000486135483

Epoch: 5| Step: 1
Training loss: 1.5140434503555298
Validation loss: 2.149110351999601

Epoch: 5| Step: 2
Training loss: 1.973010778427124
Validation loss: 2.1461100627978644

Epoch: 5| Step: 3
Training loss: 1.7664897441864014
Validation loss: 2.144311080376307

Epoch: 5| Step: 4
Training loss: 2.0609843730926514
Validation loss: 2.1471358239650726

Epoch: 5| Step: 5
Training loss: 2.3073859214782715
Validation loss: 2.15450789531072

Epoch: 5| Step: 6
Training loss: 1.9948227405548096
Validation loss: 2.1469946652650833

Epoch: 5| Step: 7
Training loss: 1.6551496982574463
Validation loss: 2.170689990123113

Epoch: 5| Step: 8
Training loss: 1.8687829971313477
Validation loss: 2.183912386496862

Epoch: 5| Step: 9
Training loss: 1.6583936214447021
Validation loss: 2.179956545432409

Epoch: 5| Step: 10
Training loss: 1.8858568668365479
Validation loss: 2.1778244574864707

Epoch: 5| Step: 11
Training loss: 2.1102442741394043
Validation loss: 2.177275071541468

Epoch: 224| Step: 0
Training loss: 2.0349185466766357
Validation loss: 2.196546653906504

Epoch: 5| Step: 1
Training loss: 1.9564564228057861
Validation loss: 2.2049434880415597

Epoch: 5| Step: 2
Training loss: 1.7561023235321045
Validation loss: 2.21381543080012

Epoch: 5| Step: 3
Training loss: 2.10929536819458
Validation loss: 2.1964010298252106

Epoch: 5| Step: 4
Training loss: 2.353269577026367
Validation loss: 2.2086449563503265

Epoch: 5| Step: 5
Training loss: 1.8504512310028076
Validation loss: 2.2107183933258057

Epoch: 5| Step: 6
Training loss: 1.9566338062286377
Validation loss: 2.1987146586179733

Epoch: 5| Step: 7
Training loss: 1.7969261407852173
Validation loss: 2.201004316409429

Epoch: 5| Step: 8
Training loss: 1.3061659336090088
Validation loss: 2.215157071749369

Epoch: 5| Step: 9
Training loss: 1.656372308731079
Validation loss: 2.1922354251146317

Epoch: 5| Step: 10
Training loss: 1.5291540622711182
Validation loss: 2.1804693142573037

Epoch: 5| Step: 11
Training loss: 1.902618646621704
Validation loss: 2.1807997276385627

Epoch: 225| Step: 0
Training loss: 1.1647753715515137
Validation loss: 2.1623093287150064

Epoch: 5| Step: 1
Training loss: 2.154223918914795
Validation loss: 2.1570601960023246

Epoch: 5| Step: 2
Training loss: 1.9590193033218384
Validation loss: 2.1459690580765405

Epoch: 5| Step: 3
Training loss: 1.6973826885223389
Validation loss: 2.154797946413358

Epoch: 5| Step: 4
Training loss: 2.0348973274230957
Validation loss: 2.1414775947729745

Epoch: 5| Step: 5
Training loss: 2.0779049396514893
Validation loss: 2.161287079254786

Epoch: 5| Step: 6
Training loss: 2.121594190597534
Validation loss: 2.1685190002123513

Epoch: 5| Step: 7
Training loss: 1.478134274482727
Validation loss: 2.180255656441053

Epoch: 5| Step: 8
Training loss: 2.1654815673828125
Validation loss: 2.1652375608682632

Epoch: 5| Step: 9
Training loss: 1.751196265220642
Validation loss: 2.173912932475408

Epoch: 5| Step: 10
Training loss: 1.8186328411102295
Validation loss: 2.185102716088295

Epoch: 5| Step: 11
Training loss: 1.9103213548660278
Validation loss: 2.180577903985977

Epoch: 226| Step: 0
Training loss: 1.798158049583435
Validation loss: 2.187889446814855

Epoch: 5| Step: 1
Training loss: 1.83742356300354
Validation loss: 2.2013088911771774

Epoch: 5| Step: 2
Training loss: 1.9867109060287476
Validation loss: 2.2103187143802643

Epoch: 5| Step: 3
Training loss: 1.7930829524993896
Validation loss: 2.1816049019495645

Epoch: 5| Step: 4
Training loss: 1.6598066091537476
Validation loss: 2.1984128008286157

Epoch: 5| Step: 5
Training loss: 1.334028720855713
Validation loss: 2.1869547168413797

Epoch: 5| Step: 6
Training loss: 1.6336429119110107
Validation loss: 2.1969192028045654

Epoch: 5| Step: 7
Training loss: 2.2865214347839355
Validation loss: 2.182515819867452

Epoch: 5| Step: 8
Training loss: 1.7006423473358154
Validation loss: 2.164088413119316

Epoch: 5| Step: 9
Training loss: 2.1357009410858154
Validation loss: 2.193873663743337

Epoch: 5| Step: 10
Training loss: 2.121131420135498
Validation loss: 2.165750508507093

Epoch: 5| Step: 11
Training loss: 1.529157042503357
Validation loss: 2.192278578877449

Epoch: 227| Step: 0
Training loss: 1.7198768854141235
Validation loss: 2.1840395629405975

Epoch: 5| Step: 1
Training loss: 1.582655906677246
Validation loss: 2.1716105739275613

Epoch: 5| Step: 2
Training loss: 1.9773719310760498
Validation loss: 2.1739533990621567

Epoch: 5| Step: 3
Training loss: 1.6833232641220093
Validation loss: 2.174991418917974

Epoch: 5| Step: 4
Training loss: 1.3708064556121826
Validation loss: 2.176618049542109

Epoch: 5| Step: 5
Training loss: 2.016019105911255
Validation loss: 2.177267740170161

Epoch: 5| Step: 6
Training loss: 1.9051765203475952
Validation loss: 2.171499272187551

Epoch: 5| Step: 7
Training loss: 1.9398205280303955
Validation loss: 2.1775280435880027

Epoch: 5| Step: 8
Training loss: 1.8750450611114502
Validation loss: 2.1711857666571936

Epoch: 5| Step: 9
Training loss: 2.212822675704956
Validation loss: 2.1773556619882584

Epoch: 5| Step: 10
Training loss: 1.7184604406356812
Validation loss: 2.185266966621081

Epoch: 5| Step: 11
Training loss: 1.7273461818695068
Validation loss: 2.1726552645365396

Epoch: 228| Step: 0
Training loss: 1.5426931381225586
Validation loss: 2.178824409842491

Epoch: 5| Step: 1
Training loss: 1.9580847024917603
Validation loss: 2.174970328807831

Epoch: 5| Step: 2
Training loss: 2.1092987060546875
Validation loss: 2.1497098008791604

Epoch: 5| Step: 3
Training loss: 1.6374843120574951
Validation loss: 2.1751005947589874

Epoch: 5| Step: 4
Training loss: 1.5252686738967896
Validation loss: 2.1738788386185965

Epoch: 5| Step: 5
Training loss: 1.7909080982208252
Validation loss: 2.1551409165064492

Epoch: 5| Step: 6
Training loss: 1.835291862487793
Validation loss: 2.166199882825216

Epoch: 5| Step: 7
Training loss: 1.5675121545791626
Validation loss: 2.180967847506205

Epoch: 5| Step: 8
Training loss: 2.609955310821533
Validation loss: 2.1768694122632346

Epoch: 5| Step: 9
Training loss: 2.16660475730896
Validation loss: 2.18460084994634

Epoch: 5| Step: 10
Training loss: 1.5445640087127686
Validation loss: 2.187058558066686

Epoch: 5| Step: 11
Training loss: 0.7749326825141907
Validation loss: 2.197406977415085

Epoch: 229| Step: 0
Training loss: 1.6832640171051025
Validation loss: 2.1871235320965448

Epoch: 5| Step: 1
Training loss: 1.6237661838531494
Validation loss: 2.188263456026713

Epoch: 5| Step: 2
Training loss: 1.6416661739349365
Validation loss: 2.174341102441152

Epoch: 5| Step: 3
Training loss: 1.9569272994995117
Validation loss: 2.2009298900763192

Epoch: 5| Step: 4
Training loss: 2.1604602336883545
Validation loss: 2.1882979571819305

Epoch: 5| Step: 5
Training loss: 2.2701008319854736
Validation loss: 2.181622942288717

Epoch: 5| Step: 6
Training loss: 2.3313817977905273
Validation loss: 2.1809332023064294

Epoch: 5| Step: 7
Training loss: 1.7243030071258545
Validation loss: 2.177766208847364

Epoch: 5| Step: 8
Training loss: 1.5588891506195068
Validation loss: 2.154933363199234

Epoch: 5| Step: 9
Training loss: 1.7842944860458374
Validation loss: 2.14603062470754

Epoch: 5| Step: 10
Training loss: 1.6170095205307007
Validation loss: 2.1389631579319635

Epoch: 5| Step: 11
Training loss: 0.9774348735809326
Validation loss: 2.1367344756921134

Epoch: 230| Step: 0
Training loss: 1.7608932256698608
Validation loss: 2.1281880040963492

Epoch: 5| Step: 1
Training loss: 2.6127285957336426
Validation loss: 2.1381538758675256

Epoch: 5| Step: 2
Training loss: 1.896636962890625
Validation loss: 2.154560476541519

Epoch: 5| Step: 3
Training loss: 1.72736394405365
Validation loss: 2.1633478899796805

Epoch: 5| Step: 4
Training loss: 0.9886398315429688
Validation loss: 2.17471111814181

Epoch: 5| Step: 5
Training loss: 1.8169887065887451
Validation loss: 2.1863205830256143

Epoch: 5| Step: 6
Training loss: 1.8173885345458984
Validation loss: 2.1806830763816833

Epoch: 5| Step: 7
Training loss: 1.712209701538086
Validation loss: 2.171170095602671

Epoch: 5| Step: 8
Training loss: 1.5082504749298096
Validation loss: 2.1940093835194907

Epoch: 5| Step: 9
Training loss: 2.10140061378479
Validation loss: 2.198457474509875

Epoch: 5| Step: 10
Training loss: 1.8914600610733032
Validation loss: 2.1831652422746024

Epoch: 5| Step: 11
Training loss: 2.751312732696533
Validation loss: 2.1988461216290793

Epoch: 231| Step: 0
Training loss: 1.2451400756835938
Validation loss: 2.172062729795774

Epoch: 5| Step: 1
Training loss: 1.6101077795028687
Validation loss: 2.1858542462189994

Epoch: 5| Step: 2
Training loss: 2.5194897651672363
Validation loss: 2.1821882128715515

Epoch: 5| Step: 3
Training loss: 1.572428584098816
Validation loss: 2.1848501761754355

Epoch: 5| Step: 4
Training loss: 2.0141665935516357
Validation loss: 2.185279438893

Epoch: 5| Step: 5
Training loss: 2.1831607818603516
Validation loss: 2.1928771138191223

Epoch: 5| Step: 6
Training loss: 1.8769543170928955
Validation loss: 2.1855250895023346

Epoch: 5| Step: 7
Training loss: 1.0419366359710693
Validation loss: 2.200249264637629

Epoch: 5| Step: 8
Training loss: 2.063702344894409
Validation loss: 2.170200675725937

Epoch: 5| Step: 9
Training loss: 1.9223964214324951
Validation loss: 2.1732537200053534

Epoch: 5| Step: 10
Training loss: 2.1423070430755615
Validation loss: 2.158125857512156

Epoch: 5| Step: 11
Training loss: 1.603588342666626
Validation loss: 2.1785265604654946

Epoch: 232| Step: 0
Training loss: 2.174447536468506
Validation loss: 2.178426742553711

Epoch: 5| Step: 1
Training loss: 1.721957802772522
Validation loss: 2.2000486155351004

Epoch: 5| Step: 2
Training loss: 2.132692813873291
Validation loss: 2.2113760908444724

Epoch: 5| Step: 3
Training loss: 1.705204963684082
Validation loss: 2.195418988664945

Epoch: 5| Step: 4
Training loss: 1.7177820205688477
Validation loss: 2.209301918745041

Epoch: 5| Step: 5
Training loss: 1.7495365142822266
Validation loss: 2.2207808196544647

Epoch: 5| Step: 6
Training loss: 1.4304007291793823
Validation loss: 2.203360070784887

Epoch: 5| Step: 7
Training loss: 1.9415630102157593
Validation loss: 2.21375764409701

Epoch: 5| Step: 8
Training loss: 1.6075260639190674
Validation loss: 2.2105514059464135

Epoch: 5| Step: 9
Training loss: 1.9778366088867188
Validation loss: 2.198518847425779

Epoch: 5| Step: 10
Training loss: 1.6323976516723633
Validation loss: 2.1893967539072037

Epoch: 5| Step: 11
Training loss: 2.519620180130005
Validation loss: 2.206814909974734

Epoch: 233| Step: 0
Training loss: 1.701857566833496
Validation loss: 2.202204088370005

Epoch: 5| Step: 1
Training loss: 2.0130794048309326
Validation loss: 2.2137522300084433

Epoch: 5| Step: 2
Training loss: 1.8163185119628906
Validation loss: 2.2149308820565543

Epoch: 5| Step: 3
Training loss: 2.033353328704834
Validation loss: 2.2193404783805213

Epoch: 5| Step: 4
Training loss: 2.139418125152588
Validation loss: 2.210231135288874

Epoch: 5| Step: 5
Training loss: 1.841988205909729
Validation loss: 2.2073679119348526

Epoch: 5| Step: 6
Training loss: 1.6915626525878906
Validation loss: 2.199072058002154

Epoch: 5| Step: 7
Training loss: 1.3469164371490479
Validation loss: 2.234759201606115

Epoch: 5| Step: 8
Training loss: 1.0168652534484863
Validation loss: 2.2166626155376434

Epoch: 5| Step: 9
Training loss: 2.2268033027648926
Validation loss: 2.2039963801701865

Epoch: 5| Step: 10
Training loss: 2.045752763748169
Validation loss: 2.1824334263801575

Epoch: 5| Step: 11
Training loss: 1.5356769561767578
Validation loss: 2.2178240915139518

Epoch: 234| Step: 0
Training loss: 2.0696232318878174
Validation loss: 2.1987439741690955

Epoch: 5| Step: 1
Training loss: 1.3408596515655518
Validation loss: 2.2113266537586846

Epoch: 5| Step: 2
Training loss: 1.812127709388733
Validation loss: 2.203613112370173

Epoch: 5| Step: 3
Training loss: 2.7820217609405518
Validation loss: 2.2021950582663217

Epoch: 5| Step: 4
Training loss: 1.8829967975616455
Validation loss: 2.175984188914299

Epoch: 5| Step: 5
Training loss: 1.3579386472702026
Validation loss: 2.174465775489807

Epoch: 5| Step: 6
Training loss: 2.289738416671753
Validation loss: 2.1712599446376166

Epoch: 5| Step: 7
Training loss: 1.1690493822097778
Validation loss: 2.1824789692958197

Epoch: 5| Step: 8
Training loss: 1.8897746801376343
Validation loss: 2.1972056726614633

Epoch: 5| Step: 9
Training loss: 1.932039499282837
Validation loss: 2.178340713183085

Epoch: 5| Step: 10
Training loss: 1.2729908227920532
Validation loss: 2.19469124575456

Epoch: 5| Step: 11
Training loss: 2.1253442764282227
Validation loss: 2.178409516811371

Epoch: 235| Step: 0
Training loss: 2.0948433876037598
Validation loss: 2.1722917556762695

Epoch: 5| Step: 1
Training loss: 2.2130699157714844
Validation loss: 2.1927230854829154

Epoch: 5| Step: 2
Training loss: 1.9352779388427734
Validation loss: 2.1734555860360465

Epoch: 5| Step: 3
Training loss: 1.7514909505844116
Validation loss: 2.178898880879084

Epoch: 5| Step: 4
Training loss: 1.9627535343170166
Validation loss: 2.164404029647509

Epoch: 5| Step: 5
Training loss: 1.9833234548568726
Validation loss: 2.157537897427877

Epoch: 5| Step: 6
Training loss: 1.8387200832366943
Validation loss: 2.1666083335876465

Epoch: 5| Step: 7
Training loss: 1.781715750694275
Validation loss: 2.1396111200253167

Epoch: 5| Step: 8
Training loss: 1.5833396911621094
Validation loss: 2.1640134751796722

Epoch: 5| Step: 9
Training loss: 1.5735832452774048
Validation loss: 2.1844709565242133

Epoch: 5| Step: 10
Training loss: 1.7069580554962158
Validation loss: 2.1799089213212333

Epoch: 5| Step: 11
Training loss: 0.8691195249557495
Validation loss: 2.2172415355841317

Epoch: 236| Step: 0
Training loss: 1.805694580078125
Validation loss: 2.215351566672325

Epoch: 5| Step: 1
Training loss: 1.7910922765731812
Validation loss: 2.2262271444002786

Epoch: 5| Step: 2
Training loss: 1.9786981344223022
Validation loss: 2.2227170318365097

Epoch: 5| Step: 3
Training loss: 1.579775094985962
Validation loss: 2.2241479754447937

Epoch: 5| Step: 4
Training loss: 1.6462981700897217
Validation loss: 2.218785415093104

Epoch: 5| Step: 5
Training loss: 1.419642686843872
Validation loss: 2.2176972776651382

Epoch: 5| Step: 6
Training loss: 2.0313103199005127
Validation loss: 2.188259025414785

Epoch: 5| Step: 7
Training loss: 1.702368974685669
Validation loss: 2.1988538801670074

Epoch: 5| Step: 8
Training loss: 2.452108144760132
Validation loss: 2.2070887287457785

Epoch: 5| Step: 9
Training loss: 1.3198561668395996
Validation loss: 2.1804034610589347

Epoch: 5| Step: 10
Training loss: 1.9843628406524658
Validation loss: 2.1984737118085227

Epoch: 5| Step: 11
Training loss: 1.8746511936187744
Validation loss: 2.2021988530953727

Epoch: 237| Step: 0
Training loss: 2.152120351791382
Validation loss: 2.1771062165498734

Epoch: 5| Step: 1
Training loss: 1.4071078300476074
Validation loss: 2.2014966209729514

Epoch: 5| Step: 2
Training loss: 1.569757342338562
Validation loss: 2.2019793887933097

Epoch: 5| Step: 3
Training loss: 1.6790239810943604
Validation loss: 2.1811755299568176

Epoch: 5| Step: 4
Training loss: 1.674009084701538
Validation loss: 2.2005595664183297

Epoch: 5| Step: 5
Training loss: 1.4861959218978882
Validation loss: 2.193342094620069

Epoch: 5| Step: 6
Training loss: 1.7952731847763062
Validation loss: 2.2235880494117737

Epoch: 5| Step: 7
Training loss: 2.1830050945281982
Validation loss: 2.180481423934301

Epoch: 5| Step: 8
Training loss: 1.4873733520507812
Validation loss: 2.222666233778

Epoch: 5| Step: 9
Training loss: 1.7363626956939697
Validation loss: 2.2224891434113183

Epoch: 5| Step: 10
Training loss: 2.5136284828186035
Validation loss: 2.236396903793017

Epoch: 5| Step: 11
Training loss: 1.2090827226638794
Validation loss: 2.2067272712786994

Epoch: 238| Step: 0
Training loss: 2.0294759273529053
Validation loss: 2.225086897611618

Epoch: 5| Step: 1
Training loss: 1.4947067499160767
Validation loss: 2.219389686981837

Epoch: 5| Step: 2
Training loss: 2.3399081230163574
Validation loss: 2.212345689535141

Epoch: 5| Step: 3
Training loss: 1.7058143615722656
Validation loss: 2.1857634087403617

Epoch: 5| Step: 4
Training loss: 2.9225997924804688
Validation loss: 2.1792315542697906

Epoch: 5| Step: 5
Training loss: 1.3657010793685913
Validation loss: 2.1591995457808175

Epoch: 5| Step: 6
Training loss: 2.218285083770752
Validation loss: 2.1565454800923667

Epoch: 5| Step: 7
Training loss: 1.8866503238677979
Validation loss: 2.1217969954013824

Epoch: 5| Step: 8
Training loss: 1.5522164106369019
Validation loss: 2.1345255076885223

Epoch: 5| Step: 9
Training loss: 1.2209317684173584
Validation loss: 2.122898429632187

Epoch: 5| Step: 10
Training loss: 1.8727611303329468
Validation loss: 2.1228298395872116

Epoch: 5| Step: 11
Training loss: 1.2505364418029785
Validation loss: 2.124082992474238

Epoch: 239| Step: 0
Training loss: 1.7478663921356201
Validation loss: 2.121542195479075

Epoch: 5| Step: 1
Training loss: 1.7451568841934204
Validation loss: 2.1234985490640006

Epoch: 5| Step: 2
Training loss: 1.7042661905288696
Validation loss: 2.117173492908478

Epoch: 5| Step: 3
Training loss: 1.7538601160049438
Validation loss: 2.1213677873214087

Epoch: 5| Step: 4
Training loss: 1.7480472326278687
Validation loss: 2.132256180047989

Epoch: 5| Step: 5
Training loss: 2.0654945373535156
Validation loss: 2.123878076672554

Epoch: 5| Step: 6
Training loss: 1.8022651672363281
Validation loss: 2.126454467574755

Epoch: 5| Step: 7
Training loss: 2.4361369609832764
Validation loss: 2.136656418442726

Epoch: 5| Step: 8
Training loss: 1.8790943622589111
Validation loss: 2.14238640666008

Epoch: 5| Step: 9
Training loss: 2.1337242126464844
Validation loss: 2.1463562647501626

Epoch: 5| Step: 10
Training loss: 1.8774547576904297
Validation loss: 2.162012736002604

Epoch: 5| Step: 11
Training loss: 1.6254796981811523
Validation loss: 2.165443037947019

Epoch: 240| Step: 0
Training loss: 1.555037260055542
Validation loss: 2.1802084843317666

Epoch: 5| Step: 1
Training loss: 1.2980425357818604
Validation loss: 2.174846798181534

Epoch: 5| Step: 2
Training loss: 2.3156707286834717
Validation loss: 2.188779811064402

Epoch: 5| Step: 3
Training loss: 2.0492732524871826
Validation loss: 2.181078573067983

Epoch: 5| Step: 4
Training loss: 1.6233733892440796
Validation loss: 2.160647004842758

Epoch: 5| Step: 5
Training loss: 1.7699981927871704
Validation loss: 2.1822924613952637

Epoch: 5| Step: 6
Training loss: 1.7905464172363281
Validation loss: 2.2020597408215203

Epoch: 5| Step: 7
Training loss: 2.0565433502197266
Validation loss: 2.185435305039088

Epoch: 5| Step: 8
Training loss: 1.5657784938812256
Validation loss: 2.199573596318563

Epoch: 5| Step: 9
Training loss: 1.8210804462432861
Validation loss: 2.2153641233841577

Epoch: 5| Step: 10
Training loss: 2.208129405975342
Validation loss: 2.211094776789347

Epoch: 5| Step: 11
Training loss: 1.1229147911071777
Validation loss: 2.212714026371638

Epoch: 241| Step: 0
Training loss: 1.8123385906219482
Validation loss: 2.190663014849027

Epoch: 5| Step: 1
Training loss: 1.8395503759384155
Validation loss: 2.2149090468883514

Epoch: 5| Step: 2
Training loss: 1.7390493154525757
Validation loss: 2.2143507450819016

Epoch: 5| Step: 3
Training loss: 1.921974778175354
Validation loss: 2.1913268864154816

Epoch: 5| Step: 4
Training loss: 2.0975308418273926
Validation loss: 2.214119036992391

Epoch: 5| Step: 5
Training loss: 2.018508195877075
Validation loss: 2.229935040076574

Epoch: 5| Step: 6
Training loss: 1.764944314956665
Validation loss: 2.2134248167276382

Epoch: 5| Step: 7
Training loss: 1.4156421422958374
Validation loss: 2.198128347595533

Epoch: 5| Step: 8
Training loss: 1.640639305114746
Validation loss: 2.2095382610956826

Epoch: 5| Step: 9
Training loss: 1.6566193103790283
Validation loss: 2.191321219007174

Epoch: 5| Step: 10
Training loss: 1.5754482746124268
Validation loss: 2.2066583087046943

Epoch: 5| Step: 11
Training loss: 2.669219493865967
Validation loss: 2.2086355288823447

Epoch: 242| Step: 0
Training loss: 1.5333079099655151
Validation loss: 2.1996387938658395

Epoch: 5| Step: 1
Training loss: 1.7124032974243164
Validation loss: 2.200683524211248

Epoch: 5| Step: 2
Training loss: 1.1592180728912354
Validation loss: 2.2283092935880027

Epoch: 5| Step: 3
Training loss: 1.9297378063201904
Validation loss: 2.200412482023239

Epoch: 5| Step: 4
Training loss: 1.3084357976913452
Validation loss: 2.19250758488973

Epoch: 5| Step: 5
Training loss: 1.7814298868179321
Validation loss: 2.2009852280219397

Epoch: 5| Step: 6
Training loss: 2.0588650703430176
Validation loss: 2.2113471825917563

Epoch: 5| Step: 7
Training loss: 2.2083210945129395
Validation loss: 2.201648309826851

Epoch: 5| Step: 8
Training loss: 1.8803508281707764
Validation loss: 2.217161307732264

Epoch: 5| Step: 9
Training loss: 2.0842370986938477
Validation loss: 2.2131487230459848

Epoch: 5| Step: 10
Training loss: 2.133002758026123
Validation loss: 2.218124106526375

Epoch: 5| Step: 11
Training loss: 1.6321797370910645
Validation loss: 2.210942601164182

Epoch: 243| Step: 0
Training loss: 1.5176721811294556
Validation loss: 2.2166850020488105

Epoch: 5| Step: 1
Training loss: 1.759012222290039
Validation loss: 2.2057186911503472

Epoch: 5| Step: 2
Training loss: 1.3608903884887695
Validation loss: 2.2373887995878854

Epoch: 5| Step: 3
Training loss: 1.998613953590393
Validation loss: 2.2246643801530204

Epoch: 5| Step: 4
Training loss: 1.9206491708755493
Validation loss: 2.2309413055578866

Epoch: 5| Step: 5
Training loss: 1.5144639015197754
Validation loss: 2.235064754883448

Epoch: 5| Step: 6
Training loss: 1.5976026058197021
Validation loss: 2.221381296714147

Epoch: 5| Step: 7
Training loss: 2.268873929977417
Validation loss: 2.2215395122766495

Epoch: 5| Step: 8
Training loss: 2.0406875610351562
Validation loss: 2.213739881912867

Epoch: 5| Step: 9
Training loss: 2.105569362640381
Validation loss: 2.2055228849252067

Epoch: 5| Step: 10
Training loss: 1.8897205591201782
Validation loss: 2.2062133451302848

Epoch: 5| Step: 11
Training loss: 2.127915859222412
Validation loss: 2.217765584588051

Epoch: 244| Step: 0
Training loss: 1.3168978691101074
Validation loss: 2.205794741710027

Epoch: 5| Step: 1
Training loss: 1.9934005737304688
Validation loss: 2.2115399837493896

Epoch: 5| Step: 2
Training loss: 1.9917347431182861
Validation loss: 2.2187085449695587

Epoch: 5| Step: 3
Training loss: 2.107041597366333
Validation loss: 2.216423213481903

Epoch: 5| Step: 4
Training loss: 1.5483677387237549
Validation loss: 2.1984589944283166

Epoch: 5| Step: 5
Training loss: 2.111938953399658
Validation loss: 2.198581318060557

Epoch: 5| Step: 6
Training loss: 1.7814197540283203
Validation loss: 2.2036910951137543

Epoch: 5| Step: 7
Training loss: 1.9398672580718994
Validation loss: 2.2016254663467407

Epoch: 5| Step: 8
Training loss: 2.0151524543762207
Validation loss: 2.191089779138565

Epoch: 5| Step: 9
Training loss: 1.9176340103149414
Validation loss: 2.1851286043723426

Epoch: 5| Step: 10
Training loss: 1.500116229057312
Validation loss: 2.171465441584587

Epoch: 5| Step: 11
Training loss: 1.459609866142273
Validation loss: 2.157204329967499

Epoch: 245| Step: 0
Training loss: 1.6255096197128296
Validation loss: 2.1723505904277167

Epoch: 5| Step: 1
Training loss: 1.485006332397461
Validation loss: 2.1653942267100015

Epoch: 5| Step: 2
Training loss: 2.0489513874053955
Validation loss: 2.167016158501307

Epoch: 5| Step: 3
Training loss: 1.829880952835083
Validation loss: 2.19944699605306

Epoch: 5| Step: 4
Training loss: 2.0574803352355957
Validation loss: 2.2018593351046243

Epoch: 5| Step: 5
Training loss: 1.3731787204742432
Validation loss: 2.2120566368103027

Epoch: 5| Step: 6
Training loss: 1.8735034465789795
Validation loss: 2.230506499608358

Epoch: 5| Step: 7
Training loss: 1.6646003723144531
Validation loss: 2.217407375574112

Epoch: 5| Step: 8
Training loss: 1.6737312078475952
Validation loss: 2.2213732997576394

Epoch: 5| Step: 9
Training loss: 2.29142427444458
Validation loss: 2.2169940024614334

Epoch: 5| Step: 10
Training loss: 1.8628746271133423
Validation loss: 2.2034790217876434

Epoch: 5| Step: 11
Training loss: 1.6177388429641724
Validation loss: 2.212289333343506

Epoch: 246| Step: 0
Training loss: 1.2525973320007324
Validation loss: 2.2060118118921914

Epoch: 5| Step: 1
Training loss: 2.0323777198791504
Validation loss: 2.187727545698484

Epoch: 5| Step: 2
Training loss: 2.673661708831787
Validation loss: 2.151316006978353

Epoch: 5| Step: 3
Training loss: 1.666690468788147
Validation loss: 2.1814172665278115

Epoch: 5| Step: 4
Training loss: 2.090437889099121
Validation loss: 2.180565228064855

Epoch: 5| Step: 5
Training loss: 1.445493459701538
Validation loss: 2.177679792046547

Epoch: 5| Step: 6
Training loss: 1.5687719583511353
Validation loss: 2.1962321201960244

Epoch: 5| Step: 7
Training loss: 1.24805748462677
Validation loss: 2.2001573145389557

Epoch: 5| Step: 8
Training loss: 2.0008199214935303
Validation loss: 2.1814975986878076

Epoch: 5| Step: 9
Training loss: 1.6206352710723877
Validation loss: 2.1782147039969764

Epoch: 5| Step: 10
Training loss: 2.202793836593628
Validation loss: 2.1833537022272744

Epoch: 5| Step: 11
Training loss: 1.0565096139907837
Validation loss: 2.1728439778089523

Epoch: 247| Step: 0
Training loss: 1.9618825912475586
Validation loss: 2.1899456282456717

Epoch: 5| Step: 1
Training loss: 1.731557846069336
Validation loss: 2.1939139862855277

Epoch: 5| Step: 2
Training loss: 2.4342079162597656
Validation loss: 2.193876435359319

Epoch: 5| Step: 3
Training loss: 2.0091233253479004
Validation loss: 2.2118724435567856

Epoch: 5| Step: 4
Training loss: 1.4355056285858154
Validation loss: 2.2301281789938607

Epoch: 5| Step: 5
Training loss: 2.385329484939575
Validation loss: 2.211932415763537

Epoch: 5| Step: 6
Training loss: 1.415440320968628
Validation loss: 2.225236435731252

Epoch: 5| Step: 7
Training loss: 1.964044213294983
Validation loss: 2.2328096131483712

Epoch: 5| Step: 8
Training loss: 1.8827778100967407
Validation loss: 2.226417377591133

Epoch: 5| Step: 9
Training loss: 1.6823793649673462
Validation loss: 2.1984917521476746

Epoch: 5| Step: 10
Training loss: 1.0148687362670898
Validation loss: 2.177344168225924

Epoch: 5| Step: 11
Training loss: 2.8847808837890625
Validation loss: 2.171570618947347

Epoch: 248| Step: 0
Training loss: 2.2262816429138184
Validation loss: 2.1857689867417016

Epoch: 5| Step: 1
Training loss: 1.7280781269073486
Validation loss: 2.16735448439916

Epoch: 5| Step: 2
Training loss: 1.3820704221725464
Validation loss: 2.1700331966082254

Epoch: 5| Step: 3
Training loss: 1.4939528703689575
Validation loss: 2.162115047375361

Epoch: 5| Step: 4
Training loss: 1.8917735815048218
Validation loss: 2.162583907445272

Epoch: 5| Step: 5
Training loss: 1.976832628250122
Validation loss: 2.1730836580197015

Epoch: 5| Step: 6
Training loss: 1.9312753677368164
Validation loss: 2.1881054242451987

Epoch: 5| Step: 7
Training loss: 2.078040361404419
Validation loss: 2.1689012298981347

Epoch: 5| Step: 8
Training loss: 2.0591177940368652
Validation loss: 2.17863105237484

Epoch: 5| Step: 9
Training loss: 1.9602863788604736
Validation loss: 2.188848296801249

Epoch: 5| Step: 10
Training loss: 1.787816047668457
Validation loss: 2.1828145186106362

Epoch: 5| Step: 11
Training loss: 1.4811477661132812
Validation loss: 2.1712719798088074

Epoch: 249| Step: 0
Training loss: 1.4310343265533447
Validation loss: 2.188593099514643

Epoch: 5| Step: 1
Training loss: 1.3574697971343994
Validation loss: 2.1997503538926444

Epoch: 5| Step: 2
Training loss: 2.6852364540100098
Validation loss: 2.2216616670290628

Epoch: 5| Step: 3
Training loss: 1.8291047811508179
Validation loss: 2.21719428896904

Epoch: 5| Step: 4
Training loss: 2.007453203201294
Validation loss: 2.2286566694577536

Epoch: 5| Step: 5
Training loss: 0.9882789850234985
Validation loss: 2.234318564335505

Epoch: 5| Step: 6
Training loss: 1.6227748394012451
Validation loss: 2.2386814008156457

Epoch: 5| Step: 7
Training loss: 1.71120285987854
Validation loss: 2.233399818340937

Epoch: 5| Step: 8
Training loss: 1.7464326620101929
Validation loss: 2.2387356559435525

Epoch: 5| Step: 9
Training loss: 2.1223082542419434
Validation loss: 2.239955857396126

Epoch: 5| Step: 10
Training loss: 1.7314990758895874
Validation loss: 2.2072359323501587

Epoch: 5| Step: 11
Training loss: 2.2627077102661133
Validation loss: 2.203954125444094

Epoch: 250| Step: 0
Training loss: 1.6811256408691406
Validation loss: 2.1915074388186135

Epoch: 5| Step: 1
Training loss: 1.249665379524231
Validation loss: 2.1889344453811646

Epoch: 5| Step: 2
Training loss: 1.9611756801605225
Validation loss: 2.1851191769043603

Epoch: 5| Step: 3
Training loss: 2.0905563831329346
Validation loss: 2.1765213708082833

Epoch: 5| Step: 4
Training loss: 1.6526752710342407
Validation loss: 2.1693380375703177

Epoch: 5| Step: 5
Training loss: 1.67145574092865
Validation loss: 2.162654126683871

Epoch: 5| Step: 6
Training loss: 2.177150249481201
Validation loss: 2.1562913258870444

Epoch: 5| Step: 7
Training loss: 1.9794361591339111
Validation loss: 2.1679862240950265

Epoch: 5| Step: 8
Training loss: 2.056457281112671
Validation loss: 2.1898308843374252

Epoch: 5| Step: 9
Training loss: 1.4899277687072754
Validation loss: 2.207965463399887

Epoch: 5| Step: 10
Training loss: 1.6882514953613281
Validation loss: 2.2003066639105477

Epoch: 5| Step: 11
Training loss: 1.7901802062988281
Validation loss: 2.204808751742045

Epoch: 251| Step: 0
Training loss: 2.2798879146575928
Validation loss: 2.2152016262213388

Epoch: 5| Step: 1
Training loss: 1.3148685693740845
Validation loss: 2.24357778330644

Epoch: 5| Step: 2
Training loss: 2.043266534805298
Validation loss: 2.259987344344457

Epoch: 5| Step: 3
Training loss: 1.8963892459869385
Validation loss: 2.253837505976359

Epoch: 5| Step: 4
Training loss: 1.7938439846038818
Validation loss: 2.2314881136020026

Epoch: 5| Step: 5
Training loss: 1.9139773845672607
Validation loss: 2.2616139302651086

Epoch: 5| Step: 6
Training loss: 1.8480873107910156
Validation loss: 2.230757494767507

Epoch: 5| Step: 7
Training loss: 2.0799927711486816
Validation loss: 2.234432523449262

Epoch: 5| Step: 8
Training loss: 1.5371090173721313
Validation loss: 2.232068498929342

Epoch: 5| Step: 9
Training loss: 1.354404330253601
Validation loss: 2.2096582800149918

Epoch: 5| Step: 10
Training loss: 1.6295385360717773
Validation loss: 2.1983991463979087

Epoch: 5| Step: 11
Training loss: 1.1447852849960327
Validation loss: 2.210348814725876

Epoch: 252| Step: 0
Training loss: 1.796294927597046
Validation loss: 2.193835139274597

Epoch: 5| Step: 1
Training loss: 2.0448355674743652
Validation loss: 2.191171705722809

Epoch: 5| Step: 2
Training loss: 1.1757867336273193
Validation loss: 2.2016911605993905

Epoch: 5| Step: 3
Training loss: 1.3430674076080322
Validation loss: 2.205166300137838

Epoch: 5| Step: 4
Training loss: 1.6460609436035156
Validation loss: 2.2017855445543923

Epoch: 5| Step: 5
Training loss: 1.7328017950057983
Validation loss: 2.2223749409119287

Epoch: 5| Step: 6
Training loss: 2.2142133712768555
Validation loss: 2.228354185819626

Epoch: 5| Step: 7
Training loss: 1.973615288734436
Validation loss: 2.1889699598153434

Epoch: 5| Step: 8
Training loss: 1.748440146446228
Validation loss: 2.2014994422594705

Epoch: 5| Step: 9
Training loss: 2.477574348449707
Validation loss: 2.222342054049174

Epoch: 5| Step: 10
Training loss: 1.8981211185455322
Validation loss: 2.2086311131715775

Epoch: 5| Step: 11
Training loss: 3.9149653911590576
Validation loss: 2.23144722978274

Epoch: 253| Step: 0
Training loss: 1.9783470630645752
Validation loss: 2.235414579510689

Epoch: 5| Step: 1
Training loss: 1.8853328227996826
Validation loss: 2.225904698173205

Epoch: 5| Step: 2
Training loss: 1.2221804857254028
Validation loss: 2.206982950369517

Epoch: 5| Step: 3
Training loss: 1.408363938331604
Validation loss: 2.2079326113065085

Epoch: 5| Step: 4
Training loss: 1.922607421875
Validation loss: 2.2018953462441764

Epoch: 5| Step: 5
Training loss: 1.6132698059082031
Validation loss: 2.198388228813807

Epoch: 5| Step: 6
Training loss: 1.8512113094329834
Validation loss: 2.1967009802659354

Epoch: 5| Step: 7
Training loss: 2.054641008377075
Validation loss: 2.1799166401227317

Epoch: 5| Step: 8
Training loss: 2.420529842376709
Validation loss: 2.1791137804587684

Epoch: 5| Step: 9
Training loss: 1.3768513202667236
Validation loss: 2.1978132923444114

Epoch: 5| Step: 10
Training loss: 1.5897859334945679
Validation loss: 2.214599465330442

Epoch: 5| Step: 11
Training loss: 2.3103227615356445
Validation loss: 2.1843517422676086

Epoch: 254| Step: 0
Training loss: 1.9932582378387451
Validation loss: 2.228653465708097

Epoch: 5| Step: 1
Training loss: 1.627815842628479
Validation loss: 2.1981128603219986

Epoch: 5| Step: 2
Training loss: 2.1963133811950684
Validation loss: 2.199694732824961

Epoch: 5| Step: 3
Training loss: 1.5531564950942993
Validation loss: 2.1905199040969214

Epoch: 5| Step: 4
Training loss: 2.271754026412964
Validation loss: 2.199010064204534

Epoch: 5| Step: 5
Training loss: 1.3403773307800293
Validation loss: 2.2301238824923835

Epoch: 5| Step: 6
Training loss: 1.7332649230957031
Validation loss: 2.2340647081534066

Epoch: 5| Step: 7
Training loss: 1.8074496984481812
Validation loss: 2.23872010409832

Epoch: 5| Step: 8
Training loss: 1.417514681816101
Validation loss: 2.2634893308083215

Epoch: 5| Step: 9
Training loss: 1.8860394954681396
Validation loss: 2.2375421126683555

Epoch: 5| Step: 10
Training loss: 1.4614298343658447
Validation loss: 2.2350332687298455

Epoch: 5| Step: 11
Training loss: 1.6551802158355713
Validation loss: 2.229947159687678

Epoch: 255| Step: 0
Training loss: 1.5450788736343384
Validation loss: 2.238338659207026

Epoch: 5| Step: 1
Training loss: 1.864774465560913
Validation loss: 2.232439065972964

Epoch: 5| Step: 2
Training loss: 2.1729934215545654
Validation loss: 2.2409712374210358

Epoch: 5| Step: 3
Training loss: 1.7264524698257446
Validation loss: 2.229195922613144

Epoch: 5| Step: 4
Training loss: 1.7724577188491821
Validation loss: 2.252179200450579

Epoch: 5| Step: 5
Training loss: 1.7516367435455322
Validation loss: 2.234739432732264

Epoch: 5| Step: 6
Training loss: 1.8302414417266846
Validation loss: 2.2453490048646927

Epoch: 5| Step: 7
Training loss: 1.292672872543335
Validation loss: 2.2020991096893945

Epoch: 5| Step: 8
Training loss: 2.0593419075012207
Validation loss: 2.2028070390224457

Epoch: 5| Step: 9
Training loss: 1.505832314491272
Validation loss: 2.195233096679052

Epoch: 5| Step: 10
Training loss: 2.004615306854248
Validation loss: 2.2220755914847055

Epoch: 5| Step: 11
Training loss: 0.9905228614807129
Validation loss: 2.2011494239171348

Epoch: 256| Step: 0
Training loss: 1.8953006267547607
Validation loss: 2.2351530889670053

Epoch: 5| Step: 1
Training loss: 2.1336236000061035
Validation loss: 2.2304357637961707

Epoch: 5| Step: 2
Training loss: 2.2858805656433105
Validation loss: 2.221527253588041

Epoch: 5| Step: 3
Training loss: 1.6917390823364258
Validation loss: 2.1960849364598594

Epoch: 5| Step: 4
Training loss: 1.4619005918502808
Validation loss: 2.2200296223163605

Epoch: 5| Step: 5
Training loss: 2.1407687664031982
Validation loss: 2.2223263531923294

Epoch: 5| Step: 6
Training loss: 1.223481297492981
Validation loss: 2.218921626607577

Epoch: 5| Step: 7
Training loss: 1.4501984119415283
Validation loss: 2.2155172377824783

Epoch: 5| Step: 8
Training loss: 1.5007036924362183
Validation loss: 2.220531716942787

Epoch: 5| Step: 9
Training loss: 1.6683292388916016
Validation loss: 2.2247526943683624

Epoch: 5| Step: 10
Training loss: 2.1836819648742676
Validation loss: 2.229309340318044

Epoch: 5| Step: 11
Training loss: 0.9421004056930542
Validation loss: 2.195065995057424

Epoch: 257| Step: 0
Training loss: 1.4183303117752075
Validation loss: 2.224098816514015

Epoch: 5| Step: 1
Training loss: 2.0177955627441406
Validation loss: 2.215765655040741

Epoch: 5| Step: 2
Training loss: 1.211444616317749
Validation loss: 2.222455153862635

Epoch: 5| Step: 3
Training loss: 1.4547560214996338
Validation loss: 2.2317529171705246

Epoch: 5| Step: 4
Training loss: 1.8792407512664795
Validation loss: 2.230715572834015

Epoch: 5| Step: 5
Training loss: 2.038320541381836
Validation loss: 2.2401779194672904

Epoch: 5| Step: 6
Training loss: 1.2387800216674805
Validation loss: 2.2429510354995728

Epoch: 5| Step: 7
Training loss: 1.9875437021255493
Validation loss: 2.2495097120602927

Epoch: 5| Step: 8
Training loss: 1.816542625427246
Validation loss: 2.2453389267126718

Epoch: 5| Step: 9
Training loss: 1.769771933555603
Validation loss: 2.2678307741880417

Epoch: 5| Step: 10
Training loss: 2.184497117996216
Validation loss: 2.266040434439977

Epoch: 5| Step: 11
Training loss: 1.4324133396148682
Validation loss: 2.26221693555514

Epoch: 258| Step: 0
Training loss: 1.4940227270126343
Validation loss: 2.230970407525698

Epoch: 5| Step: 1
Training loss: 1.3218767642974854
Validation loss: 2.2331151962280273

Epoch: 5| Step: 2
Training loss: 1.9912307262420654
Validation loss: 2.227105289697647

Epoch: 5| Step: 3
Training loss: 1.4042444229125977
Validation loss: 2.2402301927407584

Epoch: 5| Step: 4
Training loss: 1.3461629152297974
Validation loss: 2.2373152673244476

Epoch: 5| Step: 5
Training loss: 2.0187745094299316
Validation loss: 2.2215293248494468

Epoch: 5| Step: 6
Training loss: 2.4138646125793457
Validation loss: 2.1985575954119363

Epoch: 5| Step: 7
Training loss: 1.4614770412445068
Validation loss: 2.2146476755539575

Epoch: 5| Step: 8
Training loss: 1.9094212055206299
Validation loss: 2.200032353401184

Epoch: 5| Step: 9
Training loss: 1.8576946258544922
Validation loss: 2.2258641719818115

Epoch: 5| Step: 10
Training loss: 1.7577768564224243
Validation loss: 2.2075656006733575

Epoch: 5| Step: 11
Training loss: 2.584516763687134
Validation loss: 2.236141969760259

Epoch: 259| Step: 0
Training loss: 1.4702228307724
Validation loss: 2.2085377921660743

Epoch: 5| Step: 1
Training loss: 2.093909740447998
Validation loss: 2.2190045416355133

Epoch: 5| Step: 2
Training loss: 1.1519843339920044
Validation loss: 2.2123697896798453

Epoch: 5| Step: 3
Training loss: 1.6177616119384766
Validation loss: 2.213469018538793

Epoch: 5| Step: 4
Training loss: 1.968287706375122
Validation loss: 2.1975109775861106

Epoch: 5| Step: 5
Training loss: 1.8781869411468506
Validation loss: 2.190964420636495

Epoch: 5| Step: 6
Training loss: 2.018212080001831
Validation loss: 2.2376453081766763

Epoch: 5| Step: 7
Training loss: 1.6263450384140015
Validation loss: 2.2203707496325173

Epoch: 5| Step: 8
Training loss: 2.030832290649414
Validation loss: 2.213884244362513

Epoch: 5| Step: 9
Training loss: 1.8872102499008179
Validation loss: 2.201596056421598

Epoch: 5| Step: 10
Training loss: 1.2338535785675049
Validation loss: 2.2039615511894226

Epoch: 5| Step: 11
Training loss: 1.2547856569290161
Validation loss: 2.21066881219546

Epoch: 260| Step: 0
Training loss: 2.0963854789733887
Validation loss: 2.2133653362592063

Epoch: 5| Step: 1
Training loss: 1.5055763721466064
Validation loss: 2.217923581600189

Epoch: 5| Step: 2
Training loss: 1.562885046005249
Validation loss: 2.210617040594419

Epoch: 5| Step: 3
Training loss: 1.8414942026138306
Validation loss: 2.215297053257624

Epoch: 5| Step: 4
Training loss: 1.6178462505340576
Validation loss: 2.200158417224884

Epoch: 5| Step: 5
Training loss: 1.325109839439392
Validation loss: 2.2013635635375977

Epoch: 5| Step: 6
Training loss: 1.6076042652130127
Validation loss: 2.2341817120711007

Epoch: 5| Step: 7
Training loss: 1.1993844509124756
Validation loss: 2.2421505053838096

Epoch: 5| Step: 8
Training loss: 1.7998425960540771
Validation loss: 2.227339342236519

Epoch: 5| Step: 9
Training loss: 2.525460720062256
Validation loss: 2.2476716538270316

Epoch: 5| Step: 10
Training loss: 1.9246991872787476
Validation loss: 2.2654810547828674

Epoch: 5| Step: 11
Training loss: 1.7543714046478271
Validation loss: 2.2832976629336676

Epoch: 261| Step: 0
Training loss: 2.131199359893799
Validation loss: 2.21024888753891

Epoch: 5| Step: 1
Training loss: 1.5759332180023193
Validation loss: 2.2127310087283454

Epoch: 5| Step: 2
Training loss: 2.091796398162842
Validation loss: 2.1596696029106774

Epoch: 5| Step: 3
Training loss: 1.728804588317871
Validation loss: 2.2080098390579224

Epoch: 5| Step: 4
Training loss: 1.662488579750061
Validation loss: 2.1742574671904245

Epoch: 5| Step: 5
Training loss: 1.440227746963501
Validation loss: 2.1828413705031076

Epoch: 5| Step: 6
Training loss: 1.5823442935943604
Validation loss: 2.2024419705073037

Epoch: 5| Step: 7
Training loss: 1.3984373807907104
Validation loss: 2.2024849951267242

Epoch: 5| Step: 8
Training loss: 1.9868379831314087
Validation loss: 2.2200713455677032

Epoch: 5| Step: 9
Training loss: 1.7554244995117188
Validation loss: 2.2398372491200766

Epoch: 5| Step: 10
Training loss: 1.7837355136871338
Validation loss: 2.2203239301840463

Epoch: 5| Step: 11
Training loss: 2.335088014602661
Validation loss: 2.2182166477044425

Epoch: 262| Step: 0
Training loss: 1.7514371871948242
Validation loss: 2.230937048792839

Epoch: 5| Step: 1
Training loss: 1.6436312198638916
Validation loss: 2.2024856209754944

Epoch: 5| Step: 2
Training loss: 2.053773880004883
Validation loss: 2.217348183194796

Epoch: 5| Step: 3
Training loss: 1.9728901386260986
Validation loss: 2.224231332540512

Epoch: 5| Step: 4
Training loss: 1.5728063583374023
Validation loss: 2.2137556970119476

Epoch: 5| Step: 5
Training loss: 1.7003800868988037
Validation loss: 2.179720292488734

Epoch: 5| Step: 6
Training loss: 1.4520076513290405
Validation loss: 2.177535663048426

Epoch: 5| Step: 7
Training loss: 2.023310899734497
Validation loss: 2.1819197237491608

Epoch: 5| Step: 8
Training loss: 1.5769929885864258
Validation loss: 2.191116432348887

Epoch: 5| Step: 9
Training loss: 1.6162440776824951
Validation loss: 2.176323319474856

Epoch: 5| Step: 10
Training loss: 2.3449153900146484
Validation loss: 2.172249525785446

Epoch: 5| Step: 11
Training loss: 2.3291189670562744
Validation loss: 2.175344874461492

Epoch: 263| Step: 0
Training loss: 1.3716166019439697
Validation loss: 2.1691253036260605

Epoch: 5| Step: 1
Training loss: 1.6320337057113647
Validation loss: 2.1721906115611396

Epoch: 5| Step: 2
Training loss: 2.1660401821136475
Validation loss: 2.1745552817980447

Epoch: 5| Step: 3
Training loss: 1.8563915491104126
Validation loss: 2.1715028484662375

Epoch: 5| Step: 4
Training loss: 1.8040834665298462
Validation loss: 2.162642185886701

Epoch: 5| Step: 5
Training loss: 1.8994239568710327
Validation loss: 2.1921888987223306

Epoch: 5| Step: 6
Training loss: 1.9860903024673462
Validation loss: 2.188037152091662

Epoch: 5| Step: 7
Training loss: 1.4509128332138062
Validation loss: 2.232568015654882

Epoch: 5| Step: 8
Training loss: 1.4895985126495361
Validation loss: 2.2316904862721763

Epoch: 5| Step: 9
Training loss: 1.7102622985839844
Validation loss: 2.232678304115931

Epoch: 5| Step: 10
Training loss: 2.2176849842071533
Validation loss: 2.260135014851888

Epoch: 5| Step: 11
Training loss: 1.5927584171295166
Validation loss: 2.2288359105587006

Epoch: 264| Step: 0
Training loss: 1.9266992807388306
Validation loss: 2.2726772129535675

Epoch: 5| Step: 1
Training loss: 1.7532880306243896
Validation loss: 2.2816932996114097

Epoch: 5| Step: 2
Training loss: 1.8939189910888672
Validation loss: 2.2787346839904785

Epoch: 5| Step: 3
Training loss: 1.905513048171997
Validation loss: 2.2764394332965217

Epoch: 5| Step: 4
Training loss: 1.565807580947876
Validation loss: 2.2784902105728784

Epoch: 5| Step: 5
Training loss: 1.5127230882644653
Validation loss: 2.261965682109197

Epoch: 5| Step: 6
Training loss: 1.7250982522964478
Validation loss: 2.252605050802231

Epoch: 5| Step: 7
Training loss: 1.665663480758667
Validation loss: 2.2116806308428445

Epoch: 5| Step: 8
Training loss: 1.7786182165145874
Validation loss: 2.2193284829457602

Epoch: 5| Step: 9
Training loss: 2.0407423973083496
Validation loss: 2.209282234311104

Epoch: 5| Step: 10
Training loss: 1.786245346069336
Validation loss: 2.2164083222548165

Epoch: 5| Step: 11
Training loss: 2.777346134185791
Validation loss: 2.209952483574549

Epoch: 265| Step: 0
Training loss: 1.3638198375701904
Validation loss: 2.1997067282597222

Epoch: 5| Step: 1
Training loss: 2.286632537841797
Validation loss: 2.2014401058355966

Epoch: 5| Step: 2
Training loss: 2.0247092247009277
Validation loss: 2.20242573817571

Epoch: 5| Step: 3
Training loss: 1.1491485834121704
Validation loss: 2.2410404682159424

Epoch: 5| Step: 4
Training loss: 1.767040491104126
Validation loss: 2.2288345048824945

Epoch: 5| Step: 5
Training loss: 1.238281011581421
Validation loss: 2.2130452195803323

Epoch: 5| Step: 6
Training loss: 2.2175865173339844
Validation loss: 2.230978106458982

Epoch: 5| Step: 7
Training loss: 1.8884727954864502
Validation loss: 2.226618766784668

Epoch: 5| Step: 8
Training loss: 1.9572826623916626
Validation loss: 2.212051605184873

Epoch: 5| Step: 9
Training loss: 1.2327457666397095
Validation loss: 2.229595055182775

Epoch: 5| Step: 10
Training loss: 2.1978440284729004
Validation loss: 2.2134734094142914

Epoch: 5| Step: 11
Training loss: 1.6527385711669922
Validation loss: 2.198334107796351

Epoch: 266| Step: 0
Training loss: 2.03328013420105
Validation loss: 2.2125627398490906

Epoch: 5| Step: 1
Training loss: 1.6909523010253906
Validation loss: 2.200587640206019

Epoch: 5| Step: 2
Training loss: 2.20717191696167
Validation loss: 2.2136962711811066

Epoch: 5| Step: 3
Training loss: 2.2119243144989014
Validation loss: 2.231537570556005

Epoch: 5| Step: 4
Training loss: 1.4439165592193604
Validation loss: 2.2314719756444297

Epoch: 5| Step: 5
Training loss: 1.5420072078704834
Validation loss: 2.2090568790833154

Epoch: 5| Step: 6
Training loss: 1.4502054452896118
Validation loss: 2.222989797592163

Epoch: 5| Step: 7
Training loss: 1.716118574142456
Validation loss: 2.210710888107618

Epoch: 5| Step: 8
Training loss: 1.2887511253356934
Validation loss: 2.2114190061887107

Epoch: 5| Step: 9
Training loss: 1.1444144248962402
Validation loss: 2.2442509730656943

Epoch: 5| Step: 10
Training loss: 1.8682016134262085
Validation loss: 2.2143415113290152

Epoch: 5| Step: 11
Training loss: 2.888610363006592
Validation loss: 2.2455658266941705

Epoch: 267| Step: 0
Training loss: 2.099069118499756
Validation loss: 2.215472867091497

Epoch: 5| Step: 1
Training loss: 1.2850580215454102
Validation loss: 2.209266573190689

Epoch: 5| Step: 2
Training loss: 2.1309473514556885
Validation loss: 2.2339246422052383

Epoch: 5| Step: 3
Training loss: 1.4708940982818604
Validation loss: 2.2137536108493805

Epoch: 5| Step: 4
Training loss: 1.2517048120498657
Validation loss: 2.2292575389146805

Epoch: 5| Step: 5
Training loss: 1.5331530570983887
Validation loss: 2.2235240936279297

Epoch: 5| Step: 6
Training loss: 1.4867197275161743
Validation loss: 2.22133336464564

Epoch: 5| Step: 7
Training loss: 2.292365550994873
Validation loss: 2.2107612043619156

Epoch: 5| Step: 8
Training loss: 2.3718180656433105
Validation loss: 2.193369815746943

Epoch: 5| Step: 9
Training loss: 1.7295520305633545
Validation loss: 2.1911497016747794

Epoch: 5| Step: 10
Training loss: 1.4524840116500854
Validation loss: 2.193251520395279

Epoch: 5| Step: 11
Training loss: 0.6916811466217041
Validation loss: 2.195487101872762

Epoch: 268| Step: 0
Training loss: 1.3717236518859863
Validation loss: 2.19589971502622

Epoch: 5| Step: 1
Training loss: 1.9183746576309204
Validation loss: 2.207923953731855

Epoch: 5| Step: 2
Training loss: 2.2697556018829346
Validation loss: 2.203649257620176

Epoch: 5| Step: 3
Training loss: 2.0455174446105957
Validation loss: 2.21464696029822

Epoch: 5| Step: 4
Training loss: 1.9613943099975586
Validation loss: 2.1976369321346283

Epoch: 5| Step: 5
Training loss: 1.3862522840499878
Validation loss: 2.2076671024163566

Epoch: 5| Step: 6
Training loss: 1.3077476024627686
Validation loss: 2.2350178360939026

Epoch: 5| Step: 7
Training loss: 1.516381025314331
Validation loss: 2.2344586898883185

Epoch: 5| Step: 8
Training loss: 1.2017511129379272
Validation loss: 2.2266078492005668

Epoch: 5| Step: 9
Training loss: 1.852566123008728
Validation loss: 2.2323587089776993

Epoch: 5| Step: 10
Training loss: 2.109663486480713
Validation loss: 2.2275858720143638

Epoch: 5| Step: 11
Training loss: 1.2820807695388794
Validation loss: 2.226106991370519

Epoch: 269| Step: 0
Training loss: 1.8240209817886353
Validation loss: 2.2078718890746436

Epoch: 5| Step: 1
Training loss: 2.098644256591797
Validation loss: 2.1987315863370895

Epoch: 5| Step: 2
Training loss: 1.8239545822143555
Validation loss: 2.2122680942217507

Epoch: 5| Step: 3
Training loss: 1.2664004564285278
Validation loss: 2.192622939745585

Epoch: 5| Step: 4
Training loss: 1.3347448110580444
Validation loss: 2.224945326646169

Epoch: 5| Step: 5
Training loss: 2.5305144786834717
Validation loss: 2.207361578941345

Epoch: 5| Step: 6
Training loss: 1.713767647743225
Validation loss: 2.210295925537745

Epoch: 5| Step: 7
Training loss: 2.1471400260925293
Validation loss: 2.204642360409101

Epoch: 5| Step: 8
Training loss: 1.051997184753418
Validation loss: 2.2046516438325248

Epoch: 5| Step: 9
Training loss: 1.5813360214233398
Validation loss: 2.2133392691612244

Epoch: 5| Step: 10
Training loss: 1.6048332452774048
Validation loss: 2.2255840549866357

Epoch: 5| Step: 11
Training loss: 1.5671335458755493
Validation loss: 2.248337209224701

Epoch: 270| Step: 0
Training loss: 1.8700462579727173
Validation loss: 2.25112384557724

Epoch: 5| Step: 1
Training loss: 1.150039792060852
Validation loss: 2.2522622843583426

Epoch: 5| Step: 2
Training loss: 1.7835395336151123
Validation loss: 2.2314319610595703

Epoch: 5| Step: 3
Training loss: 1.8774938583374023
Validation loss: 2.2339118917783103

Epoch: 5| Step: 4
Training loss: 1.5609889030456543
Validation loss: 2.2426763474941254

Epoch: 5| Step: 5
Training loss: 1.451481580734253
Validation loss: 2.230485508839289

Epoch: 5| Step: 6
Training loss: 1.5798829793930054
Validation loss: 2.2278154691060386

Epoch: 5| Step: 7
Training loss: 2.12286114692688
Validation loss: 2.240641509493192

Epoch: 5| Step: 8
Training loss: 1.3225021362304688
Validation loss: 2.2528773844242096

Epoch: 5| Step: 9
Training loss: 2.420194149017334
Validation loss: 2.234722927212715

Epoch: 5| Step: 10
Training loss: 1.5939818620681763
Validation loss: 2.236361409227053

Epoch: 5| Step: 11
Training loss: 2.5830576419830322
Validation loss: 2.2280992021163306

Epoch: 271| Step: 0
Training loss: 1.9424569606781006
Validation loss: 2.219064066807429

Epoch: 5| Step: 1
Training loss: 2.4687445163726807
Validation loss: 2.231697196761767

Epoch: 5| Step: 2
Training loss: 1.1838159561157227
Validation loss: 2.214541271328926

Epoch: 5| Step: 3
Training loss: 1.805223822593689
Validation loss: 2.213957051436106

Epoch: 5| Step: 4
Training loss: 1.43210768699646
Validation loss: 2.1998863170544305

Epoch: 5| Step: 5
Training loss: 1.3602615594863892
Validation loss: 2.180226186911265

Epoch: 5| Step: 6
Training loss: 1.2573916912078857
Validation loss: 2.199254795908928

Epoch: 5| Step: 7
Training loss: 2.1089603900909424
Validation loss: 2.1960540115833282

Epoch: 5| Step: 8
Training loss: 1.3209254741668701
Validation loss: 2.184706677993139

Epoch: 5| Step: 9
Training loss: 1.7834501266479492
Validation loss: 2.2063694645961127

Epoch: 5| Step: 10
Training loss: 2.388958215713501
Validation loss: 2.204455708463987

Epoch: 5| Step: 11
Training loss: 1.5598042011260986
Validation loss: 2.206080491344134

Epoch: 272| Step: 0
Training loss: 1.694668173789978
Validation loss: 2.2276407927274704

Epoch: 5| Step: 1
Training loss: 1.6682841777801514
Validation loss: 2.2354822605848312

Epoch: 5| Step: 2
Training loss: 1.3973057270050049
Validation loss: 2.2375781138738

Epoch: 5| Step: 3
Training loss: 1.4158642292022705
Validation loss: 2.251371701558431

Epoch: 5| Step: 4
Training loss: 2.332019805908203
Validation loss: 2.2620140314102173

Epoch: 5| Step: 5
Training loss: 2.0624585151672363
Validation loss: 2.2534507562716803

Epoch: 5| Step: 6
Training loss: 1.7693229913711548
Validation loss: 2.234635372956594

Epoch: 5| Step: 7
Training loss: 2.167691707611084
Validation loss: 2.2586472729841867

Epoch: 5| Step: 8
Training loss: 2.1377367973327637
Validation loss: 2.240112746755282

Epoch: 5| Step: 9
Training loss: 1.9180774688720703
Validation loss: 2.2643190175294876

Epoch: 5| Step: 10
Training loss: 1.6508668661117554
Validation loss: 2.257041076819102

Epoch: 5| Step: 11
Training loss: 1.0649380683898926
Validation loss: 2.2351981103420258

Epoch: 273| Step: 0
Training loss: 1.6701997518539429
Validation loss: 2.2057275672753653

Epoch: 5| Step: 1
Training loss: 1.7348639965057373
Validation loss: 2.2012794663508735

Epoch: 5| Step: 2
Training loss: 1.279808521270752
Validation loss: 2.193666140238444

Epoch: 5| Step: 3
Training loss: 1.6050256490707397
Validation loss: 2.18972040216128

Epoch: 5| Step: 4
Training loss: 2.2313215732574463
Validation loss: 2.1901455422242484

Epoch: 5| Step: 5
Training loss: 1.560502290725708
Validation loss: 2.18644010523955

Epoch: 5| Step: 6
Training loss: 1.6025924682617188
Validation loss: 2.180358568827311

Epoch: 5| Step: 7
Training loss: 1.9052749872207642
Validation loss: 2.1732201178868613

Epoch: 5| Step: 8
Training loss: 1.6535308361053467
Validation loss: 2.182585820555687

Epoch: 5| Step: 9
Training loss: 1.836992621421814
Validation loss: 2.1770903915166855

Epoch: 5| Step: 10
Training loss: 2.1585934162139893
Validation loss: 2.185957690080007

Epoch: 5| Step: 11
Training loss: 2.7909250259399414
Validation loss: 2.181101679801941

Epoch: 274| Step: 0
Training loss: 1.5992858409881592
Validation loss: 2.173623671134313

Epoch: 5| Step: 1
Training loss: 2.1717188358306885
Validation loss: 2.185029918948809

Epoch: 5| Step: 2
Training loss: 1.450355887413025
Validation loss: 2.1805790662765503

Epoch: 5| Step: 3
Training loss: 1.0822280645370483
Validation loss: 2.1661960035562515

Epoch: 5| Step: 4
Training loss: 1.6680409908294678
Validation loss: 2.1964774827162423

Epoch: 5| Step: 5
Training loss: 1.4279658794403076
Validation loss: 2.1872550000747046

Epoch: 5| Step: 6
Training loss: 2.210686206817627
Validation loss: 2.17246650159359

Epoch: 5| Step: 7
Training loss: 1.2150684595108032
Validation loss: 2.1967754662036896

Epoch: 5| Step: 8
Training loss: 1.5946382284164429
Validation loss: 2.1979272067546844

Epoch: 5| Step: 9
Training loss: 2.2232203483581543
Validation loss: 2.207169493039449

Epoch: 5| Step: 10
Training loss: 1.8551599979400635
Validation loss: 2.215789516766866

Epoch: 5| Step: 11
Training loss: 3.6412758827209473
Validation loss: 2.2148754000663757

Epoch: 275| Step: 0
Training loss: 1.4199974536895752
Validation loss: 2.234519451856613

Epoch: 5| Step: 1
Training loss: 2.285297155380249
Validation loss: 2.236657897631327

Epoch: 5| Step: 2
Training loss: 1.47737717628479
Validation loss: 2.198043872912725

Epoch: 5| Step: 3
Training loss: 1.9735004901885986
Validation loss: 2.2283122638861337

Epoch: 5| Step: 4
Training loss: 2.2396130561828613
Validation loss: 2.225898340344429

Epoch: 5| Step: 5
Training loss: 1.7867292165756226
Validation loss: 2.2131396581729255

Epoch: 5| Step: 6
Training loss: 1.5809595584869385
Validation loss: 2.2110236138105392

Epoch: 5| Step: 7
Training loss: 1.5454118251800537
Validation loss: 2.1881328920523324

Epoch: 5| Step: 8
Training loss: 1.6799215078353882
Validation loss: 2.2102959950764975

Epoch: 5| Step: 9
Training loss: 1.33882474899292
Validation loss: 2.208868126074473

Epoch: 5| Step: 10
Training loss: 1.7970960140228271
Validation loss: 2.200740168491999

Epoch: 5| Step: 11
Training loss: 2.1276371479034424
Validation loss: 2.1697649558385215

Epoch: 276| Step: 0
Training loss: 1.658858299255371
Validation loss: 2.1825561076402664

Epoch: 5| Step: 1
Training loss: 2.1448981761932373
Validation loss: 2.203042442599932

Epoch: 5| Step: 2
Training loss: 1.4637267589569092
Validation loss: 2.1951909263928733

Epoch: 5| Step: 3
Training loss: 2.0539426803588867
Validation loss: 2.1984199583530426

Epoch: 5| Step: 4
Training loss: 1.9149882793426514
Validation loss: 2.2269557962814965

Epoch: 5| Step: 5
Training loss: 1.5193425416946411
Validation loss: 2.247142235438029

Epoch: 5| Step: 6
Training loss: 1.6779896020889282
Validation loss: 2.22311540444692

Epoch: 5| Step: 7
Training loss: 1.958245873451233
Validation loss: 2.2222900390625

Epoch: 5| Step: 8
Training loss: 1.2329165935516357
Validation loss: 2.2272619853417077

Epoch: 5| Step: 9
Training loss: 1.3294514417648315
Validation loss: 2.2283041576544442

Epoch: 5| Step: 10
Training loss: 1.7377746105194092
Validation loss: 2.234878192345301

Epoch: 5| Step: 11
Training loss: 1.6312365531921387
Validation loss: 2.234935517112414

Epoch: 277| Step: 0
Training loss: 1.55902898311615
Validation loss: 2.2542948375145593

Epoch: 5| Step: 1
Training loss: 1.6062946319580078
Validation loss: 2.2479245364665985

Epoch: 5| Step: 2
Training loss: 1.4705201387405396
Validation loss: 2.240757554769516

Epoch: 5| Step: 3
Training loss: 1.797708511352539
Validation loss: 2.243025933702787

Epoch: 5| Step: 4
Training loss: 1.2886186838150024
Validation loss: 2.2589785953362784

Epoch: 5| Step: 5
Training loss: 1.7619876861572266
Validation loss: 2.228043148914973

Epoch: 5| Step: 6
Training loss: 2.0005807876586914
Validation loss: 2.2094840705394745

Epoch: 5| Step: 7
Training loss: 2.253026247024536
Validation loss: 2.2176766941944757

Epoch: 5| Step: 8
Training loss: 1.3544760942459106
Validation loss: 2.212646017471949

Epoch: 5| Step: 9
Training loss: 1.8987843990325928
Validation loss: 2.1855459411938987

Epoch: 5| Step: 10
Training loss: 1.4672167301177979
Validation loss: 2.213864728808403

Epoch: 5| Step: 11
Training loss: 2.7398006916046143
Validation loss: 2.219559371471405

Epoch: 278| Step: 0
Training loss: 1.9414094686508179
Validation loss: 2.2300061037143073

Epoch: 5| Step: 1
Training loss: 1.3760569095611572
Validation loss: 2.223517815272013

Epoch: 5| Step: 2
Training loss: 1.360754370689392
Validation loss: 2.251276875535647

Epoch: 5| Step: 3
Training loss: 1.9610865116119385
Validation loss: 2.247262919942538

Epoch: 5| Step: 4
Training loss: 2.5463850498199463
Validation loss: 2.242474521199862

Epoch: 5| Step: 5
Training loss: 1.6837501525878906
Validation loss: 2.249324142932892

Epoch: 5| Step: 6
Training loss: 1.5107784271240234
Validation loss: 2.2506388326485953

Epoch: 5| Step: 7
Training loss: 1.9190651178359985
Validation loss: 2.2330252279837928

Epoch: 5| Step: 8
Training loss: 1.492531180381775
Validation loss: 2.265759994586309

Epoch: 5| Step: 9
Training loss: 1.2616411447525024
Validation loss: 2.252786015470823

Epoch: 5| Step: 10
Training loss: 1.4170591831207275
Validation loss: 2.251526022950808

Epoch: 5| Step: 11
Training loss: 1.9778330326080322
Validation loss: 2.2470372716585794

Epoch: 279| Step: 0
Training loss: 1.7760969400405884
Validation loss: 2.205745836098989

Epoch: 5| Step: 1
Training loss: 1.6467866897583008
Validation loss: 2.2004464169343314

Epoch: 5| Step: 2
Training loss: 1.2959131002426147
Validation loss: 2.2009179890155792

Epoch: 5| Step: 3
Training loss: 1.735918641090393
Validation loss: 2.2070637196302414

Epoch: 5| Step: 4
Training loss: 1.7568031549453735
Validation loss: 2.2127444048722587

Epoch: 5| Step: 5
Training loss: 1.8952277898788452
Validation loss: 2.2014958212773004

Epoch: 5| Step: 6
Training loss: 1.5716661214828491
Validation loss: 2.2014752378066382

Epoch: 5| Step: 7
Training loss: 1.6571366786956787
Validation loss: 2.222968250513077

Epoch: 5| Step: 8
Training loss: 1.717266321182251
Validation loss: 2.2665517131487527

Epoch: 5| Step: 9
Training loss: 2.0114359855651855
Validation loss: 2.2570267419020333

Epoch: 5| Step: 10
Training loss: 1.420332908630371
Validation loss: 2.2527205546696982

Epoch: 5| Step: 11
Training loss: 1.6951748132705688
Validation loss: 2.2379593551158905

Epoch: 280| Step: 0
Training loss: 1.8270210027694702
Validation loss: 2.2513236850500107

Epoch: 5| Step: 1
Training loss: 1.544069528579712
Validation loss: 2.2910775542259216

Epoch: 5| Step: 2
Training loss: 2.094205379486084
Validation loss: 2.2642150223255157

Epoch: 5| Step: 3
Training loss: 2.0154788494110107
Validation loss: 2.22806208829085

Epoch: 5| Step: 4
Training loss: 2.132120370864868
Validation loss: 2.2279091825087867

Epoch: 5| Step: 5
Training loss: 1.5361641645431519
Validation loss: 2.229684124390284

Epoch: 5| Step: 6
Training loss: 1.5083357095718384
Validation loss: 2.221309393644333

Epoch: 5| Step: 7
Training loss: 1.2454419136047363
Validation loss: 2.233149508635203

Epoch: 5| Step: 8
Training loss: 1.5959678888320923
Validation loss: 2.264485076069832

Epoch: 5| Step: 9
Training loss: 1.406689167022705
Validation loss: 2.263665904601415

Epoch: 5| Step: 10
Training loss: 1.42620050907135
Validation loss: 2.2383670657873154

Epoch: 5| Step: 11
Training loss: 2.805577039718628
Validation loss: 2.2515116184949875

Epoch: 281| Step: 0
Training loss: 1.9179404973983765
Validation loss: 2.2265536536773047

Epoch: 5| Step: 1
Training loss: 2.160254955291748
Validation loss: 2.2400084684292474

Epoch: 5| Step: 2
Training loss: 1.6440092325210571
Validation loss: 2.2348822951316833

Epoch: 5| Step: 3
Training loss: 0.985145092010498
Validation loss: 2.2091218878825507

Epoch: 5| Step: 4
Training loss: 2.0370593070983887
Validation loss: 2.209256519873937

Epoch: 5| Step: 5
Training loss: 1.263132929801941
Validation loss: 2.211811234553655

Epoch: 5| Step: 6
Training loss: 1.551304578781128
Validation loss: 2.235703229904175

Epoch: 5| Step: 7
Training loss: 1.7595622539520264
Validation loss: 2.2220095048348107

Epoch: 5| Step: 8
Training loss: 1.2745635509490967
Validation loss: 2.222266231973966

Epoch: 5| Step: 9
Training loss: 1.9988574981689453
Validation loss: 2.2149794350067773

Epoch: 5| Step: 10
Training loss: 2.171921491622925
Validation loss: 2.224105417728424

Epoch: 5| Step: 11
Training loss: 2.0652341842651367
Validation loss: 2.2206737647453942

Epoch: 282| Step: 0
Training loss: 1.914259672164917
Validation loss: 2.213369071483612

Epoch: 5| Step: 1
Training loss: 2.0860671997070312
Validation loss: 2.192184239625931

Epoch: 5| Step: 2
Training loss: 1.7581348419189453
Validation loss: 2.1954221030076346

Epoch: 5| Step: 3
Training loss: 2.0732150077819824
Validation loss: 2.184718703230222

Epoch: 5| Step: 4
Training loss: 2.195690631866455
Validation loss: 2.192590450247129

Epoch: 5| Step: 5
Training loss: 1.2850416898727417
Validation loss: 2.2041097233692803

Epoch: 5| Step: 6
Training loss: 1.4542782306671143
Validation loss: 2.2115231404701867

Epoch: 5| Step: 7
Training loss: 1.5384570360183716
Validation loss: 2.222528323531151

Epoch: 5| Step: 8
Training loss: 1.8105049133300781
Validation loss: 2.224640170733134

Epoch: 5| Step: 9
Training loss: 2.0321168899536133
Validation loss: 2.2468387285868325

Epoch: 5| Step: 10
Training loss: 1.2236582040786743
Validation loss: 2.2671727935473123

Epoch: 5| Step: 11
Training loss: 1.754706859588623
Validation loss: 2.2701782286167145

Epoch: 283| Step: 0
Training loss: 1.596663475036621
Validation loss: 2.2881120840708413

Epoch: 5| Step: 1
Training loss: 1.7205270528793335
Validation loss: 2.2776722411314645

Epoch: 5| Step: 2
Training loss: 1.466680884361267
Validation loss: 2.271785835425059

Epoch: 5| Step: 3
Training loss: 1.779500961303711
Validation loss: 2.281486695011457

Epoch: 5| Step: 4
Training loss: 1.7759755849838257
Validation loss: 2.2604724566141763

Epoch: 5| Step: 5
Training loss: 1.3621822595596313
Validation loss: 2.278404931227366

Epoch: 5| Step: 6
Training loss: 1.1344133615493774
Validation loss: 2.275914743542671

Epoch: 5| Step: 7
Training loss: 1.2319400310516357
Validation loss: 2.279172162214915

Epoch: 5| Step: 8
Training loss: 2.297041654586792
Validation loss: 2.25618439912796

Epoch: 5| Step: 9
Training loss: 1.7031490802764893
Validation loss: 2.2557548781236014

Epoch: 5| Step: 10
Training loss: 2.202073812484741
Validation loss: 2.2477760712305703

Epoch: 5| Step: 11
Training loss: 1.477760672569275
Validation loss: 2.245800952116648

Epoch: 284| Step: 0
Training loss: 1.461745023727417
Validation loss: 2.2502287179231644

Epoch: 5| Step: 1
Training loss: 2.0321202278137207
Validation loss: 2.218799978494644

Epoch: 5| Step: 2
Training loss: 1.6891692876815796
Validation loss: 2.234606002767881

Epoch: 5| Step: 3
Training loss: 1.6904464960098267
Validation loss: 2.226276005307833

Epoch: 5| Step: 4
Training loss: 2.3467154502868652
Validation loss: 2.2391284853219986

Epoch: 5| Step: 5
Training loss: 1.3261128664016724
Validation loss: 2.238207370042801

Epoch: 5| Step: 6
Training loss: 1.9650332927703857
Validation loss: 2.2447987844546637

Epoch: 5| Step: 7
Training loss: 1.6044328212738037
Validation loss: 2.2437347819407782

Epoch: 5| Step: 8
Training loss: 1.8702300786972046
Validation loss: 2.21731860935688

Epoch: 5| Step: 9
Training loss: 1.4859864711761475
Validation loss: 2.2292031248410544

Epoch: 5| Step: 10
Training loss: 1.220401406288147
Validation loss: 2.2421312779188156

Epoch: 5| Step: 11
Training loss: 0.8223798274993896
Validation loss: 2.2299060126145682

Epoch: 285| Step: 0
Training loss: 1.6932487487792969
Validation loss: 2.2267447312672934

Epoch: 5| Step: 1
Training loss: 1.8473308086395264
Validation loss: 2.253765473763148

Epoch: 5| Step: 2
Training loss: 1.178765892982483
Validation loss: 2.2104834417502084

Epoch: 5| Step: 3
Training loss: 1.1160591840744019
Validation loss: 2.2291977256536484

Epoch: 5| Step: 4
Training loss: 1.637698769569397
Validation loss: 2.2377879271904626

Epoch: 5| Step: 5
Training loss: 1.865735650062561
Validation loss: 2.2383035024007163

Epoch: 5| Step: 6
Training loss: 1.8198162317276
Validation loss: 2.238417848944664

Epoch: 5| Step: 7
Training loss: 1.6426823139190674
Validation loss: 2.245661586523056

Epoch: 5| Step: 8
Training loss: 1.9361588954925537
Validation loss: 2.228641450405121

Epoch: 5| Step: 9
Training loss: 1.9424108266830444
Validation loss: 2.2394391000270844

Epoch: 5| Step: 10
Training loss: 1.5886714458465576
Validation loss: 2.2349821428457894

Epoch: 5| Step: 11
Training loss: 2.276508331298828
Validation loss: 2.2306270798047385

Epoch: 286| Step: 0
Training loss: 1.849884033203125
Validation loss: 2.2339896261692047

Epoch: 5| Step: 1
Training loss: 2.0444798469543457
Validation loss: 2.246414005756378

Epoch: 5| Step: 2
Training loss: 1.7267221212387085
Validation loss: 2.2426755726337433

Epoch: 5| Step: 3
Training loss: 1.4970695972442627
Validation loss: 2.2211373994747796

Epoch: 5| Step: 4
Training loss: 1.7658355236053467
Validation loss: 2.2440031369527182

Epoch: 5| Step: 5
Training loss: 1.736738920211792
Validation loss: 2.2507929503917694

Epoch: 5| Step: 6
Training loss: 1.6711689233779907
Validation loss: 2.248405079046885

Epoch: 5| Step: 7
Training loss: 1.4499908685684204
Validation loss: 2.225083291530609

Epoch: 5| Step: 8
Training loss: 1.577244758605957
Validation loss: 2.2524306227763495

Epoch: 5| Step: 9
Training loss: 1.7249934673309326
Validation loss: 2.2262242138385773

Epoch: 5| Step: 10
Training loss: 1.3252619504928589
Validation loss: 2.2500301798184714

Epoch: 5| Step: 11
Training loss: 1.597999930381775
Validation loss: 2.2521003832419715

Epoch: 287| Step: 0
Training loss: 1.891017198562622
Validation loss: 2.2430721124013266

Epoch: 5| Step: 1
Training loss: 1.2600200176239014
Validation loss: 2.237755904595057

Epoch: 5| Step: 2
Training loss: 1.6317660808563232
Validation loss: 2.246417889992396

Epoch: 5| Step: 3
Training loss: 1.1263781785964966
Validation loss: 2.219320942958196

Epoch: 5| Step: 4
Training loss: 1.8594207763671875
Validation loss: 2.218260000149409

Epoch: 5| Step: 5
Training loss: 1.7445529699325562
Validation loss: 2.2034212052822113

Epoch: 5| Step: 6
Training loss: 2.3639678955078125
Validation loss: 2.22444549202919

Epoch: 5| Step: 7
Training loss: 1.3676480054855347
Validation loss: 2.216843068599701

Epoch: 5| Step: 8
Training loss: 2.097679615020752
Validation loss: 2.2089259376128516

Epoch: 5| Step: 9
Training loss: 1.8400834798812866
Validation loss: 2.2054134656985602

Epoch: 5| Step: 10
Training loss: 1.3785191774368286
Validation loss: 2.210499495267868

Epoch: 5| Step: 11
Training loss: 1.1412478685379028
Validation loss: 2.2110854188601174

Epoch: 288| Step: 0
Training loss: 1.1925405263900757
Validation loss: 2.233018770813942

Epoch: 5| Step: 1
Training loss: 2.102609157562256
Validation loss: 2.2492365141709647

Epoch: 5| Step: 2
Training loss: 1.7899690866470337
Validation loss: 2.2390656073888144

Epoch: 5| Step: 3
Training loss: 1.6858112812042236
Validation loss: 2.2511899769306183

Epoch: 5| Step: 4
Training loss: 1.5530019998550415
Validation loss: 2.2441715200742087

Epoch: 5| Step: 5
Training loss: 1.634699821472168
Validation loss: 2.230600913365682

Epoch: 5| Step: 6
Training loss: 2.082881212234497
Validation loss: 2.2567982574303946

Epoch: 5| Step: 7
Training loss: 1.539358377456665
Validation loss: 2.2518869837125144

Epoch: 5| Step: 8
Training loss: 1.7586650848388672
Validation loss: 2.2454824248949685

Epoch: 5| Step: 9
Training loss: 1.0695338249206543
Validation loss: 2.25514817237854

Epoch: 5| Step: 10
Training loss: 1.6972061395645142
Validation loss: 2.2418493876854577

Epoch: 5| Step: 11
Training loss: 0.894668698310852
Validation loss: 2.2553658485412598

Epoch: 289| Step: 0
Training loss: 1.6046106815338135
Validation loss: 2.2813667555650077

Epoch: 5| Step: 1
Training loss: 1.5177186727523804
Validation loss: 2.2853356897830963

Epoch: 5| Step: 2
Training loss: 1.7544549703598022
Validation loss: 2.2626399199167886

Epoch: 5| Step: 3
Training loss: 1.401729702949524
Validation loss: 2.258379270633062

Epoch: 5| Step: 4
Training loss: 1.8030649423599243
Validation loss: 2.2262770533561707

Epoch: 5| Step: 5
Training loss: 1.5759389400482178
Validation loss: 2.2453540066878

Epoch: 5| Step: 6
Training loss: 2.235069990158081
Validation loss: 2.252184977134069

Epoch: 5| Step: 7
Training loss: 1.312756061553955
Validation loss: 2.2751227964957557

Epoch: 5| Step: 8
Training loss: 1.8629529476165771
Validation loss: 2.245714783668518

Epoch: 5| Step: 9
Training loss: 0.8200567364692688
Validation loss: 2.2472148736317954

Epoch: 5| Step: 10
Training loss: 2.1399970054626465
Validation loss: 2.243966822822889

Epoch: 5| Step: 11
Training loss: 1.194326639175415
Validation loss: 2.239584510525068

Epoch: 290| Step: 0
Training loss: 1.7838512659072876
Validation loss: 2.2502222806215286

Epoch: 5| Step: 1
Training loss: 1.4041967391967773
Validation loss: 2.249978785713514

Epoch: 5| Step: 2
Training loss: 1.1229162216186523
Validation loss: 2.2287056545416513

Epoch: 5| Step: 3
Training loss: 1.763575792312622
Validation loss: 2.23242516318957

Epoch: 5| Step: 4
Training loss: 1.8512309789657593
Validation loss: 2.2379601697127023

Epoch: 5| Step: 5
Training loss: 1.9592828750610352
Validation loss: 2.257436126470566

Epoch: 5| Step: 6
Training loss: 1.5603358745574951
Validation loss: 2.2622654934724173

Epoch: 5| Step: 7
Training loss: 1.334572434425354
Validation loss: 2.2604954143365226

Epoch: 5| Step: 8
Training loss: 2.0491647720336914
Validation loss: 2.272865802049637

Epoch: 5| Step: 9
Training loss: 1.6027330160140991
Validation loss: 2.2518700311581292

Epoch: 5| Step: 10
Training loss: 1.3397371768951416
Validation loss: 2.264414077003797

Epoch: 5| Step: 11
Training loss: 1.2479158639907837
Validation loss: 2.2775295873483024

Epoch: 291| Step: 0
Training loss: 1.7836602926254272
Validation loss: 2.2728848854700723

Epoch: 5| Step: 1
Training loss: 1.6432559490203857
Validation loss: 2.2974453270435333

Epoch: 5| Step: 2
Training loss: 0.9294782876968384
Validation loss: 2.28262060880661

Epoch: 5| Step: 3
Training loss: 1.9488426446914673
Validation loss: 2.275237758954366

Epoch: 5| Step: 4
Training loss: 1.9780333042144775
Validation loss: 2.274996022383372

Epoch: 5| Step: 5
Training loss: 1.7572822570800781
Validation loss: 2.259241367379824

Epoch: 5| Step: 6
Training loss: 1.503803014755249
Validation loss: 2.2505431870619454

Epoch: 5| Step: 7
Training loss: 1.0753984451293945
Validation loss: 2.2362781961758933

Epoch: 5| Step: 8
Training loss: 2.0228374004364014
Validation loss: 2.2275922993818917

Epoch: 5| Step: 9
Training loss: 1.7564491033554077
Validation loss: 2.253800948460897

Epoch: 5| Step: 10
Training loss: 1.4241834878921509
Validation loss: 2.239953964948654

Epoch: 5| Step: 11
Training loss: 2.830758810043335
Validation loss: 2.233824377258619

Epoch: 292| Step: 0
Training loss: 1.2992504835128784
Validation loss: 2.2313936750094094

Epoch: 5| Step: 1
Training loss: 1.462554693222046
Validation loss: 2.219396357734998

Epoch: 5| Step: 2
Training loss: 1.6587899923324585
Validation loss: 2.1875528444846473

Epoch: 5| Step: 3
Training loss: 1.631333351135254
Validation loss: 2.181649977962176

Epoch: 5| Step: 4
Training loss: 1.3206521272659302
Validation loss: 2.197031299273173

Epoch: 5| Step: 5
Training loss: 1.5728613138198853
Validation loss: 2.169822300473849

Epoch: 5| Step: 6
Training loss: 1.8250858783721924
Validation loss: 2.2026013930638633

Epoch: 5| Step: 7
Training loss: 1.777528166770935
Validation loss: 2.161477064092954

Epoch: 5| Step: 8
Training loss: 1.7535253763198853
Validation loss: 2.1896742979685464

Epoch: 5| Step: 9
Training loss: 1.8823121786117554
Validation loss: 2.1949391265710196

Epoch: 5| Step: 10
Training loss: 1.9917552471160889
Validation loss: 2.1794253637393317

Epoch: 5| Step: 11
Training loss: 1.6811603307724
Validation loss: 2.179640159010887

Epoch: 293| Step: 0
Training loss: 1.5302289724349976
Validation loss: 2.2224222322305045

Epoch: 5| Step: 1
Training loss: 1.9559940099716187
Validation loss: 2.2157093385855355

Epoch: 5| Step: 2
Training loss: 1.1949145793914795
Validation loss: 2.223322346806526

Epoch: 5| Step: 3
Training loss: 1.494524359703064
Validation loss: 2.2326958080132804

Epoch: 5| Step: 4
Training loss: 1.9017254114151
Validation loss: 2.233588829636574

Epoch: 5| Step: 5
Training loss: 1.7887777090072632
Validation loss: 2.256681208809217

Epoch: 5| Step: 6
Training loss: 1.3739062547683716
Validation loss: 2.2374715954065323

Epoch: 5| Step: 7
Training loss: 1.594859004020691
Validation loss: 2.2439058472712836

Epoch: 5| Step: 8
Training loss: 1.6690410375595093
Validation loss: 2.2653073271115622

Epoch: 5| Step: 9
Training loss: 1.867621660232544
Validation loss: 2.2480960289637246

Epoch: 5| Step: 10
Training loss: 1.7443822622299194
Validation loss: 2.2502377380927405

Epoch: 5| Step: 11
Training loss: 0.34374576807022095
Validation loss: 2.246682266394297

Epoch: 294| Step: 0
Training loss: 1.0329996347427368
Validation loss: 2.2378974109888077

Epoch: 5| Step: 1
Training loss: 1.6059589385986328
Validation loss: 2.2426421443621316

Epoch: 5| Step: 2
Training loss: 1.391258955001831
Validation loss: 2.2460890263319016

Epoch: 5| Step: 3
Training loss: 1.5020681619644165
Validation loss: 2.2186362743377686

Epoch: 5| Step: 4
Training loss: 2.0444047451019287
Validation loss: 2.248630334933599

Epoch: 5| Step: 5
Training loss: 2.0809123516082764
Validation loss: 2.2552572737137475

Epoch: 5| Step: 6
Training loss: 1.458168864250183
Validation loss: 2.243926872809728

Epoch: 5| Step: 7
Training loss: 1.1827572584152222
Validation loss: 2.236142893632253

Epoch: 5| Step: 8
Training loss: 1.948785424232483
Validation loss: 2.2543505132198334

Epoch: 5| Step: 9
Training loss: 1.7045929431915283
Validation loss: 2.2527078439792

Epoch: 5| Step: 10
Training loss: 1.9568874835968018
Validation loss: 2.2477621684471765

Epoch: 5| Step: 11
Training loss: 2.403407573699951
Validation loss: 2.2244499921798706

Epoch: 295| Step: 0
Training loss: 1.0348536968231201
Validation loss: 2.230312004685402

Epoch: 5| Step: 1
Training loss: 1.563341498374939
Validation loss: 2.2792076418797174

Epoch: 5| Step: 2
Training loss: 2.133329391479492
Validation loss: 2.2427470982074738

Epoch: 5| Step: 3
Training loss: 1.3071300983428955
Validation loss: 2.237403482198715

Epoch: 5| Step: 4
Training loss: 1.865059494972229
Validation loss: 2.2348871529102325

Epoch: 5| Step: 5
Training loss: 1.9241119623184204
Validation loss: 2.213030238946279

Epoch: 5| Step: 6
Training loss: 1.928450345993042
Validation loss: 2.1971573481957116

Epoch: 5| Step: 7
Training loss: 1.7204196453094482
Validation loss: 2.2532233893871307

Epoch: 5| Step: 8
Training loss: 1.7165571451187134
Validation loss: 2.2364059487978616

Epoch: 5| Step: 9
Training loss: 1.4742248058319092
Validation loss: 2.2726576030254364

Epoch: 5| Step: 10
Training loss: 1.5174071788787842
Validation loss: 2.2862930595874786

Epoch: 5| Step: 11
Training loss: 1.050014615058899
Validation loss: 2.2926506400108337

Epoch: 296| Step: 0
Training loss: 1.6252415180206299
Validation loss: 2.270744820435842

Epoch: 5| Step: 1
Training loss: 2.38004732131958
Validation loss: 2.266721328099569

Epoch: 5| Step: 2
Training loss: 1.5418137311935425
Validation loss: 2.2885336875915527

Epoch: 5| Step: 3
Training loss: 1.7708895206451416
Validation loss: 2.262353330850601

Epoch: 5| Step: 4
Training loss: 1.264294147491455
Validation loss: 2.2829842070738473

Epoch: 5| Step: 5
Training loss: 1.6889512538909912
Validation loss: 2.267294242978096

Epoch: 5| Step: 6
Training loss: 2.1117312908172607
Validation loss: 2.2776030699412027

Epoch: 5| Step: 7
Training loss: 1.231276273727417
Validation loss: 2.2812151312828064

Epoch: 5| Step: 8
Training loss: 1.061958909034729
Validation loss: 2.256515989700953

Epoch: 5| Step: 9
Training loss: 1.8178117275238037
Validation loss: 2.255574648578962

Epoch: 5| Step: 10
Training loss: 1.4566196203231812
Validation loss: 2.242679844299952

Epoch: 5| Step: 11
Training loss: 3.135385036468506
Validation loss: 2.249910612901052

Epoch: 297| Step: 0
Training loss: 1.7599270343780518
Validation loss: 2.2464718719323478

Epoch: 5| Step: 1
Training loss: 1.8149642944335938
Validation loss: 2.2644508133331933

Epoch: 5| Step: 2
Training loss: 1.581307053565979
Validation loss: 2.254672348499298

Epoch: 5| Step: 3
Training loss: 2.120593786239624
Validation loss: 2.2469774881998696

Epoch: 5| Step: 4
Training loss: 1.5678399801254272
Validation loss: 2.2249811788400016

Epoch: 5| Step: 5
Training loss: 2.0176069736480713
Validation loss: 2.22039332985878

Epoch: 5| Step: 6
Training loss: 1.249326467514038
Validation loss: 2.2164729088544846

Epoch: 5| Step: 7
Training loss: 1.444027066230774
Validation loss: 2.2258759438991547

Epoch: 5| Step: 8
Training loss: 1.2029988765716553
Validation loss: 2.223714609940847

Epoch: 5| Step: 9
Training loss: 2.094181776046753
Validation loss: 2.216554746031761

Epoch: 5| Step: 10
Training loss: 1.041232705116272
Validation loss: 2.2112283458312354

Epoch: 5| Step: 11
Training loss: 1.7418371438980103
Validation loss: 2.2181292523940406

Epoch: 298| Step: 0
Training loss: 1.1550246477127075
Validation loss: 2.2237362066904702

Epoch: 5| Step: 1
Training loss: 1.2476357221603394
Validation loss: 2.231769949197769

Epoch: 5| Step: 2
Training loss: 1.9049570560455322
Validation loss: 2.2351748694976172

Epoch: 5| Step: 3
Training loss: 1.7607755661010742
Validation loss: 2.2447529633839927

Epoch: 5| Step: 4
Training loss: 1.627113699913025
Validation loss: 2.249766230583191

Epoch: 5| Step: 5
Training loss: 1.295469045639038
Validation loss: 2.2510312348604202

Epoch: 5| Step: 6
Training loss: 1.36166512966156
Validation loss: 2.2345910171667733

Epoch: 5| Step: 7
Training loss: 1.8780555725097656
Validation loss: 2.2542332063118615

Epoch: 5| Step: 8
Training loss: 2.0975899696350098
Validation loss: 2.27285568912824

Epoch: 5| Step: 9
Training loss: 1.0537434816360474
Validation loss: 2.2455825010935464

Epoch: 5| Step: 10
Training loss: 2.1384401321411133
Validation loss: 2.2579688678185144

Epoch: 5| Step: 11
Training loss: 1.534948468208313
Validation loss: 2.248258392016093

Epoch: 299| Step: 0
Training loss: 1.1537303924560547
Validation loss: 2.2612647861242294

Epoch: 5| Step: 1
Training loss: 1.4255998134613037
Validation loss: 2.248879889647166

Epoch: 5| Step: 2
Training loss: 1.7933546304702759
Validation loss: 2.2407996505498886

Epoch: 5| Step: 3
Training loss: 1.4477921724319458
Validation loss: 2.2618013819058738

Epoch: 5| Step: 4
Training loss: 1.7872035503387451
Validation loss: 2.257949630419413

Epoch: 5| Step: 5
Training loss: 1.1919156312942505
Validation loss: 2.2629462083180747

Epoch: 5| Step: 6
Training loss: 1.2681653499603271
Validation loss: 2.2762707471847534

Epoch: 5| Step: 7
Training loss: 1.5337156057357788
Validation loss: 2.2646321107943854

Epoch: 5| Step: 8
Training loss: 2.841999053955078
Validation loss: 2.265370895465215

Epoch: 5| Step: 9
Training loss: 1.547058343887329
Validation loss: 2.257851759592692

Epoch: 5| Step: 10
Training loss: 2.0217995643615723
Validation loss: 2.2575038373470306

Epoch: 5| Step: 11
Training loss: 0.7916364669799805
Validation loss: 2.274121438463529

Epoch: 300| Step: 0
Training loss: 1.2239426374435425
Validation loss: 2.288128907481829

Epoch: 5| Step: 1
Training loss: 1.071699857711792
Validation loss: 2.2270197769006095

Epoch: 5| Step: 2
Training loss: 2.4047389030456543
Validation loss: 2.245146984855334

Epoch: 5| Step: 3
Training loss: 1.5261088609695435
Validation loss: 2.22614656885465

Epoch: 5| Step: 4
Training loss: 1.6500437259674072
Validation loss: 2.256002446015676

Epoch: 5| Step: 5
Training loss: 1.0601446628570557
Validation loss: 2.264554371436437

Epoch: 5| Step: 6
Training loss: 1.8253109455108643
Validation loss: 2.266459509730339

Epoch: 5| Step: 7
Training loss: 1.7967636585235596
Validation loss: 2.2661098738511405

Epoch: 5| Step: 8
Training loss: 1.5058759450912476
Validation loss: 2.2634627471367517

Epoch: 5| Step: 9
Training loss: 1.5283616781234741
Validation loss: 2.2380170822143555

Epoch: 5| Step: 10
Training loss: 1.7958533763885498
Validation loss: 2.250816434621811

Epoch: 5| Step: 11
Training loss: 3.4262619018554688
Validation loss: 2.231383427977562

Epoch: 301| Step: 0
Training loss: 1.0482522249221802
Validation loss: 2.226064682006836

Epoch: 5| Step: 1
Training loss: 2.3417956829071045
Validation loss: 2.2361031671365104

Epoch: 5| Step: 2
Training loss: 1.6319118738174438
Validation loss: 2.2114982505639396

Epoch: 5| Step: 3
Training loss: 1.6757373809814453
Validation loss: 2.2374097804228463

Epoch: 5| Step: 4
Training loss: 1.6264305114746094
Validation loss: 2.222963054974874

Epoch: 5| Step: 5
Training loss: 1.1374707221984863
Validation loss: 2.2270197769006095

Epoch: 5| Step: 6
Training loss: 1.5559587478637695
Validation loss: 2.223735307653745

Epoch: 5| Step: 7
Training loss: 1.6522163152694702
Validation loss: 2.214933604001999

Epoch: 5| Step: 8
Training loss: 1.8565285205841064
Validation loss: 2.244500075777372

Epoch: 5| Step: 9
Training loss: 1.7595497369766235
Validation loss: 2.2292985220750174

Epoch: 5| Step: 10
Training loss: 2.203355312347412
Validation loss: 2.2627177387475967

Epoch: 5| Step: 11
Training loss: 1.129928708076477
Validation loss: 2.2681939154863358

Epoch: 302| Step: 0
Training loss: 2.281360626220703
Validation loss: 2.2310543755690255

Epoch: 5| Step: 1
Training loss: 1.3544065952301025
Validation loss: 2.2295530289411545

Epoch: 5| Step: 2
Training loss: 1.6588599681854248
Validation loss: 2.2148063629865646

Epoch: 5| Step: 3
Training loss: 1.416466474533081
Validation loss: 2.219993775089582

Epoch: 5| Step: 4
Training loss: 1.6003170013427734
Validation loss: 2.231439823905627

Epoch: 5| Step: 5
Training loss: 1.494552731513977
Validation loss: 2.226943095525106

Epoch: 5| Step: 6
Training loss: 1.4659587144851685
Validation loss: 2.2401347309350967

Epoch: 5| Step: 7
Training loss: 2.0845084190368652
Validation loss: 2.2640175968408585

Epoch: 5| Step: 8
Training loss: 1.5998589992523193
Validation loss: 2.2347418765227

Epoch: 5| Step: 9
Training loss: 1.4442557096481323
Validation loss: 2.2505955199400582

Epoch: 5| Step: 10
Training loss: 1.5506409406661987
Validation loss: 2.25963386396567

Epoch: 5| Step: 11
Training loss: 2.5576086044311523
Validation loss: 2.2648719251155853

Epoch: 303| Step: 0
Training loss: 1.5243505239486694
Validation loss: 2.268428007761637

Epoch: 5| Step: 1
Training loss: 2.269127368927002
Validation loss: 2.2761435409386954

Epoch: 5| Step: 2
Training loss: 1.4737293720245361
Validation loss: 2.283065895239512

Epoch: 5| Step: 3
Training loss: 1.1943341493606567
Validation loss: 2.2774687707424164

Epoch: 5| Step: 4
Training loss: 1.0361716747283936
Validation loss: 2.2767684012651443

Epoch: 5| Step: 5
Training loss: 1.216542363166809
Validation loss: 2.271113246679306

Epoch: 5| Step: 6
Training loss: 2.1374154090881348
Validation loss: 2.274600714445114

Epoch: 5| Step: 7
Training loss: 1.8554388284683228
Validation loss: 2.2938775718212128

Epoch: 5| Step: 8
Training loss: 1.752281904220581
Validation loss: 2.2891077597935996

Epoch: 5| Step: 9
Training loss: 1.7453041076660156
Validation loss: 2.2721684773763022

Epoch: 5| Step: 10
Training loss: 1.350193738937378
Validation loss: 2.2762628197669983

Epoch: 5| Step: 11
Training loss: 0.6642876863479614
Validation loss: 2.2596461524566016

Epoch: 304| Step: 0
Training loss: 1.267626166343689
Validation loss: 2.2656314820051193

Epoch: 5| Step: 1
Training loss: 1.3739004135131836
Validation loss: 2.257219990094503

Epoch: 5| Step: 2
Training loss: 1.5313564538955688
Validation loss: 2.2597622871398926

Epoch: 5| Step: 3
Training loss: 1.606814980506897
Validation loss: 2.2562186419963837

Epoch: 5| Step: 4
Training loss: 1.2652885913848877
Validation loss: 2.24045800169309

Epoch: 5| Step: 5
Training loss: 1.9528911113739014
Validation loss: 2.232259899377823

Epoch: 5| Step: 6
Training loss: 1.956944227218628
Validation loss: 2.2180063873529434

Epoch: 5| Step: 7
Training loss: 1.4076964855194092
Validation loss: 2.222933600346247

Epoch: 5| Step: 8
Training loss: 1.625769853591919
Validation loss: 2.1926216880480447

Epoch: 5| Step: 9
Training loss: 1.7503105401992798
Validation loss: 2.20295050740242

Epoch: 5| Step: 10
Training loss: 1.5038613080978394
Validation loss: 2.1953686475753784

Epoch: 5| Step: 11
Training loss: 1.619425654411316
Validation loss: 2.2186873108148575

Epoch: 305| Step: 0
Training loss: 1.371839165687561
Validation loss: 2.2498463640610376

Epoch: 5| Step: 1
Training loss: 0.9698387384414673
Validation loss: 2.228848467270533

Epoch: 5| Step: 2
Training loss: 1.6770203113555908
Validation loss: 2.267132962743441

Epoch: 5| Step: 3
Training loss: 1.6889384984970093
Validation loss: 2.2575744638840356

Epoch: 5| Step: 4
Training loss: 1.4027018547058105
Validation loss: 2.2833489974339805

Epoch: 5| Step: 5
Training loss: 1.915313720703125
Validation loss: 2.2797339459260306

Epoch: 5| Step: 6
Training loss: 1.513311505317688
Validation loss: 2.2647982984781265

Epoch: 5| Step: 7
Training loss: 2.107295513153076
Validation loss: 2.2931111405293145

Epoch: 5| Step: 8
Training loss: 1.4766933917999268
Validation loss: 2.298844267924627

Epoch: 5| Step: 9
Training loss: 1.6867687702178955
Validation loss: 2.28609162569046

Epoch: 5| Step: 10
Training loss: 1.4036327600479126
Validation loss: 2.3010002821683884

Epoch: 5| Step: 11
Training loss: 1.7393394708633423
Validation loss: 2.287295694152514

Epoch: 306| Step: 0
Training loss: 0.8168126940727234
Validation loss: 2.2658748676379523

Epoch: 5| Step: 1
Training loss: 1.5299018621444702
Validation loss: 2.2395019878943763

Epoch: 5| Step: 2
Training loss: 1.8545894622802734
Validation loss: 2.2539737472931543

Epoch: 5| Step: 3
Training loss: 2.142867088317871
Validation loss: 2.225378399093946

Epoch: 5| Step: 4
Training loss: 1.422095537185669
Validation loss: 2.1953642865022025

Epoch: 5| Step: 5
Training loss: 1.8740005493164062
Validation loss: 2.1950880338748298

Epoch: 5| Step: 6
Training loss: 1.9713414907455444
Validation loss: 2.215659514069557

Epoch: 5| Step: 7
Training loss: 1.0699818134307861
Validation loss: 2.2307007114092507

Epoch: 5| Step: 8
Training loss: 1.6978938579559326
Validation loss: 2.1982210328181586

Epoch: 5| Step: 9
Training loss: 1.6069072484970093
Validation loss: 2.2065071960290275

Epoch: 5| Step: 10
Training loss: 1.7109825611114502
Validation loss: 2.200286408265432

Epoch: 5| Step: 11
Training loss: 1.4963053464889526
Validation loss: 2.1942964990933738

Epoch: 307| Step: 0
Training loss: 1.5485765933990479
Validation loss: 2.21579717596372

Epoch: 5| Step: 1
Training loss: 1.1393282413482666
Validation loss: 2.244031851490339

Epoch: 5| Step: 2
Training loss: 1.442328929901123
Validation loss: 2.255277449886004

Epoch: 5| Step: 3
Training loss: 1.5395739078521729
Validation loss: 2.2421556214491525

Epoch: 5| Step: 4
Training loss: 1.8691871166229248
Validation loss: 2.269652470946312

Epoch: 5| Step: 5
Training loss: 1.4970208406448364
Validation loss: 2.2649739334980645

Epoch: 5| Step: 6
Training loss: 1.647282600402832
Validation loss: 2.28931832810243

Epoch: 5| Step: 7
Training loss: 1.567771077156067
Validation loss: 2.2690912733475366

Epoch: 5| Step: 8
Training loss: 1.9519243240356445
Validation loss: 2.2732975532611213

Epoch: 5| Step: 9
Training loss: 1.6090881824493408
Validation loss: 2.2736613353093467

Epoch: 5| Step: 10
Training loss: 1.5157454013824463
Validation loss: 2.2737537771463394

Epoch: 5| Step: 11
Training loss: 1.5173970460891724
Validation loss: 2.2194230953852334

Epoch: 308| Step: 0
Training loss: 1.5484342575073242
Validation loss: 2.2714430491129556

Epoch: 5| Step: 1
Training loss: 1.9910287857055664
Validation loss: 2.272887090841929

Epoch: 5| Step: 2
Training loss: 1.8086998462677002
Validation loss: 2.301353856921196

Epoch: 5| Step: 3
Training loss: 1.3765363693237305
Validation loss: 2.288520554701487

Epoch: 5| Step: 4
Training loss: 1.9648933410644531
Validation loss: 2.2934431433677673

Epoch: 5| Step: 5
Training loss: 1.3205235004425049
Validation loss: 2.2686380644639335

Epoch: 5| Step: 6
Training loss: 1.230066180229187
Validation loss: 2.284046252568563

Epoch: 5| Step: 7
Training loss: 1.5326839685440063
Validation loss: 2.258041113615036

Epoch: 5| Step: 8
Training loss: 1.4450832605361938
Validation loss: 2.2776689926783242

Epoch: 5| Step: 9
Training loss: 1.3838032484054565
Validation loss: 2.2790945172309875

Epoch: 5| Step: 10
Training loss: 1.8193657398223877
Validation loss: 2.2480419476826987

Epoch: 5| Step: 11
Training loss: 1.301323413848877
Validation loss: 2.2594027121861777

Epoch: 309| Step: 0
Training loss: 1.8568332195281982
Validation loss: 2.250100086132685

Epoch: 5| Step: 1
Training loss: 1.9683843851089478
Validation loss: 2.235953986644745

Epoch: 5| Step: 2
Training loss: 1.4910171031951904
Validation loss: 2.2521433581908545

Epoch: 5| Step: 3
Training loss: 1.5034735202789307
Validation loss: 2.2600164711475372

Epoch: 5| Step: 4
Training loss: 0.9439794421195984
Validation loss: 2.253271540006002

Epoch: 5| Step: 5
Training loss: 1.1283338069915771
Validation loss: 2.2676429649194083

Epoch: 5| Step: 6
Training loss: 1.6268255710601807
Validation loss: 2.272329717874527

Epoch: 5| Step: 7
Training loss: 1.1352332830429077
Validation loss: 2.24585268398126

Epoch: 5| Step: 8
Training loss: 1.702893614768982
Validation loss: 2.256835659344991

Epoch: 5| Step: 9
Training loss: 2.0638632774353027
Validation loss: 2.2559606482585273

Epoch: 5| Step: 10
Training loss: 1.7387335300445557
Validation loss: 2.2513477653265

Epoch: 5| Step: 11
Training loss: 0.9572979211807251
Validation loss: 2.2578190118074417

Epoch: 310| Step: 0
Training loss: 1.524848222732544
Validation loss: 2.2627399563789368

Epoch: 5| Step: 1
Training loss: 1.8091026544570923
Validation loss: 2.295973017811775

Epoch: 5| Step: 2
Training loss: 1.3074748516082764
Validation loss: 2.2699640492598214

Epoch: 5| Step: 3
Training loss: 1.5752794742584229
Validation loss: 2.271374543507894

Epoch: 5| Step: 4
Training loss: 1.0710651874542236
Validation loss: 2.299971560637156

Epoch: 5| Step: 5
Training loss: 1.1547772884368896
Validation loss: 2.2689185241858163

Epoch: 5| Step: 6
Training loss: 1.7270011901855469
Validation loss: 2.2869342466195426

Epoch: 5| Step: 7
Training loss: 1.0989774465560913
Validation loss: 2.2624468207359314

Epoch: 5| Step: 8
Training loss: 1.6251773834228516
Validation loss: 2.2737014393011727

Epoch: 5| Step: 9
Training loss: 1.926414132118225
Validation loss: 2.251106470823288

Epoch: 5| Step: 10
Training loss: 1.9346797466278076
Validation loss: 2.286588470141093

Epoch: 5| Step: 11
Training loss: 2.3768653869628906
Validation loss: 2.2848308086395264

Epoch: 311| Step: 0
Training loss: 0.8050540089607239
Validation loss: 2.270212451616923

Epoch: 5| Step: 1
Training loss: 1.7883846759796143
Validation loss: 2.2803228745857873

Epoch: 5| Step: 2
Training loss: 2.0171947479248047
Validation loss: 2.2585014750560126

Epoch: 5| Step: 3
Training loss: 1.5442554950714111
Validation loss: 2.271637866894404

Epoch: 5| Step: 4
Training loss: 1.3718822002410889
Validation loss: 2.2472838362058005

Epoch: 5| Step: 5
Training loss: 1.405550241470337
Validation loss: 2.252140775322914

Epoch: 5| Step: 6
Training loss: 1.138850450515747
Validation loss: 2.219814489285151

Epoch: 5| Step: 7
Training loss: 1.3862026929855347
Validation loss: 2.225962281227112

Epoch: 5| Step: 8
Training loss: 1.792665719985962
Validation loss: 2.2148795972267785

Epoch: 5| Step: 9
Training loss: 2.6084961891174316
Validation loss: 2.20580426355203

Epoch: 5| Step: 10
Training loss: 1.5510090589523315
Validation loss: 2.2245511213938394

Epoch: 5| Step: 11
Training loss: 1.4723563194274902
Validation loss: 2.234776943922043

Epoch: 312| Step: 0
Training loss: 1.8934398889541626
Validation loss: 2.267133116722107

Epoch: 5| Step: 1
Training loss: 1.0421135425567627
Validation loss: 2.243285372853279

Epoch: 5| Step: 2
Training loss: 1.563890814781189
Validation loss: 2.254978761076927

Epoch: 5| Step: 3
Training loss: 1.9394261837005615
Validation loss: 2.2465377946694693

Epoch: 5| Step: 4
Training loss: 1.1713768243789673
Validation loss: 2.233436793088913

Epoch: 5| Step: 5
Training loss: 1.9101321697235107
Validation loss: 2.2366227904955545

Epoch: 5| Step: 6
Training loss: 1.4156992435455322
Validation loss: 2.224182387193044

Epoch: 5| Step: 7
Training loss: 1.8991448879241943
Validation loss: 2.2492612401644387

Epoch: 5| Step: 8
Training loss: 1.2744238376617432
Validation loss: 2.2218061288197837

Epoch: 5| Step: 9
Training loss: 1.762878656387329
Validation loss: 2.2286728819211326

Epoch: 5| Step: 10
Training loss: 2.5284316539764404
Validation loss: 2.2226727306842804

Epoch: 5| Step: 11
Training loss: 0.7894176840782166
Validation loss: 2.2000283946593604

Epoch: 313| Step: 0
Training loss: 1.4424694776535034
Validation loss: 2.2249279220898948

Epoch: 5| Step: 1
Training loss: 1.487304925918579
Validation loss: 2.217616652448972

Epoch: 5| Step: 2
Training loss: 2.1776516437530518
Validation loss: 2.225428735216459

Epoch: 5| Step: 3
Training loss: 1.7167022228240967
Validation loss: 2.192492430408796

Epoch: 5| Step: 4
Training loss: 1.9421151876449585
Validation loss: 2.1890612741311393

Epoch: 5| Step: 5
Training loss: 1.645911455154419
Validation loss: 2.189863994717598

Epoch: 5| Step: 6
Training loss: 1.565459966659546
Validation loss: 2.197077661752701

Epoch: 5| Step: 7
Training loss: 1.3689610958099365
Validation loss: 2.206158106525739

Epoch: 5| Step: 8
Training loss: 1.3697313070297241
Validation loss: 2.195327863097191

Epoch: 5| Step: 9
Training loss: 1.280045747756958
Validation loss: 2.1939016928275428

Epoch: 5| Step: 10
Training loss: 1.6688051223754883
Validation loss: 2.2207130740086236

Epoch: 5| Step: 11
Training loss: 2.4062938690185547
Validation loss: 2.233233317732811

Epoch: 314| Step: 0
Training loss: 1.4227135181427002
Validation loss: 2.250139757990837

Epoch: 5| Step: 1
Training loss: 2.1248838901519775
Validation loss: 2.2476677199204764

Epoch: 5| Step: 2
Training loss: 1.4841351509094238
Validation loss: 2.2213216622670493

Epoch: 5| Step: 3
Training loss: 1.3936128616333008
Validation loss: 2.2244578103224435

Epoch: 5| Step: 4
Training loss: 1.8470875024795532
Validation loss: 2.2558997174104056

Epoch: 5| Step: 5
Training loss: 1.7238223552703857
Validation loss: 2.2535326878229776

Epoch: 5| Step: 6
Training loss: 1.4004216194152832
Validation loss: 2.249214361111323

Epoch: 5| Step: 7
Training loss: 1.1797144412994385
Validation loss: 2.238134245077769

Epoch: 5| Step: 8
Training loss: 1.3355315923690796
Validation loss: 2.2531324525674186

Epoch: 5| Step: 9
Training loss: 1.182335615158081
Validation loss: 2.254313866297404

Epoch: 5| Step: 10
Training loss: 2.043584108352661
Validation loss: 2.2570406049489975

Epoch: 5| Step: 11
Training loss: 2.1221766471862793
Validation loss: 2.2384868462880454

Epoch: 315| Step: 0
Training loss: 2.8284196853637695
Validation loss: 2.228882988293966

Epoch: 5| Step: 1
Training loss: 1.289097785949707
Validation loss: 2.2456275721391044

Epoch: 5| Step: 2
Training loss: 1.3335530757904053
Validation loss: 2.2258812536795936

Epoch: 5| Step: 3
Training loss: 1.908299446105957
Validation loss: 2.250363772114118

Epoch: 5| Step: 4
Training loss: 1.6276476383209229
Validation loss: 2.2511856059233346

Epoch: 5| Step: 5
Training loss: 1.1283175945281982
Validation loss: 2.248702973127365

Epoch: 5| Step: 6
Training loss: 1.4397176504135132
Validation loss: 2.271552493174871

Epoch: 5| Step: 7
Training loss: 1.2248351573944092
Validation loss: 2.2396900206804276

Epoch: 5| Step: 8
Training loss: 0.7741768956184387
Validation loss: 2.2681844333807626

Epoch: 5| Step: 9
Training loss: 1.3836376667022705
Validation loss: 2.250262056787809

Epoch: 5| Step: 10
Training loss: 1.9875876903533936
Validation loss: 2.262047678232193

Epoch: 5| Step: 11
Training loss: 0.8740859031677246
Validation loss: 2.2684771368900933

Epoch: 316| Step: 0
Training loss: 1.5429692268371582
Validation loss: 2.2520435651143393

Epoch: 5| Step: 1
Training loss: 1.3332695960998535
Validation loss: 2.255358005563418

Epoch: 5| Step: 2
Training loss: 1.9628101587295532
Validation loss: 2.2293387949466705

Epoch: 5| Step: 3
Training loss: 1.4194968938827515
Validation loss: 2.254102369149526

Epoch: 5| Step: 4
Training loss: 0.9215474128723145
Validation loss: 2.264834607640902

Epoch: 5| Step: 5
Training loss: 1.2833683490753174
Validation loss: 2.2685392697652182

Epoch: 5| Step: 6
Training loss: 1.716606855392456
Validation loss: 2.244269068042437

Epoch: 5| Step: 7
Training loss: 0.8463343381881714
Validation loss: 2.2706873466571174

Epoch: 5| Step: 8
Training loss: 1.4978845119476318
Validation loss: 2.247714708248774

Epoch: 5| Step: 9
Training loss: 1.7820965051651
Validation loss: 2.241524507602056

Epoch: 5| Step: 10
Training loss: 2.4878182411193848
Validation loss: 2.2465895265340805

Epoch: 5| Step: 11
Training loss: 1.907626986503601
Validation loss: 2.238555148243904

Epoch: 317| Step: 0
Training loss: 1.6418263912200928
Validation loss: 2.2662414411703744

Epoch: 5| Step: 1
Training loss: 0.9026416540145874
Validation loss: 2.242156078418096

Epoch: 5| Step: 2
Training loss: 1.5893290042877197
Validation loss: 2.2354170630375543

Epoch: 5| Step: 3
Training loss: 2.0349907875061035
Validation loss: 2.2289654264847436

Epoch: 5| Step: 4
Training loss: 1.5236849784851074
Validation loss: 2.2168385833501816

Epoch: 5| Step: 5
Training loss: 1.4890984296798706
Validation loss: 2.211840276916822

Epoch: 5| Step: 6
Training loss: 1.837105393409729
Validation loss: 2.1671175857385

Epoch: 5| Step: 7
Training loss: 2.033514976501465
Validation loss: 2.17093792061011

Epoch: 5| Step: 8
Training loss: 1.9791122674942017
Validation loss: 2.2087396532297134

Epoch: 5| Step: 9
Training loss: 1.9726581573486328
Validation loss: 2.179093728462855

Epoch: 5| Step: 10
Training loss: 1.183964729309082
Validation loss: 2.1699043860038123

Epoch: 5| Step: 11
Training loss: 1.527691125869751
Validation loss: 2.1935446560382843

Epoch: 318| Step: 0
Training loss: 1.773373007774353
Validation loss: 2.1686975061893463

Epoch: 5| Step: 1
Training loss: 1.3576961755752563
Validation loss: 2.2075575391451516

Epoch: 5| Step: 2
Training loss: 1.140031099319458
Validation loss: 2.210852806766828

Epoch: 5| Step: 3
Training loss: 2.0117926597595215
Validation loss: 2.2217562148968377

Epoch: 5| Step: 4
Training loss: 1.2346841096878052
Validation loss: 2.2245746354262033

Epoch: 5| Step: 5
Training loss: 1.7554782629013062
Validation loss: 2.2190335243940353

Epoch: 5| Step: 6
Training loss: 1.770382285118103
Validation loss: 2.2541358023881912

Epoch: 5| Step: 7
Training loss: 1.552006721496582
Validation loss: 2.266127790013949

Epoch: 5| Step: 8
Training loss: 2.1616194248199463
Validation loss: 2.284627358118693

Epoch: 5| Step: 9
Training loss: 1.5201656818389893
Validation loss: 2.2655481547117233

Epoch: 5| Step: 10
Training loss: 1.0583995580673218
Validation loss: 2.267985090613365

Epoch: 5| Step: 11
Training loss: 1.1943564414978027
Validation loss: 2.2462822447220483

Epoch: 319| Step: 0
Training loss: 1.5641902685165405
Validation loss: 2.273116499185562

Epoch: 5| Step: 1
Training loss: 1.3198416233062744
Validation loss: 2.263964225848516

Epoch: 5| Step: 2
Training loss: 2.239579677581787
Validation loss: 2.280857046445211

Epoch: 5| Step: 3
Training loss: 2.5521650314331055
Validation loss: 2.2638066758712134

Epoch: 5| Step: 4
Training loss: 1.3385679721832275
Validation loss: 2.2848289559284845

Epoch: 5| Step: 5
Training loss: 1.4927403926849365
Validation loss: 2.2716966619094214

Epoch: 5| Step: 6
Training loss: 1.031467080116272
Validation loss: 2.266309216618538

Epoch: 5| Step: 7
Training loss: 1.8916313648223877
Validation loss: 2.266566351056099

Epoch: 5| Step: 8
Training loss: 1.071893572807312
Validation loss: 2.2307879428068795

Epoch: 5| Step: 9
Training loss: 1.4752615690231323
Validation loss: 2.246418039004008

Epoch: 5| Step: 10
Training loss: 1.227656364440918
Validation loss: 2.2528193394343057

Epoch: 5| Step: 11
Training loss: 1.7145553827285767
Validation loss: 2.285122290253639

Epoch: 320| Step: 0
Training loss: 1.1682028770446777
Validation loss: 2.2989034255345664

Epoch: 5| Step: 1
Training loss: 1.8795394897460938
Validation loss: 2.280344237883886

Epoch: 5| Step: 2
Training loss: 1.396250605583191
Validation loss: 2.289429694414139

Epoch: 5| Step: 3
Training loss: 1.4361871480941772
Validation loss: 2.3105084349711738

Epoch: 5| Step: 4
Training loss: 1.2100374698638916
Validation loss: 2.282342702150345

Epoch: 5| Step: 5
Training loss: 1.460101842880249
Validation loss: 2.2682451705137887

Epoch: 5| Step: 6
Training loss: 1.858176827430725
Validation loss: 2.263216262062391

Epoch: 5| Step: 7
Training loss: 1.6386276483535767
Validation loss: 2.2931607166926065

Epoch: 5| Step: 8
Training loss: 2.001150608062744
Validation loss: 2.272356778383255

Epoch: 5| Step: 9
Training loss: 1.06043541431427
Validation loss: 2.297639454404513

Epoch: 5| Step: 10
Training loss: 1.8034919500350952
Validation loss: 2.2760879000027976

Epoch: 5| Step: 11
Training loss: 0.8282397985458374
Validation loss: 2.30343667169412

Epoch: 321| Step: 0
Training loss: 1.6853854656219482
Validation loss: 2.3230484326680503

Epoch: 5| Step: 1
Training loss: 1.9622478485107422
Validation loss: 2.31516241033872

Epoch: 5| Step: 2
Training loss: 1.4189493656158447
Validation loss: 2.27517261604468

Epoch: 5| Step: 3
Training loss: 1.7007474899291992
Validation loss: 2.3066884676615396

Epoch: 5| Step: 4
Training loss: 1.3855690956115723
Validation loss: 2.3094512720902762

Epoch: 5| Step: 5
Training loss: 1.6838815212249756
Validation loss: 2.2868618269761405

Epoch: 5| Step: 6
Training loss: 1.083168625831604
Validation loss: 2.292880435784658

Epoch: 5| Step: 7
Training loss: 1.1676908731460571
Validation loss: 2.2820110817750296

Epoch: 5| Step: 8
Training loss: 2.08312726020813
Validation loss: 2.2704059183597565

Epoch: 5| Step: 9
Training loss: 1.336073398590088
Validation loss: 2.2563426047563553

Epoch: 5| Step: 10
Training loss: 1.0484477281570435
Validation loss: 2.260805090268453

Epoch: 5| Step: 11
Training loss: 2.0682289600372314
Validation loss: 2.270281712214152

Epoch: 322| Step: 0
Training loss: 1.7025896310806274
Validation loss: 2.2710284342368445

Epoch: 5| Step: 1
Training loss: 1.2312583923339844
Validation loss: 2.2434389740228653

Epoch: 5| Step: 2
Training loss: 1.584153413772583
Validation loss: 2.243035147587458

Epoch: 5| Step: 3
Training loss: 1.3750911951065063
Validation loss: 2.2595682938893638

Epoch: 5| Step: 4
Training loss: 1.640008568763733
Validation loss: 2.2661659717559814

Epoch: 5| Step: 5
Training loss: 1.950444221496582
Validation loss: 2.280741035938263

Epoch: 5| Step: 6
Training loss: 1.5155551433563232
Validation loss: 2.272004688779513

Epoch: 5| Step: 7
Training loss: 1.1981040239334106
Validation loss: 2.2744784901539483

Epoch: 5| Step: 8
Training loss: 1.765031099319458
Validation loss: 2.250599503517151

Epoch: 5| Step: 9
Training loss: 1.4321913719177246
Validation loss: 2.2818652590115867

Epoch: 5| Step: 10
Training loss: 0.8653529286384583
Validation loss: 2.266707460085551

Epoch: 5| Step: 11
Training loss: 2.296992301940918
Validation loss: 2.239097053805987

Epoch: 323| Step: 0
Training loss: 1.761664628982544
Validation loss: 2.2606359819571176

Epoch: 5| Step: 1
Training loss: 1.3316280841827393
Validation loss: 2.2809731562932334

Epoch: 5| Step: 2
Training loss: 0.9909381866455078
Validation loss: 2.28091961145401

Epoch: 5| Step: 3
Training loss: 1.9647071361541748
Validation loss: 2.314377178748449

Epoch: 5| Step: 4
Training loss: 1.459460973739624
Validation loss: 2.271980126698812

Epoch: 5| Step: 5
Training loss: 1.409930944442749
Validation loss: 2.267955631017685

Epoch: 5| Step: 6
Training loss: 1.719072699546814
Validation loss: 2.2883952856063843

Epoch: 5| Step: 7
Training loss: 1.4927395582199097
Validation loss: 2.276847024758657

Epoch: 5| Step: 8
Training loss: 1.1883779764175415
Validation loss: 2.2524377753337226

Epoch: 5| Step: 9
Training loss: 1.5519282817840576
Validation loss: 2.240981231133143

Epoch: 5| Step: 10
Training loss: 1.80215585231781
Validation loss: 2.209154933691025

Epoch: 5| Step: 11
Training loss: 0.8887745141983032
Validation loss: 2.237694799900055

Epoch: 324| Step: 0
Training loss: 1.5380024909973145
Validation loss: 2.241747130950292

Epoch: 5| Step: 1
Training loss: 1.3926618099212646
Validation loss: 2.1874550680319467

Epoch: 5| Step: 2
Training loss: 1.4451360702514648
Validation loss: 2.189485718806585

Epoch: 5| Step: 3
Training loss: 1.4051519632339478
Validation loss: 2.2207675029834113

Epoch: 5| Step: 4
Training loss: 1.5596122741699219
Validation loss: 2.2230081309874854

Epoch: 5| Step: 5
Training loss: 1.6659352779388428
Validation loss: 2.2432083090146384

Epoch: 5| Step: 6
Training loss: 1.5193545818328857
Validation loss: 2.222090264161428

Epoch: 5| Step: 7
Training loss: 1.7798621654510498
Validation loss: 2.2210133423407874

Epoch: 5| Step: 8
Training loss: 1.2376130819320679
Validation loss: 2.2108985632658005

Epoch: 5| Step: 9
Training loss: 1.1763536930084229
Validation loss: 2.2327707956234613

Epoch: 5| Step: 10
Training loss: 1.4940019845962524
Validation loss: 2.215370406707128

Epoch: 5| Step: 11
Training loss: 2.1982827186584473
Validation loss: 2.2277350276708603

Epoch: 325| Step: 0
Training loss: 1.3461344242095947
Validation loss: 2.2145743469397225

Epoch: 5| Step: 1
Training loss: 1.5613515377044678
Validation loss: 2.24433404703935

Epoch: 5| Step: 2
Training loss: 1.239438772201538
Validation loss: 2.24018702407678

Epoch: 5| Step: 3
Training loss: 2.248427629470825
Validation loss: 2.2132920225461326

Epoch: 5| Step: 4
Training loss: 1.8776209354400635
Validation loss: 2.2618292470773063

Epoch: 5| Step: 5
Training loss: 1.9638856649398804
Validation loss: 2.2536920656760535

Epoch: 5| Step: 6
Training loss: 1.1772127151489258
Validation loss: 2.2628802359104156

Epoch: 5| Step: 7
Training loss: 0.8044974207878113
Validation loss: 2.2844389031330743

Epoch: 5| Step: 8
Training loss: 1.9091427326202393
Validation loss: 2.2574131190776825

Epoch: 5| Step: 9
Training loss: 1.8014501333236694
Validation loss: 2.248253747820854

Epoch: 5| Step: 10
Training loss: 0.8449926376342773
Validation loss: 2.249122033516566

Epoch: 5| Step: 11
Training loss: 0.3658562898635864
Validation loss: 2.2009216845035553

Epoch: 326| Step: 0
Training loss: 1.4265995025634766
Validation loss: 2.2217783679564795

Epoch: 5| Step: 1
Training loss: 1.156610369682312
Validation loss: 2.2394546270370483

Epoch: 5| Step: 2
Training loss: 2.0648884773254395
Validation loss: 2.24223925669988

Epoch: 5| Step: 3
Training loss: 1.6645286083221436
Validation loss: 2.2353887458642325

Epoch: 5| Step: 4
Training loss: 0.9230061769485474
Validation loss: 2.2365081707636514

Epoch: 5| Step: 5
Training loss: 1.3018244504928589
Validation loss: 2.254845773180326

Epoch: 5| Step: 6
Training loss: 1.3201539516448975
Validation loss: 2.2489754060904183

Epoch: 5| Step: 7
Training loss: 1.498471975326538
Validation loss: 2.241517702738444

Epoch: 5| Step: 8
Training loss: 0.9529126882553101
Validation loss: 2.238557810584704

Epoch: 5| Step: 9
Training loss: 1.7877212762832642
Validation loss: 2.2922738989194236

Epoch: 5| Step: 10
Training loss: 2.031342029571533
Validation loss: 2.30437234044075

Epoch: 5| Step: 11
Training loss: 1.585120439529419
Validation loss: 2.2831258376439414

Epoch: 327| Step: 0
Training loss: 1.3492505550384521
Validation loss: 2.304302473862966

Epoch: 5| Step: 1
Training loss: 1.1135694980621338
Validation loss: 2.2750618209441504

Epoch: 5| Step: 2
Training loss: 1.4330596923828125
Validation loss: 2.273460437854131

Epoch: 5| Step: 3
Training loss: 1.6697041988372803
Validation loss: 2.245834852258364

Epoch: 5| Step: 4
Training loss: 2.443676471710205
Validation loss: 2.226062456766764

Epoch: 5| Step: 5
Training loss: 1.332942008972168
Validation loss: 2.253242611885071

Epoch: 5| Step: 6
Training loss: 0.9557479619979858
Validation loss: 2.236967752377192

Epoch: 5| Step: 7
Training loss: 1.3521666526794434
Validation loss: 2.2465038945277533

Epoch: 5| Step: 8
Training loss: 1.9220821857452393
Validation loss: 2.218741854031881

Epoch: 5| Step: 9
Training loss: 1.779404640197754
Validation loss: 2.2682111461957297

Epoch: 5| Step: 10
Training loss: 0.9858816266059875
Validation loss: 2.253811558087667

Epoch: 5| Step: 11
Training loss: 1.8425545692443848
Validation loss: 2.247492546836535

Epoch: 328| Step: 0
Training loss: 2.331874370574951
Validation loss: 2.25099278986454

Epoch: 5| Step: 1
Training loss: 0.8381034731864929
Validation loss: 2.246292104323705

Epoch: 5| Step: 2
Training loss: 1.3422857522964478
Validation loss: 2.2773693203926086

Epoch: 5| Step: 3
Training loss: 2.1336798667907715
Validation loss: 2.217967316508293

Epoch: 5| Step: 4
Training loss: 1.2130849361419678
Validation loss: 2.238808179895083

Epoch: 5| Step: 5
Training loss: 1.3970826864242554
Validation loss: 2.22018963098526

Epoch: 5| Step: 6
Training loss: 1.5162510871887207
Validation loss: 2.222201257944107

Epoch: 5| Step: 7
Training loss: 1.578087568283081
Validation loss: 2.2213704188664756

Epoch: 5| Step: 8
Training loss: 1.8701791763305664
Validation loss: 2.204542577266693

Epoch: 5| Step: 9
Training loss: 1.3891456127166748
Validation loss: 2.18618181347847

Epoch: 5| Step: 10
Training loss: 1.1811147928237915
Validation loss: 2.1538713773091636

Epoch: 5| Step: 11
Training loss: 2.523303747177124
Validation loss: 2.1605228583017984

Epoch: 329| Step: 0
Training loss: 1.1454659700393677
Validation loss: 2.1695907513300576

Epoch: 5| Step: 1
Training loss: 1.406249761581421
Validation loss: 2.1835117489099503

Epoch: 5| Step: 2
Training loss: 1.512751817703247
Validation loss: 2.2327235341072083

Epoch: 5| Step: 3
Training loss: 1.4020496606826782
Validation loss: 2.2001354843378067

Epoch: 5| Step: 4
Training loss: 1.2796344757080078
Validation loss: 2.2337314784526825

Epoch: 5| Step: 5
Training loss: 1.9526140689849854
Validation loss: 2.2072756787141166

Epoch: 5| Step: 6
Training loss: 2.079439640045166
Validation loss: 2.207708934942881

Epoch: 5| Step: 7
Training loss: 1.2014905214309692
Validation loss: 2.1770443320274353

Epoch: 5| Step: 8
Training loss: 2.203734874725342
Validation loss: 2.1872999320427575

Epoch: 5| Step: 9
Training loss: 1.2541124820709229
Validation loss: 2.1808959345022836

Epoch: 5| Step: 10
Training loss: 1.5399599075317383
Validation loss: 2.204016630848249

Epoch: 5| Step: 11
Training loss: 0.761023998260498
Validation loss: 2.228756586710612

Epoch: 330| Step: 0
Training loss: 1.1023485660552979
Validation loss: 2.2323598911364875

Epoch: 5| Step: 1
Training loss: 1.3423341512680054
Validation loss: 2.249176253875097

Epoch: 5| Step: 2
Training loss: 1.733269453048706
Validation loss: 2.246315230925878

Epoch: 5| Step: 3
Training loss: 1.6587241888046265
Validation loss: 2.2759039302666983

Epoch: 5| Step: 4
Training loss: 1.740755319595337
Validation loss: 2.251641889413198

Epoch: 5| Step: 5
Training loss: 1.4275602102279663
Validation loss: 2.2656621436278024

Epoch: 5| Step: 6
Training loss: 1.300213098526001
Validation loss: 2.2383276323477426

Epoch: 5| Step: 7
Training loss: 1.6493943929672241
Validation loss: 2.234991431236267

Epoch: 5| Step: 8
Training loss: 1.1948400735855103
Validation loss: 2.2186046640078225

Epoch: 5| Step: 9
Training loss: 1.739487886428833
Validation loss: 2.2202538698911667

Epoch: 5| Step: 10
Training loss: 1.2302610874176025
Validation loss: 2.1917514701684317

Epoch: 5| Step: 11
Training loss: 1.103642225265503
Validation loss: 2.202177882194519

Epoch: 331| Step: 0
Training loss: 1.5014941692352295
Validation loss: 2.2063152492046356

Epoch: 5| Step: 1
Training loss: 1.515698790550232
Validation loss: 2.229745075106621

Epoch: 5| Step: 2
Training loss: 1.5266616344451904
Validation loss: 2.228111763795217

Epoch: 5| Step: 3
Training loss: 1.9822921752929688
Validation loss: 2.2321693003177643

Epoch: 5| Step: 4
Training loss: 1.3586128950119019
Validation loss: 2.2215876082579293

Epoch: 5| Step: 5
Training loss: 1.633420705795288
Validation loss: 2.2215405106544495

Epoch: 5| Step: 6
Training loss: 1.243290662765503
Validation loss: 2.238150825103124

Epoch: 5| Step: 7
Training loss: 1.2124353647232056
Validation loss: 2.2580637633800507

Epoch: 5| Step: 8
Training loss: 1.9077222347259521
Validation loss: 2.2766490976015725

Epoch: 5| Step: 9
Training loss: 1.7714658975601196
Validation loss: 2.2880260050296783

Epoch: 5| Step: 10
Training loss: 1.5241254568099976
Validation loss: 2.2666465739409127

Epoch: 5| Step: 11
Training loss: 1.6005085706710815
Validation loss: 2.2545089771350226

Epoch: 332| Step: 0
Training loss: 1.177264928817749
Validation loss: 2.2713675051927567

Epoch: 5| Step: 1
Training loss: 1.674759864807129
Validation loss: 2.2621259291966758

Epoch: 5| Step: 2
Training loss: 1.4723503589630127
Validation loss: 2.2543187737464905

Epoch: 5| Step: 3
Training loss: 1.0641443729400635
Validation loss: 2.2526462425788245

Epoch: 5| Step: 4
Training loss: 1.4019060134887695
Validation loss: 2.2583206494649253

Epoch: 5| Step: 5
Training loss: 2.328237533569336
Validation loss: 2.2408946504195533

Epoch: 5| Step: 6
Training loss: 1.4175922870635986
Validation loss: 2.2391854524612427

Epoch: 5| Step: 7
Training loss: 1.5853281021118164
Validation loss: 2.233135998249054

Epoch: 5| Step: 8
Training loss: 1.6719783544540405
Validation loss: 2.269340837995211

Epoch: 5| Step: 9
Training loss: 2.1138758659362793
Validation loss: 2.235662559668223

Epoch: 5| Step: 10
Training loss: 1.6373313665390015
Validation loss: 2.2450428704420724

Epoch: 5| Step: 11
Training loss: 1.3750879764556885
Validation loss: 2.260624756415685

Epoch: 333| Step: 0
Training loss: 2.3807578086853027
Validation loss: 2.300502190987269

Epoch: 5| Step: 1
Training loss: 1.4605414867401123
Validation loss: 2.3076763649781546

Epoch: 5| Step: 2
Training loss: 1.2677321434020996
Validation loss: 2.2698254783948264

Epoch: 5| Step: 3
Training loss: 1.8826143741607666
Validation loss: 2.26469095547994

Epoch: 5| Step: 4
Training loss: 1.5898115634918213
Validation loss: 2.2573625346024833

Epoch: 5| Step: 5
Training loss: 1.4390548467636108
Validation loss: 2.2565414806207023

Epoch: 5| Step: 6
Training loss: 1.3709725141525269
Validation loss: 2.232124318679174

Epoch: 5| Step: 7
Training loss: 1.1517257690429688
Validation loss: 2.216418152054151

Epoch: 5| Step: 8
Training loss: 1.5097578763961792
Validation loss: 2.2014468163251877

Epoch: 5| Step: 9
Training loss: 2.2635703086853027
Validation loss: 2.2066828111807504

Epoch: 5| Step: 10
Training loss: 1.0728038549423218
Validation loss: 2.1969008445739746

Epoch: 5| Step: 11
Training loss: 1.1973953247070312
Validation loss: 2.1938595473766327

Epoch: 334| Step: 0
Training loss: 2.008218288421631
Validation loss: 2.192748794953028

Epoch: 5| Step: 1
Training loss: 1.5781123638153076
Validation loss: 2.190425659219424

Epoch: 5| Step: 2
Training loss: 1.5527206659317017
Validation loss: 2.1693179408709207

Epoch: 5| Step: 3
Training loss: 1.591033697128296
Validation loss: 2.1765345384677253

Epoch: 5| Step: 4
Training loss: 1.6767568588256836
Validation loss: 2.1694945842027664

Epoch: 5| Step: 5
Training loss: 1.218281865119934
Validation loss: 2.1871756513913474

Epoch: 5| Step: 6
Training loss: 1.274638295173645
Validation loss: 2.165767123301824

Epoch: 5| Step: 7
Training loss: 1.7749042510986328
Validation loss: 2.1486265858014426

Epoch: 5| Step: 8
Training loss: 1.9677305221557617
Validation loss: 2.1897378067175546

Epoch: 5| Step: 9
Training loss: 1.2848516702651978
Validation loss: 2.1771115958690643

Epoch: 5| Step: 10
Training loss: 1.4038141965866089
Validation loss: 2.1852879325548806

Epoch: 5| Step: 11
Training loss: 1.1602792739868164
Validation loss: 2.1702505151430764

Epoch: 335| Step: 0
Training loss: 1.0245250463485718
Validation loss: 2.2224721560875573

Epoch: 5| Step: 1
Training loss: 1.3214309215545654
Validation loss: 2.1881364484628043

Epoch: 5| Step: 2
Training loss: 1.2273225784301758
Validation loss: 2.2207446644703546

Epoch: 5| Step: 3
Training loss: 1.72372305393219
Validation loss: 2.222212960322698

Epoch: 5| Step: 4
Training loss: 0.6130154728889465
Validation loss: 2.2211119532585144

Epoch: 5| Step: 5
Training loss: 1.4335715770721436
Validation loss: 2.242542107899984

Epoch: 5| Step: 6
Training loss: 2.3936824798583984
Validation loss: 2.2529264440139136

Epoch: 5| Step: 7
Training loss: 1.3881374597549438
Validation loss: 2.262371445695559

Epoch: 5| Step: 8
Training loss: 1.2542617321014404
Validation loss: 2.250428100426992

Epoch: 5| Step: 9
Training loss: 1.2756261825561523
Validation loss: 2.2761019517978034

Epoch: 5| Step: 10
Training loss: 1.9154294729232788
Validation loss: 2.23368505636851

Epoch: 5| Step: 11
Training loss: 1.8839004039764404
Validation loss: 2.2514925748109818

Epoch: 336| Step: 0
Training loss: 1.698167085647583
Validation loss: 2.2524337669213614

Epoch: 5| Step: 1
Training loss: 1.6487607955932617
Validation loss: 2.271484211087227

Epoch: 5| Step: 2
Training loss: 1.4027040004730225
Validation loss: 2.239032283425331

Epoch: 5| Step: 3
Training loss: 0.7137213945388794
Validation loss: 2.236004243294398

Epoch: 5| Step: 4
Training loss: 1.4669971466064453
Validation loss: 2.2515226105848947

Epoch: 5| Step: 5
Training loss: 1.1936947107315063
Validation loss: 2.2403726975123086

Epoch: 5| Step: 6
Training loss: 1.6973774433135986
Validation loss: 2.2187773833672204

Epoch: 5| Step: 7
Training loss: 1.3142948150634766
Validation loss: 2.2451120962699256

Epoch: 5| Step: 8
Training loss: 1.7662731409072876
Validation loss: 2.2383432934681573

Epoch: 5| Step: 9
Training loss: 1.0403732061386108
Validation loss: 2.281294360756874

Epoch: 5| Step: 10
Training loss: 1.7698615789413452
Validation loss: 2.2831651320060096

Epoch: 5| Step: 11
Training loss: 0.8363592028617859
Validation loss: 2.255723978082339

Epoch: 337| Step: 0
Training loss: 1.9592077732086182
Validation loss: 2.2962989012400308

Epoch: 5| Step: 1
Training loss: 0.9784142374992371
Validation loss: 2.3286663591861725

Epoch: 5| Step: 2
Training loss: 1.7497737407684326
Validation loss: 2.2677344580491385

Epoch: 5| Step: 3
Training loss: 1.6278455257415771
Validation loss: 2.2747556467851004

Epoch: 5| Step: 4
Training loss: 1.0563619136810303
Validation loss: 2.2750208377838135

Epoch: 5| Step: 5
Training loss: 1.5997816324234009
Validation loss: 2.2888293862342834

Epoch: 5| Step: 6
Training loss: 1.5855586528778076
Validation loss: 2.249494726459185

Epoch: 5| Step: 7
Training loss: 2.4734482765197754
Validation loss: 2.2462628235419593

Epoch: 5| Step: 8
Training loss: 1.2102134227752686
Validation loss: 2.2634695370992026

Epoch: 5| Step: 9
Training loss: 1.2314939498901367
Validation loss: 2.2520919690529504

Epoch: 5| Step: 10
Training loss: 1.1976306438446045
Validation loss: 2.2421210010846457

Epoch: 5| Step: 11
Training loss: 1.1771440505981445
Validation loss: 2.2651759535074234

Epoch: 338| Step: 0
Training loss: 0.9914342761039734
Validation loss: 2.2313216030597687

Epoch: 5| Step: 1
Training loss: 2.019932508468628
Validation loss: 2.237835645675659

Epoch: 5| Step: 2
Training loss: 1.115535020828247
Validation loss: 2.230207691589991

Epoch: 5| Step: 3
Training loss: 2.0680274963378906
Validation loss: 2.223440632224083

Epoch: 5| Step: 4
Training loss: 1.4984757900238037
Validation loss: 2.2390384674072266

Epoch: 5| Step: 5
Training loss: 1.5364701747894287
Validation loss: 2.2139212091763816

Epoch: 5| Step: 6
Training loss: 1.6464745998382568
Validation loss: 2.1912437031666436

Epoch: 5| Step: 7
Training loss: 1.4104760885238647
Validation loss: 2.2036206871271133

Epoch: 5| Step: 8
Training loss: 1.174882173538208
Validation loss: 2.183376202980677

Epoch: 5| Step: 9
Training loss: 0.9129664301872253
Validation loss: 2.210074265797933

Epoch: 5| Step: 10
Training loss: 1.8710428476333618
Validation loss: 2.2209054629007974

Epoch: 5| Step: 11
Training loss: 0.8665468692779541
Validation loss: 2.2039621074994407

Epoch: 339| Step: 0
Training loss: 0.8664814233779907
Validation loss: 2.2377713521321616

Epoch: 5| Step: 1
Training loss: 1.183119535446167
Validation loss: 2.2207400649785995

Epoch: 5| Step: 2
Training loss: 1.4283511638641357
Validation loss: 2.2125826627016068

Epoch: 5| Step: 3
Training loss: 1.7051408290863037
Validation loss: 2.23061403632164

Epoch: 5| Step: 4
Training loss: 2.0920791625976562
Validation loss: 2.233751813570658

Epoch: 5| Step: 5
Training loss: 1.5253326892852783
Validation loss: 2.222135161360105

Epoch: 5| Step: 6
Training loss: 1.850334882736206
Validation loss: 2.237388620773951

Epoch: 5| Step: 7
Training loss: 1.1346344947814941
Validation loss: 2.216238255302111

Epoch: 5| Step: 8
Training loss: 1.255354881286621
Validation loss: 2.2725677490234375

Epoch: 5| Step: 9
Training loss: 1.5593105554580688
Validation loss: 2.282869502902031

Epoch: 5| Step: 10
Training loss: 1.2649924755096436
Validation loss: 2.2963901857535043

Epoch: 5| Step: 11
Training loss: 2.306572914123535
Validation loss: 2.303708662589391

Epoch: 340| Step: 0
Training loss: 1.2625765800476074
Validation loss: 2.3054262350002923

Epoch: 5| Step: 1
Training loss: 1.3273379802703857
Validation loss: 2.344952235619227

Epoch: 5| Step: 2
Training loss: 1.6784741878509521
Validation loss: 2.2911457816759744

Epoch: 5| Step: 3
Training loss: 1.8081347942352295
Validation loss: 2.266691744327545

Epoch: 5| Step: 4
Training loss: 1.5071488618850708
Validation loss: 2.318268120288849

Epoch: 5| Step: 5
Training loss: 1.6183881759643555
Validation loss: 2.2593458741903305

Epoch: 5| Step: 6
Training loss: 1.3463407754898071
Validation loss: 2.2714759409427643

Epoch: 5| Step: 7
Training loss: 1.3260310888290405
Validation loss: 2.2910351753234863

Epoch: 5| Step: 8
Training loss: 0.9418386220932007
Validation loss: 2.2563746174176535

Epoch: 5| Step: 9
Training loss: 1.2694032192230225
Validation loss: 2.237586339314779

Epoch: 5| Step: 10
Training loss: 1.5242314338684082
Validation loss: 2.234882021943728

Epoch: 5| Step: 11
Training loss: 1.1922699213027954
Validation loss: 2.2285035848617554

Epoch: 341| Step: 0
Training loss: 1.3445091247558594
Validation loss: 2.2098917961120605

Epoch: 5| Step: 1
Training loss: 1.3841487169265747
Validation loss: 2.1845179994901023

Epoch: 5| Step: 2
Training loss: 1.4759198427200317
Validation loss: 2.2061171531677246

Epoch: 5| Step: 3
Training loss: 1.2532755136489868
Validation loss: 2.1959994981686273

Epoch: 5| Step: 4
Training loss: 1.8906326293945312
Validation loss: 2.193060060342153

Epoch: 5| Step: 5
Training loss: 2.057781934738159
Validation loss: 2.1979877750078836

Epoch: 5| Step: 6
Training loss: 1.6699107885360718
Validation loss: 2.1854521930217743

Epoch: 5| Step: 7
Training loss: 1.0902334451675415
Validation loss: 2.209932098786036

Epoch: 5| Step: 8
Training loss: 1.5142568349838257
Validation loss: 2.2029947141806283

Epoch: 5| Step: 9
Training loss: 1.119624376296997
Validation loss: 2.2082698941230774

Epoch: 5| Step: 10
Training loss: 1.2133337259292603
Validation loss: 2.197390447060267

Epoch: 5| Step: 11
Training loss: 1.356133222579956
Validation loss: 2.222352057695389

Epoch: 342| Step: 0
Training loss: 1.5654759407043457
Validation loss: 2.219929203391075

Epoch: 5| Step: 1
Training loss: 1.3179264068603516
Validation loss: 2.2209168871243796

Epoch: 5| Step: 2
Training loss: 1.554916262626648
Validation loss: 2.2435604631900787

Epoch: 5| Step: 3
Training loss: 0.9600256085395813
Validation loss: 2.22832823296388

Epoch: 5| Step: 4
Training loss: 0.9214143753051758
Validation loss: 2.2412756582101188

Epoch: 5| Step: 5
Training loss: 1.2941217422485352
Validation loss: 2.2482954959074655

Epoch: 5| Step: 6
Training loss: 1.7680232524871826
Validation loss: 2.2377556562423706

Epoch: 5| Step: 7
Training loss: 1.4810254573822021
Validation loss: 2.207385996977488

Epoch: 5| Step: 8
Training loss: 1.5711637735366821
Validation loss: 2.2088612218697867

Epoch: 5| Step: 9
Training loss: 1.468138337135315
Validation loss: 2.223093310991923

Epoch: 5| Step: 10
Training loss: 1.0709283351898193
Validation loss: 2.2297035406033197

Epoch: 5| Step: 11
Training loss: 3.4530982971191406
Validation loss: 2.2385216454664865

Epoch: 343| Step: 0
Training loss: 1.5167216062545776
Validation loss: 2.1786778966585794

Epoch: 5| Step: 1
Training loss: 0.7886113524436951
Validation loss: 2.181897595524788

Epoch: 5| Step: 2
Training loss: 1.1482758522033691
Validation loss: 2.2186109522978463

Epoch: 5| Step: 3
Training loss: 1.8074833154678345
Validation loss: 2.1952421317497888

Epoch: 5| Step: 4
Training loss: 1.3607213497161865
Validation loss: 2.208331892887751

Epoch: 5| Step: 5
Training loss: 1.6643203496932983
Validation loss: 2.23489718635877

Epoch: 5| Step: 6
Training loss: 1.1885172128677368
Validation loss: 2.182740569114685

Epoch: 5| Step: 7
Training loss: 1.7584282159805298
Validation loss: 2.207088922460874

Epoch: 5| Step: 8
Training loss: 1.3259996175765991
Validation loss: 2.1961296747128167

Epoch: 5| Step: 9
Training loss: 1.5331668853759766
Validation loss: 2.2110604345798492

Epoch: 5| Step: 10
Training loss: 1.6188678741455078
Validation loss: 2.2090778052806854

Epoch: 5| Step: 11
Training loss: 0.7582691311836243
Validation loss: 2.2033959925174713

Epoch: 344| Step: 0
Training loss: 1.7647937536239624
Validation loss: 2.183362210790316

Epoch: 5| Step: 1
Training loss: 0.8429617881774902
Validation loss: 2.1771415124336877

Epoch: 5| Step: 2
Training loss: 1.3392902612686157
Validation loss: 2.1730746924877167

Epoch: 5| Step: 3
Training loss: 1.3137894868850708
Validation loss: 2.184407740831375

Epoch: 5| Step: 4
Training loss: 0.9499760866165161
Validation loss: 2.212115839123726

Epoch: 5| Step: 5
Training loss: 1.909937858581543
Validation loss: 2.218043178319931

Epoch: 5| Step: 6
Training loss: 1.1899135112762451
Validation loss: 2.188709413011869

Epoch: 5| Step: 7
Training loss: 2.086524248123169
Validation loss: 2.193342169125875

Epoch: 5| Step: 8
Training loss: 1.4451570510864258
Validation loss: 2.199184015393257

Epoch: 5| Step: 9
Training loss: 1.4619829654693604
Validation loss: 2.1969944636027017

Epoch: 5| Step: 10
Training loss: 1.1971278190612793
Validation loss: 2.236225883165995

Epoch: 5| Step: 11
Training loss: 1.1191877126693726
Validation loss: 2.1952495078245797

Epoch: 345| Step: 0
Training loss: 1.553231954574585
Validation loss: 2.259214679400126

Epoch: 5| Step: 1
Training loss: 1.2675361633300781
Validation loss: 2.255694419145584

Epoch: 5| Step: 2
Training loss: 1.0971461534500122
Validation loss: 2.2536531537771225

Epoch: 5| Step: 3
Training loss: 1.6553542613983154
Validation loss: 2.248373900850614

Epoch: 5| Step: 4
Training loss: 1.0788699388504028
Validation loss: 2.244597057501475

Epoch: 5| Step: 5
Training loss: 1.6534255743026733
Validation loss: 2.2083533108234406

Epoch: 5| Step: 6
Training loss: 1.1109281778335571
Validation loss: 2.267168954014778

Epoch: 5| Step: 7
Training loss: 1.315787434577942
Validation loss: 2.2090550710757575

Epoch: 5| Step: 8
Training loss: 1.3804504871368408
Validation loss: 2.2652378231287003

Epoch: 5| Step: 9
Training loss: 1.7526285648345947
Validation loss: 2.1980129927396774

Epoch: 5| Step: 10
Training loss: 1.683156967163086
Validation loss: 2.18920606871446

Epoch: 5| Step: 11
Training loss: 1.0121302604675293
Validation loss: 2.2109624395767846

Epoch: 346| Step: 0
Training loss: 0.8509324789047241
Validation loss: 2.192231555779775

Epoch: 5| Step: 1
Training loss: 1.6396087408065796
Validation loss: 2.1939220130443573

Epoch: 5| Step: 2
Training loss: 1.1105891466140747
Validation loss: 2.1625719467798867

Epoch: 5| Step: 3
Training loss: 1.7272512912750244
Validation loss: 2.223091423511505

Epoch: 5| Step: 4
Training loss: 1.443597674369812
Validation loss: 2.1863584915796914

Epoch: 5| Step: 5
Training loss: 1.2356388568878174
Validation loss: 2.193056503931681

Epoch: 5| Step: 6
Training loss: 1.4856284856796265
Validation loss: 2.2096164176861444

Epoch: 5| Step: 7
Training loss: 1.3636713027954102
Validation loss: 2.2082253197828927

Epoch: 5| Step: 8
Training loss: 1.071728229522705
Validation loss: 2.2269563376903534

Epoch: 5| Step: 9
Training loss: 1.5199956893920898
Validation loss: 2.228111187616984

Epoch: 5| Step: 10
Training loss: 1.8558504581451416
Validation loss: 2.2273527334133782

Epoch: 5| Step: 11
Training loss: 1.8462679386138916
Validation loss: 2.236234337091446

Epoch: 347| Step: 0
Training loss: 2.117255449295044
Validation loss: 2.2301778197288513

Epoch: 5| Step: 1
Training loss: 1.698449730873108
Validation loss: 2.2309613029162088

Epoch: 5| Step: 2
Training loss: 1.275848150253296
Validation loss: 2.22953699529171

Epoch: 5| Step: 3
Training loss: 1.3248475790023804
Validation loss: 2.1972117125988007

Epoch: 5| Step: 4
Training loss: 1.514397144317627
Validation loss: 2.197350397706032

Epoch: 5| Step: 5
Training loss: 1.2599210739135742
Validation loss: 2.2097099920113883

Epoch: 5| Step: 6
Training loss: 1.1929126977920532
Validation loss: 2.191344608863195

Epoch: 5| Step: 7
Training loss: 1.2253913879394531
Validation loss: 2.215217560529709

Epoch: 5| Step: 8
Training loss: 1.49544095993042
Validation loss: 2.2125129401683807

Epoch: 5| Step: 9
Training loss: 1.1226056814193726
Validation loss: 2.2044006486733756

Epoch: 5| Step: 10
Training loss: 1.2041099071502686
Validation loss: 2.2269867211580276

Epoch: 5| Step: 11
Training loss: 0.8884391784667969
Validation loss: 2.215770756204923

Epoch: 348| Step: 0
Training loss: 1.0720704793930054
Validation loss: 2.1919522086779275

Epoch: 5| Step: 1
Training loss: 1.2835910320281982
Validation loss: 2.1984692364931107

Epoch: 5| Step: 2
Training loss: 1.6552845239639282
Validation loss: 2.1960056175788245

Epoch: 5| Step: 3
Training loss: 1.3444242477416992
Validation loss: 2.2538613279660544

Epoch: 5| Step: 4
Training loss: 1.4229296445846558
Validation loss: 2.181211362282435

Epoch: 5| Step: 5
Training loss: 1.5923192501068115
Validation loss: 2.2310836017131805

Epoch: 5| Step: 6
Training loss: 1.7955347299575806
Validation loss: 2.2216621736685433

Epoch: 5| Step: 7
Training loss: 0.8005452156066895
Validation loss: 2.243656704823176

Epoch: 5| Step: 8
Training loss: 1.3576298952102661
Validation loss: 2.2881421595811844

Epoch: 5| Step: 9
Training loss: 1.066445231437683
Validation loss: 2.2292444556951523

Epoch: 5| Step: 10
Training loss: 2.2886016368865967
Validation loss: 2.2447244922320047

Epoch: 5| Step: 11
Training loss: 0.8137129545211792
Validation loss: 2.2756212949752808

Epoch: 349| Step: 0
Training loss: 1.091845154762268
Validation loss: 2.287847399711609

Epoch: 5| Step: 1
Training loss: 1.3910517692565918
Validation loss: 2.230279564857483

Epoch: 5| Step: 2
Training loss: 1.1645512580871582
Validation loss: 2.220673362414042

Epoch: 5| Step: 3
Training loss: 1.0988986492156982
Validation loss: 2.2177588840325675

Epoch: 5| Step: 4
Training loss: 1.4171454906463623
Validation loss: 2.202229142189026

Epoch: 5| Step: 5
Training loss: 1.3713221549987793
Validation loss: 2.1972726732492447

Epoch: 5| Step: 6
Training loss: 2.3191466331481934
Validation loss: 2.178097744782766

Epoch: 5| Step: 7
Training loss: 1.5491619110107422
Validation loss: 2.1707229912281036

Epoch: 5| Step: 8
Training loss: 1.213688611984253
Validation loss: 2.1844422966241837

Epoch: 5| Step: 9
Training loss: 1.428367257118225
Validation loss: 2.194768249988556

Epoch: 5| Step: 10
Training loss: 1.1393288373947144
Validation loss: 2.203402062257131

Epoch: 5| Step: 11
Training loss: 1.0191030502319336
Validation loss: 2.1983616103728614

Epoch: 350| Step: 0
Training loss: 1.3788812160491943
Validation loss: 2.1969674080610275

Epoch: 5| Step: 1
Training loss: 1.5567275285720825
Validation loss: 2.1852415104707084

Epoch: 5| Step: 2
Training loss: 1.8874824047088623
Validation loss: 2.2120759934186935

Epoch: 5| Step: 3
Training loss: 1.9893608093261719
Validation loss: 2.152222494284312

Epoch: 5| Step: 4
Training loss: 1.853727102279663
Validation loss: 2.195777485768

Epoch: 5| Step: 5
Training loss: 1.0759036540985107
Validation loss: 2.1985138853391013

Epoch: 5| Step: 6
Training loss: 1.0749143362045288
Validation loss: 2.2065171202023826

Epoch: 5| Step: 7
Training loss: 1.301626443862915
Validation loss: 2.253338853518168

Epoch: 5| Step: 8
Training loss: 1.094476580619812
Validation loss: 2.2728753636280694

Epoch: 5| Step: 9
Training loss: 1.1915123462677002
Validation loss: 2.2538293600082397

Epoch: 5| Step: 10
Training loss: 1.1955863237380981
Validation loss: 2.260870094100634

Epoch: 5| Step: 11
Training loss: 1.1565287113189697
Validation loss: 2.2827509194612503

Testing loss: 2.093061669267339
