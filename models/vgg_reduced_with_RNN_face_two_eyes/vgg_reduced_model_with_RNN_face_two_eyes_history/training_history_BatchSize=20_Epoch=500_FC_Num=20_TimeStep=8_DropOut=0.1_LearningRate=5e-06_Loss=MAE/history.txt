Epoch: 1| Step: 0
Training loss: 4.915444850921631
Validation loss: 5.256240745385488

Epoch: 5| Step: 1
Training loss: 5.798005104064941
Validation loss: 5.254270672798157

Epoch: 5| Step: 2
Training loss: 5.655905723571777
Validation loss: 5.252443770567576

Epoch: 5| Step: 3
Training loss: 6.073887825012207
Validation loss: 5.250564535458882

Epoch: 5| Step: 4
Training loss: 5.532408237457275
Validation loss: 5.248799403508504

Epoch: 5| Step: 5
Training loss: 4.665287971496582
Validation loss: 5.247042218844096

Epoch: 5| Step: 6
Training loss: 5.934084892272949
Validation loss: 5.245192348957062

Epoch: 5| Step: 7
Training loss: 4.927159309387207
Validation loss: 5.2434602578481035

Epoch: 5| Step: 8
Training loss: 5.48516321182251
Validation loss: 5.241685310999553

Epoch: 5| Step: 9
Training loss: 5.663455009460449
Validation loss: 5.239827036857605

Epoch: 5| Step: 10
Training loss: 4.1664018630981445
Validation loss: 5.237885256608327

Epoch: 5| Step: 11
Training loss: 3.6260859966278076
Validation loss: 5.235973993937175

Epoch: 2| Step: 0
Training loss: 5.456105709075928
Validation loss: 5.233962555726369

Epoch: 5| Step: 1
Training loss: 6.053424835205078
Validation loss: 5.231926004091899

Epoch: 5| Step: 2
Training loss: 5.1654229164123535
Validation loss: 5.229749818642934

Epoch: 5| Step: 3
Training loss: 5.638546943664551
Validation loss: 5.227455019950867

Epoch: 5| Step: 4
Training loss: 4.392840385437012
Validation loss: 5.225099364916484

Epoch: 5| Step: 5
Training loss: 4.745751857757568
Validation loss: 5.222578863302867

Epoch: 5| Step: 6
Training loss: 5.4831862449646
Validation loss: 5.220154881477356

Epoch: 5| Step: 7
Training loss: 5.589762210845947
Validation loss: 5.21739540497462

Epoch: 5| Step: 8
Training loss: 4.733155727386475
Validation loss: 5.214660406112671

Epoch: 5| Step: 9
Training loss: 5.6831769943237305
Validation loss: 5.211639553308487

Epoch: 5| Step: 10
Training loss: 5.147724151611328
Validation loss: 5.208697597185771

Epoch: 5| Step: 11
Training loss: 5.905552387237549
Validation loss: 5.205306887626648

Epoch: 3| Step: 0
Training loss: 5.859768867492676
Validation loss: 5.202119588851929

Epoch: 5| Step: 1
Training loss: 5.085994720458984
Validation loss: 5.19849693775177

Epoch: 5| Step: 2
Training loss: 4.798536777496338
Validation loss: 5.194869081179301

Epoch: 5| Step: 3
Training loss: 3.7858147621154785
Validation loss: 5.191096365451813

Epoch: 5| Step: 4
Training loss: 5.085506439208984
Validation loss: 5.187023123105367

Epoch: 5| Step: 5
Training loss: 4.185582637786865
Validation loss: 5.182908833026886

Epoch: 5| Step: 6
Training loss: 5.813004493713379
Validation loss: 5.1785957018534345

Epoch: 5| Step: 7
Training loss: 5.798247814178467
Validation loss: 5.174048503239949

Epoch: 5| Step: 8
Training loss: 6.342042446136475
Validation loss: 5.169191201527913

Epoch: 5| Step: 9
Training loss: 5.803749084472656
Validation loss: 5.164178311824799

Epoch: 5| Step: 10
Training loss: 5.1079206466674805
Validation loss: 5.159070253372192

Epoch: 5| Step: 11
Training loss: 5.806067943572998
Validation loss: 5.153612454732259

Epoch: 4| Step: 0
Training loss: 5.193110466003418
Validation loss: 5.147806306680043

Epoch: 5| Step: 1
Training loss: 5.21455717086792
Validation loss: 5.142148375511169

Epoch: 5| Step: 2
Training loss: 4.853421688079834
Validation loss: 5.136072377363841

Epoch: 5| Step: 3
Training loss: 5.190644264221191
Validation loss: 5.129915157953898

Epoch: 5| Step: 4
Training loss: 4.632132530212402
Validation loss: 5.123442510763804

Epoch: 5| Step: 5
Training loss: 5.469071388244629
Validation loss: 5.1167775591214495

Epoch: 5| Step: 6
Training loss: 4.443540096282959
Validation loss: 5.109992881615956

Epoch: 5| Step: 7
Training loss: 4.804129123687744
Validation loss: 5.102782706419627

Epoch: 5| Step: 8
Training loss: 5.439940452575684
Validation loss: 5.095539569854736

Epoch: 5| Step: 9
Training loss: 5.97028923034668
Validation loss: 5.087795356909434

Epoch: 5| Step: 10
Training loss: 6.275460720062256
Validation loss: 5.079998433589935

Epoch: 5| Step: 11
Training loss: 3.0885157585144043
Validation loss: 5.072117308775584

Epoch: 5| Step: 0
Training loss: 5.1519670486450195
Validation loss: 5.063612580299377

Epoch: 5| Step: 1
Training loss: 5.216697692871094
Validation loss: 5.055261154969533

Epoch: 5| Step: 2
Training loss: 5.078049659729004
Validation loss: 5.046537439028422

Epoch: 5| Step: 3
Training loss: 5.889425754547119
Validation loss: 5.038139859835307

Epoch: 5| Step: 4
Training loss: 5.619415760040283
Validation loss: 5.029218216737111

Epoch: 5| Step: 5
Training loss: 4.9624738693237305
Validation loss: 5.020281255245209

Epoch: 5| Step: 6
Training loss: 4.7344651222229
Validation loss: 5.011407474676768

Epoch: 5| Step: 7
Training loss: 4.049843788146973
Validation loss: 5.002333283424377

Epoch: 5| Step: 8
Training loss: 6.137667655944824
Validation loss: 4.993210633595784

Epoch: 5| Step: 9
Training loss: 4.525897026062012
Validation loss: 4.983976354201634

Epoch: 5| Step: 10
Training loss: 4.33035135269165
Validation loss: 4.97474588950475

Epoch: 5| Step: 11
Training loss: 7.000575065612793
Validation loss: 4.965691844622294

Epoch: 6| Step: 0
Training loss: 4.922708034515381
Validation loss: 4.956103344758351

Epoch: 5| Step: 1
Training loss: 5.500149250030518
Validation loss: 4.946784277757009

Epoch: 5| Step: 2
Training loss: 4.881612300872803
Validation loss: 4.937286555767059

Epoch: 5| Step: 3
Training loss: 5.010195255279541
Validation loss: 4.927930235862732

Epoch: 5| Step: 4
Training loss: 3.996969223022461
Validation loss: 4.9182727336883545

Epoch: 5| Step: 5
Training loss: 5.367646217346191
Validation loss: 4.909214059511821

Epoch: 5| Step: 6
Training loss: 4.963831901550293
Validation loss: 4.899783531824748

Epoch: 5| Step: 7
Training loss: 5.593870639801025
Validation loss: 4.890265802542369

Epoch: 5| Step: 8
Training loss: 5.356368064880371
Validation loss: 4.881284773349762

Epoch: 5| Step: 9
Training loss: 5.631820201873779
Validation loss: 4.871773014465968

Epoch: 5| Step: 10
Training loss: 3.916358470916748
Validation loss: 4.862754225730896

Epoch: 5| Step: 11
Training loss: 3.935922384262085
Validation loss: 4.854042907555898

Epoch: 7| Step: 0
Training loss: 4.520786285400391
Validation loss: 4.844485819339752

Epoch: 5| Step: 1
Training loss: 4.743884086608887
Validation loss: 4.8361169795195265

Epoch: 5| Step: 2
Training loss: 4.91622257232666
Validation loss: 4.827525516351064

Epoch: 5| Step: 3
Training loss: 4.856348991394043
Validation loss: 4.819113850593567

Epoch: 5| Step: 4
Training loss: 4.716124534606934
Validation loss: 4.810516387224197

Epoch: 5| Step: 5
Training loss: 4.4386115074157715
Validation loss: 4.801744709412257

Epoch: 5| Step: 6
Training loss: 5.942188262939453
Validation loss: 4.793619056542714

Epoch: 5| Step: 7
Training loss: 5.352224826812744
Validation loss: 4.785396496454875

Epoch: 5| Step: 8
Training loss: 4.643718719482422
Validation loss: 4.777196526527405

Epoch: 5| Step: 9
Training loss: 4.414912700653076
Validation loss: 4.768617689609528

Epoch: 5| Step: 10
Training loss: 4.862811088562012
Validation loss: 4.7603492339452105

Epoch: 5| Step: 11
Training loss: 6.814703941345215
Validation loss: 4.751793911059697

Epoch: 8| Step: 0
Training loss: 4.003592491149902
Validation loss: 4.743567983309428

Epoch: 5| Step: 1
Training loss: 4.8920674324035645
Validation loss: 4.7353005309899645

Epoch: 5| Step: 2
Training loss: 4.343859672546387
Validation loss: 4.727282991011937

Epoch: 5| Step: 3
Training loss: 5.096000671386719
Validation loss: 4.719289799531301

Epoch: 5| Step: 4
Training loss: 5.570082664489746
Validation loss: 4.711192806561788

Epoch: 5| Step: 5
Training loss: 4.598316192626953
Validation loss: 4.703522503376007

Epoch: 5| Step: 6
Training loss: 5.307188987731934
Validation loss: 4.695825199286143

Epoch: 5| Step: 7
Training loss: 4.976757049560547
Validation loss: 4.68809727827708

Epoch: 5| Step: 8
Training loss: 4.896897792816162
Validation loss: 4.680243452390035

Epoch: 5| Step: 9
Training loss: 4.7860260009765625
Validation loss: 4.67285829782486

Epoch: 5| Step: 10
Training loss: 4.513550281524658
Validation loss: 4.665204048156738

Epoch: 5| Step: 11
Training loss: 3.7444872856140137
Validation loss: 4.657972474892934

Epoch: 9| Step: 0
Training loss: 4.755439758300781
Validation loss: 4.650839269161224

Epoch: 5| Step: 1
Training loss: 5.3687052726745605
Validation loss: 4.64387575785319

Epoch: 5| Step: 2
Training loss: 3.7944693565368652
Validation loss: 4.63738810022672

Epoch: 5| Step: 3
Training loss: 3.3204128742218018
Validation loss: 4.630531092484792

Epoch: 5| Step: 4
Training loss: 4.523954391479492
Validation loss: 4.623826245466868

Epoch: 5| Step: 5
Training loss: 6.2006940841674805
Validation loss: 4.617384672164917

Epoch: 5| Step: 6
Training loss: 5.0035080909729
Validation loss: 4.611035446325938

Epoch: 5| Step: 7
Training loss: 4.438115119934082
Validation loss: 4.604452113310496

Epoch: 5| Step: 8
Training loss: 5.052548885345459
Validation loss: 4.597917477289836

Epoch: 5| Step: 9
Training loss: 4.553143501281738
Validation loss: 4.591723461945851

Epoch: 5| Step: 10
Training loss: 4.831794261932373
Validation loss: 4.585371990998586

Epoch: 5| Step: 11
Training loss: 4.856599807739258
Validation loss: 4.578816652297974

Epoch: 10| Step: 0
Training loss: 4.083930492401123
Validation loss: 4.5729101697603864

Epoch: 5| Step: 1
Training loss: 4.456770896911621
Validation loss: 4.566644589106242

Epoch: 5| Step: 2
Training loss: 4.751836776733398
Validation loss: 4.560364782810211

Epoch: 5| Step: 3
Training loss: 5.512982368469238
Validation loss: 4.553924202919006

Epoch: 5| Step: 4
Training loss: 4.466753959655762
Validation loss: 4.547822127739589

Epoch: 5| Step: 5
Training loss: 4.643331527709961
Validation loss: 4.541319936513901

Epoch: 5| Step: 6
Training loss: 5.046578884124756
Validation loss: 4.534531474113464

Epoch: 5| Step: 7
Training loss: 4.719396591186523
Validation loss: 4.528204361597697

Epoch: 5| Step: 8
Training loss: 4.710515022277832
Validation loss: 4.521710276603699

Epoch: 5| Step: 9
Training loss: 4.562313079833984
Validation loss: 4.514983087778091

Epoch: 5| Step: 10
Training loss: 4.200045108795166
Validation loss: 4.508484264214833

Epoch: 5| Step: 11
Training loss: 4.320460796356201
Validation loss: 4.5016060670216875

Epoch: 11| Step: 0
Training loss: 4.879217147827148
Validation loss: 4.495197693506877

Epoch: 5| Step: 1
Training loss: 3.976562976837158
Validation loss: 4.4886117080847425

Epoch: 5| Step: 2
Training loss: 4.485065460205078
Validation loss: 4.482050319512685

Epoch: 5| Step: 3
Training loss: 4.758202075958252
Validation loss: 4.475829243659973

Epoch: 5| Step: 4
Training loss: 4.7200093269348145
Validation loss: 4.469160993893941

Epoch: 5| Step: 5
Training loss: 4.896993160247803
Validation loss: 4.462834517161052

Epoch: 5| Step: 6
Training loss: 4.204586982727051
Validation loss: 4.457034051418304

Epoch: 5| Step: 7
Training loss: 4.8430328369140625
Validation loss: 4.451219191153844

Epoch: 5| Step: 8
Training loss: 4.820033073425293
Validation loss: 4.445462107658386

Epoch: 5| Step: 9
Training loss: 4.007596015930176
Validation loss: 4.4401222467422485

Epoch: 5| Step: 10
Training loss: 4.60450553894043
Validation loss: 4.434404790401459

Epoch: 5| Step: 11
Training loss: 5.215566158294678
Validation loss: 4.429019560416539

Epoch: 12| Step: 0
Training loss: 5.403532028198242
Validation loss: 4.423939963181813

Epoch: 5| Step: 1
Training loss: 4.286996841430664
Validation loss: 4.418994704882304

Epoch: 5| Step: 2
Training loss: 4.248067855834961
Validation loss: 4.413776745398839

Epoch: 5| Step: 3
Training loss: 4.401031494140625
Validation loss: 4.4088805715243025

Epoch: 5| Step: 4
Training loss: 3.867936372756958
Validation loss: 4.404140681028366

Epoch: 5| Step: 5
Training loss: 4.043023109436035
Validation loss: 4.399131973584493

Epoch: 5| Step: 6
Training loss: 3.8927109241485596
Validation loss: 4.394015351931254

Epoch: 5| Step: 7
Training loss: 5.444930076599121
Validation loss: 4.38926496108373

Epoch: 5| Step: 8
Training loss: 4.816078186035156
Validation loss: 4.384660641352336

Epoch: 5| Step: 9
Training loss: 3.986923933029175
Validation loss: 4.380006770292918

Epoch: 5| Step: 10
Training loss: 4.959710597991943
Validation loss: 4.375214397907257

Epoch: 5| Step: 11
Training loss: 6.159806728363037
Validation loss: 4.370439847310384

Epoch: 13| Step: 0
Training loss: 4.430542945861816
Validation loss: 4.36576920747757

Epoch: 5| Step: 1
Training loss: 3.9584903717041016
Validation loss: 4.361127217610677

Epoch: 5| Step: 2
Training loss: 5.519484519958496
Validation loss: 4.3567773302396136

Epoch: 5| Step: 3
Training loss: 4.8787522315979
Validation loss: 4.3516503771146136

Epoch: 5| Step: 4
Training loss: 3.8384461402893066
Validation loss: 4.346969842910767

Epoch: 5| Step: 5
Training loss: 4.168646335601807
Validation loss: 4.342484166224797

Epoch: 5| Step: 6
Training loss: 4.762936592102051
Validation loss: 4.337882936000824

Epoch: 5| Step: 7
Training loss: 4.222320556640625
Validation loss: 4.33339586853981

Epoch: 5| Step: 8
Training loss: 5.018935203552246
Validation loss: 4.328981727361679

Epoch: 5| Step: 9
Training loss: 3.711571455001831
Validation loss: 4.323945353428523

Epoch: 5| Step: 10
Training loss: 4.715985298156738
Validation loss: 4.319329053163528

Epoch: 5| Step: 11
Training loss: 3.8741836547851562
Validation loss: 4.314807673295339

Epoch: 14| Step: 0
Training loss: 3.9201436042785645
Validation loss: 4.31004845102628

Epoch: 5| Step: 1
Training loss: 4.538660049438477
Validation loss: 4.305341084798177

Epoch: 5| Step: 2
Training loss: 3.970238208770752
Validation loss: 4.300861885150273

Epoch: 5| Step: 3
Training loss: 4.9203057289123535
Validation loss: 4.296429435412089

Epoch: 5| Step: 4
Training loss: 4.3349456787109375
Validation loss: 4.291741847991943

Epoch: 5| Step: 5
Training loss: 4.140671730041504
Validation loss: 4.286895583073298

Epoch: 5| Step: 6
Training loss: 5.314277648925781
Validation loss: 4.282010932763417

Epoch: 5| Step: 7
Training loss: 4.193909645080566
Validation loss: 4.276937127113342

Epoch: 5| Step: 8
Training loss: 4.4148268699646
Validation loss: 4.272279292345047

Epoch: 5| Step: 9
Training loss: 4.789453506469727
Validation loss: 4.267341842254003

Epoch: 5| Step: 10
Training loss: 3.6516571044921875
Validation loss: 4.2624223828315735

Epoch: 5| Step: 11
Training loss: 6.108940124511719
Validation loss: 4.257642984390259

Epoch: 15| Step: 0
Training loss: 4.876112461090088
Validation loss: 4.253050446510315

Epoch: 5| Step: 1
Training loss: 4.3941330909729
Validation loss: 4.2477933665116625

Epoch: 5| Step: 2
Training loss: 4.376143932342529
Validation loss: 4.243374586105347

Epoch: 5| Step: 3
Training loss: 3.7093567848205566
Validation loss: 4.238282759984334

Epoch: 5| Step: 4
Training loss: 4.662106990814209
Validation loss: 4.233701437711716

Epoch: 5| Step: 5
Training loss: 4.249863624572754
Validation loss: 4.228418588638306

Epoch: 5| Step: 6
Training loss: 3.847266435623169
Validation loss: 4.223921676476796

Epoch: 5| Step: 7
Training loss: 4.279396057128906
Validation loss: 4.218375325202942

Epoch: 5| Step: 8
Training loss: 4.286409854888916
Validation loss: 4.213392972946167

Epoch: 5| Step: 9
Training loss: 5.162409782409668
Validation loss: 4.20829975605011

Epoch: 5| Step: 10
Training loss: 4.283016204833984
Validation loss: 4.202821999788284

Epoch: 5| Step: 11
Training loss: 3.424386739730835
Validation loss: 4.197969476381938

Epoch: 16| Step: 0
Training loss: 3.541273832321167
Validation loss: 4.193812777598699

Epoch: 5| Step: 1
Training loss: 4.654579162597656
Validation loss: 4.190188109874725

Epoch: 5| Step: 2
Training loss: 4.207184791564941
Validation loss: 4.18529627720515

Epoch: 5| Step: 3
Training loss: 5.071307182312012
Validation loss: 4.179394096136093

Epoch: 5| Step: 4
Training loss: 4.062560558319092
Validation loss: 4.175659666458766

Epoch: 5| Step: 5
Training loss: 4.203096866607666
Validation loss: 4.171142945686976

Epoch: 5| Step: 6
Training loss: 4.865562438964844
Validation loss: 4.165785213311513

Epoch: 5| Step: 7
Training loss: 4.219769477844238
Validation loss: 4.160417964061101

Epoch: 5| Step: 8
Training loss: 3.212242841720581
Validation loss: 4.155551006396611

Epoch: 5| Step: 9
Training loss: 4.686737060546875
Validation loss: 4.151536405086517

Epoch: 5| Step: 10
Training loss: 4.899035453796387
Validation loss: 4.1474297642707825

Epoch: 5| Step: 11
Training loss: 2.9894328117370605
Validation loss: 4.14177746574084

Epoch: 17| Step: 0
Training loss: 4.153046607971191
Validation loss: 4.136996845404307

Epoch: 5| Step: 1
Training loss: 4.3198161125183105
Validation loss: 4.132942308982213

Epoch: 5| Step: 2
Training loss: 4.888369560241699
Validation loss: 4.128433754046758

Epoch: 5| Step: 3
Training loss: 3.982097625732422
Validation loss: 4.123706221580505

Epoch: 5| Step: 4
Training loss: 4.244220733642578
Validation loss: 4.119415203730266

Epoch: 5| Step: 5
Training loss: 4.749422550201416
Validation loss: 4.114112168550491

Epoch: 5| Step: 6
Training loss: 3.5890259742736816
Validation loss: 4.109771321217219

Epoch: 5| Step: 7
Training loss: 3.962036609649658
Validation loss: 4.1051483651002245

Epoch: 5| Step: 8
Training loss: 4.157801628112793
Validation loss: 4.100343545277913

Epoch: 5| Step: 9
Training loss: 4.691715240478516
Validation loss: 4.096144636472066

Epoch: 5| Step: 10
Training loss: 4.216378211975098
Validation loss: 4.092188070217769

Epoch: 5| Step: 11
Training loss: 3.395881175994873
Validation loss: 4.08730360865593

Epoch: 18| Step: 0
Training loss: 4.421568870544434
Validation loss: 4.081078449885051

Epoch: 5| Step: 1
Training loss: 3.775390625
Validation loss: 4.078018357356389

Epoch: 5| Step: 2
Training loss: 4.362673282623291
Validation loss: 4.07504341006279

Epoch: 5| Step: 3
Training loss: 3.59169340133667
Validation loss: 4.0679678320884705

Epoch: 5| Step: 4
Training loss: 4.0006585121154785
Validation loss: 4.063136041164398

Epoch: 5| Step: 5
Training loss: 5.034018039703369
Validation loss: 4.059537649154663

Epoch: 5| Step: 6
Training loss: 4.7918195724487305
Validation loss: 4.056531598170598

Epoch: 5| Step: 7
Training loss: 4.169707298278809
Validation loss: 4.051187723875046

Epoch: 5| Step: 8
Training loss: 4.966354846954346
Validation loss: 4.046279807885488

Epoch: 5| Step: 9
Training loss: 3.8425326347351074
Validation loss: 4.040827949841817

Epoch: 5| Step: 10
Training loss: 3.8107516765594482
Validation loss: 4.03615356485049

Epoch: 5| Step: 11
Training loss: 1.521854281425476
Validation loss: 4.0328258872032166

Epoch: 19| Step: 0
Training loss: 4.5168890953063965
Validation loss: 4.028711905082067

Epoch: 5| Step: 1
Training loss: 5.046710014343262
Validation loss: 4.0250643491744995

Epoch: 5| Step: 2
Training loss: 2.946000576019287
Validation loss: 4.019755740960439

Epoch: 5| Step: 3
Training loss: 3.7656261920928955
Validation loss: 4.014388352632523

Epoch: 5| Step: 4
Training loss: 3.711212635040283
Validation loss: 4.010725190242131

Epoch: 5| Step: 5
Training loss: 3.905752658843994
Validation loss: 4.0071602662404375

Epoch: 5| Step: 6
Training loss: 4.728872776031494
Validation loss: 4.003973891337712

Epoch: 5| Step: 7
Training loss: 4.164754867553711
Validation loss: 3.9989118576049805

Epoch: 5| Step: 8
Training loss: 4.393789291381836
Validation loss: 3.994897186756134

Epoch: 5| Step: 9
Training loss: 3.6476101875305176
Validation loss: 3.988967478275299

Epoch: 5| Step: 10
Training loss: 4.3456854820251465
Validation loss: 3.9842954178651175

Epoch: 5| Step: 11
Training loss: 6.494103908538818
Validation loss: 3.9795659879843392

Epoch: 20| Step: 0
Training loss: 4.0991692543029785
Validation loss: 3.975454350312551

Epoch: 5| Step: 1
Training loss: 3.308074951171875
Validation loss: 3.9729575713475547

Epoch: 5| Step: 2
Training loss: 4.5395097732543945
Validation loss: 3.9682306746641793

Epoch: 5| Step: 3
Training loss: 4.59246301651001
Validation loss: 3.962702751159668

Epoch: 5| Step: 4
Training loss: 4.763543605804443
Validation loss: 3.9585464100042977

Epoch: 5| Step: 5
Training loss: 4.264108657836914
Validation loss: 3.954546948273977

Epoch: 5| Step: 6
Training loss: 4.5708208084106445
Validation loss: 3.949832151333491

Epoch: 5| Step: 7
Training loss: 3.9562714099884033
Validation loss: 3.9446689188480377

Epoch: 5| Step: 8
Training loss: 3.9381942749023438
Validation loss: 3.9407970209916434

Epoch: 5| Step: 9
Training loss: 3.1434736251831055
Validation loss: 3.935548355182012

Epoch: 5| Step: 10
Training loss: 4.452434539794922
Validation loss: 3.930488407611847

Epoch: 5| Step: 11
Training loss: 1.4749655723571777
Validation loss: 3.9255220691363015

Epoch: 21| Step: 0
Training loss: 3.647645950317383
Validation loss: 3.9211965600649514

Epoch: 5| Step: 1
Training loss: 3.894824266433716
Validation loss: 3.9164074261983237

Epoch: 5| Step: 2
Training loss: 4.163115501403809
Validation loss: 3.91219425201416

Epoch: 5| Step: 3
Training loss: 3.459172010421753
Validation loss: 3.9086360931396484

Epoch: 5| Step: 4
Training loss: 4.234071254730225
Validation loss: 3.904636720816294

Epoch: 5| Step: 5
Training loss: 3.7484183311462402
Validation loss: 3.8994447191556296

Epoch: 5| Step: 6
Training loss: 3.243967056274414
Validation loss: 3.894947121540705

Epoch: 5| Step: 7
Training loss: 4.384664058685303
Validation loss: 3.8909936944643655

Epoch: 5| Step: 8
Training loss: 4.373422145843506
Validation loss: 3.8867358465989432

Epoch: 5| Step: 9
Training loss: 4.381767272949219
Validation loss: 3.8832090298334756

Epoch: 5| Step: 10
Training loss: 4.545085430145264
Validation loss: 3.878870904445648

Epoch: 5| Step: 11
Training loss: 6.25311279296875
Validation loss: 3.8742649058500924

Epoch: 22| Step: 0
Training loss: 4.171304225921631
Validation loss: 3.8683814704418182

Epoch: 5| Step: 1
Training loss: 4.088693618774414
Validation loss: 3.8641677598158517

Epoch: 5| Step: 2
Training loss: 4.505674362182617
Validation loss: 3.8602866331736245

Epoch: 5| Step: 3
Training loss: 3.774829864501953
Validation loss: 3.856206695238749

Epoch: 5| Step: 4
Training loss: 4.154975891113281
Validation loss: 3.851511627435684

Epoch: 5| Step: 5
Training loss: 3.7669131755828857
Validation loss: 3.847255448500315

Epoch: 5| Step: 6
Training loss: 4.014528274536133
Validation loss: 3.842762072881063

Epoch: 5| Step: 7
Training loss: 4.471083164215088
Validation loss: 3.8372984329859414

Epoch: 5| Step: 8
Training loss: 4.252660751342773
Validation loss: 3.8328480422496796

Epoch: 5| Step: 9
Training loss: 3.704186201095581
Validation loss: 3.828540583451589

Epoch: 5| Step: 10
Training loss: 3.336383104324341
Validation loss: 3.8234357436498008

Epoch: 5| Step: 11
Training loss: 2.692617177963257
Validation loss: 3.818722049395243

Epoch: 23| Step: 0
Training loss: 3.6830177307128906
Validation loss: 3.8184891740481057

Epoch: 5| Step: 1
Training loss: 3.4533591270446777
Validation loss: 3.8107235928376517

Epoch: 5| Step: 2
Training loss: 4.293641090393066
Validation loss: 3.806449830532074

Epoch: 5| Step: 3
Training loss: 3.3990249633789062
Validation loss: 3.806724707285563

Epoch: 5| Step: 4
Training loss: 3.3426880836486816
Validation loss: 3.8065615197022757

Epoch: 5| Step: 5
Training loss: 4.423912048339844
Validation loss: 3.8008842368920646

Epoch: 5| Step: 6
Training loss: 3.5299854278564453
Validation loss: 3.79125123222669

Epoch: 5| Step: 7
Training loss: 3.6180083751678467
Validation loss: 3.7872154712677

Epoch: 5| Step: 8
Training loss: 4.022739887237549
Validation loss: 3.783629318078359

Epoch: 5| Step: 9
Training loss: 4.2001237869262695
Validation loss: 3.782260795434316

Epoch: 5| Step: 10
Training loss: 5.136716365814209
Validation loss: 3.776419152816137

Epoch: 5| Step: 11
Training loss: 5.787540912628174
Validation loss: 3.7717455327510834

Epoch: 24| Step: 0
Training loss: 3.3041114807128906
Validation loss: 3.7666309078534446

Epoch: 5| Step: 1
Training loss: 4.16770601272583
Validation loss: 3.7620520095030465

Epoch: 5| Step: 2
Training loss: 4.384793758392334
Validation loss: 3.757631262143453

Epoch: 5| Step: 3
Training loss: 3.028799533843994
Validation loss: 3.7531129022439322

Epoch: 5| Step: 4
Training loss: 3.3001036643981934
Validation loss: 3.7488897939523063

Epoch: 5| Step: 5
Training loss: 4.1097412109375
Validation loss: 3.7435824473698935

Epoch: 5| Step: 6
Training loss: 3.199873685836792
Validation loss: 3.7389510571956635

Epoch: 5| Step: 7
Training loss: 4.497021198272705
Validation loss: 3.7349624633789062

Epoch: 5| Step: 8
Training loss: 4.496523857116699
Validation loss: 3.731068025032679

Epoch: 5| Step: 9
Training loss: 4.819060325622559
Validation loss: 3.7253034114837646

Epoch: 5| Step: 10
Training loss: 3.7958786487579346
Validation loss: 3.7203315993150077

Epoch: 5| Step: 11
Training loss: 3.032710552215576
Validation loss: 3.715692033370336

Epoch: 25| Step: 0
Training loss: 3.442056655883789
Validation loss: 3.711870014667511

Epoch: 5| Step: 1
Training loss: 3.695502758026123
Validation loss: 3.7077436447143555

Epoch: 5| Step: 2
Training loss: 3.611295700073242
Validation loss: 3.703125904003779

Epoch: 5| Step: 3
Training loss: 4.412826061248779
Validation loss: 3.6991798182328544

Epoch: 5| Step: 4
Training loss: 2.9613606929779053
Validation loss: 3.6945422887802124

Epoch: 5| Step: 5
Training loss: 4.588757514953613
Validation loss: 3.6902294556299844

Epoch: 5| Step: 6
Training loss: 3.210042953491211
Validation loss: 3.6850634813308716

Epoch: 5| Step: 7
Training loss: 3.9551596641540527
Validation loss: 3.680083086093267

Epoch: 5| Step: 8
Training loss: 4.062003135681152
Validation loss: 3.6761555671691895

Epoch: 5| Step: 9
Training loss: 4.088376045227051
Validation loss: 3.672117034594218

Epoch: 5| Step: 10
Training loss: 4.288174152374268
Validation loss: 3.6679207483927407

Epoch: 5| Step: 11
Training loss: 4.098119258880615
Validation loss: 3.663734237353007

Epoch: 26| Step: 0
Training loss: 4.320474147796631
Validation loss: 3.6597176492214203

Epoch: 5| Step: 1
Training loss: 3.1897246837615967
Validation loss: 3.655272881189982

Epoch: 5| Step: 2
Training loss: 3.6937286853790283
Validation loss: 3.650859306255976

Epoch: 5| Step: 3
Training loss: 4.370002269744873
Validation loss: 3.6490853230158486

Epoch: 5| Step: 4
Training loss: 3.455961227416992
Validation loss: 3.641911675532659

Epoch: 5| Step: 5
Training loss: 3.2970497608184814
Validation loss: 3.6386884351571402

Epoch: 5| Step: 6
Training loss: 4.624536991119385
Validation loss: 3.6349861721197763

Epoch: 5| Step: 7
Training loss: 3.684002637863159
Validation loss: 3.6311296621958413

Epoch: 5| Step: 8
Training loss: 3.4294097423553467
Validation loss: 3.627528498570124

Epoch: 5| Step: 9
Training loss: 4.040778160095215
Validation loss: 3.6231555541356406

Epoch: 5| Step: 10
Training loss: 3.5878283977508545
Validation loss: 3.6185514628887177

Epoch: 5| Step: 11
Training loss: 4.388893127441406
Validation loss: 3.6136146982510886

Epoch: 27| Step: 0
Training loss: 3.357883930206299
Validation loss: 3.608923157056173

Epoch: 5| Step: 1
Training loss: 3.4260222911834717
Validation loss: 3.6051431198914847

Epoch: 5| Step: 2
Training loss: 3.8546314239501953
Validation loss: 3.6010412077109017

Epoch: 5| Step: 3
Training loss: 4.280511856079102
Validation loss: 3.596696048974991

Epoch: 5| Step: 4
Training loss: 4.341768264770508
Validation loss: 3.5933168033758798

Epoch: 5| Step: 5
Training loss: 4.401951789855957
Validation loss: 3.588676373163859

Epoch: 5| Step: 6
Training loss: 3.5464725494384766
Validation loss: 3.583934177954992

Epoch: 5| Step: 7
Training loss: 4.012103080749512
Validation loss: 3.579643279314041

Epoch: 5| Step: 8
Training loss: 3.2611916065216064
Validation loss: 3.575924356778463

Epoch: 5| Step: 9
Training loss: 3.370342969894409
Validation loss: 3.570957084496816

Epoch: 5| Step: 10
Training loss: 3.0231716632843018
Validation loss: 3.5660400489966073

Epoch: 5| Step: 11
Training loss: 5.582828521728516
Validation loss: 3.5619011918703714

Epoch: 28| Step: 0
Training loss: 3.7882087230682373
Validation loss: 3.5567135711510978

Epoch: 5| Step: 1
Training loss: 3.6241860389709473
Validation loss: 3.5522880852222443

Epoch: 5| Step: 2
Training loss: 3.7351925373077393
Validation loss: 3.548795849084854

Epoch: 5| Step: 3
Training loss: 4.078850746154785
Validation loss: 3.5439045627911887

Epoch: 5| Step: 4
Training loss: 3.9071192741394043
Validation loss: 3.5390955011049905

Epoch: 5| Step: 5
Training loss: 3.826148509979248
Validation loss: 3.534663657347361

Epoch: 5| Step: 6
Training loss: 3.5179831981658936
Validation loss: 3.5291429658730826

Epoch: 5| Step: 7
Training loss: 3.5177547931671143
Validation loss: 3.5251615246136985

Epoch: 5| Step: 8
Training loss: 3.6570534706115723
Validation loss: 3.5206662019093833

Epoch: 5| Step: 9
Training loss: 3.487757921218872
Validation loss: 3.5163740714391074

Epoch: 5| Step: 10
Training loss: 3.870668888092041
Validation loss: 3.510963241259257

Epoch: 5| Step: 11
Training loss: 2.168661594390869
Validation loss: 3.5068687001864114

Epoch: 29| Step: 0
Training loss: 3.563045024871826
Validation loss: 3.5032508273919425

Epoch: 5| Step: 1
Training loss: 3.495638608932495
Validation loss: 3.498405317465464

Epoch: 5| Step: 2
Training loss: 3.94341778755188
Validation loss: 3.4958243171374

Epoch: 5| Step: 3
Training loss: 4.161269187927246
Validation loss: 3.4925367732842765

Epoch: 5| Step: 4
Training loss: 3.6159274578094482
Validation loss: 3.488199253877004

Epoch: 5| Step: 5
Training loss: 4.50577449798584
Validation loss: 3.48209618528684

Epoch: 5| Step: 6
Training loss: 3.2539801597595215
Validation loss: 3.476965477069219

Epoch: 5| Step: 7
Training loss: 3.1851730346679688
Validation loss: 3.4716886480649314

Epoch: 5| Step: 8
Training loss: 3.101799726486206
Validation loss: 3.4676304956277213

Epoch: 5| Step: 9
Training loss: 3.7231483459472656
Validation loss: 3.4637315769990287

Epoch: 5| Step: 10
Training loss: 3.637004852294922
Validation loss: 3.4618594646453857

Epoch: 5| Step: 11
Training loss: 3.383287191390991
Validation loss: 3.4541816214720407

Epoch: 30| Step: 0
Training loss: 3.782198429107666
Validation loss: 3.450141499439875

Epoch: 5| Step: 1
Training loss: 3.5749359130859375
Validation loss: 3.44601039091746

Epoch: 5| Step: 2
Training loss: 2.6616456508636475
Validation loss: 3.442364195982615

Epoch: 5| Step: 3
Training loss: 3.8803603649139404
Validation loss: 3.4375765522321067

Epoch: 5| Step: 4
Training loss: 3.370732069015503
Validation loss: 3.4335197508335114

Epoch: 5| Step: 5
Training loss: 3.7995803356170654
Validation loss: 3.4297968447208405

Epoch: 5| Step: 6
Training loss: 3.5541319847106934
Validation loss: 3.424345542987188

Epoch: 5| Step: 7
Training loss: 3.8329079151153564
Validation loss: 3.420366019010544

Epoch: 5| Step: 8
Training loss: 3.984717607498169
Validation loss: 3.415783077478409

Epoch: 5| Step: 9
Training loss: 3.2545688152313232
Validation loss: 3.411214659611384

Epoch: 5| Step: 10
Training loss: 3.7636349201202393
Validation loss: 3.4079979956150055

Epoch: 5| Step: 11
Training loss: 4.049885272979736
Validation loss: 3.4027342200279236

Epoch: 31| Step: 0
Training loss: 3.0168862342834473
Validation loss: 3.3988000750541687

Epoch: 5| Step: 1
Training loss: 3.403172731399536
Validation loss: 3.39422008395195

Epoch: 5| Step: 2
Training loss: 3.7003989219665527
Validation loss: 3.3898043632507324

Epoch: 5| Step: 3
Training loss: 4.043082237243652
Validation loss: 3.385023276011149

Epoch: 5| Step: 4
Training loss: 3.646742343902588
Validation loss: 3.3802389204502106

Epoch: 5| Step: 5
Training loss: 3.2716622352600098
Validation loss: 3.3760975003242493

Epoch: 5| Step: 6
Training loss: 3.6763370037078857
Validation loss: 3.3713409105936685

Epoch: 5| Step: 7
Training loss: 2.704745292663574
Validation loss: 3.3667414287726083

Epoch: 5| Step: 8
Training loss: 3.9356942176818848
Validation loss: 3.3629142542680106

Epoch: 5| Step: 9
Training loss: 3.6206793785095215
Validation loss: 3.3582835098107657

Epoch: 5| Step: 10
Training loss: 3.908351421356201
Validation loss: 3.354238589604696

Epoch: 5| Step: 11
Training loss: 3.944669246673584
Validation loss: 3.3491718570391336

Epoch: 32| Step: 0
Training loss: 2.9317288398742676
Validation loss: 3.345839887857437

Epoch: 5| Step: 1
Training loss: 3.638690233230591
Validation loss: 3.3438373804092407

Epoch: 5| Step: 2
Training loss: 3.8397974967956543
Validation loss: 3.3405447900295258

Epoch: 5| Step: 3
Training loss: 3.4579365253448486
Validation loss: 3.3388670782248178

Epoch: 5| Step: 4
Training loss: 4.548610210418701
Validation loss: 3.33322208126386

Epoch: 5| Step: 5
Training loss: 2.7282814979553223
Validation loss: 3.3262639343738556

Epoch: 5| Step: 6
Training loss: 3.587228775024414
Validation loss: 3.3219682772954306

Epoch: 5| Step: 7
Training loss: 3.5439846515655518
Validation loss: 3.317794978618622

Epoch: 5| Step: 8
Training loss: 2.863922595977783
Validation loss: 3.3140524327754974

Epoch: 5| Step: 9
Training loss: 3.6467998027801514
Validation loss: 3.311896731456121

Epoch: 5| Step: 10
Training loss: 3.8858566284179688
Validation loss: 3.30793230732282

Epoch: 5| Step: 11
Training loss: 2.538320302963257
Validation loss: 3.3014919459819794

Epoch: 33| Step: 0
Training loss: 3.9795632362365723
Validation loss: 3.2972550988197327

Epoch: 5| Step: 1
Training loss: 2.979058265686035
Validation loss: 3.2923421065012612

Epoch: 5| Step: 2
Training loss: 3.609823703765869
Validation loss: 3.2894010146458945

Epoch: 5| Step: 3
Training loss: 3.7423958778381348
Validation loss: 3.2847762604554496

Epoch: 5| Step: 4
Training loss: 3.3050436973571777
Validation loss: 3.280883232752482

Epoch: 5| Step: 5
Training loss: 3.5680949687957764
Validation loss: 3.2779214282830558

Epoch: 5| Step: 6
Training loss: 3.633579730987549
Validation loss: 3.2728375097115836

Epoch: 5| Step: 7
Training loss: 3.818803310394287
Validation loss: 3.2690351804097495

Epoch: 5| Step: 8
Training loss: 2.7675986289978027
Validation loss: 3.2643132706483207

Epoch: 5| Step: 9
Training loss: 2.913341522216797
Validation loss: 3.259636869033178

Epoch: 5| Step: 10
Training loss: 3.3643927574157715
Validation loss: 3.256325840950012

Epoch: 5| Step: 11
Training loss: 4.926182270050049
Validation loss: 3.2510875960191092

Epoch: 34| Step: 0
Training loss: 2.910196304321289
Validation loss: 3.2472603619098663

Epoch: 5| Step: 1
Training loss: 3.960175037384033
Validation loss: 3.2431292633215585

Epoch: 5| Step: 2
Training loss: 3.4814701080322266
Validation loss: 3.2383684317270913

Epoch: 5| Step: 3
Training loss: 3.4218316078186035
Validation loss: 3.233687162399292

Epoch: 5| Step: 4
Training loss: 3.6566593647003174
Validation loss: 3.2295768161614737

Epoch: 5| Step: 5
Training loss: 2.6865572929382324
Validation loss: 3.225856363773346

Epoch: 5| Step: 6
Training loss: 3.017369270324707
Validation loss: 3.221186945835749

Epoch: 5| Step: 7
Training loss: 3.698164701461792
Validation loss: 3.21740061044693

Epoch: 5| Step: 8
Training loss: 3.709217071533203
Validation loss: 3.213603059450785

Epoch: 5| Step: 9
Training loss: 3.0993599891662598
Validation loss: 3.210601548353831

Epoch: 5| Step: 10
Training loss: 3.944833278656006
Validation loss: 3.2053745488325753

Epoch: 5| Step: 11
Training loss: 2.7045440673828125
Validation loss: 3.2019013663132987

Epoch: 35| Step: 0
Training loss: 3.8169639110565186
Validation loss: 3.1965261101722717

Epoch: 5| Step: 1
Training loss: 3.081678867340088
Validation loss: 3.1922921935717263

Epoch: 5| Step: 2
Training loss: 3.1427738666534424
Validation loss: 3.1892505288124084

Epoch: 5| Step: 3
Training loss: 2.6897289752960205
Validation loss: 3.184624711672465

Epoch: 5| Step: 4
Training loss: 3.304239273071289
Validation loss: 3.1801606913407645

Epoch: 5| Step: 5
Training loss: 3.2797298431396484
Validation loss: 3.1773142913977304

Epoch: 5| Step: 6
Training loss: 4.038692474365234
Validation loss: 3.171360303958257

Epoch: 5| Step: 7
Training loss: 2.7632248401641846
Validation loss: 3.1676616768042245

Epoch: 5| Step: 8
Training loss: 3.6662209033966064
Validation loss: 3.1630673905213675

Epoch: 5| Step: 9
Training loss: 2.7420589923858643
Validation loss: 3.159411370754242

Epoch: 5| Step: 10
Training loss: 4.199204444885254
Validation loss: 3.155571699142456

Epoch: 5| Step: 11
Training loss: 4.415474891662598
Validation loss: 3.1527187724908194

Epoch: 36| Step: 0
Training loss: 3.0731358528137207
Validation loss: 3.147526293992996

Epoch: 5| Step: 1
Training loss: 2.4345457553863525
Validation loss: 3.147160996993383

Epoch: 5| Step: 2
Training loss: 3.1963582038879395
Validation loss: 3.1445486744244895

Epoch: 5| Step: 3
Training loss: 3.5232596397399902
Validation loss: 3.1415709952513375

Epoch: 5| Step: 4
Training loss: 3.8857967853546143
Validation loss: 3.134993056456248

Epoch: 5| Step: 5
Training loss: 3.7772140502929688
Validation loss: 3.1304551362991333

Epoch: 5| Step: 6
Training loss: 3.7013168334960938
Validation loss: 3.127382049957911

Epoch: 5| Step: 7
Training loss: 3.7487640380859375
Validation loss: 3.1225382486979165

Epoch: 5| Step: 8
Training loss: 3.6183533668518066
Validation loss: 3.119022091229757

Epoch: 5| Step: 9
Training loss: 2.367067813873291
Validation loss: 3.11628849307696

Epoch: 5| Step: 10
Training loss: 2.9979915618896484
Validation loss: 3.112941791613897

Epoch: 5| Step: 11
Training loss: 4.008905410766602
Validation loss: 3.1073050747315087

Epoch: 37| Step: 0
Training loss: 4.081530570983887
Validation loss: 3.1023613115151725

Epoch: 5| Step: 1
Training loss: 3.4031646251678467
Validation loss: 3.099090258280436

Epoch: 5| Step: 2
Training loss: 2.503556966781616
Validation loss: 3.0942662755648294

Epoch: 5| Step: 3
Training loss: 3.660482406616211
Validation loss: 3.0909414986769357

Epoch: 5| Step: 4
Training loss: 3.1753506660461426
Validation loss: 3.0865400036176047

Epoch: 5| Step: 5
Training loss: 2.867588520050049
Validation loss: 3.084195444981257

Epoch: 5| Step: 6
Training loss: 3.009897232055664
Validation loss: 3.0801487366358438

Epoch: 5| Step: 7
Training loss: 3.485208034515381
Validation loss: 3.075705905755361

Epoch: 5| Step: 8
Training loss: 4.0076141357421875
Validation loss: 3.0725003679593406

Epoch: 5| Step: 9
Training loss: 3.050159215927124
Validation loss: 3.067942202091217

Epoch: 5| Step: 10
Training loss: 2.761932849884033
Validation loss: 3.0651081800460815

Epoch: 5| Step: 11
Training loss: 3.237736225128174
Validation loss: 3.0611390471458435

Epoch: 38| Step: 0
Training loss: 3.333326816558838
Validation loss: 3.0577628711859384

Epoch: 5| Step: 1
Training loss: 3.057105541229248
Validation loss: 3.05405401190122

Epoch: 5| Step: 2
Training loss: 4.101025581359863
Validation loss: 3.0500616232554116

Epoch: 5| Step: 3
Training loss: 3.6213035583496094
Validation loss: 3.046465108791987

Epoch: 5| Step: 4
Training loss: 2.9074435234069824
Validation loss: 3.0437611639499664

Epoch: 5| Step: 5
Training loss: 3.371833086013794
Validation loss: 3.0396776099999747

Epoch: 5| Step: 6
Training loss: 3.5971360206604004
Validation loss: 3.0370384752750397

Epoch: 5| Step: 7
Training loss: 3.0064210891723633
Validation loss: 3.0330411891142526

Epoch: 5| Step: 8
Training loss: 2.915285587310791
Validation loss: 3.028694987297058

Epoch: 5| Step: 9
Training loss: 3.051604747772217
Validation loss: 3.0264452497164407

Epoch: 5| Step: 10
Training loss: 2.426038980484009
Validation loss: 3.022852728764216

Epoch: 5| Step: 11
Training loss: 3.8815689086914062
Validation loss: 3.0180347561836243

Epoch: 39| Step: 0
Training loss: 2.632185459136963
Validation loss: 3.0157507260640464

Epoch: 5| Step: 1
Training loss: 3.4390907287597656
Validation loss: 3.012973258892695

Epoch: 5| Step: 2
Training loss: 3.015993595123291
Validation loss: 3.0085753401120505

Epoch: 5| Step: 3
Training loss: 3.8455238342285156
Validation loss: 3.005781590938568

Epoch: 5| Step: 4
Training loss: 3.447483539581299
Validation loss: 3.0015595654646554

Epoch: 5| Step: 5
Training loss: 2.8266358375549316
Validation loss: 2.998344043890635

Epoch: 5| Step: 6
Training loss: 3.1647024154663086
Validation loss: 2.994575003782908

Epoch: 5| Step: 7
Training loss: 2.8906397819519043
Validation loss: 2.990772823492686

Epoch: 5| Step: 8
Training loss: 3.500290632247925
Validation loss: 2.9875178734461465

Epoch: 5| Step: 9
Training loss: 3.2899951934814453
Validation loss: 2.9839505751927695

Epoch: 5| Step: 10
Training loss: 2.902031898498535
Validation loss: 2.9825609922409058

Epoch: 5| Step: 11
Training loss: 3.8664984703063965
Validation loss: 2.9773759047190347

Epoch: 40| Step: 0
Training loss: 3.9860661029815674
Validation loss: 2.9752337038517

Epoch: 5| Step: 1
Training loss: 2.8163015842437744
Validation loss: 2.971069246530533

Epoch: 5| Step: 2
Training loss: 3.6233725547790527
Validation loss: 2.968490799268087

Epoch: 5| Step: 3
Training loss: 2.5520882606506348
Validation loss: 2.963866005341212

Epoch: 5| Step: 4
Training loss: 2.3443050384521484
Validation loss: 2.960934748252233

Epoch: 5| Step: 5
Training loss: 2.964735507965088
Validation loss: 2.9575389524300895

Epoch: 5| Step: 6
Training loss: 2.552884817123413
Validation loss: 2.9541891713937125

Epoch: 5| Step: 7
Training loss: 3.426499605178833
Validation loss: 2.9516085982322693

Epoch: 5| Step: 8
Training loss: 3.057476758956909
Validation loss: 2.9496438801288605

Epoch: 5| Step: 9
Training loss: 3.661715269088745
Validation loss: 2.945946991443634

Epoch: 5| Step: 10
Training loss: 3.759242296218872
Validation loss: 2.9442374408245087

Epoch: 5| Step: 11
Training loss: 2.80484676361084
Validation loss: 2.9412196576595306

Epoch: 41| Step: 0
Training loss: 2.944666862487793
Validation loss: 2.9371381402015686

Epoch: 5| Step: 1
Training loss: 3.560286283493042
Validation loss: 2.935818443695704

Epoch: 5| Step: 2
Training loss: 2.5830979347229004
Validation loss: 2.933461527029673

Epoch: 5| Step: 3
Training loss: 3.7213587760925293
Validation loss: 2.9294448097546897

Epoch: 5| Step: 4
Training loss: 2.826958179473877
Validation loss: 2.9245893408854804

Epoch: 5| Step: 5
Training loss: 4.018908500671387
Validation loss: 2.9199355443318686

Epoch: 5| Step: 6
Training loss: 2.773137331008911
Validation loss: 2.9185416996479034

Epoch: 5| Step: 7
Training loss: 2.892733335494995
Validation loss: 2.9128544529279075

Epoch: 5| Step: 8
Training loss: 2.8649697303771973
Validation loss: 2.911304106314977

Epoch: 5| Step: 9
Training loss: 3.5356154441833496
Validation loss: 2.9086970587571463

Epoch: 5| Step: 10
Training loss: 2.5715034008026123
Validation loss: 2.9062401751677194

Epoch: 5| Step: 11
Training loss: 3.2274065017700195
Validation loss: 2.9032908280690513

Epoch: 42| Step: 0
Training loss: 3.2398312091827393
Validation loss: 2.9005468835433326

Epoch: 5| Step: 1
Training loss: 3.097632884979248
Validation loss: 2.8970362842082977

Epoch: 5| Step: 2
Training loss: 3.2595653533935547
Validation loss: 2.893602430820465

Epoch: 5| Step: 3
Training loss: 3.4437294006347656
Validation loss: 2.889793445666631

Epoch: 5| Step: 4
Training loss: 3.166649580001831
Validation loss: 2.887037624915441

Epoch: 5| Step: 5
Training loss: 3.133770704269409
Validation loss: 2.8838346699873605

Epoch: 5| Step: 6
Training loss: 3.1141018867492676
Validation loss: 2.8805846174558005

Epoch: 5| Step: 7
Training loss: 3.5337021350860596
Validation loss: 2.877035746971766

Epoch: 5| Step: 8
Training loss: 2.4873008728027344
Validation loss: 2.8740822474161782

Epoch: 5| Step: 9
Training loss: 2.7911744117736816
Validation loss: 2.8698674738407135

Epoch: 5| Step: 10
Training loss: 2.740988254547119
Validation loss: 2.8671661814053855

Epoch: 5| Step: 11
Training loss: 2.971475124359131
Validation loss: 2.86560187737147

Epoch: 43| Step: 0
Training loss: 3.29835844039917
Validation loss: 2.8612343470255532

Epoch: 5| Step: 1
Training loss: 2.6906111240386963
Validation loss: 2.8599119186401367

Epoch: 5| Step: 2
Training loss: 4.019839763641357
Validation loss: 2.8565595746040344

Epoch: 5| Step: 3
Training loss: 2.4387195110321045
Validation loss: 2.8526929020881653

Epoch: 5| Step: 4
Training loss: 2.778954267501831
Validation loss: 2.8498471478621163

Epoch: 5| Step: 5
Training loss: 2.937201738357544
Validation loss: 2.8469697336355844

Epoch: 5| Step: 6
Training loss: 3.2040047645568848
Validation loss: 2.8449838956197104

Epoch: 5| Step: 7
Training loss: 3.2949535846710205
Validation loss: 2.841707726319631

Epoch: 5| Step: 8
Training loss: 3.3983588218688965
Validation loss: 2.839739422003428

Epoch: 5| Step: 9
Training loss: 3.182152032852173
Validation loss: 2.8383735915025077

Epoch: 5| Step: 10
Training loss: 2.3649702072143555
Validation loss: 2.8345296680927277

Epoch: 5| Step: 11
Training loss: 2.934044122695923
Validation loss: 2.8318943878014884

Epoch: 44| Step: 0
Training loss: 2.608933925628662
Validation loss: 2.8271421690781913

Epoch: 5| Step: 1
Training loss: 3.089761257171631
Validation loss: 2.8257123827934265

Epoch: 5| Step: 2
Training loss: 3.531958818435669
Validation loss: 2.8262355625629425

Epoch: 5| Step: 3
Training loss: 3.315504789352417
Validation loss: 2.8234401444594064

Epoch: 5| Step: 4
Training loss: 2.6249446868896484
Validation loss: 2.814592878023783

Epoch: 5| Step: 5
Training loss: 2.6622025966644287
Validation loss: 2.810881723960241

Epoch: 5| Step: 6
Training loss: 3.6324875354766846
Validation loss: 2.808348387479782

Epoch: 5| Step: 7
Training loss: 2.6655938625335693
Validation loss: 2.805535833040873

Epoch: 5| Step: 8
Training loss: 3.268650531768799
Validation loss: 2.80439430475235

Epoch: 5| Step: 9
Training loss: 2.570791482925415
Validation loss: 2.804128626982371

Epoch: 5| Step: 10
Training loss: 3.3149752616882324
Validation loss: 2.8035543064276376

Epoch: 5| Step: 11
Training loss: 2.780766487121582
Validation loss: 2.797161748011907

Epoch: 45| Step: 0
Training loss: 2.648561954498291
Validation loss: 2.794254551331202

Epoch: 5| Step: 1
Training loss: 2.92541241645813
Validation loss: 2.7895697951316833

Epoch: 5| Step: 2
Training loss: 2.748964548110962
Validation loss: 2.7849542101224265

Epoch: 5| Step: 3
Training loss: 2.8129756450653076
Validation loss: 2.783613642056783

Epoch: 5| Step: 4
Training loss: 3.2966606616973877
Validation loss: 2.778740425904592

Epoch: 5| Step: 5
Training loss: 3.131054401397705
Validation loss: 2.777682880560557

Epoch: 5| Step: 6
Training loss: 2.5622074604034424
Validation loss: 2.7756998439629874

Epoch: 5| Step: 7
Training loss: 2.783130168914795
Validation loss: 2.7736346224943795

Epoch: 5| Step: 8
Training loss: 3.8258819580078125
Validation loss: 2.77402796347936

Epoch: 5| Step: 9
Training loss: 3.255492687225342
Validation loss: 2.772584100564321

Epoch: 5| Step: 10
Training loss: 2.81360125541687
Validation loss: 2.7678858836491904

Epoch: 5| Step: 11
Training loss: 3.3654470443725586
Validation loss: 2.761562238136927

Epoch: 46| Step: 0
Training loss: 3.4732766151428223
Validation loss: 2.757848858833313

Epoch: 5| Step: 1
Training loss: 2.6309046745300293
Validation loss: 2.75384787718455

Epoch: 5| Step: 2
Training loss: 3.4055564403533936
Validation loss: 2.7523100872834525

Epoch: 5| Step: 3
Training loss: 2.881025552749634
Validation loss: 2.750274042288462

Epoch: 5| Step: 4
Training loss: 3.1502270698547363
Validation loss: 2.748794694741567

Epoch: 5| Step: 5
Training loss: 2.372013807296753
Validation loss: 2.747725337743759

Epoch: 5| Step: 6
Training loss: 2.8137459754943848
Validation loss: 2.7431458830833435

Epoch: 5| Step: 7
Training loss: 3.3576138019561768
Validation loss: 2.7402936120827994

Epoch: 5| Step: 8
Training loss: 2.340756893157959
Validation loss: 2.735545684893926

Epoch: 5| Step: 9
Training loss: 2.617885112762451
Validation loss: 2.7332452833652496

Epoch: 5| Step: 10
Training loss: 3.2829315662384033
Validation loss: 2.729486733675003

Epoch: 5| Step: 11
Training loss: 3.912060499191284
Validation loss: 2.72649014989535

Epoch: 47| Step: 0
Training loss: 2.8302643299102783
Validation loss: 2.7236025631427765

Epoch: 5| Step: 1
Training loss: 3.57574462890625
Validation loss: 2.7212534050146737

Epoch: 5| Step: 2
Training loss: 2.866525650024414
Validation loss: 2.7184304197629294

Epoch: 5| Step: 3
Training loss: 2.2222952842712402
Validation loss: 2.7144641876220703

Epoch: 5| Step: 4
Training loss: 3.033297061920166
Validation loss: 2.7111676136652627

Epoch: 5| Step: 5
Training loss: 3.00264573097229
Validation loss: 2.7084390620390573

Epoch: 5| Step: 6
Training loss: 2.718064546585083
Validation loss: 2.7047502199808755

Epoch: 5| Step: 7
Training loss: 2.5746243000030518
Validation loss: 2.7004826962947845

Epoch: 5| Step: 8
Training loss: 2.7001781463623047
Validation loss: 2.6986298064390817

Epoch: 5| Step: 9
Training loss: 3.191255807876587
Validation loss: 2.6968954702218375

Epoch: 5| Step: 10
Training loss: 3.3636527061462402
Validation loss: 2.6941939095656076

Epoch: 5| Step: 11
Training loss: 2.9211959838867188
Validation loss: 2.69057489434878

Epoch: 48| Step: 0
Training loss: 2.9501168727874756
Validation loss: 2.6881846288839975

Epoch: 5| Step: 1
Training loss: 3.1770565509796143
Validation loss: 2.6862395902474723

Epoch: 5| Step: 2
Training loss: 2.643846035003662
Validation loss: 2.6829110582669577

Epoch: 5| Step: 3
Training loss: 2.685664653778076
Validation loss: 2.6810476084550223

Epoch: 5| Step: 4
Training loss: 3.215240478515625
Validation loss: 2.677894006172816

Epoch: 5| Step: 5
Training loss: 2.753343105316162
Validation loss: 2.6771814823150635

Epoch: 5| Step: 6
Training loss: 2.6824283599853516
Validation loss: 2.672521233558655

Epoch: 5| Step: 7
Training loss: 2.5732197761535645
Validation loss: 2.671495944261551

Epoch: 5| Step: 8
Training loss: 2.7647290229797363
Validation loss: 2.6703776717185974

Epoch: 5| Step: 9
Training loss: 2.683434247970581
Validation loss: 2.6691046059131622

Epoch: 5| Step: 10
Training loss: 3.2360501289367676
Validation loss: 2.6652618745962777

Epoch: 5| Step: 11
Training loss: 4.379220962524414
Validation loss: 2.659423013528188

Epoch: 49| Step: 0
Training loss: 3.0121660232543945
Validation loss: 2.654307554165522

Epoch: 5| Step: 1
Training loss: 2.2917749881744385
Validation loss: 2.6512525777022042

Epoch: 5| Step: 2
Training loss: 3.3798279762268066
Validation loss: 2.649744172890981

Epoch: 5| Step: 3
Training loss: 2.665846109390259
Validation loss: 2.6476668814818063

Epoch: 5| Step: 4
Training loss: 2.830331802368164
Validation loss: 2.6465282638867698

Epoch: 5| Step: 5
Training loss: 3.2904727458953857
Validation loss: 2.645985394716263

Epoch: 5| Step: 6
Training loss: 2.766911268234253
Validation loss: 2.6439849783976874

Epoch: 5| Step: 7
Training loss: 2.8586246967315674
Validation loss: 2.639619847138723

Epoch: 5| Step: 8
Training loss: 2.7653605937957764
Validation loss: 2.634932259718577

Epoch: 5| Step: 9
Training loss: 3.110790491104126
Validation loss: 2.6318789621194205

Epoch: 5| Step: 10
Training loss: 2.3261752128601074
Validation loss: 2.6294085681438446

Epoch: 5| Step: 11
Training loss: 3.0216732025146484
Validation loss: 2.62520898381869

Epoch: 50| Step: 0
Training loss: 2.4545505046844482
Validation loss: 2.6224475701649985

Epoch: 5| Step: 1
Training loss: 3.1499862670898438
Validation loss: 2.6195326149463654

Epoch: 5| Step: 2
Training loss: 2.991225242614746
Validation loss: 2.615494668483734

Epoch: 5| Step: 3
Training loss: 3.053847074508667
Validation loss: 2.6120695074399314

Epoch: 5| Step: 4
Training loss: 2.533961534500122
Validation loss: 2.609896868467331

Epoch: 5| Step: 5
Training loss: 3.229206085205078
Validation loss: 2.607895096143087

Epoch: 5| Step: 6
Training loss: 2.515347480773926
Validation loss: 2.604419688383738

Epoch: 5| Step: 7
Training loss: 2.2992568016052246
Validation loss: 2.600930611292521

Epoch: 5| Step: 8
Training loss: 3.092107057571411
Validation loss: 2.5977090100447335

Epoch: 5| Step: 9
Training loss: 2.941593885421753
Validation loss: 2.5948903262615204

Epoch: 5| Step: 10
Training loss: 2.694166421890259
Validation loss: 2.591438412666321

Epoch: 5| Step: 11
Training loss: 2.5634262561798096
Validation loss: 2.5894173880418143

Epoch: 51| Step: 0
Training loss: 2.5806496143341064
Validation loss: 2.587123860915502

Epoch: 5| Step: 1
Training loss: 2.771056652069092
Validation loss: 2.5822677413622537

Epoch: 5| Step: 2
Training loss: 2.904547929763794
Validation loss: 2.580930635333061

Epoch: 5| Step: 3
Training loss: 2.5415329933166504
Validation loss: 2.5776435832182565

Epoch: 5| Step: 4
Training loss: 3.1785995960235596
Validation loss: 2.575423985719681

Epoch: 5| Step: 5
Training loss: 2.320491075515747
Validation loss: 2.5721647838751474

Epoch: 5| Step: 6
Training loss: 2.512923240661621
Validation loss: 2.5692038436730704

Epoch: 5| Step: 7
Training loss: 3.346738338470459
Validation loss: 2.570612778266271

Epoch: 5| Step: 8
Training loss: 2.922189712524414
Validation loss: 2.566425532102585

Epoch: 5| Step: 9
Training loss: 2.793602705001831
Validation loss: 2.5662547647953033

Epoch: 5| Step: 10
Training loss: 2.7179267406463623
Validation loss: 2.562490443388621

Epoch: 5| Step: 11
Training loss: 2.502971649169922
Validation loss: 2.558550367752711

Epoch: 52| Step: 0
Training loss: 2.852726697921753
Validation loss: 2.5553392271200814

Epoch: 5| Step: 1
Training loss: 2.5678653717041016
Validation loss: 2.555789276957512

Epoch: 5| Step: 2
Training loss: 3.4532103538513184
Validation loss: 2.553083668152491

Epoch: 5| Step: 3
Training loss: 3.1222195625305176
Validation loss: 2.548220386107763

Epoch: 5| Step: 4
Training loss: 2.688206672668457
Validation loss: 2.5457620471715927

Epoch: 5| Step: 5
Training loss: 2.7522552013397217
Validation loss: 2.5432248016198478

Epoch: 5| Step: 6
Training loss: 2.7794580459594727
Validation loss: 2.5412792563438416

Epoch: 5| Step: 7
Training loss: 2.8247363567352295
Validation loss: 2.5364077587922416

Epoch: 5| Step: 8
Training loss: 2.411548137664795
Validation loss: 2.5330632527669272

Epoch: 5| Step: 9
Training loss: 2.4604969024658203
Validation loss: 2.5320295095443726

Epoch: 5| Step: 10
Training loss: 2.530797243118286
Validation loss: 2.529989391565323

Epoch: 5| Step: 11
Training loss: 1.2955117225646973
Validation loss: 2.5285532673199973

Epoch: 53| Step: 0
Training loss: 2.276587724685669
Validation loss: 2.5255310336748757

Epoch: 5| Step: 1
Training loss: 3.127234697341919
Validation loss: 2.5239100058873496

Epoch: 5| Step: 2
Training loss: 2.178421974182129
Validation loss: 2.5212683379650116

Epoch: 5| Step: 3
Training loss: 2.8290042877197266
Validation loss: 2.517982065677643

Epoch: 5| Step: 4
Training loss: 3.0591139793395996
Validation loss: 2.5200307369232178

Epoch: 5| Step: 5
Training loss: 2.4337337017059326
Validation loss: 2.512699375549952

Epoch: 5| Step: 6
Training loss: 2.54829740524292
Validation loss: 2.5137765407562256

Epoch: 5| Step: 7
Training loss: 2.8699276447296143
Validation loss: 2.5096554358800254

Epoch: 5| Step: 8
Training loss: 2.2447328567504883
Validation loss: 2.5066095491250358

Epoch: 5| Step: 9
Training loss: 2.9822840690612793
Validation loss: 2.503933926423391

Epoch: 5| Step: 10
Training loss: 2.943984270095825
Validation loss: 2.503121018409729

Epoch: 5| Step: 11
Training loss: 4.218206405639648
Validation loss: 2.5008327613274255

Epoch: 54| Step: 0
Training loss: 2.9191269874572754
Validation loss: 2.4994339048862457

Epoch: 5| Step: 1
Training loss: 2.6532604694366455
Validation loss: 2.5046380907297134

Epoch: 5| Step: 2
Training loss: 2.760775327682495
Validation loss: 2.509808441003164

Epoch: 5| Step: 3
Training loss: 2.9443676471710205
Validation loss: 2.5180273999770484

Epoch: 5| Step: 4
Training loss: 2.0551397800445557
Validation loss: 2.510686198870341

Epoch: 5| Step: 5
Training loss: 2.1422011852264404
Validation loss: 2.50566558043162

Epoch: 5| Step: 6
Training loss: 2.4931483268737793
Validation loss: 2.49810728430748

Epoch: 5| Step: 7
Training loss: 2.804381847381592
Validation loss: 2.4963280856609344

Epoch: 5| Step: 8
Training loss: 3.210298538208008
Validation loss: 2.489424725373586

Epoch: 5| Step: 9
Training loss: 2.481806516647339
Validation loss: 2.4795263707637787

Epoch: 5| Step: 10
Training loss: 2.9141783714294434
Validation loss: 2.4764393866062164

Epoch: 5| Step: 11
Training loss: 3.602919578552246
Validation loss: 2.474562476078669

Epoch: 55| Step: 0
Training loss: 2.5455801486968994
Validation loss: 2.4694512486457825

Epoch: 5| Step: 1
Training loss: 2.767329454421997
Validation loss: 2.4695600867271423

Epoch: 5| Step: 2
Training loss: 2.5178892612457275
Validation loss: 2.4656124959389367

Epoch: 5| Step: 3
Training loss: 1.9890788793563843
Validation loss: 2.4651704728603363

Epoch: 5| Step: 4
Training loss: 2.895937442779541
Validation loss: 2.46057857076327

Epoch: 5| Step: 5
Training loss: 3.327617645263672
Validation loss: 2.4601752758026123

Epoch: 5| Step: 6
Training loss: 2.3526246547698975
Validation loss: 2.4574083189169564

Epoch: 5| Step: 7
Training loss: 2.796142578125
Validation loss: 2.4561924636363983

Epoch: 5| Step: 8
Training loss: 2.587859869003296
Validation loss: 2.453078180551529

Epoch: 5| Step: 9
Training loss: 2.8481624126434326
Validation loss: 2.451538324356079

Epoch: 5| Step: 10
Training loss: 2.3862342834472656
Validation loss: 2.448095699151357

Epoch: 5| Step: 11
Training loss: 3.400498151779175
Validation loss: 2.4440585176150003

Epoch: 56| Step: 0
Training loss: 2.5771913528442383
Validation loss: 2.442611257235209

Epoch: 5| Step: 1
Training loss: 2.4789750576019287
Validation loss: 2.440270274877548

Epoch: 5| Step: 2
Training loss: 2.091155529022217
Validation loss: 2.440153628587723

Epoch: 5| Step: 3
Training loss: 2.7093825340270996
Validation loss: 2.4367874562740326

Epoch: 5| Step: 4
Training loss: 2.897935152053833
Validation loss: 2.435167044401169

Epoch: 5| Step: 5
Training loss: 2.2767627239227295
Validation loss: 2.4328270653883615

Epoch: 5| Step: 6
Training loss: 3.2233309745788574
Validation loss: 2.4285040497779846

Epoch: 5| Step: 7
Training loss: 2.4876086711883545
Validation loss: 2.4338186979293823

Epoch: 5| Step: 8
Training loss: 2.5129058361053467
Validation loss: 2.4299257646004357

Epoch: 5| Step: 9
Training loss: 2.8288676738739014
Validation loss: 2.422188421090444

Epoch: 5| Step: 10
Training loss: 2.603818655014038
Validation loss: 2.423299411932627

Epoch: 5| Step: 11
Training loss: 3.164381980895996
Validation loss: 2.4258388777573905

Epoch: 57| Step: 0
Training loss: 2.733471393585205
Validation loss: 2.417218337456385

Epoch: 5| Step: 1
Training loss: 2.994847536087036
Validation loss: 2.4147647619247437

Epoch: 5| Step: 2
Training loss: 1.9267524480819702
Validation loss: 2.4128162562847137

Epoch: 5| Step: 3
Training loss: 2.2335915565490723
Validation loss: 2.4096851547559104

Epoch: 5| Step: 4
Training loss: 2.7118442058563232
Validation loss: 2.4075615108013153

Epoch: 5| Step: 5
Training loss: 2.3495090007781982
Validation loss: 2.4029305279254913

Epoch: 5| Step: 6
Training loss: 2.468064785003662
Validation loss: 2.4039581418037415

Epoch: 5| Step: 7
Training loss: 3.032844066619873
Validation loss: 2.400129030148188

Epoch: 5| Step: 8
Training loss: 2.9266514778137207
Validation loss: 2.401667649547259

Epoch: 5| Step: 9
Training loss: 2.956120014190674
Validation loss: 2.3952251772085824

Epoch: 5| Step: 10
Training loss: 2.1156868934631348
Validation loss: 2.3910323878129325

Epoch: 5| Step: 11
Training loss: 2.8703198432922363
Validation loss: 2.3921061158180237

Epoch: 58| Step: 0
Training loss: 2.898801803588867
Validation loss: 2.388960217436155

Epoch: 5| Step: 1
Training loss: 2.6434433460235596
Validation loss: 2.3882830192645392

Epoch: 5| Step: 2
Training loss: 2.8365070819854736
Validation loss: 2.3849604229132333

Epoch: 5| Step: 3
Training loss: 1.9152252674102783
Validation loss: 2.382282555103302

Epoch: 5| Step: 4
Training loss: 2.8439383506774902
Validation loss: 2.3807640075683594

Epoch: 5| Step: 5
Training loss: 2.248253107070923
Validation loss: 2.3788068691889444

Epoch: 5| Step: 6
Training loss: 2.4310107231140137
Validation loss: 2.376257707675298

Epoch: 5| Step: 7
Training loss: 2.867926597595215
Validation loss: 2.3708701928456626

Epoch: 5| Step: 8
Training loss: 2.389676570892334
Validation loss: 2.3732503751913705

Epoch: 5| Step: 9
Training loss: 2.4749197959899902
Validation loss: 2.3680181900660195

Epoch: 5| Step: 10
Training loss: 2.5668745040893555
Validation loss: 2.3664474189281464

Epoch: 5| Step: 11
Training loss: 2.5180184841156006
Validation loss: 2.3643468221028647

Epoch: 59| Step: 0
Training loss: 2.29118013381958
Validation loss: 2.3650466154019036

Epoch: 5| Step: 1
Training loss: 2.8151450157165527
Validation loss: 2.3613228797912598

Epoch: 5| Step: 2
Training loss: 2.3193893432617188
Validation loss: 2.360160837570826

Epoch: 5| Step: 3
Training loss: 2.1905517578125
Validation loss: 2.358649497230848

Epoch: 5| Step: 4
Training loss: 2.9851603507995605
Validation loss: 2.355076402425766

Epoch: 5| Step: 5
Training loss: 2.525994062423706
Validation loss: 2.3559705217679343

Epoch: 5| Step: 6
Training loss: 2.6804964542388916
Validation loss: 2.358174274365107

Epoch: 5| Step: 7
Training loss: 2.647995710372925
Validation loss: 2.3530921936035156

Epoch: 5| Step: 8
Training loss: 2.748020648956299
Validation loss: 2.349862356980642

Epoch: 5| Step: 9
Training loss: 2.1806094646453857
Validation loss: 2.3476678232351937

Epoch: 5| Step: 10
Training loss: 2.4244298934936523
Validation loss: 2.34617750843366

Epoch: 5| Step: 11
Training loss: 2.5432705879211426
Validation loss: 2.344069391489029

Epoch: 60| Step: 0
Training loss: 2.2845535278320312
Validation loss: 2.3403585851192474

Epoch: 5| Step: 1
Training loss: 2.4222841262817383
Validation loss: 2.3410370349884033

Epoch: 5| Step: 2
Training loss: 2.192110776901245
Validation loss: 2.3419641256332397

Epoch: 5| Step: 3
Training loss: 1.8915166854858398
Validation loss: 2.336866726477941

Epoch: 5| Step: 4
Training loss: 2.83205509185791
Validation loss: 2.337046374877294

Epoch: 5| Step: 5
Training loss: 2.348508834838867
Validation loss: 2.338755115866661

Epoch: 5| Step: 6
Training loss: 2.9011216163635254
Validation loss: 2.3328727881113687

Epoch: 5| Step: 7
Training loss: 2.1677498817443848
Validation loss: 2.329733302195867

Epoch: 5| Step: 8
Training loss: 2.6753764152526855
Validation loss: 2.328365216652552

Epoch: 5| Step: 9
Training loss: 2.832371473312378
Validation loss: 2.321472446123759

Epoch: 5| Step: 10
Training loss: 2.9869027137756348
Validation loss: 2.316489855448405

Epoch: 5| Step: 11
Training loss: 2.3107519149780273
Validation loss: 2.318273956576983

Epoch: 61| Step: 0
Training loss: 2.5094258785247803
Validation loss: 2.314590801795324

Epoch: 5| Step: 1
Training loss: 2.8443493843078613
Validation loss: 2.313547114531199

Epoch: 5| Step: 2
Training loss: 2.063045024871826
Validation loss: 2.3111399163802466

Epoch: 5| Step: 3
Training loss: 2.4461770057678223
Validation loss: 2.3108384211858115

Epoch: 5| Step: 4
Training loss: 2.3148577213287354
Validation loss: 2.306133588155111

Epoch: 5| Step: 5
Training loss: 2.4245591163635254
Validation loss: 2.30438802142938

Epoch: 5| Step: 6
Training loss: 2.0904903411865234
Validation loss: 2.3028436601161957

Epoch: 5| Step: 7
Training loss: 2.8029561042785645
Validation loss: 2.3002784152825675

Epoch: 5| Step: 8
Training loss: 2.3399410247802734
Validation loss: 2.3014724105596542

Epoch: 5| Step: 9
Training loss: 3.2309513092041016
Validation loss: 2.2987721314032874

Epoch: 5| Step: 10
Training loss: 2.314042329788208
Validation loss: 2.291603217522303

Epoch: 5| Step: 11
Training loss: 1.5113896131515503
Validation loss: 2.2909053713083267

Epoch: 62| Step: 0
Training loss: 2.501387119293213
Validation loss: 2.2871079444885254

Epoch: 5| Step: 1
Training loss: 2.2650504112243652
Validation loss: 2.2867691218852997

Epoch: 5| Step: 2
Training loss: 2.0979623794555664
Validation loss: 2.2813873241345086

Epoch: 5| Step: 3
Training loss: 2.9767417907714844
Validation loss: 2.283326397339503

Epoch: 5| Step: 4
Training loss: 2.525806188583374
Validation loss: 2.2851009219884872

Epoch: 5| Step: 5
Training loss: 2.7129836082458496
Validation loss: 2.2750383218129477

Epoch: 5| Step: 6
Training loss: 2.491574764251709
Validation loss: 2.2891039550304413

Epoch: 5| Step: 7
Training loss: 2.0372800827026367
Validation loss: 2.27748333911101

Epoch: 5| Step: 8
Training loss: 2.3583645820617676
Validation loss: 2.278538256883621

Epoch: 5| Step: 9
Training loss: 2.6414172649383545
Validation loss: 2.2690496842066445

Epoch: 5| Step: 10
Training loss: 2.1278250217437744
Validation loss: 2.2629377444585166

Epoch: 5| Step: 11
Training loss: 2.956542730331421
Validation loss: 2.269136816263199

Epoch: 63| Step: 0
Training loss: 1.972003698348999
Validation loss: 2.2696974078814187

Epoch: 5| Step: 1
Training loss: 2.1702682971954346
Validation loss: 2.2653276920318604

Epoch: 5| Step: 2
Training loss: 2.83843994140625
Validation loss: 2.265425071120262

Epoch: 5| Step: 3
Training loss: 2.6417031288146973
Validation loss: 2.262740964690844

Epoch: 5| Step: 4
Training loss: 2.4884774684906006
Validation loss: 2.2603926757971444

Epoch: 5| Step: 5
Training loss: 2.7038493156433105
Validation loss: 2.25915257136027

Epoch: 5| Step: 6
Training loss: 2.572693347930908
Validation loss: 2.2533317704995475

Epoch: 5| Step: 7
Training loss: 1.998766303062439
Validation loss: 2.254365419348081

Epoch: 5| Step: 8
Training loss: 2.198301315307617
Validation loss: 2.2525229354699454

Epoch: 5| Step: 9
Training loss: 2.454890251159668
Validation loss: 2.2462176332871118

Epoch: 5| Step: 10
Training loss: 2.533748149871826
Validation loss: 2.2444136639436087

Epoch: 5| Step: 11
Training loss: 2.503880500793457
Validation loss: 2.2409013211727142

Epoch: 64| Step: 0
Training loss: 2.2993063926696777
Validation loss: 2.240820790330569

Epoch: 5| Step: 1
Training loss: 2.2896952629089355
Validation loss: 2.235673407713572

Epoch: 5| Step: 2
Training loss: 2.8618152141571045
Validation loss: 2.2374142507712045

Epoch: 5| Step: 3
Training loss: 2.3016209602355957
Validation loss: 2.2338256488243737

Epoch: 5| Step: 4
Training loss: 2.7647762298583984
Validation loss: 2.2320775290330253

Epoch: 5| Step: 5
Training loss: 1.9538131952285767
Validation loss: 2.2297278294960656

Epoch: 5| Step: 6
Training loss: 2.134000301361084
Validation loss: 2.228511393070221

Epoch: 5| Step: 7
Training loss: 2.3591551780700684
Validation loss: 2.226334730784098

Epoch: 5| Step: 8
Training loss: 2.6210265159606934
Validation loss: 2.22177583972613

Epoch: 5| Step: 9
Training loss: 1.972124457359314
Validation loss: 2.228414793809255

Epoch: 5| Step: 10
Training loss: 2.667299747467041
Validation loss: 2.2190914352734885

Epoch: 5| Step: 11
Training loss: 2.559154748916626
Validation loss: 2.21710404753685

Epoch: 65| Step: 0
Training loss: 2.6645216941833496
Validation loss: 2.218369180957476

Epoch: 5| Step: 1
Training loss: 2.285271167755127
Validation loss: 2.2105760474999747

Epoch: 5| Step: 2
Training loss: 2.2040793895721436
Validation loss: 2.2128760516643524

Epoch: 5| Step: 3
Training loss: 2.122567653656006
Validation loss: 2.2116238375504813

Epoch: 5| Step: 4
Training loss: 2.7773542404174805
Validation loss: 2.211758106946945

Epoch: 5| Step: 5
Training loss: 2.2199435234069824
Validation loss: 2.2074014544487

Epoch: 5| Step: 6
Training loss: 2.505427837371826
Validation loss: 2.2047381599744162

Epoch: 5| Step: 7
Training loss: 2.275214672088623
Validation loss: 2.206019173065821

Epoch: 5| Step: 8
Training loss: 2.287409543991089
Validation loss: 2.2029144863287606

Epoch: 5| Step: 9
Training loss: 2.479670524597168
Validation loss: 2.2016930133104324

Epoch: 5| Step: 10
Training loss: 2.3520944118499756
Validation loss: 2.202990015347799

Epoch: 5| Step: 11
Training loss: 1.1682639122009277
Validation loss: 2.2076874673366547

Epoch: 66| Step: 0
Training loss: 1.9778560400009155
Validation loss: 2.2441677848498025

Epoch: 5| Step: 1
Training loss: 2.513234853744507
Validation loss: 2.2455169459184012

Epoch: 5| Step: 2
Training loss: 2.412473201751709
Validation loss: 2.2339916825294495

Epoch: 5| Step: 3
Training loss: 2.775613784790039
Validation loss: 2.204953615864118

Epoch: 5| Step: 4
Training loss: 2.588567018508911
Validation loss: 2.202043483654658

Epoch: 5| Step: 5
Training loss: 2.218787670135498
Validation loss: 2.199007029334704

Epoch: 5| Step: 6
Training loss: 2.397733211517334
Validation loss: 2.199552377065023

Epoch: 5| Step: 7
Training loss: 2.038161516189575
Validation loss: 2.210001955429713

Epoch: 5| Step: 8
Training loss: 1.9731019735336304
Validation loss: 2.216138963898023

Epoch: 5| Step: 9
Training loss: 2.4393765926361084
Validation loss: 2.222655395666758

Epoch: 5| Step: 10
Training loss: 2.822178363800049
Validation loss: 2.224233622352282

Epoch: 5| Step: 11
Training loss: 2.419778347015381
Validation loss: 2.2219204008579254

Epoch: 67| Step: 0
Training loss: 1.9631860256195068
Validation loss: 2.216481700539589

Epoch: 5| Step: 1
Training loss: 2.369284152984619
Validation loss: 2.2205898662408194

Epoch: 5| Step: 2
Training loss: 2.881730794906616
Validation loss: 2.224541316429774

Epoch: 5| Step: 3
Training loss: 2.8561103343963623
Validation loss: 2.209643691778183

Epoch: 5| Step: 4
Training loss: 2.4290263652801514
Validation loss: 2.2037224570910134

Epoch: 5| Step: 5
Training loss: 2.1424143314361572
Validation loss: 2.1905549317598343

Epoch: 5| Step: 6
Training loss: 2.3794422149658203
Validation loss: 2.1903516948223114

Epoch: 5| Step: 7
Training loss: 2.129873514175415
Validation loss: 2.1859910090764365

Epoch: 5| Step: 8
Training loss: 2.010082721710205
Validation loss: 2.1860285848379135

Epoch: 5| Step: 9
Training loss: 2.2092041969299316
Validation loss: 2.187086815635363

Epoch: 5| Step: 10
Training loss: 2.4777824878692627
Validation loss: 2.1758380929629006

Epoch: 5| Step: 11
Training loss: 2.063993215560913
Validation loss: 2.179635221759478

Epoch: 68| Step: 0
Training loss: 2.7319798469543457
Validation loss: 2.1704309781392417

Epoch: 5| Step: 1
Training loss: 2.138404369354248
Validation loss: 2.16872201859951

Epoch: 5| Step: 2
Training loss: 2.5395030975341797
Validation loss: 2.170989235242208

Epoch: 5| Step: 3
Training loss: 2.610722541809082
Validation loss: 2.1703679213921228

Epoch: 5| Step: 4
Training loss: 2.3146750926971436
Validation loss: 2.1721601635217667

Epoch: 5| Step: 5
Training loss: 1.5127156972885132
Validation loss: 2.172468369205793

Epoch: 5| Step: 6
Training loss: 2.4371492862701416
Validation loss: 2.1727113276720047

Epoch: 5| Step: 7
Training loss: 2.502326726913452
Validation loss: 2.1697334299484887

Epoch: 5| Step: 8
Training loss: 1.7526252269744873
Validation loss: 2.1672851790984473

Epoch: 5| Step: 9
Training loss: 1.9727599620819092
Validation loss: 2.1718059927225113

Epoch: 5| Step: 10
Training loss: 2.844635009765625
Validation loss: 2.170178343852361

Epoch: 5| Step: 11
Training loss: 3.3922064304351807
Validation loss: 2.173107236623764

Epoch: 69| Step: 0
Training loss: 2.111849308013916
Validation loss: 2.1697389682133994

Epoch: 5| Step: 1
Training loss: 2.301337480545044
Validation loss: 2.1689035842816033

Epoch: 5| Step: 2
Training loss: 2.3730733394622803
Validation loss: 2.1643539369106293

Epoch: 5| Step: 3
Training loss: 2.5300872325897217
Validation loss: 2.1640780717134476

Epoch: 5| Step: 4
Training loss: 2.206508159637451
Validation loss: 2.1604498426119485

Epoch: 5| Step: 5
Training loss: 2.378554105758667
Validation loss: 2.161384870608648

Epoch: 5| Step: 6
Training loss: 2.498863935470581
Validation loss: 2.159346893429756

Epoch: 5| Step: 7
Training loss: 2.1561975479125977
Validation loss: 2.1574491759141288

Epoch: 5| Step: 8
Training loss: 2.782735824584961
Validation loss: 2.156290511290232

Epoch: 5| Step: 9
Training loss: 2.042755126953125
Validation loss: 2.158198351661364

Epoch: 5| Step: 10
Training loss: 2.095942974090576
Validation loss: 2.1557006438573203

Epoch: 5| Step: 11
Training loss: 2.4896163940429688
Validation loss: 2.1535897006591163

Epoch: 70| Step: 0
Training loss: 2.232266902923584
Validation loss: 2.151667113105456

Epoch: 5| Step: 1
Training loss: 2.0775694847106934
Validation loss: 2.1526639660199485

Epoch: 5| Step: 2
Training loss: 2.2672672271728516
Validation loss: 2.1449915170669556

Epoch: 5| Step: 3
Training loss: 1.9405677318572998
Validation loss: 2.1464245170354843

Epoch: 5| Step: 4
Training loss: 2.655841112136841
Validation loss: 2.1431997815767923

Epoch: 5| Step: 5
Training loss: 2.9666011333465576
Validation loss: 2.1374503672122955

Epoch: 5| Step: 6
Training loss: 2.4224953651428223
Validation loss: 2.139515688021978

Epoch: 5| Step: 7
Training loss: 2.3116297721862793
Validation loss: 2.1446152726809182

Epoch: 5| Step: 8
Training loss: 2.0622172355651855
Validation loss: 2.143384243051211

Epoch: 5| Step: 9
Training loss: 2.0400426387786865
Validation loss: 2.138175278902054

Epoch: 5| Step: 10
Training loss: 2.203597068786621
Validation loss: 2.139471004406611

Epoch: 5| Step: 11
Training loss: 2.6785082817077637
Validation loss: 2.1373635729153952

Epoch: 71| Step: 0
Training loss: 2.293276309967041
Validation loss: 2.1379309942324958

Epoch: 5| Step: 1
Training loss: 2.7166550159454346
Validation loss: 2.128271092971166

Epoch: 5| Step: 2
Training loss: 1.723339319229126
Validation loss: 2.142364372809728

Epoch: 5| Step: 3
Training loss: 2.0846569538116455
Validation loss: 2.145506203174591

Epoch: 5| Step: 4
Training loss: 1.602170705795288
Validation loss: 2.1468445161978402

Epoch: 5| Step: 5
Training loss: 2.7868270874023438
Validation loss: 2.1451085607210794

Epoch: 5| Step: 6
Training loss: 2.1820149421691895
Validation loss: 2.144747570157051

Epoch: 5| Step: 7
Training loss: 2.323514461517334
Validation loss: 2.144298811753591

Epoch: 5| Step: 8
Training loss: 2.748260498046875
Validation loss: 2.1388412763675055

Epoch: 5| Step: 9
Training loss: 2.346240997314453
Validation loss: 2.138167535265287

Epoch: 5| Step: 10
Training loss: 2.273466110229492
Validation loss: 2.138246029615402

Epoch: 5| Step: 11
Training loss: 3.311351776123047
Validation loss: 2.138756682475408

Epoch: 72| Step: 0
Training loss: 1.9086761474609375
Validation loss: 2.1354297200838723

Epoch: 5| Step: 1
Training loss: 2.2844977378845215
Validation loss: 2.1282921582460403

Epoch: 5| Step: 2
Training loss: 1.9015998840332031
Validation loss: 2.1345707774162292

Epoch: 5| Step: 3
Training loss: 2.8584752082824707
Validation loss: 2.1364507327477136

Epoch: 5| Step: 4
Training loss: 2.511840343475342
Validation loss: 2.131490116318067

Epoch: 5| Step: 5
Training loss: 2.410903215408325
Validation loss: 2.1380219757556915

Epoch: 5| Step: 6
Training loss: 2.2069790363311768
Validation loss: 2.133194178342819

Epoch: 5| Step: 7
Training loss: 2.4849448204040527
Validation loss: 2.1291811217864356

Epoch: 5| Step: 8
Training loss: 1.9879001379013062
Validation loss: 2.1353970567385354

Epoch: 5| Step: 9
Training loss: 2.1992506980895996
Validation loss: 2.1333338816960654

Epoch: 5| Step: 10
Training loss: 2.251676082611084
Validation loss: 2.134275048971176

Epoch: 5| Step: 11
Training loss: 3.2638742923736572
Validation loss: 2.130129208167394

Epoch: 73| Step: 0
Training loss: 2.6127803325653076
Validation loss: 2.1204456786314645

Epoch: 5| Step: 1
Training loss: 1.9996435642242432
Validation loss: 2.115484982728958

Epoch: 5| Step: 2
Training loss: 2.0005574226379395
Validation loss: 2.1237934678792953

Epoch: 5| Step: 3
Training loss: 2.4331817626953125
Validation loss: 2.1214181880156198

Epoch: 5| Step: 4
Training loss: 2.175596237182617
Validation loss: 2.1210241516431174

Epoch: 5| Step: 5
Training loss: 2.378326892852783
Validation loss: 2.101363336046537

Epoch: 5| Step: 6
Training loss: 1.8951261043548584
Validation loss: 2.1104277223348618

Epoch: 5| Step: 7
Training loss: 2.637066602706909
Validation loss: 2.106857647498449

Epoch: 5| Step: 8
Training loss: 2.3666586875915527
Validation loss: 2.1064120133717856

Epoch: 5| Step: 9
Training loss: 2.1786551475524902
Validation loss: 2.1098892043034234

Epoch: 5| Step: 10
Training loss: 2.4403269290924072
Validation loss: 2.1060980558395386

Epoch: 5| Step: 11
Training loss: 1.9346988201141357
Validation loss: 2.1069000164667764

Epoch: 74| Step: 0
Training loss: 2.6265981197357178
Validation loss: 2.112331454952558

Epoch: 5| Step: 1
Training loss: 2.6482608318328857
Validation loss: 2.111718719204267

Epoch: 5| Step: 2
Training loss: 2.079163074493408
Validation loss: 2.111487870415052

Epoch: 5| Step: 3
Training loss: 1.8755041360855103
Validation loss: 2.10855695605278

Epoch: 5| Step: 4
Training loss: 2.253413677215576
Validation loss: 2.1141436646382012

Epoch: 5| Step: 5
Training loss: 1.837156057357788
Validation loss: 2.1093669881423316

Epoch: 5| Step: 6
Training loss: 2.139577627182007
Validation loss: 2.1103245466947556

Epoch: 5| Step: 7
Training loss: 2.996582508087158
Validation loss: 2.108230342467626

Epoch: 5| Step: 8
Training loss: 2.7415690422058105
Validation loss: 2.110441744327545

Epoch: 5| Step: 9
Training loss: 1.679787278175354
Validation loss: 2.1029797991116843

Epoch: 5| Step: 10
Training loss: 2.161221504211426
Validation loss: 2.1070191264152527

Epoch: 5| Step: 11
Training loss: 2.0533623695373535
Validation loss: 2.102927803993225

Epoch: 75| Step: 0
Training loss: 2.0759482383728027
Validation loss: 2.09560297926267

Epoch: 5| Step: 1
Training loss: 2.690768003463745
Validation loss: 2.090865155061086

Epoch: 5| Step: 2
Training loss: 2.318080425262451
Validation loss: 2.0920172333717346

Epoch: 5| Step: 3
Training loss: 1.8652244806289673
Validation loss: 2.0942544490098953

Epoch: 5| Step: 4
Training loss: 2.247973918914795
Validation loss: 2.0936829894781113

Epoch: 5| Step: 5
Training loss: 2.1205766201019287
Validation loss: 2.092716077963511

Epoch: 5| Step: 6
Training loss: 2.297156810760498
Validation loss: 2.0865732034047446

Epoch: 5| Step: 7
Training loss: 2.269710063934326
Validation loss: 2.0807215919097266

Epoch: 5| Step: 8
Training loss: 2.8590004444122314
Validation loss: 2.0783579448858895

Epoch: 5| Step: 9
Training loss: 2.1894474029541016
Validation loss: 2.0811679859956107

Epoch: 5| Step: 10
Training loss: 1.965020775794983
Validation loss: 2.081815257668495

Epoch: 5| Step: 11
Training loss: 1.685784935951233
Validation loss: 2.079253996411959

Epoch: 76| Step: 0
Training loss: 2.586177349090576
Validation loss: 2.084369088212649

Epoch: 5| Step: 1
Training loss: 2.228020429611206
Validation loss: 2.0863391160964966

Epoch: 5| Step: 2
Training loss: 2.110377311706543
Validation loss: 2.0890168249607086

Epoch: 5| Step: 3
Training loss: 2.400941848754883
Validation loss: 2.093695273001989

Epoch: 5| Step: 4
Training loss: 1.818886160850525
Validation loss: 2.0914922455946603

Epoch: 5| Step: 5
Training loss: 2.815380573272705
Validation loss: 2.0942061692476273

Epoch: 5| Step: 6
Training loss: 1.848003625869751
Validation loss: 2.0914975305398307

Epoch: 5| Step: 7
Training loss: 2.3122808933258057
Validation loss: 2.088507557908694

Epoch: 5| Step: 8
Training loss: 2.092602491378784
Validation loss: 2.0858849734067917

Epoch: 5| Step: 9
Training loss: 2.2847561836242676
Validation loss: 2.0815365612506866

Epoch: 5| Step: 10
Training loss: 2.2652549743652344
Validation loss: 2.082521771391233

Epoch: 5| Step: 11
Training loss: 2.6803548336029053
Validation loss: 2.0706102401018143

Epoch: 77| Step: 0
Training loss: 2.3180642127990723
Validation loss: 2.073776205380758

Epoch: 5| Step: 1
Training loss: 2.0817923545837402
Validation loss: 2.0835756808519363

Epoch: 5| Step: 2
Training loss: 2.26993989944458
Validation loss: 2.088441173235575

Epoch: 5| Step: 3
Training loss: 1.9442249536514282
Validation loss: 2.090472216407458

Epoch: 5| Step: 4
Training loss: 2.693692684173584
Validation loss: 2.0995662063360214

Epoch: 5| Step: 5
Training loss: 2.2582268714904785
Validation loss: 2.1038778573274612

Epoch: 5| Step: 6
Training loss: 2.0496551990509033
Validation loss: 2.094508876403173

Epoch: 5| Step: 7
Training loss: 2.4150443077087402
Validation loss: 2.0858342200517654

Epoch: 5| Step: 8
Training loss: 2.3028976917266846
Validation loss: 2.079768270254135

Epoch: 5| Step: 9
Training loss: 2.2198338508605957
Validation loss: 2.0767745673656464

Epoch: 5| Step: 10
Training loss: 2.1758179664611816
Validation loss: 2.058318609992663

Epoch: 5| Step: 11
Training loss: 2.5935657024383545
Validation loss: 2.0654141008853912

Epoch: 78| Step: 0
Training loss: 1.7758207321166992
Validation loss: 2.068479537963867

Epoch: 5| Step: 1
Training loss: 2.3232455253601074
Validation loss: 2.0667013128598533

Epoch: 5| Step: 2
Training loss: 2.6361823081970215
Validation loss: 2.071859429279963

Epoch: 5| Step: 3
Training loss: 2.1515746116638184
Validation loss: 2.0699774076541266

Epoch: 5| Step: 4
Training loss: 2.299680471420288
Validation loss: 2.076292266448339

Epoch: 5| Step: 5
Training loss: 2.693643093109131
Validation loss: 2.0800259709358215

Epoch: 5| Step: 6
Training loss: 2.7681095600128174
Validation loss: 2.075590173403422

Epoch: 5| Step: 7
Training loss: 2.042999744415283
Validation loss: 2.0644812136888504

Epoch: 5| Step: 8
Training loss: 2.0255494117736816
Validation loss: 2.055597191055616

Epoch: 5| Step: 9
Training loss: 1.7210330963134766
Validation loss: 2.0526446302731833

Epoch: 5| Step: 10
Training loss: 2.0143275260925293
Validation loss: 2.0581067303816476

Epoch: 5| Step: 11
Training loss: 3.093445301055908
Validation loss: 2.060407886902491

Epoch: 79| Step: 0
Training loss: 2.346724510192871
Validation loss: 2.0520876000324884

Epoch: 5| Step: 1
Training loss: 2.032472610473633
Validation loss: 2.055341958999634

Epoch: 5| Step: 2
Training loss: 2.3537540435791016
Validation loss: 2.0536850492159524

Epoch: 5| Step: 3
Training loss: 2.1639211177825928
Validation loss: 2.0478615760803223

Epoch: 5| Step: 4
Training loss: 1.8026758432388306
Validation loss: 2.0499116480350494

Epoch: 5| Step: 5
Training loss: 2.0818681716918945
Validation loss: 2.04514479637146

Epoch: 5| Step: 6
Training loss: 2.7755649089813232
Validation loss: 2.0402891288201013

Epoch: 5| Step: 7
Training loss: 2.1142618656158447
Validation loss: 2.0508218705654144

Epoch: 5| Step: 8
Training loss: 2.210073709487915
Validation loss: 2.042163555820783

Epoch: 5| Step: 9
Training loss: 1.7723808288574219
Validation loss: 2.046894227464994

Epoch: 5| Step: 10
Training loss: 2.6967873573303223
Validation loss: 2.055562491218249

Epoch: 5| Step: 11
Training loss: 3.2064566612243652
Validation loss: 2.0496117075284324

Epoch: 80| Step: 0
Training loss: 1.436943769454956
Validation loss: 2.059596354762713

Epoch: 5| Step: 1
Training loss: 2.3824195861816406
Validation loss: 2.056036353111267

Epoch: 5| Step: 2
Training loss: 2.1940667629241943
Validation loss: 2.052683929602305

Epoch: 5| Step: 3
Training loss: 2.4316020011901855
Validation loss: 2.04886927207311

Epoch: 5| Step: 4
Training loss: 2.18841290473938
Validation loss: 2.0515938699245453

Epoch: 5| Step: 5
Training loss: 1.7276325225830078
Validation loss: 2.045167704423269

Epoch: 5| Step: 6
Training loss: 2.9918324947357178
Validation loss: 2.046463986237844

Epoch: 5| Step: 7
Training loss: 2.2413437366485596
Validation loss: 2.0438326795895896

Epoch: 5| Step: 8
Training loss: 2.267728328704834
Validation loss: 2.049457460641861

Epoch: 5| Step: 9
Training loss: 2.0310375690460205
Validation loss: 2.0425485372543335

Epoch: 5| Step: 10
Training loss: 2.579665422439575
Validation loss: 2.0583725571632385

Epoch: 5| Step: 11
Training loss: 2.2710485458374023
Validation loss: 2.063916136821111

Epoch: 81| Step: 0
Training loss: 3.007474422454834
Validation loss: 2.060626129309336

Epoch: 5| Step: 1
Training loss: 1.7467072010040283
Validation loss: 2.05149677892526

Epoch: 5| Step: 2
Training loss: 2.575977325439453
Validation loss: 2.047733257214228

Epoch: 5| Step: 3
Training loss: 1.678972601890564
Validation loss: 2.0495533496141434

Epoch: 5| Step: 4
Training loss: 2.2295260429382324
Validation loss: 2.063041011492411

Epoch: 5| Step: 5
Training loss: 2.435495138168335
Validation loss: 2.056927964091301

Epoch: 5| Step: 6
Training loss: 2.1804592609405518
Validation loss: 2.0538480828205743

Epoch: 5| Step: 7
Training loss: 2.5859456062316895
Validation loss: 2.0545651664336524

Epoch: 5| Step: 8
Training loss: 2.3150506019592285
Validation loss: 2.0319102704524994

Epoch: 5| Step: 9
Training loss: 2.0079612731933594
Validation loss: 2.0377092907826104

Epoch: 5| Step: 10
Training loss: 2.098489284515381
Validation loss: 2.032861386736234

Epoch: 5| Step: 11
Training loss: 0.2541698217391968
Validation loss: 2.042996401588122

Epoch: 82| Step: 0
Training loss: 2.3509392738342285
Validation loss: 2.048715740442276

Epoch: 5| Step: 1
Training loss: 2.0278124809265137
Validation loss: 2.0556903878847756

Epoch: 5| Step: 2
Training loss: 2.125129461288452
Validation loss: 2.0558917075395584

Epoch: 5| Step: 3
Training loss: 1.9867846965789795
Validation loss: 2.0497685968875885

Epoch: 5| Step: 4
Training loss: 2.1521713733673096
Validation loss: 2.048338388403257

Epoch: 5| Step: 5
Training loss: 2.502758026123047
Validation loss: 2.048495873808861

Epoch: 5| Step: 6
Training loss: 2.2665092945098877
Validation loss: 2.0294406513373056

Epoch: 5| Step: 7
Training loss: 2.6274304389953613
Validation loss: 2.0404013097286224

Epoch: 5| Step: 8
Training loss: 2.5220537185668945
Validation loss: 2.0488932530085244

Epoch: 5| Step: 9
Training loss: 1.8355830907821655
Validation loss: 2.0561251044273376

Epoch: 5| Step: 10
Training loss: 2.3543243408203125
Validation loss: 2.0552335530519485

Epoch: 5| Step: 11
Training loss: 1.448773980140686
Validation loss: 2.05817844470342

Epoch: 83| Step: 0
Training loss: 1.8492166996002197
Validation loss: 2.0576912264029183

Epoch: 5| Step: 1
Training loss: 2.3265719413757324
Validation loss: 2.057283192873001

Epoch: 5| Step: 2
Training loss: 2.756699800491333
Validation loss: 2.048004299402237

Epoch: 5| Step: 3
Training loss: 2.141876220703125
Validation loss: 2.03979983429114

Epoch: 5| Step: 4
Training loss: 1.730851411819458
Validation loss: 2.039581606785456

Epoch: 5| Step: 5
Training loss: 2.3063623905181885
Validation loss: 2.044248898824056

Epoch: 5| Step: 6
Training loss: 2.6841235160827637
Validation loss: 2.0356862545013428

Epoch: 5| Step: 7
Training loss: 2.233924388885498
Validation loss: 2.0289697597424188

Epoch: 5| Step: 8
Training loss: 2.106517791748047
Validation loss: 2.0296039382616677

Epoch: 5| Step: 9
Training loss: 2.142192840576172
Validation loss: 2.0292550722757974

Epoch: 5| Step: 10
Training loss: 1.7986921072006226
Validation loss: 2.030327707529068

Epoch: 5| Step: 11
Training loss: 2.9489097595214844
Validation loss: 2.032048682371775

Epoch: 84| Step: 0
Training loss: 2.489243745803833
Validation loss: 2.0387036303679147

Epoch: 5| Step: 1
Training loss: 2.0078673362731934
Validation loss: 2.0475166042645774

Epoch: 5| Step: 2
Training loss: 2.4421725273132324
Validation loss: 2.051475077867508

Epoch: 5| Step: 3
Training loss: 2.6921370029449463
Validation loss: 2.052091379960378

Epoch: 5| Step: 4
Training loss: 1.8537896871566772
Validation loss: 2.038037195801735

Epoch: 5| Step: 5
Training loss: 2.3817880153656006
Validation loss: 2.043273682395617

Epoch: 5| Step: 6
Training loss: 1.7576684951782227
Validation loss: 2.0334658523400626

Epoch: 5| Step: 7
Training loss: 2.276670455932617
Validation loss: 2.0263508607943854

Epoch: 5| Step: 8
Training loss: 1.909581184387207
Validation loss: 2.0408833771944046

Epoch: 5| Step: 9
Training loss: 1.8642146587371826
Validation loss: 2.041688839594523

Epoch: 5| Step: 10
Training loss: 2.3751091957092285
Validation loss: 2.035644402106603

Epoch: 5| Step: 11
Training loss: 3.7475967407226562
Validation loss: 2.0339731574058533

Epoch: 85| Step: 0
Training loss: 2.4668452739715576
Validation loss: 2.0401676843563714

Epoch: 5| Step: 1
Training loss: 2.5050246715545654
Validation loss: 2.0254387011130652

Epoch: 5| Step: 2
Training loss: 2.771233320236206
Validation loss: 2.026179393132528

Epoch: 5| Step: 3
Training loss: 1.4428136348724365
Validation loss: 2.02557165424029

Epoch: 5| Step: 4
Training loss: 1.90093195438385
Validation loss: 2.0372977753480277

Epoch: 5| Step: 5
Training loss: 2.0153489112854004
Validation loss: 2.0407764613628387

Epoch: 5| Step: 6
Training loss: 2.533797264099121
Validation loss: 2.036032805840174

Epoch: 5| Step: 7
Training loss: 1.8403542041778564
Validation loss: 2.0319890876611075

Epoch: 5| Step: 8
Training loss: 1.718340277671814
Validation loss: 2.0313004155953727

Epoch: 5| Step: 9
Training loss: 1.852219820022583
Validation loss: 2.0292072196801505

Epoch: 5| Step: 10
Training loss: 2.7186808586120605
Validation loss: 2.0216623644034066

Epoch: 5| Step: 11
Training loss: 3.7593979835510254
Validation loss: 2.0320021510124207

Epoch: 86| Step: 0
Training loss: 2.3683104515075684
Validation loss: 2.0322201450665793

Epoch: 5| Step: 1
Training loss: 2.1136322021484375
Validation loss: 2.0373669862747192

Epoch: 5| Step: 2
Training loss: 2.0243260860443115
Validation loss: 2.0258554418881736

Epoch: 5| Step: 3
Training loss: 2.153715133666992
Validation loss: 2.0345386316378913

Epoch: 5| Step: 4
Training loss: 2.5637028217315674
Validation loss: 2.04097226758798

Epoch: 5| Step: 5
Training loss: 2.1470563411712646
Validation loss: 2.0401237308979034

Epoch: 5| Step: 6
Training loss: 2.0671935081481934
Validation loss: 2.041160653034846

Epoch: 5| Step: 7
Training loss: 1.879533052444458
Validation loss: 2.0376639664173126

Epoch: 5| Step: 8
Training loss: 2.8282008171081543
Validation loss: 2.0431707402070365

Epoch: 5| Step: 9
Training loss: 2.441528797149658
Validation loss: 2.034224266807238

Epoch: 5| Step: 10
Training loss: 1.694471001625061
Validation loss: 2.0345234473546348

Epoch: 5| Step: 11
Training loss: 1.6809465885162354
Validation loss: 2.0279096265633902

Epoch: 87| Step: 0
Training loss: 2.707487106323242
Validation loss: 2.034493386745453

Epoch: 5| Step: 1
Training loss: 2.008709669113159
Validation loss: 2.0382369458675385

Epoch: 5| Step: 2
Training loss: 1.8028910160064697
Validation loss: 2.0384033918380737

Epoch: 5| Step: 3
Training loss: 2.0421385765075684
Validation loss: 2.03850220143795

Epoch: 5| Step: 4
Training loss: 2.215520143508911
Validation loss: 2.0407062023878098

Epoch: 5| Step: 5
Training loss: 1.9673675298690796
Validation loss: 2.0336462507645288

Epoch: 5| Step: 6
Training loss: 2.246124744415283
Validation loss: 2.036762868364652

Epoch: 5| Step: 7
Training loss: 2.1796231269836426
Validation loss: 2.029123996694883

Epoch: 5| Step: 8
Training loss: 2.203329563140869
Validation loss: 2.0294610261917114

Epoch: 5| Step: 9
Training loss: 2.2589993476867676
Validation loss: 2.021049211422602

Epoch: 5| Step: 10
Training loss: 2.4536795616149902
Validation loss: 2.016873612999916

Epoch: 5| Step: 11
Training loss: 2.7069292068481445
Validation loss: 2.0250488420327506

Epoch: 88| Step: 0
Training loss: 1.9473400115966797
Validation loss: 2.0244171172380447

Epoch: 5| Step: 1
Training loss: 2.2043235301971436
Validation loss: 2.0242893298467

Epoch: 5| Step: 2
Training loss: 2.775380849838257
Validation loss: 2.0236092458168664

Epoch: 5| Step: 3
Training loss: 1.8071407079696655
Validation loss: 2.0196826259295144

Epoch: 5| Step: 4
Training loss: 2.1849770545959473
Validation loss: 2.0246852934360504

Epoch: 5| Step: 5
Training loss: 2.349608898162842
Validation loss: 2.0200527807076774

Epoch: 5| Step: 6
Training loss: 2.9438931941986084
Validation loss: 2.0141729364792504

Epoch: 5| Step: 7
Training loss: 2.181967258453369
Validation loss: 2.0278037389119468

Epoch: 5| Step: 8
Training loss: 2.1556167602539062
Validation loss: 2.0183850030104318

Epoch: 5| Step: 9
Training loss: 1.5371694564819336
Validation loss: 2.0251328150431314

Epoch: 5| Step: 10
Training loss: 1.7294641733169556
Validation loss: 2.0198413083950677

Epoch: 5| Step: 11
Training loss: 3.1033129692077637
Validation loss: 2.0302131921052933

Epoch: 89| Step: 0
Training loss: 1.6422303915023804
Validation loss: 2.0138980795939765

Epoch: 5| Step: 1
Training loss: 2.1853280067443848
Validation loss: 2.028820723295212

Epoch: 5| Step: 2
Training loss: 2.0669541358947754
Validation loss: 2.0251448353131614

Epoch: 5| Step: 3
Training loss: 1.9050991535186768
Validation loss: 2.0238941311836243

Epoch: 5| Step: 4
Training loss: 2.336477041244507
Validation loss: 2.0325261453787484

Epoch: 5| Step: 5
Training loss: 2.3914947509765625
Validation loss: 2.0332363744576774

Epoch: 5| Step: 6
Training loss: 2.2243621349334717
Validation loss: 2.0277782529592514

Epoch: 5| Step: 7
Training loss: 2.0155768394470215
Validation loss: 2.033628821372986

Epoch: 5| Step: 8
Training loss: 2.373599052429199
Validation loss: 2.042989358305931

Epoch: 5| Step: 9
Training loss: 2.421705961227417
Validation loss: 2.0352281580368676

Epoch: 5| Step: 10
Training loss: 2.2768349647521973
Validation loss: 2.0241188456614814

Epoch: 5| Step: 11
Training loss: 2.266620635986328
Validation loss: 2.026580428083738

Epoch: 90| Step: 0
Training loss: 1.932424545288086
Validation loss: 2.0246398697296777

Epoch: 5| Step: 1
Training loss: 2.207188129425049
Validation loss: 2.0283683637777963

Epoch: 5| Step: 2
Training loss: 2.2818074226379395
Validation loss: 2.017862935860952

Epoch: 5| Step: 3
Training loss: 2.160177707672119
Validation loss: 2.0199439028898873

Epoch: 5| Step: 4
Training loss: 2.035179376602173
Validation loss: 2.0272258122762046

Epoch: 5| Step: 5
Training loss: 2.050266742706299
Validation loss: 2.027260502179464

Epoch: 5| Step: 6
Training loss: 2.4463508129119873
Validation loss: 2.023091971874237

Epoch: 5| Step: 7
Training loss: 2.125113010406494
Validation loss: 2.02459180355072

Epoch: 5| Step: 8
Training loss: 2.536013603210449
Validation loss: 2.027428299188614

Epoch: 5| Step: 9
Training loss: 2.1472015380859375
Validation loss: 2.0350498209396997

Epoch: 5| Step: 10
Training loss: 1.9125077724456787
Validation loss: 2.021626869837443

Epoch: 5| Step: 11
Training loss: 2.3502886295318604
Validation loss: 2.02379302183787

Epoch: 91| Step: 0
Training loss: 1.857781171798706
Validation loss: 2.047151247660319

Epoch: 5| Step: 1
Training loss: 2.552825689315796
Validation loss: 2.0691780547300973

Epoch: 5| Step: 2
Training loss: 2.2195916175842285
Validation loss: 2.0954944690068564

Epoch: 5| Step: 3
Training loss: 2.6536948680877686
Validation loss: 2.0808493395646415

Epoch: 5| Step: 4
Training loss: 1.634932279586792
Validation loss: 2.074116051197052

Epoch: 5| Step: 5
Training loss: 2.6292693614959717
Validation loss: 2.062306438883146

Epoch: 5| Step: 6
Training loss: 2.6771697998046875
Validation loss: 2.048476388057073

Epoch: 5| Step: 7
Training loss: 1.9709970951080322
Validation loss: 2.0331656287113824

Epoch: 5| Step: 8
Training loss: 1.627445936203003
Validation loss: 2.019721180200577

Epoch: 5| Step: 9
Training loss: 2.469869613647461
Validation loss: 2.0299802174170813

Epoch: 5| Step: 10
Training loss: 2.1135005950927734
Validation loss: 2.0381287982066474

Epoch: 5| Step: 11
Training loss: 1.7416374683380127
Validation loss: 2.0430991450945535

Epoch: 92| Step: 0
Training loss: 2.491209030151367
Validation loss: 2.0441406865914664

Epoch: 5| Step: 1
Training loss: 1.6679586172103882
Validation loss: 2.0359726548194885

Epoch: 5| Step: 2
Training loss: 2.1510989665985107
Validation loss: 2.0463792284329734

Epoch: 5| Step: 3
Training loss: 2.19063663482666
Validation loss: 2.04207651813825

Epoch: 5| Step: 4
Training loss: 1.8531525135040283
Validation loss: 2.0463639895121255

Epoch: 5| Step: 5
Training loss: 2.305056571960449
Validation loss: 2.0431866894165673

Epoch: 5| Step: 6
Training loss: 2.546998977661133
Validation loss: 2.034151961406072

Epoch: 5| Step: 7
Training loss: 2.147927761077881
Validation loss: 2.0408843755722046

Epoch: 5| Step: 8
Training loss: 2.4576480388641357
Validation loss: 2.0389868766069412

Epoch: 5| Step: 9
Training loss: 2.428831100463867
Validation loss: 2.033821165561676

Epoch: 5| Step: 10
Training loss: 1.8446242809295654
Validation loss: 2.032585700352987

Epoch: 5| Step: 11
Training loss: 2.4651787281036377
Validation loss: 2.013208289941152

Epoch: 93| Step: 0
Training loss: 2.2009799480438232
Validation loss: 2.0153534561395645

Epoch: 5| Step: 1
Training loss: 1.8692913055419922
Validation loss: 2.0174683233102164

Epoch: 5| Step: 2
Training loss: 2.0040745735168457
Validation loss: 2.024433429042498

Epoch: 5| Step: 3
Training loss: 2.311447858810425
Validation loss: 2.0229542404413223

Epoch: 5| Step: 4
Training loss: 1.6009647846221924
Validation loss: 2.040749246875445

Epoch: 5| Step: 5
Training loss: 2.094425678253174
Validation loss: 2.032071848710378

Epoch: 5| Step: 6
Training loss: 2.0999817848205566
Validation loss: 2.043123876055082

Epoch: 5| Step: 7
Training loss: 2.4567718505859375
Validation loss: 2.0389293978611627

Epoch: 5| Step: 8
Training loss: 2.4239604473114014
Validation loss: 2.0324648718039193

Epoch: 5| Step: 9
Training loss: 2.3764820098876953
Validation loss: 2.02882448832194

Epoch: 5| Step: 10
Training loss: 2.052449941635132
Validation loss: 2.0141624559958777

Epoch: 5| Step: 11
Training loss: 3.977599620819092
Validation loss: 2.0190191517273584

Epoch: 94| Step: 0
Training loss: 2.5445969104766846
Validation loss: 2.017703672250112

Epoch: 5| Step: 1
Training loss: 1.4366486072540283
Validation loss: 2.0215233514706292

Epoch: 5| Step: 2
Training loss: 2.396048069000244
Validation loss: 2.033243695894877

Epoch: 5| Step: 3
Training loss: 2.5772054195404053
Validation loss: 2.039041186372439

Epoch: 5| Step: 4
Training loss: 2.426006317138672
Validation loss: 2.044210116068522

Epoch: 5| Step: 5
Training loss: 2.377683401107788
Validation loss: 2.0339939097563424

Epoch: 5| Step: 6
Training loss: 2.0594897270202637
Validation loss: 2.039502337574959

Epoch: 5| Step: 7
Training loss: 2.4186389446258545
Validation loss: 2.039186323682467

Epoch: 5| Step: 8
Training loss: 1.8779815435409546
Validation loss: 2.04282553990682

Epoch: 5| Step: 9
Training loss: 2.063955545425415
Validation loss: 2.0386716624101004

Epoch: 5| Step: 10
Training loss: 1.9509986639022827
Validation loss: 2.0300920754671097

Epoch: 5| Step: 11
Training loss: 2.107463836669922
Validation loss: 2.0349122981230416

Epoch: 95| Step: 0
Training loss: 2.1457462310791016
Validation loss: 2.022948150833448

Epoch: 5| Step: 1
Training loss: 1.9342470169067383
Validation loss: 2.0285524229208627

Epoch: 5| Step: 2
Training loss: 2.2397289276123047
Validation loss: 2.024801899989446

Epoch: 5| Step: 3
Training loss: 1.6549524068832397
Validation loss: 2.0275512288014093

Epoch: 5| Step: 4
Training loss: 1.786659598350525
Validation loss: 2.017244125405947

Epoch: 5| Step: 5
Training loss: 2.0096054077148438
Validation loss: 2.013705258568128

Epoch: 5| Step: 6
Training loss: 2.555957794189453
Validation loss: 2.02030119796594

Epoch: 5| Step: 7
Training loss: 2.5276474952697754
Validation loss: 2.026222954193751

Epoch: 5| Step: 8
Training loss: 2.034447431564331
Validation loss: 2.034217357635498

Epoch: 5| Step: 9
Training loss: 2.4708943367004395
Validation loss: 2.0321970929702124

Epoch: 5| Step: 10
Training loss: 2.6030871868133545
Validation loss: 2.040731350580851

Epoch: 5| Step: 11
Training loss: 2.0593931674957275
Validation loss: 2.0346749325593314

Epoch: 96| Step: 0
Training loss: 1.7475156784057617
Validation loss: 2.0333276242017746

Epoch: 5| Step: 1
Training loss: 2.585756778717041
Validation loss: 2.026877904931704

Epoch: 5| Step: 2
Training loss: 1.8228180408477783
Validation loss: 2.0305976569652557

Epoch: 5| Step: 3
Training loss: 2.2876086235046387
Validation loss: 2.0201717019081116

Epoch: 5| Step: 4
Training loss: 2.165679454803467
Validation loss: 2.0199146221081414

Epoch: 5| Step: 5
Training loss: 1.8351097106933594
Validation loss: 2.0284362584352493

Epoch: 5| Step: 6
Training loss: 2.346788167953491
Validation loss: 2.03049236536026

Epoch: 5| Step: 7
Training loss: 2.20566987991333
Validation loss: 2.0176736811796823

Epoch: 5| Step: 8
Training loss: 2.5034878253936768
Validation loss: 2.026595671971639

Epoch: 5| Step: 9
Training loss: 2.3626580238342285
Validation loss: 2.0221208035945892

Epoch: 5| Step: 10
Training loss: 1.9487634897232056
Validation loss: 2.023952732483546

Epoch: 5| Step: 11
Training loss: 1.6791075468063354
Validation loss: 2.00693445901076

Epoch: 97| Step: 0
Training loss: 2.1286418437957764
Validation loss: 2.010115832090378

Epoch: 5| Step: 1
Training loss: 2.335320472717285
Validation loss: 2.008688266078631

Epoch: 5| Step: 2
Training loss: 2.2944822311401367
Validation loss: 2.026312837998072

Epoch: 5| Step: 3
Training loss: 1.677851676940918
Validation loss: 2.027996152639389

Epoch: 5| Step: 4
Training loss: 2.404910087585449
Validation loss: 2.022256607810656

Epoch: 5| Step: 5
Training loss: 2.043602228164673
Validation loss: 2.035363326470057

Epoch: 5| Step: 6
Training loss: 2.462691068649292
Validation loss: 2.025283748904864

Epoch: 5| Step: 7
Training loss: 2.1154961585998535
Validation loss: 2.0318009754021964

Epoch: 5| Step: 8
Training loss: 2.3589606285095215
Validation loss: 2.0299009631077447

Epoch: 5| Step: 9
Training loss: 2.3903510570526123
Validation loss: 2.024791737397512

Epoch: 5| Step: 10
Training loss: 1.971693754196167
Validation loss: 2.013341893752416

Epoch: 5| Step: 11
Training loss: 0.9915400743484497
Validation loss: 2.012199858824412

Epoch: 98| Step: 0
Training loss: 2.294893741607666
Validation loss: 2.009355147679647

Epoch: 5| Step: 1
Training loss: 2.2647292613983154
Validation loss: 2.0148158172766366

Epoch: 5| Step: 2
Training loss: 1.7877143621444702
Validation loss: 2.032890891035398

Epoch: 5| Step: 3
Training loss: 2.2365431785583496
Validation loss: 2.0445137321949005

Epoch: 5| Step: 4
Training loss: 1.9613479375839233
Validation loss: 2.0477622350056968

Epoch: 5| Step: 5
Training loss: 2.1414499282836914
Validation loss: 2.0355385094881058

Epoch: 5| Step: 6
Training loss: 2.335420608520508
Validation loss: 2.034265950322151

Epoch: 5| Step: 7
Training loss: 2.3583195209503174
Validation loss: 2.0262685865163803

Epoch: 5| Step: 8
Training loss: 2.6143829822540283
Validation loss: 2.0159518073002496

Epoch: 5| Step: 9
Training loss: 2.107348918914795
Validation loss: 2.020645643273989

Epoch: 5| Step: 10
Training loss: 1.8781967163085938
Validation loss: 2.0155414243539176

Epoch: 5| Step: 11
Training loss: 1.7292866706848145
Validation loss: 2.018569141626358

Epoch: 99| Step: 0
Training loss: 2.368479013442993
Validation loss: 2.016310085852941

Epoch: 5| Step: 1
Training loss: 2.13901948928833
Validation loss: 2.0218282639980316

Epoch: 5| Step: 2
Training loss: 1.7991936206817627
Validation loss: 2.0253628492355347

Epoch: 5| Step: 3
Training loss: 1.9966989755630493
Validation loss: 2.0268869350353875

Epoch: 5| Step: 4
Training loss: 1.740740180015564
Validation loss: 2.030559410651525

Epoch: 5| Step: 5
Training loss: 2.08670973777771
Validation loss: 2.033022870620092

Epoch: 5| Step: 6
Training loss: 2.9708168506622314
Validation loss: 2.0322958528995514

Epoch: 5| Step: 7
Training loss: 2.01664400100708
Validation loss: 2.014967232942581

Epoch: 5| Step: 8
Training loss: 2.3260748386383057
Validation loss: 2.0214945723613105

Epoch: 5| Step: 9
Training loss: 2.4300081729888916
Validation loss: 2.024860978126526

Epoch: 5| Step: 10
Training loss: 1.8601402044296265
Validation loss: 2.0162535905838013

Epoch: 5| Step: 11
Training loss: 2.115349292755127
Validation loss: 2.0148593932390213

Epoch: 100| Step: 0
Training loss: 2.439793109893799
Validation loss: 2.01430614789327

Epoch: 5| Step: 1
Training loss: 1.9550682306289673
Validation loss: 2.0130070795615516

Epoch: 5| Step: 2
Training loss: 1.80007803440094
Validation loss: 2.023825446764628

Epoch: 5| Step: 3
Training loss: 2.0056684017181396
Validation loss: 2.031141474843025

Epoch: 5| Step: 4
Training loss: 2.245835781097412
Validation loss: 2.0346789260705314

Epoch: 5| Step: 5
Training loss: 1.81418776512146
Validation loss: 2.029294048746427

Epoch: 5| Step: 6
Training loss: 2.1528704166412354
Validation loss: 2.0276004324356713

Epoch: 5| Step: 7
Training loss: 1.9790716171264648
Validation loss: 2.031901180744171

Epoch: 5| Step: 8
Training loss: 2.6413676738739014
Validation loss: 2.028196449081103

Epoch: 5| Step: 9
Training loss: 2.5178627967834473
Validation loss: 2.0269252955913544

Epoch: 5| Step: 10
Training loss: 2.1358752250671387
Validation loss: 2.022856613000234

Epoch: 5| Step: 11
Training loss: 2.587306261062622
Validation loss: 2.021841357151667

Epoch: 101| Step: 0
Training loss: 1.780177354812622
Validation loss: 2.012447645266851

Epoch: 5| Step: 1
Training loss: 1.7073948383331299
Validation loss: 2.0207108656565347

Epoch: 5| Step: 2
Training loss: 1.9431415796279907
Validation loss: 2.0433857093254724

Epoch: 5| Step: 3
Training loss: 2.243487596511841
Validation loss: 2.052106186747551

Epoch: 5| Step: 4
Training loss: 2.1975150108337402
Validation loss: 2.0523888866106668

Epoch: 5| Step: 5
Training loss: 2.0979628562927246
Validation loss: 2.042531351248423

Epoch: 5| Step: 6
Training loss: 2.1178042888641357
Validation loss: 2.02700237929821

Epoch: 5| Step: 7
Training loss: 2.2667548656463623
Validation loss: 2.0250987112522125

Epoch: 5| Step: 8
Training loss: 2.498446226119995
Validation loss: 2.016754557689031

Epoch: 5| Step: 9
Training loss: 2.7912564277648926
Validation loss: 2.017072021961212

Epoch: 5| Step: 10
Training loss: 2.2553019523620605
Validation loss: 2.012319415807724

Epoch: 5| Step: 11
Training loss: 2.243320941925049
Validation loss: 2.008136510848999

Epoch: 102| Step: 0
Training loss: 2.0619614124298096
Validation loss: 2.0093927830457687

Epoch: 5| Step: 1
Training loss: 2.351562023162842
Validation loss: 2.0159967988729477

Epoch: 5| Step: 2
Training loss: 1.6542505025863647
Validation loss: 2.0225724081198373

Epoch: 5| Step: 3
Training loss: 2.396545886993408
Validation loss: 2.027315780520439

Epoch: 5| Step: 4
Training loss: 2.5243418216705322
Validation loss: 2.0336245795090995

Epoch: 5| Step: 5
Training loss: 2.1911356449127197
Validation loss: 2.0351079801718392

Epoch: 5| Step: 6
Training loss: 2.327238082885742
Validation loss: 2.0290503253539405

Epoch: 5| Step: 7
Training loss: 2.2754502296447754
Validation loss: 2.0359010845422745

Epoch: 5| Step: 8
Training loss: 1.8439743518829346
Validation loss: 2.018074249227842

Epoch: 5| Step: 9
Training loss: 2.2521636486053467
Validation loss: 2.0074589351812997

Epoch: 5| Step: 10
Training loss: 1.783526062965393
Validation loss: 2.0078595032294593

Epoch: 5| Step: 11
Training loss: 3.1381754875183105
Validation loss: 2.002801979581515

Epoch: 103| Step: 0
Training loss: 2.30723237991333
Validation loss: 2.01333150267601

Epoch: 5| Step: 1
Training loss: 2.115438461303711
Validation loss: 2.0161540309588113

Epoch: 5| Step: 2
Training loss: 1.9655392169952393
Validation loss: 2.016984070340792

Epoch: 5| Step: 3
Training loss: 1.61785888671875
Validation loss: 2.01589734852314

Epoch: 5| Step: 4
Training loss: 2.4238648414611816
Validation loss: 2.0245335598786673

Epoch: 5| Step: 5
Training loss: 1.8676197528839111
Validation loss: 2.0355452597141266

Epoch: 5| Step: 6
Training loss: 2.0111217498779297
Validation loss: 2.0278141498565674

Epoch: 5| Step: 7
Training loss: 2.6729698181152344
Validation loss: 2.0432405372460685

Epoch: 5| Step: 8
Training loss: 2.0053391456604004
Validation loss: 2.0203554928302765

Epoch: 5| Step: 9
Training loss: 2.0702731609344482
Validation loss: 2.0159854739904404

Epoch: 5| Step: 10
Training loss: 2.3115272521972656
Validation loss: 2.0202403465906777

Epoch: 5| Step: 11
Training loss: 3.694145679473877
Validation loss: 2.016684820254644

Epoch: 104| Step: 0
Training loss: 2.2512660026550293
Validation loss: 2.0138495912154517

Epoch: 5| Step: 1
Training loss: 1.9030319452285767
Validation loss: 2.0209667533636093

Epoch: 5| Step: 2
Training loss: 2.411616802215576
Validation loss: 2.019549379746119

Epoch: 5| Step: 3
Training loss: 1.6526867151260376
Validation loss: 2.02447480460008

Epoch: 5| Step: 4
Training loss: 2.2197787761688232
Validation loss: 2.0167616804440818

Epoch: 5| Step: 5
Training loss: 1.7511861324310303
Validation loss: 2.0250398417313895

Epoch: 5| Step: 6
Training loss: 2.494405746459961
Validation loss: 2.0475360254446664

Epoch: 5| Step: 7
Training loss: 1.8103382587432861
Validation loss: 2.0274337430795035

Epoch: 5| Step: 8
Training loss: 2.4931278228759766
Validation loss: 2.0286107709010444

Epoch: 5| Step: 9
Training loss: 2.472677230834961
Validation loss: 2.0447298685709634

Epoch: 5| Step: 10
Training loss: 2.0284476280212402
Validation loss: 2.055474882324537

Epoch: 5| Step: 11
Training loss: 2.7978978157043457
Validation loss: 2.0421742846568427

Epoch: 105| Step: 0
Training loss: 2.1974451541900635
Validation loss: 2.0271865278482437

Epoch: 5| Step: 1
Training loss: 1.9169957637786865
Validation loss: 2.0267635683218637

Epoch: 5| Step: 2
Training loss: 2.8243260383605957
Validation loss: 2.022210086385409

Epoch: 5| Step: 3
Training loss: 2.063284397125244
Validation loss: 2.032970150311788

Epoch: 5| Step: 4
Training loss: 1.462254285812378
Validation loss: 2.0438943008581796

Epoch: 5| Step: 5
Training loss: 2.1425468921661377
Validation loss: 2.0422579447428384

Epoch: 5| Step: 6
Training loss: 2.6995608806610107
Validation loss: 2.044935017824173

Epoch: 5| Step: 7
Training loss: 2.0778799057006836
Validation loss: 2.0396584371725717

Epoch: 5| Step: 8
Training loss: 2.022547483444214
Validation loss: 2.0436960260073342

Epoch: 5| Step: 9
Training loss: 2.079645872116089
Validation loss: 2.0431587447722754

Epoch: 5| Step: 10
Training loss: 2.618485927581787
Validation loss: 2.047827293475469

Epoch: 5| Step: 11
Training loss: 2.4449570178985596
Validation loss: 2.051301896572113

Epoch: 106| Step: 0
Training loss: 2.5668790340423584
Validation loss: 2.045279492934545

Epoch: 5| Step: 1
Training loss: 1.6535823345184326
Validation loss: 2.050006315112114

Epoch: 5| Step: 2
Training loss: 1.5688636302947998
Validation loss: 2.0447476655244827

Epoch: 5| Step: 3
Training loss: 1.9928054809570312
Validation loss: 2.040497342745463

Epoch: 5| Step: 4
Training loss: 1.8531734943389893
Validation loss: 2.042436639467875

Epoch: 5| Step: 5
Training loss: 2.401777982711792
Validation loss: 2.041539112726847

Epoch: 5| Step: 6
Training loss: 2.1446146965026855
Validation loss: 2.039283658067385

Epoch: 5| Step: 7
Training loss: 2.427243709564209
Validation loss: 2.036663606762886

Epoch: 5| Step: 8
Training loss: 2.7563512325286865
Validation loss: 2.036553462346395

Epoch: 5| Step: 9
Training loss: 2.3495635986328125
Validation loss: 2.0308786779642105

Epoch: 5| Step: 10
Training loss: 2.533478021621704
Validation loss: 2.0310314148664474

Epoch: 5| Step: 11
Training loss: 1.8976186513900757
Validation loss: 2.02172781030337

Epoch: 107| Step: 0
Training loss: 2.415400266647339
Validation loss: 2.014900495608648

Epoch: 5| Step: 1
Training loss: 2.4965786933898926
Validation loss: 2.008835489551226

Epoch: 5| Step: 2
Training loss: 2.4439756870269775
Validation loss: 2.007119799653689

Epoch: 5| Step: 3
Training loss: 1.8149032592773438
Validation loss: 2.0116522858540216

Epoch: 5| Step: 4
Training loss: 2.0870540142059326
Validation loss: 2.008920192718506

Epoch: 5| Step: 5
Training loss: 2.3908627033233643
Validation loss: 2.0137874633073807

Epoch: 5| Step: 6
Training loss: 2.1969122886657715
Validation loss: 2.020494202772776

Epoch: 5| Step: 7
Training loss: 2.0049996376037598
Validation loss: 2.019567613800367

Epoch: 5| Step: 8
Training loss: 2.1280465126037598
Validation loss: 2.0212303002675376

Epoch: 5| Step: 9
Training loss: 1.925436019897461
Validation loss: 2.033746987581253

Epoch: 5| Step: 10
Training loss: 1.4695221185684204
Validation loss: 2.0323589195807776

Epoch: 5| Step: 11
Training loss: 2.557135820388794
Validation loss: 2.0364174296458564

Epoch: 108| Step: 0
Training loss: 2.190218210220337
Validation loss: 2.044229745864868

Epoch: 5| Step: 1
Training loss: 1.8840999603271484
Validation loss: 2.0364813109238944

Epoch: 5| Step: 2
Training loss: 2.0005061626434326
Validation loss: 2.038851002852122

Epoch: 5| Step: 3
Training loss: 2.4012115001678467
Validation loss: 2.0257232834895453

Epoch: 5| Step: 4
Training loss: 2.0894322395324707
Validation loss: 2.0262660135825477

Epoch: 5| Step: 5
Training loss: 2.32466721534729
Validation loss: 2.0242426494757333

Epoch: 5| Step: 6
Training loss: 2.202288866043091
Validation loss: 2.01639054218928

Epoch: 5| Step: 7
Training loss: 2.397594690322876
Validation loss: 2.01905120909214

Epoch: 5| Step: 8
Training loss: 1.6765263080596924
Validation loss: 2.015398696064949

Epoch: 5| Step: 9
Training loss: 2.324812650680542
Validation loss: 2.0224185585975647

Epoch: 5| Step: 10
Training loss: 1.9595762491226196
Validation loss: 2.022788276274999

Epoch: 5| Step: 11
Training loss: 2.5372376441955566
Validation loss: 2.022368108232816

Epoch: 109| Step: 0
Training loss: 1.8033689260482788
Validation loss: 2.032276233037313

Epoch: 5| Step: 1
Training loss: 2.7583727836608887
Validation loss: 2.050578181942304

Epoch: 5| Step: 2
Training loss: 2.1352486610412598
Validation loss: 2.0585733155409494

Epoch: 5| Step: 3
Training loss: 2.1561758518218994
Validation loss: 2.0409894535938897

Epoch: 5| Step: 4
Training loss: 1.8955786228179932
Validation loss: 2.0528102914492288

Epoch: 5| Step: 5
Training loss: 2.1627745628356934
Validation loss: 2.037309284011523

Epoch: 5| Step: 6
Training loss: 2.0385875701904297
Validation loss: 2.0286336292823157

Epoch: 5| Step: 7
Training loss: 2.1327548027038574
Validation loss: 2.027897536754608

Epoch: 5| Step: 8
Training loss: 1.4749772548675537
Validation loss: 2.029242734114329

Epoch: 5| Step: 9
Training loss: 2.304687976837158
Validation loss: 2.0202972491582236

Epoch: 5| Step: 10
Training loss: 2.710690975189209
Validation loss: 2.0204078555107117

Epoch: 5| Step: 11
Training loss: 2.720968723297119
Validation loss: 2.0042967249949775

Epoch: 110| Step: 0
Training loss: 2.0140724182128906
Validation loss: 2.0236470252275467

Epoch: 5| Step: 1
Training loss: 2.6661794185638428
Validation loss: 2.0222054024537406

Epoch: 5| Step: 2
Training loss: 2.3832855224609375
Validation loss: 2.012646416823069

Epoch: 5| Step: 3
Training loss: 2.0652236938476562
Validation loss: 2.02244604130586

Epoch: 5| Step: 4
Training loss: 1.5266433954238892
Validation loss: 2.0181429982185364

Epoch: 5| Step: 5
Training loss: 2.1747357845306396
Validation loss: 2.024591734011968

Epoch: 5| Step: 6
Training loss: 2.696662425994873
Validation loss: 2.0360225240389505

Epoch: 5| Step: 7
Training loss: 2.2285799980163574
Validation loss: 2.021136353413264

Epoch: 5| Step: 8
Training loss: 1.8519237041473389
Validation loss: 2.0310506572326026

Epoch: 5| Step: 9
Training loss: 2.1680586338043213
Validation loss: 2.0198677678902945

Epoch: 5| Step: 10
Training loss: 1.8106765747070312
Validation loss: 2.0443481107552848

Epoch: 5| Step: 11
Training loss: 1.578818440437317
Validation loss: 2.0396947165330253

Epoch: 111| Step: 0
Training loss: 2.2601022720336914
Validation loss: 2.039243847131729

Epoch: 5| Step: 1
Training loss: 2.426604747772217
Validation loss: 2.0331561118364334

Epoch: 5| Step: 2
Training loss: 2.239187240600586
Validation loss: 2.0295147448778152

Epoch: 5| Step: 3
Training loss: 2.2217321395874023
Validation loss: 2.0287838131189346

Epoch: 5| Step: 4
Training loss: 2.742509126663208
Validation loss: 2.0348059087991714

Epoch: 5| Step: 5
Training loss: 1.8080202341079712
Validation loss: 2.03882826368014

Epoch: 5| Step: 6
Training loss: 1.9991321563720703
Validation loss: 2.0322274218002954

Epoch: 5| Step: 7
Training loss: 1.7551028728485107
Validation loss: 2.034937302271525

Epoch: 5| Step: 8
Training loss: 2.1277754306793213
Validation loss: 2.040063500404358

Epoch: 5| Step: 9
Training loss: 1.7678515911102295
Validation loss: 2.028250361482302

Epoch: 5| Step: 10
Training loss: 1.9381906986236572
Validation loss: 2.0338789920012155

Epoch: 5| Step: 11
Training loss: 2.6699819564819336
Validation loss: 2.0344013373057046

Epoch: 112| Step: 0
Training loss: 2.556492567062378
Validation loss: 2.0297991981108985

Epoch: 5| Step: 1
Training loss: 2.437300682067871
Validation loss: 2.0215133180220923

Epoch: 5| Step: 2
Training loss: 2.113555669784546
Validation loss: 2.0327136466900506

Epoch: 5| Step: 3
Training loss: 2.273888111114502
Validation loss: 2.0293488005797067

Epoch: 5| Step: 4
Training loss: 2.2724099159240723
Validation loss: 2.0313725620508194

Epoch: 5| Step: 5
Training loss: 1.8056672811508179
Validation loss: 2.0285525172948837

Epoch: 5| Step: 6
Training loss: 2.2222604751586914
Validation loss: 2.041789412498474

Epoch: 5| Step: 7
Training loss: 1.5854219198226929
Validation loss: 2.0357812345027924

Epoch: 5| Step: 8
Training loss: 2.518559217453003
Validation loss: 2.038660928606987

Epoch: 5| Step: 9
Training loss: 1.8388572931289673
Validation loss: 2.033456896742185

Epoch: 5| Step: 10
Training loss: 1.7735990285873413
Validation loss: 2.0382095078627267

Epoch: 5| Step: 11
Training loss: 2.0134644508361816
Validation loss: 2.0254215200742087

Epoch: 113| Step: 0
Training loss: 2.2847483158111572
Validation loss: 2.023273934920629

Epoch: 5| Step: 1
Training loss: 2.127981662750244
Validation loss: 2.0181879103183746

Epoch: 5| Step: 2
Training loss: 2.0022835731506348
Validation loss: 2.022814229130745

Epoch: 5| Step: 3
Training loss: 2.1706528663635254
Validation loss: 2.0269798636436462

Epoch: 5| Step: 4
Training loss: 1.294030785560608
Validation loss: 2.0298305302858353

Epoch: 5| Step: 5
Training loss: 2.2683334350585938
Validation loss: 2.0216075827678046

Epoch: 5| Step: 6
Training loss: 2.392787218093872
Validation loss: 2.0274812281131744

Epoch: 5| Step: 7
Training loss: 2.5440025329589844
Validation loss: 2.0191155076026917

Epoch: 5| Step: 8
Training loss: 2.3100717067718506
Validation loss: 2.015522450208664

Epoch: 5| Step: 9
Training loss: 1.9400066137313843
Validation loss: 2.0196092824141183

Epoch: 5| Step: 10
Training loss: 2.336702585220337
Validation loss: 2.012214422225952

Epoch: 5| Step: 11
Training loss: 2.2747650146484375
Validation loss: 2.01304684082667

Epoch: 114| Step: 0
Training loss: 2.4332141876220703
Validation loss: 2.0117527643839517

Epoch: 5| Step: 1
Training loss: 1.7377322912216187
Validation loss: 2.0065650840600333

Epoch: 5| Step: 2
Training loss: 1.831597924232483
Validation loss: 2.0035374959309897

Epoch: 5| Step: 3
Training loss: 1.662872076034546
Validation loss: 2.010864724715551

Epoch: 5| Step: 4
Training loss: 2.054887533187866
Validation loss: 2.0161660512288413

Epoch: 5| Step: 5
Training loss: 2.351935863494873
Validation loss: 2.0303852260112762

Epoch: 5| Step: 6
Training loss: 3.0005943775177
Validation loss: 2.034446954727173

Epoch: 5| Step: 7
Training loss: 2.6092967987060547
Validation loss: 2.051570773124695

Epoch: 5| Step: 8
Training loss: 1.9879554510116577
Validation loss: 2.0632240027189255

Epoch: 5| Step: 9
Training loss: 2.175750255584717
Validation loss: 2.056807299455007

Epoch: 5| Step: 10
Training loss: 1.6766506433486938
Validation loss: 2.05162912607193

Epoch: 5| Step: 11
Training loss: 2.460275888442993
Validation loss: 2.034156322479248

Epoch: 115| Step: 0
Training loss: 1.874540090560913
Validation loss: 2.041168009241422

Epoch: 5| Step: 1
Training loss: 2.4746968746185303
Validation loss: 2.0275418063004813

Epoch: 5| Step: 2
Training loss: 2.0784530639648438
Validation loss: 2.0267996887365975

Epoch: 5| Step: 3
Training loss: 1.940685510635376
Validation loss: 2.0248072892427444

Epoch: 5| Step: 4
Training loss: 1.9531227350234985
Validation loss: 2.0193251768747964

Epoch: 5| Step: 5
Training loss: 2.188507556915283
Validation loss: 2.017584507664045

Epoch: 5| Step: 6
Training loss: 2.4746718406677246
Validation loss: 2.017973447839419

Epoch: 5| Step: 7
Training loss: 2.172903060913086
Validation loss: 2.026899869243304

Epoch: 5| Step: 8
Training loss: 2.108503818511963
Validation loss: 2.0319835046927133

Epoch: 5| Step: 9
Training loss: 2.669372081756592
Validation loss: 2.034433528780937

Epoch: 5| Step: 10
Training loss: 1.8311268091201782
Validation loss: 2.0378309041261673

Epoch: 5| Step: 11
Training loss: 1.429276704788208
Validation loss: 2.024208431442579

Epoch: 116| Step: 0
Training loss: 1.7392604351043701
Validation loss: 2.030124848087629

Epoch: 5| Step: 1
Training loss: 2.5484116077423096
Validation loss: 2.0165038804213204

Epoch: 5| Step: 2
Training loss: 2.3625648021698
Validation loss: 2.015286778410276

Epoch: 5| Step: 3
Training loss: 1.9334379434585571
Validation loss: 2.017673830191294

Epoch: 5| Step: 4
Training loss: 2.5110130310058594
Validation loss: 2.0089982549349465

Epoch: 5| Step: 5
Training loss: 2.180527448654175
Validation loss: 2.012160191933314

Epoch: 5| Step: 6
Training loss: 2.1108925342559814
Validation loss: 2.015026018023491

Epoch: 5| Step: 7
Training loss: 1.8651593923568726
Validation loss: 2.0370518366495767

Epoch: 5| Step: 8
Training loss: 2.3730530738830566
Validation loss: 2.050402288635572

Epoch: 5| Step: 9
Training loss: 2.1440176963806152
Validation loss: 2.0564784705638885

Epoch: 5| Step: 10
Training loss: 1.8929380178451538
Validation loss: 2.0533988773822784

Epoch: 5| Step: 11
Training loss: 1.986840009689331
Validation loss: 2.038637379805247

Epoch: 117| Step: 0
Training loss: 2.210474729537964
Validation loss: 2.034528394540151

Epoch: 5| Step: 1
Training loss: 2.0652709007263184
Validation loss: 2.025802433490753

Epoch: 5| Step: 2
Training loss: 1.9177697896957397
Validation loss: 2.0412144561608634

Epoch: 5| Step: 3
Training loss: 2.36291766166687
Validation loss: 2.0359523644049964

Epoch: 5| Step: 4
Training loss: 2.2879397869110107
Validation loss: 2.0297184139490128

Epoch: 5| Step: 5
Training loss: 2.2717204093933105
Validation loss: 2.02555646498998

Epoch: 5| Step: 6
Training loss: 2.2264227867126465
Validation loss: 2.0120326628287635

Epoch: 5| Step: 7
Training loss: 2.303762435913086
Validation loss: 2.0128574271996817

Epoch: 5| Step: 8
Training loss: 1.7387869358062744
Validation loss: 2.021020084619522

Epoch: 5| Step: 9
Training loss: 1.833497405052185
Validation loss: 2.0250315815210342

Epoch: 5| Step: 10
Training loss: 1.9851655960083008
Validation loss: 2.0194501330455146

Epoch: 5| Step: 11
Training loss: 2.6432557106018066
Validation loss: 2.0214171707630157

Epoch: 118| Step: 0
Training loss: 2.149852991104126
Validation loss: 2.0169989864031472

Epoch: 5| Step: 1
Training loss: 1.9344251155853271
Validation loss: 2.024166097243627

Epoch: 5| Step: 2
Training loss: 2.1100261211395264
Validation loss: 2.021811619400978

Epoch: 5| Step: 3
Training loss: 2.6761555671691895
Validation loss: 2.0273352017005286

Epoch: 5| Step: 4
Training loss: 1.8657619953155518
Validation loss: 2.032387504975001

Epoch: 5| Step: 5
Training loss: 2.7276222705841064
Validation loss: 2.042330647508303

Epoch: 5| Step: 6
Training loss: 2.1820626258850098
Validation loss: 2.0450143615404763

Epoch: 5| Step: 7
Training loss: 1.7658497095108032
Validation loss: 2.046105613311132

Epoch: 5| Step: 8
Training loss: 1.7944453954696655
Validation loss: 2.0521784722805023

Epoch: 5| Step: 9
Training loss: 2.144315719604492
Validation loss: 2.063481127222379

Epoch: 5| Step: 10
Training loss: 2.410250663757324
Validation loss: 2.046278948585192

Epoch: 5| Step: 11
Training loss: 1.5534074306488037
Validation loss: 2.0411636332670846

Epoch: 119| Step: 0
Training loss: 1.6190407276153564
Validation loss: 2.0429913798967996

Epoch: 5| Step: 1
Training loss: 2.0921902656555176
Validation loss: 2.0320274780193963

Epoch: 5| Step: 2
Training loss: 1.890305757522583
Validation loss: 2.0172829180955887

Epoch: 5| Step: 3
Training loss: 1.5415394306182861
Validation loss: 2.0202392985423407

Epoch: 5| Step: 4
Training loss: 2.528576374053955
Validation loss: 2.0112792750199637

Epoch: 5| Step: 5
Training loss: 2.4641075134277344
Validation loss: 2.02232463657856

Epoch: 5| Step: 6
Training loss: 2.109035015106201
Validation loss: 2.0214443802833557

Epoch: 5| Step: 7
Training loss: 2.378450632095337
Validation loss: 2.018457606434822

Epoch: 5| Step: 8
Training loss: 2.291433811187744
Validation loss: 2.0226499885320663

Epoch: 5| Step: 9
Training loss: 2.3622686862945557
Validation loss: 2.014556055267652

Epoch: 5| Step: 10
Training loss: 2.346564531326294
Validation loss: 2.024273549516996

Epoch: 5| Step: 11
Training loss: 1.406555414199829
Validation loss: 2.028836930791537

Epoch: 120| Step: 0
Training loss: 2.3889591693878174
Validation loss: 2.037604679663976

Epoch: 5| Step: 1
Training loss: 2.6098153591156006
Validation loss: 2.0262826681137085

Epoch: 5| Step: 2
Training loss: 2.110260009765625
Validation loss: 2.0291912953058877

Epoch: 5| Step: 3
Training loss: 2.2680840492248535
Validation loss: 2.025601883729299

Epoch: 5| Step: 4
Training loss: 2.3849339485168457
Validation loss: 2.0187882284323373

Epoch: 5| Step: 5
Training loss: 2.197561502456665
Validation loss: 2.0220254361629486

Epoch: 5| Step: 6
Training loss: 1.8465524911880493
Validation loss: 2.014508366584778

Epoch: 5| Step: 7
Training loss: 2.13227915763855
Validation loss: 2.0198952654997506

Epoch: 5| Step: 8
Training loss: 2.108823299407959
Validation loss: 2.0178403755029044

Epoch: 5| Step: 9
Training loss: 1.6339161396026611
Validation loss: 2.010653773943583

Epoch: 5| Step: 10
Training loss: 1.636839509010315
Validation loss: 2.0118154187997184

Epoch: 5| Step: 11
Training loss: 2.203819990158081
Validation loss: 2.0108505884806314

Epoch: 121| Step: 0
Training loss: 1.9879894256591797
Validation loss: 2.0208637366692224

Epoch: 5| Step: 1
Training loss: 2.241389751434326
Validation loss: 2.0404865940411887

Epoch: 5| Step: 2
Training loss: 2.1758873462677
Validation loss: 2.052834928035736

Epoch: 5| Step: 3
Training loss: 1.969794511795044
Validation loss: 2.027656058470408

Epoch: 5| Step: 4
Training loss: 1.6226361989974976
Validation loss: 2.02429569264253

Epoch: 5| Step: 5
Training loss: 2.0727906227111816
Validation loss: 2.0159833480914435

Epoch: 5| Step: 6
Training loss: 2.15855073928833
Validation loss: 2.0316084772348404

Epoch: 5| Step: 7
Training loss: 2.7269845008850098
Validation loss: 2.0089028427998223

Epoch: 5| Step: 8
Training loss: 2.4289324283599854
Validation loss: 2.0148429522911706

Epoch: 5| Step: 9
Training loss: 1.6835966110229492
Validation loss: 2.017312506834666

Epoch: 5| Step: 10
Training loss: 2.347874402999878
Validation loss: 2.0118822852770486

Epoch: 5| Step: 11
Training loss: 1.3392720222473145
Validation loss: 2.012720083196958

Epoch: 122| Step: 0
Training loss: 2.567009449005127
Validation loss: 2.018117219209671

Epoch: 5| Step: 1
Training loss: 2.2793116569519043
Validation loss: 2.015665218234062

Epoch: 5| Step: 2
Training loss: 1.8490068912506104
Validation loss: 2.020344982544581

Epoch: 5| Step: 3
Training loss: 1.9015910625457764
Validation loss: 2.0249851047992706

Epoch: 5| Step: 4
Training loss: 2.22322416305542
Validation loss: 2.024549052119255

Epoch: 5| Step: 5
Training loss: 2.130739688873291
Validation loss: 2.030139848589897

Epoch: 5| Step: 6
Training loss: 2.0147712230682373
Validation loss: 2.0456023613611856

Epoch: 5| Step: 7
Training loss: 1.7940136194229126
Validation loss: 2.0512316127618155

Epoch: 5| Step: 8
Training loss: 2.4076449871063232
Validation loss: 2.0515016118685403

Epoch: 5| Step: 9
Training loss: 1.5795047283172607
Validation loss: 2.0621513028939567

Epoch: 5| Step: 10
Training loss: 2.6363770961761475
Validation loss: 2.0490790605545044

Epoch: 5| Step: 11
Training loss: 2.6108899116516113
Validation loss: 2.0251367638508477

Epoch: 123| Step: 0
Training loss: 2.6312835216522217
Validation loss: 2.0311628629763923

Epoch: 5| Step: 1
Training loss: 1.467650294303894
Validation loss: 2.0181791583697

Epoch: 5| Step: 2
Training loss: 2.3307926654815674
Validation loss: 2.0128371119499207

Epoch: 5| Step: 3
Training loss: 2.1296958923339844
Validation loss: 2.023032863934835

Epoch: 5| Step: 4
Training loss: 2.1447105407714844
Validation loss: 2.0311822096506753

Epoch: 5| Step: 5
Training loss: 2.526236057281494
Validation loss: 2.0320083449284234

Epoch: 5| Step: 6
Training loss: 2.486109972000122
Validation loss: 2.036940703789393

Epoch: 5| Step: 7
Training loss: 1.695534110069275
Validation loss: 2.0338109781344733

Epoch: 5| Step: 8
Training loss: 2.0101420879364014
Validation loss: 2.0369225492080054

Epoch: 5| Step: 9
Training loss: 2.534289836883545
Validation loss: 2.027585988243421

Epoch: 5| Step: 10
Training loss: 2.0954537391662598
Validation loss: 2.0259769558906555

Epoch: 5| Step: 11
Training loss: 0.4977424442768097
Validation loss: 2.01240611076355

Epoch: 124| Step: 0
Training loss: 2.48164963722229
Validation loss: 2.0164842009544373

Epoch: 5| Step: 1
Training loss: 1.8798799514770508
Validation loss: 2.016099234422048

Epoch: 5| Step: 2
Training loss: 2.4663970470428467
Validation loss: 2.0155567278464637

Epoch: 5| Step: 3
Training loss: 1.8900575637817383
Validation loss: 2.0066749900579453

Epoch: 5| Step: 4
Training loss: 2.2028141021728516
Validation loss: 2.013444870710373

Epoch: 5| Step: 5
Training loss: 1.9689528942108154
Validation loss: 2.0101414571205773

Epoch: 5| Step: 6
Training loss: 2.4811694622039795
Validation loss: 2.0093510250250497

Epoch: 5| Step: 7
Training loss: 2.0566651821136475
Validation loss: 2.0165271212657294

Epoch: 5| Step: 8
Training loss: 2.2327029705047607
Validation loss: 2.0277539789676666

Epoch: 5| Step: 9
Training loss: 2.0738701820373535
Validation loss: 2.0412634164094925

Epoch: 5| Step: 10
Training loss: 2.0057806968688965
Validation loss: 2.035211533308029

Epoch: 5| Step: 11
Training loss: 1.5356768369674683
Validation loss: 2.0433542281389236

Epoch: 125| Step: 0
Training loss: 2.0892333984375
Validation loss: 2.0295012493928275

Epoch: 5| Step: 1
Training loss: 2.7909913063049316
Validation loss: 2.0069775680700936

Epoch: 5| Step: 2
Training loss: 1.9535821676254272
Validation loss: 2.0008371522029242

Epoch: 5| Step: 3
Training loss: 2.3342056274414062
Validation loss: 2.0042029122511544

Epoch: 5| Step: 4
Training loss: 2.040696620941162
Validation loss: 2.0059677362442017

Epoch: 5| Step: 5
Training loss: 2.119990825653076
Validation loss: 2.01154092947642

Epoch: 5| Step: 6
Training loss: 1.8976726531982422
Validation loss: 2.001936992009481

Epoch: 5| Step: 7
Training loss: 1.4960277080535889
Validation loss: 2.017861028512319

Epoch: 5| Step: 8
Training loss: 2.3129618167877197
Validation loss: 2.0133685022592545

Epoch: 5| Step: 9
Training loss: 2.3057026863098145
Validation loss: 2.009817883372307

Epoch: 5| Step: 10
Training loss: 2.273247241973877
Validation loss: 2.012941891948382

Epoch: 5| Step: 11
Training loss: 1.8549151420593262
Validation loss: 2.0104332913955054

Epoch: 126| Step: 0
Training loss: 1.885732650756836
Validation loss: 2.012547547618548

Epoch: 5| Step: 1
Training loss: 1.9314813613891602
Validation loss: 2.0095087190469108

Epoch: 5| Step: 2
Training loss: 1.9586563110351562
Validation loss: 2.001329322655996

Epoch: 5| Step: 3
Training loss: 2.333246946334839
Validation loss: 2.0225700636704764

Epoch: 5| Step: 4
Training loss: 2.2851715087890625
Validation loss: 2.03473562002182

Epoch: 5| Step: 5
Training loss: 2.282782793045044
Validation loss: 2.0615144868691764

Epoch: 5| Step: 6
Training loss: 2.2513885498046875
Validation loss: 2.0604016333818436

Epoch: 5| Step: 7
Training loss: 2.1093080043792725
Validation loss: 2.06896181901296

Epoch: 5| Step: 8
Training loss: 1.7699801921844482
Validation loss: 2.0665317128101983

Epoch: 5| Step: 9
Training loss: 2.3194375038146973
Validation loss: 2.078004082043966

Epoch: 5| Step: 10
Training loss: 2.4572043418884277
Validation loss: 2.0550368825594583

Epoch: 5| Step: 11
Training loss: 1.8334112167358398
Validation loss: 2.0568662832180657

Epoch: 127| Step: 0
Training loss: 2.3119990825653076
Validation loss: 2.03021439909935

Epoch: 5| Step: 1
Training loss: 2.2786507606506348
Validation loss: 2.026826247572899

Epoch: 5| Step: 2
Training loss: 2.8553152084350586
Validation loss: 2.0195552011330924

Epoch: 5| Step: 3
Training loss: 1.9990142583847046
Validation loss: 2.005253558357557

Epoch: 5| Step: 4
Training loss: 1.711035132408142
Validation loss: 2.008166645963987

Epoch: 5| Step: 5
Training loss: 1.8774446249008179
Validation loss: 2.0200078984101615

Epoch: 5| Step: 6
Training loss: 1.495070457458496
Validation loss: 2.016323352853457

Epoch: 5| Step: 7
Training loss: 2.685276508331299
Validation loss: 2.0190066446860633

Epoch: 5| Step: 8
Training loss: 2.0482473373413086
Validation loss: 2.017917593320211

Epoch: 5| Step: 9
Training loss: 1.8649623394012451
Validation loss: 2.0082443157831826

Epoch: 5| Step: 10
Training loss: 2.331852436065674
Validation loss: 2.0154255777597427

Epoch: 5| Step: 11
Training loss: 2.2646920680999756
Validation loss: 2.0141532570123672

Epoch: 128| Step: 0
Training loss: 2.3217055797576904
Validation loss: 2.00809508562088

Epoch: 5| Step: 1
Training loss: 1.9446666240692139
Validation loss: 2.010336900750796

Epoch: 5| Step: 2
Training loss: 2.017678737640381
Validation loss: 2.0010972370704017

Epoch: 5| Step: 3
Training loss: 2.368112325668335
Validation loss: 2.0079385191202164

Epoch: 5| Step: 4
Training loss: 2.313066005706787
Validation loss: 2.0143869320551553

Epoch: 5| Step: 5
Training loss: 1.97835373878479
Validation loss: 2.020080874363581

Epoch: 5| Step: 6
Training loss: 2.48416805267334
Validation loss: 2.043510456879934

Epoch: 5| Step: 7
Training loss: 1.6933902502059937
Validation loss: 2.032999495665232

Epoch: 5| Step: 8
Training loss: 1.6111326217651367
Validation loss: 2.0586106181144714

Epoch: 5| Step: 9
Training loss: 2.162942886352539
Validation loss: 2.0617070496082306

Epoch: 5| Step: 10
Training loss: 2.139721632003784
Validation loss: 2.0546655704577765

Epoch: 5| Step: 11
Training loss: 3.040048122406006
Validation loss: 2.0561803529659906

Epoch: 129| Step: 0
Training loss: 2.0767149925231934
Validation loss: 2.0463453233242035

Epoch: 5| Step: 1
Training loss: 1.9781131744384766
Validation loss: 2.046706443031629

Epoch: 5| Step: 2
Training loss: 2.0910065174102783
Validation loss: 2.036619077126185

Epoch: 5| Step: 3
Training loss: 1.6206096410751343
Validation loss: 2.0354458689689636

Epoch: 5| Step: 4
Training loss: 2.4109444618225098
Validation loss: 2.0298895984888077

Epoch: 5| Step: 5
Training loss: 2.2669100761413574
Validation loss: 2.034546822309494

Epoch: 5| Step: 6
Training loss: 2.8019723892211914
Validation loss: 2.0376051167647042

Epoch: 5| Step: 7
Training loss: 1.9195750951766968
Validation loss: 2.040839354197184

Epoch: 5| Step: 8
Training loss: 1.9421523809432983
Validation loss: 2.028305560350418

Epoch: 5| Step: 9
Training loss: 2.2670674324035645
Validation loss: 2.0264339397350946

Epoch: 5| Step: 10
Training loss: 1.7990953922271729
Validation loss: 2.031220401326815

Epoch: 5| Step: 11
Training loss: 2.0868120193481445
Validation loss: 2.021259551246961

Epoch: 130| Step: 0
Training loss: 1.9704926013946533
Validation loss: 2.0254774739344916

Epoch: 5| Step: 1
Training loss: 1.691375494003296
Validation loss: 2.0267607420682907

Epoch: 5| Step: 2
Training loss: 2.3323779106140137
Validation loss: 2.0229460895061493

Epoch: 5| Step: 3
Training loss: 2.0119667053222656
Validation loss: 2.0244353264570236

Epoch: 5| Step: 4
Training loss: 2.360349655151367
Validation loss: 2.0383637696504593

Epoch: 5| Step: 5
Training loss: 2.003328800201416
Validation loss: 2.0273448477188745

Epoch: 5| Step: 6
Training loss: 1.5953304767608643
Validation loss: 2.035067612926165

Epoch: 5| Step: 7
Training loss: 1.787562370300293
Validation loss: 2.0425435403982797

Epoch: 5| Step: 8
Training loss: 2.4112417697906494
Validation loss: 2.0402803172667823

Epoch: 5| Step: 9
Training loss: 2.4675331115722656
Validation loss: 2.0550085256497064

Epoch: 5| Step: 10
Training loss: 2.449547290802002
Validation loss: 2.0807689875364304

Epoch: 5| Step: 11
Training loss: 3.0285959243774414
Validation loss: 2.0831768959760666

Epoch: 131| Step: 0
Training loss: 2.1133389472961426
Validation loss: 2.076257069905599

Epoch: 5| Step: 1
Training loss: 2.369502544403076
Validation loss: 2.0515537410974503

Epoch: 5| Step: 2
Training loss: 1.9677093029022217
Validation loss: 2.0324672063191733

Epoch: 5| Step: 3
Training loss: 2.269125461578369
Validation loss: 2.0336430271466575

Epoch: 5| Step: 4
Training loss: 1.677578330039978
Validation loss: 2.0386825700600943

Epoch: 5| Step: 5
Training loss: 1.673649787902832
Validation loss: 2.02679314215978

Epoch: 5| Step: 6
Training loss: 1.9927351474761963
Validation loss: 2.028893103202184

Epoch: 5| Step: 7
Training loss: 2.8793954849243164
Validation loss: 2.0289470801750817

Epoch: 5| Step: 8
Training loss: 2.514824390411377
Validation loss: 2.0206331809361777

Epoch: 5| Step: 9
Training loss: 2.3916430473327637
Validation loss: 2.0328132013479867

Epoch: 5| Step: 10
Training loss: 1.216158151626587
Validation loss: 2.0128779460986457

Epoch: 5| Step: 11
Training loss: 2.919677734375
Validation loss: 2.036114419500033

Epoch: 132| Step: 0
Training loss: 2.3368759155273438
Validation loss: 2.0195339967807135

Epoch: 5| Step: 1
Training loss: 2.016292095184326
Validation loss: 2.028399109840393

Epoch: 5| Step: 2
Training loss: 2.297092914581299
Validation loss: 2.029488871494929

Epoch: 5| Step: 3
Training loss: 2.235429048538208
Validation loss: 2.025523195664088

Epoch: 5| Step: 4
Training loss: 1.573477029800415
Validation loss: 2.0449133614699044

Epoch: 5| Step: 5
Training loss: 1.8443944454193115
Validation loss: 2.054207449158033

Epoch: 5| Step: 6
Training loss: 2.166584014892578
Validation loss: 2.0385418881972632

Epoch: 5| Step: 7
Training loss: 2.148606538772583
Validation loss: 2.0682829717795053

Epoch: 5| Step: 8
Training loss: 2.3775763511657715
Validation loss: 2.0662401715914407

Epoch: 5| Step: 9
Training loss: 2.332848310470581
Validation loss: 2.0319512337446213

Epoch: 5| Step: 10
Training loss: 2.0557403564453125
Validation loss: 2.019887944062551

Epoch: 5| Step: 11
Training loss: 2.583026885986328
Validation loss: 2.0252624998490014

Epoch: 133| Step: 0
Training loss: 2.1492745876312256
Validation loss: 2.020341450969378

Epoch: 5| Step: 1
Training loss: 1.673826813697815
Validation loss: 2.028504103422165

Epoch: 5| Step: 2
Training loss: 1.9208987951278687
Validation loss: 2.0246701538562775

Epoch: 5| Step: 3
Training loss: 2.366122245788574
Validation loss: 2.030195246140162

Epoch: 5| Step: 4
Training loss: 2.230154514312744
Validation loss: 2.0290851493676505

Epoch: 5| Step: 5
Training loss: 2.4051413536071777
Validation loss: 2.025544116894404

Epoch: 5| Step: 6
Training loss: 2.211038589477539
Validation loss: 2.0209012975295386

Epoch: 5| Step: 7
Training loss: 2.302492141723633
Validation loss: 2.0198750644922256

Epoch: 5| Step: 8
Training loss: 2.0596113204956055
Validation loss: 2.016081844766935

Epoch: 5| Step: 9
Training loss: 2.496112585067749
Validation loss: 2.01359823346138

Epoch: 5| Step: 10
Training loss: 1.773698091506958
Validation loss: 2.014262522260348

Epoch: 5| Step: 11
Training loss: 2.137017250061035
Validation loss: 2.0150175293286643

Epoch: 134| Step: 0
Training loss: 1.9574291706085205
Validation loss: 2.006849095225334

Epoch: 5| Step: 1
Training loss: 2.260098695755005
Validation loss: 2.022546192010244

Epoch: 5| Step: 2
Training loss: 2.184825897216797
Validation loss: 2.022860273718834

Epoch: 5| Step: 3
Training loss: 1.8818590641021729
Validation loss: 2.0435855636994043

Epoch: 5| Step: 4
Training loss: 2.1959266662597656
Validation loss: 2.024919718503952

Epoch: 5| Step: 5
Training loss: 2.7127490043640137
Validation loss: 2.043870290120443

Epoch: 5| Step: 6
Training loss: 2.1628525257110596
Validation loss: 2.0430009911457696

Epoch: 5| Step: 7
Training loss: 2.016982316970825
Validation loss: 2.047863701979319

Epoch: 5| Step: 8
Training loss: 1.5847423076629639
Validation loss: 2.044563442468643

Epoch: 5| Step: 9
Training loss: 1.7898380756378174
Validation loss: 2.040935307741165

Epoch: 5| Step: 10
Training loss: 2.49714994430542
Validation loss: 2.0399827361106873

Epoch: 5| Step: 11
Training loss: 1.7123517990112305
Validation loss: 2.0337458153565726

Epoch: 135| Step: 0
Training loss: 1.7559750080108643
Validation loss: 2.0286059826612473

Epoch: 5| Step: 1
Training loss: 2.63212251663208
Validation loss: 2.0203044364849725

Epoch: 5| Step: 2
Training loss: 2.068175792694092
Validation loss: 2.0205220133066177

Epoch: 5| Step: 3
Training loss: 2.3577208518981934
Validation loss: 2.0180376122395196

Epoch: 5| Step: 4
Training loss: 2.1053454875946045
Validation loss: 2.021337295571963

Epoch: 5| Step: 5
Training loss: 2.1215920448303223
Validation loss: 2.0211209108432135

Epoch: 5| Step: 6
Training loss: 2.0553064346313477
Validation loss: 2.024257411559423

Epoch: 5| Step: 7
Training loss: 2.3793423175811768
Validation loss: 2.0237302432457605

Epoch: 5| Step: 8
Training loss: 2.272010326385498
Validation loss: 2.020404269297918

Epoch: 5| Step: 9
Training loss: 1.8078691959381104
Validation loss: 2.027946343024572

Epoch: 5| Step: 10
Training loss: 1.682308554649353
Validation loss: 2.0129392047723136

Epoch: 5| Step: 11
Training loss: 1.9537947177886963
Validation loss: 2.0218611111243567

Epoch: 136| Step: 0
Training loss: 2.690176486968994
Validation loss: 2.0210047562917075

Epoch: 5| Step: 1
Training loss: 1.662896752357483
Validation loss: 2.021792486310005

Epoch: 5| Step: 2
Training loss: 1.8386074304580688
Validation loss: 2.017757644255956

Epoch: 5| Step: 3
Training loss: 1.906825304031372
Validation loss: 2.037219390273094

Epoch: 5| Step: 4
Training loss: 2.6032521724700928
Validation loss: 2.0279122640689216

Epoch: 5| Step: 5
Training loss: 2.4893264770507812
Validation loss: 2.024159004290899

Epoch: 5| Step: 6
Training loss: 1.2510902881622314
Validation loss: 2.0293741524219513

Epoch: 5| Step: 7
Training loss: 2.175062656402588
Validation loss: 2.0341048737366996

Epoch: 5| Step: 8
Training loss: 2.254384994506836
Validation loss: 2.0240962306658425

Epoch: 5| Step: 9
Training loss: 2.445772171020508
Validation loss: 2.040813828508059

Epoch: 5| Step: 10
Training loss: 1.645901083946228
Validation loss: 2.0412547339995704

Epoch: 5| Step: 11
Training loss: 2.4383645057678223
Validation loss: 2.019117593765259

Epoch: 137| Step: 0
Training loss: 1.858147382736206
Validation loss: 2.010827660560608

Epoch: 5| Step: 1
Training loss: 2.3196473121643066
Validation loss: 2.022533933321635

Epoch: 5| Step: 2
Training loss: 1.7974498271942139
Validation loss: 2.0333084215720496

Epoch: 5| Step: 3
Training loss: 1.5118458271026611
Validation loss: 2.030434841910998

Epoch: 5| Step: 4
Training loss: 2.8855090141296387
Validation loss: 2.035710190733274

Epoch: 5| Step: 5
Training loss: 2.145817995071411
Validation loss: 2.02082259953022

Epoch: 5| Step: 6
Training loss: 1.783483862876892
Validation loss: 2.0240871012210846

Epoch: 5| Step: 7
Training loss: 2.4937198162078857
Validation loss: 2.027355263630549

Epoch: 5| Step: 8
Training loss: 2.1169567108154297
Validation loss: 2.029812609155973

Epoch: 5| Step: 9
Training loss: 1.9257526397705078
Validation loss: 2.015641445914904

Epoch: 5| Step: 10
Training loss: 2.1016440391540527
Validation loss: 2.029147947827975

Epoch: 5| Step: 11
Training loss: 2.0436673164367676
Validation loss: 2.032477378845215

Epoch: 138| Step: 0
Training loss: 1.995086908340454
Validation loss: 2.0194050321976342

Epoch: 5| Step: 1
Training loss: 2.405477523803711
Validation loss: 2.023017222682635

Epoch: 5| Step: 2
Training loss: 2.094395875930786
Validation loss: 2.028321052591006

Epoch: 5| Step: 3
Training loss: 2.156951427459717
Validation loss: 2.031240622202555

Epoch: 5| Step: 4
Training loss: 2.585984706878662
Validation loss: 2.020600736141205

Epoch: 5| Step: 5
Training loss: 2.166980266571045
Validation loss: 2.0168610314528146

Epoch: 5| Step: 6
Training loss: 1.627117395401001
Validation loss: 2.028005058566729

Epoch: 5| Step: 7
Training loss: 1.4603984355926514
Validation loss: 2.0347609172264733

Epoch: 5| Step: 8
Training loss: 2.2169735431671143
Validation loss: 2.0585136661926904

Epoch: 5| Step: 9
Training loss: 2.2226173877716064
Validation loss: 2.0609370519717536

Epoch: 5| Step: 10
Training loss: 2.0690555572509766
Validation loss: 2.0626551459232965

Epoch: 5| Step: 11
Training loss: 1.412745475769043
Validation loss: 2.0540004471937814

Epoch: 139| Step: 0
Training loss: 1.8240234851837158
Validation loss: 2.056453655163447

Epoch: 5| Step: 1
Training loss: 2.301142930984497
Validation loss: 2.0582616527875266

Epoch: 5| Step: 2
Training loss: 2.5320568084716797
Validation loss: 2.0466960022846856

Epoch: 5| Step: 3
Training loss: 1.9886611700057983
Validation loss: 2.0286656071742377

Epoch: 5| Step: 4
Training loss: 2.3048596382141113
Validation loss: 2.027796442310015

Epoch: 5| Step: 5
Training loss: 1.9941730499267578
Validation loss: 2.0093026657899222

Epoch: 5| Step: 6
Training loss: 1.7612184286117554
Validation loss: 2.0122701227664948

Epoch: 5| Step: 7
Training loss: 1.7564804553985596
Validation loss: 2.0277578135331473

Epoch: 5| Step: 8
Training loss: 2.4041647911071777
Validation loss: 2.022102485100428

Epoch: 5| Step: 9
Training loss: 1.8195079565048218
Validation loss: 2.0139208237330117

Epoch: 5| Step: 10
Training loss: 2.528266429901123
Validation loss: 2.024575024843216

Epoch: 5| Step: 11
Training loss: 1.659009337425232
Validation loss: 2.026309902469317

Epoch: 140| Step: 0
Training loss: 2.017085552215576
Validation loss: 2.044717917839686

Epoch: 5| Step: 1
Training loss: 1.9855554103851318
Validation loss: 2.071068828304609

Epoch: 5| Step: 2
Training loss: 2.089099168777466
Validation loss: 2.0966612497965493

Epoch: 5| Step: 3
Training loss: 2.2649030685424805
Validation loss: 2.0943295458952584

Epoch: 5| Step: 4
Training loss: 1.9609787464141846
Validation loss: 2.088196794191996

Epoch: 5| Step: 5
Training loss: 1.8937900066375732
Validation loss: 2.086480195323626

Epoch: 5| Step: 6
Training loss: 2.5774588584899902
Validation loss: 2.05659726758798

Epoch: 5| Step: 7
Training loss: 2.636457920074463
Validation loss: 2.0355091989040375

Epoch: 5| Step: 8
Training loss: 2.0599894523620605
Validation loss: 2.0106663405895233

Epoch: 5| Step: 9
Training loss: 2.1172072887420654
Validation loss: 2.017812808354696

Epoch: 5| Step: 10
Training loss: 1.9726976156234741
Validation loss: 2.02460669974486

Epoch: 5| Step: 11
Training loss: 2.237474203109741
Validation loss: 2.0333083321650824

Epoch: 141| Step: 0
Training loss: 2.372769594192505
Validation loss: 2.035735994577408

Epoch: 5| Step: 1
Training loss: 2.213526487350464
Validation loss: 2.0448241780201593

Epoch: 5| Step: 2
Training loss: 1.850736379623413
Validation loss: 2.0440182089805603

Epoch: 5| Step: 3
Training loss: 2.3187835216522217
Validation loss: 2.0520993222792945

Epoch: 5| Step: 4
Training loss: 2.007157802581787
Validation loss: 2.0531785239775977

Epoch: 5| Step: 5
Training loss: 2.3801934719085693
Validation loss: 2.0536515365044274

Epoch: 5| Step: 6
Training loss: 2.3203673362731934
Validation loss: 2.0520683228969574

Epoch: 5| Step: 7
Training loss: 2.0867841243743896
Validation loss: 2.0464882403612137

Epoch: 5| Step: 8
Training loss: 2.3508613109588623
Validation loss: 2.0538176993529

Epoch: 5| Step: 9
Training loss: 2.0443472862243652
Validation loss: 2.0540887167056403

Epoch: 5| Step: 10
Training loss: 1.9353939294815063
Validation loss: 2.055450896422068

Epoch: 5| Step: 11
Training loss: 1.7035456895828247
Validation loss: 2.047766402363777

Epoch: 142| Step: 0
Training loss: 2.2750794887542725
Validation loss: 2.045849805076917

Epoch: 5| Step: 1
Training loss: 2.7615225315093994
Validation loss: 2.0433470010757446

Epoch: 5| Step: 2
Training loss: 1.845908761024475
Validation loss: 2.0386444280544915

Epoch: 5| Step: 3
Training loss: 1.9319099187850952
Validation loss: 2.0251402904589972

Epoch: 5| Step: 4
Training loss: 2.0104751586914062
Validation loss: 2.024440437555313

Epoch: 5| Step: 5
Training loss: 2.5971591472625732
Validation loss: 2.0164486269156137

Epoch: 5| Step: 6
Training loss: 2.0731213092803955
Validation loss: 2.023350050052007

Epoch: 5| Step: 7
Training loss: 1.639214277267456
Validation loss: 2.023224507768949

Epoch: 5| Step: 8
Training loss: 1.7016321420669556
Validation loss: 2.0154380798339844

Epoch: 5| Step: 9
Training loss: 2.2276644706726074
Validation loss: 2.0182558745145798

Epoch: 5| Step: 10
Training loss: 1.902761459350586
Validation loss: 2.034209872285525

Epoch: 5| Step: 11
Training loss: 3.873004198074341
Validation loss: 2.046812574068705

Epoch: 143| Step: 0
Training loss: 1.8653879165649414
Validation loss: 2.068201114734014

Epoch: 5| Step: 1
Training loss: 2.3791396617889404
Validation loss: 2.114384040236473

Epoch: 5| Step: 2
Training loss: 2.1499807834625244
Validation loss: 2.09494549036026

Epoch: 5| Step: 3
Training loss: 2.4070472717285156
Validation loss: 2.0930025031169257

Epoch: 5| Step: 4
Training loss: 1.836328148841858
Validation loss: 2.079669415950775

Epoch: 5| Step: 5
Training loss: 1.4835225343704224
Validation loss: 2.07220729192098

Epoch: 5| Step: 6
Training loss: 2.198944568634033
Validation loss: 2.0597661286592484

Epoch: 5| Step: 7
Training loss: 1.7835423946380615
Validation loss: 2.0311943044265113

Epoch: 5| Step: 8
Training loss: 2.5048625469207764
Validation loss: 2.0185321271419525

Epoch: 5| Step: 9
Training loss: 2.6284213066101074
Validation loss: 2.0065539131561914

Epoch: 5| Step: 10
Training loss: 2.412109375
Validation loss: 2.0073446234067283

Epoch: 5| Step: 11
Training loss: 1.8538169860839844
Validation loss: 2.007263998190562

Epoch: 144| Step: 0
Training loss: 1.8667854070663452
Validation loss: 2.0168658743302026

Epoch: 5| Step: 1
Training loss: 1.8986103534698486
Validation loss: 2.0120090742905936

Epoch: 5| Step: 2
Training loss: 2.0620968341827393
Validation loss: 2.011626477042834

Epoch: 5| Step: 3
Training loss: 2.0353426933288574
Validation loss: 2.0169365306695304

Epoch: 5| Step: 4
Training loss: 2.4166345596313477
Validation loss: 2.0085557401180267

Epoch: 5| Step: 5
Training loss: 2.409811019897461
Validation loss: 2.012283439437548

Epoch: 5| Step: 6
Training loss: 2.2279257774353027
Validation loss: 2.0095275143782296

Epoch: 5| Step: 7
Training loss: 2.52225399017334
Validation loss: 2.0082274278004966

Epoch: 5| Step: 8
Training loss: 1.7169252634048462
Validation loss: 2.0024934162696204

Epoch: 5| Step: 9
Training loss: 1.9278802871704102
Validation loss: 1.9937208692232768

Epoch: 5| Step: 10
Training loss: 2.395158290863037
Validation loss: 1.9947191625833511

Epoch: 5| Step: 11
Training loss: 0.7302906513214111
Validation loss: 2.0017747034629187

Epoch: 145| Step: 0
Training loss: 2.095505714416504
Validation loss: 2.017745852470398

Epoch: 5| Step: 1
Training loss: 2.4517440795898438
Validation loss: 2.049918621778488

Epoch: 5| Step: 2
Training loss: 1.9494798183441162
Validation loss: 2.0601645410060883

Epoch: 5| Step: 3
Training loss: 2.1860878467559814
Validation loss: 2.0697224537531533

Epoch: 5| Step: 4
Training loss: 1.8569742441177368
Validation loss: 2.057311624288559

Epoch: 5| Step: 5
Training loss: 2.2689051628112793
Validation loss: 2.0595841109752655

Epoch: 5| Step: 6
Training loss: 1.824056625366211
Validation loss: 2.042267769575119

Epoch: 5| Step: 7
Training loss: 1.7243578433990479
Validation loss: 2.041481465101242

Epoch: 5| Step: 8
Training loss: 2.6509015560150146
Validation loss: 2.031210740407308

Epoch: 5| Step: 9
Training loss: 2.321570873260498
Validation loss: 2.0166076123714447

Epoch: 5| Step: 10
Training loss: 2.150679349899292
Validation loss: 2.0068072775999704

Epoch: 5| Step: 11
Training loss: 2.575514316558838
Validation loss: 2.0002267162005105

Epoch: 146| Step: 0
Training loss: 2.428748607635498
Validation loss: 1.999339724580447

Epoch: 5| Step: 1
Training loss: 2.172945499420166
Validation loss: 2.0025249421596527

Epoch: 5| Step: 2
Training loss: 2.6984214782714844
Validation loss: 2.016284704208374

Epoch: 5| Step: 3
Training loss: 1.3291471004486084
Validation loss: 2.022068445881208

Epoch: 5| Step: 4
Training loss: 2.1856324672698975
Validation loss: 2.0331518600384393

Epoch: 5| Step: 5
Training loss: 2.320216417312622
Validation loss: 2.0361356834570565

Epoch: 5| Step: 6
Training loss: 2.0425658226013184
Validation loss: 2.0406970977783203

Epoch: 5| Step: 7
Training loss: 2.2148003578186035
Validation loss: 2.0400459120670953

Epoch: 5| Step: 8
Training loss: 1.7695379257202148
Validation loss: 2.0446298023064933

Epoch: 5| Step: 9
Training loss: 2.3246567249298096
Validation loss: 2.0443542947371802

Epoch: 5| Step: 10
Training loss: 2.2360641956329346
Validation loss: 2.0379926711320877

Epoch: 5| Step: 11
Training loss: 2.1129508018493652
Validation loss: 2.043736989299456

Epoch: 147| Step: 0
Training loss: 1.957452416419983
Validation loss: 2.0436484664678574

Epoch: 5| Step: 1
Training loss: 2.1747336387634277
Validation loss: 2.0375168224175773

Epoch: 5| Step: 2
Training loss: 1.8784854412078857
Validation loss: 2.0307934284210205

Epoch: 5| Step: 3
Training loss: 2.3428845405578613
Validation loss: 2.0444608330726624

Epoch: 5| Step: 4
Training loss: 1.816399335861206
Validation loss: 2.0244966397682824

Epoch: 5| Step: 5
Training loss: 2.1365177631378174
Validation loss: 2.031485433379809

Epoch: 5| Step: 6
Training loss: 1.9820226430892944
Validation loss: 2.018852780262629

Epoch: 5| Step: 7
Training loss: 2.76027512550354
Validation loss: 2.027567818760872

Epoch: 5| Step: 8
Training loss: 1.8773372173309326
Validation loss: 2.03043861190478

Epoch: 5| Step: 9
Training loss: 2.1141645908355713
Validation loss: 2.0303406516710916

Epoch: 5| Step: 10
Training loss: 2.333618640899658
Validation loss: 2.0471234172582626

Epoch: 5| Step: 11
Training loss: 1.589786410331726
Validation loss: 2.0576028525829315

Epoch: 148| Step: 0
Training loss: 1.900112509727478
Validation loss: 2.0604190975427628

Epoch: 5| Step: 1
Training loss: 2.3054561614990234
Validation loss: 2.0467167297999063

Epoch: 5| Step: 2
Training loss: 2.3122856616973877
Validation loss: 2.0514825880527496

Epoch: 5| Step: 3
Training loss: 2.11497163772583
Validation loss: 2.025353049238523

Epoch: 5| Step: 4
Training loss: 2.368187665939331
Validation loss: 2.0369078318277993

Epoch: 5| Step: 5
Training loss: 2.194979429244995
Validation loss: 2.0268741647402444

Epoch: 5| Step: 6
Training loss: 2.482837200164795
Validation loss: 2.0171763449907303

Epoch: 5| Step: 7
Training loss: 2.030306100845337
Validation loss: 2.0285604099432626

Epoch: 5| Step: 8
Training loss: 1.954167366027832
Validation loss: 2.025793398420016

Epoch: 5| Step: 9
Training loss: 1.973423719406128
Validation loss: 2.0205818911393485

Epoch: 5| Step: 10
Training loss: 1.5900894403457642
Validation loss: 2.0241614977518716

Epoch: 5| Step: 11
Training loss: 1.3054122924804688
Validation loss: 2.038605491320292

Epoch: 149| Step: 0
Training loss: 1.875087022781372
Validation loss: 2.046440968910853

Epoch: 5| Step: 1
Training loss: 1.8991889953613281
Validation loss: 2.04955222706

Epoch: 5| Step: 2
Training loss: 2.3967766761779785
Validation loss: 2.05659648279349

Epoch: 5| Step: 3
Training loss: 2.0403873920440674
Validation loss: 2.0635383824507394

Epoch: 5| Step: 4
Training loss: 2.0630712509155273
Validation loss: 2.047696183125178

Epoch: 5| Step: 5
Training loss: 2.187317371368408
Validation loss: 2.0491902430852256

Epoch: 5| Step: 6
Training loss: 1.6950536966323853
Validation loss: 2.048778330286344

Epoch: 5| Step: 7
Training loss: 1.7010663747787476
Validation loss: 2.0374203672011695

Epoch: 5| Step: 8
Training loss: 2.6588375568389893
Validation loss: 2.0181104441483817

Epoch: 5| Step: 9
Training loss: 2.08217453956604
Validation loss: 2.01158607006073

Epoch: 5| Step: 10
Training loss: 2.458646059036255
Validation loss: 2.0104727546374

Epoch: 5| Step: 11
Training loss: 2.235501766204834
Validation loss: 2.0053068747123084

Epoch: 150| Step: 0
Training loss: 1.943007469177246
Validation loss: 2.0010505616664886

Epoch: 5| Step: 1
Training loss: 2.2159299850463867
Validation loss: 2.0058293690284095

Epoch: 5| Step: 2
Training loss: 2.3251044750213623
Validation loss: 2.003620540102323

Epoch: 5| Step: 3
Training loss: 1.587691307067871
Validation loss: 1.998350203037262

Epoch: 5| Step: 4
Training loss: 1.8256686925888062
Validation loss: 1.9927154779434204

Epoch: 5| Step: 5
Training loss: 2.142817735671997
Validation loss: 2.009002606074015

Epoch: 5| Step: 6
Training loss: 2.4956247806549072
Validation loss: 2.002470001578331

Epoch: 5| Step: 7
Training loss: 2.364880323410034
Validation loss: 2.000739057858785

Epoch: 5| Step: 8
Training loss: 2.1332461833953857
Validation loss: 1.9956396222114563

Epoch: 5| Step: 9
Training loss: 1.6396499872207642
Validation loss: 2.005504071712494

Epoch: 5| Step: 10
Training loss: 2.3930270671844482
Validation loss: 2.019894311825434

Epoch: 5| Step: 11
Training loss: 1.6140644550323486
Validation loss: 2.0098400165637336

Epoch: 151| Step: 0
Training loss: 2.4413986206054688
Validation loss: 2.025203064084053

Epoch: 5| Step: 1
Training loss: 2.2616488933563232
Validation loss: 2.0229756782452264

Epoch: 5| Step: 2
Training loss: 2.395085096359253
Validation loss: 2.0238984475533166

Epoch: 5| Step: 3
Training loss: 2.1663901805877686
Validation loss: 2.022788425286611

Epoch: 5| Step: 4
Training loss: 2.0270309448242188
Validation loss: 2.027726635336876

Epoch: 5| Step: 5
Training loss: 2.367502212524414
Validation loss: 2.021761496861776

Epoch: 5| Step: 6
Training loss: 1.727726936340332
Validation loss: 2.0267386585474014

Epoch: 5| Step: 7
Training loss: 2.025230646133423
Validation loss: 2.029398595293363

Epoch: 5| Step: 8
Training loss: 1.8264210224151611
Validation loss: 2.0264660120010376

Epoch: 5| Step: 9
Training loss: 1.7262340784072876
Validation loss: 2.0270387480656304

Epoch: 5| Step: 10
Training loss: 2.022092342376709
Validation loss: 2.030401120583216

Epoch: 5| Step: 11
Training loss: 1.0736958980560303
Validation loss: 2.030487507581711

Epoch: 152| Step: 0
Training loss: 2.149064302444458
Validation loss: 2.025989000995954

Epoch: 5| Step: 1
Training loss: 1.895918846130371
Validation loss: 2.018629550933838

Epoch: 5| Step: 2
Training loss: 2.0073952674865723
Validation loss: 2.0251962343851724

Epoch: 5| Step: 3
Training loss: 2.305257797241211
Validation loss: 2.0187718073527017

Epoch: 5| Step: 4
Training loss: 1.5598965883255005
Validation loss: 2.0216794113318124

Epoch: 5| Step: 5
Training loss: 2.1013333797454834
Validation loss: 2.0256813317537308

Epoch: 5| Step: 6
Training loss: 2.5145139694213867
Validation loss: 2.0192712247371674

Epoch: 5| Step: 7
Training loss: 2.3270602226257324
Validation loss: 2.0225215951601663

Epoch: 5| Step: 8
Training loss: 1.7718427181243896
Validation loss: 2.025325064857801

Epoch: 5| Step: 9
Training loss: 2.2384867668151855
Validation loss: 2.029303436477979

Epoch: 5| Step: 10
Training loss: 2.0790209770202637
Validation loss: 2.0347284426291785

Epoch: 5| Step: 11
Training loss: 2.1199865341186523
Validation loss: 2.032835846145948

Epoch: 153| Step: 0
Training loss: 2.1144487857818604
Validation loss: 2.0318044871091843

Epoch: 5| Step: 1
Training loss: 2.3590123653411865
Validation loss: 2.0388219406207404

Epoch: 5| Step: 2
Training loss: 2.116121530532837
Validation loss: 2.0398827145497003

Epoch: 5| Step: 3
Training loss: 1.5344499349594116
Validation loss: 2.045097400744756

Epoch: 5| Step: 4
Training loss: 2.212132215499878
Validation loss: 2.0411045302947364

Epoch: 5| Step: 5
Training loss: 1.968510389328003
Validation loss: 2.0342279821634293

Epoch: 5| Step: 6
Training loss: 2.3951306343078613
Validation loss: 2.0303135961294174

Epoch: 5| Step: 7
Training loss: 2.296574831008911
Validation loss: 2.032197122772535

Epoch: 5| Step: 8
Training loss: 1.521475076675415
Validation loss: 2.028088832894961

Epoch: 5| Step: 9
Training loss: 2.318686008453369
Validation loss: 2.030467912554741

Epoch: 5| Step: 10
Training loss: 2.1186394691467285
Validation loss: 2.017926280697187

Epoch: 5| Step: 11
Training loss: 1.6512038707733154
Validation loss: 2.0191828111807504

Epoch: 154| Step: 0
Training loss: 1.7215144634246826
Validation loss: 2.0239767779906592

Epoch: 5| Step: 1
Training loss: 1.7775344848632812
Validation loss: 2.026598850886027

Epoch: 5| Step: 2
Training loss: 1.9881699085235596
Validation loss: 2.040751576423645

Epoch: 5| Step: 3
Training loss: 2.0581765174865723
Validation loss: 2.0327076464891434

Epoch: 5| Step: 4
Training loss: 2.071127414703369
Validation loss: 2.0432722866535187

Epoch: 5| Step: 5
Training loss: 1.6723804473876953
Validation loss: 2.0391242305437722

Epoch: 5| Step: 6
Training loss: 2.071659564971924
Validation loss: 2.0396585961182914

Epoch: 5| Step: 7
Training loss: 2.438971996307373
Validation loss: 2.033666809399923

Epoch: 5| Step: 8
Training loss: 2.204073667526245
Validation loss: 2.028506557146708

Epoch: 5| Step: 9
Training loss: 2.29801869392395
Validation loss: 2.0298240085442862

Epoch: 5| Step: 10
Training loss: 2.4242842197418213
Validation loss: 2.0179538230101266

Epoch: 5| Step: 11
Training loss: 1.9408725500106812
Validation loss: 2.0252280980348587

Epoch: 155| Step: 0
Training loss: 1.5271961688995361
Validation loss: 2.0273132572571435

Epoch: 5| Step: 1
Training loss: 1.9944721460342407
Validation loss: 2.0166947096586227

Epoch: 5| Step: 2
Training loss: 2.131293535232544
Validation loss: 2.0231396506230035

Epoch: 5| Step: 3
Training loss: 2.2330431938171387
Validation loss: 2.0334349274635315

Epoch: 5| Step: 4
Training loss: 2.3057117462158203
Validation loss: 2.0172927578290305

Epoch: 5| Step: 5
Training loss: 2.40482759475708
Validation loss: 2.018686423699061

Epoch: 5| Step: 6
Training loss: 2.127728223800659
Validation loss: 2.017546623945236

Epoch: 5| Step: 7
Training loss: 2.56221079826355
Validation loss: 2.0155603686968484

Epoch: 5| Step: 8
Training loss: 1.9443938732147217
Validation loss: 2.0187231401602426

Epoch: 5| Step: 9
Training loss: 1.8690884113311768
Validation loss: 2.0174519220987954

Epoch: 5| Step: 10
Training loss: 1.824872612953186
Validation loss: 2.0246411859989166

Epoch: 5| Step: 11
Training loss: 1.335729718208313
Validation loss: 2.0232848872741065

Epoch: 156| Step: 0
Training loss: 2.887657642364502
Validation loss: 2.0271653681993484

Epoch: 5| Step: 1
Training loss: 2.0065550804138184
Validation loss: 2.0302016536394754

Epoch: 5| Step: 2
Training loss: 1.8488872051239014
Validation loss: 2.034363547960917

Epoch: 5| Step: 3
Training loss: 2.2932980060577393
Validation loss: 2.025572275122007

Epoch: 5| Step: 4
Training loss: 1.7659975290298462
Validation loss: 2.02022647857666

Epoch: 5| Step: 5
Training loss: 1.795081377029419
Validation loss: 2.025242934624354

Epoch: 5| Step: 6
Training loss: 2.1145753860473633
Validation loss: 2.024619867404302

Epoch: 5| Step: 7
Training loss: 1.9297645092010498
Validation loss: 2.0223794678846994

Epoch: 5| Step: 8
Training loss: 2.0150482654571533
Validation loss: 2.0209742536147437

Epoch: 5| Step: 9
Training loss: 2.307711362838745
Validation loss: 2.0155359407265983

Epoch: 5| Step: 10
Training loss: 1.7069520950317383
Validation loss: 2.021965200702349

Epoch: 5| Step: 11
Training loss: 2.347973346710205
Validation loss: 2.027125433087349

Epoch: 157| Step: 0
Training loss: 2.174212694168091
Validation loss: 2.0256187866131463

Epoch: 5| Step: 1
Training loss: 1.926259994506836
Validation loss: 2.0187454173962274

Epoch: 5| Step: 2
Training loss: 2.2249112129211426
Validation loss: 2.022193670272827

Epoch: 5| Step: 3
Training loss: 1.8006649017333984
Validation loss: 2.0339853018522263

Epoch: 5| Step: 4
Training loss: 2.2938284873962402
Validation loss: 2.023473158478737

Epoch: 5| Step: 5
Training loss: 1.5878965854644775
Validation loss: 2.0186147540807724

Epoch: 5| Step: 6
Training loss: 2.7185468673706055
Validation loss: 2.014397546648979

Epoch: 5| Step: 7
Training loss: 2.33622670173645
Validation loss: 2.0245181818803153

Epoch: 5| Step: 8
Training loss: 2.179499626159668
Validation loss: 2.0301170647144318

Epoch: 5| Step: 9
Training loss: 1.949207067489624
Validation loss: 2.0214761247237525

Epoch: 5| Step: 10
Training loss: 1.7481105327606201
Validation loss: 2.020336707433065

Epoch: 5| Step: 11
Training loss: 0.821524977684021
Validation loss: 2.0215945541858673

Epoch: 158| Step: 0
Training loss: 1.9887510538101196
Validation loss: 2.0264019618431726

Epoch: 5| Step: 1
Training loss: 1.5352646112442017
Validation loss: 2.0318691035111747

Epoch: 5| Step: 2
Training loss: 2.346025228500366
Validation loss: 2.0314392298460007

Epoch: 5| Step: 3
Training loss: 2.2523093223571777
Validation loss: 2.0226643681526184

Epoch: 5| Step: 4
Training loss: 1.6794426441192627
Validation loss: 2.011387750506401

Epoch: 5| Step: 5
Training loss: 2.1383004188537598
Validation loss: 2.013142377138138

Epoch: 5| Step: 6
Training loss: 2.609508991241455
Validation loss: 2.0221319645643234

Epoch: 5| Step: 7
Training loss: 2.079965591430664
Validation loss: 2.0166160513957343

Epoch: 5| Step: 8
Training loss: 1.6602805852890015
Validation loss: 2.025419140855471

Epoch: 5| Step: 9
Training loss: 2.2427940368652344
Validation loss: 2.0302910208702087

Epoch: 5| Step: 10
Training loss: 2.2706663608551025
Validation loss: 2.0314312328894935

Epoch: 5| Step: 11
Training loss: 1.6422808170318604
Validation loss: 2.0468749006589255

Epoch: 159| Step: 0
Training loss: 1.7756335735321045
Validation loss: 2.0366017917792

Epoch: 5| Step: 1
Training loss: 2.2024128437042236
Validation loss: 2.0336905121803284

Epoch: 5| Step: 2
Training loss: 1.7446448802947998
Validation loss: 2.0453673054774604

Epoch: 5| Step: 3
Training loss: 2.3631956577301025
Validation loss: 2.032919853925705

Epoch: 5| Step: 4
Training loss: 2.2623982429504395
Validation loss: 2.044535741209984

Epoch: 5| Step: 5
Training loss: 2.3524396419525146
Validation loss: 2.0312748352686563

Epoch: 5| Step: 6
Training loss: 2.0645859241485596
Validation loss: 2.0209994117418923

Epoch: 5| Step: 7
Training loss: 2.0430915355682373
Validation loss: 2.024736002087593

Epoch: 5| Step: 8
Training loss: 1.6944156885147095
Validation loss: 2.0160178194443383

Epoch: 5| Step: 9
Training loss: 1.9944076538085938
Validation loss: 2.0222262342770896

Epoch: 5| Step: 10
Training loss: 1.7044979333877563
Validation loss: 2.021473521987597

Epoch: 5| Step: 11
Training loss: 4.09822940826416
Validation loss: 2.024672254920006

Epoch: 160| Step: 0
Training loss: 2.092545747756958
Validation loss: 2.01982053120931

Epoch: 5| Step: 1
Training loss: 2.1181843280792236
Validation loss: 2.010727440317472

Epoch: 5| Step: 2
Training loss: 1.873317003250122
Validation loss: 2.007316470146179

Epoch: 5| Step: 3
Training loss: 2.2415826320648193
Validation loss: 2.007283474008242

Epoch: 5| Step: 4
Training loss: 2.247690200805664
Validation loss: 2.018379623691241

Epoch: 5| Step: 5
Training loss: 1.8774287700653076
Validation loss: 2.0187100023031235

Epoch: 5| Step: 6
Training loss: 2.157686233520508
Validation loss: 2.0247030506531396

Epoch: 5| Step: 7
Training loss: 2.1141700744628906
Validation loss: 2.03098397453626

Epoch: 5| Step: 8
Training loss: 2.164029121398926
Validation loss: 2.0290907472372055

Epoch: 5| Step: 9
Training loss: 1.9235413074493408
Validation loss: 2.048329065243403

Epoch: 5| Step: 10
Training loss: 1.7508732080459595
Validation loss: 2.0442573875188828

Epoch: 5| Step: 11
Training loss: 3.1319570541381836
Validation loss: 2.0470163573821387

Epoch: 161| Step: 0
Training loss: 1.7008527517318726
Validation loss: 2.025813971956571

Epoch: 5| Step: 1
Training loss: 2.1045804023742676
Validation loss: 2.0301958521207175

Epoch: 5| Step: 2
Training loss: 2.9754445552825928
Validation loss: 2.019248162706693

Epoch: 5| Step: 3
Training loss: 2.069707155227661
Validation loss: 2.0149462471405664

Epoch: 5| Step: 4
Training loss: 2.2708849906921387
Validation loss: 2.0232742925484977

Epoch: 5| Step: 5
Training loss: 1.8952200412750244
Validation loss: 2.0239953647057214

Epoch: 5| Step: 6
Training loss: 2.064039945602417
Validation loss: 2.027022585272789

Epoch: 5| Step: 7
Training loss: 1.9659544229507446
Validation loss: 2.0275706897179284

Epoch: 5| Step: 8
Training loss: 2.183323621749878
Validation loss: 2.0288990835348764

Epoch: 5| Step: 9
Training loss: 2.258751392364502
Validation loss: 2.019508510828018

Epoch: 5| Step: 10
Training loss: 1.5342109203338623
Validation loss: 2.030062814553579

Epoch: 5| Step: 11
Training loss: 0.9432525634765625
Validation loss: 2.025611162185669

Epoch: 162| Step: 0
Training loss: 1.8359220027923584
Validation loss: 2.0418425103028617

Epoch: 5| Step: 1
Training loss: 2.0841095447540283
Validation loss: 2.0675332049528756

Epoch: 5| Step: 2
Training loss: 2.123901844024658
Validation loss: 2.0859153966108956

Epoch: 5| Step: 3
Training loss: 1.8733680248260498
Validation loss: 2.0885801215966544

Epoch: 5| Step: 4
Training loss: 2.1218154430389404
Validation loss: 2.059282968441645

Epoch: 5| Step: 5
Training loss: 2.367492914199829
Validation loss: 2.057185411453247

Epoch: 5| Step: 6
Training loss: 2.0664570331573486
Validation loss: 2.066727409760157

Epoch: 5| Step: 7
Training loss: 2.067936420440674
Validation loss: 2.049153889218966

Epoch: 5| Step: 8
Training loss: 2.379340171813965
Validation loss: 2.038012608885765

Epoch: 5| Step: 9
Training loss: 1.7925071716308594
Validation loss: 2.022786478201548

Epoch: 5| Step: 10
Training loss: 2.103086471557617
Validation loss: 2.0261710484822593

Epoch: 5| Step: 11
Training loss: 2.054202079772949
Validation loss: 2.0215661923090615

Epoch: 163| Step: 0
Training loss: 1.8494873046875
Validation loss: 2.026209990183512

Epoch: 5| Step: 1
Training loss: 1.8659851551055908
Validation loss: 2.02271069586277

Epoch: 5| Step: 2
Training loss: 2.171962261199951
Validation loss: 2.031591152151426

Epoch: 5| Step: 3
Training loss: 2.51442289352417
Validation loss: 2.025297383467356

Epoch: 5| Step: 4
Training loss: 2.1770098209381104
Validation loss: 2.0265119274457297

Epoch: 5| Step: 5
Training loss: 1.9776935577392578
Validation loss: 2.0253789176543555

Epoch: 5| Step: 6
Training loss: 2.2686831951141357
Validation loss: 2.0278401176134744

Epoch: 5| Step: 7
Training loss: 1.8511699438095093
Validation loss: 2.027501702308655

Epoch: 5| Step: 8
Training loss: 1.7063922882080078
Validation loss: 2.0280370662609735

Epoch: 5| Step: 9
Training loss: 2.61529278755188
Validation loss: 2.0399984568357468

Epoch: 5| Step: 10
Training loss: 1.9977493286132812
Validation loss: 2.045864765842756

Epoch: 5| Step: 11
Training loss: 1.7825791835784912
Validation loss: 2.0569045593341193

Epoch: 164| Step: 0
Training loss: 1.9073585271835327
Validation loss: 2.0617449482282004

Epoch: 5| Step: 1
Training loss: 2.0616233348846436
Validation loss: 2.0553609331448874

Epoch: 5| Step: 2
Training loss: 2.1566879749298096
Validation loss: 2.0419558386007943

Epoch: 5| Step: 3
Training loss: 2.3799490928649902
Validation loss: 2.0570138891537986

Epoch: 5| Step: 4
Training loss: 2.4761786460876465
Validation loss: 2.041827549537023

Epoch: 5| Step: 5
Training loss: 1.5546598434448242
Validation loss: 2.0237475285927453

Epoch: 5| Step: 6
Training loss: 2.013310432434082
Validation loss: 2.0246841410795846

Epoch: 5| Step: 7
Training loss: 1.9396852254867554
Validation loss: 2.018814126650492

Epoch: 5| Step: 8
Training loss: 2.2122015953063965
Validation loss: 2.0320690472920737

Epoch: 5| Step: 9
Training loss: 2.147597074508667
Validation loss: 2.0238148967425027

Epoch: 5| Step: 10
Training loss: 1.881669282913208
Validation loss: 2.025976369778315

Epoch: 5| Step: 11
Training loss: 3.032835006713867
Validation loss: 2.02518992125988

Epoch: 165| Step: 0
Training loss: 2.122969150543213
Validation loss: 2.0311906039714813

Epoch: 5| Step: 1
Training loss: 1.8356126546859741
Validation loss: 2.046337753534317

Epoch: 5| Step: 2
Training loss: 1.8205636739730835
Validation loss: 2.0269029239813485

Epoch: 5| Step: 3
Training loss: 2.1865499019622803
Validation loss: 2.0385188460350037

Epoch: 5| Step: 4
Training loss: 1.8714224100112915
Validation loss: 2.0360354483127594

Epoch: 5| Step: 5
Training loss: 1.886186957359314
Validation loss: 2.0429763346910477

Epoch: 5| Step: 6
Training loss: 2.8852832317352295
Validation loss: 2.039577012260755

Epoch: 5| Step: 7
Training loss: 1.5354652404785156
Validation loss: 2.0359287659327188

Epoch: 5| Step: 8
Training loss: 1.982140302658081
Validation loss: 2.0512725363175073

Epoch: 5| Step: 9
Training loss: 2.146730899810791
Validation loss: 2.05929825703303

Epoch: 5| Step: 10
Training loss: 2.095181703567505
Validation loss: 2.0836446980635324

Epoch: 5| Step: 11
Training loss: 3.7646851539611816
Validation loss: 2.074110209941864

Epoch: 166| Step: 0
Training loss: 1.6050962209701538
Validation loss: 2.074917897582054

Epoch: 5| Step: 1
Training loss: 1.9431324005126953
Validation loss: 2.0735692183176675

Epoch: 5| Step: 2
Training loss: 2.129220724105835
Validation loss: 2.058435315887133

Epoch: 5| Step: 3
Training loss: 1.4059317111968994
Validation loss: 2.0414072970549264

Epoch: 5| Step: 4
Training loss: 2.091322422027588
Validation loss: 2.0533523559570312

Epoch: 5| Step: 5
Training loss: 2.751861810684204
Validation loss: 2.032088816165924

Epoch: 5| Step: 6
Training loss: 1.561901569366455
Validation loss: 2.0359848688046136

Epoch: 5| Step: 7
Training loss: 1.7932889461517334
Validation loss: 2.030797084172567

Epoch: 5| Step: 8
Training loss: 2.1791281700134277
Validation loss: 2.027291918794314

Epoch: 5| Step: 9
Training loss: 2.6070215702056885
Validation loss: 2.0341694752375283

Epoch: 5| Step: 10
Training loss: 2.3499670028686523
Validation loss: 2.0243389705816903

Epoch: 5| Step: 11
Training loss: 3.0336806774139404
Validation loss: 2.0295687715212503

Epoch: 167| Step: 0
Training loss: 2.708026170730591
Validation loss: 2.038410951693853

Epoch: 5| Step: 1
Training loss: 1.8485887050628662
Validation loss: 2.0314582337935767

Epoch: 5| Step: 2
Training loss: 1.8941482305526733
Validation loss: 2.0371292332808175

Epoch: 5| Step: 3
Training loss: 2.302053213119507
Validation loss: 2.018523469567299

Epoch: 5| Step: 4
Training loss: 1.8018251657485962
Validation loss: 2.0331432620684304

Epoch: 5| Step: 5
Training loss: 1.1947405338287354
Validation loss: 2.033784473935763

Epoch: 5| Step: 6
Training loss: 1.626238226890564
Validation loss: 2.0393519749244056

Epoch: 5| Step: 7
Training loss: 2.4142050743103027
Validation loss: 2.037890230615934

Epoch: 5| Step: 8
Training loss: 2.6522700786590576
Validation loss: 2.039894863963127

Epoch: 5| Step: 9
Training loss: 1.8448717594146729
Validation loss: 2.0497808357079825

Epoch: 5| Step: 10
Training loss: 2.1937997341156006
Validation loss: 2.0571510593096414

Epoch: 5| Step: 11
Training loss: 1.9702000617980957
Validation loss: 2.0598333378632865

Epoch: 168| Step: 0
Training loss: 2.3480312824249268
Validation loss: 2.061348875363668

Epoch: 5| Step: 1
Training loss: 1.913874864578247
Validation loss: 2.092399870355924

Epoch: 5| Step: 2
Training loss: 2.378923177719116
Validation loss: 2.0926152914762497

Epoch: 5| Step: 3
Training loss: 1.9962494373321533
Validation loss: 2.095181251565615

Epoch: 5| Step: 4
Training loss: 1.8895483016967773
Validation loss: 2.096142202615738

Epoch: 5| Step: 5
Training loss: 1.8169984817504883
Validation loss: 2.1017995327711105

Epoch: 5| Step: 6
Training loss: 2.0114262104034424
Validation loss: 2.088548014561335

Epoch: 5| Step: 7
Training loss: 2.2831549644470215
Validation loss: 2.0684393843015036

Epoch: 5| Step: 8
Training loss: 1.8775628805160522
Validation loss: 2.058838432033857

Epoch: 5| Step: 9
Training loss: 2.1837239265441895
Validation loss: 2.0444311449925103

Epoch: 5| Step: 10
Training loss: 1.9957058429718018
Validation loss: 2.043210213383039

Epoch: 5| Step: 11
Training loss: 3.115757942199707
Validation loss: 2.030048375328382

Epoch: 169| Step: 0
Training loss: 2.3662312030792236
Validation loss: 2.037070189913114

Epoch: 5| Step: 1
Training loss: 2.084507703781128
Validation loss: 2.0320887019236884

Epoch: 5| Step: 2
Training loss: 2.053976535797119
Validation loss: 2.031540960073471

Epoch: 5| Step: 3
Training loss: 2.0626490116119385
Validation loss: 2.0341176142295203

Epoch: 5| Step: 4
Training loss: 2.309086322784424
Validation loss: 2.0323358128468194

Epoch: 5| Step: 5
Training loss: 1.9818878173828125
Validation loss: 2.0400021175543466

Epoch: 5| Step: 6
Training loss: 2.3168907165527344
Validation loss: 2.0277223140001297

Epoch: 5| Step: 7
Training loss: 1.5058397054672241
Validation loss: 2.0424385368824005

Epoch: 5| Step: 8
Training loss: 2.060555934906006
Validation loss: 2.043623169263204

Epoch: 5| Step: 9
Training loss: 1.7468574047088623
Validation loss: 2.04088964064916

Epoch: 5| Step: 10
Training loss: 2.4120473861694336
Validation loss: 2.0396550794442496

Epoch: 5| Step: 11
Training loss: 1.8996270895004272
Validation loss: 2.0516024827957153

Epoch: 170| Step: 0
Training loss: 2.302232027053833
Validation loss: 2.0582999885082245

Epoch: 5| Step: 1
Training loss: 2.3732495307922363
Validation loss: 2.0409521659215293

Epoch: 5| Step: 2
Training loss: 2.3213260173797607
Validation loss: 2.0404359698295593

Epoch: 5| Step: 3
Training loss: 2.556825876235962
Validation loss: 2.038660635550817

Epoch: 5| Step: 4
Training loss: 2.323021411895752
Validation loss: 2.060640295346578

Epoch: 5| Step: 5
Training loss: 1.702350378036499
Validation loss: 2.0560412257909775

Epoch: 5| Step: 6
Training loss: 1.8411794900894165
Validation loss: 2.0409997006257377

Epoch: 5| Step: 7
Training loss: 1.7656819820404053
Validation loss: 2.039661447207133

Epoch: 5| Step: 8
Training loss: 1.8511707782745361
Validation loss: 2.0353802194197974

Epoch: 5| Step: 9
Training loss: 1.9249677658081055
Validation loss: 2.040819446245829

Epoch: 5| Step: 10
Training loss: 1.6666313409805298
Validation loss: 2.034002115329107

Epoch: 5| Step: 11
Training loss: 1.8397939205169678
Validation loss: 2.042904625336329

Epoch: 171| Step: 0
Training loss: 1.9772651195526123
Validation loss: 2.0626857777436576

Epoch: 5| Step: 1
Training loss: 1.8812015056610107
Validation loss: 2.0583919982115426

Epoch: 5| Step: 2
Training loss: 2.6802241802215576
Validation loss: 2.0657111356655755

Epoch: 5| Step: 3
Training loss: 2.0064594745635986
Validation loss: 2.0656903932491937

Epoch: 5| Step: 4
Training loss: 2.0571374893188477
Validation loss: 2.0580557584762573

Epoch: 5| Step: 5
Training loss: 1.607835054397583
Validation loss: 2.0683965335289636

Epoch: 5| Step: 6
Training loss: 1.9208282232284546
Validation loss: 2.0565535575151443

Epoch: 5| Step: 7
Training loss: 2.047839403152466
Validation loss: 2.0502817183732986

Epoch: 5| Step: 8
Training loss: 2.3822827339172363
Validation loss: 2.0541616131862006

Epoch: 5| Step: 9
Training loss: 2.2076218128204346
Validation loss: 2.056971271832784

Epoch: 5| Step: 10
Training loss: 1.9039819240570068
Validation loss: 2.0467794289191565

Epoch: 5| Step: 11
Training loss: 1.3084269762039185
Validation loss: 2.0508203307787576

Epoch: 172| Step: 0
Training loss: 1.9185791015625
Validation loss: 2.0422207762797675

Epoch: 5| Step: 1
Training loss: 1.8552194833755493
Validation loss: 2.0463218837976456

Epoch: 5| Step: 2
Training loss: 1.6949764490127563
Validation loss: 2.0291391213734946

Epoch: 5| Step: 3
Training loss: 2.0902915000915527
Validation loss: 2.0381581485271454

Epoch: 5| Step: 4
Training loss: 1.818023681640625
Validation loss: 2.0387108623981476

Epoch: 5| Step: 5
Training loss: 2.383195400238037
Validation loss: 2.049072116613388

Epoch: 5| Step: 6
Training loss: 2.5128700733184814
Validation loss: 2.0369903395573297

Epoch: 5| Step: 7
Training loss: 2.1906991004943848
Validation loss: 2.0473773231108985

Epoch: 5| Step: 8
Training loss: 1.946115493774414
Validation loss: 2.043428808450699

Epoch: 5| Step: 9
Training loss: 2.3252782821655273
Validation loss: 2.0427910834550858

Epoch: 5| Step: 10
Training loss: 1.7565486431121826
Validation loss: 2.0474052081505456

Epoch: 5| Step: 11
Training loss: 1.8258670568466187
Validation loss: 2.047328308224678

Epoch: 173| Step: 0
Training loss: 2.046074390411377
Validation loss: 2.0565035939216614

Epoch: 5| Step: 1
Training loss: 2.4777274131774902
Validation loss: 2.0530029386281967

Epoch: 5| Step: 2
Training loss: 1.7097278833389282
Validation loss: 2.056900436679522

Epoch: 5| Step: 3
Training loss: 2.0601861476898193
Validation loss: 2.0490137537320456

Epoch: 5| Step: 4
Training loss: 2.1547069549560547
Validation loss: 2.0516069382429123

Epoch: 5| Step: 5
Training loss: 2.317671537399292
Validation loss: 2.0492809315522513

Epoch: 5| Step: 6
Training loss: 2.16011118888855
Validation loss: 2.0565394957860312

Epoch: 5| Step: 7
Training loss: 1.7674036026000977
Validation loss: 2.052806889017423

Epoch: 5| Step: 8
Training loss: 2.1110899448394775
Validation loss: 2.055658241113027

Epoch: 5| Step: 9
Training loss: 1.6803268194198608
Validation loss: 2.0552488267421722

Epoch: 5| Step: 10
Training loss: 2.126380205154419
Validation loss: 2.0527112831672034

Epoch: 5| Step: 11
Training loss: 1.3860729932785034
Validation loss: 2.0422769337892532

Epoch: 174| Step: 0
Training loss: 2.0407605171203613
Validation loss: 2.031856099764506

Epoch: 5| Step: 1
Training loss: 2.23380708694458
Validation loss: 2.0319814632336297

Epoch: 5| Step: 2
Training loss: 2.353484630584717
Validation loss: 2.0377994030714035

Epoch: 5| Step: 3
Training loss: 2.212338447570801
Validation loss: 2.0326238175233207

Epoch: 5| Step: 4
Training loss: 1.9035584926605225
Validation loss: 2.038735310236613

Epoch: 5| Step: 5
Training loss: 1.6014471054077148
Validation loss: 2.0332386791706085

Epoch: 5| Step: 6
Training loss: 2.4389567375183105
Validation loss: 2.0346776793400445

Epoch: 5| Step: 7
Training loss: 1.934133768081665
Validation loss: 2.039867545167605

Epoch: 5| Step: 8
Training loss: 1.5881011486053467
Validation loss: 2.0389105727275214

Epoch: 5| Step: 9
Training loss: 2.2478489875793457
Validation loss: 2.0356955329577127

Epoch: 5| Step: 10
Training loss: 2.0433061122894287
Validation loss: 2.039208317796389

Epoch: 5| Step: 11
Training loss: 1.2368571758270264
Validation loss: 2.0390421003103256

Epoch: 175| Step: 0
Training loss: 1.736504316329956
Validation loss: 2.0421443482240043

Epoch: 5| Step: 1
Training loss: 2.5117180347442627
Validation loss: 2.030913382768631

Epoch: 5| Step: 2
Training loss: 2.0688529014587402
Validation loss: 2.0267870128154755

Epoch: 5| Step: 3
Training loss: 2.449021816253662
Validation loss: 2.0420874853928885

Epoch: 5| Step: 4
Training loss: 2.1999576091766357
Validation loss: 2.031892860929171

Epoch: 5| Step: 5
Training loss: 1.5629059076309204
Validation loss: 2.0365057289600372

Epoch: 5| Step: 6
Training loss: 1.964194893836975
Validation loss: 2.0284371227025986

Epoch: 5| Step: 7
Training loss: 2.110167980194092
Validation loss: 2.034746135274569

Epoch: 5| Step: 8
Training loss: 1.613637924194336
Validation loss: 2.03456058104833

Epoch: 5| Step: 9
Training loss: 1.948207139968872
Validation loss: 2.0199083536863327

Epoch: 5| Step: 10
Training loss: 2.4034476280212402
Validation loss: 2.016788070400556

Epoch: 5| Step: 11
Training loss: 1.834963321685791
Validation loss: 2.0345512876907983

Epoch: 176| Step: 0
Training loss: 2.1041102409362793
Validation loss: 2.0343295335769653

Epoch: 5| Step: 1
Training loss: 1.6818897724151611
Validation loss: 2.0425782154003778

Epoch: 5| Step: 2
Training loss: 2.1049387454986572
Validation loss: 2.037625332673391

Epoch: 5| Step: 3
Training loss: 2.115255832672119
Validation loss: 2.059341222047806

Epoch: 5| Step: 4
Training loss: 2.34236478805542
Validation loss: 2.066130747397741

Epoch: 5| Step: 5
Training loss: 2.0065770149230957
Validation loss: 2.0560289869705834

Epoch: 5| Step: 6
Training loss: 1.791785478591919
Validation loss: 2.0586399038632712

Epoch: 5| Step: 7
Training loss: 1.4764976501464844
Validation loss: 2.0543158849080405

Epoch: 5| Step: 8
Training loss: 2.6285367012023926
Validation loss: 2.051899383465449

Epoch: 5| Step: 9
Training loss: 2.1476974487304688
Validation loss: 2.047869478662809

Epoch: 5| Step: 10
Training loss: 2.430938243865967
Validation loss: 2.033324812849363

Epoch: 5| Step: 11
Training loss: 1.857806921005249
Validation loss: 2.0266096591949463

Epoch: 177| Step: 0
Training loss: 2.105017900466919
Validation loss: 2.0201349755128226

Epoch: 5| Step: 1
Training loss: 2.4134819507598877
Validation loss: 2.0281429986159005

Epoch: 5| Step: 2
Training loss: 1.479248046875
Validation loss: 2.0207012991110482

Epoch: 5| Step: 3
Training loss: 1.7853429317474365
Validation loss: 2.0268308520317078

Epoch: 5| Step: 4
Training loss: 1.7641656398773193
Validation loss: 2.017967253923416

Epoch: 5| Step: 5
Training loss: 2.4617161750793457
Validation loss: 2.0361165205637612

Epoch: 5| Step: 6
Training loss: 2.4621219635009766
Validation loss: 2.027218942840894

Epoch: 5| Step: 7
Training loss: 2.0320489406585693
Validation loss: 2.0262179225683212

Epoch: 5| Step: 8
Training loss: 1.7612006664276123
Validation loss: 2.0316044837236404

Epoch: 5| Step: 9
Training loss: 2.003143310546875
Validation loss: 2.042528659105301

Epoch: 5| Step: 10
Training loss: 2.3875064849853516
Validation loss: 2.019659241040548

Epoch: 5| Step: 11
Training loss: 1.92560875415802
Validation loss: 2.036564047137896

Epoch: 178| Step: 0
Training loss: 2.148972988128662
Validation loss: 2.036540597677231

Epoch: 5| Step: 1
Training loss: 1.5627014636993408
Validation loss: 2.0374252746502557

Epoch: 5| Step: 2
Training loss: 1.9007670879364014
Validation loss: 2.0429724107186

Epoch: 5| Step: 3
Training loss: 2.498755931854248
Validation loss: 2.049888531366984

Epoch: 5| Step: 4
Training loss: 2.230830669403076
Validation loss: 2.0354218930006027

Epoch: 5| Step: 5
Training loss: 1.898226022720337
Validation loss: 2.0351173679033914

Epoch: 5| Step: 6
Training loss: 1.5323420763015747
Validation loss: 2.050990124543508

Epoch: 5| Step: 7
Training loss: 2.4193949699401855
Validation loss: 2.045025939742724

Epoch: 5| Step: 8
Training loss: 2.4395387172698975
Validation loss: 2.0359546840190887

Epoch: 5| Step: 9
Training loss: 1.906164526939392
Validation loss: 2.052913174033165

Epoch: 5| Step: 10
Training loss: 1.7816708087921143
Validation loss: 2.0528753101825714

Epoch: 5| Step: 11
Training loss: 3.1568543910980225
Validation loss: 2.0506282250086465

Epoch: 179| Step: 0
Training loss: 1.5213119983673096
Validation loss: 2.06415231525898

Epoch: 5| Step: 1
Training loss: 1.7532771825790405
Validation loss: 2.0516335666179657

Epoch: 5| Step: 2
Training loss: 2.0277860164642334
Validation loss: 2.059204548597336

Epoch: 5| Step: 3
Training loss: 2.0837008953094482
Validation loss: 2.0464914788802466

Epoch: 5| Step: 4
Training loss: 2.737355947494507
Validation loss: 2.0299425373474755

Epoch: 5| Step: 5
Training loss: 2.608699321746826
Validation loss: 2.0524771014849343

Epoch: 5| Step: 6
Training loss: 1.4898139238357544
Validation loss: 2.0297538886467614

Epoch: 5| Step: 7
Training loss: 2.000823497772217
Validation loss: 2.0334184070428214

Epoch: 5| Step: 8
Training loss: 2.02852201461792
Validation loss: 2.03444833556811

Epoch: 5| Step: 9
Training loss: 2.2887532711029053
Validation loss: 2.028208131591479

Epoch: 5| Step: 10
Training loss: 1.685146689414978
Validation loss: 2.028096159299215

Epoch: 5| Step: 11
Training loss: 2.4594078063964844
Validation loss: 2.0360638548930488

Epoch: 180| Step: 0
Training loss: 2.1001975536346436
Validation loss: 2.031068429350853

Epoch: 5| Step: 1
Training loss: 1.8285678625106812
Validation loss: 2.0279136498769126

Epoch: 5| Step: 2
Training loss: 1.9458402395248413
Validation loss: 2.017519702514013

Epoch: 5| Step: 3
Training loss: 1.6013448238372803
Validation loss: 2.0296342025200524

Epoch: 5| Step: 4
Training loss: 2.047159194946289
Validation loss: 2.0281919737656913

Epoch: 5| Step: 5
Training loss: 2.2999777793884277
Validation loss: 2.0213646541039147

Epoch: 5| Step: 6
Training loss: 1.8383992910385132
Validation loss: 2.038245990872383

Epoch: 5| Step: 7
Training loss: 1.9876554012298584
Validation loss: 2.030384048819542

Epoch: 5| Step: 8
Training loss: 2.150376796722412
Validation loss: 2.0151179681221643

Epoch: 5| Step: 9
Training loss: 2.506631851196289
Validation loss: 2.0291650543610253

Epoch: 5| Step: 10
Training loss: 2.0817697048187256
Validation loss: 2.0261898140112558

Epoch: 5| Step: 11
Training loss: 2.1643757820129395
Validation loss: 2.0352308054765067

Epoch: 181| Step: 0
Training loss: 2.1780641078948975
Validation loss: 2.0458139379819236

Epoch: 5| Step: 1
Training loss: 1.9599418640136719
Validation loss: 2.0328226685523987

Epoch: 5| Step: 2
Training loss: 2.1295790672302246
Validation loss: 2.0288998087247214

Epoch: 5| Step: 3
Training loss: 1.9819612503051758
Validation loss: 2.0386528968811035

Epoch: 5| Step: 4
Training loss: 2.4246506690979004
Validation loss: 2.0319394369920096

Epoch: 5| Step: 5
Training loss: 1.834059715270996
Validation loss: 2.047425851225853

Epoch: 5| Step: 6
Training loss: 1.9947296380996704
Validation loss: 2.0560652116934457

Epoch: 5| Step: 7
Training loss: 2.0577280521392822
Validation loss: 2.0591269036134086

Epoch: 5| Step: 8
Training loss: 2.1981358528137207
Validation loss: 2.0496954123179116

Epoch: 5| Step: 9
Training loss: 2.156751871109009
Validation loss: 2.074323003490766

Epoch: 5| Step: 10
Training loss: 1.6903283596038818
Validation loss: 2.0669271300236383

Epoch: 5| Step: 11
Training loss: 1.3705024719238281
Validation loss: 2.090410570303599

Epoch: 182| Step: 0
Training loss: 2.01348876953125
Validation loss: 2.073606198032697

Epoch: 5| Step: 1
Training loss: 1.8623195886611938
Validation loss: 2.065959796309471

Epoch: 5| Step: 2
Training loss: 2.384171724319458
Validation loss: 2.068048655986786

Epoch: 5| Step: 3
Training loss: 2.549834728240967
Validation loss: 2.0459083914756775

Epoch: 5| Step: 4
Training loss: 2.0808253288269043
Validation loss: 2.04641584555308

Epoch: 5| Step: 5
Training loss: 2.1038565635681152
Validation loss: 2.047899603843689

Epoch: 5| Step: 6
Training loss: 1.649468183517456
Validation loss: 2.0516568273305893

Epoch: 5| Step: 7
Training loss: 1.6163829565048218
Validation loss: 2.0509443630774817

Epoch: 5| Step: 8
Training loss: 2.532986879348755
Validation loss: 2.056724891066551

Epoch: 5| Step: 9
Training loss: 1.6155105829238892
Validation loss: 2.057189399997393

Epoch: 5| Step: 10
Training loss: 2.0695674419403076
Validation loss: 2.072533736626307

Epoch: 5| Step: 11
Training loss: 2.4107613563537598
Validation loss: 2.0701550990343094

Epoch: 183| Step: 0
Training loss: 1.8825149536132812
Validation loss: 2.0692628969748816

Epoch: 5| Step: 1
Training loss: 2.1904942989349365
Validation loss: 2.0824626882870994

Epoch: 5| Step: 2
Training loss: 2.1811723709106445
Validation loss: 2.071797331174215

Epoch: 5| Step: 3
Training loss: 2.2145087718963623
Validation loss: 2.0517945835987725

Epoch: 5| Step: 4
Training loss: 2.3730220794677734
Validation loss: 2.0620359977086387

Epoch: 5| Step: 5
Training loss: 2.2144436836242676
Validation loss: 2.0571113973855972

Epoch: 5| Step: 6
Training loss: 1.874851942062378
Validation loss: 2.072070191303889

Epoch: 5| Step: 7
Training loss: 1.7416810989379883
Validation loss: 2.0573704888423285

Epoch: 5| Step: 8
Training loss: 1.880251169204712
Validation loss: 2.0526409347852073

Epoch: 5| Step: 9
Training loss: 1.5065691471099854
Validation loss: 2.043738136688868

Epoch: 5| Step: 10
Training loss: 2.2179129123687744
Validation loss: 2.046656275788943

Epoch: 5| Step: 11
Training loss: 2.356271505355835
Validation loss: 2.034444193045298

Epoch: 184| Step: 0
Training loss: 2.0445823669433594
Validation loss: 2.039431616663933

Epoch: 5| Step: 1
Training loss: 1.9135572910308838
Validation loss: 2.022648056348165

Epoch: 5| Step: 2
Training loss: 1.8286006450653076
Validation loss: 2.0240996976693473

Epoch: 5| Step: 3
Training loss: 1.5894629955291748
Validation loss: 2.014761139949163

Epoch: 5| Step: 4
Training loss: 2.2008328437805176
Validation loss: 2.0295392026503882

Epoch: 5| Step: 5
Training loss: 2.3546080589294434
Validation loss: 2.008791337410609

Epoch: 5| Step: 6
Training loss: 1.903259038925171
Validation loss: 2.0336328595876694

Epoch: 5| Step: 7
Training loss: 2.439481019973755
Validation loss: 2.029265269637108

Epoch: 5| Step: 8
Training loss: 2.336688756942749
Validation loss: 2.0261445343494415

Epoch: 5| Step: 9
Training loss: 1.654829978942871
Validation loss: 2.025738721092542

Epoch: 5| Step: 10
Training loss: 2.235819101333618
Validation loss: 2.042497158050537

Epoch: 5| Step: 11
Training loss: 1.3849141597747803
Validation loss: 2.0507675210634866

Epoch: 185| Step: 0
Training loss: 2.0829062461853027
Validation loss: 2.0479574352502823

Epoch: 5| Step: 1
Training loss: 1.972772240638733
Validation loss: 2.04012701412042

Epoch: 5| Step: 2
Training loss: 1.5701253414154053
Validation loss: 2.029607892036438

Epoch: 5| Step: 3
Training loss: 1.8704181909561157
Validation loss: 2.0505491495132446

Epoch: 5| Step: 4
Training loss: 1.3808484077453613
Validation loss: 2.0396498143672943

Epoch: 5| Step: 5
Training loss: 2.5198569297790527
Validation loss: 2.0454099476337433

Epoch: 5| Step: 6
Training loss: 2.3827786445617676
Validation loss: 2.0331879605849585

Epoch: 5| Step: 7
Training loss: 2.15524959564209
Validation loss: 2.0377662430206933

Epoch: 5| Step: 8
Training loss: 2.4072742462158203
Validation loss: 2.0162527561187744

Epoch: 5| Step: 9
Training loss: 1.8138625621795654
Validation loss: 2.024061292409897

Epoch: 5| Step: 10
Training loss: 2.2573680877685547
Validation loss: 2.0260948638121286

Epoch: 5| Step: 11
Training loss: 1.9163650274276733
Validation loss: 2.0190111100673676

Epoch: 186| Step: 0
Training loss: 2.281130075454712
Validation loss: 2.0296558936436973

Epoch: 5| Step: 1
Training loss: 2.013469696044922
Validation loss: 2.0354065696398416

Epoch: 5| Step: 2
Training loss: 1.2416030168533325
Validation loss: 2.033065587282181

Epoch: 5| Step: 3
Training loss: 1.7213013172149658
Validation loss: 2.028716196616491

Epoch: 5| Step: 4
Training loss: 1.8960046768188477
Validation loss: 2.043422609567642

Epoch: 5| Step: 5
Training loss: 2.222994565963745
Validation loss: 2.0368306189775467

Epoch: 5| Step: 6
Training loss: 1.893265962600708
Validation loss: 2.0393692503372827

Epoch: 5| Step: 7
Training loss: 1.9421348571777344
Validation loss: 2.026677285631498

Epoch: 5| Step: 8
Training loss: 2.202932119369507
Validation loss: 2.0461713473002114

Epoch: 5| Step: 9
Training loss: 2.3288979530334473
Validation loss: 2.0473241955041885

Epoch: 5| Step: 10
Training loss: 2.315333127975464
Validation loss: 2.0594937105973563

Epoch: 5| Step: 11
Training loss: 3.0834665298461914
Validation loss: 2.0604608158270517

Epoch: 187| Step: 0
Training loss: 1.8612123727798462
Validation loss: 2.0938329795996347

Epoch: 5| Step: 1
Training loss: 1.7072598934173584
Validation loss: 2.1181382685899734

Epoch: 5| Step: 2
Training loss: 1.9319909811019897
Validation loss: 2.15352230767409

Epoch: 5| Step: 3
Training loss: 2.1120285987854004
Validation loss: 2.1194271246592202

Epoch: 5| Step: 4
Training loss: 2.031482696533203
Validation loss: 2.130047063032786

Epoch: 5| Step: 5
Training loss: 2.568025827407837
Validation loss: 2.1033926804860434

Epoch: 5| Step: 6
Training loss: 2.228116273880005
Validation loss: 2.068299109737078

Epoch: 5| Step: 7
Training loss: 2.8971638679504395
Validation loss: 2.044891575972239

Epoch: 5| Step: 8
Training loss: 1.956743836402893
Validation loss: 2.018190771341324

Epoch: 5| Step: 9
Training loss: 2.187779664993286
Validation loss: 2.0070779224236808

Epoch: 5| Step: 10
Training loss: 1.8527297973632812
Validation loss: 2.0374331921339035

Epoch: 5| Step: 11
Training loss: 2.300699234008789
Validation loss: 2.042625139156977

Epoch: 188| Step: 0
Training loss: 1.9245237112045288
Validation loss: 2.0628894766171775

Epoch: 5| Step: 1
Training loss: 1.9159982204437256
Validation loss: 2.073950399955114

Epoch: 5| Step: 2
Training loss: 2.1935184001922607
Validation loss: 2.082407221198082

Epoch: 5| Step: 3
Training loss: 1.9113105535507202
Validation loss: 2.0834843715031943

Epoch: 5| Step: 4
Training loss: 2.2332653999328613
Validation loss: 2.0843453407287598

Epoch: 5| Step: 5
Training loss: 2.0092623233795166
Validation loss: 2.08985165754954

Epoch: 5| Step: 6
Training loss: 2.550745725631714
Validation loss: 2.089847058057785

Epoch: 5| Step: 7
Training loss: 2.3213040828704834
Validation loss: 2.0862845182418823

Epoch: 5| Step: 8
Training loss: 2.4353995323181152
Validation loss: 2.0920795996983848

Epoch: 5| Step: 9
Training loss: 2.4887073040008545
Validation loss: 2.077236329515775

Epoch: 5| Step: 10
Training loss: 1.8169209957122803
Validation loss: 2.082548663020134

Epoch: 5| Step: 11
Training loss: 2.4540905952453613
Validation loss: 2.0820248971382775

Epoch: 189| Step: 0
Training loss: 2.2375807762145996
Validation loss: 2.0752114405234656

Epoch: 5| Step: 1
Training loss: 2.1346590518951416
Validation loss: 2.0751494417587915

Epoch: 5| Step: 2
Training loss: 2.296285629272461
Validation loss: 2.066720023751259

Epoch: 5| Step: 3
Training loss: 2.1232974529266357
Validation loss: 2.0696706672509513

Epoch: 5| Step: 4
Training loss: 2.3406624794006348
Validation loss: 2.060597851872444

Epoch: 5| Step: 5
Training loss: 2.372507095336914
Validation loss: 2.058442493279775

Epoch: 5| Step: 6
Training loss: 2.2005739212036133
Validation loss: 2.0420166353384652

Epoch: 5| Step: 7
Training loss: 1.7953916788101196
Validation loss: 2.0310719907283783

Epoch: 5| Step: 8
Training loss: 1.9337495565414429
Validation loss: 2.0201519231001535

Epoch: 5| Step: 9
Training loss: 2.2050976753234863
Validation loss: 2.0170476833979287

Epoch: 5| Step: 10
Training loss: 1.7392603158950806
Validation loss: 2.0216062863667807

Epoch: 5| Step: 11
Training loss: 1.5882524251937866
Validation loss: 2.034874697526296

Epoch: 190| Step: 0
Training loss: 1.8774725198745728
Validation loss: 2.036726032694181

Epoch: 5| Step: 1
Training loss: 2.1783952713012695
Validation loss: 2.0499552885691323

Epoch: 5| Step: 2
Training loss: 1.9382082223892212
Validation loss: 2.0612426151831946

Epoch: 5| Step: 3
Training loss: 1.8116753101348877
Validation loss: 2.060355712970098

Epoch: 5| Step: 4
Training loss: 2.162546157836914
Validation loss: 2.0810417334238687

Epoch: 5| Step: 5
Training loss: 1.4867461919784546
Validation loss: 2.076611946026484

Epoch: 5| Step: 6
Training loss: 2.028621196746826
Validation loss: 2.083821415901184

Epoch: 5| Step: 7
Training loss: 2.534764289855957
Validation loss: 2.074176768461863

Epoch: 5| Step: 8
Training loss: 1.9880163669586182
Validation loss: 2.0776808758576712

Epoch: 5| Step: 9
Training loss: 2.2762930393218994
Validation loss: 2.0676452169815698

Epoch: 5| Step: 10
Training loss: 2.3762998580932617
Validation loss: 2.0542058597008386

Epoch: 5| Step: 11
Training loss: 1.1696360111236572
Validation loss: 2.060117373863856

Epoch: 191| Step: 0
Training loss: 2.5894148349761963
Validation loss: 2.056336224079132

Epoch: 5| Step: 1
Training loss: 2.3615050315856934
Validation loss: 2.062247430284818

Epoch: 5| Step: 2
Training loss: 1.8173246383666992
Validation loss: 2.0638328989346824

Epoch: 5| Step: 3
Training loss: 2.148505687713623
Validation loss: 2.075977146625519

Epoch: 5| Step: 4
Training loss: 1.5989389419555664
Validation loss: 2.058619146545728

Epoch: 5| Step: 5
Training loss: 2.251734972000122
Validation loss: 2.066234995921453

Epoch: 5| Step: 6
Training loss: 1.8953673839569092
Validation loss: 2.0661014864842095

Epoch: 5| Step: 7
Training loss: 1.815421462059021
Validation loss: 2.0767329931259155

Epoch: 5| Step: 8
Training loss: 1.7928669452667236
Validation loss: 2.083047558863958

Epoch: 5| Step: 9
Training loss: 2.0457262992858887
Validation loss: 2.0630670934915543

Epoch: 5| Step: 10
Training loss: 1.8841040134429932
Validation loss: 2.072161386410395

Epoch: 5| Step: 11
Training loss: 2.4638614654541016
Validation loss: 2.078426624337832

Epoch: 192| Step: 0
Training loss: 2.6389729976654053
Validation loss: 2.0848759015401206

Epoch: 5| Step: 1
Training loss: 2.015028715133667
Validation loss: 2.0660733729600906

Epoch: 5| Step: 2
Training loss: 1.9459254741668701
Validation loss: 2.082432692249616

Epoch: 5| Step: 3
Training loss: 1.9381616115570068
Validation loss: 2.0607899526755014

Epoch: 5| Step: 4
Training loss: 2.011244297027588
Validation loss: 2.061186596751213

Epoch: 5| Step: 5
Training loss: 1.8758662939071655
Validation loss: 2.0556035141150155

Epoch: 5| Step: 6
Training loss: 1.6698795557022095
Validation loss: 2.0654532611370087

Epoch: 5| Step: 7
Training loss: 2.1026511192321777
Validation loss: 2.054626921812693

Epoch: 5| Step: 8
Training loss: 2.0957865715026855
Validation loss: 2.071805586417516

Epoch: 5| Step: 9
Training loss: 1.8254839181900024
Validation loss: 2.0689499775568643

Epoch: 5| Step: 10
Training loss: 2.066632032394409
Validation loss: 2.0583013395468392

Epoch: 5| Step: 11
Training loss: 2.1671295166015625
Validation loss: 2.0666337261597314

Epoch: 193| Step: 0
Training loss: 1.6805366277694702
Validation loss: 2.0591222693522773

Epoch: 5| Step: 1
Training loss: 2.900752544403076
Validation loss: 2.0687396625677743

Epoch: 5| Step: 2
Training loss: 1.9969522953033447
Validation loss: 2.0779547492663064

Epoch: 5| Step: 3
Training loss: 1.745883584022522
Validation loss: 2.072572802503904

Epoch: 5| Step: 4
Training loss: 1.8261619806289673
Validation loss: 2.0680304119984307

Epoch: 5| Step: 5
Training loss: 2.467740058898926
Validation loss: 2.0704126805067062

Epoch: 5| Step: 6
Training loss: 2.0521090030670166
Validation loss: 2.0584926505883536

Epoch: 5| Step: 7
Training loss: 1.3872662782669067
Validation loss: 2.061813563108444

Epoch: 5| Step: 8
Training loss: 2.041363477706909
Validation loss: 2.057929575443268

Epoch: 5| Step: 9
Training loss: 1.3909677267074585
Validation loss: 2.046931435664495

Epoch: 5| Step: 10
Training loss: 2.5127482414245605
Validation loss: 2.04933999478817

Epoch: 5| Step: 11
Training loss: 2.4460530281066895
Validation loss: 2.049802561601003

Epoch: 194| Step: 0
Training loss: 1.6963173151016235
Validation loss: 2.043423200647036

Epoch: 5| Step: 1
Training loss: 2.3862948417663574
Validation loss: 2.0488760620355606

Epoch: 5| Step: 2
Training loss: 2.0391368865966797
Validation loss: 2.030608261624972

Epoch: 5| Step: 3
Training loss: 1.6516857147216797
Validation loss: 2.032972201704979

Epoch: 5| Step: 4
Training loss: 2.324120044708252
Validation loss: 2.0317221730947495

Epoch: 5| Step: 5
Training loss: 2.084152936935425
Validation loss: 2.0300258149703345

Epoch: 5| Step: 6
Training loss: 2.134737253189087
Validation loss: 2.038832277059555

Epoch: 5| Step: 7
Training loss: 1.7490249872207642
Validation loss: 2.0381774057944617

Epoch: 5| Step: 8
Training loss: 1.7231409549713135
Validation loss: 2.0365193436543145

Epoch: 5| Step: 9
Training loss: 1.6805191040039062
Validation loss: 2.045311599969864

Epoch: 5| Step: 10
Training loss: 2.8147263526916504
Validation loss: 2.0449595352013907

Epoch: 5| Step: 11
Training loss: 2.5354676246643066
Validation loss: 2.0363027304410934

Epoch: 195| Step: 0
Training loss: 2.423835039138794
Validation loss: 2.0394812176624932

Epoch: 5| Step: 1
Training loss: 1.5349373817443848
Validation loss: 2.037635013461113

Epoch: 5| Step: 2
Training loss: 2.0120205879211426
Validation loss: 2.042237718900045

Epoch: 5| Step: 3
Training loss: 1.9553219079971313
Validation loss: 2.048809399207433

Epoch: 5| Step: 4
Training loss: 1.6689354181289673
Validation loss: 2.039661799867948

Epoch: 5| Step: 5
Training loss: 2.0746209621429443
Validation loss: 2.0409529705842337

Epoch: 5| Step: 6
Training loss: 1.7897632122039795
Validation loss: 2.0530503590901694

Epoch: 5| Step: 7
Training loss: 1.9830325841903687
Validation loss: 2.0682061463594437

Epoch: 5| Step: 8
Training loss: 1.977866530418396
Validation loss: 2.0661593029896417

Epoch: 5| Step: 9
Training loss: 2.4020540714263916
Validation loss: 2.0770840793848038

Epoch: 5| Step: 10
Training loss: 2.5840904712677
Validation loss: 2.0848331650098166

Epoch: 5| Step: 11
Training loss: 2.065049171447754
Validation loss: 2.075144579013189

Epoch: 196| Step: 0
Training loss: 1.7881405353546143
Validation loss: 2.0627483427524567

Epoch: 5| Step: 1
Training loss: 2.1894614696502686
Validation loss: 2.073297753930092

Epoch: 5| Step: 2
Training loss: 2.0004537105560303
Validation loss: 2.0775675624608994

Epoch: 5| Step: 3
Training loss: 2.245296001434326
Validation loss: 2.058623800675074

Epoch: 5| Step: 4
Training loss: 2.029259204864502
Validation loss: 2.0691895882288613

Epoch: 5| Step: 5
Training loss: 1.8102325201034546
Validation loss: 2.070535625020663

Epoch: 5| Step: 6
Training loss: 1.9676380157470703
Validation loss: 2.0574252009391785

Epoch: 5| Step: 7
Training loss: 2.0799596309661865
Validation loss: 2.0594864785671234

Epoch: 5| Step: 8
Training loss: 2.0549731254577637
Validation loss: 2.0453021079301834

Epoch: 5| Step: 9
Training loss: 2.3632009029388428
Validation loss: 2.053550640741984

Epoch: 5| Step: 10
Training loss: 1.712700605392456
Validation loss: 2.0445041358470917

Epoch: 5| Step: 11
Training loss: 2.3468403816223145
Validation loss: 2.0643885980049768

Epoch: 197| Step: 0
Training loss: 1.9359359741210938
Validation loss: 2.062913661201795

Epoch: 5| Step: 1
Training loss: 2.39611554145813
Validation loss: 2.0671254694461823

Epoch: 5| Step: 2
Training loss: 1.4381998777389526
Validation loss: 2.0653255184491477

Epoch: 5| Step: 3
Training loss: 2.4526660442352295
Validation loss: 2.0674197326103845

Epoch: 5| Step: 4
Training loss: 1.8345699310302734
Validation loss: 2.0620373537143073

Epoch: 5| Step: 5
Training loss: 2.8639140129089355
Validation loss: 2.0677442997694016

Epoch: 5| Step: 6
Training loss: 1.778311014175415
Validation loss: 2.0467022905747094

Epoch: 5| Step: 7
Training loss: 2.0138397216796875
Validation loss: 2.08065302670002

Epoch: 5| Step: 8
Training loss: 2.252702236175537
Validation loss: 2.069786657889684

Epoch: 5| Step: 9
Training loss: 1.9229761362075806
Validation loss: 2.0471078952153525

Epoch: 5| Step: 10
Training loss: 1.6164369583129883
Validation loss: 2.045153101285299

Epoch: 5| Step: 11
Training loss: 0.9137523174285889
Validation loss: 2.029894550641378

Epoch: 198| Step: 0
Training loss: 1.8586994409561157
Validation loss: 2.0257240533828735

Epoch: 5| Step: 1
Training loss: 1.4356070756912231
Validation loss: 2.026634012659391

Epoch: 5| Step: 2
Training loss: 2.4372920989990234
Validation loss: 2.0295403500398

Epoch: 5| Step: 3
Training loss: 1.8235667943954468
Validation loss: 2.027444581190745

Epoch: 5| Step: 4
Training loss: 2.071380376815796
Validation loss: 2.0364995847145715

Epoch: 5| Step: 5
Training loss: 2.105557918548584
Validation loss: 2.030493532617887

Epoch: 5| Step: 6
Training loss: 2.4201133251190186
Validation loss: 2.0393867095311484

Epoch: 5| Step: 7
Training loss: 1.8655121326446533
Validation loss: 2.0376542707284293

Epoch: 5| Step: 8
Training loss: 2.530463695526123
Validation loss: 2.0544686814149222

Epoch: 5| Step: 9
Training loss: 1.9437541961669922
Validation loss: 2.044128050406774

Epoch: 5| Step: 10
Training loss: 1.9878238439559937
Validation loss: 2.0605412820974984

Epoch: 5| Step: 11
Training loss: 1.0920591354370117
Validation loss: 2.0770153452952704

Epoch: 199| Step: 0
Training loss: 2.360400676727295
Validation loss: 2.073275556166967

Epoch: 5| Step: 1
Training loss: 2.4785714149475098
Validation loss: 2.0775156716505685

Epoch: 5| Step: 2
Training loss: 2.003683567047119
Validation loss: 2.0832970092693963

Epoch: 5| Step: 3
Training loss: 2.1782643795013428
Validation loss: 2.089823936422666

Epoch: 5| Step: 4
Training loss: 1.906307578086853
Validation loss: 2.08748297393322

Epoch: 5| Step: 5
Training loss: 2.09470796585083
Validation loss: 2.0964403251806893

Epoch: 5| Step: 6
Training loss: 1.6099780797958374
Validation loss: 2.077156513929367

Epoch: 5| Step: 7
Training loss: 2.4381814002990723
Validation loss: 2.065538307030996

Epoch: 5| Step: 8
Training loss: 1.6602191925048828
Validation loss: 2.048046206434568

Epoch: 5| Step: 9
Training loss: 1.7248685359954834
Validation loss: 2.0491402645905814

Epoch: 5| Step: 10
Training loss: 2.0396454334259033
Validation loss: 2.034407928586006

Epoch: 5| Step: 11
Training loss: 2.249556541442871
Validation loss: 2.0354435543219247

Epoch: 200| Step: 0
Training loss: 2.271850109100342
Validation loss: 2.045402561624845

Epoch: 5| Step: 1
Training loss: 2.803391695022583
Validation loss: 2.0328613171974816

Epoch: 5| Step: 2
Training loss: 2.1050593852996826
Validation loss: 2.039875641465187

Epoch: 5| Step: 3
Training loss: 1.4690372943878174
Validation loss: 2.031987731655439

Epoch: 5| Step: 4
Training loss: 1.9938827753067017
Validation loss: 2.039521818359693

Epoch: 5| Step: 5
Training loss: 1.7883059978485107
Validation loss: 2.0348199357589087

Epoch: 5| Step: 6
Training loss: 2.0107810497283936
Validation loss: 2.036203294992447

Epoch: 5| Step: 7
Training loss: 1.7307493686676025
Validation loss: 2.0443727721770606

Epoch: 5| Step: 8
Training loss: 1.7753444910049438
Validation loss: 2.0603054960568747

Epoch: 5| Step: 9
Training loss: 2.0184574127197266
Validation loss: 2.0533265521128974

Epoch: 5| Step: 10
Training loss: 2.2991340160369873
Validation loss: 2.0734814008076987

Epoch: 5| Step: 11
Training loss: 2.5829005241394043
Validation loss: 2.074688265721003

Epoch: 201| Step: 0
Training loss: 2.340338945388794
Validation loss: 2.0601149201393127

Epoch: 5| Step: 1
Training loss: 2.0106873512268066
Validation loss: 2.054209972421328

Epoch: 5| Step: 2
Training loss: 1.9287073612213135
Validation loss: 2.058326631784439

Epoch: 5| Step: 3
Training loss: 1.6614491939544678
Validation loss: 2.069405327240626

Epoch: 5| Step: 4
Training loss: 2.1183836460113525
Validation loss: 2.061017001668612

Epoch: 5| Step: 5
Training loss: 1.9846302270889282
Validation loss: 2.058853800098101

Epoch: 5| Step: 6
Training loss: 2.2759742736816406
Validation loss: 2.059385692079862

Epoch: 5| Step: 7
Training loss: 2.2985830307006836
Validation loss: 2.0465084860722222

Epoch: 5| Step: 8
Training loss: 1.711491346359253
Validation loss: 2.0690898497899375

Epoch: 5| Step: 9
Training loss: 2.0216245651245117
Validation loss: 2.051641965905825

Epoch: 5| Step: 10
Training loss: 1.9798206090927124
Validation loss: 2.072298228740692

Epoch: 5| Step: 11
Training loss: 1.1470319032669067
Validation loss: 2.061074877778689

Epoch: 202| Step: 0
Training loss: 1.8184750080108643
Validation loss: 2.065132295091947

Epoch: 5| Step: 1
Training loss: 1.6415045261383057
Validation loss: 2.0656393319368362

Epoch: 5| Step: 2
Training loss: 2.149456024169922
Validation loss: 2.0633115271727243

Epoch: 5| Step: 3
Training loss: 1.8893706798553467
Validation loss: 2.0697581420342126

Epoch: 5| Step: 4
Training loss: 1.8953959941864014
Validation loss: 2.07489076256752

Epoch: 5| Step: 5
Training loss: 2.090017318725586
Validation loss: 2.077678680419922

Epoch: 5| Step: 6
Training loss: 2.0120201110839844
Validation loss: 2.0624557038148246

Epoch: 5| Step: 7
Training loss: 2.16152286529541
Validation loss: 2.066364193956057

Epoch: 5| Step: 8
Training loss: 1.9720035791397095
Validation loss: 2.07243520518144

Epoch: 5| Step: 9
Training loss: 2.1346516609191895
Validation loss: 2.06234377125899

Epoch: 5| Step: 10
Training loss: 2.1660656929016113
Validation loss: 2.062896355986595

Epoch: 5| Step: 11
Training loss: 1.8292070627212524
Validation loss: 2.0683330843846

Epoch: 203| Step: 0
Training loss: 1.7703840732574463
Validation loss: 2.07880129913489

Epoch: 5| Step: 1
Training loss: 2.101060152053833
Validation loss: 2.059866279363632

Epoch: 5| Step: 2
Training loss: 1.5815715789794922
Validation loss: 2.0816663255294166

Epoch: 5| Step: 3
Training loss: 2.003152370452881
Validation loss: 2.0755027532577515

Epoch: 5| Step: 4
Training loss: 1.6847388744354248
Validation loss: 2.078023910522461

Epoch: 5| Step: 5
Training loss: 2.375175952911377
Validation loss: 2.072380398710569

Epoch: 5| Step: 6
Training loss: 1.9228432178497314
Validation loss: 2.0886802971363068

Epoch: 5| Step: 7
Training loss: 1.6229499578475952
Validation loss: 2.0821562707424164

Epoch: 5| Step: 8
Training loss: 1.9739364385604858
Validation loss: 2.0893872529268265

Epoch: 5| Step: 9
Training loss: 2.5796360969543457
Validation loss: 2.067056263486544

Epoch: 5| Step: 10
Training loss: 2.12752103805542
Validation loss: 2.079846610625585

Epoch: 5| Step: 11
Training loss: 2.1977787017822266
Validation loss: 2.077148030201594

Epoch: 204| Step: 0
Training loss: 2.1017825603485107
Validation loss: 2.0743586172660193

Epoch: 5| Step: 1
Training loss: 1.587087869644165
Validation loss: 2.0700638443231583

Epoch: 5| Step: 2
Training loss: 1.8152488470077515
Validation loss: 2.0552323311567307

Epoch: 5| Step: 3
Training loss: 2.090888500213623
Validation loss: 2.0690662413835526

Epoch: 5| Step: 4
Training loss: 2.2041611671447754
Validation loss: 2.0477879345417023

Epoch: 5| Step: 5
Training loss: 2.1841068267822266
Validation loss: 2.0410827149947486

Epoch: 5| Step: 6
Training loss: 1.3325121402740479
Validation loss: 2.053348273038864

Epoch: 5| Step: 7
Training loss: 2.3012967109680176
Validation loss: 2.0483409762382507

Epoch: 5| Step: 8
Training loss: 2.3077971935272217
Validation loss: 2.061425636212031

Epoch: 5| Step: 9
Training loss: 1.628011703491211
Validation loss: 2.0807483742634454

Epoch: 5| Step: 10
Training loss: 2.4700982570648193
Validation loss: 2.0741170396407447

Epoch: 5| Step: 11
Training loss: 2.0034091472625732
Validation loss: 2.087335705757141

Epoch: 205| Step: 0
Training loss: 2.4286999702453613
Validation loss: 2.09830475350221

Epoch: 5| Step: 1
Training loss: 2.220902919769287
Validation loss: 2.097972889741262

Epoch: 5| Step: 2
Training loss: 2.843000888824463
Validation loss: 2.109365319212278

Epoch: 5| Step: 3
Training loss: 2.41003155708313
Validation loss: 2.0997756173213324

Epoch: 5| Step: 4
Training loss: 1.6192785501480103
Validation loss: 2.085073029001554

Epoch: 5| Step: 5
Training loss: 1.4956666231155396
Validation loss: 2.0811098565657935

Epoch: 5| Step: 6
Training loss: 1.7491527795791626
Validation loss: 2.0814072092374167

Epoch: 5| Step: 7
Training loss: 1.924012541770935
Validation loss: 2.0695310483376184

Epoch: 5| Step: 8
Training loss: 1.436380386352539
Validation loss: 2.0567444066206613

Epoch: 5| Step: 9
Training loss: 2.0920352935791016
Validation loss: 2.048506592710813

Epoch: 5| Step: 10
Training loss: 2.3933334350585938
Validation loss: 2.0429384658734002

Epoch: 5| Step: 11
Training loss: 2.0706214904785156
Validation loss: 2.0623580118020377

Epoch: 206| Step: 0
Training loss: 2.137026309967041
Validation loss: 2.0574665317932763

Epoch: 5| Step: 1
Training loss: 1.6696075201034546
Validation loss: 2.0628663251797357

Epoch: 5| Step: 2
Training loss: 2.1814463138580322
Validation loss: 2.072226737936338

Epoch: 5| Step: 3
Training loss: 2.014427423477173
Validation loss: 2.0546524077653885

Epoch: 5| Step: 4
Training loss: 2.398191452026367
Validation loss: 2.0568876763184867

Epoch: 5| Step: 5
Training loss: 1.7328907251358032
Validation loss: 2.060324798027674

Epoch: 5| Step: 6
Training loss: 2.3024635314941406
Validation loss: 2.055397445956866

Epoch: 5| Step: 7
Training loss: 2.0984249114990234
Validation loss: 2.064569890499115

Epoch: 5| Step: 8
Training loss: 1.790004014968872
Validation loss: 2.075298393766085

Epoch: 5| Step: 9
Training loss: 2.1284656524658203
Validation loss: 2.08739040295283

Epoch: 5| Step: 10
Training loss: 2.0545215606689453
Validation loss: 2.09271377325058

Epoch: 5| Step: 11
Training loss: 1.7497868537902832
Validation loss: 2.0868065456549325

Epoch: 207| Step: 0
Training loss: 2.1193580627441406
Validation loss: 2.09949358801047

Epoch: 5| Step: 1
Training loss: 1.9772512912750244
Validation loss: 2.108354017138481

Epoch: 5| Step: 2
Training loss: 2.4933080673217773
Validation loss: 2.116220901409785

Epoch: 5| Step: 3
Training loss: 1.955773949623108
Validation loss: 2.11632605890433

Epoch: 5| Step: 4
Training loss: 2.0516271591186523
Validation loss: 2.1143962194522223

Epoch: 5| Step: 5
Training loss: 1.7889900207519531
Validation loss: 2.121897985537847

Epoch: 5| Step: 6
Training loss: 1.9510256052017212
Validation loss: 2.080577274163564

Epoch: 5| Step: 7
Training loss: 2.054927349090576
Validation loss: 2.1137313842773438

Epoch: 5| Step: 8
Training loss: 1.8740943670272827
Validation loss: 2.091676026582718

Epoch: 5| Step: 9
Training loss: 1.799810767173767
Validation loss: 2.083625783522924

Epoch: 5| Step: 10
Training loss: 2.071350574493408
Validation loss: 2.067580377062162

Epoch: 5| Step: 11
Training loss: 2.633410930633545
Validation loss: 2.067381963133812

Epoch: 208| Step: 0
Training loss: 1.9355520009994507
Validation loss: 2.04385976990064

Epoch: 5| Step: 1
Training loss: 2.135728359222412
Validation loss: 2.04870797197024

Epoch: 5| Step: 2
Training loss: 2.3449885845184326
Validation loss: 2.050187587738037

Epoch: 5| Step: 3
Training loss: 2.248159408569336
Validation loss: 2.0446247309446335

Epoch: 5| Step: 4
Training loss: 1.6097288131713867
Validation loss: 2.0512387255827584

Epoch: 5| Step: 5
Training loss: 2.152104616165161
Validation loss: 2.0618556439876556

Epoch: 5| Step: 6
Training loss: 2.4805357456207275
Validation loss: 2.0521422922611237

Epoch: 5| Step: 7
Training loss: 2.392470121383667
Validation loss: 2.050539419054985

Epoch: 5| Step: 8
Training loss: 1.9382879734039307
Validation loss: 2.049598276615143

Epoch: 5| Step: 9
Training loss: 1.7105128765106201
Validation loss: 2.045909881591797

Epoch: 5| Step: 10
Training loss: 1.889258623123169
Validation loss: 2.046479120850563

Epoch: 5| Step: 11
Training loss: 1.661588430404663
Validation loss: 2.035798499981562

Epoch: 209| Step: 0
Training loss: 2.000328540802002
Validation loss: 2.036847492059072

Epoch: 5| Step: 1
Training loss: 2.26344633102417
Validation loss: 2.041798477371534

Epoch: 5| Step: 2
Training loss: 2.0253851413726807
Validation loss: 2.0504815777142844

Epoch: 5| Step: 3
Training loss: 1.8709300756454468
Validation loss: 2.0520707070827484

Epoch: 5| Step: 4
Training loss: 2.410881519317627
Validation loss: 2.06952374180158

Epoch: 5| Step: 5
Training loss: 1.9815683364868164
Validation loss: 2.0505330711603165

Epoch: 5| Step: 6
Training loss: 1.660248041152954
Validation loss: 2.057446430126826

Epoch: 5| Step: 7
Training loss: 2.535707950592041
Validation loss: 2.0632941176493964

Epoch: 5| Step: 8
Training loss: 1.63811457157135
Validation loss: 2.0695631404717765

Epoch: 5| Step: 9
Training loss: 1.7875604629516602
Validation loss: 2.0553848346074424

Epoch: 5| Step: 10
Training loss: 2.230103015899658
Validation loss: 2.056604281067848

Epoch: 5| Step: 11
Training loss: 1.6515555381774902
Validation loss: 2.048269659280777

Epoch: 210| Step: 0
Training loss: 2.0690205097198486
Validation loss: 2.03874871134758

Epoch: 5| Step: 1
Training loss: 1.9107561111450195
Validation loss: 2.0430464347203574

Epoch: 5| Step: 2
Training loss: 2.4885947704315186
Validation loss: 2.045087923606237

Epoch: 5| Step: 3
Training loss: 2.0187580585479736
Validation loss: 2.044794425368309

Epoch: 5| Step: 4
Training loss: 2.1784231662750244
Validation loss: 2.0434377243121467

Epoch: 5| Step: 5
Training loss: 1.2458279132843018
Validation loss: 2.0404914170503616

Epoch: 5| Step: 6
Training loss: 1.8876022100448608
Validation loss: 2.052212044596672

Epoch: 5| Step: 7
Training loss: 1.750312089920044
Validation loss: 2.0468558172384896

Epoch: 5| Step: 8
Training loss: 2.4598231315612793
Validation loss: 2.068894316752752

Epoch: 5| Step: 9
Training loss: 2.368314266204834
Validation loss: 2.0637297381957374

Epoch: 5| Step: 10
Training loss: 1.803890585899353
Validation loss: 2.0518548488616943

Epoch: 5| Step: 11
Training loss: 1.387814998626709
Validation loss: 2.058608507116636

Epoch: 211| Step: 0
Training loss: 1.3960360288619995
Validation loss: 2.042328675587972

Epoch: 5| Step: 1
Training loss: 1.8188507556915283
Validation loss: 2.0431199123462043

Epoch: 5| Step: 2
Training loss: 1.905660629272461
Validation loss: 2.0218432943026223

Epoch: 5| Step: 3
Training loss: 1.88689386844635
Validation loss: 2.0329672346512475

Epoch: 5| Step: 4
Training loss: 1.716036081314087
Validation loss: 2.0385470191637673

Epoch: 5| Step: 5
Training loss: 2.2287230491638184
Validation loss: 2.0289743592341742

Epoch: 5| Step: 6
Training loss: 1.7574937343597412
Validation loss: 2.040380577246348

Epoch: 5| Step: 7
Training loss: 2.7047500610351562
Validation loss: 2.0470954378445945

Epoch: 5| Step: 8
Training loss: 2.249661684036255
Validation loss: 2.0325279235839844

Epoch: 5| Step: 9
Training loss: 1.7239910364151
Validation loss: 2.037433460354805

Epoch: 5| Step: 10
Training loss: 2.4209485054016113
Validation loss: 2.048358197013537

Epoch: 5| Step: 11
Training loss: 3.468923568725586
Validation loss: 2.0457281321287155

Epoch: 212| Step: 0
Training loss: 2.0800652503967285
Validation loss: 2.0608848184347153

Epoch: 5| Step: 1
Training loss: 2.09941029548645
Validation loss: 2.0667647322018943

Epoch: 5| Step: 2
Training loss: 2.055417537689209
Validation loss: 2.061313475171725

Epoch: 5| Step: 3
Training loss: 1.8365192413330078
Validation loss: 2.051693379878998

Epoch: 5| Step: 4
Training loss: 1.9250438213348389
Validation loss: 2.0594426542520523

Epoch: 5| Step: 5
Training loss: 1.8457590341567993
Validation loss: 2.046080162127813

Epoch: 5| Step: 6
Training loss: 1.5841249227523804
Validation loss: 2.051501969496409

Epoch: 5| Step: 7
Training loss: 2.3162801265716553
Validation loss: 2.0550092260042825

Epoch: 5| Step: 8
Training loss: 2.275691270828247
Validation loss: 2.04497566819191

Epoch: 5| Step: 9
Training loss: 1.6796729564666748
Validation loss: 2.057054584225019

Epoch: 5| Step: 10
Training loss: 1.996204137802124
Validation loss: 2.0494464387496314

Epoch: 5| Step: 11
Training loss: 2.2952351570129395
Validation loss: 2.062140425046285

Epoch: 213| Step: 0
Training loss: 2.0231385231018066
Validation loss: 2.0705382277568183

Epoch: 5| Step: 1
Training loss: 1.4168812036514282
Validation loss: 2.0662555595239005

Epoch: 5| Step: 2
Training loss: 1.8205738067626953
Validation loss: 2.0642006446917853

Epoch: 5| Step: 3
Training loss: 2.065441131591797
Validation loss: 2.07846333583196

Epoch: 5| Step: 4
Training loss: 2.240896463394165
Validation loss: 2.07431660592556

Epoch: 5| Step: 5
Training loss: 1.9775272607803345
Validation loss: 2.0759273568789163

Epoch: 5| Step: 6
Training loss: 2.7220821380615234
Validation loss: 2.0770866672197976

Epoch: 5| Step: 7
Training loss: 1.619881272315979
Validation loss: 2.0878575096527734

Epoch: 5| Step: 8
Training loss: 2.0185165405273438
Validation loss: 2.0937766482432685

Epoch: 5| Step: 9
Training loss: 2.2440037727355957
Validation loss: 2.072657843430837

Epoch: 5| Step: 10
Training loss: 2.019624948501587
Validation loss: 2.0795390059550605

Epoch: 5| Step: 11
Training loss: 0.8124253749847412
Validation loss: 2.0922513951857886

Epoch: 214| Step: 0
Training loss: 2.3749358654022217
Validation loss: 2.079506034652392

Epoch: 5| Step: 1
Training loss: 1.9241527318954468
Validation loss: 2.0815949390331903

Epoch: 5| Step: 2
Training loss: 1.5150532722473145
Validation loss: 2.087757815917333

Epoch: 5| Step: 3
Training loss: 1.8263717889785767
Validation loss: 2.0820983797311783

Epoch: 5| Step: 4
Training loss: 2.5586771965026855
Validation loss: 2.078762650489807

Epoch: 5| Step: 5
Training loss: 2.5343880653381348
Validation loss: 2.076373120148977

Epoch: 5| Step: 6
Training loss: 1.9052479267120361
Validation loss: 2.076369752486547

Epoch: 5| Step: 7
Training loss: 1.6646833419799805
Validation loss: 2.0600085904200873

Epoch: 5| Step: 8
Training loss: 1.9571895599365234
Validation loss: 2.081525648633639

Epoch: 5| Step: 9
Training loss: 1.619232177734375
Validation loss: 2.076958119869232

Epoch: 5| Step: 10
Training loss: 2.0229220390319824
Validation loss: 2.063072601954142

Epoch: 5| Step: 11
Training loss: 0.7554832696914673
Validation loss: 2.080592761437098

Epoch: 215| Step: 0
Training loss: 1.4892466068267822
Validation loss: 2.074529752135277

Epoch: 5| Step: 1
Training loss: 1.5881325006484985
Validation loss: 2.061254690090815

Epoch: 5| Step: 2
Training loss: 1.1881482601165771
Validation loss: 2.0706644008557

Epoch: 5| Step: 3
Training loss: 1.6978555917739868
Validation loss: 2.067896693944931

Epoch: 5| Step: 4
Training loss: 2.4202427864074707
Validation loss: 2.0621449699004493

Epoch: 5| Step: 5
Training loss: 2.4517745971679688
Validation loss: 2.059820279479027

Epoch: 5| Step: 6
Training loss: 2.1353676319122314
Validation loss: 2.060277074575424

Epoch: 5| Step: 7
Training loss: 2.006157398223877
Validation loss: 2.073899894952774

Epoch: 5| Step: 8
Training loss: 1.833338737487793
Validation loss: 2.0712791631619134

Epoch: 5| Step: 9
Training loss: 2.716315507888794
Validation loss: 2.058266048630079

Epoch: 5| Step: 10
Training loss: 2.117183208465576
Validation loss: 2.0685710360606513

Epoch: 5| Step: 11
Training loss: 2.409557819366455
Validation loss: 2.0778324802716575

Epoch: 216| Step: 0
Training loss: 2.1093175411224365
Validation loss: 2.0732402900854745

Epoch: 5| Step: 1
Training loss: 2.279872179031372
Validation loss: 2.080152541399002

Epoch: 5| Step: 2
Training loss: 1.5944197177886963
Validation loss: 2.069892833630244

Epoch: 5| Step: 3
Training loss: 1.785620927810669
Validation loss: 2.0672431190808616

Epoch: 5| Step: 4
Training loss: 1.5138190984725952
Validation loss: 2.0802486538887024

Epoch: 5| Step: 5
Training loss: 1.8790760040283203
Validation loss: 2.0685493548711142

Epoch: 5| Step: 6
Training loss: 1.9861904382705688
Validation loss: 2.077814976374308

Epoch: 5| Step: 7
Training loss: 1.8364473581314087
Validation loss: 2.0784144749244056

Epoch: 5| Step: 8
Training loss: 2.1399340629577637
Validation loss: 2.0782450437545776

Epoch: 5| Step: 9
Training loss: 1.8037445545196533
Validation loss: 2.0530986885229745

Epoch: 5| Step: 10
Training loss: 2.586364269256592
Validation loss: 2.0686513582865396

Epoch: 5| Step: 11
Training loss: 2.4884839057922363
Validation loss: 2.0898691018422446

Epoch: 217| Step: 0
Training loss: 1.9826961755752563
Validation loss: 2.091430207093557

Epoch: 5| Step: 1
Training loss: 2.590996503829956
Validation loss: 2.087514633933703

Epoch: 5| Step: 2
Training loss: 1.8283498287200928
Validation loss: 2.0754435608784356

Epoch: 5| Step: 3
Training loss: 1.6725473403930664
Validation loss: 2.078700914978981

Epoch: 5| Step: 4
Training loss: 2.1711597442626953
Validation loss: 2.0648641884326935

Epoch: 5| Step: 5
Training loss: 1.8001163005828857
Validation loss: 2.0424084067344666

Epoch: 5| Step: 6
Training loss: 1.9670950174331665
Validation loss: 2.0453147838513055

Epoch: 5| Step: 7
Training loss: 2.434542417526245
Validation loss: 2.02817040681839

Epoch: 5| Step: 8
Training loss: 2.0738463401794434
Validation loss: 2.039921442667643

Epoch: 5| Step: 9
Training loss: 1.6686519384384155
Validation loss: 2.0421931594610214

Epoch: 5| Step: 10
Training loss: 1.792913794517517
Validation loss: 2.0346051901578903

Epoch: 5| Step: 11
Training loss: 3.103959798812866
Validation loss: 2.0483413537343345

Epoch: 218| Step: 0
Training loss: 2.1047260761260986
Validation loss: 2.0537526309490204

Epoch: 5| Step: 1
Training loss: 1.8547248840332031
Validation loss: 2.0655973702669144

Epoch: 5| Step: 2
Training loss: 2.3563597202301025
Validation loss: 2.0653395503759384

Epoch: 5| Step: 3
Training loss: 2.044006824493408
Validation loss: 2.0713633000850677

Epoch: 5| Step: 4
Training loss: 1.6060136556625366
Validation loss: 2.0686467488606772

Epoch: 5| Step: 5
Training loss: 1.893357515335083
Validation loss: 2.071777085463206

Epoch: 5| Step: 6
Training loss: 1.7515407800674438
Validation loss: 2.0694797337055206

Epoch: 5| Step: 7
Training loss: 2.1666486263275146
Validation loss: 2.076064576705297

Epoch: 5| Step: 8
Training loss: 1.6315014362335205
Validation loss: 2.0828125526507697

Epoch: 5| Step: 9
Training loss: 1.5428078174591064
Validation loss: 2.073096161087354

Epoch: 5| Step: 10
Training loss: 2.662590503692627
Validation loss: 2.0887009700139365

Epoch: 5| Step: 11
Training loss: 2.750668525695801
Validation loss: 2.0974800139665604

Epoch: 219| Step: 0
Training loss: 2.345728635787964
Validation loss: 2.0898856818675995

Epoch: 5| Step: 1
Training loss: 1.9367882013320923
Validation loss: 2.0914297699928284

Epoch: 5| Step: 2
Training loss: 2.081709384918213
Validation loss: 2.0917912125587463

Epoch: 5| Step: 3
Training loss: 1.5920377969741821
Validation loss: 2.087318559487661

Epoch: 5| Step: 4
Training loss: 2.4319252967834473
Validation loss: 2.0733619928359985

Epoch: 5| Step: 5
Training loss: 1.9719200134277344
Validation loss: 2.065970540046692

Epoch: 5| Step: 6
Training loss: 1.9906927347183228
Validation loss: 2.088186343510946

Epoch: 5| Step: 7
Training loss: 2.2573201656341553
Validation loss: 2.079682265718778

Epoch: 5| Step: 8
Training loss: 1.9717414379119873
Validation loss: 2.0865434358517327

Epoch: 5| Step: 9
Training loss: 2.1515257358551025
Validation loss: 2.095303257306417

Epoch: 5| Step: 10
Training loss: 1.1809804439544678
Validation loss: 2.085003783305486

Epoch: 5| Step: 11
Training loss: 0.935560941696167
Validation loss: 2.0864415814479194

Epoch: 220| Step: 0
Training loss: 1.6530258655548096
Validation loss: 2.098224322001139

Epoch: 5| Step: 1
Training loss: 1.6517231464385986
Validation loss: 2.0911331176757812

Epoch: 5| Step: 2
Training loss: 1.9176883697509766
Validation loss: 2.100325400630633

Epoch: 5| Step: 3
Training loss: 2.038604974746704
Validation loss: 2.092432662844658

Epoch: 5| Step: 4
Training loss: 1.8052078485488892
Validation loss: 2.094571496049563

Epoch: 5| Step: 5
Training loss: 2.0176126956939697
Validation loss: 2.086787243684133

Epoch: 5| Step: 6
Training loss: 2.2312865257263184
Validation loss: 2.0778828263282776

Epoch: 5| Step: 7
Training loss: 1.493408441543579
Validation loss: 2.0885705898205438

Epoch: 5| Step: 8
Training loss: 1.7608263492584229
Validation loss: 2.0867169896761575

Epoch: 5| Step: 9
Training loss: 2.2071821689605713
Validation loss: 2.0883224507172904

Epoch: 5| Step: 10
Training loss: 2.5098888874053955
Validation loss: 2.0880580445130668

Epoch: 5| Step: 11
Training loss: 3.385801315307617
Validation loss: 2.0948968728383384

Epoch: 221| Step: 0
Training loss: 1.9125210046768188
Validation loss: 2.0696235398451486

Epoch: 5| Step: 1
Training loss: 1.8172180652618408
Validation loss: 2.09022818505764

Epoch: 5| Step: 2
Training loss: 2.2081761360168457
Validation loss: 2.078432152668635

Epoch: 5| Step: 3
Training loss: 1.971877098083496
Validation loss: 2.070809389154116

Epoch: 5| Step: 4
Training loss: 2.621263027191162
Validation loss: 2.0827061980962753

Epoch: 5| Step: 5
Training loss: 2.0928945541381836
Validation loss: 2.08547035853068

Epoch: 5| Step: 6
Training loss: 1.895079255104065
Validation loss: 2.081655894716581

Epoch: 5| Step: 7
Training loss: 1.7454745769500732
Validation loss: 2.068120762705803

Epoch: 5| Step: 8
Training loss: 2.3238561153411865
Validation loss: 2.075019031763077

Epoch: 5| Step: 9
Training loss: 1.4827847480773926
Validation loss: 2.097622980674108

Epoch: 5| Step: 10
Training loss: 1.8497164249420166
Validation loss: 2.0819304635127387

Epoch: 5| Step: 11
Training loss: 0.7218112945556641
Validation loss: 2.0963375916083655

Epoch: 222| Step: 0
Training loss: 2.2766900062561035
Validation loss: 2.105450843771299

Epoch: 5| Step: 1
Training loss: 1.8657652139663696
Validation loss: 2.1047419210275016

Epoch: 5| Step: 2
Training loss: 2.298781156539917
Validation loss: 2.113368719816208

Epoch: 5| Step: 3
Training loss: 1.8004570007324219
Validation loss: 2.1173043747742972

Epoch: 5| Step: 4
Training loss: 2.29038667678833
Validation loss: 2.1087053219477334

Epoch: 5| Step: 5
Training loss: 1.9035497903823853
Validation loss: 2.0921823581059775

Epoch: 5| Step: 6
Training loss: 1.9708635807037354
Validation loss: 2.0940337429443994

Epoch: 5| Step: 7
Training loss: 1.851993203163147
Validation loss: 2.0792615165313086

Epoch: 5| Step: 8
Training loss: 1.7677850723266602
Validation loss: 2.0812777131795883

Epoch: 5| Step: 9
Training loss: 2.4980177879333496
Validation loss: 2.086234231789907

Epoch: 5| Step: 10
Training loss: 1.5865776538848877
Validation loss: 2.069182256857554

Epoch: 5| Step: 11
Training loss: 1.896349549293518
Validation loss: 2.0754873901605606

Epoch: 223| Step: 0
Training loss: 1.6690537929534912
Validation loss: 2.0851466904083886

Epoch: 5| Step: 1
Training loss: 2.467564344406128
Validation loss: 2.086640273531278

Epoch: 5| Step: 2
Training loss: 2.008256435394287
Validation loss: 2.066125735640526

Epoch: 5| Step: 3
Training loss: 1.7296806573867798
Validation loss: 2.0723231732845306

Epoch: 5| Step: 4
Training loss: 1.6422370672225952
Validation loss: 2.090763305624326

Epoch: 5| Step: 5
Training loss: 1.9485172033309937
Validation loss: 2.103347967068354

Epoch: 5| Step: 6
Training loss: 1.7571815252304077
Validation loss: 2.0643690129121146

Epoch: 5| Step: 7
Training loss: 2.589195489883423
Validation loss: 2.0791302025318146

Epoch: 5| Step: 8
Training loss: 1.8182140588760376
Validation loss: 2.0783543586730957

Epoch: 5| Step: 9
Training loss: 2.081782102584839
Validation loss: 2.08099872370561

Epoch: 5| Step: 10
Training loss: 1.816540002822876
Validation loss: 2.0713379035393396

Epoch: 5| Step: 11
Training loss: 2.0962843894958496
Validation loss: 2.0901847829421363

Epoch: 224| Step: 0
Training loss: 2.25549578666687
Validation loss: 2.0801207423210144

Epoch: 5| Step: 1
Training loss: 2.2947731018066406
Validation loss: 2.1054492394129434

Epoch: 5| Step: 2
Training loss: 2.197410821914673
Validation loss: 2.1010834028323493

Epoch: 5| Step: 3
Training loss: 2.6226913928985596
Validation loss: 2.072197377681732

Epoch: 5| Step: 4
Training loss: 1.6216869354248047
Validation loss: 2.098787014683088

Epoch: 5| Step: 5
Training loss: 1.7637916803359985
Validation loss: 2.0925503224134445

Epoch: 5| Step: 6
Training loss: 1.6632192134857178
Validation loss: 2.0691761722167334

Epoch: 5| Step: 7
Training loss: 1.417962908744812
Validation loss: 2.080593859155973

Epoch: 5| Step: 8
Training loss: 2.029228687286377
Validation loss: 2.0684972355763116

Epoch: 5| Step: 9
Training loss: 2.3960118293762207
Validation loss: 2.072586253285408

Epoch: 5| Step: 10
Training loss: 1.5218393802642822
Validation loss: 2.092999200026194

Epoch: 5| Step: 11
Training loss: 1.3938963413238525
Validation loss: 2.0971803764502206

Epoch: 225| Step: 0
Training loss: 1.9614887237548828
Validation loss: 2.1242559353510537

Epoch: 5| Step: 1
Training loss: 1.8677995204925537
Validation loss: 2.119844004511833

Epoch: 5| Step: 2
Training loss: 2.476757526397705
Validation loss: 2.124685600399971

Epoch: 5| Step: 3
Training loss: 2.2973506450653076
Validation loss: 2.1438011676073074

Epoch: 5| Step: 4
Training loss: 2.011042833328247
Validation loss: 2.142396961649259

Epoch: 5| Step: 5
Training loss: 2.748328447341919
Validation loss: 2.106641491254171

Epoch: 5| Step: 6
Training loss: 1.4412232637405396
Validation loss: 2.1100132962067923

Epoch: 5| Step: 7
Training loss: 1.1889498233795166
Validation loss: 2.1106139669815698

Epoch: 5| Step: 8
Training loss: 1.9186617136001587
Validation loss: 2.097819338242213

Epoch: 5| Step: 9
Training loss: 1.9376018047332764
Validation loss: 2.100032687187195

Epoch: 5| Step: 10
Training loss: 1.6154876947402954
Validation loss: 2.096756175160408

Epoch: 5| Step: 11
Training loss: 3.222559690475464
Validation loss: 2.089680463075638

Epoch: 226| Step: 0
Training loss: 1.902144432067871
Validation loss: 2.1036093334356942

Epoch: 5| Step: 1
Training loss: 1.9371707439422607
Validation loss: 2.0912426114082336

Epoch: 5| Step: 2
Training loss: 1.8738415241241455
Validation loss: 2.0904070287942886

Epoch: 5| Step: 3
Training loss: 2.66278338432312
Validation loss: 2.088396266102791

Epoch: 5| Step: 4
Training loss: 1.412061333656311
Validation loss: 2.087584540247917

Epoch: 5| Step: 5
Training loss: 1.6319681406021118
Validation loss: 2.0810400446256003

Epoch: 5| Step: 6
Training loss: 1.548379898071289
Validation loss: 2.0869986017545066

Epoch: 5| Step: 7
Training loss: 2.1216938495635986
Validation loss: 2.0793403536081314

Epoch: 5| Step: 8
Training loss: 2.179762125015259
Validation loss: 2.0817701617876687

Epoch: 5| Step: 9
Training loss: 2.6512365341186523
Validation loss: 2.106032500664393

Epoch: 5| Step: 10
Training loss: 1.5732702016830444
Validation loss: 2.094104732076327

Epoch: 5| Step: 11
Training loss: 1.3318742513656616
Validation loss: 2.1208947549263635

Epoch: 227| Step: 0
Training loss: 1.4632922410964966
Validation loss: 2.12411900361379

Epoch: 5| Step: 1
Training loss: 2.013833999633789
Validation loss: 2.14011616508166

Epoch: 5| Step: 2
Training loss: 1.4879794120788574
Validation loss: 2.1572092473506927

Epoch: 5| Step: 3
Training loss: 2.289219617843628
Validation loss: 2.1299833953380585

Epoch: 5| Step: 4
Training loss: 1.8973737955093384
Validation loss: 2.091590479016304

Epoch: 5| Step: 5
Training loss: 1.7978191375732422
Validation loss: 2.09635391831398

Epoch: 5| Step: 6
Training loss: 1.8517227172851562
Validation loss: 2.083543375134468

Epoch: 5| Step: 7
Training loss: 2.20465350151062
Validation loss: 2.09096252421538

Epoch: 5| Step: 8
Training loss: 2.2166879177093506
Validation loss: 2.0790307819843292

Epoch: 5| Step: 9
Training loss: 2.302767753601074
Validation loss: 2.0887065331141152

Epoch: 5| Step: 10
Training loss: 2.1591737270355225
Validation loss: 2.0964076469341912

Epoch: 5| Step: 11
Training loss: 3.548469066619873
Validation loss: 2.1052557826042175

Epoch: 228| Step: 0
Training loss: 1.8751649856567383
Validation loss: 2.084157610932986

Epoch: 5| Step: 1
Training loss: 1.9002392292022705
Validation loss: 2.0956740578015647

Epoch: 5| Step: 2
Training loss: 1.5949723720550537
Validation loss: 2.078392654657364

Epoch: 5| Step: 3
Training loss: 2.998030185699463
Validation loss: 2.084504008293152

Epoch: 5| Step: 4
Training loss: 1.7698781490325928
Validation loss: 2.088771795233091

Epoch: 5| Step: 5
Training loss: 1.524804711341858
Validation loss: 2.0758103827635446

Epoch: 5| Step: 6
Training loss: 2.2122325897216797
Validation loss: 2.0822939773400626

Epoch: 5| Step: 7
Training loss: 2.041081666946411
Validation loss: 2.0994560718536377

Epoch: 5| Step: 8
Training loss: 2.080842971801758
Validation loss: 2.1068388670682907

Epoch: 5| Step: 9
Training loss: 1.9987430572509766
Validation loss: 2.113879238565763

Epoch: 5| Step: 10
Training loss: 2.0231552124023438
Validation loss: 2.119585985938708

Epoch: 5| Step: 11
Training loss: 1.9460334777832031
Validation loss: 2.125908354918162

Epoch: 229| Step: 0
Training loss: 1.792236089706421
Validation loss: 2.1166482667128244

Epoch: 5| Step: 1
Training loss: 2.166985511779785
Validation loss: 2.11410254240036

Epoch: 5| Step: 2
Training loss: 2.102864980697632
Validation loss: 2.096540038784345

Epoch: 5| Step: 3
Training loss: 1.9205214977264404
Validation loss: 2.0924587845802307

Epoch: 5| Step: 4
Training loss: 1.8209508657455444
Validation loss: 2.0915695627530417

Epoch: 5| Step: 5
Training loss: 1.6746056079864502
Validation loss: 2.0830223311980567

Epoch: 5| Step: 6
Training loss: 2.197216749191284
Validation loss: 2.07585209608078

Epoch: 5| Step: 7
Training loss: 1.7759650945663452
Validation loss: 2.0906405448913574

Epoch: 5| Step: 8
Training loss: 2.167634963989258
Validation loss: 2.086789811650912

Epoch: 5| Step: 9
Training loss: 1.6806764602661133
Validation loss: 2.084606553117434

Epoch: 5| Step: 10
Training loss: 2.042238235473633
Validation loss: 2.096008991201719

Epoch: 5| Step: 11
Training loss: 2.366128921508789
Validation loss: 2.086551681160927

Epoch: 230| Step: 0
Training loss: 1.7412374019622803
Validation loss: 2.095183695356051

Epoch: 5| Step: 1
Training loss: 2.6421685218811035
Validation loss: 2.083890269200007

Epoch: 5| Step: 2
Training loss: 1.8353456258773804
Validation loss: 2.088778426249822

Epoch: 5| Step: 3
Training loss: 2.2113754749298096
Validation loss: 2.0951466063658395

Epoch: 5| Step: 4
Training loss: 2.033508777618408
Validation loss: 2.078906789422035

Epoch: 5| Step: 5
Training loss: 2.4046459197998047
Validation loss: 2.0901130586862564

Epoch: 5| Step: 6
Training loss: 1.7258574962615967
Validation loss: 2.0994710673888526

Epoch: 5| Step: 7
Training loss: 1.7399412393569946
Validation loss: 2.1077997932831445

Epoch: 5| Step: 8
Training loss: 1.8671798706054688
Validation loss: 2.090592553218206

Epoch: 5| Step: 9
Training loss: 1.9174076318740845
Validation loss: 2.108650247255961

Epoch: 5| Step: 10
Training loss: 1.8260059356689453
Validation loss: 2.1078237493832908

Epoch: 5| Step: 11
Training loss: 0.5535297393798828
Validation loss: 2.0998617062966027

Epoch: 231| Step: 0
Training loss: 1.5076006650924683
Validation loss: 2.0961938997109733

Epoch: 5| Step: 1
Training loss: 2.414936065673828
Validation loss: 2.098201463619868

Epoch: 5| Step: 2
Training loss: 1.8936727046966553
Validation loss: 2.101470952232679

Epoch: 5| Step: 3
Training loss: 1.9081850051879883
Validation loss: 2.1051649103562036

Epoch: 5| Step: 4
Training loss: 2.1878952980041504
Validation loss: 2.08891927699248

Epoch: 5| Step: 5
Training loss: 2.3394269943237305
Validation loss: 2.099358484148979

Epoch: 5| Step: 6
Training loss: 2.1675446033477783
Validation loss: 2.0976945608854294

Epoch: 5| Step: 7
Training loss: 1.417736530303955
Validation loss: 2.091553881764412

Epoch: 5| Step: 8
Training loss: 2.1407055854797363
Validation loss: 2.0978211760520935

Epoch: 5| Step: 9
Training loss: 2.2800140380859375
Validation loss: 2.1158855309089026

Epoch: 5| Step: 10
Training loss: 1.3701051473617554
Validation loss: 2.118099038799604

Epoch: 5| Step: 11
Training loss: 0.9481222033500671
Validation loss: 2.1242716014385223

Epoch: 232| Step: 0
Training loss: 2.055198907852173
Validation loss: 2.1165191729863486

Epoch: 5| Step: 1
Training loss: 2.600214958190918
Validation loss: 2.095295548439026

Epoch: 5| Step: 2
Training loss: 1.9782259464263916
Validation loss: 2.1022164275248847

Epoch: 5| Step: 3
Training loss: 1.4528013467788696
Validation loss: 2.1003197928269706

Epoch: 5| Step: 4
Training loss: 2.4131171703338623
Validation loss: 2.1057870338360467

Epoch: 5| Step: 5
Training loss: 1.572068691253662
Validation loss: 2.0904162327448526

Epoch: 5| Step: 6
Training loss: 1.5716619491577148
Validation loss: 2.0838095297416053

Epoch: 5| Step: 7
Training loss: 1.7914354801177979
Validation loss: 2.091410835584005

Epoch: 5| Step: 8
Training loss: 2.095641613006592
Validation loss: 2.100489074985186

Epoch: 5| Step: 9
Training loss: 2.283010482788086
Validation loss: 2.113421320915222

Epoch: 5| Step: 10
Training loss: 1.9076875448226929
Validation loss: 2.0957659085591636

Epoch: 5| Step: 11
Training loss: 2.073490619659424
Validation loss: 2.0848927994569144

Epoch: 233| Step: 0
Training loss: 2.0633561611175537
Validation loss: 2.117655873298645

Epoch: 5| Step: 1
Training loss: 1.7904815673828125
Validation loss: 2.131832738717397

Epoch: 5| Step: 2
Training loss: 1.967303991317749
Validation loss: 2.132192095120748

Epoch: 5| Step: 3
Training loss: 1.840076208114624
Validation loss: 2.125117147962252

Epoch: 5| Step: 4
Training loss: 1.610271692276001
Validation loss: 2.1313019891579947

Epoch: 5| Step: 5
Training loss: 2.1252548694610596
Validation loss: 2.1336317410071692

Epoch: 5| Step: 6
Training loss: 1.5934937000274658
Validation loss: 2.112110674381256

Epoch: 5| Step: 7
Training loss: 1.8026626110076904
Validation loss: 2.1159396866957345

Epoch: 5| Step: 8
Training loss: 2.1892497539520264
Validation loss: 2.1224217216173806

Epoch: 5| Step: 9
Training loss: 2.106184482574463
Validation loss: 2.1244303981463113

Epoch: 5| Step: 10
Training loss: 1.8293530941009521
Validation loss: 2.1103908071915307

Epoch: 5| Step: 11
Training loss: 3.6512274742126465
Validation loss: 2.09892737865448

Epoch: 234| Step: 0
Training loss: 1.9579159021377563
Validation loss: 2.1048344721396766

Epoch: 5| Step: 1
Training loss: 1.391535758972168
Validation loss: 2.10324427485466

Epoch: 5| Step: 2
Training loss: 1.9326086044311523
Validation loss: 2.095445270339648

Epoch: 5| Step: 3
Training loss: 2.0877950191497803
Validation loss: 2.0860602110624313

Epoch: 5| Step: 4
Training loss: 2.9092161655426025
Validation loss: 2.083191931247711

Epoch: 5| Step: 5
Training loss: 1.872375726699829
Validation loss: 2.0850887298583984

Epoch: 5| Step: 6
Training loss: 1.5564167499542236
Validation loss: 2.07717856268088

Epoch: 5| Step: 7
Training loss: 2.15769362449646
Validation loss: 2.0987170040607452

Epoch: 5| Step: 8
Training loss: 1.6147773265838623
Validation loss: 2.106114645799001

Epoch: 5| Step: 9
Training loss: 2.078415632247925
Validation loss: 2.0905488779147468

Epoch: 5| Step: 10
Training loss: 2.1115221977233887
Validation loss: 2.102277750770251

Epoch: 5| Step: 11
Training loss: 1.4432077407836914
Validation loss: 2.108097737034162

Epoch: 235| Step: 0
Training loss: 2.197650909423828
Validation loss: 2.113395114739736

Epoch: 5| Step: 1
Training loss: 2.1058549880981445
Validation loss: 2.137944887081782

Epoch: 5| Step: 2
Training loss: 1.6335480213165283
Validation loss: 2.1618894884983697

Epoch: 5| Step: 3
Training loss: 1.5082991123199463
Validation loss: 2.1406878232955933

Epoch: 5| Step: 4
Training loss: 2.0289885997772217
Validation loss: 2.1562077601750693

Epoch: 5| Step: 5
Training loss: 2.275310754776001
Validation loss: 2.1579560935497284

Epoch: 5| Step: 6
Training loss: 2.206676959991455
Validation loss: 2.1365085591872535

Epoch: 5| Step: 7
Training loss: 1.8150066137313843
Validation loss: 2.1358526200056076

Epoch: 5| Step: 8
Training loss: 2.7219347953796387
Validation loss: 2.09017022450765

Epoch: 5| Step: 9
Training loss: 2.1251375675201416
Validation loss: 2.0811122407515845

Epoch: 5| Step: 10
Training loss: 1.3833433389663696
Validation loss: 2.0889392594496408

Epoch: 5| Step: 11
Training loss: 1.6828261613845825
Validation loss: 2.0761787494023642

Epoch: 236| Step: 0
Training loss: 1.4088443517684937
Validation loss: 2.0720053911209106

Epoch: 5| Step: 1
Training loss: 2.1622588634490967
Validation loss: 2.073985313375791

Epoch: 5| Step: 2
Training loss: 2.2789878845214844
Validation loss: 2.0811281402905784

Epoch: 5| Step: 3
Training loss: 1.7218525409698486
Validation loss: 2.0666883438825607

Epoch: 5| Step: 4
Training loss: 2.2930171489715576
Validation loss: 2.0817502439022064

Epoch: 5| Step: 5
Training loss: 1.8358291387557983
Validation loss: 2.082556828856468

Epoch: 5| Step: 6
Training loss: 2.2153213024139404
Validation loss: 2.093409076333046

Epoch: 5| Step: 7
Training loss: 1.8534090518951416
Validation loss: 2.0931343336900077

Epoch: 5| Step: 8
Training loss: 2.2932980060577393
Validation loss: 2.104598010579745

Epoch: 5| Step: 9
Training loss: 1.7504370212554932
Validation loss: 2.0877735912799835

Epoch: 5| Step: 10
Training loss: 1.7356151342391968
Validation loss: 2.1211026459932327

Epoch: 5| Step: 11
Training loss: 2.4211912155151367
Validation loss: 2.1123434702555337

Epoch: 237| Step: 0
Training loss: 1.8571243286132812
Validation loss: 2.139896790186564

Epoch: 5| Step: 1
Training loss: 1.5694849491119385
Validation loss: 2.1409183541933694

Epoch: 5| Step: 2
Training loss: 1.8392623662948608
Validation loss: 2.1337896088759103

Epoch: 5| Step: 3
Training loss: 2.0460026264190674
Validation loss: 2.1323514183362327

Epoch: 5| Step: 4
Training loss: 1.9320220947265625
Validation loss: 2.123836229244868

Epoch: 5| Step: 5
Training loss: 1.9716923236846924
Validation loss: 2.1397940516471863

Epoch: 5| Step: 6
Training loss: 2.1266822814941406
Validation loss: 2.0907597045103707

Epoch: 5| Step: 7
Training loss: 2.3913142681121826
Validation loss: 2.094312936067581

Epoch: 5| Step: 8
Training loss: 1.8103742599487305
Validation loss: 2.103884463508924

Epoch: 5| Step: 9
Training loss: 1.3727731704711914
Validation loss: 2.0903521527846656

Epoch: 5| Step: 10
Training loss: 2.3621666431427
Validation loss: 2.09017905096213

Epoch: 5| Step: 11
Training loss: 2.6890978813171387
Validation loss: 2.0765870014826455

Epoch: 238| Step: 0
Training loss: 1.6863332986831665
Validation loss: 2.0667565117279687

Epoch: 5| Step: 1
Training loss: 1.9235683679580688
Validation loss: 2.0792909612258277

Epoch: 5| Step: 2
Training loss: 1.7022173404693604
Validation loss: 2.0977412164211273

Epoch: 5| Step: 3
Training loss: 2.3342971801757812
Validation loss: 2.089864432811737

Epoch: 5| Step: 4
Training loss: 2.0755562782287598
Validation loss: 2.080610523621241

Epoch: 5| Step: 5
Training loss: 1.7909189462661743
Validation loss: 2.0812220672766366

Epoch: 5| Step: 6
Training loss: 2.152752161026001
Validation loss: 2.0877892474333444

Epoch: 5| Step: 7
Training loss: 2.1642889976501465
Validation loss: 2.0839873552322388

Epoch: 5| Step: 8
Training loss: 1.896946668624878
Validation loss: 2.0737066666285195

Epoch: 5| Step: 9
Training loss: 2.3217978477478027
Validation loss: 2.064767708381017

Epoch: 5| Step: 10
Training loss: 2.5152180194854736
Validation loss: 2.0753497978051505

Epoch: 5| Step: 11
Training loss: 1.9070571660995483
Validation loss: 2.084784204761187

Epoch: 239| Step: 0
Training loss: 1.6057155132293701
Validation loss: 2.082842469215393

Epoch: 5| Step: 1
Training loss: 2.075556993484497
Validation loss: 2.0956209897994995

Epoch: 5| Step: 2
Training loss: 1.9126275777816772
Validation loss: 2.096823111176491

Epoch: 5| Step: 3
Training loss: 1.6717125177383423
Validation loss: 2.1169698238372803

Epoch: 5| Step: 4
Training loss: 2.1082122325897217
Validation loss: 2.1071474850177765

Epoch: 5| Step: 5
Training loss: 1.7282609939575195
Validation loss: 2.1238003422816596

Epoch: 5| Step: 6
Training loss: 2.0338730812072754
Validation loss: 2.124181126554807

Epoch: 5| Step: 7
Training loss: 1.9553253650665283
Validation loss: 2.1047067840894065

Epoch: 5| Step: 8
Training loss: 1.7321821451187134
Validation loss: 2.1085403710603714

Epoch: 5| Step: 9
Training loss: 2.0674471855163574
Validation loss: 2.1274379243453345

Epoch: 5| Step: 10
Training loss: 2.140166759490967
Validation loss: 2.1254879335562387

Epoch: 5| Step: 11
Training loss: 3.236666202545166
Validation loss: 2.1109986106554666

Epoch: 240| Step: 0
Training loss: 1.2401889562606812
Validation loss: 2.1052379260460534

Epoch: 5| Step: 1
Training loss: 1.8976529836654663
Validation loss: 2.0931770900885263

Epoch: 5| Step: 2
Training loss: 1.4109777212142944
Validation loss: 2.101350242892901

Epoch: 5| Step: 3
Training loss: 2.2395544052124023
Validation loss: 2.0918996781110764

Epoch: 5| Step: 4
Training loss: 1.8255431652069092
Validation loss: 2.102408915758133

Epoch: 5| Step: 5
Training loss: 1.938302993774414
Validation loss: 2.1022053311268487

Epoch: 5| Step: 6
Training loss: 2.157209873199463
Validation loss: 2.10933418571949

Epoch: 5| Step: 7
Training loss: 2.1943745613098145
Validation loss: 2.0944238354762397

Epoch: 5| Step: 8
Training loss: 2.216794967651367
Validation loss: 2.12340347468853

Epoch: 5| Step: 9
Training loss: 2.597017765045166
Validation loss: 2.0839965095122657

Epoch: 5| Step: 10
Training loss: 1.6209461688995361
Validation loss: 2.1036043067773185

Epoch: 5| Step: 11
Training loss: 1.1976277828216553
Validation loss: 2.106965735554695

Epoch: 241| Step: 0
Training loss: 1.994653344154358
Validation loss: 2.112373873591423

Epoch: 5| Step: 1
Training loss: 1.4248453378677368
Validation loss: 2.096855401992798

Epoch: 5| Step: 2
Training loss: 1.8470869064331055
Validation loss: 2.1065625001986823

Epoch: 5| Step: 3
Training loss: 1.848681092262268
Validation loss: 2.0997115125258765

Epoch: 5| Step: 4
Training loss: 1.9456255435943604
Validation loss: 2.1004821956157684

Epoch: 5| Step: 5
Training loss: 1.9234148263931274
Validation loss: 2.0990932981173196

Epoch: 5| Step: 6
Training loss: 2.4804322719573975
Validation loss: 2.0974994401137033

Epoch: 5| Step: 7
Training loss: 1.470298409461975
Validation loss: 2.100168064236641

Epoch: 5| Step: 8
Training loss: 1.9089925289154053
Validation loss: 2.114546477794647

Epoch: 5| Step: 9
Training loss: 2.525754451751709
Validation loss: 2.1222186386585236

Epoch: 5| Step: 10
Training loss: 1.8209511041641235
Validation loss: 2.10886904100577

Epoch: 5| Step: 11
Training loss: 1.9452236890792847
Validation loss: 2.1035109609365463

Epoch: 242| Step: 0
Training loss: 2.441953182220459
Validation loss: 2.1117491871118546

Epoch: 5| Step: 1
Training loss: 1.8266162872314453
Validation loss: 2.1043858528137207

Epoch: 5| Step: 2
Training loss: 1.530649185180664
Validation loss: 2.1013685315847397

Epoch: 5| Step: 3
Training loss: 1.585334062576294
Validation loss: 2.1056875785191855

Epoch: 5| Step: 4
Training loss: 1.8636877536773682
Validation loss: 2.092801402012507

Epoch: 5| Step: 5
Training loss: 2.265796661376953
Validation loss: 2.099974205096563

Epoch: 5| Step: 6
Training loss: 1.8090741634368896
Validation loss: 2.0942974785963693

Epoch: 5| Step: 7
Training loss: 1.618736982345581
Validation loss: 2.0947475830713906

Epoch: 5| Step: 8
Training loss: 1.8933559656143188
Validation loss: 2.0794450094302497

Epoch: 5| Step: 9
Training loss: 1.7632030248641968
Validation loss: 2.092172553141912

Epoch: 5| Step: 10
Training loss: 2.5829715728759766
Validation loss: 2.1010036369164786

Epoch: 5| Step: 11
Training loss: 1.4095022678375244
Validation loss: 2.0932393074035645

Epoch: 243| Step: 0
Training loss: 1.9905359745025635
Validation loss: 2.10247865319252

Epoch: 5| Step: 1
Training loss: 2.2321765422821045
Validation loss: 2.097187101840973

Epoch: 5| Step: 2
Training loss: 2.417630195617676
Validation loss: 2.1061292042334876

Epoch: 5| Step: 3
Training loss: 1.8272044658660889
Validation loss: 2.100317567586899

Epoch: 5| Step: 4
Training loss: 1.4394201040267944
Validation loss: 2.108270381887754

Epoch: 5| Step: 5
Training loss: 2.001612424850464
Validation loss: 2.117432509859403

Epoch: 5| Step: 6
Training loss: 1.8480079174041748
Validation loss: 2.102297375599543

Epoch: 5| Step: 7
Training loss: 1.2708303928375244
Validation loss: 2.11314465602239

Epoch: 5| Step: 8
Training loss: 2.3510491847991943
Validation loss: 2.1053170363108316

Epoch: 5| Step: 9
Training loss: 2.1702911853790283
Validation loss: 2.107224573691686

Epoch: 5| Step: 10
Training loss: 1.4880797863006592
Validation loss: 2.1053235828876495

Epoch: 5| Step: 11
Training loss: 1.832654356956482
Validation loss: 2.092094764113426

Epoch: 244| Step: 0
Training loss: 1.6882766485214233
Validation loss: 2.10547769566377

Epoch: 5| Step: 1
Training loss: 1.8101211786270142
Validation loss: 2.1162444949150085

Epoch: 5| Step: 2
Training loss: 1.823866605758667
Validation loss: 2.1162971754868827

Epoch: 5| Step: 3
Training loss: 1.6943727731704712
Validation loss: 2.110530510544777

Epoch: 5| Step: 4
Training loss: 2.070580005645752
Validation loss: 2.1072768718004227

Epoch: 5| Step: 5
Training loss: 1.8052374124526978
Validation loss: 2.1048266688982644

Epoch: 5| Step: 6
Training loss: 2.2223687171936035
Validation loss: 2.1147126257419586

Epoch: 5| Step: 7
Training loss: 2.5676519870758057
Validation loss: 2.103365699450175

Epoch: 5| Step: 8
Training loss: 1.8456223011016846
Validation loss: 2.1156839380661645

Epoch: 5| Step: 9
Training loss: 1.4677914381027222
Validation loss: 2.1116513262192407

Epoch: 5| Step: 10
Training loss: 1.8837764263153076
Validation loss: 2.108479087551435

Epoch: 5| Step: 11
Training loss: 2.5665664672851562
Validation loss: 2.124039967854818

Epoch: 245| Step: 0
Training loss: 1.7566903829574585
Validation loss: 2.1326923867066703

Epoch: 5| Step: 1
Training loss: 1.8015512228012085
Validation loss: 2.1254882166783013

Epoch: 5| Step: 2
Training loss: 2.178972005844116
Validation loss: 2.104813685019811

Epoch: 5| Step: 3
Training loss: 1.445061445236206
Validation loss: 2.1021413703759513

Epoch: 5| Step: 4
Training loss: 3.114177703857422
Validation loss: 2.097640027602514

Epoch: 5| Step: 5
Training loss: 1.7570679187774658
Validation loss: 2.0968393286069236

Epoch: 5| Step: 6
Training loss: 1.5799545049667358
Validation loss: 2.091247464219729

Epoch: 5| Step: 7
Training loss: 1.787549614906311
Validation loss: 2.101288005709648

Epoch: 5| Step: 8
Training loss: 2.022284984588623
Validation loss: 2.101212481657664

Epoch: 5| Step: 9
Training loss: 1.8246967792510986
Validation loss: 2.1153444002072015

Epoch: 5| Step: 10
Training loss: 2.053713321685791
Validation loss: 2.1195715169111886

Epoch: 5| Step: 11
Training loss: 1.3745594024658203
Validation loss: 2.1229053139686584

Epoch: 246| Step: 0
Training loss: 1.9223556518554688
Validation loss: 2.136981983979543

Epoch: 5| Step: 1
Training loss: 1.7963135242462158
Validation loss: 2.1343149890502295

Epoch: 5| Step: 2
Training loss: 1.972195029258728
Validation loss: 2.1335149904092154

Epoch: 5| Step: 3
Training loss: 1.7965065240859985
Validation loss: 2.1443393329779306

Epoch: 5| Step: 4
Training loss: 1.993910551071167
Validation loss: 2.131995444496473

Epoch: 5| Step: 5
Training loss: 2.569476842880249
Validation loss: 2.1263806273539863

Epoch: 5| Step: 6
Training loss: 1.9082396030426025
Validation loss: 2.1329450060923896

Epoch: 5| Step: 7
Training loss: 1.8715851306915283
Validation loss: 2.1398309022188187

Epoch: 5| Step: 8
Training loss: 2.075259208679199
Validation loss: 2.1231141636768975

Epoch: 5| Step: 9
Training loss: 1.9856395721435547
Validation loss: 2.1344324201345444

Epoch: 5| Step: 10
Training loss: 1.2040903568267822
Validation loss: 2.1210993379354477

Epoch: 5| Step: 11
Training loss: 1.0893877744674683
Validation loss: 2.126092940568924

Epoch: 247| Step: 0
Training loss: 2.5946593284606934
Validation loss: 2.134138991435369

Epoch: 5| Step: 1
Training loss: 1.8628501892089844
Validation loss: 2.136425723632177

Epoch: 5| Step: 2
Training loss: 2.0856354236602783
Validation loss: 2.1230323861042657

Epoch: 5| Step: 3
Training loss: 2.0528852939605713
Validation loss: 2.135037119189898

Epoch: 5| Step: 4
Training loss: 1.6286605596542358
Validation loss: 2.1288780122995377

Epoch: 5| Step: 5
Training loss: 1.4038784503936768
Validation loss: 2.140051856637001

Epoch: 5| Step: 6
Training loss: 1.8430421352386475
Validation loss: 2.1301926225423813

Epoch: 5| Step: 7
Training loss: 2.0020694732666016
Validation loss: 2.134516711036364

Epoch: 5| Step: 8
Training loss: 1.821211576461792
Validation loss: 2.137416730324427

Epoch: 5| Step: 9
Training loss: 2.0704939365386963
Validation loss: 2.1276268512010574

Epoch: 5| Step: 10
Training loss: 1.9784215688705444
Validation loss: 2.121944402654966

Epoch: 5| Step: 11
Training loss: 0.27867990732192993
Validation loss: 2.1428332130114236

Epoch: 248| Step: 0
Training loss: 2.150592088699341
Validation loss: 2.137429396311442

Epoch: 5| Step: 1
Training loss: 1.6877357959747314
Validation loss: 2.137030214071274

Epoch: 5| Step: 2
Training loss: 1.8490006923675537
Validation loss: 2.130997270345688

Epoch: 5| Step: 3
Training loss: 1.6401045322418213
Validation loss: 2.1301982551813126

Epoch: 5| Step: 4
Training loss: 1.8721221685409546
Validation loss: 2.132011036078135

Epoch: 5| Step: 5
Training loss: 1.7743269205093384
Validation loss: 2.130956013997396

Epoch: 5| Step: 6
Training loss: 1.9292529821395874
Validation loss: 2.137678404649099

Epoch: 5| Step: 7
Training loss: 1.6541990041732788
Validation loss: 2.1123185952504477

Epoch: 5| Step: 8
Training loss: 1.9993541240692139
Validation loss: 2.1334529519081116

Epoch: 5| Step: 9
Training loss: 2.571103572845459
Validation loss: 2.142450749874115

Epoch: 5| Step: 10
Training loss: 2.00435471534729
Validation loss: 2.1243540892998376

Epoch: 5| Step: 11
Training loss: 2.579319953918457
Validation loss: 2.1165276914834976

Epoch: 249| Step: 0
Training loss: 1.8648927211761475
Validation loss: 2.132007067402204

Epoch: 5| Step: 1
Training loss: 1.8405765295028687
Validation loss: 2.1185451050599418

Epoch: 5| Step: 2
Training loss: 2.1113204956054688
Validation loss: 2.126893470684687

Epoch: 5| Step: 3
Training loss: 2.1508989334106445
Validation loss: 2.1054578175147376

Epoch: 5| Step: 4
Training loss: 1.6245079040527344
Validation loss: 2.0976336846748986

Epoch: 5| Step: 5
Training loss: 1.9490725994110107
Validation loss: 2.096732666095098

Epoch: 5| Step: 6
Training loss: 2.2075352668762207
Validation loss: 2.086945131421089

Epoch: 5| Step: 7
Training loss: 1.4746322631835938
Validation loss: 2.098283668359121

Epoch: 5| Step: 8
Training loss: 2.115166187286377
Validation loss: 2.095607280731201

Epoch: 5| Step: 9
Training loss: 1.7513138055801392
Validation loss: 2.0971293350060782

Epoch: 5| Step: 10
Training loss: 2.141026258468628
Validation loss: 2.0975403438011804

Epoch: 5| Step: 11
Training loss: 1.5658164024353027
Validation loss: 2.1087178786595664

Epoch: 250| Step: 0
Training loss: 1.7936832904815674
Validation loss: 2.1131556878487268

Epoch: 5| Step: 1
Training loss: 1.803048849105835
Validation loss: 2.1309682726860046

Epoch: 5| Step: 2
Training loss: 1.999913215637207
Validation loss: 2.108338470260302

Epoch: 5| Step: 3
Training loss: 2.070613384246826
Validation loss: 2.124277576804161

Epoch: 5| Step: 4
Training loss: 1.828702688217163
Validation loss: 2.1321068902810416

Epoch: 5| Step: 5
Training loss: 1.555145025253296
Validation loss: 2.117635597785314

Epoch: 5| Step: 6
Training loss: 1.9523067474365234
Validation loss: 2.145198638240496

Epoch: 5| Step: 7
Training loss: 1.9755265712738037
Validation loss: 2.130753512183825

Epoch: 5| Step: 8
Training loss: 1.9883220195770264
Validation loss: 2.136865864197413

Epoch: 5| Step: 9
Training loss: 2.013155937194824
Validation loss: 2.1269551217556

Epoch: 5| Step: 10
Training loss: 2.1173205375671387
Validation loss: 2.135632579525312

Epoch: 5| Step: 11
Training loss: 1.7957643270492554
Validation loss: 2.1154492795467377

Epoch: 251| Step: 0
Training loss: 1.9981635808944702
Validation loss: 2.1352752397457757

Epoch: 5| Step: 1
Training loss: 2.2624943256378174
Validation loss: 2.124676545461019

Epoch: 5| Step: 2
Training loss: 1.886397123336792
Validation loss: 2.125917206207911

Epoch: 5| Step: 3
Training loss: 2.704226493835449
Validation loss: 2.1242368717988334

Epoch: 5| Step: 4
Training loss: 1.872378945350647
Validation loss: 2.1386715869108834

Epoch: 5| Step: 5
Training loss: 2.176464796066284
Validation loss: 2.128581682840983

Epoch: 5| Step: 6
Training loss: 2.002734661102295
Validation loss: 2.132279396057129

Epoch: 5| Step: 7
Training loss: 2.0123302936553955
Validation loss: 2.114952305952708

Epoch: 5| Step: 8
Training loss: 1.5787872076034546
Validation loss: 2.134243110815684

Epoch: 5| Step: 9
Training loss: 1.3554449081420898
Validation loss: 2.124155804514885

Epoch: 5| Step: 10
Training loss: 1.2520573139190674
Validation loss: 2.1224936097860336

Epoch: 5| Step: 11
Training loss: 1.4677916765213013
Validation loss: 2.1114603082338967

Epoch: 252| Step: 0
Training loss: 1.5279138088226318
Validation loss: 2.1158491919438043

Epoch: 5| Step: 1
Training loss: 1.7505546808242798
Validation loss: 2.145605574051539

Epoch: 5| Step: 2
Training loss: 2.0541980266571045
Validation loss: 2.1117447167634964

Epoch: 5| Step: 3
Training loss: 1.6846773624420166
Validation loss: 2.133970325191816

Epoch: 5| Step: 4
Training loss: 2.4815990924835205
Validation loss: 2.1242108841737113

Epoch: 5| Step: 5
Training loss: 1.3935115337371826
Validation loss: 2.1137639929850898

Epoch: 5| Step: 6
Training loss: 2.026233196258545
Validation loss: 2.111226975917816

Epoch: 5| Step: 7
Training loss: 2.4928841590881348
Validation loss: 2.1168525417645774

Epoch: 5| Step: 8
Training loss: 1.9899518489837646
Validation loss: 2.1115863571564355

Epoch: 5| Step: 9
Training loss: 1.5813465118408203
Validation loss: 2.112433393796285

Epoch: 5| Step: 10
Training loss: 1.7759711742401123
Validation loss: 2.11938705543677

Epoch: 5| Step: 11
Training loss: 1.2194297313690186
Validation loss: 2.1249224046866098

Epoch: 253| Step: 0
Training loss: 2.52409291267395
Validation loss: 2.1297221730152764

Epoch: 5| Step: 1
Training loss: 1.7801697254180908
Validation loss: 2.1293997317552567

Epoch: 5| Step: 2
Training loss: 1.6693798303604126
Validation loss: 2.1028359134991965

Epoch: 5| Step: 3
Training loss: 1.983263611793518
Validation loss: 2.1292094588279724

Epoch: 5| Step: 4
Training loss: 1.5251200199127197
Validation loss: 2.130138779679934

Epoch: 5| Step: 5
Training loss: 2.3528034687042236
Validation loss: 2.1346989373366037

Epoch: 5| Step: 6
Training loss: 1.5845922231674194
Validation loss: 2.125999247034391

Epoch: 5| Step: 7
Training loss: 2.0384085178375244
Validation loss: 2.1224998434384665

Epoch: 5| Step: 8
Training loss: 1.741236686706543
Validation loss: 2.1313462307055793

Epoch: 5| Step: 9
Training loss: 1.5808991193771362
Validation loss: 2.1513983011245728

Epoch: 5| Step: 10
Training loss: 1.6206963062286377
Validation loss: 2.131250118215879

Epoch: 5| Step: 11
Training loss: 3.095902919769287
Validation loss: 2.1437719563643136

Epoch: 254| Step: 0
Training loss: 1.7815179824829102
Validation loss: 2.154375741879145

Epoch: 5| Step: 1
Training loss: 0.9848179817199707
Validation loss: 2.1444672594467797

Epoch: 5| Step: 2
Training loss: 1.949042558670044
Validation loss: 2.1279823233683905

Epoch: 5| Step: 3
Training loss: 2.5002920627593994
Validation loss: 2.157965064048767

Epoch: 5| Step: 4
Training loss: 1.7751754522323608
Validation loss: 2.1612840046485267

Epoch: 5| Step: 5
Training loss: 1.8918800354003906
Validation loss: 2.1641248812278113

Epoch: 5| Step: 6
Training loss: 1.8225209712982178
Validation loss: 2.1328601439793906

Epoch: 5| Step: 7
Training loss: 1.7387282848358154
Validation loss: 2.153521274526914

Epoch: 5| Step: 8
Training loss: 2.0131218433380127
Validation loss: 2.1277825186649957

Epoch: 5| Step: 9
Training loss: 1.9881702661514282
Validation loss: 2.1334687173366547

Epoch: 5| Step: 10
Training loss: 2.2896509170532227
Validation loss: 2.108902469277382

Epoch: 5| Step: 11
Training loss: 2.8573570251464844
Validation loss: 2.1151622533798218

Epoch: 255| Step: 0
Training loss: 2.2584266662597656
Validation loss: 2.1200343618790307

Epoch: 5| Step: 1
Training loss: 1.7346115112304688
Validation loss: 2.1134745279947915

Epoch: 5| Step: 2
Training loss: 2.1898293495178223
Validation loss: 2.103766903281212

Epoch: 5| Step: 3
Training loss: 1.3778975009918213
Validation loss: 2.127729450662931

Epoch: 5| Step: 4
Training loss: 1.6630127429962158
Validation loss: 2.1199397444725037

Epoch: 5| Step: 5
Training loss: 2.0973939895629883
Validation loss: 2.129718631505966

Epoch: 5| Step: 6
Training loss: 1.843163251876831
Validation loss: 2.1335808535416922

Epoch: 5| Step: 7
Training loss: 1.6617780923843384
Validation loss: 2.1323392440875373

Epoch: 5| Step: 8
Training loss: 2.442497968673706
Validation loss: 2.1556968688964844

Epoch: 5| Step: 9
Training loss: 1.6419589519500732
Validation loss: 2.1617273886998496

Epoch: 5| Step: 10
Training loss: 2.388671398162842
Validation loss: 2.1294815788666406

Epoch: 5| Step: 11
Training loss: 0.5585451126098633
Validation loss: 2.155515914162

Epoch: 256| Step: 0
Training loss: 2.033440113067627
Validation loss: 2.135287950436274

Epoch: 5| Step: 1
Training loss: 1.8956544399261475
Validation loss: 2.132540707786878

Epoch: 5| Step: 2
Training loss: 2.3494327068328857
Validation loss: 2.1312655011812844

Epoch: 5| Step: 3
Training loss: 1.5753427743911743
Validation loss: 2.1347194711367288

Epoch: 5| Step: 4
Training loss: 2.0522608757019043
Validation loss: 2.136164824167887

Epoch: 5| Step: 5
Training loss: 1.9421594142913818
Validation loss: 2.1167627225319543

Epoch: 5| Step: 6
Training loss: 2.084704637527466
Validation loss: 2.1473663598299026

Epoch: 5| Step: 7
Training loss: 1.7836449146270752
Validation loss: 2.128302186727524

Epoch: 5| Step: 8
Training loss: 1.8136804103851318
Validation loss: 2.1241041918595633

Epoch: 5| Step: 9
Training loss: 1.742246389389038
Validation loss: 2.105450148383776

Epoch: 5| Step: 10
Training loss: 1.581338882446289
Validation loss: 2.1227283626794815

Epoch: 5| Step: 11
Training loss: 1.4089313745498657
Validation loss: 2.1199673960606256

Epoch: 257| Step: 0
Training loss: 1.9555833339691162
Validation loss: 2.118030289808909

Epoch: 5| Step: 1
Training loss: 1.8867995738983154
Validation loss: 2.1180036614338555

Epoch: 5| Step: 2
Training loss: 1.7300201654434204
Validation loss: 2.1167064855496087

Epoch: 5| Step: 3
Training loss: 1.9211963415145874
Validation loss: 2.153996412952741

Epoch: 5| Step: 4
Training loss: 2.184567928314209
Validation loss: 2.1298720091581345

Epoch: 5| Step: 5
Training loss: 1.1631553173065186
Validation loss: 2.134842480222384

Epoch: 5| Step: 6
Training loss: 2.8285908699035645
Validation loss: 2.1296814580758414

Epoch: 5| Step: 7
Training loss: 1.8599417209625244
Validation loss: 2.124321848154068

Epoch: 5| Step: 8
Training loss: 1.7271058559417725
Validation loss: 2.1404539297024407

Epoch: 5| Step: 9
Training loss: 2.1772077083587646
Validation loss: 2.125863090157509

Epoch: 5| Step: 10
Training loss: 1.2878309488296509
Validation loss: 2.1151538689931235

Epoch: 5| Step: 11
Training loss: 1.416847825050354
Validation loss: 2.102010597785314

Epoch: 258| Step: 0
Training loss: 2.220271348953247
Validation loss: 2.128260766466459

Epoch: 5| Step: 1
Training loss: 1.7479603290557861
Validation loss: 2.110058938463529

Epoch: 5| Step: 2
Training loss: 1.945766806602478
Validation loss: 2.125510116418203

Epoch: 5| Step: 3
Training loss: 2.084266424179077
Validation loss: 2.1065752804279327

Epoch: 5| Step: 4
Training loss: 2.2090415954589844
Validation loss: 2.1487727910280228

Epoch: 5| Step: 5
Training loss: 1.5900156497955322
Validation loss: 2.145526667435964

Epoch: 5| Step: 6
Training loss: 2.0486679077148438
Validation loss: 2.1455829590559006

Epoch: 5| Step: 7
Training loss: 1.556593894958496
Validation loss: 2.14427741865317

Epoch: 5| Step: 8
Training loss: 1.8596111536026
Validation loss: 2.1493137230475745

Epoch: 5| Step: 9
Training loss: 1.682079553604126
Validation loss: 2.123039330045382

Epoch: 5| Step: 10
Training loss: 1.5030930042266846
Validation loss: 2.1205074886480966

Epoch: 5| Step: 11
Training loss: 1.5302573442459106
Validation loss: 2.142086088657379

Epoch: 259| Step: 0
Training loss: 1.8704841136932373
Validation loss: 2.1426965594291687

Epoch: 5| Step: 1
Training loss: 1.7659610509872437
Validation loss: 2.149099111557007

Epoch: 5| Step: 2
Training loss: 2.2961392402648926
Validation loss: 2.1628386278947196

Epoch: 5| Step: 3
Training loss: 1.8169552087783813
Validation loss: 2.1377885788679123

Epoch: 5| Step: 4
Training loss: 2.1140975952148438
Validation loss: 2.1518684029579163

Epoch: 5| Step: 5
Training loss: 1.5389150381088257
Validation loss: 2.1343855808178582

Epoch: 5| Step: 6
Training loss: 1.7741276025772095
Validation loss: 2.1232557743787766

Epoch: 5| Step: 7
Training loss: 1.8793519735336304
Validation loss: 2.1298514157533646

Epoch: 5| Step: 8
Training loss: 1.7342172861099243
Validation loss: 2.1108410308758416

Epoch: 5| Step: 9
Training loss: 1.8077589273452759
Validation loss: 2.134258419275284

Epoch: 5| Step: 10
Training loss: 2.3323733806610107
Validation loss: 2.140451560417811

Epoch: 5| Step: 11
Training loss: 1.3059477806091309
Validation loss: 2.135007381439209

Epoch: 260| Step: 0
Training loss: 2.2824959754943848
Validation loss: 2.126161257425944

Epoch: 5| Step: 1
Training loss: 2.2632803916931152
Validation loss: 2.139835168917974

Epoch: 5| Step: 2
Training loss: 2.063331127166748
Validation loss: 2.1258975813786187

Epoch: 5| Step: 3
Training loss: 2.7183640003204346
Validation loss: 2.1288611392180123

Epoch: 5| Step: 4
Training loss: 1.4931533336639404
Validation loss: 2.133885090549787

Epoch: 5| Step: 5
Training loss: 1.6986281871795654
Validation loss: 2.1501675645510354

Epoch: 5| Step: 6
Training loss: 1.9798450469970703
Validation loss: 2.1483531296253204

Epoch: 5| Step: 7
Training loss: 1.1852188110351562
Validation loss: 2.1446280727783837

Epoch: 5| Step: 8
Training loss: 2.1237900257110596
Validation loss: 2.1164045184850693

Epoch: 5| Step: 9
Training loss: 1.913303017616272
Validation loss: 2.126795878012975

Epoch: 5| Step: 10
Training loss: 1.3153127431869507
Validation loss: 2.1186630874872208

Epoch: 5| Step: 11
Training loss: 1.1506074666976929
Validation loss: 2.117634062965711

Epoch: 261| Step: 0
Training loss: 2.0874600410461426
Validation loss: 2.1058075527350106

Epoch: 5| Step: 1
Training loss: 1.8447885513305664
Validation loss: 2.118702878554662

Epoch: 5| Step: 2
Training loss: 2.1550354957580566
Validation loss: 2.105559527873993

Epoch: 5| Step: 3
Training loss: 2.147470235824585
Validation loss: 2.092154304186503

Epoch: 5| Step: 4
Training loss: 1.7975234985351562
Validation loss: 2.1052538802226386

Epoch: 5| Step: 5
Training loss: 1.566039800643921
Validation loss: 2.1197078178326287

Epoch: 5| Step: 6
Training loss: 1.6010639667510986
Validation loss: 2.1091227332750955

Epoch: 5| Step: 7
Training loss: 2.1158103942871094
Validation loss: 2.11607559521993

Epoch: 5| Step: 8
Training loss: 1.6330671310424805
Validation loss: 2.1283887873093286

Epoch: 5| Step: 9
Training loss: 2.72546124458313
Validation loss: 2.1128999441862106

Epoch: 5| Step: 10
Training loss: 1.5935121774673462
Validation loss: 2.118320802847544

Epoch: 5| Step: 11
Training loss: 1.562887191772461
Validation loss: 2.124639709790548

Epoch: 262| Step: 0
Training loss: 1.527693748474121
Validation loss: 2.113231365879377

Epoch: 5| Step: 1
Training loss: 2.053199052810669
Validation loss: 2.1302292893330255

Epoch: 5| Step: 2
Training loss: 1.855713129043579
Validation loss: 2.1394209365049996

Epoch: 5| Step: 3
Training loss: 1.9955472946166992
Validation loss: 2.1444627344608307

Epoch: 5| Step: 4
Training loss: 2.107975721359253
Validation loss: 2.14659250775973

Epoch: 5| Step: 5
Training loss: 1.358478307723999
Validation loss: 2.145711367328962

Epoch: 5| Step: 6
Training loss: 2.5736172199249268
Validation loss: 2.12689271569252

Epoch: 5| Step: 7
Training loss: 1.6785351037979126
Validation loss: 2.1369091868400574

Epoch: 5| Step: 8
Training loss: 1.6469529867172241
Validation loss: 2.1158591310183206

Epoch: 5| Step: 9
Training loss: 2.1696736812591553
Validation loss: 2.1202556689580283

Epoch: 5| Step: 10
Training loss: 2.3499279022216797
Validation loss: 2.104113151629766

Epoch: 5| Step: 11
Training loss: 2.636066436767578
Validation loss: 2.106080378095309

Epoch: 263| Step: 0
Training loss: 2.075684070587158
Validation loss: 2.1059568425019584

Epoch: 5| Step: 1
Training loss: 2.0816376209259033
Validation loss: 2.104249283671379

Epoch: 5| Step: 2
Training loss: 2.2983860969543457
Validation loss: 2.1028223087390265

Epoch: 5| Step: 3
Training loss: 2.15522837638855
Validation loss: 2.1078643103440604

Epoch: 5| Step: 4
Training loss: 2.0361266136169434
Validation loss: 2.10013680656751

Epoch: 5| Step: 5
Training loss: 1.7893279790878296
Validation loss: 2.0960581302642822

Epoch: 5| Step: 6
Training loss: 2.155762195587158
Validation loss: 2.1066299875577292

Epoch: 5| Step: 7
Training loss: 1.6666643619537354
Validation loss: 2.120956818262736

Epoch: 5| Step: 8
Training loss: 1.7622687816619873
Validation loss: 2.0970985988775888

Epoch: 5| Step: 9
Training loss: 1.4708698987960815
Validation loss: 2.129779358704885

Epoch: 5| Step: 10
Training loss: 2.2668209075927734
Validation loss: 2.099545086423556

Epoch: 5| Step: 11
Training loss: 1.316162347793579
Validation loss: 2.1216818044583

Epoch: 264| Step: 0
Training loss: 1.34034264087677
Validation loss: 2.1267367551724115

Epoch: 5| Step: 1
Training loss: 1.563899278640747
Validation loss: 2.154262771209081

Epoch: 5| Step: 2
Training loss: 2.148977756500244
Validation loss: 2.134272883335749

Epoch: 5| Step: 3
Training loss: 2.561457633972168
Validation loss: 2.1214524110158286

Epoch: 5| Step: 4
Training loss: 1.8176370859146118
Validation loss: 2.1301212211449942

Epoch: 5| Step: 5
Training loss: 2.200789213180542
Validation loss: 2.123478507002195

Epoch: 5| Step: 6
Training loss: 2.5358405113220215
Validation loss: 2.1275008817513785

Epoch: 5| Step: 7
Training loss: 1.5588815212249756
Validation loss: 2.130910267432531

Epoch: 5| Step: 8
Training loss: 1.5080420970916748
Validation loss: 2.1397707561651864

Epoch: 5| Step: 9
Training loss: 1.7962573766708374
Validation loss: 2.1147456566492715

Epoch: 5| Step: 10
Training loss: 1.5703972578048706
Validation loss: 2.146895632147789

Epoch: 5| Step: 11
Training loss: 1.2567291259765625
Validation loss: 2.1426719476779303

Epoch: 265| Step: 0
Training loss: 2.199651002883911
Validation loss: 2.139249394337336

Epoch: 5| Step: 1
Training loss: 1.7954113483428955
Validation loss: 2.11270139614741

Epoch: 5| Step: 2
Training loss: 1.7943302392959595
Validation loss: 2.115309774875641

Epoch: 5| Step: 3
Training loss: 1.9604148864746094
Validation loss: 2.1393972982962928

Epoch: 5| Step: 4
Training loss: 1.6107772588729858
Validation loss: 2.1434108366568885

Epoch: 5| Step: 5
Training loss: 1.9654690027236938
Validation loss: 2.148027708133062

Epoch: 5| Step: 6
Training loss: 1.916089415550232
Validation loss: 2.1372400720914206

Epoch: 5| Step: 7
Training loss: 1.653531789779663
Validation loss: 2.135866403579712

Epoch: 5| Step: 8
Training loss: 2.0831055641174316
Validation loss: 2.131452371676763

Epoch: 5| Step: 9
Training loss: 1.5777934789657593
Validation loss: 2.1330726693073907

Epoch: 5| Step: 10
Training loss: 1.7688992023468018
Validation loss: 2.1407754768927894

Epoch: 5| Step: 11
Training loss: 1.5915361642837524
Validation loss: 2.149733622868856

Epoch: 266| Step: 0
Training loss: 1.9274299144744873
Validation loss: 2.182184621691704

Epoch: 5| Step: 1
Training loss: 1.7093174457550049
Validation loss: 2.194251293937365

Epoch: 5| Step: 2
Training loss: 1.578857183456421
Validation loss: 2.1798839271068573

Epoch: 5| Step: 3
Training loss: 2.717658758163452
Validation loss: 2.177614370981852

Epoch: 5| Step: 4
Training loss: 1.947959542274475
Validation loss: 2.1786325673262277

Epoch: 5| Step: 5
Training loss: 1.6382297277450562
Validation loss: 2.171547214190165

Epoch: 5| Step: 6
Training loss: 1.7571483850479126
Validation loss: 2.1359441379706063

Epoch: 5| Step: 7
Training loss: 1.501316785812378
Validation loss: 2.1378266364336014

Epoch: 5| Step: 8
Training loss: 2.4917638301849365
Validation loss: 2.138128141562144

Epoch: 5| Step: 9
Training loss: 2.135099411010742
Validation loss: 2.119974901278814

Epoch: 5| Step: 10
Training loss: 1.8947607278823853
Validation loss: 2.1009334921836853

Epoch: 5| Step: 11
Training loss: 1.6925833225250244
Validation loss: 2.111388921737671

Epoch: 267| Step: 0
Training loss: 2.752257823944092
Validation loss: 2.110162561138471

Epoch: 5| Step: 1
Training loss: 1.7482484579086304
Validation loss: 2.1111805588006973

Epoch: 5| Step: 2
Training loss: 1.9465811252593994
Validation loss: 2.101848771174749

Epoch: 5| Step: 3
Training loss: 1.9568378925323486
Validation loss: 2.1003602544466653

Epoch: 5| Step: 4
Training loss: 1.8530282974243164
Validation loss: 2.105015312631925

Epoch: 5| Step: 5
Training loss: 1.5506534576416016
Validation loss: 2.10863666733106

Epoch: 5| Step: 6
Training loss: 1.9987821578979492
Validation loss: 2.1048049132029214

Epoch: 5| Step: 7
Training loss: 1.7853376865386963
Validation loss: 2.104256252447764

Epoch: 5| Step: 8
Training loss: 1.707830786705017
Validation loss: 2.0924708445866904

Epoch: 5| Step: 9
Training loss: 1.633270263671875
Validation loss: 2.119819680849711

Epoch: 5| Step: 10
Training loss: 1.9804527759552002
Validation loss: 2.1141928235689798

Epoch: 5| Step: 11
Training loss: 2.599060535430908
Validation loss: 2.1433878441651664

Epoch: 268| Step: 0
Training loss: 2.1352059841156006
Validation loss: 2.1284680316845574

Epoch: 5| Step: 1
Training loss: 2.0420501232147217
Validation loss: 2.1208638151486716

Epoch: 5| Step: 2
Training loss: 1.5403571128845215
Validation loss: 2.1387710173924765

Epoch: 5| Step: 3
Training loss: 1.7316980361938477
Validation loss: 2.147057592868805

Epoch: 5| Step: 4
Training loss: 1.8454656600952148
Validation loss: 2.139686957001686

Epoch: 5| Step: 5
Training loss: 2.1720378398895264
Validation loss: 2.140344033638636

Epoch: 5| Step: 6
Training loss: 2.284658670425415
Validation loss: 2.1365987956523895

Epoch: 5| Step: 7
Training loss: 1.6149013042449951
Validation loss: 2.122244859735171

Epoch: 5| Step: 8
Training loss: 1.7388702630996704
Validation loss: 2.1235244323809943

Epoch: 5| Step: 9
Training loss: 2.1360485553741455
Validation loss: 2.1291688283284507

Epoch: 5| Step: 10
Training loss: 2.5833580493927
Validation loss: 2.140875200430552

Epoch: 5| Step: 11
Training loss: 0.4586049020290375
Validation loss: 2.1434525897105536

Epoch: 269| Step: 0
Training loss: 1.8867881298065186
Validation loss: 2.1409311344226203

Epoch: 5| Step: 1
Training loss: 1.8896796703338623
Validation loss: 2.144565219680468

Epoch: 5| Step: 2
Training loss: 1.8190381526947021
Validation loss: 2.1382607420285544

Epoch: 5| Step: 3
Training loss: 2.1639225482940674
Validation loss: 2.1692128479480743

Epoch: 5| Step: 4
Training loss: 2.1399688720703125
Validation loss: 2.1337389250596366

Epoch: 5| Step: 5
Training loss: 2.158703565597534
Validation loss: 2.184037218491236

Epoch: 5| Step: 6
Training loss: 2.066187620162964
Validation loss: 2.1605753203233085

Epoch: 5| Step: 7
Training loss: 1.7938390970230103
Validation loss: 2.149662504593531

Epoch: 5| Step: 8
Training loss: 1.8739795684814453
Validation loss: 2.1625947107871375

Epoch: 5| Step: 9
Training loss: 2.3508756160736084
Validation loss: 2.150366281469663

Epoch: 5| Step: 10
Training loss: 1.4365825653076172
Validation loss: 2.1503270715475082

Epoch: 5| Step: 11
Training loss: 2.9640591144561768
Validation loss: 2.1369696656862893

Epoch: 270| Step: 0
Training loss: 1.598449945449829
Validation loss: 2.135963052511215

Epoch: 5| Step: 1
Training loss: 2.640585422515869
Validation loss: 2.1191648642222085

Epoch: 5| Step: 2
Training loss: 1.9992882013320923
Validation loss: 2.1040998746951423

Epoch: 5| Step: 3
Training loss: 1.8085577487945557
Validation loss: 2.1286102135976157

Epoch: 5| Step: 4
Training loss: 1.6397340297698975
Validation loss: 2.112777123848597

Epoch: 5| Step: 5
Training loss: 2.0753211975097656
Validation loss: 2.112165162960688

Epoch: 5| Step: 6
Training loss: 1.5305095911026
Validation loss: 2.1072107503811517

Epoch: 5| Step: 7
Training loss: 2.1805813312530518
Validation loss: 2.1120528827110925

Epoch: 5| Step: 8
Training loss: 2.204801082611084
Validation loss: 2.122460663318634

Epoch: 5| Step: 9
Training loss: 2.175137996673584
Validation loss: 2.1231249471505484

Epoch: 5| Step: 10
Training loss: 2.1271774768829346
Validation loss: 2.1335114389657974

Epoch: 5| Step: 11
Training loss: 1.2300798892974854
Validation loss: 2.1313617626825967

Epoch: 271| Step: 0
Training loss: 1.42464280128479
Validation loss: 2.1392373392979303

Epoch: 5| Step: 1
Training loss: 1.6102575063705444
Validation loss: 2.139265005787214

Epoch: 5| Step: 2
Training loss: 1.9197666645050049
Validation loss: 2.1299400329589844

Epoch: 5| Step: 3
Training loss: 1.5072026252746582
Validation loss: 2.1376987944046655

Epoch: 5| Step: 4
Training loss: 2.244955062866211
Validation loss: 2.148537223537763

Epoch: 5| Step: 5
Training loss: 2.226745367050171
Validation loss: 2.160780444741249

Epoch: 5| Step: 6
Training loss: 1.6624901294708252
Validation loss: 2.1205586393674216

Epoch: 5| Step: 7
Training loss: 2.3083713054656982
Validation loss: 2.1324318995078406

Epoch: 5| Step: 8
Training loss: 2.042837619781494
Validation loss: 2.134598304828008

Epoch: 5| Step: 9
Training loss: 2.2308969497680664
Validation loss: 2.1304606795310974

Epoch: 5| Step: 10
Training loss: 1.762691855430603
Validation loss: 2.1367311030626297

Epoch: 5| Step: 11
Training loss: 2.124307155609131
Validation loss: 2.128200888633728

Epoch: 272| Step: 0
Training loss: 1.6913620233535767
Validation loss: 2.1373858650525412

Epoch: 5| Step: 1
Training loss: 1.916642189025879
Validation loss: 2.136216700077057

Epoch: 5| Step: 2
Training loss: 1.8103253841400146
Validation loss: 2.1361019015312195

Epoch: 5| Step: 3
Training loss: 1.8721544742584229
Validation loss: 2.137587388356527

Epoch: 5| Step: 4
Training loss: 2.016740322113037
Validation loss: 2.1442688504854837

Epoch: 5| Step: 5
Training loss: 1.4002479314804077
Validation loss: 2.145456383625666

Epoch: 5| Step: 6
Training loss: 2.0160834789276123
Validation loss: 2.146289919813474

Epoch: 5| Step: 7
Training loss: 2.097348928451538
Validation loss: 2.1466607749462128

Epoch: 5| Step: 8
Training loss: 2.2375621795654297
Validation loss: 2.156248226761818

Epoch: 5| Step: 9
Training loss: 2.061072826385498
Validation loss: 2.1595092366139093

Epoch: 5| Step: 10
Training loss: 1.8843517303466797
Validation loss: 2.1409828762213388

Epoch: 5| Step: 11
Training loss: 1.5538320541381836
Validation loss: 2.15408522884051

Epoch: 273| Step: 0
Training loss: 1.8480678796768188
Validation loss: 2.1441996544599533

Epoch: 5| Step: 1
Training loss: 1.778369665145874
Validation loss: 2.145767013231913

Epoch: 5| Step: 2
Training loss: 1.5621984004974365
Validation loss: 2.113824874162674

Epoch: 5| Step: 3
Training loss: 2.165706157684326
Validation loss: 2.130977397163709

Epoch: 5| Step: 4
Training loss: 1.7062835693359375
Validation loss: 2.1127557953198752

Epoch: 5| Step: 5
Training loss: 2.2049031257629395
Validation loss: 2.1117036938667297

Epoch: 5| Step: 6
Training loss: 1.8060271739959717
Validation loss: 2.1058259258667626

Epoch: 5| Step: 7
Training loss: 1.8811261653900146
Validation loss: 2.109818031390508

Epoch: 5| Step: 8
Training loss: 1.9642503261566162
Validation loss: 2.1092611253261566

Epoch: 5| Step: 9
Training loss: 2.2221665382385254
Validation loss: 2.130019490917524

Epoch: 5| Step: 10
Training loss: 1.816171646118164
Validation loss: 2.11872997879982

Epoch: 5| Step: 11
Training loss: 1.7639366388320923
Validation loss: 2.1378812938928604

Epoch: 274| Step: 0
Training loss: 1.8777233362197876
Validation loss: 2.12542133529981

Epoch: 5| Step: 1
Training loss: 2.1778159141540527
Validation loss: 2.1073076874017715

Epoch: 5| Step: 2
Training loss: 1.5557310581207275
Validation loss: 2.1204330573479333

Epoch: 5| Step: 3
Training loss: 1.7634013891220093
Validation loss: 2.1212393095095954

Epoch: 5| Step: 4
Training loss: 1.6115562915802002
Validation loss: 2.11118945479393

Epoch: 5| Step: 5
Training loss: 2.1624979972839355
Validation loss: 2.106070796648661

Epoch: 5| Step: 6
Training loss: 1.7896144390106201
Validation loss: 2.112845147649447

Epoch: 5| Step: 7
Training loss: 1.7839889526367188
Validation loss: 2.1163964768250785

Epoch: 5| Step: 8
Training loss: 1.4972598552703857
Validation loss: 2.1310050735870996

Epoch: 5| Step: 9
Training loss: 3.0005080699920654
Validation loss: 2.115090474486351

Epoch: 5| Step: 10
Training loss: 1.5206024646759033
Validation loss: 2.149976516763369

Epoch: 5| Step: 11
Training loss: 1.847947120666504
Validation loss: 2.1244864761829376

Epoch: 275| Step: 0
Training loss: 1.6616510152816772
Validation loss: 2.1498653640349707

Epoch: 5| Step: 1
Training loss: 1.8154102563858032
Validation loss: 2.1788743684689202

Epoch: 5| Step: 2
Training loss: 2.110593795776367
Validation loss: 2.1892301390568414

Epoch: 5| Step: 3
Training loss: 1.7735620737075806
Validation loss: 2.195262387394905

Epoch: 5| Step: 4
Training loss: 1.4700725078582764
Validation loss: 2.16226027905941

Epoch: 5| Step: 5
Training loss: 1.954284429550171
Validation loss: 2.170879691839218

Epoch: 5| Step: 6
Training loss: 1.67898428440094
Validation loss: 2.188054069876671

Epoch: 5| Step: 7
Training loss: 2.022984504699707
Validation loss: 2.168667043248812

Epoch: 5| Step: 8
Training loss: 2.5783770084381104
Validation loss: 2.149666905403137

Epoch: 5| Step: 9
Training loss: 1.994339942932129
Validation loss: 2.1386919021606445

Epoch: 5| Step: 10
Training loss: 1.816300392150879
Validation loss: 2.1340739180644355

Epoch: 5| Step: 11
Training loss: 0.6471657752990723
Validation loss: 2.1345302561918893

Epoch: 276| Step: 0
Training loss: 1.5931966304779053
Validation loss: 2.136965185403824

Epoch: 5| Step: 1
Training loss: 2.102692127227783
Validation loss: 2.139680107434591

Epoch: 5| Step: 2
Training loss: 1.5190411806106567
Validation loss: 2.148488327860832

Epoch: 5| Step: 3
Training loss: 1.70974600315094
Validation loss: 2.118132029970487

Epoch: 5| Step: 4
Training loss: 1.9649473428726196
Validation loss: 2.141910051306089

Epoch: 5| Step: 5
Training loss: 1.6061729192733765
Validation loss: 2.1553469945987067

Epoch: 5| Step: 6
Training loss: 2.468520164489746
Validation loss: 2.1615441292524338

Epoch: 5| Step: 7
Training loss: 1.8267101049423218
Validation loss: 2.1287839263677597

Epoch: 5| Step: 8
Training loss: 2.454746723175049
Validation loss: 2.147887885570526

Epoch: 5| Step: 9
Training loss: 1.6646932363510132
Validation loss: 2.1458064715067544

Epoch: 5| Step: 10
Training loss: 1.470543622970581
Validation loss: 2.148313269019127

Epoch: 5| Step: 11
Training loss: 2.646716356277466
Validation loss: 2.1270791739225388

Epoch: 277| Step: 0
Training loss: 1.4989656209945679
Validation loss: 2.1145084450642266

Epoch: 5| Step: 1
Training loss: 2.459313154220581
Validation loss: 2.1135450502236686

Epoch: 5| Step: 2
Training loss: 1.9015260934829712
Validation loss: 2.11166845758756

Epoch: 5| Step: 3
Training loss: 1.572745680809021
Validation loss: 2.0951028863588967

Epoch: 5| Step: 4
Training loss: 2.082350969314575
Validation loss: 2.091065173347791

Epoch: 5| Step: 5
Training loss: 2.293645143508911
Validation loss: 2.0718367248773575

Epoch: 5| Step: 6
Training loss: 1.3556684255599976
Validation loss: 2.1046226024627686

Epoch: 5| Step: 7
Training loss: 2.0554230213165283
Validation loss: 2.08088810245196

Epoch: 5| Step: 8
Training loss: 1.4830881357192993
Validation loss: 2.084745779633522

Epoch: 5| Step: 9
Training loss: 1.8296165466308594
Validation loss: 2.08163882791996

Epoch: 5| Step: 10
Training loss: 2.3847873210906982
Validation loss: 2.082316348950068

Epoch: 5| Step: 11
Training loss: 3.3619041442871094
Validation loss: 2.100386694073677

Epoch: 278| Step: 0
Training loss: 2.201608180999756
Validation loss: 2.1091864754756293

Epoch: 5| Step: 1
Training loss: 1.5238465070724487
Validation loss: 2.101112514734268

Epoch: 5| Step: 2
Training loss: 2.283252000808716
Validation loss: 2.1102844923734665

Epoch: 5| Step: 3
Training loss: 2.0259807109832764
Validation loss: 2.1258722841739655

Epoch: 5| Step: 4
Training loss: 2.0228524208068848
Validation loss: 2.1296303123235703

Epoch: 5| Step: 5
Training loss: 1.8000974655151367
Validation loss: 2.1220038135846457

Epoch: 5| Step: 6
Training loss: 1.8490012884140015
Validation loss: 2.102070381244024

Epoch: 5| Step: 7
Training loss: 2.1003806591033936
Validation loss: 2.1016747603813806

Epoch: 5| Step: 8
Training loss: 2.0049595832824707
Validation loss: 2.110784024000168

Epoch: 5| Step: 9
Training loss: 2.0118796825408936
Validation loss: 2.1015631953875222

Epoch: 5| Step: 10
Training loss: 1.4644978046417236
Validation loss: 2.123099992672602

Epoch: 5| Step: 11
Training loss: 1.2886282205581665
Validation loss: 2.1213880429665246

Epoch: 279| Step: 0
Training loss: 1.9139740467071533
Validation loss: 2.0874017576376596

Epoch: 5| Step: 1
Training loss: 1.7997453212738037
Validation loss: 2.096815581123034

Epoch: 5| Step: 2
Training loss: 2.2208855152130127
Validation loss: 2.1089873760938644

Epoch: 5| Step: 3
Training loss: 1.9760124683380127
Validation loss: 2.1031962037086487

Epoch: 5| Step: 4
Training loss: 2.2473249435424805
Validation loss: 2.1063162237405777

Epoch: 5| Step: 5
Training loss: 1.3680322170257568
Validation loss: 2.083430826663971

Epoch: 5| Step: 6
Training loss: 2.093456506729126
Validation loss: 2.115146736303965

Epoch: 5| Step: 7
Training loss: 1.9737701416015625
Validation loss: 2.107593004902204

Epoch: 5| Step: 8
Training loss: 1.3277170658111572
Validation loss: 2.11746346950531

Epoch: 5| Step: 9
Training loss: 1.7635291814804077
Validation loss: 2.100559984644254

Epoch: 5| Step: 10
Training loss: 1.622771978378296
Validation loss: 2.106494744618734

Epoch: 5| Step: 11
Training loss: 1.7213767766952515
Validation loss: 2.1334532697995505

Epoch: 280| Step: 0
Training loss: 1.8963218927383423
Validation loss: 2.140021632115046

Epoch: 5| Step: 1
Training loss: 1.6304060220718384
Validation loss: 2.135614663362503

Epoch: 5| Step: 2
Training loss: 2.200477123260498
Validation loss: 2.1421335289875665

Epoch: 5| Step: 3
Training loss: 1.862544298171997
Validation loss: 2.147545655568441

Epoch: 5| Step: 4
Training loss: 1.9643604755401611
Validation loss: 2.1757943679889045

Epoch: 5| Step: 5
Training loss: 1.9578502178192139
Validation loss: 2.1487417966127396

Epoch: 5| Step: 6
Training loss: 2.150970697402954
Validation loss: 2.1500486681858697

Epoch: 5| Step: 7
Training loss: 1.359075903892517
Validation loss: 2.148761967817942

Epoch: 5| Step: 8
Training loss: 1.4330672025680542
Validation loss: 2.138537844022115

Epoch: 5| Step: 9
Training loss: 2.3264000415802
Validation loss: 2.133521397908529

Epoch: 5| Step: 10
Training loss: 1.8878202438354492
Validation loss: 2.1420063773790994

Epoch: 5| Step: 11
Training loss: 1.1540595293045044
Validation loss: 2.1537824471791587

Epoch: 281| Step: 0
Training loss: 2.3208041191101074
Validation loss: 2.138831893603007

Epoch: 5| Step: 1
Training loss: 1.5741970539093018
Validation loss: 2.1444406857093177

Epoch: 5| Step: 2
Training loss: 1.6981216669082642
Validation loss: 2.1339831799268723

Epoch: 5| Step: 3
Training loss: 1.573177456855774
Validation loss: 2.149086778362592

Epoch: 5| Step: 4
Training loss: 1.4233529567718506
Validation loss: 2.13289641837279

Epoch: 5| Step: 5
Training loss: 1.3458572626113892
Validation loss: 2.146331508954366

Epoch: 5| Step: 6
Training loss: 2.271665334701538
Validation loss: 2.1449463963508606

Epoch: 5| Step: 7
Training loss: 1.8301912546157837
Validation loss: 2.136547699570656

Epoch: 5| Step: 8
Training loss: 2.320880174636841
Validation loss: 2.1443981726964316

Epoch: 5| Step: 9
Training loss: 1.8748340606689453
Validation loss: 2.1685617764790854

Epoch: 5| Step: 10
Training loss: 1.8896681070327759
Validation loss: 2.1461364229520163

Epoch: 5| Step: 11
Training loss: 4.518565654754639
Validation loss: 2.142413998643557

Epoch: 282| Step: 0
Training loss: 1.8726673126220703
Validation loss: 2.1643053740262985

Epoch: 5| Step: 1
Training loss: 1.938152551651001
Validation loss: 2.144369979699453

Epoch: 5| Step: 2
Training loss: 2.5975875854492188
Validation loss: 2.132729187607765

Epoch: 5| Step: 3
Training loss: 1.589485764503479
Validation loss: 2.132396707932154

Epoch: 5| Step: 4
Training loss: 2.260885715484619
Validation loss: 2.136742780605952

Epoch: 5| Step: 5
Training loss: 2.249293804168701
Validation loss: 2.1404174466927848

Epoch: 5| Step: 6
Training loss: 1.760743498802185
Validation loss: 2.114003300666809

Epoch: 5| Step: 7
Training loss: 1.6544158458709717
Validation loss: 2.1154537896315255

Epoch: 5| Step: 8
Training loss: 1.9864553213119507
Validation loss: 2.1214491526285806

Epoch: 5| Step: 9
Training loss: 1.4465841054916382
Validation loss: 2.135567511121432

Epoch: 5| Step: 10
Training loss: 1.3432894945144653
Validation loss: 2.1314334919055304

Epoch: 5| Step: 11
Training loss: 1.0608174800872803
Validation loss: 2.10580504933993

Epoch: 283| Step: 0
Training loss: 1.4775065183639526
Validation loss: 2.1172157476345697

Epoch: 5| Step: 1
Training loss: 1.6843093633651733
Validation loss: 2.12262428800265

Epoch: 5| Step: 2
Training loss: 2.154034376144409
Validation loss: 2.1521337578694024

Epoch: 5| Step: 3
Training loss: 1.7755056619644165
Validation loss: 2.1201030214627585

Epoch: 5| Step: 4
Training loss: 2.0489938259124756
Validation loss: 2.153191556533178

Epoch: 5| Step: 5
Training loss: 1.9202566146850586
Validation loss: 2.148254543542862

Epoch: 5| Step: 6
Training loss: 1.5300285816192627
Validation loss: 2.161488781372706

Epoch: 5| Step: 7
Training loss: 1.670851707458496
Validation loss: 2.162215838829676

Epoch: 5| Step: 8
Training loss: 2.431065082550049
Validation loss: 2.1851151088873544

Epoch: 5| Step: 9
Training loss: 1.5349422693252563
Validation loss: 2.1553766429424286

Epoch: 5| Step: 10
Training loss: 2.036862850189209
Validation loss: 2.1543072760105133

Epoch: 5| Step: 11
Training loss: 1.6790003776550293
Validation loss: 2.154060661792755

Epoch: 284| Step: 0
Training loss: 1.6560423374176025
Validation loss: 2.1341277956962585

Epoch: 5| Step: 1
Training loss: 2.4085164070129395
Validation loss: 2.138120556871096

Epoch: 5| Step: 2
Training loss: 2.17265248298645
Validation loss: 2.135553946097692

Epoch: 5| Step: 3
Training loss: 1.9743115901947021
Validation loss: 2.1222754567861557

Epoch: 5| Step: 4
Training loss: 1.8936961889266968
Validation loss: 2.1323041915893555

Epoch: 5| Step: 5
Training loss: 1.2416915893554688
Validation loss: 2.1197242538134256

Epoch: 5| Step: 6
Training loss: 1.723041296005249
Validation loss: 2.1237400422493615

Epoch: 5| Step: 7
Training loss: 1.629783272743225
Validation loss: 2.137621601422628

Epoch: 5| Step: 8
Training loss: 2.0192618370056152
Validation loss: 2.119724929332733

Epoch: 5| Step: 9
Training loss: 1.4617483615875244
Validation loss: 2.1434852182865143

Epoch: 5| Step: 10
Training loss: 1.9774672985076904
Validation loss: 2.1456780234972634

Epoch: 5| Step: 11
Training loss: 2.017214298248291
Validation loss: 2.149636467297872

Epoch: 285| Step: 0
Training loss: 1.3022643327713013
Validation loss: 2.126528744896253

Epoch: 5| Step: 1
Training loss: 2.0240349769592285
Validation loss: 2.122608413298925

Epoch: 5| Step: 2
Training loss: 1.489981770515442
Validation loss: 2.1498347570498786

Epoch: 5| Step: 3
Training loss: 1.9701166152954102
Validation loss: 2.153287872672081

Epoch: 5| Step: 4
Training loss: 1.8424711227416992
Validation loss: 2.1349893659353256

Epoch: 5| Step: 5
Training loss: 1.3039358854293823
Validation loss: 2.143287936846415

Epoch: 5| Step: 6
Training loss: 2.36190128326416
Validation loss: 2.1176889538764954

Epoch: 5| Step: 7
Training loss: 1.744873046875
Validation loss: 2.1431479454040527

Epoch: 5| Step: 8
Training loss: 1.6015031337738037
Validation loss: 2.137002860506376

Epoch: 5| Step: 9
Training loss: 2.780749559402466
Validation loss: 2.126717338959376

Epoch: 5| Step: 10
Training loss: 1.6365225315093994
Validation loss: 2.148293048143387

Epoch: 5| Step: 11
Training loss: 0.7675984501838684
Validation loss: 2.1275514662265778

Epoch: 286| Step: 0
Training loss: 1.61589777469635
Validation loss: 2.1355977952480316

Epoch: 5| Step: 1
Training loss: 2.4735710620880127
Validation loss: 2.168107902010282

Epoch: 5| Step: 2
Training loss: 1.4827477931976318
Validation loss: 2.1748611281315484

Epoch: 5| Step: 3
Training loss: 1.5635730028152466
Validation loss: 2.1796622474988303

Epoch: 5| Step: 4
Training loss: 1.9246858358383179
Validation loss: 2.1826379050811133

Epoch: 5| Step: 5
Training loss: 1.6877048015594482
Validation loss: 2.160017122824987

Epoch: 5| Step: 6
Training loss: 1.610729455947876
Validation loss: 2.1675498137871423

Epoch: 5| Step: 7
Training loss: 1.871720552444458
Validation loss: 2.1418500393629074

Epoch: 5| Step: 8
Training loss: 1.8201382160186768
Validation loss: 2.1327728430430093

Epoch: 5| Step: 9
Training loss: 1.6706291437149048
Validation loss: 2.134519745906194

Epoch: 5| Step: 10
Training loss: 2.3324084281921387
Validation loss: 2.1179445137580237

Epoch: 5| Step: 11
Training loss: 2.415654182434082
Validation loss: 2.1364117612441382

Epoch: 287| Step: 0
Training loss: 1.883338212966919
Validation loss: 2.1309256305297217

Epoch: 5| Step: 1
Training loss: 1.2179062366485596
Validation loss: 2.1468466917673745

Epoch: 5| Step: 2
Training loss: 1.2547948360443115
Validation loss: 2.132154514392217

Epoch: 5| Step: 3
Training loss: 1.4995328187942505
Validation loss: 2.125913143157959

Epoch: 5| Step: 4
Training loss: 2.3149807453155518
Validation loss: 2.143527696530024

Epoch: 5| Step: 5
Training loss: 2.091979742050171
Validation loss: 2.124298413594564

Epoch: 5| Step: 6
Training loss: 1.6905301809310913
Validation loss: 2.150946721434593

Epoch: 5| Step: 7
Training loss: 1.8304550647735596
Validation loss: 2.15374888976415

Epoch: 5| Step: 8
Training loss: 1.4139384031295776
Validation loss: 2.121515522400538

Epoch: 5| Step: 9
Training loss: 2.8141591548919678
Validation loss: 2.1567008594671884

Epoch: 5| Step: 10
Training loss: 1.950901746749878
Validation loss: 2.1427518328030906

Epoch: 5| Step: 11
Training loss: 1.7893990278244019
Validation loss: 2.128901412089666

Epoch: 288| Step: 0
Training loss: 2.116637706756592
Validation loss: 2.1303097108999887

Epoch: 5| Step: 1
Training loss: 1.882075309753418
Validation loss: 2.1204604456822076

Epoch: 5| Step: 2
Training loss: 1.610438346862793
Validation loss: 2.124229778846105

Epoch: 5| Step: 3
Training loss: 1.45330011844635
Validation loss: 2.126693914333979

Epoch: 5| Step: 4
Training loss: 1.9333412647247314
Validation loss: 2.1600137849648795

Epoch: 5| Step: 5
Training loss: 2.262389659881592
Validation loss: 2.1361643026272454

Epoch: 5| Step: 6
Training loss: 1.5161263942718506
Validation loss: 2.1327397574981055

Epoch: 5| Step: 7
Training loss: 1.789124846458435
Validation loss: 2.158411353826523

Epoch: 5| Step: 8
Training loss: 1.8744933605194092
Validation loss: 2.147765894730886

Epoch: 5| Step: 9
Training loss: 1.6259078979492188
Validation loss: 2.142487575610479

Epoch: 5| Step: 10
Training loss: 1.8356786966323853
Validation loss: 2.1525747577349343

Epoch: 5| Step: 11
Training loss: 2.4160757064819336
Validation loss: 2.165640562772751

Epoch: 289| Step: 0
Training loss: 1.816424012184143
Validation loss: 2.154827356338501

Epoch: 5| Step: 1
Training loss: 2.6273391246795654
Validation loss: 2.1605634490648904

Epoch: 5| Step: 2
Training loss: 1.857718825340271
Validation loss: 2.1458729058504105

Epoch: 5| Step: 3
Training loss: 2.0051472187042236
Validation loss: 2.1734063774347305

Epoch: 5| Step: 4
Training loss: 1.8384723663330078
Validation loss: 2.1708081463972726

Epoch: 5| Step: 5
Training loss: 1.3798567056655884
Validation loss: 2.189451903104782

Epoch: 5| Step: 6
Training loss: 1.278995156288147
Validation loss: 2.1782313932975135

Epoch: 5| Step: 7
Training loss: 1.513092041015625
Validation loss: 2.1394513050715127

Epoch: 5| Step: 8
Training loss: 1.5325260162353516
Validation loss: 2.1544164419174194

Epoch: 5| Step: 9
Training loss: 1.8142755031585693
Validation loss: 2.1440058847268424

Epoch: 5| Step: 10
Training loss: 2.251488208770752
Validation loss: 2.124514271815618

Epoch: 5| Step: 11
Training loss: 2.839639902114868
Validation loss: 2.1440970251957574

Epoch: 290| Step: 0
Training loss: 2.7675929069519043
Validation loss: 2.130408306916555

Epoch: 5| Step: 1
Training loss: 1.263946294784546
Validation loss: 2.1239890406529107

Epoch: 5| Step: 2
Training loss: 1.8430681228637695
Validation loss: 2.110122337937355

Epoch: 5| Step: 3
Training loss: 1.4261394739151
Validation loss: 2.1198692520459494

Epoch: 5| Step: 4
Training loss: 1.8410907983779907
Validation loss: 2.1174573997656503

Epoch: 5| Step: 5
Training loss: 1.4596238136291504
Validation loss: 2.124371533592542

Epoch: 5| Step: 6
Training loss: 1.97344970703125
Validation loss: 2.1090126981337867

Epoch: 5| Step: 7
Training loss: 1.655853033065796
Validation loss: 2.134485219915708

Epoch: 5| Step: 8
Training loss: 1.9716460704803467
Validation loss: 2.1411633590857186

Epoch: 5| Step: 9
Training loss: 1.3033068180084229
Validation loss: 2.133578131596247

Epoch: 5| Step: 10
Training loss: 2.390866756439209
Validation loss: 2.114687755703926

Epoch: 5| Step: 11
Training loss: 1.9154435396194458
Validation loss: 2.138350327809652

Epoch: 291| Step: 0
Training loss: 1.7694091796875
Validation loss: 2.1611080865065255

Epoch: 5| Step: 1
Training loss: 2.1699280738830566
Validation loss: 2.169519672791163

Epoch: 5| Step: 2
Training loss: 1.686852216720581
Validation loss: 2.1499561965465546

Epoch: 5| Step: 3
Training loss: 1.8599853515625
Validation loss: 2.1212579905986786

Epoch: 5| Step: 4
Training loss: 1.646411657333374
Validation loss: 2.1260442982117334

Epoch: 5| Step: 5
Training loss: 1.980060338973999
Validation loss: 2.11601622402668

Epoch: 5| Step: 6
Training loss: 1.4155710935592651
Validation loss: 2.1215555717547736

Epoch: 5| Step: 7
Training loss: 1.4770066738128662
Validation loss: 2.1292812128861747

Epoch: 5| Step: 8
Training loss: 1.7088079452514648
Validation loss: 2.1009381711483

Epoch: 5| Step: 9
Training loss: 2.254976987838745
Validation loss: 2.125553468863169

Epoch: 5| Step: 10
Training loss: 1.8972002267837524
Validation loss: 2.1356817930936813

Epoch: 5| Step: 11
Training loss: 3.1907858848571777
Validation loss: 2.099114735921224

Epoch: 292| Step: 0
Training loss: 1.93235182762146
Validation loss: 2.1149007827043533

Epoch: 5| Step: 1
Training loss: 1.6437530517578125
Validation loss: 2.1235981633265815

Epoch: 5| Step: 2
Training loss: 2.458632230758667
Validation loss: 2.117250179251035

Epoch: 5| Step: 3
Training loss: 1.949191689491272
Validation loss: 2.11283448835214

Epoch: 5| Step: 4
Training loss: 2.0642929077148438
Validation loss: 2.1228896578152976

Epoch: 5| Step: 5
Training loss: 1.7445417642593384
Validation loss: 2.1083886424700418

Epoch: 5| Step: 6
Training loss: 1.675347089767456
Validation loss: 2.136197636524836

Epoch: 5| Step: 7
Training loss: 1.534307837486267
Validation loss: 2.1494811872641244

Epoch: 5| Step: 8
Training loss: 1.4309742450714111
Validation loss: 2.1397478580474854

Epoch: 5| Step: 9
Training loss: 1.6482837200164795
Validation loss: 2.160510485370954

Epoch: 5| Step: 10
Training loss: 1.8092873096466064
Validation loss: 2.136401116847992

Epoch: 5| Step: 11
Training loss: 1.9028475284576416
Validation loss: 2.154653400182724

Epoch: 293| Step: 0
Training loss: 1.9629300832748413
Validation loss: 2.1562604755163193

Epoch: 5| Step: 1
Training loss: 1.1846120357513428
Validation loss: 2.1170892814795175

Epoch: 5| Step: 2
Training loss: 1.7706634998321533
Validation loss: 2.1567784249782562

Epoch: 5| Step: 3
Training loss: 2.141864061355591
Validation loss: 2.124280278881391

Epoch: 5| Step: 4
Training loss: 1.4691126346588135
Validation loss: 2.1388381322224936

Epoch: 5| Step: 5
Training loss: 1.8320930004119873
Validation loss: 2.1140240728855133

Epoch: 5| Step: 6
Training loss: 1.542319655418396
Validation loss: 2.1312970370054245

Epoch: 5| Step: 7
Training loss: 1.7613462209701538
Validation loss: 2.119514614343643

Epoch: 5| Step: 8
Training loss: 2.5989620685577393
Validation loss: 2.132382944226265

Epoch: 5| Step: 9
Training loss: 1.5197227001190186
Validation loss: 2.125092645486196

Epoch: 5| Step: 10
Training loss: 2.051896333694458
Validation loss: 2.123807370662689

Epoch: 5| Step: 11
Training loss: 3.8162240982055664
Validation loss: 2.1323315451542535

Epoch: 294| Step: 0
Training loss: 1.8068612813949585
Validation loss: 2.1434250871340432

Epoch: 5| Step: 1
Training loss: 1.5572869777679443
Validation loss: 2.1583493997653327

Epoch: 5| Step: 2
Training loss: 1.953210473060608
Validation loss: 2.140400677919388

Epoch: 5| Step: 3
Training loss: 1.362298607826233
Validation loss: 2.1617099791765213

Epoch: 5| Step: 4
Training loss: 2.1289570331573486
Validation loss: 2.1319621900717416

Epoch: 5| Step: 5
Training loss: 1.8681144714355469
Validation loss: 2.1217731485764184

Epoch: 5| Step: 6
Training loss: 2.0390169620513916
Validation loss: 2.1320734272400537

Epoch: 5| Step: 7
Training loss: 2.5032758712768555
Validation loss: 2.1170606215794883

Epoch: 5| Step: 8
Training loss: 1.3654638528823853
Validation loss: 2.1589199900627136

Epoch: 5| Step: 9
Training loss: 1.8078477382659912
Validation loss: 2.1407317568858466

Epoch: 5| Step: 10
Training loss: 1.543196678161621
Validation loss: 2.1248261680205665

Epoch: 5| Step: 11
Training loss: 1.7398903369903564
Validation loss: 2.13881483177344

Epoch: 295| Step: 0
Training loss: 1.6095342636108398
Validation loss: 2.141507565975189

Epoch: 5| Step: 1
Training loss: 1.980860710144043
Validation loss: 2.1841617623964944

Epoch: 5| Step: 2
Training loss: 1.8253822326660156
Validation loss: 2.150581826766332

Epoch: 5| Step: 3
Training loss: 1.7727940082550049
Validation loss: 2.1884255359570184

Epoch: 5| Step: 4
Training loss: 2.408299684524536
Validation loss: 2.1938694765170417

Epoch: 5| Step: 5
Training loss: 1.9708373546600342
Validation loss: 2.182481045524279

Epoch: 5| Step: 6
Training loss: 2.337376832962036
Validation loss: 2.171694735685984

Epoch: 5| Step: 7
Training loss: 1.4546009302139282
Validation loss: 2.138624668121338

Epoch: 5| Step: 8
Training loss: 1.4716312885284424
Validation loss: 2.1550278613964715

Epoch: 5| Step: 9
Training loss: 1.52821946144104
Validation loss: 2.1605613231658936

Epoch: 5| Step: 10
Training loss: 1.6985867023468018
Validation loss: 2.1059973339239755

Epoch: 5| Step: 11
Training loss: 1.617347002029419
Validation loss: 2.1240305602550507

Epoch: 296| Step: 0
Training loss: 2.309075355529785
Validation loss: 2.106196254491806

Epoch: 5| Step: 1
Training loss: 1.1866382360458374
Validation loss: 2.092506617307663

Epoch: 5| Step: 2
Training loss: 1.6428931951522827
Validation loss: 2.108325774470965

Epoch: 5| Step: 3
Training loss: 2.0879666805267334
Validation loss: 2.1079197227954865

Epoch: 5| Step: 4
Training loss: 1.7557001113891602
Validation loss: 2.113229056199392

Epoch: 5| Step: 5
Training loss: 1.8885242938995361
Validation loss: 2.1137050737937293

Epoch: 5| Step: 6
Training loss: 1.927909255027771
Validation loss: 2.1325656175613403

Epoch: 5| Step: 7
Training loss: 1.749027967453003
Validation loss: 2.1230954229831696

Epoch: 5| Step: 8
Training loss: 1.700035810470581
Validation loss: 2.157368009289106

Epoch: 5| Step: 9
Training loss: 2.794252872467041
Validation loss: 2.1300404320160546

Epoch: 5| Step: 10
Training loss: 1.8095653057098389
Validation loss: 2.1409316658973694

Epoch: 5| Step: 11
Training loss: 0.9597337245941162
Validation loss: 2.1451527376969657

Epoch: 297| Step: 0
Training loss: 2.0926930904388428
Validation loss: 2.182377576828003

Epoch: 5| Step: 1
Training loss: 1.7218618392944336
Validation loss: 2.176420196890831

Epoch: 5| Step: 2
Training loss: 1.629451036453247
Validation loss: 2.1910309543212256

Epoch: 5| Step: 3
Training loss: 1.856217622756958
Validation loss: 2.1849603354930878

Epoch: 5| Step: 4
Training loss: 1.5277901887893677
Validation loss: 2.2027898083130517

Epoch: 5| Step: 5
Training loss: 2.073460817337036
Validation loss: 2.1830804298321405

Epoch: 5| Step: 6
Training loss: 2.013824939727783
Validation loss: 2.1515773634115853

Epoch: 5| Step: 7
Training loss: 2.231679916381836
Validation loss: 2.1344239562749863

Epoch: 5| Step: 8
Training loss: 1.4659230709075928
Validation loss: 2.1276394724845886

Epoch: 5| Step: 9
Training loss: 1.810032606124878
Validation loss: 2.1229254802068076

Epoch: 5| Step: 10
Training loss: 1.5111294984817505
Validation loss: 2.1266677578290305

Epoch: 5| Step: 11
Training loss: 2.824112892150879
Validation loss: 2.1190242369969687

Epoch: 298| Step: 0
Training loss: 2.0326061248779297
Validation loss: 2.130186975002289

Epoch: 5| Step: 1
Training loss: 1.774510145187378
Validation loss: 2.1094781309366226

Epoch: 5| Step: 2
Training loss: 1.9181926250457764
Validation loss: 2.132416541377703

Epoch: 5| Step: 3
Training loss: 1.7681691646575928
Validation loss: 2.122158403197924

Epoch: 5| Step: 4
Training loss: 1.9687252044677734
Validation loss: 2.1242185533046722

Epoch: 5| Step: 5
Training loss: 1.6098144054412842
Validation loss: 2.1291304528713226

Epoch: 5| Step: 6
Training loss: 1.6433258056640625
Validation loss: 2.1300023247798285

Epoch: 5| Step: 7
Training loss: 1.6905244588851929
Validation loss: 2.134084403514862

Epoch: 5| Step: 8
Training loss: 1.4299468994140625
Validation loss: 2.1751961509386697

Epoch: 5| Step: 9
Training loss: 1.452148675918579
Validation loss: 2.171765764554342

Epoch: 5| Step: 10
Training loss: 3.2863926887512207
Validation loss: 2.2221098244190216

Epoch: 5| Step: 11
Training loss: 2.172750949859619
Validation loss: 2.253896713256836

Epoch: 299| Step: 0
Training loss: 1.7545335292816162
Validation loss: 2.205275764067968

Epoch: 5| Step: 1
Training loss: 1.893472671508789
Validation loss: 2.1896375914414725

Epoch: 5| Step: 2
Training loss: 1.7129557132720947
Validation loss: 2.1621903081734977

Epoch: 5| Step: 3
Training loss: 1.7921688556671143
Validation loss: 2.1488283475240073

Epoch: 5| Step: 4
Training loss: 1.3731451034545898
Validation loss: 2.157953828573227

Epoch: 5| Step: 5
Training loss: 2.0190234184265137
Validation loss: 2.1681185364723206

Epoch: 5| Step: 6
Training loss: 2.2454869747161865
Validation loss: 2.1495384921630225

Epoch: 5| Step: 7
Training loss: 1.3201665878295898
Validation loss: 2.1698323289553323

Epoch: 5| Step: 8
Training loss: 1.783725380897522
Validation loss: 2.1247075150410333

Epoch: 5| Step: 9
Training loss: 1.9010528326034546
Validation loss: 2.1491804818312326

Epoch: 5| Step: 10
Training loss: 2.1542036533355713
Validation loss: 2.146144544084867

Epoch: 5| Step: 11
Training loss: 1.1161103248596191
Validation loss: 2.168647979696592

Epoch: 300| Step: 0
Training loss: 1.8017629384994507
Validation loss: 2.1646109769741693

Epoch: 5| Step: 1
Training loss: 1.629730224609375
Validation loss: 2.157990515232086

Epoch: 5| Step: 2
Training loss: 1.8704147338867188
Validation loss: 2.15842671195666

Epoch: 5| Step: 3
Training loss: 1.4166276454925537
Validation loss: 2.1640354494253793

Epoch: 5| Step: 4
Training loss: 1.5578855276107788
Validation loss: 2.164071629444758

Epoch: 5| Step: 5
Training loss: 1.8769108057022095
Validation loss: 2.142130563656489

Epoch: 5| Step: 6
Training loss: 1.5187437534332275
Validation loss: 2.16715573767821

Epoch: 5| Step: 7
Training loss: 1.6259517669677734
Validation loss: 2.1868678629398346

Epoch: 5| Step: 8
Training loss: 1.753588080406189
Validation loss: 2.159557114044825

Epoch: 5| Step: 9
Training loss: 2.0190348625183105
Validation loss: 2.1515926818052926

Epoch: 5| Step: 10
Training loss: 2.5372352600097656
Validation loss: 2.1444677213827767

Epoch: 5| Step: 11
Training loss: 2.462834358215332
Validation loss: 2.11606195072333

Epoch: 301| Step: 0
Training loss: 2.0750694274902344
Validation loss: 2.1269767582416534

Epoch: 5| Step: 1
Training loss: 1.9137840270996094
Validation loss: 2.117560848593712

Epoch: 5| Step: 2
Training loss: 1.6864547729492188
Validation loss: 2.1475810507933297

Epoch: 5| Step: 3
Training loss: 2.2665228843688965
Validation loss: 2.117659608523051

Epoch: 5| Step: 4
Training loss: 1.5368616580963135
Validation loss: 2.1157228648662567

Epoch: 5| Step: 5
Training loss: 1.7742490768432617
Validation loss: 2.1337935080130896

Epoch: 5| Step: 6
Training loss: 2.1145498752593994
Validation loss: 2.1287439664204917

Epoch: 5| Step: 7
Training loss: 1.5457260608673096
Validation loss: 2.143293191989263

Epoch: 5| Step: 8
Training loss: 1.534309983253479
Validation loss: 2.1427196760972342

Epoch: 5| Step: 9
Training loss: 1.5608489513397217
Validation loss: 2.171459063887596

Epoch: 5| Step: 10
Training loss: 2.057332754135132
Validation loss: 2.1315803478161492

Epoch: 5| Step: 11
Training loss: 1.115726351737976
Validation loss: 2.1492432157198587

Epoch: 302| Step: 0
Training loss: 1.529515266418457
Validation loss: 2.1572255641222

Epoch: 5| Step: 1
Training loss: 1.5791501998901367
Validation loss: 2.132438823580742

Epoch: 5| Step: 2
Training loss: 1.7622129917144775
Validation loss: 2.1392266899347305

Epoch: 5| Step: 3
Training loss: 2.3865010738372803
Validation loss: 2.1449135690927505

Epoch: 5| Step: 4
Training loss: 1.7995812892913818
Validation loss: 2.1253940165042877

Epoch: 5| Step: 5
Training loss: 1.6913948059082031
Validation loss: 2.1150006701548896

Epoch: 5| Step: 6
Training loss: 1.9309704303741455
Validation loss: 2.139599238832792

Epoch: 5| Step: 7
Training loss: 1.7222092151641846
Validation loss: 2.1266383280356727

Epoch: 5| Step: 8
Training loss: 1.579601764678955
Validation loss: 2.142030730843544

Epoch: 5| Step: 9
Training loss: 1.8304647207260132
Validation loss: 2.117506355047226

Epoch: 5| Step: 10
Training loss: 1.944546103477478
Validation loss: 2.155715594689051

Epoch: 5| Step: 11
Training loss: 1.3216485977172852
Validation loss: 2.1523157954216003

Epoch: 303| Step: 0
Training loss: 2.133291482925415
Validation loss: 2.17346420387427

Epoch: 5| Step: 1
Training loss: 2.2822957038879395
Validation loss: 2.1739721596240997

Epoch: 5| Step: 2
Training loss: 1.7378160953521729
Validation loss: 2.1532679200172424

Epoch: 5| Step: 3
Training loss: 2.2071304321289062
Validation loss: 2.1305059045553207

Epoch: 5| Step: 4
Training loss: 1.503781795501709
Validation loss: 2.1286922295888266

Epoch: 5| Step: 5
Training loss: 1.7183105945587158
Validation loss: 2.1173778772354126

Epoch: 5| Step: 6
Training loss: 1.3825286626815796
Validation loss: 2.112161492307981

Epoch: 5| Step: 7
Training loss: 1.4681169986724854
Validation loss: 2.1133051017920175

Epoch: 5| Step: 8
Training loss: 1.5787162780761719
Validation loss: 2.129011188944181

Epoch: 5| Step: 9
Training loss: 1.7999327182769775
Validation loss: 2.125501255194346

Epoch: 5| Step: 10
Training loss: 2.231553554534912
Validation loss: 2.1207367132107415

Epoch: 5| Step: 11
Training loss: 1.7389980554580688
Validation loss: 2.118708153565725

Epoch: 304| Step: 0
Training loss: 1.9028701782226562
Validation loss: 2.098549668987592

Epoch: 5| Step: 1
Training loss: 2.8520302772521973
Validation loss: 2.113631467024485

Epoch: 5| Step: 2
Training loss: 1.69790780544281
Validation loss: 2.1327291429042816

Epoch: 5| Step: 3
Training loss: 1.1719690561294556
Validation loss: 2.140933101375898

Epoch: 5| Step: 4
Training loss: 1.7097184658050537
Validation loss: 2.1400946279366813

Epoch: 5| Step: 5
Training loss: 1.656209945678711
Validation loss: 2.128870685895284

Epoch: 5| Step: 6
Training loss: 2.238431930541992
Validation loss: 2.1648536870876947

Epoch: 5| Step: 7
Training loss: 1.6961570978164673
Validation loss: 2.1745556543270745

Epoch: 5| Step: 8
Training loss: 1.7002512216567993
Validation loss: 2.176293507218361

Epoch: 5| Step: 9
Training loss: 2.1189208030700684
Validation loss: 2.1856383979320526

Epoch: 5| Step: 10
Training loss: 1.3618171215057373
Validation loss: 2.1953786114851632

Epoch: 5| Step: 11
Training loss: 0.5299610495567322
Validation loss: 2.183916380008062

Epoch: 305| Step: 0
Training loss: 1.7182859182357788
Validation loss: 2.1703011840581894

Epoch: 5| Step: 1
Training loss: 1.726381540298462
Validation loss: 2.173031027118365

Epoch: 5| Step: 2
Training loss: 1.7150795459747314
Validation loss: 2.1799970467885337

Epoch: 5| Step: 3
Training loss: 1.9291915893554688
Validation loss: 2.154658089081446

Epoch: 5| Step: 4
Training loss: 1.0913727283477783
Validation loss: 2.1553057432174683

Epoch: 5| Step: 5
Training loss: 1.8708572387695312
Validation loss: 2.1493595242500305

Epoch: 5| Step: 6
Training loss: 1.7251046895980835
Validation loss: 2.1391034921010337

Epoch: 5| Step: 7
Training loss: 2.5434963703155518
Validation loss: 2.1407246043284736

Epoch: 5| Step: 8
Training loss: 2.182748317718506
Validation loss: 2.1455116868019104

Epoch: 5| Step: 9
Training loss: 1.3934131860733032
Validation loss: 2.1362970620393753

Epoch: 5| Step: 10
Training loss: 1.9766700267791748
Validation loss: 2.1216761072476706

Epoch: 5| Step: 11
Training loss: 0.8134133219718933
Validation loss: 2.1320168673992157

Epoch: 306| Step: 0
Training loss: 1.8554435968399048
Validation loss: 2.161389941970507

Epoch: 5| Step: 1
Training loss: 1.2862221002578735
Validation loss: 2.161723628640175

Epoch: 5| Step: 2
Training loss: 2.1487700939178467
Validation loss: 2.202009732524554

Epoch: 5| Step: 3
Training loss: 2.0572493076324463
Validation loss: 2.2354467809200287

Epoch: 5| Step: 4
Training loss: 1.5965194702148438
Validation loss: 2.2237857580184937

Epoch: 5| Step: 5
Training loss: 1.911169409751892
Validation loss: 2.2460141678651175

Epoch: 5| Step: 6
Training loss: 2.2349677085876465
Validation loss: 2.2434794108072915

Epoch: 5| Step: 7
Training loss: 1.6149539947509766
Validation loss: 2.244465947151184

Epoch: 5| Step: 8
Training loss: 1.4105665683746338
Validation loss: 2.2219011882940927

Epoch: 5| Step: 9
Training loss: 1.7164331674575806
Validation loss: 2.193445473909378

Epoch: 5| Step: 10
Training loss: 2.0842182636260986
Validation loss: 2.1726395189762115

Epoch: 5| Step: 11
Training loss: 2.424156665802002
Validation loss: 2.145676319797834

Epoch: 307| Step: 0
Training loss: 1.9503707885742188
Validation loss: 2.1591954678297043

Epoch: 5| Step: 1
Training loss: 1.9528758525848389
Validation loss: 2.158201644817988

Epoch: 5| Step: 2
Training loss: 1.6353060007095337
Validation loss: 2.152160882949829

Epoch: 5| Step: 3
Training loss: 2.425072431564331
Validation loss: 2.144172196586927

Epoch: 5| Step: 4
Training loss: 2.1654534339904785
Validation loss: 2.141028121113777

Epoch: 5| Step: 5
Training loss: 1.2256085872650146
Validation loss: 2.1775017380714417

Epoch: 5| Step: 6
Training loss: 1.5579261779785156
Validation loss: 2.161018505692482

Epoch: 5| Step: 7
Training loss: 2.128526210784912
Validation loss: 2.1572220573822656

Epoch: 5| Step: 8
Training loss: 1.925523042678833
Validation loss: 2.181747406721115

Epoch: 5| Step: 9
Training loss: 1.2512996196746826
Validation loss: 2.172212094068527

Epoch: 5| Step: 10
Training loss: 1.764601469039917
Validation loss: 2.1486366242170334

Epoch: 5| Step: 11
Training loss: 1.435080885887146
Validation loss: 2.188133458296458

Epoch: 308| Step: 0
Training loss: 1.596441626548767
Validation loss: 2.2183412512143454

Epoch: 5| Step: 1
Training loss: 2.141282796859741
Validation loss: 2.2308409412701926

Epoch: 5| Step: 2
Training loss: 2.0067341327667236
Validation loss: 2.250275323788325

Epoch: 5| Step: 3
Training loss: 1.5997331142425537
Validation loss: 2.2373705307642617

Epoch: 5| Step: 4
Training loss: 2.168283224105835
Validation loss: 2.204096575578054

Epoch: 5| Step: 5
Training loss: 2.2373368740081787
Validation loss: 2.2129188776016235

Epoch: 5| Step: 6
Training loss: 1.5583970546722412
Validation loss: 2.163247396548589

Epoch: 5| Step: 7
Training loss: 2.101897716522217
Validation loss: 2.1663751006126404

Epoch: 5| Step: 8
Training loss: 1.5440785884857178
Validation loss: 2.142749081055323

Epoch: 5| Step: 9
Training loss: 1.6424310207366943
Validation loss: 2.1702979654073715

Epoch: 5| Step: 10
Training loss: 1.6793889999389648
Validation loss: 2.156916379928589

Epoch: 5| Step: 11
Training loss: 1.4108697175979614
Validation loss: 2.1522882729768753

Epoch: 309| Step: 0
Training loss: 1.1509287357330322
Validation loss: 2.148412456115087

Epoch: 5| Step: 1
Training loss: 2.0578877925872803
Validation loss: 2.1646437446276345

Epoch: 5| Step: 2
Training loss: 1.389796257019043
Validation loss: 2.165966177980105

Epoch: 5| Step: 3
Training loss: 2.304772138595581
Validation loss: 2.176830048362414

Epoch: 5| Step: 4
Training loss: 1.7397390604019165
Validation loss: 2.173476055264473

Epoch: 5| Step: 5
Training loss: 1.5309382677078247
Validation loss: 2.1922243734200797

Epoch: 5| Step: 6
Training loss: 1.5497092008590698
Validation loss: 2.219875087340673

Epoch: 5| Step: 7
Training loss: 1.4852359294891357
Validation loss: 2.1752415845791497

Epoch: 5| Step: 8
Training loss: 2.115116596221924
Validation loss: 2.184514661629995

Epoch: 5| Step: 9
Training loss: 1.9939342737197876
Validation loss: 2.2148420015970864

Epoch: 5| Step: 10
Training loss: 2.596196413040161
Validation loss: 2.1784762342770896

Epoch: 5| Step: 11
Training loss: 1.859794020652771
Validation loss: 2.1964006821314492

Epoch: 310| Step: 0
Training loss: 1.6472622156143188
Validation loss: 2.1739783386389413

Epoch: 5| Step: 1
Training loss: 1.5038862228393555
Validation loss: 2.16605181992054

Epoch: 5| Step: 2
Training loss: 1.8283050060272217
Validation loss: 2.160022407770157

Epoch: 5| Step: 3
Training loss: 1.5706430673599243
Validation loss: 2.137763634324074

Epoch: 5| Step: 4
Training loss: 1.910495400428772
Validation loss: 2.1358974824349084

Epoch: 5| Step: 5
Training loss: 1.9758808612823486
Validation loss: 2.1236964960892997

Epoch: 5| Step: 6
Training loss: 2.122751474380493
Validation loss: 2.133983547488848

Epoch: 5| Step: 7
Training loss: 2.0943245887756348
Validation loss: 2.1279287189245224

Epoch: 5| Step: 8
Training loss: 2.5195746421813965
Validation loss: 2.1244344462951026

Epoch: 5| Step: 9
Training loss: 1.3581550121307373
Validation loss: 2.1303997337818146

Epoch: 5| Step: 10
Training loss: 1.9822139739990234
Validation loss: 2.148624395330747

Epoch: 5| Step: 11
Training loss: 1.183377742767334
Validation loss: 2.148147394259771

Epoch: 311| Step: 0
Training loss: 1.8952592611312866
Validation loss: 2.1793995996316275

Epoch: 5| Step: 1
Training loss: 2.3470067977905273
Validation loss: 2.184528777996699

Epoch: 5| Step: 2
Training loss: 2.182180404663086
Validation loss: 2.2295836905638375

Epoch: 5| Step: 3
Training loss: 2.132744312286377
Validation loss: 2.234440098206202

Epoch: 5| Step: 4
Training loss: 1.950142502784729
Validation loss: 2.1955513656139374

Epoch: 5| Step: 5
Training loss: 1.8956193923950195
Validation loss: 2.153934439023336

Epoch: 5| Step: 6
Training loss: 1.695809006690979
Validation loss: 2.1380702952543893

Epoch: 5| Step: 7
Training loss: 1.5383245944976807
Validation loss: 2.141233578324318

Epoch: 5| Step: 8
Training loss: 1.5564327239990234
Validation loss: 2.1076203932364783

Epoch: 5| Step: 9
Training loss: 1.6245887279510498
Validation loss: 2.1232147812843323

Epoch: 5| Step: 10
Training loss: 1.522531270980835
Validation loss: 2.1022111574808755

Epoch: 5| Step: 11
Training loss: 2.312610626220703
Validation loss: 2.1152850141127906

Epoch: 312| Step: 0
Training loss: 1.8472826480865479
Validation loss: 2.098718916376432

Epoch: 5| Step: 1
Training loss: 2.4128317832946777
Validation loss: 2.085153420766195

Epoch: 5| Step: 2
Training loss: 1.460322380065918
Validation loss: 2.0731267978747687

Epoch: 5| Step: 3
Training loss: 2.0146055221557617
Validation loss: 2.073920890688896

Epoch: 5| Step: 4
Training loss: 1.943933129310608
Validation loss: 2.0761280755201974

Epoch: 5| Step: 5
Training loss: 1.6956199407577515
Validation loss: 2.076519841949145

Epoch: 5| Step: 6
Training loss: 2.0398404598236084
Validation loss: 2.0629191348950067

Epoch: 5| Step: 7
Training loss: 1.5300405025482178
Validation loss: 2.0938347379366555

Epoch: 5| Step: 8
Training loss: 1.4543721675872803
Validation loss: 2.090753674507141

Epoch: 5| Step: 9
Training loss: 1.8759644031524658
Validation loss: 2.090893824895223

Epoch: 5| Step: 10
Training loss: 1.9350475072860718
Validation loss: 2.1024390757083893

Epoch: 5| Step: 11
Training loss: 2.2858726978302
Validation loss: 2.128319804867109

Epoch: 313| Step: 0
Training loss: 1.9037320613861084
Validation loss: 2.137413521607717

Epoch: 5| Step: 1
Training loss: 2.21429705619812
Validation loss: 2.141849716504415

Epoch: 5| Step: 2
Training loss: 1.219558596611023
Validation loss: 2.1612119376659393

Epoch: 5| Step: 3
Training loss: 2.3534388542175293
Validation loss: 2.1677520324786506

Epoch: 5| Step: 4
Training loss: 1.8197740316390991
Validation loss: 2.1670112311840057

Epoch: 5| Step: 5
Training loss: 1.9473540782928467
Validation loss: 2.1411632895469666

Epoch: 5| Step: 6
Training loss: 1.515832543373108
Validation loss: 2.1212191780408225

Epoch: 5| Step: 7
Training loss: 1.4837652444839478
Validation loss: 2.1387591461340585

Epoch: 5| Step: 8
Training loss: 2.432558059692383
Validation loss: 2.1544574151436486

Epoch: 5| Step: 9
Training loss: 1.080847978591919
Validation loss: 2.1331736544768014

Epoch: 5| Step: 10
Training loss: 1.542024850845337
Validation loss: 2.1548526734113693

Epoch: 5| Step: 11
Training loss: 2.7552428245544434
Validation loss: 2.1525219629208245

Epoch: 314| Step: 0
Training loss: 1.6842018365859985
Validation loss: 2.143267144759496

Epoch: 5| Step: 1
Training loss: 1.7255802154541016
Validation loss: 2.1532759815454483

Epoch: 5| Step: 2
Training loss: 1.8759815692901611
Validation loss: 2.1739299595355988

Epoch: 5| Step: 3
Training loss: 1.8698787689208984
Validation loss: 2.180583049853643

Epoch: 5| Step: 4
Training loss: 1.5560895204544067
Validation loss: 2.168124188979467

Epoch: 5| Step: 5
Training loss: 1.7209638357162476
Validation loss: 2.16718161602815

Epoch: 5| Step: 6
Training loss: 1.65505850315094
Validation loss: 2.189106434583664

Epoch: 5| Step: 7
Training loss: 1.7580692768096924
Validation loss: 2.1982463896274567

Epoch: 5| Step: 8
Training loss: 1.5799596309661865
Validation loss: 2.200727974375089

Epoch: 5| Step: 9
Training loss: 1.6342471837997437
Validation loss: 2.1775962660710015

Epoch: 5| Step: 10
Training loss: 1.8885225057601929
Validation loss: 2.1956255733966827

Epoch: 5| Step: 11
Training loss: 3.1557626724243164
Validation loss: 2.1749895364046097

Epoch: 315| Step: 0
Training loss: 2.1834826469421387
Validation loss: 2.211010977625847

Epoch: 5| Step: 1
Training loss: 1.6081244945526123
Validation loss: 2.179260770479838

Epoch: 5| Step: 2
Training loss: 2.126399040222168
Validation loss: 2.1844725906848907

Epoch: 5| Step: 3
Training loss: 1.7155187129974365
Validation loss: 2.183039257923762

Epoch: 5| Step: 4
Training loss: 1.8072502613067627
Validation loss: 2.1705356935660043

Epoch: 5| Step: 5
Training loss: 1.104223608970642
Validation loss: 2.1583012839158378

Epoch: 5| Step: 6
Training loss: 1.7348495721817017
Validation loss: 2.1763992458581924

Epoch: 5| Step: 7
Training loss: 1.4209206104278564
Validation loss: 2.172281414270401

Epoch: 5| Step: 8
Training loss: 1.8563333749771118
Validation loss: 2.191998541355133

Epoch: 5| Step: 9
Training loss: 1.3982408046722412
Validation loss: 2.187628149986267

Epoch: 5| Step: 10
Training loss: 1.8151195049285889
Validation loss: 2.1827868272860846

Epoch: 5| Step: 11
Training loss: 4.197167873382568
Validation loss: 2.183728665113449

Epoch: 316| Step: 0
Training loss: 2.0375163555145264
Validation loss: 2.2073210875193277

Epoch: 5| Step: 1
Training loss: 1.3030469417572021
Validation loss: 2.18899534145991

Epoch: 5| Step: 2
Training loss: 1.6875566244125366
Validation loss: 2.201914995908737

Epoch: 5| Step: 3
Training loss: 1.4796704053878784
Validation loss: 2.2542574803034463

Epoch: 5| Step: 4
Training loss: 1.3170814514160156
Validation loss: 2.2221267074346542

Epoch: 5| Step: 5
Training loss: 1.881609320640564
Validation loss: 2.2380420664946237

Epoch: 5| Step: 6
Training loss: 1.9614216089248657
Validation loss: 2.220446844895681

Epoch: 5| Step: 7
Training loss: 1.699861764907837
Validation loss: 2.1912534634272256

Epoch: 5| Step: 8
Training loss: 2.542891263961792
Validation loss: 2.1576051811377206

Epoch: 5| Step: 9
Training loss: 1.7230775356292725
Validation loss: 2.1638884097337723

Epoch: 5| Step: 10
Training loss: 2.0939714908599854
Validation loss: 2.1375870605309806

Epoch: 5| Step: 11
Training loss: 2.194592237472534
Validation loss: 2.147754301627477

Epoch: 317| Step: 0
Training loss: 1.6767733097076416
Validation loss: 2.1333049088716507

Epoch: 5| Step: 1
Training loss: 1.3611748218536377
Validation loss: 2.142965813477834

Epoch: 5| Step: 2
Training loss: 1.8480768203735352
Validation loss: 2.1283598641554513

Epoch: 5| Step: 3
Training loss: 2.236515522003174
Validation loss: 2.1240153163671494

Epoch: 5| Step: 4
Training loss: 1.7342323064804077
Validation loss: 2.1430606047312417

Epoch: 5| Step: 5
Training loss: 2.2011754512786865
Validation loss: 2.1546666771173477

Epoch: 5| Step: 6
Training loss: 2.0179169178009033
Validation loss: 2.15760201215744

Epoch: 5| Step: 7
Training loss: 1.6489629745483398
Validation loss: 2.1624661485354104

Epoch: 5| Step: 8
Training loss: 2.1081748008728027
Validation loss: 2.1730613708496094

Epoch: 5| Step: 9
Training loss: 1.4584882259368896
Validation loss: 2.1813004364569983

Epoch: 5| Step: 10
Training loss: 1.4532134532928467
Validation loss: 2.1798215160767236

Epoch: 5| Step: 11
Training loss: 2.684375762939453
Validation loss: 2.1873395095268884

Epoch: 318| Step: 0
Training loss: 1.5254682302474976
Validation loss: 2.19080742696921

Epoch: 5| Step: 1
Training loss: 1.5878407955169678
Validation loss: 2.1665766835212708

Epoch: 5| Step: 2
Training loss: 2.038567543029785
Validation loss: 2.172678912679354

Epoch: 5| Step: 3
Training loss: 1.95065176486969
Validation loss: 2.161876305937767

Epoch: 5| Step: 4
Training loss: 2.27862548828125
Validation loss: 2.159155786037445

Epoch: 5| Step: 5
Training loss: 1.587364912033081
Validation loss: 2.174171050389608

Epoch: 5| Step: 6
Training loss: 1.891018271446228
Validation loss: 2.1662206600109735

Epoch: 5| Step: 7
Training loss: 0.9255553483963013
Validation loss: 2.1715121368567147

Epoch: 5| Step: 8
Training loss: 2.244410753250122
Validation loss: 2.1705006510019302

Epoch: 5| Step: 9
Training loss: 1.749673843383789
Validation loss: 2.175926133990288

Epoch: 5| Step: 10
Training loss: 1.3821938037872314
Validation loss: 2.142711192369461

Epoch: 5| Step: 11
Training loss: 1.6232928037643433
Validation loss: 2.132619430621465

Epoch: 319| Step: 0
Training loss: 1.6908944845199585
Validation loss: 2.152107094724973

Epoch: 5| Step: 1
Training loss: 2.2814416885375977
Validation loss: 2.1314892967542014

Epoch: 5| Step: 2
Training loss: 1.237856388092041
Validation loss: 2.1445473531881967

Epoch: 5| Step: 3
Training loss: 1.872617483139038
Validation loss: 2.1282179901997247

Epoch: 5| Step: 4
Training loss: 1.5411344766616821
Validation loss: 2.1714064379533133

Epoch: 5| Step: 5
Training loss: 1.607410192489624
Validation loss: 2.176942398150762

Epoch: 5| Step: 6
Training loss: 2.1290926933288574
Validation loss: 2.1704090187946954

Epoch: 5| Step: 7
Training loss: 1.867907166481018
Validation loss: 2.1746172308921814

Epoch: 5| Step: 8
Training loss: 1.7746158838272095
Validation loss: 2.1818615843852363

Epoch: 5| Step: 9
Training loss: 1.5610038042068481
Validation loss: 2.169711341460546

Epoch: 5| Step: 10
Training loss: 1.6315972805023193
Validation loss: 2.1773041983445487

Epoch: 5| Step: 11
Training loss: 3.189663887023926
Validation loss: 2.17715315024058

Epoch: 320| Step: 0
Training loss: 1.7108385562896729
Validation loss: 2.1422547847032547

Epoch: 5| Step: 1
Training loss: 1.7475227117538452
Validation loss: 2.1524953842163086

Epoch: 5| Step: 2
Training loss: 2.27274751663208
Validation loss: 2.14885713160038

Epoch: 5| Step: 3
Training loss: 1.5798835754394531
Validation loss: 2.131747921307882

Epoch: 5| Step: 4
Training loss: 1.4435312747955322
Validation loss: 2.1473790804545083

Epoch: 5| Step: 5
Training loss: 1.6322263479232788
Validation loss: 2.1580721586942673

Epoch: 5| Step: 6
Training loss: 2.1673226356506348
Validation loss: 2.149860496322314

Epoch: 5| Step: 7
Training loss: 1.930781602859497
Validation loss: 2.1426969468593597

Epoch: 5| Step: 8
Training loss: 2.260389804840088
Validation loss: 2.1393197725216546

Epoch: 5| Step: 9
Training loss: 1.3953160047531128
Validation loss: 2.149814248085022

Epoch: 5| Step: 10
Training loss: 1.4978952407836914
Validation loss: 2.179851079980532

Epoch: 5| Step: 11
Training loss: 1.2271146774291992
Validation loss: 2.1546184619267783

Epoch: 321| Step: 0
Training loss: 2.1217093467712402
Validation loss: 2.181976407766342

Epoch: 5| Step: 1
Training loss: 1.9148521423339844
Validation loss: 2.1970299979050956

Epoch: 5| Step: 2
Training loss: 1.5119669437408447
Validation loss: 2.191894064346949

Epoch: 5| Step: 3
Training loss: 1.6099752187728882
Validation loss: 2.177716081341108

Epoch: 5| Step: 4
Training loss: 2.6044726371765137
Validation loss: 2.1761505703131356

Epoch: 5| Step: 5
Training loss: 1.8529678583145142
Validation loss: 2.1636238942543664

Epoch: 5| Step: 6
Training loss: 1.3779181241989136
Validation loss: 2.15930267671744

Epoch: 5| Step: 7
Training loss: 1.9113184213638306
Validation loss: 2.1583049396673837

Epoch: 5| Step: 8
Training loss: 1.7779476642608643
Validation loss: 2.149138778448105

Epoch: 5| Step: 9
Training loss: 1.6804126501083374
Validation loss: 2.140223264694214

Epoch: 5| Step: 10
Training loss: 1.1763675212860107
Validation loss: 2.161719873547554

Epoch: 5| Step: 11
Training loss: 2.0178914070129395
Validation loss: 2.1498060127099357

Epoch: 322| Step: 0
Training loss: 1.6682803630828857
Validation loss: 2.1248717109362283

Epoch: 5| Step: 1
Training loss: 1.7709600925445557
Validation loss: 2.1303609957297645

Epoch: 5| Step: 2
Training loss: 2.5966598987579346
Validation loss: 2.168774882952372

Epoch: 5| Step: 3
Training loss: 1.5428520441055298
Validation loss: 2.1416115363438926

Epoch: 5| Step: 4
Training loss: 1.6812856197357178
Validation loss: 2.1591352075338364

Epoch: 5| Step: 5
Training loss: 1.8035379648208618
Validation loss: 2.154248630007108

Epoch: 5| Step: 6
Training loss: 1.7278022766113281
Validation loss: 2.1427858720223107

Epoch: 5| Step: 7
Training loss: 1.2551406621932983
Validation loss: 2.1791661282380423

Epoch: 5| Step: 8
Training loss: 1.1799116134643555
Validation loss: 2.136280278364817

Epoch: 5| Step: 9
Training loss: 1.3237941265106201
Validation loss: 2.178204188744227

Epoch: 5| Step: 10
Training loss: 2.1212375164031982
Validation loss: 2.173466771841049

Epoch: 5| Step: 11
Training loss: 2.7288646697998047
Validation loss: 2.167495846748352

Epoch: 323| Step: 0
Training loss: 1.936602234840393
Validation loss: 2.1998418966929116

Epoch: 5| Step: 1
Training loss: 1.5052931308746338
Validation loss: 2.1714029610157013

Epoch: 5| Step: 2
Training loss: 2.1240692138671875
Validation loss: 2.1682664652665458

Epoch: 5| Step: 3
Training loss: 1.46636962890625
Validation loss: 2.1684749772151313

Epoch: 5| Step: 4
Training loss: 1.272092580795288
Validation loss: 2.1317893266677856

Epoch: 5| Step: 5
Training loss: 1.8661060333251953
Validation loss: 2.163392091790835

Epoch: 5| Step: 6
Training loss: 1.8620713949203491
Validation loss: 2.1508109917243323

Epoch: 5| Step: 7
Training loss: 1.3756811618804932
Validation loss: 2.146390517552694

Epoch: 5| Step: 8
Training loss: 1.9910510778427124
Validation loss: 2.1340368489424386

Epoch: 5| Step: 9
Training loss: 1.833056092262268
Validation loss: 2.148616453011831

Epoch: 5| Step: 10
Training loss: 2.0470128059387207
Validation loss: 2.1411616851886115

Epoch: 5| Step: 11
Training loss: 1.3725003004074097
Validation loss: 2.1379534155130386

Epoch: 324| Step: 0
Training loss: 2.0281853675842285
Validation loss: 2.134201536575953

Epoch: 5| Step: 1
Training loss: 2.1340975761413574
Validation loss: 2.1347229033708572

Epoch: 5| Step: 2
Training loss: 1.950368881225586
Validation loss: 2.140637199083964

Epoch: 5| Step: 3
Training loss: 1.5279719829559326
Validation loss: 2.1719781955083213

Epoch: 5| Step: 4
Training loss: 2.643925189971924
Validation loss: 2.146138812104861

Epoch: 5| Step: 5
Training loss: 1.346574068069458
Validation loss: 2.1590488453706107

Epoch: 5| Step: 6
Training loss: 1.2381807565689087
Validation loss: 2.1797431955734887

Epoch: 5| Step: 7
Training loss: 1.4401919841766357
Validation loss: 2.1707800229390464

Epoch: 5| Step: 8
Training loss: 1.4165034294128418
Validation loss: 2.174727499485016

Epoch: 5| Step: 9
Training loss: 1.5661275386810303
Validation loss: 2.1816699703534446

Epoch: 5| Step: 10
Training loss: 1.9061167240142822
Validation loss: 2.1625900715589523

Epoch: 5| Step: 11
Training loss: 1.221126914024353
Validation loss: 2.150481939315796

Epoch: 325| Step: 0
Training loss: 2.1050350666046143
Validation loss: 2.1468585977951684

Epoch: 5| Step: 1
Training loss: 0.8809577226638794
Validation loss: 2.1537597328424454

Epoch: 5| Step: 2
Training loss: 2.17244029045105
Validation loss: 2.1447898894548416

Epoch: 5| Step: 3
Training loss: 2.1399643421173096
Validation loss: 2.1310685127973557

Epoch: 5| Step: 4
Training loss: 0.8706895709037781
Validation loss: 2.14268651107947

Epoch: 5| Step: 5
Training loss: 1.554908275604248
Validation loss: 2.137202555934588

Epoch: 5| Step: 6
Training loss: 1.973812460899353
Validation loss: 2.1601430972417197

Epoch: 5| Step: 7
Training loss: 1.549567461013794
Validation loss: 2.1392642309268317

Epoch: 5| Step: 8
Training loss: 1.482405424118042
Validation loss: 2.1647309164206185

Epoch: 5| Step: 9
Training loss: 1.981837511062622
Validation loss: 2.1584796607494354

Epoch: 5| Step: 10
Training loss: 2.40704607963562
Validation loss: 2.152036895354589

Epoch: 5| Step: 11
Training loss: 1.0848097801208496
Validation loss: 2.1732030361890793

Epoch: 326| Step: 0
Training loss: 1.4228947162628174
Validation loss: 2.1829720586538315

Epoch: 5| Step: 1
Training loss: 1.33036470413208
Validation loss: 2.2047713746627173

Epoch: 5| Step: 2
Training loss: 1.9414116144180298
Validation loss: 2.1894016663233438

Epoch: 5| Step: 3
Training loss: 1.3434867858886719
Validation loss: 2.1815067330996194

Epoch: 5| Step: 4
Training loss: 1.6762685775756836
Validation loss: 2.166380390524864

Epoch: 5| Step: 5
Training loss: 1.6055774688720703
Validation loss: 2.1578058848778405

Epoch: 5| Step: 6
Training loss: 1.694088339805603
Validation loss: 2.1396921475728354

Epoch: 5| Step: 7
Training loss: 2.42314076423645
Validation loss: 2.155566781759262

Epoch: 5| Step: 8
Training loss: 2.1480581760406494
Validation loss: 2.1348944207032523

Epoch: 5| Step: 9
Training loss: 2.225728988647461
Validation loss: 2.1543438782294593

Epoch: 5| Step: 10
Training loss: 1.67128586769104
Validation loss: 2.1447053452332816

Epoch: 5| Step: 11
Training loss: 0.7620277404785156
Validation loss: 2.129312972227732

Epoch: 327| Step: 0
Training loss: 1.8230178356170654
Validation loss: 2.176595777273178

Epoch: 5| Step: 1
Training loss: 1.829270601272583
Validation loss: 2.180364638566971

Epoch: 5| Step: 2
Training loss: 1.9573293924331665
Validation loss: 2.1853736142317453

Epoch: 5| Step: 3
Training loss: 1.5153801441192627
Validation loss: 2.1755566398302713

Epoch: 5| Step: 4
Training loss: 2.403005599975586
Validation loss: 2.1727313498655954

Epoch: 5| Step: 5
Training loss: 1.670670747756958
Validation loss: 2.1974665770928064

Epoch: 5| Step: 6
Training loss: 0.9830074310302734
Validation loss: 2.178112437327703

Epoch: 5| Step: 7
Training loss: 1.7336432933807373
Validation loss: 2.1795928478240967

Epoch: 5| Step: 8
Training loss: 2.1193814277648926
Validation loss: 2.189626693725586

Epoch: 5| Step: 9
Training loss: 1.473177194595337
Validation loss: 2.1673622528711953

Epoch: 5| Step: 10
Training loss: 1.1182657480239868
Validation loss: 2.166656052072843

Epoch: 5| Step: 11
Training loss: 1.0779868364334106
Validation loss: 2.1521915992101035

Epoch: 328| Step: 0
Training loss: 1.7426820993423462
Validation loss: 2.1518163879712424

Epoch: 5| Step: 1
Training loss: 1.4587665796279907
Validation loss: 2.149850438038508

Epoch: 5| Step: 2
Training loss: 2.0134854316711426
Validation loss: 2.1589441299438477

Epoch: 5| Step: 3
Training loss: 1.4782031774520874
Validation loss: 2.1485879172881446

Epoch: 5| Step: 4
Training loss: 2.0369644165039062
Validation loss: 2.1676851709683738

Epoch: 5| Step: 5
Training loss: 1.550891637802124
Validation loss: 2.1828397711118064

Epoch: 5| Step: 6
Training loss: 2.062190532684326
Validation loss: 2.14853972196579

Epoch: 5| Step: 7
Training loss: 1.614951491355896
Validation loss: 2.1980132261912027

Epoch: 5| Step: 8
Training loss: 1.5923289060592651
Validation loss: 2.2368372728427253

Epoch: 5| Step: 9
Training loss: 2.121417999267578
Validation loss: 2.197424272696177

Epoch: 5| Step: 10
Training loss: 1.4013628959655762
Validation loss: 2.179885576168696

Epoch: 5| Step: 11
Training loss: 1.4636707305908203
Validation loss: 2.1563790440559387

Epoch: 329| Step: 0
Training loss: 1.6448895931243896
Validation loss: 2.1631693740685782

Epoch: 5| Step: 1
Training loss: 1.6575359106063843
Validation loss: 2.1825449466705322

Epoch: 5| Step: 2
Training loss: 2.0699474811553955
Validation loss: 2.1599956105152764

Epoch: 5| Step: 3
Training loss: 1.2284795045852661
Validation loss: 2.1518770257631936

Epoch: 5| Step: 4
Training loss: 1.6500985622406006
Validation loss: 2.1542933334906897

Epoch: 5| Step: 5
Training loss: 1.6697463989257812
Validation loss: 2.1600226213534675

Epoch: 5| Step: 6
Training loss: 2.2910075187683105
Validation loss: 2.164069061477979

Epoch: 5| Step: 7
Training loss: 2.000596523284912
Validation loss: 2.1750219464302063

Epoch: 5| Step: 8
Training loss: 1.312945008277893
Validation loss: 2.1568633764982224

Epoch: 5| Step: 9
Training loss: 1.903873085975647
Validation loss: 2.2174145579338074

Epoch: 5| Step: 10
Training loss: 1.0930780172348022
Validation loss: 2.1679360071818032

Epoch: 5| Step: 11
Training loss: 3.160585880279541
Validation loss: 2.152550309896469

Epoch: 330| Step: 0
Training loss: 1.3716617822647095
Validation loss: 2.152230034271876

Epoch: 5| Step: 1
Training loss: 1.39107346534729
Validation loss: 2.1460016469160714

Epoch: 5| Step: 2
Training loss: 1.6028201580047607
Validation loss: 2.1374453008174896

Epoch: 5| Step: 3
Training loss: 1.7252347469329834
Validation loss: 2.150765667359034

Epoch: 5| Step: 4
Training loss: 2.2104783058166504
Validation loss: 2.147964984178543

Epoch: 5| Step: 5
Training loss: 2.366868734359741
Validation loss: 2.145657112201055

Epoch: 5| Step: 6
Training loss: 1.4344946146011353
Validation loss: 2.1399734814961753

Epoch: 5| Step: 7
Training loss: 1.873125672340393
Validation loss: 2.1321284472942352

Epoch: 5| Step: 8
Training loss: 1.4095901250839233
Validation loss: 2.1442201981941857

Epoch: 5| Step: 9
Training loss: 2.1873366832733154
Validation loss: 2.1616616596778235

Epoch: 5| Step: 10
Training loss: 1.5441408157348633
Validation loss: 2.1774275650580726

Epoch: 5| Step: 11
Training loss: 0.82206791639328
Validation loss: 2.183296705285708

Epoch: 331| Step: 0
Training loss: 1.5151798725128174
Validation loss: 2.2186627139647803

Epoch: 5| Step: 1
Training loss: 1.9528099298477173
Validation loss: 2.198484182357788

Epoch: 5| Step: 2
Training loss: 2.374443531036377
Validation loss: 2.1966594457626343

Epoch: 5| Step: 3
Training loss: 1.810036063194275
Validation loss: 2.1792249927918115

Epoch: 5| Step: 4
Training loss: 1.5067945718765259
Validation loss: 2.157184253136317

Epoch: 5| Step: 5
Training loss: 1.6925779581069946
Validation loss: 2.163058007756869

Epoch: 5| Step: 6
Training loss: 1.9722568988800049
Validation loss: 2.119520435730616

Epoch: 5| Step: 7
Training loss: 1.0926928520202637
Validation loss: 2.143840586145719

Epoch: 5| Step: 8
Training loss: 2.094855785369873
Validation loss: 2.1401297599077225

Epoch: 5| Step: 9
Training loss: 1.46004319190979
Validation loss: 2.1411749521891275

Epoch: 5| Step: 10
Training loss: 1.537308931350708
Validation loss: 2.1460164239009223

Epoch: 5| Step: 11
Training loss: 1.723671317100525
Validation loss: 2.156088282664617

Epoch: 332| Step: 0
Training loss: 2.2126059532165527
Validation loss: 2.156935895482699

Epoch: 5| Step: 1
Training loss: 2.527726650238037
Validation loss: 2.1500855684280396

Epoch: 5| Step: 2
Training loss: 1.908951997756958
Validation loss: 2.1634007592995963

Epoch: 5| Step: 3
Training loss: 1.4586156606674194
Validation loss: 2.1492800414562225

Epoch: 5| Step: 4
Training loss: 1.5596489906311035
Validation loss: 2.159652834137281

Epoch: 5| Step: 5
Training loss: 1.6054786443710327
Validation loss: 2.1768914808829627

Epoch: 5| Step: 6
Training loss: 1.114050030708313
Validation loss: 2.1638120313485465

Epoch: 5| Step: 7
Training loss: 1.276685357093811
Validation loss: 2.193601335088412

Epoch: 5| Step: 8
Training loss: 2.0666756629943848
Validation loss: 2.191276674469312

Epoch: 5| Step: 9
Training loss: 1.8473494052886963
Validation loss: 2.2231524835030236

Epoch: 5| Step: 10
Training loss: 1.702914834022522
Validation loss: 2.2098047037919364

Epoch: 5| Step: 11
Training loss: 1.9786847829818726
Validation loss: 2.1907303432623544

Epoch: 333| Step: 0
Training loss: 1.741666555404663
Validation loss: 2.2018939356009164

Epoch: 5| Step: 1
Training loss: 1.6588943004608154
Validation loss: 2.189786046743393

Epoch: 5| Step: 2
Training loss: 1.8452144861221313
Validation loss: 2.160430724422137

Epoch: 5| Step: 3
Training loss: 2.3123536109924316
Validation loss: 2.18377215663592

Epoch: 5| Step: 4
Training loss: 1.652330994606018
Validation loss: 2.1591005673011145

Epoch: 5| Step: 5
Training loss: 1.2191321849822998
Validation loss: 2.1740154325962067

Epoch: 5| Step: 6
Training loss: 1.2545697689056396
Validation loss: 2.156612435976664

Epoch: 5| Step: 7
Training loss: 1.73296320438385
Validation loss: 2.16359543800354

Epoch: 5| Step: 8
Training loss: 1.7919788360595703
Validation loss: 2.1521175801754

Epoch: 5| Step: 9
Training loss: 1.605023741722107
Validation loss: 2.140496537089348

Epoch: 5| Step: 10
Training loss: 1.4606817960739136
Validation loss: 2.1606777906417847

Epoch: 5| Step: 11
Training loss: 2.898928165435791
Validation loss: 2.1413107067346573

Epoch: 334| Step: 0
Training loss: 2.3201797008514404
Validation loss: 2.155953586101532

Epoch: 5| Step: 1
Training loss: 2.2243895530700684
Validation loss: 2.1502271542946496

Epoch: 5| Step: 2
Training loss: 2.3069701194763184
Validation loss: 2.1404703805843988

Epoch: 5| Step: 3
Training loss: 1.4411710500717163
Validation loss: 2.137225404381752

Epoch: 5| Step: 4
Training loss: 1.5398005247116089
Validation loss: 2.1563515911499658

Epoch: 5| Step: 5
Training loss: 1.7527364492416382
Validation loss: 2.1862381994724274

Epoch: 5| Step: 6
Training loss: 1.6636558771133423
Validation loss: 2.178274859984716

Epoch: 5| Step: 7
Training loss: 1.1725431680679321
Validation loss: 2.1467085977395377

Epoch: 5| Step: 8
Training loss: 1.1219332218170166
Validation loss: 2.1558128694693246

Epoch: 5| Step: 9
Training loss: 1.8813730478286743
Validation loss: 2.1212000846862793

Epoch: 5| Step: 10
Training loss: 1.410672903060913
Validation loss: 2.1370191673437753

Epoch: 5| Step: 11
Training loss: 0.778221607208252
Validation loss: 2.141794259349505

Epoch: 335| Step: 0
Training loss: 1.880724310874939
Validation loss: 2.112445498506228

Epoch: 5| Step: 1
Training loss: 2.1801400184631348
Validation loss: 2.127031753460566

Epoch: 5| Step: 2
Training loss: 1.3772776126861572
Validation loss: 2.143106217185656

Epoch: 5| Step: 3
Training loss: 1.7875354290008545
Validation loss: 2.1473914285500846

Epoch: 5| Step: 4
Training loss: 1.8779350519180298
Validation loss: 2.1192993024984994

Epoch: 5| Step: 5
Training loss: 0.7784566283226013
Validation loss: 2.136871491869291

Epoch: 5| Step: 6
Training loss: 1.4710309505462646
Validation loss: 2.1500519265731177

Epoch: 5| Step: 7
Training loss: 1.5921357870101929
Validation loss: 2.1451572328805923

Epoch: 5| Step: 8
Training loss: 2.125220775604248
Validation loss: 2.1559286763270697

Epoch: 5| Step: 9
Training loss: 1.5170795917510986
Validation loss: 2.177432343363762

Epoch: 5| Step: 10
Training loss: 2.138065814971924
Validation loss: 2.183614363272985

Epoch: 5| Step: 11
Training loss: 3.1250979900360107
Validation loss: 2.1353425482908883

Epoch: 336| Step: 0
Training loss: 1.6217565536499023
Validation loss: 2.1606661727031073

Epoch: 5| Step: 1
Training loss: 1.4095062017440796
Validation loss: 2.1843994855880737

Epoch: 5| Step: 2
Training loss: 2.0603513717651367
Validation loss: 2.1418102979660034

Epoch: 5| Step: 3
Training loss: 1.4665899276733398
Validation loss: 2.1581584761540094

Epoch: 5| Step: 4
Training loss: 2.068835735321045
Validation loss: 2.1613099028666816

Epoch: 5| Step: 5
Training loss: 1.549525499343872
Validation loss: 2.16095732152462

Epoch: 5| Step: 6
Training loss: 1.7178055047988892
Validation loss: 2.1419571886459985

Epoch: 5| Step: 7
Training loss: 1.848745346069336
Validation loss: 2.1676229486862817

Epoch: 5| Step: 8
Training loss: 1.6208499670028687
Validation loss: 2.180006225903829

Epoch: 5| Step: 9
Training loss: 1.463319182395935
Validation loss: 2.190953011314074

Epoch: 5| Step: 10
Training loss: 2.0000922679901123
Validation loss: 2.197574262817701

Epoch: 5| Step: 11
Training loss: 2.7528128623962402
Validation loss: 2.1770151257514954

Epoch: 337| Step: 0
Training loss: 1.9840087890625
Validation loss: 2.1911622236172357

Epoch: 5| Step: 1
Training loss: 1.435187578201294
Validation loss: 2.164806996782621

Epoch: 5| Step: 2
Training loss: 1.3617982864379883
Validation loss: 2.1632956812779107

Epoch: 5| Step: 3
Training loss: 1.6163609027862549
Validation loss: 2.1648197720448175

Epoch: 5| Step: 4
Training loss: 1.3874205350875854
Validation loss: 2.1688398321469626

Epoch: 5| Step: 5
Training loss: 1.5326017141342163
Validation loss: 2.1599742422501245

Epoch: 5| Step: 6
Training loss: 1.798837661743164
Validation loss: 2.151572818557421

Epoch: 5| Step: 7
Training loss: 1.4001041650772095
Validation loss: 2.1576425433158875

Epoch: 5| Step: 8
Training loss: 2.2326011657714844
Validation loss: 2.1832507153352103

Epoch: 5| Step: 9
Training loss: 1.6802165508270264
Validation loss: 2.173156147201856

Epoch: 5| Step: 10
Training loss: 1.8617483377456665
Validation loss: 2.2096095283826194

Epoch: 5| Step: 11
Training loss: 2.5882773399353027
Validation loss: 2.1982822716236115

Epoch: 338| Step: 0
Training loss: 1.585502028465271
Validation loss: 2.2064542720715203

Epoch: 5| Step: 1
Training loss: 2.181259870529175
Validation loss: 2.15572382013003

Epoch: 5| Step: 2
Training loss: 1.1561022996902466
Validation loss: 2.1421795934438705

Epoch: 5| Step: 3
Training loss: 2.394960641860962
Validation loss: 2.132885326941808

Epoch: 5| Step: 4
Training loss: 1.5013195276260376
Validation loss: 2.141215533018112

Epoch: 5| Step: 5
Training loss: 1.7009284496307373
Validation loss: 2.1347316205501556

Epoch: 5| Step: 6
Training loss: 1.5330065488815308
Validation loss: 2.142956723769506

Epoch: 5| Step: 7
Training loss: 1.785660743713379
Validation loss: 2.144523784518242

Epoch: 5| Step: 8
Training loss: 1.4703295230865479
Validation loss: 2.1573190291722617

Epoch: 5| Step: 9
Training loss: 1.631882667541504
Validation loss: 2.161187375585238

Epoch: 5| Step: 10
Training loss: 1.9229885339736938
Validation loss: 2.1270569413900375

Epoch: 5| Step: 11
Training loss: 0.5909236669540405
Validation loss: 2.185070047775904

Epoch: 339| Step: 0
Training loss: 1.7646716833114624
Validation loss: 2.1943641702334085

Epoch: 5| Step: 1
Training loss: 1.282076358795166
Validation loss: 2.20158651471138

Epoch: 5| Step: 2
Training loss: 2.008333206176758
Validation loss: 2.2021440813938775

Epoch: 5| Step: 3
Training loss: 1.8554904460906982
Validation loss: 2.192407021919886

Epoch: 5| Step: 4
Training loss: 1.9252582788467407
Validation loss: 2.173781563838323

Epoch: 5| Step: 5
Training loss: 1.818713903427124
Validation loss: 2.1665025750796

Epoch: 5| Step: 6
Training loss: 1.1921758651733398
Validation loss: 2.1704609294732413

Epoch: 5| Step: 7
Training loss: 1.5111783742904663
Validation loss: 2.137448787689209

Epoch: 5| Step: 8
Training loss: 1.6667028665542603
Validation loss: 2.1354760030905404

Epoch: 5| Step: 9
Training loss: 1.5929131507873535
Validation loss: 2.140798896551132

Epoch: 5| Step: 10
Training loss: 2.092282295227051
Validation loss: 2.131836752096812

Epoch: 5| Step: 11
Training loss: 1.4513741731643677
Validation loss: 2.126430884003639

Epoch: 340| Step: 0
Training loss: 1.628568410873413
Validation loss: 2.1410635262727737

Epoch: 5| Step: 1
Training loss: 1.8070974349975586
Validation loss: 2.1445083717505136

Epoch: 5| Step: 2
Training loss: 1.7894312143325806
Validation loss: 2.188587635755539

Epoch: 5| Step: 3
Training loss: 1.715126633644104
Validation loss: 2.1796844402949014

Epoch: 5| Step: 4
Training loss: 1.3826367855072021
Validation loss: 2.1759143074353537

Epoch: 5| Step: 5
Training loss: 1.6399723291397095
Validation loss: 2.150515844424566

Epoch: 5| Step: 6
Training loss: 1.9439074993133545
Validation loss: 2.134470904866854

Epoch: 5| Step: 7
Training loss: 2.019941806793213
Validation loss: 2.1363987574974694

Epoch: 5| Step: 8
Training loss: 1.377015233039856
Validation loss: 2.147223944465319

Epoch: 5| Step: 9
Training loss: 1.521807074546814
Validation loss: 2.1559676875670752

Epoch: 5| Step: 10
Training loss: 1.4035449028015137
Validation loss: 2.1501951068639755

Epoch: 5| Step: 11
Training loss: 3.5593180656433105
Validation loss: 2.175355980793635

Epoch: 341| Step: 0
Training loss: 1.9143235683441162
Validation loss: 2.154860327641169

Epoch: 5| Step: 1
Training loss: 2.286574363708496
Validation loss: 2.157103399435679

Epoch: 5| Step: 2
Training loss: 2.2542014122009277
Validation loss: 2.1437410712242126

Epoch: 5| Step: 3
Training loss: 1.6375339031219482
Validation loss: 2.1243908603986106

Epoch: 5| Step: 4
Training loss: 1.4422640800476074
Validation loss: 2.130935102701187

Epoch: 5| Step: 5
Training loss: 1.4740198850631714
Validation loss: 2.138578121860822

Epoch: 5| Step: 6
Training loss: 1.5227487087249756
Validation loss: 2.162423253059387

Epoch: 5| Step: 7
Training loss: 1.6095565557479858
Validation loss: 2.089555944005648

Epoch: 5| Step: 8
Training loss: 1.4481823444366455
Validation loss: 2.147293488184611

Epoch: 5| Step: 9
Training loss: 1.0898048877716064
Validation loss: 2.153634096185366

Epoch: 5| Step: 10
Training loss: 1.5547479391098022
Validation loss: 2.141487012306849

Epoch: 5| Step: 11
Training loss: 3.0408082008361816
Validation loss: 2.132942279179891

Epoch: 342| Step: 0
Training loss: 1.6580085754394531
Validation loss: 2.1422731379667916

Epoch: 5| Step: 1
Training loss: 1.6532583236694336
Validation loss: 2.149566983183225

Epoch: 5| Step: 2
Training loss: 1.714337944984436
Validation loss: 2.1628853480021157

Epoch: 5| Step: 3
Training loss: 1.725347876548767
Validation loss: 2.1796571711699166

Epoch: 5| Step: 4
Training loss: 1.548388123512268
Validation loss: 2.1776481171449027

Epoch: 5| Step: 5
Training loss: 1.6229689121246338
Validation loss: 2.173848887284597

Epoch: 5| Step: 6
Training loss: 0.9630680084228516
Validation loss: 2.1680228859186172

Epoch: 5| Step: 7
Training loss: 2.4023566246032715
Validation loss: 2.1603277772665024

Epoch: 5| Step: 8
Training loss: 1.744145154953003
Validation loss: 2.184043104449908

Epoch: 5| Step: 9
Training loss: 1.6503738164901733
Validation loss: 2.165149693687757

Epoch: 5| Step: 10
Training loss: 1.8143072128295898
Validation loss: 2.14997336268425

Epoch: 5| Step: 11
Training loss: 0.9102401733398438
Validation loss: 2.1694268037875495

Epoch: 343| Step: 0
Training loss: 1.1787046194076538
Validation loss: 2.1827992449204126

Epoch: 5| Step: 1
Training loss: 1.5036718845367432
Validation loss: 2.2258655478556952

Epoch: 5| Step: 2
Training loss: 2.1255156993865967
Validation loss: 2.193918118874232

Epoch: 5| Step: 3
Training loss: 1.775404691696167
Validation loss: 2.198562189936638

Epoch: 5| Step: 4
Training loss: 1.1898906230926514
Validation loss: 2.2017795642217

Epoch: 5| Step: 5
Training loss: 1.8224875926971436
Validation loss: 2.1986541549364724

Epoch: 5| Step: 6
Training loss: 1.9974209070205688
Validation loss: 2.1601855903863907

Epoch: 5| Step: 7
Training loss: 1.4967436790466309
Validation loss: 2.1769081354141235

Epoch: 5| Step: 8
Training loss: 1.8315929174423218
Validation loss: 2.176959385474523

Epoch: 5| Step: 9
Training loss: 1.4927161931991577
Validation loss: 2.152107228835424

Epoch: 5| Step: 10
Training loss: 1.4173741340637207
Validation loss: 2.1689525842666626

Epoch: 5| Step: 11
Training loss: 2.650083541870117
Validation loss: 2.170523295799891

Epoch: 344| Step: 0
Training loss: 1.475634217262268
Validation loss: 2.1535331507523856

Epoch: 5| Step: 1
Training loss: 1.8441234827041626
Validation loss: 2.1639918982982635

Epoch: 5| Step: 2
Training loss: 1.339858055114746
Validation loss: 2.1808577676614127

Epoch: 5| Step: 3
Training loss: 1.605238676071167
Validation loss: 2.1879277577002845

Epoch: 5| Step: 4
Training loss: 1.7148797512054443
Validation loss: 2.1935823609431586

Epoch: 5| Step: 5
Training loss: 1.9829185009002686
Validation loss: 2.174317096670469

Epoch: 5| Step: 6
Training loss: 2.1605477333068848
Validation loss: 2.2322464088598886

Epoch: 5| Step: 7
Training loss: 2.2463812828063965
Validation loss: 2.181025500098864

Epoch: 5| Step: 8
Training loss: 1.386063575744629
Validation loss: 2.195784072081248

Epoch: 5| Step: 9
Training loss: 1.3188377618789673
Validation loss: 2.1756230692068734

Epoch: 5| Step: 10
Training loss: 1.5562156438827515
Validation loss: 2.17328147093455

Epoch: 5| Step: 11
Training loss: 1.8809738159179688
Validation loss: 2.1635649700959525

Epoch: 345| Step: 0
Training loss: 1.6191279888153076
Validation loss: 2.1599713563919067

Epoch: 5| Step: 1
Training loss: 2.0318241119384766
Validation loss: 2.2092510809501014

Epoch: 5| Step: 2
Training loss: 2.3311009407043457
Validation loss: 2.17912894487381

Epoch: 5| Step: 3
Training loss: 1.7803176641464233
Validation loss: 2.218588709831238

Epoch: 5| Step: 4
Training loss: 1.6700165271759033
Validation loss: 2.19054185350736

Epoch: 5| Step: 5
Training loss: 1.3385637998580933
Validation loss: 2.2319086690743766

Epoch: 5| Step: 6
Training loss: 1.7942588329315186
Validation loss: 2.209539463122686

Epoch: 5| Step: 7
Training loss: 1.5129649639129639
Validation loss: 2.173561001817385

Epoch: 5| Step: 8
Training loss: 1.3926889896392822
Validation loss: 2.180514136950175

Epoch: 5| Step: 9
Training loss: 1.7847204208374023
Validation loss: 2.169244517882665

Epoch: 5| Step: 10
Training loss: 1.2724831104278564
Validation loss: 2.151592512925466

Epoch: 5| Step: 11
Training loss: 1.429558515548706
Validation loss: 2.130742604533831

Epoch: 346| Step: 0
Training loss: 1.140724539756775
Validation loss: 2.138479376832644

Epoch: 5| Step: 1
Training loss: 2.030062437057495
Validation loss: 2.158951446413994

Epoch: 5| Step: 2
Training loss: 1.2910008430480957
Validation loss: 2.1526487171649933

Epoch: 5| Step: 3
Training loss: 1.4101619720458984
Validation loss: 2.1278418203194938

Epoch: 5| Step: 4
Training loss: 1.8626089096069336
Validation loss: 2.14650496840477

Epoch: 5| Step: 5
Training loss: 1.5922672748565674
Validation loss: 2.1508170862992606

Epoch: 5| Step: 6
Training loss: 1.8734314441680908
Validation loss: 2.170750250418981

Epoch: 5| Step: 7
Training loss: 1.7497972249984741
Validation loss: 2.2115873793760934

Epoch: 5| Step: 8
Training loss: 2.0693325996398926
Validation loss: 2.2252209136883416

Epoch: 5| Step: 9
Training loss: 1.6171464920043945
Validation loss: 2.2602857450644174

Epoch: 5| Step: 10
Training loss: 2.185657024383545
Validation loss: 2.2298895716667175

Epoch: 5| Step: 11
Training loss: 2.625123977661133
Validation loss: 2.2372450133164725

Epoch: 347| Step: 0
Training loss: 1.2017152309417725
Validation loss: 2.1797782282034555

Epoch: 5| Step: 1
Training loss: 1.6651960611343384
Validation loss: 2.213624661167463

Epoch: 5| Step: 2
Training loss: 1.8896633386611938
Validation loss: 2.1682805319627128

Epoch: 5| Step: 3
Training loss: 1.5345513820648193
Validation loss: 2.142035722732544

Epoch: 5| Step: 4
Training loss: 1.8800216913223267
Validation loss: 2.1704915314912796

Epoch: 5| Step: 5
Training loss: 2.2976739406585693
Validation loss: 2.137452388803164

Epoch: 5| Step: 6
Training loss: 2.2967922687530518
Validation loss: 2.170720100402832

Epoch: 5| Step: 7
Training loss: 1.5984389781951904
Validation loss: 2.1584654450416565

Epoch: 5| Step: 8
Training loss: 1.3885087966918945
Validation loss: 2.158803716301918

Epoch: 5| Step: 9
Training loss: 1.39992356300354
Validation loss: 2.1544796228408813

Epoch: 5| Step: 10
Training loss: 1.68679678440094
Validation loss: 2.16153854628404

Epoch: 5| Step: 11
Training loss: 2.4137890338897705
Validation loss: 2.178846374154091

Epoch: 348| Step: 0
Training loss: 1.5114907026290894
Validation loss: 2.156483471393585

Epoch: 5| Step: 1
Training loss: 1.3595027923583984
Validation loss: 2.1497260381778083

Epoch: 5| Step: 2
Training loss: 1.8501888513565063
Validation loss: 2.1302109311024346

Epoch: 5| Step: 3
Training loss: 2.3636021614074707
Validation loss: 2.1533427834510803

Epoch: 5| Step: 4
Training loss: 1.9870249032974243
Validation loss: 2.156930302580198

Epoch: 5| Step: 5
Training loss: 1.4125231504440308
Validation loss: 2.1340389251708984

Epoch: 5| Step: 6
Training loss: 2.454383373260498
Validation loss: 2.1480654875437417

Epoch: 5| Step: 7
Training loss: 1.6469686031341553
Validation loss: 2.1913241694370904

Epoch: 5| Step: 8
Training loss: 1.599469780921936
Validation loss: 2.155268987019857

Epoch: 5| Step: 9
Training loss: 1.7279266119003296
Validation loss: 2.1721157481273017

Epoch: 5| Step: 10
Training loss: 1.376443862915039
Validation loss: 2.126178334156672

Epoch: 5| Step: 11
Training loss: 1.2585686445236206
Validation loss: 2.147120386362076

Epoch: 349| Step: 0
Training loss: 1.366909146308899
Validation loss: 2.1544561882813773

Epoch: 5| Step: 1
Training loss: 1.4940494298934937
Validation loss: 2.1558203945557275

Epoch: 5| Step: 2
Training loss: 1.6633590459823608
Validation loss: 2.1409161388874054

Epoch: 5| Step: 3
Training loss: 1.270970106124878
Validation loss: 2.1627162098884583

Epoch: 5| Step: 4
Training loss: 2.6701862812042236
Validation loss: 2.152833720048269

Epoch: 5| Step: 5
Training loss: 2.0525317192077637
Validation loss: 2.1534956942001977

Epoch: 5| Step: 6
Training loss: 1.279152512550354
Validation loss: 2.1545495440562568

Epoch: 5| Step: 7
Training loss: 2.356107234954834
Validation loss: 2.1550512115160623

Epoch: 5| Step: 8
Training loss: 1.6302942037582397
Validation loss: 2.161645144224167

Epoch: 5| Step: 9
Training loss: 1.9273014068603516
Validation loss: 2.1910952428976693

Epoch: 5| Step: 10
Training loss: 1.8198871612548828
Validation loss: 2.217157314221064

Epoch: 5| Step: 11
Training loss: 0.8922706842422485
Validation loss: 2.183900222182274

Epoch: 350| Step: 0
Training loss: 2.026700973510742
Validation loss: 2.190452496210734

Epoch: 5| Step: 1
Training loss: 2.412618398666382
Validation loss: 2.1812585244576135

Epoch: 5| Step: 2
Training loss: 1.7655986547470093
Validation loss: 2.167677710453669

Epoch: 5| Step: 3
Training loss: 1.475069284439087
Validation loss: 2.152424082159996

Epoch: 5| Step: 4
Training loss: 2.088404893875122
Validation loss: 2.156029552221298

Epoch: 5| Step: 5
Training loss: 1.6581844091415405
Validation loss: 2.146766036748886

Epoch: 5| Step: 6
Training loss: 1.703421950340271
Validation loss: 2.133548597494761

Epoch: 5| Step: 7
Training loss: 1.1338766813278198
Validation loss: 2.1286683529615402

Epoch: 5| Step: 8
Training loss: 1.730680227279663
Validation loss: 2.1228506167729697

Epoch: 5| Step: 9
Training loss: 1.2178735733032227
Validation loss: 2.1754431625207267

Epoch: 5| Step: 10
Training loss: 1.333554983139038
Validation loss: 2.151764636238416

Epoch: 5| Step: 11
Training loss: 0.979314386844635
Validation loss: 2.154751792550087

Epoch: 351| Step: 0
Training loss: 1.6574558019638062
Validation loss: 2.176221271355947

Epoch: 5| Step: 1
Training loss: 1.8127822875976562
Validation loss: 2.1539873480796814

Epoch: 5| Step: 2
Training loss: 1.2288942337036133
Validation loss: 2.186059186855952

Epoch: 5| Step: 3
Training loss: 1.7319952249526978
Validation loss: 2.167597845196724

Epoch: 5| Step: 4
Training loss: 1.5854642391204834
Validation loss: 2.1561648597319922

Epoch: 5| Step: 5
Training loss: 1.5907716751098633
Validation loss: 2.1545657267173133

Epoch: 5| Step: 6
Training loss: 1.719435691833496
Validation loss: 2.173759549856186

Epoch: 5| Step: 7
Training loss: 1.4646291732788086
Validation loss: 2.143405353029569

Epoch: 5| Step: 8
Training loss: 1.729034185409546
Validation loss: 2.1680460770924888

Epoch: 5| Step: 9
Training loss: 1.3443603515625
Validation loss: 2.162492220600446

Epoch: 5| Step: 10
Training loss: 2.5767486095428467
Validation loss: 2.1555886516968408

Epoch: 5| Step: 11
Training loss: 1.238257884979248
Validation loss: 2.1481163799762726

Epoch: 352| Step: 0
Training loss: 1.689278244972229
Validation loss: 2.1541895320018134

Epoch: 5| Step: 1
Training loss: 1.5263745784759521
Validation loss: 2.131159712870916

Epoch: 5| Step: 2
Training loss: 2.4221444129943848
Validation loss: 2.1340850045283637

Epoch: 5| Step: 3
Training loss: 1.307482361793518
Validation loss: 2.147600010037422

Epoch: 5| Step: 4
Training loss: 1.7426093816757202
Validation loss: 2.15604775150617

Epoch: 5| Step: 5
Training loss: 1.1462703943252563
Validation loss: 2.169956475496292

Epoch: 5| Step: 6
Training loss: 1.5621452331542969
Validation loss: 2.160410165786743

Epoch: 5| Step: 7
Training loss: 1.5403344631195068
Validation loss: 2.1860074003537497

Epoch: 5| Step: 8
Training loss: 1.5124218463897705
Validation loss: 2.163715740044912

Epoch: 5| Step: 9
Training loss: 1.6570688486099243
Validation loss: 2.1330520063638687

Epoch: 5| Step: 10
Training loss: 2.2414183616638184
Validation loss: 2.1611001938581467

Epoch: 5| Step: 11
Training loss: 0.4237755835056305
Validation loss: 2.1696507086356482

Epoch: 353| Step: 0
Training loss: 1.8051691055297852
Validation loss: 2.1540999859571457

Epoch: 5| Step: 1
Training loss: 1.2324522733688354
Validation loss: 2.142474258939425

Epoch: 5| Step: 2
Training loss: 1.6043020486831665
Validation loss: 2.1567670355240502

Epoch: 5| Step: 3
Training loss: 1.0695829391479492
Validation loss: 2.1407523403565087

Epoch: 5| Step: 4
Training loss: 1.8616206645965576
Validation loss: 2.161900967359543

Epoch: 5| Step: 5
Training loss: 1.9254627227783203
Validation loss: 2.1394441723823547

Epoch: 5| Step: 6
Training loss: 1.2074558734893799
Validation loss: 2.1740495413541794

Epoch: 5| Step: 7
Training loss: 1.2207776308059692
Validation loss: 2.172006368637085

Epoch: 5| Step: 8
Training loss: 2.290832281112671
Validation loss: 2.1734685699144998

Epoch: 5| Step: 9
Training loss: 2.3874568939208984
Validation loss: 2.1481375197569528

Epoch: 5| Step: 10
Training loss: 1.6454384326934814
Validation loss: 2.1749886920054755

Epoch: 5| Step: 11
Training loss: 0.3046531677246094
Validation loss: 2.2060236235459647

Epoch: 354| Step: 0
Training loss: 1.524627447128296
Validation loss: 2.195729896426201

Epoch: 5| Step: 1
Training loss: 1.5987465381622314
Validation loss: 2.176170994838079

Epoch: 5| Step: 2
Training loss: 2.1297011375427246
Validation loss: 2.165155380964279

Epoch: 5| Step: 3
Training loss: 1.8581804037094116
Validation loss: 2.150945872068405

Epoch: 5| Step: 4
Training loss: 1.284832239151001
Validation loss: 2.1484898577133813

Epoch: 5| Step: 5
Training loss: 2.023509979248047
Validation loss: 2.140545144677162

Epoch: 5| Step: 6
Training loss: 1.4945509433746338
Validation loss: 2.1574782580137253

Epoch: 5| Step: 7
Training loss: 1.8914695978164673
Validation loss: 2.1450851261615753

Epoch: 5| Step: 8
Training loss: 1.0013376474380493
Validation loss: 2.126933127641678

Epoch: 5| Step: 9
Training loss: 1.8552467823028564
Validation loss: 2.1580509493748345

Epoch: 5| Step: 10
Training loss: 1.472583293914795
Validation loss: 2.153918365637461

Epoch: 5| Step: 11
Training loss: 2.3450002670288086
Validation loss: 2.1605565498272576

Epoch: 355| Step: 0
Training loss: 1.6424452066421509
Validation loss: 2.182152276237806

Epoch: 5| Step: 1
Training loss: 1.7842485904693604
Validation loss: 2.1705318093299866

Epoch: 5| Step: 2
Training loss: 1.7747986316680908
Validation loss: 2.2083012759685516

Epoch: 5| Step: 3
Training loss: 1.7250019311904907
Validation loss: 2.188041398922602

Epoch: 5| Step: 4
Training loss: 1.532110571861267
Validation loss: 2.184551695982615

Epoch: 5| Step: 5
Training loss: 1.7716363668441772
Validation loss: 2.167485828200976

Epoch: 5| Step: 6
Training loss: 1.7942966222763062
Validation loss: 2.1831693102916083

Epoch: 5| Step: 7
Training loss: 1.8690229654312134
Validation loss: 2.1540666768948236

Epoch: 5| Step: 8
Training loss: 1.5628527402877808
Validation loss: 2.157657101750374

Epoch: 5| Step: 9
Training loss: 1.3791887760162354
Validation loss: 2.122097745537758

Epoch: 5| Step: 10
Training loss: 1.6087639331817627
Validation loss: 2.161460801959038

Epoch: 5| Step: 11
Training loss: 1.5945875644683838
Validation loss: 2.1441951940457025

Epoch: 356| Step: 0
Training loss: 1.6024854183197021
Validation loss: 2.148047258456548

Epoch: 5| Step: 1
Training loss: 2.334315299987793
Validation loss: 2.160757010181745

Epoch: 5| Step: 2
Training loss: 2.1828997135162354
Validation loss: 2.145777409275373

Epoch: 5| Step: 3
Training loss: 1.6963962316513062
Validation loss: 2.149522085984548

Epoch: 5| Step: 4
Training loss: 1.1746598482131958
Validation loss: 2.142608101169268

Epoch: 5| Step: 5
Training loss: 1.5346182584762573
Validation loss: 2.146312410632769

Epoch: 5| Step: 6
Training loss: 1.7483230829238892
Validation loss: 2.1734611243009567

Epoch: 5| Step: 7
Training loss: 0.9686678647994995
Validation loss: 2.16889758904775

Epoch: 5| Step: 8
Training loss: 1.4113839864730835
Validation loss: 2.157025391856829

Epoch: 5| Step: 9
Training loss: 1.3943930864334106
Validation loss: 2.1829098959763846

Epoch: 5| Step: 10
Training loss: 1.8046058416366577
Validation loss: 2.154367153843244

Epoch: 5| Step: 11
Training loss: 2.995558738708496
Validation loss: 2.202742417653402

Epoch: 357| Step: 0
Training loss: 1.9837944507598877
Validation loss: 2.2124668657779694

Epoch: 5| Step: 1
Training loss: 1.572911024093628
Validation loss: 2.1556482116381326

Epoch: 5| Step: 2
Training loss: 1.6756618022918701
Validation loss: 2.185023382306099

Epoch: 5| Step: 3
Training loss: 1.6888906955718994
Validation loss: 2.1333315869172416

Epoch: 5| Step: 4
Training loss: 1.5492390394210815
Validation loss: 2.144450088342031

Epoch: 5| Step: 5
Training loss: 1.6715219020843506
Validation loss: 2.1382970859607062

Epoch: 5| Step: 6
Training loss: 0.9475579261779785
Validation loss: 2.1428974022467933

Epoch: 5| Step: 7
Training loss: 1.4212721586227417
Validation loss: 2.141782825191816

Epoch: 5| Step: 8
Training loss: 2.0685811042785645
Validation loss: 2.1663649628559747

Epoch: 5| Step: 9
Training loss: 1.6398706436157227
Validation loss: 2.1509012232224145

Epoch: 5| Step: 10
Training loss: 1.4330804347991943
Validation loss: 2.1623634894688926

Epoch: 5| Step: 11
Training loss: 2.357957601547241
Validation loss: 2.1665955086549125

Epoch: 358| Step: 0
Training loss: 1.249334454536438
Validation loss: 2.205223133166631

Epoch: 5| Step: 1
Training loss: 1.6223928928375244
Validation loss: 2.1759886195262275

Epoch: 5| Step: 2
Training loss: 1.2987496852874756
Validation loss: 2.1703605304161706

Epoch: 5| Step: 3
Training loss: 1.8277702331542969
Validation loss: 2.185764029622078

Epoch: 5| Step: 4
Training loss: 1.6687042713165283
Validation loss: 2.153976837793986

Epoch: 5| Step: 5
Training loss: 1.3237017393112183
Validation loss: 2.1555311580499015

Epoch: 5| Step: 6
Training loss: 2.0719122886657715
Validation loss: 2.1465230882167816

Epoch: 5| Step: 7
Training loss: 2.0719847679138184
Validation loss: 2.13515638311704

Epoch: 5| Step: 8
Training loss: 1.7657434940338135
Validation loss: 2.15453277528286

Epoch: 5| Step: 9
Training loss: 1.5351638793945312
Validation loss: 2.1683354477087655

Epoch: 5| Step: 10
Training loss: 1.97637939453125
Validation loss: 2.1509826729695

Epoch: 5| Step: 11
Training loss: 2.0725982189178467
Validation loss: 2.172182619571686

Epoch: 359| Step: 0
Training loss: 1.6224489212036133
Validation loss: 2.1766896496216455

Epoch: 5| Step: 1
Training loss: 1.9293380975723267
Validation loss: 2.176470085978508

Epoch: 5| Step: 2
Training loss: 1.4000290632247925
Validation loss: 2.1727189322312674

Epoch: 5| Step: 3
Training loss: 1.333011269569397
Validation loss: 2.191722109913826

Epoch: 5| Step: 4
Training loss: 1.9688751697540283
Validation loss: 2.1645203282435737

Epoch: 5| Step: 5
Training loss: 1.657768964767456
Validation loss: 2.1579357782999673

Epoch: 5| Step: 6
Training loss: 1.1636278629302979
Validation loss: 2.1468367874622345

Epoch: 5| Step: 7
Training loss: 1.8114824295043945
Validation loss: 2.1772119601567588

Epoch: 5| Step: 8
Training loss: 1.2200993299484253
Validation loss: 2.166494836409887

Epoch: 5| Step: 9
Training loss: 1.9110320806503296
Validation loss: 2.1388996839523315

Epoch: 5| Step: 10
Training loss: 1.8812965154647827
Validation loss: 2.123025650779406

Epoch: 5| Step: 11
Training loss: 1.078342080116272
Validation loss: 2.1322883317867913

Epoch: 360| Step: 0
Training loss: 1.7090867757797241
Validation loss: 2.136002322038015

Epoch: 5| Step: 1
Training loss: 1.8634010553359985
Validation loss: 2.1337666511535645

Epoch: 5| Step: 2
Training loss: 1.643049955368042
Validation loss: 2.1293157637119293

Epoch: 5| Step: 3
Training loss: 2.089721918106079
Validation loss: 2.102051541209221

Epoch: 5| Step: 4
Training loss: 1.330998420715332
Validation loss: 2.1068042020003

Epoch: 5| Step: 5
Training loss: 1.9137332439422607
Validation loss: 2.095074102282524

Epoch: 5| Step: 6
Training loss: 1.4963805675506592
Validation loss: 2.1117741614580154

Epoch: 5| Step: 7
Training loss: 2.0425288677215576
Validation loss: 2.142087151606878

Epoch: 5| Step: 8
Training loss: 0.809860110282898
Validation loss: 2.1242653131484985

Epoch: 5| Step: 9
Training loss: 1.5023400783538818
Validation loss: 2.1410674303770065

Epoch: 5| Step: 10
Training loss: 1.6126222610473633
Validation loss: 2.1213935712973275

Epoch: 5| Step: 11
Training loss: 0.8498798608779907
Validation loss: 2.143333688378334

Epoch: 361| Step: 0
Training loss: 1.8211467266082764
Validation loss: 2.1644748946030936

Epoch: 5| Step: 1
Training loss: 1.3313062191009521
Validation loss: 2.1787428756554923

Epoch: 5| Step: 2
Training loss: 1.3210985660552979
Validation loss: 2.130768363674482

Epoch: 5| Step: 3
Training loss: 1.23634934425354
Validation loss: 2.163609320918719

Epoch: 5| Step: 4
Training loss: 0.8602226376533508
Validation loss: 2.1622021744648614

Epoch: 5| Step: 5
Training loss: 1.4489688873291016
Validation loss: 2.1561214476823807

Epoch: 5| Step: 6
Training loss: 2.134796619415283
Validation loss: 2.1558553824822106

Epoch: 5| Step: 7
Training loss: 1.7910699844360352
Validation loss: 2.1638366281986237

Epoch: 5| Step: 8
Training loss: 1.4271466732025146
Validation loss: 2.1729549566904702

Epoch: 5| Step: 9
Training loss: 2.1152353286743164
Validation loss: 2.1523670901854834

Epoch: 5| Step: 10
Training loss: 1.9178953170776367
Validation loss: 2.16769011815389

Epoch: 5| Step: 11
Training loss: 2.6156744956970215
Validation loss: 2.1555145829916

Epoch: 362| Step: 0
Training loss: 1.5893747806549072
Validation loss: 2.162042871117592

Epoch: 5| Step: 1
Training loss: 1.9703521728515625
Validation loss: 2.1276883482933044

Epoch: 5| Step: 2
Training loss: 1.1563374996185303
Validation loss: 2.138013650973638

Epoch: 5| Step: 3
Training loss: 1.712061882019043
Validation loss: 2.167037526766459

Epoch: 5| Step: 4
Training loss: 1.673758864402771
Validation loss: 2.1396150241295495

Epoch: 5| Step: 5
Training loss: 1.8061225414276123
Validation loss: 2.1623748143514

Epoch: 5| Step: 6
Training loss: 1.19694983959198
Validation loss: 2.149108042319616

Epoch: 5| Step: 7
Training loss: 2.1034088134765625
Validation loss: 2.136434242129326

Epoch: 5| Step: 8
Training loss: 1.6553335189819336
Validation loss: 2.1138019363085427

Epoch: 5| Step: 9
Training loss: 1.5605618953704834
Validation loss: 2.1453111668427787

Epoch: 5| Step: 10
Training loss: 1.2998777627944946
Validation loss: 2.1498293379942575

Epoch: 5| Step: 11
Training loss: 1.0598418712615967
Validation loss: 2.1797580122947693

Epoch: 363| Step: 0
Training loss: 1.9226934909820557
Validation loss: 2.175845672686895

Epoch: 5| Step: 1
Training loss: 1.7158113718032837
Validation loss: 2.1560322046279907

Epoch: 5| Step: 2
Training loss: 1.2807562351226807
Validation loss: 2.172444368402163

Epoch: 5| Step: 3
Training loss: 1.730312705039978
Validation loss: 2.1748967419068017

Epoch: 5| Step: 4
Training loss: 1.3996611833572388
Validation loss: 2.1632678359746933

Epoch: 5| Step: 5
Training loss: 1.4662153720855713
Validation loss: 2.161509190996488

Epoch: 5| Step: 6
Training loss: 1.53298819065094
Validation loss: 2.165340557694435

Epoch: 5| Step: 7
Training loss: 2.219951629638672
Validation loss: 2.158292606472969

Epoch: 5| Step: 8
Training loss: 1.1580606698989868
Validation loss: 2.140000030398369

Epoch: 5| Step: 9
Training loss: 1.2473697662353516
Validation loss: 2.127615382273992

Epoch: 5| Step: 10
Training loss: 1.5707546472549438
Validation loss: 2.1434305558602014

Epoch: 5| Step: 11
Training loss: 1.760093092918396
Validation loss: 2.1587988436222076

Epoch: 364| Step: 0
Training loss: 1.5821224451065063
Validation loss: 2.1569738537073135

Epoch: 5| Step: 1
Training loss: 1.716041922569275
Validation loss: 2.1708512206872306

Epoch: 5| Step: 2
Training loss: 2.0522003173828125
Validation loss: 2.1702306121587753

Epoch: 5| Step: 3
Training loss: 1.4145914316177368
Validation loss: 2.134474143385887

Epoch: 5| Step: 4
Training loss: 1.2809592485427856
Validation loss: 2.171218847235044

Epoch: 5| Step: 5
Training loss: 1.4531198740005493
Validation loss: 2.1808822453022003

Epoch: 5| Step: 6
Training loss: 1.194696307182312
Validation loss: 2.162251884738604

Epoch: 5| Step: 7
Training loss: 1.5795373916625977
Validation loss: 2.169299696882566

Epoch: 5| Step: 8
Training loss: 1.7362384796142578
Validation loss: 2.1586735993623734

Epoch: 5| Step: 9
Training loss: 1.3629151582717896
Validation loss: 2.192922572294871

Epoch: 5| Step: 10
Training loss: 1.5726354122161865
Validation loss: 2.137660269935926

Epoch: 5| Step: 11
Training loss: 3.875264883041382
Validation loss: 2.148576026161512

Epoch: 365| Step: 0
Training loss: 1.0904595851898193
Validation loss: 2.133857657512029

Epoch: 5| Step: 1
Training loss: 2.370901584625244
Validation loss: 2.1501609832048416

Epoch: 5| Step: 2
Training loss: 1.8551719188690186
Validation loss: 2.1498845169941583

Epoch: 5| Step: 3
Training loss: 2.0012006759643555
Validation loss: 2.101079612970352

Epoch: 5| Step: 4
Training loss: 1.8470500707626343
Validation loss: 2.1799163818359375

Epoch: 5| Step: 5
Training loss: 1.1737048625946045
Validation loss: 2.1267593055963516

Epoch: 5| Step: 6
Training loss: 1.445596694946289
Validation loss: 2.1707248290379844

Epoch: 5| Step: 7
Training loss: 1.0228897333145142
Validation loss: 2.198346803585688

Epoch: 5| Step: 8
Training loss: 1.131780982017517
Validation loss: 2.214445029695829

Epoch: 5| Step: 9
Training loss: 1.4770433902740479
Validation loss: 2.1792004108428955

Epoch: 5| Step: 10
Training loss: 1.9717891216278076
Validation loss: 2.195318470398585

Epoch: 5| Step: 11
Training loss: 1.3920481204986572
Validation loss: 2.1881392101446786

Epoch: 366| Step: 0
Training loss: 1.2168095111846924
Validation loss: 2.2199255526065826

Epoch: 5| Step: 1
Training loss: 1.437508225440979
Validation loss: 2.1752323508262634

Epoch: 5| Step: 2
Training loss: 1.8510910272598267
Validation loss: 2.198597808678945

Epoch: 5| Step: 3
Training loss: 2.451561689376831
Validation loss: 2.183555190761884

Epoch: 5| Step: 4
Training loss: 1.8059923648834229
Validation loss: 2.1689442048470178

Epoch: 5| Step: 5
Training loss: 1.392319679260254
Validation loss: 2.1984575986862183

Epoch: 5| Step: 6
Training loss: 1.5603744983673096
Validation loss: 2.1914581755797067

Epoch: 5| Step: 7
Training loss: 1.5779645442962646
Validation loss: 2.214426358540853

Epoch: 5| Step: 8
Training loss: 1.5529887676239014
Validation loss: 2.244433750708898

Epoch: 5| Step: 9
Training loss: 1.852940559387207
Validation loss: 2.2054742177327475

Epoch: 5| Step: 10
Training loss: 1.5745899677276611
Validation loss: 2.195682575305303

Epoch: 5| Step: 11
Training loss: 0.9375698566436768
Validation loss: 2.206152021884918

Epoch: 367| Step: 0
Training loss: 1.6397300958633423
Validation loss: 2.212258373697599

Epoch: 5| Step: 1
Training loss: 1.4316202402114868
Validation loss: 2.196862364808718

Epoch: 5| Step: 2
Training loss: 1.4633524417877197
Validation loss: 2.1861772338549295

Epoch: 5| Step: 3
Training loss: 1.3337763547897339
Validation loss: 2.1579536894957223

Epoch: 5| Step: 4
Training loss: 1.8944377899169922
Validation loss: 2.1828612138827643

Epoch: 5| Step: 5
Training loss: 1.7748291492462158
Validation loss: 2.165963808695475

Epoch: 5| Step: 6
Training loss: 1.4166243076324463
Validation loss: 2.160799046357473

Epoch: 5| Step: 7
Training loss: 1.4301881790161133
Validation loss: 2.17561482389768

Epoch: 5| Step: 8
Training loss: 1.6279590129852295
Validation loss: 2.168133313457171

Epoch: 5| Step: 9
Training loss: 1.82281494140625
Validation loss: 2.168916871150335

Epoch: 5| Step: 10
Training loss: 1.4501909017562866
Validation loss: 2.182113155722618

Epoch: 5| Step: 11
Training loss: 2.111494302749634
Validation loss: 2.1697427928447723

Epoch: 368| Step: 0
Training loss: 2.0697860717773438
Validation loss: 2.155763770143191

Epoch: 5| Step: 1
Training loss: 1.3530791997909546
Validation loss: 2.169138863682747

Epoch: 5| Step: 2
Training loss: 1.0870051383972168
Validation loss: 2.1588727782169976

Epoch: 5| Step: 3
Training loss: 1.7527856826782227
Validation loss: 2.179768448074659

Epoch: 5| Step: 4
Training loss: 1.8260841369628906
Validation loss: 2.198971688747406

Epoch: 5| Step: 5
Training loss: 1.6862220764160156
Validation loss: 2.1930660903453827

Epoch: 5| Step: 6
Training loss: 2.1924567222595215
Validation loss: 2.1984679798285165

Epoch: 5| Step: 7
Training loss: 1.5522792339324951
Validation loss: 2.1649272739887238

Epoch: 5| Step: 8
Training loss: 1.0767582654953003
Validation loss: 2.1788278619448342

Epoch: 5| Step: 9
Training loss: 1.606133222579956
Validation loss: 2.154944588740667

Epoch: 5| Step: 10
Training loss: 1.2574020624160767
Validation loss: 2.1766048073768616

Epoch: 5| Step: 11
Training loss: 0.9171121120452881
Validation loss: 2.147442410389582

Epoch: 369| Step: 0
Training loss: 1.4307328462600708
Validation loss: 2.1426075597604117

Epoch: 5| Step: 1
Training loss: 1.5725737810134888
Validation loss: 2.1191259225209556

Epoch: 5| Step: 2
Training loss: 1.4347318410873413
Validation loss: 2.1403194467226663

Epoch: 5| Step: 3
Training loss: 1.8003313541412354
Validation loss: 2.1694600681463876

Epoch: 5| Step: 4
Training loss: 1.7625808715820312
Validation loss: 2.152812326947848

Epoch: 5| Step: 5
Training loss: 1.5037370920181274
Validation loss: 2.187328721086184

Epoch: 5| Step: 6
Training loss: 1.3156497478485107
Validation loss: 2.1743835310141244

Epoch: 5| Step: 7
Training loss: 2.0333504676818848
Validation loss: 2.1924505283435187

Epoch: 5| Step: 8
Training loss: 2.033271312713623
Validation loss: 2.1708290030558905

Epoch: 5| Step: 9
Training loss: 0.9634566307067871
Validation loss: 2.180413747827212

Epoch: 5| Step: 10
Training loss: 1.3132826089859009
Validation loss: 2.193177953362465

Epoch: 5| Step: 11
Training loss: 1.1028261184692383
Validation loss: 2.1687796811262765

Epoch: 370| Step: 0
Training loss: 1.2799427509307861
Validation loss: 2.1432310044765472

Epoch: 5| Step: 1
Training loss: 1.7891886234283447
Validation loss: 2.1413412243127823

Epoch: 5| Step: 2
Training loss: 0.9653568267822266
Validation loss: 2.1519871801137924

Epoch: 5| Step: 3
Training loss: 1.7221038341522217
Validation loss: 2.1347274482250214

Epoch: 5| Step: 4
Training loss: 1.8510615825653076
Validation loss: 2.134066333373388

Epoch: 5| Step: 5
Training loss: 1.8209022283554077
Validation loss: 2.134725342194239

Epoch: 5| Step: 6
Training loss: 1.6148748397827148
Validation loss: 2.150934358437856

Epoch: 5| Step: 7
Training loss: 1.5406135320663452
Validation loss: 2.1769859393437705

Epoch: 5| Step: 8
Training loss: 1.9427906274795532
Validation loss: 2.1861300071080527

Epoch: 5| Step: 9
Training loss: 1.5176867246627808
Validation loss: 2.175848866502444

Epoch: 5| Step: 10
Training loss: 1.1719889640808105
Validation loss: 2.1701247145732245

Epoch: 5| Step: 11
Training loss: 0.8920357823371887
Validation loss: 2.1732099105914435

Epoch: 371| Step: 0
Training loss: 1.6489217281341553
Validation loss: 2.194810996452967

Epoch: 5| Step: 1
Training loss: 1.3889217376708984
Validation loss: 2.174781233072281

Epoch: 5| Step: 2
Training loss: 1.168891191482544
Validation loss: 2.1743805209795632

Epoch: 5| Step: 3
Training loss: 1.9213409423828125
Validation loss: 2.217503825823466

Epoch: 5| Step: 4
Training loss: 1.697975516319275
Validation loss: 2.1966956555843353

Epoch: 5| Step: 5
Training loss: 1.6195224523544312
Validation loss: 2.1690880904595056

Epoch: 5| Step: 6
Training loss: 1.2174898386001587
Validation loss: 2.180387958884239

Epoch: 5| Step: 7
Training loss: 1.8033548593521118
Validation loss: 2.1568584740161896

Epoch: 5| Step: 8
Training loss: 1.4278522729873657
Validation loss: 2.2109137078126273

Epoch: 5| Step: 9
Training loss: 2.031345844268799
Validation loss: 2.2187146147092185

Epoch: 5| Step: 10
Training loss: 1.4764429330825806
Validation loss: 2.247161308924357

Epoch: 5| Step: 11
Training loss: 1.402073621749878
Validation loss: 2.204920987288157

Epoch: 372| Step: 0
Training loss: 1.4146054983139038
Validation loss: 2.206892525156339

Epoch: 5| Step: 1
Training loss: 1.4345861673355103
Validation loss: 2.20671317478021

Epoch: 5| Step: 2
Training loss: 0.9459772109985352
Validation loss: 2.205959146221479

Epoch: 5| Step: 3
Training loss: 1.7633062601089478
Validation loss: 2.2150542785724006

Epoch: 5| Step: 4
Training loss: 1.6119091510772705
Validation loss: 2.173508654038111

Epoch: 5| Step: 5
Training loss: 1.545527458190918
Validation loss: 2.1878871272007623

Epoch: 5| Step: 6
Training loss: 1.4383535385131836
Validation loss: 2.1987549662590027

Epoch: 5| Step: 7
Training loss: 1.409189224243164
Validation loss: 2.174058119455973

Epoch: 5| Step: 8
Training loss: 1.9167983531951904
Validation loss: 2.151314526796341

Epoch: 5| Step: 9
Training loss: 1.2611067295074463
Validation loss: 2.168127174178759

Epoch: 5| Step: 10
Training loss: 1.7813198566436768
Validation loss: 2.162328451871872

Epoch: 5| Step: 11
Training loss: 2.343873977661133
Validation loss: 2.187096878886223

Epoch: 373| Step: 0
Training loss: 0.9622722864151001
Validation loss: 2.172152395049731

Epoch: 5| Step: 1
Training loss: 2.254500389099121
Validation loss: 2.167311708132426

Epoch: 5| Step: 2
Training loss: 1.4417188167572021
Validation loss: 2.157149910926819

Epoch: 5| Step: 3
Training loss: 1.6474368572235107
Validation loss: 2.177329624692599

Epoch: 5| Step: 4
Training loss: 1.1711995601654053
Validation loss: 2.174560805161794

Epoch: 5| Step: 5
Training loss: 1.1519784927368164
Validation loss: 2.179660732547442

Epoch: 5| Step: 6
Training loss: 1.4806138277053833
Validation loss: 2.1720158954461417

Epoch: 5| Step: 7
Training loss: 2.1511077880859375
Validation loss: 2.2232332030932107

Epoch: 5| Step: 8
Training loss: 1.5740318298339844
Validation loss: 2.1998408337434134

Epoch: 5| Step: 9
Training loss: 1.6004517078399658
Validation loss: 2.1808467457691827

Epoch: 5| Step: 10
Training loss: 1.5709879398345947
Validation loss: 2.1760666370391846

Epoch: 5| Step: 11
Training loss: 1.931326150894165
Validation loss: 2.1951855371395745

Epoch: 374| Step: 0
Training loss: 1.7549587488174438
Validation loss: 2.1728587796290717

Epoch: 5| Step: 1
Training loss: 1.7109358310699463
Validation loss: 2.193796450893084

Epoch: 5| Step: 2
Training loss: 1.0038419961929321
Validation loss: 2.176119416952133

Epoch: 5| Step: 3
Training loss: 2.0755727291107178
Validation loss: 2.1838467021783194

Epoch: 5| Step: 4
Training loss: 1.4969732761383057
Validation loss: 2.1578839818636575

Epoch: 5| Step: 5
Training loss: 1.493346095085144
Validation loss: 2.1472688416639962

Epoch: 5| Step: 6
Training loss: 1.632582664489746
Validation loss: 2.183360666036606

Epoch: 5| Step: 7
Training loss: 1.581552267074585
Validation loss: 2.1758605738480887

Epoch: 5| Step: 8
Training loss: 0.719185471534729
Validation loss: 2.185986320177714

Epoch: 5| Step: 9
Training loss: 1.7312721014022827
Validation loss: 2.151466632882754

Epoch: 5| Step: 10
Training loss: 1.7487175464630127
Validation loss: 2.1553643693526587

Epoch: 5| Step: 11
Training loss: 0.9680927395820618
Validation loss: 2.1510569155216217

Epoch: 375| Step: 0
Training loss: 1.3585904836654663
Validation loss: 2.1818898965915046

Epoch: 5| Step: 1
Training loss: 1.3777058124542236
Validation loss: 2.2009752690792084

Epoch: 5| Step: 2
Training loss: 2.0273489952087402
Validation loss: 2.1903695662816367

Epoch: 5| Step: 3
Training loss: 1.2921041250228882
Validation loss: 2.21121613184611

Epoch: 5| Step: 4
Training loss: 1.3811452388763428
Validation loss: 2.1679429511229196

Epoch: 5| Step: 5
Training loss: 1.314568281173706
Validation loss: 2.1615422864754996

Epoch: 5| Step: 6
Training loss: 1.1120413541793823
Validation loss: 2.158238892753919

Epoch: 5| Step: 7
Training loss: 1.9743175506591797
Validation loss: 2.1634911398092904

Epoch: 5| Step: 8
Training loss: 1.6493337154388428
Validation loss: 2.182955880959829

Epoch: 5| Step: 9
Training loss: 1.7458908557891846
Validation loss: 2.1834128896395364

Epoch: 5| Step: 10
Training loss: 1.5443986654281616
Validation loss: 2.178645392258962

Epoch: 5| Step: 11
Training loss: 2.657970428466797
Validation loss: 2.144597421089808

Epoch: 376| Step: 0
Training loss: 1.1717029809951782
Validation loss: 2.1690466503302255

Epoch: 5| Step: 1
Training loss: 2.139333724975586
Validation loss: 2.1548686027526855

Epoch: 5| Step: 2
Training loss: 1.5877536535263062
Validation loss: 2.17928147315979

Epoch: 5| Step: 3
Training loss: 2.559195041656494
Validation loss: 2.186425358057022

Epoch: 5| Step: 4
Training loss: 0.8862869143486023
Validation loss: 2.197756270567576

Epoch: 5| Step: 5
Training loss: 1.7581716775894165
Validation loss: 2.2004380772511163

Epoch: 5| Step: 6
Training loss: 1.4337995052337646
Validation loss: 2.1645070811112723

Epoch: 5| Step: 7
Training loss: 1.2835824489593506
Validation loss: 2.1894086649020514

Epoch: 5| Step: 8
Training loss: 1.649004340171814
Validation loss: 2.1699870228767395

Epoch: 5| Step: 9
Training loss: 1.893181562423706
Validation loss: 2.165458232164383

Epoch: 5| Step: 10
Training loss: 1.1096771955490112
Validation loss: 2.204073170820872

Epoch: 5| Step: 11
Training loss: 1.4098317623138428
Validation loss: 2.209894046187401

Epoch: 377| Step: 0
Training loss: 1.4374439716339111
Validation loss: 2.1836689561605453

Epoch: 5| Step: 1
Training loss: 2.121875762939453
Validation loss: 2.16681415339311

Epoch: 5| Step: 2
Training loss: 1.132555603981018
Validation loss: 2.173345704873403

Epoch: 5| Step: 3
Training loss: 1.544280767440796
Validation loss: 2.190526286760966

Epoch: 5| Step: 4
Training loss: 1.8015178442001343
Validation loss: 2.183834915359815

Epoch: 5| Step: 5
Training loss: 0.8240039944648743
Validation loss: 2.194126635789871

Epoch: 5| Step: 6
Training loss: 1.7083122730255127
Validation loss: 2.1661725441614785

Epoch: 5| Step: 7
Training loss: 1.6889464855194092
Validation loss: 2.185862789551417

Epoch: 5| Step: 8
Training loss: 1.6716915369033813
Validation loss: 2.22822434703509

Epoch: 5| Step: 9
Training loss: 1.3493088483810425
Validation loss: 2.185375471909841

Epoch: 5| Step: 10
Training loss: 1.640353798866272
Validation loss: 2.182159811258316

Epoch: 5| Step: 11
Training loss: 1.2155201435089111
Validation loss: 2.1649358769257865

Epoch: 378| Step: 0
Training loss: 1.628253698348999
Validation loss: 2.1968073695898056

Epoch: 5| Step: 1
Training loss: 1.7992750406265259
Validation loss: 2.1854980190594993

Epoch: 5| Step: 2
Training loss: 0.857349693775177
Validation loss: 2.1965150088071823

Epoch: 5| Step: 3
Training loss: 1.8705432415008545
Validation loss: 2.1707077572743096

Epoch: 5| Step: 4
Training loss: 2.389876127243042
Validation loss: 2.187360847989718

Epoch: 5| Step: 5
Training loss: 1.7373988628387451
Validation loss: 2.1711183985074363

Epoch: 5| Step: 6
Training loss: 1.4380384683609009
Validation loss: 2.1758100390434265

Epoch: 5| Step: 7
Training loss: 1.4273818731307983
Validation loss: 2.193123330672582

Epoch: 5| Step: 8
Training loss: 0.7873867750167847
Validation loss: 2.224738210439682

Epoch: 5| Step: 9
Training loss: 1.7856611013412476
Validation loss: 2.190692270795504

Epoch: 5| Step: 10
Training loss: 0.8164240717887878
Validation loss: 2.19132008155187

Epoch: 5| Step: 11
Training loss: 2.172588348388672
Validation loss: 2.208027198910713

Epoch: 379| Step: 0
Training loss: 1.8352015018463135
Validation loss: 2.2018303523461022

Epoch: 5| Step: 1
Training loss: 1.5992454290390015
Validation loss: 2.202417562405268

Epoch: 5| Step: 2
Training loss: 1.2822279930114746
Validation loss: 2.2026774883270264

Epoch: 5| Step: 3
Training loss: 1.103628158569336
Validation loss: 2.18280599017938

Epoch: 5| Step: 4
Training loss: 1.0400559902191162
Validation loss: 2.169381062189738

Epoch: 5| Step: 5
Training loss: 1.6921714544296265
Validation loss: 2.1775898138682046

Epoch: 5| Step: 6
Training loss: 1.180395245552063
Validation loss: 2.178894872466723

Epoch: 5| Step: 7
Training loss: 1.7066866159439087
Validation loss: 2.1770341793696084

Epoch: 5| Step: 8
Training loss: 1.741235375404358
Validation loss: 2.1666760245958963

Epoch: 5| Step: 9
Training loss: 2.2303333282470703
Validation loss: 2.1518045415480933

Epoch: 5| Step: 10
Training loss: 1.4577124118804932
Validation loss: 2.1692097087701163

Epoch: 5| Step: 11
Training loss: 1.1055700778961182
Validation loss: 2.1846588850021362

Epoch: 380| Step: 0
Training loss: 2.4820685386657715
Validation loss: 2.178444340825081

Epoch: 5| Step: 1
Training loss: 1.4190324544906616
Validation loss: 2.1703324715296426

Epoch: 5| Step: 2
Training loss: 1.5448232889175415
Validation loss: 2.187769035498301

Epoch: 5| Step: 3
Training loss: 1.4851183891296387
Validation loss: 2.2260455191135406

Epoch: 5| Step: 4
Training loss: 1.065602421760559
Validation loss: 2.1995451152324677

Epoch: 5| Step: 5
Training loss: 0.6275362372398376
Validation loss: 2.180096372961998

Epoch: 5| Step: 6
Training loss: 1.496609091758728
Validation loss: 2.1857949594656625

Epoch: 5| Step: 7
Training loss: 2.0917320251464844
Validation loss: 2.154940480987231

Epoch: 5| Step: 8
Training loss: 1.2259660959243774
Validation loss: 2.1561312576135

Epoch: 5| Step: 9
Training loss: 1.656825304031372
Validation loss: 2.1670783162117004

Epoch: 5| Step: 10
Training loss: 1.8807624578475952
Validation loss: 2.1549045890569687

Epoch: 5| Step: 11
Training loss: 1.342385172843933
Validation loss: 2.174839665492376

Epoch: 381| Step: 0
Training loss: 1.3388615846633911
Validation loss: 2.154130349556605

Epoch: 5| Step: 1
Training loss: 1.9191443920135498
Validation loss: 2.1507250517606735

Epoch: 5| Step: 2
Training loss: 1.5873245000839233
Validation loss: 2.1854412655035653

Epoch: 5| Step: 3
Training loss: 1.4061884880065918
Validation loss: 2.1607561260461807

Epoch: 5| Step: 4
Training loss: 1.281234622001648
Validation loss: 2.1430176893870034

Epoch: 5| Step: 5
Training loss: 1.6805301904678345
Validation loss: 2.1585037261247635

Epoch: 5| Step: 6
Training loss: 1.5727459192276
Validation loss: 2.182131210962931

Epoch: 5| Step: 7
Training loss: 1.1582295894622803
Validation loss: 2.175354316830635

Epoch: 5| Step: 8
Training loss: 2.3102505207061768
Validation loss: 2.2117970238129296

Epoch: 5| Step: 9
Training loss: 1.2081788778305054
Validation loss: 2.223596751689911

Epoch: 5| Step: 10
Training loss: 1.2471165657043457
Validation loss: 2.203099047144254

Epoch: 5| Step: 11
Training loss: 0.6902871131896973
Validation loss: 2.196299354235331

Epoch: 382| Step: 0
Training loss: 1.5254892110824585
Validation loss: 2.173442373673121

Epoch: 5| Step: 1
Training loss: 2.236579418182373
Validation loss: 2.146210571130117

Epoch: 5| Step: 2
Training loss: 1.0503000020980835
Validation loss: 2.168374384442965

Epoch: 5| Step: 3
Training loss: 1.476702094078064
Validation loss: 2.1908120065927505

Epoch: 5| Step: 4
Training loss: 2.1758525371551514
Validation loss: 2.1802711387475333

Epoch: 5| Step: 5
Training loss: 1.2483079433441162
Validation loss: 2.150135656197866

Epoch: 5| Step: 6
Training loss: 1.1656289100646973
Validation loss: 2.1934802482525506

Epoch: 5| Step: 7
Training loss: 1.1274992227554321
Validation loss: 2.1514434268077216

Epoch: 5| Step: 8
Training loss: 1.9406131505966187
Validation loss: 2.196760356426239

Epoch: 5| Step: 9
Training loss: 1.3207865953445435
Validation loss: 2.2208847453196845

Epoch: 5| Step: 10
Training loss: 1.2241719961166382
Validation loss: 2.1861281394958496

Epoch: 5| Step: 11
Training loss: 0.8512611389160156
Validation loss: 2.1995977411667504

Epoch: 383| Step: 0
Training loss: 1.5306148529052734
Validation loss: 2.175236254930496

Epoch: 5| Step: 1
Training loss: 1.4292991161346436
Validation loss: 2.1614054143428802

Epoch: 5| Step: 2
Training loss: 1.8948333263397217
Validation loss: 2.1639254540205

Epoch: 5| Step: 3
Training loss: 1.6445071697235107
Validation loss: 2.165462171037992

Epoch: 5| Step: 4
Training loss: 1.6431363821029663
Validation loss: 2.1896730065345764

Epoch: 5| Step: 5
Training loss: 1.7551047801971436
Validation loss: 2.1947916597127914

Epoch: 5| Step: 6
Training loss: 1.1363760232925415
Validation loss: 2.2129463255405426

Epoch: 5| Step: 7
Training loss: 1.6318538188934326
Validation loss: 2.1976068119208017

Epoch: 5| Step: 8
Training loss: 1.3425915241241455
Validation loss: 2.2012715538342795

Epoch: 5| Step: 9
Training loss: 1.2065162658691406
Validation loss: 2.2087983588377633

Epoch: 5| Step: 10
Training loss: 1.527791976928711
Validation loss: 2.161199743549029

Epoch: 5| Step: 11
Training loss: 2.284010171890259
Validation loss: 2.228454848130544

Epoch: 384| Step: 0
Training loss: 1.429306149482727
Validation loss: 2.200421373049418

Epoch: 5| Step: 1
Training loss: 0.9829099774360657
Validation loss: 2.199379414319992

Epoch: 5| Step: 2
Training loss: 1.0994640588760376
Validation loss: 2.1595063159863153

Epoch: 5| Step: 3
Training loss: 1.396094560623169
Validation loss: 2.175312062104543

Epoch: 5| Step: 4
Training loss: 2.0508525371551514
Validation loss: 2.1844034989674888

Epoch: 5| Step: 5
Training loss: 2.221174716949463
Validation loss: 2.1655778686205545

Epoch: 5| Step: 6
Training loss: 1.6376545429229736
Validation loss: 2.179182584087054

Epoch: 5| Step: 7
Training loss: 2.012340545654297
Validation loss: 2.161072780688604

Epoch: 5| Step: 8
Training loss: 1.2593575716018677
Validation loss: 2.2072358826796212

Epoch: 5| Step: 9
Training loss: 1.8066463470458984
Validation loss: 2.1697206795215607

Epoch: 5| Step: 10
Training loss: 1.254640817642212
Validation loss: 2.159701426823934

Epoch: 5| Step: 11
Training loss: 2.706295967102051
Validation loss: 2.181960105895996

Epoch: 385| Step: 0
Training loss: 1.75885808467865
Validation loss: 2.1604749659697213

Epoch: 5| Step: 1
Training loss: 1.7079006433486938
Validation loss: 2.1663521180550256

Epoch: 5| Step: 2
Training loss: 1.8476098775863647
Validation loss: 2.182942047715187

Epoch: 5| Step: 3
Training loss: 0.9914425611495972
Validation loss: 2.1680224239826202

Epoch: 5| Step: 4
Training loss: 1.490889310836792
Validation loss: 2.1546106239159903

Epoch: 5| Step: 5
Training loss: 1.3725829124450684
Validation loss: 2.1683678030967712

Epoch: 5| Step: 6
Training loss: 1.4018328189849854
Validation loss: 2.1768823812405267

Epoch: 5| Step: 7
Training loss: 1.503222942352295
Validation loss: 2.1831040928761163

Epoch: 5| Step: 8
Training loss: 1.813694715499878
Validation loss: 2.1820120314757028

Epoch: 5| Step: 9
Training loss: 1.4801790714263916
Validation loss: 2.1891425053278604

Epoch: 5| Step: 10
Training loss: 1.3709614276885986
Validation loss: 2.198755736152331

Epoch: 5| Step: 11
Training loss: 2.2286739349365234
Validation loss: 2.1883315443992615

Epoch: 386| Step: 0
Training loss: 1.2652314901351929
Validation loss: 2.1928584029277167

Epoch: 5| Step: 1
Training loss: 1.4859668016433716
Validation loss: 2.182385206222534

Epoch: 5| Step: 2
Training loss: 1.811222791671753
Validation loss: 2.161469335357348

Epoch: 5| Step: 3
Training loss: 1.5089728832244873
Validation loss: 2.188038562734922

Epoch: 5| Step: 4
Training loss: 1.6824455261230469
Validation loss: 2.2025301357110343

Epoch: 5| Step: 5
Training loss: 1.262269377708435
Validation loss: 2.181152572234472

Epoch: 5| Step: 6
Training loss: 1.3119447231292725
Validation loss: 2.160815397898356

Epoch: 5| Step: 7
Training loss: 1.2118057012557983
Validation loss: 2.1884314815203347

Epoch: 5| Step: 8
Training loss: 1.2515757083892822
Validation loss: 2.2001953621705375

Epoch: 5| Step: 9
Training loss: 1.764550805091858
Validation loss: 2.1600315868854523

Epoch: 5| Step: 10
Training loss: 2.082258462905884
Validation loss: 2.1789044042428336

Epoch: 5| Step: 11
Training loss: 0.9813188314437866
Validation loss: 2.1676699072122574

Epoch: 387| Step: 0
Training loss: 1.4352331161499023
Validation loss: 2.1866566787163415

Epoch: 5| Step: 1
Training loss: 1.5120837688446045
Validation loss: 2.2019555866718292

Epoch: 5| Step: 2
Training loss: 1.2024646997451782
Validation loss: 2.199424425760905

Epoch: 5| Step: 3
Training loss: 1.172875165939331
Validation loss: 2.170754830042521

Epoch: 5| Step: 4
Training loss: 2.1923820972442627
Validation loss: 2.1999316612879434

Epoch: 5| Step: 5
Training loss: 1.5074543952941895
Validation loss: 2.1787348786989846

Epoch: 5| Step: 6
Training loss: 1.468252420425415
Validation loss: 2.185777341326078

Epoch: 5| Step: 7
Training loss: 1.8994213342666626
Validation loss: 2.185622066259384

Epoch: 5| Step: 8
Training loss: 1.0867925882339478
Validation loss: 2.154857729872068

Epoch: 5| Step: 9
Training loss: 1.4583678245544434
Validation loss: 2.1843923727671304

Epoch: 5| Step: 10
Training loss: 1.7590153217315674
Validation loss: 2.1462971220413842

Epoch: 5| Step: 11
Training loss: 1.0870221853256226
Validation loss: 2.176497499148051

Epoch: 388| Step: 0
Training loss: 0.9067595601081848
Validation loss: 2.1800120721260705

Epoch: 5| Step: 1
Training loss: 1.5193010568618774
Validation loss: 2.169891724983851

Epoch: 5| Step: 2
Training loss: 1.6171451807022095
Validation loss: 2.1680112332105637

Epoch: 5| Step: 3
Training loss: 1.1798131465911865
Validation loss: 2.166946401198705

Epoch: 5| Step: 4
Training loss: 1.4809973239898682
Validation loss: 2.173383687933286

Epoch: 5| Step: 5
Training loss: 1.8496649265289307
Validation loss: 2.178751657406489

Epoch: 5| Step: 6
Training loss: 1.8966556787490845
Validation loss: 2.17707152167956

Epoch: 5| Step: 7
Training loss: 1.7595748901367188
Validation loss: 2.1702489256858826

Epoch: 5| Step: 8
Training loss: 1.7083606719970703
Validation loss: 2.1599101771910987

Epoch: 5| Step: 9
Training loss: 1.1410399675369263
Validation loss: 2.170065055290858

Epoch: 5| Step: 10
Training loss: 1.2846243381500244
Validation loss: 2.1756737927595773

Epoch: 5| Step: 11
Training loss: 1.939807653427124
Validation loss: 2.15590072174867

Epoch: 389| Step: 0
Training loss: 1.4553390741348267
Validation loss: 2.1625262200832367

Epoch: 5| Step: 1
Training loss: 1.5401159524917603
Validation loss: 2.167129337787628

Epoch: 5| Step: 2
Training loss: 1.4631630182266235
Validation loss: 2.163397287329038

Epoch: 5| Step: 3
Training loss: 1.84678053855896
Validation loss: 2.1698570201794305

Epoch: 5| Step: 4
Training loss: 2.1921005249023438
Validation loss: 2.1579656998316445

Epoch: 5| Step: 5
Training loss: 1.9885238409042358
Validation loss: 2.1551265319188437

Epoch: 5| Step: 6
Training loss: 0.9796947240829468
Validation loss: 2.1679058223962784

Epoch: 5| Step: 7
Training loss: 1.3193305730819702
Validation loss: 2.1560522615909576

Epoch: 5| Step: 8
Training loss: 1.9772064685821533
Validation loss: 2.1464862624804177

Epoch: 5| Step: 9
Training loss: 1.2050540447235107
Validation loss: 2.1316395004590354

Epoch: 5| Step: 10
Training loss: 1.237512230873108
Validation loss: 2.152549554904302

Epoch: 5| Step: 11
Training loss: 0.12366721034049988
Validation loss: 2.158048744002978

Epoch: 390| Step: 0
Training loss: 1.8263590335845947
Validation loss: 2.172052929798762

Epoch: 5| Step: 1
Training loss: 1.2718374729156494
Validation loss: 2.1920376221338906

Epoch: 5| Step: 2
Training loss: 1.2759125232696533
Validation loss: 2.1832650005817413

Epoch: 5| Step: 3
Training loss: 1.71430242061615
Validation loss: 2.1921702226003013

Epoch: 5| Step: 4
Training loss: 1.1096633672714233
Validation loss: 2.141378164291382

Epoch: 5| Step: 5
Training loss: 1.2061913013458252
Validation loss: 2.183564896384875

Epoch: 5| Step: 6
Training loss: 1.1456973552703857
Validation loss: 2.1689235667387643

Epoch: 5| Step: 7
Training loss: 1.2243322134017944
Validation loss: 2.1787538727124534

Epoch: 5| Step: 8
Training loss: 1.6290470361709595
Validation loss: 2.194716905554136

Epoch: 5| Step: 9
Training loss: 1.5403056144714355
Validation loss: 2.1783613363901773

Epoch: 5| Step: 10
Training loss: 1.7904459238052368
Validation loss: 2.1855794340372086

Epoch: 5| Step: 11
Training loss: 3.2667016983032227
Validation loss: 2.2347649931907654

Epoch: 391| Step: 0
Training loss: 1.5695116519927979
Validation loss: 2.2311468670765557

Epoch: 5| Step: 1
Training loss: 1.1043272018432617
Validation loss: 2.2485285003980002

Epoch: 5| Step: 2
Training loss: 1.9403396844863892
Validation loss: 2.213085795442263

Epoch: 5| Step: 3
Training loss: 1.805047631263733
Validation loss: 2.178167685866356

Epoch: 5| Step: 4
Training loss: 1.1297032833099365
Validation loss: 2.141028200586637

Epoch: 5| Step: 5
Training loss: 1.1448538303375244
Validation loss: 2.1554565529028573

Epoch: 5| Step: 6
Training loss: 1.23081374168396
Validation loss: 2.1273371974627175

Epoch: 5| Step: 7
Training loss: 2.150752067565918
Validation loss: 2.12874473631382

Epoch: 5| Step: 8
Training loss: 1.1921943426132202
Validation loss: 2.1457742949326835

Epoch: 5| Step: 9
Training loss: 1.593287467956543
Validation loss: 2.1204489966233573

Epoch: 5| Step: 10
Training loss: 1.5865623950958252
Validation loss: 2.1480289896329245

Epoch: 5| Step: 11
Training loss: 2.619776725769043
Validation loss: 2.169866293668747

Epoch: 392| Step: 0
Training loss: 1.4082483053207397
Validation loss: 2.141933331886927

Epoch: 5| Step: 1
Training loss: 0.9987162351608276
Validation loss: 2.1250819712877274

Epoch: 5| Step: 2
Training loss: 1.1554343700408936
Validation loss: 2.1496107478936515

Epoch: 5| Step: 3
Training loss: 1.6164567470550537
Validation loss: 2.184911623597145

Epoch: 5| Step: 4
Training loss: 1.1682960987091064
Validation loss: 2.1609388987223306

Epoch: 5| Step: 5
Training loss: 1.139850378036499
Validation loss: 2.157113860050837

Epoch: 5| Step: 6
Training loss: 1.97379469871521
Validation loss: 2.1715412735939026

Epoch: 5| Step: 7
Training loss: 1.0186265707015991
Validation loss: 2.1632473468780518

Epoch: 5| Step: 8
Training loss: 1.846097707748413
Validation loss: 2.166005477309227

Epoch: 5| Step: 9
Training loss: 1.887918472290039
Validation loss: 2.1575781802336373

Epoch: 5| Step: 10
Training loss: 1.6756623983383179
Validation loss: 2.1521117438872657

Epoch: 5| Step: 11
Training loss: 2.123353958129883
Validation loss: 2.1991085559129715

Epoch: 393| Step: 0
Training loss: 2.138350248336792
Validation loss: 2.1326704720656076

Epoch: 5| Step: 1
Training loss: 1.191157579421997
Validation loss: 2.147562712430954

Epoch: 5| Step: 2
Training loss: 1.1854677200317383
Validation loss: 2.222007781267166

Epoch: 5| Step: 3
Training loss: 1.548205018043518
Validation loss: 2.226865202188492

Epoch: 5| Step: 4
Training loss: 1.5176379680633545
Validation loss: 2.2363652487595878

Epoch: 5| Step: 5
Training loss: 1.3897334337234497
Validation loss: 2.2133499681949615

Epoch: 5| Step: 6
Training loss: 1.7201926708221436
Validation loss: 2.26338263352712

Epoch: 5| Step: 7
Training loss: 1.7450706958770752
Validation loss: 2.2724058479070663

Epoch: 5| Step: 8
Training loss: 1.1432504653930664
Validation loss: 2.2533960243066153

Epoch: 5| Step: 9
Training loss: 1.668028473854065
Validation loss: 2.213647941748301

Epoch: 5| Step: 10
Training loss: 1.711941123008728
Validation loss: 2.1774985045194626

Epoch: 5| Step: 11
Training loss: 0.7372254133224487
Validation loss: 2.19435287018617

Epoch: 394| Step: 0
Training loss: 1.0655614137649536
Validation loss: 2.205784410238266

Epoch: 5| Step: 1
Training loss: 1.7942501306533813
Validation loss: 2.1887963811556497

Epoch: 5| Step: 2
Training loss: 1.2559120655059814
Validation loss: 2.1847183108329773

Epoch: 5| Step: 3
Training loss: 1.767676591873169
Validation loss: 2.16459588209788

Epoch: 5| Step: 4
Training loss: 1.4587434530258179
Validation loss: 2.156879335641861

Epoch: 5| Step: 5
Training loss: 1.2625844478607178
Validation loss: 2.142096837361654

Epoch: 5| Step: 6
Training loss: 2.0680065155029297
Validation loss: 2.1407352685928345

Epoch: 5| Step: 7
Training loss: 1.1379915475845337
Validation loss: 2.2052961587905884

Epoch: 5| Step: 8
Training loss: 0.9325779676437378
Validation loss: 2.199201007684072

Epoch: 5| Step: 9
Training loss: 1.574070930480957
Validation loss: 2.1845405995845795

Epoch: 5| Step: 10
Training loss: 1.5970172882080078
Validation loss: 2.188460578521093

Epoch: 5| Step: 11
Training loss: 2.4545140266418457
Validation loss: 2.1574214895566306

Epoch: 395| Step: 0
Training loss: 1.2291654348373413
Validation loss: 2.2154830743869147

Epoch: 5| Step: 1
Training loss: 1.0532176494598389
Validation loss: 2.1854430735111237

Epoch: 5| Step: 2
Training loss: 1.2827098369598389
Validation loss: 2.199323902527491

Epoch: 5| Step: 3
Training loss: 1.0506572723388672
Validation loss: 2.1694687058528266

Epoch: 5| Step: 4
Training loss: 1.3576380014419556
Validation loss: 2.148772343993187

Epoch: 5| Step: 5
Training loss: 1.4498862028121948
Validation loss: 2.1688747505346933

Epoch: 5| Step: 6
Training loss: 1.126938819885254
Validation loss: 2.182975322008133

Epoch: 5| Step: 7
Training loss: 1.4620290994644165
Validation loss: 2.1858365635077157

Epoch: 5| Step: 8
Training loss: 1.5212510824203491
Validation loss: 2.1908340652783713

Epoch: 5| Step: 9
Training loss: 2.256011962890625
Validation loss: 2.1821484764417014

Epoch: 5| Step: 10
Training loss: 2.0946621894836426
Validation loss: 2.196815421183904

Epoch: 5| Step: 11
Training loss: 2.263495683670044
Validation loss: 2.205715149641037

Epoch: 396| Step: 0
Training loss: 1.1294199228286743
Validation loss: 2.198291540145874

Epoch: 5| Step: 1
Training loss: 1.6577565670013428
Validation loss: 2.1927149842182794

Epoch: 5| Step: 2
Training loss: 1.3922903537750244
Validation loss: 2.2296096086502075

Epoch: 5| Step: 3
Training loss: 2.0930135250091553
Validation loss: 2.214797019958496

Epoch: 5| Step: 4
Training loss: 1.0878386497497559
Validation loss: 2.1471379548311234

Epoch: 5| Step: 5
Training loss: 1.4537298679351807
Validation loss: 2.206296443939209

Epoch: 5| Step: 6
Training loss: 1.1657112836837769
Validation loss: 2.1568627655506134

Epoch: 5| Step: 7
Training loss: 1.9985218048095703
Validation loss: 2.1782040297985077

Epoch: 5| Step: 8
Training loss: 1.436539649963379
Validation loss: 2.200070932507515

Epoch: 5| Step: 9
Training loss: 1.4929630756378174
Validation loss: 2.183100332816442

Epoch: 5| Step: 10
Training loss: 1.4108104705810547
Validation loss: 2.1937144994735718

Epoch: 5| Step: 11
Training loss: 1.9451042413711548
Validation loss: 2.158984621365865

Epoch: 397| Step: 0
Training loss: 1.6356532573699951
Validation loss: 2.172551323970159

Epoch: 5| Step: 1
Training loss: 1.511613130569458
Validation loss: 2.205011487007141

Epoch: 5| Step: 2
Training loss: 1.905413269996643
Validation loss: 2.2407398919264474

Epoch: 5| Step: 3
Training loss: 1.700650930404663
Validation loss: 2.267881671587626

Epoch: 5| Step: 4
Training loss: 1.3782778978347778
Validation loss: 2.2587730387846627

Epoch: 5| Step: 5
Training loss: 2.0562846660614014
Validation loss: 2.249525854984919

Epoch: 5| Step: 6
Training loss: 1.451615571975708
Validation loss: 2.2331390033165612

Epoch: 5| Step: 7
Training loss: 1.4300940036773682
Validation loss: 2.2176249474287033

Epoch: 5| Step: 8
Training loss: 1.1239323616027832
Validation loss: 2.200097228089968

Epoch: 5| Step: 9
Training loss: 1.8637826442718506
Validation loss: 2.168387790520986

Epoch: 5| Step: 10
Training loss: 0.9971801042556763
Validation loss: 2.164202799399694

Epoch: 5| Step: 11
Training loss: 1.4497393369674683
Validation loss: 2.179870734612147

Epoch: 398| Step: 0
Training loss: 1.532172441482544
Validation loss: 2.1751135289669037

Epoch: 5| Step: 1
Training loss: 0.8982970118522644
Validation loss: 2.1671113669872284

Epoch: 5| Step: 2
Training loss: 1.395604133605957
Validation loss: 2.180023784438769

Epoch: 5| Step: 3
Training loss: 1.1690089702606201
Validation loss: 2.1722944925228753

Epoch: 5| Step: 4
Training loss: 1.565080165863037
Validation loss: 2.1257989406585693

Epoch: 5| Step: 5
Training loss: 1.4300391674041748
Validation loss: 2.1770433336496353

Epoch: 5| Step: 6
Training loss: 1.8857676982879639
Validation loss: 2.173360824584961

Epoch: 5| Step: 7
Training loss: 1.4528157711029053
Validation loss: 2.165238454937935

Epoch: 5| Step: 8
Training loss: 1.4140260219573975
Validation loss: 2.120574802160263

Epoch: 5| Step: 9
Training loss: 1.900669813156128
Validation loss: 2.1171771387259164

Epoch: 5| Step: 10
Training loss: 1.5061914920806885
Validation loss: 2.149440551797549

Epoch: 5| Step: 11
Training loss: 1.2202751636505127
Validation loss: 2.172082086404165

Epoch: 399| Step: 0
Training loss: 1.6642682552337646
Validation loss: 2.1683356761932373

Epoch: 5| Step: 1
Training loss: 1.1057865619659424
Validation loss: 2.1756535371144614

Epoch: 5| Step: 2
Training loss: 1.230463981628418
Validation loss: 2.1523048977057138

Epoch: 5| Step: 3
Training loss: 1.818526268005371
Validation loss: 2.1870578229427338

Epoch: 5| Step: 4
Training loss: 1.1455341577529907
Validation loss: 2.1534090091784797

Epoch: 5| Step: 5
Training loss: 1.7057498693466187
Validation loss: 2.1711801290512085

Epoch: 5| Step: 6
Training loss: 1.2205173969268799
Validation loss: 2.1597445656855903

Epoch: 5| Step: 7
Training loss: 1.72593092918396
Validation loss: 2.1850070556004844

Epoch: 5| Step: 8
Training loss: 1.984121561050415
Validation loss: 2.175031696756681

Epoch: 5| Step: 9
Training loss: 1.430735468864441
Validation loss: 2.2017711997032166

Epoch: 5| Step: 10
Training loss: 1.3103244304656982
Validation loss: 2.1898629615704217

Epoch: 5| Step: 11
Training loss: 2.771383047103882
Validation loss: 2.1675829341014228

Epoch: 400| Step: 0
Training loss: 1.8389856815338135
Validation loss: 2.2004724641640983

Epoch: 5| Step: 1
Training loss: 1.244993805885315
Validation loss: 2.1969491044680276

Epoch: 5| Step: 2
Training loss: 1.376098871231079
Validation loss: 2.1741288204987845

Epoch: 5| Step: 3
Training loss: 1.839508295059204
Validation loss: 2.169701705376307

Epoch: 5| Step: 4
Training loss: 1.6262496709823608
Validation loss: 2.185441255569458

Epoch: 5| Step: 5
Training loss: 1.1240246295928955
Validation loss: 2.170709098378817

Epoch: 5| Step: 6
Training loss: 0.9824479818344116
Validation loss: 2.176303048928579

Epoch: 5| Step: 7
Training loss: 1.6136856079101562
Validation loss: 2.2139770140250525

Epoch: 5| Step: 8
Training loss: 1.5686309337615967
Validation loss: 2.1828681031862893

Epoch: 5| Step: 9
Training loss: 1.400154709815979
Validation loss: 2.1936158488194146

Epoch: 5| Step: 10
Training loss: 1.1322664022445679
Validation loss: 2.1845543384552

Epoch: 5| Step: 11
Training loss: 0.963115930557251
Validation loss: 2.144697388013204

Epoch: 401| Step: 0
Training loss: 1.892858862876892
Validation loss: 2.1910815834999084

Epoch: 5| Step: 1
Training loss: 1.1529995203018188
Validation loss: 2.1950552662213645

Epoch: 5| Step: 2
Training loss: 1.3688881397247314
Validation loss: 2.2266274889310202

Epoch: 5| Step: 3
Training loss: 1.5919393301010132
Validation loss: 2.199241891503334

Epoch: 5| Step: 4
Training loss: 1.572049856185913
Validation loss: 2.191522022088369

Epoch: 5| Step: 5
Training loss: 1.6426738500595093
Validation loss: 2.190059413512548

Epoch: 5| Step: 6
Training loss: 1.4434887170791626
Validation loss: 2.1960734824339547

Epoch: 5| Step: 7
Training loss: 1.7022063732147217
Validation loss: 2.171334609389305

Epoch: 5| Step: 8
Training loss: 1.5143389701843262
Validation loss: 2.212187851468722

Epoch: 5| Step: 9
Training loss: 0.9227501749992371
Validation loss: 2.1900166968504586

Epoch: 5| Step: 10
Training loss: 1.5323331356048584
Validation loss: 2.224329779545466

Epoch: 5| Step: 11
Training loss: 1.4931540489196777
Validation loss: 2.2129333317279816

Epoch: 402| Step: 0
Training loss: 1.4432880878448486
Validation loss: 2.166624208291372

Epoch: 5| Step: 1
Training loss: 1.4725843667984009
Validation loss: 2.1995533257722855

Epoch: 5| Step: 2
Training loss: 1.3413922786712646
Validation loss: 2.168421601255735

Epoch: 5| Step: 3
Training loss: 1.68009352684021
Validation loss: 2.167981912692388

Epoch: 5| Step: 4
Training loss: 1.0689961910247803
Validation loss: 2.181439975897471

Epoch: 5| Step: 5
Training loss: 1.5748730897903442
Validation loss: 2.181364506483078

Epoch: 5| Step: 6
Training loss: 1.5632145404815674
Validation loss: 2.187190671761831

Epoch: 5| Step: 7
Training loss: 1.3311092853546143
Validation loss: 2.171855350335439

Epoch: 5| Step: 8
Training loss: 1.8087501525878906
Validation loss: 2.150797059138616

Epoch: 5| Step: 9
Training loss: 1.122693657875061
Validation loss: 2.1565732657909393

Epoch: 5| Step: 10
Training loss: 1.2303537130355835
Validation loss: 2.2134663661321006

Epoch: 5| Step: 11
Training loss: 0.3611874282360077
Validation loss: 2.169934719800949

Epoch: 403| Step: 0
Training loss: 2.149744749069214
Validation loss: 2.1331064701080322

Epoch: 5| Step: 1
Training loss: 1.4398497343063354
Validation loss: 2.207644576827685

Epoch: 5| Step: 2
Training loss: 1.4328877925872803
Validation loss: 2.240151062607765

Epoch: 5| Step: 3
Training loss: 1.202548623085022
Validation loss: 2.169135178128878

Epoch: 5| Step: 4
Training loss: 1.8055397272109985
Validation loss: 2.166400690873464

Epoch: 5| Step: 5
Training loss: 1.059303641319275
Validation loss: 2.203736583391825

Epoch: 5| Step: 6
Training loss: 1.8204727172851562
Validation loss: 2.220195929209391

Epoch: 5| Step: 7
Training loss: 1.1839442253112793
Validation loss: 2.2036979695161185

Epoch: 5| Step: 8
Training loss: 1.4696975946426392
Validation loss: 2.206705997387568

Epoch: 5| Step: 9
Training loss: 1.5911121368408203
Validation loss: 2.1916825026273727

Epoch: 5| Step: 10
Training loss: 1.2128336429595947
Validation loss: 2.205657730499903

Epoch: 5| Step: 11
Training loss: 1.093667984008789
Validation loss: 2.2246210475762687

Epoch: 404| Step: 0
Training loss: 1.0303514003753662
Validation loss: 2.227575605114301

Epoch: 5| Step: 1
Training loss: 1.4709115028381348
Validation loss: 2.20871102809906

Epoch: 5| Step: 2
Training loss: 1.2767612934112549
Validation loss: 2.2198724697033563

Epoch: 5| Step: 3
Training loss: 1.820307970046997
Validation loss: 2.1714486678441367

Epoch: 5| Step: 4
Training loss: 1.4140065908432007
Validation loss: 2.201884999871254

Epoch: 5| Step: 5
Training loss: 1.4025863409042358
Validation loss: 2.1706096877654395

Epoch: 5| Step: 6
Training loss: 1.5658881664276123
Validation loss: 2.210032989581426

Epoch: 5| Step: 7
Training loss: 0.7205063104629517
Validation loss: 2.187390834093094

Epoch: 5| Step: 8
Training loss: 1.6024420261383057
Validation loss: 2.2091189424196878

Epoch: 5| Step: 9
Training loss: 2.0953803062438965
Validation loss: 2.187547246615092

Epoch: 5| Step: 10
Training loss: 1.2644469738006592
Validation loss: 2.214706684152285

Epoch: 5| Step: 11
Training loss: 0.9668827056884766
Validation loss: 2.2125090261300406

Epoch: 405| Step: 0
Training loss: 2.1484456062316895
Validation loss: 2.186093270778656

Epoch: 5| Step: 1
Training loss: 1.3121278285980225
Validation loss: 2.184547965725263

Epoch: 5| Step: 2
Training loss: 1.0179226398468018
Validation loss: 2.1910232255856195

Epoch: 5| Step: 3
Training loss: 1.5819180011749268
Validation loss: 2.194810221592585

Epoch: 5| Step: 4
Training loss: 1.5793263912200928
Validation loss: 2.1797564774751663

Epoch: 5| Step: 5
Training loss: 1.6860195398330688
Validation loss: 2.165534476439158

Epoch: 5| Step: 6
Training loss: 0.8861019015312195
Validation loss: 2.1880208800236383

Epoch: 5| Step: 7
Training loss: 1.5131876468658447
Validation loss: 2.1986803809801736

Epoch: 5| Step: 8
Training loss: 0.8936293721199036
Validation loss: 2.1970376670360565

Epoch: 5| Step: 9
Training loss: 1.724493384361267
Validation loss: 2.196855833133062

Epoch: 5| Step: 10
Training loss: 1.3960601091384888
Validation loss: 2.17660682896773

Epoch: 5| Step: 11
Training loss: 1.0848095417022705
Validation loss: 2.1903462459643683

Epoch: 406| Step: 0
Training loss: 1.415652871131897
Validation loss: 2.1894304901361465

Epoch: 5| Step: 1
Training loss: 1.0593042373657227
Validation loss: 2.215358783801397

Epoch: 5| Step: 2
Training loss: 1.4100487232208252
Validation loss: 2.1847390284140906

Epoch: 5| Step: 3
Training loss: 1.536498785018921
Validation loss: 2.196940466761589

Epoch: 5| Step: 4
Training loss: 2.053706407546997
Validation loss: 2.164975514014562

Epoch: 5| Step: 5
Training loss: 0.9119170904159546
Validation loss: 2.162868767976761

Epoch: 5| Step: 6
Training loss: 1.3738327026367188
Validation loss: 2.195788323879242

Epoch: 5| Step: 7
Training loss: 1.7528711557388306
Validation loss: 2.165865510702133

Epoch: 5| Step: 8
Training loss: 0.7507911920547485
Validation loss: 2.2060570120811462

Epoch: 5| Step: 9
Training loss: 1.6731199026107788
Validation loss: 2.2094647586345673

Epoch: 5| Step: 10
Training loss: 0.8388561010360718
Validation loss: 2.176617701848348

Epoch: 5| Step: 11
Training loss: 2.3465423583984375
Validation loss: 2.199257800976435

Epoch: 407| Step: 0
Training loss: 1.5291073322296143
Validation loss: 2.168094610174497

Epoch: 5| Step: 1
Training loss: 0.8616325259208679
Validation loss: 2.151820262273153

Epoch: 5| Step: 2
Training loss: 1.015377402305603
Validation loss: 2.1910107185443244

Epoch: 5| Step: 3
Training loss: 1.6193056106567383
Validation loss: 2.1722692996263504

Epoch: 5| Step: 4
Training loss: 1.0532361268997192
Validation loss: 2.1689807126919427

Epoch: 5| Step: 5
Training loss: 0.9976285099983215
Validation loss: 2.1665235310792923

Epoch: 5| Step: 6
Training loss: 1.494653582572937
Validation loss: 2.168674806753794

Epoch: 5| Step: 7
Training loss: 2.022829294204712
Validation loss: 2.1800206204255423

Epoch: 5| Step: 8
Training loss: 2.0272457599639893
Validation loss: 2.182539482911428

Epoch: 5| Step: 9
Training loss: 1.5832353830337524
Validation loss: 2.185193434357643

Epoch: 5| Step: 10
Training loss: 1.3790127038955688
Validation loss: 2.1796902219454446

Epoch: 5| Step: 11
Training loss: 1.460432529449463
Validation loss: 2.150578702489535

Epoch: 408| Step: 0
Training loss: 1.5165517330169678
Validation loss: 2.1862263282140098

Epoch: 5| Step: 1
Training loss: 1.4431171417236328
Validation loss: 2.1851087311903634

Epoch: 5| Step: 2
Training loss: 1.034841537475586
Validation loss: 2.1589344491561255

Epoch: 5| Step: 3
Training loss: 1.4405981302261353
Validation loss: 2.159516195456187

Epoch: 5| Step: 4
Training loss: 1.0986740589141846
Validation loss: 2.157281388839086

Epoch: 5| Step: 5
Training loss: 1.7925037145614624
Validation loss: 2.1797935366630554

Epoch: 5| Step: 6
Training loss: 1.2056562900543213
Validation loss: 2.162492881218592

Epoch: 5| Step: 7
Training loss: 1.4477698802947998
Validation loss: 2.1643516967693963

Epoch: 5| Step: 8
Training loss: 1.7902863025665283
Validation loss: 2.1522517601648965

Epoch: 5| Step: 9
Training loss: 0.8051629066467285
Validation loss: 2.186425487200419

Epoch: 5| Step: 10
Training loss: 1.5907505750656128
Validation loss: 2.1562855541706085

Epoch: 5| Step: 11
Training loss: 0.9967018365859985
Validation loss: 2.1556278069814048

Epoch: 409| Step: 0
Training loss: 1.0180672407150269
Validation loss: 2.1588016202052436

Epoch: 5| Step: 1
Training loss: 1.2335907220840454
Validation loss: 2.157757043838501

Epoch: 5| Step: 2
Training loss: 0.820469081401825
Validation loss: 2.176157553990682

Epoch: 5| Step: 3
Training loss: 2.1165692806243896
Validation loss: 2.159112979968389

Epoch: 5| Step: 4
Training loss: 1.5739072561264038
Validation loss: 2.1826851218938828

Epoch: 5| Step: 5
Training loss: 1.758042335510254
Validation loss: 2.1659674843152366

Epoch: 5| Step: 6
Training loss: 1.4276235103607178
Validation loss: 2.1232934345801673

Epoch: 5| Step: 7
Training loss: 1.523221731185913
Validation loss: 2.1621071050564447

Epoch: 5| Step: 8
Training loss: 1.5002801418304443
Validation loss: 2.1799696534872055

Epoch: 5| Step: 9
Training loss: 1.2851083278656006
Validation loss: 2.1688185731569924

Epoch: 5| Step: 10
Training loss: 1.4150497913360596
Validation loss: 2.1583247979482016

Epoch: 5| Step: 11
Training loss: 0.77131187915802
Validation loss: 2.1592330088218055

Epoch: 410| Step: 0
Training loss: 1.4182636737823486
Validation loss: 2.13775572180748

Epoch: 5| Step: 1
Training loss: 1.1285974979400635
Validation loss: 2.1346229861179986

Epoch: 5| Step: 2
Training loss: 1.1022605895996094
Validation loss: 2.1169191797574363

Epoch: 5| Step: 3
Training loss: 1.8203998804092407
Validation loss: 2.169920106728872

Epoch: 5| Step: 4
Training loss: 1.4396965503692627
Validation loss: 2.1527249018351235

Epoch: 5| Step: 5
Training loss: 1.3278100490570068
Validation loss: 2.1259593218564987

Epoch: 5| Step: 6
Training loss: 1.1402897834777832
Validation loss: 2.135374759634336

Epoch: 5| Step: 7
Training loss: 1.2633880376815796
Validation loss: 2.1413905123869577

Epoch: 5| Step: 8
Training loss: 1.8870410919189453
Validation loss: 2.1931297729412713

Epoch: 5| Step: 9
Training loss: 1.052685260772705
Validation loss: 2.167518044511477

Epoch: 5| Step: 10
Training loss: 1.562496542930603
Validation loss: 2.1349473545948663

Epoch: 5| Step: 11
Training loss: 0.9451247453689575
Validation loss: 2.1527899156014123

Epoch: 411| Step: 0
Training loss: 1.2150232791900635
Validation loss: 2.150209749738375

Epoch: 5| Step: 1
Training loss: 1.1921221017837524
Validation loss: 2.175996328393618

Epoch: 5| Step: 2
Training loss: 1.6940408945083618
Validation loss: 2.149733612934748

Epoch: 5| Step: 3
Training loss: 1.4755127429962158
Validation loss: 2.1727525889873505

Epoch: 5| Step: 4
Training loss: 1.1540979146957397
Validation loss: 2.161028648416201

Epoch: 5| Step: 5
Training loss: 1.6159870624542236
Validation loss: 2.177863672375679

Epoch: 5| Step: 6
Training loss: 1.124292254447937
Validation loss: 2.1762848695119223

Epoch: 5| Step: 7
Training loss: 1.2738386392593384
Validation loss: 2.169787327448527

Epoch: 5| Step: 8
Training loss: 1.9571406841278076
Validation loss: 2.1843621283769608

Epoch: 5| Step: 9
Training loss: 0.9974687695503235
Validation loss: 2.1829620798428855

Epoch: 5| Step: 10
Training loss: 1.1606227159500122
Validation loss: 2.1753435681263604

Epoch: 5| Step: 11
Training loss: 0.4701293110847473
Validation loss: 2.1703881174325943

Epoch: 412| Step: 0
Training loss: 1.6288881301879883
Validation loss: 2.157657022277514

Epoch: 5| Step: 1
Training loss: 1.4712762832641602
Validation loss: 2.1554714838663735

Epoch: 5| Step: 2
Training loss: 1.1150232553482056
Validation loss: 2.1734373470147452

Epoch: 5| Step: 3
Training loss: 1.0694395303726196
Validation loss: 2.147928590575854

Epoch: 5| Step: 4
Training loss: 1.677433729171753
Validation loss: 2.1392400364081063

Epoch: 5| Step: 5
Training loss: 0.863752007484436
Validation loss: 2.1886150439580283

Epoch: 5| Step: 6
Training loss: 2.1589415073394775
Validation loss: 2.171827962001165

Epoch: 5| Step: 7
Training loss: 1.5096538066864014
Validation loss: 2.1755677461624146

Epoch: 5| Step: 8
Training loss: 1.5340384244918823
Validation loss: 2.177968184153239

Epoch: 5| Step: 9
Training loss: 1.287837028503418
Validation loss: 2.1762644549210868

Epoch: 5| Step: 10
Training loss: 1.642870545387268
Validation loss: 2.1709468315045037

Epoch: 5| Step: 11
Training loss: 1.255234956741333
Validation loss: 2.1493674516677856

Epoch: 413| Step: 0
Training loss: 2.1885533332824707
Validation loss: 2.134056950608889

Epoch: 5| Step: 1
Training loss: 1.6552451848983765
Validation loss: 2.165749336282412

Epoch: 5| Step: 2
Training loss: 0.8901815414428711
Validation loss: 2.1442405680815377

Epoch: 5| Step: 3
Training loss: 1.1787971258163452
Validation loss: 2.0999353329340615

Epoch: 5| Step: 4
Training loss: 1.3695685863494873
Validation loss: 2.162475993235906

Epoch: 5| Step: 5
Training loss: 1.0951894521713257
Validation loss: 2.160950909058253

Epoch: 5| Step: 6
Training loss: 1.4095677137374878
Validation loss: 2.1599837094545364

Epoch: 5| Step: 7
Training loss: 1.8936344385147095
Validation loss: 2.178599918882052

Epoch: 5| Step: 8
Training loss: 0.8969975709915161
Validation loss: 2.184737652540207

Epoch: 5| Step: 9
Training loss: 1.609310507774353
Validation loss: 2.194447120030721

Epoch: 5| Step: 10
Training loss: 1.5987322330474854
Validation loss: 2.161962936321894

Epoch: 5| Step: 11
Training loss: 1.4666712284088135
Validation loss: 2.2007320324579873

Epoch: 414| Step: 0
Training loss: 0.7260950207710266
Validation loss: 2.1833047618468604

Epoch: 5| Step: 1
Training loss: 1.2363446950912476
Validation loss: 2.1750227957963943

Epoch: 5| Step: 2
Training loss: 1.059874176979065
Validation loss: 2.1539121866226196

Epoch: 5| Step: 3
Training loss: 2.14453387260437
Validation loss: 2.1430679261684418

Epoch: 5| Step: 4
Training loss: 1.9463239908218384
Validation loss: 2.1584843595822654

Epoch: 5| Step: 5
Training loss: 1.9626188278198242
Validation loss: 2.144957979520162

Epoch: 5| Step: 6
Training loss: 1.3091403245925903
Validation loss: 2.1235866794983544

Epoch: 5| Step: 7
Training loss: 1.5598360300064087
Validation loss: 2.1510885804891586

Epoch: 5| Step: 8
Training loss: 1.3389266729354858
Validation loss: 2.1171064525842667

Epoch: 5| Step: 9
Training loss: 1.603804588317871
Validation loss: 2.148334781328837

Epoch: 5| Step: 10
Training loss: 0.7871760129928589
Validation loss: 2.1246284494797387

Epoch: 5| Step: 11
Training loss: 1.4628485441207886
Validation loss: 2.1136656999588013

Epoch: 415| Step: 0
Training loss: 1.3720500469207764
Validation loss: 2.1230419228474298

Epoch: 5| Step: 1
Training loss: 1.3176225423812866
Validation loss: 2.1095745166142783

Epoch: 5| Step: 2
Training loss: 1.9248600006103516
Validation loss: 2.11549041668574

Epoch: 5| Step: 3
Training loss: 1.6366466283798218
Validation loss: 2.1133326590061188

Epoch: 5| Step: 4
Training loss: 1.4271167516708374
Validation loss: 2.140582248568535

Epoch: 5| Step: 5
Training loss: 1.6134265661239624
Validation loss: 2.1502572198708854

Epoch: 5| Step: 6
Training loss: 1.4414418935775757
Validation loss: 2.085759753982226

Epoch: 5| Step: 7
Training loss: 1.1925840377807617
Validation loss: 2.095330839355787

Epoch: 5| Step: 8
Training loss: 1.2286689281463623
Validation loss: 2.1220318426688514

Epoch: 5| Step: 9
Training loss: 0.9977569580078125
Validation loss: 2.182449166973432

Epoch: 5| Step: 10
Training loss: 1.213977575302124
Validation loss: 2.1514233350753784

Epoch: 5| Step: 11
Training loss: 1.222693920135498
Validation loss: 2.2095829943815866

Epoch: 416| Step: 0
Training loss: 1.1408270597457886
Validation loss: 2.1318883150815964

Epoch: 5| Step: 1
Training loss: 1.2354896068572998
Validation loss: 2.179764355222384

Epoch: 5| Step: 2
Training loss: 1.0522631406784058
Validation loss: 2.1871020098527274

Epoch: 5| Step: 3
Training loss: 1.6968584060668945
Validation loss: 2.2006736596425376

Epoch: 5| Step: 4
Training loss: 1.766090750694275
Validation loss: 2.1922131876150766

Epoch: 5| Step: 5
Training loss: 1.4317984580993652
Validation loss: 2.1956666707992554

Epoch: 5| Step: 6
Training loss: 1.7259857654571533
Validation loss: 2.1820572266976037

Epoch: 5| Step: 7
Training loss: 1.227691888809204
Validation loss: 2.1842898031075797

Epoch: 5| Step: 8
Training loss: 1.3884189128875732
Validation loss: 2.1667663951714835

Epoch: 5| Step: 9
Training loss: 0.8241615295410156
Validation loss: 2.1519166777531304

Epoch: 5| Step: 10
Training loss: 1.7708314657211304
Validation loss: 2.199078674117724

Epoch: 5| Step: 11
Training loss: 1.204795241355896
Validation loss: 2.1951956202586493

Epoch: 417| Step: 0
Training loss: 1.339448094367981
Validation loss: 2.1592818101247153

Epoch: 5| Step: 1
Training loss: 1.9715900421142578
Validation loss: 2.1550806562105813

Epoch: 5| Step: 2
Training loss: 0.6898226737976074
Validation loss: 2.1147953867912292

Epoch: 5| Step: 3
Training loss: 1.629847526550293
Validation loss: 2.1028886636098227

Epoch: 5| Step: 4
Training loss: 1.2494550943374634
Validation loss: 2.127400388320287

Epoch: 5| Step: 5
Training loss: 1.1397695541381836
Validation loss: 2.140042558312416

Epoch: 5| Step: 6
Training loss: 1.8862578868865967
Validation loss: 2.137921785314878

Epoch: 5| Step: 7
Training loss: 1.749259352684021
Validation loss: 2.1109610497951508

Epoch: 5| Step: 8
Training loss: 1.39258873462677
Validation loss: 2.159183452526728

Epoch: 5| Step: 9
Training loss: 1.1277673244476318
Validation loss: 2.1773049434026084

Epoch: 5| Step: 10
Training loss: 1.1422640085220337
Validation loss: 2.181242893139521

Epoch: 5| Step: 11
Training loss: 1.4905019998550415
Validation loss: 2.1797015418608985

Epoch: 418| Step: 0
Training loss: 1.4009664058685303
Validation loss: 2.176086977124214

Epoch: 5| Step: 1
Training loss: 1.7138826847076416
Validation loss: 2.1824951469898224

Epoch: 5| Step: 2
Training loss: 1.2933437824249268
Validation loss: 2.0973269691069922

Epoch: 5| Step: 3
Training loss: 1.4210922718048096
Validation loss: 2.1307945350805917

Epoch: 5| Step: 4
Training loss: 1.2454383373260498
Validation loss: 2.1030571858088174

Epoch: 5| Step: 5
Training loss: 1.375086784362793
Validation loss: 2.152272234360377

Epoch: 5| Step: 6
Training loss: 1.2261666059494019
Validation loss: 2.1350932319959006

Epoch: 5| Step: 7
Training loss: 1.2377350330352783
Validation loss: 2.1797152906656265

Epoch: 5| Step: 8
Training loss: 1.305187702178955
Validation loss: 2.186983361840248

Epoch: 5| Step: 9
Training loss: 1.806890845298767
Validation loss: 2.168157637119293

Epoch: 5| Step: 10
Training loss: 0.9770280718803406
Validation loss: 2.1905051171779633

Epoch: 5| Step: 11
Training loss: 1.0466558933258057
Validation loss: 2.156550705432892

Epoch: 419| Step: 0
Training loss: 1.0492579936981201
Validation loss: 2.183249374230703

Epoch: 5| Step: 1
Training loss: 1.5698707103729248
Validation loss: 2.1770174403985343

Epoch: 5| Step: 2
Training loss: 1.32135009765625
Validation loss: 2.1824593047300973

Epoch: 5| Step: 3
Training loss: 1.596933126449585
Validation loss: 2.146203935146332

Epoch: 5| Step: 4
Training loss: 1.0105773210525513
Validation loss: 2.1592437823613486

Epoch: 5| Step: 5
Training loss: 1.3478825092315674
Validation loss: 2.1777108758687973

Epoch: 5| Step: 6
Training loss: 1.0783231258392334
Validation loss: 2.112214853366216

Epoch: 5| Step: 7
Training loss: 1.3368985652923584
Validation loss: 2.1855373829603195

Epoch: 5| Step: 8
Training loss: 1.4927058219909668
Validation loss: 2.12456314265728

Epoch: 5| Step: 9
Training loss: 1.6900478601455688
Validation loss: 2.1548901001612344

Epoch: 5| Step: 10
Training loss: 1.3388476371765137
Validation loss: 2.1190653840700784

Epoch: 5| Step: 11
Training loss: 1.9409700632095337
Validation loss: 2.1551122715075812

Epoch: 420| Step: 0
Training loss: 1.1383705139160156
Validation loss: 2.1717491894960403

Epoch: 5| Step: 1
Training loss: 1.0978065729141235
Validation loss: 2.1611067056655884

Epoch: 5| Step: 2
Training loss: 1.4943768978118896
Validation loss: 2.1847783426443734

Epoch: 5| Step: 3
Training loss: 1.0885809659957886
Validation loss: 2.166860818862915

Epoch: 5| Step: 4
Training loss: 1.373458981513977
Validation loss: 2.1951509515444436

Epoch: 5| Step: 5
Training loss: 1.0351841449737549
Validation loss: 2.149579112728437

Epoch: 5| Step: 6
Training loss: 1.8146079778671265
Validation loss: 2.1385640501976013

Epoch: 5| Step: 7
Training loss: 1.3109750747680664
Validation loss: 2.1338294645150504

Epoch: 5| Step: 8
Training loss: 1.7110557556152344
Validation loss: 2.1132504840691886

Epoch: 5| Step: 9
Training loss: 2.030656337738037
Validation loss: 2.169851770003637

Epoch: 5| Step: 10
Training loss: 1.6409780979156494
Validation loss: 2.1385122338930764

Epoch: 5| Step: 11
Training loss: 0.3972584009170532
Validation loss: 2.149298831820488

Epoch: 421| Step: 0
Training loss: 1.1255894899368286
Validation loss: 2.1366174519062042

Epoch: 5| Step: 1
Training loss: 0.8961095809936523
Validation loss: 2.1963760604461036

Epoch: 5| Step: 2
Training loss: 1.3298438787460327
Validation loss: 2.17020937303702

Epoch: 5| Step: 3
Training loss: 1.3685338497161865
Validation loss: 2.1370553423961005

Epoch: 5| Step: 4
Training loss: 1.6577837467193604
Validation loss: 2.2223814030488334

Epoch: 5| Step: 5
Training loss: 1.4447801113128662
Validation loss: 2.161082992951075

Epoch: 5| Step: 6
Training loss: 0.8433391451835632
Validation loss: 2.1713792035977044

Epoch: 5| Step: 7
Training loss: 1.7392444610595703
Validation loss: 2.1982043782869973

Epoch: 5| Step: 8
Training loss: 1.6391537189483643
Validation loss: 2.1870045910278955

Epoch: 5| Step: 9
Training loss: 1.5215790271759033
Validation loss: 2.193480213483175

Epoch: 5| Step: 10
Training loss: 1.054168701171875
Validation loss: 2.1940831343332925

Epoch: 5| Step: 11
Training loss: 1.7946046590805054
Validation loss: 2.141484315196673

Epoch: 422| Step: 0
Training loss: 0.9702032208442688
Validation loss: 2.144526481628418

Epoch: 5| Step: 1
Training loss: 1.8683624267578125
Validation loss: 2.194338634610176

Epoch: 5| Step: 2
Training loss: 1.1688436269760132
Validation loss: 2.168387328584989

Epoch: 5| Step: 3
Training loss: 1.4292469024658203
Validation loss: 2.197931761542956

Epoch: 5| Step: 4
Training loss: 1.4352065324783325
Validation loss: 2.2171224554379783

Epoch: 5| Step: 5
Training loss: 1.3396804332733154
Validation loss: 2.21269557873408

Epoch: 5| Step: 6
Training loss: 1.8930193185806274
Validation loss: 2.1884805311759314

Epoch: 5| Step: 7
Training loss: 1.6010935306549072
Validation loss: 2.180405547221502

Epoch: 5| Step: 8
Training loss: 1.4828178882598877
Validation loss: 2.196773345271746

Epoch: 5| Step: 9
Training loss: 0.9171808362007141
Validation loss: 2.2497577518224716

Epoch: 5| Step: 10
Training loss: 1.2838711738586426
Validation loss: 2.2250554859638214

Epoch: 5| Step: 11
Training loss: 0.5798509120941162
Validation loss: 2.1781408935785294

Epoch: 423| Step: 0
Training loss: 1.4800994396209717
Validation loss: 2.216872811317444

Epoch: 5| Step: 1
Training loss: 1.8944551944732666
Validation loss: 2.1564066807428994

Epoch: 5| Step: 2
Training loss: 0.871442973613739
Validation loss: 2.128202423453331

Epoch: 5| Step: 3
Training loss: 1.2036962509155273
Validation loss: 2.1459298580884933

Epoch: 5| Step: 4
Training loss: 1.8275524377822876
Validation loss: 2.145630195736885

Epoch: 5| Step: 5
Training loss: 1.1434993743896484
Validation loss: 2.1530729482571282

Epoch: 5| Step: 6
Training loss: 1.4238182306289673
Validation loss: 2.169772818684578

Epoch: 5| Step: 7
Training loss: 2.2105345726013184
Validation loss: 2.1693848371505737

Epoch: 5| Step: 8
Training loss: 0.7657912969589233
Validation loss: 2.1800640573104224

Epoch: 5| Step: 9
Training loss: 1.264463186264038
Validation loss: 2.1458249539136887

Epoch: 5| Step: 10
Training loss: 1.0743353366851807
Validation loss: 2.1702336370944977

Epoch: 5| Step: 11
Training loss: 0.5669783353805542
Validation loss: 2.182935819029808

Epoch: 424| Step: 0
Training loss: 1.454285740852356
Validation loss: 2.1721709122260413

Epoch: 5| Step: 1
Training loss: 1.20291006565094
Validation loss: 2.200066417455673

Epoch: 5| Step: 2
Training loss: 1.761714220046997
Validation loss: 2.191042428215345

Epoch: 5| Step: 3
Training loss: 1.7133064270019531
Validation loss: 2.1887578666210175

Epoch: 5| Step: 4
Training loss: 2.0664281845092773
Validation loss: 2.1758085787296295

Epoch: 5| Step: 5
Training loss: 1.5874924659729004
Validation loss: 2.1189418584108353

Epoch: 5| Step: 6
Training loss: 1.0093530416488647
Validation loss: 2.1559103280305862

Epoch: 5| Step: 7
Training loss: 1.7534071207046509
Validation loss: 2.1488557358582816

Epoch: 5| Step: 8
Training loss: 1.2161585092544556
Validation loss: 2.1641955574353537

Epoch: 5| Step: 9
Training loss: 1.7295423746109009
Validation loss: 2.1441145787636438

Epoch: 5| Step: 10
Training loss: 1.3588329553604126
Validation loss: 2.1118275622526803

Epoch: 5| Step: 11
Training loss: 0.9745355844497681
Validation loss: 2.1600541720787683

Epoch: 425| Step: 0
Training loss: 1.4594439268112183
Validation loss: 2.1632687151432037

Epoch: 5| Step: 1
Training loss: 0.6036215424537659
Validation loss: 2.177094280719757

Epoch: 5| Step: 2
Training loss: 1.7867475748062134
Validation loss: 2.194006452957789

Epoch: 5| Step: 3
Training loss: 1.4501639604568481
Validation loss: 2.18852029244105

Epoch: 5| Step: 4
Training loss: 1.8071037530899048
Validation loss: 2.182612826426824

Epoch: 5| Step: 5
Training loss: 1.3316707611083984
Validation loss: 2.1434916655222573

Epoch: 5| Step: 6
Training loss: 0.990608811378479
Validation loss: 2.179951657851537

Epoch: 5| Step: 7
Training loss: 1.1805343627929688
Validation loss: 2.129050925374031

Epoch: 5| Step: 8
Training loss: 1.500684142112732
Validation loss: 2.098847215374311

Epoch: 5| Step: 9
Training loss: 1.613295555114746
Validation loss: 2.135023077329

Epoch: 5| Step: 10
Training loss: 1.196533441543579
Validation loss: 2.093104586005211

Epoch: 5| Step: 11
Training loss: 1.9770994186401367
Validation loss: 2.1419143031040826

Epoch: 426| Step: 0
Training loss: 0.9999375343322754
Validation loss: 2.19500362376372

Epoch: 5| Step: 1
Training loss: 1.1094675064086914
Validation loss: 2.1083012024561563

Epoch: 5| Step: 2
Training loss: 1.3135648965835571
Validation loss: 2.136473129192988

Epoch: 5| Step: 3
Training loss: 1.3806343078613281
Validation loss: 2.1600254476070404

Epoch: 5| Step: 4
Training loss: 1.4949692487716675
Validation loss: 2.195163627465566

Epoch: 5| Step: 5
Training loss: 0.7936004400253296
Validation loss: 2.153251419464747

Epoch: 5| Step: 6
Training loss: 1.5230305194854736
Validation loss: 2.183675910035769

Epoch: 5| Step: 7
Training loss: 1.797602653503418
Validation loss: 2.173577517271042

Epoch: 5| Step: 8
Training loss: 1.6234004497528076
Validation loss: 2.1890310843785605

Epoch: 5| Step: 9
Training loss: 1.0619503259658813
Validation loss: 2.162750447789828

Epoch: 5| Step: 10
Training loss: 1.306862235069275
Validation loss: 2.170335685213407

Epoch: 5| Step: 11
Training loss: 1.9095968008041382
Validation loss: 2.2097333669662476

Epoch: 427| Step: 0
Training loss: 1.4445006847381592
Validation loss: 2.168828621506691

Epoch: 5| Step: 1
Training loss: 1.839159369468689
Validation loss: 2.168915569782257

Epoch: 5| Step: 2
Training loss: 1.299469232559204
Validation loss: 2.186076670885086

Epoch: 5| Step: 3
Training loss: 0.8413211703300476
Validation loss: 2.1814675430456796

Epoch: 5| Step: 4
Training loss: 0.6435171365737915
Validation loss: 2.164236396551132

Epoch: 5| Step: 5
Training loss: 1.607778549194336
Validation loss: 2.141486639777819

Epoch: 5| Step: 6
Training loss: 2.0237367153167725
Validation loss: 2.1266033301750817

Epoch: 5| Step: 7
Training loss: 1.5605050325393677
Validation loss: 2.147251178820928

Epoch: 5| Step: 8
Training loss: 1.6179540157318115
Validation loss: 2.0876055657863617

Epoch: 5| Step: 9
Training loss: 1.176201581954956
Validation loss: 2.1004454592863717

Epoch: 5| Step: 10
Training loss: 0.864345371723175
Validation loss: 2.13884299993515

Epoch: 5| Step: 11
Training loss: 1.5843572616577148
Validation loss: 2.119553099075953

Epoch: 428| Step: 0
Training loss: 1.2609258890151978
Validation loss: 2.1620846589406333

Epoch: 5| Step: 1
Training loss: 0.9073561429977417
Validation loss: 2.1507812291383743

Epoch: 5| Step: 2
Training loss: 1.7154510021209717
Validation loss: 2.1218295196692147

Epoch: 5| Step: 3
Training loss: 1.6277341842651367
Validation loss: 2.1422746082146964

Epoch: 5| Step: 4
Training loss: 1.4715873003005981
Validation loss: 2.1826608777046204

Epoch: 5| Step: 5
Training loss: 1.6184844970703125
Validation loss: 2.157271300752958

Epoch: 5| Step: 6
Training loss: 0.9432902336120605
Validation loss: 2.1787095814943314

Epoch: 5| Step: 7
Training loss: 1.231250524520874
Validation loss: 2.1698122968276343

Epoch: 5| Step: 8
Training loss: 1.3018478155136108
Validation loss: 2.19334052503109

Epoch: 5| Step: 9
Training loss: 1.3790183067321777
Validation loss: 2.203640361626943

Epoch: 5| Step: 10
Training loss: 1.0839101076126099
Validation loss: 2.1807528336842856

Epoch: 5| Step: 11
Training loss: 1.925668478012085
Validation loss: 2.186937431494395

Epoch: 429| Step: 0
Training loss: 1.3883981704711914
Validation loss: 2.1872193614641824

Epoch: 5| Step: 1
Training loss: 1.312942385673523
Validation loss: 2.182048345605532

Epoch: 5| Step: 2
Training loss: 1.6317241191864014
Validation loss: 2.205462098121643

Epoch: 5| Step: 3
Training loss: 1.4415541887283325
Validation loss: 2.2049561540285745

Epoch: 5| Step: 4
Training loss: 1.2000648975372314
Validation loss: 2.214848577976227

Epoch: 5| Step: 5
Training loss: 0.7425609827041626
Validation loss: 2.1786673168341317

Epoch: 5| Step: 6
Training loss: 1.1991889476776123
Validation loss: 2.1631335566441217

Epoch: 5| Step: 7
Training loss: 1.7139759063720703
Validation loss: 2.165059899290403

Epoch: 5| Step: 8
Training loss: 1.130838394165039
Validation loss: 2.099827046195666

Epoch: 5| Step: 9
Training loss: 1.8518234491348267
Validation loss: 2.1441391011079154

Epoch: 5| Step: 10
Training loss: 1.0562717914581299
Validation loss: 2.1340061773856482

Epoch: 5| Step: 11
Training loss: 0.574487030506134
Validation loss: 2.1374872624874115

Epoch: 430| Step: 0
Training loss: 0.9366162419319153
Validation loss: 2.1277357588211694

Epoch: 5| Step: 1
Training loss: 1.2183396816253662
Validation loss: 2.1257051626841226

Epoch: 5| Step: 2
Training loss: 1.0084102153778076
Validation loss: 2.1217005451520285

Epoch: 5| Step: 3
Training loss: 1.6303393840789795
Validation loss: 2.132430776953697

Epoch: 5| Step: 4
Training loss: 1.821891188621521
Validation loss: 2.1274050076802573

Epoch: 5| Step: 5
Training loss: 0.928223729133606
Validation loss: 2.1079385032256446

Epoch: 5| Step: 6
Training loss: 1.9114574193954468
Validation loss: 2.1071044504642487

Epoch: 5| Step: 7
Training loss: 0.9454565048217773
Validation loss: 2.08109088242054

Epoch: 5| Step: 8
Training loss: 1.4792261123657227
Validation loss: 2.148650864760081

Epoch: 5| Step: 9
Training loss: 1.391817569732666
Validation loss: 2.097448950012525

Epoch: 5| Step: 10
Training loss: 1.0844625234603882
Validation loss: 2.126722981532415

Epoch: 5| Step: 11
Training loss: 3.102487802505493
Validation loss: 2.128110999862353

Epoch: 431| Step: 0
Training loss: 1.3060493469238281
Validation loss: 2.1311510105927787

Epoch: 5| Step: 1
Training loss: 1.454353928565979
Validation loss: 2.1481462121009827

Epoch: 5| Step: 2
Training loss: 1.1007404327392578
Validation loss: 2.088792289296786

Epoch: 5| Step: 3
Training loss: 2.3210203647613525
Validation loss: 2.093024253845215

Epoch: 5| Step: 4
Training loss: 1.157694697380066
Validation loss: 2.0837186872959137

Epoch: 5| Step: 5
Training loss: 1.8641620874404907
Validation loss: 2.06704447666804

Epoch: 5| Step: 6
Training loss: 1.2855136394500732
Validation loss: 2.0934234211842218

Epoch: 5| Step: 7
Training loss: 1.3528892993927002
Validation loss: 2.0923691242933273

Epoch: 5| Step: 8
Training loss: 0.954371452331543
Validation loss: 2.144700492421786

Epoch: 5| Step: 9
Training loss: 0.8089467287063599
Validation loss: 2.126796970764796

Epoch: 5| Step: 10
Training loss: 1.651188611984253
Validation loss: 2.1106610695521035

Epoch: 5| Step: 11
Training loss: 0.8057822585105896
Validation loss: 2.150989050666491

Epoch: 432| Step: 0
Training loss: 1.3743823766708374
Validation loss: 2.1846326192220054

Epoch: 5| Step: 1
Training loss: 1.5862925052642822
Validation loss: 2.139342059691747

Epoch: 5| Step: 2
Training loss: 1.5470460653305054
Validation loss: 2.122820387283961

Epoch: 5| Step: 3
Training loss: 1.6075338125228882
Validation loss: 2.1013784954945245

Epoch: 5| Step: 4
Training loss: 1.3150533437728882
Validation loss: 2.1148758232593536

Epoch: 5| Step: 5
Training loss: 1.3841354846954346
Validation loss: 2.128672887881597

Epoch: 5| Step: 6
Training loss: 1.5333458185195923
Validation loss: 2.1300807942946753

Epoch: 5| Step: 7
Training loss: 1.2390891313552856
Validation loss: 2.1036697030067444

Epoch: 5| Step: 8
Training loss: 0.6299504041671753
Validation loss: 2.139496237039566

Epoch: 5| Step: 9
Training loss: 1.1679199934005737
Validation loss: 2.1267573634783425

Epoch: 5| Step: 10
Training loss: 1.203686237335205
Validation loss: 2.118960360685984

Epoch: 5| Step: 11
Training loss: 0.8627674579620361
Validation loss: 2.152101625998815

Epoch: 433| Step: 0
Training loss: 1.4988912343978882
Validation loss: 2.163520763317744

Epoch: 5| Step: 1
Training loss: 1.6604297161102295
Validation loss: 2.1831413408120475

Epoch: 5| Step: 2
Training loss: 1.2661776542663574
Validation loss: 2.1621652841567993

Epoch: 5| Step: 3
Training loss: 1.1713831424713135
Validation loss: 2.1406795581181846

Epoch: 5| Step: 4
Training loss: 0.8186529874801636
Validation loss: 2.1277409295241037

Epoch: 5| Step: 5
Training loss: 1.3106982707977295
Validation loss: 2.09055366118749

Epoch: 5| Step: 6
Training loss: 1.4826716184616089
Validation loss: 2.110528379678726

Epoch: 5| Step: 7
Training loss: 1.1882076263427734
Validation loss: 2.124407301346461

Epoch: 5| Step: 8
Training loss: 1.274147629737854
Validation loss: 2.119260758161545

Epoch: 5| Step: 9
Training loss: 1.2925684452056885
Validation loss: 2.1636789043744407

Epoch: 5| Step: 10
Training loss: 1.8953638076782227
Validation loss: 2.1553065925836563

Epoch: 5| Step: 11
Training loss: 1.67489492893219
Validation loss: 2.1750064690907798

Epoch: 434| Step: 0
Training loss: 1.5747673511505127
Validation loss: 2.148063912987709

Epoch: 5| Step: 1
Training loss: 1.1388696432113647
Validation loss: 2.185499608516693

Epoch: 5| Step: 2
Training loss: 1.6988427639007568
Validation loss: 2.2193292578061423

Epoch: 5| Step: 3
Training loss: 1.4215002059936523
Validation loss: 2.1864925771951675

Epoch: 5| Step: 4
Training loss: 1.8763649463653564
Validation loss: 2.206385592619578

Epoch: 5| Step: 5
Training loss: 1.9165489673614502
Validation loss: 2.163998082280159

Epoch: 5| Step: 6
Training loss: 1.077071189880371
Validation loss: 2.1600028773148856

Epoch: 5| Step: 7
Training loss: 1.314598798751831
Validation loss: 2.1821120530366898

Epoch: 5| Step: 8
Training loss: 1.2014999389648438
Validation loss: 2.193465237816175

Epoch: 5| Step: 9
Training loss: 0.9066104888916016
Validation loss: 2.193962593873342

Epoch: 5| Step: 10
Training loss: 1.3375657796859741
Validation loss: 2.152745227018992

Epoch: 5| Step: 11
Training loss: 0.8306195139884949
Validation loss: 2.203463599085808

Epoch: 435| Step: 0
Training loss: 0.7722305059432983
Validation loss: 2.1635959843794503

Epoch: 5| Step: 1
Training loss: 1.602163553237915
Validation loss: 2.1999191343784332

Epoch: 5| Step: 2
Training loss: 1.4376980066299438
Validation loss: 2.2190693616867065

Epoch: 5| Step: 3
Training loss: 1.1237051486968994
Validation loss: 2.207386781771978

Epoch: 5| Step: 4
Training loss: 1.3186485767364502
Validation loss: 2.194484973947207

Epoch: 5| Step: 5
Training loss: 1.4462039470672607
Validation loss: 2.2123219122489295

Epoch: 5| Step: 6
Training loss: 1.3899013996124268
Validation loss: 2.177922328313192

Epoch: 5| Step: 7
Training loss: 1.4405145645141602
Validation loss: 2.1580143918593726

Epoch: 5| Step: 8
Training loss: 1.011579990386963
Validation loss: 2.1665644894043603

Epoch: 5| Step: 9
Training loss: 1.7574503421783447
Validation loss: 2.192724590500196

Epoch: 5| Step: 10
Training loss: 1.3987858295440674
Validation loss: 2.1747140685717263

Epoch: 5| Step: 11
Training loss: 0.5123591423034668
Validation loss: 2.1862515211105347

Epoch: 436| Step: 0
Training loss: 0.9775439500808716
Validation loss: 2.1910058856010437

Epoch: 5| Step: 1
Training loss: 0.5920774340629578
Validation loss: 2.2012675752242408

Epoch: 5| Step: 2
Training loss: 1.5420416593551636
Validation loss: 2.2317391683657966

Epoch: 5| Step: 3
Training loss: 1.5375899076461792
Validation loss: 2.2084176490704217

Epoch: 5| Step: 4
Training loss: 1.6724729537963867
Validation loss: 2.22142530977726

Epoch: 5| Step: 5
Training loss: 0.5851143002510071
Validation loss: 2.209827949603399

Epoch: 5| Step: 6
Training loss: 2.145766258239746
Validation loss: 2.184688384334246

Epoch: 5| Step: 7
Training loss: 0.8425958752632141
Validation loss: 2.1853525042533875

Epoch: 5| Step: 8
Training loss: 1.4698476791381836
Validation loss: 2.179316431283951

Epoch: 5| Step: 9
Training loss: 1.0124422311782837
Validation loss: 2.197284087538719

Epoch: 5| Step: 10
Training loss: 1.9840307235717773
Validation loss: 2.2368088960647583

Epoch: 5| Step: 11
Training loss: 1.0717835426330566
Validation loss: 2.244785060485204

Epoch: 437| Step: 0
Training loss: 1.1748813390731812
Validation loss: 2.1499215761820474

Epoch: 5| Step: 1
Training loss: 1.1514253616333008
Validation loss: 2.1936040073633194

Epoch: 5| Step: 2
Training loss: 1.7018318176269531
Validation loss: 2.1861491749684014

Epoch: 5| Step: 3
Training loss: 1.7536113262176514
Validation loss: 2.2203912138938904

Epoch: 5| Step: 4
Training loss: 0.9053375124931335
Validation loss: 2.237090195218722

Epoch: 5| Step: 5
Training loss: 1.9223512411117554
Validation loss: 2.2258305797974267

Epoch: 5| Step: 6
Training loss: 1.5660415887832642
Validation loss: 2.218762238820394

Epoch: 5| Step: 7
Training loss: 1.21828031539917
Validation loss: 2.2288259913523993

Epoch: 5| Step: 8
Training loss: 1.730769395828247
Validation loss: 2.209821507334709

Epoch: 5| Step: 9
Training loss: 0.9795560836791992
Validation loss: 2.181524003545443

Epoch: 5| Step: 10
Training loss: 0.7728910446166992
Validation loss: 2.1637322207291922

Epoch: 5| Step: 11
Training loss: 0.8193271160125732
Validation loss: 2.1681272784868875

Epoch: 438| Step: 0
Training loss: 0.8806843757629395
Validation loss: 2.129839996496836

Epoch: 5| Step: 1
Training loss: 1.386978268623352
Validation loss: 2.195794999599457

Epoch: 5| Step: 2
Training loss: 1.2224223613739014
Validation loss: 2.202710891763369

Epoch: 5| Step: 3
Training loss: 1.4350825548171997
Validation loss: 2.2136832078297934

Epoch: 5| Step: 4
Training loss: 1.2578709125518799
Validation loss: 2.208781878153483

Epoch: 5| Step: 5
Training loss: 1.1136387586593628
Validation loss: 2.2168734769026437

Epoch: 5| Step: 6
Training loss: 1.9462602138519287
Validation loss: 2.216805482904116

Epoch: 5| Step: 7
Training loss: 1.5095735788345337
Validation loss: 2.2165010472138724

Epoch: 5| Step: 8
Training loss: 0.909302830696106
Validation loss: 2.2347016483545303

Epoch: 5| Step: 9
Training loss: 1.4899427890777588
Validation loss: 2.1737136195103326

Epoch: 5| Step: 10
Training loss: 0.85926353931427
Validation loss: 2.1328506022691727

Epoch: 5| Step: 11
Training loss: 3.7223591804504395
Validation loss: 2.1837250789006553

Epoch: 439| Step: 0
Training loss: 1.272679090499878
Validation loss: 2.1627319554487863

Epoch: 5| Step: 1
Training loss: 1.238665223121643
Validation loss: 2.1607072899738946

Epoch: 5| Step: 2
Training loss: 1.3194483518600464
Validation loss: 2.1854511499404907

Epoch: 5| Step: 3
Training loss: 1.3050639629364014
Validation loss: 2.1728207021951675

Epoch: 5| Step: 4
Training loss: 1.0108931064605713
Validation loss: 2.1959946155548096

Epoch: 5| Step: 5
Training loss: 0.8229542970657349
Validation loss: 2.2202388991912207

Epoch: 5| Step: 6
Training loss: 1.3372198343276978
Validation loss: 2.202848548690478

Epoch: 5| Step: 7
Training loss: 1.5769670009613037
Validation loss: 2.185948838790258

Epoch: 5| Step: 8
Training loss: 1.335787296295166
Validation loss: 2.1956672171751657

Epoch: 5| Step: 9
Training loss: 1.3068935871124268
Validation loss: 2.1817821065584817

Epoch: 5| Step: 10
Training loss: 2.014298915863037
Validation loss: 2.1627148191134133

Epoch: 5| Step: 11
Training loss: 1.1290266513824463
Validation loss: 2.1514061242341995

Epoch: 440| Step: 0
Training loss: 1.2868582010269165
Validation loss: 2.1832882463932037

Epoch: 5| Step: 1
Training loss: 1.2211394309997559
Validation loss: 2.1655377447605133

Epoch: 5| Step: 2
Training loss: 1.523324728012085
Validation loss: 2.154646764198939

Epoch: 5| Step: 3
Training loss: 0.9107184410095215
Validation loss: 2.188870136936506

Epoch: 5| Step: 4
Training loss: 0.8600224256515503
Validation loss: 2.1692342261473336

Epoch: 5| Step: 5
Training loss: 1.0462576150894165
Validation loss: 2.1502376397450766

Epoch: 5| Step: 6
Training loss: 1.6000587940216064
Validation loss: 2.1541530191898346

Epoch: 5| Step: 7
Training loss: 1.016030192375183
Validation loss: 2.1707669297854104

Epoch: 5| Step: 8
Training loss: 1.2046877145767212
Validation loss: 2.1547645777463913

Epoch: 5| Step: 9
Training loss: 2.22646427154541
Validation loss: 2.1897875467936196

Epoch: 5| Step: 10
Training loss: 1.2988945245742798
Validation loss: 2.111927638451258

Epoch: 5| Step: 11
Training loss: 1.0007702112197876
Validation loss: 2.1553844114144645

Epoch: 441| Step: 0
Training loss: 0.8488363027572632
Validation loss: 2.1701619923114777

Epoch: 5| Step: 1
Training loss: 1.372257947921753
Validation loss: 2.1606986274321875

Epoch: 5| Step: 2
Training loss: 1.0761808156967163
Validation loss: 2.1396416078011193

Epoch: 5| Step: 3
Training loss: 1.3999273777008057
Validation loss: 2.154071052869161

Epoch: 5| Step: 4
Training loss: 0.8298414349555969
Validation loss: 2.135099470615387

Epoch: 5| Step: 5
Training loss: 1.122328281402588
Validation loss: 2.1652950048446655

Epoch: 5| Step: 6
Training loss: 1.347638726234436
Validation loss: 2.117353101571401

Epoch: 5| Step: 7
Training loss: 1.3926990032196045
Validation loss: 2.130014811952909

Epoch: 5| Step: 8
Training loss: 1.759502649307251
Validation loss: 2.130821108818054

Epoch: 5| Step: 9
Training loss: 1.3264126777648926
Validation loss: 2.113225355744362

Epoch: 5| Step: 10
Training loss: 1.7558342218399048
Validation loss: 2.185715268055598

Epoch: 5| Step: 11
Training loss: 1.036487340927124
Validation loss: 2.2007148265838623

Epoch: 442| Step: 0
Training loss: 1.164602518081665
Validation loss: 2.18415629863739

Epoch: 5| Step: 1
Training loss: 1.4992393255233765
Validation loss: 2.200322757164637

Epoch: 5| Step: 2
Training loss: 1.002038836479187
Validation loss: 2.1895373662312827

Epoch: 5| Step: 3
Training loss: 1.090238332748413
Validation loss: 2.1772264689207077

Epoch: 5| Step: 4
Training loss: 1.5595015287399292
Validation loss: 2.181773548324903

Epoch: 5| Step: 5
Training loss: 1.186776876449585
Validation loss: 2.134584923585256

Epoch: 5| Step: 6
Training loss: 1.038110613822937
Validation loss: 2.184934139251709

Epoch: 5| Step: 7
Training loss: 1.4952322244644165
Validation loss: 2.134917433063189

Epoch: 5| Step: 8
Training loss: 1.154431700706482
Validation loss: 2.1423675467570624

Epoch: 5| Step: 9
Training loss: 0.9920194745063782
Validation loss: 2.1172252347071967

Epoch: 5| Step: 10
Training loss: 1.1421209573745728
Validation loss: 2.183647632598877

Epoch: 5| Step: 11
Training loss: 3.297102928161621
Validation loss: 2.1685725301504135

Epoch: 443| Step: 0
Training loss: 0.9792024493217468
Validation loss: 2.192423313856125

Epoch: 5| Step: 1
Training loss: 1.4720144271850586
Validation loss: 2.1656092007954917

Epoch: 5| Step: 2
Training loss: 0.8415462374687195
Validation loss: 2.201004604498545

Epoch: 5| Step: 3
Training loss: 1.157536506652832
Validation loss: 2.2164525588353476

Epoch: 5| Step: 4
Training loss: 1.4494394063949585
Validation loss: 2.1690238217512765

Epoch: 5| Step: 5
Training loss: 1.767987847328186
Validation loss: 2.2345017393430076

Epoch: 5| Step: 6
Training loss: 1.728586196899414
Validation loss: 2.186863919099172

Epoch: 5| Step: 7
Training loss: 0.8994596600532532
Validation loss: 2.1763042211532593

Epoch: 5| Step: 8
Training loss: 1.0019114017486572
Validation loss: 2.17715747654438

Epoch: 5| Step: 9
Training loss: 1.8151432275772095
Validation loss: 2.183794846137365

Epoch: 5| Step: 10
Training loss: 0.907611072063446
Validation loss: 2.153185094396273

Epoch: 5| Step: 11
Training loss: 1.950439453125
Validation loss: 2.190439209342003

Epoch: 444| Step: 0
Training loss: 1.0377217531204224
Validation loss: 2.211985558271408

Epoch: 5| Step: 1
Training loss: 0.9656535387039185
Validation loss: 2.199379468957583

Epoch: 5| Step: 2
Training loss: 1.4727833271026611
Validation loss: 2.1846779932578406

Epoch: 5| Step: 3
Training loss: 1.5982240438461304
Validation loss: 2.1266389737526574

Epoch: 5| Step: 4
Training loss: 1.1772041320800781
Validation loss: 2.1713807582855225

Epoch: 5| Step: 5
Training loss: 1.1657328605651855
Validation loss: 2.122867008050283

Epoch: 5| Step: 6
Training loss: 1.5090440511703491
Validation loss: 2.1320752799510956

Epoch: 5| Step: 7
Training loss: 0.8496158719062805
Validation loss: 2.1564878175656

Epoch: 5| Step: 8
Training loss: 0.9747211337089539
Validation loss: 2.144015669822693

Epoch: 5| Step: 9
Training loss: 1.586946964263916
Validation loss: 2.1416118840376535

Epoch: 5| Step: 10
Training loss: 1.7746236324310303
Validation loss: 2.190403232971827

Epoch: 5| Step: 11
Training loss: 0.6000432968139648
Validation loss: 2.1411936481793723

Epoch: 445| Step: 0
Training loss: 1.5404775142669678
Validation loss: 2.1470981438954673

Epoch: 5| Step: 1
Training loss: 1.037574291229248
Validation loss: 2.136347239216169

Epoch: 5| Step: 2
Training loss: 1.489036202430725
Validation loss: 2.1149580031633377

Epoch: 5| Step: 3
Training loss: 0.9676599502563477
Validation loss: 2.1796153485774994

Epoch: 5| Step: 4
Training loss: 1.0324897766113281
Validation loss: 2.1350651333729425

Epoch: 5| Step: 5
Training loss: 1.1125746965408325
Validation loss: 2.1360410700241723

Epoch: 5| Step: 6
Training loss: 1.0468852519989014
Validation loss: 2.1562074571847916

Epoch: 5| Step: 7
Training loss: 1.5834932327270508
Validation loss: 2.1708891689777374

Epoch: 5| Step: 8
Training loss: 1.340828537940979
Validation loss: 2.1407498866319656

Epoch: 5| Step: 9
Training loss: 1.062294602394104
Validation loss: 2.1583858281373978

Epoch: 5| Step: 10
Training loss: 1.1472766399383545
Validation loss: 2.1394141415754953

Epoch: 5| Step: 11
Training loss: 1.160989761352539
Validation loss: 2.1523237774769464

Epoch: 446| Step: 0
Training loss: 1.0665624141693115
Validation loss: 2.228912502527237

Epoch: 5| Step: 1
Training loss: 1.4619269371032715
Validation loss: 2.206328789393107

Epoch: 5| Step: 2
Training loss: 1.3740177154541016
Validation loss: 2.1890792896350226

Epoch: 5| Step: 3
Training loss: 1.170419454574585
Validation loss: 2.1669411659240723

Epoch: 5| Step: 4
Training loss: 0.8549321889877319
Validation loss: 2.1919701993465424

Epoch: 5| Step: 5
Training loss: 1.5088613033294678
Validation loss: 2.1891738871733346

Epoch: 5| Step: 6
Training loss: 1.32320237159729
Validation loss: 2.1846349189678826

Epoch: 5| Step: 7
Training loss: 1.1202621459960938
Validation loss: 2.1448931097984314

Epoch: 5| Step: 8
Training loss: 0.889007568359375
Validation loss: 2.187733272711436

Epoch: 5| Step: 9
Training loss: 1.2934709787368774
Validation loss: 2.2071163207292557

Epoch: 5| Step: 10
Training loss: 1.458977460861206
Validation loss: 2.1696577767531076

Epoch: 5| Step: 11
Training loss: 2.6460657119750977
Validation loss: 2.187501539786657

Epoch: 447| Step: 0
Training loss: 1.8386030197143555
Validation loss: 2.1355107029279075

Epoch: 5| Step: 1
Training loss: 1.372525930404663
Validation loss: 2.1186224818229675

Epoch: 5| Step: 2
Training loss: 1.4062421321868896
Validation loss: 2.1026699443658194

Epoch: 5| Step: 3
Training loss: 1.5848650932312012
Validation loss: 2.149308572212855

Epoch: 5| Step: 4
Training loss: 1.3367011547088623
Validation loss: 2.1185200264056525

Epoch: 5| Step: 5
Training loss: 0.9869050979614258
Validation loss: 2.0905157327651978

Epoch: 5| Step: 6
Training loss: 1.1878095865249634
Validation loss: 2.130470330516497

Epoch: 5| Step: 7
Training loss: 1.0759071111679077
Validation loss: 2.128077805042267

Epoch: 5| Step: 8
Training loss: 0.8186811208724976
Validation loss: 2.1413678377866745

Epoch: 5| Step: 9
Training loss: 1.3622117042541504
Validation loss: 2.176348552107811

Epoch: 5| Step: 10
Training loss: 0.8347949981689453
Validation loss: 2.167233501871427

Epoch: 5| Step: 11
Training loss: 0.6295121908187866
Validation loss: 2.18892939388752

Epoch: 448| Step: 0
Training loss: 0.9086798429489136
Validation loss: 2.144627034664154

Epoch: 5| Step: 1
Training loss: 1.1196339130401611
Validation loss: 2.177551582455635

Epoch: 5| Step: 2
Training loss: 1.1289575099945068
Validation loss: 2.1552584171295166

Epoch: 5| Step: 3
Training loss: 2.0268914699554443
Validation loss: 2.108049288392067

Epoch: 5| Step: 4
Training loss: 1.0037024021148682
Validation loss: 2.145382950703303

Epoch: 5| Step: 5
Training loss: 1.8317692279815674
Validation loss: 2.118745411435763

Epoch: 5| Step: 6
Training loss: 1.2879092693328857
Validation loss: 2.170697952310244

Epoch: 5| Step: 7
Training loss: 1.3918182849884033
Validation loss: 2.180481493473053

Epoch: 5| Step: 8
Training loss: 0.6886749267578125
Validation loss: 2.184741551677386

Epoch: 5| Step: 9
Training loss: 0.8901693224906921
Validation loss: 2.2025811026493707

Epoch: 5| Step: 10
Training loss: 1.2712929248809814
Validation loss: 2.203514496485392

Epoch: 5| Step: 11
Training loss: 1.961678147315979
Validation loss: 2.210495079557101

Epoch: 449| Step: 0
Training loss: 1.3942924737930298
Validation loss: 2.1609567205111184

Epoch: 5| Step: 1
Training loss: 0.8086645007133484
Validation loss: 2.187852626045545

Epoch: 5| Step: 2
Training loss: 0.6781123280525208
Validation loss: 2.2062230507532754

Epoch: 5| Step: 3
Training loss: 1.1867116689682007
Validation loss: 2.192984695235888

Epoch: 5| Step: 4
Training loss: 1.6397813558578491
Validation loss: 2.1738520363966622

Epoch: 5| Step: 5
Training loss: 1.442517638206482
Validation loss: 2.1595580081144967

Epoch: 5| Step: 6
Training loss: 1.5434117317199707
Validation loss: 2.1802646070718765

Epoch: 5| Step: 7
Training loss: 0.8822170495986938
Validation loss: 2.165111189087232

Epoch: 5| Step: 8
Training loss: 1.3286901712417603
Validation loss: 2.164602041244507

Epoch: 5| Step: 9
Training loss: 1.5355925559997559
Validation loss: 2.1157145897547402

Epoch: 5| Step: 10
Training loss: 1.2597289085388184
Validation loss: 2.1061960955460868

Epoch: 5| Step: 11
Training loss: 1.0347955226898193
Validation loss: 2.095492571592331

Epoch: 450| Step: 0
Training loss: 1.5546876192092896
Validation loss: 2.1351664115985236

Epoch: 5| Step: 1
Training loss: 0.9049380421638489
Validation loss: 2.140133331219355

Epoch: 5| Step: 2
Training loss: 0.7139172554016113
Validation loss: 2.084592123826345

Epoch: 5| Step: 3
Training loss: 1.2221752405166626
Validation loss: 2.1435055285692215

Epoch: 5| Step: 4
Training loss: 1.218126893043518
Validation loss: 2.1765037526686988

Epoch: 5| Step: 5
Training loss: 0.7048002481460571
Validation loss: 2.1857404311498008

Epoch: 5| Step: 6
Training loss: 1.4346189498901367
Validation loss: 2.2244518250226974

Epoch: 5| Step: 7
Training loss: 0.9771339297294617
Validation loss: 2.2137211759885154

Epoch: 5| Step: 8
Training loss: 1.3562947511672974
Validation loss: 2.207682510217031

Epoch: 5| Step: 9
Training loss: 2.1892194747924805
Validation loss: 2.211021934946378

Epoch: 5| Step: 10
Training loss: 1.2402557134628296
Validation loss: 2.176202823718389

Epoch: 5| Step: 11
Training loss: 2.6929707527160645
Validation loss: 2.150775065024694

Epoch: 451| Step: 0
Training loss: 1.205721139907837
Validation loss: 2.198558270931244

Epoch: 5| Step: 1
Training loss: 1.0158534049987793
Validation loss: 2.1626145591338477

Epoch: 5| Step: 2
Training loss: 1.8830935955047607
Validation loss: 2.147902568181356

Epoch: 5| Step: 3
Training loss: 1.751713514328003
Validation loss: 2.2098113050063453

Epoch: 5| Step: 4
Training loss: 1.5427417755126953
Validation loss: 2.167577584584554

Epoch: 5| Step: 5
Training loss: 1.2572683095932007
Validation loss: 2.194614499807358

Epoch: 5| Step: 6
Training loss: 1.4216195344924927
Validation loss: 2.2048685997724533

Epoch: 5| Step: 7
Training loss: 1.5484505891799927
Validation loss: 2.191898137331009

Epoch: 5| Step: 8
Training loss: 1.3479368686676025
Validation loss: 2.1647704343001046

Epoch: 5| Step: 9
Training loss: 0.9319254159927368
Validation loss: 2.1497183640797934

Epoch: 5| Step: 10
Training loss: 0.8609229922294617
Validation loss: 2.120195378859838

Epoch: 5| Step: 11
Training loss: 0.9359481930732727
Validation loss: 2.148185655474663

Epoch: 452| Step: 0
Training loss: 1.7264102697372437
Validation loss: 2.1778661410013833

Epoch: 5| Step: 1
Training loss: 1.0258309841156006
Validation loss: 2.1751749912897744

Epoch: 5| Step: 2
Training loss: 1.0716667175292969
Validation loss: 2.164852718512217

Epoch: 5| Step: 3
Training loss: 1.0246165990829468
Validation loss: 2.188579633831978

Epoch: 5| Step: 4
Training loss: 1.3156609535217285
Validation loss: 2.200230970978737

Epoch: 5| Step: 5
Training loss: 1.2211782932281494
Validation loss: 2.2282729198535285

Epoch: 5| Step: 6
Training loss: 1.141129732131958
Validation loss: 2.215357154607773

Epoch: 5| Step: 7
Training loss: 1.3514901399612427
Validation loss: 2.2512432833512626

Epoch: 5| Step: 8
Training loss: 1.504293441772461
Validation loss: 2.229324514667193

Epoch: 5| Step: 9
Training loss: 1.5192960500717163
Validation loss: 2.212874323129654

Epoch: 5| Step: 10
Training loss: 1.9893391132354736
Validation loss: 2.22605562210083

Epoch: 5| Step: 11
Training loss: 0.6918137073516846
Validation loss: 2.2127413749694824

Epoch: 453| Step: 0
Training loss: 0.6935626268386841
Validation loss: 2.216789722442627

Epoch: 5| Step: 1
Training loss: 1.794359803199768
Validation loss: 2.2034611304601035

Epoch: 5| Step: 2
Training loss: 1.5440585613250732
Validation loss: 2.194559986392657

Epoch: 5| Step: 3
Training loss: 1.327532410621643
Validation loss: 2.2221264243125916

Epoch: 5| Step: 4
Training loss: 1.1741950511932373
Validation loss: 2.1542236506938934

Epoch: 5| Step: 5
Training loss: 1.1099693775177002
Validation loss: 2.220177282889684

Epoch: 5| Step: 6
Training loss: 1.3841651678085327
Validation loss: 2.2089177072048187

Epoch: 5| Step: 7
Training loss: 1.1012351512908936
Validation loss: 2.221629728873571

Epoch: 5| Step: 8
Training loss: 1.0783253908157349
Validation loss: 2.1337805092334747

Epoch: 5| Step: 9
Training loss: 0.9137996435165405
Validation loss: 2.16123229265213

Epoch: 5| Step: 10
Training loss: 1.9187469482421875
Validation loss: 2.1030198335647583

Epoch: 5| Step: 11
Training loss: 1.6370508670806885
Validation loss: 2.130803550283114

Epoch: 454| Step: 0
Training loss: 1.253544569015503
Validation loss: 2.1427718500296273

Epoch: 5| Step: 1
Training loss: 1.6376562118530273
Validation loss: 2.244362860918045

Epoch: 5| Step: 2
Training loss: 1.9881086349487305
Validation loss: 2.151668777068456

Epoch: 5| Step: 3
Training loss: 1.2924695014953613
Validation loss: 2.158649275700251

Epoch: 5| Step: 4
Training loss: 1.6711251735687256
Validation loss: 2.1516567269961038

Epoch: 5| Step: 5
Training loss: 0.8913528323173523
Validation loss: 2.1424685368935266

Epoch: 5| Step: 6
Training loss: 1.4090440273284912
Validation loss: 2.124526560306549

Epoch: 5| Step: 7
Training loss: 1.26144540309906
Validation loss: 2.144139895836512

Epoch: 5| Step: 8
Training loss: 0.9814241528511047
Validation loss: 2.1629325846831002

Epoch: 5| Step: 9
Training loss: 1.4614299535751343
Validation loss: 2.1710682411988578

Epoch: 5| Step: 10
Training loss: 1.529020071029663
Validation loss: 2.207406202952067

Epoch: 5| Step: 11
Training loss: 0.9359183311462402
Validation loss: 2.162350515524546

Epoch: 455| Step: 0
Training loss: 1.4958523511886597
Validation loss: 2.1187762121359506

Epoch: 5| Step: 1
Training loss: 1.0741170644760132
Validation loss: 2.087878276904424

Epoch: 5| Step: 2
Training loss: 1.4336192607879639
Validation loss: 2.161682367324829

Epoch: 5| Step: 3
Training loss: 1.1338560581207275
Validation loss: 2.1696269462505975

Epoch: 5| Step: 4
Training loss: 1.4483847618103027
Validation loss: 2.188824305931727

Epoch: 5| Step: 5
Training loss: 1.567848563194275
Validation loss: 2.1394124925136566

Epoch: 5| Step: 6
Training loss: 1.0416439771652222
Validation loss: 2.175662020842234

Epoch: 5| Step: 7
Training loss: 1.1380093097686768
Validation loss: 2.1719203889369965

Epoch: 5| Step: 8
Training loss: 1.5886516571044922
Validation loss: 2.1876578430334725

Epoch: 5| Step: 9
Training loss: 1.0099631547927856
Validation loss: 2.202455386519432

Epoch: 5| Step: 10
Training loss: 2.0852274894714355
Validation loss: 2.2000575562318168

Epoch: 5| Step: 11
Training loss: 1.5433522462844849
Validation loss: 2.1957249542077384

Epoch: 456| Step: 0
Training loss: 0.8652609586715698
Validation loss: 2.1992983520030975

Epoch: 5| Step: 1
Training loss: 1.8392069339752197
Validation loss: 2.13787779211998

Epoch: 5| Step: 2
Training loss: 0.8893638849258423
Validation loss: 2.1424140681823096

Epoch: 5| Step: 3
Training loss: 1.3728461265563965
Validation loss: 2.118898421525955

Epoch: 5| Step: 4
Training loss: 1.0889394283294678
Validation loss: 2.098598748445511

Epoch: 5| Step: 5
Training loss: 1.3161113262176514
Validation loss: 2.0982791036367416

Epoch: 5| Step: 6
Training loss: 1.320195198059082
Validation loss: 2.1122133135795593

Epoch: 5| Step: 7
Training loss: 1.1580629348754883
Validation loss: 2.1123975863059363

Epoch: 5| Step: 8
Training loss: 1.2242767810821533
Validation loss: 2.1461515674988427

Epoch: 5| Step: 9
Training loss: 1.1092082262039185
Validation loss: 2.1026775538921356

Epoch: 5| Step: 10
Training loss: 1.470503568649292
Validation loss: 2.1502666423718133

Epoch: 5| Step: 11
Training loss: 1.8422021865844727
Validation loss: 2.1397328972816467

Epoch: 457| Step: 0
Training loss: 1.0855412483215332
Validation loss: 2.1569556097189584

Epoch: 5| Step: 1
Training loss: 1.2903152704238892
Validation loss: 2.1862803796927133

Epoch: 5| Step: 2
Training loss: 1.2067222595214844
Validation loss: 2.175395905971527

Epoch: 5| Step: 3
Training loss: 1.5055992603302002
Validation loss: 2.240270028511683

Epoch: 5| Step: 4
Training loss: 1.167672872543335
Validation loss: 2.1743730902671814

Epoch: 5| Step: 5
Training loss: 1.8750734329223633
Validation loss: 2.178442354003588

Epoch: 5| Step: 6
Training loss: 1.326842188835144
Validation loss: 2.1377106308937073

Epoch: 5| Step: 7
Training loss: 0.9413374662399292
Validation loss: 2.0936796764532724

Epoch: 5| Step: 8
Training loss: 0.9888194799423218
Validation loss: 2.1373992562294006

Epoch: 5| Step: 9
Training loss: 1.1649987697601318
Validation loss: 2.1357549726963043

Epoch: 5| Step: 10
Training loss: 1.2752450704574585
Validation loss: 2.1321992725133896

Epoch: 5| Step: 11
Training loss: 1.5836012363433838
Validation loss: 2.1375957230726876

Epoch: 458| Step: 0
Training loss: 1.6270538568496704
Validation loss: 2.0936032632986703

Epoch: 5| Step: 1
Training loss: 1.2185750007629395
Validation loss: 2.1067644904057183

Epoch: 5| Step: 2
Training loss: 1.029672622680664
Validation loss: 2.200787882010142

Epoch: 5| Step: 3
Training loss: 1.1254583597183228
Validation loss: 2.132974316676458

Epoch: 5| Step: 4
Training loss: 1.8121318817138672
Validation loss: 2.166417568922043

Epoch: 5| Step: 5
Training loss: 1.310030221939087
Validation loss: 2.178361937403679

Epoch: 5| Step: 6
Training loss: 0.9287105798721313
Validation loss: 2.1467782904704413

Epoch: 5| Step: 7
Training loss: 1.457214117050171
Validation loss: 2.137811223665873

Epoch: 5| Step: 8
Training loss: 0.8508164286613464
Validation loss: 2.1372476518154144

Epoch: 5| Step: 9
Training loss: 1.0345027446746826
Validation loss: 2.1472390939792

Epoch: 5| Step: 10
Training loss: 1.2645666599273682
Validation loss: 2.1521121909221015

Epoch: 5| Step: 11
Training loss: 0.32117778062820435
Validation loss: 2.141284480690956

Epoch: 459| Step: 0
Training loss: 1.5263445377349854
Validation loss: 2.1357232530911765

Epoch: 5| Step: 1
Training loss: 1.2430996894836426
Validation loss: 2.149484246969223

Epoch: 5| Step: 2
Training loss: 1.7779163122177124
Validation loss: 2.1509740551312766

Epoch: 5| Step: 3
Training loss: 0.9187102317810059
Validation loss: 2.1048055440187454

Epoch: 5| Step: 4
Training loss: 1.0701054334640503
Validation loss: 2.1512216279904046

Epoch: 5| Step: 5
Training loss: 1.1612670421600342
Validation loss: 2.1316624581813812

Epoch: 5| Step: 6
Training loss: 1.2037489414215088
Validation loss: 2.175542950630188

Epoch: 5| Step: 7
Training loss: 0.8256584405899048
Validation loss: 2.1547855685154595

Epoch: 5| Step: 8
Training loss: 1.0615952014923096
Validation loss: 2.142942269643148

Epoch: 5| Step: 9
Training loss: 1.214786171913147
Validation loss: 2.1325831711292267

Epoch: 5| Step: 10
Training loss: 1.1985454559326172
Validation loss: 2.1398710906505585

Epoch: 5| Step: 11
Training loss: 1.656166434288025
Validation loss: 2.151650846004486

Epoch: 460| Step: 0
Training loss: 1.5879446268081665
Validation loss: 2.1402732034524283

Epoch: 5| Step: 1
Training loss: 0.7436814308166504
Validation loss: 2.1185822983582816

Epoch: 5| Step: 2
Training loss: 0.9195449948310852
Validation loss: 2.1390100369850793

Epoch: 5| Step: 3
Training loss: 0.9641231298446655
Validation loss: 2.1438458462556205

Epoch: 5| Step: 4
Training loss: 1.673885703086853
Validation loss: 2.163973957300186

Epoch: 5| Step: 5
Training loss: 1.3961775302886963
Validation loss: 2.142759303251902

Epoch: 5| Step: 6
Training loss: 0.7978455424308777
Validation loss: 2.1303132822116218

Epoch: 5| Step: 7
Training loss: 1.6185235977172852
Validation loss: 2.099416802326838

Epoch: 5| Step: 8
Training loss: 0.9596735239028931
Validation loss: 2.1170360346635184

Epoch: 5| Step: 9
Training loss: 0.8547760248184204
Validation loss: 2.1220706552267075

Epoch: 5| Step: 10
Training loss: 1.195664882659912
Validation loss: 2.0955484559138617

Epoch: 5| Step: 11
Training loss: 3.4458956718444824
Validation loss: 2.0888039569060006

Epoch: 461| Step: 0
Training loss: 1.7421438694000244
Validation loss: 2.1413275798161826

Epoch: 5| Step: 1
Training loss: 1.4703890085220337
Validation loss: 2.110708345969518

Epoch: 5| Step: 2
Training loss: 1.2534862756729126
Validation loss: 2.1352658520142236

Epoch: 5| Step: 3
Training loss: 0.8513503074645996
Validation loss: 2.1029150734345117

Epoch: 5| Step: 4
Training loss: 0.917254626750946
Validation loss: 2.1431117554505668

Epoch: 5| Step: 5
Training loss: 1.591044545173645
Validation loss: 2.140851785739263

Epoch: 5| Step: 6
Training loss: 1.1232192516326904
Validation loss: 2.1106570959091187

Epoch: 5| Step: 7
Training loss: 1.1867927312850952
Validation loss: 2.137004777789116

Epoch: 5| Step: 8
Training loss: 0.7775891423225403
Validation loss: 2.165362924337387

Epoch: 5| Step: 9
Training loss: 1.0840681791305542
Validation loss: 2.073199580113093

Epoch: 5| Step: 10
Training loss: 1.1350765228271484
Validation loss: 2.1381478309631348

Epoch: 5| Step: 11
Training loss: 1.0881285667419434
Validation loss: 2.1534513533115387

Epoch: 462| Step: 0
Training loss: 1.7562577724456787
Validation loss: 2.1236822307109833

Epoch: 5| Step: 1
Training loss: 0.6092265844345093
Validation loss: 2.061495910088221

Epoch: 5| Step: 2
Training loss: 1.5510125160217285
Validation loss: 2.095665549238523

Epoch: 5| Step: 3
Training loss: 1.4942970275878906
Validation loss: 2.118444263935089

Epoch: 5| Step: 4
Training loss: 1.2030441761016846
Validation loss: 2.135949745774269

Epoch: 5| Step: 5
Training loss: 1.2875890731811523
Validation loss: 2.078928381204605

Epoch: 5| Step: 6
Training loss: 0.8598706126213074
Validation loss: 2.1214871406555176

Epoch: 5| Step: 7
Training loss: 1.3386571407318115
Validation loss: 2.1356009542942047

Epoch: 5| Step: 8
Training loss: 1.6632791757583618
Validation loss: 2.1422849893569946

Epoch: 5| Step: 9
Training loss: 0.7337262630462646
Validation loss: 2.1512467364470163

Epoch: 5| Step: 10
Training loss: 0.8800344467163086
Validation loss: 2.1712066431840262

Epoch: 5| Step: 11
Training loss: 1.475252628326416
Validation loss: 2.2272176891565323

Epoch: 463| Step: 0
Training loss: 1.3955039978027344
Validation loss: 2.174918701251348

Epoch: 5| Step: 1
Training loss: 0.9099227786064148
Validation loss: 2.1301402201255164

Epoch: 5| Step: 2
Training loss: 1.1174991130828857
Validation loss: 2.143479044238726

Epoch: 5| Step: 3
Training loss: 1.147722840309143
Validation loss: 2.118559390306473

Epoch: 5| Step: 4
Training loss: 0.8091837167739868
Validation loss: 2.1872722109158835

Epoch: 5| Step: 5
Training loss: 1.1067354679107666
Validation loss: 2.1243937065203986

Epoch: 5| Step: 6
Training loss: 2.1842713356018066
Validation loss: 2.12973652780056

Epoch: 5| Step: 7
Training loss: 1.2870759963989258
Validation loss: 2.1241346299648285

Epoch: 5| Step: 8
Training loss: 0.6049583554267883
Validation loss: 2.1089710046847663

Epoch: 5| Step: 9
Training loss: 1.3805242776870728
Validation loss: 2.111491779486338

Epoch: 5| Step: 10
Training loss: 1.1054526567459106
Validation loss: 2.129526063799858

Epoch: 5| Step: 11
Training loss: 0.605588972568512
Validation loss: 2.149096722404162

Epoch: 464| Step: 0
Training loss: 1.1788536310195923
Validation loss: 2.122067113717397

Epoch: 5| Step: 1
Training loss: 1.3607079982757568
Validation loss: 2.128356213370959

Epoch: 5| Step: 2
Training loss: 0.7334176301956177
Validation loss: 2.112365946173668

Epoch: 5| Step: 3
Training loss: 1.2799943685531616
Validation loss: 2.0949688106775284

Epoch: 5| Step: 4
Training loss: 1.7684173583984375
Validation loss: 2.146657427151998

Epoch: 5| Step: 5
Training loss: 1.056575894355774
Validation loss: 2.130750854810079

Epoch: 5| Step: 6
Training loss: 1.3515496253967285
Validation loss: 2.128341386715571

Epoch: 5| Step: 7
Training loss: 1.2538745403289795
Validation loss: 2.1464469581842422

Epoch: 5| Step: 8
Training loss: 1.6283124685287476
Validation loss: 2.133160963654518

Epoch: 5| Step: 9
Training loss: 0.6031683683395386
Validation loss: 2.1578812102476754

Epoch: 5| Step: 10
Training loss: 0.8314342498779297
Validation loss: 2.174768636624018

Epoch: 5| Step: 11
Training loss: 1.4166815280914307
Validation loss: 2.161004513502121

Epoch: 465| Step: 0
Training loss: 1.2330868244171143
Validation loss: 2.134440223375956

Epoch: 5| Step: 1
Training loss: 1.0470942258834839
Validation loss: 2.150427962342898

Epoch: 5| Step: 2
Training loss: 1.1474038362503052
Validation loss: 2.128974770506223

Epoch: 5| Step: 3
Training loss: 0.8633509874343872
Validation loss: 2.077311788996061

Epoch: 5| Step: 4
Training loss: 1.4255282878875732
Validation loss: 2.1282353748877845

Epoch: 5| Step: 5
Training loss: 0.9976150393486023
Validation loss: 2.1250497152407966

Epoch: 5| Step: 6
Training loss: 1.0200117826461792
Validation loss: 2.1292425394058228

Epoch: 5| Step: 7
Training loss: 1.418959140777588
Validation loss: 2.1293582717577615

Epoch: 5| Step: 8
Training loss: 1.3748250007629395
Validation loss: 2.1587473650773368

Epoch: 5| Step: 9
Training loss: 1.4278242588043213
Validation loss: 2.214378376801809

Epoch: 5| Step: 10
Training loss: 1.034748911857605
Validation loss: 2.1931835462649665

Epoch: 5| Step: 11
Training loss: 1.4197161197662354
Validation loss: 2.2134820371866226

Epoch: 466| Step: 0
Training loss: 0.7350234389305115
Validation loss: 2.23399023214976

Epoch: 5| Step: 1
Training loss: 1.5402956008911133
Validation loss: 2.182454322775205

Epoch: 5| Step: 2
Training loss: 1.0862778425216675
Validation loss: 2.1543468634287515

Epoch: 5| Step: 3
Training loss: 0.7906304001808167
Validation loss: 2.14581165711085

Epoch: 5| Step: 4
Training loss: 1.6094776391983032
Validation loss: 2.144497583309809

Epoch: 5| Step: 5
Training loss: 1.4928709268569946
Validation loss: 2.135004589955012

Epoch: 5| Step: 6
Training loss: 1.1120468378067017
Validation loss: 2.1454639534155526

Epoch: 5| Step: 7
Training loss: 1.274590253829956
Validation loss: 2.169366250435511

Epoch: 5| Step: 8
Training loss: 1.2481399774551392
Validation loss: 2.1269452422857285

Epoch: 5| Step: 9
Training loss: 0.909699559211731
Validation loss: 2.1631653855244317

Epoch: 5| Step: 10
Training loss: 1.2061353921890259
Validation loss: 2.1536089877287545

Epoch: 5| Step: 11
Training loss: 1.043966293334961
Validation loss: 2.1901542643706002

Epoch: 467| Step: 0
Training loss: 0.6782657504081726
Validation loss: 2.137742727994919

Epoch: 5| Step: 1
Training loss: 1.6110719442367554
Validation loss: 2.138933017849922

Epoch: 5| Step: 2
Training loss: 0.9674440622329712
Validation loss: 2.132831245660782

Epoch: 5| Step: 3
Training loss: 0.9406319856643677
Validation loss: 2.122104679544767

Epoch: 5| Step: 4
Training loss: 0.9830549359321594
Validation loss: 2.176701287428538

Epoch: 5| Step: 5
Training loss: 0.9452691078186035
Validation loss: 2.1714777251084647

Epoch: 5| Step: 6
Training loss: 1.2244625091552734
Validation loss: 2.139456629753113

Epoch: 5| Step: 7
Training loss: 1.258005142211914
Validation loss: 2.1237632681926093

Epoch: 5| Step: 8
Training loss: 1.298064947128296
Validation loss: 2.191085676352183

Epoch: 5| Step: 9
Training loss: 1.9751622676849365
Validation loss: 2.1934330612421036

Epoch: 5| Step: 10
Training loss: 1.1593303680419922
Validation loss: 2.1966209411621094

Epoch: 5| Step: 11
Training loss: 0.6907646059989929
Validation loss: 2.209379941225052

Epoch: 468| Step: 0
Training loss: 0.9357622265815735
Validation loss: 2.2140616377194724

Epoch: 5| Step: 1
Training loss: 1.813969612121582
Validation loss: 2.211535006761551

Epoch: 5| Step: 2
Training loss: 1.1914106607437134
Validation loss: 2.2205484906832376

Epoch: 5| Step: 3
Training loss: 1.3226112127304077
Validation loss: 2.1931910812854767

Epoch: 5| Step: 4
Training loss: 1.1117608547210693
Validation loss: 2.1542454808950424

Epoch: 5| Step: 5
Training loss: 1.193339228630066
Validation loss: 2.1395676285028458

Epoch: 5| Step: 6
Training loss: 0.9745526313781738
Validation loss: 2.1356116185585656

Epoch: 5| Step: 7
Training loss: 0.7545778155326843
Validation loss: 2.101636677980423

Epoch: 5| Step: 8
Training loss: 1.6621503829956055
Validation loss: 2.191381593545278

Epoch: 5| Step: 9
Training loss: 0.8740720748901367
Validation loss: 2.17368420958519

Epoch: 5| Step: 10
Training loss: 1.0975043773651123
Validation loss: 2.2084354360898337

Epoch: 5| Step: 11
Training loss: 0.6757816076278687
Validation loss: 2.194293628136317

Epoch: 469| Step: 0
Training loss: 0.6828354001045227
Validation loss: 2.1550789872805276

Epoch: 5| Step: 1
Training loss: 0.8012646436691284
Validation loss: 2.117789184053739

Epoch: 5| Step: 2
Training loss: 1.3517801761627197
Validation loss: 2.1146475821733475

Epoch: 5| Step: 3
Training loss: 1.6013273000717163
Validation loss: 2.1273268163204193

Epoch: 5| Step: 4
Training loss: 1.1235417127609253
Validation loss: 2.1021636724472046

Epoch: 5| Step: 5
Training loss: 1.613738775253296
Validation loss: 2.1333798319101334

Epoch: 5| Step: 6
Training loss: 1.0129263401031494
Validation loss: 2.120115637779236

Epoch: 5| Step: 7
Training loss: 1.7221912145614624
Validation loss: 2.1126682808001838

Epoch: 5| Step: 8
Training loss: 0.7698723673820496
Validation loss: 2.0862333476543427

Epoch: 5| Step: 9
Training loss: 0.7485023736953735
Validation loss: 2.1247715105613074

Epoch: 5| Step: 10
Training loss: 1.5908161401748657
Validation loss: 2.162317633628845

Epoch: 5| Step: 11
Training loss: 1.9476935863494873
Validation loss: 2.151524896423022

Epoch: 470| Step: 0
Training loss: 1.0888340473175049
Validation loss: 2.0801928440729776

Epoch: 5| Step: 1
Training loss: 0.6581707000732422
Validation loss: 2.114430159330368

Epoch: 5| Step: 2
Training loss: 1.4482243061065674
Validation loss: 2.079698294401169

Epoch: 5| Step: 3
Training loss: 1.2623260021209717
Validation loss: 2.114837035536766

Epoch: 5| Step: 4
Training loss: 1.181213140487671
Validation loss: 2.1058355073134103

Epoch: 5| Step: 5
Training loss: 1.2582050561904907
Validation loss: 2.0858348608016968

Epoch: 5| Step: 6
Training loss: 1.800775170326233
Validation loss: 2.1081491261720657

Epoch: 5| Step: 7
Training loss: 1.5213240385055542
Validation loss: 2.0869534413019815

Epoch: 5| Step: 8
Training loss: 1.4329807758331299
Validation loss: 2.138070980707804

Epoch: 5| Step: 9
Training loss: 0.6531552076339722
Validation loss: 2.176379462083181

Epoch: 5| Step: 10
Training loss: 1.275392770767212
Validation loss: 2.1406613836685815

Epoch: 5| Step: 11
Training loss: 0.4473639726638794
Validation loss: 2.180309678117434

Epoch: 471| Step: 0
Training loss: 1.1691620349884033
Validation loss: 2.181126832962036

Epoch: 5| Step: 1
Training loss: 1.4387913942337036
Validation loss: 2.1314792782068253

Epoch: 5| Step: 2
Training loss: 1.6786530017852783
Validation loss: 2.1524647871653237

Epoch: 5| Step: 3
Training loss: 1.1757901906967163
Validation loss: 2.174251397450765

Epoch: 5| Step: 4
Training loss: 1.2436113357543945
Validation loss: 2.1010268330574036

Epoch: 5| Step: 5
Training loss: 0.9002650380134583
Validation loss: 2.1345152159531913

Epoch: 5| Step: 6
Training loss: 0.9938119649887085
Validation loss: 2.0892761250336966

Epoch: 5| Step: 7
Training loss: 1.2899048328399658
Validation loss: 2.170056293408076

Epoch: 5| Step: 8
Training loss: 1.3981988430023193
Validation loss: 2.176972652475039

Epoch: 5| Step: 9
Training loss: 1.0333178043365479
Validation loss: 2.164728139837583

Epoch: 5| Step: 10
Training loss: 0.8243898153305054
Validation loss: 2.200905606150627

Epoch: 5| Step: 11
Training loss: 1.8976318836212158
Validation loss: 2.1911135216554007

Epoch: 472| Step: 0
Training loss: 0.9485724568367004
Validation loss: 2.151616041858991

Epoch: 5| Step: 1
Training loss: 1.0450185537338257
Validation loss: 2.167302389939626

Epoch: 5| Step: 2
Training loss: 1.244797945022583
Validation loss: 2.1147015392780304

Epoch: 5| Step: 3
Training loss: 1.3240329027175903
Validation loss: 2.13252654671669

Epoch: 5| Step: 4
Training loss: 1.5493313074111938
Validation loss: 2.0833321660757065

Epoch: 5| Step: 5
Training loss: 0.9126184582710266
Validation loss: 2.1497071584065757

Epoch: 5| Step: 6
Training loss: 1.408022165298462
Validation loss: 2.1359765181938806

Epoch: 5| Step: 7
Training loss: 1.537908911705017
Validation loss: 2.1114597618579865

Epoch: 5| Step: 8
Training loss: 0.9937799572944641
Validation loss: 2.1583832800388336

Epoch: 5| Step: 9
Training loss: 1.0493205785751343
Validation loss: 2.1560323536396027

Epoch: 5| Step: 10
Training loss: 1.3076354265213013
Validation loss: 2.1458921283483505

Epoch: 5| Step: 11
Training loss: 1.5568764209747314
Validation loss: 2.1873096227645874

Epoch: 473| Step: 0
Training loss: 1.560875654220581
Validation loss: 2.2314598659674325

Epoch: 5| Step: 1
Training loss: 1.323623538017273
Validation loss: 2.1983119348684945

Epoch: 5| Step: 2
Training loss: 1.2811145782470703
Validation loss: 2.192694882551829

Epoch: 5| Step: 3
Training loss: 0.9519926309585571
Validation loss: 2.1467919598023095

Epoch: 5| Step: 4
Training loss: 1.1428433656692505
Validation loss: 2.1280241956313453

Epoch: 5| Step: 5
Training loss: 1.2600418329238892
Validation loss: 2.1264610389868417

Epoch: 5| Step: 6
Training loss: 1.4435025453567505
Validation loss: 2.1010352124770484

Epoch: 5| Step: 7
Training loss: 1.7961561679840088
Validation loss: 2.1253588497638702

Epoch: 5| Step: 8
Training loss: 0.8915302157402039
Validation loss: 2.1349645058314004

Epoch: 5| Step: 9
Training loss: 1.3606302738189697
Validation loss: 2.187661737203598

Epoch: 5| Step: 10
Training loss: 1.0913708209991455
Validation loss: 2.1458814988533654

Epoch: 5| Step: 11
Training loss: 1.0648143291473389
Validation loss: 2.1339437117179236

Epoch: 474| Step: 0
Training loss: 1.1964030265808105
Validation loss: 2.0847326467434564

Epoch: 5| Step: 1
Training loss: 1.0480965375900269
Validation loss: 2.130593811472257

Epoch: 5| Step: 2
Training loss: 1.143367886543274
Validation loss: 2.18456336359183

Epoch: 5| Step: 3
Training loss: 1.675658941268921
Validation loss: 2.1783993343512216

Epoch: 5| Step: 4
Training loss: 2.120082378387451
Validation loss: 2.1634363681077957

Epoch: 5| Step: 5
Training loss: 1.0671827793121338
Validation loss: 2.1926390628019967

Epoch: 5| Step: 6
Training loss: 1.2561029195785522
Validation loss: 2.106668099761009

Epoch: 5| Step: 7
Training loss: 1.0581971406936646
Validation loss: 2.0999781042337418

Epoch: 5| Step: 8
Training loss: 1.3746068477630615
Validation loss: 2.119806786378225

Epoch: 5| Step: 9
Training loss: 0.8236921429634094
Validation loss: 2.1420166194438934

Epoch: 5| Step: 10
Training loss: 0.6595717668533325
Validation loss: 2.1067643215258918

Epoch: 5| Step: 11
Training loss: 0.9925730228424072
Validation loss: 2.1170472850402198

Epoch: 475| Step: 0
Training loss: 1.7234363555908203
Validation loss: 2.105979879697164

Epoch: 5| Step: 1
Training loss: 1.0802642107009888
Validation loss: 2.1057123045126596

Epoch: 5| Step: 2
Training loss: 0.9993759393692017
Validation loss: 2.1516993095477424

Epoch: 5| Step: 3
Training loss: 1.4240531921386719
Validation loss: 2.166860446333885

Epoch: 5| Step: 4
Training loss: 0.9769430160522461
Validation loss: 2.1576864471038184

Epoch: 5| Step: 5
Training loss: 0.9119391441345215
Validation loss: 2.139807010690371

Epoch: 5| Step: 6
Training loss: 1.0067106485366821
Validation loss: 2.1411881496508918

Epoch: 5| Step: 7
Training loss: 1.4387872219085693
Validation loss: 2.1331775238116584

Epoch: 5| Step: 8
Training loss: 1.0731736421585083
Validation loss: 2.154550219575564

Epoch: 5| Step: 9
Training loss: 1.2516696453094482
Validation loss: 2.2031014959017434

Epoch: 5| Step: 10
Training loss: 1.0652432441711426
Validation loss: 2.186663120985031

Epoch: 5| Step: 11
Training loss: 0.7189517617225647
Validation loss: 2.1829345673322678

Epoch: 476| Step: 0
Training loss: 1.2377043962478638
Validation loss: 2.1171344270308814

Epoch: 5| Step: 1
Training loss: 0.8425041437149048
Validation loss: 2.045535763104757

Epoch: 5| Step: 2
Training loss: 1.3425623178482056
Validation loss: 2.0746634205182395

Epoch: 5| Step: 3
Training loss: 1.2974321842193604
Validation loss: 2.108622799317042

Epoch: 5| Step: 4
Training loss: 1.684264898300171
Validation loss: 2.1303219695885978

Epoch: 5| Step: 5
Training loss: 1.290239691734314
Validation loss: 2.1440066943566003

Epoch: 5| Step: 6
Training loss: 1.0353670120239258
Validation loss: 2.0949255724747977

Epoch: 5| Step: 7
Training loss: 2.0783543586730957
Validation loss: 2.074717362721761

Epoch: 5| Step: 8
Training loss: 1.4184523820877075
Validation loss: 2.1225617031256356

Epoch: 5| Step: 9
Training loss: 1.0690314769744873
Validation loss: 2.146259774764379

Epoch: 5| Step: 10
Training loss: 0.6493722200393677
Validation loss: 2.2151107539733252

Epoch: 5| Step: 11
Training loss: 1.5364729166030884
Validation loss: 2.217511216799418

Epoch: 477| Step: 0
Training loss: 1.1736812591552734
Validation loss: 2.195571780204773

Epoch: 5| Step: 1
Training loss: 1.5856285095214844
Validation loss: 2.2117119431495667

Epoch: 5| Step: 2
Training loss: 1.216866135597229
Validation loss: 2.1982784271240234

Epoch: 5| Step: 3
Training loss: 0.7528796792030334
Validation loss: 2.196483795841535

Epoch: 5| Step: 4
Training loss: 1.3981454372406006
Validation loss: 2.1458071817954383

Epoch: 5| Step: 5
Training loss: 1.2327767610549927
Validation loss: 2.123567337791125

Epoch: 5| Step: 6
Training loss: 0.9883301854133606
Validation loss: 2.1256654063860574

Epoch: 5| Step: 7
Training loss: 0.9175637364387512
Validation loss: 2.1048335134983063

Epoch: 5| Step: 8
Training loss: 1.649346947669983
Validation loss: 2.0909277200698853

Epoch: 5| Step: 9
Training loss: 1.5101288557052612
Validation loss: 2.1150739938020706

Epoch: 5| Step: 10
Training loss: 0.8881438374519348
Validation loss: 2.101224755247434

Epoch: 5| Step: 11
Training loss: 1.6788522005081177
Validation loss: 2.095693459113439

Epoch: 478| Step: 0
Training loss: 1.787952184677124
Validation loss: 2.1240509202082953

Epoch: 5| Step: 1
Training loss: 0.6826914548873901
Validation loss: 2.1323051850001016

Epoch: 5| Step: 2
Training loss: 1.075063705444336
Validation loss: 2.16616419951121

Epoch: 5| Step: 3
Training loss: 1.0798146724700928
Validation loss: 2.154258539279302

Epoch: 5| Step: 4
Training loss: 0.8811795115470886
Validation loss: 2.17045866449674

Epoch: 5| Step: 5
Training loss: 0.8496764302253723
Validation loss: 2.1735517928997674

Epoch: 5| Step: 6
Training loss: 1.2155643701553345
Validation loss: 2.1757858196894326

Epoch: 5| Step: 7
Training loss: 0.8119575381278992
Validation loss: 2.1620732148488364

Epoch: 5| Step: 8
Training loss: 1.388523817062378
Validation loss: 2.151109720269839

Epoch: 5| Step: 9
Training loss: 1.3177703619003296
Validation loss: 2.203612834215164

Epoch: 5| Step: 10
Training loss: 1.5415159463882446
Validation loss: 2.13540510336558

Epoch: 5| Step: 11
Training loss: 0.6683537364006042
Validation loss: 2.121303548415502

Epoch: 479| Step: 0
Training loss: 1.0489702224731445
Validation loss: 2.087843587001165

Epoch: 5| Step: 1
Training loss: 1.0575376749038696
Validation loss: 2.08238385617733

Epoch: 5| Step: 2
Training loss: 1.2161977291107178
Validation loss: 2.136673241853714

Epoch: 5| Step: 3
Training loss: 1.685685396194458
Validation loss: 2.13194506863753

Epoch: 5| Step: 4
Training loss: 1.837078332901001
Validation loss: 2.124435464541117

Epoch: 5| Step: 5
Training loss: 1.6739895343780518
Validation loss: 2.111807813247045

Epoch: 5| Step: 6
Training loss: 0.9532290697097778
Validation loss: 2.124193956454595

Epoch: 5| Step: 7
Training loss: 0.6168991327285767
Validation loss: 2.1448047757148743

Epoch: 5| Step: 8
Training loss: 0.7985294461250305
Validation loss: 2.1460417409737906

Epoch: 5| Step: 9
Training loss: 0.5272179841995239
Validation loss: 2.116809050242106

Epoch: 5| Step: 10
Training loss: 0.9292446970939636
Validation loss: 2.171661173303922

Epoch: 5| Step: 11
Training loss: 0.6425665020942688
Validation loss: 2.1527053813139596

Epoch: 480| Step: 0
Training loss: 0.8671140670776367
Validation loss: 2.1579103072484336

Epoch: 5| Step: 1
Training loss: 1.3716496229171753
Validation loss: 2.1797435333331427

Epoch: 5| Step: 2
Training loss: 1.0579601526260376
Validation loss: 2.1499733378489814

Epoch: 5| Step: 3
Training loss: 1.236102819442749
Validation loss: 2.1531148801247277

Epoch: 5| Step: 4
Training loss: 1.6276378631591797
Validation loss: 2.1537951628367105

Epoch: 5| Step: 5
Training loss: 0.8448268175125122
Validation loss: 2.1546509812275567

Epoch: 5| Step: 6
Training loss: 1.9711062908172607
Validation loss: 2.1224456429481506

Epoch: 5| Step: 7
Training loss: 0.6539691686630249
Validation loss: 2.1267921874920526

Epoch: 5| Step: 8
Training loss: 1.1751229763031006
Validation loss: 2.1105720003445945

Epoch: 5| Step: 9
Training loss: 1.4853894710540771
Validation loss: 2.165071487426758

Epoch: 5| Step: 10
Training loss: 0.978485107421875
Validation loss: 2.1610062271356583

Epoch: 5| Step: 11
Training loss: 0.7870835065841675
Validation loss: 2.1373220831155777

Epoch: 481| Step: 0
Training loss: 0.9660779237747192
Validation loss: 2.1044941196839013

Epoch: 5| Step: 1
Training loss: 1.0866217613220215
Validation loss: 2.131024122238159

Epoch: 5| Step: 2
Training loss: 1.1106325387954712
Validation loss: 2.1774031817913055

Epoch: 5| Step: 3
Training loss: 1.3176298141479492
Validation loss: 2.2031551400820413

Epoch: 5| Step: 4
Training loss: 1.178106665611267
Validation loss: 2.208267644047737

Epoch: 5| Step: 5
Training loss: 1.5916011333465576
Validation loss: 2.171671688556671

Epoch: 5| Step: 6
Training loss: 1.256281852722168
Validation loss: 2.188378721475601

Epoch: 5| Step: 7
Training loss: 0.9525699615478516
Validation loss: 2.1995364179213843

Epoch: 5| Step: 8
Training loss: 0.8319801092147827
Validation loss: 2.174650306502978

Epoch: 5| Step: 9
Training loss: 1.2984462976455688
Validation loss: 2.156683330734571

Epoch: 5| Step: 10
Training loss: 0.8035527467727661
Validation loss: 2.1382591277360916

Epoch: 5| Step: 11
Training loss: 1.2526935338974
Validation loss: 2.135423163572947

Epoch: 482| Step: 0
Training loss: 1.0368053913116455
Validation loss: 2.1106289823849997

Epoch: 5| Step: 1
Training loss: 0.992913544178009
Validation loss: 2.110801264643669

Epoch: 5| Step: 2
Training loss: 0.6233530640602112
Validation loss: 2.1087593088547387

Epoch: 5| Step: 3
Training loss: 0.8652957677841187
Validation loss: 2.1280022462209067

Epoch: 5| Step: 4
Training loss: 1.2643232345581055
Validation loss: 2.08513938387235

Epoch: 5| Step: 5
Training loss: 0.9552158117294312
Validation loss: 2.110576177636782

Epoch: 5| Step: 6
Training loss: 1.7428401708602905
Validation loss: 2.1296565582354865

Epoch: 5| Step: 7
Training loss: 0.9180538058280945
Validation loss: 2.163048376639684

Epoch: 5| Step: 8
Training loss: 1.3001651763916016
Validation loss: 2.147247408827146

Epoch: 5| Step: 9
Training loss: 1.5328295230865479
Validation loss: 2.1867883503437042

Epoch: 5| Step: 10
Training loss: 1.196470856666565
Validation loss: 2.1480383773644767

Epoch: 5| Step: 11
Training loss: 1.3488588333129883
Validation loss: 2.139276827375094

Epoch: 483| Step: 0
Training loss: 0.8897730708122253
Validation loss: 2.123697981238365

Epoch: 5| Step: 1
Training loss: 1.4859627485275269
Validation loss: 2.1183270613352456

Epoch: 5| Step: 2
Training loss: 1.3007113933563232
Validation loss: 2.0948643585046134

Epoch: 5| Step: 3
Training loss: 0.8342894315719604
Validation loss: 2.087072635690371

Epoch: 5| Step: 4
Training loss: 0.968488872051239
Validation loss: 2.1600013772646585

Epoch: 5| Step: 5
Training loss: 0.8494876027107239
Validation loss: 2.1120888392130532

Epoch: 5| Step: 6
Training loss: 1.2454909086227417
Validation loss: 2.147292117277781

Epoch: 5| Step: 7
Training loss: 1.1979281902313232
Validation loss: 2.1425565282503762

Epoch: 5| Step: 8
Training loss: 1.0426985025405884
Validation loss: 2.1655319035053253

Epoch: 5| Step: 9
Training loss: 1.381191611289978
Validation loss: 2.15482726196448

Epoch: 5| Step: 10
Training loss: 0.9943181872367859
Validation loss: 2.171957701444626

Epoch: 5| Step: 11
Training loss: 1.431431770324707
Validation loss: 2.1596001237630844

Epoch: 484| Step: 0
Training loss: 0.9275392293930054
Validation loss: 2.1304199943939843

Epoch: 5| Step: 1
Training loss: 1.0093696117401123
Validation loss: 2.1612409005562463

Epoch: 5| Step: 2
Training loss: 0.9893307685852051
Validation loss: 2.122793957591057

Epoch: 5| Step: 3
Training loss: 0.8256075978279114
Validation loss: 2.0863643487294516

Epoch: 5| Step: 4
Training loss: 0.8899799585342407
Validation loss: 2.1109922925631204

Epoch: 5| Step: 5
Training loss: 1.9603054523468018
Validation loss: 2.1376475393772125

Epoch: 5| Step: 6
Training loss: 1.0032469034194946
Validation loss: 2.1353231171766915

Epoch: 5| Step: 7
Training loss: 1.6380417346954346
Validation loss: 2.12967141966025

Epoch: 5| Step: 8
Training loss: 1.2169477939605713
Validation loss: 2.0998020470142365

Epoch: 5| Step: 9
Training loss: 1.02372407913208
Validation loss: 2.1873169541358948

Epoch: 5| Step: 10
Training loss: 0.902274489402771
Validation loss: 2.1086874306201935

Epoch: 5| Step: 11
Training loss: 0.6057437658309937
Validation loss: 2.140783523519834

Epoch: 485| Step: 0
Training loss: 1.3843700885772705
Validation loss: 2.1657884418964386

Epoch: 5| Step: 1
Training loss: 0.7925357222557068
Validation loss: 2.1593398054440818

Epoch: 5| Step: 2
Training loss: 0.8544713854789734
Validation loss: 2.184391458829244

Epoch: 5| Step: 3
Training loss: 1.0251822471618652
Validation loss: 2.1201846351226172

Epoch: 5| Step: 4
Training loss: 2.137836456298828
Validation loss: 2.1628786524136863

Epoch: 5| Step: 5
Training loss: 1.1209901571273804
Validation loss: 2.151517222325007

Epoch: 5| Step: 6
Training loss: 1.1376841068267822
Validation loss: 2.1046521266301474

Epoch: 5| Step: 7
Training loss: 1.0464369058609009
Validation loss: 2.147265230615934

Epoch: 5| Step: 8
Training loss: 0.7455762624740601
Validation loss: 2.1599883288145065

Epoch: 5| Step: 9
Training loss: 1.851697325706482
Validation loss: 2.17963774005572

Epoch: 5| Step: 10
Training loss: 0.6191545724868774
Validation loss: 2.1546139270067215

Epoch: 5| Step: 11
Training loss: 0.7972168922424316
Validation loss: 2.133089234431585

Epoch: 486| Step: 0
Training loss: 1.3677377700805664
Validation loss: 2.1748589674631753

Epoch: 5| Step: 1
Training loss: 0.8568192720413208
Validation loss: 2.216505934794744

Epoch: 5| Step: 2
Training loss: 1.1469327211380005
Validation loss: 2.2684659312168756

Epoch: 5| Step: 3
Training loss: 1.408510446548462
Validation loss: 2.224693646033605

Epoch: 5| Step: 4
Training loss: 1.0627772808074951
Validation loss: 2.2127991716066995

Epoch: 5| Step: 5
Training loss: 1.8490833044052124
Validation loss: 2.175427863995234

Epoch: 5| Step: 6
Training loss: 2.0701637268066406
Validation loss: 2.130598912636439

Epoch: 5| Step: 7
Training loss: 1.1782160997390747
Validation loss: 2.1116128166516623

Epoch: 5| Step: 8
Training loss: 0.7893506288528442
Validation loss: 2.0907485485076904

Epoch: 5| Step: 9
Training loss: 0.8157068490982056
Validation loss: 2.1107672452926636

Epoch: 5| Step: 10
Training loss: 0.9773204922676086
Validation loss: 2.1207810044288635

Epoch: 5| Step: 11
Training loss: 0.9409405589103699
Validation loss: 2.0275136778752008

Epoch: 487| Step: 0
Training loss: 1.0162038803100586
Validation loss: 2.0657140711943307

Epoch: 5| Step: 1
Training loss: 1.2750909328460693
Validation loss: 2.0767674446105957

Epoch: 5| Step: 2
Training loss: 1.114153265953064
Validation loss: 2.0758375575145087

Epoch: 5| Step: 3
Training loss: 1.7491286993026733
Validation loss: 2.136044586698214

Epoch: 5| Step: 4
Training loss: 0.9352327585220337
Validation loss: 2.1322428981463113

Epoch: 5| Step: 5
Training loss: 1.5936418771743774
Validation loss: 2.0869153092304864

Epoch: 5| Step: 6
Training loss: 0.7195061445236206
Validation loss: 2.0992523531119027

Epoch: 5| Step: 7
Training loss: 1.1049591302871704
Validation loss: 2.0906110803286233

Epoch: 5| Step: 8
Training loss: 0.5826436281204224
Validation loss: 2.120771328608195

Epoch: 5| Step: 9
Training loss: 1.1023443937301636
Validation loss: 2.129551276564598

Epoch: 5| Step: 10
Training loss: 0.8727225065231323
Validation loss: 2.0881553143262863

Epoch: 5| Step: 11
Training loss: 0.29153192043304443
Validation loss: 2.15746878584226

Epoch: 488| Step: 0
Training loss: 0.9834628105163574
Validation loss: 2.1586287717024484

Epoch: 5| Step: 1
Training loss: 1.0990753173828125
Validation loss: 2.1839925398429236

Epoch: 5| Step: 2
Training loss: 0.9980243444442749
Validation loss: 2.213548352320989

Epoch: 5| Step: 3
Training loss: 0.8458404541015625
Validation loss: 2.186461870869001

Epoch: 5| Step: 4
Training loss: 0.9317251443862915
Validation loss: 2.142714574933052

Epoch: 5| Step: 5
Training loss: 1.3461825847625732
Validation loss: 2.057343383630117

Epoch: 5| Step: 6
Training loss: 1.1837055683135986
Validation loss: 2.066229755679766

Epoch: 5| Step: 7
Training loss: 1.5577462911605835
Validation loss: 2.0971487065156302

Epoch: 5| Step: 8
Training loss: 1.3111575841903687
Validation loss: 2.1079934338728585

Epoch: 5| Step: 9
Training loss: 1.025718331336975
Validation loss: 2.109757443269094

Epoch: 5| Step: 10
Training loss: 1.5118730068206787
Validation loss: 2.136666695276896

Epoch: 5| Step: 11
Training loss: 0.32532984018325806
Validation loss: 2.112416739265124

Epoch: 489| Step: 0
Training loss: 1.6515729427337646
Validation loss: 2.1299478014310202

Epoch: 5| Step: 1
Training loss: 1.5284160375595093
Validation loss: 2.1051242649555206

Epoch: 5| Step: 2
Training loss: 1.0817142724990845
Validation loss: 2.1869394183158875

Epoch: 5| Step: 3
Training loss: 0.9981368184089661
Validation loss: 2.2308078507582345

Epoch: 5| Step: 4
Training loss: 0.9553940892219543
Validation loss: 2.235666881004969

Epoch: 5| Step: 5
Training loss: 1.2972780466079712
Validation loss: 2.2138466586669288

Epoch: 5| Step: 6
Training loss: 1.0639121532440186
Validation loss: 2.225763981540998

Epoch: 5| Step: 7
Training loss: 0.863747775554657
Validation loss: 2.1816531221071878

Epoch: 5| Step: 8
Training loss: 0.9842813611030579
Validation loss: 2.1488793243964515

Epoch: 5| Step: 9
Training loss: 1.0413501262664795
Validation loss: 2.10785503188769

Epoch: 5| Step: 10
Training loss: 1.1505943536758423
Validation loss: 2.1228664964437485

Epoch: 5| Step: 11
Training loss: 1.5990989208221436
Validation loss: 2.07633871336778

Epoch: 490| Step: 0
Training loss: 1.0591700077056885
Validation loss: 2.103947808345159

Epoch: 5| Step: 1
Training loss: 0.7452856302261353
Validation loss: 2.0706232438484826

Epoch: 5| Step: 2
Training loss: 0.7597380876541138
Validation loss: 2.101786901553472

Epoch: 5| Step: 3
Training loss: 1.4401026964187622
Validation loss: 2.0968341132005057

Epoch: 5| Step: 4
Training loss: 1.4787856340408325
Validation loss: 2.087453300754229

Epoch: 5| Step: 5
Training loss: 1.3796011209487915
Validation loss: 2.13754008213679

Epoch: 5| Step: 6
Training loss: 1.25555419921875
Validation loss: 2.147719199458758

Epoch: 5| Step: 7
Training loss: 1.2122315168380737
Validation loss: 2.175299127896627

Epoch: 5| Step: 8
Training loss: 1.1353352069854736
Validation loss: 2.1596319377422333

Epoch: 5| Step: 9
Training loss: 0.7479674220085144
Validation loss: 2.1407690743605294

Epoch: 5| Step: 10
Training loss: 0.8884047269821167
Validation loss: 2.13884307940801

Epoch: 5| Step: 11
Training loss: 3.1131367683410645
Validation loss: 2.1324555575847626

Epoch: 491| Step: 0
Training loss: 1.0917890071868896
Validation loss: 2.1331871151924133

Epoch: 5| Step: 1
Training loss: 1.1654232740402222
Validation loss: 2.133463904261589

Epoch: 5| Step: 2
Training loss: 1.7969077825546265
Validation loss: 2.156431476275126

Epoch: 5| Step: 3
Training loss: 1.200892686843872
Validation loss: 2.1371762305498123

Epoch: 5| Step: 4
Training loss: 1.2070096731185913
Validation loss: 2.17768802245458

Epoch: 5| Step: 5
Training loss: 0.9268571734428406
Validation loss: 2.1059981932242713

Epoch: 5| Step: 6
Training loss: 1.4180768728256226
Validation loss: 2.094087536136309

Epoch: 5| Step: 7
Training loss: 0.9309083223342896
Validation loss: 2.1252464205026627

Epoch: 5| Step: 8
Training loss: 0.7265178561210632
Validation loss: 2.1061104387044907

Epoch: 5| Step: 9
Training loss: 0.7898075580596924
Validation loss: 2.096665153900782

Epoch: 5| Step: 10
Training loss: 0.8947229385375977
Validation loss: 2.124799827734629

Epoch: 5| Step: 11
Training loss: 0.8056955933570862
Validation loss: 2.1651446471611657

Epoch: 492| Step: 0
Training loss: 1.5446321964263916
Validation loss: 2.0987343241771064

Epoch: 5| Step: 1
Training loss: 1.2174594402313232
Validation loss: 2.184542109568914

Epoch: 5| Step: 2
Training loss: 0.6717328429222107
Validation loss: 2.1388725340366364

Epoch: 5| Step: 3
Training loss: 0.9110463857650757
Validation loss: 2.1399094611406326

Epoch: 5| Step: 4
Training loss: 0.8630673289299011
Validation loss: 2.114955191810926

Epoch: 5| Step: 5
Training loss: 1.103303074836731
Validation loss: 2.116634950041771

Epoch: 5| Step: 6
Training loss: 0.6767367124557495
Validation loss: 2.106015915671984

Epoch: 5| Step: 7
Training loss: 1.2543103694915771
Validation loss: 2.1032403707504272

Epoch: 5| Step: 8
Training loss: 1.554247260093689
Validation loss: 2.132448598742485

Epoch: 5| Step: 9
Training loss: 1.3493014574050903
Validation loss: 2.1681267519791922

Epoch: 5| Step: 10
Training loss: 1.184346318244934
Validation loss: 2.159363607565562

Epoch: 5| Step: 11
Training loss: 0.4182788133621216
Validation loss: 2.2041741659243903

Epoch: 493| Step: 0
Training loss: 1.0589609146118164
Validation loss: 2.157506138086319

Epoch: 5| Step: 1
Training loss: 1.3027437925338745
Validation loss: 2.1655124723911285

Epoch: 5| Step: 2
Training loss: 1.6238933801651
Validation loss: 2.1670697728792825

Epoch: 5| Step: 3
Training loss: 1.0281330347061157
Validation loss: 2.11330209672451

Epoch: 5| Step: 4
Training loss: 1.3097590208053589
Validation loss: 2.1288342823584876

Epoch: 5| Step: 5
Training loss: 1.2812716960906982
Validation loss: 2.1019643445809684

Epoch: 5| Step: 6
Training loss: 0.5595874190330505
Validation loss: 2.077517658472061

Epoch: 5| Step: 7
Training loss: 1.010629653930664
Validation loss: 2.075768152872721

Epoch: 5| Step: 8
Training loss: 1.4973695278167725
Validation loss: 2.0999760131041207

Epoch: 5| Step: 9
Training loss: 1.5126396417617798
Validation loss: 2.1223640590906143

Epoch: 5| Step: 10
Training loss: 0.5736831426620483
Validation loss: 2.137063423792521

Epoch: 5| Step: 11
Training loss: 0.5655699372291565
Validation loss: 2.138970057169596

Epoch: 494| Step: 0
Training loss: 1.1385648250579834
Validation loss: 2.152291531364123

Epoch: 5| Step: 1
Training loss: 1.1044114828109741
Validation loss: 2.1536657263835273

Epoch: 5| Step: 2
Training loss: 1.2355347871780396
Validation loss: 2.1137499113877616

Epoch: 5| Step: 3
Training loss: 0.7899720072746277
Validation loss: 2.139350871245066

Epoch: 5| Step: 4
Training loss: 0.664270281791687
Validation loss: 2.10626982152462

Epoch: 5| Step: 5
Training loss: 0.8913119435310364
Validation loss: 2.0818937023480735

Epoch: 5| Step: 6
Training loss: 1.1632226705551147
Validation loss: 2.158478766679764

Epoch: 5| Step: 7
Training loss: 1.4442371129989624
Validation loss: 2.142617483933767

Epoch: 5| Step: 8
Training loss: 1.1273752450942993
Validation loss: 2.143807351589203

Epoch: 5| Step: 9
Training loss: 1.7549991607666016
Validation loss: 2.1364741226037345

Epoch: 5| Step: 10
Training loss: 0.6407249569892883
Validation loss: 2.1310979227224984

Epoch: 5| Step: 11
Training loss: 0.7511796951293945
Validation loss: 2.0890436669190726

Epoch: 495| Step: 0
Training loss: 0.9207110404968262
Validation loss: 2.111554265022278

Epoch: 5| Step: 1
Training loss: 1.4932968616485596
Validation loss: 2.152536148826281

Epoch: 5| Step: 2
Training loss: 0.8312467336654663
Validation loss: 2.1306756337483725

Epoch: 5| Step: 3
Training loss: 0.8869003057479858
Validation loss: 2.1319338232278824

Epoch: 5| Step: 4
Training loss: 0.735725998878479
Validation loss: 2.126801292101542

Epoch: 5| Step: 5
Training loss: 0.77285236120224
Validation loss: 2.1453355650107064

Epoch: 5| Step: 6
Training loss: 1.036412000656128
Validation loss: 2.1111506124337516

Epoch: 5| Step: 7
Training loss: 1.0734189748764038
Validation loss: 2.138655682404836

Epoch: 5| Step: 8
Training loss: 1.3732095956802368
Validation loss: 2.1217520038286843

Epoch: 5| Step: 9
Training loss: 1.4876463413238525
Validation loss: 2.137678454319636

Epoch: 5| Step: 10
Training loss: 1.1397807598114014
Validation loss: 2.1753445913394294

Epoch: 5| Step: 11
Training loss: 0.6048222780227661
Validation loss: 2.1656389832496643

Epoch: 496| Step: 0
Training loss: 0.8344271779060364
Validation loss: 2.1556379397710166

Epoch: 5| Step: 1
Training loss: 1.067815899848938
Validation loss: 2.159694438179334

Epoch: 5| Step: 2
Training loss: 1.1950972080230713
Validation loss: 2.17066320280234

Epoch: 5| Step: 3
Training loss: 0.8722745180130005
Validation loss: 2.173261816302935

Epoch: 5| Step: 4
Training loss: 1.6237949132919312
Validation loss: 2.194191202521324

Epoch: 5| Step: 5
Training loss: 1.7305173873901367
Validation loss: 2.1518598000208535

Epoch: 5| Step: 6
Training loss: 1.1661317348480225
Validation loss: 2.1460298945506415

Epoch: 5| Step: 7
Training loss: 0.7600658535957336
Validation loss: 2.1195903768142066

Epoch: 5| Step: 8
Training loss: 0.7198062539100647
Validation loss: 2.1181121518214545

Epoch: 5| Step: 9
Training loss: 0.5323123335838318
Validation loss: 2.1232077280680337

Epoch: 5| Step: 10
Training loss: 1.1420509815216064
Validation loss: 2.1318320482969284

Epoch: 5| Step: 11
Training loss: 1.443535327911377
Validation loss: 2.1194536288579306

Epoch: 497| Step: 0
Training loss: 1.7703354358673096
Validation loss: 2.1098907391230264

Epoch: 5| Step: 1
Training loss: 0.9286645650863647
Validation loss: 2.0963085989157357

Epoch: 5| Step: 2
Training loss: 0.6983962059020996
Validation loss: 2.105914225180944

Epoch: 5| Step: 3
Training loss: 1.2581161260604858
Validation loss: 2.1519682655731835

Epoch: 5| Step: 4
Training loss: 1.2771941423416138
Validation loss: 2.119325816631317

Epoch: 5| Step: 5
Training loss: 0.7859667539596558
Validation loss: 2.1050832271575928

Epoch: 5| Step: 6
Training loss: 1.8797038793563843
Validation loss: 2.1652845640977225

Epoch: 5| Step: 7
Training loss: 0.8574932813644409
Validation loss: 2.1692407379547753

Epoch: 5| Step: 8
Training loss: 0.6702662110328674
Validation loss: 2.165917952855428

Epoch: 5| Step: 9
Training loss: 1.0930424928665161
Validation loss: 2.2012855807940164

Epoch: 5| Step: 10
Training loss: 0.8109596371650696
Validation loss: 2.1677208095788956

Epoch: 5| Step: 11
Training loss: 0.5755558013916016
Validation loss: 2.137661392490069

Epoch: 498| Step: 0
Training loss: 1.14290452003479
Validation loss: 2.1365489959716797

Epoch: 5| Step: 1
Training loss: 0.834672749042511
Validation loss: 2.102874497572581

Epoch: 5| Step: 2
Training loss: 1.064897894859314
Validation loss: 2.1871595730384192

Epoch: 5| Step: 3
Training loss: 0.9702369570732117
Validation loss: 2.0747745782136917

Epoch: 5| Step: 4
Training loss: 1.0604798793792725
Validation loss: 2.0972215831279755

Epoch: 5| Step: 5
Training loss: 1.1529216766357422
Validation loss: 2.0928739408651986

Epoch: 5| Step: 6
Training loss: 1.289298415184021
Validation loss: 2.0822118123372397

Epoch: 5| Step: 7
Training loss: 1.1360797882080078
Validation loss: 2.1051629136006036

Epoch: 5| Step: 8
Training loss: 1.6163698434829712
Validation loss: 2.0978601624568305

Epoch: 5| Step: 9
Training loss: 0.9130155444145203
Validation loss: 2.166896308461825

Epoch: 5| Step: 10
Training loss: 0.5860528945922852
Validation loss: 2.1994137118260064

Epoch: 5| Step: 11
Training loss: 0.6113674640655518
Validation loss: 2.162271743019422

Epoch: 499| Step: 0
Training loss: 1.1676901578903198
Validation loss: 2.1479499290386834

Epoch: 5| Step: 1
Training loss: 0.765151858329773
Validation loss: 2.1732588559389114

Epoch: 5| Step: 2
Training loss: 1.2866880893707275
Validation loss: 2.147715841730436

Epoch: 5| Step: 3
Training loss: 1.5691635608673096
Validation loss: 2.117683380842209

Epoch: 5| Step: 4
Training loss: 1.512033224105835
Validation loss: 2.126866186658541

Epoch: 5| Step: 5
Training loss: 0.7271457314491272
Validation loss: 2.1593241492907205

Epoch: 5| Step: 6
Training loss: 0.9277929067611694
Validation loss: 2.1051279654105506

Epoch: 5| Step: 7
Training loss: 0.9689055681228638
Validation loss: 2.1289900640646615

Epoch: 5| Step: 8
Training loss: 0.9474277496337891
Validation loss: 2.1389020631710687

Epoch: 5| Step: 9
Training loss: 1.1550135612487793
Validation loss: 2.1157253434260688

Epoch: 5| Step: 10
Training loss: 1.0203735828399658
Validation loss: 2.1095967839161553

Epoch: 5| Step: 11
Training loss: 1.2836384773254395
Validation loss: 2.177340234319369

Epoch: 500| Step: 0
Training loss: 1.521567463874817
Validation loss: 2.222908998529116

Epoch: 5| Step: 1
Training loss: 1.1561888456344604
Validation loss: 2.211054672797521

Epoch: 5| Step: 2
Training loss: 1.0019961595535278
Validation loss: 2.22693961362044

Epoch: 5| Step: 3
Training loss: 0.7606222033500671
Validation loss: 2.177189682920774

Epoch: 5| Step: 4
Training loss: 1.4948234558105469
Validation loss: 2.1601270933945975

Epoch: 5| Step: 5
Training loss: 1.200163722038269
Validation loss: 2.130770285924276

Epoch: 5| Step: 6
Training loss: 0.5250115394592285
Validation loss: 2.146703854203224

Epoch: 5| Step: 7
Training loss: 1.37416672706604
Validation loss: 2.1290169109900794

Epoch: 5| Step: 8
Training loss: 1.2188483476638794
Validation loss: 2.0998504211505256

Epoch: 5| Step: 9
Training loss: 1.0996676683425903
Validation loss: 2.0858322978019714

Epoch: 5| Step: 10
Training loss: 1.1316070556640625
Validation loss: 2.071940263112386

Epoch: 5| Step: 11
Training loss: 1.0937225818634033
Validation loss: 2.0689036548137665

Testing loss: 1.9064815884871449
