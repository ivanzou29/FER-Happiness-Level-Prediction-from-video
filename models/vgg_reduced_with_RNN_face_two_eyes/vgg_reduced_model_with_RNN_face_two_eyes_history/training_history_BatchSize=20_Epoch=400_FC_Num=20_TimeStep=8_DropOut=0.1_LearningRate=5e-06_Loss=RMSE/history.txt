Epoch: 1| Step: 0
Training loss: 6.489116947892659
Validation loss: 5.907671291490203

Epoch: 5| Step: 1
Training loss: 5.8832300856106565
Validation loss: 5.905201161150822

Epoch: 5| Step: 2
Training loss: 5.880526601345398
Validation loss: 5.903083221411564

Epoch: 5| Step: 3
Training loss: 5.825157903405656
Validation loss: 5.900792515324454

Epoch: 5| Step: 4
Training loss: 6.505035210762638
Validation loss: 5.898659829503219

Epoch: 5| Step: 5
Training loss: 5.662431405769859
Validation loss: 5.8965542243593365

Epoch: 5| Step: 6
Training loss: 5.231125098848687
Validation loss: 5.8943821049944285

Epoch: 5| Step: 7
Training loss: 6.923731432240912
Validation loss: 5.8922179721802

Epoch: 5| Step: 8
Training loss: 6.101428705719388
Validation loss: 5.889990808698891

Epoch: 5| Step: 9
Training loss: 6.182219747260524
Validation loss: 5.887608687632035

Epoch: 5| Step: 10
Training loss: 5.4864223386579525
Validation loss: 5.885267119631641

Epoch: 5| Step: 11
Training loss: 4.7554956065961695
Validation loss: 5.882775707222693

Epoch: 2| Step: 0
Training loss: 6.596507286908009
Validation loss: 5.880364255186625

Epoch: 5| Step: 1
Training loss: 4.958985336562037
Validation loss: 5.87784819856238

Epoch: 5| Step: 2
Training loss: 6.204016018539989
Validation loss: 5.875075968799055

Epoch: 5| Step: 3
Training loss: 5.477963430281902
Validation loss: 5.872427918430369

Epoch: 5| Step: 4
Training loss: 6.5057151318068565
Validation loss: 5.869761200910122

Epoch: 5| Step: 5
Training loss: 6.469710863778124
Validation loss: 5.866724171230227

Epoch: 5| Step: 6
Training loss: 6.789892639749628
Validation loss: 5.8638212093859

Epoch: 5| Step: 7
Training loss: 5.499088211775537
Validation loss: 5.860366900092932

Epoch: 5| Step: 8
Training loss: 5.024008900847113
Validation loss: 5.857137702204156

Epoch: 5| Step: 9
Training loss: 6.360212041331119
Validation loss: 5.853550775605066

Epoch: 5| Step: 10
Training loss: 5.479752116479051
Validation loss: 5.849961289660847

Epoch: 5| Step: 11
Training loss: 6.316767996559893
Validation loss: 5.846280813004782

Epoch: 3| Step: 0
Training loss: 5.677866395846421
Validation loss: 5.84216345535286

Epoch: 5| Step: 1
Training loss: 5.4667801279218295
Validation loss: 5.8379044833060805

Epoch: 5| Step: 2
Training loss: 6.817321471061411
Validation loss: 5.8339105206993365

Epoch: 5| Step: 3
Training loss: 5.152274153718737
Validation loss: 5.828915989766294

Epoch: 5| Step: 4
Training loss: 7.09914646659718
Validation loss: 5.824077697451341

Epoch: 5| Step: 5
Training loss: 5.3281625875003
Validation loss: 5.818877478055748

Epoch: 5| Step: 6
Training loss: 6.563645617080579
Validation loss: 5.813533827746716

Epoch: 5| Step: 7
Training loss: 4.933300695225431
Validation loss: 5.807902018086629

Epoch: 5| Step: 8
Training loss: 5.980782887426462
Validation loss: 5.801933706695348

Epoch: 5| Step: 9
Training loss: 6.267485915397579
Validation loss: 5.795565235273118

Epoch: 5| Step: 10
Training loss: 5.559821180308485
Validation loss: 5.789178906298709

Epoch: 5| Step: 11
Training loss: 5.889125967151868
Validation loss: 5.7826076322511755

Epoch: 4| Step: 0
Training loss: 6.622324565264457
Validation loss: 5.775661702524664

Epoch: 5| Step: 1
Training loss: 5.46706726343207
Validation loss: 5.768371865005045

Epoch: 5| Step: 2
Training loss: 5.676671713742611
Validation loss: 5.761090398459179

Epoch: 5| Step: 3
Training loss: 5.577405867181928
Validation loss: 5.753174900416633

Epoch: 5| Step: 4
Training loss: 5.473817929379733
Validation loss: 5.745720507828254

Epoch: 5| Step: 5
Training loss: 5.93341566450168
Validation loss: 5.738045843639531

Epoch: 5| Step: 6
Training loss: 5.6412616909319295
Validation loss: 5.729533661156425

Epoch: 5| Step: 7
Training loss: 5.693382490840723
Validation loss: 5.720583665164215

Epoch: 5| Step: 8
Training loss: 5.658901878561901
Validation loss: 5.7122032477987865

Epoch: 5| Step: 9
Training loss: 5.988771422269626
Validation loss: 5.70349534456568

Epoch: 5| Step: 10
Training loss: 6.3578007879592295
Validation loss: 5.694687922888577

Epoch: 5| Step: 11
Training loss: 6.54792693433969
Validation loss: 5.685170244929485

Epoch: 5| Step: 0
Training loss: 5.883582157280108
Validation loss: 5.675644839897328

Epoch: 5| Step: 1
Training loss: 5.901017065802189
Validation loss: 5.665809919534564

Epoch: 5| Step: 2
Training loss: 5.145080305386589
Validation loss: 5.656170017245973

Epoch: 5| Step: 3
Training loss: 5.386901099954719
Validation loss: 5.646210318879087

Epoch: 5| Step: 4
Training loss: 6.305222952982424
Validation loss: 5.6364393475627015

Epoch: 5| Step: 5
Training loss: 5.8391829815348055
Validation loss: 5.6265302130837345

Epoch: 5| Step: 6
Training loss: 6.326152277389373
Validation loss: 5.6167266897207195

Epoch: 5| Step: 7
Training loss: 5.69206909425127
Validation loss: 5.606467199069658

Epoch: 5| Step: 8
Training loss: 5.4337088862711616
Validation loss: 5.596977396812324

Epoch: 5| Step: 9
Training loss: 5.6957311070869805
Validation loss: 5.587438684876646

Epoch: 5| Step: 10
Training loss: 5.432107641285625
Validation loss: 5.578118602987659

Epoch: 5| Step: 11
Training loss: 5.804450912069547
Validation loss: 5.568620935864629

Epoch: 6| Step: 0
Training loss: 5.441449189136484
Validation loss: 5.559637997892732

Epoch: 5| Step: 1
Training loss: 5.426520476438025
Validation loss: 5.54999750927706

Epoch: 5| Step: 2
Training loss: 5.9058895909381475
Validation loss: 5.541089897926405

Epoch: 5| Step: 3
Training loss: 6.465576277890828
Validation loss: 5.532554056070439

Epoch: 5| Step: 4
Training loss: 6.114509473762906
Validation loss: 5.522884637986073

Epoch: 5| Step: 5
Training loss: 5.8016942805234235
Validation loss: 5.513529400139497

Epoch: 5| Step: 6
Training loss: 5.139122462191039
Validation loss: 5.504194271510301

Epoch: 5| Step: 7
Training loss: 4.988744082446162
Validation loss: 5.495011220104273

Epoch: 5| Step: 8
Training loss: 5.86927613976248
Validation loss: 5.48613252219785

Epoch: 5| Step: 9
Training loss: 5.390833046257061
Validation loss: 5.477125000193621

Epoch: 5| Step: 10
Training loss: 5.609774859529514
Validation loss: 5.4679054625398145

Epoch: 5| Step: 11
Training loss: 3.392331304888853
Validation loss: 5.45940115241294

Epoch: 7| Step: 0
Training loss: 4.899419804691921
Validation loss: 5.450908505546841

Epoch: 5| Step: 1
Training loss: 4.705414579086947
Validation loss: 5.442936528972281

Epoch: 5| Step: 2
Training loss: 5.841095836718524
Validation loss: 5.434356518904659

Epoch: 5| Step: 3
Training loss: 5.461495956222433
Validation loss: 5.425894113332143

Epoch: 5| Step: 4
Training loss: 5.729644237611931
Validation loss: 5.417688239183246

Epoch: 5| Step: 5
Training loss: 5.251607013163031
Validation loss: 5.4087419665078365

Epoch: 5| Step: 6
Training loss: 5.357444838232322
Validation loss: 5.400094403218793

Epoch: 5| Step: 7
Training loss: 5.138561634721153
Validation loss: 5.391515590058517

Epoch: 5| Step: 8
Training loss: 6.255031544021119
Validation loss: 5.38264735263345

Epoch: 5| Step: 9
Training loss: 6.040859335090303
Validation loss: 5.373343515567898

Epoch: 5| Step: 10
Training loss: 5.657852873069499
Validation loss: 5.364806897094355

Epoch: 5| Step: 11
Training loss: 6.640228331443217
Validation loss: 5.355817980501186

Epoch: 8| Step: 0
Training loss: 5.352431178071439
Validation loss: 5.347176834288129

Epoch: 5| Step: 1
Training loss: 5.5304316545717
Validation loss: 5.338416652301175

Epoch: 5| Step: 2
Training loss: 4.84938046932588
Validation loss: 5.330277322374016

Epoch: 5| Step: 3
Training loss: 5.5870897931908825
Validation loss: 5.3216135055980205

Epoch: 5| Step: 4
Training loss: 6.049003758650508
Validation loss: 5.313973966580924

Epoch: 5| Step: 5
Training loss: 4.928800040524827
Validation loss: 5.305801948708974

Epoch: 5| Step: 6
Training loss: 5.728629828068074
Validation loss: 5.297510069639061

Epoch: 5| Step: 7
Training loss: 5.806933947666238
Validation loss: 5.2894475994847046

Epoch: 5| Step: 8
Training loss: 5.60500562927889
Validation loss: 5.281887602831117

Epoch: 5| Step: 9
Training loss: 5.337793432384457
Validation loss: 5.273871894181811

Epoch: 5| Step: 10
Training loss: 4.645605221381258
Validation loss: 5.266783770736104

Epoch: 5| Step: 11
Training loss: 5.933771187274555
Validation loss: 5.259613544859153

Epoch: 9| Step: 0
Training loss: 5.667487178564187
Validation loss: 5.252821996430885

Epoch: 5| Step: 1
Training loss: 4.519478707762323
Validation loss: 5.245619823705207

Epoch: 5| Step: 2
Training loss: 4.960861565917385
Validation loss: 5.239506224816315

Epoch: 5| Step: 3
Training loss: 5.31622596676092
Validation loss: 5.231668499454803

Epoch: 5| Step: 4
Training loss: 5.567800846407744
Validation loss: 5.224599449647406

Epoch: 5| Step: 5
Training loss: 4.654778779342703
Validation loss: 5.21637380872786

Epoch: 5| Step: 6
Training loss: 6.140549210330636
Validation loss: 5.209471054427301

Epoch: 5| Step: 7
Training loss: 5.173754946809308
Validation loss: 5.202425698759951

Epoch: 5| Step: 8
Training loss: 5.794050572241444
Validation loss: 5.1951884013486564

Epoch: 5| Step: 9
Training loss: 5.120564285713634
Validation loss: 5.188200715626178

Epoch: 5| Step: 10
Training loss: 5.2821268109977195
Validation loss: 5.180984764227904

Epoch: 5| Step: 11
Training loss: 6.731537612820157
Validation loss: 5.17358927825258

Epoch: 10| Step: 0
Training loss: 5.212071514127928
Validation loss: 5.16593133656919

Epoch: 5| Step: 1
Training loss: 5.782333684855759
Validation loss: 5.15885625919747

Epoch: 5| Step: 2
Training loss: 4.916107189006239
Validation loss: 5.151068509619816

Epoch: 5| Step: 3
Training loss: 5.038987175430236
Validation loss: 5.144587596371363

Epoch: 5| Step: 4
Training loss: 5.239942271664448
Validation loss: 5.137080299021139

Epoch: 5| Step: 5
Training loss: 5.605236003443287
Validation loss: 5.130022921495494

Epoch: 5| Step: 6
Training loss: 5.064445592695903
Validation loss: 5.122872732976501

Epoch: 5| Step: 7
Training loss: 5.3701513732943065
Validation loss: 5.115268594035764

Epoch: 5| Step: 8
Training loss: 4.956656078813879
Validation loss: 5.1085495277112924

Epoch: 5| Step: 9
Training loss: 5.123111469939225
Validation loss: 5.1022410464830275

Epoch: 5| Step: 10
Training loss: 5.471728227826592
Validation loss: 5.094570803672753

Epoch: 5| Step: 11
Training loss: 4.964002728605173
Validation loss: 5.088338446357891

Epoch: 11| Step: 0
Training loss: 5.403748214548431
Validation loss: 5.081122412649663

Epoch: 5| Step: 1
Training loss: 5.02971099629977
Validation loss: 5.074359135182236

Epoch: 5| Step: 2
Training loss: 4.222009826359592
Validation loss: 5.06844719116732

Epoch: 5| Step: 3
Training loss: 5.7166577456806005
Validation loss: 5.060998332847627

Epoch: 5| Step: 4
Training loss: 4.181292131379898
Validation loss: 5.054382566582608

Epoch: 5| Step: 5
Training loss: 5.970616553081078
Validation loss: 5.048012738081795

Epoch: 5| Step: 6
Training loss: 5.1239096249212235
Validation loss: 5.041844320188529

Epoch: 5| Step: 7
Training loss: 4.621543830113183
Validation loss: 5.035106271002984

Epoch: 5| Step: 8
Training loss: 5.079582122676591
Validation loss: 5.029302231869113

Epoch: 5| Step: 9
Training loss: 6.0371833038986855
Validation loss: 5.023237233300574

Epoch: 5| Step: 10
Training loss: 5.103212145349187
Validation loss: 5.017546668869138

Epoch: 5| Step: 11
Training loss: 5.285454334951298
Validation loss: 5.011564542281507

Epoch: 12| Step: 0
Training loss: 5.693470598184606
Validation loss: 5.005470081144795

Epoch: 5| Step: 1
Training loss: 5.228045015241977
Validation loss: 4.9995982406058666

Epoch: 5| Step: 2
Training loss: 5.023429526505142
Validation loss: 4.993690089477906

Epoch: 5| Step: 3
Training loss: 4.245239284138156
Validation loss: 4.98876469638552

Epoch: 5| Step: 4
Training loss: 5.44205205389024
Validation loss: 4.983373750673715

Epoch: 5| Step: 5
Training loss: 5.222053806935008
Validation loss: 4.977737559511332

Epoch: 5| Step: 6
Training loss: 5.181324235593695
Validation loss: 4.972418280713625

Epoch: 5| Step: 7
Training loss: 5.695769952264671
Validation loss: 4.9670045213975085

Epoch: 5| Step: 8
Training loss: 4.497171996848495
Validation loss: 4.961253735332728

Epoch: 5| Step: 9
Training loss: 4.764645134920202
Validation loss: 4.956026745546746

Epoch: 5| Step: 10
Training loss: 4.713004549169581
Validation loss: 4.951026263280924

Epoch: 5| Step: 11
Training loss: 6.080631161103493
Validation loss: 4.94520365438055

Epoch: 13| Step: 0
Training loss: 5.345485293961073
Validation loss: 4.940572482848771

Epoch: 5| Step: 1
Training loss: 5.028716972028315
Validation loss: 4.935594215060362

Epoch: 5| Step: 2
Training loss: 4.844792604524922
Validation loss: 4.930555191696703

Epoch: 5| Step: 3
Training loss: 5.623014820321538
Validation loss: 4.925209425654506

Epoch: 5| Step: 4
Training loss: 4.852118762771282
Validation loss: 4.919432365978961

Epoch: 5| Step: 5
Training loss: 4.959717415789172
Validation loss: 4.914551185523249

Epoch: 5| Step: 6
Training loss: 4.830173687388664
Validation loss: 4.909136423214117

Epoch: 5| Step: 7
Training loss: 4.980217518173309
Validation loss: 4.904755642164291

Epoch: 5| Step: 8
Training loss: 4.8150152593986855
Validation loss: 4.899527404662318

Epoch: 5| Step: 9
Training loss: 5.21889436259443
Validation loss: 4.894349975963628

Epoch: 5| Step: 10
Training loss: 5.053883319070911
Validation loss: 4.889775276507132

Epoch: 5| Step: 11
Training loss: 4.152296437436242
Validation loss: 4.885163211822633

Epoch: 14| Step: 0
Training loss: 4.789880679561702
Validation loss: 4.8799261162850405

Epoch: 5| Step: 1
Training loss: 4.852341839641489
Validation loss: 4.875210235822682

Epoch: 5| Step: 2
Training loss: 4.785160435266027
Validation loss: 4.870731710456696

Epoch: 5| Step: 3
Training loss: 4.748554411312182
Validation loss: 4.866123815965278

Epoch: 5| Step: 4
Training loss: 4.809093111637212
Validation loss: 4.860681405224341

Epoch: 5| Step: 5
Training loss: 5.285636569891522
Validation loss: 4.8559108787556635

Epoch: 5| Step: 6
Training loss: 5.803728602031211
Validation loss: 4.851618563235459

Epoch: 5| Step: 7
Training loss: 4.968824853873076
Validation loss: 4.846884429089515

Epoch: 5| Step: 8
Training loss: 5.325822349413259
Validation loss: 4.841417682218286

Epoch: 5| Step: 9
Training loss: 4.298614260922814
Validation loss: 4.836833281329926

Epoch: 5| Step: 10
Training loss: 5.0812238891981725
Validation loss: 4.831562904598209

Epoch: 5| Step: 11
Training loss: 4.439212737181239
Validation loss: 4.826425823311244

Epoch: 15| Step: 0
Training loss: 5.7324657951894995
Validation loss: 4.82204858974667

Epoch: 5| Step: 1
Training loss: 4.095872401649107
Validation loss: 4.816600827599802

Epoch: 5| Step: 2
Training loss: 5.017544102952484
Validation loss: 4.812176210484458

Epoch: 5| Step: 3
Training loss: 4.41494045472303
Validation loss: 4.807406566344739

Epoch: 5| Step: 4
Training loss: 3.911315319360716
Validation loss: 4.80225402903778

Epoch: 5| Step: 5
Training loss: 3.9252967042000044
Validation loss: 4.797341132529448

Epoch: 5| Step: 6
Training loss: 5.022958498316074
Validation loss: 4.7927376365746905

Epoch: 5| Step: 7
Training loss: 4.91266130565969
Validation loss: 4.788231151582418

Epoch: 5| Step: 8
Training loss: 5.440715321465415
Validation loss: 4.783818811885771

Epoch: 5| Step: 9
Training loss: 5.550422844802323
Validation loss: 4.778598228723327

Epoch: 5| Step: 10
Training loss: 5.582766186201507
Validation loss: 4.77415253673364

Epoch: 5| Step: 11
Training loss: 5.227577646883805
Validation loss: 4.768766641316973

Epoch: 16| Step: 0
Training loss: 5.396696966666223
Validation loss: 4.763790031657952

Epoch: 5| Step: 1
Training loss: 4.785015543211881
Validation loss: 4.758778198989648

Epoch: 5| Step: 2
Training loss: 4.766355764924817
Validation loss: 4.753709382050758

Epoch: 5| Step: 3
Training loss: 4.84645231606377
Validation loss: 4.748862732716214

Epoch: 5| Step: 4
Training loss: 4.728668903701133
Validation loss: 4.744091357722217

Epoch: 5| Step: 5
Training loss: 4.272536494867608
Validation loss: 4.738838508964749

Epoch: 5| Step: 6
Training loss: 5.079917614786923
Validation loss: 4.7338727846247135

Epoch: 5| Step: 7
Training loss: 4.7866874144661455
Validation loss: 4.729305688212252

Epoch: 5| Step: 8
Training loss: 4.7522433153533195
Validation loss: 4.724606296748041

Epoch: 5| Step: 9
Training loss: 5.1634253312237455
Validation loss: 4.72011441174275

Epoch: 5| Step: 10
Training loss: 4.873128482846225
Validation loss: 4.714779014532781

Epoch: 5| Step: 11
Training loss: 4.787220935307589
Validation loss: 4.710183550895315

Epoch: 17| Step: 0
Training loss: 4.638032028238992
Validation loss: 4.704826283844081

Epoch: 5| Step: 1
Training loss: 3.9501980888819044
Validation loss: 4.700099905791924

Epoch: 5| Step: 2
Training loss: 5.476378085395867
Validation loss: 4.695113209045765

Epoch: 5| Step: 3
Training loss: 4.835269715479742
Validation loss: 4.690339809204956

Epoch: 5| Step: 4
Training loss: 4.351148274018048
Validation loss: 4.685202404238242

Epoch: 5| Step: 5
Training loss: 5.588333661657442
Validation loss: 4.680815919953842

Epoch: 5| Step: 6
Training loss: 4.611371141529561
Validation loss: 4.6756985178219495

Epoch: 5| Step: 7
Training loss: 5.1088081068706375
Validation loss: 4.670725422661047

Epoch: 5| Step: 8
Training loss: 4.365109626643105
Validation loss: 4.6657242916210855

Epoch: 5| Step: 9
Training loss: 5.28642119095506
Validation loss: 4.66088478637446

Epoch: 5| Step: 10
Training loss: 4.185077706803938
Validation loss: 4.656092297573749

Epoch: 5| Step: 11
Training loss: 5.583429288276829
Validation loss: 4.651256879531296

Epoch: 18| Step: 0
Training loss: 4.517824897672582
Validation loss: 4.646281005547928

Epoch: 5| Step: 1
Training loss: 5.598688939437176
Validation loss: 4.641170739345472

Epoch: 5| Step: 2
Training loss: 4.247643659024699
Validation loss: 4.636337937376182

Epoch: 5| Step: 3
Training loss: 5.046130807530556
Validation loss: 4.631516205021978

Epoch: 5| Step: 4
Training loss: 4.320459732388943
Validation loss: 4.626271305112475

Epoch: 5| Step: 5
Training loss: 4.670823607263072
Validation loss: 4.622201743192626

Epoch: 5| Step: 6
Training loss: 4.6797152153812
Validation loss: 4.617532827993479

Epoch: 5| Step: 7
Training loss: 4.78047483056996
Validation loss: 4.61239596579511

Epoch: 5| Step: 8
Training loss: 5.107674505284055
Validation loss: 4.607106209711632

Epoch: 5| Step: 9
Training loss: 4.476167724671368
Validation loss: 4.602494133084419

Epoch: 5| Step: 10
Training loss: 4.820794821771929
Validation loss: 4.596977899032042

Epoch: 5| Step: 11
Training loss: 3.664946687318416
Validation loss: 4.592203359975616

Epoch: 19| Step: 0
Training loss: 4.170572713406697
Validation loss: 4.587485265058506

Epoch: 5| Step: 1
Training loss: 4.422711943555554
Validation loss: 4.582951788482297

Epoch: 5| Step: 2
Training loss: 4.866821863147184
Validation loss: 4.578679160818857

Epoch: 5| Step: 3
Training loss: 4.618539370223734
Validation loss: 4.574588455561923

Epoch: 5| Step: 4
Training loss: 4.485639334096724
Validation loss: 4.569289942406155

Epoch: 5| Step: 5
Training loss: 4.579113954351168
Validation loss: 4.564937362916647

Epoch: 5| Step: 6
Training loss: 5.047027680062822
Validation loss: 4.5604404608586595

Epoch: 5| Step: 7
Training loss: 5.050151694257289
Validation loss: 4.555533398726838

Epoch: 5| Step: 8
Training loss: 4.767428897833552
Validation loss: 4.550766371019131

Epoch: 5| Step: 9
Training loss: 4.584508618030816
Validation loss: 4.545758734119224

Epoch: 5| Step: 10
Training loss: 4.674955341309402
Validation loss: 4.540823349248941

Epoch: 5| Step: 11
Training loss: 5.8524056859749924
Validation loss: 4.536483820052731

Epoch: 20| Step: 0
Training loss: 4.76355035368011
Validation loss: 4.531147379096798

Epoch: 5| Step: 1
Training loss: 4.7313347550615275
Validation loss: 4.526008564864935

Epoch: 5| Step: 2
Training loss: 4.622129838480785
Validation loss: 4.521298646785577

Epoch: 5| Step: 3
Training loss: 4.5008736927860005
Validation loss: 4.516827019640334

Epoch: 5| Step: 4
Training loss: 3.7526243563586967
Validation loss: 4.511325060469337

Epoch: 5| Step: 5
Training loss: 4.844912284946769
Validation loss: 4.507223310041135

Epoch: 5| Step: 6
Training loss: 4.5478808152443895
Validation loss: 4.502395464721341

Epoch: 5| Step: 7
Training loss: 4.221611352420859
Validation loss: 4.498085095796295

Epoch: 5| Step: 8
Training loss: 5.504739280021863
Validation loss: 4.49388461134636

Epoch: 5| Step: 9
Training loss: 4.60683337467999
Validation loss: 4.489173767219245

Epoch: 5| Step: 10
Training loss: 4.188008291795569
Validation loss: 4.484147122537902

Epoch: 5| Step: 11
Training loss: 6.633022704910441
Validation loss: 4.479674584031154

Epoch: 21| Step: 0
Training loss: 5.448386158111893
Validation loss: 4.474900803274586

Epoch: 5| Step: 1
Training loss: 3.823549985614504
Validation loss: 4.469381932391171

Epoch: 5| Step: 2
Training loss: 4.312233294657053
Validation loss: 4.465808745212897

Epoch: 5| Step: 3
Training loss: 5.013537962031256
Validation loss: 4.460715266636332

Epoch: 5| Step: 4
Training loss: 4.373460553303723
Validation loss: 4.456158351089505

Epoch: 5| Step: 5
Training loss: 4.454706707514602
Validation loss: 4.451021128020188

Epoch: 5| Step: 6
Training loss: 4.428310927187327
Validation loss: 4.446087421615387

Epoch: 5| Step: 7
Training loss: 4.191448570528424
Validation loss: 4.4415358203249555

Epoch: 5| Step: 8
Training loss: 5.106713024423671
Validation loss: 4.436693861543886

Epoch: 5| Step: 9
Training loss: 4.684664466266397
Validation loss: 4.4321093389153345

Epoch: 5| Step: 10
Training loss: 4.330735724056721
Validation loss: 4.427323694622927

Epoch: 5| Step: 11
Training loss: 4.448285601976668
Validation loss: 4.42231059091274

Epoch: 22| Step: 0
Training loss: 4.196573930907015
Validation loss: 4.417724422733457

Epoch: 5| Step: 1
Training loss: 3.767485226385138
Validation loss: 4.413229678647205

Epoch: 5| Step: 2
Training loss: 4.819991980581617
Validation loss: 4.408846800141359

Epoch: 5| Step: 3
Training loss: 5.060056120067486
Validation loss: 4.404313814140502

Epoch: 5| Step: 4
Training loss: 4.921543655141432
Validation loss: 4.399549809999612

Epoch: 5| Step: 5
Training loss: 4.5320255010549
Validation loss: 4.39515952359281

Epoch: 5| Step: 6
Training loss: 3.935505316351604
Validation loss: 4.390589178805768

Epoch: 5| Step: 7
Training loss: 4.391265713788201
Validation loss: 4.386060933187185

Epoch: 5| Step: 8
Training loss: 4.943740377886989
Validation loss: 4.381535961271267

Epoch: 5| Step: 9
Training loss: 4.608194077073745
Validation loss: 4.376685653382892

Epoch: 5| Step: 10
Training loss: 4.486505832897473
Validation loss: 4.372213320835482

Epoch: 5| Step: 11
Training loss: 4.048980754178152
Validation loss: 4.368197120241788

Epoch: 23| Step: 0
Training loss: 4.249676860417595
Validation loss: 4.36355616364568

Epoch: 5| Step: 1
Training loss: 4.206770553233065
Validation loss: 4.358486299158387

Epoch: 5| Step: 2
Training loss: 4.638320710391981
Validation loss: 4.353943233445857

Epoch: 5| Step: 3
Training loss: 4.370239719825474
Validation loss: 4.349513554870121

Epoch: 5| Step: 4
Training loss: 3.6346556879028435
Validation loss: 4.344923542405009

Epoch: 5| Step: 5
Training loss: 4.736831279653035
Validation loss: 4.34035817830534

Epoch: 5| Step: 6
Training loss: 4.179972929433383
Validation loss: 4.335954985712209

Epoch: 5| Step: 7
Training loss: 4.534588655871016
Validation loss: 4.331360742420204

Epoch: 5| Step: 8
Training loss: 4.969862711370713
Validation loss: 4.32708229606125

Epoch: 5| Step: 9
Training loss: 4.129748299158715
Validation loss: 4.322646312609125

Epoch: 5| Step: 10
Training loss: 5.09943638847496
Validation loss: 4.318094697176849

Epoch: 5| Step: 11
Training loss: 5.454630734037103
Validation loss: 4.313137394337685

Epoch: 24| Step: 0
Training loss: 5.092605181334892
Validation loss: 4.308476081871475

Epoch: 5| Step: 1
Training loss: 4.038353627198904
Validation loss: 4.30374256985411

Epoch: 5| Step: 2
Training loss: 3.772834303132599
Validation loss: 4.299063551754915

Epoch: 5| Step: 3
Training loss: 4.09189150024835
Validation loss: 4.294601898047136

Epoch: 5| Step: 4
Training loss: 4.079319804469695
Validation loss: 4.289507585140479

Epoch: 5| Step: 5
Training loss: 4.566318116263475
Validation loss: 4.284873918327592

Epoch: 5| Step: 6
Training loss: 4.084756771770075
Validation loss: 4.280320551609546

Epoch: 5| Step: 7
Training loss: 4.715394500700998
Validation loss: 4.2754127730737945

Epoch: 5| Step: 8
Training loss: 4.899753034946435
Validation loss: 4.271055256109735

Epoch: 5| Step: 9
Training loss: 4.306732301320152
Validation loss: 4.26633954147645

Epoch: 5| Step: 10
Training loss: 4.607444022506646
Validation loss: 4.261566159377625

Epoch: 5| Step: 11
Training loss: 4.957827288451983
Validation loss: 4.257279342261423

Epoch: 25| Step: 0
Training loss: 4.484212307520787
Validation loss: 4.251775071693498

Epoch: 5| Step: 1
Training loss: 5.1093440156982926
Validation loss: 4.247328881867095

Epoch: 5| Step: 2
Training loss: 4.628853095027082
Validation loss: 4.241943876929675

Epoch: 5| Step: 3
Training loss: 4.4641640346838125
Validation loss: 4.237433189007934

Epoch: 5| Step: 4
Training loss: 3.9027900936947524
Validation loss: 4.232204711581618

Epoch: 5| Step: 5
Training loss: 4.094249898658608
Validation loss: 4.226632879755937

Epoch: 5| Step: 6
Training loss: 3.9934948238226062
Validation loss: 4.22224902348768

Epoch: 5| Step: 7
Training loss: 5.026509391354696
Validation loss: 4.216859822630172

Epoch: 5| Step: 8
Training loss: 3.857723361438224
Validation loss: 4.212152540515264

Epoch: 5| Step: 9
Training loss: 4.322195901493669
Validation loss: 4.208034106591684

Epoch: 5| Step: 10
Training loss: 3.9855214582599463
Validation loss: 4.202473264931037

Epoch: 5| Step: 11
Training loss: 3.610168898163437
Validation loss: 4.197196064037275

Epoch: 26| Step: 0
Training loss: 4.615525929415036
Validation loss: 4.192658563480401

Epoch: 5| Step: 1
Training loss: 3.4156836669574258
Validation loss: 4.188052416181354

Epoch: 5| Step: 2
Training loss: 4.769697206751368
Validation loss: 4.183981954904924

Epoch: 5| Step: 3
Training loss: 4.3995325273659
Validation loss: 4.178996205426985

Epoch: 5| Step: 4
Training loss: 4.292883888634635
Validation loss: 4.174311889355656

Epoch: 5| Step: 5
Training loss: 3.817283006457813
Validation loss: 4.170030698167736

Epoch: 5| Step: 6
Training loss: 4.662045552296701
Validation loss: 4.165400654464787

Epoch: 5| Step: 7
Training loss: 4.244475420383334
Validation loss: 4.160931085535526

Epoch: 5| Step: 8
Training loss: 4.1688740541681755
Validation loss: 4.15614645214687

Epoch: 5| Step: 9
Training loss: 4.479294081657366
Validation loss: 4.150652948205099

Epoch: 5| Step: 10
Training loss: 4.351007121342219
Validation loss: 4.1459632961791115

Epoch: 5| Step: 11
Training loss: 3.8324791882690796
Validation loss: 4.141039903114556

Epoch: 27| Step: 0
Training loss: 4.282180573619927
Validation loss: 4.136696185950103

Epoch: 5| Step: 1
Training loss: 3.986129912813145
Validation loss: 4.131072391341437

Epoch: 5| Step: 2
Training loss: 4.601205601476699
Validation loss: 4.126056102460021

Epoch: 5| Step: 3
Training loss: 4.182349154345263
Validation loss: 4.1211511400032395

Epoch: 5| Step: 4
Training loss: 4.779866535765559
Validation loss: 4.1156068840583995

Epoch: 5| Step: 5
Training loss: 3.828302745195906
Validation loss: 4.110632453831658

Epoch: 5| Step: 6
Training loss: 4.147285373278192
Validation loss: 4.104968247664481

Epoch: 5| Step: 7
Training loss: 4.2883673766458115
Validation loss: 4.100532678565779

Epoch: 5| Step: 8
Training loss: 4.200446314031468
Validation loss: 4.096767643138534

Epoch: 5| Step: 9
Training loss: 4.484889197028076
Validation loss: 4.091798705568716

Epoch: 5| Step: 10
Training loss: 3.8951759531729446
Validation loss: 4.086388732618229

Epoch: 5| Step: 11
Training loss: 3.743611934707975
Validation loss: 4.081803106475938

Epoch: 28| Step: 0
Training loss: 4.27196861002673
Validation loss: 4.077186242573605

Epoch: 5| Step: 1
Training loss: 4.361266460742976
Validation loss: 4.072588947246662

Epoch: 5| Step: 2
Training loss: 3.954843863625559
Validation loss: 4.0674249531614874

Epoch: 5| Step: 3
Training loss: 4.220844116398003
Validation loss: 4.062558237294163

Epoch: 5| Step: 4
Training loss: 4.237147475801315
Validation loss: 4.058685529330169

Epoch: 5| Step: 5
Training loss: 3.5497958218596306
Validation loss: 4.053647853134079

Epoch: 5| Step: 6
Training loss: 4.162249143447435
Validation loss: 4.049141758378104

Epoch: 5| Step: 7
Training loss: 4.397224868920347
Validation loss: 4.044097806623481

Epoch: 5| Step: 8
Training loss: 4.413624753598358
Validation loss: 4.0399406703284475

Epoch: 5| Step: 9
Training loss: 3.9128154054692934
Validation loss: 4.0345999970401065

Epoch: 5| Step: 10
Training loss: 4.581943000535499
Validation loss: 4.030157088940475

Epoch: 5| Step: 11
Training loss: 3.482732685144922
Validation loss: 4.024964935829224

Epoch: 29| Step: 0
Training loss: 3.33922506033976
Validation loss: 4.020017055147915

Epoch: 5| Step: 1
Training loss: 4.13415505537112
Validation loss: 4.015433854873844

Epoch: 5| Step: 2
Training loss: 4.5144700417990125
Validation loss: 4.00942520998177

Epoch: 5| Step: 3
Training loss: 4.030043547137089
Validation loss: 4.004055698986129

Epoch: 5| Step: 4
Training loss: 3.9848996284509006
Validation loss: 3.9993590447370426

Epoch: 5| Step: 5
Training loss: 3.393211819459727
Validation loss: 3.9948960812420635

Epoch: 5| Step: 6
Training loss: 4.799779155737028
Validation loss: 3.98941587822113

Epoch: 5| Step: 7
Training loss: 4.316449996243251
Validation loss: 3.9847648429888536

Epoch: 5| Step: 8
Training loss: 4.556762850643201
Validation loss: 3.979816082526042

Epoch: 5| Step: 9
Training loss: 3.615289111678753
Validation loss: 3.97447457549681

Epoch: 5| Step: 10
Training loss: 4.364877379837333
Validation loss: 3.9694436636045194

Epoch: 5| Step: 11
Training loss: 4.440714142218063
Validation loss: 3.9642113142056705

Epoch: 30| Step: 0
Training loss: 3.448734029060264
Validation loss: 3.958822735430512

Epoch: 5| Step: 1
Training loss: 4.448517353076753
Validation loss: 3.9532128627094747

Epoch: 5| Step: 2
Training loss: 4.295074640586924
Validation loss: 3.948447932360521

Epoch: 5| Step: 3
Training loss: 4.07705943484442
Validation loss: 3.942860980419499

Epoch: 5| Step: 4
Training loss: 4.188056339486129
Validation loss: 3.938165835441424

Epoch: 5| Step: 5
Training loss: 4.160139056962712
Validation loss: 3.9340856472486587

Epoch: 5| Step: 6
Training loss: 4.606947230413376
Validation loss: 3.9286632429061936

Epoch: 5| Step: 7
Training loss: 3.6594391306560303
Validation loss: 3.9235899368585

Epoch: 5| Step: 8
Training loss: 4.230488813217083
Validation loss: 3.9187596930911757

Epoch: 5| Step: 9
Training loss: 3.7270476787148916
Validation loss: 3.912988958385918

Epoch: 5| Step: 10
Training loss: 3.7298635900676977
Validation loss: 3.9082730611262586

Epoch: 5| Step: 11
Training loss: 4.149528173258852
Validation loss: 3.9040491847082426

Epoch: 31| Step: 0
Training loss: 4.185778363582239
Validation loss: 3.8989544247359587

Epoch: 5| Step: 1
Training loss: 3.4628400890365656
Validation loss: 3.8944549451040373

Epoch: 5| Step: 2
Training loss: 4.090624365868457
Validation loss: 3.889729122187316

Epoch: 5| Step: 3
Training loss: 3.8236337902096875
Validation loss: 3.885726060727588

Epoch: 5| Step: 4
Training loss: 4.111211214192854
Validation loss: 3.880682997718394

Epoch: 5| Step: 5
Training loss: 4.159489337315485
Validation loss: 3.8762753192804995

Epoch: 5| Step: 6
Training loss: 4.674319441111062
Validation loss: 3.8719358275743545

Epoch: 5| Step: 7
Training loss: 4.022061307040555
Validation loss: 3.8667169355270867

Epoch: 5| Step: 8
Training loss: 3.8422876072734113
Validation loss: 3.8619860878194507

Epoch: 5| Step: 9
Training loss: 4.236852167621995
Validation loss: 3.8573131896855672

Epoch: 5| Step: 10
Training loss: 3.0974961536497507
Validation loss: 3.8527530844402156

Epoch: 5| Step: 11
Training loss: 4.870666534117508
Validation loss: 3.848001501404277

Epoch: 32| Step: 0
Training loss: 3.345258568547713
Validation loss: 3.84339825124303

Epoch: 5| Step: 1
Training loss: 4.254303044080093
Validation loss: 3.8387334388368215

Epoch: 5| Step: 2
Training loss: 3.6734347013643767
Validation loss: 3.8341743265423824

Epoch: 5| Step: 3
Training loss: 4.02192828566221
Validation loss: 3.8291339401047604

Epoch: 5| Step: 4
Training loss: 4.065519883059935
Validation loss: 3.8249821743518617

Epoch: 5| Step: 5
Training loss: 4.414067037124328
Validation loss: 3.819680112831446

Epoch: 5| Step: 6
Training loss: 3.7424104819233768
Validation loss: 3.815099783451136

Epoch: 5| Step: 7
Training loss: 4.036918499055632
Validation loss: 3.810509172334849

Epoch: 5| Step: 8
Training loss: 4.083738008545176
Validation loss: 3.8057083233028086

Epoch: 5| Step: 9
Training loss: 4.534895489381136
Validation loss: 3.800843439903503

Epoch: 5| Step: 10
Training loss: 3.2290091855605754
Validation loss: 3.796172910436604

Epoch: 5| Step: 11
Training loss: 3.3515885358746162
Validation loss: 3.7916579124154

Epoch: 33| Step: 0
Training loss: 3.415634805817066
Validation loss: 3.7867635562807114

Epoch: 5| Step: 1
Training loss: 3.9380741003609976
Validation loss: 3.782700032039867

Epoch: 5| Step: 2
Training loss: 3.692502136643088
Validation loss: 3.778058215598316

Epoch: 5| Step: 3
Training loss: 3.8928738264973757
Validation loss: 3.773457102596316

Epoch: 5| Step: 4
Training loss: 4.153735325087397
Validation loss: 3.768690615724386

Epoch: 5| Step: 5
Training loss: 3.766629793329841
Validation loss: 3.7641469025165146

Epoch: 5| Step: 6
Training loss: 4.508826183143977
Validation loss: 3.7596278468397086

Epoch: 5| Step: 7
Training loss: 3.6371232247296317
Validation loss: 3.7557598119993214

Epoch: 5| Step: 8
Training loss: 3.4238279857298175
Validation loss: 3.750480425047985

Epoch: 5| Step: 9
Training loss: 4.792905276996688
Validation loss: 3.745549400751029

Epoch: 5| Step: 10
Training loss: 3.6762785782881937
Validation loss: 3.741703280855284

Epoch: 5| Step: 11
Training loss: 2.4297228255571053
Validation loss: 3.737082405746628

Epoch: 34| Step: 0
Training loss: 4.049141856513541
Validation loss: 3.7329170221997843

Epoch: 5| Step: 1
Training loss: 3.3091870421146803
Validation loss: 3.7281915661394756

Epoch: 5| Step: 2
Training loss: 3.5557827446462507
Validation loss: 3.724175318374082

Epoch: 5| Step: 3
Training loss: 4.2806863901083645
Validation loss: 3.7196312776397567

Epoch: 5| Step: 4
Training loss: 4.443638384097321
Validation loss: 3.715333303985331

Epoch: 5| Step: 5
Training loss: 3.569234539214655
Validation loss: 3.710789369002448

Epoch: 5| Step: 6
Training loss: 3.685178640272107
Validation loss: 3.7066617191290825

Epoch: 5| Step: 7
Training loss: 4.223427221332988
Validation loss: 3.7025825972426727

Epoch: 5| Step: 8
Training loss: 3.423169870853867
Validation loss: 3.6978000067276824

Epoch: 5| Step: 9
Training loss: 3.8284512127830057
Validation loss: 3.693453487150017

Epoch: 5| Step: 10
Training loss: 3.5043090452706402
Validation loss: 3.6892386071689116

Epoch: 5| Step: 11
Training loss: 4.969461833899029
Validation loss: 3.685224170232777

Epoch: 35| Step: 0
Training loss: 4.476872884432197
Validation loss: 3.6808202880243597

Epoch: 5| Step: 1
Training loss: 3.731608111961561
Validation loss: 3.675854559561575

Epoch: 5| Step: 2
Training loss: 3.6302553426507393
Validation loss: 3.67159518535214

Epoch: 5| Step: 3
Training loss: 3.9961328886768572
Validation loss: 3.666970807524086

Epoch: 5| Step: 4
Training loss: 3.7227234969414766
Validation loss: 3.6626253108784375

Epoch: 5| Step: 5
Training loss: 4.051722624086474
Validation loss: 3.6580308994825637

Epoch: 5| Step: 6
Training loss: 3.5290263778984876
Validation loss: 3.6535502136000564

Epoch: 5| Step: 7
Training loss: 3.7049987173142576
Validation loss: 3.6488463304111294

Epoch: 5| Step: 8
Training loss: 4.003850990472329
Validation loss: 3.644677475765538

Epoch: 5| Step: 9
Training loss: 3.01708601114672
Validation loss: 3.6400168624511804

Epoch: 5| Step: 10
Training loss: 3.904205886063009
Validation loss: 3.635901791285612

Epoch: 5| Step: 11
Training loss: 2.713175880150127
Validation loss: 3.6313854901352434

Epoch: 36| Step: 0
Training loss: 3.3661097950427457
Validation loss: 3.627511294623611

Epoch: 5| Step: 1
Training loss: 4.100755826551859
Validation loss: 3.6232406249084166

Epoch: 5| Step: 2
Training loss: 3.764869835821189
Validation loss: 3.6189594144517416

Epoch: 5| Step: 3
Training loss: 3.560369959049241
Validation loss: 3.6147265758586062

Epoch: 5| Step: 4
Training loss: 4.31158658734189
Validation loss: 3.610316160725119

Epoch: 5| Step: 5
Training loss: 3.3534497902772666
Validation loss: 3.605990282928597

Epoch: 5| Step: 6
Training loss: 4.047874533446583
Validation loss: 3.6019186752630636

Epoch: 5| Step: 7
Training loss: 4.0039295921575695
Validation loss: 3.5981356080189144

Epoch: 5| Step: 8
Training loss: 3.549609503961701
Validation loss: 3.5931318110739134

Epoch: 5| Step: 9
Training loss: 3.7307390844048265
Validation loss: 3.588950371502661

Epoch: 5| Step: 10
Training loss: 3.4856751073471393
Validation loss: 3.5848088701126937

Epoch: 5| Step: 11
Training loss: 2.3237737149428463
Validation loss: 3.5804311602880037

Epoch: 37| Step: 0
Training loss: 4.2643562637850065
Validation loss: 3.576307187592594

Epoch: 5| Step: 1
Training loss: 3.7409882664663447
Validation loss: 3.5723603244560453

Epoch: 5| Step: 2
Training loss: 3.985323086304784
Validation loss: 3.568089322354844

Epoch: 5| Step: 3
Training loss: 3.2387343067891727
Validation loss: 3.563831482072502

Epoch: 5| Step: 4
Training loss: 2.8639121824152407
Validation loss: 3.560295549493703

Epoch: 5| Step: 5
Training loss: 3.4293702137369495
Validation loss: 3.5560450159047754

Epoch: 5| Step: 6
Training loss: 3.994896852118941
Validation loss: 3.5520558994758944

Epoch: 5| Step: 7
Training loss: 3.265891324367381
Validation loss: 3.5475796967152986

Epoch: 5| Step: 8
Training loss: 3.773961506665958
Validation loss: 3.543567880192674

Epoch: 5| Step: 9
Training loss: 3.887726834171067
Validation loss: 3.5393415373326698

Epoch: 5| Step: 10
Training loss: 3.8068609589822096
Validation loss: 3.53556783679276

Epoch: 5| Step: 11
Training loss: 4.392848853303928
Validation loss: 3.531420847042849

Epoch: 38| Step: 0
Training loss: 3.440400443168002
Validation loss: 3.5270280608735645

Epoch: 5| Step: 1
Training loss: 3.684782416908892
Validation loss: 3.522881891916288

Epoch: 5| Step: 2
Training loss: 3.712757186458353
Validation loss: 3.5184215019655865

Epoch: 5| Step: 3
Training loss: 3.993815051102711
Validation loss: 3.514448853599285

Epoch: 5| Step: 4
Training loss: 4.186386188012944
Validation loss: 3.509957912741579

Epoch: 5| Step: 5
Training loss: 3.5383971138259533
Validation loss: 3.505060375127159

Epoch: 5| Step: 6
Training loss: 3.698064380256577
Validation loss: 3.5007206765215115

Epoch: 5| Step: 7
Training loss: 3.3285725610521775
Validation loss: 3.495103698005236

Epoch: 5| Step: 8
Training loss: 3.5042908116204092
Validation loss: 3.4901987965938384

Epoch: 5| Step: 9
Training loss: 3.7768078397227094
Validation loss: 3.4854455623276377

Epoch: 5| Step: 10
Training loss: 3.014929972985176
Validation loss: 3.4797732353639668

Epoch: 5| Step: 11
Training loss: 3.963361190449888
Validation loss: 3.476768264681936

Epoch: 39| Step: 0
Training loss: 3.19314583813955
Validation loss: 3.4715039544533313

Epoch: 5| Step: 1
Training loss: 3.8017241983326446
Validation loss: 3.466880334556945

Epoch: 5| Step: 2
Training loss: 3.5678977897441966
Validation loss: 3.46243848034481

Epoch: 5| Step: 3
Training loss: 2.924850336142102
Validation loss: 3.458061837642716

Epoch: 5| Step: 4
Training loss: 3.6431852187622864
Validation loss: 3.4543180461670313

Epoch: 5| Step: 5
Training loss: 3.9877907865202338
Validation loss: 3.4504524809587056

Epoch: 5| Step: 6
Training loss: 3.4535152163039857
Validation loss: 3.446263263562949

Epoch: 5| Step: 7
Training loss: 3.7282253050440635
Validation loss: 3.4425723365935004

Epoch: 5| Step: 8
Training loss: 3.065811857698016
Validation loss: 3.438072931343484

Epoch: 5| Step: 9
Training loss: 4.135400780071553
Validation loss: 3.433765394067297

Epoch: 5| Step: 10
Training loss: 3.7574480478803074
Validation loss: 3.429868164749515

Epoch: 5| Step: 11
Training loss: 3.598333206023626
Validation loss: 3.425308479098139

Epoch: 40| Step: 0
Training loss: 3.318455506672956
Validation loss: 3.4213717713321445

Epoch: 5| Step: 1
Training loss: 3.5106874506772563
Validation loss: 3.4166444665296125

Epoch: 5| Step: 2
Training loss: 4.033068815862968
Validation loss: 3.412871769273798

Epoch: 5| Step: 3
Training loss: 3.4815161228335283
Validation loss: 3.408356263255344

Epoch: 5| Step: 4
Training loss: 3.5284946460875157
Validation loss: 3.4040509629556746

Epoch: 5| Step: 5
Training loss: 3.555113245022797
Validation loss: 3.4000109073987543

Epoch: 5| Step: 6
Training loss: 3.177059352763408
Validation loss: 3.395766039144499

Epoch: 5| Step: 7
Training loss: 4.097973457619093
Validation loss: 3.3916480869156094

Epoch: 5| Step: 8
Training loss: 3.1732681296833034
Validation loss: 3.3875032108193133

Epoch: 5| Step: 9
Training loss: 3.3145121095407077
Validation loss: 3.383159640196105

Epoch: 5| Step: 10
Training loss: 3.4323878335094977
Validation loss: 3.3791865884841967

Epoch: 5| Step: 11
Training loss: 4.308521149093677
Validation loss: 3.3748788576401587

Epoch: 41| Step: 0
Training loss: 3.308333457607264
Validation loss: 3.3706593239096017

Epoch: 5| Step: 1
Training loss: 3.2900521064968493
Validation loss: 3.3665803153858125

Epoch: 5| Step: 2
Training loss: 3.632108230415048
Validation loss: 3.3622249963515993

Epoch: 5| Step: 3
Training loss: 3.349452494959618
Validation loss: 3.358530254759121

Epoch: 5| Step: 4
Training loss: 4.117536786950971
Validation loss: 3.354650783352695

Epoch: 5| Step: 5
Training loss: 3.3083634369551125
Validation loss: 3.3502103364682787

Epoch: 5| Step: 6
Training loss: 3.3722342001967425
Validation loss: 3.346260696867132

Epoch: 5| Step: 7
Training loss: 3.9078112114527066
Validation loss: 3.342084728442484

Epoch: 5| Step: 8
Training loss: 3.793791975263629
Validation loss: 3.338015454857828

Epoch: 5| Step: 9
Training loss: 3.7153743521397793
Validation loss: 3.3337444866446164

Epoch: 5| Step: 10
Training loss: 2.3930398550002523
Validation loss: 3.3299784446854916

Epoch: 5| Step: 11
Training loss: 2.9837450890566584
Validation loss: 3.325815058840945

Epoch: 42| Step: 0
Training loss: 3.820574355561225
Validation loss: 3.321868170022148

Epoch: 5| Step: 1
Training loss: 3.176529349300934
Validation loss: 3.3175353759205666

Epoch: 5| Step: 2
Training loss: 3.680159811820616
Validation loss: 3.3139445855678544

Epoch: 5| Step: 3
Training loss: 3.4716364218031863
Validation loss: 3.3098808346260205

Epoch: 5| Step: 4
Training loss: 3.6507220089769383
Validation loss: 3.3059874098015527

Epoch: 5| Step: 5
Training loss: 3.76024157397382
Validation loss: 3.301836947245237

Epoch: 5| Step: 6
Training loss: 3.0008133739290366
Validation loss: 3.2983286516934776

Epoch: 5| Step: 7
Training loss: 3.202912263086027
Validation loss: 3.294346700204345

Epoch: 5| Step: 8
Training loss: 3.9468623676837877
Validation loss: 3.2902255082361007

Epoch: 5| Step: 9
Training loss: 2.6922246521939543
Validation loss: 3.2864532148237715

Epoch: 5| Step: 10
Training loss: 3.3152468826167674
Validation loss: 3.282853131509577

Epoch: 5| Step: 11
Training loss: 3.145242361849164
Validation loss: 3.2789449557847417

Epoch: 43| Step: 0
Training loss: 3.2186839272837715
Validation loss: 3.2756471239660367

Epoch: 5| Step: 1
Training loss: 3.2844873352875124
Validation loss: 3.272258652495254

Epoch: 5| Step: 2
Training loss: 3.5823983739585987
Validation loss: 3.268263856417486

Epoch: 5| Step: 3
Training loss: 3.821650920047474
Validation loss: 3.264875292467803

Epoch: 5| Step: 4
Training loss: 3.2106532507053216
Validation loss: 3.261092823754598

Epoch: 5| Step: 5
Training loss: 2.8605140960244695
Validation loss: 3.257444603361852

Epoch: 5| Step: 6
Training loss: 3.3624915991469027
Validation loss: 3.253831762565686

Epoch: 5| Step: 7
Training loss: 3.654108838820325
Validation loss: 3.250485946320546

Epoch: 5| Step: 8
Training loss: 3.3686845819069986
Validation loss: 3.246622433475326

Epoch: 5| Step: 9
Training loss: 3.5479346217568932
Validation loss: 3.2429371407614194

Epoch: 5| Step: 10
Training loss: 3.3554400441692662
Validation loss: 3.2393099044921594

Epoch: 5| Step: 11
Training loss: 3.4600321875161018
Validation loss: 3.2357826364085565

Epoch: 44| Step: 0
Training loss: 3.634973158284693
Validation loss: 3.2320915122496476

Epoch: 5| Step: 1
Training loss: 3.7827770838129378
Validation loss: 3.228333363635592

Epoch: 5| Step: 2
Training loss: 3.342644054016309
Validation loss: 3.224705190022569

Epoch: 5| Step: 3
Training loss: 3.0808609165493954
Validation loss: 3.220680919946203

Epoch: 5| Step: 4
Training loss: 2.680679004398248
Validation loss: 3.216998281004698

Epoch: 5| Step: 5
Training loss: 3.570287792028496
Validation loss: 3.213544386002654

Epoch: 5| Step: 6
Training loss: 3.774478366003017
Validation loss: 3.2101416920399677

Epoch: 5| Step: 7
Training loss: 3.1713990103327045
Validation loss: 3.2064851922471003

Epoch: 5| Step: 8
Training loss: 3.1993478229647945
Validation loss: 3.2029769801232546

Epoch: 5| Step: 9
Training loss: 2.8133375828004294
Validation loss: 3.1995950306008227

Epoch: 5| Step: 10
Training loss: 3.843305980808916
Validation loss: 3.196254196621742

Epoch: 5| Step: 11
Training loss: 2.020726571425447
Validation loss: 3.1929009998097624

Epoch: 45| Step: 0
Training loss: 3.5944391004577354
Validation loss: 3.189548469982476

Epoch: 5| Step: 1
Training loss: 3.4596264424732275
Validation loss: 3.186242581724638

Epoch: 5| Step: 2
Training loss: 3.109608397038857
Validation loss: 3.1829975654284337

Epoch: 5| Step: 3
Training loss: 3.4792386502492443
Validation loss: 3.1795650211773867

Epoch: 5| Step: 4
Training loss: 3.539489046711685
Validation loss: 3.176550777805839

Epoch: 5| Step: 5
Training loss: 3.283306530941491
Validation loss: 3.1731758989037875

Epoch: 5| Step: 6
Training loss: 3.178905943999202
Validation loss: 3.1698102510283346

Epoch: 5| Step: 7
Training loss: 2.958985180744527
Validation loss: 3.166032537328476

Epoch: 5| Step: 8
Training loss: 3.652571172314544
Validation loss: 3.162875828129867

Epoch: 5| Step: 9
Training loss: 3.0624674581239018
Validation loss: 3.1595872980638156

Epoch: 5| Step: 10
Training loss: 3.1402074431882494
Validation loss: 3.156107178531736

Epoch: 5| Step: 11
Training loss: 2.880134641361088
Validation loss: 3.152648028720814

Epoch: 46| Step: 0
Training loss: 2.4108681886985877
Validation loss: 3.1496282239543354

Epoch: 5| Step: 1
Training loss: 3.490574952998781
Validation loss: 3.1463446527893035

Epoch: 5| Step: 2
Training loss: 3.219771436078334
Validation loss: 3.14362384980377

Epoch: 5| Step: 3
Training loss: 2.9393905075348754
Validation loss: 3.1407026562808564

Epoch: 5| Step: 4
Training loss: 3.456083937340903
Validation loss: 3.137785113122409

Epoch: 5| Step: 5
Training loss: 3.713541823606055
Validation loss: 3.135086477304771

Epoch: 5| Step: 6
Training loss: 2.995529022111863
Validation loss: 3.1314895576316344

Epoch: 5| Step: 7
Training loss: 3.5240523992273443
Validation loss: 3.1285461745634313

Epoch: 5| Step: 8
Training loss: 3.2576443196528837
Validation loss: 3.1254218484343723

Epoch: 5| Step: 9
Training loss: 2.9668857543570395
Validation loss: 3.1221718197412502

Epoch: 5| Step: 10
Training loss: 3.8669983480413954
Validation loss: 3.1191571481450597

Epoch: 5| Step: 11
Training loss: 2.8117093140405887
Validation loss: 3.1155178216159083

Epoch: 47| Step: 0
Training loss: 2.6940232883967563
Validation loss: 3.112239297930594

Epoch: 5| Step: 1
Training loss: 2.9604501448976985
Validation loss: 3.1093717060678694

Epoch: 5| Step: 2
Training loss: 3.1825199492758975
Validation loss: 3.1066206229328754

Epoch: 5| Step: 3
Training loss: 3.2794848826112735
Validation loss: 3.1031297940424944

Epoch: 5| Step: 4
Training loss: 2.6902283414903483
Validation loss: 3.1001746069536074

Epoch: 5| Step: 5
Training loss: 3.3114681436145985
Validation loss: 3.097461715176337

Epoch: 5| Step: 6
Training loss: 3.6800237611335236
Validation loss: 3.09378702931448

Epoch: 5| Step: 7
Training loss: 3.067667124827125
Validation loss: 3.0907280127236354

Epoch: 5| Step: 8
Training loss: 3.70778199001255
Validation loss: 3.087366923914794

Epoch: 5| Step: 9
Training loss: 3.2183973989591395
Validation loss: 3.0843841248557333

Epoch: 5| Step: 10
Training loss: 3.717760355079425
Validation loss: 3.081137278921412

Epoch: 5| Step: 11
Training loss: 2.680176537378628
Validation loss: 3.0782037069775927

Epoch: 48| Step: 0
Training loss: 3.301307338345207
Validation loss: 3.0748853659519773

Epoch: 5| Step: 1
Training loss: 2.7406784209000348
Validation loss: 3.072355320407889

Epoch: 5| Step: 2
Training loss: 2.8305186895586676
Validation loss: 3.0694241714862893

Epoch: 5| Step: 3
Training loss: 3.2165656223798966
Validation loss: 3.06698867871177

Epoch: 5| Step: 4
Training loss: 3.0746195239875056
Validation loss: 3.0642587548638907

Epoch: 5| Step: 5
Training loss: 3.292920384894673
Validation loss: 3.0616397460390092

Epoch: 5| Step: 6
Training loss: 3.1641200684384776
Validation loss: 3.0593062115457155

Epoch: 5| Step: 7
Training loss: 3.4525641766991204
Validation loss: 3.05615393325757

Epoch: 5| Step: 8
Training loss: 2.6628929099002776
Validation loss: 3.0531146137499494

Epoch: 5| Step: 9
Training loss: 3.430604156136151
Validation loss: 3.050799270036126

Epoch: 5| Step: 10
Training loss: 3.8660285214843753
Validation loss: 3.0474431608562105

Epoch: 5| Step: 11
Training loss: 3.186732031365971
Validation loss: 3.0448217858777946

Epoch: 49| Step: 0
Training loss: 3.349146116379861
Validation loss: 3.041815079155736

Epoch: 5| Step: 1
Training loss: 3.2534557456557525
Validation loss: 3.0386974340997632

Epoch: 5| Step: 2
Training loss: 3.087896184174313
Validation loss: 3.035684154264792

Epoch: 5| Step: 3
Training loss: 3.392945791821649
Validation loss: 3.032949980329086

Epoch: 5| Step: 4
Training loss: 2.9166358037859768
Validation loss: 3.02943907386971

Epoch: 5| Step: 5
Training loss: 3.052972726919367
Validation loss: 3.026646943654765

Epoch: 5| Step: 6
Training loss: 2.578098181382765
Validation loss: 3.023918251633105

Epoch: 5| Step: 7
Training loss: 3.2862417852009584
Validation loss: 3.021124731456917

Epoch: 5| Step: 8
Training loss: 3.032426114357625
Validation loss: 3.018385238276647

Epoch: 5| Step: 9
Training loss: 3.3292625524838955
Validation loss: 3.0153891120323926

Epoch: 5| Step: 10
Training loss: 3.4344724327199487
Validation loss: 3.012577252828632

Epoch: 5| Step: 11
Training loss: 3.424703465454191
Validation loss: 3.009958507340569

Epoch: 50| Step: 0
Training loss: 3.532563631924927
Validation loss: 3.0070524039696793

Epoch: 5| Step: 1
Training loss: 2.878456028758659
Validation loss: 3.0044376281957064

Epoch: 5| Step: 2
Training loss: 2.836964655045863
Validation loss: 3.0017157721187404

Epoch: 5| Step: 3
Training loss: 2.666476054134319
Validation loss: 2.999027432308934

Epoch: 5| Step: 4
Training loss: 2.9832557057203277
Validation loss: 2.996590378776445

Epoch: 5| Step: 5
Training loss: 3.133849317257281
Validation loss: 2.993955990945667

Epoch: 5| Step: 6
Training loss: 3.176726891372723
Validation loss: 2.9911389152813954

Epoch: 5| Step: 7
Training loss: 3.409714642887708
Validation loss: 2.9891971555809884

Epoch: 5| Step: 8
Training loss: 3.4411371582685573
Validation loss: 2.9855278344940337

Epoch: 5| Step: 9
Training loss: 3.214655966853917
Validation loss: 2.982986356805056

Epoch: 5| Step: 10
Training loss: 3.1104752783971024
Validation loss: 2.9816578084299854

Epoch: 5| Step: 11
Training loss: 3.06422811524546
Validation loss: 2.9794691683616548

Epoch: 51| Step: 0
Training loss: 3.28865494547586
Validation loss: 2.9750658512841497

Epoch: 5| Step: 1
Training loss: 3.086747538809607
Validation loss: 2.9724332614696998

Epoch: 5| Step: 2
Training loss: 2.537046036726228
Validation loss: 2.970046807529302

Epoch: 5| Step: 3
Training loss: 3.360699201902989
Validation loss: 2.9671712257885767

Epoch: 5| Step: 4
Training loss: 3.242333098669767
Validation loss: 2.965107289137347

Epoch: 5| Step: 5
Training loss: 3.1783742981304317
Validation loss: 2.9622972464625725

Epoch: 5| Step: 6
Training loss: 3.3129878134786885
Validation loss: 2.9598119235268006

Epoch: 5| Step: 7
Training loss: 2.94175412171413
Validation loss: 2.9573734510417076

Epoch: 5| Step: 8
Training loss: 3.061820285648537
Validation loss: 2.9547486425159377

Epoch: 5| Step: 9
Training loss: 2.729929596548566
Validation loss: 2.952120743063342

Epoch: 5| Step: 10
Training loss: 3.102301291004937
Validation loss: 2.9500317663432862

Epoch: 5| Step: 11
Training loss: 3.9611033869509464
Validation loss: 2.947351379023337

Epoch: 52| Step: 0
Training loss: 2.9213589299222584
Validation loss: 2.9446295529085673

Epoch: 5| Step: 1
Training loss: 2.7473468987082867
Validation loss: 2.9419222442883406

Epoch: 5| Step: 2
Training loss: 3.586306218490781
Validation loss: 2.939619415750255

Epoch: 5| Step: 3
Training loss: 3.3072211470807695
Validation loss: 2.938383209750404

Epoch: 5| Step: 4
Training loss: 4.145673560253928
Validation loss: 2.952741557664004

Epoch: 5| Step: 5
Training loss: 3.18296476364167
Validation loss: 2.9317506332817485

Epoch: 5| Step: 6
Training loss: 2.872258745359298
Validation loss: 2.928906851288754

Epoch: 5| Step: 7
Training loss: 2.6744034610026404
Validation loss: 2.9273797436074176

Epoch: 5| Step: 8
Training loss: 2.7810067059690846
Validation loss: 2.925939615918332

Epoch: 5| Step: 9
Training loss: 2.542885680826882
Validation loss: 2.927538959614219

Epoch: 5| Step: 10
Training loss: 2.9126067833705482
Validation loss: 2.925053141320409

Epoch: 5| Step: 11
Training loss: 2.1785598080077238
Validation loss: 2.920441063149359

Epoch: 53| Step: 0
Training loss: 3.360258757981781
Validation loss: 2.9169604709783843

Epoch: 5| Step: 1
Training loss: 2.867152907659171
Validation loss: 2.914091070885661

Epoch: 5| Step: 2
Training loss: 3.1335637055247547
Validation loss: 2.9122947499122693

Epoch: 5| Step: 3
Training loss: 2.9869103971157136
Validation loss: 2.9091344178702596

Epoch: 5| Step: 4
Training loss: 3.432652332456997
Validation loss: 2.9067967902011524

Epoch: 5| Step: 5
Training loss: 2.665741332759038
Validation loss: 2.9046654979302757

Epoch: 5| Step: 6
Training loss: 3.015380058816614
Validation loss: 2.9023521323957944

Epoch: 5| Step: 7
Training loss: 3.1034134499287602
Validation loss: 2.8990265007013996

Epoch: 5| Step: 8
Training loss: 3.0170438126773607
Validation loss: 2.8964656418520174

Epoch: 5| Step: 9
Training loss: 2.983289591150676
Validation loss: 2.8946906563695896

Epoch: 5| Step: 10
Training loss: 3.033857187861738
Validation loss: 2.892357013501555

Epoch: 5| Step: 11
Training loss: 2.224546677775124
Validation loss: 2.8901460027333448

Epoch: 54| Step: 0
Training loss: 2.651977963288408
Validation loss: 2.8878753540620496

Epoch: 5| Step: 1
Training loss: 3.419514577893373
Validation loss: 2.886171205562183

Epoch: 5| Step: 2
Training loss: 3.4052041224215097
Validation loss: 2.88348941385125

Epoch: 5| Step: 3
Training loss: 3.304015179144326
Validation loss: 2.8816123745556372

Epoch: 5| Step: 4
Training loss: 3.0993144538628763
Validation loss: 2.8794140482195747

Epoch: 5| Step: 5
Training loss: 2.6644496244914513
Validation loss: 2.8772421331498896

Epoch: 5| Step: 6
Training loss: 3.155051126443696
Validation loss: 2.8752165450215723

Epoch: 5| Step: 7
Training loss: 2.9303872862160723
Validation loss: 2.8732389052663185

Epoch: 5| Step: 8
Training loss: 3.3603515625
Validation loss: 2.8710803699830394

Epoch: 5| Step: 9
Training loss: 2.5064752643977153
Validation loss: 2.8688767919729417

Epoch: 5| Step: 10
Training loss: 2.7965941900865556
Validation loss: 2.866876791490608

Epoch: 5| Step: 11
Training loss: 1.28505142851159
Validation loss: 2.8648860366872566

Epoch: 55| Step: 0
Training loss: 3.2660675479049766
Validation loss: 2.8631199595710863

Epoch: 5| Step: 1
Training loss: 3.1409817772901127
Validation loss: 2.8610928070898454

Epoch: 5| Step: 2
Training loss: 2.391154311678931
Validation loss: 2.859045416176036

Epoch: 5| Step: 3
Training loss: 3.11510839895167
Validation loss: 2.85699347037376

Epoch: 5| Step: 4
Training loss: 3.1306462967982727
Validation loss: 2.855183383165077

Epoch: 5| Step: 5
Training loss: 3.0518635919167476
Validation loss: 2.8533652298825314

Epoch: 5| Step: 6
Training loss: 3.0704351890841486
Validation loss: 2.851222483948005

Epoch: 5| Step: 7
Training loss: 3.04614843851186
Validation loss: 2.8496951150665177

Epoch: 5| Step: 8
Training loss: 2.143528882959714
Validation loss: 2.847320303093392

Epoch: 5| Step: 9
Training loss: 3.057803074934775
Validation loss: 2.845547520195526

Epoch: 5| Step: 10
Training loss: 3.0118742233500178
Validation loss: 2.8432297842110454

Epoch: 5| Step: 11
Training loss: 4.287922136083768
Validation loss: 2.8418565427058984

Epoch: 56| Step: 0
Training loss: 2.8259537091307605
Validation loss: 2.8394924403024655

Epoch: 5| Step: 1
Training loss: 2.8469029648178856
Validation loss: 2.8369998816040933

Epoch: 5| Step: 2
Training loss: 2.967034094984549
Validation loss: 2.8352692397332384

Epoch: 5| Step: 3
Training loss: 2.978660024675951
Validation loss: 2.833033859096375

Epoch: 5| Step: 4
Training loss: 2.893732493535058
Validation loss: 2.8307014763444878

Epoch: 5| Step: 5
Training loss: 3.1233972635582905
Validation loss: 2.8283644692496672

Epoch: 5| Step: 6
Training loss: 2.9932373436176176
Validation loss: 2.827210034197376

Epoch: 5| Step: 7
Training loss: 3.075516733311637
Validation loss: 2.825093831554845

Epoch: 5| Step: 8
Training loss: 2.803908896159329
Validation loss: 2.8227443970952995

Epoch: 5| Step: 9
Training loss: 2.7523419205039334
Validation loss: 2.821706731911389

Epoch: 5| Step: 10
Training loss: 3.455475020483797
Validation loss: 2.8188482588835586

Epoch: 5| Step: 11
Training loss: 2.3799448236112193
Validation loss: 2.816516911082574

Epoch: 57| Step: 0
Training loss: 3.3851000515507352
Validation loss: 2.8154167733374256

Epoch: 5| Step: 1
Training loss: 2.661267108853282
Validation loss: 2.8128619173097698

Epoch: 5| Step: 2
Training loss: 2.7282281285879764
Validation loss: 2.8116195536847486

Epoch: 5| Step: 3
Training loss: 2.761618432970734
Validation loss: 2.8097579163275395

Epoch: 5| Step: 4
Training loss: 2.821255090495103
Validation loss: 2.8074284639922995

Epoch: 5| Step: 5
Training loss: 3.064116537890796
Validation loss: 2.8048559189634243

Epoch: 5| Step: 6
Training loss: 2.896867434791143
Validation loss: 2.8038368989593407

Epoch: 5| Step: 7
Training loss: 2.8940369960104766
Validation loss: 2.8010087393039065

Epoch: 5| Step: 8
Training loss: 3.1161318260582376
Validation loss: 2.799926634519903

Epoch: 5| Step: 9
Training loss: 2.9807077614478197
Validation loss: 2.7980229634259977

Epoch: 5| Step: 10
Training loss: 2.8038323674069825
Validation loss: 2.795445941990284

Epoch: 5| Step: 11
Training loss: 3.919100444887722
Validation loss: 2.794320728511868

Epoch: 58| Step: 0
Training loss: 2.814106800126735
Validation loss: 2.793333165863718

Epoch: 5| Step: 1
Training loss: 2.8605095952204294
Validation loss: 2.790562038701002

Epoch: 5| Step: 2
Training loss: 2.5941865852327326
Validation loss: 2.788276454742917

Epoch: 5| Step: 3
Training loss: 2.8510509293368234
Validation loss: 2.785804127460111

Epoch: 5| Step: 4
Training loss: 2.83375755574919
Validation loss: 2.784318659790745

Epoch: 5| Step: 5
Training loss: 2.6436872614637648
Validation loss: 2.7831141050502284

Epoch: 5| Step: 6
Training loss: 3.0303936564736604
Validation loss: 2.78228363374907

Epoch: 5| Step: 7
Training loss: 3.0275124385965673
Validation loss: 2.780157985686357

Epoch: 5| Step: 8
Training loss: 3.3736839554248865
Validation loss: 2.777617189348328

Epoch: 5| Step: 9
Training loss: 3.458084618384182
Validation loss: 2.775543792098979

Epoch: 5| Step: 10
Training loss: 2.5187478910300083
Validation loss: 2.7739019408004792

Epoch: 5| Step: 11
Training loss: 2.943233980926337
Validation loss: 2.771264208847692

Epoch: 59| Step: 0
Training loss: 3.071034276246181
Validation loss: 2.769476920071586

Epoch: 5| Step: 1
Training loss: 2.4155520685988248
Validation loss: 2.768030115808075

Epoch: 5| Step: 2
Training loss: 2.64245352553513
Validation loss: 2.765789899920816

Epoch: 5| Step: 3
Training loss: 3.2077143844115
Validation loss: 2.765266948446488

Epoch: 5| Step: 4
Training loss: 3.3684437968245398
Validation loss: 2.7631765184515795

Epoch: 5| Step: 5
Training loss: 3.217969781329496
Validation loss: 2.7617215952842837

Epoch: 5| Step: 6
Training loss: 2.403001152587563
Validation loss: 2.759353351328089

Epoch: 5| Step: 7
Training loss: 2.53281335471796
Validation loss: 2.7590538091418613

Epoch: 5| Step: 8
Training loss: 2.7399950962997326
Validation loss: 2.7564285090762826

Epoch: 5| Step: 9
Training loss: 3.3955712870648953
Validation loss: 2.7547196938661447

Epoch: 5| Step: 10
Training loss: 2.496237116414129
Validation loss: 2.752221535921642

Epoch: 5| Step: 11
Training loss: 3.6715950067782295
Validation loss: 2.7506814711954815

Epoch: 60| Step: 0
Training loss: 2.955148639329295
Validation loss: 2.7488658292952

Epoch: 5| Step: 1
Training loss: 2.7897447451519697
Validation loss: 2.74709470403343

Epoch: 5| Step: 2
Training loss: 2.6271677603126937
Validation loss: 2.7445485202192725

Epoch: 5| Step: 3
Training loss: 3.133112486367811
Validation loss: 2.743416064483866

Epoch: 5| Step: 4
Training loss: 3.0922673843959743
Validation loss: 2.7412145107469326

Epoch: 5| Step: 5
Training loss: 2.997524988930891
Validation loss: 2.739547752226669

Epoch: 5| Step: 6
Training loss: 2.8902878023342704
Validation loss: 2.7381920357835274

Epoch: 5| Step: 7
Training loss: 2.6493215520155573
Validation loss: 2.7356987319421373

Epoch: 5| Step: 8
Training loss: 3.0766204410054705
Validation loss: 2.7340859759941174

Epoch: 5| Step: 9
Training loss: 2.5848565276892628
Validation loss: 2.7330166812591896

Epoch: 5| Step: 10
Training loss: 2.68853482572288
Validation loss: 2.7316850928181062

Epoch: 5| Step: 11
Training loss: 3.5879909644635086
Validation loss: 2.729773811820145

Epoch: 61| Step: 0
Training loss: 2.8926462066283167
Validation loss: 2.7282655783865977

Epoch: 5| Step: 1
Training loss: 2.664614712488378
Validation loss: 2.7286009614743545

Epoch: 5| Step: 2
Training loss: 2.6883041598145603
Validation loss: 2.72587196692605

Epoch: 5| Step: 3
Training loss: 2.39770178430003
Validation loss: 2.725450188666284

Epoch: 5| Step: 4
Training loss: 3.1995248799466243
Validation loss: 2.7231160509465737

Epoch: 5| Step: 5
Training loss: 2.518037196314122
Validation loss: 2.7222464320075077

Epoch: 5| Step: 6
Training loss: 3.2133661074833437
Validation loss: 2.7226048395820808

Epoch: 5| Step: 7
Training loss: 2.5496924794584794
Validation loss: 2.71875703014181

Epoch: 5| Step: 8
Training loss: 2.96130095090627
Validation loss: 2.7167709608965183

Epoch: 5| Step: 9
Training loss: 2.687197202435849
Validation loss: 2.7159292525455654

Epoch: 5| Step: 10
Training loss: 3.4501671183924447
Validation loss: 2.7152462082372084

Epoch: 5| Step: 11
Training loss: 3.1941166437738624
Validation loss: 2.713567405378483

Epoch: 62| Step: 0
Training loss: 3.1124444121640207
Validation loss: 2.7140220514627758

Epoch: 5| Step: 1
Training loss: 2.6373980968007658
Validation loss: 2.712837517156498

Epoch: 5| Step: 2
Training loss: 3.2163985468411065
Validation loss: 2.7111273743959403

Epoch: 5| Step: 3
Training loss: 2.99641331208103
Validation loss: 2.7096084869576593

Epoch: 5| Step: 4
Training loss: 3.0425051922467827
Validation loss: 2.708523165334454

Epoch: 5| Step: 5
Training loss: 2.7499636734383808
Validation loss: 2.706778525059625

Epoch: 5| Step: 6
Training loss: 2.6071399550599073
Validation loss: 2.706750305628393

Epoch: 5| Step: 7
Training loss: 2.460686468006305
Validation loss: 2.704832111285343

Epoch: 5| Step: 8
Training loss: 2.7914346816811397
Validation loss: 2.7040700087492096

Epoch: 5| Step: 9
Training loss: 3.055358188689805
Validation loss: 2.7015444373811586

Epoch: 5| Step: 10
Training loss: 2.54269374878131
Validation loss: 2.7003683465904724

Epoch: 5| Step: 11
Training loss: 2.8884959035101168
Validation loss: 2.7001283863826306

Epoch: 63| Step: 0
Training loss: 2.789691843358707
Validation loss: 2.6986689764454757

Epoch: 5| Step: 1
Training loss: 3.141512313680211
Validation loss: 2.6968190760171864

Epoch: 5| Step: 2
Training loss: 3.0668694601869895
Validation loss: 2.6943429391679423

Epoch: 5| Step: 3
Training loss: 3.078732812967468
Validation loss: 2.6944572381789698

Epoch: 5| Step: 4
Training loss: 2.743418186431316
Validation loss: 2.6942457548329086

Epoch: 5| Step: 5
Training loss: 2.9355611692932086
Validation loss: 2.6939431107257916

Epoch: 5| Step: 6
Training loss: 2.818035019829569
Validation loss: 2.694261351462453

Epoch: 5| Step: 7
Training loss: 2.461985337747504
Validation loss: 2.6925896274710754

Epoch: 5| Step: 8
Training loss: 2.6550133912059484
Validation loss: 2.6900823370068436

Epoch: 5| Step: 9
Training loss: 2.5523555273105996
Validation loss: 2.6884373427473816

Epoch: 5| Step: 10
Training loss: 2.853453628315651
Validation loss: 2.6867356322285834

Epoch: 5| Step: 11
Training loss: 2.919633137897998
Validation loss: 2.684566275310383

Epoch: 64| Step: 0
Training loss: 2.890331191518972
Validation loss: 2.6839775614271906

Epoch: 5| Step: 1
Training loss: 2.8890386404039443
Validation loss: 2.683107308875099

Epoch: 5| Step: 2
Training loss: 2.92247256120082
Validation loss: 2.6808505004457266

Epoch: 5| Step: 3
Training loss: 2.781195136397076
Validation loss: 2.682163484837634

Epoch: 5| Step: 4
Training loss: 2.6405867173168014
Validation loss: 2.6789199463857676

Epoch: 5| Step: 5
Training loss: 2.984672811138732
Validation loss: 2.676761950536399

Epoch: 5| Step: 6
Training loss: 2.2509872601765863
Validation loss: 2.67516366184633

Epoch: 5| Step: 7
Training loss: 2.9672189077088076
Validation loss: 2.6745756342996407

Epoch: 5| Step: 8
Training loss: 2.71892564578877
Validation loss: 2.6726240257053377

Epoch: 5| Step: 9
Training loss: 2.8513399220175613
Validation loss: 2.671548711919862

Epoch: 5| Step: 10
Training loss: 3.0759267945526236
Validation loss: 2.6696519024527565

Epoch: 5| Step: 11
Training loss: 2.3536150013057227
Validation loss: 2.668685682714376

Epoch: 65| Step: 0
Training loss: 2.719204393320555
Validation loss: 2.6665442533012924

Epoch: 5| Step: 1
Training loss: 2.679282288456704
Validation loss: 2.6649050270594663

Epoch: 5| Step: 2
Training loss: 2.5141519534150754
Validation loss: 2.6659908642859156

Epoch: 5| Step: 3
Training loss: 2.767058868261755
Validation loss: 2.6646605050725407

Epoch: 5| Step: 4
Training loss: 3.1276542073020317
Validation loss: 2.663420136421343

Epoch: 5| Step: 5
Training loss: 3.1339681496331515
Validation loss: 2.661621616279263

Epoch: 5| Step: 6
Training loss: 2.275988010032998
Validation loss: 2.6605470046395885

Epoch: 5| Step: 7
Training loss: 3.112501862919874
Validation loss: 2.659348617793411

Epoch: 5| Step: 8
Training loss: 2.5582615294512148
Validation loss: 2.6587963652173636

Epoch: 5| Step: 9
Training loss: 2.940776053267435
Validation loss: 2.657371344145034

Epoch: 5| Step: 10
Training loss: 2.922801640903445
Validation loss: 2.6559845137221254

Epoch: 5| Step: 11
Training loss: 2.4293560034988366
Validation loss: 2.656302474008488

Epoch: 66| Step: 0
Training loss: 2.846275800840151
Validation loss: 2.6506189947428305

Epoch: 5| Step: 1
Training loss: 2.5650899870556425
Validation loss: 2.6556907663501135

Epoch: 5| Step: 2
Training loss: 3.2079954753853337
Validation loss: 2.6695793469786606

Epoch: 5| Step: 3
Training loss: 2.6524773228401317
Validation loss: 2.682564180227935

Epoch: 5| Step: 4
Training loss: 2.3873849491539434
Validation loss: 2.656777370683895

Epoch: 5| Step: 5
Training loss: 3.0394625755901465
Validation loss: 2.6492230573458104

Epoch: 5| Step: 6
Training loss: 2.948639869719398
Validation loss: 2.6479983533019067

Epoch: 5| Step: 7
Training loss: 2.8387645575596503
Validation loss: 2.6481794083382155

Epoch: 5| Step: 8
Training loss: 2.8781724095452277
Validation loss: 2.648515634500079

Epoch: 5| Step: 9
Training loss: 2.3895626325522703
Validation loss: 2.649590787841593

Epoch: 5| Step: 10
Training loss: 2.9376178474324584
Validation loss: 2.6515440074580767

Epoch: 5| Step: 11
Training loss: 2.2839604827481956
Validation loss: 2.653044157290507

Epoch: 67| Step: 0
Training loss: 2.471563643222399
Validation loss: 2.650430002953086

Epoch: 5| Step: 1
Training loss: 2.653371350608685
Validation loss: 2.6501609835820354

Epoch: 5| Step: 2
Training loss: 2.8540990965332704
Validation loss: 2.6477669136045745

Epoch: 5| Step: 3
Training loss: 2.720485089746892
Validation loss: 2.646167250961038

Epoch: 5| Step: 4
Training loss: 2.9523252988805546
Validation loss: 2.6440672098717557

Epoch: 5| Step: 5
Training loss: 2.8562416460511892
Validation loss: 2.6413345474609935

Epoch: 5| Step: 6
Training loss: 2.6785023017319403
Validation loss: 2.6401866120071746

Epoch: 5| Step: 7
Training loss: 2.590202203170267
Validation loss: 2.6394355886630576

Epoch: 5| Step: 8
Training loss: 2.584388384155894
Validation loss: 2.6364074749351127

Epoch: 5| Step: 9
Training loss: 3.0857961115256365
Validation loss: 2.635311318102511

Epoch: 5| Step: 10
Training loss: 3.0030265482346064
Validation loss: 2.6327510264357867

Epoch: 5| Step: 11
Training loss: 3.0085971353809504
Validation loss: 2.6321453754777537

Epoch: 68| Step: 0
Training loss: 2.9755288880115267
Validation loss: 2.6306147358975744

Epoch: 5| Step: 1
Training loss: 2.589793853509255
Validation loss: 2.629132903910511

Epoch: 5| Step: 2
Training loss: 2.882851866579959
Validation loss: 2.6284788860358077

Epoch: 5| Step: 3
Training loss: 3.0750159038349527
Validation loss: 2.6270440181620875

Epoch: 5| Step: 4
Training loss: 2.586819777709188
Validation loss: 2.628110061252274

Epoch: 5| Step: 5
Training loss: 2.5798007027587597
Validation loss: 2.625600428258546

Epoch: 5| Step: 6
Training loss: 3.4650482495844472
Validation loss: 2.624299436515365

Epoch: 5| Step: 7
Training loss: 2.3713177696119807
Validation loss: 2.6216872140823297

Epoch: 5| Step: 8
Training loss: 2.411028983753212
Validation loss: 2.6221050163070436

Epoch: 5| Step: 9
Training loss: 2.532871998223994
Validation loss: 2.6189243114485814

Epoch: 5| Step: 10
Training loss: 2.655828913802783
Validation loss: 2.6200761899656517

Epoch: 5| Step: 11
Training loss: 3.385380640082747
Validation loss: 2.6193996285260917

Epoch: 69| Step: 0
Training loss: 2.7165352580890905
Validation loss: 2.6203958934448424

Epoch: 5| Step: 1
Training loss: 2.832875850619291
Validation loss: 2.620021924971796

Epoch: 5| Step: 2
Training loss: 3.0105527607251568
Validation loss: 2.6222004948697393

Epoch: 5| Step: 3
Training loss: 2.5927938514379982
Validation loss: 2.6224449908218044

Epoch: 5| Step: 4
Training loss: 2.8318360991490747
Validation loss: 2.617879952450494

Epoch: 5| Step: 5
Training loss: 2.675085002226008
Validation loss: 2.6186008110431467

Epoch: 5| Step: 6
Training loss: 2.916617819967413
Validation loss: 2.6176503469650734

Epoch: 5| Step: 7
Training loss: 2.6270978809733374
Validation loss: 2.618939635937553

Epoch: 5| Step: 8
Training loss: 2.9723413528699822
Validation loss: 2.6108510492951296

Epoch: 5| Step: 9
Training loss: 2.6073086717584206
Validation loss: 2.6120754894829066

Epoch: 5| Step: 10
Training loss: 2.553394328634663
Validation loss: 2.6160062069282137

Epoch: 5| Step: 11
Training loss: 2.1763249099871476
Validation loss: 2.6143646503401397

Epoch: 70| Step: 0
Training loss: 2.6087004195045367
Validation loss: 2.6123010558106086

Epoch: 5| Step: 1
Training loss: 2.900985379360718
Validation loss: 2.611784079895966

Epoch: 5| Step: 2
Training loss: 2.495474916259072
Validation loss: 2.6131363597137263

Epoch: 5| Step: 3
Training loss: 2.5606584211854173
Validation loss: 2.6157981145306115

Epoch: 5| Step: 4
Training loss: 2.876863787701935
Validation loss: 2.6203081229894996

Epoch: 5| Step: 5
Training loss: 3.0136350084325563
Validation loss: 2.6086659524572817

Epoch: 5| Step: 6
Training loss: 2.5859047694598285
Validation loss: 2.6053187047332287

Epoch: 5| Step: 7
Training loss: 3.2588875366733
Validation loss: 2.6071198096783865

Epoch: 5| Step: 8
Training loss: 2.6793538322351136
Validation loss: 2.6104991379720417

Epoch: 5| Step: 9
Training loss: 2.823310927745395
Validation loss: 2.6149250670942354

Epoch: 5| Step: 10
Training loss: 2.294177488982086
Validation loss: 2.6175431840146457

Epoch: 5| Step: 11
Training loss: 2.703582989476659
Validation loss: 2.6167178401579845

Epoch: 71| Step: 0
Training loss: 3.0028955473160934
Validation loss: 2.6211337765377194

Epoch: 5| Step: 1
Training loss: 2.706789564653014
Validation loss: 2.620802308360369

Epoch: 5| Step: 2
Training loss: 2.239997033049117
Validation loss: 2.6161817563508327

Epoch: 5| Step: 3
Training loss: 2.504277765620334
Validation loss: 2.610890567006915

Epoch: 5| Step: 4
Training loss: 2.643033255596995
Validation loss: 2.6085540599379815

Epoch: 5| Step: 5
Training loss: 2.9233495897850945
Validation loss: 2.6065332925030047

Epoch: 5| Step: 6
Training loss: 2.881407852979158
Validation loss: 2.6038424035687786

Epoch: 5| Step: 7
Training loss: 2.5111327251509374
Validation loss: 2.600244661810985

Epoch: 5| Step: 8
Training loss: 3.3022554434960236
Validation loss: 2.5998273051661323

Epoch: 5| Step: 9
Training loss: 2.5026292326614974
Validation loss: 2.602159238847912

Epoch: 5| Step: 10
Training loss: 3.0832076347779163
Validation loss: 2.603376907121547

Epoch: 5| Step: 11
Training loss: 0.9747420471035253
Validation loss: 2.5997098449047544

Epoch: 72| Step: 0
Training loss: 2.929208619715807
Validation loss: 2.5992766677798507

Epoch: 5| Step: 1
Training loss: 2.8842240679463678
Validation loss: 2.597809517911205

Epoch: 5| Step: 2
Training loss: 2.8021261691727313
Validation loss: 2.596435742003842

Epoch: 5| Step: 3
Training loss: 2.5479549622380504
Validation loss: 2.593814358812828

Epoch: 5| Step: 4
Training loss: 2.9237266833813673
Validation loss: 2.5938712018967944

Epoch: 5| Step: 5
Training loss: 2.9714346542400936
Validation loss: 2.591649300178736

Epoch: 5| Step: 6
Training loss: 2.7177166783789675
Validation loss: 2.591696719294866

Epoch: 5| Step: 7
Training loss: 2.1946787072002443
Validation loss: 2.5919994743635093

Epoch: 5| Step: 8
Training loss: 2.8497690073733595
Validation loss: 2.5934745918119235

Epoch: 5| Step: 9
Training loss: 2.5840298626299067
Validation loss: 2.591530405512272

Epoch: 5| Step: 10
Training loss: 2.597306260932629
Validation loss: 2.590204722937033

Epoch: 5| Step: 11
Training loss: 2.4923464924671257
Validation loss: 2.587838276267657

Epoch: 73| Step: 0
Training loss: 2.5526744132088357
Validation loss: 2.5865333846335745

Epoch: 5| Step: 1
Training loss: 2.536709584371434
Validation loss: 2.587559136806794

Epoch: 5| Step: 2
Training loss: 2.344177207159146
Validation loss: 2.5857915520178993

Epoch: 5| Step: 3
Training loss: 3.236408571061876
Validation loss: 2.5849795262161113

Epoch: 5| Step: 4
Training loss: 2.6098111639002277
Validation loss: 2.5844660757146687

Epoch: 5| Step: 5
Training loss: 2.8357421135128957
Validation loss: 2.5829561109362267

Epoch: 5| Step: 6
Training loss: 2.5665621310988223
Validation loss: 2.5789146562647494

Epoch: 5| Step: 7
Training loss: 2.7059067541495403
Validation loss: 2.5834473782151286

Epoch: 5| Step: 8
Training loss: 2.7608592032538803
Validation loss: 2.5819542970025333

Epoch: 5| Step: 9
Training loss: 2.5527756562868125
Validation loss: 2.581076945337476

Epoch: 5| Step: 10
Training loss: 3.1415343225532766
Validation loss: 2.577625006540538

Epoch: 5| Step: 11
Training loss: 2.409715411212932
Validation loss: 2.5763315378359604

Epoch: 74| Step: 0
Training loss: 2.5735167036624302
Validation loss: 2.578292825804369

Epoch: 5| Step: 1
Training loss: 2.826771617806405
Validation loss: 2.5908743379042707

Epoch: 5| Step: 2
Training loss: 2.91954494327134
Validation loss: 2.6074745601517586

Epoch: 5| Step: 3
Training loss: 2.818272240997566
Validation loss: 2.6056363510832545

Epoch: 5| Step: 4
Training loss: 3.1004913555948135
Validation loss: 2.5821962597205315

Epoch: 5| Step: 5
Training loss: 2.3648603727968185
Validation loss: 2.5766055436449444

Epoch: 5| Step: 6
Training loss: 2.3421829070898097
Validation loss: 2.581884944616204

Epoch: 5| Step: 7
Training loss: 2.435677066801483
Validation loss: 2.5740002976972876

Epoch: 5| Step: 8
Training loss: 2.5764248877721125
Validation loss: 2.575788583649599

Epoch: 5| Step: 9
Training loss: 2.818773943678837
Validation loss: 2.5764826311695295

Epoch: 5| Step: 10
Training loss: 2.9562932533503314
Validation loss: 2.576361386277154

Epoch: 5| Step: 11
Training loss: 3.431569897135033
Validation loss: 2.5777299674668397

Epoch: 75| Step: 0
Training loss: 2.5592896425128755
Validation loss: 2.581529377126561

Epoch: 5| Step: 1
Training loss: 2.9089967606763483
Validation loss: 2.5853575010904626

Epoch: 5| Step: 2
Training loss: 2.6515504440006565
Validation loss: 2.5838024549199408

Epoch: 5| Step: 3
Training loss: 3.0622278209328124
Validation loss: 2.585807301450404

Epoch: 5| Step: 4
Training loss: 2.843503836572674
Validation loss: 2.585409750200396

Epoch: 5| Step: 5
Training loss: 2.8294799256719023
Validation loss: 2.580863253705668

Epoch: 5| Step: 6
Training loss: 2.7348734374114
Validation loss: 2.5793894739825594

Epoch: 5| Step: 7
Training loss: 2.4295661135461106
Validation loss: 2.5746842900653704

Epoch: 5| Step: 8
Training loss: 2.760012346323014
Validation loss: 2.573379449241729

Epoch: 5| Step: 9
Training loss: 2.527438555535635
Validation loss: 2.5697650075106164

Epoch: 5| Step: 10
Training loss: 2.607356770020527
Validation loss: 2.565928197393286

Epoch: 5| Step: 11
Training loss: 1.7929216765164502
Validation loss: 2.567830418798153

Epoch: 76| Step: 0
Training loss: 2.464057712393048
Validation loss: 2.5631559896901788

Epoch: 5| Step: 1
Training loss: 2.4850037936636444
Validation loss: 2.561280324696508

Epoch: 5| Step: 2
Training loss: 2.5325884635816176
Validation loss: 2.571835361451814

Epoch: 5| Step: 3
Training loss: 2.5942126861062094
Validation loss: 2.5873831120563557

Epoch: 5| Step: 4
Training loss: 3.017307740970938
Validation loss: 2.6327959695932885

Epoch: 5| Step: 5
Training loss: 3.0978118741940976
Validation loss: 2.6317916234142253

Epoch: 5| Step: 6
Training loss: 2.9809597105971783
Validation loss: 2.6008688772421618

Epoch: 5| Step: 7
Training loss: 3.0739662231495735
Validation loss: 2.5653041367919798

Epoch: 5| Step: 8
Training loss: 2.467303854461728
Validation loss: 2.556665519979768

Epoch: 5| Step: 9
Training loss: 2.670036441825746
Validation loss: 2.5617791844535898

Epoch: 5| Step: 10
Training loss: 2.47183749125846
Validation loss: 2.5634047066442074

Epoch: 5| Step: 11
Training loss: 3.133734588767746
Validation loss: 2.5696952488354947

Epoch: 77| Step: 0
Training loss: 2.5261579558881357
Validation loss: 2.5766360404841655

Epoch: 5| Step: 1
Training loss: 2.7763391064630287
Validation loss: 2.582485326409543

Epoch: 5| Step: 2
Training loss: 2.6063724992171196
Validation loss: 2.583399634638457

Epoch: 5| Step: 3
Training loss: 2.4594832710368766
Validation loss: 2.5840971545584708

Epoch: 5| Step: 4
Training loss: 2.6194680369845034
Validation loss: 2.580490298849614

Epoch: 5| Step: 5
Training loss: 2.7977855201902244
Validation loss: 2.577979023971877

Epoch: 5| Step: 6
Training loss: 3.154711357733121
Validation loss: 2.5705164506690426

Epoch: 5| Step: 7
Training loss: 2.8546209785883105
Validation loss: 2.5620122732272503

Epoch: 5| Step: 8
Training loss: 2.6336597019063714
Validation loss: 2.5598004938780985

Epoch: 5| Step: 9
Training loss: 2.9908589334385205
Validation loss: 2.5588326029635997

Epoch: 5| Step: 10
Training loss: 2.241540795612968
Validation loss: 2.5573689293050585

Epoch: 5| Step: 11
Training loss: 2.5476557933124973
Validation loss: 2.554837660891982

Epoch: 78| Step: 0
Training loss: 2.5118997606517373
Validation loss: 2.553813921065718

Epoch: 5| Step: 1
Training loss: 2.7477750447190203
Validation loss: 2.5549551680675857

Epoch: 5| Step: 2
Training loss: 2.5683574255874255
Validation loss: 2.5520476877227374

Epoch: 5| Step: 3
Training loss: 2.638297144034566
Validation loss: 2.550448549313675

Epoch: 5| Step: 4
Training loss: 2.549940452628391
Validation loss: 2.5478609552060423

Epoch: 5| Step: 5
Training loss: 2.7682399133501763
Validation loss: 2.5506121144634872

Epoch: 5| Step: 6
Training loss: 2.3175117209260536
Validation loss: 2.5504411078226474

Epoch: 5| Step: 7
Training loss: 2.883124936755246
Validation loss: 2.546815157696298

Epoch: 5| Step: 8
Training loss: 2.9877919712803735
Validation loss: 2.5470700647586897

Epoch: 5| Step: 9
Training loss: 2.6079701736534986
Validation loss: 2.5440258245242027

Epoch: 5| Step: 10
Training loss: 2.9135473373807064
Validation loss: 2.542395945707505

Epoch: 5| Step: 11
Training loss: 2.50043617258302
Validation loss: 2.5440809334538255

Epoch: 79| Step: 0
Training loss: 2.6912839111516242
Validation loss: 2.5429232857463995

Epoch: 5| Step: 1
Training loss: 3.056098007448048
Validation loss: 2.5451859800438514

Epoch: 5| Step: 2
Training loss: 2.6452776307783807
Validation loss: 2.541545737365381

Epoch: 5| Step: 3
Training loss: 2.4817412228867637
Validation loss: 2.5427588333705557

Epoch: 5| Step: 4
Training loss: 2.814682008118098
Validation loss: 2.544572936557809

Epoch: 5| Step: 5
Training loss: 1.9833252300235824
Validation loss: 2.546560490385417

Epoch: 5| Step: 6
Training loss: 2.747626060252738
Validation loss: 2.5426293853251356

Epoch: 5| Step: 7
Training loss: 3.0725154981230047
Validation loss: 2.544734394606892

Epoch: 5| Step: 8
Training loss: 2.433711310864316
Validation loss: 2.544176466306857

Epoch: 5| Step: 9
Training loss: 2.513962285028245
Validation loss: 2.544317482579539

Epoch: 5| Step: 10
Training loss: 2.6782168253554346
Validation loss: 2.543490065869513

Epoch: 5| Step: 11
Training loss: 3.3183523338561995
Validation loss: 2.540748329969805

Epoch: 80| Step: 0
Training loss: 2.459032659685293
Validation loss: 2.54143198420288

Epoch: 5| Step: 1
Training loss: 2.5880839034546
Validation loss: 2.5423736852653134

Epoch: 5| Step: 2
Training loss: 2.4073396667774647
Validation loss: 2.54066345213898

Epoch: 5| Step: 3
Training loss: 2.47601225603734
Validation loss: 2.5391879906576382

Epoch: 5| Step: 4
Training loss: 2.76647841222887
Validation loss: 2.5396680061008685

Epoch: 5| Step: 5
Training loss: 3.0327078862648618
Validation loss: 2.5404623857784423

Epoch: 5| Step: 6
Training loss: 3.0310541463286453
Validation loss: 2.5396113306264625

Epoch: 5| Step: 7
Training loss: 2.693902749954905
Validation loss: 2.535983863072995

Epoch: 5| Step: 8
Training loss: 2.6653428566771926
Validation loss: 2.533292084021371

Epoch: 5| Step: 9
Training loss: 2.4977680733723364
Validation loss: 2.531169250361958

Epoch: 5| Step: 10
Training loss: 2.553557913227118
Validation loss: 2.5328570844996277

Epoch: 5| Step: 11
Training loss: 3.161940628459496
Validation loss: 2.5318445637685545

Epoch: 81| Step: 0
Training loss: 3.085381334623243
Validation loss: 2.531078266079404

Epoch: 5| Step: 1
Training loss: 2.6805780560257935
Validation loss: 2.5324085825819806

Epoch: 5| Step: 2
Training loss: 2.470492846319746
Validation loss: 2.5294634161557767

Epoch: 5| Step: 3
Training loss: 2.965880442673294
Validation loss: 2.530239555027006

Epoch: 5| Step: 4
Training loss: 2.64953320548549
Validation loss: 2.53139777595956

Epoch: 5| Step: 5
Training loss: 2.5428019526050627
Validation loss: 2.5313706349641065

Epoch: 5| Step: 6
Training loss: 2.8233870129697247
Validation loss: 2.5282648010957307

Epoch: 5| Step: 7
Training loss: 2.5975037035213497
Validation loss: 2.5264525141669565

Epoch: 5| Step: 8
Training loss: 2.7298241810896657
Validation loss: 2.5257916133379714

Epoch: 5| Step: 9
Training loss: 2.2201289874914596
Validation loss: 2.529335329998199

Epoch: 5| Step: 10
Training loss: 2.464003333504391
Validation loss: 2.5281075763455627

Epoch: 5| Step: 11
Training loss: 2.34180054016081
Validation loss: 2.5293177266286264

Epoch: 82| Step: 0
Training loss: 2.6999389747504865
Validation loss: 2.5269335099852275

Epoch: 5| Step: 1
Training loss: 2.869230701338755
Validation loss: 2.5273760086508603

Epoch: 5| Step: 2
Training loss: 2.296411688131712
Validation loss: 2.526382750984366

Epoch: 5| Step: 3
Training loss: 2.756834121362978
Validation loss: 2.5316251704356376

Epoch: 5| Step: 4
Training loss: 2.7077616357180885
Validation loss: 2.52941113855806

Epoch: 5| Step: 5
Training loss: 2.5156358991114343
Validation loss: 2.5284744948466833

Epoch: 5| Step: 6
Training loss: 2.457213184310265
Validation loss: 2.5283363000927364

Epoch: 5| Step: 7
Training loss: 2.7087845842083897
Validation loss: 2.5257626540001614

Epoch: 5| Step: 8
Training loss: 2.7557238917906206
Validation loss: 2.5273923363159807

Epoch: 5| Step: 9
Training loss: 2.4893236117909563
Validation loss: 2.524414700004453

Epoch: 5| Step: 10
Training loss: 2.917752218319322
Validation loss: 2.524371077800593

Epoch: 5| Step: 11
Training loss: 2.945906116354442
Validation loss: 2.5236123440758784

Epoch: 83| Step: 0
Training loss: 2.981102072446567
Validation loss: 2.522623956512386

Epoch: 5| Step: 1
Training loss: 2.5919674182657224
Validation loss: 2.5250945914682985

Epoch: 5| Step: 2
Training loss: 2.743236895226163
Validation loss: 2.523491444517966

Epoch: 5| Step: 3
Training loss: 2.6961839234696185
Validation loss: 2.524789469663653

Epoch: 5| Step: 4
Training loss: 2.4401439119329833
Validation loss: 2.522685837574615

Epoch: 5| Step: 5
Training loss: 2.6272679477070993
Validation loss: 2.525097146699122

Epoch: 5| Step: 6
Training loss: 2.4554539213057454
Validation loss: 2.523985583737751

Epoch: 5| Step: 7
Training loss: 2.690196436690257
Validation loss: 2.525921495600788

Epoch: 5| Step: 8
Training loss: 2.738304236039401
Validation loss: 2.5198694401366564

Epoch: 5| Step: 9
Training loss: 2.7568963882353446
Validation loss: 2.520938194605505

Epoch: 5| Step: 10
Training loss: 2.2792955151760617
Validation loss: 2.5207875749412545

Epoch: 5| Step: 11
Training loss: 3.2050007607969433
Validation loss: 2.5171184016475263

Epoch: 84| Step: 0
Training loss: 2.9614017495031724
Validation loss: 2.520107784892784

Epoch: 5| Step: 1
Training loss: 2.245603929267384
Validation loss: 2.5165350592750735

Epoch: 5| Step: 2
Training loss: 2.782500168216834
Validation loss: 2.518008542316027

Epoch: 5| Step: 3
Training loss: 2.2645229421621265
Validation loss: 2.5149579239795874

Epoch: 5| Step: 4
Training loss: 2.3999451114417907
Validation loss: 2.5256685014096885

Epoch: 5| Step: 5
Training loss: 2.5631259060764826
Validation loss: 2.518016274942983

Epoch: 5| Step: 6
Training loss: 2.7426154082643315
Validation loss: 2.5204400052578046

Epoch: 5| Step: 7
Training loss: 2.733436467000544
Validation loss: 2.513394452850899

Epoch: 5| Step: 8
Training loss: 3.079580979268695
Validation loss: 2.5216687029443534

Epoch: 5| Step: 9
Training loss: 2.458773675910283
Validation loss: 2.512471242047363

Epoch: 5| Step: 10
Training loss: 2.7630142561786015
Validation loss: 2.5158916395261977

Epoch: 5| Step: 11
Training loss: 2.4591644196956257
Validation loss: 2.516556940360366

Epoch: 85| Step: 0
Training loss: 2.6619957209036103
Validation loss: 2.5135775540747916

Epoch: 5| Step: 1
Training loss: 2.8044499798777354
Validation loss: 2.5148977804171815

Epoch: 5| Step: 2
Training loss: 2.3976092073232578
Validation loss: 2.5148542538459373

Epoch: 5| Step: 3
Training loss: 2.6188548683891955
Validation loss: 2.5131651183035317

Epoch: 5| Step: 4
Training loss: 2.54040351080516
Validation loss: 2.5159042077086173

Epoch: 5| Step: 5
Training loss: 2.695880863138218
Validation loss: 2.5124526625138808

Epoch: 5| Step: 6
Training loss: 3.016176479690906
Validation loss: 2.511729122237349

Epoch: 5| Step: 7
Training loss: 2.362416107464375
Validation loss: 2.5139628501032325

Epoch: 5| Step: 8
Training loss: 2.4923816952038873
Validation loss: 2.5146874127870533

Epoch: 5| Step: 9
Training loss: 2.8009367704108565
Validation loss: 2.5126511824056434

Epoch: 5| Step: 10
Training loss: 2.7275034857429588
Validation loss: 2.513466396593327

Epoch: 5| Step: 11
Training loss: 1.8739443032243286
Validation loss: 2.512874386857155

Epoch: 86| Step: 0
Training loss: 2.2353519891327682
Validation loss: 2.5120716390898035

Epoch: 5| Step: 1
Training loss: 2.6345033734267957
Validation loss: 2.514412008979236

Epoch: 5| Step: 2
Training loss: 2.7356980964668245
Validation loss: 2.5107125322946517

Epoch: 5| Step: 3
Training loss: 2.7141685030303107
Validation loss: 2.5112378424854476

Epoch: 5| Step: 4
Training loss: 2.5602338120856047
Validation loss: 2.5101368116300313

Epoch: 5| Step: 5
Training loss: 2.8255704860748643
Validation loss: 2.5104073185304783

Epoch: 5| Step: 6
Training loss: 2.647344222920651
Validation loss: 2.5085920744313857

Epoch: 5| Step: 7
Training loss: 2.4148730056259233
Validation loss: 2.509447085974996

Epoch: 5| Step: 8
Training loss: 2.5388066089503836
Validation loss: 2.5090393282115344

Epoch: 5| Step: 9
Training loss: 2.6985284609945035
Validation loss: 2.504162204493029

Epoch: 5| Step: 10
Training loss: 2.909756749529188
Validation loss: 2.507470647342799

Epoch: 5| Step: 11
Training loss: 2.520273971499618
Validation loss: 2.5089187281683283

Epoch: 87| Step: 0
Training loss: 3.0214550211688223
Validation loss: 2.504632440835604

Epoch: 5| Step: 1
Training loss: 2.3252133589440382
Validation loss: 2.502194835889822

Epoch: 5| Step: 2
Training loss: 2.6730716100448895
Validation loss: 2.5041438291040423

Epoch: 5| Step: 3
Training loss: 2.656057552771177
Validation loss: 2.5068748202625413

Epoch: 5| Step: 4
Training loss: 2.421607414968207
Validation loss: 2.502340171192892

Epoch: 5| Step: 5
Training loss: 2.16910623488462
Validation loss: 2.501593995556235

Epoch: 5| Step: 6
Training loss: 2.8916843432088637
Validation loss: 2.50303981666225

Epoch: 5| Step: 7
Training loss: 2.890507381211368
Validation loss: 2.501341026965434

Epoch: 5| Step: 8
Training loss: 2.7640082164758213
Validation loss: 2.5060023016542305

Epoch: 5| Step: 9
Training loss: 2.8084413701980835
Validation loss: 2.5056987819020073

Epoch: 5| Step: 10
Training loss: 2.0846282622107153
Validation loss: 2.5040648633814917

Epoch: 5| Step: 11
Training loss: 2.686191861467414
Validation loss: 2.5070493136973946

Epoch: 88| Step: 0
Training loss: 2.788745851466617
Validation loss: 2.507240321245504

Epoch: 5| Step: 1
Training loss: 2.530205593576174
Validation loss: 2.5040311182143116

Epoch: 5| Step: 2
Training loss: 2.575068193291929
Validation loss: 2.501563789117955

Epoch: 5| Step: 3
Training loss: 2.816042047197533
Validation loss: 2.5059127346035583

Epoch: 5| Step: 4
Training loss: 2.2586701028243
Validation loss: 2.5008782155556846

Epoch: 5| Step: 5
Training loss: 2.6918937784128505
Validation loss: 2.5015071537932934

Epoch: 5| Step: 6
Training loss: 2.846741664205266
Validation loss: 2.499922659790281

Epoch: 5| Step: 7
Training loss: 2.3494752257397282
Validation loss: 2.5032324496831557

Epoch: 5| Step: 8
Training loss: 2.703644101788951
Validation loss: 2.5066193845107665

Epoch: 5| Step: 9
Training loss: 2.697274552647472
Validation loss: 2.4999728201342335

Epoch: 5| Step: 10
Training loss: 2.6492573867180824
Validation loss: 2.5081173482740633

Epoch: 5| Step: 11
Training loss: 1.6599567607625563
Validation loss: 2.5037252645402286

Epoch: 89| Step: 0
Training loss: 2.522818663688926
Validation loss: 2.5119009589614354

Epoch: 5| Step: 1
Training loss: 2.7436350943937433
Validation loss: 2.5253958528705014

Epoch: 5| Step: 2
Training loss: 2.9753110963385185
Validation loss: 2.5291637174493813

Epoch: 5| Step: 3
Training loss: 3.062642308256907
Validation loss: 2.5229917591195745

Epoch: 5| Step: 4
Training loss: 2.8141913520589568
Validation loss: 2.5029718775274925

Epoch: 5| Step: 5
Training loss: 2.5494600996032464
Validation loss: 2.501953605435415

Epoch: 5| Step: 6
Training loss: 2.395650430967807
Validation loss: 2.499112253721387

Epoch: 5| Step: 7
Training loss: 2.3155425392943525
Validation loss: 2.5008714786146995

Epoch: 5| Step: 8
Training loss: 2.0393288390920765
Validation loss: 2.5045709744304356

Epoch: 5| Step: 9
Training loss: 2.707615556725371
Validation loss: 2.50939738024925

Epoch: 5| Step: 10
Training loss: 2.757276618050809
Validation loss: 2.5117583046780254

Epoch: 5| Step: 11
Training loss: 2.1541759080030696
Validation loss: 2.513994853688417

Epoch: 90| Step: 0
Training loss: 2.5481004633598165
Validation loss: 2.517592937858967

Epoch: 5| Step: 1
Training loss: 2.417229016964028
Validation loss: 2.5196563177092632

Epoch: 5| Step: 2
Training loss: 3.0190860474369745
Validation loss: 2.5167660899344093

Epoch: 5| Step: 3
Training loss: 2.7162927506756422
Validation loss: 2.5194832770144693

Epoch: 5| Step: 4
Training loss: 2.3862686856688744
Validation loss: 2.517270310324558

Epoch: 5| Step: 5
Training loss: 3.021169516612385
Validation loss: 2.513778941125247

Epoch: 5| Step: 6
Training loss: 2.8221685584248624
Validation loss: 2.514303669920866

Epoch: 5| Step: 7
Training loss: 2.794402238802227
Validation loss: 2.5097940643717918

Epoch: 5| Step: 8
Training loss: 2.380948097134324
Validation loss: 2.504808004649036

Epoch: 5| Step: 9
Training loss: 2.77795377703579
Validation loss: 2.506040238047493

Epoch: 5| Step: 10
Training loss: 2.000197996829258
Validation loss: 2.5011377090280424

Epoch: 5| Step: 11
Training loss: 2.496592010770564
Validation loss: 2.499928250872675

Epoch: 91| Step: 0
Training loss: 2.2352654876735607
Validation loss: 2.4977291840695255

Epoch: 5| Step: 1
Training loss: 2.555174428282295
Validation loss: 2.4970000785147284

Epoch: 5| Step: 2
Training loss: 2.5855888754036447
Validation loss: 2.494236800117661

Epoch: 5| Step: 3
Training loss: 2.8427246257295997
Validation loss: 2.4913023589578827

Epoch: 5| Step: 4
Training loss: 2.532765629385877
Validation loss: 2.4939255030420844

Epoch: 5| Step: 5
Training loss: 2.5944879240503727
Validation loss: 2.489836876752687

Epoch: 5| Step: 6
Training loss: 2.876812405067914
Validation loss: 2.496402635799543

Epoch: 5| Step: 7
Training loss: 2.4532864268455845
Validation loss: 2.494307255288172

Epoch: 5| Step: 8
Training loss: 2.734981622163443
Validation loss: 2.498674394908649

Epoch: 5| Step: 9
Training loss: 2.908151804187452
Validation loss: 2.5075653524810675

Epoch: 5| Step: 10
Training loss: 2.456248633309098
Validation loss: 2.513372901934727

Epoch: 5| Step: 11
Training loss: 2.4660347601675228
Validation loss: 2.5010621357728526

Epoch: 92| Step: 0
Training loss: 2.712582927086658
Validation loss: 2.4993503958414838

Epoch: 5| Step: 1
Training loss: 2.6578634410822635
Validation loss: 2.5010142017547494

Epoch: 5| Step: 2
Training loss: 2.432139150233772
Validation loss: 2.498815120607327

Epoch: 5| Step: 3
Training loss: 2.8954603837810335
Validation loss: 2.4912424119182046

Epoch: 5| Step: 4
Training loss: 2.574897919640665
Validation loss: 2.493561125974803

Epoch: 5| Step: 5
Training loss: 2.27328270454001
Validation loss: 2.4876752042490557

Epoch: 5| Step: 6
Training loss: 2.9126773436421867
Validation loss: 2.49224072980488

Epoch: 5| Step: 7
Training loss: 2.6901740144793482
Validation loss: 2.4923085708467934

Epoch: 5| Step: 8
Training loss: 1.99473606228002
Validation loss: 2.487378853574709

Epoch: 5| Step: 9
Training loss: 2.4531753437683474
Validation loss: 2.4867432580607653

Epoch: 5| Step: 10
Training loss: 2.933343422034283
Validation loss: 2.4890140111254775

Epoch: 5| Step: 11
Training loss: 3.0276318222314895
Validation loss: 2.4839824390358842

Epoch: 93| Step: 0
Training loss: 2.5787596875007384
Validation loss: 2.4940148473464396

Epoch: 5| Step: 1
Training loss: 2.2569261546901815
Validation loss: 2.492295014743926

Epoch: 5| Step: 2
Training loss: 2.4827393719687
Validation loss: 2.4912863310866573

Epoch: 5| Step: 3
Training loss: 2.4007654479400835
Validation loss: 2.488140335763998

Epoch: 5| Step: 4
Training loss: 2.604683867911385
Validation loss: 2.4878148490684793

Epoch: 5| Step: 5
Training loss: 2.60508219583765
Validation loss: 2.4928986064017167

Epoch: 5| Step: 6
Training loss: 3.499845910086349
Validation loss: 2.4894707360336312

Epoch: 5| Step: 7
Training loss: 2.598173666455345
Validation loss: 2.486796308788654

Epoch: 5| Step: 8
Training loss: 2.5427141897177594
Validation loss: 2.4972450514467592

Epoch: 5| Step: 9
Training loss: 2.3789896331856277
Validation loss: 2.490702574354254

Epoch: 5| Step: 10
Training loss: 2.3280685725190375
Validation loss: 2.4932017479775412

Epoch: 5| Step: 11
Training loss: 3.7446586716140806
Validation loss: 2.489854579710871

Epoch: 94| Step: 0
Training loss: 2.6211844370314332
Validation loss: 2.4891683573142935

Epoch: 5| Step: 1
Training loss: 2.9103528666802156
Validation loss: 2.4891819942995603

Epoch: 5| Step: 2
Training loss: 2.664042721672137
Validation loss: 2.4915348980316203

Epoch: 5| Step: 3
Training loss: 2.3329247275847576
Validation loss: 2.490844169204726

Epoch: 5| Step: 4
Training loss: 2.3535591849573634
Validation loss: 2.4896287807535424

Epoch: 5| Step: 5
Training loss: 2.705861817462491
Validation loss: 2.4877046069624256

Epoch: 5| Step: 6
Training loss: 2.451154269576964
Validation loss: 2.4912737982124145

Epoch: 5| Step: 7
Training loss: 2.319025164212272
Validation loss: 2.492333355086512

Epoch: 5| Step: 8
Training loss: 3.205454504960884
Validation loss: 2.4929219223082675

Epoch: 5| Step: 9
Training loss: 2.663840544731217
Validation loss: 2.4921430944554497

Epoch: 5| Step: 10
Training loss: 2.233171685854766
Validation loss: 2.4895130304494937

Epoch: 5| Step: 11
Training loss: 3.086919932373413
Validation loss: 2.4877896344752455

Epoch: 95| Step: 0
Training loss: 1.7471784597649789
Validation loss: 2.4920090997156272

Epoch: 5| Step: 1
Training loss: 2.912672596020934
Validation loss: 2.4848607825933002

Epoch: 5| Step: 2
Training loss: 2.8705236997863572
Validation loss: 2.490266691509315

Epoch: 5| Step: 3
Training loss: 2.469604730523574
Validation loss: 2.491426285872186

Epoch: 5| Step: 4
Training loss: 2.662984053618087
Validation loss: 2.4904665411140336

Epoch: 5| Step: 5
Training loss: 2.5232823563351925
Validation loss: 2.4927769186167996

Epoch: 5| Step: 6
Training loss: 2.841477880238429
Validation loss: 2.4858294334236097

Epoch: 5| Step: 7
Training loss: 2.8670088792922197
Validation loss: 2.482191934048123

Epoch: 5| Step: 8
Training loss: 2.1601694944779326
Validation loss: 2.4924741040079916

Epoch: 5| Step: 9
Training loss: 2.6487584102509696
Validation loss: 2.4850705890428726

Epoch: 5| Step: 10
Training loss: 2.589765498617508
Validation loss: 2.485630078251797

Epoch: 5| Step: 11
Training loss: 2.8810169448433673
Validation loss: 2.4829271484113637

Epoch: 96| Step: 0
Training loss: 2.0709836627678686
Validation loss: 2.487246063983377

Epoch: 5| Step: 1
Training loss: 2.899160783291518
Validation loss: 2.487140623646961

Epoch: 5| Step: 2
Training loss: 2.7360641058053923
Validation loss: 2.4921054288450875

Epoch: 5| Step: 3
Training loss: 2.3765995261012316
Validation loss: 2.490672245798033

Epoch: 5| Step: 4
Training loss: 2.4598751621049533
Validation loss: 2.485557994251119

Epoch: 5| Step: 5
Training loss: 3.0457025864314327
Validation loss: 2.4860266027940146

Epoch: 5| Step: 6
Training loss: 2.673891789839666
Validation loss: 2.4854725066949768

Epoch: 5| Step: 7
Training loss: 2.484599073369666
Validation loss: 2.4805241015408503

Epoch: 5| Step: 8
Training loss: 2.0879125495808646
Validation loss: 2.4851261898598396

Epoch: 5| Step: 9
Training loss: 2.698028699593569
Validation loss: 2.48645229384146

Epoch: 5| Step: 10
Training loss: 2.746390748547496
Validation loss: 2.4806800371829087

Epoch: 5| Step: 11
Training loss: 2.76704447897402
Validation loss: 2.4814374939346093

Epoch: 97| Step: 0
Training loss: 2.246824673021375
Validation loss: 2.481290333769963

Epoch: 5| Step: 1
Training loss: 2.7761664061346867
Validation loss: 2.484747988614239

Epoch: 5| Step: 2
Training loss: 2.986322217078443
Validation loss: 2.4844939965113966

Epoch: 5| Step: 3
Training loss: 1.831858547505136
Validation loss: 2.4821092802451163

Epoch: 5| Step: 4
Training loss: 2.9131504298509747
Validation loss: 2.483814244193793

Epoch: 5| Step: 5
Training loss: 2.4423612390028318
Validation loss: 2.478251335656645

Epoch: 5| Step: 6
Training loss: 2.526026670011594
Validation loss: 2.4830252261583774

Epoch: 5| Step: 7
Training loss: 2.5530262249781193
Validation loss: 2.482130864471497

Epoch: 5| Step: 8
Training loss: 2.185417819197078
Validation loss: 2.4813048868330365

Epoch: 5| Step: 9
Training loss: 2.8343151485764944
Validation loss: 2.487948664421816

Epoch: 5| Step: 10
Training loss: 3.028938906859836
Validation loss: 2.4910221145431297

Epoch: 5| Step: 11
Training loss: 2.3821552308154
Validation loss: 2.4841795350600657

Epoch: 98| Step: 0
Training loss: 2.7547779191746415
Validation loss: 2.4916067253885217

Epoch: 5| Step: 1
Training loss: 2.887884211884618
Validation loss: 2.487155529912252

Epoch: 5| Step: 2
Training loss: 2.2578944419062235
Validation loss: 2.4793397311436403

Epoch: 5| Step: 3
Training loss: 2.623149401151547
Validation loss: 2.4912394570961607

Epoch: 5| Step: 4
Training loss: 2.5373493694828353
Validation loss: 2.47724644776527

Epoch: 5| Step: 5
Training loss: 2.5788419709144077
Validation loss: 2.4867088603706824

Epoch: 5| Step: 6
Training loss: 2.481079026488506
Validation loss: 2.485980816457146

Epoch: 5| Step: 7
Training loss: 2.8227655199039976
Validation loss: 2.486813841645607

Epoch: 5| Step: 8
Training loss: 2.953012938618694
Validation loss: 2.484778761293002

Epoch: 5| Step: 9
Training loss: 2.0616242832688427
Validation loss: 2.4785019694083137

Epoch: 5| Step: 10
Training loss: 2.320167203008126
Validation loss: 2.476475141490746

Epoch: 5| Step: 11
Training loss: 2.917031746676852
Validation loss: 2.4807118574541445

Epoch: 99| Step: 0
Training loss: 2.550349574343678
Validation loss: 2.4804705201790966

Epoch: 5| Step: 1
Training loss: 2.6323625763094065
Validation loss: 2.4866639754734186

Epoch: 5| Step: 2
Training loss: 2.9937934251156384
Validation loss: 2.4790637144515904

Epoch: 5| Step: 3
Training loss: 2.841869193398974
Validation loss: 2.4836406822126107

Epoch: 5| Step: 4
Training loss: 2.673948944237788
Validation loss: 2.487714977495661

Epoch: 5| Step: 5
Training loss: 2.582934523121409
Validation loss: 2.490647484914387

Epoch: 5| Step: 6
Training loss: 2.6476231225970026
Validation loss: 2.492252568239561

Epoch: 5| Step: 7
Training loss: 2.0430446049045026
Validation loss: 2.494992621709684

Epoch: 5| Step: 8
Training loss: 2.2743333447597203
Validation loss: 2.4990119650585996

Epoch: 5| Step: 9
Training loss: 3.017220030835925
Validation loss: 2.5058115565355195

Epoch: 5| Step: 10
Training loss: 2.250118040591257
Validation loss: 2.5165263194198375

Epoch: 5| Step: 11
Training loss: 2.554005943165961
Validation loss: 2.521465601852427

Epoch: 100| Step: 0
Training loss: 3.023075841125844
Validation loss: 2.5131427214847624

Epoch: 5| Step: 1
Training loss: 2.410515410682018
Validation loss: 2.503078635362216

Epoch: 5| Step: 2
Training loss: 2.874576371536491
Validation loss: 2.5015978435598454

Epoch: 5| Step: 3
Training loss: 2.4444270374179236
Validation loss: 2.494738816489257

Epoch: 5| Step: 4
Training loss: 2.7743957583378505
Validation loss: 2.4908347409655858

Epoch: 5| Step: 5
Training loss: 2.9991654188855383
Validation loss: 2.4910096401593145

Epoch: 5| Step: 6
Training loss: 2.3983215900457937
Validation loss: 2.483753314496795

Epoch: 5| Step: 7
Training loss: 2.230421182689754
Validation loss: 2.4849810770690777

Epoch: 5| Step: 8
Training loss: 2.4102280666341347
Validation loss: 2.4839561517188575

Epoch: 5| Step: 9
Training loss: 2.243266095442843
Validation loss: 2.47744578786253

Epoch: 5| Step: 10
Training loss: 2.7069422059049617
Validation loss: 2.4834774843297005

Epoch: 5| Step: 11
Training loss: 2.7418284819678327
Validation loss: 2.484748112553296

Epoch: 101| Step: 0
Training loss: 2.441903562630144
Validation loss: 2.4868176326253093

Epoch: 5| Step: 1
Training loss: 2.4241560499741897
Validation loss: 2.483072999348445

Epoch: 5| Step: 2
Training loss: 3.0708765186463354
Validation loss: 2.4923688489729403

Epoch: 5| Step: 3
Training loss: 2.5917197864972192
Validation loss: 2.4937097450582986

Epoch: 5| Step: 4
Training loss: 2.8768657766886725
Validation loss: 2.4944783467283087

Epoch: 5| Step: 5
Training loss: 2.275439243042823
Validation loss: 2.501048913098098

Epoch: 5| Step: 6
Training loss: 2.4166795686399323
Validation loss: 2.4985071692217242

Epoch: 5| Step: 7
Training loss: 2.086596324190017
Validation loss: 2.48789565024515

Epoch: 5| Step: 8
Training loss: 2.8930591129259335
Validation loss: 2.4899293640438387

Epoch: 5| Step: 9
Training loss: 2.7314861623241407
Validation loss: 2.4861201428818225

Epoch: 5| Step: 10
Training loss: 2.6888770190766
Validation loss: 2.4813998399711794

Epoch: 5| Step: 11
Training loss: 3.2371837564611163
Validation loss: 2.481536687404377

Epoch: 102| Step: 0
Training loss: 2.1352286155209588
Validation loss: 2.480124033606505

Epoch: 5| Step: 1
Training loss: 2.6542343570176046
Validation loss: 2.4803077585435274

Epoch: 5| Step: 2
Training loss: 2.572893788677438
Validation loss: 2.478913413797954

Epoch: 5| Step: 3
Training loss: 2.945002936732539
Validation loss: 2.471780494333356

Epoch: 5| Step: 4
Training loss: 2.3300407771197422
Validation loss: 2.4749348583703936

Epoch: 5| Step: 5
Training loss: 2.7312173103802992
Validation loss: 2.4790856497747344

Epoch: 5| Step: 6
Training loss: 2.5869361816013594
Validation loss: 2.480995706968631

Epoch: 5| Step: 7
Training loss: 2.836334621063178
Validation loss: 2.479504086802815

Epoch: 5| Step: 8
Training loss: 2.4660571900455177
Validation loss: 2.4826282582503727

Epoch: 5| Step: 9
Training loss: 2.4754046793233657
Validation loss: 2.47397201266606

Epoch: 5| Step: 10
Training loss: 2.672800717969545
Validation loss: 2.475431029359375

Epoch: 5| Step: 11
Training loss: 2.4058742477519672
Validation loss: 2.4771676111495635

Epoch: 103| Step: 0
Training loss: 2.8724234272152223
Validation loss: 2.4790108348586064

Epoch: 5| Step: 1
Training loss: 2.5294272370784974
Validation loss: 2.474478437396433

Epoch: 5| Step: 2
Training loss: 1.9050475533625164
Validation loss: 2.4770989343479686

Epoch: 5| Step: 3
Training loss: 3.01366317263204
Validation loss: 2.474326025425245

Epoch: 5| Step: 4
Training loss: 2.447374638278061
Validation loss: 2.480106197103572

Epoch: 5| Step: 5
Training loss: 2.5321377739748643
Validation loss: 2.4839053059872285

Epoch: 5| Step: 6
Training loss: 2.940898309344572
Validation loss: 2.4739439525520903

Epoch: 5| Step: 7
Training loss: 2.7441887576405954
Validation loss: 2.4809903194719634

Epoch: 5| Step: 8
Training loss: 2.5171650028940165
Validation loss: 2.480347766078399

Epoch: 5| Step: 9
Training loss: 2.0864366941302777
Validation loss: 2.473836190404152

Epoch: 5| Step: 10
Training loss: 2.5201253501052125
Validation loss: 2.475929751024755

Epoch: 5| Step: 11
Training loss: 3.473834872971139
Validation loss: 2.470783197163401

Epoch: 104| Step: 0
Training loss: 2.300899794006803
Validation loss: 2.479509219110746

Epoch: 5| Step: 1
Training loss: 2.3831871863774614
Validation loss: 2.4887994439249206

Epoch: 5| Step: 2
Training loss: 2.9737503504582534
Validation loss: 2.4970747403496074

Epoch: 5| Step: 3
Training loss: 2.183192671789868
Validation loss: 2.520124498652496

Epoch: 5| Step: 4
Training loss: 2.9183230102054383
Validation loss: 2.5492125083698065

Epoch: 5| Step: 5
Training loss: 2.6671157299859845
Validation loss: 2.57628299144762

Epoch: 5| Step: 6
Training loss: 3.053829921530705
Validation loss: 2.5984677607949043

Epoch: 5| Step: 7
Training loss: 2.714689006100203
Validation loss: 2.583394039630307

Epoch: 5| Step: 8
Training loss: 2.425120879631107
Validation loss: 2.5915675575669748

Epoch: 5| Step: 9
Training loss: 2.959384641863253
Validation loss: 2.583700405211442

Epoch: 5| Step: 10
Training loss: 2.7925476183540985
Validation loss: 2.564544831045541

Epoch: 5| Step: 11
Training loss: 2.655900909821703
Validation loss: 2.554207993049114

Epoch: 105| Step: 0
Training loss: 2.570137087509164
Validation loss: 2.5353592966172007

Epoch: 5| Step: 1
Training loss: 2.614700456607449
Validation loss: 2.5307199292048024

Epoch: 5| Step: 2
Training loss: 2.7735280196770753
Validation loss: 2.525459573802182

Epoch: 5| Step: 3
Training loss: 2.5885385760180766
Validation loss: 2.5172862378674647

Epoch: 5| Step: 4
Training loss: 2.6794524242621436
Validation loss: 2.511474648929879

Epoch: 5| Step: 5
Training loss: 2.1939786612517067
Validation loss: 2.5036511343311374

Epoch: 5| Step: 6
Training loss: 2.9977723433955337
Validation loss: 2.4992821457519563

Epoch: 5| Step: 7
Training loss: 2.511583766602778
Validation loss: 2.4952937810805222

Epoch: 5| Step: 8
Training loss: 2.4932199091620246
Validation loss: 2.49383557395101

Epoch: 5| Step: 9
Training loss: 2.8046031716082958
Validation loss: 2.4868632198021814

Epoch: 5| Step: 10
Training loss: 2.3539656719274893
Validation loss: 2.4871558614278544

Epoch: 5| Step: 11
Training loss: 3.655580899563958
Validation loss: 2.482910136245032

Epoch: 106| Step: 0
Training loss: 3.0520406118968144
Validation loss: 2.479977079908531

Epoch: 5| Step: 1
Training loss: 2.5206979342161415
Validation loss: 2.4783102180370977

Epoch: 5| Step: 2
Training loss: 2.6641349894486193
Validation loss: 2.476571677719423

Epoch: 5| Step: 3
Training loss: 2.3643638968351963
Validation loss: 2.4759038295957665

Epoch: 5| Step: 4
Training loss: 2.741553600109425
Validation loss: 2.4727116358109815

Epoch: 5| Step: 5
Training loss: 2.233764671785557
Validation loss: 2.477401238380649

Epoch: 5| Step: 6
Training loss: 3.1653935399595077
Validation loss: 2.4809378112877343

Epoch: 5| Step: 7
Training loss: 2.6105593432023535
Validation loss: 2.478925947048359

Epoch: 5| Step: 8
Training loss: 2.266170988394061
Validation loss: 2.480393380048795

Epoch: 5| Step: 9
Training loss: 2.2121302753736294
Validation loss: 2.4770432997297993

Epoch: 5| Step: 10
Training loss: 2.490860636631565
Validation loss: 2.48141056313192

Epoch: 5| Step: 11
Training loss: 2.936570040628288
Validation loss: 2.4770042755455557

Epoch: 107| Step: 0
Training loss: 2.542161007528005
Validation loss: 2.47446607231498

Epoch: 5| Step: 1
Training loss: 2.551234907435511
Validation loss: 2.4801918135510337

Epoch: 5| Step: 2
Training loss: 2.5333602962397523
Validation loss: 2.4827651079959083

Epoch: 5| Step: 3
Training loss: 2.0113003490113317
Validation loss: 2.480491742205252

Epoch: 5| Step: 4
Training loss: 3.019246037326394
Validation loss: 2.4827790202241578

Epoch: 5| Step: 5
Training loss: 2.7280490615605677
Validation loss: 2.475806460819463

Epoch: 5| Step: 6
Training loss: 2.513667511954741
Validation loss: 2.4632750737235516

Epoch: 5| Step: 7
Training loss: 2.3984455518556316
Validation loss: 2.4735499530161755

Epoch: 5| Step: 8
Training loss: 2.634289426307439
Validation loss: 2.4724592519088873

Epoch: 5| Step: 9
Training loss: 2.6232177496930533
Validation loss: 2.471461181547874

Epoch: 5| Step: 10
Training loss: 3.104092198103757
Validation loss: 2.4748948596688205

Epoch: 5| Step: 11
Training loss: 1.1600324262822332
Validation loss: 2.472257500627766

Epoch: 108| Step: 0
Training loss: 2.124576638627588
Validation loss: 2.4741202545716683

Epoch: 5| Step: 1
Training loss: 2.7218329828218617
Validation loss: 2.4763341210737564

Epoch: 5| Step: 2
Training loss: 3.0365577712006986
Validation loss: 2.4742317262804514

Epoch: 5| Step: 3
Training loss: 2.542117115399242
Validation loss: 2.475077648261331

Epoch: 5| Step: 4
Training loss: 2.198345980064372
Validation loss: 2.4768578486619197

Epoch: 5| Step: 5
Training loss: 2.3887642993029914
Validation loss: 2.4796818163269196

Epoch: 5| Step: 6
Training loss: 2.6398083930852576
Validation loss: 2.4769248496760223

Epoch: 5| Step: 7
Training loss: 2.427603757233917
Validation loss: 2.476050936775577

Epoch: 5| Step: 8
Training loss: 3.002307957741863
Validation loss: 2.477711672666113

Epoch: 5| Step: 9
Training loss: 2.6181694352273763
Validation loss: 2.476563101687193

Epoch: 5| Step: 10
Training loss: 2.6459079241313286
Validation loss: 2.474451643632076

Epoch: 5| Step: 11
Training loss: 2.7245536333623743
Validation loss: 2.47644626733765

Epoch: 109| Step: 0
Training loss: 2.3207565550600098
Validation loss: 2.4738623081778828

Epoch: 5| Step: 1
Training loss: 2.596949063747163
Validation loss: 2.4711698953139156

Epoch: 5| Step: 2
Training loss: 2.4015674360196
Validation loss: 2.468986218253434

Epoch: 5| Step: 3
Training loss: 2.6500428322263545
Validation loss: 2.472628070495961

Epoch: 5| Step: 4
Training loss: 2.5363630293866843
Validation loss: 2.4694337702717015

Epoch: 5| Step: 5
Training loss: 2.4413961913855293
Validation loss: 2.4684717448070552

Epoch: 5| Step: 6
Training loss: 2.972002035127459
Validation loss: 2.4691972609070905

Epoch: 5| Step: 7
Training loss: 2.7190011445604605
Validation loss: 2.4626119659194043

Epoch: 5| Step: 8
Training loss: 3.2114367317383055
Validation loss: 2.459460494426835

Epoch: 5| Step: 9
Training loss: 1.9662917396688906
Validation loss: 2.4644828326601926

Epoch: 5| Step: 10
Training loss: 2.338254054223947
Validation loss: 2.471017134543354

Epoch: 5| Step: 11
Training loss: 2.4520908775850936
Validation loss: 2.473027404843482

Epoch: 110| Step: 0
Training loss: 2.644747073045606
Validation loss: 2.4655306061120377

Epoch: 5| Step: 1
Training loss: 2.7220009845785116
Validation loss: 2.465335790790329

Epoch: 5| Step: 2
Training loss: 2.497792031872322
Validation loss: 2.4671010775948874

Epoch: 5| Step: 3
Training loss: 2.2247069005043913
Validation loss: 2.4806534585740385

Epoch: 5| Step: 4
Training loss: 3.0092907728408984
Validation loss: 2.474387538554069

Epoch: 5| Step: 5
Training loss: 2.431492567342435
Validation loss: 2.4710533446728093

Epoch: 5| Step: 6
Training loss: 2.402505909478802
Validation loss: 2.472717340647777

Epoch: 5| Step: 7
Training loss: 2.3308676112026117
Validation loss: 2.4627478707164636

Epoch: 5| Step: 8
Training loss: 2.9266910131682944
Validation loss: 2.467490349692425

Epoch: 5| Step: 9
Training loss: 2.39860350192783
Validation loss: 2.4642061455720143

Epoch: 5| Step: 10
Training loss: 2.7206293384982745
Validation loss: 2.4614057388100106

Epoch: 5| Step: 11
Training loss: 1.641472443195072
Validation loss: 2.467684310553545

Epoch: 111| Step: 0
Training loss: 2.6293325546171933
Validation loss: 2.4740345484722317

Epoch: 5| Step: 1
Training loss: 2.543625144799898
Validation loss: 2.471055861311359

Epoch: 5| Step: 2
Training loss: 2.45478133150349
Validation loss: 2.478595741365921

Epoch: 5| Step: 3
Training loss: 2.7562979626969724
Validation loss: 2.4816635978616564

Epoch: 5| Step: 4
Training loss: 2.6576380973526557
Validation loss: 2.4794699272367495

Epoch: 5| Step: 5
Training loss: 2.745093129424772
Validation loss: 2.481687303533716

Epoch: 5| Step: 6
Training loss: 2.380674109319189
Validation loss: 2.484683343558165

Epoch: 5| Step: 7
Training loss: 2.6423310857251323
Validation loss: 2.488280754947663

Epoch: 5| Step: 8
Training loss: 2.667645056372671
Validation loss: 2.4859594654620967

Epoch: 5| Step: 9
Training loss: 2.9286179688374276
Validation loss: 2.4876845446298637

Epoch: 5| Step: 10
Training loss: 2.4034687168473337
Validation loss: 2.487344251002768

Epoch: 5| Step: 11
Training loss: 1.0863372835269107
Validation loss: 2.4875117239364304

Epoch: 112| Step: 0
Training loss: 2.7692957079845626
Validation loss: 2.4899821753355424

Epoch: 5| Step: 1
Training loss: 2.7091496533372323
Validation loss: 2.4889406122096336

Epoch: 5| Step: 2
Training loss: 2.6209019052079023
Validation loss: 2.4887334232107166

Epoch: 5| Step: 3
Training loss: 2.563355837931103
Validation loss: 2.487027969014672

Epoch: 5| Step: 4
Training loss: 2.398276556622926
Validation loss: 2.483745207222786

Epoch: 5| Step: 5
Training loss: 2.252110021705361
Validation loss: 2.4871813720200744

Epoch: 5| Step: 6
Training loss: 2.890692632760309
Validation loss: 2.4821212030219617

Epoch: 5| Step: 7
Training loss: 2.9577037696581945
Validation loss: 2.4792112632287893

Epoch: 5| Step: 8
Training loss: 2.4216818455611806
Validation loss: 2.478520226280164

Epoch: 5| Step: 9
Training loss: 2.4578169156354366
Validation loss: 2.4744079515897237

Epoch: 5| Step: 10
Training loss: 2.5995901151498226
Validation loss: 2.468057237475591

Epoch: 5| Step: 11
Training loss: 1.496959784223028
Validation loss: 2.472592586523376

Epoch: 113| Step: 0
Training loss: 2.699536714719971
Validation loss: 2.4661904558913457

Epoch: 5| Step: 1
Training loss: 2.5613745101817287
Validation loss: 2.4684873795354454

Epoch: 5| Step: 2
Training loss: 2.6170455666387946
Validation loss: 2.463393944201963

Epoch: 5| Step: 3
Training loss: 2.973316094329992
Validation loss: 2.462225456876424

Epoch: 5| Step: 4
Training loss: 3.0160654961838125
Validation loss: 2.4604940105645174

Epoch: 5| Step: 5
Training loss: 2.5587706060656026
Validation loss: 2.462616003921962

Epoch: 5| Step: 6
Training loss: 2.259963756371935
Validation loss: 2.4602364323619246

Epoch: 5| Step: 7
Training loss: 1.9599793665636756
Validation loss: 2.465011917398827

Epoch: 5| Step: 8
Training loss: 2.419252415406603
Validation loss: 2.469497133023563

Epoch: 5| Step: 9
Training loss: 2.3892776581984583
Validation loss: 2.468665028972874

Epoch: 5| Step: 10
Training loss: 2.7756576892806404
Validation loss: 2.465055256115276

Epoch: 5| Step: 11
Training loss: 1.8749291088689999
Validation loss: 2.4638634458783852

Epoch: 114| Step: 0
Training loss: 2.3376145482683057
Validation loss: 2.4629031046652785

Epoch: 5| Step: 1
Training loss: 3.0974248773241464
Validation loss: 2.4649367035327896

Epoch: 5| Step: 2
Training loss: 2.5986651992356586
Validation loss: 2.466440951860749

Epoch: 5| Step: 3
Training loss: 2.005085796889241
Validation loss: 2.4670291427837503

Epoch: 5| Step: 4
Training loss: 2.533668398867524
Validation loss: 2.4636575914868777

Epoch: 5| Step: 5
Training loss: 2.2907052768936422
Validation loss: 2.46063665741076

Epoch: 5| Step: 6
Training loss: 3.23943710405985
Validation loss: 2.457277715195177

Epoch: 5| Step: 7
Training loss: 2.4820209602620555
Validation loss: 2.4657279482623835

Epoch: 5| Step: 8
Training loss: 2.7129084653109854
Validation loss: 2.4631147854888504

Epoch: 5| Step: 9
Training loss: 2.372529200222455
Validation loss: 2.462889999805021

Epoch: 5| Step: 10
Training loss: 2.5180930594290643
Validation loss: 2.46479240319665

Epoch: 5| Step: 11
Training loss: 2.0024938532321808
Validation loss: 2.4697116113755446

Epoch: 115| Step: 0
Training loss: 2.7662063246294415
Validation loss: 2.4573486276783827

Epoch: 5| Step: 1
Training loss: 2.629540830206325
Validation loss: 2.4624760979978575

Epoch: 5| Step: 2
Training loss: 2.722791890031649
Validation loss: 2.4678498127869006

Epoch: 5| Step: 3
Training loss: 2.220960241512365
Validation loss: 2.475054714131136

Epoch: 5| Step: 4
Training loss: 2.593741727149363
Validation loss: 2.467814723037943

Epoch: 5| Step: 5
Training loss: 2.5046163852279055
Validation loss: 2.4707620043266267

Epoch: 5| Step: 6
Training loss: 2.7147050780961934
Validation loss: 2.4734663798770233

Epoch: 5| Step: 7
Training loss: 2.3753663834506544
Validation loss: 2.4641709152460693

Epoch: 5| Step: 8
Training loss: 2.4916679773571775
Validation loss: 2.461511379520035

Epoch: 5| Step: 9
Training loss: 2.4015546293508185
Validation loss: 2.457836809500898

Epoch: 5| Step: 10
Training loss: 2.660467681355821
Validation loss: 2.458950495972576

Epoch: 5| Step: 11
Training loss: 3.5238954369125324
Validation loss: 2.4608468659680454

Epoch: 116| Step: 0
Training loss: 2.4039252805158022
Validation loss: 2.4629015638696905

Epoch: 5| Step: 1
Training loss: 2.735231189196941
Validation loss: 2.465621619953503

Epoch: 5| Step: 2
Training loss: 2.811315668610378
Validation loss: 2.4638708000947886

Epoch: 5| Step: 3
Training loss: 2.186668237863922
Validation loss: 2.463410143469872

Epoch: 5| Step: 4
Training loss: 2.654791218222916
Validation loss: 2.467930001677897

Epoch: 5| Step: 5
Training loss: 2.199804739523217
Validation loss: 2.46410057402912

Epoch: 5| Step: 6
Training loss: 2.62695911506055
Validation loss: 2.463607060705012

Epoch: 5| Step: 7
Training loss: 2.1795408138016366
Validation loss: 2.4675871870985526

Epoch: 5| Step: 8
Training loss: 2.942289465516464
Validation loss: 2.4597259526362376

Epoch: 5| Step: 9
Training loss: 2.478519665148894
Validation loss: 2.4626600463610737

Epoch: 5| Step: 10
Training loss: 2.1571857799096
Validation loss: 2.467367662451592

Epoch: 5| Step: 11
Training loss: 4.752015338808729
Validation loss: 2.4668886877891034

Epoch: 117| Step: 0
Training loss: 2.3319280911477387
Validation loss: 2.4621714631812464

Epoch: 5| Step: 1
Training loss: 2.851218508521822
Validation loss: 2.458357307080114

Epoch: 5| Step: 2
Training loss: 2.460068322140092
Validation loss: 2.456625047188398

Epoch: 5| Step: 3
Training loss: 2.5423983682820466
Validation loss: 2.4542394281318756

Epoch: 5| Step: 4
Training loss: 2.6547720892835263
Validation loss: 2.451195616182855

Epoch: 5| Step: 5
Training loss: 2.2578544216818
Validation loss: 2.4591771646863942

Epoch: 5| Step: 6
Training loss: 2.477403179166846
Validation loss: 2.458798630506136

Epoch: 5| Step: 7
Training loss: 2.8396938027275955
Validation loss: 2.4647105161323273

Epoch: 5| Step: 8
Training loss: 2.590867796634215
Validation loss: 2.4703509998317372

Epoch: 5| Step: 9
Training loss: 2.6782654305922184
Validation loss: 2.4728062580681796

Epoch: 5| Step: 10
Training loss: 2.6926605889362834
Validation loss: 2.4579013159294574

Epoch: 5| Step: 11
Training loss: 2.670636520235911
Validation loss: 2.4535957419304704

Epoch: 118| Step: 0
Training loss: 2.4362771316826044
Validation loss: 2.461931956154422

Epoch: 5| Step: 1
Training loss: 2.7165004148884933
Validation loss: 2.4612551569912884

Epoch: 5| Step: 2
Training loss: 2.590730587196081
Validation loss: 2.4735339004774666

Epoch: 5| Step: 3
Training loss: 2.43990422545528
Validation loss: 2.473800302109397

Epoch: 5| Step: 4
Training loss: 2.8288492360831605
Validation loss: 2.4757424169038615

Epoch: 5| Step: 5
Training loss: 2.8711754612097002
Validation loss: 2.474301835690578

Epoch: 5| Step: 6
Training loss: 2.311232967200476
Validation loss: 2.4733359681699794

Epoch: 5| Step: 7
Training loss: 2.3868148459710388
Validation loss: 2.476082278924149

Epoch: 5| Step: 8
Training loss: 2.1516732557901577
Validation loss: 2.4733304736175694

Epoch: 5| Step: 9
Training loss: 2.559275761917248
Validation loss: 2.47359458792402

Epoch: 5| Step: 10
Training loss: 2.7720947453764544
Validation loss: 2.4740833384738186

Epoch: 5| Step: 11
Training loss: 3.2701134021005536
Validation loss: 2.472797849757904

Epoch: 119| Step: 0
Training loss: 2.5027105895618416
Validation loss: 2.4723200918558534

Epoch: 5| Step: 1
Training loss: 2.50795453106124
Validation loss: 2.472736463807508

Epoch: 5| Step: 2
Training loss: 2.766231836672181
Validation loss: 2.4755049853409847

Epoch: 5| Step: 3
Training loss: 2.5864481349769104
Validation loss: 2.4726743391117565

Epoch: 5| Step: 4
Training loss: 2.7532955710043656
Validation loss: 2.4773382341814103

Epoch: 5| Step: 5
Training loss: 2.4676867742684965
Validation loss: 2.4764136160333146

Epoch: 5| Step: 6
Training loss: 2.68310729036278
Validation loss: 2.4778958530962014

Epoch: 5| Step: 7
Training loss: 2.9098290176235784
Validation loss: 2.473202573215031

Epoch: 5| Step: 8
Training loss: 2.5097620151360225
Validation loss: 2.472014626676018

Epoch: 5| Step: 9
Training loss: 2.5637689565388313
Validation loss: 2.4712078639393646

Epoch: 5| Step: 10
Training loss: 2.238477022620143
Validation loss: 2.4712520085167267

Epoch: 5| Step: 11
Training loss: 2.090710725723089
Validation loss: 2.471119865884908

Epoch: 120| Step: 0
Training loss: 2.8661956318799175
Validation loss: 2.4726595243298717

Epoch: 5| Step: 1
Training loss: 2.6360696177225633
Validation loss: 2.4667246232333664

Epoch: 5| Step: 2
Training loss: 2.5680724241139274
Validation loss: 2.4681279086735564

Epoch: 5| Step: 3
Training loss: 2.346762183839163
Validation loss: 2.4724436844852757

Epoch: 5| Step: 4
Training loss: 2.8001129331974575
Validation loss: 2.4671670208613126

Epoch: 5| Step: 5
Training loss: 2.0687923968716047
Validation loss: 2.4665882206591547

Epoch: 5| Step: 6
Training loss: 2.172819412507937
Validation loss: 2.465621728737792

Epoch: 5| Step: 7
Training loss: 1.9363545754392042
Validation loss: 2.4658369289127893

Epoch: 5| Step: 8
Training loss: 2.7664033473381235
Validation loss: 2.4692575802085632

Epoch: 5| Step: 9
Training loss: 2.6634534212267873
Validation loss: 2.466748093912789

Epoch: 5| Step: 10
Training loss: 2.988509744123759
Validation loss: 2.4651535814787495

Epoch: 5| Step: 11
Training loss: 3.357225875059924
Validation loss: 2.467684427298263

Epoch: 121| Step: 0
Training loss: 2.529414323708927
Validation loss: 2.4637388079250497

Epoch: 5| Step: 1
Training loss: 2.2029792250434186
Validation loss: 2.4582166132184846

Epoch: 5| Step: 2
Training loss: 2.680507523321016
Validation loss: 2.4614757574893136

Epoch: 5| Step: 3
Training loss: 2.7083513308196085
Validation loss: 2.457970367457621

Epoch: 5| Step: 4
Training loss: 2.4519570844544463
Validation loss: 2.4548245877959145

Epoch: 5| Step: 5
Training loss: 2.5561217968417127
Validation loss: 2.458490713518324

Epoch: 5| Step: 6
Training loss: 2.2636668194507825
Validation loss: 2.453819650350402

Epoch: 5| Step: 7
Training loss: 2.652912781116757
Validation loss: 2.4609329344691964

Epoch: 5| Step: 8
Training loss: 2.8377506565512984
Validation loss: 2.462956180854639

Epoch: 5| Step: 9
Training loss: 2.037366490582748
Validation loss: 2.459233799313978

Epoch: 5| Step: 10
Training loss: 2.9365883893922518
Validation loss: 2.4612111338111617

Epoch: 5| Step: 11
Training loss: 2.895943362846627
Validation loss: 2.458055162586287

Epoch: 122| Step: 0
Training loss: 2.5219950140435636
Validation loss: 2.4632308124024767

Epoch: 5| Step: 1
Training loss: 2.5316395400977463
Validation loss: 2.458627720895014

Epoch: 5| Step: 2
Training loss: 2.803925732204537
Validation loss: 2.4562508820070295

Epoch: 5| Step: 3
Training loss: 2.2998617047735683
Validation loss: 2.4523803771395722

Epoch: 5| Step: 4
Training loss: 2.3504418018685227
Validation loss: 2.457333762948483

Epoch: 5| Step: 5
Training loss: 2.8456491689076646
Validation loss: 2.4564340873502832

Epoch: 5| Step: 6
Training loss: 2.397140301242364
Validation loss: 2.4501117901372407

Epoch: 5| Step: 7
Training loss: 3.051493894838129
Validation loss: 2.4563576159469127

Epoch: 5| Step: 8
Training loss: 2.539349161251805
Validation loss: 2.457619213111599

Epoch: 5| Step: 9
Training loss: 2.0086939913923945
Validation loss: 2.4526419234810746

Epoch: 5| Step: 10
Training loss: 2.66477576409241
Validation loss: 2.453333455034785

Epoch: 5| Step: 11
Training loss: 2.1474388437145064
Validation loss: 2.4570071083261533

Epoch: 123| Step: 0
Training loss: 2.614503947923444
Validation loss: 2.4568900718216966

Epoch: 5| Step: 1
Training loss: 2.2416701301443958
Validation loss: 2.4616078467908107

Epoch: 5| Step: 2
Training loss: 2.6216418266049226
Validation loss: 2.460250851542669

Epoch: 5| Step: 3
Training loss: 2.228736966748087
Validation loss: 2.4647314466232197

Epoch: 5| Step: 4
Training loss: 2.666192866990627
Validation loss: 2.4606132253310706

Epoch: 5| Step: 5
Training loss: 2.4468914942471685
Validation loss: 2.4571741140422176

Epoch: 5| Step: 6
Training loss: 2.2155400011036765
Validation loss: 2.4598586124401756

Epoch: 5| Step: 7
Training loss: 2.218914401988515
Validation loss: 2.464115150000442

Epoch: 5| Step: 8
Training loss: 2.9148650099838624
Validation loss: 2.471458787917781

Epoch: 5| Step: 9
Training loss: 2.9193838995420376
Validation loss: 2.467256645633304

Epoch: 5| Step: 10
Training loss: 2.696084439956035
Validation loss: 2.462213752459119

Epoch: 5| Step: 11
Training loss: 3.207607352288094
Validation loss: 2.4680327769933585

Epoch: 124| Step: 0
Training loss: 2.404250664348259
Validation loss: 2.4569291910829305

Epoch: 5| Step: 1
Training loss: 2.3683252401658828
Validation loss: 2.457699080993029

Epoch: 5| Step: 2
Training loss: 2.733727078649138
Validation loss: 2.453768833980094

Epoch: 5| Step: 3
Training loss: 3.0253523250985173
Validation loss: 2.4678149766423694

Epoch: 5| Step: 4
Training loss: 2.7179192337038827
Validation loss: 2.4596865668699124

Epoch: 5| Step: 5
Training loss: 2.651345875691281
Validation loss: 2.4608541363518137

Epoch: 5| Step: 6
Training loss: 2.047517631929934
Validation loss: 2.4758308525248496

Epoch: 5| Step: 7
Training loss: 2.7352379009543015
Validation loss: 2.47021923126376

Epoch: 5| Step: 8
Training loss: 2.614123654833024
Validation loss: 2.4799920132082853

Epoch: 5| Step: 9
Training loss: 2.301728913194959
Validation loss: 2.47934846585468

Epoch: 5| Step: 10
Training loss: 2.4207043187161714
Validation loss: 2.4745690257921034

Epoch: 5| Step: 11
Training loss: 3.584405975074926
Validation loss: 2.4743744804662495

Epoch: 125| Step: 0
Training loss: 2.6874803941588183
Validation loss: 2.4653175108279193

Epoch: 5| Step: 1
Training loss: 2.471452995765511
Validation loss: 2.471282452801317

Epoch: 5| Step: 2
Training loss: 2.637754968549749
Validation loss: 2.4702130903509376

Epoch: 5| Step: 3
Training loss: 2.9443271921511913
Validation loss: 2.473606842904678

Epoch: 5| Step: 4
Training loss: 2.588627364174728
Validation loss: 2.4714504433554483

Epoch: 5| Step: 5
Training loss: 2.5600109572474112
Validation loss: 2.4746033634071622

Epoch: 5| Step: 6
Training loss: 2.4870563168900235
Validation loss: 2.4705200971879564

Epoch: 5| Step: 7
Training loss: 2.4394789267550623
Validation loss: 2.4708036500285333

Epoch: 5| Step: 8
Training loss: 2.3959111629504823
Validation loss: 2.4651121304757693

Epoch: 5| Step: 9
Training loss: 2.096164506819166
Validation loss: 2.4690748797696447

Epoch: 5| Step: 10
Training loss: 2.7808028300983176
Validation loss: 2.473206477442261

Epoch: 5| Step: 11
Training loss: 3.1927919029429472
Validation loss: 2.465031446916605

Epoch: 126| Step: 0
Training loss: 2.4075260494482658
Validation loss: 2.4662495557382154

Epoch: 5| Step: 1
Training loss: 2.5455236301707775
Validation loss: 2.46077145616775

Epoch: 5| Step: 2
Training loss: 2.3122243974744587
Validation loss: 2.4653897373464493

Epoch: 5| Step: 3
Training loss: 2.470364875407126
Validation loss: 2.4708714102426628

Epoch: 5| Step: 4
Training loss: 2.4415537064844486
Validation loss: 2.4732846169245284

Epoch: 5| Step: 5
Training loss: 2.249121388444496
Validation loss: 2.476250044148557

Epoch: 5| Step: 6
Training loss: 2.5837978950272817
Validation loss: 2.47911043597546

Epoch: 5| Step: 7
Training loss: 2.48608090354521
Validation loss: 2.4787546598192187

Epoch: 5| Step: 8
Training loss: 2.924469311166237
Validation loss: 2.4741348819312075

Epoch: 5| Step: 9
Training loss: 3.2564628604719723
Validation loss: 2.4768294462304348

Epoch: 5| Step: 10
Training loss: 2.4677916006454654
Validation loss: 2.4701062311978315

Epoch: 5| Step: 11
Training loss: 2.6432047324468444
Validation loss: 2.471488250911064

Epoch: 127| Step: 0
Training loss: 2.5963636351590975
Validation loss: 2.468458218775522

Epoch: 5| Step: 1
Training loss: 2.773054585417246
Validation loss: 2.464172807996947

Epoch: 5| Step: 2
Training loss: 2.106208515607669
Validation loss: 2.460965918321366

Epoch: 5| Step: 3
Training loss: 2.6709230746121473
Validation loss: 2.4599340461855257

Epoch: 5| Step: 4
Training loss: 2.5824104526944014
Validation loss: 2.458336490020234

Epoch: 5| Step: 5
Training loss: 2.52408820581848
Validation loss: 2.4582451963519674

Epoch: 5| Step: 6
Training loss: 2.8019977731416774
Validation loss: 2.462160970938165

Epoch: 5| Step: 7
Training loss: 2.531435830159069
Validation loss: 2.4612584707057215

Epoch: 5| Step: 8
Training loss: 2.4544692517342197
Validation loss: 2.4569814340365843

Epoch: 5| Step: 9
Training loss: 2.469507801266799
Validation loss: 2.4569104118936047

Epoch: 5| Step: 10
Training loss: 2.619179949369217
Validation loss: 2.460511274615681

Epoch: 5| Step: 11
Training loss: 2.692514044849881
Validation loss: 2.4688753949281668

Epoch: 128| Step: 0
Training loss: 2.5106682130353355
Validation loss: 2.455359338371319

Epoch: 5| Step: 1
Training loss: 2.213879356805162
Validation loss: 2.4496806721608992

Epoch: 5| Step: 2
Training loss: 2.9372308486027103
Validation loss: 2.452518444840926

Epoch: 5| Step: 3
Training loss: 2.693635369005922
Validation loss: 2.4525828319201377

Epoch: 5| Step: 4
Training loss: 1.8826659212790862
Validation loss: 2.460073616139756

Epoch: 5| Step: 5
Training loss: 2.069802390539389
Validation loss: 2.4628364542913617

Epoch: 5| Step: 6
Training loss: 2.7660189418075194
Validation loss: 2.4683303677564483

Epoch: 5| Step: 7
Training loss: 2.5068211007059964
Validation loss: 2.4679118033232443

Epoch: 5| Step: 8
Training loss: 2.595345247855554
Validation loss: 2.4727134838581453

Epoch: 5| Step: 9
Training loss: 2.8552063953198705
Validation loss: 2.472587391646342

Epoch: 5| Step: 10
Training loss: 2.9845833431039575
Validation loss: 2.4731725200991095

Epoch: 5| Step: 11
Training loss: 1.977902587632652
Validation loss: 2.47011314856871

Epoch: 129| Step: 0
Training loss: 2.343070783743384
Validation loss: 2.4673448982306154

Epoch: 5| Step: 1
Training loss: 2.6105369676136254
Validation loss: 2.4686025261591675

Epoch: 5| Step: 2
Training loss: 2.711227797210238
Validation loss: 2.4672047752756416

Epoch: 5| Step: 3
Training loss: 2.556404586631971
Validation loss: 2.4588139085814507

Epoch: 5| Step: 4
Training loss: 2.570922964585198
Validation loss: 2.4596491514232732

Epoch: 5| Step: 5
Training loss: 2.254075491912857
Validation loss: 2.4609456380073778

Epoch: 5| Step: 6
Training loss: 2.457438667129631
Validation loss: 2.4601325075843787

Epoch: 5| Step: 7
Training loss: 2.284481633694235
Validation loss: 2.4651223744108783

Epoch: 5| Step: 8
Training loss: 2.7112753709772948
Validation loss: 2.464864967524902

Epoch: 5| Step: 9
Training loss: 2.6137042651195546
Validation loss: 2.461822245770975

Epoch: 5| Step: 10
Training loss: 2.600028745785776
Validation loss: 2.4563539680368827

Epoch: 5| Step: 11
Training loss: 3.4663964612511804
Validation loss: 2.4558072258094756

Epoch: 130| Step: 0
Training loss: 2.773598593747971
Validation loss: 2.45723327307526

Epoch: 5| Step: 1
Training loss: 2.4138011605734313
Validation loss: 2.456733163967111

Epoch: 5| Step: 2
Training loss: 2.7443732872342745
Validation loss: 2.4577990061686

Epoch: 5| Step: 3
Training loss: 2.677389777984221
Validation loss: 2.4696055792813887

Epoch: 5| Step: 4
Training loss: 2.0351687850126807
Validation loss: 2.476638511991421

Epoch: 5| Step: 5
Training loss: 2.4064278474949075
Validation loss: 2.4704781772905817

Epoch: 5| Step: 6
Training loss: 2.720435748959179
Validation loss: 2.4622062036654633

Epoch: 5| Step: 7
Training loss: 2.4332604340733557
Validation loss: 2.4529269881625577

Epoch: 5| Step: 8
Training loss: 2.4679858799720584
Validation loss: 2.4560338367666645

Epoch: 5| Step: 9
Training loss: 2.2884094556616117
Validation loss: 2.447950408919431

Epoch: 5| Step: 10
Training loss: 2.923970985362575
Validation loss: 2.44699507605854

Epoch: 5| Step: 11
Training loss: 2.8761242865817245
Validation loss: 2.450327381493779

Epoch: 131| Step: 0
Training loss: 2.739989092310892
Validation loss: 2.461383843690554

Epoch: 5| Step: 1
Training loss: 2.313273532471929
Validation loss: 2.4669426728708412

Epoch: 5| Step: 2
Training loss: 2.7075570876988344
Validation loss: 2.470530704719243

Epoch: 5| Step: 3
Training loss: 2.5923791043115574
Validation loss: 2.476483505224642

Epoch: 5| Step: 4
Training loss: 2.3372752974109514
Validation loss: 2.4756009775440977

Epoch: 5| Step: 5
Training loss: 2.4400676017526743
Validation loss: 2.4699317220434964

Epoch: 5| Step: 6
Training loss: 2.694179838718443
Validation loss: 2.475560788961729

Epoch: 5| Step: 7
Training loss: 2.6204365618457937
Validation loss: 2.4775189619560853

Epoch: 5| Step: 8
Training loss: 2.6289151377194675
Validation loss: 2.4761380976182368

Epoch: 5| Step: 9
Training loss: 2.4690928160787355
Validation loss: 2.478183007573581

Epoch: 5| Step: 10
Training loss: 2.593431384268662
Validation loss: 2.4783822723418965

Epoch: 5| Step: 11
Training loss: 3.105117413301891
Validation loss: 2.4807071200799453

Epoch: 132| Step: 0
Training loss: 2.6304578807528074
Validation loss: 2.481837121986184

Epoch: 5| Step: 1
Training loss: 2.5796497806631122
Validation loss: 2.47141347531917

Epoch: 5| Step: 2
Training loss: 2.596804096158288
Validation loss: 2.4719912140377884

Epoch: 5| Step: 3
Training loss: 2.4600030971910782
Validation loss: 2.4766883858215714

Epoch: 5| Step: 4
Training loss: 2.6292556598512093
Validation loss: 2.4716214047898735

Epoch: 5| Step: 5
Training loss: 2.668107438287689
Validation loss: 2.47165519454036

Epoch: 5| Step: 6
Training loss: 2.747082463090796
Validation loss: 2.470064646129738

Epoch: 5| Step: 7
Training loss: 2.0945867887516125
Validation loss: 2.4668027103019794

Epoch: 5| Step: 8
Training loss: 2.971857151495348
Validation loss: 2.462613172076706

Epoch: 5| Step: 9
Training loss: 2.2530445058044233
Validation loss: 2.4631758869292915

Epoch: 5| Step: 10
Training loss: 2.6207671779254094
Validation loss: 2.4644172448576476

Epoch: 5| Step: 11
Training loss: 1.8399719711946985
Validation loss: 2.4680611659424923

Epoch: 133| Step: 0
Training loss: 2.107528104040387
Validation loss: 2.4512199934128356

Epoch: 5| Step: 1
Training loss: 2.747452249294262
Validation loss: 2.451302395976656

Epoch: 5| Step: 2
Training loss: 2.6187362415616913
Validation loss: 2.451303743460275

Epoch: 5| Step: 3
Training loss: 2.4485064722606205
Validation loss: 2.4483873009581973

Epoch: 5| Step: 4
Training loss: 2.3051616633523673
Validation loss: 2.4499384843148992

Epoch: 5| Step: 5
Training loss: 2.492987047090632
Validation loss: 2.453804816872419

Epoch: 5| Step: 6
Training loss: 2.4089334560782265
Validation loss: 2.445275023054373

Epoch: 5| Step: 7
Training loss: 2.6765434126387695
Validation loss: 2.4482404447391346

Epoch: 5| Step: 8
Training loss: 2.7628780883004134
Validation loss: 2.4565838748642674

Epoch: 5| Step: 9
Training loss: 2.6232068431303133
Validation loss: 2.447369596886366

Epoch: 5| Step: 10
Training loss: 2.972134718592249
Validation loss: 2.4572147731439062

Epoch: 5| Step: 11
Training loss: 1.69200853016013
Validation loss: 2.448678840861222

Epoch: 134| Step: 0
Training loss: 2.7362652158074505
Validation loss: 2.453292022980102

Epoch: 5| Step: 1
Training loss: 2.5301938149318492
Validation loss: 2.444809196603279

Epoch: 5| Step: 2
Training loss: 2.6491761204431965
Validation loss: 2.4506016770965062

Epoch: 5| Step: 3
Training loss: 2.207226337824075
Validation loss: 2.4491723080033934

Epoch: 5| Step: 4
Training loss: 2.941083305229687
Validation loss: 2.4499336793253197

Epoch: 5| Step: 5
Training loss: 2.811526490316161
Validation loss: 2.4530579179148555

Epoch: 5| Step: 6
Training loss: 2.4127691563494125
Validation loss: 2.4500371730670225

Epoch: 5| Step: 7
Training loss: 2.2610984043740103
Validation loss: 2.451287336530386

Epoch: 5| Step: 8
Training loss: 2.784427927458211
Validation loss: 2.4553210235184935

Epoch: 5| Step: 9
Training loss: 2.136814596477771
Validation loss: 2.4584963240713336

Epoch: 5| Step: 10
Training loss: 2.5059466209297963
Validation loss: 2.451743925702506

Epoch: 5| Step: 11
Training loss: 1.5678804457298556
Validation loss: 2.4514038442246155

Epoch: 135| Step: 0
Training loss: 2.753887982679884
Validation loss: 2.462457911782021

Epoch: 5| Step: 1
Training loss: 2.5588063857849974
Validation loss: 2.4644604569795305

Epoch: 5| Step: 2
Training loss: 2.767862998499148
Validation loss: 2.4597030651886143

Epoch: 5| Step: 3
Training loss: 2.3694395928620784
Validation loss: 2.4647380002123667

Epoch: 5| Step: 4
Training loss: 2.316369710958918
Validation loss: 2.4669192040426755

Epoch: 5| Step: 5
Training loss: 1.6989171955391422
Validation loss: 2.4637022685203447

Epoch: 5| Step: 6
Training loss: 2.917188506900101
Validation loss: 2.459553905864408

Epoch: 5| Step: 7
Training loss: 2.663945975789725
Validation loss: 2.457347790857521

Epoch: 5| Step: 8
Training loss: 2.547318589599213
Validation loss: 2.4618048981015703

Epoch: 5| Step: 9
Training loss: 2.470377518379122
Validation loss: 2.4591887138935644

Epoch: 5| Step: 10
Training loss: 2.4276199620754757
Validation loss: 2.464857279744928

Epoch: 5| Step: 11
Training loss: 3.3678009111725893
Validation loss: 2.4617410145274023

Epoch: 136| Step: 0
Training loss: 2.7501685350966305
Validation loss: 2.448433834934149

Epoch: 5| Step: 1
Training loss: 2.9571891147899763
Validation loss: 2.4545924946356013

Epoch: 5| Step: 2
Training loss: 1.8467839381558273
Validation loss: 2.456658012048374

Epoch: 5| Step: 3
Training loss: 2.4285381579323992
Validation loss: 2.460401668443653

Epoch: 5| Step: 4
Training loss: 2.9773640191762825
Validation loss: 2.466916054982511

Epoch: 5| Step: 5
Training loss: 1.9532321137620392
Validation loss: 2.4541721862597052

Epoch: 5| Step: 6
Training loss: 2.773505583451302
Validation loss: 2.4613921578049345

Epoch: 5| Step: 7
Training loss: 2.4084983329173237
Validation loss: 2.4552260794070406

Epoch: 5| Step: 8
Training loss: 2.8967230731255498
Validation loss: 2.4481121343664647

Epoch: 5| Step: 9
Training loss: 2.5149309610708275
Validation loss: 2.4530329798388886

Epoch: 5| Step: 10
Training loss: 2.3224777240321357
Validation loss: 2.444037498089684

Epoch: 5| Step: 11
Training loss: 1.9953445252766229
Validation loss: 2.4502779481833437

Epoch: 137| Step: 0
Training loss: 2.946167515671081
Validation loss: 2.448567508182587

Epoch: 5| Step: 1
Training loss: 2.689433533397006
Validation loss: 2.453291043050088

Epoch: 5| Step: 2
Training loss: 2.052417618170391
Validation loss: 2.4509362622991184

Epoch: 5| Step: 3
Training loss: 2.5941826333170264
Validation loss: 2.4551577316160267

Epoch: 5| Step: 4
Training loss: 2.9363482226056594
Validation loss: 2.4531565459666993

Epoch: 5| Step: 5
Training loss: 2.243635925963463
Validation loss: 2.4535235852599926

Epoch: 5| Step: 6
Training loss: 1.9411740691889225
Validation loss: 2.453490535771989

Epoch: 5| Step: 7
Training loss: 2.088903825393104
Validation loss: 2.4524269994026144

Epoch: 5| Step: 8
Training loss: 2.6120448359369846
Validation loss: 2.4435087870312415

Epoch: 5| Step: 9
Training loss: 2.830176183924892
Validation loss: 2.4495069748921345

Epoch: 5| Step: 10
Training loss: 2.6140338173322735
Validation loss: 2.4429174237480815

Epoch: 5| Step: 11
Training loss: 2.8972399106272584
Validation loss: 2.4456971407333086

Epoch: 138| Step: 0
Training loss: 2.684543580345033
Validation loss: 2.448411580370318

Epoch: 5| Step: 1
Training loss: 2.1516371326896744
Validation loss: 2.4503205055677197

Epoch: 5| Step: 2
Training loss: 2.405318736409868
Validation loss: 2.4521314548728266

Epoch: 5| Step: 3
Training loss: 2.522603845037223
Validation loss: 2.453202669570385

Epoch: 5| Step: 4
Training loss: 2.3260150539471933
Validation loss: 2.453456710450632

Epoch: 5| Step: 5
Training loss: 3.001835261694834
Validation loss: 2.4528591757101608

Epoch: 5| Step: 6
Training loss: 2.188866760520727
Validation loss: 2.451122175019309

Epoch: 5| Step: 7
Training loss: 2.397151142312594
Validation loss: 2.4544059988612092

Epoch: 5| Step: 8
Training loss: 2.7599879861653123
Validation loss: 2.4546141650121394

Epoch: 5| Step: 9
Training loss: 2.0576329459232823
Validation loss: 2.4557852160522153

Epoch: 5| Step: 10
Training loss: 2.8980859095948293
Validation loss: 2.4522425204202607

Epoch: 5| Step: 11
Training loss: 3.391647676856814
Validation loss: 2.451735878708042

Epoch: 139| Step: 0
Training loss: 2.8402042291306073
Validation loss: 2.4478706247314994

Epoch: 5| Step: 1
Training loss: 2.2767555170701304
Validation loss: 2.443496246935925

Epoch: 5| Step: 2
Training loss: 2.3497254556217575
Validation loss: 2.4511448467329875

Epoch: 5| Step: 3
Training loss: 2.3966775705923338
Validation loss: 2.445328136552536

Epoch: 5| Step: 4
Training loss: 2.135685812263216
Validation loss: 2.449851113129162

Epoch: 5| Step: 5
Training loss: 3.366108520118427
Validation loss: 2.4419483162872595

Epoch: 5| Step: 6
Training loss: 2.69529595853733
Validation loss: 2.4492808876084866

Epoch: 5| Step: 7
Training loss: 2.2778342816340706
Validation loss: 2.4455684044523185

Epoch: 5| Step: 8
Training loss: 2.036634965994322
Validation loss: 2.4479865463238797

Epoch: 5| Step: 9
Training loss: 2.1873744383606915
Validation loss: 2.4509954097699116

Epoch: 5| Step: 10
Training loss: 2.751215146098329
Validation loss: 2.441485496760721

Epoch: 5| Step: 11
Training loss: 3.3470300291256936
Validation loss: 2.4461874285287704

Epoch: 140| Step: 0
Training loss: 2.615799265243995
Validation loss: 2.4497489416176794

Epoch: 5| Step: 1
Training loss: 2.4837487349101406
Validation loss: 2.4472178205614585

Epoch: 5| Step: 2
Training loss: 2.237151654794617
Validation loss: 2.444829793621107

Epoch: 5| Step: 3
Training loss: 2.5936145057677344
Validation loss: 2.4528028070047134

Epoch: 5| Step: 4
Training loss: 2.532716867664147
Validation loss: 2.450074483913497

Epoch: 5| Step: 5
Training loss: 2.579586470235467
Validation loss: 2.4452390954290903

Epoch: 5| Step: 6
Training loss: 2.2204993430439237
Validation loss: 2.4451838653498177

Epoch: 5| Step: 7
Training loss: 2.5274732695089526
Validation loss: 2.44631510077938

Epoch: 5| Step: 8
Training loss: 2.430300227484092
Validation loss: 2.443584465313143

Epoch: 5| Step: 9
Training loss: 3.2497718437511867
Validation loss: 2.4504725194391765

Epoch: 5| Step: 10
Training loss: 2.2016455911479023
Validation loss: 2.45313798289498

Epoch: 5| Step: 11
Training loss: 2.2931885492102486
Validation loss: 2.4527577046273437

Epoch: 141| Step: 0
Training loss: 2.6553380859406532
Validation loss: 2.4503933342666766

Epoch: 5| Step: 1
Training loss: 2.6237763777266085
Validation loss: 2.4532871516712524

Epoch: 5| Step: 2
Training loss: 2.5675213625129683
Validation loss: 2.4565640941912816

Epoch: 5| Step: 3
Training loss: 2.9586012992027233
Validation loss: 2.4594746031055137

Epoch: 5| Step: 4
Training loss: 2.2955459590258696
Validation loss: 2.461407353188989

Epoch: 5| Step: 5
Training loss: 2.758270571437394
Validation loss: 2.4635160954272655

Epoch: 5| Step: 6
Training loss: 2.804936389983821
Validation loss: 2.4635578837811924

Epoch: 5| Step: 7
Training loss: 2.657946504851094
Validation loss: 2.4649683502188817

Epoch: 5| Step: 8
Training loss: 1.8943541768489256
Validation loss: 2.460668107077398

Epoch: 5| Step: 9
Training loss: 1.860994034812423
Validation loss: 2.463453179693078

Epoch: 5| Step: 10
Training loss: 2.754236339509246
Validation loss: 2.467242070102501

Epoch: 5| Step: 11
Training loss: 2.0128943110320656
Validation loss: 2.4656615474943115

Epoch: 142| Step: 0
Training loss: 2.7732653067419224
Validation loss: 2.4626693162300586

Epoch: 5| Step: 1
Training loss: 2.47794916941039
Validation loss: 2.4565625453758586

Epoch: 5| Step: 2
Training loss: 2.288534682941387
Validation loss: 2.4520282642486744

Epoch: 5| Step: 3
Training loss: 2.3499246260547224
Validation loss: 2.456597197360041

Epoch: 5| Step: 4
Training loss: 2.8666304793032893
Validation loss: 2.466890862356481

Epoch: 5| Step: 5
Training loss: 2.633798114787929
Validation loss: 2.4707139569071477

Epoch: 5| Step: 6
Training loss: 2.517544316315611
Validation loss: 2.488294792038634

Epoch: 5| Step: 7
Training loss: 2.657887122594076
Validation loss: 2.485067407018733

Epoch: 5| Step: 8
Training loss: 2.742505177412127
Validation loss: 2.4841297236509483

Epoch: 5| Step: 9
Training loss: 2.583836742286752
Validation loss: 2.4723800778146456

Epoch: 5| Step: 10
Training loss: 1.9022453642984316
Validation loss: 2.469193491153274

Epoch: 5| Step: 11
Training loss: 2.348001108848401
Validation loss: 2.4573967464198945

Epoch: 143| Step: 0
Training loss: 2.480696059497357
Validation loss: 2.4455305130271094

Epoch: 5| Step: 1
Training loss: 2.4928477976120655
Validation loss: 2.4490216797997983

Epoch: 5| Step: 2
Training loss: 2.656025686329417
Validation loss: 2.451611041562398

Epoch: 5| Step: 3
Training loss: 2.6360124560396136
Validation loss: 2.4625701776499738

Epoch: 5| Step: 4
Training loss: 2.435971489963409
Validation loss: 2.464336183806469

Epoch: 5| Step: 5
Training loss: 2.562400257681537
Validation loss: 2.4708476993042376

Epoch: 5| Step: 6
Training loss: 2.6386926566886113
Validation loss: 2.473777619169625

Epoch: 5| Step: 7
Training loss: 3.092569453477959
Validation loss: 2.4706015102312993

Epoch: 5| Step: 8
Training loss: 2.2054303600011815
Validation loss: 2.477943432519411

Epoch: 5| Step: 9
Training loss: 2.250657091619062
Validation loss: 2.4730432136270335

Epoch: 5| Step: 10
Training loss: 2.685535245003227
Validation loss: 2.4739607252142872

Epoch: 5| Step: 11
Training loss: 1.8089166933766354
Validation loss: 2.473534205705594

Epoch: 144| Step: 0
Training loss: 2.442587409588243
Validation loss: 2.472199581134241

Epoch: 5| Step: 1
Training loss: 2.9427840411594652
Validation loss: 2.4636562769698327

Epoch: 5| Step: 2
Training loss: 2.1827303522117223
Validation loss: 2.46391931560064

Epoch: 5| Step: 3
Training loss: 2.1530669670976628
Validation loss: 2.461639643214962

Epoch: 5| Step: 4
Training loss: 2.406082642915616
Validation loss: 2.464086044334501

Epoch: 5| Step: 5
Training loss: 2.8533241160710325
Validation loss: 2.461574524472386

Epoch: 5| Step: 6
Training loss: 2.302826935361421
Validation loss: 2.456747235741559

Epoch: 5| Step: 7
Training loss: 3.0704924940779392
Validation loss: 2.4539639360622063

Epoch: 5| Step: 8
Training loss: 2.258771857539588
Validation loss: 2.4441876734149397

Epoch: 5| Step: 9
Training loss: 2.641690372236329
Validation loss: 2.450742769613123

Epoch: 5| Step: 10
Training loss: 2.397705960620733
Validation loss: 2.444724214292693

Epoch: 5| Step: 11
Training loss: 2.198311925363985
Validation loss: 2.450430465367067

Epoch: 145| Step: 0
Training loss: 2.902736057141889
Validation loss: 2.4378546350837276

Epoch: 5| Step: 1
Training loss: 2.808544004633781
Validation loss: 2.439471266887511

Epoch: 5| Step: 2
Training loss: 3.1158196452566984
Validation loss: 2.442752611345954

Epoch: 5| Step: 3
Training loss: 2.143511086544039
Validation loss: 2.4455792501960163

Epoch: 5| Step: 4
Training loss: 2.228696957832602
Validation loss: 2.4395560270117422

Epoch: 5| Step: 5
Training loss: 2.303843819026859
Validation loss: 2.4381435290612608

Epoch: 5| Step: 6
Training loss: 2.7896558627290386
Validation loss: 2.440654085387327

Epoch: 5| Step: 7
Training loss: 2.225400065769809
Validation loss: 2.4405661599868878

Epoch: 5| Step: 8
Training loss: 2.484771696844
Validation loss: 2.4448486432551326

Epoch: 5| Step: 9
Training loss: 1.909992484032987
Validation loss: 2.44852389791998

Epoch: 5| Step: 10
Training loss: 2.5727634049662145
Validation loss: 2.443969491823613

Epoch: 5| Step: 11
Training loss: 2.0049354929071894
Validation loss: 2.444905621983057

Epoch: 146| Step: 0
Training loss: 2.0454730408728197
Validation loss: 2.451893967328142

Epoch: 5| Step: 1
Training loss: 2.3385029359823135
Validation loss: 2.459960917308404

Epoch: 5| Step: 2
Training loss: 2.1703970291890706
Validation loss: 2.4617616635779704

Epoch: 5| Step: 3
Training loss: 2.5289641054622165
Validation loss: 2.464081934157006

Epoch: 5| Step: 4
Training loss: 2.807829475669938
Validation loss: 2.4615764938795497

Epoch: 5| Step: 5
Training loss: 2.776620075785949
Validation loss: 2.4599260502131237

Epoch: 5| Step: 6
Training loss: 2.7863955101465483
Validation loss: 2.4615574736989982

Epoch: 5| Step: 7
Training loss: 2.1040693455716046
Validation loss: 2.4585129839238995

Epoch: 5| Step: 8
Training loss: 2.568814568740651
Validation loss: 2.4575536887098393

Epoch: 5| Step: 9
Training loss: 2.6469117217235745
Validation loss: 2.4463220691801886

Epoch: 5| Step: 10
Training loss: 2.692074276164428
Validation loss: 2.4448693902807714

Epoch: 5| Step: 11
Training loss: 3.236928328188787
Validation loss: 2.4427276331309242

Epoch: 147| Step: 0
Training loss: 2.433796832824798
Validation loss: 2.450393853189742

Epoch: 5| Step: 1
Training loss: 2.3551749936668096
Validation loss: 2.4534836180984625

Epoch: 5| Step: 2
Training loss: 2.8581305125116825
Validation loss: 2.4548292092014927

Epoch: 5| Step: 3
Training loss: 1.9607588850036737
Validation loss: 2.457974356503315

Epoch: 5| Step: 4
Training loss: 2.9423551004233506
Validation loss: 2.453131665587228

Epoch: 5| Step: 5
Training loss: 2.8359253938274662
Validation loss: 2.4596394642678288

Epoch: 5| Step: 6
Training loss: 2.5552745459575386
Validation loss: 2.4581987874879694

Epoch: 5| Step: 7
Training loss: 2.3664490205684685
Validation loss: 2.4567443000849227

Epoch: 5| Step: 8
Training loss: 2.446042083028876
Validation loss: 2.455199304147873

Epoch: 5| Step: 9
Training loss: 2.225308677606845
Validation loss: 2.4499703227081704

Epoch: 5| Step: 10
Training loss: 2.5637394768449187
Validation loss: 2.453033907225596

Epoch: 5| Step: 11
Training loss: 2.698892797285174
Validation loss: 2.451212345918904

Epoch: 148| Step: 0
Training loss: 2.6955108127338203
Validation loss: 2.4508701822709518

Epoch: 5| Step: 1
Training loss: 2.5109014293688614
Validation loss: 2.451346730838413

Epoch: 5| Step: 2
Training loss: 2.0387578860936704
Validation loss: 2.450007987333759

Epoch: 5| Step: 3
Training loss: 2.077427453014974
Validation loss: 2.446504393825643

Epoch: 5| Step: 4
Training loss: 2.53765135064717
Validation loss: 2.449387012727051

Epoch: 5| Step: 5
Training loss: 2.486973776819803
Validation loss: 2.451850458774793

Epoch: 5| Step: 6
Training loss: 2.57042584850518
Validation loss: 2.449955105045838

Epoch: 5| Step: 7
Training loss: 2.3424182414277426
Validation loss: 2.4529805434471768

Epoch: 5| Step: 8
Training loss: 2.8044669827023943
Validation loss: 2.446741001719739

Epoch: 5| Step: 9
Training loss: 2.588205777538004
Validation loss: 2.446601592891057

Epoch: 5| Step: 10
Training loss: 2.5010677918310646
Validation loss: 2.450403169461705

Epoch: 5| Step: 11
Training loss: 4.051757930186489
Validation loss: 2.447107588528014

Epoch: 149| Step: 0
Training loss: 2.7118092655075645
Validation loss: 2.4433270520116084

Epoch: 5| Step: 1
Training loss: 1.9378872146068937
Validation loss: 2.4439842305366635

Epoch: 5| Step: 2
Training loss: 2.776322189003964
Validation loss: 2.4530080172107995

Epoch: 5| Step: 3
Training loss: 2.9821508617962653
Validation loss: 2.447873526389191

Epoch: 5| Step: 4
Training loss: 1.8971446466232305
Validation loss: 2.453735757431124

Epoch: 5| Step: 5
Training loss: 2.6560771212698815
Validation loss: 2.4517020048667257

Epoch: 5| Step: 6
Training loss: 2.660679881896626
Validation loss: 2.450249093718423

Epoch: 5| Step: 7
Training loss: 2.9663635299053848
Validation loss: 2.447330168542458

Epoch: 5| Step: 8
Training loss: 2.6417402812756974
Validation loss: 2.4485473280348176

Epoch: 5| Step: 9
Training loss: 1.9324658119168099
Validation loss: 2.453346623090152

Epoch: 5| Step: 10
Training loss: 2.384627354617875
Validation loss: 2.448584982092548

Epoch: 5| Step: 11
Training loss: 1.4187762690729537
Validation loss: 2.443497862983593

Epoch: 150| Step: 0
Training loss: 2.7792183817370324
Validation loss: 2.4481137757721276

Epoch: 5| Step: 1
Training loss: 1.822360151809582
Validation loss: 2.4463490492114985

Epoch: 5| Step: 2
Training loss: 2.5655226209613806
Validation loss: 2.4552346935537637

Epoch: 5| Step: 3
Training loss: 2.8162694466601392
Validation loss: 2.4500372419965175

Epoch: 5| Step: 4
Training loss: 2.3861753653698834
Validation loss: 2.44907411982814

Epoch: 5| Step: 5
Training loss: 2.500150771363023
Validation loss: 2.4573327725023106

Epoch: 5| Step: 6
Training loss: 2.567000182475376
Validation loss: 2.456586008005116

Epoch: 5| Step: 7
Training loss: 2.228631808088305
Validation loss: 2.4526079244389765

Epoch: 5| Step: 8
Training loss: 2.2473221844525146
Validation loss: 2.441943723389942

Epoch: 5| Step: 9
Training loss: 2.7263820118449504
Validation loss: 2.459103335734194

Epoch: 5| Step: 10
Training loss: 2.6955745846026975
Validation loss: 2.45154772710067

Epoch: 5| Step: 11
Training loss: 3.3432238869012014
Validation loss: 2.45438701620545

Epoch: 151| Step: 0
Training loss: 2.590821600840709
Validation loss: 2.453182106406264

Epoch: 5| Step: 1
Training loss: 2.3183723327223182
Validation loss: 2.4561958328046574

Epoch: 5| Step: 2
Training loss: 2.2627617995397347
Validation loss: 2.455842709604863

Epoch: 5| Step: 3
Training loss: 2.276985676850649
Validation loss: 2.4535604442771772

Epoch: 5| Step: 4
Training loss: 2.2460858950270257
Validation loss: 2.449159851663961

Epoch: 5| Step: 5
Training loss: 2.4639690799940546
Validation loss: 2.45443509991835

Epoch: 5| Step: 6
Training loss: 2.494750041786971
Validation loss: 2.4473038305338215

Epoch: 5| Step: 7
Training loss: 2.8176795737067457
Validation loss: 2.451058600697273

Epoch: 5| Step: 8
Training loss: 2.8812810867188214
Validation loss: 2.4503828706461035

Epoch: 5| Step: 9
Training loss: 3.1267332229633866
Validation loss: 2.448369914901017

Epoch: 5| Step: 10
Training loss: 1.7448473413798868
Validation loss: 2.4509926293479007

Epoch: 5| Step: 11
Training loss: 2.999121060361617
Validation loss: 2.453667392418717

Epoch: 152| Step: 0
Training loss: 2.9017338272318436
Validation loss: 2.4594151263778654

Epoch: 5| Step: 1
Training loss: 2.730923637951234
Validation loss: 2.4655677469662787

Epoch: 5| Step: 2
Training loss: 2.509836206297173
Validation loss: 2.453444992544411

Epoch: 5| Step: 3
Training loss: 1.9168942426941424
Validation loss: 2.471087932147658

Epoch: 5| Step: 4
Training loss: 2.708932448414098
Validation loss: 2.460135802620819

Epoch: 5| Step: 5
Training loss: 2.7141440827840766
Validation loss: 2.4606295922827313

Epoch: 5| Step: 6
Training loss: 2.042115013044433
Validation loss: 2.4525047619637634

Epoch: 5| Step: 7
Training loss: 2.28769953123277
Validation loss: 2.457110849939825

Epoch: 5| Step: 8
Training loss: 2.5871272274681774
Validation loss: 2.4518300625451657

Epoch: 5| Step: 9
Training loss: 2.7325305930725894
Validation loss: 2.4611370268170765

Epoch: 5| Step: 10
Training loss: 2.424957086242391
Validation loss: 2.4546132969056735

Epoch: 5| Step: 11
Training loss: 1.6389911326970907
Validation loss: 2.4525490143324338

Epoch: 153| Step: 0
Training loss: 2.4350641257049404
Validation loss: 2.4587888632351635

Epoch: 5| Step: 1
Training loss: 2.9519534739107574
Validation loss: 2.463310695947672

Epoch: 5| Step: 2
Training loss: 2.0040132073901824
Validation loss: 2.460068011203068

Epoch: 5| Step: 3
Training loss: 2.334658473522044
Validation loss: 2.458976796092826

Epoch: 5| Step: 4
Training loss: 1.9480105154783705
Validation loss: 2.4535414348350724

Epoch: 5| Step: 5
Training loss: 2.9045835249638134
Validation loss: 2.453970040722181

Epoch: 5| Step: 6
Training loss: 2.478670877414442
Validation loss: 2.449129215532595

Epoch: 5| Step: 7
Training loss: 2.978804417352025
Validation loss: 2.4564556666651365

Epoch: 5| Step: 8
Training loss: 2.429947621444266
Validation loss: 2.4561729690858485

Epoch: 5| Step: 9
Training loss: 2.569553529869536
Validation loss: 2.4512627776009217

Epoch: 5| Step: 10
Training loss: 2.2794752141094894
Validation loss: 2.4611138093956058

Epoch: 5| Step: 11
Training loss: 1.8209920768879653
Validation loss: 2.4624035076496904

Epoch: 154| Step: 0
Training loss: 2.727662135269346
Validation loss: 2.4530745499074142

Epoch: 5| Step: 1
Training loss: 2.1765666756244157
Validation loss: 2.4510936506740713

Epoch: 5| Step: 2
Training loss: 2.2314692456320477
Validation loss: 2.460071370936103

Epoch: 5| Step: 3
Training loss: 2.434396773548226
Validation loss: 2.462399733546614

Epoch: 5| Step: 4
Training loss: 2.557247360891945
Validation loss: 2.449061829297242

Epoch: 5| Step: 5
Training loss: 2.715869473777448
Validation loss: 2.4635761344600695

Epoch: 5| Step: 6
Training loss: 2.6169793345094945
Validation loss: 2.4587319476562746

Epoch: 5| Step: 7
Training loss: 3.0314392345390395
Validation loss: 2.4656382800100363

Epoch: 5| Step: 8
Training loss: 2.617036638609071
Validation loss: 2.4660353402531445

Epoch: 5| Step: 9
Training loss: 2.1222401817365184
Validation loss: 2.4674200990798094

Epoch: 5| Step: 10
Training loss: 2.197886630993554
Validation loss: 2.4557771418481025

Epoch: 5| Step: 11
Training loss: 2.468643958796062
Validation loss: 2.4616757632769537

Epoch: 155| Step: 0
Training loss: 2.469898680952549
Validation loss: 2.4580835940238273

Epoch: 5| Step: 1
Training loss: 2.346709252408175
Validation loss: 2.4692713794548067

Epoch: 5| Step: 2
Training loss: 3.1189567115179324
Validation loss: 2.46583461845453

Epoch: 5| Step: 3
Training loss: 2.85883797360504
Validation loss: 2.4610050535265104

Epoch: 5| Step: 4
Training loss: 2.315005620368743
Validation loss: 2.4606913246670947

Epoch: 5| Step: 5
Training loss: 2.5336319818473436
Validation loss: 2.467202921088972

Epoch: 5| Step: 6
Training loss: 2.8561543321343343
Validation loss: 2.4644187887366216

Epoch: 5| Step: 7
Training loss: 2.2558887562345293
Validation loss: 2.466142484561267

Epoch: 5| Step: 8
Training loss: 2.016002057907023
Validation loss: 2.4802186814858245

Epoch: 5| Step: 9
Training loss: 2.1531571030126684
Validation loss: 2.4700853382071273

Epoch: 5| Step: 10
Training loss: 2.4918499661219795
Validation loss: 2.4720176768128703

Epoch: 5| Step: 11
Training loss: 1.7067747992790676
Validation loss: 2.4637402554581724

Epoch: 156| Step: 0
Training loss: 2.636539074462621
Validation loss: 2.4584659295502944

Epoch: 5| Step: 1
Training loss: 2.498923833009152
Validation loss: 2.4776876122118665

Epoch: 5| Step: 2
Training loss: 2.0666525681332666
Validation loss: 2.5147455052279595

Epoch: 5| Step: 3
Training loss: 2.8740878109295966
Validation loss: 2.549067078518042

Epoch: 5| Step: 4
Training loss: 2.4252743398689374
Validation loss: 2.5624329589199597

Epoch: 5| Step: 5
Training loss: 2.819684325872455
Validation loss: 2.5172220890345227

Epoch: 5| Step: 6
Training loss: 2.777818684806552
Validation loss: 2.4849539707930393

Epoch: 5| Step: 7
Training loss: 2.847983593957774
Validation loss: 2.4698984396282873

Epoch: 5| Step: 8
Training loss: 2.779561248022131
Validation loss: 2.4553961192583826

Epoch: 5| Step: 9
Training loss: 2.3291351379917464
Validation loss: 2.462972435435731

Epoch: 5| Step: 10
Training loss: 2.5726254152916987
Validation loss: 2.4651738715027087

Epoch: 5| Step: 11
Training loss: 1.6594122442458803
Validation loss: 2.464303120096839

Epoch: 157| Step: 0
Training loss: 2.837653363490355
Validation loss: 2.470346920184617

Epoch: 5| Step: 1
Training loss: 2.5259710767393364
Validation loss: 2.4669022063185535

Epoch: 5| Step: 2
Training loss: 2.3895716122841715
Validation loss: 2.465532737556102

Epoch: 5| Step: 3
Training loss: 2.5000514978826796
Validation loss: 2.4660598608309754

Epoch: 5| Step: 4
Training loss: 2.8280280502309494
Validation loss: 2.463655377775254

Epoch: 5| Step: 5
Training loss: 2.430359873084934
Validation loss: 2.4636930025379367

Epoch: 5| Step: 6
Training loss: 2.5922027936947596
Validation loss: 2.4560372707793454

Epoch: 5| Step: 7
Training loss: 2.739756840963705
Validation loss: 2.45791580943418

Epoch: 5| Step: 8
Training loss: 2.413410876575637
Validation loss: 2.4525570546084383

Epoch: 5| Step: 9
Training loss: 2.2784350023372375
Validation loss: 2.4561882493375746

Epoch: 5| Step: 10
Training loss: 2.2719689309118127
Validation loss: 2.452641263270663

Epoch: 5| Step: 11
Training loss: 2.5150987536720413
Validation loss: 2.452095710757727

Epoch: 158| Step: 0
Training loss: 2.4290184743531245
Validation loss: 2.458540238278004

Epoch: 5| Step: 1
Training loss: 2.3234138697927795
Validation loss: 2.4633400083809756

Epoch: 5| Step: 2
Training loss: 2.644896894727701
Validation loss: 2.4737884617090518

Epoch: 5| Step: 3
Training loss: 2.1098765589325614
Validation loss: 2.4813649118112155

Epoch: 5| Step: 4
Training loss: 3.287711910481702
Validation loss: 2.4769705226696086

Epoch: 5| Step: 5
Training loss: 2.54958980477398
Validation loss: 2.4743814621857267

Epoch: 5| Step: 6
Training loss: 2.5369397489184355
Validation loss: 2.472445731620136

Epoch: 5| Step: 7
Training loss: 2.815160383191917
Validation loss: 2.4762463412963087

Epoch: 5| Step: 8
Training loss: 2.3878347032421074
Validation loss: 2.47532106445973

Epoch: 5| Step: 9
Training loss: 2.2426697747340913
Validation loss: 2.4684427126446176

Epoch: 5| Step: 10
Training loss: 2.5871252000414855
Validation loss: 2.4667497249314576

Epoch: 5| Step: 11
Training loss: 2.0049070718210817
Validation loss: 2.4693021036219984

Epoch: 159| Step: 0
Training loss: 2.484908808334037
Validation loss: 2.474126947914366

Epoch: 5| Step: 1
Training loss: 2.149732608579754
Validation loss: 2.4695095028714693

Epoch: 5| Step: 2
Training loss: 2.6477445973199
Validation loss: 2.4735523626952554

Epoch: 5| Step: 3
Training loss: 2.0591749496427165
Validation loss: 2.4798771049988844

Epoch: 5| Step: 4
Training loss: 2.5485040802154897
Validation loss: 2.474061109850751

Epoch: 5| Step: 5
Training loss: 2.4632533242735466
Validation loss: 2.4700001919124697

Epoch: 5| Step: 6
Training loss: 2.4721369627444063
Validation loss: 2.464872413464561

Epoch: 5| Step: 7
Training loss: 2.9186670981811
Validation loss: 2.468227037336455

Epoch: 5| Step: 8
Training loss: 2.745741755145539
Validation loss: 2.4701951782626113

Epoch: 5| Step: 9
Training loss: 2.3127971149000386
Validation loss: 2.467751747824029

Epoch: 5| Step: 10
Training loss: 2.4990282077304022
Validation loss: 2.4701222336211504

Epoch: 5| Step: 11
Training loss: 3.4989319942959747
Validation loss: 2.4638067805822663

Epoch: 160| Step: 0
Training loss: 2.3846192561040076
Validation loss: 2.4638881170911224

Epoch: 5| Step: 1
Training loss: 2.304484316387842
Validation loss: 2.4688963122409575

Epoch: 5| Step: 2
Training loss: 2.872647359469602
Validation loss: 2.4665733632814644

Epoch: 5| Step: 3
Training loss: 2.134992554269712
Validation loss: 2.4709741396020988

Epoch: 5| Step: 4
Training loss: 2.816148891674253
Validation loss: 2.459494233139318

Epoch: 5| Step: 5
Training loss: 2.3116889768631794
Validation loss: 2.475469145317827

Epoch: 5| Step: 6
Training loss: 2.5105281398816657
Validation loss: 2.461079237151237

Epoch: 5| Step: 7
Training loss: 2.6837695645817186
Validation loss: 2.4633966622344365

Epoch: 5| Step: 8
Training loss: 2.7266899887928058
Validation loss: 2.4650049655624424

Epoch: 5| Step: 9
Training loss: 2.5925047309560108
Validation loss: 2.4687740550096566

Epoch: 5| Step: 10
Training loss: 2.221797623071679
Validation loss: 2.46757701378373

Epoch: 5| Step: 11
Training loss: 2.2798499422719347
Validation loss: 2.4526367430522718

Epoch: 161| Step: 0
Training loss: 2.4333611586908934
Validation loss: 2.45968875588209

Epoch: 5| Step: 1
Training loss: 2.712597429485829
Validation loss: 2.4590186615872214

Epoch: 5| Step: 2
Training loss: 2.3444952225070015
Validation loss: 2.463569936664044

Epoch: 5| Step: 3
Training loss: 2.4076723130971622
Validation loss: 2.4641807599535994

Epoch: 5| Step: 4
Training loss: 2.3982113411606027
Validation loss: 2.4594254425123707

Epoch: 5| Step: 5
Training loss: 2.2841372051749014
Validation loss: 2.456908877448172

Epoch: 5| Step: 6
Training loss: 2.615111298973347
Validation loss: 2.462093479388223

Epoch: 5| Step: 7
Training loss: 2.8970838815055893
Validation loss: 2.460241766378428

Epoch: 5| Step: 8
Training loss: 1.9568191382915618
Validation loss: 2.454822366118858

Epoch: 5| Step: 9
Training loss: 2.7389795389793457
Validation loss: 2.4553246648712945

Epoch: 5| Step: 10
Training loss: 2.549593264735039
Validation loss: 2.4675354565447014

Epoch: 5| Step: 11
Training loss: 3.2659263654304977
Validation loss: 2.464278368382796

Epoch: 162| Step: 0
Training loss: 2.4308910271571382
Validation loss: 2.4503852220254054

Epoch: 5| Step: 1
Training loss: 2.6980672276338007
Validation loss: 2.462008740628322

Epoch: 5| Step: 2
Training loss: 2.694778433699546
Validation loss: 2.463175939358919

Epoch: 5| Step: 3
Training loss: 2.865037824237922
Validation loss: 2.4654714084453526

Epoch: 5| Step: 4
Training loss: 2.6432319728792577
Validation loss: 2.470774094438099

Epoch: 5| Step: 5
Training loss: 2.024450571381479
Validation loss: 2.4631246021525004

Epoch: 5| Step: 6
Training loss: 3.0369605319234787
Validation loss: 2.462474169652145

Epoch: 5| Step: 7
Training loss: 2.6179761922349734
Validation loss: 2.466104268761365

Epoch: 5| Step: 8
Training loss: 2.7562076556700723
Validation loss: 2.4656106206283646

Epoch: 5| Step: 9
Training loss: 2.071838162239975
Validation loss: 2.4689939394477736

Epoch: 5| Step: 10
Training loss: 1.6376948757546377
Validation loss: 2.4581686479288622

Epoch: 5| Step: 11
Training loss: 2.115818383353224
Validation loss: 2.4598868655342105

Epoch: 163| Step: 0
Training loss: 2.4684685655322807
Validation loss: 2.463018052558085

Epoch: 5| Step: 1
Training loss: 2.776243525759015
Validation loss: 2.4582769999003333

Epoch: 5| Step: 2
Training loss: 2.251078559070666
Validation loss: 2.4635303179833694

Epoch: 5| Step: 3
Training loss: 2.3011297146650818
Validation loss: 2.4602013430476033

Epoch: 5| Step: 4
Training loss: 2.4721051365799416
Validation loss: 2.462705405054744

Epoch: 5| Step: 5
Training loss: 3.1143155360262664
Validation loss: 2.467141468407065

Epoch: 5| Step: 6
Training loss: 2.5421430005924974
Validation loss: 2.467299977131019

Epoch: 5| Step: 7
Training loss: 2.823510467650403
Validation loss: 2.4548315401348058

Epoch: 5| Step: 8
Training loss: 2.066004925067419
Validation loss: 2.46301181302456

Epoch: 5| Step: 9
Training loss: 2.5475389048232677
Validation loss: 2.4578130031293357

Epoch: 5| Step: 10
Training loss: 2.275714376444623
Validation loss: 2.469088527148128

Epoch: 5| Step: 11
Training loss: 0.6813184966203215
Validation loss: 2.461039822585624

Epoch: 164| Step: 0
Training loss: 2.770969377968681
Validation loss: 2.458949247618862

Epoch: 5| Step: 1
Training loss: 2.1580146534645848
Validation loss: 2.4635872598075754

Epoch: 5| Step: 2
Training loss: 2.3179549753919586
Validation loss: 2.4687679668368268

Epoch: 5| Step: 3
Training loss: 2.961448122146254
Validation loss: 2.4696611421145462

Epoch: 5| Step: 4
Training loss: 2.505805046937622
Validation loss: 2.4846017202255344

Epoch: 5| Step: 5
Training loss: 2.6455498991611206
Validation loss: 2.4779427189149925

Epoch: 5| Step: 6
Training loss: 2.158804002891506
Validation loss: 2.481067499100011

Epoch: 5| Step: 7
Training loss: 3.000885991555488
Validation loss: 2.4777442767948585

Epoch: 5| Step: 8
Training loss: 1.95817724241619
Validation loss: 2.460467956798656

Epoch: 5| Step: 9
Training loss: 1.9172204572087992
Validation loss: 2.459546768963154

Epoch: 5| Step: 10
Training loss: 2.9064347403271027
Validation loss: 2.460129200429396

Epoch: 5| Step: 11
Training loss: 2.0719319469514077
Validation loss: 2.4627610529738466

Epoch: 165| Step: 0
Training loss: 2.222677488845691
Validation loss: 2.4622050699322955

Epoch: 5| Step: 1
Training loss: 2.5232725296186356
Validation loss: 2.4598193741858148

Epoch: 5| Step: 2
Training loss: 2.909497651199675
Validation loss: 2.4633497757539295

Epoch: 5| Step: 3
Training loss: 2.4956709573833757
Validation loss: 2.464093024968455

Epoch: 5| Step: 4
Training loss: 2.90616172738507
Validation loss: 2.473475950628612

Epoch: 5| Step: 5
Training loss: 2.371548403241742
Validation loss: 2.463006497106993

Epoch: 5| Step: 6
Training loss: 1.9528749839979516
Validation loss: 2.4665412236762907

Epoch: 5| Step: 7
Training loss: 2.477347745865096
Validation loss: 2.466113715011338

Epoch: 5| Step: 8
Training loss: 2.5122677216460447
Validation loss: 2.464683569828468

Epoch: 5| Step: 9
Training loss: 2.6037385105386845
Validation loss: 2.463393319134723

Epoch: 5| Step: 10
Training loss: 2.191500466237246
Validation loss: 2.463517216459619

Epoch: 5| Step: 11
Training loss: 2.846404963694764
Validation loss: 2.46747269160868

Epoch: 166| Step: 0
Training loss: 2.13318505020182
Validation loss: 2.4613850383417266

Epoch: 5| Step: 1
Training loss: 2.3496741129771217
Validation loss: 2.4631027102129335

Epoch: 5| Step: 2
Training loss: 3.0124012214642972
Validation loss: 2.4584575328056775

Epoch: 5| Step: 3
Training loss: 1.7587398541231734
Validation loss: 2.4637723993450544

Epoch: 5| Step: 4
Training loss: 2.991915937007772
Validation loss: 2.4694277319994016

Epoch: 5| Step: 5
Training loss: 2.871535826403588
Validation loss: 2.4611689261959553

Epoch: 5| Step: 6
Training loss: 2.6354498176349277
Validation loss: 2.464735714922189

Epoch: 5| Step: 7
Training loss: 1.9234253747404484
Validation loss: 2.4608110667856633

Epoch: 5| Step: 8
Training loss: 2.4701231023096732
Validation loss: 2.472588205229893

Epoch: 5| Step: 9
Training loss: 2.073823190677109
Validation loss: 2.458789085448585

Epoch: 5| Step: 10
Training loss: 2.5091824696411758
Validation loss: 2.4610833866535

Epoch: 5| Step: 11
Training loss: 3.450905617426142
Validation loss: 2.4618460496896817

Epoch: 167| Step: 0
Training loss: 2.6763448525394398
Validation loss: 2.471291416980801

Epoch: 5| Step: 1
Training loss: 2.449695206192184
Validation loss: 2.4615642375228823

Epoch: 5| Step: 2
Training loss: 2.299873937386276
Validation loss: 2.4621807812885

Epoch: 5| Step: 3
Training loss: 2.5276099511444623
Validation loss: 2.4672482989379407

Epoch: 5| Step: 4
Training loss: 2.382276230798066
Validation loss: 2.4600522220116106

Epoch: 5| Step: 5
Training loss: 2.2434950149715394
Validation loss: 2.460288467803455

Epoch: 5| Step: 6
Training loss: 2.5515559890766784
Validation loss: 2.471422716375183

Epoch: 5| Step: 7
Training loss: 2.786321067400024
Validation loss: 2.4639294596677637

Epoch: 5| Step: 8
Training loss: 2.1901076986229198
Validation loss: 2.463350624650534

Epoch: 5| Step: 9
Training loss: 2.7743233998573147
Validation loss: 2.455004589564688

Epoch: 5| Step: 10
Training loss: 2.4310274507705887
Validation loss: 2.4628984500076014

Epoch: 5| Step: 11
Training loss: 1.569356826804617
Validation loss: 2.459301605648237

Epoch: 168| Step: 0
Training loss: 2.208613275982067
Validation loss: 2.458418704560263

Epoch: 5| Step: 1
Training loss: 2.257469071929397
Validation loss: 2.460183265192862

Epoch: 5| Step: 2
Training loss: 2.6367153139445203
Validation loss: 2.4635643195198877

Epoch: 5| Step: 3
Training loss: 2.8105559517910677
Validation loss: 2.4544719715550167

Epoch: 5| Step: 4
Training loss: 2.378301133238806
Validation loss: 2.460656403326722

Epoch: 5| Step: 5
Training loss: 2.706896846016328
Validation loss: 2.466647786205651

Epoch: 5| Step: 6
Training loss: 2.5841546035020864
Validation loss: 2.4655715585258706

Epoch: 5| Step: 7
Training loss: 2.1799026437771105
Validation loss: 2.46595165343536

Epoch: 5| Step: 8
Training loss: 2.557838479890586
Validation loss: 2.4704971529178548

Epoch: 5| Step: 9
Training loss: 2.431044711588002
Validation loss: 2.4655580850795182

Epoch: 5| Step: 10
Training loss: 2.35712067482159
Validation loss: 2.4683715675126527

Epoch: 5| Step: 11
Training loss: 2.7560131049045316
Validation loss: 2.4638721024016554

Epoch: 169| Step: 0
Training loss: 2.342101267422652
Validation loss: 2.4609028001387525

Epoch: 5| Step: 1
Training loss: 2.307684343275363
Validation loss: 2.464899752666334

Epoch: 5| Step: 2
Training loss: 2.608649055783517
Validation loss: 2.4694298842167384

Epoch: 5| Step: 3
Training loss: 2.14712428793135
Validation loss: 2.471629063492135

Epoch: 5| Step: 4
Training loss: 2.564601408716294
Validation loss: 2.4631671110004336

Epoch: 5| Step: 5
Training loss: 2.63015051044823
Validation loss: 2.46232013916919

Epoch: 5| Step: 6
Training loss: 2.2724823403590295
Validation loss: 2.4625985085523876

Epoch: 5| Step: 7
Training loss: 3.1378273720944927
Validation loss: 2.4611369662712343

Epoch: 5| Step: 8
Training loss: 2.6001579456771973
Validation loss: 2.469492716067737

Epoch: 5| Step: 9
Training loss: 1.9013052422337418
Validation loss: 2.4710214281669813

Epoch: 5| Step: 10
Training loss: 2.5386981409242853
Validation loss: 2.4663269690780236

Epoch: 5| Step: 11
Training loss: 2.437133565893624
Validation loss: 2.4814461331877187

Epoch: 170| Step: 0
Training loss: 2.298926961454579
Validation loss: 2.4629258272547814

Epoch: 5| Step: 1
Training loss: 2.286180889238446
Validation loss: 2.4614457468450137

Epoch: 5| Step: 2
Training loss: 3.1156035488541884
Validation loss: 2.461536395147722

Epoch: 5| Step: 3
Training loss: 2.2135513006262473
Validation loss: 2.468788454504746

Epoch: 5| Step: 4
Training loss: 2.832130588236221
Validation loss: 2.470451344161791

Epoch: 5| Step: 5
Training loss: 2.542670213371141
Validation loss: 2.4696700075953912

Epoch: 5| Step: 6
Training loss: 2.2668607301475876
Validation loss: 2.4743059871074955

Epoch: 5| Step: 7
Training loss: 2.1672310338670617
Validation loss: 2.4716804109509756

Epoch: 5| Step: 8
Training loss: 2.690265031542693
Validation loss: 2.4737419127450484

Epoch: 5| Step: 9
Training loss: 2.666051127997351
Validation loss: 2.4741337817704725

Epoch: 5| Step: 10
Training loss: 2.5909973613176414
Validation loss: 2.4737327486220235

Epoch: 5| Step: 11
Training loss: 2.6704481453145585
Validation loss: 2.4659222854327307

Epoch: 171| Step: 0
Training loss: 2.8344181078542094
Validation loss: 2.4681413922409923

Epoch: 5| Step: 1
Training loss: 2.253390512681462
Validation loss: 2.458920959511399

Epoch: 5| Step: 2
Training loss: 2.367025338337455
Validation loss: 2.463582384661482

Epoch: 5| Step: 3
Training loss: 2.424581184794887
Validation loss: 2.4735569732080185

Epoch: 5| Step: 4
Training loss: 2.619128427043277
Validation loss: 2.4708283082311606

Epoch: 5| Step: 5
Training loss: 2.2670470937608664
Validation loss: 2.475912111001234

Epoch: 5| Step: 6
Training loss: 2.3901025537809737
Validation loss: 2.4761274418934134

Epoch: 5| Step: 7
Training loss: 2.6772724980317264
Validation loss: 2.488311611690961

Epoch: 5| Step: 8
Training loss: 2.2541485793351126
Validation loss: 2.493285460454507

Epoch: 5| Step: 9
Training loss: 2.477793486887006
Validation loss: 2.4916745159148865

Epoch: 5| Step: 10
Training loss: 2.6039627503984475
Validation loss: 2.491063226128672

Epoch: 5| Step: 11
Training loss: 2.4491458376993536
Validation loss: 2.497215707360486

Epoch: 172| Step: 0
Training loss: 2.5553938796091393
Validation loss: 2.489468044473932

Epoch: 5| Step: 1
Training loss: 1.8709348479711374
Validation loss: 2.4729122654062348

Epoch: 5| Step: 2
Training loss: 1.8540118792214
Validation loss: 2.4778821339522743

Epoch: 5| Step: 3
Training loss: 2.684783094513857
Validation loss: 2.4717767164622333

Epoch: 5| Step: 4
Training loss: 2.620284977622212
Validation loss: 2.4670202094246236

Epoch: 5| Step: 5
Training loss: 2.8446901884153233
Validation loss: 2.4739087424410964

Epoch: 5| Step: 6
Training loss: 2.6835562579827354
Validation loss: 2.4734500577041154

Epoch: 5| Step: 7
Training loss: 2.3732526273971057
Validation loss: 2.472352278889437

Epoch: 5| Step: 8
Training loss: 3.023165747285299
Validation loss: 2.4750103744777476

Epoch: 5| Step: 9
Training loss: 2.371979449036781
Validation loss: 2.471913588263256

Epoch: 5| Step: 10
Training loss: 2.6229385274067494
Validation loss: 2.4797974967316483

Epoch: 5| Step: 11
Training loss: 0.8075864110246453
Validation loss: 2.4738474623615385

Epoch: 173| Step: 0
Training loss: 2.707061018786986
Validation loss: 2.475397752660581

Epoch: 5| Step: 1
Training loss: 1.939190895815525
Validation loss: 2.4724611162163055

Epoch: 5| Step: 2
Training loss: 2.36934812538082
Validation loss: 2.469333086889914

Epoch: 5| Step: 3
Training loss: 2.9657068014168586
Validation loss: 2.4736185516456373

Epoch: 5| Step: 4
Training loss: 2.344103366916143
Validation loss: 2.4781601542945424

Epoch: 5| Step: 5
Training loss: 2.6488767726601177
Validation loss: 2.485481597556389

Epoch: 5| Step: 6
Training loss: 2.6815810561596667
Validation loss: 2.476537353355867

Epoch: 5| Step: 7
Training loss: 2.2456026552120067
Validation loss: 2.4743553539066934

Epoch: 5| Step: 8
Training loss: 2.4486748245017513
Validation loss: 2.4819671670615593

Epoch: 5| Step: 9
Training loss: 2.3677359471275135
Validation loss: 2.483499412668905

Epoch: 5| Step: 10
Training loss: 2.1486593235982054
Validation loss: 2.486540660179755

Epoch: 5| Step: 11
Training loss: 2.436800342794734
Validation loss: 2.48985474728391

Epoch: 174| Step: 0
Training loss: 2.0806392288981956
Validation loss: 2.475810756168466

Epoch: 5| Step: 1
Training loss: 1.7318613893930173
Validation loss: 2.4772257553514647

Epoch: 5| Step: 2
Training loss: 2.7261019867076053
Validation loss: 2.4727164648356594

Epoch: 5| Step: 3
Training loss: 2.5670161574909933
Validation loss: 2.463578283724667

Epoch: 5| Step: 4
Training loss: 2.764075755879481
Validation loss: 2.4634667069938057

Epoch: 5| Step: 5
Training loss: 2.318482573271992
Validation loss: 2.465759050974252

Epoch: 5| Step: 6
Training loss: 2.5303006687855865
Validation loss: 2.4646090392231015

Epoch: 5| Step: 7
Training loss: 2.6528691935696562
Validation loss: 2.4687568406923703

Epoch: 5| Step: 8
Training loss: 2.471724830435244
Validation loss: 2.4661202951389263

Epoch: 5| Step: 9
Training loss: 2.4551702829573046
Validation loss: 2.4647017779121523

Epoch: 5| Step: 10
Training loss: 2.7105066138395997
Validation loss: 2.464376051552084

Epoch: 5| Step: 11
Training loss: 2.3219360425685305
Validation loss: 2.465869822996526

Epoch: 175| Step: 0
Training loss: 2.7296301955271334
Validation loss: 2.471031603381949

Epoch: 5| Step: 1
Training loss: 2.4770978956593894
Validation loss: 2.469179401798303

Epoch: 5| Step: 2
Training loss: 2.313764381137301
Validation loss: 2.4678444670365516

Epoch: 5| Step: 3
Training loss: 1.9553062161098795
Validation loss: 2.470607794931665

Epoch: 5| Step: 4
Training loss: 2.504939444870283
Validation loss: 2.468797379453534

Epoch: 5| Step: 5
Training loss: 2.2388809758759853
Validation loss: 2.4806727007624474

Epoch: 5| Step: 6
Training loss: 2.324215467434657
Validation loss: 2.47676124938513

Epoch: 5| Step: 7
Training loss: 2.7590220449188414
Validation loss: 2.4727375344590325

Epoch: 5| Step: 8
Training loss: 2.808987776873983
Validation loss: 2.479303930527087

Epoch: 5| Step: 9
Training loss: 2.3053715094933067
Validation loss: 2.474642461582138

Epoch: 5| Step: 10
Training loss: 2.4467774899128125
Validation loss: 2.4729410703516

Epoch: 5| Step: 11
Training loss: 3.3029363515174333
Validation loss: 2.4781185079507986

Epoch: 176| Step: 0
Training loss: 2.7327166078645853
Validation loss: 2.481763666922492

Epoch: 5| Step: 1
Training loss: 2.605356010960432
Validation loss: 2.482896468813418

Epoch: 5| Step: 2
Training loss: 2.516493274281816
Validation loss: 2.5020835935755033

Epoch: 5| Step: 3
Training loss: 2.9570988152266975
Validation loss: 2.5055838849970025

Epoch: 5| Step: 4
Training loss: 2.5251692271414017
Validation loss: 2.508368451299306

Epoch: 5| Step: 5
Training loss: 2.5183283336933964
Validation loss: 2.4999882697783886

Epoch: 5| Step: 6
Training loss: 2.156332042073156
Validation loss: 2.4872487160104257

Epoch: 5| Step: 7
Training loss: 2.284193882891974
Validation loss: 2.491771368284992

Epoch: 5| Step: 8
Training loss: 2.215436583606366
Validation loss: 2.479322518063372

Epoch: 5| Step: 9
Training loss: 2.7547545513056972
Validation loss: 2.4885232868583014

Epoch: 5| Step: 10
Training loss: 1.639402388105041
Validation loss: 2.480675944488144

Epoch: 5| Step: 11
Training loss: 3.0558174560511677
Validation loss: 2.4842499395598696

Epoch: 177| Step: 0
Training loss: 2.7357967495183724
Validation loss: 2.47424213320884

Epoch: 5| Step: 1
Training loss: 2.51989005439334
Validation loss: 2.4791231485495606

Epoch: 5| Step: 2
Training loss: 2.3565196765812293
Validation loss: 2.482692272587493

Epoch: 5| Step: 3
Training loss: 2.3066443460226127
Validation loss: 2.485451295221856

Epoch: 5| Step: 4
Training loss: 2.5896638603507856
Validation loss: 2.4835601325978316

Epoch: 5| Step: 5
Training loss: 2.1491349631381262
Validation loss: 2.4864106944943063

Epoch: 5| Step: 6
Training loss: 2.609220214638658
Validation loss: 2.476776623218896

Epoch: 5| Step: 7
Training loss: 2.2339246602822986
Validation loss: 2.4874528457095524

Epoch: 5| Step: 8
Training loss: 2.5879414794531614
Validation loss: 2.487476356432321

Epoch: 5| Step: 9
Training loss: 2.312154073874453
Validation loss: 2.4859553215176082

Epoch: 5| Step: 10
Training loss: 2.52818018000755
Validation loss: 2.486165103527332

Epoch: 5| Step: 11
Training loss: 2.516527381309921
Validation loss: 2.490132344468204

Epoch: 178| Step: 0
Training loss: 2.20230141254285
Validation loss: 2.479925665888613

Epoch: 5| Step: 1
Training loss: 2.406676217515474
Validation loss: 2.487804195439866

Epoch: 5| Step: 2
Training loss: 1.797463693795935
Validation loss: 2.49642439489485

Epoch: 5| Step: 3
Training loss: 2.3667565888349094
Validation loss: 2.4973762254207093

Epoch: 5| Step: 4
Training loss: 2.4825033179008384
Validation loss: 2.4967861100830975

Epoch: 5| Step: 5
Training loss: 2.4830146760049776
Validation loss: 2.5020128670318895

Epoch: 5| Step: 6
Training loss: 2.4835285208200863
Validation loss: 2.5078151698905384

Epoch: 5| Step: 7
Training loss: 2.9445958568421298
Validation loss: 2.515487718489112

Epoch: 5| Step: 8
Training loss: 2.3863686961991473
Validation loss: 2.5014124575715484

Epoch: 5| Step: 9
Training loss: 2.6515259865543555
Validation loss: 2.498777965053942

Epoch: 5| Step: 10
Training loss: 2.5927170684491565
Validation loss: 2.4775303174000975

Epoch: 5| Step: 11
Training loss: 2.916467242008052
Validation loss: 2.4788809152152695

Epoch: 179| Step: 0
Training loss: 2.1432961831598445
Validation loss: 2.4714442653063213

Epoch: 5| Step: 1
Training loss: 2.8706097460872413
Validation loss: 2.473583242524868

Epoch: 5| Step: 2
Training loss: 1.8293284180304514
Validation loss: 2.46593274555772

Epoch: 5| Step: 3
Training loss: 1.9919736859640291
Validation loss: 2.47576259205959

Epoch: 5| Step: 4
Training loss: 2.6647929423556835
Validation loss: 2.4807609766436314

Epoch: 5| Step: 5
Training loss: 2.342303223706245
Validation loss: 2.476184527317742

Epoch: 5| Step: 6
Training loss: 2.995689792581005
Validation loss: 2.478267471880936

Epoch: 5| Step: 7
Training loss: 2.0123775847740832
Validation loss: 2.4714358644209864

Epoch: 5| Step: 8
Training loss: 2.4427368444366278
Validation loss: 2.4754838570058357

Epoch: 5| Step: 9
Training loss: 2.1636691510606387
Validation loss: 2.4799712555767943

Epoch: 5| Step: 10
Training loss: 3.1729973371790914
Validation loss: 2.4797152398490216

Epoch: 5| Step: 11
Training loss: 2.5275329802009345
Validation loss: 2.4792616963539054

Epoch: 180| Step: 0
Training loss: 2.9279198769097197
Validation loss: 2.473776229714841

Epoch: 5| Step: 1
Training loss: 2.7990409945817807
Validation loss: 2.489709145999423

Epoch: 5| Step: 2
Training loss: 1.974003458304115
Validation loss: 2.4866789684894752

Epoch: 5| Step: 3
Training loss: 2.3450858823101033
Validation loss: 2.48398886184939

Epoch: 5| Step: 4
Training loss: 2.407865205122334
Validation loss: 2.487023898749314

Epoch: 5| Step: 5
Training loss: 2.3814329062074324
Validation loss: 2.493827977471121

Epoch: 5| Step: 6
Training loss: 2.9112767872083687
Validation loss: 2.493667971983644

Epoch: 5| Step: 7
Training loss: 2.2136164633885573
Validation loss: 2.4920274609368644

Epoch: 5| Step: 8
Training loss: 2.2267749350412864
Validation loss: 2.486152988367654

Epoch: 5| Step: 9
Training loss: 2.263643226738477
Validation loss: 2.4787688670784536

Epoch: 5| Step: 10
Training loss: 2.2552532752465417
Validation loss: 2.473299968186826

Epoch: 5| Step: 11
Training loss: 3.031791717259895
Validation loss: 2.4780625775217335

Epoch: 181| Step: 0
Training loss: 2.47854284778071
Validation loss: 2.4742844269650672

Epoch: 5| Step: 1
Training loss: 2.149276070366008
Validation loss: 2.4778410081381685

Epoch: 5| Step: 2
Training loss: 2.1414261035910425
Validation loss: 2.4812443599428637

Epoch: 5| Step: 3
Training loss: 2.580341472945857
Validation loss: 2.478802206727548

Epoch: 5| Step: 4
Training loss: 1.9874269939905367
Validation loss: 2.47117183295403

Epoch: 5| Step: 5
Training loss: 1.6398593387526155
Validation loss: 2.4874134117340403

Epoch: 5| Step: 6
Training loss: 2.4769488974864373
Validation loss: 2.4735153096037994

Epoch: 5| Step: 7
Training loss: 2.905204995254745
Validation loss: 2.4894772404579557

Epoch: 5| Step: 8
Training loss: 2.5219970938282374
Validation loss: 2.489175046111252

Epoch: 5| Step: 9
Training loss: 2.7617455121029173
Validation loss: 2.49061496194933

Epoch: 5| Step: 10
Training loss: 2.8594005145826302
Validation loss: 2.4872045577940103

Epoch: 5| Step: 11
Training loss: 2.873737887456123
Validation loss: 2.483178144338006

Epoch: 182| Step: 0
Training loss: 2.175755170189861
Validation loss: 2.4861318626165243

Epoch: 5| Step: 1
Training loss: 2.3123458604734037
Validation loss: 2.4872945588865067

Epoch: 5| Step: 2
Training loss: 2.5190244652929406
Validation loss: 2.49210351545356

Epoch: 5| Step: 3
Training loss: 2.227336120057192
Validation loss: 2.4912540597048367

Epoch: 5| Step: 4
Training loss: 3.282434885348115
Validation loss: 2.5079059761665814

Epoch: 5| Step: 5
Training loss: 2.090659522440115
Validation loss: 2.512140186286753

Epoch: 5| Step: 6
Training loss: 2.258277713142317
Validation loss: 2.483106797295068

Epoch: 5| Step: 7
Training loss: 2.2820390355735793
Validation loss: 2.488450116985406

Epoch: 5| Step: 8
Training loss: 2.7261820967734467
Validation loss: 2.496249230387414

Epoch: 5| Step: 9
Training loss: 2.3620205629892665
Validation loss: 2.4764487744843233

Epoch: 5| Step: 10
Training loss: 2.3661440321484197
Validation loss: 2.4852905046098943

Epoch: 5| Step: 11
Training loss: 3.103850244016337
Validation loss: 2.47350916884166

Epoch: 183| Step: 0
Training loss: 2.5428537087853575
Validation loss: 2.4696213596875363

Epoch: 5| Step: 1
Training loss: 1.9242127629449084
Validation loss: 2.475793327959332

Epoch: 5| Step: 2
Training loss: 2.684903154384771
Validation loss: 2.465412169063356

Epoch: 5| Step: 3
Training loss: 2.7392260435713482
Validation loss: 2.466740152245985

Epoch: 5| Step: 4
Training loss: 2.4951784369011203
Validation loss: 2.469657566147067

Epoch: 5| Step: 5
Training loss: 2.467714309738821
Validation loss: 2.4737991897526785

Epoch: 5| Step: 6
Training loss: 2.123545541604146
Validation loss: 2.4741302082523013

Epoch: 5| Step: 7
Training loss: 2.4072472623666292
Validation loss: 2.4715369866739594

Epoch: 5| Step: 8
Training loss: 2.99788623093634
Validation loss: 2.4718971111596315

Epoch: 5| Step: 9
Training loss: 2.7118868965543843
Validation loss: 2.4724625465891474

Epoch: 5| Step: 10
Training loss: 1.8436570871509244
Validation loss: 2.47693992570722

Epoch: 5| Step: 11
Training loss: 3.5561277720492743
Validation loss: 2.476351651784002

Epoch: 184| Step: 0
Training loss: 2.1216024277105006
Validation loss: 2.4711265351939398

Epoch: 5| Step: 1
Training loss: 2.4878187004158714
Validation loss: 2.4758515084480246

Epoch: 5| Step: 2
Training loss: 2.193261107827651
Validation loss: 2.4787330261549596

Epoch: 5| Step: 3
Training loss: 2.4043962348097465
Validation loss: 2.478166191332782

Epoch: 5| Step: 4
Training loss: 2.9432411094148256
Validation loss: 2.4819283964102814

Epoch: 5| Step: 5
Training loss: 2.2801546576397724
Validation loss: 2.4798477817326603

Epoch: 5| Step: 6
Training loss: 2.7938070679709495
Validation loss: 2.490008634420793

Epoch: 5| Step: 7
Training loss: 2.270837614656198
Validation loss: 2.483005025996062

Epoch: 5| Step: 8
Training loss: 2.5735135537949207
Validation loss: 2.4882535748262677

Epoch: 5| Step: 9
Training loss: 2.6544635824212
Validation loss: 2.497770658546908

Epoch: 5| Step: 10
Training loss: 2.448494884838505
Validation loss: 2.4915698451003245

Epoch: 5| Step: 11
Training loss: 1.8848413956191126
Validation loss: 2.4981505188804896

Epoch: 185| Step: 0
Training loss: 2.477820910043693
Validation loss: 2.5003373951533328

Epoch: 5| Step: 1
Training loss: 2.6570775257669452
Validation loss: 2.511005155881903

Epoch: 5| Step: 2
Training loss: 2.4254872609253955
Validation loss: 2.5041168211632305

Epoch: 5| Step: 3
Training loss: 2.150684859737884
Validation loss: 2.5166350443750156

Epoch: 5| Step: 4
Training loss: 2.2027873328334278
Validation loss: 2.5079211551186464

Epoch: 5| Step: 5
Training loss: 2.590990459953127
Validation loss: 2.5006006115422723

Epoch: 5| Step: 6
Training loss: 2.7940306452147095
Validation loss: 2.4984479417676146

Epoch: 5| Step: 7
Training loss: 2.158898537566741
Validation loss: 2.4839318957931265

Epoch: 5| Step: 8
Training loss: 2.5288867986223864
Validation loss: 2.4888122167750533

Epoch: 5| Step: 9
Training loss: 2.8540175647261923
Validation loss: 2.476221712975623

Epoch: 5| Step: 10
Training loss: 2.159281161928892
Validation loss: 2.4766451945172014

Epoch: 5| Step: 11
Training loss: 3.728821267838585
Validation loss: 2.4684064561696593

Epoch: 186| Step: 0
Training loss: 2.579150741437597
Validation loss: 2.471126880920138

Epoch: 5| Step: 1
Training loss: 2.776674772191973
Validation loss: 2.4692182921654777

Epoch: 5| Step: 2
Training loss: 2.4444545422933066
Validation loss: 2.4688309563670168

Epoch: 5| Step: 3
Training loss: 2.5041754186628586
Validation loss: 2.4726137034053672

Epoch: 5| Step: 4
Training loss: 1.9991066844995398
Validation loss: 2.4789186314849583

Epoch: 5| Step: 5
Training loss: 3.074342834217532
Validation loss: 2.4676143835005653

Epoch: 5| Step: 6
Training loss: 1.644372782921393
Validation loss: 2.4742480493193324

Epoch: 5| Step: 7
Training loss: 2.4831096377738873
Validation loss: 2.4705001767805745

Epoch: 5| Step: 8
Training loss: 2.2726731736073322
Validation loss: 2.475284766261886

Epoch: 5| Step: 9
Training loss: 2.327219025137233
Validation loss: 2.468145610368753

Epoch: 5| Step: 10
Training loss: 2.592735919573187
Validation loss: 2.4800127706660353

Epoch: 5| Step: 11
Training loss: 2.4942486410268243
Validation loss: 2.4763096420574424

Epoch: 187| Step: 0
Training loss: 2.714378613481218
Validation loss: 2.475310417257572

Epoch: 5| Step: 1
Training loss: 2.3396556441109064
Validation loss: 2.481246149587006

Epoch: 5| Step: 2
Training loss: 2.144151442061437
Validation loss: 2.4830952193097584

Epoch: 5| Step: 3
Training loss: 1.8711136277323572
Validation loss: 2.4880803744260422

Epoch: 5| Step: 4
Training loss: 1.9814625189848647
Validation loss: 2.4860828735185247

Epoch: 5| Step: 5
Training loss: 2.4102051171985788
Validation loss: 2.4962366547766646

Epoch: 5| Step: 6
Training loss: 3.0366067648324298
Validation loss: 2.496824719651245

Epoch: 5| Step: 7
Training loss: 2.492848084535197
Validation loss: 2.5027797543431682

Epoch: 5| Step: 8
Training loss: 2.1273064157920274
Validation loss: 2.5073024116119997

Epoch: 5| Step: 9
Training loss: 2.825173708545985
Validation loss: 2.5019619792907624

Epoch: 5| Step: 10
Training loss: 2.889506685596764
Validation loss: 2.505203656822064

Epoch: 5| Step: 11
Training loss: 1.2479456232157786
Validation loss: 2.504259805618678

Epoch: 188| Step: 0
Training loss: 2.2178473987281926
Validation loss: 2.4994683952176286

Epoch: 5| Step: 1
Training loss: 2.3017768713413327
Validation loss: 2.495563026803245

Epoch: 5| Step: 2
Training loss: 2.7234925746546876
Validation loss: 2.4923106554747125

Epoch: 5| Step: 3
Training loss: 2.7479962071110786
Validation loss: 2.4918075319700046

Epoch: 5| Step: 4
Training loss: 2.3561263803286456
Validation loss: 2.4886694485056724

Epoch: 5| Step: 5
Training loss: 2.891163708775825
Validation loss: 2.4916292679466783

Epoch: 5| Step: 6
Training loss: 2.2041598655821706
Validation loss: 2.4877583399924736

Epoch: 5| Step: 7
Training loss: 2.3820919761036072
Validation loss: 2.4895773106798775

Epoch: 5| Step: 8
Training loss: 2.8255915807255114
Validation loss: 2.5009146169676724

Epoch: 5| Step: 9
Training loss: 1.7945531024191912
Validation loss: 2.498524588092329

Epoch: 5| Step: 10
Training loss: 2.3689329051560026
Validation loss: 2.495987815778034

Epoch: 5| Step: 11
Training loss: 0.7644564215774682
Validation loss: 2.49040626481158

Epoch: 189| Step: 0
Training loss: 2.4282096465096137
Validation loss: 2.4991902152496746

Epoch: 5| Step: 1
Training loss: 2.296161878262354
Validation loss: 2.4973906012126594

Epoch: 5| Step: 2
Training loss: 2.3038193958943323
Validation loss: 2.49934743470628

Epoch: 5| Step: 3
Training loss: 2.572480837914636
Validation loss: 2.4950894846314555

Epoch: 5| Step: 4
Training loss: 2.1936587148948403
Validation loss: 2.4933988802011036

Epoch: 5| Step: 5
Training loss: 2.6662600227092463
Validation loss: 2.4910424371267106

Epoch: 5| Step: 6
Training loss: 2.6367540145211237
Validation loss: 2.5041425457573947

Epoch: 5| Step: 7
Training loss: 2.0896938377159904
Validation loss: 2.4962927391240664

Epoch: 5| Step: 8
Training loss: 2.681380023782473
Validation loss: 2.492453434387058

Epoch: 5| Step: 9
Training loss: 1.9566413658538226
Validation loss: 2.49497024889799

Epoch: 5| Step: 10
Training loss: 2.554357291529618
Validation loss: 2.5067940978325933

Epoch: 5| Step: 11
Training loss: 3.561639782297302
Validation loss: 2.493002352741609

Epoch: 190| Step: 0
Training loss: 2.0601396637394633
Validation loss: 2.4911011148647884

Epoch: 5| Step: 1
Training loss: 2.408760049716828
Validation loss: 2.4825285321645176

Epoch: 5| Step: 2
Training loss: 2.1626679371799886
Validation loss: 2.4918154415848814

Epoch: 5| Step: 3
Training loss: 2.603144625696248
Validation loss: 2.485075721847094

Epoch: 5| Step: 4
Training loss: 2.326752635803074
Validation loss: 2.493379664509104

Epoch: 5| Step: 5
Training loss: 3.061722793050804
Validation loss: 2.4897783846773938

Epoch: 5| Step: 6
Training loss: 2.341540910414346
Validation loss: 2.4924277465841707

Epoch: 5| Step: 7
Training loss: 2.621583622779015
Validation loss: 2.4957948086800426

Epoch: 5| Step: 8
Training loss: 1.7063105478128513
Validation loss: 2.4967374215479383

Epoch: 5| Step: 9
Training loss: 3.093248885443485
Validation loss: 2.495709608086201

Epoch: 5| Step: 10
Training loss: 2.1107139576336977
Validation loss: 2.5005368609961907

Epoch: 5| Step: 11
Training loss: 2.3785192616460438
Validation loss: 2.491728458361308

Epoch: 191| Step: 0
Training loss: 2.245019061850863
Validation loss: 2.4949957313513824

Epoch: 5| Step: 1
Training loss: 2.1741015321452712
Validation loss: 2.493999002210208

Epoch: 5| Step: 2
Training loss: 2.0808408959429157
Validation loss: 2.481521178928213

Epoch: 5| Step: 3
Training loss: 1.9208245236518176
Validation loss: 2.492825800073671

Epoch: 5| Step: 4
Training loss: 2.5370510173896084
Validation loss: 2.4883080824877926

Epoch: 5| Step: 5
Training loss: 2.880954050351094
Validation loss: 2.494354545562285

Epoch: 5| Step: 6
Training loss: 2.6312252886193943
Validation loss: 2.4905890597403135

Epoch: 5| Step: 7
Training loss: 2.4128207374000326
Validation loss: 2.491762701042299

Epoch: 5| Step: 8
Training loss: 2.016098558257122
Validation loss: 2.489005525858472

Epoch: 5| Step: 9
Training loss: 2.838887511483406
Validation loss: 2.4925378216393126

Epoch: 5| Step: 10
Training loss: 2.782577797760925
Validation loss: 2.4925964362767097

Epoch: 5| Step: 11
Training loss: 1.9651337365996666
Validation loss: 2.500569254914805

Epoch: 192| Step: 0
Training loss: 2.594531297784223
Validation loss: 2.504594808359809

Epoch: 5| Step: 1
Training loss: 2.5125850530244027
Validation loss: 2.52559099929228

Epoch: 5| Step: 2
Training loss: 2.2418053065352637
Validation loss: 2.524794805013649

Epoch: 5| Step: 3
Training loss: 2.366763035956828
Validation loss: 2.5363485180675194

Epoch: 5| Step: 4
Training loss: 1.9430462608936145
Validation loss: 2.5345030630347423

Epoch: 5| Step: 5
Training loss: 2.301261605601804
Validation loss: 2.535769023614672

Epoch: 5| Step: 6
Training loss: 1.9284355643013409
Validation loss: 2.515703626553091

Epoch: 5| Step: 7
Training loss: 2.5376555785042076
Validation loss: 2.522006452838045

Epoch: 5| Step: 8
Training loss: 3.076395391185157
Validation loss: 2.5192728309289567

Epoch: 5| Step: 9
Training loss: 2.6718430545079483
Validation loss: 2.5009112366318917

Epoch: 5| Step: 10
Training loss: 2.1255256900172577
Validation loss: 2.4967326608667353

Epoch: 5| Step: 11
Training loss: 3.2301789860692636
Validation loss: 2.500188478676509

Epoch: 193| Step: 0
Training loss: 2.76593791678506
Validation loss: 2.489655083988374

Epoch: 5| Step: 1
Training loss: 2.445693013868404
Validation loss: 2.4897938536907103

Epoch: 5| Step: 2
Training loss: 2.449270050144315
Validation loss: 2.4889169756216614

Epoch: 5| Step: 3
Training loss: 2.1819681247931935
Validation loss: 2.493448598074997

Epoch: 5| Step: 4
Training loss: 2.8447438274557615
Validation loss: 2.49557814150538

Epoch: 5| Step: 5
Training loss: 2.509026634576671
Validation loss: 2.497536228013911

Epoch: 5| Step: 6
Training loss: 2.6549566373858022
Validation loss: 2.498926369283872

Epoch: 5| Step: 7
Training loss: 2.774949556184342
Validation loss: 2.4919703896243353

Epoch: 5| Step: 8
Training loss: 2.4552840918040553
Validation loss: 2.4972104642541963

Epoch: 5| Step: 9
Training loss: 2.6891183637881935
Validation loss: 2.503446920698833

Epoch: 5| Step: 10
Training loss: 2.5728836881143105
Validation loss: 2.495535567729064

Epoch: 5| Step: 11
Training loss: 1.8255435943998493
Validation loss: 2.4951080700333867

Epoch: 194| Step: 0
Training loss: 2.1834665442249754
Validation loss: 2.4936468003445875

Epoch: 5| Step: 1
Training loss: 2.522547987300952
Validation loss: 2.4980433754577063

Epoch: 5| Step: 2
Training loss: 2.0358606682637927
Validation loss: 2.4957926354144293

Epoch: 5| Step: 3
Training loss: 2.2500998156977454
Validation loss: 2.492214358194017

Epoch: 5| Step: 4
Training loss: 2.9658339785555246
Validation loss: 2.4849178153058324

Epoch: 5| Step: 5
Training loss: 2.211881833546935
Validation loss: 2.4847698337771362

Epoch: 5| Step: 6
Training loss: 2.5829121851391186
Validation loss: 2.4816881041265906

Epoch: 5| Step: 7
Training loss: 2.6468293925818225
Validation loss: 2.4795391032751044

Epoch: 5| Step: 8
Training loss: 2.793891466215876
Validation loss: 2.4716844542341967

Epoch: 5| Step: 9
Training loss: 2.9002694563810274
Validation loss: 2.474532634264778

Epoch: 5| Step: 10
Training loss: 2.6664910755362197
Validation loss: 2.466613432485911

Epoch: 5| Step: 11
Training loss: 2.9042581274735366
Validation loss: 2.4689142317407806

Epoch: 195| Step: 0
Training loss: 2.417552018498464
Validation loss: 2.47544237030285

Epoch: 5| Step: 1
Training loss: 2.164647873573192
Validation loss: 2.4668903469036465

Epoch: 5| Step: 2
Training loss: 2.6843723461417777
Validation loss: 2.478051236543271

Epoch: 5| Step: 3
Training loss: 2.2528766680407935
Validation loss: 2.4700645697155257

Epoch: 5| Step: 4
Training loss: 2.490937209334504
Validation loss: 2.4663848613415364

Epoch: 5| Step: 5
Training loss: 2.4541801564526446
Validation loss: 2.478972524900524

Epoch: 5| Step: 6
Training loss: 2.52170836549291
Validation loss: 2.484445434947386

Epoch: 5| Step: 7
Training loss: 2.8643909921518063
Validation loss: 2.4823414699239588

Epoch: 5| Step: 8
Training loss: 2.8789291070369774
Validation loss: 2.4875317597078976

Epoch: 5| Step: 9
Training loss: 2.5162873906533094
Validation loss: 2.4884284558312095

Epoch: 5| Step: 10
Training loss: 1.8347377022106146
Validation loss: 2.483435475139113

Epoch: 5| Step: 11
Training loss: 2.962538796987683
Validation loss: 2.4775507225851867

Epoch: 196| Step: 0
Training loss: 2.715772906139644
Validation loss: 2.4795422042523616

Epoch: 5| Step: 1
Training loss: 2.0639631687840674
Validation loss: 2.4749434159614845

Epoch: 5| Step: 2
Training loss: 1.9803477594560428
Validation loss: 2.4762433806152297

Epoch: 5| Step: 3
Training loss: 1.995248096594687
Validation loss: 2.4735914473621006

Epoch: 5| Step: 4
Training loss: 2.4039868698015434
Validation loss: 2.46834285614045

Epoch: 5| Step: 5
Training loss: 3.1340325089492738
Validation loss: 2.471302760842041

Epoch: 5| Step: 6
Training loss: 2.780674135404641
Validation loss: 2.473147174297802

Epoch: 5| Step: 7
Training loss: 2.679627887741179
Validation loss: 2.4670071546221193

Epoch: 5| Step: 8
Training loss: 2.806663306031137
Validation loss: 2.4744228903965038

Epoch: 5| Step: 9
Training loss: 2.3205315586040927
Validation loss: 2.475055508842037

Epoch: 5| Step: 10
Training loss: 2.153328727307821
Validation loss: 2.472478927513507

Epoch: 5| Step: 11
Training loss: 1.5091048320710851
Validation loss: 2.4814252155745695

Epoch: 197| Step: 0
Training loss: 1.688817463620713
Validation loss: 2.482547391674096

Epoch: 5| Step: 1
Training loss: 2.275195932858959
Validation loss: 2.4887127225221337

Epoch: 5| Step: 2
Training loss: 2.5300915739954424
Validation loss: 2.4933538348477886

Epoch: 5| Step: 3
Training loss: 2.5511433226109506
Validation loss: 2.5005647855801283

Epoch: 5| Step: 4
Training loss: 2.063237260770602
Validation loss: 2.495613752448517

Epoch: 5| Step: 5
Training loss: 2.8986498814014654
Validation loss: 2.4969247480424914

Epoch: 5| Step: 6
Training loss: 2.8638044558425615
Validation loss: 2.497009547129142

Epoch: 5| Step: 7
Training loss: 2.013387458317949
Validation loss: 2.507673495392597

Epoch: 5| Step: 8
Training loss: 2.651596480934661
Validation loss: 2.50443588344671

Epoch: 5| Step: 9
Training loss: 2.03452846340876
Validation loss: 2.5181069046895335

Epoch: 5| Step: 10
Training loss: 3.0418650592918204
Validation loss: 2.5135661757267984

Epoch: 5| Step: 11
Training loss: 0.6650192773147336
Validation loss: 2.5076795247634105

Epoch: 198| Step: 0
Training loss: 2.122325560609702
Validation loss: 2.514785101179925

Epoch: 5| Step: 1
Training loss: 2.3481159490066177
Validation loss: 2.5221774062148996

Epoch: 5| Step: 2
Training loss: 2.480658672601124
Validation loss: 2.5275533668815453

Epoch: 5| Step: 3
Training loss: 2.2608084156066024
Validation loss: 2.5286664061621202

Epoch: 5| Step: 4
Training loss: 1.9066650063945416
Validation loss: 2.5253534749448714

Epoch: 5| Step: 5
Training loss: 2.598217620997285
Validation loss: 2.529027147283643

Epoch: 5| Step: 6
Training loss: 2.8016345906808953
Validation loss: 2.517775905387856

Epoch: 5| Step: 7
Training loss: 2.356747711798845
Validation loss: 2.509041767155856

Epoch: 5| Step: 8
Training loss: 2.915038571765034
Validation loss: 2.503071438013507

Epoch: 5| Step: 9
Training loss: 2.6668620236682083
Validation loss: 2.5081564923826867

Epoch: 5| Step: 10
Training loss: 2.2213328197626723
Validation loss: 2.4993284913073213

Epoch: 5| Step: 11
Training loss: 1.6213286080343838
Validation loss: 2.50440329757607

Epoch: 199| Step: 0
Training loss: 2.6748504133379365
Validation loss: 2.5007159995921775

Epoch: 5| Step: 1
Training loss: 2.290799676290109
Validation loss: 2.500872797404104

Epoch: 5| Step: 2
Training loss: 2.8157458754662286
Validation loss: 2.4940904310050396

Epoch: 5| Step: 3
Training loss: 2.6791157015100406
Validation loss: 2.501858358303213

Epoch: 5| Step: 4
Training loss: 2.723962019169625
Validation loss: 2.5053464265911454

Epoch: 5| Step: 5
Training loss: 2.363516400200628
Validation loss: 2.5032160457859685

Epoch: 5| Step: 6
Training loss: 2.2192824893320937
Validation loss: 2.498044441227924

Epoch: 5| Step: 7
Training loss: 2.3535323399626877
Validation loss: 2.5000538780446653

Epoch: 5| Step: 8
Training loss: 2.197067156835286
Validation loss: 2.5081497868734943

Epoch: 5| Step: 9
Training loss: 2.18577038642201
Validation loss: 2.506997044211959

Epoch: 5| Step: 10
Training loss: 1.9960351028337113
Validation loss: 2.511139493903059

Epoch: 5| Step: 11
Training loss: 2.7064406506204435
Validation loss: 2.5157775042887653

Epoch: 200| Step: 0
Training loss: 2.4771389937076056
Validation loss: 2.5492202593555087

Epoch: 5| Step: 1
Training loss: 2.476385164379895
Validation loss: 2.5543171442105335

Epoch: 5| Step: 2
Training loss: 2.2820530353304216
Validation loss: 2.5475297449001997

Epoch: 5| Step: 3
Training loss: 2.796194835625167
Validation loss: 2.5551528273560526

Epoch: 5| Step: 4
Training loss: 2.926080787716757
Validation loss: 2.557825088547675

Epoch: 5| Step: 5
Training loss: 2.1305732569925553
Validation loss: 2.5358655786569146

Epoch: 5| Step: 6
Training loss: 2.6755830788842494
Validation loss: 2.5199437239963234

Epoch: 5| Step: 7
Training loss: 2.379084738563934
Validation loss: 2.5066478318367476

Epoch: 5| Step: 8
Training loss: 1.7144142255978785
Validation loss: 2.4926531445368654

Epoch: 5| Step: 9
Training loss: 2.130302097585584
Validation loss: 2.486539725314052

Epoch: 5| Step: 10
Training loss: 2.390519682116409
Validation loss: 2.482699559025423

Epoch: 5| Step: 11
Training loss: 3.5017776062313577
Validation loss: 2.4843017039493054

Epoch: 201| Step: 0
Training loss: 2.8622430477839234
Validation loss: 2.479470460107157

Epoch: 5| Step: 1
Training loss: 2.5139643714583375
Validation loss: 2.4867184021270696

Epoch: 5| Step: 2
Training loss: 2.0386593007132814
Validation loss: 2.4885797606009312

Epoch: 5| Step: 3
Training loss: 2.908625954350572
Validation loss: 2.4869688676284656

Epoch: 5| Step: 4
Training loss: 1.9492766041091738
Validation loss: 2.489314736490743

Epoch: 5| Step: 5
Training loss: 2.4159279933076765
Validation loss: 2.493046013776347

Epoch: 5| Step: 6
Training loss: 2.7060350398792776
Validation loss: 2.495186033250907

Epoch: 5| Step: 7
Training loss: 2.320370657349337
Validation loss: 2.493705737486785

Epoch: 5| Step: 8
Training loss: 2.741055768564258
Validation loss: 2.491116691310965

Epoch: 5| Step: 9
Training loss: 2.3296045300083343
Validation loss: 2.4955702657100676

Epoch: 5| Step: 10
Training loss: 1.8550439609346518
Validation loss: 2.505538753415357

Epoch: 5| Step: 11
Training loss: 1.267924069071579
Validation loss: 2.507241723852597

Epoch: 202| Step: 0
Training loss: 2.612009694208496
Validation loss: 2.5182504123763274

Epoch: 5| Step: 1
Training loss: 2.0716298644443145
Validation loss: 2.5311691718677394

Epoch: 5| Step: 2
Training loss: 2.4554892645624307
Validation loss: 2.541321638535796

Epoch: 5| Step: 3
Training loss: 2.2806509616217774
Validation loss: 2.535643132600742

Epoch: 5| Step: 4
Training loss: 2.4607776408272275
Validation loss: 2.539820287058875

Epoch: 5| Step: 5
Training loss: 2.421386177199854
Validation loss: 2.5179430152397795

Epoch: 5| Step: 6
Training loss: 2.805139191789766
Validation loss: 2.4893357673890906

Epoch: 5| Step: 7
Training loss: 2.1531428188256574
Validation loss: 2.477410513239801

Epoch: 5| Step: 8
Training loss: 2.757427415627402
Validation loss: 2.491585625943433

Epoch: 5| Step: 9
Training loss: 2.364874285528205
Validation loss: 2.4920225617010963

Epoch: 5| Step: 10
Training loss: 2.2306699110935937
Validation loss: 2.4970490762172814

Epoch: 5| Step: 11
Training loss: 2.1447775999784082
Validation loss: 2.4794540051764016

Epoch: 203| Step: 0
Training loss: 2.7198000228521657
Validation loss: 2.4978895239724737

Epoch: 5| Step: 1
Training loss: 2.9789448013032107
Validation loss: 2.494573441572846

Epoch: 5| Step: 2
Training loss: 2.1828135835157476
Validation loss: 2.5038639844639055

Epoch: 5| Step: 3
Training loss: 2.5189866061337254
Validation loss: 2.5066184412809984

Epoch: 5| Step: 4
Training loss: 2.138231596197725
Validation loss: 2.5278572806814856

Epoch: 5| Step: 5
Training loss: 1.9827222173771917
Validation loss: 2.543327032848452

Epoch: 5| Step: 6
Training loss: 2.086632087876013
Validation loss: 2.554002333597916

Epoch: 5| Step: 7
Training loss: 1.7746862644648698
Validation loss: 2.545664240116866

Epoch: 5| Step: 8
Training loss: 2.579603476400779
Validation loss: 2.5399745222626122

Epoch: 5| Step: 9
Training loss: 2.9164343786837477
Validation loss: 2.5238232391598254

Epoch: 5| Step: 10
Training loss: 2.2999040003105633
Validation loss: 2.511677703601135

Epoch: 5| Step: 11
Training loss: 1.9300552203130463
Validation loss: 2.539603389935132

Epoch: 204| Step: 0
Training loss: 2.7092422329625077
Validation loss: 2.510856553604527

Epoch: 5| Step: 1
Training loss: 2.612694644521528
Validation loss: 2.5191925964657242

Epoch: 5| Step: 2
Training loss: 2.2752693897087988
Validation loss: 2.533876426157289

Epoch: 5| Step: 3
Training loss: 2.343758850080947
Validation loss: 2.5311648664561233

Epoch: 5| Step: 4
Training loss: 2.600086423464586
Validation loss: 2.552191698277885

Epoch: 5| Step: 5
Training loss: 1.9658973856871664
Validation loss: 2.5422195819408326

Epoch: 5| Step: 6
Training loss: 2.51876890492503
Validation loss: 2.524760384725597

Epoch: 5| Step: 7
Training loss: 2.1927906905871866
Validation loss: 2.5138914283601452

Epoch: 5| Step: 8
Training loss: 2.526396442681889
Validation loss: 2.4907030649367545

Epoch: 5| Step: 9
Training loss: 2.6445598290841734
Validation loss: 2.497730922129631

Epoch: 5| Step: 10
Training loss: 2.5263015036639134
Validation loss: 2.503687804914968

Epoch: 5| Step: 11
Training loss: 2.0512187963294015
Validation loss: 2.4871310535538798

Epoch: 205| Step: 0
Training loss: 1.937479449747682
Validation loss: 2.4883926502404785

Epoch: 5| Step: 1
Training loss: 2.63104369743362
Validation loss: 2.490952399962275

Epoch: 5| Step: 2
Training loss: 2.366304843627734
Validation loss: 2.498409631640101

Epoch: 5| Step: 3
Training loss: 2.0443791905415294
Validation loss: 2.4908543192784607

Epoch: 5| Step: 4
Training loss: 2.419246600919044
Validation loss: 2.496999290788046

Epoch: 5| Step: 5
Training loss: 2.5863908906138477
Validation loss: 2.5091858467522727

Epoch: 5| Step: 6
Training loss: 2.3908709231276224
Validation loss: 2.5036069757599115

Epoch: 5| Step: 7
Training loss: 2.5343768739517
Validation loss: 2.49727243006536

Epoch: 5| Step: 8
Training loss: 2.507518144962156
Validation loss: 2.5055836669336853

Epoch: 5| Step: 9
Training loss: 2.7417991776218247
Validation loss: 2.5206271762461734

Epoch: 5| Step: 10
Training loss: 2.3656731221433147
Validation loss: 2.5117999786009424

Epoch: 5| Step: 11
Training loss: 1.835515659648919
Validation loss: 2.5275832489697168

Epoch: 206| Step: 0
Training loss: 2.638036870327123
Validation loss: 2.5265627818362035

Epoch: 5| Step: 1
Training loss: 2.164040245189607
Validation loss: 2.5296532417916633

Epoch: 5| Step: 2
Training loss: 2.401898400189984
Validation loss: 2.5221077847415447

Epoch: 5| Step: 3
Training loss: 2.1705951899297444
Validation loss: 2.520086695438743

Epoch: 5| Step: 4
Training loss: 2.4079185744678098
Validation loss: 2.5036021666385415

Epoch: 5| Step: 5
Training loss: 1.9655005265504242
Validation loss: 2.4939758716357785

Epoch: 5| Step: 6
Training loss: 3.1000822363989835
Validation loss: 2.4947205269903616

Epoch: 5| Step: 7
Training loss: 2.6459721706538706
Validation loss: 2.484509326494307

Epoch: 5| Step: 8
Training loss: 2.1724540981276634
Validation loss: 2.4990681878659964

Epoch: 5| Step: 9
Training loss: 2.0812132411150657
Validation loss: 2.491195704584169

Epoch: 5| Step: 10
Training loss: 2.5681022254229227
Validation loss: 2.501866875421764

Epoch: 5| Step: 11
Training loss: 3.0720730070637936
Validation loss: 2.5164371407653894

Epoch: 207| Step: 0
Training loss: 2.427003414382702
Validation loss: 2.5203955180808633

Epoch: 5| Step: 1
Training loss: 1.795589617530955
Validation loss: 2.5110927887464265

Epoch: 5| Step: 2
Training loss: 2.2560193818389305
Validation loss: 2.5209958651981745

Epoch: 5| Step: 3
Training loss: 2.598234505216552
Validation loss: 2.5219439287940624

Epoch: 5| Step: 4
Training loss: 2.0859629883084048
Validation loss: 2.5254321762407606

Epoch: 5| Step: 5
Training loss: 2.557807720088978
Validation loss: 2.526171817900464

Epoch: 5| Step: 6
Training loss: 2.7633350611897196
Validation loss: 2.528055038867288

Epoch: 5| Step: 7
Training loss: 2.8517387440184176
Validation loss: 2.5189589843631373

Epoch: 5| Step: 8
Training loss: 2.3038107028524797
Validation loss: 2.5218121320285274

Epoch: 5| Step: 9
Training loss: 2.339805640927659
Validation loss: 2.5232761004691824

Epoch: 5| Step: 10
Training loss: 2.3250901071458836
Validation loss: 2.517464239850799

Epoch: 5| Step: 11
Training loss: 2.2207801020423426
Validation loss: 2.5212866924555577

Epoch: 208| Step: 0
Training loss: 2.547288357943722
Validation loss: 2.5186173627336452

Epoch: 5| Step: 1
Training loss: 2.0170880116602365
Validation loss: 2.51261607980572

Epoch: 5| Step: 2
Training loss: 2.359134687096689
Validation loss: 2.5252396100043915

Epoch: 5| Step: 3
Training loss: 2.0208475040319103
Validation loss: 2.5341562807818856

Epoch: 5| Step: 4
Training loss: 2.8987392052584755
Validation loss: 2.5293947964323955

Epoch: 5| Step: 5
Training loss: 2.650132528625881
Validation loss: 2.5253832414503896

Epoch: 5| Step: 6
Training loss: 2.3498540102475127
Validation loss: 2.5240415198618487

Epoch: 5| Step: 7
Training loss: 2.1838108016285593
Validation loss: 2.527404513210853

Epoch: 5| Step: 8
Training loss: 1.9061800834466203
Validation loss: 2.528184195801141

Epoch: 5| Step: 9
Training loss: 2.69082666365749
Validation loss: 2.520939010317654

Epoch: 5| Step: 10
Training loss: 2.743654472756226
Validation loss: 2.5244427775871774

Epoch: 5| Step: 11
Training loss: 2.073939072886582
Validation loss: 2.5005310090698933

Epoch: 209| Step: 0
Training loss: 2.4585970936459427
Validation loss: 2.5079389165941364

Epoch: 5| Step: 1
Training loss: 1.7615386126463406
Validation loss: 2.4989538904818156

Epoch: 5| Step: 2
Training loss: 2.3008779301432236
Validation loss: 2.496626628415482

Epoch: 5| Step: 3
Training loss: 2.881590876409055
Validation loss: 2.4952455770029562

Epoch: 5| Step: 4
Training loss: 2.160316282004433
Validation loss: 2.4958823029411334

Epoch: 5| Step: 5
Training loss: 2.5388686825063873
Validation loss: 2.49847847414086

Epoch: 5| Step: 6
Training loss: 2.8484560415027533
Validation loss: 2.4998052759629577

Epoch: 5| Step: 7
Training loss: 2.423477725415172
Validation loss: 2.4998115706958157

Epoch: 5| Step: 8
Training loss: 2.1141796635022887
Validation loss: 2.4980272258018568

Epoch: 5| Step: 9
Training loss: 2.658818159068183
Validation loss: 2.501883313974185

Epoch: 5| Step: 10
Training loss: 2.1353016395912348
Validation loss: 2.5010087838977673

Epoch: 5| Step: 11
Training loss: 3.079997775832525
Validation loss: 2.513255177905033

Epoch: 210| Step: 0
Training loss: 2.501884227223931
Validation loss: 2.5274069933910934

Epoch: 5| Step: 1
Training loss: 2.345108452344854
Validation loss: 2.5402448473773203

Epoch: 5| Step: 2
Training loss: 2.3805795681945545
Validation loss: 2.533909628804436

Epoch: 5| Step: 3
Training loss: 2.3226820024640293
Validation loss: 2.541678515912144

Epoch: 5| Step: 4
Training loss: 2.424641856066167
Validation loss: 2.5363162442827036

Epoch: 5| Step: 5
Training loss: 2.120502649494037
Validation loss: 2.544030549420763

Epoch: 5| Step: 6
Training loss: 2.6950242040393007
Validation loss: 2.5464798907518293

Epoch: 5| Step: 7
Training loss: 2.670105465295478
Validation loss: 2.535039308316571

Epoch: 5| Step: 8
Training loss: 2.1506821991670377
Validation loss: 2.515707054142618

Epoch: 5| Step: 9
Training loss: 2.3711569964600767
Validation loss: 2.4971550688509168

Epoch: 5| Step: 10
Training loss: 2.7698609407409753
Validation loss: 2.4962765701833387

Epoch: 5| Step: 11
Training loss: 1.6321238110317315
Validation loss: 2.4905141675755837

Epoch: 211| Step: 0
Training loss: 2.257880925920312
Validation loss: 2.489566776321665

Epoch: 5| Step: 1
Training loss: 2.799573395791811
Validation loss: 2.4822810603555645

Epoch: 5| Step: 2
Training loss: 2.892634172946191
Validation loss: 2.4908627344359333

Epoch: 5| Step: 3
Training loss: 2.59393337474782
Validation loss: 2.4994619108318368

Epoch: 5| Step: 4
Training loss: 2.3243399965092366
Validation loss: 2.4901690186544614

Epoch: 5| Step: 5
Training loss: 2.2998936338293365
Validation loss: 2.4949412344189468

Epoch: 5| Step: 6
Training loss: 2.058883733430133
Validation loss: 2.4936264770751775

Epoch: 5| Step: 7
Training loss: 2.244280858053247
Validation loss: 2.492381471999695

Epoch: 5| Step: 8
Training loss: 2.3281611497363848
Validation loss: 2.5029951055528157

Epoch: 5| Step: 9
Training loss: 2.049871101048626
Validation loss: 2.4997761983832936

Epoch: 5| Step: 10
Training loss: 2.570213617434474
Validation loss: 2.502926313854677

Epoch: 5| Step: 11
Training loss: 2.6762627161499846
Validation loss: 2.5048904190790733

Epoch: 212| Step: 0
Training loss: 2.0942066890212994
Validation loss: 2.512026426337528

Epoch: 5| Step: 1
Training loss: 2.647442025764711
Validation loss: 2.5160963631748463

Epoch: 5| Step: 2
Training loss: 1.8480242308312025
Validation loss: 2.5187408528347217

Epoch: 5| Step: 3
Training loss: 2.2247691645518577
Validation loss: 2.524462772098669

Epoch: 5| Step: 4
Training loss: 2.3041191822790417
Validation loss: 2.516507201374133

Epoch: 5| Step: 5
Training loss: 2.099465838116906
Validation loss: 2.5217179422424323

Epoch: 5| Step: 6
Training loss: 2.489135308167666
Validation loss: 2.5439623304348213

Epoch: 5| Step: 7
Training loss: 2.155096768465726
Validation loss: 2.5367904513538555

Epoch: 5| Step: 8
Training loss: 2.6551535643511968
Validation loss: 2.5371074368158917

Epoch: 5| Step: 9
Training loss: 2.660014816759188
Validation loss: 2.5293243210333194

Epoch: 5| Step: 10
Training loss: 2.9361700740376597
Validation loss: 2.5330619056964068

Epoch: 5| Step: 11
Training loss: 2.4214220177119286
Validation loss: 2.540244178649421

Epoch: 213| Step: 0
Training loss: 2.4670468986701564
Validation loss: 2.540010332089033

Epoch: 5| Step: 1
Training loss: 2.600352237756742
Validation loss: 2.5335739440802545

Epoch: 5| Step: 2
Training loss: 2.7469120027482288
Validation loss: 2.5167063290479024

Epoch: 5| Step: 3
Training loss: 2.5016647518115898
Validation loss: 2.5215719273321198

Epoch: 5| Step: 4
Training loss: 2.6476269947460698
Validation loss: 2.5172339007510995

Epoch: 5| Step: 5
Training loss: 2.3408161365406537
Validation loss: 2.4998524662036505

Epoch: 5| Step: 6
Training loss: 2.834301353095018
Validation loss: 2.507681457962021

Epoch: 5| Step: 7
Training loss: 1.8967604274179053
Validation loss: 2.5067100121761277

Epoch: 5| Step: 8
Training loss: 2.0526193864231184
Validation loss: 2.5264961987322194

Epoch: 5| Step: 9
Training loss: 1.6988819007668825
Validation loss: 2.5230667109540725

Epoch: 5| Step: 10
Training loss: 2.4290581283618335
Validation loss: 2.5322342046329838

Epoch: 5| Step: 11
Training loss: 1.2247992798763876
Validation loss: 2.5336712767621763

Epoch: 214| Step: 0
Training loss: 2.7225800644492395
Validation loss: 2.5512390076485967

Epoch: 5| Step: 1
Training loss: 2.531637750761416
Validation loss: 2.548911694244318

Epoch: 5| Step: 2
Training loss: 1.811229391987771
Validation loss: 2.580496369815681

Epoch: 5| Step: 3
Training loss: 2.278955219881706
Validation loss: 2.5905078402824375

Epoch: 5| Step: 4
Training loss: 2.6225516390739334
Validation loss: 2.600080787950222

Epoch: 5| Step: 5
Training loss: 2.6336815189389706
Validation loss: 2.573481217248289

Epoch: 5| Step: 6
Training loss: 1.8718039293760087
Validation loss: 2.5503802643959537

Epoch: 5| Step: 7
Training loss: 2.5482208814773335
Validation loss: 2.5318655513605015

Epoch: 5| Step: 8
Training loss: 2.4050572399219576
Validation loss: 2.5159988421712645

Epoch: 5| Step: 9
Training loss: 2.141145851644375
Validation loss: 2.511886551523457

Epoch: 5| Step: 10
Training loss: 2.9923117987808436
Validation loss: 2.4984374328829575

Epoch: 5| Step: 11
Training loss: 2.3197979597381164
Validation loss: 2.5020689727779772

Epoch: 215| Step: 0
Training loss: 2.931496674461762
Validation loss: 2.5021620104127336

Epoch: 5| Step: 1
Training loss: 2.3542344637760504
Validation loss: 2.5090166292864664

Epoch: 5| Step: 2
Training loss: 2.6817013482916856
Validation loss: 2.5075329063211242

Epoch: 5| Step: 3
Training loss: 2.514292014333957
Validation loss: 2.501475067882256

Epoch: 5| Step: 4
Training loss: 2.2656277360570765
Validation loss: 2.508072361302241

Epoch: 5| Step: 5
Training loss: 2.335825837697489
Validation loss: 2.5147589343833463

Epoch: 5| Step: 6
Training loss: 1.9806432402599359
Validation loss: 2.524645894938549

Epoch: 5| Step: 7
Training loss: 1.9657741641650754
Validation loss: 2.520117107557804

Epoch: 5| Step: 8
Training loss: 2.6359987081081715
Validation loss: 2.539334792184131

Epoch: 5| Step: 9
Training loss: 2.4801056843973464
Validation loss: 2.5427596108281176

Epoch: 5| Step: 10
Training loss: 2.201009289102741
Validation loss: 2.5347916311982694

Epoch: 5| Step: 11
Training loss: 1.9389242044540256
Validation loss: 2.5442784770328855

Epoch: 216| Step: 0
Training loss: 2.4853239346450655
Validation loss: 2.535702212127121

Epoch: 5| Step: 1
Training loss: 1.7596556769941551
Validation loss: 2.542462440633402

Epoch: 5| Step: 2
Training loss: 2.7510164289798578
Validation loss: 2.5419718658146917

Epoch: 5| Step: 3
Training loss: 2.186445690577065
Validation loss: 2.536532380722344

Epoch: 5| Step: 4
Training loss: 2.3351891380998375
Validation loss: 2.5341399653365166

Epoch: 5| Step: 5
Training loss: 2.0859619596383117
Validation loss: 2.5330429163742263

Epoch: 5| Step: 6
Training loss: 2.0887888875431218
Validation loss: 2.536016360451496

Epoch: 5| Step: 7
Training loss: 2.811145541097946
Validation loss: 2.521329434236826

Epoch: 5| Step: 8
Training loss: 2.8140480019949443
Validation loss: 2.5087633043755924

Epoch: 5| Step: 9
Training loss: 2.475580640557696
Validation loss: 2.514849276623989

Epoch: 5| Step: 10
Training loss: 2.269441008620331
Validation loss: 2.512634173807216

Epoch: 5| Step: 11
Training loss: 1.7357465115335895
Validation loss: 2.498819982672354

Epoch: 217| Step: 0
Training loss: 2.4355791788780903
Validation loss: 2.5006281917805584

Epoch: 5| Step: 1
Training loss: 2.897724238647396
Validation loss: 2.5153647578428586

Epoch: 5| Step: 2
Training loss: 2.223369463846734
Validation loss: 2.526541934994225

Epoch: 5| Step: 3
Training loss: 2.4387344755600506
Validation loss: 2.5275254299734646

Epoch: 5| Step: 4
Training loss: 2.516430459295414
Validation loss: 2.5238015312852715

Epoch: 5| Step: 5
Training loss: 2.42080231568452
Validation loss: 2.5295914997548556

Epoch: 5| Step: 6
Training loss: 2.3376091426725405
Validation loss: 2.525562883340245

Epoch: 5| Step: 7
Training loss: 2.5289263951038645
Validation loss: 2.522483338224432

Epoch: 5| Step: 8
Training loss: 2.0270904206337943
Validation loss: 2.5210316983248573

Epoch: 5| Step: 9
Training loss: 2.416316982708455
Validation loss: 2.5137998068699847

Epoch: 5| Step: 10
Training loss: 1.982139770279571
Validation loss: 2.5246130623215772

Epoch: 5| Step: 11
Training loss: 1.6472319764392935
Validation loss: 2.5319153613725893

Epoch: 218| Step: 0
Training loss: 2.2014862892058353
Validation loss: 2.54857406032031

Epoch: 5| Step: 1
Training loss: 2.322748517392451
Validation loss: 2.5424283181459835

Epoch: 5| Step: 2
Training loss: 2.3130757414162995
Validation loss: 2.541474031485928

Epoch: 5| Step: 3
Training loss: 2.2725116115898705
Validation loss: 2.541973507187613

Epoch: 5| Step: 4
Training loss: 1.8696181306207167
Validation loss: 2.5495995183689595

Epoch: 5| Step: 5
Training loss: 2.9263667703605454
Validation loss: 2.5311142567158806

Epoch: 5| Step: 6
Training loss: 3.1452178016047236
Validation loss: 2.527654767245579

Epoch: 5| Step: 7
Training loss: 2.099776746599286
Validation loss: 2.5286144460241964

Epoch: 5| Step: 8
Training loss: 2.484484688118811
Validation loss: 2.5292085217296782

Epoch: 5| Step: 9
Training loss: 2.1960818208623554
Validation loss: 2.538323651921709

Epoch: 5| Step: 10
Training loss: 2.245893545764957
Validation loss: 2.5317963297070927

Epoch: 5| Step: 11
Training loss: 1.5990388665643644
Validation loss: 2.526664591535087

Epoch: 219| Step: 0
Training loss: 1.9807907534933507
Validation loss: 2.518502790910594

Epoch: 5| Step: 1
Training loss: 2.1576145664177413
Validation loss: 2.5306973776371633

Epoch: 5| Step: 2
Training loss: 2.637810646312267
Validation loss: 2.5238635684706328

Epoch: 5| Step: 3
Training loss: 2.8895131215148924
Validation loss: 2.524276928401925

Epoch: 5| Step: 4
Training loss: 2.435050907738647
Validation loss: 2.528530995635416

Epoch: 5| Step: 5
Training loss: 1.9535172335643436
Validation loss: 2.5220599946873223

Epoch: 5| Step: 6
Training loss: 2.6973145941087933
Validation loss: 2.524017786912468

Epoch: 5| Step: 7
Training loss: 2.129215994883716
Validation loss: 2.5256424867030463

Epoch: 5| Step: 8
Training loss: 2.49542867429499
Validation loss: 2.5386911991258696

Epoch: 5| Step: 9
Training loss: 2.353180895542975
Validation loss: 2.5376512566947116

Epoch: 5| Step: 10
Training loss: 2.1483320730524778
Validation loss: 2.5462166163391418

Epoch: 5| Step: 11
Training loss: 2.867717808214621
Validation loss: 2.547090451073391

Epoch: 220| Step: 0
Training loss: 2.5870595842834887
Validation loss: 2.5528792807388694

Epoch: 5| Step: 1
Training loss: 2.30842168847754
Validation loss: 2.57045565344689

Epoch: 5| Step: 2
Training loss: 1.911706463112142
Validation loss: 2.5735648699062117

Epoch: 5| Step: 3
Training loss: 1.8626109583016721
Validation loss: 2.5670143076759606

Epoch: 5| Step: 4
Training loss: 2.2821016159100704
Validation loss: 2.5637569174881683

Epoch: 5| Step: 5
Training loss: 2.29977317189128
Validation loss: 2.550787765549132

Epoch: 5| Step: 6
Training loss: 2.7536317079741073
Validation loss: 2.533585322755499

Epoch: 5| Step: 7
Training loss: 2.3040892778292075
Validation loss: 2.5235072816189796

Epoch: 5| Step: 8
Training loss: 2.4781406320316983
Validation loss: 2.5209427972677

Epoch: 5| Step: 9
Training loss: 2.862786597684472
Validation loss: 2.5223725101942547

Epoch: 5| Step: 10
Training loss: 2.436470009747388
Validation loss: 2.513664018351447

Epoch: 5| Step: 11
Training loss: 1.9810246095702961
Validation loss: 2.511466156483104

Epoch: 221| Step: 0
Training loss: 2.5205307981262557
Validation loss: 2.5040304556841404

Epoch: 5| Step: 1
Training loss: 1.7765912485606474
Validation loss: 2.509590156645548

Epoch: 5| Step: 2
Training loss: 2.393182919414813
Validation loss: 2.5148658080731985

Epoch: 5| Step: 3
Training loss: 3.2991990128797797
Validation loss: 2.5019693326958645

Epoch: 5| Step: 4
Training loss: 2.31275917869019
Validation loss: 2.5058569884592385

Epoch: 5| Step: 5
Training loss: 1.9396309362921613
Validation loss: 2.5057430364213937

Epoch: 5| Step: 6
Training loss: 3.013550988947803
Validation loss: 2.500345309569517

Epoch: 5| Step: 7
Training loss: 1.9303083154757428
Validation loss: 2.517233367981916

Epoch: 5| Step: 8
Training loss: 2.533428808554749
Validation loss: 2.52322618290591

Epoch: 5| Step: 9
Training loss: 2.531692560384534
Validation loss: 2.5402978718554237

Epoch: 5| Step: 10
Training loss: 1.966547142319214
Validation loss: 2.545776016965769

Epoch: 5| Step: 11
Training loss: 2.1212258201214578
Validation loss: 2.5644528964474245

Epoch: 222| Step: 0
Training loss: 1.9177093641232426
Validation loss: 2.559272293697385

Epoch: 5| Step: 1
Training loss: 2.7882499472885653
Validation loss: 2.5536370134807544

Epoch: 5| Step: 2
Training loss: 2.9749963199368326
Validation loss: 2.545118201864032

Epoch: 5| Step: 3
Training loss: 2.4018678271275626
Validation loss: 2.5462331996832277

Epoch: 5| Step: 4
Training loss: 2.0798974760170723
Validation loss: 2.537349972416111

Epoch: 5| Step: 5
Training loss: 2.2918221045289213
Validation loss: 2.5282198268488445

Epoch: 5| Step: 6
Training loss: 1.6995497107198023
Validation loss: 2.5306647825140702

Epoch: 5| Step: 7
Training loss: 2.2814375917826406
Validation loss: 2.521556011101305

Epoch: 5| Step: 8
Training loss: 2.659256703203264
Validation loss: 2.513733407358943

Epoch: 5| Step: 9
Training loss: 2.5366707673041757
Validation loss: 2.5058633829561976

Epoch: 5| Step: 10
Training loss: 2.537179289596735
Validation loss: 2.5208025778058127

Epoch: 5| Step: 11
Training loss: 2.101135096996692
Validation loss: 2.5081746621233125

Epoch: 223| Step: 0
Training loss: 1.7046446014237355
Validation loss: 2.5220495960061555

Epoch: 5| Step: 1
Training loss: 2.8583799204537734
Validation loss: 2.5135401266646356

Epoch: 5| Step: 2
Training loss: 2.793510672539841
Validation loss: 2.5146872132901117

Epoch: 5| Step: 3
Training loss: 2.2784607439708955
Validation loss: 2.5073803562019807

Epoch: 5| Step: 4
Training loss: 2.4418752479211365
Validation loss: 2.5081006970888895

Epoch: 5| Step: 5
Training loss: 1.991041444727405
Validation loss: 2.5085698427074687

Epoch: 5| Step: 6
Training loss: 1.8568280511273108
Validation loss: 2.5160205522187034

Epoch: 5| Step: 7
Training loss: 1.8414778852872367
Validation loss: 2.5398599751428566

Epoch: 5| Step: 8
Training loss: 2.297192817550024
Validation loss: 2.5249455515338446

Epoch: 5| Step: 9
Training loss: 2.8646721473566257
Validation loss: 2.528086793325557

Epoch: 5| Step: 10
Training loss: 2.5764573685923997
Validation loss: 2.548597837448779

Epoch: 5| Step: 11
Training loss: 2.65739828982717
Validation loss: 2.5282504594037274

Epoch: 224| Step: 0
Training loss: 1.62233530322498
Validation loss: 2.562143118748039

Epoch: 5| Step: 1
Training loss: 2.369723934561048
Validation loss: 2.5725755246577218

Epoch: 5| Step: 2
Training loss: 2.724327242337059
Validation loss: 2.582120304235927

Epoch: 5| Step: 3
Training loss: 2.765918349748301
Validation loss: 2.569750008298887

Epoch: 5| Step: 4
Training loss: 2.5823050164824903
Validation loss: 2.578289084559291

Epoch: 5| Step: 5
Training loss: 2.264720762610454
Validation loss: 2.5563320462304913

Epoch: 5| Step: 6
Training loss: 2.408454083734172
Validation loss: 2.5471883046727664

Epoch: 5| Step: 7
Training loss: 2.6798950648759248
Validation loss: 2.5237926788273466

Epoch: 5| Step: 8
Training loss: 2.0302243504317294
Validation loss: 2.5336173843095433

Epoch: 5| Step: 9
Training loss: 2.6607034487334453
Validation loss: 2.520833998015345

Epoch: 5| Step: 10
Training loss: 1.8238243313780755
Validation loss: 2.5123317043755016

Epoch: 5| Step: 11
Training loss: 2.3728529611486535
Validation loss: 2.519879579738566

Epoch: 225| Step: 0
Training loss: 2.286125720834793
Validation loss: 2.527237525841987

Epoch: 5| Step: 1
Training loss: 2.5213594649480573
Validation loss: 2.5312827622291025

Epoch: 5| Step: 2
Training loss: 2.478114078300432
Validation loss: 2.5294155137211063

Epoch: 5| Step: 3
Training loss: 2.566849715240907
Validation loss: 2.5428374882117573

Epoch: 5| Step: 4
Training loss: 2.271003600103833
Validation loss: 2.551078993208928

Epoch: 5| Step: 5
Training loss: 2.277428862615402
Validation loss: 2.547009946216343

Epoch: 5| Step: 6
Training loss: 2.1165822420279508
Validation loss: 2.5489042891891964

Epoch: 5| Step: 7
Training loss: 2.375532492121349
Validation loss: 2.551165627245227

Epoch: 5| Step: 8
Training loss: 2.4625650503793506
Validation loss: 2.558324839508503

Epoch: 5| Step: 9
Training loss: 1.864864804069527
Validation loss: 2.557682137030594

Epoch: 5| Step: 10
Training loss: 2.663702529348192
Validation loss: 2.5669063349909513

Epoch: 5| Step: 11
Training loss: 2.4429177937989484
Validation loss: 2.564958958783896

Epoch: 226| Step: 0
Training loss: 2.3108283522018342
Validation loss: 2.55243877868015

Epoch: 5| Step: 1
Training loss: 1.9767278669938728
Validation loss: 2.531536572721534

Epoch: 5| Step: 2
Training loss: 2.7762746993421374
Validation loss: 2.5277188517499076

Epoch: 5| Step: 3
Training loss: 2.132331766019532
Validation loss: 2.5259403693479276

Epoch: 5| Step: 4
Training loss: 2.813568336184346
Validation loss: 2.521983965158726

Epoch: 5| Step: 5
Training loss: 2.368420572448146
Validation loss: 2.515875564954447

Epoch: 5| Step: 6
Training loss: 2.563977257650033
Validation loss: 2.5156678142813726

Epoch: 5| Step: 7
Training loss: 2.3058483239189695
Validation loss: 2.5266258973342257

Epoch: 5| Step: 8
Training loss: 2.615467474237668
Validation loss: 2.5320853985837704

Epoch: 5| Step: 9
Training loss: 2.087231866667998
Validation loss: 2.531146777367771

Epoch: 5| Step: 10
Training loss: 2.421070186651731
Validation loss: 2.5270077748860236

Epoch: 5| Step: 11
Training loss: 1.3154146438565357
Validation loss: 2.5289606644153313

Epoch: 227| Step: 0
Training loss: 1.7553349646403644
Validation loss: 2.524119447380022

Epoch: 5| Step: 1
Training loss: 2.670327792673534
Validation loss: 2.5401254551485395

Epoch: 5| Step: 2
Training loss: 2.4819526619097094
Validation loss: 2.542818618772678

Epoch: 5| Step: 3
Training loss: 2.6780517746163226
Validation loss: 2.5448630095100295

Epoch: 5| Step: 4
Training loss: 2.6771862935455015
Validation loss: 2.5386512090668774

Epoch: 5| Step: 5
Training loss: 1.7294481423712853
Validation loss: 2.5503216105895414

Epoch: 5| Step: 6
Training loss: 2.6870071491505527
Validation loss: 2.5473219356504844

Epoch: 5| Step: 7
Training loss: 2.4205556906172174
Validation loss: 2.547802832164129

Epoch: 5| Step: 8
Training loss: 2.35133477309143
Validation loss: 2.547623424909309

Epoch: 5| Step: 9
Training loss: 2.00661590186675
Validation loss: 2.5468453130571564

Epoch: 5| Step: 10
Training loss: 2.661026822000486
Validation loss: 2.5235680624113264

Epoch: 5| Step: 11
Training loss: 1.5330651871171166
Validation loss: 2.5248853980077115

Epoch: 228| Step: 0
Training loss: 2.122989938037403
Validation loss: 2.5323100519447856

Epoch: 5| Step: 1
Training loss: 2.2751464712759213
Validation loss: 2.5199852605828905

Epoch: 5| Step: 2
Training loss: 2.721815463793479
Validation loss: 2.5213977139899306

Epoch: 5| Step: 3
Training loss: 2.316006450663858
Validation loss: 2.511975470554755

Epoch: 5| Step: 4
Training loss: 1.665172869096545
Validation loss: 2.510004442383279

Epoch: 5| Step: 5
Training loss: 1.8648660825455692
Validation loss: 2.5126366092621244

Epoch: 5| Step: 6
Training loss: 2.3929722052688387
Validation loss: 2.5026542044621283

Epoch: 5| Step: 7
Training loss: 2.9449158257208397
Validation loss: 2.5082216929202095

Epoch: 5| Step: 8
Training loss: 2.927962871284839
Validation loss: 2.50870567332669

Epoch: 5| Step: 9
Training loss: 2.7424239792976146
Validation loss: 2.5292052970420515

Epoch: 5| Step: 10
Training loss: 2.2270330634538302
Validation loss: 2.5353843182767735

Epoch: 5| Step: 11
Training loss: 1.1657857748224243
Validation loss: 2.5512455804360723

Epoch: 229| Step: 0
Training loss: 2.445069809835597
Validation loss: 2.5637616331449378

Epoch: 5| Step: 1
Training loss: 2.0137819839106577
Validation loss: 2.582569168237922

Epoch: 5| Step: 2
Training loss: 2.5998475433547528
Validation loss: 2.5916187116861598

Epoch: 5| Step: 3
Training loss: 1.9006050200636795
Validation loss: 2.5841749663549263

Epoch: 5| Step: 4
Training loss: 2.5759306846083296
Validation loss: 2.593229593978104

Epoch: 5| Step: 5
Training loss: 1.9184652334626773
Validation loss: 2.5946144287474273

Epoch: 5| Step: 6
Training loss: 2.405463647542747
Validation loss: 2.5820767855031557

Epoch: 5| Step: 7
Training loss: 2.509583795395332
Validation loss: 2.5660794890550482

Epoch: 5| Step: 8
Training loss: 2.55567105926034
Validation loss: 2.5521288783362563

Epoch: 5| Step: 9
Training loss: 2.641058350166534
Validation loss: 2.52835539941666

Epoch: 5| Step: 10
Training loss: 2.5456380824392806
Validation loss: 2.519082873760933

Epoch: 5| Step: 11
Training loss: 1.3287510910819196
Validation loss: 2.5005928012243506

Epoch: 230| Step: 0
Training loss: 2.471043257991942
Validation loss: 2.5099659445214026

Epoch: 5| Step: 1
Training loss: 2.2482718082584707
Validation loss: 2.512966540183303

Epoch: 5| Step: 2
Training loss: 2.422353488046496
Validation loss: 2.517962203262408

Epoch: 5| Step: 3
Training loss: 1.8153032132602527
Validation loss: 2.523646947319583

Epoch: 5| Step: 4
Training loss: 2.827957907108492
Validation loss: 2.526535024672453

Epoch: 5| Step: 5
Training loss: 2.614718966873174
Validation loss: 2.526283560638007

Epoch: 5| Step: 6
Training loss: 2.7390378595126257
Validation loss: 2.5250474067681874

Epoch: 5| Step: 7
Training loss: 2.654698805310637
Validation loss: 2.527096688617115

Epoch: 5| Step: 8
Training loss: 2.5673529099746824
Validation loss: 2.530850139478799

Epoch: 5| Step: 9
Training loss: 2.585965251485578
Validation loss: 2.517265251059165

Epoch: 5| Step: 10
Training loss: 2.382577352959285
Validation loss: 2.5173845002121884

Epoch: 5| Step: 11
Training loss: 1.9868883451317811
Validation loss: 2.5124557307757422

Epoch: 231| Step: 0
Training loss: 2.7572586324682713
Validation loss: 2.5149950142944344

Epoch: 5| Step: 1
Training loss: 2.725451923658054
Validation loss: 2.5075398076029947

Epoch: 5| Step: 2
Training loss: 2.2233056592958564
Validation loss: 2.5217882165862893

Epoch: 5| Step: 3
Training loss: 2.142081106536347
Validation loss: 2.5174390164009455

Epoch: 5| Step: 4
Training loss: 2.1109199799912526
Validation loss: 2.536886877455204

Epoch: 5| Step: 5
Training loss: 2.7198989019118143
Validation loss: 2.545372275846224

Epoch: 5| Step: 6
Training loss: 2.133750178421451
Validation loss: 2.5480939019527504

Epoch: 5| Step: 7
Training loss: 2.5559246089305656
Validation loss: 2.5451555825438144

Epoch: 5| Step: 8
Training loss: 1.6295359466979582
Validation loss: 2.540954954657958

Epoch: 5| Step: 9
Training loss: 2.044101029327299
Validation loss: 2.541644914461036

Epoch: 5| Step: 10
Training loss: 2.587199660852159
Validation loss: 2.551834839121704

Epoch: 5| Step: 11
Training loss: 3.183480514665648
Validation loss: 2.56062105344419

Epoch: 232| Step: 0
Training loss: 2.0901220974096413
Validation loss: 2.5948833456016245

Epoch: 5| Step: 1
Training loss: 2.7112468795793587
Validation loss: 2.614794469315232

Epoch: 5| Step: 2
Training loss: 2.0853830808004954
Validation loss: 2.636851166590852

Epoch: 5| Step: 3
Training loss: 2.517645456909689
Validation loss: 2.6529870655282757

Epoch: 5| Step: 4
Training loss: 2.7457698017772367
Validation loss: 2.6295114305272795

Epoch: 5| Step: 5
Training loss: 2.4264430127812404
Validation loss: 2.6295013018801505

Epoch: 5| Step: 6
Training loss: 2.6934228437330114
Validation loss: 2.5828193619843285

Epoch: 5| Step: 7
Training loss: 2.535806205204089
Validation loss: 2.5720228053063767

Epoch: 5| Step: 8
Training loss: 2.385686623124949
Validation loss: 2.5740413807267366

Epoch: 5| Step: 9
Training loss: 2.1351879710727966
Validation loss: 2.550881715347065

Epoch: 5| Step: 10
Training loss: 1.9729973526447244
Validation loss: 2.5669431777939233

Epoch: 5| Step: 11
Training loss: 2.740022853700321
Validation loss: 2.527141757540266

Epoch: 233| Step: 0
Training loss: 2.346495177801523
Validation loss: 2.545311851805809

Epoch: 5| Step: 1
Training loss: 2.9698082894768
Validation loss: 2.52454479870178

Epoch: 5| Step: 2
Training loss: 2.4025433217091443
Validation loss: 2.534579638095336

Epoch: 5| Step: 3
Training loss: 2.390091481233673
Validation loss: 2.5287528377145563

Epoch: 5| Step: 4
Training loss: 2.081625607250787
Validation loss: 2.51476438187144

Epoch: 5| Step: 5
Training loss: 1.8972033346913721
Validation loss: 2.529637937981147

Epoch: 5| Step: 6
Training loss: 2.2211430498864955
Validation loss: 2.525254566749316

Epoch: 5| Step: 7
Training loss: 2.7480610167268944
Validation loss: 2.523035972151543

Epoch: 5| Step: 8
Training loss: 2.3440716332045484
Validation loss: 2.536683910033894

Epoch: 5| Step: 9
Training loss: 2.152858997850074
Validation loss: 2.5455214174074334

Epoch: 5| Step: 10
Training loss: 2.035140317536004
Validation loss: 2.545088900366775

Epoch: 5| Step: 11
Training loss: 3.6827115795629544
Validation loss: 2.529646911358305

Epoch: 234| Step: 0
Training loss: 2.8678371930272557
Validation loss: 2.5461860614252765

Epoch: 5| Step: 1
Training loss: 1.8920034632499887
Validation loss: 2.533006784501285

Epoch: 5| Step: 2
Training loss: 2.549582884837776
Validation loss: 2.558609369827232

Epoch: 5| Step: 3
Training loss: 2.116651967015124
Validation loss: 2.5590549664812143

Epoch: 5| Step: 4
Training loss: 2.3057967280699265
Validation loss: 2.570699714782428

Epoch: 5| Step: 5
Training loss: 2.8026362066322617
Validation loss: 2.595325933395244

Epoch: 5| Step: 6
Training loss: 2.3966498158498735
Validation loss: 2.5740860367921856

Epoch: 5| Step: 7
Training loss: 2.1312006074881618
Validation loss: 2.5523537875265054

Epoch: 5| Step: 8
Training loss: 2.585679885617365
Validation loss: 2.5465197325138633

Epoch: 5| Step: 9
Training loss: 2.32746836983959
Validation loss: 2.5270061336203122

Epoch: 5| Step: 10
Training loss: 2.2532444979106243
Validation loss: 2.527432581162427

Epoch: 5| Step: 11
Training loss: 2.6927031781991473
Validation loss: 2.5205370686885216

Epoch: 235| Step: 0
Training loss: 2.3201136648352225
Validation loss: 2.5253049457803534

Epoch: 5| Step: 1
Training loss: 2.509876388302441
Validation loss: 2.5154293805628263

Epoch: 5| Step: 2
Training loss: 2.899440704870857
Validation loss: 2.5072126968577675

Epoch: 5| Step: 3
Training loss: 1.7375263074900393
Validation loss: 2.5191509856862146

Epoch: 5| Step: 4
Training loss: 2.3182133385186408
Validation loss: 2.5093488572319838

Epoch: 5| Step: 5
Training loss: 2.046461922700252
Validation loss: 2.5086558657923157

Epoch: 5| Step: 6
Training loss: 2.840653798510252
Validation loss: 2.512938670394807

Epoch: 5| Step: 7
Training loss: 2.4038488123952395
Validation loss: 2.5233736532064754

Epoch: 5| Step: 8
Training loss: 2.5717878658324955
Validation loss: 2.5273297136045714

Epoch: 5| Step: 9
Training loss: 2.0097810468462
Validation loss: 2.5395007963174914

Epoch: 5| Step: 10
Training loss: 2.413843830167558
Validation loss: 2.5487896600892586

Epoch: 5| Step: 11
Training loss: 2.008892792882661
Validation loss: 2.5478675016170493

Epoch: 236| Step: 0
Training loss: 2.1955429444913976
Validation loss: 2.5423711767040524

Epoch: 5| Step: 1
Training loss: 2.591065821858002
Validation loss: 2.5546817254517413

Epoch: 5| Step: 2
Training loss: 2.4012227241837594
Validation loss: 2.5460320152218605

Epoch: 5| Step: 3
Training loss: 2.109714508991262
Validation loss: 2.5510618553022177

Epoch: 5| Step: 4
Training loss: 2.865696823567862
Validation loss: 2.5488109173930735

Epoch: 5| Step: 5
Training loss: 2.641756165329125
Validation loss: 2.5413143520898087

Epoch: 5| Step: 6
Training loss: 2.576028422192931
Validation loss: 2.5428841142687193

Epoch: 5| Step: 7
Training loss: 1.9150891100516645
Validation loss: 2.525202583615076

Epoch: 5| Step: 8
Training loss: 1.8761957806015919
Validation loss: 2.531662157827769

Epoch: 5| Step: 9
Training loss: 2.176905124312396
Validation loss: 2.5175486371286615

Epoch: 5| Step: 10
Training loss: 2.3778635129395953
Validation loss: 2.5139401956337393

Epoch: 5| Step: 11
Training loss: 3.2638410596296525
Validation loss: 2.527067964375539

Epoch: 237| Step: 0
Training loss: 2.474420337035221
Validation loss: 2.5241797608402923

Epoch: 5| Step: 1
Training loss: 2.4610566609915425
Validation loss: 2.537921966269966

Epoch: 5| Step: 2
Training loss: 2.1458151609768548
Validation loss: 2.5460304349924106

Epoch: 5| Step: 3
Training loss: 2.689620046761468
Validation loss: 2.5317871657985687

Epoch: 5| Step: 4
Training loss: 1.8157797768782746
Validation loss: 2.5506027572049597

Epoch: 5| Step: 5
Training loss: 2.4064468699585597
Validation loss: 2.5409934658420403

Epoch: 5| Step: 6
Training loss: 2.3004880760462565
Validation loss: 2.5492317591405476

Epoch: 5| Step: 7
Training loss: 2.550754330830392
Validation loss: 2.53990169644049

Epoch: 5| Step: 8
Training loss: 2.428400121785794
Validation loss: 2.548883570510144

Epoch: 5| Step: 9
Training loss: 2.396328474102045
Validation loss: 2.549951392065777

Epoch: 5| Step: 10
Training loss: 2.1529365180224813
Validation loss: 2.5399550448842314

Epoch: 5| Step: 11
Training loss: 2.1222228808621133
Validation loss: 2.5475689814271667

Epoch: 238| Step: 0
Training loss: 2.097530538816322
Validation loss: 2.5471170306513136

Epoch: 5| Step: 1
Training loss: 2.943665061421807
Validation loss: 2.569616762746598

Epoch: 5| Step: 2
Training loss: 1.8209116199461821
Validation loss: 2.5599792999806557

Epoch: 5| Step: 3
Training loss: 2.227453006886606
Validation loss: 2.560660287230458

Epoch: 5| Step: 4
Training loss: 2.580925455080289
Validation loss: 2.5799333376305844

Epoch: 5| Step: 5
Training loss: 2.5245106780048676
Validation loss: 2.55776985628486

Epoch: 5| Step: 6
Training loss: 2.124330639601877
Validation loss: 2.561788987552845

Epoch: 5| Step: 7
Training loss: 2.651937956520087
Validation loss: 2.56042285796354

Epoch: 5| Step: 8
Training loss: 2.3483359674674054
Validation loss: 2.5795807360208465

Epoch: 5| Step: 9
Training loss: 2.4399117496040126
Validation loss: 2.5505015486168037

Epoch: 5| Step: 10
Training loss: 1.8549863810694802
Validation loss: 2.5607886298469738

Epoch: 5| Step: 11
Training loss: 2.7056930779457335
Validation loss: 2.5285450764365107

Epoch: 239| Step: 0
Training loss: 1.8932068905226036
Validation loss: 2.52978391928938

Epoch: 5| Step: 1
Training loss: 2.520557567130485
Validation loss: 2.519890764003304

Epoch: 5| Step: 2
Training loss: 2.6400983838331404
Validation loss: 2.518461961581267

Epoch: 5| Step: 3
Training loss: 2.1174341037049333
Validation loss: 2.5249095713282603

Epoch: 5| Step: 4
Training loss: 2.3470931560036097
Validation loss: 2.5157230863542046

Epoch: 5| Step: 5
Training loss: 2.988514371268412
Validation loss: 2.515389757234123

Epoch: 5| Step: 6
Training loss: 2.316169199144078
Validation loss: 2.51136599723933

Epoch: 5| Step: 7
Training loss: 2.572651920262831
Validation loss: 2.520544911795984

Epoch: 5| Step: 8
Training loss: 2.5328384878153773
Validation loss: 2.5118609517187043

Epoch: 5| Step: 9
Training loss: 2.1700177931165974
Validation loss: 2.50437087391646

Epoch: 5| Step: 10
Training loss: 2.2867818153164103
Validation loss: 2.521884723914023

Epoch: 5| Step: 11
Training loss: 1.771448305345302
Validation loss: 2.507875534802386

Epoch: 240| Step: 0
Training loss: 2.753911271327426
Validation loss: 2.51309669788599

Epoch: 5| Step: 1
Training loss: 2.282037155002684
Validation loss: 2.5022419552598287

Epoch: 5| Step: 2
Training loss: 2.3852632520447665
Validation loss: 2.5247741835874127

Epoch: 5| Step: 3
Training loss: 2.5520095087908636
Validation loss: 2.524383898910852

Epoch: 5| Step: 4
Training loss: 2.0493461310426153
Validation loss: 2.5306551277450624

Epoch: 5| Step: 5
Training loss: 2.2274395202577892
Validation loss: 2.52924107866837

Epoch: 5| Step: 6
Training loss: 2.250803486092869
Validation loss: 2.5236619666447995

Epoch: 5| Step: 7
Training loss: 2.25315445075185
Validation loss: 2.53205459664

Epoch: 5| Step: 8
Training loss: 1.9789224038893578
Validation loss: 2.5401839298450684

Epoch: 5| Step: 9
Training loss: 2.5360667235143763
Validation loss: 2.5378389158809003

Epoch: 5| Step: 10
Training loss: 2.65225188106039
Validation loss: 2.533196085790434

Epoch: 5| Step: 11
Training loss: 1.8974371892411823
Validation loss: 2.539940401552008

Epoch: 241| Step: 0
Training loss: 2.095004943987491
Validation loss: 2.5320253558287913

Epoch: 5| Step: 1
Training loss: 1.8949135935265657
Validation loss: 2.535290374107616

Epoch: 5| Step: 2
Training loss: 2.4402414213408252
Validation loss: 2.5271370246531815

Epoch: 5| Step: 3
Training loss: 2.630008279475535
Validation loss: 2.52138107564922

Epoch: 5| Step: 4
Training loss: 2.4656080702283854
Validation loss: 2.5195650911645973

Epoch: 5| Step: 5
Training loss: 2.778169361700042
Validation loss: 2.5163498637764827

Epoch: 5| Step: 6
Training loss: 1.9990452633380436
Validation loss: 2.509433226584829

Epoch: 5| Step: 7
Training loss: 2.098544311077424
Validation loss: 2.5295720936253163

Epoch: 5| Step: 8
Training loss: 2.831478596399789
Validation loss: 2.519919227082669

Epoch: 5| Step: 9
Training loss: 1.67385675501514
Validation loss: 2.5308096035546264

Epoch: 5| Step: 10
Training loss: 2.6636190185136
Validation loss: 2.5319451645158235

Epoch: 5| Step: 11
Training loss: 2.2260580997339474
Validation loss: 2.547353984203292

Epoch: 242| Step: 0
Training loss: 2.50801175950988
Validation loss: 2.5272828280983783

Epoch: 5| Step: 1
Training loss: 2.8709638708931244
Validation loss: 2.5505024795126316

Epoch: 5| Step: 2
Training loss: 2.31478686280505
Validation loss: 2.542838863370373

Epoch: 5| Step: 3
Training loss: 1.9612748057326603
Validation loss: 2.545892038204382

Epoch: 5| Step: 4
Training loss: 2.502961312227053
Validation loss: 2.5437269237886886

Epoch: 5| Step: 5
Training loss: 2.2065215205758046
Validation loss: 2.558253669948127

Epoch: 5| Step: 6
Training loss: 2.3394167706334823
Validation loss: 2.5405510945223844

Epoch: 5| Step: 7
Training loss: 2.3607092110154926
Validation loss: 2.5383751824131675

Epoch: 5| Step: 8
Training loss: 2.464805929193048
Validation loss: 2.539763927897034

Epoch: 5| Step: 9
Training loss: 2.4245427359262033
Validation loss: 2.5330729650873463

Epoch: 5| Step: 10
Training loss: 1.8013394828981308
Validation loss: 2.5341329875310796

Epoch: 5| Step: 11
Training loss: 1.2944310611684249
Validation loss: 2.53721169335657

Epoch: 243| Step: 0
Training loss: 2.036017588916041
Validation loss: 2.556029419370746

Epoch: 5| Step: 1
Training loss: 2.5612090045409035
Validation loss: 2.5621029848652137

Epoch: 5| Step: 2
Training loss: 1.779178150625338
Validation loss: 2.5456039205681003

Epoch: 5| Step: 3
Training loss: 2.8077397221901994
Validation loss: 2.5440066241724417

Epoch: 5| Step: 4
Training loss: 2.740817170490298
Validation loss: 2.556301843448573

Epoch: 5| Step: 5
Training loss: 2.2548427388234753
Validation loss: 2.552915041853326

Epoch: 5| Step: 6
Training loss: 1.8458073016441496
Validation loss: 2.551697259362842

Epoch: 5| Step: 7
Training loss: 2.6082052018581665
Validation loss: 2.541672520292035

Epoch: 5| Step: 8
Training loss: 2.699246131769129
Validation loss: 2.553453258110501

Epoch: 5| Step: 9
Training loss: 2.1573432693928494
Validation loss: 2.54461081519704

Epoch: 5| Step: 10
Training loss: 2.0772492133669456
Validation loss: 2.5589561535769745

Epoch: 5| Step: 11
Training loss: 1.7438981078769304
Validation loss: 2.5557437622408137

Epoch: 244| Step: 0
Training loss: 2.596630014186178
Validation loss: 2.572106625125869

Epoch: 5| Step: 1
Training loss: 2.8728306090532016
Validation loss: 2.594542144933238

Epoch: 5| Step: 2
Training loss: 1.6450613440580601
Validation loss: 2.6040046272727473

Epoch: 5| Step: 3
Training loss: 2.3255896364110376
Validation loss: 2.5932490696206796

Epoch: 5| Step: 4
Training loss: 2.1938689023043394
Validation loss: 2.61871111916059

Epoch: 5| Step: 5
Training loss: 2.320126304476889
Validation loss: 2.595194433544114

Epoch: 5| Step: 6
Training loss: 2.745567217035802
Validation loss: 2.58197480609891

Epoch: 5| Step: 7
Training loss: 2.6569134052079
Validation loss: 2.5527987288419074

Epoch: 5| Step: 8
Training loss: 2.302312940191397
Validation loss: 2.533865946591717

Epoch: 5| Step: 9
Training loss: 2.0716985705070647
Validation loss: 2.520587476978694

Epoch: 5| Step: 10
Training loss: 2.129479903180713
Validation loss: 2.5122599041030176

Epoch: 5| Step: 11
Training loss: 1.895350768606307
Validation loss: 2.5139534927611975

Epoch: 245| Step: 0
Training loss: 2.221144767333641
Validation loss: 2.5186791489687974

Epoch: 5| Step: 1
Training loss: 2.443935994048406
Validation loss: 2.5159062096093514

Epoch: 5| Step: 2
Training loss: 2.623310362760933
Validation loss: 2.525088377466614

Epoch: 5| Step: 3
Training loss: 2.779174544643997
Validation loss: 2.5247095324947884

Epoch: 5| Step: 4
Training loss: 1.9271810214739609
Validation loss: 2.5190172563218978

Epoch: 5| Step: 5
Training loss: 2.281189173057317
Validation loss: 2.5424442951697963

Epoch: 5| Step: 6
Training loss: 1.8048906088145584
Validation loss: 2.5340784894255557

Epoch: 5| Step: 7
Training loss: 2.3990670536619665
Validation loss: 2.5395235005048873

Epoch: 5| Step: 8
Training loss: 2.7204628295378295
Validation loss: 2.5606758246212946

Epoch: 5| Step: 9
Training loss: 2.0199320116970925
Validation loss: 2.54612397898462

Epoch: 5| Step: 10
Training loss: 2.446909227777347
Validation loss: 2.538999124371825

Epoch: 5| Step: 11
Training loss: 2.423410630215524
Validation loss: 2.5428991508432763

Epoch: 246| Step: 0
Training loss: 2.059310990816339
Validation loss: 2.5462187758278962

Epoch: 5| Step: 1
Training loss: 2.72518151404918
Validation loss: 2.5614390541727663

Epoch: 5| Step: 2
Training loss: 2.596909219123881
Validation loss: 2.5420311187056934

Epoch: 5| Step: 3
Training loss: 2.20947702649775
Validation loss: 2.5777382377514253

Epoch: 5| Step: 4
Training loss: 1.5376185115636685
Validation loss: 2.544057016488992

Epoch: 5| Step: 5
Training loss: 2.20100484788041
Validation loss: 2.5583738625657584

Epoch: 5| Step: 6
Training loss: 2.8054130274593563
Validation loss: 2.5620968431741207

Epoch: 5| Step: 7
Training loss: 2.1969138173218687
Validation loss: 2.542628232753556

Epoch: 5| Step: 8
Training loss: 2.031317372305177
Validation loss: 2.546892524924179

Epoch: 5| Step: 9
Training loss: 2.7743576887312082
Validation loss: 2.546955795800757

Epoch: 5| Step: 10
Training loss: 2.0800270038465745
Validation loss: 2.5485817313918977

Epoch: 5| Step: 11
Training loss: 3.0372864699171522
Validation loss: 2.5391955570667726

Epoch: 247| Step: 0
Training loss: 2.9410369357500916
Validation loss: 2.5279424489854114

Epoch: 5| Step: 1
Training loss: 2.520978739514522
Validation loss: 2.5404402569883104

Epoch: 5| Step: 2
Training loss: 2.0403839155854313
Validation loss: 2.540599553386258

Epoch: 5| Step: 3
Training loss: 1.9449458868349176
Validation loss: 2.552506701068009

Epoch: 5| Step: 4
Training loss: 2.110333034393445
Validation loss: 2.555057121703355

Epoch: 5| Step: 5
Training loss: 2.8683853349805775
Validation loss: 2.5569558101115732

Epoch: 5| Step: 6
Training loss: 1.900882857147352
Validation loss: 2.559803194922638

Epoch: 5| Step: 7
Training loss: 2.497336876537595
Validation loss: 2.5478212474902255

Epoch: 5| Step: 8
Training loss: 1.7544584700593062
Validation loss: 2.5406023256761054

Epoch: 5| Step: 9
Training loss: 2.5644406669180446
Validation loss: 2.5390688852083176

Epoch: 5| Step: 10
Training loss: 2.2162066644432565
Validation loss: 2.555992100552942

Epoch: 5| Step: 11
Training loss: 2.560720616781431
Validation loss: 2.5439429031136123

Epoch: 248| Step: 0
Training loss: 2.7433349295418763
Validation loss: 2.5603716489891646

Epoch: 5| Step: 1
Training loss: 1.5152940683783858
Validation loss: 2.561924759334339

Epoch: 5| Step: 2
Training loss: 2.850601996036474
Validation loss: 2.574125374087912

Epoch: 5| Step: 3
Training loss: 2.034482057159945
Validation loss: 2.5720289889556414

Epoch: 5| Step: 4
Training loss: 2.2364746045777912
Validation loss: 2.5884922350353827

Epoch: 5| Step: 5
Training loss: 2.1513583217304837
Validation loss: 2.582499778509977

Epoch: 5| Step: 6
Training loss: 2.4391057520763653
Validation loss: 2.5929448092065037

Epoch: 5| Step: 7
Training loss: 2.530942544985094
Validation loss: 2.5823358345537475

Epoch: 5| Step: 8
Training loss: 2.6717336516888066
Validation loss: 2.598377584629502

Epoch: 5| Step: 9
Training loss: 2.0212189873349162
Validation loss: 2.5771304591646658

Epoch: 5| Step: 10
Training loss: 2.227204668565768
Validation loss: 2.5396407892008885

Epoch: 5| Step: 11
Training loss: 1.7693873466942172
Validation loss: 2.5329771389597893

Epoch: 249| Step: 0
Training loss: 1.9487082628988828
Validation loss: 2.5234808194720415

Epoch: 5| Step: 1
Training loss: 2.397610798364862
Validation loss: 2.5232583367172734

Epoch: 5| Step: 2
Training loss: 2.5791748683554583
Validation loss: 2.5167611875425924

Epoch: 5| Step: 3
Training loss: 2.2539318486550006
Validation loss: 2.5058960727334547

Epoch: 5| Step: 4
Training loss: 2.9211395480454665
Validation loss: 2.513190961754953

Epoch: 5| Step: 5
Training loss: 1.9245138892180256
Validation loss: 2.5080181782200324

Epoch: 5| Step: 6
Training loss: 2.117196283638952
Validation loss: 2.5003021931794396

Epoch: 5| Step: 7
Training loss: 2.4835794002649996
Validation loss: 2.5195298936628294

Epoch: 5| Step: 8
Training loss: 2.1598350465449188
Validation loss: 2.506842767388878

Epoch: 5| Step: 9
Training loss: 2.2836435381081404
Validation loss: 2.5232845256092116

Epoch: 5| Step: 10
Training loss: 2.8032462579703386
Validation loss: 2.520711215400491

Epoch: 5| Step: 11
Training loss: 2.495683472156391
Validation loss: 2.5250354191527435

Epoch: 250| Step: 0
Training loss: 2.353805840671102
Validation loss: 2.5181488621296677

Epoch: 5| Step: 1
Training loss: 1.9801059970034172
Validation loss: 2.5242178845008083

Epoch: 5| Step: 2
Training loss: 2.3330706607469756
Validation loss: 2.514579579419798

Epoch: 5| Step: 3
Training loss: 2.304132116609422
Validation loss: 2.534376031206692

Epoch: 5| Step: 4
Training loss: 1.8890513657209413
Validation loss: 2.5279689096204403

Epoch: 5| Step: 5
Training loss: 2.678043940239912
Validation loss: 2.537473218366232

Epoch: 5| Step: 6
Training loss: 1.9541587230247086
Validation loss: 2.5536145903851812

Epoch: 5| Step: 7
Training loss: 2.056690124901402
Validation loss: 2.5563269865510434

Epoch: 5| Step: 8
Training loss: 2.566060453718156
Validation loss: 2.5525284878457755

Epoch: 5| Step: 9
Training loss: 2.7390422987859413
Validation loss: 2.559839790690599

Epoch: 5| Step: 10
Training loss: 2.5312786336150537
Validation loss: 2.566591965426365

Epoch: 5| Step: 11
Training loss: 1.6495454508892928
Validation loss: 2.563802488891094

Epoch: 251| Step: 0
Training loss: 2.4741736602770015
Validation loss: 2.5845348168820825

Epoch: 5| Step: 1
Training loss: 1.8258139846080654
Validation loss: 2.5546814610276702

Epoch: 5| Step: 2
Training loss: 2.1158161296748554
Validation loss: 2.5724256886177765

Epoch: 5| Step: 3
Training loss: 2.0910833657428802
Validation loss: 2.553464345897093

Epoch: 5| Step: 4
Training loss: 2.396030473200084
Validation loss: 2.5328885414715274

Epoch: 5| Step: 5
Training loss: 2.6539732207303373
Validation loss: 2.533315820277899

Epoch: 5| Step: 6
Training loss: 2.7386176627782235
Validation loss: 2.5338065145206112

Epoch: 5| Step: 7
Training loss: 2.439963831711658
Validation loss: 2.533186148510874

Epoch: 5| Step: 8
Training loss: 2.4989988229664095
Validation loss: 2.5306743783640697

Epoch: 5| Step: 9
Training loss: 2.306036189229557
Validation loss: 2.5326399146427967

Epoch: 5| Step: 10
Training loss: 2.4026443417443746
Validation loss: 2.5330303391053923

Epoch: 5| Step: 11
Training loss: 1.31946861791496
Validation loss: 2.5627240028788183

Epoch: 252| Step: 0
Training loss: 1.872347545045325
Validation loss: 2.573632365980339

Epoch: 5| Step: 1
Training loss: 1.9071689329410846
Validation loss: 2.584446330164337

Epoch: 5| Step: 2
Training loss: 2.0851893994414437
Validation loss: 2.590835362273369

Epoch: 5| Step: 3
Training loss: 2.510870379421419
Validation loss: 2.601841103086094

Epoch: 5| Step: 4
Training loss: 3.028891520923128
Validation loss: 2.585222569930416

Epoch: 5| Step: 5
Training loss: 1.5918686926619054
Validation loss: 2.596519301713162

Epoch: 5| Step: 6
Training loss: 2.668825606764843
Validation loss: 2.607493691282848

Epoch: 5| Step: 7
Training loss: 2.7077191072043068
Validation loss: 2.6385380174260455

Epoch: 5| Step: 8
Training loss: 1.516412746566857
Validation loss: 2.625238555331813

Epoch: 5| Step: 9
Training loss: 2.1782534677720222
Validation loss: 2.617577192606834

Epoch: 5| Step: 10
Training loss: 2.9921785757863
Validation loss: 2.6146311331301932

Epoch: 5| Step: 11
Training loss: 1.683175727654907
Validation loss: 2.596450474189063

Epoch: 253| Step: 0
Training loss: 2.3434478565012147
Validation loss: 2.5988291031096775

Epoch: 5| Step: 1
Training loss: 2.2834968475861293
Validation loss: 2.598870837179178

Epoch: 5| Step: 2
Training loss: 2.1035764892613473
Validation loss: 2.5986350297350946

Epoch: 5| Step: 3
Training loss: 2.472359445123446
Validation loss: 2.5852574148526424

Epoch: 5| Step: 4
Training loss: 2.6072201540064697
Validation loss: 2.5770914221543895

Epoch: 5| Step: 5
Training loss: 1.9442719277038956
Validation loss: 2.565025883495072

Epoch: 5| Step: 6
Training loss: 1.7523866455161374
Validation loss: 2.568983791630329

Epoch: 5| Step: 7
Training loss: 2.5647074797697904
Validation loss: 2.5711199140613235

Epoch: 5| Step: 8
Training loss: 2.1701348008859065
Validation loss: 2.5637593005039716

Epoch: 5| Step: 9
Training loss: 2.4567634181825326
Validation loss: 2.5655831149635997

Epoch: 5| Step: 10
Training loss: 2.411215476762377
Validation loss: 2.5535218070935115

Epoch: 5| Step: 11
Training loss: 2.9063523797491313
Validation loss: 2.5663784999111616

Epoch: 254| Step: 0
Training loss: 3.0042549794020825
Validation loss: 2.5422049457910387

Epoch: 5| Step: 1
Training loss: 2.4096724706296597
Validation loss: 2.552973457081649

Epoch: 5| Step: 2
Training loss: 1.7840718454425897
Validation loss: 2.563316804297655

Epoch: 5| Step: 3
Training loss: 2.2782240355514976
Validation loss: 2.568924789174649

Epoch: 5| Step: 4
Training loss: 2.8623796529333516
Validation loss: 2.572303128675114

Epoch: 5| Step: 5
Training loss: 2.59612468800921
Validation loss: 2.5744182179438218

Epoch: 5| Step: 6
Training loss: 1.5129243050629935
Validation loss: 2.5725759957657566

Epoch: 5| Step: 7
Training loss: 2.217192304524007
Validation loss: 2.5669838513246686

Epoch: 5| Step: 8
Training loss: 2.062510981675014
Validation loss: 2.5785582438487737

Epoch: 5| Step: 9
Training loss: 2.661421644302572
Validation loss: 2.5754319816257016

Epoch: 5| Step: 10
Training loss: 1.7337518208225318
Validation loss: 2.5930332089624564

Epoch: 5| Step: 11
Training loss: 1.1885849864842755
Validation loss: 2.5704467568316445

Epoch: 255| Step: 0
Training loss: 1.9404728754590868
Validation loss: 2.5636021717117887

Epoch: 5| Step: 1
Training loss: 2.0251401122799466
Validation loss: 2.558462466688932

Epoch: 5| Step: 2
Training loss: 2.298787780252121
Validation loss: 2.547474168534818

Epoch: 5| Step: 3
Training loss: 2.2919530747355084
Validation loss: 2.5535784364245933

Epoch: 5| Step: 4
Training loss: 2.9195759750178394
Validation loss: 2.5390379175805697

Epoch: 5| Step: 5
Training loss: 2.2191766677881293
Validation loss: 2.5698101959725363

Epoch: 5| Step: 6
Training loss: 2.040884088539573
Validation loss: 2.559036593175433

Epoch: 5| Step: 7
Training loss: 2.2911991914151004
Validation loss: 2.5845169322083485

Epoch: 5| Step: 8
Training loss: 2.3349574658197736
Validation loss: 2.5621545954263

Epoch: 5| Step: 9
Training loss: 2.7204593239764945
Validation loss: 2.5548553178362154

Epoch: 5| Step: 10
Training loss: 2.1429378517028876
Validation loss: 2.5626749234856274

Epoch: 5| Step: 11
Training loss: 2.3216887736950995
Validation loss: 2.5484965336470258

Epoch: 256| Step: 0
Training loss: 2.332497197156655
Validation loss: 2.5624784336888324

Epoch: 5| Step: 1
Training loss: 2.453818642292102
Validation loss: 2.5727263095775585

Epoch: 5| Step: 2
Training loss: 1.7989087081570323
Validation loss: 2.5764268040901843

Epoch: 5| Step: 3
Training loss: 2.2766923708975004
Validation loss: 2.6024917073381846

Epoch: 5| Step: 4
Training loss: 2.3948640825413112
Validation loss: 2.588078437563813

Epoch: 5| Step: 5
Training loss: 2.4149417202000736
Validation loss: 2.5671404983821167

Epoch: 5| Step: 6
Training loss: 2.4121868661641703
Validation loss: 2.5625641241036443

Epoch: 5| Step: 7
Training loss: 2.4990173315917983
Validation loss: 2.561761253371181

Epoch: 5| Step: 8
Training loss: 2.086106539959844
Validation loss: 2.576373969869155

Epoch: 5| Step: 9
Training loss: 1.9674277330865835
Validation loss: 2.5587674186336042

Epoch: 5| Step: 10
Training loss: 2.541109920455653
Validation loss: 2.5689532967565687

Epoch: 5| Step: 11
Training loss: 3.1751622796826204
Validation loss: 2.5512477454026468

Epoch: 257| Step: 0
Training loss: 2.1572908846934946
Validation loss: 2.541465533745852

Epoch: 5| Step: 1
Training loss: 1.899617836815894
Validation loss: 2.549171623381249

Epoch: 5| Step: 2
Training loss: 2.4001231281167326
Validation loss: 2.5433289858225523

Epoch: 5| Step: 3
Training loss: 1.6797613793027553
Validation loss: 2.5507724405460794

Epoch: 5| Step: 4
Training loss: 2.5746508685706764
Validation loss: 2.558200561363717

Epoch: 5| Step: 5
Training loss: 2.806762437824985
Validation loss: 2.5559789405066122

Epoch: 5| Step: 6
Training loss: 3.3715104324064007
Validation loss: 2.580065049305081

Epoch: 5| Step: 7
Training loss: 1.8209490665810166
Validation loss: 2.5572925355266225

Epoch: 5| Step: 8
Training loss: 2.152971844146651
Validation loss: 2.5652367507569616

Epoch: 5| Step: 9
Training loss: 1.8853088544787888
Validation loss: 2.569975087784775

Epoch: 5| Step: 10
Training loss: 2.211536663271578
Validation loss: 2.612467667198572

Epoch: 5| Step: 11
Training loss: 1.5640098905909166
Validation loss: 2.5840755608987034

Epoch: 258| Step: 0
Training loss: 2.0566783006772855
Validation loss: 2.610404723206821

Epoch: 5| Step: 1
Training loss: 2.96211223398418
Validation loss: 2.6153604098645684

Epoch: 5| Step: 2
Training loss: 2.1904690892438126
Validation loss: 2.6059506002690718

Epoch: 5| Step: 3
Training loss: 2.1414837750468863
Validation loss: 2.586179946643898

Epoch: 5| Step: 4
Training loss: 2.188390169221513
Validation loss: 2.5842125585967644

Epoch: 5| Step: 5
Training loss: 2.588009099587623
Validation loss: 2.5714085260561075

Epoch: 5| Step: 6
Training loss: 2.1049436009841154
Validation loss: 2.566519625872424

Epoch: 5| Step: 7
Training loss: 1.8020904482074445
Validation loss: 2.561464767375579

Epoch: 5| Step: 8
Training loss: 1.766978260068461
Validation loss: 2.5519259553509444

Epoch: 5| Step: 9
Training loss: 3.039679378868495
Validation loss: 2.5728248330122656

Epoch: 5| Step: 10
Training loss: 2.389847173872282
Validation loss: 2.5556769870561946

Epoch: 5| Step: 11
Training loss: 2.4354648408022013
Validation loss: 2.5577605970643718

Epoch: 259| Step: 0
Training loss: 2.459071635787889
Validation loss: 2.583016573549158

Epoch: 5| Step: 1
Training loss: 1.8191911902924796
Validation loss: 2.623043148353412

Epoch: 5| Step: 2
Training loss: 1.9793316889445864
Validation loss: 2.6518503365923265

Epoch: 5| Step: 3
Training loss: 3.161145181664092
Validation loss: 2.6801787761111586

Epoch: 5| Step: 4
Training loss: 1.874856053230998
Validation loss: 2.671104267936826

Epoch: 5| Step: 5
Training loss: 2.761248817011872
Validation loss: 2.6332405489457975

Epoch: 5| Step: 6
Training loss: 1.6866380821539988
Validation loss: 2.612709868669699

Epoch: 5| Step: 7
Training loss: 2.2875419487780837
Validation loss: 2.5991818835807896

Epoch: 5| Step: 8
Training loss: 2.279997390277105
Validation loss: 2.5839011519397674

Epoch: 5| Step: 9
Training loss: 2.2126442080985544
Validation loss: 2.5655208204075466

Epoch: 5| Step: 10
Training loss: 2.9746308554501835
Validation loss: 2.5486831916146473

Epoch: 5| Step: 11
Training loss: 1.9826684657479705
Validation loss: 2.5360169166951887

Epoch: 260| Step: 0
Training loss: 1.8583439765363097
Validation loss: 2.53645799912301

Epoch: 5| Step: 1
Training loss: 2.7357725223317293
Validation loss: 2.5355778261829625

Epoch: 5| Step: 2
Training loss: 2.8184477751912866
Validation loss: 2.523697523768432

Epoch: 5| Step: 3
Training loss: 2.130970589229388
Validation loss: 2.51780632174528

Epoch: 5| Step: 4
Training loss: 2.2550370736468457
Validation loss: 2.518853704149239

Epoch: 5| Step: 5
Training loss: 2.6370582644550375
Validation loss: 2.5149394694679206

Epoch: 5| Step: 6
Training loss: 2.4720994464043304
Validation loss: 2.522282240491254

Epoch: 5| Step: 7
Training loss: 2.0837184804307123
Validation loss: 2.5215653205326634

Epoch: 5| Step: 8
Training loss: 2.11759308593509
Validation loss: 2.5227088230451917

Epoch: 5| Step: 9
Training loss: 2.4032592021639374
Validation loss: 2.5305664057789223

Epoch: 5| Step: 10
Training loss: 2.2212493144277397
Validation loss: 2.5269625305985124

Epoch: 5| Step: 11
Training loss: 2.0285906476083255
Validation loss: 2.5291768402720356

Epoch: 261| Step: 0
Training loss: 2.452112073792004
Validation loss: 2.5636470948671986

Epoch: 5| Step: 1
Training loss: 2.1168210321242222
Validation loss: 2.5568799401540687

Epoch: 5| Step: 2
Training loss: 2.9836623054852955
Validation loss: 2.589303237874533

Epoch: 5| Step: 3
Training loss: 2.3315262495310227
Validation loss: 2.618714660400011

Epoch: 5| Step: 4
Training loss: 2.0824258226462065
Validation loss: 2.6257630556129397

Epoch: 5| Step: 5
Training loss: 2.1642058287161765
Validation loss: 2.628441962800459

Epoch: 5| Step: 6
Training loss: 2.3317277924944446
Validation loss: 2.6247872879492795

Epoch: 5| Step: 7
Training loss: 2.5195879316238057
Validation loss: 2.6102704283985987

Epoch: 5| Step: 8
Training loss: 2.294288164665815
Validation loss: 2.6016334203269404

Epoch: 5| Step: 9
Training loss: 2.081137288108785
Validation loss: 2.564358026000673

Epoch: 5| Step: 10
Training loss: 2.268082752312598
Validation loss: 2.5458024249149034

Epoch: 5| Step: 11
Training loss: 1.089074851449025
Validation loss: 2.5451308091714684

Epoch: 262| Step: 0
Training loss: 2.1003130634013667
Validation loss: 2.5365580879246052

Epoch: 5| Step: 1
Training loss: 2.430905052367679
Validation loss: 2.529641334908848

Epoch: 5| Step: 2
Training loss: 2.423485792454841
Validation loss: 2.5287380470148006

Epoch: 5| Step: 3
Training loss: 2.1803710303283292
Validation loss: 2.5233405284535446

Epoch: 5| Step: 4
Training loss: 2.5136068079306852
Validation loss: 2.5212820589003395

Epoch: 5| Step: 5
Training loss: 2.708526154525471
Validation loss: 2.528465100844444

Epoch: 5| Step: 6
Training loss: 1.6398416738147141
Validation loss: 2.5152470598978702

Epoch: 5| Step: 7
Training loss: 3.6061130332389877
Validation loss: 2.5301567785906065

Epoch: 5| Step: 8
Training loss: 1.746815986523634
Validation loss: 2.530476644295021

Epoch: 5| Step: 9
Training loss: 1.886731513001927
Validation loss: 2.5198046671445398

Epoch: 5| Step: 10
Training loss: 2.229829232216268
Validation loss: 2.5281512441007754

Epoch: 5| Step: 11
Training loss: 1.8954715872697676
Validation loss: 2.526145993205286

Epoch: 263| Step: 0
Training loss: 2.5952019361890915
Validation loss: 2.5419778372806143

Epoch: 5| Step: 1
Training loss: 2.696965338297885
Validation loss: 2.5394166044143986

Epoch: 5| Step: 2
Training loss: 2.2073183666256813
Validation loss: 2.5270857878314303

Epoch: 5| Step: 3
Training loss: 2.8621279278946923
Validation loss: 2.535539959522126

Epoch: 5| Step: 4
Training loss: 2.8565231025732434
Validation loss: 2.541222073541807

Epoch: 5| Step: 5
Training loss: 2.3330670840629066
Validation loss: 2.549387400569622

Epoch: 5| Step: 6
Training loss: 1.668534479975559
Validation loss: 2.550819478471432

Epoch: 5| Step: 7
Training loss: 2.4616149938588534
Validation loss: 2.5137175205357503

Epoch: 5| Step: 8
Training loss: 1.8091412039074395
Validation loss: 2.5195021950478194

Epoch: 5| Step: 9
Training loss: 2.1470664348513493
Validation loss: 2.5433573428375196

Epoch: 5| Step: 10
Training loss: 1.7901819050387175
Validation loss: 2.5269180049314217

Epoch: 5| Step: 11
Training loss: 2.123794999389624
Validation loss: 2.5273650815555837

Epoch: 264| Step: 0
Training loss: 2.39274851912378
Validation loss: 2.5361428714122334

Epoch: 5| Step: 1
Training loss: 2.6764888078529325
Validation loss: 2.536480538638528

Epoch: 5| Step: 2
Training loss: 1.8559174005281076
Validation loss: 2.538598496514872

Epoch: 5| Step: 3
Training loss: 2.6260611796054487
Validation loss: 2.5729036556074507

Epoch: 5| Step: 4
Training loss: 2.257835097678328
Validation loss: 2.567564429583176

Epoch: 5| Step: 5
Training loss: 2.4835452247527794
Validation loss: 2.588631750543877

Epoch: 5| Step: 6
Training loss: 2.28831026912586
Validation loss: 2.593616114458552

Epoch: 5| Step: 7
Training loss: 2.3138758716112786
Validation loss: 2.6154603449786333

Epoch: 5| Step: 8
Training loss: 2.2521488736544
Validation loss: 2.603719708551413

Epoch: 5| Step: 9
Training loss: 2.2614575170945694
Validation loss: 2.592552969755293

Epoch: 5| Step: 10
Training loss: 2.1665958490780386
Validation loss: 2.5833462258499185

Epoch: 5| Step: 11
Training loss: 1.5666185648953468
Validation loss: 2.561073371303896

Epoch: 265| Step: 0
Training loss: 1.5516178363255761
Validation loss: 2.5474599310881163

Epoch: 5| Step: 1
Training loss: 2.429202801112308
Validation loss: 2.5246332758372656

Epoch: 5| Step: 2
Training loss: 2.044663960424688
Validation loss: 2.5277445758803765

Epoch: 5| Step: 3
Training loss: 2.4179437047496326
Validation loss: 2.5364252449921887

Epoch: 5| Step: 4
Training loss: 2.9947084807853495
Validation loss: 2.5221803366081543

Epoch: 5| Step: 5
Training loss: 1.9588400881754209
Validation loss: 2.530106081937452

Epoch: 5| Step: 6
Training loss: 2.55823590054779
Validation loss: 2.5369248532332915

Epoch: 5| Step: 7
Training loss: 2.8000843239757107
Validation loss: 2.5272066766042687

Epoch: 5| Step: 8
Training loss: 2.251744547677557
Validation loss: 2.5272848583279934

Epoch: 5| Step: 9
Training loss: 1.7791900770209117
Validation loss: 2.5258470060451876

Epoch: 5| Step: 10
Training loss: 2.6612910288402407
Validation loss: 2.5348805187967933

Epoch: 5| Step: 11
Training loss: 1.7806694690939844
Validation loss: 2.5499454509597714

Epoch: 266| Step: 0
Training loss: 2.692712209515515
Validation loss: 2.583697079358155

Epoch: 5| Step: 1
Training loss: 2.0297079248259635
Validation loss: 2.620035108374735

Epoch: 5| Step: 2
Training loss: 1.7391853638713082
Validation loss: 2.6649899103690573

Epoch: 5| Step: 3
Training loss: 2.783911470989713
Validation loss: 2.674560127159607

Epoch: 5| Step: 4
Training loss: 1.9221772987369143
Validation loss: 2.698339213171858

Epoch: 5| Step: 5
Training loss: 2.562198528140905
Validation loss: 2.671232599883947

Epoch: 5| Step: 6
Training loss: 2.7693723302099555
Validation loss: 2.653232801873528

Epoch: 5| Step: 7
Training loss: 2.3345239757712766
Validation loss: 2.618749537653795

Epoch: 5| Step: 8
Training loss: 2.019539513930747
Validation loss: 2.583587935165938

Epoch: 5| Step: 9
Training loss: 2.298817027672078
Validation loss: 2.5530888827635763

Epoch: 5| Step: 10
Training loss: 2.619328229700976
Validation loss: 2.553443080647166

Epoch: 5| Step: 11
Training loss: 2.155891499225577
Validation loss: 2.5389204210486147

Epoch: 267| Step: 0
Training loss: 2.5562389457482277
Validation loss: 2.5393689249441573

Epoch: 5| Step: 1
Training loss: 1.8594989895552465
Validation loss: 2.552539260517486

Epoch: 5| Step: 2
Training loss: 2.5715316153876056
Validation loss: 2.5322267154998084

Epoch: 5| Step: 3
Training loss: 2.1777429144311276
Validation loss: 2.5464995366843897

Epoch: 5| Step: 4
Training loss: 2.255628750724771
Validation loss: 2.5456719375174246

Epoch: 5| Step: 5
Training loss: 2.332260452840817
Validation loss: 2.54481546526438

Epoch: 5| Step: 6
Training loss: 1.9222344163215093
Validation loss: 2.550686315042394

Epoch: 5| Step: 7
Training loss: 2.093489673429594
Validation loss: 2.544930169928093

Epoch: 5| Step: 8
Training loss: 2.287810207658111
Validation loss: 2.5404299218114215

Epoch: 5| Step: 9
Training loss: 2.0987310799250833
Validation loss: 2.5591339007082956

Epoch: 5| Step: 10
Training loss: 2.926070684115047
Validation loss: 2.547850706666408

Epoch: 5| Step: 11
Training loss: 2.2530383681997788
Validation loss: 2.55121238145595

Epoch: 268| Step: 0
Training loss: 2.5261727734917026
Validation loss: 2.540388142710977

Epoch: 5| Step: 1
Training loss: 2.0308217697638744
Validation loss: 2.573841275685094

Epoch: 5| Step: 2
Training loss: 1.711695046132336
Validation loss: 2.5593337253259074

Epoch: 5| Step: 3
Training loss: 2.6372445945557783
Validation loss: 2.561458534953288

Epoch: 5| Step: 4
Training loss: 2.4488256403645274
Validation loss: 2.565111862532533

Epoch: 5| Step: 5
Training loss: 1.9736843942340967
Validation loss: 2.5623867699952485

Epoch: 5| Step: 6
Training loss: 2.092274843633424
Validation loss: 2.578757622677189

Epoch: 5| Step: 7
Training loss: 1.9071581193916383
Validation loss: 2.5423490195924745

Epoch: 5| Step: 8
Training loss: 2.4595585910854365
Validation loss: 2.527046657829696

Epoch: 5| Step: 9
Training loss: 2.1866731443347973
Validation loss: 2.524412929158353

Epoch: 5| Step: 10
Training loss: 2.821035530210054
Validation loss: 2.515236344731403

Epoch: 5| Step: 11
Training loss: 3.730509141633424
Validation loss: 2.514810469755678

Epoch: 269| Step: 0
Training loss: 2.27940388014007
Validation loss: 2.5010970450459613

Epoch: 5| Step: 1
Training loss: 1.784956505616865
Validation loss: 2.507025570465277

Epoch: 5| Step: 2
Training loss: 2.4401240773781336
Validation loss: 2.510213247475848

Epoch: 5| Step: 3
Training loss: 2.261080795207742
Validation loss: 2.512168828131889

Epoch: 5| Step: 4
Training loss: 2.196402825394041
Validation loss: 2.500148136995211

Epoch: 5| Step: 5
Training loss: 2.475273880110073
Validation loss: 2.5033736473343082

Epoch: 5| Step: 6
Training loss: 2.118065120765753
Validation loss: 2.5123025780226342

Epoch: 5| Step: 7
Training loss: 2.236886806749988
Validation loss: 2.500530625694746

Epoch: 5| Step: 8
Training loss: 2.4193627894691345
Validation loss: 2.519975076071539

Epoch: 5| Step: 9
Training loss: 2.209987260945746
Validation loss: 2.535598822052594

Epoch: 5| Step: 10
Training loss: 2.707913781950244
Validation loss: 2.546334585727168

Epoch: 5| Step: 11
Training loss: 2.03704664183128
Validation loss: 2.5529904770945597

Epoch: 270| Step: 0
Training loss: 2.079816889589074
Validation loss: 2.568128688107446

Epoch: 5| Step: 1
Training loss: 1.9925003703654292
Validation loss: 2.5537961129935822

Epoch: 5| Step: 2
Training loss: 2.5049256438224075
Validation loss: 2.563189874997116

Epoch: 5| Step: 3
Training loss: 2.3307110038063836
Validation loss: 2.5557204441823234

Epoch: 5| Step: 4
Training loss: 2.2336490759013383
Validation loss: 2.5828274544315453

Epoch: 5| Step: 5
Training loss: 2.317199159619867
Validation loss: 2.562682007706934

Epoch: 5| Step: 6
Training loss: 2.7281166172663487
Validation loss: 2.561719523564802

Epoch: 5| Step: 7
Training loss: 2.417610104882956
Validation loss: 2.566874845972421

Epoch: 5| Step: 8
Training loss: 2.224181283917304
Validation loss: 2.5484222712588993

Epoch: 5| Step: 9
Training loss: 1.7947211583996747
Validation loss: 2.5414129167014523

Epoch: 5| Step: 10
Training loss: 2.3745536384749513
Validation loss: 2.542778558840928

Epoch: 5| Step: 11
Training loss: 2.953740454427088
Validation loss: 2.52700030957542

Epoch: 271| Step: 0
Training loss: 2.545225393211001
Validation loss: 2.5452070683889394

Epoch: 5| Step: 1
Training loss: 2.224851787645583
Validation loss: 2.5357905937823584

Epoch: 5| Step: 2
Training loss: 1.8573696959473915
Validation loss: 2.5576363886048954

Epoch: 5| Step: 3
Training loss: 1.8913001124064364
Validation loss: 2.540735747835403

Epoch: 5| Step: 4
Training loss: 2.4701168284412542
Validation loss: 2.5498663413791247

Epoch: 5| Step: 5
Training loss: 2.173797634627252
Validation loss: 2.556586443485038

Epoch: 5| Step: 6
Training loss: 2.783882010130042
Validation loss: 2.5592926390969057

Epoch: 5| Step: 7
Training loss: 1.7343830417755919
Validation loss: 2.572243754362234

Epoch: 5| Step: 8
Training loss: 2.194053859261734
Validation loss: 2.599973749064925

Epoch: 5| Step: 9
Training loss: 2.688476385136663
Validation loss: 2.5953019834179427

Epoch: 5| Step: 10
Training loss: 2.0325980774886596
Validation loss: 2.6251174582587438

Epoch: 5| Step: 11
Training loss: 3.872534921487429
Validation loss: 2.6126152143975756

Epoch: 272| Step: 0
Training loss: 2.590197508803728
Validation loss: 2.576736596531278

Epoch: 5| Step: 1
Training loss: 1.9964328186746483
Validation loss: 2.5801804065283886

Epoch: 5| Step: 2
Training loss: 2.3504507281882914
Validation loss: 2.571925950656165

Epoch: 5| Step: 3
Training loss: 2.358889195024963
Validation loss: 2.562974145488986

Epoch: 5| Step: 4
Training loss: 1.704777956624684
Validation loss: 2.5285911645816936

Epoch: 5| Step: 5
Training loss: 2.2145297250033886
Validation loss: 2.5415967803998423

Epoch: 5| Step: 6
Training loss: 2.124207517166995
Validation loss: 2.531160643456394

Epoch: 5| Step: 7
Training loss: 2.162576654211211
Validation loss: 2.528112841821709

Epoch: 5| Step: 8
Training loss: 2.8658078067756003
Validation loss: 2.530399383665129

Epoch: 5| Step: 9
Training loss: 2.5109051325479745
Validation loss: 2.5415985236387555

Epoch: 5| Step: 10
Training loss: 2.0747511013536926
Validation loss: 2.545340055984322

Epoch: 5| Step: 11
Training loss: 1.7484545013992028
Validation loss: 2.5153951125216447

Epoch: 273| Step: 0
Training loss: 2.0265066075907896
Validation loss: 2.523502656077753

Epoch: 5| Step: 1
Training loss: 3.0569998728084817
Validation loss: 2.5345730652027085

Epoch: 5| Step: 2
Training loss: 2.1302423326783875
Validation loss: 2.554497106069883

Epoch: 5| Step: 3
Training loss: 1.95290574941262
Validation loss: 2.5330810203721983

Epoch: 5| Step: 4
Training loss: 1.929681940109336
Validation loss: 2.5277346859450667

Epoch: 5| Step: 5
Training loss: 2.226653622552884
Validation loss: 2.5488329150470337

Epoch: 5| Step: 6
Training loss: 2.9968747708794883
Validation loss: 2.5265157877312205

Epoch: 5| Step: 7
Training loss: 1.975545749830682
Validation loss: 2.524564387102478

Epoch: 5| Step: 8
Training loss: 2.1991661702404013
Validation loss: 2.530660380069587

Epoch: 5| Step: 9
Training loss: 2.068279261203728
Validation loss: 2.5535886172387148

Epoch: 5| Step: 10
Training loss: 2.095197604198914
Validation loss: 2.5213639919817417

Epoch: 5| Step: 11
Training loss: 2.228160405245526
Validation loss: 2.5564426299796157

Epoch: 274| Step: 0
Training loss: 2.532101334941032
Validation loss: 2.5319648996848545

Epoch: 5| Step: 1
Training loss: 2.2795844072402027
Validation loss: 2.5407253591212235

Epoch: 5| Step: 2
Training loss: 2.9033704048298077
Validation loss: 2.5521885999391727

Epoch: 5| Step: 3
Training loss: 2.58506165392194
Validation loss: 2.5547646093834584

Epoch: 5| Step: 4
Training loss: 2.146212004301352
Validation loss: 2.579136794404644

Epoch: 5| Step: 5
Training loss: 2.267078222984028
Validation loss: 2.57669890678645

Epoch: 5| Step: 6
Training loss: 2.479138403552433
Validation loss: 2.6048064259834036

Epoch: 5| Step: 7
Training loss: 1.9772214733404734
Validation loss: 2.5527326043416396

Epoch: 5| Step: 8
Training loss: 1.4222383977960253
Validation loss: 2.5589522365414723

Epoch: 5| Step: 9
Training loss: 1.676481514118601
Validation loss: 2.5338448853958213

Epoch: 5| Step: 10
Training loss: 2.477532133785148
Validation loss: 2.5255908262235827

Epoch: 5| Step: 11
Training loss: 1.7871936215414086
Validation loss: 2.5298617523855262

Epoch: 275| Step: 0
Training loss: 1.9121645489877162
Validation loss: 2.5433426331637117

Epoch: 5| Step: 1
Training loss: 2.7032847274600034
Validation loss: 2.539288417840144

Epoch: 5| Step: 2
Training loss: 2.4910047827896395
Validation loss: 2.569648297416876

Epoch: 5| Step: 3
Training loss: 1.7766899499327784
Validation loss: 2.594594852319226

Epoch: 5| Step: 4
Training loss: 1.4625957685887447
Validation loss: 2.586913691926639

Epoch: 5| Step: 5
Training loss: 2.5633898794868037
Validation loss: 2.603430206431474

Epoch: 5| Step: 6
Training loss: 1.9166549875760495
Validation loss: 2.5971001012982895

Epoch: 5| Step: 7
Training loss: 2.6569339544826223
Validation loss: 2.6010771557382144

Epoch: 5| Step: 8
Training loss: 1.925797096790784
Validation loss: 2.5726365942136082

Epoch: 5| Step: 9
Training loss: 2.1863203955386417
Validation loss: 2.562369471226132

Epoch: 5| Step: 10
Training loss: 3.0966396515663286
Validation loss: 2.566496423136794

Epoch: 5| Step: 11
Training loss: 0.9602686096946482
Validation loss: 2.5421836332492225

Epoch: 276| Step: 0
Training loss: 1.8294791398611945
Validation loss: 2.543383605994716

Epoch: 5| Step: 1
Training loss: 2.550695257212436
Validation loss: 2.530844192785136

Epoch: 5| Step: 2
Training loss: 1.9388413247022167
Validation loss: 2.517349560298216

Epoch: 5| Step: 3
Training loss: 2.7959415007435036
Validation loss: 2.5186143453651186

Epoch: 5| Step: 4
Training loss: 2.2668782944151795
Validation loss: 2.524841917710775

Epoch: 5| Step: 5
Training loss: 2.29106235049991
Validation loss: 2.5244427500409983

Epoch: 5| Step: 6
Training loss: 2.3281296083545517
Validation loss: 2.520463157040474

Epoch: 5| Step: 7
Training loss: 2.6499837227087526
Validation loss: 2.5200656688802683

Epoch: 5| Step: 8
Training loss: 2.5694226054961775
Validation loss: 2.529205949049869

Epoch: 5| Step: 9
Training loss: 2.506708680605672
Validation loss: 2.5360240832183307

Epoch: 5| Step: 10
Training loss: 1.2800569329415217
Validation loss: 2.5371265875761306

Epoch: 5| Step: 11
Training loss: 2.8050143335693565
Validation loss: 2.550695440261757

Epoch: 277| Step: 0
Training loss: 2.353395982922403
Validation loss: 2.57511394257896

Epoch: 5| Step: 1
Training loss: 1.5486672547583271
Validation loss: 2.6048054954257123

Epoch: 5| Step: 2
Training loss: 2.3179856266632632
Validation loss: 2.6119535044927304

Epoch: 5| Step: 3
Training loss: 2.412685655951138
Validation loss: 2.6346208680138847

Epoch: 5| Step: 4
Training loss: 2.7039199277658064
Validation loss: 2.6313643146760817

Epoch: 5| Step: 5
Training loss: 2.23793535738834
Validation loss: 2.6192202668546964

Epoch: 5| Step: 6
Training loss: 2.1206814135067
Validation loss: 2.5758752312261417

Epoch: 5| Step: 7
Training loss: 2.0320746288487275
Validation loss: 2.54973926263017

Epoch: 5| Step: 8
Training loss: 2.635128824751205
Validation loss: 2.524656074379653

Epoch: 5| Step: 9
Training loss: 2.088901314405365
Validation loss: 2.5093580575563443

Epoch: 5| Step: 10
Training loss: 2.494704933225054
Validation loss: 2.4980714631231327

Epoch: 5| Step: 11
Training loss: 1.58816409600726
Validation loss: 2.4767765670662722

Epoch: 278| Step: 0
Training loss: 2.52791894325249
Validation loss: 2.479381953970848

Epoch: 5| Step: 1
Training loss: 2.2891383239894925
Validation loss: 2.5020442234342117

Epoch: 5| Step: 2
Training loss: 2.6380747381328318
Validation loss: 2.5007014522356017

Epoch: 5| Step: 3
Training loss: 2.792894311726566
Validation loss: 2.497765317175577

Epoch: 5| Step: 4
Training loss: 1.7636565992468995
Validation loss: 2.490811573030083

Epoch: 5| Step: 5
Training loss: 2.509638231658597
Validation loss: 2.50216090669424

Epoch: 5| Step: 6
Training loss: 2.4356347797012448
Validation loss: 2.503000144051174

Epoch: 5| Step: 7
Training loss: 2.4875279218937276
Validation loss: 2.503886666620555

Epoch: 5| Step: 8
Training loss: 1.7476354700932701
Validation loss: 2.5062421990429358

Epoch: 5| Step: 9
Training loss: 2.6413036129046605
Validation loss: 2.5287190684364136

Epoch: 5| Step: 10
Training loss: 1.753334750923096
Validation loss: 2.5368768019136074

Epoch: 5| Step: 11
Training loss: 1.878041597821732
Validation loss: 2.55694766297956

Epoch: 279| Step: 0
Training loss: 2.631820355937178
Validation loss: 2.5625508970152673

Epoch: 5| Step: 1
Training loss: 1.9901452461028912
Validation loss: 2.588282707790429

Epoch: 5| Step: 2
Training loss: 2.498569556128615
Validation loss: 2.588958446995572

Epoch: 5| Step: 3
Training loss: 1.9493794040562915
Validation loss: 2.6296340403540976

Epoch: 5| Step: 4
Training loss: 1.7725224760107434
Validation loss: 2.5917134160141986

Epoch: 5| Step: 5
Training loss: 1.8021257722594581
Validation loss: 2.590060229337577

Epoch: 5| Step: 6
Training loss: 2.3775290024329183
Validation loss: 2.5678284070851265

Epoch: 5| Step: 7
Training loss: 2.5094780545670767
Validation loss: 2.5332379011533286

Epoch: 5| Step: 8
Training loss: 2.5697952260174564
Validation loss: 2.52661419439895

Epoch: 5| Step: 9
Training loss: 2.681914002333383
Validation loss: 2.5181714866262657

Epoch: 5| Step: 10
Training loss: 1.870203431533702
Validation loss: 2.5235340958128494

Epoch: 5| Step: 11
Training loss: 1.8002133084109864
Validation loss: 2.5152846712321875

Epoch: 280| Step: 0
Training loss: 2.7018569000435586
Validation loss: 2.5206999441328066

Epoch: 5| Step: 1
Training loss: 2.5680675036153158
Validation loss: 2.5210976002366965

Epoch: 5| Step: 2
Training loss: 2.0872042235109842
Validation loss: 2.5184199679393564

Epoch: 5| Step: 3
Training loss: 1.3981652447668298
Validation loss: 2.5168659987571687

Epoch: 5| Step: 4
Training loss: 1.7011540759060961
Validation loss: 2.521673847922794

Epoch: 5| Step: 5
Training loss: 2.6236396170955083
Validation loss: 2.5351653507894167

Epoch: 5| Step: 6
Training loss: 2.3525773706796933
Validation loss: 2.536536383292898

Epoch: 5| Step: 7
Training loss: 2.689840495262426
Validation loss: 2.5592203901679125

Epoch: 5| Step: 8
Training loss: 2.0242355128087044
Validation loss: 2.580129148838814

Epoch: 5| Step: 9
Training loss: 2.2380030061294236
Validation loss: 2.5904555291000433

Epoch: 5| Step: 10
Training loss: 1.8984202945384818
Validation loss: 2.630333466275763

Epoch: 5| Step: 11
Training loss: 3.3674292245293524
Validation loss: 2.640409806942759

Epoch: 281| Step: 0
Training loss: 2.0220411040809774
Validation loss: 2.6565442128021894

Epoch: 5| Step: 1
Training loss: 2.371120094517465
Validation loss: 2.6498789845131694

Epoch: 5| Step: 2
Training loss: 2.582244171735775
Validation loss: 2.6234653051105874

Epoch: 5| Step: 3
Training loss: 2.1257113219861643
Validation loss: 2.5939507579092864

Epoch: 5| Step: 4
Training loss: 2.1995671540050847
Validation loss: 2.586418472077106

Epoch: 5| Step: 5
Training loss: 2.2230239322693723
Validation loss: 2.565373070010662

Epoch: 5| Step: 6
Training loss: 2.941584243556264
Validation loss: 2.5688211448977327

Epoch: 5| Step: 7
Training loss: 2.2513409962921416
Validation loss: 2.5822835963406368

Epoch: 5| Step: 8
Training loss: 2.2254598463828885
Validation loss: 2.553739490434504

Epoch: 5| Step: 9
Training loss: 2.08976012445857
Validation loss: 2.546190606743091

Epoch: 5| Step: 10
Training loss: 1.694764290346051
Validation loss: 2.5579211722101936

Epoch: 5| Step: 11
Training loss: 1.033077874190591
Validation loss: 2.5363625593857453

Epoch: 282| Step: 0
Training loss: 2.3621387588997362
Validation loss: 2.5100198698587173

Epoch: 5| Step: 1
Training loss: 1.9544118685366274
Validation loss: 2.5104186518385596

Epoch: 5| Step: 2
Training loss: 2.023391782030575
Validation loss: 2.5182185555793035

Epoch: 5| Step: 3
Training loss: 2.552749505322892
Validation loss: 2.514386916897638

Epoch: 5| Step: 4
Training loss: 2.168336249468536
Validation loss: 2.5087047981988677

Epoch: 5| Step: 5
Training loss: 2.8230334230796323
Validation loss: 2.5152030693657808

Epoch: 5| Step: 6
Training loss: 2.303173020171508
Validation loss: 2.503363266271524

Epoch: 5| Step: 7
Training loss: 1.5904536846364414
Validation loss: 2.5275931296719083

Epoch: 5| Step: 8
Training loss: 1.9374795112757088
Validation loss: 2.5537044527495443

Epoch: 5| Step: 9
Training loss: 2.836371774761822
Validation loss: 2.578994650540493

Epoch: 5| Step: 10
Training loss: 1.8498845605660517
Validation loss: 2.609681258055763

Epoch: 5| Step: 11
Training loss: 2.04330120700309
Validation loss: 2.6266977746225977

Epoch: 283| Step: 0
Training loss: 1.6955286406806604
Validation loss: 2.64200225066369

Epoch: 5| Step: 1
Training loss: 2.99120009741343
Validation loss: 2.629526017070652

Epoch: 5| Step: 2
Training loss: 2.2900044973404214
Validation loss: 2.5895903718954494

Epoch: 5| Step: 3
Training loss: 1.8216151214082554
Validation loss: 2.6025071820280004

Epoch: 5| Step: 4
Training loss: 1.9865275445118726
Validation loss: 2.5654264308955725

Epoch: 5| Step: 5
Training loss: 2.5865243666463633
Validation loss: 2.5425824928216874

Epoch: 5| Step: 6
Training loss: 2.3823056541825087
Validation loss: 2.5129018343618093

Epoch: 5| Step: 7
Training loss: 2.423958356065235
Validation loss: 2.5270754176930748

Epoch: 5| Step: 8
Training loss: 1.7137856662413924
Validation loss: 2.52654774633412

Epoch: 5| Step: 9
Training loss: 2.4008572080732185
Validation loss: 2.496815916769996

Epoch: 5| Step: 10
Training loss: 2.4498045006427818
Validation loss: 2.5071081715345023

Epoch: 5| Step: 11
Training loss: 1.1363968540885265
Validation loss: 2.5362232825205444

Epoch: 284| Step: 0
Training loss: 1.5803085178040686
Validation loss: 2.507129998192553

Epoch: 5| Step: 1
Training loss: 2.196359622240848
Validation loss: 2.5064599855311998

Epoch: 5| Step: 2
Training loss: 2.402349803885919
Validation loss: 2.5098907716574326

Epoch: 5| Step: 3
Training loss: 2.872145023042226
Validation loss: 2.5194758564382154

Epoch: 5| Step: 4
Training loss: 2.3490021920744053
Validation loss: 2.5414569108950014

Epoch: 5| Step: 5
Training loss: 2.176811700207811
Validation loss: 2.5670344427247844

Epoch: 5| Step: 6
Training loss: 2.058564679919568
Validation loss: 2.590929692645049

Epoch: 5| Step: 7
Training loss: 1.9544488921315761
Validation loss: 2.611825667815524

Epoch: 5| Step: 8
Training loss: 2.4595577186656454
Validation loss: 2.5927288312601084

Epoch: 5| Step: 9
Training loss: 2.644095132723544
Validation loss: 2.6005715591695946

Epoch: 5| Step: 10
Training loss: 1.754049928213357
Validation loss: 2.573285618221905

Epoch: 5| Step: 11
Training loss: 2.904919227356978
Validation loss: 2.545588302891014

Epoch: 285| Step: 0
Training loss: 2.0704403244000673
Validation loss: 2.5012582473580784

Epoch: 5| Step: 1
Training loss: 2.96809749459595
Validation loss: 2.531343580015342

Epoch: 5| Step: 2
Training loss: 2.0531944971500975
Validation loss: 2.5086664031501096

Epoch: 5| Step: 3
Training loss: 1.6128113734332465
Validation loss: 2.5119159872193366

Epoch: 5| Step: 4
Training loss: 2.1906279951611123
Validation loss: 2.508230132982523

Epoch: 5| Step: 5
Training loss: 2.454153440620089
Validation loss: 2.5032946811270707

Epoch: 5| Step: 6
Training loss: 2.5117678244440413
Validation loss: 2.524751512021547

Epoch: 5| Step: 7
Training loss: 1.936509586809866
Validation loss: 2.523798181603866

Epoch: 5| Step: 8
Training loss: 2.552153564317189
Validation loss: 2.5195047460931357

Epoch: 5| Step: 9
Training loss: 2.717778350134798
Validation loss: 2.519951458569419

Epoch: 5| Step: 10
Training loss: 1.6446934708347911
Validation loss: 2.51195984944422

Epoch: 5| Step: 11
Training loss: 4.117066586074352
Validation loss: 2.5274953899850883

Epoch: 286| Step: 0
Training loss: 2.1663328304842917
Validation loss: 2.545426461900364

Epoch: 5| Step: 1
Training loss: 2.305213273415585
Validation loss: 2.5874572736557266

Epoch: 5| Step: 2
Training loss: 2.4565073980138106
Validation loss: 2.625034104988525

Epoch: 5| Step: 3
Training loss: 2.163632346689387
Validation loss: 2.695063003565588

Epoch: 5| Step: 4
Training loss: 2.3732105339977694
Validation loss: 2.7012086076461563

Epoch: 5| Step: 5
Training loss: 2.4240590737827485
Validation loss: 2.6751033954602663

Epoch: 5| Step: 6
Training loss: 2.4844250943873476
Validation loss: 2.6119806220575743

Epoch: 5| Step: 7
Training loss: 2.607419223283998
Validation loss: 2.559188629960028

Epoch: 5| Step: 8
Training loss: 2.4658983395761203
Validation loss: 2.5261297675955485

Epoch: 5| Step: 9
Training loss: 2.4671622856644295
Validation loss: 2.4893232286851257

Epoch: 5| Step: 10
Training loss: 2.0283755578207043
Validation loss: 2.5007742636480823

Epoch: 5| Step: 11
Training loss: 1.6008433146101866
Validation loss: 2.5077719402895533

Epoch: 287| Step: 0
Training loss: 2.036448707135044
Validation loss: 2.5274432957190665

Epoch: 5| Step: 1
Training loss: 2.1366736705425207
Validation loss: 2.529499366932096

Epoch: 5| Step: 2
Training loss: 1.9930637003532454
Validation loss: 2.5133115820951133

Epoch: 5| Step: 3
Training loss: 2.549381076275242
Validation loss: 2.51414766627731

Epoch: 5| Step: 4
Training loss: 2.4474922190962367
Validation loss: 2.5082698377280206

Epoch: 5| Step: 5
Training loss: 2.728391891655802
Validation loss: 2.5161477388914193

Epoch: 5| Step: 6
Training loss: 2.669909194659446
Validation loss: 2.5127092725037596

Epoch: 5| Step: 7
Training loss: 2.4477720718425027
Validation loss: 2.5011955621143747

Epoch: 5| Step: 8
Training loss: 2.284627634839123
Validation loss: 2.5067218654998173

Epoch: 5| Step: 9
Training loss: 1.8772751038788402
Validation loss: 2.5186414502767023

Epoch: 5| Step: 10
Training loss: 2.7278040816244578
Validation loss: 2.5008389416353904

Epoch: 5| Step: 11
Training loss: 2.8423919788727345
Validation loss: 2.526789601031104

Epoch: 288| Step: 0
Training loss: 1.9766779929936058
Validation loss: 2.508843973345115

Epoch: 5| Step: 1
Training loss: 2.393017936298185
Validation loss: 2.5153009628515983

Epoch: 5| Step: 2
Training loss: 2.579630371792056
Validation loss: 2.5452333553928885

Epoch: 5| Step: 3
Training loss: 2.31954182885476
Validation loss: 2.5886975720516783

Epoch: 5| Step: 4
Training loss: 1.8854464393358534
Validation loss: 2.6032974865305953

Epoch: 5| Step: 5
Training loss: 2.5844983478525365
Validation loss: 2.6083368722345237

Epoch: 5| Step: 6
Training loss: 2.1578027414243492
Validation loss: 2.574527403600623

Epoch: 5| Step: 7
Training loss: 2.0467228723733917
Validation loss: 2.584876677481664

Epoch: 5| Step: 8
Training loss: 2.5852716516426018
Validation loss: 2.566107246248689

Epoch: 5| Step: 9
Training loss: 2.127013430690643
Validation loss: 2.5532902737635395

Epoch: 5| Step: 10
Training loss: 2.246372796015385
Validation loss: 2.545133537493867

Epoch: 5| Step: 11
Training loss: 3.0821058218362767
Validation loss: 2.5439219800156105

Epoch: 289| Step: 0
Training loss: 2.2345722884996397
Validation loss: 2.560129402709789

Epoch: 5| Step: 1
Training loss: 2.5732458936168756
Validation loss: 2.5713655272329383

Epoch: 5| Step: 2
Training loss: 2.35172015197116
Validation loss: 2.5491179982261936

Epoch: 5| Step: 3
Training loss: 2.1298421779780967
Validation loss: 2.5492252824804646

Epoch: 5| Step: 4
Training loss: 1.785205932192954
Validation loss: 2.5366042791646994

Epoch: 5| Step: 5
Training loss: 1.8297558544496313
Validation loss: 2.5313514485064723

Epoch: 5| Step: 6
Training loss: 2.467178230678934
Validation loss: 2.5405266946477365

Epoch: 5| Step: 7
Training loss: 2.5309506463009566
Validation loss: 2.5286070129578486

Epoch: 5| Step: 8
Training loss: 2.3302659808755686
Validation loss: 2.5394438667482624

Epoch: 5| Step: 9
Training loss: 1.8678511712990329
Validation loss: 2.5374156599639037

Epoch: 5| Step: 10
Training loss: 2.4179435075419073
Validation loss: 2.548442533711433

Epoch: 5| Step: 11
Training loss: 2.792230938112994
Validation loss: 2.5458283857983237

Epoch: 290| Step: 0
Training loss: 2.1297539659345204
Validation loss: 2.5705253277199693

Epoch: 5| Step: 1
Training loss: 2.337110346175943
Validation loss: 2.5784955962494047

Epoch: 5| Step: 2
Training loss: 2.725114060560843
Validation loss: 2.5849834768294775

Epoch: 5| Step: 3
Training loss: 2.2244493596080566
Validation loss: 2.573236296307397

Epoch: 5| Step: 4
Training loss: 2.2479346650834597
Validation loss: 2.5581101482242006

Epoch: 5| Step: 5
Training loss: 2.2806286945558765
Validation loss: 2.5528390128908955

Epoch: 5| Step: 6
Training loss: 2.4589099100122884
Validation loss: 2.5452851050650955

Epoch: 5| Step: 7
Training loss: 2.4404790231420224
Validation loss: 2.5119373627839057

Epoch: 5| Step: 8
Training loss: 2.1136615291152614
Validation loss: 2.507041289682991

Epoch: 5| Step: 9
Training loss: 1.5872583010046841
Validation loss: 2.4886923569639903

Epoch: 5| Step: 10
Training loss: 2.4745695838047377
Validation loss: 2.516008047791231

Epoch: 5| Step: 11
Training loss: 1.8663800780232547
Validation loss: 2.510038898794784

Epoch: 291| Step: 0
Training loss: 1.6535584514288784
Validation loss: 2.5158562326879066

Epoch: 5| Step: 1
Training loss: 2.40321783275896
Validation loss: 2.502548651157235

Epoch: 5| Step: 2
Training loss: 2.2971670782483766
Validation loss: 2.4974852729244783

Epoch: 5| Step: 3
Training loss: 1.718477609030699
Validation loss: 2.5071570549015485

Epoch: 5| Step: 4
Training loss: 2.249390201586132
Validation loss: 2.505690864572084

Epoch: 5| Step: 5
Training loss: 2.399724956487883
Validation loss: 2.4985397007826133

Epoch: 5| Step: 6
Training loss: 2.384296692928476
Validation loss: 2.48995100815131

Epoch: 5| Step: 7
Training loss: 2.4192689718370013
Validation loss: 2.527287108677404

Epoch: 5| Step: 8
Training loss: 1.7648354849721046
Validation loss: 2.5448024718817344

Epoch: 5| Step: 9
Training loss: 2.9085266056348935
Validation loss: 2.5691264739054525

Epoch: 5| Step: 10
Training loss: 2.464443845394342
Validation loss: 2.5907332674969807

Epoch: 5| Step: 11
Training loss: 1.4135397687808822
Validation loss: 2.576581419656882

Epoch: 292| Step: 0
Training loss: 2.4205242697246248
Validation loss: 2.614495816735482

Epoch: 5| Step: 1
Training loss: 2.2999866194957783
Validation loss: 2.585690005349509

Epoch: 5| Step: 2
Training loss: 2.124509754850707
Validation loss: 2.594849655951061

Epoch: 5| Step: 3
Training loss: 2.5648344617821275
Validation loss: 2.569045271381654

Epoch: 5| Step: 4
Training loss: 2.2994438908867565
Validation loss: 2.5636977656762694

Epoch: 5| Step: 5
Training loss: 2.2211503490276923
Validation loss: 2.536238601430839

Epoch: 5| Step: 6
Training loss: 1.9479678006184018
Validation loss: 2.5456800173240004

Epoch: 5| Step: 7
Training loss: 1.7000843868628503
Validation loss: 2.502972865789603

Epoch: 5| Step: 8
Training loss: 2.433277189138325
Validation loss: 2.5196644434851168

Epoch: 5| Step: 9
Training loss: 2.531460506021886
Validation loss: 2.5143446774020943

Epoch: 5| Step: 10
Training loss: 2.083179722526997
Validation loss: 2.5243308392400783

Epoch: 5| Step: 11
Training loss: 2.4255609826965863
Validation loss: 2.503689459482856

Epoch: 293| Step: 0
Training loss: 2.1836429924778025
Validation loss: 2.5236623701243253

Epoch: 5| Step: 1
Training loss: 2.820462378748872
Validation loss: 2.5361321191856545

Epoch: 5| Step: 2
Training loss: 1.9460373106513198
Validation loss: 2.574785948624908

Epoch: 5| Step: 3
Training loss: 2.0479569232925448
Validation loss: 2.5610431623742826

Epoch: 5| Step: 4
Training loss: 1.6714026951562602
Validation loss: 2.6078956925958194

Epoch: 5| Step: 5
Training loss: 1.9463820983118356
Validation loss: 2.6067611333391554

Epoch: 5| Step: 6
Training loss: 2.506764796175973
Validation loss: 2.598545742475688

Epoch: 5| Step: 7
Training loss: 2.8260850662365464
Validation loss: 2.568035829613986

Epoch: 5| Step: 8
Training loss: 1.9522866242635066
Validation loss: 2.5430853836962655

Epoch: 5| Step: 9
Training loss: 1.7638685554006572
Validation loss: 2.5286282042109156

Epoch: 5| Step: 10
Training loss: 2.726795612852203
Validation loss: 2.552293653320539

Epoch: 5| Step: 11
Training loss: 1.5982556699249164
Validation loss: 2.521906452227052

Epoch: 294| Step: 0
Training loss: 1.6129022850526096
Validation loss: 2.5202966025399567

Epoch: 5| Step: 1
Training loss: 2.0444399494430407
Validation loss: 2.536921544374431

Epoch: 5| Step: 2
Training loss: 2.2615515559828947
Validation loss: 2.5440817651744343

Epoch: 5| Step: 3
Training loss: 2.7956217083569395
Validation loss: 2.5232691792349713

Epoch: 5| Step: 4
Training loss: 2.260144675865035
Validation loss: 2.554474991914236

Epoch: 5| Step: 5
Training loss: 2.2898487394259655
Validation loss: 2.5440676024582234

Epoch: 5| Step: 6
Training loss: 1.9813683627901078
Validation loss: 2.5379006373324553

Epoch: 5| Step: 7
Training loss: 1.907168620411614
Validation loss: 2.5300205251052144

Epoch: 5| Step: 8
Training loss: 2.282376886329517
Validation loss: 2.5546823476259184

Epoch: 5| Step: 9
Training loss: 2.3585719074401608
Validation loss: 2.5606202969280165

Epoch: 5| Step: 10
Training loss: 2.3777264455303033
Validation loss: 2.555235696006683

Epoch: 5| Step: 11
Training loss: 2.515440655700765
Validation loss: 2.6193555477751684

Epoch: 295| Step: 0
Training loss: 2.455930721119734
Validation loss: 2.6271519771222445

Epoch: 5| Step: 1
Training loss: 2.630094670524548
Validation loss: 2.6511288062103135

Epoch: 5| Step: 2
Training loss: 2.245051770877112
Validation loss: 2.639220844409721

Epoch: 5| Step: 3
Training loss: 2.206119207120089
Validation loss: 2.635383995265766

Epoch: 5| Step: 4
Training loss: 1.8919928780597093
Validation loss: 2.584890485936468

Epoch: 5| Step: 5
Training loss: 2.341968520541746
Validation loss: 2.5507405517820887

Epoch: 5| Step: 6
Training loss: 2.4627674867611145
Validation loss: 2.5300255942023853

Epoch: 5| Step: 7
Training loss: 1.4120008920283107
Validation loss: 2.531175861528779

Epoch: 5| Step: 8
Training loss: 2.137594932545006
Validation loss: 2.504235264372272

Epoch: 5| Step: 9
Training loss: 2.8156535800241187
Validation loss: 2.5286827687094355

Epoch: 5| Step: 10
Training loss: 2.362206181415599
Validation loss: 2.5109153360442193

Epoch: 5| Step: 11
Training loss: 1.5007663994153166
Validation loss: 2.5230372202951767

Epoch: 296| Step: 0
Training loss: 2.532872751261791
Validation loss: 2.5158400907633163

Epoch: 5| Step: 1
Training loss: 1.9328695771432933
Validation loss: 2.5337966502066296

Epoch: 5| Step: 2
Training loss: 1.9989678580604027
Validation loss: 2.541450813122434

Epoch: 5| Step: 3
Training loss: 2.2241915745041423
Validation loss: 2.5628540794628702

Epoch: 5| Step: 4
Training loss: 2.353213519575599
Validation loss: 2.5814382860049077

Epoch: 5| Step: 5
Training loss: 2.122461710338499
Validation loss: 2.596312245470853

Epoch: 5| Step: 6
Training loss: 2.328313013460059
Validation loss: 2.594019389429816

Epoch: 5| Step: 7
Training loss: 2.379649780535558
Validation loss: 2.5956270901862712

Epoch: 5| Step: 8
Training loss: 2.2025298268336893
Validation loss: 2.635207738372384

Epoch: 5| Step: 9
Training loss: 2.116119340534699
Validation loss: 2.5997781982937087

Epoch: 5| Step: 10
Training loss: 2.5851173598545176
Validation loss: 2.552070751288922

Epoch: 5| Step: 11
Training loss: 1.0121542681767939
Validation loss: 2.506186920031749

Epoch: 297| Step: 0
Training loss: 2.3732958250975145
Validation loss: 2.4840832584953594

Epoch: 5| Step: 1
Training loss: 2.0514848355935187
Validation loss: 2.4809572034281557

Epoch: 5| Step: 2
Training loss: 1.9490581438640668
Validation loss: 2.4796226840731386

Epoch: 5| Step: 3
Training loss: 2.0862826515417376
Validation loss: 2.487324573171259

Epoch: 5| Step: 4
Training loss: 2.2434209428243466
Validation loss: 2.4779195827862317

Epoch: 5| Step: 5
Training loss: 2.0831782346848287
Validation loss: 2.479736031672515

Epoch: 5| Step: 6
Training loss: 2.008778024512394
Validation loss: 2.489532351803143

Epoch: 5| Step: 7
Training loss: 2.8216645019697197
Validation loss: 2.4662184471281288

Epoch: 5| Step: 8
Training loss: 2.2081075828852215
Validation loss: 2.4701249965321987

Epoch: 5| Step: 9
Training loss: 2.0437244891986404
Validation loss: 2.4875649978861443

Epoch: 5| Step: 10
Training loss: 2.4510052506551294
Validation loss: 2.4933104242381163

Epoch: 5| Step: 11
Training loss: 2.6096295443889646
Validation loss: 2.517765603435409

Epoch: 298| Step: 0
Training loss: 2.304377958556041
Validation loss: 2.536135354650979

Epoch: 5| Step: 1
Training loss: 2.194685333915727
Validation loss: 2.5477864637401035

Epoch: 5| Step: 2
Training loss: 2.26939961614682
Validation loss: 2.5812601774321404

Epoch: 5| Step: 3
Training loss: 2.163901312709015
Validation loss: 2.556868676801217

Epoch: 5| Step: 4
Training loss: 1.948664033962163
Validation loss: 2.548762232682659

Epoch: 5| Step: 5
Training loss: 1.812013758188188
Validation loss: 2.5418044871084424

Epoch: 5| Step: 6
Training loss: 2.054722078561817
Validation loss: 2.515517846583725

Epoch: 5| Step: 7
Training loss: 2.0206099973405407
Validation loss: 2.4902516642450268

Epoch: 5| Step: 8
Training loss: 2.500311832053619
Validation loss: 2.477163143706326

Epoch: 5| Step: 9
Training loss: 2.275870263624037
Validation loss: 2.480777555051572

Epoch: 5| Step: 10
Training loss: 2.917442018901967
Validation loss: 2.471741895471837

Epoch: 5| Step: 11
Training loss: 1.8332953738126385
Validation loss: 2.487974186849233

Epoch: 299| Step: 0
Training loss: 1.523500568355984
Validation loss: 2.485412844718644

Epoch: 5| Step: 1
Training loss: 2.60120057117257
Validation loss: 2.4902719751648448

Epoch: 5| Step: 2
Training loss: 2.6471568924682733
Validation loss: 2.499083585463749

Epoch: 5| Step: 3
Training loss: 2.1867482664808566
Validation loss: 2.496831200939229

Epoch: 5| Step: 4
Training loss: 1.5505950585349415
Validation loss: 2.4992522631448586

Epoch: 5| Step: 5
Training loss: 1.7496824657642334
Validation loss: 2.504335427164764

Epoch: 5| Step: 6
Training loss: 2.106293186005357
Validation loss: 2.5417697929869103

Epoch: 5| Step: 7
Training loss: 2.5322962353025833
Validation loss: 2.5581220390985537

Epoch: 5| Step: 8
Training loss: 1.7955128025967793
Validation loss: 2.5731369585771313

Epoch: 5| Step: 9
Training loss: 2.243038959527074
Validation loss: 2.572211878820179

Epoch: 5| Step: 10
Training loss: 2.5367612768802084
Validation loss: 2.5333536162683328

Epoch: 5| Step: 11
Training loss: 3.5041871229399444
Validation loss: 2.5021602853560974

Epoch: 300| Step: 0
Training loss: 2.1872233624603776
Validation loss: 2.527274868324717

Epoch: 5| Step: 1
Training loss: 2.4747414617656096
Validation loss: 2.495548640483418

Epoch: 5| Step: 2
Training loss: 2.440083235274641
Validation loss: 2.494625380010745

Epoch: 5| Step: 3
Training loss: 2.2966509859004693
Validation loss: 2.4982942682863447

Epoch: 5| Step: 4
Training loss: 2.271987505072501
Validation loss: 2.513082819093486

Epoch: 5| Step: 5
Training loss: 1.2651951377746278
Validation loss: 2.49104668028258

Epoch: 5| Step: 6
Training loss: 2.005294348783353
Validation loss: 2.5041798518008807

Epoch: 5| Step: 7
Training loss: 2.3788976308982814
Validation loss: 2.5033678496589093

Epoch: 5| Step: 8
Training loss: 2.544323257223766
Validation loss: 2.528392434641676

Epoch: 5| Step: 9
Training loss: 1.9163225804945856
Validation loss: 2.5278012914460577

Epoch: 5| Step: 10
Training loss: 2.0862544244041636
Validation loss: 2.5360540789815906

Epoch: 5| Step: 11
Training loss: 2.830269353604465
Validation loss: 2.5718596999129297

Epoch: 301| Step: 0
Training loss: 2.1020493634758575
Validation loss: 2.543146821568492

Epoch: 5| Step: 1
Training loss: 2.317701726896893
Validation loss: 2.5330560328264475

Epoch: 5| Step: 2
Training loss: 2.2303769281463763
Validation loss: 2.537638287307354

Epoch: 5| Step: 3
Training loss: 2.5477543348459477
Validation loss: 2.5211327640307286

Epoch: 5| Step: 4
Training loss: 2.173388166711014
Validation loss: 2.521022227332425

Epoch: 5| Step: 5
Training loss: 1.8792240881199775
Validation loss: 2.5256867319977037

Epoch: 5| Step: 6
Training loss: 2.0677433987838314
Validation loss: 2.5467215493747735

Epoch: 5| Step: 7
Training loss: 2.1838212824489
Validation loss: 2.551900982991912

Epoch: 5| Step: 8
Training loss: 2.504508245173168
Validation loss: 2.527264512719928

Epoch: 5| Step: 9
Training loss: 1.6274673363708347
Validation loss: 2.5365621922801287

Epoch: 5| Step: 10
Training loss: 1.8257345889800614
Validation loss: 2.536377951871224

Epoch: 5| Step: 11
Training loss: 2.8041914392277385
Validation loss: 2.5251429968179804

Epoch: 302| Step: 0
Training loss: 2.8176078190859126
Validation loss: 2.5202313143036172

Epoch: 5| Step: 1
Training loss: 2.28793421725427
Validation loss: 2.5211113935337277

Epoch: 5| Step: 2
Training loss: 1.651657142201102
Validation loss: 2.5374673537486006

Epoch: 5| Step: 3
Training loss: 1.8994737473551666
Validation loss: 2.5449820897084816

Epoch: 5| Step: 4
Training loss: 2.4116731442265844
Validation loss: 2.578530297066413

Epoch: 5| Step: 5
Training loss: 2.172615858002254
Validation loss: 2.5747707741752404

Epoch: 5| Step: 6
Training loss: 2.1188987207120715
Validation loss: 2.58308185935175

Epoch: 5| Step: 7
Training loss: 1.6587860556552432
Validation loss: 2.5682757732675436

Epoch: 5| Step: 8
Training loss: 2.286025809448538
Validation loss: 2.5751095871923404

Epoch: 5| Step: 9
Training loss: 2.4441542152098896
Validation loss: 2.552300071595563

Epoch: 5| Step: 10
Training loss: 2.2838651743108507
Validation loss: 2.516433641137981

Epoch: 5| Step: 11
Training loss: 1.0704115104823337
Validation loss: 2.5109291793410016

Epoch: 303| Step: 0
Training loss: 2.3144610569813975
Validation loss: 2.510043054429267

Epoch: 5| Step: 1
Training loss: 2.550929019964821
Validation loss: 2.511982521773588

Epoch: 5| Step: 2
Training loss: 2.1583959985225114
Validation loss: 2.4841122558297046

Epoch: 5| Step: 3
Training loss: 1.8989120329881264
Validation loss: 2.50625129582347

Epoch: 5| Step: 4
Training loss: 1.9239059509956216
Validation loss: 2.508152929711842

Epoch: 5| Step: 5
Training loss: 1.9617526119443758
Validation loss: 2.512761561536823

Epoch: 5| Step: 6
Training loss: 1.7528919439051132
Validation loss: 2.511919190599527

Epoch: 5| Step: 7
Training loss: 1.798686433030754
Validation loss: 2.5294476556204826

Epoch: 5| Step: 8
Training loss: 2.938498793898538
Validation loss: 2.5464054330081427

Epoch: 5| Step: 9
Training loss: 2.2842609966756946
Validation loss: 2.571656139697938

Epoch: 5| Step: 10
Training loss: 2.0024768274611926
Validation loss: 2.5877968786761847

Epoch: 5| Step: 11
Training loss: 3.109817396733743
Validation loss: 2.5971770033297026

Epoch: 304| Step: 0
Training loss: 1.8459864484717337
Validation loss: 2.618007356895376

Epoch: 5| Step: 1
Training loss: 2.0693411221693543
Validation loss: 2.5980490901350453

Epoch: 5| Step: 2
Training loss: 2.36393065554514
Validation loss: 2.5903102479546685

Epoch: 5| Step: 3
Training loss: 1.9228519344765385
Validation loss: 2.5697552387040528

Epoch: 5| Step: 4
Training loss: 2.506399261520038
Validation loss: 2.5837805742824167

Epoch: 5| Step: 5
Training loss: 2.385326422659834
Validation loss: 2.537412109011683

Epoch: 5| Step: 6
Training loss: 2.028452075981694
Validation loss: 2.5366278434421297

Epoch: 5| Step: 7
Training loss: 2.2285375568938863
Validation loss: 2.5251371409372947

Epoch: 5| Step: 8
Training loss: 2.3556782643527625
Validation loss: 2.500747100142466

Epoch: 5| Step: 9
Training loss: 1.8101737122399322
Validation loss: 2.497734247110812

Epoch: 5| Step: 10
Training loss: 2.146229111798083
Validation loss: 2.4984455322429153

Epoch: 5| Step: 11
Training loss: 2.637531341800414
Validation loss: 2.51302002559247

Epoch: 305| Step: 0
Training loss: 2.625785074455384
Validation loss: 2.508152927731479

Epoch: 5| Step: 1
Training loss: 2.516265598027055
Validation loss: 2.491590920756726

Epoch: 5| Step: 2
Training loss: 2.2079945310372886
Validation loss: 2.5049949259018156

Epoch: 5| Step: 3
Training loss: 2.155618547500151
Validation loss: 2.5044235274421958

Epoch: 5| Step: 4
Training loss: 2.0800381222312496
Validation loss: 2.502718996608327

Epoch: 5| Step: 5
Training loss: 2.2172523064312633
Validation loss: 2.5082955494334085

Epoch: 5| Step: 6
Training loss: 1.9842702282257443
Validation loss: 2.5214462888063784

Epoch: 5| Step: 7
Training loss: 1.661128363135208
Validation loss: 2.572179041211213

Epoch: 5| Step: 8
Training loss: 1.7601074157794425
Validation loss: 2.5626083037121514

Epoch: 5| Step: 9
Training loss: 2.1333543696955783
Validation loss: 2.564902989329594

Epoch: 5| Step: 10
Training loss: 2.295844748780751
Validation loss: 2.566390333121462

Epoch: 5| Step: 11
Training loss: 3.46779653831013
Validation loss: 2.5477439123640004

Epoch: 306| Step: 0
Training loss: 2.489981413316105
Validation loss: 2.530048646490608

Epoch: 5| Step: 1
Training loss: 2.142370361714834
Validation loss: 2.486923038721419

Epoch: 5| Step: 2
Training loss: 2.124060703696069
Validation loss: 2.4610363208770063

Epoch: 5| Step: 3
Training loss: 1.9585463698826093
Validation loss: 2.488342020918578

Epoch: 5| Step: 4
Training loss: 2.6148044953649427
Validation loss: 2.5002774720387837

Epoch: 5| Step: 5
Training loss: 1.7867347199493988
Validation loss: 2.48297813019907

Epoch: 5| Step: 6
Training loss: 2.509321952819692
Validation loss: 2.4786530945803724

Epoch: 5| Step: 7
Training loss: 1.9372589207452575
Validation loss: 2.4781149401787257

Epoch: 5| Step: 8
Training loss: 2.2108121910574896
Validation loss: 2.496543831759638

Epoch: 5| Step: 9
Training loss: 2.3794451825007186
Validation loss: 2.5501427389224482

Epoch: 5| Step: 10
Training loss: 1.6624346010352156
Validation loss: 2.54837805037209

Epoch: 5| Step: 11
Training loss: 1.1435529153420834
Validation loss: 2.5497851293703255

Epoch: 307| Step: 0
Training loss: 2.124603122225757
Validation loss: 2.550843096417081

Epoch: 5| Step: 1
Training loss: 2.606076834435236
Validation loss: 2.545053482068291

Epoch: 5| Step: 2
Training loss: 1.882768242660115
Validation loss: 2.584606400462257

Epoch: 5| Step: 3
Training loss: 1.9185970232988685
Validation loss: 2.575947148005225

Epoch: 5| Step: 4
Training loss: 2.272107236554445
Validation loss: 2.5478078814780925

Epoch: 5| Step: 5
Training loss: 2.462986653064492
Validation loss: 2.5522895470172577

Epoch: 5| Step: 6
Training loss: 2.0116508398352613
Validation loss: 2.5237363238796227

Epoch: 5| Step: 7
Training loss: 2.4787338798025704
Validation loss: 2.523569070163422

Epoch: 5| Step: 8
Training loss: 1.6999007336301044
Validation loss: 2.5104914940304566

Epoch: 5| Step: 9
Training loss: 2.1073482242473656
Validation loss: 2.5177938577511756

Epoch: 5| Step: 10
Training loss: 2.159799501509052
Validation loss: 2.5197462635804233

Epoch: 5| Step: 11
Training loss: 0.7405535731901571
Validation loss: 2.5356236219508164

Epoch: 308| Step: 0
Training loss: 1.7931269158306238
Validation loss: 2.5108015839039814

Epoch: 5| Step: 1
Training loss: 1.673273517684461
Validation loss: 2.5191843666399585

Epoch: 5| Step: 2
Training loss: 1.662851242018442
Validation loss: 2.5328261644707464

Epoch: 5| Step: 3
Training loss: 2.623128587212699
Validation loss: 2.4938292541753104

Epoch: 5| Step: 4
Training loss: 1.4703885941470887
Validation loss: 2.5355530434674813

Epoch: 5| Step: 5
Training loss: 1.7742258075958401
Validation loss: 2.5339992216383016

Epoch: 5| Step: 6
Training loss: 2.7137077314897087
Validation loss: 2.5519776004505297

Epoch: 5| Step: 7
Training loss: 1.318754733108777
Validation loss: 2.548447141272424

Epoch: 5| Step: 8
Training loss: 2.545367771998098
Validation loss: 2.6161933339205334

Epoch: 5| Step: 9
Training loss: 2.651377978223898
Validation loss: 2.5936849348494224

Epoch: 5| Step: 10
Training loss: 2.643758145222843
Validation loss: 2.612362983980074

Epoch: 5| Step: 11
Training loss: 2.226601369418127
Validation loss: 2.5986037436083573

Epoch: 309| Step: 0
Training loss: 2.100081024423359
Validation loss: 2.5461497766230403

Epoch: 5| Step: 1
Training loss: 2.649878365946083
Validation loss: 2.531865398338868

Epoch: 5| Step: 2
Training loss: 1.8927642447303787
Validation loss: 2.506541547045252

Epoch: 5| Step: 3
Training loss: 2.4419832326015025
Validation loss: 2.516426069451421

Epoch: 5| Step: 4
Training loss: 1.7689925630670824
Validation loss: 2.5129968329092285

Epoch: 5| Step: 5
Training loss: 2.418295300546344
Validation loss: 2.5139078317517463

Epoch: 5| Step: 6
Training loss: 1.4808807202458358
Validation loss: 2.5314982924327833

Epoch: 5| Step: 7
Training loss: 2.4243370093692747
Validation loss: 2.536227183739925

Epoch: 5| Step: 8
Training loss: 2.4946073544986787
Validation loss: 2.5258686314468544

Epoch: 5| Step: 9
Training loss: 2.2736695685691344
Validation loss: 2.5617303002428558

Epoch: 5| Step: 10
Training loss: 1.9129949589935582
Validation loss: 2.5773891169392393

Epoch: 5| Step: 11
Training loss: 0.8167656650354559
Validation loss: 2.574043781236692

Epoch: 310| Step: 0
Training loss: 2.065908101544476
Validation loss: 2.57622129881183

Epoch: 5| Step: 1
Training loss: 1.7373627368305655
Validation loss: 2.5804031171237134

Epoch: 5| Step: 2
Training loss: 2.16720650134458
Validation loss: 2.5565470927794247

Epoch: 5| Step: 3
Training loss: 2.2866428332666935
Validation loss: 2.546410309538124

Epoch: 5| Step: 4
Training loss: 2.1240912345501712
Validation loss: 2.5319689487104573

Epoch: 5| Step: 5
Training loss: 2.1561501521336917
Validation loss: 2.5211368659160414

Epoch: 5| Step: 6
Training loss: 2.638853302654334
Validation loss: 2.5246707355358025

Epoch: 5| Step: 7
Training loss: 2.1618652205895326
Validation loss: 2.5368667811545444

Epoch: 5| Step: 8
Training loss: 1.887121880153693
Validation loss: 2.524909638213755

Epoch: 5| Step: 9
Training loss: 2.3415449832600634
Validation loss: 2.5074459334871038

Epoch: 5| Step: 10
Training loss: 1.8554341845053426
Validation loss: 2.517027493582462

Epoch: 5| Step: 11
Training loss: 1.8780598151499344
Validation loss: 2.556767203371869

Epoch: 311| Step: 0
Training loss: 2.485604899447216
Validation loss: 2.5733422623633433

Epoch: 5| Step: 1
Training loss: 2.2664735454679166
Validation loss: 2.608092417321106

Epoch: 5| Step: 2
Training loss: 2.9132262147230197
Validation loss: 2.580585457771493

Epoch: 5| Step: 3
Training loss: 2.1821596626167974
Validation loss: 2.5541745155912925

Epoch: 5| Step: 4
Training loss: 1.9643771336076918
Validation loss: 2.5498565275059626

Epoch: 5| Step: 5
Training loss: 1.7168734623444195
Validation loss: 2.4645221337152416

Epoch: 5| Step: 6
Training loss: 2.399626694892626
Validation loss: 2.471286908766349

Epoch: 5| Step: 7
Training loss: 1.6447730532223725
Validation loss: 2.468048911600634

Epoch: 5| Step: 8
Training loss: 2.148351605172161
Validation loss: 2.462513167931839

Epoch: 5| Step: 9
Training loss: 1.643053129009319
Validation loss: 2.461625550980686

Epoch: 5| Step: 10
Training loss: 2.4398715879700905
Validation loss: 2.484485151939886

Epoch: 5| Step: 11
Training loss: 1.8770819231790827
Validation loss: 2.4896348179131715

Epoch: 312| Step: 0
Training loss: 1.8805544914093588
Validation loss: 2.511051696510026

Epoch: 5| Step: 1
Training loss: 2.3991202212156746
Validation loss: 2.5798076841168314

Epoch: 5| Step: 2
Training loss: 2.2891220762031765
Validation loss: 2.6227846826479375

Epoch: 5| Step: 3
Training loss: 2.010786295958657
Validation loss: 2.623821565476832

Epoch: 5| Step: 4
Training loss: 1.7300582639993012
Validation loss: 2.6345565822312444

Epoch: 5| Step: 5
Training loss: 1.785062891816554
Validation loss: 2.5934429752990584

Epoch: 5| Step: 6
Training loss: 2.079701105613541
Validation loss: 2.604210564561245

Epoch: 5| Step: 7
Training loss: 2.0682321136486914
Validation loss: 2.5898013871431202

Epoch: 5| Step: 8
Training loss: 1.9850385862967284
Validation loss: 2.5190803025706643

Epoch: 5| Step: 9
Training loss: 3.067973170266344
Validation loss: 2.537529029429586

Epoch: 5| Step: 10
Training loss: 2.038313103131235
Validation loss: 2.5341692601493486

Epoch: 5| Step: 11
Training loss: 3.2112197937515488
Validation loss: 2.5015655979802083

Epoch: 313| Step: 0
Training loss: 1.8935997629530532
Validation loss: 2.525957874337214

Epoch: 5| Step: 1
Training loss: 2.035702447211469
Validation loss: 2.508292135479075

Epoch: 5| Step: 2
Training loss: 2.065792230482113
Validation loss: 2.5126170306682143

Epoch: 5| Step: 3
Training loss: 2.266533189471226
Validation loss: 2.4886566310134874

Epoch: 5| Step: 4
Training loss: 1.872050826996597
Validation loss: 2.4770924455449967

Epoch: 5| Step: 5
Training loss: 2.2178626636746186
Validation loss: 2.514307858016865

Epoch: 5| Step: 6
Training loss: 2.83659418242831
Validation loss: 2.532230108954725

Epoch: 5| Step: 7
Training loss: 2.4406500782087246
Validation loss: 2.528967978598429

Epoch: 5| Step: 8
Training loss: 1.9370034104426999
Validation loss: 2.597192723882461

Epoch: 5| Step: 9
Training loss: 1.9404626775355214
Validation loss: 2.62440161469626

Epoch: 5| Step: 10
Training loss: 1.9323473062927483
Validation loss: 2.612457278539646

Epoch: 5| Step: 11
Training loss: 2.1462814332307643
Validation loss: 2.5831068167795252

Epoch: 314| Step: 0
Training loss: 1.863870395632456
Validation loss: 2.5686015625301977

Epoch: 5| Step: 1
Training loss: 2.5513048087423456
Validation loss: 2.5954049587143886

Epoch: 5| Step: 2
Training loss: 2.3513434932277613
Validation loss: 2.5825929747281675

Epoch: 5| Step: 3
Training loss: 2.0583753089897603
Validation loss: 2.5640091638869955

Epoch: 5| Step: 4
Training loss: 2.325390637303408
Validation loss: 2.547643654722078

Epoch: 5| Step: 5
Training loss: 1.4112949159433177
Validation loss: 2.5423698872557123

Epoch: 5| Step: 6
Training loss: 1.7289670193175866
Validation loss: 2.5332136622091848

Epoch: 5| Step: 7
Training loss: 2.1927707932034024
Validation loss: 2.5330944797783363

Epoch: 5| Step: 8
Training loss: 2.468260897703251
Validation loss: 2.540155959772941

Epoch: 5| Step: 9
Training loss: 1.9826908924997402
Validation loss: 2.520400287276242

Epoch: 5| Step: 10
Training loss: 2.287492441467138
Validation loss: 2.558416050765551

Epoch: 5| Step: 11
Training loss: 2.194291607112295
Validation loss: 2.6007247755955514

Epoch: 315| Step: 0
Training loss: 2.694194617165277
Validation loss: 2.6259802660686025

Epoch: 5| Step: 1
Training loss: 2.0254730237277
Validation loss: 2.630247045301326

Epoch: 5| Step: 2
Training loss: 2.0190916782024964
Validation loss: 2.594110042600649

Epoch: 5| Step: 3
Training loss: 2.1696854126898355
Validation loss: 2.5957146867504632

Epoch: 5| Step: 4
Training loss: 1.425042533239748
Validation loss: 2.5890456475933585

Epoch: 5| Step: 5
Training loss: 1.5244806875054693
Validation loss: 2.5839260533969863

Epoch: 5| Step: 6
Training loss: 1.6353856304487697
Validation loss: 2.5744273979594667

Epoch: 5| Step: 7
Training loss: 2.391194095067748
Validation loss: 2.5495480510898956

Epoch: 5| Step: 8
Training loss: 2.2798549619352846
Validation loss: 2.5623819665163876

Epoch: 5| Step: 9
Training loss: 1.798682655309126
Validation loss: 2.5463090279450316

Epoch: 5| Step: 10
Training loss: 2.3919687919877344
Validation loss: 2.5369806489500917

Epoch: 5| Step: 11
Training loss: 3.901834296191852
Validation loss: 2.5654451146876265

Epoch: 316| Step: 0
Training loss: 2.1012841930251076
Validation loss: 2.557476962822617

Epoch: 5| Step: 1
Training loss: 1.995461440296628
Validation loss: 2.6129852150054598

Epoch: 5| Step: 2
Training loss: 2.579380723721823
Validation loss: 2.5878293472808522

Epoch: 5| Step: 3
Training loss: 2.0131977459217887
Validation loss: 2.5483290884104424

Epoch: 5| Step: 4
Training loss: 1.6055467869710924
Validation loss: 2.5752471042941796

Epoch: 5| Step: 5
Training loss: 2.1684388346983368
Validation loss: 2.584420442008689

Epoch: 5| Step: 6
Training loss: 2.1069378372096605
Validation loss: 2.537798902605677

Epoch: 5| Step: 7
Training loss: 2.2442618421148857
Validation loss: 2.5279565586077717

Epoch: 5| Step: 8
Training loss: 2.7106653785996473
Validation loss: 2.5060683312216985

Epoch: 5| Step: 9
Training loss: 2.133181138371518
Validation loss: 2.4630131722520203

Epoch: 5| Step: 10
Training loss: 1.6877705392493254
Validation loss: 2.4823350588556594

Epoch: 5| Step: 11
Training loss: 2.1966179601028677
Validation loss: 2.486985360715386

Epoch: 317| Step: 0
Training loss: 1.2372224535030916
Validation loss: 2.5175764953434387

Epoch: 5| Step: 1
Training loss: 1.984026239940721
Validation loss: 2.492834692761344

Epoch: 5| Step: 2
Training loss: 1.7275085619039392
Validation loss: 2.5217178713328616

Epoch: 5| Step: 3
Training loss: 2.214871630081084
Validation loss: 2.5340621773995604

Epoch: 5| Step: 4
Training loss: 2.5521587023342875
Validation loss: 2.5638803276701116

Epoch: 5| Step: 5
Training loss: 2.3875265549386273
Validation loss: 2.5535400061114246

Epoch: 5| Step: 6
Training loss: 1.8887052010374148
Validation loss: 2.5755072240723833

Epoch: 5| Step: 7
Training loss: 2.936175433268039
Validation loss: 2.5589467200719898

Epoch: 5| Step: 8
Training loss: 2.1806610011734
Validation loss: 2.5440294365326936

Epoch: 5| Step: 9
Training loss: 1.8353693306137842
Validation loss: 2.58794628155437

Epoch: 5| Step: 10
Training loss: 2.007660262574182
Validation loss: 2.5655589221804034

Epoch: 5| Step: 11
Training loss: 2.2497699408005123
Validation loss: 2.5336156787093893

Epoch: 318| Step: 0
Training loss: 2.3187025245268775
Validation loss: 2.56731259441155

Epoch: 5| Step: 1
Training loss: 1.9972527828657947
Validation loss: 2.647704860510787

Epoch: 5| Step: 2
Training loss: 1.7045792836386946
Validation loss: 2.700896404688884

Epoch: 5| Step: 3
Training loss: 2.3527570459602654
Validation loss: 2.7024474866001413

Epoch: 5| Step: 4
Training loss: 1.98625406522917
Validation loss: 2.6990908929673285

Epoch: 5| Step: 5
Training loss: 2.386581991370081
Validation loss: 2.640735101003358

Epoch: 5| Step: 6
Training loss: 2.590005492716381
Validation loss: 2.572108567834666

Epoch: 5| Step: 7
Training loss: 2.3429342248909863
Validation loss: 2.516390302991074

Epoch: 5| Step: 8
Training loss: 1.930743033029428
Validation loss: 2.514337152763113

Epoch: 5| Step: 9
Training loss: 1.8372757599691358
Validation loss: 2.510668950970663

Epoch: 5| Step: 10
Training loss: 2.329586415237338
Validation loss: 2.527371559206255

Epoch: 5| Step: 11
Training loss: 2.2689864904977464
Validation loss: 2.5293075031071948

Epoch: 319| Step: 0
Training loss: 2.421879036192453
Validation loss: 2.5313762468479326

Epoch: 5| Step: 1
Training loss: 2.192065026035756
Validation loss: 2.5128553675332603

Epoch: 5| Step: 2
Training loss: 1.593167591266435
Validation loss: 2.5287764987258

Epoch: 5| Step: 3
Training loss: 2.213595676137205
Validation loss: 2.5482695804286415

Epoch: 5| Step: 4
Training loss: 2.0783984929291486
Validation loss: 2.548006227769382

Epoch: 5| Step: 5
Training loss: 2.4111802755808402
Validation loss: 2.5299524859225007

Epoch: 5| Step: 6
Training loss: 2.2058246926644163
Validation loss: 2.5429998650822694

Epoch: 5| Step: 7
Training loss: 2.00635377609571
Validation loss: 2.554123336918153

Epoch: 5| Step: 8
Training loss: 2.068895654074296
Validation loss: 2.5761292796051505

Epoch: 5| Step: 9
Training loss: 2.2401958485544005
Validation loss: 2.5356576126968853

Epoch: 5| Step: 10
Training loss: 2.6891096750451418
Validation loss: 2.533676871787793

Epoch: 5| Step: 11
Training loss: 1.3793578880641775
Validation loss: 2.533717295186709

Epoch: 320| Step: 0
Training loss: 1.8702656420555979
Validation loss: 2.563924250187238

Epoch: 5| Step: 1
Training loss: 2.212227488831406
Validation loss: 2.6018183852508723

Epoch: 5| Step: 2
Training loss: 1.513869222266324
Validation loss: 2.620097657542144

Epoch: 5| Step: 3
Training loss: 2.7603209760862466
Validation loss: 2.6388331923267825

Epoch: 5| Step: 4
Training loss: 2.284065912421346
Validation loss: 2.6364295028462625

Epoch: 5| Step: 5
Training loss: 2.5424013691453746
Validation loss: 2.5737863543145916

Epoch: 5| Step: 6
Training loss: 2.918244906715557
Validation loss: 2.526841364773566

Epoch: 5| Step: 7
Training loss: 1.8206052094577874
Validation loss: 2.50625597698612

Epoch: 5| Step: 8
Training loss: 1.8768447066640168
Validation loss: 2.5063157333797474

Epoch: 5| Step: 9
Training loss: 2.1504008252199043
Validation loss: 2.488481762051792

Epoch: 5| Step: 10
Training loss: 1.8769898981626314
Validation loss: 2.5001662675880834

Epoch: 5| Step: 11
Training loss: 2.060457663390173
Validation loss: 2.4934245340944288

Epoch: 321| Step: 0
Training loss: 1.9779946186312611
Validation loss: 2.5107346817393057

Epoch: 5| Step: 1
Training loss: 2.1012374456372127
Validation loss: 2.5156145707698117

Epoch: 5| Step: 2
Training loss: 2.1210625015682782
Validation loss: 2.511432237831041

Epoch: 5| Step: 3
Training loss: 2.3739424910999434
Validation loss: 2.505750571009966

Epoch: 5| Step: 4
Training loss: 2.0791382578079234
Validation loss: 2.502502297753833

Epoch: 5| Step: 5
Training loss: 2.279788450498932
Validation loss: 2.5301718986550443

Epoch: 5| Step: 6
Training loss: 2.1012917950505536
Validation loss: 2.550993321995086

Epoch: 5| Step: 7
Training loss: 2.193490898285611
Validation loss: 2.5979256511758226

Epoch: 5| Step: 8
Training loss: 2.461421858336613
Validation loss: 2.6576920503163026

Epoch: 5| Step: 9
Training loss: 2.021251543430171
Validation loss: 2.6755935510297366

Epoch: 5| Step: 10
Training loss: 2.104014954589958
Validation loss: 2.680785259200768

Epoch: 5| Step: 11
Training loss: 2.1020355259500154
Validation loss: 2.643547780544961

Epoch: 322| Step: 0
Training loss: 2.7113225042375286
Validation loss: 2.574900508396788

Epoch: 5| Step: 1
Training loss: 2.082325984283387
Validation loss: 2.523316375533922

Epoch: 5| Step: 2
Training loss: 1.9177043289675977
Validation loss: 2.526182301856999

Epoch: 5| Step: 3
Training loss: 2.3194584671581384
Validation loss: 2.5214484360209695

Epoch: 5| Step: 4
Training loss: 2.472033092203208
Validation loss: 2.5239139339390118

Epoch: 5| Step: 5
Training loss: 2.117557957744425
Validation loss: 2.54483902963

Epoch: 5| Step: 6
Training loss: 2.180951917332556
Validation loss: 2.5318213905027016

Epoch: 5| Step: 7
Training loss: 1.4589096928572522
Validation loss: 2.5608243930084185

Epoch: 5| Step: 8
Training loss: 1.814417778138957
Validation loss: 2.5443953981755523

Epoch: 5| Step: 9
Training loss: 2.094075533483762
Validation loss: 2.555815013353005

Epoch: 5| Step: 10
Training loss: 2.1898468507492317
Validation loss: 2.5445387760028018

Epoch: 5| Step: 11
Training loss: 1.618708461979687
Validation loss: 2.5632447346810245

Epoch: 323| Step: 0
Training loss: 1.4177770563865855
Validation loss: 2.5651531130902097

Epoch: 5| Step: 1
Training loss: 2.1309310942974666
Validation loss: 2.5849389821210504

Epoch: 5| Step: 2
Training loss: 2.428425844621307
Validation loss: 2.5627460129040447

Epoch: 5| Step: 3
Training loss: 2.321210899208587
Validation loss: 2.5841626879236945

Epoch: 5| Step: 4
Training loss: 1.7411024195669114
Validation loss: 2.5996475197821094

Epoch: 5| Step: 5
Training loss: 1.9844397586858795
Validation loss: 2.6164337818925563

Epoch: 5| Step: 6
Training loss: 1.7760867861687317
Validation loss: 2.610432762579425

Epoch: 5| Step: 7
Training loss: 2.2289669505938394
Validation loss: 2.613628567745559

Epoch: 5| Step: 8
Training loss: 2.3513486644561246
Validation loss: 2.656439557511127

Epoch: 5| Step: 9
Training loss: 2.4197369397844817
Validation loss: 2.6719009665850337

Epoch: 5| Step: 10
Training loss: 2.2935019917717505
Validation loss: 2.6655912180254746

Epoch: 5| Step: 11
Training loss: 2.352244940297518
Validation loss: 2.6770432366560883

Epoch: 324| Step: 0
Training loss: 2.0824997823836453
Validation loss: 2.5675389709226564

Epoch: 5| Step: 1
Training loss: 1.9892306056758158
Validation loss: 2.549452033724914

Epoch: 5| Step: 2
Training loss: 2.523516485436643
Validation loss: 2.5044473191423156

Epoch: 5| Step: 3
Training loss: 1.6643565459881071
Validation loss: 2.520141038858405

Epoch: 5| Step: 4
Training loss: 2.1171904278836995
Validation loss: 2.487418731403432

Epoch: 5| Step: 5
Training loss: 2.3470766999268164
Validation loss: 2.519648720223127

Epoch: 5| Step: 6
Training loss: 2.4235406869629292
Validation loss: 2.4814425762050836

Epoch: 5| Step: 7
Training loss: 2.3088562585391093
Validation loss: 2.4651794869942334

Epoch: 5| Step: 8
Training loss: 2.045606613286338
Validation loss: 2.5228477847941315

Epoch: 5| Step: 9
Training loss: 1.8176561218749618
Validation loss: 2.5506369222299883

Epoch: 5| Step: 10
Training loss: 2.2757660257319365
Validation loss: 2.5411027956413794

Epoch: 5| Step: 11
Training loss: 2.2063966091818754
Validation loss: 2.586729990447875

Epoch: 325| Step: 0
Training loss: 1.6233866091582096
Validation loss: 2.5265619089616984

Epoch: 5| Step: 1
Training loss: 2.135074408170374
Validation loss: 2.5328178200968856

Epoch: 5| Step: 2
Training loss: 2.355948277590603
Validation loss: 2.4987412581959574

Epoch: 5| Step: 3
Training loss: 1.582447590615461
Validation loss: 2.5177095397159293

Epoch: 5| Step: 4
Training loss: 2.060717419260452
Validation loss: 2.502784580921698

Epoch: 5| Step: 5
Training loss: 1.492159139153954
Validation loss: 2.523394764399564

Epoch: 5| Step: 6
Training loss: 2.238486075890754
Validation loss: 2.4959903789163156

Epoch: 5| Step: 7
Training loss: 2.1690674343363523
Validation loss: 2.5405145767382837

Epoch: 5| Step: 8
Training loss: 2.246132069136446
Validation loss: 2.531340648456533

Epoch: 5| Step: 9
Training loss: 2.864232674145993
Validation loss: 2.539336497855007

Epoch: 5| Step: 10
Training loss: 1.420619871748711
Validation loss: 2.5499792663815883

Epoch: 5| Step: 11
Training loss: 2.7211889968223453
Validation loss: 2.5527477891565176

Epoch: 326| Step: 0
Training loss: 2.054502413575831
Validation loss: 2.6258701517116

Epoch: 5| Step: 1
Training loss: 2.353845444991291
Validation loss: 2.714677548524019

Epoch: 5| Step: 2
Training loss: 2.2718883361844755
Validation loss: 2.7648331070567838

Epoch: 5| Step: 3
Training loss: 3.037539848411618
Validation loss: 2.7975994997394795

Epoch: 5| Step: 4
Training loss: 2.639277006909593
Validation loss: 2.670437997094044

Epoch: 5| Step: 5
Training loss: 2.1628306494387988
Validation loss: 2.5591994483493625

Epoch: 5| Step: 6
Training loss: 1.9811770886022753
Validation loss: 2.52478456317771

Epoch: 5| Step: 7
Training loss: 1.8841382815846321
Validation loss: 2.4921127076919314

Epoch: 5| Step: 8
Training loss: 2.390600067208116
Validation loss: 2.472821837269849

Epoch: 5| Step: 9
Training loss: 2.247971574067373
Validation loss: 2.4770308933102596

Epoch: 5| Step: 10
Training loss: 2.077490343973463
Validation loss: 2.490475232811766

Epoch: 5| Step: 11
Training loss: 1.8418951240944317
Validation loss: 2.50071627766753

Epoch: 327| Step: 0
Training loss: 2.2912545498284067
Validation loss: 2.487525441887873

Epoch: 5| Step: 1
Training loss: 2.663920558157345
Validation loss: 2.515153848664659

Epoch: 5| Step: 2
Training loss: 1.997837029528326
Validation loss: 2.4875169555367345

Epoch: 5| Step: 3
Training loss: 2.0362544693496765
Validation loss: 2.4723581713956784

Epoch: 5| Step: 4
Training loss: 2.342194002535639
Validation loss: 2.4632302074586385

Epoch: 5| Step: 5
Training loss: 2.0241318619637156
Validation loss: 2.425080970759295

Epoch: 5| Step: 6
Training loss: 2.127838482943917
Validation loss: 2.4429522286167424

Epoch: 5| Step: 7
Training loss: 2.4262896264607297
Validation loss: 2.4519669944067464

Epoch: 5| Step: 8
Training loss: 2.348342769740115
Validation loss: 2.5318542316582833

Epoch: 5| Step: 9
Training loss: 2.1673316913099043
Validation loss: 2.5460004026428127

Epoch: 5| Step: 10
Training loss: 2.7459164558143447
Validation loss: 2.5798230715332187

Epoch: 5| Step: 11
Training loss: 2.9491377459384704
Validation loss: 2.5608773851117745

Epoch: 328| Step: 0
Training loss: 1.884705600869821
Validation loss: 2.497938844255164

Epoch: 5| Step: 1
Training loss: 2.5849883305417194
Validation loss: 2.4603304038455653

Epoch: 5| Step: 2
Training loss: 2.1975436022081465
Validation loss: 2.445748076071254

Epoch: 5| Step: 3
Training loss: 2.2157682342932503
Validation loss: 2.4295028215650887

Epoch: 5| Step: 4
Training loss: 1.707873522897654
Validation loss: 2.429468535505364

Epoch: 5| Step: 5
Training loss: 1.9580108566450776
Validation loss: 2.439224562310286

Epoch: 5| Step: 6
Training loss: 2.481657833530273
Validation loss: 2.4469397130717803

Epoch: 5| Step: 7
Training loss: 1.8105454923260296
Validation loss: 2.4405942415911563

Epoch: 5| Step: 8
Training loss: 1.940128819524489
Validation loss: 2.442443021235285

Epoch: 5| Step: 9
Training loss: 2.6726667335391623
Validation loss: 2.4402670397118458

Epoch: 5| Step: 10
Training loss: 2.8089966040726884
Validation loss: 2.452890174301036

Epoch: 5| Step: 11
Training loss: 1.399417895826266
Validation loss: 2.445697664714673

Epoch: 329| Step: 0
Training loss: 2.6633891488036605
Validation loss: 2.4396874931397017

Epoch: 5| Step: 1
Training loss: 2.322001757441208
Validation loss: 2.4463376830365076

Epoch: 5| Step: 2
Training loss: 1.9349875618783763
Validation loss: 2.4745191815084335

Epoch: 5| Step: 3
Training loss: 2.4056302548215087
Validation loss: 2.5004240232729287

Epoch: 5| Step: 4
Training loss: 1.5383954611673116
Validation loss: 2.5167729382676995

Epoch: 5| Step: 5
Training loss: 2.35911336294431
Validation loss: 2.518130356047662

Epoch: 5| Step: 6
Training loss: 2.010963668593694
Validation loss: 2.5301920873927375

Epoch: 5| Step: 7
Training loss: 2.511150479734848
Validation loss: 2.517782987709113

Epoch: 5| Step: 8
Training loss: 2.6959254355717253
Validation loss: 2.531062205534279

Epoch: 5| Step: 9
Training loss: 1.6456782674372172
Validation loss: 2.527185614943553

Epoch: 5| Step: 10
Training loss: 2.1473454699800514
Validation loss: 2.5211748700980485

Epoch: 5| Step: 11
Training loss: 2.0019181113553954
Validation loss: 2.49382302600376

Epoch: 330| Step: 0
Training loss: 2.3359450528332117
Validation loss: 2.492048959259534

Epoch: 5| Step: 1
Training loss: 1.572634673787815
Validation loss: 2.4607022995547787

Epoch: 5| Step: 2
Training loss: 2.3805388061911494
Validation loss: 2.4310253033757596

Epoch: 5| Step: 3
Training loss: 2.0148304400793897
Validation loss: 2.4294886369676956

Epoch: 5| Step: 4
Training loss: 2.528708889636973
Validation loss: 2.438516624894608

Epoch: 5| Step: 5
Training loss: 2.0807659605844795
Validation loss: 2.4246586420080947

Epoch: 5| Step: 6
Training loss: 2.806096480148553
Validation loss: 2.415620381398986

Epoch: 5| Step: 7
Training loss: 1.603679616071938
Validation loss: 2.4304228975030964

Epoch: 5| Step: 8
Training loss: 1.9210027560681455
Validation loss: 2.444262464991145

Epoch: 5| Step: 9
Training loss: 2.023959884080147
Validation loss: 2.4586147023405114

Epoch: 5| Step: 10
Training loss: 1.6323747550040513
Validation loss: 2.4550423185801997

Epoch: 5| Step: 11
Training loss: 3.027332724274277
Validation loss: 2.431621958955873

Epoch: 331| Step: 0
Training loss: 1.8637250775539211
Validation loss: 2.4599162530923144

Epoch: 5| Step: 1
Training loss: 2.134714473240668
Validation loss: 2.467730380005832

Epoch: 5| Step: 2
Training loss: 2.594021610608225
Validation loss: 2.512739279725944

Epoch: 5| Step: 3
Training loss: 1.6957747009538926
Validation loss: 2.457309789996378

Epoch: 5| Step: 4
Training loss: 2.1342694682314374
Validation loss: 2.453436072483602

Epoch: 5| Step: 5
Training loss: 2.1218507655786536
Validation loss: 2.446294337588655

Epoch: 5| Step: 6
Training loss: 2.0470249033774865
Validation loss: 2.4307320752455794

Epoch: 5| Step: 7
Training loss: 2.028783503812217
Validation loss: 2.451937548037058

Epoch: 5| Step: 8
Training loss: 2.6443240649430644
Validation loss: 2.4039814398917083

Epoch: 5| Step: 9
Training loss: 2.0171475832747543
Validation loss: 2.4544390400697327

Epoch: 5| Step: 10
Training loss: 1.6812025467652973
Validation loss: 2.5033458572595912

Epoch: 5| Step: 11
Training loss: 1.950150872776249
Validation loss: 2.4971540782863824

Epoch: 332| Step: 0
Training loss: 1.856292349078615
Validation loss: 2.4867877080961582

Epoch: 5| Step: 1
Training loss: 2.084364394313934
Validation loss: 2.4989547729996864

Epoch: 5| Step: 2
Training loss: 2.3435044223555663
Validation loss: 2.443244835852055

Epoch: 5| Step: 3
Training loss: 2.13280243923623
Validation loss: 2.4603215047105507

Epoch: 5| Step: 4
Training loss: 1.9658443261852963
Validation loss: 2.488355582587676

Epoch: 5| Step: 5
Training loss: 1.6198569853963056
Validation loss: 2.4397738724098392

Epoch: 5| Step: 6
Training loss: 2.197716642079522
Validation loss: 2.4341364786530444

Epoch: 5| Step: 7
Training loss: 2.282627995924772
Validation loss: 2.4827410324946757

Epoch: 5| Step: 8
Training loss: 2.2202419583888338
Validation loss: 2.478085503858738

Epoch: 5| Step: 9
Training loss: 1.8512865979622928
Validation loss: 2.4746379654940616

Epoch: 5| Step: 10
Training loss: 2.2437550451705444
Validation loss: 2.481433950951398

Epoch: 5| Step: 11
Training loss: 3.089331660413337
Validation loss: 2.463895231337581

Epoch: 333| Step: 0
Training loss: 2.0446721227768143
Validation loss: 2.4507525020685046

Epoch: 5| Step: 1
Training loss: 1.8337642062208335
Validation loss: 2.4403435675487155

Epoch: 5| Step: 2
Training loss: 1.976640300199632
Validation loss: 2.4693450934806007

Epoch: 5| Step: 3
Training loss: 1.8801482412046742
Validation loss: 2.460074379347006

Epoch: 5| Step: 4
Training loss: 2.148563783575504
Validation loss: 2.473974984096242

Epoch: 5| Step: 5
Training loss: 2.044641805304663
Validation loss: 2.450292117843246

Epoch: 5| Step: 6
Training loss: 1.9640066741317188
Validation loss: 2.477099150908467

Epoch: 5| Step: 7
Training loss: 2.4150305723541625
Validation loss: 2.48459927328335

Epoch: 5| Step: 8
Training loss: 1.9761454025278005
Validation loss: 2.490422635410869

Epoch: 5| Step: 9
Training loss: 2.2336470478499724
Validation loss: 2.527794150734952

Epoch: 5| Step: 10
Training loss: 2.25209498889129
Validation loss: 2.4817040598887137

Epoch: 5| Step: 11
Training loss: 1.3731291788321498
Validation loss: 2.491000559502397

Epoch: 334| Step: 0
Training loss: 1.8083850583649566
Validation loss: 2.4742569927170597

Epoch: 5| Step: 1
Training loss: 2.0810221504378066
Validation loss: 2.4899924486114715

Epoch: 5| Step: 2
Training loss: 2.452275609008217
Validation loss: 2.4829859459136547

Epoch: 5| Step: 3
Training loss: 2.346051522966426
Validation loss: 2.4535984991586743

Epoch: 5| Step: 4
Training loss: 1.716072771739023
Validation loss: 2.4533492166056408

Epoch: 5| Step: 5
Training loss: 1.9211262430652034
Validation loss: 2.5031312486028447

Epoch: 5| Step: 6
Training loss: 1.8111639031060067
Validation loss: 2.53098981799536

Epoch: 5| Step: 7
Training loss: 2.255006729758766
Validation loss: 2.565139752187959

Epoch: 5| Step: 8
Training loss: 2.340884682443068
Validation loss: 2.545405063152066

Epoch: 5| Step: 9
Training loss: 1.7970126555415895
Validation loss: 2.4968462602205053

Epoch: 5| Step: 10
Training loss: 2.436807093802964
Validation loss: 2.4549019122356337

Epoch: 5| Step: 11
Training loss: 1.5349827636844493
Validation loss: 2.4624198566504623

Epoch: 335| Step: 0
Training loss: 1.9692499646124717
Validation loss: 2.413515899404311

Epoch: 5| Step: 1
Training loss: 1.6573731554842366
Validation loss: 2.4372057900197164

Epoch: 5| Step: 2
Training loss: 2.1720843317158964
Validation loss: 2.4606067495756885

Epoch: 5| Step: 3
Training loss: 1.9732572036741198
Validation loss: 2.458214497657363

Epoch: 5| Step: 4
Training loss: 1.9217665106693247
Validation loss: 2.4604836464232296

Epoch: 5| Step: 5
Training loss: 1.9270417767417138
Validation loss: 2.4540290017260205

Epoch: 5| Step: 6
Training loss: 1.782802908735361
Validation loss: 2.499831472120676

Epoch: 5| Step: 7
Training loss: 2.5052731215465713
Validation loss: 2.501767705776239

Epoch: 5| Step: 8
Training loss: 2.286131978187588
Validation loss: 2.515544941420014

Epoch: 5| Step: 9
Training loss: 2.2819690355010507
Validation loss: 2.5252786263877414

Epoch: 5| Step: 10
Training loss: 1.7761025590796446
Validation loss: 2.5682479118653814

Epoch: 5| Step: 11
Training loss: 3.770792474402399
Validation loss: 2.57797243071435

Epoch: 336| Step: 0
Training loss: 1.2424174641725971
Validation loss: 2.5002769634688757

Epoch: 5| Step: 1
Training loss: 2.188964680372373
Validation loss: 2.4617719517201686

Epoch: 5| Step: 2
Training loss: 2.220022239745494
Validation loss: 2.4547538168836343

Epoch: 5| Step: 3
Training loss: 1.738537030207183
Validation loss: 2.491443594757037

Epoch: 5| Step: 4
Training loss: 2.3611681862708176
Validation loss: 2.438838416034445

Epoch: 5| Step: 5
Training loss: 2.03980905013154
Validation loss: 2.442072789058193

Epoch: 5| Step: 6
Training loss: 2.374512672620233
Validation loss: 2.41988008435864

Epoch: 5| Step: 7
Training loss: 1.6046502841693773
Validation loss: 2.425718100888357

Epoch: 5| Step: 8
Training loss: 2.186397601685533
Validation loss: 2.463749811574721

Epoch: 5| Step: 9
Training loss: 2.0133590381236135
Validation loss: 2.4380541929491555

Epoch: 5| Step: 10
Training loss: 2.572067079289296
Validation loss: 2.4436576126599383

Epoch: 5| Step: 11
Training loss: 0.48954730882065667
Validation loss: 2.4854531577779047

Epoch: 337| Step: 0
Training loss: 2.252473954569869
Validation loss: 2.549136953535081

Epoch: 5| Step: 1
Training loss: 1.6257282239267115
Validation loss: 2.576858076280103

Epoch: 5| Step: 2
Training loss: 1.7492134506465618
Validation loss: 2.549016033081278

Epoch: 5| Step: 3
Training loss: 2.0318310420087258
Validation loss: 2.5527316042109898

Epoch: 5| Step: 4
Training loss: 2.388416541762624
Validation loss: 2.566639301744541

Epoch: 5| Step: 5
Training loss: 2.4834395272849212
Validation loss: 2.559195465696821

Epoch: 5| Step: 6
Training loss: 1.904374685409515
Validation loss: 2.5100423182888028

Epoch: 5| Step: 7
Training loss: 2.3782441920162722
Validation loss: 2.543706627678298

Epoch: 5| Step: 8
Training loss: 2.3571308907704647
Validation loss: 2.4876911315938743

Epoch: 5| Step: 9
Training loss: 1.5511583307002013
Validation loss: 2.5132073460018476

Epoch: 5| Step: 10
Training loss: 1.3999365332386509
Validation loss: 2.4784962378050017

Epoch: 5| Step: 11
Training loss: 1.3652999927648999
Validation loss: 2.4790621756857947

Epoch: 338| Step: 0
Training loss: 1.8260971951641904
Validation loss: 2.466516873014879

Epoch: 5| Step: 1
Training loss: 2.151798352270544
Validation loss: 2.4306235355377037

Epoch: 5| Step: 2
Training loss: 1.5757194540968926
Validation loss: 2.4904778335341495

Epoch: 5| Step: 3
Training loss: 2.1074202911399285
Validation loss: 2.5283533995147875

Epoch: 5| Step: 4
Training loss: 2.4366035769323218
Validation loss: 2.537326906201053

Epoch: 5| Step: 5
Training loss: 2.2813665281868665
Validation loss: 2.50014052790819

Epoch: 5| Step: 6
Training loss: 1.8479655936328616
Validation loss: 2.494074012784902

Epoch: 5| Step: 7
Training loss: 1.8910064312499215
Validation loss: 2.4580078771644476

Epoch: 5| Step: 8
Training loss: 2.1875852295756877
Validation loss: 2.4542033200584332

Epoch: 5| Step: 9
Training loss: 1.966264760713168
Validation loss: 2.4468510939598307

Epoch: 5| Step: 10
Training loss: 2.1461739007503478
Validation loss: 2.4440546731222375

Epoch: 5| Step: 11
Training loss: 0.9266866771220691
Validation loss: 2.46089405848999

Epoch: 339| Step: 0
Training loss: 1.961797335747197
Validation loss: 2.460325691830264

Epoch: 5| Step: 1
Training loss: 2.0091955267933668
Validation loss: 2.449721151494606

Epoch: 5| Step: 2
Training loss: 1.4138484813950896
Validation loss: 2.4430871166884334

Epoch: 5| Step: 3
Training loss: 1.590456757706847
Validation loss: 2.4170163137342797

Epoch: 5| Step: 4
Training loss: 2.4032474957858536
Validation loss: 2.4342622670460083

Epoch: 5| Step: 5
Training loss: 2.1777560519520924
Validation loss: 2.447149068457313

Epoch: 5| Step: 6
Training loss: 1.8142521380416763
Validation loss: 2.4640869756243786

Epoch: 5| Step: 7
Training loss: 2.1717500719325336
Validation loss: 2.5193991338112878

Epoch: 5| Step: 8
Training loss: 2.442727572128784
Validation loss: 2.5092810968332753

Epoch: 5| Step: 9
Training loss: 2.2090941384160234
Validation loss: 2.5232487500660494

Epoch: 5| Step: 10
Training loss: 1.4791330235196831
Validation loss: 2.5711981649494824

Epoch: 5| Step: 11
Training loss: 2.0730635880076367
Validation loss: 2.592417048920829

Epoch: 340| Step: 0
Training loss: 2.1253851373254946
Validation loss: 2.6200816952669617

Epoch: 5| Step: 1
Training loss: 2.2340155892643567
Validation loss: 2.6337446266304174

Epoch: 5| Step: 2
Training loss: 2.2390290986555903
Validation loss: 2.593350264758349

Epoch: 5| Step: 3
Training loss: 2.2043755411310184
Validation loss: 2.6098348931819624

Epoch: 5| Step: 4
Training loss: 1.7704431739786504
Validation loss: 2.522571159117757

Epoch: 5| Step: 5
Training loss: 1.778272650141242
Validation loss: 2.5000434752498797

Epoch: 5| Step: 6
Training loss: 1.897572261354109
Validation loss: 2.4606737651487007

Epoch: 5| Step: 7
Training loss: 2.173535926284993
Validation loss: 2.476758714478251

Epoch: 5| Step: 8
Training loss: 1.946354965878075
Validation loss: 2.474167922661954

Epoch: 5| Step: 9
Training loss: 1.9909531303418515
Validation loss: 2.4587844048216385

Epoch: 5| Step: 10
Training loss: 1.4400623538504487
Validation loss: 2.498218020496052

Epoch: 5| Step: 11
Training loss: 3.1071616111151816
Validation loss: 2.4832161153793897

Epoch: 341| Step: 0
Training loss: 2.17818122692682
Validation loss: 2.474115127145727

Epoch: 5| Step: 1
Training loss: 1.837952242881473
Validation loss: 2.464783552415088

Epoch: 5| Step: 2
Training loss: 1.7817109164151326
Validation loss: 2.475137049640632

Epoch: 5| Step: 3
Training loss: 1.888237383470643
Validation loss: 2.4648366606580665

Epoch: 5| Step: 4
Training loss: 2.192116144695234
Validation loss: 2.4581308658651753

Epoch: 5| Step: 5
Training loss: 1.9284013176124437
Validation loss: 2.4823694911405

Epoch: 5| Step: 6
Training loss: 2.298615814491011
Validation loss: 2.5139437797401

Epoch: 5| Step: 7
Training loss: 2.278649297802426
Validation loss: 2.4887289485874513

Epoch: 5| Step: 8
Training loss: 2.0855852036741793
Validation loss: 2.5876676067487523

Epoch: 5| Step: 9
Training loss: 1.6774999523589218
Validation loss: 2.6576299224523723

Epoch: 5| Step: 10
Training loss: 2.352719146056007
Validation loss: 2.724548284467871

Epoch: 5| Step: 11
Training loss: 1.1518068258857925
Validation loss: 2.6360816468429085

Epoch: 342| Step: 0
Training loss: 1.8688489473103918
Validation loss: 2.5864335321002145

Epoch: 5| Step: 1
Training loss: 1.7638392912866099
Validation loss: 2.506717078206325

Epoch: 5| Step: 2
Training loss: 1.9121180408503513
Validation loss: 2.4862433232031904

Epoch: 5| Step: 3
Training loss: 1.2628443276732824
Validation loss: 2.5271434694752304

Epoch: 5| Step: 4
Training loss: 2.043719006224635
Validation loss: 2.5205122346480846

Epoch: 5| Step: 5
Training loss: 2.3935026912574466
Validation loss: 2.506630302963972

Epoch: 5| Step: 6
Training loss: 2.1958502385781395
Validation loss: 2.5278112695440798

Epoch: 5| Step: 7
Training loss: 3.0883672878363475
Validation loss: 2.5081010317772154

Epoch: 5| Step: 8
Training loss: 1.8666157505493663
Validation loss: 2.5256106739791133

Epoch: 5| Step: 9
Training loss: 2.292841477249337
Validation loss: 2.523280415404226

Epoch: 5| Step: 10
Training loss: 1.6506946893068712
Validation loss: 2.5760605185240935

Epoch: 5| Step: 11
Training loss: 2.609355629489292
Validation loss: 2.557427483634029

Epoch: 343| Step: 0
Training loss: 2.315981538122512
Validation loss: 2.5802953119957883

Epoch: 5| Step: 1
Training loss: 2.1721232978992826
Validation loss: 2.5617436168813628

Epoch: 5| Step: 2
Training loss: 1.774331695038945
Validation loss: 2.563808669118461

Epoch: 5| Step: 3
Training loss: 1.7397275929587444
Validation loss: 2.622636086381966

Epoch: 5| Step: 4
Training loss: 2.1317683867561574
Validation loss: 2.6772261976028857

Epoch: 5| Step: 5
Training loss: 2.9888315529348333
Validation loss: 2.6203598230494394

Epoch: 5| Step: 6
Training loss: 1.7799305630116773
Validation loss: 2.609764271860315

Epoch: 5| Step: 7
Training loss: 1.76393127223614
Validation loss: 2.5036459285089836

Epoch: 5| Step: 8
Training loss: 2.144541033390708
Validation loss: 2.4621445697841335

Epoch: 5| Step: 9
Training loss: 1.6225647652135868
Validation loss: 2.486226337723659

Epoch: 5| Step: 10
Training loss: 2.2183175538626996
Validation loss: 2.4672013024493067

Epoch: 5| Step: 11
Training loss: 1.5010109514654006
Validation loss: 2.4582713625796404

Epoch: 344| Step: 0
Training loss: 2.255265855532797
Validation loss: 2.4786554512039856

Epoch: 5| Step: 1
Training loss: 2.772875403812064
Validation loss: 2.4837802818914856

Epoch: 5| Step: 2
Training loss: 1.3693901846743262
Validation loss: 2.483063855660597

Epoch: 5| Step: 3
Training loss: 1.5269576655466994
Validation loss: 2.5001401981143383

Epoch: 5| Step: 4
Training loss: 2.2080932222741807
Validation loss: 2.513109394680583

Epoch: 5| Step: 5
Training loss: 1.6055183495797867
Validation loss: 2.514654659522794

Epoch: 5| Step: 6
Training loss: 1.8365234738497684
Validation loss: 2.571764314694654

Epoch: 5| Step: 7
Training loss: 1.7553203633794265
Validation loss: 2.5427157720081666

Epoch: 5| Step: 8
Training loss: 2.6061367568334943
Validation loss: 2.563857083612982

Epoch: 5| Step: 9
Training loss: 2.3530489763641675
Validation loss: 2.5872518765996273

Epoch: 5| Step: 10
Training loss: 1.3974461797951985
Validation loss: 2.5764069159551983

Epoch: 5| Step: 11
Training loss: 2.006638358012577
Validation loss: 2.553413981670688

Epoch: 345| Step: 0
Training loss: 1.776313432799741
Validation loss: 2.5130878077198378

Epoch: 5| Step: 1
Training loss: 2.3147306251757382
Validation loss: 2.510482812276501

Epoch: 5| Step: 2
Training loss: 2.1196152397300434
Validation loss: 2.4940740526157463

Epoch: 5| Step: 3
Training loss: 1.8706835334916503
Validation loss: 2.478200068224751

Epoch: 5| Step: 4
Training loss: 1.9598402015588827
Validation loss: 2.4756197453685203

Epoch: 5| Step: 5
Training loss: 1.7867472630916572
Validation loss: 2.4254406880893757

Epoch: 5| Step: 6
Training loss: 1.9017382525656263
Validation loss: 2.446679822787203

Epoch: 5| Step: 7
Training loss: 1.873747725329504
Validation loss: 2.423165541506417

Epoch: 5| Step: 8
Training loss: 1.874516742736332
Validation loss: 2.436661712657321

Epoch: 5| Step: 9
Training loss: 2.1264124271488942
Validation loss: 2.4716250100701473

Epoch: 5| Step: 10
Training loss: 2.0979032175743564
Validation loss: 2.426465620312334

Epoch: 5| Step: 11
Training loss: 2.555795131962122
Validation loss: 2.4543459014553513

Epoch: 346| Step: 0
Training loss: 2.0644829205660873
Validation loss: 2.478459266641088

Epoch: 5| Step: 1
Training loss: 2.078980463388456
Validation loss: 2.4987294982112345

Epoch: 5| Step: 2
Training loss: 1.9082307374297607
Validation loss: 2.533834103814912

Epoch: 5| Step: 3
Training loss: 2.1817566816014113
Validation loss: 2.533797818557429

Epoch: 5| Step: 4
Training loss: 2.322292934093527
Validation loss: 2.5516159966165968

Epoch: 5| Step: 5
Training loss: 1.4331075483108846
Validation loss: 2.5302146945044717

Epoch: 5| Step: 6
Training loss: 1.933911045127386
Validation loss: 2.4918771070157772

Epoch: 5| Step: 7
Training loss: 2.092474933506032
Validation loss: 2.482923215458528

Epoch: 5| Step: 8
Training loss: 1.9406651515769133
Validation loss: 2.4202346620137054

Epoch: 5| Step: 9
Training loss: 1.1892301604159954
Validation loss: 2.43800579838693

Epoch: 5| Step: 10
Training loss: 2.4975580687163426
Validation loss: 2.460642991785443

Epoch: 5| Step: 11
Training loss: 1.297501056722163
Validation loss: 2.461605869337489

Epoch: 347| Step: 0
Training loss: 1.9272875978278932
Validation loss: 2.456876089819918

Epoch: 5| Step: 1
Training loss: 2.316693293009088
Validation loss: 2.4011015908685915

Epoch: 5| Step: 2
Training loss: 1.3716878446162348
Validation loss: 2.4608172755670727

Epoch: 5| Step: 3
Training loss: 1.8303482361154801
Validation loss: 2.453730631943123

Epoch: 5| Step: 4
Training loss: 2.4113870257277035
Validation loss: 2.439312904630311

Epoch: 5| Step: 5
Training loss: 2.0368586648366205
Validation loss: 2.452722834364372

Epoch: 5| Step: 6
Training loss: 2.0820804897877
Validation loss: 2.455497991064326

Epoch: 5| Step: 7
Training loss: 1.6149813581872952
Validation loss: 2.480300925677478

Epoch: 5| Step: 8
Training loss: 1.517337657282612
Validation loss: 2.4863767336968055

Epoch: 5| Step: 9
Training loss: 2.609208153056042
Validation loss: 2.5255965178174673

Epoch: 5| Step: 10
Training loss: 1.8482669522697248
Validation loss: 2.5005407026810254

Epoch: 5| Step: 11
Training loss: 2.6761645411495447
Validation loss: 2.501957071714641

Epoch: 348| Step: 0
Training loss: 2.0262449370126228
Validation loss: 2.5433022455708634

Epoch: 5| Step: 1
Training loss: 2.2864552514497904
Validation loss: 2.631267671684309

Epoch: 5| Step: 2
Training loss: 1.9987967567151872
Validation loss: 2.6504785817824557

Epoch: 5| Step: 3
Training loss: 1.9573882913686942
Validation loss: 2.5320228644788023

Epoch: 5| Step: 4
Training loss: 2.3956214700538987
Validation loss: 2.477557113956603

Epoch: 5| Step: 5
Training loss: 2.3191235511309345
Validation loss: 2.4813368452201625

Epoch: 5| Step: 6
Training loss: 1.5690568297131193
Validation loss: 2.4640304747189368

Epoch: 5| Step: 7
Training loss: 2.067686783864866
Validation loss: 2.48183385576176

Epoch: 5| Step: 8
Training loss: 2.0759828468893025
Validation loss: 2.501243881880258

Epoch: 5| Step: 9
Training loss: 2.2679437807438583
Validation loss: 2.48649380060243

Epoch: 5| Step: 10
Training loss: 1.9162052538998118
Validation loss: 2.491448208046985

Epoch: 5| Step: 11
Training loss: 1.0894666450019934
Validation loss: 2.494164616353137

Epoch: 349| Step: 0
Training loss: 1.5376192868486862
Validation loss: 2.4758125557589907

Epoch: 5| Step: 1
Training loss: 2.2193561854165234
Validation loss: 2.4946827410104966

Epoch: 5| Step: 2
Training loss: 1.6435221205877353
Validation loss: 2.47699223589614

Epoch: 5| Step: 3
Training loss: 1.9159213634950683
Validation loss: 2.4672295076974713

Epoch: 5| Step: 4
Training loss: 2.299980503497211
Validation loss: 2.491028148325929

Epoch: 5| Step: 5
Training loss: 2.9016490325596402
Validation loss: 2.5097758054217567

Epoch: 5| Step: 6
Training loss: 1.5318429538420693
Validation loss: 2.5318261067856485

Epoch: 5| Step: 7
Training loss: 2.0753285802796357
Validation loss: 2.5313260259317705

Epoch: 5| Step: 8
Training loss: 1.8906975093840281
Validation loss: 2.5481278783965817

Epoch: 5| Step: 9
Training loss: 2.3952589811652993
Validation loss: 2.531066024436575

Epoch: 5| Step: 10
Training loss: 1.8473762800115576
Validation loss: 2.4864930235306337

Epoch: 5| Step: 11
Training loss: 2.406404366433971
Validation loss: 2.462394408239008

Epoch: 350| Step: 0
Training loss: 1.7566488525795134
Validation loss: 2.4691709046955626

Epoch: 5| Step: 1
Training loss: 1.7778215709232918
Validation loss: 2.4330736219820275

Epoch: 5| Step: 2
Training loss: 2.110891291679438
Validation loss: 2.4372485022930737

Epoch: 5| Step: 3
Training loss: 2.502680104850469
Validation loss: 2.4379428110810926

Epoch: 5| Step: 4
Training loss: 2.2081947163196194
Validation loss: 2.4466407426643912

Epoch: 5| Step: 5
Training loss: 2.0189222232826483
Validation loss: 2.450967538531109

Epoch: 5| Step: 6
Training loss: 2.2710195575847902
Validation loss: 2.438466536613715

Epoch: 5| Step: 7
Training loss: 2.068777299683568
Validation loss: 2.4441033685913447

Epoch: 5| Step: 8
Training loss: 1.6840105359570152
Validation loss: 2.443172070555702

Epoch: 5| Step: 9
Training loss: 1.1204501441237442
Validation loss: 2.4920375424096206

Epoch: 5| Step: 10
Training loss: 2.4014492943910963
Validation loss: 2.5215689134990944

Epoch: 5| Step: 11
Training loss: 1.5751126688061377
Validation loss: 2.526784057590969

Epoch: 351| Step: 0
Training loss: 1.8208169524665703
Validation loss: 2.5515136913420866

Epoch: 5| Step: 1
Training loss: 2.3319457787676594
Validation loss: 2.544294590808182

Epoch: 5| Step: 2
Training loss: 2.1706364894467307
Validation loss: 2.5274747945231155

Epoch: 5| Step: 3
Training loss: 1.9897169164846946
Validation loss: 2.4988032894103913

Epoch: 5| Step: 4
Training loss: 1.9169846008430493
Validation loss: 2.470965099895398

Epoch: 5| Step: 5
Training loss: 2.646411582255359
Validation loss: 2.5061214406121417

Epoch: 5| Step: 6
Training loss: 1.9352953888912654
Validation loss: 2.4731763842063788

Epoch: 5| Step: 7
Training loss: 1.8158706367562623
Validation loss: 2.4817014339600023

Epoch: 5| Step: 8
Training loss: 1.518056825918628
Validation loss: 2.4666831986307187

Epoch: 5| Step: 9
Training loss: 1.6183441743314082
Validation loss: 2.50880849674073

Epoch: 5| Step: 10
Training loss: 1.9344957501958062
Validation loss: 2.4607146752614426

Epoch: 5| Step: 11
Training loss: 1.4288907358402505
Validation loss: 2.510061778445585

Epoch: 352| Step: 0
Training loss: 1.660202348854454
Validation loss: 2.4477901196066445

Epoch: 5| Step: 1
Training loss: 2.0206984904287904
Validation loss: 2.4277146477484717

Epoch: 5| Step: 2
Training loss: 1.736241684983668
Validation loss: 2.4409061011132533

Epoch: 5| Step: 3
Training loss: 1.5296343629548452
Validation loss: 2.4401670031902856

Epoch: 5| Step: 4
Training loss: 2.215037611562383
Validation loss: 2.4415976853656858

Epoch: 5| Step: 5
Training loss: 2.309586726124287
Validation loss: 2.4310457495215063

Epoch: 5| Step: 6
Training loss: 2.212594749016743
Validation loss: 2.4401775879672085

Epoch: 5| Step: 7
Training loss: 1.970756356131923
Validation loss: 2.4761674006250614

Epoch: 5| Step: 8
Training loss: 1.7024813494451974
Validation loss: 2.478441490305124

Epoch: 5| Step: 9
Training loss: 1.5601682430411914
Validation loss: 2.507539653096892

Epoch: 5| Step: 10
Training loss: 1.8783256283962808
Validation loss: 2.507316938499274

Epoch: 5| Step: 11
Training loss: 3.422319496583324
Validation loss: 2.4713748084205487

Epoch: 353| Step: 0
Training loss: 2.1827343937000587
Validation loss: 2.4598388338697132

Epoch: 5| Step: 1
Training loss: 1.369009057878131
Validation loss: 2.4862041377547164

Epoch: 5| Step: 2
Training loss: 2.0688727212791576
Validation loss: 2.5056999494780894

Epoch: 5| Step: 3
Training loss: 1.72212809729327
Validation loss: 2.494024598149469

Epoch: 5| Step: 4
Training loss: 1.5034783088887822
Validation loss: 2.5139780082911667

Epoch: 5| Step: 5
Training loss: 2.1545400058646713
Validation loss: 2.522587903812782

Epoch: 5| Step: 6
Training loss: 2.3418736385588894
Validation loss: 2.532029157584916

Epoch: 5| Step: 7
Training loss: 2.32969264561413
Validation loss: 2.511243083995602

Epoch: 5| Step: 8
Training loss: 2.297453100412757
Validation loss: 2.5453461385853267

Epoch: 5| Step: 9
Training loss: 1.7535822851640195
Validation loss: 2.543565624406581

Epoch: 5| Step: 10
Training loss: 2.460637828201446
Validation loss: 2.5695910692621724

Epoch: 5| Step: 11
Training loss: 1.613304747625109
Validation loss: 2.5198147853239155

Epoch: 354| Step: 0
Training loss: 1.8688699970822644
Validation loss: 2.5014916738172936

Epoch: 5| Step: 1
Training loss: 1.9708670480867376
Validation loss: 2.482582997461366

Epoch: 5| Step: 2
Training loss: 1.665957951861146
Validation loss: 2.5047202371705506

Epoch: 5| Step: 3
Training loss: 1.9389588800942348
Validation loss: 2.469705497357226

Epoch: 5| Step: 4
Training loss: 2.386151485178023
Validation loss: 2.5264101264410024

Epoch: 5| Step: 5
Training loss: 1.978596421123751
Validation loss: 2.505365338365666

Epoch: 5| Step: 6
Training loss: 2.0240409275334743
Validation loss: 2.498788766698592

Epoch: 5| Step: 7
Training loss: 2.1092513436700533
Validation loss: 2.506197007967492

Epoch: 5| Step: 8
Training loss: 2.050030438266965
Validation loss: 2.5434362994441675

Epoch: 5| Step: 9
Training loss: 1.7719612867548242
Validation loss: 2.554454260084034

Epoch: 5| Step: 10
Training loss: 1.8894404333799184
Validation loss: 2.513259968555372

Epoch: 5| Step: 11
Training loss: 0.839292052282734
Validation loss: 2.558479916124785

Epoch: 355| Step: 0
Training loss: 2.2065652811129866
Validation loss: 2.5769807723187466

Epoch: 5| Step: 1
Training loss: 2.311278665054346
Validation loss: 2.5638679869192296

Epoch: 5| Step: 2
Training loss: 1.9478584389645053
Validation loss: 2.518135839637622

Epoch: 5| Step: 3
Training loss: 1.8787177421556842
Validation loss: 2.485533841886457

Epoch: 5| Step: 4
Training loss: 2.088071267545044
Validation loss: 2.505761588397038

Epoch: 5| Step: 5
Training loss: 1.8820114014348093
Validation loss: 2.484219824145322

Epoch: 5| Step: 6
Training loss: 2.355837968575022
Validation loss: 2.460964549889832

Epoch: 5| Step: 7
Training loss: 1.7295736576925635
Validation loss: 2.4481316059521077

Epoch: 5| Step: 8
Training loss: 2.2791224971120005
Validation loss: 2.4611388431916463

Epoch: 5| Step: 9
Training loss: 1.4945359847636384
Validation loss: 2.4545665886827535

Epoch: 5| Step: 10
Training loss: 1.8127746373960356
Validation loss: 2.499626640414795

Epoch: 5| Step: 11
Training loss: 1.7401147666440078
Validation loss: 2.5266643713594275

Epoch: 356| Step: 0
Training loss: 1.7230333533974802
Validation loss: 2.5831253342313296

Epoch: 5| Step: 1
Training loss: 1.8264771558208643
Validation loss: 2.614479504888241

Epoch: 5| Step: 2
Training loss: 2.3168762656517883
Validation loss: 2.669302090097418

Epoch: 5| Step: 3
Training loss: 2.4997364858984406
Validation loss: 2.6494465596406185

Epoch: 5| Step: 4
Training loss: 1.7094687511112923
Validation loss: 2.624919394360579

Epoch: 5| Step: 5
Training loss: 2.2175316487734213
Validation loss: 2.562455684774898

Epoch: 5| Step: 6
Training loss: 1.9169743401526878
Validation loss: 2.483880235680909

Epoch: 5| Step: 7
Training loss: 1.5960294093431615
Validation loss: 2.492129744734451

Epoch: 5| Step: 8
Training loss: 2.0429185675152435
Validation loss: 2.4830927868858024

Epoch: 5| Step: 9
Training loss: 1.5708596713879293
Validation loss: 2.4248364789960153

Epoch: 5| Step: 10
Training loss: 2.0562847006980105
Validation loss: 2.431091524400135

Epoch: 5| Step: 11
Training loss: 1.5586117239085402
Validation loss: 2.4577327347519797

Epoch: 357| Step: 0
Training loss: 1.9123218328724034
Validation loss: 2.4568088594596142

Epoch: 5| Step: 1
Training loss: 2.1464925944593536
Validation loss: 2.4776206117770805

Epoch: 5| Step: 2
Training loss: 1.7709223855758451
Validation loss: 2.4813065643333077

Epoch: 5| Step: 3
Training loss: 1.7773283234649893
Validation loss: 2.477030793048009

Epoch: 5| Step: 4
Training loss: 1.7493826594701232
Validation loss: 2.4890993052106425

Epoch: 5| Step: 5
Training loss: 2.2817208836172016
Validation loss: 2.47927093620509

Epoch: 5| Step: 6
Training loss: 1.735430216039891
Validation loss: 2.456801047404534

Epoch: 5| Step: 7
Training loss: 2.3180446652181423
Validation loss: 2.463755581515754

Epoch: 5| Step: 8
Training loss: 1.6779507907112723
Validation loss: 2.473630246275163

Epoch: 5| Step: 9
Training loss: 2.4319863192399365
Validation loss: 2.5074335269446277

Epoch: 5| Step: 10
Training loss: 1.7301563816282377
Validation loss: 2.5707213782896288

Epoch: 5| Step: 11
Training loss: 1.5841153957304868
Validation loss: 2.6313671744406046

Epoch: 358| Step: 0
Training loss: 2.1318241945608207
Validation loss: 2.6320041770218303

Epoch: 5| Step: 1
Training loss: 1.4137041259527323
Validation loss: 2.6311007065451393

Epoch: 5| Step: 2
Training loss: 2.0870300175071343
Validation loss: 2.6780720541196477

Epoch: 5| Step: 3
Training loss: 1.8144366999643415
Validation loss: 2.6247178031975786

Epoch: 5| Step: 4
Training loss: 1.6208282620988894
Validation loss: 2.5850556205776702

Epoch: 5| Step: 5
Training loss: 2.5704085033540855
Validation loss: 2.5281727849580453

Epoch: 5| Step: 6
Training loss: 1.7372452638358151
Validation loss: 2.4702126560225373

Epoch: 5| Step: 7
Training loss: 1.7335021425844062
Validation loss: 2.4656457739769944

Epoch: 5| Step: 8
Training loss: 2.5450872219705447
Validation loss: 2.50135147599332

Epoch: 5| Step: 9
Training loss: 1.3965124594258602
Validation loss: 2.483000949136084

Epoch: 5| Step: 10
Training loss: 2.0906351177615083
Validation loss: 2.5057428758576967

Epoch: 5| Step: 11
Training loss: 1.0398738819459759
Validation loss: 2.4952849150717222

Epoch: 359| Step: 0
Training loss: 2.1827249999588947
Validation loss: 2.4915589403916245

Epoch: 5| Step: 1
Training loss: 1.8779026452079859
Validation loss: 2.486632822629284

Epoch: 5| Step: 2
Training loss: 1.5666919171888931
Validation loss: 2.4698209029330505

Epoch: 5| Step: 3
Training loss: 1.6608929603899232
Validation loss: 2.5047342931826906

Epoch: 5| Step: 4
Training loss: 2.166939595956568
Validation loss: 2.4659848038098704

Epoch: 5| Step: 5
Training loss: 1.8210304383442082
Validation loss: 2.4689749120316016

Epoch: 5| Step: 6
Training loss: 1.5062185766970722
Validation loss: 2.4609267017591816

Epoch: 5| Step: 7
Training loss: 1.9539746076911622
Validation loss: 2.4711138759536775

Epoch: 5| Step: 8
Training loss: 2.057354722485182
Validation loss: 2.4943409129602845

Epoch: 5| Step: 9
Training loss: 2.5973825410898375
Validation loss: 2.471972149411966

Epoch: 5| Step: 10
Training loss: 1.6931258483862062
Validation loss: 2.465831113483203

Epoch: 5| Step: 11
Training loss: 1.19383492492253
Validation loss: 2.485960724228823

Epoch: 360| Step: 0
Training loss: 1.8621860060259336
Validation loss: 2.4551524553399307

Epoch: 5| Step: 1
Training loss: 1.7157812662300933
Validation loss: 2.475155178818199

Epoch: 5| Step: 2
Training loss: 1.736080671255496
Validation loss: 2.4409369584766965

Epoch: 5| Step: 3
Training loss: 1.1741819943216574
Validation loss: 2.4179663917476595

Epoch: 5| Step: 4
Training loss: 2.0203714006634157
Validation loss: 2.4610001773017802

Epoch: 5| Step: 5
Training loss: 2.253066093108627
Validation loss: 2.433662433991903

Epoch: 5| Step: 6
Training loss: 2.787872316958591
Validation loss: 2.48373224832827

Epoch: 5| Step: 7
Training loss: 1.8053036913492608
Validation loss: 2.4585398099687716

Epoch: 5| Step: 8
Training loss: 1.7294032689504475
Validation loss: 2.467123318594957

Epoch: 5| Step: 9
Training loss: 1.521355482721418
Validation loss: 2.4754057147093014

Epoch: 5| Step: 10
Training loss: 1.7545376938743933
Validation loss: 2.4906283596754846

Epoch: 5| Step: 11
Training loss: 1.6724002761647165
Validation loss: 2.5329188312580464

Epoch: 361| Step: 0
Training loss: 1.7241278696588742
Validation loss: 2.4644735494579435

Epoch: 5| Step: 1
Training loss: 1.8888773761971873
Validation loss: 2.4568554603590873

Epoch: 5| Step: 2
Training loss: 1.7307377384450695
Validation loss: 2.4501319371269537

Epoch: 5| Step: 3
Training loss: 1.458485141300524
Validation loss: 2.4445086692611597

Epoch: 5| Step: 4
Training loss: 1.6141708175193552
Validation loss: 2.456865403117713

Epoch: 5| Step: 5
Training loss: 1.7759991265028447
Validation loss: 2.435911031550267

Epoch: 5| Step: 6
Training loss: 1.6459151943789214
Validation loss: 2.4480350479287467

Epoch: 5| Step: 7
Training loss: 2.3670578722823072
Validation loss: 2.4164866402318106

Epoch: 5| Step: 8
Training loss: 1.6145878781490555
Validation loss: 2.4299388277140523

Epoch: 5| Step: 9
Training loss: 2.3586138577534417
Validation loss: 2.43685378368789

Epoch: 5| Step: 10
Training loss: 1.9227567681329965
Validation loss: 2.4411333140079403

Epoch: 5| Step: 11
Training loss: 1.6301396592110489
Validation loss: 2.400349367561585

Epoch: 362| Step: 0
Training loss: 2.1805705807675064
Validation loss: 2.455423695459107

Epoch: 5| Step: 1
Training loss: 2.308196006114477
Validation loss: 2.4290630646189713

Epoch: 5| Step: 2
Training loss: 1.9505906408743485
Validation loss: 2.4701680082641784

Epoch: 5| Step: 3
Training loss: 1.6008976742736785
Validation loss: 2.4888377902189163

Epoch: 5| Step: 4
Training loss: 1.8911923904872592
Validation loss: 2.4501184355401633

Epoch: 5| Step: 5
Training loss: 2.480845217032946
Validation loss: 2.52077980352477

Epoch: 5| Step: 6
Training loss: 1.6482365200950155
Validation loss: 2.542070299419542

Epoch: 5| Step: 7
Training loss: 1.4771423815863234
Validation loss: 2.5469873321661503

Epoch: 5| Step: 8
Training loss: 1.7656382332364986
Validation loss: 2.5542351169551463

Epoch: 5| Step: 9
Training loss: 1.528000244165571
Validation loss: 2.5302968133935853

Epoch: 5| Step: 10
Training loss: 1.6526115326747806
Validation loss: 2.54713976250316

Epoch: 5| Step: 11
Training loss: 2.847273268410049
Validation loss: 2.4947103169875255

Epoch: 363| Step: 0
Training loss: 1.496647824308282
Validation loss: 2.4857585940910236

Epoch: 5| Step: 1
Training loss: 1.8729487324799605
Validation loss: 2.4628410243606784

Epoch: 5| Step: 2
Training loss: 2.4519050626251233
Validation loss: 2.490365138391735

Epoch: 5| Step: 3
Training loss: 2.026132445928954
Validation loss: 2.5328716609257413

Epoch: 5| Step: 4
Training loss: 1.7876604741762365
Validation loss: 2.435259405657326

Epoch: 5| Step: 5
Training loss: 1.6410845158424405
Validation loss: 2.4382597643960726

Epoch: 5| Step: 6
Training loss: 1.506099854896315
Validation loss: 2.4227132556600774

Epoch: 5| Step: 7
Training loss: 1.9452567954303224
Validation loss: 2.4392373585424405

Epoch: 5| Step: 8
Training loss: 2.127022958384988
Validation loss: 2.436050024526914

Epoch: 5| Step: 9
Training loss: 2.364094340531663
Validation loss: 2.4218415022143405

Epoch: 5| Step: 10
Training loss: 1.6344648697544484
Validation loss: 2.445301393071342

Epoch: 5| Step: 11
Training loss: 0.702451765094619
Validation loss: 2.4821295837512682

Epoch: 364| Step: 0
Training loss: 2.094075988899146
Validation loss: 2.522588177508073

Epoch: 5| Step: 1
Training loss: 1.496523404489939
Validation loss: 2.5283067373081

Epoch: 5| Step: 2
Training loss: 2.019987132343061
Validation loss: 2.546583839655088

Epoch: 5| Step: 3
Training loss: 1.7312592709289647
Validation loss: 2.5417851722689804

Epoch: 5| Step: 4
Training loss: 1.7508503346598938
Validation loss: 2.50680112003429

Epoch: 5| Step: 5
Training loss: 1.8836493947097883
Validation loss: 2.521269115633376

Epoch: 5| Step: 6
Training loss: 1.5769881128602135
Validation loss: 2.4952359305019742

Epoch: 5| Step: 7
Training loss: 1.5998047649954963
Validation loss: 2.484943700673307

Epoch: 5| Step: 8
Training loss: 1.5187650577756306
Validation loss: 2.494693723652747

Epoch: 5| Step: 9
Training loss: 2.383212997048425
Validation loss: 2.477475303959225

Epoch: 5| Step: 10
Training loss: 2.099440627303092
Validation loss: 2.4939925454277363

Epoch: 5| Step: 11
Training loss: 3.1223071894127576
Validation loss: 2.4428808839987988

Epoch: 365| Step: 0
Training loss: 1.710780654755218
Validation loss: 2.428945315588681

Epoch: 5| Step: 1
Training loss: 1.9852548886248431
Validation loss: 2.5165697381214605

Epoch: 5| Step: 2
Training loss: 1.9389931862343992
Validation loss: 2.5085152486142905

Epoch: 5| Step: 3
Training loss: 2.094567779711932
Validation loss: 2.5005379376220085

Epoch: 5| Step: 4
Training loss: 1.5242903449656877
Validation loss: 2.454055150164054

Epoch: 5| Step: 5
Training loss: 1.332993593244903
Validation loss: 2.4087776391872437

Epoch: 5| Step: 6
Training loss: 2.6208844392662636
Validation loss: 2.3790614427745984

Epoch: 5| Step: 7
Training loss: 1.881690929865726
Validation loss: 2.3667667736845073

Epoch: 5| Step: 8
Training loss: 2.1032550335117306
Validation loss: 2.3838394161804546

Epoch: 5| Step: 9
Training loss: 1.875300891893055
Validation loss: 2.36543264904629

Epoch: 5| Step: 10
Training loss: 1.9204546013719737
Validation loss: 2.3854396512174967

Epoch: 5| Step: 11
Training loss: 1.9552068372614697
Validation loss: 2.3892029665462484

Epoch: 366| Step: 0
Training loss: 1.759138903860338
Validation loss: 2.416097846722686

Epoch: 5| Step: 1
Training loss: 1.9760828453952113
Validation loss: 2.4951369233168936

Epoch: 5| Step: 2
Training loss: 1.6881634856056094
Validation loss: 2.4949657217536534

Epoch: 5| Step: 3
Training loss: 1.7385231792669986
Validation loss: 2.5254400985525285

Epoch: 5| Step: 4
Training loss: 2.056263946207633
Validation loss: 2.5310721511526824

Epoch: 5| Step: 5
Training loss: 1.7621324142340125
Validation loss: 2.48522742660274

Epoch: 5| Step: 6
Training loss: 2.6923279090793018
Validation loss: 2.45500923491021

Epoch: 5| Step: 7
Training loss: 1.9585692554428829
Validation loss: 2.4972759346659905

Epoch: 5| Step: 8
Training loss: 1.7371319003539412
Validation loss: 2.441388323908798

Epoch: 5| Step: 9
Training loss: 1.6195608957965988
Validation loss: 2.475243137760178

Epoch: 5| Step: 10
Training loss: 1.8540854346951112
Validation loss: 2.4535932519199584

Epoch: 5| Step: 11
Training loss: 1.0582925853744536
Validation loss: 2.4292008218168917

Epoch: 367| Step: 0
Training loss: 1.4446888170807726
Validation loss: 2.4194488719941525

Epoch: 5| Step: 1
Training loss: 1.901409381854785
Validation loss: 2.442179215202182

Epoch: 5| Step: 2
Training loss: 1.5836178206132678
Validation loss: 2.465508501840566

Epoch: 5| Step: 3
Training loss: 1.934686278902142
Validation loss: 2.4435962508308915

Epoch: 5| Step: 4
Training loss: 2.3078659640287524
Validation loss: 2.4521491991226996

Epoch: 5| Step: 5
Training loss: 1.8429225422628037
Validation loss: 2.4592918161383626

Epoch: 5| Step: 6
Training loss: 1.7503315066650909
Validation loss: 2.4382460422453107

Epoch: 5| Step: 7
Training loss: 1.5144543403500572
Validation loss: 2.513153734135383

Epoch: 5| Step: 8
Training loss: 2.5046920614504433
Validation loss: 2.5312324923628053

Epoch: 5| Step: 9
Training loss: 1.3213272258381301
Validation loss: 2.5473792507204114

Epoch: 5| Step: 10
Training loss: 2.1540509495992053
Validation loss: 2.56192708395168

Epoch: 5| Step: 11
Training loss: 1.111487191185226
Validation loss: 2.5595147569418133

Epoch: 368| Step: 0
Training loss: 2.0411681779860165
Validation loss: 2.545140492946321

Epoch: 5| Step: 1
Training loss: 1.5990913493178351
Validation loss: 2.5188629762413894

Epoch: 5| Step: 2
Training loss: 1.4643859147801908
Validation loss: 2.464315298332643

Epoch: 5| Step: 3
Training loss: 1.7849337983877933
Validation loss: 2.472917525883959

Epoch: 5| Step: 4
Training loss: 1.9959171463391607
Validation loss: 2.4693383389004953

Epoch: 5| Step: 5
Training loss: 2.379851155154649
Validation loss: 2.4795361905965514

Epoch: 5| Step: 6
Training loss: 1.7674331184046108
Validation loss: 2.418088077030914

Epoch: 5| Step: 7
Training loss: 2.0923632683967752
Validation loss: 2.4666934803416045

Epoch: 5| Step: 8
Training loss: 1.5136274565055308
Validation loss: 2.4845393824225823

Epoch: 5| Step: 9
Training loss: 2.23406969665572
Validation loss: 2.499884884886069

Epoch: 5| Step: 10
Training loss: 1.7370401473734094
Validation loss: 2.4847278264459143

Epoch: 5| Step: 11
Training loss: 0.936877489042125
Validation loss: 2.5158434312973053

Epoch: 369| Step: 0
Training loss: 1.649337884240334
Validation loss: 2.4781023727609033

Epoch: 5| Step: 1
Training loss: 1.7598920939702023
Validation loss: 2.4666654421399485

Epoch: 5| Step: 2
Training loss: 1.7243994372282656
Validation loss: 2.46516140736279

Epoch: 5| Step: 3
Training loss: 1.7332756063434245
Validation loss: 2.469744779661142

Epoch: 5| Step: 4
Training loss: 1.7140140133644308
Validation loss: 2.4888906366466546

Epoch: 5| Step: 5
Training loss: 2.07889731834239
Validation loss: 2.511162877803456

Epoch: 5| Step: 6
Training loss: 1.5282582230798343
Validation loss: 2.4682295649063253

Epoch: 5| Step: 7
Training loss: 1.8993423879873317
Validation loss: 2.4954825913230887

Epoch: 5| Step: 8
Training loss: 1.7981743136934076
Validation loss: 2.4925678843810113

Epoch: 5| Step: 9
Training loss: 2.427671718632836
Validation loss: 2.4779399887748417

Epoch: 5| Step: 10
Training loss: 1.7951448154741052
Validation loss: 2.4691690379039217

Epoch: 5| Step: 11
Training loss: 2.3528034573109013
Validation loss: 2.4728009190154223

Epoch: 370| Step: 0
Training loss: 2.0720243466320296
Validation loss: 2.6799414192802753

Epoch: 5| Step: 1
Training loss: 2.9661116270125314
Validation loss: 2.81879422222897

Epoch: 5| Step: 2
Training loss: 1.9012820435882838
Validation loss: 2.9210016710001687

Epoch: 5| Step: 3
Training loss: 3.1191641675888295
Validation loss: 2.924050040053227

Epoch: 5| Step: 4
Training loss: 1.6936927476053665
Validation loss: 2.680574513128399

Epoch: 5| Step: 5
Training loss: 1.7406424612268678
Validation loss: 2.5124419670614713

Epoch: 5| Step: 6
Training loss: 1.854956369426733
Validation loss: 2.4713950413391075

Epoch: 5| Step: 7
Training loss: 1.2466922387052028
Validation loss: 2.5253602862225977

Epoch: 5| Step: 8
Training loss: 2.4352513235684015
Validation loss: 2.5306775344466885

Epoch: 5| Step: 9
Training loss: 2.015608558292014
Validation loss: 2.5715031595677362

Epoch: 5| Step: 10
Training loss: 2.1792940174281656
Validation loss: 2.587748328561347

Epoch: 5| Step: 11
Training loss: 1.3647199324555361
Validation loss: 2.5783828779775155

Epoch: 371| Step: 0
Training loss: 2.5238522404314327
Validation loss: 2.587652978122036

Epoch: 5| Step: 1
Training loss: 2.141511051545806
Validation loss: 2.5974101855917517

Epoch: 5| Step: 2
Training loss: 1.4192455417817706
Validation loss: 2.5911562103114814

Epoch: 5| Step: 3
Training loss: 2.2028945910585884
Validation loss: 2.6018106076875878

Epoch: 5| Step: 4
Training loss: 1.6613838234898815
Validation loss: 2.6084551036815475

Epoch: 5| Step: 5
Training loss: 2.430352809866507
Validation loss: 2.609262418316994

Epoch: 5| Step: 6
Training loss: 1.693929996287086
Validation loss: 2.587679400191041

Epoch: 5| Step: 7
Training loss: 2.210122864876598
Validation loss: 2.6306356983023162

Epoch: 5| Step: 8
Training loss: 2.4648829243927866
Validation loss: 2.6406147202361265

Epoch: 5| Step: 9
Training loss: 1.9424431409332596
Validation loss: 2.6506539244221594

Epoch: 5| Step: 10
Training loss: 2.0451033984395113
Validation loss: 2.6089974394820197

Epoch: 5| Step: 11
Training loss: 1.127105966976516
Validation loss: 2.6095508622775427

Epoch: 372| Step: 0
Training loss: 1.971297296453749
Validation loss: 2.551167807855432

Epoch: 5| Step: 1
Training loss: 1.3222894257920705
Validation loss: 2.5506705337494435

Epoch: 5| Step: 2
Training loss: 2.137954828604106
Validation loss: 2.5642556712246014

Epoch: 5| Step: 3
Training loss: 2.273807246497837
Validation loss: 2.55718651430404

Epoch: 5| Step: 4
Training loss: 2.17609451202995
Validation loss: 2.545894160899346

Epoch: 5| Step: 5
Training loss: 1.6018980093504205
Validation loss: 2.528693690110668

Epoch: 5| Step: 6
Training loss: 1.8219720045801013
Validation loss: 2.5116232106818766

Epoch: 5| Step: 7
Training loss: 1.9137926183897258
Validation loss: 2.500121224961089

Epoch: 5| Step: 8
Training loss: 2.1686663081046387
Validation loss: 2.5026138390159987

Epoch: 5| Step: 9
Training loss: 2.241382520835257
Validation loss: 2.4873113333817116

Epoch: 5| Step: 10
Training loss: 1.9489523910140996
Validation loss: 2.4897035658838194

Epoch: 5| Step: 11
Training loss: 1.9246167730363826
Validation loss: 2.522982411639656

Epoch: 373| Step: 0
Training loss: 2.1899793470619446
Validation loss: 2.5231096666909734

Epoch: 5| Step: 1
Training loss: 1.424858233443804
Validation loss: 2.46825300517621

Epoch: 5| Step: 2
Training loss: 1.705125036828705
Validation loss: 2.4649257978757713

Epoch: 5| Step: 3
Training loss: 2.1046814870996258
Validation loss: 2.4987414052948074

Epoch: 5| Step: 4
Training loss: 1.6127146910641603
Validation loss: 2.510867578260489

Epoch: 5| Step: 5
Training loss: 2.4684045284323046
Validation loss: 2.4726371945193804

Epoch: 5| Step: 6
Training loss: 1.702993615358562
Validation loss: 2.4924069330918472

Epoch: 5| Step: 7
Training loss: 1.6513567201721409
Validation loss: 2.4823534836290833

Epoch: 5| Step: 8
Training loss: 2.1757959334530343
Validation loss: 2.448208606166571

Epoch: 5| Step: 9
Training loss: 1.8781277953268312
Validation loss: 2.4851681384917814

Epoch: 5| Step: 10
Training loss: 1.87098499212969
Validation loss: 2.5542904762101966

Epoch: 5| Step: 11
Training loss: 2.2803945113065995
Validation loss: 2.568403093282612

Epoch: 374| Step: 0
Training loss: 1.6437264328344103
Validation loss: 2.638273572849396

Epoch: 5| Step: 1
Training loss: 2.8709645352513324
Validation loss: 2.7473572871440513

Epoch: 5| Step: 2
Training loss: 2.2161040311487588
Validation loss: 2.8245219221378037

Epoch: 5| Step: 3
Training loss: 2.5631234875897566
Validation loss: 2.795839462519909

Epoch: 5| Step: 4
Training loss: 2.463839705801948
Validation loss: 2.683488828041481

Epoch: 5| Step: 5
Training loss: 2.008737788753745
Validation loss: 2.556293499925454

Epoch: 5| Step: 6
Training loss: 1.3913862737799159
Validation loss: 2.5028765222898883

Epoch: 5| Step: 7
Training loss: 1.6729087129485372
Validation loss: 2.4672636797053484

Epoch: 5| Step: 8
Training loss: 1.8056243842610133
Validation loss: 2.4822619947185354

Epoch: 5| Step: 9
Training loss: 1.8298244565139286
Validation loss: 2.4809188434414926

Epoch: 5| Step: 10
Training loss: 1.5453049369295222
Validation loss: 2.5031335226509968

Epoch: 5| Step: 11
Training loss: 1.2996011599025088
Validation loss: 2.559618694610313

Epoch: 375| Step: 0
Training loss: 1.8392873518006632
Validation loss: 2.5549670308555847

Epoch: 5| Step: 1
Training loss: 2.2071661713806594
Validation loss: 2.5440797542062983

Epoch: 5| Step: 2
Training loss: 1.4853793310294716
Validation loss: 2.5419274975398842

Epoch: 5| Step: 3
Training loss: 2.3311569645294
Validation loss: 2.5386673370381816

Epoch: 5| Step: 4
Training loss: 2.6422896696489846
Validation loss: 2.543381803438386

Epoch: 5| Step: 5
Training loss: 2.00948872340812
Validation loss: 2.531076476346283

Epoch: 5| Step: 6
Training loss: 2.2237114035916674
Validation loss: 2.558494084482149

Epoch: 5| Step: 7
Training loss: 2.0697391507827057
Validation loss: 2.5093351635714263

Epoch: 5| Step: 8
Training loss: 1.818557941481791
Validation loss: 2.543255767797726

Epoch: 5| Step: 9
Training loss: 1.5676224474863707
Validation loss: 2.521840171620736

Epoch: 5| Step: 10
Training loss: 1.4743740272923034
Validation loss: 2.532659354140434

Epoch: 5| Step: 11
Training loss: 1.893583017169783
Validation loss: 2.5339888601908793

Epoch: 376| Step: 0
Training loss: 1.5131906839741924
Validation loss: 2.495457830399016

Epoch: 5| Step: 1
Training loss: 2.336754901469869
Validation loss: 2.478305448013083

Epoch: 5| Step: 2
Training loss: 1.6638136126869654
Validation loss: 2.438628200531187

Epoch: 5| Step: 3
Training loss: 1.7751531158814466
Validation loss: 2.422640923422159

Epoch: 5| Step: 4
Training loss: 1.3911386891244328
Validation loss: 2.452555406050217

Epoch: 5| Step: 5
Training loss: 2.540015596356906
Validation loss: 2.4584647456029587

Epoch: 5| Step: 6
Training loss: 1.7059038223265819
Validation loss: 2.4251089121589673

Epoch: 5| Step: 7
Training loss: 1.5835968183159332
Validation loss: 2.4489835740809736

Epoch: 5| Step: 8
Training loss: 2.2591308124116876
Validation loss: 2.4629186860073404

Epoch: 5| Step: 9
Training loss: 1.895883734176335
Validation loss: 2.404959485339952

Epoch: 5| Step: 10
Training loss: 1.6513586692658038
Validation loss: 2.4059666636058257

Epoch: 5| Step: 11
Training loss: 1.686408785052282
Validation loss: 2.480091384657579

Epoch: 377| Step: 0
Training loss: 1.7122029541120254
Validation loss: 2.505467537591298

Epoch: 5| Step: 1
Training loss: 2.3603543907719917
Validation loss: 2.4977855729633447

Epoch: 5| Step: 2
Training loss: 1.5334210477840022
Validation loss: 2.5174531276737473

Epoch: 5| Step: 3
Training loss: 1.639860865343254
Validation loss: 2.5378538805741364

Epoch: 5| Step: 4
Training loss: 1.795870890154583
Validation loss: 2.575976245037571

Epoch: 5| Step: 5
Training loss: 1.0768602665332214
Validation loss: 2.5406991545055546

Epoch: 5| Step: 6
Training loss: 1.7639373545692394
Validation loss: 2.545093186127013

Epoch: 5| Step: 7
Training loss: 1.5988494968547007
Validation loss: 2.5634171310075002

Epoch: 5| Step: 8
Training loss: 1.7464754169655006
Validation loss: 2.560364612694787

Epoch: 5| Step: 9
Training loss: 1.718731342561199
Validation loss: 2.579446463565852

Epoch: 5| Step: 10
Training loss: 1.7669147068415758
Validation loss: 2.539010224415537

Epoch: 5| Step: 11
Training loss: 3.8009306671475085
Validation loss: 2.5814866334672675

Epoch: 378| Step: 0
Training loss: 1.7027616900786389
Validation loss: 2.593170725622416

Epoch: 5| Step: 1
Training loss: 1.7299296828957158
Validation loss: 2.573451632638653

Epoch: 5| Step: 2
Training loss: 1.4546879392432708
Validation loss: 2.5708615799706607

Epoch: 5| Step: 3
Training loss: 1.8925737158504496
Validation loss: 2.5543961587291992

Epoch: 5| Step: 4
Training loss: 1.0686587066028705
Validation loss: 2.5813121669632344

Epoch: 5| Step: 5
Training loss: 1.6935390918230488
Validation loss: 2.5533752376360637

Epoch: 5| Step: 6
Training loss: 2.4536161477750666
Validation loss: 2.5992937858963487

Epoch: 5| Step: 7
Training loss: 1.3989302550239329
Validation loss: 2.5374855935262493

Epoch: 5| Step: 8
Training loss: 2.4254472536396228
Validation loss: 2.5267229059556446

Epoch: 5| Step: 9
Training loss: 1.53294232331013
Validation loss: 2.506492869658379

Epoch: 5| Step: 10
Training loss: 1.7455397714909882
Validation loss: 2.4738701587155663

Epoch: 5| Step: 11
Training loss: 1.5373539614907743
Validation loss: 2.446605728374304

Epoch: 379| Step: 0
Training loss: 1.5922201705440824
Validation loss: 2.4241819612705306

Epoch: 5| Step: 1
Training loss: 1.4727783961954108
Validation loss: 2.4412965693950137

Epoch: 5| Step: 2
Training loss: 1.8472854209866882
Validation loss: 2.446041900270429

Epoch: 5| Step: 3
Training loss: 1.9911895047353756
Validation loss: 2.420940686557771

Epoch: 5| Step: 4
Training loss: 1.9288600120394745
Validation loss: 2.410320428895976

Epoch: 5| Step: 5
Training loss: 1.806429332027718
Validation loss: 2.407389886872476

Epoch: 5| Step: 6
Training loss: 2.2091037438045125
Validation loss: 2.3960403242395736

Epoch: 5| Step: 7
Training loss: 1.670433135712298
Validation loss: 2.4172174727643263

Epoch: 5| Step: 8
Training loss: 1.650814927313208
Validation loss: 2.450706079003275

Epoch: 5| Step: 9
Training loss: 1.6841261302984127
Validation loss: 2.4700604111700817

Epoch: 5| Step: 10
Training loss: 1.9614159961519988
Validation loss: 2.451094250507425

Epoch: 5| Step: 11
Training loss: 0.9161416884099562
Validation loss: 2.4285774148238155

Epoch: 380| Step: 0
Training loss: 1.6968934734315413
Validation loss: 2.501402266940413

Epoch: 5| Step: 1
Training loss: 2.1104326775393196
Validation loss: 2.4967406444026055

Epoch: 5| Step: 2
Training loss: 1.9555000208184348
Validation loss: 2.5616038042366562

Epoch: 5| Step: 3
Training loss: 2.0297818086370336
Validation loss: 2.539762648859277

Epoch: 5| Step: 4
Training loss: 1.4490144076582103
Validation loss: 2.527883040736503

Epoch: 5| Step: 5
Training loss: 1.9023850454121243
Validation loss: 2.5091252005879854

Epoch: 5| Step: 6
Training loss: 1.8086387018998598
Validation loss: 2.5303552089970545

Epoch: 5| Step: 7
Training loss: 1.7389927468787498
Validation loss: 2.4723366264120576

Epoch: 5| Step: 8
Training loss: 1.6456914510613943
Validation loss: 2.4800168364155866

Epoch: 5| Step: 9
Training loss: 1.172715610371561
Validation loss: 2.49632159861228

Epoch: 5| Step: 10
Training loss: 2.0984354685236
Validation loss: 2.482298591087588

Epoch: 5| Step: 11
Training loss: 1.1903792160137376
Validation loss: 2.508149870048851

Epoch: 381| Step: 0
Training loss: 1.7267382778257516
Validation loss: 2.474433850549441

Epoch: 5| Step: 1
Training loss: 2.4271619617567
Validation loss: 2.4614804108014754

Epoch: 5| Step: 2
Training loss: 1.7132835155077217
Validation loss: 2.4815720214680304

Epoch: 5| Step: 3
Training loss: 1.8082986347836534
Validation loss: 2.5177203864010447

Epoch: 5| Step: 4
Training loss: 1.7789378636247921
Validation loss: 2.5547772896295844

Epoch: 5| Step: 5
Training loss: 1.4841252970226515
Validation loss: 2.5674740115035624

Epoch: 5| Step: 6
Training loss: 1.909668280870436
Validation loss: 2.6481187829334876

Epoch: 5| Step: 7
Training loss: 1.7744340827244967
Validation loss: 2.6675843780648365

Epoch: 5| Step: 8
Training loss: 1.4762472795143222
Validation loss: 2.643887921005581

Epoch: 5| Step: 9
Training loss: 1.7287177533433522
Validation loss: 2.5501987090011102

Epoch: 5| Step: 10
Training loss: 1.909084651367038
Validation loss: 2.5515430280725386

Epoch: 5| Step: 11
Training loss: 1.3995473283136082
Validation loss: 2.5140180885338923

Epoch: 382| Step: 0
Training loss: 1.555331839452147
Validation loss: 2.5352247216177237

Epoch: 5| Step: 1
Training loss: 1.664443711149232
Validation loss: 2.5503706667343082

Epoch: 5| Step: 2
Training loss: 2.047935502310743
Validation loss: 2.5467199266649714

Epoch: 5| Step: 3
Training loss: 1.7305916426100294
Validation loss: 2.572343692352802

Epoch: 5| Step: 4
Training loss: 1.5093428203556443
Validation loss: 2.555439162814369

Epoch: 5| Step: 5
Training loss: 2.219536010780049
Validation loss: 2.5765594429968037

Epoch: 5| Step: 6
Training loss: 1.4372882687086657
Validation loss: 2.5750191369935043

Epoch: 5| Step: 7
Training loss: 2.0060332611992857
Validation loss: 2.547346133944058

Epoch: 5| Step: 8
Training loss: 1.756612681887006
Validation loss: 2.5473060087190893

Epoch: 5| Step: 9
Training loss: 1.9546718727908121
Validation loss: 2.566908227454534

Epoch: 5| Step: 10
Training loss: 1.6119359944796419
Validation loss: 2.5674939881798857

Epoch: 5| Step: 11
Training loss: 2.4363829180421614
Validation loss: 2.582667135404608

Epoch: 383| Step: 0
Training loss: 1.9136756350310389
Validation loss: 2.5487283582393747

Epoch: 5| Step: 1
Training loss: 1.5612798886152612
Validation loss: 2.5354035055612485

Epoch: 5| Step: 2
Training loss: 1.3492288011486862
Validation loss: 2.4957284197359124

Epoch: 5| Step: 3
Training loss: 1.3471288118827942
Validation loss: 2.510866268677118

Epoch: 5| Step: 4
Training loss: 1.27987285198572
Validation loss: 2.5280305007009285

Epoch: 5| Step: 5
Training loss: 1.9304627625678596
Validation loss: 2.560217255404959

Epoch: 5| Step: 6
Training loss: 2.887682762802456
Validation loss: 2.534764405049057

Epoch: 5| Step: 7
Training loss: 1.8718467901329963
Validation loss: 2.5201348264391727

Epoch: 5| Step: 8
Training loss: 1.8339890550060096
Validation loss: 2.533653629021595

Epoch: 5| Step: 9
Training loss: 1.9375604189404463
Validation loss: 2.504089102810633

Epoch: 5| Step: 10
Training loss: 1.836783615907508
Validation loss: 2.5095416531898302

Epoch: 5| Step: 11
Training loss: 1.1331683422116818
Validation loss: 2.5545764708428105

Epoch: 384| Step: 0
Training loss: 1.8233134537240177
Validation loss: 2.5534213892095003

Epoch: 5| Step: 1
Training loss: 1.816308459859228
Validation loss: 2.5813966491611806

Epoch: 5| Step: 2
Training loss: 2.00434784364399
Validation loss: 2.5421190106857705

Epoch: 5| Step: 3
Training loss: 1.4472928887603653
Validation loss: 2.4967438990837136

Epoch: 5| Step: 4
Training loss: 1.8233625538778377
Validation loss: 2.4563700883611226

Epoch: 5| Step: 5
Training loss: 2.129800423240279
Validation loss: 2.487156879939369

Epoch: 5| Step: 6
Training loss: 1.6708280904153328
Validation loss: 2.4468260439038843

Epoch: 5| Step: 7
Training loss: 1.643370665086864
Validation loss: 2.4428861440809637

Epoch: 5| Step: 8
Training loss: 1.9036393345949334
Validation loss: 2.462440266021856

Epoch: 5| Step: 9
Training loss: 1.6492794833437014
Validation loss: 2.5022457963118794

Epoch: 5| Step: 10
Training loss: 2.202274997229372
Validation loss: 2.496689985420599

Epoch: 5| Step: 11
Training loss: 1.2499170275807037
Validation loss: 2.513996394781756

Epoch: 385| Step: 0
Training loss: 1.810015191915416
Validation loss: 2.521669924188272

Epoch: 5| Step: 1
Training loss: 2.1009782737759717
Validation loss: 2.5862024254139073

Epoch: 5| Step: 2
Training loss: 1.972220737235834
Validation loss: 2.6496509521557625

Epoch: 5| Step: 3
Training loss: 2.140369929132045
Validation loss: 2.73366112245806

Epoch: 5| Step: 4
Training loss: 2.432553382750401
Validation loss: 2.6941635742213017

Epoch: 5| Step: 5
Training loss: 1.5182870512495539
Validation loss: 2.621293634031187

Epoch: 5| Step: 6
Training loss: 1.7614920527386924
Validation loss: 2.5883921164915717

Epoch: 5| Step: 7
Training loss: 1.571286786482581
Validation loss: 2.56769482194442

Epoch: 5| Step: 8
Training loss: 1.6804211101225732
Validation loss: 2.5103449488060305

Epoch: 5| Step: 9
Training loss: 1.7563456200467764
Validation loss: 2.5533125051735386

Epoch: 5| Step: 10
Training loss: 1.970417890520765
Validation loss: 2.569978342490716

Epoch: 5| Step: 11
Training loss: 2.515686603052501
Validation loss: 2.5769315326937354

Epoch: 386| Step: 0
Training loss: 1.7131922248640743
Validation loss: 2.550670864799286

Epoch: 5| Step: 1
Training loss: 1.26916583157414
Validation loss: 2.555398766198733

Epoch: 5| Step: 2
Training loss: 2.016767192993798
Validation loss: 2.543233960175995

Epoch: 5| Step: 3
Training loss: 2.148840959985982
Validation loss: 2.5346606651362107

Epoch: 5| Step: 4
Training loss: 1.5029957578932946
Validation loss: 2.551102505559821

Epoch: 5| Step: 5
Training loss: 1.7366855798351633
Validation loss: 2.5395550333271197

Epoch: 5| Step: 6
Training loss: 1.5302280207493426
Validation loss: 2.5288750413334604

Epoch: 5| Step: 7
Training loss: 1.6289538918533137
Validation loss: 2.530708364927336

Epoch: 5| Step: 8
Training loss: 1.4311638385541448
Validation loss: 2.5804930398328914

Epoch: 5| Step: 9
Training loss: 2.0053753143407316
Validation loss: 2.6057393335305075

Epoch: 5| Step: 10
Training loss: 2.4622113518564848
Validation loss: 2.555548959155715

Epoch: 5| Step: 11
Training loss: 0.6357244204896609
Validation loss: 2.528225728634692

Epoch: 387| Step: 0
Training loss: 1.465745978659433
Validation loss: 2.517669009237093

Epoch: 5| Step: 1
Training loss: 1.8133714488291783
Validation loss: 2.49800321388216

Epoch: 5| Step: 2
Training loss: 1.4012097632478275
Validation loss: 2.469300514519675

Epoch: 5| Step: 3
Training loss: 1.3555717319207754
Validation loss: 2.4641090422536274

Epoch: 5| Step: 4
Training loss: 1.8063435408186548
Validation loss: 2.444617854244621

Epoch: 5| Step: 5
Training loss: 1.6228357721750306
Validation loss: 2.471128340205767

Epoch: 5| Step: 6
Training loss: 2.0471254151895866
Validation loss: 2.4605991312556115

Epoch: 5| Step: 7
Training loss: 1.8992501234682442
Validation loss: 2.5066719313597514

Epoch: 5| Step: 8
Training loss: 1.7840317537962902
Validation loss: 2.4900587989894074

Epoch: 5| Step: 9
Training loss: 2.5952384079215953
Validation loss: 2.5055112609333627

Epoch: 5| Step: 10
Training loss: 1.9347873279102132
Validation loss: 2.533341791479731

Epoch: 5| Step: 11
Training loss: 1.0027826455850235
Validation loss: 2.5136453626647874

Epoch: 388| Step: 0
Training loss: 1.6731269640905675
Validation loss: 2.629297319018407

Epoch: 5| Step: 1
Training loss: 1.8706205084148082
Validation loss: 2.699705816949277

Epoch: 5| Step: 2
Training loss: 2.3125752617213324
Validation loss: 2.6262078874320296

Epoch: 5| Step: 3
Training loss: 2.035510715067544
Validation loss: 2.638836482570567

Epoch: 5| Step: 4
Training loss: 1.406523275313645
Validation loss: 2.5797645711370536

Epoch: 5| Step: 5
Training loss: 1.6068486504488277
Validation loss: 2.5930141646134026

Epoch: 5| Step: 6
Training loss: 1.454586729499016
Validation loss: 2.5824936314726177

Epoch: 5| Step: 7
Training loss: 2.0299550550399332
Validation loss: 2.5802197587139264

Epoch: 5| Step: 8
Training loss: 2.1121010578570982
Validation loss: 2.5603643488576218

Epoch: 5| Step: 9
Training loss: 1.7054878433004528
Validation loss: 2.5241289716894713

Epoch: 5| Step: 10
Training loss: 1.8403176509288255
Validation loss: 2.529704913557915

Epoch: 5| Step: 11
Training loss: 3.30982460087386
Validation loss: 2.470416009878954

Epoch: 389| Step: 0
Training loss: 1.4361180006280492
Validation loss: 2.486917765926263

Epoch: 5| Step: 1
Training loss: 1.667926439378468
Validation loss: 2.489139562556518

Epoch: 5| Step: 2
Training loss: 1.973234065572559
Validation loss: 2.4951531115867778

Epoch: 5| Step: 3
Training loss: 1.2843860300894512
Validation loss: 2.5033914410742084

Epoch: 5| Step: 4
Training loss: 1.6850364504530662
Validation loss: 2.50550334102842

Epoch: 5| Step: 5
Training loss: 1.6040886286129687
Validation loss: 2.4882895241464555

Epoch: 5| Step: 6
Training loss: 1.7826318567415769
Validation loss: 2.4265989644327397

Epoch: 5| Step: 7
Training loss: 1.8562169544091385
Validation loss: 2.4260018044179636

Epoch: 5| Step: 8
Training loss: 1.67678745890088
Validation loss: 2.4139698302949752

Epoch: 5| Step: 9
Training loss: 1.824677305563835
Validation loss: 2.3672164101089

Epoch: 5| Step: 10
Training loss: 1.9728892575877335
Validation loss: 2.408211688717159

Epoch: 5| Step: 11
Training loss: 2.6542851979024786
Validation loss: 2.435502358575038

Epoch: 390| Step: 0
Training loss: 1.790359693115954
Validation loss: 2.453589652534443

Epoch: 5| Step: 1
Training loss: 2.0974907552267585
Validation loss: 2.450081988993392

Epoch: 5| Step: 2
Training loss: 1.6680455067325104
Validation loss: 2.4691380224026602

Epoch: 5| Step: 3
Training loss: 2.0486017762167226
Validation loss: 2.4383925857719393

Epoch: 5| Step: 4
Training loss: 1.5956445540811244
Validation loss: 2.441567047927353

Epoch: 5| Step: 5
Training loss: 1.447347826560217
Validation loss: 2.4681512170865734

Epoch: 5| Step: 6
Training loss: 1.7172591245672342
Validation loss: 2.4424343579067087

Epoch: 5| Step: 7
Training loss: 1.7114259902148587
Validation loss: 2.468446499642753

Epoch: 5| Step: 8
Training loss: 1.5738227289315148
Validation loss: 2.465060192827922

Epoch: 5| Step: 9
Training loss: 1.70558066461797
Validation loss: 2.464762952863715

Epoch: 5| Step: 10
Training loss: 1.6352678300065993
Validation loss: 2.453832244971608

Epoch: 5| Step: 11
Training loss: 1.4875614698515534
Validation loss: 2.4553866965096485

Epoch: 391| Step: 0
Training loss: 1.7996159090751929
Validation loss: 2.445341225842313

Epoch: 5| Step: 1
Training loss: 1.6064120674751499
Validation loss: 2.435493148459932

Epoch: 5| Step: 2
Training loss: 1.9912564963254547
Validation loss: 2.4599787100785577

Epoch: 5| Step: 3
Training loss: 1.1423555075763423
Validation loss: 2.4408786132309612

Epoch: 5| Step: 4
Training loss: 1.6479274448793022
Validation loss: 2.486036560751097

Epoch: 5| Step: 5
Training loss: 1.5292279653017204
Validation loss: 2.484398191971562

Epoch: 5| Step: 6
Training loss: 2.2016861999284374
Validation loss: 2.5141261316959227

Epoch: 5| Step: 7
Training loss: 1.562437590306344
Validation loss: 2.462347835512611

Epoch: 5| Step: 8
Training loss: 1.4135580691138143
Validation loss: 2.5101350109231952

Epoch: 5| Step: 9
Training loss: 1.7639332321013177
Validation loss: 2.4915229724565244

Epoch: 5| Step: 10
Training loss: 1.836749607412728
Validation loss: 2.503559128162148

Epoch: 5| Step: 11
Training loss: 2.03093881424173
Validation loss: 2.5260431637054936

Epoch: 392| Step: 0
Training loss: 1.9489725144680978
Validation loss: 2.497761952463722

Epoch: 5| Step: 1
Training loss: 1.6441632581708676
Validation loss: 2.5365883358506767

Epoch: 5| Step: 2
Training loss: 2.456850563768173
Validation loss: 2.5156289489588732

Epoch: 5| Step: 3
Training loss: 1.3968657286334167
Validation loss: 2.5427782970858366

Epoch: 5| Step: 4
Training loss: 2.0050397793826282
Validation loss: 2.521130285558847

Epoch: 5| Step: 5
Training loss: 1.5854517000047954
Validation loss: 2.5369088884389424

Epoch: 5| Step: 6
Training loss: 1.802656079014792
Validation loss: 2.569768506025503

Epoch: 5| Step: 7
Training loss: 1.575948895608555
Validation loss: 2.515127425021404

Epoch: 5| Step: 8
Training loss: 1.7876080593711903
Validation loss: 2.5210107958937114

Epoch: 5| Step: 9
Training loss: 1.3666303098696333
Validation loss: 2.5668880101436073

Epoch: 5| Step: 10
Training loss: 1.4249447393577719
Validation loss: 2.5382191944843555

Epoch: 5| Step: 11
Training loss: 1.1381805563893943
Validation loss: 2.4945821946243822

Epoch: 393| Step: 0
Training loss: 1.7277958810041176
Validation loss: 2.4641198950843823

Epoch: 5| Step: 1
Training loss: 1.7266318190800458
Validation loss: 2.437555259502063

Epoch: 5| Step: 2
Training loss: 1.3562780597086987
Validation loss: 2.4270496829951393

Epoch: 5| Step: 3
Training loss: 2.017557090509301
Validation loss: 2.4154028952028694

Epoch: 5| Step: 4
Training loss: 2.091038442651459
Validation loss: 2.4106153672223423

Epoch: 5| Step: 5
Training loss: 1.6534012821421873
Validation loss: 2.4315017640119656

Epoch: 5| Step: 6
Training loss: 1.509850108557561
Validation loss: 2.4260427115997603

Epoch: 5| Step: 7
Training loss: 2.044469220361454
Validation loss: 2.4020006984173152

Epoch: 5| Step: 8
Training loss: 1.609304333959409
Validation loss: 2.445551392379917

Epoch: 5| Step: 9
Training loss: 1.4305644029921891
Validation loss: 2.4307839882695803

Epoch: 5| Step: 10
Training loss: 1.6727810124954734
Validation loss: 2.463037529319619

Epoch: 5| Step: 11
Training loss: 2.447856712959853
Validation loss: 2.47523529157708

Epoch: 394| Step: 0
Training loss: 1.6600818572486458
Validation loss: 2.4967671233782025

Epoch: 5| Step: 1
Training loss: 1.6552272013730571
Validation loss: 2.4386986735847827

Epoch: 5| Step: 2
Training loss: 2.029319667596374
Validation loss: 2.4771266218551857

Epoch: 5| Step: 3
Training loss: 1.7466653660534004
Validation loss: 2.483073271398147

Epoch: 5| Step: 4
Training loss: 1.0562631211227658
Validation loss: 2.454958936842508

Epoch: 5| Step: 5
Training loss: 1.7482606554638096
Validation loss: 2.466253062128872

Epoch: 5| Step: 6
Training loss: 1.5125280771723277
Validation loss: 2.4623110172608644

Epoch: 5| Step: 7
Training loss: 1.1006767012125045
Validation loss: 2.5012172437687057

Epoch: 5| Step: 8
Training loss: 2.149686914758038
Validation loss: 2.453019611662285

Epoch: 5| Step: 9
Training loss: 2.013809214218053
Validation loss: 2.4522057692027626

Epoch: 5| Step: 10
Training loss: 1.6198360114042911
Validation loss: 2.442332242197864

Epoch: 5| Step: 11
Training loss: 0.665968661176672
Validation loss: 2.467879334967697

Epoch: 395| Step: 0
Training loss: 1.2463179240182607
Validation loss: 2.473650133444023

Epoch: 5| Step: 1
Training loss: 1.7798422219503705
Validation loss: 2.462719368079078

Epoch: 5| Step: 2
Training loss: 1.5310901636275718
Validation loss: 2.4623857102118176

Epoch: 5| Step: 3
Training loss: 1.7890385122231922
Validation loss: 2.494533367496575

Epoch: 5| Step: 4
Training loss: 1.4512007904252462
Validation loss: 2.5185543403955593

Epoch: 5| Step: 5
Training loss: 1.806332981619009
Validation loss: 2.5429858721319274

Epoch: 5| Step: 6
Training loss: 2.15042100377327
Validation loss: 2.5148625965958713

Epoch: 5| Step: 7
Training loss: 2.0964019833120666
Validation loss: 2.5229663094021126

Epoch: 5| Step: 8
Training loss: 1.4056233175292234
Validation loss: 2.4922836767471055

Epoch: 5| Step: 9
Training loss: 1.4731218730131033
Validation loss: 2.483580040251379

Epoch: 5| Step: 10
Training loss: 1.704943604641316
Validation loss: 2.4808350059863282

Epoch: 5| Step: 11
Training loss: 0.825862420747413
Validation loss: 2.4947972679208035

Epoch: 396| Step: 0
Training loss: 1.7250070599397676
Validation loss: 2.4836837358663395

Epoch: 5| Step: 1
Training loss: 1.5657095941467323
Validation loss: 2.513676676712252

Epoch: 5| Step: 2
Training loss: 1.4387887070898535
Validation loss: 2.5205284254770057

Epoch: 5| Step: 3
Training loss: 1.933346757622952
Validation loss: 2.5410357197644537

Epoch: 5| Step: 4
Training loss: 2.1222880392648036
Validation loss: 2.5099781703379653

Epoch: 5| Step: 5
Training loss: 1.8791378774643872
Validation loss: 2.4755170924177636

Epoch: 5| Step: 6
Training loss: 1.426567634163817
Validation loss: 2.4890138454914266

Epoch: 5| Step: 7
Training loss: 1.5141316558507683
Validation loss: 2.484750139555713

Epoch: 5| Step: 8
Training loss: 1.4695317237443581
Validation loss: 2.453201284660058

Epoch: 5| Step: 9
Training loss: 1.9519846524510742
Validation loss: 2.4842843493031643

Epoch: 5| Step: 10
Training loss: 1.6166467914473832
Validation loss: 2.5099308657148973

Epoch: 5| Step: 11
Training loss: 0.510066152097035
Validation loss: 2.5070426111705864

Epoch: 397| Step: 0
Training loss: 1.728216285433001
Validation loss: 2.5036346597715133

Epoch: 5| Step: 1
Training loss: 1.6041856822418474
Validation loss: 2.493900113220612

Epoch: 5| Step: 2
Training loss: 1.608436829526238
Validation loss: 2.5061949269624604

Epoch: 5| Step: 3
Training loss: 1.4109917698896581
Validation loss: 2.4972992136817806

Epoch: 5| Step: 4
Training loss: 1.4466132831539031
Validation loss: 2.5077332496995086

Epoch: 5| Step: 5
Training loss: 1.711050787532582
Validation loss: 2.4939408746329796

Epoch: 5| Step: 6
Training loss: 2.3890128091218843
Validation loss: 2.5090447089313237

Epoch: 5| Step: 7
Training loss: 1.6000531038770058
Validation loss: 2.486296900023482

Epoch: 5| Step: 8
Training loss: 1.1968322268181077
Validation loss: 2.4791942235606554

Epoch: 5| Step: 9
Training loss: 1.8648656990028485
Validation loss: 2.4823327137291615

Epoch: 5| Step: 10
Training loss: 1.3390298044849074
Validation loss: 2.505073570835422

Epoch: 5| Step: 11
Training loss: 0.8067470600392594
Validation loss: 2.450323347565441

Epoch: 398| Step: 0
Training loss: 2.092387652919002
Validation loss: 2.42755119919598

Epoch: 5| Step: 1
Training loss: 1.2715438617906898
Validation loss: 2.500000107288358

Epoch: 5| Step: 2
Training loss: 1.2869512666369167
Validation loss: 2.5364530486274406

Epoch: 5| Step: 3
Training loss: 2.0597772833416275
Validation loss: 2.565629470920423

Epoch: 5| Step: 4
Training loss: 1.5232561052363758
Validation loss: 2.571059863302747

Epoch: 5| Step: 5
Training loss: 1.8693414498509846
Validation loss: 2.542156415927876

Epoch: 5| Step: 6
Training loss: 1.7695133300951766
Validation loss: 2.4757860693458844

Epoch: 5| Step: 7
Training loss: 1.3601794438627706
Validation loss: 2.507152839011201

Epoch: 5| Step: 8
Training loss: 1.6505607201316996
Validation loss: 2.503924571588686

Epoch: 5| Step: 9
Training loss: 1.888237699133495
Validation loss: 2.515586631592875

Epoch: 5| Step: 10
Training loss: 1.4183808875862285
Validation loss: 2.513024504400283

Epoch: 5| Step: 11
Training loss: 1.6358677511275406
Validation loss: 2.509532328844259

Epoch: 399| Step: 0
Training loss: 1.6816143250928686
Validation loss: 2.525947708007946

Epoch: 5| Step: 1
Training loss: 1.7313743959761412
Validation loss: 2.5350567054112063

Epoch: 5| Step: 2
Training loss: 2.118063319735723
Validation loss: 2.4981538433031973

Epoch: 5| Step: 3
Training loss: 1.1972563651444015
Validation loss: 2.5236553180802024

Epoch: 5| Step: 4
Training loss: 1.6100482458384942
Validation loss: 2.489677843723378

Epoch: 5| Step: 5
Training loss: 1.6134191274030956
Validation loss: 2.4930891201790586

Epoch: 5| Step: 6
Training loss: 1.72691776538847
Validation loss: 2.469026513850726

Epoch: 5| Step: 7
Training loss: 1.4406444324829484
Validation loss: 2.4713654465948864

Epoch: 5| Step: 8
Training loss: 1.5066089471518684
Validation loss: 2.479154656218172

Epoch: 5| Step: 9
Training loss: 1.7126037983866593
Validation loss: 2.486816809715559

Epoch: 5| Step: 10
Training loss: 1.827390343837353
Validation loss: 2.491095695387174

Epoch: 5| Step: 11
Training loss: 2.0809019651184526
Validation loss: 2.4809139763256263

Epoch: 400| Step: 0
Training loss: 1.454105087696155
Validation loss: 2.504472905479216

Epoch: 5| Step: 1
Training loss: 1.7966754304935164
Validation loss: 2.5422141131770615

Epoch: 5| Step: 2
Training loss: 1.2060384772443
Validation loss: 2.497799123130616

Epoch: 5| Step: 3
Training loss: 1.5924873586299642
Validation loss: 2.5404890425223723

Epoch: 5| Step: 4
Training loss: 1.2904206028649259
Validation loss: 2.5351412086452054

Epoch: 5| Step: 5
Training loss: 1.1203948178235144
Validation loss: 2.510967864205278

Epoch: 5| Step: 6
Training loss: 1.9896284833914615
Validation loss: 2.5173505508084424

Epoch: 5| Step: 7
Training loss: 1.8198213364865155
Validation loss: 2.5049263457740913

Epoch: 5| Step: 8
Training loss: 2.097054677618791
Validation loss: 2.4742222628434507

Epoch: 5| Step: 9
Training loss: 1.4098876528249535
Validation loss: 2.465389058387941

Epoch: 5| Step: 10
Training loss: 2.156675103341551
Validation loss: 2.4675310300385194

Epoch: 5| Step: 11
Training loss: 1.3711717806182442
Validation loss: 2.454045675713817

Testing loss: 2.146537176447138
