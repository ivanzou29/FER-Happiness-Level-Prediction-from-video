Epoch: 1| Step: 0
Training loss: 5.420565488249574
Validation loss: 5.891727118427043

Epoch: 6| Step: 1
Training loss: 6.973483133305626
Validation loss: 5.890746853189554

Epoch: 6| Step: 2
Training loss: 5.333066198493569
Validation loss: 5.889789471450178

Epoch: 6| Step: 3
Training loss: 5.967703043404373
Validation loss: 5.888744698364661

Epoch: 6| Step: 4
Training loss: 5.99438977213147
Validation loss: 5.887741367929562

Epoch: 6| Step: 5
Training loss: 6.457663946429818
Validation loss: 5.886636343187027

Epoch: 6| Step: 6
Training loss: 5.857275991222671
Validation loss: 5.88551582545466

Epoch: 6| Step: 7
Training loss: 5.320632633654991
Validation loss: 5.884362410472625

Epoch: 6| Step: 8
Training loss: 6.103937172942597
Validation loss: 5.883167973789

Epoch: 6| Step: 9
Training loss: 5.503935186392618
Validation loss: 5.882022772573596

Epoch: 6| Step: 10
Training loss: 6.241396055309924
Validation loss: 5.880795021849479

Epoch: 6| Step: 11
Training loss: 6.449338231403814
Validation loss: 5.879516191408939

Epoch: 6| Step: 12
Training loss: 6.30582702246548
Validation loss: 5.878216370314045

Epoch: 6| Step: 13
Training loss: 5.841086693604798
Validation loss: 5.876791579415022

Epoch: 2| Step: 0
Training loss: 6.052970396636563
Validation loss: 5.875414353496841

Epoch: 6| Step: 1
Training loss: 5.163397257051878
Validation loss: 5.873912981262672

Epoch: 6| Step: 2
Training loss: 7.120891256377691
Validation loss: 5.872323989146742

Epoch: 6| Step: 3
Training loss: 6.561233252927106
Validation loss: 5.870717618445788

Epoch: 6| Step: 4
Training loss: 6.240782693046295
Validation loss: 5.869098783778685

Epoch: 6| Step: 5
Training loss: 5.5676002694167765
Validation loss: 5.867357789136483

Epoch: 6| Step: 6
Training loss: 5.5952165268904555
Validation loss: 5.86554991467936

Epoch: 6| Step: 7
Training loss: 5.438475773393955
Validation loss: 5.863650783658191

Epoch: 6| Step: 8
Training loss: 5.8515644557323165
Validation loss: 5.861744177056993

Epoch: 6| Step: 9
Training loss: 6.247564833214206
Validation loss: 5.859705475706431

Epoch: 6| Step: 10
Training loss: 6.9286315870412185
Validation loss: 5.857515275614813

Epoch: 6| Step: 11
Training loss: 4.982807163966549
Validation loss: 5.85516385130134

Epoch: 6| Step: 12
Training loss: 6.080048950399808
Validation loss: 5.85291321210564

Epoch: 6| Step: 13
Training loss: 5.467805094149519
Validation loss: 5.850472539308871

Epoch: 3| Step: 0
Training loss: 5.925415269165575
Validation loss: 5.847949336438258

Epoch: 6| Step: 1
Training loss: 5.428921301043139
Validation loss: 5.845250445358316

Epoch: 6| Step: 2
Training loss: 6.281505370761088
Validation loss: 5.842344608049556

Epoch: 6| Step: 3
Training loss: 6.011153345122233
Validation loss: 5.839278633732223

Epoch: 6| Step: 4
Training loss: 6.145400347786165
Validation loss: 5.836123843539522

Epoch: 6| Step: 5
Training loss: 5.881433089646458
Validation loss: 5.832732805493977

Epoch: 6| Step: 6
Training loss: 6.627180208587197
Validation loss: 5.829093954829388

Epoch: 6| Step: 7
Training loss: 5.250399801380921
Validation loss: 5.825561177695662

Epoch: 6| Step: 8
Training loss: 5.077771547194502
Validation loss: 5.821727469747701

Epoch: 6| Step: 9
Training loss: 6.531335273441531
Validation loss: 5.817498112508688

Epoch: 6| Step: 10
Training loss: 5.844888341667658
Validation loss: 5.813293184147586

Epoch: 6| Step: 11
Training loss: 6.035274447669418
Validation loss: 5.808860623886727

Epoch: 6| Step: 12
Training loss: 5.807260756702586
Validation loss: 5.8043484971738115

Epoch: 6| Step: 13
Training loss: 6.1435549203475155
Validation loss: 5.799357332600864

Epoch: 4| Step: 0
Training loss: 5.892784957113339
Validation loss: 5.794278669602027

Epoch: 6| Step: 1
Training loss: 5.945822574825841
Validation loss: 5.7890857004515

Epoch: 6| Step: 2
Training loss: 6.894019158124518
Validation loss: 5.783474770757705

Epoch: 6| Step: 3
Training loss: 6.002847631541217
Validation loss: 5.777646262962551

Epoch: 6| Step: 4
Training loss: 7.0550670838495355
Validation loss: 5.771698630928595

Epoch: 6| Step: 5
Training loss: 5.8579246251814
Validation loss: 5.765377490788217

Epoch: 6| Step: 6
Training loss: 5.5626721301931275
Validation loss: 5.758684593487802

Epoch: 6| Step: 7
Training loss: 4.755926751319454
Validation loss: 5.752030470219579

Epoch: 6| Step: 8
Training loss: 5.431472594656885
Validation loss: 5.745202675507088

Epoch: 6| Step: 9
Training loss: 5.543880202216964
Validation loss: 5.73823479827714

Epoch: 6| Step: 10
Training loss: 5.074842689218308
Validation loss: 5.731174334543462

Epoch: 6| Step: 11
Training loss: 5.580759147768812
Validation loss: 5.723794931908933

Epoch: 6| Step: 12
Training loss: 6.100980410974752
Validation loss: 5.716544304401015

Epoch: 6| Step: 13
Training loss: 6.089315356025417
Validation loss: 5.708825064685492

Epoch: 5| Step: 0
Training loss: 6.347387013520923
Validation loss: 5.7010724837798445

Epoch: 6| Step: 1
Training loss: 5.86274642589093
Validation loss: 5.692949862880933

Epoch: 6| Step: 2
Training loss: 5.931710723573285
Validation loss: 5.684875245930022

Epoch: 6| Step: 3
Training loss: 6.1599952420303
Validation loss: 5.676498868294941

Epoch: 6| Step: 4
Training loss: 5.474297200562634
Validation loss: 5.668076349205896

Epoch: 6| Step: 5
Training loss: 4.956872719588746
Validation loss: 5.659521207249641

Epoch: 6| Step: 6
Training loss: 5.683810871604536
Validation loss: 5.651097798105321

Epoch: 6| Step: 7
Training loss: 6.058152360412592
Validation loss: 5.642473194541466

Epoch: 6| Step: 8
Training loss: 5.2540823187273045
Validation loss: 5.633577546162645

Epoch: 6| Step: 9
Training loss: 6.089256781967589
Validation loss: 5.625160158491057

Epoch: 6| Step: 10
Training loss: 6.225656938933358
Validation loss: 5.616642260097523

Epoch: 6| Step: 11
Training loss: 5.266873808702547
Validation loss: 5.60827810176201

Epoch: 6| Step: 12
Training loss: 5.553826073488927
Validation loss: 5.600278912138019

Epoch: 6| Step: 13
Training loss: 5.658193349253723
Validation loss: 5.592025888940626

Epoch: 6| Step: 0
Training loss: 5.963272857160345
Validation loss: 5.5835614039208865

Epoch: 6| Step: 1
Training loss: 5.8623462518568585
Validation loss: 5.575575529991615

Epoch: 6| Step: 2
Training loss: 5.035203032353945
Validation loss: 5.567315121341616

Epoch: 6| Step: 3
Training loss: 5.739258394083899
Validation loss: 5.558904450151404

Epoch: 6| Step: 4
Training loss: 6.054309779044575
Validation loss: 5.550756681255004

Epoch: 6| Step: 5
Training loss: 6.700493569484791
Validation loss: 5.542449647281549

Epoch: 6| Step: 6
Training loss: 5.878024357649523
Validation loss: 5.534896797842258

Epoch: 6| Step: 7
Training loss: 5.834738571207448
Validation loss: 5.527352089308344

Epoch: 6| Step: 8
Training loss: 5.04969260158313
Validation loss: 5.520232785748269

Epoch: 6| Step: 9
Training loss: 4.890915737102462
Validation loss: 5.513650484907293

Epoch: 6| Step: 10
Training loss: 5.473689175808157
Validation loss: 5.506759247051627

Epoch: 6| Step: 11
Training loss: 5.7497409264623
Validation loss: 5.500711452823472

Epoch: 6| Step: 12
Training loss: 5.7350724547115375
Validation loss: 5.494009859653694

Epoch: 6| Step: 13
Training loss: 4.896994443604003
Validation loss: 5.487479668813478

Epoch: 7| Step: 0
Training loss: 4.981570037554676
Validation loss: 5.4809517025656165

Epoch: 6| Step: 1
Training loss: 6.110483210509457
Validation loss: 5.474756107094598

Epoch: 6| Step: 2
Training loss: 5.440125631676876
Validation loss: 5.468105081950772

Epoch: 6| Step: 3
Training loss: 5.899279482537333
Validation loss: 5.461674820109383

Epoch: 6| Step: 4
Training loss: 6.302904446496862
Validation loss: 5.455497626320571

Epoch: 6| Step: 5
Training loss: 5.408092206958913
Validation loss: 5.448833186684419

Epoch: 6| Step: 6
Training loss: 5.937561356076898
Validation loss: 5.442601700853116

Epoch: 6| Step: 7
Training loss: 5.389279404917921
Validation loss: 5.436356201304037

Epoch: 6| Step: 8
Training loss: 5.785464838157319
Validation loss: 5.430571779105996

Epoch: 6| Step: 9
Training loss: 5.508266305828255
Validation loss: 5.424621003912819

Epoch: 6| Step: 10
Training loss: 5.383650450130418
Validation loss: 5.418676893422346

Epoch: 6| Step: 11
Training loss: 5.542288762026
Validation loss: 5.412839691802674

Epoch: 6| Step: 12
Training loss: 5.6619284772973995
Validation loss: 5.4069430397664

Epoch: 6| Step: 13
Training loss: 4.241964935028314
Validation loss: 5.4012495373042455

Epoch: 8| Step: 0
Training loss: 5.557979675815865
Validation loss: 5.395494732733015

Epoch: 6| Step: 1
Training loss: 5.08716949214123
Validation loss: 5.389716944484054

Epoch: 6| Step: 2
Training loss: 4.897181202286408
Validation loss: 5.384048297909181

Epoch: 6| Step: 3
Training loss: 4.084234229115815
Validation loss: 5.37830295656222

Epoch: 6| Step: 4
Training loss: 5.902394484498199
Validation loss: 5.372672737839216

Epoch: 6| Step: 5
Training loss: 5.974926055067576
Validation loss: 5.3669567400963

Epoch: 6| Step: 6
Training loss: 4.959504937414939
Validation loss: 5.3610392397124205

Epoch: 6| Step: 7
Training loss: 5.17579138412923
Validation loss: 5.355355137037956

Epoch: 6| Step: 8
Training loss: 6.3488691749811155
Validation loss: 5.350280667604983

Epoch: 6| Step: 9
Training loss: 5.413852527944951
Validation loss: 5.344848222519439

Epoch: 6| Step: 10
Training loss: 6.024432346305737
Validation loss: 5.339123959922997

Epoch: 6| Step: 11
Training loss: 5.199563947147733
Validation loss: 5.33370497521319

Epoch: 6| Step: 12
Training loss: 6.272276584482391
Validation loss: 5.327506975741916

Epoch: 6| Step: 13
Training loss: 5.369243289192171
Validation loss: 5.3216054636447225

Epoch: 9| Step: 0
Training loss: 5.166903131467698
Validation loss: 5.315754779754141

Epoch: 6| Step: 1
Training loss: 5.450363553021709
Validation loss: 5.309757586954652

Epoch: 6| Step: 2
Training loss: 5.446799908381375
Validation loss: 5.304421988927448

Epoch: 6| Step: 3
Training loss: 6.50278471936795
Validation loss: 5.298517983238827

Epoch: 6| Step: 4
Training loss: 4.583506263013714
Validation loss: 5.292817368635872

Epoch: 6| Step: 5
Training loss: 4.4239229777358755
Validation loss: 5.28709903336016

Epoch: 6| Step: 6
Training loss: 5.3898585562468755
Validation loss: 5.281685474507117

Epoch: 6| Step: 7
Training loss: 5.0352623146315265
Validation loss: 5.276218583309362

Epoch: 6| Step: 8
Training loss: 5.7059305893413095
Validation loss: 5.270431905344387

Epoch: 6| Step: 9
Training loss: 4.47558561787447
Validation loss: 5.264927607537049

Epoch: 6| Step: 10
Training loss: 6.030048468096081
Validation loss: 5.259343929882757

Epoch: 6| Step: 11
Training loss: 5.454522508515153
Validation loss: 5.253255016708103

Epoch: 6| Step: 12
Training loss: 6.270413440658987
Validation loss: 5.247655405545485

Epoch: 6| Step: 13
Training loss: 5.205196300546376
Validation loss: 5.241436771431512

Epoch: 10| Step: 0
Training loss: 5.776957469971826
Validation loss: 5.2353096654148015

Epoch: 6| Step: 1
Training loss: 4.729585245348431
Validation loss: 5.229838030551774

Epoch: 6| Step: 2
Training loss: 6.588363399782806
Validation loss: 5.22334361492639

Epoch: 6| Step: 3
Training loss: 5.873514515178265
Validation loss: 5.217440777868863

Epoch: 6| Step: 4
Training loss: 5.989979960260001
Validation loss: 5.2116109478619945

Epoch: 6| Step: 5
Training loss: 5.070550992320524
Validation loss: 5.205193094268512

Epoch: 6| Step: 6
Training loss: 5.185223918850858
Validation loss: 5.199354422671815

Epoch: 6| Step: 7
Training loss: 5.551972274194356
Validation loss: 5.19377427812725

Epoch: 6| Step: 8
Training loss: 5.610799199532158
Validation loss: 5.187747474497116

Epoch: 6| Step: 9
Training loss: 4.812665267682738
Validation loss: 5.182080022685025

Epoch: 6| Step: 10
Training loss: 4.66515262202818
Validation loss: 5.176233949836733

Epoch: 6| Step: 11
Training loss: 3.9262775164407824
Validation loss: 5.170684031939516

Epoch: 6| Step: 12
Training loss: 5.007588540721378
Validation loss: 5.165266165065382

Epoch: 6| Step: 13
Training loss: 5.17844068615867
Validation loss: 5.1597882393945875

Epoch: 11| Step: 0
Training loss: 4.729731028935905
Validation loss: 5.154087946585398

Epoch: 6| Step: 1
Training loss: 4.772915625880825
Validation loss: 5.14879755469731

Epoch: 6| Step: 2
Training loss: 5.045979045314877
Validation loss: 5.142961738168672

Epoch: 6| Step: 3
Training loss: 5.537282294478063
Validation loss: 5.1370673115757075

Epoch: 6| Step: 4
Training loss: 5.361592270644584
Validation loss: 5.131045334854538

Epoch: 6| Step: 5
Training loss: 5.74888633226291
Validation loss: 5.125796465508824

Epoch: 6| Step: 6
Training loss: 5.7659773059918376
Validation loss: 5.120201283313052

Epoch: 6| Step: 7
Training loss: 5.598111801617417
Validation loss: 5.115445636019804

Epoch: 6| Step: 8
Training loss: 5.24575197834966
Validation loss: 5.109793083047737

Epoch: 6| Step: 9
Training loss: 5.732947231569548
Validation loss: 5.104588435386919

Epoch: 6| Step: 10
Training loss: 5.4514573834672655
Validation loss: 5.099330318339487

Epoch: 6| Step: 11
Training loss: 4.229374371519136
Validation loss: 5.094305277321425

Epoch: 6| Step: 12
Training loss: 5.039084075171835
Validation loss: 5.089693541029108

Epoch: 6| Step: 13
Training loss: 4.877250152085754
Validation loss: 5.085516268098458

Epoch: 12| Step: 0
Training loss: 5.502924401755447
Validation loss: 5.080202118014153

Epoch: 6| Step: 1
Training loss: 4.603859087076009
Validation loss: 5.075793297312835

Epoch: 6| Step: 2
Training loss: 5.165978149970408
Validation loss: 5.071183594659195

Epoch: 6| Step: 3
Training loss: 5.786566521851832
Validation loss: 5.066991689362633

Epoch: 6| Step: 4
Training loss: 4.5398213315248395
Validation loss: 5.0606407236328685

Epoch: 6| Step: 5
Training loss: 5.672354181398453
Validation loss: 5.055633189172362

Epoch: 6| Step: 6
Training loss: 5.62156504550032
Validation loss: 5.050859262365994

Epoch: 6| Step: 7
Training loss: 4.82406633267575
Validation loss: 5.045594327491534

Epoch: 6| Step: 8
Training loss: 5.239314512886338
Validation loss: 5.040132788417583

Epoch: 6| Step: 9
Training loss: 5.268714609626841
Validation loss: 5.034983763935337

Epoch: 6| Step: 10
Training loss: 4.3816699818487
Validation loss: 5.030444789607643

Epoch: 6| Step: 11
Training loss: 6.154514436014854
Validation loss: 5.025047317206191

Epoch: 6| Step: 12
Training loss: 4.583152536236401
Validation loss: 5.0196964459380204

Epoch: 6| Step: 13
Training loss: 4.704774687639164
Validation loss: 5.0156575139498125

Epoch: 13| Step: 0
Training loss: 4.921725025616852
Validation loss: 5.011209860000475

Epoch: 6| Step: 1
Training loss: 5.581286990052745
Validation loss: 5.006520755858012

Epoch: 6| Step: 2
Training loss: 5.453867339839803
Validation loss: 5.001127910552368

Epoch: 6| Step: 3
Training loss: 5.206961285749955
Validation loss: 4.995296491212064

Epoch: 6| Step: 4
Training loss: 4.687342933566464
Validation loss: 4.9901784437097145

Epoch: 6| Step: 5
Training loss: 4.780900331563782
Validation loss: 4.98569779496778

Epoch: 6| Step: 6
Training loss: 4.511322611802848
Validation loss: 4.981927699404265

Epoch: 6| Step: 7
Training loss: 5.692896703434602
Validation loss: 4.9746267245783535

Epoch: 6| Step: 8
Training loss: 4.782835853218059
Validation loss: 4.970961968078399

Epoch: 6| Step: 9
Training loss: 4.493654651717937
Validation loss: 4.966042858777156

Epoch: 6| Step: 10
Training loss: 5.922235402435911
Validation loss: 4.9585013267630975

Epoch: 6| Step: 11
Training loss: 4.43420631781442
Validation loss: 4.953138381506717

Epoch: 6| Step: 12
Training loss: 4.7584155973593125
Validation loss: 4.9489700427512675

Epoch: 6| Step: 13
Training loss: 5.84763798427341
Validation loss: 4.944827601889724

Epoch: 14| Step: 0
Training loss: 5.613565988559336
Validation loss: 4.938550265994736

Epoch: 6| Step: 1
Training loss: 5.169415675775656
Validation loss: 4.932966412396718

Epoch: 6| Step: 2
Training loss: 4.8864263970052395
Validation loss: 4.92990007058077

Epoch: 6| Step: 3
Training loss: 5.718340749636653
Validation loss: 4.9254481348937995

Epoch: 6| Step: 4
Training loss: 4.981121472240545
Validation loss: 4.919396219292994

Epoch: 6| Step: 5
Training loss: 5.893867874989397
Validation loss: 4.913807614199857

Epoch: 6| Step: 6
Training loss: 4.132684197264099
Validation loss: 4.909115126846551

Epoch: 6| Step: 7
Training loss: 4.898964301442361
Validation loss: 4.905118127321389

Epoch: 6| Step: 8
Training loss: 4.868277585342605
Validation loss: 4.901530431630981

Epoch: 6| Step: 9
Training loss: 5.026068631694451
Validation loss: 4.894870982718473

Epoch: 6| Step: 10
Training loss: 4.794665296724808
Validation loss: 4.888160807888886

Epoch: 6| Step: 11
Training loss: 4.649354065361946
Validation loss: 4.883982867549055

Epoch: 6| Step: 12
Training loss: 4.176198255166423
Validation loss: 4.880328013751729

Epoch: 6| Step: 13
Training loss: 5.33228325440427
Validation loss: 4.877205276539965

Epoch: 15| Step: 0
Training loss: 4.84172951180953
Validation loss: 4.869509678256374

Epoch: 6| Step: 1
Training loss: 4.504290760364638
Validation loss: 4.864775801560295

Epoch: 6| Step: 2
Training loss: 3.8971447836723727
Validation loss: 4.860018001753299

Epoch: 6| Step: 3
Training loss: 4.861163138459336
Validation loss: 4.855555628978536

Epoch: 6| Step: 4
Training loss: 4.4470438878900564
Validation loss: 4.852379411197733

Epoch: 6| Step: 5
Training loss: 5.747345684911862
Validation loss: 4.846757902382441

Epoch: 6| Step: 6
Training loss: 5.492005867484696
Validation loss: 4.8412023591969895

Epoch: 6| Step: 7
Training loss: 4.797144779733016
Validation loss: 4.835220209765912

Epoch: 6| Step: 8
Training loss: 4.525010015149915
Validation loss: 4.830094841973025

Epoch: 6| Step: 9
Training loss: 5.203800925033817
Validation loss: 4.8251178351526205

Epoch: 6| Step: 10
Training loss: 4.9102859904796565
Validation loss: 4.819362157191847

Epoch: 6| Step: 11
Training loss: 4.72555516125156
Validation loss: 4.813561987020526

Epoch: 6| Step: 12
Training loss: 5.914248908266018
Validation loss: 4.80881963922872

Epoch: 6| Step: 13
Training loss: 5.2213479160135075
Validation loss: 4.802727292699299

Epoch: 16| Step: 0
Training loss: 5.351463417194068
Validation loss: 4.795803468126801

Epoch: 6| Step: 1
Training loss: 4.910372223273278
Validation loss: 4.7894024129344634

Epoch: 6| Step: 2
Training loss: 4.561376773058316
Validation loss: 4.782517890451366

Epoch: 6| Step: 3
Training loss: 6.326606323361742
Validation loss: 4.774547624712756

Epoch: 6| Step: 4
Training loss: 4.224860844775227
Validation loss: 4.767739649141878

Epoch: 6| Step: 5
Training loss: 5.108422240105366
Validation loss: 4.762194506708491

Epoch: 6| Step: 6
Training loss: 3.795414647706158
Validation loss: 4.75657730480176

Epoch: 6| Step: 7
Training loss: 4.436124776586798
Validation loss: 4.75235529278456

Epoch: 6| Step: 8
Training loss: 4.622641709643137
Validation loss: 4.747387585935336

Epoch: 6| Step: 9
Training loss: 5.677682304865293
Validation loss: 4.744006558509698

Epoch: 6| Step: 10
Training loss: 4.293621815374175
Validation loss: 4.737569740339028

Epoch: 6| Step: 11
Training loss: 4.396436652895152
Validation loss: 4.731784124221009

Epoch: 6| Step: 12
Training loss: 5.197797917887
Validation loss: 4.7257372595480724

Epoch: 6| Step: 13
Training loss: 4.909526532685864
Validation loss: 4.720886790867096

Epoch: 17| Step: 0
Training loss: 5.859945610236638
Validation loss: 4.716642334317011

Epoch: 6| Step: 1
Training loss: 4.402015328532684
Validation loss: 4.7105604435223665

Epoch: 6| Step: 2
Training loss: 4.857824341865994
Validation loss: 4.705075692714191

Epoch: 6| Step: 3
Training loss: 4.8492050463244825
Validation loss: 4.7006512089310455

Epoch: 6| Step: 4
Training loss: 5.664953122328006
Validation loss: 4.696153748397171

Epoch: 6| Step: 5
Training loss: 4.620996753129312
Validation loss: 4.690695186515999

Epoch: 6| Step: 6
Training loss: 5.1604061138408115
Validation loss: 4.686010675133488

Epoch: 6| Step: 7
Training loss: 4.5454227186302525
Validation loss: 4.680872712424973

Epoch: 6| Step: 8
Training loss: 4.948536380975972
Validation loss: 4.674668105476827

Epoch: 6| Step: 9
Training loss: 5.294299374372261
Validation loss: 4.670507105319446

Epoch: 6| Step: 10
Training loss: 3.8836247843682425
Validation loss: 4.665531747051712

Epoch: 6| Step: 11
Training loss: 4.934599012106082
Validation loss: 4.660904267128998

Epoch: 6| Step: 12
Training loss: 4.440126743054162
Validation loss: 4.656326395726575

Epoch: 6| Step: 13
Training loss: 3.335605863931197
Validation loss: 4.652063762226725

Epoch: 18| Step: 0
Training loss: 4.455292612520933
Validation loss: 4.6476589544650375

Epoch: 6| Step: 1
Training loss: 5.189039070974754
Validation loss: 4.643826802621056

Epoch: 6| Step: 2
Training loss: 3.8742329238167703
Validation loss: 4.638584566064302

Epoch: 6| Step: 3
Training loss: 4.440243155204875
Validation loss: 4.6341472416286384

Epoch: 6| Step: 4
Training loss: 5.038695707944255
Validation loss: 4.629873886587929

Epoch: 6| Step: 5
Training loss: 5.175781065742921
Validation loss: 4.625374237590787

Epoch: 6| Step: 6
Training loss: 4.866803443414983
Validation loss: 4.621891110942171

Epoch: 6| Step: 7
Training loss: 4.617488018654406
Validation loss: 4.615970388759351

Epoch: 6| Step: 8
Training loss: 4.151905743670163
Validation loss: 4.611286607464122

Epoch: 6| Step: 9
Training loss: 4.856683212458053
Validation loss: 4.608449896958752

Epoch: 6| Step: 10
Training loss: 4.327283646647735
Validation loss: 4.603552689616867

Epoch: 6| Step: 11
Training loss: 4.671222551901646
Validation loss: 4.59807720218075

Epoch: 6| Step: 12
Training loss: 5.822596814737578
Validation loss: 4.594000085091386

Epoch: 6| Step: 13
Training loss: 4.622565376145402
Validation loss: 4.589494009558527

Epoch: 19| Step: 0
Training loss: 4.1115681992703195
Validation loss: 4.584577940523065

Epoch: 6| Step: 1
Training loss: 4.728635021468644
Validation loss: 4.580056122792746

Epoch: 6| Step: 2
Training loss: 3.623259685672129
Validation loss: 4.575747448674401

Epoch: 6| Step: 3
Training loss: 5.379271650681093
Validation loss: 4.571154742327592

Epoch: 6| Step: 4
Training loss: 4.958908987955927
Validation loss: 4.5674603988303195

Epoch: 6| Step: 5
Training loss: 4.865191642852282
Validation loss: 4.562613707915261

Epoch: 6| Step: 6
Training loss: 4.6846080760217
Validation loss: 4.557812028513681

Epoch: 6| Step: 7
Training loss: 4.766192092923909
Validation loss: 4.5535130237926325

Epoch: 6| Step: 8
Training loss: 4.309522845060647
Validation loss: 4.54858065814177

Epoch: 6| Step: 9
Training loss: 4.2574993613349585
Validation loss: 4.5442423676598445

Epoch: 6| Step: 10
Training loss: 5.416095742679598
Validation loss: 4.539972088317664

Epoch: 6| Step: 11
Training loss: 4.4227434255865825
Validation loss: 4.535186968996998

Epoch: 6| Step: 12
Training loss: 5.238528479787518
Validation loss: 4.53094327041943

Epoch: 6| Step: 13
Training loss: 4.451447395076439
Validation loss: 4.526474990850361

Epoch: 20| Step: 0
Training loss: 4.6784666376223845
Validation loss: 4.522175702385057

Epoch: 6| Step: 1
Training loss: 4.222511027871113
Validation loss: 4.517264802091636

Epoch: 6| Step: 2
Training loss: 4.605751190713814
Validation loss: 4.512474324865731

Epoch: 6| Step: 3
Training loss: 4.554611493322184
Validation loss: 4.50830537337249

Epoch: 6| Step: 4
Training loss: 4.747906876214001
Validation loss: 4.5039951815266015

Epoch: 6| Step: 5
Training loss: 3.810134529081579
Validation loss: 4.498989804225452

Epoch: 6| Step: 6
Training loss: 4.763392591559428
Validation loss: 4.4948721031632894

Epoch: 6| Step: 7
Training loss: 4.936215390518509
Validation loss: 4.490047469196152

Epoch: 6| Step: 8
Training loss: 5.08081790827672
Validation loss: 4.486297868608066

Epoch: 6| Step: 9
Training loss: 4.896802614184603
Validation loss: 4.481435541189545

Epoch: 6| Step: 10
Training loss: 4.195345688445308
Validation loss: 4.476328437016398

Epoch: 6| Step: 11
Training loss: 4.925588799149859
Validation loss: 4.472214536219298

Epoch: 6| Step: 12
Training loss: 4.201006387300273
Validation loss: 4.467241846363112

Epoch: 6| Step: 13
Training loss: 4.8964045198165245
Validation loss: 4.463361073968749

Epoch: 21| Step: 0
Training loss: 4.924048921566724
Validation loss: 4.458680195847965

Epoch: 6| Step: 1
Training loss: 4.242370264320964
Validation loss: 4.453579028446447

Epoch: 6| Step: 2
Training loss: 5.224957275215945
Validation loss: 4.4496383848671535

Epoch: 6| Step: 3
Training loss: 5.20534525287806
Validation loss: 4.444742980838201

Epoch: 6| Step: 4
Training loss: 4.883795994702389
Validation loss: 4.439463973294323

Epoch: 6| Step: 5
Training loss: 3.629530870372817
Validation loss: 4.43446876976941

Epoch: 6| Step: 6
Training loss: 4.477372820148605
Validation loss: 4.4305459098485045

Epoch: 6| Step: 7
Training loss: 5.326497206843052
Validation loss: 4.425733646272608

Epoch: 6| Step: 8
Training loss: 4.667894383560346
Validation loss: 4.4206801778358376

Epoch: 6| Step: 9
Training loss: 4.021821106591855
Validation loss: 4.415413240798169

Epoch: 6| Step: 10
Training loss: 4.361054346534532
Validation loss: 4.410745009842416

Epoch: 6| Step: 11
Training loss: 4.9134507518663115
Validation loss: 4.405838696918045

Epoch: 6| Step: 12
Training loss: 3.6185637589198514
Validation loss: 4.401586747884174

Epoch: 6| Step: 13
Training loss: 3.8471846702998462
Validation loss: 4.397156713552941

Epoch: 22| Step: 0
Training loss: 4.1052062497847155
Validation loss: 4.392664154146577

Epoch: 6| Step: 1
Training loss: 4.322042329297601
Validation loss: 4.388104132551185

Epoch: 6| Step: 2
Training loss: 4.196549160508832
Validation loss: 4.383443187502251

Epoch: 6| Step: 3
Training loss: 4.247981096832689
Validation loss: 4.379287707648945

Epoch: 6| Step: 4
Training loss: 4.515394792331589
Validation loss: 4.375732215280146

Epoch: 6| Step: 5
Training loss: 4.054809568475033
Validation loss: 4.371474889479589

Epoch: 6| Step: 6
Training loss: 4.364258140278853
Validation loss: 4.366174442756178

Epoch: 6| Step: 7
Training loss: 4.839574576983151
Validation loss: 4.361940638433701

Epoch: 6| Step: 8
Training loss: 5.219085134378685
Validation loss: 4.357036277709271

Epoch: 6| Step: 9
Training loss: 4.877052070857504
Validation loss: 4.352816717729258

Epoch: 6| Step: 10
Training loss: 4.227403144651822
Validation loss: 4.348533174058752

Epoch: 6| Step: 11
Training loss: 4.5638985776472705
Validation loss: 4.343666679626079

Epoch: 6| Step: 12
Training loss: 4.96634063845385
Validation loss: 4.339275186665342

Epoch: 6| Step: 13
Training loss: 4.220359664704288
Validation loss: 4.335347068383179

Epoch: 23| Step: 0
Training loss: 5.089430586586157
Validation loss: 4.330357826019368

Epoch: 6| Step: 1
Training loss: 3.9504451790566506
Validation loss: 4.325401027366872

Epoch: 6| Step: 2
Training loss: 3.7540890334581
Validation loss: 4.320378354187478

Epoch: 6| Step: 3
Training loss: 4.549587214263557
Validation loss: 4.315680561080923

Epoch: 6| Step: 4
Training loss: 3.991924359333128
Validation loss: 4.310964227962008

Epoch: 6| Step: 5
Training loss: 4.622961677697742
Validation loss: 4.306371397568961

Epoch: 6| Step: 6
Training loss: 4.680854664548452
Validation loss: 4.302186436683832

Epoch: 6| Step: 7
Training loss: 4.18288907938222
Validation loss: 4.296986563419116

Epoch: 6| Step: 8
Training loss: 4.037999852657079
Validation loss: 4.2929083623506195

Epoch: 6| Step: 9
Training loss: 3.959960335426896
Validation loss: 4.28882745076736

Epoch: 6| Step: 10
Training loss: 4.009887871827454
Validation loss: 4.283885692105536

Epoch: 6| Step: 11
Training loss: 5.059096711241188
Validation loss: 4.279708751947422

Epoch: 6| Step: 12
Training loss: 4.909580728067829
Validation loss: 4.274806870825541

Epoch: 6| Step: 13
Training loss: 4.9003775859855425
Validation loss: 4.270234129514917

Epoch: 24| Step: 0
Training loss: 4.893786691111555
Validation loss: 4.26582902320266

Epoch: 6| Step: 1
Training loss: 4.024025290802187
Validation loss: 4.2616223383510015

Epoch: 6| Step: 2
Training loss: 4.841955627817939
Validation loss: 4.256712679891846

Epoch: 6| Step: 3
Training loss: 3.6435796838545547
Validation loss: 4.251589029237075

Epoch: 6| Step: 4
Training loss: 4.154471798591605
Validation loss: 4.247179104974435

Epoch: 6| Step: 5
Training loss: 4.883816693614347
Validation loss: 4.242635179927506

Epoch: 6| Step: 6
Training loss: 4.336341302987588
Validation loss: 4.238562677418378

Epoch: 6| Step: 7
Training loss: 4.447747446931376
Validation loss: 4.2334900854530835

Epoch: 6| Step: 8
Training loss: 4.322230542743414
Validation loss: 4.228639253449194

Epoch: 6| Step: 9
Training loss: 4.2531997752571025
Validation loss: 4.224219537161919

Epoch: 6| Step: 10
Training loss: 4.063192689968743
Validation loss: 4.2196952231874505

Epoch: 6| Step: 11
Training loss: 4.25559853204773
Validation loss: 4.215435053771546

Epoch: 6| Step: 12
Training loss: 4.979334851008885
Validation loss: 4.210416536301289

Epoch: 6| Step: 13
Training loss: 3.7849350304614813
Validation loss: 4.206048527767624

Epoch: 25| Step: 0
Training loss: 4.646661294051959
Validation loss: 4.201687497262995

Epoch: 6| Step: 1
Training loss: 3.8618792235633337
Validation loss: 4.197047115914325

Epoch: 6| Step: 2
Training loss: 4.140663693805053
Validation loss: 4.192577396346436

Epoch: 6| Step: 3
Training loss: 4.01301175000324
Validation loss: 4.187942481504916

Epoch: 6| Step: 4
Training loss: 4.0810606464197345
Validation loss: 4.183776433561256

Epoch: 6| Step: 5
Training loss: 4.136278397389723
Validation loss: 4.179131320538933

Epoch: 6| Step: 6
Training loss: 4.108247435460381
Validation loss: 4.174366467771736

Epoch: 6| Step: 7
Training loss: 4.689390691288367
Validation loss: 4.170226972914713

Epoch: 6| Step: 8
Training loss: 4.871869769530948
Validation loss: 4.166240759380633

Epoch: 6| Step: 9
Training loss: 3.917204610256932
Validation loss: 4.161383038135249

Epoch: 6| Step: 10
Training loss: 4.084753036224266
Validation loss: 4.156634090717071

Epoch: 6| Step: 11
Training loss: 4.603184360761067
Validation loss: 4.152050487632755

Epoch: 6| Step: 12
Training loss: 4.44500763556701
Validation loss: 4.147019406726675

Epoch: 6| Step: 13
Training loss: 4.496096295340287
Validation loss: 4.14284781046225

Epoch: 26| Step: 0
Training loss: 4.68351433744707
Validation loss: 4.138024661632741

Epoch: 6| Step: 1
Training loss: 4.947044322428916
Validation loss: 4.133272968641044

Epoch: 6| Step: 2
Training loss: 4.008655005942147
Validation loss: 4.128717192595432

Epoch: 6| Step: 3
Training loss: 3.5886075586360655
Validation loss: 4.123663059477158

Epoch: 6| Step: 4
Training loss: 4.531756142596588
Validation loss: 4.119050851117648

Epoch: 6| Step: 5
Training loss: 5.038723341299486
Validation loss: 4.113953972821867

Epoch: 6| Step: 6
Training loss: 4.294629873330339
Validation loss: 4.108819089934753

Epoch: 6| Step: 7
Training loss: 3.4203404160114483
Validation loss: 4.104426316053333

Epoch: 6| Step: 8
Training loss: 3.3248101144363273
Validation loss: 4.099509906940297

Epoch: 6| Step: 9
Training loss: 4.267182788825324
Validation loss: 4.0955210147865415

Epoch: 6| Step: 10
Training loss: 4.071443777605691
Validation loss: 4.090748489804521

Epoch: 6| Step: 11
Training loss: 4.238663307232609
Validation loss: 4.086057818010713

Epoch: 6| Step: 12
Training loss: 4.131734956333677
Validation loss: 4.081423150479282

Epoch: 6| Step: 13
Training loss: 4.4138794987645795
Validation loss: 4.077073157675781

Epoch: 27| Step: 0
Training loss: 4.1664290296817725
Validation loss: 4.0726420057067045

Epoch: 6| Step: 1
Training loss: 3.943524066722471
Validation loss: 4.06797665904828

Epoch: 6| Step: 2
Training loss: 4.2237546270367154
Validation loss: 4.063181169574734

Epoch: 6| Step: 3
Training loss: 4.5043064280425105
Validation loss: 4.058549809149166

Epoch: 6| Step: 4
Training loss: 3.7821298631696774
Validation loss: 4.05402076252164

Epoch: 6| Step: 5
Training loss: 4.2566866164809145
Validation loss: 4.049225349281052

Epoch: 6| Step: 6
Training loss: 4.769755990047064
Validation loss: 4.044940579437278

Epoch: 6| Step: 7
Training loss: 4.281695934377275
Validation loss: 4.040072188849767

Epoch: 6| Step: 8
Training loss: 4.026186106049604
Validation loss: 4.035216201479658

Epoch: 6| Step: 9
Training loss: 3.508755223753125
Validation loss: 4.030373924142043

Epoch: 6| Step: 10
Training loss: 4.397076086070089
Validation loss: 4.025755220251697

Epoch: 6| Step: 11
Training loss: 4.295885450686496
Validation loss: 4.020840277525814

Epoch: 6| Step: 12
Training loss: 4.016102803225313
Validation loss: 4.016044109950795

Epoch: 6| Step: 13
Training loss: 4.13510281823594
Validation loss: 4.011281257999746

Epoch: 28| Step: 0
Training loss: 4.510289614020784
Validation loss: 4.006539443138917

Epoch: 6| Step: 1
Training loss: 4.298710989146967
Validation loss: 4.001544912335107

Epoch: 6| Step: 2
Training loss: 4.234428827710798
Validation loss: 3.9969850542407657

Epoch: 6| Step: 3
Training loss: 3.2528668010751853
Validation loss: 3.9921927952840166

Epoch: 6| Step: 4
Training loss: 3.9056629197502954
Validation loss: 3.9872361824353835

Epoch: 6| Step: 5
Training loss: 4.767009996618564
Validation loss: 3.9829011073431952

Epoch: 6| Step: 6
Training loss: 4.37224034056948
Validation loss: 3.9785063164036703

Epoch: 6| Step: 7
Training loss: 3.7312343271204282
Validation loss: 3.9735039500806537

Epoch: 6| Step: 8
Training loss: 4.159885737977348
Validation loss: 3.9690754674386257

Epoch: 6| Step: 9
Training loss: 2.9168157993518604
Validation loss: 3.964287820060233

Epoch: 6| Step: 10
Training loss: 4.819618607939946
Validation loss: 3.9600914848562

Epoch: 6| Step: 11
Training loss: 4.1890260563211
Validation loss: 3.955613560480469

Epoch: 6| Step: 12
Training loss: 3.4091277958579393
Validation loss: 3.950704041844844

Epoch: 6| Step: 13
Training loss: 4.473778516407265
Validation loss: 3.945854205217651

Epoch: 29| Step: 0
Training loss: 4.590850537851202
Validation loss: 3.9411002356323586

Epoch: 6| Step: 1
Training loss: 4.255711700412325
Validation loss: 3.936357766440115

Epoch: 6| Step: 2
Training loss: 4.699614066653589
Validation loss: 3.9322366605368257

Epoch: 6| Step: 3
Training loss: 4.305920654458825
Validation loss: 3.9275763056364266

Epoch: 6| Step: 4
Training loss: 3.2562767452379027
Validation loss: 3.922073764500944

Epoch: 6| Step: 5
Training loss: 4.054257996730442
Validation loss: 3.917630394942452

Epoch: 6| Step: 6
Training loss: 3.378306711622402
Validation loss: 3.912593279001852

Epoch: 6| Step: 7
Training loss: 3.8328093847922267
Validation loss: 3.908094880910057

Epoch: 6| Step: 8
Training loss: 3.3241493226812815
Validation loss: 3.9037193747785044

Epoch: 6| Step: 9
Training loss: 4.581315214725973
Validation loss: 3.8992059698132993

Epoch: 6| Step: 10
Training loss: 4.1015499441772105
Validation loss: 3.8946146291303374

Epoch: 6| Step: 11
Training loss: 4.029541363235084
Validation loss: 3.890023998327031

Epoch: 6| Step: 12
Training loss: 3.535286545855047
Validation loss: 3.8850868773759895

Epoch: 6| Step: 13
Training loss: 4.309611362008497
Validation loss: 3.880856671881922

Epoch: 30| Step: 0
Training loss: 3.613448845353065
Validation loss: 3.875835246646999

Epoch: 6| Step: 1
Training loss: 4.420048744312624
Validation loss: 3.8715102981758203

Epoch: 6| Step: 2
Training loss: 3.95052822299267
Validation loss: 3.8666481541047935

Epoch: 6| Step: 3
Training loss: 4.526920328425508
Validation loss: 3.861893494938272

Epoch: 6| Step: 4
Training loss: 4.195854620830601
Validation loss: 3.8574645839210024

Epoch: 6| Step: 5
Training loss: 4.770533301013024
Validation loss: 3.852678344942097

Epoch: 6| Step: 6
Training loss: 3.7230953185784412
Validation loss: 3.8481610013876115

Epoch: 6| Step: 7
Training loss: 3.9128697570993785
Validation loss: 3.842819969738918

Epoch: 6| Step: 8
Training loss: 2.9072959412384227
Validation loss: 3.837774288882984

Epoch: 6| Step: 9
Training loss: 3.891771875194157
Validation loss: 3.8333220827241634

Epoch: 6| Step: 10
Training loss: 4.224558582609017
Validation loss: 3.828980683689871

Epoch: 6| Step: 11
Training loss: 3.951467415301801
Validation loss: 3.824167294751934

Epoch: 6| Step: 12
Training loss: 3.079926249376618
Validation loss: 3.822480442753042

Epoch: 6| Step: 13
Training loss: 4.150545493434135
Validation loss: 3.817860696136644

Epoch: 31| Step: 0
Training loss: 4.475327992273609
Validation loss: 3.8112947820724736

Epoch: 6| Step: 1
Training loss: 3.581096631239569
Validation loss: 3.8061102179055095

Epoch: 6| Step: 2
Training loss: 3.688252129871077
Validation loss: 3.8017542169689307

Epoch: 6| Step: 3
Training loss: 3.3870435512773542
Validation loss: 3.797900340089984

Epoch: 6| Step: 4
Training loss: 5.0326293570905465
Validation loss: 3.7927230299647703

Epoch: 6| Step: 5
Training loss: 4.841244744953718
Validation loss: 3.7878203253424836

Epoch: 6| Step: 6
Training loss: 4.067623253134852
Validation loss: 3.7825412069438977

Epoch: 6| Step: 7
Training loss: 2.8379827013194214
Validation loss: 3.7779895818151688

Epoch: 6| Step: 8
Training loss: 4.5220723834717
Validation loss: 3.773834123426695

Epoch: 6| Step: 9
Training loss: 1.8611013268297396
Validation loss: 3.7689406279795254

Epoch: 6| Step: 10
Training loss: 3.493429010211836
Validation loss: 3.764700347370983

Epoch: 6| Step: 11
Training loss: 4.294221481801518
Validation loss: 3.7603699671556887

Epoch: 6| Step: 12
Training loss: 3.7436444148234314
Validation loss: 3.7556212890830127

Epoch: 6| Step: 13
Training loss: 3.8901505391624873
Validation loss: 3.7510394033425003

Epoch: 32| Step: 0
Training loss: 3.308344844026183
Validation loss: 3.7462991890845747

Epoch: 6| Step: 1
Training loss: 4.198573033566104
Validation loss: 3.742182084559462

Epoch: 6| Step: 2
Training loss: 4.258511715093419
Validation loss: 3.737398697789004

Epoch: 6| Step: 3
Training loss: 3.8031564252020535
Validation loss: 3.732893390505597

Epoch: 6| Step: 4
Training loss: 4.313027169997961
Validation loss: 3.7278706235988803

Epoch: 6| Step: 5
Training loss: 4.239684882420117
Validation loss: 3.723395771492334

Epoch: 6| Step: 6
Training loss: 3.9989098016898033
Validation loss: 3.7183377975124734

Epoch: 6| Step: 7
Training loss: 4.083246865946476
Validation loss: 3.712887307288814

Epoch: 6| Step: 8
Training loss: 2.7334234707399157
Validation loss: 3.707805310207662

Epoch: 6| Step: 9
Training loss: 4.070260953668331
Validation loss: 3.703017135315376

Epoch: 6| Step: 10
Training loss: 3.258200350207876
Validation loss: 3.6976478084916784

Epoch: 6| Step: 11
Training loss: 3.2163657830069106
Validation loss: 3.693753322851555

Epoch: 6| Step: 12
Training loss: 3.7947762422599833
Validation loss: 3.6887392020080947

Epoch: 6| Step: 13
Training loss: 4.25208949166948
Validation loss: 3.6843762070705344

Epoch: 33| Step: 0
Training loss: 3.806466753821609
Validation loss: 3.680493546609326

Epoch: 6| Step: 1
Training loss: 4.04711418476021
Validation loss: 3.6758315825791485

Epoch: 6| Step: 2
Training loss: 3.597519730122152
Validation loss: 3.6708043695202752

Epoch: 6| Step: 3
Training loss: 4.314777160053341
Validation loss: 3.666789652466887

Epoch: 6| Step: 4
Training loss: 4.008051874399938
Validation loss: 3.6621881284934825

Epoch: 6| Step: 5
Training loss: 4.001975287045151
Validation loss: 3.657704034321761

Epoch: 6| Step: 6
Training loss: 3.9638350683519463
Validation loss: 3.6529488291817893

Epoch: 6| Step: 7
Training loss: 3.4433693455612877
Validation loss: 3.648978433527331

Epoch: 6| Step: 8
Training loss: 3.2021593080308777
Validation loss: 3.6443443454846

Epoch: 6| Step: 9
Training loss: 3.9554115889516095
Validation loss: 3.639652346018774

Epoch: 6| Step: 10
Training loss: 2.759981420979647
Validation loss: 3.635537015276421

Epoch: 6| Step: 11
Training loss: 4.502088697795976
Validation loss: 3.630742949968215

Epoch: 6| Step: 12
Training loss: 3.4035055320832646
Validation loss: 3.626702599405878

Epoch: 6| Step: 13
Training loss: 3.690074732987691
Validation loss: 3.622628675044215

Epoch: 34| Step: 0
Training loss: 4.316658999952973
Validation loss: 3.6178275654999092

Epoch: 6| Step: 1
Training loss: 3.6932576375794666
Validation loss: 3.613533827743026

Epoch: 6| Step: 2
Training loss: 3.4313132358414813
Validation loss: 3.608889702653036

Epoch: 6| Step: 3
Training loss: 4.19515792022016
Validation loss: 3.6048915479539416

Epoch: 6| Step: 4
Training loss: 3.4437783906462154
Validation loss: 3.5999433804404077

Epoch: 6| Step: 5
Training loss: 3.0284530477702356
Validation loss: 3.5958064290819722

Epoch: 6| Step: 6
Training loss: 3.2546558775993195
Validation loss: 3.5914695691566685

Epoch: 6| Step: 7
Training loss: 3.9291268587708457
Validation loss: 3.5872716035700374

Epoch: 6| Step: 8
Training loss: 3.900645882358529
Validation loss: 3.5831725764624576

Epoch: 6| Step: 9
Training loss: 3.6533868779019922
Validation loss: 3.5790736954988915

Epoch: 6| Step: 10
Training loss: 3.7452009646757416
Validation loss: 3.574890318212825

Epoch: 6| Step: 11
Training loss: 3.828122508768322
Validation loss: 3.5706069123731288

Epoch: 6| Step: 12
Training loss: 3.746665743853726
Validation loss: 3.566150289809169

Epoch: 6| Step: 13
Training loss: 3.8190882306691023
Validation loss: 3.5618043633064795

Epoch: 35| Step: 0
Training loss: 3.833697813093664
Validation loss: 3.557522760185731

Epoch: 6| Step: 1
Training loss: 3.8427524667868074
Validation loss: 3.5534817729264385

Epoch: 6| Step: 2
Training loss: 3.452602847568001
Validation loss: 3.548898061127243

Epoch: 6| Step: 3
Training loss: 4.453788841692735
Validation loss: 3.5448437222359583

Epoch: 6| Step: 4
Training loss: 3.57650146965595
Validation loss: 3.539811235484937

Epoch: 6| Step: 5
Training loss: 3.9610248984902836
Validation loss: 3.535412588362551

Epoch: 6| Step: 6
Training loss: 4.074981764302085
Validation loss: 3.5308455063951643

Epoch: 6| Step: 7
Training loss: 3.563415142103932
Validation loss: 3.526002073230015

Epoch: 6| Step: 8
Training loss: 3.6655005132247864
Validation loss: 3.5212788873637932

Epoch: 6| Step: 9
Training loss: 3.297663589827253
Validation loss: 3.51687093626603

Epoch: 6| Step: 10
Training loss: 2.7211498323718386
Validation loss: 3.512083086315573

Epoch: 6| Step: 11
Training loss: 3.5996774634939896
Validation loss: 3.507993561759443

Epoch: 6| Step: 12
Training loss: 3.4624879692226687
Validation loss: 3.5036525967636973

Epoch: 6| Step: 13
Training loss: 3.577624689964168
Validation loss: 3.4996147511401166

Epoch: 36| Step: 0
Training loss: 4.091248191882047
Validation loss: 3.4954741143743386

Epoch: 6| Step: 1
Training loss: 3.934392520298932
Validation loss: 3.491501230828818

Epoch: 6| Step: 2
Training loss: 3.53111604419596
Validation loss: 3.486965260134889

Epoch: 6| Step: 3
Training loss: 3.5755091271297963
Validation loss: 3.4830239589019354

Epoch: 6| Step: 4
Training loss: 3.180242466589815
Validation loss: 3.47880553847845

Epoch: 6| Step: 5
Training loss: 3.096508299272091
Validation loss: 3.4748131855027076

Epoch: 6| Step: 6
Training loss: 3.4995460215830474
Validation loss: 3.4707587213880875

Epoch: 6| Step: 7
Training loss: 3.119167072181631
Validation loss: 3.467090817020755

Epoch: 6| Step: 8
Training loss: 3.6771440077720703
Validation loss: 3.463054311017446

Epoch: 6| Step: 9
Training loss: 4.41760349534562
Validation loss: 3.459256431985121

Epoch: 6| Step: 10
Training loss: 4.258841797892082
Validation loss: 3.4550867276455697

Epoch: 6| Step: 11
Training loss: 2.313632378538133
Validation loss: 3.4509293147684965

Epoch: 6| Step: 12
Training loss: 3.919644393945424
Validation loss: 3.447247712086073

Epoch: 6| Step: 13
Training loss: 3.3729562576040695
Validation loss: 3.4434276681504574

Epoch: 37| Step: 0
Training loss: 3.675092869837266
Validation loss: 3.439254336196766

Epoch: 6| Step: 1
Training loss: 3.5574777907256636
Validation loss: 3.4351252589368824

Epoch: 6| Step: 2
Training loss: 3.5231706133331517
Validation loss: 3.430987622177847

Epoch: 6| Step: 3
Training loss: 3.8777176955874912
Validation loss: 3.4274371272765776

Epoch: 6| Step: 4
Training loss: 3.244183103132872
Validation loss: 3.423554076742146

Epoch: 6| Step: 5
Training loss: 2.935826900524578
Validation loss: 3.42003116255128

Epoch: 6| Step: 6
Training loss: 3.2687376237273917
Validation loss: 3.4166669302839474

Epoch: 6| Step: 7
Training loss: 3.642691750070977
Validation loss: 3.4130738526923037

Epoch: 6| Step: 8
Training loss: 3.859287523521535
Validation loss: 3.409280974166458

Epoch: 6| Step: 9
Training loss: 3.9110317412424385
Validation loss: 3.405835584343102

Epoch: 6| Step: 10
Training loss: 3.0632804343298616
Validation loss: 3.401844360280862

Epoch: 6| Step: 11
Training loss: 3.723864716462411
Validation loss: 3.3981659762482384

Epoch: 6| Step: 12
Training loss: 3.4119293741874785
Validation loss: 3.394384687542517

Epoch: 6| Step: 13
Training loss: 3.8686452872999038
Validation loss: 3.3907127779191435

Epoch: 38| Step: 0
Training loss: 3.673620709937731
Validation loss: 3.3867013850898053

Epoch: 6| Step: 1
Training loss: 2.9313434447662927
Validation loss: 3.382673723224241

Epoch: 6| Step: 2
Training loss: 3.8668553065181857
Validation loss: 3.378961757431837

Epoch: 6| Step: 3
Training loss: 2.9894340734847984
Validation loss: 3.3749136148394046

Epoch: 6| Step: 4
Training loss: 3.5269291191538916
Validation loss: 3.3708415845118487

Epoch: 6| Step: 5
Training loss: 3.543404515563117
Validation loss: 3.3671651250887975

Epoch: 6| Step: 6
Training loss: 3.5611336748185622
Validation loss: 3.363514961868337

Epoch: 6| Step: 7
Training loss: 3.540656196207654
Validation loss: 3.359734709651078

Epoch: 6| Step: 8
Training loss: 4.137128858256573
Validation loss: 3.3559310292669022

Epoch: 6| Step: 9
Training loss: 3.458407818708333
Validation loss: 3.3521803113819346

Epoch: 6| Step: 10
Training loss: 3.3025435037801323
Validation loss: 3.3483105987744137

Epoch: 6| Step: 11
Training loss: 3.6747822392102685
Validation loss: 3.3445323611124476

Epoch: 6| Step: 12
Training loss: 3.310421849593436
Validation loss: 3.3407726163636458

Epoch: 6| Step: 13
Training loss: 3.326880710445694
Validation loss: 3.3369536925446446

Epoch: 39| Step: 0
Training loss: 3.0275883532735164
Validation loss: 3.333399907083095

Epoch: 6| Step: 1
Training loss: 3.6538251351126476
Validation loss: 3.329852973433915

Epoch: 6| Step: 2
Training loss: 3.343306752711245
Validation loss: 3.326362764171426

Epoch: 6| Step: 3
Training loss: 3.573858791215162
Validation loss: 3.32252024535093

Epoch: 6| Step: 4
Training loss: 3.295864727836872
Validation loss: 3.318880222541106

Epoch: 6| Step: 5
Training loss: 3.755928947451054
Validation loss: 3.315413051857503

Epoch: 6| Step: 6
Training loss: 4.023514533925771
Validation loss: 3.3119926064035567

Epoch: 6| Step: 7
Training loss: 3.4655306886682684
Validation loss: 3.3078878310942774

Epoch: 6| Step: 8
Training loss: 2.654987169655009
Validation loss: 3.304093989229987

Epoch: 6| Step: 9
Training loss: 3.293686323618063
Validation loss: 3.3005622866383435

Epoch: 6| Step: 10
Training loss: 3.7519475330189977
Validation loss: 3.296643120926207

Epoch: 6| Step: 11
Training loss: 3.266672358864736
Validation loss: 3.2931205620997925

Epoch: 6| Step: 12
Training loss: 3.378101760262048
Validation loss: 3.2895096499835965

Epoch: 6| Step: 13
Training loss: 3.60669797233867
Validation loss: 3.2858825437140626

Epoch: 40| Step: 0
Training loss: 3.78213074570408
Validation loss: 3.28232022951693

Epoch: 6| Step: 1
Training loss: 3.384705328913319
Validation loss: 3.2787159656460276

Epoch: 6| Step: 2
Training loss: 2.9401982677843064
Validation loss: 3.275241812788913

Epoch: 6| Step: 3
Training loss: 3.074273037461426
Validation loss: 3.2719190136105727

Epoch: 6| Step: 4
Training loss: 3.9692442578704696
Validation loss: 3.2687594202706993

Epoch: 6| Step: 5
Training loss: 3.137751996988368
Validation loss: 3.2653600655247192

Epoch: 6| Step: 6
Training loss: 4.1869208091898225
Validation loss: 3.261983870583548

Epoch: 6| Step: 7
Training loss: 3.251746808629799
Validation loss: 3.2584898173682513

Epoch: 6| Step: 8
Training loss: 2.3807424089398266
Validation loss: 3.2548074378789478

Epoch: 6| Step: 9
Training loss: 3.782613713281631
Validation loss: 3.251742580498128

Epoch: 6| Step: 10
Training loss: 3.45416409837898
Validation loss: 3.248144732859361

Epoch: 6| Step: 11
Training loss: 3.0164964434683212
Validation loss: 3.244878229953123

Epoch: 6| Step: 12
Training loss: 3.6101781438689073
Validation loss: 3.2415214007532858

Epoch: 6| Step: 13
Training loss: 3.213225428984201
Validation loss: 3.2383091046861296

Epoch: 41| Step: 0
Training loss: 3.5552165214175293
Validation loss: 3.234789737273273

Epoch: 6| Step: 1
Training loss: 3.3254700579410135
Validation loss: 3.231103750887619

Epoch: 6| Step: 2
Training loss: 3.1561445464089806
Validation loss: 3.2279157779394145

Epoch: 6| Step: 3
Training loss: 2.5562035031741686
Validation loss: 3.2245751418960054

Epoch: 6| Step: 4
Training loss: 3.49107872345803
Validation loss: 3.221190308350989

Epoch: 6| Step: 5
Training loss: 3.066046082550337
Validation loss: 3.218091977705019

Epoch: 6| Step: 6
Training loss: 3.8329569313899974
Validation loss: 3.214914079331788

Epoch: 6| Step: 7
Training loss: 3.4569254541103254
Validation loss: 3.2116483843497012

Epoch: 6| Step: 8
Training loss: 3.033813336579239
Validation loss: 3.2086014862623653

Epoch: 6| Step: 9
Training loss: 3.411201168394336
Validation loss: 3.2053806457386504

Epoch: 6| Step: 10
Training loss: 3.5953389511229554
Validation loss: 3.201827281045544

Epoch: 6| Step: 11
Training loss: 3.23825945691551
Validation loss: 3.1985052646054757

Epoch: 6| Step: 12
Training loss: 3.3711254343818085
Validation loss: 3.1952797189288575

Epoch: 6| Step: 13
Training loss: 3.6734851959000827
Validation loss: 3.191998716632964

Epoch: 42| Step: 0
Training loss: 3.173866436066852
Validation loss: 3.1887195099305425

Epoch: 6| Step: 1
Training loss: 2.869262609621788
Validation loss: 3.1857148201628585

Epoch: 6| Step: 2
Training loss: 3.7805176333069297
Validation loss: 3.1824120198584924

Epoch: 6| Step: 3
Training loss: 3.0905143694849833
Validation loss: 3.1792346653763577

Epoch: 6| Step: 4
Training loss: 3.41430914574955
Validation loss: 3.1759951786497918

Epoch: 6| Step: 5
Training loss: 3.303656234536398
Validation loss: 3.1727210484043114

Epoch: 6| Step: 6
Training loss: 4.105565383020688
Validation loss: 3.1697011429297097

Epoch: 6| Step: 7
Training loss: 3.6568336999021755
Validation loss: 3.166419086482046

Epoch: 6| Step: 8
Training loss: 3.367766788509066
Validation loss: 3.1629095166699726

Epoch: 6| Step: 9
Training loss: 3.1766486865959473
Validation loss: 3.15957650115267

Epoch: 6| Step: 10
Training loss: 2.82548323692705
Validation loss: 3.156342130518694

Epoch: 6| Step: 11
Training loss: 3.15475216818624
Validation loss: 3.1531596776380506

Epoch: 6| Step: 12
Training loss: 2.6679481963543026
Validation loss: 3.149930273525609

Epoch: 6| Step: 13
Training loss: 3.464609234946837
Validation loss: 3.146824122815974

Epoch: 43| Step: 0
Training loss: 3.462950110529688
Validation loss: 3.1438375209307305

Epoch: 6| Step: 1
Training loss: 3.3590053621131775
Validation loss: 3.140627872092482

Epoch: 6| Step: 2
Training loss: 3.2555071314688337
Validation loss: 3.1375827003309436

Epoch: 6| Step: 3
Training loss: 4.1836835636076
Validation loss: 3.1345054637345915

Epoch: 6| Step: 4
Training loss: 2.7374903778882516
Validation loss: 3.131226465539059

Epoch: 6| Step: 5
Training loss: 3.226874015493204
Validation loss: 3.1278428942909478

Epoch: 6| Step: 6
Training loss: 3.1363140524461657
Validation loss: 3.1247200776932664

Epoch: 6| Step: 7
Training loss: 3.2929043113041963
Validation loss: 3.121777207806583

Epoch: 6| Step: 8
Training loss: 3.1167384997842853
Validation loss: 3.1187613839328403

Epoch: 6| Step: 9
Training loss: 2.5873975060844803
Validation loss: 3.1157714380804493

Epoch: 6| Step: 10
Training loss: 3.1455131182526657
Validation loss: 3.112997529532611

Epoch: 6| Step: 11
Training loss: 2.9338998038066766
Validation loss: 3.110260011612145

Epoch: 6| Step: 12
Training loss: 3.620912154334421
Validation loss: 3.1074643295012607

Epoch: 6| Step: 13
Training loss: 3.3932161757873605
Validation loss: 3.104832895628002

Epoch: 44| Step: 0
Training loss: 2.987748880274584
Validation loss: 3.1019519013759234

Epoch: 6| Step: 1
Training loss: 2.918514665350797
Validation loss: 3.0991824969258106

Epoch: 6| Step: 2
Training loss: 3.200247909956456
Validation loss: 3.0964926562233215

Epoch: 6| Step: 3
Training loss: 3.6402933518132654
Validation loss: 3.093810931803432

Epoch: 6| Step: 4
Training loss: 3.176935978374975
Validation loss: 3.091208766092023

Epoch: 6| Step: 5
Training loss: 3.061365968587867
Validation loss: 3.088249801731672

Epoch: 6| Step: 6
Training loss: 2.7799822886335024
Validation loss: 3.0856187615586834

Epoch: 6| Step: 7
Training loss: 3.6506672810994485
Validation loss: 3.0831572422228812

Epoch: 6| Step: 8
Training loss: 3.705821540344245
Validation loss: 3.080226355198831

Epoch: 6| Step: 9
Training loss: 3.0430568148561377
Validation loss: 3.0774444757282278

Epoch: 6| Step: 10
Training loss: 2.708338830404327
Validation loss: 3.0745466962986177

Epoch: 6| Step: 11
Training loss: 3.2873559724421053
Validation loss: 3.0719232063223503

Epoch: 6| Step: 12
Training loss: 3.0311911665722544
Validation loss: 3.0689879351722964

Epoch: 6| Step: 13
Training loss: 3.7335062333214992
Validation loss: 3.066344022018205

Epoch: 45| Step: 0
Training loss: 3.186786945844985
Validation loss: 3.063483203657396

Epoch: 6| Step: 1
Training loss: 3.505647190654216
Validation loss: 3.0605449015163284

Epoch: 6| Step: 2
Training loss: 3.225502412680695
Validation loss: 3.0577505223343415

Epoch: 6| Step: 3
Training loss: 3.2542353689159778
Validation loss: 3.0548930769719185

Epoch: 6| Step: 4
Training loss: 3.4506625548234564
Validation loss: 3.0518252336302476

Epoch: 6| Step: 5
Training loss: 3.0150082604847066
Validation loss: 3.049230489953393

Epoch: 6| Step: 6
Training loss: 3.156797758104134
Validation loss: 3.0463879579098365

Epoch: 6| Step: 7
Training loss: 3.606342313170055
Validation loss: 3.043548541807524

Epoch: 6| Step: 8
Training loss: 2.600778639182754
Validation loss: 3.040640884467699

Epoch: 6| Step: 9
Training loss: 3.618280167460676
Validation loss: 3.0378648609443766

Epoch: 6| Step: 10
Training loss: 3.289187902384104
Validation loss: 3.0349614863541774

Epoch: 6| Step: 11
Training loss: 2.824155265970445
Validation loss: 3.032188728985155

Epoch: 6| Step: 12
Training loss: 2.502417921002601
Validation loss: 3.0294973937092284

Epoch: 6| Step: 13
Training loss: 3.184771248643922
Validation loss: 3.026665501244218

Epoch: 46| Step: 0
Training loss: 2.7937379431411045
Validation loss: 3.024326519042474

Epoch: 6| Step: 1
Training loss: 2.8327666071158464
Validation loss: 3.02141785502184

Epoch: 6| Step: 2
Training loss: 3.6194670973061
Validation loss: 3.0186289187119493

Epoch: 6| Step: 3
Training loss: 3.1671913783045444
Validation loss: 3.0157583994505606

Epoch: 6| Step: 4
Training loss: 3.4486571531943153
Validation loss: 3.012889154711552

Epoch: 6| Step: 5
Training loss: 2.9587224964044836
Validation loss: 3.0098373137197654

Epoch: 6| Step: 6
Training loss: 2.6920291971434307
Validation loss: 3.0069166822867364

Epoch: 6| Step: 7
Training loss: 3.2267226948353085
Validation loss: 3.0040869424922727

Epoch: 6| Step: 8
Training loss: 3.128120085477065
Validation loss: 3.0013095196392534

Epoch: 6| Step: 9
Training loss: 3.2176541435113655
Validation loss: 2.9986783931271646

Epoch: 6| Step: 10
Training loss: 3.718826934275087
Validation loss: 2.9959488377347125

Epoch: 6| Step: 11
Training loss: 3.3990003799299098
Validation loss: 2.993669041844367

Epoch: 6| Step: 12
Training loss: 2.847767601400169
Validation loss: 2.9910898344968846

Epoch: 6| Step: 13
Training loss: 2.8511768655123126
Validation loss: 2.9886305527993744

Epoch: 47| Step: 0
Training loss: 3.275258142911786
Validation loss: 2.986196923809508

Epoch: 6| Step: 1
Training loss: 3.032647194305159
Validation loss: 2.9841713428078958

Epoch: 6| Step: 2
Training loss: 3.6779449289170283
Validation loss: 2.9816147054029325

Epoch: 6| Step: 3
Training loss: 3.1576977421568952
Validation loss: 2.9790786561214726

Epoch: 6| Step: 4
Training loss: 3.2766624715577053
Validation loss: 2.9770412777563444

Epoch: 6| Step: 5
Training loss: 2.476941582099839
Validation loss: 2.9745704746854535

Epoch: 6| Step: 6
Training loss: 3.1938116377464696
Validation loss: 2.9722942945668773

Epoch: 6| Step: 7
Training loss: 3.190512038126433
Validation loss: 2.9703296942483277

Epoch: 6| Step: 8
Training loss: 3.017304422255484
Validation loss: 2.9679656749447334

Epoch: 6| Step: 9
Training loss: 3.5595900044465596
Validation loss: 2.9659560591910465

Epoch: 6| Step: 10
Training loss: 3.280251196569808
Validation loss: 2.963542104675225

Epoch: 6| Step: 11
Training loss: 3.0538584957453634
Validation loss: 2.9614686648877067

Epoch: 6| Step: 12
Training loss: 2.56769166106614
Validation loss: 2.9585445534606722

Epoch: 6| Step: 13
Training loss: 2.5946468962706475
Validation loss: 2.9581287653582256

Epoch: 48| Step: 0
Training loss: 2.683498597436307
Validation loss: 2.9545838320180327

Epoch: 6| Step: 1
Training loss: 3.498073865316728
Validation loss: 2.9523925276535232

Epoch: 6| Step: 2
Training loss: 3.2293626951378576
Validation loss: 2.9496116123890666

Epoch: 6| Step: 3
Training loss: 2.5741924463991874
Validation loss: 2.9471968905500505

Epoch: 6| Step: 4
Training loss: 2.877697881262937
Validation loss: 2.945275155529717

Epoch: 6| Step: 5
Training loss: 3.2419843862864752
Validation loss: 2.942706627409224

Epoch: 6| Step: 6
Training loss: 3.2402961821636818
Validation loss: 2.9401201642493504

Epoch: 6| Step: 7
Training loss: 3.2763130467769646
Validation loss: 2.9377746453639633

Epoch: 6| Step: 8
Training loss: 3.08320067524133
Validation loss: 2.9351716790577695

Epoch: 6| Step: 9
Training loss: 3.1976032579822946
Validation loss: 2.9328805705892846

Epoch: 6| Step: 10
Training loss: 2.8123270617403775
Validation loss: 2.9301717942815735

Epoch: 6| Step: 11
Training loss: 2.851097089855709
Validation loss: 2.928406078265167

Epoch: 6| Step: 12
Training loss: 2.861572921748949
Validation loss: 2.9262149694736745

Epoch: 6| Step: 13
Training loss: 3.562053987122842
Validation loss: 2.9243646985980205

Epoch: 49| Step: 0
Training loss: 3.0469635779392057
Validation loss: 2.9221600888137123

Epoch: 6| Step: 1
Training loss: 2.4012931201087553
Validation loss: 2.9204727724853883

Epoch: 6| Step: 2
Training loss: 2.2752923379389065
Validation loss: 2.918324984551787

Epoch: 6| Step: 3
Training loss: 3.580020052890984
Validation loss: 2.9163649857132086

Epoch: 6| Step: 4
Training loss: 2.9522942883360064
Validation loss: 2.9145406376781517

Epoch: 6| Step: 5
Training loss: 2.662143138914873
Validation loss: 2.9125386908148307

Epoch: 6| Step: 6
Training loss: 3.2919538026629698
Validation loss: 2.9103427357841984

Epoch: 6| Step: 7
Training loss: 2.9354164363589352
Validation loss: 2.9104745848637776

Epoch: 6| Step: 8
Training loss: 3.8786132947734124
Validation loss: 2.920102715819441

Epoch: 6| Step: 9
Training loss: 3.028576173033173
Validation loss: 2.904464296134301

Epoch: 6| Step: 10
Training loss: 2.863739684746962
Validation loss: 2.9026628869017053

Epoch: 6| Step: 11
Training loss: 3.284325312012644
Validation loss: 2.9013837182357176

Epoch: 6| Step: 12
Training loss: 2.7849962528278884
Validation loss: 2.900813524645603

Epoch: 6| Step: 13
Training loss: 3.3817810882517843
Validation loss: 2.9009874065993264

Epoch: 50| Step: 0
Training loss: 2.950238305504343
Validation loss: 2.896032632972329

Epoch: 6| Step: 1
Training loss: 2.671372126499512
Validation loss: 2.8933705942842747

Epoch: 6| Step: 2
Training loss: 2.8301151923469696
Validation loss: 2.8915357512448874

Epoch: 6| Step: 3
Training loss: 2.8779772394379104
Validation loss: 2.89191461612236

Epoch: 6| Step: 4
Training loss: 3.3269184056542263
Validation loss: 2.8955155113593896

Epoch: 6| Step: 5
Training loss: 2.437202044151472
Validation loss: 2.8886430974063795

Epoch: 6| Step: 6
Training loss: 3.5815732906542794
Validation loss: 2.8847952952889804

Epoch: 6| Step: 7
Training loss: 3.026500008429769
Validation loss: 2.8833546667099923

Epoch: 6| Step: 8
Training loss: 2.583303441110579
Validation loss: 2.882854719809084

Epoch: 6| Step: 9
Training loss: 2.878659448694412
Validation loss: 2.882942217464459

Epoch: 6| Step: 10
Training loss: 3.6948151525943516
Validation loss: 2.8829212667868935

Epoch: 6| Step: 11
Training loss: 3.669534659754643
Validation loss: 2.8801340756952474

Epoch: 6| Step: 12
Training loss: 2.828428810619628
Validation loss: 2.8751634468389478

Epoch: 6| Step: 13
Training loss: 2.6824961365230218
Validation loss: 2.872158028012099

Epoch: 51| Step: 0
Training loss: 2.8711782845229434
Validation loss: 2.8706071852226684

Epoch: 6| Step: 1
Training loss: 3.5875841403358413
Validation loss: 2.8686533272383063

Epoch: 6| Step: 2
Training loss: 3.3030154640420144
Validation loss: 2.8676337259557063

Epoch: 6| Step: 3
Training loss: 2.1804908721249925
Validation loss: 2.8656021849411473

Epoch: 6| Step: 4
Training loss: 2.63922361849866
Validation loss: 2.8651482504790047

Epoch: 6| Step: 5
Training loss: 2.6532091574469585
Validation loss: 2.860985085469935

Epoch: 6| Step: 6
Training loss: 3.2374826143600663
Validation loss: 2.859013505052281

Epoch: 6| Step: 7
Training loss: 3.2015050746073817
Validation loss: 2.85642322151358

Epoch: 6| Step: 8
Training loss: 2.9445268711412784
Validation loss: 2.853967761791726

Epoch: 6| Step: 9
Training loss: 3.3301648976048104
Validation loss: 2.8521976547419885

Epoch: 6| Step: 10
Training loss: 2.7790858389001922
Validation loss: 2.849920613594222

Epoch: 6| Step: 11
Training loss: 2.463027889773728
Validation loss: 2.8485937541960062

Epoch: 6| Step: 12
Training loss: 3.118051356648141
Validation loss: 2.8468572806551204

Epoch: 6| Step: 13
Training loss: 3.355377231544435
Validation loss: 2.846301335120481

Epoch: 52| Step: 0
Training loss: 2.7800215676383564
Validation loss: 2.843860386533002

Epoch: 6| Step: 1
Training loss: 3.7177323944575833
Validation loss: 2.8412611833344745

Epoch: 6| Step: 2
Training loss: 3.261177502342095
Validation loss: 2.8390057432316573

Epoch: 6| Step: 3
Training loss: 2.7910038365194536
Validation loss: 2.8367016395971034

Epoch: 6| Step: 4
Training loss: 2.661255910283626
Validation loss: 2.83464643026212

Epoch: 6| Step: 5
Training loss: 3.0745371710589455
Validation loss: 2.8325147895617673

Epoch: 6| Step: 6
Training loss: 3.201003847023947
Validation loss: 2.8307601215783857

Epoch: 6| Step: 7
Training loss: 2.3852206709077843
Validation loss: 2.828998788975618

Epoch: 6| Step: 8
Training loss: 2.912135246259157
Validation loss: 2.82756171755296

Epoch: 6| Step: 9
Training loss: 3.0808322832268957
Validation loss: 2.8256817093623114

Epoch: 6| Step: 10
Training loss: 3.089815662897785
Validation loss: 2.8240876156378634

Epoch: 6| Step: 11
Training loss: 2.273190409548114
Validation loss: 2.8230263570234584

Epoch: 6| Step: 12
Training loss: 3.3006986167541226
Validation loss: 2.821192441214279

Epoch: 6| Step: 13
Training loss: 2.819768795112792
Validation loss: 2.819845750954947

Epoch: 53| Step: 0
Training loss: 3.003628126347654
Validation loss: 2.8183233937773067

Epoch: 6| Step: 1
Training loss: 2.5954062447793125
Validation loss: 2.8166857478005225

Epoch: 6| Step: 2
Training loss: 2.905330717660124
Validation loss: 2.8150643702589786

Epoch: 6| Step: 3
Training loss: 2.56055572065954
Validation loss: 2.813832285358698

Epoch: 6| Step: 4
Training loss: 3.602284522511781
Validation loss: 2.8122925293305028

Epoch: 6| Step: 5
Training loss: 3.060167163695994
Validation loss: 2.810967727337454

Epoch: 6| Step: 6
Training loss: 2.4790088592654134
Validation loss: 2.8092493133095973

Epoch: 6| Step: 7
Training loss: 3.1790430414070605
Validation loss: 2.807548926366747

Epoch: 6| Step: 8
Training loss: 2.8365087853263207
Validation loss: 2.805989465322588

Epoch: 6| Step: 9
Training loss: 3.1971078319912642
Validation loss: 2.804358106165105

Epoch: 6| Step: 10
Training loss: 2.71627589810731
Validation loss: 2.8027881222842668

Epoch: 6| Step: 11
Training loss: 3.015374207815537
Validation loss: 2.8009326562254735

Epoch: 6| Step: 12
Training loss: 2.8641114742172946
Validation loss: 2.7995971418258687

Epoch: 6| Step: 13
Training loss: 3.103257184704314
Validation loss: 2.7978666738975275

Epoch: 54| Step: 0
Training loss: 2.680693234700102
Validation loss: 2.796556067441399

Epoch: 6| Step: 1
Training loss: 3.0195227224370207
Validation loss: 2.7950380569078104

Epoch: 6| Step: 2
Training loss: 2.418845564657161
Validation loss: 2.7936482632153026

Epoch: 6| Step: 3
Training loss: 2.869919808094822
Validation loss: 2.7922388078828044

Epoch: 6| Step: 4
Training loss: 2.8452615598238125
Validation loss: 2.790844487824526

Epoch: 6| Step: 5
Training loss: 2.9136226209555263
Validation loss: 2.789344766190708

Epoch: 6| Step: 6
Training loss: 2.710698977484074
Validation loss: 2.7880940755089565

Epoch: 6| Step: 7
Training loss: 2.7794258050240424
Validation loss: 2.7866374495980857

Epoch: 6| Step: 8
Training loss: 2.7699141352046004
Validation loss: 2.785213147082023

Epoch: 6| Step: 9
Training loss: 3.47492431448428
Validation loss: 2.78367503309205

Epoch: 6| Step: 10
Training loss: 3.7446231441575337
Validation loss: 2.7821115738027324

Epoch: 6| Step: 11
Training loss: 2.853499248648251
Validation loss: 2.780716476987836

Epoch: 6| Step: 12
Training loss: 3.0017841120281465
Validation loss: 2.7791365119026383

Epoch: 6| Step: 13
Training loss: 2.6798567204108417
Validation loss: 2.777822332554698

Epoch: 55| Step: 0
Training loss: 3.4603896557792764
Validation loss: 2.7762457156502522

Epoch: 6| Step: 1
Training loss: 3.0969944135044596
Validation loss: 2.7750233875469035

Epoch: 6| Step: 2
Training loss: 2.7213262869883694
Validation loss: 2.7732781449506034

Epoch: 6| Step: 3
Training loss: 3.1989340556515424
Validation loss: 2.772058880371912

Epoch: 6| Step: 4
Training loss: 2.6248071690532115
Validation loss: 2.7704182842187

Epoch: 6| Step: 5
Training loss: 2.6875143716117367
Validation loss: 2.769185161622564

Epoch: 6| Step: 6
Training loss: 2.1872576988085592
Validation loss: 2.767648254956132

Epoch: 6| Step: 7
Training loss: 3.1905142799467976
Validation loss: 2.766399397253975

Epoch: 6| Step: 8
Training loss: 2.8783236655592197
Validation loss: 2.765164309995003

Epoch: 6| Step: 9
Training loss: 3.350565871087172
Validation loss: 2.7637261087692475

Epoch: 6| Step: 10
Training loss: 2.570312128965589
Validation loss: 2.7625493118579953

Epoch: 6| Step: 11
Training loss: 2.727743860212144
Validation loss: 2.7614538055770366

Epoch: 6| Step: 12
Training loss: 2.762505274979056
Validation loss: 2.760385165244722

Epoch: 6| Step: 13
Training loss: 3.0087182204719993
Validation loss: 2.758995760485904

Epoch: 56| Step: 0
Training loss: 2.90495123607264
Validation loss: 2.7577473287833723

Epoch: 6| Step: 1
Training loss: 2.413432116128937
Validation loss: 2.756231313975132

Epoch: 6| Step: 2
Training loss: 2.700536116603079
Validation loss: 2.7550104907898225

Epoch: 6| Step: 3
Training loss: 2.776697955586826
Validation loss: 2.7536678129824175

Epoch: 6| Step: 4
Training loss: 2.6376296892868827
Validation loss: 2.7524260743319657

Epoch: 6| Step: 5
Training loss: 2.9399204427633467
Validation loss: 2.7510722121931392

Epoch: 6| Step: 6
Training loss: 3.1579559550291085
Validation loss: 2.7497069318260836

Epoch: 6| Step: 7
Training loss: 3.0338718048150546
Validation loss: 2.7483467854790766

Epoch: 6| Step: 8
Training loss: 2.803720886786814
Validation loss: 2.7469398204459248

Epoch: 6| Step: 9
Training loss: 2.6414116584927805
Validation loss: 2.745653069174156

Epoch: 6| Step: 10
Training loss: 3.234958172252109
Validation loss: 2.7445567040729446

Epoch: 6| Step: 11
Training loss: 3.323585243689458
Validation loss: 2.7432559577285973

Epoch: 6| Step: 12
Training loss: 2.884179760244548
Validation loss: 2.7421983390804003

Epoch: 6| Step: 13
Training loss: 2.8889151800214554
Validation loss: 2.7409378493753906

Epoch: 57| Step: 0
Training loss: 3.0703131212229016
Validation loss: 2.739388235322597

Epoch: 6| Step: 1
Training loss: 2.7886631783957494
Validation loss: 2.7384640446270625

Epoch: 6| Step: 2
Training loss: 3.3204742033234536
Validation loss: 2.7374309937534

Epoch: 6| Step: 3
Training loss: 3.0305039579072655
Validation loss: 2.7359068875549113

Epoch: 6| Step: 4
Training loss: 2.9963818029920284
Validation loss: 2.7344939723699095

Epoch: 6| Step: 5
Training loss: 2.9143063031599294
Validation loss: 2.7332035280047178

Epoch: 6| Step: 6
Training loss: 2.395152373912063
Validation loss: 2.731821826401907

Epoch: 6| Step: 7
Training loss: 2.44707505929532
Validation loss: 2.73040024831085

Epoch: 6| Step: 8
Training loss: 3.003387446055378
Validation loss: 2.7292985859988343

Epoch: 6| Step: 9
Training loss: 3.381627533825518
Validation loss: 2.7281020517101418

Epoch: 6| Step: 10
Training loss: 2.5749990296593475
Validation loss: 2.727007722984264

Epoch: 6| Step: 11
Training loss: 2.5904700441113917
Validation loss: 2.725764328100557

Epoch: 6| Step: 12
Training loss: 2.9093144165680482
Validation loss: 2.724799940948986

Epoch: 6| Step: 13
Training loss: 2.6090078495327185
Validation loss: 2.7234550920517577

Epoch: 58| Step: 0
Training loss: 2.5545148412004917
Validation loss: 2.722610465950497

Epoch: 6| Step: 1
Training loss: 3.0302158439982887
Validation loss: 2.7215844356575474

Epoch: 6| Step: 2
Training loss: 3.1551285063723844
Validation loss: 2.720516712368518

Epoch: 6| Step: 3
Training loss: 3.4356690125389995
Validation loss: 2.7192600692558386

Epoch: 6| Step: 4
Training loss: 2.0241309196589614
Validation loss: 2.7184350280715397

Epoch: 6| Step: 5
Training loss: 2.9899575312733724
Validation loss: 2.7171722013903095

Epoch: 6| Step: 6
Training loss: 2.8016056565951457
Validation loss: 2.716250545913026

Epoch: 6| Step: 7
Training loss: 2.816988605707787
Validation loss: 2.7155045324952782

Epoch: 6| Step: 8
Training loss: 2.6636096200242525
Validation loss: 2.7145057669092503

Epoch: 6| Step: 9
Training loss: 2.6956286258792526
Validation loss: 2.7135605814464308

Epoch: 6| Step: 10
Training loss: 2.7053568011350655
Validation loss: 2.7125593568603734

Epoch: 6| Step: 11
Training loss: 2.9953139582209056
Validation loss: 2.711385127479009

Epoch: 6| Step: 12
Training loss: 2.927933068432859
Validation loss: 2.7105094285866773

Epoch: 6| Step: 13
Training loss: 2.9656521344727262
Validation loss: 2.709274764151929

Epoch: 59| Step: 0
Training loss: 2.8942569494586596
Validation loss: 2.708345858227061

Epoch: 6| Step: 1
Training loss: 2.952131639155813
Validation loss: 2.707153801944434

Epoch: 6| Step: 2
Training loss: 2.755408084505488
Validation loss: 2.706054760921335

Epoch: 6| Step: 3
Training loss: 2.509709766523336
Validation loss: 2.705210548216851

Epoch: 6| Step: 4
Training loss: 3.4918443481345385
Validation loss: 2.7041211800846945

Epoch: 6| Step: 5
Training loss: 3.106127552712261
Validation loss: 2.7036799190172776

Epoch: 6| Step: 6
Training loss: 3.0999044219018685
Validation loss: 2.7025815090293928

Epoch: 6| Step: 7
Training loss: 2.373582517351104
Validation loss: 2.701459132449582

Epoch: 6| Step: 8
Training loss: 2.2703649988687675
Validation loss: 2.7000941666323883

Epoch: 6| Step: 9
Training loss: 2.7075325197642695
Validation loss: 2.699658870928649

Epoch: 6| Step: 10
Training loss: 2.809307745106233
Validation loss: 2.6980766239149014

Epoch: 6| Step: 11
Training loss: 3.3794145323083344
Validation loss: 2.69749764584641

Epoch: 6| Step: 12
Training loss: 2.8991224605490133
Validation loss: 2.6964398371528198

Epoch: 6| Step: 13
Training loss: 2.210106683460464
Validation loss: 2.6955080265498115

Epoch: 60| Step: 0
Training loss: 2.477473816333912
Validation loss: 2.6942376541365016

Epoch: 6| Step: 1
Training loss: 3.3337918601967726
Validation loss: 2.693271767397321

Epoch: 6| Step: 2
Training loss: 2.8150286856997133
Validation loss: 2.6923418859434367

Epoch: 6| Step: 3
Training loss: 2.229482883829964
Validation loss: 2.6910964647276554

Epoch: 6| Step: 4
Training loss: 3.016989601792525
Validation loss: 2.6903807112337432

Epoch: 6| Step: 5
Training loss: 2.6510724938379617
Validation loss: 2.6891476363706692

Epoch: 6| Step: 6
Training loss: 2.5845897654514283
Validation loss: 2.6882036308206723

Epoch: 6| Step: 7
Training loss: 2.654762300242448
Validation loss: 2.6873035950566875

Epoch: 6| Step: 8
Training loss: 2.9582971561709255
Validation loss: 2.6863959580440646

Epoch: 6| Step: 9
Training loss: 2.85316067158355
Validation loss: 2.6854433129889785

Epoch: 6| Step: 10
Training loss: 3.2923522589345784
Validation loss: 2.6844631158401855

Epoch: 6| Step: 11
Training loss: 3.0833358420971813
Validation loss: 2.683663624127284

Epoch: 6| Step: 12
Training loss: 2.5968659769170013
Validation loss: 2.682710727189836

Epoch: 6| Step: 13
Training loss: 2.851883041969078
Validation loss: 2.681574980656315

Epoch: 61| Step: 0
Training loss: 2.827255705542731
Validation loss: 2.680738667397827

Epoch: 6| Step: 1
Training loss: 2.8327506158026985
Validation loss: 2.6799278633411

Epoch: 6| Step: 2
Training loss: 2.9251905591138683
Validation loss: 2.67912298397288

Epoch: 6| Step: 3
Training loss: 2.915602044672412
Validation loss: 2.6782718993545354

Epoch: 6| Step: 4
Training loss: 3.1863071977368422
Validation loss: 2.677449440073592

Epoch: 6| Step: 5
Training loss: 2.7004854401660507
Validation loss: 2.676654964467363

Epoch: 6| Step: 6
Training loss: 2.546675785441159
Validation loss: 2.6759709126251088

Epoch: 6| Step: 7
Training loss: 2.7994215469936314
Validation loss: 2.675193540161226

Epoch: 6| Step: 8
Training loss: 2.3809604138284235
Validation loss: 2.674379554287619

Epoch: 6| Step: 9
Training loss: 2.945792971005828
Validation loss: 2.6732357493765475

Epoch: 6| Step: 10
Training loss: 2.604199788200827
Validation loss: 2.6724090488612378

Epoch: 6| Step: 11
Training loss: 2.935152454998212
Validation loss: 2.671965480410145

Epoch: 6| Step: 12
Training loss: 2.469201927830203
Validation loss: 2.6707884157384045

Epoch: 6| Step: 13
Training loss: 3.2120389139898897
Validation loss: 2.670429857657638

Epoch: 62| Step: 0
Training loss: 2.7940669961595983
Validation loss: 2.6690913789794166

Epoch: 6| Step: 1
Training loss: 2.7684592686378706
Validation loss: 2.6685410160903045

Epoch: 6| Step: 2
Training loss: 2.5763713999449114
Validation loss: 2.66751197490489

Epoch: 6| Step: 3
Training loss: 2.471602325253644
Validation loss: 2.6670347396825074

Epoch: 6| Step: 4
Training loss: 2.697502595407052
Validation loss: 2.6661607938002585

Epoch: 6| Step: 5
Training loss: 2.925354380210523
Validation loss: 2.6651758308210947

Epoch: 6| Step: 6
Training loss: 3.2763623847300862
Validation loss: 2.6643908495024817

Epoch: 6| Step: 7
Training loss: 2.415480114143714
Validation loss: 2.6639490783949094

Epoch: 6| Step: 8
Training loss: 2.681734154300314
Validation loss: 2.6626276830345077

Epoch: 6| Step: 9
Training loss: 2.5805000231675783
Validation loss: 2.6601032059469545

Epoch: 6| Step: 10
Training loss: 2.795463077760519
Validation loss: 2.6640205939344614

Epoch: 6| Step: 11
Training loss: 3.412510150153746
Validation loss: 2.6638904415290066

Epoch: 6| Step: 12
Training loss: 2.6035681888800126
Validation loss: 2.658408152166145

Epoch: 6| Step: 13
Training loss: 3.071700619533896
Validation loss: 2.6579771223746103

Epoch: 63| Step: 0
Training loss: 3.1228954094758588
Validation loss: 2.6573025730995377

Epoch: 6| Step: 1
Training loss: 2.6331581318996227
Validation loss: 2.6559118317405286

Epoch: 6| Step: 2
Training loss: 2.6160164561789405
Validation loss: 2.655453042543813

Epoch: 6| Step: 3
Training loss: 2.644563164793113
Validation loss: 2.6542200896567265

Epoch: 6| Step: 4
Training loss: 3.1208505165703375
Validation loss: 2.6538901673582878

Epoch: 6| Step: 5
Training loss: 2.6892940831583387
Validation loss: 2.6525752884597193

Epoch: 6| Step: 6
Training loss: 2.3038465096951173
Validation loss: 2.6512503301394563

Epoch: 6| Step: 7
Training loss: 3.431308233048373
Validation loss: 2.6513960226140725

Epoch: 6| Step: 8
Training loss: 2.173704625380569
Validation loss: 2.65125437684442

Epoch: 6| Step: 9
Training loss: 2.326153835992188
Validation loss: 2.6509057230590454

Epoch: 6| Step: 10
Training loss: 2.9405902272680886
Validation loss: 2.6495320206810673

Epoch: 6| Step: 11
Training loss: 2.416459852993708
Validation loss: 2.6497417678011703

Epoch: 6| Step: 12
Training loss: 3.3058609558700285
Validation loss: 2.6491416512702513

Epoch: 6| Step: 13
Training loss: 3.007231103762727
Validation loss: 2.6490218081552848

Epoch: 64| Step: 0
Training loss: 2.562706915712338
Validation loss: 2.6480356697415295

Epoch: 6| Step: 1
Training loss: 2.6398419003396896
Validation loss: 2.6470942959247474

Epoch: 6| Step: 2
Training loss: 2.9023900804890594
Validation loss: 2.646717064119015

Epoch: 6| Step: 3
Training loss: 2.7390471732738435
Validation loss: 2.6457953462852415

Epoch: 6| Step: 4
Training loss: 2.6344219235260673
Validation loss: 2.6451003844135816

Epoch: 6| Step: 5
Training loss: 2.31001705179898
Validation loss: 2.6436590787796073

Epoch: 6| Step: 6
Training loss: 3.18677213249562
Validation loss: 2.643091874088304

Epoch: 6| Step: 7
Training loss: 3.402561255246278
Validation loss: 2.642082414091999

Epoch: 6| Step: 8
Training loss: 2.8499804981300625
Validation loss: 2.6407074924803537

Epoch: 6| Step: 9
Training loss: 2.7855627504291425
Validation loss: 2.6390741523047274

Epoch: 6| Step: 10
Training loss: 2.6636959058620504
Validation loss: 2.638817960778646

Epoch: 6| Step: 11
Training loss: 2.4626098763210753
Validation loss: 2.637336941058305

Epoch: 6| Step: 12
Training loss: 2.8737287613331532
Validation loss: 2.636689724232599

Epoch: 6| Step: 13
Training loss: 2.7299591156409813
Validation loss: 2.6349251229676023

Epoch: 65| Step: 0
Training loss: 2.44438665735932
Validation loss: 2.634331209505848

Epoch: 6| Step: 1
Training loss: 2.9169351363373868
Validation loss: 2.638949342224829

Epoch: 6| Step: 2
Training loss: 2.7295359490286613
Validation loss: 2.628094589898115

Epoch: 6| Step: 3
Training loss: 3.0363834605247315
Validation loss: 2.631280228659389

Epoch: 6| Step: 4
Training loss: 2.763102787586902
Validation loss: 2.633819598760071

Epoch: 6| Step: 5
Training loss: 2.8536352697795295
Validation loss: 2.636554763780787

Epoch: 6| Step: 6
Training loss: 2.959139718488324
Validation loss: 2.631262937319159

Epoch: 6| Step: 7
Training loss: 2.366491435732035
Validation loss: 2.631607549662501

Epoch: 6| Step: 8
Training loss: 2.7261278740605657
Validation loss: 2.6334355463238217

Epoch: 6| Step: 9
Training loss: 2.808033851555339
Validation loss: 2.6348270817237553

Epoch: 6| Step: 10
Training loss: 2.5965533446369653
Validation loss: 2.6407463753097047

Epoch: 6| Step: 11
Training loss: 2.686228074116998
Validation loss: 2.6373522715605366

Epoch: 6| Step: 12
Training loss: 2.5875736834221112
Validation loss: 2.6325449821780667

Epoch: 6| Step: 13
Training loss: 3.258283475866771
Validation loss: 2.629718528439083

Epoch: 66| Step: 0
Training loss: 2.692778084083356
Validation loss: 2.627649831737359

Epoch: 6| Step: 1
Training loss: 2.574444357170872
Validation loss: 2.6261806103755276

Epoch: 6| Step: 2
Training loss: 2.794264784797789
Validation loss: 2.6265893015344135

Epoch: 6| Step: 3
Training loss: 2.5258756497810295
Validation loss: 2.6235288403021637

Epoch: 6| Step: 4
Training loss: 3.109237897907803
Validation loss: 2.6226999257420327

Epoch: 6| Step: 5
Training loss: 2.767488875259053
Validation loss: 2.62085640558014

Epoch: 6| Step: 6
Training loss: 2.846242797199127
Validation loss: 2.6187146186714543

Epoch: 6| Step: 7
Training loss: 2.5078701119623643
Validation loss: 2.620133475623757

Epoch: 6| Step: 8
Training loss: 2.5058466256130263
Validation loss: 2.6195789855011617

Epoch: 6| Step: 9
Training loss: 2.564960322082473
Validation loss: 2.6188682056051364

Epoch: 6| Step: 10
Training loss: 2.9350237859382737
Validation loss: 2.6166895758077513

Epoch: 6| Step: 11
Training loss: 2.7806677048006807
Validation loss: 2.6175148678527065

Epoch: 6| Step: 12
Training loss: 2.8982683733928063
Validation loss: 2.616236727517294

Epoch: 6| Step: 13
Training loss: 3.04162270152747
Validation loss: 2.6144430925872215

Epoch: 67| Step: 0
Training loss: 2.7501680149424685
Validation loss: 2.615472727163563

Epoch: 6| Step: 1
Training loss: 2.6011502509214366
Validation loss: 2.6130730318408024

Epoch: 6| Step: 2
Training loss: 2.5719767924636643
Validation loss: 2.614834311143145

Epoch: 6| Step: 3
Training loss: 2.906987578615802
Validation loss: 2.6118224918819704

Epoch: 6| Step: 4
Training loss: 2.3855406105680093
Validation loss: 2.613777695102723

Epoch: 6| Step: 5
Training loss: 2.7062656921918475
Validation loss: 2.6107710950608554

Epoch: 6| Step: 6
Training loss: 2.716773092685492
Validation loss: 2.6118696094076057

Epoch: 6| Step: 7
Training loss: 2.8073903610819513
Validation loss: 2.6109081644860126

Epoch: 6| Step: 8
Training loss: 3.045703212673944
Validation loss: 2.61112519918749

Epoch: 6| Step: 9
Training loss: 2.6871227620641602
Validation loss: 2.6102976890377296

Epoch: 6| Step: 10
Training loss: 2.3229729912148827
Validation loss: 2.6107054191186814

Epoch: 6| Step: 11
Training loss: 2.8710475788166767
Validation loss: 2.6084461652911073

Epoch: 6| Step: 12
Training loss: 3.211982501313654
Validation loss: 2.6080016216729396

Epoch: 6| Step: 13
Training loss: 2.810995504852685
Validation loss: 2.6064513344455147

Epoch: 68| Step: 0
Training loss: 2.658186083535106
Validation loss: 2.6037245616747637

Epoch: 6| Step: 1
Training loss: 2.996820672490499
Validation loss: 2.602439686665383

Epoch: 6| Step: 2
Training loss: 2.76344653178034
Validation loss: 2.6010335665204822

Epoch: 6| Step: 3
Training loss: 2.6432072580616572
Validation loss: 2.6016423057557674

Epoch: 6| Step: 4
Training loss: 2.5762354544312718
Validation loss: 2.5981026249224075

Epoch: 6| Step: 5
Training loss: 2.7380722771544717
Validation loss: 2.598505555326606

Epoch: 6| Step: 6
Training loss: 2.995827634449624
Validation loss: 2.601576048058716

Epoch: 6| Step: 7
Training loss: 2.3725058861228354
Validation loss: 2.603393811302061

Epoch: 6| Step: 8
Training loss: 2.9227743957508987
Validation loss: 2.6041319323448544

Epoch: 6| Step: 9
Training loss: 2.826649655104976
Validation loss: 2.6064492763138025

Epoch: 6| Step: 10
Training loss: 2.8071041480986603
Validation loss: 2.6079011664717426

Epoch: 6| Step: 11
Training loss: 2.352058333023869
Validation loss: 2.605919596390255

Epoch: 6| Step: 12
Training loss: 2.7049348979174037
Validation loss: 2.6068432340879237

Epoch: 6| Step: 13
Training loss: 2.9482289251109455
Validation loss: 2.606683542248994

Epoch: 69| Step: 0
Training loss: 2.6934950741116856
Validation loss: 2.602366509362373

Epoch: 6| Step: 1
Training loss: 2.539198276117289
Validation loss: 2.5995293234009957

Epoch: 6| Step: 2
Training loss: 2.5230083277773168
Validation loss: 2.599954851076399

Epoch: 6| Step: 3
Training loss: 3.2166333692602844
Validation loss: 2.5976027863242312

Epoch: 6| Step: 4
Training loss: 2.2224132760359248
Validation loss: 2.597735655677607

Epoch: 6| Step: 5
Training loss: 2.3880838089809666
Validation loss: 2.5972548554716846

Epoch: 6| Step: 6
Training loss: 2.26574433111117
Validation loss: 2.597332911815779

Epoch: 6| Step: 7
Training loss: 3.0400575710165776
Validation loss: 2.595524406930249

Epoch: 6| Step: 8
Training loss: 3.030527559689742
Validation loss: 2.5983482873113974

Epoch: 6| Step: 9
Training loss: 2.856848429087085
Validation loss: 2.5953988192766246

Epoch: 6| Step: 10
Training loss: 2.9314257538573987
Validation loss: 2.5918263881893573

Epoch: 6| Step: 11
Training loss: 3.097612070391522
Validation loss: 2.5888202499418913

Epoch: 6| Step: 12
Training loss: 2.6221200494293515
Validation loss: 2.5893086935066596

Epoch: 6| Step: 13
Training loss: 2.6174776286541834
Validation loss: 2.58795044643909

Epoch: 70| Step: 0
Training loss: 2.466847326347204
Validation loss: 2.58751703216795

Epoch: 6| Step: 1
Training loss: 2.749979105783328
Validation loss: 2.5877872854268964

Epoch: 6| Step: 2
Training loss: 2.6187637365158447
Validation loss: 2.5831154351988412

Epoch: 6| Step: 3
Training loss: 2.7155441149220705
Validation loss: 2.582183210140147

Epoch: 6| Step: 4
Training loss: 2.346921783671773
Validation loss: 2.58314509372509

Epoch: 6| Step: 5
Training loss: 2.8397550923231036
Validation loss: 2.579835366767683

Epoch: 6| Step: 6
Training loss: 2.9292800823482694
Validation loss: 2.581334514943094

Epoch: 6| Step: 7
Training loss: 2.5537217674244546
Validation loss: 2.5782285573178587

Epoch: 6| Step: 8
Training loss: 2.5674981475496526
Validation loss: 2.5804156675315766

Epoch: 6| Step: 9
Training loss: 2.156944052630758
Validation loss: 2.581408480873835

Epoch: 6| Step: 10
Training loss: 2.9619457772679745
Validation loss: 2.5831009750055034

Epoch: 6| Step: 11
Training loss: 2.9400883086559344
Validation loss: 2.585829802668582

Epoch: 6| Step: 12
Training loss: 3.078369750540848
Validation loss: 2.619714987348695

Epoch: 6| Step: 13
Training loss: 3.1642192283714023
Validation loss: 2.6104010508182602

Epoch: 71| Step: 0
Training loss: 2.4558517948626455
Validation loss: 2.5755807980820036

Epoch: 6| Step: 1
Training loss: 2.516804104856331
Validation loss: 2.569255422106063

Epoch: 6| Step: 2
Training loss: 3.187839564767688
Validation loss: 2.57131970739014

Epoch: 6| Step: 3
Training loss: 2.613154249996992
Validation loss: 2.571826956305246

Epoch: 6| Step: 4
Training loss: 2.578075893974806
Validation loss: 2.5742260667989245

Epoch: 6| Step: 5
Training loss: 2.5731595397069085
Validation loss: 2.5734246765323685

Epoch: 6| Step: 6
Training loss: 3.155340838029734
Validation loss: 2.5770701244347762

Epoch: 6| Step: 7
Training loss: 2.6178516968525676
Validation loss: 2.5776049927603344

Epoch: 6| Step: 8
Training loss: 2.984129251477953
Validation loss: 2.5793620060749864

Epoch: 6| Step: 9
Training loss: 2.623926851619562
Validation loss: 2.584529727853626

Epoch: 6| Step: 10
Training loss: 2.529842974648702
Validation loss: 2.582360643391711

Epoch: 6| Step: 11
Training loss: 2.856398069855054
Validation loss: 2.5785332867008304

Epoch: 6| Step: 12
Training loss: 2.5467545182452103
Validation loss: 2.576656886851646

Epoch: 6| Step: 13
Training loss: 2.557213330800947
Validation loss: 2.5749907505770486

Epoch: 72| Step: 0
Training loss: 2.623093048620966
Validation loss: 2.5716885919021544

Epoch: 6| Step: 1
Training loss: 3.101854440320033
Validation loss: 2.5723819305688895

Epoch: 6| Step: 2
Training loss: 2.780263490059479
Validation loss: 2.5704814387711608

Epoch: 6| Step: 3
Training loss: 2.6297350366367787
Validation loss: 2.5666842220581256

Epoch: 6| Step: 4
Training loss: 2.3233238741418973
Validation loss: 2.566205594111704

Epoch: 6| Step: 5
Training loss: 3.225780327598863
Validation loss: 2.5646245724306027

Epoch: 6| Step: 6
Training loss: 2.4620422789896836
Validation loss: 2.5621566542438874

Epoch: 6| Step: 7
Training loss: 2.9979180423255363
Validation loss: 2.560989105033614

Epoch: 6| Step: 8
Training loss: 1.7359519868618767
Validation loss: 2.561395298473215

Epoch: 6| Step: 9
Training loss: 2.5149713460757424
Validation loss: 2.5636334277402035

Epoch: 6| Step: 10
Training loss: 3.0307619940817703
Validation loss: 2.573646076507213

Epoch: 6| Step: 11
Training loss: 2.8293422376700508
Validation loss: 2.5646145632526314

Epoch: 6| Step: 12
Training loss: 2.447828856712693
Validation loss: 2.559419579247708

Epoch: 6| Step: 13
Training loss: 2.771129926902985
Validation loss: 2.55786621000074

Epoch: 73| Step: 0
Training loss: 2.9665281313435634
Validation loss: 2.55730884699026

Epoch: 6| Step: 1
Training loss: 2.052291691718487
Validation loss: 2.555917037631345

Epoch: 6| Step: 2
Training loss: 2.78425812652572
Validation loss: 2.5550601854595114

Epoch: 6| Step: 3
Training loss: 3.140098565613828
Validation loss: 2.553869009383376

Epoch: 6| Step: 4
Training loss: 2.1881368527476837
Validation loss: 2.5541857616546744

Epoch: 6| Step: 5
Training loss: 2.777942190602795
Validation loss: 2.5557567291504526

Epoch: 6| Step: 6
Training loss: 2.594829564460335
Validation loss: 2.5532133961024064

Epoch: 6| Step: 7
Training loss: 2.395664164887072
Validation loss: 2.5525009643971326

Epoch: 6| Step: 8
Training loss: 2.9638042814061536
Validation loss: 2.5510082289930502

Epoch: 6| Step: 9
Training loss: 2.398307076054834
Validation loss: 2.5499173736898744

Epoch: 6| Step: 10
Training loss: 2.3040511982448004
Validation loss: 2.5511158620985426

Epoch: 6| Step: 11
Training loss: 2.7587875069132783
Validation loss: 2.549011660382955

Epoch: 6| Step: 12
Training loss: 3.2423067737379285
Validation loss: 2.5524371673890895

Epoch: 6| Step: 13
Training loss: 2.799673289584316
Validation loss: 2.553131018218687

Epoch: 74| Step: 0
Training loss: 2.4870015780785573
Validation loss: 2.548302264185294

Epoch: 6| Step: 1
Training loss: 2.6692161492429562
Validation loss: 2.5505576004038217

Epoch: 6| Step: 2
Training loss: 3.0592967817304118
Validation loss: 2.5476180320851465

Epoch: 6| Step: 3
Training loss: 2.2909707717862653
Validation loss: 2.548175222441329

Epoch: 6| Step: 4
Training loss: 2.3798249072894984
Validation loss: 2.5469601856799735

Epoch: 6| Step: 5
Training loss: 2.2184438359887046
Validation loss: 2.549582869252313

Epoch: 6| Step: 6
Training loss: 2.164596436662516
Validation loss: 2.548266602069289

Epoch: 6| Step: 7
Training loss: 2.704892148672421
Validation loss: 2.5510392888531728

Epoch: 6| Step: 8
Training loss: 2.9748597568826867
Validation loss: 2.5496697567288367

Epoch: 6| Step: 9
Training loss: 2.5088926466913786
Validation loss: 2.5508817036639195

Epoch: 6| Step: 10
Training loss: 2.6849175398966953
Validation loss: 2.546607863569511

Epoch: 6| Step: 11
Training loss: 3.1835203571869966
Validation loss: 2.5479220400920193

Epoch: 6| Step: 12
Training loss: 3.322912297898692
Validation loss: 2.549544746924444

Epoch: 6| Step: 13
Training loss: 2.6195711582783336
Validation loss: 2.5487150788358686

Epoch: 75| Step: 0
Training loss: 2.689420147197052
Validation loss: 2.552582545339044

Epoch: 6| Step: 1
Training loss: 3.0932103466654612
Validation loss: 2.5492621937669293

Epoch: 6| Step: 2
Training loss: 2.1168591008857747
Validation loss: 2.5473911253899217

Epoch: 6| Step: 3
Training loss: 2.4074689081547223
Validation loss: 2.54726068427684

Epoch: 6| Step: 4
Training loss: 2.8652154028640795
Validation loss: 2.545149142348895

Epoch: 6| Step: 5
Training loss: 2.5361907212054486
Validation loss: 2.5379057924618755

Epoch: 6| Step: 6
Training loss: 2.7923632839139296
Validation loss: 2.540413396390145

Epoch: 6| Step: 7
Training loss: 2.510061996119864
Validation loss: 2.540915774339038

Epoch: 6| Step: 8
Training loss: 2.3542274759816633
Validation loss: 2.5425845401378426

Epoch: 6| Step: 9
Training loss: 3.037442518404637
Validation loss: 2.5378984179227153

Epoch: 6| Step: 10
Training loss: 2.5412243838691504
Validation loss: 2.538368012743885

Epoch: 6| Step: 11
Training loss: 2.9245575203367604
Validation loss: 2.5395444285474604

Epoch: 6| Step: 12
Training loss: 2.5483844239340456
Validation loss: 2.5382442466580213

Epoch: 6| Step: 13
Training loss: 2.926837155091119
Validation loss: 2.537946547755752

Testing loss: 2.0940570006147143
