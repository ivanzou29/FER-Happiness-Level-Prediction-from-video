Epoch: 1| Step: 0
Training loss: 6.389663288158082
Validation loss: 5.8635613300235265

Epoch: 6| Step: 1
Training loss: 6.20831066699232
Validation loss: 5.862090679267765

Epoch: 6| Step: 2
Training loss: 5.409606773484149
Validation loss: 5.860631646928913

Epoch: 6| Step: 3
Training loss: 6.274073510334888
Validation loss: 5.859202091632792

Epoch: 6| Step: 4
Training loss: 6.576374609382413
Validation loss: 5.857696346997853

Epoch: 6| Step: 5
Training loss: 4.7256213551640815
Validation loss: 5.856207558591081

Epoch: 6| Step: 6
Training loss: 6.331469746849734
Validation loss: 5.854626602441188

Epoch: 6| Step: 7
Training loss: 6.489055810084891
Validation loss: 5.853068247565962

Epoch: 6| Step: 8
Training loss: 4.935978329046769
Validation loss: 5.851356220896142

Epoch: 6| Step: 9
Training loss: 5.080934469225755
Validation loss: 5.849675293955932

Epoch: 6| Step: 10
Training loss: 6.6756863930504835
Validation loss: 5.848012528983149

Epoch: 6| Step: 11
Training loss: 6.533667887990378
Validation loss: 5.846195464043996

Epoch: 6| Step: 12
Training loss: 5.898008055558885
Validation loss: 5.8443850411916385

Epoch: 6| Step: 13
Training loss: 5.579502480589842
Validation loss: 5.842472691600673

Epoch: 2| Step: 0
Training loss: 6.541010667828071
Validation loss: 5.840457770857082

Epoch: 6| Step: 1
Training loss: 5.404963875084347
Validation loss: 5.838419232090025

Epoch: 6| Step: 2
Training loss: 5.724909899140028
Validation loss: 5.836336461822027

Epoch: 6| Step: 3
Training loss: 6.146614085460073
Validation loss: 5.834086487605131

Epoch: 6| Step: 4
Training loss: 6.678914771641832
Validation loss: 5.831876609201604

Epoch: 6| Step: 5
Training loss: 5.989615036147983
Validation loss: 5.829428383017105

Epoch: 6| Step: 6
Training loss: 5.201061492562269
Validation loss: 5.826904987346832

Epoch: 6| Step: 7
Training loss: 6.257785678001195
Validation loss: 5.8243051783056705

Epoch: 6| Step: 8
Training loss: 4.8893464095918056
Validation loss: 5.82144980018572

Epoch: 6| Step: 9
Training loss: 5.603036003022993
Validation loss: 5.818647845525981

Epoch: 6| Step: 10
Training loss: 5.6977373149570445
Validation loss: 5.815625406682381

Epoch: 6| Step: 11
Training loss: 6.2924177045749
Validation loss: 5.812521001306146

Epoch: 6| Step: 12
Training loss: 6.202040109002188
Validation loss: 5.809246232669841

Epoch: 6| Step: 13
Training loss: 6.26018701048539
Validation loss: 5.805798594950938

Epoch: 3| Step: 0
Training loss: 5.203871664823708
Validation loss: 5.8021297852478995

Epoch: 6| Step: 1
Training loss: 6.4890660977370835
Validation loss: 5.798336177356297

Epoch: 6| Step: 2
Training loss: 6.1282582861349795
Validation loss: 5.794352158107893

Epoch: 6| Step: 3
Training loss: 5.485611561540022
Validation loss: 5.789936337777116

Epoch: 6| Step: 4
Training loss: 4.9279687366856315
Validation loss: 5.785767448468102

Epoch: 6| Step: 5
Training loss: 5.670089734963554
Validation loss: 5.781094385750538

Epoch: 6| Step: 6
Training loss: 6.707048597185633
Validation loss: 5.776475023868391

Epoch: 6| Step: 7
Training loss: 6.370865322487628
Validation loss: 5.771530228640819

Epoch: 6| Step: 8
Training loss: 5.047478701738803
Validation loss: 5.766097052046821

Epoch: 6| Step: 9
Training loss: 6.181110820996928
Validation loss: 5.760995800115441

Epoch: 6| Step: 10
Training loss: 5.435671444067564
Validation loss: 5.755570850491095

Epoch: 6| Step: 11
Training loss: 6.262634324633846
Validation loss: 5.749932385475562

Epoch: 6| Step: 12
Training loss: 5.8070370833584315
Validation loss: 5.743959847962527

Epoch: 6| Step: 13
Training loss: 6.364759710170754
Validation loss: 5.73774881924578

Epoch: 4| Step: 0
Training loss: 5.5763837730645
Validation loss: 5.731439460997964

Epoch: 6| Step: 1
Training loss: 5.040558538217493
Validation loss: 5.725076563294032

Epoch: 6| Step: 2
Training loss: 6.001565093318237
Validation loss: 5.718333689505154

Epoch: 6| Step: 3
Training loss: 6.061946882991225
Validation loss: 5.711220152853392

Epoch: 6| Step: 4
Training loss: 6.134914548196403
Validation loss: 5.7043649379395855

Epoch: 6| Step: 5
Training loss: 5.919764965649832
Validation loss: 5.696981331200345

Epoch: 6| Step: 6
Training loss: 6.095284762657986
Validation loss: 5.689750924628415

Epoch: 6| Step: 7
Training loss: 5.3110198707848095
Validation loss: 5.6820733587588625

Epoch: 6| Step: 8
Training loss: 5.629576453205025
Validation loss: 5.674502994323348

Epoch: 6| Step: 9
Training loss: 6.169197525441227
Validation loss: 5.667188180973029

Epoch: 6| Step: 10
Training loss: 6.054254961868598
Validation loss: 5.658994511143882

Epoch: 6| Step: 11
Training loss: 6.057587511136601
Validation loss: 5.651302021082217

Epoch: 6| Step: 12
Training loss: 5.093211139657845
Validation loss: 5.643474081229165

Epoch: 6| Step: 13
Training loss: 5.917950378993763
Validation loss: 5.635327332000684

Epoch: 5| Step: 0
Training loss: 5.6692742724591465
Validation loss: 5.627573371272197

Epoch: 6| Step: 1
Training loss: 6.556852690102701
Validation loss: 5.619950182366992

Epoch: 6| Step: 2
Training loss: 5.725661806725927
Validation loss: 5.61146870450391

Epoch: 6| Step: 3
Training loss: 4.6281426552404215
Validation loss: 5.603660343181045

Epoch: 6| Step: 4
Training loss: 7.147072049832578
Validation loss: 5.595680940682828

Epoch: 6| Step: 5
Training loss: 5.78089169603354
Validation loss: 5.588066410311772

Epoch: 6| Step: 6
Training loss: 5.258352628854855
Validation loss: 5.580185624456731

Epoch: 6| Step: 7
Training loss: 6.039679294686599
Validation loss: 5.572632636797414

Epoch: 6| Step: 8
Training loss: 4.962150749773385
Validation loss: 5.565001107598783

Epoch: 6| Step: 9
Training loss: 5.611459668772271
Validation loss: 5.557689772852304

Epoch: 6| Step: 10
Training loss: 5.3840250938817
Validation loss: 5.550407094602357

Epoch: 6| Step: 11
Training loss: 5.788597922274592
Validation loss: 5.543264268699883

Epoch: 6| Step: 12
Training loss: 5.940412268925844
Validation loss: 5.53610424537486

Epoch: 6| Step: 13
Training loss: 4.7692943017386416
Validation loss: 5.52891203757064

Epoch: 6| Step: 0
Training loss: 4.745149645681589
Validation loss: 5.522510700805483

Epoch: 6| Step: 1
Training loss: 5.923157726655098
Validation loss: 5.5154700180915786

Epoch: 6| Step: 2
Training loss: 6.073515647108668
Validation loss: 5.508905685552737

Epoch: 6| Step: 3
Training loss: 6.017024365444723
Validation loss: 5.502645376556327

Epoch: 6| Step: 4
Training loss: 5.892326938837525
Validation loss: 5.496224986309999

Epoch: 6| Step: 5
Training loss: 5.2671763684503965
Validation loss: 5.489810347764205

Epoch: 6| Step: 6
Training loss: 5.10603713452186
Validation loss: 5.4836223263323625

Epoch: 6| Step: 7
Training loss: 5.373362092035036
Validation loss: 5.477063615467694

Epoch: 6| Step: 8
Training loss: 5.580613721779957
Validation loss: 5.471046009370192

Epoch: 6| Step: 9
Training loss: 5.600256689183203
Validation loss: 5.4649128849291

Epoch: 6| Step: 10
Training loss: 5.8136674262354475
Validation loss: 5.458441007682931

Epoch: 6| Step: 11
Training loss: 5.7028102840177
Validation loss: 5.452141878102583

Epoch: 6| Step: 12
Training loss: 5.598330023945251
Validation loss: 5.445455789163046

Epoch: 6| Step: 13
Training loss: 5.572955303117626
Validation loss: 5.439155560429481

Epoch: 7| Step: 0
Training loss: 5.322899367372156
Validation loss: 5.432861922394677

Epoch: 6| Step: 1
Training loss: 5.4393765072588725
Validation loss: 5.426342738525693

Epoch: 6| Step: 2
Training loss: 5.346606288737061
Validation loss: 5.419918766421781

Epoch: 6| Step: 3
Training loss: 5.884912447865556
Validation loss: 5.41333510818515

Epoch: 6| Step: 4
Training loss: 5.5834653278899316
Validation loss: 5.407327063257301

Epoch: 6| Step: 5
Training loss: 5.905822738452076
Validation loss: 5.401307273913627

Epoch: 6| Step: 6
Training loss: 5.962922292026133
Validation loss: 5.395249216088051

Epoch: 6| Step: 7
Training loss: 5.928433533212196
Validation loss: 5.3893600675179965

Epoch: 6| Step: 8
Training loss: 5.023539445711766
Validation loss: 5.382870286724545

Epoch: 6| Step: 9
Training loss: 5.577400566524497
Validation loss: 5.377028829048812

Epoch: 6| Step: 10
Training loss: 5.580493926197496
Validation loss: 5.370990233377467

Epoch: 6| Step: 11
Training loss: 4.640889272646655
Validation loss: 5.3652994609968125

Epoch: 6| Step: 12
Training loss: 5.53698157645728
Validation loss: 5.359874379550606

Epoch: 6| Step: 13
Training loss: 5.317331069680526
Validation loss: 5.35401284953036

Epoch: 8| Step: 0
Training loss: 5.4899944848760756
Validation loss: 5.348727995442482

Epoch: 6| Step: 1
Training loss: 4.7984527080845165
Validation loss: 5.343342399295977

Epoch: 6| Step: 2
Training loss: 5.121591504521282
Validation loss: 5.338375430116307

Epoch: 6| Step: 3
Training loss: 6.2879578562093466
Validation loss: 5.333313266398507

Epoch: 6| Step: 4
Training loss: 5.8959671203027755
Validation loss: 5.328150505832692

Epoch: 6| Step: 5
Training loss: 4.97752900372365
Validation loss: 5.322920329571065

Epoch: 6| Step: 6
Training loss: 6.514983294239422
Validation loss: 5.317560904386784

Epoch: 6| Step: 7
Training loss: 5.068600217061944
Validation loss: 5.312115314991884

Epoch: 6| Step: 8
Training loss: 5.149777690940967
Validation loss: 5.306931632885409

Epoch: 6| Step: 9
Training loss: 5.091453924068555
Validation loss: 5.30140469847743

Epoch: 6| Step: 10
Training loss: 5.766639186080694
Validation loss: 5.295910502706153

Epoch: 6| Step: 11
Training loss: 4.725873408252193
Validation loss: 5.290215190556064

Epoch: 6| Step: 12
Training loss: 5.310586203134533
Validation loss: 5.284287070383678

Epoch: 6| Step: 13
Training loss: 5.583184349387726
Validation loss: 5.278599361697521

Epoch: 9| Step: 0
Training loss: 6.031134253463504
Validation loss: 5.272942202820343

Epoch: 6| Step: 1
Training loss: 5.4592219592754025
Validation loss: 5.26668748408843

Epoch: 6| Step: 2
Training loss: 5.417595573395545
Validation loss: 5.260466421162703

Epoch: 6| Step: 3
Training loss: 6.004767431222976
Validation loss: 5.254287845788249

Epoch: 6| Step: 4
Training loss: 5.931544479279235
Validation loss: 5.247981425157488

Epoch: 6| Step: 5
Training loss: 4.950244535320721
Validation loss: 5.241642491093343

Epoch: 6| Step: 6
Training loss: 5.665893427133687
Validation loss: 5.235219995417685

Epoch: 6| Step: 7
Training loss: 5.214992609649718
Validation loss: 5.22867032718656

Epoch: 6| Step: 8
Training loss: 5.332482846317878
Validation loss: 5.222725517062789

Epoch: 6| Step: 9
Training loss: 5.413458103721416
Validation loss: 5.217218657875913

Epoch: 6| Step: 10
Training loss: 5.2306941057221765
Validation loss: 5.211500786529543

Epoch: 6| Step: 11
Training loss: 5.696273576102942
Validation loss: 5.205974359989226

Epoch: 6| Step: 12
Training loss: 3.845748877846488
Validation loss: 5.2002798249685815

Epoch: 6| Step: 13
Training loss: 4.374100074854684
Validation loss: 5.195366742991032

Epoch: 10| Step: 0
Training loss: 6.062242325488107
Validation loss: 5.190381180688205

Epoch: 6| Step: 1
Training loss: 4.441467016336174
Validation loss: 5.185612070711865

Epoch: 6| Step: 2
Training loss: 5.72958997607554
Validation loss: 5.181158210852453

Epoch: 6| Step: 3
Training loss: 5.484062164165772
Validation loss: 5.175865761888647

Epoch: 6| Step: 4
Training loss: 5.940230855854813
Validation loss: 5.170352953847387

Epoch: 6| Step: 5
Training loss: 4.658908980850098
Validation loss: 5.165457686622197

Epoch: 6| Step: 6
Training loss: 5.361936796619063
Validation loss: 5.160471041961055

Epoch: 6| Step: 7
Training loss: 4.553520039928267
Validation loss: 5.155575147450882

Epoch: 6| Step: 8
Training loss: 6.307604411588122
Validation loss: 5.150838520710066

Epoch: 6| Step: 9
Training loss: 4.442091594550365
Validation loss: 5.145499101458749

Epoch: 6| Step: 10
Training loss: 4.324167583821047
Validation loss: 5.1408667850544845

Epoch: 6| Step: 11
Training loss: 5.723237491813118
Validation loss: 5.135884921976254

Epoch: 6| Step: 12
Training loss: 5.444828225360881
Validation loss: 5.131741470546636

Epoch: 6| Step: 13
Training loss: 4.918080444521934
Validation loss: 5.126673603491354

Epoch: 11| Step: 0
Training loss: 5.410184806445393
Validation loss: 5.122058706691649

Epoch: 6| Step: 1
Training loss: 5.657865009206418
Validation loss: 5.116460151522408

Epoch: 6| Step: 2
Training loss: 5.61987529005376
Validation loss: 5.1116118128250125

Epoch: 6| Step: 3
Training loss: 5.07226167663256
Validation loss: 5.1059981920214454

Epoch: 6| Step: 4
Training loss: 4.070346707659759
Validation loss: 5.101463110492564

Epoch: 6| Step: 5
Training loss: 4.907898061177132
Validation loss: 5.096447563842494

Epoch: 6| Step: 6
Training loss: 4.563171337327648
Validation loss: 5.091860929904919

Epoch: 6| Step: 7
Training loss: 6.217307378701793
Validation loss: 5.087745419393087

Epoch: 6| Step: 8
Training loss: 4.222880284297415
Validation loss: 5.083261312172571

Epoch: 6| Step: 9
Training loss: 5.465830345069629
Validation loss: 5.078407287576643

Epoch: 6| Step: 10
Training loss: 5.152858289082214
Validation loss: 5.074318673136458

Epoch: 6| Step: 11
Training loss: 6.074042903403203
Validation loss: 5.070075563949889

Epoch: 6| Step: 12
Training loss: 5.366612654862386
Validation loss: 5.065222114294562

Epoch: 6| Step: 13
Training loss: 4.688439847186225
Validation loss: 5.060731869467776

Epoch: 12| Step: 0
Training loss: 5.241826916273182
Validation loss: 5.056603470979282

Epoch: 6| Step: 1
Training loss: 4.971612837309595
Validation loss: 5.051740759282383

Epoch: 6| Step: 2
Training loss: 4.440663244524351
Validation loss: 5.047382372536832

Epoch: 6| Step: 3
Training loss: 5.580791445153356
Validation loss: 5.0428453544099145

Epoch: 6| Step: 4
Training loss: 5.05400484124251
Validation loss: 5.038574163544896

Epoch: 6| Step: 5
Training loss: 5.497164255309597
Validation loss: 5.034134726904788

Epoch: 6| Step: 6
Training loss: 5.794419912642113
Validation loss: 5.030001941627447

Epoch: 6| Step: 7
Training loss: 4.80212949563744
Validation loss: 5.026171915478226

Epoch: 6| Step: 8
Training loss: 5.170955518600193
Validation loss: 5.020895148987607

Epoch: 6| Step: 9
Training loss: 4.563632145292162
Validation loss: 5.016412215681558

Epoch: 6| Step: 10
Training loss: 5.341632624302946
Validation loss: 5.013241178615876

Epoch: 6| Step: 11
Training loss: 5.275590380855696
Validation loss: 5.008902254125332

Epoch: 6| Step: 12
Training loss: 4.962939049350532
Validation loss: 5.004384248541632

Epoch: 6| Step: 13
Training loss: 5.269930836406472
Validation loss: 5.000095112213856

Epoch: 13| Step: 0
Training loss: 5.49739238305814
Validation loss: 4.995921060631288

Epoch: 6| Step: 1
Training loss: 4.196787541117992
Validation loss: 4.991011360132599

Epoch: 6| Step: 2
Training loss: 4.7683437909346384
Validation loss: 4.986274221875789

Epoch: 6| Step: 3
Training loss: 5.514097526354731
Validation loss: 4.983118614410541

Epoch: 6| Step: 4
Training loss: 6.241707144768544
Validation loss: 4.979543418942424

Epoch: 6| Step: 5
Training loss: 5.019685901678876
Validation loss: 4.974922520786589

Epoch: 6| Step: 6
Training loss: 5.109943883180892
Validation loss: 4.97060156657875

Epoch: 6| Step: 7
Training loss: 4.819056416824268
Validation loss: 4.967099025434759

Epoch: 6| Step: 8
Training loss: 4.829241280998254
Validation loss: 4.9632418829847165

Epoch: 6| Step: 9
Training loss: 4.5644581394388375
Validation loss: 4.95911197265317

Epoch: 6| Step: 10
Training loss: 5.257110140680904
Validation loss: 4.955490654480942

Epoch: 6| Step: 11
Training loss: 4.032847006826412
Validation loss: 4.950178471311648

Epoch: 6| Step: 12
Training loss: 4.835548989215145
Validation loss: 4.946433086501408

Epoch: 6| Step: 13
Training loss: 6.117980983518767
Validation loss: 4.94173159929215

Epoch: 14| Step: 0
Training loss: 5.560433850548287
Validation loss: 4.937439415153585

Epoch: 6| Step: 1
Training loss: 5.313299859363088
Validation loss: 4.933500803003696

Epoch: 6| Step: 2
Training loss: 4.192583101980997
Validation loss: 4.930396204897128

Epoch: 6| Step: 3
Training loss: 4.9520707317101555
Validation loss: 4.925092632371392

Epoch: 6| Step: 4
Training loss: 4.668247817887241
Validation loss: 4.921252337432505

Epoch: 6| Step: 5
Training loss: 5.342136072411682
Validation loss: 4.917510763006904

Epoch: 6| Step: 6
Training loss: 5.088554869068189
Validation loss: 4.912983738035887

Epoch: 6| Step: 7
Training loss: 4.767037404365947
Validation loss: 4.909029908074171

Epoch: 6| Step: 8
Training loss: 5.20953762118698
Validation loss: 4.904562139433179

Epoch: 6| Step: 9
Training loss: 4.579031896762925
Validation loss: 4.900850941605253

Epoch: 6| Step: 10
Training loss: 4.948321109772477
Validation loss: 4.89634118658847

Epoch: 6| Step: 11
Training loss: 5.261615075305642
Validation loss: 4.892635204517755

Epoch: 6| Step: 12
Training loss: 5.372585020249069
Validation loss: 4.889214845589775

Epoch: 6| Step: 13
Training loss: 5.081956562311479
Validation loss: 4.884888328283193

Epoch: 15| Step: 0
Training loss: 5.00223948870341
Validation loss: 4.8802445070058535

Epoch: 6| Step: 1
Training loss: 4.295500490384168
Validation loss: 4.875491109384612

Epoch: 6| Step: 2
Training loss: 5.0089660363366235
Validation loss: 4.872286734352655

Epoch: 6| Step: 3
Training loss: 4.184655889038902
Validation loss: 4.8685354098169435

Epoch: 6| Step: 4
Training loss: 4.945425505348865
Validation loss: 4.864139980504155

Epoch: 6| Step: 5
Training loss: 5.659681090951109
Validation loss: 4.8601148395811

Epoch: 6| Step: 6
Training loss: 4.895656155024822
Validation loss: 4.85656802765626

Epoch: 6| Step: 7
Training loss: 5.649336662850304
Validation loss: 4.852752654232524

Epoch: 6| Step: 8
Training loss: 5.416545788320961
Validation loss: 4.847901630364632

Epoch: 6| Step: 9
Training loss: 5.0310631000562935
Validation loss: 4.843487443268346

Epoch: 6| Step: 10
Training loss: 4.0617926348558635
Validation loss: 4.840191721626284

Epoch: 6| Step: 11
Training loss: 5.677466628641329
Validation loss: 4.836095459165496

Epoch: 6| Step: 12
Training loss: 5.272558520495603
Validation loss: 4.831861332110994

Epoch: 6| Step: 13
Training loss: 4.185585381370354
Validation loss: 4.827436544145165

Epoch: 16| Step: 0
Training loss: 5.425079542007598
Validation loss: 4.822656491253487

Epoch: 6| Step: 1
Training loss: 4.7922595555697125
Validation loss: 4.818659057286778

Epoch: 6| Step: 2
Training loss: 4.324844384012314
Validation loss: 4.814753198976585

Epoch: 6| Step: 3
Training loss: 5.233145953830896
Validation loss: 4.810998376847493

Epoch: 6| Step: 4
Training loss: 5.221301522944817
Validation loss: 4.806747185265929

Epoch: 6| Step: 5
Training loss: 5.042877598299958
Validation loss: 4.802752064158703

Epoch: 6| Step: 6
Training loss: 4.664541350915896
Validation loss: 4.798235374175975

Epoch: 6| Step: 7
Training loss: 4.848491095770076
Validation loss: 4.793483268150731

Epoch: 6| Step: 8
Training loss: 4.584261066292558
Validation loss: 4.788925758056642

Epoch: 6| Step: 9
Training loss: 4.902968360047209
Validation loss: 4.784729366853889

Epoch: 6| Step: 10
Training loss: 5.802400407967789
Validation loss: 4.780850695057162

Epoch: 6| Step: 11
Training loss: 4.634007934932312
Validation loss: 4.776246255412095

Epoch: 6| Step: 12
Training loss: 4.711311186334694
Validation loss: 4.7722791565970235

Epoch: 6| Step: 13
Training loss: 4.513625814482639
Validation loss: 4.767679940855155

Epoch: 17| Step: 0
Training loss: 4.709253316925998
Validation loss: 4.763026128160785

Epoch: 6| Step: 1
Training loss: 4.338618698749035
Validation loss: 4.759004757749399

Epoch: 6| Step: 2
Training loss: 5.380269328753604
Validation loss: 4.755007747613082

Epoch: 6| Step: 3
Training loss: 4.163149277278828
Validation loss: 4.751008077362074

Epoch: 6| Step: 4
Training loss: 4.592830228525396
Validation loss: 4.747397613385554

Epoch: 6| Step: 5
Training loss: 4.543041592749526
Validation loss: 4.74291091755504

Epoch: 6| Step: 6
Training loss: 5.051412615217617
Validation loss: 4.7387578671583865

Epoch: 6| Step: 7
Training loss: 5.070074560757045
Validation loss: 4.734355964244683

Epoch: 6| Step: 8
Training loss: 4.450992756378512
Validation loss: 4.730071710818524

Epoch: 6| Step: 9
Training loss: 5.012822113722294
Validation loss: 4.725818047863981

Epoch: 6| Step: 10
Training loss: 5.513026330434887
Validation loss: 4.72175537806124

Epoch: 6| Step: 11
Training loss: 4.848863031889679
Validation loss: 4.7173001923166975

Epoch: 6| Step: 12
Training loss: 5.093853908485324
Validation loss: 4.713187688810152

Epoch: 6| Step: 13
Training loss: 5.09251903801919
Validation loss: 4.7091232863677

Epoch: 18| Step: 0
Training loss: 4.972124405413171
Validation loss: 4.704856883192177

Epoch: 6| Step: 1
Training loss: 4.60820587331443
Validation loss: 4.700547873576858

Epoch: 6| Step: 2
Training loss: 4.196903431470152
Validation loss: 4.696897995402444

Epoch: 6| Step: 3
Training loss: 4.832466617790603
Validation loss: 4.692619478130346

Epoch: 6| Step: 4
Training loss: 4.710813403669724
Validation loss: 4.688063795304454

Epoch: 6| Step: 5
Training loss: 5.578093883951204
Validation loss: 4.68414632566947

Epoch: 6| Step: 6
Training loss: 5.803488688455527
Validation loss: 4.6797004746229085

Epoch: 6| Step: 7
Training loss: 5.635746502581306
Validation loss: 4.675393199194869

Epoch: 6| Step: 8
Training loss: 4.741197561290348
Validation loss: 4.671546337598095

Epoch: 6| Step: 9
Training loss: 4.431256482290415
Validation loss: 4.666634162153848

Epoch: 6| Step: 10
Training loss: 4.815822494784202
Validation loss: 4.6627206240520795

Epoch: 6| Step: 11
Training loss: 4.538205825932785
Validation loss: 4.658434771330151

Epoch: 6| Step: 12
Training loss: 3.820756071273951
Validation loss: 4.654264602837391

Epoch: 6| Step: 13
Training loss: 4.14019796220661
Validation loss: 4.6498720664196584

Epoch: 19| Step: 0
Training loss: 5.090202359896634
Validation loss: 4.646340580548969

Epoch: 6| Step: 1
Training loss: 3.7058790564856308
Validation loss: 4.641858143626687

Epoch: 6| Step: 2
Training loss: 4.706633111727861
Validation loss: 4.63784710321146

Epoch: 6| Step: 3
Training loss: 4.4581974519837075
Validation loss: 4.633816434982378

Epoch: 6| Step: 4
Training loss: 4.7208396882398524
Validation loss: 4.630106641284183

Epoch: 6| Step: 5
Training loss: 4.508977623744188
Validation loss: 4.625930108375401

Epoch: 6| Step: 6
Training loss: 5.878164534813554
Validation loss: 4.622302359768656

Epoch: 6| Step: 7
Training loss: 5.323371444753631
Validation loss: 4.6181267537657344

Epoch: 6| Step: 8
Training loss: 4.68401156002348
Validation loss: 4.613660400038735

Epoch: 6| Step: 9
Training loss: 4.305775804252848
Validation loss: 4.610149805499418

Epoch: 6| Step: 10
Training loss: 5.3533659854588285
Validation loss: 4.605771172117085

Epoch: 6| Step: 11
Training loss: 4.189194066145435
Validation loss: 4.601149086550736

Epoch: 6| Step: 12
Training loss: 3.601239568502564
Validation loss: 4.597180078523947

Epoch: 6| Step: 13
Training loss: 5.359198831493241
Validation loss: 4.593318322069049

Epoch: 20| Step: 0
Training loss: 4.586497907823754
Validation loss: 4.589036162191181

Epoch: 6| Step: 1
Training loss: 4.607717028353511
Validation loss: 4.585274383588241

Epoch: 6| Step: 2
Training loss: 5.37805940365284
Validation loss: 4.58091798197663

Epoch: 6| Step: 3
Training loss: 4.454088608736097
Validation loss: 4.577113954525271

Epoch: 6| Step: 4
Training loss: 4.845463800266932
Validation loss: 4.5730092148622985

Epoch: 6| Step: 5
Training loss: 5.264936181358176
Validation loss: 4.5695783324307175

Epoch: 6| Step: 6
Training loss: 3.5588191240549523
Validation loss: 4.565013837455621

Epoch: 6| Step: 7
Training loss: 4.266013103338006
Validation loss: 4.56109242086315

Epoch: 6| Step: 8
Training loss: 4.294264565720234
Validation loss: 4.557454284673053

Epoch: 6| Step: 9
Training loss: 5.323966901256415
Validation loss: 4.553188035712327

Epoch: 6| Step: 10
Training loss: 5.685198978642508
Validation loss: 4.549117244422415

Epoch: 6| Step: 11
Training loss: 4.557213634004558
Validation loss: 4.545241719089624

Epoch: 6| Step: 12
Training loss: 4.293881681108298
Validation loss: 4.541566999315909

Epoch: 6| Step: 13
Training loss: 4.097400231813823
Validation loss: 4.537660190637529

Epoch: 21| Step: 0
Training loss: 4.3640612500138065
Validation loss: 4.534299048241825

Epoch: 6| Step: 1
Training loss: 5.514543032766133
Validation loss: 4.530326293101925

Epoch: 6| Step: 2
Training loss: 4.348255482906784
Validation loss: 4.526135050428838

Epoch: 6| Step: 3
Training loss: 4.615982337296409
Validation loss: 4.521882276830154

Epoch: 6| Step: 4
Training loss: 4.124030721821947
Validation loss: 4.517718893327158

Epoch: 6| Step: 5
Training loss: 5.322258278377957
Validation loss: 4.513535382374799

Epoch: 6| Step: 6
Training loss: 4.710126259765715
Validation loss: 4.5094774368082025

Epoch: 6| Step: 7
Training loss: 4.826739757539422
Validation loss: 4.505359601548125

Epoch: 6| Step: 8
Training loss: 4.763245035202457
Validation loss: 4.501320821693472

Epoch: 6| Step: 9
Training loss: 4.48553898289169
Validation loss: 4.497034084465457

Epoch: 6| Step: 10
Training loss: 4.027943519309944
Validation loss: 4.493370612430347

Epoch: 6| Step: 11
Training loss: 3.341442131686434
Validation loss: 4.489850607909308

Epoch: 6| Step: 12
Training loss: 4.515100151632571
Validation loss: 4.485427360799503

Epoch: 6| Step: 13
Training loss: 5.464800122123028
Validation loss: 4.481733583173235

Epoch: 22| Step: 0
Training loss: 4.300525792821915
Validation loss: 4.477633877869697

Epoch: 6| Step: 1
Training loss: 5.6265077053835295
Validation loss: 4.47364332920524

Epoch: 6| Step: 2
Training loss: 3.263219065732405
Validation loss: 4.469639029467755

Epoch: 6| Step: 3
Training loss: 4.781725292641976
Validation loss: 4.466703857912313

Epoch: 6| Step: 4
Training loss: 4.916760503013559
Validation loss: 4.462199747935366

Epoch: 6| Step: 5
Training loss: 5.354523445245486
Validation loss: 4.458186203617462

Epoch: 6| Step: 6
Training loss: 5.158751094994545
Validation loss: 4.453646659412321

Epoch: 6| Step: 7
Training loss: 4.347632340385176
Validation loss: 4.449408817669119

Epoch: 6| Step: 8
Training loss: 4.022616345208947
Validation loss: 4.4453311644901445

Epoch: 6| Step: 9
Training loss: 4.574845633482121
Validation loss: 4.441634674147902

Epoch: 6| Step: 10
Training loss: 4.256486094644427
Validation loss: 4.437183852418236

Epoch: 6| Step: 11
Training loss: 3.7569991597633345
Validation loss: 4.433383231969736

Epoch: 6| Step: 12
Training loss: 4.065194043622602
Validation loss: 4.429132156500791

Epoch: 6| Step: 13
Training loss: 5.100333610543802
Validation loss: 4.424822773949416

Epoch: 23| Step: 0
Training loss: 4.0732420704342465
Validation loss: 4.420751835643823

Epoch: 6| Step: 1
Training loss: 4.466062791532398
Validation loss: 4.416994238647821

Epoch: 6| Step: 2
Training loss: 4.581790016894176
Validation loss: 4.413159267319689

Epoch: 6| Step: 3
Training loss: 4.800133806588857
Validation loss: 4.409497049878797

Epoch: 6| Step: 4
Training loss: 4.558283281254903
Validation loss: 4.405378918409221

Epoch: 6| Step: 5
Training loss: 5.042629664904803
Validation loss: 4.401255705856009

Epoch: 6| Step: 6
Training loss: 3.904821027691382
Validation loss: 4.3972574641993045

Epoch: 6| Step: 7
Training loss: 4.343668765399344
Validation loss: 4.393423453397016

Epoch: 6| Step: 8
Training loss: 4.122534275039682
Validation loss: 4.389646409783551

Epoch: 6| Step: 9
Training loss: 6.194274892420508
Validation loss: 4.385722073441128

Epoch: 6| Step: 10
Training loss: 4.690034715080701
Validation loss: 4.381401247324346

Epoch: 6| Step: 11
Training loss: 3.7505843660899303
Validation loss: 4.377154609914466

Epoch: 6| Step: 12
Training loss: 4.411821454749045
Validation loss: 4.372982404607603

Epoch: 6| Step: 13
Training loss: 3.8582972206968846
Validation loss: 4.368918488127247

Epoch: 24| Step: 0
Training loss: 4.501254224830855
Validation loss: 4.364703769281615

Epoch: 6| Step: 1
Training loss: 4.807564719047684
Validation loss: 4.360511658945016

Epoch: 6| Step: 2
Training loss: 4.530841256483732
Validation loss: 4.356178123286154

Epoch: 6| Step: 3
Training loss: 4.2627844662426515
Validation loss: 4.352075990506642

Epoch: 6| Step: 4
Training loss: 4.858366147034653
Validation loss: 4.348120414128676

Epoch: 6| Step: 5
Training loss: 5.158801747851221
Validation loss: 4.343624616318144

Epoch: 6| Step: 6
Training loss: 5.317916621937202
Validation loss: 4.339398150339468

Epoch: 6| Step: 7
Training loss: 4.495772177086125
Validation loss: 4.335041271982689

Epoch: 6| Step: 8
Training loss: 4.3420057568259365
Validation loss: 4.330754148312205

Epoch: 6| Step: 9
Training loss: 4.06246079646048
Validation loss: 4.326773716014217

Epoch: 6| Step: 10
Training loss: 3.2863014211944748
Validation loss: 4.3224851952132495

Epoch: 6| Step: 11
Training loss: 4.74839032655903
Validation loss: 4.318628940826958

Epoch: 6| Step: 12
Training loss: 3.747869522168587
Validation loss: 4.314100972683008

Epoch: 6| Step: 13
Training loss: 4.002517861416365
Validation loss: 4.310183838348111

Epoch: 25| Step: 0
Training loss: 4.120118923507871
Validation loss: 4.306194726951885

Epoch: 6| Step: 1
Training loss: 4.648402622637014
Validation loss: 4.301979334623322

Epoch: 6| Step: 2
Training loss: 5.045107505416603
Validation loss: 4.297508979034956

Epoch: 6| Step: 3
Training loss: 3.04951089157859
Validation loss: 4.2937710179865345

Epoch: 6| Step: 4
Training loss: 4.373617117172246
Validation loss: 4.289715715427941

Epoch: 6| Step: 5
Training loss: 3.7518753448796276
Validation loss: 4.285536094018908

Epoch: 6| Step: 6
Training loss: 4.920781671100504
Validation loss: 4.281484815557615

Epoch: 6| Step: 7
Training loss: 4.324018933814957
Validation loss: 4.2777594005856034

Epoch: 6| Step: 8
Training loss: 4.503054112254329
Validation loss: 4.273775058318444

Epoch: 6| Step: 9
Training loss: 4.728759658484965
Validation loss: 4.269652834618488

Epoch: 6| Step: 10
Training loss: 4.807972946192435
Validation loss: 4.265813355252213

Epoch: 6| Step: 11
Training loss: 3.8045965101574883
Validation loss: 4.261546363689056

Epoch: 6| Step: 12
Training loss: 4.584581008786195
Validation loss: 4.257195776274913

Epoch: 6| Step: 13
Training loss: 4.638705591982724
Validation loss: 4.253134805526473

Epoch: 26| Step: 0
Training loss: 4.364021259007828
Validation loss: 4.248860711374936

Epoch: 6| Step: 1
Training loss: 4.965119577064663
Validation loss: 4.244683100086257

Epoch: 6| Step: 2
Training loss: 4.125017108303774
Validation loss: 4.240153368869149

Epoch: 6| Step: 3
Training loss: 4.481444567682168
Validation loss: 4.235753284343125

Epoch: 6| Step: 4
Training loss: 4.521721865388193
Validation loss: 4.231390113332604

Epoch: 6| Step: 5
Training loss: 4.838704687136466
Validation loss: 4.227468058658895

Epoch: 6| Step: 6
Training loss: 4.75776319055421
Validation loss: 4.222861822242954

Epoch: 6| Step: 7
Training loss: 4.437475070077419
Validation loss: 4.2185468648348206

Epoch: 6| Step: 8
Training loss: 3.256419078222687
Validation loss: 4.214172705827735

Epoch: 6| Step: 9
Training loss: 4.6040591864605345
Validation loss: 4.209791113533324

Epoch: 6| Step: 10
Training loss: 3.8258002248195724
Validation loss: 4.205743590842944

Epoch: 6| Step: 11
Training loss: 3.9515833807740868
Validation loss: 4.201405756192288

Epoch: 6| Step: 12
Training loss: 4.363083659917318
Validation loss: 4.197260550567934

Epoch: 6| Step: 13
Training loss: 4.148599107830873
Validation loss: 4.193068052541895

Epoch: 27| Step: 0
Training loss: 4.698221381455957
Validation loss: 4.188895206604052

Epoch: 6| Step: 1
Training loss: 4.00017284973522
Validation loss: 4.184763246567211

Epoch: 6| Step: 2
Training loss: 4.0053979690693655
Validation loss: 4.180411093755127

Epoch: 6| Step: 3
Training loss: 5.015785856430512
Validation loss: 4.1763889499793

Epoch: 6| Step: 4
Training loss: 3.582952715745638
Validation loss: 4.1719001454942095

Epoch: 6| Step: 5
Training loss: 5.29908908717419
Validation loss: 4.167806310565906

Epoch: 6| Step: 6
Training loss: 4.371616908343015
Validation loss: 4.163217560222565

Epoch: 6| Step: 7
Training loss: 5.370551641676401
Validation loss: 4.158765906167921

Epoch: 6| Step: 8
Training loss: 3.719133629765767
Validation loss: 4.154280709882503

Epoch: 6| Step: 9
Training loss: 3.82777870324623
Validation loss: 4.149843216044806

Epoch: 6| Step: 10
Training loss: 4.182923962344506
Validation loss: 4.145378579865059

Epoch: 6| Step: 11
Training loss: 4.500292874448345
Validation loss: 4.141029827553084

Epoch: 6| Step: 12
Training loss: 3.129645747164778
Validation loss: 4.136423726618737

Epoch: 6| Step: 13
Training loss: 3.740315456856129
Validation loss: 4.1321083050603775

Epoch: 28| Step: 0
Training loss: 4.725243149409872
Validation loss: 4.127855064235595

Epoch: 6| Step: 1
Training loss: 4.228520586746511
Validation loss: 4.123228598281907

Epoch: 6| Step: 2
Training loss: 2.973878145667835
Validation loss: 4.1188244494056265

Epoch: 6| Step: 3
Training loss: 4.062467839040367
Validation loss: 4.1143313882042225

Epoch: 6| Step: 4
Training loss: 3.9074581871797562
Validation loss: 4.109962663101927

Epoch: 6| Step: 5
Training loss: 4.116275693626157
Validation loss: 4.106245563258886

Epoch: 6| Step: 6
Training loss: 3.6977479421602006
Validation loss: 4.102057920538341

Epoch: 6| Step: 7
Training loss: 4.8361903110665025
Validation loss: 4.098142175072672

Epoch: 6| Step: 8
Training loss: 4.332929788041309
Validation loss: 4.094236466330223

Epoch: 6| Step: 9
Training loss: 4.006075774643138
Validation loss: 4.089895807352106

Epoch: 6| Step: 10
Training loss: 4.2299330945506695
Validation loss: 4.085798758393487

Epoch: 6| Step: 11
Training loss: 4.361573898695206
Validation loss: 4.081653865909922

Epoch: 6| Step: 12
Training loss: 4.92436363640123
Validation loss: 4.077387444653744

Epoch: 6| Step: 13
Training loss: 4.45826269551347
Validation loss: 4.073139031755645

Epoch: 29| Step: 0
Training loss: 3.370553372281826
Validation loss: 4.0684547016356305

Epoch: 6| Step: 1
Training loss: 4.514524121050942
Validation loss: 4.064129175061854

Epoch: 6| Step: 2
Training loss: 4.581966520016461
Validation loss: 4.059651398248513

Epoch: 6| Step: 3
Training loss: 5.234648284610364
Validation loss: 4.055231193885024

Epoch: 6| Step: 4
Training loss: 3.497821402298569
Validation loss: 4.050790235557878

Epoch: 6| Step: 5
Training loss: 4.052443278325787
Validation loss: 4.046096726921181

Epoch: 6| Step: 6
Training loss: 3.576451872401678
Validation loss: 4.041712586971165

Epoch: 6| Step: 7
Training loss: 4.888563215120322
Validation loss: 4.037494170476998

Epoch: 6| Step: 8
Training loss: 3.7309835827664863
Validation loss: 4.032927309569974

Epoch: 6| Step: 9
Training loss: 4.425655406970814
Validation loss: 4.02859991532805

Epoch: 6| Step: 10
Training loss: 3.316908296252996
Validation loss: 4.024328593613373

Epoch: 6| Step: 11
Training loss: 4.618640548379655
Validation loss: 4.0200926867755316

Epoch: 6| Step: 12
Training loss: 4.217296886968821
Validation loss: 4.0156065350415995

Epoch: 6| Step: 13
Training loss: 3.8396368582201794
Validation loss: 4.011207416736739

Epoch: 30| Step: 0
Training loss: 4.770080684723219
Validation loss: 4.007001213466409

Epoch: 6| Step: 1
Training loss: 4.424166998610224
Validation loss: 4.002402418616153

Epoch: 6| Step: 2
Training loss: 3.718790006021679
Validation loss: 3.997913253382501

Epoch: 6| Step: 3
Training loss: 4.773136210571407
Validation loss: 3.9936950982289576

Epoch: 6| Step: 4
Training loss: 3.828401765744559
Validation loss: 3.9890749668036602

Epoch: 6| Step: 5
Training loss: 4.1657567111438984
Validation loss: 3.984619721520385

Epoch: 6| Step: 6
Training loss: 4.45043649997202
Validation loss: 3.980064244255012

Epoch: 6| Step: 7
Training loss: 4.396403464035018
Validation loss: 3.975630735343127

Epoch: 6| Step: 8
Training loss: 3.8984970669218595
Validation loss: 3.9710961363302

Epoch: 6| Step: 9
Training loss: 4.244654940722025
Validation loss: 3.966596564840845

Epoch: 6| Step: 10
Training loss: 3.807505353296415
Validation loss: 3.962456526653189

Epoch: 6| Step: 11
Training loss: 3.2212798907455222
Validation loss: 3.9583394836913395

Epoch: 6| Step: 12
Training loss: 3.7019503376173293
Validation loss: 3.953711083029985

Epoch: 6| Step: 13
Training loss: 3.871827580467164
Validation loss: 3.9494774517042357

Epoch: 31| Step: 0
Training loss: 4.808444605729298
Validation loss: 3.9455869673635138

Epoch: 6| Step: 1
Training loss: 4.503062160034955
Validation loss: 3.9407817344543727

Epoch: 6| Step: 2
Training loss: 4.277726331349163
Validation loss: 3.9364259254001097

Epoch: 6| Step: 3
Training loss: 3.7687314464814605
Validation loss: 3.9317335056856333

Epoch: 6| Step: 4
Training loss: 3.793551902060966
Validation loss: 3.927175215532461

Epoch: 6| Step: 5
Training loss: 3.4563012338328005
Validation loss: 3.922808755101834

Epoch: 6| Step: 6
Training loss: 4.115074469632962
Validation loss: 3.9188820207777972

Epoch: 6| Step: 7
Training loss: 4.466445435316563
Validation loss: 3.91425954966109

Epoch: 6| Step: 8
Training loss: 3.949595447538741
Validation loss: 3.9096543189672377

Epoch: 6| Step: 9
Training loss: 3.3749652436903945
Validation loss: 3.90544714242862

Epoch: 6| Step: 10
Training loss: 4.265512765379015
Validation loss: 3.9015299648913877

Epoch: 6| Step: 11
Training loss: 4.125202751956682
Validation loss: 3.897248091143194

Epoch: 6| Step: 12
Training loss: 3.951616082180771
Validation loss: 3.8931252081864804

Epoch: 6| Step: 13
Training loss: 3.607837167740621
Validation loss: 3.888844645717778

Epoch: 32| Step: 0
Training loss: 4.287402111303962
Validation loss: 3.884543244863127

Epoch: 6| Step: 1
Training loss: 4.260289918588838
Validation loss: 3.880303783224164

Epoch: 6| Step: 2
Training loss: 3.616109534976134
Validation loss: 3.8759324582359382

Epoch: 6| Step: 3
Training loss: 4.375965774750985
Validation loss: 3.8715126383228355

Epoch: 6| Step: 4
Training loss: 3.9560314244641255
Validation loss: 3.867018077491429

Epoch: 6| Step: 5
Training loss: 3.4933839664235644
Validation loss: 3.8627440333305603

Epoch: 6| Step: 6
Training loss: 3.615434060952665
Validation loss: 3.858588258191387

Epoch: 6| Step: 7
Training loss: 4.78970546669016
Validation loss: 3.8544881669403592

Epoch: 6| Step: 8
Training loss: 4.023101377798591
Validation loss: 3.850096242287972

Epoch: 6| Step: 9
Training loss: 3.8030290376817
Validation loss: 3.8459245893425402

Epoch: 6| Step: 10
Training loss: 3.1499816288488036
Validation loss: 3.84172784393873

Epoch: 6| Step: 11
Training loss: 4.234067110361377
Validation loss: 3.837631649115905

Epoch: 6| Step: 12
Training loss: 4.103305526213601
Validation loss: 3.8333596698574985

Epoch: 6| Step: 13
Training loss: 3.899785666811743
Validation loss: 3.8291372816240257

Epoch: 33| Step: 0
Training loss: 4.012116201708972
Validation loss: 3.8249334824041163

Epoch: 6| Step: 1
Training loss: 3.919664466666758
Validation loss: 3.8208954931185835

Epoch: 6| Step: 2
Training loss: 4.050030395016996
Validation loss: 3.816591745721238

Epoch: 6| Step: 3
Training loss: 3.8568065915541787
Validation loss: 3.8124073413366077

Epoch: 6| Step: 4
Training loss: 4.144962903122502
Validation loss: 3.8079681978260136

Epoch: 6| Step: 5
Training loss: 3.734413944823405
Validation loss: 3.8033869280926935

Epoch: 6| Step: 6
Training loss: 3.8444664760342966
Validation loss: 3.7993743163874463

Epoch: 6| Step: 7
Training loss: 4.346336198620676
Validation loss: 3.7950562567681274

Epoch: 6| Step: 8
Training loss: 3.749899036319881
Validation loss: 3.790897011805223

Epoch: 6| Step: 9
Training loss: 3.7634838554164767
Validation loss: 3.7864599984369547

Epoch: 6| Step: 10
Training loss: 4.386037364294372
Validation loss: 3.782374212270753

Epoch: 6| Step: 11
Training loss: 4.2368150275600645
Validation loss: 3.7781444228277548

Epoch: 6| Step: 12
Training loss: 3.620632434417873
Validation loss: 3.773824183604765

Epoch: 6| Step: 13
Training loss: 3.251967054915736
Validation loss: 3.7693902234724237

Epoch: 34| Step: 0
Training loss: 3.635474495122679
Validation loss: 3.765285576893948

Epoch: 6| Step: 1
Training loss: 4.61806855291515
Validation loss: 3.761121977848775

Epoch: 6| Step: 2
Training loss: 3.5128820951348265
Validation loss: 3.7569623740272355

Epoch: 6| Step: 3
Training loss: 3.108548308464832
Validation loss: 3.752510417302815

Epoch: 6| Step: 4
Training loss: 4.208248376775635
Validation loss: 3.7483483385933742

Epoch: 6| Step: 5
Training loss: 4.503380459403113
Validation loss: 3.7442447579551703

Epoch: 6| Step: 6
Training loss: 3.1403703728694783
Validation loss: 3.739890543752051

Epoch: 6| Step: 7
Training loss: 3.6455160529725377
Validation loss: 3.7358716787945365

Epoch: 6| Step: 8
Training loss: 4.223332607647583
Validation loss: 3.73189755118354

Epoch: 6| Step: 9
Training loss: 3.7975119225300418
Validation loss: 3.727746121088479

Epoch: 6| Step: 10
Training loss: 3.973586132106309
Validation loss: 3.723722974191054

Epoch: 6| Step: 11
Training loss: 3.8335688283703773
Validation loss: 3.7194685255174376

Epoch: 6| Step: 12
Training loss: 3.8702100867288176
Validation loss: 3.7153680206145316

Epoch: 6| Step: 13
Training loss: 3.8373097375679346
Validation loss: 3.7112852984289746

Epoch: 35| Step: 0
Training loss: 3.9848512851051665
Validation loss: 3.706803095408589

Epoch: 6| Step: 1
Training loss: 3.8941348992381295
Validation loss: 3.7025186549302087

Epoch: 6| Step: 2
Training loss: 3.7876467232564486
Validation loss: 3.6981345887065475

Epoch: 6| Step: 3
Training loss: 3.8677669823094774
Validation loss: 3.693975807684889

Epoch: 6| Step: 4
Training loss: 3.75142871343276
Validation loss: 3.689571143800979

Epoch: 6| Step: 5
Training loss: 3.7296710534566166
Validation loss: 3.6853791943174863

Epoch: 6| Step: 6
Training loss: 3.6544270984112597
Validation loss: 3.6812722154172586

Epoch: 6| Step: 7
Training loss: 3.620219531489321
Validation loss: 3.67697553323534

Epoch: 6| Step: 8
Training loss: 3.3925271038639706
Validation loss: 3.6729577057713603

Epoch: 6| Step: 9
Training loss: 3.9753013064791607
Validation loss: 3.6688135032205125

Epoch: 6| Step: 10
Training loss: 4.349374765647447
Validation loss: 3.664677896990983

Epoch: 6| Step: 11
Training loss: 3.846854468135132
Validation loss: 3.660401294366947

Epoch: 6| Step: 12
Training loss: 3.5423395003934
Validation loss: 3.656171205546476

Epoch: 6| Step: 13
Training loss: 3.9460021974119552
Validation loss: 3.6519907734891195

Epoch: 36| Step: 0
Training loss: 3.773694773999939
Validation loss: 3.64774406862817

Epoch: 6| Step: 1
Training loss: 3.790653736228863
Validation loss: 3.6434466951701747

Epoch: 6| Step: 2
Training loss: 3.3679008701804607
Validation loss: 3.639253677319137

Epoch: 6| Step: 3
Training loss: 3.956024192404373
Validation loss: 3.6351968576751257

Epoch: 6| Step: 4
Training loss: 4.156263078941475
Validation loss: 3.6309897385878336

Epoch: 6| Step: 5
Training loss: 3.2738253925814127
Validation loss: 3.6268209509662643

Epoch: 6| Step: 6
Training loss: 3.6851184719301284
Validation loss: 3.6227251566364416

Epoch: 6| Step: 7
Training loss: 3.772967891812291
Validation loss: 3.6186660809578512

Epoch: 6| Step: 8
Training loss: 3.512837300786137
Validation loss: 3.6144585198538355

Epoch: 6| Step: 9
Training loss: 4.025936202641475
Validation loss: 3.6104056027802915

Epoch: 6| Step: 10
Training loss: 3.019947334234538
Validation loss: 3.6062565001853923

Epoch: 6| Step: 11
Training loss: 4.165563259253868
Validation loss: 3.6022094013193304

Epoch: 6| Step: 12
Training loss: 3.635531419110667
Validation loss: 3.5980561483206595

Epoch: 6| Step: 13
Training loss: 4.257317022489689
Validation loss: 3.5940941908389763

Epoch: 37| Step: 0
Training loss: 4.124572500560261
Validation loss: 3.589910850409738

Epoch: 6| Step: 1
Training loss: 3.9965011075821404
Validation loss: 3.585752572448853

Epoch: 6| Step: 2
Training loss: 3.226871060079548
Validation loss: 3.5815069715567027

Epoch: 6| Step: 3
Training loss: 3.3080538294516617
Validation loss: 3.5774362225982186

Epoch: 6| Step: 4
Training loss: 3.2440959415194865
Validation loss: 3.5733784561605777

Epoch: 6| Step: 5
Training loss: 4.918352107588845
Validation loss: 3.569487584237245

Epoch: 6| Step: 6
Training loss: 2.782567858558294
Validation loss: 3.565306912943665

Epoch: 6| Step: 7
Training loss: 3.7392991293584417
Validation loss: 3.561325325741103

Epoch: 6| Step: 8
Training loss: 4.069115519475927
Validation loss: 3.5571262587391486

Epoch: 6| Step: 9
Training loss: 3.9491923073808737
Validation loss: 3.5530757170351297

Epoch: 6| Step: 10
Training loss: 2.883935559689045
Validation loss: 3.5487226023685197

Epoch: 6| Step: 11
Training loss: 4.02577393477649
Validation loss: 3.544780678647514

Epoch: 6| Step: 12
Training loss: 3.3682726463451838
Validation loss: 3.540686060218177

Epoch: 6| Step: 13
Training loss: 3.612481699966489
Validation loss: 3.5364889032150333

Epoch: 38| Step: 0
Training loss: 4.341428726519782
Validation loss: 3.532392423935086

Epoch: 6| Step: 1
Training loss: 3.8151854765714983
Validation loss: 3.528270556024005

Epoch: 6| Step: 2
Training loss: 4.680248093183215
Validation loss: 3.5241691805172914

Epoch: 6| Step: 3
Training loss: 3.6543741223128863
Validation loss: 3.5196938034380962

Epoch: 6| Step: 4
Training loss: 3.1942705540159584
Validation loss: 3.515486085761012

Epoch: 6| Step: 5
Training loss: 2.938780647484729
Validation loss: 3.5112296199784296

Epoch: 6| Step: 6
Training loss: 2.5027031589476687
Validation loss: 3.5070788686103826

Epoch: 6| Step: 7
Training loss: 3.3874688291347237
Validation loss: 3.5033793710671435

Epoch: 6| Step: 8
Training loss: 3.5081570802272153
Validation loss: 3.4995502001243106

Epoch: 6| Step: 9
Training loss: 4.141923348182194
Validation loss: 3.4959995022648997

Epoch: 6| Step: 10
Training loss: 4.140592524563093
Validation loss: 3.49193595418354

Epoch: 6| Step: 11
Training loss: 3.233415986672778
Validation loss: 3.487910234941094

Epoch: 6| Step: 12
Training loss: 3.6015722973870266
Validation loss: 3.4837785332894486

Epoch: 6| Step: 13
Training loss: 3.2948495148026584
Validation loss: 3.480151800301429

Epoch: 39| Step: 0
Training loss: 3.6119553891338776
Validation loss: 3.4761195439954498

Epoch: 6| Step: 1
Training loss: 3.919165294489349
Validation loss: 3.472238544849601

Epoch: 6| Step: 2
Training loss: 3.312921749113171
Validation loss: 3.468195919655267

Epoch: 6| Step: 3
Training loss: 3.5454752172298725
Validation loss: 3.464290719550688

Epoch: 6| Step: 4
Training loss: 3.758437138468052
Validation loss: 3.460156928933936

Epoch: 6| Step: 5
Training loss: 2.6600011928813814
Validation loss: 3.4562027967654596

Epoch: 6| Step: 6
Training loss: 3.5953214443846533
Validation loss: 3.4524422455343706

Epoch: 6| Step: 7
Training loss: 3.9785508616351963
Validation loss: 3.4487175064242988

Epoch: 6| Step: 8
Training loss: 3.4189183948615467
Validation loss: 3.444912934146595

Epoch: 6| Step: 9
Training loss: 3.809045070414592
Validation loss: 3.4411691677079306

Epoch: 6| Step: 10
Training loss: 3.5139982401670284
Validation loss: 3.4371170524219217

Epoch: 6| Step: 11
Training loss: 3.479764479636551
Validation loss: 3.4333245089025577

Epoch: 6| Step: 12
Training loss: 3.1828010180588797
Validation loss: 3.4296149823307256

Epoch: 6| Step: 13
Training loss: 4.222510350306707
Validation loss: 3.4258202927908106

Epoch: 40| Step: 0
Training loss: 3.7559318674345064
Validation loss: 3.4219997853558293

Epoch: 6| Step: 1
Training loss: 3.511105221798407
Validation loss: 3.418102489943003

Epoch: 6| Step: 2
Training loss: 3.126273544204563
Validation loss: 3.414228073050825

Epoch: 6| Step: 3
Training loss: 3.084465660919426
Validation loss: 3.410381273300773

Epoch: 6| Step: 4
Training loss: 3.8492123627962913
Validation loss: 3.4066334079928

Epoch: 6| Step: 5
Training loss: 3.5969531835415713
Validation loss: 3.4028851749486786

Epoch: 6| Step: 6
Training loss: 2.8135158823397854
Validation loss: 3.3991929540968275

Epoch: 6| Step: 7
Training loss: 4.3615334475711895
Validation loss: 3.3954498839024287

Epoch: 6| Step: 8
Training loss: 3.997169446799295
Validation loss: 3.3915083945896556

Epoch: 6| Step: 9
Training loss: 3.586344377958488
Validation loss: 3.387461603188706

Epoch: 6| Step: 10
Training loss: 3.9889286124879324
Validation loss: 3.383720176329542

Epoch: 6| Step: 11
Training loss: 2.9866519250960075
Validation loss: 3.379559674596219

Epoch: 6| Step: 12
Training loss: 2.4899831368361744
Validation loss: 3.3757498814659246

Epoch: 6| Step: 13
Training loss: 3.8663195936597616
Validation loss: 3.3722276721793696

Epoch: 41| Step: 0
Training loss: 3.2246886347012613
Validation loss: 3.3685571137589467

Epoch: 6| Step: 1
Training loss: 3.734044399551219
Validation loss: 3.364839140593123

Epoch: 6| Step: 2
Training loss: 4.203073494180818
Validation loss: 3.3610367797394836

Epoch: 6| Step: 3
Training loss: 3.668416963762371
Validation loss: 3.3569625590606424

Epoch: 6| Step: 4
Training loss: 3.7856961427238427
Validation loss: 3.3530966945661063

Epoch: 6| Step: 5
Training loss: 3.198171367297958
Validation loss: 3.3491585030463744

Epoch: 6| Step: 6
Training loss: 3.478197583369162
Validation loss: 3.345070907799167

Epoch: 6| Step: 7
Training loss: 2.997739735132502
Validation loss: 3.3412633187898737

Epoch: 6| Step: 8
Training loss: 2.5493098129014764
Validation loss: 3.337603400982471

Epoch: 6| Step: 9
Training loss: 3.859335957070985
Validation loss: 3.334160265075391

Epoch: 6| Step: 10
Training loss: 4.485271085203621
Validation loss: 3.3307883242716474

Epoch: 6| Step: 11
Training loss: 2.661058270171575
Validation loss: 3.326900871941155

Epoch: 6| Step: 12
Training loss: 2.797609286112505
Validation loss: 3.323296018051079

Epoch: 6| Step: 13
Training loss: 3.550434091381454
Validation loss: 3.319746093309514

Epoch: 42| Step: 0
Training loss: 3.188181935085966
Validation loss: 3.3169685668859006

Epoch: 6| Step: 1
Training loss: 3.5647399285300803
Validation loss: 3.3130654985934975

Epoch: 6| Step: 2
Training loss: 3.5660813383110312
Validation loss: 3.309364514308764

Epoch: 6| Step: 3
Training loss: 4.1401846021692155
Validation loss: 3.305648964453458

Epoch: 6| Step: 4
Training loss: 3.6150615863117945
Validation loss: 3.301955179481374

Epoch: 6| Step: 5
Training loss: 3.6787887091095586
Validation loss: 3.2982790158505613

Epoch: 6| Step: 6
Training loss: 3.080549959896759
Validation loss: 3.2944242941754953

Epoch: 6| Step: 7
Training loss: 3.7163692515024906
Validation loss: 3.2908542612362983

Epoch: 6| Step: 8
Training loss: 3.383250289674562
Validation loss: 3.2871119619515348

Epoch: 6| Step: 9
Training loss: 2.7080012973799197
Validation loss: 3.2834688707315425

Epoch: 6| Step: 10
Training loss: 3.8526691448650143
Validation loss: 3.2798205456062717

Epoch: 6| Step: 11
Training loss: 2.9357414663340706
Validation loss: 3.276338819522154

Epoch: 6| Step: 12
Training loss: 2.8435876820948778
Validation loss: 3.272861002046627

Epoch: 6| Step: 13
Training loss: 3.5018289419560036
Validation loss: 3.2694232760291198

Epoch: 43| Step: 0
Training loss: 3.082192923169672
Validation loss: 3.26620558546828

Epoch: 6| Step: 1
Training loss: 3.717316679856566
Validation loss: 3.2628542691904405

Epoch: 6| Step: 2
Training loss: 3.1762495270435593
Validation loss: 3.2595533420321283

Epoch: 6| Step: 3
Training loss: 4.112303180100946
Validation loss: 3.2563850574954816

Epoch: 6| Step: 4
Training loss: 3.1314782704734303
Validation loss: 3.2529484505800808

Epoch: 6| Step: 5
Training loss: 3.495348973567802
Validation loss: 3.2496746340523646

Epoch: 6| Step: 6
Training loss: 3.497333464512572
Validation loss: 3.2461575143414163

Epoch: 6| Step: 7
Training loss: 2.5975095779198303
Validation loss: 3.242545442853426

Epoch: 6| Step: 8
Training loss: 3.2524519254282116
Validation loss: 3.2392474590170934

Epoch: 6| Step: 9
Training loss: 3.7051948524954117
Validation loss: 3.2359325694401644

Epoch: 6| Step: 10
Training loss: 2.8383708004168833
Validation loss: 3.2324376346937695

Epoch: 6| Step: 11
Training loss: 3.6653248903915765
Validation loss: 3.2291677085300527

Epoch: 6| Step: 12
Training loss: 3.2931045739522684
Validation loss: 3.225939871479732

Epoch: 6| Step: 13
Training loss: 3.5413923867924386
Validation loss: 3.222690256883388

Epoch: 44| Step: 0
Training loss: 3.361416644316716
Validation loss: 3.219222728495534

Epoch: 6| Step: 1
Training loss: 3.159997509339715
Validation loss: 3.2158586052063622

Epoch: 6| Step: 2
Training loss: 3.034624875561389
Validation loss: 3.2124112004377707

Epoch: 6| Step: 3
Training loss: 4.010519024752331
Validation loss: 3.2091903945440565

Epoch: 6| Step: 4
Training loss: 3.7046461884163318
Validation loss: 3.2058276428087535

Epoch: 6| Step: 5
Training loss: 3.7807787136487625
Validation loss: 3.202533276494476

Epoch: 6| Step: 6
Training loss: 3.6672665509877587
Validation loss: 3.1986759083892493

Epoch: 6| Step: 7
Training loss: 2.917637490871203
Validation loss: 3.19529813655992

Epoch: 6| Step: 8
Training loss: 3.1955533484833154
Validation loss: 3.191911250438244

Epoch: 6| Step: 9
Training loss: 2.840066389463038
Validation loss: 3.188283599575965

Epoch: 6| Step: 10
Training loss: 3.0651541905411532
Validation loss: 3.1850433856079183

Epoch: 6| Step: 11
Training loss: 3.118430441957249
Validation loss: 3.1818636259326394

Epoch: 6| Step: 12
Training loss: 3.3796083988662797
Validation loss: 3.1784521229000364

Epoch: 6| Step: 13
Training loss: 3.298949542614557
Validation loss: 3.175486420744277

Epoch: 45| Step: 0
Training loss: 3.1474276075453695
Validation loss: 3.1723684794582176

Epoch: 6| Step: 1
Training loss: 2.804511189564081
Validation loss: 3.1692958800497135

Epoch: 6| Step: 2
Training loss: 3.4440096167098946
Validation loss: 3.166340150228695

Epoch: 6| Step: 3
Training loss: 3.528089611325369
Validation loss: 3.1634183753922542

Epoch: 6| Step: 4
Training loss: 3.1086487808591077
Validation loss: 3.160460380062452

Epoch: 6| Step: 5
Training loss: 3.6152982123955946
Validation loss: 3.157373536819986

Epoch: 6| Step: 6
Training loss: 3.0780413466186807
Validation loss: 3.153895970112739

Epoch: 6| Step: 7
Training loss: 3.767080445194449
Validation loss: 3.151022406064693

Epoch: 6| Step: 8
Training loss: 3.7611060668545857
Validation loss: 3.1475493106711263

Epoch: 6| Step: 9
Training loss: 2.7814228989939838
Validation loss: 3.1440172995656788

Epoch: 6| Step: 10
Training loss: 2.4701406690564727
Validation loss: 3.14074790296581

Epoch: 6| Step: 11
Training loss: 3.2152123129881067
Validation loss: 3.1378722391785407

Epoch: 6| Step: 12
Training loss: 3.4586794270221475
Validation loss: 3.134860237571437

Epoch: 6| Step: 13
Training loss: 3.641542900187871
Validation loss: 3.131904337236875

Epoch: 46| Step: 0
Training loss: 3.853253656793348
Validation loss: 3.1289163082118296

Epoch: 6| Step: 1
Training loss: 3.3980412394696917
Validation loss: 3.1259484949731813

Epoch: 6| Step: 2
Training loss: 2.3994855051113566
Validation loss: 3.1230874503280965

Epoch: 6| Step: 3
Training loss: 2.787674245819562
Validation loss: 3.1203200837948755

Epoch: 6| Step: 4
Training loss: 3.3598957456581737
Validation loss: 3.1173329203887916

Epoch: 6| Step: 5
Training loss: 3.1909618651939526
Validation loss: 3.114658422851376

Epoch: 6| Step: 6
Training loss: 3.138331396582099
Validation loss: 3.1118018234137095

Epoch: 6| Step: 7
Training loss: 3.3374080230954783
Validation loss: 3.1088315913822435

Epoch: 6| Step: 8
Training loss: 3.282569402003145
Validation loss: 3.105818486063475

Epoch: 6| Step: 9
Training loss: 3.4630729338995754
Validation loss: 3.1028307316457338

Epoch: 6| Step: 10
Training loss: 2.931847998942614
Validation loss: 3.099658743728186

Epoch: 6| Step: 11
Training loss: 3.5881144246681598
Validation loss: 3.096756960521154

Epoch: 6| Step: 12
Training loss: 3.0815367404691654
Validation loss: 3.0935195554455626

Epoch: 6| Step: 13
Training loss: 3.461481675880439
Validation loss: 3.090540881630571

Epoch: 47| Step: 0
Training loss: 3.4334815379132895
Validation loss: 3.087554868347007

Epoch: 6| Step: 1
Training loss: 3.45366585064658
Validation loss: 3.084612868701502

Epoch: 6| Step: 2
Training loss: 3.631645556653033
Validation loss: 3.0816147929423456

Epoch: 6| Step: 3
Training loss: 3.4997125235070925
Validation loss: 3.078303969290864

Epoch: 6| Step: 4
Training loss: 2.9704257451863723
Validation loss: 3.0751510815605823

Epoch: 6| Step: 5
Training loss: 3.4721816675149015
Validation loss: 3.0722939760161467

Epoch: 6| Step: 6
Training loss: 3.1063602727278647
Validation loss: 3.069532222461231

Epoch: 6| Step: 7
Training loss: 3.6436579435834626
Validation loss: 3.0664109151039356

Epoch: 6| Step: 8
Training loss: 2.990750518046239
Validation loss: 3.063595854690609

Epoch: 6| Step: 9
Training loss: 3.262705981303643
Validation loss: 3.0604668440231584

Epoch: 6| Step: 10
Training loss: 2.888774217465288
Validation loss: 3.057716708338919

Epoch: 6| Step: 11
Training loss: 2.8649660906690664
Validation loss: 3.0549422187980753

Epoch: 6| Step: 12
Training loss: 2.930211704404546
Validation loss: 3.052214653306015

Epoch: 6| Step: 13
Training loss: 2.6068200491960276
Validation loss: 3.049333372901157

Epoch: 48| Step: 0
Training loss: 2.703713237285015
Validation loss: 3.0468107819921855

Epoch: 6| Step: 1
Training loss: 2.9356683742737255
Validation loss: 3.0439850754925475

Epoch: 6| Step: 2
Training loss: 3.198459707536179
Validation loss: 3.0418856729195194

Epoch: 6| Step: 3
Training loss: 2.864837931098365
Validation loss: 3.039791552545577

Epoch: 6| Step: 4
Training loss: 3.153901387745509
Validation loss: 3.0373141400652095

Epoch: 6| Step: 5
Training loss: 3.2725138305651567
Validation loss: 3.034822436631695

Epoch: 6| Step: 6
Training loss: 3.4128048323974878
Validation loss: 3.0324739298966996

Epoch: 6| Step: 7
Training loss: 2.6722964127362805
Validation loss: 3.0297749656733335

Epoch: 6| Step: 8
Training loss: 2.9925315400184793
Validation loss: 3.0274280823477273

Epoch: 6| Step: 9
Training loss: 3.5018259462580006
Validation loss: 3.0246960027442307

Epoch: 6| Step: 10
Training loss: 3.645732391413254
Validation loss: 3.022016298027532

Epoch: 6| Step: 11
Training loss: 3.206288334132131
Validation loss: 3.0192265194351013

Epoch: 6| Step: 12
Training loss: 3.220997146316207
Validation loss: 3.0165373454818027

Epoch: 6| Step: 13
Training loss: 3.44828215138092
Validation loss: 3.0139755587170076

Epoch: 49| Step: 0
Training loss: 2.6564402792600834
Validation loss: 3.011269660844351

Epoch: 6| Step: 1
Training loss: 3.983014760918337
Validation loss: 3.008591456095824

Epoch: 6| Step: 2
Training loss: 2.6963982648057594
Validation loss: 3.0060546626486597

Epoch: 6| Step: 3
Training loss: 3.13312481396026
Validation loss: 3.0033805661680644

Epoch: 6| Step: 4
Training loss: 2.891041493696333
Validation loss: 3.0009286026122783

Epoch: 6| Step: 5
Training loss: 2.745584931857325
Validation loss: 2.9984361758220084

Epoch: 6| Step: 6
Training loss: 3.6860979938696903
Validation loss: 2.995882002780474

Epoch: 6| Step: 7
Training loss: 2.9783135817743966
Validation loss: 2.99340551168961

Epoch: 6| Step: 8
Training loss: 3.1364548359554423
Validation loss: 2.990856143385781

Epoch: 6| Step: 9
Training loss: 3.0690500707037702
Validation loss: 2.9884290338678405

Epoch: 6| Step: 10
Training loss: 3.8407905164271403
Validation loss: 2.9859617585281866

Epoch: 6| Step: 11
Training loss: 2.932633609833722
Validation loss: 2.9833821614139358

Epoch: 6| Step: 12
Training loss: 2.7168318899107264
Validation loss: 2.9807945463369196

Epoch: 6| Step: 13
Training loss: 3.0670933433534855
Validation loss: 2.9783419465671765

Epoch: 50| Step: 0
Training loss: 3.2666995092285043
Validation loss: 2.975669853814114

Epoch: 6| Step: 1
Training loss: 3.3873341143203715
Validation loss: 2.9730945051894877

Epoch: 6| Step: 2
Training loss: 3.678792079175473
Validation loss: 2.97025509878658

Epoch: 6| Step: 3
Training loss: 2.919074363574125
Validation loss: 2.967596345241072

Epoch: 6| Step: 4
Training loss: 2.3365883829423764
Validation loss: 2.9649680827343663

Epoch: 6| Step: 5
Training loss: 4.108826343185732
Validation loss: 2.9623693729793974

Epoch: 6| Step: 6
Training loss: 2.7785408455422567
Validation loss: 2.95949336039821

Epoch: 6| Step: 7
Training loss: 2.7048769879531482
Validation loss: 2.956806760570475

Epoch: 6| Step: 8
Training loss: 2.527165355016941
Validation loss: 2.954523377791756

Epoch: 6| Step: 9
Training loss: 2.4705904124488107
Validation loss: 2.9517547011713985

Epoch: 6| Step: 10
Training loss: 3.3917216272298427
Validation loss: 2.949560149855631

Epoch: 6| Step: 11
Training loss: 3.2901151517525937
Validation loss: 2.9471289904492535

Epoch: 6| Step: 12
Training loss: 3.633221740642154
Validation loss: 2.9445055219525402

Epoch: 6| Step: 13
Training loss: 2.304712844967895
Validation loss: 2.9422927743071026

Epoch: 51| Step: 0
Training loss: 2.385799149634659
Validation loss: 2.9403926188652405

Epoch: 6| Step: 1
Training loss: 2.9252472862633367
Validation loss: 2.9386315973082238

Epoch: 6| Step: 2
Training loss: 3.2251271895529867
Validation loss: 2.9361740799279574

Epoch: 6| Step: 3
Training loss: 3.3215664279766295
Validation loss: 2.934164263518358

Epoch: 6| Step: 4
Training loss: 3.259189964008938
Validation loss: 2.9319752488013155

Epoch: 6| Step: 5
Training loss: 3.4936531285485666
Validation loss: 2.929519187330956

Epoch: 6| Step: 6
Training loss: 3.6393119834594643
Validation loss: 2.9269561920971294

Epoch: 6| Step: 7
Training loss: 2.867279965939178
Validation loss: 2.9247250044576547

Epoch: 6| Step: 8
Training loss: 2.774725644407641
Validation loss: 2.9217188992340377

Epoch: 6| Step: 9
Training loss: 3.0255621017414502
Validation loss: 2.919515027266623

Epoch: 6| Step: 10
Training loss: 3.2208708655246108
Validation loss: 2.916860850999866

Epoch: 6| Step: 11
Training loss: 2.763810246646425
Validation loss: 2.913808693967657

Epoch: 6| Step: 12
Training loss: 2.717769577566429
Validation loss: 2.9118032006661765

Epoch: 6| Step: 13
Training loss: 3.114572905626139
Validation loss: 2.909204819916337

Epoch: 52| Step: 0
Training loss: 3.308790036698915
Validation loss: 2.906607192317623

Epoch: 6| Step: 1
Training loss: 3.3960588220415313
Validation loss: 2.924229779682562

Epoch: 6| Step: 2
Training loss: 3.1709784382231723
Validation loss: 2.9039269258524074

Epoch: 6| Step: 3
Training loss: 3.184611189508811
Validation loss: 2.9018565779197147

Epoch: 6| Step: 4
Training loss: 2.6835767809291102
Validation loss: 2.9012971191436825

Epoch: 6| Step: 5
Training loss: 2.677901760131253
Validation loss: 2.904584113229324

Epoch: 6| Step: 6
Training loss: 3.2964335503102937
Validation loss: 2.898511311567177

Epoch: 6| Step: 7
Training loss: 2.8314117385443085
Validation loss: 2.895074543693245

Epoch: 6| Step: 8
Training loss: 3.015151545067292
Validation loss: 2.892930865539784

Epoch: 6| Step: 9
Training loss: 2.9574127555870824
Validation loss: 2.890551921848634

Epoch: 6| Step: 10
Training loss: 3.21155714752651
Validation loss: 2.889318634942303

Epoch: 6| Step: 11
Training loss: 3.0217266121283743
Validation loss: 2.888520239168065

Epoch: 6| Step: 12
Training loss: 2.7854743337166017
Validation loss: 2.8853085953250743

Epoch: 6| Step: 13
Training loss: 2.890757789654766
Validation loss: 2.8834975754443395

Epoch: 53| Step: 0
Training loss: 2.9872470636911252
Validation loss: 2.880682512447061

Epoch: 6| Step: 1
Training loss: 2.8031277795818244
Validation loss: 2.8788958014027304

Epoch: 6| Step: 2
Training loss: 3.1560599392612874
Validation loss: 2.8769426831213254

Epoch: 6| Step: 3
Training loss: 2.355447595099602
Validation loss: 2.8747738873671715

Epoch: 6| Step: 4
Training loss: 2.663379212399265
Validation loss: 2.8735071120923363

Epoch: 6| Step: 5
Training loss: 3.5616684327919246
Validation loss: 2.8717962326853974

Epoch: 6| Step: 6
Training loss: 2.2600264205063443
Validation loss: 2.86985975808967

Epoch: 6| Step: 7
Training loss: 3.0000648491526136
Validation loss: 2.8684840514686267

Epoch: 6| Step: 8
Training loss: 3.528905444665546
Validation loss: 2.8663522888022914

Epoch: 6| Step: 9
Training loss: 3.218529554799394
Validation loss: 2.864232368932834

Epoch: 6| Step: 10
Training loss: 3.28650934065921
Validation loss: 2.862037391984364

Epoch: 6| Step: 11
Training loss: 3.3365412217172965
Validation loss: 2.8596416550557158

Epoch: 6| Step: 12
Training loss: 2.9971570213406054
Validation loss: 2.8578192642490596

Epoch: 6| Step: 13
Training loss: 2.6279962787108295
Validation loss: 2.85573542193773

Epoch: 54| Step: 0
Training loss: 2.8675856144969285
Validation loss: 2.8541558304926715

Epoch: 6| Step: 1
Training loss: 2.7100339587571938
Validation loss: 2.852207797120953

Epoch: 6| Step: 2
Training loss: 2.927433214737034
Validation loss: 2.8507908861452695

Epoch: 6| Step: 3
Training loss: 2.8847755426792956
Validation loss: 2.848515580181849

Epoch: 6| Step: 4
Training loss: 2.6330772742186728
Validation loss: 2.8469697519858785

Epoch: 6| Step: 5
Training loss: 2.812082810719571
Validation loss: 2.8449079789854115

Epoch: 6| Step: 6
Training loss: 3.091855172085421
Validation loss: 2.84285840879733

Epoch: 6| Step: 7
Training loss: 3.3706184485322477
Validation loss: 2.840886431401368

Epoch: 6| Step: 8
Training loss: 3.355846166201743
Validation loss: 2.8388077824057745

Epoch: 6| Step: 9
Training loss: 2.956920626749306
Validation loss: 2.8363795360687893

Epoch: 6| Step: 10
Training loss: 3.1070280946481024
Validation loss: 2.8346817837545615

Epoch: 6| Step: 11
Training loss: 2.924843651921175
Validation loss: 2.832191452230697

Epoch: 6| Step: 12
Training loss: 2.9702530117990897
Validation loss: 2.829971455384024

Epoch: 6| Step: 13
Training loss: 3.0501159645923197
Validation loss: 2.827562054830924

Epoch: 55| Step: 0
Training loss: 3.0692553071158466
Validation loss: 2.826162300014555

Epoch: 6| Step: 1
Training loss: 2.894934663447077
Validation loss: 2.8228464903795043

Epoch: 6| Step: 2
Training loss: 2.4036619462079
Validation loss: 2.828996049982727

Epoch: 6| Step: 3
Training loss: 2.8499609225087035
Validation loss: 2.8196497849186297

Epoch: 6| Step: 4
Training loss: 3.0653691767383036
Validation loss: 2.8178129241391376

Epoch: 6| Step: 5
Training loss: 2.5543165025016754
Validation loss: 2.815774636027029

Epoch: 6| Step: 6
Training loss: 3.3382186058874814
Validation loss: 2.816660086118095

Epoch: 6| Step: 7
Training loss: 3.3095165708697287
Validation loss: 2.812871413961457

Epoch: 6| Step: 8
Training loss: 2.4891299442749237
Validation loss: 2.8119869046718007

Epoch: 6| Step: 9
Training loss: 3.1632693956812026
Validation loss: 2.8102633872531007

Epoch: 6| Step: 10
Training loss: 2.982767680867034
Validation loss: 2.809197429494955

Epoch: 6| Step: 11
Training loss: 3.417474573650527
Validation loss: 2.8057365049628897

Epoch: 6| Step: 12
Training loss: 2.7624288938182824
Validation loss: 2.802937803960424

Epoch: 6| Step: 13
Training loss: 2.8600706494548427
Validation loss: 2.8026244670305442

Epoch: 56| Step: 0
Training loss: 2.969543511601971
Validation loss: 2.799004353318958

Epoch: 6| Step: 1
Training loss: 2.867040147035251
Validation loss: 2.7974195181161727

Epoch: 6| Step: 2
Training loss: 3.0863619355567193
Validation loss: 2.7980579027179333

Epoch: 6| Step: 3
Training loss: 3.129587696939012
Validation loss: 2.7952743297378184

Epoch: 6| Step: 4
Training loss: 3.4892062918198175
Validation loss: 2.791987988972629

Epoch: 6| Step: 5
Training loss: 2.9457869817890154
Validation loss: 2.79277260542865

Epoch: 6| Step: 6
Training loss: 2.913792165535412
Validation loss: 2.790787449259542

Epoch: 6| Step: 7
Training loss: 2.9052105757379936
Validation loss: 2.788978582521317

Epoch: 6| Step: 8
Training loss: 2.7008082875384503
Validation loss: 2.7879213051811296

Epoch: 6| Step: 9
Training loss: 2.3301294901479044
Validation loss: 2.7861668276791227

Epoch: 6| Step: 10
Training loss: 2.9601209012677288
Validation loss: 2.786204550526299

Epoch: 6| Step: 11
Training loss: 2.718728953312932
Validation loss: 2.782791981807963

Epoch: 6| Step: 12
Training loss: 2.5472778750568037
Validation loss: 2.779640246242138

Epoch: 6| Step: 13
Training loss: 3.2720247921179286
Validation loss: 2.778489453754566

Epoch: 57| Step: 0
Training loss: 3.1716546043157265
Validation loss: 2.778344082856355

Epoch: 6| Step: 1
Training loss: 2.953859268214384
Validation loss: 2.7778695096658006

Epoch: 6| Step: 2
Training loss: 3.1436878660822907
Validation loss: 2.7752010845380513

Epoch: 6| Step: 3
Training loss: 2.623636345657563
Validation loss: 2.7718390358158267

Epoch: 6| Step: 4
Training loss: 2.8931510816326798
Validation loss: 2.771627747275262

Epoch: 6| Step: 5
Training loss: 2.8740542971075143
Validation loss: 2.7693654859513295

Epoch: 6| Step: 6
Training loss: 3.225164152004212
Validation loss: 2.767804280375424

Epoch: 6| Step: 7
Training loss: 2.607546776912472
Validation loss: 2.7659474129255495

Epoch: 6| Step: 8
Training loss: 2.7736521463208548
Validation loss: 2.7646656851060367

Epoch: 6| Step: 9
Training loss: 3.1288775991587747
Validation loss: 2.7631336204718195

Epoch: 6| Step: 10
Training loss: 2.9268643624248654
Validation loss: 2.761869578399712

Epoch: 6| Step: 11
Training loss: 2.895928543684556
Validation loss: 2.7589868453254787

Epoch: 6| Step: 12
Training loss: 2.7653974019166476
Validation loss: 2.7558714147458403

Epoch: 6| Step: 13
Training loss: 2.6931583365472798
Validation loss: 2.7542352863098922

Epoch: 58| Step: 0
Training loss: 3.096120215395971
Validation loss: 2.752785976520454

Epoch: 6| Step: 1
Training loss: 2.8074653491550956
Validation loss: 2.7502171835246316

Epoch: 6| Step: 2
Training loss: 2.5244202958699637
Validation loss: 2.750377224567761

Epoch: 6| Step: 3
Training loss: 3.091578945207559
Validation loss: 2.7476320041674644

Epoch: 6| Step: 4
Training loss: 2.773805233928482
Validation loss: 2.7474261434368605

Epoch: 6| Step: 5
Training loss: 2.4497023109662766
Validation loss: 2.7458531584962227

Epoch: 6| Step: 6
Training loss: 3.0496281631690363
Validation loss: 2.74421978855546

Epoch: 6| Step: 7
Training loss: 3.226542401193454
Validation loss: 2.7436186270229843

Epoch: 6| Step: 8
Training loss: 3.2172041949542542
Validation loss: 2.739691222112799

Epoch: 6| Step: 9
Training loss: 3.0309737561385104
Validation loss: 2.7373242413260965

Epoch: 6| Step: 10
Training loss: 2.8407845598149826
Validation loss: 2.7386309681103813

Epoch: 6| Step: 11
Training loss: 2.8971796725318297
Validation loss: 2.7467557960079447

Epoch: 6| Step: 12
Training loss: 2.88997218003132
Validation loss: 2.745471578181937

Epoch: 6| Step: 13
Training loss: 2.416647406753438
Validation loss: 2.7378120546428026

Epoch: 59| Step: 0
Training loss: 2.8345092876212856
Validation loss: 2.7338566752038487

Epoch: 6| Step: 1
Training loss: 3.2081794867021522
Validation loss: 2.7304427000594056

Epoch: 6| Step: 2
Training loss: 2.55229238056184
Validation loss: 2.7274941471315612

Epoch: 6| Step: 3
Training loss: 3.027074395779365
Validation loss: 2.7315040993936424

Epoch: 6| Step: 4
Training loss: 3.0776123549453094
Validation loss: 2.7342525127769406

Epoch: 6| Step: 5
Training loss: 2.5358491723548666
Validation loss: 2.7397222785864184

Epoch: 6| Step: 6
Training loss: 2.855557754736753
Validation loss: 2.7482976123515686

Epoch: 6| Step: 7
Training loss: 2.9655307380962603
Validation loss: 2.7358036632325264

Epoch: 6| Step: 8
Training loss: 2.684167259269143
Validation loss: 2.730450063922559

Epoch: 6| Step: 9
Training loss: 3.107467296179667
Validation loss: 2.7261955794042527

Epoch: 6| Step: 10
Training loss: 3.0543306342255985
Validation loss: 2.722973812781009

Epoch: 6| Step: 11
Training loss: 2.4215938281844815
Validation loss: 2.7193556070889273

Epoch: 6| Step: 12
Training loss: 2.8693982158661457
Validation loss: 2.7174918380329305

Epoch: 6| Step: 13
Training loss: 2.8775739343128133
Validation loss: 2.719037212532928

Epoch: 60| Step: 0
Training loss: 2.84923335020123
Validation loss: 2.7156706138558118

Epoch: 6| Step: 1
Training loss: 2.9485074227537043
Validation loss: 2.7136550679493348

Epoch: 6| Step: 2
Training loss: 2.716939652268
Validation loss: 2.7111803252039337

Epoch: 6| Step: 3
Training loss: 2.5022941553475433
Validation loss: 2.712608709076024

Epoch: 6| Step: 4
Training loss: 2.4065597136693997
Validation loss: 2.7112868319387293

Epoch: 6| Step: 5
Training loss: 2.79461715178026
Validation loss: 2.712408965497843

Epoch: 6| Step: 6
Training loss: 2.9724655190433844
Validation loss: 2.710556237988487

Epoch: 6| Step: 7
Training loss: 2.622306622702238
Validation loss: 2.7095746545732315

Epoch: 6| Step: 8
Training loss: 3.4229189878344815
Validation loss: 2.7076246850588386

Epoch: 6| Step: 9
Training loss: 3.0759982589895336
Validation loss: 2.70789460272154

Epoch: 6| Step: 10
Training loss: 2.922197130367078
Validation loss: 2.703310627526422

Epoch: 6| Step: 11
Training loss: 2.8665656057183146
Validation loss: 2.7006683211238744

Epoch: 6| Step: 12
Training loss: 2.4527351409769964
Validation loss: 2.6991101623569222

Epoch: 6| Step: 13
Training loss: 3.156253625848784
Validation loss: 2.699213038069059

Epoch: 61| Step: 0
Training loss: 2.571118074926238
Validation loss: 2.6963679361879094

Epoch: 6| Step: 1
Training loss: 1.8618454109291669
Validation loss: 2.696374390995211

Epoch: 6| Step: 2
Training loss: 2.7425399510299946
Validation loss: 2.6947280471265707

Epoch: 6| Step: 3
Training loss: 2.889437044745373
Validation loss: 2.6944709827868403

Epoch: 6| Step: 4
Training loss: 3.331112376048763
Validation loss: 2.6916319406904994

Epoch: 6| Step: 5
Training loss: 2.6246634676332996
Validation loss: 2.6925860782418947

Epoch: 6| Step: 6
Training loss: 3.231874540613334
Validation loss: 2.6904231298127885

Epoch: 6| Step: 7
Training loss: 2.7626930687181592
Validation loss: 2.689782319413992

Epoch: 6| Step: 8
Training loss: 2.855189527644274
Validation loss: 2.68933131787753

Epoch: 6| Step: 9
Training loss: 2.545574019774111
Validation loss: 2.6894415562200122

Epoch: 6| Step: 10
Training loss: 3.0866540777006
Validation loss: 2.6891418882713376

Epoch: 6| Step: 11
Training loss: 3.084566608572382
Validation loss: 2.687676579196873

Epoch: 6| Step: 12
Training loss: 2.787151290909844
Validation loss: 2.6871938457133866

Epoch: 6| Step: 13
Training loss: 2.9903002332415247
Validation loss: 2.6860762972473045

Epoch: 62| Step: 0
Training loss: 3.0805092499576605
Validation loss: 2.6840088369192765

Epoch: 6| Step: 1
Training loss: 2.6330722035534797
Validation loss: 2.683570058422836

Epoch: 6| Step: 2
Training loss: 2.3823065548926263
Validation loss: 2.6813821577745114

Epoch: 6| Step: 3
Training loss: 2.949967083504866
Validation loss: 2.678192566917348

Epoch: 6| Step: 4
Training loss: 2.97236140589776
Validation loss: 2.6766781828154746

Epoch: 6| Step: 5
Training loss: 3.296743525916353
Validation loss: 2.675943456035286

Epoch: 6| Step: 6
Training loss: 2.7253948870474236
Validation loss: 2.6760543052777788

Epoch: 6| Step: 7
Training loss: 2.7476670166012935
Validation loss: 2.671553326552812

Epoch: 6| Step: 8
Training loss: 3.248378055500172
Validation loss: 2.6737801375911676

Epoch: 6| Step: 9
Training loss: 2.6113478460829738
Validation loss: 2.6721524248857347

Epoch: 6| Step: 10
Training loss: 2.5848099477472033
Validation loss: 2.6705511133477846

Epoch: 6| Step: 11
Training loss: 2.596297518240669
Validation loss: 2.6685689806686264

Epoch: 6| Step: 12
Training loss: 2.4729628531029633
Validation loss: 2.666878920293644

Epoch: 6| Step: 13
Training loss: 2.918511561062533
Validation loss: 2.6617125646670288

Epoch: 63| Step: 0
Training loss: 2.603642728869444
Validation loss: 2.6638125752653785

Epoch: 6| Step: 1
Training loss: 2.8093442378412607
Validation loss: 2.6707446586976595

Epoch: 6| Step: 2
Training loss: 3.121729856368513
Validation loss: 2.6800706772950282

Epoch: 6| Step: 3
Training loss: 2.6078611996756424
Validation loss: 2.6813689388520636

Epoch: 6| Step: 4
Training loss: 3.111982009865115
Validation loss: 2.666693096228598

Epoch: 6| Step: 5
Training loss: 2.603299863879383
Validation loss: 2.661469391702172

Epoch: 6| Step: 6
Training loss: 2.9135663221177763
Validation loss: 2.6586187534312997

Epoch: 6| Step: 7
Training loss: 2.507428956931793
Validation loss: 2.6588550583815813

Epoch: 6| Step: 8
Training loss: 2.9508853876807937
Validation loss: 2.6567411828768694

Epoch: 6| Step: 9
Training loss: 2.565410635724604
Validation loss: 2.655407880545777

Epoch: 6| Step: 10
Training loss: 2.9826837510887385
Validation loss: 2.656928241381438

Epoch: 6| Step: 11
Training loss: 2.831879205239667
Validation loss: 2.655827537301279

Epoch: 6| Step: 12
Training loss: 2.4601825827784998
Validation loss: 2.6563004582418324

Epoch: 6| Step: 13
Training loss: 3.042817686197375
Validation loss: 2.65491124243645

Epoch: 64| Step: 0
Training loss: 3.1115874274009037
Validation loss: 2.6552520822178587

Epoch: 6| Step: 1
Training loss: 2.51745927173509
Validation loss: 2.650869927280144

Epoch: 6| Step: 2
Training loss: 2.9986332323079887
Validation loss: 2.652917993600221

Epoch: 6| Step: 3
Training loss: 2.683480295062372
Validation loss: 2.649632127287258

Epoch: 6| Step: 4
Training loss: 2.6739917423631505
Validation loss: 2.6497973886444033

Epoch: 6| Step: 5
Training loss: 2.507541725062554
Validation loss: 2.6473822577893484

Epoch: 6| Step: 6
Training loss: 2.9195998202410482
Validation loss: 2.64519870586155

Epoch: 6| Step: 7
Training loss: 2.321665770600587
Validation loss: 2.6454587405903522

Epoch: 6| Step: 8
Training loss: 2.9345758371412223
Validation loss: 2.6462057757627724

Epoch: 6| Step: 9
Training loss: 2.329873881057887
Validation loss: 2.6448675680869353

Epoch: 6| Step: 10
Training loss: 2.738843307820826
Validation loss: 2.639711632103252

Epoch: 6| Step: 11
Training loss: 3.3045642730608282
Validation loss: 2.641149570344841

Epoch: 6| Step: 12
Training loss: 3.2155396089624895
Validation loss: 2.638849267048667

Epoch: 6| Step: 13
Training loss: 2.5032653464453896
Validation loss: 2.637557812218338

Epoch: 65| Step: 0
Training loss: 2.69374228916702
Validation loss: 2.637254388350217

Epoch: 6| Step: 1
Training loss: 2.528839941985051
Validation loss: 2.6337693284044716

Epoch: 6| Step: 2
Training loss: 2.53963729221099
Validation loss: 2.6392307249709983

Epoch: 6| Step: 3
Training loss: 2.758481212082495
Validation loss: 2.6435725898827

Epoch: 6| Step: 4
Training loss: 3.3646100085512964
Validation loss: 2.6617738769364165

Epoch: 6| Step: 5
Training loss: 2.9675483279322146
Validation loss: 2.6398577506582295

Epoch: 6| Step: 6
Training loss: 2.0105790252219875
Validation loss: 2.6375015716789108

Epoch: 6| Step: 7
Training loss: 2.771488332174324
Validation loss: 2.6305323385467085

Epoch: 6| Step: 8
Training loss: 2.5067467251972446
Validation loss: 2.63232482257266

Epoch: 6| Step: 9
Training loss: 3.059986873922681
Validation loss: 2.6338128397764935

Epoch: 6| Step: 10
Training loss: 2.920006139043338
Validation loss: 2.6357231615286048

Epoch: 6| Step: 11
Training loss: 2.637442392018415
Validation loss: 2.639514606868743

Epoch: 6| Step: 12
Training loss: 3.049957594029533
Validation loss: 2.6371779053823117

Epoch: 6| Step: 13
Training loss: 2.828802038262785
Validation loss: 2.6364217105785115

Epoch: 66| Step: 0
Training loss: 3.0045293947896856
Validation loss: 2.632550823666586

Epoch: 6| Step: 1
Training loss: 3.195721961463555
Validation loss: 2.6321098831461747

Epoch: 6| Step: 2
Training loss: 2.454016359537401
Validation loss: 2.6306182441192663

Epoch: 6| Step: 3
Training loss: 2.896010048137536
Validation loss: 2.6291796091993422

Epoch: 6| Step: 4
Training loss: 2.7720611165728095
Validation loss: 2.624318988199596

Epoch: 6| Step: 5
Training loss: 2.182571854429942
Validation loss: 2.624979094770233

Epoch: 6| Step: 6
Training loss: 2.786460111148065
Validation loss: 2.624021998884088

Epoch: 6| Step: 7
Training loss: 3.1696867511864597
Validation loss: 2.6204986124018648

Epoch: 6| Step: 8
Training loss: 2.7912064547800055
Validation loss: 2.6181747320579793

Epoch: 6| Step: 9
Training loss: 2.513026726012494
Validation loss: 2.6176014738868414

Epoch: 6| Step: 10
Training loss: 2.9577592283712235
Validation loss: 2.619257162688914

Epoch: 6| Step: 11
Training loss: 2.871875391847005
Validation loss: 2.6143105099857338

Epoch: 6| Step: 12
Training loss: 2.404187197627879
Validation loss: 2.616537918782671

Epoch: 6| Step: 13
Training loss: 2.460068903632603
Validation loss: 2.6183938809279534

Epoch: 67| Step: 0
Training loss: 2.5337035920796045
Validation loss: 2.6170151838824913

Epoch: 6| Step: 1
Training loss: 2.9250293371571474
Validation loss: 2.6168800894650777

Epoch: 6| Step: 2
Training loss: 3.1503376492174846
Validation loss: 2.6149266132878886

Epoch: 6| Step: 3
Training loss: 3.099661064077523
Validation loss: 2.6168004750907823

Epoch: 6| Step: 4
Training loss: 2.7160817349344857
Validation loss: 2.616201961056246

Epoch: 6| Step: 5
Training loss: 2.3697443583590636
Validation loss: 2.614775515075293

Epoch: 6| Step: 6
Training loss: 3.01629567964999
Validation loss: 2.613759451821239

Epoch: 6| Step: 7
Training loss: 2.5151591373096913
Validation loss: 2.6136282484710116

Epoch: 6| Step: 8
Training loss: 2.6052099554053534
Validation loss: 2.6104753043694355

Epoch: 6| Step: 9
Training loss: 2.5765063203941034
Validation loss: 2.6075330922461197

Epoch: 6| Step: 10
Training loss: 3.076215587487041
Validation loss: 2.607661036501611

Epoch: 6| Step: 11
Training loss: 2.4113574628282715
Validation loss: 2.606601878561885

Epoch: 6| Step: 12
Training loss: 2.9477118071601383
Validation loss: 2.605182225888283

Epoch: 6| Step: 13
Training loss: 2.3316531489836834
Validation loss: 2.605849879201831

Epoch: 68| Step: 0
Training loss: 3.1708949787766016
Validation loss: 2.6217162316453444

Epoch: 6| Step: 1
Training loss: 2.4467707664144034
Validation loss: 2.629973543974428

Epoch: 6| Step: 2
Training loss: 3.166984809822196
Validation loss: 2.644565749213363

Epoch: 6| Step: 3
Training loss: 2.5016524575694232
Validation loss: 2.6286246539560763

Epoch: 6| Step: 4
Training loss: 2.483937542865744
Validation loss: 2.6173823042152375

Epoch: 6| Step: 5
Training loss: 3.245637606855796
Validation loss: 2.616999088926136

Epoch: 6| Step: 6
Training loss: 2.6888073247653717
Validation loss: 2.613976523411893

Epoch: 6| Step: 7
Training loss: 2.9201145682655802
Validation loss: 2.6161782211758497

Epoch: 6| Step: 8
Training loss: 2.5812502327611786
Validation loss: 2.617923796216659

Epoch: 6| Step: 9
Training loss: 2.8882182231255538
Validation loss: 2.619386460887436

Epoch: 6| Step: 10
Training loss: 2.7704927526743055
Validation loss: 2.6203751467254484

Epoch: 6| Step: 11
Training loss: 2.5038072206431012
Validation loss: 2.624533051633261

Epoch: 6| Step: 12
Training loss: 2.5563781929982907
Validation loss: 2.6225065923267925

Epoch: 6| Step: 13
Training loss: 2.6053355124291033
Validation loss: 2.619356977576287

Epoch: 69| Step: 0
Training loss: 2.4536074024338776
Validation loss: 2.616606888017358

Epoch: 6| Step: 1
Training loss: 2.524751586780603
Validation loss: 2.613499547244706

Epoch: 6| Step: 2
Training loss: 3.1648968385393212
Validation loss: 2.611893814431747

Epoch: 6| Step: 3
Training loss: 2.397258655226547
Validation loss: 2.6088994519875333

Epoch: 6| Step: 4
Training loss: 2.999096734440918
Validation loss: 2.6070384302022305

Epoch: 6| Step: 5
Training loss: 2.614337610701937
Validation loss: 2.604238727844126

Epoch: 6| Step: 6
Training loss: 2.41293516039218
Validation loss: 2.6013829777420683

Epoch: 6| Step: 7
Training loss: 2.5854112717794795
Validation loss: 2.6002769157689785

Epoch: 6| Step: 8
Training loss: 3.2240897025036444
Validation loss: 2.5986168789342248

Epoch: 6| Step: 9
Training loss: 3.055321200852843
Validation loss: 2.59335354758706

Epoch: 6| Step: 10
Training loss: 2.5714906351985927
Validation loss: 2.583246680826565

Epoch: 6| Step: 11
Training loss: 3.187128082717953
Validation loss: 2.5843936579690774

Epoch: 6| Step: 12
Training loss: 2.3324763449954595
Validation loss: 2.581274878849213

Epoch: 6| Step: 13
Training loss: 2.6485677591434524
Validation loss: 2.5886575889087666

Epoch: 70| Step: 0
Training loss: 2.8770568787511546
Validation loss: 2.586551666316963

Epoch: 6| Step: 1
Training loss: 2.8042459379406335
Validation loss: 2.5899627949707074

Epoch: 6| Step: 2
Training loss: 2.6960121020829333
Validation loss: 2.5956385833852655

Epoch: 6| Step: 3
Training loss: 2.711974811251309
Validation loss: 2.5869689144522483

Epoch: 6| Step: 4
Training loss: 2.819369002420198
Validation loss: 2.5905592875933596

Epoch: 6| Step: 5
Training loss: 2.895457584144867
Validation loss: 2.586044555169107

Epoch: 6| Step: 6
Training loss: 2.5712157172707215
Validation loss: 2.57850004608606

Epoch: 6| Step: 7
Training loss: 2.5785629362895626
Validation loss: 2.5863614383102465

Epoch: 6| Step: 8
Training loss: 2.2408966708450206
Validation loss: 2.583713385610594

Epoch: 6| Step: 9
Training loss: 3.284265930513475
Validation loss: 2.584124895053659

Epoch: 6| Step: 10
Training loss: 2.7274892374275654
Validation loss: 2.5880753975409077

Epoch: 6| Step: 11
Training loss: 2.256084269092812
Validation loss: 2.5847490774125284

Epoch: 6| Step: 12
Training loss: 3.2080599845928837
Validation loss: 2.5834750910801496

Epoch: 6| Step: 13
Training loss: 2.1985114740588925
Validation loss: 2.5806782727398945

Epoch: 71| Step: 0
Training loss: 2.604056963835169
Validation loss: 2.580580819052703

Epoch: 6| Step: 1
Training loss: 2.575027732329426
Validation loss: 2.578860414982317

Epoch: 6| Step: 2
Training loss: 2.310127381449813
Validation loss: 2.578691393355303

Epoch: 6| Step: 3
Training loss: 3.303851082648605
Validation loss: 2.57755794261452

Epoch: 6| Step: 4
Training loss: 2.7859128804383992
Validation loss: 2.5751746356101703

Epoch: 6| Step: 5
Training loss: 2.6240298885469175
Validation loss: 2.571663823038615

Epoch: 6| Step: 6
Training loss: 3.019586204828183
Validation loss: 2.5727111847610686

Epoch: 6| Step: 7
Training loss: 3.03713449547489
Validation loss: 2.571333291165615

Epoch: 6| Step: 8
Training loss: 2.260156806974741
Validation loss: 2.570397187203116

Epoch: 6| Step: 9
Training loss: 2.9979753019754654
Validation loss: 2.5700083884115905

Epoch: 6| Step: 10
Training loss: 2.652090967911017
Validation loss: 2.566862471241636

Epoch: 6| Step: 11
Training loss: 2.253876842921787
Validation loss: 2.565033365941057

Epoch: 6| Step: 12
Training loss: 2.7280556161978002
Validation loss: 2.5660915326943523

Epoch: 6| Step: 13
Training loss: 2.514156505280535
Validation loss: 2.564631676444207

Epoch: 72| Step: 0
Training loss: 2.887325568937462
Validation loss: 2.5637598197298854

Epoch: 6| Step: 1
Training loss: 2.4971799203554528
Validation loss: 2.5661844576718784

Epoch: 6| Step: 2
Training loss: 2.368310240333858
Validation loss: 2.5624502999052803

Epoch: 6| Step: 3
Training loss: 3.1739379488210395
Validation loss: 2.5682376576483583

Epoch: 6| Step: 4
Training loss: 2.319680587057291
Validation loss: 2.566245156723484

Epoch: 6| Step: 5
Training loss: 3.127349275636044
Validation loss: 2.5654852311368375

Epoch: 6| Step: 6
Training loss: 2.7521513413355803
Validation loss: 2.567193036993444

Epoch: 6| Step: 7
Training loss: 2.4486141645018558
Validation loss: 2.564047896401527

Epoch: 6| Step: 8
Training loss: 3.0876821487380695
Validation loss: 2.5605120197002353

Epoch: 6| Step: 9
Training loss: 2.817099307388795
Validation loss: 2.561764665870583

Epoch: 6| Step: 10
Training loss: 2.7410413297524596
Validation loss: 2.5605982880288845

Epoch: 6| Step: 11
Training loss: 2.14482273142919
Validation loss: 2.5623082965381783

Epoch: 6| Step: 12
Training loss: 2.5835930375847123
Validation loss: 2.5625561033480606

Epoch: 6| Step: 13
Training loss: 2.524109836449512
Validation loss: 2.5600589041837343

Epoch: 73| Step: 0
Training loss: 2.518111711752477
Validation loss: 2.5592953096247943

Epoch: 6| Step: 1
Training loss: 2.7623046944049174
Validation loss: 2.559491896298365

Epoch: 6| Step: 2
Training loss: 2.9584892840762733
Validation loss: 2.557770434985027

Epoch: 6| Step: 3
Training loss: 2.7081471794905223
Validation loss: 2.557180356920057

Epoch: 6| Step: 4
Training loss: 2.8891251255507897
Validation loss: 2.5591955821487375

Epoch: 6| Step: 5
Training loss: 2.766583809894949
Validation loss: 2.5595620378488833

Epoch: 6| Step: 6
Training loss: 2.4926667425307474
Validation loss: 2.555913741699421

Epoch: 6| Step: 7
Training loss: 2.8582517992259393
Validation loss: 2.554747196787146

Epoch: 6| Step: 8
Training loss: 2.8128596605700498
Validation loss: 2.551935080030371

Epoch: 6| Step: 9
Training loss: 2.5408596779706683
Validation loss: 2.5498430864512573

Epoch: 6| Step: 10
Training loss: 2.3359999632378146
Validation loss: 2.5488532249023548

Epoch: 6| Step: 11
Training loss: 2.5891643570896927
Validation loss: 2.549263393998269

Epoch: 6| Step: 12
Training loss: 2.863433792193455
Validation loss: 2.5494108622788128

Epoch: 6| Step: 13
Training loss: 2.4911317891251348
Validation loss: 2.550140160093285

Epoch: 74| Step: 0
Training loss: 2.811694983667834
Validation loss: 2.549516957476687

Epoch: 6| Step: 1
Training loss: 2.422810232416531
Validation loss: 2.5516662931618477

Epoch: 6| Step: 2
Training loss: 2.0614607533547833
Validation loss: 2.550681033850589

Epoch: 6| Step: 3
Training loss: 2.1931482690732884
Validation loss: 2.549333957255392

Epoch: 6| Step: 4
Training loss: 2.6122590533397276
Validation loss: 2.5503429525045465

Epoch: 6| Step: 5
Training loss: 2.5692760847682297
Validation loss: 2.5480420299848303

Epoch: 6| Step: 6
Training loss: 2.92914871347785
Validation loss: 2.545874650768721

Epoch: 6| Step: 7
Training loss: 2.2056374799159673
Validation loss: 2.5448532348963218

Epoch: 6| Step: 8
Training loss: 2.773225846072179
Validation loss: 2.54570311126389

Epoch: 6| Step: 9
Training loss: 2.9588394985675874
Validation loss: 2.5425825553351817

Epoch: 6| Step: 10
Training loss: 3.205686261623084
Validation loss: 2.548835374376065

Epoch: 6| Step: 11
Training loss: 2.426586269402257
Validation loss: 2.545184723246345

Epoch: 6| Step: 12
Training loss: 3.149834940385347
Validation loss: 2.548106170951509

Epoch: 6| Step: 13
Training loss: 2.903169537583473
Validation loss: 2.5473412397066104

Epoch: 75| Step: 0
Training loss: 2.4646346159173427
Validation loss: 2.5489632795998043

Epoch: 6| Step: 1
Training loss: 3.1568891425789274
Validation loss: 2.5472439847737802

Epoch: 6| Step: 2
Training loss: 3.0112057260035234
Validation loss: 2.5491872639201687

Epoch: 6| Step: 3
Training loss: 2.5427405376548933
Validation loss: 2.5479513986819025

Epoch: 6| Step: 4
Training loss: 2.6931396571796515
Validation loss: 2.548757181361722

Epoch: 6| Step: 5
Training loss: 2.8895476111908707
Validation loss: 2.549380328113686

Epoch: 6| Step: 6
Training loss: 2.540872439338646
Validation loss: 2.548411492878279

Epoch: 6| Step: 7
Training loss: 2.300449418650842
Validation loss: 2.5465159094794307

Epoch: 6| Step: 8
Training loss: 2.874857194090443
Validation loss: 2.545847656305441

Epoch: 6| Step: 9
Training loss: 2.814569517186889
Validation loss: 2.5465008123383925

Epoch: 6| Step: 10
Training loss: 2.0433450793519357
Validation loss: 2.5456259381300095

Epoch: 6| Step: 11
Training loss: 2.894331581549543
Validation loss: 2.5440332828279892

Epoch: 6| Step: 12
Training loss: 2.2649589875068137
Validation loss: 2.544133862361923

Epoch: 6| Step: 13
Training loss: 2.7781044820879606
Validation loss: 2.543372509414239

Epoch: 76| Step: 0
Training loss: 2.739423004990021
Validation loss: 2.5435145076185237

Epoch: 6| Step: 1
Training loss: 2.496345137233522
Validation loss: 2.5422177472979204

Epoch: 6| Step: 2
Training loss: 2.4208735210433683
Validation loss: 2.5419258444129453

Epoch: 6| Step: 3
Training loss: 2.3725111117168085
Validation loss: 2.5418927034853187

Epoch: 6| Step: 4
Training loss: 2.522442128299259
Validation loss: 2.5404882252668126

Epoch: 6| Step: 5
Training loss: 2.63631697242719
Validation loss: 2.5384718613907444

Epoch: 6| Step: 6
Training loss: 2.7722730314261446
Validation loss: 2.5364326668967516

Epoch: 6| Step: 7
Training loss: 3.136641219951717
Validation loss: 2.5343965980246055

Epoch: 6| Step: 8
Training loss: 2.4435222275677035
Validation loss: 2.5323431064450097

Epoch: 6| Step: 9
Training loss: 2.787672535299385
Validation loss: 2.537467032721076

Epoch: 6| Step: 10
Training loss: 2.7084861027595384
Validation loss: 2.540324252675449

Epoch: 6| Step: 11
Training loss: 2.5722735961697865
Validation loss: 2.544715324523629

Epoch: 6| Step: 12
Training loss: 2.9414503441250073
Validation loss: 2.5495690604945693

Epoch: 6| Step: 13
Training loss: 2.7499139945712963
Validation loss: 2.5404611970305226

Epoch: 77| Step: 0
Training loss: 2.3550201039357193
Validation loss: 2.5340990586583265

Epoch: 6| Step: 1
Training loss: 3.0089148941149624
Validation loss: 2.5340481429360353

Epoch: 6| Step: 2
Training loss: 2.642703981637786
Validation loss: 2.5337786191137335

Epoch: 6| Step: 3
Training loss: 2.589820919252686
Validation loss: 2.533303373770325

Epoch: 6| Step: 4
Training loss: 2.549416426658484
Validation loss: 2.5335821075595417

Epoch: 6| Step: 5
Training loss: 2.48521035023684
Validation loss: 2.5356875324820782

Epoch: 6| Step: 6
Training loss: 2.8711160049094953
Validation loss: 2.5426665330134

Epoch: 6| Step: 7
Training loss: 2.5493846300396346
Validation loss: 2.549697622435027

Epoch: 6| Step: 8
Training loss: 2.7778997924286077
Validation loss: 2.5519506043673217

Epoch: 6| Step: 9
Training loss: 2.5581051425456702
Validation loss: 2.558047869740691

Epoch: 6| Step: 10
Training loss: 2.5523458125278626
Validation loss: 2.555997724450481

Epoch: 6| Step: 11
Training loss: 2.524992472571304
Validation loss: 2.552081475289635

Epoch: 6| Step: 12
Training loss: 3.350762260598442
Validation loss: 2.547000078433689

Epoch: 6| Step: 13
Training loss: 2.5071472997008892
Validation loss: 2.541024069511814

Epoch: 78| Step: 0
Training loss: 2.3316112248680447
Validation loss: 2.536875544915521

Epoch: 6| Step: 1
Training loss: 2.83926625000896
Validation loss: 2.5327867309338807

Epoch: 6| Step: 2
Training loss: 2.803812809724047
Validation loss: 2.5325780924398833

Epoch: 6| Step: 3
Training loss: 2.825223076713947
Validation loss: 2.5304550366816723

Epoch: 6| Step: 4
Training loss: 2.4482057657716636
Validation loss: 2.5289240381877964

Epoch: 6| Step: 5
Training loss: 2.430341724496197
Validation loss: 2.5271550245145384

Epoch: 6| Step: 6
Training loss: 2.6997899998131003
Validation loss: 2.524775525303344

Epoch: 6| Step: 7
Training loss: 3.1183995541164653
Validation loss: 2.5247945531979736

Epoch: 6| Step: 8
Training loss: 2.795878312667704
Validation loss: 2.5241079945471028

Epoch: 6| Step: 9
Training loss: 2.776256493325092
Validation loss: 2.52255687169367

Epoch: 6| Step: 10
Training loss: 2.8167306234408174
Validation loss: 2.5236048372291346

Epoch: 6| Step: 11
Training loss: 2.4563419121005623
Validation loss: 2.522701789993855

Epoch: 6| Step: 12
Training loss: 2.4412606401890358
Validation loss: 2.5233155842118618

Epoch: 6| Step: 13
Training loss: 2.467061878023646
Validation loss: 2.523764290922683

Epoch: 79| Step: 0
Training loss: 2.814431184448874
Validation loss: 2.5212182520877158

Epoch: 6| Step: 1
Training loss: 2.5140354987212423
Validation loss: 2.5194982087879105

Epoch: 6| Step: 2
Training loss: 2.1297125453134007
Validation loss: 2.521524135001322

Epoch: 6| Step: 3
Training loss: 2.8011397766734016
Validation loss: 2.523641965788622

Epoch: 6| Step: 4
Training loss: 2.5381353475495487
Validation loss: 2.5220773375439007

Epoch: 6| Step: 5
Training loss: 2.952998082900208
Validation loss: 2.523540482914568

Epoch: 6| Step: 6
Training loss: 2.4128397094631073
Validation loss: 2.5243337041680887

Epoch: 6| Step: 7
Training loss: 2.2895838433480034
Validation loss: 2.5246683038201407

Epoch: 6| Step: 8
Training loss: 2.223202174072191
Validation loss: 2.524458703163485

Epoch: 6| Step: 9
Training loss: 3.1168335065877493
Validation loss: 2.5246069750193283

Epoch: 6| Step: 10
Training loss: 2.5795934945347296
Validation loss: 2.5224311955837893

Epoch: 6| Step: 11
Training loss: 3.056248258812531
Validation loss: 2.522884887087754

Epoch: 6| Step: 12
Training loss: 2.7956114743965386
Validation loss: 2.5211604092689415

Epoch: 6| Step: 13
Training loss: 2.688451731519002
Validation loss: 2.519645589752533

Epoch: 80| Step: 0
Training loss: 2.814447788124928
Validation loss: 2.5187381255041106

Epoch: 6| Step: 1
Training loss: 2.9690270545577384
Validation loss: 2.518192615789482

Epoch: 6| Step: 2
Training loss: 2.3409425324006654
Validation loss: 2.5189807536879187

Epoch: 6| Step: 3
Training loss: 3.0396467495517547
Validation loss: 2.514862576845075

Epoch: 6| Step: 4
Training loss: 2.702186730337182
Validation loss: 2.5152374980062113

Epoch: 6| Step: 5
Training loss: 2.8261484225551627
Validation loss: 2.516130463738714

Epoch: 6| Step: 6
Training loss: 2.2929372444132934
Validation loss: 2.5168646370366785

Epoch: 6| Step: 7
Training loss: 2.8585494053380973
Validation loss: 2.514250385667874

Epoch: 6| Step: 8
Training loss: 2.554484508044071
Validation loss: 2.5133141749973147

Epoch: 6| Step: 9
Training loss: 2.8075696327494386
Validation loss: 2.512027719497612

Epoch: 6| Step: 10
Training loss: 2.536977810051047
Validation loss: 2.5151354548365266

Epoch: 6| Step: 11
Training loss: 2.7804782096613985
Validation loss: 2.51274348228985

Epoch: 6| Step: 12
Training loss: 2.3670481020734027
Validation loss: 2.510440720776647

Epoch: 6| Step: 13
Training loss: 1.8072909777490658
Validation loss: 2.5081162630194056

Epoch: 81| Step: 0
Training loss: 1.9441938132777932
Validation loss: 2.5096369649759533

Epoch: 6| Step: 1
Training loss: 2.6733327536292966
Validation loss: 2.514802849729216

Epoch: 6| Step: 2
Training loss: 2.8267503632744035
Validation loss: 2.520479829030093

Epoch: 6| Step: 3
Training loss: 2.1692915446440257
Validation loss: 2.518753302282499

Epoch: 6| Step: 4
Training loss: 3.207779345222598
Validation loss: 2.531837740507599

Epoch: 6| Step: 5
Training loss: 2.3783421340847273
Validation loss: 2.525117250118559

Epoch: 6| Step: 6
Training loss: 3.01307056136488
Validation loss: 2.527208807132027

Epoch: 6| Step: 7
Training loss: 2.0508272874296876
Validation loss: 2.5346672632770884

Epoch: 6| Step: 8
Training loss: 2.7400114549272097
Validation loss: 2.5394380888322363

Epoch: 6| Step: 9
Training loss: 3.0594819436947076
Validation loss: 2.5246268777281395

Epoch: 6| Step: 10
Training loss: 2.6542765747821027
Validation loss: 2.5110939716168663

Epoch: 6| Step: 11
Training loss: 2.2494735101792256
Validation loss: 2.511214534445161

Epoch: 6| Step: 12
Training loss: 2.871162174992458
Validation loss: 2.5119631002251004

Epoch: 6| Step: 13
Training loss: 2.7724229273217773
Validation loss: 2.513899019535885

Epoch: 82| Step: 0
Training loss: 2.3745977161420586
Validation loss: 2.516585993789558

Epoch: 6| Step: 1
Training loss: 2.2239971172396413
Validation loss: 2.518054255210324

Epoch: 6| Step: 2
Training loss: 2.6854483291578446
Validation loss: 2.5234574040591435

Epoch: 6| Step: 3
Training loss: 2.3327756169770373
Validation loss: 2.5239685885454177

Epoch: 6| Step: 4
Training loss: 2.7585588261228318
Validation loss: 2.5268847969060886

Epoch: 6| Step: 5
Training loss: 2.735302228390795
Validation loss: 2.53024940965169

Epoch: 6| Step: 6
Training loss: 2.685262502699604
Validation loss: 2.5368967375850358

Epoch: 6| Step: 7
Training loss: 2.307726288814268
Validation loss: 2.535495525712479

Epoch: 6| Step: 8
Training loss: 3.158768659264085
Validation loss: 2.541544197342131

Epoch: 6| Step: 9
Training loss: 2.940215296485116
Validation loss: 2.5563300371270246

Epoch: 6| Step: 10
Training loss: 2.5935846298997824
Validation loss: 2.5352317747867805

Epoch: 6| Step: 11
Training loss: 2.603864230078139
Validation loss: 2.5304867728002645

Epoch: 6| Step: 12
Training loss: 2.7229770816170524
Validation loss: 2.5271405428715856

Epoch: 6| Step: 13
Training loss: 2.940693681585768
Validation loss: 2.520612696510339

Epoch: 83| Step: 0
Training loss: 2.960085945170412
Validation loss: 2.5179024569560595

Epoch: 6| Step: 1
Training loss: 2.586769269877914
Validation loss: 2.5172629700453895

Epoch: 6| Step: 2
Training loss: 2.658952482661868
Validation loss: 2.5142488447302176

Epoch: 6| Step: 3
Training loss: 2.8759090810737638
Validation loss: 2.507978027838669

Epoch: 6| Step: 4
Training loss: 2.5185175786089338
Validation loss: 2.5074567057154535

Epoch: 6| Step: 5
Training loss: 2.3621692405748926
Validation loss: 2.506641752426974

Epoch: 6| Step: 6
Training loss: 2.9207046531233463
Validation loss: 2.5049969166922614

Epoch: 6| Step: 7
Training loss: 2.580985407164688
Validation loss: 2.5072556429024893

Epoch: 6| Step: 8
Training loss: 2.431785928452348
Validation loss: 2.5050012948393885

Epoch: 6| Step: 9
Training loss: 2.5153364880897007
Validation loss: 2.504404209906884

Epoch: 6| Step: 10
Training loss: 2.3851219117297706
Validation loss: 2.50536825471949

Epoch: 6| Step: 11
Training loss: 2.749926999597043
Validation loss: 2.511558025274325

Epoch: 6| Step: 12
Training loss: 2.7097128264799104
Validation loss: 2.5087718930862795

Epoch: 6| Step: 13
Training loss: 2.4109478953366703
Validation loss: 2.5102144426331687

Epoch: 84| Step: 0
Training loss: 2.6539499534712
Validation loss: 2.515255697560572

Epoch: 6| Step: 1
Training loss: 2.6019504017365365
Validation loss: 2.5156482987677466

Epoch: 6| Step: 2
Training loss: 2.999791773881232
Validation loss: 2.515971063224106

Epoch: 6| Step: 3
Training loss: 2.589604753654767
Validation loss: 2.5089647096230165

Epoch: 6| Step: 4
Training loss: 2.156281180778289
Validation loss: 2.5047897787583286

Epoch: 6| Step: 5
Training loss: 3.1326858609067396
Validation loss: 2.503916882726953

Epoch: 6| Step: 6
Training loss: 2.5350343648473546
Validation loss: 2.5015986099829743

Epoch: 6| Step: 7
Training loss: 2.3925773278059896
Validation loss: 2.5011586285979654

Epoch: 6| Step: 8
Training loss: 2.7817904343753987
Validation loss: 2.4997598214808407

Epoch: 6| Step: 9
Training loss: 2.717434531987556
Validation loss: 2.5020038203538837

Epoch: 6| Step: 10
Training loss: 2.709254729209518
Validation loss: 2.5040894122486375

Epoch: 6| Step: 11
Training loss: 2.5993763212295553
Validation loss: 2.5098504711410152

Epoch: 6| Step: 12
Training loss: 2.452317414715038
Validation loss: 2.5086332346769815

Epoch: 6| Step: 13
Training loss: 2.5438061344785674
Validation loss: 2.508235955064329

Epoch: 85| Step: 0
Training loss: 2.5747284681244182
Validation loss: 2.5080600509390143

Epoch: 6| Step: 1
Training loss: 2.531149779796461
Validation loss: 2.5065641693032314

Epoch: 6| Step: 2
Training loss: 2.041958560967747
Validation loss: 2.5087152046764585

Epoch: 6| Step: 3
Training loss: 2.340834775521131
Validation loss: 2.5139886260810975

Epoch: 6| Step: 4
Training loss: 2.9528039828413917
Validation loss: 2.507283805662626

Epoch: 6| Step: 5
Training loss: 2.6925945344018425
Validation loss: 2.50420921742303

Epoch: 6| Step: 6
Training loss: 2.227786828443112
Validation loss: 2.5027360090815334

Epoch: 6| Step: 7
Training loss: 2.376882509735786
Validation loss: 2.500456609353419

Epoch: 6| Step: 8
Training loss: 2.8837978260851433
Validation loss: 2.5005750153788275

Epoch: 6| Step: 9
Training loss: 2.643582555640188
Validation loss: 2.494855578618624

Epoch: 6| Step: 10
Training loss: 3.151241142747742
Validation loss: 2.499208786056068

Epoch: 6| Step: 11
Training loss: 2.6048925583368145
Validation loss: 2.4967434494764293

Epoch: 6| Step: 12
Training loss: 2.9310660819000387
Validation loss: 2.496682819391448

Epoch: 6| Step: 13
Training loss: 2.623554194878458
Validation loss: 2.492851400088986

Epoch: 86| Step: 0
Training loss: 2.6655645079641506
Validation loss: 2.492411747871514

Epoch: 6| Step: 1
Training loss: 2.6056296143064315
Validation loss: 2.492863355174205

Epoch: 6| Step: 2
Training loss: 2.4422690858105915
Validation loss: 2.491535902791609

Epoch: 6| Step: 3
Training loss: 2.3832645175131133
Validation loss: 2.497148254236352

Epoch: 6| Step: 4
Training loss: 2.2610510596575795
Validation loss: 2.4985530321591165

Epoch: 6| Step: 5
Training loss: 3.006275289512424
Validation loss: 2.4962978209969244

Epoch: 6| Step: 6
Training loss: 3.001409835150001
Validation loss: 2.4992188981837136

Epoch: 6| Step: 7
Training loss: 2.8150025148532944
Validation loss: 2.497128522381183

Epoch: 6| Step: 8
Training loss: 2.161413892419326
Validation loss: 2.4938400991634806

Epoch: 6| Step: 9
Training loss: 2.43872909857603
Validation loss: 2.495504135515662

Epoch: 6| Step: 10
Training loss: 2.4606769726617594
Validation loss: 2.4930608608244893

Epoch: 6| Step: 11
Training loss: 3.009714768541377
Validation loss: 2.496952870172815

Epoch: 6| Step: 12
Training loss: 2.6244756992441083
Validation loss: 2.4988303150260633

Epoch: 6| Step: 13
Training loss: 2.6949865171700345
Validation loss: 2.5014095147630018

Epoch: 87| Step: 0
Training loss: 2.797663742605071
Validation loss: 2.503627767564479

Epoch: 6| Step: 1
Training loss: 2.775894409243758
Validation loss: 2.5014677507516536

Epoch: 6| Step: 2
Training loss: 2.879711768244187
Validation loss: 2.5011458949675456

Epoch: 6| Step: 3
Training loss: 2.3600602323313558
Validation loss: 2.50087033857631

Epoch: 6| Step: 4
Training loss: 2.3074475329748325
Validation loss: 2.499641329149788

Epoch: 6| Step: 5
Training loss: 2.2187291533874314
Validation loss: 2.498826816580957

Epoch: 6| Step: 6
Training loss: 2.5227471225091938
Validation loss: 2.497057963810556

Epoch: 6| Step: 7
Training loss: 3.0233425549328303
Validation loss: 2.5002738484759304

Epoch: 6| Step: 8
Training loss: 2.4978771733674137
Validation loss: 2.4966133862282294

Epoch: 6| Step: 9
Training loss: 2.897225427265128
Validation loss: 2.49572311777874

Epoch: 6| Step: 10
Training loss: 2.771582958573032
Validation loss: 2.4955413159279036

Epoch: 6| Step: 11
Training loss: 2.3406843353614337
Validation loss: 2.4968481858921954

Epoch: 6| Step: 12
Training loss: 2.4313666622149714
Validation loss: 2.4974852788909443

Epoch: 6| Step: 13
Training loss: 2.718731847242065
Validation loss: 2.4886585630221405

Epoch: 88| Step: 0
Training loss: 3.268410256929962
Validation loss: 2.4905612147646052

Epoch: 6| Step: 1
Training loss: 2.2440339570221646
Validation loss: 2.494285362224172

Epoch: 6| Step: 2
Training loss: 2.694756403514014
Validation loss: 2.4912377344452548

Epoch: 6| Step: 3
Training loss: 2.558383612703012
Validation loss: 2.492711648860458

Epoch: 6| Step: 4
Training loss: 2.6950717099757515
Validation loss: 2.489208932812969

Epoch: 6| Step: 5
Training loss: 2.5376750265558576
Validation loss: 2.4904218296480223

Epoch: 6| Step: 6
Training loss: 2.310011271990072
Validation loss: 2.489598267535716

Epoch: 6| Step: 7
Training loss: 2.6409363873413616
Validation loss: 2.488327992078598

Epoch: 6| Step: 8
Training loss: 2.8784137858456673
Validation loss: 2.490376874050431

Epoch: 6| Step: 9
Training loss: 2.4989766887601808
Validation loss: 2.4962833911570765

Epoch: 6| Step: 10
Training loss: 2.1550108071607186
Validation loss: 2.4917332345837306

Epoch: 6| Step: 11
Training loss: 2.8603017170353877
Validation loss: 2.4937626037661578

Epoch: 6| Step: 12
Training loss: 2.41102799488651
Validation loss: 2.494335815152491

Epoch: 6| Step: 13
Training loss: 2.500410618439144
Validation loss: 2.4924685360610255

Epoch: 89| Step: 0
Training loss: 2.642414186612701
Validation loss: 2.4867275942973626

Epoch: 6| Step: 1
Training loss: 2.2165445461430773
Validation loss: 2.4909269918005483

Epoch: 6| Step: 2
Training loss: 2.6062828519292096
Validation loss: 2.488468404665258

Epoch: 6| Step: 3
Training loss: 2.326825284752106
Validation loss: 2.486579348929068

Epoch: 6| Step: 4
Training loss: 2.675107996534222
Validation loss: 2.4901833921711263

Epoch: 6| Step: 5
Training loss: 3.034096551252814
Validation loss: 2.492856596573072

Epoch: 6| Step: 6
Training loss: 2.135460519728037
Validation loss: 2.4907276019154647

Epoch: 6| Step: 7
Training loss: 2.7146255954390996
Validation loss: 2.4884784007556555

Epoch: 6| Step: 8
Training loss: 2.2928393975705665
Validation loss: 2.491294477620482

Epoch: 6| Step: 9
Training loss: 3.0257419212300904
Validation loss: 2.48803516490552

Epoch: 6| Step: 10
Training loss: 2.4498963703893626
Validation loss: 2.4917861631268536

Epoch: 6| Step: 11
Training loss: 2.3781012314599925
Validation loss: 2.486542849521993

Epoch: 6| Step: 12
Training loss: 2.747463270085915
Validation loss: 2.4876592748055844

Epoch: 6| Step: 13
Training loss: 3.045054826164571
Validation loss: 2.48646108347231

Epoch: 90| Step: 0
Training loss: 2.7260350807546714
Validation loss: 2.4838863348056024

Epoch: 6| Step: 1
Training loss: 2.600459234321914
Validation loss: 2.491698883852001

Epoch: 6| Step: 2
Training loss: 3.0042040296568806
Validation loss: 2.4902597782609517

Epoch: 6| Step: 3
Training loss: 2.387026203537471
Validation loss: 2.488871785289129

Epoch: 6| Step: 4
Training loss: 2.508935029448676
Validation loss: 2.4911698084134875

Epoch: 6| Step: 5
Training loss: 2.35823385165867
Validation loss: 2.49085058628955

Epoch: 6| Step: 6
Training loss: 2.1844673933973384
Validation loss: 2.4879166651887457

Epoch: 6| Step: 7
Training loss: 2.7957987499419557
Validation loss: 2.4903891681107986

Epoch: 6| Step: 8
Training loss: 2.8669197310888976
Validation loss: 2.4907675338159105

Epoch: 6| Step: 9
Training loss: 2.836810521453865
Validation loss: 2.49170673002187

Epoch: 6| Step: 10
Training loss: 2.4551008492012167
Validation loss: 2.4911371168052825

Epoch: 6| Step: 11
Training loss: 2.5390985574362803
Validation loss: 2.4871931107188527

Epoch: 6| Step: 12
Training loss: 2.3672940573299357
Validation loss: 2.485992752634432

Epoch: 6| Step: 13
Training loss: 2.725517356827089
Validation loss: 2.489427239753182

Epoch: 91| Step: 0
Training loss: 1.9524851857305952
Validation loss: 2.489319653027864

Epoch: 6| Step: 1
Training loss: 2.0539994048551384
Validation loss: 2.490485539953241

Epoch: 6| Step: 2
Training loss: 2.7831644048841704
Validation loss: 2.4917802149013424

Epoch: 6| Step: 3
Training loss: 2.4081564942831792
Validation loss: 2.48953927505219

Epoch: 6| Step: 4
Training loss: 2.4511370531017596
Validation loss: 2.4941661637247607

Epoch: 6| Step: 5
Training loss: 3.3237433446593
Validation loss: 2.490094125824912

Epoch: 6| Step: 6
Training loss: 2.3979435017462647
Validation loss: 2.486595217374591

Epoch: 6| Step: 7
Training loss: 2.5642692226876918
Validation loss: 2.4857291363873837

Epoch: 6| Step: 8
Training loss: 2.606370761186767
Validation loss: 2.4871057341692615

Epoch: 6| Step: 9
Training loss: 2.67511949361421
Validation loss: 2.4917770573924862

Epoch: 6| Step: 10
Training loss: 2.8141745774287164
Validation loss: 2.489894916609954

Epoch: 6| Step: 11
Training loss: 2.3481474249923684
Validation loss: 2.489407845753807

Epoch: 6| Step: 12
Training loss: 2.9597698717614214
Validation loss: 2.488062027996178

Epoch: 6| Step: 13
Training loss: 2.665908308279618
Validation loss: 2.4901467062284595

Epoch: 92| Step: 0
Training loss: 2.579588133887021
Validation loss: 2.488220230064985

Epoch: 6| Step: 1
Training loss: 2.7451836283815214
Validation loss: 2.477398319178712

Epoch: 6| Step: 2
Training loss: 2.967350680186638
Validation loss: 2.4844439355015258

Epoch: 6| Step: 3
Training loss: 2.5691934949884883
Validation loss: 2.4829912150557

Epoch: 6| Step: 4
Training loss: 2.648140409567472
Validation loss: 2.4931044530958233

Epoch: 6| Step: 5
Training loss: 3.0400829808303707
Validation loss: 2.479045934435442

Epoch: 6| Step: 6
Training loss: 2.2948136194546755
Validation loss: 2.4791663728174202

Epoch: 6| Step: 7
Training loss: 2.1954638880325006
Validation loss: 2.4799266793579715

Epoch: 6| Step: 8
Training loss: 2.700561807604239
Validation loss: 2.4827778478708593

Epoch: 6| Step: 9
Training loss: 2.1753108887624673
Validation loss: 2.482026419566346

Epoch: 6| Step: 10
Training loss: 2.340014316156398
Validation loss: 2.483800729720835

Epoch: 6| Step: 11
Training loss: 2.752414683614403
Validation loss: 2.488134566474493

Epoch: 6| Step: 12
Training loss: 2.9085979206507164
Validation loss: 2.4895740226880085

Epoch: 6| Step: 13
Training loss: 2.2977890998336754
Validation loss: 2.488049969986009

Epoch: 93| Step: 0
Training loss: 1.5741428707189518
Validation loss: 2.487345025811702

Epoch: 6| Step: 1
Training loss: 2.9467730960641507
Validation loss: 2.4853385640162298

Epoch: 6| Step: 2
Training loss: 2.714217869907408
Validation loss: 2.4896200701398574

Epoch: 6| Step: 3
Training loss: 2.9633872333283278
Validation loss: 2.4847256235102124

Epoch: 6| Step: 4
Training loss: 2.5589824818007423
Validation loss: 2.487527714228276

Epoch: 6| Step: 5
Training loss: 2.1046029825098267
Validation loss: 2.4850038896065865

Epoch: 6| Step: 6
Training loss: 2.9578893265618436
Validation loss: 2.484992216521469

Epoch: 6| Step: 7
Training loss: 2.3259400220962623
Validation loss: 2.4859310451370216

Epoch: 6| Step: 8
Training loss: 2.638719401577445
Validation loss: 2.483236183809361

Epoch: 6| Step: 9
Training loss: 2.5854758227945447
Validation loss: 2.4848698057305283

Epoch: 6| Step: 10
Training loss: 2.7343014952452913
Validation loss: 2.482198021312656

Epoch: 6| Step: 11
Training loss: 2.701234012752392
Validation loss: 2.4833835246840548

Epoch: 6| Step: 12
Training loss: 2.929288058707062
Validation loss: 2.48048223056284

Epoch: 6| Step: 13
Training loss: 2.1861703373750534
Validation loss: 2.4786953090649653

Epoch: 94| Step: 0
Training loss: 2.7389778850953697
Validation loss: 2.482821124545803

Epoch: 6| Step: 1
Training loss: 2.4568619176981636
Validation loss: 2.4867240468666996

Epoch: 6| Step: 2
Training loss: 2.5999173297943794
Validation loss: 2.4845947552301735

Epoch: 6| Step: 3
Training loss: 2.3043387456265947
Validation loss: 2.4761006338768805

Epoch: 6| Step: 4
Training loss: 2.396244102315555
Validation loss: 2.4832708276225794

Epoch: 6| Step: 5
Training loss: 2.911308234661358
Validation loss: 2.4806423977521863

Epoch: 6| Step: 6
Training loss: 2.395551902716704
Validation loss: 2.4834379272281364

Epoch: 6| Step: 7
Training loss: 3.25205869761065
Validation loss: 2.4756436092322858

Epoch: 6| Step: 8
Training loss: 2.682304861289351
Validation loss: 2.4792012978921196

Epoch: 6| Step: 9
Training loss: 2.244638837552127
Validation loss: 2.4835376887970546

Epoch: 6| Step: 10
Training loss: 2.1764857249196026
Validation loss: 2.478297912158114

Epoch: 6| Step: 11
Training loss: 1.9942203696331837
Validation loss: 2.479815347472923

Epoch: 6| Step: 12
Training loss: 2.7744985350733686
Validation loss: 2.4843159794544465

Epoch: 6| Step: 13
Training loss: 3.0319788734887694
Validation loss: 2.481986987430009

Epoch: 95| Step: 0
Training loss: 2.8401053411799753
Validation loss: 2.4830602449848254

Epoch: 6| Step: 1
Training loss: 2.6941547948180635
Validation loss: 2.483454159756396

Epoch: 6| Step: 2
Training loss: 2.588785867410332
Validation loss: 2.4803654366351653

Epoch: 6| Step: 3
Training loss: 2.518469487701973
Validation loss: 2.4816113020761086

Epoch: 6| Step: 4
Training loss: 2.5602529955066893
Validation loss: 2.4846146346026967

Epoch: 6| Step: 5
Training loss: 2.1103874884870075
Validation loss: 2.4841187702856433

Epoch: 6| Step: 6
Training loss: 2.8802800000031192
Validation loss: 2.4810690966815367

Epoch: 6| Step: 7
Training loss: 3.0542176024251884
Validation loss: 2.483670796649929

Epoch: 6| Step: 8
Training loss: 2.4730347739866434
Validation loss: 2.4759366340704703

Epoch: 6| Step: 9
Training loss: 2.5150420656724712
Validation loss: 2.4752725637352913

Epoch: 6| Step: 10
Training loss: 2.403210888184722
Validation loss: 2.4770909015442584

Epoch: 6| Step: 11
Training loss: 2.233520557849519
Validation loss: 2.479156996336811

Epoch: 6| Step: 12
Training loss: 2.8405727201210493
Validation loss: 2.476054992982285

Epoch: 6| Step: 13
Training loss: 2.324577957733315
Validation loss: 2.474800485860233

Epoch: 96| Step: 0
Training loss: 2.1567954879956917
Validation loss: 2.477423148324953

Epoch: 6| Step: 1
Training loss: 2.5838280686025037
Validation loss: 2.4766663410225913

Epoch: 6| Step: 2
Training loss: 2.523590555657264
Validation loss: 2.476671828174304

Epoch: 6| Step: 3
Training loss: 2.5008732224354806
Validation loss: 2.4832045159009217

Epoch: 6| Step: 4
Training loss: 3.021331447881305
Validation loss: 2.478780272903808

Epoch: 6| Step: 5
Training loss: 2.519354951589956
Validation loss: 2.478177407517506

Epoch: 6| Step: 6
Training loss: 2.760113844665897
Validation loss: 2.4822775986166485

Epoch: 6| Step: 7
Training loss: 2.26778671790369
Validation loss: 2.481258941301175

Epoch: 6| Step: 8
Training loss: 2.781250685788188
Validation loss: 2.4776601996082306

Epoch: 6| Step: 9
Training loss: 2.5278885739070547
Validation loss: 2.4814902457540593

Epoch: 6| Step: 10
Training loss: 2.75372876616684
Validation loss: 2.4777440602907457

Epoch: 6| Step: 11
Training loss: 2.2693564368990855
Validation loss: 2.4751408263963444

Epoch: 6| Step: 12
Training loss: 3.0233094338590827
Validation loss: 2.478625460195822

Epoch: 6| Step: 13
Training loss: 2.3261087378606278
Validation loss: 2.4802541725080784

Epoch: 97| Step: 0
Training loss: 2.376050616332083
Validation loss: 2.4753845975663116

Epoch: 6| Step: 1
Training loss: 2.4195191769518876
Validation loss: 2.480721800704636

Epoch: 6| Step: 2
Training loss: 2.3119970238610352
Validation loss: 2.4763414382548614

Epoch: 6| Step: 3
Training loss: 2.829257127292248
Validation loss: 2.4741385678676227

Epoch: 6| Step: 4
Training loss: 2.207397430559996
Validation loss: 2.479263990292419

Epoch: 6| Step: 5
Training loss: 2.544536617040318
Validation loss: 2.4797394568983884

Epoch: 6| Step: 6
Training loss: 2.3722471043306443
Validation loss: 2.4801210334940555

Epoch: 6| Step: 7
Training loss: 2.537982981150556
Validation loss: 2.4775456543843375

Epoch: 6| Step: 8
Training loss: 2.6642472099639667
Validation loss: 2.477384541140722

Epoch: 6| Step: 9
Training loss: 3.2485773934411286
Validation loss: 2.4777376132707176

Epoch: 6| Step: 10
Training loss: 2.718214047978235
Validation loss: 2.4836863476999915

Epoch: 6| Step: 11
Training loss: 2.480222290290314
Validation loss: 2.4810722678177592

Epoch: 6| Step: 12
Training loss: 2.5797688185446015
Validation loss: 2.477893812468556

Epoch: 6| Step: 13
Training loss: 2.669500533974682
Validation loss: 2.4793129778945544

Epoch: 98| Step: 0
Training loss: 2.6122510216450197
Validation loss: 2.4828804927067964

Epoch: 6| Step: 1
Training loss: 2.420900801103122
Validation loss: 2.4780967925664332

Epoch: 6| Step: 2
Training loss: 2.4328266238940026
Validation loss: 2.476065536681395

Epoch: 6| Step: 3
Training loss: 1.9734465271901114
Validation loss: 2.4714833591942034

Epoch: 6| Step: 4
Training loss: 2.4728637415410732
Validation loss: 2.4670076297827066

Epoch: 6| Step: 5
Training loss: 2.388966901624144
Validation loss: 2.4681767228632383

Epoch: 6| Step: 6
Training loss: 2.33593984750483
Validation loss: 2.4672351809197144

Epoch: 6| Step: 7
Training loss: 2.8042334398894626
Validation loss: 2.4725018091969804

Epoch: 6| Step: 8
Training loss: 2.3203237000268935
Validation loss: 2.4692473735444542

Epoch: 6| Step: 9
Training loss: 2.489421780716785
Validation loss: 2.469028425008501

Epoch: 6| Step: 10
Training loss: 3.020340311442376
Validation loss: 2.474138728474749

Epoch: 6| Step: 11
Training loss: 2.8884169934882125
Validation loss: 2.4760039910154372

Epoch: 6| Step: 12
Training loss: 2.6441915229072293
Validation loss: 2.4665897752616783

Epoch: 6| Step: 13
Training loss: 3.0863259372816887
Validation loss: 2.4724627073051453

Epoch: 99| Step: 0
Training loss: 2.7755759148486887
Validation loss: 2.4737850623772677

Epoch: 6| Step: 1
Training loss: 2.4978871954376944
Validation loss: 2.4811968518257412

Epoch: 6| Step: 2
Training loss: 2.9858072249470324
Validation loss: 2.485020631593221

Epoch: 6| Step: 3
Training loss: 2.329288166496225
Validation loss: 2.481433782809696

Epoch: 6| Step: 4
Training loss: 2.763193041833666
Validation loss: 2.484950832594355

Epoch: 6| Step: 5
Training loss: 2.391906992925347
Validation loss: 2.4852351173247156

Epoch: 6| Step: 6
Training loss: 2.3114471100621676
Validation loss: 2.483976144182622

Epoch: 6| Step: 7
Training loss: 2.040086744745533
Validation loss: 2.4780527278307836

Epoch: 6| Step: 8
Training loss: 2.7335283112958617
Validation loss: 2.479591162319919

Epoch: 6| Step: 9
Training loss: 2.6653085071284686
Validation loss: 2.475053730776385

Epoch: 6| Step: 10
Training loss: 2.3836136268529637
Validation loss: 2.4733350965934013

Epoch: 6| Step: 11
Training loss: 3.022038256743241
Validation loss: 2.476947309279341

Epoch: 6| Step: 12
Training loss: 2.5609600743432863
Validation loss: 2.474321251735341

Epoch: 6| Step: 13
Training loss: 2.568171760465733
Validation loss: 2.478784424835637

Epoch: 100| Step: 0
Training loss: 2.3935698279559903
Validation loss: 2.472623193086981

Epoch: 6| Step: 1
Training loss: 2.529147652602222
Validation loss: 2.476159649644392

Epoch: 6| Step: 2
Training loss: 2.4190819170021904
Validation loss: 2.476514332460329

Epoch: 6| Step: 3
Training loss: 2.8594025157167375
Validation loss: 2.4762093485756673

Epoch: 6| Step: 4
Training loss: 2.2885039497593107
Validation loss: 2.473564828730876

Epoch: 6| Step: 5
Training loss: 1.910813918527336
Validation loss: 2.47316776426649

Epoch: 6| Step: 6
Training loss: 2.7224063183908735
Validation loss: 2.470404380458529

Epoch: 6| Step: 7
Training loss: 2.538488047245746
Validation loss: 2.47055354815263

Epoch: 6| Step: 8
Training loss: 2.5622779005610163
Validation loss: 2.469239278990142

Epoch: 6| Step: 9
Training loss: 2.9737930029204707
Validation loss: 2.476008115505544

Epoch: 6| Step: 10
Training loss: 2.5826210352553014
Validation loss: 2.46983501879484

Epoch: 6| Step: 11
Training loss: 3.0466289714370554
Validation loss: 2.4705186777536654

Epoch: 6| Step: 12
Training loss: 2.6549120057605107
Validation loss: 2.4698158249034856

Epoch: 6| Step: 13
Training loss: 2.4020849072952166
Validation loss: 2.4724784252792738

Epoch: 101| Step: 0
Training loss: 2.60978540174085
Validation loss: 2.4775313318493075

Epoch: 6| Step: 1
Training loss: 2.3669816232926024
Validation loss: 2.4731749783468446

Epoch: 6| Step: 2
Training loss: 2.9789920213278123
Validation loss: 2.4788963640674915

Epoch: 6| Step: 3
Training loss: 2.8350369623590264
Validation loss: 2.4732574487322903

Epoch: 6| Step: 4
Training loss: 2.428365366071435
Validation loss: 2.4701415377385123

Epoch: 6| Step: 5
Training loss: 2.7598442395804885
Validation loss: 2.4748005019166506

Epoch: 6| Step: 6
Training loss: 2.2158338698488955
Validation loss: 2.47569396857325

Epoch: 6| Step: 7
Training loss: 2.098749824055885
Validation loss: 2.4762339890546694

Epoch: 6| Step: 8
Training loss: 2.4544645891772703
Validation loss: 2.47554786346872

Epoch: 6| Step: 9
Training loss: 2.873224456506282
Validation loss: 2.4816367535766335

Epoch: 6| Step: 10
Training loss: 2.604736774346931
Validation loss: 2.4833207042637517

Epoch: 6| Step: 11
Training loss: 2.7328277570016146
Validation loss: 2.479255760152073

Epoch: 6| Step: 12
Training loss: 2.747789361379747
Validation loss: 2.477414980236965

Epoch: 6| Step: 13
Training loss: 2.1968810427326213
Validation loss: 2.4771807968775934

Epoch: 102| Step: 0
Training loss: 3.130271585156531
Validation loss: 2.4690094340697675

Epoch: 6| Step: 1
Training loss: 2.441307615195037
Validation loss: 2.4801327455279614

Epoch: 6| Step: 2
Training loss: 2.43566845282209
Validation loss: 2.476719062100344

Epoch: 6| Step: 3
Training loss: 2.8881975858837947
Validation loss: 2.472661810331837

Epoch: 6| Step: 4
Training loss: 2.2120054651368766
Validation loss: 2.4688038236649827

Epoch: 6| Step: 5
Training loss: 2.4911459537107032
Validation loss: 2.470867697319725

Epoch: 6| Step: 6
Training loss: 2.2723171973905054
Validation loss: 2.47683691836959

Epoch: 6| Step: 7
Training loss: 2.6382623519875805
Validation loss: 2.4791137678983484

Epoch: 6| Step: 8
Training loss: 2.4486903057056515
Validation loss: 2.4719312266800286

Epoch: 6| Step: 9
Training loss: 2.6468157008350643
Validation loss: 2.4720615597881626

Epoch: 6| Step: 10
Training loss: 2.2043977131983468
Validation loss: 2.474127758984057

Epoch: 6| Step: 11
Training loss: 2.4213303476530874
Validation loss: 2.474387512458036

Epoch: 6| Step: 12
Training loss: 2.5639491751836276
Validation loss: 2.4734173126264416

Epoch: 6| Step: 13
Training loss: 3.031584101876121
Validation loss: 2.478171402575744

Epoch: 103| Step: 0
Training loss: 2.308447508851576
Validation loss: 2.481061601252536

Epoch: 6| Step: 1
Training loss: 2.7388671596439775
Validation loss: 2.4745612015585285

Epoch: 6| Step: 2
Training loss: 3.1155844177847696
Validation loss: 2.4801933075568385

Epoch: 6| Step: 3
Training loss: 2.212283422354924
Validation loss: 2.4751253821984345

Epoch: 6| Step: 4
Training loss: 2.8032665000082244
Validation loss: 2.4756837683815007

Epoch: 6| Step: 5
Training loss: 3.1423817745721294
Validation loss: 2.4775122777773833

Epoch: 6| Step: 6
Training loss: 2.774797476861628
Validation loss: 2.4767724879758357

Epoch: 6| Step: 7
Training loss: 2.4865310238548752
Validation loss: 2.4713787939186505

Epoch: 6| Step: 8
Training loss: 2.6421424974684298
Validation loss: 2.4697668178621717

Epoch: 6| Step: 9
Training loss: 2.171844262653449
Validation loss: 2.468740777107105

Epoch: 6| Step: 10
Training loss: 1.9470726537408183
Validation loss: 2.4689139299651677

Epoch: 6| Step: 11
Training loss: 1.9488204518540062
Validation loss: 2.463123460775787

Epoch: 6| Step: 12
Training loss: 2.6314289747971262
Validation loss: 2.462426049272626

Epoch: 6| Step: 13
Training loss: 2.6414176157650693
Validation loss: 2.4596683681065303

Epoch: 104| Step: 0
Training loss: 2.247189355753171
Validation loss: 2.4700139347254777

Epoch: 6| Step: 1
Training loss: 1.8495964847425697
Validation loss: 2.473460375546905

Epoch: 6| Step: 2
Training loss: 3.145635299680914
Validation loss: 2.4763481937910288

Epoch: 6| Step: 3
Training loss: 2.7752732769548634
Validation loss: 2.4985633377852565

Epoch: 6| Step: 4
Training loss: 2.2842804102485457
Validation loss: 2.4811037387226818

Epoch: 6| Step: 5
Training loss: 2.815313330874732
Validation loss: 2.470123504480182

Epoch: 6| Step: 6
Training loss: 2.9187674086907225
Validation loss: 2.4657418156080326

Epoch: 6| Step: 7
Training loss: 2.343075260948055
Validation loss: 2.470335197947662

Epoch: 6| Step: 8
Training loss: 2.990216195956334
Validation loss: 2.4677308952832027

Epoch: 6| Step: 9
Training loss: 2.7696058857791885
Validation loss: 2.4696453579401147

Epoch: 6| Step: 10
Training loss: 2.7492643586148287
Validation loss: 2.4725375998234878

Epoch: 6| Step: 11
Training loss: 2.9516799862986693
Validation loss: 2.478161445083503

Epoch: 6| Step: 12
Training loss: 2.231331626617141
Validation loss: 2.4830869778636893

Epoch: 6| Step: 13
Training loss: 1.7677376859524916
Validation loss: 2.483184321197641

Epoch: 105| Step: 0
Training loss: 2.5012707341758373
Validation loss: 2.484889491007913

Epoch: 6| Step: 1
Training loss: 2.6738659317542632
Validation loss: 2.4834623439825063

Epoch: 6| Step: 2
Training loss: 2.450277826555007
Validation loss: 2.4783124066332793

Epoch: 6| Step: 3
Training loss: 2.2537402748071576
Validation loss: 2.4785513608504086

Epoch: 6| Step: 4
Training loss: 2.748735830869841
Validation loss: 2.483376612275474

Epoch: 6| Step: 5
Training loss: 2.0132409716045703
Validation loss: 2.483880223682616

Epoch: 6| Step: 6
Training loss: 2.460638894024206
Validation loss: 2.4753433740725383

Epoch: 6| Step: 7
Training loss: 2.880134806921801
Validation loss: 2.473244370619685

Epoch: 6| Step: 8
Training loss: 2.914915885431452
Validation loss: 2.4679684749972233

Epoch: 6| Step: 9
Training loss: 2.796185797481649
Validation loss: 2.4652537928266667

Epoch: 6| Step: 10
Training loss: 2.7870447035024912
Validation loss: 2.4695106010696057

Epoch: 6| Step: 11
Training loss: 2.5882061460072565
Validation loss: 2.4689132217982515

Epoch: 6| Step: 12
Training loss: 2.7854929930434995
Validation loss: 2.463527378312358

Epoch: 6| Step: 13
Training loss: 2.1552322860819935
Validation loss: 2.464736057514326

Epoch: 106| Step: 0
Training loss: 2.556200611784605
Validation loss: 2.4611088284390297

Epoch: 6| Step: 1
Training loss: 3.096474420871474
Validation loss: 2.462654507819567

Epoch: 6| Step: 2
Training loss: 2.313264874957874
Validation loss: 2.465330072901963

Epoch: 6| Step: 3
Training loss: 2.205470574783938
Validation loss: 2.4648192616579774

Epoch: 6| Step: 4
Training loss: 2.8690621798329934
Validation loss: 2.4667124810560703

Epoch: 6| Step: 5
Training loss: 2.5583492249565807
Validation loss: 2.4650854928213204

Epoch: 6| Step: 6
Training loss: 2.559567611209706
Validation loss: 2.46132015099238

Epoch: 6| Step: 7
Training loss: 2.383717649547377
Validation loss: 2.463720227814345

Epoch: 6| Step: 8
Training loss: 2.667251602233869
Validation loss: 2.461452410079108

Epoch: 6| Step: 9
Training loss: 1.6930883206055287
Validation loss: 2.4673460497332176

Epoch: 6| Step: 10
Training loss: 2.982799493632428
Validation loss: 2.468188467426073

Epoch: 6| Step: 11
Training loss: 2.426953313616603
Validation loss: 2.470212060831642

Epoch: 6| Step: 12
Training loss: 2.3817251257087526
Validation loss: 2.4637784192210486

Epoch: 6| Step: 13
Training loss: 2.9110792501257494
Validation loss: 2.461744291269287

Epoch: 107| Step: 0
Training loss: 2.80741575364358
Validation loss: 2.4629092436370823

Epoch: 6| Step: 1
Training loss: 2.1848320085905275
Validation loss: 2.465304372461949

Epoch: 6| Step: 2
Training loss: 2.594250182676093
Validation loss: 2.469899501454864

Epoch: 6| Step: 3
Training loss: 3.2451985911773105
Validation loss: 2.4761817310492353

Epoch: 6| Step: 4
Training loss: 3.0597693277816544
Validation loss: 2.476680588338683

Epoch: 6| Step: 5
Training loss: 2.9510306546083993
Validation loss: 2.4768373996660253

Epoch: 6| Step: 6
Training loss: 2.1830453474059044
Validation loss: 2.4761397826307645

Epoch: 6| Step: 7
Training loss: 1.9781164160085707
Validation loss: 2.4826159297589903

Epoch: 6| Step: 8
Training loss: 2.840707681625529
Validation loss: 2.480553028346995

Epoch: 6| Step: 9
Training loss: 1.9271656190642314
Validation loss: 2.4756398693582935

Epoch: 6| Step: 10
Training loss: 2.289230184304531
Validation loss: 2.4797190737301626

Epoch: 6| Step: 11
Training loss: 2.6370486808915468
Validation loss: 2.480730162134531

Epoch: 6| Step: 12
Training loss: 2.744011687918369
Validation loss: 2.475833500729759

Epoch: 6| Step: 13
Training loss: 2.3482096649737794
Validation loss: 2.470166198528978

Epoch: 108| Step: 0
Training loss: 2.593980158510111
Validation loss: 2.469789101223771

Epoch: 6| Step: 1
Training loss: 2.1821226238127007
Validation loss: 2.469126370869684

Epoch: 6| Step: 2
Training loss: 2.3589175961968176
Validation loss: 2.467774178198263

Epoch: 6| Step: 3
Training loss: 2.586688621204974
Validation loss: 2.4684619896522224

Epoch: 6| Step: 4
Training loss: 2.8188956550807975
Validation loss: 2.4679214117169965

Epoch: 6| Step: 5
Training loss: 2.340076263032699
Validation loss: 2.4591020066634752

Epoch: 6| Step: 6
Training loss: 2.703519230137298
Validation loss: 2.4606125712967

Epoch: 6| Step: 7
Training loss: 2.686169849618325
Validation loss: 2.4638030791891325

Epoch: 6| Step: 8
Training loss: 2.4954920179254314
Validation loss: 2.4659511297291856

Epoch: 6| Step: 9
Training loss: 3.089872608459972
Validation loss: 2.4603508628510506

Epoch: 6| Step: 10
Training loss: 2.188650863903364
Validation loss: 2.4597079803334028

Epoch: 6| Step: 11
Training loss: 2.3270481358538353
Validation loss: 2.462034661076675

Epoch: 6| Step: 12
Training loss: 2.91695671455875
Validation loss: 2.457631080885472

Epoch: 6| Step: 13
Training loss: 2.41445810971365
Validation loss: 2.465344708090819

Epoch: 109| Step: 0
Training loss: 3.0002937173111435
Validation loss: 2.468411531061844

Epoch: 6| Step: 1
Training loss: 2.3270672949292623
Validation loss: 2.46759679071757

Epoch: 6| Step: 2
Training loss: 2.6752211826898082
Validation loss: 2.468248598068284

Epoch: 6| Step: 3
Training loss: 2.57784551781772
Validation loss: 2.4679923524660796

Epoch: 6| Step: 4
Training loss: 2.2426812562018137
Validation loss: 2.4733185646956315

Epoch: 6| Step: 5
Training loss: 2.5781837225497446
Validation loss: 2.473836720472412

Epoch: 6| Step: 6
Training loss: 2.796368430523946
Validation loss: 2.474009821841193

Epoch: 6| Step: 7
Training loss: 3.0381269019960038
Validation loss: 2.4691959573856104

Epoch: 6| Step: 8
Training loss: 2.1156498015850302
Validation loss: 2.475730916831027

Epoch: 6| Step: 9
Training loss: 2.488058945622979
Validation loss: 2.474064454596719

Epoch: 6| Step: 10
Training loss: 2.1762849235033133
Validation loss: 2.4747382504034334

Epoch: 6| Step: 11
Training loss: 2.5231655671130544
Validation loss: 2.4729079951514836

Epoch: 6| Step: 12
Training loss: 2.5280921924475783
Validation loss: 2.472821544005742

Epoch: 6| Step: 13
Training loss: 2.642766411523668
Validation loss: 2.4699070629339572

Epoch: 110| Step: 0
Training loss: 2.882900660544323
Validation loss: 2.4699517878049795

Epoch: 6| Step: 1
Training loss: 2.3603402493781425
Validation loss: 2.468913382745296

Epoch: 6| Step: 2
Training loss: 2.660776029695133
Validation loss: 2.4691295412508145

Epoch: 6| Step: 3
Training loss: 2.4117890056414875
Validation loss: 2.466118387769804

Epoch: 6| Step: 4
Training loss: 2.208203029986841
Validation loss: 2.464318801428718

Epoch: 6| Step: 5
Training loss: 2.733653730904758
Validation loss: 2.4602849831954816

Epoch: 6| Step: 6
Training loss: 2.4929494619744093
Validation loss: 2.4595621776968826

Epoch: 6| Step: 7
Training loss: 1.9991478892890595
Validation loss: 2.460936854125246

Epoch: 6| Step: 8
Training loss: 3.0858874353138246
Validation loss: 2.463169938175782

Epoch: 6| Step: 9
Training loss: 2.8122734826316735
Validation loss: 2.460268137489189

Epoch: 6| Step: 10
Training loss: 2.3035125323568035
Validation loss: 2.454444028490633

Epoch: 6| Step: 11
Training loss: 2.6022997662031853
Validation loss: 2.4557591446913993

Epoch: 6| Step: 12
Training loss: 2.701515203517542
Validation loss: 2.461076036217183

Epoch: 6| Step: 13
Training loss: 2.317943661061876
Validation loss: 2.457789624967222

Epoch: 111| Step: 0
Training loss: 2.469407682093931
Validation loss: 2.4612463621051615

Epoch: 6| Step: 1
Training loss: 3.065076406002596
Validation loss: 2.4564507652331993

Epoch: 6| Step: 2
Training loss: 2.782260839666879
Validation loss: 2.4560989932038595

Epoch: 6| Step: 3
Training loss: 2.434656783556368
Validation loss: 2.465470481707716

Epoch: 6| Step: 4
Training loss: 2.465031297806139
Validation loss: 2.463103698338938

Epoch: 6| Step: 5
Training loss: 2.4626914903573422
Validation loss: 2.4673897098060458

Epoch: 6| Step: 6
Training loss: 2.7252494907782854
Validation loss: 2.4696959763525097

Epoch: 6| Step: 7
Training loss: 2.171312108268844
Validation loss: 2.467489137867187

Epoch: 6| Step: 8
Training loss: 2.24316650709352
Validation loss: 2.467219461753832

Epoch: 6| Step: 9
Training loss: 3.0744014622681095
Validation loss: 2.4539688343648494

Epoch: 6| Step: 10
Training loss: 2.2503713725159904
Validation loss: 2.4579753022335633

Epoch: 6| Step: 11
Training loss: 2.4564067489655548
Validation loss: 2.45590442882916

Epoch: 6| Step: 12
Training loss: 2.6221881520308337
Validation loss: 2.460660420315377

Epoch: 6| Step: 13
Training loss: 2.3463082148504504
Validation loss: 2.4577107664905014

Epoch: 112| Step: 0
Training loss: 2.922818444673302
Validation loss: 2.4563435136305665

Epoch: 6| Step: 1
Training loss: 2.9820232612117086
Validation loss: 2.4611325625663265

Epoch: 6| Step: 2
Training loss: 2.4817774406630684
Validation loss: 2.4577602645260788

Epoch: 6| Step: 3
Training loss: 1.8782080862039188
Validation loss: 2.4586096193480054

Epoch: 6| Step: 4
Training loss: 3.0250564696030238
Validation loss: 2.456093435822364

Epoch: 6| Step: 5
Training loss: 2.012978524129042
Validation loss: 2.4606906181709007

Epoch: 6| Step: 6
Training loss: 2.4149457679803863
Validation loss: 2.454824251914084

Epoch: 6| Step: 7
Training loss: 2.459901718874601
Validation loss: 2.4624253876511966

Epoch: 6| Step: 8
Training loss: 1.7621731394158773
Validation loss: 2.462970487311695

Epoch: 6| Step: 9
Training loss: 2.194101454358162
Validation loss: 2.46082096530361

Epoch: 6| Step: 10
Training loss: 2.9780508410416053
Validation loss: 2.4605779718231746

Epoch: 6| Step: 11
Training loss: 2.7986428411771165
Validation loss: 2.459876753257681

Epoch: 6| Step: 12
Training loss: 2.464184946562798
Validation loss: 2.465760815598217

Epoch: 6| Step: 13
Training loss: 2.7855344197261327
Validation loss: 2.4725775040737408

Epoch: 113| Step: 0
Training loss: 1.9269811517242046
Validation loss: 2.4766568427663307

Epoch: 6| Step: 1
Training loss: 3.088233267625844
Validation loss: 2.478406346093679

Epoch: 6| Step: 2
Training loss: 2.590117519172163
Validation loss: 2.4804003608467124

Epoch: 6| Step: 3
Training loss: 2.364698858141828
Validation loss: 2.4834989606638675

Epoch: 6| Step: 4
Training loss: 2.4235459992686934
Validation loss: 2.4824978276320393

Epoch: 6| Step: 5
Training loss: 2.7236401655960263
Validation loss: 2.4822096755210517

Epoch: 6| Step: 6
Training loss: 2.539710516766068
Validation loss: 2.485200916613603

Epoch: 6| Step: 7
Training loss: 2.9719349691636086
Validation loss: 2.4848904344900777

Epoch: 6| Step: 8
Training loss: 2.364481269773534
Validation loss: 2.483538552793139

Epoch: 6| Step: 9
Training loss: 2.083323809284057
Validation loss: 2.481588084059341

Epoch: 6| Step: 10
Training loss: 1.942910423369674
Validation loss: 2.4795878290353475

Epoch: 6| Step: 11
Training loss: 3.044682736209532
Validation loss: 2.48114911057663

Epoch: 6| Step: 12
Training loss: 2.6189643863151537
Validation loss: 2.477686966694045

Epoch: 6| Step: 13
Training loss: 3.1525341860364366
Validation loss: 2.477358628918748

Epoch: 114| Step: 0
Training loss: 2.5005338098917242
Validation loss: 2.4843306787404065

Epoch: 6| Step: 1
Training loss: 2.3017112005383287
Validation loss: 2.4769867414330884

Epoch: 6| Step: 2
Training loss: 2.81790794093317
Validation loss: 2.477147351189798

Epoch: 6| Step: 3
Training loss: 2.4481188967884098
Validation loss: 2.4836566454297357

Epoch: 6| Step: 4
Training loss: 2.143229994806537
Validation loss: 2.485888541918584

Epoch: 6| Step: 5
Training loss: 2.8381043450150596
Validation loss: 2.4753821495392234

Epoch: 6| Step: 6
Training loss: 2.726447597585615
Validation loss: 2.471148151028436

Epoch: 6| Step: 7
Training loss: 2.790902949008165
Validation loss: 2.4793610910638217

Epoch: 6| Step: 8
Training loss: 2.1137385693223556
Validation loss: 2.467154586923567

Epoch: 6| Step: 9
Training loss: 2.372634211322623
Validation loss: 2.4580364425178005

Epoch: 6| Step: 10
Training loss: 2.824382349871235
Validation loss: 2.4556456086771448

Epoch: 6| Step: 11
Training loss: 2.5607650279816645
Validation loss: 2.460546763245941

Epoch: 6| Step: 12
Training loss: 2.821183426814778
Validation loss: 2.4596418895942542

Epoch: 6| Step: 13
Training loss: 2.5491251922189835
Validation loss: 2.458241531037295

Epoch: 115| Step: 0
Training loss: 3.0999404163171906
Validation loss: 2.4524779468676434

Epoch: 6| Step: 1
Training loss: 2.6409512831770954
Validation loss: 2.459598285858579

Epoch: 6| Step: 2
Training loss: 2.482498611956897
Validation loss: 2.463759129760693

Epoch: 6| Step: 3
Training loss: 2.596544529789201
Validation loss: 2.4651403958959968

Epoch: 6| Step: 4
Training loss: 2.496021347309182
Validation loss: 2.4596495472286883

Epoch: 6| Step: 5
Training loss: 2.245682282283909
Validation loss: 2.4634811334787603

Epoch: 6| Step: 6
Training loss: 2.079547595929305
Validation loss: 2.4595419827444305

Epoch: 6| Step: 7
Training loss: 2.7262992841139173
Validation loss: 2.459324076738083

Epoch: 6| Step: 8
Training loss: 2.2863543116746325
Validation loss: 2.4555791254144643

Epoch: 6| Step: 9
Training loss: 2.393517632822113
Validation loss: 2.4620347821242055

Epoch: 6| Step: 10
Training loss: 2.4658610183830723
Validation loss: 2.453616293530489

Epoch: 6| Step: 11
Training loss: 2.7786314563802343
Validation loss: 2.462262494272966

Epoch: 6| Step: 12
Training loss: 2.4882409108962817
Validation loss: 2.459162674576059

Epoch: 6| Step: 13
Training loss: 2.6209853216674994
Validation loss: 2.4591513959030675

Epoch: 116| Step: 0
Training loss: 2.2734769313053813
Validation loss: 2.464276941321996

Epoch: 6| Step: 1
Training loss: 2.9369478721369746
Validation loss: 2.460093374651166

Epoch: 6| Step: 2
Training loss: 2.6832102761178183
Validation loss: 2.462250761789775

Epoch: 6| Step: 3
Training loss: 2.6380673272923945
Validation loss: 2.4571289463562986

Epoch: 6| Step: 4
Training loss: 1.9888922271605785
Validation loss: 2.458336043491055

Epoch: 6| Step: 5
Training loss: 2.8747074144173106
Validation loss: 2.463316237046618

Epoch: 6| Step: 6
Training loss: 2.6095330653028124
Validation loss: 2.4665319240557726

Epoch: 6| Step: 7
Training loss: 2.7285764410276743
Validation loss: 2.463527079909343

Epoch: 6| Step: 8
Training loss: 2.176860110385035
Validation loss: 2.4766082037429955

Epoch: 6| Step: 9
Training loss: 2.671902215830185
Validation loss: 2.467117365266441

Epoch: 6| Step: 10
Training loss: 3.235155536621133
Validation loss: 2.4778897552628223

Epoch: 6| Step: 11
Training loss: 1.9818783169913827
Validation loss: 2.4738082974095748

Epoch: 6| Step: 12
Training loss: 2.483007282469168
Validation loss: 2.4639889645050683

Epoch: 6| Step: 13
Training loss: 2.0762457130199548
Validation loss: 2.4699442425507936

Epoch: 117| Step: 0
Training loss: 2.5996996192544173
Validation loss: 2.4627098604036237

Epoch: 6| Step: 1
Training loss: 2.431177007761139
Validation loss: 2.4604672744632534

Epoch: 6| Step: 2
Training loss: 2.6095676008401263
Validation loss: 2.4527734719230594

Epoch: 6| Step: 3
Training loss: 2.537550631614631
Validation loss: 2.45287861163755

Epoch: 6| Step: 4
Training loss: 2.252152367121062
Validation loss: 2.4562545947807632

Epoch: 6| Step: 5
Training loss: 2.3148418631209613
Validation loss: 2.4582590372097974

Epoch: 6| Step: 6
Training loss: 2.142119394189409
Validation loss: 2.4898096138711074

Epoch: 6| Step: 7
Training loss: 3.0359135570357494
Validation loss: 2.491932320759541

Epoch: 6| Step: 8
Training loss: 2.6324598489363913
Validation loss: 2.4930478228416937

Epoch: 6| Step: 9
Training loss: 2.1266613244295534
Validation loss: 2.4765580555327413

Epoch: 6| Step: 10
Training loss: 2.6148543704968064
Validation loss: 2.4639439056181365

Epoch: 6| Step: 11
Training loss: 3.1744530634736536
Validation loss: 2.452491062807785

Epoch: 6| Step: 12
Training loss: 2.421703504827833
Validation loss: 2.45581697460051

Epoch: 6| Step: 13
Training loss: 2.8140544410433432
Validation loss: 2.466670339384008

Epoch: 118| Step: 0
Training loss: 2.22981094841965
Validation loss: 2.4735197193764935

Epoch: 6| Step: 1
Training loss: 2.1322488004931763
Validation loss: 2.476992067452928

Epoch: 6| Step: 2
Training loss: 3.203476305049207
Validation loss: 2.4782703980760497

Epoch: 6| Step: 3
Training loss: 2.0081397357664774
Validation loss: 2.4787238283838864

Epoch: 6| Step: 4
Training loss: 2.680407013233587
Validation loss: 2.4851517652582857

Epoch: 6| Step: 5
Training loss: 2.618547228699193
Validation loss: 2.489876755111737

Epoch: 6| Step: 6
Training loss: 2.708183274635846
Validation loss: 2.494484818183035

Epoch: 6| Step: 7
Training loss: 2.14307480569455
Validation loss: 2.490698262807957

Epoch: 6| Step: 8
Training loss: 2.6219990242869686
Validation loss: 2.4890571634092113

Epoch: 6| Step: 9
Training loss: 3.427967517890293
Validation loss: 2.4884383043741947

Epoch: 6| Step: 10
Training loss: 2.297310508908367
Validation loss: 2.4881722882026933

Epoch: 6| Step: 11
Training loss: 2.083153856811806
Validation loss: 2.4902565948891238

Epoch: 6| Step: 12
Training loss: 2.9252896678984257
Validation loss: 2.480061455075423

Epoch: 6| Step: 13
Training loss: 2.768535052840428
Validation loss: 2.4799974689675817

Epoch: 119| Step: 0
Training loss: 2.537937137928491
Validation loss: 2.476804286253142

Epoch: 6| Step: 1
Training loss: 2.4138485711870126
Validation loss: 2.4840630389429053

Epoch: 6| Step: 2
Training loss: 2.3837006461480805
Validation loss: 2.4798786572796123

Epoch: 6| Step: 3
Training loss: 2.6716569956578464
Validation loss: 2.4730166814858214

Epoch: 6| Step: 4
Training loss: 2.961905369052524
Validation loss: 2.480279645945323

Epoch: 6| Step: 5
Training loss: 2.2254615604986485
Validation loss: 2.4760728707043755

Epoch: 6| Step: 6
Training loss: 2.43670543533704
Validation loss: 2.4764051257010244

Epoch: 6| Step: 7
Training loss: 2.3984209985817726
Validation loss: 2.470797916649567

Epoch: 6| Step: 8
Training loss: 2.63193214254823
Validation loss: 2.473054673977894

Epoch: 6| Step: 9
Training loss: 2.7310459471014843
Validation loss: 2.4721521282498506

Epoch: 6| Step: 10
Training loss: 2.260663301809438
Validation loss: 2.4651535814787495

Epoch: 6| Step: 11
Training loss: 2.772418713491651
Validation loss: 2.4619412106070424

Epoch: 6| Step: 12
Training loss: 2.8321087004495626
Validation loss: 2.4574885182906376

Epoch: 6| Step: 13
Training loss: 2.633980602276977
Validation loss: 2.450914200693067

Epoch: 120| Step: 0
Training loss: 2.0691677167349263
Validation loss: 2.452858313057595

Epoch: 6| Step: 1
Training loss: 2.4664154603560804
Validation loss: 2.4578900072180603

Epoch: 6| Step: 2
Training loss: 2.3563822782506367
Validation loss: 2.461874566473192

Epoch: 6| Step: 3
Training loss: 2.203132142400324
Validation loss: 2.45845486992447

Epoch: 6| Step: 4
Training loss: 2.5165841305905774
Validation loss: 2.4525999896411617

Epoch: 6| Step: 5
Training loss: 2.6719632496676415
Validation loss: 2.454788405369745

Epoch: 6| Step: 6
Training loss: 2.500976085848988
Validation loss: 2.4520651761281855

Epoch: 6| Step: 7
Training loss: 2.7992430310869083
Validation loss: 2.4561000529069092

Epoch: 6| Step: 8
Training loss: 2.2053284144033416
Validation loss: 2.454562760034131

Epoch: 6| Step: 9
Training loss: 3.1055857510388702
Validation loss: 2.4555190243552047

Epoch: 6| Step: 10
Training loss: 2.4894066485884006
Validation loss: 2.459909327239347

Epoch: 6| Step: 11
Training loss: 2.677116205827531
Validation loss: 2.4606848854514256

Epoch: 6| Step: 12
Training loss: 2.8306591840631046
Validation loss: 2.4656351937783128

Epoch: 6| Step: 13
Training loss: 2.679998529917755
Validation loss: 2.471495924094094

Epoch: 121| Step: 0
Training loss: 3.1327342644338056
Validation loss: 2.468700569398375

Epoch: 6| Step: 1
Training loss: 2.699235532407578
Validation loss: 2.4715032555992607

Epoch: 6| Step: 2
Training loss: 2.1441010702066903
Validation loss: 2.4662895818680046

Epoch: 6| Step: 3
Training loss: 2.5913844524268375
Validation loss: 2.4727547431601797

Epoch: 6| Step: 4
Training loss: 2.6481441909278325
Validation loss: 2.470183185857872

Epoch: 6| Step: 5
Training loss: 2.9633270525642263
Validation loss: 2.4700366582608373

Epoch: 6| Step: 6
Training loss: 2.9511909408508883
Validation loss: 2.467769428064239

Epoch: 6| Step: 7
Training loss: 2.320706728958288
Validation loss: 2.4633441439930377

Epoch: 6| Step: 8
Training loss: 2.6118892046927127
Validation loss: 2.4645468104266346

Epoch: 6| Step: 9
Training loss: 2.2131863537018654
Validation loss: 2.4594337672863102

Epoch: 6| Step: 10
Training loss: 2.2715609956579703
Validation loss: 2.465525440676623

Epoch: 6| Step: 11
Training loss: 2.031156684492663
Validation loss: 2.45558152036427

Epoch: 6| Step: 12
Training loss: 2.47596998377094
Validation loss: 2.461515457667859

Epoch: 6| Step: 13
Training loss: 2.6397116622098964
Validation loss: 2.457110769079756

Epoch: 122| Step: 0
Training loss: 2.724718929809084
Validation loss: 2.4606942515777375

Epoch: 6| Step: 1
Training loss: 3.1279350230695204
Validation loss: 2.459647099696224

Epoch: 6| Step: 2
Training loss: 2.8785083759789645
Validation loss: 2.462753094416248

Epoch: 6| Step: 3
Training loss: 2.463204831947278
Validation loss: 2.462364743644286

Epoch: 6| Step: 4
Training loss: 2.5157972952085417
Validation loss: 2.4636798252670777

Epoch: 6| Step: 5
Training loss: 2.717531830180996
Validation loss: 2.4623659055445617

Epoch: 6| Step: 6
Training loss: 3.0840674033412516
Validation loss: 2.4672933377416464

Epoch: 6| Step: 7
Training loss: 2.5216530552118734
Validation loss: 2.4595554729910556

Epoch: 6| Step: 8
Training loss: 2.003210947272823
Validation loss: 2.464133747290749

Epoch: 6| Step: 9
Training loss: 2.192213484378309
Validation loss: 2.4647123177818044

Epoch: 6| Step: 10
Training loss: 2.3881907317702824
Validation loss: 2.4685034005018887

Epoch: 6| Step: 11
Training loss: 2.4295503142164154
Validation loss: 2.469203681947299

Epoch: 6| Step: 12
Training loss: 2.2734454702126183
Validation loss: 2.470928052230687

Epoch: 6| Step: 13
Training loss: 2.096205339223291
Validation loss: 2.4683653777328662

Epoch: 123| Step: 0
Training loss: 2.8118879711956755
Validation loss: 2.4694572433618687

Epoch: 6| Step: 1
Training loss: 2.7585614189818073
Validation loss: 2.4718031694767806

Epoch: 6| Step: 2
Training loss: 2.234108008592059
Validation loss: 2.467477945566092

Epoch: 6| Step: 3
Training loss: 2.9010529349545986
Validation loss: 2.466930781435194

Epoch: 6| Step: 4
Training loss: 2.7198487615613116
Validation loss: 2.454708584428415

Epoch: 6| Step: 5
Training loss: 2.4431581604923114
Validation loss: 2.453147078169748

Epoch: 6| Step: 6
Training loss: 2.807479446349484
Validation loss: 2.458562506214662

Epoch: 6| Step: 7
Training loss: 2.0458427330572895
Validation loss: 2.453374295212341

Epoch: 6| Step: 8
Training loss: 1.7861354821603888
Validation loss: 2.449951386780374

Epoch: 6| Step: 9
Training loss: 2.405505771234377
Validation loss: 2.4502030807459145

Epoch: 6| Step: 10
Training loss: 3.17246004168129
Validation loss: 2.4458324785463916

Epoch: 6| Step: 11
Training loss: 2.3983255664663448
Validation loss: 2.4529128904223407

Epoch: 6| Step: 12
Training loss: 2.333954955358517
Validation loss: 2.454559101362214

Epoch: 6| Step: 13
Training loss: 2.504937255743625
Validation loss: 2.4616776095202844

Epoch: 124| Step: 0
Training loss: 2.7761583333552697
Validation loss: 2.4609384930321037

Epoch: 6| Step: 1
Training loss: 2.9541905009855545
Validation loss: 2.4668484378116275

Epoch: 6| Step: 2
Training loss: 2.9078400886780624
Validation loss: 2.4636389462470163

Epoch: 6| Step: 3
Training loss: 2.26143643160534
Validation loss: 2.4640515682193254

Epoch: 6| Step: 4
Training loss: 2.757334032779263
Validation loss: 2.4595163753062876

Epoch: 6| Step: 5
Training loss: 2.847749852446126
Validation loss: 2.46462385402807

Epoch: 6| Step: 6
Training loss: 2.185356506838461
Validation loss: 2.4593733888109446

Epoch: 6| Step: 7
Training loss: 2.598548311496047
Validation loss: 2.461881410129269

Epoch: 6| Step: 8
Training loss: 2.431076977219158
Validation loss: 2.460844879829488

Epoch: 6| Step: 9
Training loss: 2.2970585133428147
Validation loss: 2.4516410145648297

Epoch: 6| Step: 10
Training loss: 1.9949741396267624
Validation loss: 2.459633957293784

Epoch: 6| Step: 11
Training loss: 2.408969679803565
Validation loss: 2.4544919491939754

Epoch: 6| Step: 12
Training loss: 2.4730827843507286
Validation loss: 2.4523596571995485

Epoch: 6| Step: 13
Training loss: 2.4536723115567
Validation loss: 2.452483779783594

Epoch: 125| Step: 0
Training loss: 2.3561668563460967
Validation loss: 2.4525065847315584

Epoch: 6| Step: 1
Training loss: 2.8943137886429846
Validation loss: 2.453562428214724

Epoch: 6| Step: 2
Training loss: 2.4016191583823567
Validation loss: 2.4502961356060067

Epoch: 6| Step: 3
Training loss: 2.5018046541256544
Validation loss: 2.455483908085082

Epoch: 6| Step: 4
Training loss: 2.8039490304033876
Validation loss: 2.4474172907963823

Epoch: 6| Step: 5
Training loss: 2.6172182906887462
Validation loss: 2.448322008269907

Epoch: 6| Step: 6
Training loss: 2.635979261898495
Validation loss: 2.4526577968300507

Epoch: 6| Step: 7
Training loss: 2.3497623891624575
Validation loss: 2.451897899408277

Epoch: 6| Step: 8
Training loss: 1.9418502698980489
Validation loss: 2.454768122581954

Epoch: 6| Step: 9
Training loss: 2.8717488689764092
Validation loss: 2.45235126385242

Epoch: 6| Step: 10
Training loss: 3.0298653812530394
Validation loss: 2.4443780659443655

Epoch: 6| Step: 11
Training loss: 2.627072832861498
Validation loss: 2.454743452788162

Epoch: 6| Step: 12
Training loss: 2.3041904754052434
Validation loss: 2.4542917769125787

Epoch: 6| Step: 13
Training loss: 1.8180540424661513
Validation loss: 2.4587810776722496

Epoch: 126| Step: 0
Training loss: 2.374664684516869
Validation loss: 2.457552645802707

Epoch: 6| Step: 1
Training loss: 2.2501486623183276
Validation loss: 2.466721703478115

Epoch: 6| Step: 2
Training loss: 2.7290623962828655
Validation loss: 2.457491493482022

Epoch: 6| Step: 3
Training loss: 2.6540902726114832
Validation loss: 2.454962542313506

Epoch: 6| Step: 4
Training loss: 2.3081037643616775
Validation loss: 2.455897795037531

Epoch: 6| Step: 5
Training loss: 2.4459907151839047
Validation loss: 2.4493616722544456

Epoch: 6| Step: 6
Training loss: 2.490591943538228
Validation loss: 2.4537927160238846

Epoch: 6| Step: 7
Training loss: 2.635941183091029
Validation loss: 2.453680635606412

Epoch: 6| Step: 8
Training loss: 2.3397721166583394
Validation loss: 2.4600005611687825

Epoch: 6| Step: 9
Training loss: 2.6797370572415065
Validation loss: 2.458122071924704

Epoch: 6| Step: 10
Training loss: 2.3834638862154613
Validation loss: 2.4534838144740116

Epoch: 6| Step: 11
Training loss: 2.4136665291085704
Validation loss: 2.460452125761083

Epoch: 6| Step: 12
Training loss: 3.260092689741064
Validation loss: 2.453149256819161

Epoch: 6| Step: 13
Training loss: 2.4002131248258314
Validation loss: 2.449829414812821

Epoch: 127| Step: 0
Training loss: 2.676005422293012
Validation loss: 2.456686500092272

Epoch: 6| Step: 1
Training loss: 2.729734832405709
Validation loss: 2.452741734720014

Epoch: 6| Step: 2
Training loss: 2.9080411252310645
Validation loss: 2.4559837255218278

Epoch: 6| Step: 3
Training loss: 1.7522113996671564
Validation loss: 2.4682226784797865

Epoch: 6| Step: 4
Training loss: 2.8159040408040545
Validation loss: 2.462530034587254

Epoch: 6| Step: 5
Training loss: 1.7826802718718775
Validation loss: 2.4698693518378474

Epoch: 6| Step: 6
Training loss: 2.3523146734907976
Validation loss: 2.4701678956584714

Epoch: 6| Step: 7
Training loss: 2.8136971363065393
Validation loss: 2.467969344443837

Epoch: 6| Step: 8
Training loss: 2.9641591765665076
Validation loss: 2.470081734701353

Epoch: 6| Step: 9
Training loss: 2.5075393480463535
Validation loss: 2.4643397634645843

Epoch: 6| Step: 10
Training loss: 2.6543833737457962
Validation loss: 2.45534764572883

Epoch: 6| Step: 11
Training loss: 2.6417552628286485
Validation loss: 2.4591295655452052

Epoch: 6| Step: 12
Training loss: 2.237281669321791
Validation loss: 2.4561034180677614

Epoch: 6| Step: 13
Training loss: 2.54424782270466
Validation loss: 2.457302319119661

Epoch: 128| Step: 0
Training loss: 2.229355622836453
Validation loss: 2.466098504315565

Epoch: 6| Step: 1
Training loss: 3.3050219499606475
Validation loss: 2.468177865928012

Epoch: 6| Step: 2
Training loss: 2.3852254688203742
Validation loss: 2.4574379071462724

Epoch: 6| Step: 3
Training loss: 2.110544290352156
Validation loss: 2.456610744215943

Epoch: 6| Step: 4
Training loss: 2.2748218005468392
Validation loss: 2.4662222979627257

Epoch: 6| Step: 5
Training loss: 2.6588491850135956
Validation loss: 2.4653924410903447

Epoch: 6| Step: 6
Training loss: 3.0294147716923403
Validation loss: 2.470843944130083

Epoch: 6| Step: 7
Training loss: 2.10435804749411
Validation loss: 2.4701751104566205

Epoch: 6| Step: 8
Training loss: 3.091646500459144
Validation loss: 2.4621617738454833

Epoch: 6| Step: 9
Training loss: 2.3893790395245045
Validation loss: 2.4613833149765054

Epoch: 6| Step: 10
Training loss: 2.577525306081632
Validation loss: 2.460169386704971

Epoch: 6| Step: 11
Training loss: 2.5196461259543215
Validation loss: 2.4631794239101605

Epoch: 6| Step: 12
Training loss: 2.205363333733663
Validation loss: 2.452244481117887

Epoch: 6| Step: 13
Training loss: 2.5724687894331044
Validation loss: 2.4522856878135864

Epoch: 129| Step: 0
Training loss: 2.590997085263414
Validation loss: 2.456645941429069

Epoch: 6| Step: 1
Training loss: 2.767209735869336
Validation loss: 2.4527026742295135

Epoch: 6| Step: 2
Training loss: 2.6453305364941353
Validation loss: 2.4448839163445424

Epoch: 6| Step: 3
Training loss: 3.040855212381618
Validation loss: 2.448695741954242

Epoch: 6| Step: 4
Training loss: 2.4428292727812626
Validation loss: 2.456828146880535

Epoch: 6| Step: 5
Training loss: 2.3403213854109266
Validation loss: 2.4483401209575066

Epoch: 6| Step: 6
Training loss: 2.5089865339882507
Validation loss: 2.455617347239972

Epoch: 6| Step: 7
Training loss: 2.5590369852545383
Validation loss: 2.449273765388183

Epoch: 6| Step: 8
Training loss: 2.49646910231647
Validation loss: 2.45567937957575

Epoch: 6| Step: 9
Training loss: 2.3312557598789434
Validation loss: 2.452899363643407

Epoch: 6| Step: 10
Training loss: 2.838307464923752
Validation loss: 2.446600870145108

Epoch: 6| Step: 11
Training loss: 2.2743188781606913
Validation loss: 2.4569801280773618

Epoch: 6| Step: 12
Training loss: 2.525083306326336
Validation loss: 2.453357612612389

Epoch: 6| Step: 13
Training loss: 1.7704544185576503
Validation loss: 2.4623872069524513

Epoch: 130| Step: 0
Training loss: 2.761770720040098
Validation loss: 2.4612284009046124

Epoch: 6| Step: 1
Training loss: 1.9078913641898085
Validation loss: 2.4576054777895

Epoch: 6| Step: 2
Training loss: 2.1233777978853623
Validation loss: 2.45407827851776

Epoch: 6| Step: 3
Training loss: 2.535711430446314
Validation loss: 2.459174825753259

Epoch: 6| Step: 4
Training loss: 3.068680268717119
Validation loss: 2.4560749030371443

Epoch: 6| Step: 5
Training loss: 2.564132449575026
Validation loss: 2.454874164259429

Epoch: 6| Step: 6
Training loss: 2.9869603647284952
Validation loss: 2.4505092662466663

Epoch: 6| Step: 7
Training loss: 2.1979460751944964
Validation loss: 2.4575826716495928

Epoch: 6| Step: 8
Training loss: 2.3050584397592973
Validation loss: 2.4590183101187986

Epoch: 6| Step: 9
Training loss: 2.646582930302811
Validation loss: 2.4519922269254053

Epoch: 6| Step: 10
Training loss: 3.096006553051541
Validation loss: 2.449596394167027

Epoch: 6| Step: 11
Training loss: 2.5228325558624443
Validation loss: 2.4609421664400615

Epoch: 6| Step: 12
Training loss: 2.40205731428821
Validation loss: 2.4553232730659724

Epoch: 6| Step: 13
Training loss: 1.94938068825692
Validation loss: 2.4590755301323526

Epoch: 131| Step: 0
Training loss: 2.2520213054780696
Validation loss: 2.461035687137854

Epoch: 6| Step: 1
Training loss: 2.110928789709546
Validation loss: 2.4577707897025234

Epoch: 6| Step: 2
Training loss: 2.620674747910999
Validation loss: 2.457369766406487

Epoch: 6| Step: 3
Training loss: 2.5536825554111138
Validation loss: 2.4587482220828014

Epoch: 6| Step: 4
Training loss: 2.556023951004832
Validation loss: 2.4635044737596448

Epoch: 6| Step: 5
Training loss: 2.2561214674586414
Validation loss: 2.4591381781373673

Epoch: 6| Step: 6
Training loss: 2.868205292625856
Validation loss: 2.4644201915292103

Epoch: 6| Step: 7
Training loss: 2.1639137630096714
Validation loss: 2.4650037001246083

Epoch: 6| Step: 8
Training loss: 2.8249871987922077
Validation loss: 2.458947651825974

Epoch: 6| Step: 9
Training loss: 2.6916286780764005
Validation loss: 2.4650825993341106

Epoch: 6| Step: 10
Training loss: 2.6247183330735533
Validation loss: 2.4601219480935033

Epoch: 6| Step: 11
Training loss: 2.6445092520087656
Validation loss: 2.4638537853721654

Epoch: 6| Step: 12
Training loss: 2.300191236921381
Validation loss: 2.4524270459859516

Epoch: 6| Step: 13
Training loss: 2.846723741350803
Validation loss: 2.4546181251116326

Epoch: 132| Step: 0
Training loss: 2.349725252688611
Validation loss: 2.458737781897039

Epoch: 6| Step: 1
Training loss: 2.1781072323045714
Validation loss: 2.455980813221742

Epoch: 6| Step: 2
Training loss: 2.4542621479555624
Validation loss: 2.458335857605581

Epoch: 6| Step: 3
Training loss: 2.164984000765774
Validation loss: 2.4617277299577367

Epoch: 6| Step: 4
Training loss: 2.900538256448969
Validation loss: 2.4770551125405658

Epoch: 6| Step: 5
Training loss: 2.3036733691364972
Validation loss: 2.468702034142252

Epoch: 6| Step: 6
Training loss: 3.111974195319425
Validation loss: 2.4600338684634866

Epoch: 6| Step: 7
Training loss: 2.73322328563068
Validation loss: 2.460471303873127

Epoch: 6| Step: 8
Training loss: 2.2641485204473764
Validation loss: 2.463952130458545

Epoch: 6| Step: 9
Training loss: 2.6302120598996392
Validation loss: 2.4495004332750265

Epoch: 6| Step: 10
Training loss: 3.1778742238357283
Validation loss: 2.4583497504855325

Epoch: 6| Step: 11
Training loss: 2.1187036019705374
Validation loss: 2.4547074350915046

Epoch: 6| Step: 12
Training loss: 1.7087731454282107
Validation loss: 2.4551671107352653

Epoch: 6| Step: 13
Training loss: 2.805640948499464
Validation loss: 2.454577605120424

Epoch: 133| Step: 0
Training loss: 2.442113178901513
Validation loss: 2.4609669355620127

Epoch: 6| Step: 1
Training loss: 3.1349612356219874
Validation loss: 2.4673523145421568

Epoch: 6| Step: 2
Training loss: 2.499042995386784
Validation loss: 2.466244355556334

Epoch: 6| Step: 3
Training loss: 2.4332968835408693
Validation loss: 2.472669700839081

Epoch: 6| Step: 4
Training loss: 2.722017188579208
Validation loss: 2.467448619886045

Epoch: 6| Step: 5
Training loss: 2.196759598849619
Validation loss: 2.479751122661421

Epoch: 6| Step: 6
Training loss: 2.940694816644303
Validation loss: 2.477557723421523

Epoch: 6| Step: 7
Training loss: 2.446209532764116
Validation loss: 2.4765843210953755

Epoch: 6| Step: 8
Training loss: 2.207361031258946
Validation loss: 2.476296026452654

Epoch: 6| Step: 9
Training loss: 2.276209029992143
Validation loss: 2.471839790077394

Epoch: 6| Step: 10
Training loss: 2.6576459021722605
Validation loss: 2.4728500346521605

Epoch: 6| Step: 11
Training loss: 2.7145505897809272
Validation loss: 2.463791370170313

Epoch: 6| Step: 12
Training loss: 2.592628420350105
Validation loss: 2.459293151165627

Epoch: 6| Step: 13
Training loss: 2.1404959089796556
Validation loss: 2.4527596608629643

Epoch: 134| Step: 0
Training loss: 2.5370315645545087
Validation loss: 2.449805214333469

Epoch: 6| Step: 1
Training loss: 1.8327209866076717
Validation loss: 2.448370259783165

Epoch: 6| Step: 2
Training loss: 2.929832515942194
Validation loss: 2.4512911702948617

Epoch: 6| Step: 3
Training loss: 2.403386083739145
Validation loss: 2.4548658766303837

Epoch: 6| Step: 4
Training loss: 2.1705321407473637
Validation loss: 2.4551835625464005

Epoch: 6| Step: 5
Training loss: 3.525223712721144
Validation loss: 2.445584949269775

Epoch: 6| Step: 6
Training loss: 2.2024855531181893
Validation loss: 2.446414297100027

Epoch: 6| Step: 7
Training loss: 2.4413902343224683
Validation loss: 2.447131551818188

Epoch: 6| Step: 8
Training loss: 2.074060811209785
Validation loss: 2.452647484632889

Epoch: 6| Step: 9
Training loss: 2.4392783695661713
Validation loss: 2.4547358607872964

Epoch: 6| Step: 10
Training loss: 2.0708845391904886
Validation loss: 2.455898523137488

Epoch: 6| Step: 11
Training loss: 2.3710487022079887
Validation loss: 2.4513547791103223

Epoch: 6| Step: 12
Training loss: 3.1935260134273995
Validation loss: 2.4503682677192993

Epoch: 6| Step: 13
Training loss: 2.5270522360737253
Validation loss: 2.4516900921844997

Epoch: 135| Step: 0
Training loss: 2.4448157832794606
Validation loss: 2.447364019682488

Epoch: 6| Step: 1
Training loss: 2.3947905109187575
Validation loss: 2.4475813832193807

Epoch: 6| Step: 2
Training loss: 2.332441590979202
Validation loss: 2.4467355651881806

Epoch: 6| Step: 3
Training loss: 1.9875673462595824
Validation loss: 2.4473452015994868

Epoch: 6| Step: 4
Training loss: 2.1976050085121073
Validation loss: 2.450578976034975

Epoch: 6| Step: 5
Training loss: 2.5111620628716618
Validation loss: 2.4505889807430097

Epoch: 6| Step: 6
Training loss: 2.977657727372613
Validation loss: 2.447310520094194

Epoch: 6| Step: 7
Training loss: 2.4595800137409927
Validation loss: 2.450810630491709

Epoch: 6| Step: 8
Training loss: 2.5711037945384545
Validation loss: 2.4489339270457973

Epoch: 6| Step: 9
Training loss: 2.44284078947886
Validation loss: 2.45068380453754

Epoch: 6| Step: 10
Training loss: 2.7402890146236385
Validation loss: 2.4508661613959344

Epoch: 6| Step: 11
Training loss: 2.3537655266377806
Validation loss: 2.454843150254053

Epoch: 6| Step: 12
Training loss: 2.7102569693321024
Validation loss: 2.4643507926487898

Epoch: 6| Step: 13
Training loss: 2.80833041212645
Validation loss: 2.4691757285751854

Epoch: 136| Step: 0
Training loss: 2.027376913339667
Validation loss: 2.465587425187366

Epoch: 6| Step: 1
Training loss: 2.7069648415262577
Validation loss: 2.4606171576081297

Epoch: 6| Step: 2
Training loss: 2.7596343077391925
Validation loss: 2.4672792053251547

Epoch: 6| Step: 3
Training loss: 2.417695999168831
Validation loss: 2.461039223158047

Epoch: 6| Step: 4
Training loss: 2.586844386094504
Validation loss: 2.4591560495738367

Epoch: 6| Step: 5
Training loss: 1.6689812403562272
Validation loss: 2.454396900156684

Epoch: 6| Step: 6
Training loss: 2.9224919774424243
Validation loss: 2.4538296297003916

Epoch: 6| Step: 7
Training loss: 2.045145133728038
Validation loss: 2.4545413745338878

Epoch: 6| Step: 8
Training loss: 2.251872555035003
Validation loss: 2.4538047804363634

Epoch: 6| Step: 9
Training loss: 2.7759146789554046
Validation loss: 2.4566432078400453

Epoch: 6| Step: 10
Training loss: 3.134705692086735
Validation loss: 2.4538120514428883

Epoch: 6| Step: 11
Training loss: 2.232675399468559
Validation loss: 2.448955969983097

Epoch: 6| Step: 12
Training loss: 2.9742437026447863
Validation loss: 2.450418643800348

Epoch: 6| Step: 13
Training loss: 2.2388095199025417
Validation loss: 2.454830313967037

Epoch: 137| Step: 0
Training loss: 2.799882773942696
Validation loss: 2.452985690751492

Epoch: 6| Step: 1
Training loss: 3.1771325946595073
Validation loss: 2.455646684757503

Epoch: 6| Step: 2
Training loss: 2.8542010080169615
Validation loss: 2.4494185743895414

Epoch: 6| Step: 3
Training loss: 2.1869273934925135
Validation loss: 2.4575685723207585

Epoch: 6| Step: 4
Training loss: 2.2920922548857465
Validation loss: 2.458692416674113

Epoch: 6| Step: 5
Training loss: 2.1289649325341085
Validation loss: 2.4615913128107887

Epoch: 6| Step: 6
Training loss: 2.659130016119361
Validation loss: 2.461820220066639

Epoch: 6| Step: 7
Training loss: 2.1995694302654667
Validation loss: 2.4577192951305116

Epoch: 6| Step: 8
Training loss: 2.361981903265251
Validation loss: 2.4606675580237645

Epoch: 6| Step: 9
Training loss: 2.276020064495121
Validation loss: 2.4534979210805834

Epoch: 6| Step: 10
Training loss: 2.653515474051869
Validation loss: 2.4532563484161845

Epoch: 6| Step: 11
Training loss: 2.624751487957509
Validation loss: 2.4636540834183553

Epoch: 6| Step: 12
Training loss: 2.2478575572909136
Validation loss: 2.464252358659047

Epoch: 6| Step: 13
Training loss: 2.427258126400345
Validation loss: 2.4646968646649694

Epoch: 138| Step: 0
Training loss: 2.2577386863812796
Validation loss: 2.46769143599692

Epoch: 6| Step: 1
Training loss: 2.3895963562596947
Validation loss: 2.4722418575959644

Epoch: 6| Step: 2
Training loss: 2.6215419698728244
Validation loss: 2.4673897098060458

Epoch: 6| Step: 3
Training loss: 2.8234287280826225
Validation loss: 2.4686440875677422

Epoch: 6| Step: 4
Training loss: 2.674364413752847
Validation loss: 2.4617094010079015

Epoch: 6| Step: 5
Training loss: 2.4262945396898656
Validation loss: 2.4572556660532143

Epoch: 6| Step: 6
Training loss: 1.9425459956709497
Validation loss: 2.459045199327994

Epoch: 6| Step: 7
Training loss: 2.7780462092929263
Validation loss: 2.45855799688286

Epoch: 6| Step: 8
Training loss: 2.293114106804049
Validation loss: 2.4666873588424396

Epoch: 6| Step: 9
Training loss: 2.74103567598013
Validation loss: 2.4589946687021853

Epoch: 6| Step: 10
Training loss: 2.465842647640182
Validation loss: 2.461993440011419

Epoch: 6| Step: 11
Training loss: 2.5033982069479177
Validation loss: 2.4532125825898987

Epoch: 6| Step: 12
Training loss: 2.7407031266702417
Validation loss: 2.459982744326975

Epoch: 6| Step: 13
Training loss: 2.4785077370712743
Validation loss: 2.453188788036196

Epoch: 139| Step: 0
Training loss: 2.5975971415972454
Validation loss: 2.4593258379005682

Epoch: 6| Step: 1
Training loss: 2.795160801856244
Validation loss: 2.452675302353767

Epoch: 6| Step: 2
Training loss: 2.398254586368002
Validation loss: 2.4547483252539593

Epoch: 6| Step: 3
Training loss: 2.4759863535269258
Validation loss: 2.4541437904660435

Epoch: 6| Step: 4
Training loss: 1.9593788426801122
Validation loss: 2.4612974519225452

Epoch: 6| Step: 5
Training loss: 2.279685123852857
Validation loss: 2.465024962618017

Epoch: 6| Step: 6
Training loss: 3.354265025969313
Validation loss: 2.4613575571820276

Epoch: 6| Step: 7
Training loss: 2.0515456164813655
Validation loss: 2.457553163214053

Epoch: 6| Step: 8
Training loss: 2.0383458540691226
Validation loss: 2.454844250966587

Epoch: 6| Step: 9
Training loss: 2.5105326033501596
Validation loss: 2.454601985187298

Epoch: 6| Step: 10
Training loss: 2.196721395274843
Validation loss: 2.4469715539452976

Epoch: 6| Step: 11
Training loss: 2.63536957307939
Validation loss: 2.454306607447445

Epoch: 6| Step: 12
Training loss: 2.596011451337388
Validation loss: 2.4501001616523985

Epoch: 6| Step: 13
Training loss: 2.917232640166956
Validation loss: 2.4515926410288253

Epoch: 140| Step: 0
Training loss: 2.603088481230187
Validation loss: 2.449973063742552

Epoch: 6| Step: 1
Training loss: 2.2366976103748017
Validation loss: 2.447669537562265

Epoch: 6| Step: 2
Training loss: 2.766886191870021
Validation loss: 2.4562310480967215

Epoch: 6| Step: 3
Training loss: 2.458200925289269
Validation loss: 2.4562904199278672

Epoch: 6| Step: 4
Training loss: 2.822220344576207
Validation loss: 2.4642075384072544

Epoch: 6| Step: 5
Training loss: 2.5316047890764763
Validation loss: 2.4616108613951635

Epoch: 6| Step: 6
Training loss: 2.483327968856172
Validation loss: 2.4631123615654675

Epoch: 6| Step: 7
Training loss: 2.9581243593435684
Validation loss: 2.4637272276294464

Epoch: 6| Step: 8
Training loss: 1.9490389999042048
Validation loss: 2.461903571177484

Epoch: 6| Step: 9
Training loss: 2.345377242727823
Validation loss: 2.453372367810958

Epoch: 6| Step: 10
Training loss: 2.7122400326239324
Validation loss: 2.4638944592341843

Epoch: 6| Step: 11
Training loss: 2.393614750719008
Validation loss: 2.4643165600927928

Epoch: 6| Step: 12
Training loss: 2.444085248893218
Validation loss: 2.4604645935696614

Epoch: 6| Step: 13
Training loss: 2.260081909518311
Validation loss: 2.4620388251083165

Epoch: 141| Step: 0
Training loss: 2.7071708434031856
Validation loss: 2.4641461964714755

Epoch: 6| Step: 1
Training loss: 2.426988482497856
Validation loss: 2.4586612568910926

Epoch: 6| Step: 2
Training loss: 2.281518371681952
Validation loss: 2.4543303749736363

Epoch: 6| Step: 3
Training loss: 2.8827777643359545
Validation loss: 2.4604118472016303

Epoch: 6| Step: 4
Training loss: 3.141874909181823
Validation loss: 2.456389973723231

Epoch: 6| Step: 5
Training loss: 2.614317820974983
Validation loss: 2.45735531010721

Epoch: 6| Step: 6
Training loss: 2.5895454614703106
Validation loss: 2.4635273057278444

Epoch: 6| Step: 7
Training loss: 2.4485370472120334
Validation loss: 2.4611018857598848

Epoch: 6| Step: 8
Training loss: 2.0224182625416804
Validation loss: 2.451547492074342

Epoch: 6| Step: 9
Training loss: 2.5848048746335186
Validation loss: 2.4600346841796443

Epoch: 6| Step: 10
Training loss: 2.111914116688245
Validation loss: 2.453654740269548

Epoch: 6| Step: 11
Training loss: 2.4968335125547525
Validation loss: 2.455632752312184

Epoch: 6| Step: 12
Training loss: 1.969286285503883
Validation loss: 2.457545539470235

Epoch: 6| Step: 13
Training loss: 2.6098977667418772
Validation loss: 2.46156925387907

Epoch: 142| Step: 0
Training loss: 2.857834030746019
Validation loss: 2.4579122608371877

Epoch: 6| Step: 1
Training loss: 2.4383768314106926
Validation loss: 2.45560640019452

Epoch: 6| Step: 2
Training loss: 2.7029703790620183
Validation loss: 2.4518622774897247

Epoch: 6| Step: 3
Training loss: 2.2913068893537485
Validation loss: 2.452729794685861

Epoch: 6| Step: 4
Training loss: 2.122924688871261
Validation loss: 2.4561697900697057

Epoch: 6| Step: 5
Training loss: 2.7660115289785727
Validation loss: 2.444007387127199

Epoch: 6| Step: 6
Training loss: 2.376499505747449
Validation loss: 2.447959710141778

Epoch: 6| Step: 7
Training loss: 2.162126577252028
Validation loss: 2.441361034737553

Epoch: 6| Step: 8
Training loss: 2.8505958068195887
Validation loss: 2.450567722716513

Epoch: 6| Step: 9
Training loss: 2.4832231262467257
Validation loss: 2.4548424380280327

Epoch: 6| Step: 10
Training loss: 1.9702203497638366
Validation loss: 2.4423793796259443

Epoch: 6| Step: 11
Training loss: 2.6951675154902626
Validation loss: 2.445564322053186

Epoch: 6| Step: 12
Training loss: 2.4990459529075597
Validation loss: 2.4523821554410277

Epoch: 6| Step: 13
Training loss: 2.7610383875083886
Validation loss: 2.4506979921187413

Epoch: 143| Step: 0
Training loss: 2.691674826720853
Validation loss: 2.443751583440321

Epoch: 6| Step: 1
Training loss: 2.520695002099544
Validation loss: 2.4429451530088713

Epoch: 6| Step: 2
Training loss: 2.171932302034661
Validation loss: 2.440769961029236

Epoch: 6| Step: 3
Training loss: 2.704567584944625
Validation loss: 2.450793679128529

Epoch: 6| Step: 4
Training loss: 2.6480527165054872
Validation loss: 2.452502841980221

Epoch: 6| Step: 5
Training loss: 2.5817713989068394
Validation loss: 2.453368691167146

Epoch: 6| Step: 6
Training loss: 2.743119996892643
Validation loss: 2.454900143852749

Epoch: 6| Step: 7
Training loss: 2.3391283371297686
Validation loss: 2.4516969723733366

Epoch: 6| Step: 8
Training loss: 2.9565242196582426
Validation loss: 2.4443714089994324

Epoch: 6| Step: 9
Training loss: 2.604014298114109
Validation loss: 2.451470369804526

Epoch: 6| Step: 10
Training loss: 2.1787301972759208
Validation loss: 2.4518228464367993

Epoch: 6| Step: 11
Training loss: 1.7886944521336985
Validation loss: 2.448589797842889

Epoch: 6| Step: 12
Training loss: 2.430089396021523
Validation loss: 2.4480935431894033

Epoch: 6| Step: 13
Training loss: 2.5567506630970236
Validation loss: 2.435614492400079

Epoch: 144| Step: 0
Training loss: 2.6420463032502037
Validation loss: 2.452187328569531

Epoch: 6| Step: 1
Training loss: 2.4193891996589283
Validation loss: 2.4474876081901753

Epoch: 6| Step: 2
Training loss: 2.2896527775885462
Validation loss: 2.4437435751698

Epoch: 6| Step: 3
Training loss: 2.9600543715664065
Validation loss: 2.455049509040004

Epoch: 6| Step: 4
Training loss: 2.9590159600211954
Validation loss: 2.4554631050992484

Epoch: 6| Step: 5
Training loss: 2.471076738055969
Validation loss: 2.466839900463349

Epoch: 6| Step: 6
Training loss: 2.6512644935798075
Validation loss: 2.4514714963452646

Epoch: 6| Step: 7
Training loss: 2.4274173446710727
Validation loss: 2.455941302676011

Epoch: 6| Step: 8
Training loss: 2.0934022073693455
Validation loss: 2.452854198241181

Epoch: 6| Step: 9
Training loss: 2.5290104884318185
Validation loss: 2.44494453887341

Epoch: 6| Step: 10
Training loss: 2.821202188001331
Validation loss: 2.452968875914084

Epoch: 6| Step: 11
Training loss: 2.3155486141893182
Validation loss: 2.4522928985090506

Epoch: 6| Step: 12
Training loss: 1.9273532850186592
Validation loss: 2.4528174399882934

Epoch: 6| Step: 13
Training loss: 2.3563427165683697
Validation loss: 2.447607488924745

Epoch: 145| Step: 0
Training loss: 1.7473374957273164
Validation loss: 2.4532967768499034

Epoch: 6| Step: 1
Training loss: 2.9486149656159077
Validation loss: 2.452855599547546

Epoch: 6| Step: 2
Training loss: 3.2299374716644
Validation loss: 2.4527568095376466

Epoch: 6| Step: 3
Training loss: 2.310473404632831
Validation loss: 2.4550926756345444

Epoch: 6| Step: 4
Training loss: 2.5298523988753208
Validation loss: 2.4568628072488665

Epoch: 6| Step: 5
Training loss: 2.26077234894837
Validation loss: 2.4566605151274987

Epoch: 6| Step: 6
Training loss: 2.962379446675254
Validation loss: 2.460804462368999

Epoch: 6| Step: 7
Training loss: 2.2299495166144836
Validation loss: 2.4625343752816047

Epoch: 6| Step: 8
Training loss: 2.7155021472880976
Validation loss: 2.4677396549820476

Epoch: 6| Step: 9
Training loss: 2.8547160230191935
Validation loss: 2.470597038956815

Epoch: 6| Step: 10
Training loss: 2.2739295033823144
Validation loss: 2.4664557053162395

Epoch: 6| Step: 11
Training loss: 1.956083818391107
Validation loss: 2.4635648397010406

Epoch: 6| Step: 12
Training loss: 2.437779924018322
Validation loss: 2.462191969426112

Epoch: 6| Step: 13
Training loss: 1.9968361864213127
Validation loss: 2.460685289164502

Epoch: 146| Step: 0
Training loss: 1.534119078509194
Validation loss: 2.458707608541306

Epoch: 6| Step: 1
Training loss: 2.7692921781455695
Validation loss: 2.462640147085826

Epoch: 6| Step: 2
Training loss: 2.33437506945098
Validation loss: 2.461437679101336

Epoch: 6| Step: 3
Training loss: 2.2017237759194996
Validation loss: 2.4647058769796253

Epoch: 6| Step: 4
Training loss: 2.6430118765879875
Validation loss: 2.4614111550473003

Epoch: 6| Step: 5
Training loss: 2.495329499589871
Validation loss: 2.4663879264962087

Epoch: 6| Step: 6
Training loss: 2.404768847105229
Validation loss: 2.4675098475163435

Epoch: 6| Step: 7
Training loss: 2.4641932673518743
Validation loss: 2.471629302637796

Epoch: 6| Step: 8
Training loss: 2.8356482828591476
Validation loss: 2.462848619611579

Epoch: 6| Step: 9
Training loss: 2.313343512854409
Validation loss: 2.4699554236761654

Epoch: 6| Step: 10
Training loss: 2.9098424550305375
Validation loss: 2.479618341242276

Epoch: 6| Step: 11
Training loss: 2.754622475846016
Validation loss: 2.4840669740902213

Epoch: 6| Step: 12
Training loss: 2.748290571023133
Validation loss: 2.4703896787338877

Epoch: 6| Step: 13
Training loss: 2.5493818244365785
Validation loss: 2.469091061882877

Epoch: 147| Step: 0
Training loss: 2.530269856893935
Validation loss: 2.4581871366402708

Epoch: 6| Step: 1
Training loss: 2.84448987118223
Validation loss: 2.458273375043995

Epoch: 6| Step: 2
Training loss: 3.2066357237445793
Validation loss: 2.4584864606419186

Epoch: 6| Step: 3
Training loss: 2.903466316911974
Validation loss: 2.4652410268656046

Epoch: 6| Step: 4
Training loss: 2.483861906221287
Validation loss: 2.470843702898143

Epoch: 6| Step: 5
Training loss: 2.7077400633670394
Validation loss: 2.472476609199434

Epoch: 6| Step: 6
Training loss: 2.6247850965905175
Validation loss: 2.4676032159224204

Epoch: 6| Step: 7
Training loss: 1.8520232967204973
Validation loss: 2.471400242742086

Epoch: 6| Step: 8
Training loss: 1.657338198766423
Validation loss: 2.4761147159450987

Epoch: 6| Step: 9
Training loss: 2.453963021171538
Validation loss: 2.4722926076830083

Epoch: 6| Step: 10
Training loss: 1.836671398465984
Validation loss: 2.475341030348607

Epoch: 6| Step: 11
Training loss: 2.585063775196325
Validation loss: 2.473048528055014

Epoch: 6| Step: 12
Training loss: 2.6083003589467393
Validation loss: 2.4683490218291375

Epoch: 6| Step: 13
Training loss: 2.5183508658498344
Validation loss: 2.4676725072314527

Epoch: 148| Step: 0
Training loss: 2.8480885704712597
Validation loss: 2.4731951744465213

Epoch: 6| Step: 1
Training loss: 2.821930566453967
Validation loss: 2.4691783678247687

Epoch: 6| Step: 2
Training loss: 2.677283095292477
Validation loss: 2.467177828028321

Epoch: 6| Step: 3
Training loss: 2.1873617946017525
Validation loss: 2.465819941857439

Epoch: 6| Step: 4
Training loss: 2.3410480437826005
Validation loss: 2.4650666810637927

Epoch: 6| Step: 5
Training loss: 2.354529856345293
Validation loss: 2.4587761970369484

Epoch: 6| Step: 6
Training loss: 2.0959326910757463
Validation loss: 2.4627303440134543

Epoch: 6| Step: 7
Training loss: 2.444775799728372
Validation loss: 2.464084111201359

Epoch: 6| Step: 8
Training loss: 3.0497351109278608
Validation loss: 2.4610843513714085

Epoch: 6| Step: 9
Training loss: 2.2632723464764357
Validation loss: 2.461900456053113

Epoch: 6| Step: 10
Training loss: 2.4463648862375806
Validation loss: 2.465995104546392

Epoch: 6| Step: 11
Training loss: 2.833768998104669
Validation loss: 2.4642104893609362

Epoch: 6| Step: 12
Training loss: 2.0085164183215523
Validation loss: 2.4593359524423466

Epoch: 6| Step: 13
Training loss: 2.3649329600600972
Validation loss: 2.4671551184273692

Epoch: 149| Step: 0
Training loss: 2.41613404115624
Validation loss: 2.4618252076543943

Epoch: 6| Step: 1
Training loss: 2.017559926633197
Validation loss: 2.478389815956939

Epoch: 6| Step: 2
Training loss: 1.8539707923325064
Validation loss: 2.489035563413977

Epoch: 6| Step: 3
Training loss: 2.3602881275091905
Validation loss: 2.4950208591845504

Epoch: 6| Step: 4
Training loss: 2.172664142197887
Validation loss: 2.5169138716449453

Epoch: 6| Step: 5
Training loss: 3.0433949476887134
Validation loss: 2.54541070263538

Epoch: 6| Step: 6
Training loss: 2.9008282366624476
Validation loss: 2.517500358033494

Epoch: 6| Step: 7
Training loss: 2.583694176442249
Validation loss: 2.4877925374907623

Epoch: 6| Step: 8
Training loss: 2.7295911521918037
Validation loss: 2.4618465460225436

Epoch: 6| Step: 9
Training loss: 2.3815472354757623
Validation loss: 2.462227248240451

Epoch: 6| Step: 10
Training loss: 2.8881825618790424
Validation loss: 2.463112813278492

Epoch: 6| Step: 11
Training loss: 2.0046497177880807
Validation loss: 2.472879922963959

Epoch: 6| Step: 12
Training loss: 2.656966527898139
Validation loss: 2.47423072252347

Epoch: 6| Step: 13
Training loss: 2.510229734264699
Validation loss: 2.476558921963808

Epoch: 150| Step: 0
Training loss: 2.34787478834126
Validation loss: 2.4728497936159197

Epoch: 6| Step: 1
Training loss: 1.9284161537978242
Validation loss: 2.4712938811195087

Epoch: 6| Step: 2
Training loss: 2.8159727908467196
Validation loss: 2.474124225609203

Epoch: 6| Step: 3
Training loss: 2.8081210485380055
Validation loss: 2.47770775148154

Epoch: 6| Step: 4
Training loss: 2.0041658408096525
Validation loss: 2.4696537729610566

Epoch: 6| Step: 5
Training loss: 2.566935352612564
Validation loss: 2.4734282451046026

Epoch: 6| Step: 6
Training loss: 2.702848916480502
Validation loss: 2.4700460934939206

Epoch: 6| Step: 7
Training loss: 1.9822582459217517
Validation loss: 2.470921330120646

Epoch: 6| Step: 8
Training loss: 2.988138113146671
Validation loss: 2.4685335426562824

Epoch: 6| Step: 9
Training loss: 2.7716115179059573
Validation loss: 2.467248371412986

Epoch: 6| Step: 10
Training loss: 2.798060927621376
Validation loss: 2.468090033542305

Epoch: 6| Step: 11
Training loss: 2.5095448437666894
Validation loss: 2.4686595723133236

Epoch: 6| Step: 12
Training loss: 2.2835141794839053
Validation loss: 2.460675454695119

Epoch: 6| Step: 13
Training loss: 2.5833428495498447
Validation loss: 2.4548331709774573

Epoch: 151| Step: 0
Training loss: 2.4778961537779325
Validation loss: 2.453580526509706

Epoch: 6| Step: 1
Training loss: 2.9683402330795654
Validation loss: 2.4604160785808933

Epoch: 6| Step: 2
Training loss: 1.9624458985859226
Validation loss: 2.4678568451682557

Epoch: 6| Step: 3
Training loss: 2.356721307785628
Validation loss: 2.4700102989404202

Epoch: 6| Step: 4
Training loss: 2.386508164426024
Validation loss: 2.482232407473382

Epoch: 6| Step: 5
Training loss: 1.9385640698723057
Validation loss: 2.4831829130030143

Epoch: 6| Step: 6
Training loss: 2.75699246671946
Validation loss: 2.4828123380334066

Epoch: 6| Step: 7
Training loss: 3.142978223103189
Validation loss: 2.486764794076298

Epoch: 6| Step: 8
Training loss: 2.8563339655114177
Validation loss: 2.515197575432213

Epoch: 6| Step: 9
Training loss: 2.3365432821322494
Validation loss: 2.527143876329868

Epoch: 6| Step: 10
Training loss: 2.820586891246532
Validation loss: 2.5230025791583923

Epoch: 6| Step: 11
Training loss: 2.8189617948619157
Validation loss: 2.5038260746109855

Epoch: 6| Step: 12
Training loss: 2.0992155335561047
Validation loss: 2.484315259683042

Epoch: 6| Step: 13
Training loss: 2.1742926664189355
Validation loss: 2.4748152256076112

Epoch: 152| Step: 0
Training loss: 2.4416020429302683
Validation loss: 2.4641746100395627

Epoch: 6| Step: 1
Training loss: 2.5014846208257087
Validation loss: 2.4670581251403965

Epoch: 6| Step: 2
Training loss: 2.857923629210191
Validation loss: 2.476808585887964

Epoch: 6| Step: 3
Training loss: 2.3488104548853053
Validation loss: 2.4758099556812905

Epoch: 6| Step: 4
Training loss: 2.314752976192016
Validation loss: 2.4815936884281053

Epoch: 6| Step: 5
Training loss: 2.4669385614124426
Validation loss: 2.481901252791536

Epoch: 6| Step: 6
Training loss: 1.9207302498894987
Validation loss: 2.4863551823336683

Epoch: 6| Step: 7
Training loss: 2.717601138762246
Validation loss: 2.4835977358094588

Epoch: 6| Step: 8
Training loss: 2.864153928072625
Validation loss: 2.480770126817269

Epoch: 6| Step: 9
Training loss: 2.893173331687035
Validation loss: 2.486989035595125

Epoch: 6| Step: 10
Training loss: 2.7796284095182977
Validation loss: 2.4863203897128625

Epoch: 6| Step: 11
Training loss: 2.1250672049273556
Validation loss: 2.482151275860949

Epoch: 6| Step: 12
Training loss: 2.5431125676377846
Validation loss: 2.4808786128683766

Epoch: 6| Step: 13
Training loss: 2.10626239716365
Validation loss: 2.476132232160924

Epoch: 153| Step: 0
Training loss: 2.346599118694679
Validation loss: 2.479791968423955

Epoch: 6| Step: 1
Training loss: 2.537793026997272
Validation loss: 2.4832381520389504

Epoch: 6| Step: 2
Training loss: 2.343200517456529
Validation loss: 2.4784069553497647

Epoch: 6| Step: 3
Training loss: 1.8607270269896459
Validation loss: 2.4699892241517043

Epoch: 6| Step: 4
Training loss: 2.7842092308422473
Validation loss: 2.47949294873657

Epoch: 6| Step: 5
Training loss: 1.9791094989216549
Validation loss: 2.4713544507255967

Epoch: 6| Step: 6
Training loss: 2.887498639259183
Validation loss: 2.4863299948901796

Epoch: 6| Step: 7
Training loss: 2.8815667166584413
Validation loss: 2.4811683449173096

Epoch: 6| Step: 8
Training loss: 1.8263906745595708
Validation loss: 2.4752159107962273

Epoch: 6| Step: 9
Training loss: 2.0899357000069583
Validation loss: 2.4825461992035134

Epoch: 6| Step: 10
Training loss: 2.6165996745416606
Validation loss: 2.475647975086623

Epoch: 6| Step: 11
Training loss: 2.8193398275107384
Validation loss: 2.4799579885472474

Epoch: 6| Step: 12
Training loss: 2.862607868944039
Validation loss: 2.471902162810149

Epoch: 6| Step: 13
Training loss: 2.660915182471415
Validation loss: 2.466273985570635

Epoch: 154| Step: 0
Training loss: 2.309868836415365
Validation loss: 2.464790597575305

Epoch: 6| Step: 1
Training loss: 2.180273052578798
Validation loss: 2.4825699044508345

Epoch: 6| Step: 2
Training loss: 2.61145201840656
Validation loss: 2.476876191851162

Epoch: 6| Step: 3
Training loss: 1.8991228287332347
Validation loss: 2.469843650366261

Epoch: 6| Step: 4
Training loss: 2.6185149057695014
Validation loss: 2.474159655494131

Epoch: 6| Step: 5
Training loss: 2.191239022522852
Validation loss: 2.475865022175528

Epoch: 6| Step: 6
Training loss: 2.8793961458814574
Validation loss: 2.4713662043051525

Epoch: 6| Step: 7
Training loss: 2.1436977191032955
Validation loss: 2.474832726936575

Epoch: 6| Step: 8
Training loss: 2.957799854442973
Validation loss: 2.4671658773282035

Epoch: 6| Step: 9
Training loss: 2.332600126417291
Validation loss: 2.469246593056775

Epoch: 6| Step: 10
Training loss: 2.822584763800785
Validation loss: 2.466754170962056

Epoch: 6| Step: 11
Training loss: 2.2645275746639904
Validation loss: 2.4697435287188467

Epoch: 6| Step: 12
Training loss: 2.380228811853462
Validation loss: 2.4746956834040787

Epoch: 6| Step: 13
Training loss: 2.7652041012588295
Validation loss: 2.4761354577629713

Epoch: 155| Step: 0
Training loss: 2.4684513732311673
Validation loss: 2.4825889036990176

Epoch: 6| Step: 1
Training loss: 2.1752677051177454
Validation loss: 2.4806190905729264

Epoch: 6| Step: 2
Training loss: 2.7168046853825993
Validation loss: 2.490713371135408

Epoch: 6| Step: 3
Training loss: 1.877509789777851
Validation loss: 2.499442006464401

Epoch: 6| Step: 4
Training loss: 2.187511553052639
Validation loss: 2.4892889564374725

Epoch: 6| Step: 5
Training loss: 2.2113926287638352
Validation loss: 2.486944872767822

Epoch: 6| Step: 6
Training loss: 2.575162630593479
Validation loss: 2.4835949998860247

Epoch: 6| Step: 7
Training loss: 2.3420622788967846
Validation loss: 2.469795657481414

Epoch: 6| Step: 8
Training loss: 2.457157392553889
Validation loss: 2.4766776522430853

Epoch: 6| Step: 9
Training loss: 3.059947916223412
Validation loss: 2.4904395882816046

Epoch: 6| Step: 10
Training loss: 2.6246122346304093
Validation loss: 2.4770613848775525

Epoch: 6| Step: 11
Training loss: 2.5869031872058117
Validation loss: 2.4792520657958668

Epoch: 6| Step: 12
Training loss: 2.21873108761746
Validation loss: 2.481185497146967

Epoch: 6| Step: 13
Training loss: 2.996725520601644
Validation loss: 2.47818722865258

Epoch: 156| Step: 0
Training loss: 2.64334336709054
Validation loss: 2.4766075218432513

Epoch: 6| Step: 1
Training loss: 2.286830712468462
Validation loss: 2.472351151817943

Epoch: 6| Step: 2
Training loss: 2.4298715797681654
Validation loss: 2.4762874815593228

Epoch: 6| Step: 3
Training loss: 2.2566085826361317
Validation loss: 2.4823493456705914

Epoch: 6| Step: 4
Training loss: 2.518254014017206
Validation loss: 2.4722576734117925

Epoch: 6| Step: 5
Training loss: 2.711394873301575
Validation loss: 2.479945963237527

Epoch: 6| Step: 6
Training loss: 2.054500324731069
Validation loss: 2.4761663816051787

Epoch: 6| Step: 7
Training loss: 2.3897871157272763
Validation loss: 2.4812143081416895

Epoch: 6| Step: 8
Training loss: 3.085782358639795
Validation loss: 2.487892986928775

Epoch: 6| Step: 9
Training loss: 2.6849649582606108
Validation loss: 2.4886830882247595

Epoch: 6| Step: 10
Training loss: 2.3414134267621285
Validation loss: 2.4885075744192737

Epoch: 6| Step: 11
Training loss: 2.7008637247687504
Validation loss: 2.490307153373803

Epoch: 6| Step: 12
Training loss: 2.699928643025441
Validation loss: 2.4789132915709

Epoch: 6| Step: 13
Training loss: 1.5271650048760022
Validation loss: 2.488441913234667

Epoch: 157| Step: 0
Training loss: 2.0126045721145247
Validation loss: 2.4767613055381013

Epoch: 6| Step: 1
Training loss: 2.550864622847845
Validation loss: 2.4751030023892993

Epoch: 6| Step: 2
Training loss: 2.98529645664916
Validation loss: 2.48169293169615

Epoch: 6| Step: 3
Training loss: 1.9620979188755119
Validation loss: 2.483157981425008

Epoch: 6| Step: 4
Training loss: 2.825027539954516
Validation loss: 2.478853836411143

Epoch: 6| Step: 5
Training loss: 2.4877121302954235
Validation loss: 2.477930583599397

Epoch: 6| Step: 6
Training loss: 2.077578709439138
Validation loss: 2.485505780404838

Epoch: 6| Step: 7
Training loss: 2.725982954194475
Validation loss: 2.467051336111773

Epoch: 6| Step: 8
Training loss: 2.565960478135625
Validation loss: 2.4713671931468477

Epoch: 6| Step: 9
Training loss: 2.583728595971644
Validation loss: 2.4818613383444617

Epoch: 6| Step: 10
Training loss: 2.0972474905797753
Validation loss: 2.4764427854081394

Epoch: 6| Step: 11
Training loss: 2.532241062133092
Validation loss: 2.4971715344423986

Epoch: 6| Step: 12
Training loss: 2.684584877415928
Validation loss: 2.4977679779196857

Epoch: 6| Step: 13
Training loss: 2.2288839452077434
Validation loss: 2.498711794519309

Epoch: 158| Step: 0
Training loss: 3.284306873373554
Validation loss: 2.486627393413255

Epoch: 6| Step: 1
Training loss: 2.3753608630234986
Validation loss: 2.4856061943633874

Epoch: 6| Step: 2
Training loss: 2.076131911803766
Validation loss: 2.480156249538574

Epoch: 6| Step: 3
Training loss: 2.4138177543941097
Validation loss: 2.485574508690036

Epoch: 6| Step: 4
Training loss: 2.709649475344706
Validation loss: 2.4782245405937853

Epoch: 6| Step: 5
Training loss: 1.9167449216485555
Validation loss: 2.4886327123027963

Epoch: 6| Step: 6
Training loss: 2.5546104116212267
Validation loss: 2.4863113758355064

Epoch: 6| Step: 7
Training loss: 2.3995209772171155
Validation loss: 2.4810293930723475

Epoch: 6| Step: 8
Training loss: 1.9574332975908046
Validation loss: 2.4788333097030537

Epoch: 6| Step: 9
Training loss: 2.3860330798597102
Validation loss: 2.4801521159250375

Epoch: 6| Step: 10
Training loss: 3.091859490344318
Validation loss: 2.4751462848216215

Epoch: 6| Step: 11
Training loss: 2.739968643844394
Validation loss: 2.479645367628803

Epoch: 6| Step: 12
Training loss: 2.4487266228627576
Validation loss: 2.4858851451463755

Epoch: 6| Step: 13
Training loss: 1.9633882565525922
Validation loss: 2.4780781276867265

Epoch: 159| Step: 0
Training loss: 2.5975269256752958
Validation loss: 2.4729610213105144

Epoch: 6| Step: 1
Training loss: 1.8455050246078066
Validation loss: 2.478051364826103

Epoch: 6| Step: 2
Training loss: 2.576507060678862
Validation loss: 2.476447358448194

Epoch: 6| Step: 3
Training loss: 2.6294796277287227
Validation loss: 2.4816601712885036

Epoch: 6| Step: 4
Training loss: 1.824055960537127
Validation loss: 2.4702966569315663

Epoch: 6| Step: 5
Training loss: 2.3105270629962096
Validation loss: 2.4677534868696664

Epoch: 6| Step: 6
Training loss: 2.4958385163913035
Validation loss: 2.4816978953565516

Epoch: 6| Step: 7
Training loss: 2.5753739909452578
Validation loss: 2.496994898610473

Epoch: 6| Step: 8
Training loss: 2.353427590904097
Validation loss: 2.497448787717829

Epoch: 6| Step: 9
Training loss: 2.0644659440753257
Validation loss: 2.4839570515631535

Epoch: 6| Step: 10
Training loss: 3.0502094509561384
Validation loss: 2.4811942894204027

Epoch: 6| Step: 11
Training loss: 2.5467782031428294
Validation loss: 2.4832937098762002

Epoch: 6| Step: 12
Training loss: 2.8385443357869238
Validation loss: 2.4755512985023196

Epoch: 6| Step: 13
Training loss: 2.7996158915407015
Validation loss: 2.476520445714304

Epoch: 160| Step: 0
Training loss: 2.7215412763065228
Validation loss: 2.4763100993864158

Epoch: 6| Step: 1
Training loss: 2.479511514823501
Validation loss: 2.4794988222698255

Epoch: 6| Step: 2
Training loss: 2.5807381997718637
Validation loss: 2.4780107549603816

Epoch: 6| Step: 3
Training loss: 2.662972951799661
Validation loss: 2.4846228469921443

Epoch: 6| Step: 4
Training loss: 3.125543013124614
Validation loss: 2.4800209261924007

Epoch: 6| Step: 5
Training loss: 2.3820417314488362
Validation loss: 2.4803781087339036

Epoch: 6| Step: 6
Training loss: 2.250898605618627
Validation loss: 2.4841821543703313

Epoch: 6| Step: 7
Training loss: 2.295327839757923
Validation loss: 2.4823353870131153

Epoch: 6| Step: 8
Training loss: 2.605601065734608
Validation loss: 2.4846632048542925

Epoch: 6| Step: 9
Training loss: 1.4880410949303167
Validation loss: 2.480699118982775

Epoch: 6| Step: 10
Training loss: 2.7756660212041164
Validation loss: 2.4821295437287505

Epoch: 6| Step: 11
Training loss: 2.457752698011938
Validation loss: 2.4811525378555785

Epoch: 6| Step: 12
Training loss: 2.204569782491088
Validation loss: 2.4793674216744814

Epoch: 6| Step: 13
Training loss: 2.5064773570601186
Validation loss: 2.479113078673536

Epoch: 161| Step: 0
Training loss: 2.356089647740964
Validation loss: 2.4798379411353544

Epoch: 6| Step: 1
Training loss: 2.9867914612560793
Validation loss: 2.4782274588224835

Epoch: 6| Step: 2
Training loss: 2.8142498083223844
Validation loss: 2.493473562217351

Epoch: 6| Step: 3
Training loss: 2.1594390506326446
Validation loss: 2.4910722108479337

Epoch: 6| Step: 4
Training loss: 2.3691929546467203
Validation loss: 2.494706223417711

Epoch: 6| Step: 5
Training loss: 2.138166143115732
Validation loss: 2.516432701586872

Epoch: 6| Step: 6
Training loss: 2.6986607196947143
Validation loss: 2.5021177064523448

Epoch: 6| Step: 7
Training loss: 2.349093639821517
Validation loss: 2.4920367889913586

Epoch: 6| Step: 8
Training loss: 2.579461323592519
Validation loss: 2.4961654342363397

Epoch: 6| Step: 9
Training loss: 2.0185380334263994
Validation loss: 2.4985387823344314

Epoch: 6| Step: 10
Training loss: 2.4869335123768206
Validation loss: 2.4778436501855423

Epoch: 6| Step: 11
Training loss: 2.6379854451574034
Validation loss: 2.488812496180417

Epoch: 6| Step: 12
Training loss: 2.6291171891947007
Validation loss: 2.4803520115092383

Epoch: 6| Step: 13
Training loss: 2.15940283662158
Validation loss: 2.472857153245217

Epoch: 162| Step: 0
Training loss: 1.9772906262734624
Validation loss: 2.475759382021944

Epoch: 6| Step: 1
Training loss: 2.0237615023987656
Validation loss: 2.476883306894451

Epoch: 6| Step: 2
Training loss: 2.9135340807237133
Validation loss: 2.477811769025187

Epoch: 6| Step: 3
Training loss: 2.615143208129038
Validation loss: 2.482018878999194

Epoch: 6| Step: 4
Training loss: 3.2048153766653615
Validation loss: 2.483706994288329

Epoch: 6| Step: 5
Training loss: 2.064398729659741
Validation loss: 2.4777752126325017

Epoch: 6| Step: 6
Training loss: 2.6070950535462067
Validation loss: 2.4787228344614833

Epoch: 6| Step: 7
Training loss: 1.878726181315833
Validation loss: 2.479201374024719

Epoch: 6| Step: 8
Training loss: 1.9472267506659082
Validation loss: 2.485484477288143

Epoch: 6| Step: 9
Training loss: 3.1083004115375106
Validation loss: 2.4742336133424745

Epoch: 6| Step: 10
Training loss: 2.3051538028004614
Validation loss: 2.473418364909689

Epoch: 6| Step: 11
Training loss: 2.2233950923861743
Validation loss: 2.4740524327635978

Epoch: 6| Step: 12
Training loss: 2.8511047832028633
Validation loss: 2.4687116273883576

Epoch: 6| Step: 13
Training loss: 2.0532734577729825
Validation loss: 2.477164210439465

Epoch: 163| Step: 0
Training loss: 2.738457993749898
Validation loss: 2.4804505274946833

Epoch: 6| Step: 1
Training loss: 2.1427254500112647
Validation loss: 2.472821624352076

Epoch: 6| Step: 2
Training loss: 2.093018361265783
Validation loss: 2.4769630469228914

Epoch: 6| Step: 3
Training loss: 2.589044001529891
Validation loss: 2.477326909937023

Epoch: 6| Step: 4
Training loss: 1.9800888389347213
Validation loss: 2.479142025950671

Epoch: 6| Step: 5
Training loss: 2.6661479763393254
Validation loss: 2.480359893572886

Epoch: 6| Step: 6
Training loss: 3.2507188442174435
Validation loss: 2.4808018258011493

Epoch: 6| Step: 7
Training loss: 2.8749237050423533
Validation loss: 2.491692935418134

Epoch: 6| Step: 8
Training loss: 2.013037743606373
Validation loss: 2.4917587341939353

Epoch: 6| Step: 9
Training loss: 2.4971338054415613
Validation loss: 2.501094451393888

Epoch: 6| Step: 10
Training loss: 1.990977918639422
Validation loss: 2.4860647281271966

Epoch: 6| Step: 11
Training loss: 2.284584847764631
Validation loss: 2.4815955218545676

Epoch: 6| Step: 12
Training loss: 2.219162808552319
Validation loss: 2.4767198161672654

Epoch: 6| Step: 13
Training loss: 2.576117826622188
Validation loss: 2.478838383286311

Epoch: 164| Step: 0
Training loss: 2.3241926945099407
Validation loss: 2.47983079450978

Epoch: 6| Step: 1
Training loss: 2.1038722848965916
Validation loss: 2.4814805417773407

Epoch: 6| Step: 2
Training loss: 3.227469919361496
Validation loss: 2.493290098226842

Epoch: 6| Step: 3
Training loss: 2.5029811251054768
Validation loss: 2.5020345991747455

Epoch: 6| Step: 4
Training loss: 2.3302770307495764
Validation loss: 2.4936644543448985

Epoch: 6| Step: 5
Training loss: 2.2940804225323896
Validation loss: 2.501571828716356

Epoch: 6| Step: 6
Training loss: 2.3688746316376177
Validation loss: 2.4875332253440052

Epoch: 6| Step: 7
Training loss: 2.166593758261152
Validation loss: 2.4994486518698773

Epoch: 6| Step: 8
Training loss: 2.0664244797016074
Validation loss: 2.4973955814068414

Epoch: 6| Step: 9
Training loss: 2.563584261130501
Validation loss: 2.492634110409115

Epoch: 6| Step: 10
Training loss: 2.8572870354377873
Validation loss: 2.49994997928169

Epoch: 6| Step: 11
Training loss: 2.278100543943983
Validation loss: 2.49932250538598

Epoch: 6| Step: 12
Training loss: 2.7103459045258735
Validation loss: 2.5044903165731984

Epoch: 6| Step: 13
Training loss: 2.415214979503232
Validation loss: 2.4918596057976057

Epoch: 165| Step: 0
Training loss: 2.1952271360043594
Validation loss: 2.4884242361557485

Epoch: 6| Step: 1
Training loss: 3.1835257493696223
Validation loss: 2.478470541621922

Epoch: 6| Step: 2
Training loss: 2.578925915781482
Validation loss: 2.4717906543666235

Epoch: 6| Step: 3
Training loss: 2.5233514257342606
Validation loss: 2.4749285164216963

Epoch: 6| Step: 4
Training loss: 2.1159545010757106
Validation loss: 2.474195052751019

Epoch: 6| Step: 5
Training loss: 2.173243030044997
Validation loss: 2.4748628482001025

Epoch: 6| Step: 6
Training loss: 2.662838920549039
Validation loss: 2.4687882110600188

Epoch: 6| Step: 7
Training loss: 2.07405368413944
Validation loss: 2.4666715798028354

Epoch: 6| Step: 8
Training loss: 2.6772814923481656
Validation loss: 2.4727309277483247

Epoch: 6| Step: 9
Training loss: 1.9478861624493287
Validation loss: 2.481295950822029

Epoch: 6| Step: 10
Training loss: 2.737974228564202
Validation loss: 2.483500232677834

Epoch: 6| Step: 11
Training loss: 2.4399372533641115
Validation loss: 2.478320976612179

Epoch: 6| Step: 12
Training loss: 2.3374155529088063
Validation loss: 2.497165988903781

Epoch: 6| Step: 13
Training loss: 2.3957134272106466
Validation loss: 2.490723071048126

Epoch: 166| Step: 0
Training loss: 2.434037610474185
Validation loss: 2.4865673156898755

Epoch: 6| Step: 1
Training loss: 2.326157115822195
Validation loss: 2.482073487556896

Epoch: 6| Step: 2
Training loss: 2.464801963294763
Validation loss: 2.483277980349686

Epoch: 6| Step: 3
Training loss: 2.789017022453984
Validation loss: 2.4694218264663084

Epoch: 6| Step: 4
Training loss: 1.5339877508139421
Validation loss: 2.487997473040828

Epoch: 6| Step: 5
Training loss: 2.556571056098455
Validation loss: 2.4858265441007252

Epoch: 6| Step: 6
Training loss: 2.0925238136021163
Validation loss: 2.481779842353686

Epoch: 6| Step: 7
Training loss: 3.054619595682679
Validation loss: 2.4966025791507644

Epoch: 6| Step: 8
Training loss: 3.0208287381542815
Validation loss: 2.486687437725844

Epoch: 6| Step: 9
Training loss: 2.250235333321466
Validation loss: 2.487064720932443

Epoch: 6| Step: 10
Training loss: 2.3651900220346
Validation loss: 2.4909217912909805

Epoch: 6| Step: 11
Training loss: 2.6440408497077152
Validation loss: 2.4946659404210565

Epoch: 6| Step: 12
Training loss: 2.186614374993167
Validation loss: 2.510906683450425

Epoch: 6| Step: 13
Training loss: 2.500159830706259
Validation loss: 2.525694618112048

Epoch: 167| Step: 0
Training loss: 2.491181460527294
Validation loss: 2.5033379364563957

Epoch: 6| Step: 1
Training loss: 2.7074363592528443
Validation loss: 2.508422777306871

Epoch: 6| Step: 2
Training loss: 2.4538575068906376
Validation loss: 2.5025717541001216

Epoch: 6| Step: 3
Training loss: 2.4841269123317846
Validation loss: 2.5016757911636023

Epoch: 6| Step: 4
Training loss: 2.3250345289065946
Validation loss: 2.502167636193315

Epoch: 6| Step: 5
Training loss: 2.8292097677356964
Validation loss: 2.4872574469108213

Epoch: 6| Step: 6
Training loss: 2.066607690810543
Validation loss: 2.491902477583965

Epoch: 6| Step: 7
Training loss: 2.112918505323369
Validation loss: 2.4973318484916827

Epoch: 6| Step: 8
Training loss: 2.694210988403956
Validation loss: 2.487839991530986

Epoch: 6| Step: 9
Training loss: 3.1013672428502264
Validation loss: 2.488247394580972

Epoch: 6| Step: 10
Training loss: 2.491673814216832
Validation loss: 2.492805970242263

Epoch: 6| Step: 11
Training loss: 2.50914408190177
Validation loss: 2.4804681893095246

Epoch: 6| Step: 12
Training loss: 2.2430022882593588
Validation loss: 2.4851457691741117

Epoch: 6| Step: 13
Training loss: 1.6417510028741364
Validation loss: 2.4807643764276235

Epoch: 168| Step: 0
Training loss: 2.332990132931913
Validation loss: 2.47588413707268

Epoch: 6| Step: 1
Training loss: 2.750162466625285
Validation loss: 2.475228111595408

Epoch: 6| Step: 2
Training loss: 2.6961711013561596
Validation loss: 2.488269336777718

Epoch: 6| Step: 3
Training loss: 1.8298234792946033
Validation loss: 2.472263331077437

Epoch: 6| Step: 4
Training loss: 2.79081077170932
Validation loss: 2.4771301950610476

Epoch: 6| Step: 5
Training loss: 2.3621628818473117
Validation loss: 2.4803651162272784

Epoch: 6| Step: 6
Training loss: 2.5349092759971947
Validation loss: 2.4776398634863375

Epoch: 6| Step: 7
Training loss: 2.7272521625090254
Validation loss: 2.476061299949249

Epoch: 6| Step: 8
Training loss: 2.328335131692522
Validation loss: 2.4758897383034175

Epoch: 6| Step: 9
Training loss: 3.0453119425726625
Validation loss: 2.4797426938326432

Epoch: 6| Step: 10
Training loss: 3.0168434014017933
Validation loss: 2.4862051406733556

Epoch: 6| Step: 11
Training loss: 1.676204885719133
Validation loss: 2.478194315880162

Epoch: 6| Step: 12
Training loss: 2.089742440593476
Validation loss: 2.4762818090176064

Epoch: 6| Step: 13
Training loss: 2.4607326846193205
Validation loss: 2.476460339417641

Epoch: 169| Step: 0
Training loss: 2.2755599454168522
Validation loss: 2.4735824995500106

Epoch: 6| Step: 1
Training loss: 2.9221578042972514
Validation loss: 2.4768612237226804

Epoch: 6| Step: 2
Training loss: 2.138690937950144
Validation loss: 2.484706112851051

Epoch: 6| Step: 3
Training loss: 2.5193718911570295
Validation loss: 2.524448723619637

Epoch: 6| Step: 4
Training loss: 2.2715565874162116
Validation loss: 2.5371860710848235

Epoch: 6| Step: 5
Training loss: 2.461510485595587
Validation loss: 2.557505190158225

Epoch: 6| Step: 6
Training loss: 2.815409278861818
Validation loss: 2.5924345533766435

Epoch: 6| Step: 7
Training loss: 2.6880233609910085
Validation loss: 2.5740062604698117

Epoch: 6| Step: 8
Training loss: 2.649315252546032
Validation loss: 2.5390102283281277

Epoch: 6| Step: 9
Training loss: 2.3888488354639583
Validation loss: 2.51864974498399

Epoch: 6| Step: 10
Training loss: 2.2878401164699103
Validation loss: 2.5012536879065412

Epoch: 6| Step: 11
Training loss: 2.672746036719639
Validation loss: 2.4916968186466777

Epoch: 6| Step: 12
Training loss: 2.2633739996259163
Validation loss: 2.4811370029551507

Epoch: 6| Step: 13
Training loss: 2.1881595162330933
Validation loss: 2.473031464000826

Epoch: 170| Step: 0
Training loss: 2.085687400883484
Validation loss: 2.4710902778954065

Epoch: 6| Step: 1
Training loss: 2.4653097398384416
Validation loss: 2.472646599741219

Epoch: 6| Step: 2
Training loss: 2.3062765559293186
Validation loss: 2.4736762250706943

Epoch: 6| Step: 3
Training loss: 1.8472014627588824
Validation loss: 2.477551620746281

Epoch: 6| Step: 4
Training loss: 2.4825626696525593
Validation loss: 2.475326349917745

Epoch: 6| Step: 5
Training loss: 2.68810646843659
Validation loss: 2.4756234331069042

Epoch: 6| Step: 6
Training loss: 2.66737388133939
Validation loss: 2.4711823452281725

Epoch: 6| Step: 7
Training loss: 2.4532886620614813
Validation loss: 2.4820954282998615

Epoch: 6| Step: 8
Training loss: 2.100662322276054
Validation loss: 2.475686761833161

Epoch: 6| Step: 9
Training loss: 2.431366269976973
Validation loss: 2.4824287500493862

Epoch: 6| Step: 10
Training loss: 3.1731694027955535
Validation loss: 2.4720207068528683

Epoch: 6| Step: 11
Training loss: 2.6889034421472644
Validation loss: 2.4842721689883307

Epoch: 6| Step: 12
Training loss: 2.493551329536295
Validation loss: 2.4784038289024752

Epoch: 6| Step: 13
Training loss: 2.308492952008443
Validation loss: 2.4658289339525434

Epoch: 171| Step: 0
Training loss: 2.324023429292903
Validation loss: 2.4758646610614408

Epoch: 6| Step: 1
Training loss: 2.662031098388338
Validation loss: 2.4806996956392897

Epoch: 6| Step: 2
Training loss: 2.5484080936833258
Validation loss: 2.479196585680373

Epoch: 6| Step: 3
Training loss: 2.4114640457601975
Validation loss: 2.4806388095821497

Epoch: 6| Step: 4
Training loss: 2.853882564317945
Validation loss: 2.4949339877144596

Epoch: 6| Step: 5
Training loss: 2.4831279767870975
Validation loss: 2.501784577798441

Epoch: 6| Step: 6
Training loss: 2.1132038546508083
Validation loss: 2.5129802456808106

Epoch: 6| Step: 7
Training loss: 2.24139347704349
Validation loss: 2.4843570540637705

Epoch: 6| Step: 8
Training loss: 2.5267340795872753
Validation loss: 2.484768210588987

Epoch: 6| Step: 9
Training loss: 2.539687047587284
Validation loss: 2.477924922837206

Epoch: 6| Step: 10
Training loss: 1.8853158098365972
Validation loss: 2.4828450352253717

Epoch: 6| Step: 11
Training loss: 2.912403933532934
Validation loss: 2.4739192571398263

Epoch: 6| Step: 12
Training loss: 2.7876538905613826
Validation loss: 2.485257118094412

Epoch: 6| Step: 13
Training loss: 1.9477135115437092
Validation loss: 2.4835819922088187

Epoch: 172| Step: 0
Training loss: 2.679718462261904
Validation loss: 2.4823391808303117

Epoch: 6| Step: 1
Training loss: 2.2505030599461864
Validation loss: 2.490917125180363

Epoch: 6| Step: 2
Training loss: 2.264420814145453
Validation loss: 2.4844964435572665

Epoch: 6| Step: 3
Training loss: 2.083159579342834
Validation loss: 2.4903543680240747

Epoch: 6| Step: 4
Training loss: 2.3610824570755904
Validation loss: 2.497993236022539

Epoch: 6| Step: 5
Training loss: 2.77369280432533
Validation loss: 2.4933796326355546

Epoch: 6| Step: 6
Training loss: 2.70461677445576
Validation loss: 2.4884672868890747

Epoch: 6| Step: 7
Training loss: 2.429475143327443
Validation loss: 2.4895280541916

Epoch: 6| Step: 8
Training loss: 2.150313456551342
Validation loss: 2.502366694133693

Epoch: 6| Step: 9
Training loss: 2.353922220777944
Validation loss: 2.498488668745229

Epoch: 6| Step: 10
Training loss: 2.9126649015838497
Validation loss: 2.4938077453071834

Epoch: 6| Step: 11
Training loss: 2.5183128072161756
Validation loss: 2.487818109437084

Epoch: 6| Step: 12
Training loss: 2.2770242090626147
Validation loss: 2.50009210734764

Epoch: 6| Step: 13
Training loss: 2.3102733098631143
Validation loss: 2.491855324159685

Epoch: 173| Step: 0
Training loss: 2.6662812153079436
Validation loss: 2.485048662575247

Epoch: 6| Step: 1
Training loss: 1.8386700362939274
Validation loss: 2.4932930785089784

Epoch: 6| Step: 2
Training loss: 2.6582700341161325
Validation loss: 2.485759677117566

Epoch: 6| Step: 3
Training loss: 2.4142908278449005
Validation loss: 2.4856318127822776

Epoch: 6| Step: 4
Training loss: 1.961164180222482
Validation loss: 2.4893610441388305

Epoch: 6| Step: 5
Training loss: 2.3034097523946446
Validation loss: 2.4892375711261843

Epoch: 6| Step: 6
Training loss: 1.8302451986711812
Validation loss: 2.493952286753071

Epoch: 6| Step: 7
Training loss: 2.568559599639579
Validation loss: 2.4959662160594247

Epoch: 6| Step: 8
Training loss: 2.4579910320183567
Validation loss: 2.4975802950446075

Epoch: 6| Step: 9
Training loss: 2.1744775341888207
Validation loss: 2.481440508468884

Epoch: 6| Step: 10
Training loss: 2.793612831383827
Validation loss: 2.4859033198217695

Epoch: 6| Step: 11
Training loss: 2.5839634301222665
Validation loss: 2.4989131790370696

Epoch: 6| Step: 12
Training loss: 2.365025908830277
Validation loss: 2.492623700560848

Epoch: 6| Step: 13
Training loss: 2.9232119189298666
Validation loss: 2.487463632634066

Epoch: 174| Step: 0
Training loss: 1.812789828049049
Validation loss: 2.481083671061995

Epoch: 6| Step: 1
Training loss: 2.5073258828043405
Validation loss: 2.484669106147141

Epoch: 6| Step: 2
Training loss: 2.2139381562221687
Validation loss: 2.482738539704661

Epoch: 6| Step: 3
Training loss: 2.9172578121757073
Validation loss: 2.483202643657208

Epoch: 6| Step: 4
Training loss: 2.276905259699118
Validation loss: 2.495398992362378

Epoch: 6| Step: 5
Training loss: 1.9627554320280993
Validation loss: 2.499449319589068

Epoch: 6| Step: 6
Training loss: 2.696326908010384
Validation loss: 2.4915256558155767

Epoch: 6| Step: 7
Training loss: 2.5873969532078447
Validation loss: 2.484656567882175

Epoch: 6| Step: 8
Training loss: 2.020893161582825
Validation loss: 2.482906731397179

Epoch: 6| Step: 9
Training loss: 2.7628542711758945
Validation loss: 2.5099937958659666

Epoch: 6| Step: 10
Training loss: 2.5504646513717315
Validation loss: 2.50496966414062

Epoch: 6| Step: 11
Training loss: 2.5772909028924778
Validation loss: 2.4881545533123797

Epoch: 6| Step: 12
Training loss: 2.3726586295057217
Validation loss: 2.5013410309369464

Epoch: 6| Step: 13
Training loss: 2.6881863804301545
Validation loss: 2.494051117910295

Epoch: 175| Step: 0
Training loss: 2.845232566619871
Validation loss: 2.4941863173061094

Epoch: 6| Step: 1
Training loss: 2.5248762345905194
Validation loss: 2.4844075326768817

Epoch: 6| Step: 2
Training loss: 2.4040821763590476
Validation loss: 2.488110914243977

Epoch: 6| Step: 3
Training loss: 1.9114878874805838
Validation loss: 2.486722065416739

Epoch: 6| Step: 4
Training loss: 2.502824808662737
Validation loss: 2.484469781822992

Epoch: 6| Step: 5
Training loss: 2.3046926724650643
Validation loss: 2.4915350654916466

Epoch: 6| Step: 6
Training loss: 1.9188715719172893
Validation loss: 2.4830575804827726

Epoch: 6| Step: 7
Training loss: 1.683620443818435
Validation loss: 2.497997690074006

Epoch: 6| Step: 8
Training loss: 2.2529468312497913
Validation loss: 2.500929945601027

Epoch: 6| Step: 9
Training loss: 1.8805609572292468
Validation loss: 2.4976818622337467

Epoch: 6| Step: 10
Training loss: 3.1156806841344125
Validation loss: 2.495514819964937

Epoch: 6| Step: 11
Training loss: 2.607915230128115
Validation loss: 2.505177842005529

Epoch: 6| Step: 12
Training loss: 2.6012444745673724
Validation loss: 2.5034604600643875

Epoch: 6| Step: 13
Training loss: 2.917526191129693
Validation loss: 2.5138823592263337

Epoch: 176| Step: 0
Training loss: 2.409132976720863
Validation loss: 2.514093047107194

Epoch: 6| Step: 1
Training loss: 2.6769763811371248
Validation loss: 2.5182010737170044

Epoch: 6| Step: 2
Training loss: 2.65172056087805
Validation loss: 2.5076237782803896

Epoch: 6| Step: 3
Training loss: 2.8247382186183456
Validation loss: 2.5065275328741214

Epoch: 6| Step: 4
Training loss: 2.4812469943626514
Validation loss: 2.501969269167619

Epoch: 6| Step: 5
Training loss: 2.190491728599203
Validation loss: 2.496907721835408

Epoch: 6| Step: 6
Training loss: 2.789809524979966
Validation loss: 2.5012490490135204

Epoch: 6| Step: 7
Training loss: 2.2511470837661904
Validation loss: 2.491345206440205

Epoch: 6| Step: 8
Training loss: 1.9704540688873224
Validation loss: 2.4919380214590765

Epoch: 6| Step: 9
Training loss: 2.5402342924059074
Validation loss: 2.4877361696676847

Epoch: 6| Step: 10
Training loss: 1.8862265503615785
Validation loss: 2.4965504928378435

Epoch: 6| Step: 11
Training loss: 1.8510551562342783
Validation loss: 2.5018161534683574

Epoch: 6| Step: 12
Training loss: 2.74833420672691
Validation loss: 2.4932273361638155

Epoch: 6| Step: 13
Training loss: 2.4326000358500623
Validation loss: 2.500776710653113

Epoch: 177| Step: 0
Training loss: 2.132873757848538
Validation loss: 2.4936117728285354

Epoch: 6| Step: 1
Training loss: 1.9468380258640408
Validation loss: 2.5086193905904732

Epoch: 6| Step: 2
Training loss: 2.1287671524942726
Validation loss: 2.4976562083171436

Epoch: 6| Step: 3
Training loss: 2.135179931419967
Validation loss: 2.5089599899602857

Epoch: 6| Step: 4
Training loss: 2.694466986239635
Validation loss: 2.538135645008911

Epoch: 6| Step: 5
Training loss: 2.220607034152638
Validation loss: 2.5404807487348497

Epoch: 6| Step: 6
Training loss: 2.8562735324950306
Validation loss: 2.5501091360286803

Epoch: 6| Step: 7
Training loss: 2.8070397673896226
Validation loss: 2.5405552315291784

Epoch: 6| Step: 8
Training loss: 2.147634571197765
Validation loss: 2.5062447120566325

Epoch: 6| Step: 9
Training loss: 2.421140300922375
Validation loss: 2.5103000492430008

Epoch: 6| Step: 10
Training loss: 2.2153537169873414
Validation loss: 2.5037888585193957

Epoch: 6| Step: 11
Training loss: 2.9253392210315488
Validation loss: 2.497664377825537

Epoch: 6| Step: 12
Training loss: 2.4005803280790374
Validation loss: 2.488437362237192

Epoch: 6| Step: 13
Training loss: 2.5551720022694444
Validation loss: 2.482514394441165

Epoch: 178| Step: 0
Training loss: 2.4620554488853883
Validation loss: 2.483557048637227

Epoch: 6| Step: 1
Training loss: 2.6744425968293566
Validation loss: 2.4936998934320895

Epoch: 6| Step: 2
Training loss: 2.8386531889586406
Validation loss: 2.4902728787107042

Epoch: 6| Step: 3
Training loss: 2.289634138474448
Validation loss: 2.4886904489317767

Epoch: 6| Step: 4
Training loss: 2.9744886648090687
Validation loss: 2.4823460721163366

Epoch: 6| Step: 5
Training loss: 2.0715911947033403
Validation loss: 2.4992858820464163

Epoch: 6| Step: 6
Training loss: 2.336913858454337
Validation loss: 2.4943597588280184

Epoch: 6| Step: 7
Training loss: 3.014568242525416
Validation loss: 2.4966430457652606

Epoch: 6| Step: 8
Training loss: 2.561616698824072
Validation loss: 2.4948170978521516

Epoch: 6| Step: 9
Training loss: 1.8321330808794585
Validation loss: 2.500537782683266

Epoch: 6| Step: 10
Training loss: 1.7542131660925036
Validation loss: 2.506334956910039

Epoch: 6| Step: 11
Training loss: 1.7317343877719442
Validation loss: 2.504457299054604

Epoch: 6| Step: 12
Training loss: 2.1082878419494144
Validation loss: 2.5097817584952833

Epoch: 6| Step: 13
Training loss: 2.8045210509997047
Validation loss: 2.5005495421092387

Epoch: 179| Step: 0
Training loss: 1.5793628936412274
Validation loss: 2.536329267430975

Epoch: 6| Step: 1
Training loss: 2.1575511379082557
Validation loss: 2.531283264569516

Epoch: 6| Step: 2
Training loss: 2.375557783782187
Validation loss: 2.535889412264772

Epoch: 6| Step: 3
Training loss: 2.5898270872566815
Validation loss: 2.5310685049537875

Epoch: 6| Step: 4
Training loss: 2.1210831840350326
Validation loss: 2.5435547199945927

Epoch: 6| Step: 5
Training loss: 2.2640594334973194
Validation loss: 2.5389214813979417

Epoch: 6| Step: 6
Training loss: 3.145423677225841
Validation loss: 2.5293549087916665

Epoch: 6| Step: 7
Training loss: 2.5460929371966237
Validation loss: 2.510710985228962

Epoch: 6| Step: 8
Training loss: 2.651812538132407
Validation loss: 2.513612657080159

Epoch: 6| Step: 9
Training loss: 1.5720612766320408
Validation loss: 2.5078582917941725

Epoch: 6| Step: 10
Training loss: 2.582658146228564
Validation loss: 2.503056549139614

Epoch: 6| Step: 11
Training loss: 2.231384730612254
Validation loss: 2.489442467528282

Epoch: 6| Step: 12
Training loss: 3.377391956557997
Validation loss: 2.490254065741187

Epoch: 6| Step: 13
Training loss: 1.6792839807590787
Validation loss: 2.48330348677482

Epoch: 180| Step: 0
Training loss: 2.511710681576028
Validation loss: 2.4792933364906222

Epoch: 6| Step: 1
Training loss: 2.550652259731468
Validation loss: 2.4833594271763184

Epoch: 6| Step: 2
Training loss: 2.7142225254562478
Validation loss: 2.4806376722593133

Epoch: 6| Step: 3
Training loss: 1.9155190667239286
Validation loss: 2.4888559553071574

Epoch: 6| Step: 4
Training loss: 2.460258075233761
Validation loss: 2.489520288943388

Epoch: 6| Step: 5
Training loss: 2.0483703974740024
Validation loss: 2.498330496603399

Epoch: 6| Step: 6
Training loss: 2.515822977367145
Validation loss: 2.492863442844618

Epoch: 6| Step: 7
Training loss: 2.944895909644369
Validation loss: 2.4969643759456845

Epoch: 6| Step: 8
Training loss: 1.8141420095599516
Validation loss: 2.4981314828963694

Epoch: 6| Step: 9
Training loss: 2.0467538579371163
Validation loss: 2.493598817403099

Epoch: 6| Step: 10
Training loss: 2.9462769242271505
Validation loss: 2.495900687411155

Epoch: 6| Step: 11
Training loss: 2.5763594621986843
Validation loss: 2.5171488693622828

Epoch: 6| Step: 12
Training loss: 2.0154455533841658
Validation loss: 2.5172638382515684

Epoch: 6| Step: 13
Training loss: 2.378071254769552
Validation loss: 2.525054350667742

Epoch: 181| Step: 0
Training loss: 2.2520781562550405
Validation loss: 2.520331290723483

Epoch: 6| Step: 1
Training loss: 3.125055999254113
Validation loss: 2.5287090939204986

Epoch: 6| Step: 2
Training loss: 2.336947933833096
Validation loss: 2.5238549563314967

Epoch: 6| Step: 3
Training loss: 2.691204091135424
Validation loss: 2.5231629370885607

Epoch: 6| Step: 4
Training loss: 1.7095370200188533
Validation loss: 2.536118538803731

Epoch: 6| Step: 5
Training loss: 2.061576867868115
Validation loss: 2.5377289307025666

Epoch: 6| Step: 6
Training loss: 2.3308139096558764
Validation loss: 2.5220628897670623

Epoch: 6| Step: 7
Training loss: 2.52817206981396
Validation loss: 2.5287493845947844

Epoch: 6| Step: 8
Training loss: 1.9512858772767303
Validation loss: 2.5265278037100485

Epoch: 6| Step: 9
Training loss: 2.3006294342885374
Validation loss: 2.5271192133516593

Epoch: 6| Step: 10
Training loss: 1.9951451505474307
Validation loss: 2.515712602247105

Epoch: 6| Step: 11
Training loss: 2.7391570210400653
Validation loss: 2.5214578364655247

Epoch: 6| Step: 12
Training loss: 2.0964536149661384
Validation loss: 2.5225028402402607

Epoch: 6| Step: 13
Training loss: 3.0323459177898417
Validation loss: 2.5092152587035255

Epoch: 182| Step: 0
Training loss: 2.6808945853750137
Validation loss: 2.5156167229620885

Epoch: 6| Step: 1
Training loss: 2.2148591432927933
Validation loss: 2.4969864484210214

Epoch: 6| Step: 2
Training loss: 2.3579337663351234
Validation loss: 2.510378102577497

Epoch: 6| Step: 3
Training loss: 2.8455861629832815
Validation loss: 2.504415697313397

Epoch: 6| Step: 4
Training loss: 1.8164714842536587
Validation loss: 2.5115532471990787

Epoch: 6| Step: 5
Training loss: 1.8353579641329774
Validation loss: 2.515178506531579

Epoch: 6| Step: 6
Training loss: 2.218735815728208
Validation loss: 2.512633177484073

Epoch: 6| Step: 7
Training loss: 2.3626399407493355
Validation loss: 2.5142438900165827

Epoch: 6| Step: 8
Training loss: 2.534010523917994
Validation loss: 2.515116511857246

Epoch: 6| Step: 9
Training loss: 2.5457500009170557
Validation loss: 2.529872865033222

Epoch: 6| Step: 10
Training loss: 2.5489603877919946
Validation loss: 2.5420128372922703

Epoch: 6| Step: 11
Training loss: 2.1771716840664253
Validation loss: 2.537186243362576

Epoch: 6| Step: 12
Training loss: 2.8963716038713683
Validation loss: 2.5450898761780287

Epoch: 6| Step: 13
Training loss: 2.4314326553572982
Validation loss: 2.527139772401829

Epoch: 183| Step: 0
Training loss: 2.418022586549791
Validation loss: 2.526858582425618

Epoch: 6| Step: 1
Training loss: 2.5378020459135824
Validation loss: 2.546675473376054

Epoch: 6| Step: 2
Training loss: 3.2437008186977883
Validation loss: 2.5376534645765694

Epoch: 6| Step: 3
Training loss: 2.2110112585698114
Validation loss: 2.5679858498138888

Epoch: 6| Step: 4
Training loss: 2.6685116663694397
Validation loss: 2.5511862650885835

Epoch: 6| Step: 5
Training loss: 2.675083576215889
Validation loss: 2.567327797465802

Epoch: 6| Step: 6
Training loss: 1.987315964725374
Validation loss: 2.5399793642061863

Epoch: 6| Step: 7
Training loss: 1.8215784737800664
Validation loss: 2.531341865034229

Epoch: 6| Step: 8
Training loss: 2.746682072830819
Validation loss: 2.5027471866024724

Epoch: 6| Step: 9
Training loss: 2.2785964582634186
Validation loss: 2.5084783476250583

Epoch: 6| Step: 10
Training loss: 2.209711496500417
Validation loss: 2.4993714337118007

Epoch: 6| Step: 11
Training loss: 2.184036455674579
Validation loss: 2.5049045137948833

Epoch: 6| Step: 12
Training loss: 2.167571050233994
Validation loss: 2.487995516561923

Epoch: 6| Step: 13
Training loss: 2.3474363709622788
Validation loss: 2.496852458968286

Epoch: 184| Step: 0
Training loss: 2.229852541166496
Validation loss: 2.506212082319964

Epoch: 6| Step: 1
Training loss: 2.61430213500203
Validation loss: 2.5083725126719285

Epoch: 6| Step: 2
Training loss: 2.131725886846813
Validation loss: 2.521928964232088

Epoch: 6| Step: 3
Training loss: 2.3989586279522848
Validation loss: 2.5448910605691744

Epoch: 6| Step: 4
Training loss: 3.2012506723161174
Validation loss: 2.5514727478376025

Epoch: 6| Step: 5
Training loss: 1.981386713070464
Validation loss: 2.6052010935840784

Epoch: 6| Step: 6
Training loss: 2.748834276212787
Validation loss: 2.613199427549209

Epoch: 6| Step: 7
Training loss: 2.0529938306088664
Validation loss: 2.5895255129663957

Epoch: 6| Step: 8
Training loss: 2.2921715151405615
Validation loss: 2.5669831856926257

Epoch: 6| Step: 9
Training loss: 2.218606433790509
Validation loss: 2.5127422962424224

Epoch: 6| Step: 10
Training loss: 2.1779233294566867
Validation loss: 2.515369536576668

Epoch: 6| Step: 11
Training loss: 2.2506728755622722
Validation loss: 2.4996292793064465

Epoch: 6| Step: 12
Training loss: 2.2987814536336035
Validation loss: 2.4873521668228853

Epoch: 6| Step: 13
Training loss: 3.2796589218137635
Validation loss: 2.4783599940928736

Epoch: 185| Step: 0
Training loss: 2.157855666141092
Validation loss: 2.4850532117835242

Epoch: 6| Step: 1
Training loss: 2.996739682194527
Validation loss: 2.483728208659057

Epoch: 6| Step: 2
Training loss: 2.697322549295231
Validation loss: 2.473770621690708

Epoch: 6| Step: 3
Training loss: 2.4459428553670652
Validation loss: 2.479795381554508

Epoch: 6| Step: 4
Training loss: 2.5284917426311107
Validation loss: 2.4839381827598483

Epoch: 6| Step: 5
Training loss: 2.0637503792977867
Validation loss: 2.478809448493718

Epoch: 6| Step: 6
Training loss: 2.3982665159431593
Validation loss: 2.4789706935414664

Epoch: 6| Step: 7
Training loss: 2.3772728735480952
Validation loss: 2.470944632285169

Epoch: 6| Step: 8
Training loss: 2.4546031993277246
Validation loss: 2.4759839943628847

Epoch: 6| Step: 9
Training loss: 2.4685446738314583
Validation loss: 2.486354167489197

Epoch: 6| Step: 10
Training loss: 2.314675622216639
Validation loss: 2.4814685798924327

Epoch: 6| Step: 11
Training loss: 2.470177056920293
Validation loss: 2.4886081706363923

Epoch: 6| Step: 12
Training loss: 1.9101814627202358
Validation loss: 2.480361223268146

Epoch: 6| Step: 13
Training loss: 2.8350711056035482
Validation loss: 2.495078217064592

Epoch: 186| Step: 0
Training loss: 2.0402685815119024
Validation loss: 2.4984836032566817

Epoch: 6| Step: 1
Training loss: 2.3741292863203687
Validation loss: 2.50362250614323

Epoch: 6| Step: 2
Training loss: 3.3443735557329184
Validation loss: 2.5132527667656817

Epoch: 6| Step: 3
Training loss: 2.5196036394942336
Validation loss: 2.509431088882874

Epoch: 6| Step: 4
Training loss: 2.2442483502620223
Validation loss: 2.50348071342177

Epoch: 6| Step: 5
Training loss: 2.566101613537023
Validation loss: 2.518655314215781

Epoch: 6| Step: 6
Training loss: 2.208785988342321
Validation loss: 2.505877214518412

Epoch: 6| Step: 7
Training loss: 2.2425966321523396
Validation loss: 2.4992509673493437

Epoch: 6| Step: 8
Training loss: 2.3678339210921773
Validation loss: 2.5080765914903274

Epoch: 6| Step: 9
Training loss: 2.436614438117764
Validation loss: 2.5211499911161326

Epoch: 6| Step: 10
Training loss: 2.9716262536787386
Validation loss: 2.5110303727488903

Epoch: 6| Step: 11
Training loss: 1.414935269442184
Validation loss: 2.4923284444944254

Epoch: 6| Step: 12
Training loss: 2.3367097018419667
Validation loss: 2.4992535748390203

Epoch: 6| Step: 13
Training loss: 2.301700531445457
Validation loss: 2.4941211481610925

Epoch: 187| Step: 0
Training loss: 2.1466908516123695
Validation loss: 2.4942545515033365

Epoch: 6| Step: 1
Training loss: 2.3117414725406165
Validation loss: 2.4840373643531293

Epoch: 6| Step: 2
Training loss: 3.004022127255397
Validation loss: 2.498806533453835

Epoch: 6| Step: 3
Training loss: 2.2497694109272066
Validation loss: 2.49448981214339

Epoch: 6| Step: 4
Training loss: 2.6103451689853427
Validation loss: 2.5141815720030882

Epoch: 6| Step: 5
Training loss: 2.220423644771863
Validation loss: 2.507079115256443

Epoch: 6| Step: 6
Training loss: 1.8309559869231715
Validation loss: 2.518498487512345

Epoch: 6| Step: 7
Training loss: 2.1706947028570083
Validation loss: 2.515370326449151

Epoch: 6| Step: 8
Training loss: 2.805322686740244
Validation loss: 2.508828659408386

Epoch: 6| Step: 9
Training loss: 2.559819936678229
Validation loss: 2.508716867808146

Epoch: 6| Step: 10
Training loss: 2.848147168118208
Validation loss: 2.507912084200614

Epoch: 6| Step: 11
Training loss: 2.079845318728103
Validation loss: 2.5097735017685046

Epoch: 6| Step: 12
Training loss: 2.2982755789394074
Validation loss: 2.487657198259938

Epoch: 6| Step: 13
Training loss: 2.425004082115906
Validation loss: 2.502200953894969

Epoch: 188| Step: 0
Training loss: 1.8984710313637894
Validation loss: 2.491523470851812

Epoch: 6| Step: 1
Training loss: 2.261850514633829
Validation loss: 2.4874062908674905

Epoch: 6| Step: 2
Training loss: 2.4465919535539276
Validation loss: 2.485720160330693

Epoch: 6| Step: 3
Training loss: 2.1176642412535758
Validation loss: 2.483366451639971

Epoch: 6| Step: 4
Training loss: 2.4819264371484713
Validation loss: 2.489187685334238

Epoch: 6| Step: 5
Training loss: 2.7364839976404105
Validation loss: 2.4838132083134425

Epoch: 6| Step: 6
Training loss: 2.308359408546923
Validation loss: 2.4836220709958017

Epoch: 6| Step: 7
Training loss: 2.137337045983231
Validation loss: 2.488521833781213

Epoch: 6| Step: 8
Training loss: 2.2146455652554904
Validation loss: 2.4928980245971237

Epoch: 6| Step: 9
Training loss: 2.8366488150525373
Validation loss: 2.4983310214747276

Epoch: 6| Step: 10
Training loss: 2.262022745788782
Validation loss: 2.5032943001593817

Epoch: 6| Step: 11
Training loss: 3.270776946600245
Validation loss: 2.5062777377374976

Epoch: 6| Step: 12
Training loss: 2.6213233267333442
Validation loss: 2.507897230006345

Epoch: 6| Step: 13
Training loss: 1.8730918075375034
Validation loss: 2.5176746871734963

Epoch: 189| Step: 0
Training loss: 2.0344010780643633
Validation loss: 2.5175537234461194

Epoch: 6| Step: 1
Training loss: 2.4854367464527587
Validation loss: 2.4978302918157675

Epoch: 6| Step: 2
Training loss: 2.0510733841406377
Validation loss: 2.4954582603335558

Epoch: 6| Step: 3
Training loss: 2.0967913501501414
Validation loss: 2.489302756381548

Epoch: 6| Step: 4
Training loss: 2.404478932358782
Validation loss: 2.497615264915862

Epoch: 6| Step: 5
Training loss: 2.3533800774633633
Validation loss: 2.4892448743222304

Epoch: 6| Step: 6
Training loss: 2.3447369341321007
Validation loss: 2.4913179162021133

Epoch: 6| Step: 7
Training loss: 2.218713679486501
Validation loss: 2.4792070038236065

Epoch: 6| Step: 8
Training loss: 3.14402093952185
Validation loss: 2.4936400737451865

Epoch: 6| Step: 9
Training loss: 2.1150961819325578
Validation loss: 2.4943987564182915

Epoch: 6| Step: 10
Training loss: 2.7992350248587115
Validation loss: 2.4935911684118306

Epoch: 6| Step: 11
Training loss: 2.691761718662135
Validation loss: 2.50294642071359

Epoch: 6| Step: 12
Training loss: 2.379306903543038
Validation loss: 2.5106703338569254

Epoch: 6| Step: 13
Training loss: 2.217525305361685
Validation loss: 2.4934083425701785

Epoch: 190| Step: 0
Training loss: 2.09656403875131
Validation loss: 2.5012297307911653

Epoch: 6| Step: 1
Training loss: 1.9374027227776986
Validation loss: 2.5041997284275

Epoch: 6| Step: 2
Training loss: 2.2766236725746087
Validation loss: 2.505837301393426

Epoch: 6| Step: 3
Training loss: 2.225390959263074
Validation loss: 2.5086946688691

Epoch: 6| Step: 4
Training loss: 2.4279247893636238
Validation loss: 2.5018447745310635

Epoch: 6| Step: 5
Training loss: 2.456778557281181
Validation loss: 2.496261837771559

Epoch: 6| Step: 6
Training loss: 2.8422404883563854
Validation loss: 2.4835202808119083

Epoch: 6| Step: 7
Training loss: 3.034358996300968
Validation loss: 2.4984516276202076

Epoch: 6| Step: 8
Training loss: 1.980906722116588
Validation loss: 2.49421394258306

Epoch: 6| Step: 9
Training loss: 2.3906433503687055
Validation loss: 2.4985772534938437

Epoch: 6| Step: 10
Training loss: 1.9616232353119378
Validation loss: 2.4983597778929467

Epoch: 6| Step: 11
Training loss: 2.654373134165971
Validation loss: 2.498086196792746

Epoch: 6| Step: 12
Training loss: 2.3798597708030034
Validation loss: 2.503050929325726

Epoch: 6| Step: 13
Training loss: 2.5334940252871667
Validation loss: 2.5232803720974326

Epoch: 191| Step: 0
Training loss: 1.9089989774210665
Validation loss: 2.5168447439924755

Epoch: 6| Step: 1
Training loss: 2.632964630712314
Validation loss: 2.5192292103862437

Epoch: 6| Step: 2
Training loss: 1.9271311642321243
Validation loss: 2.5191742400134296

Epoch: 6| Step: 3
Training loss: 2.628608221927948
Validation loss: 2.5115299579074817

Epoch: 6| Step: 4
Training loss: 1.971299110628124
Validation loss: 2.518097533158823

Epoch: 6| Step: 5
Training loss: 2.322032252617531
Validation loss: 2.5150925129988906

Epoch: 6| Step: 6
Training loss: 2.2073395370277935
Validation loss: 2.517001863182125

Epoch: 6| Step: 7
Training loss: 2.692190999866232
Validation loss: 2.524630726039262

Epoch: 6| Step: 8
Training loss: 2.303501250591067
Validation loss: 2.5115769792713474

Epoch: 6| Step: 9
Training loss: 2.3158711785180803
Validation loss: 2.5020741838663243

Epoch: 6| Step: 10
Training loss: 2.2416875727173795
Validation loss: 2.509842111730707

Epoch: 6| Step: 11
Training loss: 2.1892441472037043
Validation loss: 2.5081336904096836

Epoch: 6| Step: 12
Training loss: 2.5654822882526185
Validation loss: 2.500018572738323

Epoch: 6| Step: 13
Training loss: 3.176507733009421
Validation loss: 2.498764750170113

Epoch: 192| Step: 0
Training loss: 3.3592708127920794
Validation loss: 2.4994110605815494

Epoch: 6| Step: 1
Training loss: 2.4380044659643287
Validation loss: 2.507620236641321

Epoch: 6| Step: 2
Training loss: 1.723187768987675
Validation loss: 2.5076394501713084

Epoch: 6| Step: 3
Training loss: 2.3940596497258193
Validation loss: 2.5208409889882595

Epoch: 6| Step: 4
Training loss: 2.094678302911449
Validation loss: 2.5082678297325396

Epoch: 6| Step: 5
Training loss: 2.6268412172667004
Validation loss: 2.535250426405954

Epoch: 6| Step: 6
Training loss: 2.3968663738945986
Validation loss: 2.5175822918652484

Epoch: 6| Step: 7
Training loss: 1.9630592084011314
Validation loss: 2.5387206644641966

Epoch: 6| Step: 8
Training loss: 2.696612854347184
Validation loss: 2.5133166414139994

Epoch: 6| Step: 9
Training loss: 2.5539823252963254
Validation loss: 2.531476626827808

Epoch: 6| Step: 10
Training loss: 2.0423549218638692
Validation loss: 2.5401740277238773

Epoch: 6| Step: 11
Training loss: 2.1159775996545878
Validation loss: 2.513014677102779

Epoch: 6| Step: 12
Training loss: 2.44326442957889
Validation loss: 2.508065215912153

Epoch: 6| Step: 13
Training loss: 1.808125907088104
Validation loss: 2.522335555932839

Epoch: 193| Step: 0
Training loss: 2.645946670467677
Validation loss: 2.513050080493195

Epoch: 6| Step: 1
Training loss: 2.371155287118472
Validation loss: 2.51840601197886

Epoch: 6| Step: 2
Training loss: 2.2772604140251795
Validation loss: 2.531408964275381

Epoch: 6| Step: 3
Training loss: 1.8467877465822957
Validation loss: 2.5256665033135075

Epoch: 6| Step: 4
Training loss: 1.4441444419622602
Validation loss: 2.51503471099026

Epoch: 6| Step: 5
Training loss: 1.6268622658077665
Validation loss: 2.515282522705291

Epoch: 6| Step: 6
Training loss: 3.093126638785495
Validation loss: 2.5112865623950573

Epoch: 6| Step: 7
Training loss: 2.1462549949592318
Validation loss: 2.5141963969710712

Epoch: 6| Step: 8
Training loss: 2.424146411540557
Validation loss: 2.529258289803819

Epoch: 6| Step: 9
Training loss: 2.259624242687188
Validation loss: 2.5033004908771406

Epoch: 6| Step: 10
Training loss: 3.0495588952947905
Validation loss: 2.513170391369498

Epoch: 6| Step: 11
Training loss: 2.136940897494253
Validation loss: 2.4963512019243206

Epoch: 6| Step: 12
Training loss: 2.965655189416775
Validation loss: 2.4956813863652467

Epoch: 6| Step: 13
Training loss: 2.273809029021075
Validation loss: 2.506816979358745

Epoch: 194| Step: 0
Training loss: 1.9900990029249477
Validation loss: 2.4976274994822267

Epoch: 6| Step: 1
Training loss: 2.2046540277374684
Validation loss: 2.504478686713616

Epoch: 6| Step: 2
Training loss: 2.445493453767946
Validation loss: 2.5059617483229104

Epoch: 6| Step: 3
Training loss: 2.6639413218751726
Validation loss: 2.4965633613221088

Epoch: 6| Step: 4
Training loss: 2.0141274263439195
Validation loss: 2.509119384528758

Epoch: 6| Step: 5
Training loss: 1.9166599632919958
Validation loss: 2.5264616522069003

Epoch: 6| Step: 6
Training loss: 2.432201593488835
Validation loss: 2.5192357405029036

Epoch: 6| Step: 7
Training loss: 2.443451584647196
Validation loss: 2.5121151150124907

Epoch: 6| Step: 8
Training loss: 2.6944316806906015
Validation loss: 2.514340532828198

Epoch: 6| Step: 9
Training loss: 1.9388185137036937
Validation loss: 2.5214818220177335

Epoch: 6| Step: 10
Training loss: 2.770447916937156
Validation loss: 2.518085145563129

Epoch: 6| Step: 11
Training loss: 2.3948410854298645
Validation loss: 2.511929113142612

Epoch: 6| Step: 12
Training loss: 2.4772311009082557
Validation loss: 2.5118395043154442

Epoch: 6| Step: 13
Training loss: 2.762598655630652
Validation loss: 2.5113082241753824

Epoch: 195| Step: 0
Training loss: 2.618203219412987
Validation loss: 2.531713655180979

Epoch: 6| Step: 1
Training loss: 2.095559661875145
Validation loss: 2.5064934958675344

Epoch: 6| Step: 2
Training loss: 3.258691316990038
Validation loss: 2.529026868393134

Epoch: 6| Step: 3
Training loss: 2.5635228790458653
Validation loss: 2.52917569728121

Epoch: 6| Step: 4
Training loss: 1.966092571690805
Validation loss: 2.518018985302015

Epoch: 6| Step: 5
Training loss: 2.255017302588418
Validation loss: 2.5376809924741957

Epoch: 6| Step: 6
Training loss: 2.2047917980069216
Validation loss: 2.5286158917766346

Epoch: 6| Step: 7
Training loss: 2.340321181662338
Validation loss: 2.537232867557022

Epoch: 6| Step: 8
Training loss: 1.9275789053236652
Validation loss: 2.554470165780081

Epoch: 6| Step: 9
Training loss: 2.6361300341033367
Validation loss: 2.575406184150195

Epoch: 6| Step: 10
Training loss: 1.8286944423535805
Validation loss: 2.5722116490259594

Epoch: 6| Step: 11
Training loss: 2.8819769085098654
Validation loss: 2.568274620601339

Epoch: 6| Step: 12
Training loss: 2.2940466457703015
Validation loss: 2.5510388371327415

Epoch: 6| Step: 13
Training loss: 2.434171702915072
Validation loss: 2.5262814804499025

Epoch: 196| Step: 0
Training loss: 2.1243819291578943
Validation loss: 2.4918266202518

Epoch: 6| Step: 1
Training loss: 2.4961693980614297
Validation loss: 2.4937982725030117

Epoch: 6| Step: 2
Training loss: 2.7541732334014433
Validation loss: 2.492866686647738

Epoch: 6| Step: 3
Training loss: 2.365577578352763
Validation loss: 2.506042632341866

Epoch: 6| Step: 4
Training loss: 2.1399918336801598
Validation loss: 2.4934659367461833

Epoch: 6| Step: 5
Training loss: 1.9695362156068092
Validation loss: 2.497312372673994

Epoch: 6| Step: 6
Training loss: 3.1311770615296437
Validation loss: 2.49607849912407

Epoch: 6| Step: 7
Training loss: 2.5028952999186234
Validation loss: 2.4946170392702753

Epoch: 6| Step: 8
Training loss: 3.0191471699453576
Validation loss: 2.4962996913782223

Epoch: 6| Step: 9
Training loss: 2.095001529884235
Validation loss: 2.506284032068969

Epoch: 6| Step: 10
Training loss: 1.779970211251271
Validation loss: 2.5196092854719283

Epoch: 6| Step: 11
Training loss: 2.5453659923124135
Validation loss: 2.5086100608369075

Epoch: 6| Step: 12
Training loss: 1.819273164887622
Validation loss: 2.523676731985236

Epoch: 6| Step: 13
Training loss: 2.541116581992327
Validation loss: 2.5006588862318515

Epoch: 197| Step: 0
Training loss: 2.3375876221579093
Validation loss: 2.481668065209269

Epoch: 6| Step: 1
Training loss: 1.6880427300165763
Validation loss: 2.4937010646343323

Epoch: 6| Step: 2
Training loss: 2.014763108141374
Validation loss: 2.486263509042082

Epoch: 6| Step: 3
Training loss: 2.7106769887324553
Validation loss: 2.4950575451276333

Epoch: 6| Step: 4
Training loss: 1.983261036022645
Validation loss: 2.500930374594856

Epoch: 6| Step: 5
Training loss: 2.6025773551943674
Validation loss: 2.5038674957085236

Epoch: 6| Step: 6
Training loss: 2.5325584326552533
Validation loss: 2.50381400523123

Epoch: 6| Step: 7
Training loss: 2.3318020246298508
Validation loss: 2.5080571436565107

Epoch: 6| Step: 8
Training loss: 2.6345721513819664
Validation loss: 2.5046328374649267

Epoch: 6| Step: 9
Training loss: 2.6408173981949474
Validation loss: 2.5037619578443686

Epoch: 6| Step: 10
Training loss: 2.8077173046008266
Validation loss: 2.5086427465022085

Epoch: 6| Step: 11
Training loss: 2.3298524937578513
Validation loss: 2.5204298679104675

Epoch: 6| Step: 12
Training loss: 1.8874039758168035
Validation loss: 2.51448377545434

Epoch: 6| Step: 13
Training loss: 2.5381640913563643
Validation loss: 2.5252658766961913

Epoch: 198| Step: 0
Training loss: 2.7412631223880264
Validation loss: 2.533104488008335

Epoch: 6| Step: 1
Training loss: 1.459699299821178
Validation loss: 2.5535489810816956

Epoch: 6| Step: 2
Training loss: 2.2728628369561714
Validation loss: 2.5594632212331425

Epoch: 6| Step: 3
Training loss: 2.6733227649996696
Validation loss: 2.5855027954198584

Epoch: 6| Step: 4
Training loss: 2.473329569907123
Validation loss: 2.596543213680891

Epoch: 6| Step: 5
Training loss: 2.0981228840407904
Validation loss: 2.5678319585312894

Epoch: 6| Step: 6
Training loss: 2.073381675307922
Validation loss: 2.5546136314608385

Epoch: 6| Step: 7
Training loss: 2.806679021244841
Validation loss: 2.537993987784493

Epoch: 6| Step: 8
Training loss: 2.673247938274665
Validation loss: 2.5314545411407052

Epoch: 6| Step: 9
Training loss: 2.135734596465705
Validation loss: 2.5184370794665516

Epoch: 6| Step: 10
Training loss: 2.8737534847628323
Validation loss: 2.507245864312461

Epoch: 6| Step: 11
Training loss: 2.354936884461527
Validation loss: 2.487795077127419

Epoch: 6| Step: 12
Training loss: 2.428832464855076
Validation loss: 2.4872229544834226

Epoch: 6| Step: 13
Training loss: 2.130352459969648
Validation loss: 2.4809286337032277

Epoch: 199| Step: 0
Training loss: 2.979078135920069
Validation loss: 2.4864663971886176

Epoch: 6| Step: 1
Training loss: 2.4684072328984814
Validation loss: 2.4942893290369974

Epoch: 6| Step: 2
Training loss: 2.4186439865497147
Validation loss: 2.4932338865697803

Epoch: 6| Step: 3
Training loss: 2.68706207255938
Validation loss: 2.5005892694906886

Epoch: 6| Step: 4
Training loss: 2.8058970613855023
Validation loss: 2.4936696810045276

Epoch: 6| Step: 5
Training loss: 2.217510898223554
Validation loss: 2.492969593512985

Epoch: 6| Step: 6
Training loss: 2.174791751406857
Validation loss: 2.4840882653686056

Epoch: 6| Step: 7
Training loss: 2.741191628839638
Validation loss: 2.486151342107891

Epoch: 6| Step: 8
Training loss: 2.4672344722709494
Validation loss: 2.4874709889622744

Epoch: 6| Step: 9
Training loss: 2.008601171063632
Validation loss: 2.483946389387123

Epoch: 6| Step: 10
Training loss: 2.1185521306278936
Validation loss: 2.4870798673098067

Epoch: 6| Step: 11
Training loss: 2.729570014403641
Validation loss: 2.4875338163904743

Epoch: 6| Step: 12
Training loss: 1.6126629473540957
Validation loss: 2.488890393172483

Epoch: 6| Step: 13
Training loss: 2.101704078641826
Validation loss: 2.4966355891345593

Epoch: 200| Step: 0
Training loss: 2.6028500598364244
Validation loss: 2.4884004429605713

Epoch: 6| Step: 1
Training loss: 2.547633613923367
Validation loss: 2.5049083210202143

Epoch: 6| Step: 2
Training loss: 2.4004985887475248
Validation loss: 2.514754687783645

Epoch: 6| Step: 3
Training loss: 2.0852840700273814
Validation loss: 2.5175478913450204

Epoch: 6| Step: 4
Training loss: 2.335130226702395
Validation loss: 2.5374034606408866

Epoch: 6| Step: 5
Training loss: 1.8441056377289338
Validation loss: 2.5468986837771985

Epoch: 6| Step: 6
Training loss: 2.0769613349412213
Validation loss: 2.5390379136680217

Epoch: 6| Step: 7
Training loss: 2.7628792101164326
Validation loss: 2.520160393441974

Epoch: 6| Step: 8
Training loss: 2.3695297487721403
Validation loss: 2.5069682917659732

Epoch: 6| Step: 9
Training loss: 2.903318341636566
Validation loss: 2.495848546647804

Epoch: 6| Step: 10
Training loss: 2.3417093166752596
Validation loss: 2.502070745541822

Epoch: 6| Step: 11
Training loss: 2.4834143742729893
Validation loss: 2.494745040383515

Epoch: 6| Step: 12
Training loss: 2.220335702687635
Validation loss: 2.488474600329852

Epoch: 6| Step: 13
Training loss: 2.3826400944609043
Validation loss: 2.484954646404722

Epoch: 201| Step: 0
Training loss: 1.696892349407379
Validation loss: 2.5013218405143682

Epoch: 6| Step: 1
Training loss: 2.551296958958429
Validation loss: 2.4967135444419895

Epoch: 6| Step: 2
Training loss: 2.7710907799764266
Validation loss: 2.4987901462206965

Epoch: 6| Step: 3
Training loss: 2.4674963363419287
Validation loss: 2.507890630754745

Epoch: 6| Step: 4
Training loss: 3.062801112728009
Validation loss: 2.4958499954593

Epoch: 6| Step: 5
Training loss: 2.8320452249116403
Validation loss: 2.4928269158955096

Epoch: 6| Step: 6
Training loss: 2.499665714802781
Validation loss: 2.492849837953616

Epoch: 6| Step: 7
Training loss: 2.128536871266577
Validation loss: 2.5084572316828053

Epoch: 6| Step: 8
Training loss: 2.317948495373305
Validation loss: 2.5072874824880995

Epoch: 6| Step: 9
Training loss: 2.5455711163110375
Validation loss: 2.512580782981817

Epoch: 6| Step: 10
Training loss: 1.8281427366260314
Validation loss: 2.513194795954994

Epoch: 6| Step: 11
Training loss: 1.6926026374878382
Validation loss: 2.5280106306828336

Epoch: 6| Step: 12
Training loss: 2.0220748260191224
Validation loss: 2.5302835197056464

Epoch: 6| Step: 13
Training loss: 2.5445234992541996
Validation loss: 2.5558490193070873

Epoch: 202| Step: 0
Training loss: 2.213058478781203
Validation loss: 2.5530778128015412

Epoch: 6| Step: 1
Training loss: 1.9647993382313014
Validation loss: 2.5551671191340293

Epoch: 6| Step: 2
Training loss: 2.696342470496039
Validation loss: 2.5433843520144053

Epoch: 6| Step: 3
Training loss: 2.5418269205904402
Validation loss: 2.521047414931727

Epoch: 6| Step: 4
Training loss: 2.439810415938635
Validation loss: 2.4985328024730786

Epoch: 6| Step: 5
Training loss: 2.543536660435811
Validation loss: 2.488399772276605

Epoch: 6| Step: 6
Training loss: 2.189666111546167
Validation loss: 2.5053957091198837

Epoch: 6| Step: 7
Training loss: 1.9418062531009392
Validation loss: 2.508303490225688

Epoch: 6| Step: 8
Training loss: 2.12218400955194
Validation loss: 2.5087080611173396

Epoch: 6| Step: 9
Training loss: 2.2415406892492626
Validation loss: 2.513146713872653

Epoch: 6| Step: 10
Training loss: 2.7867842914390986
Validation loss: 2.5024218431654015

Epoch: 6| Step: 11
Training loss: 2.183364009884335
Validation loss: 2.505375154033853

Epoch: 6| Step: 12
Training loss: 2.6967205405620285
Validation loss: 2.5018352765676415

Epoch: 6| Step: 13
Training loss: 2.5439912348902154
Validation loss: 2.4898711853462854

Epoch: 203| Step: 0
Training loss: 2.1644561079108326
Validation loss: 2.4945783796038765

Epoch: 6| Step: 1
Training loss: 2.5913262130342445
Validation loss: 2.492587018651001

Epoch: 6| Step: 2
Training loss: 2.5619485773528883
Validation loss: 2.494959852778583

Epoch: 6| Step: 3
Training loss: 2.285995042536876
Validation loss: 2.492795832100315

Epoch: 6| Step: 4
Training loss: 2.103620691252298
Validation loss: 2.496847628879876

Epoch: 6| Step: 5
Training loss: 2.488944691314397
Validation loss: 2.5019127045661143

Epoch: 6| Step: 6
Training loss: 2.0209318576142334
Validation loss: 2.505666382935453

Epoch: 6| Step: 7
Training loss: 2.284861384221148
Validation loss: 2.5015636957957175

Epoch: 6| Step: 8
Training loss: 2.021547591100921
Validation loss: 2.497165949122254

Epoch: 6| Step: 9
Training loss: 2.5837535106264133
Validation loss: 2.507710091311196

Epoch: 6| Step: 10
Training loss: 2.0894344891686814
Validation loss: 2.5023493059779276

Epoch: 6| Step: 11
Training loss: 2.302034564530147
Validation loss: 2.496860376473558

Epoch: 6| Step: 12
Training loss: 2.567923783760745
Validation loss: 2.503883397419116

Epoch: 6| Step: 13
Training loss: 2.891273219654012
Validation loss: 2.527221205038363

Epoch: 204| Step: 0
Training loss: 2.2369284810965717
Validation loss: 2.554933308665993

Epoch: 6| Step: 1
Training loss: 2.1992608129025863
Validation loss: 2.5401024825780367

Epoch: 6| Step: 2
Training loss: 2.517671404309813
Validation loss: 2.563364410369092

Epoch: 6| Step: 3
Training loss: 2.1487366624099766
Validation loss: 2.5457087149662825

Epoch: 6| Step: 4
Training loss: 2.0949791104679587
Validation loss: 2.5572618118894943

Epoch: 6| Step: 5
Training loss: 2.1163956966819986
Validation loss: 2.54913730426932

Epoch: 6| Step: 6
Training loss: 2.7114833315267157
Validation loss: 2.5292250771562292

Epoch: 6| Step: 7
Training loss: 2.648076305684475
Validation loss: 2.5171850828399513

Epoch: 6| Step: 8
Training loss: 2.713059180497603
Validation loss: 2.513911309209595

Epoch: 6| Step: 9
Training loss: 2.7247658305213602
Validation loss: 2.507868939454872

Epoch: 6| Step: 10
Training loss: 1.6619002931297682
Validation loss: 2.509222408736769

Epoch: 6| Step: 11
Training loss: 2.932187572594302
Validation loss: 2.5081841341004822

Epoch: 6| Step: 12
Training loss: 1.9710120874786172
Validation loss: 2.5011663100517167

Epoch: 6| Step: 13
Training loss: 2.0302648649635637
Validation loss: 2.478634149329204

Epoch: 205| Step: 0
Training loss: 2.7603421375122124
Validation loss: 2.4988236361720646

Epoch: 6| Step: 1
Training loss: 1.768573695585663
Validation loss: 2.490346342075367

Epoch: 6| Step: 2
Training loss: 2.6744906466397715
Validation loss: 2.491432928734173

Epoch: 6| Step: 3
Training loss: 2.0413931319541203
Validation loss: 2.486140713317162

Epoch: 6| Step: 4
Training loss: 1.9867703255976557
Validation loss: 2.5021587826303024

Epoch: 6| Step: 5
Training loss: 2.7506290063219945
Validation loss: 2.4987733374671954

Epoch: 6| Step: 6
Training loss: 1.9035946847399374
Validation loss: 2.506811843516533

Epoch: 6| Step: 7
Training loss: 2.5981229205165652
Validation loss: 2.4936139400272026

Epoch: 6| Step: 8
Training loss: 2.3762320284336926
Validation loss: 2.5048644106698985

Epoch: 6| Step: 9
Training loss: 2.371515830366561
Validation loss: 2.5114971515994533

Epoch: 6| Step: 10
Training loss: 2.225314891692297
Validation loss: 2.5326634687365193

Epoch: 6| Step: 11
Training loss: 2.146610773476453
Validation loss: 2.523439428999944

Epoch: 6| Step: 12
Training loss: 2.4583843247464747
Validation loss: 2.5540823107838344

Epoch: 6| Step: 13
Training loss: 2.550223366921299
Validation loss: 2.5577211012965266

Epoch: 206| Step: 0
Training loss: 2.23408132904011
Validation loss: 2.5604082269325144

Epoch: 6| Step: 1
Training loss: 2.681107392331133
Validation loss: 2.5545564359278528

Epoch: 6| Step: 2
Training loss: 2.4317182781275646
Validation loss: 2.5576646122389946

Epoch: 6| Step: 3
Training loss: 2.801903152817919
Validation loss: 2.5356403940667676

Epoch: 6| Step: 4
Training loss: 1.9277515043446476
Validation loss: 2.519240748491531

Epoch: 6| Step: 5
Training loss: 2.998759649085501
Validation loss: 2.517409582146424

Epoch: 6| Step: 6
Training loss: 1.495693382297206
Validation loss: 2.5048352847383493

Epoch: 6| Step: 7
Training loss: 2.0256354571163473
Validation loss: 2.49754484737786

Epoch: 6| Step: 8
Training loss: 2.5495857837322555
Validation loss: 2.5136957609577624

Epoch: 6| Step: 9
Training loss: 2.4128582861303216
Validation loss: 2.507080937970271

Epoch: 6| Step: 10
Training loss: 1.9735156915899559
Validation loss: 2.50430386739201

Epoch: 6| Step: 11
Training loss: 1.9686660748713494
Validation loss: 2.4965927906676195

Epoch: 6| Step: 12
Training loss: 2.813523932670247
Validation loss: 2.504345177451545

Epoch: 6| Step: 13
Training loss: 2.417045848520482
Validation loss: 2.5061349457090545

Epoch: 207| Step: 0
Training loss: 2.334348616648827
Validation loss: 2.5128151185163947

Epoch: 6| Step: 1
Training loss: 2.997856646041442
Validation loss: 2.5070401722626516

Epoch: 6| Step: 2
Training loss: 1.832666803343097
Validation loss: 2.521773018679571

Epoch: 6| Step: 3
Training loss: 2.2286766321726077
Validation loss: 2.5289733129893035

Epoch: 6| Step: 4
Training loss: 2.175526136581049
Validation loss: 2.5053988494653994

Epoch: 6| Step: 5
Training loss: 2.491409515158618
Validation loss: 2.5212434219680535

Epoch: 6| Step: 6
Training loss: 2.3346173182373007
Validation loss: 2.5269877336810964

Epoch: 6| Step: 7
Training loss: 2.2384966202421324
Validation loss: 2.5181211956642735

Epoch: 6| Step: 8
Training loss: 2.6023926656174643
Validation loss: 2.527239239677485

Epoch: 6| Step: 9
Training loss: 2.641515999076376
Validation loss: 2.4944586216307285

Epoch: 6| Step: 10
Training loss: 1.5963379287101305
Validation loss: 2.489744561586359

Epoch: 6| Step: 11
Training loss: 3.0258571198611564
Validation loss: 2.484928973031657

Epoch: 6| Step: 12
Training loss: 2.1259683758670467
Validation loss: 2.4988471074943934

Epoch: 6| Step: 13
Training loss: 1.8179058488653215
Validation loss: 2.5059418480121787

Epoch: 208| Step: 0
Training loss: 2.102926952905543
Validation loss: 2.498891552924208

Epoch: 6| Step: 1
Training loss: 1.92743684430193
Validation loss: 2.510070370628683

Epoch: 6| Step: 2
Training loss: 2.4677473518976476
Validation loss: 2.521023614390749

Epoch: 6| Step: 3
Training loss: 2.334042191687135
Validation loss: 2.532245440252739

Epoch: 6| Step: 4
Training loss: 2.179992873153936
Validation loss: 2.520732788308654

Epoch: 6| Step: 5
Training loss: 1.9081376532076681
Validation loss: 2.5320161515534814

Epoch: 6| Step: 6
Training loss: 2.6448389322315093
Validation loss: 2.550627722800647

Epoch: 6| Step: 7
Training loss: 1.6230552480323284
Validation loss: 2.547021233664724

Epoch: 6| Step: 8
Training loss: 2.488248480516658
Validation loss: 2.545624720573956

Epoch: 6| Step: 9
Training loss: 2.404737913955376
Validation loss: 2.5371030475086287

Epoch: 6| Step: 10
Training loss: 2.5734208162620433
Validation loss: 2.519952743720447

Epoch: 6| Step: 11
Training loss: 2.4677558539020374
Validation loss: 2.5059526623839106

Epoch: 6| Step: 12
Training loss: 2.7195808631866663
Validation loss: 2.505410633656149

Epoch: 6| Step: 13
Training loss: 2.760787612654675
Validation loss: 2.504178655746966

Epoch: 209| Step: 0
Training loss: 2.364909167813698
Validation loss: 2.4976909941689955

Epoch: 6| Step: 1
Training loss: 2.1204762271195245
Validation loss: 2.5170505741384885

Epoch: 6| Step: 2
Training loss: 2.655759698832312
Validation loss: 2.508689338876967

Epoch: 6| Step: 3
Training loss: 1.8454106497765188
Validation loss: 2.5241430849182995

Epoch: 6| Step: 4
Training loss: 2.2755570117545103
Validation loss: 2.518505145745937

Epoch: 6| Step: 5
Training loss: 1.7778470510986653
Validation loss: 2.5580191940221795

Epoch: 6| Step: 6
Training loss: 2.631479350263235
Validation loss: 2.56064279445964

Epoch: 6| Step: 7
Training loss: 2.9370983742022005
Validation loss: 2.5990024682669657

Epoch: 6| Step: 8
Training loss: 2.6957439574844577
Validation loss: 2.5811199632699857

Epoch: 6| Step: 9
Training loss: 1.833380619075053
Validation loss: 2.5536516055039873

Epoch: 6| Step: 10
Training loss: 2.3461106682420505
Validation loss: 2.5628802939967787

Epoch: 6| Step: 11
Training loss: 2.5332929114412908
Validation loss: 2.5291968130695826

Epoch: 6| Step: 12
Training loss: 2.295691983486555
Validation loss: 2.532567344691458

Epoch: 6| Step: 13
Training loss: 2.5109782454787575
Validation loss: 2.5293914188109445

Epoch: 210| Step: 0
Training loss: 1.7191400258817975
Validation loss: 2.5226562125106655

Epoch: 6| Step: 1
Training loss: 1.8283432398237627
Validation loss: 2.5156902044150513

Epoch: 6| Step: 2
Training loss: 2.4017754107318594
Validation loss: 2.507645820315353

Epoch: 6| Step: 3
Training loss: 2.3108725104694883
Validation loss: 2.510075895572891

Epoch: 6| Step: 4
Training loss: 2.4639782723670227
Validation loss: 2.513198456227101

Epoch: 6| Step: 5
Training loss: 2.3315859677808555
Validation loss: 2.5250788528417574

Epoch: 6| Step: 6
Training loss: 2.3573854660092315
Validation loss: 2.5315711363230053

Epoch: 6| Step: 7
Training loss: 1.888454610168523
Validation loss: 2.5181030168202603

Epoch: 6| Step: 8
Training loss: 2.5293781282194914
Validation loss: 2.5223488521250603

Epoch: 6| Step: 9
Training loss: 2.5827523060065456
Validation loss: 2.5253995465964074

Epoch: 6| Step: 10
Training loss: 2.6448213539295353
Validation loss: 2.52770900690991

Epoch: 6| Step: 11
Training loss: 2.5497310047760546
Validation loss: 2.521362396291945

Epoch: 6| Step: 12
Training loss: 2.46010127316559
Validation loss: 2.539690927839808

Epoch: 6| Step: 13
Training loss: 2.428777002801945
Validation loss: 2.5214393034515816

Epoch: 211| Step: 0
Training loss: 2.2404423212256033
Validation loss: 2.5310368153785707

Epoch: 6| Step: 1
Training loss: 2.218983060389633
Validation loss: 2.5391145358499987

Epoch: 6| Step: 2
Training loss: 2.45168140480423
Validation loss: 2.5474054529141936

Epoch: 6| Step: 3
Training loss: 2.208475528193684
Validation loss: 2.52996881659267

Epoch: 6| Step: 4
Training loss: 2.711808825914335
Validation loss: 2.5435910418157976

Epoch: 6| Step: 5
Training loss: 1.7168013189646694
Validation loss: 2.52420756554888

Epoch: 6| Step: 6
Training loss: 2.473018384693141
Validation loss: 2.532430805090719

Epoch: 6| Step: 7
Training loss: 1.9717769060355923
Validation loss: 2.50917069524642

Epoch: 6| Step: 8
Training loss: 2.479819673934856
Validation loss: 2.514431466923985

Epoch: 6| Step: 9
Training loss: 2.474932112870547
Validation loss: 2.5082618493025497

Epoch: 6| Step: 10
Training loss: 2.3090372708411495
Validation loss: 2.51747210436976

Epoch: 6| Step: 11
Training loss: 2.82334951950832
Validation loss: 2.498308642772017

Epoch: 6| Step: 12
Training loss: 2.412008751380442
Validation loss: 2.5001932069507187

Epoch: 6| Step: 13
Training loss: 1.9633603269451692
Validation loss: 2.5002801738146867

Epoch: 212| Step: 0
Training loss: 1.894600212179144
Validation loss: 2.5097971794232743

Epoch: 6| Step: 1
Training loss: 2.4512088362502147
Validation loss: 2.5070720621339273

Epoch: 6| Step: 2
Training loss: 2.4731564369931838
Validation loss: 2.510148684390021

Epoch: 6| Step: 3
Training loss: 2.7330416671083504
Validation loss: 2.5235326097514257

Epoch: 6| Step: 4
Training loss: 2.9436376853947186
Validation loss: 2.5489917532087922

Epoch: 6| Step: 5
Training loss: 2.436040196630509
Validation loss: 2.5502556205233597

Epoch: 6| Step: 6
Training loss: 2.1495329682296913
Validation loss: 2.5636216631801334

Epoch: 6| Step: 7
Training loss: 2.259850766647725
Validation loss: 2.5647048768516583

Epoch: 6| Step: 8
Training loss: 2.9120119463602188
Validation loss: 2.5478007344539186

Epoch: 6| Step: 9
Training loss: 1.487504170516122
Validation loss: 2.5388175024527655

Epoch: 6| Step: 10
Training loss: 2.1594043823539724
Validation loss: 2.501678904410903

Epoch: 6| Step: 11
Training loss: 2.6670499367260136
Validation loss: 2.505435811670712

Epoch: 6| Step: 12
Training loss: 1.8594753975570295
Validation loss: 2.511191431897111

Epoch: 6| Step: 13
Training loss: 2.0363881781186026
Validation loss: 2.4967088891556055

Epoch: 213| Step: 0
Training loss: 1.5167633186536496
Validation loss: 2.492471246301618

Epoch: 6| Step: 1
Training loss: 2.6516490807500577
Validation loss: 2.5072575922764933

Epoch: 6| Step: 2
Training loss: 2.6327072711143598
Validation loss: 2.4915741232417448

Epoch: 6| Step: 3
Training loss: 2.1685409752983342
Validation loss: 2.478212627129989

Epoch: 6| Step: 4
Training loss: 2.1656040251185393
Validation loss: 2.502827452120662

Epoch: 6| Step: 5
Training loss: 2.1533087974465355
Validation loss: 2.5223425506208965

Epoch: 6| Step: 6
Training loss: 2.8243084862937216
Validation loss: 2.5459981239623586

Epoch: 6| Step: 7
Training loss: 2.519518569796096
Validation loss: 2.519984020782954

Epoch: 6| Step: 8
Training loss: 2.2092246170338363
Validation loss: 2.5466459986545393

Epoch: 6| Step: 9
Training loss: 2.745467178251357
Validation loss: 2.559286909873603

Epoch: 6| Step: 10
Training loss: 1.8114706602402857
Validation loss: 2.5340489583483334

Epoch: 6| Step: 11
Training loss: 2.3429623106702318
Validation loss: 2.5136030296890595

Epoch: 6| Step: 12
Training loss: 2.24207053062169
Validation loss: 2.536299171127779

Epoch: 6| Step: 13
Training loss: 2.4883019462934426
Validation loss: 2.5046140292333336

Epoch: 214| Step: 0
Training loss: 2.535634141265662
Validation loss: 2.521539909604194

Epoch: 6| Step: 1
Training loss: 2.7412215485076956
Validation loss: 2.5072781002331133

Epoch: 6| Step: 2
Training loss: 2.078500584671786
Validation loss: 2.5073726026601957

Epoch: 6| Step: 3
Training loss: 2.8385072105252966
Validation loss: 2.5122180321850767

Epoch: 6| Step: 4
Training loss: 2.346094815015472
Validation loss: 2.483561056585283

Epoch: 6| Step: 5
Training loss: 2.395478352218969
Validation loss: 2.500572393376159

Epoch: 6| Step: 6
Training loss: 2.477931946670514
Validation loss: 2.5002823431796957

Epoch: 6| Step: 7
Training loss: 2.2492524070646307
Validation loss: 2.4981235455599515

Epoch: 6| Step: 8
Training loss: 1.915309577599834
Validation loss: 2.5113031291642374

Epoch: 6| Step: 9
Training loss: 2.3948824999821396
Validation loss: 2.5041344152353

Epoch: 6| Step: 10
Training loss: 2.2276105589139807
Validation loss: 2.509460969040591

Epoch: 6| Step: 11
Training loss: 1.3919208789350535
Validation loss: 2.524557056226241

Epoch: 6| Step: 12
Training loss: 2.3288233176958584
Validation loss: 2.5369327318242374

Epoch: 6| Step: 13
Training loss: 2.379851155154649
Validation loss: 2.531994180428565

Epoch: 215| Step: 0
Training loss: 2.0414441694613124
Validation loss: 2.543624035639949

Epoch: 6| Step: 1
Training loss: 2.8614717727380707
Validation loss: 2.5333129890361175

Epoch: 6| Step: 2
Training loss: 2.2774531500108592
Validation loss: 2.544450866097903

Epoch: 6| Step: 3
Training loss: 2.439761457664744
Validation loss: 2.532473413705057

Epoch: 6| Step: 4
Training loss: 2.6468093954015535
Validation loss: 2.5232862460665904

Epoch: 6| Step: 5
Training loss: 2.054698755501788
Validation loss: 2.5079139379978836

Epoch: 6| Step: 6
Training loss: 1.8041561384826248
Validation loss: 2.5054032031197164

Epoch: 6| Step: 7
Training loss: 2.0541634126937915
Validation loss: 2.512758600392006

Epoch: 6| Step: 8
Training loss: 2.7462838813869057
Validation loss: 2.5070562440476842

Epoch: 6| Step: 9
Training loss: 2.3945901935037273
Validation loss: 2.507963514683189

Epoch: 6| Step: 10
Training loss: 2.7667246211159786
Validation loss: 2.5043666533358118

Epoch: 6| Step: 11
Training loss: 2.6288402260004107
Validation loss: 2.5149762598564225

Epoch: 6| Step: 12
Training loss: 1.8000171554595612
Validation loss: 2.514253941674247

Epoch: 6| Step: 13
Training loss: 1.8976824479475725
Validation loss: 2.523461750177757

Epoch: 216| Step: 0
Training loss: 2.3830688338685406
Validation loss: 2.529199617496964

Epoch: 6| Step: 1
Training loss: 1.6534784267322835
Validation loss: 2.518281517286784

Epoch: 6| Step: 2
Training loss: 1.706692380463088
Validation loss: 2.52919822706697

Epoch: 6| Step: 3
Training loss: 2.453245317946588
Validation loss: 2.536518923892838

Epoch: 6| Step: 4
Training loss: 2.172255338669507
Validation loss: 2.544941970148622

Epoch: 6| Step: 5
Training loss: 2.373302656289764
Validation loss: 2.5063078298896766

Epoch: 6| Step: 6
Training loss: 2.5564599843973603
Validation loss: 2.519711683648428

Epoch: 6| Step: 7
Training loss: 1.9457228507370965
Validation loss: 2.5255252952690985

Epoch: 6| Step: 8
Training loss: 2.926508203299121
Validation loss: 2.5269799970573077

Epoch: 6| Step: 9
Training loss: 2.2023897499782654
Validation loss: 2.526521245257484

Epoch: 6| Step: 10
Training loss: 2.4514794145342633
Validation loss: 2.541579062614537

Epoch: 6| Step: 11
Training loss: 2.805258945065651
Validation loss: 2.559891963010225

Epoch: 6| Step: 12
Training loss: 2.0225079732202547
Validation loss: 2.556932122360102

Epoch: 6| Step: 13
Training loss: 2.434800242351271
Validation loss: 2.537201012220947

Epoch: 217| Step: 0
Training loss: 2.5780813502460176
Validation loss: 2.5210015317011125

Epoch: 6| Step: 1
Training loss: 1.7249255122812408
Validation loss: 2.5350325935821583

Epoch: 6| Step: 2
Training loss: 2.683821533841752
Validation loss: 2.5279963111267056

Epoch: 6| Step: 3
Training loss: 2.7360553047268037
Validation loss: 2.5048866832125714

Epoch: 6| Step: 4
Training loss: 2.2840924256525477
Validation loss: 2.5209553954362245

Epoch: 6| Step: 5
Training loss: 1.9042822891068
Validation loss: 2.5172482578515165

Epoch: 6| Step: 6
Training loss: 2.240946781988767
Validation loss: 2.517654050831866

Epoch: 6| Step: 7
Training loss: 2.2554734729787427
Validation loss: 2.5044951715872776

Epoch: 6| Step: 8
Training loss: 2.320038133833978
Validation loss: 2.5138054500757385

Epoch: 6| Step: 9
Training loss: 2.1058643655889435
Validation loss: 2.5110125698411525

Epoch: 6| Step: 10
Training loss: 2.2142479581294787
Validation loss: 2.515133416774712

Epoch: 6| Step: 11
Training loss: 2.265642573847521
Validation loss: 2.5161427662022087

Epoch: 6| Step: 12
Training loss: 2.9737306274963218
Validation loss: 2.513211373861868

Epoch: 6| Step: 13
Training loss: 2.053631761505756
Validation loss: 2.5319376195984296

Epoch: 218| Step: 0
Training loss: 2.785368538105219
Validation loss: 2.531299119637583

Epoch: 6| Step: 1
Training loss: 1.2242048407606154
Validation loss: 2.5371084665987436

Epoch: 6| Step: 2
Training loss: 2.893327429218978
Validation loss: 2.536582040348432

Epoch: 6| Step: 3
Training loss: 2.2397547693211366
Validation loss: 2.5322204895770555

Epoch: 6| Step: 4
Training loss: 2.358406322774085
Validation loss: 2.530153107514848

Epoch: 6| Step: 5
Training loss: 2.6095570940451367
Validation loss: 2.5544309263653853

Epoch: 6| Step: 6
Training loss: 2.6096766862815377
Validation loss: 2.549334206647138

Epoch: 6| Step: 7
Training loss: 2.5329755388201503
Validation loss: 2.5500776285310662

Epoch: 6| Step: 8
Training loss: 1.884614137876688
Validation loss: 2.545620662049574

Epoch: 6| Step: 9
Training loss: 2.0856175552340463
Validation loss: 2.5197838314124343

Epoch: 6| Step: 10
Training loss: 1.9807070978061863
Validation loss: 2.5184494811093074

Epoch: 6| Step: 11
Training loss: 1.9462861837699796
Validation loss: 2.5240763041695113

Epoch: 6| Step: 12
Training loss: 2.6665159321939718
Validation loss: 2.515171491920326

Epoch: 6| Step: 13
Training loss: 2.113869971102817
Validation loss: 2.5103927284038563

Epoch: 219| Step: 0
Training loss: 2.62472641745373
Validation loss: 2.5097660049853796

Epoch: 6| Step: 1
Training loss: 2.328852392659714
Validation loss: 2.5125094247517863

Epoch: 6| Step: 2
Training loss: 2.5319305258646367
Validation loss: 2.508498988168011

Epoch: 6| Step: 3
Training loss: 2.1014493890549737
Validation loss: 2.523200119395829

Epoch: 6| Step: 4
Training loss: 2.0896151123470137
Validation loss: 2.517918490970432

Epoch: 6| Step: 5
Training loss: 2.347331654582804
Validation loss: 2.519972154940308

Epoch: 6| Step: 6
Training loss: 2.4949265498662068
Validation loss: 2.513890934399451

Epoch: 6| Step: 7
Training loss: 2.4827727903403867
Validation loss: 2.498765338559929

Epoch: 6| Step: 8
Training loss: 2.130964771325049
Validation loss: 2.4997192225140505

Epoch: 6| Step: 9
Training loss: 2.3495619872935913
Validation loss: 2.497394579004338

Epoch: 6| Step: 10
Training loss: 2.3509646444643706
Validation loss: 2.5064261338897236

Epoch: 6| Step: 11
Training loss: 2.531736727413337
Validation loss: 2.508983968288977

Epoch: 6| Step: 12
Training loss: 1.955012271774294
Validation loss: 2.4985525232382058

Epoch: 6| Step: 13
Training loss: 1.9207952924534866
Validation loss: 2.513941950147304

Epoch: 220| Step: 0
Training loss: 2.746517056523127
Validation loss: 2.5167032778100067

Epoch: 6| Step: 1
Training loss: 2.026492371886208
Validation loss: 2.536374787215171

Epoch: 6| Step: 2
Training loss: 2.6633647105533442
Validation loss: 2.531216719294781

Epoch: 6| Step: 3
Training loss: 2.0975696396662284
Validation loss: 2.560155881839586

Epoch: 6| Step: 4
Training loss: 2.7344839019887455
Validation loss: 2.5489852993225592

Epoch: 6| Step: 5
Training loss: 2.865579679207714
Validation loss: 2.518054507700057

Epoch: 6| Step: 6
Training loss: 1.7398623701451559
Validation loss: 2.5395960946475675

Epoch: 6| Step: 7
Training loss: 2.0311825080809536
Validation loss: 2.5162572125531906

Epoch: 6| Step: 8
Training loss: 1.8655981857443114
Validation loss: 2.5091716691897097

Epoch: 6| Step: 9
Training loss: 2.4013816829955954
Validation loss: 2.49355414218179

Epoch: 6| Step: 10
Training loss: 2.100946385712212
Validation loss: 2.4883937361127746

Epoch: 6| Step: 11
Training loss: 1.9694617059785442
Validation loss: 2.4911758857034636

Epoch: 6| Step: 12
Training loss: 1.5062139071497072
Validation loss: 2.495527431059317

Epoch: 6| Step: 13
Training loss: 3.141265651969001
Validation loss: 2.4985453029116163

Epoch: 221| Step: 0
Training loss: 2.4661136505594357
Validation loss: 2.5029431820358194

Epoch: 6| Step: 1
Training loss: 3.000246991480484
Validation loss: 2.513727187007792

Epoch: 6| Step: 2
Training loss: 2.374986146585316
Validation loss: 2.5347961734336515

Epoch: 6| Step: 3
Training loss: 2.332152090344358
Validation loss: 2.5321547064912915

Epoch: 6| Step: 4
Training loss: 1.6883231380690809
Validation loss: 2.5456642128003204

Epoch: 6| Step: 5
Training loss: 2.431528062781257
Validation loss: 2.5566409980184983

Epoch: 6| Step: 6
Training loss: 2.24585055154158
Validation loss: 2.5703707362788624

Epoch: 6| Step: 7
Training loss: 2.6520484456546725
Validation loss: 2.5842598566176886

Epoch: 6| Step: 8
Training loss: 2.130914982840239
Validation loss: 2.581416931789078

Epoch: 6| Step: 9
Training loss: 2.6639585055192616
Validation loss: 2.558425579416807

Epoch: 6| Step: 10
Training loss: 2.4624754928686126
Validation loss: 2.5772975480015603

Epoch: 6| Step: 11
Training loss: 2.1678137921465153
Validation loss: 2.5647883393453514

Epoch: 6| Step: 12
Training loss: 1.630697678642003
Validation loss: 2.563106728654299

Epoch: 6| Step: 13
Training loss: 1.6422713965155797
Validation loss: 2.524404932788939

Epoch: 222| Step: 0
Training loss: 1.9452617592685961
Validation loss: 2.513940978052102

Epoch: 6| Step: 1
Training loss: 2.5386423555633923
Validation loss: 2.5043206548922887

Epoch: 6| Step: 2
Training loss: 2.269021375835363
Validation loss: 2.4938711540092195

Epoch: 6| Step: 3
Training loss: 2.649897980075756
Validation loss: 2.509092921091089

Epoch: 6| Step: 4
Training loss: 2.6095080313207206
Validation loss: 2.5032372654675674

Epoch: 6| Step: 5
Training loss: 2.107793709775112
Validation loss: 2.5182275834550323

Epoch: 6| Step: 6
Training loss: 1.8719251852042793
Validation loss: 2.5180499471003595

Epoch: 6| Step: 7
Training loss: 2.1527908885378833
Validation loss: 2.5218185175826315

Epoch: 6| Step: 8
Training loss: 2.539485391465522
Validation loss: 2.510869714739447

Epoch: 6| Step: 9
Training loss: 1.9576826705568584
Validation loss: 2.511939664452721

Epoch: 6| Step: 10
Training loss: 2.7275314576793823
Validation loss: 2.5108891645272444

Epoch: 6| Step: 11
Training loss: 2.6227179098735967
Validation loss: 2.5066364735533337

Epoch: 6| Step: 12
Training loss: 2.3699074405993277
Validation loss: 2.5119291368712453

Epoch: 6| Step: 13
Training loss: 2.187297811700897
Validation loss: 2.518984563300413

Epoch: 223| Step: 0
Training loss: 1.817033688045555
Validation loss: 2.5260345668627404

Epoch: 6| Step: 1
Training loss: 2.6785695938830676
Validation loss: 2.538465505988126

Epoch: 6| Step: 2
Training loss: 2.3551805614086487
Validation loss: 2.5691198424622526

Epoch: 6| Step: 3
Training loss: 2.8338874574227346
Validation loss: 2.56965877796024

Epoch: 6| Step: 4
Training loss: 2.175442955249388
Validation loss: 2.5758069955875302

Epoch: 6| Step: 5
Training loss: 2.47641067761544
Validation loss: 2.5736561740782733

Epoch: 6| Step: 6
Training loss: 2.005127770593138
Validation loss: 2.5652731799424275

Epoch: 6| Step: 7
Training loss: 2.5308919582751197
Validation loss: 2.528227991899112

Epoch: 6| Step: 8
Training loss: 2.6197237849051946
Validation loss: 2.520824532191358

Epoch: 6| Step: 9
Training loss: 2.2423644311724846
Validation loss: 2.5181993852897127

Epoch: 6| Step: 10
Training loss: 2.1805365764766567
Validation loss: 2.5208623795110117

Epoch: 6| Step: 11
Training loss: 2.0767962574617966
Validation loss: 2.517933230810892

Epoch: 6| Step: 12
Training loss: 2.4797812162307977
Validation loss: 2.5156329926863354

Epoch: 6| Step: 13
Training loss: 1.8147747629349342
Validation loss: 2.519113242789768

Epoch: 224| Step: 0
Training loss: 1.920296742038618
Validation loss: 2.5236973899331923

Epoch: 6| Step: 1
Training loss: 2.569881136331135
Validation loss: 2.5347305669313327

Epoch: 6| Step: 2
Training loss: 2.4458917778696367
Validation loss: 2.5286731319086706

Epoch: 6| Step: 3
Training loss: 2.5337210944041404
Validation loss: 2.553187047297027

Epoch: 6| Step: 4
Training loss: 1.9214075031634728
Validation loss: 2.539652070285368

Epoch: 6| Step: 5
Training loss: 1.7875945886514242
Validation loss: 2.5364377584282196

Epoch: 6| Step: 6
Training loss: 2.8625140860265117
Validation loss: 2.534654196315546

Epoch: 6| Step: 7
Training loss: 1.870746046662375
Validation loss: 2.5354831134131257

Epoch: 6| Step: 8
Training loss: 2.4668129190269026
Validation loss: 2.5282984978579632

Epoch: 6| Step: 9
Training loss: 2.6892057816204544
Validation loss: 2.5373671598693717

Epoch: 6| Step: 10
Training loss: 2.203064829768983
Validation loss: 2.538272895302197

Epoch: 6| Step: 11
Training loss: 1.8102217200190318
Validation loss: 2.5319906493371356

Epoch: 6| Step: 12
Training loss: 1.9748567601664302
Validation loss: 2.5303512516126854

Epoch: 6| Step: 13
Training loss: 2.8284680911862674
Validation loss: 2.5422816131934027

Epoch: 225| Step: 0
Training loss: 2.5591909861757376
Validation loss: 2.5510857065952153

Epoch: 6| Step: 1
Training loss: 2.3810143862325335
Validation loss: 2.549260260925662

Epoch: 6| Step: 2
Training loss: 2.9007730045709974
Validation loss: 2.534399577004786

Epoch: 6| Step: 3
Training loss: 2.562442778902137
Validation loss: 2.5419286816939812

Epoch: 6| Step: 4
Training loss: 2.3667993006903933
Validation loss: 2.559211046916193

Epoch: 6| Step: 5
Training loss: 2.6051491880255373
Validation loss: 2.5540105951448404

Epoch: 6| Step: 6
Training loss: 2.07753728142257
Validation loss: 2.5489992359549833

Epoch: 6| Step: 7
Training loss: 1.576351113037158
Validation loss: 2.528191700838599

Epoch: 6| Step: 8
Training loss: 2.5709577405639847
Validation loss: 2.5660198816930113

Epoch: 6| Step: 9
Training loss: 1.4585324651003517
Validation loss: 2.51860613731558

Epoch: 6| Step: 10
Training loss: 2.101131352439699
Validation loss: 2.510778912780498

Epoch: 6| Step: 11
Training loss: 2.1605436174350556
Validation loss: 2.487664306428231

Epoch: 6| Step: 12
Training loss: 2.5927042863895213
Validation loss: 2.498733366528748

Epoch: 6| Step: 13
Training loss: 1.967520314636441
Validation loss: 2.4934802075932714

Epoch: 226| Step: 0
Training loss: 2.49593384996202
Validation loss: 2.4918625000849937

Epoch: 6| Step: 1
Training loss: 2.0301556500299154
Validation loss: 2.492549921707279

Epoch: 6| Step: 2
Training loss: 1.6184907536235167
Validation loss: 2.502354593895616

Epoch: 6| Step: 3
Training loss: 2.3645572969008697
Validation loss: 2.5004423385935506

Epoch: 6| Step: 4
Training loss: 2.4271241431564072
Validation loss: 2.4973785166426787

Epoch: 6| Step: 5
Training loss: 2.6713809621836395
Validation loss: 2.502149309680209

Epoch: 6| Step: 6
Training loss: 2.0377337924245804
Validation loss: 2.4955691332016974

Epoch: 6| Step: 7
Training loss: 2.7047250234908824
Validation loss: 2.496656407164141

Epoch: 6| Step: 8
Training loss: 1.7171613113308457
Validation loss: 2.5090076929883924

Epoch: 6| Step: 9
Training loss: 2.271666161174909
Validation loss: 2.5034693169602673

Epoch: 6| Step: 10
Training loss: 2.5205053531201678
Validation loss: 2.518566788793105

Epoch: 6| Step: 11
Training loss: 3.3828919998236278
Validation loss: 2.546968945913885

Epoch: 6| Step: 12
Training loss: 2.3683649036934993
Validation loss: 2.5638574400828604

Epoch: 6| Step: 13
Training loss: 1.7969611105810481
Validation loss: 2.5644438279296438

Epoch: 227| Step: 0
Training loss: 2.4185385086687825
Validation loss: 2.5456476511151602

Epoch: 6| Step: 1
Training loss: 1.861165058562411
Validation loss: 2.559722201155949

Epoch: 6| Step: 2
Training loss: 2.595061280954729
Validation loss: 2.543124911449772

Epoch: 6| Step: 3
Training loss: 2.8697410251328543
Validation loss: 2.53471133144135

Epoch: 6| Step: 4
Training loss: 1.3951326670849982
Validation loss: 2.5202445664131714

Epoch: 6| Step: 5
Training loss: 2.2319339676253516
Validation loss: 2.5495568491888125

Epoch: 6| Step: 6
Training loss: 1.8917017621161145
Validation loss: 2.5407586325723037

Epoch: 6| Step: 7
Training loss: 2.089712206542005
Validation loss: 2.5205796458272767

Epoch: 6| Step: 8
Training loss: 1.964544254479297
Validation loss: 2.535890391615991

Epoch: 6| Step: 9
Training loss: 2.8294170652733848
Validation loss: 2.5326306223847004

Epoch: 6| Step: 10
Training loss: 2.082565267760514
Validation loss: 2.529352143811769

Epoch: 6| Step: 11
Training loss: 2.677009601295077
Validation loss: 2.5202913700044953

Epoch: 6| Step: 12
Training loss: 2.261976579850138
Validation loss: 2.5335365924941757

Epoch: 6| Step: 13
Training loss: 2.8096912346077794
Validation loss: 2.5275460918385657

Epoch: 228| Step: 0
Training loss: 2.518631364854009
Validation loss: 2.5210897036830167

Epoch: 6| Step: 1
Training loss: 2.117745413942655
Validation loss: 2.5281017017902037

Epoch: 6| Step: 2
Training loss: 3.146231282981393
Validation loss: 2.5208497375290815

Epoch: 6| Step: 3
Training loss: 1.7848217273025737
Validation loss: 2.50309752259907

Epoch: 6| Step: 4
Training loss: 2.1517641148955766
Validation loss: 2.506769012718932

Epoch: 6| Step: 5
Training loss: 2.1381971415883023
Validation loss: 2.4921528844711434

Epoch: 6| Step: 6
Training loss: 1.8215772958083585
Validation loss: 2.4842006774138747

Epoch: 6| Step: 7
Training loss: 2.3620882916854073
Validation loss: 2.494532742267389

Epoch: 6| Step: 8
Training loss: 2.2635251541577
Validation loss: 2.491940190113377

Epoch: 6| Step: 9
Training loss: 2.8338494298290415
Validation loss: 2.4896783265275646

Epoch: 6| Step: 10
Training loss: 2.320960779531725
Validation loss: 2.494320824351082

Epoch: 6| Step: 11
Training loss: 2.618735331127808
Validation loss: 2.5043773634420017

Epoch: 6| Step: 12
Training loss: 1.8974457336225024
Validation loss: 2.5305513430310373

Epoch: 6| Step: 13
Training loss: 2.3997374748652622
Validation loss: 2.531323090428159

Epoch: 229| Step: 0
Training loss: 2.0492374676726888
Validation loss: 2.556349731713385

Epoch: 6| Step: 1
Training loss: 2.4130477994886856
Validation loss: 2.5441247018934394

Epoch: 6| Step: 2
Training loss: 1.8562075780266034
Validation loss: 2.56338817431945

Epoch: 6| Step: 3
Training loss: 2.713287302543728
Validation loss: 2.5487266315700405

Epoch: 6| Step: 4
Training loss: 2.2088236594317747
Validation loss: 2.5284418376715196

Epoch: 6| Step: 5
Training loss: 2.4032484878540044
Validation loss: 2.5290463120943953

Epoch: 6| Step: 6
Training loss: 2.132984643493685
Validation loss: 2.513944226271185

Epoch: 6| Step: 7
Training loss: 2.2735817984704085
Validation loss: 2.504461559148136

Epoch: 6| Step: 8
Training loss: 2.6613127985291376
Validation loss: 2.5031575448868835

Epoch: 6| Step: 9
Training loss: 2.6061373972180957
Validation loss: 2.5003066510640375

Epoch: 6| Step: 10
Training loss: 1.8247023927682213
Validation loss: 2.5051616947223794

Epoch: 6| Step: 11
Training loss: 2.089028115513821
Validation loss: 2.495083361133232

Epoch: 6| Step: 12
Training loss: 2.355551039743393
Validation loss: 2.5023893541334408

Epoch: 6| Step: 13
Training loss: 2.7359643295427882
Validation loss: 2.4971958805637864

Epoch: 230| Step: 0
Training loss: 1.7652473383387624
Validation loss: 2.5074810787512662

Epoch: 6| Step: 1
Training loss: 2.4112316928641184
Validation loss: 2.502908564436387

Epoch: 6| Step: 2
Training loss: 3.053766370269581
Validation loss: 2.512341253601779

Epoch: 6| Step: 3
Training loss: 2.4980979359458475
Validation loss: 2.513316182913645

Epoch: 6| Step: 4
Training loss: 2.663017895972541
Validation loss: 2.516235956594054

Epoch: 6| Step: 5
Training loss: 2.0662052511087743
Validation loss: 2.5194288602620607

Epoch: 6| Step: 6
Training loss: 2.8428757549862382
Validation loss: 2.5332535243847945

Epoch: 6| Step: 7
Training loss: 2.1193568528078175
Validation loss: 2.520304306467876

Epoch: 6| Step: 8
Training loss: 2.335616175772943
Validation loss: 2.53632655705495

Epoch: 6| Step: 9
Training loss: 1.8903148175990157
Validation loss: 2.537504154195658

Epoch: 6| Step: 10
Training loss: 2.1398521197553317
Validation loss: 2.551282333998977

Epoch: 6| Step: 11
Training loss: 2.337955789446623
Validation loss: 2.5077061932651756

Epoch: 6| Step: 12
Training loss: 1.8441035044949423
Validation loss: 2.5175383184623725

Epoch: 6| Step: 13
Training loss: 1.9911084412990185
Validation loss: 2.5135678158878143

Epoch: 231| Step: 0
Training loss: 1.9258869753401076
Validation loss: 2.5045663615135982

Epoch: 6| Step: 1
Training loss: 1.8035164869214289
Validation loss: 2.491116826896602

Epoch: 6| Step: 2
Training loss: 2.022866186840662
Validation loss: 2.495432320817081

Epoch: 6| Step: 3
Training loss: 1.7681797415820768
Validation loss: 2.500415735645584

Epoch: 6| Step: 4
Training loss: 2.6217488637052178
Validation loss: 2.4956348616241746

Epoch: 6| Step: 5
Training loss: 2.40803788384708
Validation loss: 2.4861070684995643

Epoch: 6| Step: 6
Training loss: 2.129343754321073
Validation loss: 2.495076616508564

Epoch: 6| Step: 7
Training loss: 2.528137365435902
Validation loss: 2.503704790966384

Epoch: 6| Step: 8
Training loss: 2.9107781686551006
Validation loss: 2.500182137212355

Epoch: 6| Step: 9
Training loss: 1.9462245044251076
Validation loss: 2.487264843788731

Epoch: 6| Step: 10
Training loss: 2.6733403342607995
Validation loss: 2.490775638174607

Epoch: 6| Step: 11
Training loss: 2.3326296653563943
Validation loss: 2.5099903763058435

Epoch: 6| Step: 12
Training loss: 2.747022403932578
Validation loss: 2.5116613212415504

Epoch: 6| Step: 13
Training loss: 2.2974955440639917
Validation loss: 2.4972037174183743

Epoch: 232| Step: 0
Training loss: 1.9753148057390373
Validation loss: 2.5194250749794205

Epoch: 6| Step: 1
Training loss: 2.7265138813045295
Validation loss: 2.5390738775536352

Epoch: 6| Step: 2
Training loss: 1.9102667092055685
Validation loss: 2.547127740407251

Epoch: 6| Step: 3
Training loss: 2.473460375546905
Validation loss: 2.5640990532643175

Epoch: 6| Step: 4
Training loss: 2.674320373476494
Validation loss: 2.5386519819126776

Epoch: 6| Step: 5
Training loss: 2.0537941734871
Validation loss: 2.531594084284571

Epoch: 6| Step: 6
Training loss: 1.7331716125801173
Validation loss: 2.539919148232139

Epoch: 6| Step: 7
Training loss: 2.50521421266581
Validation loss: 2.5483449582703193

Epoch: 6| Step: 8
Training loss: 1.8818527878153872
Validation loss: 2.533775890326591

Epoch: 6| Step: 9
Training loss: 2.7199139788993887
Validation loss: 2.5371582793978984

Epoch: 6| Step: 10
Training loss: 2.526093682346755
Validation loss: 2.5532484833245235

Epoch: 6| Step: 11
Training loss: 2.4274713645369688
Validation loss: 2.5341973511773013

Epoch: 6| Step: 12
Training loss: 1.8575658251059208
Validation loss: 2.506379816525375

Epoch: 6| Step: 13
Training loss: 2.0312314546178643
Validation loss: 2.5345794303655373

Epoch: 233| Step: 0
Training loss: 1.9149912546620491
Validation loss: 2.5639802487555365

Epoch: 6| Step: 1
Training loss: 1.4311794146994032
Validation loss: 2.5349123484288607

Epoch: 6| Step: 2
Training loss: 2.051864599456595
Validation loss: 2.543968211319285

Epoch: 6| Step: 3
Training loss: 2.4373479942462364
Validation loss: 2.521253209311404

Epoch: 6| Step: 4
Training loss: 1.720994697314377
Validation loss: 2.538002818107794

Epoch: 6| Step: 5
Training loss: 2.21982236924786
Validation loss: 2.5296413113463596

Epoch: 6| Step: 6
Training loss: 1.9746300821699547
Validation loss: 2.538105468361733

Epoch: 6| Step: 7
Training loss: 2.6090679787566744
Validation loss: 2.5541021082707047

Epoch: 6| Step: 8
Training loss: 2.7439432202128295
Validation loss: 2.537862640926456

Epoch: 6| Step: 9
Training loss: 2.504864156850607
Validation loss: 2.552184563529957

Epoch: 6| Step: 10
Training loss: 2.3253533166666873
Validation loss: 2.5665003867184675

Epoch: 6| Step: 11
Training loss: 2.570964139292842
Validation loss: 2.5614682733488467

Epoch: 6| Step: 12
Training loss: 2.5611973684776093
Validation loss: 2.5704742504423765

Epoch: 6| Step: 13
Training loss: 2.3671798454135726
Validation loss: 2.5126189442531826

Epoch: 234| Step: 0
Training loss: 2.8842019141805406
Validation loss: 2.517110571543131

Epoch: 6| Step: 1
Training loss: 1.843878402118235
Validation loss: 2.5221570115288294

Epoch: 6| Step: 2
Training loss: 2.558484350297131
Validation loss: 2.499990320186949

Epoch: 6| Step: 3
Training loss: 1.729554910238619
Validation loss: 2.508172869909516

Epoch: 6| Step: 4
Training loss: 2.1677802476467494
Validation loss: 2.490813232162943

Epoch: 6| Step: 5
Training loss: 2.276513499594648
Validation loss: 2.5045480525526695

Epoch: 6| Step: 6
Training loss: 1.810358689948816
Validation loss: 2.497566755622661

Epoch: 6| Step: 7
Training loss: 2.575965485537068
Validation loss: 2.4942241147893367

Epoch: 6| Step: 8
Training loss: 2.445674589118883
Validation loss: 2.500380725480447

Epoch: 6| Step: 9
Training loss: 2.001240941348235
Validation loss: 2.5011833330859394

Epoch: 6| Step: 10
Training loss: 2.496250010391564
Validation loss: 2.5195427078656825

Epoch: 6| Step: 11
Training loss: 2.466802094152733
Validation loss: 2.528373622418214

Epoch: 6| Step: 12
Training loss: 2.1011978457013
Validation loss: 2.542503349504543

Epoch: 6| Step: 13
Training loss: 2.5449604725344352
Validation loss: 2.5450267989690607

Epoch: 235| Step: 0
Training loss: 2.5282082825701195
Validation loss: 2.541629592958648

Epoch: 6| Step: 1
Training loss: 1.5889659961065363
Validation loss: 2.5319666220909167

Epoch: 6| Step: 2
Training loss: 2.3901352723597515
Validation loss: 2.5213124526608492

Epoch: 6| Step: 3
Training loss: 2.118912448113077
Validation loss: 2.5094169166645974

Epoch: 6| Step: 4
Training loss: 2.2158117046163786
Validation loss: 2.515614116637261

Epoch: 6| Step: 5
Training loss: 1.9980271861429117
Validation loss: 2.4972648758640736

Epoch: 6| Step: 6
Training loss: 2.983477872050117
Validation loss: 2.5011494219434107

Epoch: 6| Step: 7
Training loss: 2.2118212547789753
Validation loss: 2.500966155598914

Epoch: 6| Step: 8
Training loss: 2.0493083205664586
Validation loss: 2.498873782798012

Epoch: 6| Step: 9
Training loss: 2.5492755833286953
Validation loss: 2.5060478014729113

Epoch: 6| Step: 10
Training loss: 2.1577585444240874
Validation loss: 2.501019055572665

Epoch: 6| Step: 11
Training loss: 2.724530618821434
Validation loss: 2.4979802555986788

Epoch: 6| Step: 12
Training loss: 1.7649930650180379
Validation loss: 2.512026635932327

Epoch: 6| Step: 13
Training loss: 2.4863191111506873
Validation loss: 2.5015450630477756

Epoch: 236| Step: 0
Training loss: 2.1268334052911397
Validation loss: 2.506816218493896

Epoch: 6| Step: 1
Training loss: 2.548553662485616
Validation loss: 2.4963131262461036

Epoch: 6| Step: 2
Training loss: 2.5846268481569767
Validation loss: 2.4998890216354748

Epoch: 6| Step: 3
Training loss: 2.732179817783167
Validation loss: 2.5214146792321004

Epoch: 6| Step: 4
Training loss: 2.302297820949248
Validation loss: 2.4802719078156374

Epoch: 6| Step: 5
Training loss: 1.9450211517439087
Validation loss: 2.4964264362925603

Epoch: 6| Step: 6
Training loss: 2.5033051577157917
Validation loss: 2.5124671971851003

Epoch: 6| Step: 7
Training loss: 1.846208259043518
Validation loss: 2.500558123277074

Epoch: 6| Step: 8
Training loss: 1.9321725882334697
Validation loss: 2.519966091906783

Epoch: 6| Step: 9
Training loss: 2.56695290699208
Validation loss: 2.5241264292533576

Epoch: 6| Step: 10
Training loss: 2.2700925779580006
Validation loss: 2.516767254349742

Epoch: 6| Step: 11
Training loss: 2.1749397444873915
Validation loss: 2.559334171700777

Epoch: 6| Step: 12
Training loss: 2.0456222311316425
Validation loss: 2.5455248009442553

Epoch: 6| Step: 13
Training loss: 2.0149510166092663
Validation loss: 2.5761266188156697

Epoch: 237| Step: 0
Training loss: 2.6615936384252867
Validation loss: 2.555078910061972

Epoch: 6| Step: 1
Training loss: 1.969834528523445
Validation loss: 2.5425986212523903

Epoch: 6| Step: 2
Training loss: 1.6390534639791292
Validation loss: 2.5425889707744136

Epoch: 6| Step: 3
Training loss: 2.3996623636214123
Validation loss: 2.52762507465319

Epoch: 6| Step: 4
Training loss: 1.932952219570388
Validation loss: 2.4990020667560238

Epoch: 6| Step: 5
Training loss: 2.043756103506511
Validation loss: 2.5231334633032083

Epoch: 6| Step: 6
Training loss: 2.4816616764193493
Validation loss: 2.50846481950247

Epoch: 6| Step: 7
Training loss: 2.2937210122753204
Validation loss: 2.514047779824909

Epoch: 6| Step: 8
Training loss: 2.6173092030938205
Validation loss: 2.522682116247791

Epoch: 6| Step: 9
Training loss: 2.420200876773568
Validation loss: 2.511258207174523

Epoch: 6| Step: 10
Training loss: 1.8249354782195195
Validation loss: 2.5156470351113014

Epoch: 6| Step: 11
Training loss: 2.347233739018323
Validation loss: 2.5078403158417912

Epoch: 6| Step: 12
Training loss: 2.31591997623055
Validation loss: 2.5262320115777954

Epoch: 6| Step: 13
Training loss: 2.543598712293212
Validation loss: 2.5227581011091074

Epoch: 238| Step: 0
Training loss: 1.8764117330419736
Validation loss: 2.5123528312485606

Epoch: 6| Step: 1
Training loss: 2.5135652627692395
Validation loss: 2.5352794145114634

Epoch: 6| Step: 2
Training loss: 1.9825254817253442
Validation loss: 2.5178263965766257

Epoch: 6| Step: 3
Training loss: 1.8082128663376482
Validation loss: 2.528582097097217

Epoch: 6| Step: 4
Training loss: 2.725443350746789
Validation loss: 2.5374682307016316

Epoch: 6| Step: 5
Training loss: 2.16296689500311
Validation loss: 2.5442631752942715

Epoch: 6| Step: 6
Training loss: 2.4763198878108574
Validation loss: 2.556114132852732

Epoch: 6| Step: 7
Training loss: 2.4298958152445786
Validation loss: 2.563529652848059

Epoch: 6| Step: 8
Training loss: 2.100217026894743
Validation loss: 2.5958434546096267

Epoch: 6| Step: 9
Training loss: 2.798168543889415
Validation loss: 2.569818265602271

Epoch: 6| Step: 10
Training loss: 2.1007940879988447
Validation loss: 2.5424381372483227

Epoch: 6| Step: 11
Training loss: 1.7854270813088107
Validation loss: 2.533245767682019

Epoch: 6| Step: 12
Training loss: 2.2967379782152277
Validation loss: 2.519677099299248

Epoch: 6| Step: 13
Training loss: 2.24547227305637
Validation loss: 2.5293419165019047

Epoch: 239| Step: 0
Training loss: 2.438272598285476
Validation loss: 2.5301143940280406

Epoch: 6| Step: 1
Training loss: 2.2686311969179553
Validation loss: 2.5169139269021015

Epoch: 6| Step: 2
Training loss: 2.730804553686882
Validation loss: 2.5422922260930165

Epoch: 6| Step: 3
Training loss: 1.8050826659782135
Validation loss: 2.524419524569969

Epoch: 6| Step: 4
Training loss: 1.486438802240165
Validation loss: 2.5339611902534203

Epoch: 6| Step: 5
Training loss: 2.197438252767377
Validation loss: 2.519272428718037

Epoch: 6| Step: 6
Training loss: 2.2238134713680986
Validation loss: 2.4969614000454747

Epoch: 6| Step: 7
Training loss: 2.5700607408403573
Validation loss: 2.5279935603794135

Epoch: 6| Step: 8
Training loss: 2.6121871322848804
Validation loss: 2.5041539014680287

Epoch: 6| Step: 9
Training loss: 2.630308233699305
Validation loss: 2.4937665793776813

Epoch: 6| Step: 10
Training loss: 2.3007725454790773
Validation loss: 2.4932592752069236

Epoch: 6| Step: 11
Training loss: 1.9083694182514386
Validation loss: 2.4850975441417043

Epoch: 6| Step: 12
Training loss: 2.0082975165416874
Validation loss: 2.5152758875371144

Epoch: 6| Step: 13
Training loss: 2.088218327811279
Validation loss: 2.487024681646799

Epoch: 240| Step: 0
Training loss: 1.7321591355425476
Validation loss: 2.5079836524560393

Epoch: 6| Step: 1
Training loss: 2.1023578485975145
Validation loss: 2.4936996225416963

Epoch: 6| Step: 2
Training loss: 2.387469634017768
Validation loss: 2.522072862995908

Epoch: 6| Step: 3
Training loss: 2.486749438049431
Validation loss: 2.5031669981469635

Epoch: 6| Step: 4
Training loss: 1.897732513516021
Validation loss: 2.5127461469410277

Epoch: 6| Step: 5
Training loss: 1.8662166864854541
Validation loss: 2.5168606268642306

Epoch: 6| Step: 6
Training loss: 3.0462207580840923
Validation loss: 2.5237647868871527

Epoch: 6| Step: 7
Training loss: 1.816189988911106
Validation loss: 2.5412486206791494

Epoch: 6| Step: 8
Training loss: 2.1556904384626963
Validation loss: 2.5326764518319154

Epoch: 6| Step: 9
Training loss: 2.528345395962383
Validation loss: 2.554123951449475

Epoch: 6| Step: 10
Training loss: 1.8366260941669048
Validation loss: 2.540537698081757

Epoch: 6| Step: 11
Training loss: 2.842875587255668
Validation loss: 2.559798646610364

Epoch: 6| Step: 12
Training loss: 2.472409493667305
Validation loss: 2.554516591179296

Epoch: 6| Step: 13
Training loss: 1.4774012529709974
Validation loss: 2.5640721189390927

Epoch: 241| Step: 0
Training loss: 2.2553150131213697
Validation loss: 2.5774907882974754

Epoch: 6| Step: 1
Training loss: 2.3015550953835935
Validation loss: 2.612044531681624

Epoch: 6| Step: 2
Training loss: 2.2518994473017786
Validation loss: 2.601708378486961

Epoch: 6| Step: 3
Training loss: 2.2823726034387404
Validation loss: 2.586619645392657

Epoch: 6| Step: 4
Training loss: 2.1511314564238426
Validation loss: 2.5896130857551256

Epoch: 6| Step: 5
Training loss: 1.737153105102782
Validation loss: 2.550202799193939

Epoch: 6| Step: 6
Training loss: 2.706185521157161
Validation loss: 2.55799618797227

Epoch: 6| Step: 7
Training loss: 2.694145768337531
Validation loss: 2.5201465259570717

Epoch: 6| Step: 8
Training loss: 2.3985790496707695
Validation loss: 2.507978994323115

Epoch: 6| Step: 9
Training loss: 2.066943381867935
Validation loss: 2.495862891436656

Epoch: 6| Step: 10
Training loss: 2.1465051457352073
Validation loss: 2.5063319445727665

Epoch: 6| Step: 11
Training loss: 1.4469433630329818
Validation loss: 2.4935897820296513

Epoch: 6| Step: 12
Training loss: 2.8355339330621447
Validation loss: 2.491423462849844

Epoch: 6| Step: 13
Training loss: 2.1103290802033006
Validation loss: 2.472313164587287

Epoch: 242| Step: 0
Training loss: 2.006751347821863
Validation loss: 2.4977468827943783

Epoch: 6| Step: 1
Training loss: 2.4690876017681265
Validation loss: 2.5031231048741907

Epoch: 6| Step: 2
Training loss: 1.729305108591267
Validation loss: 2.4893446346330186

Epoch: 6| Step: 3
Training loss: 1.9357189483063586
Validation loss: 2.5012210089461644

Epoch: 6| Step: 4
Training loss: 2.097526787824382
Validation loss: 2.489557710353455

Epoch: 6| Step: 5
Training loss: 2.6360662712657903
Validation loss: 2.5050424585659097

Epoch: 6| Step: 6
Training loss: 1.5840628683300872
Validation loss: 2.5148531122459006

Epoch: 6| Step: 7
Training loss: 2.226708122979167
Validation loss: 2.538232583592778

Epoch: 6| Step: 8
Training loss: 2.842183111102473
Validation loss: 2.5495046601986977

Epoch: 6| Step: 9
Training loss: 2.2073346764942454
Validation loss: 2.546898761786641

Epoch: 6| Step: 10
Training loss: 2.531559772139171
Validation loss: 2.5539404100413132

Epoch: 6| Step: 11
Training loss: 2.6511317589421095
Validation loss: 2.563911839905145

Epoch: 6| Step: 12
Training loss: 2.2158153629710036
Validation loss: 2.569905690443097

Epoch: 6| Step: 13
Training loss: 2.08737875763356
Validation loss: 2.586702677297473

Epoch: 243| Step: 0
Training loss: 2.2732700142008206
Validation loss: 2.575749483877789

Epoch: 6| Step: 1
Training loss: 2.7793457713219025
Validation loss: 2.576198651972603

Epoch: 6| Step: 2
Training loss: 2.6136180620721245
Validation loss: 2.5618318136272458

Epoch: 6| Step: 3
Training loss: 2.2259175755268994
Validation loss: 2.5815691820640083

Epoch: 6| Step: 4
Training loss: 1.7525939109770476
Validation loss: 2.5717265095879442

Epoch: 6| Step: 5
Training loss: 1.9916691722880713
Validation loss: 2.5329620317187995

Epoch: 6| Step: 6
Training loss: 1.9665562957030525
Validation loss: 2.5521259122657143

Epoch: 6| Step: 7
Training loss: 2.758483113566148
Validation loss: 2.5438105395562043

Epoch: 6| Step: 8
Training loss: 2.3417109456972356
Validation loss: 2.5225174587768433

Epoch: 6| Step: 9
Training loss: 2.0890799294131974
Validation loss: 2.52208050438469

Epoch: 6| Step: 10
Training loss: 2.4442337142777912
Validation loss: 2.5171743404045235

Epoch: 6| Step: 11
Training loss: 2.1296725792477598
Validation loss: 2.505199921422676

Epoch: 6| Step: 12
Training loss: 1.8246438554214346
Validation loss: 2.500807766752432

Epoch: 6| Step: 13
Training loss: 1.6883277275893653
Validation loss: 2.5229239713866005

Epoch: 244| Step: 0
Training loss: 2.178169514927729
Validation loss: 2.504597870382555

Epoch: 6| Step: 1
Training loss: 2.5790387008384275
Validation loss: 2.5064555425540926

Epoch: 6| Step: 2
Training loss: 2.358008184585409
Validation loss: 2.5151190081045454

Epoch: 6| Step: 3
Training loss: 2.192126368284084
Validation loss: 2.5170452539470114

Epoch: 6| Step: 4
Training loss: 2.543164129999135
Validation loss: 2.527060113995693

Epoch: 6| Step: 5
Training loss: 1.893460252206148
Validation loss: 2.52836238530902

Epoch: 6| Step: 6
Training loss: 2.648388167290353
Validation loss: 2.519671658489748

Epoch: 6| Step: 7
Training loss: 2.038483870097446
Validation loss: 2.5364845373744025

Epoch: 6| Step: 8
Training loss: 2.040421073503223
Validation loss: 2.5368959544148852

Epoch: 6| Step: 9
Training loss: 1.978956077481497
Validation loss: 2.535260951187641

Epoch: 6| Step: 10
Training loss: 2.1926693463578304
Validation loss: 2.5416794500394273

Epoch: 6| Step: 11
Training loss: 2.1075551412480005
Validation loss: 2.528518458784749

Epoch: 6| Step: 12
Training loss: 2.4810181016918946
Validation loss: 2.549191441469078

Epoch: 6| Step: 13
Training loss: 1.9986789632058035
Validation loss: 2.5605911805844195

Epoch: 245| Step: 0
Training loss: 1.789684603945036
Validation loss: 2.5694646548143627

Epoch: 6| Step: 1
Training loss: 2.2475057127883153
Validation loss: 2.5532883400808206

Epoch: 6| Step: 2
Training loss: 2.391148528574828
Validation loss: 2.5515425180406903

Epoch: 6| Step: 3
Training loss: 2.6222494337677924
Validation loss: 2.546258114486746

Epoch: 6| Step: 4
Training loss: 2.4179558329938198
Validation loss: 2.542622391747182

Epoch: 6| Step: 5
Training loss: 2.4894586529229676
Validation loss: 2.5153992356113495

Epoch: 6| Step: 6
Training loss: 2.38387757558555
Validation loss: 2.5334914373535824

Epoch: 6| Step: 7
Training loss: 1.8531379274686102
Validation loss: 2.5345263999185637

Epoch: 6| Step: 8
Training loss: 2.070043236838393
Validation loss: 2.509328144502224

Epoch: 6| Step: 9
Training loss: 1.8311115876575783
Validation loss: 2.52921560345921

Epoch: 6| Step: 10
Training loss: 2.5112452320226404
Validation loss: 2.536154081881896

Epoch: 6| Step: 11
Training loss: 2.540212142075068
Validation loss: 2.546770682665607

Epoch: 6| Step: 12
Training loss: 2.1343124760284775
Validation loss: 2.579365241233532

Epoch: 6| Step: 13
Training loss: 2.11974582731905
Validation loss: 2.5974093900706285

Epoch: 246| Step: 0
Training loss: 1.583709956432912
Validation loss: 2.610164515278501

Epoch: 6| Step: 1
Training loss: 2.6313256839550485
Validation loss: 2.6131695779110706

Epoch: 6| Step: 2
Training loss: 2.225068029156637
Validation loss: 2.6056792533059414

Epoch: 6| Step: 3
Training loss: 2.242741001409181
Validation loss: 2.5798495603165623

Epoch: 6| Step: 4
Training loss: 2.629818988851426
Validation loss: 2.549434709534751

Epoch: 6| Step: 5
Training loss: 2.567374826145338
Validation loss: 2.54673348562183

Epoch: 6| Step: 6
Training loss: 1.8778159295042998
Validation loss: 2.5365398375610386

Epoch: 6| Step: 7
Training loss: 1.9315823660956628
Validation loss: 2.529027402605913

Epoch: 6| Step: 8
Training loss: 2.9775837425415355
Validation loss: 2.5309441464100537

Epoch: 6| Step: 9
Training loss: 2.361169397968583
Validation loss: 2.531651861370594

Epoch: 6| Step: 10
Training loss: 2.7976000820935494
Validation loss: 2.515578701943793

Epoch: 6| Step: 11
Training loss: 2.4211938700080484
Validation loss: 2.5164997957076554

Epoch: 6| Step: 12
Training loss: 1.301204578145578
Validation loss: 2.5073815566715596

Epoch: 6| Step: 13
Training loss: 1.8795936897188141
Validation loss: 2.5184976512874506

Epoch: 247| Step: 0
Training loss: 2.1225966157704175
Validation loss: 2.5170500137034177

Epoch: 6| Step: 1
Training loss: 2.861420113709043
Validation loss: 2.5174991189828217

Epoch: 6| Step: 2
Training loss: 2.838079143020134
Validation loss: 2.504407684694247

Epoch: 6| Step: 3
Training loss: 2.4543011998173836
Validation loss: 2.528883766009158

Epoch: 6| Step: 4
Training loss: 2.2466664521229505
Validation loss: 2.5512344245989684

Epoch: 6| Step: 5
Training loss: 2.5020415553263855
Validation loss: 2.5513456770684115

Epoch: 6| Step: 6
Training loss: 1.7153253595888616
Validation loss: 2.5276550698684845

Epoch: 6| Step: 7
Training loss: 1.8727838771140726
Validation loss: 2.5201129251740833

Epoch: 6| Step: 8
Training loss: 1.9911019153692473
Validation loss: 2.546776861316571

Epoch: 6| Step: 9
Training loss: 2.0150992720692313
Validation loss: 2.5361448377525644

Epoch: 6| Step: 10
Training loss: 2.1367552368842566
Validation loss: 2.5449268558635945

Epoch: 6| Step: 11
Training loss: 2.432533486303386
Validation loss: 2.512941038350554

Epoch: 6| Step: 12
Training loss: 1.5544668836627478
Validation loss: 2.5095246868531853

Epoch: 6| Step: 13
Training loss: 2.3658129034160176
Validation loss: 2.530279161747855

Epoch: 248| Step: 0
Training loss: 2.6183099417933593
Validation loss: 2.515235973471592

Epoch: 6| Step: 1
Training loss: 1.8631660857688397
Validation loss: 2.5348399101585186

Epoch: 6| Step: 2
Training loss: 2.0716465520559986
Validation loss: 2.496114317839589

Epoch: 6| Step: 3
Training loss: 2.5123741042446195
Validation loss: 2.534493601227208

Epoch: 6| Step: 4
Training loss: 2.2508426783665594
Validation loss: 2.52280852014883

Epoch: 6| Step: 5
Training loss: 2.4831952826853314
Validation loss: 2.549125472807673

Epoch: 6| Step: 6
Training loss: 2.2298025014688276
Validation loss: 2.581696381353779

Epoch: 6| Step: 7
Training loss: 1.7645595340257278
Validation loss: 2.585113148134455

Epoch: 6| Step: 8
Training loss: 1.945981198015172
Validation loss: 2.6000401316504385

Epoch: 6| Step: 9
Training loss: 2.683204322778021
Validation loss: 2.6029994383254578

Epoch: 6| Step: 10
Training loss: 1.9017423897304238
Validation loss: 2.5887611239845265

Epoch: 6| Step: 11
Training loss: 2.0995927960828005
Validation loss: 2.5688917258612527

Epoch: 6| Step: 12
Training loss: 2.4559443121011206
Validation loss: 2.542943279492339

Epoch: 6| Step: 13
Training loss: 2.1365735773566845
Validation loss: 2.5261510818748025

Epoch: 249| Step: 0
Training loss: 1.9706642895625277
Validation loss: 2.5265421787719453

Epoch: 6| Step: 1
Training loss: 1.8073156466986495
Validation loss: 2.5200691299568865

Epoch: 6| Step: 2
Training loss: 2.3435445059653612
Validation loss: 2.5118056816691885

Epoch: 6| Step: 3
Training loss: 1.9018500782176495
Validation loss: 2.515042492259179

Epoch: 6| Step: 4
Training loss: 2.146726835821339
Validation loss: 2.495732654924841

Epoch: 6| Step: 5
Training loss: 2.3508236760487975
Validation loss: 2.5226234485096026

Epoch: 6| Step: 6
Training loss: 1.6732217231069897
Validation loss: 2.522348946647503

Epoch: 6| Step: 7
Training loss: 2.8389871136949663
Validation loss: 2.516374275030428

Epoch: 6| Step: 8
Training loss: 2.6549981252660078
Validation loss: 2.526931642621971

Epoch: 6| Step: 9
Training loss: 2.472047173330811
Validation loss: 2.5034753009026502

Epoch: 6| Step: 10
Training loss: 2.061983795302141
Validation loss: 2.522183337894491

Epoch: 6| Step: 11
Training loss: 2.482117208758018
Validation loss: 2.5224416557044695

Epoch: 6| Step: 12
Training loss: 2.638277443659112
Validation loss: 2.541121273204858

Epoch: 6| Step: 13
Training loss: 2.149337968254929
Validation loss: 2.5567558385010782

Epoch: 250| Step: 0
Training loss: 2.772409855827851
Validation loss: 2.5482244056721948

Epoch: 6| Step: 1
Training loss: 2.343713683800673
Validation loss: 2.536585095088642

Epoch: 6| Step: 2
Training loss: 2.6488488702112165
Validation loss: 2.550602578043796

Epoch: 6| Step: 3
Training loss: 1.7440554607654626
Validation loss: 2.5348257545914543

Epoch: 6| Step: 4
Training loss: 2.232027541315391
Validation loss: 2.506808546427098

Epoch: 6| Step: 5
Training loss: 2.2431185713171278
Validation loss: 2.493537194550278

Epoch: 6| Step: 6
Training loss: 2.015150147326986
Validation loss: 2.499788227648536

Epoch: 6| Step: 7
Training loss: 1.9659519596808126
Validation loss: 2.504028476027075

Epoch: 6| Step: 8
Training loss: 2.281923795505909
Validation loss: 2.490512998863433

Epoch: 6| Step: 9
Training loss: 2.4793921830216785
Validation loss: 2.493587407649186

Epoch: 6| Step: 10
Training loss: 2.5732519160454146
Validation loss: 2.4939975921554995

Epoch: 6| Step: 11
Training loss: 2.157314977392529
Validation loss: 2.515741839173528

Epoch: 6| Step: 12
Training loss: 1.9817930229505376
Validation loss: 2.5001740871851905

Epoch: 6| Step: 13
Training loss: 2.5339553880746286
Validation loss: 2.493075739661648

Epoch: 251| Step: 0
Training loss: 2.655615876743934
Validation loss: 2.491814540591712

Epoch: 6| Step: 1
Training loss: 2.9505912770107905
Validation loss: 2.5242582547319596

Epoch: 6| Step: 2
Training loss: 1.8614526248695638
Validation loss: 2.502838176751652

Epoch: 6| Step: 3
Training loss: 2.4060633203001838
Validation loss: 2.5131019276133255

Epoch: 6| Step: 4
Training loss: 2.378020223347082
Validation loss: 2.524913202814591

Epoch: 6| Step: 5
Training loss: 2.3317654200980926
Validation loss: 2.574662598167983

Epoch: 6| Step: 6
Training loss: 1.9095898746137336
Validation loss: 2.5944345788770384

Epoch: 6| Step: 7
Training loss: 1.6092597401649984
Validation loss: 2.5643128596168325

Epoch: 6| Step: 8
Training loss: 2.6310813940399087
Validation loss: 2.5919733358726744

Epoch: 6| Step: 9
Training loss: 2.2516452284365784
Validation loss: 2.5352156543482307

Epoch: 6| Step: 10
Training loss: 1.4324614915448552
Validation loss: 2.5257133480265805

Epoch: 6| Step: 11
Training loss: 2.4170130996570074
Validation loss: 2.5193435953918324

Epoch: 6| Step: 12
Training loss: 1.813608488297591
Validation loss: 2.4911144661103313

Epoch: 6| Step: 13
Training loss: 2.666842355503768
Validation loss: 2.488446488176371

Epoch: 252| Step: 0
Training loss: 3.141382078710089
Validation loss: 2.4845024092210846

Epoch: 6| Step: 1
Training loss: 2.515883343622725
Validation loss: 2.4932581356722543

Epoch: 6| Step: 2
Training loss: 2.3424170200302803
Validation loss: 2.492141037590586

Epoch: 6| Step: 3
Training loss: 1.661048846670865
Validation loss: 2.4974014923912002

Epoch: 6| Step: 4
Training loss: 1.9583234042734354
Validation loss: 2.4653479800429645

Epoch: 6| Step: 5
Training loss: 1.3970718535237858
Validation loss: 2.486137740444254

Epoch: 6| Step: 6
Training loss: 2.1511817744872204
Validation loss: 2.4969123369655173

Epoch: 6| Step: 7
Training loss: 2.1531509021369235
Validation loss: 2.5105274592811626

Epoch: 6| Step: 8
Training loss: 1.699008270908137
Validation loss: 2.512647552965433

Epoch: 6| Step: 9
Training loss: 1.9614542853876997
Validation loss: 2.48249515452301

Epoch: 6| Step: 10
Training loss: 2.4685671774856606
Validation loss: 2.496194533978437

Epoch: 6| Step: 11
Training loss: 2.5400109969674496
Validation loss: 2.495486341267982

Epoch: 6| Step: 12
Training loss: 2.252516081453047
Validation loss: 2.510507167804663

Epoch: 6| Step: 13
Training loss: 2.4757026599701946
Validation loss: 2.5033768418040645

Epoch: 253| Step: 0
Training loss: 2.9020958200274167
Validation loss: 2.4954343749691006

Epoch: 6| Step: 1
Training loss: 2.1409098860240903
Validation loss: 2.5315349716713382

Epoch: 6| Step: 2
Training loss: 3.0905060377841163
Validation loss: 2.5263502161935194

Epoch: 6| Step: 3
Training loss: 2.535762767213146
Validation loss: 2.5454215834855236

Epoch: 6| Step: 4
Training loss: 2.326536827381285
Validation loss: 2.53335039881764

Epoch: 6| Step: 5
Training loss: 2.104134272964958
Validation loss: 2.5399443518182148

Epoch: 6| Step: 6
Training loss: 2.591297506880489
Validation loss: 2.5573224119577045

Epoch: 6| Step: 7
Training loss: 1.9781748712650056
Validation loss: 2.5468469785931345

Epoch: 6| Step: 8
Training loss: 2.0783312702347163
Validation loss: 2.5349476184235935

Epoch: 6| Step: 9
Training loss: 1.858819445792319
Validation loss: 2.5312018370265217

Epoch: 6| Step: 10
Training loss: 1.7338884375651507
Validation loss: 2.5355089409575946

Epoch: 6| Step: 11
Training loss: 2.121154671877751
Validation loss: 2.5340846166987467

Epoch: 6| Step: 12
Training loss: 2.0751410838502764
Validation loss: 2.5303363485501342

Epoch: 6| Step: 13
Training loss: 1.4422396599790224
Validation loss: 2.533271657251507

Epoch: 254| Step: 0
Training loss: 1.9911084412990185
Validation loss: 2.5236919499183297

Epoch: 6| Step: 1
Training loss: 2.072223745600618
Validation loss: 2.5290511199683827

Epoch: 6| Step: 2
Training loss: 2.075139590244532
Validation loss: 2.542635925670575

Epoch: 6| Step: 3
Training loss: 2.172678846717038
Validation loss: 2.5449657499835383

Epoch: 6| Step: 4
Training loss: 2.3355264461508813
Validation loss: 2.555172919800216

Epoch: 6| Step: 5
Training loss: 2.356205712668696
Validation loss: 2.572111371821316

Epoch: 6| Step: 6
Training loss: 2.133505013630968
Validation loss: 2.5769718249863893

Epoch: 6| Step: 7
Training loss: 2.2534260626716773
Validation loss: 2.567266288193758

Epoch: 6| Step: 8
Training loss: 2.98515717007968
Validation loss: 2.5587232406501577

Epoch: 6| Step: 9
Training loss: 1.9884632679302163
Validation loss: 2.582891846945902

Epoch: 6| Step: 10
Training loss: 2.446224542250445
Validation loss: 2.576859165352408

Epoch: 6| Step: 11
Training loss: 1.6075179116540046
Validation loss: 2.547038348055652

Epoch: 6| Step: 12
Training loss: 2.6780502611590293
Validation loss: 2.608561588899107

Epoch: 6| Step: 13
Training loss: 1.7518731038372164
Validation loss: 2.5769484792801145

Epoch: 255| Step: 0
Training loss: 2.3381167041964837
Validation loss: 2.591616722271695

Epoch: 6| Step: 1
Training loss: 1.4943834693378322
Validation loss: 2.56545493475673

Epoch: 6| Step: 2
Training loss: 1.8482394114722098
Validation loss: 2.605337754463823

Epoch: 6| Step: 3
Training loss: 2.000031113382562
Validation loss: 2.5785349741475923

Epoch: 6| Step: 4
Training loss: 2.4339499419557273
Validation loss: 2.554242094294205

Epoch: 6| Step: 5
Training loss: 3.0055957105974054
Validation loss: 2.565367482155683

Epoch: 6| Step: 6
Training loss: 2.1446139627150305
Validation loss: 2.556008855611338

Epoch: 6| Step: 7
Training loss: 1.3518393348789826
Validation loss: 2.540421530070464

Epoch: 6| Step: 8
Training loss: 1.4761364841988394
Validation loss: 2.54098358251379

Epoch: 6| Step: 9
Training loss: 3.004259423575645
Validation loss: 2.54611331963

Epoch: 6| Step: 10
Training loss: 2.40935949575381
Validation loss: 2.536316953213699

Epoch: 6| Step: 11
Training loss: 2.1716410558931853
Validation loss: 2.5178904392690917

Epoch: 6| Step: 12
Training loss: 1.6100973341526768
Validation loss: 2.5183924504033026

Epoch: 6| Step: 13
Training loss: 2.868891986333408
Validation loss: 2.5297878736343815

Epoch: 256| Step: 0
Training loss: 2.410066624587115
Validation loss: 2.506080901100728

Epoch: 6| Step: 1
Training loss: 2.48728359948854
Validation loss: 2.4969776799267813

Epoch: 6| Step: 2
Training loss: 1.9970754460126563
Validation loss: 2.508488018445492

Epoch: 6| Step: 3
Training loss: 2.5693753745845003
Validation loss: 2.489405499309069

Epoch: 6| Step: 4
Training loss: 2.111236429120044
Validation loss: 2.5007782360576347

Epoch: 6| Step: 5
Training loss: 2.6189771312459484
Validation loss: 2.490240039694333

Epoch: 6| Step: 6
Training loss: 1.557934614501367
Validation loss: 2.477725039929666

Epoch: 6| Step: 7
Training loss: 1.6250723309191484
Validation loss: 2.4974490104691407

Epoch: 6| Step: 8
Training loss: 3.0909324685910926
Validation loss: 2.5260867609672313

Epoch: 6| Step: 9
Training loss: 2.195985412639536
Validation loss: 2.5060252062663175

Epoch: 6| Step: 10
Training loss: 1.9499345279363933
Validation loss: 2.53660890627085

Epoch: 6| Step: 11
Training loss: 1.9523305879525505
Validation loss: 2.5051141881138874

Epoch: 6| Step: 12
Training loss: 1.742661552766585
Validation loss: 2.541624511827768

Epoch: 6| Step: 13
Training loss: 2.268193755254818
Validation loss: 2.5263778043390417

Epoch: 257| Step: 0
Training loss: 2.245039027157317
Validation loss: 2.545533495871768

Epoch: 6| Step: 1
Training loss: 1.8399282383400748
Validation loss: 2.5299395948670083

Epoch: 6| Step: 2
Training loss: 2.0971274393093284
Validation loss: 2.53482578594385

Epoch: 6| Step: 3
Training loss: 1.791337944155912
Validation loss: 2.4857073236340814

Epoch: 6| Step: 4
Training loss: 2.0106859833846
Validation loss: 2.5175842490268483

Epoch: 6| Step: 5
Training loss: 2.316049069018206
Validation loss: 2.5145281341317878

Epoch: 6| Step: 6
Training loss: 1.3937445379586384
Validation loss: 2.4983421391778764

Epoch: 6| Step: 7
Training loss: 2.877390655375557
Validation loss: 2.5165150491461685

Epoch: 6| Step: 8
Training loss: 2.591678481570806
Validation loss: 2.5125863498507144

Epoch: 6| Step: 9
Training loss: 2.3494270234920256
Validation loss: 2.5315359605554026

Epoch: 6| Step: 10
Training loss: 1.8123973948934604
Validation loss: 2.5287341420984912

Epoch: 6| Step: 11
Training loss: 2.8012340823346418
Validation loss: 2.5327988112948696

Epoch: 6| Step: 12
Training loss: 2.1240602547096463
Validation loss: 2.526059971903646

Epoch: 6| Step: 13
Training loss: 2.1291927039936396
Validation loss: 2.5286974575902947

Epoch: 258| Step: 0
Training loss: 2.091029663152835
Validation loss: 2.557200915143582

Epoch: 6| Step: 1
Training loss: 2.642357523098778
Validation loss: 2.510511710450546

Epoch: 6| Step: 2
Training loss: 1.9104311380562777
Validation loss: 2.5155824693200293

Epoch: 6| Step: 3
Training loss: 1.728295056769293
Validation loss: 2.5107169598252055

Epoch: 6| Step: 4
Training loss: 2.614528113360841
Validation loss: 2.5047055623558783

Epoch: 6| Step: 5
Training loss: 1.8949327810237462
Validation loss: 2.4910425089094828

Epoch: 6| Step: 6
Training loss: 1.7747268359108257
Validation loss: 2.4991712150095626

Epoch: 6| Step: 7
Training loss: 1.1498616010895208
Validation loss: 2.501602271337894

Epoch: 6| Step: 8
Training loss: 2.4988412078805946
Validation loss: 2.489661089163065

Epoch: 6| Step: 9
Training loss: 2.413962846692886
Validation loss: 2.5391072587200787

Epoch: 6| Step: 10
Training loss: 2.4622620908184887
Validation loss: 2.5103928233764763

Epoch: 6| Step: 11
Training loss: 1.9512773242823647
Validation loss: 2.512051320540854

Epoch: 6| Step: 12
Training loss: 2.6157062039366155
Validation loss: 2.562513615021551

Epoch: 6| Step: 13
Training loss: 2.5836421310282827
Validation loss: 2.5703283771306658

Epoch: 259| Step: 0
Training loss: 1.9225597867362771
Validation loss: 2.5717854941186866

Epoch: 6| Step: 1
Training loss: 1.409514558568751
Validation loss: 2.5530023334471093

Epoch: 6| Step: 2
Training loss: 2.1898975856993976
Validation loss: 2.548278601249734

Epoch: 6| Step: 3
Training loss: 1.800566091530517
Validation loss: 2.545105848203443

Epoch: 6| Step: 4
Training loss: 2.249274242759345
Validation loss: 2.5300154638508885

Epoch: 6| Step: 5
Training loss: 1.9089861759546511
Validation loss: 2.519158419049696

Epoch: 6| Step: 6
Training loss: 2.1607680601163883
Validation loss: 2.519142834593461

Epoch: 6| Step: 7
Training loss: 2.333569605536084
Validation loss: 2.540703158331828

Epoch: 6| Step: 8
Training loss: 3.0251163680968283
Validation loss: 2.5013551853678635

Epoch: 6| Step: 9
Training loss: 2.6355122384293974
Validation loss: 2.5086429128202306

Epoch: 6| Step: 10
Training loss: 2.4228536289856666
Validation loss: 2.484245152948869

Epoch: 6| Step: 11
Training loss: 2.262521868015218
Validation loss: 2.4889591716831894

Epoch: 6| Step: 12
Training loss: 2.392275371469993
Validation loss: 2.4969878806585344

Epoch: 6| Step: 13
Training loss: 1.9658012711369783
Validation loss: 2.499341719109214

Epoch: 260| Step: 0
Training loss: 2.472611413341267
Validation loss: 2.4905450604675474

Epoch: 6| Step: 1
Training loss: 1.683465018960078
Validation loss: 2.510609066714558

Epoch: 6| Step: 2
Training loss: 2.7010494488536465
Validation loss: 2.482931673499951

Epoch: 6| Step: 3
Training loss: 2.119430648716593
Validation loss: 2.4783844608744485

Epoch: 6| Step: 4
Training loss: 1.8793265334623492
Validation loss: 2.4954033077296645

Epoch: 6| Step: 5
Training loss: 2.0719278044034635
Validation loss: 2.5096267998245847

Epoch: 6| Step: 6
Training loss: 2.79805078779131
Validation loss: 2.5141312170348056

Epoch: 6| Step: 7
Training loss: 2.4687575328084246
Validation loss: 2.5124747887100893

Epoch: 6| Step: 8
Training loss: 1.6296200731909194
Validation loss: 2.5168187880698127

Epoch: 6| Step: 9
Training loss: 1.989259610294659
Validation loss: 2.5495441858393195

Epoch: 6| Step: 10
Training loss: 2.0930527622153914
Validation loss: 2.5447950080248996

Epoch: 6| Step: 11
Training loss: 2.1641810415694147
Validation loss: 2.5280880586230183

Epoch: 6| Step: 12
Training loss: 2.4249142189191377
Validation loss: 2.5523299947896745

Epoch: 6| Step: 13
Training loss: 2.010883283736415
Validation loss: 2.5593285667793713

Epoch: 261| Step: 0
Training loss: 2.4870215181003443
Validation loss: 2.562746253237902

Epoch: 6| Step: 1
Training loss: 1.538944685246171
Validation loss: 2.558294411734907

Epoch: 6| Step: 2
Training loss: 1.994444821102965
Validation loss: 2.593276015026612

Epoch: 6| Step: 3
Training loss: 3.265612150468141
Validation loss: 2.5461265540782385

Epoch: 6| Step: 4
Training loss: 2.507373331660547
Validation loss: 2.547392700875576

Epoch: 6| Step: 5
Training loss: 2.5560801964955537
Validation loss: 2.5741662968958123

Epoch: 6| Step: 6
Training loss: 2.287446685336477
Validation loss: 2.583794957621678

Epoch: 6| Step: 7
Training loss: 1.8215913005337998
Validation loss: 2.5419635651411143

Epoch: 6| Step: 8
Training loss: 2.375285282066896
Validation loss: 2.5064397364307425

Epoch: 6| Step: 9
Training loss: 1.6635671961988554
Validation loss: 2.517357658003854

Epoch: 6| Step: 10
Training loss: 1.8236717694703346
Validation loss: 2.5050146751075473

Epoch: 6| Step: 11
Training loss: 2.0253859164000234
Validation loss: 2.5124206511460323

Epoch: 6| Step: 12
Training loss: 2.471549173479065
Validation loss: 2.5089213295699384

Epoch: 6| Step: 13
Training loss: 1.620632464490619
Validation loss: 2.5040752415356877

Epoch: 262| Step: 0
Training loss: 2.597197390305597
Validation loss: 2.5054198167219544

Epoch: 6| Step: 1
Training loss: 2.5376060651588834
Validation loss: 2.521834605483162

Epoch: 6| Step: 2
Training loss: 2.29829477039468
Validation loss: 2.5286936783250087

Epoch: 6| Step: 3
Training loss: 1.7264614161939575
Validation loss: 2.5163741250145506

Epoch: 6| Step: 4
Training loss: 2.2955636153931556
Validation loss: 2.52352788584175

Epoch: 6| Step: 5
Training loss: 2.333640918440166
Validation loss: 2.524378708297324

Epoch: 6| Step: 6
Training loss: 2.1969583118426734
Validation loss: 2.5292911878053017

Epoch: 6| Step: 7
Training loss: 2.1410201327550156
Validation loss: 2.529081239676847

Epoch: 6| Step: 8
Training loss: 2.1466440934520645
Validation loss: 2.5451880955214823

Epoch: 6| Step: 9
Training loss: 2.1050715876930988
Validation loss: 2.5475472185265486

Epoch: 6| Step: 10
Training loss: 2.0614058164204163
Validation loss: 2.5391654908248773

Epoch: 6| Step: 11
Training loss: 1.6708362953495906
Validation loss: 2.5518915117277565

Epoch: 6| Step: 12
Training loss: 2.085220385094305
Validation loss: 2.523557047969611

Epoch: 6| Step: 13
Training loss: 2.554924910126855
Validation loss: 2.5061586498123734

Epoch: 263| Step: 0
Training loss: 2.3538155645556813
Validation loss: 2.516308314555262

Epoch: 6| Step: 1
Training loss: 2.43972187989888
Validation loss: 2.531388518385512

Epoch: 6| Step: 2
Training loss: 2.5065591597668573
Validation loss: 2.527615547796493

Epoch: 6| Step: 3
Training loss: 1.9907142128109203
Validation loss: 2.5173731666948593

Epoch: 6| Step: 4
Training loss: 1.687527197159487
Validation loss: 2.5328402449264686

Epoch: 6| Step: 5
Training loss: 1.8464132567627285
Validation loss: 2.5000256139714665

Epoch: 6| Step: 6
Training loss: 1.8760978663483474
Validation loss: 2.5188759594793795

Epoch: 6| Step: 7
Training loss: 2.335275307380478
Validation loss: 2.5283941634104106

Epoch: 6| Step: 8
Training loss: 2.214912426941751
Validation loss: 2.5383246499019716

Epoch: 6| Step: 9
Training loss: 1.9691429351569096
Validation loss: 2.559791381712563

Epoch: 6| Step: 10
Training loss: 2.4647588216474974
Validation loss: 2.5660528426409477

Epoch: 6| Step: 11
Training loss: 2.7072871804184904
Validation loss: 2.5589768605807817

Epoch: 6| Step: 12
Training loss: 2.1130975724532948
Validation loss: 2.5802098793350616

Epoch: 6| Step: 13
Training loss: 2.1202395354207115
Validation loss: 2.5904837422192384

Epoch: 264| Step: 0
Training loss: 2.1302304690329374
Validation loss: 2.556968129831277

Epoch: 6| Step: 1
Training loss: 2.077593398398985
Validation loss: 2.56502458219789

Epoch: 6| Step: 2
Training loss: 2.36483980600049
Validation loss: 2.556951019740959

Epoch: 6| Step: 3
Training loss: 2.840292201255565
Validation loss: 2.5119195504851946

Epoch: 6| Step: 4
Training loss: 2.088602827766869
Validation loss: 2.4935681495871815

Epoch: 6| Step: 5
Training loss: 1.3717138295661684
Validation loss: 2.4758407391420594

Epoch: 6| Step: 6
Training loss: 2.4214973401360846
Validation loss: 2.4861293972013

Epoch: 6| Step: 7
Training loss: 1.7365425930011418
Validation loss: 2.4846310273686685

Epoch: 6| Step: 8
Training loss: 2.455091914924975
Validation loss: 2.5055010512890346

Epoch: 6| Step: 9
Training loss: 2.344614098523698
Validation loss: 2.4827085780134306

Epoch: 6| Step: 10
Training loss: 2.34072130970238
Validation loss: 2.5171893608580485

Epoch: 6| Step: 11
Training loss: 1.8742675622242166
Validation loss: 2.511951180674639

Epoch: 6| Step: 12
Training loss: 2.044194453730037
Validation loss: 2.535957887590696

Epoch: 6| Step: 13
Training loss: 2.256232424849853
Validation loss: 2.573983536250437

Epoch: 265| Step: 0
Training loss: 1.8867497096078543
Validation loss: 2.566723320591703

Epoch: 6| Step: 1
Training loss: 1.4701760045258008
Validation loss: 2.580034138653249

Epoch: 6| Step: 2
Training loss: 1.842952232400016
Validation loss: 2.5806295386573432

Epoch: 6| Step: 3
Training loss: 2.386173466953333
Validation loss: 2.597463852107977

Epoch: 6| Step: 4
Training loss: 2.5285566152488173
Validation loss: 2.5808059624499595

Epoch: 6| Step: 5
Training loss: 3.08656107722612
Validation loss: 2.561413076982685

Epoch: 6| Step: 6
Training loss: 1.972508672349477
Validation loss: 2.551775253281066

Epoch: 6| Step: 7
Training loss: 2.2477566873957735
Validation loss: 2.5362420169359376

Epoch: 6| Step: 8
Training loss: 2.292966878393082
Validation loss: 2.549880674474959

Epoch: 6| Step: 9
Training loss: 2.203953688583242
Validation loss: 2.531769216526888

Epoch: 6| Step: 10
Training loss: 2.381286933191991
Validation loss: 2.500277487931592

Epoch: 6| Step: 11
Training loss: 2.051889349067798
Validation loss: 2.4747519147206356

Epoch: 6| Step: 12
Training loss: 2.412214540976656
Validation loss: 2.5152471033429786

Epoch: 6| Step: 13
Training loss: 2.2231933802870913
Validation loss: 2.5201474089373503

Epoch: 266| Step: 0
Training loss: 2.226847526644199
Validation loss: 2.549925165387274

Epoch: 6| Step: 1
Training loss: 2.552290325463885
Validation loss: 2.521197558065502

Epoch: 6| Step: 2
Training loss: 2.3584184539135045
Validation loss: 2.5300358030427037

Epoch: 6| Step: 3
Training loss: 2.268064146174197
Validation loss: 2.523182008641166

Epoch: 6| Step: 4
Training loss: 2.1433431255933617
Validation loss: 2.5146830594046627

Epoch: 6| Step: 5
Training loss: 2.0627588051920216
Validation loss: 2.5150827332799452

Epoch: 6| Step: 6
Training loss: 1.9986744898977404
Validation loss: 2.5152397887559754

Epoch: 6| Step: 7
Training loss: 1.6699878344977863
Validation loss: 2.515708842963408

Epoch: 6| Step: 8
Training loss: 2.977608404356151
Validation loss: 2.499642314754457

Epoch: 6| Step: 9
Training loss: 1.6717329588829162
Validation loss: 2.4939554415079455

Epoch: 6| Step: 10
Training loss: 2.268966315599882
Validation loss: 2.5151892969877236

Epoch: 6| Step: 11
Training loss: 2.363514685333189
Validation loss: 2.5254872188794764

Epoch: 6| Step: 12
Training loss: 1.9406883094277054
Validation loss: 2.527258091791263

Epoch: 6| Step: 13
Training loss: 1.9357416110807208
Validation loss: 2.5306004291226243

Epoch: 267| Step: 0
Training loss: 2.1172739834735017
Validation loss: 2.5463036050274184

Epoch: 6| Step: 1
Training loss: 2.048580478360164
Validation loss: 2.5328566707185147

Epoch: 6| Step: 2
Training loss: 1.9612659316087495
Validation loss: 2.5377184004981017

Epoch: 6| Step: 3
Training loss: 2.032550688764903
Validation loss: 2.5209988757757302

Epoch: 6| Step: 4
Training loss: 2.636404874981352
Validation loss: 2.515031282484436

Epoch: 6| Step: 5
Training loss: 2.8431821822149645
Validation loss: 2.5106967648413745

Epoch: 6| Step: 6
Training loss: 2.417691955993047
Validation loss: 2.499258010745085

Epoch: 6| Step: 7
Training loss: 2.227193321412037
Validation loss: 2.5025841073387736

Epoch: 6| Step: 8
Training loss: 2.2913382092533983
Validation loss: 2.4908091242117756

Epoch: 6| Step: 9
Training loss: 2.049760371833668
Validation loss: 2.5074539165883163

Epoch: 6| Step: 10
Training loss: 2.2756291997043627
Validation loss: 2.518345706193153

Epoch: 6| Step: 11
Training loss: 1.8721860751326653
Validation loss: 2.522080015966718

Epoch: 6| Step: 12
Training loss: 2.0876805027570184
Validation loss: 2.5358525727146315

Epoch: 6| Step: 13
Training loss: 1.3183233863722164
Validation loss: 2.552500995532423

Epoch: 268| Step: 0
Training loss: 2.713822119065102
Validation loss: 2.5426036222953945

Epoch: 6| Step: 1
Training loss: 1.6996067349574058
Validation loss: 2.517891425621135

Epoch: 6| Step: 2
Training loss: 2.158953644071534
Validation loss: 2.4928536715595895

Epoch: 6| Step: 3
Training loss: 2.1817726361693834
Validation loss: 2.4958886035877006

Epoch: 6| Step: 4
Training loss: 2.705865077600188
Validation loss: 2.5107409688540328

Epoch: 6| Step: 5
Training loss: 2.0791521330524874
Validation loss: 2.501348274965469

Epoch: 6| Step: 6
Training loss: 1.582966017362544
Validation loss: 2.492046675096471

Epoch: 6| Step: 7
Training loss: 1.7241581534975539
Validation loss: 2.5106657598439486

Epoch: 6| Step: 8
Training loss: 2.134962849349615
Validation loss: 2.508549091864691

Epoch: 6| Step: 9
Training loss: 2.713566629266904
Validation loss: 2.493254294719393

Epoch: 6| Step: 10
Training loss: 2.29458337762917
Validation loss: 2.527639364870909

Epoch: 6| Step: 11
Training loss: 2.0021478325665485
Validation loss: 2.506323747826174

Epoch: 6| Step: 12
Training loss: 1.7296735947350674
Validation loss: 2.4997010847045957

Epoch: 6| Step: 13
Training loss: 2.117501436163225
Validation loss: 2.514719039765344

Epoch: 269| Step: 0
Training loss: 2.0455944918913787
Validation loss: 2.528554273703149

Epoch: 6| Step: 1
Training loss: 2.0408024288696884
Validation loss: 2.5149726732714703

Epoch: 6| Step: 2
Training loss: 2.7601928812161143
Validation loss: 2.525600832721491

Epoch: 6| Step: 3
Training loss: 1.3366561652046094
Validation loss: 2.533392897855138

Epoch: 6| Step: 4
Training loss: 1.5174087567369487
Validation loss: 2.512873959902388

Epoch: 6| Step: 5
Training loss: 1.7375714513783367
Validation loss: 2.516351740966298

Epoch: 6| Step: 6
Training loss: 1.8099223914816474
Validation loss: 2.507677963942133

Epoch: 6| Step: 7
Training loss: 1.4808626883793468
Validation loss: 2.547643299882876

Epoch: 6| Step: 8
Training loss: 2.6031884963041074
Validation loss: 2.510045199525517

Epoch: 6| Step: 9
Training loss: 2.4220299455853165
Validation loss: 2.541669491208701

Epoch: 6| Step: 10
Training loss: 2.223109515857154
Validation loss: 2.5293463310600828

Epoch: 6| Step: 11
Training loss: 2.2569771775700396
Validation loss: 2.537117628906857

Epoch: 6| Step: 12
Training loss: 2.5465714911539603
Validation loss: 2.5493946834252306

Epoch: 6| Step: 13
Training loss: 2.4805020067283357
Validation loss: 2.5648866177138117

Epoch: 270| Step: 0
Training loss: 2.5001506760013408
Validation loss: 2.591186328871818

Epoch: 6| Step: 1
Training loss: 2.442173121746202
Validation loss: 2.585423029405837

Epoch: 6| Step: 2
Training loss: 2.0998893799483866
Validation loss: 2.5521817142960788

Epoch: 6| Step: 3
Training loss: 2.22226114901251
Validation loss: 2.5836657238488003

Epoch: 6| Step: 4
Training loss: 2.5281765964368463
Validation loss: 2.563317362368088

Epoch: 6| Step: 5
Training loss: 2.10843394445264
Validation loss: 2.547976733352494

Epoch: 6| Step: 6
Training loss: 2.5391871964572332
Validation loss: 2.5389702569882884

Epoch: 6| Step: 7
Training loss: 1.851929189691877
Validation loss: 2.5353473107394597

Epoch: 6| Step: 8
Training loss: 1.8512086167948516
Validation loss: 2.5697574653921564

Epoch: 6| Step: 9
Training loss: 1.827071122491529
Validation loss: 2.5688720036822166

Epoch: 6| Step: 10
Training loss: 2.173643860114907
Validation loss: 2.5812707224361224

Epoch: 6| Step: 11
Training loss: 1.950780880904707
Validation loss: 2.5018589896430656

Epoch: 6| Step: 12
Training loss: 2.1007183889770604
Validation loss: 2.5495447157530515

Epoch: 6| Step: 13
Training loss: 2.49048309879201
Validation loss: 2.516676246759568

Epoch: 271| Step: 0
Training loss: 1.6028223060550404
Validation loss: 2.5081405741954814

Epoch: 6| Step: 1
Training loss: 2.207549717862757
Validation loss: 2.5205923128109253

Epoch: 6| Step: 2
Training loss: 1.49728720450631
Validation loss: 2.504777817139872

Epoch: 6| Step: 3
Training loss: 3.0249339892538583
Validation loss: 2.4924002848543036

Epoch: 6| Step: 4
Training loss: 1.9739449399092814
Validation loss: 2.5023596833073434

Epoch: 6| Step: 5
Training loss: 2.6028412663132747
Validation loss: 2.493914198349606

Epoch: 6| Step: 6
Training loss: 2.6978226182567373
Validation loss: 2.483146955762866

Epoch: 6| Step: 7
Training loss: 2.756894226214733
Validation loss: 2.4979221451046776

Epoch: 6| Step: 8
Training loss: 2.3031986923540013
Validation loss: 2.4918774099970595

Epoch: 6| Step: 9
Training loss: 2.3289320398212476
Validation loss: 2.5002375887189667

Epoch: 6| Step: 10
Training loss: 1.828902446053585
Validation loss: 2.5080239433603806

Epoch: 6| Step: 11
Training loss: 1.7710810394571403
Validation loss: 2.5226237871781363

Epoch: 6| Step: 12
Training loss: 2.0207532362123284
Validation loss: 2.5331659953999965

Epoch: 6| Step: 13
Training loss: 2.211169119520728
Validation loss: 2.5340473588855015

Epoch: 272| Step: 0
Training loss: 2.8910885001075464
Validation loss: 2.525142554234258

Epoch: 6| Step: 1
Training loss: 2.0468069749550417
Validation loss: 2.500839362700212

Epoch: 6| Step: 2
Training loss: 2.070088385201556
Validation loss: 2.5070366773490136

Epoch: 6| Step: 3
Training loss: 1.8594451378167998
Validation loss: 2.5152871357166613

Epoch: 6| Step: 4
Training loss: 1.5879412240650486
Validation loss: 2.4881721684267304

Epoch: 6| Step: 5
Training loss: 1.555787507240284
Validation loss: 2.4738244967481964

Epoch: 6| Step: 6
Training loss: 2.2172871455032643
Validation loss: 2.4987806445976766

Epoch: 6| Step: 7
Training loss: 2.4332678807831414
Validation loss: 2.4858693680776733

Epoch: 6| Step: 8
Training loss: 2.5703211265349633
Validation loss: 2.4709200435903234

Epoch: 6| Step: 9
Training loss: 2.3825139093143135
Validation loss: 2.5285000089535123

Epoch: 6| Step: 10
Training loss: 2.200961085112854
Validation loss: 2.545043911158496

Epoch: 6| Step: 11
Training loss: 2.087955941301775
Validation loss: 2.520635499889002

Epoch: 6| Step: 12
Training loss: 2.227516906708371
Validation loss: 2.5656894435680218

Epoch: 6| Step: 13
Training loss: 1.9764947691157493
Validation loss: 2.5558194793567814

Epoch: 273| Step: 0
Training loss: 2.042690863592159
Validation loss: 2.5860560487001902

Epoch: 6| Step: 1
Training loss: 2.196982512142709
Validation loss: 2.5594974077115595

Epoch: 6| Step: 2
Training loss: 1.9162838249431235
Validation loss: 2.5746813345454593

Epoch: 6| Step: 3
Training loss: 2.421167085613366
Validation loss: 2.566717290585476

Epoch: 6| Step: 4
Training loss: 1.7094328373638328
Validation loss: 2.530245868273054

Epoch: 6| Step: 5
Training loss: 2.7114035785630892
Validation loss: 2.5480039625790782

Epoch: 6| Step: 6
Training loss: 1.1777889308661278
Validation loss: 2.5784199093234155

Epoch: 6| Step: 7
Training loss: 1.6052303833368113
Validation loss: 2.5486122244527283

Epoch: 6| Step: 8
Training loss: 2.647630056441323
Validation loss: 2.5054641534858093

Epoch: 6| Step: 9
Training loss: 2.1850290784494
Validation loss: 2.55197098672851

Epoch: 6| Step: 10
Training loss: 2.7427713582270656
Validation loss: 2.542659523909721

Epoch: 6| Step: 11
Training loss: 2.3640317119401324
Validation loss: 2.5222555725013915

Epoch: 6| Step: 12
Training loss: 1.9013969054640207
Validation loss: 2.529064019480556

Epoch: 6| Step: 13
Training loss: 2.4273645022573036
Validation loss: 2.529327211725847

Epoch: 274| Step: 0
Training loss: 2.3452253657146067
Validation loss: 2.5167054409130625

Epoch: 6| Step: 1
Training loss: 2.097370604205537
Validation loss: 2.4959261762856397

Epoch: 6| Step: 2
Training loss: 1.9408344370783015
Validation loss: 2.4887125149555454

Epoch: 6| Step: 3
Training loss: 2.1643571893993014
Validation loss: 2.5482430167708623

Epoch: 6| Step: 4
Training loss: 1.8419522718485917
Validation loss: 2.5380625315799454

Epoch: 6| Step: 5
Training loss: 2.0235715843755777
Validation loss: 2.5331978073593713

Epoch: 6| Step: 6
Training loss: 2.2679820460798035
Validation loss: 2.5115446561336348

Epoch: 6| Step: 7
Training loss: 1.936611402459552
Validation loss: 2.4762270406409326

Epoch: 6| Step: 8
Training loss: 1.8443772493644088
Validation loss: 2.4961376634057157

Epoch: 6| Step: 9
Training loss: 2.3157896408053618
Validation loss: 2.504922249070243

Epoch: 6| Step: 10
Training loss: 2.3361726470273445
Validation loss: 2.494316746072836

Epoch: 6| Step: 11
Training loss: 2.0115695342491606
Validation loss: 2.5242737682521033

Epoch: 6| Step: 12
Training loss: 2.2820836464398373
Validation loss: 2.4793627258053377

Epoch: 6| Step: 13
Training loss: 2.3829283639223084
Validation loss: 2.512585400953479

Epoch: 275| Step: 0
Training loss: 2.3994816299755937
Validation loss: 2.51241457779701

Epoch: 6| Step: 1
Training loss: 1.4192146313473246
Validation loss: 2.5010729633000612

Epoch: 6| Step: 2
Training loss: 1.653799943926671
Validation loss: 2.512042493903185

Epoch: 6| Step: 3
Training loss: 1.1523209909034289
Validation loss: 2.5444446349479386

Epoch: 6| Step: 4
Training loss: 1.9403830581691361
Validation loss: 2.537081966198257

Epoch: 6| Step: 5
Training loss: 2.5728539421888903
Validation loss: 2.5313865405018006

Epoch: 6| Step: 6
Training loss: 2.276754260446959
Validation loss: 2.5307510574963152

Epoch: 6| Step: 7
Training loss: 2.8571355002172303
Validation loss: 2.478078440372725

Epoch: 6| Step: 8
Training loss: 2.3343100093184908
Validation loss: 2.5016090936747397

Epoch: 6| Step: 9
Training loss: 1.7991815772711612
Validation loss: 2.4851956881324195

Epoch: 6| Step: 10
Training loss: 2.4038369105234696
Validation loss: 2.5110845877597923

Epoch: 6| Step: 11
Training loss: 1.5368366702381777
Validation loss: 2.493972641225067

Epoch: 6| Step: 12
Training loss: 2.635845847987053
Validation loss: 2.507905762266287

Epoch: 6| Step: 13
Training loss: 2.3961911694424374
Validation loss: 2.4768131983610515

Epoch: 276| Step: 0
Training loss: 1.717594521266193
Validation loss: 2.50326533850847

Epoch: 6| Step: 1
Training loss: 2.3156681525241796
Validation loss: 2.5275098224301877

Epoch: 6| Step: 2
Training loss: 2.5510203321028717
Validation loss: 2.5282381687054074

Epoch: 6| Step: 3
Training loss: 1.604741583844134
Validation loss: 2.532704206407197

Epoch: 6| Step: 4
Training loss: 1.5794984487421497
Validation loss: 2.526220096434428

Epoch: 6| Step: 5
Training loss: 2.4599558976724873
Validation loss: 2.5250985079141786

Epoch: 6| Step: 6
Training loss: 1.8116596510025156
Validation loss: 2.548935881342892

Epoch: 6| Step: 7
Training loss: 2.090225327496596
Validation loss: 2.5427235662391343

Epoch: 6| Step: 8
Training loss: 1.940245866827881
Validation loss: 2.5627352056098904

Epoch: 6| Step: 9
Training loss: 2.211370958089625
Validation loss: 2.552112444238001

Epoch: 6| Step: 10
Training loss: 2.7531378790113594
Validation loss: 2.5462653867855605

Epoch: 6| Step: 11
Training loss: 2.0855504509094414
Validation loss: 2.5559193541092577

Epoch: 6| Step: 12
Training loss: 2.626013787099028
Validation loss: 2.5458336009656533

Epoch: 6| Step: 13
Training loss: 1.9151979153901422
Validation loss: 2.5542672810072755

Epoch: 277| Step: 0
Training loss: 1.8963181710609631
Validation loss: 2.5144215740100804

Epoch: 6| Step: 1
Training loss: 2.5614272872907
Validation loss: 2.540846525562337

Epoch: 6| Step: 2
Training loss: 2.125378518892994
Validation loss: 2.4820498736255874

Epoch: 6| Step: 3
Training loss: 1.6262511791837788
Validation loss: 2.4953473666149213

Epoch: 6| Step: 4
Training loss: 2.3876104359275194
Validation loss: 2.4761788344808235

Epoch: 6| Step: 5
Training loss: 2.56502706085862
Validation loss: 2.466504214281335

Epoch: 6| Step: 6
Training loss: 1.3329457474676674
Validation loss: 2.4553278045222626

Epoch: 6| Step: 7
Training loss: 3.0040497466538554
Validation loss: 2.4522993638112256

Epoch: 6| Step: 8
Training loss: 1.4270395239720992
Validation loss: 2.493666756944774

Epoch: 6| Step: 9
Training loss: 2.223579094480428
Validation loss: 2.495281184729911

Epoch: 6| Step: 10
Training loss: 2.5519435506933323
Validation loss: 2.4635149018095226

Epoch: 6| Step: 11
Training loss: 2.2796553172192344
Validation loss: 2.4913358119968945

Epoch: 6| Step: 12
Training loss: 2.4811522495799614
Validation loss: 2.4766998333162733

Epoch: 6| Step: 13
Training loss: 1.9101469511652176
Validation loss: 2.4849919127007127

Epoch: 278| Step: 0
Training loss: 2.4462452045095433
Validation loss: 2.4881568290707956

Epoch: 6| Step: 1
Training loss: 2.3500369373421686
Validation loss: 2.518401160114668

Epoch: 6| Step: 2
Training loss: 2.5469122573842164
Validation loss: 2.5443106068704346

Epoch: 6| Step: 3
Training loss: 2.223726628284171
Validation loss: 2.567525587613714

Epoch: 6| Step: 4
Training loss: 1.7354618825284607
Validation loss: 2.577462621813102

Epoch: 6| Step: 5
Training loss: 1.437578613785343
Validation loss: 2.564680102516495

Epoch: 6| Step: 6
Training loss: 2.0498719152118783
Validation loss: 2.5361683553781265

Epoch: 6| Step: 7
Training loss: 2.4128266661857682
Validation loss: 2.5172982031901956

Epoch: 6| Step: 8
Training loss: 2.295928760167688
Validation loss: 2.494322736041715

Epoch: 6| Step: 9
Training loss: 2.15835380200827
Validation loss: 2.4909369860008765

Epoch: 6| Step: 10
Training loss: 2.1665908971400367
Validation loss: 2.4693903555296473

Epoch: 6| Step: 11
Training loss: 2.075145449768597
Validation loss: 2.4985240712136436

Epoch: 6| Step: 12
Training loss: 1.5345549437132116
Validation loss: 2.475797701574628

Epoch: 6| Step: 13
Training loss: 2.2915592052811102
Validation loss: 2.5030349747005896

Epoch: 279| Step: 0
Training loss: 2.113375000628149
Validation loss: 2.504815708622368

Epoch: 6| Step: 1
Training loss: 1.9345210770528312
Validation loss: 2.5211068995396553

Epoch: 6| Step: 2
Training loss: 1.9601811017817274
Validation loss: 2.5058902650367765

Epoch: 6| Step: 3
Training loss: 2.2088643521217457
Validation loss: 2.5153279494401444

Epoch: 6| Step: 4
Training loss: 2.912346301300505
Validation loss: 2.5035976749425823

Epoch: 6| Step: 5
Training loss: 2.09201285193819
Validation loss: 2.5148781404240363

Epoch: 6| Step: 6
Training loss: 2.1058014162777465
Validation loss: 2.5292892868340564

Epoch: 6| Step: 7
Training loss: 2.328571660763113
Validation loss: 2.532511863617946

Epoch: 6| Step: 8
Training loss: 2.289292047337545
Validation loss: 2.539635492863081

Epoch: 6| Step: 9
Training loss: 1.8780863473884981
Validation loss: 2.5109165902128616

Epoch: 6| Step: 10
Training loss: 2.4498280523256963
Validation loss: 2.5285397057830665

Epoch: 6| Step: 11
Training loss: 1.7791122189959692
Validation loss: 2.553045135705705

Epoch: 6| Step: 12
Training loss: 1.8980938635750884
Validation loss: 2.5239607167176947

Epoch: 6| Step: 13
Training loss: 1.9689919459312397
Validation loss: 2.5086616354070825

Epoch: 280| Step: 0
Training loss: 1.5851313604560107
Validation loss: 2.533191046567115

Epoch: 6| Step: 1
Training loss: 1.8986536224797608
Validation loss: 2.5254401732912

Epoch: 6| Step: 2
Training loss: 1.8339438794492486
Validation loss: 2.4881400283350676

Epoch: 6| Step: 3
Training loss: 1.5427987693158622
Validation loss: 2.5206541412810437

Epoch: 6| Step: 4
Training loss: 2.7555340656686766
Validation loss: 2.5221409414398597

Epoch: 6| Step: 5
Training loss: 1.3988232213850234
Validation loss: 2.5358107652097654

Epoch: 6| Step: 6
Training loss: 2.1214214935845215
Validation loss: 2.478494686662526

Epoch: 6| Step: 7
Training loss: 1.7697625756375337
Validation loss: 2.510588934172977

Epoch: 6| Step: 8
Training loss: 2.5658631004034893
Validation loss: 2.5089933995965503

Epoch: 6| Step: 9
Training loss: 2.318692756213571
Validation loss: 2.510941705104786

Epoch: 6| Step: 10
Training loss: 2.7463234687322737
Validation loss: 2.474694752092249

Epoch: 6| Step: 11
Training loss: 2.025880730389785
Validation loss: 2.5149355747270485

Epoch: 6| Step: 12
Training loss: 2.289339953588305
Validation loss: 2.4844236069248797

Epoch: 6| Step: 13
Training loss: 2.3229318341727936
Validation loss: 2.506833662847644

Epoch: 281| Step: 0
Training loss: 1.8370966072782526
Validation loss: 2.5048960426977604

Epoch: 6| Step: 1
Training loss: 1.9334513293903568
Validation loss: 2.541094470627322

Epoch: 6| Step: 2
Training loss: 1.9654070613589438
Validation loss: 2.5373027474291696

Epoch: 6| Step: 3
Training loss: 1.790287514617277
Validation loss: 2.555453280001007

Epoch: 6| Step: 4
Training loss: 2.4481549302609578
Validation loss: 2.49222262526167

Epoch: 6| Step: 5
Training loss: 2.187175399674857
Validation loss: 2.502499141864458

Epoch: 6| Step: 6
Training loss: 1.962314562935487
Validation loss: 2.463323617093544

Epoch: 6| Step: 7
Training loss: 1.7009720799948473
Validation loss: 2.4859631738270065

Epoch: 6| Step: 8
Training loss: 2.4736989310276196
Validation loss: 2.508330579821658

Epoch: 6| Step: 9
Training loss: 2.365093450655697
Validation loss: 2.4968745801763776

Epoch: 6| Step: 10
Training loss: 2.0954267705356564
Validation loss: 2.4826026608566267

Epoch: 6| Step: 11
Training loss: 2.2989494661184082
Validation loss: 2.515077693313007

Epoch: 6| Step: 12
Training loss: 2.610477785540193
Validation loss: 2.4808867655484215

Epoch: 6| Step: 13
Training loss: 1.9943403990208763
Validation loss: 2.5146948632951456

Epoch: 282| Step: 0
Training loss: 1.8843208697437859
Validation loss: 2.5866088456724308

Epoch: 6| Step: 1
Training loss: 2.140825248317912
Validation loss: 2.5655663604787824

Epoch: 6| Step: 2
Training loss: 1.9301402684367435
Validation loss: 2.5481669575693573

Epoch: 6| Step: 3
Training loss: 2.0613600152465543
Validation loss: 2.581187654347308

Epoch: 6| Step: 4
Training loss: 2.361225337338426
Validation loss: 2.5336826863668445

Epoch: 6| Step: 5
Training loss: 1.8665300432797272
Validation loss: 2.511020703807548

Epoch: 6| Step: 6
Training loss: 2.0277804747727575
Validation loss: 2.5019443739123317

Epoch: 6| Step: 7
Training loss: 2.138937849114716
Validation loss: 2.4783588717576492

Epoch: 6| Step: 8
Training loss: 1.9712042875438358
Validation loss: 2.479697424442692

Epoch: 6| Step: 9
Training loss: 2.3203768223539223
Validation loss: 2.4629157859410444

Epoch: 6| Step: 10
Training loss: 2.809340843188232
Validation loss: 2.458161628243978

Epoch: 6| Step: 11
Training loss: 2.140491342200467
Validation loss: 2.4510329897416643

Epoch: 6| Step: 12
Training loss: 2.135616038869936
Validation loss: 2.5000855749107127

Epoch: 6| Step: 13
Training loss: 2.3627816168647793
Validation loss: 2.48702870797283

Epoch: 283| Step: 0
Training loss: 1.5874324573956566
Validation loss: 2.515495059999344

Epoch: 6| Step: 1
Training loss: 2.6096361223785864
Validation loss: 2.5190576468006376

Epoch: 6| Step: 2
Training loss: 2.02088631891481
Validation loss: 2.504670834262776

Epoch: 6| Step: 3
Training loss: 2.133689839655273
Validation loss: 2.50833481749515

Epoch: 6| Step: 4
Training loss: 2.2393683278577687
Validation loss: 2.4868299003398247

Epoch: 6| Step: 5
Training loss: 2.2384146073110838
Validation loss: 2.4862739774846516

Epoch: 6| Step: 6
Training loss: 1.9573496180778553
Validation loss: 2.5030776153918075

Epoch: 6| Step: 7
Training loss: 1.8083536800288749
Validation loss: 2.486711431075661

Epoch: 6| Step: 8
Training loss: 3.1400230931690243
Validation loss: 2.4781490663095043

Epoch: 6| Step: 9
Training loss: 2.1864484166730236
Validation loss: 2.51925476292018

Epoch: 6| Step: 10
Training loss: 2.0291328547465577
Validation loss: 2.547038254449451

Epoch: 6| Step: 11
Training loss: 1.4147781331577758
Validation loss: 2.591779841520618

Epoch: 6| Step: 12
Training loss: 2.4865471323172925
Validation loss: 2.620437175989728

Epoch: 6| Step: 13
Training loss: 1.8225325116055886
Validation loss: 2.6714940385104047

Epoch: 284| Step: 0
Training loss: 2.35995385351162
Validation loss: 2.5679533392112344

Epoch: 6| Step: 1
Training loss: 2.545545359638778
Validation loss: 2.5386903852046316

Epoch: 6| Step: 2
Training loss: 2.1509847071559345
Validation loss: 2.4890840793272058

Epoch: 6| Step: 3
Training loss: 1.8722976920590966
Validation loss: 2.4825886636083303

Epoch: 6| Step: 4
Training loss: 2.022229633154698
Validation loss: 2.4683908128796466

Epoch: 6| Step: 5
Training loss: 1.9500461572906331
Validation loss: 2.4803547109586535

Epoch: 6| Step: 6
Training loss: 2.30825147334444
Validation loss: 2.5035259336887363

Epoch: 6| Step: 7
Training loss: 2.4363144167608777
Validation loss: 2.500672393021739

Epoch: 6| Step: 8
Training loss: 2.636325835163243
Validation loss: 2.4942011496006877

Epoch: 6| Step: 9
Training loss: 2.101830447675056
Validation loss: 2.5092512303696117

Epoch: 6| Step: 10
Training loss: 2.3703672499547834
Validation loss: 2.490814037799173

Epoch: 6| Step: 11
Training loss: 2.442954587148145
Validation loss: 2.5023131953944646

Epoch: 6| Step: 12
Training loss: 1.6163689204791907
Validation loss: 2.508600414247075

Epoch: 6| Step: 13
Training loss: 1.6424347115231737
Validation loss: 2.5273638119655506

Epoch: 285| Step: 0
Training loss: 1.8448716324186758
Validation loss: 2.5406667326642984

Epoch: 6| Step: 1
Training loss: 2.314196505584861
Validation loss: 2.5455544759695443

Epoch: 6| Step: 2
Training loss: 1.8166627764295635
Validation loss: 2.568291036375958

Epoch: 6| Step: 3
Training loss: 3.5637297264654424
Validation loss: 2.5275925558533467

Epoch: 6| Step: 4
Training loss: 1.7985480439442625
Validation loss: 2.574461898936163

Epoch: 6| Step: 5
Training loss: 2.2988611055275445
Validation loss: 2.5874022516040744

Epoch: 6| Step: 6
Training loss: 1.9248327430294576
Validation loss: 2.5854738401802146

Epoch: 6| Step: 7
Training loss: 1.491098535844433
Validation loss: 2.596994737419287

Epoch: 6| Step: 8
Training loss: 2.049184413655695
Validation loss: 2.53101832110575

Epoch: 6| Step: 9
Training loss: 1.4349216890399867
Validation loss: 2.552837063300767

Epoch: 6| Step: 10
Training loss: 2.839965313981694
Validation loss: 2.5266780300773943

Epoch: 6| Step: 11
Training loss: 2.2449659617674893
Validation loss: 2.5095603928226557

Epoch: 6| Step: 12
Training loss: 1.6141310848055517
Validation loss: 2.4791228239740115

Epoch: 6| Step: 13
Training loss: 1.9139382458274201
Validation loss: 2.4821958281382

Epoch: 286| Step: 0
Training loss: 2.320238927837169
Validation loss: 2.488184720916255

Epoch: 6| Step: 1
Training loss: 1.6595880231600284
Validation loss: 2.4682298909143525

Epoch: 6| Step: 2
Training loss: 2.1545062546992257
Validation loss: 2.4841849296365153

Epoch: 6| Step: 3
Training loss: 2.523229726262625
Validation loss: 2.517261233632133

Epoch: 6| Step: 4
Training loss: 1.675780609770966
Validation loss: 2.4619126824901305

Epoch: 6| Step: 5
Training loss: 1.9681723216410574
Validation loss: 2.5033253805827447

Epoch: 6| Step: 6
Training loss: 1.8404975911782484
Validation loss: 2.499246626826959

Epoch: 6| Step: 7
Training loss: 2.570449779056263
Validation loss: 2.4977490543596215

Epoch: 6| Step: 8
Training loss: 1.8933782785525402
Validation loss: 2.5234096592488306

Epoch: 6| Step: 9
Training loss: 1.648193630602157
Validation loss: 2.5597569274987433

Epoch: 6| Step: 10
Training loss: 2.480338313960997
Validation loss: 2.561353442472401

Epoch: 6| Step: 11
Training loss: 2.1373890273527762
Validation loss: 2.6085024305584206

Epoch: 6| Step: 12
Training loss: 2.292702030610557
Validation loss: 2.58762776893249

Epoch: 6| Step: 13
Training loss: 2.5195827271873066
Validation loss: 2.59889564871764

Epoch: 287| Step: 0
Training loss: 2.7008178214106673
Validation loss: 2.5538662320457135

Epoch: 6| Step: 1
Training loss: 2.528749714585956
Validation loss: 2.517564330101445

Epoch: 6| Step: 2
Training loss: 2.0345331508497813
Validation loss: 2.5133056690032576

Epoch: 6| Step: 3
Training loss: 2.0162415263878266
Validation loss: 2.4702499436418783

Epoch: 6| Step: 4
Training loss: 2.527395822734419
Validation loss: 2.455716386251408

Epoch: 6| Step: 5
Training loss: 1.929322119341258
Validation loss: 2.491623745955803

Epoch: 6| Step: 6
Training loss: 2.2732457869929186
Validation loss: 2.4680910478466993

Epoch: 6| Step: 7
Training loss: 1.8864199320779536
Validation loss: 2.463123105859952

Epoch: 6| Step: 8
Training loss: 1.677259953204201
Validation loss: 2.4861890220036793

Epoch: 6| Step: 9
Training loss: 1.9624373942308668
Validation loss: 2.478599248326631

Epoch: 6| Step: 10
Training loss: 1.9875051486350495
Validation loss: 2.48361047141338

Epoch: 6| Step: 11
Training loss: 1.6738024857648346
Validation loss: 2.4811074223139555

Epoch: 6| Step: 12
Training loss: 2.2267584463533
Validation loss: 2.481653374170281

Epoch: 6| Step: 13
Training loss: 1.615347880165848
Validation loss: 2.480291421313741

Epoch: 288| Step: 0
Training loss: 1.214416134265729
Validation loss: 2.471950548820342

Epoch: 6| Step: 1
Training loss: 2.1422360337516966
Validation loss: 2.4908497168532953

Epoch: 6| Step: 2
Training loss: 2.0887468828580964
Validation loss: 2.551853237029714

Epoch: 6| Step: 3
Training loss: 2.344125539575064
Validation loss: 2.5395520486591963

Epoch: 6| Step: 4
Training loss: 2.1949273582725377
Validation loss: 2.5692081339885386

Epoch: 6| Step: 5
Training loss: 2.104942808121842
Validation loss: 2.5620971688702303

Epoch: 6| Step: 6
Training loss: 2.369198086915217
Validation loss: 2.5410552983237498

Epoch: 6| Step: 7
Training loss: 2.3215349361659126
Validation loss: 2.5197078120542744

Epoch: 6| Step: 8
Training loss: 2.031459504107181
Validation loss: 2.5317746313386134

Epoch: 6| Step: 9
Training loss: 2.6117447012234747
Validation loss: 2.5465554581031147

Epoch: 6| Step: 10
Training loss: 2.024847769019048
Validation loss: 2.525175049508448

Epoch: 6| Step: 11
Training loss: 1.8741853851745054
Validation loss: 2.4749587248240776

Epoch: 6| Step: 12
Training loss: 1.7429069094286367
Validation loss: 2.482255875594501

Epoch: 6| Step: 13
Training loss: 2.1913897127829673
Validation loss: 2.4574571006965544

Epoch: 289| Step: 0
Training loss: 2.2693167238729615
Validation loss: 2.4646489166622865

Epoch: 6| Step: 1
Training loss: 2.104089288579257
Validation loss: 2.4864808120851434

Epoch: 6| Step: 2
Training loss: 1.92515210132881
Validation loss: 2.458449253215652

Epoch: 6| Step: 3
Training loss: 2.5748206029824146
Validation loss: 2.4598543720249855

Epoch: 6| Step: 4
Training loss: 2.6831181311547208
Validation loss: 2.461296572046847

Epoch: 6| Step: 5
Training loss: 1.968089159302709
Validation loss: 2.4796182691287845

Epoch: 6| Step: 6
Training loss: 2.0175328651218853
Validation loss: 2.48939138866958

Epoch: 6| Step: 7
Training loss: 2.402699117040581
Validation loss: 2.498355396059665

Epoch: 6| Step: 8
Training loss: 1.5934358174924315
Validation loss: 2.5227242673366015

Epoch: 6| Step: 9
Training loss: 1.6021669317226943
Validation loss: 2.5121579653857653

Epoch: 6| Step: 10
Training loss: 2.174754258227628
Validation loss: 2.575513684783879

Epoch: 6| Step: 11
Training loss: 2.0637846904868113
Validation loss: 2.5961875645258314

Epoch: 6| Step: 12
Training loss: 2.305612772751213
Validation loss: 2.614996726700805

Epoch: 6| Step: 13
Training loss: 1.7857448684253363
Validation loss: 2.6401979149941694

Epoch: 290| Step: 0
Training loss: 2.5376909982742517
Validation loss: 2.6316485902706197

Epoch: 6| Step: 1
Training loss: 1.4871437351354564
Validation loss: 2.6155727586348827

Epoch: 6| Step: 2
Training loss: 3.1618100284401693
Validation loss: 2.609058109617406

Epoch: 6| Step: 3
Training loss: 1.7848678790009926
Validation loss: 2.5865027663651614

Epoch: 6| Step: 4
Training loss: 1.9103536991348853
Validation loss: 2.5990494512716835

Epoch: 6| Step: 5
Training loss: 2.0789365402819024
Validation loss: 2.5733651350787206

Epoch: 6| Step: 6
Training loss: 2.9635146709122115
Validation loss: 2.584037966663841

Epoch: 6| Step: 7
Training loss: 1.9390022852521693
Validation loss: 2.585735578231035

Epoch: 6| Step: 8
Training loss: 2.0316915178956574
Validation loss: 2.58823940014131

Epoch: 6| Step: 9
Training loss: 1.7819828734297363
Validation loss: 2.569237419471527

Epoch: 6| Step: 10
Training loss: 1.9253397777961139
Validation loss: 2.603011543942975

Epoch: 6| Step: 11
Training loss: 1.3226963170084007
Validation loss: 2.5781875063322133

Epoch: 6| Step: 12
Training loss: 2.075948392766822
Validation loss: 2.5103738604387584

Epoch: 6| Step: 13
Training loss: 1.7152805336927066
Validation loss: 2.5421716678238147

Epoch: 291| Step: 0
Training loss: 1.8620470866017775
Validation loss: 2.511226370462783

Epoch: 6| Step: 1
Training loss: 2.3475900345539285
Validation loss: 2.502016684612992

Epoch: 6| Step: 2
Training loss: 2.139353130651168
Validation loss: 2.4612002923717395

Epoch: 6| Step: 3
Training loss: 2.1081356222256615
Validation loss: 2.475614035181708

Epoch: 6| Step: 4
Training loss: 2.3841821955051015
Validation loss: 2.491005564435974

Epoch: 6| Step: 5
Training loss: 2.405139220841667
Validation loss: 2.4742890682331975

Epoch: 6| Step: 6
Training loss: 1.7511711969827415
Validation loss: 2.4839887098776563

Epoch: 6| Step: 7
Training loss: 1.858077550257194
Validation loss: 2.5007994327283374

Epoch: 6| Step: 8
Training loss: 1.70186085112676
Validation loss: 2.502528834854853

Epoch: 6| Step: 9
Training loss: 2.271333960081924
Validation loss: 2.550681999733093

Epoch: 6| Step: 10
Training loss: 1.888763393957992
Validation loss: 2.534357079169354

Epoch: 6| Step: 11
Training loss: 2.47811186547665
Validation loss: 2.5463745155907653

Epoch: 6| Step: 12
Training loss: 2.0032768822754696
Validation loss: 2.5449181900915057

Epoch: 6| Step: 13
Training loss: 1.7803254656112821
Validation loss: 2.5439804572608353

Epoch: 292| Step: 0
Training loss: 1.9292095380047032
Validation loss: 2.5295646771181954

Epoch: 6| Step: 1
Training loss: 1.654483068587637
Validation loss: 2.516483578958893

Epoch: 6| Step: 2
Training loss: 2.0425182305296317
Validation loss: 2.5028435271425287

Epoch: 6| Step: 3
Training loss: 2.1147136804654902
Validation loss: 2.5043782678488715

Epoch: 6| Step: 4
Training loss: 1.3137225406437507
Validation loss: 2.5151342857159977

Epoch: 6| Step: 5
Training loss: 2.7900682874410054
Validation loss: 2.518451816271849

Epoch: 6| Step: 6
Training loss: 1.5158806024905391
Validation loss: 2.528908388209389

Epoch: 6| Step: 7
Training loss: 2.105612557052574
Validation loss: 2.517205154732741

Epoch: 6| Step: 8
Training loss: 2.22226447489094
Validation loss: 2.5525228991152282

Epoch: 6| Step: 9
Training loss: 1.9868462261025583
Validation loss: 2.505747490573177

Epoch: 6| Step: 10
Training loss: 2.801660290706474
Validation loss: 2.4820602637830413

Epoch: 6| Step: 11
Training loss: 2.0205073405026033
Validation loss: 2.493138656954952

Epoch: 6| Step: 12
Training loss: 1.9794802032544538
Validation loss: 2.482038570877948

Epoch: 6| Step: 13
Training loss: 2.040660013129225
Validation loss: 2.5102673376684086

Epoch: 293| Step: 0
Training loss: 2.21333242586799
Validation loss: 2.5210836827412364

Epoch: 6| Step: 1
Training loss: 2.0106850347784535
Validation loss: 2.496596538944968

Epoch: 6| Step: 2
Training loss: 1.9630185213696987
Validation loss: 2.516085564764018

Epoch: 6| Step: 3
Training loss: 2.404813461524408
Validation loss: 2.526437478008641

Epoch: 6| Step: 4
Training loss: 2.0664512470732914
Validation loss: 2.509727879498914

Epoch: 6| Step: 5
Training loss: 1.6735164392197845
Validation loss: 2.5227393650048384

Epoch: 6| Step: 6
Training loss: 2.0710069175542056
Validation loss: 2.531541579921005

Epoch: 6| Step: 7
Training loss: 2.4992314110900575
Validation loss: 2.508820660883263

Epoch: 6| Step: 8
Training loss: 2.412336306379798
Validation loss: 2.5272051671517812

Epoch: 6| Step: 9
Training loss: 2.1432917335867345
Validation loss: 2.5366914604151645

Epoch: 6| Step: 10
Training loss: 1.966455303030437
Validation loss: 2.550457437786933

Epoch: 6| Step: 11
Training loss: 1.6299817676343606
Validation loss: 2.5388190128269206

Epoch: 6| Step: 12
Training loss: 1.4760563704521725
Validation loss: 2.542419319548143

Epoch: 6| Step: 13
Training loss: 1.854169659844315
Validation loss: 2.5340337163673743

Epoch: 294| Step: 0
Training loss: 1.7710070655720582
Validation loss: 2.499528268176923

Epoch: 6| Step: 1
Training loss: 3.0267032462554955
Validation loss: 2.5430417379988524

Epoch: 6| Step: 2
Training loss: 1.6277433127370033
Validation loss: 2.5435229750792225

Epoch: 6| Step: 3
Training loss: 1.6742385841722072
Validation loss: 2.555368416322016

Epoch: 6| Step: 4
Training loss: 2.117329047282002
Validation loss: 2.559711986522893

Epoch: 6| Step: 5
Training loss: 1.4218941991159588
Validation loss: 2.5922963308674434

Epoch: 6| Step: 6
Training loss: 2.1962845031772376
Validation loss: 2.560179675571961

Epoch: 6| Step: 7
Training loss: 1.927284443301942
Validation loss: 2.5387103809825784

Epoch: 6| Step: 8
Training loss: 2.20009182391574
Validation loss: 2.563598676406964

Epoch: 6| Step: 9
Training loss: 2.561225760379175
Validation loss: 2.571758802530705

Epoch: 6| Step: 10
Training loss: 2.4899644653052113
Validation loss: 2.5376663986543972

Epoch: 6| Step: 11
Training loss: 1.6755376607634693
Validation loss: 2.501704858576904

Epoch: 6| Step: 12
Training loss: 1.813482544395593
Validation loss: 2.4934539686137955

Epoch: 6| Step: 13
Training loss: 1.5134209406417627
Validation loss: 2.5122577174009932

Epoch: 295| Step: 0
Training loss: 1.8537465023077226
Validation loss: 2.5277881182527793

Epoch: 6| Step: 1
Training loss: 1.8888325667243266
Validation loss: 2.523997100099932

Epoch: 6| Step: 2
Training loss: 1.9644183386580318
Validation loss: 2.535045541031955

Epoch: 6| Step: 3
Training loss: 2.0839241970136357
Validation loss: 2.5199977708988324

Epoch: 6| Step: 4
Training loss: 3.0171163557486436
Validation loss: 2.540504773663077

Epoch: 6| Step: 5
Training loss: 1.8643211805585365
Validation loss: 2.521721980145255

Epoch: 6| Step: 6
Training loss: 2.1886532604509155
Validation loss: 2.528896414967746

Epoch: 6| Step: 7
Training loss: 2.320783265519453
Validation loss: 2.5518061480863503

Epoch: 6| Step: 8
Training loss: 1.641277074655896
Validation loss: 2.5165067987211853

Epoch: 6| Step: 9
Training loss: 2.3124282413380723
Validation loss: 2.501520528923737

Epoch: 6| Step: 10
Training loss: 1.8646769864166488
Validation loss: 2.588095694999907

Epoch: 6| Step: 11
Training loss: 2.071085199074377
Validation loss: 2.615737817200634

Epoch: 6| Step: 12
Training loss: 2.041860363653554
Validation loss: 2.616421776345127

Epoch: 6| Step: 13
Training loss: 2.1824572613388793
Validation loss: 2.599914609289334

Epoch: 296| Step: 0
Training loss: 2.300811508316524
Validation loss: 2.5159362221353185

Epoch: 6| Step: 1
Training loss: 1.523096290915767
Validation loss: 2.4903872534006495

Epoch: 6| Step: 2
Training loss: 1.4656443938251191
Validation loss: 2.483169735143003

Epoch: 6| Step: 3
Training loss: 1.3779794317684249
Validation loss: 2.4754080985031806

Epoch: 6| Step: 4
Training loss: 2.1444832217982537
Validation loss: 2.498958116228975

Epoch: 6| Step: 5
Training loss: 2.05191421457373
Validation loss: 2.4654757117268566

Epoch: 6| Step: 6
Training loss: 1.7728630849748117
Validation loss: 2.46288768859898

Epoch: 6| Step: 7
Training loss: 1.603931071167879
Validation loss: 2.4867160571394646

Epoch: 6| Step: 8
Training loss: 2.1553828389273515
Validation loss: 2.4486782242084786

Epoch: 6| Step: 9
Training loss: 2.5886100488811477
Validation loss: 2.449662780260668

Epoch: 6| Step: 10
Training loss: 2.5067676494764957
Validation loss: 2.478316222642511

Epoch: 6| Step: 11
Training loss: 2.349193710635181
Validation loss: 2.4552757974666446

Epoch: 6| Step: 12
Training loss: 1.9908483454810388
Validation loss: 2.4887027593063573

Epoch: 6| Step: 13
Training loss: 1.9690582397395477
Validation loss: 2.487546563790957

Epoch: 297| Step: 0
Training loss: 2.1522247780044146
Validation loss: 2.5236139698347118

Epoch: 6| Step: 1
Training loss: 1.8507514819178303
Validation loss: 2.53045013725531

Epoch: 6| Step: 2
Training loss: 2.4030135546812743
Validation loss: 2.5496352670409874

Epoch: 6| Step: 3
Training loss: 1.793729998646517
Validation loss: 2.563900045625717

Epoch: 6| Step: 4
Training loss: 1.7469339759984641
Validation loss: 2.599544609365521

Epoch: 6| Step: 5
Training loss: 2.3032230185532097
Validation loss: 2.58426102521843

Epoch: 6| Step: 6
Training loss: 1.8431390946380655
Validation loss: 2.527816107276521

Epoch: 6| Step: 7
Training loss: 1.7780545668236785
Validation loss: 2.53274674766582

Epoch: 6| Step: 8
Training loss: 2.464461839593682
Validation loss: 2.499602683602293

Epoch: 6| Step: 9
Training loss: 1.592374170383531
Validation loss: 2.4651260980022336

Epoch: 6| Step: 10
Training loss: 2.1671776780261385
Validation loss: 2.4988297902596095

Epoch: 6| Step: 11
Training loss: 2.266782372924757
Validation loss: 2.4430683307218506

Epoch: 6| Step: 12
Training loss: 1.5607246994663775
Validation loss: 2.434086838962675

Epoch: 6| Step: 13
Training loss: 2.7075474895000364
Validation loss: 2.47129024721752

Epoch: 298| Step: 0
Training loss: 2.0567018331347695
Validation loss: 2.4497213055921736

Epoch: 6| Step: 1
Training loss: 2.154445390605451
Validation loss: 2.4647101171091106

Epoch: 6| Step: 2
Training loss: 1.7296992328249314
Validation loss: 2.4694030155596733

Epoch: 6| Step: 3
Training loss: 1.6665956084680282
Validation loss: 2.537621379636438

Epoch: 6| Step: 4
Training loss: 2.285690062684044
Validation loss: 2.538918249483112

Epoch: 6| Step: 5
Training loss: 2.029111587539305
Validation loss: 2.6059307430381162

Epoch: 6| Step: 6
Training loss: 1.8169920930244252
Validation loss: 2.595370525620142

Epoch: 6| Step: 7
Training loss: 2.401697980723803
Validation loss: 2.542526683286009

Epoch: 6| Step: 8
Training loss: 1.8607930137729454
Validation loss: 2.608402276473682

Epoch: 6| Step: 9
Training loss: 2.567678847282261
Validation loss: 2.554911565724555

Epoch: 6| Step: 10
Training loss: 1.8959931386590092
Validation loss: 2.5771933982081316

Epoch: 6| Step: 11
Training loss: 1.9074256898496948
Validation loss: 2.63000184309282

Epoch: 6| Step: 12
Training loss: 2.179815582559338
Validation loss: 2.5488497639367216

Epoch: 6| Step: 13
Training loss: 2.4674481206539878
Validation loss: 2.571421931651792

Epoch: 299| Step: 0
Training loss: 2.3755794621343034
Validation loss: 2.571144881349076

Epoch: 6| Step: 1
Training loss: 2.102435189607866
Validation loss: 2.590627230530911

Epoch: 6| Step: 2
Training loss: 1.5549464944545375
Validation loss: 2.561171893071803

Epoch: 6| Step: 3
Training loss: 2.274934151503458
Validation loss: 2.57448223426899

Epoch: 6| Step: 4
Training loss: 1.8515976528259155
Validation loss: 2.5346522758506125

Epoch: 6| Step: 5
Training loss: 2.7272813609015474
Validation loss: 2.5713817841950917

Epoch: 6| Step: 6
Training loss: 2.466407147063901
Validation loss: 2.5432943203093332

Epoch: 6| Step: 7
Training loss: 1.8769862780386959
Validation loss: 2.555322939426227

Epoch: 6| Step: 8
Training loss: 1.6769951112024228
Validation loss: 2.53947164515762

Epoch: 6| Step: 9
Training loss: 2.097267498456744
Validation loss: 2.5418166105931617

Epoch: 6| Step: 10
Training loss: 1.755731868675806
Validation loss: 2.5301156975749617

Epoch: 6| Step: 11
Training loss: 1.8932082128261611
Validation loss: 2.521007355812556

Epoch: 6| Step: 12
Training loss: 2.3117946889457746
Validation loss: 2.4955525734423993

Epoch: 6| Step: 13
Training loss: 2.070021353348876
Validation loss: 2.5211441594535575

Epoch: 300| Step: 0
Training loss: 1.8467088653663988
Validation loss: 2.496012543584613

Epoch: 6| Step: 1
Training loss: 2.588267034830701
Validation loss: 2.524703913661786

Epoch: 6| Step: 2
Training loss: 1.6760556723240838
Validation loss: 2.5274452766886126

Epoch: 6| Step: 3
Training loss: 1.3816089457168723
Validation loss: 2.5059904647477285

Epoch: 6| Step: 4
Training loss: 2.1982646383446496
Validation loss: 2.5048876984804527

Epoch: 6| Step: 5
Training loss: 1.647289292054905
Validation loss: 2.5401935503523845

Epoch: 6| Step: 6
Training loss: 1.934153034743438
Validation loss: 2.5080097473468204

Epoch: 6| Step: 7
Training loss: 2.066129669544206
Validation loss: 2.492773483409073

Epoch: 6| Step: 8
Training loss: 2.499499556997542
Validation loss: 2.4772591117580696

Epoch: 6| Step: 9
Training loss: 1.6836982570703745
Validation loss: 2.4756392112682937

Epoch: 6| Step: 10
Training loss: 1.6526340382935258
Validation loss: 2.512468644321321

Epoch: 6| Step: 11
Training loss: 2.971104701962624
Validation loss: 2.536639265204002

Epoch: 6| Step: 12
Training loss: 1.4666055485966771
Validation loss: 2.51226992811054

Epoch: 6| Step: 13
Training loss: 1.9955086345060458
Validation loss: 2.556585091263868

Epoch: 301| Step: 0
Training loss: 1.9334648320541445
Validation loss: 2.5338665033074768

Epoch: 6| Step: 1
Training loss: 2.1548999485235902
Validation loss: 2.513512034003733

Epoch: 6| Step: 2
Training loss: 2.3076560347714072
Validation loss: 2.4971058305549847

Epoch: 6| Step: 3
Training loss: 1.7624558220054407
Validation loss: 2.4776237933413494

Epoch: 6| Step: 4
Training loss: 2.0939360578624417
Validation loss: 2.4501864576426784

Epoch: 6| Step: 5
Training loss: 2.575208644376753
Validation loss: 2.4629639854869882

Epoch: 6| Step: 6
Training loss: 1.7797787261972324
Validation loss: 2.4588630288795366

Epoch: 6| Step: 7
Training loss: 1.8393374513817582
Validation loss: 2.471912250005035

Epoch: 6| Step: 8
Training loss: 2.3679148749374312
Validation loss: 2.485309752866446

Epoch: 6| Step: 9
Training loss: 1.9332568559099568
Validation loss: 2.480855227822163

Epoch: 6| Step: 10
Training loss: 2.060267077789608
Validation loss: 2.503334364943751

Epoch: 6| Step: 11
Training loss: 1.8809264300822826
Validation loss: 2.4793994110446844

Epoch: 6| Step: 12
Training loss: 1.714259158791627
Validation loss: 2.4736261941244204

Epoch: 6| Step: 13
Training loss: 2.292490296754093
Validation loss: 2.5122124882259733

Epoch: 302| Step: 0
Training loss: 1.7414860018732448
Validation loss: 2.4828128981945055

Epoch: 6| Step: 1
Training loss: 2.168772285632752
Validation loss: 2.4850581927173065

Epoch: 6| Step: 2
Training loss: 1.856190045348615
Validation loss: 2.4805032242108935

Epoch: 6| Step: 3
Training loss: 2.120685460819324
Validation loss: 2.48305566011916

Epoch: 6| Step: 4
Training loss: 1.4915468927953934
Validation loss: 2.479388761322729

Epoch: 6| Step: 5
Training loss: 1.348810602687984
Validation loss: 2.4679562061067912

Epoch: 6| Step: 6
Training loss: 2.6132119116828867
Validation loss: 2.5067446010561008

Epoch: 6| Step: 7
Training loss: 2.410348646500495
Validation loss: 2.5487005014245017

Epoch: 6| Step: 8
Training loss: 1.4979322804931334
Validation loss: 2.554471985789842

Epoch: 6| Step: 9
Training loss: 2.1324834884236874
Validation loss: 2.559016690229473

Epoch: 6| Step: 10
Training loss: 2.8542180485984794
Validation loss: 2.5514320684369456

Epoch: 6| Step: 11
Training loss: 1.637531233627981
Validation loss: 2.5519797609033907

Epoch: 6| Step: 12
Training loss: 2.1925394049031874
Validation loss: 2.527577235635634

Epoch: 6| Step: 13
Training loss: 1.489131734545403
Validation loss: 2.538952524786774

Epoch: 303| Step: 0
Training loss: 1.6437013394075477
Validation loss: 2.5133346493445208

Epoch: 6| Step: 1
Training loss: 2.1290082714588467
Validation loss: 2.4863157709039023

Epoch: 6| Step: 2
Training loss: 1.9687417650807437
Validation loss: 2.505397160340649

Epoch: 6| Step: 3
Training loss: 2.479779870200353
Validation loss: 2.487700006696644

Epoch: 6| Step: 4
Training loss: 2.2129124962718265
Validation loss: 2.5178770169520837

Epoch: 6| Step: 5
Training loss: 1.7334596435056808
Validation loss: 2.4862115977015993

Epoch: 6| Step: 6
Training loss: 2.741569079794837
Validation loss: 2.5035132993966176

Epoch: 6| Step: 7
Training loss: 2.266740195633799
Validation loss: 2.523421264848162

Epoch: 6| Step: 8
Training loss: 1.5769850135434622
Validation loss: 2.5049314894479453

Epoch: 6| Step: 9
Training loss: 2.702107320623659
Validation loss: 2.5206175992935718

Epoch: 6| Step: 10
Training loss: 1.340768700569725
Validation loss: 2.5161115598361166

Epoch: 6| Step: 11
Training loss: 1.7237374509004673
Validation loss: 2.536755293134618

Epoch: 6| Step: 12
Training loss: 1.9414088289485512
Validation loss: 2.586419943131429

Epoch: 6| Step: 13
Training loss: 1.5754332294752031
Validation loss: 2.5568339811665375

Epoch: 304| Step: 0
Training loss: 1.8865489053986746
Validation loss: 2.529694632696283

Epoch: 6| Step: 1
Training loss: 2.1691571252031467
Validation loss: 2.5111738674889073

Epoch: 6| Step: 2
Training loss: 1.4115710993503368
Validation loss: 2.557070881207871

Epoch: 6| Step: 3
Training loss: 2.560988189586619
Validation loss: 2.5259922035854068

Epoch: 6| Step: 4
Training loss: 1.456108230435312
Validation loss: 2.5322756945787495

Epoch: 6| Step: 5
Training loss: 1.5373691596207077
Validation loss: 2.538239816265053

Epoch: 6| Step: 6
Training loss: 1.9048008647976018
Validation loss: 2.573142629937815

Epoch: 6| Step: 7
Training loss: 2.3016798146190225
Validation loss: 2.5745457782548824

Epoch: 6| Step: 8
Training loss: 2.2283404830593465
Validation loss: 2.5461341544908818

Epoch: 6| Step: 9
Training loss: 2.276142621511111
Validation loss: 2.519364312528671

Epoch: 6| Step: 10
Training loss: 1.3487432104581503
Validation loss: 2.5211498019813416

Epoch: 6| Step: 11
Training loss: 2.0834958076700354
Validation loss: 2.5026677362080347

Epoch: 6| Step: 12
Training loss: 1.9498405000060561
Validation loss: 2.5037817485165736

Epoch: 6| Step: 13
Training loss: 1.9560673637569785
Validation loss: 2.5053444162525946

Epoch: 305| Step: 0
Training loss: 1.831115038067939
Validation loss: 2.488492205194671

Epoch: 6| Step: 1
Training loss: 1.4936105224101828
Validation loss: 2.550353282566082

Epoch: 6| Step: 2
Training loss: 1.6982844447822645
Validation loss: 2.492715092123911

Epoch: 6| Step: 3
Training loss: 1.7477904403388422
Validation loss: 2.5022918051065184

Epoch: 6| Step: 4
Training loss: 2.4238360925093163
Validation loss: 2.520260924512987

Epoch: 6| Step: 5
Training loss: 2.2042893383404962
Validation loss: 2.5033668893308185

Epoch: 6| Step: 6
Training loss: 2.3938150501625572
Validation loss: 2.5727563620190166

Epoch: 6| Step: 7
Training loss: 1.8336763783493415
Validation loss: 2.588904178239519

Epoch: 6| Step: 8
Training loss: 2.1029461131318437
Validation loss: 2.559315594677349

Epoch: 6| Step: 9
Training loss: 1.8490914381946637
Validation loss: 2.577986187521286

Epoch: 6| Step: 10
Training loss: 1.8720648362025405
Validation loss: 2.5714699748783074

Epoch: 6| Step: 11
Training loss: 1.7624724609171438
Validation loss: 2.5305011253723766

Epoch: 6| Step: 12
Training loss: 2.070483967140247
Validation loss: 2.535185975859066

Epoch: 6| Step: 13
Training loss: 1.7522001060493646
Validation loss: 2.5229127887556375

Epoch: 306| Step: 0
Training loss: 1.701597456139518
Validation loss: 2.5579738341577216

Epoch: 6| Step: 1
Training loss: 2.4815649298759412
Validation loss: 2.525123434543384

Epoch: 6| Step: 2
Training loss: 1.8076292559995222
Validation loss: 2.5473058605248426

Epoch: 6| Step: 3
Training loss: 1.8976146029114713
Validation loss: 2.5433303099381392

Epoch: 6| Step: 4
Training loss: 1.8599982619533828
Validation loss: 2.538406506429445

Epoch: 6| Step: 5
Training loss: 1.921748211407862
Validation loss: 2.5473110083199324

Epoch: 6| Step: 6
Training loss: 1.8955112085798402
Validation loss: 2.6025352454142583

Epoch: 6| Step: 7
Training loss: 1.7900866779460531
Validation loss: 2.5923746131536043

Epoch: 6| Step: 8
Training loss: 1.5731963441635086
Validation loss: 2.6079454446393173

Epoch: 6| Step: 9
Training loss: 2.0060962511135125
Validation loss: 2.569587288285361

Epoch: 6| Step: 10
Training loss: 2.3010636109433538
Validation loss: 2.5278090805751803

Epoch: 6| Step: 11
Training loss: 1.97831479528537
Validation loss: 2.5343566166359577

Epoch: 6| Step: 12
Training loss: 1.6138115627799776
Validation loss: 2.5289806349920343

Epoch: 6| Step: 13
Training loss: 2.1704324006698954
Validation loss: 2.5589075725957535

Epoch: 307| Step: 0
Training loss: 1.9191829776885176
Validation loss: 2.545777300786698

Epoch: 6| Step: 1
Training loss: 2.3864751963114688
Validation loss: 2.5404861919025574

Epoch: 6| Step: 2
Training loss: 1.6271347549004227
Validation loss: 2.5340646314625728

Epoch: 6| Step: 3
Training loss: 2.0952291245908383
Validation loss: 2.5479570988098064

Epoch: 6| Step: 4
Training loss: 1.3469370374088891
Validation loss: 2.532468659400636

Epoch: 6| Step: 5
Training loss: 1.9161766987794822
Validation loss: 2.5537444696601463

Epoch: 6| Step: 6
Training loss: 2.096804085227366
Validation loss: 2.5320243514423186

Epoch: 6| Step: 7
Training loss: 1.8740116693505893
Validation loss: 2.520531476025631

Epoch: 6| Step: 8
Training loss: 1.5022508105464532
Validation loss: 2.5498011966575747

Epoch: 6| Step: 9
Training loss: 1.8506315442104508
Validation loss: 2.504990642920992

Epoch: 6| Step: 10
Training loss: 2.204141585189907
Validation loss: 2.547486666693468

Epoch: 6| Step: 11
Training loss: 2.4511495034462154
Validation loss: 2.529867006357199

Epoch: 6| Step: 12
Training loss: 1.555181530233683
Validation loss: 2.5456195225396416

Epoch: 6| Step: 13
Training loss: 2.2120249739370133
Validation loss: 2.5356899849720573

Epoch: 308| Step: 0
Training loss: 1.9208696418469522
Validation loss: 2.54834007764597

Epoch: 6| Step: 1
Training loss: 2.073669935707778
Validation loss: 2.5403434769486686

Epoch: 6| Step: 2
Training loss: 2.382252811926228
Validation loss: 2.515449762657945

Epoch: 6| Step: 3
Training loss: 1.9153433115020209
Validation loss: 2.5094683638100768

Epoch: 6| Step: 4
Training loss: 1.7455402495465022
Validation loss: 2.5149130593725495

Epoch: 6| Step: 5
Training loss: 1.8833766108016272
Validation loss: 2.5089369775178434

Epoch: 6| Step: 6
Training loss: 1.8912055645328316
Validation loss: 2.4512056832179385

Epoch: 6| Step: 7
Training loss: 0.9285136914905129
Validation loss: 2.4493797529193446

Epoch: 6| Step: 8
Training loss: 2.0603215822111953
Validation loss: 2.473028298621896

Epoch: 6| Step: 9
Training loss: 2.1481773635124783
Validation loss: 2.482139157118985

Epoch: 6| Step: 10
Training loss: 2.016508160291562
Validation loss: 2.4891320674838497

Epoch: 6| Step: 11
Training loss: 2.005491228501495
Validation loss: 2.485109576502826

Epoch: 6| Step: 12
Training loss: 2.2927964517822814
Validation loss: 2.4384693598357616

Epoch: 6| Step: 13
Training loss: 1.7588429461268038
Validation loss: 2.4789732422158477

Epoch: 309| Step: 0
Training loss: 1.4869328996594298
Validation loss: 2.4544023723353345

Epoch: 6| Step: 1
Training loss: 2.11309509021495
Validation loss: 2.5068059626472508

Epoch: 6| Step: 2
Training loss: 2.0125453398910516
Validation loss: 2.46398160257789

Epoch: 6| Step: 3
Training loss: 2.5113344743950687
Validation loss: 2.5089557375048863

Epoch: 6| Step: 4
Training loss: 1.4985617258967452
Validation loss: 2.506862630827074

Epoch: 6| Step: 5
Training loss: 2.1681282053550146
Validation loss: 2.5195576195729243

Epoch: 6| Step: 6
Training loss: 1.745574737491727
Validation loss: 2.506625630426661

Epoch: 6| Step: 7
Training loss: 2.7367498929110927
Validation loss: 2.5381741578740544

Epoch: 6| Step: 8
Training loss: 1.5335745780628711
Validation loss: 2.5027264986231317

Epoch: 6| Step: 9
Training loss: 1.466087850595196
Validation loss: 2.4751449683789795

Epoch: 6| Step: 10
Training loss: 1.4768971059002811
Validation loss: 2.461908574736876

Epoch: 6| Step: 11
Training loss: 1.3036602339010794
Validation loss: 2.480034289020457

Epoch: 6| Step: 12
Training loss: 1.4859535256533467
Validation loss: 2.488908785383798

Epoch: 6| Step: 13
Training loss: 2.584600650479864
Validation loss: 2.4781534678366177

Epoch: 310| Step: 0
Training loss: 1.9523454865336853
Validation loss: 2.488244504073382

Epoch: 6| Step: 1
Training loss: 2.133271220415612
Validation loss: 2.5297150058833533

Epoch: 6| Step: 2
Training loss: 1.964597895201851
Validation loss: 2.582604356684014

Epoch: 6| Step: 3
Training loss: 2.2874096836958775
Validation loss: 2.5865076863597274

Epoch: 6| Step: 4
Training loss: 1.8631905907541975
Validation loss: 2.5842727573255426

Epoch: 6| Step: 5
Training loss: 1.737006450783847
Validation loss: 2.590541946865235

Epoch: 6| Step: 6
Training loss: 1.771719213563539
Validation loss: 2.5889936598759937

Epoch: 6| Step: 7
Training loss: 1.5702318768657209
Validation loss: 2.5460635961943865

Epoch: 6| Step: 8
Training loss: 1.665715287787097
Validation loss: 2.51720871445793

Epoch: 6| Step: 9
Training loss: 2.5901089585704393
Validation loss: 2.5125813997661948

Epoch: 6| Step: 10
Training loss: 1.699185075097352
Validation loss: 2.5017539388524526

Epoch: 6| Step: 11
Training loss: 2.1163971611720562
Validation loss: 2.523811635408949

Epoch: 6| Step: 12
Training loss: 2.062800992330564
Validation loss: 2.546632220782589

Epoch: 6| Step: 13
Training loss: 2.2970607967875347
Validation loss: 2.5615685018205636

Epoch: 311| Step: 0
Training loss: 2.008873803739445
Validation loss: 2.5545284676704374

Epoch: 6| Step: 1
Training loss: 1.5995510961701203
Validation loss: 2.591181873984624

Epoch: 6| Step: 2
Training loss: 1.663732361617622
Validation loss: 2.5925724773030305

Epoch: 6| Step: 3
Training loss: 1.8805101175358088
Validation loss: 2.585331164802611

Epoch: 6| Step: 4
Training loss: 1.5323172761846022
Validation loss: 2.5794829828379187

Epoch: 6| Step: 5
Training loss: 1.5163636914530367
Validation loss: 2.570403339979905

Epoch: 6| Step: 6
Training loss: 1.9954249984345294
Validation loss: 2.5423179219433463

Epoch: 6| Step: 7
Training loss: 2.1003627827043894
Validation loss: 2.5076274149918123

Epoch: 6| Step: 8
Training loss: 1.8810618005443205
Validation loss: 2.47732374202653

Epoch: 6| Step: 9
Training loss: 2.1933613316025333
Validation loss: 2.461731797658615

Epoch: 6| Step: 10
Training loss: 2.5022372725429194
Validation loss: 2.4370435955816516

Epoch: 6| Step: 11
Training loss: 2.2050369299393244
Validation loss: 2.4448407807934207

Epoch: 6| Step: 12
Training loss: 1.6408744985603363
Validation loss: 2.488505786005291

Epoch: 6| Step: 13
Training loss: 2.50957961524951
Validation loss: 2.4785790321329793

Epoch: 312| Step: 0
Training loss: 1.288176769787688
Validation loss: 2.4807523950715598

Epoch: 6| Step: 1
Training loss: 2.1583784351521476
Validation loss: 2.5025263736845482

Epoch: 6| Step: 2
Training loss: 1.5416884893299048
Validation loss: 2.5065604438578313

Epoch: 6| Step: 3
Training loss: 1.7157122035698515
Validation loss: 2.5136460443971154

Epoch: 6| Step: 4
Training loss: 1.9919168924283845
Validation loss: 2.537060571464951

Epoch: 6| Step: 5
Training loss: 1.6943149004682845
Validation loss: 2.5349832641330017

Epoch: 6| Step: 6
Training loss: 1.735679067470812
Validation loss: 2.5337227332804892

Epoch: 6| Step: 7
Training loss: 1.6718446960554925
Validation loss: 2.5528517416154

Epoch: 6| Step: 8
Training loss: 2.2028136337695137
Validation loss: 2.5771030442746627

Epoch: 6| Step: 9
Training loss: 1.994702356263156
Validation loss: 2.537541924993126

Epoch: 6| Step: 10
Training loss: 2.1168106700942584
Validation loss: 2.5047925708520262

Epoch: 6| Step: 11
Training loss: 1.8790368809960682
Validation loss: 2.497503862374813

Epoch: 6| Step: 12
Training loss: 2.277459535877868
Validation loss: 2.4918205764423895

Epoch: 6| Step: 13
Training loss: 2.070992757492627
Validation loss: 2.5093832988926406

Epoch: 313| Step: 0
Training loss: 2.0411922396671374
Validation loss: 2.542295867917284

Epoch: 6| Step: 1
Training loss: 2.089853561235731
Validation loss: 2.519797267226868

Epoch: 6| Step: 2
Training loss: 2.1214626265485528
Validation loss: 2.531519353530524

Epoch: 6| Step: 3
Training loss: 1.9214485129437313
Validation loss: 2.542600027796729

Epoch: 6| Step: 4
Training loss: 1.569257239295411
Validation loss: 2.571307050770254

Epoch: 6| Step: 5
Training loss: 1.823430938839651
Validation loss: 2.5054468423369114

Epoch: 6| Step: 6
Training loss: 1.9565371805309626
Validation loss: 2.503517918221859

Epoch: 6| Step: 7
Training loss: 1.5963825100928266
Validation loss: 2.53000613446805

Epoch: 6| Step: 8
Training loss: 1.8102126322243877
Validation loss: 2.5076771003400955

Epoch: 6| Step: 9
Training loss: 1.7985854259540595
Validation loss: 2.524233870528395

Epoch: 6| Step: 10
Training loss: 1.890487918140191
Validation loss: 2.5357642088900074

Epoch: 6| Step: 11
Training loss: 1.9534743950178504
Validation loss: 2.530914072422167

Epoch: 6| Step: 12
Training loss: 2.358794892595987
Validation loss: 2.5258319466172905

Epoch: 6| Step: 13
Training loss: 1.9350480592658936
Validation loss: 2.5261274002050955

Epoch: 314| Step: 0
Training loss: 2.4026146712708547
Validation loss: 2.5545738264919176

Epoch: 6| Step: 1
Training loss: 1.4224038450596763
Validation loss: 2.581528669067206

Epoch: 6| Step: 2
Training loss: 1.806996375447086
Validation loss: 2.6066710420931156

Epoch: 6| Step: 3
Training loss: 1.2558232090134156
Validation loss: 2.617415772157392

Epoch: 6| Step: 4
Training loss: 1.7438886060968009
Validation loss: 2.628201024017684

Epoch: 6| Step: 5
Training loss: 1.472309911663528
Validation loss: 2.56244870266316

Epoch: 6| Step: 6
Training loss: 1.455539952664471
Validation loss: 2.5932556814991234

Epoch: 6| Step: 7
Training loss: 1.9671159653992785
Validation loss: 2.549586064270256

Epoch: 6| Step: 8
Training loss: 2.1781119391379504
Validation loss: 2.5661104245636985

Epoch: 6| Step: 9
Training loss: 1.9392784324254366
Validation loss: 2.517349205135092

Epoch: 6| Step: 10
Training loss: 2.2971739282519783
Validation loss: 2.516317615766004

Epoch: 6| Step: 11
Training loss: 2.3643633926433396
Validation loss: 2.5417417348396696

Epoch: 6| Step: 12
Training loss: 2.558645559470679
Validation loss: 2.5002289428785427

Epoch: 6| Step: 13
Training loss: 1.5478655793430798
Validation loss: 2.5266571527325445

Epoch: 315| Step: 0
Training loss: 1.6471431043442961
Validation loss: 2.5043867089639082

Epoch: 6| Step: 1
Training loss: 2.3055424543057015
Validation loss: 2.5383338939201083

Epoch: 6| Step: 2
Training loss: 1.978638896509917
Validation loss: 2.5375584612847173

Epoch: 6| Step: 3
Training loss: 1.3629200629053315
Validation loss: 2.535571831808731

Epoch: 6| Step: 4
Training loss: 1.8373962450901977
Validation loss: 2.539524603632185

Epoch: 6| Step: 5
Training loss: 1.6230772821215302
Validation loss: 2.55558045750616

Epoch: 6| Step: 6
Training loss: 1.8217979558812833
Validation loss: 2.533463487502422

Epoch: 6| Step: 7
Training loss: 2.3016739102893444
Validation loss: 2.476091911780789

Epoch: 6| Step: 8
Training loss: 2.6064373543633192
Validation loss: 2.5159319340894597

Epoch: 6| Step: 9
Training loss: 1.5050314917073608
Validation loss: 2.568528101882143

Epoch: 6| Step: 10
Training loss: 1.6999045906220789
Validation loss: 2.5537075764796238

Epoch: 6| Step: 11
Training loss: 2.535927583177959
Validation loss: 2.5658991528954505

Epoch: 6| Step: 12
Training loss: 1.6308897095560195
Validation loss: 2.571971848535006

Epoch: 6| Step: 13
Training loss: 1.365929640741021
Validation loss: 2.5069612541821016

Epoch: 316| Step: 0
Training loss: 1.8549764200855725
Validation loss: 2.5239501211988165

Epoch: 6| Step: 1
Training loss: 1.7890196549395112
Validation loss: 2.501327146490304

Epoch: 6| Step: 2
Training loss: 1.755939078723193
Validation loss: 2.4830354962115573

Epoch: 6| Step: 3
Training loss: 2.500090883510391
Validation loss: 2.476388377617896

Epoch: 6| Step: 4
Training loss: 1.5864573411276761
Validation loss: 2.4872205740249798

Epoch: 6| Step: 5
Training loss: 2.091923500595213
Validation loss: 2.450104654114033

Epoch: 6| Step: 6
Training loss: 1.601084270253787
Validation loss: 2.4657915714212995

Epoch: 6| Step: 7
Training loss: 1.9114114892470397
Validation loss: 2.4716806440629115

Epoch: 6| Step: 8
Training loss: 1.7843213288741726
Validation loss: 2.4682770610047

Epoch: 6| Step: 9
Training loss: 1.7228073780434132
Validation loss: 2.474149087612376

Epoch: 6| Step: 10
Training loss: 1.3211824609534144
Validation loss: 2.4714979901015885

Epoch: 6| Step: 11
Training loss: 2.1974818686994757
Validation loss: 2.4807521548031324

Epoch: 6| Step: 12
Training loss: 1.9706034337396263
Validation loss: 2.497248932008779

Epoch: 6| Step: 13
Training loss: 2.0954676173153537
Validation loss: 2.472163379757102

Epoch: 317| Step: 0
Training loss: 2.1022448938575162
Validation loss: 2.491852134852915

Epoch: 6| Step: 1
Training loss: 1.6132847968332682
Validation loss: 2.4934801597848746

Epoch: 6| Step: 2
Training loss: 2.0047265468966162
Validation loss: 2.476562836944846

Epoch: 6| Step: 3
Training loss: 1.6811322763061307
Validation loss: 2.5175527764211494

Epoch: 6| Step: 4
Training loss: 2.0994158704435653
Validation loss: 2.5284724911101124

Epoch: 6| Step: 5
Training loss: 1.8707434977462145
Validation loss: 2.5177226038696587

Epoch: 6| Step: 6
Training loss: 1.676957435700114
Validation loss: 2.538516505297623

Epoch: 6| Step: 7
Training loss: 1.6234014424495156
Validation loss: 2.5329127717609166

Epoch: 6| Step: 8
Training loss: 2.052371267911851
Validation loss: 2.547679547816808

Epoch: 6| Step: 9
Training loss: 1.8196399412207995
Validation loss: 2.52698109779791

Epoch: 6| Step: 10
Training loss: 1.986180722929246
Validation loss: 2.5202093429250167

Epoch: 6| Step: 11
Training loss: 1.8855262921183713
Validation loss: 2.506769448639322

Epoch: 6| Step: 12
Training loss: 1.812227162839661
Validation loss: 2.4961436808432147

Epoch: 6| Step: 13
Training loss: 1.724107126996672
Validation loss: 2.4848494486549635

Epoch: 318| Step: 0
Training loss: 2.434112738412751
Validation loss: 2.507412919230904

Epoch: 6| Step: 1
Training loss: 1.815219680270237
Validation loss: 2.48449991419989

Epoch: 6| Step: 2
Training loss: 1.6384865038737624
Validation loss: 2.468604924570864

Epoch: 6| Step: 3
Training loss: 1.8107403072659718
Validation loss: 2.48882293793553

Epoch: 6| Step: 4
Training loss: 1.5272393934887234
Validation loss: 2.45790709555815

Epoch: 6| Step: 5
Training loss: 1.871782848911108
Validation loss: 2.495427774606406

Epoch: 6| Step: 6
Training loss: 2.0837485726116487
Validation loss: 2.5268833973396183

Epoch: 6| Step: 7
Training loss: 1.7604330238921637
Validation loss: 2.5243006943334207

Epoch: 6| Step: 8
Training loss: 1.9482760854272188
Validation loss: 2.5528258404815323

Epoch: 6| Step: 9
Training loss: 1.3150423041671577
Validation loss: 2.572898560948058

Epoch: 6| Step: 10
Training loss: 1.6112732294152727
Validation loss: 2.521592102192195

Epoch: 6| Step: 11
Training loss: 2.084922629368505
Validation loss: 2.513367945494307

Epoch: 6| Step: 12
Training loss: 1.6088349260204882
Validation loss: 2.508325922333002

Epoch: 6| Step: 13
Training loss: 2.36282783130989
Validation loss: 2.4947031492538616

Epoch: 319| Step: 0
Training loss: 1.7764387907976344
Validation loss: 2.4848870283578632

Epoch: 6| Step: 1
Training loss: 1.430508820635559
Validation loss: 2.499594178640174

Epoch: 6| Step: 2
Training loss: 2.443415481813594
Validation loss: 2.499376243024375

Epoch: 6| Step: 3
Training loss: 1.751543726552492
Validation loss: 2.473480015074231

Epoch: 6| Step: 4
Training loss: 1.4932842917280122
Validation loss: 2.5095127794723586

Epoch: 6| Step: 5
Training loss: 2.2004968645645127
Validation loss: 2.495523418445291

Epoch: 6| Step: 6
Training loss: 2.7110731107449313
Validation loss: 2.544233001042465

Epoch: 6| Step: 7
Training loss: 1.6851067703332914
Validation loss: 2.5933779024455506

Epoch: 6| Step: 8
Training loss: 2.43435838177044
Validation loss: 2.6331281614250654

Epoch: 6| Step: 9
Training loss: 1.7170421091024974
Validation loss: 2.619135057034265

Epoch: 6| Step: 10
Training loss: 1.55595737141954
Validation loss: 2.5783649371461785

Epoch: 6| Step: 11
Training loss: 1.6675963510932263
Validation loss: 2.5851822102544855

Epoch: 6| Step: 12
Training loss: 1.6931488715847987
Validation loss: 2.548974698701013

Epoch: 6| Step: 13
Training loss: 1.6490119547829882
Validation loss: 2.5501907856946255

Epoch: 320| Step: 0
Training loss: 2.217988864206853
Validation loss: 2.5536588567476493

Epoch: 6| Step: 1
Training loss: 1.591813350662435
Validation loss: 2.5545033379766457

Epoch: 6| Step: 2
Training loss: 2.091217559179766
Validation loss: 2.523216198487335

Epoch: 6| Step: 3
Training loss: 2.30103511737417
Validation loss: 2.528598621266834

Epoch: 6| Step: 4
Training loss: 0.9581474801230114
Validation loss: 2.542554220936133

Epoch: 6| Step: 5
Training loss: 1.718686189333942
Validation loss: 2.560645122180547

Epoch: 6| Step: 6
Training loss: 1.6755800637719056
Validation loss: 2.5883917864282515

Epoch: 6| Step: 7
Training loss: 2.4387147273060044
Validation loss: 2.6187862238961976

Epoch: 6| Step: 8
Training loss: 1.4742182130716597
Validation loss: 2.627924077672888

Epoch: 6| Step: 9
Training loss: 1.6911918380897644
Validation loss: 2.635073648276462

Epoch: 6| Step: 10
Training loss: 2.3583622457756155
Validation loss: 2.598733503648034

Epoch: 6| Step: 11
Training loss: 1.9315376832877087
Validation loss: 2.587976057453829

Epoch: 6| Step: 12
Training loss: 1.4248915313128505
Validation loss: 2.4757984799970916

Epoch: 6| Step: 13
Training loss: 1.6642559100300123
Validation loss: 2.491857939388191

Epoch: 321| Step: 0
Training loss: 1.6634892295578168
Validation loss: 2.439184747760755

Epoch: 6| Step: 1
Training loss: 1.562041329773646
Validation loss: 2.469989674607084

Epoch: 6| Step: 2
Training loss: 1.244385076967724
Validation loss: 2.4655043920197928

Epoch: 6| Step: 3
Training loss: 2.288737511592943
Validation loss: 2.4686321439658183

Epoch: 6| Step: 4
Training loss: 1.8008301701386276
Validation loss: 2.434881303441287

Epoch: 6| Step: 5
Training loss: 2.1738703501696977
Validation loss: 2.482112758227897

Epoch: 6| Step: 6
Training loss: 1.7962648102024328
Validation loss: 2.4460245625236587

Epoch: 6| Step: 7
Training loss: 1.3060491161019383
Validation loss: 2.438089739542818

Epoch: 6| Step: 8
Training loss: 2.283046903070783
Validation loss: 2.517810859113063

Epoch: 6| Step: 9
Training loss: 2.2772926599650867
Validation loss: 2.5537317414952865

Epoch: 6| Step: 10
Training loss: 1.758656210279482
Validation loss: 2.5424391453354733

Epoch: 6| Step: 11
Training loss: 2.1371404869730886
Validation loss: 2.539803843721062

Epoch: 6| Step: 12
Training loss: 2.1792730121909503
Validation loss: 2.5007399735465055

Epoch: 6| Step: 13
Training loss: 1.2286193512761387
Validation loss: 2.4960415177509336

Epoch: 322| Step: 0
Training loss: 1.883957763838275
Validation loss: 2.516098664987323

Epoch: 6| Step: 1
Training loss: 2.2290635367331855
Validation loss: 2.478299611735917

Epoch: 6| Step: 2
Training loss: 1.5263734354878522
Validation loss: 2.498807543241008

Epoch: 6| Step: 3
Training loss: 2.6140786908657847
Validation loss: 2.5162690722264953

Epoch: 6| Step: 4
Training loss: 1.0361236082885246
Validation loss: 2.4839081235562883

Epoch: 6| Step: 5
Training loss: 1.9613995862507416
Validation loss: 2.469864517246557

Epoch: 6| Step: 6
Training loss: 1.6840687942316472
Validation loss: 2.479424156045937

Epoch: 6| Step: 7
Training loss: 2.1389760815681766
Validation loss: 2.4675982158584358

Epoch: 6| Step: 8
Training loss: 2.142882222074252
Validation loss: 2.490847650943913

Epoch: 6| Step: 9
Training loss: 1.9944111699357292
Validation loss: 2.5775316576735596

Epoch: 6| Step: 10
Training loss: 1.6487125691524136
Validation loss: 2.59153676877859

Epoch: 6| Step: 11
Training loss: 1.9662905877659866
Validation loss: 2.5821229703909103

Epoch: 6| Step: 12
Training loss: 1.4895628369750775
Validation loss: 2.5030025412536068

Epoch: 6| Step: 13
Training loss: 2.3431875952832826
Validation loss: 2.480804084278227

Epoch: 323| Step: 0
Training loss: 2.1554016434668095
Validation loss: 2.4441064657537592

Epoch: 6| Step: 1
Training loss: 1.3684567037081246
Validation loss: 2.4683857097731137

Epoch: 6| Step: 2
Training loss: 1.3564731713133134
Validation loss: 2.4976659369497107

Epoch: 6| Step: 3
Training loss: 2.207988376186016
Validation loss: 2.5184565023685255

Epoch: 6| Step: 4
Training loss: 1.895723388613881
Validation loss: 2.549067218815589

Epoch: 6| Step: 5
Training loss: 2.1105216971418335
Validation loss: 2.533985425967402

Epoch: 6| Step: 6
Training loss: 2.374269774761998
Validation loss: 2.517161308924254

Epoch: 6| Step: 7
Training loss: 1.4703328146428039
Validation loss: 2.5338226713684593

Epoch: 6| Step: 8
Training loss: 1.3195488431129243
Validation loss: 2.5902239720333107

Epoch: 6| Step: 9
Training loss: 1.8727120745649053
Validation loss: 2.5938999944618777

Epoch: 6| Step: 10
Training loss: 1.809128288882288
Validation loss: 2.5670766046880944

Epoch: 6| Step: 11
Training loss: 2.5713330130002836
Validation loss: 2.5688963122129524

Epoch: 6| Step: 12
Training loss: 1.8619766626585728
Validation loss: 2.5216412681347675

Epoch: 6| Step: 13
Training loss: 2.0417999950652934
Validation loss: 2.5303205031534226

Epoch: 324| Step: 0
Training loss: 1.9933575952556724
Validation loss: 2.5273041129996123

Epoch: 6| Step: 1
Training loss: 2.0540411915349255
Validation loss: 2.540409485957645

Epoch: 6| Step: 2
Training loss: 1.5903400518152446
Validation loss: 2.5227718676073363

Epoch: 6| Step: 3
Training loss: 2.312558353821919
Validation loss: 2.537404666481589

Epoch: 6| Step: 4
Training loss: 1.7830942879059952
Validation loss: 2.548639018130908

Epoch: 6| Step: 5
Training loss: 1.3909711085595604
Validation loss: 2.5443177754117117

Epoch: 6| Step: 6
Training loss: 1.785915488760766
Validation loss: 2.532631689289853

Epoch: 6| Step: 7
Training loss: 2.0306379129616214
Validation loss: 2.552969974463285

Epoch: 6| Step: 8
Training loss: 2.263405495374817
Validation loss: 2.5978183322906645

Epoch: 6| Step: 9
Training loss: 1.7169419922758276
Validation loss: 2.597062565547955

Epoch: 6| Step: 10
Training loss: 1.6894799379194547
Validation loss: 2.592521238543514

Epoch: 6| Step: 11
Training loss: 2.12747967720411
Validation loss: 2.5995831143117782

Epoch: 6| Step: 12
Training loss: 1.6869055089350558
Validation loss: 2.526022312575193

Epoch: 6| Step: 13
Training loss: 1.511373081164727
Validation loss: 2.5118932905604567

Epoch: 325| Step: 0
Training loss: 1.6630197042558348
Validation loss: 2.494625155016202

Epoch: 6| Step: 1
Training loss: 1.4493195120852276
Validation loss: 2.542391960176624

Epoch: 6| Step: 2
Training loss: 1.515115396618218
Validation loss: 2.5711562483007255

Epoch: 6| Step: 3
Training loss: 1.8528988035950953
Validation loss: 2.5753854549507853

Epoch: 6| Step: 4
Training loss: 1.938283208241025
Validation loss: 2.596738548993706

Epoch: 6| Step: 5
Training loss: 1.5666650572558856
Validation loss: 2.5703633621269706

Epoch: 6| Step: 6
Training loss: 1.8184175901999609
Validation loss: 2.5725129205832156

Epoch: 6| Step: 7
Training loss: 1.7419924776547717
Validation loss: 2.5694169761862

Epoch: 6| Step: 8
Training loss: 2.245211910789943
Validation loss: 2.523337441931957

Epoch: 6| Step: 9
Training loss: 2.396848866943178
Validation loss: 2.5143652974446526

Epoch: 6| Step: 10
Training loss: 2.1996987396659766
Validation loss: 2.5291003294471954

Epoch: 6| Step: 11
Training loss: 1.9062957132830476
Validation loss: 2.535121296395289

Epoch: 6| Step: 12
Training loss: 1.9794741207704143
Validation loss: 2.611147980621336

Epoch: 6| Step: 13
Training loss: 2.4737342063704197
Validation loss: 2.6753743031626263

Epoch: 326| Step: 0
Training loss: 1.798608225947373
Validation loss: 2.668375292401852

Epoch: 6| Step: 1
Training loss: 1.970134429992332
Validation loss: 2.6648427765866

Epoch: 6| Step: 2
Training loss: 2.4867279618236737
Validation loss: 2.6963477979740422

Epoch: 6| Step: 3
Training loss: 2.4014770929442135
Validation loss: 2.731245695295513

Epoch: 6| Step: 4
Training loss: 1.5705696768377537
Validation loss: 2.6579790509079855

Epoch: 6| Step: 5
Training loss: 2.061220176578186
Validation loss: 2.643310039517044

Epoch: 6| Step: 6
Training loss: 1.3186976472126197
Validation loss: 2.6245890098841858

Epoch: 6| Step: 7
Training loss: 2.0988111673135434
Validation loss: 2.5745241700800667

Epoch: 6| Step: 8
Training loss: 1.1190000648839418
Validation loss: 2.511113174392149

Epoch: 6| Step: 9
Training loss: 1.4327442448290268
Validation loss: 2.4926606609049036

Epoch: 6| Step: 10
Training loss: 1.9092984447959016
Validation loss: 2.5031784912311994

Epoch: 6| Step: 11
Training loss: 1.6889277175920983
Validation loss: 2.5356207031760207

Epoch: 6| Step: 12
Training loss: 2.070915393495495
Validation loss: 2.5320796470328593

Epoch: 6| Step: 13
Training loss: 1.514437888961477
Validation loss: 2.550197158621543

Epoch: 327| Step: 0
Training loss: 1.9389616467409427
Validation loss: 2.5573313309234376

Epoch: 6| Step: 1
Training loss: 2.669037589450577
Validation loss: 2.5202847559064616

Epoch: 6| Step: 2
Training loss: 1.7309066872747618
Validation loss: 2.5449113901722056

Epoch: 6| Step: 3
Training loss: 1.6074258055702626
Validation loss: 2.5572786402063024

Epoch: 6| Step: 4
Training loss: 1.8706453618331629
Validation loss: 2.527749879447867

Epoch: 6| Step: 5
Training loss: 1.971646796561967
Validation loss: 2.571523549202928

Epoch: 6| Step: 6
Training loss: 2.2671064071822515
Validation loss: 2.5978451002879144

Epoch: 6| Step: 7
Training loss: 1.8408323575948764
Validation loss: 2.613301944698242

Epoch: 6| Step: 8
Training loss: 1.9178908073919039
Validation loss: 2.5766303922346045

Epoch: 6| Step: 9
Training loss: 1.449617068928947
Validation loss: 2.5513964812165146

Epoch: 6| Step: 10
Training loss: 1.7478046952742963
Validation loss: 2.5424584473921894

Epoch: 6| Step: 11
Training loss: 1.560727907453678
Validation loss: 2.51916463387681

Epoch: 6| Step: 12
Training loss: 1.3934683716205793
Validation loss: 2.5219251433110093

Epoch: 6| Step: 13
Training loss: 1.3471631903458205
Validation loss: 2.466757569914826

Epoch: 328| Step: 0
Training loss: 1.4149496762388591
Validation loss: 2.492080622407244

Epoch: 6| Step: 1
Training loss: 1.398348331272473
Validation loss: 2.5133799927104863

Epoch: 6| Step: 2
Training loss: 1.568059187078574
Validation loss: 2.5151466246498533

Epoch: 6| Step: 3
Training loss: 1.8180004712178677
Validation loss: 2.4824406672901174

Epoch: 6| Step: 4
Training loss: 1.7903355229649103
Validation loss: 2.507213778541326

Epoch: 6| Step: 5
Training loss: 2.2425568705038113
Validation loss: 2.4832000913226917

Epoch: 6| Step: 6
Training loss: 2.1286464147626845
Validation loss: 2.503193643289925

Epoch: 6| Step: 7
Training loss: 1.5901515203530996
Validation loss: 2.4718265437067912

Epoch: 6| Step: 8
Training loss: 1.8312029887860373
Validation loss: 2.506579007618048

Epoch: 6| Step: 9
Training loss: 1.6051100727020255
Validation loss: 2.5399599650874882

Epoch: 6| Step: 10
Training loss: 1.8559596004734256
Validation loss: 2.5600743171713014

Epoch: 6| Step: 11
Training loss: 2.6256812891820744
Validation loss: 2.6086824301313176

Epoch: 6| Step: 12
Training loss: 1.1648208912705138
Validation loss: 2.5990897828969914

Epoch: 6| Step: 13
Training loss: 1.9491276843981464
Validation loss: 2.622499925403091

Epoch: 329| Step: 0
Training loss: 1.6510723444097202
Validation loss: 2.6126073434974484

Epoch: 6| Step: 1
Training loss: 1.82089060497635
Validation loss: 2.570050660065743

Epoch: 6| Step: 2
Training loss: 1.9993756034828698
Validation loss: 2.557183853228239

Epoch: 6| Step: 3
Training loss: 1.6443229778996593
Validation loss: 2.5802684620357925

Epoch: 6| Step: 4
Training loss: 1.614823165636865
Validation loss: 2.54240105655561

Epoch: 6| Step: 5
Training loss: 1.6374709556275133
Validation loss: 2.5156818644097116

Epoch: 6| Step: 6
Training loss: 1.9848472453803332
Validation loss: 2.5542352880829764

Epoch: 6| Step: 7
Training loss: 2.239577312609246
Validation loss: 2.530061552696182

Epoch: 6| Step: 8
Training loss: 1.8519705149814334
Validation loss: 2.5471132787159676

Epoch: 6| Step: 9
Training loss: 1.4053465590231655
Validation loss: 2.520413266536643

Epoch: 6| Step: 10
Training loss: 2.3850745298628486
Validation loss: 2.537543819782004

Epoch: 6| Step: 11
Training loss: 1.5732834074752127
Validation loss: 2.52481833393002

Epoch: 6| Step: 12
Training loss: 1.5274020522909648
Validation loss: 2.525743554735964

Epoch: 6| Step: 13
Training loss: 1.9866482187007701
Validation loss: 2.537249139622055

Epoch: 330| Step: 0
Training loss: 1.6587409235828854
Validation loss: 2.5573144252616427

Epoch: 6| Step: 1
Training loss: 2.6251824633443728
Validation loss: 2.557877799078151

Epoch: 6| Step: 2
Training loss: 2.0744873562618507
Validation loss: 2.5638253188480897

Epoch: 6| Step: 3
Training loss: 2.3899357618693053
Validation loss: 2.54555953364582

Epoch: 6| Step: 4
Training loss: 2.1038649188435845
Validation loss: 2.5334034695662453

Epoch: 6| Step: 5
Training loss: 1.415380885484495
Validation loss: 2.5003086773725904

Epoch: 6| Step: 6
Training loss: 1.6171190182841413
Validation loss: 2.5331241278682564

Epoch: 6| Step: 7
Training loss: 1.4267945751595041
Validation loss: 2.559983490962699

Epoch: 6| Step: 8
Training loss: 2.0452142632121184
Validation loss: 2.5045010102845553

Epoch: 6| Step: 9
Training loss: 1.5233354583213448
Validation loss: 2.4937497367635664

Epoch: 6| Step: 10
Training loss: 1.3670253112503516
Validation loss: 2.5145686204211737

Epoch: 6| Step: 11
Training loss: 1.5444312009693368
Validation loss: 2.4456313375301058

Epoch: 6| Step: 12
Training loss: 2.123967312476869
Validation loss: 2.45831446451823

Epoch: 6| Step: 13
Training loss: 1.799308919696942
Validation loss: 2.5117437935901163

Epoch: 331| Step: 0
Training loss: 1.1860376187609523
Validation loss: 2.510090808112306

Epoch: 6| Step: 1
Training loss: 1.4317503675004406
Validation loss: 2.472287938557786

Epoch: 6| Step: 2
Training loss: 2.0577520571603274
Validation loss: 2.4764699667923207

Epoch: 6| Step: 3
Training loss: 2.6471462646702424
Validation loss: 2.4767139601096093

Epoch: 6| Step: 4
Training loss: 1.5131452271828183
Validation loss: 2.5006466664967313

Epoch: 6| Step: 5
Training loss: 2.0315382532850683
Validation loss: 2.545609485464368

Epoch: 6| Step: 6
Training loss: 1.6943834985219481
Validation loss: 2.5528150067562456

Epoch: 6| Step: 7
Training loss: 2.08187207155643
Validation loss: 2.5714891362878967

Epoch: 6| Step: 8
Training loss: 1.349987104142372
Validation loss: 2.552321307446879

Epoch: 6| Step: 9
Training loss: 1.9349831261502846
Validation loss: 2.5347979135113134

Epoch: 6| Step: 10
Training loss: 1.9481615398799785
Validation loss: 2.5161959077314697

Epoch: 6| Step: 11
Training loss: 1.4416902257210795
Validation loss: 2.488730158053766

Epoch: 6| Step: 12
Training loss: 1.7401894372003728
Validation loss: 2.5222568013383135

Epoch: 6| Step: 13
Training loss: 2.4294284302194606
Validation loss: 2.5093210818656804

Epoch: 332| Step: 0
Training loss: 1.1495650588478783
Validation loss: 2.533447544028897

Epoch: 6| Step: 1
Training loss: 1.7806173171376078
Validation loss: 2.5080390899112452

Epoch: 6| Step: 2
Training loss: 1.5576776474845173
Validation loss: 2.492576863676596

Epoch: 6| Step: 3
Training loss: 1.7539164451523703
Validation loss: 2.493918826986055

Epoch: 6| Step: 4
Training loss: 1.5506284239676211
Validation loss: 2.481782740390603

Epoch: 6| Step: 5
Training loss: 2.3713429051419554
Validation loss: 2.474747916590978

Epoch: 6| Step: 6
Training loss: 1.4885791070001086
Validation loss: 2.474148830642045

Epoch: 6| Step: 7
Training loss: 2.255323047378062
Validation loss: 2.4911785574732366

Epoch: 6| Step: 8
Training loss: 1.4040728351850258
Validation loss: 2.4973853584735495

Epoch: 6| Step: 9
Training loss: 1.7337008704036374
Validation loss: 2.516701241017839

Epoch: 6| Step: 10
Training loss: 2.038799634337472
Validation loss: 2.572272622946892

Epoch: 6| Step: 11
Training loss: 1.7503869446347788
Validation loss: 2.6078163105803682

Epoch: 6| Step: 12
Training loss: 1.8849015419135637
Validation loss: 2.6440458241943645

Epoch: 6| Step: 13
Training loss: 1.8809659775167225
Validation loss: 2.6675399204783767

Epoch: 333| Step: 0
Training loss: 1.8214407768161134
Validation loss: 2.5944367078039066

Epoch: 6| Step: 1
Training loss: 1.535277849579331
Validation loss: 2.61113296041974

Epoch: 6| Step: 2
Training loss: 1.651319109432813
Validation loss: 2.556153711745495

Epoch: 6| Step: 3
Training loss: 2.2291401181170127
Validation loss: 2.56081507112608

Epoch: 6| Step: 4
Training loss: 1.4690020730437006
Validation loss: 2.550737350421036

Epoch: 6| Step: 5
Training loss: 1.2425233398947102
Validation loss: 2.546601130576814

Epoch: 6| Step: 6
Training loss: 2.242223121280362
Validation loss: 2.567617114279973

Epoch: 6| Step: 7
Training loss: 1.5613612793968616
Validation loss: 2.5205730797802106

Epoch: 6| Step: 8
Training loss: 1.4868393368510897
Validation loss: 2.578837255868357

Epoch: 6| Step: 9
Training loss: 1.6880973888795756
Validation loss: 2.534850554215018

Epoch: 6| Step: 10
Training loss: 1.837955615590091
Validation loss: 2.5727651348099454

Epoch: 6| Step: 11
Training loss: 1.8106272657997142
Validation loss: 2.5832848287971504

Epoch: 6| Step: 12
Training loss: 1.9691234416094636
Validation loss: 2.5581064473627397

Epoch: 6| Step: 13
Training loss: 2.036267465946233
Validation loss: 2.5962925670564445

Epoch: 334| Step: 0
Training loss: 1.9638851550023424
Validation loss: 2.584321268946127

Epoch: 6| Step: 1
Training loss: 1.4460027747490352
Validation loss: 2.5166767046477694

Epoch: 6| Step: 2
Training loss: 1.2545161680150467
Validation loss: 2.568795526600731

Epoch: 6| Step: 3
Training loss: 1.8237862247793923
Validation loss: 2.5611157283709156

Epoch: 6| Step: 4
Training loss: 1.6192272057294534
Validation loss: 2.585476268498332

Epoch: 6| Step: 5
Training loss: 1.6748469667130663
Validation loss: 2.551360441836211

Epoch: 6| Step: 6
Training loss: 1.8489100132032434
Validation loss: 2.542202991953427

Epoch: 6| Step: 7
Training loss: 1.9816691656179797
Validation loss: 2.503969395040165

Epoch: 6| Step: 8
Training loss: 1.5528996601543341
Validation loss: 2.488648264281017

Epoch: 6| Step: 9
Training loss: 2.6170973121704186
Validation loss: 2.4925895374608547

Epoch: 6| Step: 10
Training loss: 1.2864392957424182
Validation loss: 2.490745111087661

Epoch: 6| Step: 11
Training loss: 1.4455099434921295
Validation loss: 2.4555277790706085

Epoch: 6| Step: 12
Training loss: 1.6293570720240875
Validation loss: 2.488799579636798

Epoch: 6| Step: 13
Training loss: 1.98175645005115
Validation loss: 2.4524825726951813

Epoch: 335| Step: 0
Training loss: 1.2258549976228177
Validation loss: 2.4748071653209025

Epoch: 6| Step: 1
Training loss: 1.8873243288054202
Validation loss: 2.512967398014443

Epoch: 6| Step: 2
Training loss: 2.2201327461213642
Validation loss: 2.5150319697659316

Epoch: 6| Step: 3
Training loss: 1.4014738567307823
Validation loss: 2.50710237457042

Epoch: 6| Step: 4
Training loss: 2.1854593840704033
Validation loss: 2.5535895022712687

Epoch: 6| Step: 5
Training loss: 1.3789474437925489
Validation loss: 2.5445680369863766

Epoch: 6| Step: 6
Training loss: 1.6889458572807132
Validation loss: 2.5815846359423844

Epoch: 6| Step: 7
Training loss: 1.671200910487824
Validation loss: 2.5595138021550183

Epoch: 6| Step: 8
Training loss: 2.041963698390457
Validation loss: 2.585027805525615

Epoch: 6| Step: 9
Training loss: 1.2477281906799185
Validation loss: 2.541968614329966

Epoch: 6| Step: 10
Training loss: 2.1013426257975287
Validation loss: 2.5415313455381154

Epoch: 6| Step: 11
Training loss: 1.7208736131709192
Validation loss: 2.5010101026147704

Epoch: 6| Step: 12
Training loss: 1.2080848811119662
Validation loss: 2.537385686169248

Epoch: 6| Step: 13
Training loss: 2.103227260875218
Validation loss: 2.5043207262944596

Epoch: 336| Step: 0
Training loss: 1.3480430158605747
Validation loss: 2.479542556818006

Epoch: 6| Step: 1
Training loss: 1.6534672518043128
Validation loss: 2.47505670090791

Epoch: 6| Step: 2
Training loss: 1.5684254253536027
Validation loss: 2.472422865489537

Epoch: 6| Step: 3
Training loss: 1.7638048901252337
Validation loss: 2.5130130168154157

Epoch: 6| Step: 4
Training loss: 1.372647092959105
Validation loss: 2.490795627749761

Epoch: 6| Step: 5
Training loss: 1.7267739006874812
Validation loss: 2.518186887736612

Epoch: 6| Step: 6
Training loss: 1.7012268828335657
Validation loss: 2.5062457901942286

Epoch: 6| Step: 7
Training loss: 1.5766208392144072
Validation loss: 2.4999113226104104

Epoch: 6| Step: 8
Training loss: 1.4919601986308837
Validation loss: 2.4768712987430144

Epoch: 6| Step: 9
Training loss: 1.3926617569174138
Validation loss: 2.521771442945277

Epoch: 6| Step: 10
Training loss: 2.2089405544531773
Validation loss: 2.5320980864745737

Epoch: 6| Step: 11
Training loss: 1.761834185216506
Validation loss: 2.5697406724051137

Epoch: 6| Step: 12
Training loss: 2.2905577895646303
Validation loss: 2.6051699930812093

Epoch: 6| Step: 13
Training loss: 2.130005494947912
Validation loss: 2.610993574306218

Epoch: 337| Step: 0
Training loss: 1.4650235078507436
Validation loss: 2.6065762828643457

Epoch: 6| Step: 1
Training loss: 1.2906733764744627
Validation loss: 2.5262801906537717

Epoch: 6| Step: 2
Training loss: 1.2374364817337833
Validation loss: 2.495897614718511

Epoch: 6| Step: 3
Training loss: 1.6963511858047127
Validation loss: 2.493399936004064

Epoch: 6| Step: 4
Training loss: 2.3591658139493967
Validation loss: 2.478880903192779

Epoch: 6| Step: 5
Training loss: 1.1742163094033913
Validation loss: 2.5264171334406833

Epoch: 6| Step: 6
Training loss: 2.1363804076844297
Validation loss: 2.500041707008876

Epoch: 6| Step: 7
Training loss: 2.0265724905410427
Validation loss: 2.5176570417308666

Epoch: 6| Step: 8
Training loss: 1.624518323081706
Validation loss: 2.513676830841135

Epoch: 6| Step: 9
Training loss: 1.9226513046827272
Validation loss: 2.5610838442702732

Epoch: 6| Step: 10
Training loss: 1.8850204374586608
Validation loss: 2.5302775049367074

Epoch: 6| Step: 11
Training loss: 1.5254594736033071
Validation loss: 2.545335831134197

Epoch: 6| Step: 12
Training loss: 2.6039600035998824
Validation loss: 2.5556470836152654

Epoch: 6| Step: 13
Training loss: 1.4522480112811798
Validation loss: 2.5890486212484847

Epoch: 338| Step: 0
Training loss: 1.3452089949963597
Validation loss: 2.593968217548165

Epoch: 6| Step: 1
Training loss: 1.4716907847592966
Validation loss: 2.5484555104841506

Epoch: 6| Step: 2
Training loss: 1.6644164949087021
Validation loss: 2.5233699761992603

Epoch: 6| Step: 3
Training loss: 1.4639140930193693
Validation loss: 2.528702305412964

Epoch: 6| Step: 4
Training loss: 1.7625930545131145
Validation loss: 2.546873471000228

Epoch: 6| Step: 5
Training loss: 1.6674424352818413
Validation loss: 2.539951000767264

Epoch: 6| Step: 6
Training loss: 2.6471631070083688
Validation loss: 2.550868969003413

Epoch: 6| Step: 7
Training loss: 1.291815805541596
Validation loss: 2.5159282304122925

Epoch: 6| Step: 8
Training loss: 2.0460788255797575
Validation loss: 2.5784119340381735

Epoch: 6| Step: 9
Training loss: 1.7442303641921129
Validation loss: 2.560180218805278

Epoch: 6| Step: 10
Training loss: 1.9180328917800642
Validation loss: 2.531060561010343

Epoch: 6| Step: 11
Training loss: 2.0157884634994905
Validation loss: 2.540782670512384

Epoch: 6| Step: 12
Training loss: 1.516493715478872
Validation loss: 2.5197119753976445

Epoch: 6| Step: 13
Training loss: 1.4017275675827003
Validation loss: 2.481040764481577

Epoch: 339| Step: 0
Training loss: 1.9654426647820415
Validation loss: 2.498825321789282

Epoch: 6| Step: 1
Training loss: 2.0204105787079953
Validation loss: 2.4883254210475556

Epoch: 6| Step: 2
Training loss: 1.0180874829203177
Validation loss: 2.517977741764721

Epoch: 6| Step: 3
Training loss: 1.5208670817075232
Validation loss: 2.526356366142589

Epoch: 6| Step: 4
Training loss: 1.6909457454223042
Validation loss: 2.516435764995917

Epoch: 6| Step: 5
Training loss: 1.2491227886661749
Validation loss: 2.5096521651254835

Epoch: 6| Step: 6
Training loss: 2.0728902639372118
Validation loss: 2.535773407395899

Epoch: 6| Step: 7
Training loss: 1.956221300591011
Validation loss: 2.515009715969665

Epoch: 6| Step: 8
Training loss: 1.6966063313101754
Validation loss: 2.5204764236964947

Epoch: 6| Step: 9
Training loss: 1.9609267397885493
Validation loss: 2.5098132493860215

Epoch: 6| Step: 10
Training loss: 1.2477179677432793
Validation loss: 2.535731097126629

Epoch: 6| Step: 11
Training loss: 1.5034116253621455
Validation loss: 2.5729738041225856

Epoch: 6| Step: 12
Training loss: 2.3034606771787085
Validation loss: 2.5928930375938513

Epoch: 6| Step: 13
Training loss: 1.2633474130944684
Validation loss: 2.576819642334577

Epoch: 340| Step: 0
Training loss: 1.478119044866522
Validation loss: 2.492615315260952

Epoch: 6| Step: 1
Training loss: 1.5064073250945478
Validation loss: 2.562816460769992

Epoch: 6| Step: 2
Training loss: 1.5225408018060016
Validation loss: 2.5759445525879645

Epoch: 6| Step: 3
Training loss: 2.00917618451685
Validation loss: 2.558140193739686

Epoch: 6| Step: 4
Training loss: 1.6949432955458914
Validation loss: 2.550481960776013

Epoch: 6| Step: 5
Training loss: 2.447207268264966
Validation loss: 2.599342277059784

Epoch: 6| Step: 6
Training loss: 2.2754276125279698
Validation loss: 2.626525995446004

Epoch: 6| Step: 7
Training loss: 1.4481858019356841
Validation loss: 2.6419750426733417

Epoch: 6| Step: 8
Training loss: 1.9449592484076135
Validation loss: 2.6316319657305445

Epoch: 6| Step: 9
Training loss: 1.4003464014793081
Validation loss: 2.5926112237392047

Epoch: 6| Step: 10
Training loss: 1.5649193915426978
Validation loss: 2.5366196995554797

Epoch: 6| Step: 11
Training loss: 1.2906374009393304
Validation loss: 2.487634356143425

Epoch: 6| Step: 12
Training loss: 1.8426870094332044
Validation loss: 2.5335860912651484

Epoch: 6| Step: 13
Training loss: 1.5088923249200106
Validation loss: 2.5481254456748696

Epoch: 341| Step: 0
Training loss: 2.078369585142712
Validation loss: 2.534559300091485

Epoch: 6| Step: 1
Training loss: 2.131103054137917
Validation loss: 2.561484849091111

Epoch: 6| Step: 2
Training loss: 1.4404478944823897
Validation loss: 2.5200204536955177

Epoch: 6| Step: 3
Training loss: 1.2397103231226874
Validation loss: 2.5239861426328227

Epoch: 6| Step: 4
Training loss: 1.982147348121455
Validation loss: 2.5139209038069867

Epoch: 6| Step: 5
Training loss: 1.6244064127228346
Validation loss: 2.550000790365259

Epoch: 6| Step: 6
Training loss: 2.24883727654415
Validation loss: 2.547785559145714

Epoch: 6| Step: 7
Training loss: 1.6398429823351586
Validation loss: 2.591789178518229

Epoch: 6| Step: 8
Training loss: 1.8290664335463067
Validation loss: 2.5561713401673942

Epoch: 6| Step: 9
Training loss: 1.3349637503828038
Validation loss: 2.6073437396854353

Epoch: 6| Step: 10
Training loss: 1.162319491328516
Validation loss: 2.594058742302187

Epoch: 6| Step: 11
Training loss: 1.5054343646744528
Validation loss: 2.5458518003136312

Epoch: 6| Step: 12
Training loss: 1.5030830012618235
Validation loss: 2.5142851869006657

Epoch: 6| Step: 13
Training loss: 1.3247145903189235
Validation loss: 2.523941359788911

Epoch: 342| Step: 0
Training loss: 1.861557328961593
Validation loss: 2.540405591160892

Epoch: 6| Step: 1
Training loss: 1.0792474294264707
Validation loss: 2.53089839549796

Epoch: 6| Step: 2
Training loss: 1.7435486270478295
Validation loss: 2.5609254418974245

Epoch: 6| Step: 3
Training loss: 1.4939303780027562
Validation loss: 2.5102377599595003

Epoch: 6| Step: 4
Training loss: 1.7280000941576756
Validation loss: 2.541288790728092

Epoch: 6| Step: 5
Training loss: 1.232200251993885
Validation loss: 2.5151885070583906

Epoch: 6| Step: 6
Training loss: 1.7254409254159413
Validation loss: 2.486128757871183

Epoch: 6| Step: 7
Training loss: 1.6877281599862277
Validation loss: 2.4967725186091148

Epoch: 6| Step: 8
Training loss: 1.6941570792213831
Validation loss: 2.5235758016221745

Epoch: 6| Step: 9
Training loss: 1.610915622507127
Validation loss: 2.5680693449350827

Epoch: 6| Step: 10
Training loss: 1.3031147597388557
Validation loss: 2.619268290504005

Epoch: 6| Step: 11
Training loss: 1.3310005473645214
Validation loss: 2.6205350201697817

Epoch: 6| Step: 12
Training loss: 2.577460925955833
Validation loss: 2.6033760447382894

Epoch: 6| Step: 13
Training loss: 2.080635562043727
Validation loss: 2.6396020868042163

Epoch: 343| Step: 0
Training loss: 1.7064381142903577
Validation loss: 2.6071211776031094

Epoch: 6| Step: 1
Training loss: 1.615890941461857
Validation loss: 2.6022464819146602

Epoch: 6| Step: 2
Training loss: 1.963824574725714
Validation loss: 2.5717463334855535

Epoch: 6| Step: 3
Training loss: 1.214440379991523
Validation loss: 2.5835880236028226

Epoch: 6| Step: 4
Training loss: 1.4630661414755914
Validation loss: 2.5684987464289333

Epoch: 6| Step: 5
Training loss: 1.467046602123922
Validation loss: 2.5520190380067937

Epoch: 6| Step: 6
Training loss: 1.8487241211602308
Validation loss: 2.532445578145725

Epoch: 6| Step: 7
Training loss: 1.878774911965327
Validation loss: 2.4962843940057864

Epoch: 6| Step: 8
Training loss: 1.602115144980116
Validation loss: 2.5539889688166464

Epoch: 6| Step: 9
Training loss: 1.5672942805020174
Validation loss: 2.566042026045791

Epoch: 6| Step: 10
Training loss: 2.1447416942296433
Validation loss: 2.631053408590172

Epoch: 6| Step: 11
Training loss: 1.8585749595946162
Validation loss: 2.6424553300588074

Epoch: 6| Step: 12
Training loss: 2.0297739387883147
Validation loss: 2.6771614320596924

Epoch: 6| Step: 13
Training loss: 1.3315761829202302
Validation loss: 2.614661520793208

Epoch: 344| Step: 0
Training loss: 1.4313276711257024
Validation loss: 2.6037993566236692

Epoch: 6| Step: 1
Training loss: 2.0482715763541925
Validation loss: 2.565130325932734

Epoch: 6| Step: 2
Training loss: 1.6528866284141757
Validation loss: 2.5551252699697993

Epoch: 6| Step: 3
Training loss: 1.9482760854272188
Validation loss: 2.559887182014777

Epoch: 6| Step: 4
Training loss: 1.5297571028089265
Validation loss: 2.5273227916793854

Epoch: 6| Step: 5
Training loss: 1.943592766783688
Validation loss: 2.5305002224503816

Epoch: 6| Step: 6
Training loss: 1.394222706232611
Validation loss: 2.549894434794505

Epoch: 6| Step: 7
Training loss: 1.254107687863438
Validation loss: 2.565363454865269

Epoch: 6| Step: 8
Training loss: 2.0867719374276263
Validation loss: 2.567648220841674

Epoch: 6| Step: 9
Training loss: 1.9499893652797133
Validation loss: 2.5171161283939205

Epoch: 6| Step: 10
Training loss: 1.9502671963466944
Validation loss: 2.520013145079464

Epoch: 6| Step: 11
Training loss: 1.2505863721716604
Validation loss: 2.5256599898236427

Epoch: 6| Step: 12
Training loss: 1.8311343081647409
Validation loss: 2.4900639015638655

Epoch: 6| Step: 13
Training loss: 1.8815253198862802
Validation loss: 2.5326211771165412

Epoch: 345| Step: 0
Training loss: 1.809720901341744
Validation loss: 2.574915990724461

Epoch: 6| Step: 1
Training loss: 1.45185944606744
Validation loss: 2.538033395213329

Epoch: 6| Step: 2
Training loss: 1.8726937415579756
Validation loss: 2.587299921528552

Epoch: 6| Step: 3
Training loss: 1.306362698452634
Validation loss: 2.531550040338985

Epoch: 6| Step: 4
Training loss: 1.9244472378846809
Validation loss: 2.541632344582207

Epoch: 6| Step: 5
Training loss: 1.732961129916512
Validation loss: 2.5267524400921144

Epoch: 6| Step: 6
Training loss: 1.2581823527893257
Validation loss: 2.4925446448732673

Epoch: 6| Step: 7
Training loss: 1.2829284373965104
Validation loss: 2.516293059863551

Epoch: 6| Step: 8
Training loss: 1.461330503753953
Validation loss: 2.547529124878674

Epoch: 6| Step: 9
Training loss: 1.6141203760071852
Validation loss: 2.5108774377000733

Epoch: 6| Step: 10
Training loss: 1.384090630320162
Validation loss: 2.5092783572413953

Epoch: 6| Step: 11
Training loss: 2.0355821628765782
Validation loss: 2.5413496778672395

Epoch: 6| Step: 12
Training loss: 1.5106400774012743
Validation loss: 2.559985105265063

Epoch: 6| Step: 13
Training loss: 2.4680800675769623
Validation loss: 2.5056136286556714

Epoch: 346| Step: 0
Training loss: 1.920531633008801
Validation loss: 2.644070576259186

Epoch: 6| Step: 1
Training loss: 1.178516337110325
Validation loss: 2.582915600462971

Epoch: 6| Step: 2
Training loss: 1.2093547691210487
Validation loss: 2.537142680211155

Epoch: 6| Step: 3
Training loss: 1.1618833177749994
Validation loss: 2.5119773371720986

Epoch: 6| Step: 4
Training loss: 1.9296264638784622
Validation loss: 2.5001253891335486

Epoch: 6| Step: 5
Training loss: 1.3511636399048201
Validation loss: 2.510000983259558

Epoch: 6| Step: 6
Training loss: 1.6805458891759608
Validation loss: 2.521471373674484

Epoch: 6| Step: 7
Training loss: 2.402918404180054
Validation loss: 2.517603418081606

Epoch: 6| Step: 8
Training loss: 1.4849831389423636
Validation loss: 2.533410033729652

Epoch: 6| Step: 9
Training loss: 1.3669563316006301
Validation loss: 2.502622278143333

Epoch: 6| Step: 10
Training loss: 2.0187340939488623
Validation loss: 2.5141584493038973

Epoch: 6| Step: 11
Training loss: 1.8360453472521145
Validation loss: 2.536582682627448

Epoch: 6| Step: 12
Training loss: 1.5325053771579618
Validation loss: 2.5353476555448418

Epoch: 6| Step: 13
Training loss: 1.7307938728860586
Validation loss: 2.5541288210215565

Epoch: 347| Step: 0
Training loss: 1.6864912762250877
Validation loss: 2.506040158766183

Epoch: 6| Step: 1
Training loss: 1.9550014179741675
Validation loss: 2.5398520938983036

Epoch: 6| Step: 2
Training loss: 1.6684024434569527
Validation loss: 2.5573057237745065

Epoch: 6| Step: 3
Training loss: 2.072398966131521
Validation loss: 2.551125137647846

Epoch: 6| Step: 4
Training loss: 1.239191484893273
Validation loss: 2.575173131128498

Epoch: 6| Step: 5
Training loss: 1.7678409275670914
Validation loss: 2.56348598708585

Epoch: 6| Step: 6
Training loss: 1.481788872026304
Validation loss: 2.5532204929580224

Epoch: 6| Step: 7
Training loss: 1.3710450166480588
Validation loss: 2.5766189183461794

Epoch: 6| Step: 8
Training loss: 1.4408756923387613
Validation loss: 2.5855591988038102

Epoch: 6| Step: 9
Training loss: 1.722900580900381
Validation loss: 2.5922941848541132

Epoch: 6| Step: 10
Training loss: 1.4119162948533759
Validation loss: 2.574478838626862

Epoch: 6| Step: 11
Training loss: 1.5754780240718993
Validation loss: 2.6083969750323495

Epoch: 6| Step: 12
Training loss: 1.4947879361450573
Validation loss: 2.585090913520466

Epoch: 6| Step: 13
Training loss: 1.555426263923511
Validation loss: 2.5550166859987065

Epoch: 348| Step: 0
Training loss: 2.2116268956801464
Validation loss: 2.575111832396992

Epoch: 6| Step: 1
Training loss: 1.8042727567684023
Validation loss: 2.548069071376978

Epoch: 6| Step: 2
Training loss: 1.6696582965413829
Validation loss: 2.542508803970963

Epoch: 6| Step: 3
Training loss: 2.1459295998124155
Validation loss: 2.555966211809034

Epoch: 6| Step: 4
Training loss: 1.4847376330275401
Validation loss: 2.551848238542227

Epoch: 6| Step: 5
Training loss: 1.1546873926309786
Validation loss: 2.53537547491544

Epoch: 6| Step: 6
Training loss: 1.7189036907492197
Validation loss: 2.5065245207682865

Epoch: 6| Step: 7
Training loss: 1.3817218854765714
Validation loss: 2.531453685650015

Epoch: 6| Step: 8
Training loss: 1.1821740829993097
Validation loss: 2.4891001393389183

Epoch: 6| Step: 9
Training loss: 1.4909843667411322
Validation loss: 2.533591470826165

Epoch: 6| Step: 10
Training loss: 1.7712217092038216
Validation loss: 2.518885235433458

Epoch: 6| Step: 11
Training loss: 1.8085497197832916
Validation loss: 2.5019879225793376

Epoch: 6| Step: 12
Training loss: 1.0664518018223075
Validation loss: 2.5360971046061906

Epoch: 6| Step: 13
Training loss: 1.1160354008990376
Validation loss: 2.594497863928425

Epoch: 349| Step: 0
Training loss: 1.3238438438457096
Validation loss: 2.670495403968405

Epoch: 6| Step: 1
Training loss: 1.7091431287871053
Validation loss: 2.669824984954419

Epoch: 6| Step: 2
Training loss: 1.5678458507291333
Validation loss: 2.678363098338373

Epoch: 6| Step: 3
Training loss: 1.8103256337318114
Validation loss: 2.637016298435857

Epoch: 6| Step: 4
Training loss: 1.830181758067451
Validation loss: 2.5442193662864505

Epoch: 6| Step: 5
Training loss: 1.4891705596878635
Validation loss: 2.513268767201266

Epoch: 6| Step: 6
Training loss: 2.012982669549163
Validation loss: 2.5672284826318705

Epoch: 6| Step: 7
Training loss: 2.2758239595417344
Validation loss: 2.5699785782827917

Epoch: 6| Step: 8
Training loss: 1.6675794803831017
Validation loss: 2.577166893688058

Epoch: 6| Step: 9
Training loss: 1.2363358387397592
Validation loss: 2.6084478257698755

Epoch: 6| Step: 10
Training loss: 1.6106519355342375
Validation loss: 2.5675663215617

Epoch: 6| Step: 11
Training loss: 1.7050662395329597
Validation loss: 2.554967198046238

Epoch: 6| Step: 12
Training loss: 2.2709811334603187
Validation loss: 2.539919023074042

Epoch: 6| Step: 13
Training loss: 1.7118917094902242
Validation loss: 2.535099054366321

Epoch: 350| Step: 0
Training loss: 2.185312758000731
Validation loss: 2.5595370584865282

Epoch: 6| Step: 1
Training loss: 1.8490857004344794
Validation loss: 2.5963532279780357

Epoch: 6| Step: 2
Training loss: 1.317495286126001
Validation loss: 2.578553705503007

Epoch: 6| Step: 3
Training loss: 1.536310824624893
Validation loss: 2.5773642602470415

Epoch: 6| Step: 4
Training loss: 1.3246836338585233
Validation loss: 2.591542066377546

Epoch: 6| Step: 5
Training loss: 1.6877170705700584
Validation loss: 2.597119368138893

Epoch: 6| Step: 6
Training loss: 1.4938623904798138
Validation loss: 2.6715128543512856

Epoch: 6| Step: 7
Training loss: 1.4008541430747448
Validation loss: 2.6109693989839724

Epoch: 6| Step: 8
Training loss: 1.7721080754562946
Validation loss: 2.6417211781682752

Epoch: 6| Step: 9
Training loss: 1.781684420966723
Validation loss: 2.5959199690916615

Epoch: 6| Step: 10
Training loss: 1.621426835368279
Validation loss: 2.5178543700821647

Epoch: 6| Step: 11
Training loss: 1.2383407434076645
Validation loss: 2.501928841053395

Epoch: 6| Step: 12
Training loss: 1.7894450615728472
Validation loss: 2.533398552314415

Epoch: 6| Step: 13
Training loss: 1.2932328706407399
Validation loss: 2.540502654285642

Testing loss: 2.263608670730278
