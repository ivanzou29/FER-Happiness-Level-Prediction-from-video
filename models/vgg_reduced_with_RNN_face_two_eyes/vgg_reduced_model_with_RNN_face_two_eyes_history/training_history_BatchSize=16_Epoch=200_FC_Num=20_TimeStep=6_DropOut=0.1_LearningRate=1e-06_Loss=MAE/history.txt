Epoch: 1| Step: 0
Training loss: 5.3142499923706055
Validation loss: 5.2199245631265985
Epoch: 9| Step: 1
Training loss: 4.0438151359558105
Validation loss: 5.219058180884492
Epoch: 9| Step: 2
Training loss: 6.305068016052246
Validation loss: 5.217995393190453
Epoch: 9| Step: 3
Training loss: 5.697652816772461
Validation loss: 5.21716428317612
Epoch: 9| Step: 4
Training loss: 4.715364456176758
Validation loss: 5.216155131086171
Epoch: 9| Step: 5
Training loss: 6.053905487060547
Validation loss: 5.215256467997599
Epoch: 9| Step: 6
Training loss: 5.901880741119385
Validation loss: 5.2144461021148905
Epoch: 9| Step: 7
Training loss: 5.382248401641846
Validation loss: 5.2135247017839825
Epoch: 9| Step: 8
Training loss: 5.863377094268799
Validation loss: 5.2126383987262095
Epoch: 9| Step: 9
Training loss: 4.8371076583862305
Validation loss: 5.211735615627371
Epoch: 9| Step: 10
Training loss: 4.767115116119385
Validation loss: 5.2106507081779645
Epoch: 9| Step: 11
Training loss: 5.691652297973633
Validation loss: 5.210042178202018
Epoch: 9| Step: 12
Training loss: 5.046454906463623
Validation loss: 5.2090631148798
Epoch: 9| Step: 13
Training loss: 5.707935333251953
Validation loss: 5.208022073018465
Epoch: 9| Step: 14
Training loss: 5.532517433166504
Validation loss: 5.2072606910046915
Epoch: 9| Step: 15
Training loss: 6.057172775268555
Validation loss: 5.2061952464014505
Epoch: 9| Step: 16
Training loss: 4.7630934715271
Validation loss: 5.205587411098343
Epoch: 9| Step: 17
Training loss: 5.474416732788086
Validation loss: 5.204356800737998
Epoch: 9| Step: 18
Training loss: 4.954723834991455
Validation loss: 5.203600928080168
Epoch: 9| Step: 19
Training loss: 4.941576957702637
Validation loss: 5.202564064547312
Epoch: 2| Step: 0
Training loss: 5.3513712882995605
Validation loss: 5.201707345976247
Epoch: 9| Step: 1
Training loss: 6.070211410522461
Validation loss: 5.200736852000944
Epoch: 9| Step: 2
Training loss: 5.283197402954102
Validation loss: 5.199911690444398
Epoch: 9| Step: 3
Training loss: 4.28780460357666
Validation loss: 5.198601465431048
Epoch: 9| Step: 4
Training loss: 5.789117813110352
Validation loss: 5.197772084380225
Epoch: 9| Step: 5
Training loss: 5.529336929321289
Validation loss: 5.196758774544695
Epoch: 9| Step: 6
Training loss: 5.533383846282959
Validation loss: 5.1956009350234655
Epoch: 9| Step: 7
Training loss: 5.240838050842285
Validation loss: 5.19464984043039
Epoch: 9| Step: 8
Training loss: 5.687813758850098
Validation loss: 5.193774991755863
Epoch: 9| Step: 9
Training loss: 4.99417781829834
Validation loss: 5.192621855427035
Epoch: 9| Step: 10
Training loss: 6.7343597412109375
Validation loss: 5.191524306647212
Epoch: 9| Step: 11
Training loss: 4.837333679199219
Validation loss: 5.190408017137925
Epoch: 9| Step: 12
Training loss: 5.491645812988281
Validation loss: 5.1893883814914625
Epoch: 9| Step: 13
Training loss: 5.1792449951171875
Validation loss: 5.188199701926691
Epoch: 9| Step: 14
Training loss: 4.706716537475586
Validation loss: 5.1871892977103915
Epoch: 9| Step: 15
Training loss: 5.833837509155273
Validation loss: 5.186041272801461
Epoch: 9| Step: 16
Training loss: 3.460150718688965
Validation loss: 5.184595982805431
Epoch: 9| Step: 17
Training loss: 4.507101535797119
Validation loss: 5.183587544255977
Epoch: 9| Step: 18
Training loss: 5.420510292053223
Validation loss: 5.1823035555777786
Epoch: 9| Step: 19
Training loss: 6.740660667419434
Validation loss: 5.181350615384767
Epoch: 3| Step: 0
Training loss: 4.667445659637451
Validation loss: 5.1798678199164305
Epoch: 9| Step: 1
Training loss: 5.24375581741333
Validation loss: 5.178597357633302
Epoch: 9| Step: 2
Training loss: 5.635288715362549
Validation loss: 5.177418506402764
Epoch: 9| Step: 3
Training loss: 4.122065544128418
Validation loss: 5.175996632884733
Epoch: 9| Step: 4
Training loss: 4.441048622131348
Validation loss: 5.174908627709039
Epoch: 9| Step: 5
Training loss: 6.529539108276367
Validation loss: 5.173556859544713
Epoch: 9| Step: 6
Training loss: 5.104570388793945
Validation loss: 5.172087429238738
Epoch: 9| Step: 7
Training loss: 4.8478546142578125
Validation loss: 5.170997135930782
Epoch: 9| Step: 8
Training loss: 5.912428855895996
Validation loss: 5.169784268029302
Epoch: 9| Step: 9
Training loss: 7.002818584442139
Validation loss: 5.168318172152952
Epoch: 9| Step: 10
Training loss: 4.8673505783081055
Validation loss: 5.167092734961201
Epoch: 9| Step: 11
Training loss: 5.549337863922119
Validation loss: 5.165376913633278
Epoch: 9| Step: 12
Training loss: 5.651384353637695
Validation loss: 5.1643417276066845
Epoch: 9| Step: 13
Training loss: 5.417193412780762
Validation loss: 5.162671308723285
Epoch: 9| Step: 14
Training loss: 5.52393913269043
Validation loss: 5.161510937505489
Epoch: 9| Step: 15
Training loss: 5.1816725730896
Validation loss: 5.160108463369685
Epoch: 9| Step: 16
Training loss: 4.961691856384277
Validation loss: 5.158738355842425
Epoch: 9| Step: 17
Training loss: 5.129124641418457
Validation loss: 5.157164302661265
Epoch: 9| Step: 18
Training loss: 4.9894537925720215
Validation loss: 5.155569381851087
Epoch: 9| Step: 19
Training loss: 5.448143005371094
Validation loss: 5.154300398106198
Epoch: 4| Step: 0
Training loss: 6.721798896789551
Validation loss: 5.152726389521318
Epoch: 9| Step: 1
Training loss: 6.257234573364258
Validation loss: 5.151559582717127
Epoch: 9| Step: 2
Training loss: 6.365540504455566
Validation loss: 5.149845661876871
Epoch: 9| Step: 3
Training loss: 5.215072154998779
Validation loss: 5.148404557070286
Epoch: 9| Step: 4
Training loss: 4.688199996948242
Validation loss: 5.146599817619049
Epoch: 9| Step: 5
Training loss: 5.130207538604736
Validation loss: 5.1452366808335555
Epoch: 9| Step: 6
Training loss: 4.914270877838135
Validation loss: 5.143589966588741
Epoch: 9| Step: 7
Training loss: 5.563097953796387
Validation loss: 5.142414837432423
Epoch: 9| Step: 8
Training loss: 4.936602592468262
Validation loss: 5.140389727173949
Epoch: 9| Step: 9
Training loss: 5.189352035522461
Validation loss: 5.139018199426665
Epoch: 9| Step: 10
Training loss: 4.906688213348389
Validation loss: 5.137300299225951
Epoch: 9| Step: 11
Training loss: 5.322376251220703
Validation loss: 5.135762825286646
Epoch: 9| Step: 12
Training loss: 5.105440139770508
Validation loss: 5.133876234507389
Epoch: 9| Step: 13
Training loss: 4.614626407623291
Validation loss: 5.13214370329603
Epoch: 9| Step: 14
Training loss: 5.096880912780762
Validation loss: 5.1306329047937185
Epoch: 9| Step: 15
Training loss: 6.171663284301758
Validation loss: 5.128781853819922
Epoch: 9| Step: 16
Training loss: 3.991300106048584
Validation loss: 5.127123661178479
Epoch: 9| Step: 17
Training loss: 4.449705123901367
Validation loss: 5.1252524218113304
Epoch: 9| Step: 18
Training loss: 6.045401573181152
Validation loss: 5.123173699962149
Epoch: 9| Step: 19
Training loss: 4.981581211090088
Validation loss: 5.121664448607739
Epoch: 5| Step: 0
Training loss: 4.584814548492432
Validation loss: 5.119998341841663
Epoch: 9| Step: 1
Training loss: 4.6258134841918945
Validation loss: 5.118199317575359
Epoch: 9| Step: 2
Training loss: 5.2056379318237305
Validation loss: 5.115973331945406
Epoch: 9| Step: 3
Training loss: 5.568815231323242
Validation loss: 5.114240999702069
Epoch: 9| Step: 4
Training loss: 5.704440116882324
Validation loss: 5.112510636556062
Epoch: 9| Step: 5
Training loss: 5.673954486846924
Validation loss: 5.1103711985855655
Epoch: 9| Step: 6
Training loss: 5.4082255363464355
Validation loss: 5.108491801529479
Epoch: 9| Step: 7
Training loss: 4.826099395751953
Validation loss: 5.106299920047787
Epoch: 9| Step: 8
Training loss: 5.299944877624512
Validation loss: 5.104347108936996
Epoch: 9| Step: 9
Training loss: 4.710825443267822
Validation loss: 5.102354018808269
Epoch: 9| Step: 10
Training loss: 3.8978681564331055
Validation loss: 5.100403730817836
Epoch: 9| Step: 11
Training loss: 4.671131134033203
Validation loss: 5.0979207951387915
Epoch: 9| Step: 12
Training loss: 6.227643966674805
Validation loss: 5.096355860181849
Epoch: 9| Step: 13
Training loss: 4.697821617126465
Validation loss: 5.093607573200472
Epoch: 9| Step: 14
Training loss: 5.693090438842773
Validation loss: 5.091517726294429
Epoch: 9| Step: 15
Training loss: 4.351318359375
Validation loss: 5.089563644189629
Epoch: 9| Step: 16
Training loss: 5.568453311920166
Validation loss: 5.08732498635491
Epoch: 9| Step: 17
Training loss: 6.1082658767700195
Validation loss: 5.08523379469947
Epoch: 9| Step: 18
Training loss: 5.95598840713501
Validation loss: 5.0825645597718605
Epoch: 9| Step: 19
Training loss: 6.191768169403076
Validation loss: 5.080392137705851
Epoch: 6| Step: 0
Training loss: 6.070804595947266
Validation loss: 5.078093858073942
Epoch: 9| Step: 1
Training loss: 6.014437198638916
Validation loss: 5.074775023426083
Epoch: 9| Step: 2
Training loss: 5.46417236328125
Validation loss: 5.0729719786335234
Epoch: 9| Step: 3
Training loss: 5.7572197914123535
Validation loss: 5.070260288046418
Epoch: 9| Step: 4
Training loss: 5.258240699768066
Validation loss: 5.067871680362619
Epoch: 9| Step: 5
Training loss: 5.117087364196777
Validation loss: 5.065559373485098
Epoch: 9| Step: 6
Training loss: 4.803459167480469
Validation loss: 5.062675976924759
Epoch: 9| Step: 7
Training loss: 4.82697868347168
Validation loss: 5.05993345487032
Epoch: 9| Step: 8
Training loss: 3.510988712310791
Validation loss: 5.057161564449612
Epoch: 9| Step: 9
Training loss: 5.331157684326172
Validation loss: 5.054950690097946
Epoch: 9| Step: 10
Training loss: 5.529562950134277
Validation loss: 5.052270192894147
Epoch: 9| Step: 11
Training loss: 5.030354976654053
Validation loss: 5.04896466852092
Epoch: 9| Step: 12
Training loss: 4.808767795562744
Validation loss: 5.046023842242124
Epoch: 9| Step: 13
Training loss: 4.0715532302856445
Validation loss: 5.0434804271451
Epoch: 9| Step: 14
Training loss: 4.968405723571777
Validation loss: 5.04020958838703
Epoch: 9| Step: 15
Training loss: 5.010097026824951
Validation loss: 5.037073910665169
Epoch: 9| Step: 16
Training loss: 6.172624588012695
Validation loss: 5.034385691443793
Epoch: 9| Step: 17
Training loss: 5.280482769012451
Validation loss: 5.0314571805995145
Epoch: 9| Step: 18
Training loss: 5.639847755432129
Validation loss: 5.028214862878374
Epoch: 9| Step: 19
Training loss: 5.401737213134766
Validation loss: 5.024749049179846
Epoch: 7| Step: 0
Training loss: 5.113706111907959
Validation loss: 5.021817540093291
Epoch: 9| Step: 1
Training loss: 6.1902947425842285
Validation loss: 5.018624086174176
Epoch: 9| Step: 2
Training loss: 4.998568058013916
Validation loss: 5.015281443973239
Epoch: 9| Step: 3
Training loss: 5.388886451721191
Validation loss: 5.012216197500984
Epoch: 9| Step: 4
Training loss: 4.272671699523926
Validation loss: 5.008676498056316
Epoch: 9| Step: 5
Training loss: 5.661120891571045
Validation loss: 5.005121673611428
Epoch: 9| Step: 6
Training loss: 5.467187881469727
Validation loss: 5.001582948423976
Epoch: 9| Step: 7
Training loss: 3.9034764766693115
Validation loss: 4.998726982006923
Epoch: 9| Step: 8
Training loss: 5.154270172119141
Validation loss: 4.994649561189061
Epoch: 9| Step: 9
Training loss: 4.361959457397461
Validation loss: 4.990856016282555
Epoch: 9| Step: 10
Training loss: 3.9897265434265137
Validation loss: 4.987011621324278
Epoch: 9| Step: 11
Training loss: 4.622763156890869
Validation loss: 4.983335738559421
Epoch: 9| Step: 12
Training loss: 5.646139621734619
Validation loss: 4.980168661625266
Epoch: 9| Step: 13
Training loss: 6.197314262390137
Validation loss: 4.976228549326066
Epoch: 9| Step: 14
Training loss: 4.386956214904785
Validation loss: 4.972311167408236
Epoch: 9| Step: 15
Training loss: 4.9557013511657715
Validation loss: 4.968110184017703
Epoch: 9| Step: 16
Training loss: 4.934446334838867
Validation loss: 4.9643341277143085
Epoch: 9| Step: 17
Training loss: 5.620176792144775
Validation loss: 4.959751485920639
Epoch: 9| Step: 18
Training loss: 6.640073776245117
Validation loss: 4.956092295886801
Epoch: 9| Step: 19
Training loss: 5.369006156921387
Validation loss: 4.9517472596477266
Epoch: 8| Step: 0
Training loss: 5.969552993774414
Validation loss: 4.9478177200976035
Epoch: 9| Step: 1
Training loss: 5.717939376831055
Validation loss: 4.943458766388378
Epoch: 9| Step: 2
Training loss: 5.517943382263184
Validation loss: 4.938657400419387
Epoch: 9| Step: 3
Training loss: 4.686911106109619
Validation loss: 4.934437432735086
Epoch: 9| Step: 4
Training loss: 5.064072132110596
Validation loss: 4.930193043441224
Epoch: 9| Step: 5
Training loss: 5.889423847198486
Validation loss: 4.92538328651044
Epoch: 9| Step: 6
Training loss: 5.517191410064697
Validation loss: 4.9203645548374535
Epoch: 9| Step: 7
Training loss: 5.712146759033203
Validation loss: 4.916741868574842
Epoch: 9| Step: 8
Training loss: 4.547697067260742
Validation loss: 4.910909189594736
Epoch: 9| Step: 9
Training loss: 4.189058780670166
Validation loss: 4.906597741216206
Epoch: 9| Step: 10
Training loss: 4.964378833770752
Validation loss: 4.9018466695607135
Epoch: 9| Step: 11
Training loss: 4.976983070373535
Validation loss: 4.897171459609656
Epoch: 9| Step: 12
Training loss: 4.2381463050842285
Validation loss: 4.892737419485188
Epoch: 9| Step: 13
Training loss: 4.642518997192383
Validation loss: 4.887042433237858
Epoch: 9| Step: 14
Training loss: 4.796933174133301
Validation loss: 4.882164087226923
Epoch: 9| Step: 15
Training loss: 4.699310302734375
Validation loss: 4.877006204865819
Epoch: 9| Step: 16
Training loss: 4.924060821533203
Validation loss: 4.872324689686727
Epoch: 9| Step: 17
Training loss: 3.877603769302368
Validation loss: 4.867135253741587
Epoch: 9| Step: 18
Training loss: 6.050434589385986
Validation loss: 4.861464569036909
Epoch: 9| Step: 19
Training loss: 5.307822227478027
Validation loss: 4.855528316909461
Epoch: 9| Step: 0
Training loss: 4.133054733276367
Validation loss: 4.850146581800722
Epoch: 9| Step: 1
Training loss: 6.080814838409424
Validation loss: 4.845338625873593
Epoch: 9| Step: 2
Training loss: 4.832755088806152
Validation loss: 4.839979401595301
Epoch: 9| Step: 3
Training loss: 5.203135967254639
Validation loss: 4.833415648920073
Epoch: 9| Step: 4
Training loss: 4.263544082641602
Validation loss: 4.828462415461917
Epoch: 9| Step: 5
Training loss: 3.666851043701172
Validation loss: 4.822542437546545
Epoch: 9| Step: 6
Training loss: 5.125119209289551
Validation loss: 4.816578600904067
Epoch: 9| Step: 7
Training loss: 5.2282538414001465
Validation loss: 4.810928982796429
Epoch: 9| Step: 8
Training loss: 4.238663673400879
Validation loss: 4.805342171689589
Epoch: 9| Step: 9
Training loss: 5.359281063079834
Validation loss: 4.799113403978965
Epoch: 9| Step: 10
Training loss: 5.227783679962158
Validation loss: 4.793204739797029
Epoch: 9| Step: 11
Training loss: 5.7835187911987305
Validation loss: 4.786942650088303
Epoch: 9| Step: 12
Training loss: 6.141432762145996
Validation loss: 4.781109705245752
Epoch: 9| Step: 13
Training loss: 4.939896583557129
Validation loss: 4.775922963945128
Epoch: 9| Step: 14
Training loss: 5.415198802947998
Validation loss: 4.768768224784796
Epoch: 9| Step: 15
Training loss: 5.477177619934082
Validation loss: 4.762793407165747
Epoch: 9| Step: 16
Training loss: 4.108139991760254
Validation loss: 4.755891467169892
Epoch: 9| Step: 17
Training loss: 3.7839808464050293
Validation loss: 4.750056743621826
Epoch: 9| Step: 18
Training loss: 5.033524513244629
Validation loss: 4.743723437082854
Epoch: 9| Step: 19
Training loss: 5.2427520751953125
Validation loss: 4.7375809717521395
Epoch: 10| Step: 0
Training loss: 4.344592571258545
Validation loss: 4.7307917642936435
Epoch: 9| Step: 1
Training loss: 6.368710041046143
Validation loss: 4.723989339183561
Epoch: 9| Step: 2
Training loss: 5.266661167144775
Validation loss: 4.717876808248835
Epoch: 9| Step: 3
Training loss: 4.016390800476074
Validation loss: 4.711083374435096
Epoch: 9| Step: 4
Training loss: 5.303508758544922
Validation loss: 4.70480059891296
Epoch: 9| Step: 5
Training loss: 4.365688323974609
Validation loss: 4.698374635024036
Epoch: 9| Step: 6
Training loss: 5.196446895599365
Validation loss: 4.691203724566123
Epoch: 9| Step: 7
Training loss: 4.56452751159668
Validation loss: 4.685025280328106
Epoch: 9| Step: 8
Training loss: 3.830984592437744
Validation loss: 4.677420465208644
Epoch: 9| Step: 9
Training loss: 4.338628768920898
Validation loss: 4.671269650081936
Epoch: 9| Step: 10
Training loss: 5.715388298034668
Validation loss: 4.664914758942968
Epoch: 9| Step: 11
Training loss: 3.8287439346313477
Validation loss: 4.6568699191800125
Epoch: 9| Step: 12
Training loss: 5.041400909423828
Validation loss: 4.650375582331376
Epoch: 9| Step: 13
Training loss: 5.595919609069824
Validation loss: 4.64385334536326
Epoch: 9| Step: 14
Training loss: 5.641289710998535
Validation loss: 4.636277481806364
Epoch: 9| Step: 15
Training loss: 5.125322341918945
Validation loss: 4.628514725527317
Epoch: 9| Step: 16
Training loss: 4.936803817749023
Validation loss: 4.621766996040619
Epoch: 9| Step: 17
Training loss: 3.655941963195801
Validation loss: 4.615626983505359
Epoch: 9| Step: 18
Training loss: 4.454079627990723
Validation loss: 4.607067183624927
Epoch: 9| Step: 19
Training loss: 5.330471038818359
Validation loss: 4.600397658862656
Epoch: 11| Step: 0
Training loss: 4.8320631980896
Validation loss: 4.5922267042475635
Epoch: 9| Step: 1
Training loss: 4.231510162353516
Validation loss: 4.587042132727534
Epoch: 9| Step: 2
Training loss: 5.051136016845703
Validation loss: 4.578170313251962
Epoch: 9| Step: 3
Training loss: 4.298026084899902
Validation loss: 4.570745691121053
Epoch: 9| Step: 4
Training loss: 3.676999568939209
Validation loss: 4.565254931827243
Epoch: 9| Step: 5
Training loss: 3.3818111419677734
Validation loss: 4.5571355099300686
Epoch: 9| Step: 6
Training loss: 4.3198113441467285
Validation loss: 4.549607975019826
Epoch: 9| Step: 7
Training loss: 5.035914897918701
Validation loss: 4.543366185195154
Epoch: 9| Step: 8
Training loss: 5.061152935028076
Validation loss: 4.5350194594842925
Epoch: 9| Step: 9
Training loss: 4.617201328277588
Validation loss: 4.528452300339294
Epoch: 9| Step: 10
Training loss: 5.9275312423706055
Validation loss: 4.520004226149415
Epoch: 9| Step: 11
Training loss: 4.138759613037109
Validation loss: 4.511968056932628
Epoch: 9| Step: 12
Training loss: 4.260553359985352
Validation loss: 4.505234025365157
Epoch: 9| Step: 13
Training loss: 4.207616806030273
Validation loss: 4.4967815069843535
Epoch: 9| Step: 14
Training loss: 4.37193489074707
Validation loss: 4.490325185034773
Epoch: 9| Step: 15
Training loss: 5.141168594360352
Validation loss: 4.48220047676306
Epoch: 9| Step: 16
Training loss: 6.357077598571777
Validation loss: 4.473875604945121
Epoch: 9| Step: 17
Training loss: 5.271024703979492
Validation loss: 4.4667999967396685
Epoch: 9| Step: 18
Training loss: 4.851930618286133
Validation loss: 4.459858609618043
Epoch: 9| Step: 19
Training loss: 5.2653117179870605
Validation loss: 4.451082435443247
Epoch: 12| Step: 0
Training loss: 3.913236141204834
Validation loss: 4.44312464762077
Epoch: 9| Step: 1
Training loss: 4.670498847961426
Validation loss: 4.434775064317442
Epoch: 9| Step: 2
Training loss: 4.753454208374023
Validation loss: 4.426550837729475
Epoch: 9| Step: 3
Training loss: 3.7800774574279785
Validation loss: 4.418578326273307
Epoch: 9| Step: 4
Training loss: 4.35886287689209
Validation loss: 4.4118435794501
Epoch: 9| Step: 5
Training loss: 5.673645973205566
Validation loss: 4.403198755044731
Epoch: 9| Step: 6
Training loss: 3.874340772628784
Validation loss: 4.394226060496817
Epoch: 9| Step: 7
Training loss: 5.3310747146606445
Validation loss: 4.387188513501942
Epoch: 9| Step: 8
Training loss: 3.634063959121704
Validation loss: 4.378476310976975
Epoch: 9| Step: 9
Training loss: 5.349208354949951
Validation loss: 4.370129197621517
Epoch: 9| Step: 10
Training loss: 4.355696201324463
Validation loss: 4.362398482055116
Epoch: 9| Step: 11
Training loss: 4.76931095123291
Validation loss: 4.355136133784013
Epoch: 9| Step: 12
Training loss: 3.641735315322876
Validation loss: 4.346991923215578
Epoch: 9| Step: 13
Training loss: 4.955245018005371
Validation loss: 4.340636321966596
Epoch: 9| Step: 14
Training loss: 5.750060081481934
Validation loss: 4.331658339328903
Epoch: 9| Step: 15
Training loss: 5.114810943603516
Validation loss: 4.3226695438083125
Epoch: 9| Step: 16
Training loss: 4.338239669799805
Validation loss: 4.314141098543894
Epoch: 9| Step: 17
Training loss: 4.686583518981934
Validation loss: 4.309367989464629
Epoch: 9| Step: 18
Training loss: 4.2806596755981445
Validation loss: 4.299593973502838
Epoch: 9| Step: 19
Training loss: 4.295511245727539
Validation loss: 4.292570772788507
Epoch: 13| Step: 0
Training loss: 4.707513809204102
Validation loss: 4.284803383641964
Epoch: 9| Step: 1
Training loss: 3.9022703170776367
Validation loss: 4.276138336538411
Epoch: 9| Step: 2
Training loss: 4.854515552520752
Validation loss: 4.267297767049117
Epoch: 9| Step: 3
Training loss: 3.7999696731567383
Validation loss: 4.26060317403121
Epoch: 9| Step: 4
Training loss: 5.417407989501953
Validation loss: 4.2526941985535105
Epoch: 9| Step: 5
Training loss: 5.220128059387207
Validation loss: 4.243916758530432
Epoch: 9| Step: 6
Training loss: 5.3244218826293945
Validation loss: 4.236969344049907
Epoch: 9| Step: 7
Training loss: 4.155425071716309
Validation loss: 4.230894346031354
Epoch: 9| Step: 8
Training loss: 3.916612148284912
Validation loss: 4.221943738649217
Epoch: 9| Step: 9
Training loss: 5.2125935554504395
Validation loss: 4.216527753596683
Epoch: 9| Step: 10
Training loss: 4.057291507720947
Validation loss: 4.207726048051025
Epoch: 9| Step: 11
Training loss: 3.895400047302246
Validation loss: 4.199312192930592
Epoch: 9| Step: 12
Training loss: 4.953948497772217
Validation loss: 4.193408352007969
Epoch: 9| Step: 13
Training loss: 4.310415744781494
Validation loss: 4.185349683967425
Epoch: 9| Step: 14
Training loss: 5.335877418518066
Validation loss: 4.178202284325798
Epoch: 9| Step: 15
Training loss: 3.7521677017211914
Validation loss: 4.171808407461043
Epoch: 9| Step: 16
Training loss: 3.7317185401916504
Validation loss: 4.165196387887859
Epoch: 9| Step: 17
Training loss: 4.0350494384765625
Validation loss: 4.156460604221701
Epoch: 9| Step: 18
Training loss: 4.192094802856445
Validation loss: 4.150497662935326
Epoch: 9| Step: 19
Training loss: 4.026480674743652
Validation loss: 4.143232856723045
Epoch: 14| Step: 0
Training loss: 4.247147083282471
Validation loss: 4.136879914098507
Epoch: 9| Step: 1
Training loss: 5.23472261428833
Validation loss: 4.130228186682832
Epoch: 9| Step: 2
Training loss: 3.7625832557678223
Validation loss: 4.123667435680362
Epoch: 9| Step: 3
Training loss: 4.606900215148926
Validation loss: 4.115733877360392
Epoch: 9| Step: 4
Training loss: 4.198356628417969
Validation loss: 4.1109917283915784
Epoch: 9| Step: 5
Training loss: 4.281361103057861
Validation loss: 4.102519308062766
Epoch: 9| Step: 6
Training loss: 4.554222106933594
Validation loss: 4.096957798484418
Epoch: 9| Step: 7
Training loss: 3.91379976272583
Validation loss: 4.089737221491423
Epoch: 9| Step: 8
Training loss: 4.723356246948242
Validation loss: 4.083989050748537
Epoch: 9| Step: 9
Training loss: 4.200771331787109
Validation loss: 4.077673177924945
Epoch: 9| Step: 10
Training loss: 4.9685869216918945
Validation loss: 4.070431184425629
Epoch: 9| Step: 11
Training loss: 2.7434346675872803
Validation loss: 4.063870349376321
Epoch: 9| Step: 12
Training loss: 4.854427337646484
Validation loss: 4.057636269562536
Epoch: 9| Step: 13
Training loss: 4.0999755859375
Validation loss: 4.050969477180097
Epoch: 9| Step: 14
Training loss: 4.040074348449707
Validation loss: 4.046943004182775
Epoch: 9| Step: 15
Training loss: 3.5404553413391113
Validation loss: 4.0393584923778505
Epoch: 9| Step: 16
Training loss: 3.9289965629577637
Validation loss: 4.034125719139044
Epoch: 9| Step: 17
Training loss: 4.608570575714111
Validation loss: 4.027466998683463
Epoch: 9| Step: 18
Training loss: 4.452990531921387
Validation loss: 4.0215795949208655
Epoch: 9| Step: 19
Training loss: 5.447909355163574
Validation loss: 4.0155062469647085
Epoch: 15| Step: 0
Training loss: 2.9104104042053223
Validation loss: 4.01008098588573
Epoch: 9| Step: 1
Training loss: 3.6841917037963867
Validation loss: 4.004617313686892
Epoch: 9| Step: 2
Training loss: 3.8215534687042236
Validation loss: 3.998576092205459
Epoch: 9| Step: 3
Training loss: 4.922098159790039
Validation loss: 3.9918868353040957
Epoch: 9| Step: 4
Training loss: 4.0114593505859375
Validation loss: 3.9859428474371383
Epoch: 9| Step: 5
Training loss: 3.3330626487731934
Validation loss: 3.981300492938474
Epoch: 9| Step: 6
Training loss: 5.434500694274902
Validation loss: 3.9753968081028344
Epoch: 9| Step: 7
Training loss: 5.102519989013672
Validation loss: 3.9697517799816544
Epoch: 9| Step: 8
Training loss: 4.658891677856445
Validation loss: 3.964166430260638
Epoch: 9| Step: 9
Training loss: 3.761178970336914
Validation loss: 3.9591084469994193
Epoch: 9| Step: 10
Training loss: 4.334442138671875
Validation loss: 3.9513969078338405
Epoch: 9| Step: 11
Training loss: 3.5217809677124023
Validation loss: 3.9488317880699104
Epoch: 9| Step: 12
Training loss: 5.147980690002441
Validation loss: 3.941726216309362
Epoch: 9| Step: 13
Training loss: 3.9892656803131104
Validation loss: 3.9360702861127237
Epoch: 9| Step: 14
Training loss: 3.915125846862793
Validation loss: 3.9301665772637016
Epoch: 9| Step: 15
Training loss: 4.390491485595703
Validation loss: 3.926761985682755
Epoch: 9| Step: 16
Training loss: 3.688150405883789
Validation loss: 3.9212832879677095
Epoch: 9| Step: 17
Training loss: 4.307949066162109
Validation loss: 3.9170515537261963
Epoch: 9| Step: 18
Training loss: 5.6654863357543945
Validation loss: 3.9104504568113696
Epoch: 9| Step: 19
Training loss: 3.691615343093872
Validation loss: 3.9056735450415303
Epoch: 16| Step: 0
Training loss: 4.612837791442871
Validation loss: 3.899421765649919
Epoch: 9| Step: 1
Training loss: 3.358945608139038
Validation loss: 3.8951827141878415
Epoch: 9| Step: 2
Training loss: 4.633864879608154
Validation loss: 3.8900885376141225
Epoch: 9| Step: 3
Training loss: 3.1491403579711914
Validation loss: 3.8845798094495594
Epoch: 9| Step: 4
Training loss: 4.250207901000977
Validation loss: 3.880215439007437
Epoch: 9| Step: 5
Training loss: 4.787264823913574
Validation loss: 3.874706089925423
Epoch: 9| Step: 6
Training loss: 3.922283172607422
Validation loss: 3.87013951651484
Epoch: 9| Step: 7
Training loss: 3.7396202087402344
Validation loss: 3.8638754113972618
Epoch: 9| Step: 8
Training loss: 4.517839431762695
Validation loss: 3.8612021748110545
Epoch: 9| Step: 9
Training loss: 4.785504341125488
Validation loss: 3.8541444737276587
Epoch: 9| Step: 10
Training loss: 4.068852424621582
Validation loss: 3.8518738986776886
Epoch: 9| Step: 11
Training loss: 4.642423629760742
Validation loss: 3.844896645854703
Epoch: 9| Step: 12
Training loss: 4.951510429382324
Validation loss: 3.840985157506929
Epoch: 9| Step: 13
Training loss: 4.239870071411133
Validation loss: 3.8362059541743436
Epoch: 9| Step: 14
Training loss: 3.824734926223755
Validation loss: 3.8306775847784906
Epoch: 9| Step: 15
Training loss: 3.6134355068206787
Validation loss: 3.82644843197555
Epoch: 9| Step: 16
Training loss: 3.7737505435943604
Validation loss: 3.8205500558125887
Epoch: 9| Step: 17
Training loss: 4.525598526000977
Validation loss: 3.8174315356522155
Epoch: 9| Step: 18
Training loss: 3.4748177528381348
Validation loss: 3.813566406853765
Epoch: 9| Step: 19
Training loss: 3.635007381439209
Validation loss: 3.8087670202735517
Epoch: 17| Step: 0
Training loss: 3.9368155002593994
Validation loss: 3.803173967402616
Epoch: 9| Step: 1
Training loss: 2.9085488319396973
Validation loss: 3.7984937455156724
Epoch: 9| Step: 2
Training loss: 4.258327960968018
Validation loss: 3.795015412268879
Epoch: 9| Step: 3
Training loss: 3.282390832901001
Validation loss: 3.7904180314043443
Epoch: 9| Step: 4
Training loss: 2.991617441177368
Validation loss: 3.7863090226976133
Epoch: 9| Step: 5
Training loss: 4.809075355529785
Validation loss: 3.7817787472292674
Epoch: 9| Step: 6
Training loss: 4.193065643310547
Validation loss: 3.7771097138631258
Epoch: 9| Step: 7
Training loss: 3.611208915710449
Validation loss: 3.7735310286926707
Epoch: 9| Step: 8
Training loss: 4.760049819946289
Validation loss: 3.7683551122816348
Epoch: 9| Step: 9
Training loss: 3.6475391387939453
Validation loss: 3.7646716927452912
Epoch: 9| Step: 10
Training loss: 4.762518405914307
Validation loss: 3.7590740944841783
Epoch: 9| Step: 11
Training loss: 4.412045478820801
Validation loss: 3.7566555249605247
Epoch: 9| Step: 12
Training loss: 2.7736785411834717
Validation loss: 3.7521415751615015
Epoch: 9| Step: 13
Training loss: 3.666995048522949
Validation loss: 3.7488690348837874
Epoch: 9| Step: 14
Training loss: 3.947114944458008
Validation loss: 3.745397795876153
Epoch: 9| Step: 15
Training loss: 3.2614479064941406
Validation loss: 3.7392247666557914
Epoch: 9| Step: 16
Training loss: 4.7875142097473145
Validation loss: 3.735509424758472
Epoch: 9| Step: 17
Training loss: 4.689874649047852
Validation loss: 3.7338206167701338
Epoch: 9| Step: 18
Training loss: 4.9073076248168945
Validation loss: 3.726434223943477
Epoch: 9| Step: 19
Training loss: 5.313086986541748
Validation loss: 3.723450667566533
Epoch: 18| Step: 0
Training loss: 3.6169896125793457
Validation loss: 3.720553864678033
Epoch: 9| Step: 1
Training loss: 4.192502498626709
Validation loss: 3.714240249112356
Epoch: 9| Step: 2
Training loss: 4.475703239440918
Validation loss: 3.7113040728534727
Epoch: 9| Step: 3
Training loss: 3.5225460529327393
Validation loss: 3.7066901296162778
Epoch: 9| Step: 4
Training loss: 4.363378524780273
Validation loss: 3.7020333104854006
Epoch: 9| Step: 5
Training loss: 3.121128559112549
Validation loss: 3.6982027986924426
Epoch: 9| Step: 6
Training loss: 3.7048354148864746
Validation loss: 3.6940954794986642
Epoch: 9| Step: 7
Training loss: 4.360167503356934
Validation loss: 3.688500761128158
Epoch: 9| Step: 8
Training loss: 3.9602508544921875
Validation loss: 3.686807325418047
Epoch: 9| Step: 9
Training loss: 3.6555016040802
Validation loss: 3.6822263628458805
Epoch: 9| Step: 10
Training loss: 3.8975749015808105
Validation loss: 3.678758902515439
Epoch: 9| Step: 11
Training loss: 4.248455047607422
Validation loss: 3.6759163081217157
Epoch: 9| Step: 12
Training loss: 3.9793570041656494
Validation loss: 3.673427833927621
Epoch: 9| Step: 13
Training loss: 4.871193885803223
Validation loss: 3.668020673792997
Epoch: 9| Step: 14
Training loss: 4.735620021820068
Validation loss: 3.661862550021933
Epoch: 9| Step: 15
Training loss: 5.054474830627441
Validation loss: 3.6612933659725053
Epoch: 9| Step: 16
Training loss: 3.347031593322754
Validation loss: 3.657275542938452
Epoch: 9| Step: 17
Training loss: 2.728177547454834
Validation loss: 3.6529319852376156
Epoch: 9| Step: 18
Training loss: 3.9333553314208984
Validation loss: 3.6489959860877166
Epoch: 9| Step: 19
Training loss: 3.7779340744018555
Validation loss: 3.6449947683073636
Epoch: 19| Step: 0
Training loss: 3.7317585945129395
Validation loss: 3.642070389480042
Epoch: 9| Step: 1
Training loss: 4.350542068481445
Validation loss: 3.6378214582264854
Epoch: 9| Step: 2
Training loss: 3.625791072845459
Validation loss: 3.633229708500046
Epoch: 9| Step: 3
Training loss: 3.849806308746338
Validation loss: 3.6299844577158096
Epoch: 9| Step: 4
Training loss: 5.303990364074707
Validation loss: 3.626532072643582
Epoch: 9| Step: 5
Training loss: 3.2891011238098145
Validation loss: 3.6234179898131664
Epoch: 9| Step: 6
Training loss: 4.423206329345703
Validation loss: 3.6187821618087
Epoch: 9| Step: 7
Training loss: 3.0501880645751953
Validation loss: 3.6158964908380304
Epoch: 9| Step: 8
Training loss: 4.301298141479492
Validation loss: 3.611843352695163
Epoch: 9| Step: 9
Training loss: 3.171165943145752
Validation loss: 3.608777629385749
Epoch: 9| Step: 10
Training loss: 4.51492977142334
Validation loss: 3.606433132569567
Epoch: 9| Step: 11
Training loss: 3.8340401649475098
Validation loss: 3.601413999530051
Epoch: 9| Step: 12
Training loss: 2.9445765018463135
Validation loss: 3.5981238677347305
Epoch: 9| Step: 13
Training loss: 4.0100202560424805
Validation loss: 3.594967711743691
Epoch: 9| Step: 14
Training loss: 3.405104637145996
Validation loss: 3.5915510362858396
Epoch: 9| Step: 15
Training loss: 3.8499560356140137
Validation loss: 3.58868572523268
Epoch: 9| Step: 16
Training loss: 4.435946464538574
Validation loss: 3.5826401178785363
Epoch: 9| Step: 17
Training loss: 4.417474746704102
Validation loss: 3.5820709629882153
Epoch: 9| Step: 18
Training loss: 4.071954250335693
Validation loss: 3.577792788581025
Epoch: 9| Step: 19
Training loss: 3.685936689376831
Validation loss: 3.573991453047279
Epoch: 20| Step: 0
Training loss: 4.314272403717041
Validation loss: 3.5699932523768583
Epoch: 9| Step: 1
Training loss: 2.7587194442749023
Validation loss: 3.5667007758463027
Epoch: 9| Step: 2
Training loss: 4.076440811157227
Validation loss: 3.5622292954287085
Epoch: 9| Step: 3
Training loss: 4.05843448638916
Validation loss: 3.5594434309348784
Epoch: 9| Step: 4
Training loss: 3.5033211708068848
Validation loss: 3.5568492995749277
Epoch: 9| Step: 5
Training loss: 3.6522088050842285
Validation loss: 3.554048586234772
Epoch: 9| Step: 6
Training loss: 4.517022132873535
Validation loss: 3.5458483747441134
Epoch: 9| Step: 7
Training loss: 3.024472951889038
Validation loss: 3.543610056527227
Epoch: 9| Step: 8
Training loss: 3.9958720207214355
Validation loss: 3.540212128659804
Epoch: 9| Step: 9
Training loss: 4.345236778259277
Validation loss: 3.5373421058380345
Epoch: 9| Step: 10
Training loss: 3.860893726348877
Validation loss: 3.534680946267766
Epoch: 9| Step: 11
Training loss: 4.966534614562988
Validation loss: 3.5296382303718183
Epoch: 9| Step: 12
Training loss: 3.705393075942993
Validation loss: 3.5267994335229447
Epoch: 9| Step: 13
Training loss: 4.1977362632751465
Validation loss: 3.5234626025604685
Epoch: 9| Step: 14
Training loss: 4.605837821960449
Validation loss: 3.5188424638707003
Epoch: 9| Step: 15
Training loss: 4.509380340576172
Validation loss: 3.5154953826245645
Epoch: 9| Step: 16
Training loss: 3.0123956203460693
Validation loss: 3.511842091306508
Epoch: 9| Step: 17
Training loss: 4.080434322357178
Validation loss: 3.5071291803456037
Epoch: 9| Step: 18
Training loss: 2.2188150882720947
Validation loss: 3.502464735250679
Epoch: 9| Step: 19
Training loss: 3.6832919120788574
Validation loss: 3.500119524894001
Epoch: 21| Step: 0
Training loss: 5.608094692230225
Validation loss: 3.4964384243642685
Epoch: 9| Step: 1
Training loss: 2.82725191116333
Validation loss: 3.492021044381231
Epoch: 9| Step: 2
Training loss: 4.502012729644775
Validation loss: 3.487966676410154
Epoch: 9| Step: 3
Training loss: 3.2144899368286133
Validation loss: 3.485036887710901
Epoch: 9| Step: 4
Training loss: 3.765430212020874
Validation loss: 3.4798897925040704
Epoch: 9| Step: 5
Training loss: 4.013946056365967
Validation loss: 3.4774499934354273
Epoch: 9| Step: 6
Training loss: 4.032325744628906
Validation loss: 3.472448743504586
Epoch: 9| Step: 7
Training loss: 4.27040958404541
Validation loss: 3.4681361613513753
Epoch: 9| Step: 8
Training loss: 3.069178581237793
Validation loss: 3.4644401365046877
Epoch: 9| Step: 9
Training loss: 4.254327297210693
Validation loss: 3.4594258593140745
Epoch: 9| Step: 10
Training loss: 3.944146156311035
Validation loss: 3.455183265878142
Epoch: 9| Step: 11
Training loss: 3.5992116928100586
Validation loss: 3.4502051631323725
Epoch: 9| Step: 12
Training loss: 2.7439610958099365
Validation loss: 3.444302428540566
Epoch: 9| Step: 13
Training loss: 3.6526284217834473
Validation loss: 3.4417982856146723
Epoch: 9| Step: 14
Training loss: 3.3409502506256104
Validation loss: 3.4381781859363585
Epoch: 9| Step: 15
Training loss: 3.7787420749664307
Validation loss: 3.4331085801982195
Epoch: 9| Step: 16
Training loss: 4.0944929122924805
Validation loss: 3.426607423549076
Epoch: 9| Step: 17
Training loss: 4.317194938659668
Validation loss: 3.4253602919818684
Epoch: 9| Step: 18
Training loss: 3.692237615585327
Validation loss: 3.4197196600248487
Epoch: 9| Step: 19
Training loss: 3.088864326477051
Validation loss: 3.414037997774083
Epoch: 22| Step: 0
Training loss: 4.046084880828857
Validation loss: 3.409992902398967
Epoch: 9| Step: 1
Training loss: 3.8744053840637207
Validation loss: 3.4062059594572878
Epoch: 9| Step: 2
Training loss: 4.362008094787598
Validation loss: 3.4014007239032993
Epoch: 9| Step: 3
Training loss: 3.0321269035339355
Validation loss: 3.395496111121967
Epoch: 9| Step: 4
Training loss: 3.0848960876464844
Validation loss: 3.393401200822789
Epoch: 9| Step: 5
Training loss: 3.955929756164551
Validation loss: 3.3867267944829926
Epoch: 9| Step: 6
Training loss: 4.769722938537598
Validation loss: 3.3836411366359793
Epoch: 9| Step: 7
Training loss: 3.2302417755126953
Validation loss: 3.3817693398153184
Epoch: 9| Step: 8
Training loss: 4.682270050048828
Validation loss: 3.3761410232928157
Epoch: 9| Step: 9
Training loss: 3.1348934173583984
Validation loss: 3.3691412750765575
Epoch: 9| Step: 10
Training loss: 3.4399032592773438
Validation loss: 3.3636560285691735
Epoch: 9| Step: 11
Training loss: 2.510981559753418
Validation loss: 3.3609502041082586
Epoch: 9| Step: 12
Training loss: 3.6937928199768066
Validation loss: 3.35856769067778
Epoch: 9| Step: 13
Training loss: 3.6385509967803955
Validation loss: 3.35390957310903
Epoch: 9| Step: 14
Training loss: 3.966599702835083
Validation loss: 3.3468413250051814
Epoch: 9| Step: 15
Training loss: 3.8687174320220947
Validation loss: 3.342747009057793
Epoch: 9| Step: 16
Training loss: 3.7278263568878174
Validation loss: 3.337230714962637
Epoch: 9| Step: 17
Training loss: 3.5572526454925537
Validation loss: 3.3342168759956636
Epoch: 9| Step: 18
Training loss: 3.636141777038574
Validation loss: 3.3299303535077214
Epoch: 9| Step: 19
Training loss: 4.156140327453613
Validation loss: 3.3228659080944474
Epoch: 23| Step: 0
Training loss: 4.562994003295898
Validation loss: 3.32078088959344
Epoch: 9| Step: 1
Training loss: 3.9650111198425293
Validation loss: 3.31811504912891
Epoch: 9| Step: 2
Training loss: 4.0614190101623535
Validation loss: 3.312235765319934
Epoch: 9| Step: 3
Training loss: 4.612246990203857
Validation loss: 3.3084010048735912
Epoch: 9| Step: 4
Training loss: 3.03706693649292
Validation loss: 3.304828487711845
Epoch: 9| Step: 5
Training loss: 2.7279789447784424
Validation loss: 3.298494640871775
Epoch: 9| Step: 6
Training loss: 4.230881214141846
Validation loss: 3.29392962147006
Epoch: 9| Step: 7
Training loss: 3.978858470916748
Validation loss: 3.289890040596612
Epoch: 9| Step: 8
Training loss: 3.537285327911377
Validation loss: 3.2864740975469138
Epoch: 9| Step: 9
Training loss: 4.181417465209961
Validation loss: 3.279785706842546
Epoch: 9| Step: 10
Training loss: 4.287191390991211
Validation loss: 3.2745694702477763
Epoch: 9| Step: 11
Training loss: 2.8378007411956787
Validation loss: 3.2706468637041053
Epoch: 9| Step: 12
Training loss: 3.4139633178710938
Validation loss: 3.2689402943892443
Epoch: 9| Step: 13
Training loss: 2.7792232036590576
Validation loss: 3.2633144718279943
Epoch: 9| Step: 14
Training loss: 3.5095269680023193
Validation loss: 3.260004938935204
Epoch: 9| Step: 15
Training loss: 2.057462215423584
Validation loss: 3.25679217139594
Epoch: 9| Step: 16
Training loss: 3.971123218536377
Validation loss: 3.2506747846123125
Epoch: 9| Step: 17
Training loss: 3.6109824180603027
Validation loss: 3.2472704914834
Epoch: 9| Step: 18
Training loss: 3.9811413288116455
Validation loss: 3.244684625872605
Epoch: 9| Step: 19
Training loss: 3.687361717224121
Validation loss: 3.2417945947578484
Epoch: 24| Step: 0
Training loss: 3.9353463649749756
Validation loss: 3.2356176908067664
Epoch: 9| Step: 1
Training loss: 3.1855223178863525
Validation loss: 3.2316867584804836
Epoch: 9| Step: 2
Training loss: 3.7106006145477295
Validation loss: 3.228109493530054
Epoch: 9| Step: 3
Training loss: 3.863443374633789
Validation loss: 3.226785599756584
Epoch: 9| Step: 4
Training loss: 4.49500846862793
Validation loss: 3.2208238248344805
Epoch: 9| Step: 5
Training loss: 2.9367642402648926
Validation loss: 3.2180268747343432
Epoch: 9| Step: 6
Training loss: 3.3830838203430176
Validation loss: 3.213879477205894
Epoch: 9| Step: 7
Training loss: 3.5122475624084473
Validation loss: 3.2091979688877683
Epoch: 9| Step: 8
Training loss: 3.501753330230713
Validation loss: 3.2073749518222945
Epoch: 9| Step: 9
Training loss: 3.3258399963378906
Validation loss: 3.2035887893155324
Epoch: 9| Step: 10
Training loss: 3.2374372482299805
Validation loss: 3.1980039301536065
Epoch: 9| Step: 11
Training loss: 3.478487968444824
Validation loss: 3.1960946364368468
Epoch: 9| Step: 12
Training loss: 3.977590322494507
Validation loss: 3.192019122967617
Epoch: 9| Step: 13
Training loss: 3.5016822814941406
Validation loss: 3.187304167438754
Epoch: 9| Step: 14
Training loss: 3.4424080848693848
Validation loss: 3.1840068402050212
Epoch: 9| Step: 15
Training loss: 3.63558030128479
Validation loss: 3.1826116438392256
Epoch: 9| Step: 16
Training loss: 3.7740373611450195
Validation loss: 3.1762777301047347
Epoch: 9| Step: 17
Training loss: 3.0522046089172363
Validation loss: 3.1738935751880675
Epoch: 9| Step: 18
Training loss: 4.341108322143555
Validation loss: 3.1702039516229426
Epoch: 9| Step: 19
Training loss: 3.4953176975250244
Validation loss: 3.166211598211055
Epoch: 25| Step: 0
Training loss: 3.6547112464904785
Validation loss: 3.164493809501044
Epoch: 9| Step: 1
Training loss: 2.916389226913452
Validation loss: 3.159213889417031
Epoch: 9| Step: 2
Training loss: 4.30793571472168
Validation loss: 3.156391828180217
Epoch: 9| Step: 3
Training loss: 4.1407318115234375
Validation loss: 3.154426519819301
Epoch: 9| Step: 4
Training loss: 3.6985385417938232
Validation loss: 3.1519650572495497
Epoch: 9| Step: 5
Training loss: 4.225296497344971
Validation loss: 3.148016903897841
Epoch: 9| Step: 6
Training loss: 3.065196990966797
Validation loss: 3.146012872243099
Epoch: 9| Step: 7
Training loss: 2.7161178588867188
Validation loss: 3.14363400370097
Epoch: 9| Step: 8
Training loss: 2.7983367443084717
Validation loss: 3.1388311557632558
Epoch: 9| Step: 9
Training loss: 3.309365749359131
Validation loss: 3.137522083392246
Epoch: 9| Step: 10
Training loss: 3.144017219543457
Validation loss: 3.134683130456389
Epoch: 9| Step: 11
Training loss: 4.28018856048584
Validation loss: 3.1289388807557468
Epoch: 9| Step: 12
Training loss: 3.366136312484741
Validation loss: 3.129450456701594
Epoch: 9| Step: 13
Training loss: 4.632931232452393
Validation loss: 3.1258265303193236
Epoch: 9| Step: 14
Training loss: 4.170340061187744
Validation loss: 3.123109832942057
Epoch: 9| Step: 15
Training loss: 2.6990461349487305
Validation loss: 3.1198997368915475
Epoch: 9| Step: 16
Training loss: 3.1066224575042725
Validation loss: 3.115955953117755
Epoch: 9| Step: 17
Training loss: 3.9467673301696777
Validation loss: 3.1120538042603636
Epoch: 9| Step: 18
Training loss: 2.6999497413635254
Validation loss: 3.1104743189091306
Epoch: 9| Step: 19
Training loss: 3.8105337619781494
Validation loss: 3.1079794314267826
Epoch: 26| Step: 0
Training loss: 2.576735258102417
Validation loss: 3.106021041492764
Epoch: 9| Step: 1
Training loss: 2.8761682510375977
Validation loss: 3.1007013595361506
Epoch: 9| Step: 2
Training loss: 3.9989044666290283
Validation loss: 3.0982583546810014
Epoch: 9| Step: 3
Training loss: 3.8379454612731934
Validation loss: 3.09635234565186
Epoch: 9| Step: 4
Training loss: 3.737298011779785
Validation loss: 3.0942391114269228
Epoch: 9| Step: 5
Training loss: 3.095963716506958
Validation loss: 3.090072293933347
Epoch: 9| Step: 6
Training loss: 3.418473720550537
Validation loss: 3.0889339292649742
Epoch: 9| Step: 7
Training loss: 3.600916862487793
Validation loss: 3.0851458662705458
Epoch: 9| Step: 8
Training loss: 3.3747360706329346
Validation loss: 3.0826070222923225
Epoch: 9| Step: 9
Training loss: 3.6041345596313477
Validation loss: 3.081037900430693
Epoch: 9| Step: 10
Training loss: 3.5963568687438965
Validation loss: 3.0773784411039284
Epoch: 9| Step: 11
Training loss: 3.6635570526123047
Validation loss: 3.0742457547633766
Epoch: 9| Step: 12
Training loss: 3.3188059329986572
Validation loss: 3.071491042487055
Epoch: 9| Step: 13
Training loss: 3.9632232189178467
Validation loss: 3.070264166207622
Epoch: 9| Step: 14
Training loss: 3.5215370655059814
Validation loss: 3.0690542210777885
Epoch: 9| Step: 15
Training loss: 2.881193161010742
Validation loss: 3.064496729871352
Epoch: 9| Step: 16
Training loss: 3.606308937072754
Validation loss: 3.0635402133996537
Epoch: 9| Step: 17
Training loss: 3.4252371788024902
Validation loss: 3.0609140516185076
Epoch: 9| Step: 18
Training loss: 3.335995674133301
Validation loss: 3.057027265322294
Epoch: 9| Step: 19
Training loss: 4.387361526489258
Validation loss: 3.0567107492213625
Epoch: 27| Step: 0
Training loss: 2.947744846343994
Validation loss: 3.0547041584261887
Epoch: 9| Step: 1
Training loss: 3.317124843597412
Validation loss: 3.0512632500353476
Epoch: 9| Step: 2
Training loss: 4.014498710632324
Validation loss: 3.0492101950611143
Epoch: 9| Step: 3
Training loss: 3.422297954559326
Validation loss: 3.045407144285792
Epoch: 9| Step: 4
Training loss: 3.047231674194336
Validation loss: 3.044716987678473
Epoch: 9| Step: 5
Training loss: 4.502291202545166
Validation loss: 3.0445058019898776
Epoch: 9| Step: 6
Training loss: 2.654526710510254
Validation loss: 3.041247309540673
Epoch: 9| Step: 7
Training loss: 4.458052158355713
Validation loss: 3.03955511223498
Epoch: 9| Step: 8
Training loss: 3.451277256011963
Validation loss: 3.034312975492409
Epoch: 9| Step: 9
Training loss: 3.587338924407959
Validation loss: 3.0371287229249804
Epoch: 9| Step: 10
Training loss: 2.7548322677612305
Validation loss: 3.032784266437558
Epoch: 9| Step: 11
Training loss: 2.6651687622070312
Validation loss: 3.030848137766337
Epoch: 9| Step: 12
Training loss: 3.6999166011810303
Validation loss: 3.028585089196404
Epoch: 9| Step: 13
Training loss: 4.00769567489624
Validation loss: 3.0268362306004803
Epoch: 9| Step: 14
Training loss: 3.787623405456543
Validation loss: 3.0280924752461824
Epoch: 9| Step: 15
Training loss: 3.28645396232605
Validation loss: 3.024248776675986
Epoch: 9| Step: 16
Training loss: 2.552675485610962
Validation loss: 3.021677440876583
Epoch: 9| Step: 17
Training loss: 3.052361249923706
Validation loss: 3.0190508108344867
Epoch: 9| Step: 18
Training loss: 4.11044979095459
Validation loss: 3.0191855928023084
Epoch: 9| Step: 19
Training loss: 3.7448878288269043
Validation loss: 3.0185156314493082
Epoch: 28| Step: 0
Training loss: 2.9810285568237305
Validation loss: 3.015889752683022
Epoch: 9| Step: 1
Training loss: 2.4986183643341064
Validation loss: 3.01273424676854
Epoch: 9| Step: 2
Training loss: 4.166225433349609
Validation loss: 3.0107574874548604
Epoch: 9| Step: 3
Training loss: 3.891012191772461
Validation loss: 3.00999098372974
Epoch: 9| Step: 4
Training loss: 4.444453239440918
Validation loss: 3.005639283777141
Epoch: 9| Step: 5
Training loss: 2.911159038543701
Validation loss: 3.0064756081258652
Epoch: 9| Step: 6
Training loss: 3.386795997619629
Validation loss: 3.0038133833905776
Epoch: 9| Step: 7
Training loss: 3.671785831451416
Validation loss: 3.0042302831471397
Epoch: 9| Step: 8
Training loss: 3.623220443725586
Validation loss: 3.0002709995928427
Epoch: 9| Step: 9
Training loss: 3.9542908668518066
Validation loss: 2.9977320424086757
Epoch: 9| Step: 10
Training loss: 3.469560146331787
Validation loss: 2.996322062375734
Epoch: 9| Step: 11
Training loss: 3.4766383171081543
Validation loss: 2.996787412561101
Epoch: 9| Step: 12
Training loss: 2.6932830810546875
Validation loss: 2.993386064501975
Epoch: 9| Step: 13
Training loss: 2.975473403930664
Validation loss: 2.9908762509874305
Epoch: 9| Step: 14
Training loss: 2.3751955032348633
Validation loss: 2.9885795613844617
Epoch: 9| Step: 15
Training loss: 4.044556617736816
Validation loss: 2.989315326265294
Epoch: 9| Step: 16
Training loss: 2.8965492248535156
Validation loss: 2.988728674195653
Epoch: 9| Step: 17
Training loss: 3.8834478855133057
Validation loss: 2.9867440059030654
Epoch: 9| Step: 18
Training loss: 3.2920069694519043
Validation loss: 2.9867554534253458
Epoch: 9| Step: 19
Training loss: 3.8039186000823975
Validation loss: 2.9824863475003687
Epoch: 29| Step: 0
Training loss: 2.750027656555176
Validation loss: 2.9828456168552098
Epoch: 9| Step: 1
Training loss: 2.754328966140747
Validation loss: 2.9811435929305263
Epoch: 9| Step: 2
Training loss: 3.818467140197754
Validation loss: 2.9802960423256852
Epoch: 9| Step: 3
Training loss: 4.203458786010742
Validation loss: 2.977779777787572
Epoch: 9| Step: 4
Training loss: 3.697923183441162
Validation loss: 2.9769941028073537
Epoch: 9| Step: 5
Training loss: 2.854173183441162
Validation loss: 2.974989527421032
Epoch: 9| Step: 6
Training loss: 4.106520175933838
Validation loss: 2.9724005229181523
Epoch: 9| Step: 7
Training loss: 3.633943557739258
Validation loss: 2.9720311130551127
Epoch: 9| Step: 8
Training loss: 3.6822245121002197
Validation loss: 2.969148767937859
Epoch: 9| Step: 9
Training loss: 3.5931100845336914
Validation loss: 2.966225961987063
Epoch: 9| Step: 10
Training loss: 2.994053363800049
Validation loss: 2.96759766640423
Epoch: 9| Step: 11
Training loss: 2.967733383178711
Validation loss: 2.966559300319754
Epoch: 9| Step: 12
Training loss: 3.400493621826172
Validation loss: 2.9647821248006476
Epoch: 9| Step: 13
Training loss: 3.696678638458252
Validation loss: 2.9628217752031287
Epoch: 9| Step: 14
Training loss: 4.381597518920898
Validation loss: 2.9617493770105376
Epoch: 9| Step: 15
Training loss: 3.3876004219055176
Validation loss: 2.959935227744013
Epoch: 9| Step: 16
Training loss: 3.1989855766296387
Validation loss: 2.9589204067806545
Epoch: 9| Step: 17
Training loss: 3.325315237045288
Validation loss: 2.9580262324792876
Epoch: 9| Step: 18
Training loss: 1.9099664688110352
Validation loss: 2.9576120753940063
Epoch: 9| Step: 19
Training loss: 3.580580234527588
Validation loss: 2.951649923118756
Epoch: 30| Step: 0
Training loss: 3.535195827484131
Validation loss: 2.9562243403290673
Epoch: 9| Step: 1
Training loss: 3.163252353668213
Validation loss: 2.9514907589919277
Epoch: 9| Step: 2
Training loss: 3.0330517292022705
Validation loss: 2.9510995930047343
Epoch: 9| Step: 3
Training loss: 3.4614062309265137
Validation loss: 2.9489577279674064
Epoch: 9| Step: 4
Training loss: 2.922013282775879
Validation loss: 2.95000691894147
Epoch: 9| Step: 5
Training loss: 3.7749197483062744
Validation loss: 2.9482895899162016
Epoch: 9| Step: 6
Training loss: 2.4715359210968018
Validation loss: 2.943713227621943
Epoch: 9| Step: 7
Training loss: 3.0958855152130127
Validation loss: 2.9449317712577985
Epoch: 9| Step: 8
Training loss: 3.7745649814605713
Validation loss: 2.944190582783102
Epoch: 9| Step: 9
Training loss: 2.9528517723083496
Validation loss: 2.9442799485844673
Epoch: 9| Step: 10
Training loss: 3.18503999710083
Validation loss: 2.9403915216596865
Epoch: 9| Step: 11
Training loss: 4.53071403503418
Validation loss: 2.9381044442705115
Epoch: 9| Step: 12
Training loss: 2.9664840698242188
Validation loss: 2.9379107197411627
Epoch: 9| Step: 13
Training loss: 3.5489606857299805
Validation loss: 2.9367059958066872
Epoch: 9| Step: 14
Training loss: 2.97585129737854
Validation loss: 2.933555946075659
Epoch: 9| Step: 15
Training loss: 2.960144281387329
Validation loss: 2.9318017153431186
Epoch: 9| Step: 16
Training loss: 4.359895706176758
Validation loss: 2.931648084585615
Epoch: 9| Step: 17
Training loss: 3.6036598682403564
Validation loss: 2.927507410804145
Epoch: 9| Step: 18
Training loss: 3.2870922088623047
Validation loss: 2.926323106820635
Epoch: 9| Step: 19
Training loss: 3.843869686126709
Validation loss: 2.923368498575773
Epoch: 31| Step: 0
Training loss: 3.8215177059173584
Validation loss: 2.9232685737472646
Epoch: 9| Step: 1
Training loss: 3.410010576248169
Validation loss: 2.9202714463789685
Epoch: 9| Step: 2
Training loss: 2.862412929534912
Validation loss: 2.919057527034403
Epoch: 9| Step: 3
Training loss: 3.9270777702331543
Validation loss: 2.9160582333159963
Epoch: 9| Step: 4
Training loss: 3.7313523292541504
Validation loss: 2.912961802036642
Epoch: 9| Step: 5
Training loss: 3.00606107711792
Validation loss: 2.912320768232826
Epoch: 9| Step: 6
Training loss: 3.7521305084228516
Validation loss: 2.912518444678766
Epoch: 9| Step: 7
Training loss: 4.643322944641113
Validation loss: 2.909874296874451
Epoch: 9| Step: 8
Training loss: 2.711308002471924
Validation loss: 2.907818492367971
Epoch: 9| Step: 9
Training loss: 2.7200546264648438
Validation loss: 2.904947596488239
Epoch: 9| Step: 10
Training loss: 3.182386875152588
Validation loss: 2.9053552613841545
Epoch: 9| Step: 11
Training loss: 3.388294219970703
Validation loss: 2.902917976859662
Epoch: 9| Step: 12
Training loss: 3.5936102867126465
Validation loss: 2.901135031267893
Epoch: 9| Step: 13
Training loss: 2.5226166248321533
Validation loss: 2.89930533333648
Epoch: 9| Step: 14
Training loss: 3.348647117614746
Validation loss: 2.8974050737971027
Epoch: 9| Step: 15
Training loss: 3.0814526081085205
Validation loss: 2.894519687556534
Epoch: 9| Step: 16
Training loss: 4.392458915710449
Validation loss: 2.8941483171723728
Epoch: 9| Step: 17
Training loss: 2.8545124530792236
Validation loss: 2.893768934894809
Epoch: 9| Step: 18
Training loss: 3.324140787124634
Validation loss: 2.8908672401373336
Epoch: 9| Step: 19
Training loss: 2.6187620162963867
Validation loss: 2.891258591370617
Epoch: 32| Step: 0
Training loss: 3.563542366027832
Validation loss: 2.8868017711227747
Epoch: 9| Step: 1
Training loss: 3.1460108757019043
Validation loss: 2.8873330946448896
Epoch: 9| Step: 2
Training loss: 3.676630973815918
Validation loss: 2.8859849010440084
Epoch: 9| Step: 3
Training loss: 3.1796789169311523
Validation loss: 2.8848241061615427
Epoch: 9| Step: 4
Training loss: 4.160540580749512
Validation loss: 2.8843082678403786
Epoch: 9| Step: 5
Training loss: 2.8304190635681152
Validation loss: 2.881418567767246
Epoch: 9| Step: 6
Training loss: 3.739729642868042
Validation loss: 2.8809858586290757
Epoch: 9| Step: 7
Training loss: 2.913909435272217
Validation loss: 2.8775498764120417
Epoch: 9| Step: 8
Training loss: 4.238371849060059
Validation loss: 2.8764777903934178
Epoch: 9| Step: 9
Training loss: 3.149441957473755
Validation loss: 2.8729593204937394
Epoch: 9| Step: 10
Training loss: 3.432839870452881
Validation loss: 2.8724119457409536
Epoch: 9| Step: 11
Training loss: 2.701751708984375
Validation loss: 2.8727745512406604
Epoch: 9| Step: 12
Training loss: 2.6440815925598145
Validation loss: 2.871991668673728
Epoch: 9| Step: 13
Training loss: 2.771906614303589
Validation loss: 2.8688796312688924
Epoch: 9| Step: 14
Training loss: 3.187232494354248
Validation loss: 2.8669177816926146
Epoch: 9| Step: 15
Training loss: 3.2707438468933105
Validation loss: 2.865929044407906
Epoch: 9| Step: 16
Training loss: 2.5140254497528076
Validation loss: 2.8639283386065806
Epoch: 9| Step: 17
Training loss: 4.061316013336182
Validation loss: 2.861457817846065
Epoch: 9| Step: 18
Training loss: 3.535186290740967
Validation loss: 2.862815891238425
Epoch: 9| Step: 19
Training loss: 3.6936891078948975
Validation loss: 2.860303151521751
Epoch: 33| Step: 0
Training loss: 3.604001760482788
Validation loss: 2.8580875551100258
Epoch: 9| Step: 1
Training loss: 2.8500542640686035
Validation loss: 2.856396659672689
Epoch: 9| Step: 2
Training loss: 3.4446306228637695
Validation loss: 2.851217564919012
Epoch: 9| Step: 3
Training loss: 3.15863037109375
Validation loss: 2.8526149585092666
Epoch: 9| Step: 4
Training loss: 2.8920047283172607
Validation loss: 2.851692139673576
Epoch: 9| Step: 5
Training loss: 3.5979082584381104
Validation loss: 2.8516614865913668
Epoch: 9| Step: 6
Training loss: 3.2807085514068604
Validation loss: 2.850907879767658
Epoch: 9| Step: 7
Training loss: 2.846099853515625
Validation loss: 2.8465328062180992
Epoch: 9| Step: 8
Training loss: 2.5851476192474365
Validation loss: 2.847010940098934
Epoch: 9| Step: 9
Training loss: 3.3070616722106934
Validation loss: 2.845330453605103
Epoch: 9| Step: 10
Training loss: 3.9954161643981934
Validation loss: 2.8422330866614693
Epoch: 9| Step: 11
Training loss: 4.810860633850098
Validation loss: 2.8420054157860846
Epoch: 9| Step: 12
Training loss: 3.1748993396759033
Validation loss: 2.8427256783135504
Epoch: 9| Step: 13
Training loss: 3.8221004009246826
Validation loss: 2.840457772179473
Epoch: 9| Step: 14
Training loss: 2.8435187339782715
Validation loss: 2.8394753246856252
Epoch: 9| Step: 15
Training loss: 3.2131412029266357
Validation loss: 2.8367439156813585
Epoch: 9| Step: 16
Training loss: 2.9027724266052246
Validation loss: 2.838217194989431
Epoch: 9| Step: 17
Training loss: 3.093461036682129
Validation loss: 2.8347234811714226
Epoch: 9| Step: 18
Training loss: 3.2017197608947754
Validation loss: 2.831217499945661
Epoch: 9| Step: 19
Training loss: 3.2829158306121826
Validation loss: 2.831735290211739
Epoch: 34| Step: 0
Training loss: 2.6560797691345215
Validation loss: 2.8297451485832816
Epoch: 9| Step: 1
Training loss: 3.306748390197754
Validation loss: 2.8296368585216056
Epoch: 9| Step: 2
Training loss: 2.9664649963378906
Validation loss: 2.825216471720085
Epoch: 9| Step: 3
Training loss: 2.464258909225464
Validation loss: 2.8243654974930577
Epoch: 9| Step: 4
Training loss: 3.0175294876098633
Validation loss: 2.823637109866245
Epoch: 9| Step: 5
Training loss: 3.928281784057617
Validation loss: 2.8232777616102918
Epoch: 9| Step: 6
Training loss: 3.0137619972229004
Validation loss: 2.8191169320250586
Epoch: 9| Step: 7
Training loss: 3.593461036682129
Validation loss: 2.81980328251132
Epoch: 9| Step: 8
Training loss: 2.5433783531188965
Validation loss: 2.8204433849389603
Epoch: 9| Step: 9
Training loss: 3.947352409362793
Validation loss: 2.816743059981641
Epoch: 9| Step: 10
Training loss: 3.8250913619995117
Validation loss: 2.8155021170060412
Epoch: 9| Step: 11
Training loss: 2.9636945724487305
Validation loss: 2.8148055539714347
Epoch: 9| Step: 12
Training loss: 3.3218870162963867
Validation loss: 2.8148168436914895
Epoch: 9| Step: 13
Training loss: 3.051311492919922
Validation loss: 2.8117069288981047
Epoch: 9| Step: 14
Training loss: 3.9236040115356445
Validation loss: 2.8110437444645724
Epoch: 9| Step: 15
Training loss: 2.936096668243408
Validation loss: 2.8095851544853594
Epoch: 9| Step: 16
Training loss: 3.7924957275390625
Validation loss: 2.808934352380766
Epoch: 9| Step: 17
Training loss: 4.02651309967041
Validation loss: 2.810786808137413
Epoch: 9| Step: 18
Training loss: 3.4239330291748047
Validation loss: 2.8034207443539185
Epoch: 9| Step: 19
Training loss: 2.729659080505371
Validation loss: 2.8046090053997452
Epoch: 35| Step: 0
Training loss: 4.195815086364746
Validation loss: 2.802541024393315
Epoch: 9| Step: 1
Training loss: 3.085874080657959
Validation loss: 2.8048562660491725
Epoch: 9| Step: 2
Training loss: 3.2628116607666016
Validation loss: 2.8005770487751036
Epoch: 9| Step: 3
Training loss: 3.580575704574585
Validation loss: 2.802991614924918
Epoch: 9| Step: 4
Training loss: 2.8108229637145996
Validation loss: 2.8007542692500054
Epoch: 9| Step: 5
Training loss: 2.9757308959960938
Validation loss: 2.7972176906873853
Epoch: 9| Step: 6
Training loss: 3.039565324783325
Validation loss: 2.794899254394092
Epoch: 9| Step: 7
Training loss: 2.903322458267212
Validation loss: 2.7922364601986014
Epoch: 9| Step: 8
Training loss: 3.4617998600006104
Validation loss: 2.792437265245177
Epoch: 9| Step: 9
Training loss: 2.960216522216797
Validation loss: 2.790633740184976
Epoch: 9| Step: 10
Training loss: 2.851200580596924
Validation loss: 2.7899730308450383
Epoch: 9| Step: 11
Training loss: 3.2423086166381836
Validation loss: 2.7901942301139555
Epoch: 9| Step: 12
Training loss: 2.2396111488342285
Validation loss: 2.7862341952838485
Epoch: 9| Step: 13
Training loss: 2.7477922439575195
Validation loss: 2.7850858290418445
Epoch: 9| Step: 14
Training loss: 3.6743650436401367
Validation loss: 2.7855991305207177
Epoch: 9| Step: 15
Training loss: 3.47259259223938
Validation loss: 2.7846915241625667
Epoch: 9| Step: 16
Training loss: 4.257872581481934
Validation loss: 2.78230995926068
Epoch: 9| Step: 17
Training loss: 3.1001338958740234
Validation loss: 2.7829876460617395
Epoch: 9| Step: 18
Training loss: 3.515739679336548
Validation loss: 2.7813574530237872
Epoch: 9| Step: 19
Training loss: 3.64064359664917
Validation loss: 2.7790979086923944
Epoch: 36| Step: 0
Training loss: 3.258989095687866
Validation loss: 2.7774304245873322
Epoch: 9| Step: 1
Training loss: 3.469177722930908
Validation loss: 2.7780603470562175
Epoch: 9| Step: 2
Training loss: 2.2530977725982666
Validation loss: 2.7742877349579076
Epoch: 9| Step: 3
Training loss: 3.6015613079071045
Validation loss: 2.7761910613492238
Epoch: 9| Step: 4
Training loss: 2.3931541442871094
Validation loss: 2.7734580262959434
Epoch: 9| Step: 5
Training loss: 3.1798276901245117
Validation loss: 2.773951569907099
Epoch: 9| Step: 6
Training loss: 3.089895486831665
Validation loss: 2.7711834804617244
Epoch: 9| Step: 7
Training loss: 2.190859794616699
Validation loss: 2.768797512534711
Epoch: 9| Step: 8
Training loss: 2.563157558441162
Validation loss: 2.7697392316173306
Epoch: 9| Step: 9
Training loss: 2.022519588470459
Validation loss: 2.7681784355383123
Epoch: 9| Step: 10
Training loss: 3.84975266456604
Validation loss: 2.7654100630780776
Epoch: 9| Step: 11
Training loss: 3.478071928024292
Validation loss: 2.7657080691495386
Epoch: 9| Step: 12
Training loss: 4.260335922241211
Validation loss: 2.7627223670053827
Epoch: 9| Step: 13
Training loss: 3.8177356719970703
Validation loss: 2.7626308948873617
Epoch: 9| Step: 14
Training loss: 3.6982264518737793
Validation loss: 2.7627313171359273
Epoch: 9| Step: 15
Training loss: 2.996549367904663
Validation loss: 2.7609329172175565
Epoch: 9| Step: 16
Training loss: 4.177163124084473
Validation loss: 2.759782141061138
Epoch: 9| Step: 17
Training loss: 4.067826271057129
Validation loss: 2.7570938738129978
Epoch: 9| Step: 18
Training loss: 3.462007522583008
Validation loss: 2.7580594724888425
Epoch: 9| Step: 19
Training loss: 2.780552625656128
Validation loss: 2.755293566545994
Epoch: 37| Step: 0
Training loss: 3.0958168506622314
Validation loss: 2.754385812677068
Epoch: 9| Step: 1
Training loss: 2.872588634490967
Validation loss: 2.75504365413309
Epoch: 9| Step: 2
Training loss: 3.443753719329834
Validation loss: 2.749741734360619
Epoch: 9| Step: 3
Training loss: 3.239753246307373
Validation loss: 2.7501148834502955
Epoch: 9| Step: 4
Training loss: 2.423034429550171
Validation loss: 2.7502636069016493
Epoch: 9| Step: 5
Training loss: 3.883763313293457
Validation loss: 2.7482094267289416
Epoch: 9| Step: 6
Training loss: 2.833007335662842
Validation loss: 2.7472540680453075
Epoch: 9| Step: 7
Training loss: 3.6181774139404297
Validation loss: 2.7481729658387546
Epoch: 9| Step: 8
Training loss: 3.3917760848999023
Validation loss: 2.746911992272027
Epoch: 9| Step: 9
Training loss: 3.938587188720703
Validation loss: 2.7442356167937354
Epoch: 9| Step: 10
Training loss: 3.306598663330078
Validation loss: 2.7423430766990715
Epoch: 9| Step: 11
Training loss: 3.245635509490967
Validation loss: 2.7412103268739987
Epoch: 9| Step: 12
Training loss: 2.7443056106567383
Validation loss: 2.743098104600426
Epoch: 9| Step: 13
Training loss: 2.9622559547424316
Validation loss: 2.738888755976725
Epoch: 9| Step: 14
Training loss: 3.81712007522583
Validation loss: 2.7389758851030748
Epoch: 9| Step: 15
Training loss: 3.693957805633545
Validation loss: 2.737403857622215
Epoch: 9| Step: 16
Training loss: 3.1320457458496094
Validation loss: 2.7367763416372615
Epoch: 9| Step: 17
Training loss: 2.8597307205200195
Validation loss: 2.736432320780034
Epoch: 9| Step: 18
Training loss: 2.8683218955993652
Validation loss: 2.735557672788771
Epoch: 9| Step: 19
Training loss: 2.8758087158203125
Validation loss: 2.7315797805786133
Epoch: 38| Step: 0
Training loss: 3.507645606994629
Validation loss: 2.7301100055090815
Epoch: 9| Step: 1
Training loss: 2.3184947967529297
Validation loss: 2.729041260781048
Epoch: 9| Step: 2
Training loss: 3.6133155822753906
Validation loss: 2.7312972065356136
Epoch: 9| Step: 3
Training loss: 3.8978474140167236
Validation loss: 2.7315610535710837
Epoch: 9| Step: 4
Training loss: 2.5746541023254395
Validation loss: 2.7276130494453925
Epoch: 9| Step: 5
Training loss: 3.474849224090576
Validation loss: 2.725653785595791
Epoch: 9| Step: 6
Training loss: 3.103343963623047
Validation loss: 2.728018352453657
Epoch: 9| Step: 7
Training loss: 3.48874568939209
Validation loss: 2.7233538353185858
Epoch: 9| Step: 8
Training loss: 3.5251476764678955
Validation loss: 2.724840232794233
Epoch: 9| Step: 9
Training loss: 3.0322890281677246
Validation loss: 2.723160071338681
Epoch: 9| Step: 10
Training loss: 3.1157140731811523
Validation loss: 2.7232920403103176
Epoch: 9| Step: 11
Training loss: 3.2855355739593506
Validation loss: 2.7227313038256526
Epoch: 9| Step: 12
Training loss: 3.063349962234497
Validation loss: 2.7193000916954424
Epoch: 9| Step: 13
Training loss: 2.784259796142578
Validation loss: 2.72085539214045
Epoch: 9| Step: 14
Training loss: 3.051241636276245
Validation loss: 2.7188937458202993
Epoch: 9| Step: 15
Training loss: 3.297390937805176
Validation loss: 2.71582686300758
Epoch: 9| Step: 16
Training loss: 2.890395402908325
Validation loss: 2.7139693061224848
Epoch: 9| Step: 17
Training loss: 2.9806292057037354
Validation loss: 2.716131400718963
Epoch: 9| Step: 18
Training loss: 3.804814100265503
Validation loss: 2.7100652765027053
Epoch: 9| Step: 19
Training loss: 3.113994598388672
Validation loss: 2.7117423822553897
Epoch: 39| Step: 0
Training loss: 3.6156530380249023
Validation loss: 2.7122400673173312
Epoch: 9| Step: 1
Training loss: 2.795466423034668
Validation loss: 2.7096585369796204
Epoch: 9| Step: 2
Training loss: 3.839167594909668
Validation loss: 2.7096760238674906
Epoch: 9| Step: 3
Training loss: 3.106943130493164
Validation loss: 2.7099182537133744
Epoch: 9| Step: 4
Training loss: 3.034435272216797
Validation loss: 2.708100085635837
Epoch: 9| Step: 5
Training loss: 2.1358795166015625
Validation loss: 2.708381136544317
Epoch: 9| Step: 6
Training loss: 2.7401323318481445
Validation loss: 2.7060750868680667
Epoch: 9| Step: 7
Training loss: 4.047882080078125
Validation loss: 2.7035093264614076
Epoch: 9| Step: 8
Training loss: 2.90621280670166
Validation loss: 2.7062707890709525
Epoch: 9| Step: 9
Training loss: 2.2627475261688232
Validation loss: 2.7036322603980416
Epoch: 9| Step: 10
Training loss: 3.1514556407928467
Validation loss: 2.70262736039196
Epoch: 9| Step: 11
Training loss: 3.250481367111206
Validation loss: 2.703333344390924
Epoch: 9| Step: 12
Training loss: 2.3114571571350098
Validation loss: 2.7046915061182255
Epoch: 9| Step: 13
Training loss: 3.379049301147461
Validation loss: 2.7007293872696034
Epoch: 9| Step: 14
Training loss: 2.555694341659546
Validation loss: 2.700117811024618
Epoch: 9| Step: 15
Training loss: 3.43463397026062
Validation loss: 2.7000298517213452
Epoch: 9| Step: 16
Training loss: 3.3530004024505615
Validation loss: 2.696180407091868
Epoch: 9| Step: 17
Training loss: 4.008753776550293
Validation loss: 2.695790961491976
Epoch: 9| Step: 18
Training loss: 4.395960807800293
Validation loss: 2.696793940427492
Epoch: 9| Step: 19
Training loss: 3.306748867034912
Validation loss: 2.6962199022444033
Epoch: 40| Step: 0
Training loss: 3.3362371921539307
Validation loss: 2.6959822632425983
Epoch: 9| Step: 1
Training loss: 3.401151657104492
Validation loss: 2.692363457714053
Epoch: 9| Step: 2
Training loss: 2.775395393371582
Validation loss: 2.6947820049395665
Epoch: 9| Step: 3
Training loss: 3.0844035148620605
Validation loss: 2.692113336041677
Epoch: 9| Step: 4
Training loss: 3.5206286907196045
Validation loss: 2.6878224980059287
Epoch: 9| Step: 5
Training loss: 2.8382179737091064
Validation loss: 2.689227087034596
Epoch: 9| Step: 6
Training loss: 2.9685988426208496
Validation loss: 2.6879331653924297
Epoch: 9| Step: 7
Training loss: 2.9357447624206543
Validation loss: 2.6863753058069904
Epoch: 9| Step: 8
Training loss: 2.8901584148406982
Validation loss: 2.6860541799943225
Epoch: 9| Step: 9
Training loss: 3.4818482398986816
Validation loss: 2.6864910022817927
Epoch: 9| Step: 10
Training loss: 3.340989589691162
Validation loss: 2.6850322545003547
Epoch: 9| Step: 11
Training loss: 3.584989309310913
Validation loss: 2.6854286279609734
Epoch: 9| Step: 12
Training loss: 3.2210233211517334
Validation loss: 2.683582512594813
Epoch: 9| Step: 13
Training loss: 3.2297165393829346
Validation loss: 2.6838357602949623
Epoch: 9| Step: 14
Training loss: 3.5277485847473145
Validation loss: 2.681023721214679
Epoch: 9| Step: 15
Training loss: 2.108543634414673
Validation loss: 2.681997060775757
Epoch: 9| Step: 16
Training loss: 3.8467307090759277
Validation loss: 2.682587358591368
Epoch: 9| Step: 17
Training loss: 2.923079252243042
Validation loss: 2.677328406478004
Epoch: 9| Step: 18
Training loss: 2.6513967514038086
Validation loss: 2.6771003651104386
Epoch: 9| Step: 19
Training loss: 3.6238417625427246
Validation loss: 2.675923774568297
Epoch: 41| Step: 0
Training loss: 2.917377233505249
Validation loss: 2.677523657572355
Epoch: 9| Step: 1
Training loss: 3.4772286415100098
Validation loss: 2.676177565142405
Epoch: 9| Step: 2
Training loss: 3.597398281097412
Validation loss: 2.675845014105598
Epoch: 9| Step: 3
Training loss: 2.593769073486328
Validation loss: 2.6735766808763683
Epoch: 9| Step: 4
Training loss: 3.1512298583984375
Validation loss: 2.6720401794790365
Epoch: 9| Step: 5
Training loss: 3.367248058319092
Validation loss: 2.67159361118893
Epoch: 9| Step: 6
Training loss: 2.2667384147644043
Validation loss: 2.6720296376043087
Epoch: 9| Step: 7
Training loss: 3.289243221282959
Validation loss: 2.6724012292546333
Epoch: 9| Step: 8
Training loss: 2.9714951515197754
Validation loss: 2.666035262800807
Epoch: 9| Step: 9
Training loss: 2.9329943656921387
Validation loss: 2.6701080636154835
Epoch: 9| Step: 10
Training loss: 3.3196616172790527
Validation loss: 2.668159263597118
Epoch: 9| Step: 11
Training loss: 2.6530299186706543
Validation loss: 2.6700639330225884
Epoch: 9| Step: 12
Training loss: 3.5693767070770264
Validation loss: 2.6681740249661234
Epoch: 9| Step: 13
Training loss: 3.9799160957336426
Validation loss: 2.668405026840649
Epoch: 9| Step: 14
Training loss: 3.0905256271362305
Validation loss: 2.663781332455093
Epoch: 9| Step: 15
Training loss: 3.6256251335144043
Validation loss: 2.6651516235132013
Epoch: 9| Step: 16
Training loss: 2.511847496032715
Validation loss: 2.663572349136682
Epoch: 9| Step: 17
Training loss: 2.778554916381836
Validation loss: 2.6623305571165017
Epoch: 9| Step: 18
Training loss: 3.0385899543762207
Validation loss: 2.6589536392431463
Epoch: 9| Step: 19
Training loss: 3.933389186859131
Validation loss: 2.6621549335315073
Epoch: 42| Step: 0
Training loss: 3.2379214763641357
Validation loss: 2.660040065538969
Epoch: 9| Step: 1
Training loss: 3.6897706985473633
Validation loss: 2.659010928311794
Epoch: 9| Step: 2
Training loss: 2.854362964630127
Validation loss: 2.6599302017431463
Epoch: 9| Step: 3
Training loss: 3.2555742263793945
Validation loss: 2.656712614375053
Epoch: 9| Step: 4
Training loss: 2.8693785667419434
Validation loss: 2.657347094240806
Epoch: 9| Step: 5
Training loss: 4.153164863586426
Validation loss: 2.654593136670778
Epoch: 9| Step: 6
Training loss: 4.0657267570495605
Validation loss: 2.653262822748088
Epoch: 9| Step: 7
Training loss: 3.3628687858581543
Validation loss: 2.6563455938435285
Epoch: 9| Step: 8
Training loss: 3.189535617828369
Validation loss: 2.653167688589302
Epoch: 9| Step: 9
Training loss: 2.1832330226898193
Validation loss: 2.652343770582899
Epoch: 9| Step: 10
Training loss: 2.895171642303467
Validation loss: 2.65138992988806
Epoch: 9| Step: 11
Training loss: 3.3802452087402344
Validation loss: 2.6525089243333118
Epoch: 9| Step: 12
Training loss: 4.1131720542907715
Validation loss: 2.650362378401722
Epoch: 9| Step: 13
Training loss: 3.338554859161377
Validation loss: 2.651372991877494
Epoch: 9| Step: 14
Training loss: 3.1413350105285645
Validation loss: 2.64602847751096
Epoch: 9| Step: 15
Training loss: 2.2840094566345215
Validation loss: 2.64890187421291
Epoch: 9| Step: 16
Training loss: 2.784625291824341
Validation loss: 2.644595552691453
Epoch: 9| Step: 17
Training loss: 3.5473217964172363
Validation loss: 2.6441658898223217
Epoch: 9| Step: 18
Training loss: 2.427243709564209
Validation loss: 2.64433309500166
Epoch: 9| Step: 19
Training loss: 2.0111374855041504
Validation loss: 2.6429238885426694
Epoch: 43| Step: 0
Training loss: 2.9663162231445312
Validation loss: 2.643050814704072
Epoch: 9| Step: 1
Training loss: 3.385206699371338
Validation loss: 2.641654060898925
Epoch: 9| Step: 2
Training loss: 3.5289688110351562
Validation loss: 2.6414249972473804
Epoch: 9| Step: 3
Training loss: 3.2815165519714355
Validation loss: 2.638970659791137
Epoch: 9| Step: 4
Training loss: 2.4962422847747803
Validation loss: 2.640026970732984
Epoch: 9| Step: 5
Training loss: 3.2091100215911865
Validation loss: 2.639816645238039
Epoch: 9| Step: 6
Training loss: 2.4154577255249023
Validation loss: 2.635884533683173
Epoch: 9| Step: 7
Training loss: 3.240755558013916
Validation loss: 2.637040834632709
Epoch: 9| Step: 8
Training loss: 2.726391077041626
Validation loss: 2.635787152557922
Epoch: 9| Step: 9
Training loss: 3.3849754333496094
Validation loss: 2.63808400510884
Epoch: 9| Step: 10
Training loss: 3.253693103790283
Validation loss: 2.632536862393935
Epoch: 9| Step: 11
Training loss: 3.212169647216797
Validation loss: 2.6326648760184965
Epoch: 9| Step: 12
Training loss: 3.5029234886169434
Validation loss: 2.6319613199439837
Epoch: 9| Step: 13
Training loss: 2.676989793777466
Validation loss: 2.630732447123356
Epoch: 9| Step: 14
Training loss: 3.484144687652588
Validation loss: 2.634758553058981
Epoch: 9| Step: 15
Training loss: 3.5897281169891357
Validation loss: 2.631199214098265
Epoch: 9| Step: 16
Training loss: 3.280296802520752
Validation loss: 2.6311537173154544
Epoch: 9| Step: 17
Training loss: 2.8092713356018066
Validation loss: 2.6326087310159805
Epoch: 9| Step: 18
Training loss: 3.117011308670044
Validation loss: 2.6268541315476672
Epoch: 9| Step: 19
Training loss: 2.956279754638672
Validation loss: 2.6301340542251257
Epoch: 44| Step: 0
Training loss: 2.347046375274658
Validation loss: 2.6290120804052557
Epoch: 9| Step: 1
Training loss: 2.8904619216918945
Validation loss: 2.626935814782012
Epoch: 9| Step: 2
Training loss: 3.344308853149414
Validation loss: 2.628427169305815
Epoch: 9| Step: 3
Training loss: 2.8475286960601807
Validation loss: 2.6231681374337175
Epoch: 9| Step: 4
Training loss: 3.941406726837158
Validation loss: 2.625777301170843
Epoch: 9| Step: 5
Training loss: 3.268906593322754
Validation loss: 2.624768763137378
Epoch: 9| Step: 6
Training loss: 2.979611396789551
Validation loss: 2.6235897866942044
Epoch: 9| Step: 7
Training loss: 3.706974506378174
Validation loss: 2.624157329257444
Epoch: 9| Step: 8
Training loss: 2.4925036430358887
Validation loss: 2.623818274024579
Epoch: 9| Step: 9
Training loss: 3.1551403999328613
Validation loss: 2.6217168904036927
Epoch: 9| Step: 10
Training loss: 2.4883878231048584
Validation loss: 2.621370768375534
Epoch: 9| Step: 11
Training loss: 3.544952392578125
Validation loss: 2.6200823037744425
Epoch: 9| Step: 12
Training loss: 3.6818323135375977
Validation loss: 2.619862712544503
Epoch: 9| Step: 13
Training loss: 2.446514129638672
Validation loss: 2.6193287767094673
Epoch: 9| Step: 14
Training loss: 3.4730167388916016
Validation loss: 2.617657374992645
Epoch: 9| Step: 15
Training loss: 3.42661190032959
Validation loss: 2.6177906029515987
Epoch: 9| Step: 16
Training loss: 2.8550264835357666
Validation loss: 2.6157880326826795
Epoch: 9| Step: 17
Training loss: 3.479362964630127
Validation loss: 2.6145190489377907
Epoch: 9| Step: 18
Training loss: 3.3548636436462402
Validation loss: 2.61446742531207
Epoch: 9| Step: 19
Training loss: 2.5637876987457275
Validation loss: 2.6152603969299535
Epoch: 45| Step: 0
Training loss: 3.15913462638855
Validation loss: 2.6159549822910226
Epoch: 9| Step: 1
Training loss: 3.064293146133423
Validation loss: 2.6129462513134634
Epoch: 9| Step: 2
Training loss: 2.849571704864502
Validation loss: 2.6117713519995163
Epoch: 9| Step: 3
Training loss: 3.077205181121826
Validation loss: 2.611962687197349
Epoch: 9| Step: 4
Training loss: 3.101522922515869
Validation loss: 2.613337779216629
Epoch: 9| Step: 5
Training loss: 3.0320403575897217
Validation loss: 2.611494158669341
Epoch: 9| Step: 6
Training loss: 3.5314178466796875
Validation loss: 2.6093816397001417
Epoch: 9| Step: 7
Training loss: 3.6989645957946777
Validation loss: 2.608703540383483
Epoch: 9| Step: 8
Training loss: 3.812566041946411
Validation loss: 2.608936467616678
Epoch: 9| Step: 9
Training loss: 3.4409360885620117
Validation loss: 2.6071911038254663
Epoch: 9| Step: 10
Training loss: 3.0774683952331543
Validation loss: 2.606557346934037
Epoch: 9| Step: 11
Training loss: 3.1317458152770996
Validation loss: 2.60855697213317
Epoch: 9| Step: 12
Training loss: 2.743957996368408
Validation loss: 2.606285777880991
Epoch: 9| Step: 13
Training loss: 2.9506149291992188
Validation loss: 2.606007166046033
Epoch: 9| Step: 14
Training loss: 2.4892330169677734
Validation loss: 2.604513698344608
Epoch: 9| Step: 15
Training loss: 3.4251644611358643
Validation loss: 2.605915054142904
Epoch: 9| Step: 16
Training loss: 3.101670265197754
Validation loss: 2.604216091924434
Epoch: 9| Step: 17
Training loss: 2.8652291297912598
Validation loss: 2.601308534471251
Epoch: 9| Step: 18
Training loss: 2.5458121299743652
Validation loss: 2.6039197959488245
Epoch: 9| Step: 19
Training loss: 2.940732002258301
Validation loss: 2.6020403834555648
Epoch: 46| Step: 0
Training loss: 2.866302251815796
Validation loss: 2.6043161436808195
Epoch: 9| Step: 1
Training loss: 3.380485773086548
Validation loss: 2.601655754254019
Epoch: 9| Step: 2
Training loss: 4.151945114135742
Validation loss: 2.598379486756359
Epoch: 9| Step: 3
Training loss: 3.3140084743499756
Validation loss: 2.5971520513081723
Epoch: 9| Step: 4
Training loss: 3.1065144538879395
Validation loss: 2.5990146184139116
Epoch: 9| Step: 5
Training loss: 2.462212085723877
Validation loss: 2.5975465928907875
Epoch: 9| Step: 6
Training loss: 2.2802746295928955
Validation loss: 2.5978722057754187
Epoch: 9| Step: 7
Training loss: 3.034099817276001
Validation loss: 2.5969937911136545
Epoch: 9| Step: 8
Training loss: 2.9673571586608887
Validation loss: 2.5975384111884687
Epoch: 9| Step: 9
Training loss: 3.406733512878418
Validation loss: 2.596891691358827
Epoch: 9| Step: 10
Training loss: 2.756354570388794
Validation loss: 2.595073355187615
Epoch: 9| Step: 11
Training loss: 3.657569408416748
Validation loss: 2.5952982936831686
Epoch: 9| Step: 12
Training loss: 2.4001898765563965
Validation loss: 2.5938790925115134
Epoch: 9| Step: 13
Training loss: 2.939436435699463
Validation loss: 2.5942328199208213
Epoch: 9| Step: 14
Training loss: 2.930391788482666
Validation loss: 2.592138058847661
Epoch: 9| Step: 15
Training loss: 3.294283866882324
Validation loss: 2.5926945655465983
Epoch: 9| Step: 16
Training loss: 3.7962021827697754
Validation loss: 2.592638003740379
Epoch: 9| Step: 17
Training loss: 2.491969108581543
Validation loss: 2.5918821019234417
Epoch: 9| Step: 18
Training loss: 3.4208247661590576
Validation loss: 2.591552931627781
Epoch: 9| Step: 19
Training loss: 3.1941428184509277
Validation loss: 2.589097148222889
Epoch: 47| Step: 0
Training loss: 2.4753339290618896
Validation loss: 2.5892603311607307
Epoch: 9| Step: 1
Training loss: 3.7445600032806396
Validation loss: 2.5898669040460383
Epoch: 9| Step: 2
Training loss: 2.526217460632324
Validation loss: 2.5855082076230493
Epoch: 9| Step: 3
Training loss: 3.2303762435913086
Validation loss: 2.5885397658931266
Epoch: 9| Step: 4
Training loss: 3.352889060974121
Validation loss: 2.5869641544149933
Epoch: 9| Step: 5
Training loss: 3.792771339416504
Validation loss: 2.588164806365967
Epoch: 9| Step: 6
Training loss: 3.432454824447632
Validation loss: 2.5844988805784594
Epoch: 9| Step: 7
Training loss: 2.5162577629089355
Validation loss: 2.5845485694116825
Epoch: 9| Step: 8
Training loss: 3.664206027984619
Validation loss: 2.5847611718898196
Epoch: 9| Step: 9
Training loss: 2.8838348388671875
Validation loss: 2.582447243251389
Epoch: 9| Step: 10
Training loss: 2.618612766265869
Validation loss: 2.5837988904911837
Epoch: 9| Step: 11
Training loss: 3.337002992630005
Validation loss: 2.582280114400301
Epoch: 9| Step: 12
Training loss: 1.9880937337875366
Validation loss: 2.5799844659489692
Epoch: 9| Step: 13
Training loss: 2.6138038635253906
Validation loss: 2.581386090182572
Epoch: 9| Step: 14
Training loss: 2.711664915084839
Validation loss: 2.5790868543034833
Epoch: 9| Step: 15
Training loss: 3.160616636276245
Validation loss: 2.5788920611786326
Epoch: 9| Step: 16
Training loss: 4.24404239654541
Validation loss: 2.5774255073327814
Epoch: 9| Step: 17
Training loss: 3.3529610633850098
Validation loss: 2.5805257395874683
Epoch: 9| Step: 18
Training loss: 3.2073004245758057
Validation loss: 2.58203763755963
Epoch: 9| Step: 19
Training loss: 2.775773525238037
Validation loss: 2.5807117198011
Epoch: 48| Step: 0
Training loss: 2.9962551593780518
Validation loss: 2.580209809241535
Epoch: 9| Step: 1
Training loss: 3.4715442657470703
Validation loss: 2.5763044717500536
Epoch: 9| Step: 2
Training loss: 3.3151774406433105
Validation loss: 2.576632998830123
Epoch: 9| Step: 3
Training loss: 3.295506238937378
Validation loss: 2.574995488571606
Epoch: 9| Step: 4
Training loss: 2.927607536315918
Validation loss: 2.574898632310277
Epoch: 9| Step: 5
Training loss: 3.324014186859131
Validation loss: 2.575995561887892
Epoch: 9| Step: 6
Training loss: 2.5363519191741943
Validation loss: 2.5742424649300335
Epoch: 9| Step: 7
Training loss: 3.5616674423217773
Validation loss: 2.5724649172035052
Epoch: 9| Step: 8
Training loss: 3.3141379356384277
Validation loss: 2.5708402112233553
Epoch: 9| Step: 9
Training loss: 3.359893321990967
Validation loss: 2.5697033876995388
Epoch: 9| Step: 10
Training loss: 2.5154154300689697
Validation loss: 2.5716049345277194
Epoch: 9| Step: 11
Training loss: 3.556771755218506
Validation loss: 2.5716500951231813
Epoch: 9| Step: 12
Training loss: 3.166602611541748
Validation loss: 2.5717981530608034
Epoch: 9| Step: 13
Training loss: 2.0595932006835938
Validation loss: 2.5713804042596613
Epoch: 9| Step: 14
Training loss: 3.2339119911193848
Validation loss: 2.5677431881856574
Epoch: 9| Step: 15
Training loss: 3.1237194538116455
Validation loss: 2.5702074568906275
Epoch: 9| Step: 16
Training loss: 2.7421164512634277
Validation loss: 2.5677431401588935
Epoch: 9| Step: 17
Training loss: 2.572763442993164
Validation loss: 2.568786543907879
Epoch: 9| Step: 18
Training loss: 3.71941876411438
Validation loss: 2.569240074363544
Epoch: 9| Step: 19
Training loss: 2.661912441253662
Validation loss: 2.5664400934315412
Epoch: 49| Step: 0
Training loss: 3.453986167907715
Validation loss: 2.565264813333964
Epoch: 9| Step: 1
Training loss: 3.3707821369171143
Validation loss: 2.565408945083618
Epoch: 9| Step: 2
Training loss: 3.1173057556152344
Validation loss: 2.5664465204417275
Epoch: 9| Step: 3
Training loss: 2.5264389514923096
Validation loss: 2.566546577343838
Epoch: 9| Step: 4
Training loss: 2.6243181228637695
Validation loss: 2.563191840974547
Epoch: 9| Step: 5
Training loss: 3.5187411308288574
Validation loss: 2.5646423984774582
Epoch: 9| Step: 6
Training loss: 3.4509527683258057
Validation loss: 2.5640848231830184
Epoch: 9| Step: 7
Training loss: 2.8664298057556152
Validation loss: 2.564919102963784
Epoch: 9| Step: 8
Training loss: 3.4699923992156982
Validation loss: 2.563109299261793
Epoch: 9| Step: 9
Training loss: 3.8283586502075195
Validation loss: 2.5613064817387423
Epoch: 9| Step: 10
Training loss: 3.267437696456909
Validation loss: 2.560433722228455
Epoch: 9| Step: 11
Training loss: 3.192312717437744
Validation loss: 2.5608315450682055
Epoch: 9| Step: 12
Training loss: 2.6205575466156006
Validation loss: 2.55865497040234
Epoch: 9| Step: 13
Training loss: 2.5044782161712646
Validation loss: 2.558206619976236
Epoch: 9| Step: 14
Training loss: 3.327944755554199
Validation loss: 2.559223365440643
Epoch: 9| Step: 15
Training loss: 2.280449628829956
Validation loss: 2.5592860506592894
Epoch: 9| Step: 16
Training loss: 2.749216079711914
Validation loss: 2.5580746724451187
Epoch: 9| Step: 17
Training loss: 2.5730996131896973
Validation loss: 2.5582631543385896
Epoch: 9| Step: 18
Training loss: 3.264803409576416
Validation loss: 2.559081144470105
Epoch: 9| Step: 19
Training loss: 3.278379440307617
Validation loss: 2.5562048472946497
Epoch: 50| Step: 0
Training loss: 3.695103406906128
Validation loss: 2.556210675685526
Epoch: 9| Step: 1
Training loss: 2.927537202835083
Validation loss: 2.5565894559132967
Epoch: 9| Step: 2
Training loss: 3.356285572052002
Validation loss: 2.5557372724409584
Epoch: 9| Step: 3
Training loss: 2.984832525253296
Validation loss: 2.552513594250027
Epoch: 9| Step: 4
Training loss: 2.960402488708496
Validation loss: 2.553155971087998
Epoch: 9| Step: 5
Training loss: 3.0954701900482178
Validation loss: 2.553357427926372
Epoch: 9| Step: 6
Training loss: 2.875248670578003
Validation loss: 2.5549825129749104
Epoch: 9| Step: 7
Training loss: 3.3929598331451416
Validation loss: 2.5521424845825855
Epoch: 9| Step: 8
Training loss: 3.0808706283569336
Validation loss: 2.5519231943775424
Epoch: 9| Step: 9
Training loss: 3.155195951461792
Validation loss: 2.5483366654073594
Epoch: 9| Step: 10
Training loss: 3.7388949394226074
Validation loss: 2.5515638358301396
Epoch: 9| Step: 11
Training loss: 3.1232779026031494
Validation loss: 2.5507404889991814
Epoch: 9| Step: 12
Training loss: 3.4637815952301025
Validation loss: 2.5500340839084106
Epoch: 9| Step: 13
Training loss: 1.990829348564148
Validation loss: 2.5486021487832926
Epoch: 9| Step: 14
Training loss: 3.7145047187805176
Validation loss: 2.5496039356259135
Epoch: 9| Step: 15
Training loss: 2.428119421005249
Validation loss: 2.548088363606295
Epoch: 9| Step: 16
Training loss: 2.5465831756591797
Validation loss: 2.5479651029161414
Epoch: 9| Step: 17
Training loss: 3.144418954849243
Validation loss: 2.5472338062396154
Epoch: 9| Step: 18
Training loss: 2.546358346939087
Validation loss: 2.5485024452209473
Epoch: 9| Step: 19
Training loss: 2.8710837364196777
Validation loss: 2.5446880035263173
Epoch: 51| Step: 0
Training loss: 3.488132953643799
Validation loss: 2.546220384913383
Epoch: 9| Step: 1
Training loss: 3.1317808628082275
Validation loss: 2.546608583532649
Epoch: 9| Step: 2
Training loss: 2.874499797821045
Validation loss: 2.5444953801820605
Epoch: 9| Step: 3
Training loss: 3.3974666595458984
Validation loss: 2.544005809070395
Epoch: 9| Step: 4
Training loss: 3.7640347480773926
Validation loss: 2.543812196031749
Epoch: 9| Step: 5
Training loss: 3.5951781272888184
Validation loss: 2.5430538791546717
Epoch: 9| Step: 6
Training loss: 2.837339401245117
Validation loss: 2.5448754434105303
Epoch: 9| Step: 7
Training loss: 2.555832862854004
Validation loss: 2.541892984788195
Epoch: 9| Step: 8
Training loss: 2.28900146484375
Validation loss: 2.543810244086835
Epoch: 9| Step: 9
Training loss: 3.098036527633667
Validation loss: 2.5399584864540925
Epoch: 9| Step: 10
Training loss: 3.1020209789276123
Validation loss: 2.5398921331913353
Epoch: 9| Step: 11
Training loss: 3.2117161750793457
Validation loss: 2.536545117124379
Epoch: 9| Step: 12
Training loss: 2.879655361175537
Validation loss: 2.53768402380909
Epoch: 9| Step: 13
Training loss: 3.1659016609191895
Validation loss: 2.5391038681963365
Epoch: 9| Step: 14
Training loss: 2.55621337890625
Validation loss: 2.5383617689283633
Epoch: 9| Step: 15
Training loss: 2.679108142852783
Validation loss: 2.5382034152531796
Epoch: 9| Step: 16
Training loss: 3.5201756954193115
Validation loss: 2.5359285135063336
Epoch: 9| Step: 17
Training loss: 2.9602973461151123
Validation loss: 2.5363360137390574
Epoch: 9| Step: 18
Training loss: 3.0221121311187744
Validation loss: 2.5351162831560314
Epoch: 9| Step: 19
Training loss: 2.8116750717163086
Validation loss: 2.5357219735495478
Epoch: 52| Step: 0
Training loss: 3.0903782844543457
Validation loss: 2.5368763028288916
Epoch: 9| Step: 1
Training loss: 2.679042100906372
Validation loss: 2.5358080692428477
Epoch: 9| Step: 2
Training loss: 2.843606472015381
Validation loss: 2.5331780327309805
Epoch: 9| Step: 3
Training loss: 3.3897900581359863
Validation loss: 2.536813322588694
Epoch: 9| Step: 4
Training loss: 2.9860074520111084
Validation loss: 2.534603990239205
Epoch: 9| Step: 5
Training loss: 3.1686205863952637
Validation loss: 2.533596781517962
Epoch: 9| Step: 6
Training loss: 2.7355523109436035
Validation loss: 2.529400912977809
Epoch: 9| Step: 7
Training loss: 3.18277645111084
Validation loss: 2.530955060780477
Epoch: 9| Step: 8
Training loss: 2.882948160171509
Validation loss: 2.531850291670655
Epoch: 9| Step: 9
Training loss: 3.3269577026367188
Validation loss: 2.5313140900014974
Epoch: 9| Step: 10
Training loss: 3.353592872619629
Validation loss: 2.5291355016420214
Epoch: 9| Step: 11
Training loss: 2.866816997528076
Validation loss: 2.5294990899751513
Epoch: 9| Step: 12
Training loss: 3.151250123977661
Validation loss: 2.5282392690507627
Epoch: 9| Step: 13
Training loss: 3.37139630317688
Validation loss: 2.5277929426097185
Epoch: 9| Step: 14
Training loss: 2.289273738861084
Validation loss: 2.5271412485795057
Epoch: 9| Step: 15
Training loss: 3.181588649749756
Validation loss: 2.526292046197027
Epoch: 9| Step: 16
Training loss: 2.9742746353149414
Validation loss: 2.5261173299748263
Epoch: 9| Step: 17
Training loss: 3.412790060043335
Validation loss: 2.528438598989583
Epoch: 9| Step: 18
Training loss: 2.9505434036254883
Validation loss: 2.5305086125572807
Epoch: 9| Step: 19
Training loss: 2.9510231018066406
Validation loss: 2.526528749534552
Epoch: 53| Step: 0
Training loss: 3.2532448768615723
Validation loss: 2.527236329565803
Epoch: 9| Step: 1
Training loss: 3.1717066764831543
Validation loss: 2.5276275127054117
Epoch: 9| Step: 2
Training loss: 3.3200013637542725
Validation loss: 2.525613843108253
Epoch: 9| Step: 3
Training loss: 3.312166213989258
Validation loss: 2.5251590793938945
Epoch: 9| Step: 4
Training loss: 2.153506278991699
Validation loss: 2.5232264343783153
Epoch: 9| Step: 5
Training loss: 2.228755474090576
Validation loss: 2.5240754275013217
Epoch: 9| Step: 6
Training loss: 3.67991042137146
Validation loss: 2.522888236766239
Epoch: 9| Step: 7
Training loss: 3.6648638248443604
Validation loss: 2.525042707113911
Epoch: 9| Step: 8
Training loss: 2.3674516677856445
Validation loss: 2.523300884438933
Epoch: 9| Step: 9
Training loss: 3.067796468734741
Validation loss: 2.521463520235295
Epoch: 9| Step: 10
Training loss: 2.9150025844573975
Validation loss: 2.521576004920246
Epoch: 9| Step: 11
Training loss: 2.4377870559692383
Validation loss: 2.518900116570562
Epoch: 9| Step: 12
Training loss: 3.6048474311828613
Validation loss: 2.5225636598875196
Epoch: 9| Step: 13
Training loss: 3.832961320877075
Validation loss: 2.518862247467041
Epoch: 9| Step: 14
Training loss: 2.725088596343994
Validation loss: 2.5212787123892806
Epoch: 9| Step: 15
Training loss: 3.4396588802337646
Validation loss: 2.517956685676849
Epoch: 9| Step: 16
Training loss: 3.384908676147461
Validation loss: 2.519114880253085
Epoch: 9| Step: 17
Training loss: 2.8581838607788086
Validation loss: 2.51958633326798
Epoch: 9| Step: 18
Training loss: 2.114117383956909
Validation loss: 2.5208921466799947
Epoch: 9| Step: 19
Training loss: 3.1300835609436035
Validation loss: 2.5191558162085443
Epoch: 54| Step: 0
Training loss: 3.786134719848633
Validation loss: 2.5202494096412935
Epoch: 9| Step: 1
Training loss: 2.213914632797241
Validation loss: 2.518713724698952
Epoch: 9| Step: 2
Training loss: 3.548753261566162
Validation loss: 2.5180076060535237
Epoch: 9| Step: 3
Training loss: 4.261420726776123
Validation loss: 2.5205130079667346
Epoch: 9| Step: 4
Training loss: 3.128276824951172
Validation loss: 2.5173773371058403
Epoch: 9| Step: 5
Training loss: 2.5922794342041016
Validation loss: 2.517600004621547
Epoch: 9| Step: 6
Training loss: 3.246115207672119
Validation loss: 2.517468392420158
Epoch: 9| Step: 7
Training loss: 3.915705919265747
Validation loss: 2.517154966326926
Epoch: 9| Step: 8
Training loss: 3.1215851306915283
Validation loss: 2.515457511805802
Epoch: 9| Step: 9
Training loss: 2.671018600463867
Validation loss: 2.516150003714527
Epoch: 9| Step: 10
Training loss: 2.2571346759796143
Validation loss: 2.5126280021324434
Epoch: 9| Step: 11
Training loss: 3.15594744682312
Validation loss: 2.51159044478437
Epoch: 9| Step: 12
Training loss: 2.436553955078125
Validation loss: 2.515383360197218
Epoch: 9| Step: 13
Training loss: 2.838894844055176
Validation loss: 2.513506264995328
Epoch: 9| Step: 14
Training loss: 2.5542685985565186
Validation loss: 2.515652328944035
Epoch: 9| Step: 15
Training loss: 3.4818806648254395
Validation loss: 2.5133349723953136
Epoch: 9| Step: 16
Training loss: 2.6472327709198
Validation loss: 2.5100316907004485
Epoch: 9| Step: 17
Training loss: 2.9938206672668457
Validation loss: 2.512875656429812
Epoch: 9| Step: 18
Training loss: 2.1243770122528076
Validation loss: 2.512155541413122
Epoch: 9| Step: 19
Training loss: 3.5577211380004883
Validation loss: 2.5127366927030277
Epoch: 55| Step: 0
Training loss: 2.8522450923919678
Validation loss: 2.511740661353516
Epoch: 9| Step: 1
Training loss: 3.2276880741119385
Validation loss: 2.5107841766137873
Epoch: 9| Step: 2
Training loss: 3.353447437286377
Validation loss: 2.5116180910480965
Epoch: 9| Step: 3
Training loss: 2.6898844242095947
Validation loss: 2.513012636479714
Epoch: 9| Step: 4
Training loss: 3.1240382194519043
Validation loss: 2.5121316360912735
Epoch: 9| Step: 5
Training loss: 3.2574033737182617
Validation loss: 2.510160972746156
Epoch: 9| Step: 6
Training loss: 3.3757290840148926
Validation loss: 2.51020865989246
Epoch: 9| Step: 7
Training loss: 3.525005340576172
Validation loss: 2.507126463402947
Epoch: 9| Step: 8
Training loss: 2.7926433086395264
Validation loss: 2.5087894381379052
Epoch: 9| Step: 9
Training loss: 3.693020820617676
Validation loss: 2.5096195207225334
Epoch: 9| Step: 10
Training loss: 3.382239818572998
Validation loss: 2.50707749925929
Epoch: 9| Step: 11
Training loss: 2.5652236938476562
Validation loss: 2.5075733764566106
Epoch: 9| Step: 12
Training loss: 3.253518581390381
Validation loss: 2.508700370788574
Epoch: 9| Step: 13
Training loss: 3.187014579772949
Validation loss: 2.508765689760661
Epoch: 9| Step: 14
Training loss: 3.0380373001098633
Validation loss: 2.507729888819962
Epoch: 9| Step: 15
Training loss: 1.9809757471084595
Validation loss: 2.505075742872499
Epoch: 9| Step: 16
Training loss: 3.132521867752075
Validation loss: 2.505034185999589
Epoch: 9| Step: 17
Training loss: 2.527676582336426
Validation loss: 2.5054697733131244
Epoch: 9| Step: 18
Training loss: 2.997603416442871
Validation loss: 2.502767012273665
Epoch: 9| Step: 19
Training loss: 2.452756404876709
Validation loss: 2.504134389136335
Epoch: 56| Step: 0
Training loss: 2.347304105758667
Validation loss: 2.5061569025190615
Epoch: 9| Step: 1
Training loss: 3.515073299407959
Validation loss: 2.5050467570051014
Epoch: 9| Step: 2
Training loss: 3.0532519817352295
Validation loss: 2.5038934560130826
Epoch: 9| Step: 3
Training loss: 2.9244699478149414
Validation loss: 2.5038413229606133
Epoch: 9| Step: 4
Training loss: 2.2348647117614746
Validation loss: 2.501694212714545
Epoch: 9| Step: 5
Training loss: 2.955172538757324
Validation loss: 2.504174573815984
Epoch: 9| Step: 6
Training loss: 3.3973464965820312
Validation loss: 2.5023593199338845
Epoch: 9| Step: 7
Training loss: 2.4959819316864014
Validation loss: 2.5031972394572746
Epoch: 9| Step: 8
Training loss: 2.9462647438049316
Validation loss: 2.5020712468263913
Epoch: 9| Step: 9
Training loss: 3.2521860599517822
Validation loss: 2.502900593572383
Epoch: 9| Step: 10
Training loss: 3.34505033493042
Validation loss: 2.502667348161876
Epoch: 9| Step: 11
Training loss: 3.159294366836548
Validation loss: 2.502393072457622
Epoch: 9| Step: 12
Training loss: 2.5043513774871826
Validation loss: 2.5033567980896656
Epoch: 9| Step: 13
Training loss: 3.7624011039733887
Validation loss: 2.5010944133182225
Epoch: 9| Step: 14
Training loss: 3.3641960620880127
Validation loss: 2.4989161491394043
Epoch: 9| Step: 15
Training loss: 2.5696661472320557
Validation loss: 2.500171241142767
Epoch: 9| Step: 16
Training loss: 3.8256571292877197
Validation loss: 2.501173459368644
Epoch: 9| Step: 17
Training loss: 3.0705454349517822
Validation loss: 2.498540159609678
Epoch: 9| Step: 18
Training loss: 2.6851580142974854
Validation loss: 2.497098307815387
Epoch: 9| Step: 19
Training loss: 2.9040799140930176
Validation loss: 2.499540296389902
Epoch: 57| Step: 0
Training loss: 3.262558937072754
Validation loss: 2.5002259985148476
Epoch: 9| Step: 1
Training loss: 3.756680965423584
Validation loss: 2.4977917379612546
Epoch: 9| Step: 2
Training loss: 2.810710906982422
Validation loss: 2.497476286167721
Epoch: 9| Step: 3
Training loss: 3.412332057952881
Validation loss: 2.495823259833905
Epoch: 9| Step: 4
Training loss: 3.668308734893799
Validation loss: 2.497215044584206
Epoch: 9| Step: 5
Training loss: 2.4795711040496826
Validation loss: 2.497077453050682
Epoch: 9| Step: 6
Training loss: 2.6633808612823486
Validation loss: 2.496302685291647
Epoch: 9| Step: 7
Training loss: 2.9181883335113525
Validation loss: 2.496514438725204
Epoch: 9| Step: 8
Training loss: 2.9086990356445312
Validation loss: 2.4951998535677684
Epoch: 9| Step: 9
Training loss: 3.842228889465332
Validation loss: 2.4948260080900124
Epoch: 9| Step: 10
Training loss: 2.2468574047088623
Validation loss: 2.496601027550457
Epoch: 9| Step: 11
Training loss: 2.5009403228759766
Validation loss: 2.493786671178804
Epoch: 9| Step: 12
Training loss: 2.783437490463257
Validation loss: 2.494619215135094
Epoch: 9| Step: 13
Training loss: 3.371832847595215
Validation loss: 2.4943193120064495
Epoch: 9| Step: 14
Training loss: 2.6055703163146973
Validation loss: 2.493295347090248
Epoch: 9| Step: 15
Training loss: 3.0061964988708496
Validation loss: 2.4923589941408992
Epoch: 9| Step: 16
Training loss: 2.8775582313537598
Validation loss: 2.4923274276925507
Epoch: 9| Step: 17
Training loss: 2.8177618980407715
Validation loss: 2.4933855447837776
Epoch: 9| Step: 18
Training loss: 2.95249605178833
Validation loss: 2.4930614584641493
Epoch: 9| Step: 19
Training loss: 3.302412986755371
Validation loss: 2.4915992390337607
Epoch: 58| Step: 0
Training loss: 2.371002197265625
Validation loss: 2.493606622270543
Epoch: 9| Step: 1
Training loss: 3.222285270690918
Validation loss: 2.4915797650385247
Epoch: 9| Step: 2
Training loss: 3.4080982208251953
Validation loss: 2.492215895824295
Epoch: 9| Step: 3
Training loss: 2.2771859169006348
Validation loss: 2.4920777296848433
Epoch: 9| Step: 4
Training loss: 3.075585126876831
Validation loss: 2.492693252700696
Epoch: 9| Step: 5
Training loss: 3.115692138671875
Validation loss: 2.4922860903705626
Epoch: 9| Step: 6
Training loss: 2.9281840324401855
Validation loss: 2.4896560967397345
Epoch: 9| Step: 7
Training loss: 3.363429546356201
Validation loss: 2.4915062986689507
Epoch: 9| Step: 8
Training loss: 3.5543618202209473
Validation loss: 2.490804027310378
Epoch: 9| Step: 9
Training loss: 3.7188730239868164
Validation loss: 2.489899196213098
Epoch: 9| Step: 10
Training loss: 2.460110664367676
Validation loss: 2.487568610006099
Epoch: 9| Step: 11
Training loss: 3.3365345001220703
Validation loss: 2.487155827686941
Epoch: 9| Step: 12
Training loss: 2.7963740825653076
Validation loss: 2.487024176892617
Epoch: 9| Step: 13
Training loss: 2.683871269226074
Validation loss: 2.4898591538984998
Epoch: 9| Step: 14
Training loss: 2.6086413860321045
Validation loss: 2.488616276130402
Epoch: 9| Step: 15
Training loss: 3.0339009761810303
Validation loss: 2.489486701196904
Epoch: 9| Step: 16
Training loss: 2.5507144927978516
Validation loss: 2.4887297050558406
Epoch: 9| Step: 17
Training loss: 3.2649009227752686
Validation loss: 2.4907142944473155
Epoch: 9| Step: 18
Training loss: 3.2284560203552246
Validation loss: 2.489444206086852
Epoch: 9| Step: 19
Training loss: 3.0866265296936035
Validation loss: 2.4868279789849153
Epoch: 59| Step: 0
Training loss: 2.929241895675659
Validation loss: 2.4872951087334174
Epoch: 9| Step: 1
Training loss: 2.3635354042053223
Validation loss: 2.4875970813010237
Epoch: 9| Step: 2
Training loss: 2.7790095806121826
Validation loss: 2.487509070540504
Epoch: 9| Step: 3
Training loss: 2.8873109817504883
Validation loss: 2.488763694282916
Epoch: 9| Step: 4
Training loss: 2.990004539489746
Validation loss: 2.4875918549599407
Epoch: 9| Step: 5
Training loss: 2.759942054748535
Validation loss: 2.487342774439201
Epoch: 9| Step: 6
Training loss: 2.91784930229187
Validation loss: 2.4861534019168334
Epoch: 9| Step: 7
Training loss: 3.0314128398895264
Validation loss: 2.4866796586153317
Epoch: 9| Step: 8
Training loss: 2.4872426986694336
Validation loss: 2.4879640778191656
Epoch: 9| Step: 9
Training loss: 4.186781883239746
Validation loss: 2.485021116064607
Epoch: 9| Step: 10
Training loss: 2.2359585762023926
Validation loss: 2.4851748951905064
Epoch: 9| Step: 11
Training loss: 3.202974796295166
Validation loss: 2.4856429837590497
Epoch: 9| Step: 12
Training loss: 2.3258416652679443
Validation loss: 2.484906157143682
Epoch: 9| Step: 13
Training loss: 3.1783604621887207
Validation loss: 2.487129330635071
Epoch: 9| Step: 14
Training loss: 3.06554913520813
Validation loss: 2.4846533442572722
Epoch: 9| Step: 15
Training loss: 3.1483144760131836
Validation loss: 2.485102308739861
Epoch: 9| Step: 16
Training loss: 2.504715919494629
Validation loss: 2.482849484724964
Epoch: 9| Step: 17
Training loss: 3.260863780975342
Validation loss: 2.483858144540581
Epoch: 9| Step: 18
Training loss: 4.0918378829956055
Validation loss: 2.4819124619737805
Epoch: 9| Step: 19
Training loss: 3.6545722484588623
Validation loss: 2.4820234604019054
Epoch: 60| Step: 0
Training loss: 2.1413936614990234
Validation loss: 2.4832979963837767
Epoch: 9| Step: 1
Training loss: 3.4444756507873535
Validation loss: 2.4808842312517783
Epoch: 9| Step: 2
Training loss: 3.2393529415130615
Validation loss: 2.4787698581064346
Epoch: 9| Step: 3
Training loss: 2.7836906909942627
Validation loss: 2.4805400165722524
Epoch: 9| Step: 4
Training loss: 2.4794418811798096
Validation loss: 2.4815016135894994
Epoch: 9| Step: 5
Training loss: 3.1821627616882324
Validation loss: 2.481155640787358
Epoch: 9| Step: 6
Training loss: 2.739821195602417
Validation loss: 2.481858289499077
Epoch: 9| Step: 7
Training loss: 2.738563299179077
Validation loss: 2.4807833064374307
Epoch: 9| Step: 8
Training loss: 3.677686929702759
Validation loss: 2.4813078701924933
Epoch: 9| Step: 9
Training loss: 2.8511221408843994
Validation loss: 2.480643598295802
Epoch: 9| Step: 10
Training loss: 2.4330384731292725
Validation loss: 2.4801436688402574
Epoch: 9| Step: 11
Training loss: 2.756223201751709
Validation loss: 2.4799292825108807
Epoch: 9| Step: 12
Training loss: 3.059781551361084
Validation loss: 2.47973901590855
Epoch: 9| Step: 13
Training loss: 3.0637571811676025
Validation loss: 2.478592450670201
Epoch: 9| Step: 14
Training loss: 3.8222272396087646
Validation loss: 2.4797532266850095
Epoch: 9| Step: 15
Training loss: 3.330165147781372
Validation loss: 2.4796756102884414
Epoch: 9| Step: 16
Training loss: 2.8006534576416016
Validation loss: 2.479285202438025
Epoch: 9| Step: 17
Training loss: 2.660426616668701
Validation loss: 2.4788891771714465
Epoch: 9| Step: 18
Training loss: 3.288409471511841
Validation loss: 2.4773731832024004
Epoch: 9| Step: 19
Training loss: 3.4634766578674316
Validation loss: 2.4778502845078063
Epoch: 61| Step: 0
Training loss: 3.4190351963043213
Validation loss: 2.4776047562523713
Epoch: 9| Step: 1
Training loss: 2.8069748878479004
Validation loss: 2.478563217808017
Epoch: 9| Step: 2
Training loss: 2.569136381149292
Validation loss: 2.47646270467223
Epoch: 9| Step: 3
Training loss: 2.109278440475464
Validation loss: 2.475747600733805
Epoch: 9| Step: 4
Training loss: 3.102970600128174
Validation loss: 2.4790808674242855
Epoch: 9| Step: 5
Training loss: 2.668153762817383
Validation loss: 2.476519307644247
Epoch: 9| Step: 6
Training loss: 2.8092260360717773
Validation loss: 2.479658517906134
Epoch: 9| Step: 7
Training loss: 3.009660243988037
Validation loss: 2.4784816512100987
Epoch: 9| Step: 8
Training loss: 2.9260425567626953
Validation loss: 2.476441414236165
Epoch: 9| Step: 9
Training loss: 1.8678131103515625
Validation loss: 2.47550738286629
Epoch: 9| Step: 10
Training loss: 3.2298378944396973
Validation loss: 2.4761657457557513
Epoch: 9| Step: 11
Training loss: 2.9975228309631348
Validation loss: 2.4768827416056354
Epoch: 9| Step: 12
Training loss: 3.6869232654571533
Validation loss: 2.4761069901555564
Epoch: 9| Step: 13
Training loss: 2.6148252487182617
Validation loss: 2.4739746052584204
Epoch: 9| Step: 14
Training loss: 3.3841025829315186
Validation loss: 2.4764995523493925
Epoch: 9| Step: 15
Training loss: 3.292832136154175
Validation loss: 2.47428434015178
Epoch: 9| Step: 16
Training loss: 3.0741095542907715
Validation loss: 2.472903783372838
Epoch: 9| Step: 17
Training loss: 3.2894275188446045
Validation loss: 2.474860060986855
Epoch: 9| Step: 18
Training loss: 3.211886405944824
Validation loss: 2.4732978378268453
Epoch: 9| Step: 19
Training loss: 3.7619762420654297
Validation loss: 2.4775053820164086
Epoch: 62| Step: 0
Training loss: 2.784924030303955
Validation loss: 2.4754320151514286
Epoch: 9| Step: 1
Training loss: 3.482250690460205
Validation loss: 2.4747996793376457
Epoch: 9| Step: 2
Training loss: 2.7594337463378906
Validation loss: 2.4745963614621607
Epoch: 9| Step: 3
Training loss: 2.6476805210113525
Validation loss: 2.473950905765561
Epoch: 9| Step: 4
Training loss: 3.2593932151794434
Validation loss: 2.472574549613239
Epoch: 9| Step: 5
Training loss: 2.824449062347412
Validation loss: 2.473600893569507
Epoch: 9| Step: 6
Training loss: 3.1101481914520264
Validation loss: 2.4720517697094158
Epoch: 9| Step: 7
Training loss: 3.112004280090332
Validation loss: 2.472837268019752
Epoch: 9| Step: 8
Training loss: 2.2933735847473145
Validation loss: 2.473864695151075
Epoch: 9| Step: 9
Training loss: 2.954127788543701
Validation loss: 2.4728470397510116
Epoch: 9| Step: 10
Training loss: 3.1680219173431396
Validation loss: 2.4711859432055796
Epoch: 9| Step: 11
Training loss: 3.1331663131713867
Validation loss: 2.4713817157333704
Epoch: 9| Step: 12
Training loss: 3.330416202545166
Validation loss: 2.4732692361735613
Epoch: 9| Step: 13
Training loss: 3.308302164077759
Validation loss: 2.4731903710811256
Epoch: 9| Step: 14
Training loss: 3.355128288269043
Validation loss: 2.4707821444641773
Epoch: 9| Step: 15
Training loss: 2.889939069747925
Validation loss: 2.471032511416099
Epoch: 9| Step: 16
Training loss: 2.618612051010132
Validation loss: 2.472046481619636
Epoch: 9| Step: 17
Training loss: 2.148632526397705
Validation loss: 2.4722380706732223
Epoch: 9| Step: 18
Training loss: 3.6569619178771973
Validation loss: 2.470293689974778
Epoch: 9| Step: 19
Training loss: 2.965913772583008
Validation loss: 2.4723825694845734
Epoch: 63| Step: 0
Training loss: 3.229701042175293
Validation loss: 2.4692755826085593
Epoch: 9| Step: 1
Training loss: 3.216878890991211
Validation loss: 2.4701176221422156
Epoch: 9| Step: 2
Training loss: 2.9418177604675293
Validation loss: 2.470788128084416
Epoch: 9| Step: 3
Training loss: 3.1093945503234863
Validation loss: 2.470480623862726
Epoch: 9| Step: 4
Training loss: 2.4948792457580566
Validation loss: 2.4701604611582035
Epoch: 9| Step: 5
Training loss: 3.416536569595337
Validation loss: 2.4686635209502077
Epoch: 9| Step: 6
Training loss: 2.250743865966797
Validation loss: 2.4689275292183854
Epoch: 9| Step: 7
Training loss: 3.430056095123291
Validation loss: 2.46987595661081
Epoch: 9| Step: 8
Training loss: 2.091460943222046
Validation loss: 2.471019614514687
Epoch: 9| Step: 9
Training loss: 3.6306710243225098
Validation loss: 2.4691379945055187
Epoch: 9| Step: 10
Training loss: 1.7796144485473633
Validation loss: 2.4691206448369747
Epoch: 9| Step: 11
Training loss: 3.304473400115967
Validation loss: 2.4694917682263493
Epoch: 9| Step: 12
Training loss: 3.3195462226867676
Validation loss: 2.4679426855320554
Epoch: 9| Step: 13
Training loss: 3.3074536323547363
Validation loss: 2.467300089143163
Epoch: 9| Step: 14
Training loss: 3.2934939861297607
Validation loss: 2.469409931477883
Epoch: 9| Step: 15
Training loss: 2.5077810287475586
Validation loss: 2.467359222096505
Epoch: 9| Step: 16
Training loss: 3.8398637771606445
Validation loss: 2.4679487163214375
Epoch: 9| Step: 17
Training loss: 3.1128387451171875
Validation loss: 2.4658612707536
Epoch: 9| Step: 18
Training loss: 2.5397863388061523
Validation loss: 2.466133437568335
Epoch: 9| Step: 19
Training loss: 2.8778603076934814
Validation loss: 2.4643996499425214
Epoch: 64| Step: 0
Training loss: 2.7694671154022217
Validation loss: 2.4671942741750814
Epoch: 9| Step: 1
Training loss: 2.125326633453369
Validation loss: 2.4656172450497853
Epoch: 9| Step: 2
Training loss: 2.531705379486084
Validation loss: 2.465313575250639
Epoch: 9| Step: 3
Training loss: 3.244295597076416
Validation loss: 2.4660497140541353
Epoch: 9| Step: 4
Training loss: 3.0388057231903076
Validation loss: 2.4651173001570665
Epoch: 9| Step: 5
Training loss: 3.464012861251831
Validation loss: 2.465413038679164
Epoch: 9| Step: 6
Training loss: 3.0621285438537598
Validation loss: 2.4645584675905514
Epoch: 9| Step: 7
Training loss: 3.2948923110961914
Validation loss: 2.464774497121358
Epoch: 9| Step: 8
Training loss: 3.349313259124756
Validation loss: 2.465441913055859
Epoch: 9| Step: 9
Training loss: 2.648560047149658
Validation loss: 2.464353889870129
Epoch: 9| Step: 10
Training loss: 3.2047905921936035
Validation loss: 2.4629939888878694
Epoch: 9| Step: 11
Training loss: 2.9264769554138184
Validation loss: 2.4644810501620067
Epoch: 9| Step: 12
Training loss: 2.6149611473083496
Validation loss: 2.464792539747499
Epoch: 9| Step: 13
Training loss: 3.0574045181274414
Validation loss: 2.464627706747261
Epoch: 9| Step: 14
Training loss: 3.5140552520751953
Validation loss: 2.4657127033892294
Epoch: 9| Step: 15
Training loss: 3.104365348815918
Validation loss: 2.463617578684855
Epoch: 9| Step: 16
Training loss: 2.644911766052246
Validation loss: 2.4661860534613083
Epoch: 9| Step: 17
Training loss: 2.144280433654785
Validation loss: 2.463476267649973
Epoch: 9| Step: 18
Training loss: 3.6324610710144043
Validation loss: 2.4656308537764513
Epoch: 9| Step: 19
Training loss: 3.2560195922851562
Validation loss: 2.461829885304403
Epoch: 65| Step: 0
Training loss: 2.7498836517333984
Validation loss: 2.4641948878336297
Epoch: 9| Step: 1
Training loss: 3.25754976272583
Validation loss: 2.4639465414362847
Epoch: 9| Step: 2
Training loss: 3.458434581756592
Validation loss: 2.462576356723154
Epoch: 9| Step: 3
Training loss: 2.4934561252593994
Validation loss: 2.4615279376077996
Epoch: 9| Step: 4
Training loss: 3.666219711303711
Validation loss: 2.4621928715877397
Epoch: 9| Step: 5
Training loss: 2.7376515865325928
Validation loss: 2.463131012676431
Epoch: 9| Step: 6
Training loss: 3.947819471359253
Validation loss: 2.461156377689444
Epoch: 9| Step: 7
Training loss: 3.1905713081359863
Validation loss: 2.4629241974233724
Epoch: 9| Step: 8
Training loss: 2.762241840362549
Validation loss: 2.4604626919725816
Epoch: 9| Step: 9
Training loss: 2.5812125205993652
Validation loss: 2.462509685283085
Epoch: 9| Step: 10
Training loss: 2.6936159133911133
Validation loss: 2.4627520600668817
Epoch: 9| Step: 11
Training loss: 2.678696632385254
Validation loss: 2.462261462383133
Epoch: 9| Step: 12
Training loss: 2.612773895263672
Validation loss: 2.4612665502287503
Epoch: 9| Step: 13
Training loss: 2.507422924041748
Validation loss: 2.458464924380076
Epoch: 9| Step: 14
Training loss: 3.787122964859009
Validation loss: 2.459279366534391
Epoch: 9| Step: 15
Training loss: 2.372558116912842
Validation loss: 2.461797444940471
Epoch: 9| Step: 16
Training loss: 3.293379306793213
Validation loss: 2.462524300856556
Epoch: 9| Step: 17
Training loss: 3.2138190269470215
Validation loss: 2.459754967861038
Epoch: 9| Step: 18
Training loss: 3.038606643676758
Validation loss: 2.4586986895087812
Epoch: 9| Step: 19
Training loss: 2.558022975921631
Validation loss: 2.459093500384324
Epoch: 66| Step: 0
Training loss: 2.762199878692627
Validation loss: 2.4591580329181477
Epoch: 9| Step: 1
Training loss: 2.500514507293701
Validation loss: 2.46030889998237
Epoch: 9| Step: 2
Training loss: 3.224320650100708
Validation loss: 2.4588628141142483
Epoch: 9| Step: 3
Training loss: 2.1562814712524414
Validation loss: 2.4599875391816064
Epoch: 9| Step: 4
Training loss: 2.988776922225952
Validation loss: 2.4580683853986454
Epoch: 9| Step: 5
Training loss: 3.2366812229156494
Validation loss: 2.458177370990781
Epoch: 9| Step: 6
Training loss: 2.8843462467193604
Validation loss: 2.458389851686766
Epoch: 9| Step: 7
Training loss: 3.131659984588623
Validation loss: 2.45879598144147
Epoch: 9| Step: 8
Training loss: 2.395979881286621
Validation loss: 2.4582428503379545
Epoch: 9| Step: 9
Training loss: 3.2274651527404785
Validation loss: 2.45823866686375
Epoch: 9| Step: 10
Training loss: 3.165229320526123
Validation loss: 2.4581852113600258
Epoch: 9| Step: 11
Training loss: 2.8547420501708984
Validation loss: 2.458716370218949
Epoch: 9| Step: 12
Training loss: 3.49680233001709
Validation loss: 2.457197043535521
Epoch: 9| Step: 13
Training loss: 3.3347983360290527
Validation loss: 2.457810983383398
Epoch: 9| Step: 14
Training loss: 3.582430362701416
Validation loss: 2.457495600199528
Epoch: 9| Step: 15
Training loss: 3.1835169792175293
Validation loss: 2.4563406542908375
Epoch: 9| Step: 16
Training loss: 2.3375468254089355
Validation loss: 2.4566214839331537
Epoch: 9| Step: 17
Training loss: 2.6578006744384766
Validation loss: 2.4571679444621792
Epoch: 9| Step: 18
Training loss: 3.5872368812561035
Validation loss: 2.4576830958290925
Epoch: 9| Step: 19
Training loss: 2.8278579711914062
Validation loss: 2.4572379503318733
Epoch: 67| Step: 0
Training loss: 3.5735666751861572
Validation loss: 2.4554241955709113
Epoch: 9| Step: 1
Training loss: 3.191242218017578
Validation loss: 2.458230188424639
Epoch: 9| Step: 2
Training loss: 2.456441640853882
Validation loss: 2.4558261658647935
Epoch: 9| Step: 3
Training loss: 3.1224730014801025
Validation loss: 2.456335882488772
Epoch: 9| Step: 4
Training loss: 3.277306318283081
Validation loss: 2.4573530207435006
Epoch: 9| Step: 5
Training loss: 2.9576780796051025
Validation loss: 2.454401880717106
Epoch: 9| Step: 6
Training loss: 3.830308437347412
Validation loss: 2.4553635343373252
Epoch: 9| Step: 7
Training loss: 2.8765649795532227
Validation loss: 2.45429722525233
Epoch: 9| Step: 8
Training loss: 2.7514514923095703
Validation loss: 2.454471461206889
Epoch: 9| Step: 9
Training loss: 2.604856014251709
Validation loss: 2.454836112989796
Epoch: 9| Step: 10
Training loss: 3.2436931133270264
Validation loss: 2.4550691388493817
Epoch: 9| Step: 11
Training loss: 2.9659318923950195
Validation loss: 2.4542070910227385
Epoch: 9| Step: 12
Training loss: 3.05000638961792
Validation loss: 2.4544741026789163
Epoch: 9| Step: 13
Training loss: 3.408230781555176
Validation loss: 2.455429131178547
Epoch: 9| Step: 14
Training loss: 2.841094493865967
Validation loss: 2.4542848686520142
Epoch: 9| Step: 15
Training loss: 2.8973255157470703
Validation loss: 2.455062960549224
Epoch: 9| Step: 16
Training loss: 3.224864959716797
Validation loss: 2.4541446836732272
Epoch: 9| Step: 17
Training loss: 2.4137136936187744
Validation loss: 2.4558781376845547
Epoch: 9| Step: 18
Training loss: 2.5526208877563477
Validation loss: 2.454264388667594
Epoch: 9| Step: 19
Training loss: 2.192901611328125
Validation loss: 2.452947282105041
Epoch: 68| Step: 0
Training loss: 3.0417144298553467
Validation loss: 2.452742600612503
Epoch: 9| Step: 1
Training loss: 2.922640800476074
Validation loss: 2.4537456756015477
Epoch: 9| Step: 2
Training loss: 2.410181999206543
Validation loss: 2.453928695308219
Epoch: 9| Step: 3
Training loss: 3.022327423095703
Validation loss: 2.4511417407783673
Epoch: 9| Step: 4
Training loss: 2.555799961090088
Validation loss: 2.4528504738704764
Epoch: 9| Step: 5
Training loss: 2.8239731788635254
Validation loss: 2.454015280702989
Epoch: 9| Step: 6
Training loss: 3.3874025344848633
Validation loss: 2.4530480748457872
Epoch: 9| Step: 7
Training loss: 2.882328987121582
Validation loss: 2.451208922502806
Epoch: 9| Step: 8
Training loss: 2.479097366333008
Validation loss: 2.450253259363792
Epoch: 9| Step: 9
Training loss: 4.0317816734313965
Validation loss: 2.452148936635299
Epoch: 9| Step: 10
Training loss: 3.2357468605041504
Validation loss: 2.452309002979196
Epoch: 9| Step: 11
Training loss: 3.2752833366394043
Validation loss: 2.4526226228947263
Epoch: 9| Step: 12
Training loss: 3.325801372528076
Validation loss: 2.453146275856512
Epoch: 9| Step: 13
Training loss: 2.5280425548553467
Validation loss: 2.4530892989618316
Epoch: 9| Step: 14
Training loss: 2.7593767642974854
Validation loss: 2.4508212178731137
Epoch: 9| Step: 15
Training loss: 2.626995086669922
Validation loss: 2.4514017979875744
Epoch: 9| Step: 16
Training loss: 2.8158326148986816
Validation loss: 2.4505490982275213
Epoch: 9| Step: 17
Training loss: 3.383403778076172
Validation loss: 2.451402231943693
Epoch: 9| Step: 18
Training loss: 2.7368083000183105
Validation loss: 2.4488869759676266
Epoch: 9| Step: 19
Training loss: 3.1974501609802246
Validation loss: 2.4507307491714148
Epoch: 69| Step: 0
Training loss: 2.7619380950927734
Validation loss: 2.449886213961265
Epoch: 9| Step: 1
Training loss: 3.1032443046569824
Validation loss: 2.450612045878129
Epoch: 9| Step: 2
Training loss: 1.969963788986206
Validation loss: 2.4493277055754077
Epoch: 9| Step: 3
Training loss: 3.3762760162353516
Validation loss: 2.449620368669359
Epoch: 9| Step: 4
Training loss: 3.057772636413574
Validation loss: 2.4486355798707593
Epoch: 9| Step: 5
Training loss: 3.119337797164917
Validation loss: 2.449769608408427
Epoch: 9| Step: 6
Training loss: 2.6813271045684814
Validation loss: 2.4497417734681273
Epoch: 9| Step: 7
Training loss: 2.538403272628784
Validation loss: 2.448272089306399
Epoch: 9| Step: 8
Training loss: 3.2838056087493896
Validation loss: 2.4492396527914693
Epoch: 9| Step: 9
Training loss: 3.310030698776245
Validation loss: 2.4486755535756943
Epoch: 9| Step: 10
Training loss: 2.6239359378814697
Validation loss: 2.448480923398793
Epoch: 9| Step: 11
Training loss: 2.6768221855163574
Validation loss: 2.447503318031915
Epoch: 9| Step: 12
Training loss: 2.777766227722168
Validation loss: 2.448106836071975
Epoch: 9| Step: 13
Training loss: 3.5112414360046387
Validation loss: 2.4470057676164365
Epoch: 9| Step: 14
Training loss: 3.7043044567108154
Validation loss: 2.448662956841558
Epoch: 9| Step: 15
Training loss: 4.062302589416504
Validation loss: 2.4480864847306725
Epoch: 9| Step: 16
Training loss: 2.5067880153656006
Validation loss: 2.4496970982860318
Epoch: 9| Step: 17
Training loss: 3.0418529510498047
Validation loss: 2.4474472176256796
Epoch: 9| Step: 18
Training loss: 3.1532230377197266
Validation loss: 2.444821822557518
Epoch: 9| Step: 19
Training loss: 2.1058125495910645
Validation loss: 2.4480526069942994
Epoch: 70| Step: 0
Training loss: 2.9426355361938477
Validation loss: 2.4463389468707626
Epoch: 9| Step: 1
Training loss: 2.717773199081421
Validation loss: 2.4460081162212566
Epoch: 9| Step: 2
Training loss: 3.1474533081054688
Validation loss: 2.4481496159121288
Epoch: 9| Step: 3
Training loss: 3.219709873199463
Validation loss: 2.448315021803053
Epoch: 9| Step: 4
Training loss: 2.669522285461426
Validation loss: 2.4480002792619113
Epoch: 9| Step: 5
Training loss: 3.1069822311401367
Validation loss: 2.444332217141021
Epoch: 9| Step: 6
Training loss: 2.9275383949279785
Validation loss: 2.4479330666631247
Epoch: 9| Step: 7
Training loss: 3.0092368125915527
Validation loss: 2.447010206661636
Epoch: 9| Step: 8
Training loss: 2.8036789894104004
Validation loss: 2.44630585299979
Epoch: 9| Step: 9
Training loss: 2.8059093952178955
Validation loss: 2.443953109302109
Epoch: 9| Step: 10
Training loss: 2.8636422157287598
Validation loss: 2.4464909327115945
Epoch: 9| Step: 11
Training loss: 3.1029860973358154
Validation loss: 2.4450139201802314
Epoch: 9| Step: 12
Training loss: 3.474782943725586
Validation loss: 2.4453077556418
Epoch: 9| Step: 13
Training loss: 2.7061471939086914
Validation loss: 2.4455651053421787
Epoch: 9| Step: 14
Training loss: 3.202604293823242
Validation loss: 2.445916916826646
Epoch: 9| Step: 15
Training loss: 3.802872657775879
Validation loss: 2.445200772594205
Epoch: 9| Step: 16
Training loss: 2.162673234939575
Validation loss: 2.444822462342626
Epoch: 9| Step: 17
Training loss: 2.7786507606506348
Validation loss: 2.4454628563613343
Epoch: 9| Step: 18
Training loss: 3.055544376373291
Validation loss: 2.4459097539778236
Epoch: 9| Step: 19
Training loss: 2.831087827682495
Validation loss: 2.4439224442132086
Epoch: 71| Step: 0
Training loss: 3.4300193786621094
Validation loss: 2.4447285923168813
Epoch: 9| Step: 1
Training loss: 3.1097497940063477
Validation loss: 2.4443664533628833
Epoch: 9| Step: 2
Training loss: 2.733588933944702
Validation loss: 2.444016901709193
Epoch: 9| Step: 3
Training loss: 3.0243754386901855
Validation loss: 2.444437371741096
Epoch: 9| Step: 4
Training loss: 3.036686897277832
Validation loss: 2.4436564479800436
Epoch: 9| Step: 5
Training loss: 2.991715908050537
Validation loss: 2.444395730821349
Epoch: 9| Step: 6
Training loss: 3.419604778289795
Validation loss: 2.443003625320874
Epoch: 9| Step: 7
Training loss: 3.2897207736968994
Validation loss: 2.4419635542862705
Epoch: 9| Step: 8
Training loss: 2.7040581703186035
Validation loss: 2.4431972555119357
Epoch: 9| Step: 9
Training loss: 1.8062288761138916
Validation loss: 2.443700618881116
Epoch: 9| Step: 10
Training loss: 3.3139500617980957
Validation loss: 2.444032106468146
Epoch: 9| Step: 11
Training loss: 3.4763240814208984
Validation loss: 2.4447424686212336
Epoch: 9| Step: 12
Training loss: 2.475095748901367
Validation loss: 2.4434532415952614
Epoch: 9| Step: 13
Training loss: 2.678511619567871
Validation loss: 2.44375511896696
Epoch: 9| Step: 14
Training loss: 2.4250566959381104
Validation loss: 2.4425187968521667
Epoch: 9| Step: 15
Training loss: 3.5819156169891357
Validation loss: 2.444149983014992
Epoch: 9| Step: 16
Training loss: 2.5980825424194336
Validation loss: 2.4441554940861763
Epoch: 9| Step: 17
Training loss: 3.647737741470337
Validation loss: 2.443471644422133
Epoch: 9| Step: 18
Training loss: 2.5303940773010254
Validation loss: 2.4430745539905354
Epoch: 9| Step: 19
Training loss: 3.0023398399353027
Validation loss: 2.4427279602709433
Epoch: 72| Step: 0
Training loss: 3.5055127143859863
Validation loss: 2.4418861848844897
Epoch: 9| Step: 1
Training loss: 2.666375160217285
Validation loss: 2.4415712631006037
Epoch: 9| Step: 2
Training loss: 2.1712756156921387
Validation loss: 2.443287568984272
Epoch: 9| Step: 3
Training loss: 3.09098482131958
Validation loss: 2.4428151648679224
Epoch: 9| Step: 4
Training loss: 2.674896478652954
Validation loss: 2.4433534265422137
Epoch: 9| Step: 5
Training loss: 3.7681126594543457
Validation loss: 2.442793003946757
Epoch: 9| Step: 6
Training loss: 3.0280327796936035
Validation loss: 2.442384278173927
Epoch: 9| Step: 7
Training loss: 2.879962921142578
Validation loss: 2.44246054038727
Epoch: 9| Step: 8
Training loss: 2.2346277236938477
Validation loss: 2.441614428870112
Epoch: 9| Step: 9
Training loss: 3.3947348594665527
Validation loss: 2.441868903825609
Epoch: 9| Step: 10
Training loss: 3.212278366088867
Validation loss: 2.4433351540737016
Epoch: 9| Step: 11
Training loss: 3.3356027603149414
Validation loss: 2.4409381708652855
Epoch: 9| Step: 12
Training loss: 2.9217114448547363
Validation loss: 2.440599645642068
Epoch: 9| Step: 13
Training loss: 3.3884639739990234
Validation loss: 2.4424967885875017
Epoch: 9| Step: 14
Training loss: 2.973712921142578
Validation loss: 2.4411966800689697
Epoch: 9| Step: 15
Training loss: 3.1090588569641113
Validation loss: 2.441319656029022
Epoch: 9| Step: 16
Training loss: 3.0731711387634277
Validation loss: 2.4415807312341045
Epoch: 9| Step: 17
Training loss: 2.3179383277893066
Validation loss: 2.440158422044713
Epoch: 9| Step: 18
Training loss: 2.580592632293701
Validation loss: 2.4437796006099783
Epoch: 9| Step: 19
Training loss: 2.9402236938476562
Validation loss: 2.4403738032142037
Epoch: 73| Step: 0
Training loss: 2.6780037879943848
Validation loss: 2.439929735746315
Epoch: 9| Step: 1
Training loss: 2.566969394683838
Validation loss: 2.4401153832030813
Epoch: 9| Step: 2
Training loss: 2.7953414916992188
Validation loss: 2.4399154203401197
Epoch: 9| Step: 3
Training loss: 3.01168155670166
Validation loss: 2.4402913223925253
Epoch: 9| Step: 4
Training loss: 2.0253117084503174
Validation loss: 2.4399950161254664
Epoch: 9| Step: 5
Training loss: 2.4431326389312744
Validation loss: 2.439936524672474
Epoch: 9| Step: 6
Training loss: 3.288116931915283
Validation loss: 2.4397408156086215
Epoch: 9| Step: 7
Training loss: 3.5661001205444336
Validation loss: 2.4401825520632077
Epoch: 9| Step: 8
Training loss: 3.59830641746521
Validation loss: 2.438570178669991
Epoch: 9| Step: 9
Training loss: 3.109220027923584
Validation loss: 2.439966731791874
Epoch: 9| Step: 10
Training loss: 3.6748862266540527
Validation loss: 2.438966322288239
Epoch: 9| Step: 11
Training loss: 3.33211612701416
Validation loss: 2.439476047488425
Epoch: 9| Step: 12
Training loss: 2.6524147987365723
Validation loss: 2.4385824134881546
Epoch: 9| Step: 13
Training loss: 2.7622640132904053
Validation loss: 2.43775033264709
Epoch: 9| Step: 14
Training loss: 2.400902271270752
Validation loss: 2.43658627880563
Epoch: 9| Step: 15
Training loss: 3.5538415908813477
Validation loss: 2.4391943036223487
Epoch: 9| Step: 16
Training loss: 2.559121608734131
Validation loss: 2.4385138021098625
Epoch: 9| Step: 17
Training loss: 3.6245152950286865
Validation loss: 2.439270477500751
Epoch: 9| Step: 18
Training loss: 2.94081974029541
Validation loss: 2.4377110313168533
Epoch: 9| Step: 19
Training loss: 2.5985236167907715
Validation loss: 2.438885928915559
Epoch: 74| Step: 0
Training loss: 3.7324624061584473
Validation loss: 2.439303278065414
Epoch: 9| Step: 1
Training loss: 2.3529937267303467
Validation loss: 2.4381618722737266
Epoch: 9| Step: 2
Training loss: 3.102945327758789
Validation loss: 2.4398059347550647
Epoch: 9| Step: 3
Training loss: 3.6537325382232666
Validation loss: 2.4374168519493487
Epoch: 9| Step: 4
Training loss: 3.513127326965332
Validation loss: 2.4368900017772646
Epoch: 9| Step: 5
Training loss: 2.5650148391723633
Validation loss: 2.436190303281057
Epoch: 9| Step: 6
Training loss: 2.716543674468994
Validation loss: 2.4356292083109023
Epoch: 9| Step: 7
Training loss: 2.908470869064331
Validation loss: 2.4338207862360015
Epoch: 9| Step: 8
Training loss: 3.2997031211853027
Validation loss: 2.4353563459657077
Epoch: 9| Step: 9
Training loss: 2.5399651527404785
Validation loss: 2.4343814695481774
Epoch: 9| Step: 10
Training loss: 3.7017908096313477
Validation loss: 2.433680728185091
Epoch: 9| Step: 11
Training loss: 2.834559440612793
Validation loss: 2.4344093679524152
Epoch: 9| Step: 12
Training loss: 2.0560615062713623
Validation loss: 2.4341043842782217
Epoch: 9| Step: 13
Training loss: 3.072328567504883
Validation loss: 2.435573753693121
Epoch: 9| Step: 14
Training loss: 3.045754909515381
Validation loss: 2.435234809093338
Epoch: 9| Step: 15
Training loss: 2.2323555946350098
Validation loss: 2.434895764151923
Epoch: 9| Step: 16
Training loss: 3.176258087158203
Validation loss: 2.434710156145713
Epoch: 9| Step: 17
Training loss: 3.834735155105591
Validation loss: 2.4356747599814437
Epoch: 9| Step: 18
Training loss: 2.8711836338043213
Validation loss: 2.434648536092086
Epoch: 9| Step: 19
Training loss: 1.9173563718795776
Validation loss: 2.4359052764426035
Epoch: 75| Step: 0
Training loss: 2.9715309143066406
Validation loss: 2.4313981258611883
Epoch: 9| Step: 1
Training loss: 2.5183792114257812
Validation loss: 2.436657027374926
Epoch: 9| Step: 2
Training loss: 3.508328914642334
Validation loss: 2.4373182735854773
Epoch: 9| Step: 3
Training loss: 3.34317684173584
Validation loss: 2.43508996551843
Epoch: 9| Step: 4
Training loss: 2.943594455718994
Validation loss: 2.4346115623446676
Epoch: 9| Step: 5
Training loss: 3.2577879428863525
Validation loss: 2.4341952423397584
Epoch: 9| Step: 6
Training loss: 2.9482531547546387
Validation loss: 2.4344232202433855
Epoch: 9| Step: 7
Training loss: 3.4620304107666016
Validation loss: 2.4319714839509925
Epoch: 9| Step: 8
Training loss: 3.5010340213775635
Validation loss: 2.43217567574206
Epoch: 9| Step: 9
Training loss: 1.7645684480667114
Validation loss: 2.434219573041518
Epoch: 9| Step: 10
Training loss: 2.8486008644104004
Validation loss: 2.432951637309232
Epoch: 9| Step: 11
Training loss: 3.095917224884033
Validation loss: 2.4327824801849802
Epoch: 9| Step: 12
Training loss: 3.5002329349517822
Validation loss: 2.433395326566353
Epoch: 9| Step: 13
Training loss: 2.487555503845215
Validation loss: 2.4326612589170606
Epoch: 9| Step: 14
Training loss: 2.7223892211914062
Validation loss: 2.4335092983657507
Epoch: 9| Step: 15
Training loss: 3.149289608001709
Validation loss: 2.4340010461189765
Epoch: 9| Step: 16
Training loss: 2.959455966949463
Validation loss: 2.433641932851119
Epoch: 9| Step: 17
Training loss: 2.273604154586792
Validation loss: 2.432798430216398
Epoch: 9| Step: 18
Training loss: 2.924689292907715
Validation loss: 2.4333844081960994
Epoch: 9| Step: 19
Training loss: 2.9088685512542725
Validation loss: 2.431863210184111
Epoch: 76| Step: 0
Training loss: 3.401822566986084
Validation loss: 2.430665985285807
Epoch: 9| Step: 1
Training loss: 3.8390629291534424
Validation loss: 2.433810788950474
Epoch: 9| Step: 2
Training loss: 3.171121120452881
Validation loss: 2.4313425314512185
Epoch: 9| Step: 3
Training loss: 3.0852818489074707
Validation loss: 2.4305412443421726
Epoch: 9| Step: 4
Training loss: 2.8660802841186523
Validation loss: 2.4311829693883444
Epoch: 9| Step: 5
Training loss: 3.056762218475342
Validation loss: 2.429591118860588
Epoch: 9| Step: 6
Training loss: 3.1362385749816895
Validation loss: 2.430161234286192
Epoch: 9| Step: 7
Training loss: 2.5578322410583496
Validation loss: 2.4305935249054174
Epoch: 9| Step: 8
Training loss: 3.3362226486206055
Validation loss: 2.430203873476536
Epoch: 9| Step: 9
Training loss: 3.2462635040283203
Validation loss: 2.4303009510040283
Epoch: 9| Step: 10
Training loss: 2.2950119972229004
Validation loss: 2.431622831083888
Epoch: 9| Step: 11
Training loss: 2.3338584899902344
Validation loss: 2.431095510935612
Epoch: 9| Step: 12
Training loss: 2.379150867462158
Validation loss: 2.4309124886560785
Epoch: 9| Step: 13
Training loss: 2.3433403968811035
Validation loss: 2.427976990775239
Epoch: 9| Step: 14
Training loss: 2.8648862838745117
Validation loss: 2.4297489742580933
Epoch: 9| Step: 15
Training loss: 1.683389663696289
Validation loss: 2.4287983942374907
Epoch: 9| Step: 16
Training loss: 2.9259560108184814
Validation loss: 2.428813145315047
Epoch: 9| Step: 17
Training loss: 3.1860551834106445
Validation loss: 2.4302334956985585
Epoch: 9| Step: 18
Training loss: 3.6062557697296143
Validation loss: 2.4292536262127995
Epoch: 9| Step: 19
Training loss: 3.7136363983154297
Validation loss: 2.4291044688053267
Epoch: 77| Step: 0
Training loss: 2.724076271057129
Validation loss: 2.427200288223706
Epoch: 9| Step: 1
Training loss: 2.785183906555176
Validation loss: 2.427870512008667
Epoch: 9| Step: 2
Training loss: 2.756476879119873
Validation loss: 2.429831886463028
Epoch: 9| Step: 3
Training loss: 3.272459030151367
Validation loss: 2.4263986872254515
Epoch: 9| Step: 4
Training loss: 2.90044903755188
Validation loss: 2.4265266270946255
Epoch: 9| Step: 5
Training loss: 2.9547667503356934
Validation loss: 2.4288865147734717
Epoch: 9| Step: 6
Training loss: 2.7838034629821777
Validation loss: 2.4273198971645438
Epoch: 9| Step: 7
Training loss: 2.736237049102783
Validation loss: 2.426393512341616
Epoch: 9| Step: 8
Training loss: 3.020134687423706
Validation loss: 2.428239187748312
Epoch: 9| Step: 9
Training loss: 2.721978187561035
Validation loss: 2.4289801806854685
Epoch: 9| Step: 10
Training loss: 3.153952121734619
Validation loss: 2.4255021853412657
Epoch: 9| Step: 11
Training loss: 2.593519449234009
Validation loss: 2.427335979269563
Epoch: 9| Step: 12
Training loss: 2.571962833404541
Validation loss: 2.427738333777558
Epoch: 9| Step: 13
Training loss: 3.515310049057007
Validation loss: 2.4311682543308617
Epoch: 9| Step: 14
Training loss: 2.3969550132751465
Validation loss: 2.428595481159018
Epoch: 9| Step: 15
Training loss: 3.660322427749634
Validation loss: 2.431251822615699
Epoch: 9| Step: 16
Training loss: 3.1052603721618652
Validation loss: 2.427484198439893
Epoch: 9| Step: 17
Training loss: 3.0588831901550293
Validation loss: 2.4281528030368063
Epoch: 9| Step: 18
Training loss: 2.92850399017334
Validation loss: 2.4253010303854086
Epoch: 9| Step: 19
Training loss: 3.3637430667877197
Validation loss: 2.4236353318468273
Epoch: 78| Step: 0
Training loss: 2.4886934757232666
Validation loss: 2.4264870719086353
Epoch: 9| Step: 1
Training loss: 2.988616704940796
Validation loss: 2.4263542436009686
Epoch: 9| Step: 2
Training loss: 2.613567352294922
Validation loss: 2.426424854093318
Epoch: 9| Step: 3
Training loss: 2.995919704437256
Validation loss: 2.4249404257150005
Epoch: 9| Step: 4
Training loss: 2.53255295753479
Validation loss: 2.425671239551023
Epoch: 9| Step: 5
Training loss: 3.350432872772217
Validation loss: 2.4255683456393453
Epoch: 9| Step: 6
Training loss: 2.6209378242492676
Validation loss: 2.426038033670659
Epoch: 9| Step: 7
Training loss: 2.8767738342285156
Validation loss: 2.4266600814654673
Epoch: 9| Step: 8
Training loss: 3.246650457382202
Validation loss: 2.4254196959433796
Epoch: 9| Step: 9
Training loss: 2.791642189025879
Validation loss: 2.426250655016453
Epoch: 9| Step: 10
Training loss: 3.375786781311035
Validation loss: 2.4254425017953776
Epoch: 9| Step: 11
Training loss: 3.0753703117370605
Validation loss: 2.424561011705467
Epoch: 9| Step: 12
Training loss: 3.004690170288086
Validation loss: 2.424597433145098
Epoch: 9| Step: 13
Training loss: 2.483985424041748
Validation loss: 2.426347598755102
Epoch: 9| Step: 14
Training loss: 3.215134620666504
Validation loss: 2.426279990793132
Epoch: 9| Step: 15
Training loss: 2.7465085983276367
Validation loss: 2.424364681724164
Epoch: 9| Step: 16
Training loss: 2.7389755249023438
Validation loss: 2.4254655838012695
Epoch: 9| Step: 17
Training loss: 3.0800774097442627
Validation loss: 2.4253782136834783
Epoch: 9| Step: 18
Training loss: 3.814816474914551
Validation loss: 2.4248292326069563
Epoch: 9| Step: 19
Training loss: 2.8774707317352295
Validation loss: 2.425704407177383
Epoch: 79| Step: 0
Training loss: 2.9126663208007812
Validation loss: 2.4272224088366943
Epoch: 9| Step: 1
Training loss: 3.3677823543548584
Validation loss: 2.4252680137003066
Epoch: 9| Step: 2
Training loss: 3.3195929527282715
Validation loss: 2.4234133813020993
Epoch: 9| Step: 3
Training loss: 3.8930504322052
Validation loss: 2.4231394229175374
Epoch: 9| Step: 4
Training loss: 2.889570951461792
Validation loss: 2.42311382122177
Epoch: 9| Step: 5
Training loss: 2.362086772918701
Validation loss: 2.422092816812529
Epoch: 9| Step: 6
Training loss: 2.3780887126922607
Validation loss: 2.4224463804162664
Epoch: 9| Step: 7
Training loss: 2.805164098739624
Validation loss: 2.4220116498658983
Epoch: 9| Step: 8
Training loss: 3.729328155517578
Validation loss: 2.4228665537113767
Epoch: 9| Step: 9
Training loss: 1.8727328777313232
Validation loss: 2.4243514666454398
Epoch: 9| Step: 10
Training loss: 3.438695192337036
Validation loss: 2.424576224183007
Epoch: 9| Step: 11
Training loss: 3.5233712196350098
Validation loss: 2.424488992142163
Epoch: 9| Step: 12
Training loss: 2.604660749435425
Validation loss: 2.4228527563081372
Epoch: 9| Step: 13
Training loss: 2.3351175785064697
Validation loss: 2.421961334111879
Epoch: 9| Step: 14
Training loss: 2.9431445598602295
Validation loss: 2.4242151452483034
Epoch: 9| Step: 15
Training loss: 2.9332218170166016
Validation loss: 2.4227907143050817
Epoch: 9| Step: 16
Training loss: 2.6671369075775146
Validation loss: 2.4211650006205057
Epoch: 9| Step: 17
Training loss: 2.6159820556640625
Validation loss: 2.42103302135742
Epoch: 9| Step: 18
Training loss: 3.4604506492614746
Validation loss: 2.421366482329883
Epoch: 9| Step: 19
Training loss: 2.8341076374053955
Validation loss: 2.4229030180320463
Epoch: 80| Step: 0
Training loss: 3.0539963245391846
Validation loss: 2.4232693747650806
Epoch: 9| Step: 1
Training loss: 3.243466377258301
Validation loss: 2.4231685717328846
Epoch: 9| Step: 2
Training loss: 2.19240140914917
Validation loss: 2.4237382995138925
Epoch: 9| Step: 3
Training loss: 3.3286349773406982
Validation loss: 2.420956963257824
Epoch: 9| Step: 4
Training loss: 2.833693027496338
Validation loss: 2.4228367479585056
Epoch: 9| Step: 5
Training loss: 3.127183675765991
Validation loss: 2.4198953350670904
Epoch: 9| Step: 6
Training loss: 3.138709306716919
Validation loss: 2.4204327459815596
Epoch: 9| Step: 7
Training loss: 2.6191413402557373
Validation loss: 2.4209469616841925
Epoch: 9| Step: 8
Training loss: 2.675210952758789
Validation loss: 2.4205636960996997
Epoch: 9| Step: 9
Training loss: 2.5215020179748535
Validation loss: 2.41853840402562
Epoch: 9| Step: 10
Training loss: 2.957105875015259
Validation loss: 2.421372575725583
Epoch: 9| Step: 11
Training loss: 3.7074153423309326
Validation loss: 2.4205417530142146
Epoch: 9| Step: 12
Training loss: 3.4480185508728027
Validation loss: 2.421600609374561
Epoch: 9| Step: 13
Training loss: 2.970142364501953
Validation loss: 2.421115813495444
Epoch: 9| Step: 14
Training loss: 3.374829053878784
Validation loss: 2.421934100363752
Epoch: 9| Step: 15
Training loss: 2.867621898651123
Validation loss: 2.420796970669314
Epoch: 9| Step: 16
Training loss: 3.1030020713806152
Validation loss: 2.4221042343180814
Epoch: 9| Step: 17
Training loss: 3.3768744468688965
Validation loss: 2.421125353669091
Epoch: 9| Step: 18
Training loss: 2.364856719970703
Validation loss: 2.4211438113836934
Epoch: 9| Step: 19
Training loss: 1.9284826517105103
Validation loss: 2.420202927623721
Epoch: 81| Step: 0
Training loss: 3.674098491668701
Validation loss: 2.420427550514825
Epoch: 9| Step: 1
Training loss: 3.4823720455169678
Validation loss: 2.419479963590773
Epoch: 9| Step: 2
Training loss: 2.844592571258545
Validation loss: 2.420501590632706
Epoch: 9| Step: 3
Training loss: 3.237950325012207
Validation loss: 2.41753263524968
Epoch: 9| Step: 4
Training loss: 3.3470356464385986
Validation loss: 2.4199120483810095
Epoch: 9| Step: 5
Training loss: 2.795034408569336
Validation loss: 2.419139695682114
Epoch: 9| Step: 6
Training loss: 3.178008556365967
Validation loss: 2.4178875659009536
Epoch: 9| Step: 7
Training loss: 2.6251821517944336
Validation loss: 2.4181017686994815
Epoch: 9| Step: 8
Training loss: 2.9626359939575195
Validation loss: 2.4159337582348064
Epoch: 9| Step: 9
Training loss: 3.6742470264434814
Validation loss: 2.416387600864438
Epoch: 9| Step: 10
Training loss: 2.5750739574432373
Validation loss: 2.417935726453932
Epoch: 9| Step: 11
Training loss: 2.8437840938568115
Validation loss: 2.4168679971489118
Epoch: 9| Step: 12
Training loss: 2.0905001163482666
Validation loss: 2.4164175764262246
Epoch: 9| Step: 13
Training loss: 2.7138359546661377
Validation loss: 2.4162144918235944
Epoch: 9| Step: 14
Training loss: 2.050593376159668
Validation loss: 2.417089513737521
Epoch: 9| Step: 15
Training loss: 2.8550844192504883
Validation loss: 2.417816324199704
Epoch: 9| Step: 16
Training loss: 3.0698962211608887
Validation loss: 2.4164970195550715
Epoch: 9| Step: 17
Training loss: 2.7297966480255127
Validation loss: 2.4190996670894487
Epoch: 9| Step: 18
Training loss: 2.890368700027466
Validation loss: 2.4172849346407883
Epoch: 9| Step: 19
Training loss: 3.1680262088775635
Validation loss: 2.416770784117335
Epoch: 82| Step: 0
Training loss: 2.6510820388793945
Validation loss: 2.4162797087388075
Epoch: 9| Step: 1
Training loss: 2.9234118461608887
Validation loss: 2.417260428984388
Epoch: 9| Step: 2
Training loss: 3.431696891784668
Validation loss: 2.4176022937829544
Epoch: 9| Step: 3
Training loss: 2.553511381149292
Validation loss: 2.417928633930014
Epoch: 9| Step: 4
Training loss: 2.7747275829315186
Validation loss: 2.4172652899790155
Epoch: 9| Step: 5
Training loss: 2.4817726612091064
Validation loss: 2.4178658938236373
Epoch: 9| Step: 6
Training loss: 3.5395612716674805
Validation loss: 2.417155707482811
Epoch: 9| Step: 7
Training loss: 2.4969608783721924
Validation loss: 2.4147156416941034
Epoch: 9| Step: 8
Training loss: 3.2846813201904297
Validation loss: 2.414318269962887
Epoch: 9| Step: 9
Training loss: 3.3601126670837402
Validation loss: 2.412103663245551
Epoch: 9| Step: 10
Training loss: 3.22244930267334
Validation loss: 2.4138458804260914
Epoch: 9| Step: 11
Training loss: 2.4553709030151367
Validation loss: 2.4150234795302796
Epoch: 9| Step: 12
Training loss: 3.063380718231201
Validation loss: 2.4136121135821447
Epoch: 9| Step: 13
Training loss: 3.136305809020996
Validation loss: 2.4132902124802844
Epoch: 9| Step: 14
Training loss: 3.079375743865967
Validation loss: 2.4115999894176454
Epoch: 9| Step: 15
Training loss: 2.6615641117095947
Validation loss: 2.412586229310619
Epoch: 9| Step: 16
Training loss: 2.889639139175415
Validation loss: 2.4120682675203833
Epoch: 9| Step: 17
Training loss: 2.4438791275024414
Validation loss: 2.412682562423267
Epoch: 9| Step: 18
Training loss: 3.408144474029541
Validation loss: 2.4153227951886844
Epoch: 9| Step: 19
Training loss: 2.869074583053589
Validation loss: 2.414136540117881
Epoch: 83| Step: 0
Training loss: 3.2179887294769287
Validation loss: 2.4136616240302438
Epoch: 9| Step: 1
Training loss: 2.7047128677368164
Validation loss: 2.412097639317135
Epoch: 9| Step: 2
Training loss: 2.9512381553649902
Validation loss: 2.4130290463673982
Epoch: 9| Step: 3
Training loss: 2.8511226177215576
Validation loss: 2.4127463831318368
Epoch: 9| Step: 4
Training loss: 3.034029245376587
Validation loss: 2.4117957207796383
Epoch: 9| Step: 5
Training loss: 3.049072742462158
Validation loss: 2.4147438745704486
Epoch: 9| Step: 6
Training loss: 3.3931784629821777
Validation loss: 2.411279891034682
Epoch: 9| Step: 7
Training loss: 3.0396032333374023
Validation loss: 2.411876476068291
Epoch: 9| Step: 8
Training loss: 2.778820037841797
Validation loss: 2.409921788483215
Epoch: 9| Step: 9
Training loss: 2.696126937866211
Validation loss: 2.4104597928712694
Epoch: 9| Step: 10
Training loss: 2.8651351928710938
Validation loss: 2.4109096218356125
Epoch: 9| Step: 11
Training loss: 3.023559093475342
Validation loss: 2.408721388672753
Epoch: 9| Step: 12
Training loss: 3.1945505142211914
Validation loss: 2.4105211281947954
Epoch: 9| Step: 13
Training loss: 2.454333782196045
Validation loss: 2.414924921749307
Epoch: 9| Step: 14
Training loss: 2.690601110458374
Validation loss: 2.4093209650876712
Epoch: 9| Step: 15
Training loss: 3.084469795227051
Validation loss: 2.410284840803352
Epoch: 9| Step: 16
Training loss: 3.070993423461914
Validation loss: 2.4123655634818317
Epoch: 9| Step: 17
Training loss: 2.4894819259643555
Validation loss: 2.412659509576482
Epoch: 9| Step: 18
Training loss: 3.093703269958496
Validation loss: 2.4098858919075066
Epoch: 9| Step: 19
Training loss: 2.9941494464874268
Validation loss: 2.4128879214362273
Epoch: 84| Step: 0
Training loss: 3.953911304473877
Validation loss: 2.4112530149144233
Epoch: 9| Step: 1
Training loss: 3.16853666305542
Validation loss: 2.41032857174496
Epoch: 9| Step: 2
Training loss: 3.2414755821228027
Validation loss: 2.4096391887115916
Epoch: 9| Step: 3
Training loss: 3.3166537284851074
Validation loss: 2.409505670019191
Epoch: 9| Step: 4
Training loss: 2.2005975246429443
Validation loss: 2.4077888152582183
Epoch: 9| Step: 5
Training loss: 2.3918166160583496
Validation loss: 2.406955833915326
Epoch: 9| Step: 6
Training loss: 3.164503574371338
Validation loss: 2.4071691893845153
Epoch: 9| Step: 7
Training loss: 2.223482370376587
Validation loss: 2.4062524244939683
Epoch: 9| Step: 8
Training loss: 2.4604105949401855
Validation loss: 2.4066697607795113
Epoch: 9| Step: 9
Training loss: 3.3154382705688477
Validation loss: 2.406687026401218
Epoch: 9| Step: 10
Training loss: 2.5952072143554688
Validation loss: 2.4079429211376384
Epoch: 9| Step: 11
Training loss: 2.2370424270629883
Validation loss: 2.4066027291387107
Epoch: 9| Step: 12
Training loss: 3.0003581047058105
Validation loss: 2.407077755001809
Epoch: 9| Step: 13
Training loss: 3.399608850479126
Validation loss: 2.4053411363697736
Epoch: 9| Step: 14
Training loss: 2.8636937141418457
Validation loss: 2.4061494877012515
Epoch: 9| Step: 15
Training loss: 2.986363410949707
Validation loss: 2.406173019958057
Epoch: 9| Step: 16
Training loss: 3.5334248542785645
Validation loss: 2.4040281172278974
Epoch: 9| Step: 17
Training loss: 2.9720449447631836
Validation loss: 2.402434088343339
Epoch: 9| Step: 18
Training loss: 2.952317714691162
Validation loss: 2.40635091623814
Epoch: 9| Step: 19
Training loss: 2.6642799377441406
Validation loss: 2.4040149733316984
Epoch: 85| Step: 0
Training loss: 3.4478464126586914
Validation loss: 2.4047472922922037
Epoch: 9| Step: 1
Training loss: 2.3487889766693115
Validation loss: 2.4057992619576214
Epoch: 9| Step: 2
Training loss: 3.0392539501190186
Validation loss: 2.404786888643992
Epoch: 9| Step: 3
Training loss: 3.5579028129577637
Validation loss: 2.405869163197579
Epoch: 9| Step: 4
Training loss: 2.2291419506073
Validation loss: 2.405062275824787
Epoch: 9| Step: 5
Training loss: 2.9103848934173584
Validation loss: 2.4024568753276796
Epoch: 9| Step: 6
Training loss: 2.577258586883545
Validation loss: 2.4033959666602045
Epoch: 9| Step: 7
Training loss: 2.9468414783477783
Validation loss: 2.4034911882963113
Epoch: 9| Step: 8
Training loss: 3.408698081970215
Validation loss: 2.4020840589948693
Epoch: 9| Step: 9
Training loss: 2.8675403594970703
Validation loss: 2.401558243113456
Epoch: 9| Step: 10
Training loss: 3.0956871509552
Validation loss: 2.4025787398111906
Epoch: 9| Step: 11
Training loss: 2.274726152420044
Validation loss: 2.402341244032057
Epoch: 9| Step: 12
Training loss: 3.403825283050537
Validation loss: 2.403021685511088
Epoch: 9| Step: 13
Training loss: 2.71063232421875
Validation loss: 2.402289980607067
Epoch: 9| Step: 14
Training loss: 2.855698823928833
Validation loss: 2.400567360061536
Epoch: 9| Step: 15
Training loss: 2.281857967376709
Validation loss: 2.4023764716635507
Epoch: 9| Step: 16
Training loss: 2.958509922027588
Validation loss: 2.398844266109329
Epoch: 9| Step: 17
Training loss: 2.6096582412719727
Validation loss: 2.401511159732187
Epoch: 9| Step: 18
Training loss: 3.82279634475708
Validation loss: 2.4047315721031572
Epoch: 9| Step: 19
Training loss: 3.1522257328033447
Validation loss: 2.4007442803691617
Epoch: 86| Step: 0
Training loss: 3.0499720573425293
Validation loss: 2.398855650167671
Epoch: 9| Step: 1
Training loss: 2.9945523738861084
Validation loss: 2.4017865863635386
Epoch: 9| Step: 2
Training loss: 2.580780506134033
Validation loss: 2.39973144737079
Epoch: 9| Step: 3
Training loss: 3.3093388080596924
Validation loss: 2.400066958914558
Epoch: 9| Step: 4
Training loss: 3.017033338546753
Validation loss: 2.3974166653996747
Epoch: 9| Step: 5
Training loss: 2.3888397216796875
Validation loss: 2.3997850280871496
Epoch: 9| Step: 6
Training loss: 2.738445281982422
Validation loss: 2.3992661074768726
Epoch: 9| Step: 7
Training loss: 4.071124076843262
Validation loss: 2.400899324485724
Epoch: 9| Step: 8
Training loss: 3.3172545433044434
Validation loss: 2.3982839678688874
Epoch: 9| Step: 9
Training loss: 3.0817925930023193
Validation loss: 2.3979224832795505
Epoch: 9| Step: 10
Training loss: 2.624582290649414
Validation loss: 2.398027648171075
Epoch: 9| Step: 11
Training loss: 2.4791359901428223
Validation loss: 2.3987301819616085
Epoch: 9| Step: 12
Training loss: 2.692211151123047
Validation loss: 2.396751438113425
Epoch: 9| Step: 13
Training loss: 2.486032247543335
Validation loss: 2.3978817051263164
Epoch: 9| Step: 14
Training loss: 2.5354981422424316
Validation loss: 2.3959212611905105
Epoch: 9| Step: 15
Training loss: 2.958554744720459
Validation loss: 2.395713982822226
Epoch: 9| Step: 16
Training loss: 2.9434545040130615
Validation loss: 2.3956214163800795
Epoch: 9| Step: 17
Training loss: 3.6434097290039062
Validation loss: 2.3957794570236755
Epoch: 9| Step: 18
Training loss: 3.161273956298828
Validation loss: 2.3936218940954412
Epoch: 9| Step: 19
Training loss: 2.4079060554504395
Validation loss: 2.395597936438142
Epoch: 87| Step: 0
Training loss: 3.1992788314819336
Validation loss: 2.3943929860917783
Epoch: 9| Step: 1
Training loss: 2.7579686641693115
Validation loss: 2.395014154825279
Epoch: 9| Step: 2
Training loss: 3.471289873123169
Validation loss: 2.3967815011525326
Epoch: 9| Step: 3
Training loss: 3.6847822666168213
Validation loss: 2.3940770231562554
Epoch: 9| Step: 4
Training loss: 2.348820209503174
Validation loss: 2.393339258303745
Epoch: 9| Step: 5
Training loss: 2.816770076751709
Validation loss: 2.394739185305808
Epoch: 9| Step: 6
Training loss: 3.031679630279541
Validation loss: 2.3945674853359193
Epoch: 9| Step: 7
Training loss: 2.297426223754883
Validation loss: 2.396501772695308
Epoch: 9| Step: 8
Training loss: 2.567682981491089
Validation loss: 2.3966459473260016
Epoch: 9| Step: 9
Training loss: 3.2988123893737793
Validation loss: 2.3945648584434456
Epoch: 9| Step: 10
Training loss: 3.3467295169830322
Validation loss: 2.395334742052092
Epoch: 9| Step: 11
Training loss: 3.1383213996887207
Validation loss: 2.3951671500857787
Epoch: 9| Step: 12
Training loss: 2.613116502761841
Validation loss: 2.393067066618007
Epoch: 9| Step: 13
Training loss: 2.3488173484802246
Validation loss: 2.3921105347091345
Epoch: 9| Step: 14
Training loss: 2.727900743484497
Validation loss: 2.3943453847075538
Epoch: 9| Step: 15
Training loss: 3.2971110343933105
Validation loss: 2.392110021851903
Epoch: 9| Step: 16
Training loss: 2.2591030597686768
Validation loss: 2.3905194954906435
Epoch: 9| Step: 17
Training loss: 2.291257381439209
Validation loss: 2.391276021655515
Epoch: 9| Step: 18
Training loss: 3.2775204181671143
Validation loss: 2.3907607682317282
Epoch: 9| Step: 19
Training loss: 3.5860610008239746
Validation loss: 2.3906799854992107
Epoch: 88| Step: 0
Training loss: 3.1294302940368652
Validation loss: 2.3905171438944426
Epoch: 9| Step: 1
Training loss: 2.804063558578491
Validation loss: 2.391742070801824
Epoch: 9| Step: 2
Training loss: 2.5271475315093994
Validation loss: 2.390952377868213
Epoch: 9| Step: 3
Training loss: 2.2718141078948975
Validation loss: 2.3908926137059714
Epoch: 9| Step: 4
Training loss: 2.5765175819396973
Validation loss: 2.389163876608979
Epoch: 9| Step: 5
Training loss: 2.7625367641448975
Validation loss: 2.3903234982662065
Epoch: 9| Step: 6
Training loss: 2.4693260192871094
Validation loss: 2.3908456238053684
Epoch: 9| Step: 7
Training loss: 3.1795437335968018
Validation loss: 2.3886066443628544
Epoch: 9| Step: 8
Training loss: 2.8575894832611084
Validation loss: 2.388955430161181
Epoch: 9| Step: 9
Training loss: 3.00630521774292
Validation loss: 2.3854542018698273
Epoch: 9| Step: 10
Training loss: 2.359205961227417
Validation loss: 2.3897693834716467
Epoch: 9| Step: 11
Training loss: 2.7304494380950928
Validation loss: 2.393179907215585
Epoch: 9| Step: 12
Training loss: 3.671243906021118
Validation loss: 2.393483439795405
Epoch: 9| Step: 13
Training loss: 3.8784327507019043
Validation loss: 2.3931681818241697
Epoch: 9| Step: 14
Training loss: 3.0381851196289062
Validation loss: 2.3991727160035277
Epoch: 9| Step: 15
Training loss: 2.9810147285461426
Validation loss: 2.3914951883631645
Epoch: 9| Step: 16
Training loss: 3.8782947063446045
Validation loss: 2.393459742017787
Epoch: 9| Step: 17
Training loss: 2.432844638824463
Validation loss: 2.388981115903786
Epoch: 9| Step: 18
Training loss: 3.089996814727783
Validation loss: 2.3886689196387643
Epoch: 9| Step: 19
Training loss: 2.6684536933898926
Validation loss: 2.386659937796833
Epoch: 89| Step: 0
Training loss: 3.1412196159362793
Validation loss: 2.3857423916137477
Epoch: 9| Step: 1
Training loss: 2.948301076889038
Validation loss: 2.386844147881158
Epoch: 9| Step: 2
Training loss: 3.0025997161865234
Validation loss: 2.3866830523923146
Epoch: 9| Step: 3
Training loss: 2.993398666381836
Validation loss: 2.3868468493866404
Epoch: 9| Step: 4
Training loss: 2.2871360778808594
Validation loss: 2.3891714802748867
Epoch: 9| Step: 5
Training loss: 2.9232163429260254
Validation loss: 2.3859628567592703
Epoch: 9| Step: 6
Training loss: 2.7182600498199463
Validation loss: 2.3865040274832747
Epoch: 9| Step: 7
Training loss: 2.8490853309631348
Validation loss: 2.385483842959507
Epoch: 9| Step: 8
Training loss: 2.801048755645752
Validation loss: 2.3855266708264247
Epoch: 9| Step: 9
Training loss: 3.813246965408325
Validation loss: 2.3852094780626913
Epoch: 9| Step: 10
Training loss: 3.024888515472412
Validation loss: 2.385333392259886
Epoch: 9| Step: 11
Training loss: 2.224391460418701
Validation loss: 2.3856318425789156
Epoch: 9| Step: 12
Training loss: 2.9944357872009277
Validation loss: 2.385760084330607
Epoch: 9| Step: 13
Training loss: 2.775838851928711
Validation loss: 2.385562428467565
Epoch: 9| Step: 14
Training loss: 3.3629953861236572
Validation loss: 2.384327502559415
Epoch: 9| Step: 15
Training loss: 2.3717269897460938
Validation loss: 2.3836713806330727
Epoch: 9| Step: 16
Training loss: 2.8217086791992188
Validation loss: 2.3831649255409517
Epoch: 9| Step: 17
Training loss: 2.7175166606903076
Validation loss: 2.3845544358809216
Epoch: 9| Step: 18
Training loss: 3.3838610649108887
Validation loss: 2.3835647054713407
Epoch: 9| Step: 19
Training loss: 3.1173698902130127
Validation loss: 2.385799977419188
Epoch: 90| Step: 0
Training loss: 2.4851794242858887
Validation loss: 2.3856694423895086
Epoch: 9| Step: 1
Training loss: 2.9924025535583496
Validation loss: 2.3853501999120916
Epoch: 9| Step: 2
Training loss: 2.7510735988616943
Validation loss: 2.384873427933069
Epoch: 9| Step: 3
Training loss: 2.9515390396118164
Validation loss: 2.384079233347941
Epoch: 9| Step: 4
Training loss: 2.7791552543640137
Validation loss: 2.3828181208466455
Epoch: 9| Step: 5
Training loss: 4.149351596832275
Validation loss: 2.382130413604297
Epoch: 9| Step: 6
Training loss: 2.863593101501465
Validation loss: 2.3807672853950117
Epoch: 9| Step: 7
Training loss: 2.2329907417297363
Validation loss: 2.3846657036019745
Epoch: 9| Step: 8
Training loss: 3.33874773979187
Validation loss: 2.3810623309595123
Epoch: 9| Step: 9
Training loss: 2.4624710083007812
Validation loss: 2.381434323976366
Epoch: 9| Step: 10
Training loss: 3.7432847023010254
Validation loss: 2.379403047424426
Epoch: 9| Step: 11
Training loss: 2.1411473751068115
Validation loss: 2.383043555047015
Epoch: 9| Step: 12
Training loss: 2.891467571258545
Validation loss: 2.3827622785842677
Epoch: 9| Step: 13
Training loss: 3.583648204803467
Validation loss: 2.382071430734593
Epoch: 9| Step: 14
Training loss: 2.467956066131592
Validation loss: 2.382756030816826
Epoch: 9| Step: 15
Training loss: 2.1562416553497314
Validation loss: 2.3809296012782366
Epoch: 9| Step: 16
Training loss: 3.1513938903808594
Validation loss: 2.3816348442928397
Epoch: 9| Step: 17
Training loss: 3.1389942169189453
Validation loss: 2.3820562499890223
Epoch: 9| Step: 18
Training loss: 3.061007499694824
Validation loss: 2.381998568987675
Epoch: 9| Step: 19
Training loss: 2.833483934402466
Validation loss: 2.3818760381328117
Epoch: 91| Step: 0
Training loss: 2.643920421600342
Validation loss: 2.384665092975973
Epoch: 9| Step: 1
Training loss: 3.1516265869140625
Validation loss: 2.380084890255825
Epoch: 9| Step: 2
Training loss: 3.2940568923950195
Validation loss: 2.3846109256469945
Epoch: 9| Step: 3
Training loss: 3.053893804550171
Validation loss: 2.37901200836511
Epoch: 9| Step: 4
Training loss: 2.9758315086364746
Validation loss: 2.3808948530567635
Epoch: 9| Step: 5
Training loss: 2.9073562622070312
Validation loss: 2.3860415760561717
Epoch: 9| Step: 6
Training loss: 2.4972429275512695
Validation loss: 2.380321902336834
Epoch: 9| Step: 7
Training loss: 3.261073112487793
Validation loss: 2.380364544957662
Epoch: 9| Step: 8
Training loss: 3.32631778717041
Validation loss: 2.381725746950657
Epoch: 9| Step: 9
Training loss: 2.8077526092529297
Validation loss: 2.380399381514076
Epoch: 9| Step: 10
Training loss: 2.498262405395508
Validation loss: 2.3815796100836004
Epoch: 9| Step: 11
Training loss: 2.799388885498047
Validation loss: 2.3795395960910715
Epoch: 9| Step: 12
Training loss: 2.7832767963409424
Validation loss: 2.378707029836641
Epoch: 9| Step: 13
Training loss: 2.3885245323181152
Validation loss: 2.3817815025933355
Epoch: 9| Step: 14
Training loss: 3.1722559928894043
Validation loss: 2.3795302360177897
Epoch: 9| Step: 15
Training loss: 2.5491409301757812
Validation loss: 2.3821142080018847
Epoch: 9| Step: 16
Training loss: 2.382279872894287
Validation loss: 2.3787109011368788
Epoch: 9| Step: 17
Training loss: 3.349966049194336
Validation loss: 2.3791480467473862
Epoch: 9| Step: 18
Training loss: 2.960264205932617
Validation loss: 2.3803050123530327
Epoch: 9| Step: 19
Training loss: 3.3127946853637695
Validation loss: 2.378773095796434
Epoch: 92| Step: 0
Training loss: 3.3272476196289062
Validation loss: 2.378451316476726
Epoch: 9| Step: 1
Training loss: 2.847647190093994
Validation loss: 2.3807931358008076
Epoch: 9| Step: 2
Training loss: 3.2965385913848877
Validation loss: 2.3794988196530786
Epoch: 9| Step: 3
Training loss: 3.091243028640747
Validation loss: 2.3769745972516727
Epoch: 9| Step: 4
Training loss: 3.2469000816345215
Validation loss: 2.378946462123514
Epoch: 9| Step: 5
Training loss: 3.106388568878174
Validation loss: 2.378665267134742
Epoch: 9| Step: 6
Training loss: 2.41702938079834
Validation loss: 2.37887238598556
Epoch: 9| Step: 7
Training loss: 2.3027491569519043
Validation loss: 2.3801771496697297
Epoch: 9| Step: 8
Training loss: 3.3903911113739014
Validation loss: 2.3789426491414902
Epoch: 9| Step: 9
Training loss: 2.253885269165039
Validation loss: 2.3782247707998154
Epoch: 9| Step: 10
Training loss: 2.3840246200561523
Validation loss: 2.3779019160236388
Epoch: 9| Step: 11
Training loss: 2.868858814239502
Validation loss: 2.378853293631574
Epoch: 9| Step: 12
Training loss: 3.446317195892334
Validation loss: 2.379564532273107
Epoch: 9| Step: 13
Training loss: 2.9701895713806152
Validation loss: 2.3742232820112927
Epoch: 9| Step: 14
Training loss: 2.641043186187744
Validation loss: 2.3777055088564647
Epoch: 9| Step: 15
Training loss: 1.7421722412109375
Validation loss: 2.3752947711258483
Epoch: 9| Step: 16
Training loss: 3.3007466793060303
Validation loss: 2.376506783121781
Epoch: 9| Step: 17
Training loss: 2.7877464294433594
Validation loss: 2.3764506535564394
Epoch: 9| Step: 18
Training loss: 3.8966197967529297
Validation loss: 2.377036164990432
Epoch: 9| Step: 19
Training loss: 2.7331690788269043
Validation loss: 2.37709198581229
Epoch: 93| Step: 0
Training loss: 2.696345806121826
Validation loss: 2.3752642724153805
Epoch: 9| Step: 1
Training loss: 3.417308807373047
Validation loss: 2.3758584097992603
Epoch: 9| Step: 2
Training loss: 2.3025565147399902
Validation loss: 2.3768411797585247
Epoch: 9| Step: 3
Training loss: 3.095890522003174
Validation loss: 2.3756655952055676
Epoch: 9| Step: 4
Training loss: 3.6025636196136475
Validation loss: 2.376222711672886
Epoch: 9| Step: 5
Training loss: 3.0444693565368652
Validation loss: 2.374516487121582
Epoch: 9| Step: 6
Training loss: 3.089524745941162
Validation loss: 2.3741179713242344
Epoch: 9| Step: 7
Training loss: 3.21307635307312
Validation loss: 2.3741813915238965
Epoch: 9| Step: 8
Training loss: 2.0454509258270264
Validation loss: 2.3746931467124885
Epoch: 9| Step: 9
Training loss: 2.734048843383789
Validation loss: 2.374464681680254
Epoch: 9| Step: 10
Training loss: 3.1721031665802
Validation loss: 2.375452569920382
Epoch: 9| Step: 11
Training loss: 3.1168317794799805
Validation loss: 2.37289422707592
Epoch: 9| Step: 12
Training loss: 2.455723285675049
Validation loss: 2.379303916752767
Epoch: 9| Step: 13
Training loss: 2.450639247894287
Validation loss: 2.375377193629313
Epoch: 9| Step: 14
Training loss: 3.2276506423950195
Validation loss: 2.3736779741246066
Epoch: 9| Step: 15
Training loss: 2.750067710876465
Validation loss: 2.3741210707657627
Epoch: 9| Step: 16
Training loss: 2.750270366668701
Validation loss: 2.374125190776029
Epoch: 9| Step: 17
Training loss: 3.0811517238616943
Validation loss: 2.3727459307197187
Epoch: 9| Step: 18
Training loss: 2.884000062942505
Validation loss: 2.3723657628615125
Epoch: 9| Step: 19
Training loss: 2.9046213626861572
Validation loss: 2.3735371750893353
Epoch: 94| Step: 0
Training loss: 2.873176097869873
Validation loss: 2.3747694166444187
Epoch: 9| Step: 1
Training loss: 3.0032100677490234
Validation loss: 2.3744619913238414
Epoch: 9| Step: 2
Training loss: 2.9787139892578125
Validation loss: 2.3741735091312326
Epoch: 9| Step: 3
Training loss: 3.001776695251465
Validation loss: 2.377035614397886
Epoch: 9| Step: 4
Training loss: 2.9816839694976807
Validation loss: 2.373013969805601
Epoch: 9| Step: 5
Training loss: 2.530512809753418
Validation loss: 2.3715630452409924
Epoch: 9| Step: 6
Training loss: 2.575873851776123
Validation loss: 2.372610949783874
Epoch: 9| Step: 7
Training loss: 2.880516767501831
Validation loss: 2.3721375311021324
Epoch: 9| Step: 8
Training loss: 3.3180201053619385
Validation loss: 2.3742675438201686
Epoch: 9| Step: 9
Training loss: 3.501253128051758
Validation loss: 2.372626247165872
Epoch: 9| Step: 10
Training loss: 2.418550729751587
Validation loss: 2.372451092699449
Epoch: 9| Step: 11
Training loss: 2.779879570007324
Validation loss: 2.37228684631183
Epoch: 9| Step: 12
Training loss: 2.4857254028320312
Validation loss: 2.3730274593229774
Epoch: 9| Step: 13
Training loss: 3.0503103733062744
Validation loss: 2.3705651828710983
Epoch: 9| Step: 14
Training loss: 3.1476035118103027
Validation loss: 2.371301795081269
Epoch: 9| Step: 15
Training loss: 3.157618999481201
Validation loss: 2.369845330286369
Epoch: 9| Step: 16
Training loss: 2.945560932159424
Validation loss: 2.3691255891923424
Epoch: 9| Step: 17
Training loss: 2.653622627258301
Validation loss: 2.371298443499229
Epoch: 9| Step: 18
Training loss: 3.081207036972046
Validation loss: 2.3747101396107846
Epoch: 9| Step: 19
Training loss: 2.631399154663086
Validation loss: 2.371077643881599
Epoch: 95| Step: 0
Training loss: 2.979893922805786
Validation loss: 2.369245623513091
Epoch: 9| Step: 1
Training loss: 3.4852561950683594
Validation loss: 2.371166953079992
Epoch: 9| Step: 2
Training loss: 3.2123265266418457
Validation loss: 2.370705825819386
Epoch: 9| Step: 3
Training loss: 2.812601089477539
Validation loss: 2.3682937004583344
Epoch: 9| Step: 4
Training loss: 2.8775315284729004
Validation loss: 2.3717312829957593
Epoch: 9| Step: 5
Training loss: 2.562215566635132
Validation loss: 2.3692380987482964
Epoch: 9| Step: 6
Training loss: 2.2563741207122803
Validation loss: 2.3735167637145778
Epoch: 9| Step: 7
Training loss: 2.9278879165649414
Validation loss: 2.37026135870021
Epoch: 9| Step: 8
Training loss: 2.955432891845703
Validation loss: 2.370303720021419
Epoch: 9| Step: 9
Training loss: 3.2287347316741943
Validation loss: 2.3700103159431074
Epoch: 9| Step: 10
Training loss: 2.6997017860412598
Validation loss: 2.3709997856359686
Epoch: 9| Step: 11
Training loss: 2.8263354301452637
Validation loss: 2.3689315816481336
Epoch: 9| Step: 12
Training loss: 2.6268365383148193
Validation loss: 2.3694007568222157
Epoch: 9| Step: 13
Training loss: 2.7889938354492188
Validation loss: 2.3729500461825364
Epoch: 9| Step: 14
Training loss: 2.6833133697509766
Validation loss: 2.3687802621786544
Epoch: 9| Step: 15
Training loss: 2.7112784385681152
Validation loss: 2.3674899811367336
Epoch: 9| Step: 16
Training loss: 2.7904322147369385
Validation loss: 2.3688212967605042
Epoch: 9| Step: 17
Training loss: 3.4790310859680176
Validation loss: 2.3698292781980776
Epoch: 9| Step: 18
Training loss: 3.102205276489258
Validation loss: 2.371255907223379
Epoch: 9| Step: 19
Training loss: 2.926149845123291
Validation loss: 2.369807910576141
Epoch: 96| Step: 0
Training loss: 2.9526519775390625
Validation loss: 2.369175705120718
Epoch: 9| Step: 1
Training loss: 3.378251552581787
Validation loss: 2.3682448898287984
Epoch: 9| Step: 2
Training loss: 3.1140997409820557
Validation loss: 2.3674379235548937
Epoch: 9| Step: 3
Training loss: 2.0573606491088867
Validation loss: 2.3708135807256903
Epoch: 9| Step: 4
Training loss: 2.8612828254699707
Validation loss: 2.3687612564443685
Epoch: 9| Step: 5
Training loss: 2.7188892364501953
Validation loss: 2.372268800255206
Epoch: 9| Step: 6
Training loss: 3.224735975265503
Validation loss: 2.369201874561447
Epoch: 9| Step: 7
Training loss: 2.840178966522217
Validation loss: 2.368178699513991
Epoch: 9| Step: 8
Training loss: 3.11892032623291
Validation loss: 2.3696540911420643
Epoch: 9| Step: 9
Training loss: 2.872779369354248
Validation loss: 2.369290501093693
Epoch: 9| Step: 10
Training loss: 2.5970330238342285
Validation loss: 2.3679979516447878
Epoch: 9| Step: 11
Training loss: 2.8192906379699707
Validation loss: 2.3662799005028154
Epoch: 9| Step: 12
Training loss: 3.728132724761963
Validation loss: 2.367262816257614
Epoch: 9| Step: 13
Training loss: 2.499026298522949
Validation loss: 2.366736103304856
Epoch: 9| Step: 14
Training loss: 2.308131217956543
Validation loss: 2.3670166379256212
Epoch: 9| Step: 15
Training loss: 3.0720622539520264
Validation loss: 2.3683049816021815
Epoch: 9| Step: 16
Training loss: 3.197288990020752
Validation loss: 2.3672072801658577
Epoch: 9| Step: 17
Training loss: 2.6183526515960693
Validation loss: 2.368616735334877
Epoch: 9| Step: 18
Training loss: 2.5749616622924805
Validation loss: 2.368666192610487
Epoch: 9| Step: 19
Training loss: 3.341512680053711
Validation loss: 2.367859234055169
Epoch: 97| Step: 0
Training loss: 2.927983283996582
Validation loss: 2.370051347094474
Epoch: 9| Step: 1
Training loss: 2.7421371936798096
Validation loss: 2.3678933579287085
Epoch: 9| Step: 2
Training loss: 2.444565773010254
Validation loss: 2.3708310641830774
Epoch: 9| Step: 3
Training loss: 2.8393423557281494
Validation loss: 2.3711201046868196
Epoch: 9| Step: 4
Training loss: 2.732055902481079
Validation loss: 2.371362319095529
Epoch: 9| Step: 5
Training loss: 1.5714634656906128
Validation loss: 2.372067895724619
Epoch: 9| Step: 6
Training loss: 3.1865386962890625
Validation loss: 2.371402032083745
Epoch: 9| Step: 7
Training loss: 3.079197406768799
Validation loss: 2.3727959471640827
Epoch: 9| Step: 8
Training loss: 3.9438648223876953
Validation loss: 2.3707391958442523
Epoch: 9| Step: 9
Training loss: 2.743701934814453
Validation loss: 2.3665242846921193
Epoch: 9| Step: 10
Training loss: 3.1818618774414062
Validation loss: 2.3683420668403024
Epoch: 9| Step: 11
Training loss: 2.6605868339538574
Validation loss: 2.3678295492268293
Epoch: 9| Step: 12
Training loss: 2.863586902618408
Validation loss: 2.3662934697789253
Epoch: 9| Step: 13
Training loss: 3.4394407272338867
Validation loss: 2.366324393869304
Epoch: 9| Step: 14
Training loss: 3.811807632446289
Validation loss: 2.3634682807990974
Epoch: 9| Step: 15
Training loss: 2.034179210662842
Validation loss: 2.3652635546896956
Epoch: 9| Step: 16
Training loss: 2.319342613220215
Validation loss: 2.364991059406198
Epoch: 9| Step: 17
Training loss: 2.86083722114563
Validation loss: 2.3682364920060412
Epoch: 9| Step: 18
Training loss: 2.5355637073516846
Validation loss: 2.3653030438388853
Epoch: 9| Step: 19
Training loss: 3.924832344055176
Validation loss: 2.365641985008185
Epoch: 98| Step: 0
Training loss: 3.7466158866882324
Validation loss: 2.3680813175311193
Epoch: 9| Step: 1
Training loss: 3.6897308826446533
Validation loss: 2.3648062129672485
Epoch: 9| Step: 2
Training loss: 3.393033504486084
Validation loss: 2.3649168786385077
Epoch: 9| Step: 3
Training loss: 3.231786012649536
Validation loss: 2.366773653373444
Epoch: 9| Step: 4
Training loss: 2.992844820022583
Validation loss: 2.3651720860021577
Epoch: 9| Step: 5
Training loss: 2.3537368774414062
Validation loss: 2.3644050419759406
Epoch: 9| Step: 6
Training loss: 2.5101211071014404
Validation loss: 2.3661530129343484
Epoch: 9| Step: 7
Training loss: 2.971627712249756
Validation loss: 2.364548419019301
Epoch: 9| Step: 8
Training loss: 3.0008246898651123
Validation loss: 2.3630355193460586
Epoch: 9| Step: 9
Training loss: 3.0700314044952393
Validation loss: 2.363607911754855
Epoch: 9| Step: 10
Training loss: 2.7685532569885254
Validation loss: 2.3656864389241172
Epoch: 9| Step: 11
Training loss: 2.064155101776123
Validation loss: 2.3645129941350262
Epoch: 9| Step: 12
Training loss: 2.467888355255127
Validation loss: 2.3632713341884477
Epoch: 9| Step: 13
Training loss: 3.004401683807373
Validation loss: 2.3643332316721084
Epoch: 9| Step: 14
Training loss: 2.7415714263916016
Validation loss: 2.3639444927517457
Epoch: 9| Step: 15
Training loss: 2.6486611366271973
Validation loss: 2.3630837639458746
Epoch: 9| Step: 16
Training loss: 1.9964923858642578
Validation loss: 2.363297019931052
Epoch: 9| Step: 17
Training loss: 2.5407652854919434
Validation loss: 2.3640443335334176
Epoch: 9| Step: 18
Training loss: 3.6927943229675293
Validation loss: 2.3633194775890103
Epoch: 9| Step: 19
Training loss: 2.9573705196380615
Validation loss: 2.363776404222996
Epoch: 99| Step: 0
Training loss: 2.9616661071777344
Validation loss: 2.3657832008471593
Epoch: 9| Step: 1
Training loss: 2.8388078212738037
Validation loss: 2.362827266720559
Epoch: 9| Step: 2
Training loss: 2.9619574546813965
Validation loss: 2.36354524969197
Epoch: 9| Step: 3
Training loss: 3.0580859184265137
Validation loss: 2.362724662684708
Epoch: 9| Step: 4
Training loss: 3.271048069000244
Validation loss: 2.364212065291919
Epoch: 9| Step: 5
Training loss: 2.3802216053009033
Validation loss: 2.3615920423603742
Epoch: 9| Step: 6
Training loss: 4.193588733673096
Validation loss: 2.364724510865246
Epoch: 9| Step: 7
Training loss: 2.6670618057250977
Validation loss: 2.3632102835950235
Epoch: 9| Step: 8
Training loss: 2.3951659202575684
Validation loss: 2.362632495036228
Epoch: 9| Step: 9
Training loss: 2.668588638305664
Validation loss: 2.3620454544643703
Epoch: 9| Step: 10
Training loss: 2.6014866828918457
Validation loss: 2.3626102372039135
Epoch: 9| Step: 11
Training loss: 2.6762855052948
Validation loss: 2.363118060201192
Epoch: 9| Step: 12
Training loss: 2.6309242248535156
Validation loss: 2.362952741787588
Epoch: 9| Step: 13
Training loss: 3.1511614322662354
Validation loss: 2.3623396235404255
Epoch: 9| Step: 14
Training loss: 2.6862423419952393
Validation loss: 2.361890264552274
Epoch: 9| Step: 15
Training loss: 3.1998300552368164
Validation loss: 2.3630574126895385
Epoch: 9| Step: 16
Training loss: 2.768547534942627
Validation loss: 2.362945119254023
Epoch: 9| Step: 17
Training loss: 3.058793306350708
Validation loss: 2.361283340042444
Epoch: 9| Step: 18
Training loss: 3.26790189743042
Validation loss: 2.361662413576524
Epoch: 9| Step: 19
Training loss: 2.3645386695861816
Validation loss: 2.3613432980269837
Epoch: 100| Step: 0
Training loss: 2.408662796020508
Validation loss: 2.360170139683236
Epoch: 9| Step: 1
Training loss: 2.0460681915283203
Validation loss: 2.3615242714504543
Epoch: 9| Step: 2
Training loss: 2.849294662475586
Validation loss: 2.359756334222478
Epoch: 9| Step: 3
Training loss: 2.50917911529541
Validation loss: 2.358464686990642
Epoch: 9| Step: 4
Training loss: 2.400069236755371
Validation loss: 2.358714750344805
Epoch: 9| Step: 5
Training loss: 3.2714200019836426
Validation loss: 2.359547565309264
Epoch: 9| Step: 6
Training loss: 3.268697738647461
Validation loss: 2.359650719937661
Epoch: 9| Step: 7
Training loss: 2.9222893714904785
Validation loss: 2.3599567267534542
Epoch: 9| Step: 8
Training loss: 2.524649143218994
Validation loss: 2.361195246950328
Epoch: 9| Step: 9
Training loss: 2.410081386566162
Validation loss: 2.359953882882921
Epoch: 9| Step: 10
Training loss: 3.168515920639038
Validation loss: 2.358036827698028
Epoch: 9| Step: 11
Training loss: 2.7775630950927734
Validation loss: 2.3608368540839324
Epoch: 9| Step: 12
Training loss: 2.519230365753174
Validation loss: 2.36035959326106
Epoch: 9| Step: 13
Training loss: 3.3455543518066406
Validation loss: 2.3602079195941954
Epoch: 9| Step: 14
Training loss: 2.6944406032562256
Validation loss: 2.3586121343022626
Epoch: 9| Step: 15
Training loss: 3.7422144412994385
Validation loss: 2.3589408003169
Epoch: 9| Step: 16
Training loss: 2.677340507507324
Validation loss: 2.3620412847120984
Epoch: 9| Step: 17
Training loss: 2.417379379272461
Validation loss: 2.3588705165780706
Epoch: 9| Step: 18
Training loss: 3.9570186138153076
Validation loss: 2.358804526088907
Epoch: 9| Step: 19
Training loss: 3.8235292434692383
Validation loss: 2.3603130004388824
Epoch: 101| Step: 0
Training loss: 2.676208019256592
Validation loss: 2.361894365694883
Epoch: 9| Step: 1
Training loss: 3.1285581588745117
Validation loss: 2.360293131080463
Epoch: 9| Step: 2
Training loss: 2.7511308193206787
Validation loss: 2.358052843766247
Epoch: 9| Step: 3
Training loss: 2.6422619819641113
Validation loss: 2.361415749831165
Epoch: 9| Step: 4
Training loss: 3.1995882987976074
Validation loss: 2.3586107706852095
Epoch: 9| Step: 5
Training loss: 2.6527745723724365
Validation loss: 2.358164789865343
Epoch: 9| Step: 6
Training loss: 2.5585525035858154
Validation loss: 2.3583455771851023
Epoch: 9| Step: 7
Training loss: 2.9538915157318115
Validation loss: 2.3565851595761966
Epoch: 9| Step: 8
Training loss: 3.2226767539978027
Validation loss: 2.3574517056238737
Epoch: 9| Step: 9
Training loss: 3.1585984230041504
Validation loss: 2.3605003305476346
Epoch: 9| Step: 10
Training loss: 2.372239351272583
Validation loss: 2.358598669655889
Epoch: 9| Step: 11
Training loss: 3.10725998878479
Validation loss: 2.3591738313222104
Epoch: 9| Step: 12
Training loss: 3.4562416076660156
Validation loss: 2.3574146263890987
Epoch: 9| Step: 13
Training loss: 1.9950405359268188
Validation loss: 2.352181757096764
Epoch: 9| Step: 14
Training loss: 2.3317480087280273
Validation loss: 2.360017698445766
Epoch: 9| Step: 15
Training loss: 2.5751194953918457
Validation loss: 2.3583952866012243
Epoch: 9| Step: 16
Training loss: 3.2930643558502197
Validation loss: 2.3561352568564655
Epoch: 9| Step: 17
Training loss: 2.8885421752929688
Validation loss: 2.3571761169021936
Epoch: 9| Step: 18
Training loss: 2.818798780441284
Validation loss: 2.3569609115449643
Epoch: 9| Step: 19
Training loss: 3.862367868423462
Validation loss: 2.3564495285637945
Epoch: 102| Step: 0
Training loss: 3.2000575065612793
Validation loss: 2.3576494206627494
Epoch: 9| Step: 1
Training loss: 2.7097413539886475
Validation loss: 2.3546206676702703
Epoch: 9| Step: 2
Training loss: 3.33709979057312
Validation loss: 2.356876229210723
Epoch: 9| Step: 3
Training loss: 3.653903007507324
Validation loss: 2.356397798593096
Epoch: 9| Step: 4
Training loss: 2.9303126335144043
Validation loss: 2.355131584105732
Epoch: 9| Step: 5
Training loss: 3.1761298179626465
Validation loss: 2.3534172936309155
Epoch: 9| Step: 6
Training loss: 2.5643413066864014
Validation loss: 2.351933878960369
Epoch: 9| Step: 7
Training loss: 2.3865737915039062
Validation loss: 2.351824154956735
Epoch: 9| Step: 8
Training loss: 2.7538061141967773
Validation loss: 2.3506744971378244
Epoch: 9| Step: 9
Training loss: 2.552907943725586
Validation loss: 2.3532936041303674
Epoch: 9| Step: 10
Training loss: 3.680185317993164
Validation loss: 2.352952687860393
Epoch: 9| Step: 11
Training loss: 3.206578493118286
Validation loss: 2.355085120784293
Epoch: 9| Step: 12
Training loss: 2.91367769241333
Validation loss: 2.3565691752399474
Epoch: 9| Step: 13
Training loss: 3.3169243335723877
Validation loss: 2.35445442817194
Epoch: 9| Step: 14
Training loss: 2.8280117511749268
Validation loss: 2.353057209536326
Epoch: 9| Step: 15
Training loss: 2.6661605834960938
Validation loss: 2.3515736936665266
Epoch: 9| Step: 16
Training loss: 2.2396347522735596
Validation loss: 2.349661151282221
Epoch: 9| Step: 17
Training loss: 2.8663077354431152
Validation loss: 2.350030447939317
Epoch: 9| Step: 18
Training loss: 2.3564066886901855
Validation loss: 2.351262486238274
Epoch: 9| Step: 19
Training loss: 2.236849308013916
Validation loss: 2.351407605109455
Epoch: 103| Step: 0
Training loss: 2.9881157875061035
Validation loss: 2.3494317102775297
Epoch: 9| Step: 1
Training loss: 2.725917339324951
Validation loss: 2.3505359296318438
Epoch: 9| Step: 2
Training loss: 2.748074769973755
Validation loss: 2.350874367377741
Epoch: 9| Step: 3
Training loss: 2.5641679763793945
Validation loss: 2.350661439003704
Epoch: 9| Step: 4
Training loss: 3.4338388442993164
Validation loss: 2.3485396028422625
Epoch: 9| Step: 5
Training loss: 3.4794764518737793
Validation loss: 2.3529716069749793
Epoch: 9| Step: 6
Training loss: 2.077232837677002
Validation loss: 2.350684865773153
Epoch: 9| Step: 7
Training loss: 3.1470284461975098
Validation loss: 2.3510541898741137
Epoch: 9| Step: 8
Training loss: 3.225715160369873
Validation loss: 2.352643525000099
Epoch: 9| Step: 9
Training loss: 2.82265043258667
Validation loss: 2.347795495026403
Epoch: 9| Step: 10
Training loss: 2.606106996536255
Validation loss: 2.3481331746355236
Epoch: 9| Step: 11
Training loss: 2.6769299507141113
Validation loss: 2.349702046071883
Epoch: 9| Step: 12
Training loss: 2.9444403648376465
Validation loss: 2.3481601948360744
Epoch: 9| Step: 13
Training loss: 3.5521793365478516
Validation loss: 2.3483573138285028
Epoch: 9| Step: 14
Training loss: 3.332832098007202
Validation loss: 2.348683213158477
Epoch: 9| Step: 15
Training loss: 3.055028200149536
Validation loss: 2.3469892440082356
Epoch: 9| Step: 16
Training loss: 2.7244348526000977
Validation loss: 2.345903641885991
Epoch: 9| Step: 17
Training loss: 2.156157970428467
Validation loss: 2.3464876010263565
Epoch: 9| Step: 18
Training loss: 2.7071032524108887
Validation loss: 2.348869261981772
Epoch: 9| Step: 19
Training loss: 2.513779640197754
Validation loss: 2.3472334017856515
Epoch: 104| Step: 0
Training loss: 2.730525493621826
Validation loss: 2.3476843885380587
Epoch: 9| Step: 1
Training loss: 2.8840718269348145
Validation loss: 2.347327539389082
Epoch: 9| Step: 2
Training loss: 2.9050490856170654
Validation loss: 2.3457292284039286
Epoch: 9| Step: 3
Training loss: 3.193410873413086
Validation loss: 2.3472453655956462
Epoch: 9| Step: 4
Training loss: 3.9994730949401855
Validation loss: 2.347914999337505
Epoch: 9| Step: 5
Training loss: 3.0778236389160156
Validation loss: 2.34539342269623
Epoch: 9| Step: 6
Training loss: 3.0241734981536865
Validation loss: 2.3458496700945517
Epoch: 9| Step: 7
Training loss: 2.01944637298584
Validation loss: 2.3444875161424816
Epoch: 9| Step: 8
Training loss: 2.868320941925049
Validation loss: 2.3455494136261423
Epoch: 9| Step: 9
Training loss: 2.5638375282287598
Validation loss: 2.3440381554390886
Epoch: 9| Step: 10
Training loss: 2.235391616821289
Validation loss: 2.343576127676655
Epoch: 9| Step: 11
Training loss: 2.382007598876953
Validation loss: 2.3446422720984588
Epoch: 9| Step: 12
Training loss: 3.2301955223083496
Validation loss: 2.345198217913401
Epoch: 9| Step: 13
Training loss: 3.410184860229492
Validation loss: 2.3453965821712135
Epoch: 9| Step: 14
Training loss: 2.279489040374756
Validation loss: 2.34481390946203
Epoch: 9| Step: 15
Training loss: 2.7499489784240723
Validation loss: 2.344372859104074
Epoch: 9| Step: 16
Training loss: 2.6617753505706787
Validation loss: 2.343267252976946
Epoch: 9| Step: 17
Training loss: 2.6855273246765137
Validation loss: 2.3436029351872505
Epoch: 9| Step: 18
Training loss: 3.5184149742126465
Validation loss: 2.343106657481022
Epoch: 9| Step: 19
Training loss: 3.012782096862793
Validation loss: 2.3449356264347654
Epoch: 105| Step: 0
Training loss: 2.5605502128601074
Validation loss: 2.344317588874762
Epoch: 9| Step: 1
Training loss: 2.9842641353607178
Validation loss: 2.3454535230458213
Epoch: 9| Step: 2
Training loss: 3.666811466217041
Validation loss: 2.3449855528289465
Epoch: 9| Step: 3
Training loss: 2.5375213623046875
Validation loss: 2.345061911953439
Epoch: 9| Step: 4
Training loss: 2.600213050842285
Validation loss: 2.348981711504271
Epoch: 9| Step: 5
Training loss: 2.739266872406006
Validation loss: 2.349618295971438
Epoch: 9| Step: 6
Training loss: 2.157996654510498
Validation loss: 2.3490009925348296
Epoch: 9| Step: 7
Training loss: 2.98500394821167
Validation loss: 2.3447012361005055
Epoch: 9| Step: 8
Training loss: 3.849520206451416
Validation loss: 2.354700301190932
Epoch: 9| Step: 9
Training loss: 2.4046525955200195
Validation loss: 2.353745164631082
Epoch: 9| Step: 10
Training loss: 2.802309989929199
Validation loss: 2.347592489324885
Epoch: 9| Step: 11
Training loss: 2.7480950355529785
Validation loss: 2.3438975416499077
Epoch: 9| Step: 12
Training loss: 2.428830623626709
Validation loss: 2.345097505789009
Epoch: 9| Step: 13
Training loss: 3.1503641605377197
Validation loss: 2.343675978749776
Epoch: 9| Step: 14
Training loss: 3.000608205795288
Validation loss: 2.3440591774398474
Epoch: 9| Step: 15
Training loss: 3.028367757797241
Validation loss: 2.3414830140930287
Epoch: 9| Step: 16
Training loss: 3.046872138977051
Validation loss: 2.34369782235125
Epoch: 9| Step: 17
Training loss: 2.63671612739563
Validation loss: 2.3454075940221335
Epoch: 9| Step: 18
Training loss: 2.7712268829345703
Validation loss: 2.3438316163399238
Epoch: 9| Step: 19
Training loss: 3.352938175201416
Validation loss: 2.3458642436446047
Epoch: 106| Step: 0
Training loss: 3.530667543411255
Validation loss: 2.3445545289156247
Epoch: 9| Step: 1
Training loss: 3.0221567153930664
Validation loss: 2.3443103128199954
Epoch: 9| Step: 2
Training loss: 2.6033852100372314
Validation loss: 2.3444807357925304
Epoch: 9| Step: 3
Training loss: 3.3839075565338135
Validation loss: 2.341279297423877
Epoch: 9| Step: 4
Training loss: 3.3402211666107178
Validation loss: 2.3425632492243813
Epoch: 9| Step: 5
Training loss: 2.9240026473999023
Validation loss: 2.3411397350777823
Epoch: 9| Step: 6
Training loss: 2.0153861045837402
Validation loss: 2.3403295201363323
Epoch: 9| Step: 7
Training loss: 2.431020498275757
Validation loss: 2.341592291276232
Epoch: 9| Step: 8
Training loss: 2.5726470947265625
Validation loss: 2.3397044740992485
Epoch: 9| Step: 9
Training loss: 3.5618209838867188
Validation loss: 2.3410917632013772
Epoch: 9| Step: 10
Training loss: 3.2291507720947266
Validation loss: 2.338913397823306
Epoch: 9| Step: 11
Training loss: 3.2552425861358643
Validation loss: 2.3390216518649094
Epoch: 9| Step: 12
Training loss: 2.747368812561035
Validation loss: 2.338697193337859
Epoch: 9| Step: 13
Training loss: 2.755638837814331
Validation loss: 2.340926178925329
Epoch: 9| Step: 14
Training loss: 2.4683988094329834
Validation loss: 2.3446390174275678
Epoch: 9| Step: 15
Training loss: 2.92232084274292
Validation loss: 2.3405350043619277
Epoch: 9| Step: 16
Training loss: 2.8671131134033203
Validation loss: 2.3401219038654575
Epoch: 9| Step: 17
Training loss: 2.3276004791259766
Validation loss: 2.34249603147987
Epoch: 9| Step: 18
Training loss: 2.1851658821105957
Validation loss: 2.3429639699647753
Epoch: 9| Step: 19
Training loss: 3.2277841567993164
Validation loss: 2.3425096110474293
Epoch: 107| Step: 0
Training loss: 2.908691167831421
Validation loss: 2.3413781845312323
Epoch: 9| Step: 1
Training loss: 2.4917831420898438
Validation loss: 2.3376165516942526
Epoch: 9| Step: 2
Training loss: 2.6275744438171387
Validation loss: 2.3416303936526073
Epoch: 9| Step: 3
Training loss: 2.732010841369629
Validation loss: 2.3416900223107646
Epoch: 9| Step: 4
Training loss: 3.696507692337036
Validation loss: 2.3427859193129503
Epoch: 9| Step: 5
Training loss: 2.23083758354187
Validation loss: 2.3395113499044515
Epoch: 9| Step: 6
Training loss: 3.521904706954956
Validation loss: 2.3398223866661674
Epoch: 9| Step: 7
Training loss: 2.6255030632019043
Validation loss: 2.3383269327149976
Epoch: 9| Step: 8
Training loss: 2.7210543155670166
Validation loss: 2.3417186188183243
Epoch: 9| Step: 9
Training loss: 3.0074195861816406
Validation loss: 2.341131218903356
Epoch: 9| Step: 10
Training loss: 2.535781145095825
Validation loss: 2.3400558361904227
Epoch: 9| Step: 11
Training loss: 2.7748830318450928
Validation loss: 2.3376456156051417
Epoch: 9| Step: 12
Training loss: 3.3609769344329834
Validation loss: 2.3392959052710225
Epoch: 9| Step: 13
Training loss: 2.133420944213867
Validation loss: 2.3375611734047212
Epoch: 9| Step: 14
Training loss: 2.259758949279785
Validation loss: 2.3412328795563404
Epoch: 9| Step: 15
Training loss: 2.719513177871704
Validation loss: 2.339519039332438
Epoch: 9| Step: 16
Training loss: 3.1072254180908203
Validation loss: 2.3392601450570196
Epoch: 9| Step: 17
Training loss: 3.272282600402832
Validation loss: 2.33923706562399
Epoch: 9| Step: 18
Training loss: 3.5140931606292725
Validation loss: 2.3380584193648195
Epoch: 9| Step: 19
Training loss: 3.0778355598449707
Validation loss: 2.3372435895659085
Epoch: 108| Step: 0
Training loss: 2.8448398113250732
Validation loss: 2.3382718974737813
Epoch: 9| Step: 1
Training loss: 2.170567512512207
Validation loss: 2.333151062615484
Epoch: 9| Step: 2
Training loss: 2.38393235206604
Validation loss: 2.3379495040975886
Epoch: 9| Step: 3
Training loss: 3.881840944290161
Validation loss: 2.3398921935678385
Epoch: 9| Step: 4
Training loss: 3.340925455093384
Validation loss: 2.336271409508136
Epoch: 9| Step: 5
Training loss: 3.395822048187256
Validation loss: 2.33773633387449
Epoch: 9| Step: 6
Training loss: 3.412714958190918
Validation loss: 2.3377030084459043
Epoch: 9| Step: 7
Training loss: 2.7591805458068848
Validation loss: 2.337551550899478
Epoch: 9| Step: 8
Training loss: 2.5975852012634277
Validation loss: 2.3384904003829408
Epoch: 9| Step: 9
Training loss: 2.9940707683563232
Validation loss: 2.3403638404050318
Epoch: 9| Step: 10
Training loss: 2.7793917655944824
Validation loss: 2.3415099133690482
Epoch: 9| Step: 11
Training loss: 3.217454195022583
Validation loss: 2.3357883606025642
Epoch: 9| Step: 12
Training loss: 2.3875300884246826
Validation loss: 2.3360371298069578
Epoch: 9| Step: 13
Training loss: 2.6346747875213623
Validation loss: 2.3382919709459484
Epoch: 9| Step: 14
Training loss: 2.5172119140625
Validation loss: 2.3377964393698054
Epoch: 9| Step: 15
Training loss: 3.5096242427825928
Validation loss: 2.3374170845361064
Epoch: 9| Step: 16
Training loss: 2.6797189712524414
Validation loss: 2.3376236476486536
Epoch: 9| Step: 17
Training loss: 2.5724992752075195
Validation loss: 2.336447360704271
Epoch: 9| Step: 18
Training loss: 2.8834855556488037
Validation loss: 2.3365202704779535
Epoch: 9| Step: 19
Training loss: 2.3235225677490234
Validation loss: 2.3350808346014227
Epoch: 109| Step: 0
Training loss: 2.044849395751953
Validation loss: 2.3356342212759333
Epoch: 9| Step: 1
Training loss: 3.45953631401062
Validation loss: 2.334772756631426
Epoch: 9| Step: 2
Training loss: 2.7338573932647705
Validation loss: 2.3378121046711215
Epoch: 9| Step: 3
Training loss: 2.114819049835205
Validation loss: 2.3348980550285723
Epoch: 9| Step: 4
Training loss: 3.3636481761932373
Validation loss: 2.3366924704407617
Epoch: 9| Step: 5
Training loss: 3.3297929763793945
Validation loss: 2.3362975892403144
Epoch: 9| Step: 6
Training loss: 3.470475673675537
Validation loss: 2.3364656074441594
Epoch: 9| Step: 7
Training loss: 2.8852357864379883
Validation loss: 2.335769780248189
Epoch: 9| Step: 8
Training loss: 3.841545343399048
Validation loss: 2.3347179486597183
Epoch: 9| Step: 9
Training loss: 2.93133807182312
Validation loss: 2.3375479694750667
Epoch: 9| Step: 10
Training loss: 2.6345181465148926
Validation loss: 2.3376449972605533
Epoch: 9| Step: 11
Training loss: 2.35087251663208
Validation loss: 2.3357202560781576
Epoch: 9| Step: 12
Training loss: 3.1873927116394043
Validation loss: 2.333400978458871
Epoch: 9| Step: 13
Training loss: 2.9351799488067627
Validation loss: 2.336940556979008
Epoch: 9| Step: 14
Training loss: 2.9063539505004883
Validation loss: 2.3355182349253045
Epoch: 9| Step: 15
Training loss: 2.6751649379730225
Validation loss: 2.336347513061633
Epoch: 9| Step: 16
Training loss: 2.6356120109558105
Validation loss: 2.3345521353989196
Epoch: 9| Step: 17
Training loss: 2.5775210857391357
Validation loss: 2.33455990544326
Epoch: 9| Step: 18
Training loss: 3.107081413269043
Validation loss: 2.3345142662953986
Epoch: 9| Step: 19
Training loss: 2.0671722888946533
Validation loss: 2.336349917830323
Epoch: 110| Step: 0
Training loss: 2.5738377571105957
Validation loss: 2.3370553478062583
Epoch: 9| Step: 1
Training loss: 2.567119598388672
Validation loss: 2.3361269655845147
Epoch: 9| Step: 2
Training loss: 3.39506196975708
Validation loss: 2.3363942533945865
Epoch: 9| Step: 3
Training loss: 2.9773292541503906
Validation loss: 2.33184098425529
Epoch: 9| Step: 4
Training loss: 3.9819459915161133
Validation loss: 2.336880824548735
Epoch: 9| Step: 5
Training loss: 2.839482307434082
Validation loss: 2.33450266783186
Epoch: 9| Step: 6
Training loss: 2.8353729248046875
Validation loss: 2.335015778918918
Epoch: 9| Step: 7
Training loss: 3.1714043617248535
Validation loss: 2.3325598394270424
Epoch: 9| Step: 8
Training loss: 2.935652732849121
Validation loss: 2.3345259410871875
Epoch: 9| Step: 9
Training loss: 3.3053269386291504
Validation loss: 2.3347122583457893
Epoch: 9| Step: 10
Training loss: 2.216492176055908
Validation loss: 2.3351003763487013
Epoch: 9| Step: 11
Training loss: 2.9083566665649414
Validation loss: 2.33604183299936
Epoch: 9| Step: 12
Training loss: 3.0261197090148926
Validation loss: 2.3328080022935387
Epoch: 9| Step: 13
Training loss: 1.638612151145935
Validation loss: 2.3321170223702627
Epoch: 9| Step: 14
Training loss: 3.2607507705688477
Validation loss: 2.3332065609719255
Epoch: 9| Step: 15
Training loss: 2.161414623260498
Validation loss: 2.3330250866979148
Epoch: 9| Step: 16
Training loss: 2.5354256629943848
Validation loss: 2.332574655683778
Epoch: 9| Step: 17
Training loss: 3.4134931564331055
Validation loss: 2.337157676545836
Epoch: 9| Step: 18
Training loss: 3.1778457164764404
Validation loss: 2.333330459731946
Epoch: 9| Step: 19
Training loss: 2.267094135284424
Validation loss: 2.335097074508667
Epoch: 111| Step: 0
Training loss: 3.1955466270446777
Validation loss: 2.332161472855712
Epoch: 9| Step: 1
Training loss: 2.333263397216797
Validation loss: 2.335191592895727
Epoch: 9| Step: 2
Training loss: 3.074620246887207
Validation loss: 2.3344474747884187
Epoch: 9| Step: 3
Training loss: 2.9758167266845703
Validation loss: 2.3326324833382803
Epoch: 9| Step: 4
Training loss: 2.7642269134521484
Validation loss: 2.333584432979282
Epoch: 9| Step: 5
Training loss: 2.490295171737671
Validation loss: 2.3325893218568763
Epoch: 9| Step: 6
Training loss: 3.099461793899536
Validation loss: 2.3335915143541297
Epoch: 9| Step: 7
Training loss: 3.157946825027466
Validation loss: 2.3330482853402335
Epoch: 9| Step: 8
Training loss: 3.5389814376831055
Validation loss: 2.3340660976849015
Epoch: 9| Step: 9
Training loss: 3.0307509899139404
Validation loss: 2.3332402508893457
Epoch: 9| Step: 10
Training loss: 2.718451499938965
Validation loss: 2.332761850288446
Epoch: 9| Step: 11
Training loss: 2.654866933822632
Validation loss: 2.332017421722412
Epoch: 9| Step: 12
Training loss: 2.5782008171081543
Validation loss: 2.334261515157686
Epoch: 9| Step: 13
Training loss: 2.7590415477752686
Validation loss: 2.332860797429256
Epoch: 9| Step: 14
Training loss: 2.3138914108276367
Validation loss: 2.332046200045579
Epoch: 9| Step: 15
Training loss: 2.1444294452667236
Validation loss: 2.333403443261016
Epoch: 9| Step: 16
Training loss: 3.3693485260009766
Validation loss: 2.3348011618895494
Epoch: 9| Step: 17
Training loss: 2.9242725372314453
Validation loss: 2.3324956156367023
Epoch: 9| Step: 18
Training loss: 2.9490928649902344
Validation loss: 2.330312866101162
Epoch: 9| Step: 19
Training loss: 3.1285042762756348
Validation loss: 2.3321433418946302
Epoch: 112| Step: 0
Training loss: 1.9049491882324219
Validation loss: 2.3308779387165317
Epoch: 9| Step: 1
Training loss: 2.5870585441589355
Validation loss: 2.331113237271206
Epoch: 9| Step: 2
Training loss: 1.9964241981506348
Validation loss: 2.334498705623819
Epoch: 9| Step: 3
Training loss: 3.183854579925537
Validation loss: 2.3350605570155083
Epoch: 9| Step: 4
Training loss: 2.7693707942962646
Validation loss: 2.3306929138924577
Epoch: 9| Step: 5
Training loss: 3.544865131378174
Validation loss: 2.3369375767467693
Epoch: 9| Step: 6
Training loss: 2.5735225677490234
Validation loss: 2.3410923703968956
Epoch: 9| Step: 7
Training loss: 2.4476258754730225
Validation loss: 2.3355866816404056
Epoch: 9| Step: 8
Training loss: 3.5097708702087402
Validation loss: 2.343028502498599
Epoch: 9| Step: 9
Training loss: 3.168696880340576
Validation loss: 2.343338860024651
Epoch: 9| Step: 10
Training loss: 2.5835301876068115
Validation loss: 2.340757038953493
Epoch: 9| Step: 11
Training loss: 2.86550235748291
Validation loss: 2.3399864255095557
Epoch: 9| Step: 12
Training loss: 3.3853118419647217
Validation loss: 2.3371654311530023
Epoch: 9| Step: 13
Training loss: 2.491100549697876
Validation loss: 2.3313102173290665
Epoch: 9| Step: 14
Training loss: 3.3404922485351562
Validation loss: 2.3325070288541507
Epoch: 9| Step: 15
Training loss: 2.640188217163086
Validation loss: 2.3340440431087135
Epoch: 9| Step: 16
Training loss: 3.328887462615967
Validation loss: 2.331431806516304
Epoch: 9| Step: 17
Training loss: 3.229902744293213
Validation loss: 2.329675163296487
Epoch: 9| Step: 18
Training loss: 3.067575216293335
Validation loss: 2.330338331435224
Epoch: 9| Step: 19
Training loss: 2.5653738975524902
Validation loss: 2.331169341107924
Epoch: 113| Step: 0
Training loss: 1.7443833351135254
Validation loss: 2.330208491936004
Epoch: 9| Step: 1
Training loss: 2.122422456741333
Validation loss: 2.3331292293054595
Epoch: 9| Step: 2
Training loss: 3.0112416744232178
Validation loss: 2.333672941159859
Epoch: 9| Step: 3
Training loss: 3.3864150047302246
Validation loss: 2.333382528462856
Epoch: 9| Step: 4
Training loss: 3.27237868309021
Validation loss: 2.334377453481551
Epoch: 9| Step: 5
Training loss: 3.203402519226074
Validation loss: 2.3309589598676284
Epoch: 9| Step: 6
Training loss: 2.682142496109009
Validation loss: 2.333773153291332
Epoch: 9| Step: 7
Training loss: 2.027575731277466
Validation loss: 2.330199208190973
Epoch: 9| Step: 8
Training loss: 2.9118237495422363
Validation loss: 2.329512786522186
Epoch: 9| Step: 9
Training loss: 3.3058648109436035
Validation loss: 2.330866112125863
Epoch: 9| Step: 10
Training loss: 3.471515417098999
Validation loss: 2.3303947122834567
Epoch: 9| Step: 11
Training loss: 3.9577717781066895
Validation loss: 2.3298030911589698
Epoch: 9| Step: 12
Training loss: 2.3221867084503174
Validation loss: 2.331185658201039
Epoch: 9| Step: 13
Training loss: 2.4163553714752197
Validation loss: 2.329081687995856
Epoch: 9| Step: 14
Training loss: 3.1306393146514893
Validation loss: 2.3297636080131254
Epoch: 9| Step: 15
Training loss: 2.2741518020629883
Validation loss: 2.330328539978686
Epoch: 9| Step: 16
Training loss: 2.46907901763916
Validation loss: 2.3306633328362336
Epoch: 9| Step: 17
Training loss: 2.9880380630493164
Validation loss: 2.3284426541637173
Epoch: 9| Step: 18
Training loss: 2.7918591499328613
Validation loss: 2.329586878097315
Epoch: 9| Step: 19
Training loss: 3.656230926513672
Validation loss: 2.3287343001194136
Epoch: 114| Step: 0
Training loss: 1.8873510360717773
Validation loss: 2.3291433080494834
Epoch: 9| Step: 1
Training loss: 2.16050386428833
Validation loss: 2.331738775582622
Epoch: 9| Step: 2
Training loss: 2.763998031616211
Validation loss: 2.330036791966116
Epoch: 9| Step: 3
Training loss: 2.6097311973571777
Validation loss: 2.3340991941287363
Epoch: 9| Step: 4
Training loss: 2.748671531677246
Validation loss: 2.3312609778891367
Epoch: 9| Step: 5
Training loss: 3.0014288425445557
Validation loss: 2.3302207499099294
Epoch: 9| Step: 6
Training loss: 2.3233399391174316
Validation loss: 2.3301533829394003
Epoch: 9| Step: 7
Training loss: 3.0886340141296387
Validation loss: 2.3319134883743398
Epoch: 9| Step: 8
Training loss: 2.7826457023620605
Validation loss: 2.3305498833278957
Epoch: 9| Step: 9
Training loss: 2.92668080329895
Validation loss: 2.3315819441843377
Epoch: 9| Step: 10
Training loss: 3.5597801208496094
Validation loss: 2.329212857664918
Epoch: 9| Step: 11
Training loss: 2.5757055282592773
Validation loss: 2.328521404334967
Epoch: 9| Step: 12
Training loss: 3.270662784576416
Validation loss: 2.327872087629579
Epoch: 9| Step: 13
Training loss: 2.374511241912842
Validation loss: 2.3280695822599125
Epoch: 9| Step: 14
Training loss: 2.998465061187744
Validation loss: 2.3264361628525547
Epoch: 9| Step: 15
Training loss: 3.61993408203125
Validation loss: 2.329894311136479
Epoch: 9| Step: 16
Training loss: 2.7941789627075195
Validation loss: 2.3294774782743386
Epoch: 9| Step: 17
Training loss: 3.9073734283447266
Validation loss: 2.3286032110667056
Epoch: 9| Step: 18
Training loss: 2.759117603302002
Validation loss: 2.330027226921466
Epoch: 9| Step: 19
Training loss: 2.8925957679748535
Validation loss: 2.3283424171612417
Epoch: 115| Step: 0
Training loss: 2.643939971923828
Validation loss: 2.329247014985668
Epoch: 9| Step: 1
Training loss: 3.04971981048584
Validation loss: 2.329699547170735
Epoch: 9| Step: 2
Training loss: 2.7592244148254395
Validation loss: 2.3273172515759364
Epoch: 9| Step: 3
Training loss: 2.630363702774048
Validation loss: 2.328026232959555
Epoch: 9| Step: 4
Training loss: 3.303098201751709
Validation loss: 2.3294756000848125
Epoch: 9| Step: 5
Training loss: 3.1162075996398926
Validation loss: 2.32604247031452
Epoch: 9| Step: 6
Training loss: 2.7333014011383057
Validation loss: 2.3298388676677675
Epoch: 9| Step: 7
Training loss: 2.375802993774414
Validation loss: 2.327277490560957
Epoch: 9| Step: 8
Training loss: 1.9216558933258057
Validation loss: 2.326970768489426
Epoch: 9| Step: 9
Training loss: 2.7824015617370605
Validation loss: 2.3272013664245605
Epoch: 9| Step: 10
Training loss: 2.301398992538452
Validation loss: 2.3283570190127807
Epoch: 9| Step: 11
Training loss: 3.586601972579956
Validation loss: 2.3270052594246624
Epoch: 9| Step: 12
Training loss: 3.453611373901367
Validation loss: 2.3271912705126425
Epoch: 9| Step: 13
Training loss: 3.3011362552642822
Validation loss: 2.3256930635987425
Epoch: 9| Step: 14
Training loss: 1.6581166982650757
Validation loss: 2.3273286270580704
Epoch: 9| Step: 15
Training loss: 2.8197522163391113
Validation loss: 2.3260854293974185
Epoch: 9| Step: 16
Training loss: 3.12457275390625
Validation loss: 2.3304510013662654
Epoch: 9| Step: 17
Training loss: 2.915414571762085
Validation loss: 2.3282534510111637
Epoch: 9| Step: 18
Training loss: 3.7216391563415527
Validation loss: 2.3271200159470813
Epoch: 9| Step: 19
Training loss: 2.8334734439849854
Validation loss: 2.3252961292541285
Epoch: 116| Step: 0
Training loss: 3.2644805908203125
Validation loss: 2.326814872755421
Epoch: 9| Step: 1
Training loss: 2.693751335144043
Validation loss: 2.3250562235605803
Epoch: 9| Step: 2
Training loss: 2.3186192512512207
Validation loss: 2.3282870182888113
Epoch: 9| Step: 3
Training loss: 2.789121627807617
Validation loss: 2.3254426940739585
Epoch: 9| Step: 4
Training loss: 2.970909595489502
Validation loss: 2.328265374512981
Epoch: 9| Step: 5
Training loss: 3.05511474609375
Validation loss: 2.327645773510281
Epoch: 9| Step: 6
Training loss: 2.629805564880371
Validation loss: 2.3263800178500387
Epoch: 9| Step: 7
Training loss: 2.7747278213500977
Validation loss: 2.327044008447112
Epoch: 9| Step: 8
Training loss: 3.0201048851013184
Validation loss: 2.326727102128722
Epoch: 9| Step: 9
Training loss: 2.4970550537109375
Validation loss: 2.325145611660086
Epoch: 9| Step: 10
Training loss: 2.869609832763672
Validation loss: 2.325573352601031
Epoch: 9| Step: 11
Training loss: 2.805938243865967
Validation loss: 2.326578889819358
Epoch: 9| Step: 12
Training loss: 2.635040760040283
Validation loss: 2.3274775065964075
Epoch: 9| Step: 13
Training loss: 3.31675386428833
Validation loss: 2.326100858853018
Epoch: 9| Step: 14
Training loss: 2.626654624938965
Validation loss: 2.327748988172133
Epoch: 9| Step: 15
Training loss: 2.8324313163757324
Validation loss: 2.3254880956608615
Epoch: 9| Step: 16
Training loss: 2.94942569732666
Validation loss: 2.3248471424733994
Epoch: 9| Step: 17
Training loss: 3.2493977546691895
Validation loss: 2.328555756335636
Epoch: 9| Step: 18
Training loss: 3.0735955238342285
Validation loss: 2.3270389450539786
Epoch: 9| Step: 19
Training loss: 2.654648542404175
Validation loss: 2.3265111412075785
Epoch: 117| Step: 0
Training loss: 2.439044952392578
Validation loss: 2.325467121686867
Epoch: 9| Step: 1
Training loss: 2.379938840866089
Validation loss: 2.3260427241702732
Epoch: 9| Step: 2
Training loss: 3.265928268432617
Validation loss: 2.326556788074027
Epoch: 9| Step: 3
Training loss: 2.7220425605773926
Validation loss: 2.325352296554785
Epoch: 9| Step: 4
Training loss: 2.6440160274505615
Validation loss: 2.3232385014458528
Epoch: 9| Step: 5
Training loss: 3.447486162185669
Validation loss: 2.324944376087875
Epoch: 9| Step: 6
Training loss: 2.802926540374756
Validation loss: 2.3256110047264924
Epoch: 9| Step: 7
Training loss: 3.2676498889923096
Validation loss: 2.324757136886926
Epoch: 9| Step: 8
Training loss: 2.825435161590576
Validation loss: 2.325209941795404
Epoch: 9| Step: 9
Training loss: 2.6509006023406982
Validation loss: 2.325082377564135
Epoch: 9| Step: 10
Training loss: 3.113276481628418
Validation loss: 2.326180363730561
Epoch: 9| Step: 11
Training loss: 3.2126312255859375
Validation loss: 2.3238772162430577
Epoch: 9| Step: 12
Training loss: 2.3186750411987305
Validation loss: 2.325782383088585
Epoch: 9| Step: 13
Training loss: 2.367588520050049
Validation loss: 2.3260955287398195
Epoch: 9| Step: 14
Training loss: 2.669546127319336
Validation loss: 2.322369280478937
Epoch: 9| Step: 15
Training loss: 2.121293544769287
Validation loss: 2.325776045270961
Epoch: 9| Step: 16
Training loss: 3.197063684463501
Validation loss: 2.3250419081543847
Epoch: 9| Step: 17
Training loss: 3.8659234046936035
Validation loss: 2.3237860614447285
Epoch: 9| Step: 18
Training loss: 2.9398531913757324
Validation loss: 2.322991817117595
Epoch: 9| Step: 19
Training loss: 2.7124953269958496
Validation loss: 2.325109051285888
Epoch: 118| Step: 0
Training loss: 2.899939775466919
Validation loss: 2.324970289957609
Epoch: 9| Step: 1
Training loss: 2.718649387359619
Validation loss: 2.32458869330317
Epoch: 9| Step: 2
Training loss: 2.5437536239624023
Validation loss: 2.322992553813852
Epoch: 9| Step: 3
Training loss: 3.3348426818847656
Validation loss: 2.325741390530154
Epoch: 9| Step: 4
Training loss: 2.9922423362731934
Validation loss: 2.326667952022964
Epoch: 9| Step: 5
Training loss: 3.1649816036224365
Validation loss: 2.3240788531817977
Epoch: 9| Step: 6
Training loss: 3.0350735187530518
Validation loss: 2.325268170816435
Epoch: 9| Step: 7
Training loss: 2.784109115600586
Validation loss: 2.325272500086174
Epoch: 9| Step: 8
Training loss: 2.697848320007324
Validation loss: 2.3235439576691004
Epoch: 9| Step: 9
Training loss: 2.5679373741149902
Validation loss: 2.3253731307365912
Epoch: 9| Step: 10
Training loss: 2.4650111198425293
Validation loss: 2.325582421940865
Epoch: 9| Step: 11
Training loss: 3.155674695968628
Validation loss: 2.323180017711447
Epoch: 9| Step: 12
Training loss: 2.985323667526245
Validation loss: 2.3248433963857966
Epoch: 9| Step: 13
Training loss: 2.9737820625305176
Validation loss: 2.324718944460368
Epoch: 9| Step: 14
Training loss: 2.8254623413085938
Validation loss: 2.322738537685477
Epoch: 9| Step: 15
Training loss: 1.969563603401184
Validation loss: 2.3235600234793243
Epoch: 9| Step: 16
Training loss: 3.3116941452026367
Validation loss: 2.3230397426824774
Epoch: 9| Step: 17
Training loss: 2.6007323265075684
Validation loss: 2.325098190376227
Epoch: 9| Step: 18
Training loss: 2.6751222610473633
Validation loss: 2.3226718285100922
Epoch: 9| Step: 19
Training loss: 3.2825493812561035
Validation loss: 2.3236679567707528
Epoch: 119| Step: 0
Training loss: 3.2776875495910645
Validation loss: 2.323168523020024
Epoch: 9| Step: 1
Training loss: 2.234921455383301
Validation loss: 2.324861926140545
Epoch: 9| Step: 2
Training loss: 2.8791463375091553
Validation loss: 2.325790974733641
Epoch: 9| Step: 3
Training loss: 2.9809396266937256
Validation loss: 2.3245829112238163
Epoch: 9| Step: 4
Training loss: 3.1365251541137695
Validation loss: 2.323873996734619
Epoch: 9| Step: 5
Training loss: 2.218658685684204
Validation loss: 2.3216424605829253
Epoch: 9| Step: 6
Training loss: 2.688135862350464
Validation loss: 2.320465602463098
Epoch: 9| Step: 7
Training loss: 2.392458915710449
Validation loss: 2.322202488672819
Epoch: 9| Step: 8
Training loss: 3.059065818786621
Validation loss: 2.3236957316775975
Epoch: 9| Step: 9
Training loss: 2.584879159927368
Validation loss: 2.3247224872918437
Epoch: 9| Step: 10
Training loss: 2.537095785140991
Validation loss: 2.323398308788272
Epoch: 9| Step: 11
Training loss: 3.5249102115631104
Validation loss: 2.3206224655933516
Epoch: 9| Step: 12
Training loss: 3.1293725967407227
Validation loss: 2.320994402864854
Epoch: 9| Step: 13
Training loss: 2.5816709995269775
Validation loss: 2.322666389479054
Epoch: 9| Step: 14
Training loss: 2.9498300552368164
Validation loss: 2.3242811470580618
Epoch: 9| Step: 15
Training loss: 3.690648317337036
Validation loss: 2.322485579003533
Epoch: 9| Step: 16
Training loss: 3.1483564376831055
Validation loss: 2.322544857752409
Epoch: 9| Step: 17
Training loss: 2.691755771636963
Validation loss: 2.3217576133261484
Epoch: 9| Step: 18
Training loss: 2.076094388961792
Validation loss: 2.3201179924628716
Epoch: 9| Step: 19
Training loss: 3.1830039024353027
Validation loss: 2.321507640022168
Epoch: 120| Step: 0
Training loss: 3.3968095779418945
Validation loss: 2.3197954841654935
Epoch: 9| Step: 1
Training loss: 2.2690203189849854
Validation loss: 2.323391049885921
Epoch: 9| Step: 2
Training loss: 2.79028058052063
Validation loss: 2.3221243645647447
Epoch: 9| Step: 3
Training loss: 2.450852394104004
Validation loss: 2.3229332742073554
Epoch: 9| Step: 4
Training loss: 3.121391773223877
Validation loss: 2.3210724292041585
Epoch: 9| Step: 5
Training loss: 2.6419286727905273
Validation loss: 2.320543654531026
Epoch: 9| Step: 6
Training loss: 2.8970746994018555
Validation loss: 2.321552734580829
Epoch: 9| Step: 7
Training loss: 2.566739082336426
Validation loss: 2.3214047503985946
Epoch: 9| Step: 8
Training loss: 3.2226643562316895
Validation loss: 2.3223200273170748
Epoch: 9| Step: 9
Training loss: 2.988656997680664
Validation loss: 2.321249047629267
Epoch: 9| Step: 10
Training loss: 2.9012088775634766
Validation loss: 2.320506284562804
Epoch: 9| Step: 11
Training loss: 2.7526559829711914
Validation loss: 2.321487051977528
Epoch: 9| Step: 12
Training loss: 2.4500160217285156
Validation loss: 2.322822397561382
Epoch: 9| Step: 13
Training loss: 2.144068956375122
Validation loss: 2.3208699921052234
Epoch: 9| Step: 14
Training loss: 2.746969223022461
Validation loss: 2.324766464370618
Epoch: 9| Step: 15
Training loss: 2.055953025817871
Validation loss: 2.322361946105957
Epoch: 9| Step: 16
Training loss: 3.3053784370422363
Validation loss: 2.3225483534147413
Epoch: 9| Step: 17
Training loss: 3.4511618614196777
Validation loss: 2.318759252699159
Epoch: 9| Step: 18
Training loss: 3.819568634033203
Validation loss: 2.3207302745297658
Epoch: 9| Step: 19
Training loss: 2.954155683517456
Validation loss: 2.32089163245057
Epoch: 121| Step: 0
Training loss: 3.7232255935668945
Validation loss: 2.319365136057353
Epoch: 9| Step: 1
Training loss: 3.264270782470703
Validation loss: 2.323635855167032
Epoch: 9| Step: 2
Training loss: 3.7252955436706543
Validation loss: 2.324098954955451
Epoch: 9| Step: 3
Training loss: 2.1961398124694824
Validation loss: 2.319943836267046
Epoch: 9| Step: 4
Training loss: 3.5274085998535156
Validation loss: 2.323741526912442
Epoch: 9| Step: 5
Training loss: 2.6437394618988037
Validation loss: 2.319101997416654
Epoch: 9| Step: 6
Training loss: 3.0366764068603516
Validation loss: 2.3197714562038723
Epoch: 9| Step: 7
Training loss: 2.9068565368652344
Validation loss: 2.321194141031169
Epoch: 9| Step: 8
Training loss: 2.731851100921631
Validation loss: 2.320162603323408
Epoch: 9| Step: 9
Training loss: 2.0261030197143555
Validation loss: 2.321042412476574
Epoch: 9| Step: 10
Training loss: 2.814952850341797
Validation loss: 2.3210324434925327
Epoch: 9| Step: 11
Training loss: 2.674940586090088
Validation loss: 2.323237395115036
Epoch: 9| Step: 12
Training loss: 3.226498603820801
Validation loss: 2.318412448004853
Epoch: 9| Step: 13
Training loss: 3.2542595863342285
Validation loss: 2.320491756466653
Epoch: 9| Step: 14
Training loss: 2.7282724380493164
Validation loss: 2.3189616735032996
Epoch: 9| Step: 15
Training loss: 2.1219372749328613
Validation loss: 2.3218299030400007
Epoch: 9| Step: 16
Training loss: 2.38394832611084
Validation loss: 2.3241854657372123
Epoch: 9| Step: 17
Training loss: 3.2105352878570557
Validation loss: 2.3201321732226035
Epoch: 9| Step: 18
Training loss: 2.802896499633789
Validation loss: 2.32294849183062
Epoch: 9| Step: 19
Training loss: 1.8900700807571411
Validation loss: 2.319362904528062
Epoch: 122| Step: 0
Training loss: 3.392725944519043
Validation loss: 2.3190054619055
Epoch: 9| Step: 1
Training loss: 2.286487102508545
Validation loss: 2.3218114453253986
Epoch: 9| Step: 2
Training loss: 3.4052324295043945
Validation loss: 2.321885759881932
Epoch: 9| Step: 3
Training loss: 2.5749781131744385
Validation loss: 2.3212212195499338
Epoch: 9| Step: 4
Training loss: 3.2984914779663086
Validation loss: 2.31945261080488
Epoch: 9| Step: 5
Training loss: 2.7169952392578125
Validation loss: 2.3194395312302403
Epoch: 9| Step: 6
Training loss: 3.0180063247680664
Validation loss: 2.3193577210680187
Epoch: 9| Step: 7
Training loss: 2.6391761302948
Validation loss: 2.3190990043201034
Epoch: 9| Step: 8
Training loss: 3.3212313652038574
Validation loss: 2.3198385633153022
Epoch: 9| Step: 9
Training loss: 2.520034074783325
Validation loss: 2.3184846167941746
Epoch: 9| Step: 10
Training loss: 3.23551082611084
Validation loss: 2.3192898643960196
Epoch: 9| Step: 11
Training loss: 2.5623607635498047
Validation loss: 2.3186854244136126
Epoch: 9| Step: 12
Training loss: 2.1245858669281006
Validation loss: 2.3187511550436777
Epoch: 9| Step: 13
Training loss: 2.578895092010498
Validation loss: 2.319704384254895
Epoch: 9| Step: 14
Training loss: 3.050973892211914
Validation loss: 2.317569724089808
Epoch: 9| Step: 15
Training loss: 3.4962050914764404
Validation loss: 2.3172673990400576
Epoch: 9| Step: 16
Training loss: 2.610429525375366
Validation loss: 2.3169280299179844
Epoch: 9| Step: 17
Training loss: 2.7309579849243164
Validation loss: 2.3227097576470683
Epoch: 9| Step: 18
Training loss: 2.3634731769561768
Validation loss: 2.321293669638874
Epoch: 9| Step: 19
Training loss: 2.9206690788269043
Validation loss: 2.3195665671671035
Epoch: 123| Step: 0
Training loss: 3.6283929347991943
Validation loss: 2.3209067334374076
Epoch: 9| Step: 1
Training loss: 2.4975595474243164
Validation loss: 2.3202800167550284
Epoch: 9| Step: 2
Training loss: 2.6182849407196045
Validation loss: 2.320310213582979
Epoch: 9| Step: 3
Training loss: 3.6455001831054688
Validation loss: 2.3182259086224675
Epoch: 9| Step: 4
Training loss: 2.987072467803955
Validation loss: 2.3201747901148075
Epoch: 9| Step: 5
Training loss: 2.7272191047668457
Validation loss: 2.3174608902965517
Epoch: 9| Step: 6
Training loss: 3.338510513305664
Validation loss: 2.3213092354561784
Epoch: 9| Step: 7
Training loss: 3.314850330352783
Validation loss: 2.31689162563077
Epoch: 9| Step: 8
Training loss: 3.0936594009399414
Validation loss: 2.3192971112916796
Epoch: 9| Step: 9
Training loss: 2.8002097606658936
Validation loss: 2.3184364099296735
Epoch: 9| Step: 10
Training loss: 2.7817282676696777
Validation loss: 2.320385639616054
Epoch: 9| Step: 11
Training loss: 2.673017978668213
Validation loss: 2.3165385911790586
Epoch: 9| Step: 12
Training loss: 3.29965877532959
Validation loss: 2.317004907903054
Epoch: 9| Step: 13
Training loss: 2.055361270904541
Validation loss: 2.3169753379958995
Epoch: 9| Step: 14
Training loss: 2.3245463371276855
Validation loss: 2.3181771940464597
Epoch: 9| Step: 15
Training loss: 2.5435049533843994
Validation loss: 2.3200175762176514
Epoch: 9| Step: 16
Training loss: 2.7159423828125
Validation loss: 2.318776395681093
Epoch: 9| Step: 17
Training loss: 2.452101945877075
Validation loss: 2.3182306358282516
Epoch: 9| Step: 18
Training loss: 2.5033252239227295
Validation loss: 2.317931168370967
Epoch: 9| Step: 19
Training loss: 2.8683860301971436
Validation loss: 2.3159330663063544
Epoch: 124| Step: 0
Training loss: 2.944988965988159
Validation loss: 2.3186166698126485
Epoch: 9| Step: 1
Training loss: 3.200909376144409
Validation loss: 2.3191682932188185
Epoch: 9| Step: 2
Training loss: 2.331453323364258
Validation loss: 2.3183760265652222
Epoch: 9| Step: 3
Training loss: 2.648085594177246
Validation loss: 2.3177931325898755
Epoch: 9| Step: 4
Training loss: 3.3589463233947754
Validation loss: 2.31831459690341
Epoch: 9| Step: 5
Training loss: 2.7901999950408936
Validation loss: 2.3179131240295847
Epoch: 9| Step: 6
Training loss: 3.9580647945404053
Validation loss: 2.3166414799450115
Epoch: 9| Step: 7
Training loss: 1.7425751686096191
Validation loss: 2.3229211260088913
Epoch: 9| Step: 8
Training loss: 3.045659065246582
Validation loss: 2.3227643434949914
Epoch: 9| Step: 9
Training loss: 2.9123456478118896
Validation loss: 2.316537541451214
Epoch: 9| Step: 10
Training loss: 2.89742374420166
Validation loss: 2.318409508080791
Epoch: 9| Step: 11
Training loss: 3.428736686706543
Validation loss: 2.319164531694042
Epoch: 9| Step: 12
Training loss: 2.816761016845703
Validation loss: 2.316895668455165
Epoch: 9| Step: 13
Training loss: 2.2241644859313965
Validation loss: 2.319313236277738
Epoch: 9| Step: 14
Training loss: 2.597607135772705
Validation loss: 2.3208876891101866
Epoch: 9| Step: 15
Training loss: 3.711904525756836
Validation loss: 2.318447316293236
Epoch: 9| Step: 16
Training loss: 2.6567728519439697
Validation loss: 2.318114523407367
Epoch: 9| Step: 17
Training loss: 2.6906347274780273
Validation loss: 2.3185911401570274
Epoch: 9| Step: 18
Training loss: 3.039947032928467
Validation loss: 2.3177291129132827
Epoch: 9| Step: 19
Training loss: 1.8784734010696411
Validation loss: 2.3157435269664517
Epoch: 125| Step: 0
Training loss: 2.8958168029785156
Validation loss: 2.3181109222576772
Epoch: 9| Step: 1
Training loss: 2.4573092460632324
Validation loss: 2.3166251491299636
Epoch: 9| Step: 2
Training loss: 3.2868523597717285
Validation loss: 2.3156591559485564
Epoch: 9| Step: 3
Training loss: 2.8737101554870605
Validation loss: 2.3160969301951018
Epoch: 9| Step: 4
Training loss: 2.860034465789795
Validation loss: 2.3172052455462997
Epoch: 9| Step: 5
Training loss: 3.1011457443237305
Validation loss: 2.3163131569786897
Epoch: 9| Step: 6
Training loss: 3.2509326934814453
Validation loss: 2.31575754049013
Epoch: 9| Step: 7
Training loss: 3.2978103160858154
Validation loss: 2.3144455367712666
Epoch: 9| Step: 8
Training loss: 3.2194271087646484
Validation loss: 2.3149486745861796
Epoch: 9| Step: 9
Training loss: 2.3093338012695312
Validation loss: 2.317288654313671
Epoch: 9| Step: 10
Training loss: 2.4110071659088135
Validation loss: 2.3180905554792006
Epoch: 9| Step: 11
Training loss: 2.060462474822998
Validation loss: 2.3170668032529544
Epoch: 9| Step: 12
Training loss: 2.916597366333008
Validation loss: 2.314788195726683
Epoch: 9| Step: 13
Training loss: 3.091193199157715
Validation loss: 2.316596648675932
Epoch: 9| Step: 14
Training loss: 2.8086626529693604
Validation loss: 2.3162501715927672
Epoch: 9| Step: 15
Training loss: 2.8553221225738525
Validation loss: 2.3181754393543272
Epoch: 9| Step: 16
Training loss: 2.827092409133911
Validation loss: 2.317588917643046
Epoch: 9| Step: 17
Training loss: 2.892644166946411
Validation loss: 2.314882894214109
Epoch: 9| Step: 18
Training loss: 2.8296873569488525
Validation loss: 2.3125791789816437
Epoch: 9| Step: 19
Training loss: 2.5963683128356934
Validation loss: 2.3172290513841367
Epoch: 126| Step: 0
Training loss: 3.479086399078369
Validation loss: 2.318602345830245
Epoch: 9| Step: 1
Training loss: 3.339578151702881
Validation loss: 2.313492032263776
Epoch: 9| Step: 2
Training loss: 3.266239643096924
Validation loss: 2.317432290358509
Epoch: 9| Step: 3
Training loss: 2.8586668968200684
Validation loss: 2.3164321484325603
Epoch: 9| Step: 4
Training loss: 2.8744564056396484
Validation loss: 2.3178436961963023
Epoch: 9| Step: 5
Training loss: 2.6784019470214844
Validation loss: 2.3190739103358426
Epoch: 9| Step: 6
Training loss: 2.6231441497802734
Validation loss: 2.3181892358999456
Epoch: 9| Step: 7
Training loss: 2.727983236312866
Validation loss: 2.319275885177173
Epoch: 9| Step: 8
Training loss: 2.9369568824768066
Validation loss: 2.3203166200102663
Epoch: 9| Step: 9
Training loss: 2.7801012992858887
Validation loss: 2.317549710651096
Epoch: 9| Step: 10
Training loss: 3.052281141281128
Validation loss: 2.32078715708616
Epoch: 9| Step: 11
Training loss: 2.6160972118377686
Validation loss: 2.324106593783811
Epoch: 9| Step: 12
Training loss: 3.0357115268707275
Validation loss: 2.32522839264904
Epoch: 9| Step: 13
Training loss: 2.889019250869751
Validation loss: 2.3193065965775963
Epoch: 9| Step: 14
Training loss: 2.7017719745635986
Validation loss: 2.3192872160630262
Epoch: 9| Step: 15
Training loss: 2.682797431945801
Validation loss: 2.31806732253205
Epoch: 9| Step: 16
Training loss: 2.520702362060547
Validation loss: 2.314754134459461
Epoch: 9| Step: 17
Training loss: 2.389796257019043
Validation loss: 2.3126146810517896
Epoch: 9| Step: 18
Training loss: 2.762807846069336
Validation loss: 2.3170546181767966
Epoch: 9| Step: 19
Training loss: 2.5509238243103027
Validation loss: 2.3154574143800803
Epoch: 127| Step: 0
Training loss: 2.243755340576172
Validation loss: 2.3152075937326004
Epoch: 9| Step: 1
Training loss: 3.2492895126342773
Validation loss: 2.3149710207534353
Epoch: 9| Step: 2
Training loss: 3.64033579826355
Validation loss: 2.3150386192815766
Epoch: 9| Step: 3
Training loss: 2.7686543464660645
Validation loss: 2.3168302988834517
Epoch: 9| Step: 4
Training loss: 2.601045608520508
Validation loss: 2.3153534930386988
Epoch: 9| Step: 5
Training loss: 2.393921375274658
Validation loss: 2.316088691889811
Epoch: 9| Step: 6
Training loss: 2.5268819332122803
Validation loss: 2.3152408445481774
Epoch: 9| Step: 7
Training loss: 3.140624523162842
Validation loss: 2.3157030901462914
Epoch: 9| Step: 8
Training loss: 3.0398330688476562
Validation loss: 2.3177656235454753
Epoch: 9| Step: 9
Training loss: 3.3522348403930664
Validation loss: 2.315295550463011
Epoch: 9| Step: 10
Training loss: 2.918018102645874
Validation loss: 2.314253429714724
Epoch: 9| Step: 11
Training loss: 2.9480652809143066
Validation loss: 2.3157079785847836
Epoch: 9| Step: 12
Training loss: 2.429685115814209
Validation loss: 2.315041650113442
Epoch: 9| Step: 13
Training loss: 2.148542881011963
Validation loss: 2.31527453703846
Epoch: 9| Step: 14
Training loss: 3.2264251708984375
Validation loss: 2.314557140679668
Epoch: 9| Step: 15
Training loss: 2.7870054244995117
Validation loss: 2.314584476484669
Epoch: 9| Step: 16
Training loss: 3.734997272491455
Validation loss: 2.314512072707252
Epoch: 9| Step: 17
Training loss: 2.9168734550476074
Validation loss: 2.3145734680642325
Epoch: 9| Step: 18
Training loss: 2.349608898162842
Validation loss: 2.314891863212311
Epoch: 9| Step: 19
Training loss: 2.3727071285247803
Validation loss: 2.3149684899144893
Epoch: 128| Step: 0
Training loss: 2.671271324157715
Validation loss: 2.314017122598003
Epoch: 9| Step: 1
Training loss: 3.0754473209381104
Validation loss: 2.31337214202332
Epoch: 9| Step: 2
Training loss: 3.7363946437835693
Validation loss: 2.3154470526057183
Epoch: 9| Step: 3
Training loss: 2.674184799194336
Validation loss: 2.314495211882557
Epoch: 9| Step: 4
Training loss: 2.1574625968933105
Validation loss: 2.3119025264712545
Epoch: 9| Step: 5
Training loss: 2.502964496612549
Validation loss: 2.3139660770086934
Epoch: 9| Step: 6
Training loss: 3.0580954551696777
Validation loss: 2.3145895398778022
Epoch: 9| Step: 7
Training loss: 2.475210189819336
Validation loss: 2.316587149668083
Epoch: 9| Step: 8
Training loss: 2.9115047454833984
Validation loss: 2.314253227316218
Epoch: 9| Step: 9
Training loss: 2.5508360862731934
Validation loss: 2.314096143777422
Epoch: 9| Step: 10
Training loss: 3.123823642730713
Validation loss: 2.3157510637379377
Epoch: 9| Step: 11
Training loss: 2.396099805831909
Validation loss: 2.3130473061431225
Epoch: 9| Step: 12
Training loss: 3.825275421142578
Validation loss: 2.3156312343885572
Epoch: 9| Step: 13
Training loss: 3.164848804473877
Validation loss: 2.3142422643496836
Epoch: 9| Step: 14
Training loss: 2.535893201828003
Validation loss: 2.3139005908005528
Epoch: 9| Step: 15
Training loss: 2.507110118865967
Validation loss: 2.3122859447122477
Epoch: 9| Step: 16
Training loss: 2.0602669715881348
Validation loss: 2.313893311315303
Epoch: 9| Step: 17
Training loss: 3.3623085021972656
Validation loss: 2.312364008786867
Epoch: 9| Step: 18
Training loss: 2.948085308074951
Validation loss: 2.316923858450471
Epoch: 9| Step: 19
Training loss: 2.994266986846924
Validation loss: 2.31707602610691
Epoch: 129| Step: 0
Training loss: 2.9302592277526855
Validation loss: 2.314580383918268
Epoch: 9| Step: 1
Training loss: 2.7852537631988525
Validation loss: 2.3137524127960205
Epoch: 9| Step: 2
Training loss: 2.4001336097717285
Validation loss: 2.313886390315543
Epoch: 9| Step: 3
Training loss: 3.442539691925049
Validation loss: 2.315165310454883
Epoch: 9| Step: 4
Training loss: 3.0862486362457275
Validation loss: 2.3166093002977988
Epoch: 9| Step: 5
Training loss: 2.566312789916992
Validation loss: 2.3145146764439644
Epoch: 9| Step: 6
Training loss: 2.020826578140259
Validation loss: 2.3135034832165395
Epoch: 9| Step: 7
Training loss: 2.4521875381469727
Validation loss: 2.3114263556844037
Epoch: 9| Step: 8
Training loss: 2.8476719856262207
Validation loss: 2.3143544282844597
Epoch: 9| Step: 9
Training loss: 2.8395190238952637
Validation loss: 2.31429921465812
Epoch: 9| Step: 10
Training loss: 2.0052242279052734
Validation loss: 2.313166010294029
Epoch: 9| Step: 11
Training loss: 2.754202365875244
Validation loss: 2.313906739941604
Epoch: 9| Step: 12
Training loss: 3.1629514694213867
Validation loss: 2.3128468398567583
Epoch: 9| Step: 13
Training loss: 3.4814867973327637
Validation loss: 2.313112728029704
Epoch: 9| Step: 14
Training loss: 3.153663396835327
Validation loss: 2.3125492179994103
Epoch: 9| Step: 15
Training loss: 2.651806354522705
Validation loss: 2.314864535983518
Epoch: 9| Step: 16
Training loss: 3.319288730621338
Validation loss: 2.3139377206349545
Epoch: 9| Step: 17
Training loss: 3.6318256855010986
Validation loss: 2.313243919139286
Epoch: 9| Step: 18
Training loss: 2.88631010055542
Validation loss: 2.3121931467124885
Epoch: 9| Step: 19
Training loss: 2.3018226623535156
Validation loss: 2.313116164516202
Epoch: 130| Step: 0
Training loss: 2.657683849334717
Validation loss: 2.313535913289022
Epoch: 9| Step: 1
Training loss: 3.06878662109375
Validation loss: 2.313491730381259
Epoch: 9| Step: 2
Training loss: 2.798429012298584
Validation loss: 2.3109078578811757
Epoch: 9| Step: 3
Training loss: 3.3834540843963623
Validation loss: 2.3109659788419874
Epoch: 9| Step: 4
Training loss: 3.422372341156006
Validation loss: 2.3083910135914096
Epoch: 9| Step: 5
Training loss: 2.848707437515259
Validation loss: 2.3126997638949387
Epoch: 9| Step: 6
Training loss: 2.1918725967407227
Validation loss: 2.3132589789603255
Epoch: 9| Step: 7
Training loss: 3.015144109725952
Validation loss: 2.3110026635712
Epoch: 9| Step: 8
Training loss: 2.6668639183044434
Validation loss: 2.312687007643336
Epoch: 9| Step: 9
Training loss: 2.4333810806274414
Validation loss: 2.310904031177219
Epoch: 9| Step: 10
Training loss: 2.2009315490722656
Validation loss: 2.3101989897035007
Epoch: 9| Step: 11
Training loss: 2.489464282989502
Validation loss: 2.3095856330377593
Epoch: 9| Step: 12
Training loss: 2.968097686767578
Validation loss: 2.311452494250785
Epoch: 9| Step: 13
Training loss: 3.824988842010498
Validation loss: 2.312805678347032
Epoch: 9| Step: 14
Training loss: 3.107942581176758
Validation loss: 2.3149143054330947
Epoch: 9| Step: 15
Training loss: 2.706855297088623
Validation loss: 2.311630219864331
Epoch: 9| Step: 16
Training loss: 2.744853973388672
Validation loss: 2.30970029350665
Epoch: 9| Step: 17
Training loss: 3.2909977436065674
Validation loss: 2.3125343580040143
Epoch: 9| Step: 18
Training loss: 1.8449010848999023
Validation loss: 2.3129211484099463
Epoch: 9| Step: 19
Training loss: 3.0122947692871094
Validation loss: 2.3117655061131757
Epoch: 131| Step: 0
Training loss: 1.7186177968978882
Validation loss: 2.310149184233851
Epoch: 9| Step: 1
Training loss: 3.418839454650879
Validation loss: 2.3117198618195895
Epoch: 9| Step: 2
Training loss: 2.8706235885620117
Validation loss: 2.313040678449672
Epoch: 9| Step: 3
Training loss: 2.5858802795410156
Validation loss: 2.312468806616694
Epoch: 9| Step: 4
Training loss: 3.1531753540039062
Validation loss: 2.312018394470215
Epoch: 9| Step: 5
Training loss: 2.1957643032073975
Validation loss: 2.310832412980443
Epoch: 9| Step: 6
Training loss: 3.004106044769287
Validation loss: 2.311130383889452
Epoch: 9| Step: 7
Training loss: 2.5871939659118652
Validation loss: 2.3148442446756707
Epoch: 9| Step: 8
Training loss: 2.6208748817443848
Validation loss: 2.3130108315310034
Epoch: 9| Step: 9
Training loss: 2.831949234008789
Validation loss: 2.3126169314487375
Epoch: 9| Step: 10
Training loss: 2.00777268409729
Validation loss: 2.3101700364256934
Epoch: 9| Step: 11
Training loss: 3.2664198875427246
Validation loss: 2.3111490568668724
Epoch: 9| Step: 12
Training loss: 3.0464885234832764
Validation loss: 2.3123954388735104
Epoch: 9| Step: 13
Training loss: 3.198626756668091
Validation loss: 2.310774297165356
Epoch: 9| Step: 14
Training loss: 3.353170394897461
Validation loss: 2.311962160275137
Epoch: 9| Step: 15
Training loss: 3.2043070793151855
Validation loss: 2.3099067211151123
Epoch: 9| Step: 16
Training loss: 3.123764991760254
Validation loss: 2.31157621376806
Epoch: 9| Step: 17
Training loss: 2.5481035709381104
Validation loss: 2.3128653841910602
Epoch: 9| Step: 18
Training loss: 2.8392233848571777
Validation loss: 2.312172646145169
Epoch: 9| Step: 19
Training loss: 3.163170099258423
Validation loss: 2.311276147691466
Epoch: 132| Step: 0
Training loss: 2.598994255065918
Validation loss: 2.310738433179238
Epoch: 9| Step: 1
Training loss: 2.4710755348205566
Validation loss: 2.3106242118121907
Epoch: 9| Step: 2
Training loss: 2.8275439739227295
Validation loss: 2.3093210312959958
Epoch: 9| Step: 3
Training loss: 2.572197914123535
Validation loss: 2.3095107644581967
Epoch: 9| Step: 4
Training loss: 3.355405330657959
Validation loss: 2.311034250602448
Epoch: 9| Step: 5
Training loss: 2.931427001953125
Validation loss: 2.3064067569568003
Epoch: 9| Step: 6
Training loss: 2.7609753608703613
Validation loss: 2.3097001459958744
Epoch: 9| Step: 7
Training loss: 3.2902159690856934
Validation loss: 2.309363817997116
Epoch: 9| Step: 8
Training loss: 3.124264717102051
Validation loss: 2.3109051803890748
Epoch: 9| Step: 9
Training loss: 3.0203819274902344
Validation loss: 2.309502059607197
Epoch: 9| Step: 10
Training loss: 2.071702241897583
Validation loss: 2.3100145189024563
Epoch: 9| Step: 11
Training loss: 3.0903220176696777
Validation loss: 2.311335236048527
Epoch: 9| Step: 12
Training loss: 2.6635396480560303
Validation loss: 2.309689900857939
Epoch: 9| Step: 13
Training loss: 2.6436476707458496
Validation loss: 2.310487642562647
Epoch: 9| Step: 14
Training loss: 2.636521100997925
Validation loss: 2.3121479380902628
Epoch: 9| Step: 15
Training loss: 3.1403725147247314
Validation loss: 2.309717536830216
Epoch: 9| Step: 16
Training loss: 2.9077165126800537
Validation loss: 2.3096467170783943
Epoch: 9| Step: 17
Training loss: 2.8697633743286133
Validation loss: 2.311209525993402
Epoch: 9| Step: 18
Training loss: 2.674018383026123
Validation loss: 2.3131057915927693
Epoch: 9| Step: 19
Training loss: 3.016425132751465
Validation loss: 2.3107228064708574
Epoch: 133| Step: 0
Training loss: 3.0466692447662354
Validation loss: 2.3125820211369357
Epoch: 9| Step: 1
Training loss: 2.3638041019439697
Validation loss: 2.311404391158399
Epoch: 9| Step: 2
Training loss: 3.117161750793457
Validation loss: 2.3138289554513616
Epoch: 9| Step: 3
Training loss: 3.1931276321411133
Validation loss: 2.307106026642614
Epoch: 9| Step: 4
Training loss: 2.30340838432312
Validation loss: 2.310092334267047
Epoch: 9| Step: 5
Training loss: 3.2155978679656982
Validation loss: 2.312215108665631
Epoch: 9| Step: 6
Training loss: 2.149186134338379
Validation loss: 2.3122721027127273
Epoch: 9| Step: 7
Training loss: 3.312887668609619
Validation loss: 2.311376326375728
Epoch: 9| Step: 8
Training loss: 2.7329764366149902
Validation loss: 2.308155963746764
Epoch: 9| Step: 9
Training loss: 2.71893310546875
Validation loss: 2.309547587264356
Epoch: 9| Step: 10
Training loss: 3.0612902641296387
Validation loss: 2.3111556588316993
Epoch: 9| Step: 11
Training loss: 3.622932195663452
Validation loss: 2.310428252323068
Epoch: 9| Step: 12
Training loss: 2.9896979331970215
Validation loss: 2.310014872242221
Epoch: 9| Step: 13
Training loss: 2.146538019180298
Validation loss: 2.30933151485251
Epoch: 9| Step: 14
Training loss: 2.7776379585266113
Validation loss: 2.3097379773640805
Epoch: 9| Step: 15
Training loss: 3.5728092193603516
Validation loss: 2.3095111915533493
Epoch: 9| Step: 16
Training loss: 2.335456132888794
Validation loss: 2.3108844842842156
Epoch: 9| Step: 17
Training loss: 2.0846304893493652
Validation loss: 2.3077797872557055
Epoch: 9| Step: 18
Training loss: 2.6256909370422363
Validation loss: 2.307313917352141
Epoch: 9| Step: 19
Training loss: 3.273829221725464
Validation loss: 2.3098403669947345
Epoch: 134| Step: 0
Training loss: 2.8423891067504883
Validation loss: 2.3085552025184355
Epoch: 9| Step: 1
Training loss: 3.5204832553863525
Validation loss: 2.310374548109315
Epoch: 9| Step: 2
Training loss: 2.503157615661621
Validation loss: 2.3094710428937733
Epoch: 9| Step: 3
Training loss: 2.3912620544433594
Validation loss: 2.3105933683381665
Epoch: 9| Step: 4
Training loss: 2.4694714546203613
Validation loss: 2.310110311714008
Epoch: 9| Step: 5
Training loss: 3.2743260860443115
Validation loss: 2.312722401653262
Epoch: 9| Step: 6
Training loss: 2.1401612758636475
Validation loss: 2.3074792957992005
Epoch: 9| Step: 7
Training loss: 2.931459426879883
Validation loss: 2.3134058996927824
Epoch: 9| Step: 8
Training loss: 3.0359935760498047
Validation loss: 2.3144724437658737
Epoch: 9| Step: 9
Training loss: 2.9054160118103027
Validation loss: 2.3121043743847087
Epoch: 9| Step: 10
Training loss: 2.719808340072632
Validation loss: 2.3119484863692907
Epoch: 9| Step: 11
Training loss: 2.3880677223205566
Validation loss: 2.308374297704628
Epoch: 9| Step: 12
Training loss: 2.6017584800720215
Validation loss: 2.311226256459737
Epoch: 9| Step: 13
Training loss: 2.9529149532318115
Validation loss: 2.311453573995357
Epoch: 9| Step: 14
Training loss: 3.3286938667297363
Validation loss: 2.3096522821796883
Epoch: 9| Step: 15
Training loss: 3.0054290294647217
Validation loss: 2.309396421308998
Epoch: 9| Step: 16
Training loss: 3.401444911956787
Validation loss: 2.3115196708294987
Epoch: 9| Step: 17
Training loss: 2.3754076957702637
Validation loss: 2.307970502393709
Epoch: 9| Step: 18
Training loss: 3.1819698810577393
Validation loss: 2.311375683160137
Epoch: 9| Step: 19
Training loss: 2.6294620037078857
Validation loss: 2.3098576274707163
Epoch: 135| Step: 0
Training loss: 2.2060530185699463
Validation loss: 2.3092895514673466
Epoch: 9| Step: 1
Training loss: 2.8033127784729004
Validation loss: 2.309396076545441
Epoch: 9| Step: 2
Training loss: 3.060908794403076
Validation loss: 2.306271350641045
Epoch: 9| Step: 3
Training loss: 2.9357171058654785
Validation loss: 2.3076730632095885
Epoch: 9| Step: 4
Training loss: 3.1349902153015137
Validation loss: 2.307682735456837
Epoch: 9| Step: 5
Training loss: 2.44580078125
Validation loss: 2.3069400101256887
Epoch: 9| Step: 6
Training loss: 3.0703866481781006
Validation loss: 2.3081006334839964
Epoch: 9| Step: 7
Training loss: 3.0496599674224854
Validation loss: 2.30821277254777
Epoch: 9| Step: 8
Training loss: 2.835843086242676
Validation loss: 2.3080097162466253
Epoch: 9| Step: 9
Training loss: 3.124039888381958
Validation loss: 2.309064297367343
Epoch: 9| Step: 10
Training loss: 2.885694980621338
Validation loss: 2.307561442148771
Epoch: 9| Step: 11
Training loss: 2.197582721710205
Validation loss: 2.3081765329237465
Epoch: 9| Step: 12
Training loss: 3.428424596786499
Validation loss: 2.3074321077881956
Epoch: 9| Step: 13
Training loss: 2.1905858516693115
Validation loss: 2.306934457888706
Epoch: 9| Step: 14
Training loss: 3.038850784301758
Validation loss: 2.3045162528538876
Epoch: 9| Step: 15
Training loss: 3.4523961544036865
Validation loss: 2.3059400345781724
Epoch: 9| Step: 16
Training loss: 2.7786521911621094
Validation loss: 2.3061559852078664
Epoch: 9| Step: 17
Training loss: 2.3091278076171875
Validation loss: 2.3062316290766214
Epoch: 9| Step: 18
Training loss: 2.492514133453369
Validation loss: 2.3072349201861044
Epoch: 9| Step: 19
Training loss: 3.145791530609131
Validation loss: 2.3095214932942563
Epoch: 136| Step: 0
Training loss: 2.5377230644226074
Validation loss: 2.3044803725729746
Epoch: 9| Step: 1
Training loss: 2.987597942352295
Validation loss: 2.307527723929865
Epoch: 9| Step: 2
Training loss: 3.6120004653930664
Validation loss: 2.3082506142074255
Epoch: 9| Step: 3
Training loss: 2.9902191162109375
Validation loss: 2.3060716982368086
Epoch: 9| Step: 4
Training loss: 2.9539504051208496
Validation loss: 2.306275256246114
Epoch: 9| Step: 5
Training loss: 3.0195682048797607
Validation loss: 2.305919938807865
Epoch: 9| Step: 6
Training loss: 2.733044147491455
Validation loss: 2.305480255497445
Epoch: 9| Step: 7
Training loss: 3.2665727138519287
Validation loss: 2.305787194547036
Epoch: 9| Step: 8
Training loss: 2.400674343109131
Validation loss: 2.3076699346089535
Epoch: 9| Step: 9
Training loss: 2.437957763671875
Validation loss: 2.3020765678488093
Epoch: 9| Step: 10
Training loss: 3.915830135345459
Validation loss: 2.3109380015366368
Epoch: 9| Step: 11
Training loss: 2.951683521270752
Validation loss: 2.3078324588940298
Epoch: 9| Step: 12
Training loss: 2.655970573425293
Validation loss: 2.30940684826254
Epoch: 9| Step: 13
Training loss: 1.7426600456237793
Validation loss: 2.3070913956319687
Epoch: 9| Step: 14
Training loss: 3.2481207847595215
Validation loss: 2.30902626274301
Epoch: 9| Step: 15
Training loss: 2.485294818878174
Validation loss: 2.309296427870826
Epoch: 9| Step: 16
Training loss: 2.5354504585266113
Validation loss: 2.305225231664644
Epoch: 9| Step: 17
Training loss: 2.7083005905151367
Validation loss: 2.3100604822309756
Epoch: 9| Step: 18
Training loss: 2.7574758529663086
Validation loss: 2.3125708583447575
Epoch: 9| Step: 19
Training loss: 2.686387062072754
Validation loss: 2.3047535007806133
Epoch: 137| Step: 0
Training loss: 2.3266677856445312
Validation loss: 2.3104543068426118
Epoch: 9| Step: 1
Training loss: 2.8831746578216553
Validation loss: 2.3093628162960353
Epoch: 9| Step: 2
Training loss: 2.772812604904175
Validation loss: 2.3069073759394585
Epoch: 9| Step: 3
Training loss: 2.9074788093566895
Validation loss: 2.310622912516697
Epoch: 9| Step: 4
Training loss: 2.332195281982422
Validation loss: 2.3068270717593404
Epoch: 9| Step: 5
Training loss: 3.0008630752563477
Validation loss: 2.3078137318865
Epoch: 9| Step: 6
Training loss: 2.6790313720703125
Validation loss: 2.308372832030701
Epoch: 9| Step: 7
Training loss: 3.579944610595703
Validation loss: 2.305764047361964
Epoch: 9| Step: 8
Training loss: 2.8694229125976562
Validation loss: 2.3048396084806044
Epoch: 9| Step: 9
Training loss: 3.0951671600341797
Validation loss: 2.305495160946743
Epoch: 9| Step: 10
Training loss: 2.499208450317383
Validation loss: 2.3087084679294834
Epoch: 9| Step: 11
Training loss: 2.8882672786712646
Validation loss: 2.3038109155009976
Epoch: 9| Step: 12
Training loss: 2.4286601543426514
Validation loss: 2.3075299708963297
Epoch: 9| Step: 13
Training loss: 2.5015859603881836
Validation loss: 2.310428236885894
Epoch: 9| Step: 14
Training loss: 2.6724917888641357
Validation loss: 2.3054231997016523
Epoch: 9| Step: 15
Training loss: 2.7572546005249023
Validation loss: 2.308682635533724
Epoch: 9| Step: 16
Training loss: 2.914964437484741
Validation loss: 2.3065115667933185
Epoch: 9| Step: 17
Training loss: 3.227299213409424
Validation loss: 2.307233719517001
Epoch: 9| Step: 18
Training loss: 3.1189818382263184
Validation loss: 2.3082945363984693
Epoch: 9| Step: 19
Training loss: 3.1134960651397705
Validation loss: 2.3031185273643877
Epoch: 138| Step: 0
Training loss: 2.635010004043579
Validation loss: 2.3057198198579196
Epoch: 9| Step: 1
Training loss: 3.027393341064453
Validation loss: 2.3054566666376677
Epoch: 9| Step: 2
Training loss: 2.336785316467285
Validation loss: 2.3063169023115857
Epoch: 9| Step: 3
Training loss: 2.4423258304595947
Validation loss: 2.3040223979263854
Epoch: 9| Step: 4
Training loss: 2.6112518310546875
Validation loss: 2.3043045122846424
Epoch: 9| Step: 5
Training loss: 1.6818735599517822
Validation loss: 2.306498440907156
Epoch: 9| Step: 6
Training loss: 2.84889817237854
Validation loss: 2.305283323466349
Epoch: 9| Step: 7
Training loss: 3.695197343826294
Validation loss: 2.3069615244007795
Epoch: 9| Step: 8
Training loss: 2.7181789875030518
Validation loss: 2.305496783565274
Epoch: 9| Step: 9
Training loss: 3.2184669971466064
Validation loss: 2.3066170507197756
Epoch: 9| Step: 10
Training loss: 2.2343242168426514
Validation loss: 2.307428864266375
Epoch: 9| Step: 11
Training loss: 3.214542865753174
Validation loss: 2.308224389878966
Epoch: 9| Step: 12
Training loss: 3.3929319381713867
Validation loss: 2.3082257980923
Epoch: 9| Step: 13
Training loss: 2.617323398590088
Validation loss: 2.310546017379212
Epoch: 9| Step: 14
Training loss: 2.850315570831299
Validation loss: 2.3077310332291416
Epoch: 9| Step: 15
Training loss: 3.118194341659546
Validation loss: 2.306533232867289
Epoch: 9| Step: 16
Training loss: 3.1808340549468994
Validation loss: 2.304319043811277
Epoch: 9| Step: 17
Training loss: 2.804431200027466
Validation loss: 2.308926645800364
Epoch: 9| Step: 18
Training loss: 3.063667058944702
Validation loss: 2.3050017005248034
Epoch: 9| Step: 19
Training loss: 2.865065574645996
Validation loss: 2.307020837454487
Epoch: 139| Step: 0
Training loss: 2.3017802238464355
Validation loss: 2.3069168715168247
Epoch: 9| Step: 1
Training loss: 2.727799892425537
Validation loss: 2.3065210469335105
Epoch: 9| Step: 2
Training loss: 2.626857042312622
Validation loss: 2.3099078000020636
Epoch: 9| Step: 3
Training loss: 2.3573555946350098
Validation loss: 2.303603990472478
Epoch: 9| Step: 4
Training loss: 2.9704761505126953
Validation loss: 2.3059111233237837
Epoch: 9| Step: 5
Training loss: 2.0940475463867188
Validation loss: 2.3054265581446587
Epoch: 9| Step: 6
Training loss: 3.2154948711395264
Validation loss: 2.305603747745212
Epoch: 9| Step: 7
Training loss: 2.563347339630127
Validation loss: 2.3069537646478886
Epoch: 9| Step: 8
Training loss: 2.484506130218506
Validation loss: 2.303445200268313
Epoch: 9| Step: 9
Training loss: 2.977982997894287
Validation loss: 2.306874981887049
Epoch: 9| Step: 10
Training loss: 3.50390887260437
Validation loss: 2.3025630823999856
Epoch: 9| Step: 11
Training loss: 2.5647122859954834
Validation loss: 2.3060966652931927
Epoch: 9| Step: 12
Training loss: 1.9537365436553955
Validation loss: 2.3037719863781825
Epoch: 9| Step: 13
Training loss: 3.834481716156006
Validation loss: 2.3066608914368443
Epoch: 9| Step: 14
Training loss: 3.2818284034729004
Validation loss: 2.3062812501578023
Epoch: 9| Step: 15
Training loss: 2.4728503227233887
Validation loss: 2.30273897785077
Epoch: 9| Step: 16
Training loss: 3.3641538619995117
Validation loss: 2.3040565380947196
Epoch: 9| Step: 17
Training loss: 3.4100992679595947
Validation loss: 2.3080960349213306
Epoch: 9| Step: 18
Training loss: 2.863903045654297
Validation loss: 2.3052337787134185
Epoch: 9| Step: 19
Training loss: 2.964658498764038
Validation loss: 2.303590114168126
Epoch: 140| Step: 0
Training loss: 3.5498766899108887
Validation loss: 2.303708169100096
Epoch: 9| Step: 1
Training loss: 2.379814624786377
Validation loss: 2.3043418376565836
Epoch: 9| Step: 2
Training loss: 2.532374382019043
Validation loss: 2.3050327575464045
Epoch: 9| Step: 3
Training loss: 2.545814037322998
Validation loss: 2.307181667080886
Epoch: 9| Step: 4
Training loss: 2.8671247959136963
Validation loss: 2.3031080969803623
Epoch: 9| Step: 5
Training loss: 3.2394051551818848
Validation loss: 2.3064737542927696
Epoch: 9| Step: 6
Training loss: 2.4624276161193848
Validation loss: 2.3056149173983567
Epoch: 9| Step: 7
Training loss: 2.7359976768493652
Validation loss: 2.305380102541807
Epoch: 9| Step: 8
Training loss: 2.568876266479492
Validation loss: 2.3041503600937
Epoch: 9| Step: 9
Training loss: 2.9660582542419434
Validation loss: 2.3023669187971154
Epoch: 9| Step: 10
Training loss: 3.029919147491455
Validation loss: 2.30140865277901
Epoch: 9| Step: 11
Training loss: 2.49530029296875
Validation loss: 2.304254093616129
Epoch: 9| Step: 12
Training loss: 2.5379366874694824
Validation loss: 2.304008685427604
Epoch: 9| Step: 13
Training loss: 3.076920986175537
Validation loss: 2.3045192073575027
Epoch: 9| Step: 14
Training loss: 2.013148069381714
Validation loss: 2.3039660745387454
Epoch: 9| Step: 15
Training loss: 3.370708465576172
Validation loss: 2.3071384292712316
Epoch: 9| Step: 16
Training loss: 2.788883924484253
Validation loss: 2.307946808904195
Epoch: 9| Step: 17
Training loss: 3.3800129890441895
Validation loss: 2.303294255579118
Epoch: 9| Step: 18
Training loss: 3.240483045578003
Validation loss: 2.3044997993990672
Epoch: 9| Step: 19
Training loss: 2.6997950077056885
Validation loss: 2.304756967283839
Epoch: 141| Step: 0
Training loss: 2.227509021759033
Validation loss: 2.301278206941893
Epoch: 9| Step: 1
Training loss: 2.5134263038635254
Validation loss: 2.3021496388552
Epoch: 9| Step: 2
Training loss: 3.012570381164551
Validation loss: 2.302967630701957
Epoch: 9| Step: 3
Training loss: 2.8504374027252197
Validation loss: 2.305318832397461
Epoch: 9| Step: 4
Training loss: 2.8958144187927246
Validation loss: 2.304664081806759
Epoch: 9| Step: 5
Training loss: 2.8591952323913574
Validation loss: 2.301676837660426
Epoch: 9| Step: 6
Training loss: 2.998647928237915
Validation loss: 2.300647795629158
Epoch: 9| Step: 7
Training loss: 3.7950541973114014
Validation loss: 2.3002164689756985
Epoch: 9| Step: 8
Training loss: 2.6645026206970215
Validation loss: 2.301969857524625
Epoch: 9| Step: 9
Training loss: 2.767008066177368
Validation loss: 2.300598638520824
Epoch: 9| Step: 10
Training loss: 2.7184958457946777
Validation loss: 2.298625143311864
Epoch: 9| Step: 11
Training loss: 2.5982444286346436
Validation loss: 2.3007425249909326
Epoch: 9| Step: 12
Training loss: 2.8882837295532227
Validation loss: 2.3024897746902577
Epoch: 9| Step: 13
Training loss: 2.566063404083252
Validation loss: 2.3014694426557143
Epoch: 9| Step: 14
Training loss: 3.0612289905548096
Validation loss: 2.3033111781525095
Epoch: 9| Step: 15
Training loss: 2.652759075164795
Validation loss: 2.3001350876238704
Epoch: 9| Step: 16
Training loss: 2.9862356185913086
Validation loss: 2.3025717186413224
Epoch: 9| Step: 17
Training loss: 2.3271334171295166
Validation loss: 2.3003896689243453
Epoch: 9| Step: 18
Training loss: 2.6576285362243652
Validation loss: 2.3007200278824183
Epoch: 9| Step: 19
Training loss: 3.5236034393310547
Validation loss: 2.30461237327658
Epoch: 142| Step: 0
Training loss: 3.376249313354492
Validation loss: 2.3004317266477954
Epoch: 9| Step: 1
Training loss: 3.1804583072662354
Validation loss: 2.2986950702804454
Epoch: 9| Step: 2
Training loss: 2.550748109817505
Validation loss: 2.3026470211770036
Epoch: 9| Step: 3
Training loss: 2.6770663261413574
Validation loss: 2.301404045640136
Epoch: 9| Step: 4
Training loss: 2.165924310684204
Validation loss: 2.3031311549728724
Epoch: 9| Step: 5
Training loss: 2.887071132659912
Validation loss: 2.3012860747550032
Epoch: 9| Step: 6
Training loss: 2.421370506286621
Validation loss: 2.301677383964868
Epoch: 9| Step: 7
Training loss: 3.287283420562744
Validation loss: 2.3021734841435935
Epoch: 9| Step: 8
Training loss: 3.5387320518493652
Validation loss: 2.3004067115646474
Epoch: 9| Step: 9
Training loss: 2.3908681869506836
Validation loss: 2.300679108221754
Epoch: 9| Step: 10
Training loss: 2.3494925498962402
Validation loss: 2.3014059975850496
Epoch: 9| Step: 11
Training loss: 2.902425527572632
Validation loss: 2.2995520409920234
Epoch: 9| Step: 12
Training loss: 2.443101406097412
Validation loss: 2.3003353643760405
Epoch: 9| Step: 13
Training loss: 3.1450653076171875
Validation loss: 2.302526043473388
Epoch: 9| Step: 14
Training loss: 2.945951223373413
Validation loss: 2.2996637306625036
Epoch: 9| Step: 15
Training loss: 2.959040641784668
Validation loss: 2.301336983124987
Epoch: 9| Step: 16
Training loss: 2.573730230331421
Validation loss: 2.298027510265652
Epoch: 9| Step: 17
Training loss: 3.0632762908935547
Validation loss: 2.301421726350304
Epoch: 9| Step: 18
Training loss: 2.9511728286743164
Validation loss: 2.2976048061315963
Epoch: 9| Step: 19
Training loss: 2.6262600421905518
Validation loss: 2.304330089967028
Epoch: 143| Step: 0
Training loss: 3.218883991241455
Validation loss: 2.301294292477395
Epoch: 9| Step: 1
Training loss: 2.527376174926758
Validation loss: 2.304526395934949
Epoch: 9| Step: 2
Training loss: 3.0635085105895996
Validation loss: 2.3040597816165405
Epoch: 9| Step: 3
Training loss: 2.9802184104919434
Validation loss: 2.3020790206442636
Epoch: 9| Step: 4
Training loss: 2.7744734287261963
Validation loss: 2.303561401024139
Epoch: 9| Step: 5
Training loss: 3.1657464504241943
Validation loss: 2.3047310294007226
Epoch: 9| Step: 6
Training loss: 2.5826430320739746
Validation loss: 2.3052183484001985
Epoch: 9| Step: 7
Training loss: 2.7913808822631836
Validation loss: 2.304722090419248
Epoch: 9| Step: 8
Training loss: 2.6104369163513184
Validation loss: 2.3073193735355955
Epoch: 9| Step: 9
Training loss: 3.1162729263305664
Validation loss: 2.3064771676235063
Epoch: 9| Step: 10
Training loss: 2.980011463165283
Validation loss: 2.3050117801419265
Epoch: 9| Step: 11
Training loss: 2.7322115898132324
Validation loss: 2.306897129086282
Epoch: 9| Step: 12
Training loss: 3.295775890350342
Validation loss: 2.3030618077559435
Epoch: 9| Step: 13
Training loss: 2.7881906032562256
Validation loss: 2.3037318274271574
Epoch: 9| Step: 14
Training loss: 3.271732807159424
Validation loss: 2.303402139128541
Epoch: 9| Step: 15
Training loss: 1.7670018672943115
Validation loss: 2.3008461084297234
Epoch: 9| Step: 16
Training loss: 2.594794273376465
Validation loss: 2.3008419592603504
Epoch: 9| Step: 17
Training loss: 2.860593557357788
Validation loss: 2.300013850061156
Epoch: 9| Step: 18
Training loss: 2.5232577323913574
Validation loss: 2.297396409425804
Epoch: 9| Step: 19
Training loss: 2.846069812774658
Validation loss: 2.2965768035367238
Epoch: 144| Step: 0
Training loss: 2.606009006500244
Validation loss: 2.297580988287068
Epoch: 9| Step: 1
Training loss: 3.2986397743225098
Validation loss: 2.298905647058281
Epoch: 9| Step: 2
Training loss: 2.3385136127471924
Validation loss: 2.296805103905767
Epoch: 9| Step: 3
Training loss: 2.238682746887207
Validation loss: 2.2996295716265123
Epoch: 9| Step: 4
Training loss: 2.907064914703369
Validation loss: 2.2994969028363124
Epoch: 9| Step: 5
Training loss: 2.9807839393615723
Validation loss: 2.2987138933415037
Epoch: 9| Step: 6
Training loss: 3.3599367141723633
Validation loss: 2.301639671805951
Epoch: 9| Step: 7
Training loss: 2.305004119873047
Validation loss: 2.3001152971665637
Epoch: 9| Step: 8
Training loss: 3.593843460083008
Validation loss: 2.298787290243794
Epoch: 9| Step: 9
Training loss: 2.07967209815979
Validation loss: 2.3024230174881093
Epoch: 9| Step: 10
Training loss: 2.830228805541992
Validation loss: 2.3001901125736373
Epoch: 9| Step: 11
Training loss: 3.4518370628356934
Validation loss: 2.3008119836985634
Epoch: 9| Step: 12
Training loss: 2.685166120529175
Validation loss: 2.300782754266862
Epoch: 9| Step: 13
Training loss: 2.8874993324279785
Validation loss: 2.299159176058049
Epoch: 9| Step: 14
Training loss: 3.378143787384033
Validation loss: 2.300849255898016
Epoch: 9| Step: 15
Training loss: 2.547095775604248
Validation loss: 2.2983815670013428
Epoch: 9| Step: 16
Training loss: 2.6304306983947754
Validation loss: 2.3006899099555804
Epoch: 9| Step: 17
Training loss: 2.8306472301483154
Validation loss: 2.302621416050753
Epoch: 9| Step: 18
Training loss: 2.8879480361938477
Validation loss: 2.2996069021362193
Epoch: 9| Step: 19
Training loss: 2.637554407119751
Validation loss: 2.2998832438489516
Epoch: 145| Step: 0
Training loss: 3.136138439178467
Validation loss: 2.299876648745091
Epoch: 9| Step: 1
Training loss: 2.7366855144500732
Validation loss: 2.3008163438426505
Epoch: 9| Step: 2
Training loss: 3.035407543182373
Validation loss: 2.298396551351753
Epoch: 9| Step: 3
Training loss: 2.4807851314544678
Validation loss: 2.3014567078446313
Epoch: 9| Step: 4
Training loss: 2.5770130157470703
Validation loss: 2.299409461535996
Epoch: 9| Step: 5
Training loss: 3.0572357177734375
Validation loss: 2.3024915276671485
Epoch: 9| Step: 6
Training loss: 3.0930302143096924
Validation loss: 2.3010584398996916
Epoch: 9| Step: 7
Training loss: 2.9117608070373535
Validation loss: 2.3018537751204677
Epoch: 9| Step: 8
Training loss: 2.21128511428833
Validation loss: 2.298438723996389
Epoch: 9| Step: 9
Training loss: 2.4117369651794434
Validation loss: 2.299205521027819
Epoch: 9| Step: 10
Training loss: 3.0231809616088867
Validation loss: 2.296523329165342
Epoch: 9| Step: 11
Training loss: 2.569471836090088
Validation loss: 2.2992148356471986
Epoch: 9| Step: 12
Training loss: 3.384660243988037
Validation loss: 2.2967535214458437
Epoch: 9| Step: 13
Training loss: 3.84433650970459
Validation loss: 2.300050026221241
Epoch: 9| Step: 14
Training loss: 3.2449164390563965
Validation loss: 2.301114801022646
Epoch: 9| Step: 15
Training loss: 3.0709056854248047
Validation loss: 2.298235625671826
Epoch: 9| Step: 16
Training loss: 2.443415641784668
Validation loss: 2.298034502447938
Epoch: 9| Step: 17
Training loss: 2.2884304523468018
Validation loss: 2.30012229020647
Epoch: 9| Step: 18
Training loss: 2.248572826385498
Validation loss: 2.300043306762366
Epoch: 9| Step: 19
Training loss: 2.5911495685577393
Validation loss: 2.2967345577349767
Epoch: 146| Step: 0
Training loss: 2.351238489151001
Validation loss: 2.2981038865425605
Epoch: 9| Step: 1
Training loss: 3.393660545349121
Validation loss: 2.2998666523171845
Epoch: 9| Step: 2
Training loss: 2.656343936920166
Validation loss: 2.2998736419266077
Epoch: 9| Step: 3
Training loss: 2.705681324005127
Validation loss: 2.29599938632773
Epoch: 9| Step: 4
Training loss: 2.5264194011688232
Validation loss: 2.298937917613297
Epoch: 9| Step: 5
Training loss: 3.345000743865967
Validation loss: 2.3015655613631654
Epoch: 9| Step: 6
Training loss: 2.5443077087402344
Validation loss: 2.3019127614206547
Epoch: 9| Step: 7
Training loss: 3.0937206745147705
Validation loss: 2.2991952930422994
Epoch: 9| Step: 8
Training loss: 3.013519763946533
Validation loss: 2.2960195026809362
Epoch: 9| Step: 9
Training loss: 2.869084358215332
Validation loss: 2.2980059634009713
Epoch: 9| Step: 10
Training loss: 2.8916893005371094
Validation loss: 2.2969988061369753
Epoch: 9| Step: 11
Training loss: 2.335022449493408
Validation loss: 2.3004772294339517
Epoch: 9| Step: 12
Training loss: 2.487309217453003
Validation loss: 2.297374235640327
Epoch: 9| Step: 13
Training loss: 2.937771797180176
Validation loss: 2.2985750170920394
Epoch: 9| Step: 14
Training loss: 3.2081005573272705
Validation loss: 2.2982329396035173
Epoch: 9| Step: 15
Training loss: 2.8136847019195557
Validation loss: 2.2954626923842394
Epoch: 9| Step: 16
Training loss: 3.452803611755371
Validation loss: 2.2983447630628406
Epoch: 9| Step: 17
Training loss: 3.135796070098877
Validation loss: 2.298141990634177
Epoch: 9| Step: 18
Training loss: 2.1557719707489014
Validation loss: 2.297311968083004
Epoch: 9| Step: 19
Training loss: 2.467205047607422
Validation loss: 2.298124472871959
Epoch: 147| Step: 0
Training loss: 3.128417491912842
Validation loss: 2.299125532452151
Epoch: 9| Step: 1
Training loss: 2.1688811779022217
Validation loss: 2.298782254294526
Epoch: 9| Step: 2
Training loss: 3.624760627746582
Validation loss: 2.297063399561875
Epoch: 9| Step: 3
Training loss: 2.904942512512207
Validation loss: 2.2952819342235866
Epoch: 9| Step: 4
Training loss: 2.7149031162261963
Validation loss: 2.2959496306000853
Epoch: 9| Step: 5
Training loss: 2.511197566986084
Validation loss: 2.296757677476183
Epoch: 9| Step: 6
Training loss: 3.13259220123291
Validation loss: 2.2956834233922065
Epoch: 9| Step: 7
Training loss: 3.2318782806396484
Validation loss: 2.298481866610136
Epoch: 9| Step: 8
Training loss: 2.535648822784424
Validation loss: 2.2983227745234536
Epoch: 9| Step: 9
Training loss: 2.4903550148010254
Validation loss: 2.2956220297504673
Epoch: 9| Step: 10
Training loss: 3.4196527004241943
Validation loss: 2.295210838317871
Epoch: 9| Step: 11
Training loss: 2.6898016929626465
Validation loss: 2.2968076064432266
Epoch: 9| Step: 12
Training loss: 3.3132143020629883
Validation loss: 2.2934117257166253
Epoch: 9| Step: 13
Training loss: 2.655287504196167
Validation loss: 2.2985792983350137
Epoch: 9| Step: 14
Training loss: 2.351883888244629
Validation loss: 2.295362645773579
Epoch: 9| Step: 15
Training loss: 2.79243803024292
Validation loss: 2.298521913212838
Epoch: 9| Step: 16
Training loss: 2.729473114013672
Validation loss: 2.2964742749715024
Epoch: 9| Step: 17
Training loss: 2.3456010818481445
Validation loss: 2.2965894997548713
Epoch: 9| Step: 18
Training loss: 2.9594597816467285
Validation loss: 2.298254160572299
Epoch: 9| Step: 19
Training loss: 2.6229467391967773
Validation loss: 2.2988094545954425
Epoch: 148| Step: 0
Training loss: 2.1684556007385254
Validation loss: 2.293169532748435
Epoch: 9| Step: 1
Training loss: 2.4375786781311035
Validation loss: 2.292410980883262
Epoch: 9| Step: 2
Training loss: 2.92930269241333
Validation loss: 2.2984530188196857
Epoch: 9| Step: 3
Training loss: 3.0650267601013184
Validation loss: 2.295324449058917
Epoch: 9| Step: 4
Training loss: 2.469496250152588
Validation loss: 2.296029566003264
Epoch: 9| Step: 5
Training loss: 2.864004611968994
Validation loss: 2.2962053885562814
Epoch: 9| Step: 6
Training loss: 2.965874671936035
Validation loss: 2.295320610348269
Epoch: 9| Step: 7
Training loss: 2.717883586883545
Validation loss: 2.2978625829271278
Epoch: 9| Step: 8
Training loss: 3.073798179626465
Validation loss: 2.297253634432237
Epoch: 9| Step: 9
Training loss: 2.560722589492798
Validation loss: 2.2955455951553456
Epoch: 9| Step: 10
Training loss: 2.923494815826416
Validation loss: 2.2985884114135082
Epoch: 9| Step: 11
Training loss: 3.0804131031036377
Validation loss: 2.2936857672904036
Epoch: 9| Step: 12
Training loss: 3.400857448577881
Validation loss: 2.2953861257155164
Epoch: 9| Step: 13
Training loss: 2.8080382347106934
Validation loss: 2.2987732561372165
Epoch: 9| Step: 14
Training loss: 3.5112762451171875
Validation loss: 2.297468645109547
Epoch: 9| Step: 15
Training loss: 2.4347667694091797
Validation loss: 2.294401352354091
Epoch: 9| Step: 16
Training loss: 2.9543867111206055
Validation loss: 2.299141535656058
Epoch: 9| Step: 17
Training loss: 2.767740488052368
Validation loss: 2.296296133411874
Epoch: 9| Step: 18
Training loss: 2.67240571975708
Validation loss: 2.297971583956437
Epoch: 9| Step: 19
Training loss: 2.5302252769470215
Validation loss: 2.296926736831665
Epoch: 149| Step: 0
Training loss: 3.066333532333374
Validation loss: 2.293210425822855
Epoch: 9| Step: 1
Training loss: 2.9137911796569824
Validation loss: 2.2970833992786543
Epoch: 9| Step: 2
Training loss: 3.0354154109954834
Validation loss: 2.2946135277370754
Epoch: 9| Step: 3
Training loss: 3.2487995624542236
Validation loss: 2.2953494504201326
Epoch: 9| Step: 4
Training loss: 2.3771800994873047
Validation loss: 2.29645777606278
Epoch: 9| Step: 5
Training loss: 2.709523916244507
Validation loss: 2.296018324309973
Epoch: 9| Step: 6
Training loss: 2.9298887252807617
Validation loss: 2.295172669047074
Epoch: 9| Step: 7
Training loss: 2.6762874126434326
Validation loss: 2.2951555646580757
Epoch: 9| Step: 8
Training loss: 3.1686971187591553
Validation loss: 2.2928903608871023
Epoch: 9| Step: 9
Training loss: 3.325390577316284
Validation loss: 2.29404502120807
Epoch: 9| Step: 10
Training loss: 3.8941664695739746
Validation loss: 2.2961662982007582
Epoch: 9| Step: 11
Training loss: 3.1702969074249268
Validation loss: 2.2943705363239317
Epoch: 9| Step: 12
Training loss: 2.777836322784424
Validation loss: 2.2926716358541586
Epoch: 9| Step: 13
Training loss: 3.5212998390197754
Validation loss: 2.293201187531725
Epoch: 9| Step: 14
Training loss: 2.515967845916748
Validation loss: 2.294661700296745
Epoch: 9| Step: 15
Training loss: 1.8686091899871826
Validation loss: 2.2942890057460867
Epoch: 9| Step: 16
Training loss: 2.388153553009033
Validation loss: 2.294127798766541
Epoch: 9| Step: 17
Training loss: 2.13571834564209
Validation loss: 2.2947751369407707
Epoch: 9| Step: 18
Training loss: 2.45139217376709
Validation loss: 2.2938607845375008
Epoch: 9| Step: 19
Training loss: 2.169506549835205
Validation loss: 2.296347643831651
Epoch: 150| Step: 0
Training loss: 2.5715503692626953
Validation loss: 2.2951552490536256
Epoch: 9| Step: 1
Training loss: 3.397367000579834
Validation loss: 2.295006546185171
Epoch: 9| Step: 2
Training loss: 3.3079113960266113
Validation loss: 2.294579171448303
Epoch: 9| Step: 3
Training loss: 2.2929420471191406
Validation loss: 2.294430852793961
Epoch: 9| Step: 4
Training loss: 2.1839072704315186
Validation loss: 2.295256165291766
Epoch: 9| Step: 5
Training loss: 1.2223374843597412
Validation loss: 2.2928564531340014
Epoch: 9| Step: 6
Training loss: 2.3093063831329346
Validation loss: 2.295667164617305
Epoch: 9| Step: 7
Training loss: 2.264535427093506
Validation loss: 2.2939387482704876
Epoch: 9| Step: 8
Training loss: 3.0449981689453125
Validation loss: 2.295491216851653
Epoch: 9| Step: 9
Training loss: 2.6741085052490234
Validation loss: 2.2956173008294414
Epoch: 9| Step: 10
Training loss: 3.607508659362793
Validation loss: 2.2965074100082727
Epoch: 9| Step: 11
Training loss: 2.6754326820373535
Validation loss: 2.2956008293645844
Epoch: 9| Step: 12
Training loss: 3.033402681350708
Validation loss: 2.297969387589599
Epoch: 9| Step: 13
Training loss: 2.535443067550659
Validation loss: 2.292192225833591
Epoch: 9| Step: 14
Training loss: 3.1653547286987305
Validation loss: 2.29601984401401
Epoch: 9| Step: 15
Training loss: 3.2730422019958496
Validation loss: 2.2937980641564018
Epoch: 9| Step: 16
Training loss: 4.066858291625977
Validation loss: 2.297033903410109
Epoch: 9| Step: 17
Training loss: 3.1427416801452637
Validation loss: 2.292413654087259
Epoch: 9| Step: 18
Training loss: 3.1268980503082275
Validation loss: 2.2922742349638354
Epoch: 9| Step: 19
Training loss: 2.4029548168182373
Validation loss: 2.294447902295229
Epoch: 151| Step: 0
Training loss: 2.483226776123047
Validation loss: 2.2958547828866425
Epoch: 9| Step: 1
Training loss: 3.1519312858581543
Validation loss: 2.29266490181573
Epoch: 9| Step: 2
Training loss: 2.6577563285827637
Validation loss: 2.291676118219499
Epoch: 9| Step: 3
Training loss: 2.7614660263061523
Validation loss: 2.2920794872928867
Epoch: 9| Step: 4
Training loss: 3.2994346618652344
Validation loss: 2.2938307763861236
Epoch: 9| Step: 5
Training loss: 3.2102577686309814
Validation loss: 2.2940156511265597
Epoch: 9| Step: 6
Training loss: 2.8914384841918945
Validation loss: 2.293237850820418
Epoch: 9| Step: 7
Training loss: 2.5322036743164062
Validation loss: 2.2923593486813334
Epoch: 9| Step: 8
Training loss: 2.5974738597869873
Validation loss: 2.2929966724176203
Epoch: 9| Step: 9
Training loss: 2.971656560897827
Validation loss: 2.2921696069429247
Epoch: 9| Step: 10
Training loss: 3.1669390201568604
Validation loss: 2.294218262322515
Epoch: 9| Step: 11
Training loss: 2.8405768871307373
Validation loss: 2.293725823326934
Epoch: 9| Step: 12
Training loss: 2.365147113800049
Validation loss: 2.2933259747868817
Epoch: 9| Step: 13
Training loss: 3.5027823448181152
Validation loss: 2.2940946311401804
Epoch: 9| Step: 14
Training loss: 2.6895182132720947
Validation loss: 2.2931673115105937
Epoch: 9| Step: 15
Training loss: 2.444462537765503
Validation loss: 2.291346424775158
Epoch: 9| Step: 16
Training loss: 3.197944402694702
Validation loss: 2.2946804924834545
Epoch: 9| Step: 17
Training loss: 2.350146532058716
Validation loss: 2.2925973273009705
Epoch: 9| Step: 18
Training loss: 2.6059865951538086
Validation loss: 2.2920274442906003
Epoch: 9| Step: 19
Training loss: 2.5495059490203857
Validation loss: 2.299175914242971
Epoch: 152| Step: 0
Training loss: 2.709353446960449
Validation loss: 2.292912896588552
Epoch: 9| Step: 1
Training loss: 2.624512195587158
Validation loss: 2.293912707472877
Epoch: 9| Step: 2
Training loss: 3.757117986679077
Validation loss: 2.2983862187364976
Epoch: 9| Step: 3
Training loss: 2.0099265575408936
Validation loss: 2.2963128132785826
Epoch: 9| Step: 4
Training loss: 2.596153497695923
Validation loss: 2.2940763500954606
Epoch: 9| Step: 5
Training loss: 2.4553279876708984
Validation loss: 2.292237547661761
Epoch: 9| Step: 6
Training loss: 2.455533027648926
Validation loss: 2.292661995338879
Epoch: 9| Step: 7
Training loss: 2.5547595024108887
Validation loss: 2.2898406347782494
Epoch: 9| Step: 8
Training loss: 2.1193222999572754
Validation loss: 2.2910859567655932
Epoch: 9| Step: 9
Training loss: 3.0326905250549316
Validation loss: 2.2917997562627996
Epoch: 9| Step: 10
Training loss: 3.007162094116211
Validation loss: 2.2888734872392615
Epoch: 9| Step: 11
Training loss: 2.763270378112793
Validation loss: 2.291566616339649
Epoch: 9| Step: 12
Training loss: 3.215984582901001
Validation loss: 2.292786064765436
Epoch: 9| Step: 13
Training loss: 3.563082695007324
Validation loss: 2.2936299010146435
Epoch: 9| Step: 14
Training loss: 2.1862170696258545
Validation loss: 2.2924070564105357
Epoch: 9| Step: 15
Training loss: 3.0977258682250977
Validation loss: 2.289103789295224
Epoch: 9| Step: 16
Training loss: 3.5925183296203613
Validation loss: 2.292484581041679
Epoch: 9| Step: 17
Training loss: 3.5625057220458984
Validation loss: 2.2894193028374543
Epoch: 9| Step: 18
Training loss: 2.3079581260681152
Validation loss: 2.291352277179416
Epoch: 9| Step: 19
Training loss: 2.6502604484558105
Validation loss: 2.2925978821816204
Epoch: 153| Step: 0
Training loss: 2.955913543701172
Validation loss: 2.2886010965855004
Epoch: 9| Step: 1
Training loss: 3.187838554382324
Validation loss: 2.2908856234104515
Epoch: 9| Step: 2
Training loss: 2.6175355911254883
Validation loss: 2.2895826032693436
Epoch: 9| Step: 3
Training loss: 3.485572099685669
Validation loss: 2.292300242314236
Epoch: 9| Step: 4
Training loss: 2.8127074241638184
Validation loss: 2.2893757236947256
Epoch: 9| Step: 5
Training loss: 2.916818618774414
Validation loss: 2.2905151423790473
Epoch: 9| Step: 6
Training loss: 2.949411392211914
Validation loss: 2.2885224699116438
Epoch: 9| Step: 7
Training loss: 3.216928005218506
Validation loss: 2.291916246894452
Epoch: 9| Step: 8
Training loss: 2.2684006690979004
Validation loss: 2.2902194132907785
Epoch: 9| Step: 9
Training loss: 2.933713436126709
Validation loss: 2.2899402422870665
Epoch: 9| Step: 10
Training loss: 3.1486148834228516
Validation loss: 2.290478634319717
Epoch: 9| Step: 11
Training loss: 3.001866340637207
Validation loss: 2.291187757210766
Epoch: 9| Step: 12
Training loss: 1.8105239868164062
Validation loss: 2.292282774294023
Epoch: 9| Step: 13
Training loss: 2.636603355407715
Validation loss: 2.2907348005034085
Epoch: 9| Step: 14
Training loss: 3.0538389682769775
Validation loss: 2.285523719924817
Epoch: 9| Step: 15
Training loss: 2.1528196334838867
Validation loss: 2.2894086271738834
Epoch: 9| Step: 16
Training loss: 2.6671180725097656
Validation loss: 2.293019272440629
Epoch: 9| Step: 17
Training loss: 3.280726909637451
Validation loss: 2.2909454990633957
Epoch: 9| Step: 18
Training loss: 2.9586825370788574
Validation loss: 2.2929620519816445
Epoch: 9| Step: 19
Training loss: 2.198242664337158
Validation loss: 2.2874347031545295
Epoch: 154| Step: 0
Training loss: 2.439931869506836
Validation loss: 2.2900496172390397
Epoch: 9| Step: 1
Training loss: 2.856346368789673
Validation loss: 2.2880071495934358
Epoch: 9| Step: 2
Training loss: 3.05173921585083
Validation loss: 2.2885860796455
Epoch: 9| Step: 3
Training loss: 2.4906387329101562
Validation loss: 2.28963781260758
Epoch: 9| Step: 4
Training loss: 3.356248378753662
Validation loss: 2.287941644517638
Epoch: 9| Step: 5
Training loss: 2.2689483165740967
Validation loss: 2.290256340726674
Epoch: 9| Step: 6
Training loss: 3.0029971599578857
Validation loss: 2.2889707495840335
Epoch: 9| Step: 7
Training loss: 3.3983592987060547
Validation loss: 2.287442720193657
Epoch: 9| Step: 8
Training loss: 2.0942442417144775
Validation loss: 2.289128044526354
Epoch: 9| Step: 9
Training loss: 3.201608180999756
Validation loss: 2.2894053236186074
Epoch: 9| Step: 10
Training loss: 2.869408130645752
Validation loss: 2.288380032820667
Epoch: 9| Step: 11
Training loss: 2.5722527503967285
Validation loss: 2.289750750973928
Epoch: 9| Step: 12
Training loss: 2.689514636993408
Validation loss: 2.290329030091814
Epoch: 9| Step: 13
Training loss: 3.1514110565185547
Validation loss: 2.2876930691355426
Epoch: 9| Step: 14
Training loss: 2.9159836769104004
Validation loss: 2.2882487928267006
Epoch: 9| Step: 15
Training loss: 3.158858299255371
Validation loss: 2.289209775787463
Epoch: 9| Step: 16
Training loss: 2.1685540676116943
Validation loss: 2.2889417212644068
Epoch: 9| Step: 17
Training loss: 2.9427273273468018
Validation loss: 2.2897485074379462
Epoch: 9| Step: 18
Training loss: 2.826704502105713
Validation loss: 2.2905103525669457
Epoch: 9| Step: 19
Training loss: 2.720468759536743
Validation loss: 2.291310102819539
Epoch: 155| Step: 0
Training loss: 2.7943122386932373
Validation loss: 2.2897779915830214
Epoch: 9| Step: 1
Training loss: 2.9348013401031494
Validation loss: 2.293136749336188
Epoch: 9| Step: 2
Training loss: 2.634829044342041
Validation loss: 2.29044467596699
Epoch: 9| Step: 3
Training loss: 2.1083436012268066
Validation loss: 2.290402018766609
Epoch: 9| Step: 4
Training loss: 2.892216682434082
Validation loss: 2.2884568224707955
Epoch: 9| Step: 5
Training loss: 3.251365900039673
Validation loss: 2.2892555607308585
Epoch: 9| Step: 6
Training loss: 2.914679765701294
Validation loss: 2.2875898570465525
Epoch: 9| Step: 7
Training loss: 2.4488372802734375
Validation loss: 2.2923310437648414
Epoch: 9| Step: 8
Training loss: 2.8005552291870117
Validation loss: 2.2938039560112164
Epoch: 9| Step: 9
Training loss: 2.794599771499634
Validation loss: 2.2897054994706627
Epoch: 9| Step: 10
Training loss: 3.0860581398010254
Validation loss: 2.28891927561314
Epoch: 9| Step: 11
Training loss: 3.100684642791748
Validation loss: 2.290862579139874
Epoch: 9| Step: 12
Training loss: 2.9061427116394043
Validation loss: 2.2890030257135843
Epoch: 9| Step: 13
Training loss: 2.9566056728363037
Validation loss: 2.2901719302582224
Epoch: 9| Step: 14
Training loss: 2.6912755966186523
Validation loss: 2.2889133100029375
Epoch: 9| Step: 15
Training loss: 3.0317680835723877
Validation loss: 2.2892977745412924
Epoch: 9| Step: 16
Training loss: 2.1289405822753906
Validation loss: 2.290200109962079
Epoch: 9| Step: 17
Training loss: 3.2644386291503906
Validation loss: 2.2884371392160867
Epoch: 9| Step: 18
Training loss: 2.9249916076660156
Validation loss: 2.2892973371546903
Epoch: 9| Step: 19
Training loss: 2.6005489826202393
Validation loss: 2.290663254346779
Epoch: 156| Step: 0
Training loss: 2.0323221683502197
Validation loss: 2.2912519235405133
Epoch: 9| Step: 1
Training loss: 2.062873363494873
Validation loss: 2.289837442713676
Epoch: 9| Step: 2
Training loss: 2.814138412475586
Validation loss: 2.287944739671062
Epoch: 9| Step: 3
Training loss: 2.66041898727417
Validation loss: 2.287445764747455
Epoch: 9| Step: 4
Training loss: 2.8316385746002197
Validation loss: 2.287817419861718
Epoch: 9| Step: 5
Training loss: 2.802065849304199
Validation loss: 2.288651883173332
Epoch: 9| Step: 6
Training loss: 3.378413677215576
Validation loss: 2.2921427488327026
Epoch: 9| Step: 7
Training loss: 2.575639009475708
Validation loss: 2.2903151846618104
Epoch: 9| Step: 8
Training loss: 2.882333755493164
Validation loss: 2.28944636077332
Epoch: 9| Step: 9
Training loss: 3.1234819889068604
Validation loss: 2.291353803744419
Epoch: 9| Step: 10
Training loss: 3.4190759658813477
Validation loss: 2.2903529559965614
Epoch: 9| Step: 11
Training loss: 2.850277900695801
Validation loss: 2.2904149585490603
Epoch: 9| Step: 12
Training loss: 2.231428623199463
Validation loss: 2.295382775848718
Epoch: 9| Step: 13
Training loss: 2.7824795246124268
Validation loss: 2.2907774765714466
Epoch: 9| Step: 14
Training loss: 3.451561212539673
Validation loss: 2.2937449894363073
Epoch: 9| Step: 15
Training loss: 2.7083752155303955
Validation loss: 2.2940125499697896
Epoch: 9| Step: 16
Training loss: 3.190946578979492
Validation loss: 2.2898197328444008
Epoch: 9| Step: 17
Training loss: 2.2875475883483887
Validation loss: 2.2922228720548343
Epoch: 9| Step: 18
Training loss: 3.07769775390625
Validation loss: 2.2928090198434514
Epoch: 9| Step: 19
Training loss: 3.0627245903015137
Validation loss: 2.293808413924073
Epoch: 157| Step: 0
Training loss: 3.7588281631469727
Validation loss: 2.289707441981748
Epoch: 9| Step: 1
Training loss: 2.5189335346221924
Validation loss: 2.2897683862301945
Epoch: 9| Step: 2
Training loss: 2.9374961853027344
Validation loss: 2.285923052177155
Epoch: 9| Step: 3
Training loss: 2.6001734733581543
Validation loss: 2.2854715354151005
Epoch: 9| Step: 4
Training loss: 2.352288246154785
Validation loss: 2.286851325481058
Epoch: 9| Step: 5
Training loss: 2.718501091003418
Validation loss: 2.2878520111385865
Epoch: 9| Step: 6
Training loss: 2.648148536682129
Validation loss: 2.2878338364388444
Epoch: 9| Step: 7
Training loss: 2.2989516258239746
Validation loss: 2.2879816439511966
Epoch: 9| Step: 8
Training loss: 3.14823842048645
Validation loss: 2.286475234752079
Epoch: 9| Step: 9
Training loss: 3.422565460205078
Validation loss: 2.2855309402342323
Epoch: 9| Step: 10
Training loss: 2.876917839050293
Validation loss: 2.2869947548392866
Epoch: 9| Step: 11
Training loss: 2.31353497505188
Validation loss: 2.286461267539923
Epoch: 9| Step: 12
Training loss: 2.2134780883789062
Validation loss: 2.286193110102372
Epoch: 9| Step: 13
Training loss: 2.992640733718872
Validation loss: 2.287790878213567
Epoch: 9| Step: 14
Training loss: 2.9550671577453613
Validation loss: 2.2865898283265476
Epoch: 9| Step: 15
Training loss: 3.0226497650146484
Validation loss: 2.2864133917170464
Epoch: 9| Step: 16
Training loss: 2.898948907852173
Validation loss: 2.285815269826985
Epoch: 9| Step: 17
Training loss: 2.2427961826324463
Validation loss: 2.28802622994073
Epoch: 9| Step: 18
Training loss: 3.7771618366241455
Validation loss: 2.2867389119786323
Epoch: 9| Step: 19
Training loss: 2.5506701469421387
Validation loss: 2.2861516124052965
Epoch: 158| Step: 0
Training loss: 2.7835302352905273
Validation loss: 2.2859095618021574
Epoch: 9| Step: 1
Training loss: 3.0024819374084473
Validation loss: 2.2859227614437074
Epoch: 9| Step: 2
Training loss: 3.377516984939575
Validation loss: 2.286100388430863
Epoch: 9| Step: 3
Training loss: 2.596346855163574
Validation loss: 2.2863264049557475
Epoch: 9| Step: 4
Training loss: 2.7407407760620117
Validation loss: 2.2857541960777996
Epoch: 9| Step: 5
Training loss: 2.0886237621307373
Validation loss: 2.28778294865176
Epoch: 9| Step: 6
Training loss: 2.394930839538574
Validation loss: 2.289861605321761
Epoch: 9| Step: 7
Training loss: 2.843381881713867
Validation loss: 2.2872857172712147
Epoch: 9| Step: 8
Training loss: 2.9546847343444824
Validation loss: 2.2842460604880355
Epoch: 9| Step: 9
Training loss: 2.749177932739258
Validation loss: 2.2865335666876043
Epoch: 9| Step: 10
Training loss: 2.891763210296631
Validation loss: 2.2853931505903065
Epoch: 9| Step: 11
Training loss: 2.638451099395752
Validation loss: 2.285348119495584
Epoch: 9| Step: 12
Training loss: 3.044434070587158
Validation loss: 2.2867955098049246
Epoch: 9| Step: 13
Training loss: 3.077157974243164
Validation loss: 2.2865689246774576
Epoch: 9| Step: 14
Training loss: 3.2535791397094727
Validation loss: 2.283650497738406
Epoch: 9| Step: 15
Training loss: 3.101893186569214
Validation loss: 2.2864526192918957
Epoch: 9| Step: 16
Training loss: 2.3983285427093506
Validation loss: 2.285629674685087
Epoch: 9| Step: 17
Training loss: 2.9455225467681885
Validation loss: 2.2846237155173323
Epoch: 9| Step: 18
Training loss: 3.034242630004883
Validation loss: 2.2850069159226454
Epoch: 9| Step: 19
Training loss: 2.2806236743927
Validation loss: 2.287284538900252
Epoch: 159| Step: 0
Training loss: 2.9429445266723633
Validation loss: 2.2869093143682684
Epoch: 9| Step: 1
Training loss: 2.5074214935302734
Validation loss: 2.2834542337939037
Epoch: 9| Step: 2
Training loss: 3.1657819747924805
Validation loss: 2.2882216705692757
Epoch: 9| Step: 3
Training loss: 2.2612946033477783
Validation loss: 2.2844270347691267
Epoch: 9| Step: 4
Training loss: 3.029371976852417
Validation loss: 2.284289854035961
Epoch: 9| Step: 5
Training loss: 2.3920187950134277
Validation loss: 2.285552335300034
Epoch: 9| Step: 6
Training loss: 2.780594825744629
Validation loss: 2.2856441436054036
Epoch: 9| Step: 7
Training loss: 2.3953909873962402
Validation loss: 2.283771624668039
Epoch: 9| Step: 8
Training loss: 3.427750587463379
Validation loss: 2.282160661203398
Epoch: 9| Step: 9
Training loss: 3.6876657009124756
Validation loss: 2.2873640043272387
Epoch: 9| Step: 10
Training loss: 3.103640556335449
Validation loss: 2.284706966482478
Epoch: 9| Step: 11
Training loss: 2.0638022422790527
Validation loss: 2.2873526108350686
Epoch: 9| Step: 12
Training loss: 1.9828956127166748
Validation loss: 2.283481388640918
Epoch: 9| Step: 13
Training loss: 3.1016321182250977
Validation loss: 2.284727307532331
Epoch: 9| Step: 14
Training loss: 2.270937204360962
Validation loss: 2.282444941911766
Epoch: 9| Step: 15
Training loss: 2.7609570026397705
Validation loss: 2.2835744370659476
Epoch: 9| Step: 16
Training loss: 2.875087022781372
Validation loss: 2.28437743941657
Epoch: 9| Step: 17
Training loss: 2.8452305793762207
Validation loss: 2.28517658761937
Epoch: 9| Step: 18
Training loss: 2.9458274841308594
Validation loss: 2.286215613214232
Epoch: 9| Step: 19
Training loss: 3.5425562858581543
Validation loss: 2.2854276955556525
Epoch: 160| Step: 0
Training loss: 3.441748857498169
Validation loss: 2.286315295336058
Epoch: 9| Step: 1
Training loss: 2.526493549346924
Validation loss: 2.2847884421725926
Epoch: 9| Step: 2
Training loss: 2.149036407470703
Validation loss: 2.2840381303279518
Epoch: 9| Step: 3
Training loss: 2.695923328399658
Validation loss: 2.2880934116651686
Epoch: 9| Step: 4
Training loss: 3.2961549758911133
Validation loss: 2.286049388295455
Epoch: 9| Step: 5
Training loss: 2.324688196182251
Validation loss: 2.284985089473587
Epoch: 9| Step: 6
Training loss: 2.5396223068237305
Validation loss: 2.2866860122131785
Epoch: 9| Step: 7
Training loss: 2.765282154083252
Validation loss: 2.284505216337794
Epoch: 9| Step: 8
Training loss: 3.683117389678955
Validation loss: 2.286151081538029
Epoch: 9| Step: 9
Training loss: 2.617661237716675
Validation loss: 2.2851948497964325
Epoch: 9| Step: 10
Training loss: 3.403616428375244
Validation loss: 2.2863028006587953
Epoch: 9| Step: 11
Training loss: 2.7657206058502197
Validation loss: 2.2831669985819207
Epoch: 9| Step: 12
Training loss: 2.456111431121826
Validation loss: 2.284372285115633
Epoch: 9| Step: 13
Training loss: 2.2780022621154785
Validation loss: 2.283033684860888
Epoch: 9| Step: 14
Training loss: 2.198793888092041
Validation loss: 2.2838034269621046
Epoch: 9| Step: 15
Training loss: 3.1861937046051025
Validation loss: 2.2849462795600615
Epoch: 9| Step: 16
Training loss: 2.92410945892334
Validation loss: 2.2849188314067375
Epoch: 9| Step: 17
Training loss: 3.5461862087249756
Validation loss: 2.2854819743753336
Epoch: 9| Step: 18
Training loss: 3.0939249992370605
Validation loss: 2.2852862258609252
Epoch: 9| Step: 19
Training loss: 2.2175800800323486
Validation loss: 2.2847811300977527
Epoch: 161| Step: 0
Training loss: 2.4560604095458984
Validation loss: 2.2865604479535877
Epoch: 9| Step: 1
Training loss: 3.082486152648926
Validation loss: 2.2857863268406273
Epoch: 9| Step: 2
Training loss: 2.949018955230713
Validation loss: 2.2842208498673475
Epoch: 9| Step: 3
Training loss: 2.357191562652588
Validation loss: 2.2885688328914506
Epoch: 9| Step: 4
Training loss: 3.0908639430999756
Validation loss: 2.2873585721571668
Epoch: 9| Step: 5
Training loss: 3.0211877822875977
Validation loss: 2.290222709985088
Epoch: 9| Step: 6
Training loss: 2.023728847503662
Validation loss: 2.286737978887215
Epoch: 9| Step: 7
Training loss: 2.6094300746917725
Validation loss: 2.2850932200177967
Epoch: 9| Step: 8
Training loss: 3.106511354446411
Validation loss: 2.2858898236597183
Epoch: 9| Step: 9
Training loss: 2.189084529876709
Validation loss: 2.284227389225857
Epoch: 9| Step: 10
Training loss: 2.000239133834839
Validation loss: 2.2854095860350903
Epoch: 9| Step: 11
Training loss: 2.8352394104003906
Validation loss: 2.2851454559847606
Epoch: 9| Step: 12
Training loss: 3.0161447525024414
Validation loss: 2.2849491688844967
Epoch: 9| Step: 13
Training loss: 2.8011646270751953
Validation loss: 2.2815040598670357
Epoch: 9| Step: 14
Training loss: 3.5291337966918945
Validation loss: 2.283990581258595
Epoch: 9| Step: 15
Training loss: 2.7411603927612305
Validation loss: 2.2893236884110264
Epoch: 9| Step: 16
Training loss: 1.973949909210205
Validation loss: 2.2842763104884742
Epoch: 9| Step: 17
Training loss: 3.500122547149658
Validation loss: 2.2858839909807385
Epoch: 9| Step: 18
Training loss: 3.3966445922851562
Validation loss: 2.285511399344575
Epoch: 9| Step: 19
Training loss: 3.421804428100586
Validation loss: 2.284298370210387
Epoch: 162| Step: 0
Training loss: 2.7158050537109375
Validation loss: 2.28454409228812
Epoch: 9| Step: 1
Training loss: 2.7660274505615234
Validation loss: 2.2856669460269186
Epoch: 9| Step: 2
Training loss: 2.8714966773986816
Validation loss: 2.285589809897992
Epoch: 9| Step: 3
Training loss: 3.872826337814331
Validation loss: 2.283115272041705
Epoch: 9| Step: 4
Training loss: 2.8663270473480225
Validation loss: 2.2826556970747256
Epoch: 9| Step: 5
Training loss: 1.6328661441802979
Validation loss: 2.2847574992145567
Epoch: 9| Step: 6
Training loss: 2.239241600036621
Validation loss: 2.284012691580134
Epoch: 9| Step: 7
Training loss: 2.907196521759033
Validation loss: 2.2849294444639905
Epoch: 9| Step: 8
Training loss: 3.3634140491485596
Validation loss: 2.2851124615977993
Epoch: 9| Step: 9
Training loss: 3.101508617401123
Validation loss: 2.2849721797078635
Epoch: 9| Step: 10
Training loss: 2.8541345596313477
Validation loss: 2.283726517245066
Epoch: 9| Step: 11
Training loss: 2.410675048828125
Validation loss: 2.2836412337186527
Epoch: 9| Step: 12
Training loss: 2.981889486312866
Validation loss: 2.282733970408817
Epoch: 9| Step: 13
Training loss: 2.316819190979004
Validation loss: 2.2834933944743314
Epoch: 9| Step: 14
Training loss: 3.3864619731903076
Validation loss: 2.28025117366434
Epoch: 9| Step: 15
Training loss: 2.6757748126983643
Validation loss: 2.28499213311312
Epoch: 9| Step: 16
Training loss: 2.9396812915802
Validation loss: 2.2847186258370926
Epoch: 9| Step: 17
Training loss: 2.644791603088379
Validation loss: 2.284577820798476
Epoch: 9| Step: 18
Training loss: 2.6104207038879395
Validation loss: 2.28567510886158
Epoch: 9| Step: 19
Training loss: 2.9561119079589844
Validation loss: 2.2857208663611104
Epoch: 163| Step: 0
Training loss: 2.6400575637817383
Validation loss: 2.285486288207898
Epoch: 9| Step: 1
Training loss: 2.95900821685791
Validation loss: 2.2823315901721983
Epoch: 9| Step: 2
Training loss: 3.046144485473633
Validation loss: 2.282793472139098
Epoch: 9| Step: 3
Training loss: 2.2741036415100098
Validation loss: 2.28168113111592
Epoch: 9| Step: 4
Training loss: 3.299650192260742
Validation loss: 2.283287801330896
Epoch: 9| Step: 5
Training loss: 2.753476142883301
Validation loss: 2.282309141090448
Epoch: 9| Step: 6
Training loss: 2.757554054260254
Validation loss: 2.286231874561996
Epoch: 9| Step: 7
Training loss: 2.9635367393493652
Validation loss: 2.286131008065862
Epoch: 9| Step: 8
Training loss: 2.8944478034973145
Validation loss: 2.2863131307011884
Epoch: 9| Step: 9
Training loss: 2.7296242713928223
Validation loss: 2.2859438186069188
Epoch: 9| Step: 10
Training loss: 3.1398205757141113
Validation loss: 2.2887609125041277
Epoch: 9| Step: 11
Training loss: 2.9098777770996094
Validation loss: 2.2854436515904157
Epoch: 9| Step: 12
Training loss: 2.613621950149536
Validation loss: 2.283036406091649
Epoch: 9| Step: 13
Training loss: 1.9735112190246582
Validation loss: 2.2816047016665233
Epoch: 9| Step: 14
Training loss: 2.865062713623047
Validation loss: 2.28904732011205
Epoch: 9| Step: 15
Training loss: 3.312220573425293
Validation loss: 2.2817040767601067
Epoch: 9| Step: 16
Training loss: 2.797712802886963
Validation loss: 2.2859831525267458
Epoch: 9| Step: 17
Training loss: 3.2028279304504395
Validation loss: 2.2844226171644473
Epoch: 9| Step: 18
Training loss: 2.532215118408203
Validation loss: 2.283306962294544
Epoch: 9| Step: 19
Training loss: 2.371738910675049
Validation loss: 2.2838864446543963
Epoch: 164| Step: 0
Training loss: 2.891387462615967
Validation loss: 2.2816834689901886
Epoch: 9| Step: 1
Training loss: 3.054804801940918
Validation loss: 2.285888267077988
Epoch: 9| Step: 2
Training loss: 3.2659106254577637
Validation loss: 2.2817022320177913
Epoch: 9| Step: 3
Training loss: 2.437959671020508
Validation loss: 2.2840580923094165
Epoch: 9| Step: 4
Training loss: 3.441814661026001
Validation loss: 2.2849020426221887
Epoch: 9| Step: 5
Training loss: 3.4634838104248047
Validation loss: 2.2824488869673916
Epoch: 9| Step: 6
Training loss: 2.927140474319458
Validation loss: 2.283946051014413
Epoch: 9| Step: 7
Training loss: 2.337329864501953
Validation loss: 2.279433910795253
Epoch: 9| Step: 8
Training loss: 2.9408421516418457
Validation loss: 2.2839952115532305
Epoch: 9| Step: 9
Training loss: 3.3430352210998535
Validation loss: 2.285200464639732
Epoch: 9| Step: 10
Training loss: 2.4485580921173096
Validation loss: 2.282776733954176
Epoch: 9| Step: 11
Training loss: 2.2740252017974854
Validation loss: 2.2811872067211345
Epoch: 9| Step: 12
Training loss: 2.795663833618164
Validation loss: 2.2845963797123314
Epoch: 9| Step: 13
Training loss: 3.3438656330108643
Validation loss: 2.283228296170132
Epoch: 9| Step: 14
Training loss: 2.809922218322754
Validation loss: 2.2835621893834723
Epoch: 9| Step: 15
Training loss: 2.815685749053955
Validation loss: 2.280381255870243
Epoch: 9| Step: 16
Training loss: 2.0929927825927734
Validation loss: 2.279683136253906
Epoch: 9| Step: 17
Training loss: 2.5685830116271973
Validation loss: 2.283059593584898
Epoch: 9| Step: 18
Training loss: 2.801988124847412
Validation loss: 2.280155941736784
Epoch: 9| Step: 19
Training loss: 2.00577974319458
Validation loss: 2.282548768914861
Epoch: 165| Step: 0
Training loss: 2.672144889831543
Validation loss: 2.2838581397379043
Epoch: 9| Step: 1
Training loss: 3.131197690963745
Validation loss: 2.283220778266303
Epoch: 9| Step: 2
Training loss: 2.9815673828125
Validation loss: 2.2827836661030063
Epoch: 9| Step: 3
Training loss: 2.3472485542297363
Validation loss: 2.2816428640763537
Epoch: 9| Step: 4
Training loss: 2.3062691688537598
Validation loss: 2.278826029180623
Epoch: 9| Step: 5
Training loss: 3.196483612060547
Validation loss: 2.2799367424395443
Epoch: 9| Step: 6
Training loss: 2.7111563682556152
Validation loss: 2.281897839882391
Epoch: 9| Step: 7
Training loss: 2.8716237545013428
Validation loss: 2.2821556887180687
Epoch: 9| Step: 8
Training loss: 2.4131038188934326
Validation loss: 2.279971405756559
Epoch: 9| Step: 9
Training loss: 2.4738144874572754
Validation loss: 2.2830771705229504
Epoch: 9| Step: 10
Training loss: 2.065359592437744
Validation loss: 2.286245057908751
Epoch: 9| Step: 11
Training loss: 2.815359592437744
Validation loss: 2.283112212050733
Epoch: 9| Step: 12
Training loss: 3.6314454078674316
Validation loss: 2.2803570949773992
Epoch: 9| Step: 13
Training loss: 2.788240909576416
Validation loss: 2.2841593035691075
Epoch: 9| Step: 14
Training loss: 2.0950539112091064
Validation loss: 2.281183584988546
Epoch: 9| Step: 15
Training loss: 3.1692376136779785
Validation loss: 2.2807641526777966
Epoch: 9| Step: 16
Training loss: 3.3882007598876953
Validation loss: 2.2825123457599887
Epoch: 9| Step: 17
Training loss: 3.3694562911987305
Validation loss: 2.277995673872584
Epoch: 9| Step: 18
Training loss: 2.965566635131836
Validation loss: 2.2833472018619236
Epoch: 9| Step: 19
Training loss: 2.6320714950561523
Validation loss: 2.2822195814667845
Epoch: 166| Step: 0
Training loss: 2.8646979331970215
Validation loss: 2.2828163431702757
Epoch: 9| Step: 1
Training loss: 2.24804949760437
Validation loss: 2.281022289674059
Epoch: 9| Step: 2
Training loss: 3.047497272491455
Validation loss: 2.2797585905884667
Epoch: 9| Step: 3
Training loss: 2.7774784564971924
Validation loss: 2.281252821572393
Epoch: 9| Step: 4
Training loss: 2.687265396118164
Validation loss: 2.281149071755169
Epoch: 9| Step: 5
Training loss: 3.1748180389404297
Validation loss: 2.282342041139122
Epoch: 9| Step: 6
Training loss: 3.2675395011901855
Validation loss: 2.2813899688583485
Epoch: 9| Step: 7
Training loss: 2.141195774078369
Validation loss: 2.2805003948348888
Epoch: 9| Step: 8
Training loss: 2.8466804027557373
Validation loss: 2.283308857636486
Epoch: 9| Step: 9
Training loss: 3.5052103996276855
Validation loss: 2.2800877780365427
Epoch: 9| Step: 10
Training loss: 2.513742208480835
Validation loss: 2.281339906102462
Epoch: 9| Step: 11
Training loss: 3.5552310943603516
Validation loss: 2.27996190674871
Epoch: 9| Step: 12
Training loss: 2.475590705871582
Validation loss: 2.2819670095718165
Epoch: 9| Step: 13
Training loss: 3.3271679878234863
Validation loss: 2.2770258865768103
Epoch: 9| Step: 14
Training loss: 2.555323600769043
Validation loss: 2.278400394556334
Epoch: 9| Step: 15
Training loss: 2.9870686531066895
Validation loss: 2.2805374148938298
Epoch: 9| Step: 16
Training loss: 2.9507503509521484
Validation loss: 2.2801476948552852
Epoch: 9| Step: 17
Training loss: 2.8356542587280273
Validation loss: 2.276848539174032
Epoch: 9| Step: 18
Training loss: 1.8344271183013916
Validation loss: 2.2807560001345846
Epoch: 9| Step: 19
Training loss: 2.4343056678771973
Validation loss: 2.2783412676063373
Epoch: 167| Step: 0
Training loss: 1.9514262676239014
Validation loss: 2.2805603339517715
Epoch: 9| Step: 1
Training loss: 2.3392820358276367
Validation loss: 2.2782337819929603
Epoch: 9| Step: 2
Training loss: 2.82474684715271
Validation loss: 2.280001883884128
Epoch: 9| Step: 3
Training loss: 2.7943999767303467
Validation loss: 2.280171884907235
Epoch: 9| Step: 4
Training loss: 2.718252182006836
Validation loss: 2.2809577554249936
Epoch: 9| Step: 5
Training loss: 2.1362650394439697
Validation loss: 2.280338530060199
Epoch: 9| Step: 6
Training loss: 3.1872732639312744
Validation loss: 2.279066185299441
Epoch: 9| Step: 7
Training loss: 2.733013153076172
Validation loss: 2.2778895141409454
Epoch: 9| Step: 8
Training loss: 2.698753833770752
Validation loss: 2.2809182028118653
Epoch: 9| Step: 9
Training loss: 2.686220645904541
Validation loss: 2.2771209855731445
Epoch: 9| Step: 10
Training loss: 3.469816207885742
Validation loss: 2.2801978519494583
Epoch: 9| Step: 11
Training loss: 3.9428257942199707
Validation loss: 2.2791564293044932
Epoch: 9| Step: 12
Training loss: 3.0870814323425293
Validation loss: 2.2817428592297673
Epoch: 9| Step: 13
Training loss: 2.8661928176879883
Validation loss: 2.279851323409046
Epoch: 9| Step: 14
Training loss: 2.6450233459472656
Validation loss: 2.2776566460835848
Epoch: 9| Step: 15
Training loss: 2.5768065452575684
Validation loss: 2.2814403575101343
Epoch: 9| Step: 16
Training loss: 2.278198480606079
Validation loss: 2.2771060501071188
Epoch: 9| Step: 17
Training loss: 2.756459951400757
Validation loss: 2.280582678403786
Epoch: 9| Step: 18
Training loss: 3.4679102897644043
Validation loss: 2.2771421036274315
Epoch: 9| Step: 19
Training loss: 2.799647808074951
Validation loss: 2.279696854756033
Epoch: 168| Step: 0
Training loss: 2.499586820602417
Validation loss: 2.2796329800173534
Epoch: 9| Step: 1
Training loss: 2.892787456512451
Validation loss: 2.277593986593562
Epoch: 9| Step: 2
Training loss: 2.7898755073547363
Validation loss: 2.2799634264527464
Epoch: 9| Step: 3
Training loss: 3.0524370670318604
Validation loss: 2.278188515052521
Epoch: 9| Step: 4
Training loss: 2.612471580505371
Validation loss: 2.2763337728788526
Epoch: 9| Step: 5
Training loss: 2.845407485961914
Validation loss: 2.2811540733996054
Epoch: 9| Step: 6
Training loss: 3.1171441078186035
Validation loss: 2.278556065593692
Epoch: 9| Step: 7
Training loss: 2.2712860107421875
Validation loss: 2.277857715277363
Epoch: 9| Step: 8
Training loss: 3.133162021636963
Validation loss: 2.277910160503799
Epoch: 9| Step: 9
Training loss: 2.731405019760132
Validation loss: 2.2785650174394787
Epoch: 9| Step: 10
Training loss: 3.1687798500061035
Validation loss: 2.2798621911796735
Epoch: 9| Step: 11
Training loss: 2.267749309539795
Validation loss: 2.2793637239675726
Epoch: 9| Step: 12
Training loss: 3.249858856201172
Validation loss: 2.2804026758070473
Epoch: 9| Step: 13
Training loss: 2.749110221862793
Validation loss: 2.2805050825901167
Epoch: 9| Step: 14
Training loss: 2.714629650115967
Validation loss: 2.2845584763039786
Epoch: 9| Step: 15
Training loss: 2.604336738586426
Validation loss: 2.2771873997269774
Epoch: 9| Step: 16
Training loss: 2.7472171783447266
Validation loss: 2.2817101701558067
Epoch: 9| Step: 17
Training loss: 2.5713281631469727
Validation loss: 2.277136481923165
Epoch: 9| Step: 18
Training loss: 2.16160249710083
Validation loss: 2.2839090198064023
Epoch: 9| Step: 19
Training loss: 3.769256114959717
Validation loss: 2.281113182040427
Epoch: 169| Step: 0
Training loss: 2.264613151550293
Validation loss: 2.278554237146172
Epoch: 9| Step: 1
Training loss: 2.403214931488037
Validation loss: 2.283868447482157
Epoch: 9| Step: 2
Training loss: 3.3414931297302246
Validation loss: 2.2799020705463215
Epoch: 9| Step: 3
Training loss: 2.7431371212005615
Validation loss: 2.280909234671284
Epoch: 9| Step: 4
Training loss: 2.7285754680633545
Validation loss: 2.27898869583075
Epoch: 9| Step: 5
Training loss: 2.1443495750427246
Validation loss: 2.2786124541605117
Epoch: 9| Step: 6
Training loss: 3.1369524002075195
Validation loss: 2.2814620741837315
Epoch: 9| Step: 7
Training loss: 3.1135318279266357
Validation loss: 2.280962991199905
Epoch: 9| Step: 8
Training loss: 3.5236005783081055
Validation loss: 2.2794879477658716
Epoch: 9| Step: 9
Training loss: 3.055013656616211
Validation loss: 2.2788931877493
Epoch: 9| Step: 10
Training loss: 2.453866481781006
Validation loss: 2.2787994780986427
Epoch: 9| Step: 11
Training loss: 2.2647533416748047
Validation loss: 2.276884557531892
Epoch: 9| Step: 12
Training loss: 2.3292179107666016
Validation loss: 2.2783624422635964
Epoch: 9| Step: 13
Training loss: 3.241342067718506
Validation loss: 2.281596753237059
Epoch: 9| Step: 14
Training loss: 3.1643223762512207
Validation loss: 2.279492137243422
Epoch: 9| Step: 15
Training loss: 2.064690113067627
Validation loss: 2.2777276056275952
Epoch: 9| Step: 16
Training loss: 2.808990716934204
Validation loss: 2.2795706327012977
Epoch: 9| Step: 17
Training loss: 2.502351760864258
Validation loss: 2.276514326068137
Epoch: 9| Step: 18
Training loss: 3.4944756031036377
Validation loss: 2.2772303468031847
Epoch: 9| Step: 19
Training loss: 3.1390857696533203
Validation loss: 2.2781160984107918
Epoch: 170| Step: 0
Training loss: 1.6269421577453613
Validation loss: 2.275588088755985
Epoch: 9| Step: 1
Training loss: 2.6877217292785645
Validation loss: 2.2786946596859172
Epoch: 9| Step: 2
Training loss: 2.6989502906799316
Validation loss: 2.2770206550900025
Epoch: 9| Step: 3
Training loss: 3.3596572875976562
Validation loss: 2.275821841877999
Epoch: 9| Step: 4
Training loss: 3.0468597412109375
Validation loss: 2.2767451306898816
Epoch: 9| Step: 5
Training loss: 2.935673475265503
Validation loss: 2.2770195659116017
Epoch: 9| Step: 6
Training loss: 2.304837703704834
Validation loss: 2.2763773005643335
Epoch: 9| Step: 7
Training loss: 2.766350746154785
Validation loss: 2.274622399172337
Epoch: 9| Step: 8
Training loss: 2.535153865814209
Validation loss: 2.278144314134721
Epoch: 9| Step: 9
Training loss: 2.6467182636260986
Validation loss: 2.2772854129187494
Epoch: 9| Step: 10
Training loss: 3.641068458557129
Validation loss: 2.280225915874509
Epoch: 9| Step: 11
Training loss: 3.2794694900512695
Validation loss: 2.2759279415761826
Epoch: 9| Step: 12
Training loss: 2.825958251953125
Validation loss: 2.2749027965737763
Epoch: 9| Step: 13
Training loss: 2.7424228191375732
Validation loss: 2.2731508951392962
Epoch: 9| Step: 14
Training loss: 2.4762725830078125
Validation loss: 2.276134768835932
Epoch: 9| Step: 15
Training loss: 2.459196090698242
Validation loss: 2.2756955074749405
Epoch: 9| Step: 16
Training loss: 2.6605923175811768
Validation loss: 2.275799051463175
Epoch: 9| Step: 17
Training loss: 2.871365547180176
Validation loss: 2.276172744284431
Epoch: 9| Step: 18
Training loss: 3.2282485961914062
Validation loss: 2.277421599669422
Epoch: 9| Step: 19
Training loss: 3.137099266052246
Validation loss: 2.2738101422357904
Epoch: 171| Step: 0
Training loss: 3.2453815937042236
Validation loss: 2.2755121378589878
Epoch: 9| Step: 1
Training loss: 2.595160722732544
Validation loss: 2.2766945739444213
Epoch: 9| Step: 2
Training loss: 2.1816070079803467
Validation loss: 2.2788984809848043
Epoch: 9| Step: 3
Training loss: 2.357835531234741
Validation loss: 2.2778010608480987
Epoch: 9| Step: 4
Training loss: 2.5374128818511963
Validation loss: 2.2781985509309837
Epoch: 9| Step: 5
Training loss: 2.39469313621521
Validation loss: 2.279227162436616
Epoch: 9| Step: 6
Training loss: 3.2104196548461914
Validation loss: 2.277536821022308
Epoch: 9| Step: 7
Training loss: 2.823075294494629
Validation loss: 2.279000158790204
Epoch: 9| Step: 8
Training loss: 2.880077362060547
Validation loss: 2.2785556059089496
Epoch: 9| Step: 9
Training loss: 2.92617130279541
Validation loss: 2.278750043978794
Epoch: 9| Step: 10
Training loss: 2.969904661178589
Validation loss: 2.275666705138392
Epoch: 9| Step: 11
Training loss: 3.305004119873047
Validation loss: 2.2754764402513024
Epoch: 9| Step: 12
Training loss: 2.730654239654541
Validation loss: 2.2807247510059274
Epoch: 9| Step: 13
Training loss: 2.7050070762634277
Validation loss: 2.2758594948610815
Epoch: 9| Step: 14
Training loss: 2.46523380279541
Validation loss: 2.2745431773096536
Epoch: 9| Step: 15
Training loss: 2.7882392406463623
Validation loss: 2.275261062512295
Epoch: 9| Step: 16
Training loss: 3.24233341217041
Validation loss: 2.2775456699536
Epoch: 9| Step: 17
Training loss: 2.5925092697143555
Validation loss: 2.2767662581779975
Epoch: 9| Step: 18
Training loss: 2.672346353530884
Validation loss: 2.274852567439457
Epoch: 9| Step: 19
Training loss: 3.2800469398498535
Validation loss: 2.2762094212950563
Epoch: 172| Step: 0
Training loss: 2.9114480018615723
Validation loss: 2.2744239860301394
Epoch: 9| Step: 1
Training loss: 3.0890913009643555
Validation loss: 2.2780876982983926
Epoch: 9| Step: 2
Training loss: 2.8203516006469727
Validation loss: 2.277192870489985
Epoch: 9| Step: 3
Training loss: 3.243786096572876
Validation loss: 2.2756999679606595
Epoch: 9| Step: 4
Training loss: 2.5022974014282227
Validation loss: 2.274533611407383
Epoch: 9| Step: 5
Training loss: 3.0616350173950195
Validation loss: 2.2799434301664503
Epoch: 9| Step: 6
Training loss: 2.9912588596343994
Validation loss: 2.274988949727669
Epoch: 9| Step: 7
Training loss: 2.333120822906494
Validation loss: 2.278519994920964
Epoch: 9| Step: 8
Training loss: 2.9339687824249268
Validation loss: 2.276731609440536
Epoch: 9| Step: 9
Training loss: 2.714193344116211
Validation loss: 2.277764442155687
Epoch: 9| Step: 10
Training loss: 3.086616039276123
Validation loss: 2.2807858985105005
Epoch: 9| Step: 11
Training loss: 2.9487380981445312
Validation loss: 2.270618123116253
Epoch: 9| Step: 12
Training loss: 2.6871542930603027
Validation loss: 2.279298469317045
Epoch: 9| Step: 13
Training loss: 2.6215271949768066
Validation loss: 2.2756289303731574
Epoch: 9| Step: 14
Training loss: 3.0612168312072754
Validation loss: 2.2763636472413866
Epoch: 9| Step: 15
Training loss: 2.7580533027648926
Validation loss: 2.2786385532763362
Epoch: 9| Step: 16
Training loss: 2.0367002487182617
Validation loss: 2.277237256653875
Epoch: 9| Step: 17
Training loss: 3.1073570251464844
Validation loss: 2.27868254064656
Epoch: 9| Step: 18
Training loss: 1.8618054389953613
Validation loss: 2.2782832607090904
Epoch: 9| Step: 19
Training loss: 3.10587215423584
Validation loss: 2.277773160728619
Epoch: 173| Step: 0
Training loss: 3.344428062438965
Validation loss: 2.279207804220186
Epoch: 9| Step: 1
Training loss: 2.7347888946533203
Validation loss: 2.2772690503717326
Epoch: 9| Step: 2
Training loss: 3.035010576248169
Validation loss: 2.2749521157724395
Epoch: 9| Step: 3
Training loss: 3.0767531394958496
Validation loss: 2.275565872947089
Epoch: 9| Step: 4
Training loss: 2.265155792236328
Validation loss: 2.275189029227058
Epoch: 9| Step: 5
Training loss: 3.1300418376922607
Validation loss: 2.2740297145980723
Epoch: 9| Step: 6
Training loss: 3.0618014335632324
Validation loss: 2.275090159272118
Epoch: 9| Step: 7
Training loss: 2.4865806102752686
Validation loss: 2.273491641600355
Epoch: 9| Step: 8
Training loss: 2.9560623168945312
Validation loss: 2.274716734028549
Epoch: 9| Step: 9
Training loss: 2.0308125019073486
Validation loss: 2.2769042244918056
Epoch: 9| Step: 10
Training loss: 2.732919692993164
Validation loss: 2.274810523437939
Epoch: 9| Step: 11
Training loss: 2.583721160888672
Validation loss: 2.273829265464124
Epoch: 9| Step: 12
Training loss: 2.757603168487549
Validation loss: 2.2756807366721064
Epoch: 9| Step: 13
Training loss: 3.2628748416900635
Validation loss: 2.276308354713934
Epoch: 9| Step: 14
Training loss: 2.625154495239258
Validation loss: 2.2754059798425907
Epoch: 9| Step: 15
Training loss: 3.399315118789673
Validation loss: 2.2761482866547946
Epoch: 9| Step: 16
Training loss: 2.529977321624756
Validation loss: 2.2770431710661745
Epoch: 9| Step: 17
Training loss: 3.140758752822876
Validation loss: 2.275938193575084
Epoch: 9| Step: 18
Training loss: 2.3610076904296875
Validation loss: 2.276156147606939
Epoch: 9| Step: 19
Training loss: 2.352062702178955
Validation loss: 2.2724652959288454
Epoch: 174| Step: 0
Training loss: 2.9405200481414795
Validation loss: 2.272382972909392
Epoch: 9| Step: 1
Training loss: 2.294769763946533
Validation loss: 2.276446252418079
Epoch: 9| Step: 2
Training loss: 3.185816526412964
Validation loss: 2.2737407272668193
Epoch: 9| Step: 3
Training loss: 3.2478320598602295
Validation loss: 2.275390520370264
Epoch: 9| Step: 4
Training loss: 3.0054168701171875
Validation loss: 2.2779550346539175
Epoch: 9| Step: 5
Training loss: 2.0596537590026855
Validation loss: 2.274657935547314
Epoch: 9| Step: 6
Training loss: 2.847515344619751
Validation loss: 2.2772062356523475
Epoch: 9| Step: 7
Training loss: 2.964806079864502
Validation loss: 2.2732315346491423
Epoch: 9| Step: 8
Training loss: 2.7956929206848145
Validation loss: 2.276341738460733
Epoch: 9| Step: 9
Training loss: 2.180604934692383
Validation loss: 2.2721563912124085
Epoch: 9| Step: 10
Training loss: 2.596343517303467
Validation loss: 2.2740920078840188
Epoch: 9| Step: 11
Training loss: 2.9404678344726562
Validation loss: 2.276156012102854
Epoch: 9| Step: 12
Training loss: 2.6497976779937744
Validation loss: 2.2729439975546417
Epoch: 9| Step: 13
Training loss: 2.427889347076416
Validation loss: 2.2735712107994575
Epoch: 9| Step: 14
Training loss: 3.746030330657959
Validation loss: 2.271818886557929
Epoch: 9| Step: 15
Training loss: 3.0883030891418457
Validation loss: 2.2759573253796255
Epoch: 9| Step: 16
Training loss: 2.5978293418884277
Validation loss: 2.274276162222993
Epoch: 9| Step: 17
Training loss: 2.6683120727539062
Validation loss: 2.27261424922257
Epoch: 9| Step: 18
Training loss: 2.9555840492248535
Validation loss: 2.2751638203216116
Epoch: 9| Step: 19
Training loss: 2.67767333984375
Validation loss: 2.2759337802585082
Epoch: 175| Step: 0
Training loss: 3.3096256256103516
Validation loss: 2.2765215335132405
Epoch: 9| Step: 1
Training loss: 2.6700541973114014
Validation loss: 2.2726785742121636
Epoch: 9| Step: 2
Training loss: 3.8884952068328857
Validation loss: 2.2736219725162865
Epoch: 9| Step: 3
Training loss: 1.9332997798919678
Validation loss: 2.2747594092389662
Epoch: 9| Step: 4
Training loss: 3.219562530517578
Validation loss: 2.272269935059033
Epoch: 9| Step: 5
Training loss: 2.617274761199951
Validation loss: 2.2730016708374023
Epoch: 9| Step: 6
Training loss: 3.0434775352478027
Validation loss: 2.2750496744251936
Epoch: 9| Step: 7
Training loss: 2.6236605644226074
Validation loss: 2.2733342304504176
Epoch: 9| Step: 8
Training loss: 3.533623456954956
Validation loss: 2.27265088764026
Epoch: 9| Step: 9
Training loss: 2.8095455169677734
Validation loss: 2.273990775183808
Epoch: 9| Step: 10
Training loss: 2.872642993927002
Validation loss: 2.273542459062535
Epoch: 9| Step: 11
Training loss: 1.9589471817016602
Validation loss: 2.2744706551805676
Epoch: 9| Step: 12
Training loss: 3.4324727058410645
Validation loss: 2.2748372220306945
Epoch: 9| Step: 13
Training loss: 2.3489747047424316
Validation loss: 2.2722682524070463
Epoch: 9| Step: 14
Training loss: 2.473968267440796
Validation loss: 2.2749268425454336
Epoch: 9| Step: 15
Training loss: 2.6311492919921875
Validation loss: 2.274485821346585
Epoch: 9| Step: 16
Training loss: 2.6111180782318115
Validation loss: 2.27142631064216
Epoch: 9| Step: 17
Training loss: 2.3466317653656006
Validation loss: 2.274762016406162
Epoch: 9| Step: 18
Training loss: 2.664320707321167
Validation loss: 2.2749326580719984
Epoch: 9| Step: 19
Training loss: 2.87646484375
Validation loss: 2.274850954254754
Epoch: 176| Step: 0
Training loss: 3.3497684001922607
Validation loss: 2.272990118685386
Epoch: 9| Step: 1
Training loss: 2.949122905731201
Validation loss: 2.27387875104122
Epoch: 9| Step: 2
Training loss: 3.1039347648620605
Validation loss: 2.2736630542672795
Epoch: 9| Step: 3
Training loss: 1.863467812538147
Validation loss: 2.2733909792179685
Epoch: 9| Step: 4
Training loss: 2.5310745239257812
Validation loss: 2.275089073524201
Epoch: 9| Step: 5
Training loss: 3.9266507625579834
Validation loss: 2.27430856485161
Epoch: 9| Step: 6
Training loss: 3.4212074279785156
Validation loss: 2.2747757271897022
Epoch: 9| Step: 7
Training loss: 2.3036537170410156
Validation loss: 2.275191126967506
Epoch: 9| Step: 8
Training loss: 1.5489420890808105
Validation loss: 2.272648535186438
Epoch: 9| Step: 9
Training loss: 3.4980287551879883
Validation loss: 2.2719870419811
Epoch: 9| Step: 10
Training loss: 3.3335330486297607
Validation loss: 2.2712762527328603
Epoch: 9| Step: 11
Training loss: 2.672741651535034
Validation loss: 2.274405930539687
Epoch: 9| Step: 12
Training loss: 2.7415645122528076
Validation loss: 2.273661056868464
Epoch: 9| Step: 13
Training loss: 2.825082778930664
Validation loss: 2.271240558555658
Epoch: 9| Step: 14
Training loss: 2.403505802154541
Validation loss: 2.27157153671594
Epoch: 9| Step: 15
Training loss: 2.148898124694824
Validation loss: 2.2713864655803433
Epoch: 9| Step: 16
Training loss: 2.307976007461548
Validation loss: 2.271946989375053
Epoch: 9| Step: 17
Training loss: 2.860013246536255
Validation loss: 2.271145621649653
Epoch: 9| Step: 18
Training loss: 3.0473740100860596
Validation loss: 2.2723937017454516
Epoch: 9| Step: 19
Training loss: 2.9089865684509277
Validation loss: 2.271106184815331
Epoch: 177| Step: 0
Training loss: 2.636507987976074
Validation loss: 2.271316401392436
Epoch: 9| Step: 1
Training loss: 3.2662620544433594
Validation loss: 2.27210408492054
Epoch: 9| Step: 2
Training loss: 3.1335763931274414
Validation loss: 2.273114149519008
Epoch: 9| Step: 3
Training loss: 2.6503405570983887
Validation loss: 2.270320643623956
Epoch: 9| Step: 4
Training loss: 2.9037866592407227
Validation loss: 2.272618695128736
Epoch: 9| Step: 5
Training loss: 2.764744281768799
Validation loss: 2.2736016640560233
Epoch: 9| Step: 6
Training loss: 2.78767728805542
Validation loss: 2.2727956377345024
Epoch: 9| Step: 7
Training loss: 3.2766571044921875
Validation loss: 2.2713669615683796
Epoch: 9| Step: 8
Training loss: 2.5828683376312256
Validation loss: 2.2734659215529187
Epoch: 9| Step: 9
Training loss: 2.7534680366516113
Validation loss: 2.2696936730858233
Epoch: 9| Step: 10
Training loss: 3.103485345840454
Validation loss: 2.2733449387035782
Epoch: 9| Step: 11
Training loss: 3.676680088043213
Validation loss: 2.2733573176020343
Epoch: 9| Step: 12
Training loss: 2.989434242248535
Validation loss: 2.274286345612231
Epoch: 9| Step: 13
Training loss: 1.9029648303985596
Validation loss: 2.2749763847255022
Epoch: 9| Step: 14
Training loss: 3.0198616981506348
Validation loss: 2.2715541184377326
Epoch: 9| Step: 15
Training loss: 2.3123104572296143
Validation loss: 2.270908435471624
Epoch: 9| Step: 16
Training loss: 1.9769847393035889
Validation loss: 2.2732496004310443
Epoch: 9| Step: 17
Training loss: 3.2617347240448
Validation loss: 2.2715300467374515
Epoch: 9| Step: 18
Training loss: 1.8661738634109497
Validation loss: 2.270870550073308
Epoch: 9| Step: 19
Training loss: 2.9172353744506836
Validation loss: 2.273330695337529
Epoch: 178| Step: 0
Training loss: 2.8131871223449707
Validation loss: 2.273534606686599
Epoch: 9| Step: 1
Training loss: 2.892972469329834
Validation loss: 2.2666536818305367
Epoch: 9| Step: 2
Training loss: 2.4421331882476807
Validation loss: 2.2735359394293035
Epoch: 9| Step: 3
Training loss: 3.0942277908325195
Validation loss: 2.2706289943173634
Epoch: 9| Step: 4
Training loss: 3.045729637145996
Validation loss: 2.2740190603750214
Epoch: 9| Step: 5
Training loss: 2.6666903495788574
Validation loss: 2.269576336840074
Epoch: 9| Step: 6
Training loss: 3.211399555206299
Validation loss: 2.271513347145465
Epoch: 9| Step: 7
Training loss: 2.4739155769348145
Validation loss: 2.2714211237516335
Epoch: 9| Step: 8
Training loss: 2.574922561645508
Validation loss: 2.270022960017911
Epoch: 9| Step: 9
Training loss: 2.4392030239105225
Validation loss: 2.2695456100024765
Epoch: 9| Step: 10
Training loss: 2.0088653564453125
Validation loss: 2.2681305691492644
Epoch: 9| Step: 11
Training loss: 2.466676950454712
Validation loss: 2.270358826616685
Epoch: 9| Step: 12
Training loss: 2.8937487602233887
Validation loss: 2.2688073039912493
Epoch: 9| Step: 13
Training loss: 2.8230676651000977
Validation loss: 2.269634967227634
Epoch: 9| Step: 14
Training loss: 2.795015811920166
Validation loss: 2.2709611422724003
Epoch: 9| Step: 15
Training loss: 3.0812854766845703
Validation loss: 2.268511907659846
Epoch: 9| Step: 16
Training loss: 2.297992706298828
Validation loss: 2.2700619405979734
Epoch: 9| Step: 17
Training loss: 3.4781534671783447
Validation loss: 2.2696577833710814
Epoch: 9| Step: 18
Training loss: 3.3057045936584473
Validation loss: 2.271763437943493
Epoch: 9| Step: 19
Training loss: 2.975706100463867
Validation loss: 2.2697976527454182
Epoch: 179| Step: 0
Training loss: 2.9215519428253174
Validation loss: 2.267114945452848
Epoch: 9| Step: 1
Training loss: 3.1933107376098633
Validation loss: 2.2683817294004154
Epoch: 9| Step: 2
Training loss: 2.7935619354248047
Validation loss: 2.271951498745157
Epoch: 9| Step: 3
Training loss: 2.3893628120422363
Validation loss: 2.2694205757525325
Epoch: 9| Step: 4
Training loss: 2.811448097229004
Validation loss: 2.2686235493035625
Epoch: 9| Step: 5
Training loss: 2.9321584701538086
Validation loss: 2.269919740210334
Epoch: 9| Step: 6
Training loss: 2.6899805068969727
Validation loss: 2.267546684621907
Epoch: 9| Step: 7
Training loss: 2.7116341590881348
Validation loss: 2.2677122877656126
Epoch: 9| Step: 8
Training loss: 3.061344623565674
Validation loss: 2.268334750648883
Epoch: 9| Step: 9
Training loss: 2.4040486812591553
Validation loss: 2.2697612381667542
Epoch: 9| Step: 10
Training loss: 2.6456871032714844
Validation loss: 2.273377929660056
Epoch: 9| Step: 11
Training loss: 3.268561840057373
Validation loss: 2.271622867892972
Epoch: 9| Step: 12
Training loss: 2.2824161052703857
Validation loss: 2.2703217130770788
Epoch: 9| Step: 13
Training loss: 2.696141004562378
Validation loss: 2.272822825171107
Epoch: 9| Step: 14
Training loss: 2.9176864624023438
Validation loss: 2.2707001082331155
Epoch: 9| Step: 15
Training loss: 2.648346185684204
Validation loss: 2.2689955937776634
Epoch: 9| Step: 16
Training loss: 2.935774087905884
Validation loss: 2.2735596526440958
Epoch: 9| Step: 17
Training loss: 2.86531400680542
Validation loss: 2.266687303995915
Epoch: 9| Step: 18
Training loss: 2.653468608856201
Validation loss: 2.270479120796533
Epoch: 9| Step: 19
Training loss: 2.9342198371887207
Validation loss: 2.2728980102127405
Epoch: 180| Step: 0
Training loss: 2.9680349826812744
Validation loss: 2.2720754969891885
Epoch: 9| Step: 1
Training loss: 2.0610671043395996
Validation loss: 2.2702802994268403
Epoch: 9| Step: 2
Training loss: 2.7715578079223633
Validation loss: 2.2689629904657815
Epoch: 9| Step: 3
Training loss: 2.3526601791381836
Validation loss: 2.2678964378164825
Epoch: 9| Step: 4
Training loss: 2.9132251739501953
Validation loss: 2.2730102041642444
Epoch: 9| Step: 5
Training loss: 3.3846898078918457
Validation loss: 2.272331070556915
Epoch: 9| Step: 6
Training loss: 2.927501678466797
Validation loss: 2.2723105982910816
Epoch: 9| Step: 7
Training loss: 2.9414963722229004
Validation loss: 2.2727114605389054
Epoch: 9| Step: 8
Training loss: 1.9604780673980713
Validation loss: 2.2667070138368675
Epoch: 9| Step: 9
Training loss: 2.58526873588562
Validation loss: 2.273301865557115
Epoch: 9| Step: 10
Training loss: 2.365290403366089
Validation loss: 2.27035981116535
Epoch: 9| Step: 11
Training loss: 3.280515432357788
Validation loss: 2.2673383496648114
Epoch: 9| Step: 12
Training loss: 3.704176425933838
Validation loss: 2.2692647992278174
Epoch: 9| Step: 13
Training loss: 2.9956297874450684
Validation loss: 2.2690559771421146
Epoch: 9| Step: 14
Training loss: 2.947096109390259
Validation loss: 2.2718313597946715
Epoch: 9| Step: 15
Training loss: 2.8016510009765625
Validation loss: 2.272074126511169
Epoch: 9| Step: 16
Training loss: 1.6139791011810303
Validation loss: 2.2695191781297863
Epoch: 9| Step: 17
Training loss: 3.3875608444213867
Validation loss: 2.2686610256167623
Epoch: 9| Step: 18
Training loss: 3.225618362426758
Validation loss: 2.271290724226039
Epoch: 9| Step: 19
Training loss: 2.555372714996338
Validation loss: 2.2704624941023135
Epoch: 181| Step: 0
Training loss: 2.945244789123535
Validation loss: 2.2720038033217835
Epoch: 9| Step: 1
Training loss: 3.077136516571045
Validation loss: 2.268591901381239
Epoch: 9| Step: 2
Training loss: 3.344154119491577
Validation loss: 2.2661772083035476
Epoch: 9| Step: 3
Training loss: 3.0541958808898926
Validation loss: 2.268719556520311
Epoch: 9| Step: 4
Training loss: 3.3890252113342285
Validation loss: 2.2688739248316923
Epoch: 9| Step: 5
Training loss: 2.842996120452881
Validation loss: 2.2681551271205325
Epoch: 9| Step: 6
Training loss: 2.828542709350586
Validation loss: 2.2709366160331013
Epoch: 9| Step: 7
Training loss: 2.618058681488037
Validation loss: 2.269012807942123
Epoch: 9| Step: 8
Training loss: 3.2248735427856445
Validation loss: 2.2679940762279704
Epoch: 9| Step: 9
Training loss: 3.275665760040283
Validation loss: 2.2683073479494604
Epoch: 9| Step: 10
Training loss: 2.3569424152374268
Validation loss: 2.266099021589156
Epoch: 9| Step: 11
Training loss: 2.8437371253967285
Validation loss: 2.270057748547561
Epoch: 9| Step: 12
Training loss: 2.2082033157348633
Validation loss: 2.2681974644283596
Epoch: 9| Step: 13
Training loss: 2.3407950401306152
Validation loss: 2.268087126368241
Epoch: 9| Step: 14
Training loss: 2.548048496246338
Validation loss: 2.2674969563381278
Epoch: 9| Step: 15
Training loss: 2.301748752593994
Validation loss: 2.266502788598589
Epoch: 9| Step: 16
Training loss: 3.5374584197998047
Validation loss: 2.265555924648861
Epoch: 9| Step: 17
Training loss: 1.9447708129882812
Validation loss: 2.2676598065191036
Epoch: 9| Step: 18
Training loss: 2.7135872840881348
Validation loss: 2.2674586275498645
Epoch: 9| Step: 19
Training loss: 2.3198604583740234
Validation loss: 2.2696961310270023
Epoch: 182| Step: 0
Training loss: 2.2469263076782227
Validation loss: 2.2688230970780627
Epoch: 9| Step: 1
Training loss: 2.98288631439209
Validation loss: 2.2673350829872296
Epoch: 9| Step: 2
Training loss: 2.22047758102417
Validation loss: 2.2705451232923877
Epoch: 9| Step: 3
Training loss: 2.75034761428833
Validation loss: 2.2674223227466612
Epoch: 9| Step: 4
Training loss: 2.6731128692626953
Validation loss: 2.2686427359958348
Epoch: 9| Step: 5
Training loss: 2.691275119781494
Validation loss: 2.2675544666729386
Epoch: 9| Step: 6
Training loss: 3.07431697845459
Validation loss: 2.268485451773774
Epoch: 9| Step: 7
Training loss: 2.318448305130005
Validation loss: 2.264991069011551
Epoch: 9| Step: 8
Training loss: 2.6319639682769775
Validation loss: 2.266821180316184
Epoch: 9| Step: 9
Training loss: 2.9563560485839844
Validation loss: 2.2691757833357338
Epoch: 9| Step: 10
Training loss: 2.8392887115478516
Validation loss: 2.266402868915805
Epoch: 9| Step: 11
Training loss: 2.663968563079834
Validation loss: 2.2681955750897633
Epoch: 9| Step: 12
Training loss: 3.045818328857422
Validation loss: 2.268645365461171
Epoch: 9| Step: 13
Training loss: 3.465027332305908
Validation loss: 2.267995369520119
Epoch: 9| Step: 14
Training loss: 3.041564464569092
Validation loss: 2.26710315230939
Epoch: 9| Step: 15
Training loss: 2.9469146728515625
Validation loss: 2.2674213193303387
Epoch: 9| Step: 16
Training loss: 2.78857421875
Validation loss: 2.265603640096651
Epoch: 9| Step: 17
Training loss: 3.061171770095825
Validation loss: 2.267563292448469
Epoch: 9| Step: 18
Training loss: 2.6536459922790527
Validation loss: 2.270365793927968
Epoch: 9| Step: 19
Training loss: 2.7330214977264404
Validation loss: 2.2677697689413168
Epoch: 183| Step: 0
Training loss: 2.6915221214294434
Validation loss: 2.2641523519008278
Epoch: 9| Step: 1
Training loss: 2.5174572467803955
Validation loss: 2.2643812611806307
Epoch: 9| Step: 2
Training loss: 2.795891284942627
Validation loss: 2.266619742345467
Epoch: 9| Step: 3
Training loss: 3.114853858947754
Validation loss: 2.265236331404542
Epoch: 9| Step: 4
Training loss: 2.836850166320801
Validation loss: 2.2665986465893204
Epoch: 9| Step: 5
Training loss: 2.826521873474121
Validation loss: 2.265998538449514
Epoch: 9| Step: 6
Training loss: 2.2392497062683105
Validation loss: 2.265526339304533
Epoch: 9| Step: 7
Training loss: 2.8741562366485596
Validation loss: 2.267173219927781
Epoch: 9| Step: 8
Training loss: 2.8199071884155273
Validation loss: 2.266146891408687
Epoch: 9| Step: 9
Training loss: 3.4176392555236816
Validation loss: 2.2680539072846337
Epoch: 9| Step: 10
Training loss: 2.3947792053222656
Validation loss: 2.2672844430525525
Epoch: 9| Step: 11
Training loss: 2.1355996131896973
Validation loss: 2.2657862395691355
Epoch: 9| Step: 12
Training loss: 3.111161708831787
Validation loss: 2.267543442815328
Epoch: 9| Step: 13
Training loss: 3.239969491958618
Validation loss: 2.2683819952628594
Epoch: 9| Step: 14
Training loss: 1.8300886154174805
Validation loss: 2.265361643523621
Epoch: 9| Step: 15
Training loss: 3.040863037109375
Validation loss: 2.2676617370234977
Epoch: 9| Step: 16
Training loss: 2.6395034790039062
Validation loss: 2.266767406635147
Epoch: 9| Step: 17
Training loss: 3.446561336517334
Validation loss: 2.2684422465537093
Epoch: 9| Step: 18
Training loss: 2.598923683166504
Validation loss: 2.266371253583071
Epoch: 9| Step: 19
Training loss: 3.1442978382110596
Validation loss: 2.268208757578898
Epoch: 184| Step: 0
Training loss: 3.268033504486084
Validation loss: 2.2684089845890623
Epoch: 9| Step: 1
Training loss: 3.1513447761535645
Validation loss: 2.2684580053356913
Epoch: 9| Step: 2
Training loss: 1.9673328399658203
Validation loss: 2.2680439571682496
Epoch: 9| Step: 3
Training loss: 2.679870367050171
Validation loss: 2.2684241336026636
Epoch: 9| Step: 4
Training loss: 2.3331286907196045
Validation loss: 2.2667966643683344
Epoch: 9| Step: 5
Training loss: 2.9563229084014893
Validation loss: 2.2692471588258263
Epoch: 9| Step: 6
Training loss: 3.183891773223877
Validation loss: 2.263549881873371
Epoch: 9| Step: 7
Training loss: 2.9103169441223145
Validation loss: 2.265537617017897
Epoch: 9| Step: 8
Training loss: 3.015716552734375
Validation loss: 2.267380170684924
Epoch: 9| Step: 9
Training loss: 2.607694149017334
Validation loss: 2.2658853788170026
Epoch: 9| Step: 10
Training loss: 3.142642021179199
Validation loss: 2.266334393041597
Epoch: 9| Step: 11
Training loss: 1.9997320175170898
Validation loss: 2.2638351668556815
Epoch: 9| Step: 12
Training loss: 3.1982662677764893
Validation loss: 2.268100510398261
Epoch: 9| Step: 13
Training loss: 3.4070138931274414
Validation loss: 2.2668813973022024
Epoch: 9| Step: 14
Training loss: 2.3904573917388916
Validation loss: 2.2666560660163277
Epoch: 9| Step: 15
Training loss: 2.8327322006225586
Validation loss: 2.2671405016947137
Epoch: 9| Step: 16
Training loss: 2.942936658859253
Validation loss: 2.2691072251299302
Epoch: 9| Step: 17
Training loss: 2.6435039043426514
Validation loss: 2.269853391235681
Epoch: 9| Step: 18
Training loss: 2.4109697341918945
Validation loss: 2.2616940916870996
Epoch: 9| Step: 19
Training loss: 2.5940797328948975
Validation loss: 2.269106607642963
Epoch: 185| Step: 0
Training loss: 3.0102972984313965
Validation loss: 2.267197624384928
Epoch: 9| Step: 1
Training loss: 2.8405723571777344
Validation loss: 2.267838177921103
Epoch: 9| Step: 2
Training loss: 2.917417049407959
Validation loss: 2.271012609811138
Epoch: 9| Step: 3
Training loss: 2.759174346923828
Validation loss: 2.2705598820885307
Epoch: 9| Step: 4
Training loss: 2.5754575729370117
Validation loss: 2.2683121351886997
Epoch: 9| Step: 5
Training loss: 2.324354648590088
Validation loss: 2.267751899554575
Epoch: 9| Step: 6
Training loss: 3.2186198234558105
Validation loss: 2.266570271347924
Epoch: 9| Step: 7
Training loss: 3.172496795654297
Validation loss: 2.2679016658728073
Epoch: 9| Step: 8
Training loss: 2.9657087326049805
Validation loss: 2.2687972475298874
Epoch: 9| Step: 9
Training loss: 2.158087730407715
Validation loss: 2.269232187339728
Epoch: 9| Step: 10
Training loss: 3.2377498149871826
Validation loss: 2.265945408841689
Epoch: 9| Step: 11
Training loss: 2.1611886024475098
Validation loss: 2.2652853049820276
Epoch: 9| Step: 12
Training loss: 2.2419273853302
Validation loss: 2.264825095375665
Epoch: 9| Step: 13
Training loss: 2.544400691986084
Validation loss: 2.2640124670893167
Epoch: 9| Step: 14
Training loss: 3.183244228363037
Validation loss: 2.2679606718982726
Epoch: 9| Step: 15
Training loss: 2.942519187927246
Validation loss: 2.2632749595230433
Epoch: 9| Step: 16
Training loss: 2.4468798637390137
Validation loss: 2.26720562427164
Epoch: 9| Step: 17
Training loss: 2.531068801879883
Validation loss: 2.2636749950244273
Epoch: 9| Step: 18
Training loss: 3.2019121646881104
Validation loss: 2.264753283356591
Epoch: 9| Step: 19
Training loss: 3.271615743637085
Validation loss: 2.2634984271989453
Epoch: 186| Step: 0
Training loss: 2.1909050941467285
Validation loss: 2.2655577247948955
Epoch: 9| Step: 1
Training loss: 2.303887128829956
Validation loss: 2.264032650336945
Epoch: 9| Step: 2
Training loss: 2.8940792083740234
Validation loss: 2.263517036712427
Epoch: 9| Step: 3
Training loss: 2.9347190856933594
Validation loss: 2.2632445774490026
Epoch: 9| Step: 4
Training loss: 2.8274941444396973
Validation loss: 2.2654276803243074
Epoch: 9| Step: 5
Training loss: 2.3670434951782227
Validation loss: 2.2664379696194215
Epoch: 9| Step: 6
Training loss: 3.2584521770477295
Validation loss: 2.2686356040213607
Epoch: 9| Step: 7
Training loss: 2.7700555324554443
Validation loss: 2.265277323962973
Epoch: 9| Step: 8
Training loss: 3.0482709407806396
Validation loss: 2.26565886401444
Epoch: 9| Step: 9
Training loss: 3.0457067489624023
Validation loss: 2.2670835608201063
Epoch: 9| Step: 10
Training loss: 2.6834826469421387
Validation loss: 2.2646232071540338
Epoch: 9| Step: 11
Training loss: 3.4239988327026367
Validation loss: 2.265813189444782
Epoch: 9| Step: 12
Training loss: 2.8163955211639404
Validation loss: 2.264564502153465
Epoch: 9| Step: 13
Training loss: 2.4259378910064697
Validation loss: 2.2646671370636646
Epoch: 9| Step: 14
Training loss: 3.118764877319336
Validation loss: 2.2644172726775245
Epoch: 9| Step: 15
Training loss: 2.422919511795044
Validation loss: 2.2663503567949475
Epoch: 9| Step: 16
Training loss: 2.4019622802734375
Validation loss: 2.2641815238719363
Epoch: 9| Step: 17
Training loss: 3.47599458694458
Validation loss: 2.2643965113934854
Epoch: 9| Step: 18
Training loss: 2.128627061843872
Validation loss: 2.2653782376282505
Epoch: 9| Step: 19
Training loss: 3.1216177940368652
Validation loss: 2.263303931668508
Epoch: 187| Step: 0
Training loss: 3.1395058631896973
Validation loss: 2.265786740419676
Epoch: 9| Step: 1
Training loss: 3.30564546585083
Validation loss: 2.2643543730536813
Epoch: 9| Step: 2
Training loss: 3.2398929595947266
Validation loss: 2.2671869727347396
Epoch: 9| Step: 3
Training loss: 2.8949289321899414
Validation loss: 2.266628558687169
Epoch: 9| Step: 4
Training loss: 2.1323752403259277
Validation loss: 2.2629147262024363
Epoch: 9| Step: 5
Training loss: 2.821254253387451
Validation loss: 2.266656182652755
Epoch: 9| Step: 6
Training loss: 2.2816903591156006
Validation loss: 2.2652381392691634
Epoch: 9| Step: 7
Training loss: 2.5174715518951416
Validation loss: 2.2640635452682165
Epoch: 9| Step: 8
Training loss: 2.865631103515625
Validation loss: 2.263770559708849
Epoch: 9| Step: 9
Training loss: 2.5644571781158447
Validation loss: 2.2622247719936235
Epoch: 9| Step: 10
Training loss: 2.8225255012512207
Validation loss: 2.2624519214355687
Epoch: 9| Step: 11
Training loss: 2.9445366859436035
Validation loss: 2.263738876624073
Epoch: 9| Step: 12
Training loss: 2.9628493785858154
Validation loss: 2.263789499406334
Epoch: 9| Step: 13
Training loss: 2.293550729751587
Validation loss: 2.2686875475396353
Epoch: 9| Step: 14
Training loss: 3.199748992919922
Validation loss: 2.2639441550206794
Epoch: 9| Step: 15
Training loss: 2.89792799949646
Validation loss: 2.2618570104777382
Epoch: 9| Step: 16
Training loss: 2.316340923309326
Validation loss: 2.2627957759143635
Epoch: 9| Step: 17
Training loss: 2.27962064743042
Validation loss: 2.2650367115898957
Epoch: 9| Step: 18
Training loss: 2.466552495956421
Validation loss: 2.261073553304878
Epoch: 9| Step: 19
Training loss: 3.701760768890381
Validation loss: 2.263407023690587
Epoch: 188| Step: 0
Training loss: 3.009629487991333
Validation loss: 2.2621200350548722
Epoch: 9| Step: 1
Training loss: 2.9353954792022705
Validation loss: 2.263596607626771
Epoch: 9| Step: 2
Training loss: 3.3654143810272217
Validation loss: 2.2628326656149444
Epoch: 9| Step: 3
Training loss: 2.6306140422821045
Validation loss: 2.265350508175308
Epoch: 9| Step: 4
Training loss: 2.825795888900757
Validation loss: 2.262628128202699
Epoch: 9| Step: 5
Training loss: 2.736116647720337
Validation loss: 2.2642215944880206
Epoch: 9| Step: 6
Training loss: 3.1175436973571777
Validation loss: 2.2641551357379064
Epoch: 9| Step: 7
Training loss: 2.7402684688568115
Validation loss: 2.2651338748794667
Epoch: 9| Step: 8
Training loss: 3.1217081546783447
Validation loss: 2.2641723344651914
Epoch: 9| Step: 9
Training loss: 2.7600576877593994
Validation loss: 2.2626275364443553
Epoch: 9| Step: 10
Training loss: 2.7091331481933594
Validation loss: 2.2644252622727867
Epoch: 9| Step: 11
Training loss: 2.963432788848877
Validation loss: 2.2617404495211813
Epoch: 9| Step: 12
Training loss: 2.698025703430176
Validation loss: 2.2603291393183977
Epoch: 9| Step: 13
Training loss: 2.634944200515747
Validation loss: 2.2631096839904785
Epoch: 9| Step: 14
Training loss: 2.7417666912078857
Validation loss: 2.262856052933837
Epoch: 9| Step: 15
Training loss: 2.5168609619140625
Validation loss: 2.2620701515417303
Epoch: 9| Step: 16
Training loss: 2.321774482727051
Validation loss: 2.2614773314633814
Epoch: 9| Step: 17
Training loss: 2.31179141998291
Validation loss: 2.2638080188696335
Epoch: 9| Step: 18
Training loss: 2.754741668701172
Validation loss: 2.2633127805998
Epoch: 9| Step: 19
Training loss: 2.709491014480591
Validation loss: 2.2642233508953944
Epoch: 189| Step: 0
Training loss: 2.1212093830108643
Validation loss: 2.26148576273335
Epoch: 9| Step: 1
Training loss: 2.951265811920166
Validation loss: 2.2638318281379535
Epoch: 9| Step: 2
Training loss: 3.1128458976745605
Validation loss: 2.264005338545326
Epoch: 9| Step: 3
Training loss: 3.431825876235962
Validation loss: 2.263841618736871
Epoch: 9| Step: 4
Training loss: 2.6025915145874023
Validation loss: 2.2654801821537154
Epoch: 9| Step: 5
Training loss: 2.8302676677703857
Validation loss: 2.267535163344239
Epoch: 9| Step: 6
Training loss: 3.0269508361816406
Validation loss: 2.2655632247170097
Epoch: 9| Step: 7
Training loss: 1.8608887195587158
Validation loss: 2.267402693522062
Epoch: 9| Step: 8
Training loss: 2.38774037361145
Validation loss: 2.265729375880399
Epoch: 9| Step: 9
Training loss: 2.3519983291625977
Validation loss: 2.264747106771675
Epoch: 9| Step: 10
Training loss: 2.771066188812256
Validation loss: 2.2640033505803387
Epoch: 9| Step: 11
Training loss: 2.270883083343506
Validation loss: 2.2637646609930684
Epoch: 9| Step: 12
Training loss: 2.765676259994507
Validation loss: 2.262080189135435
Epoch: 9| Step: 13
Training loss: 2.5880348682403564
Validation loss: 2.2591137440084554
Epoch: 9| Step: 14
Training loss: 3.320929527282715
Validation loss: 2.257907347713443
Epoch: 9| Step: 15
Training loss: 3.059185266494751
Validation loss: 2.263413528744265
Epoch: 9| Step: 16
Training loss: 2.801623821258545
Validation loss: 2.2637480068549833
Epoch: 9| Step: 17
Training loss: 2.8177194595336914
Validation loss: 2.2610289304376505
Epoch: 9| Step: 18
Training loss: 2.8992919921875
Validation loss: 2.26127566021981
Epoch: 9| Step: 19
Training loss: 3.6346356868743896
Validation loss: 2.2607513914862984
Epoch: 190| Step: 0
Training loss: 2.5660758018493652
Validation loss: 2.2643827757389428
Epoch: 9| Step: 1
Training loss: 2.2649831771850586
Validation loss: 2.26262475603776
Epoch: 9| Step: 2
Training loss: 3.037454128265381
Validation loss: 2.2617320748541854
Epoch: 9| Step: 3
Training loss: 2.9481146335601807
Validation loss: 2.2604528519747067
Epoch: 9| Step: 4
Training loss: 3.0005908012390137
Validation loss: 2.2634442349989636
Epoch: 9| Step: 5
Training loss: 2.7748398780822754
Validation loss: 2.26374100609649
Epoch: 9| Step: 6
Training loss: 2.39628529548645
Validation loss: 2.2608289632865852
Epoch: 9| Step: 7
Training loss: 3.4722023010253906
Validation loss: 2.26053182341212
Epoch: 9| Step: 8
Training loss: 2.671048164367676
Validation loss: 2.2591546036356647
Epoch: 9| Step: 9
Training loss: 2.9486684799194336
Validation loss: 2.262259193461576
Epoch: 9| Step: 10
Training loss: 2.745980978012085
Validation loss: 2.262390534654796
Epoch: 9| Step: 11
Training loss: 3.337109327316284
Validation loss: 2.2601147349789845
Epoch: 9| Step: 12
Training loss: 2.3415303230285645
Validation loss: 2.2605047637610127
Epoch: 9| Step: 13
Training loss: 2.7511138916015625
Validation loss: 2.2612987490866683
Epoch: 9| Step: 14
Training loss: 2.5975096225738525
Validation loss: 2.2636007902433546
Epoch: 9| Step: 15
Training loss: 3.0175585746765137
Validation loss: 2.2645363121581594
Epoch: 9| Step: 16
Training loss: 2.591904878616333
Validation loss: 2.263271625093419
Epoch: 9| Step: 17
Training loss: 3.0082736015319824
Validation loss: 2.2617246692986797
Epoch: 9| Step: 18
Training loss: 2.5202577114105225
Validation loss: 2.2625823912860676
Epoch: 9| Step: 19
Training loss: 2.5627925395965576
Validation loss: 2.2626432669248513
Epoch: 191| Step: 0
Training loss: 2.309213876724243
Validation loss: 2.2622937864536863
Epoch: 9| Step: 1
Training loss: 2.2904601097106934
Validation loss: 2.2622463548783776
Epoch: 9| Step: 2
Training loss: 2.950406551361084
Validation loss: 2.262439249230803
Epoch: 9| Step: 3
Training loss: 2.250156879425049
Validation loss: 2.2631571670230346
Epoch: 9| Step: 4
Training loss: 2.161242961883545
Validation loss: 2.2617736634590644
Epoch: 9| Step: 5
Training loss: 2.146787643432617
Validation loss: 2.2637353552331168
Epoch: 9| Step: 6
Training loss: 2.88515567779541
Validation loss: 2.2619557603657676
Epoch: 9| Step: 7
Training loss: 2.550328254699707
Validation loss: 2.259515971588574
Epoch: 9| Step: 8
Training loss: 2.6705126762390137
Validation loss: 2.2592437730418693
Epoch: 9| Step: 9
Training loss: 2.2532777786254883
Validation loss: 2.2644518999744663
Epoch: 9| Step: 10
Training loss: 3.01840877532959
Validation loss: 2.260724028237432
Epoch: 9| Step: 11
Training loss: 2.4088056087493896
Validation loss: 2.262953734226364
Epoch: 9| Step: 12
Training loss: 3.139039993286133
Validation loss: 2.2618734562139715
Epoch: 9| Step: 13
Training loss: 2.9281983375549316
Validation loss: 2.2593880986138215
Epoch: 9| Step: 14
Training loss: 3.3659567832946777
Validation loss: 2.2599665672659017
Epoch: 9| Step: 15
Training loss: 3.5452356338500977
Validation loss: 2.2633196844471444
Epoch: 9| Step: 16
Training loss: 2.9212636947631836
Validation loss: 2.2606794456783814
Epoch: 9| Step: 17
Training loss: 3.135624408721924
Validation loss: 2.26004120257261
Epoch: 9| Step: 18
Training loss: 3.0125527381896973
Validation loss: 2.2619861029892516
Epoch: 9| Step: 19
Training loss: 3.6634023189544678
Validation loss: 2.26051124651655
Epoch: 192| Step: 0
Training loss: 2.7506322860717773
Validation loss: 2.2633243876395466
Epoch: 9| Step: 1
Training loss: 2.763603687286377
Validation loss: 2.262613437158598
Epoch: 9| Step: 2
Training loss: 3.4625964164733887
Validation loss: 2.259221059812916
Epoch: 9| Step: 3
Training loss: 3.122666120529175
Validation loss: 2.2619614017953116
Epoch: 9| Step: 4
Training loss: 3.0957350730895996
Validation loss: 2.265114450626236
Epoch: 9| Step: 5
Training loss: 2.597616195678711
Validation loss: 2.264576246412538
Epoch: 9| Step: 6
Training loss: 2.8082804679870605
Validation loss: 2.2624847854641703
Epoch: 9| Step: 7
Training loss: 2.214437246322632
Validation loss: 2.2586450791187422
Epoch: 9| Step: 8
Training loss: 3.4585747718811035
Validation loss: 2.258735192765435
Epoch: 9| Step: 9
Training loss: 2.438666820526123
Validation loss: 2.263932624309183
Epoch: 9| Step: 10
Training loss: 3.1607513427734375
Validation loss: 2.258511942925213
Epoch: 9| Step: 11
Training loss: 2.387387990951538
Validation loss: 2.2594180450165013
Epoch: 9| Step: 12
Training loss: 2.9262590408325195
Validation loss: 2.2610763045523665
Epoch: 9| Step: 13
Training loss: 2.1459360122680664
Validation loss: 2.2610492517622256
Epoch: 9| Step: 14
Training loss: 2.4222335815429688
Validation loss: 2.26133093902533
Epoch: 9| Step: 15
Training loss: 2.396533966064453
Validation loss: 2.263145842998148
Epoch: 9| Step: 16
Training loss: 2.4051406383514404
Validation loss: 2.2599895566487485
Epoch: 9| Step: 17
Training loss: 2.3720803260803223
Validation loss: 2.2620740897363896
Epoch: 9| Step: 18
Training loss: 3.286973714828491
Validation loss: 2.262306120755861
Epoch: 9| Step: 19
Training loss: 3.3090314865112305
Validation loss: 2.2679007971029486
Epoch: 193| Step: 0
Training loss: 2.8890292644500732
Validation loss: 2.259101604386199
Epoch: 9| Step: 1
Training loss: 3.1926231384277344
Validation loss: 2.261736504465556
Epoch: 9| Step: 2
Training loss: 3.168698310852051
Validation loss: 2.2614597948335056
Epoch: 9| Step: 3
Training loss: 3.080225944519043
Validation loss: 2.2622376963389006
Epoch: 9| Step: 4
Training loss: 2.6614253520965576
Validation loss: 2.2610462312218096
Epoch: 9| Step: 5
Training loss: 2.173452854156494
Validation loss: 2.2650386583890847
Epoch: 9| Step: 6
Training loss: 3.2558839321136475
Validation loss: 2.2619191776934287
Epoch: 9| Step: 7
Training loss: 3.4217381477355957
Validation loss: 2.2616672284311528
Epoch: 9| Step: 8
Training loss: 3.0293667316436768
Validation loss: 2.2558749322410967
Epoch: 9| Step: 9
Training loss: 3.3139865398406982
Validation loss: 2.2598125394299733
Epoch: 9| Step: 10
Training loss: 2.6767992973327637
Validation loss: 2.2578373967314795
Epoch: 9| Step: 11
Training loss: 2.76505446434021
Validation loss: 2.2604095232572488
Epoch: 9| Step: 12
Training loss: 2.083634376525879
Validation loss: 2.258906326705603
Epoch: 9| Step: 13
Training loss: 2.4616360664367676
Validation loss: 2.2620928853535824
Epoch: 9| Step: 14
Training loss: 2.4232304096221924
Validation loss: 2.2616620115238986
Epoch: 9| Step: 15
Training loss: 3.076822280883789
Validation loss: 2.2587097171399235
Epoch: 9| Step: 16
Training loss: 2.8713130950927734
Validation loss: 2.262814561240107
Epoch: 9| Step: 17
Training loss: 2.9300763607025146
Validation loss: 2.2612100179246863
Epoch: 9| Step: 18
Training loss: 1.841092824935913
Validation loss: 2.2629890218913125
Epoch: 9| Step: 19
Training loss: 2.2553420066833496
Validation loss: 2.2619470074880037
Epoch: 194| Step: 0
Training loss: 3.569333076477051
Validation loss: 2.25940477848053
Epoch: 9| Step: 1
Training loss: 2.7250990867614746
Validation loss: 2.261723518371582
Epoch: 9| Step: 2
Training loss: 2.841111183166504
Validation loss: 2.2587820214333294
Epoch: 9| Step: 3
Training loss: 2.366939067840576
Validation loss: 2.2638705823061276
Epoch: 9| Step: 4
Training loss: 2.989377737045288
Validation loss: 2.2600314737223894
Epoch: 9| Step: 5
Training loss: 2.203397274017334
Validation loss: 2.2557080117918606
Epoch: 9| Step: 6
Training loss: 3.1567845344543457
Validation loss: 2.2608402710166766
Epoch: 9| Step: 7
Training loss: 2.9248642921447754
Validation loss: 2.257772262147862
Epoch: 9| Step: 8
Training loss: 2.299713134765625
Validation loss: 2.257647008346997
Epoch: 9| Step: 9
Training loss: 3.2738492488861084
Validation loss: 2.2606856479919215
Epoch: 9| Step: 10
Training loss: 2.744842052459717
Validation loss: 2.25773827635127
Epoch: 9| Step: 11
Training loss: 2.737273693084717
Validation loss: 2.2589242870001485
Epoch: 9| Step: 12
Training loss: 2.648942470550537
Validation loss: 2.2611875413990705
Epoch: 9| Step: 13
Training loss: 2.9370689392089844
Validation loss: 2.259217891761725
Epoch: 9| Step: 14
Training loss: 2.596059799194336
Validation loss: 2.257483262809918
Epoch: 9| Step: 15
Training loss: 2.0020909309387207
Validation loss: 2.258338233549818
Epoch: 9| Step: 16
Training loss: 3.0539164543151855
Validation loss: 2.255619055933232
Epoch: 9| Step: 17
Training loss: 2.8737945556640625
Validation loss: 2.260577661528004
Epoch: 9| Step: 18
Training loss: 3.116533041000366
Validation loss: 2.2576753441378368
Epoch: 9| Step: 19
Training loss: 2.4244604110717773
Validation loss: 2.254519349379505
Epoch: 195| Step: 0
Training loss: 2.2953412532806396
Validation loss: 2.259145829317381
Epoch: 9| Step: 1
Training loss: 2.526242256164551
Validation loss: 2.2594981313609392
Epoch: 9| Step: 2
Training loss: 2.82942271232605
Validation loss: 2.256584583426551
Epoch: 9| Step: 3
Training loss: 2.7257015705108643
Validation loss: 2.2573359527176233
Epoch: 9| Step: 4
Training loss: 2.4531195163726807
Validation loss: 2.2589166678970667
Epoch: 9| Step: 5
Training loss: 2.846920967102051
Validation loss: 2.2578857734048965
Epoch: 9| Step: 6
Training loss: 3.278899669647217
Validation loss: 2.2614299136100056
Epoch: 9| Step: 7
Training loss: 3.197420120239258
Validation loss: 2.2570733612389873
Epoch: 9| Step: 8
Training loss: 2.6144869327545166
Validation loss: 2.2596274091185427
Epoch: 9| Step: 9
Training loss: 2.776270866394043
Validation loss: 2.256342315845352
Epoch: 9| Step: 10
Training loss: 3.2537035942077637
Validation loss: 2.2591929984607284
Epoch: 9| Step: 11
Training loss: 3.4164133071899414
Validation loss: 2.2592349635611337
Epoch: 9| Step: 12
Training loss: 2.279478073120117
Validation loss: 2.2555773704172037
Epoch: 9| Step: 13
Training loss: 2.436910629272461
Validation loss: 2.258157973666843
Epoch: 9| Step: 14
Training loss: 2.768094778060913
Validation loss: 2.2628407564094597
Epoch: 9| Step: 15
Training loss: 2.7287189960479736
Validation loss: 2.262214905924077
Epoch: 9| Step: 16
Training loss: 2.963108777999878
Validation loss: 2.256641708689628
Epoch: 9| Step: 17
Training loss: 2.2722318172454834
Validation loss: 2.2579380694053155
Epoch: 9| Step: 18
Training loss: 3.501810073852539
Validation loss: 2.258488647371745
Epoch: 9| Step: 19
Training loss: 2.2668519020080566
Validation loss: 2.256048252256654
Epoch: 196| Step: 0
Training loss: 3.108017921447754
Validation loss: 2.260322455879596
Epoch: 9| Step: 1
Training loss: 3.8534374237060547
Validation loss: 2.2560595213938104
Epoch: 9| Step: 2
Training loss: 3.579909563064575
Validation loss: 2.2585772987749935
Epoch: 9| Step: 3
Training loss: 3.0223941802978516
Validation loss: 2.258500836736007
Epoch: 9| Step: 4
Training loss: 2.2751617431640625
Validation loss: 2.2541850419353238
Epoch: 9| Step: 5
Training loss: 3.0711371898651123
Validation loss: 2.2574136445848203
Epoch: 9| Step: 6
Training loss: 2.36704421043396
Validation loss: 2.255755460519585
Epoch: 9| Step: 7
Training loss: 2.4371345043182373
Validation loss: 2.257411244961855
Epoch: 9| Step: 8
Training loss: 2.3829190731048584
Validation loss: 2.2579359819563174
Epoch: 9| Step: 9
Training loss: 1.6673407554626465
Validation loss: 2.260661066007271
Epoch: 9| Step: 10
Training loss: 2.5959410667419434
Validation loss: 2.2548056403510004
Epoch: 9| Step: 11
Training loss: 3.392643690109253
Validation loss: 2.2621074657646014
Epoch: 9| Step: 12
Training loss: 3.1214544773101807
Validation loss: 2.2565433001346724
Epoch: 9| Step: 13
Training loss: 2.9213404655456543
Validation loss: 2.260581642603703
Epoch: 9| Step: 14
Training loss: 2.274700164794922
Validation loss: 2.257047533131332
Epoch: 9| Step: 15
Training loss: 2.5347800254821777
Validation loss: 2.2605000571381275
Epoch: 9| Step: 16
Training loss: 2.752229690551758
Validation loss: 2.2579607912104764
Epoch: 9| Step: 17
Training loss: 3.1125974655151367
Validation loss: 2.258393556951619
Epoch: 9| Step: 18
Training loss: 2.5249993801116943
Validation loss: 2.257633993951537
Epoch: 9| Step: 19
Training loss: 2.5178582668304443
Validation loss: 2.2559121032412963
Epoch: 197| Step: 0
Training loss: 3.1826565265655518
Validation loss: 2.2600178512737905
Epoch: 9| Step: 1
Training loss: 2.024503231048584
Validation loss: 2.2549439214116376
Epoch: 9| Step: 2
Training loss: 2.8274149894714355
Validation loss: 2.2580357549859467
Epoch: 9| Step: 3
Training loss: 3.739109992980957
Validation loss: 2.255969025248246
Epoch: 9| Step: 4
Training loss: 3.0804312229156494
Validation loss: 2.256528794336662
Epoch: 9| Step: 5
Training loss: 2.856658935546875
Validation loss: 2.254377813647977
Epoch: 9| Step: 6
Training loss: 2.322171688079834
Validation loss: 2.256307828340599
Epoch: 9| Step: 7
Training loss: 2.1792373657226562
Validation loss: 2.255462023851683
Epoch: 9| Step: 8
Training loss: 3.101064682006836
Validation loss: 2.255882240885453
Epoch: 9| Step: 9
Training loss: 3.6246180534362793
Validation loss: 2.2570710696762415
Epoch: 9| Step: 10
Training loss: 3.0987350940704346
Validation loss: 2.2583296504809702
Epoch: 9| Step: 11
Training loss: 2.248971939086914
Validation loss: 2.2560241085162267
Epoch: 9| Step: 12
Training loss: 2.8778891563415527
Validation loss: 2.2560110126467916
Epoch: 9| Step: 13
Training loss: 3.0299811363220215
Validation loss: 2.2552185556013806
Epoch: 9| Step: 14
Training loss: 2.4902849197387695
Validation loss: 2.2542378696606313
Epoch: 9| Step: 15
Training loss: 2.488490104675293
Validation loss: 2.256604276972709
Epoch: 9| Step: 16
Training loss: 2.548184633255005
Validation loss: 2.2563440113616506
Epoch: 9| Step: 17
Training loss: 3.6628177165985107
Validation loss: 2.2542675484856254
Epoch: 9| Step: 18
Training loss: 1.9229567050933838
Validation loss: 2.255740534487388
Epoch: 9| Step: 19
Training loss: 2.1317028999328613
Validation loss: 2.25789266524555
Epoch: 198| Step: 0
Training loss: 2.599822998046875
Validation loss: 2.2531198374659036
Epoch: 9| Step: 1
Training loss: 2.853573799133301
Validation loss: 2.255853865644057
Epoch: 9| Step: 2
Training loss: 2.9433579444885254
Validation loss: 2.256342646029356
Epoch: 9| Step: 3
Training loss: 2.426379680633545
Validation loss: 2.2565420908893614
Epoch: 9| Step: 4
Training loss: 2.2648651599884033
Validation loss: 2.2552205229834685
Epoch: 9| Step: 5
Training loss: 2.4395790100097656
Validation loss: 2.258402097139427
Epoch: 9| Step: 6
Training loss: 3.7312068939208984
Validation loss: 2.254450676252516
Epoch: 9| Step: 7
Training loss: 3.4303576946258545
Validation loss: 2.255643400356924
Epoch: 9| Step: 8
Training loss: 3.0578341484069824
Validation loss: 2.256872207140751
Epoch: 9| Step: 9
Training loss: 2.7378005981445312
Validation loss: 2.254785831026036
Epoch: 9| Step: 10
Training loss: 2.278548240661621
Validation loss: 2.257220763954327
Epoch: 9| Step: 11
Training loss: 2.5208210945129395
Validation loss: 2.2532531374650038
Epoch: 9| Step: 12
Training loss: 1.9040234088897705
Validation loss: 2.254907362752681
Epoch: 9| Step: 13
Training loss: 3.0974087715148926
Validation loss: 2.2553611573555488
Epoch: 9| Step: 14
Training loss: 2.806218147277832
Validation loss: 2.2557611774197586
Epoch: 9| Step: 15
Training loss: 2.658385753631592
Validation loss: 2.256236259885829
Epoch: 9| Step: 16
Training loss: 2.9989075660705566
Validation loss: 2.255236805771752
Epoch: 9| Step: 17
Training loss: 1.7405818700790405
Validation loss: 2.256432354879036
Epoch: 9| Step: 18
Training loss: 3.3455147743225098
Validation loss: 2.2567583554082637
Epoch: 9| Step: 19
Training loss: 3.6424801349639893
Validation loss: 2.254604044578058
Epoch: 199| Step: 0
Training loss: 2.471864700317383
Validation loss: 2.2556727344183614
Epoch: 9| Step: 1
Training loss: 2.3487346172332764
Validation loss: 2.2582355694805116
Epoch: 9| Step: 2
Training loss: 2.6296472549438477
Validation loss: 2.2591833159220305
Epoch: 9| Step: 3
Training loss: 3.6961605548858643
Validation loss: 2.254073709892712
Epoch: 9| Step: 4
Training loss: 2.787595748901367
Validation loss: 2.2542062852022458
Epoch: 9| Step: 5
Training loss: 3.3425395488739014
Validation loss: 2.2544120575884263
Epoch: 9| Step: 6
Training loss: 2.76070499420166
Validation loss: 2.2588977796568286
Epoch: 9| Step: 7
Training loss: 3.0239200592041016
Validation loss: 2.254836547288963
Epoch: 9| Step: 8
Training loss: 2.527705430984497
Validation loss: 2.254508304938996
Epoch: 9| Step: 9
Training loss: 3.11519193649292
Validation loss: 2.254686381319444
Epoch: 9| Step: 10
Training loss: 2.901014566421509
Validation loss: 2.255281228813336
Epoch: 9| Step: 11
Training loss: 2.674811363220215
Validation loss: 2.253631000896152
Epoch: 9| Step: 12
Training loss: 3.031834602355957
Validation loss: 2.254706998523191
Epoch: 9| Step: 13
Training loss: 2.766773223876953
Validation loss: 2.2535070292383645
Epoch: 9| Step: 14
Training loss: 2.7042932510375977
Validation loss: 2.255747477785289
Epoch: 9| Step: 15
Training loss: 2.4729902744293213
Validation loss: 2.255102690175283
Epoch: 9| Step: 16
Training loss: 2.891758918762207
Validation loss: 2.2574481569605767
Epoch: 9| Step: 17
Training loss: 2.627455711364746
Validation loss: 2.255490327910554
Epoch: 9| Step: 18
Training loss: 2.9615538120269775
Validation loss: 2.2530239417398574
Epoch: 9| Step: 19
Training loss: 1.6809608936309814
Validation loss: 2.2509374241177125
Epoch: 200| Step: 0
Training loss: 2.460509777069092
Validation loss: 2.2533588100680344
Epoch: 9| Step: 1
Training loss: 2.4586963653564453
Validation loss: 2.252107489880898
Epoch: 9| Step: 2
Training loss: 2.3612451553344727
Validation loss: 2.2517324934760445
Epoch: 9| Step: 3
Training loss: 2.1838669776916504
Validation loss: 2.256967872166805
Epoch: 9| Step: 4
Training loss: 2.529815673828125
Validation loss: 2.2511530677191645
Epoch: 9| Step: 5
Training loss: 3.1927874088287354
Validation loss: 2.2536428266291995
Epoch: 9| Step: 6
Training loss: 2.464836359024048
Validation loss: 2.25435989451923
Epoch: 9| Step: 7
Training loss: 3.4517276287078857
Validation loss: 2.2574346562941296
Epoch: 9| Step: 8
Training loss: 3.670217514038086
Validation loss: 2.2531416484777878
Epoch: 9| Step: 9
Training loss: 3.167555809020996
Validation loss: 2.252335851998638
Epoch: 9| Step: 10
Training loss: 2.6175663471221924
Validation loss: 2.257846348577266
Epoch: 9| Step: 11
Training loss: 2.285696268081665
Validation loss: 2.253534635193914
Epoch: 9| Step: 12
Training loss: 2.704728126525879
Validation loss: 2.2543432643945267
Epoch: 9| Step: 13
Training loss: 2.586258888244629
Validation loss: 2.2542222841180486
Epoch: 9| Step: 14
Training loss: 2.0599727630615234
Validation loss: 2.2563731361636155
Epoch: 9| Step: 15
Training loss: 3.329073905944824
Validation loss: 2.256274719032452
Epoch: 9| Step: 16
Training loss: 3.1810302734375
Validation loss: 2.253252636614463
Epoch: 9| Step: 17
Training loss: 3.3941829204559326
Validation loss: 2.254219844186906
Epoch: 9| Step: 18
Training loss: 2.5879244804382324
Validation loss: 2.2539983739098197
Epoch: 9| Step: 19
Training loss: 2.703871488571167
Validation loss: 2.2535717727469025
