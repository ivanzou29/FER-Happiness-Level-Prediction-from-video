Epoch: 1| Step: 0
Training loss: 5.992336465309384
Validation loss: 5.859192054435638

Epoch: 6| Step: 1
Training loss: 5.240645294059171
Validation loss: 5.857575325833628

Epoch: 6| Step: 2
Training loss: 6.4168452778848035
Validation loss: 5.855884322641169

Epoch: 6| Step: 3
Training loss: 5.071268658640111
Validation loss: 5.854114120446681

Epoch: 6| Step: 4
Training loss: 7.101527852896092
Validation loss: 5.852461904917514

Epoch: 6| Step: 5
Training loss: 5.519961459813127
Validation loss: 5.850812346958645

Epoch: 6| Step: 6
Training loss: 5.7208281529739535
Validation loss: 5.84919218805708

Epoch: 6| Step: 7
Training loss: 6.168693553044047
Validation loss: 5.847367362151319

Epoch: 6| Step: 8
Training loss: 6.971176751298992
Validation loss: 5.845586124485174

Epoch: 6| Step: 9
Training loss: 5.956117693781557
Validation loss: 5.843807770958591

Epoch: 6| Step: 10
Training loss: 6.182673257450893
Validation loss: 5.841896375129523

Epoch: 6| Step: 11
Training loss: 5.625355009956004
Validation loss: 5.839892224096825

Epoch: 6| Step: 12
Training loss: 5.557790069491917
Validation loss: 5.83782666944413

Epoch: 6| Step: 13
Training loss: 5.602889963763783
Validation loss: 5.83567529622964

Epoch: 2| Step: 0
Training loss: 5.376742058493621
Validation loss: 5.833579993709646

Epoch: 6| Step: 1
Training loss: 6.362545938082411
Validation loss: 5.831109095183143

Epoch: 6| Step: 2
Training loss: 6.149250524489911
Validation loss: 5.828782604436391

Epoch: 6| Step: 3
Training loss: 5.273127703573871
Validation loss: 5.826267931772193

Epoch: 6| Step: 4
Training loss: 5.412457909541523
Validation loss: 5.823650698268598

Epoch: 6| Step: 5
Training loss: 5.416584170764772
Validation loss: 5.820891472269667

Epoch: 6| Step: 6
Training loss: 6.485340313125501
Validation loss: 5.818062229941387

Epoch: 6| Step: 7
Training loss: 5.7256344905891625
Validation loss: 5.8151955319060535

Epoch: 6| Step: 8
Training loss: 5.766250204288488
Validation loss: 5.812218252483816

Epoch: 6| Step: 9
Training loss: 5.532704135250481
Validation loss: 5.8090385329998275

Epoch: 6| Step: 10
Training loss: 6.1650556917297115
Validation loss: 5.805646677635521

Epoch: 6| Step: 11
Training loss: 6.185764878637812
Validation loss: 5.802255551460689

Epoch: 6| Step: 12
Training loss: 6.245278062455872
Validation loss: 5.79848406481825

Epoch: 6| Step: 13
Training loss: 6.710960805583805
Validation loss: 5.794564553577795

Epoch: 3| Step: 0
Training loss: 6.3931297859086715
Validation loss: 5.790256447479658

Epoch: 6| Step: 1
Training loss: 5.922845685410316
Validation loss: 5.786162315325628

Epoch: 6| Step: 2
Training loss: 5.1880474491111315
Validation loss: 5.78155865919247

Epoch: 6| Step: 3
Training loss: 6.28350334173584
Validation loss: 5.777053244515041

Epoch: 6| Step: 4
Training loss: 6.29367824843115
Validation loss: 5.772318358605428

Epoch: 6| Step: 5
Training loss: 6.183340813288659
Validation loss: 5.767209160191421

Epoch: 6| Step: 6
Training loss: 5.840658910498803
Validation loss: 5.76193254149615

Epoch: 6| Step: 7
Training loss: 5.557085638210489
Validation loss: 5.756514245456014

Epoch: 6| Step: 8
Training loss: 5.432788781022964
Validation loss: 5.7510166098803035

Epoch: 6| Step: 9
Training loss: 5.132553303065977
Validation loss: 5.745436142583595

Epoch: 6| Step: 10
Training loss: 5.729253742827859
Validation loss: 5.739533088958019

Epoch: 6| Step: 11
Training loss: 4.860854141467232
Validation loss: 5.733598315229382

Epoch: 6| Step: 12
Training loss: 6.9537641252960185
Validation loss: 5.727380573565579

Epoch: 6| Step: 13
Training loss: 6.112684363332726
Validation loss: 5.720992213314531

Epoch: 4| Step: 0
Training loss: 5.707753098599335
Validation loss: 5.7145956545743415

Epoch: 6| Step: 1
Training loss: 5.914188922856149
Validation loss: 5.707986482352504

Epoch: 6| Step: 2
Training loss: 6.026928554234865
Validation loss: 5.701034594777193

Epoch: 6| Step: 3
Training loss: 5.693188850898254
Validation loss: 5.6941254978747065

Epoch: 6| Step: 4
Training loss: 6.023999218903955
Validation loss: 5.687329439952374

Epoch: 6| Step: 5
Training loss: 5.459897969728349
Validation loss: 5.6802347471414825

Epoch: 6| Step: 6
Training loss: 5.167378940502244
Validation loss: 5.672914912344607

Epoch: 6| Step: 7
Training loss: 6.535095834766318
Validation loss: 5.665787497741492

Epoch: 6| Step: 8
Training loss: 5.8057283723572315
Validation loss: 5.658547203655162

Epoch: 6| Step: 9
Training loss: 6.3122126447784055
Validation loss: 5.651361140583065

Epoch: 6| Step: 10
Training loss: 5.8039326850883715
Validation loss: 5.643774166175132

Epoch: 6| Step: 11
Training loss: 6.004219478857595
Validation loss: 5.636316628320684

Epoch: 6| Step: 12
Training loss: 5.92134417970542
Validation loss: 5.628874821677746

Epoch: 6| Step: 13
Training loss: 4.327508655277193
Validation loss: 5.621188391162026

Epoch: 5| Step: 0
Training loss: 5.709052196077652
Validation loss: 5.614019286558016

Epoch: 6| Step: 1
Training loss: 6.511818338695566
Validation loss: 5.606447693944364

Epoch: 6| Step: 2
Training loss: 5.83413770670197
Validation loss: 5.598649023220978

Epoch: 6| Step: 3
Training loss: 5.310577403714199
Validation loss: 5.591454686762602

Epoch: 6| Step: 4
Training loss: 4.36448364629532
Validation loss: 5.5836293251189195

Epoch: 6| Step: 5
Training loss: 6.009416185100029
Validation loss: 5.576641494563437

Epoch: 6| Step: 6
Training loss: 5.770349401939105
Validation loss: 5.568932689177538

Epoch: 6| Step: 7
Training loss: 5.561881041647291
Validation loss: 5.56137679400428

Epoch: 6| Step: 8
Training loss: 5.855454091772013
Validation loss: 5.553998558360192

Epoch: 6| Step: 9
Training loss: 6.14702988523011
Validation loss: 5.546098767622352

Epoch: 6| Step: 10
Training loss: 4.810482047941696
Validation loss: 5.538422009912537

Epoch: 6| Step: 11
Training loss: 6.335157767411028
Validation loss: 5.53055950387971

Epoch: 6| Step: 12
Training loss: 5.251729044703694
Validation loss: 5.523265643505998

Epoch: 6| Step: 13
Training loss: 5.738775160627769
Validation loss: 5.515324542081277

Epoch: 6| Step: 0
Training loss: 5.647206870176646
Validation loss: 5.507354904897868

Epoch: 6| Step: 1
Training loss: 5.500055486225798
Validation loss: 5.499968817651381

Epoch: 6| Step: 2
Training loss: 4.64791102914142
Validation loss: 5.492228566174928

Epoch: 6| Step: 3
Training loss: 5.365373196522667
Validation loss: 5.484996879945353

Epoch: 6| Step: 4
Training loss: 5.222161554205095
Validation loss: 5.477274414459394

Epoch: 6| Step: 5
Training loss: 6.830827889484679
Validation loss: 5.47027616004819

Epoch: 6| Step: 6
Training loss: 5.281652311091095
Validation loss: 5.462600098368583

Epoch: 6| Step: 7
Training loss: 6.034090154119104
Validation loss: 5.4553791040051784

Epoch: 6| Step: 8
Training loss: 6.271325008680538
Validation loss: 5.4480118557823864

Epoch: 6| Step: 9
Training loss: 5.035504550295809
Validation loss: 5.440560922641565

Epoch: 6| Step: 10
Training loss: 4.68819371494373
Validation loss: 5.43330487475909

Epoch: 6| Step: 11
Training loss: 5.904547874978249
Validation loss: 5.425943949388223

Epoch: 6| Step: 12
Training loss: 5.035870627901101
Validation loss: 5.4186903865575395

Epoch: 6| Step: 13
Training loss: 6.1833673412830725
Validation loss: 5.411673175951575

Epoch: 7| Step: 0
Training loss: 5.130981676192752
Validation loss: 5.404013169147174

Epoch: 6| Step: 1
Training loss: 5.602455227633392
Validation loss: 5.3967381409751445

Epoch: 6| Step: 2
Training loss: 6.018301073803254
Validation loss: 5.389217203938623

Epoch: 6| Step: 3
Training loss: 6.125560501299299
Validation loss: 5.381452191992618

Epoch: 6| Step: 4
Training loss: 4.949101591944018
Validation loss: 5.373908383020907

Epoch: 6| Step: 5
Training loss: 5.198410510172835
Validation loss: 5.36603268300389

Epoch: 6| Step: 6
Training loss: 5.606961637003425
Validation loss: 5.358388470751165

Epoch: 6| Step: 7
Training loss: 5.205363207483813
Validation loss: 5.350308592978549

Epoch: 6| Step: 8
Training loss: 5.539484134439597
Validation loss: 5.342747555228846

Epoch: 6| Step: 9
Training loss: 6.013900866458624
Validation loss: 5.3347707937163005

Epoch: 6| Step: 10
Training loss: 5.057251081163047
Validation loss: 5.326701491476397

Epoch: 6| Step: 11
Training loss: 6.029843497451635
Validation loss: 5.318702517640061

Epoch: 6| Step: 12
Training loss: 5.228808184287905
Validation loss: 5.310783348229359

Epoch: 6| Step: 13
Training loss: 4.736094348289877
Validation loss: 5.302552308012374

Epoch: 8| Step: 0
Training loss: 5.379492368325207
Validation loss: 5.294552934532871

Epoch: 6| Step: 1
Training loss: 5.365601595437089
Validation loss: 5.2865276563887855

Epoch: 6| Step: 2
Training loss: 6.402416440633714
Validation loss: 5.278310254769943

Epoch: 6| Step: 3
Training loss: 5.31514216522684
Validation loss: 5.269497436988053

Epoch: 6| Step: 4
Training loss: 4.692348160154308
Validation loss: 5.261539251319161

Epoch: 6| Step: 5
Training loss: 5.195519372937168
Validation loss: 5.252993714074228

Epoch: 6| Step: 6
Training loss: 6.020070521553103
Validation loss: 5.244871359266722

Epoch: 6| Step: 7
Training loss: 5.536063992753367
Validation loss: 5.236627107531929

Epoch: 6| Step: 8
Training loss: 4.865678923889333
Validation loss: 5.228461057111977

Epoch: 6| Step: 9
Training loss: 5.468832658415501
Validation loss: 5.220282993806057

Epoch: 6| Step: 10
Training loss: 5.416285379145896
Validation loss: 5.212273452677971

Epoch: 6| Step: 11
Training loss: 5.823060317704346
Validation loss: 5.203881194462839

Epoch: 6| Step: 12
Training loss: 4.546919465257237
Validation loss: 5.195758481112368

Epoch: 6| Step: 13
Training loss: 4.766385177268099
Validation loss: 5.187399744497453

Epoch: 9| Step: 0
Training loss: 5.6378388432004165
Validation loss: 5.179650614872282

Epoch: 6| Step: 1
Training loss: 5.677148474456643
Validation loss: 5.17216999484221

Epoch: 6| Step: 2
Training loss: 5.3067455765753415
Validation loss: 5.164270009206205

Epoch: 6| Step: 3
Training loss: 5.12212905486454
Validation loss: 5.156923593006992

Epoch: 6| Step: 4
Training loss: 5.0133281451732765
Validation loss: 5.148970704163817

Epoch: 6| Step: 5
Training loss: 5.35536012323733
Validation loss: 5.14115548995865

Epoch: 6| Step: 6
Training loss: 4.764784441752553
Validation loss: 5.13291478164002

Epoch: 6| Step: 7
Training loss: 4.432713896038279
Validation loss: 5.124511943621462

Epoch: 6| Step: 8
Training loss: 5.400522891972024
Validation loss: 5.116680432693569

Epoch: 6| Step: 9
Training loss: 5.101436128555416
Validation loss: 5.108947456040387

Epoch: 6| Step: 10
Training loss: 5.191849872587545
Validation loss: 5.100375681485155

Epoch: 6| Step: 11
Training loss: 6.082127212031975
Validation loss: 5.092064732767654

Epoch: 6| Step: 12
Training loss: 4.754502822443483
Validation loss: 5.083954799164036

Epoch: 6| Step: 13
Training loss: 5.4814871550770246
Validation loss: 5.075781022030195

Epoch: 10| Step: 0
Training loss: 4.690587158863745
Validation loss: 5.067988556200379

Epoch: 6| Step: 1
Training loss: 5.778388887675096
Validation loss: 5.060591506712116

Epoch: 6| Step: 2
Training loss: 4.799610662564937
Validation loss: 5.0533791155154555

Epoch: 6| Step: 3
Training loss: 5.456691854267715
Validation loss: 5.046662065326671

Epoch: 6| Step: 4
Training loss: 5.41721708973477
Validation loss: 5.039517230824741

Epoch: 6| Step: 5
Training loss: 4.640186224850673
Validation loss: 5.032401227643434

Epoch: 6| Step: 6
Training loss: 5.6841226128514935
Validation loss: 5.025711486196212

Epoch: 6| Step: 7
Training loss: 4.647100483927031
Validation loss: 5.0189449299366835

Epoch: 6| Step: 8
Training loss: 5.501827976589633
Validation loss: 5.01253369098861

Epoch: 6| Step: 9
Training loss: 4.489547457924142
Validation loss: 5.006140847986638

Epoch: 6| Step: 10
Training loss: 4.375813871703746
Validation loss: 4.999697898639183

Epoch: 6| Step: 11
Training loss: 5.516910738122126
Validation loss: 4.993410727729172

Epoch: 6| Step: 12
Training loss: 4.908147942885182
Validation loss: 4.9863896777663035

Epoch: 6| Step: 13
Training loss: 5.838320897806296
Validation loss: 4.979988551707558

Epoch: 11| Step: 0
Training loss: 5.127555768152852
Validation loss: 4.973097268980032

Epoch: 6| Step: 1
Training loss: 5.192773184057287
Validation loss: 4.9661116242959995

Epoch: 6| Step: 2
Training loss: 5.145567770011512
Validation loss: 4.959097549571348

Epoch: 6| Step: 3
Training loss: 5.4301859455341095
Validation loss: 4.95156909721098

Epoch: 6| Step: 4
Training loss: 5.131452824513732
Validation loss: 4.943963500121687

Epoch: 6| Step: 5
Training loss: 5.812201379467876
Validation loss: 4.936308801590087

Epoch: 6| Step: 6
Training loss: 4.695841170775206
Validation loss: 4.929667848123675

Epoch: 6| Step: 7
Training loss: 6.343724142688989
Validation loss: 4.92273823267686

Epoch: 6| Step: 8
Training loss: 4.817006960841038
Validation loss: 4.916678487903587

Epoch: 6| Step: 9
Training loss: 5.182504845712166
Validation loss: 4.909193512564662

Epoch: 6| Step: 10
Training loss: 4.384979854524415
Validation loss: 4.90317168317898

Epoch: 6| Step: 11
Training loss: 4.432558558938389
Validation loss: 4.897213431557387

Epoch: 6| Step: 12
Training loss: 3.9687656192021636
Validation loss: 4.890801667261343

Epoch: 6| Step: 13
Training loss: 4.645959735513608
Validation loss: 4.884425872778612

Epoch: 12| Step: 0
Training loss: 4.467576519738279
Validation loss: 4.878255718792374

Epoch: 6| Step: 1
Training loss: 4.787196232892151
Validation loss: 4.872802206355683

Epoch: 6| Step: 2
Training loss: 5.274229541214335
Validation loss: 4.866661896550876

Epoch: 6| Step: 3
Training loss: 4.8904372109139285
Validation loss: 4.861087738465327

Epoch: 6| Step: 4
Training loss: 4.327728363481925
Validation loss: 4.855841984703764

Epoch: 6| Step: 5
Training loss: 5.280910864781527
Validation loss: 4.850252344180223

Epoch: 6| Step: 6
Training loss: 5.892898889699258
Validation loss: 4.84554255961516

Epoch: 6| Step: 7
Training loss: 5.31514216522684
Validation loss: 4.839554280021297

Epoch: 6| Step: 8
Training loss: 5.8326758241211305
Validation loss: 4.834970602520132

Epoch: 6| Step: 9
Training loss: 4.644153833093759
Validation loss: 4.828288811103214

Epoch: 6| Step: 10
Training loss: 5.1722533672490885
Validation loss: 4.82262069859603

Epoch: 6| Step: 11
Training loss: 3.8066428797613896
Validation loss: 4.817535540257137

Epoch: 6| Step: 12
Training loss: 5.0954819057720915
Validation loss: 4.811557132455085

Epoch: 6| Step: 13
Training loss: 4.328690805187414
Validation loss: 4.8064551763968

Epoch: 13| Step: 0
Training loss: 5.386012129879398
Validation loss: 4.800655006381463

Epoch: 6| Step: 1
Training loss: 4.5972052833473
Validation loss: 4.795291701464701

Epoch: 6| Step: 2
Training loss: 5.036704950563732
Validation loss: 4.790346688059749

Epoch: 6| Step: 3
Training loss: 4.529199807268944
Validation loss: 4.785198999330728

Epoch: 6| Step: 4
Training loss: 5.241150436492853
Validation loss: 4.779742333558109

Epoch: 6| Step: 5
Training loss: 4.531764770732905
Validation loss: 4.774429343111924

Epoch: 6| Step: 6
Training loss: 5.187176062339603
Validation loss: 4.7697156682499315

Epoch: 6| Step: 7
Training loss: 5.452939967647864
Validation loss: 4.764130221384231

Epoch: 6| Step: 8
Training loss: 4.245940569770317
Validation loss: 4.759909181930581

Epoch: 6| Step: 9
Training loss: 5.030800746028433
Validation loss: 4.754202940811108

Epoch: 6| Step: 10
Training loss: 4.370433276801917
Validation loss: 4.749412065225725

Epoch: 6| Step: 11
Training loss: 4.683692301142053
Validation loss: 4.743999974864598

Epoch: 6| Step: 12
Training loss: 5.247496598430256
Validation loss: 4.738883713727726

Epoch: 6| Step: 13
Training loss: 4.787359186795831
Validation loss: 4.733906587398673

Epoch: 14| Step: 0
Training loss: 4.184016586577177
Validation loss: 4.7295595697652795

Epoch: 6| Step: 1
Training loss: 4.5644748541951765
Validation loss: 4.72350629040724

Epoch: 6| Step: 2
Training loss: 4.552147603690607
Validation loss: 4.718414008365912

Epoch: 6| Step: 3
Training loss: 5.4166530119895
Validation loss: 4.714490285717423

Epoch: 6| Step: 4
Training loss: 4.6333793820807525
Validation loss: 4.709000526125221

Epoch: 6| Step: 5
Training loss: 5.563271458310088
Validation loss: 4.704407306977645

Epoch: 6| Step: 6
Training loss: 5.356502908902966
Validation loss: 4.69960583122914

Epoch: 6| Step: 7
Training loss: 4.331234032187265
Validation loss: 4.694532383553439

Epoch: 6| Step: 8
Training loss: 5.017480239715211
Validation loss: 4.688904954381562

Epoch: 6| Step: 9
Training loss: 4.930746747579876
Validation loss: 4.684016344669013

Epoch: 6| Step: 10
Training loss: 4.0887100994947
Validation loss: 4.679007640569592

Epoch: 6| Step: 11
Training loss: 4.801094311903993
Validation loss: 4.67454107415337

Epoch: 6| Step: 12
Training loss: 5.001035964455109
Validation loss: 4.669969763484333

Epoch: 6| Step: 13
Training loss: 4.8326493579499985
Validation loss: 4.6633896675188335

Epoch: 15| Step: 0
Training loss: 4.5219789568189155
Validation loss: 4.659345344706638

Epoch: 6| Step: 1
Training loss: 4.950949206038321
Validation loss: 4.65479718442218

Epoch: 6| Step: 2
Training loss: 5.227556849662668
Validation loss: 4.648898694323047

Epoch: 6| Step: 3
Training loss: 4.011798148404893
Validation loss: 4.643776317058076

Epoch: 6| Step: 4
Training loss: 4.416120363433389
Validation loss: 4.6399373959012085

Epoch: 6| Step: 5
Training loss: 5.38844427697589
Validation loss: 4.6340774601814845

Epoch: 6| Step: 6
Training loss: 4.7919461154996865
Validation loss: 4.62923213707573

Epoch: 6| Step: 7
Training loss: 4.909885104635612
Validation loss: 4.624489283501412

Epoch: 6| Step: 8
Training loss: 4.720576255018381
Validation loss: 4.620392058995528

Epoch: 6| Step: 9
Training loss: 4.329132733963176
Validation loss: 4.6143509380759165

Epoch: 6| Step: 10
Training loss: 4.7267848443312515
Validation loss: 4.609712025880559

Epoch: 6| Step: 11
Training loss: 4.664139176701694
Validation loss: 4.605199959687003

Epoch: 6| Step: 12
Training loss: 4.779635287620387
Validation loss: 4.5995770474193485

Epoch: 6| Step: 13
Training loss: 4.9658866645333575
Validation loss: 4.594552452255995

Epoch: 16| Step: 0
Training loss: 4.574066967486033
Validation loss: 4.591161418101459

Epoch: 6| Step: 1
Training loss: 4.966444716305336
Validation loss: 4.586135314106335

Epoch: 6| Step: 2
Training loss: 4.432829642304711
Validation loss: 4.579828234093329

Epoch: 6| Step: 3
Training loss: 5.338414255498131
Validation loss: 4.574732125366453

Epoch: 6| Step: 4
Training loss: 4.911661261866331
Validation loss: 4.5699859589431275

Epoch: 6| Step: 5
Training loss: 4.212701148598987
Validation loss: 4.565809556249673

Epoch: 6| Step: 6
Training loss: 4.460300807644899
Validation loss: 4.562786250083674

Epoch: 6| Step: 7
Training loss: 5.566291459890964
Validation loss: 4.555240586616832

Epoch: 6| Step: 8
Training loss: 4.531730889420286
Validation loss: 4.550414937001584

Epoch: 6| Step: 9
Training loss: 4.204020691912368
Validation loss: 4.546870210870098

Epoch: 6| Step: 10
Training loss: 3.718978233706565
Validation loss: 4.541715580854744

Epoch: 6| Step: 11
Training loss: 4.581486948502828
Validation loss: 4.5373191440153775

Epoch: 6| Step: 12
Training loss: 5.205445284892895
Validation loss: 4.532015786190883

Epoch: 6| Step: 13
Training loss: 4.581087683577342
Validation loss: 4.527482108283189

Epoch: 17| Step: 0
Training loss: 4.209702347768964
Validation loss: 4.5234724097258185

Epoch: 6| Step: 1
Training loss: 4.839754290057995
Validation loss: 4.519596065319142

Epoch: 6| Step: 2
Training loss: 5.196894217046738
Validation loss: 4.513330019400736

Epoch: 6| Step: 3
Training loss: 4.974572566854402
Validation loss: 4.508707381906252

Epoch: 6| Step: 4
Training loss: 4.094519157078832
Validation loss: 4.503332281801979

Epoch: 6| Step: 5
Training loss: 4.83365785671233
Validation loss: 4.49881511559493

Epoch: 6| Step: 6
Training loss: 3.402678130544088
Validation loss: 4.494377031647218

Epoch: 6| Step: 7
Training loss: 4.537154356347193
Validation loss: 4.490310975812834

Epoch: 6| Step: 8
Training loss: 4.3544152050481015
Validation loss: 4.484705151888744

Epoch: 6| Step: 9
Training loss: 5.448170507095905
Validation loss: 4.48053420134599

Epoch: 6| Step: 10
Training loss: 4.143934776823872
Validation loss: 4.475417846834852

Epoch: 6| Step: 11
Training loss: 4.94713627600595
Validation loss: 4.471852734837084

Epoch: 6| Step: 12
Training loss: 4.3933880891605215
Validation loss: 4.4673124370825334

Epoch: 6| Step: 13
Training loss: 4.921799819614312
Validation loss: 4.463093964043636

Epoch: 18| Step: 0
Training loss: 4.100394644003461
Validation loss: 4.456756966721512

Epoch: 6| Step: 1
Training loss: 4.031211202272118
Validation loss: 4.451289176650679

Epoch: 6| Step: 2
Training loss: 4.676114305507185
Validation loss: 4.446809397088664

Epoch: 6| Step: 3
Training loss: 5.01636573336698
Validation loss: 4.44296796367279

Epoch: 6| Step: 4
Training loss: 4.648040703258782
Validation loss: 4.438034705958244

Epoch: 6| Step: 5
Training loss: 4.36903781624963
Validation loss: 4.433376706898316

Epoch: 6| Step: 6
Training loss: 3.3249051991191996
Validation loss: 4.427474090684169

Epoch: 6| Step: 7
Training loss: 4.738889851681213
Validation loss: 4.422916824309672

Epoch: 6| Step: 8
Training loss: 5.252878036003959
Validation loss: 4.418899271744498

Epoch: 6| Step: 9
Training loss: 3.7949867105565445
Validation loss: 4.415599940094566

Epoch: 6| Step: 10
Training loss: 4.868855051418018
Validation loss: 4.411364948075441

Epoch: 6| Step: 11
Training loss: 5.168559599278974
Validation loss: 4.406603859835219

Epoch: 6| Step: 12
Training loss: 4.141256032398735
Validation loss: 4.399760524417308

Epoch: 6| Step: 13
Training loss: 5.165562952757084
Validation loss: 4.39636886492389

Epoch: 19| Step: 0
Training loss: 5.240159758250906
Validation loss: 4.394649557145926

Epoch: 6| Step: 1
Training loss: 4.2919360820067265
Validation loss: 4.390215129432794

Epoch: 6| Step: 2
Training loss: 5.004689115916458
Validation loss: 4.384314893227595

Epoch: 6| Step: 3
Training loss: 4.139360112297821
Validation loss: 4.378376320980154

Epoch: 6| Step: 4
Training loss: 4.255900158277513
Validation loss: 4.374386499168781

Epoch: 6| Step: 5
Training loss: 4.355850818794282
Validation loss: 4.370298457017999

Epoch: 6| Step: 6
Training loss: 4.743678051952018
Validation loss: 4.366184217188797

Epoch: 6| Step: 7
Training loss: 4.438682291196086
Validation loss: 4.359887934944831

Epoch: 6| Step: 8
Training loss: 4.397373429862995
Validation loss: 4.353392256843786

Epoch: 6| Step: 9
Training loss: 4.411416994491905
Validation loss: 4.348884054984909

Epoch: 6| Step: 10
Training loss: 2.634086142345738
Validation loss: 4.343945908188009

Epoch: 6| Step: 11
Training loss: 5.439892823341593
Validation loss: 4.3396367785672325

Epoch: 6| Step: 12
Training loss: 4.6839054821586545
Validation loss: 4.3353897802694545

Epoch: 6| Step: 13
Training loss: 4.233839613509799
Validation loss: 4.32965567613936

Epoch: 20| Step: 0
Training loss: 4.255239062468731
Validation loss: 4.3242751901510434

Epoch: 6| Step: 1
Training loss: 4.582916980674843
Validation loss: 4.320594672610689

Epoch: 6| Step: 2
Training loss: 4.457687449982715
Validation loss: 4.315777311922092

Epoch: 6| Step: 3
Training loss: 4.305305339693477
Validation loss: 4.3109335334872965

Epoch: 6| Step: 4
Training loss: 4.183298308895857
Validation loss: 4.305826506070635

Epoch: 6| Step: 5
Training loss: 5.006537931355905
Validation loss: 4.301661503811004

Epoch: 6| Step: 6
Training loss: 4.653867175860497
Validation loss: 4.296803458803108

Epoch: 6| Step: 7
Training loss: 5.044069815591913
Validation loss: 4.2919317675935424

Epoch: 6| Step: 8
Training loss: 4.426775801205729
Validation loss: 4.2861173856476

Epoch: 6| Step: 9
Training loss: 3.9567582995616375
Validation loss: 4.2813499791706695

Epoch: 6| Step: 10
Training loss: 3.966707199487974
Validation loss: 4.276737666047409

Epoch: 6| Step: 11
Training loss: 4.137140384039557
Validation loss: 4.271720545966369

Epoch: 6| Step: 12
Training loss: 4.708963312634356
Validation loss: 4.267819241972804

Epoch: 6| Step: 13
Training loss: 4.09664535053399
Validation loss: 4.262625789184622

Epoch: 21| Step: 0
Training loss: 4.163246633106928
Validation loss: 4.257561875179485

Epoch: 6| Step: 1
Training loss: 4.274633934008314
Validation loss: 4.252820668390787

Epoch: 6| Step: 2
Training loss: 4.850231141550354
Validation loss: 4.2482570365279235

Epoch: 6| Step: 3
Training loss: 3.4822838499708175
Validation loss: 4.243135780676268

Epoch: 6| Step: 4
Training loss: 3.801315034901458
Validation loss: 4.23880040143203

Epoch: 6| Step: 5
Training loss: 4.872154383451087
Validation loss: 4.234650662729048

Epoch: 6| Step: 6
Training loss: 4.0973741636102865
Validation loss: 4.230556178341644

Epoch: 6| Step: 7
Training loss: 4.416753924005698
Validation loss: 4.2256353634155825

Epoch: 6| Step: 8
Training loss: 3.651878939340358
Validation loss: 4.221287715262542

Epoch: 6| Step: 9
Training loss: 3.64789049512072
Validation loss: 4.2164140992547745

Epoch: 6| Step: 10
Training loss: 4.163105752760431
Validation loss: 4.211534333972362

Epoch: 6| Step: 11
Training loss: 5.339279714290275
Validation loss: 4.206840187298602

Epoch: 6| Step: 12
Training loss: 4.908816109938963
Validation loss: 4.202214252258826

Epoch: 6| Step: 13
Training loss: 4.849653031040919
Validation loss: 4.197456101109792

Epoch: 22| Step: 0
Training loss: 4.38401345511272
Validation loss: 4.192652042871917

Epoch: 6| Step: 1
Training loss: 4.312133331190815
Validation loss: 4.187861203989139

Epoch: 6| Step: 2
Training loss: 4.408259805932673
Validation loss: 4.182800901708244

Epoch: 6| Step: 3
Training loss: 3.6860867394493892
Validation loss: 4.177393488733219

Epoch: 6| Step: 4
Training loss: 3.6088790222507057
Validation loss: 4.172683580312983

Epoch: 6| Step: 5
Training loss: 3.789660094023587
Validation loss: 4.168479480573481

Epoch: 6| Step: 6
Training loss: 4.3175572030276586
Validation loss: 4.163415320550968

Epoch: 6| Step: 7
Training loss: 4.060501311222236
Validation loss: 4.159244634475453

Epoch: 6| Step: 8
Training loss: 3.9640275387543578
Validation loss: 4.154333528453527

Epoch: 6| Step: 9
Training loss: 3.94022541485703
Validation loss: 4.150051954625937

Epoch: 6| Step: 10
Training loss: 4.632684869921967
Validation loss: 4.145752789403483

Epoch: 6| Step: 11
Training loss: 4.7662685272472975
Validation loss: 4.140728739272637

Epoch: 6| Step: 12
Training loss: 5.283111424804923
Validation loss: 4.135644107332673

Epoch: 6| Step: 13
Training loss: 4.6065013138887085
Validation loss: 4.131100872847458

Epoch: 23| Step: 0
Training loss: 4.302396576617529
Validation loss: 4.125670079994028

Epoch: 6| Step: 1
Training loss: 3.5622242603334513
Validation loss: 4.120972314283851

Epoch: 6| Step: 2
Training loss: 4.36616692534712
Validation loss: 4.115630983016662

Epoch: 6| Step: 3
Training loss: 3.9460701092283954
Validation loss: 4.11100885475991

Epoch: 6| Step: 4
Training loss: 4.656886114922021
Validation loss: 4.105995103346006

Epoch: 6| Step: 5
Training loss: 4.1167529345494
Validation loss: 4.101292386318952

Epoch: 6| Step: 6
Training loss: 3.8428236922936905
Validation loss: 4.0958607209312845

Epoch: 6| Step: 7
Training loss: 4.725474435713109
Validation loss: 4.0911793293624825

Epoch: 6| Step: 8
Training loss: 4.311178032420104
Validation loss: 4.086286579729578

Epoch: 6| Step: 9
Training loss: 3.6128594559553973
Validation loss: 4.081364890288025

Epoch: 6| Step: 10
Training loss: 4.626712378973232
Validation loss: 4.07674178907081

Epoch: 6| Step: 11
Training loss: 3.7767907953920616
Validation loss: 4.0721910940983905

Epoch: 6| Step: 12
Training loss: 4.05096017263963
Validation loss: 4.0668815068783575

Epoch: 6| Step: 13
Training loss: 4.980839446988799
Validation loss: 4.061991400548841

Epoch: 24| Step: 0
Training loss: 4.7808696121790675
Validation loss: 4.057345676021834

Epoch: 6| Step: 1
Training loss: 4.111576317478872
Validation loss: 4.052098677082316

Epoch: 6| Step: 2
Training loss: 3.1168209615719253
Validation loss: 4.046620109317514

Epoch: 6| Step: 3
Training loss: 4.515448015697967
Validation loss: 4.041603887535777

Epoch: 6| Step: 4
Training loss: 4.373157004042598
Validation loss: 4.0370045478989836

Epoch: 6| Step: 5
Training loss: 4.377787546662233
Validation loss: 4.032446947247404

Epoch: 6| Step: 6
Training loss: 4.535743957868739
Validation loss: 4.026920921706829

Epoch: 6| Step: 7
Training loss: 4.546758381504911
Validation loss: 4.0223634736905085

Epoch: 6| Step: 8
Training loss: 3.699544342439323
Validation loss: 4.016892763688817

Epoch: 6| Step: 9
Training loss: 3.8977806134167103
Validation loss: 4.011937488014387

Epoch: 6| Step: 10
Training loss: 3.8620078801094944
Validation loss: 4.0068820123567

Epoch: 6| Step: 11
Training loss: 4.388497811342867
Validation loss: 4.002533964370005

Epoch: 6| Step: 12
Training loss: 3.618072203835624
Validation loss: 3.997296055181168

Epoch: 6| Step: 13
Training loss: 4.084990470062682
Validation loss: 3.991892266850088

Epoch: 25| Step: 0
Training loss: 4.423224900235845
Validation loss: 3.9881303430515582

Epoch: 6| Step: 1
Training loss: 3.8717293010697067
Validation loss: 3.9827580979648642

Epoch: 6| Step: 2
Training loss: 3.892047177866837
Validation loss: 3.9776015207700515

Epoch: 6| Step: 3
Training loss: 4.498772771702969
Validation loss: 3.9727754778179567

Epoch: 6| Step: 4
Training loss: 4.611097524742936
Validation loss: 3.967526144523668

Epoch: 6| Step: 5
Training loss: 4.238839023997291
Validation loss: 3.962710172612895

Epoch: 6| Step: 6
Training loss: 3.9611787440402546
Validation loss: 3.9576871779567973

Epoch: 6| Step: 7
Training loss: 3.643317017258398
Validation loss: 3.9534838668110037

Epoch: 6| Step: 8
Training loss: 3.840091980587517
Validation loss: 3.947832326399142

Epoch: 6| Step: 9
Training loss: 4.396195214488501
Validation loss: 3.942485881998654

Epoch: 6| Step: 10
Training loss: 4.058281219168704
Validation loss: 3.9376465300891157

Epoch: 6| Step: 11
Training loss: 3.1281220671404677
Validation loss: 3.9331730273818333

Epoch: 6| Step: 12
Training loss: 4.417888880108057
Validation loss: 3.9291251192832464

Epoch: 6| Step: 13
Training loss: 4.042968278230648
Validation loss: 3.9233106439972043

Epoch: 26| Step: 0
Training loss: 3.45630620045006
Validation loss: 3.918051873767711

Epoch: 6| Step: 1
Training loss: 2.833879549071382
Validation loss: 3.9127090763864323

Epoch: 6| Step: 2
Training loss: 4.849846135481187
Validation loss: 3.908146512271124

Epoch: 6| Step: 3
Training loss: 4.862486208231767
Validation loss: 3.9038902173983185

Epoch: 6| Step: 4
Training loss: 3.9725933538838665
Validation loss: 3.8981019552867813

Epoch: 6| Step: 5
Training loss: 3.5743174721680364
Validation loss: 3.892794983127161

Epoch: 6| Step: 6
Training loss: 3.3071259865099507
Validation loss: 3.8877820680263975

Epoch: 6| Step: 7
Training loss: 4.1616382520197295
Validation loss: 3.8832468855462716

Epoch: 6| Step: 8
Training loss: 4.531313981229327
Validation loss: 3.879004634391873

Epoch: 6| Step: 9
Training loss: 3.4643076726023714
Validation loss: 3.874021201441198

Epoch: 6| Step: 10
Training loss: 4.126359195460441
Validation loss: 3.8690505757862015

Epoch: 6| Step: 11
Training loss: 4.906466922702549
Validation loss: 3.8636187697501283

Epoch: 6| Step: 12
Training loss: 3.710050392528395
Validation loss: 3.8580553112557445

Epoch: 6| Step: 13
Training loss: 3.859926253884238
Validation loss: 3.8534721711059965

Epoch: 27| Step: 0
Training loss: 3.97202748411875
Validation loss: 3.8481182924713715

Epoch: 6| Step: 1
Training loss: 3.7926655106963216
Validation loss: 3.843896403018567

Epoch: 6| Step: 2
Training loss: 3.245511697120727
Validation loss: 3.8380669240280154

Epoch: 6| Step: 3
Training loss: 4.339906377881257
Validation loss: 3.8341383641560944

Epoch: 6| Step: 4
Training loss: 3.9288990602486287
Validation loss: 3.8290208663551195

Epoch: 6| Step: 5
Training loss: 4.110040066934462
Validation loss: 3.8240262256824327

Epoch: 6| Step: 6
Training loss: 3.942672480727153
Validation loss: 3.818961811590932

Epoch: 6| Step: 7
Training loss: 3.9659173423321543
Validation loss: 3.814463250634602

Epoch: 6| Step: 8
Training loss: 5.069132475057504
Validation loss: 3.809346400824558

Epoch: 6| Step: 9
Training loss: 2.8026069426060536
Validation loss: 3.8042392140239953

Epoch: 6| Step: 10
Training loss: 3.4955287711261236
Validation loss: 3.79946597512953

Epoch: 6| Step: 11
Training loss: 4.904741966623247
Validation loss: 3.7938948292034884

Epoch: 6| Step: 12
Training loss: 3.4201258539165513
Validation loss: 3.7886977606813117

Epoch: 6| Step: 13
Training loss: 3.7379421929409977
Validation loss: 3.7841144567630534

Epoch: 28| Step: 0
Training loss: 3.631812304558091
Validation loss: 3.780252078025638

Epoch: 6| Step: 1
Training loss: 3.3939214055453677
Validation loss: 3.776291572807488

Epoch: 6| Step: 2
Training loss: 4.362814800632631
Validation loss: 3.771274333618679

Epoch: 6| Step: 3
Training loss: 3.627852139985472
Validation loss: 3.7655837398394914

Epoch: 6| Step: 4
Training loss: 4.251279077472527
Validation loss: 3.7607701242010703

Epoch: 6| Step: 5
Training loss: 3.5895111295169126
Validation loss: 3.755671937695429

Epoch: 6| Step: 6
Training loss: 4.083925061591043
Validation loss: 3.75106544194009

Epoch: 6| Step: 7
Training loss: 4.344801741138461
Validation loss: 3.745391514697539

Epoch: 6| Step: 8
Training loss: 3.5414615945722296
Validation loss: 3.7402995635909653

Epoch: 6| Step: 9
Training loss: 3.7881316309840805
Validation loss: 3.7351745643318326

Epoch: 6| Step: 10
Training loss: 4.476427858468213
Validation loss: 3.7306861694249718

Epoch: 6| Step: 11
Training loss: 3.755587420682635
Validation loss: 3.725475373966938

Epoch: 6| Step: 12
Training loss: 3.9210696666378477
Validation loss: 3.720678326381433

Epoch: 6| Step: 13
Training loss: 3.37757831564574
Validation loss: 3.716049688530574

Epoch: 29| Step: 0
Training loss: 4.77962930175626
Validation loss: 3.710663602659345

Epoch: 6| Step: 1
Training loss: 4.432935489404584
Validation loss: 3.707119639514977

Epoch: 6| Step: 2
Training loss: 3.425570787078433
Validation loss: 3.700488669112266

Epoch: 6| Step: 3
Training loss: 3.4120056800392518
Validation loss: 3.696344770434178

Epoch: 6| Step: 4
Training loss: 3.916867771802447
Validation loss: 3.6915637324142843

Epoch: 6| Step: 5
Training loss: 3.3966289750523297
Validation loss: 3.686614668435165

Epoch: 6| Step: 6
Training loss: 3.6058523980355126
Validation loss: 3.682288026425704

Epoch: 6| Step: 7
Training loss: 2.9107742370262155
Validation loss: 3.6767836314422433

Epoch: 6| Step: 8
Training loss: 3.6022588424918256
Validation loss: 3.672350091161965

Epoch: 6| Step: 9
Training loss: 3.964829318015606
Validation loss: 3.667868930052883

Epoch: 6| Step: 10
Training loss: 4.476566547704867
Validation loss: 3.663320307605785

Epoch: 6| Step: 11
Training loss: 3.871003335614789
Validation loss: 3.6587196768844428

Epoch: 6| Step: 12
Training loss: 3.0621272268941606
Validation loss: 3.6537744558818557

Epoch: 6| Step: 13
Training loss: 4.079521320162471
Validation loss: 3.6487841118157536

Epoch: 30| Step: 0
Training loss: 3.6706330491907693
Validation loss: 3.644243932957918

Epoch: 6| Step: 1
Training loss: 4.276211857942016
Validation loss: 3.639205612266564

Epoch: 6| Step: 2
Training loss: 3.408762853617087
Validation loss: 3.634679127435555

Epoch: 6| Step: 3
Training loss: 4.392005567606192
Validation loss: 3.629926118685597

Epoch: 6| Step: 4
Training loss: 3.367904976081938
Validation loss: 3.6251860384502805

Epoch: 6| Step: 5
Training loss: 4.020765524705847
Validation loss: 3.620160588554072

Epoch: 6| Step: 6
Training loss: 4.673142685386719
Validation loss: 3.615813332776589

Epoch: 6| Step: 7
Training loss: 3.4543827579825983
Validation loss: 3.6105699639079267

Epoch: 6| Step: 8
Training loss: 3.580728574810557
Validation loss: 3.6064120484894384

Epoch: 6| Step: 9
Training loss: 3.7146175728826454
Validation loss: 3.6019883528116368

Epoch: 6| Step: 10
Training loss: 3.9525688895990627
Validation loss: 3.597521762494891

Epoch: 6| Step: 11
Training loss: 3.3427265062528626
Validation loss: 3.5923126884726893

Epoch: 6| Step: 12
Training loss: 3.201228478183219
Validation loss: 3.587416134163044

Epoch: 6| Step: 13
Training loss: 3.0738328160705723
Validation loss: 3.581855262085596

Epoch: 31| Step: 0
Training loss: 3.6769401515211872
Validation loss: 3.576740824513367

Epoch: 6| Step: 1
Training loss: 3.415251710252813
Validation loss: 3.5724065247771657

Epoch: 6| Step: 2
Training loss: 3.5201644412557553
Validation loss: 3.568324787130252

Epoch: 6| Step: 3
Training loss: 3.8419017535013995
Validation loss: 3.5628999072924517

Epoch: 6| Step: 4
Training loss: 3.8330578221259892
Validation loss: 3.5584677022419022

Epoch: 6| Step: 5
Training loss: 3.5780469061312745
Validation loss: 3.5545820171649036

Epoch: 6| Step: 6
Training loss: 4.315668241490009
Validation loss: 3.548338824677477

Epoch: 6| Step: 7
Training loss: 4.040896207908085
Validation loss: 3.5439883681767315

Epoch: 6| Step: 8
Training loss: 3.4197743556668705
Validation loss: 3.5392244707534855

Epoch: 6| Step: 9
Training loss: 3.9110168668441276
Validation loss: 3.5345015732788725

Epoch: 6| Step: 10
Training loss: 3.2357481469602423
Validation loss: 3.5299724867399624

Epoch: 6| Step: 11
Training loss: 3.7918353759345194
Validation loss: 3.52618531122814

Epoch: 6| Step: 12
Training loss: 3.58815455828693
Validation loss: 3.520988916123422

Epoch: 6| Step: 13
Training loss: 3.280591044788944
Validation loss: 3.515963344540582

Epoch: 32| Step: 0
Training loss: 3.3506928140288204
Validation loss: 3.5119614904438685

Epoch: 6| Step: 1
Training loss: 3.4783598979038532
Validation loss: 3.507728286785799

Epoch: 6| Step: 2
Training loss: 3.9105131765713543
Validation loss: 3.502727376857775

Epoch: 6| Step: 3
Training loss: 2.766008598319789
Validation loss: 3.4981387729951825

Epoch: 6| Step: 4
Training loss: 3.470587990932893
Validation loss: 3.493625125916718

Epoch: 6| Step: 5
Training loss: 4.0697923207077045
Validation loss: 3.489672205158643

Epoch: 6| Step: 6
Training loss: 3.4260128556259186
Validation loss: 3.485148505098445

Epoch: 6| Step: 7
Training loss: 3.359360237976287
Validation loss: 3.4808697824454913

Epoch: 6| Step: 8
Training loss: 3.075724328802819
Validation loss: 3.476023954476482

Epoch: 6| Step: 9
Training loss: 4.203590565816268
Validation loss: 3.4718747198206037

Epoch: 6| Step: 10
Training loss: 3.9491861494852496
Validation loss: 3.467422231229774

Epoch: 6| Step: 11
Training loss: 4.003853610553365
Validation loss: 3.4622688574364524

Epoch: 6| Step: 12
Training loss: 3.1611347734682673
Validation loss: 3.4580301282094945

Epoch: 6| Step: 13
Training loss: 4.112249145277668
Validation loss: 3.4541679751980783

Epoch: 33| Step: 0
Training loss: 2.9571895985302117
Validation loss: 3.449698104180918

Epoch: 6| Step: 1
Training loss: 2.843909625928577
Validation loss: 3.4446628041596115

Epoch: 6| Step: 2
Training loss: 3.3474804755304572
Validation loss: 3.4403753219497344

Epoch: 6| Step: 3
Training loss: 3.662606997440511
Validation loss: 3.4366602941306597

Epoch: 6| Step: 4
Training loss: 3.173586529266255
Validation loss: 3.432145230879515

Epoch: 6| Step: 5
Training loss: 3.87455660836669
Validation loss: 3.4282372724334422

Epoch: 6| Step: 6
Training loss: 4.09156543013397
Validation loss: 3.4236559130918485

Epoch: 6| Step: 7
Training loss: 3.7134135448437866
Validation loss: 3.419284054492609

Epoch: 6| Step: 8
Training loss: 3.099767977737706
Validation loss: 3.4146569241562634

Epoch: 6| Step: 9
Training loss: 4.604296145912812
Validation loss: 3.410953563979133

Epoch: 6| Step: 10
Training loss: 3.420049868660686
Validation loss: 3.4069081641769774

Epoch: 6| Step: 11
Training loss: 3.4722367366911264
Validation loss: 3.401340084020878

Epoch: 6| Step: 12
Training loss: 3.628958546700002
Validation loss: 3.397203208136787

Epoch: 6| Step: 13
Training loss: 3.5431820638048035
Validation loss: 3.3923452323369285

Epoch: 34| Step: 0
Training loss: 3.284983227830685
Validation loss: 3.3880637906767377

Epoch: 6| Step: 1
Training loss: 3.506383252119224
Validation loss: 3.3840628318259234

Epoch: 6| Step: 2
Training loss: 3.3796642710063374
Validation loss: 3.379362195367379

Epoch: 6| Step: 3
Training loss: 3.333031847353276
Validation loss: 3.3756215382693435

Epoch: 6| Step: 4
Training loss: 3.944327595969454
Validation loss: 3.3716233162788822

Epoch: 6| Step: 5
Training loss: 3.4709520653195565
Validation loss: 3.3675882288365986

Epoch: 6| Step: 6
Training loss: 4.119157294596427
Validation loss: 3.3635430080914808

Epoch: 6| Step: 7
Training loss: 3.7785496172583213
Validation loss: 3.35773033868769

Epoch: 6| Step: 8
Training loss: 2.995704118243739
Validation loss: 3.353922193317386

Epoch: 6| Step: 9
Training loss: 3.6959486044906162
Validation loss: 3.349337297813333

Epoch: 6| Step: 10
Training loss: 2.8916079937555126
Validation loss: 3.3445733978768963

Epoch: 6| Step: 11
Training loss: 3.4083077750767226
Validation loss: 3.3408572795108364

Epoch: 6| Step: 12
Training loss: 3.3211964586197014
Validation loss: 3.3360577218446337

Epoch: 6| Step: 13
Training loss: 3.6525210414021907
Validation loss: 3.3321664834166924

Epoch: 35| Step: 0
Training loss: 3.15280658486566
Validation loss: 3.327908289484768

Epoch: 6| Step: 1
Training loss: 3.344165526623646
Validation loss: 3.3233097684962822

Epoch: 6| Step: 2
Training loss: 4.241747754314307
Validation loss: 3.320522909042415

Epoch: 6| Step: 3
Training loss: 3.808139120501796
Validation loss: 3.3152889171261024

Epoch: 6| Step: 4
Training loss: 3.50925869430527
Validation loss: 3.311991502611191

Epoch: 6| Step: 5
Training loss: 3.0965323219133847
Validation loss: 3.3074614153375292

Epoch: 6| Step: 6
Training loss: 3.0086659199179593
Validation loss: 3.304186435045433

Epoch: 6| Step: 7
Training loss: 4.128204488169473
Validation loss: 3.2997180317337067

Epoch: 6| Step: 8
Training loss: 3.2428524943967214
Validation loss: 3.2943255071915347

Epoch: 6| Step: 9
Training loss: 2.8495677084749373
Validation loss: 3.2901922295790866

Epoch: 6| Step: 10
Training loss: 3.230192419408827
Validation loss: 3.2862192219090587

Epoch: 6| Step: 11
Training loss: 3.192692435610314
Validation loss: 3.2820567032516315

Epoch: 6| Step: 12
Training loss: 3.240131949104453
Validation loss: 3.2789533782449083

Epoch: 6| Step: 13
Training loss: 3.8001077335545492
Validation loss: 3.2749604390208273

Epoch: 36| Step: 0
Training loss: 3.5794464736178297
Validation loss: 3.271077084216051

Epoch: 6| Step: 1
Training loss: 3.146691228506705
Validation loss: 3.2670668806094687

Epoch: 6| Step: 2
Training loss: 3.1690902136074355
Validation loss: 3.2656594355226254

Epoch: 6| Step: 3
Training loss: 3.511553903684442
Validation loss: 3.26053920592762

Epoch: 6| Step: 4
Training loss: 3.099188138417797
Validation loss: 3.259910694548999

Epoch: 6| Step: 5
Training loss: 3.7463152266059527
Validation loss: 3.2591495956549945

Epoch: 6| Step: 6
Training loss: 3.3865303594337095
Validation loss: 3.2581136611554813

Epoch: 6| Step: 7
Training loss: 3.6790732095728247
Validation loss: 3.2562747439410202

Epoch: 6| Step: 8
Training loss: 3.5075597863189802
Validation loss: 3.2468181586774425

Epoch: 6| Step: 9
Training loss: 2.512509140073938
Validation loss: 3.2410590724416792

Epoch: 6| Step: 10
Training loss: 3.9257471187493285
Validation loss: 3.2353753034244717

Epoch: 6| Step: 11
Training loss: 3.610835981076788
Validation loss: 3.2299793369313337

Epoch: 6| Step: 12
Training loss: 3.014355327961999
Validation loss: 3.2258556906469757

Epoch: 6| Step: 13
Training loss: 3.3242307992217
Validation loss: 3.2229718849434548

Epoch: 37| Step: 0
Training loss: 3.160996295949714
Validation loss: 3.220334598145235

Epoch: 6| Step: 1
Training loss: 2.91991828229294
Validation loss: 3.217902062584753

Epoch: 6| Step: 2
Training loss: 3.5333477979639865
Validation loss: 3.2139299097376752

Epoch: 6| Step: 3
Training loss: 3.0809540890867
Validation loss: 3.2086246572894064

Epoch: 6| Step: 4
Training loss: 3.2755824961504043
Validation loss: 3.2020594243331995

Epoch: 6| Step: 5
Training loss: 3.807391887690338
Validation loss: 3.198823139725446

Epoch: 6| Step: 6
Training loss: 3.5040724086595865
Validation loss: 3.1947620791389904

Epoch: 6| Step: 7
Training loss: 3.77379838627528
Validation loss: 3.1909765221132447

Epoch: 6| Step: 8
Training loss: 3.0930048497948546
Validation loss: 3.1868464853383003

Epoch: 6| Step: 9
Training loss: 3.974740500946662
Validation loss: 3.1836108622646884

Epoch: 6| Step: 10
Training loss: 3.2827281710484524
Validation loss: 3.1789439313731354

Epoch: 6| Step: 11
Training loss: 2.289722334507096
Validation loss: 3.175164757606376

Epoch: 6| Step: 12
Training loss: 3.6223903338758277
Validation loss: 3.1723413985788746

Epoch: 6| Step: 13
Training loss: 3.0101033788018343
Validation loss: 3.1697329098389964

Epoch: 38| Step: 0
Training loss: 3.0271378773244737
Validation loss: 3.1674794275046785

Epoch: 6| Step: 1
Training loss: 3.5226637166126653
Validation loss: 3.163992321350708

Epoch: 6| Step: 2
Training loss: 3.2986954277818
Validation loss: 3.1595147750628954

Epoch: 6| Step: 3
Training loss: 3.0241248953625353
Validation loss: 3.155137876469307

Epoch: 6| Step: 4
Training loss: 3.6551988182839086
Validation loss: 3.1512396674041643

Epoch: 6| Step: 5
Training loss: 3.9203575815867717
Validation loss: 3.1463390895358287

Epoch: 6| Step: 6
Training loss: 2.780927746566299
Validation loss: 3.142246112627752

Epoch: 6| Step: 7
Training loss: 2.869488284118845
Validation loss: 3.1380829020122025

Epoch: 6| Step: 8
Training loss: 3.3561542063988816
Validation loss: 3.134299593595566

Epoch: 6| Step: 9
Training loss: 2.893167727985763
Validation loss: 3.1315901758686375

Epoch: 6| Step: 10
Training loss: 3.4529018416296875
Validation loss: 3.1285963853552747

Epoch: 6| Step: 11
Training loss: 3.080932266535804
Validation loss: 3.12446884727565

Epoch: 6| Step: 12
Training loss: 3.171521096616603
Validation loss: 3.121463643906118

Epoch: 6| Step: 13
Training loss: 3.6854080473240356
Validation loss: 3.1192175708978658

Epoch: 39| Step: 0
Training loss: 3.340625051386006
Validation loss: 3.1137636481840625

Epoch: 6| Step: 1
Training loss: 3.3602912540450594
Validation loss: 3.110607867657118

Epoch: 6| Step: 2
Training loss: 3.3752283089733814
Validation loss: 3.1078082407312757

Epoch: 6| Step: 3
Training loss: 3.4469189693797166
Validation loss: 3.1046479809950775

Epoch: 6| Step: 4
Training loss: 2.7761293913893126
Validation loss: 3.1007384928020985

Epoch: 6| Step: 5
Training loss: 2.9130176788118387
Validation loss: 3.097614943881151

Epoch: 6| Step: 6
Training loss: 2.6049910397659226
Validation loss: 3.092870118348783

Epoch: 6| Step: 7
Training loss: 3.24190157813052
Validation loss: 3.0900124087079384

Epoch: 6| Step: 8
Training loss: 3.4442512105931478
Validation loss: 3.0865179747270206

Epoch: 6| Step: 9
Training loss: 3.251419784295546
Validation loss: 3.0817027591787585

Epoch: 6| Step: 10
Training loss: 3.10832495666957
Validation loss: 3.0793176654412395

Epoch: 6| Step: 11
Training loss: 3.6707499627046634
Validation loss: 3.076460954918998

Epoch: 6| Step: 12
Training loss: 3.207248619974315
Validation loss: 3.0731987365747697

Epoch: 6| Step: 13
Training loss: 3.3735735669242777
Validation loss: 3.0694865765180466

Epoch: 40| Step: 0
Training loss: 2.0791648615011917
Validation loss: 3.069216389380607

Epoch: 6| Step: 1
Training loss: 3.3582875465572224
Validation loss: 3.0769746183088875

Epoch: 6| Step: 2
Training loss: 3.0744042540521543
Validation loss: 3.063511389503083

Epoch: 6| Step: 3
Training loss: 3.0243519427750285
Validation loss: 3.0588528980884924

Epoch: 6| Step: 4
Training loss: 3.0587195593438117
Validation loss: 3.0556030982586284

Epoch: 6| Step: 5
Training loss: 3.150234722293244
Validation loss: 3.052369951627641

Epoch: 6| Step: 6
Training loss: 3.6672119399866654
Validation loss: 3.051169982448543

Epoch: 6| Step: 7
Training loss: 3.6782646262892427
Validation loss: 3.047351219586535

Epoch: 6| Step: 8
Training loss: 2.9726450214349365
Validation loss: 3.044533924039287

Epoch: 6| Step: 9
Training loss: 3.142906916211832
Validation loss: 3.0419444040104104

Epoch: 6| Step: 10
Training loss: 3.046543044567055
Validation loss: 3.038035790554674

Epoch: 6| Step: 11
Training loss: 3.805944340902768
Validation loss: 3.0361096600172974

Epoch: 6| Step: 12
Training loss: 3.0490980596991517
Validation loss: 3.031632101090149

Epoch: 6| Step: 13
Training loss: 3.1876127933666236
Validation loss: 3.027825797475004

Epoch: 41| Step: 0
Training loss: 2.846438300496808
Validation loss: 3.022663079703746

Epoch: 6| Step: 1
Training loss: 3.4292837265880185
Validation loss: 3.021150103216818

Epoch: 6| Step: 2
Training loss: 3.0906843929928924
Validation loss: 3.018477913735737

Epoch: 6| Step: 3
Training loss: 3.295835936907396
Validation loss: 3.0152659490692924

Epoch: 6| Step: 4
Training loss: 3.095030548487258
Validation loss: 3.0126060039816758

Epoch: 6| Step: 5
Training loss: 2.965559359146613
Validation loss: 3.009351262427778

Epoch: 6| Step: 6
Training loss: 3.31455469284935
Validation loss: 3.006345158139595

Epoch: 6| Step: 7
Training loss: 2.8825963050390366
Validation loss: 3.004093807534438

Epoch: 6| Step: 8
Training loss: 3.3395376321700114
Validation loss: 3.0001752457826023

Epoch: 6| Step: 9
Training loss: 2.811155464072091
Validation loss: 2.997246856478228

Epoch: 6| Step: 10
Training loss: 2.9311218819345215
Validation loss: 2.9940073904779956

Epoch: 6| Step: 11
Training loss: 3.35181659010981
Validation loss: 2.991322896292071

Epoch: 6| Step: 12
Training loss: 2.9469730947435844
Validation loss: 2.992961069746261

Epoch: 6| Step: 13
Training loss: 3.6422170669749856
Validation loss: 2.9977900524499224

Epoch: 42| Step: 0
Training loss: 2.987662377194341
Validation loss: 2.9829599111269296

Epoch: 6| Step: 1
Training loss: 2.8826389829110304
Validation loss: 2.9805013872312003

Epoch: 6| Step: 2
Training loss: 2.703708916368303
Validation loss: 2.978272875289786

Epoch: 6| Step: 3
Training loss: 3.1441375675534893
Validation loss: 2.9762528759908955

Epoch: 6| Step: 4
Training loss: 3.4201377046758386
Validation loss: 2.9739767409165276

Epoch: 6| Step: 5
Training loss: 3.382968396829949
Validation loss: 2.971826892975521

Epoch: 6| Step: 6
Training loss: 3.551096147899059
Validation loss: 2.968439132744061

Epoch: 6| Step: 7
Training loss: 3.0330570772851972
Validation loss: 2.9662346071662937

Epoch: 6| Step: 8
Training loss: 2.9873974259775524
Validation loss: 2.962250457855497

Epoch: 6| Step: 9
Training loss: 2.759459957141237
Validation loss: 2.9595755713549594

Epoch: 6| Step: 10
Training loss: 2.786832029768927
Validation loss: 2.9560524963901758

Epoch: 6| Step: 11
Training loss: 3.036364301443676
Validation loss: 2.953479819536298

Epoch: 6| Step: 12
Training loss: 3.1750664651476934
Validation loss: 2.949444059477029

Epoch: 6| Step: 13
Training loss: 3.493006940789457
Validation loss: 2.946118596108

Epoch: 43| Step: 0
Training loss: 3.453575691742364
Validation loss: 2.9424169660599757

Epoch: 6| Step: 1
Training loss: 2.3683762791511818
Validation loss: 2.9406813175269146

Epoch: 6| Step: 2
Training loss: 3.2159156541913605
Validation loss: 2.9404200115908274

Epoch: 6| Step: 3
Training loss: 3.4763234259879723
Validation loss: 2.9367635628962474

Epoch: 6| Step: 4
Training loss: 3.1829980210931197
Validation loss: 2.934276096788377

Epoch: 6| Step: 5
Training loss: 3.3200663396802677
Validation loss: 2.931126165858276

Epoch: 6| Step: 6
Training loss: 3.001443515625479
Validation loss: 2.9243475096572857

Epoch: 6| Step: 7
Training loss: 3.2863304407512195
Validation loss: 2.921104166278086

Epoch: 6| Step: 8
Training loss: 3.4486322649568435
Validation loss: 2.919583338204009

Epoch: 6| Step: 9
Training loss: 2.960426628709891
Validation loss: 2.9166755721546638

Epoch: 6| Step: 10
Training loss: 2.8565710108561064
Validation loss: 2.9140413912502057

Epoch: 6| Step: 11
Training loss: 2.6814775632666117
Validation loss: 2.9120312413104785

Epoch: 6| Step: 12
Training loss: 2.8111373143321403
Validation loss: 2.909161220499181

Epoch: 6| Step: 13
Training loss: 2.6288536485961527
Validation loss: 2.907451558998354

Epoch: 44| Step: 0
Training loss: 3.451612322453337
Validation loss: 2.9047130225860758

Epoch: 6| Step: 1
Training loss: 2.6986786540761587
Validation loss: 2.9019543064313744

Epoch: 6| Step: 2
Training loss: 3.27808016299994
Validation loss: 2.8996463801195476

Epoch: 6| Step: 3
Training loss: 2.8577759654367467
Validation loss: 2.896473715435228

Epoch: 6| Step: 4
Training loss: 3.002410079537032
Validation loss: 2.8950572769261655

Epoch: 6| Step: 5
Training loss: 3.088805900879909
Validation loss: 2.89027684494982

Epoch: 6| Step: 6
Training loss: 2.8090678996608083
Validation loss: 2.8882359297614464

Epoch: 6| Step: 7
Training loss: 3.0282370153914173
Validation loss: 2.8862549336488854

Epoch: 6| Step: 8
Training loss: 3.486885295551182
Validation loss: 2.8799411495695053

Epoch: 6| Step: 9
Training loss: 2.767093160993137
Validation loss: 2.884271447226423

Epoch: 6| Step: 10
Training loss: 2.84046629073103
Validation loss: 2.884839207858587

Epoch: 6| Step: 11
Training loss: 3.227842358811062
Validation loss: 2.877855016669288

Epoch: 6| Step: 12
Training loss: 2.8934938782949704
Validation loss: 2.878067273925466

Epoch: 6| Step: 13
Training loss: 2.9080709679718515
Validation loss: 2.8705101613786996

Epoch: 45| Step: 0
Training loss: 2.4814335906477374
Validation loss: 2.86865598681063

Epoch: 6| Step: 1
Training loss: 3.2150175805449166
Validation loss: 2.8690093832552845

Epoch: 6| Step: 2
Training loss: 3.547348461395833
Validation loss: 2.8679278506670056

Epoch: 6| Step: 3
Training loss: 2.658610473185631
Validation loss: 2.8704942280584462

Epoch: 6| Step: 4
Training loss: 3.4977173855065122
Validation loss: 2.8707040119987317

Epoch: 6| Step: 5
Training loss: 3.065761153282266
Validation loss: 2.8634354158248403

Epoch: 6| Step: 6
Training loss: 2.471974645021644
Validation loss: 2.8581056539388374

Epoch: 6| Step: 7
Training loss: 3.341723817509425
Validation loss: 2.853930085301342

Epoch: 6| Step: 8
Training loss: 2.949976620339028
Validation loss: 2.8513061895970075

Epoch: 6| Step: 9
Training loss: 2.4932663833414956
Validation loss: 2.849638811725921

Epoch: 6| Step: 10
Training loss: 2.8991892371889465
Validation loss: 2.8471177668652308

Epoch: 6| Step: 11
Training loss: 3.1947370164838587
Validation loss: 2.847982673094044

Epoch: 6| Step: 12
Training loss: 3.1528186842122046
Validation loss: 2.8440489978593426

Epoch: 6| Step: 13
Training loss: 2.7539838198295232
Validation loss: 2.840341740338543

Epoch: 46| Step: 0
Training loss: 2.6607460118831705
Validation loss: 2.8399857000653586

Epoch: 6| Step: 1
Training loss: 3.299576362236075
Validation loss: 2.8378666252981946

Epoch: 6| Step: 2
Training loss: 3.2193976185944053
Validation loss: 2.8363148111621856

Epoch: 6| Step: 3
Training loss: 3.112323991938876
Validation loss: 2.833108589197206

Epoch: 6| Step: 4
Training loss: 3.498174736374107
Validation loss: 2.8303681921059187

Epoch: 6| Step: 5
Training loss: 3.0133889560573293
Validation loss: 2.8256663810874136

Epoch: 6| Step: 6
Training loss: 2.6924348811613688
Validation loss: 2.8247746808153544

Epoch: 6| Step: 7
Training loss: 3.0963603095316397
Validation loss: 2.8217399415583007

Epoch: 6| Step: 8
Training loss: 3.0335494296333474
Validation loss: 2.8211551862048774

Epoch: 6| Step: 9
Training loss: 2.685616920251302
Validation loss: 2.8139555378943744

Epoch: 6| Step: 10
Training loss: 2.824460263300084
Validation loss: 2.813265985802185

Epoch: 6| Step: 11
Training loss: 2.7196083906104587
Validation loss: 2.8108735079193417

Epoch: 6| Step: 12
Training loss: 2.821995198846595
Validation loss: 2.808801324112581

Epoch: 6| Step: 13
Training loss: 2.7021599077616147
Validation loss: 2.8061183867428077

Epoch: 47| Step: 0
Training loss: 3.0602935316132323
Validation loss: 2.8064107887066125

Epoch: 6| Step: 1
Training loss: 3.1663915280391164
Validation loss: 2.80561541240615

Epoch: 6| Step: 2
Training loss: 2.8431865427363143
Validation loss: 2.802677989574188

Epoch: 6| Step: 3
Training loss: 3.090766778515455
Validation loss: 2.8008972597946777

Epoch: 6| Step: 4
Training loss: 3.0870045808857602
Validation loss: 2.7991167599801168

Epoch: 6| Step: 5
Training loss: 2.978796413506656
Validation loss: 2.7969448997244704

Epoch: 6| Step: 6
Training loss: 2.7248633044193236
Validation loss: 2.798266584983564

Epoch: 6| Step: 7
Training loss: 3.0031130851009085
Validation loss: 2.7951102629802294

Epoch: 6| Step: 8
Training loss: 2.8008906344410973
Validation loss: 2.790828654969802

Epoch: 6| Step: 9
Training loss: 2.962382344030169
Validation loss: 2.791389456313292

Epoch: 6| Step: 10
Training loss: 2.4662973316443764
Validation loss: 2.788189691772042

Epoch: 6| Step: 11
Training loss: 2.8460648725009565
Validation loss: 2.7869837518087666

Epoch: 6| Step: 12
Training loss: 3.3402988770669557
Validation loss: 2.7832358624947795

Epoch: 6| Step: 13
Training loss: 2.614491272378297
Validation loss: 2.779921710972551

Epoch: 48| Step: 0
Training loss: 3.2603227563238018
Validation loss: 2.7804439248097474

Epoch: 6| Step: 1
Training loss: 2.830900569009129
Validation loss: 2.7796830896146374

Epoch: 6| Step: 2
Training loss: 3.1595250125214287
Validation loss: 2.7782200371156236

Epoch: 6| Step: 3
Training loss: 3.4189387574469436
Validation loss: 2.7785568342223677

Epoch: 6| Step: 4
Training loss: 3.2528591783956244
Validation loss: 2.7759902166831796

Epoch: 6| Step: 5
Training loss: 3.04233608108329
Validation loss: 2.7736463154728983

Epoch: 6| Step: 6
Training loss: 2.980112756989668
Validation loss: 2.7705644653967814

Epoch: 6| Step: 7
Training loss: 2.5556222681192793
Validation loss: 2.767921198559294

Epoch: 6| Step: 8
Training loss: 2.691119927621909
Validation loss: 2.7648567957524075

Epoch: 6| Step: 9
Training loss: 2.706094687147984
Validation loss: 2.761839076707265

Epoch: 6| Step: 10
Training loss: 2.773720138547222
Validation loss: 2.762122240316649

Epoch: 6| Step: 11
Training loss: 2.358765277014557
Validation loss: 2.758143260165504

Epoch: 6| Step: 12
Training loss: 2.794774636069688
Validation loss: 2.756037817390582

Epoch: 6| Step: 13
Training loss: 2.783279107378398
Validation loss: 2.7563514333270547

Epoch: 49| Step: 0
Training loss: 2.792347317366162
Validation loss: 2.7533344658194268

Epoch: 6| Step: 1
Training loss: 2.838999710690335
Validation loss: 2.751005133535887

Epoch: 6| Step: 2
Training loss: 3.390542587474103
Validation loss: 2.749186236460368

Epoch: 6| Step: 3
Training loss: 2.799105985149736
Validation loss: 2.747661651238686

Epoch: 6| Step: 4
Training loss: 2.782512421147538
Validation loss: 2.7449202438052156

Epoch: 6| Step: 5
Training loss: 2.9381187274332774
Validation loss: 2.743304381103822

Epoch: 6| Step: 6
Training loss: 3.0055776244657952
Validation loss: 2.7430344710901142

Epoch: 6| Step: 7
Training loss: 2.632077077600814
Validation loss: 2.7408660718849824

Epoch: 6| Step: 8
Training loss: 3.169469061832144
Validation loss: 2.739022887792706

Epoch: 6| Step: 9
Training loss: 2.9430684007219616
Validation loss: 2.7368426859056445

Epoch: 6| Step: 10
Training loss: 3.0201982203224778
Validation loss: 2.7337719352178205

Epoch: 6| Step: 11
Training loss: 2.6810911189313757
Validation loss: 2.73192776840448

Epoch: 6| Step: 12
Training loss: 2.7018850492510698
Validation loss: 2.7317192332167637

Epoch: 6| Step: 13
Training loss: 2.581663720178698
Validation loss: 2.7290041683440562

Epoch: 50| Step: 0
Training loss: 3.0590896301905817
Validation loss: 2.7274829582383595

Epoch: 6| Step: 1
Training loss: 2.8993729472497414
Validation loss: 2.7264483554560637

Epoch: 6| Step: 2
Training loss: 2.9174179925972683
Validation loss: 2.730065340976546

Epoch: 6| Step: 3
Training loss: 1.9412152754802998
Validation loss: 2.7439226708790536

Epoch: 6| Step: 4
Training loss: 2.6969342204252102
Validation loss: 2.7500644734078477

Epoch: 6| Step: 5
Training loss: 2.88789857697911
Validation loss: 2.7214307759040874

Epoch: 6| Step: 6
Training loss: 2.852899274639789
Validation loss: 2.7196175809675083

Epoch: 6| Step: 7
Training loss: 2.9103833410766704
Validation loss: 2.7165222541088982

Epoch: 6| Step: 8
Training loss: 2.6567333006150475
Validation loss: 2.7185984602163344

Epoch: 6| Step: 9
Training loss: 3.217132754645158
Validation loss: 2.719701680789273

Epoch: 6| Step: 10
Training loss: 3.1000916190606085
Validation loss: 2.7217383641292994

Epoch: 6| Step: 11
Training loss: 2.3254778873341237
Validation loss: 2.7245911664821483

Epoch: 6| Step: 12
Training loss: 2.9728917192794873
Validation loss: 2.7249917622246307

Epoch: 6| Step: 13
Training loss: 3.385184850336428
Validation loss: 2.7203127874717143

Epoch: 51| Step: 0
Training loss: 2.3123809165192215
Validation loss: 2.7199799689555753

Epoch: 6| Step: 1
Training loss: 2.62379227966294
Validation loss: 2.7164678385784

Epoch: 6| Step: 2
Training loss: 2.765311099412141
Validation loss: 2.713974994368064

Epoch: 6| Step: 3
Training loss: 2.4423271700603983
Validation loss: 2.711452248373884

Epoch: 6| Step: 4
Training loss: 3.0916236737356053
Validation loss: 2.7087298665386212

Epoch: 6| Step: 5
Training loss: 3.303198368408953
Validation loss: 2.706210321571605

Epoch: 6| Step: 6
Training loss: 2.802764488350858
Validation loss: 2.703870747621649

Epoch: 6| Step: 7
Training loss: 3.2846142189025183
Validation loss: 2.701489624546688

Epoch: 6| Step: 8
Training loss: 2.9361861516994527
Validation loss: 2.697985708367096

Epoch: 6| Step: 9
Training loss: 2.794467166616973
Validation loss: 2.6945555135331847

Epoch: 6| Step: 10
Training loss: 2.6158122990315356
Validation loss: 2.6909026406975887

Epoch: 6| Step: 11
Training loss: 3.4032041598274407
Validation loss: 2.6916489475560663

Epoch: 6| Step: 12
Training loss: 2.5080790630575924
Validation loss: 2.687534627765272

Epoch: 6| Step: 13
Training loss: 2.641526469011207
Validation loss: 2.6849615987474102

Epoch: 52| Step: 0
Training loss: 2.512658971055937
Validation loss: 2.6811722033521304

Epoch: 6| Step: 1
Training loss: 3.2173602613146115
Validation loss: 2.683084038789723

Epoch: 6| Step: 2
Training loss: 2.950840949761782
Validation loss: 2.6858383187028676

Epoch: 6| Step: 3
Training loss: 2.5078417814927993
Validation loss: 2.6782735907255923

Epoch: 6| Step: 4
Training loss: 2.5299190271560206
Validation loss: 2.6789051392987635

Epoch: 6| Step: 5
Training loss: 2.641568438592001
Validation loss: 2.677205499812884

Epoch: 6| Step: 6
Training loss: 2.586491551354276
Validation loss: 2.682294639412921

Epoch: 6| Step: 7
Training loss: 2.6438470628744994
Validation loss: 2.682733478393245

Epoch: 6| Step: 8
Training loss: 2.5524066227226623
Validation loss: 2.6725325342332575

Epoch: 6| Step: 9
Training loss: 2.8071149346957274
Validation loss: 2.6729008748238905

Epoch: 6| Step: 10
Training loss: 2.812688270201369
Validation loss: 2.6710222307396676

Epoch: 6| Step: 11
Training loss: 3.4866465190745406
Validation loss: 2.6678310077608085

Epoch: 6| Step: 12
Training loss: 3.5601399953511694
Validation loss: 2.6685786446107858

Epoch: 6| Step: 13
Training loss: 2.246539740028614
Validation loss: 2.6654458281274613

Epoch: 53| Step: 0
Training loss: 2.878028932639381
Validation loss: 2.6624905151771343

Epoch: 6| Step: 1
Training loss: 2.86087413740593
Validation loss: 2.659185455536421

Epoch: 6| Step: 2
Training loss: 2.9763407787335683
Validation loss: 2.6602448286712423

Epoch: 6| Step: 3
Training loss: 2.579600703664084
Validation loss: 2.6615152719955204

Epoch: 6| Step: 4
Training loss: 2.598277357606532
Validation loss: 2.66007093982704

Epoch: 6| Step: 5
Training loss: 3.4144155638378475
Validation loss: 2.6596197258500656

Epoch: 6| Step: 6
Training loss: 2.0895061469789793
Validation loss: 2.6597770760515145

Epoch: 6| Step: 7
Training loss: 2.9485777707839635
Validation loss: 2.660351582216224

Epoch: 6| Step: 8
Training loss: 2.838035459032116
Validation loss: 2.6583729506822067

Epoch: 6| Step: 9
Training loss: 2.7177364170021723
Validation loss: 2.6576683894936926

Epoch: 6| Step: 10
Training loss: 3.093919999817545
Validation loss: 2.6547178898733934

Epoch: 6| Step: 11
Training loss: 2.226938209289693
Validation loss: 2.652562023352121

Epoch: 6| Step: 12
Training loss: 2.627238636029657
Validation loss: 2.6523945222544834

Epoch: 6| Step: 13
Training loss: 3.016692451942918
Validation loss: 2.651209922702241

Epoch: 54| Step: 0
Training loss: 2.5633264464974954
Validation loss: 2.6488391867926415

Epoch: 6| Step: 1
Training loss: 2.8753960378124575
Validation loss: 2.648960988269295

Epoch: 6| Step: 2
Training loss: 2.6096275344443836
Validation loss: 2.6449280389035907

Epoch: 6| Step: 3
Training loss: 2.5180976041703422
Validation loss: 2.6444288616184335

Epoch: 6| Step: 4
Training loss: 3.3060165870928873
Validation loss: 2.6414579473485627

Epoch: 6| Step: 5
Training loss: 2.790859210020719
Validation loss: 2.6415505451909804

Epoch: 6| Step: 6
Training loss: 3.1691297856553047
Validation loss: 2.637012923042998

Epoch: 6| Step: 7
Training loss: 2.219577688653136
Validation loss: 2.6388672013534884

Epoch: 6| Step: 8
Training loss: 2.6592784895457897
Validation loss: 2.637239803116942

Epoch: 6| Step: 9
Training loss: 2.7032158455990802
Validation loss: 2.6344311697248384

Epoch: 6| Step: 10
Training loss: 3.0740450236808807
Validation loss: 2.634497249688473

Epoch: 6| Step: 11
Training loss: 2.8837574803024255
Validation loss: 2.6356758673739575

Epoch: 6| Step: 12
Training loss: 2.5822686390672644
Validation loss: 2.63391450935163

Epoch: 6| Step: 13
Training loss: 2.674011892909991
Validation loss: 2.6305724744869203

Epoch: 55| Step: 0
Training loss: 2.5907218445644298
Validation loss: 2.6337123732858094

Epoch: 6| Step: 1
Training loss: 2.6607723558915577
Validation loss: 2.6307870712860826

Epoch: 6| Step: 2
Training loss: 2.965752785183672
Validation loss: 2.630784654582821

Epoch: 6| Step: 3
Training loss: 2.7837896859980535
Validation loss: 2.6288054448337785

Epoch: 6| Step: 4
Training loss: 2.8902914318727837
Validation loss: 2.6277698859037355

Epoch: 6| Step: 5
Training loss: 2.669421045062077
Validation loss: 2.6251202510356473

Epoch: 6| Step: 6
Training loss: 2.8375429595518455
Validation loss: 2.624835205960424

Epoch: 6| Step: 7
Training loss: 2.952521852934068
Validation loss: 2.624053784540278

Epoch: 6| Step: 8
Training loss: 3.0540252514028197
Validation loss: 2.6236326047026908

Epoch: 6| Step: 9
Training loss: 2.759669038306726
Validation loss: 2.62177967660583

Epoch: 6| Step: 10
Training loss: 2.823622011321165
Validation loss: 2.620055325072009

Epoch: 6| Step: 11
Training loss: 2.633509331467383
Validation loss: 2.620060041773386

Epoch: 6| Step: 12
Training loss: 2.923975062325275
Validation loss: 2.618383637189297

Epoch: 6| Step: 13
Training loss: 1.8711817965567592
Validation loss: 2.615772437919781

Epoch: 56| Step: 0
Training loss: 2.8054789751971834
Validation loss: 2.616120184387162

Epoch: 6| Step: 1
Training loss: 2.5526758142013346
Validation loss: 2.61578338307594

Epoch: 6| Step: 2
Training loss: 2.7692190836390895
Validation loss: 2.614523534863516

Epoch: 6| Step: 3
Training loss: 2.6976269501377272
Validation loss: 2.615497403999625

Epoch: 6| Step: 4
Training loss: 2.103238710047352
Validation loss: 2.616336391849442

Epoch: 6| Step: 5
Training loss: 2.7870166445023967
Validation loss: 2.615378108311379

Epoch: 6| Step: 6
Training loss: 2.9159314091677793
Validation loss: 2.6139897031009682

Epoch: 6| Step: 7
Training loss: 2.897365649501143
Validation loss: 2.6100843154569064

Epoch: 6| Step: 8
Training loss: 2.6680489970659513
Validation loss: 2.6101936533277597

Epoch: 6| Step: 9
Training loss: 2.951824244883266
Validation loss: 2.6077078177909305

Epoch: 6| Step: 10
Training loss: 2.4775150043791516
Validation loss: 2.606649105699058

Epoch: 6| Step: 11
Training loss: 3.1065019532226237
Validation loss: 2.6072073820854933

Epoch: 6| Step: 12
Training loss: 2.4844984107884733
Validation loss: 2.6048965550224366

Epoch: 6| Step: 13
Training loss: 3.057887905713467
Validation loss: 2.6042021990577204

Epoch: 57| Step: 0
Training loss: 2.9848247408894353
Validation loss: 2.6043201604747854

Epoch: 6| Step: 1
Training loss: 2.040934905139755
Validation loss: 2.6033102967134014

Epoch: 6| Step: 2
Training loss: 3.0075654956411655
Validation loss: 2.603583054314438

Epoch: 6| Step: 3
Training loss: 2.775179463674922
Validation loss: 2.6024116451522765

Epoch: 6| Step: 4
Training loss: 2.45606818072213
Validation loss: 2.601107338924281

Epoch: 6| Step: 5
Training loss: 2.9558067457238146
Validation loss: 2.598845872503548

Epoch: 6| Step: 6
Training loss: 2.744348093247134
Validation loss: 2.598748779003009

Epoch: 6| Step: 7
Training loss: 2.5981118168426436
Validation loss: 2.59226476896375

Epoch: 6| Step: 8
Training loss: 2.977535539314085
Validation loss: 2.594921858461797

Epoch: 6| Step: 9
Training loss: 3.029462149444517
Validation loss: 2.5918402477737432

Epoch: 6| Step: 10
Training loss: 2.561543728176879
Validation loss: 2.588852544546716

Epoch: 6| Step: 11
Training loss: 2.622022575071731
Validation loss: 2.593620251087502

Epoch: 6| Step: 12
Training loss: 2.5871516486194044
Validation loss: 2.592405989783835

Epoch: 6| Step: 13
Training loss: 2.7544333528414446
Validation loss: 2.5882327600955883

Epoch: 58| Step: 0
Training loss: 3.0026163772021524
Validation loss: 2.587632836511826

Epoch: 6| Step: 1
Training loss: 2.6526466612399036
Validation loss: 2.587452547433741

Epoch: 6| Step: 2
Training loss: 2.5410938764012796
Validation loss: 2.5870169300763513

Epoch: 6| Step: 3
Training loss: 2.8608163004796956
Validation loss: 2.585971551615243

Epoch: 6| Step: 4
Training loss: 2.0851404617529385
Validation loss: 2.585747472690091

Epoch: 6| Step: 5
Training loss: 3.0339819797994116
Validation loss: 2.5852401884240965

Epoch: 6| Step: 6
Training loss: 2.851885717180803
Validation loss: 2.5847010273457007

Epoch: 6| Step: 7
Training loss: 3.1797063953484948
Validation loss: 2.585413008530268

Epoch: 6| Step: 8
Training loss: 2.629321764095819
Validation loss: 2.582351887811048

Epoch: 6| Step: 9
Training loss: 2.9494159960944097
Validation loss: 2.5816614575843477

Epoch: 6| Step: 10
Training loss: 2.7648967926464842
Validation loss: 2.5799162681802144

Epoch: 6| Step: 11
Training loss: 2.48615867834446
Validation loss: 2.5765490560680173

Epoch: 6| Step: 12
Training loss: 2.7359599724178363
Validation loss: 2.5832692466498037

Epoch: 6| Step: 13
Training loss: 2.047546975292101
Validation loss: 2.587553120803423

Epoch: 59| Step: 0
Training loss: 3.121514321876824
Validation loss: 2.5930247844125045

Epoch: 6| Step: 1
Training loss: 2.8455769465741936
Validation loss: 2.591167512480302

Epoch: 6| Step: 2
Training loss: 2.7649222305425676
Validation loss: 2.5982029389783006

Epoch: 6| Step: 3
Training loss: 2.5117858592986013
Validation loss: 2.5968224738570336

Epoch: 6| Step: 4
Training loss: 2.9951374064466716
Validation loss: 2.5858310550782515

Epoch: 6| Step: 5
Training loss: 2.5819657818087745
Validation loss: 2.5746924312319157

Epoch: 6| Step: 6
Training loss: 2.664915960536315
Validation loss: 2.5737843819943755

Epoch: 6| Step: 7
Training loss: 2.6167318830036974
Validation loss: 2.574960728071169

Epoch: 6| Step: 8
Training loss: 2.8041571750640832
Validation loss: 2.5734287992946814

Epoch: 6| Step: 9
Training loss: 2.727693689254026
Validation loss: 2.5726684471171

Epoch: 6| Step: 10
Training loss: 2.8430647810493457
Validation loss: 2.5714860148421987

Epoch: 6| Step: 11
Training loss: 2.756312581084957
Validation loss: 2.570253597616545

Epoch: 6| Step: 12
Training loss: 2.3348259466023875
Validation loss: 2.572633895058673

Epoch: 6| Step: 13
Training loss: 2.2950756264985377
Validation loss: 2.5746730621583755

Epoch: 60| Step: 0
Training loss: 2.8503873729125275
Validation loss: 2.5699897880450266

Epoch: 6| Step: 1
Training loss: 2.9024925963893047
Validation loss: 2.568821436870209

Epoch: 6| Step: 2
Training loss: 2.4382599844061743
Validation loss: 2.5698898261633234

Epoch: 6| Step: 3
Training loss: 3.198875921229804
Validation loss: 2.566586531176655

Epoch: 6| Step: 4
Training loss: 2.6992817276537404
Validation loss: 2.567233373781979

Epoch: 6| Step: 5
Training loss: 2.652662300228345
Validation loss: 2.5649784167040375

Epoch: 6| Step: 6
Training loss: 2.888308364868836
Validation loss: 2.5624476326654544

Epoch: 6| Step: 7
Training loss: 2.075275044424176
Validation loss: 2.56192856906891

Epoch: 6| Step: 8
Training loss: 2.8431617212177795
Validation loss: 2.560129216454682

Epoch: 6| Step: 9
Training loss: 2.5637138097060275
Validation loss: 2.5560627229045934

Epoch: 6| Step: 10
Training loss: 2.7352815705578015
Validation loss: 2.5593316098961174

Epoch: 6| Step: 11
Training loss: 2.8471235449420833
Validation loss: 2.5599628386681195

Epoch: 6| Step: 12
Training loss: 2.7520639303843595
Validation loss: 2.561085954373871

Epoch: 6| Step: 13
Training loss: 2.0701261616467432
Validation loss: 2.558649535214056

Epoch: 61| Step: 0
Training loss: 2.912525579643069
Validation loss: 2.5554177954303414

Epoch: 6| Step: 1
Training loss: 2.729323423897191
Validation loss: 2.5562653719090864

Epoch: 6| Step: 2
Training loss: 2.782699721469811
Validation loss: 2.5571762390398454

Epoch: 6| Step: 3
Training loss: 3.107606010807709
Validation loss: 2.554654944598369

Epoch: 6| Step: 4
Training loss: 2.674591111635743
Validation loss: 2.5545887592610423

Epoch: 6| Step: 5
Training loss: 2.974914254627803
Validation loss: 2.5522729971857823

Epoch: 6| Step: 6
Training loss: 2.181187376855854
Validation loss: 2.5547014988506938

Epoch: 6| Step: 7
Training loss: 2.5634547990147585
Validation loss: 2.5484232964695823

Epoch: 6| Step: 8
Training loss: 2.477993524630678
Validation loss: 2.5520794667324957

Epoch: 6| Step: 9
Training loss: 2.43059824467061
Validation loss: 2.549700131580426

Epoch: 6| Step: 10
Training loss: 2.7578368793739165
Validation loss: 2.551566952734397

Epoch: 6| Step: 11
Training loss: 2.9083959388734986
Validation loss: 2.549572349042984

Epoch: 6| Step: 12
Training loss: 2.6515912658533747
Validation loss: 2.5446121835413495

Epoch: 6| Step: 13
Training loss: 2.3237710473480737
Validation loss: 2.546786238482956

Epoch: 62| Step: 0
Training loss: 2.988659564237078
Validation loss: 2.5478528569721304

Epoch: 6| Step: 1
Training loss: 2.635075623731821
Validation loss: 2.547334547650386

Epoch: 6| Step: 2
Training loss: 2.5738701128433203
Validation loss: 2.544696679816853

Epoch: 6| Step: 3
Training loss: 2.2695192740513415
Validation loss: 2.5481501626431626

Epoch: 6| Step: 4
Training loss: 2.6564492543602656
Validation loss: 2.544962775564606

Epoch: 6| Step: 5
Training loss: 2.775066058773052
Validation loss: 2.545374328724095

Epoch: 6| Step: 6
Training loss: 2.180865444616979
Validation loss: 2.543485746162379

Epoch: 6| Step: 7
Training loss: 3.376197884929603
Validation loss: 2.5423147646813278

Epoch: 6| Step: 8
Training loss: 2.5795141003543676
Validation loss: 2.540865949190147

Epoch: 6| Step: 9
Training loss: 2.721261103497458
Validation loss: 2.540169944847502

Epoch: 6| Step: 10
Training loss: 2.709284121563292
Validation loss: 2.5422237103709993

Epoch: 6| Step: 11
Training loss: 3.0065691867710793
Validation loss: 2.5446279711754

Epoch: 6| Step: 12
Training loss: 2.60704457271328
Validation loss: 2.5422342688055357

Epoch: 6| Step: 13
Training loss: 2.084881347280648
Validation loss: 2.5405103262671607

Epoch: 63| Step: 0
Training loss: 2.5816544850872463
Validation loss: 2.540513141667412

Epoch: 6| Step: 1
Training loss: 2.2843915654324127
Validation loss: 2.5395752530886058

Epoch: 6| Step: 2
Training loss: 2.71935467189239
Validation loss: 2.538050100521934

Epoch: 6| Step: 3
Training loss: 2.4576190190875713
Validation loss: 2.537646543408573

Epoch: 6| Step: 4
Training loss: 2.896143084821817
Validation loss: 2.5361099056070655

Epoch: 6| Step: 5
Training loss: 2.609118694577968
Validation loss: 2.5364538632666163

Epoch: 6| Step: 6
Training loss: 2.8834628066906567
Validation loss: 2.5360150481859627

Epoch: 6| Step: 7
Training loss: 2.8978152365431447
Validation loss: 2.537500051363739

Epoch: 6| Step: 8
Training loss: 2.3612687550693994
Validation loss: 2.535882674318136

Epoch: 6| Step: 9
Training loss: 3.1554851549500835
Validation loss: 2.536517130165701

Epoch: 6| Step: 10
Training loss: 2.8565236033608437
Validation loss: 2.538224583794894

Epoch: 6| Step: 11
Training loss: 2.2761332990298246
Validation loss: 2.5341147393030012

Epoch: 6| Step: 12
Training loss: 2.98888420055767
Validation loss: 2.5321118335794917

Epoch: 6| Step: 13
Training loss: 2.1735767311678726
Validation loss: 2.532913713042975

Epoch: 64| Step: 0
Training loss: 2.4239351431853824
Validation loss: 2.5308603057412147

Epoch: 6| Step: 1
Training loss: 2.428161141655593
Validation loss: 2.5305673283055246

Epoch: 6| Step: 2
Training loss: 3.3645680587626545
Validation loss: 2.5295402341046853

Epoch: 6| Step: 3
Training loss: 2.6461261577215334
Validation loss: 2.534503870461587

Epoch: 6| Step: 4
Training loss: 2.1684206929691427
Validation loss: 2.52976236466262

Epoch: 6| Step: 5
Training loss: 2.233166668020321
Validation loss: 2.5335923334369275

Epoch: 6| Step: 6
Training loss: 2.401393001335432
Validation loss: 2.528344452979577

Epoch: 6| Step: 7
Training loss: 3.3015125796240015
Validation loss: 2.533944144355206

Epoch: 6| Step: 8
Training loss: 2.4686953381631476
Validation loss: 2.5246228562760975

Epoch: 6| Step: 9
Training loss: 2.744158696559712
Validation loss: 2.5237665109533594

Epoch: 6| Step: 10
Training loss: 2.630006647718027
Validation loss: 2.5223793826898264

Epoch: 6| Step: 11
Training loss: 2.806051363637361
Validation loss: 2.524121800911072

Epoch: 6| Step: 12
Training loss: 3.0300743733459434
Validation loss: 2.527368088476801

Epoch: 6| Step: 13
Training loss: 2.2359824633925736
Validation loss: 2.530077140571937

Epoch: 65| Step: 0
Training loss: 2.7613373186803205
Validation loss: 2.525787408885926

Epoch: 6| Step: 1
Training loss: 2.3320977027409024
Validation loss: 2.525340320452954

Epoch: 6| Step: 2
Training loss: 2.3393109818386644
Validation loss: 2.522366504129783

Epoch: 6| Step: 3
Training loss: 2.9862048545928244
Validation loss: 2.5218139401543715

Epoch: 6| Step: 4
Training loss: 2.582388941102297
Validation loss: 2.5185016036309684

Epoch: 6| Step: 5
Training loss: 2.512989061118506
Validation loss: 2.5192192258997843

Epoch: 6| Step: 6
Training loss: 2.582318034671551
Validation loss: 2.5187113213862617

Epoch: 6| Step: 7
Training loss: 3.391772379309507
Validation loss: 2.5246974291666997

Epoch: 6| Step: 8
Training loss: 2.3838244681286063
Validation loss: 2.521236298145137

Epoch: 6| Step: 9
Training loss: 2.84670397582906
Validation loss: 2.5245834126535156

Epoch: 6| Step: 10
Training loss: 2.8576930367855597
Validation loss: 2.52306586049397

Epoch: 6| Step: 11
Training loss: 2.746291521094483
Validation loss: 2.5244358634868185

Epoch: 6| Step: 12
Training loss: 1.9422266740600016
Validation loss: 2.5236825892864356

Epoch: 6| Step: 13
Training loss: 2.4817487162631573
Validation loss: 2.520464205447799

Epoch: 66| Step: 0
Training loss: 2.5694303071145743
Validation loss: 2.519239825760516

Epoch: 6| Step: 1
Training loss: 3.042595307887752
Validation loss: 2.518522974578597

Epoch: 6| Step: 2
Training loss: 2.671773629747341
Validation loss: 2.51973238987381

Epoch: 6| Step: 3
Training loss: 2.8839186947032145
Validation loss: 2.517140471044566

Epoch: 6| Step: 4
Training loss: 2.85223414206044
Validation loss: 2.515535578115769

Epoch: 6| Step: 5
Training loss: 2.543271751341542
Validation loss: 2.5167110933925616

Epoch: 6| Step: 6
Training loss: 2.3616394897849915
Validation loss: 2.517477273709032

Epoch: 6| Step: 7
Training loss: 2.430379100631098
Validation loss: 2.514125147817982

Epoch: 6| Step: 8
Training loss: 2.805592170535155
Validation loss: 2.5196917184596246

Epoch: 6| Step: 9
Training loss: 2.219867908225231
Validation loss: 2.514569552767544

Epoch: 6| Step: 10
Training loss: 2.6849893775033653
Validation loss: 2.509719503847259

Epoch: 6| Step: 11
Training loss: 2.8027745260625787
Validation loss: 2.5140108098860106

Epoch: 6| Step: 12
Training loss: 2.4981970007481635
Validation loss: 2.5109379070276114

Epoch: 6| Step: 13
Training loss: 2.4797771781372715
Validation loss: 2.509827989330345

Epoch: 67| Step: 0
Training loss: 2.9809801855289333
Validation loss: 2.509442157408857

Epoch: 6| Step: 1
Training loss: 2.702577745023352
Validation loss: 2.5162723885033045

Epoch: 6| Step: 2
Training loss: 2.23331815894746
Validation loss: 2.507915474905692

Epoch: 6| Step: 3
Training loss: 2.7801300537096374
Validation loss: 2.5149461766241696

Epoch: 6| Step: 4
Training loss: 2.3754360401019503
Validation loss: 2.5135684245256056

Epoch: 6| Step: 5
Training loss: 3.170034090454479
Validation loss: 2.5086046910648787

Epoch: 6| Step: 6
Training loss: 2.840917832794611
Validation loss: 2.5078676560338797

Epoch: 6| Step: 7
Training loss: 2.594461366469829
Validation loss: 2.5125951745778403

Epoch: 6| Step: 8
Training loss: 2.559823382811827
Validation loss: 2.5129108200633525

Epoch: 6| Step: 9
Training loss: 2.627000863588073
Validation loss: 2.5115003080484937

Epoch: 6| Step: 10
Training loss: 2.5617926016606694
Validation loss: 2.512280011391365

Epoch: 6| Step: 11
Training loss: 2.4209028692539607
Validation loss: 2.514454808357327

Epoch: 6| Step: 12
Training loss: 2.5173800962470314
Validation loss: 2.5120713780896327

Epoch: 6| Step: 13
Training loss: 2.367989986353399
Validation loss: 2.5090549041560855

Epoch: 68| Step: 0
Training loss: 2.6818879548975403
Validation loss: 2.5105338537530315

Epoch: 6| Step: 1
Training loss: 2.5851821026585826
Validation loss: 2.508705811921566

Epoch: 6| Step: 2
Training loss: 2.430622669080547
Validation loss: 2.507030789082137

Epoch: 6| Step: 3
Training loss: 2.158932551367119
Validation loss: 2.5035416629758775

Epoch: 6| Step: 4
Training loss: 2.4120364282365507
Validation loss: 2.5103204690274956

Epoch: 6| Step: 5
Training loss: 2.9865388864476
Validation loss: 2.508878392239915

Epoch: 6| Step: 6
Training loss: 2.3228992980398933
Validation loss: 2.509880813349987

Epoch: 6| Step: 7
Training loss: 2.9104891797814676
Validation loss: 2.513794163651563

Epoch: 6| Step: 8
Training loss: 2.8138268625750285
Validation loss: 2.5086400299729545

Epoch: 6| Step: 9
Training loss: 2.5061082604870144
Validation loss: 2.5147402453406698

Epoch: 6| Step: 10
Training loss: 2.7772681203167413
Validation loss: 2.522128762765017

Epoch: 6| Step: 11
Training loss: 2.9461869376048555
Validation loss: 2.513154295439327

Epoch: 6| Step: 12
Training loss: 2.9867276011222823
Validation loss: 2.518561345585018

Epoch: 6| Step: 13
Training loss: 2.4395729444778285
Validation loss: 2.5146370126409154

Epoch: 69| Step: 0
Training loss: 3.1265248965051913
Validation loss: 2.513864758295498

Epoch: 6| Step: 1
Training loss: 2.6357402879242415
Validation loss: 2.5195629029170874

Epoch: 6| Step: 2
Training loss: 2.404489442874723
Validation loss: 2.5159508235478953

Epoch: 6| Step: 3
Training loss: 2.2828775113331177
Validation loss: 2.515040359324916

Epoch: 6| Step: 4
Training loss: 2.415917927301654
Validation loss: 2.5103086524825304

Epoch: 6| Step: 5
Training loss: 2.347173301543115
Validation loss: 2.50857662233493

Epoch: 6| Step: 6
Training loss: 2.531264881985091
Validation loss: 2.507563989671563

Epoch: 6| Step: 7
Training loss: 3.0808002445451654
Validation loss: 2.5030898232593746

Epoch: 6| Step: 8
Training loss: 3.2726467151553034
Validation loss: 2.50331168175116

Epoch: 6| Step: 9
Training loss: 2.9531161192099438
Validation loss: 2.505061509448907

Epoch: 6| Step: 10
Training loss: 2.2809525387319556
Validation loss: 2.510845524943679

Epoch: 6| Step: 11
Training loss: 2.3981605394725967
Validation loss: 2.5134099207810845

Epoch: 6| Step: 12
Training loss: 2.419797732514885
Validation loss: 2.520172999463516

Epoch: 6| Step: 13
Training loss: 2.575928926038281
Validation loss: 2.5143295174737093

Epoch: 70| Step: 0
Training loss: 2.6235472882798074
Validation loss: 2.5197102958679083

Epoch: 6| Step: 1
Training loss: 2.665779969695975
Validation loss: 2.5345294728143637

Epoch: 6| Step: 2
Training loss: 3.0180135962076995
Validation loss: 2.509707074898676

Epoch: 6| Step: 3
Training loss: 2.140157049780083
Validation loss: 2.501963543677891

Epoch: 6| Step: 4
Training loss: 3.051574213227168
Validation loss: 2.502293424867461

Epoch: 6| Step: 5
Training loss: 1.9504286808371083
Validation loss: 2.5009997435179034

Epoch: 6| Step: 6
Training loss: 2.618141114455567
Validation loss: 2.500798940154071

Epoch: 6| Step: 7
Training loss: 2.7722418128446655
Validation loss: 2.4975160338453843

Epoch: 6| Step: 8
Training loss: 2.7358077301150434
Validation loss: 2.5011967576089122

Epoch: 6| Step: 9
Training loss: 2.210390056865804
Validation loss: 2.499807461635885

Epoch: 6| Step: 10
Training loss: 2.723166900865737
Validation loss: 2.502813440968008

Epoch: 6| Step: 11
Training loss: 3.472399741827115
Validation loss: 2.49995179129849

Epoch: 6| Step: 12
Training loss: 2.2491341090334034
Validation loss: 2.501478457384348

Epoch: 6| Step: 13
Training loss: 2.1093042432432467
Validation loss: 2.499623302053895

Epoch: 71| Step: 0
Training loss: 2.628624003932996
Validation loss: 2.499148430430738

Epoch: 6| Step: 1
Training loss: 2.6082999019085014
Validation loss: 2.501920455175356

Epoch: 6| Step: 2
Training loss: 2.8194507751226734
Validation loss: 2.498821902847514

Epoch: 6| Step: 3
Training loss: 2.202652359714335
Validation loss: 2.49880107105473

Epoch: 6| Step: 4
Training loss: 2.2515923905092743
Validation loss: 2.5020447792896507

Epoch: 6| Step: 5
Training loss: 2.8790076146079753
Validation loss: 2.500425954135182

Epoch: 6| Step: 6
Training loss: 3.021798569384317
Validation loss: 2.503368397283854

Epoch: 6| Step: 7
Training loss: 2.7845120106220738
Validation loss: 2.498112076939139

Epoch: 6| Step: 8
Training loss: 2.348405004544287
Validation loss: 2.5018167808481033

Epoch: 6| Step: 9
Training loss: 2.598128793514989
Validation loss: 2.501242884991675

Epoch: 6| Step: 10
Training loss: 2.675172611264745
Validation loss: 2.499522227092378

Epoch: 6| Step: 11
Training loss: 2.9476629536681656
Validation loss: 2.4966573621154624

Epoch: 6| Step: 12
Training loss: 2.383388162084504
Validation loss: 2.4947136619228543

Epoch: 6| Step: 13
Training loss: 2.3731258426290025
Validation loss: 2.496400610299859

Epoch: 72| Step: 0
Training loss: 2.3579210260187695
Validation loss: 2.4959330857795377

Epoch: 6| Step: 1
Training loss: 2.7839239746324256
Validation loss: 2.4919359644249437

Epoch: 6| Step: 2
Training loss: 2.820480891138139
Validation loss: 2.4933868519841154

Epoch: 6| Step: 3
Training loss: 2.0430614093022696
Validation loss: 2.4878911501572003

Epoch: 6| Step: 4
Training loss: 2.167531342241304
Validation loss: 2.486690218185834

Epoch: 6| Step: 5
Training loss: 2.5583844514227603
Validation loss: 2.4859211906571055

Epoch: 6| Step: 6
Training loss: 2.6528528368207924
Validation loss: 2.491461445789215

Epoch: 6| Step: 7
Training loss: 2.3146921026411476
Validation loss: 2.485952248520562

Epoch: 6| Step: 8
Training loss: 2.797916325057618
Validation loss: 2.4928529781635196

Epoch: 6| Step: 9
Training loss: 2.4387160960020364
Validation loss: 2.480406688804899

Epoch: 6| Step: 10
Training loss: 3.550243240404809
Validation loss: 2.488091941191618

Epoch: 6| Step: 11
Training loss: 2.6868347409150033
Validation loss: 2.4928111349402333

Epoch: 6| Step: 12
Training loss: 2.4135823682816846
Validation loss: 2.4897284738112053

Epoch: 6| Step: 13
Training loss: 2.776939738272611
Validation loss: 2.4927805769882694

Epoch: 73| Step: 0
Training loss: 2.078064422871791
Validation loss: 2.4942053714514394

Epoch: 6| Step: 1
Training loss: 2.920074560964044
Validation loss: 2.4938347294562244

Epoch: 6| Step: 2
Training loss: 2.846041583981848
Validation loss: 2.4938089961289305

Epoch: 6| Step: 3
Training loss: 2.574003589766933
Validation loss: 2.498018544473627

Epoch: 6| Step: 4
Training loss: 2.7774773202102345
Validation loss: 2.4968303296068326

Epoch: 6| Step: 5
Training loss: 2.4584465862846696
Validation loss: 2.496346856359969

Epoch: 6| Step: 6
Training loss: 2.6626635147531976
Validation loss: 2.497315841417346

Epoch: 6| Step: 7
Training loss: 2.3989742312206164
Validation loss: 2.4975833020273

Epoch: 6| Step: 8
Training loss: 2.7803689654184938
Validation loss: 2.5030650740874423

Epoch: 6| Step: 9
Training loss: 3.1103379181902455
Validation loss: 2.498951151494186

Epoch: 6| Step: 10
Training loss: 2.5191257357471586
Validation loss: 2.4972105835966474

Epoch: 6| Step: 11
Training loss: 2.471058792026184
Validation loss: 2.4936262101606084

Epoch: 6| Step: 12
Training loss: 2.1458493821614906
Validation loss: 2.493717612786821

Epoch: 6| Step: 13
Training loss: 2.7225326006490134
Validation loss: 2.4998686120157827

Epoch: 74| Step: 0
Training loss: 2.506611283820016
Validation loss: 2.501916730756494

Epoch: 6| Step: 1
Training loss: 2.6868883368371206
Validation loss: 2.5011330262296423

Epoch: 6| Step: 2
Training loss: 2.17127883742645
Validation loss: 2.4993289046771903

Epoch: 6| Step: 3
Training loss: 2.5919171947156596
Validation loss: 2.4959648628370004

Epoch: 6| Step: 4
Training loss: 2.7531576234787645
Validation loss: 2.4987752934585155

Epoch: 6| Step: 5
Training loss: 2.4479680373841575
Validation loss: 2.4932883769927554

Epoch: 6| Step: 6
Training loss: 2.7613476796657834
Validation loss: 2.4844351227401

Epoch: 6| Step: 7
Training loss: 2.20776635814918
Validation loss: 2.491177712077738

Epoch: 6| Step: 8
Training loss: 2.2472765652572435
Validation loss: 2.484965432180553

Epoch: 6| Step: 9
Training loss: 2.813716371081942
Validation loss: 2.4916742368304567

Epoch: 6| Step: 10
Training loss: 2.4710643881139718
Validation loss: 2.4893674131688535

Epoch: 6| Step: 11
Training loss: 2.8915756724292665
Validation loss: 2.488528971415462

Epoch: 6| Step: 12
Training loss: 2.930069962014526
Validation loss: 2.487622791243618

Epoch: 6| Step: 13
Training loss: 2.8590616356742773
Validation loss: 2.486805508660428

Epoch: 75| Step: 0
Training loss: 2.630895533663683
Validation loss: 2.488291095133278

Epoch: 6| Step: 1
Training loss: 2.818203293251483
Validation loss: 2.4902857237863603

Epoch: 6| Step: 2
Training loss: 3.0687335664577167
Validation loss: 2.500552815669332

Epoch: 6| Step: 3
Training loss: 2.8218764092831563
Validation loss: 2.50340965135191

Epoch: 6| Step: 4
Training loss: 2.299243665813594
Validation loss: 2.4928084091287492

Epoch: 6| Step: 5
Training loss: 2.696198160365535
Validation loss: 2.489739246886423

Epoch: 6| Step: 6
Training loss: 2.8078624213551313
Validation loss: 2.4833908690970907

Epoch: 6| Step: 7
Training loss: 2.849517507033109
Validation loss: 2.4830763839646797

Epoch: 6| Step: 8
Training loss: 2.601485150994471
Validation loss: 2.483501224688274

Epoch: 6| Step: 9
Training loss: 1.8742444105407159
Validation loss: 2.4843168271849447

Epoch: 6| Step: 10
Training loss: 2.0597177871424277
Validation loss: 2.483386340844998

Epoch: 6| Step: 11
Training loss: 2.341633973170581
Validation loss: 2.4830545399063664

Epoch: 6| Step: 12
Training loss: 2.676819002829192
Validation loss: 2.482262647050685

Epoch: 6| Step: 13
Training loss: 2.751559508894465
Validation loss: 2.482416376547498

Epoch: 76| Step: 0
Training loss: 2.6817528242073396
Validation loss: 2.47855811036323

Epoch: 6| Step: 1
Training loss: 3.4501139082970305
Validation loss: 2.4785255971016062

Epoch: 6| Step: 2
Training loss: 2.161495959096145
Validation loss: 2.4824388584983637

Epoch: 6| Step: 3
Training loss: 2.758338337765982
Validation loss: 2.483654037564644

Epoch: 6| Step: 4
Training loss: 2.46190563716453
Validation loss: 2.4855356923903473

Epoch: 6| Step: 5
Training loss: 2.135061789697243
Validation loss: 2.4833563709683895

Epoch: 6| Step: 6
Training loss: 2.5065401361198054
Validation loss: 2.480758049381832

Epoch: 6| Step: 7
Training loss: 2.4542437875371204
Validation loss: 2.4853191061342605

Epoch: 6| Step: 8
Training loss: 3.04111754455493
Validation loss: 2.4835230328176805

Epoch: 6| Step: 9
Training loss: 2.004798972880168
Validation loss: 2.482049713530371

Epoch: 6| Step: 10
Training loss: 2.4042524493255466
Validation loss: 2.4865252228651737

Epoch: 6| Step: 11
Training loss: 2.9723217809844136
Validation loss: 2.4798175748005646

Epoch: 6| Step: 12
Training loss: 2.616720038272629
Validation loss: 2.47676725774582

Epoch: 6| Step: 13
Training loss: 2.3117889135812186
Validation loss: 2.4758663863838253

Epoch: 77| Step: 0
Training loss: 2.1408645607212744
Validation loss: 2.4789662213329176

Epoch: 6| Step: 1
Training loss: 2.4331111031347814
Validation loss: 2.478804190500684

Epoch: 6| Step: 2
Training loss: 2.443870631213808
Validation loss: 2.4728350582224343

Epoch: 6| Step: 3
Training loss: 2.7628275198129613
Validation loss: 2.4780960068483866

Epoch: 6| Step: 4
Training loss: 2.6379140447534155
Validation loss: 2.4754606537527093

Epoch: 6| Step: 5
Training loss: 2.808260116603753
Validation loss: 2.4732393016274683

Epoch: 6| Step: 6
Training loss: 2.590164555952073
Validation loss: 2.4731826262130605

Epoch: 6| Step: 7
Training loss: 2.6369164964910348
Validation loss: 2.4717183837916075

Epoch: 6| Step: 8
Training loss: 2.6668723940965084
Validation loss: 2.4742025127707206

Epoch: 6| Step: 9
Training loss: 2.8088828668885255
Validation loss: 2.4763945513556123

Epoch: 6| Step: 10
Training loss: 2.6121681477167202
Validation loss: 2.4791003039370954

Epoch: 6| Step: 11
Training loss: 2.2289259831156367
Validation loss: 2.479595008411933

Epoch: 6| Step: 12
Training loss: 2.680510903240757
Validation loss: 2.4810736291628737

Epoch: 6| Step: 13
Training loss: 2.7572597565706167
Validation loss: 2.480950256230294

Epoch: 78| Step: 0
Training loss: 2.0413046016269925
Validation loss: 2.480739676830819

Epoch: 6| Step: 1
Training loss: 2.3176592418029234
Validation loss: 2.4792632610405803

Epoch: 6| Step: 2
Training loss: 2.8862244798433254
Validation loss: 2.477524643694288

Epoch: 6| Step: 3
Training loss: 2.5662473864572246
Validation loss: 2.4770565081770233

Epoch: 6| Step: 4
Training loss: 2.491502817267552
Validation loss: 2.4728207726808016

Epoch: 6| Step: 5
Training loss: 2.6102141898243243
Validation loss: 2.4770947033936945

Epoch: 6| Step: 6
Training loss: 2.8088197152993284
Validation loss: 2.4737150748603174

Epoch: 6| Step: 7
Training loss: 2.8935746273675935
Validation loss: 2.474716493314932

Epoch: 6| Step: 8
Training loss: 2.625958767139406
Validation loss: 2.477120770769586

Epoch: 6| Step: 9
Training loss: 2.3978755926419715
Validation loss: 2.47736701773956

Epoch: 6| Step: 10
Training loss: 2.30765841104604
Validation loss: 2.475597077093198

Epoch: 6| Step: 11
Training loss: 2.791539222503228
Validation loss: 2.479302864714574

Epoch: 6| Step: 12
Training loss: 2.327303952852924
Validation loss: 2.4710895542716598

Epoch: 6| Step: 13
Training loss: 2.9775392226447153
Validation loss: 2.464537184845637

Epoch: 79| Step: 0
Training loss: 2.4670084351394244
Validation loss: 2.4783517208670003

Epoch: 6| Step: 1
Training loss: 2.7836680669764657
Validation loss: 2.474970613812502

Epoch: 6| Step: 2
Training loss: 2.3555812018075977
Validation loss: 2.4742854226703823

Epoch: 6| Step: 3
Training loss: 2.1362828676609333
Validation loss: 2.4750007976183905

Epoch: 6| Step: 4
Training loss: 2.6447261586339326
Validation loss: 2.4777589428997877

Epoch: 6| Step: 5
Training loss: 2.6533882432875706
Validation loss: 2.4760578977197016

Epoch: 6| Step: 6
Training loss: 2.381182103428102
Validation loss: 2.481154699921639

Epoch: 6| Step: 7
Training loss: 2.826729698992851
Validation loss: 2.476801446564857

Epoch: 6| Step: 8
Training loss: 2.5020190668759383
Validation loss: 2.4742989449512804

Epoch: 6| Step: 9
Training loss: 2.3010934511030245
Validation loss: 2.470335857450635

Epoch: 6| Step: 10
Training loss: 2.826292846030977
Validation loss: 2.47414982640193

Epoch: 6| Step: 11
Training loss: 2.3498313843316585
Validation loss: 2.476551140118367

Epoch: 6| Step: 12
Training loss: 2.6982181532814864
Validation loss: 2.4757780643826637

Epoch: 6| Step: 13
Training loss: 3.06798731383246
Validation loss: 2.4795135661392087

Epoch: 80| Step: 0
Training loss: 2.7085728074841153
Validation loss: 2.477927135827931

Epoch: 6| Step: 1
Training loss: 2.2833305173239316
Validation loss: 2.4793442547661813

Epoch: 6| Step: 2
Training loss: 2.528529742346027
Validation loss: 2.47547937047195

Epoch: 6| Step: 3
Training loss: 2.207296547937569
Validation loss: 2.4754872680503075

Epoch: 6| Step: 4
Training loss: 2.7693427146798024
Validation loss: 2.4802309097443827

Epoch: 6| Step: 5
Training loss: 3.357840253982409
Validation loss: 2.4770057353791484

Epoch: 6| Step: 6
Training loss: 2.325695229228321
Validation loss: 2.4781612847370846

Epoch: 6| Step: 7
Training loss: 2.3417860831043034
Validation loss: 2.4768947374454426

Epoch: 6| Step: 8
Training loss: 2.274943164492767
Validation loss: 2.4722507861507714

Epoch: 6| Step: 9
Training loss: 2.341825381655102
Validation loss: 2.471055801008548

Epoch: 6| Step: 10
Training loss: 2.9127125412825294
Validation loss: 2.472747881388249

Epoch: 6| Step: 11
Training loss: 2.659340530333491
Validation loss: 2.466926400153563

Epoch: 6| Step: 12
Training loss: 2.9130883928186937
Validation loss: 2.4777018015331786

Epoch: 6| Step: 13
Training loss: 2.4102144157031105
Validation loss: 2.4732284968471023

Epoch: 81| Step: 0
Training loss: 2.0574482403498635
Validation loss: 2.4802926869622572

Epoch: 6| Step: 1
Training loss: 2.777911979824301
Validation loss: 2.4804494781946964

Epoch: 6| Step: 2
Training loss: 2.621766505764442
Validation loss: 2.478874659504791

Epoch: 6| Step: 3
Training loss: 2.4826552478692947
Validation loss: 2.4810494771880314

Epoch: 6| Step: 4
Training loss: 2.4253041263490327
Validation loss: 2.4859937756185033

Epoch: 6| Step: 5
Training loss: 2.4812290258025573
Validation loss: 2.490353745734742

Epoch: 6| Step: 6
Training loss: 2.6389225093194515
Validation loss: 2.5006926212894434

Epoch: 6| Step: 7
Training loss: 2.5659032412903944
Validation loss: 2.5031160009177147

Epoch: 6| Step: 8
Training loss: 2.859535587991816
Validation loss: 2.5104088262116337

Epoch: 6| Step: 9
Training loss: 3.1384643410113497
Validation loss: 2.513374332739473

Epoch: 6| Step: 10
Training loss: 2.767998232080193
Validation loss: 2.5147334349257617

Epoch: 6| Step: 11
Training loss: 2.555995501321765
Validation loss: 2.5114128911387374

Epoch: 6| Step: 12
Training loss: 2.7698802217001943
Validation loss: 2.5192031686173966

Epoch: 6| Step: 13
Training loss: 2.5652767116909523
Validation loss: 2.511493931859127

Epoch: 82| Step: 0
Training loss: 2.988813524899319
Validation loss: 2.508945419133424

Epoch: 6| Step: 1
Training loss: 2.9986877750430074
Validation loss: 2.517143865104912

Epoch: 6| Step: 2
Training loss: 1.9432761936500764
Validation loss: 2.505857741686635

Epoch: 6| Step: 3
Training loss: 2.3731822034136707
Validation loss: 2.51172645452968

Epoch: 6| Step: 4
Training loss: 3.0362297133439005
Validation loss: 2.505651380628909

Epoch: 6| Step: 5
Training loss: 2.8136621405409143
Validation loss: 2.5022049081589937

Epoch: 6| Step: 6
Training loss: 2.223734455022145
Validation loss: 2.503785097203454

Epoch: 6| Step: 7
Training loss: 2.861131139230431
Validation loss: 2.4980523310947955

Epoch: 6| Step: 8
Training loss: 2.441572455280065
Validation loss: 2.495890275266369

Epoch: 6| Step: 9
Training loss: 2.69662558594649
Validation loss: 2.494496024711695

Epoch: 6| Step: 10
Training loss: 2.6088448174303327
Validation loss: 2.4911184539236757

Epoch: 6| Step: 11
Training loss: 2.539277522445811
Validation loss: 2.4885810260260204

Epoch: 6| Step: 12
Training loss: 2.8194484073838653
Validation loss: 2.4905077655790895

Epoch: 6| Step: 13
Training loss: 2.219030335674966
Validation loss: 2.4872632142408433

Epoch: 83| Step: 0
Training loss: 2.37742631350788
Validation loss: 2.479740642706477

Epoch: 6| Step: 1
Training loss: 3.1073922588056773
Validation loss: 2.47698022827278

Epoch: 6| Step: 2
Training loss: 2.4257765323021756
Validation loss: 2.4777756696909714

Epoch: 6| Step: 3
Training loss: 3.09361898742089
Validation loss: 2.4761625462352455

Epoch: 6| Step: 4
Training loss: 2.5123310203094515
Validation loss: 2.4751475611281486

Epoch: 6| Step: 5
Training loss: 2.1689459720423354
Validation loss: 2.472524710757693

Epoch: 6| Step: 6
Training loss: 2.3621274543374384
Validation loss: 2.47451953077519

Epoch: 6| Step: 7
Training loss: 2.616798121396087
Validation loss: 2.4766639664619414

Epoch: 6| Step: 8
Training loss: 2.7268181711028765
Validation loss: 2.4709184434673004

Epoch: 6| Step: 9
Training loss: 2.5990018872807905
Validation loss: 2.4674726553744524

Epoch: 6| Step: 10
Training loss: 2.451622180686391
Validation loss: 2.4708771695842033

Epoch: 6| Step: 11
Training loss: 2.4615798354110505
Validation loss: 2.4704909322737327

Epoch: 6| Step: 12
Training loss: 2.5295965186587948
Validation loss: 2.471014392731105

Epoch: 6| Step: 13
Training loss: 2.664197901531831
Validation loss: 2.4681804176974618

Epoch: 84| Step: 0
Training loss: 2.4918895770570586
Validation loss: 2.469909830107754

Epoch: 6| Step: 1
Training loss: 2.5194024577971357
Validation loss: 2.4656297304134656

Epoch: 6| Step: 2
Training loss: 2.459571386540155
Validation loss: 2.4692247473479294

Epoch: 6| Step: 3
Training loss: 2.4419889929521017
Validation loss: 2.4686281198281663

Epoch: 6| Step: 4
Training loss: 2.825162231378219
Validation loss: 2.470827041755201

Epoch: 6| Step: 5
Training loss: 2.257391022410132
Validation loss: 2.469420941439696

Epoch: 6| Step: 6
Training loss: 2.910416108888879
Validation loss: 2.4769305127237744

Epoch: 6| Step: 7
Training loss: 2.5099212242014244
Validation loss: 2.472173273004383

Epoch: 6| Step: 8
Training loss: 2.803646393833226
Validation loss: 2.4699682617979826

Epoch: 6| Step: 9
Training loss: 2.4426094691286115
Validation loss: 2.4741069762431493

Epoch: 6| Step: 10
Training loss: 3.0147200891934434
Validation loss: 2.469519595816915

Epoch: 6| Step: 11
Training loss: 2.3779602675459275
Validation loss: 2.464679073710947

Epoch: 6| Step: 12
Training loss: 2.6618489217096517
Validation loss: 2.46923189248502

Epoch: 6| Step: 13
Training loss: 2.2374974554462987
Validation loss: 2.469041509358418

Epoch: 85| Step: 0
Training loss: 2.4063804888332503
Validation loss: 2.467518752934118

Epoch: 6| Step: 1
Training loss: 2.882537911423025
Validation loss: 2.4665391414342928

Epoch: 6| Step: 2
Training loss: 2.4204004536477153
Validation loss: 2.4715821161382796

Epoch: 6| Step: 3
Training loss: 2.5887618300657125
Validation loss: 2.475697957149782

Epoch: 6| Step: 4
Training loss: 2.4456371542796504
Validation loss: 2.474102045536338

Epoch: 6| Step: 5
Training loss: 2.4895240638306935
Validation loss: 2.4765139152823425

Epoch: 6| Step: 6
Training loss: 2.5401708443323248
Validation loss: 2.477825079619883

Epoch: 6| Step: 7
Training loss: 2.4566322087528754
Validation loss: 2.479404331216806

Epoch: 6| Step: 8
Training loss: 2.386758207753574
Validation loss: 2.481330125285307

Epoch: 6| Step: 9
Training loss: 2.5944325112125806
Validation loss: 2.476122491138191

Epoch: 6| Step: 10
Training loss: 2.7220291882364758
Validation loss: 2.479543646566044

Epoch: 6| Step: 11
Training loss: 2.2840348059545876
Validation loss: 2.4813170096495734

Epoch: 6| Step: 12
Training loss: 2.831492068824391
Validation loss: 2.478158751262301

Epoch: 6| Step: 13
Training loss: 3.022899017878374
Validation loss: 2.4725299017486315

Epoch: 86| Step: 0
Training loss: 2.600929343584209
Validation loss: 2.478157340211931

Epoch: 6| Step: 1
Training loss: 2.634421109014343
Validation loss: 2.4761785777211336

Epoch: 6| Step: 2
Training loss: 2.6766673159410472
Validation loss: 2.479802656474376

Epoch: 6| Step: 3
Training loss: 1.9994024337694214
Validation loss: 2.4778417738911873

Epoch: 6| Step: 4
Training loss: 2.069201016314449
Validation loss: 2.4755893724807696

Epoch: 6| Step: 5
Training loss: 2.5648416194389854
Validation loss: 2.4777555349826557

Epoch: 6| Step: 6
Training loss: 3.021761170761203
Validation loss: 2.479069641095302

Epoch: 6| Step: 7
Training loss: 3.157008467084413
Validation loss: 2.4753792841405073

Epoch: 6| Step: 8
Training loss: 2.204549666975407
Validation loss: 2.4732649678124052

Epoch: 6| Step: 9
Training loss: 2.2782350238871674
Validation loss: 2.4708236162360198

Epoch: 6| Step: 10
Training loss: 2.4517637716011387
Validation loss: 2.4683014828440557

Epoch: 6| Step: 11
Training loss: 2.9968559956669005
Validation loss: 2.4696928549673935

Epoch: 6| Step: 12
Training loss: 2.907562615728143
Validation loss: 2.4650705659372205

Epoch: 6| Step: 13
Training loss: 2.2733869514220397
Validation loss: 2.4634356378450426

Epoch: 87| Step: 0
Training loss: 3.152219710810877
Validation loss: 2.4610335477624394

Epoch: 6| Step: 1
Training loss: 2.917925771782303
Validation loss: 2.460674647265673

Epoch: 6| Step: 2
Training loss: 2.626644527645371
Validation loss: 2.467004923782208

Epoch: 6| Step: 3
Training loss: 2.5768053781234768
Validation loss: 2.4665656586749285

Epoch: 6| Step: 4
Training loss: 2.2131078197692555
Validation loss: 2.462139082534778

Epoch: 6| Step: 5
Training loss: 2.8736366688340707
Validation loss: 2.4630385941039648

Epoch: 6| Step: 6
Training loss: 2.2834952814443077
Validation loss: 2.4698850058738357

Epoch: 6| Step: 7
Training loss: 1.7973663985005908
Validation loss: 2.471324286700638

Epoch: 6| Step: 8
Training loss: 2.7167257029509737
Validation loss: 2.472448564257334

Epoch: 6| Step: 9
Training loss: 2.835549067858878
Validation loss: 2.469571214413073

Epoch: 6| Step: 10
Training loss: 2.4910780969580304
Validation loss: 2.4729038012158395

Epoch: 6| Step: 11
Training loss: 2.2220829390215444
Validation loss: 2.4689287048558644

Epoch: 6| Step: 12
Training loss: 2.6485364327196095
Validation loss: 2.461235771067032

Epoch: 6| Step: 13
Training loss: 2.2987957662867
Validation loss: 2.458321576709976

Epoch: 88| Step: 0
Training loss: 2.176703704394246
Validation loss: 2.4571973606031277

Epoch: 6| Step: 1
Training loss: 2.2932879406110884
Validation loss: 2.4567869516770857

Epoch: 6| Step: 2
Training loss: 2.8614461099821593
Validation loss: 2.44814915195602

Epoch: 6| Step: 3
Training loss: 2.9885730875162264
Validation loss: 2.451773058356839

Epoch: 6| Step: 4
Training loss: 2.9065408868727425
Validation loss: 2.459546078294192

Epoch: 6| Step: 5
Training loss: 2.9196233386265984
Validation loss: 2.460233234369195

Epoch: 6| Step: 6
Training loss: 2.3589018290404313
Validation loss: 2.4658264764387687

Epoch: 6| Step: 7
Training loss: 2.5920042114576813
Validation loss: 2.4678112289298553

Epoch: 6| Step: 8
Training loss: 2.1002853653796265
Validation loss: 2.4657626527396324

Epoch: 6| Step: 9
Training loss: 2.2746205610825325
Validation loss: 2.465954997095238

Epoch: 6| Step: 10
Training loss: 2.45988446669921
Validation loss: 2.4670431618710253

Epoch: 6| Step: 11
Training loss: 3.0036833721364222
Validation loss: 2.4688603179362714

Epoch: 6| Step: 12
Training loss: 2.0635258984208
Validation loss: 2.4651495355433757

Epoch: 6| Step: 13
Training loss: 2.734112623433052
Validation loss: 2.4611791905798137

Epoch: 89| Step: 0
Training loss: 2.3396952841501735
Validation loss: 2.458012193512476

Epoch: 6| Step: 1
Training loss: 2.478176902429507
Validation loss: 2.4627983041673724

Epoch: 6| Step: 2
Training loss: 2.9426900587386564
Validation loss: 2.4610320865275965

Epoch: 6| Step: 3
Training loss: 2.177332107956295
Validation loss: 2.4509446483324453

Epoch: 6| Step: 4
Training loss: 2.3366566447298385
Validation loss: 2.4590153044557503

Epoch: 6| Step: 5
Training loss: 2.6085661588193894
Validation loss: 2.4573777706966884

Epoch: 6| Step: 6
Training loss: 2.4133779795962136
Validation loss: 2.453709801946882

Epoch: 6| Step: 7
Training loss: 2.5469350047151593
Validation loss: 2.454267264238171

Epoch: 6| Step: 8
Training loss: 2.5754632329462233
Validation loss: 2.446986526279642

Epoch: 6| Step: 9
Training loss: 2.5682111225926776
Validation loss: 2.4520192742116547

Epoch: 6| Step: 10
Training loss: 2.5114503898057237
Validation loss: 2.459414330652302

Epoch: 6| Step: 11
Training loss: 3.028625453225488
Validation loss: 2.4592606578907614

Epoch: 6| Step: 12
Training loss: 3.049835175610097
Validation loss: 2.4585915499922715

Epoch: 6| Step: 13
Training loss: 2.2701457204554183
Validation loss: 2.4684835201612465

Epoch: 90| Step: 0
Training loss: 2.6791878726608442
Validation loss: 2.466762032040025

Epoch: 6| Step: 1
Training loss: 3.184942977610413
Validation loss: 2.4724507982214026

Epoch: 6| Step: 2
Training loss: 2.880047058409773
Validation loss: 2.473714520670792

Epoch: 6| Step: 3
Training loss: 2.031476756423673
Validation loss: 2.4677178039841388

Epoch: 6| Step: 4
Training loss: 2.2443175084296336
Validation loss: 2.4751852961577137

Epoch: 6| Step: 5
Training loss: 2.81513963383515
Validation loss: 2.4737996796715835

Epoch: 6| Step: 6
Training loss: 2.655050388296254
Validation loss: 2.4735058554744613

Epoch: 6| Step: 7
Training loss: 2.3344860862436585
Validation loss: 2.4729172667770705

Epoch: 6| Step: 8
Training loss: 2.6261706693670073
Validation loss: 2.472319071250219

Epoch: 6| Step: 9
Training loss: 2.201084788511297
Validation loss: 2.4779229503872857

Epoch: 6| Step: 10
Training loss: 2.4781756517349716
Validation loss: 2.4711206699014174

Epoch: 6| Step: 11
Training loss: 2.780805059267716
Validation loss: 2.475229781173776

Epoch: 6| Step: 12
Training loss: 2.2811477847257677
Validation loss: 2.470391914559797

Epoch: 6| Step: 13
Training loss: 2.5148407086688467
Validation loss: 2.469562654296565

Epoch: 91| Step: 0
Training loss: 2.8979577338359523
Validation loss: 2.4662103748570128

Epoch: 6| Step: 1
Training loss: 2.352216357199452
Validation loss: 2.4715640773133907

Epoch: 6| Step: 2
Training loss: 3.112660421503953
Validation loss: 2.4673785814727967

Epoch: 6| Step: 3
Training loss: 2.782142238872214
Validation loss: 2.4694053810108993

Epoch: 6| Step: 4
Training loss: 1.979247790899245
Validation loss: 2.4607983746636113

Epoch: 6| Step: 5
Training loss: 2.6486152881824307
Validation loss: 2.4699097416225935

Epoch: 6| Step: 6
Training loss: 1.9471332042056197
Validation loss: 2.461151783812564

Epoch: 6| Step: 7
Training loss: 2.635331847342508
Validation loss: 2.4668135472547488

Epoch: 6| Step: 8
Training loss: 3.0077398910675996
Validation loss: 2.468446101223457

Epoch: 6| Step: 9
Training loss: 1.9999033785368923
Validation loss: 2.4655645639468826

Epoch: 6| Step: 10
Training loss: 2.8653585228940686
Validation loss: 2.4649362521540032

Epoch: 6| Step: 11
Training loss: 2.6114602351527267
Validation loss: 2.4653791278428754

Epoch: 6| Step: 12
Training loss: 2.154569994161529
Validation loss: 2.4654505124416732

Epoch: 6| Step: 13
Training loss: 2.5647512641752654
Validation loss: 2.458198823858895

Epoch: 92| Step: 0
Training loss: 2.737619796291635
Validation loss: 2.4674944602314075

Epoch: 6| Step: 1
Training loss: 2.731225865167965
Validation loss: 2.468526210379704

Epoch: 6| Step: 2
Training loss: 2.159156940673375
Validation loss: 2.4711314115368914

Epoch: 6| Step: 3
Training loss: 2.609885616938451
Validation loss: 2.4684467209867793

Epoch: 6| Step: 4
Training loss: 2.447849700228187
Validation loss: 2.4730874600090726

Epoch: 6| Step: 5
Training loss: 3.018162741710463
Validation loss: 2.4684978790954046

Epoch: 6| Step: 6
Training loss: 2.5576269754788368
Validation loss: 2.472650167368337

Epoch: 6| Step: 7
Training loss: 2.7619121219430456
Validation loss: 2.474844006397224

Epoch: 6| Step: 8
Training loss: 2.3559978643644075
Validation loss: 2.475508151565986

Epoch: 6| Step: 9
Training loss: 2.243109324164792
Validation loss: 2.4677535834832773

Epoch: 6| Step: 10
Training loss: 2.5970985215410716
Validation loss: 2.473034701681175

Epoch: 6| Step: 11
Training loss: 2.563390065504992
Validation loss: 2.474324511817248

Epoch: 6| Step: 12
Training loss: 2.2054529538806773
Validation loss: 2.4701872878942135

Epoch: 6| Step: 13
Training loss: 2.6453772224309144
Validation loss: 2.4748076951811937

Epoch: 93| Step: 0
Training loss: 2.7965172053953147
Validation loss: 2.4724082400552634

Epoch: 6| Step: 1
Training loss: 1.928990411911585
Validation loss: 2.462804403063843

Epoch: 6| Step: 2
Training loss: 3.18164302294262
Validation loss: 2.4688840580206364

Epoch: 6| Step: 3
Training loss: 2.665795710509738
Validation loss: 2.467900761876103

Epoch: 6| Step: 4
Training loss: 1.762523729421619
Validation loss: 2.4614771982816173

Epoch: 6| Step: 5
Training loss: 2.590871845628647
Validation loss: 2.462069006057381

Epoch: 6| Step: 6
Training loss: 2.7617736551959107
Validation loss: 2.4611362195390596

Epoch: 6| Step: 7
Training loss: 2.2949309133798077
Validation loss: 2.470499263992617

Epoch: 6| Step: 8
Training loss: 1.8767010919497518
Validation loss: 2.4695443754522164

Epoch: 6| Step: 9
Training loss: 2.7617601879847387
Validation loss: 2.475282484688965

Epoch: 6| Step: 10
Training loss: 2.6039828934993894
Validation loss: 2.4764581090705002

Epoch: 6| Step: 11
Training loss: 2.9789175894236544
Validation loss: 2.4770163391995332

Epoch: 6| Step: 12
Training loss: 2.5096798418279938
Validation loss: 2.477305496387238

Epoch: 6| Step: 13
Training loss: 2.7579783100716515
Validation loss: 2.471259953773531

Epoch: 94| Step: 0
Training loss: 2.3061192090337426
Validation loss: 2.473469757557327

Epoch: 6| Step: 1
Training loss: 2.215613498846207
Validation loss: 2.472314104832535

Epoch: 6| Step: 2
Training loss: 2.4312597750195124
Validation loss: 2.4676965968984264

Epoch: 6| Step: 3
Training loss: 2.274982988901781
Validation loss: 2.4680333928353626

Epoch: 6| Step: 4
Training loss: 2.9943441482320896
Validation loss: 2.469038258394802

Epoch: 6| Step: 5
Training loss: 2.537046788525101
Validation loss: 2.467114208405992

Epoch: 6| Step: 6
Training loss: 2.416625504855685
Validation loss: 2.4704716148019665

Epoch: 6| Step: 7
Training loss: 3.0065579262613324
Validation loss: 2.4713739220834863

Epoch: 6| Step: 8
Training loss: 2.475316067945762
Validation loss: 2.4661508068019797

Epoch: 6| Step: 9
Training loss: 2.821123001424479
Validation loss: 2.4660213375926743

Epoch: 6| Step: 10
Training loss: 2.4592697062849234
Validation loss: 2.4668866461102095

Epoch: 6| Step: 11
Training loss: 2.15306530608102
Validation loss: 2.468935850849706

Epoch: 6| Step: 12
Training loss: 2.8333668052341774
Validation loss: 2.4669882850353355

Epoch: 6| Step: 13
Training loss: 2.6496925643510782
Validation loss: 2.4620101286542653

Epoch: 95| Step: 0
Training loss: 2.496364047559325
Validation loss: 2.4766308988638484

Epoch: 6| Step: 1
Training loss: 2.2261409962874237
Validation loss: 2.478449899509933

Epoch: 6| Step: 2
Training loss: 2.491870441418246
Validation loss: 2.4846821161294255

Epoch: 6| Step: 3
Training loss: 2.6353091392644936
Validation loss: 2.501889897306194

Epoch: 6| Step: 4
Training loss: 2.721628003130986
Validation loss: 2.5151955453200077

Epoch: 6| Step: 5
Training loss: 2.6920677224833187
Validation loss: 2.5266476300897165

Epoch: 6| Step: 6
Training loss: 2.5062421118405225
Validation loss: 2.5386147285208676

Epoch: 6| Step: 7
Training loss: 2.301453781926863
Validation loss: 2.5199356582541395

Epoch: 6| Step: 8
Training loss: 3.094070263864331
Validation loss: 2.4964571247057052

Epoch: 6| Step: 9
Training loss: 2.820298551487971
Validation loss: 2.4852091350602628

Epoch: 6| Step: 10
Training loss: 3.124103264893271
Validation loss: 2.4764399132137522

Epoch: 6| Step: 11
Training loss: 2.6008030238204083
Validation loss: 2.478630606346761

Epoch: 6| Step: 12
Training loss: 2.515290611267585
Validation loss: 2.4707539308171826

Epoch: 6| Step: 13
Training loss: 2.0001720116078237
Validation loss: 2.4702037764029434

Epoch: 96| Step: 0
Training loss: 2.591420241862381
Validation loss: 2.470183805185364

Epoch: 6| Step: 1
Training loss: 2.2735293654925233
Validation loss: 2.4699344932116793

Epoch: 6| Step: 2
Training loss: 2.9393940764417916
Validation loss: 2.4803225977335113

Epoch: 6| Step: 3
Training loss: 2.623779194648068
Validation loss: 2.4834780163402215

Epoch: 6| Step: 4
Training loss: 2.556658343318569
Validation loss: 2.488799084687563

Epoch: 6| Step: 5
Training loss: 2.441439648209058
Validation loss: 2.4801035374388767

Epoch: 6| Step: 6
Training loss: 2.4055949719111647
Validation loss: 2.4870019136090926

Epoch: 6| Step: 7
Training loss: 2.2348175677574282
Validation loss: 2.484133342769797

Epoch: 6| Step: 8
Training loss: 2.7200170611800125
Validation loss: 2.4834335910690672

Epoch: 6| Step: 9
Training loss: 2.8761947471354765
Validation loss: 2.4732657871979593

Epoch: 6| Step: 10
Training loss: 2.559372086109929
Validation loss: 2.47306183215117

Epoch: 6| Step: 11
Training loss: 2.8941081737872256
Validation loss: 2.4781693260971696

Epoch: 6| Step: 12
Training loss: 2.673179620269944
Validation loss: 2.4736127484864916

Epoch: 6| Step: 13
Training loss: 2.42349090812462
Validation loss: 2.470598695581039

Epoch: 97| Step: 0
Training loss: 2.543901076270862
Validation loss: 2.4665661419755756

Epoch: 6| Step: 1
Training loss: 2.3242869647618316
Validation loss: 2.4664872177249575

Epoch: 6| Step: 2
Training loss: 2.438376440300352
Validation loss: 2.460464092920535

Epoch: 6| Step: 3
Training loss: 2.3502363857122086
Validation loss: 2.460073345584748

Epoch: 6| Step: 4
Training loss: 2.3635030847266627
Validation loss: 2.461654897604435

Epoch: 6| Step: 5
Training loss: 2.8202430103649236
Validation loss: 2.4683064251381133

Epoch: 6| Step: 6
Training loss: 2.5962783256532016
Validation loss: 2.462554529557737

Epoch: 6| Step: 7
Training loss: 2.355448506080089
Validation loss: 2.4657411226454875

Epoch: 6| Step: 8
Training loss: 2.4445585118276516
Validation loss: 2.470623480476847

Epoch: 6| Step: 9
Training loss: 2.5545333209161507
Validation loss: 2.4690531612918583

Epoch: 6| Step: 10
Training loss: 2.7789709633281077
Validation loss: 2.46733078221448

Epoch: 6| Step: 11
Training loss: 3.161417743520753
Validation loss: 2.469276291646009

Epoch: 6| Step: 12
Training loss: 2.259034773033369
Validation loss: 2.460552068328262

Epoch: 6| Step: 13
Training loss: 2.961821170083482
Validation loss: 2.4619677935109543

Epoch: 98| Step: 0
Training loss: 2.5772875726225486
Validation loss: 2.4584330091366327

Epoch: 6| Step: 1
Training loss: 2.536670015393861
Validation loss: 2.459232284496051

Epoch: 6| Step: 2
Training loss: 2.773898835832757
Validation loss: 2.4637148569749887

Epoch: 6| Step: 3
Training loss: 2.7782193076708133
Validation loss: 2.457622188144764

Epoch: 6| Step: 4
Training loss: 2.1687574446932403
Validation loss: 2.4602129157122166

Epoch: 6| Step: 5
Training loss: 2.5819571941795787
Validation loss: 2.460171833717832

Epoch: 6| Step: 6
Training loss: 3.070359401975574
Validation loss: 2.4660598084626613

Epoch: 6| Step: 7
Training loss: 2.080548701538875
Validation loss: 2.4658554104865975

Epoch: 6| Step: 8
Training loss: 3.0915792536823825
Validation loss: 2.469401374224838

Epoch: 6| Step: 9
Training loss: 2.24959327412464
Validation loss: 2.4668700226736036

Epoch: 6| Step: 10
Training loss: 2.507006173916348
Validation loss: 2.471852425505532

Epoch: 6| Step: 11
Training loss: 2.4674295684749588
Validation loss: 2.4657648444153204

Epoch: 6| Step: 12
Training loss: 2.5219366848384563
Validation loss: 2.464831659012292

Epoch: 6| Step: 13
Training loss: 2.467608030789275
Validation loss: 2.463954823684633

Epoch: 99| Step: 0
Training loss: 2.8755005110566256
Validation loss: 2.465124453819731

Epoch: 6| Step: 1
Training loss: 3.0855576679810284
Validation loss: 2.4666588936717617

Epoch: 6| Step: 2
Training loss: 2.338015853345132
Validation loss: 2.4660860891601226

Epoch: 6| Step: 3
Training loss: 2.230516957632224
Validation loss: 2.463155177138919

Epoch: 6| Step: 4
Training loss: 2.815808279018775
Validation loss: 2.464282181936698

Epoch: 6| Step: 5
Training loss: 2.8212243294213497
Validation loss: 2.4643987464518538

Epoch: 6| Step: 6
Training loss: 1.866587267049868
Validation loss: 2.462957725649465

Epoch: 6| Step: 7
Training loss: 2.9808203813504135
Validation loss: 2.4637997084166914

Epoch: 6| Step: 8
Training loss: 2.22106275775016
Validation loss: 2.4643097393241624

Epoch: 6| Step: 9
Training loss: 2.2308316177781466
Validation loss: 2.462380501870068

Epoch: 6| Step: 10
Training loss: 2.6171832184258355
Validation loss: 2.462684164890042

Epoch: 6| Step: 11
Training loss: 2.7235972722560193
Validation loss: 2.464914658418716

Epoch: 6| Step: 12
Training loss: 2.3521834152549084
Validation loss: 2.466462520150404

Epoch: 6| Step: 13
Training loss: 2.392377921311281
Validation loss: 2.4655420409453876

Epoch: 100| Step: 0
Training loss: 2.3246189830685955
Validation loss: 2.465276116981007

Epoch: 6| Step: 1
Training loss: 2.3586760237130635
Validation loss: 2.4641052526209304

Epoch: 6| Step: 2
Training loss: 2.2379378076933945
Validation loss: 2.460483052916349

Epoch: 6| Step: 3
Training loss: 2.8851261107386144
Validation loss: 2.460670577817234

Epoch: 6| Step: 4
Training loss: 1.889906439307173
Validation loss: 2.458759987440254

Epoch: 6| Step: 5
Training loss: 2.846332425484976
Validation loss: 2.4534844137230127

Epoch: 6| Step: 6
Training loss: 2.544387163973213
Validation loss: 2.4582188843632586

Epoch: 6| Step: 7
Training loss: 2.776176883536797
Validation loss: 2.4526425107846657

Epoch: 6| Step: 8
Training loss: 2.9848407162288115
Validation loss: 2.4558114408516762

Epoch: 6| Step: 9
Training loss: 3.1032636382911836
Validation loss: 2.458980674427774

Epoch: 6| Step: 10
Training loss: 1.8201540767510325
Validation loss: 2.4554407645514127

Epoch: 6| Step: 11
Training loss: 2.4047759854679196
Validation loss: 2.4512372376743397

Epoch: 6| Step: 12
Training loss: 2.667424650549181
Validation loss: 2.457231312315533

Epoch: 6| Step: 13
Training loss: 2.7016119277871526
Validation loss: 2.4555712204453166

Epoch: 101| Step: 0
Training loss: 2.327227323398062
Validation loss: 2.460830847634174

Epoch: 6| Step: 1
Training loss: 2.407592795099828
Validation loss: 2.4640838048026406

Epoch: 6| Step: 2
Training loss: 2.530001296996738
Validation loss: 2.465276729482031

Epoch: 6| Step: 3
Training loss: 2.563375370026538
Validation loss: 2.4653929568563546

Epoch: 6| Step: 4
Training loss: 2.6421784114850526
Validation loss: 2.470344865278489

Epoch: 6| Step: 5
Training loss: 2.6387313282647997
Validation loss: 2.4669693911431407

Epoch: 6| Step: 6
Training loss: 3.0106780434802625
Validation loss: 2.4671334716344244

Epoch: 6| Step: 7
Training loss: 2.7301667009536867
Validation loss: 2.4670667583740102

Epoch: 6| Step: 8
Training loss: 2.0682962063949386
Validation loss: 2.465179662289242

Epoch: 6| Step: 9
Training loss: 2.485984233078862
Validation loss: 2.4687683169172314

Epoch: 6| Step: 10
Training loss: 2.714762602766563
Validation loss: 2.469455183692621

Epoch: 6| Step: 11
Training loss: 2.9726565708155213
Validation loss: 2.467683143106058

Epoch: 6| Step: 12
Training loss: 2.2334650494274944
Validation loss: 2.4706038745350405

Epoch: 6| Step: 13
Training loss: 2.320026007539394
Validation loss: 2.4702970429881317

Epoch: 102| Step: 0
Training loss: 2.493284169526652
Validation loss: 2.4694926275676305

Epoch: 6| Step: 1
Training loss: 2.67857333228634
Validation loss: 2.46596029054269

Epoch: 6| Step: 2
Training loss: 2.4054136928441068
Validation loss: 2.470704974549497

Epoch: 6| Step: 3
Training loss: 2.490188514436781
Validation loss: 2.4657037023788573

Epoch: 6| Step: 4
Training loss: 2.9429572526197303
Validation loss: 2.4665357905111778

Epoch: 6| Step: 5
Training loss: 2.436468444081291
Validation loss: 2.464865271811375

Epoch: 6| Step: 6
Training loss: 2.4161403565215553
Validation loss: 2.45921567395133

Epoch: 6| Step: 7
Training loss: 2.92472643102737
Validation loss: 2.4630825483227086

Epoch: 6| Step: 8
Training loss: 2.8065691828013684
Validation loss: 2.463133495193231

Epoch: 6| Step: 9
Training loss: 2.1802579618644757
Validation loss: 2.45865025875098

Epoch: 6| Step: 10
Training loss: 2.4274680251619367
Validation loss: 2.4677693072980005

Epoch: 6| Step: 11
Training loss: 2.1703481452931332
Validation loss: 2.4600951352629172

Epoch: 6| Step: 12
Training loss: 2.661685901525367
Validation loss: 2.4606573036172117

Epoch: 6| Step: 13
Training loss: 2.456273287985479
Validation loss: 2.4553648812308304

Epoch: 103| Step: 0
Training loss: 2.9999453221742485
Validation loss: 2.456976424486441

Epoch: 6| Step: 1
Training loss: 2.6696670064549255
Validation loss: 2.4554531768910226

Epoch: 6| Step: 2
Training loss: 2.2919495379100674
Validation loss: 2.4574530097502194

Epoch: 6| Step: 3
Training loss: 2.6382169860839007
Validation loss: 2.458109915543425

Epoch: 6| Step: 4
Training loss: 2.7794523108546816
Validation loss: 2.453383478692253

Epoch: 6| Step: 5
Training loss: 2.7146258589213654
Validation loss: 2.4561135297012338

Epoch: 6| Step: 6
Training loss: 2.0492432849155526
Validation loss: 2.460454822818294

Epoch: 6| Step: 7
Training loss: 2.31256041576749
Validation loss: 2.461318673783322

Epoch: 6| Step: 8
Training loss: 2.6088959031369074
Validation loss: 2.4595156321211364

Epoch: 6| Step: 9
Training loss: 2.38460515862537
Validation loss: 2.4587952266115565

Epoch: 6| Step: 10
Training loss: 2.351722990623616
Validation loss: 2.4539068964297774

Epoch: 6| Step: 11
Training loss: 2.4389123981629774
Validation loss: 2.454085710633452

Epoch: 6| Step: 12
Training loss: 2.41305600020002
Validation loss: 2.4553143395990755

Epoch: 6| Step: 13
Training loss: 2.889877965125917
Validation loss: 2.4504846184406115

Epoch: 104| Step: 0
Training loss: 2.437258097064766
Validation loss: 2.443251109602401

Epoch: 6| Step: 1
Training loss: 2.846016117181667
Validation loss: 2.448148210545497

Epoch: 6| Step: 2
Training loss: 2.476926758750224
Validation loss: 2.4514996921135315

Epoch: 6| Step: 3
Training loss: 2.371987188648795
Validation loss: 2.443593291244335

Epoch: 6| Step: 4
Training loss: 2.7888402342721106
Validation loss: 2.4482846788315857

Epoch: 6| Step: 5
Training loss: 2.4225968792482298
Validation loss: 2.441213110849984

Epoch: 6| Step: 6
Training loss: 1.623579431374674
Validation loss: 2.4436141221043064

Epoch: 6| Step: 7
Training loss: 3.1044628505514607
Validation loss: 2.4499262792174505

Epoch: 6| Step: 8
Training loss: 2.6486485940083173
Validation loss: 2.462037098165816

Epoch: 6| Step: 9
Training loss: 2.7106952833862676
Validation loss: 2.4480159225361584

Epoch: 6| Step: 10
Training loss: 2.6950174805989002
Validation loss: 2.45607573624699

Epoch: 6| Step: 11
Training loss: 2.7419824768107484
Validation loss: 2.4569213228040447

Epoch: 6| Step: 12
Training loss: 2.2888929284727793
Validation loss: 2.457898438235138

Epoch: 6| Step: 13
Training loss: 2.33451631621286
Validation loss: 2.4531389304897395

Epoch: 105| Step: 0
Training loss: 2.3452056433461266
Validation loss: 2.45366507252553

Epoch: 6| Step: 1
Training loss: 2.88453883142861
Validation loss: 2.456039010030108

Epoch: 6| Step: 2
Training loss: 3.1186532229160533
Validation loss: 2.450731717696371

Epoch: 6| Step: 3
Training loss: 3.0084326166763367
Validation loss: 2.447019036390855

Epoch: 6| Step: 4
Training loss: 1.990396929121255
Validation loss: 2.4507906552718897

Epoch: 6| Step: 5
Training loss: 1.9801929289332187
Validation loss: 2.4549132549449904

Epoch: 6| Step: 6
Training loss: 2.4744186026751107
Validation loss: 2.4494232708858994

Epoch: 6| Step: 7
Training loss: 2.67551785028841
Validation loss: 2.448673355891896

Epoch: 6| Step: 8
Training loss: 2.1237465022407993
Validation loss: 2.4518690599558703

Epoch: 6| Step: 9
Training loss: 2.578860276305607
Validation loss: 2.4484085292274766

Epoch: 6| Step: 10
Training loss: 2.337284580034885
Validation loss: 2.445341961147947

Epoch: 6| Step: 11
Training loss: 2.365440000609691
Validation loss: 2.4412377871565814

Epoch: 6| Step: 12
Training loss: 2.521783623345757
Validation loss: 2.448450384732969

Epoch: 6| Step: 13
Training loss: 2.785434618035853
Validation loss: 2.4532166968051894

Epoch: 106| Step: 0
Training loss: 2.7273020793317873
Validation loss: 2.4401166027380508

Epoch: 6| Step: 1
Training loss: 2.4607883953155696
Validation loss: 2.4511539939846223

Epoch: 6| Step: 2
Training loss: 3.1432249021251017
Validation loss: 2.448495452850671

Epoch: 6| Step: 3
Training loss: 2.6071385833346876
Validation loss: 2.4535370498885443

Epoch: 6| Step: 4
Training loss: 2.745792464635683
Validation loss: 2.4477887681596098

Epoch: 6| Step: 5
Training loss: 2.186292042314363
Validation loss: 2.4412033525715273

Epoch: 6| Step: 6
Training loss: 2.8015476173222584
Validation loss: 2.451333106261488

Epoch: 6| Step: 7
Training loss: 2.2394532868235375
Validation loss: 2.4463154256469917

Epoch: 6| Step: 8
Training loss: 2.4041300761470183
Validation loss: 2.4432834417272282

Epoch: 6| Step: 9
Training loss: 2.551115098869642
Validation loss: 2.441015846064006

Epoch: 6| Step: 10
Training loss: 2.0695860541904176
Validation loss: 2.452031436480098

Epoch: 6| Step: 11
Training loss: 2.753386319907552
Validation loss: 2.4502519601248984

Epoch: 6| Step: 12
Training loss: 2.48181519497067
Validation loss: 2.4451908166609027

Epoch: 6| Step: 13
Training loss: 2.2475920613987963
Validation loss: 2.450264301446303

Epoch: 107| Step: 0
Training loss: 2.467366857212127
Validation loss: 2.4578893767093892

Epoch: 6| Step: 1
Training loss: 2.5118934012956555
Validation loss: 2.4612898155596743

Epoch: 6| Step: 2
Training loss: 2.5421898933872993
Validation loss: 2.465269685711064

Epoch: 6| Step: 3
Training loss: 2.294173539891901
Validation loss: 2.461636043488105

Epoch: 6| Step: 4
Training loss: 2.1277823465008847
Validation loss: 2.4653000044081907

Epoch: 6| Step: 5
Training loss: 2.980436112411406
Validation loss: 2.462678130237615

Epoch: 6| Step: 6
Training loss: 2.4083123224875265
Validation loss: 2.467191856336945

Epoch: 6| Step: 7
Training loss: 3.219123003929597
Validation loss: 2.4644693371379645

Epoch: 6| Step: 8
Training loss: 2.2098491672464844
Validation loss: 2.46682514527855

Epoch: 6| Step: 9
Training loss: 2.278526875615118
Validation loss: 2.4674376367574586

Epoch: 6| Step: 10
Training loss: 2.273510279588382
Validation loss: 2.465407640024689

Epoch: 6| Step: 11
Training loss: 2.6238640643474325
Validation loss: 2.45685530266556

Epoch: 6| Step: 12
Training loss: 2.8052574152476635
Validation loss: 2.447702363285329

Epoch: 6| Step: 13
Training loss: 2.6170769056040735
Validation loss: 2.4511565067371808

Epoch: 108| Step: 0
Training loss: 2.8850819821667533
Validation loss: 2.440176912171285

Epoch: 6| Step: 1
Training loss: 2.2332480196054205
Validation loss: 2.4433411400081755

Epoch: 6| Step: 2
Training loss: 2.091828104706769
Validation loss: 2.441939354230711

Epoch: 6| Step: 3
Training loss: 2.201781383974663
Validation loss: 2.4454837369428106

Epoch: 6| Step: 4
Training loss: 2.7173632011618927
Validation loss: 2.4465470777574407

Epoch: 6| Step: 5
Training loss: 2.7096216707676826
Validation loss: 2.4428938176401207

Epoch: 6| Step: 6
Training loss: 2.5275783518372905
Validation loss: 2.4499062643479625

Epoch: 6| Step: 7
Training loss: 2.981085277301203
Validation loss: 2.448671221943409

Epoch: 6| Step: 8
Training loss: 2.0950038059536906
Validation loss: 2.4493953351170106

Epoch: 6| Step: 9
Training loss: 2.8133282607456174
Validation loss: 2.4519609900986468

Epoch: 6| Step: 10
Training loss: 2.1209743740147005
Validation loss: 2.4466142206088546

Epoch: 6| Step: 11
Training loss: 2.728163022609864
Validation loss: 2.455540692623414

Epoch: 6| Step: 12
Training loss: 2.6094424301846084
Validation loss: 2.4528672878694486

Epoch: 6| Step: 13
Training loss: 2.664011845708406
Validation loss: 2.442461604581521

Epoch: 109| Step: 0
Training loss: 2.067738210108328
Validation loss: 2.446059384100031

Epoch: 6| Step: 1
Training loss: 2.0966588780188222
Validation loss: 2.44910065175072

Epoch: 6| Step: 2
Training loss: 2.612928152819996
Validation loss: 2.4419400946288214

Epoch: 6| Step: 3
Training loss: 2.476118463125829
Validation loss: 2.442670278245985

Epoch: 6| Step: 4
Training loss: 2.6870282668460774
Validation loss: 2.4425510011500258

Epoch: 6| Step: 5
Training loss: 2.232747585669064
Validation loss: 2.446072331394353

Epoch: 6| Step: 6
Training loss: 1.6906953863979763
Validation loss: 2.442296826499984

Epoch: 6| Step: 7
Training loss: 2.934678366095126
Validation loss: 2.451424351388566

Epoch: 6| Step: 8
Training loss: 1.8974667174545266
Validation loss: 2.442956994474401

Epoch: 6| Step: 9
Training loss: 2.2152964618762576
Validation loss: 2.4539086452870387

Epoch: 6| Step: 10
Training loss: 2.681091830338894
Validation loss: 2.4574340425464083

Epoch: 6| Step: 11
Training loss: 3.0629552386055483
Validation loss: 2.453163422042692

Epoch: 6| Step: 12
Training loss: 3.1360154366989117
Validation loss: 2.4547364759183044

Epoch: 6| Step: 13
Training loss: 3.0847147003758457
Validation loss: 2.4567769964703023

Epoch: 110| Step: 0
Training loss: 2.686678028824147
Validation loss: 2.4489544772030287

Epoch: 6| Step: 1
Training loss: 2.4841053174554513
Validation loss: 2.4591300341485565

Epoch: 6| Step: 2
Training loss: 2.6265899747538244
Validation loss: 2.448044060713134

Epoch: 6| Step: 3
Training loss: 2.9464106043148077
Validation loss: 2.450578449043549

Epoch: 6| Step: 4
Training loss: 2.298044853981189
Validation loss: 2.4479354587131223

Epoch: 6| Step: 5
Training loss: 2.8026084738708152
Validation loss: 2.4551621743611847

Epoch: 6| Step: 6
Training loss: 2.037010709836481
Validation loss: 2.4539774650693507

Epoch: 6| Step: 7
Training loss: 2.6961916167084246
Validation loss: 2.4612233152374996

Epoch: 6| Step: 8
Training loss: 2.2976332470398386
Validation loss: 2.461909252637689

Epoch: 6| Step: 9
Training loss: 2.7712039173856184
Validation loss: 2.4603802246788695

Epoch: 6| Step: 10
Training loss: 2.4910923575573456
Validation loss: 2.459321103763687

Epoch: 6| Step: 11
Training loss: 2.7901643345060885
Validation loss: 2.459955235386694

Epoch: 6| Step: 12
Training loss: 2.1341367529942774
Validation loss: 2.461857473390599

Epoch: 6| Step: 13
Training loss: 2.172989922736685
Validation loss: 2.4509894436126825

Epoch: 111| Step: 0
Training loss: 2.621650375183019
Validation loss: 2.448379267276174

Epoch: 6| Step: 1
Training loss: 2.330493106644426
Validation loss: 2.4539719109796914

Epoch: 6| Step: 2
Training loss: 2.5282209191910727
Validation loss: 2.456242825511391

Epoch: 6| Step: 3
Training loss: 2.9511988579900637
Validation loss: 2.4447346289902057

Epoch: 6| Step: 4
Training loss: 2.4198892635829745
Validation loss: 2.4506750487321556

Epoch: 6| Step: 5
Training loss: 2.8401207874025594
Validation loss: 2.4465537856287827

Epoch: 6| Step: 6
Training loss: 2.67605264220184
Validation loss: 2.4494356082712563

Epoch: 6| Step: 7
Training loss: 3.2011450626165106
Validation loss: 2.450540789132071

Epoch: 6| Step: 8
Training loss: 2.6597638393916574
Validation loss: 2.456311418122977

Epoch: 6| Step: 9
Training loss: 2.010052333359263
Validation loss: 2.4624820766668076

Epoch: 6| Step: 10
Training loss: 1.9661482922536535
Validation loss: 2.457574352731985

Epoch: 6| Step: 11
Training loss: 1.9390611204377584
Validation loss: 2.4628262492515964

Epoch: 6| Step: 12
Training loss: 2.5327588517510007
Validation loss: 2.4492939963334033

Epoch: 6| Step: 13
Training loss: 2.596132218577839
Validation loss: 2.453599377746159

Epoch: 112| Step: 0
Training loss: 2.1950787728671144
Validation loss: 2.4488141842671096

Epoch: 6| Step: 1
Training loss: 2.3867437233375335
Validation loss: 2.456582752689902

Epoch: 6| Step: 2
Training loss: 2.138069911181315
Validation loss: 2.469702492633466

Epoch: 6| Step: 3
Training loss: 2.652409997935775
Validation loss: 2.4650390434784

Epoch: 6| Step: 4
Training loss: 2.6593686813118054
Validation loss: 2.4655354653183132

Epoch: 6| Step: 5
Training loss: 2.5506851622167974
Validation loss: 2.4672032432061917

Epoch: 6| Step: 6
Training loss: 2.182739309013626
Validation loss: 2.465216687539502

Epoch: 6| Step: 7
Training loss: 2.462630401101968
Validation loss: 2.4615839194989473

Epoch: 6| Step: 8
Training loss: 3.220064061635289
Validation loss: 2.462237512247044

Epoch: 6| Step: 9
Training loss: 2.098857514363609
Validation loss: 2.4642737485728063

Epoch: 6| Step: 10
Training loss: 2.866264672888536
Validation loss: 2.46519760276075

Epoch: 6| Step: 11
Training loss: 3.0295279419046874
Validation loss: 2.4709074033942837

Epoch: 6| Step: 12
Training loss: 2.0244174778748927
Validation loss: 2.459900668886111

Epoch: 6| Step: 13
Training loss: 2.557442116180209
Validation loss: 2.4549258965614484

Epoch: 113| Step: 0
Training loss: 2.3620265183474265
Validation loss: 2.463101399432928

Epoch: 6| Step: 1
Training loss: 2.723649094328799
Validation loss: 2.4620083532721053

Epoch: 6| Step: 2
Training loss: 2.3799541401652156
Validation loss: 2.458925019735344

Epoch: 6| Step: 3
Training loss: 2.9323189679371717
Validation loss: 2.4546223664783526

Epoch: 6| Step: 4
Training loss: 2.9696806402648037
Validation loss: 2.4541461058588134

Epoch: 6| Step: 5
Training loss: 2.146702402164933
Validation loss: 2.4539804121322284

Epoch: 6| Step: 6
Training loss: 2.875375971881815
Validation loss: 2.4513015611443283

Epoch: 6| Step: 7
Training loss: 2.328782059289617
Validation loss: 2.448000534460637

Epoch: 6| Step: 8
Training loss: 2.5294439206773416
Validation loss: 2.4437666974550107

Epoch: 6| Step: 9
Training loss: 2.134667787814079
Validation loss: 2.44403879877085

Epoch: 6| Step: 10
Training loss: 2.3297989734816045
Validation loss: 2.4551750736522076

Epoch: 6| Step: 11
Training loss: 3.006225960173421
Validation loss: 2.449966851808163

Epoch: 6| Step: 12
Training loss: 2.0015257737470264
Validation loss: 2.449378122501471

Epoch: 6| Step: 13
Training loss: 2.2779462746839925
Validation loss: 2.451786169964246

Epoch: 114| Step: 0
Training loss: 2.8701293155898058
Validation loss: 2.451191360781197

Epoch: 6| Step: 1
Training loss: 2.6624898883466384
Validation loss: 2.453644586113521

Epoch: 6| Step: 2
Training loss: 2.13731986731279
Validation loss: 2.439154902713177

Epoch: 6| Step: 3
Training loss: 2.5928133456792115
Validation loss: 2.45201989812696

Epoch: 6| Step: 4
Training loss: 2.33858235641684
Validation loss: 2.4562031088665317

Epoch: 6| Step: 5
Training loss: 2.680707642803766
Validation loss: 2.4419045959480856

Epoch: 6| Step: 6
Training loss: 2.1662278342282364
Validation loss: 2.454307659829156

Epoch: 6| Step: 7
Training loss: 2.621505045564181
Validation loss: 2.4384793816365447

Epoch: 6| Step: 8
Training loss: 2.887793726658303
Validation loss: 2.443143677027328

Epoch: 6| Step: 9
Training loss: 2.7970546046720886
Validation loss: 2.4550824950550307

Epoch: 6| Step: 10
Training loss: 2.4018188895650487
Validation loss: 2.4550711814521193

Epoch: 6| Step: 11
Training loss: 1.8155866188811813
Validation loss: 2.4580755718249327

Epoch: 6| Step: 12
Training loss: 2.9533248914450154
Validation loss: 2.4627815885959183

Epoch: 6| Step: 13
Training loss: 2.3687826390898894
Validation loss: 2.466137207617708

Epoch: 115| Step: 0
Training loss: 2.3347081039922672
Validation loss: 2.4708822997088893

Epoch: 6| Step: 1
Training loss: 2.3974810255650274
Validation loss: 2.4605574056978674

Epoch: 6| Step: 2
Training loss: 2.3532260827470437
Validation loss: 2.4560218277964614

Epoch: 6| Step: 3
Training loss: 2.7296083592786613
Validation loss: 2.462283393124488

Epoch: 6| Step: 4
Training loss: 2.8906124630217995
Validation loss: 2.463099382846942

Epoch: 6| Step: 5
Training loss: 2.7363174950163796
Validation loss: 2.4657174006474363

Epoch: 6| Step: 6
Training loss: 2.4875063565426987
Validation loss: 2.4625890125123413

Epoch: 6| Step: 7
Training loss: 2.2918735988707324
Validation loss: 2.456818038188244

Epoch: 6| Step: 8
Training loss: 2.6632748331544875
Validation loss: 2.455176627389087

Epoch: 6| Step: 9
Training loss: 2.9443234672725143
Validation loss: 2.4482295113717094

Epoch: 6| Step: 10
Training loss: 2.4824830534664866
Validation loss: 2.451639961038445

Epoch: 6| Step: 11
Training loss: 2.128847565848284
Validation loss: 2.456972656198247

Epoch: 6| Step: 12
Training loss: 2.7329362844499836
Validation loss: 2.454692469380782

Epoch: 6| Step: 13
Training loss: 2.0360763724941426
Validation loss: 2.456604379224892

Epoch: 116| Step: 0
Training loss: 2.6322982693403065
Validation loss: 2.4484561785561807

Epoch: 6| Step: 1
Training loss: 2.7256840818387698
Validation loss: 2.4525446924200316

Epoch: 6| Step: 2
Training loss: 2.398842246233473
Validation loss: 2.4501933015095707

Epoch: 6| Step: 3
Training loss: 2.3704712504647225
Validation loss: 2.4474457037478032

Epoch: 6| Step: 4
Training loss: 2.637172812466043
Validation loss: 2.447725383238005

Epoch: 6| Step: 5
Training loss: 2.4986134498768546
Validation loss: 2.4527150194206624

Epoch: 6| Step: 6
Training loss: 2.534935422898698
Validation loss: 2.4475095748584192

Epoch: 6| Step: 7
Training loss: 2.868080935444169
Validation loss: 2.4511329191843423

Epoch: 6| Step: 8
Training loss: 2.0752147287694616
Validation loss: 2.456535996990993

Epoch: 6| Step: 9
Training loss: 2.1954052454135558
Validation loss: 2.4478553980741964

Epoch: 6| Step: 10
Training loss: 2.274436075932005
Validation loss: 2.459444099499297

Epoch: 6| Step: 11
Training loss: 2.216029473793872
Validation loss: 2.4599835035241355

Epoch: 6| Step: 12
Training loss: 2.591648215405036
Validation loss: 2.4653089097494476

Epoch: 6| Step: 13
Training loss: 3.0567864818934
Validation loss: 2.4547367592022695

Epoch: 117| Step: 0
Training loss: 2.40658358949189
Validation loss: 2.4583985002145474

Epoch: 6| Step: 1
Training loss: 2.7799575888877164
Validation loss: 2.460717440661209

Epoch: 6| Step: 2
Training loss: 2.690243939254906
Validation loss: 2.4585448082520576

Epoch: 6| Step: 3
Training loss: 2.3782781764662775
Validation loss: 2.4580492458961123

Epoch: 6| Step: 4
Training loss: 2.2655140816733526
Validation loss: 2.451909576089244

Epoch: 6| Step: 5
Training loss: 2.7699505444184687
Validation loss: 2.45676461508048

Epoch: 6| Step: 6
Training loss: 2.4951065809767226
Validation loss: 2.454820682660951

Epoch: 6| Step: 7
Training loss: 2.459360737741067
Validation loss: 2.448919412835577

Epoch: 6| Step: 8
Training loss: 2.8929592296207782
Validation loss: 2.4460328882314015

Epoch: 6| Step: 9
Training loss: 1.9374152749518048
Validation loss: 2.4457178480664465

Epoch: 6| Step: 10
Training loss: 2.442651928302634
Validation loss: 2.4449715341056373

Epoch: 6| Step: 11
Training loss: 2.1552668002276594
Validation loss: 2.4404352724098675

Epoch: 6| Step: 12
Training loss: 2.975444754045183
Validation loss: 2.448416335601315

Epoch: 6| Step: 13
Training loss: 2.4602718361249014
Validation loss: 2.4455043567147317

Epoch: 118| Step: 0
Training loss: 2.4177277526557686
Validation loss: 2.4482336988835773

Epoch: 6| Step: 1
Training loss: 2.517544600424094
Validation loss: 2.4440384817298795

Epoch: 6| Step: 2
Training loss: 1.9038255000531719
Validation loss: 2.440418224554578

Epoch: 6| Step: 3
Training loss: 2.2061415778040896
Validation loss: 2.447037548448999

Epoch: 6| Step: 4
Training loss: 2.685214645643113
Validation loss: 2.4481673633090457

Epoch: 6| Step: 5
Training loss: 2.077647563040882
Validation loss: 2.4538894563683433

Epoch: 6| Step: 6
Training loss: 3.202038389911006
Validation loss: 2.439088026976611

Epoch: 6| Step: 7
Training loss: 2.5807866084650657
Validation loss: 2.4568687187094476

Epoch: 6| Step: 8
Training loss: 2.6940072700158844
Validation loss: 2.452347472253757

Epoch: 6| Step: 9
Training loss: 2.530161305588994
Validation loss: 2.457129722607107

Epoch: 6| Step: 10
Training loss: 2.19307999772097
Validation loss: 2.465879582363173

Epoch: 6| Step: 11
Training loss: 2.64651644641545
Validation loss: 2.454709604262124

Epoch: 6| Step: 12
Training loss: 2.240968592221507
Validation loss: 2.4577039516412396

Epoch: 6| Step: 13
Training loss: 2.920677714934354
Validation loss: 2.460490756382278

Epoch: 119| Step: 0
Training loss: 2.5419990343081533
Validation loss: 2.4559620126236394

Epoch: 6| Step: 1
Training loss: 2.598139254760546
Validation loss: 2.4599817428324897

Epoch: 6| Step: 2
Training loss: 2.475078535278899
Validation loss: 2.4558007292907265

Epoch: 6| Step: 3
Training loss: 2.863226459390082
Validation loss: 2.453436675793322

Epoch: 6| Step: 4
Training loss: 2.3791652093761497
Validation loss: 2.447099384203475

Epoch: 6| Step: 5
Training loss: 2.3143706101786172
Validation loss: 2.454831600836165

Epoch: 6| Step: 6
Training loss: 2.529288014282259
Validation loss: 2.447537499680511

Epoch: 6| Step: 7
Training loss: 1.91641638683526
Validation loss: 2.4461898529788133

Epoch: 6| Step: 8
Training loss: 1.9194365127529636
Validation loss: 2.452429200970687

Epoch: 6| Step: 9
Training loss: 3.055719459838604
Validation loss: 2.439027454385926

Epoch: 6| Step: 10
Training loss: 2.294510435192447
Validation loss: 2.4465707744894227

Epoch: 6| Step: 11
Training loss: 2.4494693025626546
Validation loss: 2.4444198197752485

Epoch: 6| Step: 12
Training loss: 3.4154535946849416
Validation loss: 2.44385879417521

Epoch: 6| Step: 13
Training loss: 1.9971839629947605
Validation loss: 2.44634521582362

Epoch: 120| Step: 0
Training loss: 2.262454214739274
Validation loss: 2.4474288346124284

Epoch: 6| Step: 1
Training loss: 1.8549850315199543
Validation loss: 2.4424846088519283

Epoch: 6| Step: 2
Training loss: 3.1079079699152756
Validation loss: 2.4475752788600493

Epoch: 6| Step: 3
Training loss: 2.9392788958954617
Validation loss: 2.4423068488651194

Epoch: 6| Step: 4
Training loss: 3.0000282922046453
Validation loss: 2.4481626725189467

Epoch: 6| Step: 5
Training loss: 2.562513025762435
Validation loss: 2.455416732659483

Epoch: 6| Step: 6
Training loss: 2.2264658053633775
Validation loss: 2.4547006523739916

Epoch: 6| Step: 7
Training loss: 2.9198072328038025
Validation loss: 2.457444835922026

Epoch: 6| Step: 8
Training loss: 2.484683035701502
Validation loss: 2.451579309571605

Epoch: 6| Step: 9
Training loss: 2.4593318484639566
Validation loss: 2.4496970472714668

Epoch: 6| Step: 10
Training loss: 2.5881981317891745
Validation loss: 2.4532263506061045

Epoch: 6| Step: 11
Training loss: 1.9142818403103148
Validation loss: 2.4459631463542038

Epoch: 6| Step: 12
Training loss: 2.3994673217277938
Validation loss: 2.440800209610771

Epoch: 6| Step: 13
Training loss: 2.1300263144430227
Validation loss: 2.4528920737316118

Epoch: 121| Step: 0
Training loss: 2.2923502047155817
Validation loss: 2.44989734356739

Epoch: 6| Step: 1
Training loss: 2.1051798606380374
Validation loss: 2.436649141400827

Epoch: 6| Step: 2
Training loss: 2.405985731004877
Validation loss: 2.447023364002955

Epoch: 6| Step: 3
Training loss: 2.3245160081049208
Validation loss: 2.441943707117482

Epoch: 6| Step: 4
Training loss: 2.25794259194851
Validation loss: 2.4458655482504157

Epoch: 6| Step: 5
Training loss: 2.886476251020451
Validation loss: 2.4487649516463312

Epoch: 6| Step: 6
Training loss: 2.6474440070004572
Validation loss: 2.447027691607402

Epoch: 6| Step: 7
Training loss: 2.347473746773491
Validation loss: 2.4592962695926004

Epoch: 6| Step: 8
Training loss: 2.702236051417749
Validation loss: 2.455211440548221

Epoch: 6| Step: 9
Training loss: 1.9616119319223058
Validation loss: 2.453529033068537

Epoch: 6| Step: 10
Training loss: 2.4915359267144606
Validation loss: 2.4407646292301735

Epoch: 6| Step: 11
Training loss: 3.026856532114368
Validation loss: 2.4433495846355777

Epoch: 6| Step: 12
Training loss: 3.009869553283531
Validation loss: 2.449379168889186

Epoch: 6| Step: 13
Training loss: 2.5295768199927493
Validation loss: 2.4415879652426247

Epoch: 122| Step: 0
Training loss: 2.2970881979471205
Validation loss: 2.4437874455359547

Epoch: 6| Step: 1
Training loss: 2.1043360676575715
Validation loss: 2.4565787735161293

Epoch: 6| Step: 2
Training loss: 2.638544470635837
Validation loss: 2.451976385730958

Epoch: 6| Step: 3
Training loss: 3.003945458284024
Validation loss: 2.449962772683411

Epoch: 6| Step: 4
Training loss: 2.65264135834358
Validation loss: 2.4471478871537276

Epoch: 6| Step: 5
Training loss: 2.3031843035450272
Validation loss: 2.4487070038756102

Epoch: 6| Step: 6
Training loss: 2.436319505493711
Validation loss: 2.4462249321060057

Epoch: 6| Step: 7
Training loss: 2.5234121787864643
Validation loss: 2.450292389478272

Epoch: 6| Step: 8
Training loss: 2.745350114350847
Validation loss: 2.454273659576433

Epoch: 6| Step: 9
Training loss: 2.1375296830464228
Validation loss: 2.4585397170337395

Epoch: 6| Step: 10
Training loss: 2.27460263732929
Validation loss: 2.4529254451504126

Epoch: 6| Step: 11
Training loss: 2.1890886260276807
Validation loss: 2.4542430913280744

Epoch: 6| Step: 12
Training loss: 2.597905334921083
Validation loss: 2.450182176161727

Epoch: 6| Step: 13
Training loss: 2.951648807424936
Validation loss: 2.4543622697254452

Epoch: 123| Step: 0
Training loss: 2.297601079035216
Validation loss: 2.4551827937726345

Epoch: 6| Step: 1
Training loss: 2.904016436317526
Validation loss: 2.457628542415497

Epoch: 6| Step: 2
Training loss: 2.249602494624235
Validation loss: 2.456447432900951

Epoch: 6| Step: 3
Training loss: 2.669558228938884
Validation loss: 2.451536688943285

Epoch: 6| Step: 4
Training loss: 2.2721243405368163
Validation loss: 2.4539415413837697

Epoch: 6| Step: 5
Training loss: 2.863809617486386
Validation loss: 2.450550615627641

Epoch: 6| Step: 6
Training loss: 2.9433750893844777
Validation loss: 2.457482066640425

Epoch: 6| Step: 7
Training loss: 2.1297119855697604
Validation loss: 2.4530993255761935

Epoch: 6| Step: 8
Training loss: 2.2753577234075117
Validation loss: 2.446730408795332

Epoch: 6| Step: 9
Training loss: 2.820943492351847
Validation loss: 2.4527837592897193

Epoch: 6| Step: 10
Training loss: 2.9043595923582934
Validation loss: 2.446676814147459

Epoch: 6| Step: 11
Training loss: 2.3676801615788774
Validation loss: 2.4466310303957286

Epoch: 6| Step: 12
Training loss: 2.0003243421774055
Validation loss: 2.4457258661197154

Epoch: 6| Step: 13
Training loss: 1.9870053377506955
Validation loss: 2.4490210510643045

Epoch: 124| Step: 0
Training loss: 1.8642695782761247
Validation loss: 2.4527817990231795

Epoch: 6| Step: 1
Training loss: 2.476782852141337
Validation loss: 2.448029411370903

Epoch: 6| Step: 2
Training loss: 2.8913029056232467
Validation loss: 2.4494186879491453

Epoch: 6| Step: 3
Training loss: 2.391488511453701
Validation loss: 2.4472977579559028

Epoch: 6| Step: 4
Training loss: 2.3348698552394227
Validation loss: 2.4471890335295785

Epoch: 6| Step: 5
Training loss: 2.585504870225535
Validation loss: 2.4471930117336598

Epoch: 6| Step: 6
Training loss: 2.6944215048199096
Validation loss: 2.4440226377582337

Epoch: 6| Step: 7
Training loss: 2.409624384183469
Validation loss: 2.453071674650145

Epoch: 6| Step: 8
Training loss: 2.5629443271884735
Validation loss: 2.4459407596510365

Epoch: 6| Step: 9
Training loss: 2.5149350375209374
Validation loss: 2.450513174198409

Epoch: 6| Step: 10
Training loss: 2.3251278421673667
Validation loss: 2.44474291845632

Epoch: 6| Step: 11
Training loss: 2.4406899339778496
Validation loss: 2.4408470876594235

Epoch: 6| Step: 12
Training loss: 2.5467269948068405
Validation loss: 2.440591921482451

Epoch: 6| Step: 13
Training loss: 2.811155548883685
Validation loss: 2.4530438857223995

Epoch: 125| Step: 0
Training loss: 3.1072561434434074
Validation loss: 2.4551809406222516

Epoch: 6| Step: 1
Training loss: 1.7701539550249172
Validation loss: 2.462209528203843

Epoch: 6| Step: 2
Training loss: 1.6961411239776365
Validation loss: 2.451420688032668

Epoch: 6| Step: 3
Training loss: 1.8437898275955225
Validation loss: 2.4619175811181555

Epoch: 6| Step: 4
Training loss: 2.93016744115679
Validation loss: 2.461597204844719

Epoch: 6| Step: 5
Training loss: 1.9983357419255843
Validation loss: 2.4678357841929692

Epoch: 6| Step: 6
Training loss: 2.3733454512526078
Validation loss: 2.450610189940365

Epoch: 6| Step: 7
Training loss: 2.761574057494098
Validation loss: 2.45593303482783

Epoch: 6| Step: 8
Training loss: 2.780254571634271
Validation loss: 2.450803010094265

Epoch: 6| Step: 9
Training loss: 2.9624977530297882
Validation loss: 2.44257634720686

Epoch: 6| Step: 10
Training loss: 2.7918231882275335
Validation loss: 2.4448516541446277

Epoch: 6| Step: 11
Training loss: 2.2772118348640134
Validation loss: 2.4390263139515556

Epoch: 6| Step: 12
Training loss: 2.9259468306784098
Validation loss: 2.4486482595663577

Epoch: 6| Step: 13
Training loss: 2.116330356863579
Validation loss: 2.4477905051544604

Testing loss: 1.977740013482864
