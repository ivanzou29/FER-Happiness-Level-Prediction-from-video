Epoch: 1| Step: 0
Training loss: 4.7337446212768555
Validation loss: 5.325396120548248

Epoch: 5| Step: 1
Training loss: 5.5223236083984375
Validation loss: 5.323855896790822

Epoch: 5| Step: 2
Training loss: 4.751032829284668
Validation loss: 5.322479883829753

Epoch: 5| Step: 3
Training loss: 5.364933490753174
Validation loss: 5.32104355096817

Epoch: 5| Step: 4
Training loss: 6.137872219085693
Validation loss: 5.319607198238373

Epoch: 5| Step: 5
Training loss: 5.781737327575684
Validation loss: 5.318251172701518

Epoch: 5| Step: 6
Training loss: 5.380295753479004
Validation loss: 5.31683748960495

Epoch: 5| Step: 7
Training loss: 4.859261989593506
Validation loss: 5.3154377937316895

Epoch: 5| Step: 8
Training loss: 4.807718753814697
Validation loss: 5.314031660556793

Epoch: 5| Step: 9
Training loss: 5.415862083435059
Validation loss: 5.312597572803497

Epoch: 5| Step: 10
Training loss: 6.238849639892578
Validation loss: 5.311129907766978

Epoch: 5| Step: 11
Training loss: 6.697770118713379
Validation loss: 5.3095530072848005

Epoch: 2| Step: 0
Training loss: 6.235896587371826
Validation loss: 5.308023830254872

Epoch: 5| Step: 1
Training loss: 6.1182990074157715
Validation loss: 5.306379199028015

Epoch: 5| Step: 2
Training loss: 5.2973737716674805
Validation loss: 5.304706672827403

Epoch: 5| Step: 3
Training loss: 5.177298545837402
Validation loss: 5.302866915861766

Epoch: 5| Step: 4
Training loss: 5.348496437072754
Validation loss: 5.301017979780833

Epoch: 5| Step: 5
Training loss: 4.439782619476318
Validation loss: 5.299069205919902

Epoch: 5| Step: 6
Training loss: 5.786245822906494
Validation loss: 5.297053078810374

Epoch: 5| Step: 7
Training loss: 5.804723262786865
Validation loss: 5.294889152050018

Epoch: 5| Step: 8
Training loss: 4.737423896789551
Validation loss: 5.292661388715108

Epoch: 5| Step: 9
Training loss: 4.981274127960205
Validation loss: 5.290238221486409

Epoch: 5| Step: 10
Training loss: 4.976247787475586
Validation loss: 5.287807484467824

Epoch: 5| Step: 11
Training loss: 6.0609869956970215
Validation loss: 5.285131653149922

Epoch: 3| Step: 0
Training loss: 4.518649101257324
Validation loss: 5.28226105372111

Epoch: 5| Step: 1
Training loss: 5.103640556335449
Validation loss: 5.279312213261922

Epoch: 5| Step: 2
Training loss: 5.55772590637207
Validation loss: 5.276316404342651

Epoch: 5| Step: 3
Training loss: 4.968514919281006
Validation loss: 5.272907574971517

Epoch: 5| Step: 4
Training loss: 5.095038414001465
Validation loss: 5.269522488117218

Epoch: 5| Step: 5
Training loss: 4.831178665161133
Validation loss: 5.2657654484113054

Epoch: 5| Step: 6
Training loss: 5.409575462341309
Validation loss: 5.2618448138237

Epoch: 5| Step: 7
Training loss: 5.605797290802002
Validation loss: 5.257893681526184

Epoch: 5| Step: 8
Training loss: 5.346364974975586
Validation loss: 5.253625849882762

Epoch: 5| Step: 9
Training loss: 5.857863426208496
Validation loss: 5.248924394448598

Epoch: 5| Step: 10
Training loss: 6.082459449768066
Validation loss: 5.244056145350139

Epoch: 5| Step: 11
Training loss: 6.762274742126465
Validation loss: 5.238927920659383

Epoch: 4| Step: 0
Training loss: 4.756869792938232
Validation loss: 5.2336464921633405

Epoch: 5| Step: 1
Training loss: 4.982805252075195
Validation loss: 5.2279277841250105

Epoch: 5| Step: 2
Training loss: 5.687381744384766
Validation loss: 5.222037176291148

Epoch: 5| Step: 3
Training loss: 6.095681190490723
Validation loss: 5.21574072043101

Epoch: 5| Step: 4
Training loss: 4.624016284942627
Validation loss: 5.209214588006337

Epoch: 5| Step: 5
Training loss: 5.278285980224609
Validation loss: 5.202271044254303

Epoch: 5| Step: 6
Training loss: 5.577794551849365
Validation loss: 5.195303936799367

Epoch: 5| Step: 7
Training loss: 5.316485404968262
Validation loss: 5.187880615393321

Epoch: 5| Step: 8
Training loss: 4.65678071975708
Validation loss: 5.1798690756162005

Epoch: 5| Step: 9
Training loss: 5.222268104553223
Validation loss: 5.171546836694081

Epoch: 5| Step: 10
Training loss: 6.216378211975098
Validation loss: 5.163078824679057

Epoch: 5| Step: 11
Training loss: 3.0125176906585693
Validation loss: 5.1543957988421125

Epoch: 5| Step: 0
Training loss: 5.232072353363037
Validation loss: 5.145016193389893

Epoch: 5| Step: 1
Training loss: 5.2937235832214355
Validation loss: 5.13564928372701

Epoch: 5| Step: 2
Training loss: 5.394350528717041
Validation loss: 5.126087645689647

Epoch: 5| Step: 3
Training loss: 5.586346626281738
Validation loss: 5.116013924280803

Epoch: 5| Step: 4
Training loss: 4.0147480964660645
Validation loss: 5.105860094229381

Epoch: 5| Step: 5
Training loss: 4.285616874694824
Validation loss: 5.095788141091664

Epoch: 5| Step: 6
Training loss: 5.174637794494629
Validation loss: 5.085409760475159

Epoch: 5| Step: 7
Training loss: 5.633284568786621
Validation loss: 5.075017432371776

Epoch: 5| Step: 8
Training loss: 4.589541435241699
Validation loss: 5.064541459083557

Epoch: 5| Step: 9
Training loss: 5.595278263092041
Validation loss: 5.053969244162242

Epoch: 5| Step: 10
Training loss: 5.937215805053711
Validation loss: 5.043675184249878

Epoch: 5| Step: 11
Training loss: 5.838057994842529
Validation loss: 5.033008495966594

Epoch: 6| Step: 0
Training loss: 5.643208980560303
Validation loss: 5.022123495737712

Epoch: 5| Step: 1
Training loss: 5.867283821105957
Validation loss: 5.011196474234263

Epoch: 5| Step: 2
Training loss: 3.942052125930786
Validation loss: 5.0002848108609514

Epoch: 5| Step: 3
Training loss: 4.306624412536621
Validation loss: 4.98909177382787

Epoch: 5| Step: 4
Training loss: 5.716431140899658
Validation loss: 4.977401336034139

Epoch: 5| Step: 5
Training loss: 4.390191078186035
Validation loss: 4.966452499230702

Epoch: 5| Step: 6
Training loss: 4.432601451873779
Validation loss: 4.9546581109364825

Epoch: 5| Step: 7
Training loss: 4.152387619018555
Validation loss: 4.942976574103038

Epoch: 5| Step: 8
Training loss: 5.909129619598389
Validation loss: 4.931594967842102

Epoch: 5| Step: 9
Training loss: 5.026281833648682
Validation loss: 4.9197389880816145

Epoch: 5| Step: 10
Training loss: 5.885180473327637
Validation loss: 4.908379038174947

Epoch: 5| Step: 11
Training loss: 6.245889186859131
Validation loss: 4.897136112054189

Epoch: 7| Step: 0
Training loss: 5.067205429077148
Validation loss: 4.886370082696279

Epoch: 5| Step: 1
Training loss: 5.520943641662598
Validation loss: 4.876380642255147

Epoch: 5| Step: 2
Training loss: 5.457825660705566
Validation loss: 4.8663925131162005

Epoch: 5| Step: 3
Training loss: 4.393994331359863
Validation loss: 4.856343428293864

Epoch: 5| Step: 4
Training loss: 5.083845615386963
Validation loss: 4.8467318415641785

Epoch: 5| Step: 5
Training loss: 4.941120624542236
Validation loss: 4.83784822622935

Epoch: 5| Step: 6
Training loss: 4.440656661987305
Validation loss: 4.82877637942632

Epoch: 5| Step: 7
Training loss: 4.245343208312988
Validation loss: 4.820172945658366

Epoch: 5| Step: 8
Training loss: 5.020047187805176
Validation loss: 4.811624685923259

Epoch: 5| Step: 9
Training loss: 4.428456783294678
Validation loss: 4.803130855162938

Epoch: 5| Step: 10
Training loss: 5.129110813140869
Validation loss: 4.795101602872212

Epoch: 5| Step: 11
Training loss: 7.227817058563232
Validation loss: 4.787344614664714

Epoch: 8| Step: 0
Training loss: 4.460691452026367
Validation loss: 4.779493769009908

Epoch: 5| Step: 1
Training loss: 4.275559425354004
Validation loss: 4.772101819515228

Epoch: 5| Step: 2
Training loss: 5.329870223999023
Validation loss: 4.764541774988174

Epoch: 5| Step: 3
Training loss: 4.76789665222168
Validation loss: 4.756868402163188

Epoch: 5| Step: 4
Training loss: 5.038841247558594
Validation loss: 4.750321249167125

Epoch: 5| Step: 5
Training loss: 4.37286901473999
Validation loss: 4.743598421414693

Epoch: 5| Step: 6
Training loss: 5.470816612243652
Validation loss: 4.736424525578816

Epoch: 5| Step: 7
Training loss: 3.973331928253174
Validation loss: 4.729990303516388

Epoch: 5| Step: 8
Training loss: 5.381317138671875
Validation loss: 4.723214725653331

Epoch: 5| Step: 9
Training loss: 4.889986515045166
Validation loss: 4.716690500577291

Epoch: 5| Step: 10
Training loss: 4.716619491577148
Validation loss: 4.7099233865737915

Epoch: 5| Step: 11
Training loss: 7.3199639320373535
Validation loss: 4.703304370244344

Epoch: 9| Step: 0
Training loss: 5.162112712860107
Validation loss: 4.697390407323837

Epoch: 5| Step: 1
Training loss: 4.592053413391113
Validation loss: 4.690837303797404

Epoch: 5| Step: 2
Training loss: 4.229283332824707
Validation loss: 4.684797128041585

Epoch: 5| Step: 3
Training loss: 5.09841251373291
Validation loss: 4.678996841112773

Epoch: 5| Step: 4
Training loss: 4.220184326171875
Validation loss: 4.672555863857269

Epoch: 5| Step: 5
Training loss: 4.590507507324219
Validation loss: 4.66614842414856

Epoch: 5| Step: 6
Training loss: 5.455719470977783
Validation loss: 4.6598154703776045

Epoch: 5| Step: 7
Training loss: 4.679192543029785
Validation loss: 4.653959770997365

Epoch: 5| Step: 8
Training loss: 4.177491188049316
Validation loss: 4.6476418773333235

Epoch: 5| Step: 9
Training loss: 4.632807731628418
Validation loss: 4.6416405240694685

Epoch: 5| Step: 10
Training loss: 5.420634746551514
Validation loss: 4.635579804579417

Epoch: 5| Step: 11
Training loss: 5.304388999938965
Validation loss: 4.629735887050629

Epoch: 10| Step: 0
Training loss: 4.598167419433594
Validation loss: 4.624287048975627

Epoch: 5| Step: 1
Training loss: 4.749480247497559
Validation loss: 4.618497808774312

Epoch: 5| Step: 2
Training loss: 4.516117095947266
Validation loss: 4.612128138542175

Epoch: 5| Step: 3
Training loss: 4.503262042999268
Validation loss: 4.606348693370819

Epoch: 5| Step: 4
Training loss: 5.375936508178711
Validation loss: 4.5999018748601275

Epoch: 5| Step: 5
Training loss: 4.85745096206665
Validation loss: 4.594589332739512

Epoch: 5| Step: 6
Training loss: 4.846268653869629
Validation loss: 4.588095664978027

Epoch: 5| Step: 7
Training loss: 4.392560005187988
Validation loss: 4.582777480284373

Epoch: 5| Step: 8
Training loss: 4.233864784240723
Validation loss: 4.576472520828247

Epoch: 5| Step: 9
Training loss: 4.426233768463135
Validation loss: 4.57046976685524

Epoch: 5| Step: 10
Training loss: 5.323324680328369
Validation loss: 4.5642276207606

Epoch: 5| Step: 11
Training loss: 3.6825788021087646
Validation loss: 4.557728946208954

Epoch: 11| Step: 0
Training loss: 4.874424457550049
Validation loss: 4.552790155013402

Epoch: 5| Step: 1
Training loss: 2.8945157527923584
Validation loss: 4.545732220013936

Epoch: 5| Step: 2
Training loss: 4.799105644226074
Validation loss: 4.5380719403425855

Epoch: 5| Step: 3
Training loss: 5.137482643127441
Validation loss: 4.530673166116078

Epoch: 5| Step: 4
Training loss: 4.902568817138672
Validation loss: 4.525730133056641

Epoch: 5| Step: 5
Training loss: 4.596600532531738
Validation loss: 4.519232581059138

Epoch: 5| Step: 6
Training loss: 4.116252899169922
Validation loss: 4.5111508667469025

Epoch: 5| Step: 7
Training loss: 4.113051891326904
Validation loss: 4.504193663597107

Epoch: 5| Step: 8
Training loss: 4.791330814361572
Validation loss: 4.497329155604045

Epoch: 5| Step: 9
Training loss: 5.49729061126709
Validation loss: 4.490901708602905

Epoch: 5| Step: 10
Training loss: 4.978801727294922
Validation loss: 4.484158595403035

Epoch: 5| Step: 11
Training loss: 5.266040802001953
Validation loss: 4.477639933427175

Epoch: 12| Step: 0
Training loss: 4.265326023101807
Validation loss: 4.470499912897746

Epoch: 5| Step: 1
Training loss: 4.986935138702393
Validation loss: 4.464967379967372

Epoch: 5| Step: 2
Training loss: 4.854039192199707
Validation loss: 4.45873208840688

Epoch: 5| Step: 3
Training loss: 4.887530326843262
Validation loss: 4.4509430428345995

Epoch: 5| Step: 4
Training loss: 4.084502220153809
Validation loss: 4.445439567168553

Epoch: 5| Step: 5
Training loss: 4.354571342468262
Validation loss: 4.440195739269257

Epoch: 5| Step: 6
Training loss: 4.657064914703369
Validation loss: 4.434233138958613

Epoch: 5| Step: 7
Training loss: 4.19512414932251
Validation loss: 4.427862584590912

Epoch: 5| Step: 8
Training loss: 3.9805195331573486
Validation loss: 4.421093602975209

Epoch: 5| Step: 9
Training loss: 4.489795207977295
Validation loss: 4.415401558081309

Epoch: 5| Step: 10
Training loss: 5.210568428039551
Validation loss: 4.409374554951985

Epoch: 5| Step: 11
Training loss: 5.107538223266602
Validation loss: 4.403088390827179

Epoch: 13| Step: 0
Training loss: 4.137851238250732
Validation loss: 4.397526999314626

Epoch: 5| Step: 1
Training loss: 4.281135082244873
Validation loss: 4.392339626948039

Epoch: 5| Step: 2
Training loss: 4.104475975036621
Validation loss: 4.386975248654683

Epoch: 5| Step: 3
Training loss: 4.057987213134766
Validation loss: 4.381399770577748

Epoch: 5| Step: 4
Training loss: 5.151926517486572
Validation loss: 4.3760210772355395

Epoch: 5| Step: 5
Training loss: 4.150374412536621
Validation loss: 4.370285749435425

Epoch: 5| Step: 6
Training loss: 4.695546627044678
Validation loss: 4.364737411340077

Epoch: 5| Step: 7
Training loss: 4.508628845214844
Validation loss: 4.359449913104375

Epoch: 5| Step: 8
Training loss: 4.9527435302734375
Validation loss: 4.353924075762431

Epoch: 5| Step: 9
Training loss: 4.337595462799072
Validation loss: 4.348447908957799

Epoch: 5| Step: 10
Training loss: 4.616787910461426
Validation loss: 4.343860437472661

Epoch: 5| Step: 11
Training loss: 6.382994174957275
Validation loss: 4.338496496280034

Epoch: 14| Step: 0
Training loss: 5.74505615234375
Validation loss: 4.332912902037303

Epoch: 5| Step: 1
Training loss: 4.140721797943115
Validation loss: 4.328421274820964

Epoch: 5| Step: 2
Training loss: 4.670167446136475
Validation loss: 4.324138134717941

Epoch: 5| Step: 3
Training loss: 4.17160701751709
Validation loss: 4.319445421298345

Epoch: 5| Step: 4
Training loss: 4.31012487411499
Validation loss: 4.313459773858388

Epoch: 5| Step: 5
Training loss: 4.004966735839844
Validation loss: 4.3078421751658125

Epoch: 5| Step: 6
Training loss: 4.744114875793457
Validation loss: 4.302972416083018

Epoch: 5| Step: 7
Training loss: 4.83587121963501
Validation loss: 4.297505259513855

Epoch: 5| Step: 8
Training loss: 3.9931018352508545
Validation loss: 4.292038182417552

Epoch: 5| Step: 9
Training loss: 4.123305320739746
Validation loss: 4.286393990119298

Epoch: 5| Step: 10
Training loss: 4.379262447357178
Validation loss: 4.280847012996674

Epoch: 5| Step: 11
Training loss: 2.639235019683838
Validation loss: 4.276488085587819

Epoch: 15| Step: 0
Training loss: 4.421318531036377
Validation loss: 4.271441360314687

Epoch: 5| Step: 1
Training loss: 3.698471784591675
Validation loss: 4.266304691632588

Epoch: 5| Step: 2
Training loss: 4.308082103729248
Validation loss: 4.260778119166692

Epoch: 5| Step: 3
Training loss: 4.034405708312988
Validation loss: 4.255929549535115

Epoch: 5| Step: 4
Training loss: 4.798905849456787
Validation loss: 4.250726143519084

Epoch: 5| Step: 5
Training loss: 4.38012170791626
Validation loss: 4.246016134818395

Epoch: 5| Step: 6
Training loss: 5.4055914878845215
Validation loss: 4.240898251533508

Epoch: 5| Step: 7
Training loss: 4.248233318328857
Validation loss: 4.234741310278575

Epoch: 5| Step: 8
Training loss: 4.027135848999023
Validation loss: 4.229404240846634

Epoch: 5| Step: 9
Training loss: 4.139194011688232
Validation loss: 4.223990976810455

Epoch: 5| Step: 10
Training loss: 4.628468990325928
Validation loss: 4.218498428662618

Epoch: 5| Step: 11
Training loss: 4.460961818695068
Validation loss: 4.213462680578232

Epoch: 16| Step: 0
Training loss: 3.8380255699157715
Validation loss: 4.2081697682539625

Epoch: 5| Step: 1
Training loss: 3.635383129119873
Validation loss: 4.202984342972438

Epoch: 5| Step: 2
Training loss: 5.025090217590332
Validation loss: 4.1985145807266235

Epoch: 5| Step: 3
Training loss: 4.589913368225098
Validation loss: 4.193446775277455

Epoch: 5| Step: 4
Training loss: 4.138805389404297
Validation loss: 4.188593417406082

Epoch: 5| Step: 5
Training loss: 5.566343307495117
Validation loss: 4.183468719323476

Epoch: 5| Step: 6
Training loss: 3.8259785175323486
Validation loss: 4.178461720546086

Epoch: 5| Step: 7
Training loss: 4.722287178039551
Validation loss: 4.17423290014267

Epoch: 5| Step: 8
Training loss: 3.6667962074279785
Validation loss: 4.169013539950053

Epoch: 5| Step: 9
Training loss: 5.232041358947754
Validation loss: 4.164129237333934

Epoch: 5| Step: 10
Training loss: 3.3922455310821533
Validation loss: 4.15897798538208

Epoch: 5| Step: 11
Training loss: 3.639693021774292
Validation loss: 4.155155857404073

Epoch: 17| Step: 0
Training loss: 4.198965549468994
Validation loss: 4.15037069718043

Epoch: 5| Step: 1
Training loss: 3.8496575355529785
Validation loss: 4.145607113838196

Epoch: 5| Step: 2
Training loss: 3.6888649463653564
Validation loss: 4.14043668905894

Epoch: 5| Step: 3
Training loss: 5.113224983215332
Validation loss: 4.135864069064458

Epoch: 5| Step: 4
Training loss: 4.726362705230713
Validation loss: 4.131082822879155

Epoch: 5| Step: 5
Training loss: 3.622838258743286
Validation loss: 4.126955538988113

Epoch: 5| Step: 6
Training loss: 4.5004377365112305
Validation loss: 4.122429708639781

Epoch: 5| Step: 7
Training loss: 4.075425624847412
Validation loss: 4.117625524600347

Epoch: 5| Step: 8
Training loss: 4.15449857711792
Validation loss: 4.112715780735016

Epoch: 5| Step: 9
Training loss: 4.641852378845215
Validation loss: 4.108465214570363

Epoch: 5| Step: 10
Training loss: 4.511261463165283
Validation loss: 4.104758510986964

Epoch: 5| Step: 11
Training loss: 3.432708978652954
Validation loss: 4.099700570106506

Epoch: 18| Step: 0
Training loss: 3.544389247894287
Validation loss: 4.09531890352567

Epoch: 5| Step: 1
Training loss: 3.8785643577575684
Validation loss: 4.091337561607361

Epoch: 5| Step: 2
Training loss: 4.496493339538574
Validation loss: 4.087335616350174

Epoch: 5| Step: 3
Training loss: 4.37998104095459
Validation loss: 4.082854996124904

Epoch: 5| Step: 4
Training loss: 4.513422966003418
Validation loss: 4.07846666375796

Epoch: 5| Step: 5
Training loss: 4.245310306549072
Validation loss: 4.073727409044902

Epoch: 5| Step: 6
Training loss: 5.029726982116699
Validation loss: 4.068728377421697

Epoch: 5| Step: 7
Training loss: 4.314342975616455
Validation loss: 4.064062515894572

Epoch: 5| Step: 8
Training loss: 3.816946506500244
Validation loss: 4.060442805290222

Epoch: 5| Step: 9
Training loss: 3.977139711380005
Validation loss: 4.055522819360097

Epoch: 5| Step: 10
Training loss: 4.32346248626709
Validation loss: 4.051185409228007

Epoch: 5| Step: 11
Training loss: 3.5084526538848877
Validation loss: 4.046798278888066

Epoch: 19| Step: 0
Training loss: 5.2206573486328125
Validation loss: 4.042653948068619

Epoch: 5| Step: 1
Training loss: 3.7973625659942627
Validation loss: 4.038842519124349

Epoch: 5| Step: 2
Training loss: 4.752346515655518
Validation loss: 4.034600704908371

Epoch: 5| Step: 3
Training loss: 4.153017997741699
Validation loss: 4.030029505491257

Epoch: 5| Step: 4
Training loss: 3.8771278858184814
Validation loss: 4.0255065361658735

Epoch: 5| Step: 5
Training loss: 4.167211055755615
Validation loss: 4.021208971738815

Epoch: 5| Step: 6
Training loss: 3.533414363861084
Validation loss: 4.016820589701335

Epoch: 5| Step: 7
Training loss: 4.573745250701904
Validation loss: 4.012367496887843

Epoch: 5| Step: 8
Training loss: 4.3255085945129395
Validation loss: 4.008185883363088

Epoch: 5| Step: 9
Training loss: 3.4520251750946045
Validation loss: 4.004211763540904

Epoch: 5| Step: 10
Training loss: 4.113917350769043
Validation loss: 3.999547779560089

Epoch: 5| Step: 11
Training loss: 3.412555694580078
Validation loss: 3.9951520462830863

Epoch: 20| Step: 0
Training loss: 3.0956037044525146
Validation loss: 3.9911277691523233

Epoch: 5| Step: 1
Training loss: 4.800610065460205
Validation loss: 3.986629923184713

Epoch: 5| Step: 2
Training loss: 2.9298934936523438
Validation loss: 3.9821524918079376

Epoch: 5| Step: 3
Training loss: 4.816679954528809
Validation loss: 3.9788363774617515

Epoch: 5| Step: 4
Training loss: 4.549574851989746
Validation loss: 3.974730799595515

Epoch: 5| Step: 5
Training loss: 4.6867570877075195
Validation loss: 3.970111588637034

Epoch: 5| Step: 6
Training loss: 4.411025047302246
Validation loss: 3.9657647212346396

Epoch: 5| Step: 7
Training loss: 4.654088973999023
Validation loss: 3.9606584906578064

Epoch: 5| Step: 8
Training loss: 3.9010918140411377
Validation loss: 3.956484099229177

Epoch: 5| Step: 9
Training loss: 3.5246105194091797
Validation loss: 3.951970338821411

Epoch: 5| Step: 10
Training loss: 4.205202579498291
Validation loss: 3.947823623816172

Epoch: 5| Step: 11
Training loss: 2.534156322479248
Validation loss: 3.9434556464354196

Epoch: 21| Step: 0
Training loss: 4.812880516052246
Validation loss: 3.9393228391806283

Epoch: 5| Step: 1
Training loss: 3.9415011405944824
Validation loss: 3.934112032254537

Epoch: 5| Step: 2
Training loss: 3.6517443656921387
Validation loss: 3.9294789334138236

Epoch: 5| Step: 3
Training loss: 4.575591087341309
Validation loss: 3.9251440167427063

Epoch: 5| Step: 4
Training loss: 3.479290723800659
Validation loss: 3.920558452606201

Epoch: 5| Step: 5
Training loss: 3.9459125995635986
Validation loss: 3.915793687105179

Epoch: 5| Step: 6
Training loss: 3.6384475231170654
Validation loss: 3.9114804764588675

Epoch: 5| Step: 7
Training loss: 4.303605556488037
Validation loss: 3.90673033396403

Epoch: 5| Step: 8
Training loss: 4.585758209228516
Validation loss: 3.9022175868352256

Epoch: 5| Step: 9
Training loss: 4.6126251220703125
Validation loss: 3.8980936408042908

Epoch: 5| Step: 10
Training loss: 3.4201793670654297
Validation loss: 3.8935795029004416

Epoch: 5| Step: 11
Training loss: 2.7492904663085938
Validation loss: 3.8889619608720145

Epoch: 22| Step: 0
Training loss: 4.422492980957031
Validation loss: 3.8849024971326194

Epoch: 5| Step: 1
Training loss: 3.35266375541687
Validation loss: 3.8807610074679055

Epoch: 5| Step: 2
Training loss: 4.4419450759887695
Validation loss: 3.8758732676506042

Epoch: 5| Step: 3
Training loss: 4.3091020584106445
Validation loss: 3.871354321638743

Epoch: 5| Step: 4
Training loss: 4.3013200759887695
Validation loss: 3.8665719032287598

Epoch: 5| Step: 5
Training loss: 3.5328211784362793
Validation loss: 3.8615978757540383

Epoch: 5| Step: 6
Training loss: 4.165380001068115
Validation loss: 3.85736753543218

Epoch: 5| Step: 7
Training loss: 4.002341270446777
Validation loss: 3.8533004820346832

Epoch: 5| Step: 8
Training loss: 3.9511120319366455
Validation loss: 3.8484861155351004

Epoch: 5| Step: 9
Training loss: 4.464959144592285
Validation loss: 3.844231148560842

Epoch: 5| Step: 10
Training loss: 3.2545166015625
Validation loss: 3.8399024109045663

Epoch: 5| Step: 11
Training loss: 3.7976155281066895
Validation loss: 3.8352169891198478

Epoch: 23| Step: 0
Training loss: 4.25948429107666
Validation loss: 3.83062481880188

Epoch: 5| Step: 1
Training loss: 4.146738529205322
Validation loss: 3.826049188772837

Epoch: 5| Step: 2
Training loss: 3.956333637237549
Validation loss: 3.8216436207294464

Epoch: 5| Step: 3
Training loss: 4.005237579345703
Validation loss: 3.81709748506546

Epoch: 5| Step: 4
Training loss: 3.6399643421173096
Validation loss: 3.8126313587029776

Epoch: 5| Step: 5
Training loss: 3.5608832836151123
Validation loss: 3.8087399204572043

Epoch: 5| Step: 6
Training loss: 4.461271286010742
Validation loss: 3.804744780063629

Epoch: 5| Step: 7
Training loss: 3.338975191116333
Validation loss: 3.8002084692319236

Epoch: 5| Step: 8
Training loss: 4.145871162414551
Validation loss: 3.7951061725616455

Epoch: 5| Step: 9
Training loss: 3.7927634716033936
Validation loss: 3.791883329550425

Epoch: 5| Step: 10
Training loss: 4.526823997497559
Validation loss: 3.787967254718145

Epoch: 5| Step: 11
Training loss: 2.7768757343292236
Validation loss: 3.78275935848554

Epoch: 24| Step: 0
Training loss: 3.5242812633514404
Validation loss: 3.779117335875829

Epoch: 5| Step: 1
Training loss: 3.1724164485931396
Validation loss: 3.774665673573812

Epoch: 5| Step: 2
Training loss: 3.663510799407959
Validation loss: 3.76994921763738

Epoch: 5| Step: 3
Training loss: 3.546273708343506
Validation loss: 3.7652843594551086

Epoch: 5| Step: 4
Training loss: 4.569119453430176
Validation loss: 3.761036882797877

Epoch: 5| Step: 5
Training loss: 3.6916985511779785
Validation loss: 3.7571191489696503

Epoch: 5| Step: 6
Training loss: 3.4618172645568848
Validation loss: 3.7525305648644767

Epoch: 5| Step: 7
Training loss: 4.645843029022217
Validation loss: 3.7474968334039054

Epoch: 5| Step: 8
Training loss: 3.746933698654175
Validation loss: 3.742661585410436

Epoch: 5| Step: 9
Training loss: 4.087031364440918
Validation loss: 3.737828403711319

Epoch: 5| Step: 10
Training loss: 4.789155960083008
Validation loss: 3.734053452809652

Epoch: 5| Step: 11
Training loss: 4.714080810546875
Validation loss: 3.7294052839279175

Epoch: 25| Step: 0
Training loss: 3.545663833618164
Validation loss: 3.7252312501271567

Epoch: 5| Step: 1
Training loss: 4.210319995880127
Validation loss: 3.721305082241694

Epoch: 5| Step: 2
Training loss: 3.944352626800537
Validation loss: 3.717148015896479

Epoch: 5| Step: 3
Training loss: 3.5933997631073
Validation loss: 3.712815264860789

Epoch: 5| Step: 4
Training loss: 4.024248123168945
Validation loss: 3.7088868816693625

Epoch: 5| Step: 5
Training loss: 3.107334613800049
Validation loss: 3.7041890621185303

Epoch: 5| Step: 6
Training loss: 3.8015174865722656
Validation loss: 3.700757622718811

Epoch: 5| Step: 7
Training loss: 3.266139268875122
Validation loss: 3.6962324380874634

Epoch: 5| Step: 8
Training loss: 4.005824089050293
Validation loss: 3.691461523373922

Epoch: 5| Step: 9
Training loss: 4.827683448791504
Validation loss: 3.688074251015981

Epoch: 5| Step: 10
Training loss: 3.935530185699463
Validation loss: 3.683650473753611

Epoch: 5| Step: 11
Training loss: 5.01883602142334
Validation loss: 3.6796252926190696

Epoch: 26| Step: 0
Training loss: 3.542074203491211
Validation loss: 3.674781004587809

Epoch: 5| Step: 1
Training loss: 3.6508469581604004
Validation loss: 3.6700251698493958

Epoch: 5| Step: 2
Training loss: 4.154360294342041
Validation loss: 3.6654840608437858

Epoch: 5| Step: 3
Training loss: 3.4081320762634277
Validation loss: 3.6615619560082755

Epoch: 5| Step: 4
Training loss: 4.937679767608643
Validation loss: 3.6571822663148246

Epoch: 5| Step: 5
Training loss: 4.031004428863525
Validation loss: 3.6527640720208487

Epoch: 5| Step: 6
Training loss: 3.5930233001708984
Validation loss: 3.649040997028351

Epoch: 5| Step: 7
Training loss: 3.934617519378662
Validation loss: 3.6438717444737754

Epoch: 5| Step: 8
Training loss: 3.330045223236084
Validation loss: 3.6401049395402274

Epoch: 5| Step: 9
Training loss: 4.535669803619385
Validation loss: 3.635878066221873

Epoch: 5| Step: 10
Training loss: 3.3432376384735107
Validation loss: 3.6315520902474723

Epoch: 5| Step: 11
Training loss: 1.3093239068984985
Validation loss: 3.6274138192335763

Epoch: 27| Step: 0
Training loss: 4.1736955642700195
Validation loss: 3.6230955024560294

Epoch: 5| Step: 1
Training loss: 3.463771343231201
Validation loss: 3.618859420220057

Epoch: 5| Step: 2
Training loss: 4.626989841461182
Validation loss: 3.6145838697751365

Epoch: 5| Step: 3
Training loss: 5.164357662200928
Validation loss: 3.6104121704896293

Epoch: 5| Step: 4
Training loss: 3.6725471019744873
Validation loss: 3.6059237817923226

Epoch: 5| Step: 5
Training loss: 3.6764655113220215
Validation loss: 3.601270079612732

Epoch: 5| Step: 6
Training loss: 3.626859188079834
Validation loss: 3.5974014898141227

Epoch: 5| Step: 7
Training loss: 2.941483974456787
Validation loss: 3.5928952197233834

Epoch: 5| Step: 8
Training loss: 3.242568254470825
Validation loss: 3.5889040529727936

Epoch: 5| Step: 9
Training loss: 3.5628459453582764
Validation loss: 3.5849149326483407

Epoch: 5| Step: 10
Training loss: 3.7172679901123047
Validation loss: 3.5806609988212585

Epoch: 5| Step: 11
Training loss: 1.5845506191253662
Validation loss: 3.5766009787718454

Epoch: 28| Step: 0
Training loss: 3.9269046783447266
Validation loss: 3.5721435447533927

Epoch: 5| Step: 1
Training loss: 4.458460807800293
Validation loss: 3.5692785878976188

Epoch: 5| Step: 2
Training loss: 3.8861541748046875
Validation loss: 3.5643050273259482

Epoch: 5| Step: 3
Training loss: 3.016420364379883
Validation loss: 3.560341010491053

Epoch: 5| Step: 4
Training loss: 4.04042387008667
Validation loss: 3.556390086809794

Epoch: 5| Step: 5
Training loss: 3.4710586071014404
Validation loss: 3.5526496966679892

Epoch: 5| Step: 6
Training loss: 3.8522307872772217
Validation loss: 3.5486735304196677

Epoch: 5| Step: 7
Training loss: 3.5377109050750732
Validation loss: 3.544004480044047

Epoch: 5| Step: 8
Training loss: 3.216701030731201
Validation loss: 3.5396812558174133

Epoch: 5| Step: 9
Training loss: 4.0551042556762695
Validation loss: 3.5352205634117126

Epoch: 5| Step: 10
Training loss: 3.3067173957824707
Validation loss: 3.531119624773661

Epoch: 5| Step: 11
Training loss: 4.338376045227051
Validation loss: 3.5278117060661316

Epoch: 29| Step: 0
Training loss: 4.212714195251465
Validation loss: 3.523060897986094

Epoch: 5| Step: 1
Training loss: 3.114997148513794
Validation loss: 3.5188224812348685

Epoch: 5| Step: 2
Training loss: 3.743896484375
Validation loss: 3.514377683401108

Epoch: 5| Step: 3
Training loss: 3.931626081466675
Validation loss: 3.5099492967128754

Epoch: 5| Step: 4
Training loss: 3.1412851810455322
Validation loss: 3.5058035254478455

Epoch: 5| Step: 5
Training loss: 3.034874200820923
Validation loss: 3.5012664198875427

Epoch: 5| Step: 6
Training loss: 4.218982219696045
Validation loss: 3.4972806870937347

Epoch: 5| Step: 7
Training loss: 4.128020286560059
Validation loss: 3.4928882817427316

Epoch: 5| Step: 8
Training loss: 3.2780795097351074
Validation loss: 3.4886939028898873

Epoch: 5| Step: 9
Training loss: 3.9654898643493652
Validation loss: 3.48450959722201

Epoch: 5| Step: 10
Training loss: 3.7362160682678223
Validation loss: 3.4795143008232117

Epoch: 5| Step: 11
Training loss: 2.9725279808044434
Validation loss: 3.4754645029703775

Epoch: 30| Step: 0
Training loss: 3.606848955154419
Validation loss: 3.4717595080534616

Epoch: 5| Step: 1
Training loss: 3.7907230854034424
Validation loss: 3.46757510304451

Epoch: 5| Step: 2
Training loss: 2.9854037761688232
Validation loss: 3.464058597882589

Epoch: 5| Step: 3
Training loss: 3.7792916297912598
Validation loss: 3.4601547519365945

Epoch: 5| Step: 4
Training loss: 3.9201996326446533
Validation loss: 3.4556828339894614

Epoch: 5| Step: 5
Training loss: 3.6430320739746094
Validation loss: 3.4515190521876016

Epoch: 5| Step: 6
Training loss: 4.539814472198486
Validation loss: 3.4474854270617166

Epoch: 5| Step: 7
Training loss: 4.217578887939453
Validation loss: 3.4435054858525596

Epoch: 5| Step: 8
Training loss: 3.023528575897217
Validation loss: 3.4392492175102234

Epoch: 5| Step: 9
Training loss: 3.0771679878234863
Validation loss: 3.435250163078308

Epoch: 5| Step: 10
Training loss: 3.298915386199951
Validation loss: 3.43125186363856

Epoch: 5| Step: 11
Training loss: 3.2279186248779297
Validation loss: 3.4273225168387094

Epoch: 31| Step: 0
Training loss: 4.031429290771484
Validation loss: 3.4233396351337433

Epoch: 5| Step: 1
Training loss: 2.981448173522949
Validation loss: 3.419499476750692

Epoch: 5| Step: 2
Training loss: 3.463683605194092
Validation loss: 3.4154075384140015

Epoch: 5| Step: 3
Training loss: 4.0995283126831055
Validation loss: 3.411614050467809

Epoch: 5| Step: 4
Training loss: 3.761223554611206
Validation loss: 3.4077125787734985

Epoch: 5| Step: 5
Training loss: 2.843318223953247
Validation loss: 3.4031336903572083

Epoch: 5| Step: 6
Training loss: 3.187838077545166
Validation loss: 3.399381180604299

Epoch: 5| Step: 7
Training loss: 3.2640061378479004
Validation loss: 3.3953329424063363

Epoch: 5| Step: 8
Training loss: 3.9783332347869873
Validation loss: 3.391450067361196

Epoch: 5| Step: 9
Training loss: 3.5370049476623535
Validation loss: 3.387842367092768

Epoch: 5| Step: 10
Training loss: 4.215132713317871
Validation loss: 3.3836208879947662

Epoch: 5| Step: 11
Training loss: 3.1903133392333984
Validation loss: 3.379643460114797

Epoch: 32| Step: 0
Training loss: 4.035079479217529
Validation loss: 3.375639130671819

Epoch: 5| Step: 1
Training loss: 3.7275142669677734
Validation loss: 3.3714067240556083

Epoch: 5| Step: 2
Training loss: 3.417706251144409
Validation loss: 3.3673034608364105

Epoch: 5| Step: 3
Training loss: 4.008012771606445
Validation loss: 3.363284319639206

Epoch: 5| Step: 4
Training loss: 3.7865726947784424
Validation loss: 3.3593518237272897

Epoch: 5| Step: 5
Training loss: 3.4835453033447266
Validation loss: 3.3555811941623688

Epoch: 5| Step: 6
Training loss: 2.6683075428009033
Validation loss: 3.3507540822029114

Epoch: 5| Step: 7
Training loss: 3.795184373855591
Validation loss: 3.346695830424627

Epoch: 5| Step: 8
Training loss: 3.5324432849884033
Validation loss: 3.342356731494268

Epoch: 5| Step: 9
Training loss: 2.911219835281372
Validation loss: 3.338606903950373

Epoch: 5| Step: 10
Training loss: 3.603846788406372
Validation loss: 3.3341545462608337

Epoch: 5| Step: 11
Training loss: 2.6753008365631104
Validation loss: 3.330494225025177

Epoch: 33| Step: 0
Training loss: 3.877354383468628
Validation loss: 3.3265936573346457

Epoch: 5| Step: 1
Training loss: 2.9225685596466064
Validation loss: 3.3222031195958457

Epoch: 5| Step: 2
Training loss: 4.18555212020874
Validation loss: 3.318931063016256

Epoch: 5| Step: 3
Training loss: 3.1092286109924316
Validation loss: 3.3143882950146994

Epoch: 5| Step: 4
Training loss: 3.276968479156494
Validation loss: 3.310533881187439

Epoch: 5| Step: 5
Training loss: 4.697403430938721
Validation loss: 3.3064949015776315

Epoch: 5| Step: 6
Training loss: 4.001635551452637
Validation loss: 3.301669885714849

Epoch: 5| Step: 7
Training loss: 3.9500527381896973
Validation loss: 3.2974087397257485

Epoch: 5| Step: 8
Training loss: 2.8530354499816895
Validation loss: 3.2934336264928183

Epoch: 5| Step: 9
Training loss: 2.335488796234131
Validation loss: 3.2894861896832785

Epoch: 5| Step: 10
Training loss: 3.4512076377868652
Validation loss: 3.2862941225369773

Epoch: 5| Step: 11
Training loss: 1.7195876836776733
Validation loss: 3.2830788791179657

Epoch: 34| Step: 0
Training loss: 2.658078193664551
Validation loss: 3.282147685686747

Epoch: 5| Step: 1
Training loss: 3.4341659545898438
Validation loss: 3.2765176594257355

Epoch: 5| Step: 2
Training loss: 3.9930853843688965
Validation loss: 3.2728001375993094

Epoch: 5| Step: 3
Training loss: 3.6030056476593018
Validation loss: 3.2692678372065225

Epoch: 5| Step: 4
Training loss: 3.234621524810791
Validation loss: 3.266487419605255

Epoch: 5| Step: 5
Training loss: 3.796448230743408
Validation loss: 3.2628496289253235

Epoch: 5| Step: 6
Training loss: 3.850688934326172
Validation loss: 3.2600070436795554

Epoch: 5| Step: 7
Training loss: 3.6555793285369873
Validation loss: 3.255209525426229

Epoch: 5| Step: 8
Training loss: 2.751584529876709
Validation loss: 3.2515922486782074

Epoch: 5| Step: 9
Training loss: 3.1436924934387207
Validation loss: 3.2482864459355674

Epoch: 5| Step: 10
Training loss: 3.8675739765167236
Validation loss: 3.244288682937622

Epoch: 5| Step: 11
Training loss: 2.734652042388916
Validation loss: 3.2400716841220856

Epoch: 35| Step: 0
Training loss: 2.9306838512420654
Validation loss: 3.2368112007776895

Epoch: 5| Step: 1
Training loss: 3.6999053955078125
Validation loss: 3.233439713716507

Epoch: 5| Step: 2
Training loss: 3.7099437713623047
Validation loss: 3.230242043733597

Epoch: 5| Step: 3
Training loss: 3.0134940147399902
Validation loss: 3.225845903158188

Epoch: 5| Step: 4
Training loss: 3.367743730545044
Validation loss: 3.2220511535803475

Epoch: 5| Step: 5
Training loss: 3.033068895339966
Validation loss: 3.2175810635089874

Epoch: 5| Step: 6
Training loss: 3.4765095710754395
Validation loss: 3.2137058277924857

Epoch: 5| Step: 7
Training loss: 3.417448043823242
Validation loss: 3.2098191181818643

Epoch: 5| Step: 8
Training loss: 3.3120033740997314
Validation loss: 3.20606263478597

Epoch: 5| Step: 9
Training loss: 3.2732348442077637
Validation loss: 3.2021390398343406

Epoch: 5| Step: 10
Training loss: 4.309613227844238
Validation loss: 3.1985153953234353

Epoch: 5| Step: 11
Training loss: 2.629244804382324
Validation loss: 3.1948364675045013

Epoch: 36| Step: 0
Training loss: 3.390712022781372
Validation loss: 3.191346903642019

Epoch: 5| Step: 1
Training loss: 3.392940044403076
Validation loss: 3.187804867823919

Epoch: 5| Step: 2
Training loss: 3.577446699142456
Validation loss: 3.184637943903605

Epoch: 5| Step: 3
Training loss: 3.120906352996826
Validation loss: 3.181451549132665

Epoch: 5| Step: 4
Training loss: 3.193669080734253
Validation loss: 3.177780697743098

Epoch: 5| Step: 5
Training loss: 3.4358413219451904
Validation loss: 3.1739594638347626

Epoch: 5| Step: 6
Training loss: 3.288337230682373
Validation loss: 3.1700647175312042

Epoch: 5| Step: 7
Training loss: 3.7201812267303467
Validation loss: 3.166026304165522

Epoch: 5| Step: 8
Training loss: 2.419147253036499
Validation loss: 3.16252593199412

Epoch: 5| Step: 9
Training loss: 3.1942520141601562
Validation loss: 3.1587259670098624

Epoch: 5| Step: 10
Training loss: 3.915735960006714
Validation loss: 3.1552983025709787

Epoch: 5| Step: 11
Training loss: 4.774656772613525
Validation loss: 3.1516763269901276

Epoch: 37| Step: 0
Training loss: 2.9453861713409424
Validation loss: 3.1481666465600333

Epoch: 5| Step: 1
Training loss: 3.438227415084839
Validation loss: 3.1446066399415336

Epoch: 5| Step: 2
Training loss: 3.698991298675537
Validation loss: 3.140556047360102

Epoch: 5| Step: 3
Training loss: 3.4843266010284424
Validation loss: 3.1369884808858237

Epoch: 5| Step: 4
Training loss: 3.524022340774536
Validation loss: 3.1334300140539804

Epoch: 5| Step: 5
Training loss: 3.5063090324401855
Validation loss: 3.1290780206521354

Epoch: 5| Step: 6
Training loss: 2.5677709579467773
Validation loss: 3.1249964932600656

Epoch: 5| Step: 7
Training loss: 3.1475768089294434
Validation loss: 3.1208616395791373

Epoch: 5| Step: 8
Training loss: 2.8020944595336914
Validation loss: 3.1171784003575644

Epoch: 5| Step: 9
Training loss: 3.352858304977417
Validation loss: 3.113679349422455

Epoch: 5| Step: 10
Training loss: 3.6732001304626465
Validation loss: 3.1096771955490112

Epoch: 5| Step: 11
Training loss: 5.030003547668457
Validation loss: 3.106349766254425

Epoch: 38| Step: 0
Training loss: 3.1242942810058594
Validation loss: 3.1015168527762094

Epoch: 5| Step: 1
Training loss: 3.1376748085021973
Validation loss: 3.098521580298742

Epoch: 5| Step: 2
Training loss: 3.4428420066833496
Validation loss: 3.0952053566773734

Epoch: 5| Step: 3
Training loss: 2.911721706390381
Validation loss: 3.0922805964946747

Epoch: 5| Step: 4
Training loss: 3.9744575023651123
Validation loss: 3.087996522585551

Epoch: 5| Step: 5
Training loss: 3.3387324810028076
Validation loss: 3.0855877101421356

Epoch: 5| Step: 6
Training loss: 3.170254945755005
Validation loss: 3.0819314618905387

Epoch: 5| Step: 7
Training loss: 3.48877215385437
Validation loss: 3.0775751968224845

Epoch: 5| Step: 8
Training loss: 3.503779649734497
Validation loss: 3.0733819603919983

Epoch: 5| Step: 9
Training loss: 2.703155994415283
Validation loss: 3.069689095020294

Epoch: 5| Step: 10
Training loss: 3.369842052459717
Validation loss: 3.06614018479983

Epoch: 5| Step: 11
Training loss: 2.5409793853759766
Validation loss: 3.0630632738272348

Epoch: 39| Step: 0
Training loss: 3.62701678276062
Validation loss: 3.0592278639475503

Epoch: 5| Step: 1
Training loss: 3.003431797027588
Validation loss: 3.0561499893665314

Epoch: 5| Step: 2
Training loss: 2.9687061309814453
Validation loss: 3.052702486515045

Epoch: 5| Step: 3
Training loss: 2.6391372680664062
Validation loss: 3.0489025910695395

Epoch: 5| Step: 4
Training loss: 2.6964945793151855
Validation loss: 3.045348276694616

Epoch: 5| Step: 5
Training loss: 3.133010149002075
Validation loss: 3.04248916109403

Epoch: 5| Step: 6
Training loss: 3.2247729301452637
Validation loss: 3.0386140743891397

Epoch: 5| Step: 7
Training loss: 4.030973434448242
Validation loss: 3.035871466000875

Epoch: 5| Step: 8
Training loss: 4.066318511962891
Validation loss: 3.033171077569326

Epoch: 5| Step: 9
Training loss: 3.6359405517578125
Validation loss: 3.028982937335968

Epoch: 5| Step: 10
Training loss: 3.0390539169311523
Validation loss: 3.025896370410919

Epoch: 5| Step: 11
Training loss: 0.7976030111312866
Validation loss: 3.0224805772304535

Epoch: 40| Step: 0
Training loss: 3.0351951122283936
Validation loss: 3.0187459886074066

Epoch: 5| Step: 1
Training loss: 3.3686835765838623
Validation loss: 3.016666362682978

Epoch: 5| Step: 2
Training loss: 2.925508975982666
Validation loss: 3.015030642350515

Epoch: 5| Step: 3
Training loss: 3.0764994621276855
Validation loss: 3.011867086092631

Epoch: 5| Step: 4
Training loss: 2.8844916820526123
Validation loss: 3.008480489253998

Epoch: 5| Step: 5
Training loss: 3.587934970855713
Validation loss: 3.004004269838333

Epoch: 5| Step: 6
Training loss: 3.5319952964782715
Validation loss: 3.0007622440656028

Epoch: 5| Step: 7
Training loss: 3.4924628734588623
Validation loss: 2.997487743695577

Epoch: 5| Step: 8
Training loss: 3.144892930984497
Validation loss: 2.9945692916711173

Epoch: 5| Step: 9
Training loss: 3.349449634552002
Validation loss: 2.9914935330549874

Epoch: 5| Step: 10
Training loss: 2.950448513031006
Validation loss: 2.988165646791458

Epoch: 5| Step: 11
Training loss: 2.2743754386901855
Validation loss: 2.9849436283111572

Epoch: 41| Step: 0
Training loss: 3.254868745803833
Validation loss: 2.981706976890564

Epoch: 5| Step: 1
Training loss: 3.195481777191162
Validation loss: 2.978713423013687

Epoch: 5| Step: 2
Training loss: 3.0601210594177246
Validation loss: 2.97571470340093

Epoch: 5| Step: 3
Training loss: 2.904649257659912
Validation loss: 2.972241461277008

Epoch: 5| Step: 4
Training loss: 3.221552610397339
Validation loss: 2.9692607522010803

Epoch: 5| Step: 5
Training loss: 3.037057399749756
Validation loss: 2.966649224360784

Epoch: 5| Step: 6
Training loss: 3.4057419300079346
Validation loss: 2.962531437476476

Epoch: 5| Step: 7
Training loss: 3.728443145751953
Validation loss: 2.960373063882192

Epoch: 5| Step: 8
Training loss: 3.5820350646972656
Validation loss: 2.9576202730337777

Epoch: 5| Step: 9
Training loss: 2.6637063026428223
Validation loss: 2.9531649152437844

Epoch: 5| Step: 10
Training loss: 2.8669142723083496
Validation loss: 2.95002909998099

Epoch: 5| Step: 11
Training loss: 2.5981545448303223
Validation loss: 2.946821520725886

Epoch: 42| Step: 0
Training loss: 2.880650043487549
Validation loss: 2.9439337948958078

Epoch: 5| Step: 1
Training loss: 3.3042423725128174
Validation loss: 2.9411493241786957

Epoch: 5| Step: 2
Training loss: 3.407106399536133
Validation loss: 2.9385057787100473

Epoch: 5| Step: 3
Training loss: 3.5042243003845215
Validation loss: 2.935434401035309

Epoch: 5| Step: 4
Training loss: 3.7346835136413574
Validation loss: 2.9332039654254913

Epoch: 5| Step: 5
Training loss: 2.7725136280059814
Validation loss: 2.9304190377394357

Epoch: 5| Step: 6
Training loss: 2.8210647106170654
Validation loss: 2.9268646438916526

Epoch: 5| Step: 7
Training loss: 3.369535446166992
Validation loss: 2.925145983695984

Epoch: 5| Step: 8
Training loss: 3.730937957763672
Validation loss: 2.9203754564126334

Epoch: 5| Step: 9
Training loss: 2.313204050064087
Validation loss: 2.917690177758535

Epoch: 5| Step: 10
Training loss: 2.662984609603882
Validation loss: 2.9128355185190835

Epoch: 5| Step: 11
Training loss: 2.816863536834717
Validation loss: 2.910688668489456

Epoch: 43| Step: 0
Training loss: 3.1367311477661133
Validation loss: 2.9073171814282737

Epoch: 5| Step: 1
Training loss: 3.0934040546417236
Validation loss: 2.904438406229019

Epoch: 5| Step: 2
Training loss: 3.312061309814453
Validation loss: 2.9032131135463715

Epoch: 5| Step: 3
Training loss: 3.468945026397705
Validation loss: 2.907402455806732

Epoch: 5| Step: 4
Training loss: 3.032471179962158
Validation loss: 2.898570944865545

Epoch: 5| Step: 5
Training loss: 3.1198179721832275
Validation loss: 2.8949353297551474

Epoch: 5| Step: 6
Training loss: 2.7777750492095947
Validation loss: 2.895751198132833

Epoch: 5| Step: 7
Training loss: 3.1713974475860596
Validation loss: 2.8872464299201965

Epoch: 5| Step: 8
Training loss: 2.4979870319366455
Validation loss: 2.884426782528559

Epoch: 5| Step: 9
Training loss: 2.987889528274536
Validation loss: 2.8848799963792167

Epoch: 5| Step: 10
Training loss: 3.446516752243042
Validation loss: 2.8932378391424813

Epoch: 5| Step: 11
Training loss: 3.1903836727142334
Validation loss: 2.897290607293447

Epoch: 44| Step: 0
Training loss: 3.0637412071228027
Validation loss: 2.8740236461162567

Epoch: 5| Step: 1
Training loss: 4.167571067810059
Validation loss: 2.869730621576309

Epoch: 5| Step: 2
Training loss: 2.8165998458862305
Validation loss: 2.8669538696606955

Epoch: 5| Step: 3
Training loss: 2.8751425743103027
Validation loss: 2.864636113246282

Epoch: 5| Step: 4
Training loss: 2.9518115520477295
Validation loss: 2.8684321641921997

Epoch: 5| Step: 5
Training loss: 3.49290132522583
Validation loss: 2.865868419408798

Epoch: 5| Step: 6
Training loss: 3.20092511177063
Validation loss: 2.8554093341032663

Epoch: 5| Step: 7
Training loss: 2.566425323486328
Validation loss: 2.8524097402890525

Epoch: 5| Step: 8
Training loss: 3.247136354446411
Validation loss: 2.8489144146442413

Epoch: 5| Step: 9
Training loss: 2.804875612258911
Validation loss: 2.848090132077535

Epoch: 5| Step: 10
Training loss: 2.4526333808898926
Validation loss: 2.8438035051027932

Epoch: 5| Step: 11
Training loss: 3.4138307571411133
Validation loss: 2.842095891634623

Epoch: 45| Step: 0
Training loss: 3.024531126022339
Validation loss: 2.8384533325831094

Epoch: 5| Step: 1
Training loss: 3.364894390106201
Validation loss: 2.8344682157039642

Epoch: 5| Step: 2
Training loss: 3.2080070972442627
Validation loss: 2.831015239159266

Epoch: 5| Step: 3
Training loss: 2.9948627948760986
Validation loss: 2.8302050729592643

Epoch: 5| Step: 4
Training loss: 2.6419124603271484
Validation loss: 2.8305824995040894

Epoch: 5| Step: 5
Training loss: 3.498485565185547
Validation loss: 2.8321264882882438

Epoch: 5| Step: 6
Training loss: 2.452507495880127
Validation loss: 2.836240996917089

Epoch: 5| Step: 7
Training loss: 3.08243465423584
Validation loss: 2.818732092777888

Epoch: 5| Step: 8
Training loss: 2.4704647064208984
Validation loss: 2.8161178727944693

Epoch: 5| Step: 9
Training loss: 3.470083236694336
Validation loss: 2.815051794052124

Epoch: 5| Step: 10
Training loss: 3.0265088081359863
Validation loss: 2.8130251467227936

Epoch: 5| Step: 11
Training loss: 3.488528251647949
Validation loss: 2.808778405189514

Epoch: 46| Step: 0
Training loss: 2.834552049636841
Validation loss: 2.805564800898234

Epoch: 5| Step: 1
Training loss: 2.9940707683563232
Validation loss: 2.8004051049550376

Epoch: 5| Step: 2
Training loss: 2.546619415283203
Validation loss: 2.797599067290624

Epoch: 5| Step: 3
Training loss: 2.7649378776550293
Validation loss: 2.793283681074778

Epoch: 5| Step: 4
Training loss: 2.8632454872131348
Validation loss: 2.792479077974955

Epoch: 5| Step: 5
Training loss: 3.1077637672424316
Validation loss: 2.787799914677938

Epoch: 5| Step: 6
Training loss: 3.7137160301208496
Validation loss: 2.7847885886828103

Epoch: 5| Step: 7
Training loss: 3.0246574878692627
Validation loss: 2.7830420633157096

Epoch: 5| Step: 8
Training loss: 2.5908074378967285
Validation loss: 2.778246437509855

Epoch: 5| Step: 9
Training loss: 3.408782482147217
Validation loss: 2.7755695283412933

Epoch: 5| Step: 10
Training loss: 3.0817408561706543
Validation loss: 2.772680471340815

Epoch: 5| Step: 11
Training loss: 3.062652349472046
Validation loss: 2.774592250585556

Epoch: 47| Step: 0
Training loss: 2.8148605823516846
Validation loss: 2.7755386432011924

Epoch: 5| Step: 1
Training loss: 2.7436306476593018
Validation loss: 2.770146002372106

Epoch: 5| Step: 2
Training loss: 3.0034339427948
Validation loss: 2.7634958227475486

Epoch: 5| Step: 3
Training loss: 2.4931836128234863
Validation loss: 2.758002827564875

Epoch: 5| Step: 4
Training loss: 2.94462251663208
Validation loss: 2.7561443050702414

Epoch: 5| Step: 5
Training loss: 3.8609416484832764
Validation loss: 2.7545127669970193

Epoch: 5| Step: 6
Training loss: 3.071782350540161
Validation loss: 2.7497226198514304

Epoch: 5| Step: 7
Training loss: 3.2264418601989746
Validation loss: 2.746920416752497

Epoch: 5| Step: 8
Training loss: 2.724787473678589
Validation loss: 2.74316198627154

Epoch: 5| Step: 9
Training loss: 2.557502269744873
Validation loss: 2.7404682834943137

Epoch: 5| Step: 10
Training loss: 2.961905002593994
Validation loss: 2.73887966076533

Epoch: 5| Step: 11
Training loss: 3.658595561981201
Validation loss: 2.735829015572866

Epoch: 48| Step: 0
Training loss: 3.108004331588745
Validation loss: 2.7312161326408386

Epoch: 5| Step: 1
Training loss: 3.52148699760437
Validation loss: 2.7286541759967804

Epoch: 5| Step: 2
Training loss: 2.9083030223846436
Validation loss: 2.724631498257319

Epoch: 5| Step: 3
Training loss: 3.356330394744873
Validation loss: 2.722631812095642

Epoch: 5| Step: 4
Training loss: 2.823296070098877
Validation loss: 2.72318368156751

Epoch: 5| Step: 5
Training loss: 2.7165820598602295
Validation loss: 2.7234291434288025

Epoch: 5| Step: 6
Training loss: 2.508145809173584
Validation loss: 2.718958785136541

Epoch: 5| Step: 7
Training loss: 2.9427077770233154
Validation loss: 2.71882231036822

Epoch: 5| Step: 8
Training loss: 3.3085949420928955
Validation loss: 2.729991912841797

Epoch: 5| Step: 9
Training loss: 2.3993217945098877
Validation loss: 2.712007522583008

Epoch: 5| Step: 10
Training loss: 2.7421388626098633
Validation loss: 2.702248384555181

Epoch: 5| Step: 11
Training loss: 2.097233772277832
Validation loss: 2.7049576143423715

Epoch: 49| Step: 0
Training loss: 2.996216297149658
Validation loss: 2.703458696603775

Epoch: 5| Step: 1
Training loss: 2.944364070892334
Validation loss: 2.699360281229019

Epoch: 5| Step: 2
Training loss: 2.8423516750335693
Validation loss: 2.697246789932251

Epoch: 5| Step: 3
Training loss: 2.976102352142334
Validation loss: 2.6940567096074424

Epoch: 5| Step: 4
Training loss: 2.2988038063049316
Validation loss: 2.6916695634524026

Epoch: 5| Step: 5
Training loss: 2.91121506690979
Validation loss: 2.6869729657967887

Epoch: 5| Step: 6
Training loss: 3.2967307567596436
Validation loss: 2.689325273036957

Epoch: 5| Step: 7
Training loss: 3.195152997970581
Validation loss: 2.682067463795344

Epoch: 5| Step: 8
Training loss: 2.5921101570129395
Validation loss: 2.678696562846502

Epoch: 5| Step: 9
Training loss: 2.611778974533081
Validation loss: 2.679746985435486

Epoch: 5| Step: 10
Training loss: 3.0373005867004395
Validation loss: 2.673726409673691

Epoch: 5| Step: 11
Training loss: 3.3241689205169678
Validation loss: 2.6711463779211044

Epoch: 50| Step: 0
Training loss: 3.0352814197540283
Validation loss: 2.6692460775375366

Epoch: 5| Step: 1
Training loss: 3.095796823501587
Validation loss: 2.667163292566935

Epoch: 5| Step: 2
Training loss: 2.6373543739318848
Validation loss: 2.6649995744228363

Epoch: 5| Step: 3
Training loss: 3.305823564529419
Validation loss: 2.661166171232859

Epoch: 5| Step: 4
Training loss: 2.719794750213623
Validation loss: 2.65749654173851

Epoch: 5| Step: 5
Training loss: 2.6822195053100586
Validation loss: 2.6549015641212463

Epoch: 5| Step: 6
Training loss: 2.6807167530059814
Validation loss: 2.6537522872289023

Epoch: 5| Step: 7
Training loss: 2.7044546604156494
Validation loss: 2.649891128142675

Epoch: 5| Step: 8
Training loss: 2.7898826599121094
Validation loss: 2.645835985740026

Epoch: 5| Step: 9
Training loss: 3.201925277709961
Validation loss: 2.641167094310125

Epoch: 5| Step: 10
Training loss: 2.688778877258301
Validation loss: 2.6387663980325065

Epoch: 5| Step: 11
Training loss: 2.0054829120635986
Validation loss: 2.6369716425736747

Testing loss: 2.2512785822367496
