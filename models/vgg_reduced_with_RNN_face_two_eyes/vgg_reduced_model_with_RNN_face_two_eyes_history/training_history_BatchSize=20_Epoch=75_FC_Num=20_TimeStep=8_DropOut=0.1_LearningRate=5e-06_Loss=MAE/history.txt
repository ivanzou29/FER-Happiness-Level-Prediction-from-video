Epoch: 1| Step: 0
Training loss: 5.91165018081665
Validation loss: 5.343164126078288

Epoch: 5| Step: 1
Training loss: 6.6101179122924805
Validation loss: 5.341656943162282

Epoch: 5| Step: 2
Training loss: 4.503771781921387
Validation loss: 5.340191821257274

Epoch: 5| Step: 3
Training loss: 5.882335662841797
Validation loss: 5.3388601541519165

Epoch: 5| Step: 4
Training loss: 5.896252155303955
Validation loss: 5.3375415205955505

Epoch: 5| Step: 5
Training loss: 4.799169540405273
Validation loss: 5.336315453052521

Epoch: 5| Step: 6
Training loss: 5.3786749839782715
Validation loss: 5.335061430931091

Epoch: 5| Step: 7
Training loss: 5.191432476043701
Validation loss: 5.333829740683238

Epoch: 5| Step: 8
Training loss: 5.081244468688965
Validation loss: 5.332560161749522

Epoch: 5| Step: 9
Training loss: 4.174714088439941
Validation loss: 5.331359565258026

Epoch: 5| Step: 10
Training loss: 5.809660911560059
Validation loss: 5.330023487408956

Epoch: 5| Step: 11
Training loss: 6.491208076477051
Validation loss: 5.328685402870178

Epoch: 2| Step: 0
Training loss: 5.337034702301025
Validation loss: 5.3273195425669355

Epoch: 5| Step: 1
Training loss: 4.541743278503418
Validation loss: 5.325928290685018

Epoch: 5| Step: 2
Training loss: 5.982499599456787
Validation loss: 5.324489216009776

Epoch: 5| Step: 3
Training loss: 5.011605262756348
Validation loss: 5.322966118653615

Epoch: 5| Step: 4
Training loss: 5.8499250411987305
Validation loss: 5.321390986442566

Epoch: 5| Step: 5
Training loss: 5.741730690002441
Validation loss: 5.3197668592135114

Epoch: 5| Step: 6
Training loss: 5.064278602600098
Validation loss: 5.318037768205007

Epoch: 5| Step: 7
Training loss: 6.372471809387207
Validation loss: 5.316272675991058

Epoch: 5| Step: 8
Training loss: 5.767747402191162
Validation loss: 5.314442773660024

Epoch: 5| Step: 9
Training loss: 4.925878047943115
Validation loss: 5.312451819578807

Epoch: 5| Step: 10
Training loss: 4.839377403259277
Validation loss: 5.310408294200897

Epoch: 5| Step: 11
Training loss: 4.551667213439941
Validation loss: 5.308347404003143

Epoch: 3| Step: 0
Training loss: 6.552617073059082
Validation loss: 5.306152522563934

Epoch: 5| Step: 1
Training loss: 5.0609869956970215
Validation loss: 5.3038110335667925

Epoch: 5| Step: 2
Training loss: 5.188471794128418
Validation loss: 5.30139164129893

Epoch: 5| Step: 3
Training loss: 5.871783256530762
Validation loss: 5.298973659674327

Epoch: 5| Step: 4
Training loss: 5.899661540985107
Validation loss: 5.296239018440247

Epoch: 5| Step: 5
Training loss: 4.615904808044434
Validation loss: 5.29360955953598

Epoch: 5| Step: 6
Training loss: 5.4572858810424805
Validation loss: 5.290738761425018

Epoch: 5| Step: 7
Training loss: 4.223103046417236
Validation loss: 5.287782867749532

Epoch: 5| Step: 8
Training loss: 5.078326225280762
Validation loss: 5.284795482953389

Epoch: 5| Step: 9
Training loss: 5.794839859008789
Validation loss: 5.2816968361536665

Epoch: 5| Step: 10
Training loss: 5.26737642288208
Validation loss: 5.278335253397624

Epoch: 5| Step: 11
Training loss: 5.227502822875977
Validation loss: 5.274741351604462

Epoch: 4| Step: 0
Training loss: 4.948319911956787
Validation loss: 5.271180709203084

Epoch: 5| Step: 1
Training loss: 5.234334945678711
Validation loss: 5.267483671506246

Epoch: 5| Step: 2
Training loss: 5.809390068054199
Validation loss: 5.263441165288289

Epoch: 5| Step: 3
Training loss: 5.121331214904785
Validation loss: 5.259410520394643

Epoch: 5| Step: 4
Training loss: 5.824491024017334
Validation loss: 5.255277077356975

Epoch: 5| Step: 5
Training loss: 5.13032341003418
Validation loss: 5.251005570093791

Epoch: 5| Step: 6
Training loss: 5.998757362365723
Validation loss: 5.246394395828247

Epoch: 5| Step: 7
Training loss: 5.3972320556640625
Validation loss: 5.2417130668958025

Epoch: 5| Step: 8
Training loss: 5.274473667144775
Validation loss: 5.236971298853557

Epoch: 5| Step: 9
Training loss: 5.260706901550293
Validation loss: 5.232182621955872

Epoch: 5| Step: 10
Training loss: 4.9454240798950195
Validation loss: 5.226997335751851

Epoch: 5| Step: 11
Training loss: 3.1735832691192627
Validation loss: 5.22189199924469

Epoch: 5| Step: 0
Training loss: 4.410489559173584
Validation loss: 5.216438730557759

Epoch: 5| Step: 1
Training loss: 4.422783851623535
Validation loss: 5.210978249708812

Epoch: 5| Step: 2
Training loss: 6.9336113929748535
Validation loss: 5.205330530802409

Epoch: 5| Step: 3
Training loss: 5.445700168609619
Validation loss: 5.199102938175201

Epoch: 5| Step: 4
Training loss: 5.360221862792969
Validation loss: 5.192872444788615

Epoch: 5| Step: 5
Training loss: 4.818381309509277
Validation loss: 5.186368803183238

Epoch: 5| Step: 6
Training loss: 5.009941577911377
Validation loss: 5.179619053999583

Epoch: 5| Step: 7
Training loss: 5.4541015625
Validation loss: 5.172473589579265

Epoch: 5| Step: 8
Training loss: 4.498979091644287
Validation loss: 5.165207614501317

Epoch: 5| Step: 9
Training loss: 5.149635314941406
Validation loss: 5.1574813524882

Epoch: 5| Step: 10
Training loss: 6.428308010101318
Validation loss: 5.149864157040914

Epoch: 5| Step: 11
Training loss: 4.653164386749268
Validation loss: 5.141742547353108

Epoch: 6| Step: 0
Training loss: 5.185944557189941
Validation loss: 5.133161664009094

Epoch: 5| Step: 1
Training loss: 5.338313102722168
Validation loss: 5.124535818894704

Epoch: 5| Step: 2
Training loss: 4.576897144317627
Validation loss: 5.115807672341664

Epoch: 5| Step: 3
Training loss: 6.437050819396973
Validation loss: 5.106698075930278

Epoch: 5| Step: 4
Training loss: 4.016697406768799
Validation loss: 5.097620348135631

Epoch: 5| Step: 5
Training loss: 5.308016777038574
Validation loss: 5.088165769974391

Epoch: 5| Step: 6
Training loss: 5.064091682434082
Validation loss: 5.078818082809448

Epoch: 5| Step: 7
Training loss: 4.080615043640137
Validation loss: 5.068809429804484

Epoch: 5| Step: 8
Training loss: 6.177884101867676
Validation loss: 5.0591614445050554

Epoch: 5| Step: 9
Training loss: 5.390124797821045
Validation loss: 5.049269338448842

Epoch: 5| Step: 10
Training loss: 5.403632164001465
Validation loss: 5.039116144180298

Epoch: 5| Step: 11
Training loss: 4.112564563751221
Validation loss: 5.029351353645325

Epoch: 7| Step: 0
Training loss: 3.7482151985168457
Validation loss: 5.0193020304044085

Epoch: 5| Step: 1
Training loss: 3.881582736968994
Validation loss: 5.009206732114156

Epoch: 5| Step: 2
Training loss: 6.163233757019043
Validation loss: 4.9991008043289185

Epoch: 5| Step: 3
Training loss: 5.983803749084473
Validation loss: 4.9890926877657575

Epoch: 5| Step: 4
Training loss: 6.023229122161865
Validation loss: 4.979126413663228

Epoch: 5| Step: 5
Training loss: 4.910399436950684
Validation loss: 4.969353179136912

Epoch: 5| Step: 6
Training loss: 4.652569770812988
Validation loss: 4.959513962268829

Epoch: 5| Step: 7
Training loss: 5.429495334625244
Validation loss: 4.94993132352829

Epoch: 5| Step: 8
Training loss: 4.082156181335449
Validation loss: 4.940507372220357

Epoch: 5| Step: 9
Training loss: 5.4818291664123535
Validation loss: 4.931075394153595

Epoch: 5| Step: 10
Training loss: 5.847836017608643
Validation loss: 4.921973705291748

Epoch: 5| Step: 11
Training loss: 1.834048867225647
Validation loss: 4.913337210814158

Epoch: 8| Step: 0
Training loss: 4.735694885253906
Validation loss: 4.9051235516866045

Epoch: 5| Step: 1
Training loss: 5.263461112976074
Validation loss: 4.898055573304494

Epoch: 5| Step: 2
Training loss: 4.9141130447387695
Validation loss: 4.890421688556671

Epoch: 5| Step: 3
Training loss: 4.851473331451416
Validation loss: 4.883155465126038

Epoch: 5| Step: 4
Training loss: 4.707821846008301
Validation loss: 4.876150945822398

Epoch: 5| Step: 5
Training loss: 4.877986907958984
Validation loss: 4.869423568248749

Epoch: 5| Step: 6
Training loss: 4.060340404510498
Validation loss: 4.862747629483541

Epoch: 5| Step: 7
Training loss: 4.250451564788818
Validation loss: 4.856020311514537

Epoch: 5| Step: 8
Training loss: 5.104358673095703
Validation loss: 4.849116404851277

Epoch: 5| Step: 9
Training loss: 5.1620354652404785
Validation loss: 4.842497189839681

Epoch: 5| Step: 10
Training loss: 6.805203437805176
Validation loss: 4.836164037386577

Epoch: 5| Step: 11
Training loss: 3.8126354217529297
Validation loss: 4.829552372296651

Epoch: 9| Step: 0
Training loss: 5.18034553527832
Validation loss: 4.822723845640819

Epoch: 5| Step: 1
Training loss: 5.6628923416137695
Validation loss: 4.8169242938359575

Epoch: 5| Step: 2
Training loss: 4.450211524963379
Validation loss: 4.811075667540233

Epoch: 5| Step: 3
Training loss: 5.144601345062256
Validation loss: 4.805572589238484

Epoch: 5| Step: 4
Training loss: 5.662012577056885
Validation loss: 4.800230046113332

Epoch: 5| Step: 5
Training loss: 4.356716156005859
Validation loss: 4.79490311940511

Epoch: 5| Step: 6
Training loss: 5.128287315368652
Validation loss: 4.790026366710663

Epoch: 5| Step: 7
Training loss: 4.832472801208496
Validation loss: 4.784766455491384

Epoch: 5| Step: 8
Training loss: 4.211075782775879
Validation loss: 4.7797128558158875

Epoch: 5| Step: 9
Training loss: 4.688727378845215
Validation loss: 4.774355053901672

Epoch: 5| Step: 10
Training loss: 4.262607574462891
Validation loss: 4.7690573533376055

Epoch: 5| Step: 11
Training loss: 5.570111274719238
Validation loss: 4.764215876658757

Epoch: 10| Step: 0
Training loss: 5.478174686431885
Validation loss: 4.759096185366313

Epoch: 5| Step: 1
Training loss: 5.7871317863464355
Validation loss: 4.754502554734548

Epoch: 5| Step: 2
Training loss: 5.020799160003662
Validation loss: 4.749835014343262

Epoch: 5| Step: 3
Training loss: 5.086096286773682
Validation loss: 4.745260645945867

Epoch: 5| Step: 4
Training loss: 4.851177215576172
Validation loss: 4.7408323884010315

Epoch: 5| Step: 5
Training loss: 5.159734725952148
Validation loss: 4.735885739326477

Epoch: 5| Step: 6
Training loss: 3.9381232261657715
Validation loss: 4.730591595172882

Epoch: 5| Step: 7
Training loss: 4.530850410461426
Validation loss: 4.725091060002645

Epoch: 5| Step: 8
Training loss: 3.848680019378662
Validation loss: 4.719862143198649

Epoch: 5| Step: 9
Training loss: 5.163910865783691
Validation loss: 4.714657594760259

Epoch: 5| Step: 10
Training loss: 3.995312452316284
Validation loss: 4.709640125433604

Epoch: 5| Step: 11
Training loss: 6.007057189941406
Validation loss: 4.704633712768555

Epoch: 11| Step: 0
Training loss: 5.068073272705078
Validation loss: 4.699815273284912

Epoch: 5| Step: 1
Training loss: 5.629552364349365
Validation loss: 4.694653918345769

Epoch: 5| Step: 2
Training loss: 4.721431732177734
Validation loss: 4.689402520656586

Epoch: 5| Step: 3
Training loss: 4.683650016784668
Validation loss: 4.684000273545583

Epoch: 5| Step: 4
Training loss: 4.193844318389893
Validation loss: 4.678410430749257

Epoch: 5| Step: 5
Training loss: 4.572166442871094
Validation loss: 4.673083821932475

Epoch: 5| Step: 6
Training loss: 4.791736602783203
Validation loss: 4.6673583984375

Epoch: 5| Step: 7
Training loss: 5.2890119552612305
Validation loss: 4.662376840909322

Epoch: 5| Step: 8
Training loss: 4.210004806518555
Validation loss: 4.656827449798584

Epoch: 5| Step: 9
Training loss: 5.135676383972168
Validation loss: 4.651426672935486

Epoch: 5| Step: 10
Training loss: 4.121365547180176
Validation loss: 4.645930528640747

Epoch: 5| Step: 11
Training loss: 4.953655242919922
Validation loss: 4.640425145626068

Epoch: 12| Step: 0
Training loss: 4.693374156951904
Validation loss: 4.635080635547638

Epoch: 5| Step: 1
Training loss: 4.375344753265381
Validation loss: 4.6296316385269165

Epoch: 5| Step: 2
Training loss: 4.233776092529297
Validation loss: 4.624231268962224

Epoch: 5| Step: 3
Training loss: 4.130860328674316
Validation loss: 4.618890245755513

Epoch: 5| Step: 4
Training loss: 5.136754512786865
Validation loss: 4.613279481728871

Epoch: 5| Step: 5
Training loss: 4.150367736816406
Validation loss: 4.607687671979268

Epoch: 5| Step: 6
Training loss: 4.731938362121582
Validation loss: 4.602321743965149

Epoch: 5| Step: 7
Training loss: 4.441065788269043
Validation loss: 4.597019652525584

Epoch: 5| Step: 8
Training loss: 5.477985858917236
Validation loss: 4.591206838687261

Epoch: 5| Step: 9
Training loss: 5.6755242347717285
Validation loss: 4.585253397623698

Epoch: 5| Step: 10
Training loss: 4.899350166320801
Validation loss: 4.579414228598277

Epoch: 5| Step: 11
Training loss: 3.7187516689300537
Validation loss: 4.5735516746838885

Epoch: 13| Step: 0
Training loss: 4.728306293487549
Validation loss: 4.568096558252971

Epoch: 5| Step: 1
Training loss: 4.741817474365234
Validation loss: 4.562155365943909

Epoch: 5| Step: 2
Training loss: 5.269797325134277
Validation loss: 4.5560084482034044

Epoch: 5| Step: 3
Training loss: 4.942224025726318
Validation loss: 4.550419747829437

Epoch: 5| Step: 4
Training loss: 3.3024864196777344
Validation loss: 4.544343411922455

Epoch: 5| Step: 5
Training loss: 5.022871017456055
Validation loss: 4.53864445288976

Epoch: 5| Step: 6
Training loss: 5.218952178955078
Validation loss: 4.532746811707814

Epoch: 5| Step: 7
Training loss: 4.272393703460693
Validation loss: 4.526889602343242

Epoch: 5| Step: 8
Training loss: 4.52860164642334
Validation loss: 4.520452817281087

Epoch: 5| Step: 9
Training loss: 5.108809471130371
Validation loss: 4.514301995436351

Epoch: 5| Step: 10
Training loss: 4.180253028869629
Validation loss: 4.508395552635193

Epoch: 5| Step: 11
Training loss: 3.3415307998657227
Validation loss: 4.50198679169019

Epoch: 14| Step: 0
Training loss: 4.0994086265563965
Validation loss: 4.496563871701558

Epoch: 5| Step: 1
Training loss: 4.940610885620117
Validation loss: 4.491192827622096

Epoch: 5| Step: 2
Training loss: 4.940019130706787
Validation loss: 4.485336095094681

Epoch: 5| Step: 3
Training loss: 4.439898490905762
Validation loss: 4.479504416386287

Epoch: 5| Step: 4
Training loss: 4.858599662780762
Validation loss: 4.474167088667552

Epoch: 5| Step: 5
Training loss: 5.112043380737305
Validation loss: 4.468934794267018

Epoch: 5| Step: 6
Training loss: 3.947800397872925
Validation loss: 4.463605562845866

Epoch: 5| Step: 7
Training loss: 4.720451354980469
Validation loss: 4.458661913871765

Epoch: 5| Step: 8
Training loss: 5.44803524017334
Validation loss: 4.4533378183841705

Epoch: 5| Step: 9
Training loss: 3.7006797790527344
Validation loss: 4.448143422603607

Epoch: 5| Step: 10
Training loss: 4.51837682723999
Validation loss: 4.442066788673401

Epoch: 5| Step: 11
Training loss: 2.6955618858337402
Validation loss: 4.4365850786368055

Epoch: 15| Step: 0
Training loss: 4.751634120941162
Validation loss: 4.431745986143748

Epoch: 5| Step: 1
Training loss: 3.7595887184143066
Validation loss: 4.4261868596076965

Epoch: 5| Step: 2
Training loss: 4.713970184326172
Validation loss: 4.42127537727356

Epoch: 5| Step: 3
Training loss: 4.242392539978027
Validation loss: 4.415393630663554

Epoch: 5| Step: 4
Training loss: 4.218942165374756
Validation loss: 4.40874919295311

Epoch: 5| Step: 5
Training loss: 5.002255916595459
Validation loss: 4.402728686730067

Epoch: 5| Step: 6
Training loss: 4.3267035484313965
Validation loss: 4.396959235270818

Epoch: 5| Step: 7
Training loss: 4.290772914886475
Validation loss: 4.391130646069844

Epoch: 5| Step: 8
Training loss: 4.611506462097168
Validation loss: 4.385280559460322

Epoch: 5| Step: 9
Training loss: 4.769343852996826
Validation loss: 4.379152486721675

Epoch: 5| Step: 10
Training loss: 5.05832576751709
Validation loss: 4.37213608622551

Epoch: 5| Step: 11
Training loss: 4.260077476501465
Validation loss: 4.3658793568611145

Epoch: 16| Step: 0
Training loss: 4.396723747253418
Validation loss: 4.359750757614772

Epoch: 5| Step: 1
Training loss: 3.820538282394409
Validation loss: 4.353890101114909

Epoch: 5| Step: 2
Training loss: 3.561399459838867
Validation loss: 4.348168849945068

Epoch: 5| Step: 3
Training loss: 3.463014602661133
Validation loss: 4.342002312342326

Epoch: 5| Step: 4
Training loss: 4.248452186584473
Validation loss: 4.336076309283574

Epoch: 5| Step: 5
Training loss: 3.6432747840881348
Validation loss: 4.32984138528506

Epoch: 5| Step: 6
Training loss: 4.743350028991699
Validation loss: 4.323340982198715

Epoch: 5| Step: 7
Training loss: 6.026058197021484
Validation loss: 4.317178428173065

Epoch: 5| Step: 8
Training loss: 4.576809883117676
Validation loss: 4.310392359892528

Epoch: 5| Step: 9
Training loss: 4.346965789794922
Validation loss: 4.304672876993815

Epoch: 5| Step: 10
Training loss: 6.008395195007324
Validation loss: 4.299006621042888

Epoch: 5| Step: 11
Training loss: 5.090392112731934
Validation loss: 4.2931487162907915

Epoch: 17| Step: 0
Training loss: 4.056520938873291
Validation loss: 4.286891768376033

Epoch: 5| Step: 1
Training loss: 4.302674293518066
Validation loss: 4.28076845407486

Epoch: 5| Step: 2
Training loss: 5.461244106292725
Validation loss: 4.275395721197128

Epoch: 5| Step: 3
Training loss: 4.508272647857666
Validation loss: 4.269811590512593

Epoch: 5| Step: 4
Training loss: 3.348454236984253
Validation loss: 4.263815720876058

Epoch: 5| Step: 5
Training loss: 4.226809978485107
Validation loss: 4.258119304974874

Epoch: 5| Step: 6
Training loss: 4.527270793914795
Validation loss: 4.252053002516429

Epoch: 5| Step: 7
Training loss: 4.3758320808410645
Validation loss: 4.24658281604449

Epoch: 5| Step: 8
Training loss: 4.43959903717041
Validation loss: 4.240084042151769

Epoch: 5| Step: 9
Training loss: 4.703616142272949
Validation loss: 4.235123197237651

Epoch: 5| Step: 10
Training loss: 4.362805366516113
Validation loss: 4.229483862717946

Epoch: 5| Step: 11
Training loss: 4.019426345825195
Validation loss: 4.223706086476644

Epoch: 18| Step: 0
Training loss: 4.7639055252075195
Validation loss: 4.216919402281444

Epoch: 5| Step: 1
Training loss: 4.386968612670898
Validation loss: 4.211826831102371

Epoch: 5| Step: 2
Training loss: 4.835670471191406
Validation loss: 4.206009924411774

Epoch: 5| Step: 3
Training loss: 4.022395133972168
Validation loss: 4.199855963389079

Epoch: 5| Step: 4
Training loss: 4.969461917877197
Validation loss: 4.194294293721517

Epoch: 5| Step: 5
Training loss: 4.588526248931885
Validation loss: 4.188144405682881

Epoch: 5| Step: 6
Training loss: 3.5479488372802734
Validation loss: 4.1826441784699755

Epoch: 5| Step: 7
Training loss: 3.951695203781128
Validation loss: 4.176723758379619

Epoch: 5| Step: 8
Training loss: 4.181318759918213
Validation loss: 4.171021242936452

Epoch: 5| Step: 9
Training loss: 4.246491432189941
Validation loss: 4.165202548106511

Epoch: 5| Step: 10
Training loss: 4.521467685699463
Validation loss: 4.159170349438985

Epoch: 5| Step: 11
Training loss: 2.024846076965332
Validation loss: 4.153481483459473

Epoch: 19| Step: 0
Training loss: 3.995831251144409
Validation loss: 4.147647221883138

Epoch: 5| Step: 1
Training loss: 4.865958213806152
Validation loss: 4.143284986416499

Epoch: 5| Step: 2
Training loss: 4.033329963684082
Validation loss: 4.138187348842621

Epoch: 5| Step: 3
Training loss: 5.312119007110596
Validation loss: 4.133081396420796

Epoch: 5| Step: 4
Training loss: 4.727665901184082
Validation loss: 4.1275893449783325

Epoch: 5| Step: 5
Training loss: 4.934018611907959
Validation loss: 4.122816950082779

Epoch: 5| Step: 6
Training loss: 3.593432664871216
Validation loss: 4.116652756929398

Epoch: 5| Step: 7
Training loss: 3.9388365745544434
Validation loss: 4.111387809117635

Epoch: 5| Step: 8
Training loss: 4.09238338470459
Validation loss: 4.105822304884593

Epoch: 5| Step: 9
Training loss: 3.1122069358825684
Validation loss: 4.100248843431473

Epoch: 5| Step: 10
Training loss: 3.8689656257629395
Validation loss: 4.09448163708051

Epoch: 5| Step: 11
Training loss: 6.195936679840088
Validation loss: 4.089177747567494

Epoch: 20| Step: 0
Training loss: 3.7298855781555176
Validation loss: 4.083278586467107

Epoch: 5| Step: 1
Training loss: 4.459630489349365
Validation loss: 4.0774842003981275

Epoch: 5| Step: 2
Training loss: 3.8550498485565186
Validation loss: 4.071778843800227

Epoch: 5| Step: 3
Training loss: 3.792426586151123
Validation loss: 4.066352307796478

Epoch: 5| Step: 4
Training loss: 4.400230884552002
Validation loss: 4.06169315179189

Epoch: 5| Step: 5
Training loss: 3.8205313682556152
Validation loss: 4.055794417858124

Epoch: 5| Step: 6
Training loss: 3.3873400688171387
Validation loss: 4.0515808661778765

Epoch: 5| Step: 7
Training loss: 4.397036075592041
Validation loss: 4.045509974161784

Epoch: 5| Step: 8
Training loss: 4.223654747009277
Validation loss: 4.040625194708507

Epoch: 5| Step: 9
Training loss: 4.708447456359863
Validation loss: 4.0360813438892365

Epoch: 5| Step: 10
Training loss: 4.985232353210449
Validation loss: 4.031397263209025

Epoch: 5| Step: 11
Training loss: 6.328843116760254
Validation loss: 4.025527487198512

Epoch: 21| Step: 0
Training loss: 3.601198673248291
Validation loss: 4.019924173752467

Epoch: 5| Step: 1
Training loss: 4.264914512634277
Validation loss: 4.014914413293202

Epoch: 5| Step: 2
Training loss: 3.921083927154541
Validation loss: 4.009238978226979

Epoch: 5| Step: 3
Training loss: 4.260135650634766
Validation loss: 4.00373978416125

Epoch: 5| Step: 4
Training loss: 4.106729030609131
Validation loss: 3.998368958632151

Epoch: 5| Step: 5
Training loss: 4.1311421394348145
Validation loss: 3.9926810761292777

Epoch: 5| Step: 6
Training loss: 4.917897701263428
Validation loss: 3.9875351389249167

Epoch: 5| Step: 7
Training loss: 3.916550397872925
Validation loss: 3.981990079085032

Epoch: 5| Step: 8
Training loss: 4.697554111480713
Validation loss: 3.9763028721014657

Epoch: 5| Step: 9
Training loss: 3.748016357421875
Validation loss: 3.970943331718445

Epoch: 5| Step: 10
Training loss: 4.23260498046875
Validation loss: 3.96539443731308

Epoch: 5| Step: 11
Training loss: 2.7319388389587402
Validation loss: 3.960464745759964

Epoch: 22| Step: 0
Training loss: 3.812431812286377
Validation loss: 3.955235411723455

Epoch: 5| Step: 1
Training loss: 4.447809219360352
Validation loss: 3.9506691793600717

Epoch: 5| Step: 2
Training loss: 3.999082565307617
Validation loss: 3.9455994069576263

Epoch: 5| Step: 3
Training loss: 4.767184257507324
Validation loss: 3.9396890699863434

Epoch: 5| Step: 4
Training loss: 3.742579221725464
Validation loss: 3.9324892163276672

Epoch: 5| Step: 5
Training loss: 4.736155033111572
Validation loss: 3.9275133311748505

Epoch: 5| Step: 6
Training loss: 3.961035966873169
Validation loss: 3.9219376842180886

Epoch: 5| Step: 7
Training loss: 3.9150185585021973
Validation loss: 3.916338841120402

Epoch: 5| Step: 8
Training loss: 4.510697364807129
Validation loss: 3.9103002349535623

Epoch: 5| Step: 9
Training loss: 3.5062828063964844
Validation loss: 3.9054010113080344

Epoch: 5| Step: 10
Training loss: 3.7065463066101074
Validation loss: 3.900514076153437

Epoch: 5| Step: 11
Training loss: 2.668579578399658
Validation loss: 3.8948659797509513

Epoch: 23| Step: 0
Training loss: 4.272897243499756
Validation loss: 3.888705680767695

Epoch: 5| Step: 1
Training loss: 4.186293125152588
Validation loss: 3.8827202916145325

Epoch: 5| Step: 2
Training loss: 3.9252731800079346
Validation loss: 3.877165744702021

Epoch: 5| Step: 3
Training loss: 4.283185005187988
Validation loss: 3.8724266787370047

Epoch: 5| Step: 4
Training loss: 3.7434990406036377
Validation loss: 3.8666800558567047

Epoch: 5| Step: 5
Training loss: 4.11367654800415
Validation loss: 3.861023098230362

Epoch: 5| Step: 6
Training loss: 4.177689552307129
Validation loss: 3.855342576901118

Epoch: 5| Step: 7
Training loss: 4.606071472167969
Validation loss: 3.8510027627150216

Epoch: 5| Step: 8
Training loss: 3.605617046356201
Validation loss: 3.8451576431592307

Epoch: 5| Step: 9
Training loss: 3.12961483001709
Validation loss: 3.8391537964344025

Epoch: 5| Step: 10
Training loss: 3.9877936840057373
Validation loss: 3.835044711828232

Epoch: 5| Step: 11
Training loss: 4.612269401550293
Validation loss: 3.8294444481531777

Epoch: 24| Step: 0
Training loss: 4.065523147583008
Validation loss: 3.8232273161411285

Epoch: 5| Step: 1
Training loss: 4.380609512329102
Validation loss: 3.8180498679478965

Epoch: 5| Step: 2
Training loss: 3.6421303749084473
Validation loss: 3.812224189440409

Epoch: 5| Step: 3
Training loss: 4.3034796714782715
Validation loss: 3.8070746262868247

Epoch: 5| Step: 4
Training loss: 4.215485572814941
Validation loss: 3.801470090945562

Epoch: 5| Step: 5
Training loss: 4.668334007263184
Validation loss: 3.795916805664698

Epoch: 5| Step: 6
Training loss: 3.332026243209839
Validation loss: 3.7901556392510733

Epoch: 5| Step: 7
Training loss: 3.6809113025665283
Validation loss: 3.7852098643779755

Epoch: 5| Step: 8
Training loss: 3.8034660816192627
Validation loss: 3.7797075609366098

Epoch: 5| Step: 9
Training loss: 3.6106972694396973
Validation loss: 3.7743721505006156

Epoch: 5| Step: 10
Training loss: 3.7805569171905518
Validation loss: 3.770051807165146

Epoch: 5| Step: 11
Training loss: 3.9301271438598633
Validation loss: 3.7641582588354745

Epoch: 25| Step: 0
Training loss: 3.046558141708374
Validation loss: 3.7594043016433716

Epoch: 5| Step: 1
Training loss: 4.168656349182129
Validation loss: 3.7533899446328483

Epoch: 5| Step: 2
Training loss: 4.144012928009033
Validation loss: 3.747925112644831

Epoch: 5| Step: 3
Training loss: 3.82133150100708
Validation loss: 3.743768940369288

Epoch: 5| Step: 4
Training loss: 3.9655864238739014
Validation loss: 3.7377953430016837

Epoch: 5| Step: 5
Training loss: 4.253214359283447
Validation loss: 3.7326314946015677

Epoch: 5| Step: 6
Training loss: 4.458797454833984
Validation loss: 3.7277694741884866

Epoch: 5| Step: 7
Training loss: 3.8049702644348145
Validation loss: 3.722616950670878

Epoch: 5| Step: 8
Training loss: 4.679258823394775
Validation loss: 3.7165395319461823

Epoch: 5| Step: 9
Training loss: 2.9912781715393066
Validation loss: 3.711440692345301

Epoch: 5| Step: 10
Training loss: 3.8457694053649902
Validation loss: 3.706669191519419

Epoch: 5| Step: 11
Training loss: 2.1013803482055664
Validation loss: 3.7007615864276886

Epoch: 26| Step: 0
Training loss: 4.673187255859375
Validation loss: 3.6959563493728638

Epoch: 5| Step: 1
Training loss: 3.538175106048584
Validation loss: 3.691567122936249

Epoch: 5| Step: 2
Training loss: 3.3450050354003906
Validation loss: 3.685657868782679

Epoch: 5| Step: 3
Training loss: 4.40224552154541
Validation loss: 3.6812413136164346

Epoch: 5| Step: 4
Training loss: 4.386795997619629
Validation loss: 3.6763104697068534

Epoch: 5| Step: 5
Training loss: 3.2180278301239014
Validation loss: 3.6709204614162445

Epoch: 5| Step: 6
Training loss: 3.5230560302734375
Validation loss: 3.6655574838320413

Epoch: 5| Step: 7
Training loss: 3.6850810050964355
Validation loss: 3.660753627618154

Epoch: 5| Step: 8
Training loss: 3.222083330154419
Validation loss: 3.6551768481731415

Epoch: 5| Step: 9
Training loss: 4.430662631988525
Validation loss: 3.650255471467972

Epoch: 5| Step: 10
Training loss: 3.8107409477233887
Validation loss: 3.6450455685456595

Epoch: 5| Step: 11
Training loss: 3.4790000915527344
Validation loss: 3.6409880220890045

Epoch: 27| Step: 0
Training loss: 3.039414167404175
Validation loss: 3.635312815507253

Epoch: 5| Step: 1
Training loss: 3.7819793224334717
Validation loss: 3.6300456623236337

Epoch: 5| Step: 2
Training loss: 3.2135162353515625
Validation loss: 3.6251972019672394

Epoch: 5| Step: 3
Training loss: 3.615466594696045
Validation loss: 3.619485149780909

Epoch: 5| Step: 4
Training loss: 3.9773383140563965
Validation loss: 3.6143491864204407

Epoch: 5| Step: 5
Training loss: 4.415085792541504
Validation loss: 3.6094504396120706

Epoch: 5| Step: 6
Training loss: 3.731950044631958
Validation loss: 3.6039382020632424

Epoch: 5| Step: 7
Training loss: 3.437990665435791
Validation loss: 3.598994721968969

Epoch: 5| Step: 8
Training loss: 3.661669969558716
Validation loss: 3.5938267409801483

Epoch: 5| Step: 9
Training loss: 4.242382526397705
Validation loss: 3.588285356760025

Epoch: 5| Step: 10
Training loss: 4.354973316192627
Validation loss: 3.58327787121137

Epoch: 5| Step: 11
Training loss: 3.8596696853637695
Validation loss: 3.5778146386146545

Epoch: 28| Step: 0
Training loss: 3.3591148853302
Validation loss: 3.5721588333447776

Epoch: 5| Step: 1
Training loss: 3.9178645610809326
Validation loss: 3.5669593115647635

Epoch: 5| Step: 2
Training loss: 4.156607151031494
Validation loss: 3.561772972345352

Epoch: 5| Step: 3
Training loss: 3.4330620765686035
Validation loss: 3.5563871661822

Epoch: 5| Step: 4
Training loss: 4.583028316497803
Validation loss: 3.5506215194861093

Epoch: 5| Step: 5
Training loss: 3.423020839691162
Validation loss: 3.545067568620046

Epoch: 5| Step: 6
Training loss: 3.656428575515747
Validation loss: 3.539580990870794

Epoch: 5| Step: 7
Training loss: 2.8478007316589355
Validation loss: 3.534300774335861

Epoch: 5| Step: 8
Training loss: 4.447925090789795
Validation loss: 3.5295860966046653

Epoch: 5| Step: 9
Training loss: 3.355757474899292
Validation loss: 3.523646871248881

Epoch: 5| Step: 10
Training loss: 3.583925247192383
Validation loss: 3.5188549359639487

Epoch: 5| Step: 11
Training loss: 3.904613971710205
Validation loss: 3.513075053691864

Epoch: 29| Step: 0
Training loss: 4.253990650177002
Validation loss: 3.508805066347122

Epoch: 5| Step: 1
Training loss: 2.744175434112549
Validation loss: 3.502533187468847

Epoch: 5| Step: 2
Training loss: 4.017538547515869
Validation loss: 3.4974143902460733

Epoch: 5| Step: 3
Training loss: 4.813416481018066
Validation loss: 3.4917094707489014

Epoch: 5| Step: 4
Training loss: 3.818816661834717
Validation loss: 3.486229360103607

Epoch: 5| Step: 5
Training loss: 3.824532985687256
Validation loss: 3.480764995018641

Epoch: 5| Step: 6
Training loss: 3.147195816040039
Validation loss: 3.4761533240477243

Epoch: 5| Step: 7
Training loss: 3.118380308151245
Validation loss: 3.470452924569448

Epoch: 5| Step: 8
Training loss: 3.425724506378174
Validation loss: 3.4660788079102836

Epoch: 5| Step: 9
Training loss: 3.629734754562378
Validation loss: 3.4598677257696786

Epoch: 5| Step: 10
Training loss: 3.3957290649414062
Validation loss: 3.454287717739741

Epoch: 5| Step: 11
Training loss: 3.3141613006591797
Validation loss: 3.449513773123423

Epoch: 30| Step: 0
Training loss: 3.267059326171875
Validation loss: 3.4446023603280387

Epoch: 5| Step: 1
Training loss: 4.018567085266113
Validation loss: 3.439631402492523

Epoch: 5| Step: 2
Training loss: 3.7295947074890137
Validation loss: 3.4342978497346244

Epoch: 5| Step: 3
Training loss: 3.3329615592956543
Validation loss: 3.4293543795744577

Epoch: 5| Step: 4
Training loss: 3.8946051597595215
Validation loss: 3.424861659606298

Epoch: 5| Step: 5
Training loss: 3.616917848587036
Validation loss: 3.4197194973627725

Epoch: 5| Step: 6
Training loss: 3.6604812145233154
Validation loss: 3.4145049452781677

Epoch: 5| Step: 7
Training loss: 3.3717598915100098
Validation loss: 3.409494996070862

Epoch: 5| Step: 8
Training loss: 3.7859160900115967
Validation loss: 3.4041803578535714

Epoch: 5| Step: 9
Training loss: 3.4727942943573
Validation loss: 3.399693340063095

Epoch: 5| Step: 10
Training loss: 3.468536853790283
Validation loss: 3.394499490658442

Epoch: 5| Step: 11
Training loss: 2.702800750732422
Validation loss: 3.38907382885615

Epoch: 31| Step: 0
Training loss: 2.893726348876953
Validation loss: 3.3836058477560678

Epoch: 5| Step: 1
Training loss: 3.661656141281128
Validation loss: 3.379334678252538

Epoch: 5| Step: 2
Training loss: 3.712186098098755
Validation loss: 3.375114639600118

Epoch: 5| Step: 3
Training loss: 3.4913711547851562
Validation loss: 3.3687520722548165

Epoch: 5| Step: 4
Training loss: 2.847637891769409
Validation loss: 3.363209625085195

Epoch: 5| Step: 5
Training loss: 3.866006374359131
Validation loss: 3.359283914168676

Epoch: 5| Step: 6
Training loss: 3.3018577098846436
Validation loss: 3.3536289632320404

Epoch: 5| Step: 7
Training loss: 3.3346779346466064
Validation loss: 3.348039666811625

Epoch: 5| Step: 8
Training loss: 3.4830498695373535
Validation loss: 3.3429738779862723

Epoch: 5| Step: 9
Training loss: 4.110557556152344
Validation loss: 3.3367405931154885

Epoch: 5| Step: 10
Training loss: 4.038872241973877
Validation loss: 3.3306629061698914

Epoch: 5| Step: 11
Training loss: 3.7832019329071045
Validation loss: 3.326033612092336

Epoch: 32| Step: 0
Training loss: 3.0479934215545654
Validation loss: 3.3192264835039773

Epoch: 5| Step: 1
Training loss: 3.4770827293395996
Validation loss: 3.3137218157450357

Epoch: 5| Step: 2
Training loss: 3.9908318519592285
Validation loss: 3.307840714852015

Epoch: 5| Step: 3
Training loss: 4.251263618469238
Validation loss: 3.3036248286565146

Epoch: 5| Step: 4
Training loss: 3.626392364501953
Validation loss: 3.2982427179813385

Epoch: 5| Step: 5
Training loss: 3.228628158569336
Validation loss: 3.2932374576727548

Epoch: 5| Step: 6
Training loss: 3.4508864879608154
Validation loss: 3.2870869239171348

Epoch: 5| Step: 7
Training loss: 3.258444309234619
Validation loss: 3.2826719085375466

Epoch: 5| Step: 8
Training loss: 3.00703763961792
Validation loss: 3.278187702099482

Epoch: 5| Step: 9
Training loss: 3.365320920944214
Validation loss: 3.272848437229792

Epoch: 5| Step: 10
Training loss: 3.769367218017578
Validation loss: 3.2680095036824546

Epoch: 5| Step: 11
Training loss: 1.8236825466156006
Validation loss: 3.262825836737951

Epoch: 33| Step: 0
Training loss: 3.0739071369171143
Validation loss: 3.25879575808843

Epoch: 5| Step: 1
Training loss: 4.2049102783203125
Validation loss: 3.2546713848908744

Epoch: 5| Step: 2
Training loss: 3.1800599098205566
Validation loss: 3.2500140964984894

Epoch: 5| Step: 3
Training loss: 3.7458252906799316
Validation loss: 3.2451103031635284

Epoch: 5| Step: 4
Training loss: 3.489184856414795
Validation loss: 3.2404890855153403

Epoch: 5| Step: 5
Training loss: 3.7587127685546875
Validation loss: 3.2360543608665466

Epoch: 5| Step: 6
Training loss: 3.6687285900115967
Validation loss: 3.232046922047933

Epoch: 5| Step: 7
Training loss: 2.9464831352233887
Validation loss: 3.2274102667967477

Epoch: 5| Step: 8
Training loss: 2.857585906982422
Validation loss: 3.2238723933696747

Epoch: 5| Step: 9
Training loss: 3.455451488494873
Validation loss: 3.2195636332035065

Epoch: 5| Step: 10
Training loss: 3.3460540771484375
Validation loss: 3.2147604723771415

Epoch: 5| Step: 11
Training loss: 2.6209259033203125
Validation loss: 3.2103833854198456

Epoch: 34| Step: 0
Training loss: 3.357973575592041
Validation loss: 3.2060931026935577

Epoch: 5| Step: 1
Training loss: 3.040431499481201
Validation loss: 3.201996107896169

Epoch: 5| Step: 2
Training loss: 3.6534409523010254
Validation loss: 3.197677969932556

Epoch: 5| Step: 3
Training loss: 4.449339389801025
Validation loss: 3.1931989987691245

Epoch: 5| Step: 4
Training loss: 2.582613468170166
Validation loss: 3.188166707754135

Epoch: 5| Step: 5
Training loss: 3.7790157794952393
Validation loss: 3.1847605804602304

Epoch: 5| Step: 6
Training loss: 3.7254691123962402
Validation loss: 3.180200765530268

Epoch: 5| Step: 7
Training loss: 3.6526870727539062
Validation loss: 3.175583819548289

Epoch: 5| Step: 8
Training loss: 2.619016647338867
Validation loss: 3.1717513501644135

Epoch: 5| Step: 9
Training loss: 3.1440980434417725
Validation loss: 3.1667659680048623

Epoch: 5| Step: 10
Training loss: 2.9442942142486572
Validation loss: 3.1620652774969735

Epoch: 5| Step: 11
Training loss: 3.7696542739868164
Validation loss: 3.157113194465637

Epoch: 35| Step: 0
Training loss: 3.325275421142578
Validation loss: 3.153085549672445

Epoch: 5| Step: 1
Training loss: 3.9594032764434814
Validation loss: 3.1487205425898233

Epoch: 5| Step: 2
Training loss: 3.2075374126434326
Validation loss: 3.1445365746816

Epoch: 5| Step: 3
Training loss: 3.08546781539917
Validation loss: 3.140274246533712

Epoch: 5| Step: 4
Training loss: 2.1172890663146973
Validation loss: 3.136164496342341

Epoch: 5| Step: 5
Training loss: 3.9276394844055176
Validation loss: 3.1317574083805084

Epoch: 5| Step: 6
Training loss: 3.8332386016845703
Validation loss: 3.128850599129995

Epoch: 5| Step: 7
Training loss: 3.274890184402466
Validation loss: 3.123582512140274

Epoch: 5| Step: 8
Training loss: 3.1150574684143066
Validation loss: 3.119047631820043

Epoch: 5| Step: 9
Training loss: 3.23138427734375
Validation loss: 3.1151382426420846

Epoch: 5| Step: 10
Training loss: 3.424697160720825
Validation loss: 3.1108610530694327

Epoch: 5| Step: 11
Training loss: 3.3045740127563477
Validation loss: 3.106290409962336

Epoch: 36| Step: 0
Training loss: 2.9481403827667236
Validation loss: 3.1019460260868073

Epoch: 5| Step: 1
Training loss: 3.1675853729248047
Validation loss: 3.099022090435028

Epoch: 5| Step: 2
Training loss: 3.4070770740509033
Validation loss: 3.0944728950659433

Epoch: 5| Step: 3
Training loss: 3.658419132232666
Validation loss: 3.091066757837931

Epoch: 5| Step: 4
Training loss: 2.528080701828003
Validation loss: 3.0864208241303763

Epoch: 5| Step: 5
Training loss: 3.357450008392334
Validation loss: 3.082670380671819

Epoch: 5| Step: 6
Training loss: 3.780086040496826
Validation loss: 3.0790259142716727

Epoch: 5| Step: 7
Training loss: 3.6493427753448486
Validation loss: 3.0751448571681976

Epoch: 5| Step: 8
Training loss: 2.70978045463562
Validation loss: 3.071376552184423

Epoch: 5| Step: 9
Training loss: 2.962980031967163
Validation loss: 3.0674703220526376

Epoch: 5| Step: 10
Training loss: 3.7909858226776123
Validation loss: 3.063207527001699

Epoch: 5| Step: 11
Training loss: 3.4490933418273926
Validation loss: 3.059616277615229

Epoch: 37| Step: 0
Training loss: 2.7811596393585205
Validation loss: 3.05572842558225

Epoch: 5| Step: 1
Training loss: 2.601227283477783
Validation loss: 3.051717003186544

Epoch: 5| Step: 2
Training loss: 3.85661244392395
Validation loss: 3.0477194488048553

Epoch: 5| Step: 3
Training loss: 3.4076087474823
Validation loss: 3.0438599983851113

Epoch: 5| Step: 4
Training loss: 3.291724443435669
Validation loss: 3.0397276679674783

Epoch: 5| Step: 5
Training loss: 3.036360263824463
Validation loss: 3.0354046126206717

Epoch: 5| Step: 6
Training loss: 2.975742816925049
Validation loss: 3.031240334113439

Epoch: 5| Step: 7
Training loss: 2.963367223739624
Validation loss: 3.027441700299581

Epoch: 5| Step: 8
Training loss: 3.7849559783935547
Validation loss: 3.0234236319859824

Epoch: 5| Step: 9
Training loss: 3.544790267944336
Validation loss: 3.0191519260406494

Epoch: 5| Step: 10
Training loss: 3.165600299835205
Validation loss: 3.0151888926823935

Epoch: 5| Step: 11
Training loss: 3.7236554622650146
Validation loss: 3.011329879363378

Epoch: 38| Step: 0
Training loss: 3.130491256713867
Validation loss: 3.0073272585868835

Epoch: 5| Step: 1
Training loss: 3.8848540782928467
Validation loss: 3.0036198496818542

Epoch: 5| Step: 2
Training loss: 3.5161290168762207
Validation loss: 3.000508596499761

Epoch: 5| Step: 3
Training loss: 3.3817124366760254
Validation loss: 2.996313532193502

Epoch: 5| Step: 4
Training loss: 3.027127742767334
Validation loss: 2.993200441201528

Epoch: 5| Step: 5
Training loss: 3.1651816368103027
Validation loss: 2.9892295002937317

Epoch: 5| Step: 6
Training loss: 3.20796275138855
Validation loss: 2.9853077630201974

Epoch: 5| Step: 7
Training loss: 2.5582141876220703
Validation loss: 2.981934239466985

Epoch: 5| Step: 8
Training loss: 3.1686625480651855
Validation loss: 2.977883289257685

Epoch: 5| Step: 9
Training loss: 3.040799617767334
Validation loss: 2.9735774993896484

Epoch: 5| Step: 10
Training loss: 2.922135591506958
Validation loss: 2.969718416531881

Epoch: 5| Step: 11
Training loss: 3.294485092163086
Validation loss: 2.9668029844760895

Epoch: 39| Step: 0
Training loss: 3.0427041053771973
Validation loss: 2.962498734394709

Epoch: 5| Step: 1
Training loss: 2.722510814666748
Validation loss: 2.9589620729287467

Epoch: 5| Step: 2
Training loss: 2.82912540435791
Validation loss: 2.9557445446650186

Epoch: 5| Step: 3
Training loss: 3.567007541656494
Validation loss: 2.9515834748744965

Epoch: 5| Step: 4
Training loss: 2.286044120788574
Validation loss: 2.9474281469980874

Epoch: 5| Step: 5
Training loss: 3.1736512184143066
Validation loss: 2.944129486878713

Epoch: 5| Step: 6
Training loss: 3.1213793754577637
Validation loss: 2.941372255484263

Epoch: 5| Step: 7
Training loss: 3.502373456954956
Validation loss: 2.938031633694967

Epoch: 5| Step: 8
Training loss: 3.6372039318084717
Validation loss: 2.9344356854756675

Epoch: 5| Step: 9
Training loss: 3.2891697883605957
Validation loss: 2.930256644884745

Epoch: 5| Step: 10
Training loss: 3.470245361328125
Validation loss: 2.926231493552526

Epoch: 5| Step: 11
Training loss: 2.817262649536133
Validation loss: 2.9229466219743094

Epoch: 40| Step: 0
Training loss: 3.3425140380859375
Validation loss: 2.923235456148783

Epoch: 5| Step: 1
Training loss: 3.4165637493133545
Validation loss: 2.927053769429525

Epoch: 5| Step: 2
Training loss: 3.340927839279175
Validation loss: 2.925608883301417

Epoch: 5| Step: 3
Training loss: 2.6555848121643066
Validation loss: 2.915322591861089

Epoch: 5| Step: 4
Training loss: 2.631793260574341
Validation loss: 2.9131164252758026

Epoch: 5| Step: 5
Training loss: 3.352837324142456
Validation loss: 2.9047391017278037

Epoch: 5| Step: 6
Training loss: 2.9788527488708496
Validation loss: 2.9022380212942758

Epoch: 5| Step: 7
Training loss: 3.327505588531494
Validation loss: 2.8995851576328278

Epoch: 5| Step: 8
Training loss: 3.066319704055786
Validation loss: 2.898667494455973

Epoch: 5| Step: 9
Training loss: 2.8756332397460938
Validation loss: 2.897125780582428

Epoch: 5| Step: 10
Training loss: 2.932692766189575
Validation loss: 2.894604911406835

Epoch: 5| Step: 11
Training loss: 4.504076957702637
Validation loss: 2.8896438578764596

Epoch: 41| Step: 0
Training loss: 2.7277400493621826
Validation loss: 2.8832453389962516

Epoch: 5| Step: 1
Training loss: 3.2288107872009277
Validation loss: 2.8788194060325623

Epoch: 5| Step: 2
Training loss: 2.885810375213623
Validation loss: 2.8744170467058816

Epoch: 5| Step: 3
Training loss: 3.1203269958496094
Validation loss: 2.87408917148908

Epoch: 5| Step: 4
Training loss: 2.8385767936706543
Validation loss: 2.868045816818873

Epoch: 5| Step: 5
Training loss: 3.144211769104004
Validation loss: 2.8669779300689697

Epoch: 5| Step: 6
Training loss: 3.0453529357910156
Validation loss: 2.862924059232076

Epoch: 5| Step: 7
Training loss: 3.2506325244903564
Validation loss: 2.860239714384079

Epoch: 5| Step: 8
Training loss: 3.084759473800659
Validation loss: 2.857406576474508

Epoch: 5| Step: 9
Training loss: 3.17185378074646
Validation loss: 2.85530619819959

Epoch: 5| Step: 10
Training loss: 3.3040823936462402
Validation loss: 2.854114572207133

Epoch: 5| Step: 11
Training loss: 2.8981118202209473
Validation loss: 2.851176460584005

Epoch: 42| Step: 0
Training loss: 3.414278507232666
Validation loss: 2.8433739691972733

Epoch: 5| Step: 1
Training loss: 3.006113052368164
Validation loss: 2.840309128165245

Epoch: 5| Step: 2
Training loss: 2.573406457901001
Validation loss: 2.8370013435681662

Epoch: 5| Step: 3
Training loss: 2.81386661529541
Validation loss: 2.833870400985082

Epoch: 5| Step: 4
Training loss: 2.9308595657348633
Validation loss: 2.828852246205012

Epoch: 5| Step: 5
Training loss: 2.947521209716797
Validation loss: 2.8243382026751838

Epoch: 5| Step: 6
Training loss: 3.421926975250244
Validation loss: 2.8203734159469604

Epoch: 5| Step: 7
Training loss: 3.25732159614563
Validation loss: 2.8191557923952737

Epoch: 5| Step: 8
Training loss: 2.9453089237213135
Validation loss: 2.8272799849510193

Epoch: 5| Step: 9
Training loss: 3.382723331451416
Validation loss: 2.8227688670158386

Epoch: 5| Step: 10
Training loss: 2.5270090103149414
Validation loss: 2.8139877120653787

Epoch: 5| Step: 11
Training loss: 3.861360788345337
Validation loss: 2.8065714240074158

Epoch: 43| Step: 0
Training loss: 3.308776378631592
Validation loss: 2.7999232709407806

Epoch: 5| Step: 1
Training loss: 3.492027997970581
Validation loss: 2.797028988599777

Epoch: 5| Step: 2
Training loss: 3.2623119354248047
Validation loss: 2.7944241960843406

Epoch: 5| Step: 3
Training loss: 2.47908353805542
Validation loss: 2.793856451908747

Epoch: 5| Step: 4
Training loss: 2.7910423278808594
Validation loss: 2.7903156081835427

Epoch: 5| Step: 5
Training loss: 3.012134552001953
Validation loss: 2.7875004609425864

Epoch: 5| Step: 6
Training loss: 3.2073123455047607
Validation loss: 2.7823039392630258

Epoch: 5| Step: 7
Training loss: 2.7230701446533203
Validation loss: 2.7790084977944693

Epoch: 5| Step: 8
Training loss: 2.5890231132507324
Validation loss: 2.7727893590927124

Epoch: 5| Step: 9
Training loss: 2.995090961456299
Validation loss: 2.7718573013941445

Epoch: 5| Step: 10
Training loss: 2.9220669269561768
Validation loss: 2.766842563947042

Epoch: 5| Step: 11
Training loss: 3.7717294692993164
Validation loss: 2.763345698515574

Epoch: 44| Step: 0
Training loss: 2.6853253841400146
Validation loss: 2.759465883175532

Epoch: 5| Step: 1
Training loss: 2.7914950847625732
Validation loss: 2.7564853529135385

Epoch: 5| Step: 2
Training loss: 3.176199436187744
Validation loss: 2.754940221707026

Epoch: 5| Step: 3
Training loss: 2.719482421875
Validation loss: 2.752940764029821

Epoch: 5| Step: 4
Training loss: 3.5272388458251953
Validation loss: 2.7523949642976127

Epoch: 5| Step: 5
Training loss: 3.01358962059021
Validation loss: 2.750016748905182

Epoch: 5| Step: 6
Training loss: 3.2706916332244873
Validation loss: 2.7486460308233895

Epoch: 5| Step: 7
Training loss: 2.7727363109588623
Validation loss: 2.739274869362513

Epoch: 5| Step: 8
Training loss: 1.9546657800674438
Validation loss: 2.736235280831655

Epoch: 5| Step: 9
Training loss: 3.0665760040283203
Validation loss: 2.7309457262357077

Epoch: 5| Step: 10
Training loss: 3.2497901916503906
Validation loss: 2.730178793271383

Epoch: 5| Step: 11
Training loss: 3.8229336738586426
Validation loss: 2.726851304372152

Epoch: 45| Step: 0
Training loss: 3.1849734783172607
Validation loss: 2.7300418416659036

Epoch: 5| Step: 1
Training loss: 2.2440357208251953
Validation loss: 2.7362069884936013

Epoch: 5| Step: 2
Training loss: 2.8870749473571777
Validation loss: 2.7533305287361145

Epoch: 5| Step: 3
Training loss: 2.752375364303589
Validation loss: 2.7516935765743256

Epoch: 5| Step: 4
Training loss: 3.2424087524414062
Validation loss: 2.7400695979595184

Epoch: 5| Step: 5
Training loss: 2.9592795372009277
Validation loss: 2.7197303672631583

Epoch: 5| Step: 6
Training loss: 3.053135633468628
Validation loss: 2.7078979909420013

Epoch: 5| Step: 7
Training loss: 2.741556406021118
Validation loss: 2.7018535484870276

Epoch: 5| Step: 8
Training loss: 2.4080426692962646
Validation loss: 2.696665187676748

Epoch: 5| Step: 9
Training loss: 3.26153826713562
Validation loss: 2.6952703098456063

Epoch: 5| Step: 10
Training loss: 3.267061710357666
Validation loss: 2.6950031419595084

Epoch: 5| Step: 11
Training loss: 3.5573673248291016
Validation loss: 2.6937491794427237

Epoch: 46| Step: 0
Training loss: 3.6912055015563965
Validation loss: 2.690231502056122

Epoch: 5| Step: 1
Training loss: 2.5316708087921143
Validation loss: 2.684080575903257

Epoch: 5| Step: 2
Training loss: 2.7270727157592773
Validation loss: 2.6800789535045624

Epoch: 5| Step: 3
Training loss: 2.9748787879943848
Validation loss: 2.6751419802506766

Epoch: 5| Step: 4
Training loss: 2.5598371028900146
Validation loss: 2.6695557733376822

Epoch: 5| Step: 5
Training loss: 2.898305654525757
Validation loss: 2.6671410699685416

Epoch: 5| Step: 6
Training loss: 2.5766170024871826
Validation loss: 2.6643580297629037

Epoch: 5| Step: 7
Training loss: 2.8836798667907715
Validation loss: 2.6625300347805023

Epoch: 5| Step: 8
Training loss: 3.271286725997925
Validation loss: 2.6580184400081635

Epoch: 5| Step: 9
Training loss: 2.8423404693603516
Validation loss: 2.6547529697418213

Epoch: 5| Step: 10
Training loss: 2.2835350036621094
Validation loss: 2.6526532769203186

Epoch: 5| Step: 11
Training loss: 4.648462295532227
Validation loss: 2.6486374040444693

Epoch: 47| Step: 0
Training loss: 3.0258331298828125
Validation loss: 2.6455432971318564

Epoch: 5| Step: 1
Training loss: 2.879950761795044
Validation loss: 2.640719215075175

Epoch: 5| Step: 2
Training loss: 2.8779191970825195
Validation loss: 2.638066659371058

Epoch: 5| Step: 3
Training loss: 3.158778667449951
Validation loss: 2.6331371863683066

Epoch: 5| Step: 4
Training loss: 2.928225040435791
Validation loss: 2.632264494895935

Epoch: 5| Step: 5
Training loss: 2.2787444591522217
Validation loss: 2.6281091272830963

Epoch: 5| Step: 6
Training loss: 3.285020351409912
Validation loss: 2.6258239150047302

Epoch: 5| Step: 7
Training loss: 2.696580171585083
Validation loss: 2.6203014651934304

Epoch: 5| Step: 8
Training loss: 2.0239176750183105
Validation loss: 2.61517600218455

Epoch: 5| Step: 9
Training loss: 2.4980528354644775
Validation loss: 2.6153809229532876

Epoch: 5| Step: 10
Training loss: 3.281552791595459
Validation loss: 2.6094039479891458

Epoch: 5| Step: 11
Training loss: 3.7207448482513428
Validation loss: 2.611519694328308

Epoch: 48| Step: 0
Training loss: 3.3914787769317627
Validation loss: 2.6102649768193564

Epoch: 5| Step: 1
Training loss: 2.9027419090270996
Validation loss: 2.6055126190185547

Epoch: 5| Step: 2
Training loss: 2.8505351543426514
Validation loss: 2.599092185497284

Epoch: 5| Step: 3
Training loss: 3.1008026599884033
Validation loss: 2.592770536740621

Epoch: 5| Step: 4
Training loss: 2.1907763481140137
Validation loss: 2.5912174383799234

Epoch: 5| Step: 5
Training loss: 2.4871811866760254
Validation loss: 2.588028907775879

Epoch: 5| Step: 6
Training loss: 3.1334357261657715
Validation loss: 2.5871624648571014

Epoch: 5| Step: 7
Training loss: 2.3366119861602783
Validation loss: 2.5859027008215585

Epoch: 5| Step: 8
Training loss: 2.6365160942077637
Validation loss: 2.593630333741506

Epoch: 5| Step: 9
Training loss: 2.5106441974639893
Validation loss: 2.5809338887532554

Epoch: 5| Step: 10
Training loss: 2.8607866764068604
Validation loss: 2.576599419116974

Epoch: 5| Step: 11
Training loss: 3.9206955432891846
Validation loss: 2.566752791404724

Epoch: 49| Step: 0
Training loss: 2.900444507598877
Validation loss: 2.566435952981313

Epoch: 5| Step: 1
Training loss: 2.868422746658325
Validation loss: 2.565762385725975

Epoch: 5| Step: 2
Training loss: 2.9014716148376465
Validation loss: 2.565042659640312

Epoch: 5| Step: 3
Training loss: 2.8993937969207764
Validation loss: 2.5613589684168496

Epoch: 5| Step: 4
Training loss: 2.257471799850464
Validation loss: 2.5602985521157584

Epoch: 5| Step: 5
Training loss: 3.2455334663391113
Validation loss: 2.558244605859121

Epoch: 5| Step: 6
Training loss: 2.8297269344329834
Validation loss: 2.5547825594743094

Epoch: 5| Step: 7
Training loss: 2.9283480644226074
Validation loss: 2.549692158897718

Epoch: 5| Step: 8
Training loss: 2.75369930267334
Validation loss: 2.5443351666132608

Epoch: 5| Step: 9
Training loss: 2.9726920127868652
Validation loss: 2.5426370203495026

Epoch: 5| Step: 10
Training loss: 1.9919353723526
Validation loss: 2.5350972612698874

Epoch: 5| Step: 11
Training loss: 1.4488422870635986
Validation loss: 2.535853544871012

Epoch: 50| Step: 0
Training loss: 2.509565591812134
Validation loss: 2.5324128369490304

Epoch: 5| Step: 1
Training loss: 3.099991798400879
Validation loss: 2.5361980398495994

Epoch: 5| Step: 2
Training loss: 3.001218795776367
Validation loss: 2.5317501922448478

Epoch: 5| Step: 3
Training loss: 2.608107089996338
Validation loss: 2.5260036289691925

Epoch: 5| Step: 4
Training loss: 3.184077024459839
Validation loss: 2.5182361900806427

Epoch: 5| Step: 5
Training loss: 3.2837417125701904
Validation loss: 2.511853521068891

Epoch: 5| Step: 6
Training loss: 2.3090107440948486
Validation loss: 2.5116672813892365

Epoch: 5| Step: 7
Training loss: 2.294062376022339
Validation loss: 2.5111532310644784

Epoch: 5| Step: 8
Training loss: 2.705312490463257
Validation loss: 2.5103646516799927

Epoch: 5| Step: 9
Training loss: 2.456540107727051
Validation loss: 2.5100387036800385

Epoch: 5| Step: 10
Training loss: 2.5746116638183594
Validation loss: 2.5095211068789163

Epoch: 5| Step: 11
Training loss: 1.886716365814209
Validation loss: 2.5083123544851937

Epoch: 51| Step: 0
Training loss: 3.4915242195129395
Validation loss: 2.506310373544693

Epoch: 5| Step: 1
Training loss: 2.542370319366455
Validation loss: 2.500781238079071

Epoch: 5| Step: 2
Training loss: 2.7173283100128174
Validation loss: 2.499410996834437

Epoch: 5| Step: 3
Training loss: 2.72271728515625
Validation loss: 2.4927732845147452

Epoch: 5| Step: 4
Training loss: 2.692725658416748
Validation loss: 2.4890371362368264

Epoch: 5| Step: 5
Training loss: 2.5436487197875977
Validation loss: 2.4860864778359733

Epoch: 5| Step: 6
Training loss: 2.499255418777466
Validation loss: 2.478813022375107

Epoch: 5| Step: 7
Training loss: 2.383002758026123
Validation loss: 2.476220518350601

Epoch: 5| Step: 8
Training loss: 2.6362974643707275
Validation loss: 2.4739889999230704

Epoch: 5| Step: 9
Training loss: 2.5820248126983643
Validation loss: 2.4731507996718087

Epoch: 5| Step: 10
Training loss: 2.4516146183013916
Validation loss: 2.472392648458481

Epoch: 5| Step: 11
Training loss: 3.760748863220215
Validation loss: 2.4624597430229187

Epoch: 52| Step: 0
Training loss: 2.7597451210021973
Validation loss: 2.470739006996155

Epoch: 5| Step: 1
Training loss: 2.6106626987457275
Validation loss: 2.4644206762313843

Epoch: 5| Step: 2
Training loss: 2.2836532592773438
Validation loss: 2.4607059260209403

Epoch: 5| Step: 3
Training loss: 3.048658609390259
Validation loss: 2.4567073384920755

Epoch: 5| Step: 4
Training loss: 2.5098319053649902
Validation loss: 2.4539896150430045

Epoch: 5| Step: 5
Training loss: 2.9644289016723633
Validation loss: 2.449911057949066

Epoch: 5| Step: 6
Training loss: 2.7007997035980225
Validation loss: 2.443078180154165

Epoch: 5| Step: 7
Training loss: 2.4491443634033203
Validation loss: 2.44195490082105

Epoch: 5| Step: 8
Training loss: 2.6602001190185547
Validation loss: 2.438779224952062

Epoch: 5| Step: 9
Training loss: 2.2086737155914307
Validation loss: 2.4381564358870187

Epoch: 5| Step: 10
Training loss: 3.0559327602386475
Validation loss: 2.4359921514987946

Epoch: 5| Step: 11
Training loss: 1.0564405918121338
Validation loss: 2.4308223028977713

Epoch: 53| Step: 0
Training loss: 2.568394184112549
Validation loss: 2.4272614121437073

Epoch: 5| Step: 1
Training loss: 2.4599404335021973
Validation loss: 2.426349307099978

Epoch: 5| Step: 2
Training loss: 3.2324624061584473
Validation loss: 2.4273841877778373

Epoch: 5| Step: 3
Training loss: 2.7166943550109863
Validation loss: 2.4228758116563163

Epoch: 5| Step: 4
Training loss: 3.072819232940674
Validation loss: 2.4246649742126465

Epoch: 5| Step: 5
Training loss: 2.626697540283203
Validation loss: 2.424391806125641

Epoch: 5| Step: 6
Training loss: 2.4038543701171875
Validation loss: 2.419184704621633

Epoch: 5| Step: 7
Training loss: 2.215327024459839
Validation loss: 2.4186147650082908

Epoch: 5| Step: 8
Training loss: 2.2833633422851562
Validation loss: 2.414781093597412

Epoch: 5| Step: 9
Training loss: 2.622471570968628
Validation loss: 2.4062953740358353

Epoch: 5| Step: 10
Training loss: 2.641235828399658
Validation loss: 2.4104044139385223

Epoch: 5| Step: 11
Training loss: 1.612782597541809
Validation loss: 2.403444210688273

Epoch: 54| Step: 0
Training loss: 2.8870978355407715
Validation loss: 2.4093238413333893

Epoch: 5| Step: 1
Training loss: 2.109921932220459
Validation loss: 2.4043272535006204

Epoch: 5| Step: 2
Training loss: 2.6067757606506348
Validation loss: 2.3915621836980185

Epoch: 5| Step: 3
Training loss: 2.433138132095337
Validation loss: 2.390261799097061

Epoch: 5| Step: 4
Training loss: 2.507021903991699
Validation loss: 2.3853567143281302

Epoch: 5| Step: 5
Training loss: 2.2704532146453857
Validation loss: 2.3885660469532013

Epoch: 5| Step: 6
Training loss: 3.319082736968994
Validation loss: 2.3847813804944358

Epoch: 5| Step: 7
Training loss: 2.7913296222686768
Validation loss: 2.3809103469053903

Epoch: 5| Step: 8
Training loss: 2.365070343017578
Validation loss: 2.380974382162094

Epoch: 5| Step: 9
Training loss: 2.519381523132324
Validation loss: 2.373972793420156

Epoch: 5| Step: 10
Training loss: 2.3043885231018066
Validation loss: 2.372202157974243

Epoch: 5| Step: 11
Training loss: 3.4373648166656494
Validation loss: 2.3774052460988364

Epoch: 55| Step: 0
Training loss: 2.8849055767059326
Validation loss: 2.3724165111780167

Epoch: 5| Step: 1
Training loss: 2.4845986366271973
Validation loss: 2.3706576426823935

Epoch: 5| Step: 2
Training loss: 2.5103774070739746
Validation loss: 2.365975648164749

Epoch: 5| Step: 3
Training loss: 2.4426915645599365
Validation loss: 2.3584230641523996

Epoch: 5| Step: 4
Training loss: 2.8587679862976074
Validation loss: 2.3593844374020896

Epoch: 5| Step: 5
Training loss: 3.083918333053589
Validation loss: 2.358872483174006

Epoch: 5| Step: 6
Training loss: 2.3756842613220215
Validation loss: 2.3519864877065024

Epoch: 5| Step: 7
Training loss: 1.8563636541366577
Validation loss: 2.348828911781311

Epoch: 5| Step: 8
Training loss: 2.675968647003174
Validation loss: 2.3478189408779144

Epoch: 5| Step: 9
Training loss: 2.311676263809204
Validation loss: 2.345711683233579

Epoch: 5| Step: 10
Training loss: 2.3641116619110107
Validation loss: 2.349474569161733

Epoch: 5| Step: 11
Training loss: 2.1278762817382812
Validation loss: 2.3438122322161994

Epoch: 56| Step: 0
Training loss: 3.3097152709960938
Validation loss: 2.346356968084971

Epoch: 5| Step: 1
Training loss: 2.3561668395996094
Validation loss: 2.346570293108622

Epoch: 5| Step: 2
Training loss: 2.830963611602783
Validation loss: 2.333197608590126

Epoch: 5| Step: 3
Training loss: 2.5052192211151123
Validation loss: 2.333839863538742

Epoch: 5| Step: 4
Training loss: 1.9328029155731201
Validation loss: 2.3293668826421103

Epoch: 5| Step: 5
Training loss: 2.732701301574707
Validation loss: 2.327586909135183

Epoch: 5| Step: 6
Training loss: 2.2440543174743652
Validation loss: 2.3275504112243652

Epoch: 5| Step: 7
Training loss: 2.280759334564209
Validation loss: 2.3242446879545846

Epoch: 5| Step: 8
Training loss: 2.6667304039001465
Validation loss: 2.323503072063128

Epoch: 5| Step: 9
Training loss: 2.0162341594696045
Validation loss: 2.3187556167443595

Epoch: 5| Step: 10
Training loss: 2.4941861629486084
Validation loss: 2.3238502045472464

Epoch: 5| Step: 11
Training loss: 3.2918789386749268
Validation loss: 2.3131771435340247

Epoch: 57| Step: 0
Training loss: 2.579481601715088
Validation loss: 2.313905656337738

Epoch: 5| Step: 1
Training loss: 2.4963669776916504
Validation loss: 2.3074105083942413

Epoch: 5| Step: 2
Training loss: 1.6853262186050415
Validation loss: 2.3045683801174164

Epoch: 5| Step: 3
Training loss: 2.7210707664489746
Validation loss: 2.2999956657489142

Epoch: 5| Step: 4
Training loss: 2.684696674346924
Validation loss: 2.3048530220985413

Epoch: 5| Step: 5
Training loss: 2.6525795459747314
Validation loss: 2.3073078046242395

Epoch: 5| Step: 6
Training loss: 2.3164005279541016
Validation loss: 2.298161248366038

Epoch: 5| Step: 7
Training loss: 2.391653537750244
Validation loss: 2.291829605897268

Epoch: 5| Step: 8
Training loss: 2.6783244609832764
Validation loss: 2.285318076610565

Epoch: 5| Step: 9
Training loss: 2.101895809173584
Validation loss: 2.2821576247612634

Epoch: 5| Step: 10
Training loss: 2.571986675262451
Validation loss: 2.286692495147387

Epoch: 5| Step: 11
Training loss: 3.3246755599975586
Validation loss: 2.2816971788803735

Epoch: 58| Step: 0
Training loss: 2.1124954223632812
Validation loss: 2.280873457590739

Epoch: 5| Step: 1
Training loss: 2.2271227836608887
Validation loss: 2.2831691006819406

Epoch: 5| Step: 2
Training loss: 2.4026734828948975
Validation loss: 2.2859745025634766

Epoch: 5| Step: 3
Training loss: 2.79878306388855
Validation loss: 2.2806315322717032

Epoch: 5| Step: 4
Training loss: 2.598784923553467
Validation loss: 2.2738432437181473

Epoch: 5| Step: 5
Training loss: 1.986303687095642
Validation loss: 2.2749217649300895

Epoch: 5| Step: 6
Training loss: 1.8250048160552979
Validation loss: 2.268380030989647

Epoch: 5| Step: 7
Training loss: 3.1449081897735596
Validation loss: 2.2652069528897605

Epoch: 5| Step: 8
Training loss: 2.7816247940063477
Validation loss: 2.264295091231664

Epoch: 5| Step: 9
Training loss: 2.517176389694214
Validation loss: 2.2617032527923584

Epoch: 5| Step: 10
Training loss: 2.4455909729003906
Validation loss: 2.2589954932530723

Epoch: 5| Step: 11
Training loss: 2.1552839279174805
Validation loss: 2.258339246114095

Epoch: 59| Step: 0
Training loss: 2.48315167427063
Validation loss: 2.253357062737147

Epoch: 5| Step: 1
Training loss: 2.8191328048706055
Validation loss: 2.2500304132699966

Epoch: 5| Step: 2
Training loss: 2.349116802215576
Validation loss: 2.250431920091311

Epoch: 5| Step: 3
Training loss: 1.889346718788147
Validation loss: 2.2490499168634415

Epoch: 5| Step: 4
Training loss: 2.231839418411255
Validation loss: 2.2515012472867966

Epoch: 5| Step: 5
Training loss: 2.6391406059265137
Validation loss: 2.2467668056488037

Epoch: 5| Step: 6
Training loss: 1.6506760120391846
Validation loss: 2.246578633785248

Epoch: 5| Step: 7
Training loss: 2.3160006999969482
Validation loss: 2.2484227269887924

Epoch: 5| Step: 8
Training loss: 2.5516092777252197
Validation loss: 2.239658147096634

Epoch: 5| Step: 9
Training loss: 2.4875380992889404
Validation loss: 2.240118076403936

Epoch: 5| Step: 10
Training loss: 2.8205065727233887
Validation loss: 2.2321603496869407

Epoch: 5| Step: 11
Training loss: 3.228705644607544
Validation loss: 2.2302689254283905

Epoch: 60| Step: 0
Training loss: 2.4391093254089355
Validation loss: 2.222814053297043

Epoch: 5| Step: 1
Training loss: 2.1794819831848145
Validation loss: 2.2224514285723367

Epoch: 5| Step: 2
Training loss: 2.6064469814300537
Validation loss: 2.2269724110762277

Epoch: 5| Step: 3
Training loss: 2.4886527061462402
Validation loss: 2.229795748988787

Epoch: 5| Step: 4
Training loss: 2.0830864906311035
Validation loss: 2.232630133628845

Epoch: 5| Step: 5
Training loss: 3.230360507965088
Validation loss: 2.2280299961566925

Epoch: 5| Step: 6
Training loss: 2.0156140327453613
Validation loss: 2.226943681637446

Epoch: 5| Step: 7
Training loss: 1.8441684246063232
Validation loss: 2.2211803694566092

Epoch: 5| Step: 8
Training loss: 2.3519692420959473
Validation loss: 2.2104666928450265

Epoch: 5| Step: 9
Training loss: 2.465393543243408
Validation loss: 2.208260029554367

Epoch: 5| Step: 10
Training loss: 2.429692029953003
Validation loss: 2.2068946063518524

Epoch: 5| Step: 11
Training loss: 1.974105954170227
Validation loss: 2.20686212182045

Epoch: 61| Step: 0
Training loss: 2.591003894805908
Validation loss: 2.2079100410143533

Epoch: 5| Step: 1
Training loss: 2.5504369735717773
Validation loss: 2.2014435480038324

Epoch: 5| Step: 2
Training loss: 2.3665661811828613
Validation loss: 2.2031235794226327

Epoch: 5| Step: 3
Training loss: 1.5864994525909424
Validation loss: 2.200761536757151

Epoch: 5| Step: 4
Training loss: 2.454850673675537
Validation loss: 2.194262315829595

Epoch: 5| Step: 5
Training loss: 2.9273886680603027
Validation loss: 2.1903091867764792

Epoch: 5| Step: 6
Training loss: 2.6918551921844482
Validation loss: 2.1912067433198295

Epoch: 5| Step: 7
Training loss: 2.476494550704956
Validation loss: 2.1873127122720084

Epoch: 5| Step: 8
Training loss: 2.101972818374634
Validation loss: 2.1846152196327844

Epoch: 5| Step: 9
Training loss: 1.9708764553070068
Validation loss: 2.1913225849469504

Epoch: 5| Step: 10
Training loss: 1.912642240524292
Validation loss: 2.190788303812345

Epoch: 5| Step: 11
Training loss: 2.952357769012451
Validation loss: 2.187370906273524

Epoch: 62| Step: 0
Training loss: 2.045975923538208
Validation loss: 2.198223347465197

Epoch: 5| Step: 1
Training loss: 1.9892385005950928
Validation loss: 2.2082261939843497

Epoch: 5| Step: 2
Training loss: 2.05063796043396
Validation loss: 2.209123283624649

Epoch: 5| Step: 3
Training loss: 2.192368745803833
Validation loss: 2.2012016077836356

Epoch: 5| Step: 4
Training loss: 2.572223424911499
Validation loss: 2.1867211709419885

Epoch: 5| Step: 5
Training loss: 2.3861584663391113
Validation loss: 2.181729873021444

Epoch: 5| Step: 6
Training loss: 2.5864531993865967
Validation loss: 2.1644428869088492

Epoch: 5| Step: 7
Training loss: 2.6118578910827637
Validation loss: 2.171038940548897

Epoch: 5| Step: 8
Training loss: 2.1609292030334473
Validation loss: 2.1735628247261047

Epoch: 5| Step: 9
Training loss: 2.7233078479766846
Validation loss: 2.175217072168986

Epoch: 5| Step: 10
Training loss: 2.257965564727783
Validation loss: 2.1731525311867395

Epoch: 5| Step: 11
Training loss: 2.0898404121398926
Validation loss: 2.1749627391497293

Epoch: 63| Step: 0
Training loss: 2.4614810943603516
Validation loss: 2.1691811084747314

Epoch: 5| Step: 1
Training loss: 2.327913284301758
Validation loss: 2.1703130255142846

Epoch: 5| Step: 2
Training loss: 2.408813714981079
Validation loss: 2.1674249470233917

Epoch: 5| Step: 3
Training loss: 2.3943252563476562
Validation loss: 2.1675120095411935

Epoch: 5| Step: 4
Training loss: 2.566659688949585
Validation loss: 2.1615743388732276

Epoch: 5| Step: 5
Training loss: 1.706040382385254
Validation loss: 2.165762275457382

Epoch: 5| Step: 6
Training loss: 2.5690929889678955
Validation loss: 2.1658933609724045

Epoch: 5| Step: 7
Training loss: 2.207531452178955
Validation loss: 2.157794177532196

Epoch: 5| Step: 8
Training loss: 1.8357681035995483
Validation loss: 2.158423205216726

Epoch: 5| Step: 9
Training loss: 2.756946563720703
Validation loss: 2.1593937377134957

Epoch: 5| Step: 10
Training loss: 2.337367534637451
Validation loss: 2.154603451490402

Epoch: 5| Step: 11
Training loss: 2.2966787815093994
Validation loss: 2.151605879267057

Epoch: 64| Step: 0
Training loss: 2.154062271118164
Validation loss: 2.1558438539505005

Epoch: 5| Step: 1
Training loss: 2.6307873725891113
Validation loss: 2.1490442355473838

Epoch: 5| Step: 2
Training loss: 2.1645121574401855
Validation loss: 2.1473607619603476

Epoch: 5| Step: 3
Training loss: 1.9953571557998657
Validation loss: 2.1537872652212777

Epoch: 5| Step: 4
Training loss: 1.9674718379974365
Validation loss: 2.1540332237879434

Epoch: 5| Step: 5
Training loss: 1.9845895767211914
Validation loss: 2.145180116097132

Epoch: 5| Step: 6
Training loss: 2.621403694152832
Validation loss: 2.1483583450317383

Epoch: 5| Step: 7
Training loss: 2.4209110736846924
Validation loss: 2.1549243231614432

Epoch: 5| Step: 8
Training loss: 2.8352408409118652
Validation loss: 2.145216926932335

Epoch: 5| Step: 9
Training loss: 1.8770921230316162
Validation loss: 2.14730928838253

Epoch: 5| Step: 10
Training loss: 2.5198607444763184
Validation loss: 2.1424148927132287

Epoch: 5| Step: 11
Training loss: 2.8988161087036133
Validation loss: 2.1482681234677634

Epoch: 65| Step: 0
Training loss: 2.6721644401550293
Validation loss: 2.1540757218996682

Epoch: 5| Step: 1
Training loss: 2.4587209224700928
Validation loss: 2.1549828151861825

Epoch: 5| Step: 2
Training loss: 2.618192195892334
Validation loss: 2.1620729863643646

Epoch: 5| Step: 3
Training loss: 2.3727965354919434
Validation loss: 2.160345509648323

Epoch: 5| Step: 4
Training loss: 2.247842311859131
Validation loss: 2.157203440864881

Epoch: 5| Step: 5
Training loss: 1.9535919427871704
Validation loss: 2.1505717684825263

Epoch: 5| Step: 6
Training loss: 2.045597553253174
Validation loss: 2.143952245513598

Epoch: 5| Step: 7
Training loss: 3.0084433555603027
Validation loss: 2.139287451903025

Epoch: 5| Step: 8
Training loss: 1.8892772197723389
Validation loss: 2.1334355970223746

Epoch: 5| Step: 9
Training loss: 2.835524797439575
Validation loss: 2.1268333345651627

Epoch: 5| Step: 10
Training loss: 1.618129014968872
Validation loss: 2.130519837141037

Epoch: 5| Step: 11
Training loss: 0.4147515296936035
Validation loss: 2.1142527063687644

Epoch: 66| Step: 0
Training loss: 2.438544750213623
Validation loss: 2.121419017513593

Epoch: 5| Step: 1
Training loss: 1.6801261901855469
Validation loss: 2.1308155755201974

Epoch: 5| Step: 2
Training loss: 2.4285521507263184
Validation loss: 2.134655108054479

Epoch: 5| Step: 3
Training loss: 2.331043243408203
Validation loss: 2.127084175745646

Epoch: 5| Step: 4
Training loss: 2.716780185699463
Validation loss: 2.1277436167001724

Epoch: 5| Step: 5
Training loss: 2.6993443965911865
Validation loss: 2.1380032350619635

Epoch: 5| Step: 6
Training loss: 1.42338228225708
Validation loss: 2.1214504142602286

Epoch: 5| Step: 7
Training loss: 2.1529641151428223
Validation loss: 2.115652243296305

Epoch: 5| Step: 8
Training loss: 2.5331172943115234
Validation loss: 2.1123641282320023

Epoch: 5| Step: 9
Training loss: 2.1433587074279785
Validation loss: 2.1059718430042267

Epoch: 5| Step: 10
Training loss: 2.419804096221924
Validation loss: 2.119541347026825

Epoch: 5| Step: 11
Training loss: 2.525625705718994
Validation loss: 2.1123294085264206

Epoch: 67| Step: 0
Training loss: 2.2946648597717285
Validation loss: 2.1286442279815674

Epoch: 5| Step: 1
Training loss: 2.106480598449707
Validation loss: 2.1337521920601525

Epoch: 5| Step: 2
Training loss: 2.2854390144348145
Validation loss: 2.122675359249115

Epoch: 5| Step: 3
Training loss: 1.8038934469223022
Validation loss: 2.1292235801617303

Epoch: 5| Step: 4
Training loss: 2.7299256324768066
Validation loss: 2.1367471317450204

Epoch: 5| Step: 5
Training loss: 2.572606086730957
Validation loss: 2.1330833385388055

Epoch: 5| Step: 6
Training loss: 2.2193243503570557
Validation loss: 2.1215336322784424

Epoch: 5| Step: 7
Training loss: 2.315150737762451
Validation loss: 2.111249938607216

Epoch: 5| Step: 8
Training loss: 1.700716257095337
Validation loss: 2.10348146657149

Epoch: 5| Step: 9
Training loss: 2.753755807876587
Validation loss: 2.099752724170685

Epoch: 5| Step: 10
Training loss: 2.2678542137145996
Validation loss: 2.1017091423273087

Epoch: 5| Step: 11
Training loss: 1.768418550491333
Validation loss: 2.0960073421398797

Epoch: 68| Step: 0
Training loss: 2.3580188751220703
Validation loss: 2.1130666583776474

Epoch: 5| Step: 1
Training loss: 2.233299732208252
Validation loss: 2.109579344590505

Epoch: 5| Step: 2
Training loss: 2.330242872238159
Validation loss: 2.119007701675097

Epoch: 5| Step: 3
Training loss: 2.4303059577941895
Validation loss: 2.121211369832357

Epoch: 5| Step: 4
Training loss: 2.1212315559387207
Validation loss: 2.1172217478354773

Epoch: 5| Step: 5
Training loss: 2.626049041748047
Validation loss: 2.11869885524114

Epoch: 5| Step: 6
Training loss: 2.5763537883758545
Validation loss: 2.119191894928614

Epoch: 5| Step: 7
Training loss: 2.143136978149414
Validation loss: 2.1102747718493142

Epoch: 5| Step: 8
Training loss: 2.0289156436920166
Validation loss: 2.1053940703471503

Epoch: 5| Step: 9
Training loss: 2.568333387374878
Validation loss: 2.104234163959821

Epoch: 5| Step: 10
Training loss: 1.5865991115570068
Validation loss: 2.098082810640335

Epoch: 5| Step: 11
Training loss: 2.7027575969696045
Validation loss: 2.0976248184839883

Epoch: 69| Step: 0
Training loss: 1.8340809345245361
Validation loss: 2.092954804499944

Epoch: 5| Step: 1
Training loss: 1.8986635208129883
Validation loss: 2.077710285782814

Epoch: 5| Step: 2
Training loss: 2.575843334197998
Validation loss: 2.0825625558694205

Epoch: 5| Step: 3
Training loss: 1.9033358097076416
Validation loss: 2.0905233025550842

Epoch: 5| Step: 4
Training loss: 2.4639790058135986
Validation loss: 2.102694128950437

Epoch: 5| Step: 5
Training loss: 2.2113847732543945
Validation loss: 2.1050302733977637

Epoch: 5| Step: 6
Training loss: 2.4957990646362305
Validation loss: 2.1066399415334067

Epoch: 5| Step: 7
Training loss: 2.040674924850464
Validation loss: 2.105579902728399

Epoch: 5| Step: 8
Training loss: 2.3553550243377686
Validation loss: 2.0958056996266046

Epoch: 5| Step: 9
Training loss: 2.4053401947021484
Validation loss: 2.0727546711762748

Epoch: 5| Step: 10
Training loss: 2.60200834274292
Validation loss: 2.076536332567533

Epoch: 5| Step: 11
Training loss: 2.823517084121704
Validation loss: 2.0781692365805307

Epoch: 70| Step: 0
Training loss: 2.0694000720977783
Validation loss: 2.0877690811951957

Epoch: 5| Step: 1
Training loss: 1.4240257740020752
Validation loss: 2.088989486296972

Epoch: 5| Step: 2
Training loss: 2.291792631149292
Validation loss: 2.091239258646965

Epoch: 5| Step: 3
Training loss: 2.3798508644104004
Validation loss: 2.100155378381411

Epoch: 5| Step: 4
Training loss: 2.4235007762908936
Validation loss: 2.099499081571897

Epoch: 5| Step: 5
Training loss: 2.3501551151275635
Validation loss: 2.100767895579338

Epoch: 5| Step: 6
Training loss: 2.314058303833008
Validation loss: 2.1045844902594886

Epoch: 5| Step: 7
Training loss: 2.575552463531494
Validation loss: 2.095857928196589

Epoch: 5| Step: 8
Training loss: 2.289409637451172
Validation loss: 2.0980867445468903

Epoch: 5| Step: 9
Training loss: 2.6712849140167236
Validation loss: 2.0923072497049966

Epoch: 5| Step: 10
Training loss: 2.228616714477539
Validation loss: 2.0826883912086487

Epoch: 5| Step: 11
Training loss: 1.7909752130508423
Validation loss: 2.0784719586372375

Epoch: 71| Step: 0
Training loss: 2.607567071914673
Validation loss: 2.072045316298803

Epoch: 5| Step: 1
Training loss: 2.4104244709014893
Validation loss: 2.065262421965599

Epoch: 5| Step: 2
Training loss: 2.372360944747925
Validation loss: 2.0604709535837173

Epoch: 5| Step: 3
Training loss: 2.1052658557891846
Validation loss: 2.062268396218618

Epoch: 5| Step: 4
Training loss: 1.6938635110855103
Validation loss: 2.062116647760073

Epoch: 5| Step: 5
Training loss: 2.235034465789795
Validation loss: 2.0634571313858032

Epoch: 5| Step: 6
Training loss: 1.8831504583358765
Validation loss: 2.0667813271284103

Epoch: 5| Step: 7
Training loss: 2.697035312652588
Validation loss: 2.0698664436737695

Epoch: 5| Step: 8
Training loss: 2.1947059631347656
Validation loss: 2.066130052010218

Epoch: 5| Step: 9
Training loss: 1.7305316925048828
Validation loss: 2.066330929597219

Epoch: 5| Step: 10
Training loss: 2.414442777633667
Validation loss: 2.0626303354899087

Epoch: 5| Step: 11
Training loss: 3.453993320465088
Validation loss: 2.0608799308538437

Epoch: 72| Step: 0
Training loss: 2.8515450954437256
Validation loss: 2.056915064652761

Epoch: 5| Step: 1
Training loss: 2.521545171737671
Validation loss: 2.0675790160894394

Epoch: 5| Step: 2
Training loss: 2.164018154144287
Validation loss: 2.0804116328557334

Epoch: 5| Step: 3
Training loss: 2.3137624263763428
Validation loss: 2.0881556371847787

Epoch: 5| Step: 4
Training loss: 2.25819993019104
Validation loss: 2.1069406320651374

Epoch: 5| Step: 5
Training loss: 2.4461827278137207
Validation loss: 2.1258353193600974

Epoch: 5| Step: 6
Training loss: 1.8984180688858032
Validation loss: 2.135688006877899

Epoch: 5| Step: 7
Training loss: 2.3519976139068604
Validation loss: 2.1402127544085183

Epoch: 5| Step: 8
Training loss: 1.9974238872528076
Validation loss: 2.1291990180810294

Epoch: 5| Step: 9
Training loss: 2.006225347518921
Validation loss: 2.1275262435277305

Epoch: 5| Step: 10
Training loss: 2.256803035736084
Validation loss: 2.118697782357534

Epoch: 5| Step: 11
Training loss: 2.3250908851623535
Validation loss: 2.108640193939209

Epoch: 73| Step: 0
Training loss: 2.285656690597534
Validation loss: 2.106153517961502

Epoch: 5| Step: 1
Training loss: 2.22493839263916
Validation loss: 2.0983135402202606

Epoch: 5| Step: 2
Training loss: 2.0942177772521973
Validation loss: 2.0914713541666665

Epoch: 5| Step: 3
Training loss: 2.7389461994171143
Validation loss: 2.0832135627667108

Epoch: 5| Step: 4
Training loss: 2.4241225719451904
Validation loss: 2.0720411588748298

Epoch: 5| Step: 5
Training loss: 2.2967116832733154
Validation loss: 2.0653008868296943

Epoch: 5| Step: 6
Training loss: 2.1921610832214355
Validation loss: 2.065367206931114

Epoch: 5| Step: 7
Training loss: 1.652142882347107
Validation loss: 2.0639305810133615

Epoch: 5| Step: 8
Training loss: 2.8435912132263184
Validation loss: 2.0580252011617026

Epoch: 5| Step: 9
Training loss: 1.9437789916992188
Validation loss: 2.0456110686063766

Epoch: 5| Step: 10
Training loss: 2.276092290878296
Validation loss: 2.048666000366211

Epoch: 5| Step: 11
Training loss: 1.312685489654541
Validation loss: 2.0494121462106705

Epoch: 74| Step: 0
Training loss: 2.292647361755371
Validation loss: 2.0596631318330765

Epoch: 5| Step: 1
Training loss: 2.390834331512451
Validation loss: 2.047584002216657

Epoch: 5| Step: 2
Training loss: 2.445793628692627
Validation loss: 2.059182678659757

Epoch: 5| Step: 3
Training loss: 2.301381826400757
Validation loss: 2.0465630888938904

Epoch: 5| Step: 4
Training loss: 2.0999958515167236
Validation loss: 2.053915192683538

Epoch: 5| Step: 5
Training loss: 2.40507435798645
Validation loss: 2.043041780591011

Epoch: 5| Step: 6
Training loss: 1.6410629749298096
Validation loss: 2.0349873155355453

Epoch: 5| Step: 7
Training loss: 2.1217517852783203
Validation loss: 2.042370781302452

Epoch: 5| Step: 8
Training loss: 2.4846596717834473
Validation loss: 2.0381126403808594

Epoch: 5| Step: 9
Training loss: 2.464759111404419
Validation loss: 2.0419447322686515

Epoch: 5| Step: 10
Training loss: 1.911214828491211
Validation loss: 2.0412624378999076

Epoch: 5| Step: 11
Training loss: 1.5045883655548096
Validation loss: 2.0490212937196097

Epoch: 75| Step: 0
Training loss: 2.1239917278289795
Validation loss: 2.0353404780228934

Epoch: 5| Step: 1
Training loss: 2.306087017059326
Validation loss: 2.038390100002289

Epoch: 5| Step: 2
Training loss: 2.0355870723724365
Validation loss: 2.039055675268173

Epoch: 5| Step: 3
Training loss: 2.1033358573913574
Validation loss: 2.041750351587931

Epoch: 5| Step: 4
Training loss: 2.273427963256836
Validation loss: 2.0359525183836618

Epoch: 5| Step: 5
Training loss: 2.4071481227874756
Validation loss: 2.0448035150766373

Epoch: 5| Step: 6
Training loss: 2.6434075832366943
Validation loss: 2.0524366597334542

Epoch: 5| Step: 7
Training loss: 2.144561767578125
Validation loss: 2.0426297982533774

Epoch: 5| Step: 8
Training loss: 2.232781171798706
Validation loss: 2.035493865609169

Epoch: 5| Step: 9
Training loss: 2.071091890335083
Validation loss: 2.0296352356672287

Epoch: 5| Step: 10
Training loss: 2.2246241569519043
Validation loss: 2.036057705680529

Epoch: 5| Step: 11
Training loss: 1.035662293434143
Validation loss: 2.035093734661738

Testing loss: 1.6574555867009884
