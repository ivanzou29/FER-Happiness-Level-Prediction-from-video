Epoch: 1| Step: 0
Training loss: 6.501992727143589
Validation loss: 5.876710061172557

Epoch: 5| Step: 1
Training loss: 5.909343252596007
Validation loss: 5.875239225346284

Epoch: 5| Step: 2
Training loss: 6.237141924959688
Validation loss: 5.873787788701981

Epoch: 5| Step: 3
Training loss: 6.479498001245508
Validation loss: 5.8722367924188985

Epoch: 5| Step: 4
Training loss: 5.451803052629304
Validation loss: 5.870704088036055

Epoch: 5| Step: 5
Training loss: 5.52431557675272
Validation loss: 5.869265835442512

Epoch: 5| Step: 6
Training loss: 6.046733056110173
Validation loss: 5.867689278010313

Epoch: 5| Step: 7
Training loss: 5.695533193490694
Validation loss: 5.866053715929558

Epoch: 5| Step: 8
Training loss: 5.245115460196839
Validation loss: 5.864517721980187

Epoch: 5| Step: 9
Training loss: 5.949601539925738
Validation loss: 5.862900435457509

Epoch: 5| Step: 10
Training loss: 6.697641544021094
Validation loss: 5.861224236182571

Epoch: 5| Step: 11
Training loss: 5.591269172074426
Validation loss: 5.859425150338767

Epoch: 2| Step: 0
Training loss: 5.550754275917482
Validation loss: 5.8576012329848925

Epoch: 5| Step: 1
Training loss: 5.946682224566945
Validation loss: 5.855786905940205

Epoch: 5| Step: 2
Training loss: 6.676764597156309
Validation loss: 5.853870658133329

Epoch: 5| Step: 3
Training loss: 5.6026977920853875
Validation loss: 5.85182904399088

Epoch: 5| Step: 4
Training loss: 6.3327056506799915
Validation loss: 5.8495507714462365

Epoch: 5| Step: 5
Training loss: 5.813530287133117
Validation loss: 5.847361517923543

Epoch: 5| Step: 6
Training loss: 5.917344103791479
Validation loss: 5.845103258461411

Epoch: 5| Step: 7
Training loss: 6.940619789612801
Validation loss: 5.842604519778759

Epoch: 5| Step: 8
Training loss: 5.307974290108527
Validation loss: 5.840111536458909

Epoch: 5| Step: 9
Training loss: 6.071430353757452
Validation loss: 5.837452805387548

Epoch: 5| Step: 10
Training loss: 5.2918509904292685
Validation loss: 5.834623203266224

Epoch: 5| Step: 11
Training loss: 5.509606554831124
Validation loss: 5.831635264337286

Epoch: 3| Step: 0
Training loss: 6.116563241415106
Validation loss: 5.82871561748048

Epoch: 5| Step: 1
Training loss: 5.666829536939718
Validation loss: 5.825574724280363

Epoch: 5| Step: 2
Training loss: 5.437584185770713
Validation loss: 5.822254896234035

Epoch: 5| Step: 3
Training loss: 5.8041081710609905
Validation loss: 5.818775740476738

Epoch: 5| Step: 4
Training loss: 4.43926236254249
Validation loss: 5.8151500567413414

Epoch: 5| Step: 5
Training loss: 6.6243421119948245
Validation loss: 5.811417078843952

Epoch: 5| Step: 6
Training loss: 6.27683205171755
Validation loss: 5.807421554230488

Epoch: 5| Step: 7
Training loss: 6.0402777116606465
Validation loss: 5.803272257908375

Epoch: 5| Step: 8
Training loss: 5.929234584152178
Validation loss: 5.799081462989376

Epoch: 5| Step: 9
Training loss: 5.978908980750389
Validation loss: 5.794517373544194

Epoch: 5| Step: 10
Training loss: 6.430217290027815
Validation loss: 5.789701453128778

Epoch: 5| Step: 11
Training loss: 6.6446601366284215
Validation loss: 5.7846528906888794

Epoch: 4| Step: 0
Training loss: 5.303676323451999
Validation loss: 5.779535056402938

Epoch: 5| Step: 1
Training loss: 6.1130762620384544
Validation loss: 5.774005110063308

Epoch: 5| Step: 2
Training loss: 4.97663972755767
Validation loss: 5.768449189845734

Epoch: 5| Step: 3
Training loss: 6.515429743121234
Validation loss: 5.76266952342525

Epoch: 5| Step: 4
Training loss: 5.664534597782297
Validation loss: 5.756736320084524

Epoch: 5| Step: 5
Training loss: 6.027765245712699
Validation loss: 5.750530322124386

Epoch: 5| Step: 6
Training loss: 6.173004742329955
Validation loss: 5.744222059972942

Epoch: 5| Step: 7
Training loss: 5.47387594589919
Validation loss: 5.737748528377332

Epoch: 5| Step: 8
Training loss: 6.681379993911952
Validation loss: 5.7314099607397315

Epoch: 5| Step: 9
Training loss: 5.491736880573768
Validation loss: 5.724431500534186

Epoch: 5| Step: 10
Training loss: 5.930873345172245
Validation loss: 5.717355943874112

Epoch: 5| Step: 11
Training loss: 5.53533956780064
Validation loss: 5.710888801085274

Epoch: 5| Step: 0
Training loss: 6.047168970971174
Validation loss: 5.703744271157279

Epoch: 5| Step: 1
Training loss: 5.6561115732694365
Validation loss: 5.696804498322381

Epoch: 5| Step: 2
Training loss: 6.812079460392916
Validation loss: 5.689886053751186

Epoch: 5| Step: 3
Training loss: 4.901619639624513
Validation loss: 5.6826166980159964

Epoch: 5| Step: 4
Training loss: 4.77048032473529
Validation loss: 5.675934262892161

Epoch: 5| Step: 5
Training loss: 5.375430954800657
Validation loss: 5.668974191535686

Epoch: 5| Step: 6
Training loss: 5.833401743169829
Validation loss: 5.662065526646216

Epoch: 5| Step: 7
Training loss: 6.281125499193683
Validation loss: 5.654920186334847

Epoch: 5| Step: 8
Training loss: 5.97075455643125
Validation loss: 5.648156334512658

Epoch: 5| Step: 9
Training loss: 6.0958307870723525
Validation loss: 5.640878455049724

Epoch: 5| Step: 10
Training loss: 5.803330274329492
Validation loss: 5.63400128324623

Epoch: 5| Step: 11
Training loss: 4.660303591551702
Validation loss: 5.626756817598688

Epoch: 6| Step: 0
Training loss: 5.762718729431536
Validation loss: 5.620087010987259

Epoch: 5| Step: 1
Training loss: 5.831225677472218
Validation loss: 5.613401074989896

Epoch: 5| Step: 2
Training loss: 5.37201128526583
Validation loss: 5.607047296686851

Epoch: 5| Step: 3
Training loss: 5.006237145263322
Validation loss: 5.600685692996005

Epoch: 5| Step: 4
Training loss: 5.609078997184411
Validation loss: 5.594430381271498

Epoch: 5| Step: 5
Training loss: 5.097803480572598
Validation loss: 5.588023346266222

Epoch: 5| Step: 6
Training loss: 5.894899471807373
Validation loss: 5.582074545355809

Epoch: 5| Step: 7
Training loss: 5.794232941121418
Validation loss: 5.5758357261265274

Epoch: 5| Step: 8
Training loss: 5.588773591655781
Validation loss: 5.569852270487826

Epoch: 5| Step: 9
Training loss: 6.889998565363631
Validation loss: 5.5635501213226135

Epoch: 5| Step: 10
Training loss: 5.769500835651047
Validation loss: 5.557527248128725

Epoch: 5| Step: 11
Training loss: 5.3873298635856735
Validation loss: 5.551420636256352

Epoch: 7| Step: 0
Training loss: 6.279361573830762
Validation loss: 5.545559858844327

Epoch: 5| Step: 1
Training loss: 5.63609965117315
Validation loss: 5.539746850641691

Epoch: 5| Step: 2
Training loss: 5.484721376615367
Validation loss: 5.534188260633359

Epoch: 5| Step: 3
Training loss: 5.633652707739526
Validation loss: 5.528756529720601

Epoch: 5| Step: 4
Training loss: 5.428285530277288
Validation loss: 5.52326652121936

Epoch: 5| Step: 5
Training loss: 5.673084813078923
Validation loss: 5.518022896723652

Epoch: 5| Step: 6
Training loss: 5.462757598599327
Validation loss: 5.512704719150245

Epoch: 5| Step: 7
Training loss: 5.1388121773890925
Validation loss: 5.5074149563215125

Epoch: 5| Step: 8
Training loss: 5.929613517530899
Validation loss: 5.502035255708362

Epoch: 5| Step: 9
Training loss: 5.557170758158071
Validation loss: 5.496868181106938

Epoch: 5| Step: 10
Training loss: 5.923036969609372
Validation loss: 5.491523901550614

Epoch: 5| Step: 11
Training loss: 4.5375532835466945
Validation loss: 5.486349838900122

Epoch: 8| Step: 0
Training loss: 5.844372394892846
Validation loss: 5.48109327706263

Epoch: 5| Step: 1
Training loss: 5.481079328570159
Validation loss: 5.475696090679718

Epoch: 5| Step: 2
Training loss: 5.51038039928056
Validation loss: 5.470804333616021

Epoch: 5| Step: 3
Training loss: 5.499288686358282
Validation loss: 5.465120917038615

Epoch: 5| Step: 4
Training loss: 6.150981992151614
Validation loss: 5.4593369335411595

Epoch: 5| Step: 5
Training loss: 4.890679209838335
Validation loss: 5.453470694615945

Epoch: 5| Step: 6
Training loss: 5.469597276720365
Validation loss: 5.447436764393697

Epoch: 5| Step: 7
Training loss: 5.97787592798241
Validation loss: 5.441768498171364

Epoch: 5| Step: 8
Training loss: 5.288174756150454
Validation loss: 5.435674360879483

Epoch: 5| Step: 9
Training loss: 5.193388021733703
Validation loss: 5.430341722333271

Epoch: 5| Step: 10
Training loss: 5.720046266488715
Validation loss: 5.42520457114978

Epoch: 5| Step: 11
Training loss: 6.428903117024392
Validation loss: 5.4195679475164065

Epoch: 9| Step: 0
Training loss: 5.8661640356509
Validation loss: 5.414082257857241

Epoch: 5| Step: 1
Training loss: 4.62271061501537
Validation loss: 5.408475979871822

Epoch: 5| Step: 2
Training loss: 5.543588099647618
Validation loss: 5.403125374483088

Epoch: 5| Step: 3
Training loss: 5.221330199024115
Validation loss: 5.398311453422888

Epoch: 5| Step: 4
Training loss: 5.4339747785503105
Validation loss: 5.393456140368796

Epoch: 5| Step: 5
Training loss: 5.705442193000976
Validation loss: 5.388339419661881

Epoch: 5| Step: 6
Training loss: 5.72899905797678
Validation loss: 5.383537254762252

Epoch: 5| Step: 7
Training loss: 5.841437060550516
Validation loss: 5.378848760515104

Epoch: 5| Step: 8
Training loss: 5.903613920143765
Validation loss: 5.373750615367985

Epoch: 5| Step: 9
Training loss: 5.522376059664929
Validation loss: 5.368540423517442

Epoch: 5| Step: 10
Training loss: 5.343234031708001
Validation loss: 5.363657546173004

Epoch: 5| Step: 11
Training loss: 4.132188948263425
Validation loss: 5.358831765509335

Epoch: 10| Step: 0
Training loss: 5.923026020848831
Validation loss: 5.354395377868891

Epoch: 5| Step: 1
Training loss: 6.126988613620524
Validation loss: 5.349526478855267

Epoch: 5| Step: 2
Training loss: 4.9897087999893746
Validation loss: 5.345438707116784

Epoch: 5| Step: 3
Training loss: 6.035632186937512
Validation loss: 5.340606627517327

Epoch: 5| Step: 4
Training loss: 5.686786984195318
Validation loss: 5.335538090529838

Epoch: 5| Step: 5
Training loss: 5.4885959304247915
Validation loss: 5.331100378884803

Epoch: 5| Step: 6
Training loss: 5.939663783875188
Validation loss: 5.326196606826575

Epoch: 5| Step: 7
Training loss: 4.674737264012688
Validation loss: 5.321561632172169

Epoch: 5| Step: 8
Training loss: 5.317198885564415
Validation loss: 5.316868739737453

Epoch: 5| Step: 9
Training loss: 4.182417788886115
Validation loss: 5.311778943363704

Epoch: 5| Step: 10
Training loss: 4.904911903577918
Validation loss: 5.307138482585684

Epoch: 5| Step: 11
Training loss: 7.052100432772921
Validation loss: 5.303221524824462

Epoch: 11| Step: 0
Training loss: 4.996637739759866
Validation loss: 5.2987851474967425

Epoch: 5| Step: 1
Training loss: 5.056947653869338
Validation loss: 5.294446698026299

Epoch: 5| Step: 2
Training loss: 5.034884449183116
Validation loss: 5.290662853017677

Epoch: 5| Step: 3
Training loss: 5.556383520523799
Validation loss: 5.28647070321075

Epoch: 5| Step: 4
Training loss: 6.189460829022501
Validation loss: 5.282484673933528

Epoch: 5| Step: 5
Training loss: 5.116445519620924
Validation loss: 5.277844325978968

Epoch: 5| Step: 6
Training loss: 5.348630583718953
Validation loss: 5.274108459738928

Epoch: 5| Step: 7
Training loss: 6.013386099189847
Validation loss: 5.269711441642888

Epoch: 5| Step: 8
Training loss: 5.04996511617264
Validation loss: 5.265591841082964

Epoch: 5| Step: 9
Training loss: 5.531067926028729
Validation loss: 5.261147048654689

Epoch: 5| Step: 10
Training loss: 5.586846209685632
Validation loss: 5.256698921256246

Epoch: 5| Step: 11
Training loss: 4.214212647883012
Validation loss: 5.252303927352548

Epoch: 12| Step: 0
Training loss: 6.042111750903023
Validation loss: 5.248695642926168

Epoch: 5| Step: 1
Training loss: 5.3998401547545285
Validation loss: 5.244051219668224

Epoch: 5| Step: 2
Training loss: 5.624376898268324
Validation loss: 5.239601456273958

Epoch: 5| Step: 3
Training loss: 5.996426789916322
Validation loss: 5.234865201704149

Epoch: 5| Step: 4
Training loss: 5.659999216032479
Validation loss: 5.230529009904228

Epoch: 5| Step: 5
Training loss: 5.120297018615023
Validation loss: 5.225765925946824

Epoch: 5| Step: 6
Training loss: 5.503013825471464
Validation loss: 5.221003063190046

Epoch: 5| Step: 7
Training loss: 4.70511866291171
Validation loss: 5.216954011691629

Epoch: 5| Step: 8
Training loss: 5.471769011825556
Validation loss: 5.212412017884758

Epoch: 5| Step: 9
Training loss: 4.202789179776739
Validation loss: 5.208060191303752

Epoch: 5| Step: 10
Training loss: 5.093884799788431
Validation loss: 5.203874650473743

Epoch: 5| Step: 11
Training loss: 4.077293106527674
Validation loss: 5.199916014237626

Epoch: 13| Step: 0
Training loss: 5.0496956233085495
Validation loss: 5.195677130196071

Epoch: 5| Step: 1
Training loss: 5.376162913294954
Validation loss: 5.191289199569653

Epoch: 5| Step: 2
Training loss: 5.23308526846276
Validation loss: 5.187242103202092

Epoch: 5| Step: 3
Training loss: 5.418427440366224
Validation loss: 5.183046773469471

Epoch: 5| Step: 4
Training loss: 5.590846325676382
Validation loss: 5.178983568600407

Epoch: 5| Step: 5
Training loss: 5.219243009202707
Validation loss: 5.175065991384804

Epoch: 5| Step: 6
Training loss: 5.321878748840338
Validation loss: 5.170511540439525

Epoch: 5| Step: 7
Training loss: 5.870632090028689
Validation loss: 5.1668601948373825

Epoch: 5| Step: 8
Training loss: 5.192260580039322
Validation loss: 5.163000331337565

Epoch: 5| Step: 9
Training loss: 4.920185101756526
Validation loss: 5.159016731957739

Epoch: 5| Step: 10
Training loss: 4.738469232539619
Validation loss: 5.155087334145606

Epoch: 5| Step: 11
Training loss: 6.565668412963327
Validation loss: 5.150907511518234

Epoch: 14| Step: 0
Training loss: 5.4918935162583855
Validation loss: 5.147044918217829

Epoch: 5| Step: 1
Training loss: 5.53408189252639
Validation loss: 5.143010684495331

Epoch: 5| Step: 2
Training loss: 5.5109194818801885
Validation loss: 5.138536711243903

Epoch: 5| Step: 3
Training loss: 5.85590326835911
Validation loss: 5.134830219553667

Epoch: 5| Step: 4
Training loss: 5.326231320717033
Validation loss: 5.1305646382125065

Epoch: 5| Step: 5
Training loss: 4.466548350650776
Validation loss: 5.126443179004508

Epoch: 5| Step: 6
Training loss: 4.696471923263353
Validation loss: 5.122607517829969

Epoch: 5| Step: 7
Training loss: 4.774807048314393
Validation loss: 5.118388400504636

Epoch: 5| Step: 8
Training loss: 5.614262483826766
Validation loss: 5.1146548538749474

Epoch: 5| Step: 9
Training loss: 5.256145876330546
Validation loss: 5.110403472638687

Epoch: 5| Step: 10
Training loss: 5.054971064966779
Validation loss: 5.105967716428267

Epoch: 5| Step: 11
Training loss: 5.323847779457354
Validation loss: 5.102611307365849

Epoch: 15| Step: 0
Training loss: 5.069193429988606
Validation loss: 5.098737377435738

Epoch: 5| Step: 1
Training loss: 5.167834775403442
Validation loss: 5.094634675507454

Epoch: 5| Step: 2
Training loss: 5.092141488386211
Validation loss: 5.0908293512682325

Epoch: 5| Step: 3
Training loss: 5.056637230227714
Validation loss: 5.086060881399931

Epoch: 5| Step: 4
Training loss: 5.00755140364836
Validation loss: 5.082228597864858

Epoch: 5| Step: 5
Training loss: 5.25074871718924
Validation loss: 5.078566186764366

Epoch: 5| Step: 6
Training loss: 5.5944692479610465
Validation loss: 5.074443323707739

Epoch: 5| Step: 7
Training loss: 5.460316285694386
Validation loss: 5.069936071214787

Epoch: 5| Step: 8
Training loss: 5.232047129870817
Validation loss: 5.065982946997935

Epoch: 5| Step: 9
Training loss: 5.527181907414165
Validation loss: 5.063017893230724

Epoch: 5| Step: 10
Training loss: 4.68208101482605
Validation loss: 5.058668114939134

Epoch: 5| Step: 11
Training loss: 5.416751606593134
Validation loss: 5.054774311623213

Epoch: 16| Step: 0
Training loss: 5.170740101004756
Validation loss: 5.049658788037591

Epoch: 5| Step: 1
Training loss: 5.4149389397021945
Validation loss: 5.045621576546274

Epoch: 5| Step: 2
Training loss: 5.156838863155109
Validation loss: 5.042160540684911

Epoch: 5| Step: 3
Training loss: 4.498919039277397
Validation loss: 5.037542361261987

Epoch: 5| Step: 4
Training loss: 4.869273808597716
Validation loss: 5.032322479050538

Epoch: 5| Step: 5
Training loss: 5.512500429045299
Validation loss: 5.027871733285785

Epoch: 5| Step: 6
Training loss: 4.894402650694864
Validation loss: 5.0233617591981785

Epoch: 5| Step: 7
Training loss: 5.414054044906818
Validation loss: 5.019723233956233

Epoch: 5| Step: 8
Training loss: 5.916714878512677
Validation loss: 5.015511563960331

Epoch: 5| Step: 9
Training loss: 4.554428276419427
Validation loss: 5.011126758065128

Epoch: 5| Step: 10
Training loss: 5.555705174444696
Validation loss: 5.006290301646088

Epoch: 5| Step: 11
Training loss: 1.8151614938564824
Validation loss: 5.002058892731204

Epoch: 17| Step: 0
Training loss: 5.288410817149824
Validation loss: 4.99821932396899

Epoch: 5| Step: 1
Training loss: 5.198245764986793
Validation loss: 4.994062426823502

Epoch: 5| Step: 2
Training loss: 5.406592562191544
Validation loss: 4.990100294925945

Epoch: 5| Step: 3
Training loss: 5.34769851522971
Validation loss: 4.985746842622996

Epoch: 5| Step: 4
Training loss: 5.435496344761535
Validation loss: 4.981547056663593

Epoch: 5| Step: 5
Training loss: 4.520731747565572
Validation loss: 4.977087036148467

Epoch: 5| Step: 6
Training loss: 4.768834168577534
Validation loss: 4.973183323529873

Epoch: 5| Step: 7
Training loss: 4.426109847204043
Validation loss: 4.969119364127194

Epoch: 5| Step: 8
Training loss: 5.0017895357132245
Validation loss: 4.964955118302359

Epoch: 5| Step: 9
Training loss: 5.095355009190011
Validation loss: 4.960948938071214

Epoch: 5| Step: 10
Training loss: 5.9239034676217655
Validation loss: 4.957058641194207

Epoch: 5| Step: 11
Training loss: 1.828605132345828
Validation loss: 4.95242985802343

Epoch: 18| Step: 0
Training loss: 5.068576885987814
Validation loss: 4.948139887007547

Epoch: 5| Step: 1
Training loss: 5.211801254312479
Validation loss: 4.943784866499415

Epoch: 5| Step: 2
Training loss: 5.521046510815224
Validation loss: 4.940523855359138

Epoch: 5| Step: 3
Training loss: 4.7685325882974
Validation loss: 4.936510542221659

Epoch: 5| Step: 4
Training loss: 3.925274352185997
Validation loss: 4.932118295632272

Epoch: 5| Step: 5
Training loss: 4.5557924896487805
Validation loss: 4.928215310819994

Epoch: 5| Step: 6
Training loss: 5.772065986980454
Validation loss: 4.924079449786596

Epoch: 5| Step: 7
Training loss: 5.263328345700865
Validation loss: 4.920250470135976

Epoch: 5| Step: 8
Training loss: 5.0351333321700125
Validation loss: 4.916352442490338

Epoch: 5| Step: 9
Training loss: 4.871400139785215
Validation loss: 4.911800767672792

Epoch: 5| Step: 10
Training loss: 5.572395352612762
Validation loss: 4.9077212401605745

Epoch: 5| Step: 11
Training loss: 3.747702085251682
Validation loss: 4.90345213823729

Epoch: 19| Step: 0
Training loss: 5.399180823463234
Validation loss: 4.899563381633378

Epoch: 5| Step: 1
Training loss: 4.906432518935342
Validation loss: 4.895301606001484

Epoch: 5| Step: 2
Training loss: 4.275446836085482
Validation loss: 4.8917382042813236

Epoch: 5| Step: 3
Training loss: 4.400988311745123
Validation loss: 4.887436978388314

Epoch: 5| Step: 4
Training loss: 5.198975520817967
Validation loss: 4.883005920648224

Epoch: 5| Step: 5
Training loss: 4.486555785405076
Validation loss: 4.879189435458897

Epoch: 5| Step: 6
Training loss: 5.625399766067845
Validation loss: 4.875032946483429

Epoch: 5| Step: 7
Training loss: 4.869802981548798
Validation loss: 4.871046125703813

Epoch: 5| Step: 8
Training loss: 5.37171303248045
Validation loss: 4.866958318859079

Epoch: 5| Step: 9
Training loss: 5.809445142399473
Validation loss: 4.862970222219859

Epoch: 5| Step: 10
Training loss: 4.5798998832587845
Validation loss: 4.8582845938425905

Epoch: 5| Step: 11
Training loss: 4.299608505524805
Validation loss: 4.854057358532929

Epoch: 20| Step: 0
Training loss: 4.611357492097297
Validation loss: 4.849694925066527

Epoch: 5| Step: 1
Training loss: 4.883172057074096
Validation loss: 4.845791245089403

Epoch: 5| Step: 2
Training loss: 5.281840816157428
Validation loss: 4.841412371896826

Epoch: 5| Step: 3
Training loss: 4.3784545338766065
Validation loss: 4.836876116138525

Epoch: 5| Step: 4
Training loss: 4.978842412161357
Validation loss: 4.832755468068808

Epoch: 5| Step: 5
Training loss: 5.953278146611157
Validation loss: 4.82852017329629

Epoch: 5| Step: 6
Training loss: 4.644144181660784
Validation loss: 4.82405819439093

Epoch: 5| Step: 7
Training loss: 4.017307270509498
Validation loss: 4.819852661753782

Epoch: 5| Step: 8
Training loss: 4.807346507621012
Validation loss: 4.81542306122214

Epoch: 5| Step: 9
Training loss: 5.494687896278974
Validation loss: 4.810852648193363

Epoch: 5| Step: 10
Training loss: 4.849795795349717
Validation loss: 4.80676498365885

Epoch: 5| Step: 11
Training loss: 6.362360972626129
Validation loss: 4.802587506133969

Epoch: 21| Step: 0
Training loss: 4.840758156468772
Validation loss: 4.797858900461474

Epoch: 5| Step: 1
Training loss: 4.795819393152061
Validation loss: 4.794008133497939

Epoch: 5| Step: 2
Training loss: 4.750510338924084
Validation loss: 4.789514981789166

Epoch: 5| Step: 3
Training loss: 5.194770956855504
Validation loss: 4.7851784385114815

Epoch: 5| Step: 4
Training loss: 4.643609830607125
Validation loss: 4.7805287849823905

Epoch: 5| Step: 5
Training loss: 4.554135951677049
Validation loss: 4.775978714733626

Epoch: 5| Step: 6
Training loss: 5.447900756268095
Validation loss: 4.771874212911558

Epoch: 5| Step: 7
Training loss: 5.1007013923188556
Validation loss: 4.76700750423956

Epoch: 5| Step: 8
Training loss: 4.725019521521553
Validation loss: 4.762622967498373

Epoch: 5| Step: 9
Training loss: 4.631428555278219
Validation loss: 4.7578890689395

Epoch: 5| Step: 10
Training loss: 4.899297173367701
Validation loss: 4.753662169978616

Epoch: 5| Step: 11
Training loss: 6.144446816807052
Validation loss: 4.749324474485133

Epoch: 22| Step: 0
Training loss: 4.845437229769036
Validation loss: 4.744111702941958

Epoch: 5| Step: 1
Training loss: 4.986656503888006
Validation loss: 4.740467452983473

Epoch: 5| Step: 2
Training loss: 5.460468059221778
Validation loss: 4.7358566332652305

Epoch: 5| Step: 3
Training loss: 4.981059631002968
Validation loss: 4.731042585105604

Epoch: 5| Step: 4
Training loss: 4.6721113776687515
Validation loss: 4.726437687342459

Epoch: 5| Step: 5
Training loss: 5.039125332699351
Validation loss: 4.72206900884119

Epoch: 5| Step: 6
Training loss: 4.496352730988721
Validation loss: 4.717103641451581

Epoch: 5| Step: 7
Training loss: 4.840768006923136
Validation loss: 4.71206370694207

Epoch: 5| Step: 8
Training loss: 4.604115320440088
Validation loss: 4.707445890912841

Epoch: 5| Step: 9
Training loss: 4.712422960698929
Validation loss: 4.702298012450975

Epoch: 5| Step: 10
Training loss: 4.367201039083441
Validation loss: 4.6973075077042825

Epoch: 5| Step: 11
Training loss: 5.963349300652427
Validation loss: 4.69238163540839

Epoch: 23| Step: 0
Training loss: 4.578404961576411
Validation loss: 4.687836011923377

Epoch: 5| Step: 1
Training loss: 4.178443566719406
Validation loss: 4.68307398907242

Epoch: 5| Step: 2
Training loss: 4.758607995189337
Validation loss: 4.678105362294783

Epoch: 5| Step: 3
Training loss: 5.069694963416905
Validation loss: 4.673083885739541

Epoch: 5| Step: 4
Training loss: 4.626976827912588
Validation loss: 4.668320144345057

Epoch: 5| Step: 5
Training loss: 4.8785868434028155
Validation loss: 4.663354867899547

Epoch: 5| Step: 6
Training loss: 4.314463956032693
Validation loss: 4.658881406098495

Epoch: 5| Step: 7
Training loss: 5.326451192483435
Validation loss: 4.654439305260425

Epoch: 5| Step: 8
Training loss: 5.367647509455758
Validation loss: 4.6500277750833305

Epoch: 5| Step: 9
Training loss: 4.241659619838255
Validation loss: 4.644705249124765

Epoch: 5| Step: 10
Training loss: 5.354657735705685
Validation loss: 4.63968573589852

Epoch: 5| Step: 11
Training loss: 3.6751740913936013
Validation loss: 4.634583493338212

Epoch: 24| Step: 0
Training loss: 4.181450644840766
Validation loss: 4.629491373629178

Epoch: 5| Step: 1
Training loss: 4.062621598991444
Validation loss: 4.625227097786709

Epoch: 5| Step: 2
Training loss: 4.20698885953864
Validation loss: 4.620434479430415

Epoch: 5| Step: 3
Training loss: 5.005787551608719
Validation loss: 4.615540151950448

Epoch: 5| Step: 4
Training loss: 4.274018131401506
Validation loss: 4.6108331906136915

Epoch: 5| Step: 5
Training loss: 4.130341510461573
Validation loss: 4.606266167317714

Epoch: 5| Step: 6
Training loss: 5.142347238633411
Validation loss: 4.602590673804664

Epoch: 5| Step: 7
Training loss: 5.310466601602292
Validation loss: 4.597833449050379

Epoch: 5| Step: 8
Training loss: 5.103251015671782
Validation loss: 4.591921003235934

Epoch: 5| Step: 9
Training loss: 5.117895272498615
Validation loss: 4.588453790672602

Epoch: 5| Step: 10
Training loss: 5.340484870871357
Validation loss: 4.583840466388446

Epoch: 5| Step: 11
Training loss: 4.155506956753526
Validation loss: 4.57773366216793

Epoch: 25| Step: 0
Training loss: 4.582102431112707
Validation loss: 4.572514625666361

Epoch: 5| Step: 1
Training loss: 4.678455222380809
Validation loss: 4.568682248873884

Epoch: 5| Step: 2
Training loss: 4.787580301194003
Validation loss: 4.564244942575743

Epoch: 5| Step: 3
Training loss: 4.375336770311252
Validation loss: 4.557345984725586

Epoch: 5| Step: 4
Training loss: 4.507128050358577
Validation loss: 4.552167052220025

Epoch: 5| Step: 5
Training loss: 4.635328564896022
Validation loss: 4.547876547046545

Epoch: 5| Step: 6
Training loss: 4.305928406243799
Validation loss: 4.542998471522286

Epoch: 5| Step: 7
Training loss: 4.4708586299544395
Validation loss: 4.53735615823686

Epoch: 5| Step: 8
Training loss: 4.776341929785242
Validation loss: 4.532143270204883

Epoch: 5| Step: 9
Training loss: 5.483076066742694
Validation loss: 4.527855454437127

Epoch: 5| Step: 10
Training loss: 4.600717049149297
Validation loss: 4.523279036852197

Epoch: 5| Step: 11
Training loss: 5.27590834765183
Validation loss: 4.516583993138688

Epoch: 26| Step: 0
Training loss: 4.930305937894255
Validation loss: 4.51167214990195

Epoch: 5| Step: 1
Training loss: 4.347441497461759
Validation loss: 4.506263272763695

Epoch: 5| Step: 2
Training loss: 5.0765228091467405
Validation loss: 4.500894978499034

Epoch: 5| Step: 3
Training loss: 5.300654230584825
Validation loss: 4.495284117254492

Epoch: 5| Step: 4
Training loss: 4.65225580934675
Validation loss: 4.49013457782646

Epoch: 5| Step: 5
Training loss: 4.409890909381048
Validation loss: 4.484426659830334

Epoch: 5| Step: 6
Training loss: 3.78945989982708
Validation loss: 4.47918592345364

Epoch: 5| Step: 7
Training loss: 4.963237655738817
Validation loss: 4.473422046829662

Epoch: 5| Step: 8
Training loss: 4.414513164908935
Validation loss: 4.468219547755683

Epoch: 5| Step: 9
Training loss: 4.67826034360309
Validation loss: 4.463388797215023

Epoch: 5| Step: 10
Training loss: 3.889460010068477
Validation loss: 4.45758487384557

Epoch: 5| Step: 11
Training loss: 4.927007415165091
Validation loss: 4.452286432739244

Epoch: 27| Step: 0
Training loss: 4.644360820700878
Validation loss: 4.446505627244416

Epoch: 5| Step: 1
Training loss: 4.4034990962610046
Validation loss: 4.441605088461367

Epoch: 5| Step: 2
Training loss: 5.332448687299817
Validation loss: 4.436792173929509

Epoch: 5| Step: 3
Training loss: 4.309635703850424
Validation loss: 4.430566923564702

Epoch: 5| Step: 4
Training loss: 3.70756322743783
Validation loss: 4.425965864478527

Epoch: 5| Step: 5
Training loss: 4.256888024995329
Validation loss: 4.422440711724323

Epoch: 5| Step: 6
Training loss: 4.669567546221554
Validation loss: 4.41640794044209

Epoch: 5| Step: 7
Training loss: 4.462410224417554
Validation loss: 4.40964143967747

Epoch: 5| Step: 8
Training loss: 4.563257650932494
Validation loss: 4.4043712623782065

Epoch: 5| Step: 9
Training loss: 4.958584349019173
Validation loss: 4.399759350322368

Epoch: 5| Step: 10
Training loss: 4.729915117143315
Validation loss: 4.393637197465475

Epoch: 5| Step: 11
Training loss: 3.5198259135026473
Validation loss: 4.387970303962381

Epoch: 28| Step: 0
Training loss: 4.291176752564841
Validation loss: 4.381664146080661

Epoch: 5| Step: 1
Training loss: 4.552037405426857
Validation loss: 4.376536971279595

Epoch: 5| Step: 2
Training loss: 4.849096288743386
Validation loss: 4.371294441422663

Epoch: 5| Step: 3
Training loss: 5.049921114465958
Validation loss: 4.365416420732711

Epoch: 5| Step: 4
Training loss: 4.162756623843218
Validation loss: 4.359772175296142

Epoch: 5| Step: 5
Training loss: 4.261174265959787
Validation loss: 4.353731789234594

Epoch: 5| Step: 6
Training loss: 4.337817635023031
Validation loss: 4.348387796892603

Epoch: 5| Step: 7
Training loss: 3.8059523592927507
Validation loss: 4.343241334766903

Epoch: 5| Step: 8
Training loss: 5.204196762270782
Validation loss: 4.337814364735527

Epoch: 5| Step: 9
Training loss: 4.030862479102884
Validation loss: 4.332770392030678

Epoch: 5| Step: 10
Training loss: 4.421482028281469
Validation loss: 4.326092207083941

Epoch: 5| Step: 11
Training loss: 5.236929472300688
Validation loss: 4.320818410986819

Epoch: 29| Step: 0
Training loss: 4.260152471258411
Validation loss: 4.316571442217765

Epoch: 5| Step: 1
Training loss: 4.165959081968021
Validation loss: 4.310486659862515

Epoch: 5| Step: 2
Training loss: 4.245114154696122
Validation loss: 4.3041223523104275

Epoch: 5| Step: 3
Training loss: 4.225617421198
Validation loss: 4.298093939617142

Epoch: 5| Step: 4
Training loss: 4.602138826453859
Validation loss: 4.29344029334557

Epoch: 5| Step: 5
Training loss: 4.634177716017988
Validation loss: 4.2876902262803

Epoch: 5| Step: 6
Training loss: 4.459394999982525
Validation loss: 4.28152145212004

Epoch: 5| Step: 7
Training loss: 4.288757202177969
Validation loss: 4.275816743846158

Epoch: 5| Step: 8
Training loss: 4.654597661283705
Validation loss: 4.2701467691014035

Epoch: 5| Step: 9
Training loss: 4.152428497856353
Validation loss: 4.264136253717146

Epoch: 5| Step: 10
Training loss: 4.671738230256595
Validation loss: 4.258356396761335

Epoch: 5| Step: 11
Training loss: 5.2207948253497225
Validation loss: 4.252866241297162

Epoch: 30| Step: 0
Training loss: 4.018761267282878
Validation loss: 4.24688520544911

Epoch: 5| Step: 1
Training loss: 4.583992280697273
Validation loss: 4.241056793876007

Epoch: 5| Step: 2
Training loss: 4.834333162921951
Validation loss: 4.235017265605898

Epoch: 5| Step: 3
Training loss: 4.265263915935685
Validation loss: 4.229046667992948

Epoch: 5| Step: 4
Training loss: 4.671595944647176
Validation loss: 4.223216779207527

Epoch: 5| Step: 5
Training loss: 4.63266716611732
Validation loss: 4.217662397935157

Epoch: 5| Step: 6
Training loss: 4.314315634833949
Validation loss: 4.2114144163116585

Epoch: 5| Step: 7
Training loss: 4.083495130382599
Validation loss: 4.205682120832635

Epoch: 5| Step: 8
Training loss: 3.752757393830009
Validation loss: 4.199959566285008

Epoch: 5| Step: 9
Training loss: 4.52377354982839
Validation loss: 4.1945794978865845

Epoch: 5| Step: 10
Training loss: 4.388117933095119
Validation loss: 4.1878605018416915

Epoch: 5| Step: 11
Training loss: 1.9078335047759805
Validation loss: 4.1822170553365225

Epoch: 31| Step: 0
Training loss: 4.833413792082988
Validation loss: 4.176606513354109

Epoch: 5| Step: 1
Training loss: 4.294638533741582
Validation loss: 4.171288967047725

Epoch: 5| Step: 2
Training loss: 3.6528199890044286
Validation loss: 4.165580711310552

Epoch: 5| Step: 3
Training loss: 4.510420284607503
Validation loss: 4.16030611296606

Epoch: 5| Step: 4
Training loss: 5.079985010920962
Validation loss: 4.154597869476261

Epoch: 5| Step: 5
Training loss: 4.1010430288599204
Validation loss: 4.149267134051843

Epoch: 5| Step: 6
Training loss: 3.9232557077650116
Validation loss: 4.143631665212056

Epoch: 5| Step: 7
Training loss: 3.6509581523201105
Validation loss: 4.138293208318084

Epoch: 5| Step: 8
Training loss: 4.221611126517936
Validation loss: 4.1327415897701565

Epoch: 5| Step: 9
Training loss: 4.5305316224054994
Validation loss: 4.128403333761698

Epoch: 5| Step: 10
Training loss: 4.2612666966364925
Validation loss: 4.121703453822748

Epoch: 5| Step: 11
Training loss: 3.079155918734061
Validation loss: 4.116049839184212

Epoch: 32| Step: 0
Training loss: 4.081786868432334
Validation loss: 4.110991040544112

Epoch: 5| Step: 1
Training loss: 4.226757898238586
Validation loss: 4.105848053488421

Epoch: 5| Step: 2
Training loss: 4.559754054815377
Validation loss: 4.0998865536369635

Epoch: 5| Step: 3
Training loss: 4.587492748951184
Validation loss: 4.094419031583359

Epoch: 5| Step: 4
Training loss: 4.050984185339786
Validation loss: 4.089367537295624

Epoch: 5| Step: 5
Training loss: 4.1380261596619805
Validation loss: 4.084189532816001

Epoch: 5| Step: 6
Training loss: 4.294282332158776
Validation loss: 4.078840151620646

Epoch: 5| Step: 7
Training loss: 4.877318197877265
Validation loss: 4.07310071596012

Epoch: 5| Step: 8
Training loss: 3.2903929712811726
Validation loss: 4.066712103196404

Epoch: 5| Step: 9
Training loss: 4.2842468019945334
Validation loss: 4.061529752826237

Epoch: 5| Step: 10
Training loss: 4.1678612077562205
Validation loss: 4.055921064342011

Epoch: 5| Step: 11
Training loss: 1.502738757086191
Validation loss: 4.0500362867527215

Epoch: 33| Step: 0
Training loss: 4.288646240046575
Validation loss: 4.045679905212053

Epoch: 5| Step: 1
Training loss: 4.530450158394341
Validation loss: 4.040430723880971

Epoch: 5| Step: 2
Training loss: 3.2336439697907773
Validation loss: 4.035390388562074

Epoch: 5| Step: 3
Training loss: 4.004061782421232
Validation loss: 4.030570019685005

Epoch: 5| Step: 4
Training loss: 4.31548040480635
Validation loss: 4.024825287022318

Epoch: 5| Step: 5
Training loss: 3.817808613971507
Validation loss: 4.020620071935477

Epoch: 5| Step: 6
Training loss: 4.5178875914053265
Validation loss: 4.015915851474805

Epoch: 5| Step: 7
Training loss: 4.1941953055949375
Validation loss: 4.00983139160053

Epoch: 5| Step: 8
Training loss: 3.3972082962439685
Validation loss: 4.00478399812626

Epoch: 5| Step: 9
Training loss: 4.35261848827436
Validation loss: 4.0003606315804285

Epoch: 5| Step: 10
Training loss: 4.643252056220163
Validation loss: 3.9948950915354033

Epoch: 5| Step: 11
Training loss: 4.7244004530207775
Validation loss: 3.989613100477013

Epoch: 34| Step: 0
Training loss: 4.511561905417681
Validation loss: 3.984260891545725

Epoch: 5| Step: 1
Training loss: 3.739548806090425
Validation loss: 3.979114745169153

Epoch: 5| Step: 2
Training loss: 5.255040609999521
Validation loss: 3.9743484998814242

Epoch: 5| Step: 3
Training loss: 4.109648140652168
Validation loss: 3.9672404144111693

Epoch: 5| Step: 4
Training loss: 3.853953271405385
Validation loss: 3.961598458404375

Epoch: 5| Step: 5
Training loss: 3.164652451511063
Validation loss: 3.9569116281225956

Epoch: 5| Step: 6
Training loss: 4.016236967367806
Validation loss: 3.9516463599024476

Epoch: 5| Step: 7
Training loss: 4.274010098607401
Validation loss: 3.945796027942059

Epoch: 5| Step: 8
Training loss: 4.10460870882815
Validation loss: 3.940337919405907

Epoch: 5| Step: 9
Training loss: 3.27280975367907
Validation loss: 3.9348476296717925

Epoch: 5| Step: 10
Training loss: 4.286223036224289
Validation loss: 3.9298974367239348

Epoch: 5| Step: 11
Training loss: 4.1725307906416385
Validation loss: 3.9241075582394007

Epoch: 35| Step: 0
Training loss: 3.228632450009356
Validation loss: 3.918911258598033

Epoch: 5| Step: 1
Training loss: 4.356143533070609
Validation loss: 3.9141866800046863

Epoch: 5| Step: 2
Training loss: 4.489811914323469
Validation loss: 3.9097757525907895

Epoch: 5| Step: 3
Training loss: 3.767614068808584
Validation loss: 3.9039919112159494

Epoch: 5| Step: 4
Training loss: 3.6863730050019132
Validation loss: 3.8987968906030126

Epoch: 5| Step: 5
Training loss: 4.126214744419567
Validation loss: 3.893389270088877

Epoch: 5| Step: 6
Training loss: 4.554311013733521
Validation loss: 3.8883705807986724

Epoch: 5| Step: 7
Training loss: 3.8336893552119773
Validation loss: 3.8830454530687692

Epoch: 5| Step: 8
Training loss: 3.9862336255488158
Validation loss: 3.8774805435686166

Epoch: 5| Step: 9
Training loss: 4.083847065482257
Validation loss: 3.8724194517187107

Epoch: 5| Step: 10
Training loss: 3.8093341127349656
Validation loss: 3.867689142540005

Epoch: 5| Step: 11
Training loss: 4.874780503246683
Validation loss: 3.862008826702876

Epoch: 36| Step: 0
Training loss: 3.772722954554348
Validation loss: 3.856798411014654

Epoch: 5| Step: 1
Training loss: 3.3904809877250455
Validation loss: 3.851922323404681

Epoch: 5| Step: 2
Training loss: 4.436874990370563
Validation loss: 3.8455930855220997

Epoch: 5| Step: 3
Training loss: 3.8814823934914204
Validation loss: 3.841103679188603

Epoch: 5| Step: 4
Training loss: 3.0556024220272873
Validation loss: 3.836601407050931

Epoch: 5| Step: 5
Training loss: 3.9844934782476735
Validation loss: 3.8330466674649544

Epoch: 5| Step: 6
Training loss: 3.5306109635068497
Validation loss: 3.8271556535234077

Epoch: 5| Step: 7
Training loss: 3.9339098836470887
Validation loss: 3.8210105232300853

Epoch: 5| Step: 8
Training loss: 4.364799160351491
Validation loss: 3.8174186100472296

Epoch: 5| Step: 9
Training loss: 4.819908088029353
Validation loss: 3.81151018165644

Epoch: 5| Step: 10
Training loss: 4.0508151517385595
Validation loss: 3.8055744273157903

Epoch: 5| Step: 11
Training loss: 4.29497294549559
Validation loss: 3.800974805346131

Epoch: 37| Step: 0
Training loss: 3.7598361397608224
Validation loss: 3.7938857117647333

Epoch: 5| Step: 1
Training loss: 4.240967520681408
Validation loss: 3.789356128549792

Epoch: 5| Step: 2
Training loss: 3.999774330449037
Validation loss: 3.784090047451403

Epoch: 5| Step: 3
Training loss: 4.2533029175710215
Validation loss: 3.777876944190933

Epoch: 5| Step: 4
Training loss: 3.835133641188579
Validation loss: 3.7733327194208877

Epoch: 5| Step: 5
Training loss: 3.632252771059731
Validation loss: 3.7677149321807937

Epoch: 5| Step: 6
Training loss: 4.03350412201591
Validation loss: 3.7624728647523007

Epoch: 5| Step: 7
Training loss: 3.971150670909127
Validation loss: 3.7569802804124266

Epoch: 5| Step: 8
Training loss: 3.960353469678857
Validation loss: 3.7516409038934087

Epoch: 5| Step: 9
Training loss: 3.6978005547718626
Validation loss: 3.7461435992889043

Epoch: 5| Step: 10
Training loss: 3.4405728564005438
Validation loss: 3.741659839994891

Epoch: 5| Step: 11
Training loss: 4.080249685987366
Validation loss: 3.7367355462213276

Epoch: 38| Step: 0
Training loss: 4.311976304252784
Validation loss: 3.731218624142816

Epoch: 5| Step: 1
Training loss: 3.727590487102704
Validation loss: 3.72646485739903

Epoch: 5| Step: 2
Training loss: 4.261933122902305
Validation loss: 3.720016349360043

Epoch: 5| Step: 3
Training loss: 3.404893797620021
Validation loss: 3.714984440537767

Epoch: 5| Step: 4
Training loss: 4.0567353650317655
Validation loss: 3.7094939840805905

Epoch: 5| Step: 5
Training loss: 3.9965706668382253
Validation loss: 3.705674046606665

Epoch: 5| Step: 6
Training loss: 3.4061030084933974
Validation loss: 3.700163954461565

Epoch: 5| Step: 7
Training loss: 3.7098063140241218
Validation loss: 3.695457606191888

Epoch: 5| Step: 8
Training loss: 4.375836537629432
Validation loss: 3.69050471416414

Epoch: 5| Step: 9
Training loss: 3.561659730563255
Validation loss: 3.6858198249794176

Epoch: 5| Step: 10
Training loss: 3.3445580477622263
Validation loss: 3.679932804124776

Epoch: 5| Step: 11
Training loss: 3.3584184571135642
Validation loss: 3.6754391518129093

Epoch: 39| Step: 0
Training loss: 3.341464108030177
Validation loss: 3.670565719389944

Epoch: 5| Step: 1
Training loss: 3.944493697908125
Validation loss: 3.6652918951258884

Epoch: 5| Step: 2
Training loss: 3.7425218404923837
Validation loss: 3.6613534918688813

Epoch: 5| Step: 3
Training loss: 3.020590375579088
Validation loss: 3.656903461194937

Epoch: 5| Step: 4
Training loss: 3.6767642969730336
Validation loss: 3.6524601066128786

Epoch: 5| Step: 5
Training loss: 4.1056132341071985
Validation loss: 3.6464779837929813

Epoch: 5| Step: 6
Training loss: 3.5747271400306047
Validation loss: 3.641681539663733

Epoch: 5| Step: 7
Training loss: 3.822091466554789
Validation loss: 3.637870117356894

Epoch: 5| Step: 8
Training loss: 4.113765793071373
Validation loss: 3.63308179397306

Epoch: 5| Step: 9
Training loss: 3.846607789614322
Validation loss: 3.628642137960968

Epoch: 5| Step: 10
Training loss: 4.446201014427189
Validation loss: 3.6253719632277055

Epoch: 5| Step: 11
Training loss: 2.4342242016686257
Validation loss: 3.6200514043842977

Epoch: 40| Step: 0
Training loss: 3.3520254246696632
Validation loss: 3.6155803177605037

Epoch: 5| Step: 1
Training loss: 3.518168838778124
Validation loss: 3.610578644551615

Epoch: 5| Step: 2
Training loss: 3.719416069838615
Validation loss: 3.6066336742262393

Epoch: 5| Step: 3
Training loss: 3.705380682287771
Validation loss: 3.6017283899989887

Epoch: 5| Step: 4
Training loss: 2.7433488348348707
Validation loss: 3.5984210300110053

Epoch: 5| Step: 5
Training loss: 3.5685882745498105
Validation loss: 3.598261757039085

Epoch: 5| Step: 6
Training loss: 3.9698039179886244
Validation loss: 3.590927209577953

Epoch: 5| Step: 7
Training loss: 4.299064161795719
Validation loss: 3.5848033333148455

Epoch: 5| Step: 8
Training loss: 4.300115965233162
Validation loss: 3.5805682207407528

Epoch: 5| Step: 9
Training loss: 3.7263365223183316
Validation loss: 3.5767903066656936

Epoch: 5| Step: 10
Training loss: 3.635745990924347
Validation loss: 3.571914541582436

Epoch: 5| Step: 11
Training loss: 4.708929288613922
Validation loss: 3.5667349701131563

Epoch: 41| Step: 0
Training loss: 3.736079764599023
Validation loss: 3.561483500279135

Epoch: 5| Step: 1
Training loss: 2.925357803240065
Validation loss: 3.5560169905681085

Epoch: 5| Step: 2
Training loss: 3.8839647513773095
Validation loss: 3.5525559402739653

Epoch: 5| Step: 3
Training loss: 4.379864848938915
Validation loss: 3.5486353232413532

Epoch: 5| Step: 4
Training loss: 3.8828590436329473
Validation loss: 3.5423041256199754

Epoch: 5| Step: 5
Training loss: 2.936795738694714
Validation loss: 3.5371238670283947

Epoch: 5| Step: 6
Training loss: 3.4844546458631296
Validation loss: 3.5326593113040556

Epoch: 5| Step: 7
Training loss: 4.0887142979163205
Validation loss: 3.529204983298692

Epoch: 5| Step: 8
Training loss: 3.6728667522867897
Validation loss: 3.5232464498191045

Epoch: 5| Step: 9
Training loss: 3.8355516290135014
Validation loss: 3.5192943441047806

Epoch: 5| Step: 10
Training loss: 3.5004095110422604
Validation loss: 3.5136666445421945

Epoch: 5| Step: 11
Training loss: 2.611798468767274
Validation loss: 3.5104026605494574

Epoch: 42| Step: 0
Training loss: 3.4033742541905254
Validation loss: 3.504785711573677

Epoch: 5| Step: 1
Training loss: 4.627516190940028
Validation loss: 3.50037227081333

Epoch: 5| Step: 2
Training loss: 3.5462772353010217
Validation loss: 3.496173191411138

Epoch: 5| Step: 3
Training loss: 2.8033973042752387
Validation loss: 3.491737570001009

Epoch: 5| Step: 4
Training loss: 3.2718864899791535
Validation loss: 3.4875987069712613

Epoch: 5| Step: 5
Training loss: 3.1398306833770318
Validation loss: 3.4832682769273253

Epoch: 5| Step: 6
Training loss: 3.403146011946224
Validation loss: 3.479505611896626

Epoch: 5| Step: 7
Training loss: 4.443896344614677
Validation loss: 3.4757048559821544

Epoch: 5| Step: 8
Training loss: 3.624568124234836
Validation loss: 3.4712565304112415

Epoch: 5| Step: 9
Training loss: 3.578332087092071
Validation loss: 3.4663842527883615

Epoch: 5| Step: 10
Training loss: 3.63378118910394
Validation loss: 3.4623704961803012

Epoch: 5| Step: 11
Training loss: 3.417908342100115
Validation loss: 3.458123227520076

Epoch: 43| Step: 0
Training loss: 3.4255501855156534
Validation loss: 3.4532504396971553

Epoch: 5| Step: 1
Training loss: 3.6712786251065257
Validation loss: 3.4499234220971413

Epoch: 5| Step: 2
Training loss: 3.6064290496434706
Validation loss: 3.445374987807584

Epoch: 5| Step: 3
Training loss: 3.6969149383425544
Validation loss: 3.4400927475829497

Epoch: 5| Step: 4
Training loss: 3.481634045550484
Validation loss: 3.43548960996739

Epoch: 5| Step: 5
Training loss: 3.549421564177265
Validation loss: 3.4310701576727127

Epoch: 5| Step: 6
Training loss: 3.65816336883596
Validation loss: 3.4269935669587688

Epoch: 5| Step: 7
Training loss: 3.597335751450925
Validation loss: 3.4229755780023696

Epoch: 5| Step: 8
Training loss: 3.1357646930638965
Validation loss: 3.4191565551409955

Epoch: 5| Step: 9
Training loss: 3.6239502800989687
Validation loss: 3.4145304099530405

Epoch: 5| Step: 10
Training loss: 3.705551189653251
Validation loss: 3.4110031212485152

Epoch: 5| Step: 11
Training loss: 3.996534873204138
Validation loss: 3.406657909035546

Epoch: 44| Step: 0
Training loss: 3.497452626319912
Validation loss: 3.4018160925091516

Epoch: 5| Step: 1
Training loss: 3.3010041471985123
Validation loss: 3.397324940473344

Epoch: 5| Step: 2
Training loss: 3.197991849696859
Validation loss: 3.393391855847839

Epoch: 5| Step: 3
Training loss: 3.6642324574954954
Validation loss: 3.3891586379184426

Epoch: 5| Step: 4
Training loss: 4.025694101324208
Validation loss: 3.3851871862640546

Epoch: 5| Step: 5
Training loss: 3.1180781189220843
Validation loss: 3.381130972299093

Epoch: 5| Step: 6
Training loss: 3.463483231512851
Validation loss: 3.3757566322088803

Epoch: 5| Step: 7
Training loss: 3.7503177508201486
Validation loss: 3.372377754467357

Epoch: 5| Step: 8
Training loss: 3.489875318163691
Validation loss: 3.367578178452665

Epoch: 5| Step: 9
Training loss: 3.26027025050428
Validation loss: 3.363874429636158

Epoch: 5| Step: 10
Training loss: 3.6023127173743985
Validation loss: 3.3593780931562036

Epoch: 5| Step: 11
Training loss: 4.581030018353158
Validation loss: 3.356422676555424

Epoch: 45| Step: 0
Training loss: 3.3480698676071423
Validation loss: 3.35667717415555

Epoch: 5| Step: 1
Training loss: 3.35037943271201
Validation loss: 3.348022132324873

Epoch: 5| Step: 2
Training loss: 3.7333212926080086
Validation loss: 3.3445244305273887

Epoch: 5| Step: 3
Training loss: 3.3226110782239067
Validation loss: 3.3410346631380707

Epoch: 5| Step: 4
Training loss: 4.14947784080339
Validation loss: 3.3385061280991915

Epoch: 5| Step: 5
Training loss: 2.945784229982613
Validation loss: 3.335067105406912

Epoch: 5| Step: 6
Training loss: 3.442067666203787
Validation loss: 3.3317140381272594

Epoch: 5| Step: 7
Training loss: 3.238397575470239
Validation loss: 3.327632061625501

Epoch: 5| Step: 8
Training loss: 3.6018107363865624
Validation loss: 3.3246724662939258

Epoch: 5| Step: 9
Training loss: 3.4241758649796425
Validation loss: 3.3205905453817293

Epoch: 5| Step: 10
Training loss: 3.5878164650235855
Validation loss: 3.316445316343708

Epoch: 5| Step: 11
Training loss: 3.186228779138091
Validation loss: 3.3117887225133993

Epoch: 46| Step: 0
Training loss: 2.948151775640446
Validation loss: 3.3080198772848783

Epoch: 5| Step: 1
Training loss: 3.7445843055129298
Validation loss: 3.3045062112344374

Epoch: 5| Step: 2
Training loss: 3.5302427762759097
Validation loss: 3.3001644694399324

Epoch: 5| Step: 3
Training loss: 2.8798621155262554
Validation loss: 3.2957462077836253

Epoch: 5| Step: 4
Training loss: 3.4724754054693254
Validation loss: 3.29113884307478

Epoch: 5| Step: 5
Training loss: 3.382382125435898
Validation loss: 3.2865016388294417

Epoch: 5| Step: 6
Training loss: 3.8178089886658797
Validation loss: 3.28121178922657

Epoch: 5| Step: 7
Training loss: 3.084709444629767
Validation loss: 3.2764920267273636

Epoch: 5| Step: 8
Training loss: 3.6115549613555102
Validation loss: 3.272213472568002

Epoch: 5| Step: 9
Training loss: 3.4261809825939262
Validation loss: 3.268654384029063

Epoch: 5| Step: 10
Training loss: 3.6419135829805787
Validation loss: 3.264676353250796

Epoch: 5| Step: 11
Training loss: 3.4463035905315063
Validation loss: 3.2606940024563835

Epoch: 47| Step: 0
Training loss: 4.092118265644874
Validation loss: 3.2568174347359062

Epoch: 5| Step: 1
Training loss: 3.107513637374698
Validation loss: 3.251195412646506

Epoch: 5| Step: 2
Training loss: 3.4564586445362195
Validation loss: 3.247634974741798

Epoch: 5| Step: 3
Training loss: 3.2070218828368833
Validation loss: 3.2439095546703802

Epoch: 5| Step: 4
Training loss: 3.3518329502351007
Validation loss: 3.2396541886180765

Epoch: 5| Step: 5
Training loss: 3.1583103215998922
Validation loss: 3.2356389412528332

Epoch: 5| Step: 6
Training loss: 2.8737048673466483
Validation loss: 3.2323979464257038

Epoch: 5| Step: 7
Training loss: 3.709427375712925
Validation loss: 3.2277868655708426

Epoch: 5| Step: 8
Training loss: 3.150077146766189
Validation loss: 3.223131179492967

Epoch: 5| Step: 9
Training loss: 3.5371933605348764
Validation loss: 3.2192559076142278

Epoch: 5| Step: 10
Training loss: 3.0355078298423446
Validation loss: 3.2161349380040916

Epoch: 5| Step: 11
Training loss: 4.583772372401067
Validation loss: 3.2125589835346697

Epoch: 48| Step: 0
Training loss: 3.0704320830918705
Validation loss: 3.2088824902406037

Epoch: 5| Step: 1
Training loss: 3.2001252805504756
Validation loss: 3.2043983905638673

Epoch: 5| Step: 2
Training loss: 3.316695669101702
Validation loss: 3.2015366904002036

Epoch: 5| Step: 3
Training loss: 3.6471237660005955
Validation loss: 3.1968278222007123

Epoch: 5| Step: 4
Training loss: 3.5586895558161986
Validation loss: 3.192442677052188

Epoch: 5| Step: 5
Training loss: 3.563958521977285
Validation loss: 3.188209180540041

Epoch: 5| Step: 6
Training loss: 2.895232616296283
Validation loss: 3.183995383423824

Epoch: 5| Step: 7
Training loss: 2.779534057018765
Validation loss: 3.181267067164597

Epoch: 5| Step: 8
Training loss: 3.383762569791673
Validation loss: 3.178633319084831

Epoch: 5| Step: 9
Training loss: 3.176965096363311
Validation loss: 3.1745891515482643

Epoch: 5| Step: 10
Training loss: 3.7557473961953725
Validation loss: 3.1719679544793604

Epoch: 5| Step: 11
Training loss: 3.8894700630311863
Validation loss: 3.166364797626251

Epoch: 49| Step: 0
Training loss: 3.635470691414294
Validation loss: 3.1631672915370244

Epoch: 5| Step: 1
Training loss: 3.6431598270444607
Validation loss: 3.166667465577945

Epoch: 5| Step: 2
Training loss: 3.6136615614887684
Validation loss: 3.160809236074754

Epoch: 5| Step: 3
Training loss: 2.6432954726648603
Validation loss: 3.151134600989695

Epoch: 5| Step: 4
Training loss: 3.1836069305708747
Validation loss: 3.1481573959964813

Epoch: 5| Step: 5
Training loss: 2.9825910259211326
Validation loss: 3.1455189229884852

Epoch: 5| Step: 6
Training loss: 3.092876118243389
Validation loss: 3.1421464805764656

Epoch: 5| Step: 7
Training loss: 3.6140567421609586
Validation loss: 3.140526183235978

Epoch: 5| Step: 8
Training loss: 3.137061987466618
Validation loss: 3.136801155246203

Epoch: 5| Step: 9
Training loss: 3.303805907776261
Validation loss: 3.133223331495486

Epoch: 5| Step: 10
Training loss: 3.147907070412053
Validation loss: 3.1286307986356343

Epoch: 5| Step: 11
Training loss: 3.3078187217167367
Validation loss: 3.1242405350028855

Epoch: 50| Step: 0
Training loss: 2.647135636829543
Validation loss: 3.1214103490410428

Epoch: 5| Step: 1
Training loss: 3.8778613201446395
Validation loss: 3.1173195743227238

Epoch: 5| Step: 2
Training loss: 3.4325552314821235
Validation loss: 3.1132690352866756

Epoch: 5| Step: 3
Training loss: 3.33257672941985
Validation loss: 3.1105492960679206

Epoch: 5| Step: 4
Training loss: 3.229878271306976
Validation loss: 3.1067229035680737

Epoch: 5| Step: 5
Training loss: 3.343956771589428
Validation loss: 3.1029019286159696

Epoch: 5| Step: 6
Training loss: 3.2012091140489582
Validation loss: 3.10013527305854

Epoch: 5| Step: 7
Training loss: 2.6663945973206227
Validation loss: 3.0959617851652257

Epoch: 5| Step: 8
Training loss: 3.120466682548386
Validation loss: 3.0930427359345924

Epoch: 5| Step: 9
Training loss: 3.161381996569675
Validation loss: 3.0891079482686123

Epoch: 5| Step: 10
Training loss: 3.2176943038448518
Validation loss: 3.0849965685068477

Epoch: 5| Step: 11
Training loss: 4.344056043203649
Validation loss: 3.0816005249483323

Testing loss: 2.6610151447846393
