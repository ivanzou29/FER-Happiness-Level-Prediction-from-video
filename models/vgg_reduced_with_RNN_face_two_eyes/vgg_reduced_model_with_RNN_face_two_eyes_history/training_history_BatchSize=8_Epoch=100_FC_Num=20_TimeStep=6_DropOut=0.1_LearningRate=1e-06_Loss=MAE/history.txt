Epoch: 1| Step: 0
Training loss: 2.986140012741089
Validation loss: 5.18203244106375
Epoch: 18| Step: 1
Training loss: 6.337303161621094
Validation loss: 5.180750781683613
Epoch: 18| Step: 2
Training loss: 5.535637855529785
Validation loss: 5.179994339565579
Epoch: 18| Step: 3
Training loss: 6.137343406677246
Validation loss: 5.179021845618598
Epoch: 18| Step: 4
Training loss: 4.560188293457031
Validation loss: 5.177754036814189
Epoch: 18| Step: 5
Training loss: 3.7056941986083984
Validation loss: 5.176699888791969
Epoch: 18| Step: 6
Training loss: 4.059334754943848
Validation loss: 5.175577345511896
Epoch: 18| Step: 7
Training loss: 6.183587074279785
Validation loss: 5.174548475004786
Epoch: 18| Step: 8
Training loss: 4.338947296142578
Validation loss: 5.173459169675978
Epoch: 18| Step: 9
Training loss: 5.869483947753906
Validation loss: 5.172702847624854
Epoch: 18| Step: 10
Training loss: 6.12766695022583
Validation loss: 5.171096125952632
Epoch: 18| Step: 11
Training loss: 4.392775535583496
Validation loss: 5.170234767653102
Epoch: 18| Step: 12
Training loss: 4.625551223754883
Validation loss: 5.169065900843778
Epoch: 18| Step: 13
Training loss: 4.879025459289551
Validation loss: 5.1682384545854525
Epoch: 18| Step: 14
Training loss: 6.023829936981201
Validation loss: 5.166846409118433
Epoch: 18| Step: 15
Training loss: 5.689761638641357
Validation loss: 5.165711519529494
Epoch: 18| Step: 16
Training loss: 4.854771137237549
Validation loss: 5.164787896245503
Epoch: 18| Step: 17
Training loss: 7.370632171630859
Validation loss: 5.16394650164268
Epoch: 18| Step: 18
Training loss: 5.495509147644043
Validation loss: 5.162525080948424
Epoch: 18| Step: 19
Training loss: 4.935238838195801
Validation loss: 5.161850915538321
Epoch: 18| Step: 20
Training loss: 3.605956554412842
Validation loss: 5.1609319937314915
Epoch: 18| Step: 21
Training loss: 5.704357147216797
Validation loss: 5.15915084056717
Epoch: 18| Step: 22
Training loss: 4.972762107849121
Validation loss: 5.158317497308306
Epoch: 18| Step: 23
Training loss: 5.246351718902588
Validation loss: 5.15718810678386
Epoch: 18| Step: 24
Training loss: 5.305605888366699
Validation loss: 5.156407532932089
Epoch: 18| Step: 25
Training loss: 4.671738624572754
Validation loss: 5.155056895111962
Epoch: 18| Step: 26
Training loss: 5.900849342346191
Validation loss: 5.15373453304922
Epoch: 18| Step: 27
Training loss: 5.837497711181641
Validation loss: 5.15250850924485
Epoch: 18| Step: 28
Training loss: 5.906599998474121
Validation loss: 5.151506044881807
Epoch: 18| Step: 29
Training loss: 5.871335029602051
Validation loss: 5.149998920426952
Epoch: 18| Step: 30
Training loss: 4.46103048324585
Validation loss: 5.149137181343792
Epoch: 18| Step: 31
Training loss: 6.492260456085205
Validation loss: 5.148253639824956
Epoch: 18| Step: 32
Training loss: 4.783400535583496
Validation loss: 5.146213864251006
Epoch: 18| Step: 33
Training loss: 5.4745192527771
Validation loss: 5.145863649656447
Epoch: 18| Step: 34
Training loss: 6.366145610809326
Validation loss: 5.1439783641760295
Epoch: 18| Step: 35
Training loss: 5.657382965087891
Validation loss: 5.142447354982225
Epoch: 18| Step: 36
Training loss: 5.917822360992432
Validation loss: 5.141083559543967
Epoch: 18| Step: 37
Training loss: 6.313507080078125
Validation loss: 5.1397969945729205
Epoch: 18| Step: 38
Training loss: 5.30275297164917
Validation loss: 5.1386189186315745
Epoch: 18| Step: 39
Training loss: 4.254194259643555
Validation loss: 5.137599737524129
Epoch: 2| Step: 0
Training loss: 6.004626274108887
Validation loss: 5.1365218471280105
Epoch: 18| Step: 1
Training loss: 5.4349775314331055
Validation loss: 5.135031955705272
Epoch: 18| Step: 2
Training loss: 3.6924664974212646
Validation loss: 5.133057820711205
Epoch: 18| Step: 3
Training loss: 4.356070518493652
Validation loss: 5.132200841423419
Epoch: 18| Step: 4
Training loss: 3.72880220413208
Validation loss: 5.131000878999559
Epoch: 18| Step: 5
Training loss: 5.81415319442749
Validation loss: 5.128644603619472
Epoch: 18| Step: 6
Training loss: 3.8444013595581055
Validation loss: 5.127745827324956
Epoch: 18| Step: 7
Training loss: 5.3192138671875
Validation loss: 5.125806468853847
Epoch: 18| Step: 8
Training loss: 4.581355094909668
Validation loss: 5.12513250584225
Epoch: 18| Step: 9
Training loss: 5.542068958282471
Validation loss: 5.1233490199493845
Epoch: 18| Step: 10
Training loss: 6.650282859802246
Validation loss: 5.1227518054221175
Epoch: 18| Step: 11
Training loss: 5.971997261047363
Validation loss: 5.120513123574017
Epoch: 18| Step: 12
Training loss: 5.178892135620117
Validation loss: 5.1185885504852955
Epoch: 18| Step: 13
Training loss: 7.0648369789123535
Validation loss: 5.117046232703778
Epoch: 18| Step: 14
Training loss: 6.029845237731934
Validation loss: 5.115698615424067
Epoch: 18| Step: 15
Training loss: 2.9712061882019043
Validation loss: 5.114623150379538
Epoch: 18| Step: 16
Training loss: 6.523285865783691
Validation loss: 5.1124857484007915
Epoch: 18| Step: 17
Training loss: 5.139021873474121
Validation loss: 5.110815953865326
Epoch: 18| Step: 18
Training loss: 4.3690104484558105
Validation loss: 5.1093734322692
Epoch: 18| Step: 19
Training loss: 5.896142959594727
Validation loss: 5.106524278791689
Epoch: 18| Step: 20
Training loss: 5.364439964294434
Validation loss: 5.10563675105143
Epoch: 18| Step: 21
Training loss: 4.4477434158325195
Validation loss: 5.105231720766575
Epoch: 18| Step: 22
Training loss: 4.794861316680908
Validation loss: 5.102598667144775
Epoch: 18| Step: 23
Training loss: 4.671108245849609
Validation loss: 5.101002772077382
Epoch: 18| Step: 24
Training loss: 6.5027971267700195
Validation loss: 5.097613183714503
Epoch: 18| Step: 25
Training loss: 6.222621917724609
Validation loss: 5.096552941438963
Epoch: 18| Step: 26
Training loss: 3.798360824584961
Validation loss: 5.095004627172895
Epoch: 18| Step: 27
Training loss: 5.5157999992370605
Validation loss: 5.092801004862614
Epoch: 18| Step: 28
Training loss: 6.421929359436035
Validation loss: 5.090911153409121
Epoch: 18| Step: 29
Training loss: 4.39512300491333
Validation loss: 5.088520156393806
Epoch: 18| Step: 30
Training loss: 5.9010396003723145
Validation loss: 5.087104797363281
Epoch: 18| Step: 31
Training loss: 4.5628461837768555
Validation loss: 5.08539298283968
Epoch: 18| Step: 32
Training loss: 4.241246223449707
Validation loss: 5.083676224989857
Epoch: 18| Step: 33
Training loss: 4.689210414886475
Validation loss: 5.081281236607394
Epoch: 18| Step: 34
Training loss: 6.3542914390563965
Validation loss: 5.0785935834157385
Epoch: 18| Step: 35
Training loss: 3.557868003845215
Validation loss: 5.077496770474551
Epoch: 18| Step: 36
Training loss: 5.703290939331055
Validation loss: 5.07604101235918
Epoch: 18| Step: 37
Training loss: 6.237744331359863
Validation loss: 5.072592745581977
Epoch: 18| Step: 38
Training loss: 5.9564900398254395
Validation loss: 5.070174256674678
Epoch: 18| Step: 39
Training loss: 6.610393524169922
Validation loss: 5.067564696716747
Epoch: 3| Step: 0
Training loss: 6.1337761878967285
Validation loss: 5.065477710833653
Epoch: 18| Step: 1
Training loss: 4.88151741027832
Validation loss: 5.063020610123229
Epoch: 18| Step: 2
Training loss: 5.807660102844238
Validation loss: 5.060002014791365
Epoch: 18| Step: 3
Training loss: 6.127479553222656
Validation loss: 5.0588633430947505
Epoch: 18| Step: 4
Training loss: 4.135465621948242
Validation loss: 5.054730604020811
Epoch: 18| Step: 5
Training loss: 5.582972526550293
Validation loss: 5.0539378193642595
Epoch: 18| Step: 6
Training loss: 6.2579450607299805
Validation loss: 5.052431947035755
Epoch: 18| Step: 7
Training loss: 5.538944244384766
Validation loss: 5.0482350459201735
Epoch: 18| Step: 8
Training loss: 4.179467678070068
Validation loss: 5.045340946252398
Epoch: 18| Step: 9
Training loss: 5.797331809997559
Validation loss: 5.043551849804336
Epoch: 18| Step: 10
Training loss: 5.168414115905762
Validation loss: 5.040069940278856
Epoch: 18| Step: 11
Training loss: 5.339017868041992
Validation loss: 5.039290929012162
Epoch: 18| Step: 12
Training loss: 5.4741902351379395
Validation loss: 5.03576881079365
Epoch: 18| Step: 13
Training loss: 3.9188551902770996
Validation loss: 5.032110708222972
Epoch: 18| Step: 14
Training loss: 4.266749382019043
Validation loss: 5.030585855031185
Epoch: 18| Step: 15
Training loss: 4.147847652435303
Validation loss: 5.028698487247494
Epoch: 18| Step: 16
Training loss: 5.273995876312256
Validation loss: 5.026500015807667
Epoch: 18| Step: 17
Training loss: 5.207294940948486
Validation loss: 5.022285506022063
Epoch: 18| Step: 18
Training loss: 4.706009864807129
Validation loss: 5.019137924523663
Epoch: 18| Step: 19
Training loss: 7.065052509307861
Validation loss: 5.017256318236426
Epoch: 18| Step: 20
Training loss: 6.247922897338867
Validation loss: 5.011952103470727
Epoch: 18| Step: 21
Training loss: 5.318593978881836
Validation loss: 5.008761230990183
Epoch: 18| Step: 22
Training loss: 4.849754810333252
Validation loss: 5.006926491963777
Epoch: 18| Step: 23
Training loss: 5.3193817138671875
Validation loss: 5.0026789226120325
Epoch: 18| Step: 24
Training loss: 4.0492939949035645
Validation loss: 5.001873650996805
Epoch: 18| Step: 25
Training loss: 4.02163028717041
Validation loss: 4.998726004319225
Epoch: 18| Step: 26
Training loss: 5.418547630310059
Validation loss: 4.9962801796069245
Epoch: 18| Step: 27
Training loss: 4.139294624328613
Validation loss: 4.99157942284783
Epoch: 18| Step: 28
Training loss: 5.072868824005127
Validation loss: 4.98896578233019
Epoch: 18| Step: 29
Training loss: 5.257284164428711
Validation loss: 4.985168734900386
Epoch: 18| Step: 30
Training loss: 5.591230869293213
Validation loss: 4.982637662681745
Epoch: 18| Step: 31
Training loss: 6.151047706604004
Validation loss: 4.9772592345587645
Epoch: 18| Step: 32
Training loss: 5.470227241516113
Validation loss: 4.973775596069775
Epoch: 18| Step: 33
Training loss: 6.165441513061523
Validation loss: 4.970380927161347
Epoch: 18| Step: 34
Training loss: 4.885066032409668
Validation loss: 4.967301855841987
Epoch: 18| Step: 35
Training loss: 2.822305202484131
Validation loss: 4.961801623268951
Epoch: 18| Step: 36
Training loss: 6.426931858062744
Validation loss: 4.960753252180361
Epoch: 18| Step: 37
Training loss: 4.159900665283203
Validation loss: 4.956255003702727
Epoch: 18| Step: 38
Training loss: 6.5172224044799805
Validation loss: 4.952581913351155
Epoch: 18| Step: 39
Training loss: 3.723939895629883
Validation loss: 4.949878663467846
Epoch: 4| Step: 0
Training loss: 4.743102073669434
Validation loss: 4.944007424141863
Epoch: 18| Step: 1
Training loss: 5.827176570892334
Validation loss: 4.942276110752023
Epoch: 18| Step: 2
Training loss: 6.20413875579834
Validation loss: 4.934038244563041
Epoch: 18| Step: 3
Training loss: 6.481419086456299
Validation loss: 4.935334622431144
Epoch: 18| Step: 4
Training loss: 6.540424823760986
Validation loss: 4.931640371144247
Epoch: 18| Step: 5
Training loss: 5.826027870178223
Validation loss: 4.922889232635498
Epoch: 18| Step: 6
Training loss: 3.204986095428467
Validation loss: 4.921381943517452
Epoch: 18| Step: 7
Training loss: 5.658294677734375
Validation loss: 4.91595363273895
Epoch: 18| Step: 8
Training loss: 5.5099029541015625
Validation loss: 4.913608516720559
Epoch: 18| Step: 9
Training loss: 3.9978790283203125
Validation loss: 4.905278785623235
Epoch: 18| Step: 10
Training loss: 5.767928123474121
Validation loss: 4.905047704847597
Epoch: 18| Step: 11
Training loss: 3.0452287197113037
Validation loss: 4.899766397133148
Epoch: 18| Step: 12
Training loss: 4.372129917144775
Validation loss: 4.89495033497433
Epoch: 18| Step: 13
Training loss: 5.568042278289795
Validation loss: 4.891640676868906
Epoch: 18| Step: 14
Training loss: 4.339502811431885
Validation loss: 4.886862634754867
Epoch: 18| Step: 15
Training loss: 6.305521488189697
Validation loss: 4.883119229790118
Epoch: 18| Step: 16
Training loss: 4.217536449432373
Validation loss: 4.877648665750627
Epoch: 18| Step: 17
Training loss: 2.7776598930358887
Validation loss: 4.87181334186801
Epoch: 18| Step: 18
Training loss: 7.454217910766602
Validation loss: 4.869367174107394
Epoch: 18| Step: 19
Training loss: 5.433066368103027
Validation loss: 4.863249483726007
Epoch: 18| Step: 20
Training loss: 4.2860002517700195
Validation loss: 4.859194566877626
Epoch: 18| Step: 21
Training loss: 6.179530620574951
Validation loss: 4.852918213219952
Epoch: 18| Step: 22
Training loss: 3.970895290374756
Validation loss: 4.850748971211824
Epoch: 18| Step: 23
Training loss: 4.0853681564331055
Validation loss: 4.844776700726516
Epoch: 18| Step: 24
Training loss: 5.316674709320068
Validation loss: 4.839817403889389
Epoch: 18| Step: 25
Training loss: 6.54508113861084
Validation loss: 4.834096406003554
Epoch: 18| Step: 26
Training loss: 4.329423427581787
Validation loss: 4.830003724681387
Epoch: 18| Step: 27
Training loss: 4.421720504760742
Validation loss: 4.8265373552445885
Epoch: 18| Step: 28
Training loss: 5.310632228851318
Validation loss: 4.821858960947544
Epoch: 18| Step: 29
Training loss: 6.013806343078613
Validation loss: 4.81676987092272
Epoch: 18| Step: 30
Training loss: 5.179599761962891
Validation loss: 4.813482660183803
Epoch: 18| Step: 31
Training loss: 4.380137920379639
Validation loss: 4.811240158492713
Epoch: 18| Step: 32
Training loss: 5.165882587432861
Validation loss: 4.804554369809816
Epoch: 18| Step: 33
Training loss: 4.1336989402771
Validation loss: 4.792926705998482
Epoch: 18| Step: 34
Training loss: 5.682353973388672
Validation loss: 4.790246798837785
Epoch: 18| Step: 35
Training loss: 4.5150017738342285
Validation loss: 4.785997750947801
Epoch: 18| Step: 36
Training loss: 4.388205051422119
Validation loss: 4.7804171918965075
Epoch: 18| Step: 37
Training loss: 4.639906883239746
Validation loss: 4.777334491125972
Epoch: 18| Step: 38
Training loss: 5.1528730392456055
Validation loss: 4.772284238458537
Epoch: 18| Step: 39
Training loss: 4.16877555847168
Validation loss: 4.764114822415139
Epoch: 5| Step: 0
Training loss: 4.567712783813477
Validation loss: 4.754679501485482
Epoch: 18| Step: 1
Training loss: 5.764047622680664
Validation loss: 4.753717487664532
Epoch: 18| Step: 2
Training loss: 3.5539257526397705
Validation loss: 4.748815961878934
Epoch: 18| Step: 3
Training loss: 4.278780937194824
Validation loss: 4.748912315574481
Epoch: 18| Step: 4
Training loss: 4.4774370193481445
Validation loss: 4.742115020751953
Epoch: 18| Step: 5
Training loss: 4.402979373931885
Validation loss: 4.740793307050526
Epoch: 18| Step: 6
Training loss: 4.651172637939453
Validation loss: 4.726910519085342
Epoch: 18| Step: 7
Training loss: 5.382765769958496
Validation loss: 4.722025818104367
Epoch: 18| Step: 8
Training loss: 1.9762866497039795
Validation loss: 4.720176861440535
Epoch: 18| Step: 9
Training loss: 5.406872272491455
Validation loss: 4.711104465045517
Epoch: 18| Step: 10
Training loss: 4.51950740814209
Validation loss: 4.710807772849104
Epoch: 18| Step: 11
Training loss: 2.0177791118621826
Validation loss: 4.70802906434313
Epoch: 18| Step: 12
Training loss: 6.1865739822387695
Validation loss: 4.6986038221729745
Epoch: 18| Step: 13
Training loss: 5.943728446960449
Validation loss: 4.693716100651583
Epoch: 18| Step: 14
Training loss: 6.349167823791504
Validation loss: 4.689602158910079
Epoch: 18| Step: 15
Training loss: 5.563747406005859
Validation loss: 4.680565813462511
Epoch: 18| Step: 16
Training loss: 2.982882022857666
Validation loss: 4.672932744883805
Epoch: 18| Step: 17
Training loss: 5.318592071533203
Validation loss: 4.667501874964872
Epoch: 18| Step: 18
Training loss: 4.4967498779296875
Validation loss: 4.664254210835738
Epoch: 18| Step: 19
Training loss: 4.267455577850342
Validation loss: 4.658258177393632
Epoch: 18| Step: 20
Training loss: 5.57175350189209
Validation loss: 4.6514684828065285
Epoch: 18| Step: 21
Training loss: 4.674396514892578
Validation loss: 4.650309116720296
Epoch: 18| Step: 22
Training loss: 5.327332496643066
Validation loss: 4.6454465852366935
Epoch: 18| Step: 23
Training loss: 6.4881367683410645
Validation loss: 4.637498666914247
Epoch: 18| Step: 24
Training loss: 5.726041793823242
Validation loss: 4.62802997252924
Epoch: 18| Step: 25
Training loss: 3.7869675159454346
Validation loss: 4.630845176230232
Epoch: 18| Step: 26
Training loss: 6.333294868469238
Validation loss: 4.6172609209156725
Epoch: 18| Step: 27
Training loss: 4.273067951202393
Validation loss: 4.619276660809414
Epoch: 18| Step: 28
Training loss: 6.776893138885498
Validation loss: 4.607553931448957
Epoch: 18| Step: 29
Training loss: 4.302811622619629
Validation loss: 4.599864352521279
Epoch: 18| Step: 30
Training loss: 5.54850435256958
Validation loss: 4.596173344756202
Epoch: 18| Step: 31
Training loss: 5.144477844238281
Validation loss: 4.5933573091630455
Epoch: 18| Step: 32
Training loss: 4.581791400909424
Validation loss: 4.588642816749408
Epoch: 18| Step: 33
Training loss: 6.36036491394043
Validation loss: 4.58784376803062
Epoch: 18| Step: 34
Training loss: 3.949004650115967
Validation loss: 4.568691353146121
Epoch: 18| Step: 35
Training loss: 4.834301948547363
Validation loss: 4.57161043016173
Epoch: 18| Step: 36
Training loss: 3.899385929107666
Validation loss: 4.564105551877468
Epoch: 18| Step: 37
Training loss: 5.25032901763916
Validation loss: 4.557009096625897
Epoch: 18| Step: 38
Training loss: 3.1234068870544434
Validation loss: 4.55523346482421
Epoch: 18| Step: 39
Training loss: 5.405576229095459
Validation loss: 4.548546180450659
Epoch: 6| Step: 0
Training loss: 5.1340508460998535
Validation loss: 4.541445550301092
Epoch: 18| Step: 1
Training loss: 4.410623073577881
Validation loss: 4.5349707003120034
Epoch: 18| Step: 2
Training loss: 3.539316177368164
Validation loss: 4.524718222858237
Epoch: 18| Step: 3
Training loss: 6.091116428375244
Validation loss: 4.526034036128641
Epoch: 18| Step: 4
Training loss: 6.549941062927246
Validation loss: 4.514635686394122
Epoch: 18| Step: 5
Training loss: 5.695138931274414
Validation loss: 4.5106611251831055
Epoch: 18| Step: 6
Training loss: 4.877610206604004
Validation loss: 4.505275263203134
Epoch: 18| Step: 7
Training loss: 4.477470874786377
Validation loss: 4.498894046536453
Epoch: 18| Step: 8
Training loss: 5.121387004852295
Validation loss: 4.498756343512226
Epoch: 18| Step: 9
Training loss: 3.397228956222534
Validation loss: 4.49351560469154
Epoch: 18| Step: 10
Training loss: 3.448925018310547
Validation loss: 4.481919933566086
Epoch: 18| Step: 11
Training loss: 3.1720943450927734
Validation loss: 4.480349712234607
Epoch: 18| Step: 12
Training loss: 4.365674018859863
Validation loss: 4.47151586477705
Epoch: 18| Step: 13
Training loss: 3.5731143951416016
Validation loss: 4.469203081062372
Epoch: 18| Step: 14
Training loss: 3.831913709640503
Validation loss: 4.466069104860154
Epoch: 18| Step: 15
Training loss: 6.5562896728515625
Validation loss: 4.452910310072864
Epoch: 18| Step: 16
Training loss: 3.0076448917388916
Validation loss: 4.452096198102553
Epoch: 18| Step: 17
Training loss: 4.033025741577148
Validation loss: 4.440191615399697
Epoch: 18| Step: 18
Training loss: 4.559389114379883
Validation loss: 4.441998239901426
Epoch: 18| Step: 19
Training loss: 5.352246284484863
Validation loss: 4.435496076405477
Epoch: 18| Step: 20
Training loss: 4.634936332702637
Validation loss: 4.434073959323142
Epoch: 18| Step: 21
Training loss: 4.673286437988281
Validation loss: 4.428866280068596
Epoch: 18| Step: 22
Training loss: 5.090351104736328
Validation loss: 4.414777436702371
Epoch: 18| Step: 23
Training loss: 4.313699245452881
Validation loss: 4.411524602835127
Epoch: 18| Step: 24
Training loss: 5.084618091583252
Validation loss: 4.406367778778076
Epoch: 18| Step: 25
Training loss: 4.955346584320068
Validation loss: 4.396941119818378
Epoch: 18| Step: 26
Training loss: 4.5908660888671875
Validation loss: 4.391144323692047
Epoch: 18| Step: 27
Training loss: 4.0774102210998535
Validation loss: 4.393438133404409
Epoch: 18| Step: 28
Training loss: 6.414271354675293
Validation loss: 4.382838479048914
Epoch: 18| Step: 29
Training loss: 3.980648994445801
Validation loss: 4.382112762053236
Epoch: 18| Step: 30
Training loss: 5.174978256225586
Validation loss: 4.374152060035321
Epoch: 18| Step: 31
Training loss: 4.227940559387207
Validation loss: 4.367738130281297
Epoch: 18| Step: 32
Training loss: 5.238641738891602
Validation loss: 4.364325122009936
Epoch: 18| Step: 33
Training loss: 4.956323623657227
Validation loss: 4.358172095936837
Epoch: 18| Step: 34
Training loss: 3.665652275085449
Validation loss: 4.356712234963616
Epoch: 18| Step: 35
Training loss: 3.891051769256592
Validation loss: 4.346056835256892
Epoch: 18| Step: 36
Training loss: 6.260933876037598
Validation loss: 4.342719752153904
Epoch: 18| Step: 37
Training loss: 3.928264617919922
Validation loss: 4.335947393513412
Epoch: 18| Step: 38
Training loss: 4.156215667724609
Validation loss: 4.331220767480864
Epoch: 18| Step: 39
Training loss: 4.707608699798584
Validation loss: 4.323672934401807
Epoch: 7| Step: 0
Training loss: 4.819850444793701
Validation loss: 4.3240190015422355
Epoch: 18| Step: 1
Training loss: 4.283139228820801
Validation loss: 4.31290156549687
Epoch: 18| Step: 2
Training loss: 4.056072235107422
Validation loss: 4.311617696885582
Epoch: 18| Step: 3
Training loss: 4.57891845703125
Validation loss: 4.30284197210408
Epoch: 18| Step: 4
Training loss: 5.912031173706055
Validation loss: 4.297167997566058
Epoch: 18| Step: 5
Training loss: 3.643312454223633
Validation loss: 4.29093442546378
Epoch: 18| Step: 6
Training loss: 4.075570106506348
Validation loss: 4.291712109133494
Epoch: 18| Step: 7
Training loss: 3.5304627418518066
Validation loss: 4.27707600765091
Epoch: 18| Step: 8
Training loss: 5.569861888885498
Validation loss: 4.284704705794081
Epoch: 18| Step: 9
Training loss: 5.2259907722473145
Validation loss: 4.271698440579201
Epoch: 18| Step: 10
Training loss: 3.7518959045410156
Validation loss: 4.272030429016772
Epoch: 18| Step: 11
Training loss: 3.976273536682129
Validation loss: 4.257977017395788
Epoch: 18| Step: 12
Training loss: 4.180170059204102
Validation loss: 4.255181765384811
Epoch: 18| Step: 13
Training loss: 4.112489700317383
Validation loss: 4.240775101476436
Epoch: 18| Step: 14
Training loss: 4.312858581542969
Validation loss: 4.240628321393788
Epoch: 18| Step: 15
Training loss: 3.9013144969940186
Validation loss: 4.243751968411233
Epoch: 18| Step: 16
Training loss: 3.997086763381958
Validation loss: 4.240939150611274
Epoch: 18| Step: 17
Training loss: 5.300131797790527
Validation loss: 4.2330982153364225
Epoch: 18| Step: 18
Training loss: 4.488699913024902
Validation loss: 4.233720312873237
Epoch: 18| Step: 19
Training loss: 4.821337699890137
Validation loss: 4.22910421357738
Epoch: 18| Step: 20
Training loss: 4.632303237915039
Validation loss: 4.222017847376762
Epoch: 18| Step: 21
Training loss: 4.986681938171387
Validation loss: 4.218103952545056
Epoch: 18| Step: 22
Training loss: 4.462954521179199
Validation loss: 4.2110293923522075
Epoch: 18| Step: 23
Training loss: 2.946568250656128
Validation loss: 4.200737464342186
Epoch: 18| Step: 24
Training loss: 4.980347156524658
Validation loss: 4.199296441867197
Epoch: 18| Step: 25
Training loss: 4.796233654022217
Validation loss: 4.194927726718162
Epoch: 18| Step: 26
Training loss: 2.794843912124634
Validation loss: 4.195308891131724
Epoch: 18| Step: 27
Training loss: 4.220484733581543
Validation loss: 4.181658285127269
Epoch: 18| Step: 28
Training loss: 5.1140289306640625
Validation loss: 4.183721442874387
Epoch: 18| Step: 29
Training loss: 3.0937533378601074
Validation loss: 4.180841308703526
Epoch: 18| Step: 30
Training loss: 4.996854305267334
Validation loss: 4.165297985076904
Epoch: 18| Step: 31
Training loss: 4.434645175933838
Validation loss: 4.16360703818232
Epoch: 18| Step: 32
Training loss: 3.4459564685821533
Validation loss: 4.156914577209692
Epoch: 18| Step: 33
Training loss: 3.0988330841064453
Validation loss: 4.14433085318092
Epoch: 18| Step: 34
Training loss: 5.552435398101807
Validation loss: 4.157920635003838
Epoch: 18| Step: 35
Training loss: 4.896096229553223
Validation loss: 4.143078388927652
Epoch: 18| Step: 36
Training loss: 4.984254837036133
Validation loss: 4.14589500255722
Epoch: 18| Step: 37
Training loss: 4.939908981323242
Validation loss: 4.130822830062976
Epoch: 18| Step: 38
Training loss: 5.493788719177246
Validation loss: 4.137915738194966
Epoch: 18| Step: 39
Training loss: 4.733591079711914
Validation loss: 4.118539868498877
Epoch: 8| Step: 0
Training loss: 3.417847156524658
Validation loss: 4.122525304341488
Epoch: 18| Step: 1
Training loss: 3.8637096881866455
Validation loss: 4.117126536883896
Epoch: 18| Step: 2
Training loss: 4.368040084838867
Validation loss: 4.118236226143597
Epoch: 18| Step: 3
Training loss: 3.7584125995635986
Validation loss: 4.104721086488353
Epoch: 18| Step: 4
Training loss: 4.9780731201171875
Validation loss: 4.102905492988421
Epoch: 18| Step: 5
Training loss: 4.021340847015381
Validation loss: 4.0908392693499005
Epoch: 18| Step: 6
Training loss: 5.875757217407227
Validation loss: 4.096285334593958
Epoch: 18| Step: 7
Training loss: 3.620215892791748
Validation loss: 4.0920014690152176
Epoch: 18| Step: 8
Training loss: 4.078412055969238
Validation loss: 4.087048082900562
Epoch: 18| Step: 9
Training loss: 4.135897636413574
Validation loss: 4.0772241791375246
Epoch: 18| Step: 10
Training loss: 4.932830810546875
Validation loss: 4.066077098571997
Epoch: 18| Step: 11
Training loss: 5.215301036834717
Validation loss: 4.065613098281751
Epoch: 18| Step: 12
Training loss: 3.8348476886749268
Validation loss: 4.060933778611876
Epoch: 18| Step: 13
Training loss: 4.665816783905029
Validation loss: 4.059368365102535
Epoch: 18| Step: 14
Training loss: 2.685112953186035
Validation loss: 4.055665589065003
Epoch: 18| Step: 15
Training loss: 4.423202037811279
Validation loss: 4.052127467642586
Epoch: 18| Step: 16
Training loss: 4.451986312866211
Validation loss: 4.057042273686086
Epoch: 18| Step: 17
Training loss: 5.0770697593688965
Validation loss: 4.04185107457552
Epoch: 18| Step: 18
Training loss: 4.96724796295166
Validation loss: 4.040448344868722
Epoch: 18| Step: 19
Training loss: 4.959360122680664
Validation loss: 4.031491626080849
Epoch: 18| Step: 20
Training loss: 4.404506206512451
Validation loss: 4.029383695382866
Epoch: 18| Step: 21
Training loss: 3.59151554107666
Validation loss: 4.022196570746333
Epoch: 18| Step: 22
Training loss: 4.2324628829956055
Validation loss: 4.022085419661707
Epoch: 18| Step: 23
Training loss: 4.083131790161133
Validation loss: 4.013487260118663
Epoch: 18| Step: 24
Training loss: 3.9424548149108887
Validation loss: 4.0006085231149795
Epoch: 18| Step: 25
Training loss: 4.264048099517822
Validation loss: 4.007218736538784
Epoch: 18| Step: 26
Training loss: 3.6509251594543457
Validation loss: 4.001790235368468
Epoch: 18| Step: 27
Training loss: 3.6414403915405273
Validation loss: 3.9913594053803587
Epoch: 18| Step: 28
Training loss: 4.8670973777771
Validation loss: 3.994901390384427
Epoch: 18| Step: 29
Training loss: 5.7875657081604
Validation loss: 3.9926387491843682
Epoch: 18| Step: 30
Training loss: 4.543740272521973
Validation loss: 3.98969094530284
Epoch: 18| Step: 31
Training loss: 3.930393695831299
Validation loss: 3.9845089655128314
Epoch: 18| Step: 32
Training loss: 3.6217949390411377
Validation loss: 3.9766067703850836
Epoch: 18| Step: 33
Training loss: 4.213980197906494
Validation loss: 3.9723940238678197
Epoch: 18| Step: 34
Training loss: 3.7795071601867676
Validation loss: 3.9744041223320172
Epoch: 18| Step: 35
Training loss: 2.5753767490386963
Validation loss: 3.961858759681098
Epoch: 18| Step: 36
Training loss: 3.8516554832458496
Validation loss: 3.9642663962549443
Epoch: 18| Step: 37
Training loss: 4.7943644523620605
Validation loss: 3.9496269654884615
Epoch: 18| Step: 38
Training loss: 4.463637351989746
Validation loss: 3.9556915262620227
Epoch: 18| Step: 39
Training loss: 4.837169647216797
Validation loss: 3.9489838202222645
Epoch: 9| Step: 0
Training loss: 5.247258186340332
Validation loss: 3.939393453460803
Epoch: 18| Step: 1
Training loss: 2.9972167015075684
Validation loss: 3.9443731616726883
Epoch: 18| Step: 2
Training loss: 4.017467975616455
Validation loss: 3.9347149193715705
Epoch: 18| Step: 3
Training loss: 4.145054817199707
Validation loss: 3.927544935144109
Epoch: 18| Step: 4
Training loss: 3.712416172027588
Validation loss: 3.9206398751238267
Epoch: 18| Step: 5
Training loss: 3.850935935974121
Validation loss: 3.923553449644459
Epoch: 18| Step: 6
Training loss: 3.2363100051879883
Validation loss: 3.9203843332880695
Epoch: 18| Step: 7
Training loss: 5.364255905151367
Validation loss: 3.9052384362803947
Epoch: 18| Step: 8
Training loss: 6.80202054977417
Validation loss: 3.908194284644916
Epoch: 18| Step: 9
Training loss: 4.232787132263184
Validation loss: 3.903308986759872
Epoch: 18| Step: 10
Training loss: 3.5822525024414062
Validation loss: 3.895128678932464
Epoch: 18| Step: 11
Training loss: 5.333591938018799
Validation loss: 3.898213154978032
Epoch: 18| Step: 12
Training loss: 3.875824451446533
Validation loss: 3.8911114013452326
Epoch: 18| Step: 13
Training loss: 3.0205583572387695
Validation loss: 3.8914409095434834
Epoch: 18| Step: 14
Training loss: 4.323976516723633
Validation loss: 3.882705204778438
Epoch: 18| Step: 15
Training loss: 5.720394134521484
Validation loss: 3.8853733110770903
Epoch: 18| Step: 16
Training loss: 3.3483059406280518
Validation loss: 3.873242963132241
Epoch: 18| Step: 17
Training loss: 4.464548587799072
Validation loss: 3.8748083526282002
Epoch: 18| Step: 18
Training loss: 3.5183777809143066
Validation loss: 3.8682826543025834
Epoch: 18| Step: 19
Training loss: 3.270306348800659
Validation loss: 3.867538397260707
Epoch: 18| Step: 20
Training loss: 3.0175626277923584
Validation loss: 3.8600374623168285
Epoch: 18| Step: 21
Training loss: 5.877097129821777
Validation loss: 3.855849736028438
Epoch: 18| Step: 22
Training loss: 5.11813497543335
Validation loss: 3.8439170130722813
Epoch: 18| Step: 23
Training loss: 3.539548873901367
Validation loss: 3.851396873700533
Epoch: 18| Step: 24
Training loss: 3.6228127479553223
Validation loss: 3.82565990454859
Epoch: 18| Step: 25
Training loss: 3.9223153591156006
Validation loss: 3.834661554089553
Epoch: 18| Step: 26
Training loss: 3.799952507019043
Validation loss: 3.8359294194969342
Epoch: 18| Step: 27
Training loss: 3.2461788654327393
Validation loss: 3.8267111984088267
Epoch: 18| Step: 28
Training loss: 4.300320625305176
Validation loss: 3.827896715068131
Epoch: 18| Step: 29
Training loss: 3.8720862865448
Validation loss: 3.833489584408218
Epoch: 18| Step: 30
Training loss: 4.75585412979126
Validation loss: 3.818477284136436
Epoch: 18| Step: 31
Training loss: 3.879584550857544
Validation loss: 3.8113297078249264
Epoch: 18| Step: 32
Training loss: 4.824262619018555
Validation loss: 3.805392165835813
Epoch: 18| Step: 33
Training loss: 4.046616077423096
Validation loss: 3.8143337699149154
Epoch: 18| Step: 34
Training loss: 3.9904685020446777
Validation loss: 3.810603261851578
Epoch: 18| Step: 35
Training loss: 4.049788951873779
Validation loss: 3.8027591705322266
Epoch: 18| Step: 36
Training loss: 4.387621879577637
Validation loss: 3.8013923511230687
Epoch: 18| Step: 37
Training loss: 3.2507824897766113
Validation loss: 3.8052278971500533
Epoch: 18| Step: 38
Training loss: 2.9031553268432617
Validation loss: 3.7982023808595944
Epoch: 18| Step: 39
Training loss: 4.540109157562256
Validation loss: 3.794921288387381
Epoch: 10| Step: 0
Training loss: 5.1972246170043945
Validation loss: 3.7963357297636624
Epoch: 18| Step: 1
Training loss: 4.118914604187012
Validation loss: 3.7797969828406686
Epoch: 18| Step: 2
Training loss: 4.333742141723633
Validation loss: 3.7721243264863817
Epoch: 18| Step: 3
Training loss: 5.611203193664551
Validation loss: 3.7712214867845715
Epoch: 18| Step: 4
Training loss: 3.7171125411987305
Validation loss: 3.7704027453772455
Epoch: 18| Step: 5
Training loss: 2.9962387084960938
Validation loss: 3.7744358546442265
Epoch: 18| Step: 6
Training loss: 5.558355331420898
Validation loss: 3.771022450152061
Epoch: 18| Step: 7
Training loss: 4.7283406257629395
Validation loss: 3.7665910686520365
Epoch: 18| Step: 8
Training loss: 4.233222007751465
Validation loss: 3.7656187582359038
Epoch: 18| Step: 9
Training loss: 3.4746437072753906
Validation loss: 3.764169147546343
Epoch: 18| Step: 10
Training loss: 3.0717785358428955
Validation loss: 3.7583978673537
Epoch: 18| Step: 11
Training loss: 3.4751858711242676
Validation loss: 3.759975601443284
Epoch: 18| Step: 12
Training loss: 3.4384851455688477
Validation loss: 3.7486588560419976
Epoch: 18| Step: 13
Training loss: 4.1058349609375
Validation loss: 3.7534719268195063
Epoch: 18| Step: 14
Training loss: 5.338174819946289
Validation loss: 3.7549148652193356
Epoch: 18| Step: 15
Training loss: 4.63651180267334
Validation loss: 3.741647497355509
Epoch: 18| Step: 16
Training loss: 3.8444325923919678
Validation loss: 3.736138189439293
Epoch: 18| Step: 17
Training loss: 4.015885353088379
Validation loss: 3.743100250367638
Epoch: 18| Step: 18
Training loss: 4.322569847106934
Validation loss: 3.741841986882601
Epoch: 18| Step: 19
Training loss: 2.45072078704834
Validation loss: 3.7236667365478953
Epoch: 18| Step: 20
Training loss: 5.302309989929199
Validation loss: 3.725617693482543
Epoch: 18| Step: 21
Training loss: 4.021736145019531
Validation loss: 3.7188978915591893
Epoch: 18| Step: 22
Training loss: 3.610710859298706
Validation loss: 3.7285517394113885
Epoch: 18| Step: 23
Training loss: 3.254321575164795
Validation loss: 3.7182723875526045
Epoch: 18| Step: 24
Training loss: 4.06171178817749
Validation loss: 3.7033835760981058
Epoch: 18| Step: 25
Training loss: 3.743842124938965
Validation loss: 3.7030505911051796
Epoch: 18| Step: 26
Training loss: 4.016833305358887
Validation loss: 3.7089492365610686
Epoch: 18| Step: 27
Training loss: 3.0027546882629395
Validation loss: 3.709916030760292
Epoch: 18| Step: 28
Training loss: 2.8720462322235107
Validation loss: 3.7010416538595297
Epoch: 18| Step: 29
Training loss: 4.26063346862793
Validation loss: 3.709328970463156
Epoch: 18| Step: 30
Training loss: 4.595920562744141
Validation loss: 3.694374952384894
Epoch: 18| Step: 31
Training loss: 4.500306129455566
Validation loss: 3.6858732477366494
Epoch: 18| Step: 32
Training loss: 3.5103182792663574
Validation loss: 3.6900388662763635
Epoch: 18| Step: 33
Training loss: 3.0926828384399414
Validation loss: 3.686996350185477
Epoch: 18| Step: 34
Training loss: 4.322847843170166
Validation loss: 3.691153234715084
Epoch: 18| Step: 35
Training loss: 4.429591655731201
Validation loss: 3.6716073056776746
Epoch: 18| Step: 36
Training loss: 3.209010601043701
Validation loss: 3.6773534472897755
Epoch: 18| Step: 37
Training loss: 3.433012008666992
Validation loss: 3.679834396719075
Epoch: 18| Step: 38
Training loss: 3.8189451694488525
Validation loss: 3.6825795722522323
Epoch: 18| Step: 39
Training loss: 4.726084232330322
Validation loss: 3.68357993029862
Epoch: 11| Step: 0
Training loss: 2.847153663635254
Validation loss: 3.6781575473950063
Epoch: 18| Step: 1
Training loss: 3.9930315017700195
Validation loss: 3.6779496189501644
Epoch: 18| Step: 2
Training loss: 4.826189041137695
Validation loss: 3.657144148572743
Epoch: 18| Step: 3
Training loss: 4.604817867279053
Validation loss: 3.653988174397311
Epoch: 18| Step: 4
Training loss: 3.8409719467163086
Validation loss: 3.671780181445664
Epoch: 18| Step: 5
Training loss: 3.732058048248291
Validation loss: 3.6469618673804853
Epoch: 18| Step: 6
Training loss: 3.281744956970215
Validation loss: 3.6526449121159614
Epoch: 18| Step: 7
Training loss: 2.547316074371338
Validation loss: 3.650100960148324
Epoch: 18| Step: 8
Training loss: 4.60654354095459
Validation loss: 3.649313916405328
Epoch: 18| Step: 9
Training loss: 4.533361911773682
Validation loss: 3.6471906360104787
Epoch: 18| Step: 10
Training loss: 4.000815391540527
Validation loss: 3.6365574486821677
Epoch: 18| Step: 11
Training loss: 2.797529697418213
Validation loss: 3.621614126850375
Epoch: 18| Step: 12
Training loss: 3.270279884338379
Validation loss: 3.6407990404170194
Epoch: 18| Step: 13
Training loss: 3.418372631072998
Validation loss: 3.6378573548021933
Epoch: 18| Step: 14
Training loss: 4.279263973236084
Validation loss: 3.63644463038273
Epoch: 18| Step: 15
Training loss: 3.8431689739227295
Validation loss: 3.6256937809127696
Epoch: 18| Step: 16
Training loss: 3.322782516479492
Validation loss: 3.61574760786921
Epoch: 18| Step: 17
Training loss: 2.845615863800049
Validation loss: 3.6248509557984714
Epoch: 18| Step: 18
Training loss: 3.551121234893799
Validation loss: 3.615386444887669
Epoch: 18| Step: 19
Training loss: 4.546962738037109
Validation loss: 3.6229806014959762
Epoch: 18| Step: 20
Training loss: 3.012545108795166
Validation loss: 3.6239294662750026
Epoch: 18| Step: 21
Training loss: 2.771195411682129
Validation loss: 3.6019291997813494
Epoch: 18| Step: 22
Training loss: 4.434276103973389
Validation loss: 3.623646228433513
Epoch: 18| Step: 23
Training loss: 4.040620803833008
Validation loss: 3.611028405402204
Epoch: 18| Step: 24
Training loss: 4.709897994995117
Validation loss: 3.598592053214423
Epoch: 18| Step: 25
Training loss: 5.202200889587402
Validation loss: 3.609200493037272
Epoch: 18| Step: 26
Training loss: 5.225582122802734
Validation loss: 3.593137665618238
Epoch: 18| Step: 27
Training loss: 3.7173900604248047
Validation loss: 3.59307323771415
Epoch: 18| Step: 28
Training loss: 3.938906192779541
Validation loss: 3.5783885931797164
Epoch: 18| Step: 29
Training loss: 4.474145889282227
Validation loss: 3.580948359674687
Epoch: 18| Step: 30
Training loss: 3.2545576095581055
Validation loss: 3.5904085104414025
Epoch: 18| Step: 31
Training loss: 4.062542915344238
Validation loss: 3.5941110360536643
Epoch: 18| Step: 32
Training loss: 3.9242405891418457
Validation loss: 3.580896350119611
Epoch: 18| Step: 33
Training loss: 3.8146042823791504
Validation loss: 3.589767605280705
Epoch: 18| Step: 34
Training loss: 5.07630729675293
Validation loss: 3.586596828570469
Epoch: 18| Step: 35
Training loss: 4.19722843170166
Validation loss: 3.582756454138447
Epoch: 18| Step: 36
Training loss: 5.512009620666504
Validation loss: 3.5779282583607186
Epoch: 18| Step: 37
Training loss: 3.540041446685791
Validation loss: 3.5799529380935557
Epoch: 18| Step: 38
Training loss: 2.9135279655456543
Validation loss: 3.565953079745066
Epoch: 18| Step: 39
Training loss: 3.9509265422821045
Validation loss: 3.5693472495181955
Epoch: 12| Step: 0
Training loss: 5.168807506561279
Validation loss: 3.56332122679237
Epoch: 18| Step: 1
Training loss: 2.952312707901001
Validation loss: 3.5568085128454854
Epoch: 18| Step: 2
Training loss: 4.126149654388428
Validation loss: 3.5614537163604076
Epoch: 18| Step: 3
Training loss: 3.8579039573669434
Validation loss: 3.5557312793868907
Epoch: 18| Step: 4
Training loss: 2.3199923038482666
Validation loss: 3.542097964732767
Epoch: 18| Step: 5
Training loss: 4.881747245788574
Validation loss: 3.5414518949796827
Epoch: 18| Step: 6
Training loss: 5.082583427429199
Validation loss: 3.534524553971325
Epoch: 18| Step: 7
Training loss: 3.7962307929992676
Validation loss: 3.544691199021374
Epoch: 18| Step: 8
Training loss: 4.789909362792969
Validation loss: 3.53703347556025
Epoch: 18| Step: 9
Training loss: 4.210786819458008
Validation loss: 3.5124961386481637
Epoch: 18| Step: 10
Training loss: 4.163639068603516
Validation loss: 3.5440615612825903
Epoch: 18| Step: 11
Training loss: 4.909043312072754
Validation loss: 3.5333412362517214
Epoch: 18| Step: 12
Training loss: 5.066290855407715
Validation loss: 3.532512987260338
Epoch: 18| Step: 13
Training loss: 2.0710835456848145
Validation loss: 3.5294479946438355
Epoch: 18| Step: 14
Training loss: 3.854539155960083
Validation loss: 3.5065970836783484
Epoch: 18| Step: 15
Training loss: 3.7780280113220215
Validation loss: 3.5147134725996056
Epoch: 18| Step: 16
Training loss: 3.8539748191833496
Validation loss: 3.527275716658119
Epoch: 18| Step: 17
Training loss: 4.934070110321045
Validation loss: 3.513585358214893
Epoch: 18| Step: 18
Training loss: 3.4286553859710693
Validation loss: 3.5131382804980382
Epoch: 18| Step: 19
Training loss: 2.388993740081787
Validation loss: 3.5135285348343333
Epoch: 18| Step: 20
Training loss: 4.718125343322754
Validation loss: 3.5046935475987495
Epoch: 18| Step: 21
Training loss: 4.309165954589844
Validation loss: 3.4977496081976582
Epoch: 18| Step: 22
Training loss: 3.3967843055725098
Validation loss: 3.4865405508082548
Epoch: 18| Step: 23
Training loss: 3.316108226776123
Validation loss: 3.5018816320158597
Epoch: 18| Step: 24
Training loss: 2.809785842895508
Validation loss: 3.4986540790942073
Epoch: 18| Step: 25
Training loss: 4.364193916320801
Validation loss: 3.48381211431764
Epoch: 18| Step: 26
Training loss: 3.2504310607910156
Validation loss: 3.4890023650025292
Epoch: 18| Step: 27
Training loss: 3.5191097259521484
Validation loss: 3.483073018437667
Epoch: 18| Step: 28
Training loss: 3.2740607261657715
Validation loss: 3.4810676025829728
Epoch: 18| Step: 29
Training loss: 3.134566068649292
Validation loss: 3.490267082941618
Epoch: 18| Step: 30
Training loss: 4.587334632873535
Validation loss: 3.4831677323622667
Epoch: 18| Step: 31
Training loss: 4.089162826538086
Validation loss: 3.46970508252974
Epoch: 18| Step: 32
Training loss: 3.4368276596069336
Validation loss: 3.477271536271349
Epoch: 18| Step: 33
Training loss: 3.5984230041503906
Validation loss: 3.4535620692822575
Epoch: 18| Step: 34
Training loss: 2.2789041996002197
Validation loss: 3.47821652117393
Epoch: 18| Step: 35
Training loss: 4.527583122253418
Validation loss: 3.46488811472337
Epoch: 18| Step: 36
Training loss: 4.46403694152832
Validation loss: 3.4610007272349845
Epoch: 18| Step: 37
Training loss: 4.730506896972656
Validation loss: 3.4693724834661688
Epoch: 18| Step: 38
Training loss: 3.1346042156219482
Validation loss: 3.462384266819028
Epoch: 18| Step: 39
Training loss: 2.041623592376709
Validation loss: 3.457258726195466
Epoch: 13| Step: 0
Training loss: 2.462831735610962
Validation loss: 3.466214692849907
Epoch: 18| Step: 1
Training loss: 4.254765510559082
Validation loss: 3.4579677461720197
Epoch: 18| Step: 2
Training loss: 3.1933765411376953
Validation loss: 3.448321579171599
Epoch: 18| Step: 3
Training loss: 2.7077531814575195
Validation loss: 3.4359404560473323
Epoch: 18| Step: 4
Training loss: 2.3463778495788574
Validation loss: 3.4299421842149695
Epoch: 18| Step: 5
Training loss: 3.1210837364196777
Validation loss: 3.436860151428113
Epoch: 18| Step: 6
Training loss: 4.929665565490723
Validation loss: 3.454655486045124
Epoch: 18| Step: 7
Training loss: 3.2381553649902344
Validation loss: 3.435372208519805
Epoch: 18| Step: 8
Training loss: 3.7996935844421387
Validation loss: 3.4186160757387283
Epoch: 18| Step: 9
Training loss: 3.848675012588501
Validation loss: 3.4261612429035653
Epoch: 18| Step: 10
Training loss: 5.138762474060059
Validation loss: 3.439775610999238
Epoch: 18| Step: 11
Training loss: 4.789794445037842
Validation loss: 3.439452524665448
Epoch: 18| Step: 12
Training loss: 1.8760391473770142
Validation loss: 3.4314332694458445
Epoch: 18| Step: 13
Training loss: 4.624475479125977
Validation loss: 3.4217493482630887
Epoch: 18| Step: 14
Training loss: 4.440074920654297
Validation loss: 3.4256378901090554
Epoch: 18| Step: 15
Training loss: 4.181860446929932
Validation loss: 3.4242775251539492
Epoch: 18| Step: 16
Training loss: 3.5856151580810547
Validation loss: 3.4312321642319934
Epoch: 18| Step: 17
Training loss: 3.4493439197540283
Validation loss: 3.4266638858712835
Epoch: 18| Step: 18
Training loss: 4.041671276092529
Validation loss: 3.4256498436276
Epoch: 18| Step: 19
Training loss: 3.7151105403900146
Validation loss: 3.4054989746148636
Epoch: 18| Step: 20
Training loss: 4.738135814666748
Validation loss: 3.3988177313221444
Epoch: 18| Step: 21
Training loss: 3.5719830989837646
Validation loss: 3.4053390249073936
Epoch: 18| Step: 22
Training loss: 5.306145191192627
Validation loss: 3.4033418250598495
Epoch: 18| Step: 23
Training loss: 4.110950946807861
Validation loss: 3.396014815611805
Epoch: 18| Step: 24
Training loss: 2.282440185546875
Validation loss: 3.4069286456211008
Epoch: 18| Step: 25
Training loss: 3.8236241340637207
Validation loss: 3.4002178247026404
Epoch: 18| Step: 26
Training loss: 3.353844404220581
Validation loss: 3.3912363601245468
Epoch: 18| Step: 27
Training loss: 4.119897842407227
Validation loss: 3.405965311064137
Epoch: 18| Step: 28
Training loss: 3.9232125282287598
Validation loss: 3.4036638239304797
Epoch: 18| Step: 29
Training loss: 3.2375290393829346
Validation loss: 3.402152586326325
Epoch: 18| Step: 30
Training loss: 4.477537155151367
Validation loss: 3.3938238277709742
Epoch: 18| Step: 31
Training loss: 4.9209136962890625
Validation loss: 3.3712052732920474
Epoch: 18| Step: 32
Training loss: 3.8276238441467285
Validation loss: 3.3845121568913084
Epoch: 18| Step: 33
Training loss: 4.125863075256348
Validation loss: 3.3929737506152913
Epoch: 18| Step: 34
Training loss: 2.6510891914367676
Validation loss: 3.3866997914348573
Epoch: 18| Step: 35
Training loss: 3.180262804031372
Validation loss: 3.390509903859749
Epoch: 18| Step: 36
Training loss: 4.062965393066406
Validation loss: 3.366436757629724
Epoch: 18| Step: 37
Training loss: 3.3762617111206055
Validation loss: 3.3863204880584057
Epoch: 18| Step: 38
Training loss: 3.5455002784729004
Validation loss: 3.3564417207841393
Epoch: 18| Step: 39
Training loss: 3.54428768157959
Validation loss: 3.3840675148174917
Epoch: 14| Step: 0
Training loss: 3.050600528717041
Validation loss: 3.3767500781326842
Epoch: 18| Step: 1
Training loss: 3.8198728561401367
Validation loss: 3.3737499319392144
Epoch: 18| Step: 2
Training loss: 4.6715545654296875
Validation loss: 3.3779707606747853
Epoch: 18| Step: 3
Training loss: 2.754493236541748
Validation loss: 3.3685071862858833
Epoch: 18| Step: 4
Training loss: 3.777087450027466
Validation loss: 3.3400520077712246
Epoch: 18| Step: 5
Training loss: 2.627352714538574
Validation loss: 3.356766699029387
Epoch: 18| Step: 6
Training loss: 4.492547988891602
Validation loss: 3.3735431973025096
Epoch: 18| Step: 7
Training loss: 4.5933356285095215
Validation loss: 3.369444800795411
Epoch: 18| Step: 8
Training loss: 3.341125011444092
Validation loss: 3.3567339619286627
Epoch: 18| Step: 9
Training loss: 4.176940441131592
Validation loss: 3.3675829403692012
Epoch: 18| Step: 10
Training loss: 2.8171777725219727
Validation loss: 3.3590552978378407
Epoch: 18| Step: 11
Training loss: 3.636343240737915
Validation loss: 3.3597120449697373
Epoch: 18| Step: 12
Training loss: 3.434572696685791
Validation loss: 3.3622986910154493
Epoch: 18| Step: 13
Training loss: 4.903227806091309
Validation loss: 3.345806494033594
Epoch: 18| Step: 14
Training loss: 4.161588668823242
Validation loss: 3.3411542940482817
Epoch: 18| Step: 15
Training loss: 3.477759838104248
Validation loss: 3.363868863462544
Epoch: 18| Step: 16
Training loss: 3.6122703552246094
Validation loss: 3.3538575412558136
Epoch: 18| Step: 17
Training loss: 4.940916061401367
Validation loss: 3.3430661889288924
Epoch: 18| Step: 18
Training loss: 2.711327075958252
Validation loss: 3.335209448560536
Epoch: 18| Step: 19
Training loss: 4.972226142883301
Validation loss: 3.350156650268774
Epoch: 18| Step: 20
Training loss: 3.7117702960968018
Validation loss: 3.3526225278703428
Epoch: 18| Step: 21
Training loss: 2.8195831775665283
Validation loss: 3.33634402769075
Epoch: 18| Step: 22
Training loss: 3.200871706008911
Validation loss: 3.338146305770325
Epoch: 18| Step: 23
Training loss: 4.102878570556641
Validation loss: 3.3327935479527753
Epoch: 18| Step: 24
Training loss: 3.998687267303467
Validation loss: 3.3364383882755857
Epoch: 18| Step: 25
Training loss: 3.205435276031494
Validation loss: 3.3120337698957045
Epoch: 18| Step: 26
Training loss: 3.505851984024048
Validation loss: 3.3357054689805286
Epoch: 18| Step: 27
Training loss: 4.229445457458496
Validation loss: 3.327400150916559
Epoch: 18| Step: 28
Training loss: 3.2808456420898438
Validation loss: 3.3271872525592503
Epoch: 18| Step: 29
Training loss: 4.165735244750977
Validation loss: 3.336548057391489
Epoch: 18| Step: 30
Training loss: 4.37938117980957
Validation loss: 3.3165760760684666
Epoch: 18| Step: 31
Training loss: 4.031685829162598
Validation loss: 3.3312379078899355
Epoch: 18| Step: 32
Training loss: 3.8659157752990723
Validation loss: 3.319564586063083
Epoch: 18| Step: 33
Training loss: 3.6362476348876953
Validation loss: 3.3273348773983744
Epoch: 18| Step: 34
Training loss: 1.63582444190979
Validation loss: 3.3203004504279265
Epoch: 18| Step: 35
Training loss: 3.1536355018615723
Validation loss: 3.3172094598948525
Epoch: 18| Step: 36
Training loss: 3.1833512783050537
Validation loss: 3.31836797179078
Epoch: 18| Step: 37
Training loss: 3.930365562438965
Validation loss: 3.3132193088531494
Epoch: 18| Step: 38
Training loss: 3.7569479942321777
Validation loss: 3.320800098583853
Epoch: 18| Step: 39
Training loss: 3.4552507400512695
Validation loss: 3.325175158411479
Epoch: 15| Step: 0
Training loss: 2.703841209411621
Validation loss: 3.3216843519279426
Epoch: 18| Step: 1
Training loss: 4.09841775894165
Validation loss: 3.306759254537898
Epoch: 18| Step: 2
Training loss: 2.481297731399536
Validation loss: 3.312059452207826
Epoch: 18| Step: 3
Training loss: 3.3251914978027344
Validation loss: 3.2983587397088248
Epoch: 18| Step: 4
Training loss: 3.6599857807159424
Validation loss: 3.3092786356699553
Epoch: 18| Step: 5
Training loss: 3.34135103225708
Validation loss: 3.2932103126169108
Epoch: 18| Step: 6
Training loss: 3.103579044342041
Validation loss: 3.3129459868232125
Epoch: 18| Step: 7
Training loss: 3.566004991531372
Validation loss: 3.3073600393405065
Epoch: 18| Step: 8
Training loss: 4.000514030456543
Validation loss: 3.3037955675193733
Epoch: 18| Step: 9
Training loss: 2.587533950805664
Validation loss: 3.286801147803986
Epoch: 18| Step: 10
Training loss: 3.5120749473571777
Validation loss: 3.295021907888728
Epoch: 18| Step: 11
Training loss: 3.0182056427001953
Validation loss: 3.2941657827912474
Epoch: 18| Step: 12
Training loss: 4.19157600402832
Validation loss: 3.3018237515319164
Epoch: 18| Step: 13
Training loss: 3.2618565559387207
Validation loss: 3.28507623741095
Epoch: 18| Step: 14
Training loss: 3.013915538787842
Validation loss: 3.279478817534961
Epoch: 18| Step: 15
Training loss: 4.506330966949463
Validation loss: 3.2889675133519893
Epoch: 18| Step: 16
Training loss: 3.22001051902771
Validation loss: 3.2793091218248547
Epoch: 18| Step: 17
Training loss: 3.2476840019226074
Validation loss: 3.28063243413143
Epoch: 18| Step: 18
Training loss: 4.265397071838379
Validation loss: 3.2868914501272517
Epoch: 18| Step: 19
Training loss: 3.2273459434509277
Validation loss: 3.283290495975412
Epoch: 18| Step: 20
Training loss: 2.709439754486084
Validation loss: 3.2906240353481375
Epoch: 18| Step: 21
Training loss: 4.884377956390381
Validation loss: 3.2872978011481195
Epoch: 18| Step: 22
Training loss: 5.065193176269531
Validation loss: 3.283024928552641
Epoch: 18| Step: 23
Training loss: 4.557849884033203
Validation loss: 3.2817738364926345
Epoch: 18| Step: 24
Training loss: 4.680046081542969
Validation loss: 3.2795845450257226
Epoch: 18| Step: 25
Training loss: 3.367854595184326
Validation loss: 3.2844507539872643
Epoch: 18| Step: 26
Training loss: 4.050520896911621
Validation loss: 3.281031693486001
Epoch: 18| Step: 27
Training loss: 4.433302879333496
Validation loss: 3.2661773866886716
Epoch: 18| Step: 28
Training loss: 3.103727102279663
Validation loss: 3.2669817698087624
Epoch: 18| Step: 29
Training loss: 4.53291130065918
Validation loss: 3.2760568033877036
Epoch: 18| Step: 30
Training loss: 4.25871467590332
Validation loss: 3.2783636086278682
Epoch: 18| Step: 31
Training loss: 4.00895881652832
Validation loss: 3.257744344875967
Epoch: 18| Step: 32
Training loss: 4.193824291229248
Validation loss: 3.26118300286986
Epoch: 18| Step: 33
Training loss: 2.857931137084961
Validation loss: 3.2649121456009023
Epoch: 18| Step: 34
Training loss: 3.0091049671173096
Validation loss: 3.2674158528554353
Epoch: 18| Step: 35
Training loss: 4.179797172546387
Validation loss: 3.2647835848142774
Epoch: 18| Step: 36
Training loss: 4.127785682678223
Validation loss: 3.275048887986931
Epoch: 18| Step: 37
Training loss: 3.8381338119506836
Validation loss: 3.2756093920563623
Epoch: 18| Step: 38
Training loss: 2.649338960647583
Validation loss: 3.265012219655428
Epoch: 18| Step: 39
Training loss: 3.356213092803955
Validation loss: 3.24456672874286
Epoch: 16| Step: 0
Training loss: 2.2570836544036865
Validation loss: 3.2646408218274012
Epoch: 18| Step: 1
Training loss: 3.743320941925049
Validation loss: 3.2551687827213205
Epoch: 18| Step: 2
Training loss: 5.0575666427612305
Validation loss: 3.2506274147857006
Epoch: 18| Step: 3
Training loss: 2.549321174621582
Validation loss: 3.2677308852724036
Epoch: 18| Step: 4
Training loss: 3.328408718109131
Validation loss: 3.255285034934394
Epoch: 18| Step: 5
Training loss: 3.120043992996216
Validation loss: 3.2636569875607386
Epoch: 18| Step: 6
Training loss: 3.3478827476501465
Validation loss: 3.2642388395268283
Epoch: 18| Step: 7
Training loss: 4.200371742248535
Validation loss: 3.2599155405442493
Epoch: 18| Step: 8
Training loss: 3.9149246215820312
Validation loss: 3.240205721889468
Epoch: 18| Step: 9
Training loss: 4.334231376647949
Validation loss: 3.253440362086399
Epoch: 18| Step: 10
Training loss: 2.4885830879211426
Validation loss: 3.2489216344819654
Epoch: 18| Step: 11
Training loss: 4.690985679626465
Validation loss: 3.253994717014779
Epoch: 18| Step: 12
Training loss: 3.149670124053955
Validation loss: 3.2613923395280358
Epoch: 18| Step: 13
Training loss: 3.722750186920166
Validation loss: 3.25219119366982
Epoch: 18| Step: 14
Training loss: 2.402616024017334
Validation loss: 3.261570825851221
Epoch: 18| Step: 15
Training loss: 5.209356307983398
Validation loss: 3.2567159057521136
Epoch: 18| Step: 16
Training loss: 2.739586114883423
Validation loss: 3.243716881429549
Epoch: 18| Step: 17
Training loss: 2.9434821605682373
Validation loss: 3.254201572576015
Epoch: 18| Step: 18
Training loss: 3.6028597354888916
Validation loss: 3.2521522542555554
Epoch: 18| Step: 19
Training loss: 4.764623165130615
Validation loss: 3.25545230357767
Epoch: 18| Step: 20
Training loss: 3.30607533454895
Validation loss: 3.250396731946108
Epoch: 18| Step: 21
Training loss: 2.350935935974121
Validation loss: 3.2501975580942717
Epoch: 18| Step: 22
Training loss: 4.916903495788574
Validation loss: 3.241371144493707
Epoch: 18| Step: 23
Training loss: 3.7381982803344727
Validation loss: 3.2446903564947114
Epoch: 18| Step: 24
Training loss: 3.0088295936584473
Validation loss: 3.238284978935187
Epoch: 18| Step: 25
Training loss: 3.1450893878936768
Validation loss: 3.251996352518205
Epoch: 18| Step: 26
Training loss: 4.453756332397461
Validation loss: 3.2359895380280856
Epoch: 18| Step: 27
Training loss: 3.524351119995117
Validation loss: 3.236447462932669
Epoch: 18| Step: 28
Training loss: 3.216761827468872
Validation loss: 3.24509744849994
Epoch: 18| Step: 29
Training loss: 2.214629650115967
Validation loss: 3.2394417687285717
Epoch: 18| Step: 30
Training loss: 4.982668876647949
Validation loss: 3.2462207456286865
Epoch: 18| Step: 31
Training loss: 3.334071397781372
Validation loss: 3.233704090118408
Epoch: 18| Step: 32
Training loss: 3.8225009441375732
Validation loss: 3.2296129233545536
Epoch: 18| Step: 33
Training loss: 3.638277053833008
Validation loss: 3.2379439391678186
Epoch: 18| Step: 34
Training loss: 3.922851324081421
Validation loss: 3.231927964327147
Epoch: 18| Step: 35
Training loss: 3.6550369262695312
Validation loss: 3.227032829531663
Epoch: 18| Step: 36
Training loss: 2.5021095275878906
Validation loss: 3.232210184172761
Epoch: 18| Step: 37
Training loss: 3.5371510982513428
Validation loss: 3.236506324877842
Epoch: 18| Step: 38
Training loss: 4.585930347442627
Validation loss: 3.235205345016589
Epoch: 18| Step: 39
Training loss: 4.3175506591796875
Validation loss: 3.2335698347297503
Epoch: 17| Step: 0
Training loss: 2.5400161743164062
Validation loss: 3.2372221517905913
Epoch: 18| Step: 1
Training loss: 3.753702163696289
Validation loss: 3.2244126590893423
Epoch: 18| Step: 2
Training loss: 3.5837831497192383
Validation loss: 3.2266219588492415
Epoch: 18| Step: 3
Training loss: 2.571972131729126
Validation loss: 3.2099792442733435
Epoch: 18| Step: 4
Training loss: 2.913299083709717
Validation loss: 3.2232902324456965
Epoch: 18| Step: 5
Training loss: 3.9336581230163574
Validation loss: 3.2206213405664017
Epoch: 18| Step: 6
Training loss: 3.3159708976745605
Validation loss: 3.226232809986142
Epoch: 18| Step: 7
Training loss: 5.041921138763428
Validation loss: 3.2017664574890685
Epoch: 18| Step: 8
Training loss: 2.889914035797119
Validation loss: 3.2182907200545716
Epoch: 18| Step: 9
Training loss: 3.88912034034729
Validation loss: 3.208566163941253
Epoch: 18| Step: 10
Training loss: 3.105340003967285
Validation loss: 3.2148364447861266
Epoch: 18| Step: 11
Training loss: 2.8722667694091797
Validation loss: 3.219077460199809
Epoch: 18| Step: 12
Training loss: 2.978968381881714
Validation loss: 3.2210519125135684
Epoch: 18| Step: 13
Training loss: 2.6110498905181885
Validation loss: 3.228730676843108
Epoch: 18| Step: 14
Training loss: 3.847653865814209
Validation loss: 3.2230985576300313
Epoch: 18| Step: 15
Training loss: 5.094105243682861
Validation loss: 3.229690193272323
Epoch: 18| Step: 16
Training loss: 4.346584320068359
Validation loss: 3.203427294175402
Epoch: 18| Step: 17
Training loss: 3.448183298110962
Validation loss: 3.213336869109449
Epoch: 18| Step: 18
Training loss: 3.9641520977020264
Validation loss: 3.2250839446088393
Epoch: 18| Step: 19
Training loss: 3.5806822776794434
Validation loss: 3.2175617355236903
Epoch: 18| Step: 20
Training loss: 3.609109878540039
Validation loss: 3.205500424337044
Epoch: 18| Step: 21
Training loss: 3.4978601932525635
Validation loss: 3.1954771237407655
Epoch: 18| Step: 22
Training loss: 3.885056734085083
Validation loss: 3.2183053047536947
Epoch: 18| Step: 23
Training loss: 4.270852088928223
Validation loss: 3.217066562433037
Epoch: 18| Step: 24
Training loss: 2.8232834339141846
Validation loss: 3.196983171023911
Epoch: 18| Step: 25
Training loss: 5.0272016525268555
Validation loss: 3.2127530248902683
Epoch: 18| Step: 26
Training loss: 3.1331324577331543
Validation loss: 3.1946520410853325
Epoch: 18| Step: 27
Training loss: 3.111186981201172
Validation loss: 3.21853865650918
Epoch: 18| Step: 28
Training loss: 2.480964183807373
Validation loss: 3.1935759911434256
Epoch: 18| Step: 29
Training loss: 3.880189895629883
Validation loss: 3.2079064280009097
Epoch: 18| Step: 30
Training loss: 3.276930809020996
Validation loss: 3.206047627565672
Epoch: 18| Step: 31
Training loss: 3.1830086708068848
Validation loss: 3.188781741711733
Epoch: 18| Step: 32
Training loss: 3.0672669410705566
Validation loss: 3.206897637826933
Epoch: 18| Step: 33
Training loss: 3.0488171577453613
Validation loss: 3.202465693727672
Epoch: 18| Step: 34
Training loss: 5.236644744873047
Validation loss: 3.2036033740146554
Epoch: 18| Step: 35
Training loss: 2.549617290496826
Validation loss: 3.211825194118692
Epoch: 18| Step: 36
Training loss: 5.094918251037598
Validation loss: 3.1931859863747794
Epoch: 18| Step: 37
Training loss: 3.99167537689209
Validation loss: 3.191709708824432
Epoch: 18| Step: 38
Training loss: 3.09725022315979
Validation loss: 3.1971538066864014
Epoch: 18| Step: 39
Training loss: 3.9657490253448486
Validation loss: 3.1920008230552397
Epoch: 18| Step: 0
Training loss: 3.194775104522705
Validation loss: 3.204315828762466
Epoch: 18| Step: 1
Training loss: 1.7258331775665283
Validation loss: 3.203018574405917
Epoch: 18| Step: 2
Training loss: 3.1530871391296387
Validation loss: 3.182167936572068
Epoch: 18| Step: 3
Training loss: 4.000295639038086
Validation loss: 3.1939419190660656
Epoch: 18| Step: 4
Training loss: 3.465075731277466
Validation loss: 3.1830702308270573
Epoch: 18| Step: 5
Training loss: 3.3011531829833984
Validation loss: 3.190580621040125
Epoch: 18| Step: 6
Training loss: 4.074324607849121
Validation loss: 3.202011195875758
Epoch: 18| Step: 7
Training loss: 3.3648681640625
Validation loss: 3.1850525526691684
Epoch: 18| Step: 8
Training loss: 4.013791084289551
Validation loss: 3.1836937657363125
Epoch: 18| Step: 9
Training loss: 3.1799793243408203
Validation loss: 3.197521281756943
Epoch: 18| Step: 10
Training loss: 2.0624911785125732
Validation loss: 3.1880305636700967
Epoch: 18| Step: 11
Training loss: 4.40480899810791
Validation loss: 3.1858169552233577
Epoch: 18| Step: 12
Training loss: 4.12952995300293
Validation loss: 3.191829425396679
Epoch: 18| Step: 13
Training loss: 3.4079785346984863
Validation loss: 3.1894401303298183
Epoch: 18| Step: 14
Training loss: 2.8577029705047607
Validation loss: 3.195356403323386
Epoch: 18| Step: 15
Training loss: 4.405857086181641
Validation loss: 3.1957237463203265
Epoch: 18| Step: 16
Training loss: 3.5301318168640137
Validation loss: 3.192382289351319
Epoch: 18| Step: 17
Training loss: 3.824286937713623
Validation loss: 3.1968709667809576
Epoch: 18| Step: 18
Training loss: 2.9391379356384277
Validation loss: 3.191899121236458
Epoch: 18| Step: 19
Training loss: 3.1990199089050293
Validation loss: 3.1796708947463
Epoch: 18| Step: 20
Training loss: 3.2905704975128174
Validation loss: 3.187960552654678
Epoch: 18| Step: 21
Training loss: 2.2482998371124268
Validation loss: 3.190318201943267
Epoch: 18| Step: 22
Training loss: 2.210952043533325
Validation loss: 3.1751195766942963
Epoch: 18| Step: 23
Training loss: 3.2846975326538086
Validation loss: 3.1694653222886777
Epoch: 18| Step: 24
Training loss: 2.661541223526001
Validation loss: 3.175164430261516
Epoch: 18| Step: 25
Training loss: 3.9835946559906006
Validation loss: 3.1938564382868706
Epoch: 18| Step: 26
Training loss: 4.463335990905762
Validation loss: 3.175803579872461
Epoch: 18| Step: 27
Training loss: 5.2503204345703125
Validation loss: 3.181376002675338
Epoch: 18| Step: 28
Training loss: 3.9368038177490234
Validation loss: 3.1885404518182328
Epoch: 18| Step: 29
Training loss: 3.566788911819458
Validation loss: 3.173795357024927
Epoch: 18| Step: 30
Training loss: 3.5984649658203125
Validation loss: 3.1614327876687907
Epoch: 18| Step: 31
Training loss: 2.6610159873962402
Validation loss: 3.178943917048063
Epoch: 18| Step: 32
Training loss: 2.9229166507720947
Validation loss: 3.1814028307688322
Epoch: 18| Step: 33
Training loss: 4.648987770080566
Validation loss: 3.1776486249278775
Epoch: 18| Step: 34
Training loss: 4.740146160125732
Validation loss: 3.1730658304777077
Epoch: 18| Step: 35
Training loss: 3.793248414993286
Validation loss: 3.1483640893757774
Epoch: 18| Step: 36
Training loss: 3.995262622833252
Validation loss: 3.1668968355055336
Epoch: 18| Step: 37
Training loss: 4.206888198852539
Validation loss: 3.1615896482261823
Epoch: 18| Step: 38
Training loss: 4.0923919677734375
Validation loss: 3.1612298042654134
Epoch: 18| Step: 39
Training loss: 4.26341438293457
Validation loss: 3.167988564470689
Epoch: 19| Step: 0
Training loss: 3.187986373901367
Validation loss: 3.1640722905989174
Epoch: 18| Step: 1
Training loss: 3.900301933288574
Validation loss: 3.1439176583461625
Epoch: 18| Step: 2
Training loss: 3.152094841003418
Validation loss: 3.1797425506783905
Epoch: 18| Step: 3
Training loss: 2.747028350830078
Validation loss: 3.1604464380003567
Epoch: 18| Step: 4
Training loss: 4.733443260192871
Validation loss: 3.140254205937008
Epoch: 18| Step: 5
Training loss: 3.478933811187744
Validation loss: 3.166862599283671
Epoch: 18| Step: 6
Training loss: 4.1468329429626465
Validation loss: 3.1712425921460707
Epoch: 18| Step: 7
Training loss: 3.292867660522461
Validation loss: 3.163318270401989
Epoch: 18| Step: 8
Training loss: 4.13663911819458
Validation loss: 3.169364273119316
Epoch: 18| Step: 9
Training loss: 3.6295652389526367
Validation loss: 3.1675250616004997
Epoch: 18| Step: 10
Training loss: 3.0033154487609863
Validation loss: 3.1521276921677073
Epoch: 18| Step: 11
Training loss: 3.597386360168457
Validation loss: 3.1642051120456176
Epoch: 18| Step: 12
Training loss: 3.913694381713867
Validation loss: 3.1459418252217684
Epoch: 18| Step: 13
Training loss: 3.4259605407714844
Validation loss: 3.150808277747614
Epoch: 18| Step: 14
Training loss: 4.5708160400390625
Validation loss: 3.1660358751420494
Epoch: 18| Step: 15
Training loss: 4.076213836669922
Validation loss: 3.1558754975847205
Epoch: 18| Step: 16
Training loss: 2.9634337425231934
Validation loss: 3.1561097729977945
Epoch: 18| Step: 17
Training loss: 4.703900337219238
Validation loss: 3.147996312422718
Epoch: 18| Step: 18
Training loss: 3.768975257873535
Validation loss: 3.1683884901966124
Epoch: 18| Step: 19
Training loss: 3.304731845855713
Validation loss: 3.161698459721298
Epoch: 18| Step: 20
Training loss: 3.4005656242370605
Validation loss: 3.1416737518722204
Epoch: 18| Step: 21
Training loss: 3.6037464141845703
Validation loss: 3.163537490282127
Epoch: 18| Step: 22
Training loss: 3.3783864974975586
Validation loss: 3.127192312007328
Epoch: 18| Step: 23
Training loss: 2.5397496223449707
Validation loss: 3.140237022646897
Epoch: 18| Step: 24
Training loss: 3.1451570987701416
Validation loss: 3.149699852620955
Epoch: 18| Step: 25
Training loss: 3.11867094039917
Validation loss: 3.130643168799311
Epoch: 18| Step: 26
Training loss: 3.837585687637329
Validation loss: 3.136160992889953
Epoch: 18| Step: 27
Training loss: 4.387117385864258
Validation loss: 3.1562158083744185
Epoch: 18| Step: 28
Training loss: 3.678786277770996
Validation loss: 3.1349317221332798
Epoch: 18| Step: 29
Training loss: 2.3144068717956543
Validation loss: 3.1458314039724335
Epoch: 18| Step: 30
Training loss: 3.7445969581604004
Validation loss: 3.145730546910128
Epoch: 18| Step: 31
Training loss: 3.6264641284942627
Validation loss: 3.148119778941861
Epoch: 18| Step: 32
Training loss: 1.9271111488342285
Validation loss: 3.12106598023888
Epoch: 18| Step: 33
Training loss: 3.1596169471740723
Validation loss: 3.1493685811543637
Epoch: 18| Step: 34
Training loss: 3.61767315864563
Validation loss: 3.137357758103515
Epoch: 18| Step: 35
Training loss: 3.0465054512023926
Validation loss: 3.1359465619642957
Epoch: 18| Step: 36
Training loss: 3.1512465476989746
Validation loss: 3.140065364700427
Epoch: 18| Step: 37
Training loss: 3.7587790489196777
Validation loss: 3.1301390138461436
Epoch: 18| Step: 38
Training loss: 3.462775230407715
Validation loss: 3.1379278786748435
Epoch: 18| Step: 39
Training loss: 4.29758358001709
Validation loss: 3.136885457759281
Epoch: 20| Step: 0
Training loss: 4.016947269439697
Validation loss: 3.1398654755928534
Epoch: 18| Step: 1
Training loss: 4.098113059997559
Validation loss: 3.1113759407894217
Epoch: 18| Step: 2
Training loss: 2.5876083374023438
Validation loss: 3.1332713631417253
Epoch: 18| Step: 3
Training loss: 2.614962100982666
Validation loss: 3.107068212769872
Epoch: 18| Step: 4
Training loss: 3.3110151290893555
Validation loss: 3.135786010207032
Epoch: 18| Step: 5
Training loss: 3.7882609367370605
Validation loss: 3.134220514366095
Epoch: 18| Step: 6
Training loss: 3.9401252269744873
Validation loss: 3.1323275686167986
Epoch: 18| Step: 7
Training loss: 3.8802270889282227
Validation loss: 3.1191340196046897
Epoch: 18| Step: 8
Training loss: 3.459174156188965
Validation loss: 3.142123013091602
Epoch: 18| Step: 9
Training loss: 3.5216033458709717
Validation loss: 3.133199594861312
Epoch: 18| Step: 10
Training loss: 3.96848464012146
Validation loss: 3.1144494238517266
Epoch: 18| Step: 11
Training loss: 5.26690149307251
Validation loss: 3.1402052117766237
Epoch: 18| Step: 12
Training loss: 3.251412868499756
Validation loss: 3.1257524318832286
Epoch: 18| Step: 13
Training loss: 3.3801870346069336
Validation loss: 3.1300411052841075
Epoch: 18| Step: 14
Training loss: 3.113283395767212
Validation loss: 3.115174461611741
Epoch: 18| Step: 15
Training loss: 2.292391061782837
Validation loss: 3.1265108139394857
Epoch: 18| Step: 16
Training loss: 4.258437156677246
Validation loss: 3.105107643621431
Epoch: 18| Step: 17
Training loss: 3.9115381240844727
Validation loss: 3.1133516538057395
Epoch: 18| Step: 18
Training loss: 4.92294454574585
Validation loss: 3.123070204000679
Epoch: 18| Step: 19
Training loss: 3.907963514328003
Validation loss: 3.1217952426388966
Epoch: 18| Step: 20
Training loss: 3.091534376144409
Validation loss: 3.10801448924936
Epoch: 18| Step: 21
Training loss: 2.4178221225738525
Validation loss: 3.1295114506920463
Epoch: 18| Step: 22
Training loss: 3.9233756065368652
Validation loss: 3.108951158660779
Epoch: 18| Step: 23
Training loss: 3.119875907897949
Validation loss: 3.097668736958675
Epoch: 18| Step: 24
Training loss: 3.3844399452209473
Validation loss: 3.1046150416779
Epoch: 18| Step: 25
Training loss: 3.794816732406616
Validation loss: 3.1058936556466192
Epoch: 18| Step: 26
Training loss: 3.9958014488220215
Validation loss: 3.1119570011715236
Epoch: 18| Step: 27
Training loss: 2.984182834625244
Validation loss: 3.1088152909450395
Epoch: 18| Step: 28
Training loss: 2.3655848503112793
Validation loss: 3.1056733920419815
Epoch: 18| Step: 29
Training loss: 3.006760358810425
Validation loss: 3.0919274649174096
Epoch: 18| Step: 30
Training loss: 4.9170098304748535
Validation loss: 3.1103317291616537
Epoch: 18| Step: 31
Training loss: 1.4655969142913818
Validation loss: 3.086213887166634
Epoch: 18| Step: 32
Training loss: 3.089571952819824
Validation loss: 3.1002545082311834
Epoch: 18| Step: 33
Training loss: 3.774367332458496
Validation loss: 3.1124169346239925
Epoch: 18| Step: 34
Training loss: 2.2827048301696777
Validation loss: 3.1044309602366935
Epoch: 18| Step: 35
Training loss: 3.897326946258545
Validation loss: 3.0801647446996014
Epoch: 18| Step: 36
Training loss: 2.9034829139709473
Validation loss: 3.0993340049716207
Epoch: 18| Step: 37
Training loss: 2.838925838470459
Validation loss: 3.108471836117532
Epoch: 18| Step: 38
Training loss: 4.809236526489258
Validation loss: 3.113163268823418
Epoch: 18| Step: 39
Training loss: 3.6399002075195312
Validation loss: 3.101218609501132
Epoch: 21| Step: 0
Training loss: 2.7070882320404053
Validation loss: 3.0863939086310297
Epoch: 18| Step: 1
Training loss: 4.767009258270264
Validation loss: 3.084803605251175
Epoch: 18| Step: 2
Training loss: 3.9898104667663574
Validation loss: 3.0970717719990573
Epoch: 18| Step: 3
Training loss: 4.839049816131592
Validation loss: 3.1022206896500624
Epoch: 18| Step: 4
Training loss: 4.458077430725098
Validation loss: 3.1022531917626908
Epoch: 18| Step: 5
Training loss: 2.8620996475219727
Validation loss: 3.096975763924688
Epoch: 18| Step: 6
Training loss: 2.855217456817627
Validation loss: 3.0850222453796605
Epoch: 18| Step: 7
Training loss: 2.5274181365966797
Validation loss: 3.104477132824685
Epoch: 18| Step: 8
Training loss: 2.918252944946289
Validation loss: 3.0991796743955544
Epoch: 18| Step: 9
Training loss: 3.2073469161987305
Validation loss: 3.102564532122166
Epoch: 18| Step: 10
Training loss: 2.793907403945923
Validation loss: 3.077925758824932
Epoch: 18| Step: 11
Training loss: 4.561148643493652
Validation loss: 3.071713617379717
Epoch: 18| Step: 12
Training loss: 3.7532095909118652
Validation loss: 3.096424775157901
Epoch: 18| Step: 13
Training loss: 3.301443576812744
Validation loss: 3.107403274920347
Epoch: 18| Step: 14
Training loss: 3.525773048400879
Validation loss: 3.0887519164051085
Epoch: 18| Step: 15
Training loss: 3.5591135025024414
Validation loss: 3.09313952837059
Epoch: 18| Step: 16
Training loss: 4.828497886657715
Validation loss: 3.0722427128030243
Epoch: 18| Step: 17
Training loss: 3.490668773651123
Validation loss: 3.0747003298011615
Epoch: 18| Step: 18
Training loss: 2.1076788902282715
Validation loss: 3.0924918068398672
Epoch: 18| Step: 19
Training loss: 3.016690254211426
Validation loss: 3.0633794335152604
Epoch: 18| Step: 20
Training loss: 4.142910480499268
Validation loss: 3.087485882875731
Epoch: 18| Step: 21
Training loss: 4.040897369384766
Validation loss: 3.0910735404748713
Epoch: 18| Step: 22
Training loss: 2.3311705589294434
Validation loss: 3.081012211257605
Epoch: 18| Step: 23
Training loss: 3.718125581741333
Validation loss: 3.078644665025121
Epoch: 18| Step: 24
Training loss: 3.2765567302703857
Validation loss: 3.0843165503989023
Epoch: 18| Step: 25
Training loss: 4.167142391204834
Validation loss: 3.0870835695335335
Epoch: 18| Step: 26
Training loss: 3.9058997631073
Validation loss: 3.062267015306212
Epoch: 18| Step: 27
Training loss: 3.9331295490264893
Validation loss: 3.079548988410895
Epoch: 18| Step: 28
Training loss: 4.4669904708862305
Validation loss: 3.090070362571332
Epoch: 18| Step: 29
Training loss: 2.6576385498046875
Validation loss: 3.078147001403699
Epoch: 18| Step: 30
Training loss: 4.679288387298584
Validation loss: 3.0829036115742414
Epoch: 18| Step: 31
Training loss: 3.8361005783081055
Validation loss: 3.07826712491701
Epoch: 18| Step: 32
Training loss: 2.3010072708129883
Validation loss: 3.060007042164425
Epoch: 18| Step: 33
Training loss: 2.0201663970947266
Validation loss: 3.0559122253664963
Epoch: 18| Step: 34
Training loss: 3.999241828918457
Validation loss: 3.0718870780450835
Epoch: 18| Step: 35
Training loss: 4.515985012054443
Validation loss: 3.060566775232768
Epoch: 18| Step: 36
Training loss: 2.202415943145752
Validation loss: 3.080638576754563
Epoch: 18| Step: 37
Training loss: 2.6836817264556885
Validation loss: 3.063552885604419
Epoch: 18| Step: 38
Training loss: 3.3030927181243896
Validation loss: 3.0607716848524356
Epoch: 18| Step: 39
Training loss: 2.828214645385742
Validation loss: 3.073987128923265
Epoch: 22| Step: 0
Training loss: 4.489530086517334
Validation loss: 3.073411881494865
Epoch: 18| Step: 1
Training loss: 3.4364066123962402
Validation loss: 3.0612809109173234
Epoch: 18| Step: 2
Training loss: 2.5675907135009766
Validation loss: 3.0681441104669367
Epoch: 18| Step: 3
Training loss: 2.9218175411224365
Validation loss: 3.0556035196180824
Epoch: 18| Step: 4
Training loss: 3.520134925842285
Validation loss: 3.0651290965594833
Epoch: 18| Step: 5
Training loss: 3.1465535163879395
Validation loss: 3.043726478549216
Epoch: 18| Step: 6
Training loss: 2.4610602855682373
Validation loss: 3.057621000482024
Epoch: 18| Step: 7
Training loss: 2.3541629314422607
Validation loss: 3.0586161441940196
Epoch: 18| Step: 8
Training loss: 4.135942459106445
Validation loss: 3.0701154230309906
Epoch: 18| Step: 9
Training loss: 3.5707788467407227
Validation loss: 3.0683197683567625
Epoch: 18| Step: 10
Training loss: 4.195243835449219
Validation loss: 3.067378083578974
Epoch: 18| Step: 11
Training loss: 2.5797863006591797
Validation loss: 3.0636034149060145
Epoch: 18| Step: 12
Training loss: 4.329507827758789
Validation loss: 3.0662487633794333
Epoch: 18| Step: 13
Training loss: 3.3985180854797363
Validation loss: 3.0471615722711136
Epoch: 18| Step: 14
Training loss: 3.53560209274292
Validation loss: 3.053230253912562
Epoch: 18| Step: 15
Training loss: 3.7343666553497314
Validation loss: 3.054594352090959
Epoch: 18| Step: 16
Training loss: 3.013066291809082
Validation loss: 3.0486453865929475
Epoch: 18| Step: 17
Training loss: 3.427886962890625
Validation loss: 3.044428363978434
Epoch: 18| Step: 18
Training loss: 2.211487293243408
Validation loss: 3.046559529338809
Epoch: 18| Step: 19
Training loss: 4.011682510375977
Validation loss: 3.060712189983121
Epoch: 18| Step: 20
Training loss: 3.232041358947754
Validation loss: 3.052884957773222
Epoch: 18| Step: 21
Training loss: 4.600205421447754
Validation loss: 3.058072252239255
Epoch: 18| Step: 22
Training loss: 3.4556193351745605
Validation loss: 3.0562284524492225
Epoch: 18| Step: 23
Training loss: 4.3198137283325195
Validation loss: 3.0602699646846854
Epoch: 18| Step: 24
Training loss: 2.533681869506836
Validation loss: 3.037191852391195
Epoch: 18| Step: 25
Training loss: 3.728832721710205
Validation loss: 3.0702227739979038
Epoch: 18| Step: 26
Training loss: 5.119043827056885
Validation loss: 3.064402811818843
Epoch: 18| Step: 27
Training loss: 3.53609037399292
Validation loss: 3.048143551504012
Epoch: 18| Step: 28
Training loss: 3.6541638374328613
Validation loss: 3.051906254651735
Epoch: 18| Step: 29
Training loss: 4.5984697341918945
Validation loss: 3.044812022353248
Epoch: 18| Step: 30
Training loss: 3.737433433532715
Validation loss: 3.0466037791409937
Epoch: 18| Step: 31
Training loss: 3.721950054168701
Validation loss: 3.0420831759198963
Epoch: 18| Step: 32
Training loss: 2.1216514110565186
Validation loss: 3.0488512052906502
Epoch: 18| Step: 33
Training loss: 4.031418800354004
Validation loss: 3.0450248049317503
Epoch: 18| Step: 34
Training loss: 3.1392242908477783
Validation loss: 3.0514912365151825
Epoch: 18| Step: 35
Training loss: 2.3840980529785156
Validation loss: 3.051483276079027
Epoch: 18| Step: 36
Training loss: 4.007171630859375
Validation loss: 3.048643415780376
Epoch: 18| Step: 37
Training loss: 3.3682072162628174
Validation loss: 3.0419879954495874
Epoch: 18| Step: 38
Training loss: 2.8180594444274902
Validation loss: 3.040217626009056
Epoch: 18| Step: 39
Training loss: 2.8363537788391113
Validation loss: 3.028451535341551
Epoch: 23| Step: 0
Training loss: 4.357666969299316
Validation loss: 3.0432735158385134
Epoch: 18| Step: 1
Training loss: 4.09174919128418
Validation loss: 3.0321317302237314
Epoch: 18| Step: 2
Training loss: 2.7424283027648926
Validation loss: 3.0286477195273203
Epoch: 18| Step: 3
Training loss: 3.1450600624084473
Validation loss: 3.025198665454233
Epoch: 18| Step: 4
Training loss: 2.9124839305877686
Validation loss: 3.0402440012787744
Epoch: 18| Step: 5
Training loss: 3.0438194274902344
Validation loss: 3.0444621816813515
Epoch: 18| Step: 6
Training loss: 2.253232002258301
Validation loss: 3.0226827628320927
Epoch: 18| Step: 7
Training loss: 3.470263957977295
Validation loss: 3.0433012084137623
Epoch: 18| Step: 8
Training loss: 3.5654549598693848
Validation loss: 3.014163264267736
Epoch: 18| Step: 9
Training loss: 3.419612407684326
Validation loss: 3.035580605911694
Epoch: 18| Step: 10
Training loss: 4.8566389083862305
Validation loss: 3.0371052309763518
Epoch: 18| Step: 11
Training loss: 3.5537853240966797
Validation loss: 3.0347800220516947
Epoch: 18| Step: 12
Training loss: 2.9775052070617676
Validation loss: 3.051064251138152
Epoch: 18| Step: 13
Training loss: 3.969897985458374
Validation loss: 3.0333804724027784
Epoch: 18| Step: 14
Training loss: 3.2744898796081543
Validation loss: 3.042543191703961
Epoch: 18| Step: 15
Training loss: 2.4826085567474365
Validation loss: 3.030736954092122
Epoch: 18| Step: 16
Training loss: 3.671393394470215
Validation loss: 3.005784195961712
Epoch: 18| Step: 17
Training loss: 3.6577014923095703
Validation loss: 3.035329738109232
Epoch: 18| Step: 18
Training loss: 3.8883306980133057
Validation loss: 3.005875822451475
Epoch: 18| Step: 19
Training loss: 4.366451263427734
Validation loss: 3.036369900051638
Epoch: 18| Step: 20
Training loss: 1.4261502027511597
Validation loss: 3.0316345022736693
Epoch: 18| Step: 21
Training loss: 3.042469024658203
Validation loss: 3.01732402739765
Epoch: 18| Step: 22
Training loss: 3.3771450519561768
Validation loss: 2.9949075661117224
Epoch: 18| Step: 23
Training loss: 3.8133370876312256
Validation loss: 3.0151058306796945
Epoch: 18| Step: 24
Training loss: 3.6126153469085693
Validation loss: 2.995967494498054
Epoch: 18| Step: 25
Training loss: 2.5415310859680176
Validation loss: 3.0258820262744273
Epoch: 18| Step: 26
Training loss: 4.0429534912109375
Validation loss: 3.006002961302833
Epoch: 18| Step: 27
Training loss: 3.832366466522217
Validation loss: 3.025771259403915
Epoch: 18| Step: 28
Training loss: 3.258315086364746
Validation loss: 3.0243064105081903
Epoch: 18| Step: 29
Training loss: 2.6804006099700928
Validation loss: 3.014949083328247
Epoch: 18| Step: 30
Training loss: 2.6861438751220703
Validation loss: 3.023565808646113
Epoch: 18| Step: 31
Training loss: 2.9710779190063477
Validation loss: 3.0288382605683033
Epoch: 18| Step: 32
Training loss: 3.5170509815216064
Validation loss: 3.0162121417711107
Epoch: 18| Step: 33
Training loss: 5.292398452758789
Validation loss: 3.0123830184662084
Epoch: 18| Step: 34
Training loss: 2.612198829650879
Validation loss: 3.0342332956602247
Epoch: 18| Step: 35
Training loss: 3.3632919788360596
Validation loss: 3.0112921694199817
Epoch: 18| Step: 36
Training loss: 4.18988037109375
Validation loss: 3.0051872558730968
Epoch: 18| Step: 37
Training loss: 2.6272754669189453
Validation loss: 2.998696920683058
Epoch: 18| Step: 38
Training loss: 4.403926372528076
Validation loss: 3.0026082512286068
Epoch: 18| Step: 39
Training loss: 4.1678996086120605
Validation loss: 3.004714250564575
Epoch: 24| Step: 0
Training loss: 2.4626777172088623
Validation loss: 3.005530973132566
Epoch: 18| Step: 1
Training loss: 3.990218162536621
Validation loss: 3.021489589334392
Epoch: 18| Step: 2
Training loss: 4.062522888183594
Validation loss: 2.9873094490106156
Epoch: 18| Step: 3
Training loss: 2.389237880706787
Validation loss: 3.0017733333779755
Epoch: 18| Step: 4
Training loss: 3.9136910438537598
Validation loss: 2.9843186989105006
Epoch: 18| Step: 5
Training loss: 3.779099225997925
Validation loss: 2.993268184524646
Epoch: 18| Step: 6
Training loss: 3.362687587738037
Validation loss: 3.0022027818419095
Epoch: 18| Step: 7
Training loss: 2.805757999420166
Validation loss: 3.000505943950132
Epoch: 18| Step: 8
Training loss: 4.524389266967773
Validation loss: 3.007374207750499
Epoch: 18| Step: 9
Training loss: 2.5986509323120117
Validation loss: 2.9929490775513132
Epoch: 18| Step: 10
Training loss: 4.35099458694458
Validation loss: 2.988972135584989
Epoch: 18| Step: 11
Training loss: 3.458751678466797
Validation loss: 3.008407694830311
Epoch: 18| Step: 12
Training loss: 3.614570140838623
Validation loss: 2.9998575534751946
Epoch: 18| Step: 13
Training loss: 3.6729695796966553
Validation loss: 2.969382829803357
Epoch: 18| Step: 14
Training loss: 3.3746955394744873
Validation loss: 3.0007511248691476
Epoch: 18| Step: 15
Training loss: 2.4962339401245117
Validation loss: 2.9924361757237277
Epoch: 18| Step: 16
Training loss: 3.3350276947021484
Validation loss: 3.004610818067043
Epoch: 18| Step: 17
Training loss: 3.311941623687744
Validation loss: 2.990350417953601
Epoch: 18| Step: 18
Training loss: 3.623263359069824
Validation loss: 2.999534022036216
Epoch: 18| Step: 19
Training loss: 2.374753475189209
Validation loss: 3.0030565287569444
Epoch: 18| Step: 20
Training loss: 2.9591586589813232
Validation loss: 3.0026680857157535
Epoch: 18| Step: 21
Training loss: 2.632986307144165
Validation loss: 3.006457052856898
Epoch: 18| Step: 22
Training loss: 3.752790689468384
Validation loss: 2.984213914802606
Epoch: 18| Step: 23
Training loss: 3.814680576324463
Validation loss: 3.005852003749326
Epoch: 18| Step: 24
Training loss: 4.866076469421387
Validation loss: 3.0036719034044004
Epoch: 18| Step: 25
Training loss: 4.257815837860107
Validation loss: 2.995065051017048
Epoch: 18| Step: 26
Training loss: 2.6171975135803223
Validation loss: 2.982919696423647
Epoch: 18| Step: 27
Training loss: 4.108800888061523
Validation loss: 2.985478883166965
Epoch: 18| Step: 28
Training loss: 3.852553367614746
Validation loss: 2.986578759529608
Epoch: 18| Step: 29
Training loss: 4.250385761260986
Validation loss: 2.994144967991671
Epoch: 18| Step: 30
Training loss: 2.91465425491333
Validation loss: 2.985965819667569
Epoch: 18| Step: 31
Training loss: 2.133765935897827
Validation loss: 2.978032630124538
Epoch: 18| Step: 32
Training loss: 3.8231847286224365
Validation loss: 2.978622410794814
Epoch: 18| Step: 33
Training loss: 2.096656084060669
Validation loss: 2.976842048356859
Epoch: 18| Step: 34
Training loss: 4.046963214874268
Validation loss: 2.999502465021696
Epoch: 18| Step: 35
Training loss: 4.0586323738098145
Validation loss: 2.9875453303186155
Epoch: 18| Step: 36
Training loss: 1.273101806640625
Validation loss: 2.9645993212144153
Epoch: 18| Step: 37
Training loss: 4.249266624450684
Validation loss: 2.974574460400094
Epoch: 18| Step: 38
Training loss: 3.1649413108825684
Validation loss: 2.970360574104803
Epoch: 18| Step: 39
Training loss: 3.2354063987731934
Validation loss: 2.9870522262381134
Epoch: 25| Step: 0
Training loss: 2.5062496662139893
Validation loss: 2.96833006598109
Epoch: 18| Step: 1
Training loss: 2.684323310852051
Validation loss: 2.9869019968046557
Epoch: 18| Step: 2
Training loss: 2.0102572441101074
Validation loss: 2.97381313241643
Epoch: 18| Step: 3
Training loss: 4.244201183319092
Validation loss: 2.9736327173040924
Epoch: 18| Step: 4
Training loss: 3.097944498062134
Validation loss: 2.972243123774906
Epoch: 18| Step: 5
Training loss: 2.935615062713623
Validation loss: 2.985283978551412
Epoch: 18| Step: 6
Training loss: 3.6670045852661133
Validation loss: 2.9756151772231507
Epoch: 18| Step: 7
Training loss: 4.06117057800293
Validation loss: 2.9710610290225463
Epoch: 18| Step: 8
Training loss: 2.738734722137451
Validation loss: 2.9697545020700358
Epoch: 18| Step: 9
Training loss: 3.8370630741119385
Validation loss: 2.972549856995507
Epoch: 18| Step: 10
Training loss: 3.088921070098877
Validation loss: 2.964369972832769
Epoch: 18| Step: 11
Training loss: 4.635472774505615
Validation loss: 2.981393251487677
Epoch: 18| Step: 12
Training loss: 2.067037582397461
Validation loss: 2.962948070155631
Epoch: 18| Step: 13
Training loss: 2.977066993713379
Validation loss: 2.9797322132604585
Epoch: 18| Step: 14
Training loss: 3.2954626083374023
Validation loss: 2.9696341195552467
Epoch: 18| Step: 15
Training loss: 4.1236186027526855
Validation loss: 2.980623782109871
Epoch: 18| Step: 16
Training loss: 3.616323471069336
Validation loss: 2.971954687036199
Epoch: 18| Step: 17
Training loss: 4.6790666580200195
Validation loss: 2.935458968869216
Epoch: 18| Step: 18
Training loss: 2.505183696746826
Validation loss: 2.965186577049091
Epoch: 18| Step: 19
Training loss: 4.130561828613281
Validation loss: 2.9685080188641444
Epoch: 18| Step: 20
Training loss: 1.3457646369934082
Validation loss: 2.9557933292800573
Epoch: 18| Step: 21
Training loss: 5.249791622161865
Validation loss: 2.949191455360797
Epoch: 18| Step: 22
Training loss: 2.7037534713745117
Validation loss: 2.973609510943186
Epoch: 18| Step: 23
Training loss: 4.117053031921387
Validation loss: 2.9754888513963
Epoch: 18| Step: 24
Training loss: 3.234757661819458
Validation loss: 2.9502999834019503
Epoch: 18| Step: 25
Training loss: 3.4522972106933594
Validation loss: 2.953944087886124
Epoch: 18| Step: 26
Training loss: 3.4163477420806885
Validation loss: 2.9406667904888124
Epoch: 18| Step: 27
Training loss: 2.994202136993408
Validation loss: 2.955366505993356
Epoch: 18| Step: 28
Training loss: 3.9402620792388916
Validation loss: 2.9465689933557306
Epoch: 18| Step: 29
Training loss: 3.5895371437072754
Validation loss: 2.9612064327267436
Epoch: 18| Step: 30
Training loss: 2.6962151527404785
Validation loss: 2.9535398706257774
Epoch: 18| Step: 31
Training loss: 3.906684398651123
Validation loss: 2.9661915456648353
Epoch: 18| Step: 32
Training loss: 4.932566165924072
Validation loss: 2.958057428435456
Epoch: 18| Step: 33
Training loss: 2.5738282203674316
Validation loss: 2.951254829228353
Epoch: 18| Step: 34
Training loss: 4.4063215255737305
Validation loss: 2.950358136952352
Epoch: 18| Step: 35
Training loss: 3.5205235481262207
Validation loss: 2.9499687016439093
Epoch: 18| Step: 36
Training loss: 2.005599021911621
Validation loss: 2.9568985421880543
Epoch: 18| Step: 37
Training loss: 4.070382118225098
Validation loss: 2.9424386110237175
Epoch: 18| Step: 38
Training loss: 3.4954395294189453
Validation loss: 2.941852432360752
Epoch: 18| Step: 39
Training loss: 3.147210121154785
Validation loss: 2.935656602434117
Epoch: 26| Step: 0
Training loss: 3.743274688720703
Validation loss: 2.9506636712190915
Epoch: 18| Step: 1
Training loss: 2.2277305126190186
Validation loss: 2.942738016732305
Epoch: 18| Step: 2
Training loss: 4.249979019165039
Validation loss: 2.941445928683384
Epoch: 18| Step: 3
Training loss: 3.330120801925659
Validation loss: 2.9437531584458387
Epoch: 18| Step: 4
Training loss: 1.932185411453247
Validation loss: 2.930949796017983
Epoch: 18| Step: 5
Training loss: 2.0954859256744385
Validation loss: 2.939142278630099
Epoch: 18| Step: 6
Training loss: 4.150801181793213
Validation loss: 2.9477006136942254
Epoch: 18| Step: 7
Training loss: 3.14583158493042
Validation loss: 2.9460552133244575
Epoch: 18| Step: 8
Training loss: 2.319077491760254
Validation loss: 2.932767231687367
Epoch: 18| Step: 9
Training loss: 3.506159782409668
Validation loss: 2.9309502514146213
Epoch: 18| Step: 10
Training loss: 3.2531814575195312
Validation loss: 2.9211824008886764
Epoch: 18| Step: 11
Training loss: 4.276710510253906
Validation loss: 2.9363893304797384
Epoch: 18| Step: 12
Training loss: 3.1980533599853516
Validation loss: 2.9326975328459155
Epoch: 18| Step: 13
Training loss: 3.3337907791137695
Validation loss: 2.942081077493352
Epoch: 18| Step: 14
Training loss: 3.1390881538391113
Validation loss: 2.938179825707305
Epoch: 18| Step: 15
Training loss: 3.6391005516052246
Validation loss: 2.929729976242395
Epoch: 18| Step: 16
Training loss: 2.71903133392334
Validation loss: 2.937081659440514
Epoch: 18| Step: 17
Training loss: 3.7803354263305664
Validation loss: 2.9489746882761123
Epoch: 18| Step: 18
Training loss: 4.126162528991699
Validation loss: 2.9150145414064257
Epoch: 18| Step: 19
Training loss: 2.592639446258545
Validation loss: 2.942038541217502
Epoch: 18| Step: 20
Training loss: 3.831613540649414
Validation loss: 2.942157210205956
Epoch: 18| Step: 21
Training loss: 4.164066791534424
Validation loss: 2.9448455477790008
Epoch: 18| Step: 22
Training loss: 3.992417812347412
Validation loss: 2.922223501925846
Epoch: 18| Step: 23
Training loss: 2.4188308715820312
Validation loss: 2.9202711839470075
Epoch: 18| Step: 24
Training loss: 4.840998649597168
Validation loss: 2.912725600407278
Epoch: 18| Step: 25
Training loss: 4.152498245239258
Validation loss: 2.928392108395803
Epoch: 18| Step: 26
Training loss: 3.549631118774414
Validation loss: 2.9301009126704374
Epoch: 18| Step: 27
Training loss: 2.9998435974121094
Validation loss: 2.942384779882088
Epoch: 18| Step: 28
Training loss: 5.727898597717285
Validation loss: 2.9317710811285664
Epoch: 18| Step: 29
Training loss: 2.2626519203186035
Validation loss: 2.934924082790347
Epoch: 18| Step: 30
Training loss: 3.7679450511932373
Validation loss: 2.937181076557516
Epoch: 18| Step: 31
Training loss: 3.358513832092285
Validation loss: 2.9171763667099766
Epoch: 18| Step: 32
Training loss: 1.9648752212524414
Validation loss: 2.9215698379406825
Epoch: 18| Step: 33
Training loss: 3.4411938190460205
Validation loss: 2.9267091253678577
Epoch: 18| Step: 34
Training loss: 3.509519338607788
Validation loss: 2.9306289892402484
Epoch: 18| Step: 35
Training loss: 3.245452880859375
Validation loss: 2.9281192511963328
Epoch: 18| Step: 36
Training loss: 3.0010247230529785
Validation loss: 2.934818736083216
Epoch: 18| Step: 37
Training loss: 2.627157211303711
Validation loss: 2.9400548488973715
Epoch: 18| Step: 38
Training loss: 2.5708811283111572
Validation loss: 2.9345623880839176
Epoch: 18| Step: 39
Training loss: 3.584620475769043
Validation loss: 2.9200229061593252
Epoch: 27| Step: 0
Training loss: 3.4083657264709473
Validation loss: 2.9067075106737423
Epoch: 18| Step: 1
Training loss: 3.2471041679382324
Validation loss: 2.9196197780773794
Epoch: 18| Step: 2
Training loss: 2.7682533264160156
Validation loss: 2.9180246351434174
Epoch: 18| Step: 3
Training loss: 3.0423550605773926
Validation loss: 2.921403068432705
Epoch: 18| Step: 4
Training loss: 2.534156560897827
Validation loss: 2.9084907418532335
Epoch: 18| Step: 5
Training loss: 4.323204517364502
Validation loss: 2.917298788647
Epoch: 18| Step: 6
Training loss: 2.790717363357544
Validation loss: 2.9167833298230343
Epoch: 18| Step: 7
Training loss: 3.5308284759521484
Validation loss: 2.914550762382343
Epoch: 18| Step: 8
Training loss: 3.6748077869415283
Validation loss: 2.9164624008343374
Epoch: 18| Step: 9
Training loss: 5.087538242340088
Validation loss: 2.9169230504001646
Epoch: 18| Step: 10
Training loss: 4.294645309448242
Validation loss: 2.9153391079936952
Epoch: 18| Step: 11
Training loss: 3.0731682777404785
Validation loss: 2.9008368330893757
Epoch: 18| Step: 12
Training loss: 3.058907985687256
Validation loss: 2.909684755819307
Epoch: 18| Step: 13
Training loss: 3.8281333446502686
Validation loss: 2.9185514244244253
Epoch: 18| Step: 14
Training loss: 1.316023349761963
Validation loss: 2.9170482981976846
Epoch: 18| Step: 15
Training loss: 3.6740994453430176
Validation loss: 2.9079519758979195
Epoch: 18| Step: 16
Training loss: 2.6029858589172363
Validation loss: 2.9340216701836894
Epoch: 18| Step: 17
Training loss: 3.6085593700408936
Validation loss: 2.9173536403573674
Epoch: 18| Step: 18
Training loss: 3.577402114868164
Validation loss: 2.9118464010224927
Epoch: 18| Step: 19
Training loss: 3.471259593963623
Validation loss: 2.905219632086994
Epoch: 18| Step: 20
Training loss: 3.305595874786377
Validation loss: 2.9130445538664893
Epoch: 18| Step: 21
Training loss: 3.101785182952881
Validation loss: 2.9098039462412
Epoch: 18| Step: 22
Training loss: 3.3362951278686523
Validation loss: 2.90015831268091
Epoch: 18| Step: 23
Training loss: 3.5082263946533203
Validation loss: 2.9127148621373897
Epoch: 18| Step: 24
Training loss: 3.8156204223632812
Validation loss: 2.8991494367448545
Epoch: 18| Step: 25
Training loss: 2.849083662033081
Validation loss: 2.9012514532898828
Epoch: 18| Step: 26
Training loss: 2.408357620239258
Validation loss: 2.9111685341210674
Epoch: 18| Step: 27
Training loss: 3.378434181213379
Validation loss: 2.8762394026886646
Epoch: 18| Step: 28
Training loss: 2.7752203941345215
Validation loss: 2.900485651098567
Epoch: 18| Step: 29
Training loss: 4.518831253051758
Validation loss: 2.895377120525717
Epoch: 18| Step: 30
Training loss: 2.469688892364502
Validation loss: 2.8978495366281742
Epoch: 18| Step: 31
Training loss: 3.2704617977142334
Validation loss: 2.9163760418514553
Epoch: 18| Step: 32
Training loss: 3.5152132511138916
Validation loss: 2.9047220696648246
Epoch: 18| Step: 33
Training loss: 3.1455960273742676
Validation loss: 2.898237494255999
Epoch: 18| Step: 34
Training loss: 2.707521677017212
Validation loss: 2.9046469077789525
Epoch: 18| Step: 35
Training loss: 3.355271816253662
Validation loss: 2.902705228585991
Epoch: 18| Step: 36
Training loss: 4.107516288757324
Validation loss: 2.8933606679491004
Epoch: 18| Step: 37
Training loss: 3.957817554473877
Validation loss: 2.888927895388157
Epoch: 18| Step: 38
Training loss: 4.444941520690918
Validation loss: 2.8939392257937424
Epoch: 18| Step: 39
Training loss: 2.6486263275146484
Validation loss: 2.8966652249260774
Epoch: 28| Step: 0
Training loss: 3.9716756343841553
Validation loss: 2.8986511727888806
Epoch: 18| Step: 1
Training loss: 2.527320384979248
Validation loss: 2.9083382500161368
Epoch: 18| Step: 2
Training loss: 4.64113187789917
Validation loss: 2.9063893342189653
Epoch: 18| Step: 3
Training loss: 2.581569194793701
Validation loss: 2.8832858226282134
Epoch: 18| Step: 4
Training loss: 3.682852268218994
Validation loss: 2.892272592448502
Epoch: 18| Step: 5
Training loss: 2.565209150314331
Validation loss: 2.8944860345168077
Epoch: 18| Step: 6
Training loss: 2.448533058166504
Validation loss: 2.89281144931162
Epoch: 18| Step: 7
Training loss: 2.5741171836853027
Validation loss: 2.894028967233013
Epoch: 18| Step: 8
Training loss: 2.777853012084961
Validation loss: 2.893308118092928
Epoch: 18| Step: 9
Training loss: 3.37487530708313
Validation loss: 2.863567813694906
Epoch: 18| Step: 10
Training loss: 3.512859344482422
Validation loss: 2.882727262785109
Epoch: 18| Step: 11
Training loss: 3.1027798652648926
Validation loss: 2.882574952763619
Epoch: 18| Step: 12
Training loss: 3.805880308151245
Validation loss: 2.8897038106438067
Epoch: 18| Step: 13
Training loss: 4.325277328491211
Validation loss: 2.8974010738537466
Epoch: 18| Step: 14
Training loss: 3.2010273933410645
Validation loss: 2.9068057742907847
Epoch: 18| Step: 15
Training loss: 3.325124740600586
Validation loss: 2.8919960148900534
Epoch: 18| Step: 16
Training loss: 3.2435684204101562
Validation loss: 2.861385455234445
Epoch: 18| Step: 17
Training loss: 2.470280170440674
Validation loss: 2.8901812755804266
Epoch: 18| Step: 18
Training loss: 4.224063873291016
Validation loss: 2.8886748003445084
Epoch: 18| Step: 19
Training loss: 4.053674697875977
Validation loss: 2.885334699273967
Epoch: 18| Step: 20
Training loss: 3.017214775085449
Validation loss: 2.9007568496594325
Epoch: 18| Step: 21
Training loss: 3.2483019828796387
Validation loss: 2.883035474543949
Epoch: 18| Step: 22
Training loss: 3.2958145141601562
Validation loss: 2.8867549081500488
Epoch: 18| Step: 23
Training loss: 3.931819200515747
Validation loss: 2.8887847704853087
Epoch: 18| Step: 24
Training loss: 3.086894989013672
Validation loss: 2.8733471057397857
Epoch: 18| Step: 25
Training loss: 3.1346895694732666
Validation loss: 2.8829977083549223
Epoch: 18| Step: 26
Training loss: 2.3920326232910156
Validation loss: 2.903020448821912
Epoch: 18| Step: 27
Training loss: 3.0568137168884277
Validation loss: 2.8708851328856655
Epoch: 18| Step: 28
Training loss: 2.051408290863037
Validation loss: 2.863099480704438
Epoch: 18| Step: 29
Training loss: 2.599062919616699
Validation loss: 2.8942914094856316
Epoch: 18| Step: 30
Training loss: 3.6757755279541016
Validation loss: 2.88045429497314
Epoch: 18| Step: 31
Training loss: 3.3171586990356445
Validation loss: 2.8747812329436377
Epoch: 18| Step: 32
Training loss: 3.447000026702881
Validation loss: 2.876429622979473
Epoch: 18| Step: 33
Training loss: 5.402586936950684
Validation loss: 2.8669315726636984
Epoch: 18| Step: 34
Training loss: 2.71000337600708
Validation loss: 2.8915443043057008
Epoch: 18| Step: 35
Training loss: 4.154026985168457
Validation loss: 2.8772714189488253
Epoch: 18| Step: 36
Training loss: 2.133314371109009
Validation loss: 2.8777003335438187
Epoch: 18| Step: 37
Training loss: 3.895677089691162
Validation loss: 2.871834705201842
Epoch: 18| Step: 38
Training loss: 4.7080888748168945
Validation loss: 2.8578640385497387
Epoch: 18| Step: 39
Training loss: 2.8711414337158203
Validation loss: 2.8911940759892087
Epoch: 29| Step: 0
Training loss: 1.9780882596969604
Validation loss: 2.872192139248196
Epoch: 18| Step: 1
Training loss: 3.5778279304504395
Validation loss: 2.880139832873996
Epoch: 18| Step: 2
Training loss: 2.0313994884490967
Validation loss: 2.859430694751602
Epoch: 18| Step: 3
Training loss: 4.106682777404785
Validation loss: 2.8680281133102854
Epoch: 18| Step: 4
Training loss: 2.895204544067383
Validation loss: 2.876194778963816
Epoch: 18| Step: 5
Training loss: 3.3029329776763916
Validation loss: 2.8802490251527417
Epoch: 18| Step: 6
Training loss: 2.4686522483825684
Validation loss: 2.8764763101399375
Epoch: 18| Step: 7
Training loss: 2.865765333175659
Validation loss: 2.856562558266756
Epoch: 18| Step: 8
Training loss: 3.858867883682251
Validation loss: 2.879682458561959
Epoch: 18| Step: 9
Training loss: 2.5662450790405273
Validation loss: 2.865985849778429
Epoch: 18| Step: 10
Training loss: 2.674694776535034
Validation loss: 2.849603776451495
Epoch: 18| Step: 11
Training loss: 3.3204405307769775
Validation loss: 2.86508877843404
Epoch: 18| Step: 12
Training loss: 4.748270034790039
Validation loss: 2.8735058273342875
Epoch: 18| Step: 13
Training loss: 4.6592512130737305
Validation loss: 2.8724688728936285
Epoch: 18| Step: 14
Training loss: 3.3770055770874023
Validation loss: 2.8670907466531657
Epoch: 18| Step: 15
Training loss: 5.054516792297363
Validation loss: 2.8532894746862727
Epoch: 18| Step: 16
Training loss: 2.5994341373443604
Validation loss: 2.8677411525369547
Epoch: 18| Step: 17
Training loss: 2.8453316688537598
Validation loss: 2.866021432464929
Epoch: 18| Step: 18
Training loss: 2.837775230407715
Validation loss: 2.873809898499962
Epoch: 18| Step: 19
Training loss: 2.2776105403900146
Validation loss: 2.8614650904703485
Epoch: 18| Step: 20
Training loss: 3.2204360961914062
Validation loss: 2.8476125898121074
Epoch: 18| Step: 21
Training loss: 3.0286176204681396
Validation loss: 2.865139583889529
Epoch: 18| Step: 22
Training loss: 2.6313562393188477
Validation loss: 2.872979736156601
Epoch: 18| Step: 23
Training loss: 3.074723720550537
Validation loss: 2.8565479877183764
Epoch: 18| Step: 24
Training loss: 3.700085163116455
Validation loss: 2.860903166180892
Epoch: 18| Step: 25
Training loss: 4.149325847625732
Validation loss: 2.8497019362964218
Epoch: 18| Step: 26
Training loss: 2.5404000282287598
Validation loss: 2.8412050609108355
Epoch: 18| Step: 27
Training loss: 3.7390263080596924
Validation loss: 2.8560123666584922
Epoch: 18| Step: 28
Training loss: 4.493380546569824
Validation loss: 2.847620001799769
Epoch: 18| Step: 29
Training loss: 2.9206180572509766
Validation loss: 2.8628103149880606
Epoch: 18| Step: 30
Training loss: 3.1484060287475586
Validation loss: 2.842322171163216
Epoch: 18| Step: 31
Training loss: 3.9487197399139404
Validation loss: 2.862207304659507
Epoch: 18| Step: 32
Training loss: 2.390643358230591
Validation loss: 2.859330735618262
Epoch: 18| Step: 33
Training loss: 2.7298879623413086
Validation loss: 2.849693182561037
Epoch: 18| Step: 34
Training loss: 3.5040488243103027
Validation loss: 2.860678876904275
Epoch: 18| Step: 35
Training loss: 4.748790264129639
Validation loss: 2.85882979674305
Epoch: 18| Step: 36
Training loss: 4.108439922332764
Validation loss: 2.8555458260954714
Epoch: 18| Step: 37
Training loss: 2.1804137229919434
Validation loss: 2.861045355419461
Epoch: 18| Step: 38
Training loss: 3.374279022216797
Validation loss: 2.841204435705281
Epoch: 18| Step: 39
Training loss: 4.342310905456543
Validation loss: 2.861686998134037
Epoch: 30| Step: 0
Training loss: 3.81673264503479
Validation loss: 2.847964797946189
Epoch: 18| Step: 1
Training loss: 2.893293857574463
Validation loss: 2.862089517305223
Epoch: 18| Step: 2
Training loss: 3.2485575675964355
Validation loss: 2.8675722972952205
Epoch: 18| Step: 3
Training loss: 3.0328664779663086
Validation loss: 2.8404001726521004
Epoch: 18| Step: 4
Training loss: 2.45857834815979
Validation loss: 2.8473984543368114
Epoch: 18| Step: 5
Training loss: 3.225419044494629
Validation loss: 2.846423159400336
Epoch: 18| Step: 6
Training loss: 3.7585227489471436
Validation loss: 2.82465108864599
Epoch: 18| Step: 7
Training loss: 2.8469748497009277
Validation loss: 2.8526508482240085
Epoch: 18| Step: 8
Training loss: 2.8897159099578857
Validation loss: 2.848760273816774
Epoch: 18| Step: 9
Training loss: 3.7488274574279785
Validation loss: 2.850421634509409
Epoch: 18| Step: 10
Training loss: 3.8926918506622314
Validation loss: 2.832516670227051
Epoch: 18| Step: 11
Training loss: 3.270484209060669
Validation loss: 2.858244889074092
Epoch: 18| Step: 12
Training loss: 3.783383369445801
Validation loss: 2.860195907757437
Epoch: 18| Step: 13
Training loss: 3.7247250080108643
Validation loss: 2.8424043672547925
Epoch: 18| Step: 14
Training loss: 3.8474090099334717
Validation loss: 2.84704311288518
Epoch: 18| Step: 15
Training loss: 3.0505504608154297
Validation loss: 2.8455519676208496
Epoch: 18| Step: 16
Training loss: 2.8236587047576904
Validation loss: 2.845331361825518
Epoch: 18| Step: 17
Training loss: 4.654592514038086
Validation loss: 2.861223548436336
Epoch: 18| Step: 18
Training loss: 3.664179563522339
Validation loss: 2.8442500383733846
Epoch: 18| Step: 19
Training loss: 2.410858631134033
Validation loss: 2.845862006111968
Epoch: 18| Step: 20
Training loss: 3.015164613723755
Validation loss: 2.850971683323812
Epoch: 18| Step: 21
Training loss: 2.9718899726867676
Validation loss: 2.8435088370343764
Epoch: 18| Step: 22
Training loss: 3.541151523590088
Validation loss: 2.834297384289529
Epoch: 18| Step: 23
Training loss: 2.536318063735962
Validation loss: 2.84829399053999
Epoch: 18| Step: 24
Training loss: 3.9047231674194336
Validation loss: 2.848609325697096
Epoch: 18| Step: 25
Training loss: 2.5473012924194336
Validation loss: 2.854124091512008
Epoch: 18| Step: 26
Training loss: 4.050948143005371
Validation loss: 2.8338501710685895
Epoch: 18| Step: 27
Training loss: 3.9512035846710205
Validation loss: 2.860364025445293
Epoch: 18| Step: 28
Training loss: 3.171476364135742
Validation loss: 2.8390188097096174
Epoch: 18| Step: 29
Training loss: 3.082828998565674
Validation loss: 2.8503053951606474
Epoch: 18| Step: 30
Training loss: 4.160414695739746
Validation loss: 2.8188724517822266
Epoch: 18| Step: 31
Training loss: 2.5057008266448975
Validation loss: 2.840181023096867
Epoch: 18| Step: 32
Training loss: 2.457549571990967
Validation loss: 2.826947565559003
Epoch: 18| Step: 33
Training loss: 3.0613927841186523
Validation loss: 2.8448887831873173
Epoch: 18| Step: 34
Training loss: 2.4805803298950195
Validation loss: 2.8511128339836067
Epoch: 18| Step: 35
Training loss: 3.4312610626220703
Validation loss: 2.836885589489834
Epoch: 18| Step: 36
Training loss: 3.92319393157959
Validation loss: 2.8283645677909575
Epoch: 18| Step: 37
Training loss: 3.0739190578460693
Validation loss: 2.8168956272893673
Epoch: 18| Step: 38
Training loss: 2.9473354816436768
Validation loss: 2.825816005253963
Epoch: 18| Step: 39
Training loss: 3.380796432495117
Validation loss: 2.828225271307307
Epoch: 31| Step: 0
Training loss: 2.9630680084228516
Validation loss: 2.8299432594141516
Epoch: 18| Step: 1
Training loss: 3.1181254386901855
Validation loss: 2.8207207274951522
Epoch: 18| Step: 2
Training loss: 3.6700730323791504
Validation loss: 2.834190080491759
Epoch: 18| Step: 3
Training loss: 2.812511444091797
Validation loss: 2.8324508684144605
Epoch: 18| Step: 4
Training loss: 2.897674083709717
Validation loss: 2.8190149454761753
Epoch: 18| Step: 5
Training loss: 4.475234031677246
Validation loss: 2.8221817977136845
Epoch: 18| Step: 6
Training loss: 3.7844738960266113
Validation loss: 2.8408328663530966
Epoch: 18| Step: 7
Training loss: 2.680105447769165
Validation loss: 2.828195294030279
Epoch: 18| Step: 8
Training loss: 4.0954999923706055
Validation loss: 2.8308202534270803
Epoch: 18| Step: 9
Training loss: 2.8396823406219482
Validation loss: 2.8448101222086297
Epoch: 18| Step: 10
Training loss: 3.5008316040039062
Validation loss: 2.8343717983300736
Epoch: 18| Step: 11
Training loss: 4.3834333419799805
Validation loss: 2.82919020446942
Epoch: 18| Step: 12
Training loss: 3.0714921951293945
Validation loss: 2.817919900949053
Epoch: 18| Step: 13
Training loss: 3.050792694091797
Validation loss: 2.8232192470015383
Epoch: 18| Step: 14
Training loss: 4.048426151275635
Validation loss: 2.8180242956971093
Epoch: 18| Step: 15
Training loss: 4.1556596755981445
Validation loss: 2.8201586222477095
Epoch: 18| Step: 16
Training loss: 4.392437934875488
Validation loss: 2.8127590769486464
Epoch: 18| Step: 17
Training loss: 3.171469211578369
Validation loss: 2.7984321717735674
Epoch: 18| Step: 18
Training loss: 1.589003562927246
Validation loss: 2.8358369662607315
Epoch: 18| Step: 19
Training loss: 2.333474636077881
Validation loss: 2.823872456447684
Epoch: 18| Step: 20
Training loss: 2.766298770904541
Validation loss: 2.7944945208460306
Epoch: 18| Step: 21
Training loss: 3.0034537315368652
Validation loss: 2.8274953210954186
Epoch: 18| Step: 22
Training loss: 3.2887020111083984
Validation loss: 2.8321716682516413
Epoch: 18| Step: 23
Training loss: 4.945215225219727
Validation loss: 2.828915695492312
Epoch: 18| Step: 24
Training loss: 1.9405865669250488
Validation loss: 2.8293298817367005
Epoch: 18| Step: 25
Training loss: 2.763333797454834
Validation loss: 2.792973895724729
Epoch: 18| Step: 26
Training loss: 2.542370319366455
Validation loss: 2.819275149338537
Epoch: 18| Step: 27
Training loss: 2.970492362976074
Validation loss: 2.772631271279973
Epoch: 18| Step: 28
Training loss: 2.505466938018799
Validation loss: 2.8092852736548553
Epoch: 18| Step: 29
Training loss: 2.5554699897766113
Validation loss: 2.8398467756861407
Epoch: 18| Step: 30
Training loss: 3.714674949645996
Validation loss: 2.804942502821092
Epoch: 18| Step: 31
Training loss: 3.4631032943725586
Validation loss: 2.8318995400298412
Epoch: 18| Step: 32
Training loss: 4.353702068328857
Validation loss: 2.8288761257267683
Epoch: 18| Step: 33
Training loss: 3.9003007411956787
Validation loss: 2.8210901030533604
Epoch: 18| Step: 34
Training loss: 4.476489067077637
Validation loss: 2.8283219388920626
Epoch: 18| Step: 35
Training loss: 3.8393802642822266
Validation loss: 2.793453574180603
Epoch: 18| Step: 36
Training loss: 3.4019103050231934
Validation loss: 2.8209716519005865
Epoch: 18| Step: 37
Training loss: 2.314347982406616
Validation loss: 2.7971325418074353
Epoch: 18| Step: 38
Training loss: 1.7148247957229614
Validation loss: 2.826108116040127
Epoch: 18| Step: 39
Training loss: 3.660090923309326
Validation loss: 2.799139830705931
Epoch: 32| Step: 0
Training loss: 3.594780921936035
Validation loss: 2.7934906259715127
Epoch: 18| Step: 1
Training loss: 2.9787991046905518
Validation loss: 2.8062574057270298
Epoch: 18| Step: 2
Training loss: 3.169020652770996
Validation loss: 2.8294595214102767
Epoch: 18| Step: 3
Training loss: 3.470025062561035
Validation loss: 2.8025053387923204
Epoch: 18| Step: 4
Training loss: 3.7687501907348633
Validation loss: 2.7940075414643872
Epoch: 18| Step: 5
Training loss: 3.1859166622161865
Validation loss: 2.812473215645166
Epoch: 18| Step: 6
Training loss: 2.784449577331543
Validation loss: 2.8173035511867606
Epoch: 18| Step: 7
Training loss: 3.8225815296173096
Validation loss: 2.8069878121931775
Epoch: 18| Step: 8
Training loss: 3.3764777183532715
Validation loss: 2.792987296049543
Epoch: 18| Step: 9
Training loss: 2.151838541030884
Validation loss: 2.791493146539592
Epoch: 18| Step: 10
Training loss: 3.8598580360412598
Validation loss: 2.8225390087786337
Epoch: 18| Step: 11
Training loss: 3.403912305831909
Validation loss: 2.8131147820314917
Epoch: 18| Step: 12
Training loss: 1.6378917694091797
Validation loss: 2.808815072766311
Epoch: 18| Step: 13
Training loss: 3.060800552368164
Validation loss: 2.8305934401724837
Epoch: 18| Step: 14
Training loss: 4.2154541015625
Validation loss: 2.804858881792576
Epoch: 18| Step: 15
Training loss: 3.228013515472412
Validation loss: 2.8098821914453302
Epoch: 18| Step: 16
Training loss: 2.833043098449707
Validation loss: 2.8021670382657495
Epoch: 18| Step: 17
Training loss: 3.5880117416381836
Validation loss: 2.7920197480016475
Epoch: 18| Step: 18
Training loss: 3.791184902191162
Validation loss: 2.7978624096877285
Epoch: 18| Step: 19
Training loss: 3.5144829750061035
Validation loss: 2.7942779321464704
Epoch: 18| Step: 20
Training loss: 4.092220783233643
Validation loss: 2.801893774554026
Epoch: 18| Step: 21
Training loss: 1.4968788623809814
Validation loss: 2.7995501628024972
Epoch: 18| Step: 22
Training loss: 4.597733974456787
Validation loss: 2.8098305523824347
Epoch: 18| Step: 23
Training loss: 3.204315662384033
Validation loss: 2.800291980770852
Epoch: 18| Step: 24
Training loss: 4.513043403625488
Validation loss: 2.8120976866578027
Epoch: 18| Step: 25
Training loss: 3.483762741088867
Validation loss: 2.8048300983236847
Epoch: 18| Step: 26
Training loss: 3.4282705783843994
Validation loss: 2.808328944144489
Epoch: 18| Step: 27
Training loss: 2.8749568462371826
Validation loss: 2.803153542305926
Epoch: 18| Step: 28
Training loss: 2.9315316677093506
Validation loss: 2.794341183394837
Epoch: 18| Step: 29
Training loss: 3.514676332473755
Validation loss: 2.800585392567751
Epoch: 18| Step: 30
Training loss: 3.3211750984191895
Validation loss: 2.7960824125962294
Epoch: 18| Step: 31
Training loss: 3.12874698638916
Validation loss: 2.7833930708521564
Epoch: 18| Step: 32
Training loss: 3.7568352222442627
Validation loss: 2.801729274310654
Epoch: 18| Step: 33
Training loss: 3.2162458896636963
Validation loss: 2.8055876279048784
Epoch: 18| Step: 34
Training loss: 1.938431978225708
Validation loss: 2.7982836807374474
Epoch: 18| Step: 35
Training loss: 2.1016335487365723
Validation loss: 2.8000568708927513
Epoch: 18| Step: 36
Training loss: 3.788259506225586
Validation loss: 2.8026002276715616
Epoch: 18| Step: 37
Training loss: 3.15215802192688
Validation loss: 2.7866136032900366
Epoch: 18| Step: 38
Training loss: 3.6819493770599365
Validation loss: 2.813195665105641
Epoch: 18| Step: 39
Training loss: 2.5681090354919434
Validation loss: 2.7946197557792387
Epoch: 33| Step: 0
Training loss: 3.4281318187713623
Validation loss: 2.8019182707765977
Epoch: 18| Step: 1
Training loss: 3.6534628868103027
Validation loss: 2.8017115867395197
Epoch: 18| Step: 2
Training loss: 2.6808810234069824
Validation loss: 2.793300671543149
Epoch: 18| Step: 3
Training loss: 3.5379977226257324
Validation loss: 2.792419392427952
Epoch: 18| Step: 4
Training loss: 3.810133934020996
Validation loss: 2.7877716349183226
Epoch: 18| Step: 5
Training loss: 3.705733299255371
Validation loss: 2.7978156187551484
Epoch: 18| Step: 6
Training loss: 3.630983829498291
Validation loss: 2.7918655374924914
Epoch: 18| Step: 7
Training loss: 3.10540771484375
Validation loss: 2.7910619030753487
Epoch: 18| Step: 8
Training loss: 3.1331217288970947
Validation loss: 2.7866450754000986
Epoch: 18| Step: 9
Training loss: 3.425187826156616
Validation loss: 2.7915680031124634
Epoch: 18| Step: 10
Training loss: 3.8021316528320312
Validation loss: 2.7789905757355173
Epoch: 18| Step: 11
Training loss: 2.8281664848327637
Validation loss: 2.7890564228990953
Epoch: 18| Step: 12
Training loss: 2.7543606758117676
Validation loss: 2.796453930491166
Epoch: 18| Step: 13
Training loss: 3.439565658569336
Validation loss: 2.760425507593498
Epoch: 18| Step: 14
Training loss: 2.667510509490967
Validation loss: 2.7969398327010997
Epoch: 18| Step: 15
Training loss: 2.475348472595215
Validation loss: 2.806606440235385
Epoch: 18| Step: 16
Training loss: 2.8557066917419434
Validation loss: 2.7835215355852525
Epoch: 18| Step: 17
Training loss: 3.469703435897827
Validation loss: 2.7870622830425233
Epoch: 18| Step: 18
Training loss: 4.283060073852539
Validation loss: 2.770131306682559
Epoch: 18| Step: 19
Training loss: 2.653095006942749
Validation loss: 2.7923812763296443
Epoch: 18| Step: 20
Training loss: 0.8617238998413086
Validation loss: 2.7810368585071976
Epoch: 18| Step: 21
Training loss: 2.781109094619751
Validation loss: 2.7780463695526123
Epoch: 18| Step: 22
Training loss: 3.7414145469665527
Validation loss: 2.790125442065781
Epoch: 18| Step: 23
Training loss: 4.057211875915527
Validation loss: 2.780526993086012
Epoch: 18| Step: 24
Training loss: 2.425440788269043
Validation loss: 2.791646038027976
Epoch: 18| Step: 25
Training loss: 3.1957762241363525
Validation loss: 2.7862601588955886
Epoch: 18| Step: 26
Training loss: 4.576920509338379
Validation loss: 2.7907506682032306
Epoch: 18| Step: 27
Training loss: 3.8283305168151855
Validation loss: 2.7761644605252385
Epoch: 18| Step: 28
Training loss: 3.242030382156372
Validation loss: 2.7908394353852857
Epoch: 18| Step: 29
Training loss: 2.4578256607055664
Validation loss: 2.7860838397801353
Epoch: 18| Step: 30
Training loss: 3.999330520629883
Validation loss: 2.784547080238946
Epoch: 18| Step: 31
Training loss: 4.238211631774902
Validation loss: 2.8072398480751533
Epoch: 18| Step: 32
Training loss: 3.255011796951294
Validation loss: 2.7882616965890787
Epoch: 18| Step: 33
Training loss: 3.1026852130889893
Validation loss: 2.786506265187435
Epoch: 18| Step: 34
Training loss: 3.8490662574768066
Validation loss: 2.7907163410735647
Epoch: 18| Step: 35
Training loss: 2.3875367641448975
Validation loss: 2.780297382272405
Epoch: 18| Step: 36
Training loss: 3.1921639442443848
Validation loss: 2.7813531966518155
Epoch: 18| Step: 37
Training loss: 2.913189649581909
Validation loss: 2.7732977661297475
Epoch: 18| Step: 38
Training loss: 3.3548035621643066
Validation loss: 2.7733447534574878
Epoch: 18| Step: 39
Training loss: 3.1289443969726562
Validation loss: 2.793745160960465
Epoch: 34| Step: 0
Training loss: 3.4938786029815674
Validation loss: 2.778125208916424
Epoch: 18| Step: 1
Training loss: 3.1420533657073975
Validation loss: 2.785735310410424
Epoch: 18| Step: 2
Training loss: 3.525597333908081
Validation loss: 2.7714929169030498
Epoch: 18| Step: 3
Training loss: 3.5840392112731934
Validation loss: 2.775136377314012
Epoch: 18| Step: 4
Training loss: 4.43003511428833
Validation loss: 2.7791760328004687
Epoch: 18| Step: 5
Training loss: 3.085819721221924
Validation loss: 2.751744170840696
Epoch: 18| Step: 6
Training loss: 2.9248838424682617
Validation loss: 2.778902271668688
Epoch: 18| Step: 7
Training loss: 2.7629683017730713
Validation loss: 2.777607984680066
Epoch: 18| Step: 8
Training loss: 3.8932247161865234
Validation loss: 2.759100011784396
Epoch: 18| Step: 9
Training loss: 2.6908316612243652
Validation loss: 2.7811042319098824
Epoch: 18| Step: 10
Training loss: 2.6318747997283936
Validation loss: 2.7810042264650194
Epoch: 18| Step: 11
Training loss: 3.1620302200317383
Validation loss: 2.7879905734988424
Epoch: 18| Step: 12
Training loss: 2.9018778800964355
Validation loss: 2.750174047277986
Epoch: 18| Step: 13
Training loss: 4.356919288635254
Validation loss: 2.780336256507489
Epoch: 18| Step: 14
Training loss: 2.658982276916504
Validation loss: 2.7586834327780085
Epoch: 18| Step: 15
Training loss: 2.070723533630371
Validation loss: 2.761831813578983
Epoch: 18| Step: 16
Training loss: 3.7229509353637695
Validation loss: 2.76927591227799
Epoch: 18| Step: 17
Training loss: 2.013486862182617
Validation loss: 2.784569222292454
Epoch: 18| Step: 18
Training loss: 3.573513984680176
Validation loss: 2.774974412197689
Epoch: 18| Step: 19
Training loss: 4.468367099761963
Validation loss: 2.7543366915888066
Epoch: 18| Step: 20
Training loss: 2.5665078163146973
Validation loss: 2.773253269332776
Epoch: 18| Step: 21
Training loss: 3.9219717979431152
Validation loss: 2.7687009778811777
Epoch: 18| Step: 22
Training loss: 3.703129768371582
Validation loss: 2.7575274843106166
Epoch: 18| Step: 23
Training loss: 2.712259531021118
Validation loss: 2.783815762979521
Epoch: 18| Step: 24
Training loss: 3.327291250228882
Validation loss: 2.7587653853052814
Epoch: 18| Step: 25
Training loss: 2.7957499027252197
Validation loss: 2.7743470085610586
Epoch: 18| Step: 26
Training loss: 3.1404285430908203
Validation loss: 2.7712570480305514
Epoch: 18| Step: 27
Training loss: 4.3432135581970215
Validation loss: 2.75128028032591
Epoch: 18| Step: 28
Training loss: 3.3096766471862793
Validation loss: 2.7708002731954453
Epoch: 18| Step: 29
Training loss: 3.524334192276001
Validation loss: 2.7737776246859873
Epoch: 18| Step: 30
Training loss: 4.469050407409668
Validation loss: 2.777364832034214
Epoch: 18| Step: 31
Training loss: 3.3112263679504395
Validation loss: 2.7612558303119465
Epoch: 18| Step: 32
Training loss: 1.844252347946167
Validation loss: 2.7715676465480446
Epoch: 18| Step: 33
Training loss: 3.4858591556549072
Validation loss: 2.77234623415007
Epoch: 18| Step: 34
Training loss: 2.3032732009887695
Validation loss: 2.7697770767074696
Epoch: 18| Step: 35
Training loss: 2.4576077461242676
Validation loss: 2.7635918778481243
Epoch: 18| Step: 36
Training loss: 2.8188984394073486
Validation loss: 2.77116911188304
Epoch: 18| Step: 37
Training loss: 5.0308403968811035
Validation loss: 2.7544745163951845
Epoch: 18| Step: 38
Training loss: 2.4171247482299805
Validation loss: 2.7571352523007837
Epoch: 18| Step: 39
Training loss: 2.372131824493408
Validation loss: 2.7626214739230037
Epoch: 35| Step: 0
Training loss: 3.4868905544281006
Validation loss: 2.767871141433716
Epoch: 18| Step: 1
Training loss: 3.840567111968994
Validation loss: 2.7707652479624576
Epoch: 18| Step: 2
Training loss: 2.287783145904541
Validation loss: 2.748011556460703
Epoch: 18| Step: 3
Training loss: 3.8306286334991455
Validation loss: 2.7657818399744927
Epoch: 18| Step: 4
Training loss: 2.9808595180511475
Validation loss: 2.74654624144808
Epoch: 18| Step: 5
Training loss: 4.468184471130371
Validation loss: 2.7423351634320596
Epoch: 18| Step: 6
Training loss: 3.5926458835601807
Validation loss: 2.7396082054796835
Epoch: 18| Step: 7
Training loss: 5.100955486297607
Validation loss: 2.7689980328511847
Epoch: 18| Step: 8
Training loss: 2.315162181854248
Validation loss: 2.7467722429646004
Epoch: 18| Step: 9
Training loss: 4.098315238952637
Validation loss: 2.7434600703150247
Epoch: 18| Step: 10
Training loss: 2.969344139099121
Validation loss: 2.739811754912781
Epoch: 18| Step: 11
Training loss: 3.1613900661468506
Validation loss: 2.771433001799549
Epoch: 18| Step: 12
Training loss: 2.8602375984191895
Validation loss: 2.751408163592112
Epoch: 18| Step: 13
Training loss: 2.354090690612793
Validation loss: 2.731422271659906
Epoch: 18| Step: 14
Training loss: 4.0310444831848145
Validation loss: 2.7684495003103353
Epoch: 18| Step: 15
Training loss: 3.2827656269073486
Validation loss: 2.7666951477956427
Epoch: 18| Step: 16
Training loss: 4.446857452392578
Validation loss: 2.7426172040349286
Epoch: 18| Step: 17
Training loss: 2.6921191215515137
Validation loss: 2.7391864481589776
Epoch: 18| Step: 18
Training loss: 3.7223291397094727
Validation loss: 2.7426787983599326
Epoch: 18| Step: 19
Training loss: 2.8530125617980957
Validation loss: 2.7649582152743992
Epoch: 18| Step: 20
Training loss: 3.552964687347412
Validation loss: 2.7481160609842203
Epoch: 18| Step: 21
Training loss: 3.5875298976898193
Validation loss: 2.7287606301067546
Epoch: 18| Step: 22
Training loss: 2.4547994136810303
Validation loss: 2.755080199070114
Epoch: 18| Step: 23
Training loss: 2.5233945846557617
Validation loss: 2.7470623194742547
Epoch: 18| Step: 24
Training loss: 1.0957814455032349
Validation loss: 2.733633199184061
Epoch: 18| Step: 25
Training loss: 2.2915139198303223
Validation loss: 2.760333117821234
Epoch: 18| Step: 26
Training loss: 3.2145533561706543
Validation loss: 2.7311003748461498
Epoch: 18| Step: 27
Training loss: 3.1082444190979004
Validation loss: 2.7503718489365614
Epoch: 18| Step: 28
Training loss: 3.780374526977539
Validation loss: 2.749569661325688
Epoch: 18| Step: 29
Training loss: 2.9058499336242676
Validation loss: 2.7371852260699376
Epoch: 18| Step: 30
Training loss: 3.7781944274902344
Validation loss: 2.7348935123827816
Epoch: 18| Step: 31
Training loss: 2.814974069595337
Validation loss: 2.7463184629412862
Epoch: 18| Step: 32
Training loss: 2.920856475830078
Validation loss: 2.738947909512966
Epoch: 18| Step: 33
Training loss: 2.971245765686035
Validation loss: 2.76339241240522
Epoch: 18| Step: 34
Training loss: 3.6121349334716797
Validation loss: 2.7329966790384526
Epoch: 18| Step: 35
Training loss: 4.171236038208008
Validation loss: 2.7598236070262443
Epoch: 18| Step: 36
Training loss: 3.414111375808716
Validation loss: 2.7391907328324354
Epoch: 18| Step: 37
Training loss: 2.19405460357666
Validation loss: 2.73277467960934
Epoch: 18| Step: 38
Training loss: 2.6549391746520996
Validation loss: 2.750000243564304
Epoch: 18| Step: 39
Training loss: 3.29842209815979
Validation loss: 2.7337053525362083
Epoch: 36| Step: 0
Training loss: 2.833472728729248
Validation loss: 2.740408348522598
Epoch: 18| Step: 1
Training loss: 2.5548081398010254
Validation loss: 2.7398627095942873
Epoch: 18| Step: 2
Training loss: 3.1696767807006836
Validation loss: 2.7239675967813395
Epoch: 18| Step: 3
Training loss: 3.1723427772521973
Validation loss: 2.755708365131625
Epoch: 18| Step: 4
Training loss: 2.960984230041504
Validation loss: 2.724468534798931
Epoch: 18| Step: 5
Training loss: 2.9941482543945312
Validation loss: 2.7396001489899997
Epoch: 18| Step: 6
Training loss: 2.349074602127075
Validation loss: 2.7549701457400975
Epoch: 18| Step: 7
Training loss: 3.114914894104004
Validation loss: 2.753933803640681
Epoch: 18| Step: 8
Training loss: 3.3202028274536133
Validation loss: 2.7311766164765943
Epoch: 18| Step: 9
Training loss: 2.702584743499756
Validation loss: 2.7349721733614696
Epoch: 18| Step: 10
Training loss: 2.9987521171569824
Validation loss: 2.7376050040018645
Epoch: 18| Step: 11
Training loss: 4.169759750366211
Validation loss: 2.7481768611523747
Epoch: 18| Step: 12
Training loss: 2.4646120071411133
Validation loss: 2.7391439118831276
Epoch: 18| Step: 13
Training loss: 3.1387195587158203
Validation loss: 2.748956848391526
Epoch: 18| Step: 14
Training loss: 2.784547805786133
Validation loss: 2.7464895848747637
Epoch: 18| Step: 15
Training loss: 2.5828018188476562
Validation loss: 2.748317601869432
Epoch: 18| Step: 16
Training loss: 3.9220080375671387
Validation loss: 2.7542030965681557
Epoch: 18| Step: 17
Training loss: 3.6856606006622314
Validation loss: 2.748403823632988
Epoch: 18| Step: 18
Training loss: 1.7801778316497803
Validation loss: 2.7335513620067844
Epoch: 18| Step: 19
Training loss: 2.901977062225342
Validation loss: 2.721390615264289
Epoch: 18| Step: 20
Training loss: 3.757934808731079
Validation loss: 2.7243154923692883
Epoch: 18| Step: 21
Training loss: 3.8897147178649902
Validation loss: 2.7344110513762603
Epoch: 18| Step: 22
Training loss: 4.497219085693359
Validation loss: 2.750002161204386
Epoch: 18| Step: 23
Training loss: 2.790830373764038
Validation loss: 2.745374213019721
Epoch: 18| Step: 24
Training loss: 3.4349398612976074
Validation loss: 2.7319522452869003
Epoch: 18| Step: 25
Training loss: 2.4246692657470703
Validation loss: 2.7400363589362273
Epoch: 18| Step: 26
Training loss: 4.066822052001953
Validation loss: 2.738411018316694
Epoch: 18| Step: 27
Training loss: 4.199241638183594
Validation loss: 2.7405490412128914
Epoch: 18| Step: 28
Training loss: 2.3111472129821777
Validation loss: 2.7377891163174195
Epoch: 18| Step: 29
Training loss: 3.5665907859802246
Validation loss: 2.7600692845076966
Epoch: 18| Step: 30
Training loss: 3.3994550704956055
Validation loss: 2.732323926129787
Epoch: 18| Step: 31
Training loss: 2.844391345977783
Validation loss: 2.7245255854489994
Epoch: 18| Step: 32
Training loss: 3.2762598991394043
Validation loss: 2.7556663022624504
Epoch: 18| Step: 33
Training loss: 3.4872941970825195
Validation loss: 2.741526855839242
Epoch: 18| Step: 34
Training loss: 3.507901191711426
Validation loss: 2.7498715567074234
Epoch: 18| Step: 35
Training loss: 3.2272164821624756
Validation loss: 2.741095764173878
Epoch: 18| Step: 36
Training loss: 3.5729949474334717
Validation loss: 2.7286083303767144
Epoch: 18| Step: 37
Training loss: 2.8497414588928223
Validation loss: 2.7321229152542226
Epoch: 18| Step: 38
Training loss: 2.3141696453094482
Validation loss: 2.7315941251439155
Epoch: 18| Step: 39
Training loss: 4.9271721839904785
Validation loss: 2.7406089717535664
Epoch: 37| Step: 0
Training loss: 3.3158082962036133
Validation loss: 2.724664401665008
Epoch: 18| Step: 1
Training loss: 3.0811514854431152
Validation loss: 2.74579050043504
Epoch: 18| Step: 2
Training loss: 3.8681869506835938
Validation loss: 2.711562739859382
Epoch: 18| Step: 3
Training loss: 3.059267997741699
Validation loss: 2.717614640434869
Epoch: 18| Step: 4
Training loss: 2.7864513397216797
Validation loss: 2.73081674507196
Epoch: 18| Step: 5
Training loss: 3.1918511390686035
Validation loss: 2.732571221084046
Epoch: 18| Step: 6
Training loss: 2.733781576156616
Validation loss: 2.739684880208626
Epoch: 18| Step: 7
Training loss: 2.4789490699768066
Validation loss: 2.7347804007770344
Epoch: 18| Step: 8
Training loss: 3.114497184753418
Validation loss: 2.729163961444827
Epoch: 18| Step: 9
Training loss: 2.7608017921447754
Validation loss: 2.7316338398473725
Epoch: 18| Step: 10
Training loss: 2.9788851737976074
Validation loss: 2.7304291296348295
Epoch: 18| Step: 11
Training loss: 3.540095806121826
Validation loss: 2.720890022867875
Epoch: 18| Step: 12
Training loss: 3.6215906143188477
Validation loss: 2.740076840352669
Epoch: 18| Step: 13
Training loss: 4.878507137298584
Validation loss: 2.7234007403147307
Epoch: 18| Step: 14
Training loss: 3.0682201385498047
Validation loss: 2.741415935454609
Epoch: 18| Step: 15
Training loss: 2.6591591835021973
Validation loss: 2.740669551513178
Epoch: 18| Step: 16
Training loss: 3.830111265182495
Validation loss: 2.7289649265275586
Epoch: 18| Step: 17
Training loss: 2.918316125869751
Validation loss: 2.7458353763004
Epoch: 18| Step: 18
Training loss: 2.2168374061584473
Validation loss: 2.702011863104731
Epoch: 18| Step: 19
Training loss: 3.735971212387085
Validation loss: 2.7173484074983665
Epoch: 18| Step: 20
Training loss: 4.381913185119629
Validation loss: 2.7160239682780754
Epoch: 18| Step: 21
Training loss: 3.3845772743225098
Validation loss: 2.723678286127049
Epoch: 18| Step: 22
Training loss: 2.827524185180664
Validation loss: 2.7308564906497654
Epoch: 18| Step: 23
Training loss: 3.6732380390167236
Validation loss: 2.7331723051963093
Epoch: 18| Step: 24
Training loss: 3.1783785820007324
Validation loss: 2.7330919924399835
Epoch: 18| Step: 25
Training loss: 3.457754611968994
Validation loss: 2.75128594919932
Epoch: 18| Step: 26
Training loss: 3.5797340869903564
Validation loss: 2.735571650292376
Epoch: 18| Step: 27
Training loss: 2.0615439414978027
Validation loss: 2.7418477106437407
Epoch: 18| Step: 28
Training loss: 3.0422656536102295
Validation loss: 2.7326256525602273
Epoch: 18| Step: 29
Training loss: 2.4583446979522705
Validation loss: 2.7315068956759334
Epoch: 18| Step: 30
Training loss: 2.785522937774658
Validation loss: 2.7386656099086184
Epoch: 18| Step: 31
Training loss: 3.216698169708252
Validation loss: 2.7287780689678605
Epoch: 18| Step: 32
Training loss: 2.8544797897338867
Validation loss: 2.7357347543291053
Epoch: 18| Step: 33
Training loss: 3.591228485107422
Validation loss: 2.7277235007114546
Epoch: 18| Step: 34
Training loss: 3.65781831741333
Validation loss: 2.7366889380722594
Epoch: 18| Step: 35
Training loss: 2.7738499641418457
Validation loss: 2.7136103540873355
Epoch: 18| Step: 36
Training loss: 3.1126575469970703
Validation loss: 2.7281718665747334
Epoch: 18| Step: 37
Training loss: 2.4860496520996094
Validation loss: 2.7271919747908338
Epoch: 18| Step: 38
Training loss: 3.421462059020996
Validation loss: 2.728867324993765
Epoch: 18| Step: 39
Training loss: 3.483703851699829
Validation loss: 2.7359322815490286
Epoch: 38| Step: 0
Training loss: 3.5571987628936768
Validation loss: 2.717400333006605
Epoch: 18| Step: 1
Training loss: 3.068350315093994
Validation loss: 2.7285432618298975
Epoch: 18| Step: 2
Training loss: 2.4648983478546143
Validation loss: 2.734557173234953
Epoch: 18| Step: 3
Training loss: 4.807315826416016
Validation loss: 2.7325639364530714
Epoch: 18| Step: 4
Training loss: 3.4930927753448486
Validation loss: 2.7214571537731365
Epoch: 18| Step: 5
Training loss: 3.3903441429138184
Validation loss: 2.730826624863439
Epoch: 18| Step: 6
Training loss: 2.3013641834259033
Validation loss: 2.732761021140668
Epoch: 18| Step: 7
Training loss: 3.451643228530884
Validation loss: 2.7051846689457517
Epoch: 18| Step: 8
Training loss: 3.116946220397949
Validation loss: 2.7121174901509457
Epoch: 18| Step: 9
Training loss: 3.2091739177703857
Validation loss: 2.713979610436254
Epoch: 18| Step: 10
Training loss: 3.2219035625457764
Validation loss: 2.7354926394044066
Epoch: 18| Step: 11
Training loss: 3.296328067779541
Validation loss: 2.7389414173235997
Epoch: 18| Step: 12
Training loss: 2.4566822052001953
Validation loss: 2.691451129295843
Epoch: 18| Step: 13
Training loss: 3.7530174255371094
Validation loss: 2.714912582644456
Epoch: 18| Step: 14
Training loss: 2.0441954135894775
Validation loss: 2.717681997542759
Epoch: 18| Step: 15
Training loss: 4.9834089279174805
Validation loss: 2.72456058152288
Epoch: 18| Step: 16
Training loss: 3.630861759185791
Validation loss: 2.7299389599038544
Epoch: 18| Step: 17
Training loss: 2.11043643951416
Validation loss: 2.7030354575287525
Epoch: 18| Step: 18
Training loss: 4.734979629516602
Validation loss: 2.736879606041119
Epoch: 18| Step: 19
Training loss: 3.4673914909362793
Validation loss: 2.6961310407240613
Epoch: 18| Step: 20
Training loss: 3.0514414310455322
Validation loss: 2.702413490350298
Epoch: 18| Step: 21
Training loss: 2.5660367012023926
Validation loss: 2.695637308436332
Epoch: 18| Step: 22
Training loss: 2.9504003524780273
Validation loss: 2.7255036161957884
Epoch: 18| Step: 23
Training loss: 2.110098123550415
Validation loss: 2.7143805558732947
Epoch: 18| Step: 24
Training loss: 2.4132823944091797
Validation loss: 2.702749758315601
Epoch: 18| Step: 25
Training loss: 3.551382064819336
Validation loss: 2.7009859736874806
Epoch: 18| Step: 26
Training loss: 2.309713840484619
Validation loss: 2.722795161411917
Epoch: 18| Step: 27
Training loss: 3.2075657844543457
Validation loss: 2.7192279898005425
Epoch: 18| Step: 28
Training loss: 3.0726029872894287
Validation loss: 2.7208538175486834
Epoch: 18| Step: 29
Training loss: 1.8489751815795898
Validation loss: 2.7002411711987833
Epoch: 18| Step: 30
Training loss: 2.7950220108032227
Validation loss: 2.7186338541319044
Epoch: 18| Step: 31
Training loss: 3.8937177658081055
Validation loss: 2.7287559251991107
Epoch: 18| Step: 32
Training loss: 4.360005855560303
Validation loss: 2.738502462133229
Epoch: 18| Step: 33
Training loss: 3.7079660892486572
Validation loss: 2.703025565730582
Epoch: 18| Step: 34
Training loss: 4.113447189331055
Validation loss: 2.706034986235255
Epoch: 18| Step: 35
Training loss: 3.3524415493011475
Validation loss: 2.709024490212365
Epoch: 18| Step: 36
Training loss: 1.6559219360351562
Validation loss: 2.707515406094009
Epoch: 18| Step: 37
Training loss: 4.767005443572998
Validation loss: 2.70711783539477
Epoch: 18| Step: 38
Training loss: 2.898310661315918
Validation loss: 2.7051360418470645
Epoch: 18| Step: 39
Training loss: 2.5419838428497314
Validation loss: 2.7220492002775343
Epoch: 39| Step: 0
Training loss: 4.405572414398193
Validation loss: 2.7309124761348147
Epoch: 18| Step: 1
Training loss: 2.718517303466797
Validation loss: 2.71949785218822
Epoch: 18| Step: 2
Training loss: 3.9463703632354736
Validation loss: 2.7136065668339353
Epoch: 18| Step: 3
Training loss: 3.3948795795440674
Validation loss: 2.710425157341168
Epoch: 18| Step: 4
Training loss: 4.347219467163086
Validation loss: 2.7052800149368723
Epoch: 18| Step: 5
Training loss: 3.6577200889587402
Validation loss: 2.695979202394005
Epoch: 18| Step: 6
Training loss: 2.564002752304077
Validation loss: 2.7143951542943503
Epoch: 18| Step: 7
Training loss: 2.854599952697754
Validation loss: 2.704437683812148
Epoch: 18| Step: 8
Training loss: 3.883746385574341
Validation loss: 2.693246340580124
Epoch: 18| Step: 9
Training loss: 3.10614013671875
Validation loss: 2.705302608956536
Epoch: 18| Step: 10
Training loss: 3.010648012161255
Validation loss: 2.698300835039976
Epoch: 18| Step: 11
Training loss: 3.5900847911834717
Validation loss: 2.71725495942205
Epoch: 18| Step: 12
Training loss: 3.840517520904541
Validation loss: 2.699439258884183
Epoch: 18| Step: 13
Training loss: 2.6078426837921143
Validation loss: 2.7050175821180824
Epoch: 18| Step: 14
Training loss: 3.415675163269043
Validation loss: 2.687016073748362
Epoch: 18| Step: 15
Training loss: 3.6382944583892822
Validation loss: 2.7058377883417144
Epoch: 18| Step: 16
Training loss: 3.8663830757141113
Validation loss: 2.697411140949606
Epoch: 18| Step: 17
Training loss: 1.5805870294570923
Validation loss: 2.6770880685435783
Epoch: 18| Step: 18
Training loss: 3.822011947631836
Validation loss: 2.7163918584370785
Epoch: 18| Step: 19
Training loss: 2.967461585998535
Validation loss: 2.7100467244498163
Epoch: 18| Step: 20
Training loss: 2.9020979404449463
Validation loss: 2.7000121246996542
Epoch: 18| Step: 21
Training loss: 2.5650646686553955
Validation loss: 2.7114081502818377
Epoch: 18| Step: 22
Training loss: 2.474294662475586
Validation loss: 2.7105548167400224
Epoch: 18| Step: 23
Training loss: 2.9943437576293945
Validation loss: 2.694814515628403
Epoch: 18| Step: 24
Training loss: 3.6801133155822754
Validation loss: 2.6970723944602253
Epoch: 18| Step: 25
Training loss: 2.920070171356201
Validation loss: 2.723361104512386
Epoch: 18| Step: 26
Training loss: 3.615241050720215
Validation loss: 2.7149940934970225
Epoch: 18| Step: 27
Training loss: 2.6729021072387695
Validation loss: 2.7013439325977573
Epoch: 18| Step: 28
Training loss: 1.861688256263733
Validation loss: 2.6903035640716553
Epoch: 18| Step: 29
Training loss: 2.9253649711608887
Validation loss: 2.721588433217659
Epoch: 18| Step: 30
Training loss: 3.6758880615234375
Validation loss: 2.6985308901011513
Epoch: 18| Step: 31
Training loss: 2.2127320766448975
Validation loss: 2.704608280881703
Epoch: 18| Step: 32
Training loss: 3.4130241870880127
Validation loss: 2.7065507345062367
Epoch: 18| Step: 33
Training loss: 2.7225937843322754
Validation loss: 2.7039271412993506
Epoch: 18| Step: 34
Training loss: 3.597230911254883
Validation loss: 2.7032166487879032
Epoch: 18| Step: 35
Training loss: 3.5704100131988525
Validation loss: 2.712056911248955
Epoch: 18| Step: 36
Training loss: 3.4714736938476562
Validation loss: 2.6986857352496907
Epoch: 18| Step: 37
Training loss: 3.740722894668579
Validation loss: 2.666028343516288
Epoch: 18| Step: 38
Training loss: 2.611304998397827
Validation loss: 2.6909690683694194
Epoch: 18| Step: 39
Training loss: 2.1545164585113525
Validation loss: 2.690589993977718
Epoch: 40| Step: 0
Training loss: 2.7547988891601562
Validation loss: 2.703758913836033
Epoch: 18| Step: 1
Training loss: 3.923015832901001
Validation loss: 2.679027476756693
Epoch: 18| Step: 2
Training loss: 2.886935234069824
Validation loss: 2.6650652954046676
Epoch: 18| Step: 3
Training loss: 3.699380874633789
Validation loss: 2.681074175045645
Epoch: 18| Step: 4
Training loss: 4.076662063598633
Validation loss: 2.680069696988991
Epoch: 18| Step: 5
Training loss: 3.850966691970825
Validation loss: 2.6966086548866985
Epoch: 18| Step: 6
Training loss: 2.901848793029785
Validation loss: 2.694906185856826
Epoch: 18| Step: 7
Training loss: 3.194704055786133
Validation loss: 2.69320624852352
Epoch: 18| Step: 8
Training loss: 2.3764452934265137
Validation loss: 2.703765671887844
Epoch: 18| Step: 9
Training loss: 1.9837815761566162
Validation loss: 2.709221517439369
Epoch: 18| Step: 10
Training loss: 3.3285880088806152
Validation loss: 2.7176504306655995
Epoch: 18| Step: 11
Training loss: 3.369483470916748
Validation loss: 2.6974406559690296
Epoch: 18| Step: 12
Training loss: 2.237868309020996
Validation loss: 2.694927251596245
Epoch: 18| Step: 13
Training loss: 2.8271188735961914
Validation loss: 2.6973973881426474
Epoch: 18| Step: 14
Training loss: 2.8413875102996826
Validation loss: 2.6912996168616865
Epoch: 18| Step: 15
Training loss: 3.4151875972747803
Validation loss: 2.7072937728689728
Epoch: 18| Step: 16
Training loss: 4.078420639038086
Validation loss: 2.677108620568145
Epoch: 18| Step: 17
Training loss: 3.4986202716827393
Validation loss: 2.68766528153591
Epoch: 18| Step: 18
Training loss: 3.037879705429077
Validation loss: 2.6773126091030863
Epoch: 18| Step: 19
Training loss: 3.279794454574585
Validation loss: 2.678070390824791
Epoch: 18| Step: 20
Training loss: 1.8979804515838623
Validation loss: 2.6932653977716567
Epoch: 18| Step: 21
Training loss: 2.364025354385376
Validation loss: 2.685989491373515
Epoch: 18| Step: 22
Training loss: 3.7863736152648926
Validation loss: 2.6641979423358286
Epoch: 18| Step: 23
Training loss: 2.196887493133545
Validation loss: 2.6833463109654487
Epoch: 18| Step: 24
Training loss: 2.8659191131591797
Validation loss: 2.667232940522887
Epoch: 18| Step: 25
Training loss: 2.6090569496154785
Validation loss: 2.6844203815185765
Epoch: 18| Step: 26
Training loss: 3.1695244312286377
Validation loss: 2.6972803580675193
Epoch: 18| Step: 27
Training loss: 1.907206654548645
Validation loss: 2.6791325009984077
Epoch: 18| Step: 28
Training loss: 3.6374716758728027
Validation loss: 2.6397884543851124
Epoch: 18| Step: 29
Training loss: 2.6449007987976074
Validation loss: 2.681324677501651
Epoch: 18| Step: 30
Training loss: 2.6474339962005615
Validation loss: 2.6916847434832896
Epoch: 18| Step: 31
Training loss: 3.3830747604370117
Validation loss: 2.6893944019893947
Epoch: 18| Step: 32
Training loss: 4.564228057861328
Validation loss: 2.675125454827178
Epoch: 18| Step: 33
Training loss: 5.019233703613281
Validation loss: 2.6902682523933246
Epoch: 18| Step: 34
Training loss: 3.0745086669921875
Validation loss: 2.6683669621995887
Epoch: 18| Step: 35
Training loss: 2.8677163124084473
Validation loss: 2.660665889438108
Epoch: 18| Step: 36
Training loss: 2.4598662853240967
Validation loss: 2.6999471256201217
Epoch: 18| Step: 37
Training loss: 3.3508453369140625
Validation loss: 2.701609220436151
Epoch: 18| Step: 38
Training loss: 4.541829586029053
Validation loss: 2.6536901597496416
Epoch: 18| Step: 39
Training loss: 3.77842378616333
Validation loss: 2.662777811503239
Epoch: 41| Step: 0
Training loss: 3.1026511192321777
Validation loss: 2.6733204752421207
Epoch: 18| Step: 1
Training loss: 3.8592941761016846
Validation loss: 2.6811848595845613
Epoch: 18| Step: 2
Training loss: 2.438403844833374
Validation loss: 2.6760373046929886
Epoch: 18| Step: 3
Training loss: 2.585526943206787
Validation loss: 2.6743382704343728
Epoch: 18| Step: 4
Training loss: 2.2271718978881836
Validation loss: 2.6896973805461855
Epoch: 18| Step: 5
Training loss: 1.8654439449310303
Validation loss: 2.693160442997226
Epoch: 18| Step: 6
Training loss: 4.383610725402832
Validation loss: 2.6918104243793075
Epoch: 18| Step: 7
Training loss: 3.8679940700531006
Validation loss: 2.682291346488239
Epoch: 18| Step: 8
Training loss: 3.722775936126709
Validation loss: 2.671592040027646
Epoch: 18| Step: 9
Training loss: 3.52493953704834
Validation loss: 2.695796206700716
Epoch: 18| Step: 10
Training loss: 2.7796263694763184
Validation loss: 2.6795011012674235
Epoch: 18| Step: 11
Training loss: 3.8911662101745605
Validation loss: 2.6548311255818646
Epoch: 18| Step: 12
Training loss: 2.7429776191711426
Validation loss: 2.678820747265713
Epoch: 18| Step: 13
Training loss: 3.244363784790039
Validation loss: 2.6859272967139596
Epoch: 18| Step: 14
Training loss: 3.58852481842041
Validation loss: 2.673242296246316
Epoch: 18| Step: 15
Training loss: 3.24307918548584
Validation loss: 2.663626778897622
Epoch: 18| Step: 16
Training loss: 2.7769675254821777
Validation loss: 2.6795487077973728
Epoch: 18| Step: 17
Training loss: 4.4842071533203125
Validation loss: 2.6873493571933227
Epoch: 18| Step: 18
Training loss: 1.8570376634597778
Validation loss: 2.6698892665423934
Epoch: 18| Step: 19
Training loss: 3.8107261657714844
Validation loss: 2.6512386867468307
Epoch: 18| Step: 20
Training loss: 3.9670825004577637
Validation loss: 2.627088985854773
Epoch: 18| Step: 21
Training loss: 2.7654242515563965
Validation loss: 2.666785211871854
Epoch: 18| Step: 22
Training loss: 2.7926321029663086
Validation loss: 2.657762909964692
Epoch: 18| Step: 23
Training loss: 3.0354976654052734
Validation loss: 2.6744385263045056
Epoch: 18| Step: 24
Training loss: 1.7696309089660645
Validation loss: 2.6634974102322144
Epoch: 18| Step: 25
Training loss: 3.557696580886841
Validation loss: 2.668285827842548
Epoch: 18| Step: 26
Training loss: 2.1038224697113037
Validation loss: 2.6548503422908647
Epoch: 18| Step: 27
Training loss: 3.9937987327575684
Validation loss: 2.677052707123242
Epoch: 18| Step: 28
Training loss: 2.546633243560791
Validation loss: 2.669627887739552
Epoch: 18| Step: 29
Training loss: 2.6516852378845215
Validation loss: 2.654090083760323
Epoch: 18| Step: 30
Training loss: 3.8487813472747803
Validation loss: 2.6694877216284225
Epoch: 18| Step: 31
Training loss: 2.8477835655212402
Validation loss: 2.6474644494571273
Epoch: 18| Step: 32
Training loss: 4.168270111083984
Validation loss: 2.682085413726971
Epoch: 18| Step: 33
Training loss: 4.207381248474121
Validation loss: 2.6654952327124506
Epoch: 18| Step: 34
Training loss: 3.62229585647583
Validation loss: 2.6628809592706695
Epoch: 18| Step: 35
Training loss: 1.8073400259017944
Validation loss: 2.6662206426798867
Epoch: 18| Step: 36
Training loss: 2.8461575508117676
Validation loss: 2.682522599645656
Epoch: 18| Step: 37
Training loss: 2.8424124717712402
Validation loss: 2.668877605054018
Epoch: 18| Step: 38
Training loss: 3.0037147998809814
Validation loss: 2.6722002423924507
Epoch: 18| Step: 39
Training loss: 3.391909122467041
Validation loss: 2.6774075494395744
Epoch: 42| Step: 0
Training loss: 3.0744242668151855
Validation loss: 2.672476121847578
Epoch: 18| Step: 1
Training loss: 4.002162933349609
Validation loss: 2.679339739058515
Epoch: 18| Step: 2
Training loss: 3.7559354305267334
Validation loss: 2.672566226060442
Epoch: 18| Step: 3
Training loss: 3.715452194213867
Validation loss: 2.644231746522643
Epoch: 18| Step: 4
Training loss: 2.7165162563323975
Validation loss: 2.650981076329732
Epoch: 18| Step: 5
Training loss: 2.6008853912353516
Validation loss: 2.623610861867452
Epoch: 18| Step: 6
Training loss: 3.345961332321167
Validation loss: 2.6632527841938485
Epoch: 18| Step: 7
Training loss: 3.477639675140381
Validation loss: 2.654511153269157
Epoch: 18| Step: 8
Training loss: 2.937925338745117
Validation loss: 2.6546173078550708
Epoch: 18| Step: 9
Training loss: 4.760462284088135
Validation loss: 2.649855136871338
Epoch: 18| Step: 10
Training loss: 3.157355785369873
Validation loss: 2.654240903236883
Epoch: 18| Step: 11
Training loss: 2.4336962699890137
Validation loss: 2.6463794742556783
Epoch: 18| Step: 12
Training loss: 3.4526710510253906
Validation loss: 2.644271564140594
Epoch: 18| Step: 13
Training loss: 3.254823684692383
Validation loss: 2.658079787123975
Epoch: 18| Step: 14
Training loss: 3.246760129928589
Validation loss: 2.6439788135693227
Epoch: 18| Step: 15
Training loss: 3.594595432281494
Validation loss: 2.656875195263101
Epoch: 18| Step: 16
Training loss: 3.9402523040771484
Validation loss: 2.641949193940746
Epoch: 18| Step: 17
Training loss: 3.3388829231262207
Validation loss: 2.6522099079845622
Epoch: 18| Step: 18
Training loss: 2.389040470123291
Validation loss: 2.657649237474949
Epoch: 18| Step: 19
Training loss: 3.065548896789551
Validation loss: 2.6616622441106563
Epoch: 18| Step: 20
Training loss: 3.6544137001037598
Validation loss: 2.655447589407722
Epoch: 18| Step: 21
Training loss: 3.6957507133483887
Validation loss: 2.6554037100977177
Epoch: 18| Step: 22
Training loss: 2.9147186279296875
Validation loss: 2.6639072620611395
Epoch: 18| Step: 23
Training loss: 2.436713933944702
Validation loss: 2.657681953992775
Epoch: 18| Step: 24
Training loss: 4.148163795471191
Validation loss: 2.64304382680989
Epoch: 18| Step: 25
Training loss: 3.418595552444458
Validation loss: 2.636778680540675
Epoch: 18| Step: 26
Training loss: 2.7818503379821777
Validation loss: 2.670419157837792
Epoch: 18| Step: 27
Training loss: 2.553006887435913
Validation loss: 2.637898261598546
Epoch: 18| Step: 28
Training loss: 2.7554569244384766
Validation loss: 2.665175401907173
Epoch: 18| Step: 29
Training loss: 2.437655210494995
Validation loss: 2.6382060102421603
Epoch: 18| Step: 30
Training loss: 2.2628207206726074
Validation loss: 2.636166466225823
Epoch: 18| Step: 31
Training loss: 2.882497787475586
Validation loss: 2.6522406828489236
Epoch: 18| Step: 32
Training loss: 1.9838722944259644
Validation loss: 2.6212324161323712
Epoch: 18| Step: 33
Training loss: 3.780935049057007
Validation loss: 2.64506832472712
Epoch: 18| Step: 34
Training loss: 2.1388158798217773
Validation loss: 2.6377111133054005
Epoch: 18| Step: 35
Training loss: 3.683077812194824
Validation loss: 2.636944400320808
Epoch: 18| Step: 36
Training loss: 3.064434051513672
Validation loss: 2.6691792577290707
Epoch: 18| Step: 37
Training loss: 2.9514570236206055
Validation loss: 2.6479264866533896
Epoch: 18| Step: 38
Training loss: 3.4830055236816406
Validation loss: 2.6631888185473653
Epoch: 18| Step: 39
Training loss: 2.760535717010498
Validation loss: 2.6540365322030706
Epoch: 43| Step: 0
Training loss: 2.8013041019439697
Validation loss: 2.6438094351789077
Epoch: 18| Step: 1
Training loss: 3.010659694671631
Validation loss: 2.6599028590771794
Epoch: 18| Step: 2
Training loss: 3.808152198791504
Validation loss: 2.6622693727342344
Epoch: 18| Step: 3
Training loss: 3.0055220127105713
Validation loss: 2.6449379835197395
Epoch: 18| Step: 4
Training loss: 3.666820526123047
Validation loss: 2.625622111258747
Epoch: 18| Step: 5
Training loss: 2.521562099456787
Validation loss: 2.645352087432532
Epoch: 18| Step: 6
Training loss: 3.199850082397461
Validation loss: 2.6423535947319414
Epoch: 18| Step: 7
Training loss: 2.4013864994049072
Validation loss: 2.6574838204349547
Epoch: 18| Step: 8
Training loss: 2.5870161056518555
Validation loss: 2.6479745048413172
Epoch: 18| Step: 9
Training loss: 3.0778210163116455
Validation loss: 2.6648284291191926
Epoch: 18| Step: 10
Training loss: 2.641341209411621
Validation loss: 2.650080337798853
Epoch: 18| Step: 11
Training loss: 3.599010705947876
Validation loss: 2.655564320173195
Epoch: 18| Step: 12
Training loss: 4.266506671905518
Validation loss: 2.637979329061165
Epoch: 18| Step: 13
Training loss: 3.0219221115112305
Validation loss: 2.661321525093463
Epoch: 18| Step: 14
Training loss: 2.624737501144409
Validation loss: 2.630479599932115
Epoch: 18| Step: 15
Training loss: 2.7019155025482178
Validation loss: 2.6263890094894298
Epoch: 18| Step: 16
Training loss: 3.205411911010742
Validation loss: 2.6392457159303073
Epoch: 18| Step: 17
Training loss: 3.3695926666259766
Validation loss: 2.6095939480143486
Epoch: 18| Step: 18
Training loss: 2.8871982097625732
Validation loss: 2.64036027133036
Epoch: 18| Step: 19
Training loss: 3.008212089538574
Validation loss: 2.638820296568836
Epoch: 18| Step: 20
Training loss: 2.2354767322540283
Validation loss: 2.648273341947322
Epoch: 18| Step: 21
Training loss: 4.213940143585205
Validation loss: 2.6598192762127884
Epoch: 18| Step: 22
Training loss: 2.8972556591033936
Validation loss: 2.645724780267949
Epoch: 18| Step: 23
Training loss: 3.1179862022399902
Validation loss: 2.6476224660873413
Epoch: 18| Step: 24
Training loss: 3.4397025108337402
Validation loss: 2.6141961032538106
Epoch: 18| Step: 25
Training loss: 3.780809164047241
Validation loss: 2.637471055812973
Epoch: 18| Step: 26
Training loss: 2.32908296585083
Validation loss: 2.6348372517729834
Epoch: 18| Step: 27
Training loss: 2.1294074058532715
Validation loss: 2.655653414966391
Epoch: 18| Step: 28
Training loss: 3.8146870136260986
Validation loss: 2.652972398044394
Epoch: 18| Step: 29
Training loss: 3.764312505722046
Validation loss: 2.6482252354244533
Epoch: 18| Step: 30
Training loss: 2.7612128257751465
Validation loss: 2.620887117420169
Epoch: 18| Step: 31
Training loss: 3.491786479949951
Validation loss: 2.6292429604976295
Epoch: 18| Step: 32
Training loss: 4.232753753662109
Validation loss: 2.634225538308672
Epoch: 18| Step: 33
Training loss: 3.0068252086639404
Validation loss: 2.6505438012184857
Epoch: 18| Step: 34
Training loss: 2.1140799522399902
Validation loss: 2.6413839103506622
Epoch: 18| Step: 35
Training loss: 3.306621551513672
Validation loss: 2.614304104297281
Epoch: 18| Step: 36
Training loss: 3.5166501998901367
Validation loss: 2.6463464232657454
Epoch: 18| Step: 37
Training loss: 2.0863723754882812
Validation loss: 2.63135170422012
Epoch: 18| Step: 38
Training loss: 4.1955060958862305
Validation loss: 2.6422671688546377
Epoch: 18| Step: 39
Training loss: 3.161360740661621
Validation loss: 2.6283625921757103
Epoch: 44| Step: 0
Training loss: 3.3425493240356445
Validation loss: 2.6382000394862333
Epoch: 18| Step: 1
Training loss: 2.276798725128174
Validation loss: 2.627174086279149
Epoch: 18| Step: 2
Training loss: 2.122480869293213
Validation loss: 2.616537570953369
Epoch: 18| Step: 3
Training loss: 2.5162816047668457
Validation loss: 2.5990947527851134
Epoch: 18| Step: 4
Training loss: 2.335181951522827
Validation loss: 2.6416943999503157
Epoch: 18| Step: 5
Training loss: 4.149447441101074
Validation loss: 2.5958128267054934
Epoch: 18| Step: 6
Training loss: 3.1507461071014404
Validation loss: 2.650173674384467
Epoch: 18| Step: 7
Training loss: 1.8942824602127075
Validation loss: 2.6467285910956293
Epoch: 18| Step: 8
Training loss: 3.7894721031188965
Validation loss: 2.630976061169192
Epoch: 18| Step: 9
Training loss: 4.125336647033691
Validation loss: 2.6333952721931952
Epoch: 18| Step: 10
Training loss: 2.1199982166290283
Validation loss: 2.634542253377626
Epoch: 18| Step: 11
Training loss: 2.570230007171631
Validation loss: 2.610172812029612
Epoch: 18| Step: 12
Training loss: 3.302510976791382
Validation loss: 2.6194968257876607
Epoch: 18| Step: 13
Training loss: 2.9521408081054688
Validation loss: 2.626839852161545
Epoch: 18| Step: 14
Training loss: 3.682145595550537
Validation loss: 2.618556763628404
Epoch: 18| Step: 15
Training loss: 2.1214706897735596
Validation loss: 2.6228703500555572
Epoch: 18| Step: 16
Training loss: 3.846984386444092
Validation loss: 2.6195951159909474
Epoch: 18| Step: 17
Training loss: 2.6900932788848877
Validation loss: 2.6226867274414722
Epoch: 18| Step: 18
Training loss: 2.51853084564209
Validation loss: 2.612506194938001
Epoch: 18| Step: 19
Training loss: 3.048159599304199
Validation loss: 2.6168172882615233
Epoch: 18| Step: 20
Training loss: 2.9145779609680176
Validation loss: 2.649529174077425
Epoch: 18| Step: 21
Training loss: 2.7355453968048096
Validation loss: 2.619462092145741
Epoch: 18| Step: 22
Training loss: 2.766036033630371
Validation loss: 2.642826605186188
Epoch: 18| Step: 23
Training loss: 1.868177890777588
Validation loss: 2.619415056791237
Epoch: 18| Step: 24
Training loss: 4.113372802734375
Validation loss: 2.61191455837634
Epoch: 18| Step: 25
Training loss: 2.818356990814209
Validation loss: 2.635487902936318
Epoch: 18| Step: 26
Training loss: 5.530879020690918
Validation loss: 2.638633678285338
Epoch: 18| Step: 27
Training loss: 3.1094107627868652
Validation loss: 2.6382915253261867
Epoch: 18| Step: 28
Training loss: 4.350099086761475
Validation loss: 2.627237012918047
Epoch: 18| Step: 29
Training loss: 3.4873886108398438
Validation loss: 2.623261287058
Epoch: 18| Step: 30
Training loss: 3.291239023208618
Validation loss: 2.63245343818939
Epoch: 18| Step: 31
Training loss: 3.1768040657043457
Validation loss: 2.6256616321399058
Epoch: 18| Step: 32
Training loss: 2.594639539718628
Validation loss: 2.633025795435734
Epoch: 18| Step: 33
Training loss: 3.4700632095336914
Validation loss: 2.640864696434076
Epoch: 18| Step: 34
Training loss: 3.3578948974609375
Validation loss: 2.626271201552247
Epoch: 18| Step: 35
Training loss: 2.773958206176758
Validation loss: 2.622884530815289
Epoch: 18| Step: 36
Training loss: 3.6926121711730957
Validation loss: 2.6268285418585906
Epoch: 18| Step: 37
Training loss: 2.654529094696045
Validation loss: 2.616059798988507
Epoch: 18| Step: 38
Training loss: 3.331890106201172
Validation loss: 2.626156341686523
Epoch: 18| Step: 39
Training loss: 3.891935348510742
Validation loss: 2.6304573618250786
Epoch: 45| Step: 0
Training loss: 4.272005558013916
Validation loss: 2.6410946762390273
Epoch: 18| Step: 1
Training loss: 3.6557366847991943
Validation loss: 2.619587992592681
Epoch: 18| Step: 2
Training loss: 2.159201145172119
Validation loss: 2.6078901273741137
Epoch: 18| Step: 3
Training loss: 3.098480224609375
Validation loss: 2.634403393422957
Epoch: 18| Step: 4
Training loss: 3.3556594848632812
Validation loss: 2.6188915719231254
Epoch: 18| Step: 5
Training loss: 2.645923614501953
Validation loss: 2.6275737602933704
Epoch: 18| Step: 6
Training loss: 3.430838108062744
Validation loss: 2.6360809597180044
Epoch: 18| Step: 7
Training loss: 2.350151538848877
Validation loss: 2.6332944074123024
Epoch: 18| Step: 8
Training loss: 2.906587839126587
Validation loss: 2.6072543936667683
Epoch: 18| Step: 9
Training loss: 4.810944080352783
Validation loss: 2.6291983573556803
Epoch: 18| Step: 10
Training loss: 3.616565704345703
Validation loss: 2.6490935232999515
Epoch: 18| Step: 11
Training loss: 1.84678316116333
Validation loss: 2.6328843051581075
Epoch: 18| Step: 12
Training loss: 2.767714262008667
Validation loss: 2.636782591291469
Epoch: 18| Step: 13
Training loss: 2.955354928970337
Validation loss: 2.6054848192407074
Epoch: 18| Step: 14
Training loss: 3.0428383350372314
Validation loss: 2.608462572955399
Epoch: 18| Step: 15
Training loss: 3.0565073490142822
Validation loss: 2.6257106057173916
Epoch: 18| Step: 16
Training loss: 2.71006178855896
Validation loss: 2.591122578802726
Epoch: 18| Step: 17
Training loss: 2.7238190174102783
Validation loss: 2.643420396091269
Epoch: 18| Step: 18
Training loss: 3.3241071701049805
Validation loss: 2.6332011874631154
Epoch: 18| Step: 19
Training loss: 3.130133867263794
Validation loss: 2.6165782393311425
Epoch: 18| Step: 20
Training loss: 4.493846416473389
Validation loss: 2.63422054180996
Epoch: 18| Step: 21
Training loss: 3.2358155250549316
Validation loss: 2.62322543164809
Epoch: 18| Step: 22
Training loss: 2.9111390113830566
Validation loss: 2.6282737546687502
Epoch: 18| Step: 23
Training loss: 3.6768252849578857
Validation loss: 2.59880898667754
Epoch: 18| Step: 24
Training loss: 3.017096996307373
Validation loss: 2.6396883743272412
Epoch: 18| Step: 25
Training loss: 2.2966809272766113
Validation loss: 2.6149865894866506
Epoch: 18| Step: 26
Training loss: 2.535984754562378
Validation loss: 2.6320428925452473
Epoch: 18| Step: 27
Training loss: 2.859860897064209
Validation loss: 2.6399948631259176
Epoch: 18| Step: 28
Training loss: 3.962602138519287
Validation loss: 2.6119058852573094
Epoch: 18| Step: 29
Training loss: 3.791746139526367
Validation loss: 2.613980615739342
Epoch: 18| Step: 30
Training loss: 2.175724744796753
Validation loss: 2.609731969215887
Epoch: 18| Step: 31
Training loss: 1.7328648567199707
Validation loss: 2.5990585903469605
Epoch: 18| Step: 32
Training loss: 4.652697563171387
Validation loss: 2.5934150579164355
Epoch: 18| Step: 33
Training loss: 3.584108352661133
Validation loss: 2.6231201775640036
Epoch: 18| Step: 34
Training loss: 2.5345516204833984
Validation loss: 2.615096153115197
Epoch: 18| Step: 35
Training loss: 3.1138579845428467
Validation loss: 2.603227876073165
Epoch: 18| Step: 36
Training loss: 3.5409021377563477
Validation loss: 2.6087264500075964
Epoch: 18| Step: 37
Training loss: 2.444460391998291
Validation loss: 2.637965938170179
Epoch: 18| Step: 38
Training loss: 3.2917168140411377
Validation loss: 2.612758540421081
Epoch: 18| Step: 39
Training loss: 2.4539425373077393
Validation loss: 2.62760629585321
Epoch: 46| Step: 0
Training loss: 3.5751616954803467
Validation loss: 2.617708566377489
Epoch: 18| Step: 1
Training loss: 3.515562057495117
Validation loss: 2.6107377354189647
Epoch: 18| Step: 2
Training loss: 1.950282335281372
Validation loss: 2.6053043475253976
Epoch: 18| Step: 3
Training loss: 3.162876605987549
Validation loss: 2.622453799350656
Epoch: 18| Step: 4
Training loss: 2.880004405975342
Validation loss: 2.6236191773586137
Epoch: 18| Step: 5
Training loss: 3.201995372772217
Validation loss: 2.6249153699806267
Epoch: 18| Step: 6
Training loss: 3.3321237564086914
Validation loss: 2.6240682516166633
Epoch: 18| Step: 7
Training loss: 2.089200496673584
Validation loss: 2.6285705703625575
Epoch: 18| Step: 8
Training loss: 2.299370765686035
Validation loss: 2.60478961553505
Epoch: 18| Step: 9
Training loss: 2.8391504287719727
Validation loss: 2.611804342955994
Epoch: 18| Step: 10
Training loss: 3.1972641944885254
Validation loss: 2.599270362648175
Epoch: 18| Step: 11
Training loss: 3.400078773498535
Validation loss: 2.6022336705983116
Epoch: 18| Step: 12
Training loss: 2.223501682281494
Validation loss: 2.614488591393121
Epoch: 18| Step: 13
Training loss: 2.2034058570861816
Validation loss: 2.62945623020474
Epoch: 18| Step: 14
Training loss: 3.4456686973571777
Validation loss: 2.60673597219179
Epoch: 18| Step: 15
Training loss: 3.773611545562744
Validation loss: 2.59480994811161
Epoch: 18| Step: 16
Training loss: 3.8804149627685547
Validation loss: 2.6095964291112885
Epoch: 18| Step: 17
Training loss: 3.5000858306884766
Validation loss: 2.6168901182764728
Epoch: 18| Step: 18
Training loss: 4.59090518951416
Validation loss: 2.6176197949073297
Epoch: 18| Step: 19
Training loss: 2.4463675022125244
Validation loss: 2.635295297602098
Epoch: 18| Step: 20
Training loss: 3.207244396209717
Validation loss: 2.618473561547643
Epoch: 18| Step: 21
Training loss: 2.7666921615600586
Validation loss: 2.62725070569155
Epoch: 18| Step: 22
Training loss: 3.298349618911743
Validation loss: 2.6205818670259107
Epoch: 18| Step: 23
Training loss: 2.7407071590423584
Validation loss: 2.634102581216277
Epoch: 18| Step: 24
Training loss: 2.948695182800293
Validation loss: 2.612322748993798
Epoch: 18| Step: 25
Training loss: 3.690598964691162
Validation loss: 2.586694966117255
Epoch: 18| Step: 26
Training loss: 2.7382144927978516
Validation loss: 2.6119892477131574
Epoch: 18| Step: 27
Training loss: 3.1710410118103027
Validation loss: 2.623695479880134
Epoch: 18| Step: 28
Training loss: 3.8216402530670166
Validation loss: 2.6142130446948593
Epoch: 18| Step: 29
Training loss: 3.8447587490081787
Validation loss: 2.6215091506354242
Epoch: 18| Step: 30
Training loss: 3.955003023147583
Validation loss: 2.6131010861705533
Epoch: 18| Step: 31
Training loss: 2.7593090534210205
Validation loss: 2.608962698806104
Epoch: 18| Step: 32
Training loss: 2.1897454261779785
Validation loss: 2.612889310438856
Epoch: 18| Step: 33
Training loss: 2.463992118835449
Validation loss: 2.6217417614065486
Epoch: 18| Step: 34
Training loss: 3.6891112327575684
Validation loss: 2.5981698276327667
Epoch: 18| Step: 35
Training loss: 2.715156316757202
Validation loss: 2.6128033013652554
Epoch: 18| Step: 36
Training loss: 3.510432481765747
Validation loss: 2.596404989846319
Epoch: 18| Step: 37
Training loss: 2.764191150665283
Validation loss: 2.5993782822176708
Epoch: 18| Step: 38
Training loss: 3.9030513763427734
Validation loss: 2.5994438799165134
Epoch: 18| Step: 39
Training loss: 2.742382526397705
Validation loss: 2.6128933446870435
Epoch: 47| Step: 0
Training loss: 3.967318296432495
Validation loss: 2.6063203674426183
Epoch: 18| Step: 1
Training loss: 3.12929630279541
Validation loss: 2.618334315663619
Epoch: 18| Step: 2
Training loss: 2.6904726028442383
Validation loss: 2.6192323226722882
Epoch: 18| Step: 3
Training loss: 3.3349533081054688
Validation loss: 2.611097464458548
Epoch: 18| Step: 4
Training loss: 3.314788341522217
Validation loss: 2.5958924859547787
Epoch: 18| Step: 5
Training loss: 2.763979911804199
Validation loss: 2.6091490254985343
Epoch: 18| Step: 6
Training loss: 3.5284583568573
Validation loss: 2.607330387444805
Epoch: 18| Step: 7
Training loss: 2.839101791381836
Validation loss: 2.613705828893099
Epoch: 18| Step: 8
Training loss: 3.1691627502441406
Validation loss: 2.598819031132211
Epoch: 18| Step: 9
Training loss: 3.815516948699951
Validation loss: 2.5877950260107467
Epoch: 18| Step: 10
Training loss: 2.9411652088165283
Validation loss: 2.6155138770453363
Epoch: 18| Step: 11
Training loss: 2.446455240249634
Validation loss: 2.5919405522106365
Epoch: 18| Step: 12
Training loss: 3.203571319580078
Validation loss: 2.6121758840066924
Epoch: 18| Step: 13
Training loss: 2.8229730129241943
Validation loss: 2.6100468223901103
Epoch: 18| Step: 14
Training loss: 4.735248565673828
Validation loss: 2.5894189592745662
Epoch: 18| Step: 15
Training loss: 3.092954397201538
Validation loss: 2.6024137572418873
Epoch: 18| Step: 16
Training loss: 2.904327630996704
Validation loss: 2.6021034477425995
Epoch: 18| Step: 17
Training loss: 2.9732093811035156
Validation loss: 2.608611636024585
Epoch: 18| Step: 18
Training loss: 2.832146167755127
Validation loss: 2.6120431268815514
Epoch: 18| Step: 19
Training loss: 3.8233261108398438
Validation loss: 2.617764342603066
Epoch: 18| Step: 20
Training loss: 2.547886371612549
Validation loss: 2.6034157310458395
Epoch: 18| Step: 21
Training loss: 2.465054512023926
Validation loss: 2.61563925948932
Epoch: 18| Step: 22
Training loss: 2.5001490116119385
Validation loss: 2.597004579983169
Epoch: 18| Step: 23
Training loss: 2.4274063110351562
Validation loss: 2.608023607473579
Epoch: 18| Step: 24
Training loss: 2.272355556488037
Validation loss: 2.6049595633856684
Epoch: 18| Step: 25
Training loss: 3.7018237113952637
Validation loss: 2.5815850684968686
Epoch: 18| Step: 26
Training loss: 4.282130241394043
Validation loss: 2.604439430957218
Epoch: 18| Step: 27
Training loss: 1.7404600381851196
Validation loss: 2.592980413128146
Epoch: 18| Step: 28
Training loss: 3.016122341156006
Validation loss: 2.58420422780428
Epoch: 18| Step: 29
Training loss: 3.1042959690093994
Validation loss: 2.5952189251673308
Epoch: 18| Step: 30
Training loss: 3.1579079627990723
Validation loss: 2.601067158815672
Epoch: 18| Step: 31
Training loss: 3.463343620300293
Validation loss: 2.6174960016346662
Epoch: 18| Step: 32
Training loss: 2.7574214935302734
Validation loss: 2.5965651728266437
Epoch: 18| Step: 33
Training loss: 4.192667007446289
Validation loss: 2.582174438366787
Epoch: 18| Step: 34
Training loss: 2.6633405685424805
Validation loss: 2.590531530997736
Epoch: 18| Step: 35
Training loss: 3.8190340995788574
Validation loss: 2.6134591046854747
Epoch: 18| Step: 36
Training loss: 2.3345673084259033
Validation loss: 2.616047848900445
Epoch: 18| Step: 37
Training loss: 2.886746406555176
Validation loss: 2.5957816101664264
Epoch: 18| Step: 38
Training loss: 3.3229312896728516
Validation loss: 2.621357264278604
Epoch: 18| Step: 39
Training loss: 2.713928699493408
Validation loss: 2.595128294375303
Epoch: 48| Step: 0
Training loss: 2.71524715423584
Validation loss: 2.6025192754731763
Epoch: 18| Step: 1
Training loss: 4.395637512207031
Validation loss: 2.603375347398168
Epoch: 18| Step: 2
Training loss: 4.196916580200195
Validation loss: 2.5992363219638523
Epoch: 18| Step: 3
Training loss: 1.725653886795044
Validation loss: 2.609462228610361
Epoch: 18| Step: 4
Training loss: 2.2691962718963623
Validation loss: 2.5666383787882414
Epoch: 18| Step: 5
Training loss: 3.4095144271850586
Validation loss: 2.616827652608748
Epoch: 18| Step: 6
Training loss: 3.053097724914551
Validation loss: 2.590287208557129
Epoch: 18| Step: 7
Training loss: 2.515195846557617
Validation loss: 2.6098912225352775
Epoch: 18| Step: 8
Training loss: 2.9350876808166504
Validation loss: 2.5735538914906892
Epoch: 18| Step: 9
Training loss: 3.1007609367370605
Validation loss: 2.612243208096182
Epoch: 18| Step: 10
Training loss: 4.51344108581543
Validation loss: 2.62487009446398
Epoch: 18| Step: 11
Training loss: 2.7039871215820312
Validation loss: 2.5871690657499027
Epoch: 18| Step: 12
Training loss: 2.8421263694763184
Validation loss: 2.594005063283358
Epoch: 18| Step: 13
Training loss: 3.02070951461792
Validation loss: 2.589735483951706
Epoch: 18| Step: 14
Training loss: 3.84448504447937
Validation loss: 2.588297492308582
Epoch: 18| Step: 15
Training loss: 2.273446559906006
Validation loss: 2.5969021165971276
Epoch: 18| Step: 16
Training loss: 3.5087244510650635
Validation loss: 2.5942424389955807
Epoch: 18| Step: 17
Training loss: 3.3328590393066406
Validation loss: 2.597632841240588
Epoch: 18| Step: 18
Training loss: 4.212902069091797
Validation loss: 2.581532967176369
Epoch: 18| Step: 19
Training loss: 3.0701537132263184
Validation loss: 2.5970674641698386
Epoch: 18| Step: 20
Training loss: 2.9221620559692383
Validation loss: 2.6100606858301507
Epoch: 18| Step: 21
Training loss: 2.3450162410736084
Validation loss: 2.566309386877705
Epoch: 18| Step: 22
Training loss: 2.3708319664001465
Validation loss: 2.5947800094275166
Epoch: 18| Step: 23
Training loss: 2.2666211128234863
Validation loss: 2.5878775479982226
Epoch: 18| Step: 24
Training loss: 3.766598701477051
Validation loss: 2.5870470769113774
Epoch: 18| Step: 25
Training loss: 2.026357412338257
Validation loss: 2.591771546027643
Epoch: 18| Step: 26
Training loss: 4.183223724365234
Validation loss: 2.603450625920467
Epoch: 18| Step: 27
Training loss: 3.7766857147216797
Validation loss: 2.620853848594556
Epoch: 18| Step: 28
Training loss: 2.833630084991455
Validation loss: 2.59985130639385
Epoch: 18| Step: 29
Training loss: 2.73532772064209
Validation loss: 2.5950001949886623
Epoch: 18| Step: 30
Training loss: 3.2935380935668945
Validation loss: 2.5828774730078607
Epoch: 18| Step: 31
Training loss: 2.8867390155792236
Validation loss: 2.589900311806219
Epoch: 18| Step: 32
Training loss: 3.1716368198394775
Validation loss: 2.5792844792921765
Epoch: 18| Step: 33
Training loss: 3.2198901176452637
Validation loss: 2.609020760591082
Epoch: 18| Step: 34
Training loss: 2.2210946083068848
Validation loss: 2.6054014267681316
Epoch: 18| Step: 35
Training loss: 2.4122884273529053
Validation loss: 2.5917458877289037
Epoch: 18| Step: 36
Training loss: 2.83083176612854
Validation loss: 2.585229296478436
Epoch: 18| Step: 37
Training loss: 3.629298448562622
Validation loss: 2.604313817813242
Epoch: 18| Step: 38
Training loss: 3.277440071105957
Validation loss: 2.60945418584261
Epoch: 18| Step: 39
Training loss: 3.948420286178589
Validation loss: 2.598197352971962
Epoch: 49| Step: 0
Training loss: 2.917259931564331
Validation loss: 2.6002678030686415
Epoch: 18| Step: 1
Training loss: 3.520570755004883
Validation loss: 2.5874083127906853
Epoch: 18| Step: 2
Training loss: 3.522258996963501
Validation loss: 2.594857955150467
Epoch: 18| Step: 3
Training loss: 3.801424980163574
Validation loss: 2.598914028071671
Epoch: 18| Step: 4
Training loss: 2.6989216804504395
Validation loss: 2.599470136834563
Epoch: 18| Step: 5
Training loss: 3.316659688949585
Validation loss: 2.6051446962699614
Epoch: 18| Step: 6
Training loss: 3.845174551010132
Validation loss: 2.578959722313092
Epoch: 18| Step: 7
Training loss: 2.744947671890259
Validation loss: 2.5864299767308956
Epoch: 18| Step: 8
Training loss: 2.1937272548675537
Validation loss: 2.6101796232539116
Epoch: 18| Step: 9
Training loss: 5.371158599853516
Validation loss: 2.600274326132356
Epoch: 18| Step: 10
Training loss: 3.1030092239379883
Validation loss: 2.602416216040687
Epoch: 18| Step: 11
Training loss: 2.2314019203186035
Validation loss: 2.5709201140369444
Epoch: 18| Step: 12
Training loss: 2.210880994796753
Validation loss: 2.5680251498874145
Epoch: 18| Step: 13
Training loss: 3.2418606281280518
Validation loss: 2.5933500313930375
Epoch: 18| Step: 14
Training loss: 3.1328396797180176
Validation loss: 2.6063884693941626
Epoch: 18| Step: 15
Training loss: 2.157153367996216
Validation loss: 2.590770150260102
Epoch: 18| Step: 16
Training loss: 2.54815411567688
Validation loss: 2.601587545957497
Epoch: 18| Step: 17
Training loss: 2.6040267944335938
Validation loss: 2.5952202982182127
Epoch: 18| Step: 18
Training loss: 2.497317314147949
Validation loss: 2.597126971045844
Epoch: 18| Step: 19
Training loss: 3.040095090866089
Validation loss: 2.5987684829629583
Epoch: 18| Step: 20
Training loss: 2.9034476280212402
Validation loss: 2.593611621170593
Epoch: 18| Step: 21
Training loss: 3.030672550201416
Validation loss: 2.5809099980824284
Epoch: 18| Step: 22
Training loss: 2.3793816566467285
Validation loss: 2.5938575284944165
Epoch: 18| Step: 23
Training loss: 3.531811237335205
Validation loss: 2.598421180848595
Epoch: 18| Step: 24
Training loss: 3.7439393997192383
Validation loss: 2.576746973202383
Epoch: 18| Step: 25
Training loss: 2.4058942794799805
Validation loss: 2.582689744105442
Epoch: 18| Step: 26
Training loss: 2.47705078125
Validation loss: 2.59328167558574
Epoch: 18| Step: 27
Training loss: 3.5930733680725098
Validation loss: 2.5818738105485766
Epoch: 18| Step: 28
Training loss: 3.6271591186523438
Validation loss: 2.570527083582158
Epoch: 18| Step: 29
Training loss: 3.316164970397949
Validation loss: 2.5722898853768545
Epoch: 18| Step: 30
Training loss: 2.4999160766601562
Validation loss: 2.5871535651117776
Epoch: 18| Step: 31
Training loss: 2.920236825942993
Validation loss: 2.593343323940853
Epoch: 18| Step: 32
Training loss: 3.9029433727264404
Validation loss: 2.5910525390570114
Epoch: 18| Step: 33
Training loss: 3.199859619140625
Validation loss: 2.580425193841509
Epoch: 18| Step: 34
Training loss: 3.6072890758514404
Validation loss: 2.5901591692039436
Epoch: 18| Step: 35
Training loss: 2.8501267433166504
Validation loss: 2.5838774245419946
Epoch: 18| Step: 36
Training loss: 2.4842684268951416
Validation loss: 2.59388952461078
Epoch: 18| Step: 37
Training loss: 3.50405216217041
Validation loss: 2.5849704879650965
Epoch: 18| Step: 38
Training loss: 2.198925018310547
Validation loss: 2.5784069505526865
Epoch: 18| Step: 39
Training loss: 3.821967124938965
Validation loss: 2.6044678928183136
Epoch: 50| Step: 0
Training loss: 3.533905029296875
Validation loss: 2.588857974937494
Epoch: 18| Step: 1
Training loss: 3.2352914810180664
Validation loss: 2.595142801888555
Epoch: 18| Step: 2
Training loss: 3.130483627319336
Validation loss: 2.597793966746159
Epoch: 18| Step: 3
Training loss: 3.533031940460205
Validation loss: 2.589785973802745
Epoch: 18| Step: 4
Training loss: 3.9691736698150635
Validation loss: 2.600578055964957
Epoch: 18| Step: 5
Training loss: 2.534440517425537
Validation loss: 2.583042139629666
Epoch: 18| Step: 6
Training loss: 3.5554370880126953
Validation loss: 2.6065289974212646
Epoch: 18| Step: 7
Training loss: 4.372755527496338
Validation loss: 2.5853441910778017
Epoch: 18| Step: 8
Training loss: 2.574108362197876
Validation loss: 2.603799132134417
Epoch: 18| Step: 9
Training loss: 3.3175768852233887
Validation loss: 2.559948991528518
Epoch: 18| Step: 10
Training loss: 3.1423892974853516
Validation loss: 2.593245158950202
Epoch: 18| Step: 11
Training loss: 2.1832008361816406
Validation loss: 2.5707355711957534
Epoch: 18| Step: 12
Training loss: 1.2890846729278564
Validation loss: 2.595538199376717
Epoch: 18| Step: 13
Training loss: 2.0909149646759033
Validation loss: 2.576022427716701
Epoch: 18| Step: 14
Training loss: 1.4139699935913086
Validation loss: 2.573488828947218
Epoch: 18| Step: 15
Training loss: 4.290928363800049
Validation loss: 2.588206860658934
Epoch: 18| Step: 16
Training loss: 3.035304307937622
Validation loss: 2.57183667052564
Epoch: 18| Step: 17
Training loss: 2.5736746788024902
Validation loss: 2.5832330906133856
Epoch: 18| Step: 18
Training loss: 2.854644298553467
Validation loss: 2.576573713220281
Epoch: 18| Step: 19
Training loss: 2.140126943588257
Validation loss: 2.6028039867071797
Epoch: 18| Step: 20
Training loss: 4.5639238357543945
Validation loss: 2.5778445545717967
Epoch: 18| Step: 21
Training loss: 3.8955626487731934
Validation loss: 2.6019104264622968
Epoch: 18| Step: 22
Training loss: 3.061025619506836
Validation loss: 2.5820876196991627
Epoch: 18| Step: 23
Training loss: 2.736660957336426
Validation loss: 2.6050501821710053
Epoch: 18| Step: 24
Training loss: 3.3812267780303955
Validation loss: 2.5773977187040042
Epoch: 18| Step: 25
Training loss: 3.021352529525757
Validation loss: 2.5724603066341483
Epoch: 18| Step: 26
Training loss: 1.8108844757080078
Validation loss: 2.6031994322221057
Epoch: 18| Step: 27
Training loss: 2.2715251445770264
Validation loss: 2.5936669943143995
Epoch: 18| Step: 28
Training loss: 3.446852207183838
Validation loss: 2.5816470976356123
Epoch: 18| Step: 29
Training loss: 2.974061965942383
Validation loss: 2.5800369763545854
Epoch: 18| Step: 30
Training loss: 3.584209442138672
Validation loss: 2.584337967762844
Epoch: 18| Step: 31
Training loss: 2.740339756011963
Validation loss: 2.580818015036823
Epoch: 18| Step: 32
Training loss: 3.4470343589782715
Validation loss: 2.5920016336784086
Epoch: 18| Step: 33
Training loss: 3.8808236122131348
Validation loss: 2.5840658335376987
Epoch: 18| Step: 34
Training loss: 3.538191795349121
Validation loss: 2.5659586697173635
Epoch: 18| Step: 35
Training loss: 3.2819180488586426
Validation loss: 2.5877792509339694
Epoch: 18| Step: 36
Training loss: 3.9117023944854736
Validation loss: 2.590925964520132
Epoch: 18| Step: 37
Training loss: 2.340010166168213
Validation loss: 2.5720507532572574
Epoch: 18| Step: 38
Training loss: 2.8094208240509033
Validation loss: 2.586114651865239
Epoch: 18| Step: 39
Training loss: 3.038633346557617
Validation loss: 2.5962394947628322
Epoch: 51| Step: 0
Training loss: 4.4674835205078125
Validation loss: 2.5766432456832997
Epoch: 18| Step: 1
Training loss: 3.4829654693603516
Validation loss: 2.5946863160716545
Epoch: 18| Step: 2
Training loss: 3.8449621200561523
Validation loss: 2.562166756005596
Epoch: 18| Step: 3
Training loss: 3.05751895904541
Validation loss: 2.5629732968995897
Epoch: 18| Step: 4
Training loss: 4.154059410095215
Validation loss: 2.5754636088721186
Epoch: 18| Step: 5
Training loss: 3.7664942741394043
Validation loss: 2.572399816495909
Epoch: 18| Step: 6
Training loss: 3.324265956878662
Validation loss: 2.5987576130482792
Epoch: 18| Step: 7
Training loss: 3.150928020477295
Validation loss: 2.591481494388992
Epoch: 18| Step: 8
Training loss: 3.411130905151367
Validation loss: 2.600229539459558
Epoch: 18| Step: 9
Training loss: 3.4342262744903564
Validation loss: 2.5661977692473705
Epoch: 18| Step: 10
Training loss: 3.539700984954834
Validation loss: 2.5829947543658798
Epoch: 18| Step: 11
Training loss: 2.743027448654175
Validation loss: 2.568374993132173
Epoch: 18| Step: 12
Training loss: 2.1956911087036133
Validation loss: 2.5662395902674833
Epoch: 18| Step: 13
Training loss: 2.8724660873413086
Validation loss: 2.5659911049355704
Epoch: 18| Step: 14
Training loss: 2.963350534439087
Validation loss: 2.548771032326513
Epoch: 18| Step: 15
Training loss: 3.0771121978759766
Validation loss: 2.567813664031543
Epoch: 18| Step: 16
Training loss: 3.207789421081543
Validation loss: 2.572965481298433
Epoch: 18| Step: 17
Training loss: 4.002447605133057
Validation loss: 2.5679582734759765
Epoch: 18| Step: 18
Training loss: 2.7927186489105225
Validation loss: 2.582928747153111
Epoch: 18| Step: 19
Training loss: 3.052210807800293
Validation loss: 2.5587428593807084
Epoch: 18| Step: 20
Training loss: 2.659478187561035
Validation loss: 2.594216806425465
Epoch: 18| Step: 21
Training loss: 1.9516611099243164
Validation loss: 2.5661981225871355
Epoch: 18| Step: 22
Training loss: 2.6271748542785645
Validation loss: 2.5826236824337525
Epoch: 18| Step: 23
Training loss: 2.7885611057281494
Validation loss: 2.5882536027071286
Epoch: 18| Step: 24
Training loss: 2.522301197052002
Validation loss: 2.583636942527277
Epoch: 18| Step: 25
Training loss: 2.7930688858032227
Validation loss: 2.5857834048408397
Epoch: 18| Step: 26
Training loss: 4.425546169281006
Validation loss: 2.593500974366991
Epoch: 18| Step: 27
Training loss: 3.2360522747039795
Validation loss: 2.5736598299561644
Epoch: 18| Step: 28
Training loss: 3.251990795135498
Validation loss: 2.581181870947639
Epoch: 18| Step: 29
Training loss: 3.145941734313965
Validation loss: 2.5484112321044043
Epoch: 18| Step: 30
Training loss: 2.700047492980957
Validation loss: 2.581832892603154
Epoch: 18| Step: 31
Training loss: 2.1920931339263916
Validation loss: 2.5623073303442205
Epoch: 18| Step: 32
Training loss: 2.799715042114258
Validation loss: 2.5839358902663636
Epoch: 18| Step: 33
Training loss: 2.674649953842163
Validation loss: 2.571517728215499
Epoch: 18| Step: 34
Training loss: 2.315711736679077
Validation loss: 2.570257658581082
Epoch: 18| Step: 35
Training loss: 2.3603897094726562
Validation loss: 2.5813834367038533
Epoch: 18| Step: 36
Training loss: 2.910322904586792
Validation loss: 2.562484310685302
Epoch: 18| Step: 37
Training loss: 3.4044370651245117
Validation loss: 2.5970876997323344
Epoch: 18| Step: 38
Training loss: 3.0014841556549072
Validation loss: 2.5711690298944925
Epoch: 18| Step: 39
Training loss: 2.5135655403137207
Validation loss: 2.578579051889104
Epoch: 52| Step: 0
Training loss: 3.017988443374634
Validation loss: 2.5797191858291626
Epoch: 18| Step: 1
Training loss: 2.8300297260284424
Validation loss: 2.5960939084883217
Epoch: 18| Step: 2
Training loss: 2.814943790435791
Validation loss: 2.5816527510718474
Epoch: 18| Step: 3
Training loss: 3.448387622833252
Validation loss: 2.5922734462957586
Epoch: 18| Step: 4
Training loss: 2.7027196884155273
Validation loss: 2.561475602842921
Epoch: 18| Step: 5
Training loss: 3.967395305633545
Validation loss: 2.5626675585191028
Epoch: 18| Step: 6
Training loss: 2.5919337272644043
Validation loss: 2.560894778306536
Epoch: 18| Step: 7
Training loss: 3.4712023735046387
Validation loss: 2.5745159867856144
Epoch: 18| Step: 8
Training loss: 3.4995555877685547
Validation loss: 2.590373250220319
Epoch: 18| Step: 9
Training loss: 3.532806873321533
Validation loss: 2.5798753920218926
Epoch: 18| Step: 10
Training loss: 2.900753974914551
Validation loss: 2.5697759415605943
Epoch: 18| Step: 11
Training loss: 1.8643672466278076
Validation loss: 2.570958400801789
Epoch: 18| Step: 12
Training loss: 3.6117444038391113
Validation loss: 2.5763184629755913
Epoch: 18| Step: 13
Training loss: 2.7850565910339355
Validation loss: 2.575051921734707
Epoch: 18| Step: 14
Training loss: 2.510629892349243
Validation loss: 2.566150771628181
Epoch: 18| Step: 15
Training loss: 3.2990002632141113
Validation loss: 2.5522640763426856
Epoch: 18| Step: 16
Training loss: 2.3406503200531006
Validation loss: 2.56010257768974
Epoch: 18| Step: 17
Training loss: 3.559638738632202
Validation loss: 2.568036376143531
Epoch: 18| Step: 18
Training loss: 2.7901451587677
Validation loss: 2.5476323597722774
Epoch: 18| Step: 19
Training loss: 2.8507399559020996
Validation loss: 2.585567868870797
Epoch: 18| Step: 20
Training loss: 4.4631171226501465
Validation loss: 2.5649084581745614
Epoch: 18| Step: 21
Training loss: 3.3030147552490234
Validation loss: 2.5750509560536994
Epoch: 18| Step: 22
Training loss: 2.8346805572509766
Validation loss: 2.5726005919545676
Epoch: 18| Step: 23
Training loss: 3.07179594039917
Validation loss: 2.5786309765397215
Epoch: 18| Step: 24
Training loss: 2.7044711112976074
Validation loss: 2.546113950743092
Epoch: 18| Step: 25
Training loss: 3.243271589279175
Validation loss: 2.5892632659390675
Epoch: 18| Step: 26
Training loss: 1.5169808864593506
Validation loss: 2.588616576983774
Epoch: 18| Step: 27
Training loss: 3.52022123336792
Validation loss: 2.5500996001332785
Epoch: 18| Step: 28
Training loss: 3.2946994304656982
Validation loss: 2.5862556498685327
Epoch: 18| Step: 29
Training loss: 2.3503427505493164
Validation loss: 2.578990191006832
Epoch: 18| Step: 30
Training loss: 3.608241558074951
Validation loss: 2.572585167644693
Epoch: 18| Step: 31
Training loss: 3.367922067642212
Validation loss: 2.545613400370097
Epoch: 18| Step: 32
Training loss: 2.6068148612976074
Validation loss: 2.5641949116754876
Epoch: 18| Step: 33
Training loss: 3.0721230506896973
Validation loss: 2.5681838165941855
Epoch: 18| Step: 34
Training loss: 3.4641122817993164
Validation loss: 2.5601921167305046
Epoch: 18| Step: 35
Training loss: 2.8999550342559814
Validation loss: 2.5559239833475016
Epoch: 18| Step: 36
Training loss: 4.102261543273926
Validation loss: 2.5591410098316
Epoch: 18| Step: 37
Training loss: 2.5219757556915283
Validation loss: 2.5740824894939394
Epoch: 18| Step: 38
Training loss: 3.9678964614868164
Validation loss: 2.587915370790221
Epoch: 18| Step: 39
Training loss: 1.9166882038116455
Validation loss: 2.5373350493341897
Epoch: 53| Step: 0
Training loss: 2.703878402709961
Validation loss: 2.5777760563994483
Epoch: 18| Step: 1
Training loss: 2.910352945327759
Validation loss: 2.538132525176453
Epoch: 18| Step: 2
Training loss: 3.3310062885284424
Validation loss: 2.59387454026037
Epoch: 18| Step: 3
Training loss: 3.502741813659668
Validation loss: 2.5629047772867217
Epoch: 18| Step: 4
Training loss: 3.2150564193725586
Validation loss: 2.579917274790702
Epoch: 18| Step: 5
Training loss: 2.4573376178741455
Validation loss: 2.567634608248155
Epoch: 18| Step: 6
Training loss: 2.134110927581787
Validation loss: 2.5612208397268392
Epoch: 18| Step: 7
Training loss: 2.485598564147949
Validation loss: 2.5683849604009725
Epoch: 18| Step: 8
Training loss: 3.450948715209961
Validation loss: 2.5657179029725437
Epoch: 18| Step: 9
Training loss: 3.708188533782959
Validation loss: 2.5647258844307
Epoch: 18| Step: 10
Training loss: 3.3102126121520996
Validation loss: 2.5435079250404304
Epoch: 18| Step: 11
Training loss: 3.1346631050109863
Validation loss: 2.5734379325839254
Epoch: 18| Step: 12
Training loss: 2.4865806102752686
Validation loss: 2.5427814241793514
Epoch: 18| Step: 13
Training loss: 3.061211585998535
Validation loss: 2.5837772904540137
Epoch: 18| Step: 14
Training loss: 2.3958683013916016
Validation loss: 2.562173908562969
Epoch: 18| Step: 15
Training loss: 3.36077618598938
Validation loss: 2.557015919856888
Epoch: 18| Step: 16
Training loss: 3.0654897689819336
Validation loss: 2.5635682421622517
Epoch: 18| Step: 17
Training loss: 4.714789390563965
Validation loss: 2.53738921837841
Epoch: 18| Step: 18
Training loss: 3.2817935943603516
Validation loss: 2.578050321812252
Epoch: 18| Step: 19
Training loss: 3.3494467735290527
Validation loss: 2.5731030316661587
Epoch: 18| Step: 20
Training loss: 2.994400978088379
Validation loss: 2.5741927915339846
Epoch: 18| Step: 21
Training loss: 2.6091766357421875
Validation loss: 2.5775839630648387
Epoch: 18| Step: 22
Training loss: 2.4977924823760986
Validation loss: 2.5660911069499504
Epoch: 18| Step: 23
Training loss: 3.4602813720703125
Validation loss: 2.530728027974959
Epoch: 18| Step: 24
Training loss: 3.0051956176757812
Validation loss: 2.5643568665003604
Epoch: 18| Step: 25
Training loss: 2.894436836242676
Validation loss: 2.5565123866787918
Epoch: 18| Step: 26
Training loss: 3.8408217430114746
Validation loss: 2.566261588240699
Epoch: 18| Step: 27
Training loss: 3.4331963062286377
Validation loss: 2.5471840505119707
Epoch: 18| Step: 28
Training loss: 2.0888166427612305
Validation loss: 2.55802367145209
Epoch: 18| Step: 29
Training loss: 3.317856550216675
Validation loss: 2.5583894389996424
Epoch: 18| Step: 30
Training loss: 2.6508402824401855
Validation loss: 2.5716604123012625
Epoch: 18| Step: 31
Training loss: 3.1762442588806152
Validation loss: 2.5634363589526936
Epoch: 18| Step: 32
Training loss: 3.804967164993286
Validation loss: 2.5709733208306402
Epoch: 18| Step: 33
Training loss: 2.0957047939300537
Validation loss: 2.557803044645049
Epoch: 18| Step: 34
Training loss: 2.6383299827575684
Validation loss: 2.576342937757643
Epoch: 18| Step: 35
Training loss: 2.824692726135254
Validation loss: 2.574025346220826
Epoch: 18| Step: 36
Training loss: 3.000309705734253
Validation loss: 2.5612871441052114
Epoch: 18| Step: 37
Training loss: 4.282374382019043
Validation loss: 2.5661112370250896
Epoch: 18| Step: 38
Training loss: 2.0220155715942383
Validation loss: 2.560838843849923
Epoch: 18| Step: 39
Training loss: 3.8363378047943115
Validation loss: 2.5777476382770126
Epoch: 54| Step: 0
Training loss: 4.100678443908691
Validation loss: 2.5493517230740554
Epoch: 18| Step: 1
Training loss: 3.254523277282715
Validation loss: 2.5533763967829644
Epoch: 18| Step: 2
Training loss: 2.4945247173309326
Validation loss: 2.5455539003550576
Epoch: 18| Step: 3
Training loss: 3.6126160621643066
Validation loss: 2.5714702297457688
Epoch: 18| Step: 4
Training loss: 2.9739632606506348
Validation loss: 2.548556514781156
Epoch: 18| Step: 5
Training loss: 2.424802303314209
Validation loss: 2.563479314605109
Epoch: 18| Step: 6
Training loss: 3.048583745956421
Validation loss: 2.5720092932954968
Epoch: 18| Step: 7
Training loss: 2.5393660068511963
Validation loss: 2.583233963671348
Epoch: 18| Step: 8
Training loss: 2.7159347534179688
Validation loss: 2.5860980328896064
Epoch: 18| Step: 9
Training loss: 3.3506100177764893
Validation loss: 2.578821115356555
Epoch: 18| Step: 10
Training loss: 2.620802879333496
Validation loss: 2.5471735961145634
Epoch: 18| Step: 11
Training loss: 2.3142080307006836
Validation loss: 2.54717340743799
Epoch: 18| Step: 12
Training loss: 3.4404070377349854
Validation loss: 2.5627822378556506
Epoch: 18| Step: 13
Training loss: 2.4135568141937256
Validation loss: 2.5610192525301048
Epoch: 18| Step: 14
Training loss: 2.082038640975952
Validation loss: 2.5594075540844483
Epoch: 18| Step: 15
Training loss: 4.723993301391602
Validation loss: 2.5669525681639747
Epoch: 18| Step: 16
Training loss: 2.8816847801208496
Validation loss: 2.5793060810445883
Epoch: 18| Step: 17
Training loss: 3.9905755519866943
Validation loss: 2.5664905301100918
Epoch: 18| Step: 18
Training loss: 2.3608717918395996
Validation loss: 2.5597286601718383
Epoch: 18| Step: 19
Training loss: 2.9434022903442383
Validation loss: 2.5476733892084025
Epoch: 18| Step: 20
Training loss: 3.5496678352355957
Validation loss: 2.539586743862509
Epoch: 18| Step: 21
Training loss: 3.549224853515625
Validation loss: 2.564155425956781
Epoch: 18| Step: 22
Training loss: 2.6463406085968018
Validation loss: 2.5698143269518297
Epoch: 18| Step: 23
Training loss: 3.460059881210327
Validation loss: 2.5489029764271467
Epoch: 18| Step: 24
Training loss: 2.3788795471191406
Validation loss: 2.5564083452705
Epoch: 18| Step: 25
Training loss: 1.436624526977539
Validation loss: 2.57448629681155
Epoch: 18| Step: 26
Training loss: 3.6012768745422363
Validation loss: 2.5602096490722768
Epoch: 18| Step: 27
Training loss: 3.671158790588379
Validation loss: 2.5775277871879743
Epoch: 18| Step: 28
Training loss: 3.5480194091796875
Validation loss: 2.5420748818692545
Epoch: 18| Step: 29
Training loss: 2.771225929260254
Validation loss: 2.52878573129503
Epoch: 18| Step: 30
Training loss: 2.791071891784668
Validation loss: 2.571915973862298
Epoch: 18| Step: 31
Training loss: 2.658550262451172
Validation loss: 2.576955971957968
Epoch: 18| Step: 32
Training loss: 2.4077329635620117
Validation loss: 2.558599017506881
Epoch: 18| Step: 33
Training loss: 3.0495176315307617
Validation loss: 2.5444258978898575
Epoch: 18| Step: 34
Training loss: 2.7699484825134277
Validation loss: 2.5676432170456263
Epoch: 18| Step: 35
Training loss: 3.2100017070770264
Validation loss: 2.561307818769551
Epoch: 18| Step: 36
Training loss: 3.241156578063965
Validation loss: 2.559591209288124
Epoch: 18| Step: 37
Training loss: 5.139510154724121
Validation loss: 2.5369712568873126
Epoch: 18| Step: 38
Training loss: 3.1047887802124023
Validation loss: 2.562845104889904
Epoch: 18| Step: 39
Training loss: 2.7711219787597656
Validation loss: 2.5530346520513083
Epoch: 55| Step: 0
Training loss: 2.128626823425293
Validation loss: 2.533729031789217
Epoch: 18| Step: 1
Training loss: 3.6047492027282715
Validation loss: 2.5685137347351734
Epoch: 18| Step: 2
Training loss: 1.8647706508636475
Validation loss: 2.5619590402507098
Epoch: 18| Step: 3
Training loss: 3.636629581451416
Validation loss: 2.565382261070416
Epoch: 18| Step: 4
Training loss: 4.521581649780273
Validation loss: 2.5581745655416586
Epoch: 18| Step: 5
Training loss: 2.4347639083862305
Validation loss: 2.5600354997374173
Epoch: 18| Step: 6
Training loss: 3.285787582397461
Validation loss: 2.562046064747323
Epoch: 18| Step: 7
Training loss: 1.9648551940917969
Validation loss: 2.5633004920945752
Epoch: 18| Step: 8
Training loss: 3.2243289947509766
Validation loss: 2.5477653716107924
Epoch: 18| Step: 9
Training loss: 3.8031721115112305
Validation loss: 2.557500509907016
Epoch: 18| Step: 10
Training loss: 1.8583028316497803
Validation loss: 2.549151811668341
Epoch: 18| Step: 11
Training loss: 4.242084503173828
Validation loss: 2.574701105090354
Epoch: 18| Step: 12
Training loss: 3.3827109336853027
Validation loss: 2.5556155091567003
Epoch: 18| Step: 13
Training loss: 3.329829216003418
Validation loss: 2.5552955617149955
Epoch: 18| Step: 14
Training loss: 2.310764789581299
Validation loss: 2.555124077007925
Epoch: 18| Step: 15
Training loss: 4.191499710083008
Validation loss: 2.569798311741232
Epoch: 18| Step: 16
Training loss: 2.7015743255615234
Validation loss: 2.556998561612136
Epoch: 18| Step: 17
Training loss: 2.9301557540893555
Validation loss: 2.552847524341062
Epoch: 18| Step: 18
Training loss: 1.5924873352050781
Validation loss: 2.543485718665363
Epoch: 18| Step: 19
Training loss: 3.6428897380828857
Validation loss: 2.53947950610154
Epoch: 18| Step: 20
Training loss: 3.6053483486175537
Validation loss: 2.5631985492843516
Epoch: 18| Step: 21
Training loss: 2.29483699798584
Validation loss: 2.550799671694529
Epoch: 18| Step: 22
Training loss: 3.0208070278167725
Validation loss: 2.5447896624640594
Epoch: 18| Step: 23
Training loss: 4.304193019866943
Validation loss: 2.5668089072481335
Epoch: 18| Step: 24
Training loss: 3.934933662414551
Validation loss: 2.5424876195921313
Epoch: 18| Step: 25
Training loss: 2.8704395294189453
Validation loss: 2.5681172103332957
Epoch: 18| Step: 26
Training loss: 1.6229547262191772
Validation loss: 2.549274971159242
Epoch: 18| Step: 27
Training loss: 3.4528298377990723
Validation loss: 2.5461494854028275
Epoch: 18| Step: 28
Training loss: 2.8448195457458496
Validation loss: 2.5576448337637263
Epoch: 18| Step: 29
Training loss: 2.0008490085601807
Validation loss: 2.5455886648713255
Epoch: 18| Step: 30
Training loss: 3.078376531600952
Validation loss: 2.550760269165039
Epoch: 18| Step: 31
Training loss: 2.494889259338379
Validation loss: 2.555911023839772
Epoch: 18| Step: 32
Training loss: 2.961791515350342
Validation loss: 2.5683104751779022
Epoch: 18| Step: 33
Training loss: 3.5697686672210693
Validation loss: 2.5515400986019654
Epoch: 18| Step: 34
Training loss: 3.507294178009033
Validation loss: 2.5610017502050604
Epoch: 18| Step: 35
Training loss: 3.061375617980957
Validation loss: 2.5665470044389904
Epoch: 18| Step: 36
Training loss: 3.441187620162964
Validation loss: 2.5666086433602753
Epoch: 18| Step: 37
Training loss: 2.522860050201416
Validation loss: 2.550364604099191
Epoch: 18| Step: 38
Training loss: 3.119779586791992
Validation loss: 2.5599393827452075
Epoch: 18| Step: 39
Training loss: 4.208346366882324
Validation loss: 2.551334387106861
Epoch: 56| Step: 0
Training loss: 2.6384410858154297
Validation loss: 2.5517738774526033
Epoch: 18| Step: 1
Training loss: 2.765444755554199
Validation loss: 2.56089803640791
Epoch: 18| Step: 2
Training loss: 3.892209529876709
Validation loss: 2.560548576519644
Epoch: 18| Step: 3
Training loss: 4.0218610763549805
Validation loss: 2.5669117934412236
Epoch: 18| Step: 4
Training loss: 3.6618542671203613
Validation loss: 2.5572774324485725
Epoch: 18| Step: 5
Training loss: 2.851588726043701
Validation loss: 2.53648738037768
Epoch: 18| Step: 6
Training loss: 3.5440292358398438
Validation loss: 2.554455758856355
Epoch: 18| Step: 7
Training loss: 2.9469919204711914
Validation loss: 2.53278454087621
Epoch: 18| Step: 8
Training loss: 2.753504991531372
Validation loss: 2.563981469586599
Epoch: 18| Step: 9
Training loss: 2.59735107421875
Validation loss: 2.5387240279492715
Epoch: 18| Step: 10
Training loss: 3.5931177139282227
Validation loss: 2.528404635491131
Epoch: 18| Step: 11
Training loss: 4.475461006164551
Validation loss: 2.535146070041245
Epoch: 18| Step: 12
Training loss: 2.5815789699554443
Validation loss: 2.5403944468326705
Epoch: 18| Step: 13
Training loss: 2.4388275146484375
Validation loss: 2.558690916720054
Epoch: 18| Step: 14
Training loss: 2.7019829750061035
Validation loss: 2.5237644284749203
Epoch: 18| Step: 15
Training loss: 2.4833765029907227
Validation loss: 2.5467834729942487
Epoch: 18| Step: 16
Training loss: 1.6051695346832275
Validation loss: 2.567525774454899
Epoch: 18| Step: 17
Training loss: 2.9233627319335938
Validation loss: 2.5447233237808558
Epoch: 18| Step: 18
Training loss: 4.089263916015625
Validation loss: 2.559471711837988
Epoch: 18| Step: 19
Training loss: 3.4544837474823
Validation loss: 2.537613167179574
Epoch: 18| Step: 20
Training loss: 2.4109549522399902
Validation loss: 2.5678695568935477
Epoch: 18| Step: 21
Training loss: 1.9807848930358887
Validation loss: 2.5326929066678603
Epoch: 18| Step: 22
Training loss: 3.716729164123535
Validation loss: 2.549065027305548
Epoch: 18| Step: 23
Training loss: 2.830000877380371
Validation loss: 2.5547143568237907
Epoch: 18| Step: 24
Training loss: 3.3591694831848145
Validation loss: 2.548178636770454
Epoch: 18| Step: 25
Training loss: 2.2042086124420166
Validation loss: 2.5658238002722213
Epoch: 18| Step: 26
Training loss: 4.782639026641846
Validation loss: 2.5497790592179883
Epoch: 18| Step: 27
Training loss: 3.267033100128174
Validation loss: 2.5492092816949747
Epoch: 18| Step: 28
Training loss: 1.8794360160827637
Validation loss: 2.558569786359938
Epoch: 18| Step: 29
Training loss: 2.982771873474121
Validation loss: 2.5478948294687616
Epoch: 18| Step: 30
Training loss: 3.1677088737487793
Validation loss: 2.548721184833444
Epoch: 18| Step: 31
Training loss: 3.272221088409424
Validation loss: 2.5606507963413816
Epoch: 18| Step: 32
Training loss: 3.943162202835083
Validation loss: 2.5498393473865315
Epoch: 18| Step: 33
Training loss: 3.315847635269165
Validation loss: 2.534695798544575
Epoch: 18| Step: 34
Training loss: 2.7706351280212402
Validation loss: 2.5507151926164147
Epoch: 18| Step: 35
Training loss: 3.231891632080078
Validation loss: 2.545112988074049
Epoch: 18| Step: 36
Training loss: 3.241939067840576
Validation loss: 2.556653789479098
Epoch: 18| Step: 37
Training loss: 3.385765552520752
Validation loss: 2.5534463649173436
Epoch: 18| Step: 38
Training loss: 2.445159435272217
Validation loss: 2.546556575692815
Epoch: 18| Step: 39
Training loss: 2.0183825492858887
Validation loss: 2.5593102252740656
Epoch: 57| Step: 0
Training loss: 3.612222194671631
Validation loss: 2.562698467172307
Epoch: 18| Step: 1
Training loss: 2.686328887939453
Validation loss: 2.5505404215064837
Epoch: 18| Step: 2
Training loss: 3.4339137077331543
Validation loss: 2.575303170320799
Epoch: 18| Step: 3
Training loss: 3.083204746246338
Validation loss: 2.5615050775541675
Epoch: 18| Step: 4
Training loss: 3.763817310333252
Validation loss: 2.5550765802534365
Epoch: 18| Step: 5
Training loss: 2.927130699157715
Validation loss: 2.526948546334136
Epoch: 18| Step: 6
Training loss: 2.917447566986084
Validation loss: 2.5438084293612473
Epoch: 18| Step: 7
Training loss: 2.951718330383301
Validation loss: 2.5454357253561777
Epoch: 18| Step: 8
Training loss: 2.74688458442688
Validation loss: 2.537621324868511
Epoch: 18| Step: 9
Training loss: 2.4755568504333496
Validation loss: 2.54067522501774
Epoch: 18| Step: 10
Training loss: 3.1776537895202637
Validation loss: 2.541089807482932
Epoch: 18| Step: 11
Training loss: 3.1353819370269775
Validation loss: 2.5452271468347782
Epoch: 18| Step: 12
Training loss: 2.039175271987915
Validation loss: 2.5374314081754616
Epoch: 18| Step: 13
Training loss: 3.3541324138641357
Validation loss: 2.550168647182931
Epoch: 18| Step: 14
Training loss: 2.5406689643859863
Validation loss: 2.528254169354336
Epoch: 18| Step: 15
Training loss: 3.2332987785339355
Validation loss: 2.536656542647657
Epoch: 18| Step: 16
Training loss: 2.012705087661743
Validation loss: 2.5309338689708025
Epoch: 18| Step: 17
Training loss: 5.075177192687988
Validation loss: 2.5576179181929115
Epoch: 18| Step: 18
Training loss: 2.5700976848602295
Validation loss: 2.538208405748546
Epoch: 18| Step: 19
Training loss: 3.8420143127441406
Validation loss: 2.5410321513525873
Epoch: 18| Step: 20
Training loss: 4.2202839851379395
Validation loss: 2.533534417907111
Epoch: 18| Step: 21
Training loss: 1.9782387018203735
Validation loss: 2.5233990168399947
Epoch: 18| Step: 22
Training loss: 3.3928885459899902
Validation loss: 2.5212073617701907
Epoch: 18| Step: 23
Training loss: 3.1079750061035156
Validation loss: 2.5301950012179586
Epoch: 18| Step: 24
Training loss: 2.623530387878418
Validation loss: 2.5198187382101156
Epoch: 18| Step: 25
Training loss: 2.239868402481079
Validation loss: 2.5655384818426996
Epoch: 18| Step: 26
Training loss: 3.9247848987579346
Validation loss: 2.539439827418156
Epoch: 18| Step: 27
Training loss: 3.306779384613037
Validation loss: 2.560462859037111
Epoch: 18| Step: 28
Training loss: 4.4050374031066895
Validation loss: 2.5433183736938365
Epoch: 18| Step: 29
Training loss: 3.143730640411377
Validation loss: 2.517786429082747
Epoch: 18| Step: 30
Training loss: 3.45878529548645
Validation loss: 2.5290632247924805
Epoch: 18| Step: 31
Training loss: 3.099625587463379
Validation loss: 2.550776459759088
Epoch: 18| Step: 32
Training loss: 1.860870599746704
Validation loss: 2.520406440007601
Epoch: 18| Step: 33
Training loss: 2.8225386142730713
Validation loss: 2.5444475335182903
Epoch: 18| Step: 34
Training loss: 2.886624813079834
Validation loss: 2.5198185186591937
Epoch: 18| Step: 35
Training loss: 3.2113499641418457
Validation loss: 2.53795324641166
Epoch: 18| Step: 36
Training loss: 2.172156572341919
Validation loss: 2.524895980203752
Epoch: 18| Step: 37
Training loss: 3.200298547744751
Validation loss: 2.5136363969432365
Epoch: 18| Step: 38
Training loss: 2.294611692428589
Validation loss: 2.5502272887195616
Epoch: 18| Step: 39
Training loss: 2.613649845123291
Validation loss: 2.551896329406354
Epoch: 58| Step: 0
Training loss: 4.004508972167969
Validation loss: 2.5597546272140614
Epoch: 18| Step: 1
Training loss: 2.8883326053619385
Validation loss: 2.549105664808973
Epoch: 18| Step: 2
Training loss: 3.0440611839294434
Validation loss: 2.525591593852146
Epoch: 18| Step: 3
Training loss: 3.732384204864502
Validation loss: 2.539317319719054
Epoch: 18| Step: 4
Training loss: 2.6137030124664307
Validation loss: 2.5292127612683415
Epoch: 18| Step: 5
Training loss: 2.809098958969116
Validation loss: 2.538638036028087
Epoch: 18| Step: 6
Training loss: 4.298103332519531
Validation loss: 2.5358731523692177
Epoch: 18| Step: 7
Training loss: 2.0857419967651367
Validation loss: 2.5668642212161057
Epoch: 18| Step: 8
Training loss: 4.197746276855469
Validation loss: 2.527974641580376
Epoch: 18| Step: 9
Training loss: 2.249959707260132
Validation loss: 2.540403969853902
Epoch: 18| Step: 10
Training loss: 3.6349639892578125
Validation loss: 2.525742246092652
Epoch: 18| Step: 11
Training loss: 3.739020347595215
Validation loss: 2.5339172846979374
Epoch: 18| Step: 12
Training loss: 1.7549653053283691
Validation loss: 2.5428872297136045
Epoch: 18| Step: 13
Training loss: 1.9647512435913086
Validation loss: 2.5302270963895235
Epoch: 18| Step: 14
Training loss: 3.9263062477111816
Validation loss: 2.511592852983543
Epoch: 18| Step: 15
Training loss: 3.8262269496917725
Validation loss: 2.5536576483747084
Epoch: 18| Step: 16
Training loss: 2.4836740493774414
Validation loss: 2.508665391867109
Epoch: 18| Step: 17
Training loss: 3.2639689445495605
Validation loss: 2.529064080698027
Epoch: 18| Step: 18
Training loss: 2.769552230834961
Validation loss: 2.5266014569097286
Epoch: 18| Step: 19
Training loss: 2.60495662689209
Validation loss: 2.5348041666497427
Epoch: 18| Step: 20
Training loss: 3.3582353591918945
Validation loss: 2.524298731371653
Epoch: 18| Step: 21
Training loss: 2.8883519172668457
Validation loss: 2.536393666438919
Epoch: 18| Step: 22
Training loss: 2.2719383239746094
Validation loss: 2.5229652665501874
Epoch: 18| Step: 23
Training loss: 3.4230895042419434
Validation loss: 2.5503625192230555
Epoch: 18| Step: 24
Training loss: 2.831881046295166
Validation loss: 2.532306515055595
Epoch: 18| Step: 25
Training loss: 3.1532044410705566
Validation loss: 2.540274531721211
Epoch: 18| Step: 26
Training loss: 3.2635512351989746
Validation loss: 2.5251068640098295
Epoch: 18| Step: 27
Training loss: 3.233858108520508
Validation loss: 2.5256045576479793
Epoch: 18| Step: 28
Training loss: 0.8719985485076904
Validation loss: 2.5324968142475157
Epoch: 18| Step: 29
Training loss: 2.149195671081543
Validation loss: 2.523498632067399
Epoch: 18| Step: 30
Training loss: 3.1264803409576416
Validation loss: 2.5221389737918223
Epoch: 18| Step: 31
Training loss: 2.3770229816436768
Validation loss: 2.5340484114859603
Epoch: 18| Step: 32
Training loss: 3.337563991546631
Validation loss: 2.5258387284313173
Epoch: 18| Step: 33
Training loss: 4.232156753540039
Validation loss: 2.5391772136413793
Epoch: 18| Step: 34
Training loss: 3.42716121673584
Validation loss: 2.53330324708129
Epoch: 18| Step: 35
Training loss: 3.1091301441192627
Validation loss: 2.5224687161205486
Epoch: 18| Step: 36
Training loss: 3.0244898796081543
Validation loss: 2.533519992725455
Epoch: 18| Step: 37
Training loss: 3.615018129348755
Validation loss: 2.516165488057857
Epoch: 18| Step: 38
Training loss: 2.6290314197540283
Validation loss: 2.527186568692434
Epoch: 18| Step: 39
Training loss: 3.1174156665802
Validation loss: 2.549735698768561
Epoch: 59| Step: 0
Training loss: 3.6049466133117676
Validation loss: 2.512968697136255
Epoch: 18| Step: 1
Training loss: 2.3174448013305664
Validation loss: 2.526096035250657
Epoch: 18| Step: 2
Training loss: 3.1894731521606445
Validation loss: 2.5197367968319133
Epoch: 18| Step: 3
Training loss: 3.25534725189209
Validation loss: 2.531160908637287
Epoch: 18| Step: 4
Training loss: 2.514435291290283
Validation loss: 2.5496741713379785
Epoch: 18| Step: 5
Training loss: 2.4955687522888184
Validation loss: 2.5186437651407805
Epoch: 18| Step: 6
Training loss: 2.7267167568206787
Validation loss: 2.510076164341659
Epoch: 18| Step: 7
Training loss: 2.9194533824920654
Validation loss: 2.535841360366602
Epoch: 18| Step: 8
Training loss: 3.288278579711914
Validation loss: 2.523350189058043
Epoch: 18| Step: 9
Training loss: 2.3373351097106934
Validation loss: 2.5089689218740667
Epoch: 18| Step: 10
Training loss: 3.8223235607147217
Validation loss: 2.5203617562492973
Epoch: 18| Step: 11
Training loss: 2.99950909614563
Validation loss: 2.5352591473421606
Epoch: 18| Step: 12
Training loss: 3.546537160873413
Validation loss: 2.545741227033327
Epoch: 18| Step: 13
Training loss: 4.018003940582275
Validation loss: 2.5351253859430765
Epoch: 18| Step: 14
Training loss: 3.4425618648529053
Validation loss: 2.552605452297403
Epoch: 18| Step: 15
Training loss: 2.347804546356201
Validation loss: 2.5318315680936085
Epoch: 18| Step: 16
Training loss: 2.778235673904419
Validation loss: 2.514736366357735
Epoch: 18| Step: 17
Training loss: 3.2772128582000732
Validation loss: 2.529632451722948
Epoch: 18| Step: 18
Training loss: 2.2376749515533447
Validation loss: 2.5290428683054533
Epoch: 18| Step: 19
Training loss: 2.246206283569336
Validation loss: 2.5180888810603737
Epoch: 18| Step: 20
Training loss: 3.5057828426361084
Validation loss: 2.5204408957803848
Epoch: 18| Step: 21
Training loss: 2.0767176151275635
Validation loss: 2.523510399482233
Epoch: 18| Step: 22
Training loss: 2.5486745834350586
Validation loss: 2.527005770223604
Epoch: 18| Step: 23
Training loss: 3.382316827774048
Validation loss: 2.5492807652452867
Epoch: 18| Step: 24
Training loss: 3.36616849899292
Validation loss: 2.5461705434236594
Epoch: 18| Step: 25
Training loss: 4.281126976013184
Validation loss: 2.5505054391545356
Epoch: 18| Step: 26
Training loss: 2.2738685607910156
Validation loss: 2.5204165204823448
Epoch: 18| Step: 27
Training loss: 3.059918165206909
Validation loss: 2.501095770074309
Epoch: 18| Step: 28
Training loss: 3.3949172496795654
Validation loss: 2.523235381078377
Epoch: 18| Step: 29
Training loss: 3.042541980743408
Validation loss: 2.5097719422347256
Epoch: 18| Step: 30
Training loss: 3.1675705909729004
Validation loss: 2.5341511630325866
Epoch: 18| Step: 31
Training loss: 2.6688084602355957
Validation loss: 2.519925610624629
Epoch: 18| Step: 32
Training loss: 2.5582666397094727
Validation loss: 2.4982677492306387
Epoch: 18| Step: 33
Training loss: 3.6423897743225098
Validation loss: 2.5267676552422613
Epoch: 18| Step: 34
Training loss: 2.8604373931884766
Validation loss: 2.525053408506105
Epoch: 18| Step: 35
Training loss: 3.968548059463501
Validation loss: 2.5417831201347516
Epoch: 18| Step: 36
Training loss: 3.670151472091675
Validation loss: 2.518211658052403
Epoch: 18| Step: 37
Training loss: 3.370898485183716
Validation loss: 2.544276553092243
Epoch: 18| Step: 38
Training loss: 2.2083609104156494
Validation loss: 2.5266019148792296
Epoch: 18| Step: 39
Training loss: 3.488832950592041
Validation loss: 2.5137503713154965
Epoch: 60| Step: 0
Training loss: 2.7515268325805664
Validation loss: 2.5301756717318256
Epoch: 18| Step: 1
Training loss: 2.306102991104126
Validation loss: 2.5247525139678295
Epoch: 18| Step: 2
Training loss: 3.5984444618225098
Validation loss: 2.5231533925310314
Epoch: 18| Step: 3
Training loss: 3.909611463546753
Validation loss: 2.514827815748805
Epoch: 18| Step: 4
Training loss: 3.039846420288086
Validation loss: 2.525434816483971
Epoch: 18| Step: 5
Training loss: 3.4422097206115723
Validation loss: 2.5062871176561865
Epoch: 18| Step: 6
Training loss: 2.866940498352051
Validation loss: 2.530753869804547
Epoch: 18| Step: 7
Training loss: 3.9102559089660645
Validation loss: 2.5163316452245916
Epoch: 18| Step: 8
Training loss: 2.849954605102539
Validation loss: 2.5231901836052217
Epoch: 18| Step: 9
Training loss: 2.528533458709717
Validation loss: 2.5238385903749534
Epoch: 18| Step: 10
Training loss: 2.6504533290863037
Validation loss: 2.529274060571794
Epoch: 18| Step: 11
Training loss: 1.4411847591400146
Validation loss: 2.5309469991450686
Epoch: 18| Step: 12
Training loss: 2.866349935531616
Validation loss: 2.527913925459059
Epoch: 18| Step: 13
Training loss: 3.5560097694396973
Validation loss: 2.5224543895652825
Epoch: 18| Step: 14
Training loss: 4.782554626464844
Validation loss: 2.5186662845474355
Epoch: 18| Step: 15
Training loss: 3.9179329872131348
Validation loss: 2.538885764938464
Epoch: 18| Step: 16
Training loss: 2.3290247917175293
Validation loss: 2.5268279837189818
Epoch: 18| Step: 17
Training loss: 2.7659685611724854
Validation loss: 2.525843683764231
Epoch: 18| Step: 18
Training loss: 3.5616164207458496
Validation loss: 2.5446514963246076
Epoch: 18| Step: 19
Training loss: 3.9092788696289062
Validation loss: 2.524400616721284
Epoch: 18| Step: 20
Training loss: 2.516305923461914
Validation loss: 2.5285363694746716
Epoch: 18| Step: 21
Training loss: 3.0162668228149414
Validation loss: 2.5154179446131204
Epoch: 18| Step: 22
Training loss: 2.5555307865142822
Validation loss: 2.5320299803781854
Epoch: 18| Step: 23
Training loss: 3.5557429790496826
Validation loss: 2.5269970053391493
Epoch: 18| Step: 24
Training loss: 2.2900784015655518
Validation loss: 2.507256427257181
Epoch: 18| Step: 25
Training loss: 2.7872633934020996
Validation loss: 2.5126008146958387
Epoch: 18| Step: 26
Training loss: 3.7411580085754395
Validation loss: 2.5040174782704963
Epoch: 18| Step: 27
Training loss: 2.820816993713379
Validation loss: 2.513727520867217
Epoch: 18| Step: 28
Training loss: 2.9070799350738525
Validation loss: 2.5384589682380074
Epoch: 18| Step: 29
Training loss: 1.5478906631469727
Validation loss: 2.5302254570473868
Epoch: 18| Step: 30
Training loss: 3.269853115081787
Validation loss: 2.5120399581442636
Epoch: 18| Step: 31
Training loss: 2.3850607872009277
Validation loss: 2.490950884578897
Epoch: 18| Step: 32
Training loss: 2.6716458797454834
Validation loss: 2.5455294067053487
Epoch: 18| Step: 33
Training loss: 3.4695332050323486
Validation loss: 2.5291407751522477
Epoch: 18| Step: 34
Training loss: 3.001985549926758
Validation loss: 2.5361212586327424
Epoch: 18| Step: 35
Training loss: 1.4157246351242065
Validation loss: 2.519336300788166
Epoch: 18| Step: 36
Training loss: 3.7748863697052
Validation loss: 2.5212220528142915
Epoch: 18| Step: 37
Training loss: 2.571310520172119
Validation loss: 2.5252243031700736
Epoch: 18| Step: 38
Training loss: 3.269489288330078
Validation loss: 2.5160352652021447
Epoch: 18| Step: 39
Training loss: 3.8728508949279785
Validation loss: 2.52424029309115
Epoch: 61| Step: 0
Training loss: 2.6871347427368164
Validation loss: 2.525260580529412
Epoch: 18| Step: 1
Training loss: 3.9860332012176514
Validation loss: 2.510512696753303
Epoch: 18| Step: 2
Training loss: 2.684206962585449
Validation loss: 2.532398783045707
Epoch: 18| Step: 3
Training loss: 2.873112201690674
Validation loss: 2.5024086159767864
Epoch: 18| Step: 4
Training loss: 3.432983875274658
Validation loss: 2.533102011509079
Epoch: 18| Step: 5
Training loss: 2.831495761871338
Validation loss: 2.5049809560501317
Epoch: 18| Step: 6
Training loss: 3.7907509803771973
Validation loss: 2.528469764071403
Epoch: 18| Step: 7
Training loss: 2.506269931793213
Validation loss: 2.528487365022838
Epoch: 18| Step: 8
Training loss: 2.451526641845703
Validation loss: 2.510636370816677
Epoch: 18| Step: 9
Training loss: 2.693711757659912
Validation loss: 2.52637294385073
Epoch: 18| Step: 10
Training loss: 3.1041340827941895
Validation loss: 2.501614811180307
Epoch: 18| Step: 11
Training loss: 3.4645416736602783
Validation loss: 2.509491784109486
Epoch: 18| Step: 12
Training loss: 1.9036681652069092
Validation loss: 2.5226303947915274
Epoch: 18| Step: 13
Training loss: 3.1834137439727783
Validation loss: 2.5385287442653297
Epoch: 18| Step: 14
Training loss: 3.896637201309204
Validation loss: 2.5384435439281328
Epoch: 18| Step: 15
Training loss: 2.7770934104919434
Validation loss: 2.5213421403075293
Epoch: 18| Step: 16
Training loss: 4.089381217956543
Validation loss: 2.522569257578404
Epoch: 18| Step: 17
Training loss: 2.002344846725464
Validation loss: 2.5074898476223293
Epoch: 18| Step: 18
Training loss: 2.886258602142334
Validation loss: 2.533295326953312
Epoch: 18| Step: 19
Training loss: 3.546619415283203
Validation loss: 2.514075931027639
Epoch: 18| Step: 20
Training loss: 3.149402379989624
Validation loss: 2.502921191908473
Epoch: 18| Step: 21
Training loss: 2.95963191986084
Validation loss: 2.5129974557341432
Epoch: 18| Step: 22
Training loss: 4.0262041091918945
Validation loss: 2.5212343322287363
Epoch: 18| Step: 23
Training loss: 2.8544514179229736
Validation loss: 2.522443085265674
Epoch: 18| Step: 24
Training loss: 2.8940601348876953
Validation loss: 2.538383742888197
Epoch: 18| Step: 25
Training loss: 3.6415555477142334
Validation loss: 2.539640189932405
Epoch: 18| Step: 26
Training loss: 3.801774501800537
Validation loss: 2.5345005817550548
Epoch: 18| Step: 27
Training loss: 2.1241650581359863
Validation loss: 2.5065225834469143
Epoch: 18| Step: 28
Training loss: 2.5873489379882812
Validation loss: 2.5230242245488887
Epoch: 18| Step: 29
Training loss: 1.1071245670318604
Validation loss: 2.5159705045411913
Epoch: 18| Step: 30
Training loss: 3.793353319168091
Validation loss: 2.5044675593753514
Epoch: 18| Step: 31
Training loss: 2.3257243633270264
Validation loss: 2.5254529774617804
Epoch: 18| Step: 32
Training loss: 3.0340685844421387
Validation loss: 2.52724213737378
Epoch: 18| Step: 33
Training loss: 2.5182571411132812
Validation loss: 2.531832250759756
Epoch: 18| Step: 34
Training loss: 2.255398750305176
Validation loss: 2.5244284225024765
Epoch: 18| Step: 35
Training loss: 4.21865701675415
Validation loss: 2.5174411732515845
Epoch: 18| Step: 36
Training loss: 2.3712451457977295
Validation loss: 2.5182996362233334
Epoch: 18| Step: 37
Training loss: 3.31601619720459
Validation loss: 2.5208415912209654
Epoch: 18| Step: 38
Training loss: 3.3605098724365234
Validation loss: 2.5069181816183406
Epoch: 18| Step: 39
Training loss: 3.4988865852355957
Validation loss: 2.5399685463459374
Epoch: 62| Step: 0
Training loss: 2.4129819869995117
Validation loss: 2.5007460992113293
Epoch: 18| Step: 1
Training loss: 2.53892183303833
Validation loss: 2.5078748456008144
Epoch: 18| Step: 2
Training loss: 4.213947296142578
Validation loss: 2.5214000996068227
Epoch: 18| Step: 3
Training loss: 3.4402594566345215
Validation loss: 2.524190068244934
Epoch: 18| Step: 4
Training loss: 3.5272140502929688
Validation loss: 2.515379770196599
Epoch: 18| Step: 5
Training loss: 1.9477262496948242
Validation loss: 2.5288795481482857
Epoch: 18| Step: 6
Training loss: 2.3400721549987793
Validation loss: 2.5239944046349834
Epoch: 18| Step: 7
Training loss: 2.271850824356079
Validation loss: 2.5334048168264705
Epoch: 18| Step: 8
Training loss: 3.180565118789673
Validation loss: 2.5330223316768947
Epoch: 18| Step: 9
Training loss: 2.8305282592773438
Validation loss: 2.491780632691418
Epoch: 18| Step: 10
Training loss: 3.022780418395996
Validation loss: 2.5075341025702387
Epoch: 18| Step: 11
Training loss: 2.720473289489746
Validation loss: 2.5188610708113197
Epoch: 18| Step: 12
Training loss: 3.2537214756011963
Validation loss: 2.5176977185036638
Epoch: 18| Step: 13
Training loss: 3.6152777671813965
Validation loss: 2.5168059867063013
Epoch: 18| Step: 14
Training loss: 3.753337860107422
Validation loss: 2.503273994802571
Epoch: 18| Step: 15
Training loss: 2.7612316608428955
Validation loss: 2.5114620589523864
Epoch: 18| Step: 16
Training loss: 4.152761936187744
Validation loss: 2.5110483152403247
Epoch: 18| Step: 17
Training loss: 3.0749735832214355
Validation loss: 2.5112335304562134
Epoch: 18| Step: 18
Training loss: 2.926480293273926
Validation loss: 2.5298786231939743
Epoch: 18| Step: 19
Training loss: 2.6452932357788086
Validation loss: 2.512683389855803
Epoch: 18| Step: 20
Training loss: 2.897977352142334
Validation loss: 2.51809983459308
Epoch: 18| Step: 21
Training loss: 1.8933520317077637
Validation loss: 2.489272179363443
Epoch: 18| Step: 22
Training loss: 2.8955535888671875
Validation loss: 2.5398996082141245
Epoch: 18| Step: 23
Training loss: 3.4997544288635254
Validation loss: 2.545814629938963
Epoch: 18| Step: 24
Training loss: 1.932735562324524
Validation loss: 2.5142635149921446
Epoch: 18| Step: 25
Training loss: 3.6797127723693848
Validation loss: 2.524576248882486
Epoch: 18| Step: 26
Training loss: 2.3058881759643555
Validation loss: 2.5171400368642463
Epoch: 18| Step: 27
Training loss: 3.55888032913208
Validation loss: 2.5086763797046467
Epoch: 18| Step: 28
Training loss: 3.068087577819824
Validation loss: 2.492891791913149
Epoch: 18| Step: 29
Training loss: 3.0050010681152344
Validation loss: 2.5095695454439673
Epoch: 18| Step: 30
Training loss: 2.5092315673828125
Validation loss: 2.5167695408244786
Epoch: 18| Step: 31
Training loss: 3.0687255859375
Validation loss: 2.520385781638056
Epoch: 18| Step: 32
Training loss: 2.707550048828125
Validation loss: 2.5172645033692285
Epoch: 18| Step: 33
Training loss: 3.3682847023010254
Validation loss: 2.50317748416242
Epoch: 18| Step: 34
Training loss: 3.2916736602783203
Validation loss: 2.5192604665275957
Epoch: 18| Step: 35
Training loss: 3.6973061561584473
Validation loss: 2.5383187326595937
Epoch: 18| Step: 36
Training loss: 3.0910158157348633
Validation loss: 2.5146426785764078
Epoch: 18| Step: 37
Training loss: 3.635495662689209
Validation loss: 2.509881101923881
Epoch: 18| Step: 38
Training loss: 3.814692497253418
Validation loss: 2.503962252637465
Epoch: 18| Step: 39
Training loss: 1.6900362968444824
Validation loss: 2.524453509625771
Epoch: 63| Step: 0
Training loss: 3.3235607147216797
Validation loss: 2.515576144774183
Epoch: 18| Step: 1
Training loss: 2.3361847400665283
Validation loss: 2.509757760831778
Epoch: 18| Step: 2
Training loss: 3.678645133972168
Validation loss: 2.5186712964833213
Epoch: 18| Step: 3
Training loss: 3.465047597885132
Validation loss: 2.5081994173338087
Epoch: 18| Step: 4
Training loss: 1.8818809986114502
Validation loss: 2.497267318286484
Epoch: 18| Step: 5
Training loss: 3.179230213165283
Validation loss: 2.4982830483278784
Epoch: 18| Step: 6
Training loss: 3.511340618133545
Validation loss: 2.5083271616654432
Epoch: 18| Step: 7
Training loss: 4.364617824554443
Validation loss: 2.53127631180578
Epoch: 18| Step: 8
Training loss: 3.0706589221954346
Validation loss: 2.4948680863963615
Epoch: 18| Step: 9
Training loss: 3.1077475547790527
Validation loss: 2.5119180747930954
Epoch: 18| Step: 10
Training loss: 2.5020337104797363
Validation loss: 2.5248352229166375
Epoch: 18| Step: 11
Training loss: 1.8644391298294067
Validation loss: 2.521827333265071
Epoch: 18| Step: 12
Training loss: 2.630603313446045
Validation loss: 2.505290056732919
Epoch: 18| Step: 13
Training loss: 3.578958511352539
Validation loss: 2.4954110135277396
Epoch: 18| Step: 14
Training loss: 2.45339298248291
Validation loss: 2.5126331169828235
Epoch: 18| Step: 15
Training loss: 2.929743528366089
Validation loss: 2.482879804835903
Epoch: 18| Step: 16
Training loss: 2.5117616653442383
Validation loss: 2.5120686927287696
Epoch: 18| Step: 17
Training loss: 3.0098955631256104
Validation loss: 2.520118294859962
Epoch: 18| Step: 18
Training loss: 2.2037270069122314
Validation loss: 2.5362085481341796
Epoch: 18| Step: 19
Training loss: 2.6238036155700684
Validation loss: 2.5277776975425885
Epoch: 18| Step: 20
Training loss: 2.8234472274780273
Validation loss: 2.4915332125245238
Epoch: 18| Step: 21
Training loss: 2.267988920211792
Validation loss: 2.517736201663669
Epoch: 18| Step: 22
Training loss: 3.5886600017547607
Validation loss: 2.5081236979944244
Epoch: 18| Step: 23
Training loss: 3.1383843421936035
Validation loss: 2.536625121137221
Epoch: 18| Step: 24
Training loss: 2.640754222869873
Validation loss: 2.5365836071453507
Epoch: 18| Step: 25
Training loss: 3.270507335662842
Validation loss: 2.491439381520525
Epoch: 18| Step: 26
Training loss: 3.016620635986328
Validation loss: 2.509089668877691
Epoch: 18| Step: 27
Training loss: 3.451671838760376
Validation loss: 2.529469200175443
Epoch: 18| Step: 28
Training loss: 3.443356513977051
Validation loss: 2.5292550454036795
Epoch: 18| Step: 29
Training loss: 2.372978448867798
Validation loss: 2.506519578343673
Epoch: 18| Step: 30
Training loss: 3.1846818923950195
Validation loss: 2.4841700938108158
Epoch: 18| Step: 31
Training loss: 4.06402063369751
Validation loss: 2.4973892976911807
Epoch: 18| Step: 32
Training loss: 3.749211311340332
Validation loss: 2.5166338330550158
Epoch: 18| Step: 33
Training loss: 3.0527377128601074
Validation loss: 2.507986202514429
Epoch: 18| Step: 34
Training loss: 2.402583599090576
Validation loss: 2.5096788869487296
Epoch: 18| Step: 35
Training loss: 2.5111148357391357
Validation loss: 2.505984431548084
Epoch: 18| Step: 36
Training loss: 3.1184093952178955
Validation loss: 2.511048922435843
Epoch: 18| Step: 37
Training loss: 3.718177318572998
Validation loss: 2.5200107697960283
Epoch: 18| Step: 38
Training loss: 3.4674248695373535
Validation loss: 2.5262638167511646
Epoch: 18| Step: 39
Training loss: 2.744737148284912
Validation loss: 2.506986259556503
Epoch: 64| Step: 0
Training loss: 2.2095022201538086
Validation loss: 2.517867829302232
Epoch: 18| Step: 1
Training loss: 2.261359930038452
Validation loss: 2.5086708669182207
Epoch: 18| Step: 2
Training loss: 2.832742691040039
Validation loss: 2.5190517464987665
Epoch: 18| Step: 3
Training loss: 2.6912126541137695
Validation loss: 2.5237616806579153
Epoch: 18| Step: 4
Training loss: 3.422821521759033
Validation loss: 2.505861253189526
Epoch: 18| Step: 5
Training loss: 3.375810384750366
Validation loss: 2.512339724053582
Epoch: 18| Step: 6
Training loss: 1.907655119895935
Validation loss: 2.5179278507507106
Epoch: 18| Step: 7
Training loss: 3.818382740020752
Validation loss: 2.5188638606517433
Epoch: 18| Step: 8
Training loss: 1.81827712059021
Validation loss: 2.5012007531502265
Epoch: 18| Step: 9
Training loss: 3.231978416442871
Validation loss: 2.496411170890863
Epoch: 18| Step: 10
Training loss: 2.8332648277282715
Validation loss: 2.49686029660616
Epoch: 18| Step: 11
Training loss: 3.07989239692688
Validation loss: 2.519723494275868
Epoch: 18| Step: 12
Training loss: 3.7183077335357666
Validation loss: 2.5119477141675333
Epoch: 18| Step: 13
Training loss: 3.296211004257202
Validation loss: 2.522306099212427
Epoch: 18| Step: 14
Training loss: 3.392817258834839
Validation loss: 2.5092368983536315
Epoch: 18| Step: 15
Training loss: 2.9656715393066406
Validation loss: 2.5018791775051636
Epoch: 18| Step: 16
Training loss: 2.667151927947998
Validation loss: 2.5239088398089513
Epoch: 18| Step: 17
Training loss: 3.3271260261535645
Validation loss: 2.499491720748462
Epoch: 18| Step: 18
Training loss: 2.513648748397827
Validation loss: 2.499563163990597
Epoch: 18| Step: 19
Training loss: 4.109495162963867
Validation loss: 2.4941053870770573
Epoch: 18| Step: 20
Training loss: 3.1553940773010254
Validation loss: 2.5061822100508984
Epoch: 18| Step: 21
Training loss: 1.8513785600662231
Validation loss: 2.4816047407740314
Epoch: 18| Step: 22
Training loss: 1.8726879358291626
Validation loss: 2.5099838431790578
Epoch: 18| Step: 23
Training loss: 2.2509844303131104
Validation loss: 2.512904167175293
Epoch: 18| Step: 24
Training loss: 3.6234774589538574
Validation loss: 2.499373481428023
Epoch: 18| Step: 25
Training loss: 2.335263252258301
Validation loss: 2.4991790442157993
Epoch: 18| Step: 26
Training loss: 2.7197065353393555
Validation loss: 2.496908750465448
Epoch: 18| Step: 27
Training loss: 2.9180407524108887
Validation loss: 2.5059859032253566
Epoch: 18| Step: 28
Training loss: 4.3518266677856445
Validation loss: 2.4914240905706833
Epoch: 18| Step: 29
Training loss: 2.732774257659912
Validation loss: 2.502952493351998
Epoch: 18| Step: 30
Training loss: 3.519601345062256
Validation loss: 2.4804081230712454
Epoch: 18| Step: 31
Training loss: 3.2883810997009277
Validation loss: 2.505589100954344
Epoch: 18| Step: 32
Training loss: 4.279541492462158
Validation loss: 2.4730878485192496
Epoch: 18| Step: 33
Training loss: 3.6603479385375977
Validation loss: 2.4910453549391933
Epoch: 18| Step: 34
Training loss: 2.149880886077881
Validation loss: 2.511204460541979
Epoch: 18| Step: 35
Training loss: 2.312882900238037
Validation loss: 2.5169331675810778
Epoch: 18| Step: 36
Training loss: 3.7426342964172363
Validation loss: 2.488686131058837
Epoch: 18| Step: 37
Training loss: 3.2104315757751465
Validation loss: 2.5111543977860924
Epoch: 18| Step: 38
Training loss: 2.681227684020996
Validation loss: 2.505443374030024
Epoch: 18| Step: 39
Training loss: 4.324872970581055
Validation loss: 2.5239541067493905
Epoch: 65| Step: 0
Training loss: 3.850937843322754
Validation loss: 2.5040355689234013
Epoch: 18| Step: 1
Training loss: 3.2458598613739014
Validation loss: 2.4904575056309324
Epoch: 18| Step: 2
Training loss: 3.0719661712646484
Validation loss: 2.5240566010097805
Epoch: 18| Step: 3
Training loss: 2.9107589721679688
Validation loss: 2.5064985889325038
Epoch: 18| Step: 4
Training loss: 2.8018784523010254
Validation loss: 2.485117018651619
Epoch: 18| Step: 5
Training loss: 2.9857664108276367
Validation loss: 2.515289599089314
Epoch: 18| Step: 6
Training loss: 4.131682395935059
Validation loss: 2.4789130190293567
Epoch: 18| Step: 7
Training loss: 2.6248507499694824
Validation loss: 2.472691134583178
Epoch: 18| Step: 8
Training loss: 2.0313148498535156
Validation loss: 2.5104379019291283
Epoch: 18| Step: 9
Training loss: 3.313584804534912
Validation loss: 2.49094016946477
Epoch: 18| Step: 10
Training loss: 2.384753704071045
Validation loss: 2.5067068621409025
Epoch: 18| Step: 11
Training loss: 2.922809600830078
Validation loss: 2.5062925969954017
Epoch: 18| Step: 12
Training loss: 3.10791277885437
Validation loss: 2.497770872047479
Epoch: 18| Step: 13
Training loss: 2.4700801372528076
Validation loss: 2.4899963414926325
Epoch: 18| Step: 14
Training loss: 3.1467442512512207
Validation loss: 2.48459735534174
Epoch: 18| Step: 15
Training loss: 3.799746513366699
Validation loss: 2.4979863449823942
Epoch: 18| Step: 16
Training loss: 3.3630266189575195
Validation loss: 2.5004653484701254
Epoch: 18| Step: 17
Training loss: 2.007981777191162
Validation loss: 2.492801884095446
Epoch: 18| Step: 18
Training loss: 3.3450045585632324
Validation loss: 2.4906366068682226
Epoch: 18| Step: 19
Training loss: 2.9516732692718506
Validation loss: 2.504003413289571
Epoch: 18| Step: 20
Training loss: 3.9542479515075684
Validation loss: 2.502311579615092
Epoch: 18| Step: 21
Training loss: 1.8364849090576172
Validation loss: 2.494355229165057
Epoch: 18| Step: 22
Training loss: 3.192629098892212
Validation loss: 2.4907029498395303
Epoch: 18| Step: 23
Training loss: 3.4932665824890137
Validation loss: 2.5092447129942532
Epoch: 18| Step: 24
Training loss: 2.7087414264678955
Validation loss: 2.4950692104778702
Epoch: 18| Step: 25
Training loss: 1.9805281162261963
Validation loss: 2.500266877867335
Epoch: 18| Step: 26
Training loss: 3.726123809814453
Validation loss: 2.5087880933885094
Epoch: 18| Step: 27
Training loss: 4.247453689575195
Validation loss: 2.506101604845884
Epoch: 18| Step: 28
Training loss: 3.9640722274780273
Validation loss: 2.5063520729970588
Epoch: 18| Step: 29
Training loss: 2.274688959121704
Validation loss: 2.474960171061454
Epoch: 18| Step: 30
Training loss: 2.974724769592285
Validation loss: 2.4911943416801288
Epoch: 18| Step: 31
Training loss: 2.6166248321533203
Validation loss: 2.486837783305765
Epoch: 18| Step: 32
Training loss: 3.3966188430786133
Validation loss: 2.493160768378553
Epoch: 18| Step: 33
Training loss: 1.8996951580047607
Validation loss: 2.486211164392156
Epoch: 18| Step: 34
Training loss: 2.48048734664917
Validation loss: 2.509166974815533
Epoch: 18| Step: 35
Training loss: 3.6961660385131836
Validation loss: 2.5050972725847642
Epoch: 18| Step: 36
Training loss: 2.698110580444336
Validation loss: 2.512886278920894
Epoch: 18| Step: 37
Training loss: 1.7719825506210327
Validation loss: 2.501371975425336
Epoch: 18| Step: 38
Training loss: 3.089353561401367
Validation loss: 2.5152986718596315
Epoch: 18| Step: 39
Training loss: 3.5949597358703613
Validation loss: 2.4947807514410223
Epoch: 66| Step: 0
Training loss: 2.64377498626709
Validation loss: 2.4669604387214714
Epoch: 18| Step: 1
Training loss: 4.087430953979492
Validation loss: 2.502853872964708
Epoch: 18| Step: 2
Training loss: 3.136965274810791
Validation loss: 2.4807450445435886
Epoch: 18| Step: 3
Training loss: 3.6043999195098877
Validation loss: 2.4925753572861926
Epoch: 18| Step: 4
Training loss: 3.0157713890075684
Validation loss: 2.513719268839994
Epoch: 18| Step: 5
Training loss: 2.0737802982330322
Validation loss: 2.4911942550604294
Epoch: 18| Step: 6
Training loss: 2.371119976043701
Validation loss: 2.5074613694664385
Epoch: 18| Step: 7
Training loss: 3.662518262863159
Validation loss: 2.514871966066978
Epoch: 18| Step: 8
Training loss: 2.578709840774536
Validation loss: 2.5136171656546833
Epoch: 18| Step: 9
Training loss: 3.22080659866333
Validation loss: 2.466395313791234
Epoch: 18| Step: 10
Training loss: 3.736893653869629
Validation loss: 2.4894411426653966
Epoch: 18| Step: 11
Training loss: 1.3008170127868652
Validation loss: 2.5064932403804585
Epoch: 18| Step: 12
Training loss: 3.52923846244812
Validation loss: 2.487751578255523
Epoch: 18| Step: 13
Training loss: 3.0473251342773438
Validation loss: 2.4913990574774982
Epoch: 18| Step: 14
Training loss: 3.1441726684570312
Validation loss: 2.4904433960537258
Epoch: 18| Step: 15
Training loss: 3.3483879566192627
Validation loss: 2.500916570210628
Epoch: 18| Step: 16
Training loss: 4.007999420166016
Validation loss: 2.4874241720858237
Epoch: 18| Step: 17
Training loss: 2.140979766845703
Validation loss: 2.5069772459620197
Epoch: 18| Step: 18
Training loss: 1.8203375339508057
Validation loss: 2.492590924818739
Epoch: 18| Step: 19
Training loss: 3.3704993724823
Validation loss: 2.5033552106335866
Epoch: 18| Step: 20
Training loss: 2.8847732543945312
Validation loss: 2.5080667536893335
Epoch: 18| Step: 21
Training loss: 3.290104866027832
Validation loss: 2.5079296492844176
Epoch: 18| Step: 22
Training loss: 2.439196825027466
Validation loss: 2.5034022039646726
Epoch: 18| Step: 23
Training loss: 3.164247751235962
Validation loss: 2.4702087855167525
Epoch: 18| Step: 24
Training loss: 3.1215100288391113
Validation loss: 2.4817986882847847
Epoch: 18| Step: 25
Training loss: 3.2995290756225586
Validation loss: 2.485714272629443
Epoch: 18| Step: 26
Training loss: 2.2484264373779297
Validation loss: 2.5140612262616053
Epoch: 18| Step: 27
Training loss: 2.0411863327026367
Validation loss: 2.496900516448261
Epoch: 18| Step: 28
Training loss: 2.813253879547119
Validation loss: 2.4760912270854702
Epoch: 18| Step: 29
Training loss: 2.4090704917907715
Validation loss: 2.485716084782168
Epoch: 18| Step: 30
Training loss: 3.2094035148620605
Validation loss: 2.520638062799577
Epoch: 18| Step: 31
Training loss: 3.7224206924438477
Validation loss: 2.5126021628757176
Epoch: 18| Step: 32
Training loss: 3.2465131282806396
Validation loss: 2.4996756186588205
Epoch: 18| Step: 33
Training loss: 3.485093832015991
Validation loss: 2.5184786148208507
Epoch: 18| Step: 34
Training loss: 3.1291184425354004
Validation loss: 2.499406986099353
Epoch: 18| Step: 35
Training loss: 3.610145330429077
Validation loss: 2.501454922792723
Epoch: 18| Step: 36
Training loss: 3.073627471923828
Validation loss: 2.4960912148729504
Epoch: 18| Step: 37
Training loss: 1.82618248462677
Validation loss: 2.5032791388120583
Epoch: 18| Step: 38
Training loss: 4.1095123291015625
Validation loss: 2.5006076363350846
Epoch: 18| Step: 39
Training loss: 2.8622965812683105
Validation loss: 2.5109524400971774
Epoch: 67| Step: 0
Training loss: 2.4849843978881836
Validation loss: 2.4730701618057362
Epoch: 18| Step: 1
Training loss: 2.2964963912963867
Validation loss: 2.506812989282951
Epoch: 18| Step: 2
Training loss: 1.837199330329895
Validation loss: 2.4764941013116633
Epoch: 18| Step: 3
Training loss: 3.7542245388031006
Validation loss: 2.493967498806741
Epoch: 18| Step: 4
Training loss: 1.7960392236709595
Validation loss: 2.4812455691879602
Epoch: 18| Step: 5
Training loss: 4.046745777130127
Validation loss: 2.5017451879789503
Epoch: 18| Step: 6
Training loss: 3.472698450088501
Validation loss: 2.4955415605641096
Epoch: 18| Step: 7
Training loss: 3.683443069458008
Validation loss: 2.4891841668876813
Epoch: 18| Step: 8
Training loss: 2.1685590744018555
Validation loss: 2.4856168915041916
Epoch: 18| Step: 9
Training loss: 2.566706657409668
Validation loss: 2.486429428882736
Epoch: 18| Step: 10
Training loss: 3.0442099571228027
Validation loss: 2.491823685254982
Epoch: 18| Step: 11
Training loss: 2.934083938598633
Validation loss: 2.4906704065611036
Epoch: 18| Step: 12
Training loss: 1.6999183893203735
Validation loss: 2.4826309783853215
Epoch: 18| Step: 13
Training loss: 3.3009021282196045
Validation loss: 2.4746482200759776
Epoch: 18| Step: 14
Training loss: 3.2966413497924805
Validation loss: 2.4896359100616237
Epoch: 18| Step: 15
Training loss: 1.9429676532745361
Validation loss: 2.4696073111870307
Epoch: 18| Step: 16
Training loss: 3.976567268371582
Validation loss: 2.4923641956109797
Epoch: 18| Step: 17
Training loss: 4.062219619750977
Validation loss: 2.4649645750471154
Epoch: 18| Step: 18
Training loss: 3.7833304405212402
Validation loss: 2.4812755224516065
Epoch: 18| Step: 19
Training loss: 3.65960693359375
Validation loss: 2.4894559795050313
Epoch: 18| Step: 20
Training loss: 3.251070499420166
Validation loss: 2.494449227405109
Epoch: 18| Step: 21
Training loss: 3.341808795928955
Validation loss: 2.457699486677595
Epoch: 18| Step: 22
Training loss: 3.329563617706299
Validation loss: 2.460788021842353
Epoch: 18| Step: 23
Training loss: 2.4204580783843994
Validation loss: 2.4914778325197506
Epoch: 18| Step: 24
Training loss: 3.41072416305542
Validation loss: 2.472495902356484
Epoch: 18| Step: 25
Training loss: 2.5067834854125977
Validation loss: 2.5064116399065197
Epoch: 18| Step: 26
Training loss: 2.506115436553955
Validation loss: 2.491440332193169
Epoch: 18| Step: 27
Training loss: 2.575526714324951
Validation loss: 2.5063216617639115
Epoch: 18| Step: 28
Training loss: 3.3526501655578613
Validation loss: 2.4980467995293707
Epoch: 18| Step: 29
Training loss: 2.5996711254119873
Validation loss: 2.4811935845038873
Epoch: 18| Step: 30
Training loss: 3.5364603996276855
Validation loss: 2.4875657129630766
Epoch: 18| Step: 31
Training loss: 2.9198269844055176
Validation loss: 2.481783510112076
Epoch: 18| Step: 32
Training loss: 3.584580421447754
Validation loss: 2.489458717030587
Epoch: 18| Step: 33
Training loss: 3.927288293838501
Validation loss: 2.490346854539226
Epoch: 18| Step: 34
Training loss: 2.0017342567443848
Validation loss: 2.492365439161122
Epoch: 18| Step: 35
Training loss: 2.897904872894287
Validation loss: 2.4808704544314377
Epoch: 18| Step: 36
Training loss: 2.736381769180298
Validation loss: 2.499476990253805
Epoch: 18| Step: 37
Training loss: 2.2486863136291504
Validation loss: 2.491768329263591
Epoch: 18| Step: 38
Training loss: 3.374931812286377
Validation loss: 2.5050992348211274
Epoch: 18| Step: 39
Training loss: 4.001900672912598
Validation loss: 2.489041304416794
Epoch: 68| Step: 0
Training loss: 3.8366551399230957
Validation loss: 2.5059511601496087
Epoch: 18| Step: 1
Training loss: 2.2306463718414307
Validation loss: 2.5007867470062037
Epoch: 18| Step: 2
Training loss: 2.5352020263671875
Validation loss: 2.495869440998105
Epoch: 18| Step: 3
Training loss: 3.24198055267334
Validation loss: 2.4932193756103516
Epoch: 18| Step: 4
Training loss: 3.172560930252075
Validation loss: 2.494902480420449
Epoch: 18| Step: 5
Training loss: 3.197496175765991
Validation loss: 2.502009868621826
Epoch: 18| Step: 6
Training loss: 2.6192450523376465
Validation loss: 2.4888973613437133
Epoch: 18| Step: 7
Training loss: 2.8157944679260254
Validation loss: 2.4945801436472284
Epoch: 18| Step: 8
Training loss: 2.252096652984619
Validation loss: 2.5115717246378066
Epoch: 18| Step: 9
Training loss: 2.433025360107422
Validation loss: 2.5059460856074054
Epoch: 18| Step: 10
Training loss: 3.721081018447876
Validation loss: 2.4921165824794085
Epoch: 18| Step: 11
Training loss: 3.419808864593506
Validation loss: 2.4660233559368328
Epoch: 18| Step: 12
Training loss: 1.924797773361206
Validation loss: 2.490601230010712
Epoch: 18| Step: 13
Training loss: 3.1174726486206055
Validation loss: 2.480664124591745
Epoch: 18| Step: 14
Training loss: 1.9292126893997192
Validation loss: 2.477983694282367
Epoch: 18| Step: 15
Training loss: 3.4882419109344482
Validation loss: 2.4818434192122316
Epoch: 18| Step: 16
Training loss: 3.3344156742095947
Validation loss: 2.5075131912025617
Epoch: 18| Step: 17
Training loss: 3.255728244781494
Validation loss: 2.5064357373354245
Epoch: 18| Step: 18
Training loss: 3.5389490127563477
Validation loss: 2.489214008660625
Epoch: 18| Step: 19
Training loss: 2.3266100883483887
Validation loss: 2.49464297637665
Epoch: 18| Step: 20
Training loss: 3.4984118938446045
Validation loss: 2.497955224496855
Epoch: 18| Step: 21
Training loss: 4.312626838684082
Validation loss: 2.4801425830923396
Epoch: 18| Step: 22
Training loss: 2.751636028289795
Validation loss: 2.4949992474892158
Epoch: 18| Step: 23
Training loss: 2.7520570755004883
Validation loss: 2.496530592870369
Epoch: 18| Step: 24
Training loss: 3.699186325073242
Validation loss: 2.4674387595636382
Epoch: 18| Step: 25
Training loss: 3.813724994659424
Validation loss: 2.4879978835153924
Epoch: 18| Step: 26
Training loss: 2.0438966751098633
Validation loss: 2.4846633132413136
Epoch: 18| Step: 27
Training loss: 4.1969523429870605
Validation loss: 2.48101264710049
Epoch: 18| Step: 28
Training loss: 2.9748551845550537
Validation loss: 2.4835388145858435
Epoch: 18| Step: 29
Training loss: 2.872574806213379
Validation loss: 2.499030550606817
Epoch: 18| Step: 30
Training loss: 3.2735347747802734
Validation loss: 2.475113677463943
Epoch: 18| Step: 31
Training loss: 4.04252815246582
Validation loss: 2.4742872612081843
Epoch: 18| Step: 32
Training loss: 3.2843289375305176
Validation loss: 2.4791192939813187
Epoch: 18| Step: 33
Training loss: 1.8791519403457642
Validation loss: 2.488772498617927
Epoch: 18| Step: 34
Training loss: 2.264177083969116
Validation loss: 2.4927118819394556
Epoch: 18| Step: 35
Training loss: 2.4536256790161133
Validation loss: 2.494102347668984
Epoch: 18| Step: 36
Training loss: 3.508474826812744
Validation loss: 2.502314272544367
Epoch: 18| Step: 37
Training loss: 2.8334085941314697
Validation loss: 2.5046199191388467
Epoch: 18| Step: 38
Training loss: 1.9166107177734375
Validation loss: 2.4807399425575203
Epoch: 18| Step: 39
Training loss: 3.7586185932159424
Validation loss: 2.4697600989032993
Epoch: 69| Step: 0
Training loss: 2.4357993602752686
Validation loss: 2.5048244874254406
Epoch: 18| Step: 1
Training loss: 4.098054885864258
Validation loss: 2.49712759385006
Epoch: 18| Step: 2
Training loss: 2.991992950439453
Validation loss: 2.513799394634988
Epoch: 18| Step: 3
Training loss: 2.916691303253174
Validation loss: 2.508421538545073
Epoch: 18| Step: 4
Training loss: 2.1562819480895996
Validation loss: 2.4896524861562166
Epoch: 18| Step: 5
Training loss: 2.424452066421509
Validation loss: 2.4756860544355654
Epoch: 18| Step: 6
Training loss: 3.1882989406585693
Validation loss: 2.4931924463176043
Epoch: 18| Step: 7
Training loss: 4.445279598236084
Validation loss: 2.4896044954121543
Epoch: 18| Step: 8
Training loss: 3.5964505672454834
Validation loss: 2.46919596280983
Epoch: 18| Step: 9
Training loss: 2.700470209121704
Validation loss: 2.4922060709205462
Epoch: 18| Step: 10
Training loss: 1.5780565738677979
Validation loss: 2.4800060858829416
Epoch: 18| Step: 11
Training loss: 3.6523854732513428
Validation loss: 2.5003891660155153
Epoch: 18| Step: 12
Training loss: 4.225982666015625
Validation loss: 2.491082200043493
Epoch: 18| Step: 13
Training loss: 2.409503698348999
Validation loss: 2.4774828420268546
Epoch: 18| Step: 14
Training loss: 3.599255084991455
Validation loss: 2.4554914724912575
Epoch: 18| Step: 15
Training loss: 3.9122719764709473
Validation loss: 2.5086831188888
Epoch: 18| Step: 16
Training loss: 4.32660436630249
Validation loss: 2.496536961562342
Epoch: 18| Step: 17
Training loss: 2.8756957054138184
Validation loss: 2.484414403387111
Epoch: 18| Step: 18
Training loss: 2.0146901607513428
Validation loss: 2.488926110507773
Epoch: 18| Step: 19
Training loss: 2.709542989730835
Validation loss: 2.485438674473934
Epoch: 18| Step: 20
Training loss: 2.8074395656585693
Validation loss: 2.50451726536099
Epoch: 18| Step: 21
Training loss: 2.964576482772827
Validation loss: 2.4912793224664043
Epoch: 18| Step: 22
Training loss: 2.6426079273223877
Validation loss: 2.4992624752813106
Epoch: 18| Step: 23
Training loss: 3.0220401287078857
Validation loss: 2.504238878222678
Epoch: 18| Step: 24
Training loss: 2.925692558288574
Validation loss: 2.4865340311750233
Epoch: 18| Step: 25
Training loss: 2.6299071311950684
Validation loss: 2.493037523125573
Epoch: 18| Step: 26
Training loss: 2.065913677215576
Validation loss: 2.491639252189252
Epoch: 18| Step: 27
Training loss: 2.7715096473693848
Validation loss: 2.485158536073973
Epoch: 18| Step: 28
Training loss: 2.4909486770629883
Validation loss: 2.470223358209185
Epoch: 18| Step: 29
Training loss: 2.916313648223877
Validation loss: 2.4970309528515493
Epoch: 18| Step: 30
Training loss: 3.2755770683288574
Validation loss: 2.4904493959687595
Epoch: 18| Step: 31
Training loss: 3.1869282722473145
Validation loss: 2.4798755834428525
Epoch: 18| Step: 32
Training loss: 1.8571981191635132
Validation loss: 2.492516089686387
Epoch: 18| Step: 33
Training loss: 4.43204402923584
Validation loss: 2.5037435824922523
Epoch: 18| Step: 34
Training loss: 3.346285104751587
Validation loss: 2.503683722276482
Epoch: 18| Step: 35
Training loss: 3.363729476928711
Validation loss: 2.5044148585779205
Epoch: 18| Step: 36
Training loss: 1.9517731666564941
Validation loss: 2.5011880723692532
Epoch: 18| Step: 37
Training loss: 2.631434679031372
Validation loss: 2.47423492661483
Epoch: 18| Step: 38
Training loss: 2.6374831199645996
Validation loss: 2.4622513047225185
Epoch: 18| Step: 39
Training loss: 3.1388497352600098
Validation loss: 2.4940053854914876
Epoch: 70| Step: 0
Training loss: 2.8709075450897217
Validation loss: 2.509930336218086
Epoch: 18| Step: 1
Training loss: 2.8714723587036133
Validation loss: 2.4883457688118913
Epoch: 18| Step: 2
Training loss: 2.3136322498321533
Validation loss: 2.472140754727151
Epoch: 18| Step: 3
Training loss: 3.4110097885131836
Validation loss: 2.4793927137800256
Epoch: 18| Step: 4
Training loss: 2.0729994773864746
Validation loss: 2.4738012183484415
Epoch: 18| Step: 5
Training loss: 3.475411891937256
Validation loss: 2.473607557283031
Epoch: 18| Step: 6
Training loss: 2.931778907775879
Validation loss: 2.4723370795627293
Epoch: 18| Step: 7
Training loss: 3.2239599227905273
Validation loss: 2.488721291795909
Epoch: 18| Step: 8
Training loss: 4.023849010467529
Validation loss: 2.4943689107894897
Epoch: 18| Step: 9
Training loss: 2.211576461791992
Validation loss: 2.487921755090892
Epoch: 18| Step: 10
Training loss: 2.629204034805298
Validation loss: 2.4910808587245805
Epoch: 18| Step: 11
Training loss: 3.6276168823242188
Validation loss: 2.499260003618199
Epoch: 18| Step: 12
Training loss: 3.334900379180908
Validation loss: 2.474898906062833
Epoch: 18| Step: 13
Training loss: 1.5857014656066895
Validation loss: 2.4977555566554446
Epoch: 18| Step: 14
Training loss: 3.593186855316162
Validation loss: 2.487833222039312
Epoch: 18| Step: 15
Training loss: 2.798081398010254
Validation loss: 2.488019977542136
Epoch: 18| Step: 16
Training loss: 3.2049736976623535
Validation loss: 2.4968552537959257
Epoch: 18| Step: 17
Training loss: 2.224937677383423
Validation loss: 2.4722388794096255
Epoch: 18| Step: 18
Training loss: 2.9392077922821045
Validation loss: 2.4658609268476637
Epoch: 18| Step: 19
Training loss: 3.94887113571167
Validation loss: 2.462937698089819
Epoch: 18| Step: 20
Training loss: 3.9809470176696777
Validation loss: 2.486467407761718
Epoch: 18| Step: 21
Training loss: 2.7076849937438965
Validation loss: 2.497843672045701
Epoch: 18| Step: 22
Training loss: 3.2121734619140625
Validation loss: 2.4703834502817057
Epoch: 18| Step: 23
Training loss: 3.36346697807312
Validation loss: 2.4662167957360794
Epoch: 18| Step: 24
Training loss: 3.7336721420288086
Validation loss: 2.483642257374825
Epoch: 18| Step: 25
Training loss: 2.4607462882995605
Validation loss: 2.484908832920541
Epoch: 18| Step: 26
Training loss: 2.3463187217712402
Validation loss: 2.465752965254749
Epoch: 18| Step: 27
Training loss: 2.5606930255889893
Validation loss: 2.4883942158102133
Epoch: 18| Step: 28
Training loss: 2.492337226867676
Validation loss: 2.482342960165559
Epoch: 18| Step: 29
Training loss: 3.025514602661133
Validation loss: 2.477901403852504
Epoch: 18| Step: 30
Training loss: 1.890734076499939
Validation loss: 2.450972633396121
Epoch: 18| Step: 31
Training loss: 3.1695950031280518
Validation loss: 2.462084538645024
Epoch: 18| Step: 32
Training loss: 2.7956466674804688
Validation loss: 2.468054033869462
Epoch: 18| Step: 33
Training loss: 3.7312912940979004
Validation loss: 2.4919068178684594
Epoch: 18| Step: 34
Training loss: 3.300508737564087
Validation loss: 2.468912282436014
Epoch: 18| Step: 35
Training loss: 3.850191831588745
Validation loss: 2.4944791931042567
Epoch: 18| Step: 36
Training loss: 3.341987371444702
Validation loss: 2.457692295527287
Epoch: 18| Step: 37
Training loss: 2.881364345550537
Validation loss: 2.472376459794079
Epoch: 18| Step: 38
Training loss: 2.6593122482299805
Validation loss: 2.464095376378341
Epoch: 18| Step: 39
Training loss: 2.9132652282714844
Validation loss: 2.4912919380681977
Epoch: 71| Step: 0
Training loss: 3.923280715942383
Validation loss: 2.4783996540865454
Epoch: 18| Step: 1
Training loss: 2.9380156993865967
Validation loss: 2.4979039919462136
Epoch: 18| Step: 2
Training loss: 3.8223166465759277
Validation loss: 2.4763650619726385
Epoch: 18| Step: 3
Training loss: 2.8145852088928223
Validation loss: 2.4696359188436605
Epoch: 18| Step: 4
Training loss: 3.1527459621429443
Validation loss: 2.4863536049136155
Epoch: 18| Step: 5
Training loss: 3.458189010620117
Validation loss: 2.476266439012486
Epoch: 18| Step: 6
Training loss: 2.4428772926330566
Validation loss: 2.4705909001741477
Epoch: 18| Step: 7
Training loss: 3.0063557624816895
Validation loss: 2.475465138181508
Epoch: 18| Step: 8
Training loss: 3.393899917602539
Validation loss: 2.4548256019894166
Epoch: 18| Step: 9
Training loss: 1.9414446353912354
Validation loss: 2.477510146957507
Epoch: 18| Step: 10
Training loss: 3.660562038421631
Validation loss: 2.4797515791954754
Epoch: 18| Step: 11
Training loss: 3.4487383365631104
Validation loss: 2.458459442467998
Epoch: 18| Step: 12
Training loss: 2.6033987998962402
Validation loss: 2.476434163052401
Epoch: 18| Step: 13
Training loss: 2.9333810806274414
Validation loss: 2.477636193199981
Epoch: 18| Step: 14
Training loss: 2.945908546447754
Validation loss: 2.4646336509169435
Epoch: 18| Step: 15
Training loss: 3.2619595527648926
Validation loss: 2.4918066083098487
Epoch: 18| Step: 16
Training loss: 2.917964220046997
Validation loss: 2.478301058570258
Epoch: 18| Step: 17
Training loss: 2.8725247383117676
Validation loss: 2.480819024628015
Epoch: 18| Step: 18
Training loss: 2.7227184772491455
Validation loss: 2.491497417148069
Epoch: 18| Step: 19
Training loss: 3.1990878582000732
Validation loss: 2.4758210542390673
Epoch: 18| Step: 20
Training loss: 3.0681357383728027
Validation loss: 2.4631191882298147
Epoch: 18| Step: 21
Training loss: 3.270293951034546
Validation loss: 2.484301314937125
Epoch: 18| Step: 22
Training loss: 3.608062267303467
Validation loss: 2.459329358107752
Epoch: 18| Step: 23
Training loss: 2.980137825012207
Validation loss: 2.4923729038924622
Epoch: 18| Step: 24
Training loss: 2.8746275901794434
Validation loss: 2.4858691246389486
Epoch: 18| Step: 25
Training loss: 2.2378573417663574
Validation loss: 2.486576260422631
Epoch: 18| Step: 26
Training loss: 3.170583963394165
Validation loss: 2.4877145736337565
Epoch: 18| Step: 27
Training loss: 2.93245267868042
Validation loss: 2.4928978089805987
Epoch: 18| Step: 28
Training loss: 2.0920796394348145
Validation loss: 2.500892721491752
Epoch: 18| Step: 29
Training loss: 3.385941505432129
Validation loss: 2.46136032848907
Epoch: 18| Step: 30
Training loss: 4.642454624176025
Validation loss: 2.486000265148904
Epoch: 18| Step: 31
Training loss: 2.130718231201172
Validation loss: 2.459558759661887
Epoch: 18| Step: 32
Training loss: 3.000049591064453
Validation loss: 2.4964130816699788
Epoch: 18| Step: 33
Training loss: 1.8265235424041748
Validation loss: 2.478583951648191
Epoch: 18| Step: 34
Training loss: 1.8440961837768555
Validation loss: 2.4826900547356914
Epoch: 18| Step: 35
Training loss: 3.957927703857422
Validation loss: 2.4771023294050916
Epoch: 18| Step: 36
Training loss: 2.710831880569458
Validation loss: 2.472644502310444
Epoch: 18| Step: 37
Training loss: 2.3793222904205322
Validation loss: 2.482245182819504
Epoch: 18| Step: 38
Training loss: 3.281287908554077
Validation loss: 2.4678702182906993
Epoch: 18| Step: 39
Training loss: 3.356543779373169
Validation loss: 2.500386497957243
Epoch: 72| Step: 0
Training loss: 3.123809337615967
Validation loss: 2.4717279492522315
Epoch: 18| Step: 1
Training loss: 1.1951088905334473
Validation loss: 2.46721955083257
Epoch: 18| Step: 2
Training loss: 3.8336169719696045
Validation loss: 2.492825180506535
Epoch: 18| Step: 3
Training loss: 2.864851474761963
Validation loss: 2.4964296714865046
Epoch: 18| Step: 4
Training loss: 2.714977741241455
Validation loss: 2.488694607782707
Epoch: 18| Step: 5
Training loss: 3.1555426120758057
Validation loss: 2.480465820367388
Epoch: 18| Step: 6
Training loss: 2.732323169708252
Validation loss: 2.488768212229228
Epoch: 18| Step: 7
Training loss: 2.921633243560791
Validation loss: 2.482314653533826
Epoch: 18| Step: 8
Training loss: 3.238529682159424
Validation loss: 2.4698874307193344
Epoch: 18| Step: 9
Training loss: 4.312346935272217
Validation loss: 2.475529536926489
Epoch: 18| Step: 10
Training loss: 2.242623805999756
Validation loss: 2.4751599795526738
Epoch: 18| Step: 11
Training loss: 3.6916537284851074
Validation loss: 2.4880454368728526
Epoch: 18| Step: 12
Training loss: 3.0247607231140137
Validation loss: 2.467010664425308
Epoch: 18| Step: 13
Training loss: 4.214306831359863
Validation loss: 2.479520099626171
Epoch: 18| Step: 14
Training loss: 3.2979583740234375
Validation loss: 2.459564435396263
Epoch: 18| Step: 15
Training loss: 3.193946599960327
Validation loss: 2.4889903561674434
Epoch: 18| Step: 16
Training loss: 2.826679229736328
Validation loss: 2.4828755804103055
Epoch: 18| Step: 17
Training loss: 2.898366689682007
Validation loss: 2.48304358660746
Epoch: 18| Step: 18
Training loss: 3.5502846240997314
Validation loss: 2.475368521196379
Epoch: 18| Step: 19
Training loss: 2.570862293243408
Validation loss: 2.479107801862758
Epoch: 18| Step: 20
Training loss: 2.450258255004883
Validation loss: 2.486835047495451
Epoch: 18| Step: 21
Training loss: 2.7698302268981934
Validation loss: 2.4766059504996103
Epoch: 18| Step: 22
Training loss: 1.9841530323028564
Validation loss: 2.4627313528129524
Epoch: 18| Step: 23
Training loss: 2.523280620574951
Validation loss: 2.4676801489411497
Epoch: 18| Step: 24
Training loss: 3.572373628616333
Validation loss: 2.477934674393359
Epoch: 18| Step: 25
Training loss: 3.5678915977478027
Validation loss: 2.488501908967821
Epoch: 18| Step: 26
Training loss: 2.2092151641845703
Validation loss: 2.479186222707625
Epoch: 18| Step: 27
Training loss: 2.398329496383667
Validation loss: 2.4841035523002954
Epoch: 18| Step: 28
Training loss: 1.8506495952606201
Validation loss: 2.4823867438508453
Epoch: 18| Step: 29
Training loss: 2.8759517669677734
Validation loss: 2.4660857752930347
Epoch: 18| Step: 30
Training loss: 3.5915184020996094
Validation loss: 2.48803530322562
Epoch: 18| Step: 31
Training loss: 3.135801315307617
Validation loss: 2.4908143865118784
Epoch: 18| Step: 32
Training loss: 4.087658882141113
Validation loss: 2.4685041527096314
Epoch: 18| Step: 33
Training loss: 2.5320305824279785
Validation loss: 2.4593780658227935
Epoch: 18| Step: 34
Training loss: 3.1675148010253906
Validation loss: 2.4930858903651614
Epoch: 18| Step: 35
Training loss: 3.2053565979003906
Validation loss: 2.4613625660217067
Epoch: 18| Step: 36
Training loss: 2.3914525508880615
Validation loss: 2.4689814272544366
Epoch: 18| Step: 37
Training loss: 2.8443264961242676
Validation loss: 2.4509648273317075
Epoch: 18| Step: 38
Training loss: 4.444239616394043
Validation loss: 2.4679357388036713
Epoch: 18| Step: 39
Training loss: 2.37724232673645
Validation loss: 2.4769225832369686
Epoch: 73| Step: 0
Training loss: 3.5125484466552734
Validation loss: 2.4901947632110377
Epoch: 18| Step: 1
Training loss: 3.91786789894104
Validation loss: 2.4645332218074114
Epoch: 18| Step: 2
Training loss: 2.901559352874756
Validation loss: 2.4859924657310515
Epoch: 18| Step: 3
Training loss: 3.8030245304107666
Validation loss: 2.4912830994283555
Epoch: 18| Step: 4
Training loss: 2.2369606494903564
Validation loss: 2.471806716575897
Epoch: 18| Step: 5
Training loss: 3.336108684539795
Validation loss: 2.47790013757541
Epoch: 18| Step: 6
Training loss: 3.3436689376831055
Validation loss: 2.486282995278887
Epoch: 18| Step: 7
Training loss: 1.7329432964324951
Validation loss: 2.4942940482132725
Epoch: 18| Step: 8
Training loss: 2.9772820472717285
Validation loss: 2.500060577186749
Epoch: 18| Step: 9
Training loss: 3.1672122478485107
Validation loss: 2.479939694027249
Epoch: 18| Step: 10
Training loss: 4.253859519958496
Validation loss: 2.4696393218829478
Epoch: 18| Step: 11
Training loss: 3.15777587890625
Validation loss: 2.491949937326445
Epoch: 18| Step: 12
Training loss: 3.945427894592285
Validation loss: 2.4843048251790107
Epoch: 18| Step: 13
Training loss: 2.0901317596435547
Validation loss: 2.4645643654487115
Epoch: 18| Step: 14
Training loss: 2.1433866024017334
Validation loss: 2.484227005526316
Epoch: 18| Step: 15
Training loss: 2.6334640979766846
Validation loss: 2.4935557447749077
Epoch: 18| Step: 16
Training loss: 3.3808584213256836
Validation loss: 2.498315960383244
Epoch: 18| Step: 17
Training loss: 3.947389841079712
Validation loss: 2.46729139115313
Epoch: 18| Step: 18
Training loss: 3.9468941688537598
Validation loss: 2.4634613776378496
Epoch: 18| Step: 19
Training loss: 3.28434419631958
Validation loss: 2.4846863437899582
Epoch: 18| Step: 20
Training loss: 2.7217140197753906
Validation loss: 2.455113774580921
Epoch: 18| Step: 21
Training loss: 2.10066819190979
Validation loss: 2.4637360881558426
Epoch: 18| Step: 22
Training loss: 3.083395004272461
Validation loss: 2.481451590284169
Epoch: 18| Step: 23
Training loss: 3.5479488372802734
Validation loss: 2.455876844392406
Epoch: 18| Step: 24
Training loss: 3.2462363243103027
Validation loss: 2.467416679258827
Epoch: 18| Step: 25
Training loss: 3.238379955291748
Validation loss: 2.4674603784684654
Epoch: 18| Step: 26
Training loss: 2.540870189666748
Validation loss: 2.46769251068719
Epoch: 18| Step: 27
Training loss: 2.26435923576355
Validation loss: 2.4651549754382893
Epoch: 18| Step: 28
Training loss: 2.2570393085479736
Validation loss: 2.459647103179273
Epoch: 18| Step: 29
Training loss: 1.9323982000350952
Validation loss: 2.4862753555929062
Epoch: 18| Step: 30
Training loss: 2.9559268951416016
Validation loss: 2.4803527019006744
Epoch: 18| Step: 31
Training loss: 2.4682226181030273
Validation loss: 2.4911395697284946
Epoch: 18| Step: 32
Training loss: 3.754204273223877
Validation loss: 2.484770267129802
Epoch: 18| Step: 33
Training loss: 3.530147075653076
Validation loss: 2.450718167016832
Epoch: 18| Step: 34
Training loss: 2.675832748413086
Validation loss: 2.483045909044554
Epoch: 18| Step: 35
Training loss: 3.472794532775879
Validation loss: 2.460844446429246
Epoch: 18| Step: 36
Training loss: 2.7512197494506836
Validation loss: 2.4846069504031174
Epoch: 18| Step: 37
Training loss: 1.6226179599761963
Validation loss: 2.496752548560822
Epoch: 18| Step: 38
Training loss: 2.5579240322113037
Validation loss: 2.4778996285774726
Epoch: 18| Step: 39
Training loss: 3.857869863510132
Validation loss: 2.468391557391599
Epoch: 74| Step: 0
Training loss: 3.1679444313049316
Validation loss: 2.470694588242675
Epoch: 18| Step: 1
Training loss: 2.3056955337524414
Validation loss: 2.4615232138324985
Epoch: 18| Step: 2
Training loss: 3.92087984085083
Validation loss: 2.470635156837299
Epoch: 18| Step: 3
Training loss: 3.4983277320861816
Validation loss: 2.4669984844948747
Epoch: 18| Step: 4
Training loss: 3.135468006134033
Validation loss: 2.4804385951954684
Epoch: 18| Step: 5
Training loss: 1.911594271659851
Validation loss: 2.4785235854361556
Epoch: 18| Step: 6
Training loss: 3.3875718116760254
Validation loss: 2.4564843606605806
Epoch: 18| Step: 7
Training loss: 2.5286216735839844
Validation loss: 2.4802071259176133
Epoch: 18| Step: 8
Training loss: 3.328247547149658
Validation loss: 2.484794093550538
Epoch: 18| Step: 9
Training loss: 2.610020637512207
Validation loss: 2.492017320591769
Epoch: 18| Step: 10
Training loss: 4.009692668914795
Validation loss: 2.459932505655632
Epoch: 18| Step: 11
Training loss: 2.04714035987854
Validation loss: 2.475333919628061
Epoch: 18| Step: 12
Training loss: 3.969055652618408
Validation loss: 2.454786412149882
Epoch: 18| Step: 13
Training loss: 2.71435546875
Validation loss: 2.4756824910211908
Epoch: 18| Step: 14
Training loss: 3.080454111099243
Validation loss: 2.44092377998846
Epoch: 18| Step: 15
Training loss: 2.458744525909424
Validation loss: 2.4762904541097956
Epoch: 18| Step: 16
Training loss: 3.2638156414031982
Validation loss: 2.4658565847136136
Epoch: 18| Step: 17
Training loss: 2.8761215209960938
Validation loss: 2.478875083031414
Epoch: 18| Step: 18
Training loss: 3.3036293983459473
Validation loss: 2.485914465334776
Epoch: 18| Step: 19
Training loss: 3.5531716346740723
Validation loss: 2.4610466562586724
Epoch: 18| Step: 20
Training loss: 2.120011329650879
Validation loss: 2.4848892843122963
Epoch: 18| Step: 21
Training loss: 2.2257752418518066
Validation loss: 2.4594075062292085
Epoch: 18| Step: 22
Training loss: 2.4183902740478516
Validation loss: 2.461887291009478
Epoch: 18| Step: 23
Training loss: 2.7751646041870117
Validation loss: 2.4761246483531787
Epoch: 18| Step: 24
Training loss: 3.1943225860595703
Validation loss: 2.463444822983776
Epoch: 18| Step: 25
Training loss: 3.805560827255249
Validation loss: 2.472753252056863
Epoch: 18| Step: 26
Training loss: 3.247317314147949
Validation loss: 2.48569851298984
Epoch: 18| Step: 27
Training loss: 2.5390663146972656
Validation loss: 2.4894540550039825
Epoch: 18| Step: 28
Training loss: 3.2959237098693848
Validation loss: 2.484899240432026
Epoch: 18| Step: 29
Training loss: 2.9052586555480957
Validation loss: 2.480905666625757
Epoch: 18| Step: 30
Training loss: 1.9571754932403564
Validation loss: 2.4735900360903296
Epoch: 18| Step: 31
Training loss: 3.2804622650146484
Validation loss: 2.4923114999592735
Epoch: 18| Step: 32
Training loss: 2.9255740642547607
Validation loss: 2.482034561445387
Epoch: 18| Step: 33
Training loss: 2.6900217533111572
Validation loss: 2.4967223808919785
Epoch: 18| Step: 34
Training loss: 4.018994331359863
Validation loss: 2.4839002125554805
Epoch: 18| Step: 35
Training loss: 2.437439441680908
Validation loss: 2.4744654679469926
Epoch: 18| Step: 36
Training loss: 3.2785861492156982
Validation loss: 2.4830232609947807
Epoch: 18| Step: 37
Training loss: 3.0663373470306396
Validation loss: 2.493241706340433
Epoch: 18| Step: 38
Training loss: 3.930933713912964
Validation loss: 2.4623365204968897
Epoch: 18| Step: 39
Training loss: 1.916808843612671
Validation loss: 2.4703582602439167
Epoch: 75| Step: 0
Training loss: 2.5507168769836426
Validation loss: 2.477462543858041
Epoch: 18| Step: 1
Training loss: 3.0627691745758057
Validation loss: 2.478071986342506
Epoch: 18| Step: 2
Training loss: 3.2917726039886475
Validation loss: 2.469200647134575
Epoch: 18| Step: 3
Training loss: 2.4845168590545654
Validation loss: 2.4819949299311466
Epoch: 18| Step: 4
Training loss: 2.64900279045105
Validation loss: 2.483802140187874
Epoch: 18| Step: 5
Training loss: 3.3275203704833984
Validation loss: 2.474808535129904
Epoch: 18| Step: 6
Training loss: 2.7888951301574707
Validation loss: 2.4594173277024742
Epoch: 18| Step: 7
Training loss: 3.386289596557617
Validation loss: 2.461929858159676
Epoch: 18| Step: 8
Training loss: 3.059098482131958
Validation loss: 2.4774087401602767
Epoch: 18| Step: 9
Training loss: 2.5438642501831055
Validation loss: 2.458371160699309
Epoch: 18| Step: 10
Training loss: 3.6939196586608887
Validation loss: 2.4560078433949313
Epoch: 18| Step: 11
Training loss: 2.426750659942627
Validation loss: 2.4596235700648466
Epoch: 18| Step: 12
Training loss: 3.7544450759887695
Validation loss: 2.4441019596813396
Epoch: 18| Step: 13
Training loss: 2.471924304962158
Validation loss: 2.489974228598231
Epoch: 18| Step: 14
Training loss: 2.8869457244873047
Validation loss: 2.464432935920551
Epoch: 18| Step: 15
Training loss: 3.168947219848633
Validation loss: 2.462464840292073
Epoch: 18| Step: 16
Training loss: 2.758676528930664
Validation loss: 2.47483424402827
Epoch: 18| Step: 17
Training loss: 2.2612133026123047
Validation loss: 2.4848973956897105
Epoch: 18| Step: 18
Training loss: 3.938591480255127
Validation loss: 2.4897860863225922
Epoch: 18| Step: 19
Training loss: 2.556682586669922
Validation loss: 2.4630074273768088
Epoch: 18| Step: 20
Training loss: 2.9692223072052
Validation loss: 2.4698478652418947
Epoch: 18| Step: 21
Training loss: 3.1545934677124023
Validation loss: 2.4556961402618627
Epoch: 18| Step: 22
Training loss: 2.0518898963928223
Validation loss: 2.4564827543368444
Epoch: 18| Step: 23
Training loss: 2.4895882606506348
Validation loss: 2.461887711243664
Epoch: 18| Step: 24
Training loss: 3.263087272644043
Validation loss: 2.484417237823816
Epoch: 18| Step: 25
Training loss: 2.8779640197753906
Validation loss: 2.47431672391274
Epoch: 18| Step: 26
Training loss: 3.0290110111236572
Validation loss: 2.4735457914338697
Epoch: 18| Step: 27
Training loss: 2.2359697818756104
Validation loss: 2.471698814158817
Epoch: 18| Step: 28
Training loss: 3.2481658458709717
Validation loss: 2.4536128108449975
Epoch: 18| Step: 29
Training loss: 2.7962818145751953
Validation loss: 2.476259871352491
Epoch: 18| Step: 30
Training loss: 3.1210246086120605
Validation loss: 2.468891961111439
Epoch: 18| Step: 31
Training loss: 3.3533151149749756
Validation loss: 2.4660796072843265
Epoch: 18| Step: 32
Training loss: 2.6995182037353516
Validation loss: 2.491367971296791
Epoch: 18| Step: 33
Training loss: 3.301785469055176
Validation loss: 2.4670133161887846
Epoch: 18| Step: 34
Training loss: 3.7770328521728516
Validation loss: 2.485062145500732
Epoch: 18| Step: 35
Training loss: 1.7028744220733643
Validation loss: 2.4778598272543157
Epoch: 18| Step: 36
Training loss: 2.4363515377044678
Validation loss: 2.4728012788209983
Epoch: 18| Step: 37
Training loss: 2.537264347076416
Validation loss: 2.4703476463290426
Epoch: 18| Step: 38
Training loss: 4.636528015136719
Validation loss: 2.4577518461419525
Epoch: 18| Step: 39
Training loss: 4.358546257019043
Validation loss: 2.482635796498909
Epoch: 76| Step: 0
Training loss: 2.9564056396484375
Validation loss: 2.487942585842215
Epoch: 18| Step: 1
Training loss: 2.7971138954162598
Validation loss: 2.4900715642695803
Epoch: 18| Step: 2
Training loss: 2.796891927719116
Validation loss: 2.462795444529691
Epoch: 18| Step: 3
Training loss: 3.1807188987731934
Validation loss: 2.4779784610803177
Epoch: 18| Step: 4
Training loss: 2.747310161590576
Validation loss: 2.463118318173525
Epoch: 18| Step: 5
Training loss: 2.0958967208862305
Validation loss: 2.470202615792803
Epoch: 18| Step: 6
Training loss: 2.9855518341064453
Validation loss: 2.488983680876039
Epoch: 18| Step: 7
Training loss: 3.625166654586792
Validation loss: 2.4829881465692316
Epoch: 18| Step: 8
Training loss: 3.060546398162842
Validation loss: 2.4733999667407796
Epoch: 18| Step: 9
Training loss: 2.241368293762207
Validation loss: 2.4866868712061603
Epoch: 18| Step: 10
Training loss: 4.30301570892334
Validation loss: 2.460335471647249
Epoch: 18| Step: 11
Training loss: 3.343919277191162
Validation loss: 2.454147229091727
Epoch: 18| Step: 12
Training loss: 2.8967833518981934
Validation loss: 2.471526706819054
Epoch: 18| Step: 13
Training loss: 2.484302043914795
Validation loss: 2.4696436734508267
Epoch: 18| Step: 14
Training loss: 2.385051965713501
Validation loss: 2.4649679317748805
Epoch: 18| Step: 15
Training loss: 4.4467267990112305
Validation loss: 2.4600884485587797
Epoch: 18| Step: 16
Training loss: 3.12581205368042
Validation loss: 2.477070714072358
Epoch: 18| Step: 17
Training loss: 3.495715618133545
Validation loss: 2.4564677108105997
Epoch: 18| Step: 18
Training loss: 1.8787169456481934
Validation loss: 2.4618152568666196
Epoch: 18| Step: 19
Training loss: 3.56485652923584
Validation loss: 2.4759508851620793
Epoch: 18| Step: 20
Training loss: 2.5978810787200928
Validation loss: 2.479228726393885
Epoch: 18| Step: 21
Training loss: 2.323896646499634
Validation loss: 2.47673131750642
Epoch: 18| Step: 22
Training loss: 2.285083770751953
Validation loss: 2.451826936049427
Epoch: 18| Step: 23
Training loss: 3.0505077838897705
Validation loss: 2.46283698939591
Epoch: 18| Step: 24
Training loss: 2.502387046813965
Validation loss: 2.4630208615776445
Epoch: 18| Step: 25
Training loss: 2.8070549964904785
Validation loss: 2.4477881141703763
Epoch: 18| Step: 26
Training loss: 3.8765037059783936
Validation loss: 2.4597490562809456
Epoch: 18| Step: 27
Training loss: 3.1886215209960938
Validation loss: 2.4760249570119295
Epoch: 18| Step: 28
Training loss: 3.2379825115203857
Validation loss: 2.462514079732003
Epoch: 18| Step: 29
Training loss: 3.412940502166748
Validation loss: 2.449606422040102
Epoch: 18| Step: 30
Training loss: 2.73873233795166
Validation loss: 2.4707604655258946
Epoch: 18| Step: 31
Training loss: 2.800926446914673
Validation loss: 2.4486445968957256
Epoch: 18| Step: 32
Training loss: 2.893434524536133
Validation loss: 2.469521823546869
Epoch: 18| Step: 33
Training loss: 3.1998136043548584
Validation loss: 2.4687770630815904
Epoch: 18| Step: 34
Training loss: 3.35573148727417
Validation loss: 2.4492046747276253
Epoch: 18| Step: 35
Training loss: 2.7565574645996094
Validation loss: 2.4586052277105317
Epoch: 18| Step: 36
Training loss: 3.048396110534668
Validation loss: 2.4669007020030946
Epoch: 18| Step: 37
Training loss: 2.3099288940429688
Validation loss: 2.468622741081732
Epoch: 18| Step: 38
Training loss: 2.9103217124938965
Validation loss: 2.43933896002152
Epoch: 18| Step: 39
Training loss: 3.9088973999023438
Validation loss: 2.450568713730188
Epoch: 77| Step: 0
Training loss: 3.0763392448425293
Validation loss: 2.437570733132122
Epoch: 18| Step: 1
Training loss: 2.6436123847961426
Validation loss: 2.443538034562584
Epoch: 18| Step: 2
Training loss: 2.964460611343384
Validation loss: 2.436413400464778
Epoch: 18| Step: 3
Training loss: 2.813025951385498
Validation loss: 2.436172248648225
Epoch: 18| Step: 4
Training loss: 2.458317995071411
Validation loss: 2.459696220837051
Epoch: 18| Step: 5
Training loss: 2.4660778045654297
Validation loss: 2.4579013285877034
Epoch: 18| Step: 6
Training loss: 3.3143887519836426
Validation loss: 2.4554584695280885
Epoch: 18| Step: 7
Training loss: 1.914806842803955
Validation loss: 2.4338980818823943
Epoch: 18| Step: 8
Training loss: 3.272399425506592
Validation loss: 2.4479929581820534
Epoch: 18| Step: 9
Training loss: 1.4140057563781738
Validation loss: 2.4457636239717333
Epoch: 18| Step: 10
Training loss: 2.690746784210205
Validation loss: 2.4767352934363935
Epoch: 18| Step: 11
Training loss: 2.4115519523620605
Validation loss: 2.4233702052411417
Epoch: 18| Step: 12
Training loss: 2.9763762950897217
Validation loss: 2.4412433406431897
Epoch: 18| Step: 13
Training loss: 3.5659756660461426
Validation loss: 2.449486476911915
Epoch: 18| Step: 14
Training loss: 4.03681755065918
Validation loss: 2.4658505213346413
Epoch: 18| Step: 15
Training loss: 2.875020742416382
Validation loss: 2.4423789720741107
Epoch: 18| Step: 16
Training loss: 2.219216823577881
Validation loss: 2.4382091323248773
Epoch: 18| Step: 17
Training loss: 3.152895450592041
Validation loss: 2.4441044124767934
Epoch: 18| Step: 18
Training loss: 3.0270185470581055
Validation loss: 2.439458956821359
Epoch: 18| Step: 19
Training loss: 4.820224761962891
Validation loss: 2.41723614287891
Epoch: 18| Step: 20
Training loss: 1.926041603088379
Validation loss: 2.4515999941517124
Epoch: 18| Step: 21
Training loss: 3.031172752380371
Validation loss: 2.4612582295918637
Epoch: 18| Step: 22
Training loss: 3.1078953742980957
Validation loss: 2.4544730846830407
Epoch: 18| Step: 23
Training loss: 3.64548921585083
Validation loss: 2.4551418753836654
Epoch: 18| Step: 24
Training loss: 2.264590263366699
Validation loss: 2.430593966151313
Epoch: 18| Step: 25
Training loss: 3.118288278579712
Validation loss: 2.449635639036302
Epoch: 18| Step: 26
Training loss: 2.0684642791748047
Validation loss: 2.455924241662883
Epoch: 18| Step: 27
Training loss: 2.699216842651367
Validation loss: 2.44100563131648
Epoch: 18| Step: 28
Training loss: 3.016190528869629
Validation loss: 2.4564344214020872
Epoch: 18| Step: 29
Training loss: 2.3011484146118164
Validation loss: 2.448248376949228
Epoch: 18| Step: 30
Training loss: 2.741011619567871
Validation loss: 2.463296751324221
Epoch: 18| Step: 31
Training loss: 2.554243564605713
Validation loss: 2.457512533064369
Epoch: 18| Step: 32
Training loss: 4.254042148590088
Validation loss: 2.4427726989169773
Epoch: 18| Step: 33
Training loss: 3.7575626373291016
Validation loss: 2.4391786589039315
Epoch: 18| Step: 34
Training loss: 3.400294542312622
Validation loss: 2.451145057197955
Epoch: 18| Step: 35
Training loss: 3.1907715797424316
Validation loss: 2.4662897295231443
Epoch: 18| Step: 36
Training loss: 3.322666645050049
Validation loss: 2.45248785807932
Epoch: 18| Step: 37
Training loss: 3.377561092376709
Validation loss: 2.4331168768217237
Epoch: 18| Step: 38
Training loss: 3.450657844543457
Validation loss: 2.455203267310163
Epoch: 18| Step: 39
Training loss: 2.643219470977783
Validation loss: 2.4332657276297645
Epoch: 78| Step: 0
Training loss: 2.8543851375579834
Validation loss: 2.441588012863406
Epoch: 18| Step: 1
Training loss: 3.220371723175049
Validation loss: 2.4587897516840655
Epoch: 18| Step: 2
Training loss: 3.3681552410125732
Validation loss: 2.457295109042161
Epoch: 18| Step: 3
Training loss: 2.5346553325653076
Validation loss: 2.468528666084619
Epoch: 18| Step: 4
Training loss: 2.226194381713867
Validation loss: 2.455546147531743
Epoch: 18| Step: 5
Training loss: 3.079280138015747
Validation loss: 2.4356686571519153
Epoch: 18| Step: 6
Training loss: 3.0683434009552
Validation loss: 2.457205060574648
Epoch: 18| Step: 7
Training loss: 4.16441011428833
Validation loss: 2.437008892031882
Epoch: 18| Step: 8
Training loss: 3.6594676971435547
Validation loss: 2.4278270829495767
Epoch: 18| Step: 9
Training loss: 2.4785008430480957
Validation loss: 2.4367287810757863
Epoch: 18| Step: 10
Training loss: 2.91801118850708
Validation loss: 2.4688887287386887
Epoch: 18| Step: 11
Training loss: 2.2861742973327637
Validation loss: 2.4423469124938086
Epoch: 18| Step: 12
Training loss: 3.3443777561187744
Validation loss: 2.4367593312435014
Epoch: 18| Step: 13
Training loss: 3.2689337730407715
Validation loss: 2.436730775044119
Epoch: 18| Step: 14
Training loss: 2.8003220558166504
Validation loss: 2.443059027623787
Epoch: 18| Step: 15
Training loss: 2.94671368598938
Validation loss: 2.452750272888074
Epoch: 18| Step: 16
Training loss: 2.9037528038024902
Validation loss: 2.4508546384976064
Epoch: 18| Step: 17
Training loss: 3.1011266708374023
Validation loss: 2.4585466539259437
Epoch: 18| Step: 18
Training loss: 3.5137557983398438
Validation loss: 2.415588056440834
Epoch: 18| Step: 19
Training loss: 2.8290042877197266
Validation loss: 2.421009283271625
Epoch: 18| Step: 20
Training loss: 2.913036823272705
Validation loss: 2.4713895320892334
Epoch: 18| Step: 21
Training loss: 4.517626762390137
Validation loss: 2.4444375003842143
Epoch: 18| Step: 22
Training loss: 2.5636987686157227
Validation loss: 2.4474115560380674
Epoch: 18| Step: 23
Training loss: 1.8784122467041016
Validation loss: 2.4612677397487834
Epoch: 18| Step: 24
Training loss: 3.0994980335235596
Validation loss: 2.4388392949275834
Epoch: 18| Step: 25
Training loss: 2.6001763343811035
Validation loss: 2.443705625671277
Epoch: 18| Step: 26
Training loss: 2.611599922180176
Validation loss: 2.4470264499993633
Epoch: 18| Step: 27
Training loss: 2.2657036781311035
Validation loss: 2.436380532148073
Epoch: 18| Step: 28
Training loss: 2.96693754196167
Validation loss: 2.451714196651102
Epoch: 18| Step: 29
Training loss: 3.8184895515441895
Validation loss: 2.44764502442998
Epoch: 18| Step: 30
Training loss: 2.7290964126586914
Validation loss: 2.4302034035003444
Epoch: 18| Step: 31
Training loss: 2.5586066246032715
Validation loss: 2.444638683641557
Epoch: 18| Step: 32
Training loss: 2.8511803150177
Validation loss: 2.432159922963424
Epoch: 18| Step: 33
Training loss: 2.5437428951263428
Validation loss: 2.431940636188864
Epoch: 18| Step: 34
Training loss: 3.054555892944336
Validation loss: 2.438824679354112
Epoch: 18| Step: 35
Training loss: 2.7834630012512207
Validation loss: 2.4386129615118177
Epoch: 18| Step: 36
Training loss: 2.377041816711426
Validation loss: 2.44326053677703
Epoch: 18| Step: 37
Training loss: 1.742093801498413
Validation loss: 2.4408483488096606
Epoch: 18| Step: 38
Training loss: 4.081360816955566
Validation loss: 2.4472006229187944
Epoch: 18| Step: 39
Training loss: 4.3864617347717285
Validation loss: 2.460696066026207
Epoch: 79| Step: 0
Training loss: 1.902449131011963
Validation loss: 2.4542142881763924
Epoch: 18| Step: 1
Training loss: 2.6349563598632812
Validation loss: 2.44481811420523
Epoch: 18| Step: 2
Training loss: 3.409830093383789
Validation loss: 2.4320312524013383
Epoch: 18| Step: 3
Training loss: 2.642106533050537
Validation loss: 2.42226128784015
Epoch: 18| Step: 4
Training loss: 1.8902764320373535
Validation loss: 2.419240631645532
Epoch: 18| Step: 5
Training loss: 3.3883581161499023
Validation loss: 2.4424688833222974
Epoch: 18| Step: 6
Training loss: 2.8487706184387207
Validation loss: 2.448250959245421
Epoch: 18| Step: 7
Training loss: 3.5412020683288574
Validation loss: 2.4244922836907477
Epoch: 18| Step: 8
Training loss: 2.819340705871582
Validation loss: 2.428439323850673
Epoch: 18| Step: 9
Training loss: 2.7986669540405273
Validation loss: 2.4382003691556644
Epoch: 18| Step: 10
Training loss: 4.475574970245361
Validation loss: 2.4091338545298404
Epoch: 18| Step: 11
Training loss: 3.080111026763916
Validation loss: 2.451033791192144
Epoch: 18| Step: 12
Training loss: 3.686934471130371
Validation loss: 2.421796485674467
Epoch: 18| Step: 13
Training loss: 2.943905830383301
Validation loss: 2.452759324217872
Epoch: 18| Step: 14
Training loss: 3.228701114654541
Validation loss: 2.4396454850546747
Epoch: 18| Step: 15
Training loss: 1.7918672561645508
Validation loss: 2.444129401402508
Epoch: 18| Step: 16
Training loss: 2.21750807762146
Validation loss: 2.430838768430751
Epoch: 18| Step: 17
Training loss: 2.109983444213867
Validation loss: 2.443945766352921
Epoch: 18| Step: 18
Training loss: 2.796924114227295
Validation loss: 2.444271775887167
Epoch: 18| Step: 19
Training loss: 3.471498489379883
Validation loss: 2.450729946438357
Epoch: 18| Step: 20
Training loss: 1.9188711643218994
Validation loss: 2.429216320566136
Epoch: 18| Step: 21
Training loss: 3.7676117420196533
Validation loss: 2.44178844613137
Epoch: 18| Step: 22
Training loss: 2.532032012939453
Validation loss: 2.4632291896737737
Epoch: 18| Step: 23
Training loss: 4.236642360687256
Validation loss: 2.4232194183541718
Epoch: 18| Step: 24
Training loss: 3.9493885040283203
Validation loss: 2.423692923655613
Epoch: 18| Step: 25
Training loss: 3.050936698913574
Validation loss: 2.4594213104934144
Epoch: 18| Step: 26
Training loss: 3.401984214782715
Validation loss: 2.4406064079819823
Epoch: 18| Step: 27
Training loss: 2.9360103607177734
Validation loss: 2.4400292737878484
Epoch: 18| Step: 28
Training loss: 3.5103321075439453
Validation loss: 2.4480219088869988
Epoch: 18| Step: 29
Training loss: 1.696824550628662
Validation loss: 2.4586188758877543
Epoch: 18| Step: 30
Training loss: 2.8487212657928467
Validation loss: 2.44275858848215
Epoch: 18| Step: 31
Training loss: 3.129472017288208
Validation loss: 2.417261917814076
Epoch: 18| Step: 32
Training loss: 1.967325210571289
Validation loss: 2.4394550529315318
Epoch: 18| Step: 33
Training loss: 3.568763017654419
Validation loss: 2.4288750290870667
Epoch: 18| Step: 34
Training loss: 2.235233783721924
Validation loss: 2.438447765309176
Epoch: 18| Step: 35
Training loss: 2.935150146484375
Validation loss: 2.435020685195923
Epoch: 18| Step: 36
Training loss: 2.9758524894714355
Validation loss: 2.4332991246696856
Epoch: 18| Step: 37
Training loss: 2.166105270385742
Validation loss: 2.4352853821335936
Epoch: 18| Step: 38
Training loss: 3.0930888652801514
Validation loss: 2.4504624836736446
Epoch: 18| Step: 39
Training loss: 3.5782930850982666
Validation loss: 2.4462232658331344
Epoch: 80| Step: 0
Training loss: 3.009977340698242
Validation loss: 2.4332061105494875
Epoch: 18| Step: 1
Training loss: 2.877305269241333
Validation loss: 2.427490769530372
Epoch: 18| Step: 2
Training loss: 2.7973685264587402
Validation loss: 2.4283370971679688
Epoch: 18| Step: 3
Training loss: 3.292182207107544
Validation loss: 2.4378963597386862
Epoch: 18| Step: 4
Training loss: 3.1714468002319336
Validation loss: 2.4464129475380876
Epoch: 18| Step: 5
Training loss: 3.1077399253845215
Validation loss: 2.425980030203895
Epoch: 18| Step: 6
Training loss: 3.63132381439209
Validation loss: 2.44127304776967
Epoch: 18| Step: 7
Training loss: 3.243147373199463
Validation loss: 2.433097226156605
Epoch: 18| Step: 8
Training loss: 3.0474376678466797
Validation loss: 2.4444418382301607
Epoch: 18| Step: 9
Training loss: 2.3054261207580566
Validation loss: 2.4400972256557547
Epoch: 18| Step: 10
Training loss: 4.6820549964904785
Validation loss: 2.4447396298964246
Epoch: 18| Step: 11
Training loss: 2.1434268951416016
Validation loss: 2.4306825305060515
Epoch: 18| Step: 12
Training loss: 3.0840940475463867
Validation loss: 2.4540245858885403
Epoch: 18| Step: 13
Training loss: 2.7247314453125
Validation loss: 2.4322056727443666
Epoch: 18| Step: 14
Training loss: 1.4867234230041504
Validation loss: 2.4425692438221662
Epoch: 18| Step: 15
Training loss: 3.4122486114501953
Validation loss: 2.4380437761759586
Epoch: 18| Step: 16
Training loss: 2.362273693084717
Validation loss: 2.446446796115354
Epoch: 18| Step: 17
Training loss: 3.210516929626465
Validation loss: 2.4552948028921224
Epoch: 18| Step: 18
Training loss: 3.010218620300293
Validation loss: 2.45646618767608
Epoch: 18| Step: 19
Training loss: 2.9631972312927246
Validation loss: 2.4001818372191286
Epoch: 18| Step: 20
Training loss: 4.212717056274414
Validation loss: 2.445198902980887
Epoch: 18| Step: 21
Training loss: 3.622509717941284
Validation loss: 2.4423831709854893
Epoch: 18| Step: 22
Training loss: 2.877040386199951
Validation loss: 2.4508392141877318
Epoch: 18| Step: 23
Training loss: 3.5578956604003906
Validation loss: 2.4325044206578097
Epoch: 18| Step: 24
Training loss: 2.7773077487945557
Validation loss: 2.4528168071088174
Epoch: 18| Step: 25
Training loss: 2.802112102508545
Validation loss: 2.439203490456231
Epoch: 18| Step: 26
Training loss: 2.558006763458252
Validation loss: 2.437551675082968
Epoch: 18| Step: 27
Training loss: 2.856684684753418
Validation loss: 2.4298177966110996
Epoch: 18| Step: 28
Training loss: 2.9386043548583984
Validation loss: 2.4226023001636534
Epoch: 18| Step: 29
Training loss: 2.477079391479492
Validation loss: 2.4291068306929775
Epoch: 18| Step: 30
Training loss: 2.6592977046966553
Validation loss: 2.4303337704363486
Epoch: 18| Step: 31
Training loss: 2.891690254211426
Validation loss: 2.4479857331557238
Epoch: 18| Step: 32
Training loss: 2.9154739379882812
Validation loss: 2.43051441796392
Epoch: 18| Step: 33
Training loss: 1.8308852910995483
Validation loss: 2.447246874836709
Epoch: 18| Step: 34
Training loss: 2.925780773162842
Validation loss: 2.4375450199456523
Epoch: 18| Step: 35
Training loss: 2.5289220809936523
Validation loss: 2.4463541730702354
Epoch: 18| Step: 36
Training loss: 3.6597490310668945
Validation loss: 2.4343927712749234
Epoch: 18| Step: 37
Training loss: 1.8849780559539795
Validation loss: 2.424282739488341
Epoch: 18| Step: 38
Training loss: 3.8711788654327393
Validation loss: 2.42251083662184
Epoch: 18| Step: 39
Training loss: 2.842949390411377
Validation loss: 2.421831811932351
Epoch: 81| Step: 0
Training loss: 2.4017298221588135
Validation loss: 2.4408089479954125
Epoch: 18| Step: 1
Training loss: 2.718208074569702
Validation loss: 2.448490991866846
Epoch: 18| Step: 2
Training loss: 2.1240580081939697
Validation loss: 2.439982748717713
Epoch: 18| Step: 3
Training loss: 2.513737678527832
Validation loss: 2.4270473538542823
Epoch: 18| Step: 4
Training loss: 2.9919216632843018
Validation loss: 2.437866139754975
Epoch: 18| Step: 5
Training loss: 3.1647918224334717
Validation loss: 2.4203893881049945
Epoch: 18| Step: 6
Training loss: 2.1514203548431396
Validation loss: 2.4230038004813435
Epoch: 18| Step: 7
Training loss: 2.59303617477417
Validation loss: 2.4461320715842487
Epoch: 18| Step: 8
Training loss: 3.695448637008667
Validation loss: 2.4460729403461485
Epoch: 18| Step: 9
Training loss: 1.89106023311615
Validation loss: 2.4279813106111487
Epoch: 18| Step: 10
Training loss: 2.9445948600769043
Validation loss: 2.4358257132468464
Epoch: 18| Step: 11
Training loss: 3.4313321113586426
Validation loss: 2.4527491253914593
Epoch: 18| Step: 12
Training loss: 3.6305174827575684
Validation loss: 2.4348882376718866
Epoch: 18| Step: 13
Training loss: 1.710994005203247
Validation loss: 2.420986998853066
Epoch: 18| Step: 14
Training loss: 2.256558656692505
Validation loss: 2.446655011005539
Epoch: 18| Step: 15
Training loss: 2.8209147453308105
Validation loss: 2.421644327451857
Epoch: 18| Step: 16
Training loss: 3.2204408645629883
Validation loss: 2.428119124268456
Epoch: 18| Step: 17
Training loss: 2.5599498748779297
Validation loss: 2.4472056978898085
Epoch: 18| Step: 18
Training loss: 3.1327338218688965
Validation loss: 2.4534545476488074
Epoch: 18| Step: 19
Training loss: 3.862569570541382
Validation loss: 2.4276954029961457
Epoch: 18| Step: 20
Training loss: 3.733582019805908
Validation loss: 2.4243271934042734
Epoch: 18| Step: 21
Training loss: 3.3704166412353516
Validation loss: 2.4444148746325816
Epoch: 18| Step: 22
Training loss: 3.161696434020996
Validation loss: 2.4297235012054443
Epoch: 18| Step: 23
Training loss: 2.3576102256774902
Validation loss: 2.428274094629631
Epoch: 18| Step: 24
Training loss: 2.5725488662719727
Validation loss: 2.426504078528864
Epoch: 18| Step: 25
Training loss: 2.710298538208008
Validation loss: 2.4374334469115992
Epoch: 18| Step: 26
Training loss: 3.010004997253418
Validation loss: 2.441083106205618
Epoch: 18| Step: 27
Training loss: 2.288672924041748
Validation loss: 2.4512264059601927
Epoch: 18| Step: 28
Training loss: 2.8879995346069336
Validation loss: 2.438973881357865
Epoch: 18| Step: 29
Training loss: 3.8439674377441406
Validation loss: 2.4372578370485374
Epoch: 18| Step: 30
Training loss: 3.1851003170013428
Validation loss: 2.4202101247773755
Epoch: 18| Step: 31
Training loss: 3.3039960861206055
Validation loss: 2.4306762938876805
Epoch: 18| Step: 32
Training loss: 3.338784694671631
Validation loss: 2.4372066748228005
Epoch: 18| Step: 33
Training loss: 3.5967555046081543
Validation loss: 2.432096886120254
Epoch: 18| Step: 34
Training loss: 3.656809091567993
Validation loss: 2.426836063535951
Epoch: 18| Step: 35
Training loss: 2.395890235900879
Validation loss: 2.4449844068760496
Epoch: 18| Step: 36
Training loss: 3.0513956546783447
Validation loss: 2.4520870112686706
Epoch: 18| Step: 37
Training loss: 3.6724436283111572
Validation loss: 2.42934941816673
Epoch: 18| Step: 38
Training loss: 3.0450644493103027
Validation loss: 2.4285680595919383
Epoch: 18| Step: 39
Training loss: 3.55918288230896
Validation loss: 2.4405866449685405
Epoch: 82| Step: 0
Training loss: 2.253810405731201
Validation loss: 2.4508007113024486
Epoch: 18| Step: 1
Training loss: 3.398240089416504
Validation loss: 2.399644152723628
Epoch: 18| Step: 2
Training loss: 3.0519917011260986
Validation loss: 2.442104349891059
Epoch: 18| Step: 3
Training loss: 4.116659641265869
Validation loss: 2.44655546696066
Epoch: 18| Step: 4
Training loss: 2.209777593612671
Validation loss: 2.449661369803998
Epoch: 18| Step: 5
Training loss: 3.2198867797851562
Validation loss: 2.433053906872976
Epoch: 18| Step: 6
Training loss: 3.7204339504241943
Validation loss: 2.428709249702289
Epoch: 18| Step: 7
Training loss: 3.4735336303710938
Validation loss: 2.4348660347273023
Epoch: 18| Step: 8
Training loss: 2.4399280548095703
Validation loss: 2.4309241823155245
Epoch: 18| Step: 9
Training loss: 3.474857807159424
Validation loss: 2.438139989221696
Epoch: 18| Step: 10
Training loss: 2.8713185787200928
Validation loss: 2.4313661245991
Epoch: 18| Step: 11
Training loss: 2.966684579849243
Validation loss: 2.4339904244855153
Epoch: 18| Step: 12
Training loss: 2.198359966278076
Validation loss: 2.3933052690766696
Epoch: 18| Step: 13
Training loss: 3.360203266143799
Validation loss: 2.440678917246757
Epoch: 18| Step: 14
Training loss: 2.766406297683716
Validation loss: 2.4569841751949393
Epoch: 18| Step: 15
Training loss: 2.3757965564727783
Validation loss: 2.445966291770661
Epoch: 18| Step: 16
Training loss: 4.408878326416016
Validation loss: 2.4160553388458363
Epoch: 18| Step: 17
Training loss: 1.897318959236145
Validation loss: 2.4359332503174707
Epoch: 18| Step: 18
Training loss: 2.780294418334961
Validation loss: 2.4341480852031023
Epoch: 18| Step: 19
Training loss: 3.364436149597168
Validation loss: 2.4015633219437635
Epoch: 18| Step: 20
Training loss: 2.536604404449463
Validation loss: 2.4267640130982984
Epoch: 18| Step: 21
Training loss: 3.0622007846832275
Validation loss: 2.439645492773262
Epoch: 18| Step: 22
Training loss: 2.5254268646240234
Validation loss: 2.4646522878742902
Epoch: 18| Step: 23
Training loss: 2.5989274978637695
Validation loss: 2.421518410710122
Epoch: 18| Step: 24
Training loss: 2.2129693031311035
Validation loss: 2.4318857553193896
Epoch: 18| Step: 25
Training loss: 2.895582675933838
Validation loss: 2.4270337760019647
Epoch: 18| Step: 26
Training loss: 2.8328070640563965
Validation loss: 2.4419975572352786
Epoch: 18| Step: 27
Training loss: 2.1645631790161133
Validation loss: 2.448802049211461
Epoch: 18| Step: 28
Training loss: 3.349771499633789
Validation loss: 2.434032982201885
Epoch: 18| Step: 29
Training loss: 3.152257204055786
Validation loss: 2.422040414467132
Epoch: 18| Step: 30
Training loss: 3.5804007053375244
Validation loss: 2.4190058793952995
Epoch: 18| Step: 31
Training loss: 2.0179014205932617
Validation loss: 2.423354533078859
Epoch: 18| Step: 32
Training loss: 2.4956862926483154
Validation loss: 2.4232833934344833
Epoch: 18| Step: 33
Training loss: 3.263123035430908
Validation loss: 2.4291262335056882
Epoch: 18| Step: 34
Training loss: 2.7385811805725098
Validation loss: 2.4306584416533545
Epoch: 18| Step: 35
Training loss: 2.7187273502349854
Validation loss: 2.4344064537569774
Epoch: 18| Step: 36
Training loss: 3.108747959136963
Validation loss: 2.4475128273312134
Epoch: 18| Step: 37
Training loss: 4.056415557861328
Validation loss: 2.424185947548571
Epoch: 18| Step: 38
Training loss: 2.9666383266448975
Validation loss: 2.422230847447896
Epoch: 18| Step: 39
Training loss: 2.7276835441589355
Validation loss: 2.445138133687081
Epoch: 83| Step: 0
Training loss: 3.875638484954834
Validation loss: 2.4455923571003426
Epoch: 18| Step: 1
Training loss: 2.9510974884033203
Validation loss: 2.438372064837449
Epoch: 18| Step: 2
Training loss: 3.3408374786376953
Validation loss: 2.4351349966131526
Epoch: 18| Step: 3
Training loss: 2.6433253288269043
Validation loss: 2.423791113088457
Epoch: 18| Step: 4
Training loss: 3.519197463989258
Validation loss: 2.460064517508308
Epoch: 18| Step: 5
Training loss: 2.919735908508301
Validation loss: 2.4354985274856897
Epoch: 18| Step: 6
Training loss: 1.7876026630401611
Validation loss: 2.4273245711978393
Epoch: 18| Step: 7
Training loss: 3.103738784790039
Validation loss: 2.421857286700242
Epoch: 18| Step: 8
Training loss: 2.786303997039795
Validation loss: 2.42891504438661
Epoch: 18| Step: 9
Training loss: 3.0093331336975098
Validation loss: 2.4312976718806536
Epoch: 18| Step: 10
Training loss: 2.3931941986083984
Validation loss: 2.4383645452183784
Epoch: 18| Step: 11
Training loss: 3.4242537021636963
Validation loss: 2.4299865300706824
Epoch: 18| Step: 12
Training loss: 3.0765388011932373
Validation loss: 2.4184399268610015
Epoch: 18| Step: 13
Training loss: 2.2933709621429443
Validation loss: 2.4399584411717146
Epoch: 18| Step: 14
Training loss: 3.8619933128356934
Validation loss: 2.4191769721696703
Epoch: 18| Step: 15
Training loss: 3.2564878463745117
Validation loss: 2.430231703271111
Epoch: 18| Step: 16
Training loss: 2.124680757522583
Validation loss: 2.4467182699724925
Epoch: 18| Step: 17
Training loss: 2.34965181350708
Validation loss: 2.4353961961732495
Epoch: 18| Step: 18
Training loss: 3.094326972961426
Validation loss: 2.436854856477367
Epoch: 18| Step: 19
Training loss: 2.6365489959716797
Validation loss: 2.4319884965745664
Epoch: 18| Step: 20
Training loss: 3.003906011581421
Validation loss: 2.4169068422248894
Epoch: 18| Step: 21
Training loss: 2.588134288787842
Validation loss: 2.432291408236936
Epoch: 18| Step: 22
Training loss: 2.336214065551758
Validation loss: 2.4124047927719228
Epoch: 18| Step: 23
Training loss: 3.8213672637939453
Validation loss: 2.42916837999289
Epoch: 18| Step: 24
Training loss: 2.850620746612549
Validation loss: 2.4465194486027997
Epoch: 18| Step: 25
Training loss: 3.0660128593444824
Validation loss: 2.449961712034486
Epoch: 18| Step: 26
Training loss: 2.1382970809936523
Validation loss: 2.42318911089314
Epoch: 18| Step: 27
Training loss: 2.822442054748535
Validation loss: 2.4442692832123463
Epoch: 18| Step: 28
Training loss: 3.9904415607452393
Validation loss: 2.4485868927386165
Epoch: 18| Step: 29
Training loss: 3.2313895225524902
Validation loss: 2.431529099992711
Epoch: 18| Step: 30
Training loss: 3.628108501434326
Validation loss: 2.4367389112925357
Epoch: 18| Step: 31
Training loss: 3.8826403617858887
Validation loss: 2.4350373204663502
Epoch: 18| Step: 32
Training loss: 2.052372455596924
Validation loss: 2.4374437152052955
Epoch: 18| Step: 33
Training loss: 3.765901565551758
Validation loss: 2.4123295176801065
Epoch: 18| Step: 34
Training loss: 3.7756409645080566
Validation loss: 2.436047130351444
Epoch: 18| Step: 35
Training loss: 2.3987414836883545
Validation loss: 2.424754217374239
Epoch: 18| Step: 36
Training loss: 2.4923224449157715
Validation loss: 2.4115939620587468
Epoch: 18| Step: 37
Training loss: 2.0730020999908447
Validation loss: 2.4293471617664366
Epoch: 18| Step: 38
Training loss: 2.9727702140808105
Validation loss: 2.455966602984092
Epoch: 18| Step: 39
Training loss: 2.8696846961975098
Validation loss: 2.429614844082071
Epoch: 84| Step: 0
Training loss: 2.792464256286621
Validation loss: 2.420130453521399
Epoch: 18| Step: 1
Training loss: 3.0843920707702637
Validation loss: 2.4206690050715167
Epoch: 18| Step: 2
Training loss: 3.259000062942505
Validation loss: 2.3956594055505107
Epoch: 18| Step: 3
Training loss: 2.944765090942383
Validation loss: 2.4566891519285794
Epoch: 18| Step: 4
Training loss: 2.8891472816467285
Validation loss: 2.434222715364086
Epoch: 18| Step: 5
Training loss: 2.5751750469207764
Validation loss: 2.431664924827411
Epoch: 18| Step: 6
Training loss: 2.347935676574707
Validation loss: 2.4472342995430925
Epoch: 18| Step: 7
Training loss: 2.321837902069092
Validation loss: 2.4209598259960146
Epoch: 18| Step: 8
Training loss: 2.7561686038970947
Validation loss: 2.442173396940712
Epoch: 18| Step: 9
Training loss: 3.146724224090576
Validation loss: 2.420163751506119
Epoch: 18| Step: 10
Training loss: 3.0362143516540527
Validation loss: 2.436096519017391
Epoch: 18| Step: 11
Training loss: 3.618170738220215
Validation loss: 2.4246970921111624
Epoch: 18| Step: 12
Training loss: 2.943727970123291
Validation loss: 2.4354445762771495
Epoch: 18| Step: 13
Training loss: 2.679180145263672
Validation loss: 2.4302869151822097
Epoch: 18| Step: 14
Training loss: 2.4626612663269043
Validation loss: 2.4354738914709295
Epoch: 18| Step: 15
Training loss: 3.2464170455932617
Validation loss: 2.438809890541241
Epoch: 18| Step: 16
Training loss: 3.563115119934082
Validation loss: 2.44213451498704
Epoch: 18| Step: 17
Training loss: 3.8075098991394043
Validation loss: 2.4332637821170064
Epoch: 18| Step: 18
Training loss: 2.3964500427246094
Validation loss: 2.4446619997779244
Epoch: 18| Step: 19
Training loss: 3.515428066253662
Validation loss: 2.4052722505528292
Epoch: 18| Step: 20
Training loss: 3.1047661304473877
Validation loss: 2.4265168467871576
Epoch: 18| Step: 21
Training loss: 2.8289027214050293
Validation loss: 2.443842369875462
Epoch: 18| Step: 22
Training loss: 1.4962927103042603
Validation loss: 2.436904373786432
Epoch: 18| Step: 23
Training loss: 3.432847261428833
Validation loss: 2.430747418094882
Epoch: 18| Step: 24
Training loss: 3.7410967350006104
Validation loss: 2.4065413423579374
Epoch: 18| Step: 25
Training loss: 2.137946844100952
Validation loss: 2.4221121767442004
Epoch: 18| Step: 26
Training loss: 3.4780771732330322
Validation loss: 2.44459155823687
Epoch: 18| Step: 27
Training loss: 1.699352741241455
Validation loss: 2.427355284313504
Epoch: 18| Step: 28
Training loss: 3.862189769744873
Validation loss: 2.4234734250487184
Epoch: 18| Step: 29
Training loss: 2.717578411102295
Validation loss: 2.4332615162828843
Epoch: 18| Step: 30
Training loss: 3.090142250061035
Validation loss: 2.437511685940859
Epoch: 18| Step: 31
Training loss: 3.630263328552246
Validation loss: 2.433024529072878
Epoch: 18| Step: 32
Training loss: 2.746145725250244
Validation loss: 2.4115019444939043
Epoch: 18| Step: 33
Training loss: 3.4224674701690674
Validation loss: 2.4344661604586264
Epoch: 18| Step: 34
Training loss: 3.159951686859131
Validation loss: 2.4121350453054307
Epoch: 18| Step: 35
Training loss: 3.0604541301727295
Validation loss: 2.433793484735832
Epoch: 18| Step: 36
Training loss: 2.6858792304992676
Validation loss: 2.44948857122188
Epoch: 18| Step: 37
Training loss: 3.159149646759033
Validation loss: 2.4338163763499088
Epoch: 18| Step: 38
Training loss: 2.7508959770202637
Validation loss: 2.4411220979347505
Epoch: 18| Step: 39
Training loss: 2.395718574523926
Validation loss: 2.4441328374601956
Epoch: 85| Step: 0
Training loss: 1.7684049606323242
Validation loss: 2.427329946764939
Epoch: 18| Step: 1
Training loss: 3.043581485748291
Validation loss: 2.431071389493325
Epoch: 18| Step: 2
Training loss: 2.9887044429779053
Validation loss: 2.410124614084367
Epoch: 18| Step: 3
Training loss: 5.28935432434082
Validation loss: 2.40992722408377
Epoch: 18| Step: 4
Training loss: 2.6113030910491943
Validation loss: 2.433647291265803
Epoch: 18| Step: 5
Training loss: 2.609402656555176
Validation loss: 2.444353296173562
Epoch: 18| Step: 6
Training loss: 2.0371510982513428
Validation loss: 2.437278671659154
Epoch: 18| Step: 7
Training loss: 1.9709446430206299
Validation loss: 2.438948334549828
Epoch: 18| Step: 8
Training loss: 3.28971529006958
Validation loss: 2.4046123508069157
Epoch: 18| Step: 9
Training loss: 1.8473894596099854
Validation loss: 2.429231882095337
Epoch: 18| Step: 10
Training loss: 3.2268707752227783
Validation loss: 2.426606207442798
Epoch: 18| Step: 11
Training loss: 2.5087060928344727
Validation loss: 2.4557032945344774
Epoch: 18| Step: 12
Training loss: 2.8479020595550537
Validation loss: 2.4068219284359498
Epoch: 18| Step: 13
Training loss: 2.7076187133789062
Validation loss: 2.4250243070314257
Epoch: 18| Step: 14
Training loss: 1.8807693719863892
Validation loss: 2.425096354896216
Epoch: 18| Step: 15
Training loss: 3.1530697345733643
Validation loss: 2.4509071566218097
Epoch: 18| Step: 16
Training loss: 3.7418038845062256
Validation loss: 2.4171235698590174
Epoch: 18| Step: 17
Training loss: 3.6325631141662598
Validation loss: 2.409349716824593
Epoch: 18| Step: 18
Training loss: 2.342604160308838
Validation loss: 2.423309358761465
Epoch: 18| Step: 19
Training loss: 4.446896076202393
Validation loss: 2.4251017947848754
Epoch: 18| Step: 20
Training loss: 2.7899961471557617
Validation loss: 2.4434792120679676
Epoch: 18| Step: 21
Training loss: 2.648960828781128
Validation loss: 2.432936467712732
Epoch: 18| Step: 22
Training loss: 4.079383373260498
Validation loss: 2.426274923969516
Epoch: 18| Step: 23
Training loss: 3.030435085296631
Validation loss: 2.4235403486292997
Epoch: 18| Step: 24
Training loss: 3.165649890899658
Validation loss: 2.4242566197896176
Epoch: 18| Step: 25
Training loss: 2.5145516395568848
Validation loss: 2.4021973575619486
Epoch: 18| Step: 26
Training loss: 3.2966442108154297
Validation loss: 2.4282188623500387
Epoch: 18| Step: 27
Training loss: 2.937844753265381
Validation loss: 2.4167167831667893
Epoch: 18| Step: 28
Training loss: 3.1393790245056152
Validation loss: 2.4135071373671937
Epoch: 18| Step: 29
Training loss: 2.8013010025024414
Validation loss: 2.422318306758249
Epoch: 18| Step: 30
Training loss: 3.186530828475952
Validation loss: 2.433974609100561
Epoch: 18| Step: 31
Training loss: 3.5998692512512207
Validation loss: 2.4262403429840966
Epoch: 18| Step: 32
Training loss: 3.0591189861297607
Validation loss: 2.4312282586269243
Epoch: 18| Step: 33
Training loss: 3.534402847290039
Validation loss: 2.447581761174922
Epoch: 18| Step: 34
Training loss: 2.227686643600464
Validation loss: 2.4232976350852913
Epoch: 18| Step: 35
Training loss: 2.9778051376342773
Validation loss: 2.4290903058412265
Epoch: 18| Step: 36
Training loss: 2.5857763290405273
Validation loss: 2.441684997339043
Epoch: 18| Step: 37
Training loss: 2.617358922958374
Validation loss: 2.434956905653151
Epoch: 18| Step: 38
Training loss: 3.340888023376465
Validation loss: 2.4161792170229575
Epoch: 18| Step: 39
Training loss: 3.110011339187622
Validation loss: 2.4245440170919297
Epoch: 86| Step: 0
Training loss: 2.49124813079834
Validation loss: 2.4322996636946423
Epoch: 18| Step: 1
Training loss: 3.9131863117218018
Validation loss: 2.4264435339317045
Epoch: 18| Step: 2
Training loss: 3.965250015258789
Validation loss: 2.4192732443912424
Epoch: 18| Step: 3
Training loss: 2.674210548400879
Validation loss: 2.40567399100434
Epoch: 18| Step: 4
Training loss: 3.0017917156219482
Validation loss: 2.4307432714983714
Epoch: 18| Step: 5
Training loss: 3.493041515350342
Validation loss: 2.4142990043695023
Epoch: 18| Step: 6
Training loss: 1.740148901939392
Validation loss: 2.4188104533463073
Epoch: 18| Step: 7
Training loss: 1.956873893737793
Validation loss: 2.4099363903347535
Epoch: 18| Step: 8
Training loss: 2.5263915061950684
Validation loss: 2.4152432585791717
Epoch: 18| Step: 9
Training loss: 2.7573866844177246
Validation loss: 2.415900043446383
Epoch: 18| Step: 10
Training loss: 3.8806514739990234
Validation loss: 2.4477186014326358
Epoch: 18| Step: 11
Training loss: 3.6554107666015625
Validation loss: 2.434950472639619
Epoch: 18| Step: 12
Training loss: 2.2897427082061768
Validation loss: 2.4239946552317777
Epoch: 18| Step: 13
Training loss: 4.024918556213379
Validation loss: 2.409049693629038
Epoch: 18| Step: 14
Training loss: 2.156064510345459
Validation loss: 2.435909650737433
Epoch: 18| Step: 15
Training loss: 3.598956346511841
Validation loss: 2.4378796721533904
Epoch: 18| Step: 16
Training loss: 3.3905062675476074
Validation loss: 2.4438039673318106
Epoch: 18| Step: 17
Training loss: 2.396864414215088
Validation loss: 2.4273256174952005
Epoch: 18| Step: 18
Training loss: 3.1603779792785645
Validation loss: 2.451909142432453
Epoch: 18| Step: 19
Training loss: 2.901841163635254
Validation loss: 2.413547466127135
Epoch: 18| Step: 20
Training loss: 2.093306541442871
Validation loss: 2.4164590338151233
Epoch: 18| Step: 21
Training loss: 2.5456295013427734
Validation loss: 2.411549396652112
Epoch: 18| Step: 22
Training loss: 3.5578465461730957
Validation loss: 2.404865167123808
Epoch: 18| Step: 23
Training loss: 3.3947300910949707
Validation loss: 2.419116759471756
Epoch: 18| Step: 24
Training loss: 3.222938060760498
Validation loss: 2.426764528528392
Epoch: 18| Step: 25
Training loss: 3.6044771671295166
Validation loss: 2.424910355814927
Epoch: 18| Step: 26
Training loss: 2.2827534675598145
Validation loss: 2.441725233475939
Epoch: 18| Step: 27
Training loss: 2.172241687774658
Validation loss: 2.4243726713194262
Epoch: 18| Step: 28
Training loss: 3.5014591217041016
Validation loss: 2.4380492220679635
Epoch: 18| Step: 29
Training loss: 2.13995623588562
Validation loss: 2.4385917178160854
Epoch: 18| Step: 30
Training loss: 2.3926327228546143
Validation loss: 2.419992669880819
Epoch: 18| Step: 31
Training loss: 3.00056791305542
Validation loss: 2.41900182113373
Epoch: 18| Step: 32
Training loss: 2.9365601539611816
Validation loss: 2.4287331550241373
Epoch: 18| Step: 33
Training loss: 3.6905953884124756
Validation loss: 2.4361025155019416
Epoch: 18| Step: 34
Training loss: 3.6880552768707275
Validation loss: 2.4317010568200255
Epoch: 18| Step: 35
Training loss: 2.298673152923584
Validation loss: 2.436621207985089
Epoch: 18| Step: 36
Training loss: 3.0123114585876465
Validation loss: 2.408974901377726
Epoch: 18| Step: 37
Training loss: 2.3513312339782715
Validation loss: 2.4232482652870013
Epoch: 18| Step: 38
Training loss: 2.4798738956451416
Validation loss: 2.4091237517569564
Epoch: 18| Step: 39
Training loss: 2.997462272644043
Validation loss: 2.4172642256716173
Epoch: 87| Step: 0
Training loss: 3.31650972366333
Validation loss: 2.410622246831441
Epoch: 18| Step: 1
Training loss: 2.7365567684173584
Validation loss: 2.4078699633371916
Epoch: 18| Step: 2
Training loss: 3.2962746620178223
Validation loss: 2.4088463800416577
Epoch: 18| Step: 3
Training loss: 1.8730336427688599
Validation loss: 2.405486214075157
Epoch: 18| Step: 4
Training loss: 2.5089287757873535
Validation loss: 2.429041024592283
Epoch: 18| Step: 5
Training loss: 2.487398624420166
Validation loss: 2.405377631564792
Epoch: 18| Step: 6
Training loss: 2.624598979949951
Validation loss: 2.420224946179836
Epoch: 18| Step: 7
Training loss: 3.0995354652404785
Validation loss: 2.4118228627623415
Epoch: 18| Step: 8
Training loss: 3.1845998764038086
Validation loss: 2.3695624766589924
Epoch: 18| Step: 9
Training loss: 3.1402530670166016
Validation loss: 2.4028386520824845
Epoch: 18| Step: 10
Training loss: 2.978580951690674
Validation loss: 2.3915058691724598
Epoch: 18| Step: 11
Training loss: 2.9966084957122803
Validation loss: 2.422130349728701
Epoch: 18| Step: 12
Training loss: 2.9249422550201416
Validation loss: 2.426367536723185
Epoch: 18| Step: 13
Training loss: 2.9442334175109863
Validation loss: 2.4239552364074926
Epoch: 18| Step: 14
Training loss: 2.805077075958252
Validation loss: 2.4247702986216373
Epoch: 18| Step: 15
Training loss: 3.079420804977417
Validation loss: 2.408676463494198
Epoch: 18| Step: 16
Training loss: 3.748042106628418
Validation loss: 2.42281229032887
Epoch: 18| Step: 17
Training loss: 3.3187007904052734
Validation loss: 2.38582722746211
Epoch: 18| Step: 18
Training loss: 3.89823317527771
Validation loss: 2.399500044129735
Epoch: 18| Step: 19
Training loss: 2.740652322769165
Validation loss: 2.418022171198893
Epoch: 18| Step: 20
Training loss: 2.6290700435638428
Validation loss: 2.4254259085483687
Epoch: 18| Step: 21
Training loss: 2.1941957473754883
Validation loss: 2.4126008088640174
Epoch: 18| Step: 22
Training loss: 2.910890579223633
Validation loss: 2.403731966190201
Epoch: 18| Step: 23
Training loss: 3.284646511077881
Validation loss: 2.421500451273198
Epoch: 18| Step: 24
Training loss: 2.9307589530944824
Validation loss: 2.4126330451142017
Epoch: 18| Step: 25
Training loss: 2.8772568702697754
Validation loss: 2.4222826974855054
Epoch: 18| Step: 26
Training loss: 2.7292144298553467
Validation loss: 2.3949797650892957
Epoch: 18| Step: 27
Training loss: 3.0888819694519043
Validation loss: 2.4193286484093974
Epoch: 18| Step: 28
Training loss: 2.4823391437530518
Validation loss: 2.410054302044052
Epoch: 18| Step: 29
Training loss: 3.111696481704712
Validation loss: 2.4137507711383077
Epoch: 18| Step: 30
Training loss: 3.102449417114258
Validation loss: 2.4183412936093998
Epoch: 18| Step: 31
Training loss: 2.9916152954101562
Validation loss: 2.4103312303694033
Epoch: 18| Step: 32
Training loss: 2.7592995166778564
Validation loss: 2.412148448631918
Epoch: 18| Step: 33
Training loss: 3.226414680480957
Validation loss: 2.4203555035076554
Epoch: 18| Step: 34
Training loss: 3.7484922409057617
Validation loss: 2.414031734569467
Epoch: 18| Step: 35
Training loss: 2.321458339691162
Validation loss: 2.397927874283825
Epoch: 18| Step: 36
Training loss: 4.126498222351074
Validation loss: 2.3936205939423267
Epoch: 18| Step: 37
Training loss: 2.6308064460754395
Validation loss: 2.393578784928905
Epoch: 18| Step: 38
Training loss: 2.483945846557617
Validation loss: 2.3934675360755095
Epoch: 18| Step: 39
Training loss: 2.0938873291015625
Validation loss: 2.42422241101162
Epoch: 88| Step: 0
Training loss: 4.473116874694824
Validation loss: 2.4126957286176065
Epoch: 18| Step: 1
Training loss: 2.624098300933838
Validation loss: 2.406182285693052
Epoch: 18| Step: 2
Training loss: 4.032357692718506
Validation loss: 2.410404613549761
Epoch: 18| Step: 3
Training loss: 2.5474092960357666
Validation loss: 2.410256764871611
Epoch: 18| Step: 4
Training loss: 3.678982973098755
Validation loss: 2.4218582163611764
Epoch: 18| Step: 5
Training loss: 3.078930616378784
Validation loss: 2.4102907180786133
Epoch: 18| Step: 6
Training loss: 2.074007511138916
Validation loss: 2.4018786536703867
Epoch: 18| Step: 7
Training loss: 2.785623788833618
Validation loss: 2.397524118423462
Epoch: 18| Step: 8
Training loss: 2.6383121013641357
Validation loss: 2.3992252984492897
Epoch: 18| Step: 9
Training loss: 2.694962501525879
Validation loss: 2.3724550686294226
Epoch: 18| Step: 10
Training loss: 3.651298999786377
Validation loss: 2.4220382000902574
Epoch: 18| Step: 11
Training loss: 1.7963050603866577
Validation loss: 2.4015246381004935
Epoch: 18| Step: 12
Training loss: 2.841080665588379
Validation loss: 2.4023608149384423
Epoch: 18| Step: 13
Training loss: 3.0938258171081543
Validation loss: 2.3936291727230703
Epoch: 18| Step: 14
Training loss: 2.4418139457702637
Validation loss: 2.4081077146873198
Epoch: 18| Step: 15
Training loss: 3.105963706970215
Validation loss: 2.400911432376011
Epoch: 18| Step: 16
Training loss: 3.395120143890381
Validation loss: 2.380375404152081
Epoch: 18| Step: 17
Training loss: 2.391731023788452
Validation loss: 2.436399031886094
Epoch: 18| Step: 18
Training loss: 3.1656429767608643
Validation loss: 2.420021208070165
Epoch: 18| Step: 19
Training loss: 2.423473358154297
Validation loss: 2.426038776370261
Epoch: 18| Step: 20
Training loss: 3.125284433364868
Validation loss: 2.40871800107064
Epoch: 18| Step: 21
Training loss: 2.1172752380371094
Validation loss: 2.4223950955507565
Epoch: 18| Step: 22
Training loss: 2.2786896228790283
Validation loss: 2.402980150936319
Epoch: 18| Step: 23
Training loss: 2.3611385822296143
Validation loss: 2.382666105846707
Epoch: 18| Step: 24
Training loss: 2.8944084644317627
Validation loss: 2.392329231440592
Epoch: 18| Step: 25
Training loss: 4.0746049880981445
Validation loss: 2.401225782984452
Epoch: 18| Step: 26
Training loss: 2.8087058067321777
Validation loss: 2.4172441993685934
Epoch: 18| Step: 27
Training loss: 3.104741096496582
Validation loss: 2.4024708296755235
Epoch: 18| Step: 28
Training loss: 2.603445053100586
Validation loss: 2.4082119499179098
Epoch: 18| Step: 29
Training loss: 3.2605814933776855
Validation loss: 2.421721384679671
Epoch: 18| Step: 30
Training loss: 2.828232765197754
Validation loss: 2.394767461920814
Epoch: 18| Step: 31
Training loss: 2.5176844596862793
Validation loss: 2.4056632836088
Epoch: 18| Step: 32
Training loss: 2.2422022819519043
Validation loss: 2.412310972488184
Epoch: 18| Step: 33
Training loss: 2.168585777282715
Validation loss: 2.395309955953694
Epoch: 18| Step: 34
Training loss: 3.505439043045044
Validation loss: 2.381737046104541
Epoch: 18| Step: 35
Training loss: 3.3397719860076904
Validation loss: 2.4119321444480537
Epoch: 18| Step: 36
Training loss: 3.6603293418884277
Validation loss: 2.402462480737151
Epoch: 18| Step: 37
Training loss: 2.567064046859741
Validation loss: 2.4023098362435538
Epoch: 18| Step: 38
Training loss: 2.840785503387451
Validation loss: 2.3969994440353175
Epoch: 18| Step: 39
Training loss: 3.960203170776367
Validation loss: 2.4044134235210555
Epoch: 89| Step: 0
Training loss: 2.7671220302581787
Validation loss: 2.409726678038673
Epoch: 18| Step: 1
Training loss: 2.4576478004455566
Validation loss: 2.4212875366210938
Epoch: 18| Step: 2
Training loss: 2.7823362350463867
Validation loss: 2.4247356713246955
Epoch: 18| Step: 3
Training loss: 2.6467602252960205
Validation loss: 2.4048048197794305
Epoch: 18| Step: 4
Training loss: 3.0292487144470215
Validation loss: 2.3982591646180738
Epoch: 18| Step: 5
Training loss: 3.1986303329467773
Validation loss: 2.413681845013186
Epoch: 18| Step: 6
Training loss: 3.848494529724121
Validation loss: 2.4314032064067375
Epoch: 18| Step: 7
Training loss: 3.6494035720825195
Validation loss: 2.403231018738781
Epoch: 18| Step: 8
Training loss: 2.3006443977355957
Validation loss: 2.3790234370197325
Epoch: 18| Step: 9
Training loss: 3.14693546295166
Validation loss: 2.402261486156381
Epoch: 18| Step: 10
Training loss: 2.713649272918701
Validation loss: 2.3928973486097598
Epoch: 18| Step: 11
Training loss: 2.6697545051574707
Validation loss: 2.4198949748663594
Epoch: 18| Step: 12
Training loss: 2.6767027378082275
Validation loss: 2.4022037536977865
Epoch: 18| Step: 13
Training loss: 2.3368515968322754
Validation loss: 2.4013936553927633
Epoch: 18| Step: 14
Training loss: 2.720496892929077
Validation loss: 2.418730042821212
Epoch: 18| Step: 15
Training loss: 3.0674209594726562
Validation loss: 2.3916293657083307
Epoch: 18| Step: 16
Training loss: 3.2963643074035645
Validation loss: 2.4147868242195183
Epoch: 18| Step: 17
Training loss: 2.2258737087249756
Validation loss: 2.393322265405449
Epoch: 18| Step: 18
Training loss: 2.375298261642456
Validation loss: 2.3994832450537373
Epoch: 18| Step: 19
Training loss: 2.7782366275787354
Validation loss: 2.4027863955326216
Epoch: 18| Step: 20
Training loss: 2.4019832611083984
Validation loss: 2.3883996318570144
Epoch: 18| Step: 21
Training loss: 2.524521827697754
Validation loss: 2.4103363572264747
Epoch: 18| Step: 22
Training loss: 2.9228413105010986
Validation loss: 2.405783227021746
Epoch: 18| Step: 23
Training loss: 2.81716251373291
Validation loss: 2.3761204545446435
Epoch: 18| Step: 24
Training loss: 2.8537111282348633
Validation loss: 2.4058831758636363
Epoch: 18| Step: 25
Training loss: 2.011207103729248
Validation loss: 2.400195270991154
Epoch: 18| Step: 26
Training loss: 2.8455355167388916
Validation loss: 2.4275379369584775
Epoch: 18| Step: 27
Training loss: 2.5562682151794434
Validation loss: 2.408117198257995
Epoch: 18| Step: 28
Training loss: 2.876819133758545
Validation loss: 2.400440916740637
Epoch: 18| Step: 29
Training loss: 4.353523254394531
Validation loss: 2.414418768539703
Epoch: 18| Step: 30
Training loss: 3.4670798778533936
Validation loss: 2.401671894591489
Epoch: 18| Step: 31
Training loss: 3.737541437149048
Validation loss: 2.3949964509593498
Epoch: 18| Step: 32
Training loss: 2.992612361907959
Validation loss: 2.42408507333385
Epoch: 18| Step: 33
Training loss: 2.5800328254699707
Validation loss: 2.398870902095767
Epoch: 18| Step: 34
Training loss: 2.7585573196411133
Validation loss: 2.419699520515881
Epoch: 18| Step: 35
Training loss: 3.7900583744049072
Validation loss: 2.3825526872127174
Epoch: 18| Step: 36
Training loss: 3.4521408081054688
Validation loss: 2.413422063957873
Epoch: 18| Step: 37
Training loss: 3.488332986831665
Validation loss: 2.4153434797156628
Epoch: 18| Step: 38
Training loss: 2.927316188812256
Validation loss: 2.3822074168020015
Epoch: 18| Step: 39
Training loss: 2.598783254623413
Validation loss: 2.414074430362784
Epoch: 90| Step: 0
Training loss: 2.256838321685791
Validation loss: 2.4148998140431135
Epoch: 18| Step: 1
Training loss: 2.5877580642700195
Validation loss: 2.4062315834511954
Epoch: 18| Step: 2
Training loss: 3.789699077606201
Validation loss: 2.4116723005720178
Epoch: 18| Step: 3
Training loss: 2.30349063873291
Validation loss: 2.412486961419634
Epoch: 18| Step: 4
Training loss: 1.94062077999115
Validation loss: 2.3945354248979966
Epoch: 18| Step: 5
Training loss: 2.712575674057007
Validation loss: 2.40006838685317
Epoch: 18| Step: 6
Training loss: 2.764214038848877
Validation loss: 2.4112853973889523
Epoch: 18| Step: 7
Training loss: 2.781196117401123
Validation loss: 2.3976149644783074
Epoch: 18| Step: 8
Training loss: 4.421647071838379
Validation loss: 2.4165004294553247
Epoch: 18| Step: 9
Training loss: 3.7447402477264404
Validation loss: 2.3956441381852405
Epoch: 18| Step: 10
Training loss: 1.605684757232666
Validation loss: 2.3947702466155127
Epoch: 18| Step: 11
Training loss: 3.1770052909851074
Validation loss: 2.409968856427309
Epoch: 18| Step: 12
Training loss: 4.189304351806641
Validation loss: 2.3968215005860913
Epoch: 18| Step: 13
Training loss: 2.1001439094543457
Validation loss: 2.39049252674734
Epoch: 18| Step: 14
Training loss: 2.5883941650390625
Validation loss: 2.3821235414889217
Epoch: 18| Step: 15
Training loss: 2.2912001609802246
Validation loss: 2.398120679443689
Epoch: 18| Step: 16
Training loss: 3.5127158164978027
Validation loss: 2.3973935216450863
Epoch: 18| Step: 17
Training loss: 3.5791871547698975
Validation loss: 2.3836301710965824
Epoch: 18| Step: 18
Training loss: 3.0281238555908203
Validation loss: 2.3999749121906087
Epoch: 18| Step: 19
Training loss: 2.9241414070129395
Validation loss: 2.417387831982949
Epoch: 18| Step: 20
Training loss: 3.7641162872314453
Validation loss: 2.4254110914340123
Epoch: 18| Step: 21
Training loss: 2.8908443450927734
Validation loss: 2.3967788545347806
Epoch: 18| Step: 22
Training loss: 3.4222259521484375
Validation loss: 2.409308088769158
Epoch: 18| Step: 23
Training loss: 3.535663366317749
Validation loss: 2.367797069412341
Epoch: 18| Step: 24
Training loss: 3.5847620964050293
Validation loss: 2.39876825860936
Epoch: 18| Step: 25
Training loss: 1.603331446647644
Validation loss: 2.4007354846103586
Epoch: 18| Step: 26
Training loss: 3.5139942169189453
Validation loss: 2.395471620902741
Epoch: 18| Step: 27
Training loss: 3.4289186000823975
Validation loss: 2.373426857612116
Epoch: 18| Step: 28
Training loss: 2.0600857734680176
Validation loss: 2.39560730337239
Epoch: 18| Step: 29
Training loss: 2.580681800842285
Validation loss: 2.4121223885378393
Epoch: 18| Step: 30
Training loss: 2.664632797241211
Validation loss: 2.3876916504592347
Epoch: 18| Step: 31
Training loss: 2.7794761657714844
Validation loss: 2.4137964454486216
Epoch: 18| Step: 32
Training loss: 3.0549914836883545
Validation loss: 2.3926510073298175
Epoch: 18| Step: 33
Training loss: 2.8091156482696533
Validation loss: 2.4090440805009803
Epoch: 18| Step: 34
Training loss: 2.809434652328491
Validation loss: 2.416497121611945
Epoch: 18| Step: 35
Training loss: 2.3346617221832275
Validation loss: 2.417909457958002
Epoch: 18| Step: 36
Training loss: 1.8327181339263916
Validation loss: 2.422921907987526
Epoch: 18| Step: 37
Training loss: 3.3372278213500977
Validation loss: 2.3978546489056924
Epoch: 18| Step: 38
Training loss: 3.618074893951416
Validation loss: 2.3908491769282936
Epoch: 18| Step: 39
Training loss: 3.297619342803955
Validation loss: 2.3831005936903917
Epoch: 91| Step: 0
Training loss: 2.4900500774383545
Validation loss: 2.395144831362388
Epoch: 18| Step: 1
Training loss: 4.0731892585754395
Validation loss: 2.3996846950311457
Epoch: 18| Step: 2
Training loss: 3.561896562576294
Validation loss: 2.4219903637179367
Epoch: 18| Step: 3
Training loss: 3.1122069358825684
Validation loss: 2.417139423836907
Epoch: 18| Step: 4
Training loss: 3.2126541137695312
Validation loss: 2.3956905097412546
Epoch: 18| Step: 5
Training loss: 2.347827911376953
Validation loss: 2.403726669524213
Epoch: 18| Step: 6
Training loss: 3.1388840675354004
Validation loss: 2.409914765426581
Epoch: 18| Step: 7
Training loss: 3.2961184978485107
Validation loss: 2.3901752019100053
Epoch: 18| Step: 8
Training loss: 2.862826347351074
Validation loss: 2.413053973973226
Epoch: 18| Step: 9
Training loss: 2.628000020980835
Validation loss: 2.3985657177383093
Epoch: 18| Step: 10
Training loss: 1.0213801860809326
Validation loss: 2.392903662414002
Epoch: 18| Step: 11
Training loss: 3.5591378211975098
Validation loss: 2.417928570466076
Epoch: 18| Step: 12
Training loss: 2.5098109245300293
Validation loss: 2.409819134705358
Epoch: 18| Step: 13
Training loss: 2.3957724571228027
Validation loss: 2.3889801545108824
Epoch: 18| Step: 14
Training loss: 3.138589382171631
Validation loss: 2.3987767867904775
Epoch: 18| Step: 15
Training loss: 2.400728702545166
Validation loss: 2.399745776498918
Epoch: 18| Step: 16
Training loss: 3.467714786529541
Validation loss: 2.400820258710024
Epoch: 18| Step: 17
Training loss: 2.5779056549072266
Validation loss: 2.396083732303098
Epoch: 18| Step: 18
Training loss: 2.793731689453125
Validation loss: 2.376440026777254
Epoch: 18| Step: 19
Training loss: 3.609318971633911
Validation loss: 2.3971681174614448
Epoch: 18| Step: 20
Training loss: 3.0632171630859375
Validation loss: 2.3809773587494445
Epoch: 18| Step: 21
Training loss: 3.7659718990325928
Validation loss: 2.402970727399099
Epoch: 18| Step: 22
Training loss: 1.9053666591644287
Validation loss: 2.371422472617609
Epoch: 18| Step: 23
Training loss: 2.8621110916137695
Validation loss: 2.3918290995865417
Epoch: 18| Step: 24
Training loss: 1.9656453132629395
Validation loss: 2.363873469743797
Epoch: 18| Step: 25
Training loss: 3.0531187057495117
Validation loss: 2.4138899810022587
Epoch: 18| Step: 26
Training loss: 3.627751111984253
Validation loss: 2.39951878743206
Epoch: 18| Step: 27
Training loss: 3.6416494846343994
Validation loss: 2.393235801792831
Epoch: 18| Step: 28
Training loss: 2.0383551120758057
Validation loss: 2.3805195787827746
Epoch: 18| Step: 29
Training loss: 2.637753486633301
Validation loss: 2.4058736056732615
Epoch: 18| Step: 30
Training loss: 2.302433490753174
Validation loss: 2.414942842593296
Epoch: 18| Step: 31
Training loss: 3.851229190826416
Validation loss: 2.3729342659600348
Epoch: 18| Step: 32
Training loss: 2.3337199687957764
Validation loss: 2.4130779925010186
Epoch: 18| Step: 33
Training loss: 3.1230034828186035
Validation loss: 2.4020287630369337
Epoch: 18| Step: 34
Training loss: 2.7000784873962402
Validation loss: 2.3988848367183326
Epoch: 18| Step: 35
Training loss: 2.1800434589385986
Validation loss: 2.391132756102857
Epoch: 18| Step: 36
Training loss: 3.403761148452759
Validation loss: 2.4070095038242476
Epoch: 18| Step: 37
Training loss: 2.967211961746216
Validation loss: 2.388723733613817
Epoch: 18| Step: 38
Training loss: 4.258889675140381
Validation loss: 2.376375019121513
Epoch: 18| Step: 39
Training loss: 3.245088577270508
Validation loss: 2.40270546700457
Epoch: 92| Step: 0
Training loss: 3.1058077812194824
Validation loss: 2.3955043168376675
Epoch: 18| Step: 1
Training loss: 4.237387180328369
Validation loss: 2.375341352798956
Epoch: 18| Step: 2
Training loss: 2.3520398139953613
Validation loss: 2.4045635281706885
Epoch: 18| Step: 3
Training loss: 2.6031854152679443
Validation loss: 2.3932833997465726
Epoch: 18| Step: 4
Training loss: 2.3281025886535645
Validation loss: 2.3959761849410244
Epoch: 18| Step: 5
Training loss: 3.243633270263672
Validation loss: 2.3946997759153517
Epoch: 18| Step: 6
Training loss: 2.249795913696289
Validation loss: 2.420216711305028
Epoch: 18| Step: 7
Training loss: 2.7918522357940674
Validation loss: 2.407238843629686
Epoch: 18| Step: 8
Training loss: 2.832352638244629
Validation loss: 2.408849306243787
Epoch: 18| Step: 9
Training loss: 3.1654293537139893
Validation loss: 2.4018584995818655
Epoch: 18| Step: 10
Training loss: 3.9317102432250977
Validation loss: 2.397952441688922
Epoch: 18| Step: 11
Training loss: 2.55377197265625
Validation loss: 2.4103640498017236
Epoch: 18| Step: 12
Training loss: 3.786716938018799
Validation loss: 2.369316732283119
Epoch: 18| Step: 13
Training loss: 2.0712130069732666
Validation loss: 2.3781336468758343
Epoch: 18| Step: 14
Training loss: 2.909872531890869
Validation loss: 2.3996631413054983
Epoch: 18| Step: 15
Training loss: 2.1762051582336426
Validation loss: 2.410309076309204
Epoch: 18| Step: 16
Training loss: 3.130730390548706
Validation loss: 2.4086627256956032
Epoch: 18| Step: 17
Training loss: 3.563270092010498
Validation loss: 2.417548692483696
Epoch: 18| Step: 18
Training loss: 2.653419256210327
Validation loss: 2.4158415151156967
Epoch: 18| Step: 19
Training loss: 2.4700896739959717
Validation loss: 2.401131002165431
Epoch: 18| Step: 20
Training loss: 2.548898458480835
Validation loss: 2.3940069478192774
Epoch: 18| Step: 21
Training loss: 2.978114128112793
Validation loss: 2.396538118664309
Epoch: 18| Step: 22
Training loss: 2.44877028465271
Validation loss: 2.388795164849261
Epoch: 18| Step: 23
Training loss: 3.2386393547058105
Validation loss: 2.3843352434446485
Epoch: 18| Step: 24
Training loss: 2.4912173748016357
Validation loss: 2.3967249599292124
Epoch: 18| Step: 25
Training loss: 3.7711427211761475
Validation loss: 2.4091341015246273
Epoch: 18| Step: 26
Training loss: 2.8453354835510254
Validation loss: 2.389319208886126
Epoch: 18| Step: 27
Training loss: 1.1819660663604736
Validation loss: 2.3916724671562797
Epoch: 18| Step: 28
Training loss: 2.9412245750427246
Validation loss: 2.373777146819684
Epoch: 18| Step: 29
Training loss: 3.4811387062072754
Validation loss: 2.391661362682315
Epoch: 18| Step: 30
Training loss: 3.4501829147338867
Validation loss: 2.3798293081118906
Epoch: 18| Step: 31
Training loss: 3.9543392658233643
Validation loss: 2.4014286857714757
Epoch: 18| Step: 32
Training loss: 3.4572744369506836
Validation loss: 2.3949721528471803
Epoch: 18| Step: 33
Training loss: 2.672593593597412
Validation loss: 2.3858534998173337
Epoch: 18| Step: 34
Training loss: 3.552241802215576
Validation loss: 2.389036382702615
Epoch: 18| Step: 35
Training loss: 2.4745683670043945
Validation loss: 2.4093626943423594
Epoch: 18| Step: 36
Training loss: 2.8890557289123535
Validation loss: 2.378286076964234
Epoch: 18| Step: 37
Training loss: 4.043564796447754
Validation loss: 2.4134881736563263
Epoch: 18| Step: 38
Training loss: 2.1071510314941406
Validation loss: 2.3844495823057437
Epoch: 18| Step: 39
Training loss: 1.652354121208191
Validation loss: 2.4141517543106628
Epoch: 93| Step: 0
Training loss: 2.212888717651367
Validation loss: 2.400942750971952
Epoch: 18| Step: 1
Training loss: 2.2785048484802246
Validation loss: 2.39049312536665
Epoch: 18| Step: 2
Training loss: 3.679992198944092
Validation loss: 2.392934714718688
Epoch: 18| Step: 3
Training loss: 3.0313875675201416
Validation loss: 2.3735206058557083
Epoch: 18| Step: 4
Training loss: 2.3855881690979004
Validation loss: 2.4116633761700967
Epoch: 18| Step: 5
Training loss: 3.663715124130249
Validation loss: 2.383977823120227
Epoch: 18| Step: 6
Training loss: 3.058563232421875
Validation loss: 2.395727252788681
Epoch: 18| Step: 7
Training loss: 2.931222438812256
Validation loss: 2.3942153865484883
Epoch: 18| Step: 8
Training loss: 2.262101650238037
Validation loss: 2.3817586272740536
Epoch: 18| Step: 9
Training loss: 2.4748289585113525
Validation loss: 2.407214556666587
Epoch: 18| Step: 10
Training loss: 3.900376319885254
Validation loss: 2.4046154245198204
Epoch: 18| Step: 11
Training loss: 3.1150734424591064
Validation loss: 2.397907310252567
Epoch: 18| Step: 12
Training loss: 3.693682909011841
Validation loss: 2.3949837049991967
Epoch: 18| Step: 13
Training loss: 3.2207822799682617
Validation loss: 2.37875978294894
Epoch: 18| Step: 14
Training loss: 2.7879180908203125
Validation loss: 2.4142783168408513
Epoch: 18| Step: 15
Training loss: 3.343104362487793
Validation loss: 2.398723930763684
Epoch: 18| Step: 16
Training loss: 2.9398534297943115
Validation loss: 2.410388088912415
Epoch: 18| Step: 17
Training loss: 2.2174644470214844
Validation loss: 2.402183042155753
Epoch: 18| Step: 18
Training loss: 2.741124153137207
Validation loss: 2.389066697882234
Epoch: 18| Step: 19
Training loss: 2.599254608154297
Validation loss: 2.396109927472451
Epoch: 18| Step: 20
Training loss: 3.1890368461608887
Validation loss: 2.4112056948298175
Epoch: 18| Step: 21
Training loss: 3.333369731903076
Validation loss: 2.3822053593697308
Epoch: 18| Step: 22
Training loss: 3.4869329929351807
Validation loss: 2.383369773411922
Epoch: 18| Step: 23
Training loss: 2.281442880630493
Validation loss: 2.3793626397633725
Epoch: 18| Step: 24
Training loss: 2.532966375350952
Validation loss: 2.396281575127471
Epoch: 18| Step: 25
Training loss: 3.460118293762207
Validation loss: 2.3907350190251853
Epoch: 18| Step: 26
Training loss: 1.8322722911834717
Validation loss: 2.386481846836831
Epoch: 18| Step: 27
Training loss: 3.0435051918029785
Validation loss: 2.4033559929552695
Epoch: 18| Step: 28
Training loss: 3.0556387901306152
Validation loss: 2.4043239963998038
Epoch: 18| Step: 29
Training loss: 2.850893974304199
Validation loss: 2.385621055424642
Epoch: 18| Step: 30
Training loss: 3.138643741607666
Validation loss: 2.372765950161776
Epoch: 18| Step: 31
Training loss: 3.5198380947113037
Validation loss: 2.3954293367674024
Epoch: 18| Step: 32
Training loss: 2.603888511657715
Validation loss: 2.386700213384285
Epoch: 18| Step: 33
Training loss: 2.1680855751037598
Validation loss: 2.3822166190730583
Epoch: 18| Step: 34
Training loss: 2.9637136459350586
Validation loss: 2.3889850523832035
Epoch: 18| Step: 35
Training loss: 1.8690978288650513
Validation loss: 2.3963412286566315
Epoch: 18| Step: 36
Training loss: 2.2655844688415527
Validation loss: 2.4095817452712023
Epoch: 18| Step: 37
Training loss: 2.4922780990600586
Validation loss: 2.399869543185337
Epoch: 18| Step: 38
Training loss: 4.055418491363525
Validation loss: 2.3915456662075125
Epoch: 18| Step: 39
Training loss: 3.566411018371582
Validation loss: 2.4049610834327533
Epoch: 94| Step: 0
Training loss: 2.462639331817627
Validation loss: 2.3812273011790763
Epoch: 18| Step: 1
Training loss: 3.574340581893921
Validation loss: 2.3929518684208824
Epoch: 18| Step: 2
Training loss: 2.1701531410217285
Validation loss: 2.397162315656813
Epoch: 18| Step: 3
Training loss: 2.217759609222412
Validation loss: 2.4042880037705676
Epoch: 18| Step: 4
Training loss: 3.16823148727417
Validation loss: 2.3820788843168628
Epoch: 18| Step: 5
Training loss: 2.682732105255127
Validation loss: 2.4036579054894207
Epoch: 18| Step: 6
Training loss: 2.536929130554199
Validation loss: 2.3910058865444266
Epoch: 18| Step: 7
Training loss: 2.7526895999908447
Validation loss: 2.388366442361324
Epoch: 18| Step: 8
Training loss: 2.468230962753296
Validation loss: 2.3685277897676977
Epoch: 18| Step: 9
Training loss: 2.722734212875366
Validation loss: 2.382399648213558
Epoch: 18| Step: 10
Training loss: 3.024228096008301
Validation loss: 2.3888977928984936
Epoch: 18| Step: 11
Training loss: 2.247685670852661
Validation loss: 2.3924254350525014
Epoch: 18| Step: 12
Training loss: 2.7665226459503174
Validation loss: 2.389396284981597
Epoch: 18| Step: 13
Training loss: 4.066397190093994
Validation loss: 2.3959007469012583
Epoch: 18| Step: 14
Training loss: 3.0505781173706055
Validation loss: 2.3936597357550973
Epoch: 18| Step: 15
Training loss: 3.902050018310547
Validation loss: 2.3902218629130356
Epoch: 18| Step: 16
Training loss: 2.527634620666504
Validation loss: 2.397817858689123
Epoch: 18| Step: 17
Training loss: 3.2043795585632324
Validation loss: 2.392900124728251
Epoch: 18| Step: 18
Training loss: 2.947516679763794
Validation loss: 2.3887449382878034
Epoch: 18| Step: 19
Training loss: 2.9138870239257812
Validation loss: 2.4039329693471787
Epoch: 18| Step: 20
Training loss: 2.161670207977295
Validation loss: 2.383926105156219
Epoch: 18| Step: 21
Training loss: 3.8301074504852295
Validation loss: 2.3641946658813695
Epoch: 18| Step: 22
Training loss: 2.923966884613037
Validation loss: 2.4077662992820463
Epoch: 18| Step: 23
Training loss: 2.7238430976867676
Validation loss: 2.400259312965887
Epoch: 18| Step: 24
Training loss: 2.11781907081604
Validation loss: 2.373571695612489
Epoch: 18| Step: 25
Training loss: 3.215200185775757
Validation loss: 2.384852685516687
Epoch: 18| Step: 26
Training loss: 2.5544581413269043
Validation loss: 2.3822007908237923
Epoch: 18| Step: 27
Training loss: 3.5501856803894043
Validation loss: 2.3716670309039327
Epoch: 18| Step: 28
Training loss: 3.7948551177978516
Validation loss: 2.396739373104178
Epoch: 18| Step: 29
Training loss: 3.1955835819244385
Validation loss: 2.3828691960238726
Epoch: 18| Step: 30
Training loss: 2.3880650997161865
Validation loss: 2.3771083273475977
Epoch: 18| Step: 31
Training loss: 2.4562387466430664
Validation loss: 2.391495258688069
Epoch: 18| Step: 32
Training loss: 2.322240114212036
Validation loss: 2.388005553389625
Epoch: 18| Step: 33
Training loss: 3.008282423019409
Validation loss: 2.4105962111795547
Epoch: 18| Step: 34
Training loss: 3.885667562484741
Validation loss: 2.382972940266561
Epoch: 18| Step: 35
Training loss: 2.269991159439087
Validation loss: 2.389997902533991
Epoch: 18| Step: 36
Training loss: 3.0639255046844482
Validation loss: 2.41351482679518
Epoch: 18| Step: 37
Training loss: 2.8326916694641113
Validation loss: 2.41076850548065
Epoch: 18| Step: 38
Training loss: 2.8062610626220703
Validation loss: 2.3887650606443556
Epoch: 18| Step: 39
Training loss: 4.116765022277832
Validation loss: 2.4122410163604955
Epoch: 95| Step: 0
Training loss: 3.2795233726501465
Validation loss: 2.384629750423294
Epoch: 18| Step: 1
Training loss: 4.120018482208252
Validation loss: 2.4155863051791844
Epoch: 18| Step: 2
Training loss: 2.655163288116455
Validation loss: 2.389103994095068
Epoch: 18| Step: 3
Training loss: 1.6976110935211182
Validation loss: 2.402244384340245
Epoch: 18| Step: 4
Training loss: 2.1670937538146973
Validation loss: 2.394354180466357
Epoch: 18| Step: 5
Training loss: 3.6339120864868164
Validation loss: 2.3906049539716983
Epoch: 18| Step: 6
Training loss: 3.0668063163757324
Validation loss: 2.403558141035999
Epoch: 18| Step: 7
Training loss: 2.2405593395233154
Validation loss: 2.4030680913719342
Epoch: 18| Step: 8
Training loss: 2.115710496902466
Validation loss: 2.3895197617921897
Epoch: 18| Step: 9
Training loss: 2.435483455657959
Validation loss: 2.376268633835607
Epoch: 18| Step: 10
Training loss: 3.990081787109375
Validation loss: 2.394707377866018
Epoch: 18| Step: 11
Training loss: 3.6344213485717773
Validation loss: 2.397476004182006
Epoch: 18| Step: 12
Training loss: 3.1090140342712402
Validation loss: 2.377775391228765
Epoch: 18| Step: 13
Training loss: 2.6081900596618652
Validation loss: 2.3708698029140773
Epoch: 18| Step: 14
Training loss: 2.0994832515716553
Validation loss: 2.3879437532356316
Epoch: 18| Step: 15
Training loss: 3.6414852142333984
Validation loss: 2.3932643665684212
Epoch: 18| Step: 16
Training loss: 3.3531839847564697
Validation loss: 2.4025645444719053
Epoch: 18| Step: 17
Training loss: 3.169034719467163
Validation loss: 2.3884016266829677
Epoch: 18| Step: 18
Training loss: 2.5297210216522217
Validation loss: 2.3824258845487085
Epoch: 18| Step: 19
Training loss: 3.0257627964019775
Validation loss: 2.4182107225596474
Epoch: 18| Step: 20
Training loss: 2.9567346572875977
Validation loss: 2.3792557519116846
Epoch: 18| Step: 21
Training loss: 2.844477891921997
Validation loss: 2.3782232871158517
Epoch: 18| Step: 22
Training loss: 2.1032004356384277
Validation loss: 2.4075456986324393
Epoch: 18| Step: 23
Training loss: 3.0471553802490234
Validation loss: 2.3895323610991883
Epoch: 18| Step: 24
Training loss: 2.4431304931640625
Validation loss: 2.410353757494645
Epoch: 18| Step: 25
Training loss: 3.4420762062072754
Validation loss: 2.3908556056537216
Epoch: 18| Step: 26
Training loss: 2.0798144340515137
Validation loss: 2.3794158980143156
Epoch: 18| Step: 27
Training loss: 1.8413290977478027
Validation loss: 2.3826833191535455
Epoch: 18| Step: 28
Training loss: 2.059636116027832
Validation loss: 2.3910003291617197
Epoch: 18| Step: 29
Training loss: 3.404916286468506
Validation loss: 2.4041430589964063
Epoch: 18| Step: 30
Training loss: 3.583932399749756
Validation loss: 2.4037367319889205
Epoch: 18| Step: 31
Training loss: 2.418288230895996
Validation loss: 2.4019784910215747
Epoch: 18| Step: 32
Training loss: 2.5493483543395996
Validation loss: 2.371420388599094
Epoch: 18| Step: 33
Training loss: 3.305199146270752
Validation loss: 2.4040177983345745
Epoch: 18| Step: 34
Training loss: 2.373352289199829
Validation loss: 2.356822792574656
Epoch: 18| Step: 35
Training loss: 4.503738880157471
Validation loss: 2.4054824619842092
Epoch: 18| Step: 36
Training loss: 2.338254928588867
Validation loss: 2.3856623241369674
Epoch: 18| Step: 37
Training loss: 3.3639416694641113
Validation loss: 2.400870873773698
Epoch: 18| Step: 38
Training loss: 4.054234027862549
Validation loss: 2.391333902482506
Epoch: 18| Step: 39
Training loss: 2.7755653858184814
Validation loss: 2.3880893017748277
Epoch: 96| Step: 0
Training loss: 3.31207275390625
Validation loss: 2.384531520253463
Epoch: 18| Step: 1
Training loss: 2.838700771331787
Validation loss: 2.3742503073575687
Epoch: 18| Step: 2
Training loss: 2.42509126663208
Validation loss: 2.4018020578425565
Epoch: 18| Step: 3
Training loss: 2.7032723426818848
Validation loss: 2.387788516154392
Epoch: 18| Step: 4
Training loss: 2.2562875747680664
Validation loss: 2.3828803463805492
Epoch: 18| Step: 5
Training loss: 3.5760390758514404
Validation loss: 2.3800575711744294
Epoch: 18| Step: 6
Training loss: 2.7777414321899414
Validation loss: 2.387003564148498
Epoch: 18| Step: 7
Training loss: 3.250486135482788
Validation loss: 2.4028968416529595
Epoch: 18| Step: 8
Training loss: 2.4575917720794678
Validation loss: 2.383548585631007
Epoch: 18| Step: 9
Training loss: 2.50508189201355
Validation loss: 2.3949111983072844
Epoch: 18| Step: 10
Training loss: 2.414100170135498
Validation loss: 2.3774684092981353
Epoch: 18| Step: 11
Training loss: 3.826707601547241
Validation loss: 2.365040545840915
Epoch: 18| Step: 12
Training loss: 3.0408401489257812
Validation loss: 2.398851461547742
Epoch: 18| Step: 13
Training loss: 3.495281457901001
Validation loss: 2.3885923036568455
Epoch: 18| Step: 14
Training loss: 2.540584087371826
Validation loss: 2.4135905787241545
Epoch: 18| Step: 15
Training loss: 3.5734524726867676
Validation loss: 2.386000617802572
Epoch: 18| Step: 16
Training loss: 3.1088438034057617
Validation loss: 2.386411469617336
Epoch: 18| Step: 17
Training loss: 2.3264706134796143
Validation loss: 2.38114016519176
Epoch: 18| Step: 18
Training loss: 2.9814043045043945
Validation loss: 2.38725592249589
Epoch: 18| Step: 19
Training loss: 3.4282655715942383
Validation loss: 2.4015177291074243
Epoch: 18| Step: 20
Training loss: 2.2061002254486084
Validation loss: 2.392927739260008
Epoch: 18| Step: 21
Training loss: 2.5526297092437744
Validation loss: 2.3967589234276643
Epoch: 18| Step: 22
Training loss: 2.0631825923919678
Validation loss: 2.3867647982329774
Epoch: 18| Step: 23
Training loss: 3.137521266937256
Validation loss: 2.383380836720089
Epoch: 18| Step: 24
Training loss: 3.4779839515686035
Validation loss: 2.3897229132892415
Epoch: 18| Step: 25
Training loss: 2.5143589973449707
Validation loss: 2.3597472777469553
Epoch: 18| Step: 26
Training loss: 2.4563212394714355
Validation loss: 2.3957523870811186
Epoch: 18| Step: 27
Training loss: 2.9430644512176514
Validation loss: 2.401117793090052
Epoch: 18| Step: 28
Training loss: 2.840552806854248
Validation loss: 2.3773175289304995
Epoch: 18| Step: 29
Training loss: 2.9613564014434814
Validation loss: 2.3926837667286827
Epoch: 18| Step: 30
Training loss: 2.18064022064209
Validation loss: 2.383352497498766
Epoch: 18| Step: 31
Training loss: 2.971892833709717
Validation loss: 2.3913657382237825
Epoch: 18| Step: 32
Training loss: 3.276607036590576
Validation loss: 2.3913207036985766
Epoch: 18| Step: 33
Training loss: 3.0808088779449463
Validation loss: 2.3832283774725824
Epoch: 18| Step: 34
Training loss: 3.4286606311798096
Validation loss: 2.39418385354735
Epoch: 18| Step: 35
Training loss: 3.296052932739258
Validation loss: 2.4145096703399
Epoch: 18| Step: 36
Training loss: 2.8973398208618164
Validation loss: 2.3697641864954995
Epoch: 18| Step: 37
Training loss: 2.7619829177856445
Validation loss: 2.362312249142489
Epoch: 18| Step: 38
Training loss: 3.4487674236297607
Validation loss: 2.399217597872233
Epoch: 18| Step: 39
Training loss: 3.2974610328674316
Validation loss: 2.3991816386902074
Epoch: 97| Step: 0
Training loss: 2.8774728775024414
Validation loss: 2.3851683156953443
Epoch: 18| Step: 1
Training loss: 3.0403735637664795
Validation loss: 2.362010301017075
Epoch: 18| Step: 2
Training loss: 3.1645729541778564
Validation loss: 2.39600861844399
Epoch: 18| Step: 3
Training loss: 2.886833667755127
Validation loss: 2.384607423123696
Epoch: 18| Step: 4
Training loss: 3.566495895385742
Validation loss: 2.3977465149309993
Epoch: 18| Step: 5
Training loss: 2.989522695541382
Validation loss: 2.4193632534081986
Epoch: 18| Step: 6
Training loss: 3.0959460735321045
Validation loss: 2.371485531758919
Epoch: 18| Step: 7
Training loss: 2.662233829498291
Validation loss: 2.3800324553208387
Epoch: 18| Step: 8
Training loss: 1.7667262554168701
Validation loss: 2.414915568536992
Epoch: 18| Step: 9
Training loss: 2.8184335231781006
Validation loss: 2.3891959250402106
Epoch: 18| Step: 10
Training loss: 3.222494602203369
Validation loss: 2.3991972602528633
Epoch: 18| Step: 11
Training loss: 3.0926411151885986
Validation loss: 2.3830107064555874
Epoch: 18| Step: 12
Training loss: 4.055102825164795
Validation loss: 2.357012318192626
Epoch: 18| Step: 13
Training loss: 2.8970117568969727
Validation loss: 2.379413901473121
Epoch: 18| Step: 14
Training loss: 2.7504971027374268
Validation loss: 2.3957979507583507
Epoch: 18| Step: 15
Training loss: 2.9047369956970215
Validation loss: 2.404696267285793
Epoch: 18| Step: 16
Training loss: 2.078033685684204
Validation loss: 2.39572899290126
Epoch: 18| Step: 17
Training loss: 2.6565194129943848
Validation loss: 2.367256050058406
Epoch: 18| Step: 18
Training loss: 2.9061121940612793
Validation loss: 2.399467439102612
Epoch: 18| Step: 19
Training loss: 2.37465238571167
Validation loss: 2.3886168569111996
Epoch: 18| Step: 20
Training loss: 3.0712337493896484
Validation loss: 2.3833035753785277
Epoch: 18| Step: 21
Training loss: 3.0321249961853027
Validation loss: 2.3975703681973246
Epoch: 18| Step: 22
Training loss: 2.6155810356140137
Validation loss: 2.3861292763579662
Epoch: 18| Step: 23
Training loss: 2.1206631660461426
Validation loss: 2.381557430294778
Epoch: 18| Step: 24
Training loss: 3.274840831756592
Validation loss: 2.3927648667808916
Epoch: 18| Step: 25
Training loss: 3.4247326850891113
Validation loss: 2.372271059228362
Epoch: 18| Step: 26
Training loss: 2.4535300731658936
Validation loss: 2.3722540157304395
Epoch: 18| Step: 27
Training loss: 2.9946069717407227
Validation loss: 2.376573123520227
Epoch: 18| Step: 28
Training loss: 2.663403034210205
Validation loss: 2.3827670649658863
Epoch: 18| Step: 29
Training loss: 2.579211950302124
Validation loss: 2.393138772720913
Epoch: 18| Step: 30
Training loss: 2.667374610900879
Validation loss: 2.391522399813151
Epoch: 18| Step: 31
Training loss: 3.4710922241210938
Validation loss: 2.3973255929329413
Epoch: 18| Step: 32
Training loss: 2.5700607299804688
Validation loss: 2.3811348599495648
Epoch: 18| Step: 33
Training loss: 2.6244688034057617
Validation loss: 2.3729419699675747
Epoch: 18| Step: 34
Training loss: 4.618499755859375
Validation loss: 2.404689936329135
Epoch: 18| Step: 35
Training loss: 3.456976890563965
Validation loss: 2.401306189221444
Epoch: 18| Step: 36
Training loss: 3.136728286743164
Validation loss: 2.397269092875419
Epoch: 18| Step: 37
Training loss: 2.1437251567840576
Validation loss: 2.3958342298329307
Epoch: 18| Step: 38
Training loss: 3.0582756996154785
Validation loss: 2.3760121503322242
Epoch: 18| Step: 39
Training loss: 2.3282907009124756
Validation loss: 2.383817045808696
Epoch: 98| Step: 0
Training loss: 3.2986929416656494
Validation loss: 2.38744402274811
Epoch: 18| Step: 1
Training loss: 3.683535099029541
Validation loss: 2.38378868171637
Epoch: 18| Step: 2
Training loss: 2.7709572315216064
Validation loss: 2.3580870804169196
Epoch: 18| Step: 3
Training loss: 2.8862991333007812
Validation loss: 2.3861066832495252
Epoch: 18| Step: 4
Training loss: 2.9196019172668457
Validation loss: 2.3640170080198657
Epoch: 18| Step: 5
Training loss: 3.0052835941314697
Validation loss: 2.4121172754027005
Epoch: 18| Step: 6
Training loss: 2.8526620864868164
Validation loss: 2.3900854381725942
Epoch: 18| Step: 7
Training loss: 3.4342546463012695
Validation loss: 2.3763298902580208
Epoch: 18| Step: 8
Training loss: 3.291127920150757
Validation loss: 2.38703470950504
Epoch: 18| Step: 9
Training loss: 3.3456838130950928
Validation loss: 2.3838041094567277
Epoch: 18| Step: 10
Training loss: 2.810324192047119
Validation loss: 2.38612727810153
Epoch: 18| Step: 11
Training loss: 2.368746757507324
Validation loss: 2.3768771946859015
Epoch: 18| Step: 12
Training loss: 2.1103973388671875
Validation loss: 2.3714580467279007
Epoch: 18| Step: 13
Training loss: 3.3648366928100586
Validation loss: 2.3957635069922576
Epoch: 18| Step: 14
Training loss: 2.0852441787719727
Validation loss: 2.3978536609265446
Epoch: 18| Step: 15
Training loss: 2.4497880935668945
Validation loss: 2.4075692934955626
Epoch: 18| Step: 16
Training loss: 2.3867971897125244
Validation loss: 2.3812568822353004
Epoch: 18| Step: 17
Training loss: 2.443336009979248
Validation loss: 2.397864401769295
Epoch: 18| Step: 18
Training loss: 4.509222030639648
Validation loss: 2.386245762701515
Epoch: 18| Step: 19
Training loss: 3.07696533203125
Validation loss: 2.3938475478467325
Epoch: 18| Step: 20
Training loss: 3.336495876312256
Validation loss: 2.382961722586652
Epoch: 18| Step: 21
Training loss: 3.3183794021606445
Validation loss: 2.3785725068702974
Epoch: 18| Step: 22
Training loss: 2.5506958961486816
Validation loss: 2.3940051957000072
Epoch: 18| Step: 23
Training loss: 2.764225482940674
Validation loss: 2.390838278283318
Epoch: 18| Step: 24
Training loss: 3.226077079772949
Validation loss: 2.393039860313745
Epoch: 18| Step: 25
Training loss: 2.5154919624328613
Validation loss: 2.3847670555114746
Epoch: 18| Step: 26
Training loss: 1.969424843788147
Validation loss: 2.3566887117118287
Epoch: 18| Step: 27
Training loss: 3.193927526473999
Validation loss: 2.3827255629807067
Epoch: 18| Step: 28
Training loss: 2.1524062156677246
Validation loss: 2.3780278421992023
Epoch: 18| Step: 29
Training loss: 2.293285846710205
Validation loss: 2.3813124882231516
Epoch: 18| Step: 30
Training loss: 2.186361789703369
Validation loss: 2.3873212131664907
Epoch: 18| Step: 31
Training loss: 3.733720064163208
Validation loss: 2.3772879723164677
Epoch: 18| Step: 32
Training loss: 3.0761475563049316
Validation loss: 2.3871520457507893
Epoch: 18| Step: 33
Training loss: 2.4698829650878906
Validation loss: 2.387719516273883
Epoch: 18| Step: 34
Training loss: 2.988570213317871
Validation loss: 2.3752430008469725
Epoch: 18| Step: 35
Training loss: 3.165675640106201
Validation loss: 2.3732093512583123
Epoch: 18| Step: 36
Training loss: 3.348600149154663
Validation loss: 2.374985136574121
Epoch: 18| Step: 37
Training loss: 2.3482155799865723
Validation loss: 2.389766718843858
Epoch: 18| Step: 38
Training loss: 3.1206107139587402
Validation loss: 2.365842381827265
Epoch: 18| Step: 39
Training loss: 2.9730305671691895
Validation loss: 2.3894815787994603
Epoch: 99| Step: 0
Training loss: 2.3968935012817383
Validation loss: 2.3687548611661513
Epoch: 18| Step: 1
Training loss: 2.6137595176696777
Validation loss: 2.387722643159276
Epoch: 18| Step: 2
Training loss: 3.3120880126953125
Validation loss: 2.3887007553800403
Epoch: 18| Step: 3
Training loss: 2.5728282928466797
Validation loss: 2.385666540200762
Epoch: 18| Step: 4
Training loss: 3.3158020973205566
Validation loss: 2.403174942345928
Epoch: 18| Step: 5
Training loss: 2.807793617248535
Validation loss: 2.394327630241998
Epoch: 18| Step: 6
Training loss: 2.668003559112549
Validation loss: 2.3767236685581343
Epoch: 18| Step: 7
Training loss: 3.120117664337158
Validation loss: 2.3822703181410865
Epoch: 18| Step: 8
Training loss: 2.8009591102600098
Validation loss: 2.3758240415037966
Epoch: 18| Step: 9
Training loss: 2.098759651184082
Validation loss: 2.365541538746237
Epoch: 18| Step: 10
Training loss: 1.8191362619400024
Validation loss: 2.3904497023109053
Epoch: 18| Step: 11
Training loss: 2.6215362548828125
Validation loss: 2.4006250522119537
Epoch: 18| Step: 12
Training loss: 3.0827383995056152
Validation loss: 2.383821122080302
Epoch: 18| Step: 13
Training loss: 2.8728578090667725
Validation loss: 2.3996590590305464
Epoch: 18| Step: 14
Training loss: 2.0293726921081543
Validation loss: 2.397791879640209
Epoch: 18| Step: 15
Training loss: 1.6034066677093506
Validation loss: 2.3738541054211075
Epoch: 18| Step: 16
Training loss: 2.332301139831543
Validation loss: 2.373777609077289
Epoch: 18| Step: 17
Training loss: 3.5279738903045654
Validation loss: 2.393369117229105
Epoch: 18| Step: 18
Training loss: 4.23677396774292
Validation loss: 2.387989510735162
Epoch: 18| Step: 19
Training loss: 3.149319887161255
Validation loss: 2.3869891312482547
Epoch: 18| Step: 20
Training loss: 2.6947665214538574
Validation loss: 2.37323535603585
Epoch: 18| Step: 21
Training loss: 3.1788034439086914
Validation loss: 2.3690205542303677
Epoch: 18| Step: 22
Training loss: 2.7077817916870117
Validation loss: 2.3587112135166746
Epoch: 18| Step: 23
Training loss: 2.8562910556793213
Validation loss: 2.371578223413701
Epoch: 18| Step: 24
Training loss: 2.994964122772217
Validation loss: 2.3923337030753813
Epoch: 18| Step: 25
Training loss: 4.160765647888184
Validation loss: 2.37093327800147
Epoch: 18| Step: 26
Training loss: 3.5946593284606934
Validation loss: 2.365961447036524
Epoch: 18| Step: 27
Training loss: 3.143143892288208
Validation loss: 2.4068199661995866
Epoch: 18| Step: 28
Training loss: 2.8299641609191895
Validation loss: 2.370794025256479
Epoch: 18| Step: 29
Training loss: 3.2079825401306152
Validation loss: 2.388176943758409
Epoch: 18| Step: 30
Training loss: 3.2924869060516357
Validation loss: 2.3702514480343826
Epoch: 18| Step: 31
Training loss: 2.9501495361328125
Validation loss: 2.3979125434546162
Epoch: 18| Step: 32
Training loss: 3.168063163757324
Validation loss: 2.384189401599143
Epoch: 18| Step: 33
Training loss: 3.8966281414031982
Validation loss: 2.3941832600737647
Epoch: 18| Step: 34
Training loss: 2.179332733154297
Validation loss: 2.38176063667956
Epoch: 18| Step: 35
Training loss: 3.347041606903076
Validation loss: 2.334649087713777
Epoch: 18| Step: 36
Training loss: 2.2022061347961426
Validation loss: 2.373551444184008
Epoch: 18| Step: 37
Training loss: 3.448929786682129
Validation loss: 2.3912981002450846
Epoch: 18| Step: 38
Training loss: 2.905561685562134
Validation loss: 2.3772267300447973
Epoch: 18| Step: 39
Training loss: 2.901893377304077
Validation loss: 2.3710761704890846
Epoch: 100| Step: 0
Training loss: 3.1001102924346924
Validation loss: 2.3793036474598397
Epoch: 18| Step: 1
Training loss: 2.999959945678711
Validation loss: 2.3712672767021674
Epoch: 18| Step: 2
Training loss: 2.4733047485351562
Validation loss: 2.370136622902301
Epoch: 18| Step: 3
Training loss: 2.8279075622558594
Validation loss: 2.388945071817302
Epoch: 18| Step: 4
Training loss: 3.605867624282837
Validation loss: 2.390144676613293
Epoch: 18| Step: 5
Training loss: 2.287307024002075
Validation loss: 2.360783042667581
Epoch: 18| Step: 6
Training loss: 2.802886724472046
Validation loss: 2.3753761743470063
Epoch: 18| Step: 7
Training loss: 2.774711847305298
Validation loss: 2.3707689398484266
Epoch: 18| Step: 8
Training loss: 2.7164649963378906
Validation loss: 2.3811408958846716
Epoch: 18| Step: 9
Training loss: 3.6251702308654785
Validation loss: 2.400440679179679
Epoch: 18| Step: 10
Training loss: 3.3344366550445557
Validation loss: 2.3790418458499496
Epoch: 18| Step: 11
Training loss: 1.764845371246338
Validation loss: 2.362247166016119
Epoch: 18| Step: 12
Training loss: 2.976012706756592
Validation loss: 2.3939487548183194
Epoch: 18| Step: 13
Training loss: 2.3682785034179688
Validation loss: 2.3742115857789843
Epoch: 18| Step: 14
Training loss: 3.1816763877868652
Validation loss: 2.378520423559834
Epoch: 18| Step: 15
Training loss: 3.5471534729003906
Validation loss: 2.4068374976837377
Epoch: 18| Step: 16
Training loss: 3.6334471702575684
Validation loss: 2.3865826044151253
Epoch: 18| Step: 17
Training loss: 2.8955841064453125
Validation loss: 2.3728663784136876
Epoch: 18| Step: 18
Training loss: 2.719597816467285
Validation loss: 2.3671531591484016
Epoch: 18| Step: 19
Training loss: 2.1517648696899414
Validation loss: 2.393982772346881
Epoch: 18| Step: 20
Training loss: 2.5285720825195312
Validation loss: 2.3825508501889896
Epoch: 18| Step: 21
Training loss: 3.996743679046631
Validation loss: 2.380414278387166
Epoch: 18| Step: 22
Training loss: 2.1341958045959473
Validation loss: 2.3849752583949684
Epoch: 18| Step: 23
Training loss: 3.847525119781494
Validation loss: 2.379619853959667
Epoch: 18| Step: 24
Training loss: 2.8247997760772705
Validation loss: 2.3744602752246444
Epoch: 18| Step: 25
Training loss: 1.8583567142486572
Validation loss: 2.3944957119097814
Epoch: 18| Step: 26
Training loss: 3.197516918182373
Validation loss: 2.3875043216369134
Epoch: 18| Step: 27
Training loss: 2.99118971824646
Validation loss: 2.3656937981681
Epoch: 18| Step: 28
Training loss: 4.093180179595947
Validation loss: 2.3955387640342436
Epoch: 18| Step: 29
Training loss: 3.2523977756500244
Validation loss: 2.379326822088777
Epoch: 18| Step: 30
Training loss: 3.3251004219055176
Validation loss: 2.3602024582650163
Epoch: 18| Step: 31
Training loss: 2.288533926010132
Validation loss: 2.365093711468813
Epoch: 18| Step: 32
Training loss: 2.6750869750976562
Validation loss: 2.3885483707455424
Epoch: 18| Step: 33
Training loss: 2.325195074081421
Validation loss: 2.3680757558603083
Epoch: 18| Step: 34
Training loss: 2.7888832092285156
Validation loss: 2.3801900397101754
Epoch: 18| Step: 35
Training loss: 1.7847521305084229
Validation loss: 2.3714740207727005
Epoch: 18| Step: 36
Training loss: 3.116318464279175
Validation loss: 2.3944985797936966
Epoch: 18| Step: 37
Training loss: 2.9000496864318848
Validation loss: 2.3893623823742214
Epoch: 18| Step: 38
Training loss: 2.7347702980041504
Validation loss: 2.3818758974830025
Epoch: 18| Step: 39
Training loss: 4.21391487121582
Validation loss: 2.3742871524618683
