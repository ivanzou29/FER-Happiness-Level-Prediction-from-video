Epoch: 1| Step: 0
Training loss: 5.494009017944336
Validation loss: 5.336929798126221

Epoch: 6| Step: 1
Training loss: 6.2669358253479
Validation loss: 5.335127989451091

Epoch: 6| Step: 2
Training loss: 5.422077178955078
Validation loss: 5.3334165414174395

Epoch: 6| Step: 3
Training loss: 5.463432312011719
Validation loss: 5.331751346588135

Epoch: 6| Step: 4
Training loss: 5.731449127197266
Validation loss: 5.329991181691487

Epoch: 6| Step: 5
Training loss: 6.448387145996094
Validation loss: 5.328366835912068

Epoch: 6| Step: 6
Training loss: 5.471068382263184
Validation loss: 5.326572418212891

Epoch: 6| Step: 7
Training loss: 5.915186882019043
Validation loss: 5.3248240152994795

Epoch: 6| Step: 8
Training loss: 5.693686485290527
Validation loss: 5.323004166285197

Epoch: 6| Step: 9
Training loss: 4.924376487731934
Validation loss: 5.321312030156453

Epoch: 6| Step: 10
Training loss: 5.2750749588012695
Validation loss: 5.319386720657349

Epoch: 6| Step: 11
Training loss: 3.800753116607666
Validation loss: 5.3174839814503985

Epoch: 6| Step: 12
Training loss: 5.164854049682617
Validation loss: 5.315401315689087

Epoch: 6| Step: 13
Training loss: 4.454126358032227
Validation loss: 5.313352743784587

Epoch: 2| Step: 0
Training loss: 4.99847936630249
Validation loss: 5.311140378316243

Epoch: 6| Step: 1
Training loss: 6.032944679260254
Validation loss: 5.308909098307292

Epoch: 6| Step: 2
Training loss: 5.24479866027832
Validation loss: 5.306487401326497

Epoch: 6| Step: 3
Training loss: 4.450305938720703
Validation loss: 5.304125865300496

Epoch: 6| Step: 4
Training loss: 5.615293502807617
Validation loss: 5.301559289296468

Epoch: 6| Step: 5
Training loss: 4.770418167114258
Validation loss: 5.298913796742757

Epoch: 6| Step: 6
Training loss: 5.397336959838867
Validation loss: 5.296121438344319

Epoch: 6| Step: 7
Training loss: 5.138506889343262
Validation loss: 5.293242534001668

Epoch: 6| Step: 8
Training loss: 5.304201602935791
Validation loss: 5.29023543993632

Epoch: 6| Step: 9
Training loss: 4.209173202514648
Validation loss: 5.287007967631022

Epoch: 6| Step: 10
Training loss: 6.3040080070495605
Validation loss: 5.283828099568685

Epoch: 6| Step: 11
Training loss: 6.600156784057617
Validation loss: 5.280268510182698

Epoch: 6| Step: 12
Training loss: 5.549788475036621
Validation loss: 5.276745239893596

Epoch: 6| Step: 13
Training loss: 5.469598770141602
Validation loss: 5.273072640101115

Epoch: 3| Step: 0
Training loss: 4.495512008666992
Validation loss: 5.269256830215454

Epoch: 6| Step: 1
Training loss: 5.201991558074951
Validation loss: 5.265108108520508

Epoch: 6| Step: 2
Training loss: 5.783791542053223
Validation loss: 5.2609485785166425

Epoch: 6| Step: 3
Training loss: 3.9645378589630127
Validation loss: 5.256491502126058

Epoch: 6| Step: 4
Training loss: 4.769125938415527
Validation loss: 5.252016544342041

Epoch: 6| Step: 5
Training loss: 4.977812767028809
Validation loss: 5.247246026992798

Epoch: 6| Step: 6
Training loss: 5.197484493255615
Validation loss: 5.242343346277873

Epoch: 6| Step: 7
Training loss: 6.016252517700195
Validation loss: 5.2370937665303545

Epoch: 6| Step: 8
Training loss: 5.285882472991943
Validation loss: 5.23176383972168

Epoch: 6| Step: 9
Training loss: 5.036448001861572
Validation loss: 5.226047595342

Epoch: 6| Step: 10
Training loss: 5.894004821777344
Validation loss: 5.220293362935384

Epoch: 6| Step: 11
Training loss: 7.09902286529541
Validation loss: 5.214044570922852

Epoch: 6| Step: 12
Training loss: 5.466541290283203
Validation loss: 5.2079111735026045

Epoch: 6| Step: 13
Training loss: 5.122516632080078
Validation loss: 5.201362053553264

Epoch: 4| Step: 0
Training loss: 3.894463062286377
Validation loss: 5.194831848144531

Epoch: 6| Step: 1
Training loss: 5.041806697845459
Validation loss: 5.188176552454631

Epoch: 6| Step: 2
Training loss: 4.2427167892456055
Validation loss: 5.181204636891683

Epoch: 6| Step: 3
Training loss: 6.468493461608887
Validation loss: 5.174455086390178

Epoch: 6| Step: 4
Training loss: 5.905900001525879
Validation loss: 5.1673805713653564

Epoch: 6| Step: 5
Training loss: 4.695672035217285
Validation loss: 5.160202582677205

Epoch: 6| Step: 6
Training loss: 6.126582622528076
Validation loss: 5.152956326802571

Epoch: 6| Step: 7
Training loss: 4.860675811767578
Validation loss: 5.1455996831258135

Epoch: 6| Step: 8
Training loss: 5.60705041885376
Validation loss: 5.138504544893901

Epoch: 6| Step: 9
Training loss: 6.079434394836426
Validation loss: 5.131124496459961

Epoch: 6| Step: 10
Training loss: 4.940808296203613
Validation loss: 5.1236294110616045

Epoch: 6| Step: 11
Training loss: 5.505625247955322
Validation loss: 5.116036494572957

Epoch: 6| Step: 12
Training loss: 5.165896892547607
Validation loss: 5.108503182729085

Epoch: 6| Step: 13
Training loss: 4.578398704528809
Validation loss: 5.101078430811564

Epoch: 5| Step: 0
Training loss: 5.336912631988525
Validation loss: 5.093518257141113

Epoch: 6| Step: 1
Training loss: 5.141558647155762
Validation loss: 5.086067279179891

Epoch: 6| Step: 2
Training loss: 5.270216941833496
Validation loss: 5.078695615132649

Epoch: 6| Step: 3
Training loss: 4.51542854309082
Validation loss: 5.071137428283691

Epoch: 6| Step: 4
Training loss: 5.928736686706543
Validation loss: 5.063679615656535

Epoch: 6| Step: 5
Training loss: 5.441045761108398
Validation loss: 5.056360960006714

Epoch: 6| Step: 6
Training loss: 3.605985164642334
Validation loss: 5.0489834149678545

Epoch: 6| Step: 7
Training loss: 5.114964962005615
Validation loss: 5.041613578796387

Epoch: 6| Step: 8
Training loss: 4.938721656799316
Validation loss: 5.034263054529826

Epoch: 6| Step: 9
Training loss: 4.1694512367248535
Validation loss: 5.026711702346802

Epoch: 6| Step: 10
Training loss: 5.67744779586792
Validation loss: 5.019483009974162

Epoch: 6| Step: 11
Training loss: 5.0218400955200195
Validation loss: 5.011868715286255

Epoch: 6| Step: 12
Training loss: 5.862788200378418
Validation loss: 5.004570007324219

Epoch: 6| Step: 13
Training loss: 5.70639181137085
Validation loss: 4.99709431330363

Epoch: 6| Step: 0
Training loss: 4.1568732261657715
Validation loss: 4.9896293481191

Epoch: 6| Step: 1
Training loss: 4.470266819000244
Validation loss: 4.982175191243489

Epoch: 6| Step: 2
Training loss: 4.854579925537109
Validation loss: 4.975052356719971

Epoch: 6| Step: 3
Training loss: 5.493752479553223
Validation loss: 4.96774419148763

Epoch: 6| Step: 4
Training loss: 5.122776985168457
Validation loss: 4.960770765940349

Epoch: 6| Step: 5
Training loss: 5.2867560386657715
Validation loss: 4.953367630640666

Epoch: 6| Step: 6
Training loss: 5.601731300354004
Validation loss: 4.94630233446757

Epoch: 6| Step: 7
Training loss: 6.772008419036865
Validation loss: 4.939453323682149

Epoch: 6| Step: 8
Training loss: 4.9648919105529785
Validation loss: 4.932433287302653

Epoch: 6| Step: 9
Training loss: 4.800153732299805
Validation loss: 4.925842205683391

Epoch: 6| Step: 10
Training loss: 5.334616661071777
Validation loss: 4.918961524963379

Epoch: 6| Step: 11
Training loss: 3.8493828773498535
Validation loss: 4.912190039952596

Epoch: 6| Step: 12
Training loss: 5.013133525848389
Validation loss: 4.9054940938949585

Epoch: 6| Step: 13
Training loss: 4.664758682250977
Validation loss: 4.899099111557007

Epoch: 7| Step: 0
Training loss: 4.620526313781738
Validation loss: 4.892849763234456

Epoch: 6| Step: 1
Training loss: 4.790120601654053
Validation loss: 4.886457284291585

Epoch: 6| Step: 2
Training loss: 6.099271774291992
Validation loss: 4.880403558413188

Epoch: 6| Step: 3
Training loss: 5.238382339477539
Validation loss: 4.87443466981252

Epoch: 6| Step: 4
Training loss: 5.274075031280518
Validation loss: 4.868254741032918

Epoch: 6| Step: 5
Training loss: 5.42673397064209
Validation loss: 4.862533966700236

Epoch: 6| Step: 6
Training loss: 4.325113296508789
Validation loss: 4.856953064600627

Epoch: 6| Step: 7
Training loss: 5.053678512573242
Validation loss: 4.851371208826701

Epoch: 6| Step: 8
Training loss: 5.5549211502075195
Validation loss: 4.845792690912883

Epoch: 6| Step: 9
Training loss: 4.160592079162598
Validation loss: 4.840288003285726

Epoch: 6| Step: 10
Training loss: 3.667299270629883
Validation loss: 4.8348495165507

Epoch: 6| Step: 11
Training loss: 4.663059234619141
Validation loss: 4.829250812530518

Epoch: 6| Step: 12
Training loss: 5.651988983154297
Validation loss: 4.823910037676494

Epoch: 6| Step: 13
Training loss: 4.645571231842041
Validation loss: 4.818585952123006

Epoch: 8| Step: 0
Training loss: 4.444507598876953
Validation loss: 4.813267548878987

Epoch: 6| Step: 1
Training loss: 4.330153465270996
Validation loss: 4.807806173960368

Epoch: 6| Step: 2
Training loss: 4.339918613433838
Validation loss: 4.8021078904469805

Epoch: 6| Step: 3
Training loss: 5.814287185668945
Validation loss: 4.796740372975667

Epoch: 6| Step: 4
Training loss: 5.836181640625
Validation loss: 4.791101535161336

Epoch: 6| Step: 5
Training loss: 5.5453081130981445
Validation loss: 4.7856020132700605

Epoch: 6| Step: 6
Training loss: 4.6525678634643555
Validation loss: 4.7800421714782715

Epoch: 6| Step: 7
Training loss: 5.672059059143066
Validation loss: 4.7744970719019575

Epoch: 6| Step: 8
Training loss: 4.681387424468994
Validation loss: 4.7690220673878985

Epoch: 6| Step: 9
Training loss: 3.9334888458251953
Validation loss: 4.76387898127238

Epoch: 6| Step: 10
Training loss: 4.48220682144165
Validation loss: 4.758655309677124

Epoch: 6| Step: 11
Training loss: 4.146193027496338
Validation loss: 4.753440697987874

Epoch: 6| Step: 12
Training loss: 4.274272441864014
Validation loss: 4.748274087905884

Epoch: 6| Step: 13
Training loss: 6.012617588043213
Validation loss: 4.743431170781453

Epoch: 9| Step: 0
Training loss: 6.289247512817383
Validation loss: 4.738734404246013

Epoch: 6| Step: 1
Training loss: 4.807424545288086
Validation loss: 4.733739733695984

Epoch: 6| Step: 2
Training loss: 4.297877311706543
Validation loss: 4.728809634844462

Epoch: 6| Step: 3
Training loss: 5.111440658569336
Validation loss: 4.724046587944031

Epoch: 6| Step: 4
Training loss: 4.992218017578125
Validation loss: 4.719352086385091

Epoch: 6| Step: 5
Training loss: 5.491725444793701
Validation loss: 4.714625914891561

Epoch: 6| Step: 6
Training loss: 4.7216339111328125
Validation loss: 4.7101781368255615

Epoch: 6| Step: 7
Training loss: 3.824559450149536
Validation loss: 4.705099980036418

Epoch: 6| Step: 8
Training loss: 4.127628803253174
Validation loss: 4.700499057769775

Epoch: 6| Step: 9
Training loss: 5.326710224151611
Validation loss: 4.695702354113261

Epoch: 6| Step: 10
Training loss: 4.949667453765869
Validation loss: 4.690951665242513

Epoch: 6| Step: 11
Training loss: 4.1575751304626465
Validation loss: 4.686531186103821

Epoch: 6| Step: 12
Training loss: 4.7697319984436035
Validation loss: 4.6816229820251465

Epoch: 6| Step: 13
Training loss: 4.361729621887207
Validation loss: 4.6773122151692705

Epoch: 10| Step: 0
Training loss: 5.22114372253418
Validation loss: 4.672576268513997

Epoch: 6| Step: 1
Training loss: 5.226624488830566
Validation loss: 4.668288946151733

Epoch: 6| Step: 2
Training loss: 3.8774898052215576
Validation loss: 4.663464705149333

Epoch: 6| Step: 3
Training loss: 5.5165791511535645
Validation loss: 4.659007549285889

Epoch: 6| Step: 4
Training loss: 4.532715320587158
Validation loss: 4.65424366792043

Epoch: 6| Step: 5
Training loss: 4.308170795440674
Validation loss: 4.649777094523112

Epoch: 6| Step: 6
Training loss: 5.51643180847168
Validation loss: 4.645505825678508

Epoch: 6| Step: 7
Training loss: 3.834697723388672
Validation loss: 4.640926281611125

Epoch: 6| Step: 8
Training loss: 4.992217063903809
Validation loss: 4.636825958887736

Epoch: 6| Step: 9
Training loss: 4.700847625732422
Validation loss: 4.632170995076497

Epoch: 6| Step: 10
Training loss: 3.967273235321045
Validation loss: 4.627912759780884

Epoch: 6| Step: 11
Training loss: 5.552420616149902
Validation loss: 4.623275796572368

Epoch: 6| Step: 12
Training loss: 4.614324569702148
Validation loss: 4.618910710016887

Epoch: 6| Step: 13
Training loss: 4.512253761291504
Validation loss: 4.614734411239624

Epoch: 11| Step: 0
Training loss: 4.304067611694336
Validation loss: 4.610164165496826

Epoch: 6| Step: 1
Training loss: 3.2819058895111084
Validation loss: 4.605768799781799

Epoch: 6| Step: 2
Training loss: 5.95757532119751
Validation loss: 4.6016848882039385

Epoch: 6| Step: 3
Training loss: 4.058170318603516
Validation loss: 4.597144325574239

Epoch: 6| Step: 4
Training loss: 5.753478050231934
Validation loss: 4.592381954193115

Epoch: 6| Step: 5
Training loss: 4.762645721435547
Validation loss: 4.588098923365275

Epoch: 6| Step: 6
Training loss: 3.6296439170837402
Validation loss: 4.583841562271118

Epoch: 6| Step: 7
Training loss: 5.676645278930664
Validation loss: 4.579622189203898

Epoch: 6| Step: 8
Training loss: 5.3664469718933105
Validation loss: 4.575068314870198

Epoch: 6| Step: 9
Training loss: 4.338613510131836
Validation loss: 4.570922295252482

Epoch: 6| Step: 10
Training loss: 5.192766189575195
Validation loss: 4.566732009251912

Epoch: 6| Step: 11
Training loss: 3.935319423675537
Validation loss: 4.562303066253662

Epoch: 6| Step: 12
Training loss: 4.438807964324951
Validation loss: 4.557572444279988

Epoch: 6| Step: 13
Training loss: 4.859000205993652
Validation loss: 4.552701036135356

Epoch: 12| Step: 0
Training loss: 3.0284104347229004
Validation loss: 4.548459927241008

Epoch: 6| Step: 1
Training loss: 4.794588088989258
Validation loss: 4.544246991475423

Epoch: 6| Step: 2
Training loss: 5.32905387878418
Validation loss: 4.539607683817546

Epoch: 6| Step: 3
Training loss: 4.224753379821777
Validation loss: 4.535240729649861

Epoch: 6| Step: 4
Training loss: 4.7183451652526855
Validation loss: 4.5304023424784345

Epoch: 6| Step: 5
Training loss: 4.57437801361084
Validation loss: 4.526051640510559

Epoch: 6| Step: 6
Training loss: 5.427748680114746
Validation loss: 4.521166245142619

Epoch: 6| Step: 7
Training loss: 4.3519721031188965
Validation loss: 4.5166652997334795

Epoch: 6| Step: 8
Training loss: 4.628841400146484
Validation loss: 4.511768380800883

Epoch: 6| Step: 9
Training loss: 4.016848087310791
Validation loss: 4.507253487904866

Epoch: 6| Step: 10
Training loss: 5.445228099822998
Validation loss: 4.502469380696614

Epoch: 6| Step: 11
Training loss: 4.228182792663574
Validation loss: 4.497474034627278

Epoch: 6| Step: 12
Training loss: 5.169357776641846
Validation loss: 4.4932520389556885

Epoch: 6| Step: 13
Training loss: 4.777609825134277
Validation loss: 4.487772544225057

Epoch: 13| Step: 0
Training loss: 4.368474960327148
Validation loss: 4.482897202173869

Epoch: 6| Step: 1
Training loss: 4.0666584968566895
Validation loss: 4.4778819878896075

Epoch: 6| Step: 2
Training loss: 5.481825828552246
Validation loss: 4.473246971766154

Epoch: 6| Step: 3
Training loss: 4.426801681518555
Validation loss: 4.468239943186442

Epoch: 6| Step: 4
Training loss: 4.954960823059082
Validation loss: 4.463575998942058

Epoch: 6| Step: 5
Training loss: 5.59883975982666
Validation loss: 4.458342711130778

Epoch: 6| Step: 6
Training loss: 3.782210350036621
Validation loss: 4.4533601601918535

Epoch: 6| Step: 7
Training loss: 5.157223701477051
Validation loss: 4.448173522949219

Epoch: 6| Step: 8
Training loss: 4.558073043823242
Validation loss: 4.442930658658345

Epoch: 6| Step: 9
Training loss: 4.900703430175781
Validation loss: 4.43777072429657

Epoch: 6| Step: 10
Training loss: 4.5846052169799805
Validation loss: 4.432464361190796

Epoch: 6| Step: 11
Training loss: 4.27487850189209
Validation loss: 4.427531798680623

Epoch: 6| Step: 12
Training loss: 4.00032901763916
Validation loss: 4.422426025072734

Epoch: 6| Step: 13
Training loss: 3.712322235107422
Validation loss: 4.417040506998698

Epoch: 14| Step: 0
Training loss: 3.266754150390625
Validation loss: 4.412085612614949

Epoch: 6| Step: 1
Training loss: 5.242416858673096
Validation loss: 4.407080292701721

Epoch: 6| Step: 2
Training loss: 4.814358711242676
Validation loss: 4.401392579078674

Epoch: 6| Step: 3
Training loss: 4.869758129119873
Validation loss: 4.3959290981292725

Epoch: 6| Step: 4
Training loss: 4.901870250701904
Validation loss: 4.390748858451843

Epoch: 6| Step: 5
Training loss: 3.295764446258545
Validation loss: 4.3847523132960005

Epoch: 6| Step: 6
Training loss: 5.015885353088379
Validation loss: 4.379255930582683

Epoch: 6| Step: 7
Training loss: 5.787442207336426
Validation loss: 4.372975150744121

Epoch: 6| Step: 8
Training loss: 4.842504501342773
Validation loss: 4.36733607451121

Epoch: 6| Step: 9
Training loss: 3.6112585067749023
Validation loss: 4.361047148704529

Epoch: 6| Step: 10
Training loss: 3.815373420715332
Validation loss: 4.355198462804158

Epoch: 6| Step: 11
Training loss: 3.384608268737793
Validation loss: 4.349995056788127

Epoch: 6| Step: 12
Training loss: 4.311992645263672
Validation loss: 4.3440277973810835

Epoch: 6| Step: 13
Training loss: 5.737427711486816
Validation loss: 4.338330984115601

Epoch: 15| Step: 0
Training loss: 4.1478166580200195
Validation loss: 4.3322213888168335

Epoch: 6| Step: 1
Training loss: 4.096825122833252
Validation loss: 4.327820976575215

Epoch: 6| Step: 2
Training loss: 4.175342559814453
Validation loss: 4.323348840077718

Epoch: 6| Step: 3
Training loss: 4.123842716217041
Validation loss: 4.317114512125651

Epoch: 6| Step: 4
Training loss: 5.350321292877197
Validation loss: 4.3113930225372314

Epoch: 6| Step: 5
Training loss: 4.140142440795898
Validation loss: 4.306165178616841

Epoch: 6| Step: 6
Training loss: 3.600099563598633
Validation loss: 4.300397038459778

Epoch: 6| Step: 7
Training loss: 4.3204665184021
Validation loss: 4.295242071151733

Epoch: 6| Step: 8
Training loss: 4.915542125701904
Validation loss: 4.289348363876343

Epoch: 6| Step: 9
Training loss: 3.251945972442627
Validation loss: 4.283615350723267

Epoch: 6| Step: 10
Training loss: 5.216329574584961
Validation loss: 4.279539465904236

Epoch: 6| Step: 11
Training loss: 4.914518356323242
Validation loss: 4.273680845896403

Epoch: 6| Step: 12
Training loss: 5.251822471618652
Validation loss: 4.267830729484558

Epoch: 6| Step: 13
Training loss: 4.401401042938232
Validation loss: 4.262577136357625

Epoch: 16| Step: 0
Training loss: 3.5075783729553223
Validation loss: 4.257121880849202

Epoch: 6| Step: 1
Training loss: 4.647521018981934
Validation loss: 4.252019842465718

Epoch: 6| Step: 2
Training loss: 3.683816432952881
Validation loss: 4.246611038843791

Epoch: 6| Step: 3
Training loss: 5.820463180541992
Validation loss: 4.241214315096538

Epoch: 6| Step: 4
Training loss: 3.867459297180176
Validation loss: 4.236363649368286

Epoch: 6| Step: 5
Training loss: 4.29383659362793
Validation loss: 4.2314809163411455

Epoch: 6| Step: 6
Training loss: 3.8571081161499023
Validation loss: 4.226690451304118

Epoch: 6| Step: 7
Training loss: 3.4898629188537598
Validation loss: 4.220441301663716

Epoch: 6| Step: 8
Training loss: 4.664727210998535
Validation loss: 4.21483302116394

Epoch: 6| Step: 9
Training loss: 4.310542106628418
Validation loss: 4.21263591448466

Epoch: 6| Step: 10
Training loss: 4.424184799194336
Validation loss: 4.206619739532471

Epoch: 6| Step: 11
Training loss: 4.52421760559082
Validation loss: 4.200961271921794

Epoch: 6| Step: 12
Training loss: 5.213590621948242
Validation loss: 4.196852684020996

Epoch: 6| Step: 13
Training loss: 4.653024673461914
Validation loss: 4.19007392724355

Epoch: 17| Step: 0
Training loss: 4.1794281005859375
Validation loss: 4.18563727537791

Epoch: 6| Step: 1
Training loss: 4.752743244171143
Validation loss: 4.180913368860881

Epoch: 6| Step: 2
Training loss: 4.555017471313477
Validation loss: 4.176496744155884

Epoch: 6| Step: 3
Training loss: 4.687498092651367
Validation loss: 4.168966968854268

Epoch: 6| Step: 4
Training loss: 4.725425720214844
Validation loss: 4.164016604423523

Epoch: 6| Step: 5
Training loss: 4.571267127990723
Validation loss: 4.159228960673015

Epoch: 6| Step: 6
Training loss: 3.55676531791687
Validation loss: 4.154565811157227

Epoch: 6| Step: 7
Training loss: 3.290818691253662
Validation loss: 4.148955742518107

Epoch: 6| Step: 8
Training loss: 4.084751605987549
Validation loss: 4.146866838137309

Epoch: 6| Step: 9
Training loss: 4.682013511657715
Validation loss: 4.140135010083516

Epoch: 6| Step: 10
Training loss: 4.061563491821289
Validation loss: 4.138177990913391

Epoch: 6| Step: 11
Training loss: 3.9146766662597656
Validation loss: 4.133673032124837

Epoch: 6| Step: 12
Training loss: 4.614434242248535
Validation loss: 4.127704540888469

Epoch: 6| Step: 13
Training loss: 4.382602691650391
Validation loss: 4.122315804163615

Epoch: 18| Step: 0
Training loss: 3.968303918838501
Validation loss: 4.118865807851155

Epoch: 6| Step: 1
Training loss: 5.035752773284912
Validation loss: 4.114916682243347

Epoch: 6| Step: 2
Training loss: 3.8443174362182617
Validation loss: 4.108158707618713

Epoch: 6| Step: 3
Training loss: 4.777219295501709
Validation loss: 4.103240489959717

Epoch: 6| Step: 4
Training loss: 4.203708648681641
Validation loss: 4.097760121027629

Epoch: 6| Step: 5
Training loss: 3.5436184406280518
Validation loss: 4.094202438990275

Epoch: 6| Step: 6
Training loss: 3.807983875274658
Validation loss: 4.090061187744141

Epoch: 6| Step: 7
Training loss: 3.405367374420166
Validation loss: 4.085134665171306

Epoch: 6| Step: 8
Training loss: 4.285102844238281
Validation loss: 4.0799879630406695

Epoch: 6| Step: 9
Training loss: 4.181935787200928
Validation loss: 4.075965841611226

Epoch: 6| Step: 10
Training loss: 4.814379692077637
Validation loss: 4.071110725402832

Epoch: 6| Step: 11
Training loss: 4.469974517822266
Validation loss: 4.068426728248596

Epoch: 6| Step: 12
Training loss: 4.862177848815918
Validation loss: 4.062687714894612

Epoch: 6| Step: 13
Training loss: 4.010778903961182
Validation loss: 4.057909607887268

Epoch: 19| Step: 0
Training loss: 2.906208038330078
Validation loss: 4.053595383961995

Epoch: 6| Step: 1
Training loss: 4.433871269226074
Validation loss: 4.0508162180582685

Epoch: 6| Step: 2
Training loss: 4.145517349243164
Validation loss: 4.046098510424296

Epoch: 6| Step: 3
Training loss: 4.473955154418945
Validation loss: 4.041735212008159

Epoch: 6| Step: 4
Training loss: 3.579624891281128
Validation loss: 4.038541873296102

Epoch: 6| Step: 5
Training loss: 5.459551811218262
Validation loss: 4.032821814219157

Epoch: 6| Step: 6
Training loss: 4.854448318481445
Validation loss: 4.028836528460185

Epoch: 6| Step: 7
Training loss: 4.375348091125488
Validation loss: 4.025923530260722

Epoch: 6| Step: 8
Training loss: 4.1586713790893555
Validation loss: 4.020524422327678

Epoch: 6| Step: 9
Training loss: 3.404745578765869
Validation loss: 4.0162034034729

Epoch: 6| Step: 10
Training loss: 3.9706602096557617
Validation loss: 4.0121298631032305

Epoch: 6| Step: 11
Training loss: 4.362290859222412
Validation loss: 4.007778127988179

Epoch: 6| Step: 12
Training loss: 4.004909515380859
Validation loss: 4.003658612569173

Epoch: 6| Step: 13
Training loss: 4.2642364501953125
Validation loss: 4.0003849267959595

Epoch: 20| Step: 0
Training loss: 4.601446151733398
Validation loss: 3.9949089686075845

Epoch: 6| Step: 1
Training loss: 4.86511754989624
Validation loss: 3.9905522664388022

Epoch: 6| Step: 2
Training loss: 4.284879207611084
Validation loss: 3.9862724939982095

Epoch: 6| Step: 3
Training loss: 4.225123405456543
Validation loss: 3.9819130500157676

Epoch: 6| Step: 4
Training loss: 4.423646926879883
Validation loss: 3.977105696996053

Epoch: 6| Step: 5
Training loss: 3.43911075592041
Validation loss: 3.97330371538798

Epoch: 6| Step: 6
Training loss: 5.054094314575195
Validation loss: 3.9689395427703857

Epoch: 6| Step: 7
Training loss: 4.4149675369262695
Validation loss: 3.964694023132324

Epoch: 6| Step: 8
Training loss: 3.690092086791992
Validation loss: 3.960474729537964

Epoch: 6| Step: 9
Training loss: 4.119811058044434
Validation loss: 3.9560769399007163

Epoch: 6| Step: 10
Training loss: 3.708043098449707
Validation loss: 3.9514007568359375

Epoch: 6| Step: 11
Training loss: 4.171934127807617
Validation loss: 3.947471817334493

Epoch: 6| Step: 12
Training loss: 4.059419631958008
Validation loss: 3.9435516198476157

Epoch: 6| Step: 13
Training loss: 2.5361740589141846
Validation loss: 3.939413905143738

Epoch: 21| Step: 0
Training loss: 4.5097808837890625
Validation loss: 3.935232321421305

Epoch: 6| Step: 1
Training loss: 3.9350244998931885
Validation loss: 3.9305174748102822

Epoch: 6| Step: 2
Training loss: 3.6545753479003906
Validation loss: 3.926607529322306

Epoch: 6| Step: 3
Training loss: 3.27496075630188
Validation loss: 3.9217081467310586

Epoch: 6| Step: 4
Training loss: 4.308866024017334
Validation loss: 3.918199578921

Epoch: 6| Step: 5
Training loss: 4.839977264404297
Validation loss: 3.91317888100942

Epoch: 6| Step: 6
Training loss: 4.371108055114746
Validation loss: 3.9093422889709473

Epoch: 6| Step: 7
Training loss: 4.515137672424316
Validation loss: 3.9054791927337646

Epoch: 6| Step: 8
Training loss: 4.439940929412842
Validation loss: 3.9013530015945435

Epoch: 6| Step: 9
Training loss: 3.15836763381958
Validation loss: 3.897308627764384

Epoch: 6| Step: 10
Training loss: 4.447208881378174
Validation loss: 3.8930964867273965

Epoch: 6| Step: 11
Training loss: 3.9006190299987793
Validation loss: 3.889240582784017

Epoch: 6| Step: 12
Training loss: 3.942222833633423
Validation loss: 3.8847298622131348

Epoch: 6| Step: 13
Training loss: 3.513704776763916
Validation loss: 3.880682190259298

Epoch: 22| Step: 0
Training loss: 4.51579475402832
Validation loss: 3.876882553100586

Epoch: 6| Step: 1
Training loss: 3.9584109783172607
Validation loss: 3.875486175219218

Epoch: 6| Step: 2
Training loss: 3.476128101348877
Validation loss: 3.8694653511047363

Epoch: 6| Step: 3
Training loss: 4.011261463165283
Validation loss: 3.8645017544428506

Epoch: 6| Step: 4
Training loss: 4.465033531188965
Validation loss: 3.859729290008545

Epoch: 6| Step: 5
Training loss: 3.7097787857055664
Validation loss: 3.8560773928960166

Epoch: 6| Step: 6
Training loss: 3.5310440063476562
Validation loss: 3.851884365081787

Epoch: 6| Step: 7
Training loss: 3.862636089324951
Validation loss: 3.8481818437576294

Epoch: 6| Step: 8
Training loss: 4.770509719848633
Validation loss: 3.843936324119568

Epoch: 6| Step: 9
Training loss: 2.889944076538086
Validation loss: 3.8395365476608276

Epoch: 6| Step: 10
Training loss: 4.337136745452881
Validation loss: 3.835613965988159

Epoch: 6| Step: 11
Training loss: 4.58156681060791
Validation loss: 3.8309752543767295

Epoch: 6| Step: 12
Training loss: 4.274250507354736
Validation loss: 3.8266270955403647

Epoch: 6| Step: 13
Training loss: 3.658324718475342
Validation loss: 3.822182377179464

Epoch: 23| Step: 0
Training loss: 3.4501242637634277
Validation loss: 3.81857959429423

Epoch: 6| Step: 1
Training loss: 4.140869617462158
Validation loss: 3.814096132914225

Epoch: 6| Step: 2
Training loss: 3.747133731842041
Validation loss: 3.8101752201716104

Epoch: 6| Step: 3
Training loss: 2.9922289848327637
Validation loss: 3.8066091934839883

Epoch: 6| Step: 4
Training loss: 4.312725067138672
Validation loss: 3.8030693928400674

Epoch: 6| Step: 5
Training loss: 4.445777893066406
Validation loss: 3.7984400192896524

Epoch: 6| Step: 6
Training loss: 3.990164041519165
Validation loss: 3.794662872950236

Epoch: 6| Step: 7
Training loss: 4.09102201461792
Validation loss: 3.790480852127075

Epoch: 6| Step: 8
Training loss: 4.843647003173828
Validation loss: 3.7858945528666177

Epoch: 6| Step: 9
Training loss: 4.833189010620117
Validation loss: 3.7819371223449707

Epoch: 6| Step: 10
Training loss: 3.9178500175476074
Validation loss: 3.777508099873861

Epoch: 6| Step: 11
Training loss: 2.859044313430786
Validation loss: 3.7735735177993774

Epoch: 6| Step: 12
Training loss: 4.082738876342773
Validation loss: 3.7693180243174234

Epoch: 6| Step: 13
Training loss: 3.5796942710876465
Validation loss: 3.765056927998861

Epoch: 24| Step: 0
Training loss: 3.66204833984375
Validation loss: 3.7611759503682456

Epoch: 6| Step: 1
Training loss: 4.353845596313477
Validation loss: 3.7575713793436685

Epoch: 6| Step: 2
Training loss: 2.844237804412842
Validation loss: 3.7532890240351358

Epoch: 6| Step: 3
Training loss: 3.8237321376800537
Validation loss: 3.7502419153849282

Epoch: 6| Step: 4
Training loss: 4.012392997741699
Validation loss: 3.745243469874064

Epoch: 6| Step: 5
Training loss: 3.887772560119629
Validation loss: 3.741420348485311

Epoch: 6| Step: 6
Training loss: 3.7850446701049805
Validation loss: 3.7372159163157144

Epoch: 6| Step: 7
Training loss: 4.334029674530029
Validation loss: 3.733027458190918

Epoch: 6| Step: 8
Training loss: 3.223898410797119
Validation loss: 3.729434092839559

Epoch: 6| Step: 9
Training loss: 3.5953240394592285
Validation loss: 3.7252347469329834

Epoch: 6| Step: 10
Training loss: 4.640475273132324
Validation loss: 3.7209323247273765

Epoch: 6| Step: 11
Training loss: 2.979421377182007
Validation loss: 3.7166093587875366

Epoch: 6| Step: 12
Training loss: 4.838589668273926
Validation loss: 3.713034192721049

Epoch: 6| Step: 13
Training loss: 4.547717094421387
Validation loss: 3.7084311644236245

Epoch: 25| Step: 0
Training loss: 3.932283878326416
Validation loss: 3.7053496837615967

Epoch: 6| Step: 1
Training loss: 3.723802089691162
Validation loss: 3.700921138127645

Epoch: 6| Step: 2
Training loss: 3.6701016426086426
Validation loss: 3.696659803390503

Epoch: 6| Step: 3
Training loss: 3.127202033996582
Validation loss: 3.6935425202051797

Epoch: 6| Step: 4
Training loss: 3.5001461505889893
Validation loss: 3.6894951661427817

Epoch: 6| Step: 5
Training loss: 4.001582145690918
Validation loss: 3.685579260190328

Epoch: 6| Step: 6
Training loss: 4.357616424560547
Validation loss: 3.6817332903544107

Epoch: 6| Step: 7
Training loss: 3.4961066246032715
Validation loss: 3.677862286567688

Epoch: 6| Step: 8
Training loss: 4.440704822540283
Validation loss: 3.6744091908137

Epoch: 6| Step: 9
Training loss: 4.215908527374268
Validation loss: 3.670488198598226

Epoch: 6| Step: 10
Training loss: 4.340969085693359
Validation loss: 3.6661277612050376

Epoch: 6| Step: 11
Training loss: 3.507176399230957
Validation loss: 3.6621849139531455

Epoch: 6| Step: 12
Training loss: 3.7903289794921875
Validation loss: 3.658218264579773

Epoch: 6| Step: 13
Training loss: 3.6633152961730957
Validation loss: 3.6540298064549765

Epoch: 26| Step: 0
Training loss: 3.414311647415161
Validation loss: 3.649756908416748

Epoch: 6| Step: 1
Training loss: 3.2783358097076416
Validation loss: 3.6456137895584106

Epoch: 6| Step: 2
Training loss: 4.2099504470825195
Validation loss: 3.641526182492574

Epoch: 6| Step: 3
Training loss: 4.255967140197754
Validation loss: 3.637324849764506

Epoch: 6| Step: 4
Training loss: 3.397711753845215
Validation loss: 3.633920907974243

Epoch: 6| Step: 5
Training loss: 4.055550575256348
Validation loss: 3.630027095476786

Epoch: 6| Step: 6
Training loss: 3.190497398376465
Validation loss: 3.6258545319239297

Epoch: 6| Step: 7
Training loss: 3.7961018085479736
Validation loss: 3.6217289765675864

Epoch: 6| Step: 8
Training loss: 3.8907485008239746
Validation loss: 3.6172083218892417

Epoch: 6| Step: 9
Training loss: 4.397971153259277
Validation loss: 3.6130808194478354

Epoch: 6| Step: 10
Training loss: 2.6838386058807373
Validation loss: 3.6092673540115356

Epoch: 6| Step: 11
Training loss: 4.351878643035889
Validation loss: 3.604881763458252

Epoch: 6| Step: 12
Training loss: 4.426936626434326
Validation loss: 3.6010344425837197

Epoch: 6| Step: 13
Training loss: 3.6628096103668213
Validation loss: 3.5965629418691

Epoch: 27| Step: 0
Training loss: 5.066288948059082
Validation loss: 3.592359701792399

Epoch: 6| Step: 1
Training loss: 2.949375629425049
Validation loss: 3.588186422983805

Epoch: 6| Step: 2
Training loss: 4.094344139099121
Validation loss: 3.584403475125631

Epoch: 6| Step: 3
Training loss: 4.212059020996094
Validation loss: 3.5798697074254355

Epoch: 6| Step: 4
Training loss: 3.9739434719085693
Validation loss: 3.5759894847869873

Epoch: 6| Step: 5
Training loss: 3.6353759765625
Validation loss: 3.5716934204101562

Epoch: 6| Step: 6
Training loss: 2.718071460723877
Validation loss: 3.5675605138142905

Epoch: 6| Step: 7
Training loss: 4.1010260581970215
Validation loss: 3.563907504081726

Epoch: 6| Step: 8
Training loss: 3.231079578399658
Validation loss: 3.559916694959005

Epoch: 6| Step: 9
Training loss: 4.09708309173584
Validation loss: 3.5561035871505737

Epoch: 6| Step: 10
Training loss: 3.4202375411987305
Validation loss: 3.5519548654556274

Epoch: 6| Step: 11
Training loss: 3.567469596862793
Validation loss: 3.54755437374115

Epoch: 6| Step: 12
Training loss: 3.6815364360809326
Validation loss: 3.5439186096191406

Epoch: 6| Step: 13
Training loss: 3.461808919906616
Validation loss: 3.5404009024302163

Epoch: 28| Step: 0
Training loss: 3.2408623695373535
Validation loss: 3.5390345652898154

Epoch: 6| Step: 1
Training loss: 4.379473686218262
Validation loss: 3.532621741294861

Epoch: 6| Step: 2
Training loss: 2.972104072570801
Validation loss: 3.5271859169006348

Epoch: 6| Step: 3
Training loss: 3.530052423477173
Validation loss: 3.5245110988616943

Epoch: 6| Step: 4
Training loss: 3.7349624633789062
Validation loss: 3.523406744003296

Epoch: 6| Step: 5
Training loss: 3.6317200660705566
Validation loss: 3.5168848435084024

Epoch: 6| Step: 6
Training loss: 2.993992328643799
Validation loss: 3.5120665629704795

Epoch: 6| Step: 7
Training loss: 3.6497485637664795
Validation loss: 3.50698983669281

Epoch: 6| Step: 8
Training loss: 3.38748836517334
Validation loss: 3.502606829007467

Epoch: 6| Step: 9
Training loss: 3.8040473461151123
Validation loss: 3.49893856048584

Epoch: 6| Step: 10
Training loss: 4.545596599578857
Validation loss: 3.4975200096766152

Epoch: 6| Step: 11
Training loss: 3.585671901702881
Validation loss: 3.4961063067118325

Epoch: 6| Step: 12
Training loss: 4.3836493492126465
Validation loss: 3.4910762310028076

Epoch: 6| Step: 13
Training loss: 3.653766393661499
Validation loss: 3.4821151892344155

Epoch: 29| Step: 0
Training loss: 3.4138455390930176
Validation loss: 3.4770594040552774

Epoch: 6| Step: 1
Training loss: 3.964561939239502
Validation loss: 3.473997871081034

Epoch: 6| Step: 2
Training loss: 3.9890453815460205
Validation loss: 3.4712138970692954

Epoch: 6| Step: 3
Training loss: 4.160228252410889
Validation loss: 3.468979835510254

Epoch: 6| Step: 4
Training loss: 3.4021310806274414
Validation loss: 3.4634600083033242

Epoch: 6| Step: 5
Training loss: 3.308849334716797
Validation loss: 3.4594773848851523

Epoch: 6| Step: 6
Training loss: 3.635380268096924
Validation loss: 3.4537301460901895

Epoch: 6| Step: 7
Training loss: 3.859795570373535
Validation loss: 3.4489402770996094

Epoch: 6| Step: 8
Training loss: 3.2983083724975586
Validation loss: 3.4441516399383545

Epoch: 6| Step: 9
Training loss: 4.094974517822266
Validation loss: 3.439806858698527

Epoch: 6| Step: 10
Training loss: 4.058968544006348
Validation loss: 3.4353694121042886

Epoch: 6| Step: 11
Training loss: 3.2039856910705566
Validation loss: 3.43216343720754

Epoch: 6| Step: 12
Training loss: 3.0656559467315674
Validation loss: 3.429470976193746

Epoch: 6| Step: 13
Training loss: 3.1989917755126953
Validation loss: 3.4284417629241943

Epoch: 30| Step: 0
Training loss: 3.238154411315918
Validation loss: 3.4220858017603555

Epoch: 6| Step: 1
Training loss: 3.3837332725524902
Validation loss: 3.417516271273295

Epoch: 6| Step: 2
Training loss: 3.9996657371520996
Validation loss: 3.4170502026875815

Epoch: 6| Step: 3
Training loss: 3.0209498405456543
Validation loss: 3.408037304878235

Epoch: 6| Step: 4
Training loss: 3.6059818267822266
Validation loss: 3.4036432902018228

Epoch: 6| Step: 5
Training loss: 4.242454528808594
Validation loss: 3.4008611838022866

Epoch: 6| Step: 6
Training loss: 3.383636951446533
Validation loss: 3.396390954653422

Epoch: 6| Step: 7
Training loss: 5.205691337585449
Validation loss: 3.3929827213287354

Epoch: 6| Step: 8
Training loss: 3.639897584915161
Validation loss: 3.3893940448760986

Epoch: 6| Step: 9
Training loss: 2.5238561630249023
Validation loss: 3.3850975831349692

Epoch: 6| Step: 10
Training loss: 3.134110927581787
Validation loss: 3.381596406300863

Epoch: 6| Step: 11
Training loss: 3.3982834815979004
Validation loss: 3.3770265579223633

Epoch: 6| Step: 12
Training loss: 3.530174732208252
Validation loss: 3.3730223178863525

Epoch: 6| Step: 13
Training loss: 3.5607988834381104
Validation loss: 3.368440548578898

Epoch: 31| Step: 0
Training loss: 3.056476354598999
Validation loss: 3.36404816309611

Epoch: 6| Step: 1
Training loss: 3.351254463195801
Validation loss: 3.360054532686869

Epoch: 6| Step: 2
Training loss: 4.228013038635254
Validation loss: 3.3561789194742837

Epoch: 6| Step: 3
Training loss: 4.147485733032227
Validation loss: 3.351445515950521

Epoch: 6| Step: 4
Training loss: 3.4264254570007324
Validation loss: 3.3464345137278237

Epoch: 6| Step: 5
Training loss: 3.624253273010254
Validation loss: 3.3423171043395996

Epoch: 6| Step: 6
Training loss: 3.133540153503418
Validation loss: 3.339088559150696

Epoch: 6| Step: 7
Training loss: 3.8118784427642822
Validation loss: 3.3346910079320273

Epoch: 6| Step: 8
Training loss: 3.0844039916992188
Validation loss: 3.3308700720469155

Epoch: 6| Step: 9
Training loss: 3.7153432369232178
Validation loss: 3.3269609212875366

Epoch: 6| Step: 10
Training loss: 3.4425928592681885
Validation loss: 3.3223842779795327

Epoch: 6| Step: 11
Training loss: 3.1986160278320312
Validation loss: 3.3188602924346924

Epoch: 6| Step: 12
Training loss: 4.3052778244018555
Validation loss: 3.3145490090052285

Epoch: 6| Step: 13
Training loss: 2.6201140880584717
Validation loss: 3.3106635014216104

Epoch: 32| Step: 0
Training loss: 3.496526002883911
Validation loss: 3.3065954446792603

Epoch: 6| Step: 1
Training loss: 3.6222176551818848
Validation loss: 3.3024561405181885

Epoch: 6| Step: 2
Training loss: 3.4540352821350098
Validation loss: 3.297999103864034

Epoch: 6| Step: 3
Training loss: 3.5562493801116943
Validation loss: 3.2952630122502646

Epoch: 6| Step: 4
Training loss: 3.600651979446411
Validation loss: 3.295725146929423

Epoch: 6| Step: 5
Training loss: 3.5380067825317383
Validation loss: 3.2882053454717

Epoch: 6| Step: 6
Training loss: 3.5497965812683105
Validation loss: 3.2824589014053345

Epoch: 6| Step: 7
Training loss: 3.937389373779297
Validation loss: 3.2788822253545127

Epoch: 6| Step: 8
Training loss: 4.076510906219482
Validation loss: 3.274034857749939

Epoch: 6| Step: 9
Training loss: 3.0667552947998047
Validation loss: 3.2707794507344565

Epoch: 6| Step: 10
Training loss: 3.1533684730529785
Validation loss: 3.266236941019694

Epoch: 6| Step: 11
Training loss: 3.632040500640869
Validation loss: 3.2631712357203164

Epoch: 6| Step: 12
Training loss: 3.307948112487793
Validation loss: 3.2594939470291138

Epoch: 6| Step: 13
Training loss: 2.450918197631836
Validation loss: 3.2556511958440146

Epoch: 33| Step: 0
Training loss: 3.4295387268066406
Validation loss: 3.252086798350016

Epoch: 6| Step: 1
Training loss: 4.206198692321777
Validation loss: 3.2485225598017373

Epoch: 6| Step: 2
Training loss: 2.7404208183288574
Validation loss: 3.2449384133021035

Epoch: 6| Step: 3
Training loss: 3.582641124725342
Validation loss: 3.241379737854004

Epoch: 6| Step: 4
Training loss: 3.805199146270752
Validation loss: 3.237923741340637

Epoch: 6| Step: 5
Training loss: 2.496488571166992
Validation loss: 3.234286069869995

Epoch: 6| Step: 6
Training loss: 3.8445281982421875
Validation loss: 3.2303579648335776

Epoch: 6| Step: 7
Training loss: 2.8185744285583496
Validation loss: 3.225886424382528

Epoch: 6| Step: 8
Training loss: 3.4905288219451904
Validation loss: 3.223116079966227

Epoch: 6| Step: 9
Training loss: 2.7895708084106445
Validation loss: 3.2194144328435264

Epoch: 6| Step: 10
Training loss: 3.3162386417388916
Validation loss: 3.215298612912496

Epoch: 6| Step: 11
Training loss: 4.076207160949707
Validation loss: 3.2128710746765137

Epoch: 6| Step: 12
Training loss: 3.446476459503174
Validation loss: 3.2088494300842285

Epoch: 6| Step: 13
Training loss: 3.6490461826324463
Validation loss: 3.2057966391245523

Epoch: 34| Step: 0
Training loss: 3.4417948722839355
Validation loss: 3.2013206084569297

Epoch: 6| Step: 1
Training loss: 2.6042251586914062
Validation loss: 3.1980594396591187

Epoch: 6| Step: 2
Training loss: 2.1809792518615723
Validation loss: 3.1936525106430054

Epoch: 6| Step: 3
Training loss: 4.579839706420898
Validation loss: 3.1896851460138955

Epoch: 6| Step: 4
Training loss: 2.8900256156921387
Validation loss: 3.186944286028544

Epoch: 6| Step: 5
Training loss: 4.2451066970825195
Validation loss: 3.183892289797465

Epoch: 6| Step: 6
Training loss: 3.3657774925231934
Validation loss: 3.1792385578155518

Epoch: 6| Step: 7
Training loss: 2.933803081512451
Validation loss: 3.1750789086023965

Epoch: 6| Step: 8
Training loss: 4.096160411834717
Validation loss: 3.170897642771403

Epoch: 6| Step: 9
Training loss: 3.6675491333007812
Validation loss: 3.1680806477864585

Epoch: 6| Step: 10
Training loss: 3.4062113761901855
Validation loss: 3.1639825900395713

Epoch: 6| Step: 11
Training loss: 3.6435799598693848
Validation loss: 3.1611124674479165

Epoch: 6| Step: 12
Training loss: 3.1324400901794434
Validation loss: 3.1568930943806968

Epoch: 6| Step: 13
Training loss: 2.87699031829834
Validation loss: 3.1530224879582724

Epoch: 35| Step: 0
Training loss: 3.396714210510254
Validation loss: 3.1494275331497192

Epoch: 6| Step: 1
Training loss: 2.9411582946777344
Validation loss: 3.1454453468322754

Epoch: 6| Step: 2
Training loss: 3.3963170051574707
Validation loss: 3.142029960950216

Epoch: 6| Step: 3
Training loss: 4.104403495788574
Validation loss: 3.138225038846334

Epoch: 6| Step: 4
Training loss: 2.9279215335845947
Validation loss: 3.134609580039978

Epoch: 6| Step: 5
Training loss: 3.618468761444092
Validation loss: 3.1314425468444824

Epoch: 6| Step: 6
Training loss: 3.2656919956207275
Validation loss: 3.1272446314493814

Epoch: 6| Step: 7
Training loss: 3.3967204093933105
Validation loss: 3.123931407928467

Epoch: 6| Step: 8
Training loss: 4.122433662414551
Validation loss: 3.1190272172292075

Epoch: 6| Step: 9
Training loss: 3.051316738128662
Validation loss: 3.114991784095764

Epoch: 6| Step: 10
Training loss: 3.3777036666870117
Validation loss: 3.1125961343447366

Epoch: 6| Step: 11
Training loss: 3.484808921813965
Validation loss: 3.1091227531433105

Epoch: 6| Step: 12
Training loss: 3.1238698959350586
Validation loss: 3.1056282122929892

Epoch: 6| Step: 13
Training loss: 2.15938138961792
Validation loss: 3.101525823275248

Epoch: 36| Step: 0
Training loss: 3.7127718925476074
Validation loss: 3.097071806589762

Epoch: 6| Step: 1
Training loss: 3.0884623527526855
Validation loss: 3.094116508960724

Epoch: 6| Step: 2
Training loss: 3.425337791442871
Validation loss: 3.091460903485616

Epoch: 6| Step: 3
Training loss: 4.189293384552002
Validation loss: 3.087380846341451

Epoch: 6| Step: 4
Training loss: 3.91149640083313
Validation loss: 3.08355184396108

Epoch: 6| Step: 5
Training loss: 3.196134328842163
Validation loss: 3.080224553743998

Epoch: 6| Step: 6
Training loss: 3.0491061210632324
Validation loss: 3.075993299484253

Epoch: 6| Step: 7
Training loss: 3.041203737258911
Validation loss: 3.0730106830596924

Epoch: 6| Step: 8
Training loss: 2.727426290512085
Validation loss: 3.0691590706507363

Epoch: 6| Step: 9
Training loss: 3.1304094791412354
Validation loss: 3.065908193588257

Epoch: 6| Step: 10
Training loss: 2.3450069427490234
Validation loss: 3.062695622444153

Epoch: 6| Step: 11
Training loss: 2.6877198219299316
Validation loss: 3.059634208679199

Epoch: 6| Step: 12
Training loss: 3.9987757205963135
Validation loss: 3.0563398599624634

Epoch: 6| Step: 13
Training loss: 3.2303597927093506
Validation loss: 3.0530124505360923

Epoch: 37| Step: 0
Training loss: 2.8833489418029785
Validation loss: 3.050929228464762

Epoch: 6| Step: 1
Training loss: 2.946413040161133
Validation loss: 3.047317902247111

Epoch: 6| Step: 2
Training loss: 2.6413941383361816
Validation loss: 3.0440806945165

Epoch: 6| Step: 3
Training loss: 3.490957498550415
Validation loss: 3.04016908009847

Epoch: 6| Step: 4
Training loss: 3.206578254699707
Validation loss: 3.0374054511388144

Epoch: 6| Step: 5
Training loss: 2.676546812057495
Validation loss: 3.0343734423319497

Epoch: 6| Step: 6
Training loss: 4.028542518615723
Validation loss: 3.0312275886535645

Epoch: 6| Step: 7
Training loss: 3.0812361240386963
Validation loss: 3.028066396713257

Epoch: 6| Step: 8
Training loss: 3.147334575653076
Validation loss: 3.0247403383255005

Epoch: 6| Step: 9
Training loss: 2.818850040435791
Validation loss: 3.02158792813619

Epoch: 6| Step: 10
Training loss: 3.6362733840942383
Validation loss: 3.0185099045435586

Epoch: 6| Step: 11
Training loss: 3.9461331367492676
Validation loss: 3.0150731801986694

Epoch: 6| Step: 12
Training loss: 3.5027713775634766
Validation loss: 3.012130856513977

Epoch: 6| Step: 13
Training loss: 3.076268196105957
Validation loss: 3.008699138959249

Epoch: 38| Step: 0
Training loss: 3.0667333602905273
Validation loss: 3.0054184993108115

Epoch: 6| Step: 1
Training loss: 2.4558334350585938
Validation loss: 3.002325177192688

Epoch: 6| Step: 2
Training loss: 3.7285356521606445
Validation loss: 2.9990046421686807

Epoch: 6| Step: 3
Training loss: 2.9613587856292725
Validation loss: 2.996037721633911

Epoch: 6| Step: 4
Training loss: 4.427523136138916
Validation loss: 2.9930694897969565

Epoch: 6| Step: 5
Training loss: 2.6594595909118652
Validation loss: 2.989590803782145

Epoch: 6| Step: 6
Training loss: 2.953268527984619
Validation loss: 2.9862323999404907

Epoch: 6| Step: 7
Training loss: 4.052931785583496
Validation loss: 2.9833118120829263

Epoch: 6| Step: 8
Training loss: 2.835559844970703
Validation loss: 2.979288101196289

Epoch: 6| Step: 9
Training loss: 2.9572176933288574
Validation loss: 2.9767598708470664

Epoch: 6| Step: 10
Training loss: 3.336635112762451
Validation loss: 2.973373373349508

Epoch: 6| Step: 11
Training loss: 2.2455484867095947
Validation loss: 2.9684685468673706

Epoch: 6| Step: 12
Training loss: 3.4128198623657227
Validation loss: 2.965831478436788

Epoch: 6| Step: 13
Training loss: 3.4139132499694824
Validation loss: 2.9614827632904053

Epoch: 39| Step: 0
Training loss: 2.6059470176696777
Validation loss: 2.9584107796351113

Epoch: 6| Step: 1
Training loss: 3.0495705604553223
Validation loss: 2.9551915327707925

Epoch: 6| Step: 2
Training loss: 3.1047685146331787
Validation loss: 2.952367623647054

Epoch: 6| Step: 3
Training loss: 3.018766403198242
Validation loss: 2.9507105350494385

Epoch: 6| Step: 4
Training loss: 3.7296218872070312
Validation loss: 2.946638305981954

Epoch: 6| Step: 5
Training loss: 3.0366010665893555
Validation loss: 2.947958469390869

Epoch: 6| Step: 6
Training loss: 3.0387158393859863
Validation loss: 2.9403212467829385

Epoch: 6| Step: 7
Training loss: 2.726977825164795
Validation loss: 2.9388506015141806

Epoch: 6| Step: 8
Training loss: 3.449165105819702
Validation loss: 2.934860348701477

Epoch: 6| Step: 9
Training loss: 3.258929491043091
Validation loss: 2.930481791496277

Epoch: 6| Step: 10
Training loss: 3.0964479446411133
Validation loss: 2.927064140637716

Epoch: 6| Step: 11
Training loss: 2.9958860874176025
Validation loss: 2.924073020617167

Epoch: 6| Step: 12
Training loss: 2.7996416091918945
Validation loss: 2.9215705394744873

Epoch: 6| Step: 13
Training loss: 3.9974544048309326
Validation loss: 2.9201122522354126

Epoch: 40| Step: 0
Training loss: 3.5919370651245117
Validation loss: 2.9156183004379272

Epoch: 6| Step: 1
Training loss: 2.6790592670440674
Validation loss: 2.912438948949178

Epoch: 6| Step: 2
Training loss: 3.6539878845214844
Validation loss: 2.907950480779012

Epoch: 6| Step: 3
Training loss: 3.4637227058410645
Validation loss: 2.905084490776062

Epoch: 6| Step: 4
Training loss: 2.757605791091919
Validation loss: 2.9014419317245483

Epoch: 6| Step: 5
Training loss: 2.3783042430877686
Validation loss: 2.8994988203048706

Epoch: 6| Step: 6
Training loss: 3.56290864944458
Validation loss: 2.905386288960775

Epoch: 6| Step: 7
Training loss: 3.213311195373535
Validation loss: 2.9010352293650308

Epoch: 6| Step: 8
Training loss: 2.8642585277557373
Validation loss: 2.8894875049591064

Epoch: 6| Step: 9
Training loss: 3.0358338356018066
Validation loss: 2.8867481549580893

Epoch: 6| Step: 10
Training loss: 3.4637413024902344
Validation loss: 2.8848434686660767

Epoch: 6| Step: 11
Training loss: 2.933079957962036
Validation loss: 2.8949554363886514

Epoch: 6| Step: 12
Training loss: 2.4299654960632324
Validation loss: 2.9300254583358765

Epoch: 6| Step: 13
Training loss: 3.4697160720825195
Validation loss: 2.8853105306625366

Epoch: 41| Step: 0
Training loss: 2.994419813156128
Validation loss: 2.8751452366511026

Epoch: 6| Step: 1
Training loss: 2.973076343536377
Validation loss: 2.871983607610067

Epoch: 6| Step: 2
Training loss: 2.686882495880127
Validation loss: 2.8689778248469033

Epoch: 6| Step: 3
Training loss: 2.774576187133789
Validation loss: 2.869646668434143

Epoch: 6| Step: 4
Training loss: 3.148062229156494
Validation loss: 2.867638866106669

Epoch: 6| Step: 5
Training loss: 2.8870084285736084
Validation loss: 2.8654768466949463

Epoch: 6| Step: 6
Training loss: 2.775590181350708
Validation loss: 2.8629363775253296

Epoch: 6| Step: 7
Training loss: 3.0748653411865234
Validation loss: 2.8578125834465027

Epoch: 6| Step: 8
Training loss: 3.3023879528045654
Validation loss: 2.8521964947382608

Epoch: 6| Step: 9
Training loss: 3.6784744262695312
Validation loss: 2.849206487337748

Epoch: 6| Step: 10
Training loss: 3.157604217529297
Validation loss: 2.8449252049128213

Epoch: 6| Step: 11
Training loss: 2.8782317638397217
Validation loss: 2.8408567905426025

Epoch: 6| Step: 12
Training loss: 3.1308090686798096
Validation loss: 2.838555653889974

Epoch: 6| Step: 13
Training loss: 3.442084550857544
Validation loss: 2.8356985251108804

Epoch: 42| Step: 0
Training loss: 2.3716182708740234
Validation loss: 2.832512060801188

Epoch: 6| Step: 1
Training loss: 3.38395094871521
Validation loss: 2.8289906978607178

Epoch: 6| Step: 2
Training loss: 3.2055914402008057
Validation loss: 2.8258397976557412

Epoch: 6| Step: 3
Training loss: 2.8806116580963135
Validation loss: 2.82280162970225

Epoch: 6| Step: 4
Training loss: 3.0143113136291504
Validation loss: 2.82031257947286

Epoch: 6| Step: 5
Training loss: 3.72908616065979
Validation loss: 2.8169093132019043

Epoch: 6| Step: 6
Training loss: 2.3576130867004395
Validation loss: 2.8141878048578897

Epoch: 6| Step: 7
Training loss: 2.576009750366211
Validation loss: 2.812408725420634

Epoch: 6| Step: 8
Training loss: 3.537806987762451
Validation loss: 2.8096932967503867

Epoch: 6| Step: 9
Training loss: 3.873323917388916
Validation loss: 2.809128999710083

Epoch: 6| Step: 10
Training loss: 2.4669413566589355
Validation loss: 2.8073469003041587

Epoch: 6| Step: 11
Training loss: 3.09432053565979
Validation loss: 2.8060117959976196

Epoch: 6| Step: 12
Training loss: 3.084152936935425
Validation loss: 2.798666795094808

Epoch: 6| Step: 13
Training loss: 2.7577860355377197
Validation loss: 2.794987519582113

Epoch: 43| Step: 0
Training loss: 2.301966905593872
Validation loss: 2.792517979939779

Epoch: 6| Step: 1
Training loss: 3.1628189086914062
Validation loss: 2.7900107304255166

Epoch: 6| Step: 2
Training loss: 2.933048725128174
Validation loss: 2.786235809326172

Epoch: 6| Step: 3
Training loss: 2.213075637817383
Validation loss: 2.784674644470215

Epoch: 6| Step: 4
Training loss: 2.9857964515686035
Validation loss: 2.7818991343180337

Epoch: 6| Step: 5
Training loss: 2.4766898155212402
Validation loss: 2.7788105408350625

Epoch: 6| Step: 6
Training loss: 3.8706889152526855
Validation loss: 2.7765829960505166

Epoch: 6| Step: 7
Training loss: 2.1314008235931396
Validation loss: 2.7733835776646933

Epoch: 6| Step: 8
Training loss: 3.3503220081329346
Validation loss: 2.7715803384780884

Epoch: 6| Step: 9
Training loss: 3.051267385482788
Validation loss: 2.7688915133476257

Epoch: 6| Step: 10
Training loss: 2.6089234352111816
Validation loss: 2.7682100534439087

Epoch: 6| Step: 11
Training loss: 3.9807686805725098
Validation loss: 2.769911209742228

Epoch: 6| Step: 12
Training loss: 3.50161075592041
Validation loss: 2.7719362576802573

Epoch: 6| Step: 13
Training loss: 3.2024617195129395
Validation loss: 2.7611360947291055

Epoch: 44| Step: 0
Training loss: 2.779730796813965
Validation loss: 2.7554878393809

Epoch: 6| Step: 1
Training loss: 2.698017120361328
Validation loss: 2.7533206144968667

Epoch: 6| Step: 2
Training loss: 3.093484401702881
Validation loss: 2.750834822654724

Epoch: 6| Step: 3
Training loss: 3.137113571166992
Validation loss: 2.7480318546295166

Epoch: 6| Step: 4
Training loss: 2.989452838897705
Validation loss: 2.7449578841527305

Epoch: 6| Step: 5
Training loss: 2.7168471813201904
Validation loss: 2.7428605556488037

Epoch: 6| Step: 6
Training loss: 2.4760208129882812
Validation loss: 2.740039308865865

Epoch: 6| Step: 7
Training loss: 3.230884075164795
Validation loss: 2.736532290776571

Epoch: 6| Step: 8
Training loss: 3.315542221069336
Validation loss: 2.7343002955118814

Epoch: 6| Step: 9
Training loss: 3.3297550678253174
Validation loss: 2.7308634519577026

Epoch: 6| Step: 10
Training loss: 2.4209744930267334
Validation loss: 2.728120962778727

Epoch: 6| Step: 11
Training loss: 3.5574748516082764
Validation loss: 2.7259817520777383

Epoch: 6| Step: 12
Training loss: 1.9447475671768188
Validation loss: 2.7223581075668335

Epoch: 6| Step: 13
Training loss: 3.5649094581604004
Validation loss: 2.7197308341662088

Epoch: 45| Step: 0
Training loss: 3.371603488922119
Validation loss: 2.7162551482518515

Epoch: 6| Step: 1
Training loss: 2.9838156700134277
Validation loss: 2.7146544456481934

Epoch: 6| Step: 2
Training loss: 2.6577858924865723
Validation loss: 2.7117799520492554

Epoch: 6| Step: 3
Training loss: 3.1049816608428955
Validation loss: 2.7093603213628135

Epoch: 6| Step: 4
Training loss: 2.847907304763794
Validation loss: 2.706257144610087

Epoch: 6| Step: 5
Training loss: 2.5242292881011963
Validation loss: 2.7053209145863852

Epoch: 6| Step: 6
Training loss: 2.9276633262634277
Validation loss: 2.6999574502309165

Epoch: 6| Step: 7
Training loss: 3.856536865234375
Validation loss: 2.699230949083964

Epoch: 6| Step: 8
Training loss: 3.0231218338012695
Validation loss: 2.6961487929026284

Epoch: 6| Step: 9
Training loss: 2.729618787765503
Validation loss: 2.6945082346598306

Epoch: 6| Step: 10
Training loss: 3.112029552459717
Validation loss: 2.692288955052694

Epoch: 6| Step: 11
Training loss: 2.733057975769043
Validation loss: 2.686731537183126

Epoch: 6| Step: 12
Training loss: 2.557666063308716
Validation loss: 2.684730648994446

Epoch: 6| Step: 13
Training loss: 2.271998405456543
Validation loss: 2.681060870488485

Epoch: 46| Step: 0
Training loss: 3.2379777431488037
Validation loss: 2.6815250317255654

Epoch: 6| Step: 1
Training loss: 2.1792778968811035
Validation loss: 2.6804842154184976

Epoch: 6| Step: 2
Training loss: 3.090862274169922
Validation loss: 2.6814253330230713

Epoch: 6| Step: 3
Training loss: 2.861706495285034
Validation loss: 2.6857664783795676

Epoch: 6| Step: 4
Training loss: 2.2703428268432617
Validation loss: 2.6952823400497437

Epoch: 6| Step: 5
Training loss: 2.549086570739746
Validation loss: 2.6845417817433677

Epoch: 6| Step: 6
Training loss: 2.8351964950561523
Validation loss: 2.6801635026931763

Epoch: 6| Step: 7
Training loss: 2.8790645599365234
Validation loss: 2.6698827743530273

Epoch: 6| Step: 8
Training loss: 2.9524314403533936
Validation loss: 2.6664320627848306

Epoch: 6| Step: 9
Training loss: 2.889500617980957
Validation loss: 2.661390463511149

Epoch: 6| Step: 10
Training loss: 3.0989551544189453
Validation loss: 2.6555516719818115

Epoch: 6| Step: 11
Training loss: 2.863518714904785
Validation loss: 2.6521048545837402

Epoch: 6| Step: 12
Training loss: 3.7689931392669678
Validation loss: 2.6536823511123657

Epoch: 6| Step: 13
Training loss: 2.7013907432556152
Validation loss: 2.6509007612864175

Epoch: 47| Step: 0
Training loss: 3.2988059520721436
Validation loss: 2.65113095442454

Epoch: 6| Step: 1
Training loss: 3.194206953048706
Validation loss: 2.6451853116353354

Epoch: 6| Step: 2
Training loss: 2.593087673187256
Validation loss: 2.641617695490519

Epoch: 6| Step: 3
Training loss: 2.4601263999938965
Validation loss: 2.6375163793563843

Epoch: 6| Step: 4
Training loss: 2.639953136444092
Validation loss: 2.634334166844686

Epoch: 6| Step: 5
Training loss: 2.8140697479248047
Validation loss: 2.6316071351369223

Epoch: 6| Step: 6
Training loss: 2.06268048286438
Validation loss: 2.628971576690674

Epoch: 6| Step: 7
Training loss: 2.854398250579834
Validation loss: 2.626397212346395

Epoch: 6| Step: 8
Training loss: 2.9802403450012207
Validation loss: 2.622416893641154

Epoch: 6| Step: 9
Training loss: 2.6101691722869873
Validation loss: 2.6190784772237143

Epoch: 6| Step: 10
Training loss: 2.599205493927002
Validation loss: 2.6144933303197226

Epoch: 6| Step: 11
Training loss: 2.7895710468292236
Validation loss: 2.6156086921691895

Epoch: 6| Step: 12
Training loss: 3.7040657997131348
Validation loss: 2.6150728464126587

Epoch: 6| Step: 13
Training loss: 2.976400852203369
Validation loss: 2.6210959752400718

Epoch: 48| Step: 0
Training loss: 2.681429862976074
Validation loss: 2.626301368077596

Epoch: 6| Step: 1
Training loss: 2.8696744441986084
Validation loss: 2.616874615351359

Epoch: 6| Step: 2
Training loss: 2.886821746826172
Validation loss: 2.613619248072306

Epoch: 6| Step: 3
Training loss: 2.9176721572875977
Validation loss: 2.6032079458236694

Epoch: 6| Step: 4
Training loss: 1.9646551609039307
Validation loss: 2.6013400554656982

Epoch: 6| Step: 5
Training loss: 2.7178683280944824
Validation loss: 2.61710532506307

Epoch: 6| Step: 6
Training loss: 2.882713556289673
Validation loss: 2.6354405879974365

Epoch: 6| Step: 7
Training loss: 2.448481559753418
Validation loss: 2.5909714698791504

Epoch: 6| Step: 8
Training loss: 2.5448923110961914
Validation loss: 2.588775118192037

Epoch: 6| Step: 9
Training loss: 3.2354817390441895
Validation loss: 2.587269147237142

Epoch: 6| Step: 10
Training loss: 3.121572971343994
Validation loss: 2.58952001730601

Epoch: 6| Step: 11
Training loss: 2.9571568965911865
Validation loss: 2.6037704944610596

Epoch: 6| Step: 12
Training loss: 3.3677897453308105
Validation loss: 2.6147375106811523

Epoch: 6| Step: 13
Training loss: 2.5273995399475098
Validation loss: 2.6022329727808633

Epoch: 49| Step: 0
Training loss: 3.498983860015869
Validation loss: 2.5885388056437173

Epoch: 6| Step: 1
Training loss: 2.8507261276245117
Validation loss: 2.5728880961736045

Epoch: 6| Step: 2
Training loss: 2.331852436065674
Validation loss: 2.569721738497416

Epoch: 6| Step: 3
Training loss: 2.60455060005188
Validation loss: 2.5659849643707275

Epoch: 6| Step: 4
Training loss: 2.2110447883605957
Validation loss: 2.561814030011495

Epoch: 6| Step: 5
Training loss: 2.6188011169433594
Validation loss: 2.5597490270932517

Epoch: 6| Step: 6
Training loss: 2.8885488510131836
Validation loss: 2.5576948722203574

Epoch: 6| Step: 7
Training loss: 3.0623064041137695
Validation loss: 2.557385245958964

Epoch: 6| Step: 8
Training loss: 3.1487884521484375
Validation loss: 2.555508255958557

Epoch: 6| Step: 9
Training loss: 2.2462730407714844
Validation loss: 2.549989859263102

Epoch: 6| Step: 10
Training loss: 2.966233253479004
Validation loss: 2.5482959747314453

Epoch: 6| Step: 11
Training loss: 3.008575916290283
Validation loss: 2.544214904308319

Epoch: 6| Step: 12
Training loss: 2.9409780502319336
Validation loss: 2.5406184991200766

Epoch: 6| Step: 13
Training loss: 2.2662858963012695
Validation loss: 2.5384188294410706

Epoch: 50| Step: 0
Training loss: 3.0471889972686768
Validation loss: 2.534753600756327

Epoch: 6| Step: 1
Training loss: 2.748913288116455
Validation loss: 2.5316669940948486

Epoch: 6| Step: 2
Training loss: 2.3142056465148926
Validation loss: 2.529494067033132

Epoch: 6| Step: 3
Training loss: 2.4012041091918945
Validation loss: 2.528424064318339

Epoch: 6| Step: 4
Training loss: 2.606076240539551
Validation loss: 2.52438215414683

Epoch: 6| Step: 5
Training loss: 3.0186402797698975
Validation loss: 2.5242254734039307

Epoch: 6| Step: 6
Training loss: 2.9640908241271973
Validation loss: 2.5215532382329306

Epoch: 6| Step: 7
Training loss: 3.3603246212005615
Validation loss: 2.5179096857706704

Epoch: 6| Step: 8
Training loss: 2.074117660522461
Validation loss: 2.5154343843460083

Epoch: 6| Step: 9
Training loss: 2.932302236557007
Validation loss: 2.5138302644093833

Epoch: 6| Step: 10
Training loss: 2.5011203289031982
Validation loss: 2.5081408421198526

Epoch: 6| Step: 11
Training loss: 2.0553388595581055
Validation loss: 2.511374354362488

Epoch: 6| Step: 12
Training loss: 2.919325351715088
Validation loss: 2.5081953605016074

Epoch: 6| Step: 13
Training loss: 3.025485038757324
Validation loss: 2.5059260924657187

Testing loss: 2.123661598713278
