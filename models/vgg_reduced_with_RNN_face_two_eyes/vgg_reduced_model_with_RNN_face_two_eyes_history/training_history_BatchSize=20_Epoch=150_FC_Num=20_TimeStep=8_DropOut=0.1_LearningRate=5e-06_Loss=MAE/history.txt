Epoch: 1| Step: 0
Training loss: 5.487881660461426
Validation loss: 5.229364474614461

Epoch: 5| Step: 1
Training loss: 4.985586643218994
Validation loss: 5.227087755997975

Epoch: 5| Step: 2
Training loss: 4.092925548553467
Validation loss: 5.224857687950134

Epoch: 5| Step: 3
Training loss: 5.381359577178955
Validation loss: 5.2225850621859236

Epoch: 5| Step: 4
Training loss: 5.458348751068115
Validation loss: 5.2204888463020325

Epoch: 5| Step: 5
Training loss: 5.502982139587402
Validation loss: 5.218436499436696

Epoch: 5| Step: 6
Training loss: 5.638357162475586
Validation loss: 5.216375827789307

Epoch: 5| Step: 7
Training loss: 6.072083950042725
Validation loss: 5.214245140552521

Epoch: 5| Step: 8
Training loss: 4.834406852722168
Validation loss: 5.21216603120168

Epoch: 5| Step: 9
Training loss: 6.007230281829834
Validation loss: 5.209888895352681

Epoch: 5| Step: 10
Training loss: 5.03089714050293
Validation loss: 5.207670311133067

Epoch: 5| Step: 11
Training loss: 3.6424734592437744
Validation loss: 5.205334524313609

Epoch: 2| Step: 0
Training loss: 5.676981449127197
Validation loss: 5.203025023142497

Epoch: 5| Step: 1
Training loss: 4.881092071533203
Validation loss: 5.2004004915555315

Epoch: 5| Step: 2
Training loss: 5.228453636169434
Validation loss: 5.19781231880188

Epoch: 5| Step: 3
Training loss: 5.3658342361450195
Validation loss: 5.195219874382019

Epoch: 5| Step: 4
Training loss: 5.126585483551025
Validation loss: 5.192300220330556

Epoch: 5| Step: 5
Training loss: 5.279266357421875
Validation loss: 5.1894612312316895

Epoch: 5| Step: 6
Training loss: 5.133882999420166
Validation loss: 5.186391035715739

Epoch: 5| Step: 7
Training loss: 5.534742832183838
Validation loss: 5.183295746644338

Epoch: 5| Step: 8
Training loss: 5.742061614990234
Validation loss: 5.179756581783295

Epoch: 5| Step: 9
Training loss: 4.490197658538818
Validation loss: 5.176260948181152

Epoch: 5| Step: 10
Training loss: 5.115355014801025
Validation loss: 5.172653992970784

Epoch: 5| Step: 11
Training loss: 6.613766193389893
Validation loss: 5.168526570002238

Epoch: 3| Step: 0
Training loss: 5.485814571380615
Validation loss: 5.164493560791016

Epoch: 5| Step: 1
Training loss: 5.04510498046875
Validation loss: 5.160240928332011

Epoch: 5| Step: 2
Training loss: 5.781501770019531
Validation loss: 5.15569939215978

Epoch: 5| Step: 3
Training loss: 5.414990425109863
Validation loss: 5.151228666305542

Epoch: 5| Step: 4
Training loss: 4.929050445556641
Validation loss: 5.146081646283467

Epoch: 5| Step: 5
Training loss: 5.515681266784668
Validation loss: 5.14081350962321

Epoch: 5| Step: 6
Training loss: 4.40293025970459
Validation loss: 5.1353715260823565

Epoch: 5| Step: 7
Training loss: 5.523186683654785
Validation loss: 5.129840473333995

Epoch: 5| Step: 8
Training loss: 5.304524898529053
Validation loss: 5.123928030331929

Epoch: 5| Step: 9
Training loss: 5.548035144805908
Validation loss: 5.11778849363327

Epoch: 5| Step: 10
Training loss: 4.443592071533203
Validation loss: 5.11123389005661

Epoch: 5| Step: 11
Training loss: 4.857732772827148
Validation loss: 5.104646861553192

Epoch: 4| Step: 0
Training loss: 5.563455104827881
Validation loss: 5.0977727969487505

Epoch: 5| Step: 1
Training loss: 6.092623233795166
Validation loss: 5.090762774149577

Epoch: 5| Step: 2
Training loss: 5.524022579193115
Validation loss: 5.083621879418691

Epoch: 5| Step: 3
Training loss: 5.019016742706299
Validation loss: 5.0758103132247925

Epoch: 5| Step: 4
Training loss: 5.06369686126709
Validation loss: 5.06820285320282

Epoch: 5| Step: 5
Training loss: 4.209604740142822
Validation loss: 5.060131977001826

Epoch: 5| Step: 6
Training loss: 4.660636901855469
Validation loss: 5.052227795124054

Epoch: 5| Step: 7
Training loss: 4.022587776184082
Validation loss: 5.043931702772777

Epoch: 5| Step: 8
Training loss: 5.3283562660217285
Validation loss: 5.035551428794861

Epoch: 5| Step: 9
Training loss: 5.356600761413574
Validation loss: 5.027794460455577

Epoch: 5| Step: 10
Training loss: 5.57880163192749
Validation loss: 5.018951376279195

Epoch: 5| Step: 11
Training loss: 5.472395896911621
Validation loss: 5.0102914571762085

Epoch: 5| Step: 0
Training loss: 5.446465492248535
Validation loss: 5.001795371373494

Epoch: 5| Step: 1
Training loss: 4.81325626373291
Validation loss: 4.993179718653361

Epoch: 5| Step: 2
Training loss: 3.9978058338165283
Validation loss: 4.984641472498576

Epoch: 5| Step: 3
Training loss: 5.628140926361084
Validation loss: 4.9754810730616255

Epoch: 5| Step: 4
Training loss: 4.800250053405762
Validation loss: 4.9668481548627215

Epoch: 5| Step: 5
Training loss: 5.717355251312256
Validation loss: 4.958149830500285

Epoch: 5| Step: 6
Training loss: 6.267526626586914
Validation loss: 4.949307759602864

Epoch: 5| Step: 7
Training loss: 4.747652530670166
Validation loss: 4.940659880638123

Epoch: 5| Step: 8
Training loss: 4.362146854400635
Validation loss: 4.931891620159149

Epoch: 5| Step: 9
Training loss: 5.350778579711914
Validation loss: 4.923082013924916

Epoch: 5| Step: 10
Training loss: 4.496722221374512
Validation loss: 4.91446711619695

Epoch: 5| Step: 11
Training loss: 4.115577697753906
Validation loss: 4.905752976735433

Epoch: 6| Step: 0
Training loss: 4.731637001037598
Validation loss: 4.897211770216624

Epoch: 5| Step: 1
Training loss: 4.992251396179199
Validation loss: 4.888261536757152

Epoch: 5| Step: 2
Training loss: 4.805863857269287
Validation loss: 4.879410564899445

Epoch: 5| Step: 3
Training loss: 4.886152744293213
Validation loss: 4.870554059743881

Epoch: 5| Step: 4
Training loss: 4.455991268157959
Validation loss: 4.861732244491577

Epoch: 5| Step: 5
Training loss: 4.624769687652588
Validation loss: 4.852834602197011

Epoch: 5| Step: 6
Training loss: 5.419405460357666
Validation loss: 4.843333164850871

Epoch: 5| Step: 7
Training loss: 4.90883207321167
Validation loss: 4.834893703460693

Epoch: 5| Step: 8
Training loss: 4.683533668518066
Validation loss: 4.826201140880585

Epoch: 5| Step: 9
Training loss: 5.167372703552246
Validation loss: 4.817491392294566

Epoch: 5| Step: 10
Training loss: 5.31690788269043
Validation loss: 4.809129476547241

Epoch: 5| Step: 11
Training loss: 6.639131546020508
Validation loss: 4.800360600153605

Epoch: 7| Step: 0
Training loss: 3.211782932281494
Validation loss: 4.7916414340337115

Epoch: 5| Step: 1
Training loss: 4.872936248779297
Validation loss: 4.783498068650563

Epoch: 5| Step: 2
Training loss: 5.269460201263428
Validation loss: 4.774919191996257

Epoch: 5| Step: 3
Training loss: 4.548806190490723
Validation loss: 4.766538639863332

Epoch: 5| Step: 4
Training loss: 5.701452255249023
Validation loss: 4.757844050725301

Epoch: 5| Step: 5
Training loss: 4.887737274169922
Validation loss: 4.749638736248016

Epoch: 5| Step: 6
Training loss: 4.721192836761475
Validation loss: 4.741488933563232

Epoch: 5| Step: 7
Training loss: 4.346571445465088
Validation loss: 4.732983410358429

Epoch: 5| Step: 8
Training loss: 5.8370161056518555
Validation loss: 4.7243490020434065

Epoch: 5| Step: 9
Training loss: 5.7171831130981445
Validation loss: 4.716349144776662

Epoch: 5| Step: 10
Training loss: 4.467221736907959
Validation loss: 4.708569119373958

Epoch: 5| Step: 11
Training loss: 3.138815402984619
Validation loss: 4.700576047102611

Epoch: 8| Step: 0
Training loss: 5.507375717163086
Validation loss: 4.69245704015096

Epoch: 5| Step: 1
Training loss: 4.8316650390625
Validation loss: 4.684309909741084

Epoch: 5| Step: 2
Training loss: 3.925931453704834
Validation loss: 4.6765925486882525

Epoch: 5| Step: 3
Training loss: 5.084070205688477
Validation loss: 4.668779631455739

Epoch: 5| Step: 4
Training loss: 5.009182929992676
Validation loss: 4.660682559013367

Epoch: 5| Step: 5
Training loss: 4.46307373046875
Validation loss: 4.652635504802068

Epoch: 5| Step: 6
Training loss: 4.833701133728027
Validation loss: 4.643687844276428

Epoch: 5| Step: 7
Training loss: 4.428292274475098
Validation loss: 4.634055932362874

Epoch: 5| Step: 8
Training loss: 4.27963924407959
Validation loss: 4.622750550508499

Epoch: 5| Step: 9
Training loss: 4.701974391937256
Validation loss: 4.608788549900055

Epoch: 5| Step: 10
Training loss: 4.72609806060791
Validation loss: 4.597923268874486

Epoch: 5| Step: 11
Training loss: 6.77525520324707
Validation loss: 4.5887550214926405

Epoch: 9| Step: 0
Training loss: 5.40947961807251
Validation loss: 4.580356578032176

Epoch: 5| Step: 1
Training loss: 4.316424369812012
Validation loss: 4.572315206130345

Epoch: 5| Step: 2
Training loss: 4.900616645812988
Validation loss: 4.564130822817485

Epoch: 5| Step: 3
Training loss: 4.125662803649902
Validation loss: 4.556833465894063

Epoch: 5| Step: 4
Training loss: 5.1220855712890625
Validation loss: 4.549574136734009

Epoch: 5| Step: 5
Training loss: 4.477005958557129
Validation loss: 4.542238612969716

Epoch: 5| Step: 6
Training loss: 3.33839750289917
Validation loss: 4.534842034180959

Epoch: 5| Step: 7
Training loss: 5.1689066886901855
Validation loss: 4.52783461411794

Epoch: 5| Step: 8
Training loss: 3.5591721534729004
Validation loss: 4.520321011543274

Epoch: 5| Step: 9
Training loss: 5.307270050048828
Validation loss: 4.513068477312724

Epoch: 5| Step: 10
Training loss: 5.241534233093262
Validation loss: 4.505658229192098

Epoch: 5| Step: 11
Training loss: 5.305832862854004
Validation loss: 4.498937666416168

Epoch: 10| Step: 0
Training loss: 4.267060279846191
Validation loss: 4.492208421230316

Epoch: 5| Step: 1
Training loss: 5.314000606536865
Validation loss: 4.485719621181488

Epoch: 5| Step: 2
Training loss: 5.057253837585449
Validation loss: 4.479588637749354

Epoch: 5| Step: 3
Training loss: 5.217164516448975
Validation loss: 4.473428209622701

Epoch: 5| Step: 4
Training loss: 3.8159546852111816
Validation loss: 4.467436611652374

Epoch: 5| Step: 5
Training loss: 4.205083847045898
Validation loss: 4.4613110323747

Epoch: 5| Step: 6
Training loss: 4.912414073944092
Validation loss: 4.455059538284938

Epoch: 5| Step: 7
Training loss: 4.831270694732666
Validation loss: 4.448966304461162

Epoch: 5| Step: 8
Training loss: 3.5302634239196777
Validation loss: 4.4431154529253645

Epoch: 5| Step: 9
Training loss: 3.9277424812316895
Validation loss: 4.437261650959651

Epoch: 5| Step: 10
Training loss: 4.833924293518066
Validation loss: 4.431397438049316

Epoch: 5| Step: 11
Training loss: 6.563819885253906
Validation loss: 4.4261368115743

Epoch: 11| Step: 0
Training loss: 5.188645362854004
Validation loss: 4.420539279778798

Epoch: 5| Step: 1
Training loss: 4.184548854827881
Validation loss: 4.415055324633916

Epoch: 5| Step: 2
Training loss: 3.7623000144958496
Validation loss: 4.409807562828064

Epoch: 5| Step: 3
Training loss: 5.675988674163818
Validation loss: 4.405037581920624

Epoch: 5| Step: 4
Training loss: 4.580502986907959
Validation loss: 4.399778763453166

Epoch: 5| Step: 5
Training loss: 4.440604209899902
Validation loss: 4.394475281238556

Epoch: 5| Step: 6
Training loss: 4.671502590179443
Validation loss: 4.389413336912791

Epoch: 5| Step: 7
Training loss: 4.589690208435059
Validation loss: 4.384283781051636

Epoch: 5| Step: 8
Training loss: 4.278323173522949
Validation loss: 4.379089951515198

Epoch: 5| Step: 9
Training loss: 3.9667587280273438
Validation loss: 4.3738439083099365

Epoch: 5| Step: 10
Training loss: 4.205492973327637
Validation loss: 4.368697126706441

Epoch: 5| Step: 11
Training loss: 4.9463653564453125
Validation loss: 4.363499015569687

Epoch: 12| Step: 0
Training loss: 4.3299126625061035
Validation loss: 4.3581258952617645

Epoch: 5| Step: 1
Training loss: 4.034069061279297
Validation loss: 4.352709839741389

Epoch: 5| Step: 2
Training loss: 3.5149528980255127
Validation loss: 4.347264518340428

Epoch: 5| Step: 3
Training loss: 5.18781042098999
Validation loss: 4.341982066631317

Epoch: 5| Step: 4
Training loss: 3.9951300621032715
Validation loss: 4.336542516946793

Epoch: 5| Step: 5
Training loss: 5.004940986633301
Validation loss: 4.3314604957898455

Epoch: 5| Step: 6
Training loss: 5.611933708190918
Validation loss: 4.32575457294782

Epoch: 5| Step: 7
Training loss: 4.099963188171387
Validation loss: 4.3202024102211

Epoch: 5| Step: 8
Training loss: 3.750856399536133
Validation loss: 4.314529409011205

Epoch: 5| Step: 9
Training loss: 5.1168999671936035
Validation loss: 4.308858851591746

Epoch: 5| Step: 10
Training loss: 4.470207214355469
Validation loss: 4.303566753864288

Epoch: 5| Step: 11
Training loss: 3.8719208240509033
Validation loss: 4.298407514890035

Epoch: 13| Step: 0
Training loss: 4.309657096862793
Validation loss: 4.293748239676158

Epoch: 5| Step: 1
Training loss: 4.858626842498779
Validation loss: 4.288026442130406

Epoch: 5| Step: 2
Training loss: 4.642683506011963
Validation loss: 4.282696108023326

Epoch: 5| Step: 3
Training loss: 4.405219554901123
Validation loss: 4.2773377597332

Epoch: 5| Step: 4
Training loss: 4.511704444885254
Validation loss: 4.2723812858263654

Epoch: 5| Step: 5
Training loss: 4.046034812927246
Validation loss: 4.266438225905101

Epoch: 5| Step: 6
Training loss: 4.464369773864746
Validation loss: 4.261107871929805

Epoch: 5| Step: 7
Training loss: 4.247309684753418
Validation loss: 4.256407340367635

Epoch: 5| Step: 8
Training loss: 4.379582405090332
Validation loss: 4.251722653706868

Epoch: 5| Step: 9
Training loss: 4.625312805175781
Validation loss: 4.246780316034953

Epoch: 5| Step: 10
Training loss: 3.881308078765869
Validation loss: 4.240670283635457

Epoch: 5| Step: 11
Training loss: 4.2064433097839355
Validation loss: 4.234967688719432

Epoch: 14| Step: 0
Training loss: 4.42197322845459
Validation loss: 4.230064660310745

Epoch: 5| Step: 1
Training loss: 4.796161651611328
Validation loss: 4.2251379787921906

Epoch: 5| Step: 2
Training loss: 4.1745405197143555
Validation loss: 4.21952149271965

Epoch: 5| Step: 3
Training loss: 4.130461692810059
Validation loss: 4.213845123847325

Epoch: 5| Step: 4
Training loss: 5.119955539703369
Validation loss: 4.208196073770523

Epoch: 5| Step: 5
Training loss: 4.045001029968262
Validation loss: 4.203383555014928

Epoch: 5| Step: 6
Training loss: 4.056408882141113
Validation loss: 4.198232928911845

Epoch: 5| Step: 7
Training loss: 4.653972148895264
Validation loss: 4.192582716544469

Epoch: 5| Step: 8
Training loss: 4.114447593688965
Validation loss: 4.187397072712581

Epoch: 5| Step: 9
Training loss: 4.76682710647583
Validation loss: 4.183143864075343

Epoch: 5| Step: 10
Training loss: 3.3894448280334473
Validation loss: 4.177966773509979

Epoch: 5| Step: 11
Training loss: 4.478551864624023
Validation loss: 4.172319213549296

Epoch: 15| Step: 0
Training loss: 4.720992088317871
Validation loss: 4.1687659819920855

Epoch: 5| Step: 1
Training loss: 4.4018707275390625
Validation loss: 4.164729058742523

Epoch: 5| Step: 2
Training loss: 4.746814727783203
Validation loss: 4.158607999483745

Epoch: 5| Step: 3
Training loss: 4.0632853507995605
Validation loss: 4.15267738699913

Epoch: 5| Step: 4
Training loss: 4.380067348480225
Validation loss: 4.147894183794658

Epoch: 5| Step: 5
Training loss: 3.7101149559020996
Validation loss: 4.143896599610646

Epoch: 5| Step: 6
Training loss: 4.290896892547607
Validation loss: 4.143130193154017

Epoch: 5| Step: 7
Training loss: 4.636087894439697
Validation loss: 4.133451739947001

Epoch: 5| Step: 8
Training loss: 4.049799919128418
Validation loss: 4.130659917990367

Epoch: 5| Step: 9
Training loss: 3.8818199634552
Validation loss: 4.127509613831838

Epoch: 5| Step: 10
Training loss: 4.447012424468994
Validation loss: 4.12389341990153

Epoch: 5| Step: 11
Training loss: 3.1312201023101807
Validation loss: 4.118178288141887

Epoch: 16| Step: 0
Training loss: 3.464296340942383
Validation loss: 4.111583888530731

Epoch: 5| Step: 1
Training loss: 4.306775093078613
Validation loss: 4.105163464943568

Epoch: 5| Step: 2
Training loss: 4.427294731140137
Validation loss: 4.100154300530751

Epoch: 5| Step: 3
Training loss: 4.158656120300293
Validation loss: 4.097184171279271

Epoch: 5| Step: 4
Training loss: 4.534135341644287
Validation loss: 4.093373318513234

Epoch: 5| Step: 5
Training loss: 4.611122131347656
Validation loss: 4.084848721822103

Epoch: 5| Step: 6
Training loss: 4.339719772338867
Validation loss: 4.080402284860611

Epoch: 5| Step: 7
Training loss: 4.121369361877441
Validation loss: 4.075193365414937

Epoch: 5| Step: 8
Training loss: 3.9095020294189453
Validation loss: 4.069639633099238

Epoch: 5| Step: 9
Training loss: 4.041571140289307
Validation loss: 4.0657378534475965

Epoch: 5| Step: 10
Training loss: 4.070125102996826
Validation loss: 4.060904602209727

Epoch: 5| Step: 11
Training loss: 6.836957931518555
Validation loss: 4.056275775035222

Epoch: 17| Step: 0
Training loss: 4.3690385818481445
Validation loss: 4.052036980787913

Epoch: 5| Step: 1
Training loss: 4.407729148864746
Validation loss: 4.047537515560786

Epoch: 5| Step: 2
Training loss: 4.187930583953857
Validation loss: 4.0424425303936005

Epoch: 5| Step: 3
Training loss: 4.078338146209717
Validation loss: 4.037827283143997

Epoch: 5| Step: 4
Training loss: 3.7850589752197266
Validation loss: 4.033067544301351

Epoch: 5| Step: 5
Training loss: 4.779616355895996
Validation loss: 4.027916630109151

Epoch: 5| Step: 6
Training loss: 3.735823154449463
Validation loss: 4.024186760187149

Epoch: 5| Step: 7
Training loss: 3.7656192779541016
Validation loss: 4.019067356983821

Epoch: 5| Step: 8
Training loss: 4.187577247619629
Validation loss: 4.0137786368529005

Epoch: 5| Step: 9
Training loss: 4.457810401916504
Validation loss: 4.009358257055283

Epoch: 5| Step: 10
Training loss: 4.279616355895996
Validation loss: 4.005052665869395

Epoch: 5| Step: 11
Training loss: 3.4744036197662354
Validation loss: 4.000753392775853

Epoch: 18| Step: 0
Training loss: 3.4194939136505127
Validation loss: 3.9974739452203116

Epoch: 5| Step: 1
Training loss: 4.7462968826293945
Validation loss: 3.9933427770932517

Epoch: 5| Step: 2
Training loss: 3.8774189949035645
Validation loss: 3.988961031039556

Epoch: 5| Step: 3
Training loss: 4.056800842285156
Validation loss: 3.9861013889312744

Epoch: 5| Step: 4
Training loss: 3.8439927101135254
Validation loss: 3.9791176418463388

Epoch: 5| Step: 5
Training loss: 4.3012824058532715
Validation loss: 3.977371553579966

Epoch: 5| Step: 6
Training loss: 4.225277900695801
Validation loss: 3.9759940604368844

Epoch: 5| Step: 7
Training loss: 4.2066731452941895
Validation loss: 3.971662402153015

Epoch: 5| Step: 8
Training loss: 3.9424991607666016
Validation loss: 3.964677562316259

Epoch: 5| Step: 9
Training loss: 4.264273166656494
Validation loss: 3.959427406390508

Epoch: 5| Step: 10
Training loss: 4.455226898193359
Validation loss: 3.9536582628885903

Epoch: 5| Step: 11
Training loss: 4.148480415344238
Validation loss: 3.948083132505417

Epoch: 19| Step: 0
Training loss: 3.9526500701904297
Validation loss: 3.9426931738853455

Epoch: 5| Step: 1
Training loss: 4.6212334632873535
Validation loss: 3.9386260509490967

Epoch: 5| Step: 2
Training loss: 4.674469947814941
Validation loss: 3.9353545208772025

Epoch: 5| Step: 3
Training loss: 4.043200492858887
Validation loss: 3.9282272855440774

Epoch: 5| Step: 4
Training loss: 3.501512050628662
Validation loss: 3.923827608426412

Epoch: 5| Step: 5
Training loss: 2.8450608253479004
Validation loss: 3.920276681582133

Epoch: 5| Step: 6
Training loss: 4.477651119232178
Validation loss: 3.9166253109773

Epoch: 5| Step: 7
Training loss: 4.903006553649902
Validation loss: 3.9123198787371316

Epoch: 5| Step: 8
Training loss: 4.393376350402832
Validation loss: 3.907762289047241

Epoch: 5| Step: 9
Training loss: 3.6191399097442627
Validation loss: 3.9032084743181863

Epoch: 5| Step: 10
Training loss: 3.706164598464966
Validation loss: 3.8974519073963165

Epoch: 5| Step: 11
Training loss: 4.215882301330566
Validation loss: 3.8916443983713784

Epoch: 20| Step: 0
Training loss: 3.840569257736206
Validation loss: 3.887057989835739

Epoch: 5| Step: 1
Training loss: 3.3387420177459717
Validation loss: 3.8826829691727958

Epoch: 5| Step: 2
Training loss: 4.26865291595459
Validation loss: 3.8812183141708374

Epoch: 5| Step: 3
Training loss: 4.312795162200928
Validation loss: 3.8764564792315164

Epoch: 5| Step: 4
Training loss: 4.303231716156006
Validation loss: 3.8696201046307883

Epoch: 5| Step: 5
Training loss: 5.031837463378906
Validation loss: 3.8651209076245627

Epoch: 5| Step: 6
Training loss: 4.1749773025512695
Validation loss: 3.861425240834554

Epoch: 5| Step: 7
Training loss: 3.4670510292053223
Validation loss: 3.857092489798864

Epoch: 5| Step: 8
Training loss: 4.427722930908203
Validation loss: 3.8527623116970062

Epoch: 5| Step: 9
Training loss: 3.186917543411255
Validation loss: 3.8479276398817697

Epoch: 5| Step: 10
Training loss: 3.8518226146698
Validation loss: 3.8434354861577353

Epoch: 5| Step: 11
Training loss: 3.9234142303466797
Validation loss: 3.8386313716570535

Epoch: 21| Step: 0
Training loss: 4.088296413421631
Validation loss: 3.8338878055413566

Epoch: 5| Step: 1
Training loss: 4.323151588439941
Validation loss: 3.829482982556025

Epoch: 5| Step: 2
Training loss: 4.2348809242248535
Validation loss: 3.8254296580950418

Epoch: 5| Step: 3
Training loss: 4.017258167266846
Validation loss: 3.819719801346461

Epoch: 5| Step: 4
Training loss: 3.9203171730041504
Validation loss: 3.8158546686172485

Epoch: 5| Step: 5
Training loss: 3.7585983276367188
Validation loss: 3.811784287293752

Epoch: 5| Step: 6
Training loss: 3.521071195602417
Validation loss: 3.8081717093785605

Epoch: 5| Step: 7
Training loss: 4.206002235412598
Validation loss: 3.803933093945185

Epoch: 5| Step: 8
Training loss: 3.419268846511841
Validation loss: 3.7995521426200867

Epoch: 5| Step: 9
Training loss: 3.428769588470459
Validation loss: 3.7946190237998962

Epoch: 5| Step: 10
Training loss: 4.412910461425781
Validation loss: 3.7899613777796426

Epoch: 5| Step: 11
Training loss: 5.527736186981201
Validation loss: 3.7845053474108377

Epoch: 22| Step: 0
Training loss: 4.040661811828613
Validation loss: 3.7801305254300437

Epoch: 5| Step: 1
Training loss: 3.941336154937744
Validation loss: 3.7761615018049874

Epoch: 5| Step: 2
Training loss: 4.399909973144531
Validation loss: 3.7721497217814126

Epoch: 5| Step: 3
Training loss: 3.7155158519744873
Validation loss: 3.767737497886022

Epoch: 5| Step: 4
Training loss: 3.9059653282165527
Validation loss: 3.761889030536016

Epoch: 5| Step: 5
Training loss: 3.7276992797851562
Validation loss: 3.7573677400747933

Epoch: 5| Step: 6
Training loss: 3.1050658226013184
Validation loss: 3.752811372280121

Epoch: 5| Step: 7
Training loss: 3.100071430206299
Validation loss: 3.748802920182546

Epoch: 5| Step: 8
Training loss: 4.868055820465088
Validation loss: 3.743859122196833

Epoch: 5| Step: 9
Training loss: 4.67717170715332
Validation loss: 3.739247759183248

Epoch: 5| Step: 10
Training loss: 3.2889227867126465
Validation loss: 3.734862665335337

Epoch: 5| Step: 11
Training loss: 5.419480323791504
Validation loss: 3.73097617427508

Epoch: 23| Step: 0
Training loss: 4.518463611602783
Validation loss: 3.7269365588823953

Epoch: 5| Step: 1
Training loss: 4.030007362365723
Validation loss: 3.721816301345825

Epoch: 5| Step: 2
Training loss: 3.5454909801483154
Validation loss: 3.7175014913082123

Epoch: 5| Step: 3
Training loss: 3.9321541786193848
Validation loss: 3.7130216161410012

Epoch: 5| Step: 4
Training loss: 4.350178241729736
Validation loss: 3.708025942246119

Epoch: 5| Step: 5
Training loss: 4.107089042663574
Validation loss: 3.703573743502299

Epoch: 5| Step: 6
Training loss: 4.248902797698975
Validation loss: 3.699224352836609

Epoch: 5| Step: 7
Training loss: 2.6256346702575684
Validation loss: 3.695780704418818

Epoch: 5| Step: 8
Training loss: 3.630084276199341
Validation loss: 3.6908708413441977

Epoch: 5| Step: 9
Training loss: 4.189958572387695
Validation loss: 3.6867620944976807

Epoch: 5| Step: 10
Training loss: 3.4665863513946533
Validation loss: 3.6824023524920144

Epoch: 5| Step: 11
Training loss: 3.2187628746032715
Validation loss: 3.677632302045822

Epoch: 24| Step: 0
Training loss: 3.5659098625183105
Validation loss: 3.6738835175832114

Epoch: 5| Step: 1
Training loss: 4.381121635437012
Validation loss: 3.671550234158834

Epoch: 5| Step: 2
Training loss: 4.201123237609863
Validation loss: 3.6657118101914725

Epoch: 5| Step: 3
Training loss: 4.241304874420166
Validation loss: 3.6615463693936667

Epoch: 5| Step: 4
Training loss: 4.364317893981934
Validation loss: 3.6573340396086373

Epoch: 5| Step: 5
Training loss: 3.6176483631134033
Validation loss: 3.652899295091629

Epoch: 5| Step: 6
Training loss: 3.0363032817840576
Validation loss: 3.6489982306957245

Epoch: 5| Step: 7
Training loss: 3.267981767654419
Validation loss: 3.6443607608477273

Epoch: 5| Step: 8
Training loss: 3.676842451095581
Validation loss: 3.6402398546536765

Epoch: 5| Step: 9
Training loss: 4.2212066650390625
Validation loss: 3.635934670766195

Epoch: 5| Step: 10
Training loss: 3.446977138519287
Validation loss: 3.631728013356527

Epoch: 5| Step: 11
Training loss: 3.5987424850463867
Validation loss: 3.6275949577490487

Epoch: 25| Step: 0
Training loss: 4.535431861877441
Validation loss: 3.6292907992998757

Epoch: 5| Step: 1
Training loss: 3.977526903152466
Validation loss: 3.6212298770745597

Epoch: 5| Step: 2
Training loss: 3.875936985015869
Validation loss: 3.6153995394706726

Epoch: 5| Step: 3
Training loss: 4.427300453186035
Validation loss: 3.612421303987503

Epoch: 5| Step: 4
Training loss: 3.1570026874542236
Validation loss: 3.6094599664211273

Epoch: 5| Step: 5
Training loss: 3.5851356983184814
Validation loss: 3.6052351593971252

Epoch: 5| Step: 6
Training loss: 4.358586311340332
Validation loss: 3.6004017889499664

Epoch: 5| Step: 7
Training loss: 2.7645764350891113
Validation loss: 3.5967815617720285

Epoch: 5| Step: 8
Training loss: 2.841839551925659
Validation loss: 3.5926221311092377

Epoch: 5| Step: 9
Training loss: 4.0055623054504395
Validation loss: 3.5879895289738974

Epoch: 5| Step: 10
Training loss: 3.698080062866211
Validation loss: 3.5836252570152283

Epoch: 5| Step: 11
Training loss: 4.938767433166504
Validation loss: 3.5790100594361625

Epoch: 26| Step: 0
Training loss: 4.234401702880859
Validation loss: 3.574713150660197

Epoch: 5| Step: 1
Training loss: 3.257617473602295
Validation loss: 3.57043128212293

Epoch: 5| Step: 2
Training loss: 4.256102561950684
Validation loss: 3.5674097339312234

Epoch: 5| Step: 3
Training loss: 3.6267189979553223
Validation loss: 3.560737977425257

Epoch: 5| Step: 4
Training loss: 4.750463008880615
Validation loss: 3.5558196802934012

Epoch: 5| Step: 5
Training loss: 3.2012081146240234
Validation loss: 3.551176925500234

Epoch: 5| Step: 6
Training loss: 3.193507194519043
Validation loss: 3.54781374335289

Epoch: 5| Step: 7
Training loss: 3.8294429779052734
Validation loss: 3.5451353589693704

Epoch: 5| Step: 8
Training loss: 3.7488338947296143
Validation loss: 3.539685239394506

Epoch: 5| Step: 9
Training loss: 2.9683218002319336
Validation loss: 3.5356158514817557

Epoch: 5| Step: 10
Training loss: 3.9445037841796875
Validation loss: 3.530631403128306

Epoch: 5| Step: 11
Training loss: 3.1350960731506348
Validation loss: 3.525417993466059

Epoch: 27| Step: 0
Training loss: 3.5112624168395996
Validation loss: 3.5210340917110443

Epoch: 5| Step: 1
Training loss: 4.151032447814941
Validation loss: 3.51614573597908

Epoch: 5| Step: 2
Training loss: 3.889625072479248
Validation loss: 3.5126595199108124

Epoch: 5| Step: 3
Training loss: 3.1433825492858887
Validation loss: 3.5080651144186654

Epoch: 5| Step: 4
Training loss: 3.620180606842041
Validation loss: 3.5042965610822043

Epoch: 5| Step: 5
Training loss: 4.067910194396973
Validation loss: 3.499654899040858

Epoch: 5| Step: 6
Training loss: 3.8597254753112793
Validation loss: 3.494362066189448

Epoch: 5| Step: 7
Training loss: 4.012879371643066
Validation loss: 3.49093034863472

Epoch: 5| Step: 8
Training loss: 3.5437724590301514
Validation loss: 3.487048178911209

Epoch: 5| Step: 9
Training loss: 3.15358304977417
Validation loss: 3.483213245868683

Epoch: 5| Step: 10
Training loss: 3.260890245437622
Validation loss: 3.479198634624481

Epoch: 5| Step: 11
Training loss: 4.240151882171631
Validation loss: 3.474232425292333

Epoch: 28| Step: 0
Training loss: 3.276463270187378
Validation loss: 3.469607005516688

Epoch: 5| Step: 1
Training loss: 3.4079976081848145
Validation loss: 3.4647218684355416

Epoch: 5| Step: 2
Training loss: 3.9494712352752686
Validation loss: 3.4596461057662964

Epoch: 5| Step: 3
Training loss: 3.0968379974365234
Validation loss: 3.4549484650293985

Epoch: 5| Step: 4
Training loss: 4.23382043838501
Validation loss: 3.450531472762426

Epoch: 5| Step: 5
Training loss: 3.9580159187316895
Validation loss: 3.4463493128617606

Epoch: 5| Step: 6
Training loss: 3.2513298988342285
Validation loss: 3.4421586294968924

Epoch: 5| Step: 7
Training loss: 3.0955963134765625
Validation loss: 3.437954694032669

Epoch: 5| Step: 8
Training loss: 4.062167167663574
Validation loss: 3.4337319334348044

Epoch: 5| Step: 9
Training loss: 3.8353347778320312
Validation loss: 3.42893186211586

Epoch: 5| Step: 10
Training loss: 3.2968602180480957
Validation loss: 3.424214859803518

Epoch: 5| Step: 11
Training loss: 4.941100120544434
Validation loss: 3.419553836186727

Epoch: 29| Step: 0
Training loss: 3.787487745285034
Validation loss: 3.416852037111918

Epoch: 5| Step: 1
Training loss: 2.289066791534424
Validation loss: 3.413939525683721

Epoch: 5| Step: 2
Training loss: 3.512202739715576
Validation loss: 3.414198805888494

Epoch: 5| Step: 3
Training loss: 3.814662456512451
Validation loss: 3.4083441396554313

Epoch: 5| Step: 4
Training loss: 4.0063066482543945
Validation loss: 3.404604434967041

Epoch: 5| Step: 5
Training loss: 3.1518211364746094
Validation loss: 3.398270140091578

Epoch: 5| Step: 6
Training loss: 3.602843761444092
Validation loss: 3.3926444550355277

Epoch: 5| Step: 7
Training loss: 4.191789627075195
Validation loss: 3.387335499127706

Epoch: 5| Step: 8
Training loss: 3.098398208618164
Validation loss: 3.3820369243621826

Epoch: 5| Step: 9
Training loss: 4.131543159484863
Validation loss: 3.3777612348397574

Epoch: 5| Step: 10
Training loss: 3.4256668090820312
Validation loss: 3.3749312460422516

Epoch: 5| Step: 11
Training loss: 4.646763324737549
Validation loss: 3.3689777553081512

Epoch: 30| Step: 0
Training loss: 3.3543410301208496
Validation loss: 3.3651623328526816

Epoch: 5| Step: 1
Training loss: 3.614422559738159
Validation loss: 3.36010334889094

Epoch: 5| Step: 2
Training loss: 3.769535541534424
Validation loss: 3.355256368716558

Epoch: 5| Step: 3
Training loss: 3.0390145778656006
Validation loss: 3.3509873747825623

Epoch: 5| Step: 4
Training loss: 3.37949800491333
Validation loss: 3.3458194037278495

Epoch: 5| Step: 5
Training loss: 3.4631829261779785
Validation loss: 3.3418429295221963

Epoch: 5| Step: 6
Training loss: 3.5061957836151123
Validation loss: 3.3368744452794394

Epoch: 5| Step: 7
Training loss: 3.846359968185425
Validation loss: 3.3323812186717987

Epoch: 5| Step: 8
Training loss: 3.4378063678741455
Validation loss: 3.3280994296073914

Epoch: 5| Step: 9
Training loss: 3.1250665187835693
Validation loss: 3.323554039001465

Epoch: 5| Step: 10
Training loss: 3.850820541381836
Validation loss: 3.319235513607661

Epoch: 5| Step: 11
Training loss: 4.741922378540039
Validation loss: 3.315131733814875

Epoch: 31| Step: 0
Training loss: 3.1591074466705322
Validation loss: 3.3096475899219513

Epoch: 5| Step: 1
Training loss: 3.605653762817383
Validation loss: 3.304549366235733

Epoch: 5| Step: 2
Training loss: 3.115884304046631
Validation loss: 3.2994642655054727

Epoch: 5| Step: 3
Training loss: 2.93440580368042
Validation loss: 3.294449200232824

Epoch: 5| Step: 4
Training loss: 3.433368682861328
Validation loss: 3.2904193997383118

Epoch: 5| Step: 5
Training loss: 4.164613723754883
Validation loss: 3.2865545749664307

Epoch: 5| Step: 6
Training loss: 3.3873016834259033
Validation loss: 3.281427522500356

Epoch: 5| Step: 7
Training loss: 4.2683610916137695
Validation loss: 3.2777006030082703

Epoch: 5| Step: 8
Training loss: 3.793517589569092
Validation loss: 3.272740383942922

Epoch: 5| Step: 9
Training loss: 3.115845203399658
Validation loss: 3.2692919870217643

Epoch: 5| Step: 10
Training loss: 3.3845062255859375
Validation loss: 3.265181064605713

Epoch: 5| Step: 11
Training loss: 2.1334195137023926
Validation loss: 3.260499060153961

Epoch: 32| Step: 0
Training loss: 3.1312458515167236
Validation loss: 3.2566227316856384

Epoch: 5| Step: 1
Training loss: 3.493131637573242
Validation loss: 3.254089077313741

Epoch: 5| Step: 2
Training loss: 3.0956571102142334
Validation loss: 3.2487197617689767

Epoch: 5| Step: 3
Training loss: 3.2786307334899902
Validation loss: 3.24419038494428

Epoch: 5| Step: 4
Training loss: 4.284938812255859
Validation loss: 3.2405495842297873

Epoch: 5| Step: 5
Training loss: 3.2121644020080566
Validation loss: 3.2362441221872964

Epoch: 5| Step: 6
Training loss: 4.2048163414001465
Validation loss: 3.232742895682653

Epoch: 5| Step: 7
Training loss: 2.868638515472412
Validation loss: 3.2286355594793954

Epoch: 5| Step: 8
Training loss: 3.525355815887451
Validation loss: 3.223569134871165

Epoch: 5| Step: 9
Training loss: 3.2058792114257812
Validation loss: 3.218684673309326

Epoch: 5| Step: 10
Training loss: 3.1429455280303955
Validation loss: 3.2138181626796722

Epoch: 5| Step: 11
Training loss: 3.9301857948303223
Validation loss: 3.2092476189136505

Epoch: 33| Step: 0
Training loss: 3.4984099864959717
Validation loss: 3.204597989718119

Epoch: 5| Step: 1
Training loss: 4.0918169021606445
Validation loss: 3.2007553974787393

Epoch: 5| Step: 2
Training loss: 3.258915424346924
Validation loss: 3.1951969067255654

Epoch: 5| Step: 3
Training loss: 3.3269546031951904
Validation loss: 3.1911587913831077

Epoch: 5| Step: 4
Training loss: 3.9075958728790283
Validation loss: 3.185125390688578

Epoch: 5| Step: 5
Training loss: 3.50838041305542
Validation loss: 3.182422379652659

Epoch: 5| Step: 6
Training loss: 2.547882556915283
Validation loss: 3.177244553963343

Epoch: 5| Step: 7
Training loss: 2.507319688796997
Validation loss: 3.1721355617046356

Epoch: 5| Step: 8
Training loss: 4.137516021728516
Validation loss: 3.168114403883616

Epoch: 5| Step: 9
Training loss: 3.086113452911377
Validation loss: 3.164236048857371

Epoch: 5| Step: 10
Training loss: 3.0062689781188965
Validation loss: 3.159964253505071

Epoch: 5| Step: 11
Training loss: 4.08787202835083
Validation loss: 3.1552825470765433

Epoch: 34| Step: 0
Training loss: 3.3088226318359375
Validation loss: 3.151549518108368

Epoch: 5| Step: 1
Training loss: 3.294347047805786
Validation loss: 3.1476745108763375

Epoch: 5| Step: 2
Training loss: 3.904238224029541
Validation loss: 3.1430954933166504

Epoch: 5| Step: 3
Training loss: 3.960171937942505
Validation loss: 3.1389840145905814

Epoch: 5| Step: 4
Training loss: 3.301497220993042
Validation loss: 3.1347456773122153

Epoch: 5| Step: 5
Training loss: 2.9422507286071777
Validation loss: 3.1309978663921356

Epoch: 5| Step: 6
Training loss: 3.327167510986328
Validation loss: 3.125945051511129

Epoch: 5| Step: 7
Training loss: 3.4013588428497314
Validation loss: 3.1231238146622977

Epoch: 5| Step: 8
Training loss: 3.0545687675476074
Validation loss: 3.118802030881246

Epoch: 5| Step: 9
Training loss: 2.7910866737365723
Validation loss: 3.11334165930748

Epoch: 5| Step: 10
Training loss: 3.1490137577056885
Validation loss: 3.1091678142547607

Epoch: 5| Step: 11
Training loss: 3.5670289993286133
Validation loss: 3.104670355717341

Epoch: 35| Step: 0
Training loss: 4.728536605834961
Validation loss: 3.101547052462896

Epoch: 5| Step: 1
Training loss: 2.9708616733551025
Validation loss: 3.096893926461538

Epoch: 5| Step: 2
Training loss: 3.1823201179504395
Validation loss: 3.0934192339579263

Epoch: 5| Step: 3
Training loss: 3.165797710418701
Validation loss: 3.0895983278751373

Epoch: 5| Step: 4
Training loss: 3.4482436180114746
Validation loss: 3.0851602454980216

Epoch: 5| Step: 5
Training loss: 4.121088981628418
Validation loss: 3.081680417060852

Epoch: 5| Step: 6
Training loss: 3.1250150203704834
Validation loss: 3.077837367852529

Epoch: 5| Step: 7
Training loss: 2.7579824924468994
Validation loss: 3.0729585190614066

Epoch: 5| Step: 8
Training loss: 3.070211410522461
Validation loss: 3.0699119865894318

Epoch: 5| Step: 9
Training loss: 2.6481270790100098
Validation loss: 3.0654819309711456

Epoch: 5| Step: 10
Training loss: 2.6274688243865967
Validation loss: 3.061010350783666

Epoch: 5| Step: 11
Training loss: 4.009406089782715
Validation loss: 3.057973881562551

Epoch: 36| Step: 0
Training loss: 3.3356432914733887
Validation loss: 3.0559108654658

Epoch: 5| Step: 1
Training loss: 2.3765015602111816
Validation loss: 3.053056061267853

Epoch: 5| Step: 2
Training loss: 4.383415222167969
Validation loss: 3.0490670204162598

Epoch: 5| Step: 3
Training loss: 2.5447773933410645
Validation loss: 3.0448226630687714

Epoch: 5| Step: 4
Training loss: 3.763991594314575
Validation loss: 3.0412472784519196

Epoch: 5| Step: 5
Training loss: 3.3547332286834717
Validation loss: 3.0384759505589805

Epoch: 5| Step: 6
Training loss: 3.0473923683166504
Validation loss: 3.034887284040451

Epoch: 5| Step: 7
Training loss: 3.2862906455993652
Validation loss: 3.03163089354833

Epoch: 5| Step: 8
Training loss: 3.259319305419922
Validation loss: 3.0281687478224435

Epoch: 5| Step: 9
Training loss: 2.713531494140625
Validation loss: 3.0245156486829123

Epoch: 5| Step: 10
Training loss: 3.3431313037872314
Validation loss: 3.020695606867472

Epoch: 5| Step: 11
Training loss: 3.700934410095215
Validation loss: 3.016737778981527

Epoch: 37| Step: 0
Training loss: 4.189605236053467
Validation loss: 3.0129804611206055

Epoch: 5| Step: 1
Training loss: 2.4980876445770264
Validation loss: 3.008957783381144

Epoch: 5| Step: 2
Training loss: 3.0871949195861816
Validation loss: 3.005340794722239

Epoch: 5| Step: 3
Training loss: 4.259146690368652
Validation loss: 3.0024233063062034

Epoch: 5| Step: 4
Training loss: 2.6006360054016113
Validation loss: 2.9988184173901877

Epoch: 5| Step: 5
Training loss: 3.7022812366485596
Validation loss: 2.994880735874176

Epoch: 5| Step: 6
Training loss: 2.779482364654541
Validation loss: 2.991687426964442

Epoch: 5| Step: 7
Training loss: 2.6475331783294678
Validation loss: 2.9885913133621216

Epoch: 5| Step: 8
Training loss: 3.0318527221679688
Validation loss: 2.9851039350032806

Epoch: 5| Step: 9
Training loss: 2.906601667404175
Validation loss: 2.981814742088318

Epoch: 5| Step: 10
Training loss: 3.2787728309631348
Validation loss: 2.984333485364914

Epoch: 5| Step: 11
Training loss: 3.6313650608062744
Validation loss: 2.9757204155127206

Epoch: 38| Step: 0
Training loss: 3.1821234226226807
Validation loss: 2.9720108807086945

Epoch: 5| Step: 1
Training loss: 3.1374809741973877
Validation loss: 2.967810789744059

Epoch: 5| Step: 2
Training loss: 2.702909469604492
Validation loss: 2.96473095814387

Epoch: 5| Step: 3
Training loss: 3.082213878631592
Validation loss: 2.9617692132790885

Epoch: 5| Step: 4
Training loss: 3.1482532024383545
Validation loss: 2.9577459494272866

Epoch: 5| Step: 5
Training loss: 2.842646837234497
Validation loss: 2.953749507665634

Epoch: 5| Step: 6
Training loss: 3.6747994422912598
Validation loss: 2.9497161507606506

Epoch: 5| Step: 7
Training loss: 3.3391189575195312
Validation loss: 2.9456846117973328

Epoch: 5| Step: 8
Training loss: 2.95770263671875
Validation loss: 2.941863387823105

Epoch: 5| Step: 9
Training loss: 3.171163320541382
Validation loss: 2.939313809076945

Epoch: 5| Step: 10
Training loss: 3.3825716972351074
Validation loss: 2.936074366172155

Epoch: 5| Step: 11
Training loss: 3.2908668518066406
Validation loss: 2.9326355954011283

Epoch: 39| Step: 0
Training loss: 3.3236591815948486
Validation loss: 2.928988754749298

Epoch: 5| Step: 1
Training loss: 2.687605381011963
Validation loss: 2.9243785043557486

Epoch: 5| Step: 2
Training loss: 3.417264223098755
Validation loss: 2.921311100323995

Epoch: 5| Step: 3
Training loss: 2.8624050617218018
Validation loss: 2.917554418245951

Epoch: 5| Step: 4
Training loss: 3.3656246662139893
Validation loss: 2.913551847139994

Epoch: 5| Step: 5
Training loss: 2.8323943614959717
Validation loss: 2.909932255744934

Epoch: 5| Step: 6
Training loss: 3.7280426025390625
Validation loss: 2.9064311484495797

Epoch: 5| Step: 7
Training loss: 3.2130908966064453
Validation loss: 2.9029316703478494

Epoch: 5| Step: 8
Training loss: 2.874211549758911
Validation loss: 2.898121625185013

Epoch: 5| Step: 9
Training loss: 2.5905611515045166
Validation loss: 2.895733038584391

Epoch: 5| Step: 10
Training loss: 3.336543560028076
Validation loss: 2.892363985379537

Epoch: 5| Step: 11
Training loss: 3.2446043491363525
Validation loss: 2.88928692539533

Epoch: 40| Step: 0
Training loss: 2.764636993408203
Validation loss: 2.886430283387502

Epoch: 5| Step: 1
Training loss: 3.101393222808838
Validation loss: 2.8826132913430533

Epoch: 5| Step: 2
Training loss: 2.733278274536133
Validation loss: 2.87919220328331

Epoch: 5| Step: 3
Training loss: 2.720451831817627
Validation loss: 2.8761125107606254

Epoch: 5| Step: 4
Training loss: 3.1265058517456055
Validation loss: 2.8719050685564675

Epoch: 5| Step: 5
Training loss: 3.422779083251953
Validation loss: 2.8728924989700317

Epoch: 5| Step: 6
Training loss: 2.7678706645965576
Validation loss: 2.8661777476469674

Epoch: 5| Step: 7
Training loss: 3.619572162628174
Validation loss: 2.862494170665741

Epoch: 5| Step: 8
Training loss: 2.8847265243530273
Validation loss: 2.859492023785909

Epoch: 5| Step: 9
Training loss: 3.434816360473633
Validation loss: 2.8571296433607736

Epoch: 5| Step: 10
Training loss: 3.2169525623321533
Validation loss: 2.8533184925715127

Epoch: 5| Step: 11
Training loss: 3.311509132385254
Validation loss: 2.850263754526774

Epoch: 41| Step: 0
Training loss: 3.623988389968872
Validation loss: 2.847988650202751

Epoch: 5| Step: 1
Training loss: 2.430087089538574
Validation loss: 2.844685365756353

Epoch: 5| Step: 2
Training loss: 2.923330783843994
Validation loss: 2.8420080741246543

Epoch: 5| Step: 3
Training loss: 3.0909228324890137
Validation loss: 2.8385962545871735

Epoch: 5| Step: 4
Training loss: 3.744253635406494
Validation loss: 2.8361527919769287

Epoch: 5| Step: 5
Training loss: 3.2084598541259766
Validation loss: 2.8328224420547485

Epoch: 5| Step: 6
Training loss: 3.480032444000244
Validation loss: 2.8290148774782815

Epoch: 5| Step: 7
Training loss: 2.660550355911255
Validation loss: 2.8255334993203483

Epoch: 5| Step: 8
Training loss: 2.6556267738342285
Validation loss: 2.82257487376531

Epoch: 5| Step: 9
Training loss: 3.130357027053833
Validation loss: 2.8185379107793174

Epoch: 5| Step: 10
Training loss: 2.6785151958465576
Validation loss: 2.8173643052577972

Epoch: 5| Step: 11
Training loss: 2.281735420227051
Validation loss: 2.8168966869513192

Epoch: 42| Step: 0
Training loss: 2.6736881732940674
Validation loss: 2.8217132091522217

Epoch: 5| Step: 1
Training loss: 3.9747719764709473
Validation loss: 2.8117052912712097

Epoch: 5| Step: 2
Training loss: 3.3597731590270996
Validation loss: 2.8057291309038797

Epoch: 5| Step: 3
Training loss: 3.0724799633026123
Validation loss: 2.8022061785062156

Epoch: 5| Step: 4
Training loss: 2.3476219177246094
Validation loss: 2.7997902433077493

Epoch: 5| Step: 5
Training loss: 3.048926591873169
Validation loss: 2.7972622215747833

Epoch: 5| Step: 6
Training loss: 3.094841718673706
Validation loss: 2.7958028415838876

Epoch: 5| Step: 7
Training loss: 2.905808925628662
Validation loss: 2.792949467897415

Epoch: 5| Step: 8
Training loss: 2.581625461578369
Validation loss: 2.789309153954188

Epoch: 5| Step: 9
Training loss: 3.1970887184143066
Validation loss: 2.7869983911514282

Epoch: 5| Step: 10
Training loss: 2.78873610496521
Validation loss: 2.7844167749087014

Epoch: 5| Step: 11
Training loss: 3.4021518230438232
Validation loss: 2.781803697347641

Epoch: 43| Step: 0
Training loss: 3.2811496257781982
Validation loss: 2.778962423404058

Epoch: 5| Step: 1
Training loss: 3.0576813220977783
Validation loss: 2.7750886380672455

Epoch: 5| Step: 2
Training loss: 2.6051008701324463
Validation loss: 2.772383898496628

Epoch: 5| Step: 3
Training loss: 2.771940231323242
Validation loss: 2.7688421308994293

Epoch: 5| Step: 4
Training loss: 3.336876392364502
Validation loss: 2.766288975874583

Epoch: 5| Step: 5
Training loss: 2.1246743202209473
Validation loss: 2.7627446254094443

Epoch: 5| Step: 6
Training loss: 2.8891310691833496
Validation loss: 2.7602293392022452

Epoch: 5| Step: 7
Training loss: 2.885354518890381
Validation loss: 2.7568553487459817

Epoch: 5| Step: 8
Training loss: 3.621610164642334
Validation loss: 2.755226492881775

Epoch: 5| Step: 9
Training loss: 3.7334468364715576
Validation loss: 2.7519244949022927

Epoch: 5| Step: 10
Training loss: 2.6586623191833496
Validation loss: 2.74861733118693

Epoch: 5| Step: 11
Training loss: 1.7529115676879883
Validation loss: 2.745105584462484

Epoch: 44| Step: 0
Training loss: 2.7815957069396973
Validation loss: 2.743286778529485

Epoch: 5| Step: 1
Training loss: 3.2738819122314453
Validation loss: 2.7406519055366516

Epoch: 5| Step: 2
Training loss: 3.1159610748291016
Validation loss: 2.737805406252543

Epoch: 5| Step: 3
Training loss: 2.6351125240325928
Validation loss: 2.7351662715276084

Epoch: 5| Step: 4
Training loss: 2.9390857219696045
Validation loss: 2.732052514950434

Epoch: 5| Step: 5
Training loss: 3.2307770252227783
Validation loss: 2.7300094862778983

Epoch: 5| Step: 6
Training loss: 3.276257038116455
Validation loss: 2.7267727156480155

Epoch: 5| Step: 7
Training loss: 2.745206356048584
Validation loss: 2.724486996730169

Epoch: 5| Step: 8
Training loss: 2.457737922668457
Validation loss: 2.7217396100362143

Epoch: 5| Step: 9
Training loss: 3.096383571624756
Validation loss: 2.7187436620394387

Epoch: 5| Step: 10
Training loss: 2.9084620475769043
Validation loss: 2.716242810090383

Epoch: 5| Step: 11
Training loss: 2.245821952819824
Validation loss: 2.712258587280909

Epoch: 45| Step: 0
Training loss: 2.881340742111206
Validation loss: 2.7103245854377747

Epoch: 5| Step: 1
Training loss: 3.3224740028381348
Validation loss: 2.7074006299177804

Epoch: 5| Step: 2
Training loss: 3.408517360687256
Validation loss: 2.7044046024481454

Epoch: 5| Step: 3
Training loss: 2.90567684173584
Validation loss: 2.702335541447004

Epoch: 5| Step: 4
Training loss: 3.035451650619507
Validation loss: 2.6992390950520835

Epoch: 5| Step: 5
Training loss: 3.359844923019409
Validation loss: 2.696863353252411

Epoch: 5| Step: 6
Training loss: 2.7569868564605713
Validation loss: 2.6927808125813804

Epoch: 5| Step: 7
Training loss: 2.156066417694092
Validation loss: 2.689665655295054

Epoch: 5| Step: 8
Training loss: 2.559370756149292
Validation loss: 2.687861998875936

Epoch: 5| Step: 9
Training loss: 2.7279090881347656
Validation loss: 2.6844899555047355

Epoch: 5| Step: 10
Training loss: 2.5819203853607178
Validation loss: 2.6820506850878396

Epoch: 5| Step: 11
Training loss: 4.18337345123291
Validation loss: 2.6787788371245065

Epoch: 46| Step: 0
Training loss: 2.360903263092041
Validation loss: 2.6761210362116494

Epoch: 5| Step: 1
Training loss: 3.165365695953369
Validation loss: 2.674080948034922

Epoch: 5| Step: 2
Training loss: 2.635960102081299
Validation loss: 2.671354820330938

Epoch: 5| Step: 3
Training loss: 2.645136833190918
Validation loss: 2.668341636657715

Epoch: 5| Step: 4
Training loss: 3.03185772895813
Validation loss: 2.6650645434856415

Epoch: 5| Step: 5
Training loss: 2.893568754196167
Validation loss: 2.6626565357049308

Epoch: 5| Step: 6
Training loss: 2.7292208671569824
Validation loss: 2.660137494405111

Epoch: 5| Step: 7
Training loss: 2.656738758087158
Validation loss: 2.657345642646154

Epoch: 5| Step: 8
Training loss: 2.900643825531006
Validation loss: 2.654953887065252

Epoch: 5| Step: 9
Training loss: 3.290785551071167
Validation loss: 2.6524946689605713

Epoch: 5| Step: 10
Training loss: 3.1219229698181152
Validation loss: 2.649322917064031

Epoch: 5| Step: 11
Training loss: 3.4141597747802734
Validation loss: 2.6476341982682547

Epoch: 47| Step: 0
Training loss: 2.3839924335479736
Validation loss: 2.6427919467290244

Epoch: 5| Step: 1
Training loss: 2.8872389793395996
Validation loss: 2.6400940318902335

Epoch: 5| Step: 2
Training loss: 2.8451874256134033
Validation loss: 2.637259364128113

Epoch: 5| Step: 3
Training loss: 3.0367252826690674
Validation loss: 2.633770336707433

Epoch: 5| Step: 4
Training loss: 2.619901180267334
Validation loss: 2.631155570348104

Epoch: 5| Step: 5
Training loss: 3.072645902633667
Validation loss: 2.627746750911077

Epoch: 5| Step: 6
Training loss: 2.8153257369995117
Validation loss: 2.6253582537174225

Epoch: 5| Step: 7
Training loss: 2.61780047416687
Validation loss: 2.621631254752477

Epoch: 5| Step: 8
Training loss: 3.3823165893554688
Validation loss: 2.619372397661209

Epoch: 5| Step: 9
Training loss: 2.7367262840270996
Validation loss: 2.615810304880142

Epoch: 5| Step: 10
Training loss: 2.9835453033447266
Validation loss: 2.6132619281609855

Epoch: 5| Step: 11
Training loss: 1.6378142833709717
Validation loss: 2.608935217062632

Epoch: 48| Step: 0
Training loss: 3.0720393657684326
Validation loss: 2.6081023613611856

Epoch: 5| Step: 1
Training loss: 2.992445707321167
Validation loss: 2.6062908867994943

Epoch: 5| Step: 2
Training loss: 3.086872100830078
Validation loss: 2.6034919917583466

Epoch: 5| Step: 3
Training loss: 2.5429887771606445
Validation loss: 2.599571406841278

Epoch: 5| Step: 4
Training loss: 2.5007243156433105
Validation loss: 2.596162716547648

Epoch: 5| Step: 5
Training loss: 3.495607852935791
Validation loss: 2.5936964253584542

Epoch: 5| Step: 6
Training loss: 2.1859912872314453
Validation loss: 2.5913357535998025

Epoch: 5| Step: 7
Training loss: 2.4449973106384277
Validation loss: 2.5892751614252725

Epoch: 5| Step: 8
Training loss: 3.2203521728515625
Validation loss: 2.587292194366455

Epoch: 5| Step: 9
Training loss: 2.678100109100342
Validation loss: 2.5870540142059326

Epoch: 5| Step: 10
Training loss: 2.5406155586242676
Validation loss: 2.583492120107015

Epoch: 5| Step: 11
Training loss: 2.855747699737549
Validation loss: 2.5796131243308387

Epoch: 49| Step: 0
Training loss: 2.221940279006958
Validation loss: 2.5769161581993103

Epoch: 5| Step: 1
Training loss: 2.627932071685791
Validation loss: 2.574861913919449

Epoch: 5| Step: 2
Training loss: 2.65783953666687
Validation loss: 2.5719780027866364

Epoch: 5| Step: 3
Training loss: 3.027629852294922
Validation loss: 2.5693796475728354

Epoch: 5| Step: 4
Training loss: 3.016292095184326
Validation loss: 2.566734085480372

Epoch: 5| Step: 5
Training loss: 2.8845834732055664
Validation loss: 2.564390500386556

Epoch: 5| Step: 6
Training loss: 2.5875754356384277
Validation loss: 2.5618452429771423

Epoch: 5| Step: 7
Training loss: 2.452643871307373
Validation loss: 2.5582683086395264

Epoch: 5| Step: 8
Training loss: 2.9668819904327393
Validation loss: 2.5550111333529153

Epoch: 5| Step: 9
Training loss: 2.516571521759033
Validation loss: 2.552650809288025

Epoch: 5| Step: 10
Training loss: 3.408456325531006
Validation loss: 2.5505926509698233

Epoch: 5| Step: 11
Training loss: 2.947883367538452
Validation loss: 2.546265463034312

Epoch: 50| Step: 0
Training loss: 2.867626905441284
Validation loss: 2.5436197916666665

Epoch: 5| Step: 1
Training loss: 2.7322335243225098
Validation loss: 2.5410286287466683

Epoch: 5| Step: 2
Training loss: 2.4031879901885986
Validation loss: 2.540531804164251

Epoch: 5| Step: 3
Training loss: 2.9259634017944336
Validation loss: 2.5381897538900375

Epoch: 5| Step: 4
Training loss: 3.085158348083496
Validation loss: 2.53562663992246

Epoch: 5| Step: 5
Training loss: 2.813222646713257
Validation loss: 2.5324144860108695

Epoch: 5| Step: 6
Training loss: 3.0259768962860107
Validation loss: 2.5299113591512046

Epoch: 5| Step: 7
Training loss: 2.4079537391662598
Validation loss: 2.527670666575432

Epoch: 5| Step: 8
Training loss: 2.284782648086548
Validation loss: 2.5250878433386483

Epoch: 5| Step: 9
Training loss: 3.446760654449463
Validation loss: 2.5225194791952767

Epoch: 5| Step: 10
Training loss: 2.039236068725586
Validation loss: 2.520809695124626

Epoch: 5| Step: 11
Training loss: 2.9162402153015137
Validation loss: 2.517069478829702

Epoch: 51| Step: 0
Training loss: 2.2612786293029785
Validation loss: 2.5160172084967294

Epoch: 5| Step: 1
Training loss: 2.2025129795074463
Validation loss: 2.5137995034456253

Epoch: 5| Step: 2
Training loss: 3.377173662185669
Validation loss: 2.5239588022232056

Epoch: 5| Step: 3
Training loss: 2.575056552886963
Validation loss: 2.5104450980822244

Epoch: 5| Step: 4
Training loss: 3.2860209941864014
Validation loss: 2.5056919554869332

Epoch: 5| Step: 5
Training loss: 2.3973469734191895
Validation loss: 2.5059575835863748

Epoch: 5| Step: 6
Training loss: 3.1321682929992676
Validation loss: 2.5048694411913552

Epoch: 5| Step: 7
Training loss: 2.6580677032470703
Validation loss: 2.503695289293925

Epoch: 5| Step: 8
Training loss: 2.5960330963134766
Validation loss: 2.5038253168265023

Epoch: 5| Step: 9
Training loss: 3.034270763397217
Validation loss: 2.50199818611145

Epoch: 5| Step: 10
Training loss: 2.2305049896240234
Validation loss: 2.5019030471642814

Epoch: 5| Step: 11
Training loss: 2.800123929977417
Validation loss: 2.4979193905989328

Epoch: 52| Step: 0
Training loss: 2.8498294353485107
Validation loss: 2.49675382177035

Epoch: 5| Step: 1
Training loss: 2.730931043624878
Validation loss: 2.4913430412610373

Epoch: 5| Step: 2
Training loss: 2.989290952682495
Validation loss: 2.4912966191768646

Epoch: 5| Step: 3
Training loss: 3.145054578781128
Validation loss: 2.488348603248596

Epoch: 5| Step: 4
Training loss: 2.9771132469177246
Validation loss: 2.4865023096402488

Epoch: 5| Step: 5
Training loss: 1.9202558994293213
Validation loss: 2.4839854935805

Epoch: 5| Step: 6
Training loss: 2.781766653060913
Validation loss: 2.4812126457691193

Epoch: 5| Step: 7
Training loss: 2.648646116256714
Validation loss: 2.478064407904943

Epoch: 5| Step: 8
Training loss: 2.729557752609253
Validation loss: 2.4758230100075402

Epoch: 5| Step: 9
Training loss: 2.17693829536438
Validation loss: 2.472962041695913

Epoch: 5| Step: 10
Training loss: 2.710519790649414
Validation loss: 2.4704437255859375

Epoch: 5| Step: 11
Training loss: 1.5710177421569824
Validation loss: 2.4690287510553994

Epoch: 53| Step: 0
Training loss: 2.0099682807922363
Validation loss: 2.4656180143356323

Epoch: 5| Step: 1
Training loss: 3.060685634613037
Validation loss: 2.4626631438732147

Epoch: 5| Step: 2
Training loss: 2.9585328102111816
Validation loss: 2.4601184278726578

Epoch: 5| Step: 3
Training loss: 2.8968584537506104
Validation loss: 2.457191606362661

Epoch: 5| Step: 4
Training loss: 3.1690526008605957
Validation loss: 2.4552366038163504

Epoch: 5| Step: 5
Training loss: 3.354565143585205
Validation loss: 2.4571229815483093

Epoch: 5| Step: 6
Training loss: 2.4220404624938965
Validation loss: 2.4514502187569938

Epoch: 5| Step: 7
Training loss: 1.924846887588501
Validation loss: 2.448466350634893

Epoch: 5| Step: 8
Training loss: 2.3550355434417725
Validation loss: 2.4459251364072165

Epoch: 5| Step: 9
Training loss: 2.4842655658721924
Validation loss: 2.4452109138170877

Epoch: 5| Step: 10
Training loss: 2.3948991298675537
Validation loss: 2.446460783481598

Epoch: 5| Step: 11
Training loss: 2.972590923309326
Validation loss: 2.4453963935375214

Epoch: 54| Step: 0
Training loss: 2.4650719165802
Validation loss: 2.4444641172885895

Epoch: 5| Step: 1
Training loss: 2.7270519733428955
Validation loss: 2.443857262531916

Epoch: 5| Step: 2
Training loss: 2.3060555458068848
Validation loss: 2.442494422197342

Epoch: 5| Step: 3
Training loss: 3.193882942199707
Validation loss: 2.4391296803951263

Epoch: 5| Step: 4
Training loss: 2.8512051105499268
Validation loss: 2.4346951842308044

Epoch: 5| Step: 5
Training loss: 3.059075117111206
Validation loss: 2.430931026736895

Epoch: 5| Step: 6
Training loss: 2.9834516048431396
Validation loss: 2.4269115030765533

Epoch: 5| Step: 7
Training loss: 2.077329158782959
Validation loss: 2.424300601085027

Epoch: 5| Step: 8
Training loss: 2.538372278213501
Validation loss: 2.4218398928642273

Epoch: 5| Step: 9
Training loss: 2.185326099395752
Validation loss: 2.4185010691483817

Epoch: 5| Step: 10
Training loss: 2.436253070831299
Validation loss: 2.4154708882172904

Epoch: 5| Step: 11
Training loss: 2.3341283798217773
Validation loss: 2.4126117328802743

Epoch: 55| Step: 0
Training loss: 2.141162633895874
Validation loss: 2.4080199102560678

Epoch: 5| Step: 1
Training loss: 2.271195650100708
Validation loss: 2.406718442837397

Epoch: 5| Step: 2
Training loss: 2.6085822582244873
Validation loss: 2.402126133441925

Epoch: 5| Step: 3
Training loss: 2.756652593612671
Validation loss: 2.4023982882499695

Epoch: 5| Step: 4
Training loss: 2.034022092819214
Validation loss: 2.400254418452581

Epoch: 5| Step: 5
Training loss: 3.085113286972046
Validation loss: 2.3979847133159637

Epoch: 5| Step: 6
Training loss: 2.727736473083496
Validation loss: 2.394549543658892

Epoch: 5| Step: 7
Training loss: 2.505629062652588
Validation loss: 2.3919699589411416

Epoch: 5| Step: 8
Training loss: 2.6475019454956055
Validation loss: 2.385777642329534

Epoch: 5| Step: 9
Training loss: 2.615020990371704
Validation loss: 2.385782112677892

Epoch: 5| Step: 10
Training loss: 2.9606611728668213
Validation loss: 2.3824663758277893

Epoch: 5| Step: 11
Training loss: 2.7822718620300293
Validation loss: 2.3822080145279565

Epoch: 56| Step: 0
Training loss: 2.401171922683716
Validation loss: 2.3811067243417106

Epoch: 5| Step: 1
Training loss: 2.3912525177001953
Validation loss: 2.3795664509137473

Epoch: 5| Step: 2
Training loss: 2.920351028442383
Validation loss: 2.3779230614503226

Epoch: 5| Step: 3
Training loss: 2.9469847679138184
Validation loss: 2.379075060288111

Epoch: 5| Step: 4
Training loss: 2.6900198459625244
Validation loss: 2.3769581615924835

Epoch: 5| Step: 5
Training loss: 2.2730889320373535
Validation loss: 2.374653438727061

Epoch: 5| Step: 6
Training loss: 2.2100634574890137
Validation loss: 2.371739685535431

Epoch: 5| Step: 7
Training loss: 2.432584047317505
Validation loss: 2.3712475498517356

Epoch: 5| Step: 8
Training loss: 2.607614755630493
Validation loss: 2.367632965246836

Epoch: 5| Step: 9
Training loss: 2.426772117614746
Validation loss: 2.363893131415049

Epoch: 5| Step: 10
Training loss: 2.614326000213623
Validation loss: 2.3634678622086844

Epoch: 5| Step: 11
Training loss: 3.3774845600128174
Validation loss: 2.358567704757055

Epoch: 57| Step: 0
Training loss: 2.833263397216797
Validation loss: 2.358185271422068

Epoch: 5| Step: 1
Training loss: 2.154265880584717
Validation loss: 2.352096974849701

Epoch: 5| Step: 2
Training loss: 2.0177388191223145
Validation loss: 2.3505318264166513

Epoch: 5| Step: 3
Training loss: 2.4636054039001465
Validation loss: 2.349220703045527

Epoch: 5| Step: 4
Training loss: 2.8384006023406982
Validation loss: 2.345896770556768

Epoch: 5| Step: 5
Training loss: 2.6024398803710938
Validation loss: 2.343883822361628

Epoch: 5| Step: 6
Training loss: 3.2003989219665527
Validation loss: 2.342875291903814

Epoch: 5| Step: 7
Training loss: 2.9195778369903564
Validation loss: 2.3408604015906653

Epoch: 5| Step: 8
Training loss: 2.1167163848876953
Validation loss: 2.337098012367884

Epoch: 5| Step: 9
Training loss: 2.3548569679260254
Validation loss: 2.337701921661695

Epoch: 5| Step: 10
Training loss: 2.263714551925659
Validation loss: 2.3335299690564475

Epoch: 5| Step: 11
Training loss: 2.3958330154418945
Validation loss: 2.3318621118863425

Epoch: 58| Step: 0
Training loss: 2.620915174484253
Validation loss: 2.3280037343502045

Epoch: 5| Step: 1
Training loss: 2.3056423664093018
Validation loss: 2.3269744316736856

Epoch: 5| Step: 2
Training loss: 1.762147307395935
Validation loss: 2.3234373281399407

Epoch: 5| Step: 3
Training loss: 1.8109207153320312
Validation loss: 2.322433724999428

Epoch: 5| Step: 4
Training loss: 2.646305561065674
Validation loss: 2.315974459052086

Epoch: 5| Step: 5
Training loss: 2.6707520484924316
Validation loss: 2.3171447813510895

Epoch: 5| Step: 6
Training loss: 2.560663938522339
Validation loss: 2.31420174241066

Epoch: 5| Step: 7
Training loss: 2.5343143939971924
Validation loss: 2.311935464541117

Epoch: 5| Step: 8
Training loss: 2.889124631881714
Validation loss: 2.3101122677326202

Epoch: 5| Step: 9
Training loss: 2.3165817260742188
Validation loss: 2.308011809984843

Epoch: 5| Step: 10
Training loss: 3.1971850395202637
Validation loss: 2.305362900098165

Epoch: 5| Step: 11
Training loss: 3.1024279594421387
Validation loss: 2.300646960735321

Epoch: 59| Step: 0
Training loss: 2.1954057216644287
Validation loss: 2.299421951174736

Epoch: 5| Step: 1
Training loss: 2.30128812789917
Validation loss: 2.2940331598122916

Epoch: 5| Step: 2
Training loss: 2.269786834716797
Validation loss: 2.2936233977476754

Epoch: 5| Step: 3
Training loss: 2.916908025741577
Validation loss: 2.290096948544184

Epoch: 5| Step: 4
Training loss: 2.6159567832946777
Validation loss: 2.289758870999018

Epoch: 5| Step: 5
Training loss: 2.6873512268066406
Validation loss: 2.286142776409785

Epoch: 5| Step: 6
Training loss: 2.344911813735962
Validation loss: 2.287487104535103

Epoch: 5| Step: 7
Training loss: 2.250464916229248
Validation loss: 2.284814010063807

Epoch: 5| Step: 8
Training loss: 2.4903717041015625
Validation loss: 2.283367762962977

Epoch: 5| Step: 9
Training loss: 2.3779866695404053
Validation loss: 2.2815353920062384

Epoch: 5| Step: 10
Training loss: 2.633711814880371
Validation loss: 2.2795378963152566

Epoch: 5| Step: 11
Training loss: 2.5271224975585938
Validation loss: 2.2801027446985245

Epoch: 60| Step: 0
Training loss: 2.482614040374756
Validation loss: 2.2784222960472107

Epoch: 5| Step: 1
Training loss: 2.412654161453247
Validation loss: 2.2762127916018167

Epoch: 5| Step: 2
Training loss: 2.6669445037841797
Validation loss: 2.2742335150639215

Epoch: 5| Step: 3
Training loss: 3.0482609272003174
Validation loss: 2.274164398511251

Epoch: 5| Step: 4
Training loss: 2.384687900543213
Validation loss: 2.270375723640124

Epoch: 5| Step: 5
Training loss: 2.7351067066192627
Validation loss: 2.2693235178788504

Epoch: 5| Step: 6
Training loss: 2.155552625656128
Validation loss: 2.266699234644572

Epoch: 5| Step: 7
Training loss: 2.212125301361084
Validation loss: 2.263888488213221

Epoch: 5| Step: 8
Training loss: 2.430208921432495
Validation loss: 2.2606175988912582

Epoch: 5| Step: 9
Training loss: 2.427577495574951
Validation loss: 2.256600891550382

Epoch: 5| Step: 10
Training loss: 1.6806074380874634
Validation loss: 2.253568321466446

Epoch: 5| Step: 11
Training loss: 3.1296606063842773
Validation loss: 2.2500631908575692

Epoch: 61| Step: 0
Training loss: 2.50144624710083
Validation loss: 2.244885047276815

Epoch: 5| Step: 1
Training loss: 2.7271857261657715
Validation loss: 2.2437584499518075

Epoch: 5| Step: 2
Training loss: 2.3060643672943115
Validation loss: 2.241091032822927

Epoch: 5| Step: 3
Training loss: 2.420243740081787
Validation loss: 2.240347037712733

Epoch: 5| Step: 4
Training loss: 2.3488049507141113
Validation loss: 2.2369340856870017

Epoch: 5| Step: 5
Training loss: 1.8545173406600952
Validation loss: 2.235776116450628

Epoch: 5| Step: 6
Training loss: 2.179330825805664
Validation loss: 2.2335122575362525

Epoch: 5| Step: 7
Training loss: 2.20405912399292
Validation loss: 2.233813797434171

Epoch: 5| Step: 8
Training loss: 2.8261990547180176
Validation loss: 2.234561731417974

Epoch: 5| Step: 9
Training loss: 2.4666216373443604
Validation loss: 2.2353966186443963

Epoch: 5| Step: 10
Training loss: 2.6081693172454834
Validation loss: 2.233242154121399

Epoch: 5| Step: 11
Training loss: 2.608351707458496
Validation loss: 2.2331267595291138

Epoch: 62| Step: 0
Training loss: 1.9684641361236572
Validation loss: 2.2284719149271646

Epoch: 5| Step: 1
Training loss: 2.4771840572357178
Validation loss: 2.2265145977338157

Epoch: 5| Step: 2
Training loss: 2.0422027111053467
Validation loss: 2.2251159101724625

Epoch: 5| Step: 3
Training loss: 2.487325668334961
Validation loss: 2.2204290280739465

Epoch: 5| Step: 4
Training loss: 3.1019062995910645
Validation loss: 2.222408026456833

Epoch: 5| Step: 5
Training loss: 1.7674328088760376
Validation loss: 2.220086455345154

Epoch: 5| Step: 6
Training loss: 2.376704692840576
Validation loss: 2.214059899250666

Epoch: 5| Step: 7
Training loss: 2.5350940227508545
Validation loss: 2.211702808737755

Epoch: 5| Step: 8
Training loss: 2.6771676540374756
Validation loss: 2.206722309192022

Epoch: 5| Step: 9
Training loss: 2.2159390449523926
Validation loss: 2.211790238817533

Epoch: 5| Step: 10
Training loss: 2.4544408321380615
Validation loss: 2.2099662323792777

Epoch: 5| Step: 11
Training loss: 2.736941337585449
Validation loss: 2.2059835294882455

Epoch: 63| Step: 0
Training loss: 2.3768038749694824
Validation loss: 2.204677144686381

Epoch: 5| Step: 1
Training loss: 2.2037415504455566
Validation loss: 2.20444663365682

Epoch: 5| Step: 2
Training loss: 2.6460976600646973
Validation loss: 2.20139088233312

Epoch: 5| Step: 3
Training loss: 2.589886426925659
Validation loss: 2.199601501226425

Epoch: 5| Step: 4
Training loss: 2.095837116241455
Validation loss: 2.200682580471039

Epoch: 5| Step: 5
Training loss: 2.4242687225341797
Validation loss: 2.196233958005905

Epoch: 5| Step: 6
Training loss: 2.188429355621338
Validation loss: 2.1948877225319543

Epoch: 5| Step: 7
Training loss: 2.076720714569092
Validation loss: 2.1981049279371896

Epoch: 5| Step: 8
Training loss: 2.9390454292297363
Validation loss: 2.189467817544937

Epoch: 5| Step: 9
Training loss: 2.1163852214813232
Validation loss: 2.1889493415753045

Epoch: 5| Step: 10
Training loss: 2.6088130474090576
Validation loss: 2.182510808110237

Epoch: 5| Step: 11
Training loss: 1.43613600730896
Validation loss: 2.1858321328957877

Epoch: 64| Step: 0
Training loss: 2.3417859077453613
Validation loss: 2.1884263853232064

Epoch: 5| Step: 1
Training loss: 2.42765736579895
Validation loss: 2.195327411095301

Epoch: 5| Step: 2
Training loss: 2.323045253753662
Validation loss: 2.198202763994535

Epoch: 5| Step: 3
Training loss: 2.625377655029297
Validation loss: 2.2016791701316833

Epoch: 5| Step: 4
Training loss: 2.4278738498687744
Validation loss: 2.20315953095754

Epoch: 5| Step: 5
Training loss: 2.5151209831237793
Validation loss: 2.208335449298223

Epoch: 5| Step: 6
Training loss: 2.3638949394226074
Validation loss: 2.208992898464203

Epoch: 5| Step: 7
Training loss: 2.705639362335205
Validation loss: 2.211595267057419

Epoch: 5| Step: 8
Training loss: 2.2628567218780518
Validation loss: 2.2046680450439453

Epoch: 5| Step: 9
Training loss: 2.047234296798706
Validation loss: 2.196150233348211

Epoch: 5| Step: 10
Training loss: 2.1916470527648926
Validation loss: 2.1898370732863746

Epoch: 5| Step: 11
Training loss: 1.2419441938400269
Validation loss: 2.18815678358078

Epoch: 65| Step: 0
Training loss: 2.5065693855285645
Validation loss: 2.1794862896203995

Epoch: 5| Step: 1
Training loss: 2.8757436275482178
Validation loss: 2.172485113143921

Epoch: 5| Step: 2
Training loss: 2.01745343208313
Validation loss: 2.170204962293307

Epoch: 5| Step: 3
Training loss: 2.47662353515625
Validation loss: 2.1693231562773385

Epoch: 5| Step: 4
Training loss: 1.905832052230835
Validation loss: 2.1724486549695334

Epoch: 5| Step: 5
Training loss: 1.9677555561065674
Validation loss: 2.169036234418551

Epoch: 5| Step: 6
Training loss: 2.409249782562256
Validation loss: 2.164783795674642

Epoch: 5| Step: 7
Training loss: 2.6239054203033447
Validation loss: 2.1664482206106186

Epoch: 5| Step: 8
Training loss: 2.111539363861084
Validation loss: 2.161291937033335

Epoch: 5| Step: 9
Training loss: 2.123121738433838
Validation loss: 2.1664780328671136

Epoch: 5| Step: 10
Training loss: 2.4652113914489746
Validation loss: 2.1571225772301355

Epoch: 5| Step: 11
Training loss: 3.3894898891448975
Validation loss: 2.1575913627942405

Epoch: 66| Step: 0
Training loss: 2.683065891265869
Validation loss: 2.163728659351667

Epoch: 5| Step: 1
Training loss: 2.4750335216522217
Validation loss: 2.1633974512418113

Epoch: 5| Step: 2
Training loss: 2.867352247238159
Validation loss: 2.153409277399381

Epoch: 5| Step: 3
Training loss: 2.4966933727264404
Validation loss: 2.1543055375417075

Epoch: 5| Step: 4
Training loss: 2.388211727142334
Validation loss: 2.1570788621902466

Epoch: 5| Step: 5
Training loss: 2.170027256011963
Validation loss: 2.1553632616996765

Epoch: 5| Step: 6
Training loss: 2.7473011016845703
Validation loss: 2.162283723553022

Epoch: 5| Step: 7
Training loss: 1.7346992492675781
Validation loss: 2.1645674457152686

Epoch: 5| Step: 8
Training loss: 1.6929330825805664
Validation loss: 2.1733272473017373

Epoch: 5| Step: 9
Training loss: 2.3702902793884277
Validation loss: 2.170707643032074

Epoch: 5| Step: 10
Training loss: 1.9893032312393188
Validation loss: 2.1720506846904755

Epoch: 5| Step: 11
Training loss: 2.7440004348754883
Validation loss: 2.1692403852939606

Epoch: 67| Step: 0
Training loss: 2.329381227493286
Validation loss: 2.1504982809225717

Epoch: 5| Step: 1
Training loss: 1.6377750635147095
Validation loss: 2.150612711906433

Epoch: 5| Step: 2
Training loss: 2.375093460083008
Validation loss: 2.1452717383702598

Epoch: 5| Step: 3
Training loss: 2.9269211292266846
Validation loss: 2.1440751453240714

Epoch: 5| Step: 4
Training loss: 2.3320882320404053
Validation loss: 2.1392814020315805

Epoch: 5| Step: 5
Training loss: 2.1919641494750977
Validation loss: 2.1444465120633445

Epoch: 5| Step: 6
Training loss: 2.520092487335205
Validation loss: 2.145827348033587

Epoch: 5| Step: 7
Training loss: 2.4366142749786377
Validation loss: 2.145705590645472

Epoch: 5| Step: 8
Training loss: 2.0896782875061035
Validation loss: 2.143261651198069

Epoch: 5| Step: 9
Training loss: 2.230186939239502
Validation loss: 2.138671721021334

Epoch: 5| Step: 10
Training loss: 2.4328906536102295
Validation loss: 2.134769171476364

Epoch: 5| Step: 11
Training loss: 2.7191288471221924
Validation loss: 2.1436441838741302

Epoch: 68| Step: 0
Training loss: 2.7314600944519043
Validation loss: 2.145293374856313

Epoch: 5| Step: 1
Training loss: 1.6862766742706299
Validation loss: 2.1445694963137307

Epoch: 5| Step: 2
Training loss: 2.40251088142395
Validation loss: 2.144773637255033

Epoch: 5| Step: 3
Training loss: 1.747702956199646
Validation loss: 2.146218200524648

Epoch: 5| Step: 4
Training loss: 2.5992283821105957
Validation loss: 2.144363055626551

Epoch: 5| Step: 5
Training loss: 2.4171130657196045
Validation loss: 2.149132708708445

Epoch: 5| Step: 6
Training loss: 2.383888006210327
Validation loss: 2.1435892979303994

Epoch: 5| Step: 7
Training loss: 2.28332257270813
Validation loss: 2.1425660848617554

Epoch: 5| Step: 8
Training loss: 2.8139045238494873
Validation loss: 2.143714189529419

Epoch: 5| Step: 9
Training loss: 2.3634421825408936
Validation loss: 2.1460631589094796

Epoch: 5| Step: 10
Training loss: 2.151285171508789
Validation loss: 2.1414130479097366

Epoch: 5| Step: 11
Training loss: 2.061100959777832
Validation loss: 2.1391542504231134

Epoch: 69| Step: 0
Training loss: 2.152170181274414
Validation loss: 2.132597511013349

Epoch: 5| Step: 1
Training loss: 1.9700138568878174
Validation loss: 2.130503495534261

Epoch: 5| Step: 2
Training loss: 2.4856479167938232
Validation loss: 2.131431221961975

Epoch: 5| Step: 3
Training loss: 2.5818088054656982
Validation loss: 2.1278364260991416

Epoch: 5| Step: 4
Training loss: 2.6408002376556396
Validation loss: 2.126224329074224

Epoch: 5| Step: 5
Training loss: 2.171671152114868
Validation loss: 2.1238553623358407

Epoch: 5| Step: 6
Training loss: 2.0992140769958496
Validation loss: 2.1196066041787467

Epoch: 5| Step: 7
Training loss: 2.1257481575012207
Validation loss: 2.118495136499405

Epoch: 5| Step: 8
Training loss: 2.011550188064575
Validation loss: 2.1169153501590094

Epoch: 5| Step: 9
Training loss: 2.320537567138672
Validation loss: 2.116885006427765

Epoch: 5| Step: 10
Training loss: 2.7340140342712402
Validation loss: 2.1143066386381784

Epoch: 5| Step: 11
Training loss: 2.7453017234802246
Validation loss: 2.1144043505191803

Epoch: 70| Step: 0
Training loss: 2.4981794357299805
Validation loss: 2.114544063806534

Epoch: 5| Step: 1
Training loss: 2.2608845233917236
Validation loss: 2.1120286186536155

Epoch: 5| Step: 2
Training loss: 2.583848476409912
Validation loss: 2.1147319426139197

Epoch: 5| Step: 3
Training loss: 2.09067964553833
Validation loss: 2.113814428448677

Epoch: 5| Step: 4
Training loss: 2.1878724098205566
Validation loss: 2.11222235361735

Epoch: 5| Step: 5
Training loss: 2.529219388961792
Validation loss: 2.111330916484197

Epoch: 5| Step: 6
Training loss: 2.0683722496032715
Validation loss: 2.112755318482717

Epoch: 5| Step: 7
Training loss: 2.274871826171875
Validation loss: 2.1053552627563477

Epoch: 5| Step: 8
Training loss: 2.193636894226074
Validation loss: 2.107717896501223

Epoch: 5| Step: 9
Training loss: 2.336374521255493
Validation loss: 2.1060986469189324

Epoch: 5| Step: 10
Training loss: 2.262690544128418
Validation loss: 2.1017007678747177

Epoch: 5| Step: 11
Training loss: 2.0754036903381348
Validation loss: 2.1001786440610886

Epoch: 71| Step: 0
Training loss: 1.8538362979888916
Validation loss: 2.103183070818583

Epoch: 5| Step: 1
Training loss: 2.055163860321045
Validation loss: 2.1075858026742935

Epoch: 5| Step: 2
Training loss: 1.927687406539917
Validation loss: 2.1017419397830963

Epoch: 5| Step: 3
Training loss: 2.394973039627075
Validation loss: 2.1018293350934982

Epoch: 5| Step: 4
Training loss: 2.545825958251953
Validation loss: 2.099848116437594

Epoch: 5| Step: 5
Training loss: 2.7339890003204346
Validation loss: 2.099171926577886

Epoch: 5| Step: 6
Training loss: 2.184774875640869
Validation loss: 2.1046731372674308

Epoch: 5| Step: 7
Training loss: 2.166787624359131
Validation loss: 2.105896865328153

Epoch: 5| Step: 8
Training loss: 2.7196736335754395
Validation loss: 2.105148563782374

Epoch: 5| Step: 9
Training loss: 2.0744433403015137
Validation loss: 2.0992002487182617

Epoch: 5| Step: 10
Training loss: 2.781526565551758
Validation loss: 2.101080665985743

Epoch: 5| Step: 11
Training loss: 0.7063038349151611
Validation loss: 2.0951662013928094

Epoch: 72| Step: 0
Training loss: 2.4872145652770996
Validation loss: 2.0953761835892997

Epoch: 5| Step: 1
Training loss: 2.5262043476104736
Validation loss: 2.096026728550593

Epoch: 5| Step: 2
Training loss: 2.1559224128723145
Validation loss: 2.1015184422334037

Epoch: 5| Step: 3
Training loss: 2.121201276779175
Validation loss: 2.1009798695643744

Epoch: 5| Step: 4
Training loss: 2.703209638595581
Validation loss: 2.097369685769081

Epoch: 5| Step: 5
Training loss: 2.122838020324707
Validation loss: 2.0877472857634225

Epoch: 5| Step: 6
Training loss: 2.3245890140533447
Validation loss: 2.0913573106129966

Epoch: 5| Step: 7
Training loss: 2.360194206237793
Validation loss: 2.100812092423439

Epoch: 5| Step: 8
Training loss: 2.250288486480713
Validation loss: 2.1041215558846793

Epoch: 5| Step: 9
Training loss: 1.9683904647827148
Validation loss: 2.1125527173280716

Epoch: 5| Step: 10
Training loss: 2.3647656440734863
Validation loss: 2.120241383711497

Epoch: 5| Step: 11
Training loss: 2.3650944232940674
Validation loss: 2.1288266529639563

Epoch: 73| Step: 0
Training loss: 2.270895481109619
Validation loss: 2.125928392012914

Epoch: 5| Step: 1
Training loss: 2.390883207321167
Validation loss: 2.120992034673691

Epoch: 5| Step: 2
Training loss: 2.7683470249176025
Validation loss: 2.1154208978017173

Epoch: 5| Step: 3
Training loss: 2.0500056743621826
Validation loss: 2.1098849177360535

Epoch: 5| Step: 4
Training loss: 1.9186174869537354
Validation loss: 2.1062027166287103

Epoch: 5| Step: 5
Training loss: 2.674614667892456
Validation loss: 2.105349972844124

Epoch: 5| Step: 6
Training loss: 2.139626979827881
Validation loss: 2.098673924803734

Epoch: 5| Step: 7
Training loss: 2.1455273628234863
Validation loss: 2.0949010898669562

Epoch: 5| Step: 8
Training loss: 2.0494420528411865
Validation loss: 2.0930075546105704

Epoch: 5| Step: 9
Training loss: 2.4492297172546387
Validation loss: 2.088177338242531

Epoch: 5| Step: 10
Training loss: 2.2295944690704346
Validation loss: 2.0858037223418555

Epoch: 5| Step: 11
Training loss: 2.9001107215881348
Validation loss: 2.0784285565217337

Epoch: 74| Step: 0
Training loss: 2.354328155517578
Validation loss: 2.0795487513144812

Epoch: 5| Step: 1
Training loss: 2.8377089500427246
Validation loss: 2.0734913100798926

Epoch: 5| Step: 2
Training loss: 1.987161636352539
Validation loss: 2.0774939407904944

Epoch: 5| Step: 3
Training loss: 1.7832920551300049
Validation loss: 2.073740452528

Epoch: 5| Step: 4
Training loss: 2.104128122329712
Validation loss: 2.0639328757921853

Epoch: 5| Step: 5
Training loss: 2.2700254917144775
Validation loss: 2.0743560791015625

Epoch: 5| Step: 6
Training loss: 1.850398302078247
Validation loss: 2.075848569472631

Epoch: 5| Step: 7
Training loss: 2.6890194416046143
Validation loss: 2.071364904443423

Epoch: 5| Step: 8
Training loss: 2.452153444290161
Validation loss: 2.077937051653862

Epoch: 5| Step: 9
Training loss: 1.812077283859253
Validation loss: 2.0784130692481995

Epoch: 5| Step: 10
Training loss: 2.5338375568389893
Validation loss: 2.080951745311419

Epoch: 5| Step: 11
Training loss: 3.4453163146972656
Validation loss: 2.077809363603592

Epoch: 75| Step: 0
Training loss: 2.458002805709839
Validation loss: 2.06300979355971

Epoch: 5| Step: 1
Training loss: 1.752852439880371
Validation loss: 2.0711619357268014

Epoch: 5| Step: 2
Training loss: 1.9444319009780884
Validation loss: 2.0767762760321298

Epoch: 5| Step: 3
Training loss: 2.361788272857666
Validation loss: 2.0730028301477432

Epoch: 5| Step: 4
Training loss: 2.3649685382843018
Validation loss: 2.0780180295308432

Epoch: 5| Step: 5
Training loss: 2.330928087234497
Validation loss: 2.081403667728106

Epoch: 5| Step: 6
Training loss: 2.3887927532196045
Validation loss: 2.082801192998886

Epoch: 5| Step: 7
Training loss: 2.462353229522705
Validation loss: 2.0824924608071647

Epoch: 5| Step: 8
Training loss: 2.6133837699890137
Validation loss: 2.084563543399175

Epoch: 5| Step: 9
Training loss: 2.2228171825408936
Validation loss: 2.079469313224157

Epoch: 5| Step: 10
Training loss: 1.9557266235351562
Validation loss: 2.0791782587766647

Epoch: 5| Step: 11
Training loss: 2.4832286834716797
Validation loss: 2.0768822878599167

Epoch: 76| Step: 0
Training loss: 1.8286895751953125
Validation loss: 2.079219644268354

Epoch: 5| Step: 1
Training loss: 3.1730635166168213
Validation loss: 2.076979234814644

Epoch: 5| Step: 2
Training loss: 2.401876926422119
Validation loss: 2.0745756725470224

Epoch: 5| Step: 3
Training loss: 2.0815436840057373
Validation loss: 2.0788255532582602

Epoch: 5| Step: 4
Training loss: 2.2162938117980957
Validation loss: 2.075291633605957

Epoch: 5| Step: 5
Training loss: 2.3510704040527344
Validation loss: 2.071538438399633

Epoch: 5| Step: 6
Training loss: 2.39314341545105
Validation loss: 2.06755859653155

Epoch: 5| Step: 7
Training loss: 1.9971153736114502
Validation loss: 2.0657086819410324

Epoch: 5| Step: 8
Training loss: 2.3802762031555176
Validation loss: 2.0657150546709695

Epoch: 5| Step: 9
Training loss: 2.294804811477661
Validation loss: 2.063513363401095

Epoch: 5| Step: 10
Training loss: 1.8164970874786377
Validation loss: 2.0593574345111847

Epoch: 5| Step: 11
Training loss: 1.9478278160095215
Validation loss: 2.0545947204033532

Epoch: 77| Step: 0
Training loss: 2.1865391731262207
Validation loss: 2.0529818733533225

Epoch: 5| Step: 1
Training loss: 2.3389906883239746
Validation loss: 2.0533383935689926

Epoch: 5| Step: 2
Training loss: 1.7865015268325806
Validation loss: 2.0582742542028427

Epoch: 5| Step: 3
Training loss: 2.127673625946045
Validation loss: 2.069416711727778

Epoch: 5| Step: 4
Training loss: 2.4386215209960938
Validation loss: 2.0763054341077805

Epoch: 5| Step: 5
Training loss: 2.215719699859619
Validation loss: 2.09129199385643

Epoch: 5| Step: 6
Training loss: 2.793367385864258
Validation loss: 2.1111391435066857

Epoch: 5| Step: 7
Training loss: 2.58966326713562
Validation loss: 2.093749205271403

Epoch: 5| Step: 8
Training loss: 2.2226529121398926
Validation loss: 2.075289269288381

Epoch: 5| Step: 9
Training loss: 1.8926208019256592
Validation loss: 2.058739721775055

Epoch: 5| Step: 10
Training loss: 2.3427376747131348
Validation loss: 2.0460999260346093

Epoch: 5| Step: 11
Training loss: 2.72896146774292
Validation loss: 2.0440580646197

Epoch: 78| Step: 0
Training loss: 2.5475873947143555
Validation loss: 2.0471450984477997

Epoch: 5| Step: 1
Training loss: 2.282644271850586
Validation loss: 2.055197904507319

Epoch: 5| Step: 2
Training loss: 2.2931416034698486
Validation loss: 2.0567174504200616

Epoch: 5| Step: 3
Training loss: 2.652270793914795
Validation loss: 2.063416803876559

Epoch: 5| Step: 4
Training loss: 2.0614781379699707
Validation loss: 2.0648843248685202

Epoch: 5| Step: 5
Training loss: 2.089963436126709
Validation loss: 2.0664550215005875

Epoch: 5| Step: 6
Training loss: 2.1313118934631348
Validation loss: 2.068166504303614

Epoch: 5| Step: 7
Training loss: 1.9934284687042236
Validation loss: 2.06762524942557

Epoch: 5| Step: 8
Training loss: 2.3913981914520264
Validation loss: 2.0673895130554834

Epoch: 5| Step: 9
Training loss: 2.247886896133423
Validation loss: 2.068035567800204

Epoch: 5| Step: 10
Training loss: 2.1061618328094482
Validation loss: 2.064917951822281

Epoch: 5| Step: 11
Training loss: 2.6398837566375732
Validation loss: 2.064636319875717

Epoch: 79| Step: 0
Training loss: 2.552851915359497
Validation loss: 2.0608107149600983

Epoch: 5| Step: 1
Training loss: 1.9475412368774414
Validation loss: 2.0596129645903907

Epoch: 5| Step: 2
Training loss: 2.2311367988586426
Validation loss: 2.054766913255056

Epoch: 5| Step: 3
Training loss: 2.228968858718872
Validation loss: 2.0513275861740112

Epoch: 5| Step: 4
Training loss: 2.4100539684295654
Validation loss: 2.0474392622709274

Epoch: 5| Step: 5
Training loss: 2.5358099937438965
Validation loss: 2.0470772137244544

Epoch: 5| Step: 6
Training loss: 1.823237657546997
Validation loss: 2.0482544203599296

Epoch: 5| Step: 7
Training loss: 2.815988063812256
Validation loss: 2.0486209243535995

Epoch: 5| Step: 8
Training loss: 2.2673287391662598
Validation loss: 2.048679212729136

Epoch: 5| Step: 9
Training loss: 1.7153174877166748
Validation loss: 2.046609858671824

Epoch: 5| Step: 10
Training loss: 2.2287726402282715
Validation loss: 2.051519105831782

Epoch: 5| Step: 11
Training loss: 1.9063098430633545
Validation loss: 2.047016054391861

Epoch: 80| Step: 0
Training loss: 2.1168792247772217
Validation loss: 2.037875617543856

Epoch: 5| Step: 1
Training loss: 1.945680022239685
Validation loss: 2.039602115750313

Epoch: 5| Step: 2
Training loss: 2.1750669479370117
Validation loss: 2.0373206734657288

Epoch: 5| Step: 3
Training loss: 2.3364500999450684
Validation loss: 2.039572447538376

Epoch: 5| Step: 4
Training loss: 2.4705090522766113
Validation loss: 2.0377452621857324

Epoch: 5| Step: 5
Training loss: 2.4311747550964355
Validation loss: 2.0392995874087014

Epoch: 5| Step: 6
Training loss: 2.2945733070373535
Validation loss: 2.0400599340597787

Epoch: 5| Step: 7
Training loss: 2.263385057449341
Validation loss: 2.0373727728923163

Epoch: 5| Step: 8
Training loss: 2.1563358306884766
Validation loss: 2.037560378511747

Epoch: 5| Step: 9
Training loss: 2.428115129470825
Validation loss: 2.033728505174319

Epoch: 5| Step: 10
Training loss: 2.1605734825134277
Validation loss: 2.0372779071331024

Epoch: 5| Step: 11
Training loss: 1.0606915950775146
Validation loss: 2.035222366452217

Epoch: 81| Step: 0
Training loss: 2.075284957885742
Validation loss: 2.0366756866375604

Epoch: 5| Step: 1
Training loss: 2.0250978469848633
Validation loss: 2.034121811389923

Epoch: 5| Step: 2
Training loss: 2.108715772628784
Validation loss: 2.0316085467735925

Epoch: 5| Step: 3
Training loss: 2.6301109790802
Validation loss: 2.033510838945707

Epoch: 5| Step: 4
Training loss: 2.2151970863342285
Validation loss: 2.0353971123695374

Epoch: 5| Step: 5
Training loss: 2.185518980026245
Validation loss: 2.032061532139778

Epoch: 5| Step: 6
Training loss: 2.2460789680480957
Validation loss: 2.031253228584925

Epoch: 5| Step: 7
Training loss: 2.2183940410614014
Validation loss: 2.032883808016777

Epoch: 5| Step: 8
Training loss: 2.3466973304748535
Validation loss: 2.0350891600052514

Epoch: 5| Step: 9
Training loss: 2.4222521781921387
Validation loss: 2.0360538562138877

Epoch: 5| Step: 10
Training loss: 2.1233248710632324
Validation loss: 2.038798068960508

Epoch: 5| Step: 11
Training loss: 1.4291813373565674
Validation loss: 2.0411847829818726

Epoch: 82| Step: 0
Training loss: 2.1580348014831543
Validation loss: 2.042365849018097

Epoch: 5| Step: 1
Training loss: 1.6198447942733765
Validation loss: 2.0413612574338913

Epoch: 5| Step: 2
Training loss: 2.6983578205108643
Validation loss: 2.0340768148501716

Epoch: 5| Step: 3
Training loss: 2.0305376052856445
Validation loss: 2.0289074033498764

Epoch: 5| Step: 4
Training loss: 2.435544967651367
Validation loss: 2.0338383416334787

Epoch: 5| Step: 5
Training loss: 2.646190643310547
Validation loss: 2.0286567906538644

Epoch: 5| Step: 6
Training loss: 2.6951146125793457
Validation loss: 2.0291921446720758

Epoch: 5| Step: 7
Training loss: 2.160093307495117
Validation loss: 2.030333697795868

Epoch: 5| Step: 8
Training loss: 1.4431846141815186
Validation loss: 2.0309533129135766

Epoch: 5| Step: 9
Training loss: 2.5914058685302734
Validation loss: 2.034330000480016

Epoch: 5| Step: 10
Training loss: 1.917467474937439
Validation loss: 2.0344376415014267

Epoch: 5| Step: 11
Training loss: 2.2065682411193848
Validation loss: 2.031833599011103

Epoch: 83| Step: 0
Training loss: 2.220435857772827
Validation loss: 2.0235792994499207

Epoch: 5| Step: 1
Training loss: 2.2476096153259277
Validation loss: 2.028687765200933

Epoch: 5| Step: 2
Training loss: 2.011763095855713
Validation loss: 2.0177039355039597

Epoch: 5| Step: 3
Training loss: 2.0484507083892822
Validation loss: 2.0177924036979675

Epoch: 5| Step: 4
Training loss: 2.4273366928100586
Validation loss: 2.0315340558687844

Epoch: 5| Step: 5
Training loss: 2.6726040840148926
Validation loss: 2.0278960714737573

Epoch: 5| Step: 6
Training loss: 1.9598344564437866
Validation loss: 2.031945730249087

Epoch: 5| Step: 7
Training loss: 2.580155611038208
Validation loss: 2.029892439643542

Epoch: 5| Step: 8
Training loss: 2.257807493209839
Validation loss: 2.0254881381988525

Epoch: 5| Step: 9
Training loss: 2.2647478580474854
Validation loss: 2.022755205631256

Epoch: 5| Step: 10
Training loss: 1.4861564636230469
Validation loss: 2.0212421665589013

Epoch: 5| Step: 11
Training loss: 3.101931571960449
Validation loss: 2.0183633863925934

Epoch: 84| Step: 0
Training loss: 2.292771100997925
Validation loss: 2.023284857471784

Epoch: 5| Step: 1
Training loss: 2.477076292037964
Validation loss: 2.0278418262799582

Epoch: 5| Step: 2
Training loss: 2.428619861602783
Validation loss: 2.026204059521357

Epoch: 5| Step: 3
Training loss: 2.519749164581299
Validation loss: 2.031001259883245

Epoch: 5| Step: 4
Training loss: 2.2947793006896973
Validation loss: 2.034418508410454

Epoch: 5| Step: 5
Training loss: 2.224348545074463
Validation loss: 2.038720349470774

Epoch: 5| Step: 6
Training loss: 2.0423171520233154
Validation loss: 2.035688191652298

Epoch: 5| Step: 7
Training loss: 2.330888032913208
Validation loss: 2.036760558684667

Epoch: 5| Step: 8
Training loss: 1.656084418296814
Validation loss: 2.037620037794113

Epoch: 5| Step: 9
Training loss: 1.6465179920196533
Validation loss: 2.0323492536942163

Epoch: 5| Step: 10
Training loss: 2.3251843452453613
Validation loss: 2.0267082353432975

Epoch: 5| Step: 11
Training loss: 2.5186057090759277
Validation loss: 2.024337947368622

Epoch: 85| Step: 0
Training loss: 1.9699628353118896
Validation loss: 2.023172006011009

Epoch: 5| Step: 1
Training loss: 1.6293060779571533
Validation loss: 2.0216687421003976

Epoch: 5| Step: 2
Training loss: 2.4058237075805664
Validation loss: 2.024190957347552

Epoch: 5| Step: 3
Training loss: 1.9627517461776733
Validation loss: 2.0265070497989655

Epoch: 5| Step: 4
Training loss: 2.962921619415283
Validation loss: 2.0247409641742706

Epoch: 5| Step: 5
Training loss: 1.7705142498016357
Validation loss: 2.0228064507246017

Epoch: 5| Step: 6
Training loss: 1.8615165948867798
Validation loss: 2.021441305677096

Epoch: 5| Step: 7
Training loss: 2.5766515731811523
Validation loss: 2.0255627632141113

Epoch: 5| Step: 8
Training loss: 2.217014789581299
Validation loss: 2.019936223824819

Epoch: 5| Step: 9
Training loss: 2.6600475311279297
Validation loss: 2.0231052736441293

Epoch: 5| Step: 10
Training loss: 2.076326608657837
Validation loss: 2.021924411257108

Epoch: 5| Step: 11
Training loss: 2.881946563720703
Validation loss: 2.0236652195453644

Epoch: 86| Step: 0
Training loss: 2.530552387237549
Validation loss: 2.023027797540029

Epoch: 5| Step: 1
Training loss: 2.18005633354187
Validation loss: 2.0255991965532303

Epoch: 5| Step: 2
Training loss: 2.3990697860717773
Validation loss: 2.0235416988531747

Epoch: 5| Step: 3
Training loss: 2.40734601020813
Validation loss: 2.0207440008719764

Epoch: 5| Step: 4
Training loss: 1.6740375757217407
Validation loss: 2.0287004510561624

Epoch: 5| Step: 5
Training loss: 1.610672950744629
Validation loss: 2.027973880370458

Epoch: 5| Step: 6
Training loss: 2.2866950035095215
Validation loss: 2.0301613211631775

Epoch: 5| Step: 7
Training loss: 1.8692394495010376
Validation loss: 2.02998515466849

Epoch: 5| Step: 8
Training loss: 2.1261305809020996
Validation loss: 2.0260666062434516

Epoch: 5| Step: 9
Training loss: 2.6699650287628174
Validation loss: 2.02559628089269

Epoch: 5| Step: 10
Training loss: 2.280595302581787
Validation loss: 2.018746023376783

Epoch: 5| Step: 11
Training loss: 2.8883657455444336
Validation loss: 2.0173025876283646

Epoch: 87| Step: 0
Training loss: 2.286032199859619
Validation loss: 2.0242013235886893

Epoch: 5| Step: 1
Training loss: 1.4687391519546509
Validation loss: 2.0303413520256677

Epoch: 5| Step: 2
Training loss: 2.5306434631347656
Validation loss: 2.037073756257693

Epoch: 5| Step: 3
Training loss: 2.364997148513794
Validation loss: 2.0349281281232834

Epoch: 5| Step: 4
Training loss: 2.0716261863708496
Validation loss: 2.0359340409437814

Epoch: 5| Step: 5
Training loss: 1.9006859064102173
Validation loss: 2.041290963689486

Epoch: 5| Step: 6
Training loss: 2.2614479064941406
Validation loss: 2.037196561694145

Epoch: 5| Step: 7
Training loss: 2.6835131645202637
Validation loss: 2.0338246723016105

Epoch: 5| Step: 8
Training loss: 1.6716324090957642
Validation loss: 2.0222302824258804

Epoch: 5| Step: 9
Training loss: 2.2156472206115723
Validation loss: 2.024356206258138

Epoch: 5| Step: 10
Training loss: 2.602459669113159
Validation loss: 2.02506847679615

Epoch: 5| Step: 11
Training loss: 2.1980042457580566
Validation loss: 2.019190728664398

Epoch: 88| Step: 0
Training loss: 2.015489339828491
Validation loss: 2.014120747645696

Epoch: 5| Step: 1
Training loss: 2.509812831878662
Validation loss: 2.0144448975721994

Epoch: 5| Step: 2
Training loss: 1.7250959873199463
Validation loss: 2.0175699839989343

Epoch: 5| Step: 3
Training loss: 1.9323374032974243
Validation loss: 2.019771764675776

Epoch: 5| Step: 4
Training loss: 2.142336845397949
Validation loss: 2.024648313721021

Epoch: 5| Step: 5
Training loss: 1.848105788230896
Validation loss: 2.0184444884459176

Epoch: 5| Step: 6
Training loss: 2.4963834285736084
Validation loss: 2.0176744858423867

Epoch: 5| Step: 7
Training loss: 2.4854302406311035
Validation loss: 2.0281465897957482

Epoch: 5| Step: 8
Training loss: 2.536187171936035
Validation loss: 2.0201674550771713

Epoch: 5| Step: 9
Training loss: 2.1345772743225098
Validation loss: 2.024902954697609

Epoch: 5| Step: 10
Training loss: 2.0820040702819824
Validation loss: 2.019553696115812

Epoch: 5| Step: 11
Training loss: 2.7536089420318604
Validation loss: 2.019221156835556

Epoch: 89| Step: 0
Training loss: 1.7209666967391968
Validation loss: 2.0215751032034555

Epoch: 5| Step: 1
Training loss: 1.8660728931427002
Validation loss: 2.02028921743234

Epoch: 5| Step: 2
Training loss: 1.9363949298858643
Validation loss: 2.0221147189537683

Epoch: 5| Step: 3
Training loss: 2.818655490875244
Validation loss: 2.017956256866455

Epoch: 5| Step: 4
Training loss: 1.8607265949249268
Validation loss: 2.0252622018257775

Epoch: 5| Step: 5
Training loss: 2.0598464012145996
Validation loss: 2.023283297816912

Epoch: 5| Step: 6
Training loss: 2.475097179412842
Validation loss: 2.0176250636577606

Epoch: 5| Step: 7
Training loss: 2.096315860748291
Validation loss: 2.0227989504734674

Epoch: 5| Step: 8
Training loss: 2.067082643508911
Validation loss: 2.0164895157019296

Epoch: 5| Step: 9
Training loss: 2.353036880493164
Validation loss: 2.0167487313350043

Epoch: 5| Step: 10
Training loss: 2.4943089485168457
Validation loss: 2.0176892479260764

Epoch: 5| Step: 11
Training loss: 3.2944130897521973
Validation loss: 2.0125631590684256

Epoch: 90| Step: 0
Training loss: 1.820542573928833
Validation loss: 2.019979308048884

Epoch: 5| Step: 1
Training loss: 2.5730795860290527
Validation loss: 2.016897608836492

Epoch: 5| Step: 2
Training loss: 2.582475185394287
Validation loss: 2.0118850618600845

Epoch: 5| Step: 3
Training loss: 2.076219081878662
Validation loss: 2.0164371927579245

Epoch: 5| Step: 4
Training loss: 2.0027225017547607
Validation loss: 2.010001932581266

Epoch: 5| Step: 5
Training loss: 2.4846420288085938
Validation loss: 2.015056605140368

Epoch: 5| Step: 6
Training loss: 1.8279409408569336
Validation loss: 2.0124672005573907

Epoch: 5| Step: 7
Training loss: 1.8610280752182007
Validation loss: 2.013299271464348

Epoch: 5| Step: 8
Training loss: 2.3756301403045654
Validation loss: 2.0122065444787345

Epoch: 5| Step: 9
Training loss: 2.13291335105896
Validation loss: 2.0098347763220468

Epoch: 5| Step: 10
Training loss: 2.038846254348755
Validation loss: 2.017566978931427

Epoch: 5| Step: 11
Training loss: 2.9036366939544678
Validation loss: 2.0102968364953995

Epoch: 91| Step: 0
Training loss: 2.304018497467041
Validation loss: 2.0101097176472345

Epoch: 5| Step: 1
Training loss: 2.6906440258026123
Validation loss: 2.0186994870503745

Epoch: 5| Step: 2
Training loss: 1.7015939950942993
Validation loss: 2.0146402468283973

Epoch: 5| Step: 3
Training loss: 1.844605803489685
Validation loss: 2.0199993352095285

Epoch: 5| Step: 4
Training loss: 1.9046661853790283
Validation loss: 2.0160320848226547

Epoch: 5| Step: 5
Training loss: 2.3946826457977295
Validation loss: 2.020925218860308

Epoch: 5| Step: 6
Training loss: 2.506282091140747
Validation loss: 2.0183458775281906

Epoch: 5| Step: 7
Training loss: 2.043388843536377
Validation loss: 2.0201503733793893

Epoch: 5| Step: 8
Training loss: 2.0099170207977295
Validation loss: 2.0244776755571365

Epoch: 5| Step: 9
Training loss: 2.2376654148101807
Validation loss: 2.026286313931147

Epoch: 5| Step: 10
Training loss: 2.505068302154541
Validation loss: 2.017897521456083

Epoch: 5| Step: 11
Training loss: 0.6098501086235046
Validation loss: 2.0226241747538247

Epoch: 92| Step: 0
Training loss: 2.2458438873291016
Validation loss: 2.0144259184598923

Epoch: 5| Step: 1
Training loss: 2.2359976768493652
Validation loss: 2.012698233127594

Epoch: 5| Step: 2
Training loss: 1.9030195474624634
Validation loss: 2.0143654892841973

Epoch: 5| Step: 3
Training loss: 1.9886516332626343
Validation loss: 2.0113037526607513

Epoch: 5| Step: 4
Training loss: 1.9658229351043701
Validation loss: 2.0150200525919595

Epoch: 5| Step: 5
Training loss: 2.1581451892852783
Validation loss: 2.012536490956942

Epoch: 5| Step: 6
Training loss: 2.4909987449645996
Validation loss: 2.015230933825175

Epoch: 5| Step: 7
Training loss: 2.304351329803467
Validation loss: 2.0124190797408423

Epoch: 5| Step: 8
Training loss: 2.453911304473877
Validation loss: 2.0126720319191613

Epoch: 5| Step: 9
Training loss: 2.1864235401153564
Validation loss: 2.0157578537861505

Epoch: 5| Step: 10
Training loss: 1.7035859823226929
Validation loss: 2.0099851240714393

Epoch: 5| Step: 11
Training loss: 3.1926634311676025
Validation loss: 2.0148664116859436

Epoch: 93| Step: 0
Training loss: 2.5477700233459473
Validation loss: 2.014236534635226

Epoch: 5| Step: 1
Training loss: 2.0307343006134033
Validation loss: 2.014400968949

Epoch: 5| Step: 2
Training loss: 2.4974400997161865
Validation loss: 2.0152254005273185

Epoch: 5| Step: 3
Training loss: 1.9495693445205688
Validation loss: 2.018560806910197

Epoch: 5| Step: 4
Training loss: 2.5647473335266113
Validation loss: 2.0175986687342324

Epoch: 5| Step: 5
Training loss: 1.6738483905792236
Validation loss: 2.019740159312884

Epoch: 5| Step: 6
Training loss: 2.005664110183716
Validation loss: 2.023616830507914

Epoch: 5| Step: 7
Training loss: 2.4625613689422607
Validation loss: 2.029350454608599

Epoch: 5| Step: 8
Training loss: 1.9949944019317627
Validation loss: 2.032399043440819

Epoch: 5| Step: 9
Training loss: 1.654906988143921
Validation loss: 2.032334973414739

Epoch: 5| Step: 10
Training loss: 2.161501884460449
Validation loss: 2.0346084435780845

Epoch: 5| Step: 11
Training loss: 2.8295130729675293
Validation loss: 2.034875839948654

Epoch: 94| Step: 0
Training loss: 1.7096267938613892
Validation loss: 2.029644767443339

Epoch: 5| Step: 1
Training loss: 2.119920492172241
Validation loss: 2.0359835028648376

Epoch: 5| Step: 2
Training loss: 2.138413667678833
Validation loss: 2.0314539472262063

Epoch: 5| Step: 3
Training loss: 2.0202841758728027
Validation loss: 2.0319223503271737

Epoch: 5| Step: 4
Training loss: 2.4400649070739746
Validation loss: 2.0344623078902564

Epoch: 5| Step: 5
Training loss: 2.003040313720703
Validation loss: 2.0319604525963464

Epoch: 5| Step: 6
Training loss: 2.1133334636688232
Validation loss: 2.0265829265117645

Epoch: 5| Step: 7
Training loss: 2.362980365753174
Validation loss: 2.023395280043284

Epoch: 5| Step: 8
Training loss: 2.559591293334961
Validation loss: 2.023257151246071

Epoch: 5| Step: 9
Training loss: 2.3138747215270996
Validation loss: 2.034224589665731

Epoch: 5| Step: 10
Training loss: 1.8764331340789795
Validation loss: 2.0222190618515015

Epoch: 5| Step: 11
Training loss: 2.0794878005981445
Validation loss: 2.0230740954478583

Epoch: 95| Step: 0
Training loss: 2.371328353881836
Validation loss: 2.018151472012202

Epoch: 5| Step: 1
Training loss: 1.808249831199646
Validation loss: 2.0221631824970245

Epoch: 5| Step: 2
Training loss: 2.090284585952759
Validation loss: 2.022947207093239

Epoch: 5| Step: 3
Training loss: 2.298766613006592
Validation loss: 2.0200565407673516

Epoch: 5| Step: 4
Training loss: 2.421670913696289
Validation loss: 2.021864101290703

Epoch: 5| Step: 5
Training loss: 1.7234214544296265
Validation loss: 2.020782376329104

Epoch: 5| Step: 6
Training loss: 1.902017593383789
Validation loss: 2.015614385406176

Epoch: 5| Step: 7
Training loss: 1.7787597179412842
Validation loss: 2.0163505375385284

Epoch: 5| Step: 8
Training loss: 2.8091509342193604
Validation loss: 2.029541323582331

Epoch: 5| Step: 9
Training loss: 2.3373467922210693
Validation loss: 2.0330943961938224

Epoch: 5| Step: 10
Training loss: 2.462860345840454
Validation loss: 2.0395620514949164

Epoch: 5| Step: 11
Training loss: 2.0274996757507324
Validation loss: 2.038941279053688

Epoch: 96| Step: 0
Training loss: 2.669844388961792
Validation loss: 2.014948457479477

Epoch: 5| Step: 1
Training loss: 2.0128939151763916
Validation loss: 2.0120351165533066

Epoch: 5| Step: 2
Training loss: 1.3706649541854858
Validation loss: 2.006137470404307

Epoch: 5| Step: 3
Training loss: 2.468061923980713
Validation loss: 2.0087608794371286

Epoch: 5| Step: 4
Training loss: 2.590716600418091
Validation loss: 2.0134511093298593

Epoch: 5| Step: 5
Training loss: 1.6385126113891602
Validation loss: 2.010066270828247

Epoch: 5| Step: 6
Training loss: 2.809483528137207
Validation loss: 2.0142119278510413

Epoch: 5| Step: 7
Training loss: 2.3951404094696045
Validation loss: 2.0114394575357437

Epoch: 5| Step: 8
Training loss: 2.210127353668213
Validation loss: 2.0040947099526725

Epoch: 5| Step: 9
Training loss: 1.9560928344726562
Validation loss: 2.008130302031835

Epoch: 5| Step: 10
Training loss: 1.9759079217910767
Validation loss: 2.004891723394394

Epoch: 5| Step: 11
Training loss: 1.2631173133850098
Validation loss: 2.0048465182383857

Epoch: 97| Step: 0
Training loss: 1.86093008518219
Validation loss: 2.013562187552452

Epoch: 5| Step: 1
Training loss: 2.469701051712036
Validation loss: 2.028655414779981

Epoch: 5| Step: 2
Training loss: 2.117213726043701
Validation loss: 2.0226915180683136

Epoch: 5| Step: 3
Training loss: 2.3369364738464355
Validation loss: 2.0257368783156076

Epoch: 5| Step: 4
Training loss: 1.9677913188934326
Validation loss: 2.0304634074370065

Epoch: 5| Step: 5
Training loss: 2.1844232082366943
Validation loss: 2.0284623901049295

Epoch: 5| Step: 6
Training loss: 1.6210968494415283
Validation loss: 2.035930643479029

Epoch: 5| Step: 7
Training loss: 2.41676664352417
Validation loss: 2.038264830907186

Epoch: 5| Step: 8
Training loss: 2.5356311798095703
Validation loss: 2.0338725795348487

Epoch: 5| Step: 9
Training loss: 2.464404821395874
Validation loss: 2.0242171734571457

Epoch: 5| Step: 10
Training loss: 1.9030259847640991
Validation loss: 2.021201873819033

Epoch: 5| Step: 11
Training loss: 1.97246253490448
Validation loss: 2.0103478829065957

Epoch: 98| Step: 0
Training loss: 2.3803157806396484
Validation loss: 2.017865866422653

Epoch: 5| Step: 1
Training loss: 2.186568021774292
Validation loss: 2.006011192997297

Epoch: 5| Step: 2
Training loss: 2.462343454360962
Validation loss: 2.0135744363069534

Epoch: 5| Step: 3
Training loss: 1.9553314447402954
Validation loss: 2.0090368638436

Epoch: 5| Step: 4
Training loss: 2.1249759197235107
Validation loss: 2.009796768426895

Epoch: 5| Step: 5
Training loss: 1.5703761577606201
Validation loss: 2.0110064248243966

Epoch: 5| Step: 6
Training loss: 1.9762274026870728
Validation loss: 2.012391358613968

Epoch: 5| Step: 7
Training loss: 1.999608039855957
Validation loss: 2.0161151736974716

Epoch: 5| Step: 8
Training loss: 1.8065942525863647
Validation loss: 2.0263331731160483

Epoch: 5| Step: 9
Training loss: 2.3057608604431152
Validation loss: 2.0292809456586838

Epoch: 5| Step: 10
Training loss: 2.9154279232025146
Validation loss: 2.0195801109075546

Epoch: 5| Step: 11
Training loss: 2.429079294204712
Validation loss: 2.011640787124634

Epoch: 99| Step: 0
Training loss: 2.1457977294921875
Validation loss: 2.0170594354470572

Epoch: 5| Step: 1
Training loss: 1.6024833917617798
Validation loss: 2.004412457346916

Epoch: 5| Step: 2
Training loss: 2.5036909580230713
Validation loss: 2.0067755579948425

Epoch: 5| Step: 3
Training loss: 1.9803993701934814
Validation loss: 2.0098706632852554

Epoch: 5| Step: 4
Training loss: 2.5767109394073486
Validation loss: 2.0085591872533164

Epoch: 5| Step: 5
Training loss: 1.979740858078003
Validation loss: 2.0134842743476233

Epoch: 5| Step: 6
Training loss: 2.186619281768799
Validation loss: 2.0080136209726334

Epoch: 5| Step: 7
Training loss: 2.7393882274627686
Validation loss: 2.006213625272115

Epoch: 5| Step: 8
Training loss: 2.0633602142333984
Validation loss: 2.016586586833

Epoch: 5| Step: 9
Training loss: 2.253488540649414
Validation loss: 2.0168675084908805

Epoch: 5| Step: 10
Training loss: 1.8029438257217407
Validation loss: 2.0161518106857934

Epoch: 5| Step: 11
Training loss: 1.2973456382751465
Validation loss: 2.019002914428711

Epoch: 100| Step: 0
Training loss: 2.3157410621643066
Validation loss: 2.0208896348873773

Epoch: 5| Step: 1
Training loss: 2.494814157485962
Validation loss: 2.0201300432284675

Epoch: 5| Step: 2
Training loss: 2.5525741577148438
Validation loss: 2.0221325705448785

Epoch: 5| Step: 3
Training loss: 1.982111930847168
Validation loss: 2.0250857522090278

Epoch: 5| Step: 4
Training loss: 1.9170528650283813
Validation loss: 2.028522695104281

Epoch: 5| Step: 5
Training loss: 2.0489838123321533
Validation loss: 2.0214062134424844

Epoch: 5| Step: 6
Training loss: 1.9083770513534546
Validation loss: 2.0216818352540336

Epoch: 5| Step: 7
Training loss: 1.735704779624939
Validation loss: 2.0196631103754044

Epoch: 5| Step: 8
Training loss: 2.028607130050659
Validation loss: 2.0138403922319412

Epoch: 5| Step: 9
Training loss: 2.2130656242370605
Validation loss: 2.0119204421838126

Epoch: 5| Step: 10
Training loss: 2.2812836170196533
Validation loss: 2.0173787673314414

Epoch: 5| Step: 11
Training loss: 2.3992929458618164
Validation loss: 2.0177907894055047

Epoch: 101| Step: 0
Training loss: 2.244924783706665
Validation loss: 2.0179120004177094

Epoch: 5| Step: 1
Training loss: 2.4121601581573486
Validation loss: 2.0061655044555664

Epoch: 5| Step: 2
Training loss: 1.9174083471298218
Validation loss: 2.007408852378527

Epoch: 5| Step: 3
Training loss: 2.3297295570373535
Validation loss: 2.0065661867459617

Epoch: 5| Step: 4
Training loss: 1.9752986431121826
Validation loss: 2.014969681700071

Epoch: 5| Step: 5
Training loss: 1.9835789203643799
Validation loss: 2.0135192622741065

Epoch: 5| Step: 6
Training loss: 2.034904956817627
Validation loss: 2.0206419825553894

Epoch: 5| Step: 7
Training loss: 1.7972532510757446
Validation loss: 2.0112371991078057

Epoch: 5| Step: 8
Training loss: 2.4386839866638184
Validation loss: 2.0080333004395166

Epoch: 5| Step: 9
Training loss: 2.574446678161621
Validation loss: 2.008263796567917

Epoch: 5| Step: 10
Training loss: 2.0693554878234863
Validation loss: 2.005284547805786

Epoch: 5| Step: 11
Training loss: 1.7591757774353027
Validation loss: 2.0023289918899536

Epoch: 102| Step: 0
Training loss: 2.5483834743499756
Validation loss: 2.0034161508083344

Epoch: 5| Step: 1
Training loss: 1.9320217370986938
Validation loss: 2.002132003506025

Epoch: 5| Step: 2
Training loss: 2.430724620819092
Validation loss: 2.0045132637023926

Epoch: 5| Step: 3
Training loss: 1.9960014820098877
Validation loss: 2.0007986625035605

Epoch: 5| Step: 4
Training loss: 2.155015707015991
Validation loss: 2.0056408693393073

Epoch: 5| Step: 5
Training loss: 2.143630266189575
Validation loss: 2.002050518989563

Epoch: 5| Step: 6
Training loss: 2.4351003170013428
Validation loss: 2.0025258461634317

Epoch: 5| Step: 7
Training loss: 1.850870132446289
Validation loss: 2.0048604706923165

Epoch: 5| Step: 8
Training loss: 1.8309948444366455
Validation loss: 2.00681604941686

Epoch: 5| Step: 9
Training loss: 1.417044758796692
Validation loss: 2.0094600220521293

Epoch: 5| Step: 10
Training loss: 2.5214450359344482
Validation loss: 2.0180490662654242

Epoch: 5| Step: 11
Training loss: 3.665884494781494
Validation loss: 2.0258258332808814

Epoch: 103| Step: 0
Training loss: 2.414472818374634
Validation loss: 2.0232654561599097

Epoch: 5| Step: 1
Training loss: 1.5128058195114136
Validation loss: 2.021642252802849

Epoch: 5| Step: 2
Training loss: 2.028904914855957
Validation loss: 2.0225915163755417

Epoch: 5| Step: 3
Training loss: 1.8593900203704834
Validation loss: 2.0210086554288864

Epoch: 5| Step: 4
Training loss: 2.189650535583496
Validation loss: 2.0222311466932297

Epoch: 5| Step: 5
Training loss: 2.252358913421631
Validation loss: 2.0163391331831613

Epoch: 5| Step: 6
Training loss: 2.6240992546081543
Validation loss: 2.018320952852567

Epoch: 5| Step: 7
Training loss: 1.804455041885376
Validation loss: 2.015743543704351

Epoch: 5| Step: 8
Training loss: 2.5478458404541016
Validation loss: 2.0137095053990683

Epoch: 5| Step: 9
Training loss: 2.277578115463257
Validation loss: 2.022766575217247

Epoch: 5| Step: 10
Training loss: 2.1428184509277344
Validation loss: 2.0138363440831504

Epoch: 5| Step: 11
Training loss: 2.1667656898498535
Validation loss: 2.014973650376002

Epoch: 104| Step: 0
Training loss: 1.6723521947860718
Validation loss: 2.0173880209525428

Epoch: 5| Step: 1
Training loss: 1.8169151544570923
Validation loss: 2.0313315292199454

Epoch: 5| Step: 2
Training loss: 2.417203426361084
Validation loss: 2.0339364310105643

Epoch: 5| Step: 3
Training loss: 2.037393093109131
Validation loss: 2.0309456239144006

Epoch: 5| Step: 4
Training loss: 2.344176769256592
Validation loss: 2.0409963627656302

Epoch: 5| Step: 5
Training loss: 2.0756192207336426
Validation loss: 2.045811469356219

Epoch: 5| Step: 6
Training loss: 2.219287395477295
Validation loss: 2.0622881899277368

Epoch: 5| Step: 7
Training loss: 2.1927502155303955
Validation loss: 2.0447576145331063

Epoch: 5| Step: 8
Training loss: 2.237417697906494
Validation loss: 2.0493499487638474

Epoch: 5| Step: 9
Training loss: 2.3344175815582275
Validation loss: 2.0379722068707147

Epoch: 5| Step: 10
Training loss: 2.5022599697113037
Validation loss: 2.0412652591864267

Epoch: 5| Step: 11
Training loss: 2.102307081222534
Validation loss: 2.027277539173762

Epoch: 105| Step: 0
Training loss: 1.731968879699707
Validation loss: 2.0279771288235984

Epoch: 5| Step: 1
Training loss: 2.923537254333496
Validation loss: 2.020548164844513

Epoch: 5| Step: 2
Training loss: 2.1435070037841797
Validation loss: 2.011744504173597

Epoch: 5| Step: 3
Training loss: 1.8999662399291992
Validation loss: 2.014148791631063

Epoch: 5| Step: 4
Training loss: 2.8609111309051514
Validation loss: 2.015678197145462

Epoch: 5| Step: 5
Training loss: 1.915268898010254
Validation loss: 2.0143524507681527

Epoch: 5| Step: 6
Training loss: 2.3019022941589355
Validation loss: 2.017116074760755

Epoch: 5| Step: 7
Training loss: 2.0652804374694824
Validation loss: 2.0210459182659783

Epoch: 5| Step: 8
Training loss: 1.3623580932617188
Validation loss: 2.017748847603798

Epoch: 5| Step: 9
Training loss: 2.4154887199401855
Validation loss: 2.01216122508049

Epoch: 5| Step: 10
Training loss: 1.9726359844207764
Validation loss: 2.010975937048594

Epoch: 5| Step: 11
Training loss: 2.9981279373168945
Validation loss: 2.005826766292254

Epoch: 106| Step: 0
Training loss: 2.263439893722534
Validation loss: 2.008046180009842

Epoch: 5| Step: 1
Training loss: 1.7216523885726929
Validation loss: 2.0070708642403283

Epoch: 5| Step: 2
Training loss: 2.4304332733154297
Validation loss: 2.014813169836998

Epoch: 5| Step: 3
Training loss: 2.4473533630371094
Validation loss: 2.0111108670632043

Epoch: 5| Step: 4
Training loss: 2.099174737930298
Validation loss: 2.014928196867307

Epoch: 5| Step: 5
Training loss: 2.0103111267089844
Validation loss: 2.0268315275510154

Epoch: 5| Step: 6
Training loss: 1.8297169208526611
Validation loss: 2.0266793022553125

Epoch: 5| Step: 7
Training loss: 1.5265309810638428
Validation loss: 2.022077962756157

Epoch: 5| Step: 8
Training loss: 2.0040078163146973
Validation loss: 2.0271880626678467

Epoch: 5| Step: 9
Training loss: 2.5029473304748535
Validation loss: 2.0254218180974326

Epoch: 5| Step: 10
Training loss: 2.5649025440216064
Validation loss: 2.0191920349995294

Epoch: 5| Step: 11
Training loss: 3.4154725074768066
Validation loss: 2.016175091266632

Epoch: 107| Step: 0
Training loss: 2.673241138458252
Validation loss: 2.013699601093928

Epoch: 5| Step: 1
Training loss: 1.787027359008789
Validation loss: 2.0119716922442117

Epoch: 5| Step: 2
Training loss: 1.8867228031158447
Validation loss: 2.0027537246545157

Epoch: 5| Step: 3
Training loss: 2.259523391723633
Validation loss: 1.9998426487048466

Epoch: 5| Step: 4
Training loss: 2.164276599884033
Validation loss: 2.001727526386579

Epoch: 5| Step: 5
Training loss: 2.020728349685669
Validation loss: 1.9994470377763112

Epoch: 5| Step: 6
Training loss: 2.5346813201904297
Validation loss: 2.003382051984469

Epoch: 5| Step: 7
Training loss: 1.5724698305130005
Validation loss: 2.005810037255287

Epoch: 5| Step: 8
Training loss: 2.3164405822753906
Validation loss: 1.998712529738744

Epoch: 5| Step: 9
Training loss: 2.160165309906006
Validation loss: 2.0033504168192544

Epoch: 5| Step: 10
Training loss: 2.336940050125122
Validation loss: 2.0084984997908273

Epoch: 5| Step: 11
Training loss: 1.6394028663635254
Validation loss: 2.009491190314293

Epoch: 108| Step: 0
Training loss: 2.1036908626556396
Validation loss: 2.0203643242518106

Epoch: 5| Step: 1
Training loss: 2.1307568550109863
Validation loss: 2.021319026748339

Epoch: 5| Step: 2
Training loss: 1.8562389612197876
Validation loss: 2.019617219765981

Epoch: 5| Step: 3
Training loss: 2.0939974784851074
Validation loss: 2.0218733896811805

Epoch: 5| Step: 4
Training loss: 1.8626158237457275
Validation loss: 2.0153724749883017

Epoch: 5| Step: 5
Training loss: 2.4002156257629395
Validation loss: 2.030852402249972

Epoch: 5| Step: 6
Training loss: 1.9476381540298462
Validation loss: 2.040027226010958

Epoch: 5| Step: 7
Training loss: 2.0495991706848145
Validation loss: 2.0287186205387115

Epoch: 5| Step: 8
Training loss: 2.9252657890319824
Validation loss: 2.0293185114860535

Epoch: 5| Step: 9
Training loss: 1.9699188470840454
Validation loss: 2.0276512255271277

Epoch: 5| Step: 10
Training loss: 2.4785454273223877
Validation loss: 2.026737521092097

Epoch: 5| Step: 11
Training loss: 0.46379053592681885
Validation loss: 2.0194745659828186

Epoch: 109| Step: 0
Training loss: 1.9644854068756104
Validation loss: 2.0177622586488724

Epoch: 5| Step: 1
Training loss: 2.2583882808685303
Validation loss: 2.0136173367500305

Epoch: 5| Step: 2
Training loss: 2.096238613128662
Validation loss: 2.013502220312754

Epoch: 5| Step: 3
Training loss: 2.3499672412872314
Validation loss: 2.011742273966471

Epoch: 5| Step: 4
Training loss: 1.847590446472168
Validation loss: 2.0212151557207108

Epoch: 5| Step: 5
Training loss: 2.3248391151428223
Validation loss: 2.0178379267454147

Epoch: 5| Step: 6
Training loss: 2.633981943130493
Validation loss: 2.0197091102600098

Epoch: 5| Step: 7
Training loss: 1.7053381204605103
Validation loss: 2.022103692094485

Epoch: 5| Step: 8
Training loss: 1.9183290004730225
Validation loss: 2.0174374083677926

Epoch: 5| Step: 9
Training loss: 2.426091432571411
Validation loss: 2.016355479756991

Epoch: 5| Step: 10
Training loss: 2.2339749336242676
Validation loss: 2.0097948213418326

Epoch: 5| Step: 11
Training loss: 1.858216643333435
Validation loss: 2.0069193840026855

Epoch: 110| Step: 0
Training loss: 2.1238162517547607
Validation loss: 2.0044100284576416

Epoch: 5| Step: 1
Training loss: 2.52034068107605
Validation loss: 2.007361426949501

Epoch: 5| Step: 2
Training loss: 2.1059319972991943
Validation loss: 2.012709637482961

Epoch: 5| Step: 3
Training loss: 2.180992603302002
Validation loss: 2.014479527870814

Epoch: 5| Step: 4
Training loss: 2.100844383239746
Validation loss: 2.0209008554617562

Epoch: 5| Step: 5
Training loss: 1.9917100667953491
Validation loss: 2.0249232947826385

Epoch: 5| Step: 6
Training loss: 2.1614465713500977
Validation loss: 2.0116714040438333

Epoch: 5| Step: 7
Training loss: 1.7006816864013672
Validation loss: 2.0200719286998114

Epoch: 5| Step: 8
Training loss: 2.33935284614563
Validation loss: 2.0160077611605325

Epoch: 5| Step: 9
Training loss: 2.2485079765319824
Validation loss: 2.0142621050278344

Epoch: 5| Step: 10
Training loss: 2.145796537399292
Validation loss: 2.0180001060167947

Epoch: 5| Step: 11
Training loss: 1.9626133441925049
Validation loss: 2.0159598092238107

Epoch: 111| Step: 0
Training loss: 2.4916911125183105
Validation loss: 2.0087770521640778

Epoch: 5| Step: 1
Training loss: 2.2268614768981934
Validation loss: 2.009954368074735

Epoch: 5| Step: 2
Training loss: 1.843924880027771
Validation loss: 2.019975225130717

Epoch: 5| Step: 3
Training loss: 1.866471290588379
Validation loss: 2.015350172917048

Epoch: 5| Step: 4
Training loss: 1.4523999691009521
Validation loss: 2.0130389084418616

Epoch: 5| Step: 5
Training loss: 2.496129274368286
Validation loss: 2.009339908758799

Epoch: 5| Step: 6
Training loss: 2.2182469367980957
Validation loss: 2.010234519839287

Epoch: 5| Step: 7
Training loss: 2.1340785026550293
Validation loss: 1.999586875240008

Epoch: 5| Step: 8
Training loss: 2.4997646808624268
Validation loss: 2.008096014459928

Epoch: 5| Step: 9
Training loss: 2.4192276000976562
Validation loss: 2.012114033102989

Epoch: 5| Step: 10
Training loss: 1.7324508428573608
Validation loss: 2.006096879641215

Epoch: 5| Step: 11
Training loss: 2.18399977684021
Validation loss: 2.0064073453346887

Epoch: 112| Step: 0
Training loss: 1.8113330602645874
Validation loss: 2.013883332411448

Epoch: 5| Step: 1
Training loss: 1.850219488143921
Validation loss: 2.0237738887468972

Epoch: 5| Step: 2
Training loss: 1.813103437423706
Validation loss: 2.0260863850514093

Epoch: 5| Step: 3
Training loss: 2.3015217781066895
Validation loss: 2.045015419522921

Epoch: 5| Step: 4
Training loss: 2.9069840908050537
Validation loss: 2.0299994349479675

Epoch: 5| Step: 5
Training loss: 2.1700589656829834
Validation loss: 2.031513129671415

Epoch: 5| Step: 6
Training loss: 1.8053417205810547
Validation loss: 2.0289636154969535

Epoch: 5| Step: 7
Training loss: 2.1279194355010986
Validation loss: 2.0256331712007523

Epoch: 5| Step: 8
Training loss: 2.9183859825134277
Validation loss: 2.0296966085831323

Epoch: 5| Step: 9
Training loss: 1.9782583713531494
Validation loss: 2.0153916279474893

Epoch: 5| Step: 10
Training loss: 1.9235312938690186
Validation loss: 2.0183251947164536

Epoch: 5| Step: 11
Training loss: 2.8360214233398438
Validation loss: 2.01338400443395

Epoch: 113| Step: 0
Training loss: 2.4638915061950684
Validation loss: 2.002302890022596

Epoch: 5| Step: 1
Training loss: 1.7906911373138428
Validation loss: 2.0078564137220383

Epoch: 5| Step: 2
Training loss: 1.7838590145111084
Validation loss: 1.9995995710293453

Epoch: 5| Step: 3
Training loss: 2.0313096046447754
Validation loss: 2.006057654817899

Epoch: 5| Step: 4
Training loss: 1.9389976263046265
Validation loss: 2.003269076347351

Epoch: 5| Step: 5
Training loss: 2.488891124725342
Validation loss: 2.008471076687177

Epoch: 5| Step: 6
Training loss: 2.2990686893463135
Validation loss: 2.0051267047723136

Epoch: 5| Step: 7
Training loss: 2.2469706535339355
Validation loss: 2.013703927397728

Epoch: 5| Step: 8
Training loss: 2.4636528491973877
Validation loss: 2.0020284752051034

Epoch: 5| Step: 9
Training loss: 2.1785387992858887
Validation loss: 2.0051280707120895

Epoch: 5| Step: 10
Training loss: 1.8573119640350342
Validation loss: 2.0074856827656427

Epoch: 5| Step: 11
Training loss: 2.836104154586792
Validation loss: 2.001801391442617

Epoch: 114| Step: 0
Training loss: 2.333730697631836
Validation loss: 1.9994190434614818

Epoch: 5| Step: 1
Training loss: 1.758850336074829
Validation loss: 2.002176155646642

Epoch: 5| Step: 2
Training loss: 1.948835015296936
Validation loss: 2.009666924675306

Epoch: 5| Step: 3
Training loss: 2.399178981781006
Validation loss: 2.0086423506339393

Epoch: 5| Step: 4
Training loss: 2.0661303997039795
Validation loss: 2.0132254312435784

Epoch: 5| Step: 5
Training loss: 2.3600401878356934
Validation loss: 2.0061795065800347

Epoch: 5| Step: 6
Training loss: 2.20176362991333
Validation loss: 2.011945257584254

Epoch: 5| Step: 7
Training loss: 1.809061050415039
Validation loss: 2.016445577144623

Epoch: 5| Step: 8
Training loss: 2.2575910091400146
Validation loss: 2.0108665923277536

Epoch: 5| Step: 9
Training loss: 1.8989006280899048
Validation loss: 2.0076376497745514

Epoch: 5| Step: 10
Training loss: 2.356318950653076
Validation loss: 2.007594421505928

Epoch: 5| Step: 11
Training loss: 1.9093575477600098
Validation loss: 2.007903963327408

Epoch: 115| Step: 0
Training loss: 2.283914566040039
Validation loss: 2.0127999633550644

Epoch: 5| Step: 1
Training loss: 1.8240283727645874
Validation loss: 2.020124390721321

Epoch: 5| Step: 2
Training loss: 2.4319775104522705
Validation loss: 2.0448385874430337

Epoch: 5| Step: 3
Training loss: 2.0290274620056152
Validation loss: 2.039848114053408

Epoch: 5| Step: 4
Training loss: 2.463252305984497
Validation loss: 2.0420624762773514

Epoch: 5| Step: 5
Training loss: 1.8233855962753296
Validation loss: 2.028232991695404

Epoch: 5| Step: 6
Training loss: 1.8074992895126343
Validation loss: 2.0215494533379874

Epoch: 5| Step: 7
Training loss: 2.2149689197540283
Validation loss: 2.008315314849218

Epoch: 5| Step: 8
Training loss: 2.8312933444976807
Validation loss: 2.000689556201299

Epoch: 5| Step: 9
Training loss: 2.0199973583221436
Validation loss: 1.9999563197294872

Epoch: 5| Step: 10
Training loss: 1.9719932079315186
Validation loss: 1.99045596520106

Epoch: 5| Step: 11
Training loss: 2.417288303375244
Validation loss: 1.9929215908050537

Epoch: 116| Step: 0
Training loss: 2.1919047832489014
Validation loss: 1.9901069949070613

Epoch: 5| Step: 1
Training loss: 2.367973804473877
Validation loss: 2.000234226385752

Epoch: 5| Step: 2
Training loss: 2.1919000148773193
Validation loss: 2.000953714052836

Epoch: 5| Step: 3
Training loss: 2.3582773208618164
Validation loss: 2.0074168145656586

Epoch: 5| Step: 4
Training loss: 2.3321235179901123
Validation loss: 2.017765243848165

Epoch: 5| Step: 5
Training loss: 2.2077810764312744
Validation loss: 2.0095235258340836

Epoch: 5| Step: 6
Training loss: 2.140559673309326
Validation loss: 2.008213371038437

Epoch: 5| Step: 7
Training loss: 1.5886896848678589
Validation loss: 2.009219522277514

Epoch: 5| Step: 8
Training loss: 1.9560083150863647
Validation loss: 2.005819966395696

Epoch: 5| Step: 9
Training loss: 1.8238475322723389
Validation loss: 2.0014022886753082

Epoch: 5| Step: 10
Training loss: 2.3304288387298584
Validation loss: 2.0056888361771903

Epoch: 5| Step: 11
Training loss: 3.034334182739258
Validation loss: 1.9993109852075577

Epoch: 117| Step: 0
Training loss: 1.7970510721206665
Validation loss: 2.000084107120832

Epoch: 5| Step: 1
Training loss: 1.8213260173797607
Validation loss: 2.0067466646432877

Epoch: 5| Step: 2
Training loss: 1.817609429359436
Validation loss: 2.014478867252668

Epoch: 5| Step: 3
Training loss: 2.413632392883301
Validation loss: 2.0145765791336694

Epoch: 5| Step: 4
Training loss: 2.540415048599243
Validation loss: 2.0139574110507965

Epoch: 5| Step: 5
Training loss: 1.819079041481018
Validation loss: 2.0185771038134894

Epoch: 5| Step: 6
Training loss: 2.260038137435913
Validation loss: 2.0111265629529953

Epoch: 5| Step: 7
Training loss: 2.63220477104187
Validation loss: 2.0157767981290817

Epoch: 5| Step: 8
Training loss: 1.851771593093872
Validation loss: 2.022199114163717

Epoch: 5| Step: 9
Training loss: 2.0887341499328613
Validation loss: 2.0164407889048257

Epoch: 5| Step: 10
Training loss: 2.332714796066284
Validation loss: 2.011210153500239

Epoch: 5| Step: 11
Training loss: 1.6102983951568604
Validation loss: 2.0227501740058265

Epoch: 118| Step: 0
Training loss: 2.1025278568267822
Validation loss: 2.0244845747947693

Epoch: 5| Step: 1
Training loss: 2.526672840118408
Validation loss: 2.0267874002456665

Epoch: 5| Step: 2
Training loss: 1.9026035070419312
Validation loss: 2.027565822005272

Epoch: 5| Step: 3
Training loss: 2.334603786468506
Validation loss: 2.0224728484948478

Epoch: 5| Step: 4
Training loss: 1.8380498886108398
Validation loss: 2.021475230654081

Epoch: 5| Step: 5
Training loss: 2.059415817260742
Validation loss: 2.012371157606443

Epoch: 5| Step: 6
Training loss: 2.0759663581848145
Validation loss: 2.011276667316755

Epoch: 5| Step: 7
Training loss: 2.056138277053833
Validation loss: 2.007163648804029

Epoch: 5| Step: 8
Training loss: 1.9285463094711304
Validation loss: 2.0018195311228433

Epoch: 5| Step: 9
Training loss: 2.6276612281799316
Validation loss: 2.003595287601153

Epoch: 5| Step: 10
Training loss: 1.9167588949203491
Validation loss: 2.004207839568456

Epoch: 5| Step: 11
Training loss: 2.0845727920532227
Validation loss: 2.004687195022901

Epoch: 119| Step: 0
Training loss: 2.1253018379211426
Validation loss: 2.0101057589054108

Epoch: 5| Step: 1
Training loss: 2.1762447357177734
Validation loss: 2.018997078140577

Epoch: 5| Step: 2
Training loss: 2.2652428150177
Validation loss: 2.0154736936092377

Epoch: 5| Step: 3
Training loss: 1.9216363430023193
Validation loss: 2.0192490021387735

Epoch: 5| Step: 4
Training loss: 1.855743408203125
Validation loss: 2.009321709473928

Epoch: 5| Step: 5
Training loss: 2.1270668506622314
Validation loss: 2.0160941779613495

Epoch: 5| Step: 6
Training loss: 2.5236923694610596
Validation loss: 2.012780025601387

Epoch: 5| Step: 7
Training loss: 1.987135648727417
Validation loss: 2.0218558311462402

Epoch: 5| Step: 8
Training loss: 2.027791976928711
Validation loss: 2.01542000969251

Epoch: 5| Step: 9
Training loss: 1.7628819942474365
Validation loss: 2.015542984008789

Epoch: 5| Step: 10
Training loss: 2.7189183235168457
Validation loss: 2.0177482962608337

Epoch: 5| Step: 11
Training loss: 0.909037172794342
Validation loss: 2.0123388121525445

Epoch: 120| Step: 0
Training loss: 1.8617849349975586
Validation loss: 2.0084789196650186

Epoch: 5| Step: 1
Training loss: 2.0190913677215576
Validation loss: 2.0099392582972846

Epoch: 5| Step: 2
Training loss: 2.9093286991119385
Validation loss: 2.0035659124453864

Epoch: 5| Step: 3
Training loss: 2.3594021797180176
Validation loss: 2.001772632201513

Epoch: 5| Step: 4
Training loss: 1.5700911283493042
Validation loss: 2.004381169875463

Epoch: 5| Step: 5
Training loss: 1.761355996131897
Validation loss: 2.0090261002381644

Epoch: 5| Step: 6
Training loss: 2.4520747661590576
Validation loss: 2.0115517477194467

Epoch: 5| Step: 7
Training loss: 1.9493837356567383
Validation loss: 2.0089489171902337

Epoch: 5| Step: 8
Training loss: 2.049118995666504
Validation loss: 2.014245996872584

Epoch: 5| Step: 9
Training loss: 1.7920191287994385
Validation loss: 2.012469773491224

Epoch: 5| Step: 10
Training loss: 2.1502277851104736
Validation loss: 2.012441709637642

Epoch: 5| Step: 11
Training loss: 3.694312334060669
Validation loss: 2.019631028175354

Epoch: 121| Step: 0
Training loss: 1.7538611888885498
Validation loss: 2.0207773596048355

Epoch: 5| Step: 1
Training loss: 2.6534202098846436
Validation loss: 2.0272333224614463

Epoch: 5| Step: 2
Training loss: 1.88851797580719
Validation loss: 2.018426532546679

Epoch: 5| Step: 3
Training loss: 2.2067978382110596
Validation loss: 2.0136716117461524

Epoch: 5| Step: 4
Training loss: 2.7030932903289795
Validation loss: 2.0127149671316147

Epoch: 5| Step: 5
Training loss: 1.7800544500350952
Validation loss: 2.0184511691331863

Epoch: 5| Step: 6
Training loss: 2.0245118141174316
Validation loss: 2.0077059268951416

Epoch: 5| Step: 7
Training loss: 1.9889495372772217
Validation loss: 2.01351265112559

Epoch: 5| Step: 8
Training loss: 2.4520316123962402
Validation loss: 2.0139991690715155

Epoch: 5| Step: 9
Training loss: 2.0853664875030518
Validation loss: 2.0151840647061667

Epoch: 5| Step: 10
Training loss: 2.036587953567505
Validation loss: 2.019324913620949

Epoch: 5| Step: 11
Training loss: 0.39820951223373413
Validation loss: 2.0159876346588135

Epoch: 122| Step: 0
Training loss: 1.8936169147491455
Validation loss: 2.0170201510190964

Epoch: 5| Step: 1
Training loss: 1.7911593914031982
Validation loss: 2.0196791191895804

Epoch: 5| Step: 2
Training loss: 2.3602733612060547
Validation loss: 2.019203762213389

Epoch: 5| Step: 3
Training loss: 1.9076869487762451
Validation loss: 2.020993615190188

Epoch: 5| Step: 4
Training loss: 1.9794098138809204
Validation loss: 2.0223369101683297

Epoch: 5| Step: 5
Training loss: 2.5744681358337402
Validation loss: 2.020539954304695

Epoch: 5| Step: 6
Training loss: 2.4766945838928223
Validation loss: 2.019426092505455

Epoch: 5| Step: 7
Training loss: 1.8997828960418701
Validation loss: 2.020743658145269

Epoch: 5| Step: 8
Training loss: 1.7720146179199219
Validation loss: 2.020144442717234

Epoch: 5| Step: 9
Training loss: 2.570852279663086
Validation loss: 2.0187354534864426

Epoch: 5| Step: 10
Training loss: 2.0610110759735107
Validation loss: 2.024718791246414

Epoch: 5| Step: 11
Training loss: 1.2054362297058105
Validation loss: 2.0255407840013504

Epoch: 123| Step: 0
Training loss: 1.7785255908966064
Validation loss: 2.0207010159889855

Epoch: 5| Step: 1
Training loss: 1.9382699728012085
Validation loss: 2.017854834596316

Epoch: 5| Step: 2
Training loss: 1.3593993186950684
Validation loss: 2.015281448761622

Epoch: 5| Step: 3
Training loss: 1.7888615131378174
Validation loss: 2.0152456909418106

Epoch: 5| Step: 4
Training loss: 2.296099901199341
Validation loss: 2.025878091653188

Epoch: 5| Step: 5
Training loss: 2.156480312347412
Validation loss: 2.0162573705116906

Epoch: 5| Step: 6
Training loss: 2.1884684562683105
Validation loss: 2.018575911720594

Epoch: 5| Step: 7
Training loss: 2.0388972759246826
Validation loss: 2.02217099070549

Epoch: 5| Step: 8
Training loss: 3.006838321685791
Validation loss: 2.0182887564102807

Epoch: 5| Step: 9
Training loss: 2.263458251953125
Validation loss: 2.022588257988294

Epoch: 5| Step: 10
Training loss: 2.123483419418335
Validation loss: 2.01836766799291

Epoch: 5| Step: 11
Training loss: 2.5508110523223877
Validation loss: 2.0182140370210013

Epoch: 124| Step: 0
Training loss: 1.885190725326538
Validation loss: 2.014753813544909

Epoch: 5| Step: 1
Training loss: 1.8025528192520142
Validation loss: 2.010265519221624

Epoch: 5| Step: 2
Training loss: 2.1833949089050293
Validation loss: 2.0035174091657004

Epoch: 5| Step: 3
Training loss: 2.0362637042999268
Validation loss: 2.001990169286728

Epoch: 5| Step: 4
Training loss: 2.2659811973571777
Validation loss: 2.0030584583679834

Epoch: 5| Step: 5
Training loss: 2.2926125526428223
Validation loss: 2.000235214829445

Epoch: 5| Step: 6
Training loss: 2.6087353229522705
Validation loss: 2.000739941994349

Epoch: 5| Step: 7
Training loss: 2.0171656608581543
Validation loss: 2.0043828884760537

Epoch: 5| Step: 8
Training loss: 2.3165946006774902
Validation loss: 2.004264081517855

Epoch: 5| Step: 9
Training loss: 2.371568441390991
Validation loss: 2.005348985393842

Epoch: 5| Step: 10
Training loss: 1.4896472692489624
Validation loss: 2.0081207354863486

Epoch: 5| Step: 11
Training loss: 2.0130839347839355
Validation loss: 2.0141211251417794

Epoch: 125| Step: 0
Training loss: 1.7942886352539062
Validation loss: 2.0076391994953156

Epoch: 5| Step: 1
Training loss: 2.608520030975342
Validation loss: 2.014545818169912

Epoch: 5| Step: 2
Training loss: 2.4879038333892822
Validation loss: 2.013163283467293

Epoch: 5| Step: 3
Training loss: 2.1227564811706543
Validation loss: 2.015484109520912

Epoch: 5| Step: 4
Training loss: 2.3448257446289062
Validation loss: 2.0137788355350494

Epoch: 5| Step: 5
Training loss: 1.946420431137085
Validation loss: 2.015428806344668

Epoch: 5| Step: 6
Training loss: 2.021803855895996
Validation loss: 2.0173737357060113

Epoch: 5| Step: 7
Training loss: 1.9079433679580688
Validation loss: 2.011935442686081

Epoch: 5| Step: 8
Training loss: 2.3944945335388184
Validation loss: 2.0132853438456855

Epoch: 5| Step: 9
Training loss: 1.4940097332000732
Validation loss: 2.0195539941390357

Epoch: 5| Step: 10
Training loss: 1.9030847549438477
Validation loss: 2.0183498660723367

Epoch: 5| Step: 11
Training loss: 2.059385299682617
Validation loss: 2.014717901746432

Epoch: 126| Step: 0
Training loss: 2.31695818901062
Validation loss: 2.0111586650212607

Epoch: 5| Step: 1
Training loss: 2.4009087085723877
Validation loss: 2.0139318257570267

Epoch: 5| Step: 2
Training loss: 1.6501331329345703
Validation loss: 2.011683071653048

Epoch: 5| Step: 3
Training loss: 2.0937392711639404
Validation loss: 2.014349271853765

Epoch: 5| Step: 4
Training loss: 2.0326523780822754
Validation loss: 2.012636383374532

Epoch: 5| Step: 5
Training loss: 2.31931734085083
Validation loss: 2.012203355630239

Epoch: 5| Step: 6
Training loss: 1.8042991161346436
Validation loss: 2.016257037719091

Epoch: 5| Step: 7
Training loss: 2.085785150527954
Validation loss: 2.016708413759867

Epoch: 5| Step: 8
Training loss: 2.100154399871826
Validation loss: 2.020702595512072

Epoch: 5| Step: 9
Training loss: 2.05901837348938
Validation loss: 2.0242873628934226

Epoch: 5| Step: 10
Training loss: 2.195493459701538
Validation loss: 2.017585719625155

Epoch: 5| Step: 11
Training loss: 1.800344705581665
Validation loss: 2.015423779686292

Epoch: 127| Step: 0
Training loss: 2.6412291526794434
Validation loss: 2.013008236885071

Epoch: 5| Step: 1
Training loss: 2.6279563903808594
Validation loss: 2.0135698467493057

Epoch: 5| Step: 2
Training loss: 1.3546311855316162
Validation loss: 2.015873675545057

Epoch: 5| Step: 3
Training loss: 2.241936206817627
Validation loss: 2.0149029940366745

Epoch: 5| Step: 4
Training loss: 1.8634297847747803
Validation loss: 2.007060627142588

Epoch: 5| Step: 5
Training loss: 1.833993911743164
Validation loss: 2.009058102965355

Epoch: 5| Step: 6
Training loss: 1.8314428329467773
Validation loss: 2.0132648944854736

Epoch: 5| Step: 7
Training loss: 2.1745200157165527
Validation loss: 2.013043870528539

Epoch: 5| Step: 8
Training loss: 2.0852837562561035
Validation loss: 2.016103188196818

Epoch: 5| Step: 9
Training loss: 2.422701835632324
Validation loss: 2.017007360855738

Epoch: 5| Step: 10
Training loss: 2.1759421825408936
Validation loss: 2.017974009116491

Epoch: 5| Step: 11
Training loss: 1.509985327720642
Validation loss: 2.021698012948036

Epoch: 128| Step: 0
Training loss: 2.076550006866455
Validation loss: 2.0231121430794397

Epoch: 5| Step: 1
Training loss: 2.160890817642212
Validation loss: 2.0406602124373117

Epoch: 5| Step: 2
Training loss: 2.285188674926758
Validation loss: 2.0342590510845184

Epoch: 5| Step: 3
Training loss: 2.673978328704834
Validation loss: 2.0567774772644043

Epoch: 5| Step: 4
Training loss: 1.9115898609161377
Validation loss: 2.0530711660782495

Epoch: 5| Step: 5
Training loss: 1.9892394542694092
Validation loss: 2.039811516801516

Epoch: 5| Step: 6
Training loss: 2.457517623901367
Validation loss: 2.025896285971006

Epoch: 5| Step: 7
Training loss: 2.2731916904449463
Validation loss: 2.0275983413060508

Epoch: 5| Step: 8
Training loss: 1.6384391784667969
Validation loss: 2.0266094903151193

Epoch: 5| Step: 9
Training loss: 1.9534685611724854
Validation loss: 2.0264258285363517

Epoch: 5| Step: 10
Training loss: 2.023766040802002
Validation loss: 2.0255921880404153

Epoch: 5| Step: 11
Training loss: 1.8674445152282715
Validation loss: 2.015978236993154

Epoch: 129| Step: 0
Training loss: 2.1206607818603516
Validation loss: 2.007282793521881

Epoch: 5| Step: 1
Training loss: 2.0471320152282715
Validation loss: 2.008631149927775

Epoch: 5| Step: 2
Training loss: 1.8614070415496826
Validation loss: 2.0142567257086434

Epoch: 5| Step: 3
Training loss: 2.1235809326171875
Validation loss: 2.012945771217346

Epoch: 5| Step: 4
Training loss: 2.0927250385284424
Validation loss: 2.0159578224023185

Epoch: 5| Step: 5
Training loss: 2.0831246376037598
Validation loss: 2.015480433901151

Epoch: 5| Step: 6
Training loss: 1.98240065574646
Validation loss: 2.0156338016192117

Epoch: 5| Step: 7
Training loss: 1.77541983127594
Validation loss: 2.010427604118983

Epoch: 5| Step: 8
Training loss: 1.7938770055770874
Validation loss: 2.012189641594887

Epoch: 5| Step: 9
Training loss: 2.306427240371704
Validation loss: 2.0139814416567483

Epoch: 5| Step: 10
Training loss: 2.7955667972564697
Validation loss: 2.0147108336289725

Epoch: 5| Step: 11
Training loss: 3.5431067943573
Validation loss: 2.020328000187874

Epoch: 130| Step: 0
Training loss: 2.0243191719055176
Validation loss: 2.0297613640626273

Epoch: 5| Step: 1
Training loss: 2.5963196754455566
Validation loss: 2.022020012140274

Epoch: 5| Step: 2
Training loss: 1.9190700054168701
Validation loss: 2.0204866329828897

Epoch: 5| Step: 3
Training loss: 2.344738721847534
Validation loss: 2.02128995458285

Epoch: 5| Step: 4
Training loss: 2.396864652633667
Validation loss: 2.0290665129820504

Epoch: 5| Step: 5
Training loss: 2.0870490074157715
Validation loss: 2.0246783643960953

Epoch: 5| Step: 6
Training loss: 2.061793804168701
Validation loss: 2.0156267335017524

Epoch: 5| Step: 7
Training loss: 1.8095009326934814
Validation loss: 2.0168194472789764

Epoch: 5| Step: 8
Training loss: 2.1310038566589355
Validation loss: 2.0211573938528695

Epoch: 5| Step: 9
Training loss: 1.7904388904571533
Validation loss: 2.017709791660309

Epoch: 5| Step: 10
Training loss: 1.9171371459960938
Validation loss: 2.0198309222857156

Epoch: 5| Step: 11
Training loss: 2.3158864974975586
Validation loss: 2.020907983183861

Epoch: 131| Step: 0
Training loss: 2.1897079944610596
Validation loss: 2.026960680882136

Epoch: 5| Step: 1
Training loss: 2.7923316955566406
Validation loss: 2.0279784003893533

Epoch: 5| Step: 2
Training loss: 2.0719571113586426
Validation loss: 2.0363712112108865

Epoch: 5| Step: 3
Training loss: 2.401193857192993
Validation loss: 2.0220367362101874

Epoch: 5| Step: 4
Training loss: 2.1711318492889404
Validation loss: 2.020198255777359

Epoch: 5| Step: 5
Training loss: 1.8842260837554932
Validation loss: 2.0180072337388992

Epoch: 5| Step: 6
Training loss: 1.909165620803833
Validation loss: 2.0139757146437964

Epoch: 5| Step: 7
Training loss: 2.0623762607574463
Validation loss: 2.0115921050310135

Epoch: 5| Step: 8
Training loss: 2.0505332946777344
Validation loss: 2.0161843399206796

Epoch: 5| Step: 9
Training loss: 1.6362411975860596
Validation loss: 2.025150328874588

Epoch: 5| Step: 10
Training loss: 1.8579180240631104
Validation loss: 2.0241776406764984

Epoch: 5| Step: 11
Training loss: 2.805605888366699
Validation loss: 2.0164614419142404

Epoch: 132| Step: 0
Training loss: 1.690293312072754
Validation loss: 2.0211312671502433

Epoch: 5| Step: 1
Training loss: 1.7604948282241821
Validation loss: 2.015268291036288

Epoch: 5| Step: 2
Training loss: 2.1100261211395264
Validation loss: 2.018993616104126

Epoch: 5| Step: 3
Training loss: 2.4566891193389893
Validation loss: 2.00790865222613

Epoch: 5| Step: 4
Training loss: 1.9184383153915405
Validation loss: 2.016855706771215

Epoch: 5| Step: 5
Training loss: 2.465331554412842
Validation loss: 2.0105771919091544

Epoch: 5| Step: 6
Training loss: 1.6505725383758545
Validation loss: 2.0173691660165787

Epoch: 5| Step: 7
Training loss: 1.7222697734832764
Validation loss: 2.0218249410390854

Epoch: 5| Step: 8
Training loss: 2.1572132110595703
Validation loss: 2.030108004808426

Epoch: 5| Step: 9
Training loss: 3.146869421005249
Validation loss: 2.0230552554130554

Epoch: 5| Step: 10
Training loss: 1.9279205799102783
Validation loss: 2.0177329629659653

Epoch: 5| Step: 11
Training loss: 1.1738224029541016
Validation loss: 2.0170495559771857

Epoch: 133| Step: 0
Training loss: 2.1184639930725098
Validation loss: 2.0236095736424127

Epoch: 5| Step: 1
Training loss: 1.1409447193145752
Validation loss: 2.0175811698039374

Epoch: 5| Step: 2
Training loss: 2.0084524154663086
Validation loss: 2.0092803984880447

Epoch: 5| Step: 3
Training loss: 2.553126096725464
Validation loss: 2.0195586731036506

Epoch: 5| Step: 4
Training loss: 2.4242568016052246
Validation loss: 2.010158305366834

Epoch: 5| Step: 5
Training loss: 1.4873183965682983
Validation loss: 2.022003635764122

Epoch: 5| Step: 6
Training loss: 1.9819406270980835
Validation loss: 2.019655242562294

Epoch: 5| Step: 7
Training loss: 2.4341583251953125
Validation loss: 2.0217772473891578

Epoch: 5| Step: 8
Training loss: 2.7115836143493652
Validation loss: 2.019515415032705

Epoch: 5| Step: 9
Training loss: 1.6705535650253296
Validation loss: 2.0218874166409173

Epoch: 5| Step: 10
Training loss: 2.427884578704834
Validation loss: 2.0165108293294907

Epoch: 5| Step: 11
Training loss: 2.0477616786956787
Validation loss: 2.0179074555635452

Epoch: 134| Step: 0
Training loss: 2.140439033508301
Validation loss: 2.02947228650252

Epoch: 5| Step: 1
Training loss: 1.927159070968628
Validation loss: 2.0218546837568283

Epoch: 5| Step: 2
Training loss: 2.0923755168914795
Validation loss: 2.0305252323547998

Epoch: 5| Step: 3
Training loss: 2.643303632736206
Validation loss: 2.0328833957513175

Epoch: 5| Step: 4
Training loss: 2.148582935333252
Validation loss: 2.018183042605718

Epoch: 5| Step: 5
Training loss: 2.342839241027832
Validation loss: 2.0293759455283484

Epoch: 5| Step: 6
Training loss: 1.652775526046753
Validation loss: 2.0283931295077005

Epoch: 5| Step: 7
Training loss: 1.8326237201690674
Validation loss: 2.0262805968523026

Epoch: 5| Step: 8
Training loss: 2.0810158252716064
Validation loss: 2.030239005883535

Epoch: 5| Step: 9
Training loss: 2.3314409255981445
Validation loss: 2.0281260162591934

Epoch: 5| Step: 10
Training loss: 1.7887834310531616
Validation loss: 2.0283815562725067

Epoch: 5| Step: 11
Training loss: 1.4617085456848145
Validation loss: 2.034500007828077

Epoch: 135| Step: 0
Training loss: 2.0482544898986816
Validation loss: 2.034303362170855

Epoch: 5| Step: 1
Training loss: 2.0720529556274414
Validation loss: 2.0231385876735053

Epoch: 5| Step: 2
Training loss: 2.2595365047454834
Validation loss: 2.030572305123011

Epoch: 5| Step: 3
Training loss: 2.1154251098632812
Validation loss: 2.026545857389768

Epoch: 5| Step: 4
Training loss: 2.197636127471924
Validation loss: 2.023047238588333

Epoch: 5| Step: 5
Training loss: 1.9531011581420898
Validation loss: 2.0251372903585434

Epoch: 5| Step: 6
Training loss: 2.6988186836242676
Validation loss: 2.0183079491058984

Epoch: 5| Step: 7
Training loss: 2.253025770187378
Validation loss: 2.02669724325339

Epoch: 5| Step: 8
Training loss: 2.0676207542419434
Validation loss: 2.017244338989258

Epoch: 5| Step: 9
Training loss: 1.6940956115722656
Validation loss: 2.0152032524347305

Epoch: 5| Step: 10
Training loss: 1.5978443622589111
Validation loss: 2.0152736455202103

Epoch: 5| Step: 11
Training loss: 1.3782209157943726
Validation loss: 2.0160241375366845

Epoch: 136| Step: 0
Training loss: 1.6592981815338135
Validation loss: 2.0102114031712213

Epoch: 5| Step: 1
Training loss: 2.0723156929016113
Validation loss: 2.0284829338391623

Epoch: 5| Step: 2
Training loss: 1.851700782775879
Validation loss: 2.024306590358416

Epoch: 5| Step: 3
Training loss: 1.7917022705078125
Validation loss: 2.022754520177841

Epoch: 5| Step: 4
Training loss: 1.8032032251358032
Validation loss: 2.027647465467453

Epoch: 5| Step: 5
Training loss: 1.9395393133163452
Validation loss: 2.0409357200066247

Epoch: 5| Step: 6
Training loss: 2.7322354316711426
Validation loss: 2.0373843014240265

Epoch: 5| Step: 7
Training loss: 1.9493598937988281
Validation loss: 2.042416969935099

Epoch: 5| Step: 8
Training loss: 1.7410799264907837
Validation loss: 2.0457563002904258

Epoch: 5| Step: 9
Training loss: 2.3894619941711426
Validation loss: 2.0375851144393287

Epoch: 5| Step: 10
Training loss: 2.947100877761841
Validation loss: 2.0297984878222146

Epoch: 5| Step: 11
Training loss: 2.44693922996521
Validation loss: 2.035976474483808

Epoch: 137| Step: 0
Training loss: 2.198820114135742
Validation loss: 2.01625890036424

Epoch: 5| Step: 1
Training loss: 1.8326711654663086
Validation loss: 2.012121553222338

Epoch: 5| Step: 2
Training loss: 2.131457805633545
Validation loss: 2.0086689243714013

Epoch: 5| Step: 3
Training loss: 1.8437058925628662
Validation loss: 2.0122840901215873

Epoch: 5| Step: 4
Training loss: 2.64815354347229
Validation loss: 2.011571243405342

Epoch: 5| Step: 5
Training loss: 1.954930067062378
Validation loss: 2.0058021595080695

Epoch: 5| Step: 6
Training loss: 1.839862585067749
Validation loss: 2.0058849304914474

Epoch: 5| Step: 7
Training loss: 1.9949626922607422
Validation loss: 2.0017103453477225

Epoch: 5| Step: 8
Training loss: 2.110197067260742
Validation loss: 2.000881160298983

Epoch: 5| Step: 9
Training loss: 2.4233803749084473
Validation loss: 2.014047642548879

Epoch: 5| Step: 10
Training loss: 2.305643081665039
Validation loss: 2.0099827498197556

Epoch: 5| Step: 11
Training loss: 0.8285800218582153
Validation loss: 2.0176448673009872

Epoch: 138| Step: 0
Training loss: 1.7010633945465088
Validation loss: 2.0206891000270844

Epoch: 5| Step: 1
Training loss: 2.0603203773498535
Validation loss: 2.0240173637866974

Epoch: 5| Step: 2
Training loss: 2.0123448371887207
Validation loss: 2.0322933942079544

Epoch: 5| Step: 3
Training loss: 2.0707123279571533
Validation loss: 2.032607595125834

Epoch: 5| Step: 4
Training loss: 2.0056490898132324
Validation loss: 2.0369220823049545

Epoch: 5| Step: 5
Training loss: 2.384629964828491
Validation loss: 2.0429086784521737

Epoch: 5| Step: 6
Training loss: 2.065337657928467
Validation loss: 2.036131943265597

Epoch: 5| Step: 7
Training loss: 2.607438802719116
Validation loss: 2.0207301576932273

Epoch: 5| Step: 8
Training loss: 1.7415916919708252
Validation loss: 2.0199251224597297

Epoch: 5| Step: 9
Training loss: 2.1994309425354004
Validation loss: 2.016114130616188

Epoch: 5| Step: 10
Training loss: 2.033970355987549
Validation loss: 2.0113699436187744

Epoch: 5| Step: 11
Training loss: 2.678924322128296
Validation loss: 2.0067114432652793

Epoch: 139| Step: 0
Training loss: 2.2178053855895996
Validation loss: 2.006863762935003

Epoch: 5| Step: 1
Training loss: 1.5649657249450684
Validation loss: 2.006165554126104

Epoch: 5| Step: 2
Training loss: 2.1098122596740723
Validation loss: 2.015341281890869

Epoch: 5| Step: 3
Training loss: 2.3120594024658203
Validation loss: 2.014704500635465

Epoch: 5| Step: 4
Training loss: 2.042066812515259
Validation loss: 2.019618699947993

Epoch: 5| Step: 5
Training loss: 1.9422467947006226
Validation loss: 2.015098512172699

Epoch: 5| Step: 6
Training loss: 2.1009128093719482
Validation loss: 2.025579238931338

Epoch: 5| Step: 7
Training loss: 2.1305994987487793
Validation loss: 2.025505075852076

Epoch: 5| Step: 8
Training loss: 2.1745407581329346
Validation loss: 2.0259195268154144

Epoch: 5| Step: 9
Training loss: 2.229536533355713
Validation loss: 2.0225749065478644

Epoch: 5| Step: 10
Training loss: 2.1037814617156982
Validation loss: 2.0406312296787896

Epoch: 5| Step: 11
Training loss: 1.527322769165039
Validation loss: 2.0345733165740967

Epoch: 140| Step: 0
Training loss: 2.3762168884277344
Validation loss: 2.0306227654218674

Epoch: 5| Step: 1
Training loss: 2.039041757583618
Validation loss: 2.0283737629652023

Epoch: 5| Step: 2
Training loss: 1.614076852798462
Validation loss: 2.032298053304354

Epoch: 5| Step: 3
Training loss: 1.970560073852539
Validation loss: 2.024558578928312

Epoch: 5| Step: 4
Training loss: 2.0066940784454346
Validation loss: 2.0224587321281433

Epoch: 5| Step: 5
Training loss: 2.262620449066162
Validation loss: 2.0220836897691092

Epoch: 5| Step: 6
Training loss: 2.1591548919677734
Validation loss: 2.0213154504696527

Epoch: 5| Step: 7
Training loss: 1.6545358896255493
Validation loss: 2.0267706712086997

Epoch: 5| Step: 8
Training loss: 2.3601951599121094
Validation loss: 2.025678346554438

Epoch: 5| Step: 9
Training loss: 1.8843529224395752
Validation loss: 2.0282989889383316

Epoch: 5| Step: 10
Training loss: 2.3673667907714844
Validation loss: 2.0309380690256753

Epoch: 5| Step: 11
Training loss: 2.0596518516540527
Validation loss: 2.027847463885943

Epoch: 141| Step: 0
Training loss: 2.0402801036834717
Validation loss: 2.0358969817558923

Epoch: 5| Step: 1
Training loss: 1.9694627523422241
Validation loss: 2.0342890272537866

Epoch: 5| Step: 2
Training loss: 1.8681695461273193
Validation loss: 2.0364571511745453

Epoch: 5| Step: 3
Training loss: 2.0587477684020996
Validation loss: 2.0284589529037476

Epoch: 5| Step: 4
Training loss: 2.3847832679748535
Validation loss: 2.0387992709875107

Epoch: 5| Step: 5
Training loss: 1.8961896896362305
Validation loss: 2.035204365849495

Epoch: 5| Step: 6
Training loss: 2.161782741546631
Validation loss: 2.0344161291917167

Epoch: 5| Step: 7
Training loss: 1.5860642194747925
Validation loss: 2.03690105676651

Epoch: 5| Step: 8
Training loss: 2.7966208457946777
Validation loss: 2.0304580529530845

Epoch: 5| Step: 9
Training loss: 1.6503503322601318
Validation loss: 2.031290357311567

Epoch: 5| Step: 10
Training loss: 2.0501790046691895
Validation loss: 2.037238965431849

Epoch: 5| Step: 11
Training loss: 3.5781497955322266
Validation loss: 2.0326720078786216

Epoch: 142| Step: 0
Training loss: 2.5251331329345703
Validation loss: 2.0284051845471063

Epoch: 5| Step: 1
Training loss: 2.157949924468994
Validation loss: 2.0219457099835076

Epoch: 5| Step: 2
Training loss: 2.120967388153076
Validation loss: 2.0282086730003357

Epoch: 5| Step: 3
Training loss: 2.2570431232452393
Validation loss: 2.0118924379348755

Epoch: 5| Step: 4
Training loss: 2.1266965866088867
Validation loss: 2.0126093477010727

Epoch: 5| Step: 5
Training loss: 1.926500678062439
Validation loss: 2.019299899538358

Epoch: 5| Step: 6
Training loss: 1.8621286153793335
Validation loss: 2.019931266705195

Epoch: 5| Step: 7
Training loss: 2.0618298053741455
Validation loss: 2.027429093917211

Epoch: 5| Step: 8
Training loss: 2.0100340843200684
Validation loss: 2.0197008699178696

Epoch: 5| Step: 9
Training loss: 1.9896087646484375
Validation loss: 2.0247269521156945

Epoch: 5| Step: 10
Training loss: 1.7048448324203491
Validation loss: 2.0267587850491204

Epoch: 5| Step: 11
Training loss: 2.9179975986480713
Validation loss: 2.041339620947838

Epoch: 143| Step: 0
Training loss: 2.1703107357025146
Validation loss: 2.052196651697159

Epoch: 5| Step: 1
Training loss: 2.2967593669891357
Validation loss: 2.051424225171407

Epoch: 5| Step: 2
Training loss: 2.193774700164795
Validation loss: 2.0605027129252753

Epoch: 5| Step: 3
Training loss: 2.0977821350097656
Validation loss: 2.0504940152168274

Epoch: 5| Step: 4
Training loss: 2.4616596698760986
Validation loss: 2.0737698723872504

Epoch: 5| Step: 5
Training loss: 1.6190303564071655
Validation loss: 2.0721439321835837

Epoch: 5| Step: 6
Training loss: 2.2334799766540527
Validation loss: 2.0549015204111734

Epoch: 5| Step: 7
Training loss: 1.9825137853622437
Validation loss: 2.053174997369448

Epoch: 5| Step: 8
Training loss: 1.9424480199813843
Validation loss: 2.043324495355288

Epoch: 5| Step: 9
Training loss: 2.2212226390838623
Validation loss: 2.0415251155694327

Epoch: 5| Step: 10
Training loss: 1.8387916088104248
Validation loss: 2.0233678221702576

Epoch: 5| Step: 11
Training loss: 1.5666877031326294
Validation loss: 2.0188481559356055

Epoch: 144| Step: 0
Training loss: 2.6204113960266113
Validation loss: 2.0179191331068673

Epoch: 5| Step: 1
Training loss: 1.9657758474349976
Validation loss: 2.01812611023585

Epoch: 5| Step: 2
Training loss: 1.845630407333374
Validation loss: 2.0241408298412957

Epoch: 5| Step: 3
Training loss: 2.2383620738983154
Validation loss: 2.0236568997303643

Epoch: 5| Step: 4
Training loss: 1.7837018966674805
Validation loss: 2.023661896586418

Epoch: 5| Step: 5
Training loss: 2.632807970046997
Validation loss: 2.029365211725235

Epoch: 5| Step: 6
Training loss: 1.5319061279296875
Validation loss: 2.031840259830157

Epoch: 5| Step: 7
Training loss: 1.9817912578582764
Validation loss: 2.038329338033994

Epoch: 5| Step: 8
Training loss: 1.4978469610214233
Validation loss: 2.0387620826562247

Epoch: 5| Step: 9
Training loss: 2.7346208095550537
Validation loss: 2.0546314120292664

Epoch: 5| Step: 10
Training loss: 2.2490475177764893
Validation loss: 2.0587463825941086

Epoch: 5| Step: 11
Training loss: 1.7261886596679688
Validation loss: 2.0512859423955283

Epoch: 145| Step: 0
Training loss: 2.0786144733428955
Validation loss: 2.0549905598163605

Epoch: 5| Step: 1
Training loss: 2.4086992740631104
Validation loss: 2.0430870105822883

Epoch: 5| Step: 2
Training loss: 2.670632839202881
Validation loss: 2.042809079090754

Epoch: 5| Step: 3
Training loss: 2.4987220764160156
Validation loss: 2.0376492142677307

Epoch: 5| Step: 4
Training loss: 2.082601308822632
Validation loss: 2.0441295206546783

Epoch: 5| Step: 5
Training loss: 1.8597930669784546
Validation loss: 2.034823313355446

Epoch: 5| Step: 6
Training loss: 1.5555399656295776
Validation loss: 2.0310279726982117

Epoch: 5| Step: 7
Training loss: 1.943643569946289
Validation loss: 2.028850277264913

Epoch: 5| Step: 8
Training loss: 1.8797180652618408
Validation loss: 2.024342735608419

Epoch: 5| Step: 9
Training loss: 1.9125077724456787
Validation loss: 2.024878775080045

Epoch: 5| Step: 10
Training loss: 2.064455509185791
Validation loss: 2.0215756595134735

Epoch: 5| Step: 11
Training loss: 1.8408664464950562
Validation loss: 2.0235210359096527

Epoch: 146| Step: 0
Training loss: 2.276660680770874
Validation loss: 2.0191761404275894

Epoch: 5| Step: 1
Training loss: 2.029873847961426
Validation loss: 2.0275914520025253

Epoch: 5| Step: 2
Training loss: 2.1452863216400146
Validation loss: 2.0214578161636987

Epoch: 5| Step: 3
Training loss: 2.2329533100128174
Validation loss: 2.0262639274199805

Epoch: 5| Step: 4
Training loss: 1.9718656539916992
Validation loss: 2.018146057923635

Epoch: 5| Step: 5
Training loss: 1.7913049459457397
Validation loss: 2.0288274188836417

Epoch: 5| Step: 6
Training loss: 1.8929952383041382
Validation loss: 2.0300483107566833

Epoch: 5| Step: 7
Training loss: 2.2923152446746826
Validation loss: 2.027626857161522

Epoch: 5| Step: 8
Training loss: 2.098991870880127
Validation loss: 2.036247948805491

Epoch: 5| Step: 9
Training loss: 2.4151320457458496
Validation loss: 2.044528365135193

Epoch: 5| Step: 10
Training loss: 1.8973681926727295
Validation loss: 2.0519471168518066

Epoch: 5| Step: 11
Training loss: 1.8521900177001953
Validation loss: 2.0425077925125756

Epoch: 147| Step: 0
Training loss: 2.1457326412200928
Validation loss: 2.0423775166273117

Epoch: 5| Step: 1
Training loss: 1.619110107421875
Validation loss: 2.0332188308238983

Epoch: 5| Step: 2
Training loss: 2.0415501594543457
Validation loss: 2.0287321507930756

Epoch: 5| Step: 3
Training loss: 2.897172451019287
Validation loss: 2.0291637778282166

Epoch: 5| Step: 4
Training loss: 1.4508806467056274
Validation loss: 2.0274169544378915

Epoch: 5| Step: 5
Training loss: 2.4686310291290283
Validation loss: 2.0281923164923987

Epoch: 5| Step: 6
Training loss: 1.8701988458633423
Validation loss: 2.023354480663935

Epoch: 5| Step: 7
Training loss: 2.582287311553955
Validation loss: 2.0274241218964257

Epoch: 5| Step: 8
Training loss: 2.258340835571289
Validation loss: 2.029133295019468

Epoch: 5| Step: 9
Training loss: 1.8961632251739502
Validation loss: 2.032224198182424

Epoch: 5| Step: 10
Training loss: 1.725243330001831
Validation loss: 2.0376436561346054

Epoch: 5| Step: 11
Training loss: 1.1584476232528687
Validation loss: 2.0309559404850006

Epoch: 148| Step: 0
Training loss: 2.3917973041534424
Validation loss: 2.031581555803617

Epoch: 5| Step: 1
Training loss: 1.7876379489898682
Validation loss: 2.0413258969783783

Epoch: 5| Step: 2
Training loss: 2.5418412685394287
Validation loss: 2.0462330232063928

Epoch: 5| Step: 3
Training loss: 2.025203227996826
Validation loss: 2.0541221549113593

Epoch: 5| Step: 4
Training loss: 1.7863922119140625
Validation loss: 2.0597582509120307

Epoch: 5| Step: 5
Training loss: 1.9649460315704346
Validation loss: 2.066197246313095

Epoch: 5| Step: 6
Training loss: 2.195268154144287
Validation loss: 2.0639571895202002

Epoch: 5| Step: 7
Training loss: 2.1387526988983154
Validation loss: 2.056838055451711

Epoch: 5| Step: 8
Training loss: 2.3977773189544678
Validation loss: 2.0583944668372474

Epoch: 5| Step: 9
Training loss: 1.3949315547943115
Validation loss: 2.0640636583169303

Epoch: 5| Step: 10
Training loss: 2.121163845062256
Validation loss: 2.0550267746051154

Epoch: 5| Step: 11
Training loss: 2.084534168243408
Validation loss: 2.0339517146348953

Epoch: 149| Step: 0
Training loss: 2.097954273223877
Validation loss: 2.0346522331237793

Epoch: 5| Step: 1
Training loss: 1.790768027305603
Validation loss: 2.0187626779079437

Epoch: 5| Step: 2
Training loss: 1.7811110019683838
Validation loss: 2.026177058617274

Epoch: 5| Step: 3
Training loss: 2.0830860137939453
Validation loss: 2.0287563552459082

Epoch: 5| Step: 4
Training loss: 2.2316761016845703
Validation loss: 2.031219740708669

Epoch: 5| Step: 5
Training loss: 2.608058214187622
Validation loss: 2.033374403913816

Epoch: 5| Step: 6
Training loss: 1.5097191333770752
Validation loss: 2.034353976448377

Epoch: 5| Step: 7
Training loss: 2.5569965839385986
Validation loss: 2.0408870528141656

Epoch: 5| Step: 8
Training loss: 2.0419209003448486
Validation loss: 2.056696524222692

Epoch: 5| Step: 9
Training loss: 2.3876869678497314
Validation loss: 2.0550835182269416

Epoch: 5| Step: 10
Training loss: 1.8921352624893188
Validation loss: 2.0527770469586053

Epoch: 5| Step: 11
Training loss: 0.9939249157905579
Validation loss: 2.0555587311585746

Epoch: 150| Step: 0
Training loss: 2.031583547592163
Validation loss: 2.064817170302073

Epoch: 5| Step: 1
Training loss: 2.0025691986083984
Validation loss: 2.0673331866661706

Epoch: 5| Step: 2
Training loss: 2.2901864051818848
Validation loss: 2.073884750405947

Epoch: 5| Step: 3
Training loss: 2.5013256072998047
Validation loss: 2.074344793955485

Epoch: 5| Step: 4
Training loss: 1.6391103267669678
Validation loss: 2.0777472953001657

Epoch: 5| Step: 5
Training loss: 1.5750682353973389
Validation loss: 2.0611174404621124

Epoch: 5| Step: 6
Training loss: 2.1550490856170654
Validation loss: 2.0628418723742166

Epoch: 5| Step: 7
Training loss: 1.7587770223617554
Validation loss: 2.04877245426178

Epoch: 5| Step: 8
Training loss: 1.9743473529815674
Validation loss: 2.050263370076815

Epoch: 5| Step: 9
Training loss: 2.177284002304077
Validation loss: 2.0524022728204727

Epoch: 5| Step: 10
Training loss: 2.4646365642547607
Validation loss: 2.0342023919026055

Epoch: 5| Step: 11
Training loss: 2.0743346214294434
Validation loss: 2.0353572368621826

Testing loss: 1.6927083387649318
