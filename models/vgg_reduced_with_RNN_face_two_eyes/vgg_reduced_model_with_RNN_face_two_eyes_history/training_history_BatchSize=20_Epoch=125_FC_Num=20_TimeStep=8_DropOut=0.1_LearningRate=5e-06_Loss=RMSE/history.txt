Epoch: 1| Step: 0
Training loss: 5.32313191774319
Validation loss: 5.920849203812843

Epoch: 5| Step: 1
Training loss: 5.329791124556054
Validation loss: 5.919313035963605

Epoch: 5| Step: 2
Training loss: 6.589857932427685
Validation loss: 5.917722710760569

Epoch: 5| Step: 3
Training loss: 5.959353415215564
Validation loss: 5.916239826046688

Epoch: 5| Step: 4
Training loss: 6.309361650245907
Validation loss: 5.914689864323107

Epoch: 5| Step: 5
Training loss: 5.9922432032735236
Validation loss: 5.913218577015822

Epoch: 5| Step: 6
Training loss: 6.113392009280188
Validation loss: 5.911666646863652

Epoch: 5| Step: 7
Training loss: 5.721320903289551
Validation loss: 5.910063022400138

Epoch: 5| Step: 8
Training loss: 5.57718443220196
Validation loss: 5.908536801334231

Epoch: 5| Step: 9
Training loss: 6.47973584519733
Validation loss: 5.906976941027263

Epoch: 5| Step: 10
Training loss: 6.5615890597300845
Validation loss: 5.905376625410658

Epoch: 5| Step: 11
Training loss: 6.910081447888663
Validation loss: 5.903754364707745

Epoch: 2| Step: 0
Training loss: 5.451691622201232
Validation loss: 5.901974888469689

Epoch: 5| Step: 1
Training loss: 6.65005964668313
Validation loss: 5.900337206369204

Epoch: 5| Step: 2
Training loss: 5.4523652430082175
Validation loss: 5.8985756763164074

Epoch: 5| Step: 3
Training loss: 5.986498901520019
Validation loss: 5.8967413073952075

Epoch: 5| Step: 4
Training loss: 6.20550783450725
Validation loss: 5.894979646521955

Epoch: 5| Step: 5
Training loss: 5.927506881446013
Validation loss: 5.893122419356128

Epoch: 5| Step: 6
Training loss: 5.883869375100215
Validation loss: 5.891127580946003

Epoch: 5| Step: 7
Training loss: 5.452653137603168
Validation loss: 5.889054605963357

Epoch: 5| Step: 8
Training loss: 6.757195769816859
Validation loss: 5.887094493704824

Epoch: 5| Step: 9
Training loss: 5.627983997194792
Validation loss: 5.884888490815841

Epoch: 5| Step: 10
Training loss: 6.490741003962304
Validation loss: 5.882628020441627

Epoch: 5| Step: 11
Training loss: 6.093090158586533
Validation loss: 5.880058133482366

Epoch: 3| Step: 0
Training loss: 5.883119856263686
Validation loss: 5.8777415865573355

Epoch: 5| Step: 1
Training loss: 5.3277458883866355
Validation loss: 5.875236655264273

Epoch: 5| Step: 2
Training loss: 6.19062402639521
Validation loss: 5.872466833075907

Epoch: 5| Step: 3
Training loss: 6.147597996014823
Validation loss: 5.869940946813742

Epoch: 5| Step: 4
Training loss: 6.415029176450938
Validation loss: 5.86691017358968

Epoch: 5| Step: 5
Training loss: 5.794912988175693
Validation loss: 5.863883166980748

Epoch: 5| Step: 6
Training loss: 5.497683991132759
Validation loss: 5.8608084048565425

Epoch: 5| Step: 7
Training loss: 6.330444513656092
Validation loss: 5.857388138342654

Epoch: 5| Step: 8
Training loss: 5.8058009767550125
Validation loss: 5.853983366009576

Epoch: 5| Step: 9
Training loss: 6.159766727340728
Validation loss: 5.8505013509166925

Epoch: 5| Step: 10
Training loss: 5.8045376620970535
Validation loss: 5.846964728766012

Epoch: 5| Step: 11
Training loss: 7.3785169588615185
Validation loss: 5.843065599153265

Epoch: 4| Step: 0
Training loss: 5.8178414033875745
Validation loss: 5.838827327531179

Epoch: 5| Step: 1
Training loss: 6.229747460208058
Validation loss: 5.834564026935918

Epoch: 5| Step: 2
Training loss: 5.6097167184606525
Validation loss: 5.830178056858337

Epoch: 5| Step: 3
Training loss: 5.6970302675717726
Validation loss: 5.825466991909586

Epoch: 5| Step: 4
Training loss: 5.631105627311345
Validation loss: 5.820791510684534

Epoch: 5| Step: 5
Training loss: 5.149477122901143
Validation loss: 5.815794650224885

Epoch: 5| Step: 6
Training loss: 5.4637690067418845
Validation loss: 5.810462526195373

Epoch: 5| Step: 7
Training loss: 6.165323300141175
Validation loss: 5.80498656182345

Epoch: 5| Step: 8
Training loss: 6.479897150236007
Validation loss: 5.799446481567786

Epoch: 5| Step: 9
Training loss: 6.967956224060947
Validation loss: 5.793718409117791

Epoch: 5| Step: 10
Training loss: 5.959670905941779
Validation loss: 5.787610962135637

Epoch: 5| Step: 11
Training loss: 5.036498181705834
Validation loss: 5.781590274728749

Epoch: 5| Step: 0
Training loss: 6.425975669076296
Validation loss: 5.775094716284812

Epoch: 5| Step: 1
Training loss: 6.3968213174614545
Validation loss: 5.768385628558085

Epoch: 5| Step: 2
Training loss: 6.05570052009365
Validation loss: 5.761486135841133

Epoch: 5| Step: 3
Training loss: 6.451966558115519
Validation loss: 5.7544719679505425

Epoch: 5| Step: 4
Training loss: 4.897951725626477
Validation loss: 5.74748392618063

Epoch: 5| Step: 5
Training loss: 5.842098880002843
Validation loss: 5.740136061660749

Epoch: 5| Step: 6
Training loss: 6.04662233756295
Validation loss: 5.732631172202195

Epoch: 5| Step: 7
Training loss: 4.684358892228602
Validation loss: 5.725165890285011

Epoch: 5| Step: 8
Training loss: 6.093204728208571
Validation loss: 5.717512257358104

Epoch: 5| Step: 9
Training loss: 5.314933309342994
Validation loss: 5.709514449319568

Epoch: 5| Step: 10
Training loss: 5.86895895881492
Validation loss: 5.701839744634217

Epoch: 5| Step: 11
Training loss: 6.031044753935641
Validation loss: 5.693982492746698

Epoch: 6| Step: 0
Training loss: 5.347961194167939
Validation loss: 5.685722562398681

Epoch: 5| Step: 1
Training loss: 5.853667467583457
Validation loss: 5.677497717989742

Epoch: 5| Step: 2
Training loss: 5.3299979668303825
Validation loss: 5.6693013344748655

Epoch: 5| Step: 3
Training loss: 6.126140877484066
Validation loss: 5.6611649321116015

Epoch: 5| Step: 4
Training loss: 5.646280512631243
Validation loss: 5.652769187412509

Epoch: 5| Step: 5
Training loss: 5.704519441041695
Validation loss: 5.644200418494249

Epoch: 5| Step: 6
Training loss: 5.367479430231658
Validation loss: 5.636119067781457

Epoch: 5| Step: 7
Training loss: 5.777310735622371
Validation loss: 5.62743044021211

Epoch: 5| Step: 8
Training loss: 6.763180896939439
Validation loss: 5.618860907161949

Epoch: 5| Step: 9
Training loss: 5.374066826300175
Validation loss: 5.610066278307519

Epoch: 5| Step: 10
Training loss: 6.021236348990974
Validation loss: 5.601064669638868

Epoch: 5| Step: 11
Training loss: 5.1901933043833
Validation loss: 5.592238721091576

Epoch: 7| Step: 0
Training loss: 4.7176225338433095
Validation loss: 5.583384658330852

Epoch: 5| Step: 1
Training loss: 5.193903635922411
Validation loss: 5.57436894778283

Epoch: 5| Step: 2
Training loss: 6.744672863084562
Validation loss: 5.5660917779979515

Epoch: 5| Step: 3
Training loss: 6.453759557084095
Validation loss: 5.556992937214526

Epoch: 5| Step: 4
Training loss: 5.708037802663944
Validation loss: 5.547590139790461

Epoch: 5| Step: 5
Training loss: 4.983664148039483
Validation loss: 5.538565853291605

Epoch: 5| Step: 6
Training loss: 5.305636651094522
Validation loss: 5.529867268809499

Epoch: 5| Step: 7
Training loss: 5.106454930576379
Validation loss: 5.521077962769757

Epoch: 5| Step: 8
Training loss: 5.761692266888289
Validation loss: 5.512308126615055

Epoch: 5| Step: 9
Training loss: 5.49011503922467
Validation loss: 5.503089643859796

Epoch: 5| Step: 10
Training loss: 6.1091923601016695
Validation loss: 5.494475617441928

Epoch: 5| Step: 11
Training loss: 7.006289789799759
Validation loss: 5.484876466668067

Epoch: 8| Step: 0
Training loss: 5.206769520276491
Validation loss: 5.475764297602068

Epoch: 5| Step: 1
Training loss: 5.706390198638811
Validation loss: 5.466034649255358

Epoch: 5| Step: 2
Training loss: 4.969610751469189
Validation loss: 5.456588563323209

Epoch: 5| Step: 3
Training loss: 5.813595248163795
Validation loss: 5.447449493314119

Epoch: 5| Step: 4
Training loss: 5.284973457147067
Validation loss: 5.439118287003947

Epoch: 5| Step: 5
Training loss: 6.036915386320384
Validation loss: 5.429943541566394

Epoch: 5| Step: 6
Training loss: 5.531860490287945
Validation loss: 5.422437142171515

Epoch: 5| Step: 7
Training loss: 5.536158221326636
Validation loss: 5.414115674306819

Epoch: 5| Step: 8
Training loss: 5.349432171786728
Validation loss: 5.4061276489995524

Epoch: 5| Step: 9
Training loss: 5.851205567906531
Validation loss: 5.398159529673552

Epoch: 5| Step: 10
Training loss: 5.391013664940137
Validation loss: 5.390224991114849

Epoch: 5| Step: 11
Training loss: 6.864422238147521
Validation loss: 5.382826481668578

Epoch: 9| Step: 0
Training loss: 5.402499446983609
Validation loss: 5.375955334123997

Epoch: 5| Step: 1
Training loss: 5.519933125740427
Validation loss: 5.367882866307261

Epoch: 5| Step: 2
Training loss: 5.956423188740802
Validation loss: 5.360580775801349

Epoch: 5| Step: 3
Training loss: 5.664654804698737
Validation loss: 5.353489141481071

Epoch: 5| Step: 4
Training loss: 5.6656187247879615
Validation loss: 5.345785322243808

Epoch: 5| Step: 5
Training loss: 5.681979340088399
Validation loss: 5.338606800209245

Epoch: 5| Step: 6
Training loss: 5.4549272504757935
Validation loss: 5.331746784302664

Epoch: 5| Step: 7
Training loss: 4.760272312549359
Validation loss: 5.32495241248369

Epoch: 5| Step: 8
Training loss: 4.532605619551802
Validation loss: 5.31814637156275

Epoch: 5| Step: 9
Training loss: 5.13101252983257
Validation loss: 5.312213964802722

Epoch: 5| Step: 10
Training loss: 5.866062264664425
Validation loss: 5.305947028303437

Epoch: 5| Step: 11
Training loss: 6.708788491045021
Validation loss: 5.300351925028127

Epoch: 10| Step: 0
Training loss: 5.337887051773411
Validation loss: 5.293663491687328

Epoch: 5| Step: 1
Training loss: 4.970173373968917
Validation loss: 5.287994397123391

Epoch: 5| Step: 2
Training loss: 5.178555786409854
Validation loss: 5.281506902702531

Epoch: 5| Step: 3
Training loss: 5.912107439296016
Validation loss: 5.274953538530341

Epoch: 5| Step: 4
Training loss: 5.430524363621951
Validation loss: 5.269193358978389

Epoch: 5| Step: 5
Training loss: 4.911162037439143
Validation loss: 5.262742510997043

Epoch: 5| Step: 6
Training loss: 5.067330775321801
Validation loss: 5.256534370050919

Epoch: 5| Step: 7
Training loss: 5.382147361731066
Validation loss: 5.250875437877015

Epoch: 5| Step: 8
Training loss: 5.948871524769458
Validation loss: 5.245441069517289

Epoch: 5| Step: 9
Training loss: 5.650876016137309
Validation loss: 5.240097645063342

Epoch: 5| Step: 10
Training loss: 5.329282215447477
Validation loss: 5.234311724987288

Epoch: 5| Step: 11
Training loss: 5.5223663888623795
Validation loss: 5.229031020250422

Epoch: 11| Step: 0
Training loss: 4.942308040551519
Validation loss: 5.224665496619819

Epoch: 5| Step: 1
Training loss: 5.453757875110258
Validation loss: 5.219384952377778

Epoch: 5| Step: 2
Training loss: 5.915381099390418
Validation loss: 5.213965002117581

Epoch: 5| Step: 3
Training loss: 5.425747502594833
Validation loss: 5.20817349252206

Epoch: 5| Step: 4
Training loss: 5.150811488836519
Validation loss: 5.2022462776807865

Epoch: 5| Step: 5
Training loss: 6.169596963884865
Validation loss: 5.19637860136955

Epoch: 5| Step: 6
Training loss: 5.577427411737703
Validation loss: 5.191822640947251

Epoch: 5| Step: 7
Training loss: 3.5627039800772393
Validation loss: 5.185514031621705

Epoch: 5| Step: 8
Training loss: 5.3290352589161465
Validation loss: 5.180944920152647

Epoch: 5| Step: 9
Training loss: 5.247130018242804
Validation loss: 5.175329339793709

Epoch: 5| Step: 10
Training loss: 5.454291713476932
Validation loss: 5.171300581488824

Epoch: 5| Step: 11
Training loss: 4.825797597157434
Validation loss: 5.165402114099721

Epoch: 12| Step: 0
Training loss: 5.664305288438713
Validation loss: 5.161146824967181

Epoch: 5| Step: 1
Training loss: 5.693152333285157
Validation loss: 5.155844408517355

Epoch: 5| Step: 2
Training loss: 5.209802323762922
Validation loss: 5.15003738667519

Epoch: 5| Step: 3
Training loss: 5.044733402100313
Validation loss: 5.144412445573499

Epoch: 5| Step: 4
Training loss: 5.058028141641822
Validation loss: 5.140013297963041

Epoch: 5| Step: 5
Training loss: 4.568742844436406
Validation loss: 5.13579508668415

Epoch: 5| Step: 6
Training loss: 5.6501234395544095
Validation loss: 5.130471549728727

Epoch: 5| Step: 7
Training loss: 4.854677339904781
Validation loss: 5.124829398006144

Epoch: 5| Step: 8
Training loss: 5.220286617083582
Validation loss: 5.119259363898281

Epoch: 5| Step: 9
Training loss: 5.753595637725263
Validation loss: 5.113927906665019

Epoch: 5| Step: 10
Training loss: 4.969082227432285
Validation loss: 5.1081034782351775

Epoch: 5| Step: 11
Training loss: 5.429275782501837
Validation loss: 5.10315144102399

Epoch: 13| Step: 0
Training loss: 5.857619528696683
Validation loss: 5.097881318990768

Epoch: 5| Step: 1
Training loss: 4.719416085025111
Validation loss: 5.091989630379698

Epoch: 5| Step: 2
Training loss: 4.531043107143646
Validation loss: 5.086590609242255

Epoch: 5| Step: 3
Training loss: 5.059547222521382
Validation loss: 5.0816066133514965

Epoch: 5| Step: 4
Training loss: 4.483914341675845
Validation loss: 5.075857914286989

Epoch: 5| Step: 5
Training loss: 5.8223157469119
Validation loss: 5.070744038121873

Epoch: 5| Step: 6
Training loss: 5.774852945676578
Validation loss: 5.064570219503373

Epoch: 5| Step: 7
Training loss: 5.172903091263315
Validation loss: 5.058859799727318

Epoch: 5| Step: 8
Training loss: 5.139326586712755
Validation loss: 5.052986082716543

Epoch: 5| Step: 9
Training loss: 4.589737158004304
Validation loss: 5.047667379150025

Epoch: 5| Step: 10
Training loss: 5.504860204434017
Validation loss: 5.042937215858635

Epoch: 5| Step: 11
Training loss: 6.216851179369326
Validation loss: 5.0362447820267

Epoch: 14| Step: 0
Training loss: 5.920195731458487
Validation loss: 5.0309231259012925

Epoch: 5| Step: 1
Training loss: 5.261590243825616
Validation loss: 5.025551793498617

Epoch: 5| Step: 2
Training loss: 4.876537960715553
Validation loss: 5.020541054645832

Epoch: 5| Step: 3
Training loss: 5.022634011849976
Validation loss: 5.0153969765363495

Epoch: 5| Step: 4
Training loss: 5.223091192972551
Validation loss: 5.009042677046323

Epoch: 5| Step: 5
Training loss: 5.751289554784105
Validation loss: 5.003298648868188

Epoch: 5| Step: 6
Training loss: 4.595987618359121
Validation loss: 4.9982913992126425

Epoch: 5| Step: 7
Training loss: 4.290295255233047
Validation loss: 4.992292376209116

Epoch: 5| Step: 8
Training loss: 5.175464318126744
Validation loss: 4.987492701398438

Epoch: 5| Step: 9
Training loss: 5.342875626621665
Validation loss: 4.9822753422133585

Epoch: 5| Step: 10
Training loss: 4.726396239327889
Validation loss: 4.978385260117145

Epoch: 5| Step: 11
Training loss: 5.243333853212118
Validation loss: 4.972328097295403

Epoch: 15| Step: 0
Training loss: 5.159147431075814
Validation loss: 4.967312538898709

Epoch: 5| Step: 1
Training loss: 4.433843046061114
Validation loss: 4.962215741501561

Epoch: 5| Step: 2
Training loss: 4.456213806775795
Validation loss: 4.957384309853541

Epoch: 5| Step: 3
Training loss: 5.381848253053637
Validation loss: 4.951433817638966

Epoch: 5| Step: 4
Training loss: 4.628946012817086
Validation loss: 4.944833291345134

Epoch: 5| Step: 5
Training loss: 5.316124072634088
Validation loss: 4.939877320026277

Epoch: 5| Step: 6
Training loss: 5.694583380433461
Validation loss: 4.934493038544553

Epoch: 5| Step: 7
Training loss: 4.334525873464074
Validation loss: 4.929731478648586

Epoch: 5| Step: 8
Training loss: 5.202928510741871
Validation loss: 4.923659333227714

Epoch: 5| Step: 9
Training loss: 4.9755994502699235
Validation loss: 4.917187997151073

Epoch: 5| Step: 10
Training loss: 5.550553426557072
Validation loss: 4.912787906405691

Epoch: 5| Step: 11
Training loss: 6.61941177474648
Validation loss: 4.906823191599445

Epoch: 16| Step: 0
Training loss: 4.819793524850663
Validation loss: 4.900531846331828

Epoch: 5| Step: 1
Training loss: 4.853025943607367
Validation loss: 4.895213735886764

Epoch: 5| Step: 2
Training loss: 5.5222334136099
Validation loss: 4.889773740611105

Epoch: 5| Step: 3
Training loss: 5.427256614959719
Validation loss: 4.885341491879983

Epoch: 5| Step: 4
Training loss: 4.189110972697804
Validation loss: 4.87906112811938

Epoch: 5| Step: 5
Training loss: 5.358284975647434
Validation loss: 4.8729707863574765

Epoch: 5| Step: 6
Training loss: 5.093758050643082
Validation loss: 4.867491188596468

Epoch: 5| Step: 7
Training loss: 5.205409559393984
Validation loss: 4.86139354914669

Epoch: 5| Step: 8
Training loss: 4.396807787069007
Validation loss: 4.856668747007142

Epoch: 5| Step: 9
Training loss: 4.591727921111362
Validation loss: 4.850019822948623

Epoch: 5| Step: 10
Training loss: 5.426938904971743
Validation loss: 4.845275802661959

Epoch: 5| Step: 11
Training loss: 4.540277157696562
Validation loss: 4.839922666483577

Epoch: 17| Step: 0
Training loss: 5.1288452609664
Validation loss: 4.8366372501434824

Epoch: 5| Step: 1
Training loss: 4.262448647824605
Validation loss: 4.8292952007251815

Epoch: 5| Step: 2
Training loss: 4.802679371063131
Validation loss: 4.823841668139637

Epoch: 5| Step: 3
Training loss: 5.701272574800118
Validation loss: 4.818322329874229

Epoch: 5| Step: 4
Training loss: 4.945647651681232
Validation loss: 4.813082928052813

Epoch: 5| Step: 5
Training loss: 3.9909320805753055
Validation loss: 4.807785614966664

Epoch: 5| Step: 6
Training loss: 5.1591235852228365
Validation loss: 4.801797931434497

Epoch: 5| Step: 7
Training loss: 4.418861467609261
Validation loss: 4.796465853162853

Epoch: 5| Step: 8
Training loss: 5.09302314299743
Validation loss: 4.7902862661322185

Epoch: 5| Step: 9
Training loss: 5.401912470639829
Validation loss: 4.785353240026102

Epoch: 5| Step: 10
Training loss: 5.362855898555533
Validation loss: 4.781269663518891

Epoch: 5| Step: 11
Training loss: 3.3624443758649947
Validation loss: 4.775729846932525

Epoch: 18| Step: 0
Training loss: 4.443713498938082
Validation loss: 4.769181288934999

Epoch: 5| Step: 1
Training loss: 5.054643539402636
Validation loss: 4.763924809250322

Epoch: 5| Step: 2
Training loss: 5.1914259061304895
Validation loss: 4.759455054368177

Epoch: 5| Step: 3
Training loss: 5.068000348555531
Validation loss: 4.7535946194544785

Epoch: 5| Step: 4
Training loss: 5.0392082252426835
Validation loss: 4.748557281573348

Epoch: 5| Step: 5
Training loss: 4.250678961879254
Validation loss: 4.742260232165507

Epoch: 5| Step: 6
Training loss: 4.571125186491949
Validation loss: 4.736895730526532

Epoch: 5| Step: 7
Training loss: 4.724834435201246
Validation loss: 4.731794235124036

Epoch: 5| Step: 8
Training loss: 4.961857844009656
Validation loss: 4.726311530393961

Epoch: 5| Step: 9
Training loss: 4.885187508333447
Validation loss: 4.7207655570452935

Epoch: 5| Step: 10
Training loss: 5.1195426355168685
Validation loss: 4.716719866453725

Epoch: 5| Step: 11
Training loss: 5.655368462253159
Validation loss: 4.711302482168939

Epoch: 19| Step: 0
Training loss: 4.192033050683458
Validation loss: 4.704966061193018

Epoch: 5| Step: 1
Training loss: 4.4949747212582825
Validation loss: 4.6994551390153045

Epoch: 5| Step: 2
Training loss: 4.20583984733265
Validation loss: 4.694455737728001

Epoch: 5| Step: 3
Training loss: 4.294984713828049
Validation loss: 4.688072110337017

Epoch: 5| Step: 4
Training loss: 4.947448558414648
Validation loss: 4.682744305224098

Epoch: 5| Step: 5
Training loss: 5.069963393220285
Validation loss: 4.676967579769282

Epoch: 5| Step: 6
Training loss: 4.441264100765022
Validation loss: 4.672710960555596

Epoch: 5| Step: 7
Training loss: 5.6962066074147515
Validation loss: 4.667908914733205

Epoch: 5| Step: 8
Training loss: 4.940548498923459
Validation loss: 4.6616576111321075

Epoch: 5| Step: 9
Training loss: 5.40783280151401
Validation loss: 4.6561402514877335

Epoch: 5| Step: 10
Training loss: 5.041760005034378
Validation loss: 4.6500422937254084

Epoch: 5| Step: 11
Training loss: 3.988203176842041
Validation loss: 4.645288275775178

Epoch: 20| Step: 0
Training loss: 5.095029518109318
Validation loss: 4.64011268913242

Epoch: 5| Step: 1
Training loss: 5.0919534522339065
Validation loss: 4.6340738759008495

Epoch: 5| Step: 2
Training loss: 4.4018595580697175
Validation loss: 4.628281288504561

Epoch: 5| Step: 3
Training loss: 4.00444046550482
Validation loss: 4.623148891374693

Epoch: 5| Step: 4
Training loss: 5.241575293459671
Validation loss: 4.616966805990157

Epoch: 5| Step: 5
Training loss: 5.062383014598859
Validation loss: 4.612076126305753

Epoch: 5| Step: 6
Training loss: 4.116654710842383
Validation loss: 4.606409573734785

Epoch: 5| Step: 7
Training loss: 5.354003705860975
Validation loss: 4.600595308911177

Epoch: 5| Step: 8
Training loss: 4.3271024852629445
Validation loss: 4.59564930065199

Epoch: 5| Step: 9
Training loss: 4.156639367701976
Validation loss: 4.588827895706404

Epoch: 5| Step: 10
Training loss: 4.9284240748015975
Validation loss: 4.583827060058301

Epoch: 5| Step: 11
Training loss: 5.148230587588652
Validation loss: 4.577794515509443

Epoch: 21| Step: 0
Training loss: 4.77315678996376
Validation loss: 4.572682114699667

Epoch: 5| Step: 1
Training loss: 5.073820290841015
Validation loss: 4.5679745511372145

Epoch: 5| Step: 2
Training loss: 4.255684361003899
Validation loss: 4.560806221296199

Epoch: 5| Step: 3
Training loss: 4.726318958407954
Validation loss: 4.555255403005792

Epoch: 5| Step: 4
Training loss: 4.439715624800936
Validation loss: 4.549029754061697

Epoch: 5| Step: 5
Training loss: 4.612489223726085
Validation loss: 4.543146682626641

Epoch: 5| Step: 6
Training loss: 4.995983417834701
Validation loss: 4.538191658738453

Epoch: 5| Step: 7
Training loss: 4.785426690380785
Validation loss: 4.5325429540591715

Epoch: 5| Step: 8
Training loss: 4.434111469978878
Validation loss: 4.525977599199381

Epoch: 5| Step: 9
Training loss: 4.762503780653847
Validation loss: 4.520196951918793

Epoch: 5| Step: 10
Training loss: 4.560252432946807
Validation loss: 4.5148347957390484

Epoch: 5| Step: 11
Training loss: 4.275515537519688
Validation loss: 4.51007196226598

Epoch: 22| Step: 0
Training loss: 4.7526747551122055
Validation loss: 4.506587729846664

Epoch: 5| Step: 1
Training loss: 4.251722772024461
Validation loss: 4.498017421840763

Epoch: 5| Step: 2
Training loss: 4.815019616773343
Validation loss: 4.493935949645816

Epoch: 5| Step: 3
Training loss: 5.135536899152192
Validation loss: 4.489427646436435

Epoch: 5| Step: 4
Training loss: 4.2590160103842045
Validation loss: 4.4848433636545115

Epoch: 5| Step: 5
Training loss: 4.716022840216463
Validation loss: 4.479110658280674

Epoch: 5| Step: 6
Training loss: 4.4298756608240515
Validation loss: 4.473040159759709

Epoch: 5| Step: 7
Training loss: 4.626685376711198
Validation loss: 4.4663873575667425

Epoch: 5| Step: 8
Training loss: 4.535078654253811
Validation loss: 4.460038356722983

Epoch: 5| Step: 9
Training loss: 4.558158167251938
Validation loss: 4.45344366082328

Epoch: 5| Step: 10
Training loss: 4.876733129486927
Validation loss: 4.448078307431602

Epoch: 5| Step: 11
Training loss: 2.3027186372977906
Validation loss: 4.442668510637172

Epoch: 23| Step: 0
Training loss: 4.500037299107572
Validation loss: 4.441593086833216

Epoch: 5| Step: 1
Training loss: 5.137879168772391
Validation loss: 4.431655052120105

Epoch: 5| Step: 2
Training loss: 4.699892067177206
Validation loss: 4.428089515186705

Epoch: 5| Step: 3
Training loss: 4.3552946731608735
Validation loss: 4.421825107612007

Epoch: 5| Step: 4
Training loss: 5.063308086185826
Validation loss: 4.416308917845592

Epoch: 5| Step: 5
Training loss: 4.847529161433407
Validation loss: 4.4113846209364045

Epoch: 5| Step: 6
Training loss: 4.2926270728167495
Validation loss: 4.406019678251121

Epoch: 5| Step: 7
Training loss: 4.5184653038152485
Validation loss: 4.400734247008212

Epoch: 5| Step: 8
Training loss: 5.145265658594293
Validation loss: 4.394391111046777

Epoch: 5| Step: 9
Training loss: 3.6318780825314154
Validation loss: 4.387378700731475

Epoch: 5| Step: 10
Training loss: 3.3911793339161926
Validation loss: 4.380962831497562

Epoch: 5| Step: 11
Training loss: 4.638034495683953
Validation loss: 4.376411936761237

Epoch: 24| Step: 0
Training loss: 4.776835479273378
Validation loss: 4.369984494828477

Epoch: 5| Step: 1
Training loss: 4.295726497788102
Validation loss: 4.365517548913767

Epoch: 5| Step: 2
Training loss: 5.283960854280651
Validation loss: 4.360114268488306

Epoch: 5| Step: 3
Training loss: 4.19863867723139
Validation loss: 4.354259050414357

Epoch: 5| Step: 4
Training loss: 4.017214924181965
Validation loss: 4.34801383660088

Epoch: 5| Step: 5
Training loss: 4.428775431069819
Validation loss: 4.342305983969551

Epoch: 5| Step: 6
Training loss: 4.5091142543345
Validation loss: 4.336458045482359

Epoch: 5| Step: 7
Training loss: 4.640892149560002
Validation loss: 4.3308205089314376

Epoch: 5| Step: 8
Training loss: 4.714750502327173
Validation loss: 4.324938876394491

Epoch: 5| Step: 9
Training loss: 3.357922475086917
Validation loss: 4.319009042746742

Epoch: 5| Step: 10
Training loss: 4.7176201080250815
Validation loss: 4.3137156942943955

Epoch: 5| Step: 11
Training loss: 4.453168688108064
Validation loss: 4.308255341129508

Epoch: 25| Step: 0
Training loss: 4.219387656164478
Validation loss: 4.3026241150412705

Epoch: 5| Step: 1
Training loss: 5.1502856351287045
Validation loss: 4.297292289122932

Epoch: 5| Step: 2
Training loss: 4.073979283845243
Validation loss: 4.290400048101142

Epoch: 5| Step: 3
Training loss: 5.021586170448171
Validation loss: 4.285239831740456

Epoch: 5| Step: 4
Training loss: 4.353101146712061
Validation loss: 4.278978408763163

Epoch: 5| Step: 5
Training loss: 4.1984333386132615
Validation loss: 4.2734903847201755

Epoch: 5| Step: 6
Training loss: 4.21886573915312
Validation loss: 4.267240262715136

Epoch: 5| Step: 7
Training loss: 4.493100705412089
Validation loss: 4.261235704794334

Epoch: 5| Step: 8
Training loss: 4.3932372226727905
Validation loss: 4.255310714156165

Epoch: 5| Step: 9
Training loss: 4.513476642792039
Validation loss: 4.249816320227403

Epoch: 5| Step: 10
Training loss: 3.8712264114267243
Validation loss: 4.2435286376629255

Epoch: 5| Step: 11
Training loss: 3.1083166727091687
Validation loss: 4.237641668624099

Epoch: 26| Step: 0
Training loss: 4.2436561360603955
Validation loss: 4.231722612155147

Epoch: 5| Step: 1
Training loss: 4.530429529032462
Validation loss: 4.225894036024734

Epoch: 5| Step: 2
Training loss: 3.9626700620529736
Validation loss: 4.220024500349375

Epoch: 5| Step: 3
Training loss: 4.8398199073136485
Validation loss: 4.214593318349739

Epoch: 5| Step: 4
Training loss: 3.446151527434135
Validation loss: 4.208798187693012

Epoch: 5| Step: 5
Training loss: 4.334803527462819
Validation loss: 4.202409685757862

Epoch: 5| Step: 6
Training loss: 4.04240447451104
Validation loss: 4.196734418902851

Epoch: 5| Step: 7
Training loss: 3.6678213266599777
Validation loss: 4.190405283797369

Epoch: 5| Step: 8
Training loss: 4.811538005641889
Validation loss: 4.1850130942659005

Epoch: 5| Step: 9
Training loss: 4.636483241899726
Validation loss: 4.179564686334528

Epoch: 5| Step: 10
Training loss: 4.672791662200976
Validation loss: 4.172793978891851

Epoch: 5| Step: 11
Training loss: 5.3229002631943105
Validation loss: 4.166135113506766

Epoch: 27| Step: 0
Training loss: 4.307665561498673
Validation loss: 4.161165776987964

Epoch: 5| Step: 1
Training loss: 4.832311302957057
Validation loss: 4.154672653211884

Epoch: 5| Step: 2
Training loss: 3.577434756405815
Validation loss: 4.147299879357268

Epoch: 5| Step: 3
Training loss: 4.786327383791157
Validation loss: 4.140494741634179

Epoch: 5| Step: 4
Training loss: 4.077927390970844
Validation loss: 4.134199346038853

Epoch: 5| Step: 5
Training loss: 4.095407863701533
Validation loss: 4.129477070183523

Epoch: 5| Step: 6
Training loss: 4.243843556245071
Validation loss: 4.122015875509836

Epoch: 5| Step: 7
Training loss: 4.0511492099482895
Validation loss: 4.115457778271638

Epoch: 5| Step: 8
Training loss: 4.170619818639774
Validation loss: 4.109579306045524

Epoch: 5| Step: 9
Training loss: 4.2684410776533435
Validation loss: 4.1046059884859005

Epoch: 5| Step: 10
Training loss: 4.465250846078885
Validation loss: 4.0990539387754605

Epoch: 5| Step: 11
Training loss: 3.391199581841481
Validation loss: 4.0912050048252855

Epoch: 28| Step: 0
Training loss: 3.9934913611203386
Validation loss: 4.084954395755567

Epoch: 5| Step: 1
Training loss: 3.7672694244400415
Validation loss: 4.078892646537444

Epoch: 5| Step: 2
Training loss: 4.545904626237731
Validation loss: 4.072707688742003

Epoch: 5| Step: 3
Training loss: 4.159934798243209
Validation loss: 4.067518596970072

Epoch: 5| Step: 4
Training loss: 4.362619156836037
Validation loss: 4.061875084961487

Epoch: 5| Step: 5
Training loss: 4.450734992889232
Validation loss: 4.053855742083956

Epoch: 5| Step: 6
Training loss: 3.9948873031819696
Validation loss: 4.047727330613339

Epoch: 5| Step: 7
Training loss: 3.3132429909110632
Validation loss: 4.042829516680866

Epoch: 5| Step: 8
Training loss: 4.442236937557407
Validation loss: 4.03740509086995

Epoch: 5| Step: 9
Training loss: 3.6945389629565026
Validation loss: 4.031850370900448

Epoch: 5| Step: 10
Training loss: 4.923618552784153
Validation loss: 4.025633045629326

Epoch: 5| Step: 11
Training loss: 4.876029272728565
Validation loss: 4.018634781439064

Epoch: 29| Step: 0
Training loss: 4.512476262164884
Validation loss: 4.0113847464118075

Epoch: 5| Step: 1
Training loss: 3.9856580874831478
Validation loss: 4.005621531205211

Epoch: 5| Step: 2
Training loss: 3.486820337934084
Validation loss: 4.00013847409409

Epoch: 5| Step: 3
Training loss: 4.446871894626243
Validation loss: 3.9936955758188764

Epoch: 5| Step: 4
Training loss: 3.3683863229435635
Validation loss: 3.9875602257225338

Epoch: 5| Step: 5
Training loss: 4.037174100684572
Validation loss: 3.9814203813745532

Epoch: 5| Step: 6
Training loss: 4.557742002489268
Validation loss: 3.9756781013667406

Epoch: 5| Step: 7
Training loss: 3.4410900442663546
Validation loss: 3.969888378691268

Epoch: 5| Step: 8
Training loss: 4.1372044668073755
Validation loss: 3.9633419556332785

Epoch: 5| Step: 9
Training loss: 4.485127987263439
Validation loss: 3.9577994973779442

Epoch: 5| Step: 10
Training loss: 4.239447339225412
Validation loss: 3.9516892118841884

Epoch: 5| Step: 11
Training loss: 5.4365152804692265
Validation loss: 3.945958790233147

Epoch: 30| Step: 0
Training loss: 3.867855869680964
Validation loss: 3.9390861101967447

Epoch: 5| Step: 1
Training loss: 3.952446197008453
Validation loss: 3.9324278431064585

Epoch: 5| Step: 2
Training loss: 4.302509622335895
Validation loss: 3.927241904837378

Epoch: 5| Step: 3
Training loss: 4.16023052310459
Validation loss: 3.920864816080489

Epoch: 5| Step: 4
Training loss: 3.7387957722098095
Validation loss: 3.91484157501548

Epoch: 5| Step: 5
Training loss: 4.0610271424882605
Validation loss: 3.9078204952474946

Epoch: 5| Step: 6
Training loss: 4.145976973046903
Validation loss: 3.9023871077329924

Epoch: 5| Step: 7
Training loss: 3.5071017558420055
Validation loss: 3.8959699324597112

Epoch: 5| Step: 8
Training loss: 4.560313916025443
Validation loss: 3.891446166084928

Epoch: 5| Step: 9
Training loss: 3.9006823114048697
Validation loss: 3.8850225584519955

Epoch: 5| Step: 10
Training loss: 4.0780599888556175
Validation loss: 3.8793469166219317

Epoch: 5| Step: 11
Training loss: 4.47582639597202
Validation loss: 3.8734044717722145

Epoch: 31| Step: 0
Training loss: 3.962908794122654
Validation loss: 3.8669303474598316

Epoch: 5| Step: 1
Training loss: 4.884987211025212
Validation loss: 3.8610917107272322

Epoch: 5| Step: 2
Training loss: 4.1136257683058535
Validation loss: 3.854405646604646

Epoch: 5| Step: 3
Training loss: 3.9627382898733448
Validation loss: 3.8488554762267175

Epoch: 5| Step: 4
Training loss: 3.180633928942689
Validation loss: 3.8427328402464282

Epoch: 5| Step: 5
Training loss: 4.319308669616337
Validation loss: 3.837537868035409

Epoch: 5| Step: 6
Training loss: 3.5556464945236828
Validation loss: 3.830704195143034

Epoch: 5| Step: 7
Training loss: 4.0454268644513895
Validation loss: 3.825873453686989

Epoch: 5| Step: 8
Training loss: 2.7385716957679467
Validation loss: 3.8198569714647452

Epoch: 5| Step: 9
Training loss: 4.484595529270976
Validation loss: 3.813889677535869

Epoch: 5| Step: 10
Training loss: 3.6897149626681602
Validation loss: 3.8081992650936094

Epoch: 5| Step: 11
Training loss: 5.309907527484773
Validation loss: 3.802800634297044

Epoch: 32| Step: 0
Training loss: 4.294332077795657
Validation loss: 3.7966921256023674

Epoch: 5| Step: 1
Training loss: 3.451844128870052
Validation loss: 3.791630391935999

Epoch: 5| Step: 2
Training loss: 3.835979267211511
Validation loss: 3.786067395009583

Epoch: 5| Step: 3
Training loss: 4.565253693967423
Validation loss: 3.7803641613633125

Epoch: 5| Step: 4
Training loss: 3.96493875925266
Validation loss: 3.774032824872032

Epoch: 5| Step: 5
Training loss: 4.184975845467742
Validation loss: 3.767642782476188

Epoch: 5| Step: 6
Training loss: 3.45091183540344
Validation loss: 3.7624471400910564

Epoch: 5| Step: 7
Training loss: 3.555227519506185
Validation loss: 3.75703210585435

Epoch: 5| Step: 8
Training loss: 3.600002654392535
Validation loss: 3.7514221038032125

Epoch: 5| Step: 9
Training loss: 3.873995004582766
Validation loss: 3.747290686890025

Epoch: 5| Step: 10
Training loss: 3.711385663727481
Validation loss: 3.7409840814326043

Epoch: 5| Step: 11
Training loss: 5.132460026127803
Validation loss: 3.735352450767528

Epoch: 33| Step: 0
Training loss: 3.5268795007855775
Validation loss: 3.72940646453706

Epoch: 5| Step: 1
Training loss: 4.004518817470166
Validation loss: 3.7255548038406694

Epoch: 5| Step: 2
Training loss: 4.023960353618091
Validation loss: 3.7222235776098516

Epoch: 5| Step: 3
Training loss: 2.8697471730590265
Validation loss: 3.7156787766825943

Epoch: 5| Step: 4
Training loss: 3.687240979424079
Validation loss: 3.7096938930556327

Epoch: 5| Step: 5
Training loss: 3.9952166089667123
Validation loss: 3.703604622857793

Epoch: 5| Step: 6
Training loss: 3.873533278954937
Validation loss: 3.6991019144912767

Epoch: 5| Step: 7
Training loss: 3.8381789858670308
Validation loss: 3.694755065897288

Epoch: 5| Step: 8
Training loss: 4.443439430940905
Validation loss: 3.688658176805907

Epoch: 5| Step: 9
Training loss: 3.9673691397360766
Validation loss: 3.6831169129925927

Epoch: 5| Step: 10
Training loss: 3.66571619256971
Validation loss: 3.677745347049693

Epoch: 5| Step: 11
Training loss: 4.416976318060979
Validation loss: 3.671825949699741

Epoch: 34| Step: 0
Training loss: 3.651877241889648
Validation loss: 3.666327410233064

Epoch: 5| Step: 1
Training loss: 2.6785408436073554
Validation loss: 3.6618331194629814

Epoch: 5| Step: 2
Training loss: 4.127496599626903
Validation loss: 3.6566546941600033

Epoch: 5| Step: 3
Training loss: 4.031439724974629
Validation loss: 3.651048938709514

Epoch: 5| Step: 4
Training loss: 3.110978829508315
Validation loss: 3.6452558096368968

Epoch: 5| Step: 5
Training loss: 3.426194204149604
Validation loss: 3.6399584693513187

Epoch: 5| Step: 6
Training loss: 4.3739243411204205
Validation loss: 3.6358641082215484

Epoch: 5| Step: 7
Training loss: 3.93124558974657
Validation loss: 3.6301350451623873

Epoch: 5| Step: 8
Training loss: 3.808059107105352
Validation loss: 3.624394536152924

Epoch: 5| Step: 9
Training loss: 3.675395949436174
Validation loss: 3.6194437404071405

Epoch: 5| Step: 10
Training loss: 4.330407157238328
Validation loss: 3.616016574670071

Epoch: 5| Step: 11
Training loss: 3.938966024050353
Validation loss: 3.609666771263252

Epoch: 35| Step: 0
Training loss: 4.199771493417687
Validation loss: 3.6040365033910193

Epoch: 5| Step: 1
Training loss: 4.522676762995457
Validation loss: 3.5980835645996754

Epoch: 5| Step: 2
Training loss: 2.989050592856413
Validation loss: 3.5930288503472236

Epoch: 5| Step: 3
Training loss: 3.955830850439027
Validation loss: 3.5873549464161383

Epoch: 5| Step: 4
Training loss: 3.703993297134168
Validation loss: 3.581826423604511

Epoch: 5| Step: 5
Training loss: 3.898138306169795
Validation loss: 3.5769601394480675

Epoch: 5| Step: 6
Training loss: 3.4187192256455967
Validation loss: 3.572093766911879

Epoch: 5| Step: 7
Training loss: 3.088799417085748
Validation loss: 3.5669716383032224

Epoch: 5| Step: 8
Training loss: 3.578708784297093
Validation loss: 3.5614747306548162

Epoch: 5| Step: 9
Training loss: 3.7439094675073425
Validation loss: 3.5561830497567297

Epoch: 5| Step: 10
Training loss: 3.378998824598882
Validation loss: 3.550731690763522

Epoch: 5| Step: 11
Training loss: 4.264156997209482
Validation loss: 3.54663510848707

Epoch: 36| Step: 0
Training loss: 3.7938735464174416
Validation loss: 3.5416091446786684

Epoch: 5| Step: 1
Training loss: 3.3037243605162576
Validation loss: 3.536892026770494

Epoch: 5| Step: 2
Training loss: 4.226821750439135
Validation loss: 3.531581272351808

Epoch: 5| Step: 3
Training loss: 3.8548726990259743
Validation loss: 3.5274950166122307

Epoch: 5| Step: 4
Training loss: 3.304108841828226
Validation loss: 3.5222858935052157

Epoch: 5| Step: 5
Training loss: 3.5660995234509687
Validation loss: 3.5169441009000546

Epoch: 5| Step: 6
Training loss: 3.6849269618504468
Validation loss: 3.511836654273607

Epoch: 5| Step: 7
Training loss: 3.746514289807323
Validation loss: 3.506457808485104

Epoch: 5| Step: 8
Training loss: 3.453912291384532
Validation loss: 3.5021953055783044

Epoch: 5| Step: 9
Training loss: 3.536602184008624
Validation loss: 3.4978436912087227

Epoch: 5| Step: 10
Training loss: 3.624015674464536
Validation loss: 3.492596834843214

Epoch: 5| Step: 11
Training loss: 3.788543728581475
Validation loss: 3.4883713434708947

Epoch: 37| Step: 0
Training loss: 3.2323945842409123
Validation loss: 3.4833650422516254

Epoch: 5| Step: 1
Training loss: 3.590765601211563
Validation loss: 3.4784613406418425

Epoch: 5| Step: 2
Training loss: 3.5841477525772687
Validation loss: 3.474834587084744

Epoch: 5| Step: 3
Training loss: 3.209828874536553
Validation loss: 3.4703992582878334

Epoch: 5| Step: 4
Training loss: 3.364031168662881
Validation loss: 3.4660499076075

Epoch: 5| Step: 5
Training loss: 3.4323522690713175
Validation loss: 3.4614840751162976

Epoch: 5| Step: 6
Training loss: 3.700587952783863
Validation loss: 3.4576529365930617

Epoch: 5| Step: 7
Training loss: 4.003011761745505
Validation loss: 3.45324268974794

Epoch: 5| Step: 8
Training loss: 4.0542445887218825
Validation loss: 3.448963540335484

Epoch: 5| Step: 9
Training loss: 3.89437060852244
Validation loss: 3.444742433841937

Epoch: 5| Step: 10
Training loss: 3.6732655590841388
Validation loss: 3.4396235178112136

Epoch: 5| Step: 11
Training loss: 1.82859131172133
Validation loss: 3.435374776300656

Epoch: 38| Step: 0
Training loss: 3.5288538272081023
Validation loss: 3.431219374352661

Epoch: 5| Step: 1
Training loss: 3.840719501521515
Validation loss: 3.4267334551709716

Epoch: 5| Step: 2
Training loss: 3.112851600244387
Validation loss: 3.422816282082353

Epoch: 5| Step: 3
Training loss: 3.6696895507557286
Validation loss: 3.418391610282264

Epoch: 5| Step: 4
Training loss: 4.272649437805984
Validation loss: 3.4145078041299177

Epoch: 5| Step: 5
Training loss: 3.159101652098428
Validation loss: 3.4105457317994246

Epoch: 5| Step: 6
Training loss: 3.524226943936523
Validation loss: 3.4059273161559265

Epoch: 5| Step: 7
Training loss: 3.5712810513138202
Validation loss: 3.4013939811796843

Epoch: 5| Step: 8
Training loss: 3.353953257972603
Validation loss: 3.3972825875892685

Epoch: 5| Step: 9
Training loss: 3.4764618248239123
Validation loss: 3.3928344899092955

Epoch: 5| Step: 10
Training loss: 3.5704624803957223
Validation loss: 3.389015858952004

Epoch: 5| Step: 11
Training loss: 2.494401002584455
Validation loss: 3.3845526937728794

Epoch: 39| Step: 0
Training loss: 3.492089460050683
Validation loss: 3.3804203558651342

Epoch: 5| Step: 1
Training loss: 2.8811399161602167
Validation loss: 3.3763685865971773

Epoch: 5| Step: 2
Training loss: 3.9826146444425086
Validation loss: 3.3729562193161735

Epoch: 5| Step: 3
Training loss: 3.528835585255929
Validation loss: 3.3691384312719306

Epoch: 5| Step: 4
Training loss: 3.8947396332634465
Validation loss: 3.3644826281488296

Epoch: 5| Step: 5
Training loss: 2.71970973120914
Validation loss: 3.360385033225445

Epoch: 5| Step: 6
Training loss: 3.769791320367892
Validation loss: 3.356655279656055

Epoch: 5| Step: 7
Training loss: 3.32215869513949
Validation loss: 3.3528431873811657

Epoch: 5| Step: 8
Training loss: 3.6632053047649946
Validation loss: 3.34835436028435

Epoch: 5| Step: 9
Training loss: 3.784473526898221
Validation loss: 3.3449503446465756

Epoch: 5| Step: 10
Training loss: 3.1346299376786737
Validation loss: 3.3406273322339626

Epoch: 5| Step: 11
Training loss: 3.84925931270806
Validation loss: 3.3362143860973394

Epoch: 40| Step: 0
Training loss: 4.180048447469641
Validation loss: 3.3320862384297083

Epoch: 5| Step: 1
Training loss: 2.674761456700437
Validation loss: 3.3279101760614376

Epoch: 5| Step: 2
Training loss: 3.090102540570891
Validation loss: 3.323908126788205

Epoch: 5| Step: 3
Training loss: 3.7039284136386024
Validation loss: 3.319728294288767

Epoch: 5| Step: 4
Training loss: 3.5967604260130797
Validation loss: 3.31559017880989

Epoch: 5| Step: 5
Training loss: 3.524248727591897
Validation loss: 3.3128232138471607

Epoch: 5| Step: 6
Training loss: 3.7487432281239634
Validation loss: 3.307697203195517

Epoch: 5| Step: 7
Training loss: 3.2591909881467207
Validation loss: 3.303261331170642

Epoch: 5| Step: 8
Training loss: 3.2325701261792457
Validation loss: 3.2995745437594275

Epoch: 5| Step: 9
Training loss: 3.10625895876907
Validation loss: 3.2960893619951492

Epoch: 5| Step: 10
Training loss: 3.6828453298795916
Validation loss: 3.291288255516768

Epoch: 5| Step: 11
Training loss: 3.0901567032964095
Validation loss: 3.2875480034324736

Epoch: 41| Step: 0
Training loss: 3.3391766512132617
Validation loss: 3.283947783226551

Epoch: 5| Step: 1
Training loss: 3.4035121168602087
Validation loss: 3.279999119125612

Epoch: 5| Step: 2
Training loss: 3.1024665187655183
Validation loss: 3.2763322035262012

Epoch: 5| Step: 3
Training loss: 3.422249133415706
Validation loss: 3.271922942414215

Epoch: 5| Step: 4
Training loss: 3.6168686003205677
Validation loss: 3.2687120220246486

Epoch: 5| Step: 5
Training loss: 3.204678489043737
Validation loss: 3.2648264016466944

Epoch: 5| Step: 6
Training loss: 3.855493238191608
Validation loss: 3.2609984251605577

Epoch: 5| Step: 7
Training loss: 3.3554040904803997
Validation loss: 3.257263716742569

Epoch: 5| Step: 8
Training loss: 3.231939458431093
Validation loss: 3.253629436831223

Epoch: 5| Step: 9
Training loss: 3.3951775009204375
Validation loss: 3.2491528495115825

Epoch: 5| Step: 10
Training loss: 3.3159491377865264
Validation loss: 3.245672860461468

Epoch: 5| Step: 11
Training loss: 4.031632516145198
Validation loss: 3.241313261872897

Epoch: 42| Step: 0
Training loss: 3.4237508291777616
Validation loss: 3.237433997209274

Epoch: 5| Step: 1
Training loss: 2.684445530561027
Validation loss: 3.233509801853405

Epoch: 5| Step: 2
Training loss: 2.7694183025276264
Validation loss: 3.2295441663212068

Epoch: 5| Step: 3
Training loss: 2.8840002078877665
Validation loss: 3.2262603642936316

Epoch: 5| Step: 4
Training loss: 3.710505731460757
Validation loss: 3.222268499301506

Epoch: 5| Step: 5
Training loss: 3.2739644866862876
Validation loss: 3.2188370146609784

Epoch: 5| Step: 6
Training loss: 4.228542914533765
Validation loss: 3.21559274012847

Epoch: 5| Step: 7
Training loss: 3.009507373025675
Validation loss: 3.2119307640803605

Epoch: 5| Step: 8
Training loss: 3.562343928615971
Validation loss: 3.2081481221644843

Epoch: 5| Step: 9
Training loss: 3.454576420302984
Validation loss: 3.2046301616050745

Epoch: 5| Step: 10
Training loss: 3.476824186955957
Validation loss: 3.2003039024507474

Epoch: 5| Step: 11
Training loss: 4.019984865682021
Validation loss: 3.196879987193842

Epoch: 43| Step: 0
Training loss: 3.4262945471355013
Validation loss: 3.193181764599987

Epoch: 5| Step: 1
Training loss: 2.9133229480561216
Validation loss: 3.189381106689316

Epoch: 5| Step: 2
Training loss: 2.929140736739606
Validation loss: 3.185031377487087

Epoch: 5| Step: 3
Training loss: 3.803809344643276
Validation loss: 3.181866039317705

Epoch: 5| Step: 4
Training loss: 3.43186488800143
Validation loss: 3.177416040895511

Epoch: 5| Step: 5
Training loss: 3.288922884553475
Validation loss: 3.1738503730189778

Epoch: 5| Step: 6
Training loss: 2.945388752484004
Validation loss: 3.170236665518426

Epoch: 5| Step: 7
Training loss: 3.5775192614236104
Validation loss: 3.1663059177624056

Epoch: 5| Step: 8
Training loss: 3.2782525313219315
Validation loss: 3.162714924752784

Epoch: 5| Step: 9
Training loss: 3.185800136506624
Validation loss: 3.1591756687993664

Epoch: 5| Step: 10
Training loss: 3.4522246831219356
Validation loss: 3.1564046802954007

Epoch: 5| Step: 11
Training loss: 3.8018943983539772
Validation loss: 3.1525971579850607

Epoch: 44| Step: 0
Training loss: 2.997677539852239
Validation loss: 3.1485388481544674

Epoch: 5| Step: 1
Training loss: 3.0702612486776815
Validation loss: 3.144545406207015

Epoch: 5| Step: 2
Training loss: 3.0335161056229336
Validation loss: 3.1408388055551466

Epoch: 5| Step: 3
Training loss: 3.211881104459972
Validation loss: 3.1372053909792244

Epoch: 5| Step: 4
Training loss: 3.3437782357708246
Validation loss: 3.1339550519193744

Epoch: 5| Step: 5
Training loss: 3.577724117827037
Validation loss: 3.1308934651512095

Epoch: 5| Step: 6
Training loss: 3.7092261936128
Validation loss: 3.1272599504386576

Epoch: 5| Step: 7
Training loss: 3.4088154502323347
Validation loss: 3.124003804685642

Epoch: 5| Step: 8
Training loss: 3.6720456347486694
Validation loss: 3.120261840969411

Epoch: 5| Step: 9
Training loss: 3.080041898467207
Validation loss: 3.1170271893599333

Epoch: 5| Step: 10
Training loss: 2.7809501229113414
Validation loss: 3.1132768561548794

Epoch: 5| Step: 11
Training loss: 3.069961799607579
Validation loss: 3.109853046416566

Epoch: 45| Step: 0
Training loss: 2.9780247418238552
Validation loss: 3.1063920222051356

Epoch: 5| Step: 1
Training loss: 3.373698089415078
Validation loss: 3.1031600111426565

Epoch: 5| Step: 2
Training loss: 3.25748769481147
Validation loss: 3.099988741495341

Epoch: 5| Step: 3
Training loss: 3.2926607361229254
Validation loss: 3.096415302816291

Epoch: 5| Step: 4
Training loss: 3.324403499933649
Validation loss: 3.0930177355024613

Epoch: 5| Step: 5
Training loss: 3.2068013748879736
Validation loss: 3.0899354235476246

Epoch: 5| Step: 6
Training loss: 3.0524485155867276
Validation loss: 3.0868473369591825

Epoch: 5| Step: 7
Training loss: 3.679028364946784
Validation loss: 3.083446975280548

Epoch: 5| Step: 8
Training loss: 3.002074795741044
Validation loss: 3.080429837584712

Epoch: 5| Step: 9
Training loss: 3.001819059099702
Validation loss: 3.0774278286916523

Epoch: 5| Step: 10
Training loss: 3.3336609838306512
Validation loss: 3.074127758186979

Epoch: 5| Step: 11
Training loss: 3.127928315494938
Validation loss: 3.0712425758066106

Epoch: 46| Step: 0
Training loss: 3.2080082584189187
Validation loss: 3.0680566319059417

Epoch: 5| Step: 1
Training loss: 3.3302909000022347
Validation loss: 3.0648336374863288

Epoch: 5| Step: 2
Training loss: 3.7474353921625676
Validation loss: 3.061655359503422

Epoch: 5| Step: 3
Training loss: 3.264634415633214
Validation loss: 3.058124978887798

Epoch: 5| Step: 4
Training loss: 3.037916266406831
Validation loss: 3.0547774643914636

Epoch: 5| Step: 5
Training loss: 2.8413204672080705
Validation loss: 3.0518323688809366

Epoch: 5| Step: 6
Training loss: 2.8810215791200644
Validation loss: 3.0487547691915804

Epoch: 5| Step: 7
Training loss: 3.428889640164686
Validation loss: 3.045975788810266

Epoch: 5| Step: 8
Training loss: 3.162888448025912
Validation loss: 3.0426861783198023

Epoch: 5| Step: 9
Training loss: 3.4640487567386375
Validation loss: 3.0394287313650796

Epoch: 5| Step: 10
Training loss: 2.813033413636705
Validation loss: 3.036064417933615

Epoch: 5| Step: 11
Training loss: 2.1737050641127724
Validation loss: 3.033552560290043

Epoch: 47| Step: 0
Training loss: 3.212347533174012
Validation loss: 3.030670533391819

Epoch: 5| Step: 1
Training loss: 3.193517203907446
Validation loss: 3.0281944900743487

Epoch: 5| Step: 2
Training loss: 2.6708816555688495
Validation loss: 3.0254514165606783

Epoch: 5| Step: 3
Training loss: 3.220918535994839
Validation loss: 3.023359246765027

Epoch: 5| Step: 4
Training loss: 3.6916364325554727
Validation loss: 3.0199249392564513

Epoch: 5| Step: 5
Training loss: 3.1592141009524406
Validation loss: 3.0170412740333927

Epoch: 5| Step: 6
Training loss: 3.5024534890288064
Validation loss: 3.01465017740677

Epoch: 5| Step: 7
Training loss: 3.477094356701479
Validation loss: 3.0114499082197845

Epoch: 5| Step: 8
Training loss: 2.8762096679724487
Validation loss: 3.0083349987846124

Epoch: 5| Step: 9
Training loss: 2.708969853258437
Validation loss: 3.006065806074856

Epoch: 5| Step: 10
Training loss: 3.0522663638769614
Validation loss: 3.0027463680229807

Epoch: 5| Step: 11
Training loss: 2.183834820100727
Validation loss: 2.9999449314255413

Epoch: 48| Step: 0
Training loss: 3.5011782706450285
Validation loss: 2.9977500147268756

Epoch: 5| Step: 1
Training loss: 2.813597486201886
Validation loss: 2.9958225875223174

Epoch: 5| Step: 2
Training loss: 2.86989405473024
Validation loss: 2.9938029782964

Epoch: 5| Step: 3
Training loss: 3.238455883880591
Validation loss: 2.990771663342098

Epoch: 5| Step: 4
Training loss: 3.698398841620414
Validation loss: 2.988191487744781

Epoch: 5| Step: 5
Training loss: 2.7161766238248837
Validation loss: 2.9860681920084517

Epoch: 5| Step: 6
Training loss: 3.0575226799910524
Validation loss: 2.9829469596193854

Epoch: 5| Step: 7
Training loss: 3.0322386712217972
Validation loss: 2.9799949332701945

Epoch: 5| Step: 8
Training loss: 3.3210870534990415
Validation loss: 2.977069524533223

Epoch: 5| Step: 9
Training loss: 2.812119352225234
Validation loss: 2.9748456714575235

Epoch: 5| Step: 10
Training loss: 3.3663708610383156
Validation loss: 2.972607101321525

Epoch: 5| Step: 11
Training loss: 2.0370778916176313
Validation loss: 2.96996953911686

Epoch: 49| Step: 0
Training loss: 3.270724171236254
Validation loss: 2.9681064008466196

Epoch: 5| Step: 1
Training loss: 2.8920472641244452
Validation loss: 2.9655641158955346

Epoch: 5| Step: 2
Training loss: 3.0406127741255204
Validation loss: 2.964127482129419

Epoch: 5| Step: 3
Training loss: 2.7855938197208143
Validation loss: 2.962060720332637

Epoch: 5| Step: 4
Training loss: 3.6624765440935123
Validation loss: 2.9603148672187776

Epoch: 5| Step: 5
Training loss: 3.3966110056720566
Validation loss: 2.9581989013770675

Epoch: 5| Step: 6
Training loss: 2.6230514196837955
Validation loss: 2.955010402632087

Epoch: 5| Step: 7
Training loss: 2.8010105693580956
Validation loss: 2.9526592371747302

Epoch: 5| Step: 8
Training loss: 3.294250021807203
Validation loss: 2.9498847529426837

Epoch: 5| Step: 9
Training loss: 3.0403154237136953
Validation loss: 2.9467995529791695

Epoch: 5| Step: 10
Training loss: 3.1814173086721813
Validation loss: 2.943510214103229

Epoch: 5| Step: 11
Training loss: 2.8332947747093855
Validation loss: 2.941593685991899

Epoch: 50| Step: 0
Training loss: 3.0518589045756195
Validation loss: 2.939856240310783

Epoch: 5| Step: 1
Training loss: 3.1052152326256186
Validation loss: 2.9380355610529336

Epoch: 5| Step: 2
Training loss: 2.7262594060022827
Validation loss: 2.9348320952667093

Epoch: 5| Step: 3
Training loss: 3.5259834108184203
Validation loss: 2.9325124827978635

Epoch: 5| Step: 4
Training loss: 2.9564109968094194
Validation loss: 2.929692128495693

Epoch: 5| Step: 5
Training loss: 3.1266350092908577
Validation loss: 2.92760737853911

Epoch: 5| Step: 6
Training loss: 3.4823469751917946
Validation loss: 2.924804558432889

Epoch: 5| Step: 7
Training loss: 3.251719533417855
Validation loss: 2.922047846232466

Epoch: 5| Step: 8
Training loss: 2.936542436077135
Validation loss: 2.9188117529240243

Epoch: 5| Step: 9
Training loss: 2.9444808797761257
Validation loss: 2.9169329975782157

Epoch: 5| Step: 10
Training loss: 2.8061266423832802
Validation loss: 2.914477202060328

Epoch: 5| Step: 11
Training loss: 1.3674444338651799
Validation loss: 2.9117552424461413

Epoch: 51| Step: 0
Training loss: 3.176843969781551
Validation loss: 2.9102466816687307

Epoch: 5| Step: 1
Training loss: 2.945847359011946
Validation loss: 2.9070413154797543

Epoch: 5| Step: 2
Training loss: 3.024060246800936
Validation loss: 2.9064976849855455

Epoch: 5| Step: 3
Training loss: 3.6397376554918988
Validation loss: 2.9034863050398525

Epoch: 5| Step: 4
Training loss: 2.465808226300825
Validation loss: 2.90074176824817

Epoch: 5| Step: 5
Training loss: 2.5002342114411094
Validation loss: 2.8983707334603537

Epoch: 5| Step: 6
Training loss: 2.733708763701124
Validation loss: 2.896705864197371

Epoch: 5| Step: 7
Training loss: 3.3246952347441807
Validation loss: 2.8945549446127994

Epoch: 5| Step: 8
Training loss: 2.8840122775955335
Validation loss: 2.8933668896399976

Epoch: 5| Step: 9
Training loss: 3.307699792065282
Validation loss: 2.8891893206679136

Epoch: 5| Step: 10
Training loss: 3.2026560370305646
Validation loss: 2.8869037112944334

Epoch: 5| Step: 11
Training loss: 3.187758790524682
Validation loss: 2.885855160571074

Epoch: 52| Step: 0
Training loss: 3.430860453521549
Validation loss: 2.883727303272182

Epoch: 5| Step: 1
Training loss: 2.3421641770436508
Validation loss: 2.8818279504530664

Epoch: 5| Step: 2
Training loss: 3.437611803490764
Validation loss: 2.8792543584679056

Epoch: 5| Step: 3
Training loss: 3.0623000721969973
Validation loss: 2.8775234792222624

Epoch: 5| Step: 4
Training loss: 3.151275188946101
Validation loss: 2.8749681346620104

Epoch: 5| Step: 5
Training loss: 2.625774269355772
Validation loss: 2.8732717855190675

Epoch: 5| Step: 6
Training loss: 3.007698829781896
Validation loss: 2.871396729967849

Epoch: 5| Step: 7
Training loss: 3.3766924535200387
Validation loss: 2.8689411181391677

Epoch: 5| Step: 8
Training loss: 2.7020593207318573
Validation loss: 2.867266803722261

Epoch: 5| Step: 9
Training loss: 3.2234838544329705
Validation loss: 2.8652369892062497

Epoch: 5| Step: 10
Training loss: 2.7281424855024734
Validation loss: 2.862461175613644

Epoch: 5| Step: 11
Training loss: 2.232884903862374
Validation loss: 2.860415708778334

Epoch: 53| Step: 0
Training loss: 3.0609891629106665
Validation loss: 2.8587625573764694

Epoch: 5| Step: 1
Training loss: 2.9855665454568374
Validation loss: 2.8563119397448626

Epoch: 5| Step: 2
Training loss: 2.9994286946861792
Validation loss: 2.854010376978648

Epoch: 5| Step: 3
Training loss: 2.7755667236642334
Validation loss: 2.8523613877570884

Epoch: 5| Step: 4
Training loss: 3.2965624331153274
Validation loss: 2.8499882363193736

Epoch: 5| Step: 5
Training loss: 2.549018659814454
Validation loss: 2.8490471672049154

Epoch: 5| Step: 6
Training loss: 2.7730140900114626
Validation loss: 2.8465427511877723

Epoch: 5| Step: 7
Training loss: 3.18476750553805
Validation loss: 2.843691161528624

Epoch: 5| Step: 8
Training loss: 2.9455428703735573
Validation loss: 2.841086076107437

Epoch: 5| Step: 9
Training loss: 3.3410693680459147
Validation loss: 2.8407863047970454

Epoch: 5| Step: 10
Training loss: 2.952118232716387
Validation loss: 2.8375665243755797

Epoch: 5| Step: 11
Training loss: 2.679618634376131
Validation loss: 2.835747977825669

Epoch: 54| Step: 0
Training loss: 2.717297922603097
Validation loss: 2.8340879386769395

Epoch: 5| Step: 1
Training loss: 3.071174946955899
Validation loss: 2.8329246812993114

Epoch: 5| Step: 2
Training loss: 3.0570826981639025
Validation loss: 2.830741637809863

Epoch: 5| Step: 3
Training loss: 3.006622316776303
Validation loss: 2.8293728543085157

Epoch: 5| Step: 4
Training loss: 2.8188150504106564
Validation loss: 2.8273425697168895

Epoch: 5| Step: 5
Training loss: 2.984013240917784
Validation loss: 2.8255587046439383

Epoch: 5| Step: 6
Training loss: 2.970346122121979
Validation loss: 2.822955762350789

Epoch: 5| Step: 7
Training loss: 2.895109090643825
Validation loss: 2.820264320983497

Epoch: 5| Step: 8
Training loss: 2.990899428768104
Validation loss: 2.8189801373812124

Epoch: 5| Step: 9
Training loss: 3.3572187733980123
Validation loss: 2.816783176124832

Epoch: 5| Step: 10
Training loss: 2.9265158613392
Validation loss: 2.8150143263482206

Epoch: 5| Step: 11
Training loss: 1.811293364769848
Validation loss: 2.81278604889504

Epoch: 55| Step: 0
Training loss: 2.930556511740707
Validation loss: 2.812435965338877

Epoch: 5| Step: 1
Training loss: 3.1812951525048843
Validation loss: 2.816336184268098

Epoch: 5| Step: 2
Training loss: 3.2166809542903594
Validation loss: 2.8200544660180484

Epoch: 5| Step: 3
Training loss: 2.942836864443896
Validation loss: 2.8137004656832776

Epoch: 5| Step: 4
Training loss: 2.9435336865687205
Validation loss: 2.8052821578264964

Epoch: 5| Step: 5
Training loss: 2.880031495186996
Validation loss: 2.8023715751378937

Epoch: 5| Step: 6
Training loss: 2.9976934466963447
Validation loss: 2.8040903105597157

Epoch: 5| Step: 7
Training loss: 2.7452480701578357
Validation loss: 2.8010663464244985

Epoch: 5| Step: 8
Training loss: 2.555293113482872
Validation loss: 2.800095137614721

Epoch: 5| Step: 9
Training loss: 3.1110237389360487
Validation loss: 2.7974553598280276

Epoch: 5| Step: 10
Training loss: 3.0376682564558126
Validation loss: 2.7964683642024304

Epoch: 5| Step: 11
Training loss: 1.7804670118764483
Validation loss: 2.7962039092665925

Epoch: 56| Step: 0
Training loss: 2.6612511620758657
Validation loss: 2.7959985194368313

Epoch: 5| Step: 1
Training loss: 2.904244828415205
Validation loss: 2.7969581158327097

Epoch: 5| Step: 2
Training loss: 3.788547001015858
Validation loss: 2.7930200460920815

Epoch: 5| Step: 3
Training loss: 2.84823104436636
Validation loss: 2.7910243203962235

Epoch: 5| Step: 4
Training loss: 2.216118985352269
Validation loss: 2.78720329285041

Epoch: 5| Step: 5
Training loss: 2.760213870870436
Validation loss: 2.784622355219145

Epoch: 5| Step: 6
Training loss: 2.990892732727819
Validation loss: 2.782914938478999

Epoch: 5| Step: 7
Training loss: 3.022850590795864
Validation loss: 2.78131059873478

Epoch: 5| Step: 8
Training loss: 2.8142484528285783
Validation loss: 2.780021599798886

Epoch: 5| Step: 9
Training loss: 3.117795344773234
Validation loss: 2.7762063975361744

Epoch: 5| Step: 10
Training loss: 2.954362236691015
Validation loss: 2.774561211115468

Epoch: 5| Step: 11
Training loss: 2.2334635549509074
Validation loss: 2.77086918432423

Epoch: 57| Step: 0
Training loss: 2.6504553925395156
Validation loss: 2.7694696689461553

Epoch: 5| Step: 1
Training loss: 2.9557444747102672
Validation loss: 2.7689221263337274

Epoch: 5| Step: 2
Training loss: 3.096545565084665
Validation loss: 2.7717472567361927

Epoch: 5| Step: 3
Training loss: 2.832181771323202
Validation loss: 2.782845725150855

Epoch: 5| Step: 4
Training loss: 3.0680516584640336
Validation loss: 2.786683097877231

Epoch: 5| Step: 5
Training loss: 2.578998579506337
Validation loss: 2.7678657656856123

Epoch: 5| Step: 6
Training loss: 3.156168266220105
Validation loss: 2.761690185485483

Epoch: 5| Step: 7
Training loss: 3.0282225287038615
Validation loss: 2.7688011351284456

Epoch: 5| Step: 8
Training loss: 2.766829578551604
Validation loss: 2.7819962518339048

Epoch: 5| Step: 9
Training loss: 2.8897781368746784
Validation loss: 2.804773285101977

Epoch: 5| Step: 10
Training loss: 3.042663480555844
Validation loss: 2.799017861380038

Epoch: 5| Step: 11
Training loss: 2.860022966519422
Validation loss: 2.7857072453706806

Epoch: 58| Step: 0
Training loss: 2.7308575485718842
Validation loss: 2.7785665160528086

Epoch: 5| Step: 1
Training loss: 2.6867951644320107
Validation loss: 2.7743812567151993

Epoch: 5| Step: 2
Training loss: 2.653577919123097
Validation loss: 2.772790824466924

Epoch: 5| Step: 3
Training loss: 2.8989722897276695
Validation loss: 2.773166969250543

Epoch: 5| Step: 4
Training loss: 3.054343123670662
Validation loss: 2.775106986019717

Epoch: 5| Step: 5
Training loss: 2.9465965487335217
Validation loss: 2.7697204862364355

Epoch: 5| Step: 6
Training loss: 3.0577190215296146
Validation loss: 2.763041728399416

Epoch: 5| Step: 7
Training loss: 3.1730545932366425
Validation loss: 2.7555293573416804

Epoch: 5| Step: 8
Training loss: 2.8049234700090167
Validation loss: 2.7516349606754287

Epoch: 5| Step: 9
Training loss: 3.2072081801643444
Validation loss: 2.74788934816013

Epoch: 5| Step: 10
Training loss: 2.7223237325811134
Validation loss: 2.7442587721834655

Epoch: 5| Step: 11
Training loss: 2.4335600481715343
Validation loss: 2.7422307799891605

Epoch: 59| Step: 0
Training loss: 2.7737641477976136
Validation loss: 2.7390783168396253

Epoch: 5| Step: 1
Training loss: 2.7401594612610465
Validation loss: 2.740563142485107

Epoch: 5| Step: 2
Training loss: 3.1871749113769154
Validation loss: 2.73931456771687

Epoch: 5| Step: 3
Training loss: 3.17795449908881
Validation loss: 2.738237653631037

Epoch: 5| Step: 4
Training loss: 2.6651173402243113
Validation loss: 2.7354381492644713

Epoch: 5| Step: 5
Training loss: 2.8675350633388144
Validation loss: 2.733764943688296

Epoch: 5| Step: 6
Training loss: 2.418455996129018
Validation loss: 2.7328879827068207

Epoch: 5| Step: 7
Training loss: 2.7495114152542675
Validation loss: 2.7319685455622746

Epoch: 5| Step: 8
Training loss: 3.291140518308947
Validation loss: 2.728973550491741

Epoch: 5| Step: 9
Training loss: 2.9355103267747285
Validation loss: 2.7252928684354116

Epoch: 5| Step: 10
Training loss: 2.849699901374365
Validation loss: 2.720889090384896

Epoch: 5| Step: 11
Training loss: 1.8564493579609722
Validation loss: 2.7172936269440164

Epoch: 60| Step: 0
Training loss: 2.88253989649455
Validation loss: 2.714053888477462

Epoch: 5| Step: 1
Training loss: 2.7993982111144655
Validation loss: 2.7137729829294974

Epoch: 5| Step: 2
Training loss: 2.582568506622844
Validation loss: 2.714304856346986

Epoch: 5| Step: 3
Training loss: 2.6027980310590024
Validation loss: 2.7162442151420727

Epoch: 5| Step: 4
Training loss: 2.5664406226888627
Validation loss: 2.716222819879743

Epoch: 5| Step: 5
Training loss: 2.9020422551702203
Validation loss: 2.7180182067693104

Epoch: 5| Step: 6
Training loss: 2.7306059228497435
Validation loss: 2.7197335097602586

Epoch: 5| Step: 7
Training loss: 2.8979654673222868
Validation loss: 2.7179771691484604

Epoch: 5| Step: 8
Training loss: 3.0371266453488066
Validation loss: 2.714131338197812

Epoch: 5| Step: 9
Training loss: 2.804348640904631
Validation loss: 2.713173115767984

Epoch: 5| Step: 10
Training loss: 3.5493718572093162
Validation loss: 2.7104786787824127

Epoch: 5| Step: 11
Training loss: 2.525174042397271
Validation loss: 2.7096520270162787

Epoch: 61| Step: 0
Training loss: 2.5725725898844156
Validation loss: 2.7072153070143057

Epoch: 5| Step: 1
Training loss: 2.5759653004269887
Validation loss: 2.7054021501252046

Epoch: 5| Step: 2
Training loss: 3.1583038295149515
Validation loss: 2.703127212376507

Epoch: 5| Step: 3
Training loss: 2.815531389752803
Validation loss: 2.6996314013508087

Epoch: 5| Step: 4
Training loss: 2.953099972250509
Validation loss: 2.696803939902763

Epoch: 5| Step: 5
Training loss: 2.9425529686528393
Validation loss: 2.694344144824567

Epoch: 5| Step: 6
Training loss: 3.2198201594865568
Validation loss: 2.6926525572577686

Epoch: 5| Step: 7
Training loss: 3.085780813367893
Validation loss: 2.689447237191627

Epoch: 5| Step: 8
Training loss: 2.390273722851383
Validation loss: 2.687818135054308

Epoch: 5| Step: 9
Training loss: 2.5848884413828253
Validation loss: 2.68612342148092

Epoch: 5| Step: 10
Training loss: 2.815937061354231
Validation loss: 2.6843613327797535

Epoch: 5| Step: 11
Training loss: 2.706251420159441
Validation loss: 2.6823308231989413

Epoch: 62| Step: 0
Training loss: 2.8269645038126407
Validation loss: 2.68225922549484

Epoch: 5| Step: 1
Training loss: 2.942097900452527
Validation loss: 2.680096634900643

Epoch: 5| Step: 2
Training loss: 3.117976268127446
Validation loss: 2.6805246600630968

Epoch: 5| Step: 3
Training loss: 3.090261939838033
Validation loss: 2.678937219363053

Epoch: 5| Step: 4
Training loss: 2.7712023687678515
Validation loss: 2.6787988507137195

Epoch: 5| Step: 5
Training loss: 2.5916826212924446
Validation loss: 2.6754931849399592

Epoch: 5| Step: 6
Training loss: 2.5042168339820576
Validation loss: 2.6766968508744924

Epoch: 5| Step: 7
Training loss: 3.0811921151006945
Validation loss: 2.673744614613397

Epoch: 5| Step: 8
Training loss: 2.4835869840929976
Validation loss: 2.670851059516091

Epoch: 5| Step: 9
Training loss: 2.6430286550653554
Validation loss: 2.6710878387561303

Epoch: 5| Step: 10
Training loss: 2.915378140612087
Validation loss: 2.6677921920002827

Epoch: 5| Step: 11
Training loss: 2.522431353116049
Validation loss: 2.6660179017072374

Epoch: 63| Step: 0
Training loss: 3.0462371941110633
Validation loss: 2.667638841136266

Epoch: 5| Step: 1
Training loss: 2.9437052340657206
Validation loss: 2.665733909394522

Epoch: 5| Step: 2
Training loss: 2.3821570323490473
Validation loss: 2.667054045127563

Epoch: 5| Step: 3
Training loss: 2.7821418103919693
Validation loss: 2.6745999663997044

Epoch: 5| Step: 4
Training loss: 2.871011206030692
Validation loss: 2.665178812718736

Epoch: 5| Step: 5
Training loss: 3.1154875362454875
Validation loss: 2.6641503037109397

Epoch: 5| Step: 6
Training loss: 2.9997089562700348
Validation loss: 2.657007939528899

Epoch: 5| Step: 7
Training loss: 2.539519471347921
Validation loss: 2.658246600794986

Epoch: 5| Step: 8
Training loss: 2.8853771514573867
Validation loss: 2.6576636199247927

Epoch: 5| Step: 9
Training loss: 2.7483249244383945
Validation loss: 2.6598086809249724

Epoch: 5| Step: 10
Training loss: 2.5622994879451686
Validation loss: 2.6595535155647867

Epoch: 5| Step: 11
Training loss: 2.1033236133493927
Validation loss: 2.6609729889171714

Epoch: 64| Step: 0
Training loss: 2.6397775949371987
Validation loss: 2.662205571922545

Epoch: 5| Step: 1
Training loss: 2.591495683269376
Validation loss: 2.6637550989558973

Epoch: 5| Step: 2
Training loss: 3.3184953092559453
Validation loss: 2.6645605902537577

Epoch: 5| Step: 3
Training loss: 2.7870008184173773
Validation loss: 2.6646953774448323

Epoch: 5| Step: 4
Training loss: 2.7181039678409427
Validation loss: 2.6613218953096904

Epoch: 5| Step: 5
Training loss: 3.0065571332660985
Validation loss: 2.661461680211739

Epoch: 5| Step: 6
Training loss: 2.5882082647044413
Validation loss: 2.658717090586548

Epoch: 5| Step: 7
Training loss: 3.0567782142555684
Validation loss: 2.6552772012197297

Epoch: 5| Step: 8
Training loss: 2.4863135493975754
Validation loss: 2.6542718215744325

Epoch: 5| Step: 9
Training loss: 2.4987925474619668
Validation loss: 2.6502016244215687

Epoch: 5| Step: 10
Training loss: 2.722474364413093
Validation loss: 2.6491771329121225

Epoch: 5| Step: 11
Training loss: 3.698005324182964
Validation loss: 2.645681363094233

Epoch: 65| Step: 0
Training loss: 2.544431204347252
Validation loss: 2.6440567950835017

Epoch: 5| Step: 1
Training loss: 3.0009633742693453
Validation loss: 2.6422926472970327

Epoch: 5| Step: 2
Training loss: 2.8332065853117228
Validation loss: 2.6421117716471314

Epoch: 5| Step: 3
Training loss: 2.361806462937127
Validation loss: 2.638325191964388

Epoch: 5| Step: 4
Training loss: 2.7723635891239615
Validation loss: 2.6374791421713355

Epoch: 5| Step: 5
Training loss: 3.1182223253932766
Validation loss: 2.6380779615406715

Epoch: 5| Step: 6
Training loss: 2.659211067857903
Validation loss: 2.6346702435881193

Epoch: 5| Step: 7
Training loss: 3.0987963893260235
Validation loss: 2.6420679006309804

Epoch: 5| Step: 8
Training loss: 2.5776894866230537
Validation loss: 2.6453598279600388

Epoch: 5| Step: 9
Training loss: 2.8936344461459473
Validation loss: 2.6345843230830894

Epoch: 5| Step: 10
Training loss: 2.6583585560557723
Validation loss: 2.634945677837326

Epoch: 5| Step: 11
Training loss: 2.6542782814435673
Validation loss: 2.6380631586854992

Epoch: 66| Step: 0
Training loss: 2.838080319118209
Validation loss: 2.635686824104535

Epoch: 5| Step: 1
Training loss: 2.8471551985463273
Validation loss: 2.634348563668375

Epoch: 5| Step: 2
Training loss: 2.986091160276335
Validation loss: 2.6416404923386807

Epoch: 5| Step: 3
Training loss: 2.660221944885619
Validation loss: 2.636333654091443

Epoch: 5| Step: 4
Training loss: 2.1346188675395337
Validation loss: 2.6342674332963485

Epoch: 5| Step: 5
Training loss: 3.1089083067340817
Validation loss: 2.6286133654510166

Epoch: 5| Step: 6
Training loss: 2.6157752026963745
Validation loss: 2.6238924369296233

Epoch: 5| Step: 7
Training loss: 2.6734423585509806
Validation loss: 2.6210827057364616

Epoch: 5| Step: 8
Training loss: 3.2201349926723126
Validation loss: 2.622106031651688

Epoch: 5| Step: 9
Training loss: 2.5137978309546116
Validation loss: 2.6218591549394183

Epoch: 5| Step: 10
Training loss: 2.7957432337729107
Validation loss: 2.6221384883757426

Epoch: 5| Step: 11
Training loss: 1.862809479366542
Validation loss: 2.62116431621193

Epoch: 67| Step: 0
Training loss: 2.7565548544382974
Validation loss: 2.6206851608548436

Epoch: 5| Step: 1
Training loss: 2.7716949576445855
Validation loss: 2.620411082327674

Epoch: 5| Step: 2
Training loss: 2.792172533196894
Validation loss: 2.6171469158612917

Epoch: 5| Step: 3
Training loss: 2.727893930548929
Validation loss: 2.615417417084827

Epoch: 5| Step: 4
Training loss: 2.501777207967013
Validation loss: 2.6141194556446874

Epoch: 5| Step: 5
Training loss: 3.16774778148136
Validation loss: 2.615338012677837

Epoch: 5| Step: 6
Training loss: 2.870955732492601
Validation loss: 2.6106799017049873

Epoch: 5| Step: 7
Training loss: 2.360638210834344
Validation loss: 2.6122618332434597

Epoch: 5| Step: 8
Training loss: 2.8516400888416937
Validation loss: 2.6138624334758847

Epoch: 5| Step: 9
Training loss: 3.1126035864571286
Validation loss: 2.611937964061488

Epoch: 5| Step: 10
Training loss: 2.2126544445895995
Validation loss: 2.6094179663861143

Epoch: 5| Step: 11
Training loss: 2.641230677377382
Validation loss: 2.6053311160527004

Epoch: 68| Step: 0
Training loss: 2.043158031907265
Validation loss: 2.6028263393923763

Epoch: 5| Step: 1
Training loss: 2.9648414983728273
Validation loss: 2.6038289016389333

Epoch: 5| Step: 2
Training loss: 2.881431517603222
Validation loss: 2.605827139131483

Epoch: 5| Step: 3
Training loss: 3.0185403123141206
Validation loss: 2.620774406464047

Epoch: 5| Step: 4
Training loss: 2.9135803969292002
Validation loss: 2.611594115020216

Epoch: 5| Step: 5
Training loss: 2.7643083789722875
Validation loss: 2.603381558644016

Epoch: 5| Step: 6
Training loss: 2.6286054101814718
Validation loss: 2.6015754332808037

Epoch: 5| Step: 7
Training loss: 2.5504599773450316
Validation loss: 2.6005770484618647

Epoch: 5| Step: 8
Training loss: 2.3755017804568905
Validation loss: 2.60058918827516

Epoch: 5| Step: 9
Training loss: 2.627146433698403
Validation loss: 2.6012321926902424

Epoch: 5| Step: 10
Training loss: 3.309388912989374
Validation loss: 2.603152727465591

Epoch: 5| Step: 11
Training loss: 2.1972509765136716
Validation loss: 2.606873380998444

Epoch: 69| Step: 0
Training loss: 2.932260751420113
Validation loss: 2.6056246122288416

Epoch: 5| Step: 1
Training loss: 2.955222379059211
Validation loss: 2.600503050910594

Epoch: 5| Step: 2
Training loss: 3.2269895700452245
Validation loss: 2.6002453552227593

Epoch: 5| Step: 3
Training loss: 2.321157590539606
Validation loss: 2.5948647895493395

Epoch: 5| Step: 4
Training loss: 2.7259258412316596
Validation loss: 2.5928941333406073

Epoch: 5| Step: 5
Training loss: 2.945136512739998
Validation loss: 2.5913153639243065

Epoch: 5| Step: 6
Training loss: 2.7676895108418633
Validation loss: 2.590918124878773

Epoch: 5| Step: 7
Training loss: 2.9478999340719265
Validation loss: 2.5894496842317025

Epoch: 5| Step: 8
Training loss: 2.8216879071876195
Validation loss: 2.5888911202618483

Epoch: 5| Step: 9
Training loss: 2.021839821935448
Validation loss: 2.587994670575741

Epoch: 5| Step: 10
Training loss: 2.2428100997531395
Validation loss: 2.5828870008323643

Epoch: 5| Step: 11
Training loss: 2.0597282048889696
Validation loss: 2.5832894242051854

Epoch: 70| Step: 0
Training loss: 2.3596579274691423
Validation loss: 2.5834460092911

Epoch: 5| Step: 1
Training loss: 2.6020775820625546
Validation loss: 2.586215358684661

Epoch: 5| Step: 2
Training loss: 2.7505140691056544
Validation loss: 2.5824834530544307

Epoch: 5| Step: 3
Training loss: 2.154135510374894
Validation loss: 2.584565020290374

Epoch: 5| Step: 4
Training loss: 2.9334971974582005
Validation loss: 2.5812279802665516

Epoch: 5| Step: 5
Training loss: 2.697287369515447
Validation loss: 2.5819480794110725

Epoch: 5| Step: 6
Training loss: 3.0108494079087538
Validation loss: 2.583246515466192

Epoch: 5| Step: 7
Training loss: 2.8952174640998405
Validation loss: 2.5789564121456023

Epoch: 5| Step: 8
Training loss: 2.445166635276127
Validation loss: 2.5781930683282352

Epoch: 5| Step: 9
Training loss: 2.8848244693981435
Validation loss: 2.5781054987314356

Epoch: 5| Step: 10
Training loss: 2.948966837854675
Validation loss: 2.5770051874685374

Epoch: 5| Step: 11
Training loss: 2.8241777219206083
Validation loss: 2.5730442769661153

Epoch: 71| Step: 0
Training loss: 2.884629749360142
Validation loss: 2.5755266254438345

Epoch: 5| Step: 1
Training loss: 2.9006702635080908
Validation loss: 2.5732754883128486

Epoch: 5| Step: 2
Training loss: 3.1524590113105617
Validation loss: 2.5710244936691904

Epoch: 5| Step: 3
Training loss: 2.7089775101864175
Validation loss: 2.571436113691496

Epoch: 5| Step: 4
Training loss: 2.5974518430209144
Validation loss: 2.5727516782940056

Epoch: 5| Step: 5
Training loss: 2.051941635997248
Validation loss: 2.574982648933

Epoch: 5| Step: 6
Training loss: 2.795098363820822
Validation loss: 2.572477941650189

Epoch: 5| Step: 7
Training loss: 2.9069395170267742
Validation loss: 2.5746425343506427

Epoch: 5| Step: 8
Training loss: 2.6013594081294635
Validation loss: 2.574634277272708

Epoch: 5| Step: 9
Training loss: 2.5045636484957723
Validation loss: 2.572217828359163

Epoch: 5| Step: 10
Training loss: 2.634510070306598
Validation loss: 2.5718373777558665

Epoch: 5| Step: 11
Training loss: 2.4789098932556253
Validation loss: 2.5705009592335584

Epoch: 72| Step: 0
Training loss: 2.63631841940654
Validation loss: 2.5686563878509228

Epoch: 5| Step: 1
Training loss: 2.7509370421149546
Validation loss: 2.567463224111104

Epoch: 5| Step: 2
Training loss: 2.5585719449810362
Validation loss: 2.566928460086374

Epoch: 5| Step: 3
Training loss: 3.173189238581219
Validation loss: 2.5633353368216407

Epoch: 5| Step: 4
Training loss: 2.2512816911211044
Validation loss: 2.5612803363322207

Epoch: 5| Step: 5
Training loss: 3.0869023227196886
Validation loss: 2.56596764039448

Epoch: 5| Step: 6
Training loss: 2.667046629141564
Validation loss: 2.56007501564286

Epoch: 5| Step: 7
Training loss: 2.6406605735052984
Validation loss: 2.5622629040455704

Epoch: 5| Step: 8
Training loss: 2.553830717643811
Validation loss: 2.558615283050392

Epoch: 5| Step: 9
Training loss: 2.385708409311124
Validation loss: 2.559163798342304

Epoch: 5| Step: 10
Training loss: 2.895949949116539
Validation loss: 2.5567959319858056

Epoch: 5| Step: 11
Training loss: 2.2109134524490033
Validation loss: 2.5604613537428507

Epoch: 73| Step: 0
Training loss: 2.876810747548311
Validation loss: 2.5568658483281324

Epoch: 5| Step: 1
Training loss: 2.330030442395076
Validation loss: 2.5599230664273813

Epoch: 5| Step: 2
Training loss: 2.47381497151781
Validation loss: 2.556442225844884

Epoch: 5| Step: 3
Training loss: 2.4462777569599035
Validation loss: 2.563232824939149

Epoch: 5| Step: 4
Training loss: 2.534368877662197
Validation loss: 2.5689592287068588

Epoch: 5| Step: 5
Training loss: 2.152957890950564
Validation loss: 2.557595366386943

Epoch: 5| Step: 6
Training loss: 2.7968467838846007
Validation loss: 2.5625811153072

Epoch: 5| Step: 7
Training loss: 2.8473794433687694
Validation loss: 2.5595946550333624

Epoch: 5| Step: 8
Training loss: 3.1729203930284173
Validation loss: 2.561845416689036

Epoch: 5| Step: 9
Training loss: 2.5538942931307553
Validation loss: 2.5510065817506913

Epoch: 5| Step: 10
Training loss: 2.860905805544503
Validation loss: 2.5549747449431695

Epoch: 5| Step: 11
Training loss: 3.8819114821658536
Validation loss: 2.5496881936367655

Epoch: 74| Step: 0
Training loss: 2.4938697040481173
Validation loss: 2.554214795443775

Epoch: 5| Step: 1
Training loss: 2.8771728928917044
Validation loss: 2.5505401512963557

Epoch: 5| Step: 2
Training loss: 2.8379161647164604
Validation loss: 2.5524477108186705

Epoch: 5| Step: 3
Training loss: 2.5867015251616174
Validation loss: 2.552877887640704

Epoch: 5| Step: 4
Training loss: 2.3878169303766072
Validation loss: 2.5555925545110356

Epoch: 5| Step: 5
Training loss: 2.814235067292185
Validation loss: 2.5560788517794957

Epoch: 5| Step: 6
Training loss: 2.8352207928078066
Validation loss: 2.5527132281998965

Epoch: 5| Step: 7
Training loss: 2.4264067551347455
Validation loss: 2.55376278379094

Epoch: 5| Step: 8
Training loss: 2.673632216817497
Validation loss: 2.550492932945571

Epoch: 5| Step: 9
Training loss: 3.0545866576425444
Validation loss: 2.549058730800084

Epoch: 5| Step: 10
Training loss: 2.4712498237173723
Validation loss: 2.5479131310771908

Epoch: 5| Step: 11
Training loss: 2.504773446534264
Validation loss: 2.5474395438305977

Epoch: 75| Step: 0
Training loss: 2.5331493833748597
Validation loss: 2.546762908621982

Epoch: 5| Step: 1
Training loss: 2.4657655857169503
Validation loss: 2.5455041796419478

Epoch: 5| Step: 2
Training loss: 2.4400913451247046
Validation loss: 2.546136546197149

Epoch: 5| Step: 3
Training loss: 2.8745665845499615
Validation loss: 2.5430649769942595

Epoch: 5| Step: 4
Training loss: 2.296545822533558
Validation loss: 2.5463106275084533

Epoch: 5| Step: 5
Training loss: 2.8297396102648484
Validation loss: 2.5443387733428637

Epoch: 5| Step: 6
Training loss: 2.8281400058411466
Validation loss: 2.5485519084123305

Epoch: 5| Step: 7
Training loss: 2.923534554400116
Validation loss: 2.543118610644367

Epoch: 5| Step: 8
Training loss: 2.5676721618044174
Validation loss: 2.542008804265024

Epoch: 5| Step: 9
Training loss: 2.95219657068766
Validation loss: 2.542575264688488

Epoch: 5| Step: 10
Training loss: 2.7823753223436998
Validation loss: 2.53997647781444

Epoch: 5| Step: 11
Training loss: 1.8300309638233574
Validation loss: 2.536969751476176

Epoch: 76| Step: 0
Training loss: 2.8478111361020306
Validation loss: 2.5389763450677516

Epoch: 5| Step: 1
Training loss: 2.707848627781657
Validation loss: 2.5418352920586043

Epoch: 5| Step: 2
Training loss: 2.6795650710006207
Validation loss: 2.540064002861435

Epoch: 5| Step: 3
Training loss: 2.3497859289184544
Validation loss: 2.5377036307362077

Epoch: 5| Step: 4
Training loss: 2.913463541201126
Validation loss: 2.54014190422613

Epoch: 5| Step: 5
Training loss: 2.6176791967573547
Validation loss: 2.5393412040923304

Epoch: 5| Step: 6
Training loss: 2.8618740146932677
Validation loss: 2.5415922073234687

Epoch: 5| Step: 7
Training loss: 2.7773456385695936
Validation loss: 2.5409404167834446

Epoch: 5| Step: 8
Training loss: 2.645950995604903
Validation loss: 2.543158192568361

Epoch: 5| Step: 9
Training loss: 2.2318816244667468
Validation loss: 2.5400409554260936

Epoch: 5| Step: 10
Training loss: 2.688610734511818
Validation loss: 2.544925657490564

Epoch: 5| Step: 11
Training loss: 2.380565747249493
Validation loss: 2.5401555960661155

Epoch: 77| Step: 0
Training loss: 2.7373592985042476
Validation loss: 2.542664778785808

Epoch: 5| Step: 1
Training loss: 2.6168028591535735
Validation loss: 2.5380141690988225

Epoch: 5| Step: 2
Training loss: 2.694232226619411
Validation loss: 2.5376372812277497

Epoch: 5| Step: 3
Training loss: 2.462633692796194
Validation loss: 2.5435568583097257

Epoch: 5| Step: 4
Training loss: 2.8197781804277455
Validation loss: 2.54866999772656

Epoch: 5| Step: 5
Training loss: 2.8152068781340236
Validation loss: 2.5436530376702904

Epoch: 5| Step: 6
Training loss: 2.518472611745472
Validation loss: 2.5370973269103345

Epoch: 5| Step: 7
Training loss: 2.5721508744929378
Validation loss: 2.5342101539343567

Epoch: 5| Step: 8
Training loss: 2.59045448984512
Validation loss: 2.53736684665942

Epoch: 5| Step: 9
Training loss: 2.354529451307151
Validation loss: 2.538462754845235

Epoch: 5| Step: 10
Training loss: 2.9814269199297567
Validation loss: 2.542009746086882

Epoch: 5| Step: 11
Training loss: 3.605140877773876
Validation loss: 2.5450555859461645

Epoch: 78| Step: 0
Training loss: 2.5675287912568976
Validation loss: 2.5475903931947155

Epoch: 5| Step: 1
Training loss: 3.0584587369426868
Validation loss: 2.545442868916557

Epoch: 5| Step: 2
Training loss: 2.718746930701617
Validation loss: 2.5483884585659435

Epoch: 5| Step: 3
Training loss: 2.7049658356093826
Validation loss: 2.5494108895552134

Epoch: 5| Step: 4
Training loss: 3.2382179318485513
Validation loss: 2.548805012604242

Epoch: 5| Step: 5
Training loss: 2.5968423816087554
Validation loss: 2.55088397408754

Epoch: 5| Step: 6
Training loss: 2.50542985620098
Validation loss: 2.551031835455829

Epoch: 5| Step: 7
Training loss: 2.713119112723254
Validation loss: 2.547867770647279

Epoch: 5| Step: 8
Training loss: 2.8342115125853415
Validation loss: 2.54674458316082

Epoch: 5| Step: 9
Training loss: 2.059493908611272
Validation loss: 2.544079414489194

Epoch: 5| Step: 10
Training loss: 2.0919693164289304
Validation loss: 2.5406028496346367

Epoch: 5| Step: 11
Training loss: 3.291075898928763
Validation loss: 2.5380011232830535

Epoch: 79| Step: 0
Training loss: 2.580857372210987
Validation loss: 2.5383870522414327

Epoch: 5| Step: 1
Training loss: 2.9012296240213096
Validation loss: 2.533497222949937

Epoch: 5| Step: 2
Training loss: 3.03378048699538
Validation loss: 2.5313866268380267

Epoch: 5| Step: 3
Training loss: 2.7215672070406356
Validation loss: 2.532375419096841

Epoch: 5| Step: 4
Training loss: 2.228075229682781
Validation loss: 2.529549820475378

Epoch: 5| Step: 5
Training loss: 2.7648767870858393
Validation loss: 2.5254165124906254

Epoch: 5| Step: 6
Training loss: 2.5896024519648595
Validation loss: 2.534490873209859

Epoch: 5| Step: 7
Training loss: 2.9682028818425334
Validation loss: 2.5358735075480356

Epoch: 5| Step: 8
Training loss: 2.7974895462781704
Validation loss: 2.5321959191981542

Epoch: 5| Step: 9
Training loss: 2.368255173021834
Validation loss: 2.5311663303753886

Epoch: 5| Step: 10
Training loss: 2.293256231479377
Validation loss: 2.5297148252428627

Epoch: 5| Step: 11
Training loss: 2.2158986427043024
Validation loss: 2.5234363977136556

Epoch: 80| Step: 0
Training loss: 2.5297374209119425
Validation loss: 2.525667785556514

Epoch: 5| Step: 1
Training loss: 2.916756455992131
Validation loss: 2.5246631452699386

Epoch: 5| Step: 2
Training loss: 2.444555000733534
Validation loss: 2.5280131574237537

Epoch: 5| Step: 3
Training loss: 2.500512928795605
Validation loss: 2.532493411498366

Epoch: 5| Step: 4
Training loss: 2.5679941592164925
Validation loss: 2.525380885161234

Epoch: 5| Step: 5
Training loss: 2.5521860737783184
Validation loss: 2.524368578896443

Epoch: 5| Step: 6
Training loss: 2.7200204796581073
Validation loss: 2.5236984999781997

Epoch: 5| Step: 7
Training loss: 2.740504865286047
Validation loss: 2.5179554942767752

Epoch: 5| Step: 8
Training loss: 2.8331459955850855
Validation loss: 2.5208435583826767

Epoch: 5| Step: 9
Training loss: 2.685085365174434
Validation loss: 2.520937741431975

Epoch: 5| Step: 10
Training loss: 2.7114226596951014
Validation loss: 2.518002581075669

Epoch: 5| Step: 11
Training loss: 2.1746372797391746
Validation loss: 2.518711258280292

Epoch: 81| Step: 0
Training loss: 2.898539991186144
Validation loss: 2.52309501811878

Epoch: 5| Step: 1
Training loss: 2.5538613386339115
Validation loss: 2.526390273169703

Epoch: 5| Step: 2
Training loss: 2.453724198752272
Validation loss: 2.526439994526728

Epoch: 5| Step: 3
Training loss: 2.8162342288832427
Validation loss: 2.523668611255505

Epoch: 5| Step: 4
Training loss: 2.589797628000652
Validation loss: 2.5299323168692633

Epoch: 5| Step: 5
Training loss: 2.611052470754925
Validation loss: 2.527790224710731

Epoch: 5| Step: 6
Training loss: 3.0389062208773585
Validation loss: 2.524273181872685

Epoch: 5| Step: 7
Training loss: 3.259808338358565
Validation loss: 2.521088608250962

Epoch: 5| Step: 8
Training loss: 2.2596997883667913
Validation loss: 2.5233971205749133

Epoch: 5| Step: 9
Training loss: 2.2974095144291855
Validation loss: 2.520334463699791

Epoch: 5| Step: 10
Training loss: 2.3208662714467123
Validation loss: 2.521357463437101

Epoch: 5| Step: 11
Training loss: 1.9232761888703185
Validation loss: 2.5185259841677654

Epoch: 82| Step: 0
Training loss: 2.1375796520718042
Validation loss: 2.5173741098411795

Epoch: 5| Step: 1
Training loss: 2.438567099152761
Validation loss: 2.517473524952602

Epoch: 5| Step: 2
Training loss: 3.201531883975821
Validation loss: 2.515242276981803

Epoch: 5| Step: 3
Training loss: 2.7990219144954773
Validation loss: 2.512912496231136

Epoch: 5| Step: 4
Training loss: 2.374784660615706
Validation loss: 2.512082529890934

Epoch: 5| Step: 5
Training loss: 2.572005065373109
Validation loss: 2.515476056540965

Epoch: 5| Step: 6
Training loss: 2.5466512570073068
Validation loss: 2.5101334595439617

Epoch: 5| Step: 7
Training loss: 2.9585606841361742
Validation loss: 2.512183704521247

Epoch: 5| Step: 8
Training loss: 2.498938239651401
Validation loss: 2.5124663431371035

Epoch: 5| Step: 9
Training loss: 2.555517779177038
Validation loss: 2.511623046538835

Epoch: 5| Step: 10
Training loss: 2.45573937153373
Validation loss: 2.515062071721222

Epoch: 5| Step: 11
Training loss: 3.746305044060654
Validation loss: 2.5138401349634156

Epoch: 83| Step: 0
Training loss: 2.3152927340481027
Validation loss: 2.5091539797868103

Epoch: 5| Step: 1
Training loss: 2.6789022913447713
Validation loss: 2.5079746570232007

Epoch: 5| Step: 2
Training loss: 2.813504866060774
Validation loss: 2.512236443419399

Epoch: 5| Step: 3
Training loss: 3.282191114339225
Validation loss: 2.503667184225364

Epoch: 5| Step: 4
Training loss: 2.3967366602637727
Validation loss: 2.5121317672700347

Epoch: 5| Step: 5
Training loss: 2.6602950767108746
Validation loss: 2.512178464973641

Epoch: 5| Step: 6
Training loss: 2.3260437540152297
Validation loss: 2.514836616265034

Epoch: 5| Step: 7
Training loss: 2.943691627263858
Validation loss: 2.5201922591983057

Epoch: 5| Step: 8
Training loss: 2.4490547186087923
Validation loss: 2.522045416827139

Epoch: 5| Step: 9
Training loss: 2.6724286314496126
Validation loss: 2.52021212581923

Epoch: 5| Step: 10
Training loss: 2.6501227224471626
Validation loss: 2.5156798781259537

Epoch: 5| Step: 11
Training loss: 1.3495475434687432
Validation loss: 2.5141255192418277

Epoch: 84| Step: 0
Training loss: 2.863346531060045
Validation loss: 2.5136704680768127

Epoch: 5| Step: 1
Training loss: 2.4760615567211004
Validation loss: 2.5166685336992356

Epoch: 5| Step: 2
Training loss: 2.58801020507923
Validation loss: 2.509553540641077

Epoch: 5| Step: 3
Training loss: 2.489405307762462
Validation loss: 2.5077381499331866

Epoch: 5| Step: 4
Training loss: 2.617475897997749
Validation loss: 2.5043304131701265

Epoch: 5| Step: 5
Training loss: 2.67875686366937
Validation loss: 2.5039629242940618

Epoch: 5| Step: 6
Training loss: 2.463934729244179
Validation loss: 2.502686801198451

Epoch: 5| Step: 7
Training loss: 2.8491941885573344
Validation loss: 2.500204332266527

Epoch: 5| Step: 8
Training loss: 2.8992514071607913
Validation loss: 2.499011658967099

Epoch: 5| Step: 9
Training loss: 2.308852128030049
Validation loss: 2.5039823206129146

Epoch: 5| Step: 10
Training loss: 2.7291312373145122
Validation loss: 2.5001350247159393

Epoch: 5| Step: 11
Training loss: 2.33152287499522
Validation loss: 2.5005151416597515

Epoch: 85| Step: 0
Training loss: 2.385108317028801
Validation loss: 2.500938108387656

Epoch: 5| Step: 1
Training loss: 2.7672477314972737
Validation loss: 2.498817875646153

Epoch: 5| Step: 2
Training loss: 2.5077597354079693
Validation loss: 2.5106283444214634

Epoch: 5| Step: 3
Training loss: 2.5293019651855153
Validation loss: 2.5065909844202707

Epoch: 5| Step: 4
Training loss: 2.3840784930933943
Validation loss: 2.513726297820379

Epoch: 5| Step: 5
Training loss: 2.354768209206969
Validation loss: 2.5229300351868895

Epoch: 5| Step: 6
Training loss: 3.3550445324007385
Validation loss: 2.5366773621746797

Epoch: 5| Step: 7
Training loss: 2.813872023876379
Validation loss: 2.5351882956056184

Epoch: 5| Step: 8
Training loss: 2.9773417576683343
Validation loss: 2.514261895256962

Epoch: 5| Step: 9
Training loss: 2.5670752270341515
Validation loss: 2.5040188871649915

Epoch: 5| Step: 10
Training loss: 2.3943291185205533
Validation loss: 2.498020819199287

Epoch: 5| Step: 11
Training loss: 2.078739161552026
Validation loss: 2.497443966738146

Epoch: 86| Step: 0
Training loss: 2.2445815859128606
Validation loss: 2.49977037646836

Epoch: 5| Step: 1
Training loss: 2.940578227628909
Validation loss: 2.4983810308682037

Epoch: 5| Step: 2
Training loss: 2.951099973013489
Validation loss: 2.5015285984452826

Epoch: 5| Step: 3
Training loss: 2.719590857251724
Validation loss: 2.5043744994847588

Epoch: 5| Step: 4
Training loss: 3.0707558658788865
Validation loss: 2.5032239788804307

Epoch: 5| Step: 5
Training loss: 3.0542307168264884
Validation loss: 2.502296604836262

Epoch: 5| Step: 6
Training loss: 2.3284027138787753
Validation loss: 2.501635485380023

Epoch: 5| Step: 7
Training loss: 2.4106452730180394
Validation loss: 2.5025121583938583

Epoch: 5| Step: 8
Training loss: 2.463154112404971
Validation loss: 2.505170057854273

Epoch: 5| Step: 9
Training loss: 2.2951107385716987
Validation loss: 2.5048582872723184

Epoch: 5| Step: 10
Training loss: 2.300214558420694
Validation loss: 2.500996847888445

Epoch: 5| Step: 11
Training loss: 2.1112146338238613
Validation loss: 2.5002841191969005

Epoch: 87| Step: 0
Training loss: 2.717525952030132
Validation loss: 2.5021532521151792

Epoch: 5| Step: 1
Training loss: 2.513825145871063
Validation loss: 2.5021606009879527

Epoch: 5| Step: 2
Training loss: 3.0005751694218685
Validation loss: 2.503039971446116

Epoch: 5| Step: 3
Training loss: 2.729807674075037
Validation loss: 2.4984410909181975

Epoch: 5| Step: 4
Training loss: 2.602620502507429
Validation loss: 2.4992255998306714

Epoch: 5| Step: 5
Training loss: 2.3756150904777207
Validation loss: 2.499360384181739

Epoch: 5| Step: 6
Training loss: 2.318471467185402
Validation loss: 2.5017396993182643

Epoch: 5| Step: 7
Training loss: 2.607777089129386
Validation loss: 2.498954983690844

Epoch: 5| Step: 8
Training loss: 2.776205395611176
Validation loss: 2.495948464906965

Epoch: 5| Step: 9
Training loss: 2.3773068718834445
Validation loss: 2.497917332992486

Epoch: 5| Step: 10
Training loss: 2.67601834103011
Validation loss: 2.498191990339476

Epoch: 5| Step: 11
Training loss: 2.9627063470112263
Validation loss: 2.498775504164806

Epoch: 88| Step: 0
Training loss: 2.4308221749498724
Validation loss: 2.4952887051251404

Epoch: 5| Step: 1
Training loss: 2.5809355241717373
Validation loss: 2.4967149967304096

Epoch: 5| Step: 2
Training loss: 2.4175853517726047
Validation loss: 2.50106418132909

Epoch: 5| Step: 3
Training loss: 2.9406447115003376
Validation loss: 2.49609377785903

Epoch: 5| Step: 4
Training loss: 2.795692748066095
Validation loss: 2.4942306267320298

Epoch: 5| Step: 5
Training loss: 2.5088304966897637
Validation loss: 2.494168043670461

Epoch: 5| Step: 6
Training loss: 2.40773380653466
Validation loss: 2.4930330235328766

Epoch: 5| Step: 7
Training loss: 2.8561483219003763
Validation loss: 2.495602284235805

Epoch: 5| Step: 8
Training loss: 2.5632516642417853
Validation loss: 2.4934719964877132

Epoch: 5| Step: 9
Training loss: 2.5991221486501006
Validation loss: 2.4939799903037865

Epoch: 5| Step: 10
Training loss: 2.27648742174963
Validation loss: 2.489545232622269

Epoch: 5| Step: 11
Training loss: 3.7086716972599016
Validation loss: 2.493490442553074

Epoch: 89| Step: 0
Training loss: 3.027594653161169
Validation loss: 2.494084281155523

Epoch: 5| Step: 1
Training loss: 2.7640242604682896
Validation loss: 2.495398343464253

Epoch: 5| Step: 2
Training loss: 2.8480909144002853
Validation loss: 2.494629802244499

Epoch: 5| Step: 3
Training loss: 2.8855331525919143
Validation loss: 2.4916590506034306

Epoch: 5| Step: 4
Training loss: 2.4301682760112406
Validation loss: 2.496351046725724

Epoch: 5| Step: 5
Training loss: 2.243637626192888
Validation loss: 2.495844001195289

Epoch: 5| Step: 6
Training loss: 2.0697051686945764
Validation loss: 2.492380670855912

Epoch: 5| Step: 7
Training loss: 2.5724099364238127
Validation loss: 2.4896710445536487

Epoch: 5| Step: 8
Training loss: 2.3538133361690132
Validation loss: 2.493262984667572

Epoch: 5| Step: 9
Training loss: 2.6159008906077506
Validation loss: 2.489733309730736

Epoch: 5| Step: 10
Training loss: 2.965167484023961
Validation loss: 2.4851039640731933

Epoch: 5| Step: 11
Training loss: 1.2115931059026934
Validation loss: 2.488072936053047

Epoch: 90| Step: 0
Training loss: 2.5900089907398076
Validation loss: 2.4919380214590765

Epoch: 5| Step: 1
Training loss: 3.2696512763120418
Validation loss: 2.4902362579139123

Epoch: 5| Step: 2
Training loss: 2.3009630011643063
Validation loss: 2.490497566227316

Epoch: 5| Step: 3
Training loss: 2.1801430284318886
Validation loss: 2.4939429698463758

Epoch: 5| Step: 4
Training loss: 2.536570009335828
Validation loss: 2.497996994128988

Epoch: 5| Step: 5
Training loss: 2.2865973729384357
Validation loss: 2.5045691697219366

Epoch: 5| Step: 6
Training loss: 2.6972076387684467
Validation loss: 2.5031579655616847

Epoch: 5| Step: 7
Training loss: 3.3105507639634237
Validation loss: 2.4991471107313927

Epoch: 5| Step: 8
Training loss: 2.2167706324162553
Validation loss: 2.490437111175221

Epoch: 5| Step: 9
Training loss: 2.2816719814523787
Validation loss: 2.494065823549791

Epoch: 5| Step: 10
Training loss: 2.6478716490545655
Validation loss: 2.4896107130792937

Epoch: 5| Step: 11
Training loss: 3.136197437562024
Validation loss: 2.488255471216288

Epoch: 91| Step: 0
Training loss: 2.6914705620377717
Validation loss: 2.489471430371762

Epoch: 5| Step: 1
Training loss: 2.471654607735265
Validation loss: 2.494878278966282

Epoch: 5| Step: 2
Training loss: 3.15128411655502
Validation loss: 2.4956645327904083

Epoch: 5| Step: 3
Training loss: 1.8835373745443815
Validation loss: 2.493651272118869

Epoch: 5| Step: 4
Training loss: 2.3596273123120595
Validation loss: 2.4941203754571895

Epoch: 5| Step: 5
Training loss: 2.660796907555715
Validation loss: 2.4916956863712185

Epoch: 5| Step: 6
Training loss: 2.8877073667633932
Validation loss: 2.4922933884849385

Epoch: 5| Step: 7
Training loss: 2.739720204539839
Validation loss: 2.4940102388041265

Epoch: 5| Step: 8
Training loss: 2.51243512273883
Validation loss: 2.486376398081904

Epoch: 5| Step: 9
Training loss: 2.3739669962567733
Validation loss: 2.4940501500116965

Epoch: 5| Step: 10
Training loss: 2.915477582960151
Validation loss: 2.4896871686108213

Epoch: 5| Step: 11
Training loss: 2.220672634052988
Validation loss: 2.4883416735919637

Epoch: 92| Step: 0
Training loss: 2.834581623726398
Validation loss: 2.491497175380303

Epoch: 5| Step: 1
Training loss: 2.576071181220133
Validation loss: 2.4919690481846155

Epoch: 5| Step: 2
Training loss: 2.2794314935543407
Validation loss: 2.4866836665222687

Epoch: 5| Step: 3
Training loss: 2.5824776637246014
Validation loss: 2.4891619478654996

Epoch: 5| Step: 4
Training loss: 2.5753167781602198
Validation loss: 2.493681620215651

Epoch: 5| Step: 5
Training loss: 2.3163245252631266
Validation loss: 2.488142110466626

Epoch: 5| Step: 6
Training loss: 2.60493823002014
Validation loss: 2.4866907854632085

Epoch: 5| Step: 7
Training loss: 2.245279127920217
Validation loss: 2.478808454605646

Epoch: 5| Step: 8
Training loss: 2.9622963879626765
Validation loss: 2.48521404373042

Epoch: 5| Step: 9
Training loss: 2.799954812502674
Validation loss: 2.4886315866168225

Epoch: 5| Step: 10
Training loss: 2.973712347561142
Validation loss: 2.4892058438782296

Epoch: 5| Step: 11
Training loss: 1.3788505737476129
Validation loss: 2.4894844671327814

Epoch: 93| Step: 0
Training loss: 2.39568058577415
Validation loss: 2.482492589456101

Epoch: 5| Step: 1
Training loss: 2.9007961824517188
Validation loss: 2.485967473605257

Epoch: 5| Step: 2
Training loss: 2.2993080591036903
Validation loss: 2.4796854459437174

Epoch: 5| Step: 3
Training loss: 2.905983533231074
Validation loss: 2.4847698337771362

Epoch: 5| Step: 4
Training loss: 2.9403894701044075
Validation loss: 2.4821490786429696

Epoch: 5| Step: 5
Training loss: 2.2554500059770044
Validation loss: 2.4895818795448643

Epoch: 5| Step: 6
Training loss: 2.451626945898223
Validation loss: 2.484309801409769

Epoch: 5| Step: 7
Training loss: 2.463060414015129
Validation loss: 2.4855098291754114

Epoch: 5| Step: 8
Training loss: 2.404640055505045
Validation loss: 2.4833824326207847

Epoch: 5| Step: 9
Training loss: 3.0513296574653865
Validation loss: 2.4861471425422477

Epoch: 5| Step: 10
Training loss: 2.256637954116041
Validation loss: 2.4823007501544563

Epoch: 5| Step: 11
Training loss: 2.9714404312882223
Validation loss: 2.485560030584888

Epoch: 94| Step: 0
Training loss: 2.9049441777707803
Validation loss: 2.481630000427903

Epoch: 5| Step: 1
Training loss: 2.2174297219271213
Validation loss: 2.485170540902953

Epoch: 5| Step: 2
Training loss: 2.5089870091174578
Validation loss: 2.4797959423971077

Epoch: 5| Step: 3
Training loss: 2.5719484265438273
Validation loss: 2.485102906744397

Epoch: 5| Step: 4
Training loss: 2.265973504984771
Validation loss: 2.482495750770633

Epoch: 5| Step: 5
Training loss: 2.916184376396436
Validation loss: 2.479844262516819

Epoch: 5| Step: 6
Training loss: 2.902373487030112
Validation loss: 2.4800659893982906

Epoch: 5| Step: 7
Training loss: 2.1563108131568165
Validation loss: 2.477914322904953

Epoch: 5| Step: 8
Training loss: 2.9019594412978944
Validation loss: 2.4903139388395035

Epoch: 5| Step: 9
Training loss: 2.6580755804379983
Validation loss: 2.484001039554186

Epoch: 5| Step: 10
Training loss: 2.397613284365255
Validation loss: 2.482819107971937

Epoch: 5| Step: 11
Training loss: 2.912624955668899
Validation loss: 2.488287713617846

Epoch: 95| Step: 0
Training loss: 2.3700619609797244
Validation loss: 2.4782444590397534

Epoch: 5| Step: 1
Training loss: 3.176163804026764
Validation loss: 2.478188367100006

Epoch: 5| Step: 2
Training loss: 2.5772314199232476
Validation loss: 2.4824576706685293

Epoch: 5| Step: 3
Training loss: 2.742349733949603
Validation loss: 2.484314847813755

Epoch: 5| Step: 4
Training loss: 2.550426230618072
Validation loss: 2.483778528069824

Epoch: 5| Step: 5
Training loss: 2.4397253002249784
Validation loss: 2.4859712738677606

Epoch: 5| Step: 6
Training loss: 2.8802718879259412
Validation loss: 2.4789487211346315

Epoch: 5| Step: 7
Training loss: 2.3181243751671086
Validation loss: 2.480417656560011

Epoch: 5| Step: 8
Training loss: 2.5599657878973847
Validation loss: 2.483127596726025

Epoch: 5| Step: 9
Training loss: 2.4439110197985667
Validation loss: 2.4803532210551853

Epoch: 5| Step: 10
Training loss: 2.4086211770593686
Validation loss: 2.4825690161083767

Epoch: 5| Step: 11
Training loss: 2.290275798997499
Validation loss: 2.485094006376604

Epoch: 96| Step: 0
Training loss: 2.1512481614968904
Validation loss: 2.477899737901357

Epoch: 5| Step: 1
Training loss: 2.457080349333048
Validation loss: 2.4864941122301256

Epoch: 5| Step: 2
Training loss: 2.889673519766945
Validation loss: 2.4841889785603652

Epoch: 5| Step: 3
Training loss: 2.4495779257793235
Validation loss: 2.4858063706988145

Epoch: 5| Step: 4
Training loss: 1.958720135196369
Validation loss: 2.4875696303495918

Epoch: 5| Step: 5
Training loss: 2.2952058916672473
Validation loss: 2.4877066994416155

Epoch: 5| Step: 6
Training loss: 3.377856705674808
Validation loss: 2.5032612867078994

Epoch: 5| Step: 7
Training loss: 2.661639143344252
Validation loss: 2.495103025551735

Epoch: 5| Step: 8
Training loss: 2.61087331185008
Validation loss: 2.5018155737375665

Epoch: 5| Step: 9
Training loss: 2.164367764422588
Validation loss: 2.4826770834367076

Epoch: 5| Step: 10
Training loss: 3.2465770008256447
Validation loss: 2.4794183744882528

Epoch: 5| Step: 11
Training loss: 2.601871873027637
Validation loss: 2.4768861184138147

Epoch: 97| Step: 0
Training loss: 2.8456905576785814
Validation loss: 2.4801149251096937

Epoch: 5| Step: 1
Training loss: 2.3322965384792087
Validation loss: 2.479917546101367

Epoch: 5| Step: 2
Training loss: 2.6963336281856636
Validation loss: 2.4847828392340463

Epoch: 5| Step: 3
Training loss: 2.547375214490091
Validation loss: 2.4900124963385526

Epoch: 5| Step: 4
Training loss: 2.3440799735165205
Validation loss: 2.4919544577386468

Epoch: 5| Step: 5
Training loss: 2.7419365662096697
Validation loss: 2.4897742630489126

Epoch: 5| Step: 6
Training loss: 2.6010257751525288
Validation loss: 2.4919998552718816

Epoch: 5| Step: 7
Training loss: 2.6185792780834247
Validation loss: 2.493590658478245

Epoch: 5| Step: 8
Training loss: 2.571573707481046
Validation loss: 2.497289006265823

Epoch: 5| Step: 9
Training loss: 2.5009459613207428
Validation loss: 2.497485024321712

Epoch: 5| Step: 10
Training loss: 2.7784450831495886
Validation loss: 2.4985236099987267

Epoch: 5| Step: 11
Training loss: 2.973598496312666
Validation loss: 2.494452034616097

Epoch: 98| Step: 0
Training loss: 2.952597757735031
Validation loss: 2.4917918681474993

Epoch: 5| Step: 1
Training loss: 2.804084904363437
Validation loss: 2.489588259980715

Epoch: 5| Step: 2
Training loss: 3.07893693933338
Validation loss: 2.4886942051193217

Epoch: 5| Step: 3
Training loss: 2.765076146379314
Validation loss: 2.484622675068009

Epoch: 5| Step: 4
Training loss: 2.023648637632964
Validation loss: 2.487087592246287

Epoch: 5| Step: 5
Training loss: 2.339878088391867
Validation loss: 2.476450764154117

Epoch: 5| Step: 6
Training loss: 2.4956980885675626
Validation loss: 2.4749968641113553

Epoch: 5| Step: 7
Training loss: 2.9880007144666685
Validation loss: 2.471581493141843

Epoch: 5| Step: 8
Training loss: 2.5698332644156063
Validation loss: 2.471922401459208

Epoch: 5| Step: 9
Training loss: 2.599909993594486
Validation loss: 2.467343791016068

Epoch: 5| Step: 10
Training loss: 1.8302141299849806
Validation loss: 2.469563281824911

Epoch: 5| Step: 11
Training loss: 1.7864222471931779
Validation loss: 2.4704195003028953

Epoch: 99| Step: 0
Training loss: 2.4694164680276023
Validation loss: 2.478457619279124

Epoch: 5| Step: 1
Training loss: 2.786113644014853
Validation loss: 2.474260790891006

Epoch: 5| Step: 2
Training loss: 1.943210676628926
Validation loss: 2.473349395230246

Epoch: 5| Step: 3
Training loss: 2.891637346483667
Validation loss: 2.473136208442725

Epoch: 5| Step: 4
Training loss: 2.49410353523225
Validation loss: 2.472362305985945

Epoch: 5| Step: 5
Training loss: 2.475061966862068
Validation loss: 2.4728844664377903

Epoch: 5| Step: 6
Training loss: 3.227958026419288
Validation loss: 2.4728942161982865

Epoch: 5| Step: 7
Training loss: 2.7160503093908424
Validation loss: 2.47607256177715

Epoch: 5| Step: 8
Training loss: 2.5476524243038012
Validation loss: 2.4717084163793235

Epoch: 5| Step: 9
Training loss: 2.5442277689282355
Validation loss: 2.475012301083703

Epoch: 5| Step: 10
Training loss: 2.269132017650227
Validation loss: 2.4758088241651426

Epoch: 5| Step: 11
Training loss: 1.9363953302266834
Validation loss: 2.4779666365780773

Epoch: 100| Step: 0
Training loss: 2.312927722037458
Validation loss: 2.479792813694987

Epoch: 5| Step: 1
Training loss: 2.6142444973628973
Validation loss: 2.4799065260614497

Epoch: 5| Step: 2
Training loss: 3.1107377176401774
Validation loss: 2.4832037478011073

Epoch: 5| Step: 3
Training loss: 2.8729848018659845
Validation loss: 2.4826965220118833

Epoch: 5| Step: 4
Training loss: 2.332192675755879
Validation loss: 2.484682663874573

Epoch: 5| Step: 5
Training loss: 2.590488543442583
Validation loss: 2.485720028447161

Epoch: 5| Step: 6
Training loss: 2.6558211036434862
Validation loss: 2.4854217579339943

Epoch: 5| Step: 7
Training loss: 2.6483696222749886
Validation loss: 2.482917546074047

Epoch: 5| Step: 8
Training loss: 2.3099042397008875
Validation loss: 2.4805994995580076

Epoch: 5| Step: 9
Training loss: 2.6064960793517464
Validation loss: 2.4805115463289527

Epoch: 5| Step: 10
Training loss: 2.5806581017146684
Validation loss: 2.475992106988987

Epoch: 5| Step: 11
Training loss: 1.970107322131912
Validation loss: 2.479719157859149

Epoch: 101| Step: 0
Training loss: 2.436251002429425
Validation loss: 2.4804452289257077

Epoch: 5| Step: 1
Training loss: 2.810842746327172
Validation loss: 2.4737340577845344

Epoch: 5| Step: 2
Training loss: 2.7303628314298565
Validation loss: 2.4738412380950177

Epoch: 5| Step: 3
Training loss: 2.012912551579829
Validation loss: 2.4750556172116855

Epoch: 5| Step: 4
Training loss: 2.358397527658986
Validation loss: 2.4712483283246125

Epoch: 5| Step: 5
Training loss: 2.355422289945255
Validation loss: 2.4700711775252686

Epoch: 5| Step: 6
Training loss: 2.45864354347739
Validation loss: 2.4669271129177406

Epoch: 5| Step: 7
Training loss: 2.818728437996756
Validation loss: 2.47543860604641

Epoch: 5| Step: 8
Training loss: 2.793093719887711
Validation loss: 2.4758315948249963

Epoch: 5| Step: 9
Training loss: 2.7867213235024564
Validation loss: 2.4700400044345803

Epoch: 5| Step: 10
Training loss: 2.744050091644929
Validation loss: 2.4702973445947807

Epoch: 5| Step: 11
Training loss: 1.9492290855852297
Validation loss: 2.4729558151561464

Epoch: 102| Step: 0
Training loss: 2.5881696672967727
Validation loss: 2.47546473099177

Epoch: 5| Step: 1
Training loss: 2.8702296611064275
Validation loss: 2.471758208829312

Epoch: 5| Step: 2
Training loss: 2.192792865153705
Validation loss: 2.4704384924656386

Epoch: 5| Step: 3
Training loss: 2.468723924716428
Validation loss: 2.4737422781848335

Epoch: 5| Step: 4
Training loss: 2.7646253255392117
Validation loss: 2.480636218567746

Epoch: 5| Step: 5
Training loss: 2.1409064337620594
Validation loss: 2.473323006951127

Epoch: 5| Step: 6
Training loss: 2.103802363015451
Validation loss: 2.4600730225339533

Epoch: 5| Step: 7
Training loss: 2.2184003097699043
Validation loss: 2.4688034092079305

Epoch: 5| Step: 8
Training loss: 2.919894439670441
Validation loss: 2.4655022001125793

Epoch: 5| Step: 9
Training loss: 2.7740342049005986
Validation loss: 2.4645079733150173

Epoch: 5| Step: 10
Training loss: 2.9481381893610985
Validation loss: 2.466672292640645

Epoch: 5| Step: 11
Training loss: 3.2087460207050706
Validation loss: 2.4706268097722663

Epoch: 103| Step: 0
Training loss: 2.9609854903144224
Validation loss: 2.469829930738841

Epoch: 5| Step: 1
Training loss: 2.8598912507836016
Validation loss: 2.4811030220233095

Epoch: 5| Step: 2
Training loss: 2.4217223088522406
Validation loss: 2.481406695833445

Epoch: 5| Step: 3
Training loss: 2.8169804806424046
Validation loss: 2.482347264683056

Epoch: 5| Step: 4
Training loss: 2.074370700134069
Validation loss: 2.4779470927455876

Epoch: 5| Step: 5
Training loss: 2.287221539334377
Validation loss: 2.4831785563958304

Epoch: 5| Step: 6
Training loss: 2.512989345741988
Validation loss: 2.477862028173084

Epoch: 5| Step: 7
Training loss: 2.786688470101122
Validation loss: 2.476559587831921

Epoch: 5| Step: 8
Training loss: 2.659718571309859
Validation loss: 2.469968525236187

Epoch: 5| Step: 9
Training loss: 2.3585675607385332
Validation loss: 2.4616181577716767

Epoch: 5| Step: 10
Training loss: 2.6344436437458203
Validation loss: 2.457961015201506

Epoch: 5| Step: 11
Training loss: 1.9116539573524107
Validation loss: 2.4659964762290216

Epoch: 104| Step: 0
Training loss: 2.3711142625502752
Validation loss: 2.4779964230867977

Epoch: 5| Step: 1
Training loss: 2.6477688195596447
Validation loss: 2.4752103722556997

Epoch: 5| Step: 2
Training loss: 3.0467887670589606
Validation loss: 2.493493482355932

Epoch: 5| Step: 3
Training loss: 2.365501584017233
Validation loss: 2.481207926190881

Epoch: 5| Step: 4
Training loss: 2.4178124594518926
Validation loss: 2.474036070288317

Epoch: 5| Step: 5
Training loss: 2.8604044077463056
Validation loss: 2.477580646411004

Epoch: 5| Step: 6
Training loss: 2.7279488173462925
Validation loss: 2.47305431647038

Epoch: 5| Step: 7
Training loss: 2.3779210648585964
Validation loss: 2.4757583106709533

Epoch: 5| Step: 8
Training loss: 2.8861945764268224
Validation loss: 2.4779181194819664

Epoch: 5| Step: 9
Training loss: 2.4555473273797745
Validation loss: 2.4833883969604873

Epoch: 5| Step: 10
Training loss: 2.463345176382679
Validation loss: 2.4782751641590504

Epoch: 5| Step: 11
Training loss: 1.791546824979054
Validation loss: 2.4811650257630045

Epoch: 105| Step: 0
Training loss: 2.2721688312744153
Validation loss: 2.4835385407931954

Epoch: 5| Step: 1
Training loss: 2.6231630346464265
Validation loss: 2.481306716469314

Epoch: 5| Step: 2
Training loss: 2.911795135470507
Validation loss: 2.4713102215530114

Epoch: 5| Step: 3
Training loss: 2.6856383152046397
Validation loss: 2.47068270748985

Epoch: 5| Step: 4
Training loss: 2.8535532234111796
Validation loss: 2.4862837906106385

Epoch: 5| Step: 5
Training loss: 2.6488758725857084
Validation loss: 2.479717895924048

Epoch: 5| Step: 6
Training loss: 2.6247629331078817
Validation loss: 2.486567831058883

Epoch: 5| Step: 7
Training loss: 2.792199942673687
Validation loss: 2.485674040632482

Epoch: 5| Step: 8
Training loss: 1.7909802815019036
Validation loss: 2.479118824879191

Epoch: 5| Step: 9
Training loss: 2.582894462304986
Validation loss: 2.4820417607875056

Epoch: 5| Step: 10
Training loss: 2.4470257592071123
Validation loss: 2.475523163992145

Epoch: 5| Step: 11
Training loss: 2.8424428094295813
Validation loss: 2.477492004597193

Epoch: 106| Step: 0
Training loss: 2.3234069945353655
Validation loss: 2.478767588628841

Epoch: 5| Step: 1
Training loss: 2.4108323890780006
Validation loss: 2.4781357454289044

Epoch: 5| Step: 2
Training loss: 2.99123245814369
Validation loss: 2.484719744341033

Epoch: 5| Step: 3
Training loss: 2.9964008994491587
Validation loss: 2.4764925669073277

Epoch: 5| Step: 4
Training loss: 2.6915781882499967
Validation loss: 2.4750323296692756

Epoch: 5| Step: 5
Training loss: 2.884638510391263
Validation loss: 2.4747566153246523

Epoch: 5| Step: 6
Training loss: 2.4058232114724514
Validation loss: 2.477643700578895

Epoch: 5| Step: 7
Training loss: 2.2140465972049292
Validation loss: 2.4840320554387234

Epoch: 5| Step: 8
Training loss: 2.5305756977655465
Validation loss: 2.470616634900611

Epoch: 5| Step: 9
Training loss: 2.583464208999875
Validation loss: 2.4751480668343264

Epoch: 5| Step: 10
Training loss: 2.1958381865108163
Validation loss: 2.472884761703042

Epoch: 5| Step: 11
Training loss: 2.142938630507438
Validation loss: 2.4741621890487404

Epoch: 107| Step: 0
Training loss: 2.9278819305920285
Validation loss: 2.4752005633897474

Epoch: 5| Step: 1
Training loss: 2.1196957753180343
Validation loss: 2.4769011465523567

Epoch: 5| Step: 2
Training loss: 2.43601024780874
Validation loss: 2.484737203893552

Epoch: 5| Step: 3
Training loss: 2.5697017048300843
Validation loss: 2.4774879066359463

Epoch: 5| Step: 4
Training loss: 2.267496953623617
Validation loss: 2.476366382298581

Epoch: 5| Step: 5
Training loss: 2.6892609260935023
Validation loss: 2.4740886747591304

Epoch: 5| Step: 6
Training loss: 2.6058994377623677
Validation loss: 2.4787898030999256

Epoch: 5| Step: 7
Training loss: 2.699595534088108
Validation loss: 2.474320508982089

Epoch: 5| Step: 8
Training loss: 2.498893302102058
Validation loss: 2.474695390362032

Epoch: 5| Step: 9
Training loss: 2.46810305846704
Validation loss: 2.472293499717977

Epoch: 5| Step: 10
Training loss: 2.973905082978594
Validation loss: 2.4717917354753

Epoch: 5| Step: 11
Training loss: 2.107354899306441
Validation loss: 2.4736434669230034

Epoch: 108| Step: 0
Training loss: 2.5055870568249294
Validation loss: 2.469069806240898

Epoch: 5| Step: 1
Training loss: 2.2637559218516166
Validation loss: 2.4735778007308795

Epoch: 5| Step: 2
Training loss: 2.5551553933503692
Validation loss: 2.475849863363334

Epoch: 5| Step: 3
Training loss: 2.9269733521421735
Validation loss: 2.4737187373271032

Epoch: 5| Step: 4
Training loss: 2.6455910839607686
Validation loss: 2.4685297316458725

Epoch: 5| Step: 5
Training loss: 2.117431288756204
Validation loss: 2.4616378837078736

Epoch: 5| Step: 6
Training loss: 2.9479793546411797
Validation loss: 2.4594879725488448

Epoch: 5| Step: 7
Training loss: 2.811915866803269
Validation loss: 2.461738734525858

Epoch: 5| Step: 8
Training loss: 2.14790898151176
Validation loss: 2.4603497201875766

Epoch: 5| Step: 9
Training loss: 2.423588595669816
Validation loss: 2.471631601650362

Epoch: 5| Step: 10
Training loss: 2.916801903632082
Validation loss: 2.4685927594485486

Epoch: 5| Step: 11
Training loss: 1.4884516901256455
Validation loss: 2.4701457564724065

Epoch: 109| Step: 0
Training loss: 2.444696220763718
Validation loss: 2.470572776522344

Epoch: 5| Step: 1
Training loss: 2.576043045489884
Validation loss: 2.4741183573851564

Epoch: 5| Step: 2
Training loss: 2.5578986002529547
Validation loss: 2.467935262712288

Epoch: 5| Step: 3
Training loss: 2.7103131809363514
Validation loss: 2.467811160496814

Epoch: 5| Step: 4
Training loss: 2.8415569191003907
Validation loss: 2.4631822853521985

Epoch: 5| Step: 5
Training loss: 2.1701747908271583
Validation loss: 2.466555086449582

Epoch: 5| Step: 6
Training loss: 2.6285318501969877
Validation loss: 2.466311288430738

Epoch: 5| Step: 7
Training loss: 2.637403882340819
Validation loss: 2.462944596879273

Epoch: 5| Step: 8
Training loss: 2.609416207542091
Validation loss: 2.46202798327867

Epoch: 5| Step: 9
Training loss: 2.47728509319232
Validation loss: 2.4616096628179713

Epoch: 5| Step: 10
Training loss: 2.39267797144978
Validation loss: 2.458510757498525

Epoch: 5| Step: 11
Training loss: 2.6767375044833432
Validation loss: 2.465553165480428

Epoch: 110| Step: 0
Training loss: 2.532392644235415
Validation loss: 2.4645446922377277

Epoch: 5| Step: 1
Training loss: 2.416244952358888
Validation loss: 2.4644921964453603

Epoch: 5| Step: 2
Training loss: 1.7774435497392782
Validation loss: 2.4697376641642044

Epoch: 5| Step: 3
Training loss: 2.6102181174679746
Validation loss: 2.467619532485866

Epoch: 5| Step: 4
Training loss: 2.4967571206847374
Validation loss: 2.4695912247764413

Epoch: 5| Step: 5
Training loss: 2.3471333814833857
Validation loss: 2.4751667096605896

Epoch: 5| Step: 6
Training loss: 2.5350218562400975
Validation loss: 2.4768564990374053

Epoch: 5| Step: 7
Training loss: 2.457564885785659
Validation loss: 2.454121255751344

Epoch: 5| Step: 8
Training loss: 3.1158949387826365
Validation loss: 2.459765572013045

Epoch: 5| Step: 9
Training loss: 2.8928751667409847
Validation loss: 2.459908075333814

Epoch: 5| Step: 10
Training loss: 2.5477490007864394
Validation loss: 2.465386328449026

Epoch: 5| Step: 11
Training loss: 3.368615787925384
Validation loss: 2.4718451834518853

Epoch: 111| Step: 0
Training loss: 2.989575712790175
Validation loss: 2.470731157588624

Epoch: 5| Step: 1
Training loss: 2.8879839404919743
Validation loss: 2.472157645513198

Epoch: 5| Step: 2
Training loss: 2.640535161222548
Validation loss: 2.475210777613072

Epoch: 5| Step: 3
Training loss: 2.8100632177823597
Validation loss: 2.483359647191142

Epoch: 5| Step: 4
Training loss: 2.720558880160906
Validation loss: 2.4951376001527112

Epoch: 5| Step: 5
Training loss: 2.496987530556107
Validation loss: 2.4990887610387476

Epoch: 5| Step: 6
Training loss: 2.498758961679133
Validation loss: 2.5033312140716983

Epoch: 5| Step: 7
Training loss: 2.198738980853915
Validation loss: 2.503387032333758

Epoch: 5| Step: 8
Training loss: 2.132577177486956
Validation loss: 2.506193143242487

Epoch: 5| Step: 9
Training loss: 2.842811177985052
Validation loss: 2.5130956701227243

Epoch: 5| Step: 10
Training loss: 2.372406999636409
Validation loss: 2.508547737509825

Epoch: 5| Step: 11
Training loss: 2.636749041347993
Validation loss: 2.51036611614274

Epoch: 112| Step: 0
Training loss: 2.3450911690043914
Validation loss: 2.50782884016091

Epoch: 5| Step: 1
Training loss: 2.6482531278007113
Validation loss: 2.5075683157968527

Epoch: 5| Step: 2
Training loss: 2.7439263636882205
Validation loss: 2.498343443397321

Epoch: 5| Step: 3
Training loss: 2.9320982919535212
Validation loss: 2.497715752841146

Epoch: 5| Step: 4
Training loss: 2.515379615330937
Validation loss: 2.4925169333402786

Epoch: 5| Step: 5
Training loss: 2.3367206192136663
Validation loss: 2.491578652561469

Epoch: 5| Step: 6
Training loss: 2.7796809882033586
Validation loss: 2.4852287936662854

Epoch: 5| Step: 7
Training loss: 2.76861514070903
Validation loss: 2.483112694285495

Epoch: 5| Step: 8
Training loss: 2.448018584598481
Validation loss: 2.479464245949646

Epoch: 5| Step: 9
Training loss: 2.1071101710299027
Validation loss: 2.480186738731028

Epoch: 5| Step: 10
Training loss: 2.9675169944115876
Validation loss: 2.4734877824843373

Epoch: 5| Step: 11
Training loss: 2.511234218914296
Validation loss: 2.4736048449232797

Epoch: 113| Step: 0
Training loss: 2.5275155293546963
Validation loss: 2.4707582168568556

Epoch: 5| Step: 1
Training loss: 2.6685570533204217
Validation loss: 2.4705911603444144

Epoch: 5| Step: 2
Training loss: 2.8890898055936503
Validation loss: 2.4694317990851657

Epoch: 5| Step: 3
Training loss: 2.844143347731666
Validation loss: 2.4677225421406814

Epoch: 5| Step: 4
Training loss: 2.105284277596698
Validation loss: 2.463512639579714

Epoch: 5| Step: 5
Training loss: 2.8182842538065436
Validation loss: 2.459022483298095

Epoch: 5| Step: 6
Training loss: 2.3473962522418454
Validation loss: 2.4633664007660254

Epoch: 5| Step: 7
Training loss: 2.019162526217613
Validation loss: 2.4583465500384722

Epoch: 5| Step: 8
Training loss: 3.100359089880728
Validation loss: 2.455178112339822

Epoch: 5| Step: 9
Training loss: 2.081833248492787
Validation loss: 2.4580905331037184

Epoch: 5| Step: 10
Training loss: 2.629024689997733
Validation loss: 2.4524183814699434

Epoch: 5| Step: 11
Training loss: 2.383220300016993
Validation loss: 2.4607034965553853

Epoch: 114| Step: 0
Training loss: 2.678253145835451
Validation loss: 2.4546257498534203

Epoch: 5| Step: 1
Training loss: 2.667628253974644
Validation loss: 2.4515312144202124

Epoch: 5| Step: 2
Training loss: 2.6209268303605424
Validation loss: 2.451269359093942

Epoch: 5| Step: 3
Training loss: 2.4564941983735817
Validation loss: 2.464687316250922

Epoch: 5| Step: 4
Training loss: 2.531240675167286
Validation loss: 2.4672975090035205

Epoch: 5| Step: 5
Training loss: 2.543736964386852
Validation loss: 2.467841987377337

Epoch: 5| Step: 6
Training loss: 2.110757106524609
Validation loss: 2.471854266157294

Epoch: 5| Step: 7
Training loss: 2.968497175192521
Validation loss: 2.472014216775917

Epoch: 5| Step: 8
Training loss: 2.610564183610602
Validation loss: 2.4723108903173885

Epoch: 5| Step: 9
Training loss: 2.571589839510442
Validation loss: 2.4697545257268434

Epoch: 5| Step: 10
Training loss: 2.7138841428772698
Validation loss: 2.46823888227927

Epoch: 5| Step: 11
Training loss: 1.8611081164448242
Validation loss: 2.4624076932462837

Epoch: 115| Step: 0
Training loss: 2.0705520203427183
Validation loss: 2.4665433099440732

Epoch: 5| Step: 1
Training loss: 2.450973636468291
Validation loss: 2.4698800023849397

Epoch: 5| Step: 2
Training loss: 2.825194637378938
Validation loss: 2.4591579724421737

Epoch: 5| Step: 3
Training loss: 2.743287651018476
Validation loss: 2.4644633229805977

Epoch: 5| Step: 4
Training loss: 2.359471603335849
Validation loss: 2.4666619383491697

Epoch: 5| Step: 5
Training loss: 2.290686958588741
Validation loss: 2.4611713641423605

Epoch: 5| Step: 6
Training loss: 2.7167907319866744
Validation loss: 2.459358705969948

Epoch: 5| Step: 7
Training loss: 2.769161226548683
Validation loss: 2.45497740116841

Epoch: 5| Step: 8
Training loss: 2.660140296563304
Validation loss: 2.4607786097019773

Epoch: 5| Step: 9
Training loss: 2.591474523096344
Validation loss: 2.4546733472947473

Epoch: 5| Step: 10
Training loss: 2.80150736357201
Validation loss: 2.4582836798055374

Epoch: 5| Step: 11
Training loss: 2.0599125902834214
Validation loss: 2.4549186693200604

Epoch: 116| Step: 0
Training loss: 2.7065645065978465
Validation loss: 2.459769283520342

Epoch: 5| Step: 1
Training loss: 2.7641411372805553
Validation loss: 2.4550411977244107

Epoch: 5| Step: 2
Training loss: 2.098340709553127
Validation loss: 2.454776475290599

Epoch: 5| Step: 3
Training loss: 2.894115588038299
Validation loss: 2.4571281943630936

Epoch: 5| Step: 4
Training loss: 3.001498801624339
Validation loss: 2.451430113868734

Epoch: 5| Step: 5
Training loss: 2.194604291070435
Validation loss: 2.454890660523717

Epoch: 5| Step: 6
Training loss: 2.150445949525315
Validation loss: 2.4626900502754583

Epoch: 5| Step: 7
Training loss: 2.903439711480699
Validation loss: 2.4496044137189

Epoch: 5| Step: 8
Training loss: 2.445246393937222
Validation loss: 2.455866280237531

Epoch: 5| Step: 9
Training loss: 2.3124947418977913
Validation loss: 2.455201596291424

Epoch: 5| Step: 10
Training loss: 2.5508063929955798
Validation loss: 2.4604090410825523

Epoch: 5| Step: 11
Training loss: 2.043517875904947
Validation loss: 2.45730596764319

Epoch: 117| Step: 0
Training loss: 2.699475686062902
Validation loss: 2.4537248019911493

Epoch: 5| Step: 1
Training loss: 2.245599682413316
Validation loss: 2.4587231073814233

Epoch: 5| Step: 2
Training loss: 2.310787597911663
Validation loss: 2.45472605104565

Epoch: 5| Step: 3
Training loss: 2.7986363666700074
Validation loss: 2.459921325308124

Epoch: 5| Step: 4
Training loss: 2.382471679327041
Validation loss: 2.4640761367591444

Epoch: 5| Step: 5
Training loss: 2.5997499675836937
Validation loss: 2.4722136894416953

Epoch: 5| Step: 6
Training loss: 2.327010739343088
Validation loss: 2.4581473422948683

Epoch: 5| Step: 7
Training loss: 2.595772931012071
Validation loss: 2.4556228086080374

Epoch: 5| Step: 8
Training loss: 2.7815610733088567
Validation loss: 2.4575164469494872

Epoch: 5| Step: 9
Training loss: 2.050969810899753
Validation loss: 2.4590293833699146

Epoch: 5| Step: 10
Training loss: 3.055564032648831
Validation loss: 2.464265903744729

Epoch: 5| Step: 11
Training loss: 2.6887558065623955
Validation loss: 2.4565398832233676

Epoch: 118| Step: 0
Training loss: 2.2204363150170803
Validation loss: 2.467905423200316

Epoch: 5| Step: 1
Training loss: 2.5733492921258607
Validation loss: 2.4675384598813452

Epoch: 5| Step: 2
Training loss: 2.398081501438749
Validation loss: 2.4682125279083826

Epoch: 5| Step: 3
Training loss: 2.23767912589884
Validation loss: 2.4711989115166584

Epoch: 5| Step: 4
Training loss: 3.04855597660277
Validation loss: 2.468987871934921

Epoch: 5| Step: 5
Training loss: 2.79097855091498
Validation loss: 2.4692145807799553

Epoch: 5| Step: 6
Training loss: 2.9734838388894462
Validation loss: 2.4679892369766736

Epoch: 5| Step: 7
Training loss: 2.6191583756564323
Validation loss: 2.4629514133616253

Epoch: 5| Step: 8
Training loss: 2.5997507929580173
Validation loss: 2.464319273076486

Epoch: 5| Step: 9
Training loss: 2.2469569927423816
Validation loss: 2.4636995790503633

Epoch: 5| Step: 10
Training loss: 2.4256469885977756
Validation loss: 2.4659157349910226

Epoch: 5| Step: 11
Training loss: 2.8268600079554056
Validation loss: 2.467881677727214

Epoch: 119| Step: 0
Training loss: 2.832394911995854
Validation loss: 2.4652221679385273

Epoch: 5| Step: 1
Training loss: 2.658875189139825
Validation loss: 2.457304405145965

Epoch: 5| Step: 2
Training loss: 2.240530431818716
Validation loss: 2.4651876653998053

Epoch: 5| Step: 3
Training loss: 2.3240072202192805
Validation loss: 2.463024207376573

Epoch: 5| Step: 4
Training loss: 2.7946420632121405
Validation loss: 2.459954189459377

Epoch: 5| Step: 5
Training loss: 1.9969112267588518
Validation loss: 2.4561984576899425

Epoch: 5| Step: 6
Training loss: 2.8248663406485797
Validation loss: 2.4627535824988276

Epoch: 5| Step: 7
Training loss: 2.500777886485847
Validation loss: 2.456868492278935

Epoch: 5| Step: 8
Training loss: 2.45213822849204
Validation loss: 2.463005730774986

Epoch: 5| Step: 9
Training loss: 2.772869127087207
Validation loss: 2.461547501464133

Epoch: 5| Step: 10
Training loss: 2.5738085129002664
Validation loss: 2.456693350113461

Epoch: 5| Step: 11
Training loss: 2.068491930581873
Validation loss: 2.456572206247757

Epoch: 120| Step: 0
Training loss: 2.308279567969142
Validation loss: 2.4521243004197744

Epoch: 5| Step: 1
Training loss: 2.6193416100178117
Validation loss: 2.4645980656092963

Epoch: 5| Step: 2
Training loss: 2.4180485183795524
Validation loss: 2.4573870968746574

Epoch: 5| Step: 3
Training loss: 2.5053375485750027
Validation loss: 2.4725442010241223

Epoch: 5| Step: 4
Training loss: 3.0427716133792435
Validation loss: 2.4797071073542525

Epoch: 5| Step: 5
Training loss: 2.4844390093156887
Validation loss: 2.46324994871588

Epoch: 5| Step: 6
Training loss: 2.947871303321647
Validation loss: 2.4471003503747406

Epoch: 5| Step: 7
Training loss: 2.113323105487482
Validation loss: 2.4483584120391972

Epoch: 5| Step: 8
Training loss: 2.1851515016037073
Validation loss: 2.452313416467503

Epoch: 5| Step: 9
Training loss: 2.731753067720076
Validation loss: 2.4551963646173105

Epoch: 5| Step: 10
Training loss: 2.4959768348499196
Validation loss: 2.462034306003883

Epoch: 5| Step: 11
Training loss: 2.9013407271702367
Validation loss: 2.4634464896099075

Epoch: 121| Step: 0
Training loss: 2.350061488868928
Validation loss: 2.4633351186307944

Epoch: 5| Step: 1
Training loss: 2.272120982709944
Validation loss: 2.4736589886444618

Epoch: 5| Step: 2
Training loss: 2.8433842685813535
Validation loss: 2.4656472284485873

Epoch: 5| Step: 3
Training loss: 2.576332810286577
Validation loss: 2.4593675479994137

Epoch: 5| Step: 4
Training loss: 2.6543323550965234
Validation loss: 2.4662059197898825

Epoch: 5| Step: 5
Training loss: 2.5213559662428273
Validation loss: 2.4646153774956834

Epoch: 5| Step: 6
Training loss: 2.747170553266865
Validation loss: 2.458563734561676

Epoch: 5| Step: 7
Training loss: 2.4742187577088925
Validation loss: 2.4485484275204135

Epoch: 5| Step: 8
Training loss: 2.524010938557229
Validation loss: 2.4482103874982677

Epoch: 5| Step: 9
Training loss: 2.3106413924296385
Validation loss: 2.4496544750005578

Epoch: 5| Step: 10
Training loss: 2.6763177709715755
Validation loss: 2.4458313494083432

Epoch: 5| Step: 11
Training loss: 2.456007412100924
Validation loss: 2.4589910166243953

Epoch: 122| Step: 0
Training loss: 2.297128676334795
Validation loss: 2.4567866928907423

Epoch: 5| Step: 1
Training loss: 2.514836252846613
Validation loss: 2.451806062116072

Epoch: 5| Step: 2
Training loss: 2.710059295793867
Validation loss: 2.44779525550441

Epoch: 5| Step: 3
Training loss: 2.644019659191459
Validation loss: 2.4540485741182003

Epoch: 5| Step: 4
Training loss: 2.5703779867346244
Validation loss: 2.4540218973340915

Epoch: 5| Step: 5
Training loss: 2.6561395958788405
Validation loss: 2.4534121626735756

Epoch: 5| Step: 6
Training loss: 2.349207919127219
Validation loss: 2.4468475658556357

Epoch: 5| Step: 7
Training loss: 2.6906436011261787
Validation loss: 2.4544597728113993

Epoch: 5| Step: 8
Training loss: 2.8636692507618244
Validation loss: 2.453714368771688

Epoch: 5| Step: 9
Training loss: 2.167959182305746
Validation loss: 2.4600696264599073

Epoch: 5| Step: 10
Training loss: 2.204580921649305
Validation loss: 2.459438771831172

Epoch: 5| Step: 11
Training loss: 3.220712600425722
Validation loss: 2.4542726557522894

Epoch: 123| Step: 0
Training loss: 2.5644288595755538
Validation loss: 2.4614190130097198

Epoch: 5| Step: 1
Training loss: 2.343230940244441
Validation loss: 2.457309994151511

Epoch: 5| Step: 2
Training loss: 2.725713996790082
Validation loss: 2.4574889447619066

Epoch: 5| Step: 3
Training loss: 2.5717773901028806
Validation loss: 2.4563162510796825

Epoch: 5| Step: 4
Training loss: 2.453307515540623
Validation loss: 2.4520644752492475

Epoch: 5| Step: 5
Training loss: 2.7546986407110405
Validation loss: 2.454417975262945

Epoch: 5| Step: 6
Training loss: 2.212212723869618
Validation loss: 2.4567906858801116

Epoch: 5| Step: 7
Training loss: 2.757742905211415
Validation loss: 2.4526575436835456

Epoch: 5| Step: 8
Training loss: 2.6089587764794953
Validation loss: 2.4554767027145674

Epoch: 5| Step: 9
Training loss: 2.6368431683608433
Validation loss: 2.446654222839614

Epoch: 5| Step: 10
Training loss: 2.331618996224445
Validation loss: 2.4497501135566977

Epoch: 5| Step: 11
Training loss: 1.8753390959239686
Validation loss: 2.4517368308965795

Epoch: 124| Step: 0
Training loss: 2.3289209835657525
Validation loss: 2.4496402975969516

Epoch: 5| Step: 1
Training loss: 2.095500840292716
Validation loss: 2.457741570505181

Epoch: 5| Step: 2
Training loss: 2.06855566950247
Validation loss: 2.4603934398096365

Epoch: 5| Step: 3
Training loss: 2.0408728736711694
Validation loss: 2.4605840519992657

Epoch: 5| Step: 4
Training loss: 2.5979235059887253
Validation loss: 2.460303742683763

Epoch: 5| Step: 5
Training loss: 2.909344901841914
Validation loss: 2.4541446000441836

Epoch: 5| Step: 6
Training loss: 2.6770580503306403
Validation loss: 2.4434715629454407

Epoch: 5| Step: 7
Training loss: 3.064693832912147
Validation loss: 2.451598921781421

Epoch: 5| Step: 8
Training loss: 2.9409104698170414
Validation loss: 2.4497313624651254

Epoch: 5| Step: 9
Training loss: 2.4078283706726205
Validation loss: 2.448432463555754

Epoch: 5| Step: 10
Training loss: 2.1414318930737304
Validation loss: 2.451330650425469

Epoch: 5| Step: 11
Training loss: 3.786230165235038
Validation loss: 2.458053449010816

Epoch: 125| Step: 0
Training loss: 2.8919565793862922
Validation loss: 2.4543115698280213

Epoch: 5| Step: 1
Training loss: 2.720485089746892
Validation loss: 2.4634747822064855

Epoch: 5| Step: 2
Training loss: 3.026688122050103
Validation loss: 2.4556770979915745

Epoch: 5| Step: 3
Training loss: 2.250572343722506
Validation loss: 2.4596683317573342

Epoch: 5| Step: 4
Training loss: 1.7482533594004004
Validation loss: 2.455559043344789

Epoch: 5| Step: 5
Training loss: 2.8343195227395275
Validation loss: 2.461708008776941

Epoch: 5| Step: 6
Training loss: 2.25132553473739
Validation loss: 2.460804103081765

Epoch: 5| Step: 7
Training loss: 2.292575887008513
Validation loss: 2.456578429786385

Epoch: 5| Step: 8
Training loss: 2.4562214546389165
Validation loss: 2.447504533744668

Epoch: 5| Step: 9
Training loss: 2.573957369186816
Validation loss: 2.448066781223138

Epoch: 5| Step: 10
Training loss: 2.6508695975010395
Validation loss: 2.4505651728760056

Epoch: 5| Step: 11
Training loss: 1.6997005787995165
Validation loss: 2.448418088380377

Testing loss: 2.0096288236908455
