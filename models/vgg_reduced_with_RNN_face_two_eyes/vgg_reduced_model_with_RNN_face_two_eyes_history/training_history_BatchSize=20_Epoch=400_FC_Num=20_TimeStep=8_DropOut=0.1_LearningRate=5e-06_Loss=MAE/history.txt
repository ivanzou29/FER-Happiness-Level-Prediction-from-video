Epoch: 1| Step: 0
Training loss: 5.420536994934082
Validation loss: 5.347288390000661

Epoch: 5| Step: 1
Training loss: 5.534276008605957
Validation loss: 5.345080475012462

Epoch: 5| Step: 2
Training loss: 5.686539173126221
Validation loss: 5.342938145001729

Epoch: 5| Step: 3
Training loss: 5.124110698699951
Validation loss: 5.340651313463847

Epoch: 5| Step: 4
Training loss: 5.557741165161133
Validation loss: 5.338300049304962

Epoch: 5| Step: 5
Training loss: 5.42840051651001
Validation loss: 5.335862974325816

Epoch: 5| Step: 6
Training loss: 5.557076454162598
Validation loss: 5.333482503890991

Epoch: 5| Step: 7
Training loss: 5.284002780914307
Validation loss: 5.330777982870738

Epoch: 5| Step: 8
Training loss: 5.726900577545166
Validation loss: 5.327993869781494

Epoch: 5| Step: 9
Training loss: 4.933917999267578
Validation loss: 5.325195789337158

Epoch: 5| Step: 10
Training loss: 5.302707672119141
Validation loss: 5.322312653064728

Epoch: 5| Step: 11
Training loss: 4.852705955505371
Validation loss: 5.319342931111653

Epoch: 2| Step: 0
Training loss: 5.841256141662598
Validation loss: 5.316035707791646

Epoch: 5| Step: 1
Training loss: 5.122717380523682
Validation loss: 5.312751094500224

Epoch: 5| Step: 2
Training loss: 5.581447601318359
Validation loss: 5.30934335788091

Epoch: 5| Step: 3
Training loss: 4.901276111602783
Validation loss: 5.3055500984191895

Epoch: 5| Step: 4
Training loss: 5.381067276000977
Validation loss: 5.301900287469228

Epoch: 5| Step: 5
Training loss: 5.335548400878906
Validation loss: 5.29785434405009

Epoch: 5| Step: 6
Training loss: 5.936899662017822
Validation loss: 5.293505748112996

Epoch: 5| Step: 7
Training loss: 4.981825828552246
Validation loss: 5.289085169633229

Epoch: 5| Step: 8
Training loss: 5.243961334228516
Validation loss: 5.2845086852709455

Epoch: 5| Step: 9
Training loss: 5.735215663909912
Validation loss: 5.279526591300964

Epoch: 5| Step: 10
Training loss: 4.890479564666748
Validation loss: 5.27457453807195

Epoch: 5| Step: 11
Training loss: 5.708259582519531
Validation loss: 5.269064426422119

Epoch: 3| Step: 0
Training loss: 6.119234561920166
Validation loss: 5.263650258382161

Epoch: 5| Step: 1
Training loss: 6.077619552612305
Validation loss: 5.257506986459096

Epoch: 5| Step: 2
Training loss: 5.24852991104126
Validation loss: 5.25137855609258

Epoch: 5| Step: 3
Training loss: 5.348184585571289
Validation loss: 5.244733115037282

Epoch: 5| Step: 4
Training loss: 4.200826168060303
Validation loss: 5.238078912099202

Epoch: 5| Step: 5
Training loss: 5.662032127380371
Validation loss: 5.230890254179637

Epoch: 5| Step: 6
Training loss: 4.593588829040527
Validation loss: 5.223455369472504

Epoch: 5| Step: 7
Training loss: 5.416830062866211
Validation loss: 5.215272426605225

Epoch: 5| Step: 8
Training loss: 5.4859161376953125
Validation loss: 5.207084993521373

Epoch: 5| Step: 9
Training loss: 4.536072731018066
Validation loss: 5.198393126328786

Epoch: 5| Step: 10
Training loss: 5.453408241271973
Validation loss: 5.1895572145779925

Epoch: 5| Step: 11
Training loss: 6.007688045501709
Validation loss: 5.180172979831696

Epoch: 4| Step: 0
Training loss: 5.306841850280762
Validation loss: 5.170505464076996

Epoch: 5| Step: 1
Training loss: 5.581395149230957
Validation loss: 5.160319745540619

Epoch: 5| Step: 2
Training loss: 3.9410362243652344
Validation loss: 5.149758398532867

Epoch: 5| Step: 3
Training loss: 5.674139499664307
Validation loss: 5.13860023021698

Epoch: 5| Step: 4
Training loss: 4.658202171325684
Validation loss: 5.127435465653737

Epoch: 5| Step: 5
Training loss: 4.632906436920166
Validation loss: 5.11553970972697

Epoch: 5| Step: 6
Training loss: 5.417022705078125
Validation loss: 5.103510816891988

Epoch: 5| Step: 7
Training loss: 5.207250118255615
Validation loss: 5.091050406297048

Epoch: 5| Step: 8
Training loss: 6.146162986755371
Validation loss: 5.078229248523712

Epoch: 5| Step: 9
Training loss: 5.217015266418457
Validation loss: 5.064685781796773

Epoch: 5| Step: 10
Training loss: 5.614558219909668
Validation loss: 5.051392555236816

Epoch: 5| Step: 11
Training loss: 3.4388248920440674
Validation loss: 5.037957986195882

Epoch: 5| Step: 0
Training loss: 4.719937324523926
Validation loss: 5.023995717366536

Epoch: 5| Step: 1
Training loss: 4.4630208015441895
Validation loss: 5.010182440280914

Epoch: 5| Step: 2
Training loss: 6.130932331085205
Validation loss: 4.995633403460185

Epoch: 5| Step: 3
Training loss: 4.544547080993652
Validation loss: 4.9814130663871765

Epoch: 5| Step: 4
Training loss: 6.099469184875488
Validation loss: 4.967062691847484

Epoch: 5| Step: 5
Training loss: 4.961325645446777
Validation loss: 4.952740987141927

Epoch: 5| Step: 6
Training loss: 5.95794153213501
Validation loss: 4.938504894574483

Epoch: 5| Step: 7
Training loss: 3.960393190383911
Validation loss: 4.922923386096954

Epoch: 5| Step: 8
Training loss: 5.49928617477417
Validation loss: 4.908795128266017

Epoch: 5| Step: 9
Training loss: 5.147268772125244
Validation loss: 4.8945761521657305

Epoch: 5| Step: 10
Training loss: 4.158238410949707
Validation loss: 4.880518098672231

Epoch: 5| Step: 11
Training loss: 3.714256763458252
Validation loss: 4.8666196664174395

Epoch: 6| Step: 0
Training loss: 5.770741939544678
Validation loss: 4.853597104549408

Epoch: 5| Step: 1
Training loss: 5.556377410888672
Validation loss: 4.840292076269786

Epoch: 5| Step: 2
Training loss: 5.039348125457764
Validation loss: 4.827384829521179

Epoch: 5| Step: 3
Training loss: 6.04477071762085
Validation loss: 4.8147051731745405

Epoch: 5| Step: 4
Training loss: 4.706052303314209
Validation loss: 4.8016850252946215

Epoch: 5| Step: 5
Training loss: 3.444500684738159
Validation loss: 4.789216955502828

Epoch: 5| Step: 6
Training loss: 5.431557655334473
Validation loss: 4.77653956413269

Epoch: 5| Step: 7
Training loss: 4.552985191345215
Validation loss: 4.764089067776998

Epoch: 5| Step: 8
Training loss: 4.773758888244629
Validation loss: 4.752326726913452

Epoch: 5| Step: 9
Training loss: 4.490439414978027
Validation loss: 4.7408246994018555

Epoch: 5| Step: 10
Training loss: 3.834475040435791
Validation loss: 4.729005177815755

Epoch: 5| Step: 11
Training loss: 5.058707237243652
Validation loss: 4.718075235684712

Epoch: 7| Step: 0
Training loss: 5.561587333679199
Validation loss: 4.707580169041951

Epoch: 5| Step: 1
Training loss: 4.784621238708496
Validation loss: 4.696352074543635

Epoch: 5| Step: 2
Training loss: 4.470943450927734
Validation loss: 4.686232705911

Epoch: 5| Step: 3
Training loss: 4.7487945556640625
Validation loss: 4.676141391197841

Epoch: 5| Step: 4
Training loss: 4.790754318237305
Validation loss: 4.666073004404704

Epoch: 5| Step: 5
Training loss: 4.875787258148193
Validation loss: 4.6560773849487305

Epoch: 5| Step: 6
Training loss: 4.2540154457092285
Validation loss: 4.646476884682973

Epoch: 5| Step: 7
Training loss: 4.454634666442871
Validation loss: 4.6372184952100115

Epoch: 5| Step: 8
Training loss: 5.199636936187744
Validation loss: 4.628531416257222

Epoch: 5| Step: 9
Training loss: 4.524993896484375
Validation loss: 4.619635899861653

Epoch: 5| Step: 10
Training loss: 5.023931980133057
Validation loss: 4.610951632261276

Epoch: 5| Step: 11
Training loss: 2.698939085006714
Validation loss: 4.603074789047241

Epoch: 8| Step: 0
Training loss: 4.382043838500977
Validation loss: 4.594392637411754

Epoch: 5| Step: 1
Training loss: 3.4540576934814453
Validation loss: 4.586616049210231

Epoch: 5| Step: 2
Training loss: 5.138916492462158
Validation loss: 4.578841745853424

Epoch: 5| Step: 3
Training loss: 4.282313823699951
Validation loss: 4.571169118086497

Epoch: 5| Step: 4
Training loss: 4.407553672790527
Validation loss: 4.563438554604848

Epoch: 5| Step: 5
Training loss: 3.39465069770813
Validation loss: 4.555577119191487

Epoch: 5| Step: 6
Training loss: 5.4469499588012695
Validation loss: 4.548045466343562

Epoch: 5| Step: 7
Training loss: 5.9983625411987305
Validation loss: 4.540889481703441

Epoch: 5| Step: 8
Training loss: 4.901251792907715
Validation loss: 4.533771832784017

Epoch: 5| Step: 9
Training loss: 5.329395771026611
Validation loss: 4.526912043492

Epoch: 5| Step: 10
Training loss: 4.988526344299316
Validation loss: 4.519532183806102

Epoch: 5| Step: 11
Training loss: 2.2458150386810303
Validation loss: 4.512845575809479

Epoch: 9| Step: 0
Training loss: 5.602565288543701
Validation loss: 4.50672588745753

Epoch: 5| Step: 1
Training loss: 4.197136878967285
Validation loss: 4.500493208567302

Epoch: 5| Step: 2
Training loss: 4.233521461486816
Validation loss: 4.4941317439079285

Epoch: 5| Step: 3
Training loss: 4.695605278015137
Validation loss: 4.488184591134389

Epoch: 5| Step: 4
Training loss: 5.179723262786865
Validation loss: 4.482344756523768

Epoch: 5| Step: 5
Training loss: 4.2619547843933105
Validation loss: 4.476294577121735

Epoch: 5| Step: 6
Training loss: 4.741610527038574
Validation loss: 4.470369299252828

Epoch: 5| Step: 7
Training loss: 5.111246585845947
Validation loss: 4.464561263720195

Epoch: 5| Step: 8
Training loss: 3.8512635231018066
Validation loss: 4.4585667451222735

Epoch: 5| Step: 9
Training loss: 4.148279666900635
Validation loss: 4.45256628592809

Epoch: 5| Step: 10
Training loss: 4.063841819763184
Validation loss: 4.446896255016327

Epoch: 5| Step: 11
Training loss: 6.346995830535889
Validation loss: 4.440444370110829

Epoch: 10| Step: 0
Training loss: 5.34269905090332
Validation loss: 4.434522598981857

Epoch: 5| Step: 1
Training loss: 4.607443809509277
Validation loss: 4.428618272145589

Epoch: 5| Step: 2
Training loss: 5.144211769104004
Validation loss: 4.422462681929271

Epoch: 5| Step: 3
Training loss: 5.130316734313965
Validation loss: 4.416573256254196

Epoch: 5| Step: 4
Training loss: 4.911351680755615
Validation loss: 4.410755753517151

Epoch: 5| Step: 5
Training loss: 3.7689099311828613
Validation loss: 4.405021438995997

Epoch: 5| Step: 6
Training loss: 3.9017295837402344
Validation loss: 4.398829321066539

Epoch: 5| Step: 7
Training loss: 4.4060821533203125
Validation loss: 4.393152316411336

Epoch: 5| Step: 8
Training loss: 3.8070998191833496
Validation loss: 4.387254436810811

Epoch: 5| Step: 9
Training loss: 4.059149265289307
Validation loss: 4.38128266731898

Epoch: 5| Step: 10
Training loss: 4.887316703796387
Validation loss: 4.375357588132222

Epoch: 5| Step: 11
Training loss: 3.3828024864196777
Validation loss: 4.369817554950714

Epoch: 11| Step: 0
Training loss: 4.937714576721191
Validation loss: 4.363415757815043

Epoch: 5| Step: 1
Training loss: 4.545856952667236
Validation loss: 4.357358296712239

Epoch: 5| Step: 2
Training loss: 4.536889553070068
Validation loss: 4.351507504781087

Epoch: 5| Step: 3
Training loss: 4.833293914794922
Validation loss: 4.345867971579234

Epoch: 5| Step: 4
Training loss: 5.678413391113281
Validation loss: 4.340152710676193

Epoch: 5| Step: 5
Training loss: 3.578524112701416
Validation loss: 4.334424565235774

Epoch: 5| Step: 6
Training loss: 4.103449821472168
Validation loss: 4.3285655577977495

Epoch: 5| Step: 7
Training loss: 4.6263275146484375
Validation loss: 4.323233286539714

Epoch: 5| Step: 8
Training loss: 5.097795009613037
Validation loss: 4.317402084668477

Epoch: 5| Step: 9
Training loss: 3.8166489601135254
Validation loss: 4.312061101198196

Epoch: 5| Step: 10
Training loss: 3.671642303466797
Validation loss: 4.306503673394521

Epoch: 5| Step: 11
Training loss: 2.537238597869873
Validation loss: 4.301006654898326

Epoch: 12| Step: 0
Training loss: 4.443585395812988
Validation loss: 4.295427153507869

Epoch: 5| Step: 1
Training loss: 4.7909064292907715
Validation loss: 4.290124952793121

Epoch: 5| Step: 2
Training loss: 3.6455821990966797
Validation loss: 4.284448474645615

Epoch: 5| Step: 3
Training loss: 4.224761962890625
Validation loss: 4.278689136107762

Epoch: 5| Step: 4
Training loss: 4.809676170349121
Validation loss: 4.273457904656728

Epoch: 5| Step: 5
Training loss: 4.8275465965271
Validation loss: 4.26793897151947

Epoch: 5| Step: 6
Training loss: 5.234004020690918
Validation loss: 4.262616137663524

Epoch: 5| Step: 7
Training loss: 4.388182163238525
Validation loss: 4.257150967915853

Epoch: 5| Step: 8
Training loss: 3.3279380798339844
Validation loss: 4.251553664604823

Epoch: 5| Step: 9
Training loss: 4.367726802825928
Validation loss: 4.246143579483032

Epoch: 5| Step: 10
Training loss: 4.500626087188721
Validation loss: 4.240234712759654

Epoch: 5| Step: 11
Training loss: 3.278560161590576
Validation loss: 4.234684745470683

Epoch: 13| Step: 0
Training loss: 4.3464860916137695
Validation loss: 4.2288322150707245

Epoch: 5| Step: 1
Training loss: 3.397439479827881
Validation loss: 4.223352054754893

Epoch: 5| Step: 2
Training loss: 4.8289666175842285
Validation loss: 4.218438069025676

Epoch: 5| Step: 3
Training loss: 4.526629447937012
Validation loss: 4.212949216365814

Epoch: 5| Step: 4
Training loss: 4.399285793304443
Validation loss: 4.207023521264394

Epoch: 5| Step: 5
Training loss: 5.19399881362915
Validation loss: 4.201554576555888

Epoch: 5| Step: 6
Training loss: 4.882266521453857
Validation loss: 4.195964912573497

Epoch: 5| Step: 7
Training loss: 4.7332563400268555
Validation loss: 4.190610686937968

Epoch: 5| Step: 8
Training loss: 3.824927568435669
Validation loss: 4.185671577850978

Epoch: 5| Step: 9
Training loss: 3.7471981048583984
Validation loss: 4.180237531661987

Epoch: 5| Step: 10
Training loss: 4.065811634063721
Validation loss: 4.173904647429784

Epoch: 5| Step: 11
Training loss: 3.017613649368286
Validation loss: 4.168846040964127

Epoch: 14| Step: 0
Training loss: 4.717637062072754
Validation loss: 4.163802872101466

Epoch: 5| Step: 1
Training loss: 4.372997283935547
Validation loss: 4.159171273310979

Epoch: 5| Step: 2
Training loss: 3.3988144397735596
Validation loss: 4.153978953758876

Epoch: 5| Step: 3
Training loss: 4.266307830810547
Validation loss: 4.148913522561391

Epoch: 5| Step: 4
Training loss: 4.123734474182129
Validation loss: 4.143334448337555

Epoch: 5| Step: 5
Training loss: 4.246672630310059
Validation loss: 4.137055337429047

Epoch: 5| Step: 6
Training loss: 4.3894429206848145
Validation loss: 4.1319751143455505

Epoch: 5| Step: 7
Training loss: 3.6806557178497314
Validation loss: 4.1264416972796125

Epoch: 5| Step: 8
Training loss: 4.366776943206787
Validation loss: 4.122119893630345

Epoch: 5| Step: 9
Training loss: 4.268532752990723
Validation loss: 4.116949260234833

Epoch: 5| Step: 10
Training loss: 5.25652551651001
Validation loss: 4.111632724603017

Epoch: 5| Step: 11
Training loss: 4.092878818511963
Validation loss: 4.106090774138768

Epoch: 15| Step: 0
Training loss: 4.644350051879883
Validation loss: 4.100653350353241

Epoch: 5| Step: 1
Training loss: 3.6191723346710205
Validation loss: 4.096409936745961

Epoch: 5| Step: 2
Training loss: 4.257932662963867
Validation loss: 4.091542879740397

Epoch: 5| Step: 3
Training loss: 4.592597007751465
Validation loss: 4.086876501639684

Epoch: 5| Step: 4
Training loss: 3.5129082202911377
Validation loss: 4.080796241760254

Epoch: 5| Step: 5
Training loss: 2.84580659866333
Validation loss: 4.075389365355174

Epoch: 5| Step: 6
Training loss: 4.75410795211792
Validation loss: 4.070724467436473

Epoch: 5| Step: 7
Training loss: 4.6308770179748535
Validation loss: 4.0660921931266785

Epoch: 5| Step: 8
Training loss: 4.403120994567871
Validation loss: 4.0609487891197205

Epoch: 5| Step: 9
Training loss: 4.574591636657715
Validation loss: 4.055968741575877

Epoch: 5| Step: 10
Training loss: 5.038176536560059
Validation loss: 4.051214883724849

Epoch: 5| Step: 11
Training loss: 1.8336923122406006
Validation loss: 4.0464707513650255

Epoch: 16| Step: 0
Training loss: 4.664664268493652
Validation loss: 4.042070825894673

Epoch: 5| Step: 1
Training loss: 3.522850751876831
Validation loss: 4.036935935417811

Epoch: 5| Step: 2
Training loss: 4.10489559173584
Validation loss: 4.032886068026225

Epoch: 5| Step: 3
Training loss: 3.7128310203552246
Validation loss: 4.027663121620814

Epoch: 5| Step: 4
Training loss: 4.365870475769043
Validation loss: 4.023567954699199

Epoch: 5| Step: 5
Training loss: 4.4503493309021
Validation loss: 4.01898592710495

Epoch: 5| Step: 6
Training loss: 4.675473213195801
Validation loss: 4.0133937895298

Epoch: 5| Step: 7
Training loss: 3.331930160522461
Validation loss: 4.0087504386901855

Epoch: 5| Step: 8
Training loss: 4.818715572357178
Validation loss: 4.00392101208369

Epoch: 5| Step: 9
Training loss: 4.7215118408203125
Validation loss: 4.000065982341766

Epoch: 5| Step: 10
Training loss: 3.183708667755127
Validation loss: 3.9950549403826394

Epoch: 5| Step: 11
Training loss: 5.403189659118652
Validation loss: 3.9905529220898948

Epoch: 17| Step: 0
Training loss: 5.052407741546631
Validation loss: 3.9855193893114724

Epoch: 5| Step: 1
Training loss: 3.6703460216522217
Validation loss: 3.980590303738912

Epoch: 5| Step: 2
Training loss: 3.8194644451141357
Validation loss: 3.975736141204834

Epoch: 5| Step: 3
Training loss: 3.7148120403289795
Validation loss: 3.9709199368953705

Epoch: 5| Step: 4
Training loss: 4.7795329093933105
Validation loss: 3.9662206570307412

Epoch: 5| Step: 5
Training loss: 3.9345755577087402
Validation loss: 3.9619149367014566

Epoch: 5| Step: 6
Training loss: 3.327165126800537
Validation loss: 3.9565733075141907

Epoch: 5| Step: 7
Training loss: 4.136662483215332
Validation loss: 3.951655646165212

Epoch: 5| Step: 8
Training loss: 4.557079315185547
Validation loss: 3.9472761948903403

Epoch: 5| Step: 9
Training loss: 4.579184532165527
Validation loss: 3.942796458800634

Epoch: 5| Step: 10
Training loss: 3.881474733352661
Validation loss: 3.9376140236854553

Epoch: 5| Step: 11
Training loss: 2.8144145011901855
Validation loss: 3.932072957356771

Epoch: 18| Step: 0
Training loss: 3.853012800216675
Validation loss: 3.928293138742447

Epoch: 5| Step: 1
Training loss: 3.550353527069092
Validation loss: 3.9243055284023285

Epoch: 5| Step: 2
Training loss: 4.470125675201416
Validation loss: 3.9201924204826355

Epoch: 5| Step: 3
Training loss: 4.093022346496582
Validation loss: 3.914912313222885

Epoch: 5| Step: 4
Training loss: 3.912091016769409
Validation loss: 3.9099702338377633

Epoch: 5| Step: 5
Training loss: 4.821082592010498
Validation loss: 3.9057716925938926

Epoch: 5| Step: 6
Training loss: 4.007984638214111
Validation loss: 3.9008260567982993

Epoch: 5| Step: 7
Training loss: 4.529829978942871
Validation loss: 3.8960182666778564

Epoch: 5| Step: 8
Training loss: 4.048293113708496
Validation loss: 3.8912572662035623

Epoch: 5| Step: 9
Training loss: 3.612415313720703
Validation loss: 3.886237323284149

Epoch: 5| Step: 10
Training loss: 4.225152969360352
Validation loss: 3.8823253512382507

Epoch: 5| Step: 11
Training loss: 1.3972824811935425
Validation loss: 3.8769538203875222

Epoch: 19| Step: 0
Training loss: 4.109442710876465
Validation loss: 3.873003661632538

Epoch: 5| Step: 1
Training loss: 4.111977577209473
Validation loss: 3.86895560224851

Epoch: 5| Step: 2
Training loss: 4.254490852355957
Validation loss: 3.8649958968162537

Epoch: 5| Step: 3
Training loss: 4.822348117828369
Validation loss: 3.8607121407985687

Epoch: 5| Step: 4
Training loss: 3.778174877166748
Validation loss: 3.855556547641754

Epoch: 5| Step: 5
Training loss: 5.330679893493652
Validation loss: 3.850448568662008

Epoch: 5| Step: 6
Training loss: 2.6261866092681885
Validation loss: 3.8449053267637887

Epoch: 5| Step: 7
Training loss: 3.8045735359191895
Validation loss: 3.8399164577325187

Epoch: 5| Step: 8
Training loss: 3.711022138595581
Validation loss: 3.8354432582855225

Epoch: 5| Step: 9
Training loss: 3.5756688117980957
Validation loss: 3.8302383720874786

Epoch: 5| Step: 10
Training loss: 3.99646258354187
Validation loss: 3.824807494878769

Epoch: 5| Step: 11
Training loss: 3.5304617881774902
Validation loss: 3.820087730884552

Epoch: 20| Step: 0
Training loss: 3.2328522205352783
Validation loss: 3.816155791282654

Epoch: 5| Step: 1
Training loss: 3.164890766143799
Validation loss: 3.813812514146169

Epoch: 5| Step: 2
Training loss: 4.654679775238037
Validation loss: 3.8071143527825675

Epoch: 5| Step: 3
Training loss: 4.091160774230957
Validation loss: 3.802460789680481

Epoch: 5| Step: 4
Training loss: 4.0216875076293945
Validation loss: 3.797088881333669

Epoch: 5| Step: 5
Training loss: 4.381707191467285
Validation loss: 3.7934237023194632

Epoch: 5| Step: 6
Training loss: 3.6393496990203857
Validation loss: 3.7878975868225098

Epoch: 5| Step: 7
Training loss: 4.288731098175049
Validation loss: 3.783310294151306

Epoch: 5| Step: 8
Training loss: 3.761350631713867
Validation loss: 3.7779698272546134

Epoch: 5| Step: 9
Training loss: 3.895808458328247
Validation loss: 3.7734367847442627

Epoch: 5| Step: 10
Training loss: 4.524473667144775
Validation loss: 3.767985681692759

Epoch: 5| Step: 11
Training loss: 2.779170513153076
Validation loss: 3.763738691806793

Epoch: 21| Step: 0
Training loss: 3.8917031288146973
Validation loss: 3.760159800450007

Epoch: 5| Step: 1
Training loss: 3.8592324256896973
Validation loss: 3.7551573514938354

Epoch: 5| Step: 2
Training loss: 3.935960054397583
Validation loss: 3.749584913253784

Epoch: 5| Step: 3
Training loss: 4.534581184387207
Validation loss: 3.746410051981608

Epoch: 5| Step: 4
Training loss: 3.435344696044922
Validation loss: 3.7418835759162903

Epoch: 5| Step: 5
Training loss: 3.8333332538604736
Validation loss: 3.73738956451416

Epoch: 5| Step: 6
Training loss: 4.366416931152344
Validation loss: 3.7332725723584494

Epoch: 5| Step: 7
Training loss: 4.483859062194824
Validation loss: 3.7274820804595947

Epoch: 5| Step: 8
Training loss: 2.806016206741333
Validation loss: 3.7227242092291513

Epoch: 5| Step: 9
Training loss: 4.235055446624756
Validation loss: 3.717732230822245

Epoch: 5| Step: 10
Training loss: 3.350836992263794
Validation loss: 3.712594827016195

Epoch: 5| Step: 11
Training loss: 4.526134967803955
Validation loss: 3.709327300389608

Epoch: 22| Step: 0
Training loss: 3.6213219165802
Validation loss: 3.7053100764751434

Epoch: 5| Step: 1
Training loss: 4.059149742126465
Validation loss: 3.7024544874827066

Epoch: 5| Step: 2
Training loss: 3.953953504562378
Validation loss: 3.6959683895111084

Epoch: 5| Step: 3
Training loss: 3.6995766162872314
Validation loss: 3.6905874212582908

Epoch: 5| Step: 4
Training loss: 4.486393451690674
Validation loss: 3.6866672535737357

Epoch: 5| Step: 5
Training loss: 3.8897387981414795
Validation loss: 3.6827619473139444

Epoch: 5| Step: 6
Training loss: 2.8473401069641113
Validation loss: 3.6786268452803292

Epoch: 5| Step: 7
Training loss: 3.4901680946350098
Validation loss: 3.674315025409063

Epoch: 5| Step: 8
Training loss: 3.438605785369873
Validation loss: 3.669993758201599

Epoch: 5| Step: 9
Training loss: 3.72497296333313
Validation loss: 3.664539029200872

Epoch: 5| Step: 10
Training loss: 4.714468002319336
Validation loss: 3.6596832970778146

Epoch: 5| Step: 11
Training loss: 5.635842800140381
Validation loss: 3.655400733153025

Epoch: 23| Step: 0
Training loss: 3.7523601055145264
Validation loss: 3.650913049777349

Epoch: 5| Step: 1
Training loss: 3.9771676063537598
Validation loss: 3.648044914007187

Epoch: 5| Step: 2
Training loss: 3.1322944164276123
Validation loss: 3.6424724658330283

Epoch: 5| Step: 3
Training loss: 4.089038848876953
Validation loss: 3.6375565926233926

Epoch: 5| Step: 4
Training loss: 4.24184513092041
Validation loss: 3.6322056651115417

Epoch: 5| Step: 5
Training loss: 3.506918430328369
Validation loss: 3.6284978687763214

Epoch: 5| Step: 6
Training loss: 3.1854500770568848
Validation loss: 3.6238775054613748

Epoch: 5| Step: 7
Training loss: 4.302038192749023
Validation loss: 3.6198298931121826

Epoch: 5| Step: 8
Training loss: 3.936131238937378
Validation loss: 3.6147254010041556

Epoch: 5| Step: 9
Training loss: 3.6946372985839844
Validation loss: 3.6095361709594727

Epoch: 5| Step: 10
Training loss: 3.6844661235809326
Validation loss: 3.6048647463321686

Epoch: 5| Step: 11
Training loss: 4.746342182159424
Validation loss: 3.5996713042259216

Epoch: 24| Step: 0
Training loss: 3.4470267295837402
Validation loss: 3.594977597395579

Epoch: 5| Step: 1
Training loss: 4.169672012329102
Validation loss: 3.5901942352453866

Epoch: 5| Step: 2
Training loss: 3.9456610679626465
Validation loss: 3.5858521858851113

Epoch: 5| Step: 3
Training loss: 4.485170841217041
Validation loss: 3.5817065139611564

Epoch: 5| Step: 4
Training loss: 3.907858371734619
Validation loss: 3.5767107705275216

Epoch: 5| Step: 5
Training loss: 3.496711254119873
Validation loss: 3.5704601307710013

Epoch: 5| Step: 6
Training loss: 3.0745484828948975
Validation loss: 3.5654969910780587

Epoch: 5| Step: 7
Training loss: 3.6442184448242188
Validation loss: 3.560124566157659

Epoch: 5| Step: 8
Training loss: 3.488524913787842
Validation loss: 3.5568949977556863

Epoch: 5| Step: 9
Training loss: 3.5721306800842285
Validation loss: 3.5524805784225464

Epoch: 5| Step: 10
Training loss: 3.777630567550659
Validation loss: 3.5475932459036508

Epoch: 5| Step: 11
Training loss: 4.1942853927612305
Validation loss: 3.5427380800247192

Epoch: 25| Step: 0
Training loss: 3.270456314086914
Validation loss: 3.5371491511662803

Epoch: 5| Step: 1
Training loss: 3.380465030670166
Validation loss: 3.532361537218094

Epoch: 5| Step: 2
Training loss: 3.0715491771698
Validation loss: 3.5282680491606393

Epoch: 5| Step: 3
Training loss: 4.296563625335693
Validation loss: 3.523827830950419

Epoch: 5| Step: 4
Training loss: 3.114454746246338
Validation loss: 3.5189061363538108

Epoch: 5| Step: 5
Training loss: 5.093465328216553
Validation loss: 3.514374703168869

Epoch: 5| Step: 6
Training loss: 3.546029567718506
Validation loss: 3.5095558861891427

Epoch: 5| Step: 7
Training loss: 4.167000770568848
Validation loss: 3.505479554335276

Epoch: 5| Step: 8
Training loss: 3.8887641429901123
Validation loss: 3.499990999698639

Epoch: 5| Step: 9
Training loss: 3.2616209983825684
Validation loss: 3.4956749379634857

Epoch: 5| Step: 10
Training loss: 3.29661226272583
Validation loss: 3.4909425576527915

Epoch: 5| Step: 11
Training loss: 4.076216220855713
Validation loss: 3.4866805374622345

Epoch: 26| Step: 0
Training loss: 4.08389949798584
Validation loss: 3.481828192869822

Epoch: 5| Step: 1
Training loss: 4.222415924072266
Validation loss: 3.4770861069361367

Epoch: 5| Step: 2
Training loss: 3.1461169719696045
Validation loss: 3.4732229014237723

Epoch: 5| Step: 3
Training loss: 5.026305198669434
Validation loss: 3.4678399761517844

Epoch: 5| Step: 4
Training loss: 3.554415464401245
Validation loss: 3.463674376408259

Epoch: 5| Step: 5
Training loss: 3.7947304248809814
Validation loss: 3.458671122789383

Epoch: 5| Step: 6
Training loss: 3.9884438514709473
Validation loss: 3.4538780550161996

Epoch: 5| Step: 7
Training loss: 3.526303768157959
Validation loss: 3.4485334058602652

Epoch: 5| Step: 8
Training loss: 3.077357769012451
Validation loss: 3.4442134896914163

Epoch: 5| Step: 9
Training loss: 2.9075968265533447
Validation loss: 3.439441959063212

Epoch: 5| Step: 10
Training loss: 2.3505239486694336
Validation loss: 3.4347363809744516

Epoch: 5| Step: 11
Training loss: 4.614778518676758
Validation loss: 3.429269770781199

Epoch: 27| Step: 0
Training loss: 4.091664791107178
Validation loss: 3.4258322219053903

Epoch: 5| Step: 1
Training loss: 3.7743873596191406
Validation loss: 3.4216872652371726

Epoch: 5| Step: 2
Training loss: 3.650097608566284
Validation loss: 3.417153666416804

Epoch: 5| Step: 3
Training loss: 3.6133720874786377
Validation loss: 3.413359393676122

Epoch: 5| Step: 4
Training loss: 3.7808990478515625
Validation loss: 3.4080706437428794

Epoch: 5| Step: 5
Training loss: 3.265150785446167
Validation loss: 3.4040763775507608

Epoch: 5| Step: 6
Training loss: 4.148813247680664
Validation loss: 3.3998657166957855

Epoch: 5| Step: 7
Training loss: 3.679964542388916
Validation loss: 3.3954304854075112

Epoch: 5| Step: 8
Training loss: 2.403550624847412
Validation loss: 3.389599790175756

Epoch: 5| Step: 9
Training loss: 3.0012407302856445
Validation loss: 3.3855618437131247

Epoch: 5| Step: 10
Training loss: 4.144369602203369
Validation loss: 3.381728410720825

Epoch: 5| Step: 11
Training loss: 2.28425931930542
Validation loss: 3.377835472424825

Epoch: 28| Step: 0
Training loss: 4.358412742614746
Validation loss: 3.373587022225062

Epoch: 5| Step: 1
Training loss: 3.325732707977295
Validation loss: 3.3689589301745095

Epoch: 5| Step: 2
Training loss: 4.083781719207764
Validation loss: 3.364420394102732

Epoch: 5| Step: 3
Training loss: 3.925102949142456
Validation loss: 3.360025535027186

Epoch: 5| Step: 4
Training loss: 3.459592342376709
Validation loss: 3.3558340668678284

Epoch: 5| Step: 5
Training loss: 3.2986252307891846
Validation loss: 3.351017504930496

Epoch: 5| Step: 6
Training loss: 2.869019031524658
Validation loss: 3.3469812075297036

Epoch: 5| Step: 7
Training loss: 2.6880581378936768
Validation loss: 3.342345933119456

Epoch: 5| Step: 8
Training loss: 3.982581377029419
Validation loss: 3.33786474665006

Epoch: 5| Step: 9
Training loss: 3.528087615966797
Validation loss: 3.3334213296572366

Epoch: 5| Step: 10
Training loss: 3.457796096801758
Validation loss: 3.329690863688787

Epoch: 5| Step: 11
Training loss: 2.438375949859619
Validation loss: 3.3249128659566245

Epoch: 29| Step: 0
Training loss: 3.049107074737549
Validation loss: 3.321450412273407

Epoch: 5| Step: 1
Training loss: 3.2707080841064453
Validation loss: 3.3167379399140677

Epoch: 5| Step: 2
Training loss: 2.6372933387756348
Validation loss: 3.3135261138280234

Epoch: 5| Step: 3
Training loss: 4.00970458984375
Validation loss: 3.30944287776947

Epoch: 5| Step: 4
Training loss: 2.840869903564453
Validation loss: 3.3059193988641105

Epoch: 5| Step: 5
Training loss: 3.951742649078369
Validation loss: 3.3041231830914817

Epoch: 5| Step: 6
Training loss: 3.5159385204315186
Validation loss: 3.3020915488402047

Epoch: 5| Step: 7
Training loss: 3.3977432250976562
Validation loss: 3.2934895157814026

Epoch: 5| Step: 8
Training loss: 3.9856276512145996
Validation loss: 3.2887177566687265

Epoch: 5| Step: 9
Training loss: 3.9831790924072266
Validation loss: 3.2847439547379813

Epoch: 5| Step: 10
Training loss: 3.520599365234375
Validation loss: 3.281274269024531

Epoch: 5| Step: 11
Training loss: 3.8122828006744385
Validation loss: 3.2776554226875305

Epoch: 30| Step: 0
Training loss: 4.034697532653809
Validation loss: 3.2741678853829703

Epoch: 5| Step: 1
Training loss: 3.5934128761291504
Validation loss: 3.2697405417760215

Epoch: 5| Step: 2
Training loss: 3.1195755004882812
Validation loss: 3.2648158272107444

Epoch: 5| Step: 3
Training loss: 3.730846881866455
Validation loss: 3.2598120172818503

Epoch: 5| Step: 4
Training loss: 3.5908660888671875
Validation loss: 3.25541153550148

Epoch: 5| Step: 5
Training loss: 3.355746030807495
Validation loss: 3.2508316040039062

Epoch: 5| Step: 6
Training loss: 3.7846627235412598
Validation loss: 3.2468875646591187

Epoch: 5| Step: 7
Training loss: 3.2573745250701904
Validation loss: 3.242664376894633

Epoch: 5| Step: 8
Training loss: 2.8566620349884033
Validation loss: 3.2385983963807425

Epoch: 5| Step: 9
Training loss: 3.7963356971740723
Validation loss: 3.234558343887329

Epoch: 5| Step: 10
Training loss: 2.750849962234497
Validation loss: 3.230355511109034

Epoch: 5| Step: 11
Training loss: 2.7361271381378174
Validation loss: 3.226858248313268

Epoch: 31| Step: 0
Training loss: 3.7086493968963623
Validation loss: 3.2224720418453217

Epoch: 5| Step: 1
Training loss: 4.101346015930176
Validation loss: 3.2178679605325065

Epoch: 5| Step: 2
Training loss: 3.6731269359588623
Validation loss: 3.2138430972894034

Epoch: 5| Step: 3
Training loss: 3.1130363941192627
Validation loss: 3.2094352742036185

Epoch: 5| Step: 4
Training loss: 3.607586622238159
Validation loss: 3.205074985822042

Epoch: 5| Step: 5
Training loss: 2.2545275688171387
Validation loss: 3.200543095668157

Epoch: 5| Step: 6
Training loss: 2.9315333366394043
Validation loss: 3.196334332227707

Epoch: 5| Step: 7
Training loss: 2.8465564250946045
Validation loss: 3.192260513703028

Epoch: 5| Step: 8
Training loss: 3.546771287918091
Validation loss: 3.188486953576406

Epoch: 5| Step: 9
Training loss: 2.643756866455078
Validation loss: 3.184594690799713

Epoch: 5| Step: 10
Training loss: 4.287851810455322
Validation loss: 3.180136412382126

Epoch: 5| Step: 11
Training loss: 5.8461151123046875
Validation loss: 3.1764654417832694

Epoch: 32| Step: 0
Training loss: 3.407727003097534
Validation loss: 3.171585738658905

Epoch: 5| Step: 1
Training loss: 3.3695785999298096
Validation loss: 3.1671368877092996

Epoch: 5| Step: 2
Training loss: 3.666750431060791
Validation loss: 3.162944664557775

Epoch: 5| Step: 3
Training loss: 3.1441524028778076
Validation loss: 3.158354163169861

Epoch: 5| Step: 4
Training loss: 3.7589774131774902
Validation loss: 3.15429151058197

Epoch: 5| Step: 5
Training loss: 4.180942058563232
Validation loss: 3.1499325136343637

Epoch: 5| Step: 6
Training loss: 3.507956027984619
Validation loss: 3.145643482605616

Epoch: 5| Step: 7
Training loss: 3.084430456161499
Validation loss: 3.1418720384438834

Epoch: 5| Step: 8
Training loss: 3.450469493865967
Validation loss: 3.1374685068925223

Epoch: 5| Step: 9
Training loss: 3.3526787757873535
Validation loss: 3.133776923020681

Epoch: 5| Step: 10
Training loss: 1.7497990131378174
Validation loss: 3.129514773686727

Epoch: 5| Step: 11
Training loss: 3.5350193977355957
Validation loss: 3.1254053910573325

Epoch: 33| Step: 0
Training loss: 3.650669574737549
Validation loss: 3.121363123257955

Epoch: 5| Step: 1
Training loss: 3.2707366943359375
Validation loss: 3.117211252450943

Epoch: 5| Step: 2
Training loss: 2.892364501953125
Validation loss: 3.1129619777202606

Epoch: 5| Step: 3
Training loss: 3.223503589630127
Validation loss: 3.1085082292556763

Epoch: 5| Step: 4
Training loss: 3.4756457805633545
Validation loss: 3.1040390133857727

Epoch: 5| Step: 5
Training loss: 3.064605236053467
Validation loss: 3.100321372350057

Epoch: 5| Step: 6
Training loss: 3.3714852333068848
Validation loss: 3.0971212883790336

Epoch: 5| Step: 7
Training loss: 3.2298038005828857
Validation loss: 3.0936925609906516

Epoch: 5| Step: 8
Training loss: 3.5164475440979004
Validation loss: 3.089250256617864

Epoch: 5| Step: 9
Training loss: 3.343672513961792
Validation loss: 3.086047887802124

Epoch: 5| Step: 10
Training loss: 3.1036906242370605
Validation loss: 3.082540343205134

Epoch: 5| Step: 11
Training loss: 3.5910134315490723
Validation loss: 3.078959807753563

Epoch: 34| Step: 0
Training loss: 4.229184150695801
Validation loss: 3.0753110150496163

Epoch: 5| Step: 1
Training loss: 3.9667389392852783
Validation loss: 3.0714811583360038

Epoch: 5| Step: 2
Training loss: 3.2644150257110596
Validation loss: 3.0675989290078483

Epoch: 5| Step: 3
Training loss: 4.131923198699951
Validation loss: 3.06367818514506

Epoch: 5| Step: 4
Training loss: 2.769394636154175
Validation loss: 3.0596910417079926

Epoch: 5| Step: 5
Training loss: 2.8237640857696533
Validation loss: 3.0558068454265594

Epoch: 5| Step: 6
Training loss: 2.8681366443634033
Validation loss: 3.0518009066581726

Epoch: 5| Step: 7
Training loss: 2.842690944671631
Validation loss: 3.048897306124369

Epoch: 5| Step: 8
Training loss: 3.4948418140411377
Validation loss: 3.044974754254023

Epoch: 5| Step: 9
Training loss: 1.959975004196167
Validation loss: 3.041466395060221

Epoch: 5| Step: 10
Training loss: 3.2980778217315674
Validation loss: 3.03831913570563

Epoch: 5| Step: 11
Training loss: 3.6735482215881348
Validation loss: 3.0346192121505737

Epoch: 35| Step: 0
Training loss: 3.02518892288208
Validation loss: 3.0315584242343903

Epoch: 5| Step: 1
Training loss: 3.431863784790039
Validation loss: 3.0288860698541007

Epoch: 5| Step: 2
Training loss: 3.549175262451172
Validation loss: 3.0268964171409607

Epoch: 5| Step: 3
Training loss: 3.3809783458709717
Validation loss: 3.0207947889963784

Epoch: 5| Step: 4
Training loss: 3.0504164695739746
Validation loss: 3.018238991498947

Epoch: 5| Step: 5
Training loss: 2.8993022441864014
Validation loss: 3.0147812267144523

Epoch: 5| Step: 6
Training loss: 3.0802178382873535
Validation loss: 3.0122556686401367

Epoch: 5| Step: 7
Training loss: 3.1363956928253174
Validation loss: 3.009405722220739

Epoch: 5| Step: 8
Training loss: 2.4347379207611084
Validation loss: 3.0065852801005044

Epoch: 5| Step: 9
Training loss: 3.383812427520752
Validation loss: 3.003115634123484

Epoch: 5| Step: 10
Training loss: 4.182797431945801
Validation loss: 2.999927739302317

Epoch: 5| Step: 11
Training loss: 1.9128082990646362
Validation loss: 2.9960784316062927

Epoch: 36| Step: 0
Training loss: 3.1842308044433594
Validation loss: 2.9929787119229636

Epoch: 5| Step: 1
Training loss: 3.727492094039917
Validation loss: 2.990112821261088

Epoch: 5| Step: 2
Training loss: 3.4860424995422363
Validation loss: 2.986716777086258

Epoch: 5| Step: 3
Training loss: 2.9042611122131348
Validation loss: 2.983185132344564

Epoch: 5| Step: 4
Training loss: 2.9456939697265625
Validation loss: 2.9806795517603555

Epoch: 5| Step: 5
Training loss: 3.4958300590515137
Validation loss: 2.977509697278341

Epoch: 5| Step: 6
Training loss: 3.0434865951538086
Validation loss: 2.9745007356007895

Epoch: 5| Step: 7
Training loss: 3.633898973464966
Validation loss: 2.971113622188568

Epoch: 5| Step: 8
Training loss: 2.2354774475097656
Validation loss: 2.9682452579339347

Epoch: 5| Step: 9
Training loss: 3.0196316242218018
Validation loss: 2.9655747512976327

Epoch: 5| Step: 10
Training loss: 3.436673641204834
Validation loss: 2.9624904493490853

Epoch: 5| Step: 11
Training loss: 2.2096335887908936
Validation loss: 2.959237297375997

Epoch: 37| Step: 0
Training loss: 2.9412574768066406
Validation loss: 2.9559626082579293

Epoch: 5| Step: 1
Training loss: 3.0915701389312744
Validation loss: 2.9551517268021903

Epoch: 5| Step: 2
Training loss: 3.3617911338806152
Validation loss: 2.951125423113505

Epoch: 5| Step: 3
Training loss: 3.1469669342041016
Validation loss: 2.9485216538111367

Epoch: 5| Step: 4
Training loss: 2.933438301086426
Validation loss: 2.9450781544049582

Epoch: 5| Step: 5
Training loss: 3.786734104156494
Validation loss: 2.9420578380425773

Epoch: 5| Step: 6
Training loss: 3.2139739990234375
Validation loss: 2.938570419947306

Epoch: 5| Step: 7
Training loss: 3.6489429473876953
Validation loss: 2.935297707716624

Epoch: 5| Step: 8
Training loss: 2.9275450706481934
Validation loss: 2.93162668744723

Epoch: 5| Step: 9
Training loss: 2.9114956855773926
Validation loss: 2.928358723719915

Epoch: 5| Step: 10
Training loss: 2.9593262672424316
Validation loss: 2.9254060089588165

Epoch: 5| Step: 11
Training loss: 1.3740333318710327
Validation loss: 2.922262211640676

Epoch: 38| Step: 0
Training loss: 2.5303432941436768
Validation loss: 2.919281780719757

Epoch: 5| Step: 1
Training loss: 2.914705753326416
Validation loss: 2.9164652725060782

Epoch: 5| Step: 2
Training loss: 2.0842013359069824
Validation loss: 2.9139685531457267

Epoch: 5| Step: 3
Training loss: 3.7827467918395996
Validation loss: 2.910954395929972

Epoch: 5| Step: 4
Training loss: 3.3514328002929688
Validation loss: 2.9084561665852866

Epoch: 5| Step: 5
Training loss: 2.800037384033203
Validation loss: 2.905539095401764

Epoch: 5| Step: 6
Training loss: 3.5064148902893066
Validation loss: 2.90267151594162

Epoch: 5| Step: 7
Training loss: 3.7091641426086426
Validation loss: 2.899638762076696

Epoch: 5| Step: 8
Training loss: 3.4735100269317627
Validation loss: 2.896204878886541

Epoch: 5| Step: 9
Training loss: 2.98775053024292
Validation loss: 2.893026332060496

Epoch: 5| Step: 10
Training loss: 3.3125319480895996
Validation loss: 2.8897099991639457

Epoch: 5| Step: 11
Training loss: 1.8601295948028564
Validation loss: 2.886464754740397

Epoch: 39| Step: 0
Training loss: 3.4186363220214844
Validation loss: 2.8838101824124656

Epoch: 5| Step: 1
Training loss: 3.3991432189941406
Validation loss: 2.881120761235555

Epoch: 5| Step: 2
Training loss: 3.55322265625
Validation loss: 2.8782643179098764

Epoch: 5| Step: 3
Training loss: 2.2014212608337402
Validation loss: 2.8752552568912506

Epoch: 5| Step: 4
Training loss: 2.8917789459228516
Validation loss: 2.8725098371505737

Epoch: 5| Step: 5
Training loss: 3.472623109817505
Validation loss: 2.8696901202201843

Epoch: 5| Step: 6
Training loss: 2.41141939163208
Validation loss: 2.8660576144854226

Epoch: 5| Step: 7
Training loss: 3.5837368965148926
Validation loss: 2.8638340632120767

Epoch: 5| Step: 8
Training loss: 2.956648588180542
Validation loss: 2.8607673148314157

Epoch: 5| Step: 9
Training loss: 2.934709072113037
Validation loss: 2.8588133653004966

Epoch: 5| Step: 10
Training loss: 2.9996237754821777
Validation loss: 2.856042524178823

Epoch: 5| Step: 11
Training loss: 3.3055198192596436
Validation loss: 2.8527120451132455

Epoch: 40| Step: 0
Training loss: 3.508131504058838
Validation loss: 2.850212146838506

Epoch: 5| Step: 1
Training loss: 2.839940309524536
Validation loss: 2.8464006582895913

Epoch: 5| Step: 2
Training loss: 3.048665761947632
Validation loss: 2.8425861299037933

Epoch: 5| Step: 3
Training loss: 3.4139392375946045
Validation loss: 2.839987854162852

Epoch: 5| Step: 4
Training loss: 2.540078639984131
Validation loss: 2.8376751045385995

Epoch: 5| Step: 5
Training loss: 3.762411594390869
Validation loss: 2.834344575802485

Epoch: 5| Step: 6
Training loss: 2.7544662952423096
Validation loss: 2.831612288951874

Epoch: 5| Step: 7
Training loss: 2.1921513080596924
Validation loss: 2.82771302262942

Epoch: 5| Step: 8
Training loss: 3.2975521087646484
Validation loss: 2.8251783748467765

Epoch: 5| Step: 9
Training loss: 2.6630890369415283
Validation loss: 2.8222258587678275

Epoch: 5| Step: 10
Training loss: 3.3797271251678467
Validation loss: 2.8194023072719574

Epoch: 5| Step: 11
Training loss: 3.5971314907073975
Validation loss: 2.8166060149669647

Epoch: 41| Step: 0
Training loss: 2.648574113845825
Validation loss: 2.8158582051595054

Epoch: 5| Step: 1
Training loss: 3.6230671405792236
Validation loss: 2.822337577740351

Epoch: 5| Step: 2
Training loss: 3.1855549812316895
Validation loss: 2.8075587153434753

Epoch: 5| Step: 3
Training loss: 3.20622181892395
Validation loss: 2.8051330844561257

Epoch: 5| Step: 4
Training loss: 2.364805221557617
Validation loss: 2.8015256375074387

Epoch: 5| Step: 5
Training loss: 3.217303514480591
Validation loss: 2.7998212575912476

Epoch: 5| Step: 6
Training loss: 3.4303321838378906
Validation loss: 2.79732879002889

Epoch: 5| Step: 7
Training loss: 2.8900160789489746
Validation loss: 2.8141645888487496

Epoch: 5| Step: 8
Training loss: 2.9659218788146973
Validation loss: 2.790676643451055

Epoch: 5| Step: 9
Training loss: 2.3467955589294434
Validation loss: 2.788481225570043

Epoch: 5| Step: 10
Training loss: 3.0902252197265625
Validation loss: 2.7900960743427277

Epoch: 5| Step: 11
Training loss: 4.2009782791137695
Validation loss: 2.79609352350235

Epoch: 42| Step: 0
Training loss: 3.001443386077881
Validation loss: 2.8073595414559045

Epoch: 5| Step: 1
Training loss: 3.110210418701172
Validation loss: 2.8039345145225525

Epoch: 5| Step: 2
Training loss: 2.802757740020752
Validation loss: 2.7936488687992096

Epoch: 5| Step: 3
Training loss: 3.3554587364196777
Validation loss: 2.7871392965316772

Epoch: 5| Step: 4
Training loss: 3.5027976036071777
Validation loss: 2.779015282789866

Epoch: 5| Step: 5
Training loss: 2.9784510135650635
Validation loss: 2.7710185647010803

Epoch: 5| Step: 6
Training loss: 3.3892102241516113
Validation loss: 2.7665723164876304

Epoch: 5| Step: 7
Training loss: 2.773674488067627
Validation loss: 2.7626944283644357

Epoch: 5| Step: 8
Training loss: 2.534327268600464
Validation loss: 2.760951121648153

Epoch: 5| Step: 9
Training loss: 2.863264799118042
Validation loss: 2.759986847639084

Epoch: 5| Step: 10
Training loss: 2.6208255290985107
Validation loss: 2.757880598306656

Epoch: 5| Step: 11
Training loss: 2.7222812175750732
Validation loss: 2.7537189523379006

Epoch: 43| Step: 0
Training loss: 2.780372142791748
Validation loss: 2.74977899591128

Epoch: 5| Step: 1
Training loss: 2.893608808517456
Validation loss: 2.746358871459961

Epoch: 5| Step: 2
Training loss: 2.7608368396759033
Validation loss: 2.7457241912682853

Epoch: 5| Step: 3
Training loss: 2.743272304534912
Validation loss: 2.741503963867823

Epoch: 5| Step: 4
Training loss: 3.2143187522888184
Validation loss: 2.739204386870066

Epoch: 5| Step: 5
Training loss: 2.7780215740203857
Validation loss: 2.7369013925393424

Epoch: 5| Step: 6
Training loss: 2.603529930114746
Validation loss: 2.7338916957378387

Epoch: 5| Step: 7
Training loss: 3.347613573074341
Validation loss: 2.731943726539612

Epoch: 5| Step: 8
Training loss: 2.919424057006836
Validation loss: 2.7292188902695975

Epoch: 5| Step: 9
Training loss: 2.7742953300476074
Validation loss: 2.726518710454305

Epoch: 5| Step: 10
Training loss: 3.759828567504883
Validation loss: 2.7239978114763894

Epoch: 5| Step: 11
Training loss: 2.045884132385254
Validation loss: 2.7209075490633645

Epoch: 44| Step: 0
Training loss: 3.0105090141296387
Validation loss: 2.717877825101217

Epoch: 5| Step: 1
Training loss: 2.8566274642944336
Validation loss: 2.714892973502477

Epoch: 5| Step: 2
Training loss: 2.249340057373047
Validation loss: 2.7120754023392997

Epoch: 5| Step: 3
Training loss: 2.4115166664123535
Validation loss: 2.708960543076197

Epoch: 5| Step: 4
Training loss: 3.0754706859588623
Validation loss: 2.706451286872228

Epoch: 5| Step: 5
Training loss: 2.9877257347106934
Validation loss: 2.703257272640864

Epoch: 5| Step: 6
Training loss: 3.4100029468536377
Validation loss: 2.7006692389647164

Epoch: 5| Step: 7
Training loss: 2.9879722595214844
Validation loss: 2.697396288315455

Epoch: 5| Step: 8
Training loss: 3.3154053688049316
Validation loss: 2.693856199582418

Epoch: 5| Step: 9
Training loss: 2.3744142055511475
Validation loss: 2.6910239458084106

Epoch: 5| Step: 10
Training loss: 3.2248711585998535
Validation loss: 2.6877311070760093

Epoch: 5| Step: 11
Training loss: 3.5463709831237793
Validation loss: 2.685094118118286

Epoch: 45| Step: 0
Training loss: 3.0755271911621094
Validation loss: 2.6822332243124642

Epoch: 5| Step: 1
Training loss: 2.927107810974121
Validation loss: 2.6796757777531943

Epoch: 5| Step: 2
Training loss: 3.308000087738037
Validation loss: 2.6771963040033975

Epoch: 5| Step: 3
Training loss: 3.351635694503784
Validation loss: 2.674265444278717

Epoch: 5| Step: 4
Training loss: 2.8896751403808594
Validation loss: 2.6706476410230002

Epoch: 5| Step: 5
Training loss: 3.096388339996338
Validation loss: 2.6684609949588776

Epoch: 5| Step: 6
Training loss: 2.6732125282287598
Validation loss: 2.6653279761473336

Epoch: 5| Step: 7
Training loss: 2.3421292304992676
Validation loss: 2.662725498278936

Epoch: 5| Step: 8
Training loss: 2.8040149211883545
Validation loss: 2.659907261530558

Epoch: 5| Step: 9
Training loss: 2.7486658096313477
Validation loss: 2.6567129691441855

Epoch: 5| Step: 10
Training loss: 2.4456210136413574
Validation loss: 2.654297331968943

Epoch: 5| Step: 11
Training loss: 2.6971092224121094
Validation loss: 2.651102433602015

Epoch: 46| Step: 0
Training loss: 2.7442047595977783
Validation loss: 2.648315668106079

Epoch: 5| Step: 1
Training loss: 2.3689990043640137
Validation loss: 2.6452630857626596

Epoch: 5| Step: 2
Training loss: 2.757361650466919
Validation loss: 2.6422632733980813

Epoch: 5| Step: 3
Training loss: 2.3967559337615967
Validation loss: 2.639406830072403

Epoch: 5| Step: 4
Training loss: 3.201925754547119
Validation loss: 2.637797713279724

Epoch: 5| Step: 5
Training loss: 2.632564067840576
Validation loss: 2.634939521551132

Epoch: 5| Step: 6
Training loss: 2.9813358783721924
Validation loss: 2.6321241656939187

Epoch: 5| Step: 7
Training loss: 3.0573248863220215
Validation loss: 2.628465453783671

Epoch: 5| Step: 8
Training loss: 3.304891586303711
Validation loss: 2.6269915799299874

Epoch: 5| Step: 9
Training loss: 2.9862654209136963
Validation loss: 2.6242751330137253

Epoch: 5| Step: 10
Training loss: 2.8340821266174316
Validation loss: 2.621519764264425

Epoch: 5| Step: 11
Training loss: 2.6701574325561523
Validation loss: 2.6201117237408957

Epoch: 47| Step: 0
Training loss: 3.215939998626709
Validation loss: 2.6171742975711823

Epoch: 5| Step: 1
Training loss: 2.7714455127716064
Validation loss: 2.614862859249115

Epoch: 5| Step: 2
Training loss: 2.8599908351898193
Validation loss: 2.612339496612549

Epoch: 5| Step: 3
Training loss: 2.5181026458740234
Validation loss: 2.609517425298691

Epoch: 5| Step: 4
Training loss: 3.0816140174865723
Validation loss: 2.607047806183497

Epoch: 5| Step: 5
Training loss: 2.572223424911499
Validation loss: 2.6039454440275827

Epoch: 5| Step: 6
Training loss: 2.525550365447998
Validation loss: 2.601236641407013

Epoch: 5| Step: 7
Training loss: 2.4356722831726074
Validation loss: 2.5983112355073295

Epoch: 5| Step: 8
Training loss: 3.3758301734924316
Validation loss: 2.5952474574247995

Epoch: 5| Step: 9
Training loss: 3.2138679027557373
Validation loss: 2.592188944419225

Epoch: 5| Step: 10
Training loss: 2.6567864418029785
Validation loss: 2.589180737733841

Epoch: 5| Step: 11
Training loss: 1.0316555500030518
Validation loss: 2.58644271393617

Epoch: 48| Step: 0
Training loss: 2.7183001041412354
Validation loss: 2.58326123158137

Epoch: 5| Step: 1
Training loss: 2.5936155319213867
Validation loss: 2.5804316202799478

Epoch: 5| Step: 2
Training loss: 3.7046737670898438
Validation loss: 2.5781591683626175

Epoch: 5| Step: 3
Training loss: 2.450692653656006
Validation loss: 2.575442244609197

Epoch: 5| Step: 4
Training loss: 3.069544792175293
Validation loss: 2.572510321935018

Epoch: 5| Step: 5
Training loss: 2.0970969200134277
Validation loss: 2.570335100094477

Epoch: 5| Step: 6
Training loss: 2.7209370136260986
Validation loss: 2.5662580033143363

Epoch: 5| Step: 7
Training loss: 2.7139651775360107
Validation loss: 2.5637533366680145

Epoch: 5| Step: 8
Training loss: 3.080608367919922
Validation loss: 2.561879277229309

Epoch: 5| Step: 9
Training loss: 2.980921983718872
Validation loss: 2.558796137571335

Epoch: 5| Step: 10
Training loss: 2.540431499481201
Validation loss: 2.5561115543047586

Epoch: 5| Step: 11
Training loss: 1.8500292301177979
Validation loss: 2.555415948232015

Epoch: 49| Step: 0
Training loss: 2.2901611328125
Validation loss: 2.551830838123957

Epoch: 5| Step: 1
Training loss: 2.451918125152588
Validation loss: 2.550718824068705

Epoch: 5| Step: 2
Training loss: 3.3896644115448
Validation loss: 2.547541171312332

Epoch: 5| Step: 3
Training loss: 2.920078754425049
Validation loss: 2.5458789567152658

Epoch: 5| Step: 4
Training loss: 2.344930648803711
Validation loss: 2.5438340504964194

Epoch: 5| Step: 5
Training loss: 2.931480884552002
Validation loss: 2.5417235692342124

Epoch: 5| Step: 6
Training loss: 3.1080403327941895
Validation loss: 2.540063281853994

Epoch: 5| Step: 7
Training loss: 2.6464412212371826
Validation loss: 2.5365247627099357

Epoch: 5| Step: 8
Training loss: 2.9960219860076904
Validation loss: 2.5338174204031625

Epoch: 5| Step: 9
Training loss: 2.4875571727752686
Validation loss: 2.5312000811100006

Epoch: 5| Step: 10
Training loss: 2.392800807952881
Validation loss: 2.5289559861024222

Epoch: 5| Step: 11
Training loss: 3.598865032196045
Validation loss: 2.5268727441628775

Epoch: 50| Step: 0
Training loss: 3.129389524459839
Validation loss: 2.524495999018351

Epoch: 5| Step: 1
Training loss: 3.0213358402252197
Validation loss: 2.522407978773117

Epoch: 5| Step: 2
Training loss: 3.0707550048828125
Validation loss: 2.5193476180235543

Epoch: 5| Step: 3
Training loss: 2.349137544631958
Validation loss: 2.518080691496531

Epoch: 5| Step: 4
Training loss: 2.681009292602539
Validation loss: 2.515524377425512

Epoch: 5| Step: 5
Training loss: 2.49065899848938
Validation loss: 2.513039161761602

Epoch: 5| Step: 6
Training loss: 2.385120391845703
Validation loss: 2.5108552277088165

Epoch: 5| Step: 7
Training loss: 2.8789443969726562
Validation loss: 2.506913185119629

Epoch: 5| Step: 8
Training loss: 2.483797311782837
Validation loss: 2.505974307656288

Epoch: 5| Step: 9
Training loss: 2.623108386993408
Validation loss: 2.504025066892306

Epoch: 5| Step: 10
Training loss: 2.628041982650757
Validation loss: 2.5018143355846405

Epoch: 5| Step: 11
Training loss: 2.9508585929870605
Validation loss: 2.49768735965093

Epoch: 51| Step: 0
Training loss: 3.1148314476013184
Validation loss: 2.495258718729019

Epoch: 5| Step: 1
Training loss: 2.4766201972961426
Validation loss: 2.492402066787084

Epoch: 5| Step: 2
Training loss: 2.922670602798462
Validation loss: 2.490840127070745

Epoch: 5| Step: 3
Training loss: 2.607408046722412
Validation loss: 2.4884523848692575

Epoch: 5| Step: 4
Training loss: 2.9677164554595947
Validation loss: 2.482747366031011

Epoch: 5| Step: 5
Training loss: 2.8401405811309814
Validation loss: 2.4802784820397696

Epoch: 5| Step: 6
Training loss: 2.5293221473693848
Validation loss: 2.4781986077626548

Epoch: 5| Step: 7
Training loss: 2.262725830078125
Validation loss: 2.4760295748710632

Epoch: 5| Step: 8
Training loss: 2.078927516937256
Validation loss: 2.4735542883475623

Epoch: 5| Step: 9
Training loss: 3.1046054363250732
Validation loss: 2.471273422241211

Epoch: 5| Step: 10
Training loss: 2.4878573417663574
Validation loss: 2.4665408531824746

Epoch: 5| Step: 11
Training loss: 2.8908448219299316
Validation loss: 2.4661649664243064

Epoch: 52| Step: 0
Training loss: 2.6419482231140137
Validation loss: 2.461459865172704

Epoch: 5| Step: 1
Training loss: 2.540194034576416
Validation loss: 2.460506096482277

Epoch: 5| Step: 2
Training loss: 2.8845722675323486
Validation loss: 2.4572459061940513

Epoch: 5| Step: 3
Training loss: 2.960171937942505
Validation loss: 2.453991115093231

Epoch: 5| Step: 4
Training loss: 2.4779155254364014
Validation loss: 2.450400878985723

Epoch: 5| Step: 5
Training loss: 2.7006804943084717
Validation loss: 2.4467157125473022

Epoch: 5| Step: 6
Training loss: 2.5625720024108887
Validation loss: 2.4444454312324524

Epoch: 5| Step: 7
Training loss: 2.2172203063964844
Validation loss: 2.4435582160949707

Epoch: 5| Step: 8
Training loss: 2.7835073471069336
Validation loss: 2.438124358654022

Epoch: 5| Step: 9
Training loss: 2.6742916107177734
Validation loss: 2.4361991385618844

Epoch: 5| Step: 10
Training loss: 2.5181632041931152
Validation loss: 2.435041864713033

Epoch: 5| Step: 11
Training loss: 3.2116832733154297
Validation loss: 2.4306569397449493

Epoch: 53| Step: 0
Training loss: 2.7565433979034424
Validation loss: 2.429464896519979

Epoch: 5| Step: 1
Training loss: 2.38504958152771
Validation loss: 2.4278128296136856

Epoch: 5| Step: 2
Training loss: 2.5654194355010986
Validation loss: 2.4268223543961844

Epoch: 5| Step: 3
Training loss: 2.3722214698791504
Validation loss: 2.423911899328232

Epoch: 5| Step: 4
Training loss: 2.9266605377197266
Validation loss: 2.4228460987408957

Epoch: 5| Step: 5
Training loss: 2.4995200634002686
Validation loss: 2.419638991355896

Epoch: 5| Step: 6
Training loss: 2.8162312507629395
Validation loss: 2.41735115647316

Epoch: 5| Step: 7
Training loss: 2.1165337562561035
Validation loss: 2.414866973956426

Epoch: 5| Step: 8
Training loss: 3.009373426437378
Validation loss: 2.411798824866613

Epoch: 5| Step: 9
Training loss: 2.7682676315307617
Validation loss: 2.4121086994806924

Epoch: 5| Step: 10
Training loss: 2.7174839973449707
Validation loss: 2.4099442660808563

Epoch: 5| Step: 11
Training loss: 1.4581454992294312
Validation loss: 2.406896263360977

Epoch: 54| Step: 0
Training loss: 2.420758008956909
Validation loss: 2.4048040409882865

Epoch: 5| Step: 1
Training loss: 2.638235330581665
Validation loss: 2.4023268272479377

Epoch: 5| Step: 2
Training loss: 2.274868965148926
Validation loss: 2.4014859795570374

Epoch: 5| Step: 3
Training loss: 2.5741753578186035
Validation loss: 2.398398737112681

Epoch: 5| Step: 4
Training loss: 2.1636643409729004
Validation loss: 2.393548369407654

Epoch: 5| Step: 5
Training loss: 2.7715070247650146
Validation loss: 2.3971057136853537

Epoch: 5| Step: 6
Training loss: 2.6537978649139404
Validation loss: 2.3957603772481284

Epoch: 5| Step: 7
Training loss: 2.797043561935425
Validation loss: 2.3901268939177194

Epoch: 5| Step: 8
Training loss: 2.4637434482574463
Validation loss: 2.3895296255747476

Epoch: 5| Step: 9
Training loss: 2.9401752948760986
Validation loss: 2.3904477953910828

Epoch: 5| Step: 10
Training loss: 2.477097988128662
Validation loss: 2.38972444832325

Epoch: 5| Step: 11
Training loss: 3.6053967475891113
Validation loss: 2.3908329705397287

Epoch: 55| Step: 0
Training loss: 2.8084893226623535
Validation loss: 2.388606771826744

Epoch: 5| Step: 1
Training loss: 2.549912929534912
Validation loss: 2.384954830010732

Epoch: 5| Step: 2
Training loss: 2.4507288932800293
Validation loss: 2.3806237876415253

Epoch: 5| Step: 3
Training loss: 3.0398216247558594
Validation loss: 2.377673382560412

Epoch: 5| Step: 4
Training loss: 2.7923052310943604
Validation loss: 2.375615288813909

Epoch: 5| Step: 5
Training loss: 2.393247604370117
Validation loss: 2.3719278474648795

Epoch: 5| Step: 6
Training loss: 2.6603283882141113
Validation loss: 2.371758386492729

Epoch: 5| Step: 7
Training loss: 2.3613805770874023
Validation loss: 2.365929822127024

Epoch: 5| Step: 8
Training loss: 2.3390023708343506
Validation loss: 2.3634022076924643

Epoch: 5| Step: 9
Training loss: 2.6171298027038574
Validation loss: 2.3591702381769815

Epoch: 5| Step: 10
Training loss: 2.147251605987549
Validation loss: 2.359876334667206

Epoch: 5| Step: 11
Training loss: 2.376481533050537
Validation loss: 2.3577673534552255

Epoch: 56| Step: 0
Training loss: 2.061537742614746
Validation loss: 2.3523184408744178

Epoch: 5| Step: 1
Training loss: 2.7946531772613525
Validation loss: 2.3494344453016915

Epoch: 5| Step: 2
Training loss: 2.6825108528137207
Validation loss: 2.3471592168013253

Epoch: 5| Step: 3
Training loss: 1.8862276077270508
Validation loss: 2.345764805873235

Epoch: 5| Step: 4
Training loss: 1.844099998474121
Validation loss: 2.342987686395645

Epoch: 5| Step: 5
Training loss: 2.538940191268921
Validation loss: 2.3394299745559692

Epoch: 5| Step: 6
Training loss: 2.4454760551452637
Validation loss: 2.34003484249115

Epoch: 5| Step: 7
Training loss: 3.4614710807800293
Validation loss: 2.3345448871453605

Epoch: 5| Step: 8
Training loss: 2.6727030277252197
Validation loss: 2.33495531976223

Epoch: 5| Step: 9
Training loss: 2.8061306476593018
Validation loss: 2.3278762698173523

Epoch: 5| Step: 10
Training loss: 2.8283255100250244
Validation loss: 2.325563073158264

Epoch: 5| Step: 11
Training loss: 0.9884517192840576
Validation loss: 2.3282815416653952

Epoch: 57| Step: 0
Training loss: 2.758448362350464
Validation loss: 2.344743420680364

Epoch: 5| Step: 1
Training loss: 1.7997496128082275
Validation loss: 2.3525228003660836

Epoch: 5| Step: 2
Training loss: 2.8577704429626465
Validation loss: 2.3630761404832206

Epoch: 5| Step: 3
Training loss: 2.8433780670166016
Validation loss: 2.362365891536077

Epoch: 5| Step: 4
Training loss: 2.993177890777588
Validation loss: 2.359694783886274

Epoch: 5| Step: 5
Training loss: 2.154940128326416
Validation loss: 2.348745326201121

Epoch: 5| Step: 6
Training loss: 1.8115558624267578
Validation loss: 2.338060667117437

Epoch: 5| Step: 7
Training loss: 2.521000623703003
Validation loss: 2.3206209739049277

Epoch: 5| Step: 8
Training loss: 2.823610305786133
Validation loss: 2.3064692318439484

Epoch: 5| Step: 9
Training loss: 2.4785943031311035
Validation loss: 2.3075599670410156

Epoch: 5| Step: 10
Training loss: 2.6985814571380615
Validation loss: 2.311068202058474

Epoch: 5| Step: 11
Training loss: 2.059211015701294
Validation loss: 2.3270315527915955

Epoch: 58| Step: 0
Training loss: 2.5205841064453125
Validation loss: 2.3125120798746743

Epoch: 5| Step: 1
Training loss: 2.1961982250213623
Validation loss: 2.3099020272493362

Epoch: 5| Step: 2
Training loss: 2.991076946258545
Validation loss: 2.3061583638191223

Epoch: 5| Step: 3
Training loss: 2.1402509212493896
Validation loss: 2.3051781256993613

Epoch: 5| Step: 4
Training loss: 2.2179298400878906
Validation loss: 2.309119905034701

Epoch: 5| Step: 5
Training loss: 2.6194839477539062
Validation loss: 2.304998755455017

Epoch: 5| Step: 6
Training loss: 2.6369495391845703
Validation loss: 2.292874480287234

Epoch: 5| Step: 7
Training loss: 2.3970694541931152
Validation loss: 2.2908862133820853

Epoch: 5| Step: 8
Training loss: 2.7372825145721436
Validation loss: 2.28596826394399

Epoch: 5| Step: 9
Training loss: 2.4026083946228027
Validation loss: 2.27933706343174

Epoch: 5| Step: 10
Training loss: 2.455930233001709
Validation loss: 2.2772670090198517

Epoch: 5| Step: 11
Training loss: 1.7967326641082764
Validation loss: 2.278584082921346

Epoch: 59| Step: 0
Training loss: 2.27288556098938
Validation loss: 2.2768875112136207

Epoch: 5| Step: 1
Training loss: 2.6784565448760986
Validation loss: 2.2739800214767456

Epoch: 5| Step: 2
Training loss: 2.668915271759033
Validation loss: 2.2760605017344155

Epoch: 5| Step: 3
Training loss: 2.599607467651367
Validation loss: 2.2752006351947784

Epoch: 5| Step: 4
Training loss: 2.7658400535583496
Validation loss: 2.271809150775274

Epoch: 5| Step: 5
Training loss: 2.490689992904663
Validation loss: 2.2666101853052774

Epoch: 5| Step: 6
Training loss: 2.451258420944214
Validation loss: 2.2604624877373376

Epoch: 5| Step: 7
Training loss: 2.360598564147949
Validation loss: 2.2621241907278695

Epoch: 5| Step: 8
Training loss: 2.474238634109497
Validation loss: 2.2562409540017447

Epoch: 5| Step: 9
Training loss: 1.807428002357483
Validation loss: 2.2529617647329965

Epoch: 5| Step: 10
Training loss: 2.2264962196350098
Validation loss: 2.252659499645233

Epoch: 5| Step: 11
Training loss: 2.405388355255127
Validation loss: 2.251490126053492

Epoch: 60| Step: 0
Training loss: 2.122126340866089
Validation loss: 2.24969212214152

Epoch: 5| Step: 1
Training loss: 2.3054516315460205
Validation loss: 2.2474273343880973

Epoch: 5| Step: 2
Training loss: 2.410182476043701
Validation loss: 2.2437108854452767

Epoch: 5| Step: 3
Training loss: 1.9491450786590576
Validation loss: 2.240735466281573

Epoch: 5| Step: 4
Training loss: 2.736327886581421
Validation loss: 2.240158294637998

Epoch: 5| Step: 5
Training loss: 1.5756763219833374
Validation loss: 2.2382214417060218

Epoch: 5| Step: 6
Training loss: 2.542151927947998
Validation loss: 2.2320666909217834

Epoch: 5| Step: 7
Training loss: 2.045093059539795
Validation loss: 2.230989625056585

Epoch: 5| Step: 8
Training loss: 2.718752145767212
Validation loss: 2.228053962190946

Epoch: 5| Step: 9
Training loss: 3.1313984394073486
Validation loss: 2.2280646363894143

Epoch: 5| Step: 10
Training loss: 2.6708645820617676
Validation loss: 2.2222098211447396

Epoch: 5| Step: 11
Training loss: 3.6203277111053467
Validation loss: 2.225596790512403

Epoch: 61| Step: 0
Training loss: 1.4506415128707886
Validation loss: 2.2214980820814767

Epoch: 5| Step: 1
Training loss: 2.4848904609680176
Validation loss: 2.223469704389572

Epoch: 5| Step: 2
Training loss: 1.6142923831939697
Validation loss: 2.2201598385969796

Epoch: 5| Step: 3
Training loss: 2.153317451477051
Validation loss: 2.2160073667764664

Epoch: 5| Step: 4
Training loss: 3.073409080505371
Validation loss: 2.2151560485363007

Epoch: 5| Step: 5
Training loss: 2.5800821781158447
Validation loss: 2.2141353636980057

Epoch: 5| Step: 6
Training loss: 2.9177305698394775
Validation loss: 2.213321308294932

Epoch: 5| Step: 7
Training loss: 2.6035869121551514
Validation loss: 2.2132610976696014

Epoch: 5| Step: 8
Training loss: 2.179901599884033
Validation loss: 2.2062016328175864

Epoch: 5| Step: 9
Training loss: 2.694481372833252
Validation loss: 2.2077208856741586

Epoch: 5| Step: 10
Training loss: 2.459116220474243
Validation loss: 2.2041971683502197

Epoch: 5| Step: 11
Training loss: 2.083012342453003
Validation loss: 2.202607904871305

Epoch: 62| Step: 0
Training loss: 2.313190221786499
Validation loss: 2.2078278213739395

Epoch: 5| Step: 1
Training loss: 2.231071949005127
Validation loss: 2.202737142642339

Epoch: 5| Step: 2
Training loss: 2.207549571990967
Validation loss: 2.202075555920601

Epoch: 5| Step: 3
Training loss: 2.703705310821533
Validation loss: 2.2023963729540506

Epoch: 5| Step: 4
Training loss: 1.7769590616226196
Validation loss: 2.1991887191931405

Epoch: 5| Step: 5
Training loss: 2.194594144821167
Validation loss: 2.195679451028506

Epoch: 5| Step: 6
Training loss: 2.6478323936462402
Validation loss: 2.194815377394358

Epoch: 5| Step: 7
Training loss: 2.5145325660705566
Validation loss: 2.1950019001960754

Epoch: 5| Step: 8
Training loss: 2.469311475753784
Validation loss: 2.196174611647924

Epoch: 5| Step: 9
Training loss: 2.452033758163452
Validation loss: 2.1928926209608712

Epoch: 5| Step: 10
Training loss: 2.6032590866088867
Validation loss: 2.190347909927368

Epoch: 5| Step: 11
Training loss: 1.4466100931167603
Validation loss: 2.189671595891317

Epoch: 63| Step: 0
Training loss: 2.0200424194335938
Validation loss: 2.1869901021321616

Epoch: 5| Step: 1
Training loss: 2.5995452404022217
Validation loss: 2.184748406211535

Epoch: 5| Step: 2
Training loss: 2.432950258255005
Validation loss: 2.18368162214756

Epoch: 5| Step: 3
Training loss: 2.3050129413604736
Validation loss: 2.1903306245803833

Epoch: 5| Step: 4
Training loss: 3.040764331817627
Validation loss: 2.187305082877477

Epoch: 5| Step: 5
Training loss: 2.3208117485046387
Validation loss: 2.1873827377955117

Epoch: 5| Step: 6
Training loss: 2.4136881828308105
Validation loss: 2.1789847711722055

Epoch: 5| Step: 7
Training loss: 2.2306668758392334
Validation loss: 2.171864906946818

Epoch: 5| Step: 8
Training loss: 2.249974012374878
Validation loss: 2.176414504647255

Epoch: 5| Step: 9
Training loss: 2.303218364715576
Validation loss: 2.1678838630517325

Epoch: 5| Step: 10
Training loss: 1.5248329639434814
Validation loss: 2.1740699062744775

Epoch: 5| Step: 11
Training loss: 3.952979803085327
Validation loss: 2.171092838048935

Epoch: 64| Step: 0
Training loss: 2.835059404373169
Validation loss: 2.1745470464229584

Epoch: 5| Step: 1
Training loss: 2.2360260486602783
Validation loss: 2.1729852855205536

Epoch: 5| Step: 2
Training loss: 1.8969227075576782
Validation loss: 2.1773036966721215

Epoch: 5| Step: 3
Training loss: 2.2279694080352783
Validation loss: 2.1783955792586007

Epoch: 5| Step: 4
Training loss: 2.849996328353882
Validation loss: 2.179018020629883

Epoch: 5| Step: 5
Training loss: 1.7695165872573853
Validation loss: 2.1780268400907516

Epoch: 5| Step: 6
Training loss: 2.6987223625183105
Validation loss: 2.1765751938025155

Epoch: 5| Step: 7
Training loss: 2.7053744792938232
Validation loss: 2.1781048675378165

Epoch: 5| Step: 8
Training loss: 1.8056821823120117
Validation loss: 2.1784400145212808

Epoch: 5| Step: 9
Training loss: 2.512918472290039
Validation loss: 2.1703230142593384

Epoch: 5| Step: 10
Training loss: 2.363065242767334
Validation loss: 2.1700059672196708

Epoch: 5| Step: 11
Training loss: 1.507594347000122
Validation loss: 2.16294797261556

Epoch: 65| Step: 0
Training loss: 2.5424270629882812
Validation loss: 2.16177428762118

Epoch: 5| Step: 1
Training loss: 1.8760029077529907
Validation loss: 2.160287340482076

Epoch: 5| Step: 2
Training loss: 2.4974236488342285
Validation loss: 2.155630439519882

Epoch: 5| Step: 3
Training loss: 2.1917920112609863
Validation loss: 2.1560801963011422

Epoch: 5| Step: 4
Training loss: 2.240712881088257
Validation loss: 2.157710706194242

Epoch: 5| Step: 5
Training loss: 2.7146294116973877
Validation loss: 2.156142383813858

Epoch: 5| Step: 6
Training loss: 2.6543638706207275
Validation loss: 2.1504509647687278

Epoch: 5| Step: 7
Training loss: 1.7748695611953735
Validation loss: 2.148847371339798

Epoch: 5| Step: 8
Training loss: 2.1049070358276367
Validation loss: 2.1468897263209024

Epoch: 5| Step: 9
Training loss: 2.3343348503112793
Validation loss: 2.142912452419599

Epoch: 5| Step: 10
Training loss: 2.573086738586426
Validation loss: 2.1445125738779702

Epoch: 5| Step: 11
Training loss: 1.9731535911560059
Validation loss: 2.1419513523578644

Epoch: 66| Step: 0
Training loss: 2.642399311065674
Validation loss: 2.1534274319807687

Epoch: 5| Step: 1
Training loss: 2.7653567790985107
Validation loss: 2.156910394628843

Epoch: 5| Step: 2
Training loss: 1.8872178792953491
Validation loss: 2.157382994890213

Epoch: 5| Step: 3
Training loss: 1.877171277999878
Validation loss: 2.1486214896043143

Epoch: 5| Step: 4
Training loss: 2.139733076095581
Validation loss: 2.148461719353994

Epoch: 5| Step: 5
Training loss: 2.395064115524292
Validation loss: 2.142538865407308

Epoch: 5| Step: 6
Training loss: 2.0011253356933594
Validation loss: 2.1419874727725983

Epoch: 5| Step: 7
Training loss: 2.5104594230651855
Validation loss: 2.1301486591498056

Epoch: 5| Step: 8
Training loss: 2.452925443649292
Validation loss: 2.14243953426679

Epoch: 5| Step: 9
Training loss: 1.775215744972229
Validation loss: 2.145062173406283

Epoch: 5| Step: 10
Training loss: 2.754625082015991
Validation loss: 2.1476983428001404

Epoch: 5| Step: 11
Training loss: 3.707260847091675
Validation loss: 2.1348970582087836

Epoch: 67| Step: 0
Training loss: 3.0736019611358643
Validation loss: 2.129190062483152

Epoch: 5| Step: 1
Training loss: 2.590200185775757
Validation loss: 2.1270680874586105

Epoch: 5| Step: 2
Training loss: 1.9223651885986328
Validation loss: 2.1273592362801232

Epoch: 5| Step: 3
Training loss: 2.6649057865142822
Validation loss: 2.12369704246521

Epoch: 5| Step: 4
Training loss: 1.9774818420410156
Validation loss: 2.128543883562088

Epoch: 5| Step: 5
Training loss: 2.561763286590576
Validation loss: 2.1287005643049874

Epoch: 5| Step: 6
Training loss: 2.534247398376465
Validation loss: 2.1273643920818963

Epoch: 5| Step: 7
Training loss: 1.7662360668182373
Validation loss: 2.1279945224523544

Epoch: 5| Step: 8
Training loss: 2.122769355773926
Validation loss: 2.124738931655884

Epoch: 5| Step: 9
Training loss: 1.7410190105438232
Validation loss: 2.123092403014501

Epoch: 5| Step: 10
Training loss: 2.1530652046203613
Validation loss: 2.1220642626285553

Epoch: 5| Step: 11
Training loss: 2.8323235511779785
Validation loss: 2.1225847601890564

Epoch: 68| Step: 0
Training loss: 2.3364415168762207
Validation loss: 2.113936478892962

Epoch: 5| Step: 1
Training loss: 2.468632459640503
Validation loss: 2.110148017605146

Epoch: 5| Step: 2
Training loss: 1.8935108184814453
Validation loss: 2.1064516752958298

Epoch: 5| Step: 3
Training loss: 2.4154117107391357
Validation loss: 2.1154356449842453

Epoch: 5| Step: 4
Training loss: 2.3612301349639893
Validation loss: 2.1240952014923096

Epoch: 5| Step: 5
Training loss: 1.4825258255004883
Validation loss: 2.140140945712725

Epoch: 5| Step: 6
Training loss: 2.2649285793304443
Validation loss: 2.123101313908895

Epoch: 5| Step: 7
Training loss: 2.8466970920562744
Validation loss: 2.1083569129308066

Epoch: 5| Step: 8
Training loss: 2.70725154876709
Validation loss: 2.1067059139410653

Epoch: 5| Step: 9
Training loss: 2.1097683906555176
Validation loss: 2.111632744471232

Epoch: 5| Step: 10
Training loss: 2.4972336292266846
Validation loss: 2.1151933620373407

Epoch: 5| Step: 11
Training loss: 1.7264738082885742
Validation loss: 2.121458942691485

Epoch: 69| Step: 0
Training loss: 2.522862195968628
Validation loss: 2.1192889412244162

Epoch: 5| Step: 1
Training loss: 1.855391263961792
Validation loss: 2.1209175835053125

Epoch: 5| Step: 2
Training loss: 1.6278212070465088
Validation loss: 2.122865706682205

Epoch: 5| Step: 3
Training loss: 2.2561450004577637
Validation loss: 2.123609652121862

Epoch: 5| Step: 4
Training loss: 2.071906328201294
Validation loss: 2.125742812951406

Epoch: 5| Step: 5
Training loss: 2.8577046394348145
Validation loss: 2.1205161114533744

Epoch: 5| Step: 6
Training loss: 2.5423390865325928
Validation loss: 2.1170667111873627

Epoch: 5| Step: 7
Training loss: 2.84024715423584
Validation loss: 2.1179306407769523

Epoch: 5| Step: 8
Training loss: 2.1201117038726807
Validation loss: 2.1139664947986603

Epoch: 5| Step: 9
Training loss: 2.2140731811523438
Validation loss: 2.112904980778694

Epoch: 5| Step: 10
Training loss: 2.2789504528045654
Validation loss: 2.1102793514728546

Epoch: 5| Step: 11
Training loss: 2.578630208969116
Validation loss: 2.107658565044403

Epoch: 70| Step: 0
Training loss: 2.1994071006774902
Validation loss: 2.099829817811648

Epoch: 5| Step: 1
Training loss: 2.4524848461151123
Validation loss: 2.102798422177633

Epoch: 5| Step: 2
Training loss: 2.023297071456909
Validation loss: 2.0960422406593957

Epoch: 5| Step: 3
Training loss: 1.9321537017822266
Validation loss: 2.0984105120102563

Epoch: 5| Step: 4
Training loss: 2.353888750076294
Validation loss: 2.0955678671598434

Epoch: 5| Step: 5
Training loss: 2.376845598220825
Validation loss: 2.098928779363632

Epoch: 5| Step: 6
Training loss: 2.174076557159424
Validation loss: 2.0894520531098046

Epoch: 5| Step: 7
Training loss: 2.0258259773254395
Validation loss: 2.0924858252207437

Epoch: 5| Step: 8
Training loss: 2.3647220134735107
Validation loss: 2.087344075242678

Epoch: 5| Step: 9
Training loss: 2.3786234855651855
Validation loss: 2.0857798357804618

Epoch: 5| Step: 10
Training loss: 2.595522403717041
Validation loss: 2.086369683345159

Epoch: 5| Step: 11
Training loss: 2.7412912845611572
Validation loss: 2.0867411543925605

Epoch: 71| Step: 0
Training loss: 2.486717700958252
Validation loss: 2.0788588523864746

Epoch: 5| Step: 1
Training loss: 2.407261610031128
Validation loss: 2.0797458489735923

Epoch: 5| Step: 2
Training loss: 2.3581724166870117
Validation loss: 2.0870620906352997

Epoch: 5| Step: 3
Training loss: 1.5154650211334229
Validation loss: 2.0830835004647574

Epoch: 5| Step: 4
Training loss: 1.5369293689727783
Validation loss: 2.083505700031916

Epoch: 5| Step: 5
Training loss: 2.6257400512695312
Validation loss: 2.0815363973379135

Epoch: 5| Step: 6
Training loss: 2.772172689437866
Validation loss: 2.0878915737072625

Epoch: 5| Step: 7
Training loss: 2.4080944061279297
Validation loss: 2.0737051318089166

Epoch: 5| Step: 8
Training loss: 2.0409770011901855
Validation loss: 2.070718372861544

Epoch: 5| Step: 9
Training loss: 2.240936517715454
Validation loss: 2.0794288317362466

Epoch: 5| Step: 10
Training loss: 2.3140225410461426
Validation loss: 2.080642968416214

Epoch: 5| Step: 11
Training loss: 2.841897964477539
Validation loss: 2.0738212019205093

Epoch: 72| Step: 0
Training loss: 1.960882544517517
Validation loss: 2.069732815027237

Epoch: 5| Step: 1
Training loss: 2.552487850189209
Validation loss: 2.070810983578364

Epoch: 5| Step: 2
Training loss: 2.1841042041778564
Validation loss: 2.0782403548558555

Epoch: 5| Step: 3
Training loss: 2.0597472190856934
Validation loss: 2.085727502902349

Epoch: 5| Step: 4
Training loss: 2.3375205993652344
Validation loss: 2.0860272645950317

Epoch: 5| Step: 5
Training loss: 2.3526082038879395
Validation loss: 2.0851952532927194

Epoch: 5| Step: 6
Training loss: 2.143125295639038
Validation loss: 2.0862564047177634

Epoch: 5| Step: 7
Training loss: 2.520251512527466
Validation loss: 2.0809666166702905

Epoch: 5| Step: 8
Training loss: 2.3384313583374023
Validation loss: 2.0835992644230523

Epoch: 5| Step: 9
Training loss: 2.0167815685272217
Validation loss: 2.077426865696907

Epoch: 5| Step: 10
Training loss: 2.346604824066162
Validation loss: 2.08198319375515

Epoch: 5| Step: 11
Training loss: 2.5770926475524902
Validation loss: 2.077292114496231

Epoch: 73| Step: 0
Training loss: 2.0206334590911865
Validation loss: 2.069441497325897

Epoch: 5| Step: 1
Training loss: 2.7992658615112305
Validation loss: 2.0609532296657562

Epoch: 5| Step: 2
Training loss: 2.1047136783599854
Validation loss: 2.0567557066679

Epoch: 5| Step: 3
Training loss: 1.809739351272583
Validation loss: 2.0624801268180213

Epoch: 5| Step: 4
Training loss: 2.843472957611084
Validation loss: 2.0683468679587045

Epoch: 5| Step: 5
Training loss: 2.2205283641815186
Validation loss: 2.0659553905328116

Epoch: 5| Step: 6
Training loss: 2.429386854171753
Validation loss: 2.0700857688983283

Epoch: 5| Step: 7
Training loss: 2.184051513671875
Validation loss: 2.0676575899124146

Epoch: 5| Step: 8
Training loss: 1.9976485967636108
Validation loss: 2.0651786774396896

Epoch: 5| Step: 9
Training loss: 2.17136812210083
Validation loss: 2.0537823289632797

Epoch: 5| Step: 10
Training loss: 2.0763940811157227
Validation loss: 2.0517231474320092

Epoch: 5| Step: 11
Training loss: 2.7685470581054688
Validation loss: 2.043728773792585

Epoch: 74| Step: 0
Training loss: 2.20656156539917
Validation loss: 2.0554101864496865

Epoch: 5| Step: 1
Training loss: 2.533146381378174
Validation loss: 2.0524273961782455

Epoch: 5| Step: 2
Training loss: 2.0611133575439453
Validation loss: 2.0546136697133384

Epoch: 5| Step: 3
Training loss: 2.822244167327881
Validation loss: 2.057005137205124

Epoch: 5| Step: 4
Training loss: 1.4906524419784546
Validation loss: 2.0514327635367713

Epoch: 5| Step: 5
Training loss: 1.9196319580078125
Validation loss: 2.050388440489769

Epoch: 5| Step: 6
Training loss: 2.6231913566589355
Validation loss: 2.0519904543956122

Epoch: 5| Step: 7
Training loss: 2.064558506011963
Validation loss: 2.051605840524038

Epoch: 5| Step: 8
Training loss: 2.4920995235443115
Validation loss: 2.0524773597717285

Epoch: 5| Step: 9
Training loss: 2.085716962814331
Validation loss: 2.0470364689826965

Epoch: 5| Step: 10
Training loss: 2.3201687335968018
Validation loss: 2.0525815983613334

Epoch: 5| Step: 11
Training loss: 2.295706272125244
Validation loss: 2.0552045504252114

Epoch: 75| Step: 0
Training loss: 2.3825249671936035
Validation loss: 2.051225632429123

Epoch: 5| Step: 1
Training loss: 1.959944725036621
Validation loss: 2.04383913675944

Epoch: 5| Step: 2
Training loss: 2.7761662006378174
Validation loss: 2.047065223256747

Epoch: 5| Step: 3
Training loss: 2.0403153896331787
Validation loss: 2.0458578765392303

Epoch: 5| Step: 4
Training loss: 1.5521249771118164
Validation loss: 2.045338893930117

Epoch: 5| Step: 5
Training loss: 2.0792555809020996
Validation loss: 2.048318679134051

Epoch: 5| Step: 6
Training loss: 2.608372449874878
Validation loss: 2.049803296724955

Epoch: 5| Step: 7
Training loss: 1.7618471384048462
Validation loss: 2.0472652365763984

Epoch: 5| Step: 8
Training loss: 2.3640997409820557
Validation loss: 2.05110236008962

Epoch: 5| Step: 9
Training loss: 2.731980562210083
Validation loss: 2.053153077761332

Epoch: 5| Step: 10
Training loss: 2.328050136566162
Validation loss: 2.0603113869825997

Epoch: 5| Step: 11
Training loss: 2.4023098945617676
Validation loss: 2.0574269791444144

Epoch: 76| Step: 0
Training loss: 2.4114201068878174
Validation loss: 2.06344165901343

Epoch: 5| Step: 1
Training loss: 2.3838813304901123
Validation loss: 2.05774096151193

Epoch: 5| Step: 2
Training loss: 2.0781140327453613
Validation loss: 2.0579789827267327

Epoch: 5| Step: 3
Training loss: 2.0956239700317383
Validation loss: 2.0525016685326896

Epoch: 5| Step: 4
Training loss: 2.797281503677368
Validation loss: 2.053539276123047

Epoch: 5| Step: 5
Training loss: 2.2478716373443604
Validation loss: 2.05413651963075

Epoch: 5| Step: 6
Training loss: 1.744506597518921
Validation loss: 2.0562844028075538

Epoch: 5| Step: 7
Training loss: 2.65704345703125
Validation loss: 2.048400272925695

Epoch: 5| Step: 8
Training loss: 1.9824192523956299
Validation loss: 2.043393393357595

Epoch: 5| Step: 9
Training loss: 1.8696925640106201
Validation loss: 2.038544754187266

Epoch: 5| Step: 10
Training loss: 2.2867774963378906
Validation loss: 2.036400407552719

Epoch: 5| Step: 11
Training loss: 2.3504409790039062
Validation loss: 2.0375007639328637

Epoch: 77| Step: 0
Training loss: 2.3874926567077637
Validation loss: 2.0438260535399118

Epoch: 5| Step: 1
Training loss: 2.507274627685547
Validation loss: 2.0388124783833823

Epoch: 5| Step: 2
Training loss: 2.2552788257598877
Validation loss: 2.038024057944616

Epoch: 5| Step: 3
Training loss: 2.2157890796661377
Validation loss: 2.036583279569944

Epoch: 5| Step: 4
Training loss: 2.2982594966888428
Validation loss: 2.0420770943164825

Epoch: 5| Step: 5
Training loss: 1.8598064184188843
Validation loss: 2.0438453257083893

Epoch: 5| Step: 6
Training loss: 2.0666260719299316
Validation loss: 2.0374383131663003

Epoch: 5| Step: 7
Training loss: 2.3556320667266846
Validation loss: 2.034312774737676

Epoch: 5| Step: 8
Training loss: 2.291010856628418
Validation loss: 2.036844144264857

Epoch: 5| Step: 9
Training loss: 2.099093198776245
Validation loss: 2.0379999379316964

Epoch: 5| Step: 10
Training loss: 2.032115936279297
Validation loss: 2.039888689915339

Epoch: 5| Step: 11
Training loss: 2.6869351863861084
Validation loss: 2.040828342239062

Epoch: 78| Step: 0
Training loss: 2.1834068298339844
Validation loss: 2.0384830435117087

Epoch: 5| Step: 1
Training loss: 1.5303823947906494
Validation loss: 2.0337903598944345

Epoch: 5| Step: 2
Training loss: 2.5679433345794678
Validation loss: 2.0308442811171212

Epoch: 5| Step: 3
Training loss: 2.3527984619140625
Validation loss: 2.0375241885582605

Epoch: 5| Step: 4
Training loss: 2.306090831756592
Validation loss: 2.040375605225563

Epoch: 5| Step: 5
Training loss: 2.092160940170288
Validation loss: 2.045658975839615

Epoch: 5| Step: 6
Training loss: 2.0104265213012695
Validation loss: 2.030763159195582

Epoch: 5| Step: 7
Training loss: 2.2207815647125244
Validation loss: 2.032519906759262

Epoch: 5| Step: 8
Training loss: 2.4893767833709717
Validation loss: 2.026353264848391

Epoch: 5| Step: 9
Training loss: 2.3454203605651855
Validation loss: 2.031474123398463

Epoch: 5| Step: 10
Training loss: 2.4683334827423096
Validation loss: 2.0284442553917565

Epoch: 5| Step: 11
Training loss: 1.814363956451416
Validation loss: 2.0288243691126504

Epoch: 79| Step: 0
Training loss: 2.063290596008301
Validation loss: 2.0365357995033264

Epoch: 5| Step: 1
Training loss: 1.992283582687378
Validation loss: 2.0371119678020477

Epoch: 5| Step: 2
Training loss: 2.071964979171753
Validation loss: 2.0365257610877356

Epoch: 5| Step: 3
Training loss: 2.613623857498169
Validation loss: 2.035305524865786

Epoch: 5| Step: 4
Training loss: 2.116527557373047
Validation loss: 2.0340714752674103

Epoch: 5| Step: 5
Training loss: 1.9151054620742798
Validation loss: 2.028234541416168

Epoch: 5| Step: 6
Training loss: 2.5506701469421387
Validation loss: 2.032815436522166

Epoch: 5| Step: 7
Training loss: 1.807743787765503
Validation loss: 2.0318443228801093

Epoch: 5| Step: 8
Training loss: 2.8453710079193115
Validation loss: 2.036123255888621

Epoch: 5| Step: 9
Training loss: 1.9747005701065063
Validation loss: 2.040232852101326

Epoch: 5| Step: 10
Training loss: 2.309688091278076
Validation loss: 2.04178324341774

Epoch: 5| Step: 11
Training loss: 2.6194119453430176
Validation loss: 2.0415150225162506

Epoch: 80| Step: 0
Training loss: 1.832329511642456
Validation loss: 2.0416189779837928

Epoch: 5| Step: 1
Training loss: 2.7174978256225586
Validation loss: 2.0394555628299713

Epoch: 5| Step: 2
Training loss: 1.648176908493042
Validation loss: 2.0371398329734802

Epoch: 5| Step: 3
Training loss: 1.8698101043701172
Validation loss: 2.038731018702189

Epoch: 5| Step: 4
Training loss: 2.588733673095703
Validation loss: 2.043904567758242

Epoch: 5| Step: 5
Training loss: 2.511728286743164
Validation loss: 2.030848870674769

Epoch: 5| Step: 6
Training loss: 1.9161268472671509
Validation loss: 2.0277336637179055

Epoch: 5| Step: 7
Training loss: 3.021527051925659
Validation loss: 2.030348072449366

Epoch: 5| Step: 8
Training loss: 2.2056307792663574
Validation loss: 2.0296997278928757

Epoch: 5| Step: 9
Training loss: 2.152820110321045
Validation loss: 2.024772177139918

Epoch: 5| Step: 10
Training loss: 1.7457386255264282
Validation loss: 2.031620974342028

Epoch: 5| Step: 11
Training loss: 2.6802992820739746
Validation loss: 2.02981906135877

Epoch: 81| Step: 0
Training loss: 2.2696800231933594
Validation loss: 2.029720967014631

Epoch: 5| Step: 1
Training loss: 2.6812641620635986
Validation loss: 2.0257685432831445

Epoch: 5| Step: 2
Training loss: 2.4845762252807617
Validation loss: 2.0208441068728766

Epoch: 5| Step: 3
Training loss: 2.598358392715454
Validation loss: 2.0305081059535346

Epoch: 5| Step: 4
Training loss: 2.3365085124969482
Validation loss: 2.0367325892051062

Epoch: 5| Step: 5
Training loss: 1.8874247074127197
Validation loss: 2.0382820069789886

Epoch: 5| Step: 6
Training loss: 2.521472930908203
Validation loss: 2.0410946557919183

Epoch: 5| Step: 7
Training loss: 2.1988892555236816
Validation loss: 2.039211725195249

Epoch: 5| Step: 8
Training loss: 1.8014904260635376
Validation loss: 2.039534737666448

Epoch: 5| Step: 9
Training loss: 2.064396619796753
Validation loss: 2.0335488617420197

Epoch: 5| Step: 10
Training loss: 1.6157665252685547
Validation loss: 2.028743803501129

Epoch: 5| Step: 11
Training loss: 1.5697956085205078
Validation loss: 2.024913335839907

Epoch: 82| Step: 0
Training loss: 2.512298107147217
Validation loss: 2.0247899939616523

Epoch: 5| Step: 1
Training loss: 1.5351126194000244
Validation loss: 2.022645319501559

Epoch: 5| Step: 2
Training loss: 2.588764190673828
Validation loss: 2.0322567969560623

Epoch: 5| Step: 3
Training loss: 2.1047356128692627
Validation loss: 2.026656443874041

Epoch: 5| Step: 4
Training loss: 2.4785356521606445
Validation loss: 2.0250394493341446

Epoch: 5| Step: 5
Training loss: 1.9505866765975952
Validation loss: 2.033623735109965

Epoch: 5| Step: 6
Training loss: 2.179697036743164
Validation loss: 2.0351581126451492

Epoch: 5| Step: 7
Training loss: 2.256939649581909
Validation loss: 2.0271789878606796

Epoch: 5| Step: 8
Training loss: 1.9327024221420288
Validation loss: 2.023682286341985

Epoch: 5| Step: 9
Training loss: 2.6992666721343994
Validation loss: 2.0175658116738

Epoch: 5| Step: 10
Training loss: 1.7974014282226562
Validation loss: 2.0289798428614936

Epoch: 5| Step: 11
Training loss: 3.1613903045654297
Validation loss: 2.0248558024565377

Epoch: 83| Step: 0
Training loss: 2.1948318481445312
Validation loss: 2.0288984924554825

Epoch: 5| Step: 1
Training loss: 2.5873780250549316
Validation loss: 2.0402870575586953

Epoch: 5| Step: 2
Training loss: 2.1230053901672363
Validation loss: 2.041386842727661

Epoch: 5| Step: 3
Training loss: 2.108954668045044
Validation loss: 2.0483999053637185

Epoch: 5| Step: 4
Training loss: 1.85994553565979
Validation loss: 2.043253873785337

Epoch: 5| Step: 5
Training loss: 1.9817644357681274
Validation loss: 2.0455559343099594

Epoch: 5| Step: 6
Training loss: 2.280653953552246
Validation loss: 2.0445514420668283

Epoch: 5| Step: 7
Training loss: 2.167806386947632
Validation loss: 2.037342349688212

Epoch: 5| Step: 8
Training loss: 2.3222644329071045
Validation loss: 2.038782755533854

Epoch: 5| Step: 9
Training loss: 2.2041432857513428
Validation loss: 2.0357229759295783

Epoch: 5| Step: 10
Training loss: 2.237769603729248
Validation loss: 2.0285551945368447

Epoch: 5| Step: 11
Training loss: 3.8764114379882812
Validation loss: 2.0285640756289163

Epoch: 84| Step: 0
Training loss: 2.603511095046997
Validation loss: 2.023117313782374

Epoch: 5| Step: 1
Training loss: 1.9523166418075562
Validation loss: 2.016832252343496

Epoch: 5| Step: 2
Training loss: 2.125241756439209
Validation loss: 2.0137285391489663

Epoch: 5| Step: 3
Training loss: 2.424215316772461
Validation loss: 2.013468856612841

Epoch: 5| Step: 4
Training loss: 2.1637156009674072
Validation loss: 2.0224482218424478

Epoch: 5| Step: 5
Training loss: 2.9378609657287598
Validation loss: 2.010873958468437

Epoch: 5| Step: 6
Training loss: 2.7356693744659424
Validation loss: 2.016776293516159

Epoch: 5| Step: 7
Training loss: 2.0533976554870605
Validation loss: 2.008691449960073

Epoch: 5| Step: 8
Training loss: 1.8197343349456787
Validation loss: 2.0097842464844384

Epoch: 5| Step: 9
Training loss: 2.1500911712646484
Validation loss: 2.017132133245468

Epoch: 5| Step: 10
Training loss: 1.3385345935821533
Validation loss: 2.0185873061418533

Epoch: 5| Step: 11
Training loss: 1.379611849784851
Validation loss: 2.0219722191492715

Epoch: 85| Step: 0
Training loss: 1.7274253368377686
Validation loss: 2.021975268920263

Epoch: 5| Step: 1
Training loss: 2.109711170196533
Validation loss: 2.0191689680020013

Epoch: 5| Step: 2
Training loss: 2.3051021099090576
Validation loss: 2.0192375679810843

Epoch: 5| Step: 3
Training loss: 1.9742858409881592
Validation loss: 2.021976128220558

Epoch: 5| Step: 4
Training loss: 2.2912583351135254
Validation loss: 2.03106560309728

Epoch: 5| Step: 5
Training loss: 1.7412124872207642
Validation loss: 2.0147663752237954

Epoch: 5| Step: 6
Training loss: 2.4696693420410156
Validation loss: 2.015888422727585

Epoch: 5| Step: 7
Training loss: 2.6579527854919434
Validation loss: 2.0209684669971466

Epoch: 5| Step: 8
Training loss: 1.968427062034607
Validation loss: 2.014813373486201

Epoch: 5| Step: 9
Training loss: 2.3641629219055176
Validation loss: 2.0157077411810556

Epoch: 5| Step: 10
Training loss: 2.3623154163360596
Validation loss: 2.014666055639585

Epoch: 5| Step: 11
Training loss: 2.755681037902832
Validation loss: 2.0116875072320304

Epoch: 86| Step: 0
Training loss: 2.278146982192993
Validation loss: 2.0203549712896347

Epoch: 5| Step: 1
Training loss: 2.5968613624572754
Validation loss: 2.024776875972748

Epoch: 5| Step: 2
Training loss: 2.103631019592285
Validation loss: 2.037566284338633

Epoch: 5| Step: 3
Training loss: 2.2611072063446045
Validation loss: 2.0387581288814545

Epoch: 5| Step: 4
Training loss: 2.2880711555480957
Validation loss: 2.0390487213929496

Epoch: 5| Step: 5
Training loss: 2.569068431854248
Validation loss: 2.0408450762430825

Epoch: 5| Step: 6
Training loss: 2.028674840927124
Validation loss: 2.040268510580063

Epoch: 5| Step: 7
Training loss: 1.8397700786590576
Validation loss: 2.0375794718662896

Epoch: 5| Step: 8
Training loss: 1.9929783344268799
Validation loss: 2.036490812897682

Epoch: 5| Step: 9
Training loss: 2.1511306762695312
Validation loss: 2.023709014058113

Epoch: 5| Step: 10
Training loss: 2.261155843734741
Validation loss: 2.015331894159317

Epoch: 5| Step: 11
Training loss: 2.098555088043213
Validation loss: 2.013518586754799

Epoch: 87| Step: 0
Training loss: 2.157938003540039
Validation loss: 2.014435718456904

Epoch: 5| Step: 1
Training loss: 2.3006412982940674
Validation loss: 2.021493151783943

Epoch: 5| Step: 2
Training loss: 2.6913156509399414
Validation loss: 2.0226130932569504

Epoch: 5| Step: 3
Training loss: 1.8393793106079102
Validation loss: 2.0260674158732095

Epoch: 5| Step: 4
Training loss: 1.8080332279205322
Validation loss: 2.0227257957061133

Epoch: 5| Step: 5
Training loss: 2.4566454887390137
Validation loss: 2.0216971983512244

Epoch: 5| Step: 6
Training loss: 2.437671422958374
Validation loss: 2.018030062317848

Epoch: 5| Step: 7
Training loss: 2.2422986030578613
Validation loss: 2.0174298336108527

Epoch: 5| Step: 8
Training loss: 2.1184468269348145
Validation loss: 2.0143230805794397

Epoch: 5| Step: 9
Training loss: 1.9269943237304688
Validation loss: 2.010852118333181

Epoch: 5| Step: 10
Training loss: 2.324235439300537
Validation loss: 2.014578844110171

Epoch: 5| Step: 11
Training loss: 1.504433035850525
Validation loss: 2.014181469877561

Epoch: 88| Step: 0
Training loss: 2.9103641510009766
Validation loss: 2.020148828625679

Epoch: 5| Step: 1
Training loss: 2.324371814727783
Validation loss: 2.0239014824231467

Epoch: 5| Step: 2
Training loss: 1.8263318538665771
Validation loss: 2.020778775215149

Epoch: 5| Step: 3
Training loss: 1.7416598796844482
Validation loss: 2.0231050550937653

Epoch: 5| Step: 4
Training loss: 2.306373357772827
Validation loss: 2.0277930945158005

Epoch: 5| Step: 5
Training loss: 1.9061740636825562
Validation loss: 2.029061878720919

Epoch: 5| Step: 6
Training loss: 2.5150630474090576
Validation loss: 2.034634788831075

Epoch: 5| Step: 7
Training loss: 1.881556510925293
Validation loss: 2.0192933728297553

Epoch: 5| Step: 8
Training loss: 1.909181833267212
Validation loss: 2.0223542352517447

Epoch: 5| Step: 9
Training loss: 2.9091970920562744
Validation loss: 2.020011857151985

Epoch: 5| Step: 10
Training loss: 1.8544895648956299
Validation loss: 2.009460980693499

Epoch: 5| Step: 11
Training loss: 2.4367897510528564
Validation loss: 2.0135212937990823

Epoch: 89| Step: 0
Training loss: 1.9121549129486084
Validation loss: 2.0158258378505707

Epoch: 5| Step: 1
Training loss: 1.9744964838027954
Validation loss: 2.0171177238225937

Epoch: 5| Step: 2
Training loss: 2.2599780559539795
Validation loss: 2.0201833844184875

Epoch: 5| Step: 3
Training loss: 2.885089635848999
Validation loss: 2.0187473694483438

Epoch: 5| Step: 4
Training loss: 2.186098575592041
Validation loss: 2.020828604698181

Epoch: 5| Step: 5
Training loss: 2.074185848236084
Validation loss: 2.0245340963204703

Epoch: 5| Step: 6
Training loss: 2.753190517425537
Validation loss: 2.026592254638672

Epoch: 5| Step: 7
Training loss: 2.1631813049316406
Validation loss: 2.026987060904503

Epoch: 5| Step: 8
Training loss: 1.939329743385315
Validation loss: 2.024517978231112

Epoch: 5| Step: 9
Training loss: 2.2455811500549316
Validation loss: 2.021905248363813

Epoch: 5| Step: 10
Training loss: 1.690574288368225
Validation loss: 2.0156615376472473

Epoch: 5| Step: 11
Training loss: 2.739182472229004
Validation loss: 2.0078094949324927

Epoch: 90| Step: 0
Training loss: 2.2359695434570312
Validation loss: 2.008292337258657

Epoch: 5| Step: 1
Training loss: 2.6451542377471924
Validation loss: 2.017101541161537

Epoch: 5| Step: 2
Training loss: 1.9838483333587646
Validation loss: 2.0241421163082123

Epoch: 5| Step: 3
Training loss: 2.148378610610962
Validation loss: 2.0225137720505395

Epoch: 5| Step: 4
Training loss: 2.3235092163085938
Validation loss: 2.0212440689404807

Epoch: 5| Step: 5
Training loss: 2.2744226455688477
Validation loss: 2.010526344180107

Epoch: 5| Step: 6
Training loss: 2.0920658111572266
Validation loss: 2.007356643676758

Epoch: 5| Step: 7
Training loss: 2.0401687622070312
Validation loss: 2.0137236515680947

Epoch: 5| Step: 8
Training loss: 2.0174496173858643
Validation loss: 2.0171549121538797

Epoch: 5| Step: 9
Training loss: 2.337224006652832
Validation loss: 2.0168934067090354

Epoch: 5| Step: 10
Training loss: 1.9067836999893188
Validation loss: 2.021957755088806

Epoch: 5| Step: 11
Training loss: 1.9955006837844849
Validation loss: 2.0310181230306625

Epoch: 91| Step: 0
Training loss: 2.0808727741241455
Validation loss: 2.027982716759046

Epoch: 5| Step: 1
Training loss: 2.162400245666504
Validation loss: 2.025204434990883

Epoch: 5| Step: 2
Training loss: 2.437457323074341
Validation loss: 2.0286122610171637

Epoch: 5| Step: 3
Training loss: 2.4735302925109863
Validation loss: 2.0159647713104882

Epoch: 5| Step: 4
Training loss: 2.4214768409729004
Validation loss: 2.0153295745452247

Epoch: 5| Step: 5
Training loss: 1.719343900680542
Validation loss: 2.0187334567308426

Epoch: 5| Step: 6
Training loss: 2.1761832237243652
Validation loss: 2.0112322022517524

Epoch: 5| Step: 7
Training loss: 2.2949390411376953
Validation loss: 2.013648902376493

Epoch: 5| Step: 8
Training loss: 1.9328800439834595
Validation loss: 2.016494726141294

Epoch: 5| Step: 9
Training loss: 1.2896652221679688
Validation loss: 2.0103909969329834

Epoch: 5| Step: 10
Training loss: 3.040597915649414
Validation loss: 2.015495936075846

Epoch: 5| Step: 11
Training loss: 1.8043999671936035
Validation loss: 2.0193174133698144

Epoch: 92| Step: 0
Training loss: 2.0886759757995605
Validation loss: 2.018121416370074

Epoch: 5| Step: 1
Training loss: 2.3085110187530518
Validation loss: 2.0215267837047577

Epoch: 5| Step: 2
Training loss: 1.9710756540298462
Validation loss: 2.017944927016894

Epoch: 5| Step: 3
Training loss: 2.4309232234954834
Validation loss: 2.0183660288651786

Epoch: 5| Step: 4
Training loss: 2.0191593170166016
Validation loss: 2.0173217902580896

Epoch: 5| Step: 5
Training loss: 1.7127430438995361
Validation loss: 2.011790911356608

Epoch: 5| Step: 6
Training loss: 2.2552380561828613
Validation loss: 2.021985024213791

Epoch: 5| Step: 7
Training loss: 2.3537039756774902
Validation loss: 2.017635946472486

Epoch: 5| Step: 8
Training loss: 2.240358352661133
Validation loss: 2.014687721927961

Epoch: 5| Step: 9
Training loss: 2.952164649963379
Validation loss: 2.0186489820480347

Epoch: 5| Step: 10
Training loss: 1.5878889560699463
Validation loss: 2.0145836919546127

Epoch: 5| Step: 11
Training loss: 2.1810874938964844
Validation loss: 2.0122102200984955

Epoch: 93| Step: 0
Training loss: 2.4362564086914062
Validation loss: 2.019074648618698

Epoch: 5| Step: 1
Training loss: 2.0378923416137695
Validation loss: 2.011784320076307

Epoch: 5| Step: 2
Training loss: 2.032757043838501
Validation loss: 2.0139953841765723

Epoch: 5| Step: 3
Training loss: 2.7868692874908447
Validation loss: 2.017379492521286

Epoch: 5| Step: 4
Training loss: 2.2726948261260986
Validation loss: 2.0110177397727966

Epoch: 5| Step: 5
Training loss: 2.41286301612854
Validation loss: 2.0108115474383035

Epoch: 5| Step: 6
Training loss: 1.71792471408844
Validation loss: 2.019140680631002

Epoch: 5| Step: 7
Training loss: 2.3302841186523438
Validation loss: 2.0222773949305215

Epoch: 5| Step: 8
Training loss: 1.7737579345703125
Validation loss: 2.016687716046969

Epoch: 5| Step: 9
Training loss: 2.395371913909912
Validation loss: 2.0238804320494332

Epoch: 5| Step: 10
Training loss: 1.7170603275299072
Validation loss: 2.0076439877351127

Epoch: 5| Step: 11
Training loss: 1.8063277006149292
Validation loss: 2.0215210020542145

Epoch: 94| Step: 0
Training loss: 1.8245474100112915
Validation loss: 2.0281948695580163

Epoch: 5| Step: 1
Training loss: 2.4075300693511963
Validation loss: 2.0312721530596414

Epoch: 5| Step: 2
Training loss: 2.6277947425842285
Validation loss: 2.0343822687864304

Epoch: 5| Step: 3
Training loss: 2.352853298187256
Validation loss: 2.0427593340476355

Epoch: 5| Step: 4
Training loss: 2.521510601043701
Validation loss: 2.029303327202797

Epoch: 5| Step: 5
Training loss: 1.5690762996673584
Validation loss: 2.03254497051239

Epoch: 5| Step: 6
Training loss: 1.6929330825805664
Validation loss: 2.0180270125468573

Epoch: 5| Step: 7
Training loss: 2.2230281829833984
Validation loss: 2.0165516237417855

Epoch: 5| Step: 8
Training loss: 2.188093662261963
Validation loss: 2.014340649048487

Epoch: 5| Step: 9
Training loss: 1.9807440042495728
Validation loss: 2.010123382012049

Epoch: 5| Step: 10
Training loss: 2.5874950885772705
Validation loss: 2.0153871725002923

Epoch: 5| Step: 11
Training loss: 1.950024127960205
Validation loss: 2.023874948422114

Epoch: 95| Step: 0
Training loss: 1.8654937744140625
Validation loss: 2.0185966889063516

Epoch: 5| Step: 1
Training loss: 1.9913734197616577
Validation loss: 2.0159809490044913

Epoch: 5| Step: 2
Training loss: 2.4336674213409424
Validation loss: 2.0074426432450614

Epoch: 5| Step: 3
Training loss: 2.1991279125213623
Validation loss: 2.0168793002764382

Epoch: 5| Step: 4
Training loss: 1.9948734045028687
Validation loss: 2.027097394069036

Epoch: 5| Step: 5
Training loss: 1.9306113719940186
Validation loss: 2.0190313259760537

Epoch: 5| Step: 6
Training loss: 2.5010619163513184
Validation loss: 2.0323927650849023

Epoch: 5| Step: 7
Training loss: 2.110731840133667
Validation loss: 2.0263071109851203

Epoch: 5| Step: 8
Training loss: 1.7209663391113281
Validation loss: 2.0277519275744758

Epoch: 5| Step: 9
Training loss: 2.3460745811462402
Validation loss: 2.011431947350502

Epoch: 5| Step: 10
Training loss: 2.6627731323242188
Validation loss: 2.0091545581817627

Epoch: 5| Step: 11
Training loss: 2.624570369720459
Validation loss: 2.017407933870951

Epoch: 96| Step: 0
Training loss: 2.620248794555664
Validation loss: 2.0115633656581244

Epoch: 5| Step: 1
Training loss: 1.87277090549469
Validation loss: 2.0133088876803718

Epoch: 5| Step: 2
Training loss: 1.8431575298309326
Validation loss: 2.0065067360798516

Epoch: 5| Step: 3
Training loss: 2.2360386848449707
Validation loss: 2.0089037468036017

Epoch: 5| Step: 4
Training loss: 2.2373433113098145
Validation loss: 2.0137481143077216

Epoch: 5| Step: 5
Training loss: 1.7846542596817017
Validation loss: 2.0122748017311096

Epoch: 5| Step: 6
Training loss: 2.1246039867401123
Validation loss: 2.0072479049364724

Epoch: 5| Step: 7
Training loss: 2.483879804611206
Validation loss: 2.0050932317972183

Epoch: 5| Step: 8
Training loss: 2.295292377471924
Validation loss: 2.011200169722239

Epoch: 5| Step: 9
Training loss: 2.120823383331299
Validation loss: 2.014241317907969

Epoch: 5| Step: 10
Training loss: 2.026015043258667
Validation loss: 2.0044771482547126

Epoch: 5| Step: 11
Training loss: 2.4891536235809326
Validation loss: 2.01534133652846

Epoch: 97| Step: 0
Training loss: 2.2736713886260986
Validation loss: 2.018944392601649

Epoch: 5| Step: 1
Training loss: 2.18526029586792
Validation loss: 2.017951766649882

Epoch: 5| Step: 2
Training loss: 1.9810584783554077
Validation loss: 2.026951715350151

Epoch: 5| Step: 3
Training loss: 2.585852861404419
Validation loss: 2.032876710096995

Epoch: 5| Step: 4
Training loss: 2.2890117168426514
Validation loss: 2.0331815779209137

Epoch: 5| Step: 5
Training loss: 2.0094246864318848
Validation loss: 2.0351702272892

Epoch: 5| Step: 6
Training loss: 2.0399856567382812
Validation loss: 2.0375630259513855

Epoch: 5| Step: 7
Training loss: 2.5221524238586426
Validation loss: 2.036472807327906

Epoch: 5| Step: 8
Training loss: 2.267983913421631
Validation loss: 2.0274559954802194

Epoch: 5| Step: 9
Training loss: 1.8538949489593506
Validation loss: 2.0199942141771317

Epoch: 5| Step: 10
Training loss: 2.0310444831848145
Validation loss: 2.018837263186773

Epoch: 5| Step: 11
Training loss: 0.866722583770752
Validation loss: 2.0078049699465432

Epoch: 98| Step: 0
Training loss: 2.1760215759277344
Validation loss: 2.0164829045534134

Epoch: 5| Step: 1
Training loss: 2.1291959285736084
Validation loss: 2.029323384165764

Epoch: 5| Step: 2
Training loss: 2.5970959663391113
Validation loss: 2.033001815279325

Epoch: 5| Step: 3
Training loss: 2.110771894454956
Validation loss: 2.0415205905834832

Epoch: 5| Step: 4
Training loss: 2.441505193710327
Validation loss: 2.04240312675635

Epoch: 5| Step: 5
Training loss: 2.123579978942871
Validation loss: 2.0406360228856406

Epoch: 5| Step: 6
Training loss: 1.9722217321395874
Validation loss: 2.0444043477376304

Epoch: 5| Step: 7
Training loss: 1.8767669200897217
Validation loss: 2.05063529809316

Epoch: 5| Step: 8
Training loss: 2.224381923675537
Validation loss: 2.0481556256612143

Epoch: 5| Step: 9
Training loss: 1.9639723300933838
Validation loss: 2.0501764516035714

Epoch: 5| Step: 10
Training loss: 3.132497549057007
Validation loss: 2.0487136244773865

Epoch: 5| Step: 11
Training loss: 1.403791904449463
Validation loss: 2.0449671298265457

Epoch: 99| Step: 0
Training loss: 2.6950879096984863
Validation loss: 2.0420846144358316

Epoch: 5| Step: 1
Training loss: 1.996506929397583
Validation loss: 2.0411687841018042

Epoch: 5| Step: 2
Training loss: 1.8502635955810547
Validation loss: 2.0400337924559913

Epoch: 5| Step: 3
Training loss: 2.1187024116516113
Validation loss: 2.0375578006108603

Epoch: 5| Step: 4
Training loss: 2.9441306591033936
Validation loss: 2.0415631184975305

Epoch: 5| Step: 5
Training loss: 2.4880871772766113
Validation loss: 2.0363945017258325

Epoch: 5| Step: 6
Training loss: 2.1365694999694824
Validation loss: 2.041370843847593

Epoch: 5| Step: 7
Training loss: 2.063977003097534
Validation loss: 2.0352985163529715

Epoch: 5| Step: 8
Training loss: 1.6443793773651123
Validation loss: 2.0350014170010886

Epoch: 5| Step: 9
Training loss: 2.4266512393951416
Validation loss: 2.035603846112887

Epoch: 5| Step: 10
Training loss: 1.9676300287246704
Validation loss: 2.0331491579612098

Epoch: 5| Step: 11
Training loss: 2.2708206176757812
Validation loss: 2.0378816723823547

Epoch: 100| Step: 0
Training loss: 2.5808424949645996
Validation loss: 2.0331205626328788

Epoch: 5| Step: 1
Training loss: 2.2523224353790283
Validation loss: 2.026677186290423

Epoch: 5| Step: 2
Training loss: 2.6318259239196777
Validation loss: 2.01847480237484

Epoch: 5| Step: 3
Training loss: 2.273984909057617
Validation loss: 2.0150488714377084

Epoch: 5| Step: 4
Training loss: 1.951096534729004
Validation loss: 2.0137570798397064

Epoch: 5| Step: 5
Training loss: 1.7819522619247437
Validation loss: 2.0140109161535897

Epoch: 5| Step: 6
Training loss: 1.8725591897964478
Validation loss: 2.022502506772677

Epoch: 5| Step: 7
Training loss: 2.2497897148132324
Validation loss: 2.026659627755483

Epoch: 5| Step: 8
Training loss: 1.851843237876892
Validation loss: 2.0201049198706946

Epoch: 5| Step: 9
Training loss: 2.204230308532715
Validation loss: 2.0264882594347

Epoch: 5| Step: 10
Training loss: 1.917687177658081
Validation loss: 2.0402576327323914

Epoch: 5| Step: 11
Training loss: 3.035818576812744
Validation loss: 2.0345337440570197

Epoch: 101| Step: 0
Training loss: 2.052236318588257
Validation loss: 2.026353895664215

Epoch: 5| Step: 1
Training loss: 2.7626349925994873
Validation loss: 2.017894968390465

Epoch: 5| Step: 2
Training loss: 2.038228750228882
Validation loss: 2.0269620567560196

Epoch: 5| Step: 3
Training loss: 1.9694774150848389
Validation loss: 2.031726290782293

Epoch: 5| Step: 4
Training loss: 1.7073948383331299
Validation loss: 2.034485121568044

Epoch: 5| Step: 5
Training loss: 1.988093614578247
Validation loss: 2.0362047404050827

Epoch: 5| Step: 6
Training loss: 2.01225209236145
Validation loss: 2.0345641573270163

Epoch: 5| Step: 7
Training loss: 2.74743390083313
Validation loss: 2.039825141429901

Epoch: 5| Step: 8
Training loss: 2.024214267730713
Validation loss: 2.035260816415151

Epoch: 5| Step: 9
Training loss: 2.6425509452819824
Validation loss: 2.037574380636215

Epoch: 5| Step: 10
Training loss: 2.064697742462158
Validation loss: 2.0393596291542053

Epoch: 5| Step: 11
Training loss: 1.3232779502868652
Validation loss: 2.0385036865870156

Epoch: 102| Step: 0
Training loss: 1.8519861698150635
Validation loss: 2.037786121169726

Epoch: 5| Step: 1
Training loss: 2.1951193809509277
Validation loss: 2.0400742242733636

Epoch: 5| Step: 2
Training loss: 2.5019736289978027
Validation loss: 2.0356447299321494

Epoch: 5| Step: 3
Training loss: 2.2692348957061768
Validation loss: 2.0376871724923453

Epoch: 5| Step: 4
Training loss: 1.7327778339385986
Validation loss: 2.029478336373965

Epoch: 5| Step: 5
Training loss: 2.3596529960632324
Validation loss: 2.0234301338593164

Epoch: 5| Step: 6
Training loss: 2.1327903270721436
Validation loss: 2.022425855199496

Epoch: 5| Step: 7
Training loss: 2.519231081008911
Validation loss: 2.0090347677469254

Epoch: 5| Step: 8
Training loss: 2.247929096221924
Validation loss: 2.00596954425176

Epoch: 5| Step: 9
Training loss: 2.0986721515655518
Validation loss: 2.005393922328949

Epoch: 5| Step: 10
Training loss: 1.9614171981811523
Validation loss: 2.0155565043290458

Epoch: 5| Step: 11
Training loss: 2.1011433601379395
Validation loss: 2.0171408404906592

Epoch: 103| Step: 0
Training loss: 2.0803818702697754
Validation loss: 2.0379463334878287

Epoch: 5| Step: 1
Training loss: 2.308176279067993
Validation loss: 2.039766386151314

Epoch: 5| Step: 2
Training loss: 2.038602352142334
Validation loss: 2.061558187007904

Epoch: 5| Step: 3
Training loss: 1.9535576105117798
Validation loss: 2.063566654920578

Epoch: 5| Step: 4
Training loss: 2.6796250343322754
Validation loss: 2.053417364756266

Epoch: 5| Step: 5
Training loss: 2.054856300354004
Validation loss: 2.029201144973437

Epoch: 5| Step: 6
Training loss: 2.1154847145080566
Validation loss: 2.0269190619389215

Epoch: 5| Step: 7
Training loss: 2.2236688137054443
Validation loss: 2.0242682695388794

Epoch: 5| Step: 8
Training loss: 1.8021005392074585
Validation loss: 2.0126358369986215

Epoch: 5| Step: 9
Training loss: 2.168896198272705
Validation loss: 2.00596089164416

Epoch: 5| Step: 10
Training loss: 2.5172207355499268
Validation loss: 2.00560953716437

Epoch: 5| Step: 11
Training loss: 2.164599895477295
Validation loss: 2.007456049323082

Epoch: 104| Step: 0
Training loss: 2.093989372253418
Validation loss: 2.0092235753933587

Epoch: 5| Step: 1
Training loss: 2.174104690551758
Validation loss: 2.0220710833867392

Epoch: 5| Step: 2
Training loss: 2.4496893882751465
Validation loss: 2.0191032687822976

Epoch: 5| Step: 3
Training loss: 2.151538848876953
Validation loss: 2.0260323584079742

Epoch: 5| Step: 4
Training loss: 1.6346648931503296
Validation loss: 2.0222874581813812

Epoch: 5| Step: 5
Training loss: 2.316965103149414
Validation loss: 2.0256319542725882

Epoch: 5| Step: 6
Training loss: 2.012714147567749
Validation loss: 2.0204920123020806

Epoch: 5| Step: 7
Training loss: 2.003220558166504
Validation loss: 2.01976969341437

Epoch: 5| Step: 8
Training loss: 2.236212968826294
Validation loss: 2.020548721154531

Epoch: 5| Step: 9
Training loss: 2.2874221801757812
Validation loss: 2.0214679489533105

Epoch: 5| Step: 10
Training loss: 2.2704567909240723
Validation loss: 2.0201605210701623

Epoch: 5| Step: 11
Training loss: 3.1243600845336914
Validation loss: 2.019980068008105

Epoch: 105| Step: 0
Training loss: 2.438425064086914
Validation loss: 2.0122073739767075

Epoch: 5| Step: 1
Training loss: 1.7274038791656494
Validation loss: 2.0154036780198417

Epoch: 5| Step: 2
Training loss: 2.7365283966064453
Validation loss: 2.0213626325130463

Epoch: 5| Step: 3
Training loss: 1.9244152307510376
Validation loss: 2.0317854384581246

Epoch: 5| Step: 4
Training loss: 2.530339002609253
Validation loss: 2.0390521536270776

Epoch: 5| Step: 5
Training loss: 2.1202259063720703
Validation loss: 2.04540025194486

Epoch: 5| Step: 6
Training loss: 1.847092866897583
Validation loss: 2.04096927245458

Epoch: 5| Step: 7
Training loss: 2.461130142211914
Validation loss: 2.0390560726324716

Epoch: 5| Step: 8
Training loss: 2.1181204319000244
Validation loss: 2.0378513783216476

Epoch: 5| Step: 9
Training loss: 1.9325278997421265
Validation loss: 2.0509699881076813

Epoch: 5| Step: 10
Training loss: 1.919848084449768
Validation loss: 2.042641485730807

Epoch: 5| Step: 11
Training loss: 1.6590361595153809
Validation loss: 2.04161544640859

Epoch: 106| Step: 0
Training loss: 1.862524390220642
Validation loss: 2.0405023942391076

Epoch: 5| Step: 1
Training loss: 1.6368564367294312
Validation loss: 2.0388211409250894

Epoch: 5| Step: 2
Training loss: 1.7192847728729248
Validation loss: 2.0390047281980515

Epoch: 5| Step: 3
Training loss: 2.237929105758667
Validation loss: 2.0316406935453415

Epoch: 5| Step: 4
Training loss: 2.717160701751709
Validation loss: 2.0351902842521667

Epoch: 5| Step: 5
Training loss: 2.1341774463653564
Validation loss: 2.0380199998617172

Epoch: 5| Step: 6
Training loss: 2.5310256481170654
Validation loss: 2.033741056919098

Epoch: 5| Step: 7
Training loss: 2.3660781383514404
Validation loss: 2.022802417476972

Epoch: 5| Step: 8
Training loss: 1.889317274093628
Validation loss: 2.024841398000717

Epoch: 5| Step: 9
Training loss: 2.1724648475646973
Validation loss: 2.011945034066836

Epoch: 5| Step: 10
Training loss: 2.272538900375366
Validation loss: 2.0184705555438995

Epoch: 5| Step: 11
Training loss: 2.5140042304992676
Validation loss: 2.0151020338137946

Epoch: 107| Step: 0
Training loss: 1.751680612564087
Validation loss: 2.0237461775541306

Epoch: 5| Step: 1
Training loss: 2.1234989166259766
Validation loss: 2.020627344648043

Epoch: 5| Step: 2
Training loss: 2.2419285774230957
Validation loss: 2.0209797869126

Epoch: 5| Step: 3
Training loss: 2.2429306507110596
Validation loss: 2.0221561094125113

Epoch: 5| Step: 4
Training loss: 2.329646587371826
Validation loss: 2.028427312771479

Epoch: 5| Step: 5
Training loss: 2.195019483566284
Validation loss: 2.020967404047648

Epoch: 5| Step: 6
Training loss: 1.532767415046692
Validation loss: 2.0245881527662277

Epoch: 5| Step: 7
Training loss: 2.0236127376556396
Validation loss: 2.0155400534470878

Epoch: 5| Step: 8
Training loss: 2.942296266555786
Validation loss: 2.01597930987676

Epoch: 5| Step: 9
Training loss: 2.0773684978485107
Validation loss: 2.0171359181404114

Epoch: 5| Step: 10
Training loss: 2.10356068611145
Validation loss: 2.0231086959441504

Epoch: 5| Step: 11
Training loss: 2.6870808601379395
Validation loss: 2.015151416261991

Epoch: 108| Step: 0
Training loss: 2.143033266067505
Validation loss: 2.0248232185840607

Epoch: 5| Step: 1
Training loss: 2.770554780960083
Validation loss: 2.0318280905485153

Epoch: 5| Step: 2
Training loss: 1.7134971618652344
Validation loss: 2.0399153232574463

Epoch: 5| Step: 3
Training loss: 2.1893351078033447
Validation loss: 2.030542274316152

Epoch: 5| Step: 4
Training loss: 2.151982545852661
Validation loss: 2.0303763151168823

Epoch: 5| Step: 5
Training loss: 1.704922080039978
Validation loss: 2.0421791623036065

Epoch: 5| Step: 6
Training loss: 2.2281012535095215
Validation loss: 2.0355126907428107

Epoch: 5| Step: 7
Training loss: 1.9506616592407227
Validation loss: 2.0310499171415963

Epoch: 5| Step: 8
Training loss: 2.1701645851135254
Validation loss: 2.0259911169608436

Epoch: 5| Step: 9
Training loss: 2.239100694656372
Validation loss: 2.031958738962809

Epoch: 5| Step: 10
Training loss: 2.176375150680542
Validation loss: 2.0197685112555823

Epoch: 5| Step: 11
Training loss: 2.463841676712036
Validation loss: 2.0151871691147485

Epoch: 109| Step: 0
Training loss: 1.642047643661499
Validation loss: 2.011472071210543

Epoch: 5| Step: 1
Training loss: 2.07769775390625
Validation loss: 2.0155186305443444

Epoch: 5| Step: 2
Training loss: 2.209188938140869
Validation loss: 2.0218143612146378

Epoch: 5| Step: 3
Training loss: 1.5454503297805786
Validation loss: 2.025699188311895

Epoch: 5| Step: 4
Training loss: 2.0175609588623047
Validation loss: 2.0280195623636246

Epoch: 5| Step: 5
Training loss: 2.446451425552368
Validation loss: 2.0270530184110007

Epoch: 5| Step: 6
Training loss: 2.3265933990478516
Validation loss: 2.0259926368792853

Epoch: 5| Step: 7
Training loss: 2.117225408554077
Validation loss: 2.02324711283048

Epoch: 5| Step: 8
Training loss: 2.3859024047851562
Validation loss: 2.02592770755291

Epoch: 5| Step: 9
Training loss: 2.407282590866089
Validation loss: 2.018924360473951

Epoch: 5| Step: 10
Training loss: 2.559061288833618
Validation loss: 2.0133512914180756

Epoch: 5| Step: 11
Training loss: 2.0062808990478516
Validation loss: 2.0078045278787613

Epoch: 110| Step: 0
Training loss: 2.9767041206359863
Validation loss: 2.0104085405667624

Epoch: 5| Step: 1
Training loss: 2.100893497467041
Validation loss: 2.0075820485750833

Epoch: 5| Step: 2
Training loss: 2.214060068130493
Validation loss: 2.015343720714251

Epoch: 5| Step: 3
Training loss: 2.3916878700256348
Validation loss: 2.007196307182312

Epoch: 5| Step: 4
Training loss: 1.7943893671035767
Validation loss: 2.0136264910300574

Epoch: 5| Step: 5
Training loss: 1.6932700872421265
Validation loss: 2.0166773200035095

Epoch: 5| Step: 6
Training loss: 1.8295996189117432
Validation loss: 2.0232845594485602

Epoch: 5| Step: 7
Training loss: 1.7748569250106812
Validation loss: 2.0264690071344376

Epoch: 5| Step: 8
Training loss: 2.0973830223083496
Validation loss: 2.0363602687915168

Epoch: 5| Step: 9
Training loss: 2.0755398273468018
Validation loss: 2.0313330640395484

Epoch: 5| Step: 10
Training loss: 2.4044270515441895
Validation loss: 2.0466660261154175

Epoch: 5| Step: 11
Training loss: 2.610318183898926
Validation loss: 2.0591170688470206

Epoch: 111| Step: 0
Training loss: 3.1764774322509766
Validation loss: 2.0748122731844583

Epoch: 5| Step: 1
Training loss: 2.4474387168884277
Validation loss: 2.084159791469574

Epoch: 5| Step: 2
Training loss: 1.5582751035690308
Validation loss: 2.0780266175667443

Epoch: 5| Step: 3
Training loss: 1.83905827999115
Validation loss: 2.080389161904653

Epoch: 5| Step: 4
Training loss: 1.9785076379776
Validation loss: 2.0831664552291236

Epoch: 5| Step: 5
Training loss: 2.126453399658203
Validation loss: 2.0728792548179626

Epoch: 5| Step: 6
Training loss: 1.9119014739990234
Validation loss: 2.0602547377347946

Epoch: 5| Step: 7
Training loss: 2.4000964164733887
Validation loss: 2.049007693926493

Epoch: 5| Step: 8
Training loss: 2.1272575855255127
Validation loss: 2.0426184187332788

Epoch: 5| Step: 9
Training loss: 1.8891048431396484
Validation loss: 2.0267929633458457

Epoch: 5| Step: 10
Training loss: 2.057018280029297
Validation loss: 2.013240580757459

Epoch: 5| Step: 11
Training loss: 3.1955714225769043
Validation loss: 2.009343445301056

Epoch: 112| Step: 0
Training loss: 1.8436111211776733
Validation loss: 2.0110648224751153

Epoch: 5| Step: 1
Training loss: 1.716859221458435
Validation loss: 2.0127582301696143

Epoch: 5| Step: 2
Training loss: 2.108875036239624
Validation loss: 2.016048570473989

Epoch: 5| Step: 3
Training loss: 2.015164613723755
Validation loss: 2.014125873645147

Epoch: 5| Step: 4
Training loss: 2.202683687210083
Validation loss: 2.013670027256012

Epoch: 5| Step: 5
Training loss: 1.6903431415557861
Validation loss: 2.0080077995856604

Epoch: 5| Step: 6
Training loss: 2.5569093227386475
Validation loss: 2.0109716902176538

Epoch: 5| Step: 7
Training loss: 2.3043906688690186
Validation loss: 2.0205048571030297

Epoch: 5| Step: 8
Training loss: 2.4366841316223145
Validation loss: 2.023226350545883

Epoch: 5| Step: 9
Training loss: 1.9949443340301514
Validation loss: 2.029403661688169

Epoch: 5| Step: 10
Training loss: 2.6960196495056152
Validation loss: 2.040655488769213

Epoch: 5| Step: 11
Training loss: 2.410752296447754
Validation loss: 2.0452136248350143

Epoch: 113| Step: 0
Training loss: 2.0975565910339355
Validation loss: 2.0413890133301416

Epoch: 5| Step: 1
Training loss: 1.8189777135849
Validation loss: 2.0419666270414987

Epoch: 5| Step: 2
Training loss: 2.204869508743286
Validation loss: 2.036709984143575

Epoch: 5| Step: 3
Training loss: 2.308936595916748
Validation loss: 2.029456466436386

Epoch: 5| Step: 4
Training loss: 2.539503812789917
Validation loss: 2.032300353050232

Epoch: 5| Step: 5
Training loss: 2.567413568496704
Validation loss: 2.0242521266142526

Epoch: 5| Step: 6
Training loss: 2.0651988983154297
Validation loss: 2.0308143695195517

Epoch: 5| Step: 7
Training loss: 2.246854305267334
Validation loss: 2.0283676087856293

Epoch: 5| Step: 8
Training loss: 2.2614996433258057
Validation loss: 2.02519757548968

Epoch: 5| Step: 9
Training loss: 1.8076940774917603
Validation loss: 2.024902115265528

Epoch: 5| Step: 10
Training loss: 1.3645426034927368
Validation loss: 2.031819701194763

Epoch: 5| Step: 11
Training loss: 2.537438154220581
Validation loss: 2.0293096154928207

Epoch: 114| Step: 0
Training loss: 2.059998035430908
Validation loss: 2.0233802646398544

Epoch: 5| Step: 1
Training loss: 2.0975680351257324
Validation loss: 2.0147065867980323

Epoch: 5| Step: 2
Training loss: 2.7281601428985596
Validation loss: 2.025243600209554

Epoch: 5| Step: 3
Training loss: 2.070807933807373
Validation loss: 2.0153956512610116

Epoch: 5| Step: 4
Training loss: 2.0478599071502686
Validation loss: 2.019536107778549

Epoch: 5| Step: 5
Training loss: 2.5674631595611572
Validation loss: 2.0127884397904077

Epoch: 5| Step: 6
Training loss: 2.3156049251556396
Validation loss: 2.0131411254405975

Epoch: 5| Step: 7
Training loss: 2.0258891582489014
Validation loss: 2.0147652477025986

Epoch: 5| Step: 8
Training loss: 2.074537754058838
Validation loss: 2.0147195557753244

Epoch: 5| Step: 9
Training loss: 1.3884798288345337
Validation loss: 2.013616159558296

Epoch: 5| Step: 10
Training loss: 2.147963047027588
Validation loss: 2.0121302058299384

Epoch: 5| Step: 11
Training loss: 1.4149885177612305
Validation loss: 2.0108627378940582

Epoch: 115| Step: 0
Training loss: 2.3948781490325928
Validation loss: 2.016083210706711

Epoch: 5| Step: 1
Training loss: 1.9562419652938843
Validation loss: 2.0252879559993744

Epoch: 5| Step: 2
Training loss: 2.3511013984680176
Validation loss: 2.021466846267382

Epoch: 5| Step: 3
Training loss: 2.4809632301330566
Validation loss: 2.031282439827919

Epoch: 5| Step: 4
Training loss: 1.751173973083496
Validation loss: 2.0375789354244866

Epoch: 5| Step: 5
Training loss: 1.8102878332138062
Validation loss: 2.0252957940101624

Epoch: 5| Step: 6
Training loss: 2.069657564163208
Validation loss: 2.0281999657551446

Epoch: 5| Step: 7
Training loss: 2.45241117477417
Validation loss: 2.038987015684446

Epoch: 5| Step: 8
Training loss: 2.3128108978271484
Validation loss: 2.0451335261265435

Epoch: 5| Step: 9
Training loss: 2.0337471961975098
Validation loss: 2.040068432688713

Epoch: 5| Step: 10
Training loss: 1.5869228839874268
Validation loss: 2.039232353369395

Epoch: 5| Step: 11
Training loss: 2.366011619567871
Validation loss: 2.0423976331949234

Epoch: 116| Step: 0
Training loss: 1.8982317447662354
Validation loss: 2.0531428257624307

Epoch: 5| Step: 1
Training loss: 2.4049251079559326
Validation loss: 2.0757927298545837

Epoch: 5| Step: 2
Training loss: 2.158839225769043
Validation loss: 2.067592034737269

Epoch: 5| Step: 3
Training loss: 2.201108455657959
Validation loss: 2.078700433174769

Epoch: 5| Step: 4
Training loss: 2.265190601348877
Validation loss: 2.0635068863630295

Epoch: 5| Step: 5
Training loss: 2.19478178024292
Validation loss: 2.0548233340183892

Epoch: 5| Step: 6
Training loss: 2.248892307281494
Validation loss: 2.049876401821772

Epoch: 5| Step: 7
Training loss: 2.136573553085327
Validation loss: 2.0428983916838965

Epoch: 5| Step: 8
Training loss: 2.224485397338867
Validation loss: 2.0370859851439795

Epoch: 5| Step: 9
Training loss: 2.0514559745788574
Validation loss: 2.0271409253279367

Epoch: 5| Step: 10
Training loss: 1.8289207220077515
Validation loss: 2.0188801139593124

Epoch: 5| Step: 11
Training loss: 2.378349781036377
Validation loss: 2.0020287334918976

Epoch: 117| Step: 0
Training loss: 1.933205008506775
Validation loss: 2.0108380019664764

Epoch: 5| Step: 1
Training loss: 2.5686421394348145
Validation loss: 2.022188345591227

Epoch: 5| Step: 2
Training loss: 1.835513710975647
Validation loss: 2.0219584008057914

Epoch: 5| Step: 3
Training loss: 2.339940309524536
Validation loss: 2.0203255315621695

Epoch: 5| Step: 4
Training loss: 2.4868969917297363
Validation loss: 2.0281645009915032

Epoch: 5| Step: 5
Training loss: 2.153918504714966
Validation loss: 2.0221588810284934

Epoch: 5| Step: 6
Training loss: 1.9009500741958618
Validation loss: 2.026935895284017

Epoch: 5| Step: 7
Training loss: 2.284794807434082
Validation loss: 2.034158170223236

Epoch: 5| Step: 8
Training loss: 2.423243999481201
Validation loss: 2.0321316172679267

Epoch: 5| Step: 9
Training loss: 1.9980628490447998
Validation loss: 2.0365352829297385

Epoch: 5| Step: 10
Training loss: 1.9105840921401978
Validation loss: 2.036216050386429

Epoch: 5| Step: 11
Training loss: 2.346496820449829
Validation loss: 2.035163397590319

Epoch: 118| Step: 0
Training loss: 2.412994861602783
Validation loss: 2.030200312534968

Epoch: 5| Step: 1
Training loss: 2.5198330879211426
Validation loss: 2.027806227405866

Epoch: 5| Step: 2
Training loss: 1.8487157821655273
Validation loss: 2.0293590873479843

Epoch: 5| Step: 3
Training loss: 2.2532012462615967
Validation loss: 2.0234425167242684

Epoch: 5| Step: 4
Training loss: 2.598715305328369
Validation loss: 2.012680932879448

Epoch: 5| Step: 5
Training loss: 1.8820679187774658
Validation loss: 2.011623019973437

Epoch: 5| Step: 6
Training loss: 2.263556718826294
Validation loss: 2.0091086576382318

Epoch: 5| Step: 7
Training loss: 2.22473406791687
Validation loss: 2.0064536184072495

Epoch: 5| Step: 8
Training loss: 1.6363379955291748
Validation loss: 2.0088825722535453

Epoch: 5| Step: 9
Training loss: 2.172273635864258
Validation loss: 2.0190588732560477

Epoch: 5| Step: 10
Training loss: 1.9373722076416016
Validation loss: 2.025057166814804

Epoch: 5| Step: 11
Training loss: 1.0047913789749146
Validation loss: 2.0382664998372397

Epoch: 119| Step: 0
Training loss: 2.7651782035827637
Validation loss: 2.0362661629915237

Epoch: 5| Step: 1
Training loss: 1.8241922855377197
Validation loss: 2.039204850792885

Epoch: 5| Step: 2
Training loss: 1.5128543376922607
Validation loss: 2.0444318850835166

Epoch: 5| Step: 3
Training loss: 1.870035171508789
Validation loss: 2.0530723283688226

Epoch: 5| Step: 4
Training loss: 2.129127025604248
Validation loss: 2.047246679663658

Epoch: 5| Step: 5
Training loss: 2.2193167209625244
Validation loss: 2.037854259212812

Epoch: 5| Step: 6
Training loss: 1.8502452373504639
Validation loss: 2.032463232676188

Epoch: 5| Step: 7
Training loss: 2.1609325408935547
Validation loss: 2.0191157211860022

Epoch: 5| Step: 8
Training loss: 2.784902572631836
Validation loss: 2.0073778927326202

Epoch: 5| Step: 9
Training loss: 1.9771778583526611
Validation loss: 2.0181933542092643

Epoch: 5| Step: 10
Training loss: 2.0467238426208496
Validation loss: 2.011188581585884

Epoch: 5| Step: 11
Training loss: 2.733694553375244
Validation loss: 2.0124861101309457

Epoch: 120| Step: 0
Training loss: 2.1704835891723633
Validation loss: 2.006473441918691

Epoch: 5| Step: 1
Training loss: 2.273388624191284
Validation loss: 2.006697252392769

Epoch: 5| Step: 2
Training loss: 1.8380119800567627
Validation loss: 2.010412265857061

Epoch: 5| Step: 3
Training loss: 2.2588958740234375
Validation loss: 2.0196309238672256

Epoch: 5| Step: 4
Training loss: 1.8305866718292236
Validation loss: 2.012241671482722

Epoch: 5| Step: 5
Training loss: 2.914738416671753
Validation loss: 2.0159067263205848

Epoch: 5| Step: 6
Training loss: 2.151332378387451
Validation loss: 2.013005013267199

Epoch: 5| Step: 7
Training loss: 2.1822500228881836
Validation loss: 2.0113987823327384

Epoch: 5| Step: 8
Training loss: 1.5524035692214966
Validation loss: 2.00492762029171

Epoch: 5| Step: 9
Training loss: 1.9310247898101807
Validation loss: 2.0117438435554504

Epoch: 5| Step: 10
Training loss: 2.3931784629821777
Validation loss: 2.0117217451334

Epoch: 5| Step: 11
Training loss: 2.3374133110046387
Validation loss: 2.0185864915450416

Epoch: 121| Step: 0
Training loss: 1.6423492431640625
Validation loss: 2.0213276147842407

Epoch: 5| Step: 1
Training loss: 2.2373971939086914
Validation loss: 2.037438213825226

Epoch: 5| Step: 2
Training loss: 2.1793582439422607
Validation loss: 2.0329733987649283

Epoch: 5| Step: 3
Training loss: 2.4984002113342285
Validation loss: 2.0374277383089066

Epoch: 5| Step: 4
Training loss: 2.525472640991211
Validation loss: 2.0451195935408273

Epoch: 5| Step: 5
Training loss: 1.8380012512207031
Validation loss: 2.034509470065435

Epoch: 5| Step: 6
Training loss: 2.3698575496673584
Validation loss: 2.030769700805346

Epoch: 5| Step: 7
Training loss: 2.2066009044647217
Validation loss: 2.0294492890437446

Epoch: 5| Step: 8
Training loss: 2.2183451652526855
Validation loss: 2.0342996964852014

Epoch: 5| Step: 9
Training loss: 1.7340450286865234
Validation loss: 2.0274241069952645

Epoch: 5| Step: 10
Training loss: 1.7296196222305298
Validation loss: 2.028057719270388

Epoch: 5| Step: 11
Training loss: 2.347773551940918
Validation loss: 2.023512969414393

Epoch: 122| Step: 0
Training loss: 1.8848435878753662
Validation loss: 2.029707908630371

Epoch: 5| Step: 1
Training loss: 1.7040973901748657
Validation loss: 2.016821265220642

Epoch: 5| Step: 2
Training loss: 1.8768565654754639
Validation loss: 2.0154829770326614

Epoch: 5| Step: 3
Training loss: 1.9718735218048096
Validation loss: 2.017605021595955

Epoch: 5| Step: 4
Training loss: 2.2641024589538574
Validation loss: 2.0163031965494156

Epoch: 5| Step: 5
Training loss: 2.2441933155059814
Validation loss: 2.0099745392799377

Epoch: 5| Step: 6
Training loss: 2.1908650398254395
Validation loss: 2.0142863343159356

Epoch: 5| Step: 7
Training loss: 2.082523822784424
Validation loss: 2.0207243313392005

Epoch: 5| Step: 8
Training loss: 2.5435078144073486
Validation loss: 2.0239685078461966

Epoch: 5| Step: 9
Training loss: 1.9363584518432617
Validation loss: 2.0355943193038306

Epoch: 5| Step: 10
Training loss: 2.6428303718566895
Validation loss: 2.03776349623998

Epoch: 5| Step: 11
Training loss: 1.543027400970459
Validation loss: 2.0439235866069794

Epoch: 123| Step: 0
Training loss: 2.170822858810425
Validation loss: 2.0509240130583444

Epoch: 5| Step: 1
Training loss: 2.2819294929504395
Validation loss: 2.048712372779846

Epoch: 5| Step: 2
Training loss: 2.0212769508361816
Validation loss: 2.0412924587726593

Epoch: 5| Step: 3
Training loss: 2.3518803119659424
Validation loss: 2.0357919236024222

Epoch: 5| Step: 4
Training loss: 2.018234968185425
Validation loss: 2.0230791866779327

Epoch: 5| Step: 5
Training loss: 1.6756738424301147
Validation loss: 2.0210347125927606

Epoch: 5| Step: 6
Training loss: 2.317819118499756
Validation loss: 2.019116520881653

Epoch: 5| Step: 7
Training loss: 1.9443992376327515
Validation loss: 2.0160431216160455

Epoch: 5| Step: 8
Training loss: 2.190511703491211
Validation loss: 2.0177872627973557

Epoch: 5| Step: 9
Training loss: 1.9204521179199219
Validation loss: 2.0139678567647934

Epoch: 5| Step: 10
Training loss: 2.4370956420898438
Validation loss: 2.0170063227415085

Epoch: 5| Step: 11
Training loss: 1.8557629585266113
Validation loss: 2.0156273742516837

Epoch: 124| Step: 0
Training loss: 2.41272234916687
Validation loss: 2.018216257294019

Epoch: 5| Step: 1
Training loss: 2.3369312286376953
Validation loss: 2.0186436822017035

Epoch: 5| Step: 2
Training loss: 1.7070308923721313
Validation loss: 2.0148227463165918

Epoch: 5| Step: 3
Training loss: 2.4691617488861084
Validation loss: 2.012716919183731

Epoch: 5| Step: 4
Training loss: 2.142481565475464
Validation loss: 2.017484575510025

Epoch: 5| Step: 5
Training loss: 1.9428508281707764
Validation loss: 2.0197544544935226

Epoch: 5| Step: 6
Training loss: 1.8316494226455688
Validation loss: 2.0216145714124045

Epoch: 5| Step: 7
Training loss: 1.983381986618042
Validation loss: 2.02886309226354

Epoch: 5| Step: 8
Training loss: 1.9604419469833374
Validation loss: 2.0292370170354843

Epoch: 5| Step: 9
Training loss: 1.806885004043579
Validation loss: 2.0294056038061776

Epoch: 5| Step: 10
Training loss: 2.6624367237091064
Validation loss: 2.0411269068717957

Epoch: 5| Step: 11
Training loss: 1.458625078201294
Validation loss: 2.0354992846647897

Epoch: 125| Step: 0
Training loss: 2.450155258178711
Validation loss: 2.0415060420831046

Epoch: 5| Step: 1
Training loss: 2.2594125270843506
Validation loss: 2.0391615132490792

Epoch: 5| Step: 2
Training loss: 1.7280582189559937
Validation loss: 2.037400176127752

Epoch: 5| Step: 3
Training loss: 2.2528064250946045
Validation loss: 2.0315889567136765

Epoch: 5| Step: 4
Training loss: 1.5874167680740356
Validation loss: 2.0286795496940613

Epoch: 5| Step: 5
Training loss: 2.570465564727783
Validation loss: 2.029981498916944

Epoch: 5| Step: 6
Training loss: 2.377814531326294
Validation loss: 2.0169432212909064

Epoch: 5| Step: 7
Training loss: 1.6573522090911865
Validation loss: 2.0331942637761435

Epoch: 5| Step: 8
Training loss: 2.197021484375
Validation loss: 2.0226114789644876

Epoch: 5| Step: 9
Training loss: 2.483355760574341
Validation loss: 2.0245867321888604

Epoch: 5| Step: 10
Training loss: 1.7848182916641235
Validation loss: 2.0201968948046365

Epoch: 5| Step: 11
Training loss: 2.5270938873291016
Validation loss: 2.0198417554299035

Epoch: 126| Step: 0
Training loss: 1.725070595741272
Validation loss: 2.021055887142817

Epoch: 5| Step: 1
Training loss: 1.595285415649414
Validation loss: 2.0285999476909637

Epoch: 5| Step: 2
Training loss: 2.304143190383911
Validation loss: 2.031471615036329

Epoch: 5| Step: 3
Training loss: 2.0452020168304443
Validation loss: 2.0433160265286765

Epoch: 5| Step: 4
Training loss: 2.015463352203369
Validation loss: 2.034178306659063

Epoch: 5| Step: 5
Training loss: 2.6942241191864014
Validation loss: 2.0377314488093057

Epoch: 5| Step: 6
Training loss: 2.318436861038208
Validation loss: 2.0432360470294952

Epoch: 5| Step: 7
Training loss: 2.6192378997802734
Validation loss: 2.0285166104634604

Epoch: 5| Step: 8
Training loss: 2.1000607013702393
Validation loss: 2.039661784966787

Epoch: 5| Step: 9
Training loss: 1.9232866764068604
Validation loss: 2.035578340291977

Epoch: 5| Step: 10
Training loss: 1.9235302209854126
Validation loss: 2.039060557881991

Epoch: 5| Step: 11
Training loss: 1.8867967128753662
Validation loss: 2.0420519411563873

Epoch: 127| Step: 0
Training loss: 2.170293092727661
Validation loss: 2.044145847360293

Epoch: 5| Step: 1
Training loss: 1.7900205850601196
Validation loss: 2.0412104527155557

Epoch: 5| Step: 2
Training loss: 2.1122639179229736
Validation loss: 2.0344103823105493

Epoch: 5| Step: 3
Training loss: 2.1182703971862793
Validation loss: 2.034697875380516

Epoch: 5| Step: 4
Training loss: 1.7799733877182007
Validation loss: 2.0230388045310974

Epoch: 5| Step: 5
Training loss: 2.3693370819091797
Validation loss: 2.0374046166737876

Epoch: 5| Step: 6
Training loss: 1.5417717695236206
Validation loss: 2.0275729596614838

Epoch: 5| Step: 7
Training loss: 2.1584537029266357
Validation loss: 2.0186083813508353

Epoch: 5| Step: 8
Training loss: 2.727107286453247
Validation loss: 2.022224018971125

Epoch: 5| Step: 9
Training loss: 2.2923405170440674
Validation loss: 2.015986740589142

Epoch: 5| Step: 10
Training loss: 2.216881275177002
Validation loss: 2.021890098849932

Epoch: 5| Step: 11
Training loss: 1.5709495544433594
Validation loss: 2.016794895132383

Epoch: 128| Step: 0
Training loss: 1.8070068359375
Validation loss: 2.020358701546987

Epoch: 5| Step: 1
Training loss: 2.49412202835083
Validation loss: 2.020138611396154

Epoch: 5| Step: 2
Training loss: 2.143592357635498
Validation loss: 2.02118918299675

Epoch: 5| Step: 3
Training loss: 2.4064059257507324
Validation loss: 2.0203833977381387

Epoch: 5| Step: 4
Training loss: 2.389490842819214
Validation loss: 2.023057614763578

Epoch: 5| Step: 5
Training loss: 1.9634487628936768
Validation loss: 2.017720932761828

Epoch: 5| Step: 6
Training loss: 1.5069990158081055
Validation loss: 2.0306649257739386

Epoch: 5| Step: 7
Training loss: 2.457139492034912
Validation loss: 2.0298565328121185

Epoch: 5| Step: 8
Training loss: 2.0818634033203125
Validation loss: 2.0232676963011422

Epoch: 5| Step: 9
Training loss: 2.0297114849090576
Validation loss: 2.0235913892587027

Epoch: 5| Step: 10
Training loss: 2.164938449859619
Validation loss: 2.0360267808039985

Epoch: 5| Step: 11
Training loss: 1.4533326625823975
Validation loss: 2.0293458153804145

Epoch: 129| Step: 0
Training loss: 1.5759763717651367
Validation loss: 2.0319193253914514

Epoch: 5| Step: 1
Training loss: 2.1827549934387207
Validation loss: 2.0298606902360916

Epoch: 5| Step: 2
Training loss: 2.3045096397399902
Validation loss: 2.0318739811579385

Epoch: 5| Step: 3
Training loss: 1.9855785369873047
Validation loss: 2.0293208907047906

Epoch: 5| Step: 4
Training loss: 1.6709530353546143
Validation loss: 2.027024274071058

Epoch: 5| Step: 5
Training loss: 1.976192831993103
Validation loss: 2.033714065949122

Epoch: 5| Step: 6
Training loss: 2.601339817047119
Validation loss: 2.0352919697761536

Epoch: 5| Step: 7
Training loss: 1.8707237243652344
Validation loss: 2.032010684410731

Epoch: 5| Step: 8
Training loss: 2.4996190071105957
Validation loss: 2.0313610583543777

Epoch: 5| Step: 9
Training loss: 2.4177956581115723
Validation loss: 2.0248907854159675

Epoch: 5| Step: 10
Training loss: 2.2720329761505127
Validation loss: 2.022731766104698

Epoch: 5| Step: 11
Training loss: 0.7579604387283325
Validation loss: 2.0301097482442856

Epoch: 130| Step: 0
Training loss: 2.123791456222534
Validation loss: 2.03968745470047

Epoch: 5| Step: 1
Training loss: 2.189047336578369
Validation loss: 2.0402514984210334

Epoch: 5| Step: 2
Training loss: 2.2548282146453857
Validation loss: 2.06504858036836

Epoch: 5| Step: 3
Training loss: 2.5454938411712646
Validation loss: 2.074739654858907

Epoch: 5| Step: 4
Training loss: 1.806668996810913
Validation loss: 2.0574932545423508

Epoch: 5| Step: 5
Training loss: 2.0831973552703857
Validation loss: 2.039333298802376

Epoch: 5| Step: 6
Training loss: 2.0255331993103027
Validation loss: 2.036271164814631

Epoch: 5| Step: 7
Training loss: 2.0121583938598633
Validation loss: 2.023274779319763

Epoch: 5| Step: 8
Training loss: 1.8758487701416016
Validation loss: 2.038306340575218

Epoch: 5| Step: 9
Training loss: 2.467517852783203
Validation loss: 2.023631622393926

Epoch: 5| Step: 10
Training loss: 1.930464506149292
Validation loss: 2.0290455470482507

Epoch: 5| Step: 11
Training loss: 2.322328567504883
Validation loss: 2.028631587823232

Epoch: 131| Step: 0
Training loss: 1.9861271381378174
Validation loss: 2.0292917788028717

Epoch: 5| Step: 1
Training loss: 2.379627227783203
Validation loss: 2.0322039475043616

Epoch: 5| Step: 2
Training loss: 1.9028980731964111
Validation loss: 2.0329090356826782

Epoch: 5| Step: 3
Training loss: 1.5530576705932617
Validation loss: 2.0275522669156394

Epoch: 5| Step: 4
Training loss: 2.26491117477417
Validation loss: 2.029703805843989

Epoch: 5| Step: 5
Training loss: 1.8759937286376953
Validation loss: 2.0190244764089584

Epoch: 5| Step: 6
Training loss: 2.068621873855591
Validation loss: 2.0200616071621575

Epoch: 5| Step: 7
Training loss: 2.290781021118164
Validation loss: 2.032762368520101

Epoch: 5| Step: 8
Training loss: 2.144432544708252
Validation loss: 2.0226086576779685

Epoch: 5| Step: 9
Training loss: 2.179778575897217
Validation loss: 2.03067813316981

Epoch: 5| Step: 10
Training loss: 2.2067911624908447
Validation loss: 2.0232596347729364

Epoch: 5| Step: 11
Training loss: 3.2129387855529785
Validation loss: 2.0347956319650016

Epoch: 132| Step: 0
Training loss: 1.930127501487732
Validation loss: 2.0353282590707145

Epoch: 5| Step: 1
Training loss: 2.2845618724823
Validation loss: 2.051548351844152

Epoch: 5| Step: 2
Training loss: 2.629990339279175
Validation loss: 2.0720375229914985

Epoch: 5| Step: 3
Training loss: 1.8115718364715576
Validation loss: 2.0906895647446313

Epoch: 5| Step: 4
Training loss: 2.3632919788360596
Validation loss: 2.083863074580828

Epoch: 5| Step: 5
Training loss: 2.3688013553619385
Validation loss: 2.068555807073911

Epoch: 5| Step: 6
Training loss: 2.345977783203125
Validation loss: 2.046850308775902

Epoch: 5| Step: 7
Training loss: 1.6882988214492798
Validation loss: 2.0402842462062836

Epoch: 5| Step: 8
Training loss: 2.1961681842803955
Validation loss: 2.021766593058904

Epoch: 5| Step: 9
Training loss: 1.8997341394424438
Validation loss: 2.0174039204915366

Epoch: 5| Step: 10
Training loss: 2.263852596282959
Validation loss: 2.009544392426809

Epoch: 5| Step: 11
Training loss: 1.094529628753662
Validation loss: 2.0152453432480493

Epoch: 133| Step: 0
Training loss: 1.7669893503189087
Validation loss: 2.0182409584522247

Epoch: 5| Step: 1
Training loss: 2.7721734046936035
Validation loss: 2.0111726423104606

Epoch: 5| Step: 2
Training loss: 2.2904982566833496
Validation loss: 2.013426055510839

Epoch: 5| Step: 3
Training loss: 2.6117396354675293
Validation loss: 2.0151910384496055

Epoch: 5| Step: 4
Training loss: 1.8522182703018188
Validation loss: 2.0125618427991867

Epoch: 5| Step: 5
Training loss: 2.2323293685913086
Validation loss: 2.01553442577521

Epoch: 5| Step: 6
Training loss: 2.163830280303955
Validation loss: 2.0080646673838296

Epoch: 5| Step: 7
Training loss: 1.9974607229232788
Validation loss: 2.0159358282883963

Epoch: 5| Step: 8
Training loss: 2.2906272411346436
Validation loss: 2.0235475351413093

Epoch: 5| Step: 9
Training loss: 1.7450249195098877
Validation loss: 2.0292571236689887

Epoch: 5| Step: 10
Training loss: 1.5949783325195312
Validation loss: 2.032112235824267

Epoch: 5| Step: 11
Training loss: 2.6483917236328125
Validation loss: 2.0296735018491745

Epoch: 134| Step: 0
Training loss: 1.935464859008789
Validation loss: 2.028191104531288

Epoch: 5| Step: 1
Training loss: 2.195918560028076
Validation loss: 2.0355069438616433

Epoch: 5| Step: 2
Training loss: 1.6630589962005615
Validation loss: 2.0325320611397424

Epoch: 5| Step: 3
Training loss: 1.6113027334213257
Validation loss: 2.0339466631412506

Epoch: 5| Step: 4
Training loss: 2.692451000213623
Validation loss: 2.0262435426314673

Epoch: 5| Step: 5
Training loss: 2.0529630184173584
Validation loss: 2.035076747337977

Epoch: 5| Step: 6
Training loss: 2.3333652019500732
Validation loss: 2.035113975405693

Epoch: 5| Step: 7
Training loss: 2.126339912414551
Validation loss: 2.0347622434298196

Epoch: 5| Step: 8
Training loss: 2.0124690532684326
Validation loss: 2.0265205949544907

Epoch: 5| Step: 9
Training loss: 2.4752583503723145
Validation loss: 2.036330595612526

Epoch: 5| Step: 10
Training loss: 1.9656375646591187
Validation loss: 2.0299929877122245

Epoch: 5| Step: 11
Training loss: 2.244548797607422
Validation loss: 2.0265159954627356

Epoch: 135| Step: 0
Training loss: 1.7772537469863892
Validation loss: 2.0276484340429306

Epoch: 5| Step: 1
Training loss: 2.1248576641082764
Validation loss: 2.023717706402143

Epoch: 5| Step: 2
Training loss: 2.679347515106201
Validation loss: 2.0246221820513406

Epoch: 5| Step: 3
Training loss: 1.9624207019805908
Validation loss: 2.0298626075188317

Epoch: 5| Step: 4
Training loss: 2.007794141769409
Validation loss: 2.0313278635342917

Epoch: 5| Step: 5
Training loss: 2.654508352279663
Validation loss: 2.03130737443765

Epoch: 5| Step: 6
Training loss: 1.8801990747451782
Validation loss: 2.0341829607884088

Epoch: 5| Step: 7
Training loss: 2.322166919708252
Validation loss: 2.021946907043457

Epoch: 5| Step: 8
Training loss: 2.1891446113586426
Validation loss: 2.0279710491498313

Epoch: 5| Step: 9
Training loss: 1.7018457651138306
Validation loss: 2.0314637074867883

Epoch: 5| Step: 10
Training loss: 1.6588798761367798
Validation loss: 2.0298100809256234

Epoch: 5| Step: 11
Training loss: 1.776118516921997
Validation loss: 2.0427492757638297

Epoch: 136| Step: 0
Training loss: 2.2515745162963867
Validation loss: 2.04705419143041

Epoch: 5| Step: 1
Training loss: 1.9990603923797607
Validation loss: 2.053797498345375

Epoch: 5| Step: 2
Training loss: 2.2933363914489746
Validation loss: 2.0465886096159616

Epoch: 5| Step: 3
Training loss: 2.1838672161102295
Validation loss: 2.053243656953176

Epoch: 5| Step: 4
Training loss: 1.9493637084960938
Validation loss: 2.054801200826963

Epoch: 5| Step: 5
Training loss: 2.769902467727661
Validation loss: 2.0464496264855065

Epoch: 5| Step: 6
Training loss: 1.3576561212539673
Validation loss: 2.0357460230588913

Epoch: 5| Step: 7
Training loss: 2.175617218017578
Validation loss: 2.025397722919782

Epoch: 5| Step: 8
Training loss: 1.7713518142700195
Validation loss: 2.0367878526449203

Epoch: 5| Step: 9
Training loss: 2.5562996864318848
Validation loss: 2.0353503276904426

Epoch: 5| Step: 10
Training loss: 1.8861411809921265
Validation loss: 2.040109192331632

Epoch: 5| Step: 11
Training loss: 1.5954339504241943
Validation loss: 2.030575598279635

Epoch: 137| Step: 0
Training loss: 1.6331363916397095
Validation loss: 2.034409483273824

Epoch: 5| Step: 1
Training loss: 2.1771252155303955
Validation loss: 2.037685508529345

Epoch: 5| Step: 2
Training loss: 1.7756803035736084
Validation loss: 2.0305027812719345

Epoch: 5| Step: 3
Training loss: 2.059481620788574
Validation loss: 2.0362197955449424

Epoch: 5| Step: 4
Training loss: 2.2454628944396973
Validation loss: 2.0326172709465027

Epoch: 5| Step: 5
Training loss: 2.0264365673065186
Validation loss: 2.0416148900985718

Epoch: 5| Step: 6
Training loss: 2.3151423931121826
Validation loss: 2.037889927625656

Epoch: 5| Step: 7
Training loss: 1.9984681606292725
Validation loss: 2.045668904980024

Epoch: 5| Step: 8
Training loss: 2.3391690254211426
Validation loss: 2.0508432388305664

Epoch: 5| Step: 9
Training loss: 1.9235655069351196
Validation loss: 2.04666967689991

Epoch: 5| Step: 10
Training loss: 2.6289234161376953
Validation loss: 2.045576666792234

Epoch: 5| Step: 11
Training loss: 1.1505303382873535
Validation loss: 2.036174868543943

Epoch: 138| Step: 0
Training loss: 2.119932174682617
Validation loss: 2.033777485291163

Epoch: 5| Step: 1
Training loss: 2.187054395675659
Validation loss: 2.013537347316742

Epoch: 5| Step: 2
Training loss: 2.0118179321289062
Validation loss: 2.0202145079771676

Epoch: 5| Step: 3
Training loss: 2.1143767833709717
Validation loss: 2.0268635948499045

Epoch: 5| Step: 4
Training loss: 2.581190586090088
Validation loss: 2.0242397089799247

Epoch: 5| Step: 5
Training loss: 1.714272141456604
Validation loss: 2.031951059897741

Epoch: 5| Step: 6
Training loss: 1.5459712743759155
Validation loss: 2.031124487519264

Epoch: 5| Step: 7
Training loss: 2.1424524784088135
Validation loss: 2.0274247427781424

Epoch: 5| Step: 8
Training loss: 2.1515254974365234
Validation loss: 2.0344522843758264

Epoch: 5| Step: 9
Training loss: 2.6436307430267334
Validation loss: 2.0286858876546225

Epoch: 5| Step: 10
Training loss: 2.0953643321990967
Validation loss: 2.028695752223333

Epoch: 5| Step: 11
Training loss: 1.936274528503418
Validation loss: 2.034119486808777

Epoch: 139| Step: 0
Training loss: 2.362159252166748
Validation loss: 2.0222954154014587

Epoch: 5| Step: 1
Training loss: 1.7913929224014282
Validation loss: 2.025340214371681

Epoch: 5| Step: 2
Training loss: 2.2093544006347656
Validation loss: 2.0261617402235665

Epoch: 5| Step: 3
Training loss: 2.2621376514434814
Validation loss: 2.043475796778997

Epoch: 5| Step: 4
Training loss: 2.0184576511383057
Validation loss: 2.0511927157640457

Epoch: 5| Step: 5
Training loss: 1.9596656560897827
Validation loss: 2.046497737367948

Epoch: 5| Step: 6
Training loss: 2.088853359222412
Validation loss: 2.0440601110458374

Epoch: 5| Step: 7
Training loss: 2.0937438011169434
Validation loss: 2.0545759995778403

Epoch: 5| Step: 8
Training loss: 1.8027492761611938
Validation loss: 2.0551795760790506

Epoch: 5| Step: 9
Training loss: 2.8284037113189697
Validation loss: 2.0628001342217126

Epoch: 5| Step: 10
Training loss: 1.812813401222229
Validation loss: 2.0541319847106934

Epoch: 5| Step: 11
Training loss: 1.1934940814971924
Validation loss: 2.0457535137732825

Epoch: 140| Step: 0
Training loss: 2.16487717628479
Validation loss: 2.0449449767669043

Epoch: 5| Step: 1
Training loss: 1.6395527124404907
Validation loss: 2.0512247880299888

Epoch: 5| Step: 2
Training loss: 2.673462390899658
Validation loss: 2.0529677222172418

Epoch: 5| Step: 3
Training loss: 1.6994787454605103
Validation loss: 2.0393378287553787

Epoch: 5| Step: 4
Training loss: 2.4046120643615723
Validation loss: 2.050985415776571

Epoch: 5| Step: 5
Training loss: 2.3592987060546875
Validation loss: 2.0433193941911063

Epoch: 5| Step: 6
Training loss: 1.7995891571044922
Validation loss: 2.044541592399279

Epoch: 5| Step: 7
Training loss: 2.1231987476348877
Validation loss: 2.0452045996983848

Epoch: 5| Step: 8
Training loss: 1.6917686462402344
Validation loss: 2.0444887429475784

Epoch: 5| Step: 9
Training loss: 2.318993091583252
Validation loss: 2.0465716620286307

Epoch: 5| Step: 10
Training loss: 2.086103916168213
Validation loss: 2.050931433836619

Epoch: 5| Step: 11
Training loss: 1.7947372198104858
Validation loss: 2.0403295358022056

Epoch: 141| Step: 0
Training loss: 2.4437389373779297
Validation loss: 2.0437399595975876

Epoch: 5| Step: 1
Training loss: 2.0539486408233643
Validation loss: 2.047928288578987

Epoch: 5| Step: 2
Training loss: 2.1010780334472656
Validation loss: 2.055456111828486

Epoch: 5| Step: 3
Training loss: 2.583388090133667
Validation loss: 2.049376279115677

Epoch: 5| Step: 4
Training loss: 2.0386385917663574
Validation loss: 2.0420683473348618

Epoch: 5| Step: 5
Training loss: 1.7453625202178955
Validation loss: 2.060612514615059

Epoch: 5| Step: 6
Training loss: 1.9698559045791626
Validation loss: 2.0545919090509415

Epoch: 5| Step: 7
Training loss: 2.4017233848571777
Validation loss: 2.0548952321211496

Epoch: 5| Step: 8
Training loss: 1.898612380027771
Validation loss: 2.0591900249322257

Epoch: 5| Step: 9
Training loss: 2.0369668006896973
Validation loss: 2.0547056446472802

Epoch: 5| Step: 10
Training loss: 1.7493648529052734
Validation loss: 2.051875496904055

Epoch: 5| Step: 11
Training loss: 1.1965844631195068
Validation loss: 2.036052962144216

Epoch: 142| Step: 0
Training loss: 1.2456432580947876
Validation loss: 2.0355792492628098

Epoch: 5| Step: 1
Training loss: 2.2454636096954346
Validation loss: 2.037296881278356

Epoch: 5| Step: 2
Training loss: 2.1007239818573
Validation loss: 2.0345799326896667

Epoch: 5| Step: 3
Training loss: 2.2061526775360107
Validation loss: 2.0445981671412787

Epoch: 5| Step: 4
Training loss: 2.066908836364746
Validation loss: 2.045288090904554

Epoch: 5| Step: 5
Training loss: 2.076693058013916
Validation loss: 2.0345697601636252

Epoch: 5| Step: 6
Training loss: 2.4217090606689453
Validation loss: 2.0464334984620414

Epoch: 5| Step: 7
Training loss: 1.744101881980896
Validation loss: 2.0500788440306983

Epoch: 5| Step: 8
Training loss: 2.1449086666107178
Validation loss: 2.050935283303261

Epoch: 5| Step: 9
Training loss: 2.1194584369659424
Validation loss: 2.0407497932513556

Epoch: 5| Step: 10
Training loss: 2.4778451919555664
Validation loss: 2.0443011224269867

Epoch: 5| Step: 11
Training loss: 2.4874329566955566
Validation loss: 2.0427402605613074

Epoch: 143| Step: 0
Training loss: 1.7785766124725342
Validation loss: 2.045744294921557

Epoch: 5| Step: 1
Training loss: 2.2230520248413086
Validation loss: 2.0475996186335883

Epoch: 5| Step: 2
Training loss: 1.986936330795288
Validation loss: 2.0446960628032684

Epoch: 5| Step: 3
Training loss: 1.9444373846054077
Validation loss: 2.0549851010243096

Epoch: 5| Step: 4
Training loss: 1.4565788507461548
Validation loss: 2.0446352710326514

Epoch: 5| Step: 5
Training loss: 1.9774284362792969
Validation loss: 2.04862387975057

Epoch: 5| Step: 6
Training loss: 2.4574356079101562
Validation loss: 2.0546250144640603

Epoch: 5| Step: 7
Training loss: 2.091141939163208
Validation loss: 2.047971487045288

Epoch: 5| Step: 8
Training loss: 2.285693645477295
Validation loss: 2.0518556783596673

Epoch: 5| Step: 9
Training loss: 2.3615689277648926
Validation loss: 2.0524326463540397

Epoch: 5| Step: 10
Training loss: 2.314661979675293
Validation loss: 2.0472792039314904

Epoch: 5| Step: 11
Training loss: 1.3079252243041992
Validation loss: 2.0449704925219216

Epoch: 144| Step: 0
Training loss: 2.2779152393341064
Validation loss: 2.047493482629458

Epoch: 5| Step: 1
Training loss: 1.7608213424682617
Validation loss: 2.0323193868001304

Epoch: 5| Step: 2
Training loss: 1.7888555526733398
Validation loss: 2.0482510377963385

Epoch: 5| Step: 3
Training loss: 1.7700048685073853
Validation loss: 2.0436020294825235

Epoch: 5| Step: 4
Training loss: 2.3773601055145264
Validation loss: 2.0397971669832864

Epoch: 5| Step: 5
Training loss: 1.8140690326690674
Validation loss: 2.0412221203247705

Epoch: 5| Step: 6
Training loss: 2.28593373298645
Validation loss: 2.0372537871201835

Epoch: 5| Step: 7
Training loss: 1.9357013702392578
Validation loss: 2.046903798977534

Epoch: 5| Step: 8
Training loss: 2.3691165447235107
Validation loss: 2.045260488986969

Epoch: 5| Step: 9
Training loss: 2.3057363033294678
Validation loss: 2.0394424150387445

Epoch: 5| Step: 10
Training loss: 2.0363001823425293
Validation loss: 2.0337686191002526

Epoch: 5| Step: 11
Training loss: 2.3702361583709717
Validation loss: 2.034487600127856

Epoch: 145| Step: 0
Training loss: 1.8060665130615234
Validation loss: 2.0374209135770798

Epoch: 5| Step: 1
Training loss: 2.071726083755493
Validation loss: 2.0363430927197137

Epoch: 5| Step: 2
Training loss: 2.0589191913604736
Validation loss: 2.028232624133428

Epoch: 5| Step: 3
Training loss: 2.5210793018341064
Validation loss: 2.039455220103264

Epoch: 5| Step: 4
Training loss: 1.5961706638336182
Validation loss: 2.051965440313021

Epoch: 5| Step: 5
Training loss: 2.2485437393188477
Validation loss: 2.048224295179049

Epoch: 5| Step: 6
Training loss: 2.0987801551818848
Validation loss: 2.0479905555645623

Epoch: 5| Step: 7
Training loss: 2.4076695442199707
Validation loss: 2.043146679798762

Epoch: 5| Step: 8
Training loss: 2.277182102203369
Validation loss: 2.0417386442422867

Epoch: 5| Step: 9
Training loss: 2.1328892707824707
Validation loss: 2.0413959374030433

Epoch: 5| Step: 10
Training loss: 2.021907091140747
Validation loss: 2.0373316258192062

Epoch: 5| Step: 11
Training loss: 2.603858470916748
Validation loss: 2.03109277288119

Epoch: 146| Step: 0
Training loss: 2.160344362258911
Validation loss: 2.030230075120926

Epoch: 5| Step: 1
Training loss: 2.2128853797912598
Validation loss: 2.029461825887362

Epoch: 5| Step: 2
Training loss: 2.1733078956604004
Validation loss: 2.026729941368103

Epoch: 5| Step: 3
Training loss: 2.328575611114502
Validation loss: 2.0282801489035287

Epoch: 5| Step: 4
Training loss: 1.8247989416122437
Validation loss: 2.022583390275637

Epoch: 5| Step: 5
Training loss: 1.654815912246704
Validation loss: 2.018570691347122

Epoch: 5| Step: 6
Training loss: 2.5093994140625
Validation loss: 2.0264949252208075

Epoch: 5| Step: 7
Training loss: 2.5473544597625732
Validation loss: 2.033707097172737

Epoch: 5| Step: 8
Training loss: 1.9094493389129639
Validation loss: 2.0477969447771707

Epoch: 5| Step: 9
Training loss: 1.6903924942016602
Validation loss: 2.049078017473221

Epoch: 5| Step: 10
Training loss: 1.839734673500061
Validation loss: 2.0560446033875146

Epoch: 5| Step: 11
Training loss: 2.155785322189331
Validation loss: 2.0605679055054984

Epoch: 147| Step: 0
Training loss: 2.2862448692321777
Validation loss: 2.0514013717571893

Epoch: 5| Step: 1
Training loss: 2.2418620586395264
Validation loss: 2.0493003825346627

Epoch: 5| Step: 2
Training loss: 2.2091152667999268
Validation loss: 2.058976724743843

Epoch: 5| Step: 3
Training loss: 1.6264005899429321
Validation loss: 2.0519208858410516

Epoch: 5| Step: 4
Training loss: 2.5930206775665283
Validation loss: 2.0469968020915985

Epoch: 5| Step: 5
Training loss: 2.786923885345459
Validation loss: 2.0534896701574326

Epoch: 5| Step: 6
Training loss: 2.179105281829834
Validation loss: 2.050031989812851

Epoch: 5| Step: 7
Training loss: 1.221213936805725
Validation loss: 2.0453294118245444

Epoch: 5| Step: 8
Training loss: 1.4923261404037476
Validation loss: 2.055539603034655

Epoch: 5| Step: 9
Training loss: 2.3230843544006348
Validation loss: 2.043590153257052

Epoch: 5| Step: 10
Training loss: 1.7456159591674805
Validation loss: 2.0567728877067566

Epoch: 5| Step: 11
Training loss: 2.9957070350646973
Validation loss: 2.046989917755127

Epoch: 148| Step: 0
Training loss: 1.7964388132095337
Validation loss: 2.0532579720020294

Epoch: 5| Step: 1
Training loss: 2.3245973587036133
Validation loss: 2.0595561464627585

Epoch: 5| Step: 2
Training loss: 2.8196113109588623
Validation loss: 2.050711547334989

Epoch: 5| Step: 3
Training loss: 1.7132213115692139
Validation loss: 2.0536485662062964

Epoch: 5| Step: 4
Training loss: 1.9225480556488037
Validation loss: 2.044119670987129

Epoch: 5| Step: 5
Training loss: 1.950446367263794
Validation loss: 2.053561424215635

Epoch: 5| Step: 6
Training loss: 2.149735927581787
Validation loss: 2.0481675962607064

Epoch: 5| Step: 7
Training loss: 1.4438550472259521
Validation loss: 2.0534440179665885

Epoch: 5| Step: 8
Training loss: 2.0803518295288086
Validation loss: 2.0479956765969596

Epoch: 5| Step: 9
Training loss: 1.9763057231903076
Validation loss: 2.0478712916374207

Epoch: 5| Step: 10
Training loss: 2.450639247894287
Validation loss: 2.0499919950962067

Epoch: 5| Step: 11
Training loss: 2.6728029251098633
Validation loss: 2.0552098701397576

Epoch: 149| Step: 0
Training loss: 1.960944414138794
Validation loss: 2.051319102446238

Epoch: 5| Step: 1
Training loss: 1.712423324584961
Validation loss: 2.0501731584469476

Epoch: 5| Step: 2
Training loss: 2.2248828411102295
Validation loss: 2.05095674097538

Epoch: 5| Step: 3
Training loss: 1.8721898794174194
Validation loss: 2.0468119035164514

Epoch: 5| Step: 4
Training loss: 2.2029480934143066
Validation loss: 2.041807303826014

Epoch: 5| Step: 5
Training loss: 1.767394781112671
Validation loss: 2.0463107377290726

Epoch: 5| Step: 6
Training loss: 2.073429584503174
Validation loss: 2.0531218151251474

Epoch: 5| Step: 7
Training loss: 1.9759079217910767
Validation loss: 2.0517868399620056

Epoch: 5| Step: 8
Training loss: 2.4869065284729004
Validation loss: 2.045065477490425

Epoch: 5| Step: 9
Training loss: 2.4939305782318115
Validation loss: 2.0490993509689965

Epoch: 5| Step: 10
Training loss: 2.0039820671081543
Validation loss: 2.0361268122990928

Epoch: 5| Step: 11
Training loss: 1.6169732809066772
Validation loss: 2.033594990770022

Epoch: 150| Step: 0
Training loss: 1.9121183156967163
Validation loss: 2.03790682554245

Epoch: 5| Step: 1
Training loss: 1.8809318542480469
Validation loss: 2.043526351451874

Epoch: 5| Step: 2
Training loss: 2.2977514266967773
Validation loss: 2.03731632232666

Epoch: 5| Step: 3
Training loss: 2.4811851978302
Validation loss: 2.0431778033574424

Epoch: 5| Step: 4
Training loss: 1.898705244064331
Validation loss: 2.03884024421374

Epoch: 5| Step: 5
Training loss: 1.8644987344741821
Validation loss: 2.0400226712226868

Epoch: 5| Step: 6
Training loss: 2.3302674293518066
Validation loss: 2.035232717792193

Epoch: 5| Step: 7
Training loss: 2.0291812419891357
Validation loss: 2.0474530508120856

Epoch: 5| Step: 8
Training loss: 2.5499842166900635
Validation loss: 2.0443981985251107

Epoch: 5| Step: 9
Training loss: 1.9585567712783813
Validation loss: 2.0404189775387445

Epoch: 5| Step: 10
Training loss: 2.2388854026794434
Validation loss: 2.039035732547442

Epoch: 5| Step: 11
Training loss: 1.8349969387054443
Validation loss: 2.03959451119105

Epoch: 151| Step: 0
Training loss: 1.8348352909088135
Validation loss: 2.038390884796778

Epoch: 5| Step: 1
Training loss: 2.314157247543335
Validation loss: 2.0358912299076715

Epoch: 5| Step: 2
Training loss: 2.1482975482940674
Validation loss: 2.030094454685847

Epoch: 5| Step: 3
Training loss: 2.061819553375244
Validation loss: 2.0292077412207923

Epoch: 5| Step: 4
Training loss: 1.6329046487808228
Validation loss: 2.036711851755778

Epoch: 5| Step: 5
Training loss: 2.3625645637512207
Validation loss: 2.043881664673487

Epoch: 5| Step: 6
Training loss: 1.713159203529358
Validation loss: 2.042447676261266

Epoch: 5| Step: 7
Training loss: 2.6778531074523926
Validation loss: 2.054488847653071

Epoch: 5| Step: 8
Training loss: 2.0303733348846436
Validation loss: 2.0511352866888046

Epoch: 5| Step: 9
Training loss: 2.565821409225464
Validation loss: 2.0739617546399436

Epoch: 5| Step: 10
Training loss: 1.7901184558868408
Validation loss: 2.0725677410761514

Epoch: 5| Step: 11
Training loss: 1.8328357934951782
Validation loss: 2.066170205672582

Epoch: 152| Step: 0
Training loss: 2.0444540977478027
Validation loss: 2.049890990058581

Epoch: 5| Step: 1
Training loss: 1.3412872552871704
Validation loss: 2.033074622352918

Epoch: 5| Step: 2
Training loss: 2.33625864982605
Validation loss: 2.0254576752583184

Epoch: 5| Step: 3
Training loss: 2.2265989780426025
Validation loss: 2.040392274657885

Epoch: 5| Step: 4
Training loss: 1.9070851802825928
Validation loss: 2.0348980327447257

Epoch: 5| Step: 5
Training loss: 2.6824989318847656
Validation loss: 2.0379956364631653

Epoch: 5| Step: 6
Training loss: 2.0929274559020996
Validation loss: 2.0439795901377997

Epoch: 5| Step: 7
Training loss: 2.4606940746307373
Validation loss: 2.047563155492147

Epoch: 5| Step: 8
Training loss: 2.119809865951538
Validation loss: 2.037143722176552

Epoch: 5| Step: 9
Training loss: 1.9481273889541626
Validation loss: 2.0399290174245834

Epoch: 5| Step: 10
Training loss: 1.8612496852874756
Validation loss: 2.0354285885890326

Epoch: 5| Step: 11
Training loss: 2.10976505279541
Validation loss: 2.0430756161610284

Epoch: 153| Step: 0
Training loss: 2.4550728797912598
Validation loss: 2.034603640437126

Epoch: 5| Step: 1
Training loss: 2.0606417655944824
Validation loss: 2.0434180547793708

Epoch: 5| Step: 2
Training loss: 2.017916202545166
Validation loss: 2.039472902814547

Epoch: 5| Step: 3
Training loss: 2.085139036178589
Validation loss: 2.0371833791335425

Epoch: 5| Step: 4
Training loss: 1.8687642812728882
Validation loss: 2.033012807369232

Epoch: 5| Step: 5
Training loss: 2.0745670795440674
Validation loss: 2.0250529249509177

Epoch: 5| Step: 6
Training loss: 2.479064464569092
Validation loss: 2.043492098649343

Epoch: 5| Step: 7
Training loss: 1.9058870077133179
Validation loss: 2.040000170469284

Epoch: 5| Step: 8
Training loss: 1.9868457317352295
Validation loss: 2.038153290748596

Epoch: 5| Step: 9
Training loss: 2.27551531791687
Validation loss: 2.0538010398546853

Epoch: 5| Step: 10
Training loss: 1.7700847387313843
Validation loss: 2.044723908106486

Epoch: 5| Step: 11
Training loss: 2.162061929702759
Validation loss: 2.056722571452459

Epoch: 154| Step: 0
Training loss: 2.2029802799224854
Validation loss: 2.054433450102806

Epoch: 5| Step: 1
Training loss: 2.739220380783081
Validation loss: 2.052723000446955

Epoch: 5| Step: 2
Training loss: 1.8099079132080078
Validation loss: 2.0540676017602286

Epoch: 5| Step: 3
Training loss: 2.0625510215759277
Validation loss: 2.046737859646479

Epoch: 5| Step: 4
Training loss: 1.2680516242980957
Validation loss: 2.059414396683375

Epoch: 5| Step: 5
Training loss: 2.1326045989990234
Validation loss: 2.0645364771286645

Epoch: 5| Step: 6
Training loss: 2.456068754196167
Validation loss: 2.065424437324206

Epoch: 5| Step: 7
Training loss: 2.035863161087036
Validation loss: 2.060165529449781

Epoch: 5| Step: 8
Training loss: 2.0752041339874268
Validation loss: 2.0550108750661216

Epoch: 5| Step: 9
Training loss: 2.154489755630493
Validation loss: 2.0547617822885513

Epoch: 5| Step: 10
Training loss: 2.1507866382598877
Validation loss: 2.0485879878203073

Epoch: 5| Step: 11
Training loss: 1.2350187301635742
Validation loss: 2.0625812063614526

Epoch: 155| Step: 0
Training loss: 2.268557071685791
Validation loss: 2.0557779669761658

Epoch: 5| Step: 1
Training loss: 1.9940874576568604
Validation loss: 2.056586037079493

Epoch: 5| Step: 2
Training loss: 2.333005428314209
Validation loss: 2.0461433629194894

Epoch: 5| Step: 3
Training loss: 2.3142406940460205
Validation loss: 2.054016664624214

Epoch: 5| Step: 4
Training loss: 1.8517563343048096
Validation loss: 2.0634420911471048

Epoch: 5| Step: 5
Training loss: 1.684962272644043
Validation loss: 2.0563813199599585

Epoch: 5| Step: 6
Training loss: 2.134765148162842
Validation loss: 2.057437300682068

Epoch: 5| Step: 7
Training loss: 1.8522655963897705
Validation loss: 2.056687374909719

Epoch: 5| Step: 8
Training loss: 1.9774322509765625
Validation loss: 2.063204621275266

Epoch: 5| Step: 9
Training loss: 2.282349109649658
Validation loss: 2.062886819243431

Epoch: 5| Step: 10
Training loss: 2.0484261512756348
Validation loss: 2.0550545354684195

Epoch: 5| Step: 11
Training loss: 1.8101238012313843
Validation loss: 2.056311880548795

Epoch: 156| Step: 0
Training loss: 1.781700849533081
Validation loss: 2.059491882721583

Epoch: 5| Step: 1
Training loss: 2.060624361038208
Validation loss: 2.059207320213318

Epoch: 5| Step: 2
Training loss: 2.228203773498535
Validation loss: 2.0676963329315186

Epoch: 5| Step: 3
Training loss: 1.8427423238754272
Validation loss: 2.063069904843966

Epoch: 5| Step: 4
Training loss: 2.273695468902588
Validation loss: 2.0728031347195306

Epoch: 5| Step: 5
Training loss: 1.5826777219772339
Validation loss: 2.0646318048238754

Epoch: 5| Step: 6
Training loss: 1.9324795007705688
Validation loss: 2.0635760724544525

Epoch: 5| Step: 7
Training loss: 2.076112747192383
Validation loss: 2.0501415729522705

Epoch: 5| Step: 8
Training loss: 2.343078851699829
Validation loss: 2.0636408030986786

Epoch: 5| Step: 9
Training loss: 2.5901756286621094
Validation loss: 2.060264895359675

Epoch: 5| Step: 10
Training loss: 1.7757488489151
Validation loss: 2.0627342412869134

Epoch: 5| Step: 11
Training loss: 2.0815367698669434
Validation loss: 2.0574227968851724

Epoch: 157| Step: 0
Training loss: 1.9522926807403564
Validation loss: 2.059872329235077

Epoch: 5| Step: 1
Training loss: 1.3583123683929443
Validation loss: 2.0614366879065833

Epoch: 5| Step: 2
Training loss: 1.4246118068695068
Validation loss: 2.0490949551264444

Epoch: 5| Step: 3
Training loss: 2.215223789215088
Validation loss: 2.054879978299141

Epoch: 5| Step: 4
Training loss: 2.4701385498046875
Validation loss: 2.062553952137629

Epoch: 5| Step: 5
Training loss: 2.039973020553589
Validation loss: 2.0662099421024323

Epoch: 5| Step: 6
Training loss: 2.0199809074401855
Validation loss: 2.0568916151920953

Epoch: 5| Step: 7
Training loss: 2.3248534202575684
Validation loss: 2.0515939692656198

Epoch: 5| Step: 8
Training loss: 2.835789680480957
Validation loss: 2.0578552385171256

Epoch: 5| Step: 9
Training loss: 1.9530220031738281
Validation loss: 2.0588907301425934

Epoch: 5| Step: 10
Training loss: 2.117126941680908
Validation loss: 2.0537292013565698

Epoch: 5| Step: 11
Training loss: 1.8502814769744873
Validation loss: 2.051962971687317

Epoch: 158| Step: 0
Training loss: 2.46551251411438
Validation loss: 2.045966938138008

Epoch: 5| Step: 1
Training loss: 1.9915927648544312
Validation loss: 2.0537156065305076

Epoch: 5| Step: 2
Training loss: 1.8781299591064453
Validation loss: 2.0525081058343253

Epoch: 5| Step: 3
Training loss: 2.2122292518615723
Validation loss: 2.0449122885862985

Epoch: 5| Step: 4
Training loss: 2.544088840484619
Validation loss: 2.0443827460209527

Epoch: 5| Step: 5
Training loss: 1.6981899738311768
Validation loss: 2.045390248298645

Epoch: 5| Step: 6
Training loss: 1.8523404598236084
Validation loss: 2.0536617984374366

Epoch: 5| Step: 7
Training loss: 2.119856357574463
Validation loss: 2.051456262667974

Epoch: 5| Step: 8
Training loss: 2.1756155490875244
Validation loss: 2.061738053957621

Epoch: 5| Step: 9
Training loss: 2.2485482692718506
Validation loss: 2.052444944779078

Epoch: 5| Step: 10
Training loss: 1.7110445499420166
Validation loss: 2.0553108602762222

Epoch: 5| Step: 11
Training loss: 1.0113792419433594
Validation loss: 2.0497254729270935

Epoch: 159| Step: 0
Training loss: 1.9860012531280518
Validation loss: 2.0682716220617294

Epoch: 5| Step: 1
Training loss: 2.09391450881958
Validation loss: 2.0622522830963135

Epoch: 5| Step: 2
Training loss: 1.8757503032684326
Validation loss: 2.06324332455794

Epoch: 5| Step: 3
Training loss: 2.3098087310791016
Validation loss: 2.0740905900796256

Epoch: 5| Step: 4
Training loss: 1.8498430252075195
Validation loss: 2.0775084694226584

Epoch: 5| Step: 5
Training loss: 2.1001086235046387
Validation loss: 2.06994899113973

Epoch: 5| Step: 6
Training loss: 2.039795398712158
Validation loss: 2.069748123486837

Epoch: 5| Step: 7
Training loss: 1.4312121868133545
Validation loss: 2.064647967616717

Epoch: 5| Step: 8
Training loss: 2.527742862701416
Validation loss: 2.0553138703107834

Epoch: 5| Step: 9
Training loss: 2.0953099727630615
Validation loss: 2.0622861882050834

Epoch: 5| Step: 10
Training loss: 2.086183786392212
Validation loss: 2.0564178228378296

Epoch: 5| Step: 11
Training loss: 1.9549461603164673
Validation loss: 2.0578047235806785

Epoch: 160| Step: 0
Training loss: 2.1464593410491943
Validation loss: 2.048418253660202

Epoch: 5| Step: 1
Training loss: 2.2518742084503174
Validation loss: 2.0475605030854545

Epoch: 5| Step: 2
Training loss: 1.9771976470947266
Validation loss: 2.0545147309700647

Epoch: 5| Step: 3
Training loss: 2.312793493270874
Validation loss: 2.055021658539772

Epoch: 5| Step: 4
Training loss: 1.8299493789672852
Validation loss: 2.0585754414399466

Epoch: 5| Step: 5
Training loss: 2.1761035919189453
Validation loss: 2.049960563580195

Epoch: 5| Step: 6
Training loss: 2.1244595050811768
Validation loss: 2.0485741943120956

Epoch: 5| Step: 7
Training loss: 1.7452385425567627
Validation loss: 2.056081155935923

Epoch: 5| Step: 8
Training loss: 1.7366440296173096
Validation loss: 2.06034646431605

Epoch: 5| Step: 9
Training loss: 1.7332136631011963
Validation loss: 2.060085872809092

Epoch: 5| Step: 10
Training loss: 2.4012696743011475
Validation loss: 2.0539728800455728

Epoch: 5| Step: 11
Training loss: 1.6169861555099487
Validation loss: 2.0627779215574265

Epoch: 161| Step: 0
Training loss: 2.1076741218566895
Validation loss: 2.0724008679389954

Epoch: 5| Step: 1
Training loss: 1.921050786972046
Validation loss: 2.063110480705897

Epoch: 5| Step: 2
Training loss: 1.8940664529800415
Validation loss: 2.0642928580443063

Epoch: 5| Step: 3
Training loss: 2.066154956817627
Validation loss: 2.057224993904432

Epoch: 5| Step: 4
Training loss: 2.217580795288086
Validation loss: 2.0546028514703116

Epoch: 5| Step: 5
Training loss: 2.3465309143066406
Validation loss: 2.066808730363846

Epoch: 5| Step: 6
Training loss: 2.2695822715759277
Validation loss: 2.0531372676293054

Epoch: 5| Step: 7
Training loss: 2.156334400177002
Validation loss: 2.057764232158661

Epoch: 5| Step: 8
Training loss: 1.8126246929168701
Validation loss: 2.0665038724740348

Epoch: 5| Step: 9
Training loss: 1.8014789819717407
Validation loss: 2.0546772529681525

Epoch: 5| Step: 10
Training loss: 1.6010541915893555
Validation loss: 2.0633506973584494

Epoch: 5| Step: 11
Training loss: 2.81406307220459
Validation loss: 2.0529050081968307

Epoch: 162| Step: 0
Training loss: 2.125701427459717
Validation loss: 2.0519504696130753

Epoch: 5| Step: 1
Training loss: 1.9723964929580688
Validation loss: 2.0446814397970834

Epoch: 5| Step: 2
Training loss: 2.4702866077423096
Validation loss: 2.0594522009293237

Epoch: 5| Step: 3
Training loss: 2.544642210006714
Validation loss: 2.0567726492881775

Epoch: 5| Step: 4
Training loss: 2.1041901111602783
Validation loss: 2.042975236972173

Epoch: 5| Step: 5
Training loss: 1.812567949295044
Validation loss: 2.044611637790998

Epoch: 5| Step: 6
Training loss: 1.8339236974716187
Validation loss: 2.059758106867472

Epoch: 5| Step: 7
Training loss: 2.3695499897003174
Validation loss: 2.058641110857328

Epoch: 5| Step: 8
Training loss: 1.7307891845703125
Validation loss: 2.0606962144374847

Epoch: 5| Step: 9
Training loss: 1.4079177379608154
Validation loss: 2.053722158074379

Epoch: 5| Step: 10
Training loss: 1.8691208362579346
Validation loss: 2.0635058879852295

Epoch: 5| Step: 11
Training loss: 2.906442642211914
Validation loss: 2.059902628262838

Epoch: 163| Step: 0
Training loss: 2.04470157623291
Validation loss: 2.0596647361914315

Epoch: 5| Step: 1
Training loss: 1.8942577838897705
Validation loss: 2.065037419398626

Epoch: 5| Step: 2
Training loss: 2.47794771194458
Validation loss: 2.0604800085226693

Epoch: 5| Step: 3
Training loss: 1.994957685470581
Validation loss: 2.056504095594088

Epoch: 5| Step: 4
Training loss: 2.433189868927002
Validation loss: 2.0579613695542016

Epoch: 5| Step: 5
Training loss: 1.8296390771865845
Validation loss: 2.056963101029396

Epoch: 5| Step: 6
Training loss: 1.9392913579940796
Validation loss: 2.055983786781629

Epoch: 5| Step: 7
Training loss: 1.7553552389144897
Validation loss: 2.0533457348744073

Epoch: 5| Step: 8
Training loss: 2.1983513832092285
Validation loss: 2.059581329425176

Epoch: 5| Step: 9
Training loss: 1.6554151773452759
Validation loss: 2.061775431036949

Epoch: 5| Step: 10
Training loss: 2.513838768005371
Validation loss: 2.0587292263905206

Epoch: 5| Step: 11
Training loss: 0.4724457561969757
Validation loss: 2.06527940928936

Epoch: 164| Step: 0
Training loss: 2.2230896949768066
Validation loss: 2.0521582613388696

Epoch: 5| Step: 1
Training loss: 1.9448169469833374
Validation loss: 2.0590915977954865

Epoch: 5| Step: 2
Training loss: 2.288472890853882
Validation loss: 2.0623925675948462

Epoch: 5| Step: 3
Training loss: 1.613986611366272
Validation loss: 2.0714395940303802

Epoch: 5| Step: 4
Training loss: 1.992968201637268
Validation loss: 2.0758452912171683

Epoch: 5| Step: 5
Training loss: 2.290825605392456
Validation loss: 2.07272677620252

Epoch: 5| Step: 6
Training loss: 2.556764841079712
Validation loss: 2.066811040043831

Epoch: 5| Step: 7
Training loss: 1.7392959594726562
Validation loss: 2.0574009716510773

Epoch: 5| Step: 8
Training loss: 2.143990993499756
Validation loss: 2.0604223857323327

Epoch: 5| Step: 9
Training loss: 1.9358783960342407
Validation loss: 2.0634917269150415

Epoch: 5| Step: 10
Training loss: 1.8751217126846313
Validation loss: 2.060511037707329

Epoch: 5| Step: 11
Training loss: 1.3603228330612183
Validation loss: 2.0607518553733826

Epoch: 165| Step: 0
Training loss: 1.6686420440673828
Validation loss: 2.0598433862129846

Epoch: 5| Step: 1
Training loss: 2.4672160148620605
Validation loss: 2.0564591586589813

Epoch: 5| Step: 2
Training loss: 2.0640461444854736
Validation loss: 2.0612765550613403

Epoch: 5| Step: 3
Training loss: 1.8739608526229858
Validation loss: 2.0543907632430396

Epoch: 5| Step: 4
Training loss: 1.5767313241958618
Validation loss: 2.0665194193522134

Epoch: 5| Step: 5
Training loss: 1.7500636577606201
Validation loss: 2.0706347723801932

Epoch: 5| Step: 6
Training loss: 2.015784978866577
Validation loss: 2.055504565437635

Epoch: 5| Step: 7
Training loss: 2.420346975326538
Validation loss: 2.061420420805613

Epoch: 5| Step: 8
Training loss: 1.9602676630020142
Validation loss: 2.0675168931484222

Epoch: 5| Step: 9
Training loss: 2.4447474479675293
Validation loss: 2.0756095399459205

Epoch: 5| Step: 10
Training loss: 2.0427584648132324
Validation loss: 2.0597208191951117

Epoch: 5| Step: 11
Training loss: 2.152024030685425
Validation loss: 2.045719563961029

Epoch: 166| Step: 0
Training loss: 1.5731446743011475
Validation loss: 2.063995192448298

Epoch: 5| Step: 1
Training loss: 2.373889446258545
Validation loss: 2.054861838618914

Epoch: 5| Step: 2
Training loss: 1.8508293628692627
Validation loss: 2.056253969669342

Epoch: 5| Step: 3
Training loss: 2.4266273975372314
Validation loss: 2.0528542399406433

Epoch: 5| Step: 4
Training loss: 1.9314079284667969
Validation loss: 2.067191888888677

Epoch: 5| Step: 5
Training loss: 2.0486130714416504
Validation loss: 2.068112388253212

Epoch: 5| Step: 6
Training loss: 1.9551503658294678
Validation loss: 2.063274770975113

Epoch: 5| Step: 7
Training loss: 1.976453423500061
Validation loss: 2.061143880089124

Epoch: 5| Step: 8
Training loss: 2.1460530757904053
Validation loss: 2.066945711771647

Epoch: 5| Step: 9
Training loss: 2.425348997116089
Validation loss: 2.0657846381266913

Epoch: 5| Step: 10
Training loss: 1.7995437383651733
Validation loss: 2.0645845433076224

Epoch: 5| Step: 11
Training loss: 0.9805563688278198
Validation loss: 2.063561831911405

Epoch: 167| Step: 0
Training loss: 1.5684128999710083
Validation loss: 2.0620944499969482

Epoch: 5| Step: 1
Training loss: 2.121218681335449
Validation loss: 2.0567094832658768

Epoch: 5| Step: 2
Training loss: 2.0534207820892334
Validation loss: 2.0676100055376687

Epoch: 5| Step: 3
Training loss: 2.208653688430786
Validation loss: 2.065401464700699

Epoch: 5| Step: 4
Training loss: 1.902062177658081
Validation loss: 2.0734970569610596

Epoch: 5| Step: 5
Training loss: 2.56941556930542
Validation loss: 2.0754056672255197

Epoch: 5| Step: 6
Training loss: 1.7931709289550781
Validation loss: 2.0655712137619653

Epoch: 5| Step: 7
Training loss: 2.321384906768799
Validation loss: 2.0689383347829184

Epoch: 5| Step: 8
Training loss: 1.6309703588485718
Validation loss: 2.074459026257197

Epoch: 5| Step: 9
Training loss: 1.7616453170776367
Validation loss: 2.0644729832808175

Epoch: 5| Step: 10
Training loss: 2.2612791061401367
Validation loss: 2.0657288233439126

Epoch: 5| Step: 11
Training loss: 2.7617063522338867
Validation loss: 2.0554030189911523

Epoch: 168| Step: 0
Training loss: 2.243699312210083
Validation loss: 2.049243917067846

Epoch: 5| Step: 1
Training loss: 1.879717230796814
Validation loss: 2.0448122123877206

Epoch: 5| Step: 2
Training loss: 2.251526355743408
Validation loss: 2.0465196619431176

Epoch: 5| Step: 3
Training loss: 2.351731777191162
Validation loss: 2.0455879966417947

Epoch: 5| Step: 4
Training loss: 1.6880117654800415
Validation loss: 2.0493119806051254

Epoch: 5| Step: 5
Training loss: 1.5631792545318604
Validation loss: 2.0472822785377502

Epoch: 5| Step: 6
Training loss: 2.0597243309020996
Validation loss: 2.045706952611605

Epoch: 5| Step: 7
Training loss: 2.055619716644287
Validation loss: 2.0431677301724753

Epoch: 5| Step: 8
Training loss: 2.0297627449035645
Validation loss: 2.038040190935135

Epoch: 5| Step: 9
Training loss: 2.4518001079559326
Validation loss: 2.0523432393868766

Epoch: 5| Step: 10
Training loss: 2.3280794620513916
Validation loss: 2.054463103413582

Epoch: 5| Step: 11
Training loss: 2.1123907566070557
Validation loss: 2.0601985404888787

Epoch: 169| Step: 0
Training loss: 1.5506422519683838
Validation loss: 2.0616582383712134

Epoch: 5| Step: 1
Training loss: 2.277067184448242
Validation loss: 2.069207717974981

Epoch: 5| Step: 2
Training loss: 1.922194242477417
Validation loss: 2.062870745857557

Epoch: 5| Step: 3
Training loss: 2.1012330055236816
Validation loss: 2.0603819340467453

Epoch: 5| Step: 4
Training loss: 1.5868135690689087
Validation loss: 2.054062848289808

Epoch: 5| Step: 5
Training loss: 2.3878653049468994
Validation loss: 2.0448238253593445

Epoch: 5| Step: 6
Training loss: 2.026691436767578
Validation loss: 2.0593030552069345

Epoch: 5| Step: 7
Training loss: 2.0474040508270264
Validation loss: 2.0577021092176437

Epoch: 5| Step: 8
Training loss: 2.18109393119812
Validation loss: 2.0584876586993537

Epoch: 5| Step: 9
Training loss: 2.4274160861968994
Validation loss: 2.0679352482159934

Epoch: 5| Step: 10
Training loss: 1.9479916095733643
Validation loss: 2.0659926931063333

Epoch: 5| Step: 11
Training loss: 1.786816120147705
Validation loss: 2.061020185550054

Epoch: 170| Step: 0
Training loss: 2.529568910598755
Validation loss: 2.050955146551132

Epoch: 5| Step: 1
Training loss: 2.4936530590057373
Validation loss: 2.0569769541422525

Epoch: 5| Step: 2
Training loss: 1.7808551788330078
Validation loss: 2.062933787703514

Epoch: 5| Step: 3
Training loss: 2.0680031776428223
Validation loss: 2.054183383782705

Epoch: 5| Step: 4
Training loss: 2.097949504852295
Validation loss: 2.0514141619205475

Epoch: 5| Step: 5
Training loss: 2.0516207218170166
Validation loss: 2.055544098218282

Epoch: 5| Step: 6
Training loss: 2.088061809539795
Validation loss: 2.0521066735188165

Epoch: 5| Step: 7
Training loss: 1.6832164525985718
Validation loss: 2.0587103962898254

Epoch: 5| Step: 8
Training loss: 1.8779159784317017
Validation loss: 2.063080444931984

Epoch: 5| Step: 9
Training loss: 2.129354953765869
Validation loss: 2.067719096938769

Epoch: 5| Step: 10
Training loss: 1.606076955795288
Validation loss: 2.058729827404022

Epoch: 5| Step: 11
Training loss: 1.8274197578430176
Validation loss: 2.064424936970075

Epoch: 171| Step: 0
Training loss: 1.3767530918121338
Validation loss: 2.0588751435279846

Epoch: 5| Step: 1
Training loss: 1.8807084560394287
Validation loss: 2.0620235602060952

Epoch: 5| Step: 2
Training loss: 1.9364550113677979
Validation loss: 2.0666426519552865

Epoch: 5| Step: 3
Training loss: 1.7791246175765991
Validation loss: 2.062518467505773

Epoch: 5| Step: 4
Training loss: 1.9794666767120361
Validation loss: 2.0675121396780014

Epoch: 5| Step: 5
Training loss: 2.4928157329559326
Validation loss: 2.066952019929886

Epoch: 5| Step: 6
Training loss: 2.2926788330078125
Validation loss: 2.069071556131045

Epoch: 5| Step: 7
Training loss: 2.072103261947632
Validation loss: 2.0728984077771506

Epoch: 5| Step: 8
Training loss: 1.7183048725128174
Validation loss: 2.065564771493276

Epoch: 5| Step: 9
Training loss: 2.7550132274627686
Validation loss: 2.060771013299624

Epoch: 5| Step: 10
Training loss: 2.0702390670776367
Validation loss: 2.067610735694567

Epoch: 5| Step: 11
Training loss: 1.990339994430542
Validation loss: 2.066645155350367

Epoch: 172| Step: 0
Training loss: 1.8504705429077148
Validation loss: 2.057158042987188

Epoch: 5| Step: 1
Training loss: 1.711896538734436
Validation loss: 2.06297038992246

Epoch: 5| Step: 2
Training loss: 2.671095132827759
Validation loss: 2.043582151333491

Epoch: 5| Step: 3
Training loss: 2.2530717849731445
Validation loss: 2.045727680126826

Epoch: 5| Step: 4
Training loss: 1.7956374883651733
Validation loss: 2.049968178073565

Epoch: 5| Step: 5
Training loss: 2.459254503250122
Validation loss: 2.0425326923529306

Epoch: 5| Step: 6
Training loss: 2.085484266281128
Validation loss: 2.04510727028052

Epoch: 5| Step: 7
Training loss: 1.8128420114517212
Validation loss: 2.0417540023724237

Epoch: 5| Step: 8
Training loss: 2.17439341545105
Validation loss: 2.0401504933834076

Epoch: 5| Step: 9
Training loss: 2.4475173950195312
Validation loss: 2.0363786617914834

Epoch: 5| Step: 10
Training loss: 1.5610651969909668
Validation loss: 2.04790028433005

Epoch: 5| Step: 11
Training loss: 2.6049256324768066
Validation loss: 2.0549056828022003

Epoch: 173| Step: 0
Training loss: 1.8416248559951782
Validation loss: 2.0537138283252716

Epoch: 5| Step: 1
Training loss: 1.5735056400299072
Validation loss: 2.0599785447120667

Epoch: 5| Step: 2
Training loss: 2.032576560974121
Validation loss: 2.0713463127613068

Epoch: 5| Step: 3
Training loss: 2.5790233612060547
Validation loss: 2.0714600682258606

Epoch: 5| Step: 4
Training loss: 2.2540810108184814
Validation loss: 2.0773197263479233

Epoch: 5| Step: 5
Training loss: 2.5662522315979004
Validation loss: 2.078567033012708

Epoch: 5| Step: 6
Training loss: 2.384504556655884
Validation loss: 2.0787452707688012

Epoch: 5| Step: 7
Training loss: 2.1555306911468506
Validation loss: 2.0672296583652496

Epoch: 5| Step: 8
Training loss: 1.949313759803772
Validation loss: 2.0670080929994583

Epoch: 5| Step: 9
Training loss: 1.3811830282211304
Validation loss: 2.0705634405215583

Epoch: 5| Step: 10
Training loss: 1.9449020624160767
Validation loss: 2.0684757182995477

Epoch: 5| Step: 11
Training loss: 1.7039268016815186
Validation loss: 2.072356656193733

Epoch: 174| Step: 0
Training loss: 1.6340935230255127
Validation loss: 2.066819762190183

Epoch: 5| Step: 1
Training loss: 1.6369762420654297
Validation loss: 2.0586751053730645

Epoch: 5| Step: 2
Training loss: 2.0736775398254395
Validation loss: 2.053950140873591

Epoch: 5| Step: 3
Training loss: 2.122976779937744
Validation loss: 2.068184564510981

Epoch: 5| Step: 4
Training loss: 1.8763240575790405
Validation loss: 2.065478245417277

Epoch: 5| Step: 5
Training loss: 1.9438495635986328
Validation loss: 2.0511010785897574

Epoch: 5| Step: 6
Training loss: 2.3394298553466797
Validation loss: 2.0561556170384088

Epoch: 5| Step: 7
Training loss: 2.603823184967041
Validation loss: 2.044754981994629

Epoch: 5| Step: 8
Training loss: 2.1825265884399414
Validation loss: 2.072600012024244

Epoch: 5| Step: 9
Training loss: 2.249213933944702
Validation loss: 2.07456802825133

Epoch: 5| Step: 10
Training loss: 1.672981858253479
Validation loss: 2.0715660651524863

Epoch: 5| Step: 11
Training loss: 1.5254130363464355
Validation loss: 2.0724859088659286

Epoch: 175| Step: 0
Training loss: 2.361262798309326
Validation loss: 2.065090075135231

Epoch: 5| Step: 1
Training loss: 2.1679117679595947
Validation loss: 2.0711936404307685

Epoch: 5| Step: 2
Training loss: 2.1026339530944824
Validation loss: 2.0602811922629676

Epoch: 5| Step: 3
Training loss: 2.4873886108398438
Validation loss: 2.0642272432645163

Epoch: 5| Step: 4
Training loss: 2.0801215171813965
Validation loss: 2.0512342751026154

Epoch: 5| Step: 5
Training loss: 2.1459240913391113
Validation loss: 2.051494151353836

Epoch: 5| Step: 6
Training loss: 2.0276002883911133
Validation loss: 2.0581360956033072

Epoch: 5| Step: 7
Training loss: 2.0653347969055176
Validation loss: 2.0554233541091285

Epoch: 5| Step: 8
Training loss: 1.4349695444107056
Validation loss: 2.05378927787145

Epoch: 5| Step: 9
Training loss: 1.7758057117462158
Validation loss: 2.0600233674049377

Epoch: 5| Step: 10
Training loss: 2.238687753677368
Validation loss: 2.0568473438421884

Epoch: 5| Step: 11
Training loss: 1.431685209274292
Validation loss: 2.060575485229492

Epoch: 176| Step: 0
Training loss: 2.793124198913574
Validation loss: 2.061088631550471

Epoch: 5| Step: 1
Training loss: 1.8150303363800049
Validation loss: 2.071173240741094

Epoch: 5| Step: 2
Training loss: 2.0155980587005615
Validation loss: 2.086517865459124

Epoch: 5| Step: 3
Training loss: 1.6513878107070923
Validation loss: 2.071678360303243

Epoch: 5| Step: 4
Training loss: 2.392317533493042
Validation loss: 2.0734512309233346

Epoch: 5| Step: 5
Training loss: 1.4086930751800537
Validation loss: 2.063073347012202

Epoch: 5| Step: 6
Training loss: 2.477464437484741
Validation loss: 2.058875327308973

Epoch: 5| Step: 7
Training loss: 1.7659927606582642
Validation loss: 2.0517433434724808

Epoch: 5| Step: 8
Training loss: 2.652801275253296
Validation loss: 2.053846592704455

Epoch: 5| Step: 9
Training loss: 2.233849048614502
Validation loss: 2.055073842406273

Epoch: 5| Step: 10
Training loss: 1.739524483680725
Validation loss: 2.0439695864915848

Epoch: 5| Step: 11
Training loss: 0.8924088478088379
Validation loss: 2.041858514149984

Epoch: 177| Step: 0
Training loss: 1.9814895391464233
Validation loss: 2.036890079577764

Epoch: 5| Step: 1
Training loss: 1.9314028024673462
Validation loss: 2.045861691236496

Epoch: 5| Step: 2
Training loss: 1.9197404384613037
Validation loss: 2.0341216127077737

Epoch: 5| Step: 3
Training loss: 2.415252208709717
Validation loss: 2.040037845571836

Epoch: 5| Step: 4
Training loss: 2.0788016319274902
Validation loss: 2.0395413090785346

Epoch: 5| Step: 5
Training loss: 1.86810302734375
Validation loss: 2.044595922032992

Epoch: 5| Step: 6
Training loss: 2.167004346847534
Validation loss: 2.0458916376034417

Epoch: 5| Step: 7
Training loss: 1.9124631881713867
Validation loss: 2.0507450004418692

Epoch: 5| Step: 8
Training loss: 1.9067684412002563
Validation loss: 2.0447144359350204

Epoch: 5| Step: 9
Training loss: 2.254716396331787
Validation loss: 2.0601446678241095

Epoch: 5| Step: 10
Training loss: 2.190528392791748
Validation loss: 2.0618597169717154

Epoch: 5| Step: 11
Training loss: 1.3238096237182617
Validation loss: 2.076091160376867

Epoch: 178| Step: 0
Training loss: 1.843287706375122
Validation loss: 2.0653842836618423

Epoch: 5| Step: 1
Training loss: 2.1061763763427734
Validation loss: 2.050095980366071

Epoch: 5| Step: 2
Training loss: 1.9353570938110352
Validation loss: 2.0636392335096994

Epoch: 5| Step: 3
Training loss: 2.3687736988067627
Validation loss: 2.067411075035731

Epoch: 5| Step: 4
Training loss: 2.0941176414489746
Validation loss: 2.058199112613996

Epoch: 5| Step: 5
Training loss: 1.1174813508987427
Validation loss: 2.0572102864583335

Epoch: 5| Step: 6
Training loss: 2.2019944190979004
Validation loss: 2.057571197549502

Epoch: 5| Step: 7
Training loss: 1.7309757471084595
Validation loss: 2.0529110580682755

Epoch: 5| Step: 8
Training loss: 2.498126745223999
Validation loss: 2.0562501748402915

Epoch: 5| Step: 9
Training loss: 2.526275634765625
Validation loss: 2.0585728834072747

Epoch: 5| Step: 10
Training loss: 2.2724761962890625
Validation loss: 2.0602775116761527

Epoch: 5| Step: 11
Training loss: 0.5331918001174927
Validation loss: 2.056083152691523

Epoch: 179| Step: 0
Training loss: 2.228193521499634
Validation loss: 2.059633473555247

Epoch: 5| Step: 1
Training loss: 2.1396162509918213
Validation loss: 2.061302120486895

Epoch: 5| Step: 2
Training loss: 2.806731700897217
Validation loss: 2.070079897840818

Epoch: 5| Step: 3
Training loss: 1.9163818359375
Validation loss: 2.0614949067433677

Epoch: 5| Step: 4
Training loss: 1.9652029275894165
Validation loss: 2.0708008060852685

Epoch: 5| Step: 5
Training loss: 1.8890116214752197
Validation loss: 2.065831243991852

Epoch: 5| Step: 6
Training loss: 1.65704345703125
Validation loss: 2.066274339954058

Epoch: 5| Step: 7
Training loss: 2.04765248298645
Validation loss: 2.0681902865568795

Epoch: 5| Step: 8
Training loss: 1.984551191329956
Validation loss: 2.067293365796407

Epoch: 5| Step: 9
Training loss: 1.9663833379745483
Validation loss: 2.07161974410216

Epoch: 5| Step: 10
Training loss: 1.7213176488876343
Validation loss: 2.0808064341545105

Epoch: 5| Step: 11
Training loss: 2.288668394088745
Validation loss: 2.073397467533747

Epoch: 180| Step: 0
Training loss: 2.0937488079071045
Validation loss: 2.065141881505648

Epoch: 5| Step: 1
Training loss: 2.144056797027588
Validation loss: 2.0627270440260568

Epoch: 5| Step: 2
Training loss: 2.2328410148620605
Validation loss: 2.057604362567266

Epoch: 5| Step: 3
Training loss: 2.368971347808838
Validation loss: 2.057683696349462

Epoch: 5| Step: 4
Training loss: 1.8884124755859375
Validation loss: 2.053458720445633

Epoch: 5| Step: 5
Training loss: 1.4267178773880005
Validation loss: 2.0440883288780847

Epoch: 5| Step: 6
Training loss: 1.7209761142730713
Validation loss: 2.0484988739093146

Epoch: 5| Step: 7
Training loss: 2.727898359298706
Validation loss: 2.052272250254949

Epoch: 5| Step: 8
Training loss: 1.6404037475585938
Validation loss: 2.0555954376856485

Epoch: 5| Step: 9
Training loss: 2.098583459854126
Validation loss: 2.054427449901899

Epoch: 5| Step: 10
Training loss: 2.1246185302734375
Validation loss: 2.057864581545194

Epoch: 5| Step: 11
Training loss: 1.5138651132583618
Validation loss: 2.060232535004616

Epoch: 181| Step: 0
Training loss: 1.8538650274276733
Validation loss: 2.0640106946229935

Epoch: 5| Step: 1
Training loss: 2.097801923751831
Validation loss: 2.061001072327296

Epoch: 5| Step: 2
Training loss: 2.7223706245422363
Validation loss: 2.0649414658546448

Epoch: 5| Step: 3
Training loss: 2.196424961090088
Validation loss: 2.0790754655996957

Epoch: 5| Step: 4
Training loss: 2.392014980316162
Validation loss: 2.0790572613477707

Epoch: 5| Step: 5
Training loss: 1.2891924381256104
Validation loss: 2.071447879076004

Epoch: 5| Step: 6
Training loss: 2.0494377613067627
Validation loss: 2.0710715850194297

Epoch: 5| Step: 7
Training loss: 1.967402696609497
Validation loss: 2.073731248577436

Epoch: 5| Step: 8
Training loss: 1.9400192499160767
Validation loss: 2.0716680387655892

Epoch: 5| Step: 9
Training loss: 2.120516300201416
Validation loss: 2.074582894643148

Epoch: 5| Step: 10
Training loss: 1.3923006057739258
Validation loss: 2.064961314201355

Epoch: 5| Step: 11
Training loss: 2.328749418258667
Validation loss: 2.071548024813334

Epoch: 182| Step: 0
Training loss: 1.6334302425384521
Validation loss: 2.0732188721497855

Epoch: 5| Step: 1
Training loss: 1.6446224451065063
Validation loss: 2.071285908420881

Epoch: 5| Step: 2
Training loss: 2.529433012008667
Validation loss: 2.0658566504716873

Epoch: 5| Step: 3
Training loss: 1.9493343830108643
Validation loss: 2.076430315772692

Epoch: 5| Step: 4
Training loss: 1.7455066442489624
Validation loss: 2.071621671319008

Epoch: 5| Step: 5
Training loss: 2.2798266410827637
Validation loss: 2.074514791369438

Epoch: 5| Step: 6
Training loss: 1.7915273904800415
Validation loss: 2.08080293238163

Epoch: 5| Step: 7
Training loss: 2.719956159591675
Validation loss: 2.074443146586418

Epoch: 5| Step: 8
Training loss: 1.9909698963165283
Validation loss: 2.071684276064237

Epoch: 5| Step: 9
Training loss: 1.3160487413406372
Validation loss: 2.0740537693103156

Epoch: 5| Step: 10
Training loss: 2.429677724838257
Validation loss: 2.0769441723823547

Epoch: 5| Step: 11
Training loss: 1.7846434116363525
Validation loss: 2.0790242751439414

Epoch: 183| Step: 0
Training loss: 2.0326335430145264
Validation loss: 2.067342425386111

Epoch: 5| Step: 1
Training loss: 1.8343406915664673
Validation loss: 2.0728980203469596

Epoch: 5| Step: 2
Training loss: 2.3382599353790283
Validation loss: 2.0740651289621987

Epoch: 5| Step: 3
Training loss: 1.9305366277694702
Validation loss: 2.06891268491745

Epoch: 5| Step: 4
Training loss: 1.766238808631897
Validation loss: 2.078591153025627

Epoch: 5| Step: 5
Training loss: 2.2554922103881836
Validation loss: 2.068320552508036

Epoch: 5| Step: 6
Training loss: 2.0956063270568848
Validation loss: 2.0718550781408944

Epoch: 5| Step: 7
Training loss: 1.6346447467803955
Validation loss: 2.0634286304314933

Epoch: 5| Step: 8
Training loss: 1.8334684371948242
Validation loss: 2.0675745209058127

Epoch: 5| Step: 9
Training loss: 2.319932460784912
Validation loss: 2.0659910341103873

Epoch: 5| Step: 10
Training loss: 1.8900638818740845
Validation loss: 2.0680664678414664

Epoch: 5| Step: 11
Training loss: 2.7445337772369385
Validation loss: 2.0661850770314536

Epoch: 184| Step: 0
Training loss: 2.038947343826294
Validation loss: 2.073947032292684

Epoch: 5| Step: 1
Training loss: 2.2049171924591064
Validation loss: 2.059923534591993

Epoch: 5| Step: 2
Training loss: 2.045457124710083
Validation loss: 2.0671478609244027

Epoch: 5| Step: 3
Training loss: 2.404777765274048
Validation loss: 2.062244484821955

Epoch: 5| Step: 4
Training loss: 1.5205485820770264
Validation loss: 2.0684068302313485

Epoch: 5| Step: 5
Training loss: 2.154632568359375
Validation loss: 2.0606981217861176

Epoch: 5| Step: 6
Training loss: 1.8316442966461182
Validation loss: 2.062780146797498

Epoch: 5| Step: 7
Training loss: 2.058053493499756
Validation loss: 2.076640526453654

Epoch: 5| Step: 8
Training loss: 1.783787488937378
Validation loss: 2.0755557169516883

Epoch: 5| Step: 9
Training loss: 1.914032220840454
Validation loss: 2.0624175667762756

Epoch: 5| Step: 10
Training loss: 1.899488091468811
Validation loss: 2.072887902458509

Epoch: 5| Step: 11
Training loss: 2.489360809326172
Validation loss: 2.06934488316377

Epoch: 185| Step: 0
Training loss: 2.2896177768707275
Validation loss: 2.0650187929471335

Epoch: 5| Step: 1
Training loss: 1.9877116680145264
Validation loss: 2.063655376434326

Epoch: 5| Step: 2
Training loss: 2.5526885986328125
Validation loss: 2.064642369747162

Epoch: 5| Step: 3
Training loss: 1.875327467918396
Validation loss: 2.058897236982981

Epoch: 5| Step: 4
Training loss: 1.7588346004486084
Validation loss: 2.0653196970621743

Epoch: 5| Step: 5
Training loss: 1.904089331626892
Validation loss: 2.058557167649269

Epoch: 5| Step: 6
Training loss: 1.5091568231582642
Validation loss: 2.060343106587728

Epoch: 5| Step: 7
Training loss: 2.1106925010681152
Validation loss: 2.0579012284676232

Epoch: 5| Step: 8
Training loss: 1.6051725149154663
Validation loss: 2.0599720825751624

Epoch: 5| Step: 9
Training loss: 2.313610076904297
Validation loss: 2.0546288192272186

Epoch: 5| Step: 10
Training loss: 2.493802070617676
Validation loss: 2.063497935732206

Epoch: 5| Step: 11
Training loss: 1.6705900430679321
Validation loss: 2.0677427550156913

Epoch: 186| Step: 0
Training loss: 1.2486450672149658
Validation loss: 2.06568052371343

Epoch: 5| Step: 1
Training loss: 1.5709261894226074
Validation loss: 2.0670591642459235

Epoch: 5| Step: 2
Training loss: 1.8828904628753662
Validation loss: 2.066068261861801

Epoch: 5| Step: 3
Training loss: 1.9625389575958252
Validation loss: 2.0665143678585687

Epoch: 5| Step: 4
Training loss: 2.312397003173828
Validation loss: 2.0744780798753104

Epoch: 5| Step: 5
Training loss: 2.124037504196167
Validation loss: 2.065693120161692

Epoch: 5| Step: 6
Training loss: 1.7442705631256104
Validation loss: 2.0859713902076087

Epoch: 5| Step: 7
Training loss: 2.6285016536712646
Validation loss: 2.065734604994456

Epoch: 5| Step: 8
Training loss: 2.3252384662628174
Validation loss: 2.1012621025244393

Epoch: 5| Step: 9
Training loss: 2.2525975704193115
Validation loss: 2.0936963856220245

Epoch: 5| Step: 10
Training loss: 2.450396776199341
Validation loss: 2.0631347646315894

Epoch: 5| Step: 11
Training loss: 1.3893852233886719
Validation loss: 2.065286969145139

Epoch: 187| Step: 0
Training loss: 2.2297637462615967
Validation loss: 2.0657991816600165

Epoch: 5| Step: 1
Training loss: 1.7264280319213867
Validation loss: 2.0573610166708627

Epoch: 5| Step: 2
Training loss: 2.561554193496704
Validation loss: 2.0597171237071357

Epoch: 5| Step: 3
Training loss: 2.0211169719696045
Validation loss: 2.0533929467201233

Epoch: 5| Step: 4
Training loss: 2.143033504486084
Validation loss: 2.0593874752521515

Epoch: 5| Step: 5
Training loss: 2.0003905296325684
Validation loss: 2.055819938580195

Epoch: 5| Step: 6
Training loss: 1.9980844259262085
Validation loss: 2.056652824083964

Epoch: 5| Step: 7
Training loss: 1.9773565530776978
Validation loss: 2.0501195738712945

Epoch: 5| Step: 8
Training loss: 2.0346333980560303
Validation loss: 2.0640627096096673

Epoch: 5| Step: 9
Training loss: 2.0333251953125
Validation loss: 2.0525791148344674

Epoch: 5| Step: 10
Training loss: 2.3472483158111572
Validation loss: 2.0568070660034814

Epoch: 5| Step: 11
Training loss: 1.6370534896850586
Validation loss: 2.05544513463974

Epoch: 188| Step: 0
Training loss: 2.031113386154175
Validation loss: 2.058015594879786

Epoch: 5| Step: 1
Training loss: 1.5565541982650757
Validation loss: 2.063671827316284

Epoch: 5| Step: 2
Training loss: 2.0586743354797363
Validation loss: 2.070795565843582

Epoch: 5| Step: 3
Training loss: 2.389965057373047
Validation loss: 2.0785737931728363

Epoch: 5| Step: 4
Training loss: 2.013314723968506
Validation loss: 2.0733589877684913

Epoch: 5| Step: 5
Training loss: 1.9243404865264893
Validation loss: 2.0721943775812783

Epoch: 5| Step: 6
Training loss: 2.038367509841919
Validation loss: 2.0776146948337555

Epoch: 5| Step: 7
Training loss: 2.2913658618927
Validation loss: 2.0871391743421555

Epoch: 5| Step: 8
Training loss: 1.9679248332977295
Validation loss: 2.0736876179774604

Epoch: 5| Step: 9
Training loss: 2.345004081726074
Validation loss: 2.0763833125432334

Epoch: 5| Step: 10
Training loss: 1.6786625385284424
Validation loss: 2.0754615565141044

Epoch: 5| Step: 11
Training loss: 1.9309501647949219
Validation loss: 2.0675659775733948

Epoch: 189| Step: 0
Training loss: 2.004058361053467
Validation loss: 2.0601741522550583

Epoch: 5| Step: 1
Training loss: 1.5262938737869263
Validation loss: 2.0708036025365195

Epoch: 5| Step: 2
Training loss: 2.463515043258667
Validation loss: 2.068113620082537

Epoch: 5| Step: 3
Training loss: 1.994272232055664
Validation loss: 2.0718069672584534

Epoch: 5| Step: 4
Training loss: 2.044212579727173
Validation loss: 2.0694093803564706

Epoch: 5| Step: 5
Training loss: 1.8295905590057373
Validation loss: 2.066740314165751

Epoch: 5| Step: 6
Training loss: 1.9007396697998047
Validation loss: 2.0736444741487503

Epoch: 5| Step: 7
Training loss: 2.4495301246643066
Validation loss: 2.075237904985746

Epoch: 5| Step: 8
Training loss: 2.065316915512085
Validation loss: 2.0741828829050064

Epoch: 5| Step: 9
Training loss: 1.625643014907837
Validation loss: 2.0831832389036813

Epoch: 5| Step: 10
Training loss: 2.179473876953125
Validation loss: 2.0799271961053214

Epoch: 5| Step: 11
Training loss: 1.9007185697555542
Validation loss: 2.072398910919825

Epoch: 190| Step: 0
Training loss: 1.8121639490127563
Validation loss: 2.075445835789045

Epoch: 5| Step: 1
Training loss: 1.9905649423599243
Validation loss: 2.082564870516459

Epoch: 5| Step: 2
Training loss: 2.033109664916992
Validation loss: 2.088982656598091

Epoch: 5| Step: 3
Training loss: 2.763146162033081
Validation loss: 2.077548921108246

Epoch: 5| Step: 4
Training loss: 2.272998332977295
Validation loss: 2.074583649635315

Epoch: 5| Step: 5
Training loss: 2.119767665863037
Validation loss: 2.0820638090372086

Epoch: 5| Step: 6
Training loss: 1.8166821002960205
Validation loss: 2.074898968140284

Epoch: 5| Step: 7
Training loss: 1.5609492063522339
Validation loss: 2.0795748432477317

Epoch: 5| Step: 8
Training loss: 2.037895679473877
Validation loss: 2.077203318476677

Epoch: 5| Step: 9
Training loss: 1.7000586986541748
Validation loss: 2.0677098830540976

Epoch: 5| Step: 10
Training loss: 2.211364269256592
Validation loss: 2.0781808495521545

Epoch: 5| Step: 11
Training loss: 1.150521993637085
Validation loss: 2.055181543032328

Epoch: 191| Step: 0
Training loss: 2.3144359588623047
Validation loss: 2.057208855946859

Epoch: 5| Step: 1
Training loss: 1.795392632484436
Validation loss: 2.0670237044493356

Epoch: 5| Step: 2
Training loss: 1.7818691730499268
Validation loss: 2.0676884154478707

Epoch: 5| Step: 3
Training loss: 2.339324474334717
Validation loss: 2.0661376814047494

Epoch: 5| Step: 4
Training loss: 2.24725341796875
Validation loss: 2.0632044027249017

Epoch: 5| Step: 5
Training loss: 1.9906622171401978
Validation loss: 2.073758512735367

Epoch: 5| Step: 6
Training loss: 2.112032890319824
Validation loss: 2.067161132891973

Epoch: 5| Step: 7
Training loss: 1.821420431137085
Validation loss: 2.07921036084493

Epoch: 5| Step: 8
Training loss: 1.8480373620986938
Validation loss: 2.076686436931292

Epoch: 5| Step: 9
Training loss: 2.1632447242736816
Validation loss: 2.0780959924062095

Epoch: 5| Step: 10
Training loss: 1.774685263633728
Validation loss: 2.068747798601786

Epoch: 5| Step: 11
Training loss: 1.563605785369873
Validation loss: 2.0683269699414573

Epoch: 192| Step: 0
Training loss: 2.289687395095825
Validation loss: 2.082213968038559

Epoch: 5| Step: 1
Training loss: 2.389615535736084
Validation loss: 2.076198478539785

Epoch: 5| Step: 2
Training loss: 1.7663007974624634
Validation loss: 2.0790412525335946

Epoch: 5| Step: 3
Training loss: 1.8349294662475586
Validation loss: 2.0764211465915046

Epoch: 5| Step: 4
Training loss: 1.909447431564331
Validation loss: 2.075466364622116

Epoch: 5| Step: 5
Training loss: 2.0266852378845215
Validation loss: 2.085585206747055

Epoch: 5| Step: 6
Training loss: 1.893911600112915
Validation loss: 2.0698214073975882

Epoch: 5| Step: 7
Training loss: 1.6343486309051514
Validation loss: 2.0832781990369162

Epoch: 5| Step: 8
Training loss: 2.0000948905944824
Validation loss: 2.0863079031308494

Epoch: 5| Step: 9
Training loss: 2.368882656097412
Validation loss: 2.0752221991618476

Epoch: 5| Step: 10
Training loss: 1.7894665002822876
Validation loss: 2.069351683060328

Epoch: 5| Step: 11
Training loss: 1.6656423807144165
Validation loss: 2.064572741587957

Epoch: 193| Step: 0
Training loss: 1.7383924722671509
Validation loss: 2.0841922064622245

Epoch: 5| Step: 1
Training loss: 1.8128677606582642
Validation loss: 2.0797678331534066

Epoch: 5| Step: 2
Training loss: 3.138293504714966
Validation loss: 2.079992617170016

Epoch: 5| Step: 3
Training loss: 2.113816738128662
Validation loss: 2.076127062241236

Epoch: 5| Step: 4
Training loss: 1.803175926208496
Validation loss: 2.0751271694898605

Epoch: 5| Step: 5
Training loss: 1.5987862348556519
Validation loss: 2.074897532661756

Epoch: 5| Step: 6
Training loss: 2.242380380630493
Validation loss: 2.0855892995993295

Epoch: 5| Step: 7
Training loss: 1.8994762897491455
Validation loss: 2.078436662753423

Epoch: 5| Step: 8
Training loss: 2.315147638320923
Validation loss: 2.0754659324884415

Epoch: 5| Step: 9
Training loss: 1.9795417785644531
Validation loss: 2.0738472640514374

Epoch: 5| Step: 10
Training loss: 1.294420599937439
Validation loss: 2.082027013103167

Epoch: 5| Step: 11
Training loss: 1.5800204277038574
Validation loss: 2.0777939011653266

Epoch: 194| Step: 0
Training loss: 2.055996894836426
Validation loss: 2.0726943711439767

Epoch: 5| Step: 1
Training loss: 1.6540679931640625
Validation loss: 2.069762349128723

Epoch: 5| Step: 2
Training loss: 2.0645763874053955
Validation loss: 2.094786827762922

Epoch: 5| Step: 3
Training loss: 1.9207614660263062
Validation loss: 2.087794785698255

Epoch: 5| Step: 4
Training loss: 2.247157573699951
Validation loss: 2.0848105599482856

Epoch: 5| Step: 5
Training loss: 2.08492374420166
Validation loss: 2.082590475678444

Epoch: 5| Step: 6
Training loss: 1.5667610168457031
Validation loss: 2.077540715535482

Epoch: 5| Step: 7
Training loss: 1.9500948190689087
Validation loss: 2.0922461102406182

Epoch: 5| Step: 8
Training loss: 2.182537078857422
Validation loss: 2.0855737725893655

Epoch: 5| Step: 9
Training loss: 2.0491089820861816
Validation loss: 2.0916239817937217

Epoch: 5| Step: 10
Training loss: 2.387288808822632
Validation loss: 2.087251757582029

Epoch: 5| Step: 11
Training loss: 0.9066728353500366
Validation loss: 2.077718218167623

Epoch: 195| Step: 0
Training loss: 1.939857840538025
Validation loss: 2.078686445951462

Epoch: 5| Step: 1
Training loss: 2.138701915740967
Validation loss: 2.0852758338054023

Epoch: 5| Step: 2
Training loss: 2.2911813259124756
Validation loss: 2.0760385245084763

Epoch: 5| Step: 3
Training loss: 1.5911251306533813
Validation loss: 2.072173853715261

Epoch: 5| Step: 4
Training loss: 1.889838457107544
Validation loss: 2.0682989756266275

Epoch: 5| Step: 5
Training loss: 1.78433358669281
Validation loss: 2.0776945104201636

Epoch: 5| Step: 6
Training loss: 2.0533156394958496
Validation loss: 2.0719393293062844

Epoch: 5| Step: 7
Training loss: 1.9373283386230469
Validation loss: 2.0782827585935593

Epoch: 5| Step: 8
Training loss: 2.281435012817383
Validation loss: 2.074648837248484

Epoch: 5| Step: 9
Training loss: 2.0944626331329346
Validation loss: 2.0814460813999176

Epoch: 5| Step: 10
Training loss: 2.049208879470825
Validation loss: 2.073857312401136

Epoch: 5| Step: 11
Training loss: 2.0286545753479004
Validation loss: 2.087551782528559

Epoch: 196| Step: 0
Training loss: 1.955080270767212
Validation loss: 2.0869288543860116

Epoch: 5| Step: 1
Training loss: 2.5682930946350098
Validation loss: 2.0829327404499054

Epoch: 5| Step: 2
Training loss: 2.116940975189209
Validation loss: 2.083572198947271

Epoch: 5| Step: 3
Training loss: 1.9392168521881104
Validation loss: 2.0909059892098107

Epoch: 5| Step: 4
Training loss: 1.8718373775482178
Validation loss: 2.0868156601985297

Epoch: 5| Step: 5
Training loss: 1.6630338430404663
Validation loss: 2.0923084070285163

Epoch: 5| Step: 6
Training loss: 1.7444686889648438
Validation loss: 2.1030764679114022

Epoch: 5| Step: 7
Training loss: 2.0476579666137695
Validation loss: 2.093741108973821

Epoch: 5| Step: 8
Training loss: 1.8901058435440063
Validation loss: 2.082716852426529

Epoch: 5| Step: 9
Training loss: 2.0558955669403076
Validation loss: 2.0952292482058206

Epoch: 5| Step: 10
Training loss: 1.9162826538085938
Validation loss: 2.0884821514288583

Epoch: 5| Step: 11
Training loss: 1.6216837167739868
Validation loss: 2.074275096257528

Epoch: 197| Step: 0
Training loss: 1.8362919092178345
Validation loss: 2.079957435528437

Epoch: 5| Step: 1
Training loss: 2.3793976306915283
Validation loss: 2.0831757535537085

Epoch: 5| Step: 2
Training loss: 2.219730854034424
Validation loss: 2.078748012582461

Epoch: 5| Step: 3
Training loss: 1.9161525964736938
Validation loss: 2.0865188986063004

Epoch: 5| Step: 4
Training loss: 1.7318483591079712
Validation loss: 2.0822541316350303

Epoch: 5| Step: 5
Training loss: 1.8259483575820923
Validation loss: 2.079764907558759

Epoch: 5| Step: 6
Training loss: 2.0672106742858887
Validation loss: 2.086906209588051

Epoch: 5| Step: 7
Training loss: 1.7980592250823975
Validation loss: 2.090259005626043

Epoch: 5| Step: 8
Training loss: 2.0662150382995605
Validation loss: 2.0949840595324836

Epoch: 5| Step: 9
Training loss: 2.0538268089294434
Validation loss: 2.097473551829656

Epoch: 5| Step: 10
Training loss: 2.1540541648864746
Validation loss: 2.0872437258561454

Epoch: 5| Step: 11
Training loss: 0.8549041748046875
Validation loss: 2.0906088203191757

Epoch: 198| Step: 0
Training loss: 2.3442866802215576
Validation loss: 2.096806282798449

Epoch: 5| Step: 1
Training loss: 1.9629974365234375
Validation loss: 2.101875419418017

Epoch: 5| Step: 2
Training loss: 2.0521225929260254
Validation loss: 2.0906695226828256

Epoch: 5| Step: 3
Training loss: 1.391420602798462
Validation loss: 2.0844173630078635

Epoch: 5| Step: 4
Training loss: 1.7432410717010498
Validation loss: 2.0905635406573615

Epoch: 5| Step: 5
Training loss: 2.106682300567627
Validation loss: 2.0935118595759072

Epoch: 5| Step: 6
Training loss: 1.8603565692901611
Validation loss: 2.0995683123668036

Epoch: 5| Step: 7
Training loss: 2.130221128463745
Validation loss: 2.0822341293096542

Epoch: 5| Step: 8
Training loss: 1.9229576587677002
Validation loss: 2.086960713068644

Epoch: 5| Step: 9
Training loss: 2.409611225128174
Validation loss: 2.0990553895632424

Epoch: 5| Step: 10
Training loss: 1.6018177270889282
Validation loss: 2.075478116671244

Epoch: 5| Step: 11
Training loss: 2.3100039958953857
Validation loss: 2.085307255387306

Epoch: 199| Step: 0
Training loss: 2.3867881298065186
Validation loss: 2.0768764118353524

Epoch: 5| Step: 1
Training loss: 1.7197325229644775
Validation loss: 2.08372234304746

Epoch: 5| Step: 2
Training loss: 1.8462623357772827
Validation loss: 2.084223593274752

Epoch: 5| Step: 3
Training loss: 1.8090708255767822
Validation loss: 2.0790005127588906

Epoch: 5| Step: 4
Training loss: 1.9853235483169556
Validation loss: 2.078063815832138

Epoch: 5| Step: 5
Training loss: 1.465747594833374
Validation loss: 2.0717204908529916

Epoch: 5| Step: 6
Training loss: 1.9886382818222046
Validation loss: 2.0757973392804465

Epoch: 5| Step: 7
Training loss: 2.3973584175109863
Validation loss: 2.0833637168010077

Epoch: 5| Step: 8
Training loss: 2.046574354171753
Validation loss: 2.0789988736311593

Epoch: 5| Step: 9
Training loss: 2.3792662620544434
Validation loss: 2.0923094699780145

Epoch: 5| Step: 10
Training loss: 1.886375069618225
Validation loss: 2.0936030447483063

Epoch: 5| Step: 11
Training loss: 1.2922877073287964
Validation loss: 2.095697596669197

Epoch: 200| Step: 0
Training loss: 2.258967161178589
Validation loss: 2.098712762196859

Epoch: 5| Step: 1
Training loss: 1.7299325466156006
Validation loss: 2.0963796973228455

Epoch: 5| Step: 2
Training loss: 1.7332849502563477
Validation loss: 2.0990998645623526

Epoch: 5| Step: 3
Training loss: 1.9593379497528076
Validation loss: 2.075568055113157

Epoch: 5| Step: 4
Training loss: 1.3106778860092163
Validation loss: 2.088769406080246

Epoch: 5| Step: 5
Training loss: 2.4187979698181152
Validation loss: 2.0918882340192795

Epoch: 5| Step: 6
Training loss: 2.3636274337768555
Validation loss: 2.0864879389603934

Epoch: 5| Step: 7
Training loss: 2.3066561222076416
Validation loss: 2.0886174887418747

Epoch: 5| Step: 8
Training loss: 1.924426794052124
Validation loss: 2.081641366084417

Epoch: 5| Step: 9
Training loss: 1.9534289836883545
Validation loss: 2.0757611791292825

Epoch: 5| Step: 10
Training loss: 1.8735265731811523
Validation loss: 2.092548976341883

Epoch: 5| Step: 11
Training loss: 1.9150199890136719
Validation loss: 2.093859409292539

Epoch: 201| Step: 0
Training loss: 1.850113868713379
Validation loss: 2.0856816172599792

Epoch: 5| Step: 1
Training loss: 1.618140459060669
Validation loss: 2.093065783381462

Epoch: 5| Step: 2
Training loss: 2.20747709274292
Validation loss: 2.103297084569931

Epoch: 5| Step: 3
Training loss: 1.7920652627944946
Validation loss: 2.0974432776371636

Epoch: 5| Step: 4
Training loss: 1.9261682033538818
Validation loss: 2.098201056321462

Epoch: 5| Step: 5
Training loss: 2.448178768157959
Validation loss: 2.078447903196017

Epoch: 5| Step: 6
Training loss: 2.4997472763061523
Validation loss: 2.0923376431067786

Epoch: 5| Step: 7
Training loss: 1.6988985538482666
Validation loss: 2.081412191192309

Epoch: 5| Step: 8
Training loss: 2.2507271766662598
Validation loss: 2.0785339176654816

Epoch: 5| Step: 9
Training loss: 1.6900436878204346
Validation loss: 2.0694999247789383

Epoch: 5| Step: 10
Training loss: 1.8574367761611938
Validation loss: 2.069909850756327

Epoch: 5| Step: 11
Training loss: 2.6325345039367676
Validation loss: 2.062685400247574

Epoch: 202| Step: 0
Training loss: 1.899417519569397
Validation loss: 2.0561533868312836

Epoch: 5| Step: 1
Training loss: 1.9827992916107178
Validation loss: 2.061130568385124

Epoch: 5| Step: 2
Training loss: 1.4952059984207153
Validation loss: 2.0677670339743295

Epoch: 5| Step: 3
Training loss: 2.056933641433716
Validation loss: 2.058443854252497

Epoch: 5| Step: 4
Training loss: 1.7220481634140015
Validation loss: 2.0519134253263474

Epoch: 5| Step: 5
Training loss: 1.5642765760421753
Validation loss: 2.0658373683691025

Epoch: 5| Step: 6
Training loss: 2.445507049560547
Validation loss: 2.06637113293012

Epoch: 5| Step: 7
Training loss: 1.9426853656768799
Validation loss: 2.0739974826574326

Epoch: 5| Step: 8
Training loss: 2.6976873874664307
Validation loss: 2.0654180298248925

Epoch: 5| Step: 9
Training loss: 2.667933225631714
Validation loss: 2.0686961511770883

Epoch: 5| Step: 10
Training loss: 1.9382156133651733
Validation loss: 2.0777334620555243

Epoch: 5| Step: 11
Training loss: 1.4195587635040283
Validation loss: 2.0677126298348107

Epoch: 203| Step: 0
Training loss: 1.7953522205352783
Validation loss: 2.072221055626869

Epoch: 5| Step: 1
Training loss: 1.8830448389053345
Validation loss: 2.084112137556076

Epoch: 5| Step: 2
Training loss: 2.243849992752075
Validation loss: 2.08556666970253

Epoch: 5| Step: 3
Training loss: 2.018815755844116
Validation loss: 2.091387669245402

Epoch: 5| Step: 4
Training loss: 2.7748825550079346
Validation loss: 2.1075791915257773

Epoch: 5| Step: 5
Training loss: 2.1614432334899902
Validation loss: 2.0994149148464203

Epoch: 5| Step: 6
Training loss: 2.118048906326294
Validation loss: 2.1012155363957086

Epoch: 5| Step: 7
Training loss: 1.5002071857452393
Validation loss: 2.093950167298317

Epoch: 5| Step: 8
Training loss: 1.7833340167999268
Validation loss: 2.0893753518660865

Epoch: 5| Step: 9
Training loss: 1.4912251234054565
Validation loss: 2.1060605347156525

Epoch: 5| Step: 10
Training loss: 2.0673489570617676
Validation loss: 2.0868342320124307

Epoch: 5| Step: 11
Training loss: 2.3788344860076904
Validation loss: 2.1095602413018546

Epoch: 204| Step: 0
Training loss: 1.6304905414581299
Validation loss: 2.098397597670555

Epoch: 5| Step: 1
Training loss: 2.1246824264526367
Validation loss: 2.0936605681975684

Epoch: 5| Step: 2
Training loss: 2.28084135055542
Validation loss: 2.1003929475943246

Epoch: 5| Step: 3
Training loss: 1.4087404012680054
Validation loss: 2.0924038539330163

Epoch: 5| Step: 4
Training loss: 2.348668336868286
Validation loss: 2.095153341690699

Epoch: 5| Step: 5
Training loss: 2.34574818611145
Validation loss: 2.0797646393378577

Epoch: 5| Step: 6
Training loss: 1.4805123805999756
Validation loss: 2.0825654665629068

Epoch: 5| Step: 7
Training loss: 2.0815978050231934
Validation loss: 2.0944052040576935

Epoch: 5| Step: 8
Training loss: 1.6603491306304932
Validation loss: 2.0907463828722634

Epoch: 5| Step: 9
Training loss: 2.315622091293335
Validation loss: 2.09569384654363

Epoch: 5| Step: 10
Training loss: 1.9466807842254639
Validation loss: 2.094749838113785

Epoch: 5| Step: 11
Training loss: 1.9523842334747314
Validation loss: 2.1041929125785828

Epoch: 205| Step: 0
Training loss: 1.6083904504776
Validation loss: 2.1049381842215857

Epoch: 5| Step: 1
Training loss: 1.9512465000152588
Validation loss: 2.1024282375971475

Epoch: 5| Step: 2
Training loss: 2.007211685180664
Validation loss: 2.1012516568104425

Epoch: 5| Step: 3
Training loss: 2.3689377307891846
Validation loss: 2.0903222362200418

Epoch: 5| Step: 4
Training loss: 1.8899650573730469
Validation loss: 2.0721049855152764

Epoch: 5| Step: 5
Training loss: 2.1723785400390625
Validation loss: 2.0712528626124063

Epoch: 5| Step: 6
Training loss: 2.038595676422119
Validation loss: 2.0684583286444345

Epoch: 5| Step: 7
Training loss: 1.7940477132797241
Validation loss: 2.0593003084262214

Epoch: 5| Step: 8
Training loss: 1.9031448364257812
Validation loss: 2.075696110725403

Epoch: 5| Step: 9
Training loss: 2.126530647277832
Validation loss: 2.064593583345413

Epoch: 5| Step: 10
Training loss: 2.1483025550842285
Validation loss: 2.0637066662311554

Epoch: 5| Step: 11
Training loss: 1.3111789226531982
Validation loss: 2.0602703193823495

Epoch: 206| Step: 0
Training loss: 1.4422197341918945
Validation loss: 2.0528180499871573

Epoch: 5| Step: 1
Training loss: 2.5072598457336426
Validation loss: 2.0672462234894433

Epoch: 5| Step: 2
Training loss: 2.2792694568634033
Validation loss: 2.0660279989242554

Epoch: 5| Step: 3
Training loss: 1.8616735935211182
Validation loss: 2.0779258956511817

Epoch: 5| Step: 4
Training loss: 2.167257785797119
Validation loss: 2.081163282195727

Epoch: 5| Step: 5
Training loss: 2.273090362548828
Validation loss: 2.07265397409598

Epoch: 5| Step: 6
Training loss: 2.091273546218872
Validation loss: 2.071982945005099

Epoch: 5| Step: 7
Training loss: 1.771500825881958
Validation loss: 2.078280737002691

Epoch: 5| Step: 8
Training loss: 1.531388521194458
Validation loss: 2.0766449769337973

Epoch: 5| Step: 9
Training loss: 2.0319647789001465
Validation loss: 2.068322648604711

Epoch: 5| Step: 10
Training loss: 2.0416598320007324
Validation loss: 2.0689417024453483

Epoch: 5| Step: 11
Training loss: 1.055293321609497
Validation loss: 2.061229258775711

Epoch: 207| Step: 0
Training loss: 1.9103460311889648
Validation loss: 2.056950961550077

Epoch: 5| Step: 1
Training loss: 2.434760332107544
Validation loss: 2.0453342497348785

Epoch: 5| Step: 2
Training loss: 1.8555259704589844
Validation loss: 2.047812898953756

Epoch: 5| Step: 3
Training loss: 2.0929927825927734
Validation loss: 2.0464985768000283

Epoch: 5| Step: 4
Training loss: 1.8279085159301758
Validation loss: 2.0531870623429618

Epoch: 5| Step: 5
Training loss: 2.7263879776000977
Validation loss: 2.053440183401108

Epoch: 5| Step: 6
Training loss: 2.0959880352020264
Validation loss: 2.046010653177897

Epoch: 5| Step: 7
Training loss: 2.2735018730163574
Validation loss: 2.0531647503376007

Epoch: 5| Step: 8
Training loss: 1.80922532081604
Validation loss: 2.048902859290441

Epoch: 5| Step: 9
Training loss: 1.8066486120224
Validation loss: 2.043355072538058

Epoch: 5| Step: 10
Training loss: 2.011955499649048
Validation loss: 2.0462556133667626

Epoch: 5| Step: 11
Training loss: 2.1122171878814697
Validation loss: 2.0470762153466544

Epoch: 208| Step: 0
Training loss: 1.9165176153182983
Validation loss: 2.0414628436168036

Epoch: 5| Step: 1
Training loss: 2.2969417572021484
Validation loss: 2.0457637906074524

Epoch: 5| Step: 2
Training loss: 2.1537492275238037
Validation loss: 2.052430788675944

Epoch: 5| Step: 3
Training loss: 1.617461919784546
Validation loss: 2.0484783351421356

Epoch: 5| Step: 4
Training loss: 2.029323101043701
Validation loss: 2.0474179486433663

Epoch: 5| Step: 5
Training loss: 1.9961280822753906
Validation loss: 2.0545133153597512

Epoch: 5| Step: 6
Training loss: 1.8521522283554077
Validation loss: 2.0644889821608863

Epoch: 5| Step: 7
Training loss: 2.3827826976776123
Validation loss: 2.0610018322865167

Epoch: 5| Step: 8
Training loss: 1.3571221828460693
Validation loss: 2.0756992995738983

Epoch: 5| Step: 9
Training loss: 2.5281360149383545
Validation loss: 2.0725603799025216

Epoch: 5| Step: 10
Training loss: 2.1963837146759033
Validation loss: 2.070197453101476

Epoch: 5| Step: 11
Training loss: 1.9230622053146362
Validation loss: 2.078680286804835

Epoch: 209| Step: 0
Training loss: 2.413681745529175
Validation loss: 2.080336883664131

Epoch: 5| Step: 1
Training loss: 2.0380303859710693
Validation loss: 2.0675474355618157

Epoch: 5| Step: 2
Training loss: 1.8637583255767822
Validation loss: 2.0808772246042886

Epoch: 5| Step: 3
Training loss: 2.2135658264160156
Validation loss: 2.092633470892906

Epoch: 5| Step: 4
Training loss: 1.4750897884368896
Validation loss: 2.0915639797846475

Epoch: 5| Step: 5
Training loss: 2.29638409614563
Validation loss: 2.087678616245588

Epoch: 5| Step: 6
Training loss: 1.310712218284607
Validation loss: 2.096113527814547

Epoch: 5| Step: 7
Training loss: 2.0570788383483887
Validation loss: 2.1087057838837304

Epoch: 5| Step: 8
Training loss: 2.3515801429748535
Validation loss: 2.1014727652072906

Epoch: 5| Step: 9
Training loss: 1.7014105319976807
Validation loss: 2.0965379575888314

Epoch: 5| Step: 10
Training loss: 1.9400246143341064
Validation loss: 2.0860143154859543

Epoch: 5| Step: 11
Training loss: 2.2901949882507324
Validation loss: 2.0917030970255532

Epoch: 210| Step: 0
Training loss: 1.9957771301269531
Validation loss: 2.098639488220215

Epoch: 5| Step: 1
Training loss: 2.072453260421753
Validation loss: 2.101717919111252

Epoch: 5| Step: 2
Training loss: 2.093280553817749
Validation loss: 2.092293764154116

Epoch: 5| Step: 3
Training loss: 1.8808355331420898
Validation loss: 2.095953568816185

Epoch: 5| Step: 4
Training loss: 2.1484880447387695
Validation loss: 2.098526746034622

Epoch: 5| Step: 5
Training loss: 1.9178117513656616
Validation loss: 2.098115692536036

Epoch: 5| Step: 6
Training loss: 2.1112332344055176
Validation loss: 2.1076478213071823

Epoch: 5| Step: 7
Training loss: 1.7032315731048584
Validation loss: 2.093099132180214

Epoch: 5| Step: 8
Training loss: 2.280189037322998
Validation loss: 2.107193812727928

Epoch: 5| Step: 9
Training loss: 1.4247022867202759
Validation loss: 2.1045477439959845

Epoch: 5| Step: 10
Training loss: 1.7985426187515259
Validation loss: 2.092409978310267

Epoch: 5| Step: 11
Training loss: 2.4180541038513184
Validation loss: 2.10604335864385

Epoch: 211| Step: 0
Training loss: 1.7588313817977905
Validation loss: 2.1128181914488473

Epoch: 5| Step: 1
Training loss: 2.3332319259643555
Validation loss: 2.099408899744352

Epoch: 5| Step: 2
Training loss: 1.752899408340454
Validation loss: 2.0972647170225778

Epoch: 5| Step: 3
Training loss: 1.7989184856414795
Validation loss: 2.0962884028752646

Epoch: 5| Step: 4
Training loss: 2.4543583393096924
Validation loss: 2.099755341808001

Epoch: 5| Step: 5
Training loss: 1.8015470504760742
Validation loss: 2.10234464208285

Epoch: 5| Step: 6
Training loss: 2.388715982437134
Validation loss: 2.096261332432429

Epoch: 5| Step: 7
Training loss: 1.8683570623397827
Validation loss: 2.0902507404486337

Epoch: 5| Step: 8
Training loss: 1.886156678199768
Validation loss: 2.098408634463946

Epoch: 5| Step: 9
Training loss: 2.0787625312805176
Validation loss: 2.088174437483152

Epoch: 5| Step: 10
Training loss: 1.6033645868301392
Validation loss: 2.1034618467092514

Epoch: 5| Step: 11
Training loss: 1.5027559995651245
Validation loss: 2.104422534505526

Epoch: 212| Step: 0
Training loss: 2.333095073699951
Validation loss: 2.095135678847631

Epoch: 5| Step: 1
Training loss: 2.1951708793640137
Validation loss: 2.1017118195692697

Epoch: 5| Step: 2
Training loss: 1.727656364440918
Validation loss: 2.096829598148664

Epoch: 5| Step: 3
Training loss: 1.4287022352218628
Validation loss: 2.1011725465456643

Epoch: 5| Step: 4
Training loss: 2.5907158851623535
Validation loss: 2.1015566686789193

Epoch: 5| Step: 5
Training loss: 1.7279847860336304
Validation loss: 2.1034287363290787

Epoch: 5| Step: 6
Training loss: 2.476706027984619
Validation loss: 2.106734206279119

Epoch: 5| Step: 7
Training loss: 1.7574405670166016
Validation loss: 2.1083865761756897

Epoch: 5| Step: 8
Training loss: 1.8613386154174805
Validation loss: 2.1117393175760903

Epoch: 5| Step: 9
Training loss: 2.0898776054382324
Validation loss: 2.109766274690628

Epoch: 5| Step: 10
Training loss: 1.4624980688095093
Validation loss: 2.108179693420728

Epoch: 5| Step: 11
Training loss: 1.6651792526245117
Validation loss: 2.1146206955115

Epoch: 213| Step: 0
Training loss: 2.4960641860961914
Validation loss: 2.113194018602371

Epoch: 5| Step: 1
Training loss: 1.9915863275527954
Validation loss: 2.1143173774083457

Epoch: 5| Step: 2
Training loss: 2.3198695182800293
Validation loss: 2.104870706796646

Epoch: 5| Step: 3
Training loss: 1.438865065574646
Validation loss: 2.1080514788627625

Epoch: 5| Step: 4
Training loss: 1.6208264827728271
Validation loss: 2.099680403868357

Epoch: 5| Step: 5
Training loss: 1.8903669118881226
Validation loss: 2.105738028883934

Epoch: 5| Step: 6
Training loss: 2.0515267848968506
Validation loss: 2.1069844166437783

Epoch: 5| Step: 7
Training loss: 1.4728314876556396
Validation loss: 2.1131839553515115

Epoch: 5| Step: 8
Training loss: 1.941364049911499
Validation loss: 2.106987009445826

Epoch: 5| Step: 9
Training loss: 2.0000808238983154
Validation loss: 2.1003864258527756

Epoch: 5| Step: 10
Training loss: 2.2726454734802246
Validation loss: 2.094635476668676

Epoch: 5| Step: 11
Training loss: 1.5756351947784424
Validation loss: 2.102343440055847

Epoch: 214| Step: 0
Training loss: 1.4752922058105469
Validation loss: 2.103654980659485

Epoch: 5| Step: 1
Training loss: 2.399390697479248
Validation loss: 2.103283921877543

Epoch: 5| Step: 2
Training loss: 1.9702033996582031
Validation loss: 2.1078650653362274

Epoch: 5| Step: 3
Training loss: 2.21392560005188
Validation loss: 2.104075998067856

Epoch: 5| Step: 4
Training loss: 1.7640479803085327
Validation loss: 2.1015892177820206

Epoch: 5| Step: 5
Training loss: 1.9295374155044556
Validation loss: 2.1046242713928223

Epoch: 5| Step: 6
Training loss: 2.1195175647735596
Validation loss: 2.100827823082606

Epoch: 5| Step: 7
Training loss: 1.885438323020935
Validation loss: 2.109425072868665

Epoch: 5| Step: 8
Training loss: 2.224424362182617
Validation loss: 2.098134229580561

Epoch: 5| Step: 9
Training loss: 2.016578197479248
Validation loss: 2.102900837858518

Epoch: 5| Step: 10
Training loss: 1.5407681465148926
Validation loss: 2.108336478471756

Epoch: 5| Step: 11
Training loss: 1.030975580215454
Validation loss: 2.0999438911676407

Epoch: 215| Step: 0
Training loss: 2.2015271186828613
Validation loss: 2.093695198496183

Epoch: 5| Step: 1
Training loss: 1.5486650466918945
Validation loss: 2.0898221284151077

Epoch: 5| Step: 2
Training loss: 2.4142918586730957
Validation loss: 2.103307152787844

Epoch: 5| Step: 3
Training loss: 2.05291485786438
Validation loss: 2.0942096610864005

Epoch: 5| Step: 4
Training loss: 1.8949857950210571
Validation loss: 2.0946909685929618

Epoch: 5| Step: 5
Training loss: 1.760727882385254
Validation loss: 2.1001642048358917

Epoch: 5| Step: 6
Training loss: 1.493436336517334
Validation loss: 2.093262309829394

Epoch: 5| Step: 7
Training loss: 2.062514543533325
Validation loss: 2.1045742332935333

Epoch: 5| Step: 8
Training loss: 2.408864974975586
Validation loss: 2.107999304930369

Epoch: 5| Step: 9
Training loss: 1.509594202041626
Validation loss: 2.106382062037786

Epoch: 5| Step: 10
Training loss: 2.266634941101074
Validation loss: 2.113415777683258

Epoch: 5| Step: 11
Training loss: 1.299879550933838
Validation loss: 2.110602786143621

Epoch: 216| Step: 0
Training loss: 2.329817295074463
Validation loss: 2.114755223194758

Epoch: 5| Step: 1
Training loss: 1.356857180595398
Validation loss: 2.1202711860338845

Epoch: 5| Step: 2
Training loss: 1.9675264358520508
Validation loss: 2.117878094315529

Epoch: 5| Step: 3
Training loss: 1.8063290119171143
Validation loss: 2.116924320658048

Epoch: 5| Step: 4
Training loss: 2.6029512882232666
Validation loss: 2.109156092007955

Epoch: 5| Step: 5
Training loss: 1.4499619007110596
Validation loss: 2.106655473510424

Epoch: 5| Step: 6
Training loss: 2.4089863300323486
Validation loss: 2.095031186938286

Epoch: 5| Step: 7
Training loss: 1.8761180639266968
Validation loss: 2.1046935419241586

Epoch: 5| Step: 8
Training loss: 1.9728376865386963
Validation loss: 2.101775492231051

Epoch: 5| Step: 9
Training loss: 1.9511497020721436
Validation loss: 2.10140123963356

Epoch: 5| Step: 10
Training loss: 1.9834563732147217
Validation loss: 2.0983962217966714

Epoch: 5| Step: 11
Training loss: 1.2685717344284058
Validation loss: 2.0870473980903625

Epoch: 217| Step: 0
Training loss: 2.0434794425964355
Validation loss: 2.0864540189504623

Epoch: 5| Step: 1
Training loss: 2.2264254093170166
Validation loss: 2.0801878770192466

Epoch: 5| Step: 2
Training loss: 2.345961570739746
Validation loss: 2.0789895554383597

Epoch: 5| Step: 3
Training loss: 2.124101161956787
Validation loss: 2.0713954071203866

Epoch: 5| Step: 4
Training loss: 1.68865966796875
Validation loss: 2.084931249419848

Epoch: 5| Step: 5
Training loss: 1.82241690158844
Validation loss: 2.0814511477947235

Epoch: 5| Step: 6
Training loss: 1.9239156246185303
Validation loss: 2.0792442162831626

Epoch: 5| Step: 7
Training loss: 2.1690666675567627
Validation loss: 2.085464889804522

Epoch: 5| Step: 8
Training loss: 2.303973436355591
Validation loss: 2.0819090008735657

Epoch: 5| Step: 9
Training loss: 2.2739109992980957
Validation loss: 2.069709594051043

Epoch: 5| Step: 10
Training loss: 1.4887663125991821
Validation loss: 2.088547319173813

Epoch: 5| Step: 11
Training loss: 2.2540712356567383
Validation loss: 2.081379011273384

Epoch: 218| Step: 0
Training loss: 1.863743543624878
Validation loss: 2.0815740823745728

Epoch: 5| Step: 1
Training loss: 2.4127326011657715
Validation loss: 2.097457617521286

Epoch: 5| Step: 2
Training loss: 2.179699182510376
Validation loss: 2.092149873574575

Epoch: 5| Step: 3
Training loss: 2.4743330478668213
Validation loss: 2.0957587311665216

Epoch: 5| Step: 4
Training loss: 2.223390579223633
Validation loss: 2.0968499332666397

Epoch: 5| Step: 5
Training loss: 1.5993062257766724
Validation loss: 2.0982315142949424

Epoch: 5| Step: 6
Training loss: 2.0852158069610596
Validation loss: 2.098965028921763

Epoch: 5| Step: 7
Training loss: 1.4790639877319336
Validation loss: 2.091463625431061

Epoch: 5| Step: 8
Training loss: 1.751880407333374
Validation loss: 2.0999077558517456

Epoch: 5| Step: 9
Training loss: 1.962980031967163
Validation loss: 2.0961168160041175

Epoch: 5| Step: 10
Training loss: 1.602423906326294
Validation loss: 2.095054676135381

Epoch: 5| Step: 11
Training loss: 1.74779212474823
Validation loss: 2.1009233792622886

Epoch: 219| Step: 0
Training loss: 1.6656910181045532
Validation loss: 2.093266104658445

Epoch: 5| Step: 1
Training loss: 2.1903135776519775
Validation loss: 2.081169232726097

Epoch: 5| Step: 2
Training loss: 2.119865894317627
Validation loss: 2.101681649684906

Epoch: 5| Step: 3
Training loss: 1.9281387329101562
Validation loss: 2.1000296572844186

Epoch: 5| Step: 4
Training loss: 1.6247217655181885
Validation loss: 2.1026901404062905

Epoch: 5| Step: 5
Training loss: 2.1478188037872314
Validation loss: 2.1016748547554016

Epoch: 5| Step: 6
Training loss: 2.1075589656829834
Validation loss: 2.0979240089654922

Epoch: 5| Step: 7
Training loss: 1.9378783702850342
Validation loss: 2.105054716269175

Epoch: 5| Step: 8
Training loss: 1.9130483865737915
Validation loss: 2.1062281131744385

Epoch: 5| Step: 9
Training loss: 2.3878135681152344
Validation loss: 2.1068105498949685

Epoch: 5| Step: 10
Training loss: 2.061436653137207
Validation loss: 2.1126556545495987

Epoch: 5| Step: 11
Training loss: 1.7608870267868042
Validation loss: 2.1060780733823776

Epoch: 220| Step: 0
Training loss: 2.7139148712158203
Validation loss: 2.100624536474546

Epoch: 5| Step: 1
Training loss: 1.6595360040664673
Validation loss: 2.1287792374690375

Epoch: 5| Step: 2
Training loss: 1.8616650104522705
Validation loss: 2.113071858882904

Epoch: 5| Step: 3
Training loss: 1.5358846187591553
Validation loss: 2.116904377937317

Epoch: 5| Step: 4
Training loss: 1.7916958332061768
Validation loss: 2.124261478583018

Epoch: 5| Step: 5
Training loss: 2.445974588394165
Validation loss: 2.109867279728254

Epoch: 5| Step: 6
Training loss: 1.9183027744293213
Validation loss: 2.1201370110114417

Epoch: 5| Step: 7
Training loss: 1.9610496759414673
Validation loss: 2.1095281541347504

Epoch: 5| Step: 8
Training loss: 1.440359354019165
Validation loss: 2.1216546297073364

Epoch: 5| Step: 9
Training loss: 1.9762392044067383
Validation loss: 2.1078510135412216

Epoch: 5| Step: 10
Training loss: 2.3163235187530518
Validation loss: 2.113080178697904

Epoch: 5| Step: 11
Training loss: 1.2910820245742798
Validation loss: 2.1110739509264627

Epoch: 221| Step: 0
Training loss: 2.1171722412109375
Validation loss: 2.1117764015992484

Epoch: 5| Step: 1
Training loss: 1.5654895305633545
Validation loss: 2.110822240511576

Epoch: 5| Step: 2
Training loss: 2.842308521270752
Validation loss: 2.1202345738808313

Epoch: 5| Step: 3
Training loss: 1.9673078060150146
Validation loss: 2.11702453593413

Epoch: 5| Step: 4
Training loss: 1.5243580341339111
Validation loss: 2.1232532213131585

Epoch: 5| Step: 5
Training loss: 1.5862289667129517
Validation loss: 2.1057248463233313

Epoch: 5| Step: 6
Training loss: 1.9583247900009155
Validation loss: 2.111810401082039

Epoch: 5| Step: 7
Training loss: 2.0229244232177734
Validation loss: 2.109533200661341

Epoch: 5| Step: 8
Training loss: 2.250770092010498
Validation loss: 2.109011391798655

Epoch: 5| Step: 9
Training loss: 1.8194907903671265
Validation loss: 2.1088403860727944

Epoch: 5| Step: 10
Training loss: 1.9841938018798828
Validation loss: 2.111640547712644

Epoch: 5| Step: 11
Training loss: 1.3649733066558838
Validation loss: 2.1067969352006912

Epoch: 222| Step: 0
Training loss: 1.7916339635849
Validation loss: 2.105895842115084

Epoch: 5| Step: 1
Training loss: 2.3797805309295654
Validation loss: 2.1143613358338675

Epoch: 5| Step: 2
Training loss: 2.034151554107666
Validation loss: 2.098290652036667

Epoch: 5| Step: 3
Training loss: 1.866159439086914
Validation loss: 2.116128588716189

Epoch: 5| Step: 4
Training loss: 1.6071010828018188
Validation loss: 2.104120140274366

Epoch: 5| Step: 5
Training loss: 2.215123414993286
Validation loss: 2.116447314620018

Epoch: 5| Step: 6
Training loss: 1.3809260129928589
Validation loss: 2.126102422674497

Epoch: 5| Step: 7
Training loss: 1.8269811868667603
Validation loss: 2.122951795657476

Epoch: 5| Step: 8
Training loss: 2.038486957550049
Validation loss: 2.1300218800703683

Epoch: 5| Step: 9
Training loss: 2.0967955589294434
Validation loss: 2.120243231455485

Epoch: 5| Step: 10
Training loss: 1.9868425130844116
Validation loss: 2.1265602012475333

Epoch: 5| Step: 11
Training loss: 1.7057652473449707
Validation loss: 2.1308759997288385

Epoch: 223| Step: 0
Training loss: 1.6459376811981201
Validation loss: 2.12063567340374

Epoch: 5| Step: 1
Training loss: 2.8597540855407715
Validation loss: 2.1164818505446115

Epoch: 5| Step: 2
Training loss: 2.2319564819335938
Validation loss: 2.1261211186647415

Epoch: 5| Step: 3
Training loss: 2.170853853225708
Validation loss: 2.1287113279104233

Epoch: 5| Step: 4
Training loss: 1.384640097618103
Validation loss: 2.1106851597627005

Epoch: 5| Step: 5
Training loss: 2.045523166656494
Validation loss: 2.120249624053637

Epoch: 5| Step: 6
Training loss: 1.538246512413025
Validation loss: 2.119535485903422

Epoch: 5| Step: 7
Training loss: 2.1709859371185303
Validation loss: 2.11277104417483

Epoch: 5| Step: 8
Training loss: 2.1623220443725586
Validation loss: 2.117584526538849

Epoch: 5| Step: 9
Training loss: 1.458552360534668
Validation loss: 2.1197061290343604

Epoch: 5| Step: 10
Training loss: 1.445960283279419
Validation loss: 2.112112502257029

Epoch: 5| Step: 11
Training loss: 1.9295085668563843
Validation loss: 2.1169365098079047

Epoch: 224| Step: 0
Training loss: 1.8403537273406982
Validation loss: 2.112080146869024

Epoch: 5| Step: 1
Training loss: 2.164965867996216
Validation loss: 2.1087825993696847

Epoch: 5| Step: 2
Training loss: 1.8038084506988525
Validation loss: 2.115620548526446

Epoch: 5| Step: 3
Training loss: 2.2828052043914795
Validation loss: 2.109228024880091

Epoch: 5| Step: 4
Training loss: 1.958491325378418
Validation loss: 2.108511656522751

Epoch: 5| Step: 5
Training loss: 2.143378496170044
Validation loss: 2.109757681687673

Epoch: 5| Step: 6
Training loss: 1.8911960124969482
Validation loss: 2.111196979880333

Epoch: 5| Step: 7
Training loss: 1.8931877613067627
Validation loss: 2.107951298356056

Epoch: 5| Step: 8
Training loss: 1.5738166570663452
Validation loss: 2.119407961765925

Epoch: 5| Step: 9
Training loss: 1.9463531970977783
Validation loss: 2.111155852675438

Epoch: 5| Step: 10
Training loss: 1.905739426612854
Validation loss: 2.108799825112025

Epoch: 5| Step: 11
Training loss: 1.4695186614990234
Validation loss: 2.1110725849866867

Epoch: 225| Step: 0
Training loss: 1.8931739330291748
Validation loss: 2.126160353422165

Epoch: 5| Step: 1
Training loss: 1.7614414691925049
Validation loss: 2.124763930837313

Epoch: 5| Step: 2
Training loss: 2.5371620655059814
Validation loss: 2.127882738908132

Epoch: 5| Step: 3
Training loss: 1.246350646018982
Validation loss: 2.121718297402064

Epoch: 5| Step: 4
Training loss: 1.9030888080596924
Validation loss: 2.1223276456197104

Epoch: 5| Step: 5
Training loss: 1.449074625968933
Validation loss: 2.1031826039155326

Epoch: 5| Step: 6
Training loss: 2.3647239208221436
Validation loss: 2.123863399028778

Epoch: 5| Step: 7
Training loss: 1.779571533203125
Validation loss: 2.1198139637708664

Epoch: 5| Step: 8
Training loss: 2.3458800315856934
Validation loss: 2.1104762305816016

Epoch: 5| Step: 9
Training loss: 2.081191301345825
Validation loss: 2.1185420701901116

Epoch: 5| Step: 10
Training loss: 2.02333402633667
Validation loss: 2.1002666304508844

Epoch: 5| Step: 11
Training loss: 1.707242727279663
Validation loss: 2.1295311798652015

Epoch: 226| Step: 0
Training loss: 2.4644365310668945
Validation loss: 2.1258553663889566

Epoch: 5| Step: 1
Training loss: 1.6028209924697876
Validation loss: 2.110114092628161

Epoch: 5| Step: 2
Training loss: 1.35245943069458
Validation loss: 2.110988969604174

Epoch: 5| Step: 3
Training loss: 1.6303437948226929
Validation loss: 2.1167214115460715

Epoch: 5| Step: 4
Training loss: 2.056060314178467
Validation loss: 2.118464097380638

Epoch: 5| Step: 5
Training loss: 1.9778894186019897
Validation loss: 2.1244331945975623

Epoch: 5| Step: 6
Training loss: 1.8104156255722046
Validation loss: 2.09876956542333

Epoch: 5| Step: 7
Training loss: 2.114637851715088
Validation loss: 2.1125183949867883

Epoch: 5| Step: 8
Training loss: 1.9963066577911377
Validation loss: 2.115264981985092

Epoch: 5| Step: 9
Training loss: 1.743908166885376
Validation loss: 2.1073835591475167

Epoch: 5| Step: 10
Training loss: 2.495542049407959
Validation loss: 2.1324046850204468

Epoch: 5| Step: 11
Training loss: 1.5609420537948608
Validation loss: 2.120878020922343

Epoch: 227| Step: 0
Training loss: 2.1162846088409424
Validation loss: 2.1264136135578156

Epoch: 5| Step: 1
Training loss: 1.598445177078247
Validation loss: 2.122856537501017

Epoch: 5| Step: 2
Training loss: 1.9495702981948853
Validation loss: 2.1362975587447486

Epoch: 5| Step: 3
Training loss: 2.274989366531372
Validation loss: 2.113241175810496

Epoch: 5| Step: 4
Training loss: 2.4767651557922363
Validation loss: 2.1187613755464554

Epoch: 5| Step: 5
Training loss: 2.028653860092163
Validation loss: 2.124075065056483

Epoch: 5| Step: 6
Training loss: 2.2728538513183594
Validation loss: 2.114072228471438

Epoch: 5| Step: 7
Training loss: 1.5229641199111938
Validation loss: 2.1060944398244223

Epoch: 5| Step: 8
Training loss: 2.0677530765533447
Validation loss: 2.119002421696981

Epoch: 5| Step: 9
Training loss: 1.7853034734725952
Validation loss: 2.112897897760073

Epoch: 5| Step: 10
Training loss: 1.2673693895339966
Validation loss: 2.1211453874905906

Epoch: 5| Step: 11
Training loss: 0.9444191455841064
Validation loss: 2.1084124197562537

Epoch: 228| Step: 0
Training loss: 2.232086658477783
Validation loss: 2.1138997226953506

Epoch: 5| Step: 1
Training loss: 2.26619291305542
Validation loss: 2.1140854954719543

Epoch: 5| Step: 2
Training loss: 1.7181533575057983
Validation loss: 2.125419164697329

Epoch: 5| Step: 3
Training loss: 2.0748276710510254
Validation loss: 2.1283257802327475

Epoch: 5| Step: 4
Training loss: 1.9272629022598267
Validation loss: 2.1250688632329306

Epoch: 5| Step: 5
Training loss: 1.9607858657836914
Validation loss: 2.121690263350805

Epoch: 5| Step: 6
Training loss: 2.127599000930786
Validation loss: 2.119856874148051

Epoch: 5| Step: 7
Training loss: 1.4967761039733887
Validation loss: 2.118206391731898

Epoch: 5| Step: 8
Training loss: 1.9664039611816406
Validation loss: 2.119513829549154

Epoch: 5| Step: 9
Training loss: 2.024656295776367
Validation loss: 2.112969001134237

Epoch: 5| Step: 10
Training loss: 1.6704661846160889
Validation loss: 2.1127048432826996

Epoch: 5| Step: 11
Training loss: 1.155893087387085
Validation loss: 2.1030213683843613

Epoch: 229| Step: 0
Training loss: 1.7357715368270874
Validation loss: 2.1136690378189087

Epoch: 5| Step: 1
Training loss: 2.3031904697418213
Validation loss: 2.1055415322383246

Epoch: 5| Step: 2
Training loss: 1.4415565729141235
Validation loss: 2.1115176528692245

Epoch: 5| Step: 3
Training loss: 1.9625160694122314
Validation loss: 2.114841709534327

Epoch: 5| Step: 4
Training loss: 1.866194486618042
Validation loss: 2.111932451526324

Epoch: 5| Step: 5
Training loss: 1.6273057460784912
Validation loss: 2.107323572039604

Epoch: 5| Step: 6
Training loss: 1.9079900979995728
Validation loss: 2.102017973860105

Epoch: 5| Step: 7
Training loss: 1.7812461853027344
Validation loss: 2.1131819784641266

Epoch: 5| Step: 8
Training loss: 2.022254467010498
Validation loss: 2.1049404243628183

Epoch: 5| Step: 9
Training loss: 2.3781652450561523
Validation loss: 2.118007560571035

Epoch: 5| Step: 10
Training loss: 2.288179397583008
Validation loss: 2.1152519385019937

Epoch: 5| Step: 11
Training loss: 1.2454590797424316
Validation loss: 2.1200557549794516

Epoch: 230| Step: 0
Training loss: 2.4850080013275146
Validation loss: 2.1333653032779694

Epoch: 5| Step: 1
Training loss: 2.072965145111084
Validation loss: 2.1519349118073783

Epoch: 5| Step: 2
Training loss: 2.539303779602051
Validation loss: 2.146215115984281

Epoch: 5| Step: 3
Training loss: 1.657965064048767
Validation loss: 2.1509091357390084

Epoch: 5| Step: 4
Training loss: 1.7333307266235352
Validation loss: 2.1392652839422226

Epoch: 5| Step: 5
Training loss: 1.792729139328003
Validation loss: 2.1411590526501336

Epoch: 5| Step: 6
Training loss: 1.5511367321014404
Validation loss: 2.125905747214953

Epoch: 5| Step: 7
Training loss: 1.9471954107284546
Validation loss: 2.109479417403539

Epoch: 5| Step: 8
Training loss: 1.4869539737701416
Validation loss: 2.11327717701594

Epoch: 5| Step: 9
Training loss: 2.0101656913757324
Validation loss: 2.1110496819019318

Epoch: 5| Step: 10
Training loss: 2.4304890632629395
Validation loss: 2.097918763756752

Epoch: 5| Step: 11
Training loss: 1.5771058797836304
Validation loss: 2.0894341419140496

Epoch: 231| Step: 0
Training loss: 2.3415470123291016
Validation loss: 2.097538471221924

Epoch: 5| Step: 1
Training loss: 1.8925683498382568
Validation loss: 2.1196503788232803

Epoch: 5| Step: 2
Training loss: 1.8471399545669556
Validation loss: 2.1049757301807404

Epoch: 5| Step: 3
Training loss: 2.1211695671081543
Validation loss: 2.1125272711118064

Epoch: 5| Step: 4
Training loss: 2.3933799266815186
Validation loss: 2.1002027144034705

Epoch: 5| Step: 5
Training loss: 2.0756702423095703
Validation loss: 2.1057643393675485

Epoch: 5| Step: 6
Training loss: 1.6319992542266846
Validation loss: 2.11763788263003

Epoch: 5| Step: 7
Training loss: 2.307955265045166
Validation loss: 2.1157345473766327

Epoch: 5| Step: 8
Training loss: 1.801626205444336
Validation loss: 2.113895987470945

Epoch: 5| Step: 9
Training loss: 1.4750866889953613
Validation loss: 2.129157612721125

Epoch: 5| Step: 10
Training loss: 1.5207483768463135
Validation loss: 2.1334415276845298

Epoch: 5| Step: 11
Training loss: 1.1550700664520264
Validation loss: 2.125143493215243

Epoch: 232| Step: 0
Training loss: 1.9323062896728516
Validation loss: 2.1252001225948334

Epoch: 5| Step: 1
Training loss: 1.4521681070327759
Validation loss: 2.122408280769984

Epoch: 5| Step: 2
Training loss: 2.123762369155884
Validation loss: 2.1124519606431327

Epoch: 5| Step: 3
Training loss: 2.113117218017578
Validation loss: 2.1205180337031684

Epoch: 5| Step: 4
Training loss: 1.6741596460342407
Validation loss: 2.1207102040449777

Epoch: 5| Step: 5
Training loss: 2.575653553009033
Validation loss: 2.118457476298014

Epoch: 5| Step: 6
Training loss: 2.0375735759735107
Validation loss: 2.1126660207907357

Epoch: 5| Step: 7
Training loss: 1.6076221466064453
Validation loss: 2.1206469933191934

Epoch: 5| Step: 8
Training loss: 1.940173864364624
Validation loss: 2.1249548147122064

Epoch: 5| Step: 9
Training loss: 1.7869828939437866
Validation loss: 2.130123327175776

Epoch: 5| Step: 10
Training loss: 1.9028993844985962
Validation loss: 2.1252379616101584

Epoch: 5| Step: 11
Training loss: 1.7250922918319702
Validation loss: 2.127961367368698

Epoch: 233| Step: 0
Training loss: 2.092308521270752
Validation loss: 2.131348262230555

Epoch: 5| Step: 1
Training loss: 1.9691169261932373
Validation loss: 2.121707538763682

Epoch: 5| Step: 2
Training loss: 2.0726935863494873
Validation loss: 2.122532178958257

Epoch: 5| Step: 3
Training loss: 2.207580089569092
Validation loss: 2.1291819562514624

Epoch: 5| Step: 4
Training loss: 1.9599189758300781
Validation loss: 2.135865012804667

Epoch: 5| Step: 5
Training loss: 2.191500425338745
Validation loss: 2.124087616801262

Epoch: 5| Step: 6
Training loss: 1.6896116733551025
Validation loss: 2.117692679166794

Epoch: 5| Step: 7
Training loss: 1.6705337762832642
Validation loss: 2.118879958987236

Epoch: 5| Step: 8
Training loss: 1.6683683395385742
Validation loss: 2.1152794857819877

Epoch: 5| Step: 9
Training loss: 2.255751371383667
Validation loss: 2.1130126615365348

Epoch: 5| Step: 10
Training loss: 1.549290657043457
Validation loss: 2.121567557255427

Epoch: 5| Step: 11
Training loss: 1.0372940301895142
Validation loss: 2.11035984257857

Epoch: 234| Step: 0
Training loss: 2.2264621257781982
Validation loss: 2.1207518527905145

Epoch: 5| Step: 1
Training loss: 2.005427837371826
Validation loss: 2.1200091739495597

Epoch: 5| Step: 2
Training loss: 2.2853951454162598
Validation loss: 2.1058082381884256

Epoch: 5| Step: 3
Training loss: 1.7219871282577515
Validation loss: 2.123569210370382

Epoch: 5| Step: 4
Training loss: 1.6669609546661377
Validation loss: 2.1189113408327103

Epoch: 5| Step: 5
Training loss: 1.6832225322723389
Validation loss: 2.1124910662571588

Epoch: 5| Step: 6
Training loss: 2.2434353828430176
Validation loss: 2.113612790902456

Epoch: 5| Step: 7
Training loss: 2.09946870803833
Validation loss: 2.1060926566521325

Epoch: 5| Step: 8
Training loss: 1.7925446033477783
Validation loss: 2.1187620957692466

Epoch: 5| Step: 9
Training loss: 1.7575714588165283
Validation loss: 2.1037570039431253

Epoch: 5| Step: 10
Training loss: 1.7238353490829468
Validation loss: 2.1100182781616845

Epoch: 5| Step: 11
Training loss: 1.2699917554855347
Validation loss: 2.1152065048615136

Epoch: 235| Step: 0
Training loss: 1.731520414352417
Validation loss: 2.1140040258566537

Epoch: 5| Step: 1
Training loss: 1.445655107498169
Validation loss: 2.111578186353048

Epoch: 5| Step: 2
Training loss: 2.128836154937744
Validation loss: 2.107308804988861

Epoch: 5| Step: 3
Training loss: 1.9757871627807617
Validation loss: 2.1106298665205636

Epoch: 5| Step: 4
Training loss: 2.0445361137390137
Validation loss: 2.110501527786255

Epoch: 5| Step: 5
Training loss: 1.9636214971542358
Validation loss: 2.10290697713693

Epoch: 5| Step: 6
Training loss: 2.196255922317505
Validation loss: 2.1147858599821725

Epoch: 5| Step: 7
Training loss: 1.694422721862793
Validation loss: 2.1151364147663116

Epoch: 5| Step: 8
Training loss: 1.7654826641082764
Validation loss: 2.123242119948069

Epoch: 5| Step: 9
Training loss: 2.1292052268981934
Validation loss: 2.1163711746533713

Epoch: 5| Step: 10
Training loss: 2.1083545684814453
Validation loss: 2.1183987061182656

Epoch: 5| Step: 11
Training loss: 1.2857253551483154
Validation loss: 2.1096199502547583

Epoch: 236| Step: 0
Training loss: 1.9463014602661133
Validation loss: 2.124857852856318

Epoch: 5| Step: 1
Training loss: 1.802182912826538
Validation loss: 2.12982714176178

Epoch: 5| Step: 2
Training loss: 1.9834697246551514
Validation loss: 2.122056325276693

Epoch: 5| Step: 3
Training loss: 1.5248229503631592
Validation loss: 2.1169488728046417

Epoch: 5| Step: 4
Training loss: 2.1683216094970703
Validation loss: 2.1254738519589105

Epoch: 5| Step: 5
Training loss: 1.440946102142334
Validation loss: 2.122593432664871

Epoch: 5| Step: 6
Training loss: 2.176165819168091
Validation loss: 2.1025922894477844

Epoch: 5| Step: 7
Training loss: 2.629307746887207
Validation loss: 2.125304192304611

Epoch: 5| Step: 8
Training loss: 1.7379472255706787
Validation loss: 2.1178993781407676

Epoch: 5| Step: 9
Training loss: 1.6679515838623047
Validation loss: 2.1317418118317923

Epoch: 5| Step: 10
Training loss: 1.8722610473632812
Validation loss: 2.1190179139375687

Epoch: 5| Step: 11
Training loss: 2.086918354034424
Validation loss: 2.125574916601181

Epoch: 237| Step: 0
Training loss: 1.6712665557861328
Validation loss: 2.12301567196846

Epoch: 5| Step: 1
Training loss: 1.4972559213638306
Validation loss: 2.112896407643954

Epoch: 5| Step: 2
Training loss: 1.880671739578247
Validation loss: 2.139975999792417

Epoch: 5| Step: 3
Training loss: 2.403839588165283
Validation loss: 2.1235073059797287

Epoch: 5| Step: 4
Training loss: 1.765155553817749
Validation loss: 2.1340981920560202

Epoch: 5| Step: 5
Training loss: 2.0234375
Validation loss: 2.127555340528488

Epoch: 5| Step: 6
Training loss: 1.9284884929656982
Validation loss: 2.1204275687535605

Epoch: 5| Step: 7
Training loss: 1.9224313497543335
Validation loss: 2.1191334327061973

Epoch: 5| Step: 8
Training loss: 1.99355149269104
Validation loss: 2.123399391770363

Epoch: 5| Step: 9
Training loss: 1.9407564401626587
Validation loss: 2.122351422905922

Epoch: 5| Step: 10
Training loss: 1.8902209997177124
Validation loss: 2.126760333776474

Epoch: 5| Step: 11
Training loss: 1.9027800559997559
Validation loss: 2.12529523173968

Epoch: 238| Step: 0
Training loss: 1.4037349224090576
Validation loss: 2.1210425396760306

Epoch: 5| Step: 1
Training loss: 2.2960572242736816
Validation loss: 2.140313337246577

Epoch: 5| Step: 2
Training loss: 2.505143642425537
Validation loss: 2.1264806936184564

Epoch: 5| Step: 3
Training loss: 1.9892685413360596
Validation loss: 2.1345388889312744

Epoch: 5| Step: 4
Training loss: 2.377704620361328
Validation loss: 2.1363236556450524

Epoch: 5| Step: 5
Training loss: 1.898644208908081
Validation loss: 2.1487420399983725

Epoch: 5| Step: 6
Training loss: 1.6867763996124268
Validation loss: 2.1307651003201804

Epoch: 5| Step: 7
Training loss: 1.7110286951065063
Validation loss: 2.1236908435821533

Epoch: 5| Step: 8
Training loss: 2.058614492416382
Validation loss: 2.1190169602632523

Epoch: 5| Step: 9
Training loss: 1.6266810894012451
Validation loss: 2.1232560525337854

Epoch: 5| Step: 10
Training loss: 1.4220044612884521
Validation loss: 2.1113120764493942

Epoch: 5| Step: 11
Training loss: 1.998053789138794
Validation loss: 2.1192950904369354

Epoch: 239| Step: 0
Training loss: 1.6578757762908936
Validation loss: 2.1238687684138617

Epoch: 5| Step: 1
Training loss: 2.5284595489501953
Validation loss: 2.11063289642334

Epoch: 5| Step: 2
Training loss: 1.8100979328155518
Validation loss: 2.1276723643143973

Epoch: 5| Step: 3
Training loss: 2.01763653755188
Validation loss: 2.1218340496222177

Epoch: 5| Step: 4
Training loss: 1.6549049615859985
Validation loss: 2.1362991333007812

Epoch: 5| Step: 5
Training loss: 1.931772232055664
Validation loss: 2.133641635378202

Epoch: 5| Step: 6
Training loss: 1.6401363611221313
Validation loss: 2.1204124788443246

Epoch: 5| Step: 7
Training loss: 2.085249185562134
Validation loss: 2.1212834318478904

Epoch: 5| Step: 8
Training loss: 1.795204758644104
Validation loss: 2.13500947256883

Epoch: 5| Step: 9
Training loss: 1.920241355895996
Validation loss: 2.1337872793277106

Epoch: 5| Step: 10
Training loss: 1.8601093292236328
Validation loss: 2.1513412495454154

Epoch: 5| Step: 11
Training loss: 1.675958275794983
Validation loss: 2.157106260458628

Epoch: 240| Step: 0
Training loss: 2.294928789138794
Validation loss: 2.145231788357099

Epoch: 5| Step: 1
Training loss: 1.913680076599121
Validation loss: 2.1476989736159644

Epoch: 5| Step: 2
Training loss: 1.4185587167739868
Validation loss: 2.1581050554911294

Epoch: 5| Step: 3
Training loss: 1.8959163427352905
Validation loss: 2.13903080423673

Epoch: 5| Step: 4
Training loss: 1.661953330039978
Validation loss: 2.1287223547697067

Epoch: 5| Step: 5
Training loss: 1.9968929290771484
Validation loss: 2.130710323651632

Epoch: 5| Step: 6
Training loss: 1.6907713413238525
Validation loss: 2.1217687278985977

Epoch: 5| Step: 7
Training loss: 1.9275903701782227
Validation loss: 2.124880055586497

Epoch: 5| Step: 8
Training loss: 2.2179243564605713
Validation loss: 2.119963804880778

Epoch: 5| Step: 9
Training loss: 2.7178499698638916
Validation loss: 2.120483100414276

Epoch: 5| Step: 10
Training loss: 1.6001228094100952
Validation loss: 2.121108924349149

Epoch: 5| Step: 11
Training loss: 2.011035203933716
Validation loss: 2.121750811735789

Epoch: 241| Step: 0
Training loss: 1.8663246631622314
Validation loss: 2.1321430106957755

Epoch: 5| Step: 1
Training loss: 1.9385435581207275
Validation loss: 2.147971043984095

Epoch: 5| Step: 2
Training loss: 2.2388715744018555
Validation loss: 2.1431774894396463

Epoch: 5| Step: 3
Training loss: 1.8605324029922485
Validation loss: 2.1369658509890237

Epoch: 5| Step: 4
Training loss: 1.7881062030792236
Validation loss: 2.1445998748143515

Epoch: 5| Step: 5
Training loss: 2.057847261428833
Validation loss: 2.1441468546787896

Epoch: 5| Step: 6
Training loss: 1.8541465997695923
Validation loss: 2.1386542121569314

Epoch: 5| Step: 7
Training loss: 1.893043875694275
Validation loss: 2.138946289817492

Epoch: 5| Step: 8
Training loss: 1.4361040592193604
Validation loss: 2.152210916082064

Epoch: 5| Step: 9
Training loss: 1.785740852355957
Validation loss: 2.16504900654157

Epoch: 5| Step: 10
Training loss: 2.200388193130493
Validation loss: 2.1512449284394584

Epoch: 5| Step: 11
Training loss: 1.3068052530288696
Validation loss: 2.143446365992228

Epoch: 242| Step: 0
Training loss: 1.9442908763885498
Validation loss: 2.126105303565661

Epoch: 5| Step: 1
Training loss: 1.995070219039917
Validation loss: 2.144464006026586

Epoch: 5| Step: 2
Training loss: 1.8882986307144165
Validation loss: 2.1243888586759567

Epoch: 5| Step: 3
Training loss: 1.8815793991088867
Validation loss: 2.146926795442899

Epoch: 5| Step: 4
Training loss: 1.9636119604110718
Validation loss: 2.139917403459549

Epoch: 5| Step: 5
Training loss: 1.82144033908844
Validation loss: 2.145712678631147

Epoch: 5| Step: 6
Training loss: 1.6485369205474854
Validation loss: 2.130811254183451

Epoch: 5| Step: 7
Training loss: 1.7330601215362549
Validation loss: 2.1439402302106223

Epoch: 5| Step: 8
Training loss: 1.5442506074905396
Validation loss: 2.1337797343730927

Epoch: 5| Step: 9
Training loss: 1.881488561630249
Validation loss: 2.131120959917704

Epoch: 5| Step: 10
Training loss: 2.060272216796875
Validation loss: 2.13265323638916

Epoch: 5| Step: 11
Training loss: 3.669032096862793
Validation loss: 2.123869796593984

Epoch: 243| Step: 0
Training loss: 1.5959019660949707
Validation loss: 2.123583883047104

Epoch: 5| Step: 1
Training loss: 1.8199018239974976
Validation loss: 2.1271181106567383

Epoch: 5| Step: 2
Training loss: 1.9265037775039673
Validation loss: 2.12512477238973

Epoch: 5| Step: 3
Training loss: 2.333556890487671
Validation loss: 2.150933255751928

Epoch: 5| Step: 4
Training loss: 1.3880534172058105
Validation loss: 2.1380429913600287

Epoch: 5| Step: 5
Training loss: 2.0203633308410645
Validation loss: 2.142575075229009

Epoch: 5| Step: 6
Training loss: 2.0182032585144043
Validation loss: 2.137140760819117

Epoch: 5| Step: 7
Training loss: 2.6613733768463135
Validation loss: 2.1534195840358734

Epoch: 5| Step: 8
Training loss: 1.2584335803985596
Validation loss: 2.1434716979662576

Epoch: 5| Step: 9
Training loss: 1.7445091009140015
Validation loss: 2.1484162906805673

Epoch: 5| Step: 10
Training loss: 2.1399385929107666
Validation loss: 2.1351674596468606

Epoch: 5| Step: 11
Training loss: 1.2323859930038452
Validation loss: 2.1351524939139686

Epoch: 244| Step: 0
Training loss: 1.8271934986114502
Validation loss: 2.1417003373305

Epoch: 5| Step: 1
Training loss: 1.5807892084121704
Validation loss: 2.135993351538976

Epoch: 5| Step: 2
Training loss: 2.4185566902160645
Validation loss: 2.1299921025832496

Epoch: 5| Step: 3
Training loss: 1.61960768699646
Validation loss: 2.12432270248731

Epoch: 5| Step: 4
Training loss: 1.7768256664276123
Validation loss: 2.134649862845739

Epoch: 5| Step: 5
Training loss: 2.4403929710388184
Validation loss: 2.1290531903505325

Epoch: 5| Step: 6
Training loss: 1.5433169603347778
Validation loss: 2.130891109506289

Epoch: 5| Step: 7
Training loss: 2.371823787689209
Validation loss: 2.142543370525042

Epoch: 5| Step: 8
Training loss: 1.9032812118530273
Validation loss: 2.139752825101217

Epoch: 5| Step: 9
Training loss: 2.3726296424865723
Validation loss: 2.140307684739431

Epoch: 5| Step: 10
Training loss: 1.079003095626831
Validation loss: 2.1410655975341797

Epoch: 5| Step: 11
Training loss: 1.4028775691986084
Validation loss: 2.1465838650862374

Epoch: 245| Step: 0
Training loss: 1.8657848834991455
Validation loss: 2.1523730208476386

Epoch: 5| Step: 1
Training loss: 1.665930986404419
Validation loss: 2.1413273215293884

Epoch: 5| Step: 2
Training loss: 2.2321584224700928
Validation loss: 2.131212373574575

Epoch: 5| Step: 3
Training loss: 1.5493255853652954
Validation loss: 2.1423385043938956

Epoch: 5| Step: 4
Training loss: 1.8551099300384521
Validation loss: 2.1140104134877524

Epoch: 5| Step: 5
Training loss: 1.8250439167022705
Validation loss: 2.129027550419172

Epoch: 5| Step: 6
Training loss: 2.0906260013580322
Validation loss: 2.1153626441955566

Epoch: 5| Step: 7
Training loss: 2.038235902786255
Validation loss: 2.119124710559845

Epoch: 5| Step: 8
Training loss: 1.8656765222549438
Validation loss: 2.1233851611614227

Epoch: 5| Step: 9
Training loss: 1.871437430381775
Validation loss: 2.1231467177470527

Epoch: 5| Step: 10
Training loss: 2.0018868446350098
Validation loss: 2.1378552267948785

Epoch: 5| Step: 11
Training loss: 1.5046993494033813
Validation loss: 2.1272780696551004

Epoch: 246| Step: 0
Training loss: 1.6903460025787354
Validation loss: 2.131348967552185

Epoch: 5| Step: 1
Training loss: 2.437138319015503
Validation loss: 2.131211429834366

Epoch: 5| Step: 2
Training loss: 2.0982446670532227
Validation loss: 2.1270231505235038

Epoch: 5| Step: 3
Training loss: 2.0844614505767822
Validation loss: 2.1356833775838218

Epoch: 5| Step: 4
Training loss: 2.1811530590057373
Validation loss: 2.1508127748966217

Epoch: 5| Step: 5
Training loss: 1.58005952835083
Validation loss: 2.12839941183726

Epoch: 5| Step: 6
Training loss: 1.6940743923187256
Validation loss: 2.1393980383872986

Epoch: 5| Step: 7
Training loss: 1.5426641702651978
Validation loss: 2.1477032800515494

Epoch: 5| Step: 8
Training loss: 1.9665616750717163
Validation loss: 2.1252949138482413

Epoch: 5| Step: 9
Training loss: 1.9547773599624634
Validation loss: 2.122301608324051

Epoch: 5| Step: 10
Training loss: 1.9210973978042603
Validation loss: 2.137521510322889

Epoch: 5| Step: 11
Training loss: 1.2873258590698242
Validation loss: 2.1273349225521088

Epoch: 247| Step: 0
Training loss: 1.8133341073989868
Validation loss: 2.133580729365349

Epoch: 5| Step: 1
Training loss: 1.709566354751587
Validation loss: 2.119159663716952

Epoch: 5| Step: 2
Training loss: 1.8021736145019531
Validation loss: 2.128862122694651

Epoch: 5| Step: 3
Training loss: 1.744624376296997
Validation loss: 2.137178957462311

Epoch: 5| Step: 4
Training loss: 2.2375261783599854
Validation loss: 2.132246990998586

Epoch: 5| Step: 5
Training loss: 2.1734957695007324
Validation loss: 2.1243255337079368

Epoch: 5| Step: 6
Training loss: 2.581606388092041
Validation loss: 2.1330986668666205

Epoch: 5| Step: 7
Training loss: 1.7713878154754639
Validation loss: 2.137795150279999

Epoch: 5| Step: 8
Training loss: 1.5095399618148804
Validation loss: 2.127925137678782

Epoch: 5| Step: 9
Training loss: 1.8129940032958984
Validation loss: 2.1363471845785775

Epoch: 5| Step: 10
Training loss: 1.7202314138412476
Validation loss: 2.1442513912916183

Epoch: 5| Step: 11
Training loss: 2.1440858840942383
Validation loss: 2.146032601594925

Epoch: 248| Step: 0
Training loss: 1.8699359893798828
Validation loss: 2.139181067546209

Epoch: 5| Step: 1
Training loss: 1.4515693187713623
Validation loss: 2.1385387629270554

Epoch: 5| Step: 2
Training loss: 2.3036468029022217
Validation loss: 2.142968386411667

Epoch: 5| Step: 3
Training loss: 2.2459588050842285
Validation loss: 2.131833573182424

Epoch: 5| Step: 4
Training loss: 1.5235469341278076
Validation loss: 2.137048602104187

Epoch: 5| Step: 5
Training loss: 2.553642749786377
Validation loss: 2.1290494551261268

Epoch: 5| Step: 6
Training loss: 1.6557903289794922
Validation loss: 2.1327394346396127

Epoch: 5| Step: 7
Training loss: 2.4122016429901123
Validation loss: 2.1355129977067313

Epoch: 5| Step: 8
Training loss: 1.4115419387817383
Validation loss: 2.122582127650579

Epoch: 5| Step: 9
Training loss: 1.4202148914337158
Validation loss: 2.1387645105520883

Epoch: 5| Step: 10
Training loss: 1.924676537513733
Validation loss: 2.136956438422203

Epoch: 5| Step: 11
Training loss: 2.502406120300293
Validation loss: 2.1435513297716775

Epoch: 249| Step: 0
Training loss: 1.746411919593811
Validation loss: 2.144734804828962

Epoch: 5| Step: 1
Training loss: 1.5382447242736816
Validation loss: 2.146986315647761

Epoch: 5| Step: 2
Training loss: 2.1515116691589355
Validation loss: 2.1617603302001953

Epoch: 5| Step: 3
Training loss: 1.961239218711853
Validation loss: 2.1637236972649894

Epoch: 5| Step: 4
Training loss: 1.7510114908218384
Validation loss: 2.16280190149943

Epoch: 5| Step: 5
Training loss: 2.0524215698242188
Validation loss: 2.146583770712217

Epoch: 5| Step: 6
Training loss: 2.37327241897583
Validation loss: 2.1434923013051352

Epoch: 5| Step: 7
Training loss: 1.978278398513794
Validation loss: 2.15435062845548

Epoch: 5| Step: 8
Training loss: 1.9068164825439453
Validation loss: 2.150177369515101

Epoch: 5| Step: 9
Training loss: 1.8873870372772217
Validation loss: 2.152701993783315

Epoch: 5| Step: 10
Training loss: 1.6536471843719482
Validation loss: 2.1554084668556848

Epoch: 5| Step: 11
Training loss: 0.6614617109298706
Validation loss: 2.1286849975585938

Epoch: 250| Step: 0
Training loss: 1.938770055770874
Validation loss: 2.112641150752703

Epoch: 5| Step: 1
Training loss: 2.410813331604004
Validation loss: 2.119755064447721

Epoch: 5| Step: 2
Training loss: 2.438264846801758
Validation loss: 2.1156636426846185

Epoch: 5| Step: 3
Training loss: 2.2824981212615967
Validation loss: 2.1165220042069754

Epoch: 5| Step: 4
Training loss: 1.8102314472198486
Validation loss: 2.111059938867887

Epoch: 5| Step: 5
Training loss: 1.5509121417999268
Validation loss: 2.1128284434477487

Epoch: 5| Step: 6
Training loss: 2.430835485458374
Validation loss: 2.1095493833223977

Epoch: 5| Step: 7
Training loss: 1.6765682697296143
Validation loss: 2.124836564064026

Epoch: 5| Step: 8
Training loss: 1.9476966857910156
Validation loss: 2.1233082711696625

Epoch: 5| Step: 9
Training loss: 1.6801478862762451
Validation loss: 2.118586853146553

Epoch: 5| Step: 10
Training loss: 1.4091789722442627
Validation loss: 2.1176167180140815

Epoch: 5| Step: 11
Training loss: 1.2203295230865479
Validation loss: 2.132145881652832

Epoch: 251| Step: 0
Training loss: 1.8903741836547852
Validation loss: 2.1530741105477014

Epoch: 5| Step: 1
Training loss: 1.7616386413574219
Validation loss: 2.1606170336405435

Epoch: 5| Step: 2
Training loss: 2.5802810192108154
Validation loss: 2.175742268562317

Epoch: 5| Step: 3
Training loss: 1.7280175685882568
Validation loss: 2.1886181930700936

Epoch: 5| Step: 4
Training loss: 1.6724859476089478
Validation loss: 2.1739895145098367

Epoch: 5| Step: 5
Training loss: 2.106905460357666
Validation loss: 2.1551304906606674

Epoch: 5| Step: 6
Training loss: 2.2998569011688232
Validation loss: 2.1503616174062095

Epoch: 5| Step: 7
Training loss: 1.782710313796997
Validation loss: 2.1585946828126907

Epoch: 5| Step: 8
Training loss: 1.9659826755523682
Validation loss: 2.1433482666810355

Epoch: 5| Step: 9
Training loss: 1.7857033014297485
Validation loss: 2.1372144569953284

Epoch: 5| Step: 10
Training loss: 2.0003743171691895
Validation loss: 2.1217784136533737

Epoch: 5| Step: 11
Training loss: 2.579296588897705
Validation loss: 2.128875563542048

Epoch: 252| Step: 0
Training loss: 2.013601779937744
Validation loss: 2.1231322586536407

Epoch: 5| Step: 1
Training loss: 2.0784130096435547
Validation loss: 2.1161935875813165

Epoch: 5| Step: 2
Training loss: 1.9718440771102905
Validation loss: 2.107811212539673

Epoch: 5| Step: 3
Training loss: 1.8043349981307983
Validation loss: 2.113844727476438

Epoch: 5| Step: 4
Training loss: 2.6349120140075684
Validation loss: 2.1238464464743934

Epoch: 5| Step: 5
Training loss: 1.5511547327041626
Validation loss: 2.1190355072418847

Epoch: 5| Step: 6
Training loss: 2.3352115154266357
Validation loss: 2.1153634985287986

Epoch: 5| Step: 7
Training loss: 1.572803020477295
Validation loss: 2.1169163833061853

Epoch: 5| Step: 8
Training loss: 1.6828120946884155
Validation loss: 2.1078153550624847

Epoch: 5| Step: 9
Training loss: 2.0856449604034424
Validation loss: 2.118224506576856

Epoch: 5| Step: 10
Training loss: 1.9165170192718506
Validation loss: 2.1139160643021264

Epoch: 5| Step: 11
Training loss: 1.6309568881988525
Validation loss: 2.1261235425869622

Epoch: 253| Step: 0
Training loss: 1.3034484386444092
Validation loss: 2.129194205005964

Epoch: 5| Step: 1
Training loss: 2.1044867038726807
Validation loss: 2.133767028649648

Epoch: 5| Step: 2
Training loss: 1.3330192565917969
Validation loss: 2.1471271912256875

Epoch: 5| Step: 3
Training loss: 2.241649627685547
Validation loss: 2.1433942914009094

Epoch: 5| Step: 4
Training loss: 1.846122145652771
Validation loss: 2.1444207529226937

Epoch: 5| Step: 5
Training loss: 1.7194099426269531
Validation loss: 2.1568929851055145

Epoch: 5| Step: 6
Training loss: 2.381455898284912
Validation loss: 2.157450551788012

Epoch: 5| Step: 7
Training loss: 2.6214587688446045
Validation loss: 2.1620997885862985

Epoch: 5| Step: 8
Training loss: 1.9178301095962524
Validation loss: 2.173379202683767

Epoch: 5| Step: 9
Training loss: 1.9747823476791382
Validation loss: 2.1546273132165275

Epoch: 5| Step: 10
Training loss: 1.590854287147522
Validation loss: 2.156345953543981

Epoch: 5| Step: 11
Training loss: 1.4895418882369995
Validation loss: 2.150864760080973

Epoch: 254| Step: 0
Training loss: 1.4338171482086182
Validation loss: 2.1396155258019767

Epoch: 5| Step: 1
Training loss: 1.4682564735412598
Validation loss: 2.115226368109385

Epoch: 5| Step: 2
Training loss: 2.1736032962799072
Validation loss: 2.1217318773269653

Epoch: 5| Step: 3
Training loss: 2.6459901332855225
Validation loss: 2.1076997568209968

Epoch: 5| Step: 4
Training loss: 1.8745629787445068
Validation loss: 2.11409592628479

Epoch: 5| Step: 5
Training loss: 1.9439620971679688
Validation loss: 2.113706727822622

Epoch: 5| Step: 6
Training loss: 2.448613405227661
Validation loss: 2.1162976125876107

Epoch: 5| Step: 7
Training loss: 1.3361457586288452
Validation loss: 2.1292764842510223

Epoch: 5| Step: 8
Training loss: 1.4499796628952026
Validation loss: 2.128145714600881

Epoch: 5| Step: 9
Training loss: 2.640293836593628
Validation loss: 2.125232140223185

Epoch: 5| Step: 10
Training loss: 1.0979807376861572
Validation loss: 2.13130155702432

Epoch: 5| Step: 11
Training loss: 2.3732504844665527
Validation loss: 2.1115561376015344

Epoch: 255| Step: 0
Training loss: 1.4528464078903198
Validation loss: 2.1294563313325248

Epoch: 5| Step: 1
Training loss: 1.5688589811325073
Validation loss: 2.1243442247311273

Epoch: 5| Step: 2
Training loss: 1.8750755786895752
Validation loss: 2.139287680387497

Epoch: 5| Step: 3
Training loss: 2.0921382904052734
Validation loss: 2.1359899441401162

Epoch: 5| Step: 4
Training loss: 2.5784125328063965
Validation loss: 2.135114371776581

Epoch: 5| Step: 5
Training loss: 1.9653160572052002
Validation loss: 2.1460495243469873

Epoch: 5| Step: 6
Training loss: 1.9862581491470337
Validation loss: 2.1509547034899392

Epoch: 5| Step: 7
Training loss: 2.173529624938965
Validation loss: 2.1519720405340195

Epoch: 5| Step: 8
Training loss: 1.6050688028335571
Validation loss: 2.1480650901794434

Epoch: 5| Step: 9
Training loss: 1.4432340860366821
Validation loss: 2.144048680861791

Epoch: 5| Step: 10
Training loss: 1.7241392135620117
Validation loss: 2.1516636113325753

Epoch: 5| Step: 11
Training loss: 3.245344400405884
Validation loss: 2.1459224422772727

Epoch: 256| Step: 0
Training loss: 1.7805198431015015
Validation loss: 2.147300730148951

Epoch: 5| Step: 1
Training loss: 2.059981107711792
Validation loss: 2.1388643980026245

Epoch: 5| Step: 2
Training loss: 1.873774766921997
Validation loss: 2.169387623667717

Epoch: 5| Step: 3
Training loss: 1.8595316410064697
Validation loss: 2.142291600505511

Epoch: 5| Step: 4
Training loss: 1.5242674350738525
Validation loss: 2.142830024162928

Epoch: 5| Step: 5
Training loss: 1.908712387084961
Validation loss: 2.1404228111108146

Epoch: 5| Step: 6
Training loss: 1.9069076776504517
Validation loss: 2.13199345767498

Epoch: 5| Step: 7
Training loss: 2.1462111473083496
Validation loss: 2.1260516544183097

Epoch: 5| Step: 8
Training loss: 1.448213815689087
Validation loss: 2.137620434165001

Epoch: 5| Step: 9
Training loss: 1.6111724376678467
Validation loss: 2.1285608609517417

Epoch: 5| Step: 10
Training loss: 2.7127537727355957
Validation loss: 2.125774954756101

Epoch: 5| Step: 11
Training loss: 1.0080654621124268
Validation loss: 2.128024011850357

Epoch: 257| Step: 0
Training loss: 1.7627336978912354
Validation loss: 2.1213019291559854

Epoch: 5| Step: 1
Training loss: 1.79518723487854
Validation loss: 2.1508096059163413

Epoch: 5| Step: 2
Training loss: 1.9740464687347412
Validation loss: 2.155607501665751

Epoch: 5| Step: 3
Training loss: 1.481804370880127
Validation loss: 2.152426133553187

Epoch: 5| Step: 4
Training loss: 2.0852904319763184
Validation loss: 2.161763146519661

Epoch: 5| Step: 5
Training loss: 1.8825600147247314
Validation loss: 2.14713853597641

Epoch: 5| Step: 6
Training loss: 2.1668946743011475
Validation loss: 2.1410969545443854

Epoch: 5| Step: 7
Training loss: 2.1011483669281006
Validation loss: 2.1415747503439584

Epoch: 5| Step: 8
Training loss: 1.8922621011734009
Validation loss: 2.152678961555163

Epoch: 5| Step: 9
Training loss: 1.84530508518219
Validation loss: 2.1523107290267944

Epoch: 5| Step: 10
Training loss: 1.620317816734314
Validation loss: 2.166481484969457

Epoch: 5| Step: 11
Training loss: 2.7969069480895996
Validation loss: 2.171842227379481

Epoch: 258| Step: 0
Training loss: 1.979540228843689
Validation loss: 2.163853093981743

Epoch: 5| Step: 1
Training loss: 1.7557904720306396
Validation loss: 2.148798018693924

Epoch: 5| Step: 2
Training loss: 2.3331525325775146
Validation loss: 2.1576863527297974

Epoch: 5| Step: 3
Training loss: 2.059957504272461
Validation loss: 2.1597197155157724

Epoch: 5| Step: 4
Training loss: 1.6179778575897217
Validation loss: 2.153172935048739

Epoch: 5| Step: 5
Training loss: 1.9006397724151611
Validation loss: 2.172243798772494

Epoch: 5| Step: 6
Training loss: 1.9614107608795166
Validation loss: 2.160868684450785

Epoch: 5| Step: 7
Training loss: 1.9330734014511108
Validation loss: 2.14263949294885

Epoch: 5| Step: 8
Training loss: 1.9112695455551147
Validation loss: 2.14774589240551

Epoch: 5| Step: 9
Training loss: 1.5236644744873047
Validation loss: 2.153629074494044

Epoch: 5| Step: 10
Training loss: 1.7390247583389282
Validation loss: 2.1389073779185614

Epoch: 5| Step: 11
Training loss: 1.4168699979782104
Validation loss: 2.1408193856477737

Epoch: 259| Step: 0
Training loss: 2.1387932300567627
Validation loss: 2.1353522340456643

Epoch: 5| Step: 1
Training loss: 1.845410943031311
Validation loss: 2.1290304760138192

Epoch: 5| Step: 2
Training loss: 2.3736166954040527
Validation loss: 2.1377371152242026

Epoch: 5| Step: 3
Training loss: 1.8544948101043701
Validation loss: 2.144381175438563

Epoch: 5| Step: 4
Training loss: 2.021635055541992
Validation loss: 2.143888289729754

Epoch: 5| Step: 5
Training loss: 1.9577564001083374
Validation loss: 2.1499560276667276

Epoch: 5| Step: 6
Training loss: 1.5375467538833618
Validation loss: 2.1467057863871255

Epoch: 5| Step: 7
Training loss: 1.8884727954864502
Validation loss: 2.131654813885689

Epoch: 5| Step: 8
Training loss: 1.6881307363510132
Validation loss: 2.140145699183146

Epoch: 5| Step: 9
Training loss: 1.5858855247497559
Validation loss: 2.14789479970932

Epoch: 5| Step: 10
Training loss: 1.8123515844345093
Validation loss: 2.142826408147812

Epoch: 5| Step: 11
Training loss: 0.9413379430770874
Validation loss: 2.147786815961202

Epoch: 260| Step: 0
Training loss: 2.289257049560547
Validation loss: 2.138499602675438

Epoch: 5| Step: 1
Training loss: 1.8057466745376587
Validation loss: 2.131636122862498

Epoch: 5| Step: 2
Training loss: 1.2844569683074951
Validation loss: 2.144751712679863

Epoch: 5| Step: 3
Training loss: 1.1474629640579224
Validation loss: 2.148986667394638

Epoch: 5| Step: 4
Training loss: 2.2127442359924316
Validation loss: 2.1436294118563333

Epoch: 5| Step: 5
Training loss: 2.122830390930176
Validation loss: 2.141023501753807

Epoch: 5| Step: 6
Training loss: 2.4335217475891113
Validation loss: 2.137914697329203

Epoch: 5| Step: 7
Training loss: 1.6725925207138062
Validation loss: 2.1465966403484344

Epoch: 5| Step: 8
Training loss: 1.890447974205017
Validation loss: 2.133333593606949

Epoch: 5| Step: 9
Training loss: 1.6392500400543213
Validation loss: 2.149809608856837

Epoch: 5| Step: 10
Training loss: 1.9496700763702393
Validation loss: 2.1442939043045044

Epoch: 5| Step: 11
Training loss: 1.5741978883743286
Validation loss: 2.136696403225263

Epoch: 261| Step: 0
Training loss: 1.5681034326553345
Validation loss: 2.1480340560277305

Epoch: 5| Step: 1
Training loss: 2.151834011077881
Validation loss: 2.1530065685510635

Epoch: 5| Step: 2
Training loss: 1.5917537212371826
Validation loss: 2.160699879129728

Epoch: 5| Step: 3
Training loss: 1.6749095916748047
Validation loss: 2.157308593392372

Epoch: 5| Step: 4
Training loss: 2.036881685256958
Validation loss: 2.173351138830185

Epoch: 5| Step: 5
Training loss: 2.0956149101257324
Validation loss: 2.167961652080218

Epoch: 5| Step: 6
Training loss: 2.0573036670684814
Validation loss: 2.1449840565522513

Epoch: 5| Step: 7
Training loss: 1.9364852905273438
Validation loss: 2.135117252667745

Epoch: 5| Step: 8
Training loss: 1.7629468441009521
Validation loss: 2.150949781139692

Epoch: 5| Step: 9
Training loss: 2.1007091999053955
Validation loss: 2.1419970442851386

Epoch: 5| Step: 10
Training loss: 1.8227481842041016
Validation loss: 2.1383621394634247

Epoch: 5| Step: 11
Training loss: 1.5004281997680664
Validation loss: 2.1478191216786704

Epoch: 262| Step: 0
Training loss: 1.8850934505462646
Validation loss: 2.145626733700434

Epoch: 5| Step: 1
Training loss: 1.7937145233154297
Validation loss: 2.1399499475955963

Epoch: 5| Step: 2
Training loss: 1.4828500747680664
Validation loss: 2.144208922982216

Epoch: 5| Step: 3
Training loss: 2.2512905597686768
Validation loss: 2.1497212052345276

Epoch: 5| Step: 4
Training loss: 2.071277618408203
Validation loss: 2.1513172686100006

Epoch: 5| Step: 5
Training loss: 2.2687437534332275
Validation loss: 2.1665198703606925

Epoch: 5| Step: 6
Training loss: 1.865851640701294
Validation loss: 2.164252832531929

Epoch: 5| Step: 7
Training loss: 1.6995452642440796
Validation loss: 2.1585951199134192

Epoch: 5| Step: 8
Training loss: 1.3481853008270264
Validation loss: 2.168817321459452

Epoch: 5| Step: 9
Training loss: 2.133847713470459
Validation loss: 2.1613283654054007

Epoch: 5| Step: 10
Training loss: 1.7268301248550415
Validation loss: 2.161059389511744

Epoch: 5| Step: 11
Training loss: 0.9316350221633911
Validation loss: 2.154536470770836

Epoch: 263| Step: 0
Training loss: 2.079387903213501
Validation loss: 2.1565671463807425

Epoch: 5| Step: 1
Training loss: 1.5283756256103516
Validation loss: 2.151526858409246

Epoch: 5| Step: 2
Training loss: 2.1458816528320312
Validation loss: 2.1624206403891244

Epoch: 5| Step: 3
Training loss: 1.602156400680542
Validation loss: 2.1514994502067566

Epoch: 5| Step: 4
Training loss: 1.5274673700332642
Validation loss: 2.1469484716653824

Epoch: 5| Step: 5
Training loss: 1.6936557292938232
Validation loss: 2.1498396545648575

Epoch: 5| Step: 6
Training loss: 2.1030020713806152
Validation loss: 2.1467898984750113

Epoch: 5| Step: 7
Training loss: 1.4582792520523071
Validation loss: 2.1344230473041534

Epoch: 5| Step: 8
Training loss: 1.8571733236312866
Validation loss: 2.157150149345398

Epoch: 5| Step: 9
Training loss: 2.142285108566284
Validation loss: 2.144165833791097

Epoch: 5| Step: 10
Training loss: 1.9729995727539062
Validation loss: 2.138780946532885

Epoch: 5| Step: 11
Training loss: 2.759751319885254
Validation loss: 2.1571213056643805

Epoch: 264| Step: 0
Training loss: 2.2183895111083984
Validation loss: 2.138012314836184

Epoch: 5| Step: 1
Training loss: 1.6684157848358154
Validation loss: 2.146472712357839

Epoch: 5| Step: 2
Training loss: 2.2844855785369873
Validation loss: 2.1358604431152344

Epoch: 5| Step: 3
Training loss: 1.628867506980896
Validation loss: 2.1404851973056793

Epoch: 5| Step: 4
Training loss: 2.2545318603515625
Validation loss: 2.14321938653787

Epoch: 5| Step: 5
Training loss: 1.5661656856536865
Validation loss: 2.1473853141069412

Epoch: 5| Step: 6
Training loss: 1.2501468658447266
Validation loss: 2.154509057601293

Epoch: 5| Step: 7
Training loss: 1.7912477254867554
Validation loss: 2.157311648130417

Epoch: 5| Step: 8
Training loss: 2.797010660171509
Validation loss: 2.165218636393547

Epoch: 5| Step: 9
Training loss: 1.6928333044052124
Validation loss: 2.1595206956068673

Epoch: 5| Step: 10
Training loss: 1.2280244827270508
Validation loss: 2.1778185764948526

Epoch: 5| Step: 11
Training loss: 1.6466100215911865
Validation loss: 2.1600745419661203

Epoch: 265| Step: 0
Training loss: 1.6631568670272827
Validation loss: 2.1472130119800568

Epoch: 5| Step: 1
Training loss: 1.86916983127594
Validation loss: 2.1637911995251975

Epoch: 5| Step: 2
Training loss: 1.8469280004501343
Validation loss: 2.156178633371989

Epoch: 5| Step: 3
Training loss: 2.2065014839172363
Validation loss: 2.170444612701734

Epoch: 5| Step: 4
Training loss: 2.030564785003662
Validation loss: 2.1626531879107156

Epoch: 5| Step: 5
Training loss: 2.1783337593078613
Validation loss: 2.1560117453336716

Epoch: 5| Step: 6
Training loss: 1.6856663227081299
Validation loss: 2.1650826185941696

Epoch: 5| Step: 7
Training loss: 1.7004753351211548
Validation loss: 2.184471686681112

Epoch: 5| Step: 8
Training loss: 1.9916608333587646
Validation loss: 2.163896153370539

Epoch: 5| Step: 9
Training loss: 1.8213531970977783
Validation loss: 2.1769987096389136

Epoch: 5| Step: 10
Training loss: 1.3202272653579712
Validation loss: 2.168213283022245

Epoch: 5| Step: 11
Training loss: 1.024721622467041
Validation loss: 2.1588937441507974

Epoch: 266| Step: 0
Training loss: 2.634507179260254
Validation loss: 2.163599361975988

Epoch: 5| Step: 1
Training loss: 1.7578647136688232
Validation loss: 2.1595357855161033

Epoch: 5| Step: 2
Training loss: 1.8222415447235107
Validation loss: 2.1541083256403604

Epoch: 5| Step: 3
Training loss: 1.6555471420288086
Validation loss: 2.1547053257624307

Epoch: 5| Step: 4
Training loss: 1.4811756610870361
Validation loss: 2.164910306533178

Epoch: 5| Step: 5
Training loss: 1.349622130393982
Validation loss: 2.149814168612162

Epoch: 5| Step: 6
Training loss: 1.7227157354354858
Validation loss: 2.167130301396052

Epoch: 5| Step: 7
Training loss: 1.8325639963150024
Validation loss: 2.16918816169103

Epoch: 5| Step: 8
Training loss: 1.9011033773422241
Validation loss: 2.1481894801060357

Epoch: 5| Step: 9
Training loss: 1.5733014345169067
Validation loss: 2.1532556861639023

Epoch: 5| Step: 10
Training loss: 2.184828996658325
Validation loss: 2.1538253823916116

Epoch: 5| Step: 11
Training loss: 2.705922842025757
Validation loss: 2.1726494232813516

Epoch: 267| Step: 0
Training loss: 2.4866957664489746
Validation loss: 2.1869707653919854

Epoch: 5| Step: 1
Training loss: 1.8920557498931885
Validation loss: 2.1731880754232407

Epoch: 5| Step: 2
Training loss: 1.2850165367126465
Validation loss: 2.173063317934672

Epoch: 5| Step: 3
Training loss: 1.82247793674469
Validation loss: 2.1674912373224893

Epoch: 5| Step: 4
Training loss: 2.2709298133850098
Validation loss: 2.1679347157478333

Epoch: 5| Step: 5
Training loss: 1.6710236072540283
Validation loss: 2.1708363691965737

Epoch: 5| Step: 6
Training loss: 1.9441817998886108
Validation loss: 2.1468247026205063

Epoch: 5| Step: 7
Training loss: 1.6166908740997314
Validation loss: 2.153254816929499

Epoch: 5| Step: 8
Training loss: 1.9198076725006104
Validation loss: 2.1525594741106033

Epoch: 5| Step: 9
Training loss: 1.7912406921386719
Validation loss: 2.1326208064953485

Epoch: 5| Step: 10
Training loss: 1.7748876810073853
Validation loss: 2.136658191680908

Epoch: 5| Step: 11
Training loss: 2.0975489616394043
Validation loss: 2.1528122574090958

Epoch: 268| Step: 0
Training loss: 1.9467408657073975
Validation loss: 2.149468849102656

Epoch: 5| Step: 1
Training loss: 1.9980350732803345
Validation loss: 2.1446230113506317

Epoch: 5| Step: 2
Training loss: 1.3462849855422974
Validation loss: 2.1722816278537116

Epoch: 5| Step: 3
Training loss: 1.8007876873016357
Validation loss: 2.170393372575442

Epoch: 5| Step: 4
Training loss: 1.3859068155288696
Validation loss: 2.152832329273224

Epoch: 5| Step: 5
Training loss: 1.809455156326294
Validation loss: 2.157109320163727

Epoch: 5| Step: 6
Training loss: 2.3186426162719727
Validation loss: 2.154148668050766

Epoch: 5| Step: 7
Training loss: 1.915234923362732
Validation loss: 2.144829655687014

Epoch: 5| Step: 8
Training loss: 1.3245975971221924
Validation loss: 2.1469882130622864

Epoch: 5| Step: 9
Training loss: 2.4990735054016113
Validation loss: 2.1416452626387277

Epoch: 5| Step: 10
Training loss: 2.1720170974731445
Validation loss: 2.144125054279963

Epoch: 5| Step: 11
Training loss: 1.8126435279846191
Validation loss: 2.1576473315556846

Epoch: 269| Step: 0
Training loss: 2.0381979942321777
Validation loss: 2.1484935730695724

Epoch: 5| Step: 1
Training loss: 1.228960633277893
Validation loss: 2.1657131065924964

Epoch: 5| Step: 2
Training loss: 1.637742042541504
Validation loss: 2.176687036951383

Epoch: 5| Step: 3
Training loss: 2.1544582843780518
Validation loss: 2.167487079898516

Epoch: 5| Step: 4
Training loss: 2.2121152877807617
Validation loss: 2.173320268591245

Epoch: 5| Step: 5
Training loss: 1.6428083181381226
Validation loss: 2.191389431556066

Epoch: 5| Step: 6
Training loss: 1.485565185546875
Validation loss: 2.192800427476565

Epoch: 5| Step: 7
Training loss: 2.311816453933716
Validation loss: 2.1838740011056266

Epoch: 5| Step: 8
Training loss: 1.5348901748657227
Validation loss: 2.1857676754395166

Epoch: 5| Step: 9
Training loss: 1.7795559167861938
Validation loss: 2.1841796139876046

Epoch: 5| Step: 10
Training loss: 2.5616447925567627
Validation loss: 2.185521110892296

Epoch: 5| Step: 11
Training loss: 1.749560832977295
Validation loss: 2.1550993472337723

Epoch: 270| Step: 0
Training loss: 1.8446117639541626
Validation loss: 2.1407927175362906

Epoch: 5| Step: 1
Training loss: 1.6691253185272217
Validation loss: 2.127241869767507

Epoch: 5| Step: 2
Training loss: 1.143977165222168
Validation loss: 2.13496225575606

Epoch: 5| Step: 3
Training loss: 1.6322011947631836
Validation loss: 2.1215458710988364

Epoch: 5| Step: 4
Training loss: 2.337674617767334
Validation loss: 2.1172867516676583

Epoch: 5| Step: 5
Training loss: 2.226964235305786
Validation loss: 2.1137488981088004

Epoch: 5| Step: 6
Training loss: 2.095834970474243
Validation loss: 2.1165209859609604

Epoch: 5| Step: 7
Training loss: 2.0573673248291016
Validation loss: 2.1050649682680764

Epoch: 5| Step: 8
Training loss: 2.3042242527008057
Validation loss: 2.1241854230562844

Epoch: 5| Step: 9
Training loss: 1.6298929452896118
Validation loss: 2.1130947122971215

Epoch: 5| Step: 10
Training loss: 2.3657147884368896
Validation loss: 2.1258744249741235

Epoch: 5| Step: 11
Training loss: 1.254660964012146
Validation loss: 2.137543340524038

Epoch: 271| Step: 0
Training loss: 2.0971920490264893
Validation loss: 2.1604842245578766

Epoch: 5| Step: 1
Training loss: 1.779017686843872
Validation loss: 2.1675453086694083

Epoch: 5| Step: 2
Training loss: 2.296185255050659
Validation loss: 2.1752372682094574

Epoch: 5| Step: 3
Training loss: 1.652213454246521
Validation loss: 2.1848394721746445

Epoch: 5| Step: 4
Training loss: 1.9950675964355469
Validation loss: 2.1943831543127694

Epoch: 5| Step: 5
Training loss: 2.0731966495513916
Validation loss: 2.180929328004519

Epoch: 5| Step: 6
Training loss: 2.503774642944336
Validation loss: 2.1864493936300278

Epoch: 5| Step: 7
Training loss: 1.5254778861999512
Validation loss: 2.168233633041382

Epoch: 5| Step: 8
Training loss: 1.8082090616226196
Validation loss: 2.1728412210941315

Epoch: 5| Step: 9
Training loss: 1.8493883609771729
Validation loss: 2.159001961350441

Epoch: 5| Step: 10
Training loss: 1.3289449214935303
Validation loss: 2.16374009847641

Epoch: 5| Step: 11
Training loss: 1.0868268013000488
Validation loss: 2.165824815630913

Epoch: 272| Step: 0
Training loss: 1.779848337173462
Validation loss: 2.1737372080485025

Epoch: 5| Step: 1
Training loss: 1.9435027837753296
Validation loss: 2.1559249063332877

Epoch: 5| Step: 2
Training loss: 2.079354763031006
Validation loss: 2.1616161266962686

Epoch: 5| Step: 3
Training loss: 1.3893461227416992
Validation loss: 2.170109142859777

Epoch: 5| Step: 4
Training loss: 2.5392849445343018
Validation loss: 2.1635804772377014

Epoch: 5| Step: 5
Training loss: 2.346457004547119
Validation loss: 2.1579975535472236

Epoch: 5| Step: 6
Training loss: 1.6630172729492188
Validation loss: 2.1604263484477997

Epoch: 5| Step: 7
Training loss: 1.570375919342041
Validation loss: 2.1651518046855927

Epoch: 5| Step: 8
Training loss: 1.3363544940948486
Validation loss: 2.167790194352468

Epoch: 5| Step: 9
Training loss: 1.665203332901001
Validation loss: 2.156103561321894

Epoch: 5| Step: 10
Training loss: 1.8863223791122437
Validation loss: 2.1716284354527793

Epoch: 5| Step: 11
Training loss: 0.9185646772384644
Validation loss: 2.183142840862274

Epoch: 273| Step: 0
Training loss: 2.029611825942993
Validation loss: 2.186611076196035

Epoch: 5| Step: 1
Training loss: 1.6309436559677124
Validation loss: 2.172288532058398

Epoch: 5| Step: 2
Training loss: 1.5977776050567627
Validation loss: 2.181397020816803

Epoch: 5| Step: 3
Training loss: 2.185291051864624
Validation loss: 2.176208352049192

Epoch: 5| Step: 4
Training loss: 1.7589107751846313
Validation loss: 2.1715973714987435

Epoch: 5| Step: 5
Training loss: 1.3653078079223633
Validation loss: 2.1617561876773834

Epoch: 5| Step: 6
Training loss: 1.862908959388733
Validation loss: 2.1658442368110022

Epoch: 5| Step: 7
Training loss: 2.3827528953552246
Validation loss: 2.145802214741707

Epoch: 5| Step: 8
Training loss: 1.855098009109497
Validation loss: 2.1465081373850503

Epoch: 5| Step: 9
Training loss: 1.6409785747528076
Validation loss: 2.1474665949742

Epoch: 5| Step: 10
Training loss: 1.8990533351898193
Validation loss: 2.139386296272278

Epoch: 5| Step: 11
Training loss: 2.9683828353881836
Validation loss: 2.119393159945806

Epoch: 274| Step: 0
Training loss: 2.1366991996765137
Validation loss: 2.1363343944152198

Epoch: 5| Step: 1
Training loss: 1.972898244857788
Validation loss: 2.143986980120341

Epoch: 5| Step: 2
Training loss: 2.243703603744507
Validation loss: 2.143597975373268

Epoch: 5| Step: 3
Training loss: 1.8061726093292236
Validation loss: 2.146701996525129

Epoch: 5| Step: 4
Training loss: 1.6526000499725342
Validation loss: 2.1672464112440744

Epoch: 5| Step: 5
Training loss: 2.0610945224761963
Validation loss: 2.1645161509513855

Epoch: 5| Step: 6
Training loss: 2.0058600902557373
Validation loss: 2.1456837505102158

Epoch: 5| Step: 7
Training loss: 1.3742824792861938
Validation loss: 2.179943025112152

Epoch: 5| Step: 8
Training loss: 1.712505578994751
Validation loss: 2.1551085710525513

Epoch: 5| Step: 9
Training loss: 1.6096264123916626
Validation loss: 2.1547669172286987

Epoch: 5| Step: 10
Training loss: 1.55591881275177
Validation loss: 2.1454955538113913

Epoch: 5| Step: 11
Training loss: 1.7509331703186035
Validation loss: 2.1520822793245316

Epoch: 275| Step: 0
Training loss: 1.9112002849578857
Validation loss: 2.1466884116331735

Epoch: 5| Step: 1
Training loss: 2.2685647010803223
Validation loss: 2.161477893590927

Epoch: 5| Step: 2
Training loss: 1.6697725057601929
Validation loss: 2.1659829914569855

Epoch: 5| Step: 3
Training loss: 1.0678600072860718
Validation loss: 2.1578605473041534

Epoch: 5| Step: 4
Training loss: 2.0163967609405518
Validation loss: 2.155508284767469

Epoch: 5| Step: 5
Training loss: 1.879730224609375
Validation loss: 2.172981947660446

Epoch: 5| Step: 6
Training loss: 1.8298122882843018
Validation loss: 2.1444526612758636

Epoch: 5| Step: 7
Training loss: 1.3737894296646118
Validation loss: 2.177626003821691

Epoch: 5| Step: 8
Training loss: 2.0921661853790283
Validation loss: 2.168499449888865

Epoch: 5| Step: 9
Training loss: 1.7286651134490967
Validation loss: 2.1593702137470245

Epoch: 5| Step: 10
Training loss: 2.161378860473633
Validation loss: 2.158579478661219

Epoch: 5| Step: 11
Training loss: 1.989773154258728
Validation loss: 2.1624097575743995

Epoch: 276| Step: 0
Training loss: 1.8668317794799805
Validation loss: 2.1790039589007697

Epoch: 5| Step: 1
Training loss: 1.8709843158721924
Validation loss: 2.160561372836431

Epoch: 5| Step: 2
Training loss: 1.549591064453125
Validation loss: 2.1602984915177026

Epoch: 5| Step: 3
Training loss: 1.959265947341919
Validation loss: 2.161032721400261

Epoch: 5| Step: 4
Training loss: 1.5919246673583984
Validation loss: 2.167529741923014

Epoch: 5| Step: 5
Training loss: 1.5938235521316528
Validation loss: 2.152649680773417

Epoch: 5| Step: 6
Training loss: 1.322501540184021
Validation loss: 2.1685740053653717

Epoch: 5| Step: 7
Training loss: 1.95536208152771
Validation loss: 2.166350449124972

Epoch: 5| Step: 8
Training loss: 1.8985207080841064
Validation loss: 2.163659910360972

Epoch: 5| Step: 9
Training loss: 2.1715078353881836
Validation loss: 2.174385959903399

Epoch: 5| Step: 10
Training loss: 1.9397881031036377
Validation loss: 2.1741106510162354

Epoch: 5| Step: 11
Training loss: 2.0873613357543945
Validation loss: 2.167121668656667

Epoch: 277| Step: 0
Training loss: 2.3477561473846436
Validation loss: 2.1618604511022568

Epoch: 5| Step: 1
Training loss: 2.1762614250183105
Validation loss: 2.1866736660401025

Epoch: 5| Step: 2
Training loss: 1.7951641082763672
Validation loss: 2.180060237646103

Epoch: 5| Step: 3
Training loss: 1.4577399492263794
Validation loss: 2.171054204305013

Epoch: 5| Step: 4
Training loss: 1.7503840923309326
Validation loss: 2.1695384482542672

Epoch: 5| Step: 5
Training loss: 1.5963023900985718
Validation loss: 2.180938964088758

Epoch: 5| Step: 6
Training loss: 1.0995935201644897
Validation loss: 2.185215582450231

Epoch: 5| Step: 7
Training loss: 2.2109525203704834
Validation loss: 2.177158455053965

Epoch: 5| Step: 8
Training loss: 2.4270365238189697
Validation loss: 2.1617741684118905

Epoch: 5| Step: 9
Training loss: 1.4883549213409424
Validation loss: 2.1645425210396447

Epoch: 5| Step: 10
Training loss: 1.5245487689971924
Validation loss: 2.1636971533298492

Epoch: 5| Step: 11
Training loss: 2.473888397216797
Validation loss: 2.1825030595064163

Epoch: 278| Step: 0
Training loss: 1.6782413721084595
Validation loss: 2.1829389880100885

Epoch: 5| Step: 1
Training loss: 1.8845802545547485
Validation loss: 2.1877860526243844

Epoch: 5| Step: 2
Training loss: 2.0810203552246094
Validation loss: 2.1824032167593637

Epoch: 5| Step: 3
Training loss: 2.1172561645507812
Validation loss: 2.1732769161462784

Epoch: 5| Step: 4
Training loss: 2.379671335220337
Validation loss: 2.1605244477589927

Epoch: 5| Step: 5
Training loss: 1.6526803970336914
Validation loss: 2.1519738137722015

Epoch: 5| Step: 6
Training loss: 1.6566874980926514
Validation loss: 2.1671485155820847

Epoch: 5| Step: 7
Training loss: 1.7557361125946045
Validation loss: 2.1433062106370926

Epoch: 5| Step: 8
Training loss: 2.0263803005218506
Validation loss: 2.144748106598854

Epoch: 5| Step: 9
Training loss: 2.001366376876831
Validation loss: 2.1618512322505317

Epoch: 5| Step: 10
Training loss: 1.406611680984497
Validation loss: 2.159704089164734

Epoch: 5| Step: 11
Training loss: 1.8891719579696655
Validation loss: 2.1602740635474524

Epoch: 279| Step: 0
Training loss: 1.8440717458724976
Validation loss: 2.158139685789744

Epoch: 5| Step: 1
Training loss: 1.8790245056152344
Validation loss: 2.166272600491842

Epoch: 5| Step: 2
Training loss: 1.4036668539047241
Validation loss: 2.1671666900316873

Epoch: 5| Step: 3
Training loss: 1.9767372608184814
Validation loss: 2.1729421516259513

Epoch: 5| Step: 4
Training loss: 1.9391698837280273
Validation loss: 2.1642341961463294

Epoch: 5| Step: 5
Training loss: 1.8863147497177124
Validation loss: 2.1563995430866876

Epoch: 5| Step: 6
Training loss: 1.8439161777496338
Validation loss: 2.1665153900782266

Epoch: 5| Step: 7
Training loss: 2.095240831375122
Validation loss: 2.171408404906591

Epoch: 5| Step: 8
Training loss: 1.5139234066009521
Validation loss: 2.176423559586207

Epoch: 5| Step: 9
Training loss: 1.9510806798934937
Validation loss: 2.1552654008070626

Epoch: 5| Step: 10
Training loss: 2.0535430908203125
Validation loss: 2.1610166132450104

Epoch: 5| Step: 11
Training loss: 1.0878186225891113
Validation loss: 2.1618506610393524

Epoch: 280| Step: 0
Training loss: 1.7968566417694092
Validation loss: 2.1481033066908517

Epoch: 5| Step: 1
Training loss: 1.6886005401611328
Validation loss: 2.151544456680616

Epoch: 5| Step: 2
Training loss: 1.6473567485809326
Validation loss: 2.1460704306761422

Epoch: 5| Step: 3
Training loss: 1.9319038391113281
Validation loss: 2.1573005467653275

Epoch: 5| Step: 4
Training loss: 2.321112632751465
Validation loss: 2.161623681584994

Epoch: 5| Step: 5
Training loss: 1.4656684398651123
Validation loss: 2.171101987361908

Epoch: 5| Step: 6
Training loss: 1.4771409034729004
Validation loss: 2.185289884606997

Epoch: 5| Step: 7
Training loss: 1.6789058446884155
Validation loss: 2.1652716199556985

Epoch: 5| Step: 8
Training loss: 1.9626041650772095
Validation loss: 2.172212799390157

Epoch: 5| Step: 9
Training loss: 1.8476299047470093
Validation loss: 2.1835827032725015

Epoch: 5| Step: 10
Training loss: 2.077378749847412
Validation loss: 2.1753474374612174

Epoch: 5| Step: 11
Training loss: 2.0758438110351562
Validation loss: 2.1680133044719696

Epoch: 281| Step: 0
Training loss: 1.8634122610092163
Validation loss: 2.1713008979956308

Epoch: 5| Step: 1
Training loss: 1.770250678062439
Validation loss: 2.173481355110804

Epoch: 5| Step: 2
Training loss: 1.4291667938232422
Validation loss: 2.1704384287198386

Epoch: 5| Step: 3
Training loss: 1.4740581512451172
Validation loss: 2.1787860691547394

Epoch: 5| Step: 4
Training loss: 1.4292688369750977
Validation loss: 2.188799967368444

Epoch: 5| Step: 5
Training loss: 1.730242133140564
Validation loss: 2.193106303612391

Epoch: 5| Step: 6
Training loss: 1.957227349281311
Validation loss: 2.1728334575891495

Epoch: 5| Step: 7
Training loss: 2.1395657062530518
Validation loss: 2.1688096026579538

Epoch: 5| Step: 8
Training loss: 1.4318745136260986
Validation loss: 2.172156890233358

Epoch: 5| Step: 9
Training loss: 2.357219696044922
Validation loss: 2.168953721721967

Epoch: 5| Step: 10
Training loss: 2.38401198387146
Validation loss: 2.1635919560988746

Epoch: 5| Step: 11
Training loss: 2.5398335456848145
Validation loss: 2.170951967438062

Epoch: 282| Step: 0
Training loss: 1.3850696086883545
Validation loss: 2.163723975419998

Epoch: 5| Step: 1
Training loss: 1.7517518997192383
Validation loss: 2.152752528587977

Epoch: 5| Step: 2
Training loss: 2.0274548530578613
Validation loss: 2.1443678438663483

Epoch: 5| Step: 3
Training loss: 2.092433214187622
Validation loss: 2.1394886573155723

Epoch: 5| Step: 4
Training loss: 1.9897429943084717
Validation loss: 2.157924393812815

Epoch: 5| Step: 5
Training loss: 2.02601957321167
Validation loss: 2.154104063908259

Epoch: 5| Step: 6
Training loss: 1.5988991260528564
Validation loss: 2.153661216298739

Epoch: 5| Step: 7
Training loss: 1.6963249444961548
Validation loss: 2.1627462009588876

Epoch: 5| Step: 8
Training loss: 1.5882456302642822
Validation loss: 2.1611769000689187

Epoch: 5| Step: 9
Training loss: 1.5634119510650635
Validation loss: 2.1415554881095886

Epoch: 5| Step: 10
Training loss: 2.468623638153076
Validation loss: 2.1450563867886863

Epoch: 5| Step: 11
Training loss: 2.980064868927002
Validation loss: 2.1562717258930206

Epoch: 283| Step: 0
Training loss: 1.8976694345474243
Validation loss: 2.1832484304904938

Epoch: 5| Step: 1
Training loss: 1.7232780456542969
Validation loss: 2.1707306603590646

Epoch: 5| Step: 2
Training loss: 1.727338194847107
Validation loss: 2.191701889038086

Epoch: 5| Step: 3
Training loss: 2.0771727561950684
Validation loss: 2.1670390466849008

Epoch: 5| Step: 4
Training loss: 1.4029967784881592
Validation loss: 2.161470949649811

Epoch: 5| Step: 5
Training loss: 2.0253798961639404
Validation loss: 2.167760799328486

Epoch: 5| Step: 6
Training loss: 1.707418441772461
Validation loss: 2.1519666016101837

Epoch: 5| Step: 7
Training loss: 2.076995372772217
Validation loss: 2.164755036433538

Epoch: 5| Step: 8
Training loss: 2.2958693504333496
Validation loss: 2.156990905602773

Epoch: 5| Step: 9
Training loss: 1.6349914073944092
Validation loss: 2.177438070376714

Epoch: 5| Step: 10
Training loss: 1.7965608835220337
Validation loss: 2.1761532028516135

Epoch: 5| Step: 11
Training loss: 0.8389735221862793
Validation loss: 2.168875907858213

Epoch: 284| Step: 0
Training loss: 1.7657325267791748
Validation loss: 2.183231676618258

Epoch: 5| Step: 1
Training loss: 2.0340921878814697
Validation loss: 2.1964739859104156

Epoch: 5| Step: 2
Training loss: 2.012070655822754
Validation loss: 2.198320060968399

Epoch: 5| Step: 3
Training loss: 1.5150655508041382
Validation loss: 2.1972052653630576

Epoch: 5| Step: 4
Training loss: 2.0842082500457764
Validation loss: 2.199771523475647

Epoch: 5| Step: 5
Training loss: 1.6685054302215576
Validation loss: 2.193339472015699

Epoch: 5| Step: 6
Training loss: 1.7354786396026611
Validation loss: 2.1773305535316467

Epoch: 5| Step: 7
Training loss: 1.3584346771240234
Validation loss: 2.162491112947464

Epoch: 5| Step: 8
Training loss: 1.8907124996185303
Validation loss: 2.1703105916579566

Epoch: 5| Step: 9
Training loss: 1.7747678756713867
Validation loss: 2.151721258958181

Epoch: 5| Step: 10
Training loss: 2.597048044204712
Validation loss: 2.158231114347776

Epoch: 5| Step: 11
Training loss: 1.178108811378479
Validation loss: 2.1378733615080514

Epoch: 285| Step: 0
Training loss: 1.8808238506317139
Validation loss: 2.1466160118579865

Epoch: 5| Step: 1
Training loss: 1.8939743041992188
Validation loss: 2.1487686187028885

Epoch: 5| Step: 2
Training loss: 2.4291470050811768
Validation loss: 2.138328492641449

Epoch: 5| Step: 3
Training loss: 1.9833253622055054
Validation loss: 2.1375173379977546

Epoch: 5| Step: 4
Training loss: 1.0845978260040283
Validation loss: 2.167811875542005

Epoch: 5| Step: 5
Training loss: 1.8524181842803955
Validation loss: 2.149104207754135

Epoch: 5| Step: 6
Training loss: 2.3222484588623047
Validation loss: 2.165140767892202

Epoch: 5| Step: 7
Training loss: 1.718237280845642
Validation loss: 2.155172129472097

Epoch: 5| Step: 8
Training loss: 1.6333898305892944
Validation loss: 2.1689715683460236

Epoch: 5| Step: 9
Training loss: 1.5449495315551758
Validation loss: 2.1676696042219796

Epoch: 5| Step: 10
Training loss: 1.7574775218963623
Validation loss: 2.183288569251696

Epoch: 5| Step: 11
Training loss: 2.1332340240478516
Validation loss: 2.1621546894311905

Epoch: 286| Step: 0
Training loss: 1.6167875528335571
Validation loss: 2.1780521472295127

Epoch: 5| Step: 1
Training loss: 1.2530893087387085
Validation loss: 2.1723350087801614

Epoch: 5| Step: 2
Training loss: 2.405036449432373
Validation loss: 2.1638831247886023

Epoch: 5| Step: 3
Training loss: 1.4430768489837646
Validation loss: 2.1831454584995904

Epoch: 5| Step: 4
Training loss: 2.0627048015594482
Validation loss: 2.1763742864131927

Epoch: 5| Step: 5
Training loss: 1.5660923719406128
Validation loss: 2.167495613296827

Epoch: 5| Step: 6
Training loss: 2.62471342086792
Validation loss: 2.1776398171981177

Epoch: 5| Step: 7
Training loss: 1.5626225471496582
Validation loss: 2.1932517240444818

Epoch: 5| Step: 8
Training loss: 1.751675009727478
Validation loss: 2.1903165380160012

Epoch: 5| Step: 9
Training loss: 1.9798307418823242
Validation loss: 2.1827423373858132

Epoch: 5| Step: 10
Training loss: 1.638155221939087
Validation loss: 2.172857994834582

Epoch: 5| Step: 11
Training loss: 1.3148581981658936
Validation loss: 2.185088872909546

Epoch: 287| Step: 0
Training loss: 1.423067331314087
Validation loss: 2.185852368672689

Epoch: 5| Step: 1
Training loss: 2.063227653503418
Validation loss: 2.191819687684377

Epoch: 5| Step: 2
Training loss: 1.6894500255584717
Validation loss: 2.1872848769028983

Epoch: 5| Step: 3
Training loss: 2.0903546810150146
Validation loss: 2.185027281443278

Epoch: 5| Step: 4
Training loss: 1.3764879703521729
Validation loss: 2.1709786653518677

Epoch: 5| Step: 5
Training loss: 1.6972545385360718
Validation loss: 2.177875111500422

Epoch: 5| Step: 6
Training loss: 1.247244119644165
Validation loss: 2.17410084605217

Epoch: 5| Step: 7
Training loss: 2.16521954536438
Validation loss: 2.16897581020991

Epoch: 5| Step: 8
Training loss: 2.398411273956299
Validation loss: 2.1811484495798745

Epoch: 5| Step: 9
Training loss: 1.7112029790878296
Validation loss: 2.1464282423257828

Epoch: 5| Step: 10
Training loss: 1.8748886585235596
Validation loss: 2.1725916067759194

Epoch: 5| Step: 11
Training loss: 3.662067413330078
Validation loss: 2.1649023294448853

Epoch: 288| Step: 0
Training loss: 2.224095106124878
Validation loss: 2.16651850938797

Epoch: 5| Step: 1
Training loss: 2.2116684913635254
Validation loss: 2.161170408129692

Epoch: 5| Step: 2
Training loss: 1.8411986827850342
Validation loss: 2.157389556368192

Epoch: 5| Step: 3
Training loss: 1.973966360092163
Validation loss: 2.172611579298973

Epoch: 5| Step: 4
Training loss: 2.094452381134033
Validation loss: 2.164264569679896

Epoch: 5| Step: 5
Training loss: 1.8606704473495483
Validation loss: 2.1591412127017975

Epoch: 5| Step: 6
Training loss: 1.7319759130477905
Validation loss: 2.189473956823349

Epoch: 5| Step: 7
Training loss: 1.2864106893539429
Validation loss: 2.1935507357120514

Epoch: 5| Step: 8
Training loss: 2.259392499923706
Validation loss: 2.1881028513113656

Epoch: 5| Step: 9
Training loss: 1.7154004573822021
Validation loss: 2.2160256107648215

Epoch: 5| Step: 10
Training loss: 1.3235543966293335
Validation loss: 2.206959381699562

Epoch: 5| Step: 11
Training loss: 1.607642412185669
Validation loss: 2.2081639418999353

Epoch: 289| Step: 0
Training loss: 1.8806604146957397
Validation loss: 2.195027321577072

Epoch: 5| Step: 1
Training loss: 1.5380733013153076
Validation loss: 2.20429265499115

Epoch: 5| Step: 2
Training loss: 1.6010370254516602
Validation loss: 2.1825538029273353

Epoch: 5| Step: 3
Training loss: 2.2739713191986084
Validation loss: 2.1542476266622543

Epoch: 5| Step: 4
Training loss: 1.913100004196167
Validation loss: 2.1698415726423264

Epoch: 5| Step: 5
Training loss: 1.8607399463653564
Validation loss: 2.1806278924147287

Epoch: 5| Step: 6
Training loss: 1.7583248615264893
Validation loss: 2.1655974984169006

Epoch: 5| Step: 7
Training loss: 1.1791751384735107
Validation loss: 2.1703783869743347

Epoch: 5| Step: 8
Training loss: 1.7204015254974365
Validation loss: 2.177866150935491

Epoch: 5| Step: 9
Training loss: 2.1811118125915527
Validation loss: 2.1832374582688012

Epoch: 5| Step: 10
Training loss: 1.8613452911376953
Validation loss: 2.173744743069013

Epoch: 5| Step: 11
Training loss: 2.2204432487487793
Validation loss: 2.1608061343431473

Epoch: 290| Step: 0
Training loss: 1.60097336769104
Validation loss: 2.1760545720656714

Epoch: 5| Step: 1
Training loss: 2.0146470069885254
Validation loss: 2.1563502053419747

Epoch: 5| Step: 2
Training loss: 2.013213634490967
Validation loss: 2.1878797809282937

Epoch: 5| Step: 3
Training loss: 1.524373173713684
Validation loss: 2.187738130489985

Epoch: 5| Step: 4
Training loss: 1.8889834880828857
Validation loss: 2.180085072914759

Epoch: 5| Step: 5
Training loss: 1.4552967548370361
Validation loss: 2.1958350837230682

Epoch: 5| Step: 6
Training loss: 1.9577157497406006
Validation loss: 2.2142018576463065

Epoch: 5| Step: 7
Training loss: 1.4049665927886963
Validation loss: 2.1948727866013846

Epoch: 5| Step: 8
Training loss: 1.6284278631210327
Validation loss: 2.2007308304309845

Epoch: 5| Step: 9
Training loss: 2.145394802093506
Validation loss: 2.185967485109965

Epoch: 5| Step: 10
Training loss: 1.6996921300888062
Validation loss: 2.200746218363444

Epoch: 5| Step: 11
Training loss: 3.0491621494293213
Validation loss: 2.1887912650903067

Epoch: 291| Step: 0
Training loss: 1.9116935729980469
Validation loss: 2.206426282723745

Epoch: 5| Step: 1
Training loss: 1.916553258895874
Validation loss: 2.1899536152680716

Epoch: 5| Step: 2
Training loss: 2.5298123359680176
Validation loss: 2.1996899843215942

Epoch: 5| Step: 3
Training loss: 1.0823091268539429
Validation loss: 2.2089218497276306

Epoch: 5| Step: 4
Training loss: 1.9512704610824585
Validation loss: 2.193115303913752

Epoch: 5| Step: 5
Training loss: 1.8075368404388428
Validation loss: 2.1894012292226157

Epoch: 5| Step: 6
Training loss: 1.780050277709961
Validation loss: 2.1949239919583

Epoch: 5| Step: 7
Training loss: 2.070622444152832
Validation loss: 2.20289354523023

Epoch: 5| Step: 8
Training loss: 1.2551789283752441
Validation loss: 2.2111283938090005

Epoch: 5| Step: 9
Training loss: 1.4986193180084229
Validation loss: 2.2097692688306174

Epoch: 5| Step: 10
Training loss: 1.9704625606536865
Validation loss: 2.1993161042531333

Epoch: 5| Step: 11
Training loss: 0.9738881587982178
Validation loss: 2.1869097352027893

Epoch: 292| Step: 0
Training loss: 1.7350937128067017
Validation loss: 2.1872091591358185

Epoch: 5| Step: 1
Training loss: 1.2505226135253906
Validation loss: 2.161207770307859

Epoch: 5| Step: 2
Training loss: 1.6015350818634033
Validation loss: 2.1592306246360145

Epoch: 5| Step: 3
Training loss: 2.533905506134033
Validation loss: 2.144843578338623

Epoch: 5| Step: 4
Training loss: 1.7740741968154907
Validation loss: 2.162107268969218

Epoch: 5| Step: 5
Training loss: 2.5527737140655518
Validation loss: 2.1498336543639502

Epoch: 5| Step: 6
Training loss: 1.3784281015396118
Validation loss: 2.160200357437134

Epoch: 5| Step: 7
Training loss: 1.5323482751846313
Validation loss: 2.1619377036889396

Epoch: 5| Step: 8
Training loss: 2.167598009109497
Validation loss: 2.1592042644818625

Epoch: 5| Step: 9
Training loss: 1.707463026046753
Validation loss: 2.173062632481257

Epoch: 5| Step: 10
Training loss: 1.873490571975708
Validation loss: 2.178014794985453

Epoch: 5| Step: 11
Training loss: 1.125163197517395
Validation loss: 2.175864120324453

Epoch: 293| Step: 0
Training loss: 2.3582801818847656
Validation loss: 2.1701086908578873

Epoch: 5| Step: 1
Training loss: 1.6930453777313232
Validation loss: 2.1945200314124427

Epoch: 5| Step: 2
Training loss: 1.3892542123794556
Validation loss: 2.1822256793578467

Epoch: 5| Step: 3
Training loss: 1.8543994426727295
Validation loss: 2.1881704131762185

Epoch: 5| Step: 4
Training loss: 1.814170479774475
Validation loss: 2.2036385337511697

Epoch: 5| Step: 5
Training loss: 1.9039875268936157
Validation loss: 2.2005207240581512

Epoch: 5| Step: 6
Training loss: 1.907552719116211
Validation loss: 2.203317662080129

Epoch: 5| Step: 7
Training loss: 1.5640604496002197
Validation loss: 2.1877356270949044

Epoch: 5| Step: 8
Training loss: 1.5464897155761719
Validation loss: 2.1942932258049646

Epoch: 5| Step: 9
Training loss: 1.7012230157852173
Validation loss: 2.1964052269856134

Epoch: 5| Step: 10
Training loss: 2.212897777557373
Validation loss: 2.1891260097424188

Epoch: 5| Step: 11
Training loss: 1.3593506813049316
Validation loss: 2.19311914841334

Epoch: 294| Step: 0
Training loss: 1.842789888381958
Validation loss: 2.183668375015259

Epoch: 5| Step: 1
Training loss: 1.9482505321502686
Validation loss: 2.1699045499165854

Epoch: 5| Step: 2
Training loss: 2.035964250564575
Validation loss: 2.177053208152453

Epoch: 5| Step: 3
Training loss: 2.1878628730773926
Validation loss: 2.1930924902359643

Epoch: 5| Step: 4
Training loss: 1.4948375225067139
Validation loss: 2.1815994729598365

Epoch: 5| Step: 5
Training loss: 1.9158029556274414
Validation loss: 2.176883061726888

Epoch: 5| Step: 6
Training loss: 1.3692312240600586
Validation loss: 2.191958616177241

Epoch: 5| Step: 7
Training loss: 2.12966251373291
Validation loss: 2.1830410112937293

Epoch: 5| Step: 8
Training loss: 1.5838987827301025
Validation loss: 2.1970215340455375

Epoch: 5| Step: 9
Training loss: 1.7176634073257446
Validation loss: 2.213193396727244

Epoch: 5| Step: 10
Training loss: 1.3664629459381104
Validation loss: 2.206782504916191

Epoch: 5| Step: 11
Training loss: 1.6878726482391357
Validation loss: 2.1791843275229135

Epoch: 295| Step: 0
Training loss: 1.894688606262207
Validation loss: 2.190483142932256

Epoch: 5| Step: 1
Training loss: 1.546381950378418
Validation loss: 2.182838370402654

Epoch: 5| Step: 2
Training loss: 1.8193979263305664
Validation loss: 2.168231944243113

Epoch: 5| Step: 3
Training loss: 1.792645812034607
Validation loss: 2.1671610524257026

Epoch: 5| Step: 4
Training loss: 1.4480364322662354
Validation loss: 2.177790328860283

Epoch: 5| Step: 5
Training loss: 1.2072842121124268
Validation loss: 2.177529220779737

Epoch: 5| Step: 6
Training loss: 1.1723629236221313
Validation loss: 2.187226394812266

Epoch: 5| Step: 7
Training loss: 1.6738741397857666
Validation loss: 2.199296534061432

Epoch: 5| Step: 8
Training loss: 2.1849913597106934
Validation loss: 2.1882479588190713

Epoch: 5| Step: 9
Training loss: 1.9794238805770874
Validation loss: 2.190010964870453

Epoch: 5| Step: 10
Training loss: 2.6430504322052
Validation loss: 2.1789874831835427

Epoch: 5| Step: 11
Training loss: 2.154216766357422
Validation loss: 2.199460670351982

Epoch: 296| Step: 0
Training loss: 1.4888790845870972
Validation loss: 2.2165755927562714

Epoch: 5| Step: 1
Training loss: 1.4709157943725586
Validation loss: 2.1985707680384317

Epoch: 5| Step: 2
Training loss: 1.2596549987792969
Validation loss: 2.2089473058780036

Epoch: 5| Step: 3
Training loss: 2.1231796741485596
Validation loss: 2.219482511281967

Epoch: 5| Step: 4
Training loss: 1.9435714483261108
Validation loss: 2.214670737584432

Epoch: 5| Step: 5
Training loss: 1.6087589263916016
Validation loss: 2.1992963751157126

Epoch: 5| Step: 6
Training loss: 2.151348114013672
Validation loss: 2.184752603371938

Epoch: 5| Step: 7
Training loss: 2.0009074211120605
Validation loss: 2.1767323364814124

Epoch: 5| Step: 8
Training loss: 2.155362367630005
Validation loss: 2.1773355901241302

Epoch: 5| Step: 9
Training loss: 1.4647753238677979
Validation loss: 2.174597923954328

Epoch: 5| Step: 10
Training loss: 1.9329302310943604
Validation loss: 2.176728760202726

Epoch: 5| Step: 11
Training loss: 0.8624541759490967
Validation loss: 2.1757705261309943

Epoch: 297| Step: 0
Training loss: 2.025574207305908
Validation loss: 2.1608341336250305

Epoch: 5| Step: 1
Training loss: 1.4863088130950928
Validation loss: 2.18233522772789

Epoch: 5| Step: 2
Training loss: 1.9958480596542358
Validation loss: 2.1929709017276764

Epoch: 5| Step: 3
Training loss: 1.5547599792480469
Validation loss: 2.184632624189059

Epoch: 5| Step: 4
Training loss: 1.7506173849105835
Validation loss: 2.199984848499298

Epoch: 5| Step: 5
Training loss: 2.1953377723693848
Validation loss: 2.1771691143512726

Epoch: 5| Step: 6
Training loss: 1.698984146118164
Validation loss: 2.1881814201672873

Epoch: 5| Step: 7
Training loss: 1.764094591140747
Validation loss: 2.1825440724690757

Epoch: 5| Step: 8
Training loss: 1.4896780252456665
Validation loss: 2.185709292689959

Epoch: 5| Step: 9
Training loss: 2.0613975524902344
Validation loss: 2.175644983847936

Epoch: 5| Step: 10
Training loss: 1.471925973892212
Validation loss: 2.178813914457957

Epoch: 5| Step: 11
Training loss: 1.1567362546920776
Validation loss: 2.1856713046630225

Epoch: 298| Step: 0
Training loss: 1.4776891469955444
Validation loss: 2.179314191142718

Epoch: 5| Step: 1
Training loss: 2.102625608444214
Validation loss: 2.183203101158142

Epoch: 5| Step: 2
Training loss: 2.0122528076171875
Validation loss: 2.166129390398661

Epoch: 5| Step: 3
Training loss: 1.6231441497802734
Validation loss: 2.1968200703461966

Epoch: 5| Step: 4
Training loss: 1.8634936809539795
Validation loss: 2.1809186190366745

Epoch: 5| Step: 5
Training loss: 1.7929515838623047
Validation loss: 2.1882706930239997

Epoch: 5| Step: 6
Training loss: 1.6076583862304688
Validation loss: 2.1747561246156693

Epoch: 5| Step: 7
Training loss: 1.3912450075149536
Validation loss: 2.1822106341520944

Epoch: 5| Step: 8
Training loss: 2.453974723815918
Validation loss: 2.165697991847992

Epoch: 5| Step: 9
Training loss: 1.7906417846679688
Validation loss: 2.1689172784487405

Epoch: 5| Step: 10
Training loss: 1.4345331192016602
Validation loss: 2.171237424015999

Epoch: 5| Step: 11
Training loss: 2.2057180404663086
Validation loss: 2.1941606402397156

Epoch: 299| Step: 0
Training loss: 1.7311303615570068
Validation loss: 2.178570802013079

Epoch: 5| Step: 1
Training loss: 1.675278902053833
Validation loss: 2.177811731894811

Epoch: 5| Step: 2
Training loss: 1.7586252689361572
Validation loss: 2.166439155737559

Epoch: 5| Step: 3
Training loss: 1.0865882635116577
Validation loss: 2.1745957136154175

Epoch: 5| Step: 4
Training loss: 1.7437845468521118
Validation loss: 2.192112763722738

Epoch: 5| Step: 5
Training loss: 1.7972290515899658
Validation loss: 2.188203811645508

Epoch: 5| Step: 6
Training loss: 1.5436254739761353
Validation loss: 2.1632310301065445

Epoch: 5| Step: 7
Training loss: 2.4015839099884033
Validation loss: 2.1869032829999924

Epoch: 5| Step: 8
Training loss: 1.1714799404144287
Validation loss: 2.1981127808491387

Epoch: 5| Step: 9
Training loss: 2.0657012462615967
Validation loss: 2.1921631395816803

Epoch: 5| Step: 10
Training loss: 2.0919976234436035
Validation loss: 2.188888669013977

Epoch: 5| Step: 11
Training loss: 2.0204246044158936
Validation loss: 2.1757015784581504

Epoch: 300| Step: 0
Training loss: 1.926978349685669
Validation loss: 2.1997373153765998

Epoch: 5| Step: 1
Training loss: 1.2170145511627197
Validation loss: 2.183949460585912

Epoch: 5| Step: 2
Training loss: 1.7288986444473267
Validation loss: 2.1867259542147317

Epoch: 5| Step: 3
Training loss: 1.8212058544158936
Validation loss: 2.160584713021914

Epoch: 5| Step: 4
Training loss: 2.8706812858581543
Validation loss: 2.1866573095321655

Epoch: 5| Step: 5
Training loss: 1.5037474632263184
Validation loss: 2.182009985049566

Epoch: 5| Step: 6
Training loss: 1.7042347192764282
Validation loss: 2.1725789656241736

Epoch: 5| Step: 7
Training loss: 1.2837425470352173
Validation loss: 2.1918896486361823

Epoch: 5| Step: 8
Training loss: 2.2208991050720215
Validation loss: 2.167892267306646

Epoch: 5| Step: 9
Training loss: 1.176560401916504
Validation loss: 2.1699217160542807

Epoch: 5| Step: 10
Training loss: 2.1417500972747803
Validation loss: 2.170194794734319

Epoch: 5| Step: 11
Training loss: 1.8585354089736938
Validation loss: 2.168760230143865

Epoch: 301| Step: 0
Training loss: 1.6423523426055908
Validation loss: 2.167304957906405

Epoch: 5| Step: 1
Training loss: 2.1486384868621826
Validation loss: 2.1892907420794168

Epoch: 5| Step: 2
Training loss: 1.6921453475952148
Validation loss: 2.168707256515821

Epoch: 5| Step: 3
Training loss: 1.7556962966918945
Validation loss: 2.17116641998291

Epoch: 5| Step: 4
Training loss: 1.8519617319107056
Validation loss: 2.1837005416552224

Epoch: 5| Step: 5
Training loss: 1.8044211864471436
Validation loss: 2.180151656270027

Epoch: 5| Step: 6
Training loss: 1.6817524433135986
Validation loss: 2.1873575150966644

Epoch: 5| Step: 7
Training loss: 1.8090012073516846
Validation loss: 2.169917573531469

Epoch: 5| Step: 8
Training loss: 1.87410569190979
Validation loss: 2.1814485589663186

Epoch: 5| Step: 9
Training loss: 1.2231404781341553
Validation loss: 2.1868891517321267

Epoch: 5| Step: 10
Training loss: 1.6457288265228271
Validation loss: 2.193509896596273

Epoch: 5| Step: 11
Training loss: 2.912696361541748
Validation loss: 2.1855778147776923

Epoch: 302| Step: 0
Training loss: 1.4834706783294678
Validation loss: 2.1990835666656494

Epoch: 5| Step: 1
Training loss: 1.9430334568023682
Validation loss: 2.1858857423067093

Epoch: 5| Step: 2
Training loss: 1.770864486694336
Validation loss: 2.1886505782604218

Epoch: 5| Step: 3
Training loss: 1.7686223983764648
Validation loss: 2.1972283770640693

Epoch: 5| Step: 4
Training loss: 1.9817222356796265
Validation loss: 2.1819443305333457

Epoch: 5| Step: 5
Training loss: 1.7051655054092407
Validation loss: 2.18049285809199

Epoch: 5| Step: 6
Training loss: 1.9556783437728882
Validation loss: 2.17397578060627

Epoch: 5| Step: 7
Training loss: 1.7380472421646118
Validation loss: 2.186156248052915

Epoch: 5| Step: 8
Training loss: 1.885353446006775
Validation loss: 2.191755309700966

Epoch: 5| Step: 9
Training loss: 1.3598543405532837
Validation loss: 2.1925886472066245

Epoch: 5| Step: 10
Training loss: 1.3892745971679688
Validation loss: 2.173565069834391

Epoch: 5| Step: 11
Training loss: 2.5935630798339844
Validation loss: 2.190143957734108

Epoch: 303| Step: 0
Training loss: 1.5127973556518555
Validation loss: 2.1960424383481345

Epoch: 5| Step: 1
Training loss: 1.8094898462295532
Validation loss: 2.213836361964544

Epoch: 5| Step: 2
Training loss: 2.195852041244507
Validation loss: 2.197513331969579

Epoch: 5| Step: 3
Training loss: 1.801222801208496
Validation loss: 2.2292430798212686

Epoch: 5| Step: 4
Training loss: 1.9646356105804443
Validation loss: 2.2166595309972763

Epoch: 5| Step: 5
Training loss: 1.5272109508514404
Validation loss: 2.2075458616018295

Epoch: 5| Step: 6
Training loss: 1.7299787998199463
Validation loss: 2.2042585810025535

Epoch: 5| Step: 7
Training loss: 1.1148977279663086
Validation loss: 2.2089553425709405

Epoch: 5| Step: 8
Training loss: 1.8929564952850342
Validation loss: 2.2099429766337075

Epoch: 5| Step: 9
Training loss: 1.7133369445800781
Validation loss: 2.207932874560356

Epoch: 5| Step: 10
Training loss: 2.1312613487243652
Validation loss: 2.1762459675470986

Epoch: 5| Step: 11
Training loss: 2.75661563873291
Validation loss: 2.191642627120018

Epoch: 304| Step: 0
Training loss: 1.8336868286132812
Validation loss: 2.158072034517924

Epoch: 5| Step: 1
Training loss: 2.5635244846343994
Validation loss: 2.1446947753429413

Epoch: 5| Step: 2
Training loss: 1.7936804294586182
Validation loss: 2.1324914395809174

Epoch: 5| Step: 3
Training loss: 1.657941222190857
Validation loss: 2.1349699993928275

Epoch: 5| Step: 4
Training loss: 2.2316973209381104
Validation loss: 2.1246194591124854

Epoch: 5| Step: 5
Training loss: 1.974930763244629
Validation loss: 2.140628144145012

Epoch: 5| Step: 6
Training loss: 1.265885353088379
Validation loss: 2.136543025573095

Epoch: 5| Step: 7
Training loss: 1.6626405715942383
Validation loss: 2.1146681159734726

Epoch: 5| Step: 8
Training loss: 1.5315518379211426
Validation loss: 2.1345190008481345

Epoch: 5| Step: 9
Training loss: 1.8916685581207275
Validation loss: 2.109262486298879

Epoch: 5| Step: 10
Training loss: 1.8856449127197266
Validation loss: 2.124210014939308

Epoch: 5| Step: 11
Training loss: 2.646186351776123
Validation loss: 2.128103663523992

Epoch: 305| Step: 0
Training loss: 2.0835347175598145
Validation loss: 2.1376998126506805

Epoch: 5| Step: 1
Training loss: 1.707553505897522
Validation loss: 2.1475499669710794

Epoch: 5| Step: 2
Training loss: 2.4835634231567383
Validation loss: 2.154176731904348

Epoch: 5| Step: 3
Training loss: 1.6881630420684814
Validation loss: 2.1781583428382874

Epoch: 5| Step: 4
Training loss: 1.6785447597503662
Validation loss: 2.179819996158282

Epoch: 5| Step: 5
Training loss: 1.9121955633163452
Validation loss: 2.2045496304829917

Epoch: 5| Step: 6
Training loss: 1.834973931312561
Validation loss: 2.196122964223226

Epoch: 5| Step: 7
Training loss: 1.7954847812652588
Validation loss: 2.189688593149185

Epoch: 5| Step: 8
Training loss: 1.9544273614883423
Validation loss: 2.2052859167257943

Epoch: 5| Step: 9
Training loss: 1.6031872034072876
Validation loss: 2.218705783287684

Epoch: 5| Step: 10
Training loss: 1.7281605005264282
Validation loss: 2.1920099457105002

Epoch: 5| Step: 11
Training loss: 1.0205450057983398
Validation loss: 2.198839729030927

Epoch: 306| Step: 0
Training loss: 1.371708869934082
Validation loss: 2.16488079726696

Epoch: 5| Step: 1
Training loss: 1.742121696472168
Validation loss: 2.169321815172831

Epoch: 5| Step: 2
Training loss: 2.6168582439422607
Validation loss: 2.158784175912539

Epoch: 5| Step: 3
Training loss: 1.7261600494384766
Validation loss: 2.163752401868502

Epoch: 5| Step: 4
Training loss: 1.7423601150512695
Validation loss: 2.1529358327388763

Epoch: 5| Step: 5
Training loss: 2.4353039264678955
Validation loss: 2.144878476858139

Epoch: 5| Step: 6
Training loss: 1.5391603708267212
Validation loss: 2.1727855702241263

Epoch: 5| Step: 7
Training loss: 1.6946579217910767
Validation loss: 2.1722175627946854

Epoch: 5| Step: 8
Training loss: 2.1553428173065186
Validation loss: 2.1766435156265893

Epoch: 5| Step: 9
Training loss: 1.6262327432632446
Validation loss: 2.2020102938016257

Epoch: 5| Step: 10
Training loss: 1.6432346105575562
Validation loss: 2.2054900328318277

Epoch: 5| Step: 11
Training loss: 1.1469192504882812
Validation loss: 2.2048898537953696

Epoch: 307| Step: 0
Training loss: 2.1018457412719727
Validation loss: 2.2073322534561157

Epoch: 5| Step: 1
Training loss: 1.8744415044784546
Validation loss: 2.2080097993214927

Epoch: 5| Step: 2
Training loss: 2.158114433288574
Validation loss: 2.2016333589951196

Epoch: 5| Step: 3
Training loss: 1.411974549293518
Validation loss: 2.2115707198778787

Epoch: 5| Step: 4
Training loss: 1.2607269287109375
Validation loss: 2.197080781062444

Epoch: 5| Step: 5
Training loss: 2.3088831901550293
Validation loss: 2.1801431079705558

Epoch: 5| Step: 6
Training loss: 1.7530834674835205
Validation loss: 2.2018111050128937

Epoch: 5| Step: 7
Training loss: 1.751622200012207
Validation loss: 2.2054926256338754

Epoch: 5| Step: 8
Training loss: 1.8438169956207275
Validation loss: 2.1974389404058456

Epoch: 5| Step: 9
Training loss: 1.7036911249160767
Validation loss: 2.2051901469628015

Epoch: 5| Step: 10
Training loss: 1.4102070331573486
Validation loss: 2.2135020246108374

Epoch: 5| Step: 11
Training loss: 3.242265224456787
Validation loss: 2.208541437983513

Epoch: 308| Step: 0
Training loss: 1.7963577508926392
Validation loss: 2.20473442475001

Epoch: 5| Step: 1
Training loss: 1.7515861988067627
Validation loss: 2.1985720743735633

Epoch: 5| Step: 2
Training loss: 1.9265750646591187
Validation loss: 2.198157012462616

Epoch: 5| Step: 3
Training loss: 2.1118950843811035
Validation loss: 2.184009542067846

Epoch: 5| Step: 4
Training loss: 1.2440789937973022
Validation loss: 2.1976519574721656

Epoch: 5| Step: 5
Training loss: 2.1293094158172607
Validation loss: 2.1961643050114312

Epoch: 5| Step: 6
Training loss: 2.284024238586426
Validation loss: 2.2080012609561286

Epoch: 5| Step: 7
Training loss: 2.0098557472229004
Validation loss: 2.2075817237297692

Epoch: 5| Step: 8
Training loss: 1.5172109603881836
Validation loss: 2.200316165884336

Epoch: 5| Step: 9
Training loss: 1.345001459121704
Validation loss: 2.2118504444758096

Epoch: 5| Step: 10
Training loss: 1.3232215642929077
Validation loss: 2.2362207770347595

Epoch: 5| Step: 11
Training loss: 2.1895737648010254
Validation loss: 2.217849150300026

Epoch: 309| Step: 0
Training loss: 1.6534597873687744
Validation loss: 2.238831639289856

Epoch: 5| Step: 1
Training loss: 1.7171447277069092
Validation loss: 2.2405781944592795

Epoch: 5| Step: 2
Training loss: 1.5176184177398682
Validation loss: 2.2278894186019897

Epoch: 5| Step: 3
Training loss: 2.0497355461120605
Validation loss: 2.221101070443789

Epoch: 5| Step: 4
Training loss: 1.3830081224441528
Validation loss: 2.2171102662881217

Epoch: 5| Step: 5
Training loss: 1.7569221258163452
Validation loss: 2.2196965316931405

Epoch: 5| Step: 6
Training loss: 2.1003212928771973
Validation loss: 2.211240202188492

Epoch: 5| Step: 7
Training loss: 1.3853838443756104
Validation loss: 2.2165132015943527

Epoch: 5| Step: 8
Training loss: 1.6591112613677979
Validation loss: 2.1986971348524094

Epoch: 5| Step: 9
Training loss: 2.0706396102905273
Validation loss: 2.1971439719200134

Epoch: 5| Step: 10
Training loss: 1.630335807800293
Validation loss: 2.1755965451399484

Epoch: 5| Step: 11
Training loss: 2.3132576942443848
Validation loss: 2.194417337576548

Epoch: 310| Step: 0
Training loss: 1.6755119562149048
Validation loss: 2.2041821430126824

Epoch: 5| Step: 1
Training loss: 1.373971939086914
Validation loss: 2.2089385638634362

Epoch: 5| Step: 2
Training loss: 1.662952184677124
Validation loss: 2.225628395875295

Epoch: 5| Step: 3
Training loss: 1.4017918109893799
Validation loss: 2.217953453461329

Epoch: 5| Step: 4
Training loss: 1.6594165563583374
Validation loss: 2.2259686092535653

Epoch: 5| Step: 5
Training loss: 1.617765188217163
Validation loss: 2.210788498322169

Epoch: 5| Step: 6
Training loss: 1.5333709716796875
Validation loss: 2.2253699898719788

Epoch: 5| Step: 7
Training loss: 2.448939800262451
Validation loss: 2.2014272262652717

Epoch: 5| Step: 8
Training loss: 2.1858272552490234
Validation loss: 2.2253343065579734

Epoch: 5| Step: 9
Training loss: 2.1137726306915283
Validation loss: 2.210961769024531

Epoch: 5| Step: 10
Training loss: 1.8673244714736938
Validation loss: 2.205219119787216

Epoch: 5| Step: 11
Training loss: 2.367840528488159
Validation loss: 2.2134257654349008

Epoch: 311| Step: 0
Training loss: 1.9249608516693115
Validation loss: 2.203565776348114

Epoch: 5| Step: 1
Training loss: 1.881129264831543
Validation loss: 2.1989863316218057

Epoch: 5| Step: 2
Training loss: 1.9178158044815063
Validation loss: 2.2016183038552604

Epoch: 5| Step: 3
Training loss: 1.7755839824676514
Validation loss: 2.1958777209122977

Epoch: 5| Step: 4
Training loss: 1.6592471599578857
Validation loss: 2.1803353081146875

Epoch: 5| Step: 5
Training loss: 1.384281873703003
Validation loss: 2.2073513517777124

Epoch: 5| Step: 6
Training loss: 1.9890810251235962
Validation loss: 2.202095796664556

Epoch: 5| Step: 7
Training loss: 1.8741121292114258
Validation loss: 2.190161089102427

Epoch: 5| Step: 8
Training loss: 1.7557246685028076
Validation loss: 2.2048270404338837

Epoch: 5| Step: 9
Training loss: 1.6456825733184814
Validation loss: 2.19257124265035

Epoch: 5| Step: 10
Training loss: 1.5316942930221558
Validation loss: 2.186100870370865

Epoch: 5| Step: 11
Training loss: 1.4353891611099243
Validation loss: 2.176715781291326

Epoch: 312| Step: 0
Training loss: 1.4572842121124268
Validation loss: 2.1955171326796212

Epoch: 5| Step: 1
Training loss: 1.7586206197738647
Validation loss: 2.197078118721644

Epoch: 5| Step: 2
Training loss: 1.636223554611206
Validation loss: 2.175567408402761

Epoch: 5| Step: 3
Training loss: 1.2860310077667236
Validation loss: 2.1895967721939087

Epoch: 5| Step: 4
Training loss: 1.6705634593963623
Validation loss: 2.1784898887077966

Epoch: 5| Step: 5
Training loss: 1.9030574560165405
Validation loss: 2.1766719669103622

Epoch: 5| Step: 6
Training loss: 1.2599319219589233
Validation loss: 2.177421659231186

Epoch: 5| Step: 7
Training loss: 2.371612071990967
Validation loss: 2.1822015047073364

Epoch: 5| Step: 8
Training loss: 1.8571844100952148
Validation loss: 2.179597189029058

Epoch: 5| Step: 9
Training loss: 2.186612844467163
Validation loss: 2.1859784374634423

Epoch: 5| Step: 10
Training loss: 2.0545103549957275
Validation loss: 2.1785337130228677

Epoch: 5| Step: 11
Training loss: 1.273999571800232
Validation loss: 2.2025143802165985

Epoch: 313| Step: 0
Training loss: 1.603704810142517
Validation loss: 2.2089770634969077

Epoch: 5| Step: 1
Training loss: 1.614995002746582
Validation loss: 2.215345640977224

Epoch: 5| Step: 2
Training loss: 1.631201982498169
Validation loss: 2.2261502047379813

Epoch: 5| Step: 3
Training loss: 1.9134505987167358
Validation loss: 2.2188934087753296

Epoch: 5| Step: 4
Training loss: 1.7230017185211182
Validation loss: 2.2227542201677957

Epoch: 5| Step: 5
Training loss: 1.9301764965057373
Validation loss: 2.20435560743014

Epoch: 5| Step: 6
Training loss: 1.4549932479858398
Validation loss: 2.2500267227490744

Epoch: 5| Step: 7
Training loss: 2.255199909210205
Validation loss: 2.2167727450529733

Epoch: 5| Step: 8
Training loss: 1.5298023223876953
Validation loss: 2.2269624521334968

Epoch: 5| Step: 9
Training loss: 1.3803166151046753
Validation loss: 2.2097850243250527

Epoch: 5| Step: 10
Training loss: 1.8971971273422241
Validation loss: 2.2089949200550714

Epoch: 5| Step: 11
Training loss: 4.140439987182617
Validation loss: 2.215096036593119

Epoch: 314| Step: 0
Training loss: 1.1743018627166748
Validation loss: 2.2002013325691223

Epoch: 5| Step: 1
Training loss: 2.103309154510498
Validation loss: 2.208676944176356

Epoch: 5| Step: 2
Training loss: 1.8839976787567139
Validation loss: 2.1916957894961038

Epoch: 5| Step: 3
Training loss: 1.5305404663085938
Validation loss: 2.2110737462838492

Epoch: 5| Step: 4
Training loss: 1.7915904521942139
Validation loss: 2.201170896490415

Epoch: 5| Step: 5
Training loss: 2.0046353340148926
Validation loss: 2.2072309851646423

Epoch: 5| Step: 6
Training loss: 1.7143865823745728
Validation loss: 2.185575231909752

Epoch: 5| Step: 7
Training loss: 1.8891061544418335
Validation loss: 2.2049130698045096

Epoch: 5| Step: 8
Training loss: 1.4912161827087402
Validation loss: 2.2123150626818338

Epoch: 5| Step: 9
Training loss: 1.5752729177474976
Validation loss: 2.2184072583913803

Epoch: 5| Step: 10
Training loss: 1.8246736526489258
Validation loss: 2.186433439453443

Epoch: 5| Step: 11
Training loss: 4.173005104064941
Validation loss: 2.205265318353971

Epoch: 315| Step: 0
Training loss: 1.9480514526367188
Validation loss: 2.1973764499028525

Epoch: 5| Step: 1
Training loss: 2.0317630767822266
Validation loss: 2.173100858926773

Epoch: 5| Step: 2
Training loss: 1.666748046875
Validation loss: 2.1816357572873435

Epoch: 5| Step: 3
Training loss: 1.2467975616455078
Validation loss: 2.1904088854789734

Epoch: 5| Step: 4
Training loss: 1.5192234516143799
Validation loss: 2.189756194750468

Epoch: 5| Step: 5
Training loss: 1.7520339488983154
Validation loss: 2.1920840243498483

Epoch: 5| Step: 6
Training loss: 1.3117496967315674
Validation loss: 2.1807820200920105

Epoch: 5| Step: 7
Training loss: 1.9657459259033203
Validation loss: 2.2020447651545205

Epoch: 5| Step: 8
Training loss: 1.7548038959503174
Validation loss: 2.213651200135549

Epoch: 5| Step: 9
Training loss: 1.9187160730361938
Validation loss: 2.1805524975061417

Epoch: 5| Step: 10
Training loss: 1.807135820388794
Validation loss: 2.2074303328990936

Epoch: 5| Step: 11
Training loss: 1.5670146942138672
Validation loss: 2.219650318225225

Epoch: 316| Step: 0
Training loss: 1.5584602355957031
Validation loss: 2.2350293497244516

Epoch: 5| Step: 1
Training loss: 1.537033200263977
Validation loss: 2.213314265012741

Epoch: 5| Step: 2
Training loss: 1.9654080867767334
Validation loss: 2.2235838969548545

Epoch: 5| Step: 3
Training loss: 1.6418460607528687
Validation loss: 2.2229240188995996

Epoch: 5| Step: 4
Training loss: 1.673541784286499
Validation loss: 2.22506220638752

Epoch: 5| Step: 5
Training loss: 1.926976203918457
Validation loss: 2.2163230081399283

Epoch: 5| Step: 6
Training loss: 1.7014249563217163
Validation loss: 2.209451268116633

Epoch: 5| Step: 7
Training loss: 1.8775688409805298
Validation loss: 2.183231234550476

Epoch: 5| Step: 8
Training loss: 1.7263195514678955
Validation loss: 2.176089882850647

Epoch: 5| Step: 9
Training loss: 2.252908229827881
Validation loss: 2.1750881721576056

Epoch: 5| Step: 10
Training loss: 1.8870683908462524
Validation loss: 2.194041738907496

Epoch: 5| Step: 11
Training loss: 0.8422935009002686
Validation loss: 2.1782787442207336

Epoch: 317| Step: 0
Training loss: 2.0724029541015625
Validation loss: 2.195336878299713

Epoch: 5| Step: 1
Training loss: 1.8685519695281982
Validation loss: 2.1823377311229706

Epoch: 5| Step: 2
Training loss: 1.5427353382110596
Validation loss: 2.192604720592499

Epoch: 5| Step: 3
Training loss: 2.395951747894287
Validation loss: 2.1988225877285004

Epoch: 5| Step: 4
Training loss: 1.4040114879608154
Validation loss: 2.2003900905450187

Epoch: 5| Step: 5
Training loss: 1.8685150146484375
Validation loss: 2.2180407444636026

Epoch: 5| Step: 6
Training loss: 1.7442080974578857
Validation loss: 2.181446060538292

Epoch: 5| Step: 7
Training loss: 1.53536057472229
Validation loss: 2.209346835811933

Epoch: 5| Step: 8
Training loss: 1.4725100994110107
Validation loss: 2.183067967494329

Epoch: 5| Step: 9
Training loss: 1.670251488685608
Validation loss: 2.213961496949196

Epoch: 5| Step: 10
Training loss: 1.435879111289978
Validation loss: 2.1921019752820334

Epoch: 5| Step: 11
Training loss: 1.545220136642456
Validation loss: 2.197516987721125

Epoch: 318| Step: 0
Training loss: 1.4985926151275635
Validation loss: 2.1782291531562805

Epoch: 5| Step: 1
Training loss: 1.609464406967163
Validation loss: 2.212122360865275

Epoch: 5| Step: 2
Training loss: 1.6064962148666382
Validation loss: 2.205908626317978

Epoch: 5| Step: 3
Training loss: 1.901855230331421
Validation loss: 2.2312572648127875

Epoch: 5| Step: 4
Training loss: 1.6846210956573486
Validation loss: 2.25488809744517

Epoch: 5| Step: 5
Training loss: 1.7350718975067139
Validation loss: 2.2301284670829773

Epoch: 5| Step: 6
Training loss: 1.6596062183380127
Validation loss: 2.2289299269517264

Epoch: 5| Step: 7
Training loss: 1.9794375896453857
Validation loss: 2.2202871441841125

Epoch: 5| Step: 8
Training loss: 1.6450622081756592
Validation loss: 2.2225949317216873

Epoch: 5| Step: 9
Training loss: 1.8977330923080444
Validation loss: 2.2161516149838767

Epoch: 5| Step: 10
Training loss: 1.7459516525268555
Validation loss: 2.1847444772720337

Epoch: 5| Step: 11
Training loss: 2.0787596702575684
Validation loss: 2.2200120091438293

Epoch: 319| Step: 0
Training loss: 1.6942017078399658
Validation loss: 2.1977882981300354

Epoch: 5| Step: 1
Training loss: 1.4097931385040283
Validation loss: 2.195597936709722

Epoch: 5| Step: 2
Training loss: 1.9529911279678345
Validation loss: 2.191813046733538

Epoch: 5| Step: 3
Training loss: 1.599759817123413
Validation loss: 2.1978533565998077

Epoch: 5| Step: 4
Training loss: 1.8751318454742432
Validation loss: 2.19415952761968

Epoch: 5| Step: 5
Training loss: 2.00871205329895
Validation loss: 2.183842266599337

Epoch: 5| Step: 6
Training loss: 2.004822254180908
Validation loss: 2.2037710895140967

Epoch: 5| Step: 7
Training loss: 1.5227622985839844
Validation loss: 2.2142361104488373

Epoch: 5| Step: 8
Training loss: 1.1132681369781494
Validation loss: 2.2041763216257095

Epoch: 5| Step: 9
Training loss: 1.7146075963974
Validation loss: 2.207142079869906

Epoch: 5| Step: 10
Training loss: 1.9072341918945312
Validation loss: 2.213486433029175

Epoch: 5| Step: 11
Training loss: 1.1132625341415405
Validation loss: 2.2116057872772217

Epoch: 320| Step: 0
Training loss: 1.5557959079742432
Validation loss: 2.210942248503367

Epoch: 5| Step: 1
Training loss: 1.473099946975708
Validation loss: 2.211397538582484

Epoch: 5| Step: 2
Training loss: 1.722718596458435
Validation loss: 2.216957320769628

Epoch: 5| Step: 3
Training loss: 1.7321462631225586
Validation loss: 2.203739732503891

Epoch: 5| Step: 4
Training loss: 1.4642608165740967
Validation loss: 2.2137254079182944

Epoch: 5| Step: 5
Training loss: 1.6824756860733032
Validation loss: 2.213817223906517

Epoch: 5| Step: 6
Training loss: 1.5774167776107788
Validation loss: 2.2089736560980477

Epoch: 5| Step: 7
Training loss: 1.5648889541625977
Validation loss: 2.2276269694169364

Epoch: 5| Step: 8
Training loss: 2.51143217086792
Validation loss: 2.2138604124387107

Epoch: 5| Step: 9
Training loss: 1.6611156463623047
Validation loss: 2.204423447450002

Epoch: 5| Step: 10
Training loss: 1.4417288303375244
Validation loss: 2.2129270285367966

Epoch: 5| Step: 11
Training loss: 1.8835681676864624
Validation loss: 2.1822805802027383

Epoch: 321| Step: 0
Training loss: 1.4594056606292725
Validation loss: 2.185488517085711

Epoch: 5| Step: 1
Training loss: 1.7896791696548462
Validation loss: 2.200680136680603

Epoch: 5| Step: 2
Training loss: 1.8063647747039795
Validation loss: 2.20892866452535

Epoch: 5| Step: 3
Training loss: 2.0460052490234375
Validation loss: 2.2150947799285254

Epoch: 5| Step: 4
Training loss: 1.8730170726776123
Validation loss: 2.219136744737625

Epoch: 5| Step: 5
Training loss: 1.2907586097717285
Validation loss: 2.1949320286512375

Epoch: 5| Step: 6
Training loss: 1.6486997604370117
Validation loss: 2.184287200371424

Epoch: 5| Step: 7
Training loss: 1.6889654397964478
Validation loss: 2.1967916836341224

Epoch: 5| Step: 8
Training loss: 1.6619542837142944
Validation loss: 2.182182361682256

Epoch: 5| Step: 9
Training loss: 2.605638027191162
Validation loss: 2.200758015116056

Epoch: 5| Step: 10
Training loss: 1.1392738819122314
Validation loss: 2.195996185143789

Epoch: 5| Step: 11
Training loss: 0.48842716217041016
Validation loss: 2.213260685404142

Epoch: 322| Step: 0
Training loss: 2.007364511489868
Validation loss: 2.219130277633667

Epoch: 5| Step: 1
Training loss: 1.5927364826202393
Validation loss: 2.245940307776133

Epoch: 5| Step: 2
Training loss: 1.6418678760528564
Validation loss: 2.23655699690183

Epoch: 5| Step: 3
Training loss: 2.3828017711639404
Validation loss: 2.232780565818151

Epoch: 5| Step: 4
Training loss: 1.535171389579773
Validation loss: 2.225227952003479

Epoch: 5| Step: 5
Training loss: 1.4942458868026733
Validation loss: 2.244055519501368

Epoch: 5| Step: 6
Training loss: 1.5460631847381592
Validation loss: 2.248387932777405

Epoch: 5| Step: 7
Training loss: 1.1557998657226562
Validation loss: 2.2243782182534537

Epoch: 5| Step: 8
Training loss: 1.7819617986679077
Validation loss: 2.2113117973009744

Epoch: 5| Step: 9
Training loss: 1.7326492071151733
Validation loss: 2.212031344572703

Epoch: 5| Step: 10
Training loss: 1.9669029712677002
Validation loss: 2.2082513819138208

Epoch: 5| Step: 11
Training loss: 2.036339282989502
Validation loss: 2.183222085237503

Epoch: 323| Step: 0
Training loss: 1.7089771032333374
Validation loss: 2.200880214571953

Epoch: 5| Step: 1
Training loss: 1.3908393383026123
Validation loss: 2.210915227731069

Epoch: 5| Step: 2
Training loss: 1.812201738357544
Validation loss: 2.2005929549535117

Epoch: 5| Step: 3
Training loss: 1.8951218128204346
Validation loss: 2.2126050939162574

Epoch: 5| Step: 4
Training loss: 1.5763452053070068
Validation loss: 2.2236278454462686

Epoch: 5| Step: 5
Training loss: 1.7191531658172607
Validation loss: 2.2100932747125626

Epoch: 5| Step: 6
Training loss: 1.927799940109253
Validation loss: 2.200066606203715

Epoch: 5| Step: 7
Training loss: 1.2787061929702759
Validation loss: 2.2151097307602563

Epoch: 5| Step: 8
Training loss: 1.950941801071167
Validation loss: 2.2267350306113562

Epoch: 5| Step: 9
Training loss: 1.521653175354004
Validation loss: 2.230918029944102

Epoch: 5| Step: 10
Training loss: 2.087836742401123
Validation loss: 2.2203462620576224

Epoch: 5| Step: 11
Training loss: 1.743973731994629
Validation loss: 2.231318215529124

Epoch: 324| Step: 0
Training loss: 1.6619430780410767
Validation loss: 2.2216287901004157

Epoch: 5| Step: 1
Training loss: 2.234814405441284
Validation loss: 2.2257670213778815

Epoch: 5| Step: 2
Training loss: 1.287562608718872
Validation loss: 2.203754112124443

Epoch: 5| Step: 3
Training loss: 1.8623775243759155
Validation loss: 2.20689923564593

Epoch: 5| Step: 4
Training loss: 2.1019399166107178
Validation loss: 2.2001404563585916

Epoch: 5| Step: 5
Training loss: 1.5337064266204834
Validation loss: 2.1963689774274826

Epoch: 5| Step: 6
Training loss: 1.9324066638946533
Validation loss: 2.224258601665497

Epoch: 5| Step: 7
Training loss: 2.1097846031188965
Validation loss: 2.2316380739212036

Epoch: 5| Step: 8
Training loss: 0.7925185561180115
Validation loss: 2.209761073191961

Epoch: 5| Step: 9
Training loss: 1.7987722158432007
Validation loss: 2.2404455741246543

Epoch: 5| Step: 10
Training loss: 1.586712121963501
Validation loss: 2.246520052353541

Epoch: 5| Step: 11
Training loss: 0.8414550423622131
Validation loss: 2.2284293174743652

Epoch: 325| Step: 0
Training loss: 1.4430501461029053
Validation loss: 2.2131377855936685

Epoch: 5| Step: 1
Training loss: 1.4943181276321411
Validation loss: 2.223622297247251

Epoch: 5| Step: 2
Training loss: 1.1347564458847046
Validation loss: 2.205092966556549

Epoch: 5| Step: 3
Training loss: 2.591245174407959
Validation loss: 2.212830051779747

Epoch: 5| Step: 4
Training loss: 1.9846594333648682
Validation loss: 2.208889067173004

Epoch: 5| Step: 5
Training loss: 1.7146461009979248
Validation loss: 2.20407934486866

Epoch: 5| Step: 6
Training loss: 1.4524999856948853
Validation loss: 2.212259535988172

Epoch: 5| Step: 7
Training loss: 1.4006562232971191
Validation loss: 2.215868284304937

Epoch: 5| Step: 8
Training loss: 1.444760799407959
Validation loss: 2.2290437519550323

Epoch: 5| Step: 9
Training loss: 1.5701993703842163
Validation loss: 2.2093763947486877

Epoch: 5| Step: 10
Training loss: 1.6430270671844482
Validation loss: 2.2205573320388794

Epoch: 5| Step: 11
Training loss: 4.720949172973633
Validation loss: 2.2344777335723243

Epoch: 326| Step: 0
Training loss: 1.1467872858047485
Validation loss: 2.2136046290397644

Epoch: 5| Step: 1
Training loss: 2.536046028137207
Validation loss: 2.2145387132962546

Epoch: 5| Step: 2
Training loss: 1.5334333181381226
Validation loss: 2.210465927918752

Epoch: 5| Step: 3
Training loss: 1.8049455881118774
Validation loss: 2.197337955236435

Epoch: 5| Step: 4
Training loss: 1.5297696590423584
Validation loss: 2.187152847647667

Epoch: 5| Step: 5
Training loss: 1.5534580945968628
Validation loss: 2.1856214900811515

Epoch: 5| Step: 6
Training loss: 1.4263118505477905
Validation loss: 2.192477067311605

Epoch: 5| Step: 7
Training loss: 2.3132033348083496
Validation loss: 2.187280764182409

Epoch: 5| Step: 8
Training loss: 1.5768541097640991
Validation loss: 2.198615243037542

Epoch: 5| Step: 9
Training loss: 1.588030457496643
Validation loss: 2.2088818897803626

Epoch: 5| Step: 10
Training loss: 1.682189702987671
Validation loss: 2.2187925974527993

Epoch: 5| Step: 11
Training loss: 1.3917120695114136
Validation loss: 2.2142290274302163

Epoch: 327| Step: 0
Training loss: 1.9943958520889282
Validation loss: 2.2159202893575034

Epoch: 5| Step: 1
Training loss: 1.4992585182189941
Validation loss: 2.2160048335790634

Epoch: 5| Step: 2
Training loss: 1.7281808853149414
Validation loss: 2.2127819508314133

Epoch: 5| Step: 3
Training loss: 1.8979921340942383
Validation loss: 2.2198051114877067

Epoch: 5| Step: 4
Training loss: 1.895958662033081
Validation loss: 2.224838674068451

Epoch: 5| Step: 5
Training loss: 1.7978847026824951
Validation loss: 2.237398068110148

Epoch: 5| Step: 6
Training loss: 1.6702104806900024
Validation loss: 2.2522296706835427

Epoch: 5| Step: 7
Training loss: 1.5406181812286377
Validation loss: 2.2537469367186227

Epoch: 5| Step: 8
Training loss: 1.3807146549224854
Validation loss: 2.205970138311386

Epoch: 5| Step: 9
Training loss: 1.4487007856369019
Validation loss: 2.197638829549154

Epoch: 5| Step: 10
Training loss: 1.976291298866272
Validation loss: 2.2185143530368805

Epoch: 5| Step: 11
Training loss: 2.9055163860321045
Validation loss: 2.2089076340198517

Epoch: 328| Step: 0
Training loss: 1.5946567058563232
Validation loss: 2.1994914760192237

Epoch: 5| Step: 1
Training loss: 2.2153725624084473
Validation loss: 2.2078289637962976

Epoch: 5| Step: 2
Training loss: 2.42319917678833
Validation loss: 2.1881374617417655

Epoch: 5| Step: 3
Training loss: 1.513768196105957
Validation loss: 2.1804064313570657

Epoch: 5| Step: 4
Training loss: 1.6423089504241943
Validation loss: 2.1739709228277206

Epoch: 5| Step: 5
Training loss: 1.3000959157943726
Validation loss: 2.164903829495112

Epoch: 5| Step: 6
Training loss: 1.3669207096099854
Validation loss: 2.1737788021564484

Epoch: 5| Step: 7
Training loss: 1.4816946983337402
Validation loss: 2.1836705952882767

Epoch: 5| Step: 8
Training loss: 1.7645180225372314
Validation loss: 2.188010036945343

Epoch: 5| Step: 9
Training loss: 1.7007919549942017
Validation loss: 2.2052368223667145

Epoch: 5| Step: 10
Training loss: 1.4682934284210205
Validation loss: 2.1962467233339944

Epoch: 5| Step: 11
Training loss: 2.471416711807251
Validation loss: 2.2135939796765647

Epoch: 329| Step: 0
Training loss: 2.0846195220947266
Validation loss: 2.219372803966204

Epoch: 5| Step: 1
Training loss: 2.337172031402588
Validation loss: 2.2035289208094277

Epoch: 5| Step: 2
Training loss: 1.5728412866592407
Validation loss: 2.2242631713549295

Epoch: 5| Step: 3
Training loss: 0.9639253616333008
Validation loss: 2.2208519876003265

Epoch: 5| Step: 4
Training loss: 1.8254661560058594
Validation loss: 2.2039450208346048

Epoch: 5| Step: 5
Training loss: 0.9661451578140259
Validation loss: 2.226010575890541

Epoch: 5| Step: 6
Training loss: 1.5445244312286377
Validation loss: 2.206754833459854

Epoch: 5| Step: 7
Training loss: 1.69330632686615
Validation loss: 2.1847939689954123

Epoch: 5| Step: 8
Training loss: 1.6666961908340454
Validation loss: 2.196024770538012

Epoch: 5| Step: 9
Training loss: 1.64556086063385
Validation loss: 2.189235215385755

Epoch: 5| Step: 10
Training loss: 2.184563398361206
Validation loss: 2.185039758682251

Epoch: 5| Step: 11
Training loss: 0.8499517440795898
Validation loss: 2.1865906020005546

Epoch: 330| Step: 0
Training loss: 2.1299357414245605
Validation loss: 2.176155850291252

Epoch: 5| Step: 1
Training loss: 1.1086809635162354
Validation loss: 2.2029893497625985

Epoch: 5| Step: 2
Training loss: 2.02344012260437
Validation loss: 2.1879790971676507

Epoch: 5| Step: 3
Training loss: 1.8877264261245728
Validation loss: 2.1881371090809503

Epoch: 5| Step: 4
Training loss: 1.5925976037979126
Validation loss: 2.209652990102768

Epoch: 5| Step: 5
Training loss: 1.4099105596542358
Validation loss: 2.210080792506536

Epoch: 5| Step: 6
Training loss: 1.5078117847442627
Validation loss: 2.213678151369095

Epoch: 5| Step: 7
Training loss: 2.0899884700775146
Validation loss: 2.2162316193183265

Epoch: 5| Step: 8
Training loss: 1.778733491897583
Validation loss: 2.228535369038582

Epoch: 5| Step: 9
Training loss: 1.360556960105896
Validation loss: 2.208827495574951

Epoch: 5| Step: 10
Training loss: 1.2746154069900513
Validation loss: 2.216425061225891

Epoch: 5| Step: 11
Training loss: 2.0922372341156006
Validation loss: 2.2171082695325217

Epoch: 331| Step: 0
Training loss: 1.7285470962524414
Validation loss: 2.2274866004784903

Epoch: 5| Step: 1
Training loss: 1.6761045455932617
Validation loss: 2.2059893906116486

Epoch: 5| Step: 2
Training loss: 1.4317023754119873
Validation loss: 2.2286041527986526

Epoch: 5| Step: 3
Training loss: 1.6948986053466797
Validation loss: 2.2143405427535376

Epoch: 5| Step: 4
Training loss: 1.1515089273452759
Validation loss: 2.1970547139644623

Epoch: 5| Step: 5
Training loss: 2.123063564300537
Validation loss: 2.2039395570755005

Epoch: 5| Step: 6
Training loss: 1.061645269393921
Validation loss: 2.205561821659406

Epoch: 5| Step: 7
Training loss: 1.5403673648834229
Validation loss: 2.1979753524065018

Epoch: 5| Step: 8
Training loss: 1.9319334030151367
Validation loss: 2.2170041302839913

Epoch: 5| Step: 9
Training loss: 1.7244548797607422
Validation loss: 2.198315292596817

Epoch: 5| Step: 10
Training loss: 1.9677789211273193
Validation loss: 2.209229126572609

Epoch: 5| Step: 11
Training loss: 1.866532802581787
Validation loss: 2.2123317321141562

Epoch: 332| Step: 0
Training loss: 1.6992946863174438
Validation loss: 2.204974522193273

Epoch: 5| Step: 1
Training loss: 1.1407760381698608
Validation loss: 2.190528094768524

Epoch: 5| Step: 2
Training loss: 2.262718439102173
Validation loss: 2.1872125466664634

Epoch: 5| Step: 3
Training loss: 1.4473577737808228
Validation loss: 2.18908662100633

Epoch: 5| Step: 4
Training loss: 1.892433762550354
Validation loss: 2.2038363019625344

Epoch: 5| Step: 5
Training loss: 1.5081859827041626
Validation loss: 2.2169697086016336

Epoch: 5| Step: 6
Training loss: 1.562201738357544
Validation loss: 2.179969365398089

Epoch: 5| Step: 7
Training loss: 1.89219069480896
Validation loss: 2.194667011499405

Epoch: 5| Step: 8
Training loss: 1.424594521522522
Validation loss: 2.1774020741383233

Epoch: 5| Step: 9
Training loss: 1.5382137298583984
Validation loss: 2.194269190231959

Epoch: 5| Step: 10
Training loss: 1.8480907678604126
Validation loss: 2.2094538609186807

Epoch: 5| Step: 11
Training loss: 3.9122121334075928
Validation loss: 2.2092706014712653

Epoch: 333| Step: 0
Training loss: 1.7455413341522217
Validation loss: 2.23795876900355

Epoch: 5| Step: 1
Training loss: 1.3435710668563843
Validation loss: 2.2253261605898538

Epoch: 5| Step: 2
Training loss: 1.7584158182144165
Validation loss: 2.2143601775169373

Epoch: 5| Step: 3
Training loss: 1.9529008865356445
Validation loss: 2.222956637541453

Epoch: 5| Step: 4
Training loss: 1.8248968124389648
Validation loss: 2.2375425895055137

Epoch: 5| Step: 5
Training loss: 1.4124186038970947
Validation loss: 2.237814500927925

Epoch: 5| Step: 6
Training loss: 1.401776909828186
Validation loss: 2.2072087874015174

Epoch: 5| Step: 7
Training loss: 1.4436328411102295
Validation loss: 2.2122226655483246

Epoch: 5| Step: 8
Training loss: 2.1404061317443848
Validation loss: 2.1886759599049888

Epoch: 5| Step: 9
Training loss: 1.6299951076507568
Validation loss: 2.1977463165918985

Epoch: 5| Step: 10
Training loss: 1.9233291149139404
Validation loss: 2.19477079808712

Epoch: 5| Step: 11
Training loss: 2.4129185676574707
Validation loss: 2.207923357685407

Epoch: 334| Step: 0
Training loss: 1.7086979150772095
Validation loss: 2.1844648271799088

Epoch: 5| Step: 1
Training loss: 1.8535646200180054
Validation loss: 2.187756488720576

Epoch: 5| Step: 2
Training loss: 1.7214456796646118
Validation loss: 2.1952411979436874

Epoch: 5| Step: 3
Training loss: 1.1785213947296143
Validation loss: 2.206472764412562

Epoch: 5| Step: 4
Training loss: 1.9104779958724976
Validation loss: 2.20211453239123

Epoch: 5| Step: 5
Training loss: 1.2831064462661743
Validation loss: 2.214330663283666

Epoch: 5| Step: 6
Training loss: 2.22891902923584
Validation loss: 2.2397159536679587

Epoch: 5| Step: 7
Training loss: 1.7775169610977173
Validation loss: 2.2164010206858316

Epoch: 5| Step: 8
Training loss: 1.5461572408676147
Validation loss: 2.2158524294694266

Epoch: 5| Step: 9
Training loss: 1.713756799697876
Validation loss: 2.2142791599035263

Epoch: 5| Step: 10
Training loss: 1.4670250415802002
Validation loss: 2.184135456879934

Epoch: 5| Step: 11
Training loss: 2.7516889572143555
Validation loss: 2.1787572453419366

Epoch: 335| Step: 0
Training loss: 1.9638655185699463
Validation loss: 2.1889246304829917

Epoch: 5| Step: 1
Training loss: 1.456215262413025
Validation loss: 2.1825612088044486

Epoch: 5| Step: 2
Training loss: 1.8048579692840576
Validation loss: 2.1780188977718353

Epoch: 5| Step: 3
Training loss: 1.539995789527893
Validation loss: 2.2002622236808143

Epoch: 5| Step: 4
Training loss: 1.8926961421966553
Validation loss: 2.2014338225126266

Epoch: 5| Step: 5
Training loss: 1.955815076828003
Validation loss: 2.195738345384598

Epoch: 5| Step: 6
Training loss: 1.2523351907730103
Validation loss: 2.223828300833702

Epoch: 5| Step: 7
Training loss: 1.3895047903060913
Validation loss: 2.2152455896139145

Epoch: 5| Step: 8
Training loss: 1.8260068893432617
Validation loss: 2.2193799863258996

Epoch: 5| Step: 9
Training loss: 1.292366623878479
Validation loss: 2.216479038198789

Epoch: 5| Step: 10
Training loss: 1.5467870235443115
Validation loss: 2.2141267160574594

Epoch: 5| Step: 11
Training loss: 2.1171679496765137
Validation loss: 2.209480161468188

Epoch: 336| Step: 0
Training loss: 1.7199681997299194
Validation loss: 2.200097451607386

Epoch: 5| Step: 1
Training loss: 1.2715873718261719
Validation loss: 2.174958512187004

Epoch: 5| Step: 2
Training loss: 1.8739477396011353
Validation loss: 2.1862129469712577

Epoch: 5| Step: 3
Training loss: 2.2417614459991455
Validation loss: 2.1887008349100747

Epoch: 5| Step: 4
Training loss: 1.5592044591903687
Validation loss: 2.1946330269177756

Epoch: 5| Step: 5
Training loss: 1.369518518447876
Validation loss: 2.218998755017916

Epoch: 5| Step: 6
Training loss: 2.1479990482330322
Validation loss: 2.2070964177449546

Epoch: 5| Step: 7
Training loss: 2.016385078430176
Validation loss: 2.2215467989444733

Epoch: 5| Step: 8
Training loss: 1.2434015274047852
Validation loss: 2.2065607607364655

Epoch: 5| Step: 9
Training loss: 1.2671856880187988
Validation loss: 2.186795324087143

Epoch: 5| Step: 10
Training loss: 1.56207275390625
Validation loss: 2.200577358404795

Epoch: 5| Step: 11
Training loss: 1.192150354385376
Validation loss: 2.2085872689882913

Epoch: 337| Step: 0
Training loss: 1.2747399806976318
Validation loss: 2.18983785311381

Epoch: 5| Step: 1
Training loss: 2.25036358833313
Validation loss: 2.209320694208145

Epoch: 5| Step: 2
Training loss: 1.3958089351654053
Validation loss: 2.213801314433416

Epoch: 5| Step: 3
Training loss: 1.9427992105484009
Validation loss: 2.2189576973517737

Epoch: 5| Step: 4
Training loss: 1.2444288730621338
Validation loss: 2.20202906926473

Epoch: 5| Step: 5
Training loss: 1.5656572580337524
Validation loss: 2.180597275495529

Epoch: 5| Step: 6
Training loss: 2.077202081680298
Validation loss: 2.192099690437317

Epoch: 5| Step: 7
Training loss: 1.6188024282455444
Validation loss: 2.200258900721868

Epoch: 5| Step: 8
Training loss: 1.540440559387207
Validation loss: 2.2042377342780433

Epoch: 5| Step: 9
Training loss: 1.4826452732086182
Validation loss: 2.2036562661329904

Epoch: 5| Step: 10
Training loss: 1.782947301864624
Validation loss: 2.22218981385231

Epoch: 5| Step: 11
Training loss: 1.4310261011123657
Validation loss: 2.21086223423481

Epoch: 338| Step: 0
Training loss: 1.706742286682129
Validation loss: 2.245552748441696

Epoch: 5| Step: 1
Training loss: 1.9408611059188843
Validation loss: 2.240735093752543

Epoch: 5| Step: 2
Training loss: 1.580260992050171
Validation loss: 2.229860931634903

Epoch: 5| Step: 3
Training loss: 1.6020710468292236
Validation loss: 2.244189659754435

Epoch: 5| Step: 4
Training loss: 1.279055118560791
Validation loss: 2.240210344394048

Epoch: 5| Step: 5
Training loss: 2.0001871585845947
Validation loss: 2.2106426656246185

Epoch: 5| Step: 6
Training loss: 2.0169994831085205
Validation loss: 2.2248646517594657

Epoch: 5| Step: 7
Training loss: 1.7595325708389282
Validation loss: 2.190158873796463

Epoch: 5| Step: 8
Training loss: 1.2059454917907715
Validation loss: 2.2062555253505707

Epoch: 5| Step: 9
Training loss: 1.6541223526000977
Validation loss: 2.181073397397995

Epoch: 5| Step: 10
Training loss: 1.5202049016952515
Validation loss: 2.2201496263345084

Epoch: 5| Step: 11
Training loss: 3.984229803085327
Validation loss: 2.217542370160421

Epoch: 339| Step: 0
Training loss: 1.830339789390564
Validation loss: 2.2161759634812674

Epoch: 5| Step: 1
Training loss: 1.7382415533065796
Validation loss: 2.2283053398132324

Epoch: 5| Step: 2
Training loss: 1.7505080699920654
Validation loss: 2.190378944079081

Epoch: 5| Step: 3
Training loss: 1.6964658498764038
Validation loss: 2.202775572737058

Epoch: 5| Step: 4
Training loss: 2.136155605316162
Validation loss: 2.227760463953018

Epoch: 5| Step: 5
Training loss: 1.1408960819244385
Validation loss: 2.2016528050104776

Epoch: 5| Step: 6
Training loss: 1.4280731678009033
Validation loss: 2.203600451350212

Epoch: 5| Step: 7
Training loss: 1.959587812423706
Validation loss: 2.2076850682497025

Epoch: 5| Step: 8
Training loss: 1.2520813941955566
Validation loss: 2.2112062921126685

Epoch: 5| Step: 9
Training loss: 1.6913621425628662
Validation loss: 2.189524302879969

Epoch: 5| Step: 10
Training loss: 1.523938536643982
Validation loss: 2.206248258550962

Epoch: 5| Step: 11
Training loss: 2.569403886795044
Validation loss: 2.1958499352137246

Epoch: 340| Step: 0
Training loss: 1.633130669593811
Validation loss: 2.202294260263443

Epoch: 5| Step: 1
Training loss: 1.9195480346679688
Validation loss: 2.2204912503560386

Epoch: 5| Step: 2
Training loss: 1.9192997217178345
Validation loss: 2.225558504462242

Epoch: 5| Step: 3
Training loss: 1.2695367336273193
Validation loss: 2.2193219711383185

Epoch: 5| Step: 4
Training loss: 1.7105659246444702
Validation loss: 2.204095706343651

Epoch: 5| Step: 5
Training loss: 1.661878228187561
Validation loss: 2.2333817034959793

Epoch: 5| Step: 6
Training loss: 1.560496211051941
Validation loss: 2.220315804084142

Epoch: 5| Step: 7
Training loss: 1.2551673650741577
Validation loss: 2.228149652481079

Epoch: 5| Step: 8
Training loss: 1.929389238357544
Validation loss: 2.220952406525612

Epoch: 5| Step: 9
Training loss: 1.391298532485962
Validation loss: 2.235785350203514

Epoch: 5| Step: 10
Training loss: 1.7169744968414307
Validation loss: 2.2261116604010263

Epoch: 5| Step: 11
Training loss: 1.596631646156311
Validation loss: 2.216498469312986

Epoch: 341| Step: 0
Training loss: 1.5653088092803955
Validation loss: 2.221537878115972

Epoch: 5| Step: 1
Training loss: 1.1936750411987305
Validation loss: 2.1898803611596427

Epoch: 5| Step: 2
Training loss: 1.7042205333709717
Validation loss: 2.202399174372355

Epoch: 5| Step: 3
Training loss: 1.0382801294326782
Validation loss: 2.2094005743662515

Epoch: 5| Step: 4
Training loss: 2.1249425411224365
Validation loss: 2.2233488460381827

Epoch: 5| Step: 5
Training loss: 1.3967714309692383
Validation loss: 2.2228504021962485

Epoch: 5| Step: 6
Training loss: 1.6375688314437866
Validation loss: 2.2176909148693085

Epoch: 5| Step: 7
Training loss: 1.5688444375991821
Validation loss: 2.20841716726621

Epoch: 5| Step: 8
Training loss: 1.8564090728759766
Validation loss: 2.2006168514490128

Epoch: 5| Step: 9
Training loss: 1.673743486404419
Validation loss: 2.1985409408807755

Epoch: 5| Step: 10
Training loss: 2.2273380756378174
Validation loss: 2.169684872031212

Epoch: 5| Step: 11
Training loss: 0.9359371662139893
Validation loss: 2.227657044927279

Epoch: 342| Step: 0
Training loss: 1.3781691789627075
Validation loss: 2.2089194307724633

Epoch: 5| Step: 1
Training loss: 2.510730743408203
Validation loss: 2.202390809853872

Epoch: 5| Step: 2
Training loss: 1.2745792865753174
Validation loss: 2.213126281897227

Epoch: 5| Step: 3
Training loss: 1.3088634014129639
Validation loss: 2.2117931793133416

Epoch: 5| Step: 4
Training loss: 1.8871313333511353
Validation loss: 2.200061395764351

Epoch: 5| Step: 5
Training loss: 1.3495361804962158
Validation loss: 2.1907046685616174

Epoch: 5| Step: 6
Training loss: 1.165173888206482
Validation loss: 2.2087295949459076

Epoch: 5| Step: 7
Training loss: 1.7728614807128906
Validation loss: 2.1970873375733695

Epoch: 5| Step: 8
Training loss: 1.40300714969635
Validation loss: 2.207174559434255

Epoch: 5| Step: 9
Training loss: 1.9246422052383423
Validation loss: 2.1991164485613504

Epoch: 5| Step: 10
Training loss: 1.5656840801239014
Validation loss: 2.217270145813624

Epoch: 5| Step: 11
Training loss: 2.8160505294799805
Validation loss: 2.1921496589978537

Epoch: 343| Step: 0
Training loss: 2.482618808746338
Validation loss: 2.2070370415846505

Epoch: 5| Step: 1
Training loss: 1.2998487949371338
Validation loss: 2.2202958911657333

Epoch: 5| Step: 2
Training loss: 1.6707265377044678
Validation loss: 2.2100407828887305

Epoch: 5| Step: 3
Training loss: 1.4902844429016113
Validation loss: 2.2031364738941193

Epoch: 5| Step: 4
Training loss: 1.4075007438659668
Validation loss: 2.2073045819997787

Epoch: 5| Step: 5
Training loss: 1.298833966255188
Validation loss: 2.2062310526768365

Epoch: 5| Step: 6
Training loss: 1.3227280378341675
Validation loss: 2.194372991720835

Epoch: 5| Step: 7
Training loss: 1.429390788078308
Validation loss: 2.1936196237802505

Epoch: 5| Step: 8
Training loss: 2.084233283996582
Validation loss: 2.223847339550654

Epoch: 5| Step: 9
Training loss: 0.7913178205490112
Validation loss: 2.217685396472613

Epoch: 5| Step: 10
Training loss: 2.1417155265808105
Validation loss: 2.213277886311213

Epoch: 5| Step: 11
Training loss: 3.1783933639526367
Validation loss: 2.200885052482287

Epoch: 344| Step: 0
Training loss: 1.411206841468811
Validation loss: 2.226195305585861

Epoch: 5| Step: 1
Training loss: 1.5596134662628174
Validation loss: 2.217640290657679

Epoch: 5| Step: 2
Training loss: 1.9244587421417236
Validation loss: 2.215813636779785

Epoch: 5| Step: 3
Training loss: 1.6719785928726196
Validation loss: 2.23698066174984

Epoch: 5| Step: 4
Training loss: 1.781583547592163
Validation loss: 2.2034884293874106

Epoch: 5| Step: 5
Training loss: 1.3865373134613037
Validation loss: 2.213978280623754

Epoch: 5| Step: 6
Training loss: 1.7293230295181274
Validation loss: 2.2076609035333

Epoch: 5| Step: 7
Training loss: 1.9459253549575806
Validation loss: 2.197059785326322

Epoch: 5| Step: 8
Training loss: 1.837756872177124
Validation loss: 2.194547509153684

Epoch: 5| Step: 9
Training loss: 1.4116756916046143
Validation loss: 2.2098296085993447

Epoch: 5| Step: 10
Training loss: 1.2879693508148193
Validation loss: 2.1877117256323495

Epoch: 5| Step: 11
Training loss: 1.0334571599960327
Validation loss: 2.21932644645373

Epoch: 345| Step: 0
Training loss: 1.7642806768417358
Validation loss: 2.2142409284909568

Epoch: 5| Step: 1
Training loss: 1.3015820980072021
Validation loss: 2.2040251394112906

Epoch: 5| Step: 2
Training loss: 1.5624631643295288
Validation loss: 2.212308794260025

Epoch: 5| Step: 3
Training loss: 1.4402316808700562
Validation loss: 2.2066527952750525

Epoch: 5| Step: 4
Training loss: 1.805487036705017
Validation loss: 2.19605819384257

Epoch: 5| Step: 5
Training loss: 1.9691299200057983
Validation loss: 2.23027932147185

Epoch: 5| Step: 6
Training loss: 1.062206506729126
Validation loss: 2.192689746618271

Epoch: 5| Step: 7
Training loss: 1.5719423294067383
Validation loss: 2.2132323483626046

Epoch: 5| Step: 8
Training loss: 2.245820999145508
Validation loss: 2.213789244492849

Epoch: 5| Step: 9
Training loss: 1.913020372390747
Validation loss: 2.1990936199824014

Epoch: 5| Step: 10
Training loss: 1.1594829559326172
Validation loss: 2.2246924936771393

Epoch: 5| Step: 11
Training loss: 1.1315271854400635
Validation loss: 2.227637638648351

Epoch: 346| Step: 0
Training loss: 1.6910858154296875
Validation loss: 2.213329633076986

Epoch: 5| Step: 1
Training loss: 1.5760669708251953
Validation loss: 2.1688085546096167

Epoch: 5| Step: 2
Training loss: 1.1618221998214722
Validation loss: 2.1795703321695328

Epoch: 5| Step: 3
Training loss: 1.532112956047058
Validation loss: 2.178375075260798

Epoch: 5| Step: 4
Training loss: 1.4882893562316895
Validation loss: 2.1729185432195663

Epoch: 5| Step: 5
Training loss: 2.008824348449707
Validation loss: 2.179227367043495

Epoch: 5| Step: 6
Training loss: 1.9398887157440186
Validation loss: 2.1730932543675103

Epoch: 5| Step: 7
Training loss: 2.2482292652130127
Validation loss: 2.157539735237757

Epoch: 5| Step: 8
Training loss: 1.9786163568496704
Validation loss: 2.1659495681524277

Epoch: 5| Step: 9
Training loss: 1.7565845251083374
Validation loss: 2.166594589749972

Epoch: 5| Step: 10
Training loss: 1.403045654296875
Validation loss: 2.1953627914190292

Epoch: 5| Step: 11
Training loss: 2.640829086303711
Validation loss: 2.1923430263996124

Epoch: 347| Step: 0
Training loss: 1.4458162784576416
Validation loss: 2.1668952256441116

Epoch: 5| Step: 1
Training loss: 1.3677982091903687
Validation loss: 2.1953172783056893

Epoch: 5| Step: 2
Training loss: 1.847499132156372
Validation loss: 2.1737501472234726

Epoch: 5| Step: 3
Training loss: 1.7119624614715576
Validation loss: 2.179633935292562

Epoch: 5| Step: 4
Training loss: 1.6126163005828857
Validation loss: 2.1993672251701355

Epoch: 5| Step: 5
Training loss: 1.7710819244384766
Validation loss: 2.186268170674642

Epoch: 5| Step: 6
Training loss: 1.9497783184051514
Validation loss: 2.218690052628517

Epoch: 5| Step: 7
Training loss: 1.9541782140731812
Validation loss: 2.2034929394721985

Epoch: 5| Step: 8
Training loss: 1.1881641149520874
Validation loss: 2.2004427214463553

Epoch: 5| Step: 9
Training loss: 1.361737608909607
Validation loss: 2.174067333340645

Epoch: 5| Step: 10
Training loss: 1.4892324209213257
Validation loss: 2.2095304479201636

Epoch: 5| Step: 11
Training loss: 1.5542759895324707
Validation loss: 2.188624228040377

Epoch: 348| Step: 0
Training loss: 1.0733174085617065
Validation loss: 2.222316339612007

Epoch: 5| Step: 1
Training loss: 1.3692265748977661
Validation loss: 2.1987233410278955

Epoch: 5| Step: 2
Training loss: 1.157810926437378
Validation loss: 2.188233415285746

Epoch: 5| Step: 3
Training loss: 1.9581092596054077
Validation loss: 2.194929540157318

Epoch: 5| Step: 4
Training loss: 1.9855310916900635
Validation loss: 2.162203515569369

Epoch: 5| Step: 5
Training loss: 1.7438350915908813
Validation loss: 2.2004920144875846

Epoch: 5| Step: 6
Training loss: 1.6262626647949219
Validation loss: 2.1972132523854575

Epoch: 5| Step: 7
Training loss: 1.7556993961334229
Validation loss: 2.206425348917643

Epoch: 5| Step: 8
Training loss: 1.4464058876037598
Validation loss: 2.1940165162086487

Epoch: 5| Step: 9
Training loss: 1.938381552696228
Validation loss: 2.2159505784511566

Epoch: 5| Step: 10
Training loss: 1.265506386756897
Validation loss: 2.2067237546046576

Epoch: 5| Step: 11
Training loss: 2.3252224922180176
Validation loss: 2.225293919444084

Epoch: 349| Step: 0
Training loss: 1.5714160203933716
Validation loss: 2.2227698465188346

Epoch: 5| Step: 1
Training loss: 1.4946602582931519
Validation loss: 2.2000589271386466

Epoch: 5| Step: 2
Training loss: 1.3300137519836426
Validation loss: 2.2092404067516327

Epoch: 5| Step: 3
Training loss: 1.7131054401397705
Validation loss: 2.2016515930493674

Epoch: 5| Step: 4
Training loss: 1.4119787216186523
Validation loss: 2.2244755625724792

Epoch: 5| Step: 5
Training loss: 1.6947696208953857
Validation loss: 2.203663150469462

Epoch: 5| Step: 6
Training loss: 1.4910595417022705
Validation loss: 2.2118682910998664

Epoch: 5| Step: 7
Training loss: 1.7157142162322998
Validation loss: 2.225706319014231

Epoch: 5| Step: 8
Training loss: 2.2571334838867188
Validation loss: 2.232900559902191

Epoch: 5| Step: 9
Training loss: 1.4482733011245728
Validation loss: 2.217008570830027

Epoch: 5| Step: 10
Training loss: 1.4529627561569214
Validation loss: 2.2434611916542053

Epoch: 5| Step: 11
Training loss: 1.8509975671768188
Validation loss: 2.2186384399731955

Epoch: 350| Step: 0
Training loss: 1.4197953939437866
Validation loss: 2.2112547159194946

Epoch: 5| Step: 1
Training loss: 1.376320481300354
Validation loss: 2.1856393069028854

Epoch: 5| Step: 2
Training loss: 1.6158355474472046
Validation loss: 2.2109119991461434

Epoch: 5| Step: 3
Training loss: 2.6930618286132812
Validation loss: 2.195112327734629

Epoch: 5| Step: 4
Training loss: 1.985675573348999
Validation loss: 2.185399293899536

Epoch: 5| Step: 5
Training loss: 1.3534793853759766
Validation loss: 2.2041864742835364

Epoch: 5| Step: 6
Training loss: 1.1879501342773438
Validation loss: 2.187941109140714

Epoch: 5| Step: 7
Training loss: 1.5366960763931274
Validation loss: 2.190871993700663

Epoch: 5| Step: 8
Training loss: 1.234493613243103
Validation loss: 2.1997615496317544

Epoch: 5| Step: 9
Training loss: 1.092503547668457
Validation loss: 2.182971954345703

Epoch: 5| Step: 10
Training loss: 2.302750825881958
Validation loss: 2.218297233184179

Epoch: 5| Step: 11
Training loss: 1.3564265966415405
Validation loss: 2.1715161204338074

Epoch: 351| Step: 0
Training loss: 1.7690980434417725
Validation loss: 2.2069349586963654

Epoch: 5| Step: 1
Training loss: 1.2386037111282349
Validation loss: 2.197106823325157

Epoch: 5| Step: 2
Training loss: 0.9346574544906616
Validation loss: 2.1991658359766006

Epoch: 5| Step: 3
Training loss: 1.9663194417953491
Validation loss: 2.210905442635218

Epoch: 5| Step: 4
Training loss: 2.4259402751922607
Validation loss: 2.2179385870695114

Epoch: 5| Step: 5
Training loss: 1.600898027420044
Validation loss: 2.2045001834630966

Epoch: 5| Step: 6
Training loss: 1.8262741565704346
Validation loss: 2.207567647099495

Epoch: 5| Step: 7
Training loss: 1.5180730819702148
Validation loss: 2.2137175798416138

Epoch: 5| Step: 8
Training loss: 1.887554407119751
Validation loss: 2.190233369668325

Epoch: 5| Step: 9
Training loss: 1.6481716632843018
Validation loss: 2.1975716104110083

Epoch: 5| Step: 10
Training loss: 1.466423749923706
Validation loss: 2.1755437652269998

Epoch: 5| Step: 11
Training loss: 2.2983040809631348
Validation loss: 2.1842403560876846

Epoch: 352| Step: 0
Training loss: 1.7713432312011719
Validation loss: 2.1912075827519097

Epoch: 5| Step: 1
Training loss: 1.7317075729370117
Validation loss: 2.2063414802153907

Epoch: 5| Step: 2
Training loss: 1.1987665891647339
Validation loss: 2.1863843500614166

Epoch: 5| Step: 3
Training loss: 1.4909098148345947
Validation loss: 2.185964360833168

Epoch: 5| Step: 4
Training loss: 1.392907977104187
Validation loss: 2.1920039455095925

Epoch: 5| Step: 5
Training loss: 1.0386488437652588
Validation loss: 2.2024743954340615

Epoch: 5| Step: 6
Training loss: 1.764944076538086
Validation loss: 2.2007259527842202

Epoch: 5| Step: 7
Training loss: 1.1639641523361206
Validation loss: 2.2387206703424454

Epoch: 5| Step: 8
Training loss: 2.211421489715576
Validation loss: 2.183810050288836

Epoch: 5| Step: 9
Training loss: 1.7630802392959595
Validation loss: 2.2160259783267975

Epoch: 5| Step: 10
Training loss: 1.7743523120880127
Validation loss: 2.187240536014239

Epoch: 5| Step: 11
Training loss: 2.5511889457702637
Validation loss: 2.2086869279543557

Epoch: 353| Step: 0
Training loss: 1.7173693180084229
Validation loss: 2.1972094625234604

Epoch: 5| Step: 1
Training loss: 1.942997932434082
Validation loss: 2.192273125052452

Epoch: 5| Step: 2
Training loss: 1.530059576034546
Validation loss: 2.195734699567159

Epoch: 5| Step: 3
Training loss: 0.9502288699150085
Validation loss: 2.224849825104078

Epoch: 5| Step: 4
Training loss: 1.8876798152923584
Validation loss: 2.2096174309651055

Epoch: 5| Step: 5
Training loss: 1.2846930027008057
Validation loss: 2.208181540171305

Epoch: 5| Step: 6
Training loss: 1.7159175872802734
Validation loss: 2.2075808346271515

Epoch: 5| Step: 7
Training loss: 1.8629964590072632
Validation loss: 2.2060840129852295

Epoch: 5| Step: 8
Training loss: 1.7668159008026123
Validation loss: 2.1779222885767617

Epoch: 5| Step: 9
Training loss: 1.1827975511550903
Validation loss: 2.2001633445421853

Epoch: 5| Step: 10
Training loss: 1.6446115970611572
Validation loss: 2.1888217826684317

Epoch: 5| Step: 11
Training loss: 2.2861533164978027
Validation loss: 2.2006753782431283

Epoch: 354| Step: 0
Training loss: 1.2751142978668213
Validation loss: 2.2054749876260757

Epoch: 5| Step: 1
Training loss: 1.5104156732559204
Validation loss: 2.2088488886753717

Epoch: 5| Step: 2
Training loss: 1.6887575387954712
Validation loss: 2.2188672522703805

Epoch: 5| Step: 3
Training loss: 1.501124620437622
Validation loss: 2.203686664501826

Epoch: 5| Step: 4
Training loss: 1.6854798793792725
Validation loss: 2.208157350619634

Epoch: 5| Step: 5
Training loss: 1.9502336978912354
Validation loss: 2.2062624245882034

Epoch: 5| Step: 6
Training loss: 1.3541672229766846
Validation loss: 2.1957397560278573

Epoch: 5| Step: 7
Training loss: 1.167647123336792
Validation loss: 2.2135067085425058

Epoch: 5| Step: 8
Training loss: 1.8904306888580322
Validation loss: 2.2024629712104797

Epoch: 5| Step: 9
Training loss: 1.8270126581192017
Validation loss: 2.238803038994471

Epoch: 5| Step: 10
Training loss: 1.713355302810669
Validation loss: 2.193191925684611

Epoch: 5| Step: 11
Training loss: 0.5170666575431824
Validation loss: 2.2028715908527374

Epoch: 355| Step: 0
Training loss: 1.3805696964263916
Validation loss: 2.180699567000071

Epoch: 5| Step: 1
Training loss: 2.585792303085327
Validation loss: 2.1760655492544174

Epoch: 5| Step: 2
Training loss: 1.2057170867919922
Validation loss: 2.1959228267272315

Epoch: 5| Step: 3
Training loss: 2.0034141540527344
Validation loss: 2.2066119611263275

Epoch: 5| Step: 4
Training loss: 1.768958330154419
Validation loss: 2.2089456717173257

Epoch: 5| Step: 5
Training loss: 1.2708367109298706
Validation loss: 2.180804520845413

Epoch: 5| Step: 6
Training loss: 1.2031173706054688
Validation loss: 2.1726394097010293

Epoch: 5| Step: 7
Training loss: 1.224030613899231
Validation loss: 2.1763596882422767

Epoch: 5| Step: 8
Training loss: 1.5710949897766113
Validation loss: 2.190869693954786

Epoch: 5| Step: 9
Training loss: 1.9056968688964844
Validation loss: 2.184884632627169

Epoch: 5| Step: 10
Training loss: 1.5165812969207764
Validation loss: 2.1804503897825875

Epoch: 5| Step: 11
Training loss: 0.7960624694824219
Validation loss: 2.166021848718325

Epoch: 356| Step: 0
Training loss: 1.0378679037094116
Validation loss: 2.1732643991708755

Epoch: 5| Step: 1
Training loss: 1.380244493484497
Validation loss: 2.19434883693854

Epoch: 5| Step: 2
Training loss: 1.1696134805679321
Validation loss: 2.1467950691779456

Epoch: 5| Step: 3
Training loss: 1.777888536453247
Validation loss: 2.1572824666897454

Epoch: 5| Step: 4
Training loss: 1.6420949697494507
Validation loss: 2.16030453145504

Epoch: 5| Step: 5
Training loss: 2.1070139408111572
Validation loss: 2.182482570409775

Epoch: 5| Step: 6
Training loss: 1.4994595050811768
Validation loss: 2.173796902100245

Epoch: 5| Step: 7
Training loss: 2.0559029579162598
Validation loss: 2.171959231297175

Epoch: 5| Step: 8
Training loss: 1.4138988256454468
Validation loss: 2.17178746064504

Epoch: 5| Step: 9
Training loss: 1.3298819065093994
Validation loss: 2.1551137069861093

Epoch: 5| Step: 10
Training loss: 1.6833858489990234
Validation loss: 2.1973987221717834

Epoch: 5| Step: 11
Training loss: 2.609006404876709
Validation loss: 2.192219610015551

Epoch: 357| Step: 0
Training loss: 1.0951372385025024
Validation loss: 2.2018749912579856

Epoch: 5| Step: 1
Training loss: 1.7756531238555908
Validation loss: 2.1913709541161857

Epoch: 5| Step: 2
Training loss: 2.075685501098633
Validation loss: 2.1931050568819046

Epoch: 5| Step: 3
Training loss: 1.4169301986694336
Validation loss: 2.20746847987175

Epoch: 5| Step: 4
Training loss: 1.3166605234146118
Validation loss: 2.1924281070629754

Epoch: 5| Step: 5
Training loss: 0.9521846771240234
Validation loss: 2.202165812253952

Epoch: 5| Step: 6
Training loss: 2.002584457397461
Validation loss: 2.2075113902489343

Epoch: 5| Step: 7
Training loss: 1.927724838256836
Validation loss: 2.2057121048370996

Epoch: 5| Step: 8
Training loss: 1.571973204612732
Validation loss: 2.1988964527845383

Epoch: 5| Step: 9
Training loss: 1.5215996503829956
Validation loss: 2.215842306613922

Epoch: 5| Step: 10
Training loss: 1.7737808227539062
Validation loss: 2.1926595916350684

Epoch: 5| Step: 11
Training loss: 1.8069612979888916
Validation loss: 2.1949747999509177

Epoch: 358| Step: 0
Training loss: 2.385200023651123
Validation loss: 2.206148554881414

Epoch: 5| Step: 1
Training loss: 1.563240885734558
Validation loss: 2.191261649131775

Epoch: 5| Step: 2
Training loss: 1.541682481765747
Validation loss: 2.2458409667015076

Epoch: 5| Step: 3
Training loss: 2.0930991172790527
Validation loss: 2.2206291059652963

Epoch: 5| Step: 4
Training loss: 1.7289578914642334
Validation loss: 2.2093085845311484

Epoch: 5| Step: 5
Training loss: 1.2415101528167725
Validation loss: 2.2046000212430954

Epoch: 5| Step: 6
Training loss: 1.3996427059173584
Validation loss: 2.2282985746860504

Epoch: 5| Step: 7
Training loss: 1.7075309753417969
Validation loss: 2.2414414286613464

Epoch: 5| Step: 8
Training loss: 1.39763343334198
Validation loss: 2.210481425126394

Epoch: 5| Step: 9
Training loss: 1.4825795888900757
Validation loss: 2.1942636320988336

Epoch: 5| Step: 10
Training loss: 1.3892978429794312
Validation loss: 2.198902984460195

Epoch: 5| Step: 11
Training loss: 0.3856748044490814
Validation loss: 2.2165397703647614

Epoch: 359| Step: 0
Training loss: 1.9967225790023804
Validation loss: 2.2007153977950416

Epoch: 5| Step: 1
Training loss: 1.6094890832901
Validation loss: 2.1933422138293586

Epoch: 5| Step: 2
Training loss: 1.3384053707122803
Validation loss: 2.1903557578722634

Epoch: 5| Step: 3
Training loss: 1.603946328163147
Validation loss: 2.147871101895968

Epoch: 5| Step: 4
Training loss: 1.5066030025482178
Validation loss: 2.1731752355893454

Epoch: 5| Step: 5
Training loss: 1.7576137781143188
Validation loss: 2.194746673107147

Epoch: 5| Step: 6
Training loss: 1.8052114248275757
Validation loss: 2.1998231957356134

Epoch: 5| Step: 7
Training loss: 0.8831270337104797
Validation loss: 2.208203688263893

Epoch: 5| Step: 8
Training loss: 2.115231990814209
Validation loss: 2.201798379421234

Epoch: 5| Step: 9
Training loss: 1.9516903162002563
Validation loss: 2.1991431961456933

Epoch: 5| Step: 10
Training loss: 0.8184612989425659
Validation loss: 2.203177124261856

Epoch: 5| Step: 11
Training loss: 1.6487764120101929
Validation loss: 2.2091274758179984

Epoch: 360| Step: 0
Training loss: 1.7839027643203735
Validation loss: 2.205883026123047

Epoch: 5| Step: 1
Training loss: 1.0746071338653564
Validation loss: 2.2138753732045493

Epoch: 5| Step: 2
Training loss: 1.2077049016952515
Validation loss: 2.180290867884954

Epoch: 5| Step: 3
Training loss: 0.9157170057296753
Validation loss: 2.190757622321447

Epoch: 5| Step: 4
Training loss: 1.5887141227722168
Validation loss: 2.179884890715281

Epoch: 5| Step: 5
Training loss: 1.7241716384887695
Validation loss: 2.17795991897583

Epoch: 5| Step: 6
Training loss: 1.9619220495224
Validation loss: 2.173628012339274

Epoch: 5| Step: 7
Training loss: 1.7629778385162354
Validation loss: 2.1864784161249795

Epoch: 5| Step: 8
Training loss: 1.7948532104492188
Validation loss: 2.201910932858785

Epoch: 5| Step: 9
Training loss: 2.007920503616333
Validation loss: 2.2033936431010566

Epoch: 5| Step: 10
Training loss: 1.0317044258117676
Validation loss: 2.201249524950981

Epoch: 5| Step: 11
Training loss: 2.5531835556030273
Validation loss: 2.188679128885269

Epoch: 361| Step: 0
Training loss: 1.7674729824066162
Validation loss: 2.214782863855362

Epoch: 5| Step: 1
Training loss: 1.1328896284103394
Validation loss: 2.187370518843333

Epoch: 5| Step: 2
Training loss: 2.0325798988342285
Validation loss: 2.2063791751861572

Epoch: 5| Step: 3
Training loss: 2.0275845527648926
Validation loss: 2.2240201234817505

Epoch: 5| Step: 4
Training loss: 1.7618687152862549
Validation loss: 2.207959994673729

Epoch: 5| Step: 5
Training loss: 1.9982112646102905
Validation loss: 2.2371784299612045

Epoch: 5| Step: 6
Training loss: 2.0776824951171875
Validation loss: 2.195195918281873

Epoch: 5| Step: 7
Training loss: 1.38172447681427
Validation loss: 2.1934479027986526

Epoch: 5| Step: 8
Training loss: 1.4519360065460205
Validation loss: 2.179013282060623

Epoch: 5| Step: 9
Training loss: 1.9013383388519287
Validation loss: 2.169060309727987

Epoch: 5| Step: 10
Training loss: 1.3112257719039917
Validation loss: 2.1669810811678567

Epoch: 5| Step: 11
Training loss: 1.347852110862732
Validation loss: 2.167652060588201

Epoch: 362| Step: 0
Training loss: 1.290130853652954
Validation loss: 2.198934257030487

Epoch: 5| Step: 1
Training loss: 2.3893442153930664
Validation loss: 2.1420514384905496

Epoch: 5| Step: 2
Training loss: 1.502140760421753
Validation loss: 2.1565440942843757

Epoch: 5| Step: 3
Training loss: 1.961876630783081
Validation loss: 2.169307698806127

Epoch: 5| Step: 4
Training loss: 1.852171540260315
Validation loss: 2.1710735062758126

Epoch: 5| Step: 5
Training loss: 1.349913239479065
Validation loss: 2.1683656672636666

Epoch: 5| Step: 6
Training loss: 1.3592798709869385
Validation loss: 2.202833150823911

Epoch: 5| Step: 7
Training loss: 1.2558435201644897
Validation loss: 2.1846672693888345

Epoch: 5| Step: 8
Training loss: 1.1126900911331177
Validation loss: 2.177202214797338

Epoch: 5| Step: 9
Training loss: 2.160562038421631
Validation loss: 2.166106348236402

Epoch: 5| Step: 10
Training loss: 1.4668738842010498
Validation loss: 2.1886220226685205

Epoch: 5| Step: 11
Training loss: 0.7356825470924377
Validation loss: 2.1773181358973184

Epoch: 363| Step: 0
Training loss: 0.9103564023971558
Validation loss: 2.184557855129242

Epoch: 5| Step: 1
Training loss: 1.647726058959961
Validation loss: 2.2147631843884787

Epoch: 5| Step: 2
Training loss: 1.554715633392334
Validation loss: 2.197483321030935

Epoch: 5| Step: 3
Training loss: 1.6525942087173462
Validation loss: 2.1876710653305054

Epoch: 5| Step: 4
Training loss: 1.877031683921814
Validation loss: 2.1910418570041656

Epoch: 5| Step: 5
Training loss: 0.7739852666854858
Validation loss: 2.166623363892237

Epoch: 5| Step: 6
Training loss: 2.0113396644592285
Validation loss: 2.1760227382183075

Epoch: 5| Step: 7
Training loss: 1.437718152999878
Validation loss: 2.1899805665016174

Epoch: 5| Step: 8
Training loss: 1.145613431930542
Validation loss: 2.171964858969053

Epoch: 5| Step: 9
Training loss: 2.0415189266204834
Validation loss: 2.1715011099974313

Epoch: 5| Step: 10
Training loss: 2.2850732803344727
Validation loss: 2.18871700266997

Epoch: 5| Step: 11
Training loss: 0.8836016654968262
Validation loss: 2.188867842157682

Epoch: 364| Step: 0
Training loss: 1.3297364711761475
Validation loss: 2.176727811495463

Epoch: 5| Step: 1
Training loss: 1.857414960861206
Validation loss: 2.1934215426445007

Epoch: 5| Step: 2
Training loss: 1.438162922859192
Validation loss: 2.20218226313591

Epoch: 5| Step: 3
Training loss: 1.0816175937652588
Validation loss: 2.2224982182184854

Epoch: 5| Step: 4
Training loss: 1.4413427114486694
Validation loss: 2.2137149025996528

Epoch: 5| Step: 5
Training loss: 1.8620061874389648
Validation loss: 2.220920537908872

Epoch: 5| Step: 6
Training loss: 2.023540496826172
Validation loss: 2.2192811419566474

Epoch: 5| Step: 7
Training loss: 1.6248328685760498
Validation loss: 2.196957300106684

Epoch: 5| Step: 8
Training loss: 1.1881539821624756
Validation loss: 2.2318775057792664

Epoch: 5| Step: 9
Training loss: 2.131692409515381
Validation loss: 2.216309035817782

Epoch: 5| Step: 10
Training loss: 1.246930718421936
Validation loss: 2.2028167446454368

Epoch: 5| Step: 11
Training loss: 1.7058048248291016
Validation loss: 2.206488460302353

Epoch: 365| Step: 0
Training loss: 1.7526090145111084
Validation loss: 2.1833849400281906

Epoch: 5| Step: 1
Training loss: 1.211484670639038
Validation loss: 2.2087088425954184

Epoch: 5| Step: 2
Training loss: 1.7194103002548218
Validation loss: 2.2316717555125556

Epoch: 5| Step: 3
Training loss: 2.0664591789245605
Validation loss: 2.188300207257271

Epoch: 5| Step: 4
Training loss: 1.7432243824005127
Validation loss: 2.1933723787466683

Epoch: 5| Step: 5
Training loss: 1.9731414318084717
Validation loss: 2.171127676963806

Epoch: 5| Step: 6
Training loss: 1.347125768661499
Validation loss: 2.2230447580417

Epoch: 5| Step: 7
Training loss: 1.2061121463775635
Validation loss: 2.2236900627613068

Epoch: 5| Step: 8
Training loss: 1.5098577737808228
Validation loss: 2.2164658308029175

Epoch: 5| Step: 9
Training loss: 1.29066002368927
Validation loss: 2.244147708018621

Epoch: 5| Step: 10
Training loss: 1.585186243057251
Validation loss: 2.234204957882563

Epoch: 5| Step: 11
Training loss: 1.5355958938598633
Validation loss: 2.2354081124067307

Epoch: 366| Step: 0
Training loss: 1.6811615228652954
Validation loss: 2.1894617726405463

Epoch: 5| Step: 1
Training loss: 1.272994041442871
Validation loss: 2.1727936367193856

Epoch: 5| Step: 2
Training loss: 1.694372534751892
Validation loss: 2.182513395945231

Epoch: 5| Step: 3
Training loss: 1.3524898290634155
Validation loss: 2.1930467933416367

Epoch: 5| Step: 4
Training loss: 1.3828898668289185
Validation loss: 2.209994927048683

Epoch: 5| Step: 5
Training loss: 1.3049010038375854
Validation loss: 2.172971790035566

Epoch: 5| Step: 6
Training loss: 1.044180154800415
Validation loss: 2.183485413591067

Epoch: 5| Step: 7
Training loss: 1.7268158197402954
Validation loss: 2.192440445224444

Epoch: 5| Step: 8
Training loss: 2.019118309020996
Validation loss: 2.174517740805944

Epoch: 5| Step: 9
Training loss: 2.523867607116699
Validation loss: 2.168855741620064

Epoch: 5| Step: 10
Training loss: 1.723031759262085
Validation loss: 2.1570573896169662

Epoch: 5| Step: 11
Training loss: 1.3722798824310303
Validation loss: 2.1770930339892707

Epoch: 367| Step: 0
Training loss: 1.5082703828811646
Validation loss: 2.207686886191368

Epoch: 5| Step: 1
Training loss: 1.9404224157333374
Validation loss: 2.182720144589742

Epoch: 5| Step: 2
Training loss: 1.2864325046539307
Validation loss: 2.18799019853274

Epoch: 5| Step: 3
Training loss: 1.2865564823150635
Validation loss: 2.190308079123497

Epoch: 5| Step: 4
Training loss: 1.5155080556869507
Validation loss: 2.1867241114377975

Epoch: 5| Step: 5
Training loss: 1.928674340248108
Validation loss: 2.180222138762474

Epoch: 5| Step: 6
Training loss: 1.515505313873291
Validation loss: 2.1795503348112106

Epoch: 5| Step: 7
Training loss: 1.3948700428009033
Validation loss: 2.1939535985390344

Epoch: 5| Step: 8
Training loss: 1.5129770040512085
Validation loss: 2.176998863617579

Epoch: 5| Step: 9
Training loss: 1.3666530847549438
Validation loss: 2.1982568303743997

Epoch: 5| Step: 10
Training loss: 1.942395567893982
Validation loss: 2.1791964073975882

Epoch: 5| Step: 11
Training loss: 0.7641498446464539
Validation loss: 2.1892047921816506

Epoch: 368| Step: 0
Training loss: 1.9964895248413086
Validation loss: 2.1902403434117637

Epoch: 5| Step: 1
Training loss: 1.3014438152313232
Validation loss: 2.1925137042999268

Epoch: 5| Step: 2
Training loss: 1.2330411672592163
Validation loss: 2.181137333313624

Epoch: 5| Step: 3
Training loss: 0.9191229939460754
Validation loss: 2.186936318874359

Epoch: 5| Step: 4
Training loss: 1.5243550539016724
Validation loss: 2.1902363946040473

Epoch: 5| Step: 5
Training loss: 1.5021013021469116
Validation loss: 2.198725640773773

Epoch: 5| Step: 6
Training loss: 1.6382560729980469
Validation loss: 2.1980114380518594

Epoch: 5| Step: 7
Training loss: 1.683434247970581
Validation loss: 2.195324182510376

Epoch: 5| Step: 8
Training loss: 1.703818917274475
Validation loss: 2.170760636528333

Epoch: 5| Step: 9
Training loss: 1.3662410974502563
Validation loss: 2.194789613286654

Epoch: 5| Step: 10
Training loss: 2.202265977859497
Validation loss: 2.1552388767401376

Epoch: 5| Step: 11
Training loss: 0.9620468020439148
Validation loss: 2.1779043277104697

Epoch: 369| Step: 0
Training loss: 1.464523434638977
Validation loss: 2.186017448703448

Epoch: 5| Step: 1
Training loss: 1.6004936695098877
Validation loss: 2.1921178003152213

Epoch: 5| Step: 2
Training loss: 1.442596197128296
Validation loss: 2.1728183229764304

Epoch: 5| Step: 3
Training loss: 1.9402227401733398
Validation loss: 2.1623956114053726

Epoch: 5| Step: 4
Training loss: 1.2315523624420166
Validation loss: 2.209008405605952

Epoch: 5| Step: 5
Training loss: 1.5751888751983643
Validation loss: 2.1947787453730903

Epoch: 5| Step: 6
Training loss: 1.4198437929153442
Validation loss: 2.1833789199590683

Epoch: 5| Step: 7
Training loss: 1.589876413345337
Validation loss: 2.1859039862950644

Epoch: 5| Step: 8
Training loss: 0.8495247960090637
Validation loss: 2.2001998275518417

Epoch: 5| Step: 9
Training loss: 1.7297852039337158
Validation loss: 2.186795011162758

Epoch: 5| Step: 10
Training loss: 1.613516092300415
Validation loss: 2.1829826682806015

Epoch: 5| Step: 11
Training loss: 2.0012521743774414
Validation loss: 2.194552426536878

Epoch: 370| Step: 0
Training loss: 1.9258739948272705
Validation loss: 2.172874296704928

Epoch: 5| Step: 1
Training loss: 1.1616590023040771
Validation loss: 2.2023156682650247

Epoch: 5| Step: 2
Training loss: 1.3678280115127563
Validation loss: 2.1894961396853128

Epoch: 5| Step: 3
Training loss: 1.7467857599258423
Validation loss: 2.183604508638382

Epoch: 5| Step: 4
Training loss: 1.6513545513153076
Validation loss: 2.168122097849846

Epoch: 5| Step: 5
Training loss: 1.6427793502807617
Validation loss: 2.1693815837303796

Epoch: 5| Step: 6
Training loss: 1.5054839849472046
Validation loss: 2.171427766482035

Epoch: 5| Step: 7
Training loss: 1.117520809173584
Validation loss: 2.190427223841349

Epoch: 5| Step: 8
Training loss: 1.4742728471755981
Validation loss: 2.2086572845776877

Epoch: 5| Step: 9
Training loss: 1.8732223510742188
Validation loss: 2.2092972497145333

Epoch: 5| Step: 10
Training loss: 1.7101894617080688
Validation loss: 2.1958268086115518

Epoch: 5| Step: 11
Training loss: 1.3610641956329346
Validation loss: 2.179287920395533

Epoch: 371| Step: 0
Training loss: 1.6509950160980225
Validation loss: 2.1926122506459556

Epoch: 5| Step: 1
Training loss: 1.5691877603530884
Validation loss: 2.188437898953756

Epoch: 5| Step: 2
Training loss: 1.6098527908325195
Validation loss: 2.205262298385302

Epoch: 5| Step: 3
Training loss: 1.6396281719207764
Validation loss: 2.169358273347219

Epoch: 5| Step: 4
Training loss: 1.3238064050674438
Validation loss: 2.179609845081965

Epoch: 5| Step: 5
Training loss: 1.580457329750061
Validation loss: 2.1749329566955566

Epoch: 5| Step: 6
Training loss: 1.6385717391967773
Validation loss: 2.180401772260666

Epoch: 5| Step: 7
Training loss: 1.1293773651123047
Validation loss: 2.1998446881771088

Epoch: 5| Step: 8
Training loss: 1.7053200006484985
Validation loss: 2.1899257004261017

Epoch: 5| Step: 9
Training loss: 1.381151556968689
Validation loss: 2.19014410674572

Epoch: 5| Step: 10
Training loss: 1.407597303390503
Validation loss: 2.193490872780482

Epoch: 5| Step: 11
Training loss: 2.8088343143463135
Validation loss: 2.1712783873081207

Epoch: 372| Step: 0
Training loss: 1.6467256546020508
Validation loss: 2.158506100376447

Epoch: 5| Step: 1
Training loss: 1.506565809249878
Validation loss: 2.181397000948588

Epoch: 5| Step: 2
Training loss: 0.8850783109664917
Validation loss: 2.1789664228757224

Epoch: 5| Step: 3
Training loss: 1.3208258152008057
Validation loss: 2.1843068252007165

Epoch: 5| Step: 4
Training loss: 0.8413902521133423
Validation loss: 2.175338144103686

Epoch: 5| Step: 5
Training loss: 1.9144103527069092
Validation loss: 2.1696492582559586

Epoch: 5| Step: 6
Training loss: 1.4601943492889404
Validation loss: 2.136882255474726

Epoch: 5| Step: 7
Training loss: 2.030104398727417
Validation loss: 2.1930586944023767

Epoch: 5| Step: 8
Training loss: 1.5341079235076904
Validation loss: 2.1790994505087533

Epoch: 5| Step: 9
Training loss: 1.589113473892212
Validation loss: 2.1620301604270935

Epoch: 5| Step: 10
Training loss: 1.8390142917633057
Validation loss: 2.157264292240143

Epoch: 5| Step: 11
Training loss: 1.8206117153167725
Validation loss: 2.144928604364395

Epoch: 373| Step: 0
Training loss: 1.0118924379348755
Validation loss: 2.1542669037977853

Epoch: 5| Step: 1
Training loss: 1.5443419218063354
Validation loss: 2.1798450648784637

Epoch: 5| Step: 2
Training loss: 1.6631923913955688
Validation loss: 2.150466412305832

Epoch: 5| Step: 3
Training loss: 1.5935250520706177
Validation loss: 2.165038973093033

Epoch: 5| Step: 4
Training loss: 1.8102216720581055
Validation loss: 2.1802866458892822

Epoch: 5| Step: 5
Training loss: 1.4175682067871094
Validation loss: 2.1638332903385162

Epoch: 5| Step: 6
Training loss: 1.3049211502075195
Validation loss: 2.168813501795133

Epoch: 5| Step: 7
Training loss: 1.4712235927581787
Validation loss: 2.166489894191424

Epoch: 5| Step: 8
Training loss: 1.8109996318817139
Validation loss: 2.174147516489029

Epoch: 5| Step: 9
Training loss: 1.587137222290039
Validation loss: 2.1872702638308206

Epoch: 5| Step: 10
Training loss: 1.6393499374389648
Validation loss: 2.164607286453247

Epoch: 5| Step: 11
Training loss: 0.387115478515625
Validation loss: 2.178824787338575

Epoch: 374| Step: 0
Training loss: 2.1130831241607666
Validation loss: 2.1841775476932526

Epoch: 5| Step: 1
Training loss: 1.648868203163147
Validation loss: 2.1791625320911407

Epoch: 5| Step: 2
Training loss: 1.2906553745269775
Validation loss: 2.1933543533086777

Epoch: 5| Step: 3
Training loss: 1.3265998363494873
Validation loss: 2.176056742668152

Epoch: 5| Step: 4
Training loss: 0.6490586400032043
Validation loss: 2.1961775720119476

Epoch: 5| Step: 5
Training loss: 1.0800795555114746
Validation loss: 2.1888709465662637

Epoch: 5| Step: 6
Training loss: 1.6233294010162354
Validation loss: 2.1977922717730203

Epoch: 5| Step: 7
Training loss: 1.6060972213745117
Validation loss: 2.184350530306498

Epoch: 5| Step: 8
Training loss: 0.8677383661270142
Validation loss: 2.1824254790941873

Epoch: 5| Step: 9
Training loss: 1.5918972492218018
Validation loss: 2.2070667147636414

Epoch: 5| Step: 10
Training loss: 2.2474284172058105
Validation loss: 2.1916850159565606

Epoch: 5| Step: 11
Training loss: 2.386723279953003
Validation loss: 2.171887238820394

Epoch: 375| Step: 0
Training loss: 1.1852641105651855
Validation loss: 2.1779483457406363

Epoch: 5| Step: 1
Training loss: 1.723855972290039
Validation loss: 2.1704366703828177

Epoch: 5| Step: 2
Training loss: 1.8940738439559937
Validation loss: 2.166682874162992

Epoch: 5| Step: 3
Training loss: 2.042933464050293
Validation loss: 2.194721668958664

Epoch: 5| Step: 4
Training loss: 1.934038519859314
Validation loss: 2.171387473742167

Epoch: 5| Step: 5
Training loss: 1.7482318878173828
Validation loss: 2.1940521548191705

Epoch: 5| Step: 6
Training loss: 1.3678770065307617
Validation loss: 2.150332267085711

Epoch: 5| Step: 7
Training loss: 1.3949613571166992
Validation loss: 2.17154731353124

Epoch: 5| Step: 8
Training loss: 1.1335707902908325
Validation loss: 2.161509176095327

Epoch: 5| Step: 9
Training loss: 1.975172996520996
Validation loss: 2.189433674017588

Epoch: 5| Step: 10
Training loss: 1.150054931640625
Validation loss: 2.1691274841626487

Epoch: 5| Step: 11
Training loss: 0.8796126842498779
Validation loss: 2.217838376760483

Epoch: 376| Step: 0
Training loss: 2.3136606216430664
Validation loss: 2.1929545203844705

Epoch: 5| Step: 1
Training loss: 1.6761690378189087
Validation loss: 2.18183633685112

Epoch: 5| Step: 2
Training loss: 1.2277991771697998
Validation loss: 2.177872876326243

Epoch: 5| Step: 3
Training loss: 1.2171480655670166
Validation loss: 2.195929447809855

Epoch: 5| Step: 4
Training loss: 1.9673900604248047
Validation loss: 2.21005587776502

Epoch: 5| Step: 5
Training loss: 0.9230786561965942
Validation loss: 2.2186214874188104

Epoch: 5| Step: 6
Training loss: 1.8136186599731445
Validation loss: 2.187407299876213

Epoch: 5| Step: 7
Training loss: 1.5108977556228638
Validation loss: 2.1924177209536233

Epoch: 5| Step: 8
Training loss: 1.0786879062652588
Validation loss: 2.19816155731678

Epoch: 5| Step: 9
Training loss: 2.000986337661743
Validation loss: 2.204223225514094

Epoch: 5| Step: 10
Training loss: 1.277184247970581
Validation loss: 2.2055695007244744

Epoch: 5| Step: 11
Training loss: 0.8271082639694214
Validation loss: 2.208331381281217

Epoch: 377| Step: 0
Training loss: 1.9111381769180298
Validation loss: 2.218846932053566

Epoch: 5| Step: 1
Training loss: 1.4361486434936523
Validation loss: 2.2231901784737906

Epoch: 5| Step: 2
Training loss: 1.365588665008545
Validation loss: 2.2165342370669046

Epoch: 5| Step: 3
Training loss: 1.691241979598999
Validation loss: 2.214849124352137

Epoch: 5| Step: 4
Training loss: 1.425601601600647
Validation loss: 2.211313416560491

Epoch: 5| Step: 5
Training loss: 2.1081950664520264
Validation loss: 2.2082128624121347

Epoch: 5| Step: 6
Training loss: 1.0713491439819336
Validation loss: 2.2207181056340537

Epoch: 5| Step: 7
Training loss: 2.1678075790405273
Validation loss: 2.233477478226026

Epoch: 5| Step: 8
Training loss: 1.0697829723358154
Validation loss: 2.2450133860111237

Epoch: 5| Step: 9
Training loss: 1.6871974468231201
Validation loss: 2.243054062128067

Epoch: 5| Step: 10
Training loss: 1.0535532236099243
Validation loss: 2.2244056512912116

Epoch: 5| Step: 11
Training loss: 0.5269839763641357
Validation loss: 2.2017159362634025

Epoch: 378| Step: 0
Training loss: 1.440882921218872
Validation loss: 2.1975673784812293

Epoch: 5| Step: 1
Training loss: 1.010384440422058
Validation loss: 2.2105181167523065

Epoch: 5| Step: 2
Training loss: 1.4180219173431396
Validation loss: 2.2098113894462585

Epoch: 5| Step: 3
Training loss: 2.336211681365967
Validation loss: 2.2451127767562866

Epoch: 5| Step: 4
Training loss: 1.6976115703582764
Validation loss: 2.1996653427680335

Epoch: 5| Step: 5
Training loss: 1.2312073707580566
Validation loss: 2.2074688325325647

Epoch: 5| Step: 6
Training loss: 1.029853105545044
Validation loss: 2.208463509877523

Epoch: 5| Step: 7
Training loss: 2.169508934020996
Validation loss: 2.220611115296682

Epoch: 5| Step: 8
Training loss: 1.2987667322158813
Validation loss: 2.2187184939781823

Epoch: 5| Step: 9
Training loss: 1.4216761589050293
Validation loss: 2.208572750290235

Epoch: 5| Step: 10
Training loss: 1.320639729499817
Validation loss: 2.2023159911235175

Epoch: 5| Step: 11
Training loss: 1.0942697525024414
Validation loss: 2.2229943374792733

Epoch: 379| Step: 0
Training loss: 1.7158918380737305
Validation loss: 2.2259069929520288

Epoch: 5| Step: 1
Training loss: 1.2541526556015015
Validation loss: 2.203737129767736

Epoch: 5| Step: 2
Training loss: 1.5858654975891113
Validation loss: 2.2146238485972085

Epoch: 5| Step: 3
Training loss: 1.6146621704101562
Validation loss: 2.1763957689205804

Epoch: 5| Step: 4
Training loss: 1.4676274061203003
Validation loss: 2.1901283214489617

Epoch: 5| Step: 5
Training loss: 1.3497021198272705
Validation loss: 2.1941973765691123

Epoch: 5| Step: 6
Training loss: 1.514221429824829
Validation loss: 2.1895603040854135

Epoch: 5| Step: 7
Training loss: 1.5652085542678833
Validation loss: 2.1846806605656943

Epoch: 5| Step: 8
Training loss: 1.2395471334457397
Validation loss: 2.1936839818954468

Epoch: 5| Step: 9
Training loss: 1.755904197692871
Validation loss: 2.2127261261145272

Epoch: 5| Step: 10
Training loss: 1.0441787242889404
Validation loss: 2.180311550696691

Epoch: 5| Step: 11
Training loss: 1.4489089250564575
Validation loss: 2.1971151381731033

Epoch: 380| Step: 0
Training loss: 1.8434336185455322
Validation loss: 2.179747020204862

Epoch: 5| Step: 1
Training loss: 1.524572730064392
Validation loss: 2.1939752300580344

Epoch: 5| Step: 2
Training loss: 1.3361393213272095
Validation loss: 2.192405258615812

Epoch: 5| Step: 3
Training loss: 1.9796860218048096
Validation loss: 2.21277125676473

Epoch: 5| Step: 4
Training loss: 1.805641531944275
Validation loss: 2.221681162714958

Epoch: 5| Step: 5
Training loss: 0.8503113985061646
Validation loss: 2.2009352644284568

Epoch: 5| Step: 6
Training loss: 1.135796070098877
Validation loss: 2.2293059130509696

Epoch: 5| Step: 7
Training loss: 1.7183758020401
Validation loss: 2.213222106297811

Epoch: 5| Step: 8
Training loss: 1.5378042459487915
Validation loss: 2.2087434430917106

Epoch: 5| Step: 9
Training loss: 1.4073083400726318
Validation loss: 2.218489110469818

Epoch: 5| Step: 10
Training loss: 1.0694146156311035
Validation loss: 2.2152454257011414

Epoch: 5| Step: 11
Training loss: 2.0292837619781494
Validation loss: 2.251555939515432

Epoch: 381| Step: 0
Training loss: 1.2974904775619507
Validation loss: 2.1981345812479653

Epoch: 5| Step: 1
Training loss: 1.325730562210083
Validation loss: 2.227862591544787

Epoch: 5| Step: 2
Training loss: 1.5995252132415771
Validation loss: 2.213738520940145

Epoch: 5| Step: 3
Training loss: 1.5364930629730225
Validation loss: 2.1940095275640488

Epoch: 5| Step: 4
Training loss: 0.8087989687919617
Validation loss: 2.1593877921501794

Epoch: 5| Step: 5
Training loss: 1.729949951171875
Validation loss: 2.1726798911889396

Epoch: 5| Step: 6
Training loss: 1.175987720489502
Validation loss: 2.1523706167936325

Epoch: 5| Step: 7
Training loss: 1.4818856716156006
Validation loss: 2.1911252637704215

Epoch: 5| Step: 8
Training loss: 1.3549134731292725
Validation loss: 2.1494301507870355

Epoch: 5| Step: 9
Training loss: 1.9323656558990479
Validation loss: 2.1541382173697152

Epoch: 5| Step: 10
Training loss: 2.10810923576355
Validation loss: 2.225199207663536

Epoch: 5| Step: 11
Training loss: 1.3096699714660645
Validation loss: 2.173516352971395

Epoch: 382| Step: 0
Training loss: 1.4383046627044678
Validation loss: 2.2100709974765778

Epoch: 5| Step: 1
Training loss: 1.6112092733383179
Validation loss: 2.2079469859600067

Epoch: 5| Step: 2
Training loss: 1.5543200969696045
Validation loss: 2.2075204153855643

Epoch: 5| Step: 3
Training loss: 1.5783857107162476
Validation loss: 2.244107405344645

Epoch: 5| Step: 4
Training loss: 1.690866470336914
Validation loss: 2.2469361275434494

Epoch: 5| Step: 5
Training loss: 0.9723516702651978
Validation loss: 2.2010238567988076

Epoch: 5| Step: 6
Training loss: 1.7847461700439453
Validation loss: 2.2059442649284997

Epoch: 5| Step: 7
Training loss: 1.3359088897705078
Validation loss: 2.192217101653417

Epoch: 5| Step: 8
Training loss: 1.5264619588851929
Validation loss: 2.204256763060888

Epoch: 5| Step: 9
Training loss: 1.5351053476333618
Validation loss: 2.1964555929104486

Epoch: 5| Step: 10
Training loss: 1.714250922203064
Validation loss: 2.188034941752752

Epoch: 5| Step: 11
Training loss: 0.5056642889976501
Validation loss: 2.174071172873179

Epoch: 383| Step: 0
Training loss: 1.2814997434616089
Validation loss: 2.173729141553243

Epoch: 5| Step: 1
Training loss: 1.5186541080474854
Validation loss: 2.2051625649134317

Epoch: 5| Step: 2
Training loss: 1.059607982635498
Validation loss: 2.1866134802500405

Epoch: 5| Step: 3
Training loss: 1.5588819980621338
Validation loss: 2.210529794295629

Epoch: 5| Step: 4
Training loss: 2.162235736846924
Validation loss: 2.1916382362445197

Epoch: 5| Step: 5
Training loss: 1.2624895572662354
Validation loss: 2.200143739581108

Epoch: 5| Step: 6
Training loss: 1.7763980627059937
Validation loss: 2.2100426057974496

Epoch: 5| Step: 7
Training loss: 1.2094013690948486
Validation loss: 2.234676872690519

Epoch: 5| Step: 8
Training loss: 1.3457918167114258
Validation loss: 2.1828788618246713

Epoch: 5| Step: 9
Training loss: 1.7701514959335327
Validation loss: 2.2039117763439813

Epoch: 5| Step: 10
Training loss: 0.8396676778793335
Validation loss: 2.1827552864948907

Epoch: 5| Step: 11
Training loss: 2.384401321411133
Validation loss: 2.1619372069835663

Epoch: 384| Step: 0
Training loss: 1.0839385986328125
Validation loss: 2.1459015607833862

Epoch: 5| Step: 1
Training loss: 1.2943588495254517
Validation loss: 2.1506315569082894

Epoch: 5| Step: 2
Training loss: 1.4167531728744507
Validation loss: 2.15405435860157

Epoch: 5| Step: 3
Training loss: 1.5433422327041626
Validation loss: 2.1413526783386865

Epoch: 5| Step: 4
Training loss: 1.1582810878753662
Validation loss: 2.142161895831426

Epoch: 5| Step: 5
Training loss: 1.4914389848709106
Validation loss: 2.1474242955446243

Epoch: 5| Step: 6
Training loss: 0.9459763765335083
Validation loss: 2.15475827952226

Epoch: 5| Step: 7
Training loss: 1.9433447122573853
Validation loss: 2.1677552511294684

Epoch: 5| Step: 8
Training loss: 1.9011948108673096
Validation loss: 2.183353235324224

Epoch: 5| Step: 9
Training loss: 2.138017177581787
Validation loss: 2.1899140179157257

Epoch: 5| Step: 10
Training loss: 1.7020599842071533
Validation loss: 2.164270227154096

Epoch: 5| Step: 11
Training loss: 1.9413505792617798
Validation loss: 2.1715820829073587

Epoch: 385| Step: 0
Training loss: 1.8379710912704468
Validation loss: 2.1450740645329156

Epoch: 5| Step: 1
Training loss: 1.7857029438018799
Validation loss: 2.1445228854815164

Epoch: 5| Step: 2
Training loss: 1.3170171976089478
Validation loss: 2.1650776863098145

Epoch: 5| Step: 3
Training loss: 1.7432819604873657
Validation loss: 2.1342051724592843

Epoch: 5| Step: 4
Training loss: 1.4970195293426514
Validation loss: 2.1180180509885154

Epoch: 5| Step: 5
Training loss: 1.1679933071136475
Validation loss: 2.1271278709173203

Epoch: 5| Step: 6
Training loss: 1.3249428272247314
Validation loss: 2.134042516350746

Epoch: 5| Step: 7
Training loss: 1.9658225774765015
Validation loss: 2.1271662563085556

Epoch: 5| Step: 8
Training loss: 1.4646543264389038
Validation loss: 2.1313333809375763

Epoch: 5| Step: 9
Training loss: 0.9479702115058899
Validation loss: 2.1563945213953652

Epoch: 5| Step: 10
Training loss: 1.72780442237854
Validation loss: 2.128094802300135

Epoch: 5| Step: 11
Training loss: 1.449540615081787
Validation loss: 2.147544433673223

Epoch: 386| Step: 0
Training loss: 0.8009915351867676
Validation loss: 2.1605011969804764

Epoch: 5| Step: 1
Training loss: 1.1688350439071655
Validation loss: 2.1458532015482583

Epoch: 5| Step: 2
Training loss: 1.5476369857788086
Validation loss: 2.146324316660563

Epoch: 5| Step: 3
Training loss: 1.7005201578140259
Validation loss: 2.174388751387596

Epoch: 5| Step: 4
Training loss: 2.5442605018615723
Validation loss: 2.195582389831543

Epoch: 5| Step: 5
Training loss: 1.2211730480194092
Validation loss: 2.191383590300878

Epoch: 5| Step: 6
Training loss: 1.6248239278793335
Validation loss: 2.1970887879530587

Epoch: 5| Step: 7
Training loss: 0.9626103639602661
Validation loss: 2.2154638220866523

Epoch: 5| Step: 8
Training loss: 1.6515315771102905
Validation loss: 2.2255823612213135

Epoch: 5| Step: 9
Training loss: 1.471252202987671
Validation loss: 2.2261613408724465

Epoch: 5| Step: 10
Training loss: 2.204491138458252
Validation loss: 2.2201780726512275

Epoch: 5| Step: 11
Training loss: 0.5860278606414795
Validation loss: 2.199336518843969

Epoch: 387| Step: 0
Training loss: 1.144344687461853
Validation loss: 2.229006379842758

Epoch: 5| Step: 1
Training loss: 1.1511017084121704
Validation loss: 2.2218717137972512

Epoch: 5| Step: 2
Training loss: 1.5672839879989624
Validation loss: 2.2202597806851068

Epoch: 5| Step: 3
Training loss: 1.5634450912475586
Validation loss: 2.2238401770591736

Epoch: 5| Step: 4
Training loss: 1.7375895977020264
Validation loss: 2.2194145967562995

Epoch: 5| Step: 5
Training loss: 1.6953914165496826
Validation loss: 2.214058975378672

Epoch: 5| Step: 6
Training loss: 1.506042242050171
Validation loss: 2.206968143582344

Epoch: 5| Step: 7
Training loss: 1.5909779071807861
Validation loss: 2.2373838424682617

Epoch: 5| Step: 8
Training loss: 1.2798984050750732
Validation loss: 2.214887489875158

Epoch: 5| Step: 9
Training loss: 1.0866622924804688
Validation loss: 2.221264526247978

Epoch: 5| Step: 10
Training loss: 1.6725623607635498
Validation loss: 2.2296436776717505

Epoch: 5| Step: 11
Training loss: 1.5153510570526123
Validation loss: 2.1934181253115335

Epoch: 388| Step: 0
Training loss: 1.820002555847168
Validation loss: 2.2004210452238717

Epoch: 5| Step: 1
Training loss: 1.5731091499328613
Validation loss: 2.1767788032690683

Epoch: 5| Step: 2
Training loss: 2.1044275760650635
Validation loss: 2.229023963212967

Epoch: 5| Step: 3
Training loss: 1.491163969039917
Validation loss: 2.219369242588679

Epoch: 5| Step: 4
Training loss: 1.1777375936508179
Validation loss: 2.2258820037047067

Epoch: 5| Step: 5
Training loss: 1.1621195077896118
Validation loss: 2.249358187119166

Epoch: 5| Step: 6
Training loss: 1.408880352973938
Validation loss: 2.1971639494101205

Epoch: 5| Step: 7
Training loss: 1.6268422603607178
Validation loss: 2.2008588264385858

Epoch: 5| Step: 8
Training loss: 1.3576810359954834
Validation loss: 2.188758542140325

Epoch: 5| Step: 9
Training loss: 0.8692417144775391
Validation loss: 2.165585681796074

Epoch: 5| Step: 10
Training loss: 1.4909656047821045
Validation loss: 2.18379670381546

Epoch: 5| Step: 11
Training loss: 1.7390828132629395
Validation loss: 2.1585279603799186

Epoch: 389| Step: 0
Training loss: 1.3182313442230225
Validation loss: 2.1520238469044366

Epoch: 5| Step: 1
Training loss: 1.2680898904800415
Validation loss: 2.180173233151436

Epoch: 5| Step: 2
Training loss: 1.2571680545806885
Validation loss: 2.187686577439308

Epoch: 5| Step: 3
Training loss: 1.716853141784668
Validation loss: 2.180225193500519

Epoch: 5| Step: 4
Training loss: 1.3123819828033447
Validation loss: 2.1402409921089807

Epoch: 5| Step: 5
Training loss: 1.5518707036972046
Validation loss: 2.166711817185084

Epoch: 5| Step: 6
Training loss: 2.001147747039795
Validation loss: 2.1647864629824958

Epoch: 5| Step: 7
Training loss: 1.640600562095642
Validation loss: 2.1217987537384033

Epoch: 5| Step: 8
Training loss: 2.2862956523895264
Validation loss: 2.1647000958522162

Epoch: 5| Step: 9
Training loss: 1.5656214952468872
Validation loss: 2.189240043361982

Epoch: 5| Step: 10
Training loss: 1.2687588930130005
Validation loss: 2.200014034907023

Epoch: 5| Step: 11
Training loss: 0.8175017833709717
Validation loss: 2.162467271089554

Epoch: 390| Step: 0
Training loss: 1.8833106756210327
Validation loss: 2.129090264439583

Epoch: 5| Step: 1
Training loss: 2.048398733139038
Validation loss: 2.1665306836366653

Epoch: 5| Step: 2
Training loss: 1.2403357028961182
Validation loss: 2.1418953239917755

Epoch: 5| Step: 3
Training loss: 1.511979341506958
Validation loss: 2.167718713482221

Epoch: 5| Step: 4
Training loss: 1.8237444162368774
Validation loss: 2.1455555061499276

Epoch: 5| Step: 5
Training loss: 1.4322150945663452
Validation loss: 2.1694789280494056

Epoch: 5| Step: 6
Training loss: 1.1061185598373413
Validation loss: 2.15866427620252

Epoch: 5| Step: 7
Training loss: 1.3149898052215576
Validation loss: 2.1701843589544296

Epoch: 5| Step: 8
Training loss: 1.3196316957473755
Validation loss: 2.2051391700903573

Epoch: 5| Step: 9
Training loss: 1.4014790058135986
Validation loss: 2.2034069945414863

Epoch: 5| Step: 10
Training loss: 1.687374472618103
Validation loss: 2.1851392636696496

Epoch: 5| Step: 11
Training loss: 1.1561298370361328
Validation loss: 2.215206265449524

Epoch: 391| Step: 0
Training loss: 1.3338708877563477
Validation loss: 2.2012155950069427

Epoch: 5| Step: 1
Training loss: 1.6135146617889404
Validation loss: 2.179991697271665

Epoch: 5| Step: 2
Training loss: 1.5379812717437744
Validation loss: 2.1910231709480286

Epoch: 5| Step: 3
Training loss: 1.6003469228744507
Validation loss: 2.2012482285499573

Epoch: 5| Step: 4
Training loss: 1.8019109964370728
Validation loss: 2.1917253931363425

Epoch: 5| Step: 5
Training loss: 1.2704025506973267
Validation loss: 2.1631298760573068

Epoch: 5| Step: 6
Training loss: 1.8159233331680298
Validation loss: 2.1846043467521667

Epoch: 5| Step: 7
Training loss: 0.9061222076416016
Validation loss: 2.1514676610628762

Epoch: 5| Step: 8
Training loss: 1.2446651458740234
Validation loss: 2.1433455497026443

Epoch: 5| Step: 9
Training loss: 0.9908512830734253
Validation loss: 2.159244184692701

Epoch: 5| Step: 10
Training loss: 1.633183479309082
Validation loss: 2.1606385310490928

Epoch: 5| Step: 11
Training loss: 2.5004236698150635
Validation loss: 2.1647844264904657

Epoch: 392| Step: 0
Training loss: 2.069129228591919
Validation loss: 2.1359443167845407

Epoch: 5| Step: 1
Training loss: 1.648044228553772
Validation loss: 2.157827228307724

Epoch: 5| Step: 2
Training loss: 1.4724323749542236
Validation loss: 2.135697697599729

Epoch: 5| Step: 3
Training loss: 0.9814192056655884
Validation loss: 2.1767814507087073

Epoch: 5| Step: 4
Training loss: 1.2790114879608154
Validation loss: 2.182534704605738

Epoch: 5| Step: 5
Training loss: 1.6699440479278564
Validation loss: 2.164574791987737

Epoch: 5| Step: 6
Training loss: 1.347375512123108
Validation loss: 2.1747131695350013

Epoch: 5| Step: 7
Training loss: 1.0064165592193604
Validation loss: 2.1876902480920157

Epoch: 5| Step: 8
Training loss: 1.4804056882858276
Validation loss: 2.169768532117208

Epoch: 5| Step: 9
Training loss: 1.4440147876739502
Validation loss: 2.1704143236080804

Epoch: 5| Step: 10
Training loss: 1.4307000637054443
Validation loss: 2.195298199852308

Epoch: 5| Step: 11
Training loss: 1.004631757736206
Validation loss: 2.189544916152954

Epoch: 393| Step: 0
Training loss: 1.4288043975830078
Validation loss: 2.2010424832503

Epoch: 5| Step: 1
Training loss: 1.8522908687591553
Validation loss: 2.201753447453181

Epoch: 5| Step: 2
Training loss: 1.5889021158218384
Validation loss: 2.187944541374842

Epoch: 5| Step: 3
Training loss: 1.3317230939865112
Validation loss: 2.1984797219435372

Epoch: 5| Step: 4
Training loss: 1.4240267276763916
Validation loss: 2.189735621213913

Epoch: 5| Step: 5
Training loss: 1.374868631362915
Validation loss: 2.1809229850769043

Epoch: 5| Step: 6
Training loss: 1.435518503189087
Validation loss: 2.1613644460837045

Epoch: 5| Step: 7
Training loss: 1.4773914813995361
Validation loss: 2.165199170509974

Epoch: 5| Step: 8
Training loss: 1.2289714813232422
Validation loss: 2.1663268407185874

Epoch: 5| Step: 9
Training loss: 1.25453782081604
Validation loss: 2.196094905336698

Epoch: 5| Step: 10
Training loss: 1.2231204509735107
Validation loss: 2.20472684999307

Epoch: 5| Step: 11
Training loss: 1.5207706689834595
Validation loss: 2.192328835527102

Epoch: 394| Step: 0
Training loss: 1.7389179468154907
Validation loss: 2.1765217880407968

Epoch: 5| Step: 1
Training loss: 1.94586980342865
Validation loss: 2.2416232228279114

Epoch: 5| Step: 2
Training loss: 1.3751901388168335
Validation loss: 2.227969934542974

Epoch: 5| Step: 3
Training loss: 1.179559588432312
Validation loss: 2.2437663773695626

Epoch: 5| Step: 4
Training loss: 1.486556887626648
Validation loss: 2.231590360403061

Epoch: 5| Step: 5
Training loss: 1.2435872554779053
Validation loss: 2.209249809384346

Epoch: 5| Step: 6
Training loss: 1.2493938207626343
Validation loss: 2.2119829257329306

Epoch: 5| Step: 7
Training loss: 1.615370750427246
Validation loss: 2.185816446940104

Epoch: 5| Step: 8
Training loss: 1.7962833642959595
Validation loss: 2.1865958174069724

Epoch: 5| Step: 9
Training loss: 1.791020393371582
Validation loss: 2.215526590744654

Epoch: 5| Step: 10
Training loss: 1.4254977703094482
Validation loss: 2.194212550918261

Epoch: 5| Step: 11
Training loss: 1.243402123451233
Validation loss: 2.2096593181292215

Epoch: 395| Step: 0
Training loss: 1.6157077550888062
Validation loss: 2.221982921163241

Epoch: 5| Step: 1
Training loss: 2.018857002258301
Validation loss: 2.228322813908259

Epoch: 5| Step: 2
Training loss: 0.7575724720954895
Validation loss: 2.204164614280065

Epoch: 5| Step: 3
Training loss: 1.9146476984024048
Validation loss: 2.2134973108768463

Epoch: 5| Step: 4
Training loss: 1.7450586557388306
Validation loss: 2.202622522910436

Epoch: 5| Step: 5
Training loss: 1.5255370140075684
Validation loss: 2.2036098490158715

Epoch: 5| Step: 6
Training loss: 1.123079538345337
Validation loss: 2.1910951733589172

Epoch: 5| Step: 7
Training loss: 1.466421365737915
Validation loss: 2.2233447382847467

Epoch: 5| Step: 8
Training loss: 2.0712995529174805
Validation loss: 2.1932580272356668

Epoch: 5| Step: 9
Training loss: 1.7510664463043213
Validation loss: 2.1738597253958383

Epoch: 5| Step: 10
Training loss: 1.6713371276855469
Validation loss: 2.194448937972387

Epoch: 5| Step: 11
Training loss: 1.7980729341506958
Validation loss: 2.2057816485563913

Epoch: 396| Step: 0
Training loss: 1.6968284845352173
Validation loss: 2.1796452701091766

Epoch: 5| Step: 1
Training loss: 1.3911511898040771
Validation loss: 2.202232375741005

Epoch: 5| Step: 2
Training loss: 1.3297338485717773
Validation loss: 2.185939133167267

Epoch: 5| Step: 3
Training loss: 1.8565032482147217
Validation loss: 2.209204206864039

Epoch: 5| Step: 4
Training loss: 1.6380583047866821
Validation loss: 2.218605101108551

Epoch: 5| Step: 5
Training loss: 1.163149118423462
Validation loss: 2.197771434982618

Epoch: 5| Step: 6
Training loss: 1.6413545608520508
Validation loss: 2.1852061649163566

Epoch: 5| Step: 7
Training loss: 1.0377651453018188
Validation loss: 2.2002747853597007

Epoch: 5| Step: 8
Training loss: 1.444060206413269
Validation loss: 2.1686890572309494

Epoch: 5| Step: 9
Training loss: 1.5703411102294922
Validation loss: 2.1869449665149054

Epoch: 5| Step: 10
Training loss: 1.3601442575454712
Validation loss: 2.1664962569872537

Epoch: 5| Step: 11
Training loss: 1.884700894355774
Validation loss: 2.1742467830578485

Epoch: 397| Step: 0
Training loss: 1.4668201208114624
Validation loss: 2.1781742026408515

Epoch: 5| Step: 1
Training loss: 1.5436103343963623
Validation loss: 2.17229101061821

Epoch: 5| Step: 2
Training loss: 1.2605210542678833
Validation loss: 2.179566413164139

Epoch: 5| Step: 3
Training loss: 1.6326210498809814
Validation loss: 2.1669067641099296

Epoch: 5| Step: 4
Training loss: 1.3928086757659912
Validation loss: 2.192260980606079

Epoch: 5| Step: 5
Training loss: 0.94831782579422
Validation loss: 2.1895346542199454

Epoch: 5| Step: 6
Training loss: 1.8725436925888062
Validation loss: 2.2008439848820367

Epoch: 5| Step: 7
Training loss: 1.09768545627594
Validation loss: 2.1641659140586853

Epoch: 5| Step: 8
Training loss: 1.570219874382019
Validation loss: 2.192321762442589

Epoch: 5| Step: 9
Training loss: 1.8408130407333374
Validation loss: 2.1926014870405197

Epoch: 5| Step: 10
Training loss: 1.099475383758545
Validation loss: 2.2110175589720407

Epoch: 5| Step: 11
Training loss: 1.00618577003479
Validation loss: 2.189563030997912

Epoch: 398| Step: 0
Training loss: 1.5623009204864502
Validation loss: 2.2086166590452194

Epoch: 5| Step: 1
Training loss: 1.5215418338775635
Validation loss: 2.1708358327547708

Epoch: 5| Step: 2
Training loss: 1.460981011390686
Validation loss: 2.181889613469442

Epoch: 5| Step: 3
Training loss: 0.848044216632843
Validation loss: 2.199515461921692

Epoch: 5| Step: 4
Training loss: 1.8441693782806396
Validation loss: 2.2044676343599954

Epoch: 5| Step: 5
Training loss: 1.406431794166565
Validation loss: 2.2029129713773727

Epoch: 5| Step: 6
Training loss: 1.5803877115249634
Validation loss: 2.1659781436125436

Epoch: 5| Step: 7
Training loss: 1.4280354976654053
Validation loss: 2.2302831957737603

Epoch: 5| Step: 8
Training loss: 1.8589149713516235
Validation loss: 2.197677085796992

Epoch: 5| Step: 9
Training loss: 1.603482961654663
Validation loss: 2.2048157254854837

Epoch: 5| Step: 10
Training loss: 1.3795859813690186
Validation loss: 2.198808193206787

Epoch: 5| Step: 11
Training loss: 1.4446995258331299
Validation loss: 2.180410693089167

Epoch: 399| Step: 0
Training loss: 1.360064148902893
Validation loss: 2.174569924672445

Epoch: 5| Step: 1
Training loss: 0.9136969447135925
Validation loss: 2.194190243879954

Epoch: 5| Step: 2
Training loss: 1.6060705184936523
Validation loss: 2.176521375775337

Epoch: 5| Step: 3
Training loss: 1.5430009365081787
Validation loss: 2.1611505101124444

Epoch: 5| Step: 4
Training loss: 1.2758593559265137
Validation loss: 2.1352733969688416

Epoch: 5| Step: 5
Training loss: 1.4651644229888916
Validation loss: 2.17155958712101

Epoch: 5| Step: 6
Training loss: 1.607275366783142
Validation loss: 2.1476685454448066

Epoch: 5| Step: 7
Training loss: 2.2575953006744385
Validation loss: 2.153465767701467

Epoch: 5| Step: 8
Training loss: 1.6170270442962646
Validation loss: 2.144001394510269

Epoch: 5| Step: 9
Training loss: 1.241586446762085
Validation loss: 2.143915315469106

Epoch: 5| Step: 10
Training loss: 1.2309380769729614
Validation loss: 2.1545555790265403

Epoch: 5| Step: 11
Training loss: 1.6371076107025146
Validation loss: 2.151110584537188

Epoch: 400| Step: 0
Training loss: 1.7591397762298584
Validation loss: 2.1854967176914215

Epoch: 5| Step: 1
Training loss: 1.840155839920044
Validation loss: 2.173046042521795

Epoch: 5| Step: 2
Training loss: 1.0439400672912598
Validation loss: 2.1879090319077172

Epoch: 5| Step: 3
Training loss: 1.330336332321167
Validation loss: 2.1806436528762183

Epoch: 5| Step: 4
Training loss: 1.1569149494171143
Validation loss: 2.1854257782300315

Epoch: 5| Step: 5
Training loss: 1.107595443725586
Validation loss: 2.184840848048528

Epoch: 5| Step: 6
Training loss: 1.5005743503570557
Validation loss: 2.176895628372828

Epoch: 5| Step: 7
Training loss: 1.4036369323730469
Validation loss: 2.173555607597033

Epoch: 5| Step: 8
Training loss: 1.1577211618423462
Validation loss: 2.2149091362953186

Epoch: 5| Step: 9
Training loss: 1.9291197061538696
Validation loss: 2.190631151199341

Epoch: 5| Step: 10
Training loss: 1.4024425745010376
Validation loss: 2.1780174672603607

Epoch: 5| Step: 11
Training loss: 1.604575276374817
Validation loss: 2.1285886615514755

Testing loss: 1.8996184369642957
