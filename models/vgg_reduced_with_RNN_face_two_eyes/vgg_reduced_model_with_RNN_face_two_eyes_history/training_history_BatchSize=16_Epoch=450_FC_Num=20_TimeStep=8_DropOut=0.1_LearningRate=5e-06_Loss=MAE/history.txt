Epoch: 1| Step: 0
Training loss: 4.909719467163086
Validation loss: 5.215641895929973

Epoch: 6| Step: 1
Training loss: 5.04039192199707
Validation loss: 5.214308659235637

Epoch: 6| Step: 2
Training loss: 5.632757663726807
Validation loss: 5.2130186557769775

Epoch: 6| Step: 3
Training loss: 6.269033432006836
Validation loss: 5.2116932074228925

Epoch: 6| Step: 4
Training loss: 5.617730140686035
Validation loss: 5.2103645006815595

Epoch: 6| Step: 5
Training loss: 4.25483512878418
Validation loss: 5.208997885386149

Epoch: 6| Step: 6
Training loss: 4.540298938751221
Validation loss: 5.207651933034261

Epoch: 6| Step: 7
Training loss: 5.369522571563721
Validation loss: 5.20632274945577

Epoch: 6| Step: 8
Training loss: 5.043766021728516
Validation loss: 5.2048739194869995

Epoch: 6| Step: 9
Training loss: 6.0471086502075195
Validation loss: 5.203417539596558

Epoch: 6| Step: 10
Training loss: 5.975595951080322
Validation loss: 5.201898495356242

Epoch: 6| Step: 11
Training loss: 5.277164459228516
Validation loss: 5.200363715489705

Epoch: 6| Step: 12
Training loss: 5.598921775817871
Validation loss: 5.1986509958903

Epoch: 6| Step: 13
Training loss: 4.293343544006348
Validation loss: 5.196920871734619

Epoch: 2| Step: 0
Training loss: 5.847317695617676
Validation loss: 5.195091009140015

Epoch: 6| Step: 1
Training loss: 4.763807773590088
Validation loss: 5.1932469209035235

Epoch: 6| Step: 2
Training loss: 4.655430793762207
Validation loss: 5.191306511561076

Epoch: 6| Step: 3
Training loss: 5.790290355682373
Validation loss: 5.189244747161865

Epoch: 6| Step: 4
Training loss: 5.997461318969727
Validation loss: 5.186984539031982

Epoch: 6| Step: 5
Training loss: 5.2436370849609375
Validation loss: 5.184826532999675

Epoch: 6| Step: 6
Training loss: 5.513403415679932
Validation loss: 5.182379166285197

Epoch: 6| Step: 7
Training loss: 4.689411163330078
Validation loss: 5.179819901784261

Epoch: 6| Step: 8
Training loss: 4.436652183532715
Validation loss: 5.177178064982097

Epoch: 6| Step: 9
Training loss: 4.948697090148926
Validation loss: 5.174344142278035

Epoch: 6| Step: 10
Training loss: 4.381398677825928
Validation loss: 5.171547889709473

Epoch: 6| Step: 11
Training loss: 6.358305931091309
Validation loss: 5.168427626291911

Epoch: 6| Step: 12
Training loss: 5.629156112670898
Validation loss: 5.16520619392395

Epoch: 6| Step: 13
Training loss: 5.259786605834961
Validation loss: 5.161815484364827

Epoch: 3| Step: 0
Training loss: 5.461217880249023
Validation loss: 5.158264239629109

Epoch: 6| Step: 1
Training loss: 6.181519985198975
Validation loss: 5.1546125411987305

Epoch: 6| Step: 2
Training loss: 5.491127014160156
Validation loss: 5.150512615839641

Epoch: 6| Step: 3
Training loss: 5.694906711578369
Validation loss: 5.146506309509277

Epoch: 6| Step: 4
Training loss: 4.293025016784668
Validation loss: 5.141955614089966

Epoch: 6| Step: 5
Training loss: 5.4582438468933105
Validation loss: 5.137543598810832

Epoch: 6| Step: 6
Training loss: 6.615849494934082
Validation loss: 5.132683515548706

Epoch: 6| Step: 7
Training loss: 4.617254734039307
Validation loss: 5.127564589182536

Epoch: 6| Step: 8
Training loss: 5.3138227462768555
Validation loss: 5.122367858886719

Epoch: 6| Step: 9
Training loss: 4.898266792297363
Validation loss: 5.116617838541667

Epoch: 6| Step: 10
Training loss: 5.533520221710205
Validation loss: 5.110934734344482

Epoch: 6| Step: 11
Training loss: 5.298107624053955
Validation loss: 5.105091253916423

Epoch: 6| Step: 12
Training loss: 4.349095344543457
Validation loss: 5.098863283793132

Epoch: 6| Step: 13
Training loss: 3.6113104820251465
Validation loss: 5.092530727386475

Epoch: 4| Step: 0
Training loss: 5.215706825256348
Validation loss: 5.086063067118327

Epoch: 6| Step: 1
Training loss: 4.825234413146973
Validation loss: 5.0796200434366865

Epoch: 6| Step: 2
Training loss: 4.3158979415893555
Validation loss: 5.072938680648804

Epoch: 6| Step: 3
Training loss: 5.251689910888672
Validation loss: 5.066026131312053

Epoch: 6| Step: 4
Training loss: 4.462800979614258
Validation loss: 5.059262911478679

Epoch: 6| Step: 5
Training loss: 4.3320159912109375
Validation loss: 5.052243789037068

Epoch: 6| Step: 6
Training loss: 5.693991184234619
Validation loss: 5.045102119445801

Epoch: 6| Step: 7
Training loss: 6.23992395401001
Validation loss: 5.038202126820882

Epoch: 6| Step: 8
Training loss: 4.754857540130615
Validation loss: 5.0307215849558515

Epoch: 6| Step: 9
Training loss: 5.976815223693848
Validation loss: 5.023374239603679

Epoch: 6| Step: 10
Training loss: 5.352297782897949
Validation loss: 5.01625935236613

Epoch: 6| Step: 11
Training loss: 5.378060340881348
Validation loss: 5.008523305257161

Epoch: 6| Step: 12
Training loss: 5.574065208435059
Validation loss: 5.001065572102864

Epoch: 6| Step: 13
Training loss: 4.2733154296875
Validation loss: 4.993426402409871

Epoch: 5| Step: 0
Training loss: 5.7797346115112305
Validation loss: 4.9860310554504395

Epoch: 6| Step: 1
Training loss: 4.882843017578125
Validation loss: 4.978363712628682

Epoch: 6| Step: 2
Training loss: 4.184756278991699
Validation loss: 4.970542987187703

Epoch: 6| Step: 3
Training loss: 4.422098159790039
Validation loss: 4.962860027949016

Epoch: 6| Step: 4
Training loss: 4.769718647003174
Validation loss: 4.955121914545695

Epoch: 6| Step: 5
Training loss: 5.067677021026611
Validation loss: 4.946843822797139

Epoch: 6| Step: 6
Training loss: 6.10030460357666
Validation loss: 4.938558022181193

Epoch: 6| Step: 7
Training loss: 4.1121826171875
Validation loss: 4.929991086324056

Epoch: 6| Step: 8
Training loss: 5.21445369720459
Validation loss: 4.921091397603353

Epoch: 6| Step: 9
Training loss: 5.011194229125977
Validation loss: 4.911984443664551

Epoch: 6| Step: 10
Training loss: 5.857580661773682
Validation loss: 4.903060833613078

Epoch: 6| Step: 11
Training loss: 4.311916351318359
Validation loss: 4.894649823506673

Epoch: 6| Step: 12
Training loss: 4.95060920715332
Validation loss: 4.885241826375325

Epoch: 6| Step: 13
Training loss: 5.545117378234863
Validation loss: 4.876539786656697

Epoch: 6| Step: 0
Training loss: 4.761113166809082
Validation loss: 4.867651700973511

Epoch: 6| Step: 1
Training loss: 4.7818379402160645
Validation loss: 4.8590296904246015

Epoch: 6| Step: 2
Training loss: 5.852119445800781
Validation loss: 4.850640296936035

Epoch: 6| Step: 3
Training loss: 4.377552509307861
Validation loss: 4.840836922327678

Epoch: 6| Step: 4
Training loss: 5.221639156341553
Validation loss: 4.831468383471171

Epoch: 6| Step: 5
Training loss: 4.4973320960998535
Validation loss: 4.822349627812703

Epoch: 6| Step: 6
Training loss: 6.117856979370117
Validation loss: 4.813588301340739

Epoch: 6| Step: 7
Training loss: 5.190649032592773
Validation loss: 4.804592132568359

Epoch: 6| Step: 8
Training loss: 4.497908592224121
Validation loss: 4.796398162841797

Epoch: 6| Step: 9
Training loss: 3.4269466400146484
Validation loss: 4.787623802820842

Epoch: 6| Step: 10
Training loss: 4.4470672607421875
Validation loss: 4.779468854268392

Epoch: 6| Step: 11
Training loss: 5.336165428161621
Validation loss: 4.771051327387492

Epoch: 6| Step: 12
Training loss: 5.386126518249512
Validation loss: 4.762108167012532

Epoch: 6| Step: 13
Training loss: 4.6484150886535645
Validation loss: 4.753054777781169

Epoch: 7| Step: 0
Training loss: 4.369565963745117
Validation loss: 4.744269212086995

Epoch: 6| Step: 1
Training loss: 5.047194004058838
Validation loss: 4.735542933146159

Epoch: 6| Step: 2
Training loss: 5.037119388580322
Validation loss: 4.726921399434407

Epoch: 6| Step: 3
Training loss: 5.399985313415527
Validation loss: 4.717901945114136

Epoch: 6| Step: 4
Training loss: 5.8212151527404785
Validation loss: 4.709798097610474

Epoch: 6| Step: 5
Training loss: 3.953876256942749
Validation loss: 4.701578776041667

Epoch: 6| Step: 6
Training loss: 5.487400054931641
Validation loss: 4.693082094192505

Epoch: 6| Step: 7
Training loss: 4.112607479095459
Validation loss: 4.684807062149048

Epoch: 6| Step: 8
Training loss: 4.982146263122559
Validation loss: 4.676523764928182

Epoch: 6| Step: 9
Training loss: 5.5130486488342285
Validation loss: 4.668174386024475

Epoch: 6| Step: 10
Training loss: 4.851055145263672
Validation loss: 4.660115639368693

Epoch: 6| Step: 11
Training loss: 3.981901168823242
Validation loss: 4.651996374130249

Epoch: 6| Step: 12
Training loss: 4.555972099304199
Validation loss: 4.643595973650615

Epoch: 6| Step: 13
Training loss: 3.8543930053710938
Validation loss: 4.635558048884074

Epoch: 8| Step: 0
Training loss: 4.803545951843262
Validation loss: 4.62759002049764

Epoch: 6| Step: 1
Training loss: 4.841320037841797
Validation loss: 4.619662284851074

Epoch: 6| Step: 2
Training loss: 5.58608865737915
Validation loss: 4.612106482187907

Epoch: 6| Step: 3
Training loss: 4.47783088684082
Validation loss: 4.604283054669698

Epoch: 6| Step: 4
Training loss: 4.4173126220703125
Validation loss: 4.596801678339641

Epoch: 6| Step: 5
Training loss: 4.925863265991211
Validation loss: 4.589423576990764

Epoch: 6| Step: 6
Training loss: 4.574477195739746
Validation loss: 4.582006812095642

Epoch: 6| Step: 7
Training loss: 4.394881248474121
Validation loss: 4.574591954549153

Epoch: 6| Step: 8
Training loss: 4.22131872177124
Validation loss: 4.567850430806478

Epoch: 6| Step: 9
Training loss: 4.582369804382324
Validation loss: 4.561320861180623

Epoch: 6| Step: 10
Training loss: 3.2126803398132324
Validation loss: 4.554970979690552

Epoch: 6| Step: 11
Training loss: 4.929249286651611
Validation loss: 4.549221118291219

Epoch: 6| Step: 12
Training loss: 4.849521636962891
Validation loss: 4.542829831441243

Epoch: 6| Step: 13
Training loss: 5.707226753234863
Validation loss: 4.537319580713908

Epoch: 9| Step: 0
Training loss: 5.236930847167969
Validation loss: 4.5308765570322675

Epoch: 6| Step: 1
Training loss: 3.485898971557617
Validation loss: 4.525459448496501

Epoch: 6| Step: 2
Training loss: 5.45045280456543
Validation loss: 4.519695520401001

Epoch: 6| Step: 3
Training loss: 3.3460726737976074
Validation loss: 4.5137589772542315

Epoch: 6| Step: 4
Training loss: 5.029811859130859
Validation loss: 4.508356332778931

Epoch: 6| Step: 5
Training loss: 5.372247695922852
Validation loss: 4.502789696057637

Epoch: 6| Step: 6
Training loss: 5.057315826416016
Validation loss: 4.497174819310506

Epoch: 6| Step: 7
Training loss: 4.675060749053955
Validation loss: 4.49224066734314

Epoch: 6| Step: 8
Training loss: 4.242892265319824
Validation loss: 4.486690918604533

Epoch: 6| Step: 9
Training loss: 3.996680736541748
Validation loss: 4.4813040892283125

Epoch: 6| Step: 10
Training loss: 4.041496276855469
Validation loss: 4.475579380989075

Epoch: 6| Step: 11
Training loss: 5.470105171203613
Validation loss: 4.470772425333659

Epoch: 6| Step: 12
Training loss: 4.697916030883789
Validation loss: 4.465249141057332

Epoch: 6| Step: 13
Training loss: 4.31855583190918
Validation loss: 4.459954261779785

Epoch: 10| Step: 0
Training loss: 4.067660331726074
Validation loss: 4.4549500942230225

Epoch: 6| Step: 1
Training loss: 3.8829009532928467
Validation loss: 4.449506521224976

Epoch: 6| Step: 2
Training loss: 4.295900344848633
Validation loss: 4.444529096285502

Epoch: 6| Step: 3
Training loss: 4.270294666290283
Validation loss: 4.439123471577962

Epoch: 6| Step: 4
Training loss: 3.848940849304199
Validation loss: 4.433317979176839

Epoch: 6| Step: 5
Training loss: 5.148042678833008
Validation loss: 4.428581317265828

Epoch: 6| Step: 6
Training loss: 4.543405532836914
Validation loss: 4.423653642336528

Epoch: 6| Step: 7
Training loss: 4.1932196617126465
Validation loss: 4.418546279271443

Epoch: 6| Step: 8
Training loss: 5.767665386199951
Validation loss: 4.41409174601237

Epoch: 6| Step: 9
Training loss: 4.27437686920166
Validation loss: 4.409274697303772

Epoch: 6| Step: 10
Training loss: 5.035240173339844
Validation loss: 4.404671907424927

Epoch: 6| Step: 11
Training loss: 5.263057708740234
Validation loss: 4.399127721786499

Epoch: 6| Step: 12
Training loss: 3.4669318199157715
Validation loss: 4.394524137179057

Epoch: 6| Step: 13
Training loss: 5.442805290222168
Validation loss: 4.389037171999614

Epoch: 11| Step: 0
Training loss: 4.556769371032715
Validation loss: 4.3848287264506025

Epoch: 6| Step: 1
Training loss: 3.920797824859619
Validation loss: 4.379893859227498

Epoch: 6| Step: 2
Training loss: 5.222565650939941
Validation loss: 4.374986370404561

Epoch: 6| Step: 3
Training loss: 4.288043022155762
Validation loss: 4.37053124109904

Epoch: 6| Step: 4
Training loss: 4.680639266967773
Validation loss: 4.3652024269104

Epoch: 6| Step: 5
Training loss: 5.099761486053467
Validation loss: 4.360480427742004

Epoch: 6| Step: 6
Training loss: 5.034368515014648
Validation loss: 4.355323712031047

Epoch: 6| Step: 7
Training loss: 4.377068042755127
Validation loss: 4.350648204485576

Epoch: 6| Step: 8
Training loss: 4.377622604370117
Validation loss: 4.345896482467651

Epoch: 6| Step: 9
Training loss: 4.484956741333008
Validation loss: 4.340701699256897

Epoch: 6| Step: 10
Training loss: 4.566426753997803
Validation loss: 4.3358207543691

Epoch: 6| Step: 11
Training loss: 4.813385009765625
Validation loss: 4.331439971923828

Epoch: 6| Step: 12
Training loss: 3.696826457977295
Validation loss: 4.3263365427653

Epoch: 6| Step: 13
Training loss: 3.523169994354248
Validation loss: 4.3211363554000854

Epoch: 12| Step: 0
Training loss: 4.343342304229736
Validation loss: 4.3173502286275225

Epoch: 6| Step: 1
Training loss: 4.62600040435791
Validation loss: 4.312499642372131

Epoch: 6| Step: 2
Training loss: 4.250722885131836
Validation loss: 4.307291944821675

Epoch: 6| Step: 3
Training loss: 4.774140357971191
Validation loss: 4.302912036577861

Epoch: 6| Step: 4
Training loss: 2.5437233448028564
Validation loss: 4.298402706782023

Epoch: 6| Step: 5
Training loss: 4.292032241821289
Validation loss: 4.294150431950887

Epoch: 6| Step: 6
Training loss: 4.369682312011719
Validation loss: 4.2887769142786665

Epoch: 6| Step: 7
Training loss: 4.542790412902832
Validation loss: 4.284603754679362

Epoch: 6| Step: 8
Training loss: 4.957932949066162
Validation loss: 4.2800478140513105

Epoch: 6| Step: 9
Training loss: 4.90620231628418
Validation loss: 4.275227705637614

Epoch: 6| Step: 10
Training loss: 4.8873372077941895
Validation loss: 4.270492513974507

Epoch: 6| Step: 11
Training loss: 4.521306991577148
Validation loss: 4.266210238138835

Epoch: 6| Step: 12
Training loss: 3.997121810913086
Validation loss: 4.260957797368367

Epoch: 6| Step: 13
Training loss: 4.751250267028809
Validation loss: 4.256312767664592

Epoch: 13| Step: 0
Training loss: 4.727887153625488
Validation loss: 4.250874161720276

Epoch: 6| Step: 1
Training loss: 4.946116924285889
Validation loss: 4.246300975481669

Epoch: 6| Step: 2
Training loss: 4.681129455566406
Validation loss: 4.2407054503758745

Epoch: 6| Step: 3
Training loss: 5.026350021362305
Validation loss: 4.236623605092366

Epoch: 6| Step: 4
Training loss: 4.792289733886719
Validation loss: 4.231316526730855

Epoch: 6| Step: 5
Training loss: 4.986083507537842
Validation loss: 4.22638742129008

Epoch: 6| Step: 6
Training loss: 3.6877264976501465
Validation loss: 4.221833825111389

Epoch: 6| Step: 7
Training loss: 3.6431922912597656
Validation loss: 4.216023047765096

Epoch: 6| Step: 8
Training loss: 4.453804969787598
Validation loss: 4.211004455884297

Epoch: 6| Step: 9
Training loss: 4.168889999389648
Validation loss: 4.204952796300252

Epoch: 6| Step: 10
Training loss: 4.348623752593994
Validation loss: 4.199938535690308

Epoch: 6| Step: 11
Training loss: 3.6831490993499756
Validation loss: 4.1949003140131635

Epoch: 6| Step: 12
Training loss: 3.308408260345459
Validation loss: 4.1902371644973755

Epoch: 6| Step: 13
Training loss: 4.453731536865234
Validation loss: 4.185144821802775

Epoch: 14| Step: 0
Training loss: 5.126001834869385
Validation loss: 4.179950475692749

Epoch: 6| Step: 1
Training loss: 4.050762176513672
Validation loss: 4.17471981048584

Epoch: 6| Step: 2
Training loss: 3.7088911533355713
Validation loss: 4.169644117355347

Epoch: 6| Step: 3
Training loss: 4.267308712005615
Validation loss: 4.165395935376485

Epoch: 6| Step: 4
Training loss: 3.7025532722473145
Validation loss: 4.16133991877238

Epoch: 6| Step: 5
Training loss: 4.468527793884277
Validation loss: 4.156815012296041

Epoch: 6| Step: 6
Training loss: 3.4303040504455566
Validation loss: 4.151281634966533

Epoch: 6| Step: 7
Training loss: 4.481861591339111
Validation loss: 4.14658260345459

Epoch: 6| Step: 8
Training loss: 4.600098609924316
Validation loss: 4.142018834749858

Epoch: 6| Step: 9
Training loss: 4.393381118774414
Validation loss: 4.136399706204732

Epoch: 6| Step: 10
Training loss: 4.375803470611572
Validation loss: 4.131653547286987

Epoch: 6| Step: 11
Training loss: 4.78239631652832
Validation loss: 4.1268571217854815

Epoch: 6| Step: 12
Training loss: 4.440122604370117
Validation loss: 4.121456027030945

Epoch: 6| Step: 13
Training loss: 4.149848937988281
Validation loss: 4.1168538729349775

Epoch: 15| Step: 0
Training loss: 4.743636608123779
Validation loss: 4.11142361164093

Epoch: 6| Step: 1
Training loss: 4.1674981117248535
Validation loss: 4.106571674346924

Epoch: 6| Step: 2
Training loss: 4.601768493652344
Validation loss: 4.101819276809692

Epoch: 6| Step: 3
Training loss: 4.389400005340576
Validation loss: 4.096640984217326

Epoch: 6| Step: 4
Training loss: 4.232229232788086
Validation loss: 4.092038869857788

Epoch: 6| Step: 5
Training loss: 4.27614688873291
Validation loss: 4.08695113658905

Epoch: 6| Step: 6
Training loss: 4.45609188079834
Validation loss: 4.082001407941182

Epoch: 6| Step: 7
Training loss: 4.544883728027344
Validation loss: 4.077784140904744

Epoch: 6| Step: 8
Training loss: 4.1221747398376465
Validation loss: 4.072602351506551

Epoch: 6| Step: 9
Training loss: 4.697005271911621
Validation loss: 4.0671073993047075

Epoch: 6| Step: 10
Training loss: 3.7018277645111084
Validation loss: 4.062150001525879

Epoch: 6| Step: 11
Training loss: 3.1674885749816895
Validation loss: 4.056858936945598

Epoch: 6| Step: 12
Training loss: 4.242276668548584
Validation loss: 4.051677942276001

Epoch: 6| Step: 13
Training loss: 3.758181095123291
Validation loss: 4.0476168394088745

Epoch: 16| Step: 0
Training loss: 4.009549140930176
Validation loss: 4.0429534912109375

Epoch: 6| Step: 1
Training loss: 4.148107528686523
Validation loss: 4.03735888004303

Epoch: 6| Step: 2
Training loss: 4.8517303466796875
Validation loss: 4.031501015027364

Epoch: 6| Step: 3
Training loss: 4.912055015563965
Validation loss: 4.026965498924255

Epoch: 6| Step: 4
Training loss: 4.488027572631836
Validation loss: 4.021968364715576

Epoch: 6| Step: 5
Training loss: 4.333731651306152
Validation loss: 4.01679007212321

Epoch: 6| Step: 6
Training loss: 4.297590255737305
Validation loss: 4.011344830195109

Epoch: 6| Step: 7
Training loss: 3.527458906173706
Validation loss: 4.007270137468974

Epoch: 6| Step: 8
Training loss: 4.013660430908203
Validation loss: 4.002190192540486

Epoch: 6| Step: 9
Training loss: 4.282064437866211
Validation loss: 3.997080087661743

Epoch: 6| Step: 10
Training loss: 4.66567325592041
Validation loss: 3.992931882540385

Epoch: 6| Step: 11
Training loss: 3.926426649093628
Validation loss: 3.9879445234934487

Epoch: 6| Step: 12
Training loss: 3.48960542678833
Validation loss: 3.983089486757914

Epoch: 6| Step: 13
Training loss: 3.1955318450927734
Validation loss: 3.9772507349650064

Epoch: 17| Step: 0
Training loss: 5.0086259841918945
Validation loss: 3.971763292948405

Epoch: 6| Step: 1
Training loss: 4.145336151123047
Validation loss: 3.9680598974227905

Epoch: 6| Step: 2
Training loss: 3.177042007446289
Validation loss: 3.962425112724304

Epoch: 6| Step: 3
Training loss: 4.699400901794434
Validation loss: 3.9569838841756186

Epoch: 6| Step: 4
Training loss: 3.5338048934936523
Validation loss: 3.952647606531779

Epoch: 6| Step: 5
Training loss: 3.7280497550964355
Validation loss: 3.9468379815419516

Epoch: 6| Step: 6
Training loss: 4.184369087219238
Validation loss: 3.9418787956237793

Epoch: 6| Step: 7
Training loss: 3.979121446609497
Validation loss: 3.936979095141093

Epoch: 6| Step: 8
Training loss: 4.133060932159424
Validation loss: 3.93225089708964

Epoch: 6| Step: 9
Training loss: 5.565177917480469
Validation loss: 3.92629341284434

Epoch: 6| Step: 10
Training loss: 3.2628793716430664
Validation loss: 3.9214659134546914

Epoch: 6| Step: 11
Training loss: 3.2775464057922363
Validation loss: 3.9164701302846274

Epoch: 6| Step: 12
Training loss: 4.6384735107421875
Validation loss: 3.9117961327234902

Epoch: 6| Step: 13
Training loss: 3.9035468101501465
Validation loss: 3.906454563140869

Epoch: 18| Step: 0
Training loss: 4.584037780761719
Validation loss: 3.9016631841659546

Epoch: 6| Step: 1
Training loss: 4.380484104156494
Validation loss: 3.8969786167144775

Epoch: 6| Step: 2
Training loss: 3.342850685119629
Validation loss: 3.891208211580912

Epoch: 6| Step: 3
Training loss: 4.579775810241699
Validation loss: 3.886408885320028

Epoch: 6| Step: 4
Training loss: 4.065725326538086
Validation loss: 3.881446878115336

Epoch: 6| Step: 5
Training loss: 4.067310333251953
Validation loss: 3.8775830268859863

Epoch: 6| Step: 6
Training loss: 4.140954494476318
Validation loss: 3.872232675552368

Epoch: 6| Step: 7
Training loss: 4.103900909423828
Validation loss: 3.8662749926249185

Epoch: 6| Step: 8
Training loss: 3.9123969078063965
Validation loss: 3.8621521393458047

Epoch: 6| Step: 9
Training loss: 4.587277412414551
Validation loss: 3.8577887614568076

Epoch: 6| Step: 10
Training loss: 3.727766990661621
Validation loss: 3.8524241844813027

Epoch: 6| Step: 11
Training loss: 3.677264451980591
Validation loss: 3.848663012186686

Epoch: 6| Step: 12
Training loss: 4.034496307373047
Validation loss: 3.8456643422444663

Epoch: 6| Step: 13
Training loss: 3.1223368644714355
Validation loss: 3.8393065134684243

Epoch: 19| Step: 0
Training loss: 4.3253173828125
Validation loss: 3.834107836087545

Epoch: 6| Step: 1
Training loss: 4.086305141448975
Validation loss: 3.829653263092041

Epoch: 6| Step: 2
Training loss: 4.581260681152344
Validation loss: 3.8253682454427085

Epoch: 6| Step: 3
Training loss: 3.6382808685302734
Validation loss: 3.8201541105906167

Epoch: 6| Step: 4
Training loss: 3.931777000427246
Validation loss: 3.8152241309483848

Epoch: 6| Step: 5
Training loss: 3.2645931243896484
Validation loss: 3.810541033744812

Epoch: 6| Step: 6
Training loss: 4.2429304122924805
Validation loss: 3.8060237566630044

Epoch: 6| Step: 7
Training loss: 3.772054433822632
Validation loss: 3.800556461016337

Epoch: 6| Step: 8
Training loss: 2.5685858726501465
Validation loss: 3.795414169629415

Epoch: 6| Step: 9
Training loss: 3.9739248752593994
Validation loss: 3.791199286778768

Epoch: 6| Step: 10
Training loss: 4.482865810394287
Validation loss: 3.787021517753601

Epoch: 6| Step: 11
Training loss: 4.319537162780762
Validation loss: 3.783130923906962

Epoch: 6| Step: 12
Training loss: 4.696319580078125
Validation loss: 3.77803627649943

Epoch: 6| Step: 13
Training loss: 3.564650535583496
Validation loss: 3.7733802000681558

Epoch: 20| Step: 0
Training loss: 3.976334571838379
Validation loss: 3.7687191565831504

Epoch: 6| Step: 1
Training loss: 3.7828354835510254
Validation loss: 3.764897267023722

Epoch: 6| Step: 2
Training loss: 3.664599895477295
Validation loss: 3.761102239290873

Epoch: 6| Step: 3
Training loss: 3.693758726119995
Validation loss: 3.7552732626597085

Epoch: 6| Step: 4
Training loss: 4.084139823913574
Validation loss: 3.7502978642781577

Epoch: 6| Step: 5
Training loss: 4.395761489868164
Validation loss: 3.7456777493158975

Epoch: 6| Step: 6
Training loss: 4.268458366394043
Validation loss: 3.7415932416915894

Epoch: 6| Step: 7
Training loss: 4.251780986785889
Validation loss: 3.737364888191223

Epoch: 6| Step: 8
Training loss: 3.8079235553741455
Validation loss: 3.733256379763285

Epoch: 6| Step: 9
Training loss: 3.4050869941711426
Validation loss: 3.727709174156189

Epoch: 6| Step: 10
Training loss: 3.3939766883850098
Validation loss: 3.723522742589315

Epoch: 6| Step: 11
Training loss: 4.266515731811523
Validation loss: 3.7197020053863525

Epoch: 6| Step: 12
Training loss: 4.542911529541016
Validation loss: 3.715413451194763

Epoch: 6| Step: 13
Training loss: 3.0688681602478027
Validation loss: 3.7105466524759927

Epoch: 21| Step: 0
Training loss: 4.023704528808594
Validation loss: 3.7067465782165527

Epoch: 6| Step: 1
Training loss: 3.752289295196533
Validation loss: 3.7019274632136026

Epoch: 6| Step: 2
Training loss: 3.900954008102417
Validation loss: 3.6977387269337973

Epoch: 6| Step: 3
Training loss: 3.2869181632995605
Validation loss: 3.693983713785807

Epoch: 6| Step: 4
Training loss: 4.180393218994141
Validation loss: 3.688973625500997

Epoch: 6| Step: 5
Training loss: 3.8203978538513184
Validation loss: 3.6846326986948648

Epoch: 6| Step: 6
Training loss: 4.691514015197754
Validation loss: 3.680292089780172

Epoch: 6| Step: 7
Training loss: 4.054302215576172
Validation loss: 3.675844589869181

Epoch: 6| Step: 8
Training loss: 4.132951736450195
Validation loss: 3.670974771181742

Epoch: 6| Step: 9
Training loss: 3.6581814289093018
Validation loss: 3.6668235460917153

Epoch: 6| Step: 10
Training loss: 3.7722368240356445
Validation loss: 3.6644696791966758

Epoch: 6| Step: 11
Training loss: 3.5901341438293457
Validation loss: 3.6663493712743125

Epoch: 6| Step: 12
Training loss: 3.843228816986084
Validation loss: 3.6544750928878784

Epoch: 6| Step: 13
Training loss: 3.04439115524292
Validation loss: 3.649702032407125

Epoch: 22| Step: 0
Training loss: 4.513738632202148
Validation loss: 3.6458773215611777

Epoch: 6| Step: 1
Training loss: 3.7470123767852783
Validation loss: 3.641408920288086

Epoch: 6| Step: 2
Training loss: 2.453822612762451
Validation loss: 3.636832038561503

Epoch: 6| Step: 3
Training loss: 3.4691128730773926
Validation loss: 3.6329238017400107

Epoch: 6| Step: 4
Training loss: 3.1782259941101074
Validation loss: 3.6282589435577393

Epoch: 6| Step: 5
Training loss: 3.300644874572754
Validation loss: 3.62376340230306

Epoch: 6| Step: 6
Training loss: 5.089195251464844
Validation loss: 3.6197257041931152

Epoch: 6| Step: 7
Training loss: 4.248401641845703
Validation loss: 3.6141583919525146

Epoch: 6| Step: 8
Training loss: 3.9201602935791016
Validation loss: 3.6097557147343955

Epoch: 6| Step: 9
Training loss: 3.8077564239501953
Validation loss: 3.6054557959238687

Epoch: 6| Step: 10
Training loss: 3.4385945796966553
Validation loss: 3.600586414337158

Epoch: 6| Step: 11
Training loss: 4.350437164306641
Validation loss: 3.596344749132792

Epoch: 6| Step: 12
Training loss: 3.2507331371307373
Validation loss: 3.591956853866577

Epoch: 6| Step: 13
Training loss: 4.151482582092285
Validation loss: 3.587684432665507

Epoch: 23| Step: 0
Training loss: 3.247091054916382
Validation loss: 3.583919803301493

Epoch: 6| Step: 1
Training loss: 2.3902177810668945
Validation loss: 3.580063223838806

Epoch: 6| Step: 2
Training loss: 3.8591268062591553
Validation loss: 3.575873096783956

Epoch: 6| Step: 3
Training loss: 3.9556632041931152
Validation loss: 3.5711878140767417

Epoch: 6| Step: 4
Training loss: 3.2839324474334717
Validation loss: 3.566831906636556

Epoch: 6| Step: 5
Training loss: 4.464881420135498
Validation loss: 3.563258250554403

Epoch: 6| Step: 6
Training loss: 3.800011396408081
Validation loss: 3.559849421183268

Epoch: 6| Step: 7
Training loss: 4.608006477355957
Validation loss: 3.55539079507192

Epoch: 6| Step: 8
Training loss: 3.159254550933838
Validation loss: 3.550581932067871

Epoch: 6| Step: 9
Training loss: 3.5011515617370605
Validation loss: 3.5457138220469155

Epoch: 6| Step: 10
Training loss: 4.506655216217041
Validation loss: 3.540946364402771

Epoch: 6| Step: 11
Training loss: 3.395329236984253
Validation loss: 3.5365813970565796

Epoch: 6| Step: 12
Training loss: 4.1184983253479
Validation loss: 3.532693306605021

Epoch: 6| Step: 13
Training loss: 3.782726526260376
Validation loss: 3.5282324949900308

Epoch: 24| Step: 0
Training loss: 3.7229084968566895
Validation loss: 3.523147384325663

Epoch: 6| Step: 1
Training loss: 3.296154499053955
Validation loss: 3.5179770390192666

Epoch: 6| Step: 2
Training loss: 3.432084083557129
Validation loss: 3.513788938522339

Epoch: 6| Step: 3
Training loss: 3.6846060752868652
Validation loss: 3.509483019510905

Epoch: 6| Step: 4
Training loss: 4.715330600738525
Validation loss: 3.5046536922454834

Epoch: 6| Step: 5
Training loss: 4.020500659942627
Validation loss: 3.5005129178365073

Epoch: 6| Step: 6
Training loss: 3.1744518280029297
Validation loss: 3.4964524507522583

Epoch: 6| Step: 7
Training loss: 3.7569100856781006
Validation loss: 3.491726835568746

Epoch: 6| Step: 8
Training loss: 3.6258246898651123
Validation loss: 3.4869767824808755

Epoch: 6| Step: 9
Training loss: 4.1056694984436035
Validation loss: 3.482046604156494

Epoch: 6| Step: 10
Training loss: 3.368513345718384
Validation loss: 3.477718393007914

Epoch: 6| Step: 11
Training loss: 3.4687628746032715
Validation loss: 3.4735477765401206

Epoch: 6| Step: 12
Training loss: 3.8582663536071777
Validation loss: 3.4692710638046265

Epoch: 6| Step: 13
Training loss: 3.0232489109039307
Validation loss: 3.465123693148295

Epoch: 25| Step: 0
Training loss: 3.5391979217529297
Validation loss: 3.460585037867228

Epoch: 6| Step: 1
Training loss: 4.573981285095215
Validation loss: 3.4565770626068115

Epoch: 6| Step: 2
Training loss: 4.2011308670043945
Validation loss: 3.45196525255839

Epoch: 6| Step: 3
Training loss: 3.4956929683685303
Validation loss: 3.4468392928441367

Epoch: 6| Step: 4
Training loss: 4.331189155578613
Validation loss: 3.442993919054667

Epoch: 6| Step: 5
Training loss: 4.284743309020996
Validation loss: 3.4378298918406167

Epoch: 6| Step: 6
Training loss: 3.433753490447998
Validation loss: 3.4339292844136557

Epoch: 6| Step: 7
Training loss: 3.9319074153900146
Validation loss: 3.429052392641703

Epoch: 6| Step: 8
Training loss: 3.3283920288085938
Validation loss: 3.424259583155314

Epoch: 6| Step: 9
Training loss: 2.1198391914367676
Validation loss: 3.4197030464808145

Epoch: 6| Step: 10
Training loss: 3.6981117725372314
Validation loss: 3.4160933097203574

Epoch: 6| Step: 11
Training loss: 2.9657797813415527
Validation loss: 3.4118069410324097

Epoch: 6| Step: 12
Training loss: 2.863278388977051
Validation loss: 3.407081047693888

Epoch: 6| Step: 13
Training loss: 3.6606011390686035
Validation loss: 3.4028265476226807

Epoch: 26| Step: 0
Training loss: 3.597683906555176
Validation loss: 3.3993024428685508

Epoch: 6| Step: 1
Training loss: 3.577669143676758
Validation loss: 3.3957978089650473

Epoch: 6| Step: 2
Training loss: 3.5521233081817627
Validation loss: 3.391807039578756

Epoch: 6| Step: 3
Training loss: 3.9769463539123535
Validation loss: 3.387907385826111

Epoch: 6| Step: 4
Training loss: 3.707444190979004
Validation loss: 3.383981545766195

Epoch: 6| Step: 5
Training loss: 3.9761672019958496
Validation loss: 3.3799341519673667

Epoch: 6| Step: 6
Training loss: 3.379887580871582
Validation loss: 3.3758289019266763

Epoch: 6| Step: 7
Training loss: 2.5766758918762207
Validation loss: 3.371815005938212

Epoch: 6| Step: 8
Training loss: 4.013096332550049
Validation loss: 3.367132822672526

Epoch: 6| Step: 9
Training loss: 2.8630900382995605
Validation loss: 3.3629130522410073

Epoch: 6| Step: 10
Training loss: 3.5068211555480957
Validation loss: 3.3591219186782837

Epoch: 6| Step: 11
Training loss: 3.807945728302002
Validation loss: 3.354356527328491

Epoch: 6| Step: 12
Training loss: 2.9942216873168945
Validation loss: 3.34971292813619

Epoch: 6| Step: 13
Training loss: 4.068942070007324
Validation loss: 3.3458788792292276

Epoch: 27| Step: 0
Training loss: 3.8935301303863525
Validation loss: 3.3414024114608765

Epoch: 6| Step: 1
Training loss: 3.3708786964416504
Validation loss: 3.337729334831238

Epoch: 6| Step: 2
Training loss: 2.739001750946045
Validation loss: 3.3332463105519614

Epoch: 6| Step: 3
Training loss: 2.6380319595336914
Validation loss: 3.329532345136007

Epoch: 6| Step: 4
Training loss: 3.8390183448791504
Validation loss: 3.325012524922689

Epoch: 6| Step: 5
Training loss: 4.026401042938232
Validation loss: 3.320680797100067

Epoch: 6| Step: 6
Training loss: 3.3142709732055664
Validation loss: 3.3165742556254068

Epoch: 6| Step: 7
Training loss: 4.026765823364258
Validation loss: 3.3118091821670532

Epoch: 6| Step: 8
Training loss: 3.56223201751709
Validation loss: 3.3075414101282754

Epoch: 6| Step: 9
Training loss: 3.8282217979431152
Validation loss: 3.3029475609461465

Epoch: 6| Step: 10
Training loss: 4.2291669845581055
Validation loss: 3.298835833867391

Epoch: 6| Step: 11
Training loss: 2.308913469314575
Validation loss: 3.294963002204895

Epoch: 6| Step: 12
Training loss: 3.867501974105835
Validation loss: 3.2913164297739663

Epoch: 6| Step: 13
Training loss: 3.2089791297912598
Validation loss: 3.2876590490341187

Epoch: 28| Step: 0
Training loss: 3.2484664916992188
Validation loss: 3.2832581996917725

Epoch: 6| Step: 1
Training loss: 4.050623416900635
Validation loss: 3.2798041502634683

Epoch: 6| Step: 2
Training loss: 2.6725587844848633
Validation loss: 3.2762047052383423

Epoch: 6| Step: 3
Training loss: 3.59661865234375
Validation loss: 3.272580703099569

Epoch: 6| Step: 4
Training loss: 3.349053382873535
Validation loss: 3.2688293854395547

Epoch: 6| Step: 5
Training loss: 3.3250834941864014
Validation loss: 3.265820542971293

Epoch: 6| Step: 6
Training loss: 3.526348114013672
Validation loss: 3.2617937326431274

Epoch: 6| Step: 7
Training loss: 3.3825321197509766
Validation loss: 3.25789205233256

Epoch: 6| Step: 8
Training loss: 2.8681774139404297
Validation loss: 3.254065195719401

Epoch: 6| Step: 9
Training loss: 3.3718714714050293
Validation loss: 3.2503491242726645

Epoch: 6| Step: 10
Training loss: 3.7191829681396484
Validation loss: 3.246554891268412

Epoch: 6| Step: 11
Training loss: 3.4351298809051514
Validation loss: 3.2424385945002236

Epoch: 6| Step: 12
Training loss: 3.3517708778381348
Validation loss: 3.2392181952794394

Epoch: 6| Step: 13
Training loss: 4.216552257537842
Validation loss: 3.2345770994822183

Epoch: 29| Step: 0
Training loss: 3.879666566848755
Validation loss: 3.230459372202555

Epoch: 6| Step: 1
Training loss: 3.2279696464538574
Validation loss: 3.22668993473053

Epoch: 6| Step: 2
Training loss: 3.6513290405273438
Validation loss: 3.222961664199829

Epoch: 6| Step: 3
Training loss: 3.102585554122925
Validation loss: 3.2190564473470054

Epoch: 6| Step: 4
Training loss: 2.7281970977783203
Validation loss: 3.215595285097758

Epoch: 6| Step: 5
Training loss: 2.6669647693634033
Validation loss: 3.211677074432373

Epoch: 6| Step: 6
Training loss: 3.631211280822754
Validation loss: 3.2087263266245523

Epoch: 6| Step: 7
Training loss: 3.2290596961975098
Validation loss: 3.2049612998962402

Epoch: 6| Step: 8
Training loss: 3.3237385749816895
Validation loss: 3.201364755630493

Epoch: 6| Step: 9
Training loss: 3.5893666744232178
Validation loss: 3.197533289591471

Epoch: 6| Step: 10
Training loss: 3.400324821472168
Validation loss: 3.193405191103617

Epoch: 6| Step: 11
Training loss: 3.696047782897949
Validation loss: 3.18965737024943

Epoch: 6| Step: 12
Training loss: 3.578244209289551
Validation loss: 3.1857007344563804

Epoch: 6| Step: 13
Training loss: 3.7000513076782227
Validation loss: 3.182745377222697

Epoch: 30| Step: 0
Training loss: 3.263857841491699
Validation loss: 3.1786975065867105

Epoch: 6| Step: 1
Training loss: 3.425291061401367
Validation loss: 3.1759877602259317

Epoch: 6| Step: 2
Training loss: 3.5437498092651367
Validation loss: 3.1698976357777915

Epoch: 6| Step: 3
Training loss: 3.631397247314453
Validation loss: 3.165875713030497

Epoch: 6| Step: 4
Training loss: 2.6888294219970703
Validation loss: 3.162002523740133

Epoch: 6| Step: 5
Training loss: 3.4935877323150635
Validation loss: 3.1579084396362305

Epoch: 6| Step: 6
Training loss: 2.6066908836364746
Validation loss: 3.1544169982274375

Epoch: 6| Step: 7
Training loss: 3.202120542526245
Validation loss: 3.1512593825658164

Epoch: 6| Step: 8
Training loss: 2.922417402267456
Validation loss: 3.14805801709493

Epoch: 6| Step: 9
Training loss: 3.576406955718994
Validation loss: 3.1445531447728476

Epoch: 6| Step: 10
Training loss: 4.080167770385742
Validation loss: 3.1415445804595947

Epoch: 6| Step: 11
Training loss: 3.230996608734131
Validation loss: 3.137091855208079

Epoch: 6| Step: 12
Training loss: 3.8256418704986572
Validation loss: 3.1330029169718423

Epoch: 6| Step: 13
Training loss: 3.246391534805298
Validation loss: 3.129299283027649

Epoch: 31| Step: 0
Training loss: 3.430521249771118
Validation loss: 3.125247518221537

Epoch: 6| Step: 1
Training loss: 3.227473258972168
Validation loss: 3.1211300690968833

Epoch: 6| Step: 2
Training loss: 3.614682674407959
Validation loss: 3.1167895793914795

Epoch: 6| Step: 3
Training loss: 3.6480636596679688
Validation loss: 3.11221714814504

Epoch: 6| Step: 4
Training loss: 2.514824390411377
Validation loss: 3.1082241535186768

Epoch: 6| Step: 5
Training loss: 2.922086000442505
Validation loss: 3.1046520272890725

Epoch: 6| Step: 6
Training loss: 3.0901999473571777
Validation loss: 3.100639502207438

Epoch: 6| Step: 7
Training loss: 3.179682731628418
Validation loss: 3.0980128049850464

Epoch: 6| Step: 8
Training loss: 2.7876405715942383
Validation loss: 3.094529946645101

Epoch: 6| Step: 9
Training loss: 3.2925686836242676
Validation loss: 3.090709686279297

Epoch: 6| Step: 10
Training loss: 3.8852851390838623
Validation loss: 3.0869619051615396

Epoch: 6| Step: 11
Training loss: 3.202075242996216
Validation loss: 3.083368460337321

Epoch: 6| Step: 12
Training loss: 3.730377435684204
Validation loss: 3.080024758974711

Epoch: 6| Step: 13
Training loss: 3.5497007369995117
Validation loss: 3.077270189921061

Epoch: 32| Step: 0
Training loss: 3.8585658073425293
Validation loss: 3.0733715295791626

Epoch: 6| Step: 1
Training loss: 2.9609925746917725
Validation loss: 3.070052146911621

Epoch: 6| Step: 2
Training loss: 2.8255867958068848
Validation loss: 3.0666948159535727

Epoch: 6| Step: 3
Training loss: 3.538036823272705
Validation loss: 3.063108762105306

Epoch: 6| Step: 4
Training loss: 2.715284824371338
Validation loss: 3.060035546620687

Epoch: 6| Step: 5
Training loss: 3.7152791023254395
Validation loss: 3.0568469365437827

Epoch: 6| Step: 6
Training loss: 3.168938159942627
Validation loss: 3.053459048271179

Epoch: 6| Step: 7
Training loss: 2.7158024311065674
Validation loss: 3.0499470233917236

Epoch: 6| Step: 8
Training loss: 3.1223926544189453
Validation loss: 3.0468353430430093

Epoch: 6| Step: 9
Training loss: 3.2142741680145264
Validation loss: 3.0436903635660806

Epoch: 6| Step: 10
Training loss: 3.432340383529663
Validation loss: 3.0404602686564126

Epoch: 6| Step: 11
Training loss: 3.494454860687256
Validation loss: 3.0372369289398193

Epoch: 6| Step: 12
Training loss: 3.8000049591064453
Validation loss: 3.033870538075765

Epoch: 6| Step: 13
Training loss: 2.833651065826416
Validation loss: 3.030513644218445

Epoch: 33| Step: 0
Training loss: 2.8036060333251953
Validation loss: 3.026655395825704

Epoch: 6| Step: 1
Training loss: 4.819457054138184
Validation loss: 3.0234621365865073

Epoch: 6| Step: 2
Training loss: 2.149838447570801
Validation loss: 3.0193244218826294

Epoch: 6| Step: 3
Training loss: 2.9467406272888184
Validation loss: 3.0164190928141275

Epoch: 6| Step: 4
Training loss: 3.2491962909698486
Validation loss: 3.013070901234945

Epoch: 6| Step: 5
Training loss: 2.6891794204711914
Validation loss: 3.009963810443878

Epoch: 6| Step: 6
Training loss: 4.326343536376953
Validation loss: 3.0060909589131675

Epoch: 6| Step: 7
Training loss: 2.5632824897766113
Validation loss: 3.0028949975967407

Epoch: 6| Step: 8
Training loss: 2.8707923889160156
Validation loss: 2.9994447231292725

Epoch: 6| Step: 9
Training loss: 3.495154857635498
Validation loss: 2.9959760506947837

Epoch: 6| Step: 10
Training loss: 3.5103836059570312
Validation loss: 2.9922128915786743

Epoch: 6| Step: 11
Training loss: 3.014461040496826
Validation loss: 2.989049752553304

Epoch: 6| Step: 12
Training loss: 3.061819553375244
Validation loss: 2.9849678675333657

Epoch: 6| Step: 13
Training loss: 3.2938060760498047
Validation loss: 2.982972025871277

Epoch: 34| Step: 0
Training loss: 2.188802480697632
Validation loss: 2.9791645606358848

Epoch: 6| Step: 1
Training loss: 3.2961254119873047
Validation loss: 2.976008176803589

Epoch: 6| Step: 2
Training loss: 3.608806610107422
Validation loss: 2.972789208094279

Epoch: 6| Step: 3
Training loss: 3.4428629875183105
Validation loss: 2.9692861636479697

Epoch: 6| Step: 4
Training loss: 2.773790121078491
Validation loss: 2.964697241783142

Epoch: 6| Step: 5
Training loss: 3.2236673831939697
Validation loss: 2.961970806121826

Epoch: 6| Step: 6
Training loss: 3.288370132446289
Validation loss: 2.959231734275818

Epoch: 6| Step: 7
Training loss: 2.9950695037841797
Validation loss: 2.9551097551981607

Epoch: 6| Step: 8
Training loss: 3.0950841903686523
Validation loss: 2.9510079622268677

Epoch: 6| Step: 9
Training loss: 3.2007179260253906
Validation loss: 2.9493064880371094

Epoch: 6| Step: 10
Training loss: 4.506025314331055
Validation loss: 2.946053663889567

Epoch: 6| Step: 11
Training loss: 2.7907586097717285
Validation loss: 2.942069093386332

Epoch: 6| Step: 12
Training loss: 2.9266371726989746
Validation loss: 2.9387784401575723

Epoch: 6| Step: 13
Training loss: 2.873265504837036
Validation loss: 2.936944842338562

Epoch: 35| Step: 0
Training loss: 3.132582902908325
Validation loss: 2.9334967136383057

Epoch: 6| Step: 1
Training loss: 3.147695541381836
Validation loss: 2.930677056312561

Epoch: 6| Step: 2
Training loss: 3.8245041370391846
Validation loss: 2.9283350706100464

Epoch: 6| Step: 3
Training loss: 3.5395689010620117
Validation loss: 2.924199024836222

Epoch: 6| Step: 4
Training loss: 3.973238468170166
Validation loss: 2.9192238251368203

Epoch: 6| Step: 5
Training loss: 2.3873801231384277
Validation loss: 2.9185827175776162

Epoch: 6| Step: 6
Training loss: 3.5335240364074707
Validation loss: 2.9158690770467124

Epoch: 6| Step: 7
Training loss: 2.1886091232299805
Validation loss: 2.909444729487101

Epoch: 6| Step: 8
Training loss: 3.147900104522705
Validation loss: 2.9065585931142173

Epoch: 6| Step: 9
Training loss: 2.2432029247283936
Validation loss: 2.9036120573679605

Epoch: 6| Step: 10
Training loss: 3.501350164413452
Validation loss: 2.9003785053888955

Epoch: 6| Step: 11
Training loss: 2.3400163650512695
Validation loss: 2.898026943206787

Epoch: 6| Step: 12
Training loss: 2.6240923404693604
Validation loss: 2.8945807615915933

Epoch: 6| Step: 13
Training loss: 4.067852973937988
Validation loss: 2.891841411590576

Epoch: 36| Step: 0
Training loss: 3.6527113914489746
Validation loss: 2.8886972665786743

Epoch: 6| Step: 1
Training loss: 3.7189033031463623
Validation loss: 2.885682145754496

Epoch: 6| Step: 2
Training loss: 3.003404140472412
Validation loss: 2.8822197119394937

Epoch: 6| Step: 3
Training loss: 2.951533317565918
Validation loss: 2.8789572715759277

Epoch: 6| Step: 4
Training loss: 2.9085187911987305
Validation loss: 2.881394942601522

Epoch: 6| Step: 5
Training loss: 2.2700815200805664
Validation loss: 2.872669816017151

Epoch: 6| Step: 6
Training loss: 3.987584114074707
Validation loss: 2.872955600420634

Epoch: 6| Step: 7
Training loss: 3.2668838500976562
Validation loss: 2.8732762734095254

Epoch: 6| Step: 8
Training loss: 3.1549692153930664
Validation loss: 2.8749363819758096

Epoch: 6| Step: 9
Training loss: 2.280735969543457
Validation loss: 2.8693905671437583

Epoch: 6| Step: 10
Training loss: 2.9576730728149414
Validation loss: 2.8631794850031533

Epoch: 6| Step: 11
Training loss: 2.8381965160369873
Validation loss: 2.859920342763265

Epoch: 6| Step: 12
Training loss: 2.584944725036621
Validation loss: 2.8563477993011475

Epoch: 6| Step: 13
Training loss: 3.5759401321411133
Validation loss: 2.8563602765401206

Epoch: 37| Step: 0
Training loss: 3.663597822189331
Validation loss: 2.851822018623352

Epoch: 6| Step: 1
Training loss: 2.9015254974365234
Validation loss: 2.847580830256144

Epoch: 6| Step: 2
Training loss: 3.17282772064209
Validation loss: 2.845690886179606

Epoch: 6| Step: 3
Training loss: 3.121309280395508
Validation loss: 2.8419442176818848

Epoch: 6| Step: 4
Training loss: 2.7222518920898438
Validation loss: 2.850552042325338

Epoch: 6| Step: 5
Training loss: 3.4696884155273438
Validation loss: 2.8408580223719277

Epoch: 6| Step: 6
Training loss: 2.8188390731811523
Validation loss: 2.8370157877604165

Epoch: 6| Step: 7
Training loss: 3.1578054428100586
Validation loss: 2.8319645325342813

Epoch: 6| Step: 8
Training loss: 2.676072120666504
Validation loss: 2.8277740478515625

Epoch: 6| Step: 9
Training loss: 3.295039653778076
Validation loss: 2.8240256706873574

Epoch: 6| Step: 10
Training loss: 2.607527256011963
Validation loss: 2.8196171522140503

Epoch: 6| Step: 11
Training loss: 3.498736619949341
Validation loss: 2.816559592882792

Epoch: 6| Step: 12
Training loss: 2.4973814487457275
Validation loss: 2.8133952418963113

Epoch: 6| Step: 13
Training loss: 3.0045342445373535
Validation loss: 2.8093711535135903

Epoch: 38| Step: 0
Training loss: 2.811739444732666
Validation loss: 2.8066912094751992

Epoch: 6| Step: 1
Training loss: 3.1200687885284424
Validation loss: 2.803389072418213

Epoch: 6| Step: 2
Training loss: 2.873806953430176
Validation loss: 2.802541653315226

Epoch: 6| Step: 3
Training loss: 2.5763494968414307
Validation loss: 2.799205462137858

Epoch: 6| Step: 4
Training loss: 2.871764659881592
Validation loss: 2.7969338496526084

Epoch: 6| Step: 5
Training loss: 3.6835434436798096
Validation loss: 2.7928749322891235

Epoch: 6| Step: 6
Training loss: 1.731456995010376
Validation loss: 2.7897127866744995

Epoch: 6| Step: 7
Training loss: 3.1916046142578125
Validation loss: 2.7856289943059287

Epoch: 6| Step: 8
Training loss: 2.743093967437744
Validation loss: 2.7832955916722617

Epoch: 6| Step: 9
Training loss: 3.0588245391845703
Validation loss: 2.781144857406616

Epoch: 6| Step: 10
Training loss: 3.2322444915771484
Validation loss: 2.7743260065714517

Epoch: 6| Step: 11
Training loss: 3.546426296234131
Validation loss: 2.7746716141700745

Epoch: 6| Step: 12
Training loss: 2.898224353790283
Validation loss: 2.774327834447225

Epoch: 6| Step: 13
Training loss: 3.5848870277404785
Validation loss: 2.7945704460144043

Epoch: 39| Step: 0
Training loss: 3.0979971885681152
Validation loss: 2.827070116996765

Epoch: 6| Step: 1
Training loss: 2.9224343299865723
Validation loss: 2.799374302228292

Epoch: 6| Step: 2
Training loss: 2.969557762145996
Validation loss: 2.7604827086130777

Epoch: 6| Step: 3
Training loss: 2.933863401412964
Validation loss: 2.7570447524388633

Epoch: 6| Step: 4
Training loss: 2.7109665870666504
Validation loss: 2.7576218048731485

Epoch: 6| Step: 5
Training loss: 2.940471649169922
Validation loss: 2.7637919982274375

Epoch: 6| Step: 6
Training loss: 3.4012868404388428
Validation loss: 2.7745723327000937

Epoch: 6| Step: 7
Training loss: 3.0796151161193848
Validation loss: 2.7698272466659546

Epoch: 6| Step: 8
Training loss: 2.9139328002929688
Validation loss: 2.759137749671936

Epoch: 6| Step: 9
Training loss: 2.237293243408203
Validation loss: 2.7504965464274087

Epoch: 6| Step: 10
Training loss: 3.1355128288269043
Validation loss: 2.743083635965983

Epoch: 6| Step: 11
Training loss: 3.0800821781158447
Validation loss: 2.7396910587946572

Epoch: 6| Step: 12
Training loss: 3.008723735809326
Validation loss: 2.736178994178772

Epoch: 6| Step: 13
Training loss: 3.13238525390625
Validation loss: 2.7373530864715576

Epoch: 40| Step: 0
Training loss: 3.3604588508605957
Validation loss: 2.7338802417119346

Epoch: 6| Step: 1
Training loss: 2.832555055618286
Validation loss: 2.732174277305603

Epoch: 6| Step: 2
Training loss: 2.437944173812866
Validation loss: 2.730503042538961

Epoch: 6| Step: 3
Training loss: 3.2951345443725586
Validation loss: 2.729292154312134

Epoch: 6| Step: 4
Training loss: 2.8631911277770996
Validation loss: 2.72052538394928

Epoch: 6| Step: 5
Training loss: 2.830148220062256
Validation loss: 2.715414524078369

Epoch: 6| Step: 6
Training loss: 2.8760995864868164
Validation loss: 2.7077844540278115

Epoch: 6| Step: 7
Training loss: 2.882688045501709
Validation loss: 2.7046409845352173

Epoch: 6| Step: 8
Training loss: 2.9736855030059814
Validation loss: 2.7002223332722983

Epoch: 6| Step: 9
Training loss: 3.116743564605713
Validation loss: 2.699009895324707

Epoch: 6| Step: 10
Training loss: 3.238029956817627
Validation loss: 2.694559693336487

Epoch: 6| Step: 11
Training loss: 2.6288084983825684
Validation loss: 2.6933555205663047

Epoch: 6| Step: 12
Training loss: 3.0016422271728516
Validation loss: 2.689030726750692

Epoch: 6| Step: 13
Training loss: 2.555027484893799
Validation loss: 2.687257726987203

Epoch: 41| Step: 0
Training loss: 2.751514196395874
Validation loss: 2.6896015803019204

Epoch: 6| Step: 1
Training loss: 3.2972829341888428
Validation loss: 2.6871822675069175

Epoch: 6| Step: 2
Training loss: 2.83634352684021
Validation loss: 2.6792489290237427

Epoch: 6| Step: 3
Training loss: 3.1142282485961914
Validation loss: 2.674545685450236

Epoch: 6| Step: 4
Training loss: 3.2391743659973145
Validation loss: 2.6708786884943643

Epoch: 6| Step: 5
Training loss: 2.5165982246398926
Validation loss: 2.6682121753692627

Epoch: 6| Step: 6
Training loss: 2.6500892639160156
Validation loss: 2.6665759881337485

Epoch: 6| Step: 7
Training loss: 2.7656426429748535
Validation loss: 2.6640947262446084

Epoch: 6| Step: 8
Training loss: 2.891486883163452
Validation loss: 2.6611634492874146

Epoch: 6| Step: 9
Training loss: 2.4944229125976562
Validation loss: 2.65500017007192

Epoch: 6| Step: 10
Training loss: 2.1793882846832275
Validation loss: 2.6537187496821084

Epoch: 6| Step: 11
Training loss: 3.933135509490967
Validation loss: 2.6490428845087686

Epoch: 6| Step: 12
Training loss: 3.060480833053589
Validation loss: 2.649674654006958

Epoch: 6| Step: 13
Training loss: 2.4559526443481445
Validation loss: 2.6487189133961997

Epoch: 42| Step: 0
Training loss: 2.7603840827941895
Validation loss: 2.6455917755762735

Epoch: 6| Step: 1
Training loss: 3.262103796005249
Validation loss: 2.644742210706075

Epoch: 6| Step: 2
Training loss: 2.536411762237549
Validation loss: 2.6400610407193503

Epoch: 6| Step: 3
Training loss: 3.373883008956909
Validation loss: 2.6366191307703652

Epoch: 6| Step: 4
Training loss: 2.6183254718780518
Validation loss: 2.6368176142374673

Epoch: 6| Step: 5
Training loss: 2.1519598960876465
Validation loss: 2.639974276224772

Epoch: 6| Step: 6
Training loss: 3.1149866580963135
Validation loss: 2.6408401330312095

Epoch: 6| Step: 7
Training loss: 2.941743850708008
Validation loss: 2.635995348294576

Epoch: 6| Step: 8
Training loss: 3.0322322845458984
Validation loss: 2.627627670764923

Epoch: 6| Step: 9
Training loss: 3.2005653381347656
Validation loss: 2.6198463837305703

Epoch: 6| Step: 10
Training loss: 2.6881394386291504
Validation loss: 2.6159921487172446

Epoch: 6| Step: 11
Training loss: 2.753735065460205
Validation loss: 2.6115282773971558

Epoch: 6| Step: 12
Training loss: 2.8848280906677246
Validation loss: 2.6125847895940146

Epoch: 6| Step: 13
Training loss: 2.3517210483551025
Validation loss: 2.6178887685139975

Epoch: 43| Step: 0
Training loss: 2.8702194690704346
Validation loss: 2.6137781143188477

Epoch: 6| Step: 1
Training loss: 2.3669872283935547
Validation loss: 2.603060523668925

Epoch: 6| Step: 2
Training loss: 2.506800889968872
Validation loss: 2.5954308112462363

Epoch: 6| Step: 3
Training loss: 3.4304299354553223
Validation loss: 2.592713256676992

Epoch: 6| Step: 4
Training loss: 3.1347203254699707
Validation loss: 2.590980132420858

Epoch: 6| Step: 5
Training loss: 2.8644418716430664
Validation loss: 2.585982084274292

Epoch: 6| Step: 6
Training loss: 2.705606460571289
Validation loss: 2.5831671555836997

Epoch: 6| Step: 7
Training loss: 2.485896587371826
Validation loss: 2.580659548441569

Epoch: 6| Step: 8
Training loss: 1.9474996328353882
Validation loss: 2.5822014013926187

Epoch: 6| Step: 9
Training loss: 3.5467207431793213
Validation loss: 2.582214832305908

Epoch: 6| Step: 10
Training loss: 2.6629750728607178
Validation loss: 2.5817606449127197

Epoch: 6| Step: 11
Training loss: 2.6065540313720703
Validation loss: 2.575583060582479

Epoch: 6| Step: 12
Training loss: 2.572323799133301
Validation loss: 2.5687021215756736

Epoch: 6| Step: 13
Training loss: 3.2717297077178955
Validation loss: 2.5608807802200317

Epoch: 44| Step: 0
Training loss: 2.5375211238861084
Validation loss: 2.559807618459066

Epoch: 6| Step: 1
Training loss: 3.279796600341797
Validation loss: 2.555836021900177

Epoch: 6| Step: 2
Training loss: 2.9028549194335938
Validation loss: 2.5570351084073386

Epoch: 6| Step: 3
Training loss: 2.216017484664917
Validation loss: 2.553893208503723

Epoch: 6| Step: 4
Training loss: 3.0152711868286133
Validation loss: 2.5532259742418923

Epoch: 6| Step: 5
Training loss: 3.082791805267334
Validation loss: 2.546044667561849

Epoch: 6| Step: 6
Training loss: 2.313783645629883
Validation loss: 2.545417229334513

Epoch: 6| Step: 7
Training loss: 3.055025100708008
Validation loss: 2.544869581858317

Epoch: 6| Step: 8
Training loss: 3.170839786529541
Validation loss: 2.5430726607640586

Epoch: 6| Step: 9
Training loss: 2.5446360111236572
Validation loss: 2.540286660194397

Epoch: 6| Step: 10
Training loss: 2.7409095764160156
Validation loss: 2.532934625943502

Epoch: 6| Step: 11
Training loss: 2.737694025039673
Validation loss: 2.533207654953003

Epoch: 6| Step: 12
Training loss: 2.763162136077881
Validation loss: 2.5293007294336953

Epoch: 6| Step: 13
Training loss: 1.9425915479660034
Validation loss: 2.527100125948588

Epoch: 45| Step: 0
Training loss: 3.0094127655029297
Validation loss: 2.5292371114095054

Epoch: 6| Step: 1
Training loss: 2.7989919185638428
Validation loss: 2.5330309867858887

Epoch: 6| Step: 2
Training loss: 2.7308568954467773
Validation loss: 2.5293631553649902

Epoch: 6| Step: 3
Training loss: 3.3139801025390625
Validation loss: 2.531062682469686

Epoch: 6| Step: 4
Training loss: 2.0460166931152344
Validation loss: 2.5246830383936563

Epoch: 6| Step: 5
Training loss: 2.4990806579589844
Validation loss: 2.5227877696355185

Epoch: 6| Step: 6
Training loss: 3.002332925796509
Validation loss: 2.518860141436259

Epoch: 6| Step: 7
Training loss: 2.68654203414917
Validation loss: 2.5130785703659058

Epoch: 6| Step: 8
Training loss: 2.924391508102417
Validation loss: 2.5070632696151733

Epoch: 6| Step: 9
Training loss: 2.710557222366333
Validation loss: 2.505322058995565

Epoch: 6| Step: 10
Training loss: 3.0757155418395996
Validation loss: 2.5027615626653037

Epoch: 6| Step: 11
Training loss: 2.1637630462646484
Validation loss: 2.5045929153760276

Epoch: 6| Step: 12
Training loss: 2.8119425773620605
Validation loss: 2.495692233244578

Epoch: 6| Step: 13
Training loss: 2.080242156982422
Validation loss: 2.4911916653315225

Epoch: 46| Step: 0
Training loss: 2.561232566833496
Validation loss: 2.4877782265345254

Epoch: 6| Step: 1
Training loss: 2.4628701210021973
Validation loss: 2.480579694112142

Epoch: 6| Step: 2
Training loss: 2.676804780960083
Validation loss: 2.4770434697469077

Epoch: 6| Step: 3
Training loss: 3.5462498664855957
Validation loss: 2.478221853574117

Epoch: 6| Step: 4
Training loss: 2.8649957180023193
Validation loss: 2.4720759789148965

Epoch: 6| Step: 5
Training loss: 2.475215435028076
Validation loss: 2.47061026096344

Epoch: 6| Step: 6
Training loss: 2.857311725616455
Validation loss: 2.4680800437927246

Epoch: 6| Step: 7
Training loss: 3.227372646331787
Validation loss: 2.4640398422876992

Epoch: 6| Step: 8
Training loss: 2.891265630722046
Validation loss: 2.4646318356196084

Epoch: 6| Step: 9
Training loss: 2.268406867980957
Validation loss: 2.462246855099996

Epoch: 6| Step: 10
Training loss: 2.2426791191101074
Validation loss: 2.457618474960327

Epoch: 6| Step: 11
Training loss: 2.746267557144165
Validation loss: 2.4604196548461914

Epoch: 6| Step: 12
Training loss: 2.290815830230713
Validation loss: 2.458905339241028

Epoch: 6| Step: 13
Training loss: 2.061842918395996
Validation loss: 2.449784199396769

Epoch: 47| Step: 0
Training loss: 3.1822564601898193
Validation loss: 2.4478041330973306

Epoch: 6| Step: 1
Training loss: 3.1236958503723145
Validation loss: 2.44963276386261

Epoch: 6| Step: 2
Training loss: 2.391228675842285
Validation loss: 2.4440411726633706

Epoch: 6| Step: 3
Training loss: 2.726850986480713
Validation loss: 2.4352603753407798

Epoch: 6| Step: 4
Training loss: 2.8301897048950195
Validation loss: 2.4303718407948813

Epoch: 6| Step: 5
Training loss: 2.115847110748291
Validation loss: 2.430940786997477

Epoch: 6| Step: 6
Training loss: 2.067084312438965
Validation loss: 2.4260645707448325

Epoch: 6| Step: 7
Training loss: 2.3304309844970703
Validation loss: 2.428597946961721

Epoch: 6| Step: 8
Training loss: 2.750885486602783
Validation loss: 2.421765168507894

Epoch: 6| Step: 9
Training loss: 2.708167552947998
Validation loss: 2.4180369774500527

Epoch: 6| Step: 10
Training loss: 2.718843460083008
Validation loss: 2.4172572692235312

Epoch: 6| Step: 11
Training loss: 2.4620859622955322
Validation loss: 2.4105425278345742

Epoch: 6| Step: 12
Training loss: 2.8489365577697754
Validation loss: 2.4127363761266074

Epoch: 6| Step: 13
Training loss: 2.304985523223877
Validation loss: 2.4124309619267783

Epoch: 48| Step: 0
Training loss: 2.378261089324951
Validation loss: 2.400955319404602

Epoch: 6| Step: 1
Training loss: 2.862600326538086
Validation loss: 2.4023080666859946

Epoch: 6| Step: 2
Training loss: 2.0667331218719482
Validation loss: 2.401715795199076

Epoch: 6| Step: 3
Training loss: 2.040408134460449
Validation loss: 2.3969231446584067

Epoch: 6| Step: 4
Training loss: 2.4646856784820557
Validation loss: 2.391821722189585

Epoch: 6| Step: 5
Training loss: 2.5312163829803467
Validation loss: 2.395323157310486

Epoch: 6| Step: 6
Training loss: 2.7333765029907227
Validation loss: 2.390408436457316

Epoch: 6| Step: 7
Training loss: 3.2221169471740723
Validation loss: 2.3942314783732095

Epoch: 6| Step: 8
Training loss: 2.204385995864868
Validation loss: 2.384660800298055

Epoch: 6| Step: 9
Training loss: 2.8322231769561768
Validation loss: 2.3812930583953857

Epoch: 6| Step: 10
Training loss: 2.5056509971618652
Validation loss: 2.377777099609375

Epoch: 6| Step: 11
Training loss: 2.6789941787719727
Validation loss: 2.3725518186887107

Epoch: 6| Step: 12
Training loss: 2.8159422874450684
Validation loss: 2.3718525966008506

Epoch: 6| Step: 13
Training loss: 2.5361390113830566
Validation loss: 2.369380752245585

Epoch: 49| Step: 0
Training loss: 2.4915218353271484
Validation loss: 2.371195912361145

Epoch: 6| Step: 1
Training loss: 2.2326526641845703
Validation loss: 2.373180111249288

Epoch: 6| Step: 2
Training loss: 2.7361416816711426
Validation loss: 2.4029146830240884

Epoch: 6| Step: 3
Training loss: 2.442493200302124
Validation loss: 2.3894285758336387

Epoch: 6| Step: 4
Training loss: 2.8270740509033203
Validation loss: 2.36408539613088

Epoch: 6| Step: 5
Training loss: 2.4992642402648926
Validation loss: 2.3517070412635803

Epoch: 6| Step: 6
Training loss: 2.159083843231201
Validation loss: 2.35511322816213

Epoch: 6| Step: 7
Training loss: 3.1446194648742676
Validation loss: 2.3511205911636353

Epoch: 6| Step: 8
Training loss: 2.1835598945617676
Validation loss: 2.3487926522890725

Epoch: 6| Step: 9
Training loss: 2.605358839035034
Validation loss: 2.343465189139048

Epoch: 6| Step: 10
Training loss: 2.40303897857666
Validation loss: 2.3434408704439798

Epoch: 6| Step: 11
Training loss: 2.256535768508911
Validation loss: 2.3403597275416055

Epoch: 6| Step: 12
Training loss: 2.829464912414551
Validation loss: 2.3437626361846924

Epoch: 6| Step: 13
Training loss: 2.5930089950561523
Validation loss: 2.336018900076548

Epoch: 50| Step: 0
Training loss: 3.080963134765625
Validation loss: 2.3330134948094687

Epoch: 6| Step: 1
Training loss: 1.949708104133606
Validation loss: 2.336222489674886

Epoch: 6| Step: 2
Training loss: 3.055936336517334
Validation loss: 2.3302887280782065

Epoch: 6| Step: 3
Training loss: 2.6978297233581543
Validation loss: 2.325466593106588

Epoch: 6| Step: 4
Training loss: 2.2288756370544434
Validation loss: 2.3186463912328086

Epoch: 6| Step: 5
Training loss: 2.0062992572784424
Validation loss: 2.328243891398112

Epoch: 6| Step: 6
Training loss: 3.2742810249328613
Validation loss: 2.317766567071279

Epoch: 6| Step: 7
Training loss: 1.8918296098709106
Validation loss: 2.316255211830139

Epoch: 6| Step: 8
Training loss: 2.090946912765503
Validation loss: 2.3142693638801575

Epoch: 6| Step: 9
Training loss: 2.689000368118286
Validation loss: 2.31106436252594

Epoch: 6| Step: 10
Training loss: 2.049808979034424
Validation loss: 2.311525523662567

Epoch: 6| Step: 11
Training loss: 2.4305977821350098
Validation loss: 2.3147236506144204

Epoch: 6| Step: 12
Training loss: 2.3081183433532715
Validation loss: 2.3117608030637107

Epoch: 6| Step: 13
Training loss: 3.1956048011779785
Validation loss: 2.3089849948883057

Epoch: 51| Step: 0
Training loss: 2.8278281688690186
Validation loss: 2.303533355394999

Epoch: 6| Step: 1
Training loss: 2.8141589164733887
Validation loss: 2.3052902817726135

Epoch: 6| Step: 2
Training loss: 2.1590490341186523
Validation loss: 2.2996291319529214

Epoch: 6| Step: 3
Training loss: 2.9653210639953613
Validation loss: 2.2954532504081726

Epoch: 6| Step: 4
Training loss: 2.535322666168213
Validation loss: 2.2894717852274575

Epoch: 6| Step: 5
Training loss: 1.8122330904006958
Validation loss: 2.2901121973991394

Epoch: 6| Step: 6
Training loss: 2.878628730773926
Validation loss: 2.2846485575040183

Epoch: 6| Step: 7
Training loss: 1.7068593502044678
Validation loss: 2.2855637470881143

Epoch: 6| Step: 8
Training loss: 2.7394585609436035
Validation loss: 2.2810292641321817

Epoch: 6| Step: 9
Training loss: 2.437223434448242
Validation loss: 2.2849403818448386

Epoch: 6| Step: 10
Training loss: 2.131746768951416
Validation loss: 2.2721186876296997

Epoch: 6| Step: 11
Training loss: 2.903977870941162
Validation loss: 2.2747091253598533

Epoch: 6| Step: 12
Training loss: 2.2344651222229004
Validation loss: 2.276352564493815

Epoch: 6| Step: 13
Training loss: 2.072946071624756
Validation loss: 2.2690210739771524

Epoch: 52| Step: 0
Training loss: 2.5036988258361816
Validation loss: 2.26811691125234

Epoch: 6| Step: 1
Training loss: 2.5228397846221924
Validation loss: 2.276662528514862

Epoch: 6| Step: 2
Training loss: 2.6622121334075928
Validation loss: 2.263657788435618

Epoch: 6| Step: 3
Training loss: 2.294473171234131
Validation loss: 2.263534982999166

Epoch: 6| Step: 4
Training loss: 2.634833812713623
Validation loss: 2.258821646372477

Epoch: 6| Step: 5
Training loss: 2.1423699855804443
Validation loss: 2.2569799423217773

Epoch: 6| Step: 6
Training loss: 2.41580867767334
Validation loss: 2.2621454199155173

Epoch: 6| Step: 7
Training loss: 2.190135955810547
Validation loss: 2.261790136496226

Epoch: 6| Step: 8
Training loss: 1.8351536989212036
Validation loss: 2.2623236179351807

Epoch: 6| Step: 9
Training loss: 2.8528051376342773
Validation loss: 2.262115021546682

Epoch: 6| Step: 10
Training loss: 2.385718584060669
Validation loss: 2.26133131980896

Epoch: 6| Step: 11
Training loss: 1.992934226989746
Validation loss: 2.257800340652466

Epoch: 6| Step: 12
Training loss: 2.5780837535858154
Validation loss: 2.249098539352417

Epoch: 6| Step: 13
Training loss: 3.073246479034424
Validation loss: 2.2425907452901206

Epoch: 53| Step: 0
Training loss: 1.8803274631500244
Validation loss: 2.2344346046447754

Epoch: 6| Step: 1
Training loss: 3.1182918548583984
Validation loss: 2.23100753625234

Epoch: 6| Step: 2
Training loss: 3.3155946731567383
Validation loss: 2.2310179074605307

Epoch: 6| Step: 3
Training loss: 2.2290124893188477
Validation loss: 2.2323832710584006

Epoch: 6| Step: 4
Training loss: 2.481954336166382
Validation loss: 2.2227611541748047

Epoch: 6| Step: 5
Training loss: 2.3965630531311035
Validation loss: 2.2306623458862305

Epoch: 6| Step: 6
Training loss: 1.793289065361023
Validation loss: 2.242749253908793

Epoch: 6| Step: 7
Training loss: 3.2835373878479004
Validation loss: 2.2443001667658486

Epoch: 6| Step: 8
Training loss: 2.476390838623047
Validation loss: 2.2198569774627686

Epoch: 6| Step: 9
Training loss: 2.4443013668060303
Validation loss: 2.2154282530148826

Epoch: 6| Step: 10
Training loss: 1.7921998500823975
Validation loss: 2.2238766153653464

Epoch: 6| Step: 11
Training loss: 1.8995323181152344
Validation loss: 2.2063294450441995

Epoch: 6| Step: 12
Training loss: 2.0826518535614014
Validation loss: 2.2074937423070273

Epoch: 6| Step: 13
Training loss: 2.0903239250183105
Validation loss: 2.2043432195981345

Epoch: 54| Step: 0
Training loss: 2.6597423553466797
Validation loss: 2.2058977286020913

Epoch: 6| Step: 1
Training loss: 1.7436559200286865
Validation loss: 2.207609494527181

Epoch: 6| Step: 2
Training loss: 2.3616716861724854
Validation loss: 2.2050459583600364

Epoch: 6| Step: 3
Training loss: 1.8933069705963135
Validation loss: 2.204856793085734

Epoch: 6| Step: 4
Training loss: 2.4164834022521973
Validation loss: 2.2019479076067605

Epoch: 6| Step: 5
Training loss: 2.462895393371582
Validation loss: 2.2045429150263467

Epoch: 6| Step: 6
Training loss: 2.3830838203430176
Validation loss: 2.203520715236664

Epoch: 6| Step: 7
Training loss: 1.932307243347168
Validation loss: 2.2053197423617044

Epoch: 6| Step: 8
Training loss: 2.7285051345825195
Validation loss: 2.190768043200175

Epoch: 6| Step: 9
Training loss: 2.535606622695923
Validation loss: 2.191158135732015

Epoch: 6| Step: 10
Training loss: 2.9057741165161133
Validation loss: 2.1857267220815024

Epoch: 6| Step: 11
Training loss: 1.4851611852645874
Validation loss: 2.1839948097864785

Epoch: 6| Step: 12
Training loss: 2.4228172302246094
Validation loss: 2.19755228360494

Epoch: 6| Step: 13
Training loss: 2.9600727558135986
Validation loss: 2.1985601782798767

Epoch: 55| Step: 0
Training loss: 2.423556327819824
Validation loss: 2.1930346488952637

Epoch: 6| Step: 1
Training loss: 2.6390979290008545
Validation loss: 2.1929256518681846

Epoch: 6| Step: 2
Training loss: 2.337545871734619
Validation loss: 2.191740175088247

Epoch: 6| Step: 3
Training loss: 2.457670211791992
Validation loss: 2.1810561219851174

Epoch: 6| Step: 4
Training loss: 1.6379823684692383
Validation loss: 2.179848333199819

Epoch: 6| Step: 5
Training loss: 2.7050371170043945
Validation loss: 2.1794023513793945

Epoch: 6| Step: 6
Training loss: 2.141979694366455
Validation loss: 2.1739769776662192

Epoch: 6| Step: 7
Training loss: 2.435002326965332
Validation loss: 2.1751731634140015

Epoch: 6| Step: 8
Training loss: 1.8826038837432861
Validation loss: 2.170730193456014

Epoch: 6| Step: 9
Training loss: 2.3058552742004395
Validation loss: 2.169106662273407

Epoch: 6| Step: 10
Training loss: 2.135272979736328
Validation loss: 2.1790873209635415

Epoch: 6| Step: 11
Training loss: 2.395629405975342
Validation loss: 2.184760888417562

Epoch: 6| Step: 12
Training loss: 2.783729076385498
Validation loss: 2.2163038849830627

Epoch: 6| Step: 13
Training loss: 2.599625587463379
Validation loss: 2.239012360572815

Epoch: 56| Step: 0
Training loss: 2.1173062324523926
Validation loss: 2.1978518962860107

Epoch: 6| Step: 1
Training loss: 1.9007731676101685
Validation loss: 2.1925031741460166

Epoch: 6| Step: 2
Training loss: 2.592978000640869
Validation loss: 2.159836530685425

Epoch: 6| Step: 3
Training loss: 1.5953526496887207
Validation loss: 2.1559346516927085

Epoch: 6| Step: 4
Training loss: 2.5848684310913086
Validation loss: 2.1577154994010925

Epoch: 6| Step: 5
Training loss: 2.683398723602295
Validation loss: 2.1590325832366943

Epoch: 6| Step: 6
Training loss: 2.434953451156616
Validation loss: 2.161747932434082

Epoch: 6| Step: 7
Training loss: 2.075953960418701
Validation loss: 2.163318316141764

Epoch: 6| Step: 8
Training loss: 2.738945722579956
Validation loss: 2.161703368028005

Epoch: 6| Step: 9
Training loss: 2.311880111694336
Validation loss: 2.165861447652181

Epoch: 6| Step: 10
Training loss: 2.745500087738037
Validation loss: 2.158708373705546

Epoch: 6| Step: 11
Training loss: 2.6796298027038574
Validation loss: 2.155041297276815

Epoch: 6| Step: 12
Training loss: 1.9621376991271973
Validation loss: 2.156029224395752

Epoch: 6| Step: 13
Training loss: 2.08156156539917
Validation loss: 2.1592880288759866

Epoch: 57| Step: 0
Training loss: 1.9009774923324585
Validation loss: 2.1617656151453652

Epoch: 6| Step: 1
Training loss: 2.235680103302002
Validation loss: 2.15799887975057

Epoch: 6| Step: 2
Training loss: 2.5309884548187256
Validation loss: 2.1578285296758017

Epoch: 6| Step: 3
Training loss: 1.7077078819274902
Validation loss: 2.14943790435791

Epoch: 6| Step: 4
Training loss: 2.543025255203247
Validation loss: 2.155381123224894

Epoch: 6| Step: 5
Training loss: 2.662982702255249
Validation loss: 2.1456525127092996

Epoch: 6| Step: 6
Training loss: 2.2205889225006104
Validation loss: 2.139749228954315

Epoch: 6| Step: 7
Training loss: 2.2464869022369385
Validation loss: 2.1383155981699624

Epoch: 6| Step: 8
Training loss: 2.7514901161193848
Validation loss: 2.1561210552851358

Epoch: 6| Step: 9
Training loss: 2.431734561920166
Validation loss: 2.1714362700780234

Epoch: 6| Step: 10
Training loss: 1.8604204654693604
Validation loss: 2.19182018438975

Epoch: 6| Step: 11
Training loss: 2.3660712242126465
Validation loss: 2.1533963878949485

Epoch: 6| Step: 12
Training loss: 2.41458797454834
Validation loss: 2.1677782932917276

Epoch: 6| Step: 13
Training loss: 2.5672054290771484
Validation loss: 2.1468849182128906

Epoch: 58| Step: 0
Training loss: 2.3617947101593018
Validation loss: 2.1290821631749473

Epoch: 6| Step: 1
Training loss: 2.624255418777466
Validation loss: 2.117490271727244

Epoch: 6| Step: 2
Training loss: 2.347883701324463
Validation loss: 2.132879157861074

Epoch: 6| Step: 3
Training loss: 2.429302215576172
Validation loss: 2.1363651156425476

Epoch: 6| Step: 4
Training loss: 2.4108951091766357
Validation loss: 2.1458665132522583

Epoch: 6| Step: 5
Training loss: 2.2942333221435547
Validation loss: 2.1564886768658957

Epoch: 6| Step: 6
Training loss: 2.8792943954467773
Validation loss: 2.1584091981252036

Epoch: 6| Step: 7
Training loss: 1.9312458038330078
Validation loss: 2.1673171321551004

Epoch: 6| Step: 8
Training loss: 2.9657554626464844
Validation loss: 2.1604599356651306

Epoch: 6| Step: 9
Training loss: 1.6245582103729248
Validation loss: 2.159774343172709

Epoch: 6| Step: 10
Training loss: 1.8638496398925781
Validation loss: 2.1662973761558533

Epoch: 6| Step: 11
Training loss: 2.644643783569336
Validation loss: 2.1514896551767984

Epoch: 6| Step: 12
Training loss: 1.9844130277633667
Validation loss: 2.1270819902420044

Epoch: 6| Step: 13
Training loss: 2.0049619674682617
Validation loss: 2.1151180466016135

Epoch: 59| Step: 0
Training loss: 2.3596818447113037
Validation loss: 2.116317629814148

Epoch: 6| Step: 1
Training loss: 2.0702054500579834
Validation loss: 2.106931428114573

Epoch: 6| Step: 2
Training loss: 2.1369171142578125
Validation loss: 2.105520705382029

Epoch: 6| Step: 3
Training loss: 2.656345844268799
Validation loss: 2.104821960131327

Epoch: 6| Step: 4
Training loss: 2.224212646484375
Validation loss: 2.1110577980677285

Epoch: 6| Step: 5
Training loss: 1.9770491123199463
Validation loss: 2.1121631860733032

Epoch: 6| Step: 6
Training loss: 2.2731943130493164
Validation loss: 2.1404733459154763

Epoch: 6| Step: 7
Training loss: 2.297745943069458
Validation loss: 2.1605996092160544

Epoch: 6| Step: 8
Training loss: 2.458521604537964
Validation loss: 2.1315064430236816

Epoch: 6| Step: 9
Training loss: 2.495364189147949
Validation loss: 2.127667705217997

Epoch: 6| Step: 10
Training loss: 2.1452205181121826
Validation loss: 2.1132895747820535

Epoch: 6| Step: 11
Training loss: 2.298569679260254
Validation loss: 2.1013392408688865

Epoch: 6| Step: 12
Training loss: 1.9356082677841187
Validation loss: 2.085064649581909

Epoch: 6| Step: 13
Training loss: 2.259881019592285
Validation loss: 2.0950130820274353

Epoch: 60| Step: 0
Training loss: 2.596182107925415
Validation loss: 2.0901732047398887

Epoch: 6| Step: 1
Training loss: 1.8222965002059937
Validation loss: 2.0943044424057007

Epoch: 6| Step: 2
Training loss: 1.9667445421218872
Validation loss: 2.0908535917599997

Epoch: 6| Step: 3
Training loss: 2.8759331703186035
Validation loss: 2.0967646837234497

Epoch: 6| Step: 4
Training loss: 1.661750078201294
Validation loss: 2.1008033752441406

Epoch: 6| Step: 5
Training loss: 2.500586986541748
Validation loss: 2.101996898651123

Epoch: 6| Step: 6
Training loss: 3.316709041595459
Validation loss: 2.1014777024586997

Epoch: 6| Step: 7
Training loss: 1.4531514644622803
Validation loss: 2.0972320238749185

Epoch: 6| Step: 8
Training loss: 2.293633222579956
Validation loss: 2.098625580469767

Epoch: 6| Step: 9
Training loss: 2.099020481109619
Validation loss: 2.093654374281565

Epoch: 6| Step: 10
Training loss: 2.2435529232025146
Validation loss: 2.08881284793218

Epoch: 6| Step: 11
Training loss: 2.5510663986206055
Validation loss: 2.0819207628568015

Epoch: 6| Step: 12
Training loss: 2.5602455139160156
Validation loss: 2.0833113392194114

Epoch: 6| Step: 13
Training loss: 1.796415090560913
Validation loss: 2.078291098276774

Epoch: 61| Step: 0
Training loss: 2.9605789184570312
Validation loss: 2.0706653396288552

Epoch: 6| Step: 1
Training loss: 2.1876416206359863
Validation loss: 2.0809357166290283

Epoch: 6| Step: 2
Training loss: 1.5110551118850708
Validation loss: 2.0981183449427285

Epoch: 6| Step: 3
Training loss: 2.180602550506592
Validation loss: 2.1305262446403503

Epoch: 6| Step: 4
Training loss: 2.209597587585449
Validation loss: 2.1425601045290628

Epoch: 6| Step: 5
Training loss: 2.125063896179199
Validation loss: 2.1118143598238626

Epoch: 6| Step: 6
Training loss: 2.326695442199707
Validation loss: 2.0868303577105203

Epoch: 6| Step: 7
Training loss: 2.5650782585144043
Validation loss: 2.085431694984436

Epoch: 6| Step: 8
Training loss: 2.3720908164978027
Validation loss: 2.077514330546061

Epoch: 6| Step: 9
Training loss: 2.6584949493408203
Validation loss: 2.0705056389172873

Epoch: 6| Step: 10
Training loss: 2.542747735977173
Validation loss: 2.062864820162455

Epoch: 6| Step: 11
Training loss: 2.2276206016540527
Validation loss: 2.070177733898163

Epoch: 6| Step: 12
Training loss: 1.663778305053711
Validation loss: 2.082637588183085

Epoch: 6| Step: 13
Training loss: 1.9750986099243164
Validation loss: 2.0793393651644387

Epoch: 62| Step: 0
Training loss: 2.3505859375
Validation loss: 2.0841546654701233

Epoch: 6| Step: 1
Training loss: 2.7701282501220703
Validation loss: 2.0836251974105835

Epoch: 6| Step: 2
Training loss: 2.3949859142303467
Validation loss: 2.085688312848409

Epoch: 6| Step: 3
Training loss: 2.1926612854003906
Validation loss: 2.087667445341746

Epoch: 6| Step: 4
Training loss: 1.6786797046661377
Validation loss: 2.086694339911143

Epoch: 6| Step: 5
Training loss: 2.65889048576355
Validation loss: 2.084345599015554

Epoch: 6| Step: 6
Training loss: 2.6866602897644043
Validation loss: 2.078054924805959

Epoch: 6| Step: 7
Training loss: 1.9010436534881592
Validation loss: 2.085424304008484

Epoch: 6| Step: 8
Training loss: 1.577807903289795
Validation loss: 2.0811899503072104

Epoch: 6| Step: 9
Training loss: 2.625068187713623
Validation loss: 2.073436737060547

Epoch: 6| Step: 10
Training loss: 2.2392592430114746
Validation loss: 2.0716047088305154

Epoch: 6| Step: 11
Training loss: 2.13889741897583
Validation loss: 2.0732356905937195

Epoch: 6| Step: 12
Training loss: 1.8896673917770386
Validation loss: 2.0660999019940696

Epoch: 6| Step: 13
Training loss: 2.4583067893981934
Validation loss: 2.05967785914739

Epoch: 63| Step: 0
Training loss: 1.8039413690567017
Validation loss: 2.0514425237973533

Epoch: 6| Step: 1
Training loss: 2.0532195568084717
Validation loss: 2.0726714531580606

Epoch: 6| Step: 2
Training loss: 2.1286425590515137
Validation loss: 2.091241717338562

Epoch: 6| Step: 3
Training loss: 2.720393657684326
Validation loss: 2.1037106116612754

Epoch: 6| Step: 4
Training loss: 2.274090528488159
Validation loss: 2.1306942900021872

Epoch: 6| Step: 5
Training loss: 2.1573638916015625
Validation loss: 2.141384561856588

Epoch: 6| Step: 6
Training loss: 2.240347385406494
Validation loss: 2.141000250975291

Epoch: 6| Step: 7
Training loss: 2.1967971324920654
Validation loss: 2.131642202536265

Epoch: 6| Step: 8
Training loss: 3.113276243209839
Validation loss: 2.0997645258903503

Epoch: 6| Step: 9
Training loss: 2.3259291648864746
Validation loss: 2.069068451722463

Epoch: 6| Step: 10
Training loss: 2.2592058181762695
Validation loss: 2.0576618909835815

Epoch: 6| Step: 11
Training loss: 2.418684244155884
Validation loss: 2.0489587982495627

Epoch: 6| Step: 12
Training loss: 1.8022658824920654
Validation loss: 2.062641660372416

Epoch: 6| Step: 13
Training loss: 2.0557005405426025
Validation loss: 2.07064680258433

Epoch: 64| Step: 0
Training loss: 2.2487387657165527
Validation loss: 2.0766933461030326

Epoch: 6| Step: 1
Training loss: 2.656667470932007
Validation loss: 2.0860084692637124

Epoch: 6| Step: 2
Training loss: 2.0067689418792725
Validation loss: 2.093981464703878

Epoch: 6| Step: 3
Training loss: 2.0269222259521484
Validation loss: 2.095082918802897

Epoch: 6| Step: 4
Training loss: 1.8672701120376587
Validation loss: 2.0967097878456116

Epoch: 6| Step: 5
Training loss: 2.4310555458068848
Validation loss: 2.0969797571500144

Epoch: 6| Step: 6
Training loss: 2.6550614833831787
Validation loss: 2.0815593600273132

Epoch: 6| Step: 7
Training loss: 2.231934070587158
Validation loss: 2.0760224064191184

Epoch: 6| Step: 8
Training loss: 2.469388008117676
Validation loss: 2.0759153962135315

Epoch: 6| Step: 9
Training loss: 1.940379023551941
Validation loss: 2.0693397323290506

Epoch: 6| Step: 10
Training loss: 2.410053253173828
Validation loss: 2.070299506187439

Epoch: 6| Step: 11
Training loss: 2.554595470428467
Validation loss: 2.0615235567092896

Epoch: 6| Step: 12
Training loss: 2.105729103088379
Validation loss: 2.0642648140589395

Epoch: 6| Step: 13
Training loss: 2.1181793212890625
Validation loss: 2.0575901667277017

Epoch: 65| Step: 0
Training loss: 2.139296531677246
Validation loss: 2.059611678123474

Epoch: 6| Step: 1
Training loss: 2.7434678077697754
Validation loss: 2.050412654876709

Epoch: 6| Step: 2
Training loss: 2.1011579036712646
Validation loss: 2.0385350584983826

Epoch: 6| Step: 3
Training loss: 2.1323978900909424
Validation loss: 2.040079971154531

Epoch: 6| Step: 4
Training loss: 2.6445562839508057
Validation loss: 2.034104307492574

Epoch: 6| Step: 5
Training loss: 2.008361577987671
Validation loss: 2.0284719467163086

Epoch: 6| Step: 6
Training loss: 2.200756072998047
Validation loss: 2.0286445220311484

Epoch: 6| Step: 7
Training loss: 1.8801326751708984
Validation loss: 2.0581347147623696

Epoch: 6| Step: 8
Training loss: 2.6545872688293457
Validation loss: 2.073987583319346

Epoch: 6| Step: 9
Training loss: 1.8042627573013306
Validation loss: 2.080385466416677

Epoch: 6| Step: 10
Training loss: 2.6259922981262207
Validation loss: 2.082628866036733

Epoch: 6| Step: 11
Training loss: 2.293031692504883
Validation loss: 2.0625970164934793

Epoch: 6| Step: 12
Training loss: 1.7361754179000854
Validation loss: 2.050034681955973

Epoch: 6| Step: 13
Training loss: 2.37730073928833
Validation loss: 2.0384968320528665

Epoch: 66| Step: 0
Training loss: 1.819338321685791
Validation loss: 2.034741163253784

Epoch: 6| Step: 1
Training loss: 1.5567395687103271
Validation loss: 2.0329004724820456

Epoch: 6| Step: 2
Training loss: 2.372715950012207
Validation loss: 2.0208993752797446

Epoch: 6| Step: 3
Training loss: 2.613616943359375
Validation loss: 2.023885707060496

Epoch: 6| Step: 4
Training loss: 2.001115322113037
Validation loss: 2.023152490456899

Epoch: 6| Step: 5
Training loss: 1.9603947401046753
Validation loss: 2.026287078857422

Epoch: 6| Step: 6
Training loss: 2.438336133956909
Validation loss: 2.0239081978797913

Epoch: 6| Step: 7
Training loss: 1.8951712846755981
Validation loss: 2.022154529889425

Epoch: 6| Step: 8
Training loss: 2.688835382461548
Validation loss: 2.0263631939888

Epoch: 6| Step: 9
Training loss: 2.431623697280884
Validation loss: 2.0254587133725486

Epoch: 6| Step: 10
Training loss: 2.295480251312256
Validation loss: 2.0314181645711265

Epoch: 6| Step: 11
Training loss: 2.1140758991241455
Validation loss: 2.0274339516957602

Epoch: 6| Step: 12
Training loss: 2.1936326026916504
Validation loss: 2.0293518702189126

Epoch: 6| Step: 13
Training loss: 2.509561538696289
Validation loss: 2.0256645679473877

Epoch: 67| Step: 0
Training loss: 2.348545551300049
Validation loss: 2.0219296415646872

Epoch: 6| Step: 1
Training loss: 1.7336790561676025
Validation loss: 2.0342740217844644

Epoch: 6| Step: 2
Training loss: 2.7978901863098145
Validation loss: 2.0299958984057107

Epoch: 6| Step: 3
Training loss: 1.9279046058654785
Validation loss: 2.0329696933428445

Epoch: 6| Step: 4
Training loss: 2.234219551086426
Validation loss: 2.032063901424408

Epoch: 6| Step: 5
Training loss: 2.223872184753418
Validation loss: 2.030345340569814

Epoch: 6| Step: 6
Training loss: 2.5179131031036377
Validation loss: 2.0371740460395813

Epoch: 6| Step: 7
Training loss: 2.1620588302612305
Validation loss: 2.0294441183408103

Epoch: 6| Step: 8
Training loss: 1.43210768699646
Validation loss: 2.037238279978434

Epoch: 6| Step: 9
Training loss: 2.4717235565185547
Validation loss: 2.0354109009106955

Epoch: 6| Step: 10
Training loss: 2.554002046585083
Validation loss: 2.0415459473927817

Epoch: 6| Step: 11
Training loss: 1.8493497371673584
Validation loss: 2.0426389376322427

Epoch: 6| Step: 12
Training loss: 2.126523971557617
Validation loss: 2.056022524833679

Epoch: 6| Step: 13
Training loss: 2.3048152923583984
Validation loss: 2.0431979099909463

Epoch: 68| Step: 0
Training loss: 3.010061264038086
Validation loss: 2.046975235144297

Epoch: 6| Step: 1
Training loss: 1.69148588180542
Validation loss: 2.0330638686815896

Epoch: 6| Step: 2
Training loss: 2.1702396869659424
Validation loss: 2.028087834517161

Epoch: 6| Step: 3
Training loss: 1.5946614742279053
Validation loss: 2.0209638277689614

Epoch: 6| Step: 4
Training loss: 1.7406840324401855
Validation loss: 2.0246752897898355

Epoch: 6| Step: 5
Training loss: 2.48012375831604
Validation loss: 2.018420994281769

Epoch: 6| Step: 6
Training loss: 2.44053053855896
Validation loss: 2.02303014198939

Epoch: 6| Step: 7
Training loss: 2.425987958908081
Validation loss: 2.0265504121780396

Epoch: 6| Step: 8
Training loss: 2.1481571197509766
Validation loss: 2.023238201936086

Epoch: 6| Step: 9
Training loss: 2.594877243041992
Validation loss: 2.03224907318751

Epoch: 6| Step: 10
Training loss: 1.9958595037460327
Validation loss: 2.0158493916193643

Epoch: 6| Step: 11
Training loss: 2.143134117126465
Validation loss: 2.022247572739919

Epoch: 6| Step: 12
Training loss: 2.209244728088379
Validation loss: 2.0224180221557617

Epoch: 6| Step: 13
Training loss: 2.214691638946533
Validation loss: 2.017168958981832

Epoch: 69| Step: 0
Training loss: 2.8098158836364746
Validation loss: 2.018336375554403

Epoch: 6| Step: 1
Training loss: 2.536839008331299
Validation loss: 2.013376772403717

Epoch: 6| Step: 2
Training loss: 2.8080315589904785
Validation loss: 2.0162397424379983

Epoch: 6| Step: 3
Training loss: 1.812367558479309
Validation loss: 2.014315962791443

Epoch: 6| Step: 4
Training loss: 1.761566400527954
Validation loss: 2.0128546754519143

Epoch: 6| Step: 5
Training loss: 2.1964235305786133
Validation loss: 2.012718439102173

Epoch: 6| Step: 6
Training loss: 2.061343193054199
Validation loss: 2.0207923650741577

Epoch: 6| Step: 7
Training loss: 1.7261885404586792
Validation loss: 2.01557465394338

Epoch: 6| Step: 8
Training loss: 2.494988441467285
Validation loss: 2.019668479760488

Epoch: 6| Step: 9
Training loss: 2.41304349899292
Validation loss: 2.018769105275472

Epoch: 6| Step: 10
Training loss: 2.177671432495117
Validation loss: 2.0249325037002563

Epoch: 6| Step: 11
Training loss: 1.4834405183792114
Validation loss: 2.0199232498804727

Epoch: 6| Step: 12
Training loss: 2.2367122173309326
Validation loss: 2.0297237833340964

Epoch: 6| Step: 13
Training loss: 2.1442036628723145
Validation loss: 2.0260910391807556

Epoch: 70| Step: 0
Training loss: 2.0681519508361816
Validation loss: 2.021958112716675

Epoch: 6| Step: 1
Training loss: 1.7154608964920044
Validation loss: 2.0248000025749207

Epoch: 6| Step: 2
Training loss: 2.3281631469726562
Validation loss: 2.0227165619532266

Epoch: 6| Step: 3
Training loss: 2.1671183109283447
Validation loss: 2.027663509051005

Epoch: 6| Step: 4
Training loss: 2.454803943634033
Validation loss: 2.038636942704519

Epoch: 6| Step: 5
Training loss: 2.5303804874420166
Validation loss: 2.04297536611557

Epoch: 6| Step: 6
Training loss: 2.2357983589172363
Validation loss: 2.057210405667623

Epoch: 6| Step: 7
Training loss: 2.452723741531372
Validation loss: 2.0488683780034385

Epoch: 6| Step: 8
Training loss: 2.065640449523926
Validation loss: 2.042401055494944

Epoch: 6| Step: 9
Training loss: 2.66115140914917
Validation loss: 2.0531720519065857

Epoch: 6| Step: 10
Training loss: 1.9238100051879883
Validation loss: 2.0390912294387817

Epoch: 6| Step: 11
Training loss: 2.476957082748413
Validation loss: 2.0322547554969788

Epoch: 6| Step: 12
Training loss: 1.5040969848632812
Validation loss: 2.0314531524976096

Epoch: 6| Step: 13
Training loss: 1.8597822189331055
Validation loss: 2.0367967089017234

Epoch: 71| Step: 0
Training loss: 2.5058631896972656
Validation loss: 2.0339236855506897

Epoch: 6| Step: 1
Training loss: 2.1955230236053467
Validation loss: 2.021296958128611

Epoch: 6| Step: 2
Training loss: 2.2425434589385986
Validation loss: 2.0309080282847085

Epoch: 6| Step: 3
Training loss: 1.9697132110595703
Validation loss: 2.0224780639012656

Epoch: 6| Step: 4
Training loss: 2.049656391143799
Validation loss: 2.0200448036193848

Epoch: 6| Step: 5
Training loss: 1.614444375038147
Validation loss: 2.0199278195699057

Epoch: 6| Step: 6
Training loss: 2.3473262786865234
Validation loss: 2.0299441615740457

Epoch: 6| Step: 7
Training loss: 2.7031078338623047
Validation loss: 2.028294563293457

Epoch: 6| Step: 8
Training loss: 2.3346352577209473
Validation loss: 2.0398766795794168

Epoch: 6| Step: 9
Training loss: 1.8501535654067993
Validation loss: 2.038910766442617

Epoch: 6| Step: 10
Training loss: 2.7000210285186768
Validation loss: 2.051972985267639

Epoch: 6| Step: 11
Training loss: 1.8929916620254517
Validation loss: 2.039697508017222

Epoch: 6| Step: 12
Training loss: 2.057494640350342
Validation loss: 2.0256932576497397

Epoch: 6| Step: 13
Training loss: 2.4600629806518555
Validation loss: 2.0261098742485046

Epoch: 72| Step: 0
Training loss: 2.195685386657715
Validation loss: 2.033804496129354

Epoch: 6| Step: 1
Training loss: 2.308900833129883
Validation loss: 2.033389449119568

Epoch: 6| Step: 2
Training loss: 1.3663686513900757
Validation loss: 2.034596105416616

Epoch: 6| Step: 3
Training loss: 2.487818956375122
Validation loss: 2.0362634658813477

Epoch: 6| Step: 4
Training loss: 2.324676513671875
Validation loss: 2.036715825398763

Epoch: 6| Step: 5
Training loss: 2.864600658416748
Validation loss: 2.0466251174608865

Epoch: 6| Step: 6
Training loss: 1.9800090789794922
Validation loss: 2.044770081837972

Epoch: 6| Step: 7
Training loss: 2.677032470703125
Validation loss: 2.045451025168101

Epoch: 6| Step: 8
Training loss: 1.9958915710449219
Validation loss: 2.0510324239730835

Epoch: 6| Step: 9
Training loss: 2.032379150390625
Validation loss: 2.043812910715739

Epoch: 6| Step: 10
Training loss: 2.3530220985412598
Validation loss: 2.0451629360516868

Epoch: 6| Step: 11
Training loss: 2.1315603256225586
Validation loss: 2.0382831494013467

Epoch: 6| Step: 12
Training loss: 2.330134391784668
Validation loss: 2.0432242353757224

Epoch: 6| Step: 13
Training loss: 2.047356605529785
Validation loss: 2.0386787056922913

Epoch: 73| Step: 0
Training loss: 2.2250850200653076
Validation loss: 2.0439724127451577

Epoch: 6| Step: 1
Training loss: 1.9695159196853638
Validation loss: 2.0427521069844565

Epoch: 6| Step: 2
Training loss: 2.160757541656494
Validation loss: 2.038534164428711

Epoch: 6| Step: 3
Training loss: 2.180365562438965
Validation loss: 2.0263284842173257

Epoch: 6| Step: 4
Training loss: 2.362278938293457
Validation loss: 2.0203933715820312

Epoch: 6| Step: 5
Training loss: 2.2488067150115967
Validation loss: 2.0129223267237344

Epoch: 6| Step: 6
Training loss: 1.8085497617721558
Validation loss: 2.015075206756592

Epoch: 6| Step: 7
Training loss: 2.227156162261963
Validation loss: 2.0354711016019187

Epoch: 6| Step: 8
Training loss: 2.339622974395752
Validation loss: 2.0276620586713157

Epoch: 6| Step: 9
Training loss: 1.9681282043457031
Validation loss: 2.051874279975891

Epoch: 6| Step: 10
Training loss: 2.132020950317383
Validation loss: 2.061485230922699

Epoch: 6| Step: 11
Training loss: 1.7262027263641357
Validation loss: 2.0634328524271646

Epoch: 6| Step: 12
Training loss: 2.7868733406066895
Validation loss: 2.062831779321035

Epoch: 6| Step: 13
Training loss: 2.326071262359619
Validation loss: 2.048698604106903

Epoch: 74| Step: 0
Training loss: 1.3344051837921143
Validation loss: 2.0456518729527793

Epoch: 6| Step: 1
Training loss: 1.9389631748199463
Validation loss: 2.0364646911621094

Epoch: 6| Step: 2
Training loss: 1.9797495603561401
Validation loss: 2.0274124145507812

Epoch: 6| Step: 3
Training loss: 2.0984888076782227
Validation loss: 2.031437873840332

Epoch: 6| Step: 4
Training loss: 2.5622129440307617
Validation loss: 2.031184713045756

Epoch: 6| Step: 5
Training loss: 2.3448941707611084
Validation loss: 2.0309178630510965

Epoch: 6| Step: 6
Training loss: 1.8801926374435425
Validation loss: 2.031760553518931

Epoch: 6| Step: 7
Training loss: 2.592510223388672
Validation loss: 2.021132210890452

Epoch: 6| Step: 8
Training loss: 2.3395495414733887
Validation loss: 2.028753101825714

Epoch: 6| Step: 9
Training loss: 2.281309127807617
Validation loss: 2.027878165245056

Epoch: 6| Step: 10
Training loss: 2.6648030281066895
Validation loss: 2.0232909520467124

Epoch: 6| Step: 11
Training loss: 2.452035427093506
Validation loss: 2.023538112640381

Epoch: 6| Step: 12
Training loss: 1.9797284603118896
Validation loss: 2.023669441541036

Epoch: 6| Step: 13
Training loss: 2.2490220069885254
Validation loss: 2.0209344228108725

Epoch: 75| Step: 0
Training loss: 2.3499391078948975
Validation loss: 2.0226771434148154

Epoch: 6| Step: 1
Training loss: 1.8609488010406494
Validation loss: 2.0222214261690774

Epoch: 6| Step: 2
Training loss: 2.635434150695801
Validation loss: 2.0300599137941995

Epoch: 6| Step: 3
Training loss: 1.9750494956970215
Validation loss: 2.024549663066864

Epoch: 6| Step: 4
Training loss: 2.438638687133789
Validation loss: 2.0184736251831055

Epoch: 6| Step: 5
Training loss: 2.3392858505249023
Validation loss: 2.0274630188941956

Epoch: 6| Step: 6
Training loss: 1.9287946224212646
Validation loss: 2.0296295881271362

Epoch: 6| Step: 7
Training loss: 2.5436854362487793
Validation loss: 2.044757068157196

Epoch: 6| Step: 8
Training loss: 2.1230955123901367
Validation loss: 2.0551063219706216

Epoch: 6| Step: 9
Training loss: 2.729414939880371
Validation loss: 2.0664464433987937

Epoch: 6| Step: 10
Training loss: 1.486977458000183
Validation loss: 2.051160673300425

Epoch: 6| Step: 11
Training loss: 2.037811756134033
Validation loss: 2.04818061987559

Epoch: 6| Step: 12
Training loss: 2.0101943016052246
Validation loss: 2.043773134549459

Epoch: 6| Step: 13
Training loss: 2.18782114982605
Validation loss: 2.028433362642924

Epoch: 76| Step: 0
Training loss: 1.696489930152893
Validation loss: 2.0278220574061074

Epoch: 6| Step: 1
Training loss: 2.3555736541748047
Validation loss: 2.032011349995931

Epoch: 6| Step: 2
Training loss: 2.5774309635162354
Validation loss: 2.025419374306997

Epoch: 6| Step: 3
Training loss: 2.1509621143341064
Validation loss: 2.0334500074386597

Epoch: 6| Step: 4
Training loss: 2.093930721282959
Validation loss: 2.0322710275650024

Epoch: 6| Step: 5
Training loss: 1.5270922183990479
Validation loss: 2.0282927751541138

Epoch: 6| Step: 6
Training loss: 2.3709981441497803
Validation loss: 2.03511506319046

Epoch: 6| Step: 7
Training loss: 2.233137607574463
Validation loss: 2.041108767191569

Epoch: 6| Step: 8
Training loss: 2.4487059116363525
Validation loss: 2.02581125497818

Epoch: 6| Step: 9
Training loss: 2.243835210800171
Validation loss: 2.0208973487218223

Epoch: 6| Step: 10
Training loss: 2.409726142883301
Validation loss: 2.02027157942454

Epoch: 6| Step: 11
Training loss: 2.2813851833343506
Validation loss: 2.0218425989151

Epoch: 6| Step: 12
Training loss: 1.8002997636795044
Validation loss: 2.017684757709503

Epoch: 6| Step: 13
Training loss: 2.2116222381591797
Validation loss: 2.022417724132538

Epoch: 77| Step: 0
Training loss: 2.282238721847534
Validation loss: 2.0260323683420816

Epoch: 6| Step: 1
Training loss: 1.7611958980560303
Validation loss: 2.0248595476150513

Epoch: 6| Step: 2
Training loss: 2.6031064987182617
Validation loss: 2.029447078704834

Epoch: 6| Step: 3
Training loss: 1.757442831993103
Validation loss: 2.0345084269841514

Epoch: 6| Step: 4
Training loss: 1.7288415431976318
Validation loss: 2.037261744340261

Epoch: 6| Step: 5
Training loss: 2.2255055904388428
Validation loss: 2.0346743067105613

Epoch: 6| Step: 6
Training loss: 1.994242548942566
Validation loss: 2.0360504190127053

Epoch: 6| Step: 7
Training loss: 2.370236396789551
Validation loss: 2.031695306301117

Epoch: 6| Step: 8
Training loss: 2.3946313858032227
Validation loss: 2.036386708418528

Epoch: 6| Step: 9
Training loss: 2.659891128540039
Validation loss: 2.032425800959269

Epoch: 6| Step: 10
Training loss: 1.9561092853546143
Validation loss: 2.0331587394078574

Epoch: 6| Step: 11
Training loss: 2.1871185302734375
Validation loss: 2.030897577603658

Epoch: 6| Step: 12
Training loss: 2.635068893432617
Validation loss: 2.0269735455513

Epoch: 6| Step: 13
Training loss: 2.2042958736419678
Validation loss: 2.020293712615967

Epoch: 78| Step: 0
Training loss: 1.6062690019607544
Validation loss: 2.0014997720718384

Epoch: 6| Step: 1
Training loss: 2.6945414543151855
Validation loss: 2.0143845876057944

Epoch: 6| Step: 2
Training loss: 2.138745069503784
Validation loss: 2.026396413644155

Epoch: 6| Step: 3
Training loss: 2.051140546798706
Validation loss: 2.0323029359181723

Epoch: 6| Step: 4
Training loss: 2.3414931297302246
Validation loss: 2.0267800092697144

Epoch: 6| Step: 5
Training loss: 2.1963133811950684
Validation loss: 2.040234605471293

Epoch: 6| Step: 6
Training loss: 1.9217606782913208
Validation loss: 2.0223368604977927

Epoch: 6| Step: 7
Training loss: 2.419621229171753
Validation loss: 2.0237773656845093

Epoch: 6| Step: 8
Training loss: 2.4679107666015625
Validation loss: 2.0254326462745667

Epoch: 6| Step: 9
Training loss: 2.604487419128418
Validation loss: 2.0215136408805847

Epoch: 6| Step: 10
Training loss: 1.9969706535339355
Validation loss: 2.0116814374923706

Epoch: 6| Step: 11
Training loss: 2.2760796546936035
Validation loss: 2.010419030984243

Epoch: 6| Step: 12
Training loss: 1.8858139514923096
Validation loss: 2.0185362895329795

Epoch: 6| Step: 13
Training loss: 1.825700044631958
Validation loss: 2.0238102078437805

Epoch: 79| Step: 0
Training loss: 2.0375962257385254
Validation loss: 2.0260924100875854

Epoch: 6| Step: 1
Training loss: 1.9304195642471313
Validation loss: 2.032463868459066

Epoch: 6| Step: 2
Training loss: 2.40377140045166
Validation loss: 2.0270745158195496

Epoch: 6| Step: 3
Training loss: 2.0212249755859375
Validation loss: 2.0417423049608865

Epoch: 6| Step: 4
Training loss: 2.687758445739746
Validation loss: 2.064380923906962

Epoch: 6| Step: 5
Training loss: 2.221978187561035
Validation loss: 2.0632993380228677

Epoch: 6| Step: 6
Training loss: 1.7493515014648438
Validation loss: 2.0663174589474997

Epoch: 6| Step: 7
Training loss: 2.0265538692474365
Validation loss: 2.068349540233612

Epoch: 6| Step: 8
Training loss: 2.603400945663452
Validation loss: 2.0642924706141152

Epoch: 6| Step: 9
Training loss: 2.6451125144958496
Validation loss: 2.0405678153038025

Epoch: 6| Step: 10
Training loss: 2.4452452659606934
Validation loss: 2.0181511441866555

Epoch: 6| Step: 11
Training loss: 1.6323492527008057
Validation loss: 2.02059413989385

Epoch: 6| Step: 12
Training loss: 1.5053648948669434
Validation loss: 2.012020528316498

Epoch: 6| Step: 13
Training loss: 2.500019073486328
Validation loss: 2.0223705569903054

Epoch: 80| Step: 0
Training loss: 2.0229132175445557
Validation loss: 2.0254809260368347

Epoch: 6| Step: 1
Training loss: 2.087881088256836
Validation loss: 2.027987519900004

Epoch: 6| Step: 2
Training loss: 1.753473162651062
Validation loss: 2.0314274430274963

Epoch: 6| Step: 3
Training loss: 2.088001251220703
Validation loss: 2.0298303365707397

Epoch: 6| Step: 4
Training loss: 2.548053026199341
Validation loss: 2.03303599357605

Epoch: 6| Step: 5
Training loss: 2.6244802474975586
Validation loss: 2.030202309290568

Epoch: 6| Step: 6
Training loss: 2.448719024658203
Validation loss: 2.04081654548645

Epoch: 6| Step: 7
Training loss: 2.2496628761291504
Validation loss: 2.0331590374310813

Epoch: 6| Step: 8
Training loss: 1.7578012943267822
Validation loss: 2.038540244102478

Epoch: 6| Step: 9
Training loss: 2.958433151245117
Validation loss: 2.042548954486847

Epoch: 6| Step: 10
Training loss: 2.041408061981201
Validation loss: 2.0359097917874656

Epoch: 6| Step: 11
Training loss: 2.059469699859619
Validation loss: 2.0348586638768515

Epoch: 6| Step: 12
Training loss: 2.207115650177002
Validation loss: 2.036321461200714

Epoch: 6| Step: 13
Training loss: 2.0626702308654785
Validation loss: 2.0316712657610574

Epoch: 81| Step: 0
Training loss: 2.2888996601104736
Validation loss: 2.04001514116923

Epoch: 6| Step: 1
Training loss: 2.2189316749572754
Validation loss: 2.035442888736725

Epoch: 6| Step: 2
Training loss: 2.2554984092712402
Validation loss: 2.0231058597564697

Epoch: 6| Step: 3
Training loss: 1.8368053436279297
Validation loss: 2.03399924437205

Epoch: 6| Step: 4
Training loss: 2.3062584400177
Validation loss: 2.027262032032013

Epoch: 6| Step: 5
Training loss: 2.117340564727783
Validation loss: 2.02747372786204

Epoch: 6| Step: 6
Training loss: 1.3123936653137207
Validation loss: 2.0173836946487427

Epoch: 6| Step: 7
Training loss: 2.6461172103881836
Validation loss: 2.015164613723755

Epoch: 6| Step: 8
Training loss: 2.3331189155578613
Validation loss: 2.0177249113718667

Epoch: 6| Step: 9
Training loss: 2.6048381328582764
Validation loss: 2.0266570448875427

Epoch: 6| Step: 10
Training loss: 2.3610002994537354
Validation loss: 2.035526235898336

Epoch: 6| Step: 11
Training loss: 2.0119290351867676
Validation loss: 2.04283877213796

Epoch: 6| Step: 12
Training loss: 1.6251946687698364
Validation loss: 2.034011503060659

Epoch: 6| Step: 13
Training loss: 2.254551410675049
Validation loss: 2.044081171353658

Epoch: 82| Step: 0
Training loss: 2.241034746170044
Validation loss: 2.043875813484192

Epoch: 6| Step: 1
Training loss: 1.8867321014404297
Validation loss: 2.053202668825785

Epoch: 6| Step: 2
Training loss: 2.021085262298584
Validation loss: 2.0398224194844565

Epoch: 6| Step: 3
Training loss: 2.703545093536377
Validation loss: 2.0414130886395774

Epoch: 6| Step: 4
Training loss: 2.5507266521453857
Validation loss: 2.031931459903717

Epoch: 6| Step: 5
Training loss: 2.1460201740264893
Validation loss: 2.0341654618581138

Epoch: 6| Step: 6
Training loss: 2.1185622215270996
Validation loss: 2.0292943318684897

Epoch: 6| Step: 7
Training loss: 2.036099433898926
Validation loss: 2.0251544713974

Epoch: 6| Step: 8
Training loss: 2.497223377227783
Validation loss: 2.0215508341789246

Epoch: 6| Step: 9
Training loss: 2.1556143760681152
Validation loss: 2.0164036750793457

Epoch: 6| Step: 10
Training loss: 2.230947971343994
Validation loss: 2.0171823700269065

Epoch: 6| Step: 11
Training loss: 2.1254382133483887
Validation loss: 2.0178354581197104

Epoch: 6| Step: 12
Training loss: 1.6566170454025269
Validation loss: 2.0170803666114807

Epoch: 6| Step: 13
Training loss: 1.9704384803771973
Validation loss: 2.0208818713823953

Epoch: 83| Step: 0
Training loss: 3.434725522994995
Validation loss: 2.026106913884481

Epoch: 6| Step: 1
Training loss: 1.7941148281097412
Validation loss: 2.0309951305389404

Epoch: 6| Step: 2
Training loss: 2.3771934509277344
Validation loss: 2.035694698492686

Epoch: 6| Step: 3
Training loss: 2.4140446186065674
Validation loss: 2.0452953775723777

Epoch: 6| Step: 4
Training loss: 1.875537395477295
Validation loss: 2.035166621208191

Epoch: 6| Step: 5
Training loss: 2.100635051727295
Validation loss: 2.039157509803772

Epoch: 6| Step: 6
Training loss: 2.2415993213653564
Validation loss: 2.0287392338116965

Epoch: 6| Step: 7
Training loss: 2.1306748390197754
Validation loss: 2.0265627106030784

Epoch: 6| Step: 8
Training loss: 1.8962934017181396
Validation loss: 2.0355958938598633

Epoch: 6| Step: 9
Training loss: 2.1892051696777344
Validation loss: 2.0233043829600015

Epoch: 6| Step: 10
Training loss: 1.515951156616211
Validation loss: 2.014548937479655

Epoch: 6| Step: 11
Training loss: 2.2407326698303223
Validation loss: 2.0226040283838906

Epoch: 6| Step: 12
Training loss: 2.3179140090942383
Validation loss: 2.0240511298179626

Epoch: 6| Step: 13
Training loss: 1.9343228340148926
Validation loss: 2.0203845500946045

Epoch: 84| Step: 0
Training loss: 2.3908205032348633
Validation loss: 2.023671567440033

Epoch: 6| Step: 1
Training loss: 2.5392918586730957
Validation loss: 2.0323993961016336

Epoch: 6| Step: 2
Training loss: 2.4834787845611572
Validation loss: 2.0420042276382446

Epoch: 6| Step: 3
Training loss: 1.9207432270050049
Validation loss: 2.025165379047394

Epoch: 6| Step: 4
Training loss: 1.637417197227478
Validation loss: 2.030669848124186

Epoch: 6| Step: 5
Training loss: 2.429506301879883
Validation loss: 2.0195348262786865

Epoch: 6| Step: 6
Training loss: 2.4243006706237793
Validation loss: 2.0317498644193015

Epoch: 6| Step: 7
Training loss: 2.064831018447876
Validation loss: 2.0225655237833657

Epoch: 6| Step: 8
Training loss: 1.536627173423767
Validation loss: 2.0300404032071433

Epoch: 6| Step: 9
Training loss: 2.67995548248291
Validation loss: 2.026107589403788

Epoch: 6| Step: 10
Training loss: 1.5560743808746338
Validation loss: 2.030704458554586

Epoch: 6| Step: 11
Training loss: 2.121072769165039
Validation loss: 2.0324891408284507

Epoch: 6| Step: 12
Training loss: 2.4309465885162354
Validation loss: 2.015490154425303

Epoch: 6| Step: 13
Training loss: 1.818289041519165
Validation loss: 2.0214332938194275

Epoch: 85| Step: 0
Training loss: 2.267904758453369
Validation loss: 2.023800015449524

Epoch: 6| Step: 1
Training loss: 2.3957324028015137
Validation loss: 2.0177364349365234

Epoch: 6| Step: 2
Training loss: 1.7375550270080566
Validation loss: 2.0152778029441833

Epoch: 6| Step: 3
Training loss: 1.9268617630004883
Validation loss: 2.023865362008413

Epoch: 6| Step: 4
Training loss: 2.356387138366699
Validation loss: 2.0434593160947165

Epoch: 6| Step: 5
Training loss: 2.491605520248413
Validation loss: 2.056261579195658

Epoch: 6| Step: 6
Training loss: 2.1135287284851074
Validation loss: 2.0584848721822104

Epoch: 6| Step: 7
Training loss: 2.530477523803711
Validation loss: 2.0635828971862793

Epoch: 6| Step: 8
Training loss: 1.9935657978057861
Validation loss: 2.0525397857030234

Epoch: 6| Step: 9
Training loss: 1.7985097169876099
Validation loss: 2.034985442956289

Epoch: 6| Step: 10
Training loss: 1.9300061464309692
Validation loss: 2.0275981426239014

Epoch: 6| Step: 11
Training loss: 2.6835737228393555
Validation loss: 2.020131528377533

Epoch: 6| Step: 12
Training loss: 2.302171230316162
Validation loss: 2.0037911931673684

Epoch: 6| Step: 13
Training loss: 1.8571356534957886
Validation loss: 2.002831836541494

Epoch: 86| Step: 0
Training loss: 2.0729804039001465
Validation loss: 2.0080052812894187

Epoch: 6| Step: 1
Training loss: 2.1952619552612305
Validation loss: 2.0091659824053445

Epoch: 6| Step: 2
Training loss: 2.285966634750366
Validation loss: 2.0151902039845786

Epoch: 6| Step: 3
Training loss: 1.5622504949569702
Validation loss: 2.0226598183314004

Epoch: 6| Step: 4
Training loss: 2.458527088165283
Validation loss: 2.0319693088531494

Epoch: 6| Step: 5
Training loss: 1.8389054536819458
Validation loss: 2.0303213795026145

Epoch: 6| Step: 6
Training loss: 1.889911413192749
Validation loss: 2.0204397241274514

Epoch: 6| Step: 7
Training loss: 2.428529739379883
Validation loss: 2.0341126918792725

Epoch: 6| Step: 8
Training loss: 2.8193931579589844
Validation loss: 2.030353387196859

Epoch: 6| Step: 9
Training loss: 1.7656846046447754
Validation loss: 2.026972492535909

Epoch: 6| Step: 10
Training loss: 2.501408576965332
Validation loss: 2.0231711864471436

Epoch: 6| Step: 11
Training loss: 2.4277634620666504
Validation loss: 2.020428240299225

Epoch: 6| Step: 12
Training loss: 2.1289005279541016
Validation loss: 2.019213159879049

Epoch: 6| Step: 13
Training loss: 2.1039018630981445
Validation loss: 2.023581405480703

Epoch: 87| Step: 0
Training loss: 1.653065800666809
Validation loss: 2.01172403494517

Epoch: 6| Step: 1
Training loss: 2.4881770610809326
Validation loss: 2.01347949107488

Epoch: 6| Step: 2
Training loss: 2.112626075744629
Validation loss: 2.0013229846954346

Epoch: 6| Step: 3
Training loss: 2.26682710647583
Validation loss: 2.008256812890371

Epoch: 6| Step: 4
Training loss: 2.0593042373657227
Validation loss: 2.0113938252131143

Epoch: 6| Step: 5
Training loss: 2.080315589904785
Validation loss: 2.0223429600397744

Epoch: 6| Step: 6
Training loss: 2.477566957473755
Validation loss: 2.0355992118517556

Epoch: 6| Step: 7
Training loss: 2.321251153945923
Validation loss: 2.046571373939514

Epoch: 6| Step: 8
Training loss: 2.2017810344696045
Validation loss: 2.0391494035720825

Epoch: 6| Step: 9
Training loss: 1.9487087726593018
Validation loss: 2.059397121270498

Epoch: 6| Step: 10
Training loss: 2.820270538330078
Validation loss: 2.0412803888320923

Epoch: 6| Step: 11
Training loss: 2.065538167953491
Validation loss: 2.0360295176506042

Epoch: 6| Step: 12
Training loss: 1.3020789623260498
Validation loss: 2.024991055329641

Epoch: 6| Step: 13
Training loss: 2.5969576835632324
Validation loss: 2.0063015023867288

Epoch: 88| Step: 0
Training loss: 1.3470449447631836
Validation loss: 2.004063367843628

Epoch: 6| Step: 1
Training loss: 1.4234871864318848
Validation loss: 2.007166008154551

Epoch: 6| Step: 2
Training loss: 2.431692123413086
Validation loss: 2.0119066635767617

Epoch: 6| Step: 3
Training loss: 2.783477306365967
Validation loss: 2.018113354841868

Epoch: 6| Step: 4
Training loss: 2.4989936351776123
Validation loss: 2.0173006852467856

Epoch: 6| Step: 5
Training loss: 2.388251781463623
Validation loss: 2.020192583401998

Epoch: 6| Step: 6
Training loss: 1.894594669342041
Validation loss: 2.0218571623166404

Epoch: 6| Step: 7
Training loss: 2.2328543663024902
Validation loss: 2.0105825861295066

Epoch: 6| Step: 8
Training loss: 1.9608207941055298
Validation loss: 2.01905357837677

Epoch: 6| Step: 9
Training loss: 2.654844045639038
Validation loss: 2.0124523043632507

Epoch: 6| Step: 10
Training loss: 2.1964612007141113
Validation loss: 2.002784570058187

Epoch: 6| Step: 11
Training loss: 1.859673023223877
Validation loss: 2.008531610171

Epoch: 6| Step: 12
Training loss: 2.5412611961364746
Validation loss: 2.012958804766337

Epoch: 6| Step: 13
Training loss: 2.1757278442382812
Validation loss: 2.010634422302246

Epoch: 89| Step: 0
Training loss: 2.056391716003418
Validation loss: 2.0121068954467773

Epoch: 6| Step: 1
Training loss: 2.1666150093078613
Validation loss: 2.019725422064463

Epoch: 6| Step: 2
Training loss: 1.757200002670288
Validation loss: 2.0223968426386514

Epoch: 6| Step: 3
Training loss: 2.3189897537231445
Validation loss: 2.0295501152674356

Epoch: 6| Step: 4
Training loss: 2.327272415161133
Validation loss: 2.0390134851137796

Epoch: 6| Step: 5
Training loss: 2.2101035118103027
Validation loss: 2.056494355201721

Epoch: 6| Step: 6
Training loss: 2.112882137298584
Validation loss: 2.0354198018709817

Epoch: 6| Step: 7
Training loss: 2.402113199234009
Validation loss: 2.028575042883555

Epoch: 6| Step: 8
Training loss: 2.936858654022217
Validation loss: 2.017928977807363

Epoch: 6| Step: 9
Training loss: 1.813157558441162
Validation loss: 2.0057246486345925

Epoch: 6| Step: 10
Training loss: 2.279007911682129
Validation loss: 2.0075592398643494

Epoch: 6| Step: 11
Training loss: 1.926991581916809
Validation loss: 2.0122923851013184

Epoch: 6| Step: 12
Training loss: 2.332477569580078
Validation loss: 2.015861372152964

Epoch: 6| Step: 13
Training loss: 1.8808319568634033
Validation loss: 2.015709320704142

Epoch: 90| Step: 0
Training loss: 1.7778615951538086
Validation loss: 2.0219038923581443

Epoch: 6| Step: 1
Training loss: 2.536919593811035
Validation loss: 2.0261794924736023

Epoch: 6| Step: 2
Training loss: 2.786090850830078
Validation loss: 2.022976577281952

Epoch: 6| Step: 3
Training loss: 2.064650058746338
Validation loss: 2.0268150170644126

Epoch: 6| Step: 4
Training loss: 2.09559965133667
Validation loss: 2.021811842918396

Epoch: 6| Step: 5
Training loss: 2.000649929046631
Validation loss: 2.020996868610382

Epoch: 6| Step: 6
Training loss: 2.4377834796905518
Validation loss: 2.0183995366096497

Epoch: 6| Step: 7
Training loss: 2.725486993789673
Validation loss: 2.008788069089254

Epoch: 6| Step: 8
Training loss: 2.0497963428497314
Validation loss: 2.0107099215189614

Epoch: 6| Step: 9
Training loss: 1.8017442226409912
Validation loss: 2.0057668884595237

Epoch: 6| Step: 10
Training loss: 2.2414886951446533
Validation loss: 2.000164747238159

Epoch: 6| Step: 11
Training loss: 1.9067938327789307
Validation loss: 2.009383181730906

Epoch: 6| Step: 12
Training loss: 1.8979823589324951
Validation loss: 2.0172411600748696

Epoch: 6| Step: 13
Training loss: 2.0915982723236084
Validation loss: 2.0197027126948037

Epoch: 91| Step: 0
Training loss: 1.887874960899353
Validation loss: 2.02510929107666

Epoch: 6| Step: 1
Training loss: 1.8857359886169434
Validation loss: 2.0345619122187295

Epoch: 6| Step: 2
Training loss: 2.19718074798584
Validation loss: 2.040481905142466

Epoch: 6| Step: 3
Training loss: 2.567892551422119
Validation loss: 2.036688049634298

Epoch: 6| Step: 4
Training loss: 2.6027207374572754
Validation loss: 2.0379401644070945

Epoch: 6| Step: 5
Training loss: 1.328539252281189
Validation loss: 2.0416379968325296

Epoch: 6| Step: 6
Training loss: 2.2512803077697754
Validation loss: 2.0280478596687317

Epoch: 6| Step: 7
Training loss: 2.0929880142211914
Validation loss: 2.027452568213145

Epoch: 6| Step: 8
Training loss: 1.8169493675231934
Validation loss: 2.023463944594065

Epoch: 6| Step: 9
Training loss: 2.3083834648132324
Validation loss: 2.0289620558420816

Epoch: 6| Step: 10
Training loss: 2.1121253967285156
Validation loss: 2.0288353164990744

Epoch: 6| Step: 11
Training loss: 2.3916995525360107
Validation loss: 2.025812784830729

Epoch: 6| Step: 12
Training loss: 2.54410982131958
Validation loss: 2.0370699365933738

Epoch: 6| Step: 13
Training loss: 2.0706329345703125
Validation loss: 2.0240649978319802

Epoch: 92| Step: 0
Training loss: 1.888198971748352
Validation loss: 2.0155217051506042

Epoch: 6| Step: 1
Training loss: 2.230346202850342
Validation loss: 2.012652893861135

Epoch: 6| Step: 2
Training loss: 1.6048415899276733
Validation loss: 2.009976069132487

Epoch: 6| Step: 3
Training loss: 2.3956894874572754
Validation loss: 2.009347418944041

Epoch: 6| Step: 4
Training loss: 1.9420839548110962
Validation loss: 2.0015781919161477

Epoch: 6| Step: 5
Training loss: 2.4903197288513184
Validation loss: 2.0104592045148215

Epoch: 6| Step: 6
Training loss: 2.3375496864318848
Validation loss: 2.0173749327659607

Epoch: 6| Step: 7
Training loss: 2.443857192993164
Validation loss: 2.011418263117472

Epoch: 6| Step: 8
Training loss: 1.90952467918396
Validation loss: 2.0047863523165383

Epoch: 6| Step: 9
Training loss: 2.192564010620117
Validation loss: 2.007938027381897

Epoch: 6| Step: 10
Training loss: 2.175614833831787
Validation loss: 2.0101898113886514

Epoch: 6| Step: 11
Training loss: 2.5934948921203613
Validation loss: 2.00165992975235

Epoch: 6| Step: 12
Training loss: 2.134000778198242
Validation loss: 2.002689758936564

Epoch: 6| Step: 13
Training loss: 1.7181611061096191
Validation loss: 2.0031001369158425

Epoch: 93| Step: 0
Training loss: 2.1036767959594727
Validation loss: 2.0056238174438477

Epoch: 6| Step: 1
Training loss: 2.3413591384887695
Validation loss: 1.9878297050793965

Epoch: 6| Step: 2
Training loss: 1.8762643337249756
Validation loss: 2.001466910044352

Epoch: 6| Step: 3
Training loss: 2.1174113750457764
Validation loss: 2.005090296268463

Epoch: 6| Step: 4
Training loss: 1.8879151344299316
Validation loss: 2.010245621204376

Epoch: 6| Step: 5
Training loss: 2.3590750694274902
Validation loss: 2.007210612297058

Epoch: 6| Step: 6
Training loss: 2.1830482482910156
Validation loss: 2.004324972629547

Epoch: 6| Step: 7
Training loss: 2.3879241943359375
Validation loss: 2.0260573625564575

Epoch: 6| Step: 8
Training loss: 1.9842040538787842
Validation loss: 2.0173985958099365

Epoch: 6| Step: 9
Training loss: 2.257406711578369
Validation loss: 2.0089062054951987

Epoch: 6| Step: 10
Training loss: 1.7624577283859253
Validation loss: 2.0093573729197183

Epoch: 6| Step: 11
Training loss: 2.0671982765197754
Validation loss: 2.0156301458676658

Epoch: 6| Step: 12
Training loss: 2.0243685245513916
Validation loss: 2.00413187344869

Epoch: 6| Step: 13
Training loss: 2.614583969116211
Validation loss: 2.014760454495748

Epoch: 94| Step: 0
Training loss: 1.9922840595245361
Validation loss: 2.0150054494539895

Epoch: 6| Step: 1
Training loss: 1.6092449426651
Validation loss: 2.007340411345164

Epoch: 6| Step: 2
Training loss: 1.98600435256958
Validation loss: 2.0197495222091675

Epoch: 6| Step: 3
Training loss: 2.0873219966888428
Validation loss: 2.0049813191095986

Epoch: 6| Step: 4
Training loss: 1.9502606391906738
Validation loss: 2.015522380669912

Epoch: 6| Step: 5
Training loss: 2.1484904289245605
Validation loss: 2.01649800936381

Epoch: 6| Step: 6
Training loss: 2.34572172164917
Validation loss: 2.0092702905337014

Epoch: 6| Step: 7
Training loss: 2.3470029830932617
Validation loss: 2.014737367630005

Epoch: 6| Step: 8
Training loss: 2.0196738243103027
Validation loss: 2.0131641825040183

Epoch: 6| Step: 9
Training loss: 2.3134713172912598
Validation loss: 2.0163336793581643

Epoch: 6| Step: 10
Training loss: 2.5039095878601074
Validation loss: 2.0147994558016458

Epoch: 6| Step: 11
Training loss: 2.0664162635803223
Validation loss: 2.018001079559326

Epoch: 6| Step: 12
Training loss: 2.3200626373291016
Validation loss: 2.0132732590039573

Epoch: 6| Step: 13
Training loss: 1.9843473434448242
Validation loss: 2.0334402124087014

Epoch: 95| Step: 0
Training loss: 1.9463063478469849
Validation loss: 2.0227606693903604

Epoch: 6| Step: 1
Training loss: 2.2779805660247803
Validation loss: 2.032476266225179

Epoch: 6| Step: 2
Training loss: 1.860278844833374
Validation loss: 2.021980345249176

Epoch: 6| Step: 3
Training loss: 2.1170127391815186
Validation loss: 2.027908464272817

Epoch: 6| Step: 4
Training loss: 1.9991261959075928
Validation loss: 2.0103967984517417

Epoch: 6| Step: 5
Training loss: 2.1762759685516357
Validation loss: 2.01532644033432

Epoch: 6| Step: 6
Training loss: 2.216691493988037
Validation loss: 2.0041534503300986

Epoch: 6| Step: 7
Training loss: 1.958967685699463
Validation loss: 2.0070765614509583

Epoch: 6| Step: 8
Training loss: 2.2420976161956787
Validation loss: 2.017704407374064

Epoch: 6| Step: 9
Training loss: 2.0624778270721436
Validation loss: 2.0193867484728494

Epoch: 6| Step: 10
Training loss: 2.1473135948181152
Validation loss: 2.013307193915049

Epoch: 6| Step: 11
Training loss: 2.907400131225586
Validation loss: 2.011752168337504

Epoch: 6| Step: 12
Training loss: 2.2042717933654785
Validation loss: 2.00851309299469

Epoch: 6| Step: 13
Training loss: 1.9588524103164673
Validation loss: 2.013467013835907

Epoch: 96| Step: 0
Training loss: 2.0413410663604736
Validation loss: 2.001542051633199

Epoch: 6| Step: 1
Training loss: 2.2708358764648438
Validation loss: 2.0075363715489707

Epoch: 6| Step: 2
Training loss: 1.9942421913146973
Validation loss: 2.017182548840841

Epoch: 6| Step: 3
Training loss: 2.3019793033599854
Validation loss: 2.0032944083213806

Epoch: 6| Step: 4
Training loss: 1.916920781135559
Validation loss: 2.005637009938558

Epoch: 6| Step: 5
Training loss: 2.833756923675537
Validation loss: 2.023309310277303

Epoch: 6| Step: 6
Training loss: 2.222428798675537
Validation loss: 2.016396462917328

Epoch: 6| Step: 7
Training loss: 2.597069263458252
Validation loss: 2.019184390703837

Epoch: 6| Step: 8
Training loss: 1.728703260421753
Validation loss: 2.018689592679342

Epoch: 6| Step: 9
Training loss: 1.6764445304870605
Validation loss: 2.0189700524012246

Epoch: 6| Step: 10
Training loss: 1.5467242002487183
Validation loss: 2.0253403782844543

Epoch: 6| Step: 11
Training loss: 2.0590105056762695
Validation loss: 2.0254936615626016

Epoch: 6| Step: 12
Training loss: 2.5629589557647705
Validation loss: 2.0261993209520974

Epoch: 6| Step: 13
Training loss: 2.043947696685791
Validation loss: 2.034346024195353

Epoch: 97| Step: 0
Training loss: 2.2193045616149902
Validation loss: 2.024438818295797

Epoch: 6| Step: 1
Training loss: 2.0170350074768066
Validation loss: 2.019695520401001

Epoch: 6| Step: 2
Training loss: 1.7557792663574219
Validation loss: 2.022406737009684

Epoch: 6| Step: 3
Training loss: 1.8165972232818604
Validation loss: 2.015216807524363

Epoch: 6| Step: 4
Training loss: 2.4465694427490234
Validation loss: 2.0131380955378213

Epoch: 6| Step: 5
Training loss: 2.135221004486084
Validation loss: 2.011017918586731

Epoch: 6| Step: 6
Training loss: 2.225734233856201
Validation loss: 2.003565768400828

Epoch: 6| Step: 7
Training loss: 1.8054734468460083
Validation loss: 2.0163486003875732

Epoch: 6| Step: 8
Training loss: 2.406648635864258
Validation loss: 2.0099249283472695

Epoch: 6| Step: 9
Training loss: 1.7631011009216309
Validation loss: 2.004534443219503

Epoch: 6| Step: 10
Training loss: 2.3869833946228027
Validation loss: 2.009664257367452

Epoch: 6| Step: 11
Training loss: 2.2299928665161133
Validation loss: 2.0066603223482766

Epoch: 6| Step: 12
Training loss: 2.4986581802368164
Validation loss: 2.014610528945923

Epoch: 6| Step: 13
Training loss: 2.170055866241455
Validation loss: 2.02130655447642

Epoch: 98| Step: 0
Training loss: 2.2236084938049316
Validation loss: 2.026924947897593

Epoch: 6| Step: 1
Training loss: 1.7610735893249512
Validation loss: 2.019536236921946

Epoch: 6| Step: 2
Training loss: 2.280071496963501
Validation loss: 2.023560345172882

Epoch: 6| Step: 3
Training loss: 2.8064494132995605
Validation loss: 2.0248799125353494

Epoch: 6| Step: 4
Training loss: 1.8433220386505127
Validation loss: 2.027725577354431

Epoch: 6| Step: 5
Training loss: 1.4968900680541992
Validation loss: 2.034826874732971

Epoch: 6| Step: 6
Training loss: 2.1276679039001465
Validation loss: 2.0361072222391763

Epoch: 6| Step: 7
Training loss: 2.490673542022705
Validation loss: 2.0330342253049216

Epoch: 6| Step: 8
Training loss: 2.014796257019043
Validation loss: 2.0443262656529746

Epoch: 6| Step: 9
Training loss: 1.9142532348632812
Validation loss: 2.0333147644996643

Epoch: 6| Step: 10
Training loss: 1.7471270561218262
Validation loss: 2.029247601826986

Epoch: 6| Step: 11
Training loss: 2.240455150604248
Validation loss: 2.0191533168156943

Epoch: 6| Step: 12
Training loss: 2.1981563568115234
Validation loss: 2.006606082121531

Epoch: 6| Step: 13
Training loss: 2.841613531112671
Validation loss: 2.0041611393292746

Epoch: 99| Step: 0
Training loss: 2.6105265617370605
Validation loss: 2.0080513755480447

Epoch: 6| Step: 1
Training loss: 1.8225390911102295
Validation loss: 2.008298397064209

Epoch: 6| Step: 2
Training loss: 2.4334235191345215
Validation loss: 2.0078575015068054

Epoch: 6| Step: 3
Training loss: 2.362304210662842
Validation loss: 2.01808633406957

Epoch: 6| Step: 4
Training loss: 2.5960521697998047
Validation loss: 2.0193747878074646

Epoch: 6| Step: 5
Training loss: 1.8250114917755127
Validation loss: 2.021825393040975

Epoch: 6| Step: 6
Training loss: 1.791821837425232
Validation loss: 2.0167221228281655

Epoch: 6| Step: 7
Training loss: 1.58822500705719
Validation loss: 2.023760954538981

Epoch: 6| Step: 8
Training loss: 2.4858293533325195
Validation loss: 2.017948309580485

Epoch: 6| Step: 9
Training loss: 1.6559003591537476
Validation loss: 2.0139447848002114

Epoch: 6| Step: 10
Training loss: 1.6621356010437012
Validation loss: 2.0123606522878013

Epoch: 6| Step: 11
Training loss: 2.249812126159668
Validation loss: 2.00537778933843

Epoch: 6| Step: 12
Training loss: 2.633657455444336
Validation loss: 2.0093866984049478

Epoch: 6| Step: 13
Training loss: 2.3933181762695312
Validation loss: 1.9970707694689434

Epoch: 100| Step: 0
Training loss: 1.8809736967086792
Validation loss: 2.0011748671531677

Epoch: 6| Step: 1
Training loss: 2.025803804397583
Validation loss: 2.0232242743174234

Epoch: 6| Step: 2
Training loss: 1.815926194190979
Validation loss: 2.020754039287567

Epoch: 6| Step: 3
Training loss: 1.9085893630981445
Validation loss: 2.030239482720693

Epoch: 6| Step: 4
Training loss: 1.6914315223693848
Validation loss: 2.0391570727030435

Epoch: 6| Step: 5
Training loss: 2.1319785118103027
Validation loss: 2.046347161134084

Epoch: 6| Step: 6
Training loss: 2.5341129302978516
Validation loss: 2.057517488797506

Epoch: 6| Step: 7
Training loss: 2.0315568447113037
Validation loss: 2.0512532393137612

Epoch: 6| Step: 8
Training loss: 2.812512159347534
Validation loss: 2.0551175475120544

Epoch: 6| Step: 9
Training loss: 2.3581368923187256
Validation loss: 2.030681530634562

Epoch: 6| Step: 10
Training loss: 2.294175148010254
Validation loss: 2.012784242630005

Epoch: 6| Step: 11
Training loss: 2.1400492191314697
Validation loss: 2.0078854163487754

Epoch: 6| Step: 12
Training loss: 2.8065297603607178
Validation loss: 2.006741523742676

Epoch: 6| Step: 13
Training loss: 1.805050253868103
Validation loss: 2.0140574971834817

Epoch: 101| Step: 0
Training loss: 2.1437642574310303
Validation loss: 2.020667870839437

Epoch: 6| Step: 1
Training loss: 1.9935836791992188
Validation loss: 2.030878484249115

Epoch: 6| Step: 2
Training loss: 2.075516700744629
Validation loss: 2.0369271834691367

Epoch: 6| Step: 3
Training loss: 2.225790500640869
Validation loss: 2.035446524620056

Epoch: 6| Step: 4
Training loss: 2.415165901184082
Validation loss: 2.032319883505503

Epoch: 6| Step: 5
Training loss: 2.2832441329956055
Validation loss: 2.0371280113855996

Epoch: 6| Step: 6
Training loss: 2.541428565979004
Validation loss: 2.0374421874682107

Epoch: 6| Step: 7
Training loss: 2.1006007194519043
Validation loss: 2.045506695906321

Epoch: 6| Step: 8
Training loss: 2.4133710861206055
Validation loss: 2.023704767227173

Epoch: 6| Step: 9
Training loss: 1.958886742591858
Validation loss: 2.039614677429199

Epoch: 6| Step: 10
Training loss: 2.3223605155944824
Validation loss: 2.036395231882731

Epoch: 6| Step: 11
Training loss: 1.7242233753204346
Validation loss: 2.03201025724411

Epoch: 6| Step: 12
Training loss: 2.2792654037475586
Validation loss: 2.0379350781440735

Epoch: 6| Step: 13
Training loss: 2.3665151596069336
Validation loss: 2.0372974077860513

Epoch: 102| Step: 0
Training loss: 2.4643218517303467
Validation loss: 2.0361376206080117

Epoch: 6| Step: 1
Training loss: 1.8388272523880005
Validation loss: 2.031907637914022

Epoch: 6| Step: 2
Training loss: 1.885071039199829
Validation loss: 2.0301547050476074

Epoch: 6| Step: 3
Training loss: 2.7256741523742676
Validation loss: 2.031746506690979

Epoch: 6| Step: 4
Training loss: 2.403646945953369
Validation loss: 2.034114142258962

Epoch: 6| Step: 5
Training loss: 2.1492748260498047
Validation loss: 2.0284358263015747

Epoch: 6| Step: 6
Training loss: 2.0180435180664062
Validation loss: 2.0229850808779397

Epoch: 6| Step: 7
Training loss: 1.5297038555145264
Validation loss: 2.031625986099243

Epoch: 6| Step: 8
Training loss: 2.186044216156006
Validation loss: 2.0168572465578714

Epoch: 6| Step: 9
Training loss: 1.7463371753692627
Validation loss: 2.0119122862815857

Epoch: 6| Step: 10
Training loss: 2.198211669921875
Validation loss: 2.01487143834432

Epoch: 6| Step: 11
Training loss: 2.228550434112549
Validation loss: 2.0208120942115784

Epoch: 6| Step: 12
Training loss: 2.1459739208221436
Validation loss: 2.0321351687113443

Epoch: 6| Step: 13
Training loss: 2.5423622131347656
Validation loss: 2.030627508958181

Epoch: 103| Step: 0
Training loss: 2.2057394981384277
Validation loss: 2.042388459046682

Epoch: 6| Step: 1
Training loss: 2.3568758964538574
Validation loss: 2.0464130640029907

Epoch: 6| Step: 2
Training loss: 2.383383274078369
Validation loss: 2.0455190340677896

Epoch: 6| Step: 3
Training loss: 2.031447410583496
Validation loss: 2.044596175352732

Epoch: 6| Step: 4
Training loss: 1.1842550039291382
Validation loss: 2.0445717573165894

Epoch: 6| Step: 5
Training loss: 2.0622763633728027
Validation loss: 2.035423457622528

Epoch: 6| Step: 6
Training loss: 2.061495304107666
Validation loss: 2.023331900437673

Epoch: 6| Step: 7
Training loss: 2.2190682888031006
Validation loss: 2.021150847276052

Epoch: 6| Step: 8
Training loss: 1.5607099533081055
Validation loss: 2.013143519560496

Epoch: 6| Step: 9
Training loss: 2.123178482055664
Validation loss: 2.01082181930542

Epoch: 6| Step: 10
Training loss: 2.2164759635925293
Validation loss: 2.0167575677235923

Epoch: 6| Step: 11
Training loss: 2.2276432514190674
Validation loss: 2.0135483940442405

Epoch: 6| Step: 12
Training loss: 3.2175519466400146
Validation loss: 2.0164982080459595

Epoch: 6| Step: 13
Training loss: 2.127007007598877
Validation loss: 2.01057497660319

Epoch: 104| Step: 0
Training loss: 1.6319539546966553
Validation loss: 2.017068942387899

Epoch: 6| Step: 1
Training loss: 2.4633288383483887
Validation loss: 2.0234418908754983

Epoch: 6| Step: 2
Training loss: 2.1502504348754883
Validation loss: 2.0165059765179953

Epoch: 6| Step: 3
Training loss: 1.9514011144638062
Validation loss: 2.0218997597694397

Epoch: 6| Step: 4
Training loss: 2.2760629653930664
Validation loss: 2.020796000957489

Epoch: 6| Step: 5
Training loss: 2.547494649887085
Validation loss: 2.022721310456594

Epoch: 6| Step: 6
Training loss: 1.6956079006195068
Validation loss: 2.02510933081309

Epoch: 6| Step: 7
Training loss: 2.264044761657715
Validation loss: 2.0130614042282104

Epoch: 6| Step: 8
Training loss: 1.7720898389816284
Validation loss: 2.0201388796170554

Epoch: 6| Step: 9
Training loss: 2.2092952728271484
Validation loss: 2.0352702935536704

Epoch: 6| Step: 10
Training loss: 2.090351104736328
Validation loss: 2.0226322015126548

Epoch: 6| Step: 11
Training loss: 2.3457717895507812
Validation loss: 2.0298309326171875

Epoch: 6| Step: 12
Training loss: 2.5049033164978027
Validation loss: 2.040272533893585

Epoch: 6| Step: 13
Training loss: 1.7763999700546265
Validation loss: 2.045655091603597

Epoch: 105| Step: 0
Training loss: 1.5850292444229126
Validation loss: 2.032292147477468

Epoch: 6| Step: 1
Training loss: 2.5016489028930664
Validation loss: 2.0388612945874534

Epoch: 6| Step: 2
Training loss: 1.9702558517456055
Validation loss: 2.0430484612782798

Epoch: 6| Step: 3
Training loss: 1.778276801109314
Validation loss: 2.052277664343516

Epoch: 6| Step: 4
Training loss: 2.299774646759033
Validation loss: 2.0575714707374573

Epoch: 6| Step: 5
Training loss: 3.020871639251709
Validation loss: 2.055065115292867

Epoch: 6| Step: 6
Training loss: 2.2733728885650635
Validation loss: 2.067262609799703

Epoch: 6| Step: 7
Training loss: 2.010228157043457
Validation loss: 2.0657413005828857

Epoch: 6| Step: 8
Training loss: 1.9684529304504395
Validation loss: 2.0587101380030313

Epoch: 6| Step: 9
Training loss: 2.4727392196655273
Validation loss: 2.0436846216519675

Epoch: 6| Step: 10
Training loss: 2.220846652984619
Validation loss: 2.021695593992869

Epoch: 6| Step: 11
Training loss: 1.8573367595672607
Validation loss: 2.0093871355056763

Epoch: 6| Step: 12
Training loss: 1.6869398355484009
Validation loss: 2.020273129145304

Epoch: 6| Step: 13
Training loss: 2.446190357208252
Validation loss: 2.037977715333303

Epoch: 106| Step: 0
Training loss: 2.9986138343811035
Validation loss: 2.042380928993225

Epoch: 6| Step: 1
Training loss: 1.825071930885315
Validation loss: 2.0492347876230874

Epoch: 6| Step: 2
Training loss: 2.748868465423584
Validation loss: 2.0457034508387246

Epoch: 6| Step: 3
Training loss: 2.2675867080688477
Validation loss: 2.0428777933120728

Epoch: 6| Step: 4
Training loss: 2.2297379970550537
Validation loss: 2.048143903414408

Epoch: 6| Step: 5
Training loss: 2.3241665363311768
Validation loss: 2.055267095565796

Epoch: 6| Step: 6
Training loss: 2.4733219146728516
Validation loss: 2.0542470812797546

Epoch: 6| Step: 7
Training loss: 2.436964511871338
Validation loss: 2.05372154712677

Epoch: 6| Step: 8
Training loss: 1.9466166496276855
Validation loss: 2.0541325211524963

Epoch: 6| Step: 9
Training loss: 1.4960929155349731
Validation loss: 2.053080062071482

Epoch: 6| Step: 10
Training loss: 2.016390800476074
Validation loss: 2.0544023315111795

Epoch: 6| Step: 11
Training loss: 2.4738609790802
Validation loss: 2.051815172036489

Epoch: 6| Step: 12
Training loss: 1.762014389038086
Validation loss: 2.0478355288505554

Epoch: 6| Step: 13
Training loss: 2.0367279052734375
Validation loss: 2.0541273951530457

Epoch: 107| Step: 0
Training loss: 2.1582119464874268
Validation loss: 2.044923563798269

Epoch: 6| Step: 1
Training loss: 2.213261127471924
Validation loss: 2.0504291653633118

Epoch: 6| Step: 2
Training loss: 2.2126810550689697
Validation loss: 2.04630309343338

Epoch: 6| Step: 3
Training loss: 1.496274471282959
Validation loss: 2.0479098359743753

Epoch: 6| Step: 4
Training loss: 2.0123815536499023
Validation loss: 2.0445932745933533

Epoch: 6| Step: 5
Training loss: 2.1940388679504395
Validation loss: 2.0432721972465515

Epoch: 6| Step: 6
Training loss: 1.86262047290802
Validation loss: 2.0388346115748086

Epoch: 6| Step: 7
Training loss: 1.9242579936981201
Validation loss: 2.0287684003512063

Epoch: 6| Step: 8
Training loss: 2.4361820220947266
Validation loss: 2.021959741910299

Epoch: 6| Step: 9
Training loss: 2.4847311973571777
Validation loss: 2.021883408228556

Epoch: 6| Step: 10
Training loss: 2.013202428817749
Validation loss: 2.0240599314371743

Epoch: 6| Step: 11
Training loss: 2.7073659896850586
Validation loss: 2.0280129512151084

Epoch: 6| Step: 12
Training loss: 2.2646493911743164
Validation loss: 2.018685241540273

Epoch: 6| Step: 13
Training loss: 2.2845687866210938
Validation loss: 2.006573657194773

Epoch: 108| Step: 0
Training loss: 2.1656248569488525
Validation loss: 1.9999638597170513

Epoch: 6| Step: 1
Training loss: 2.2804946899414062
Validation loss: 1.9965794682502747

Epoch: 6| Step: 2
Training loss: 1.5676542520523071
Validation loss: 2.0090456008911133

Epoch: 6| Step: 3
Training loss: 2.579763650894165
Validation loss: 2.005927642186483

Epoch: 6| Step: 4
Training loss: 2.3697009086608887
Validation loss: 2.0127021869023642

Epoch: 6| Step: 5
Training loss: 2.391055107116699
Validation loss: 2.028948406378428

Epoch: 6| Step: 6
Training loss: 1.5504157543182373
Validation loss: 2.044807811578115

Epoch: 6| Step: 7
Training loss: 1.8755543231964111
Validation loss: 2.0591703255971274

Epoch: 6| Step: 8
Training loss: 2.027683973312378
Validation loss: 2.0668506423632302

Epoch: 6| Step: 9
Training loss: 2.8107709884643555
Validation loss: 2.0744399627049765

Epoch: 6| Step: 10
Training loss: 2.155750036239624
Validation loss: 2.0998363892237344

Epoch: 6| Step: 11
Training loss: 2.294301986694336
Validation loss: 2.0730921626091003

Epoch: 6| Step: 12
Training loss: 1.8408386707305908
Validation loss: 2.0816793044408164

Epoch: 6| Step: 13
Training loss: 2.346463680267334
Validation loss: 2.057187497615814

Epoch: 109| Step: 0
Training loss: 2.226224899291992
Validation loss: 2.049924314022064

Epoch: 6| Step: 1
Training loss: 2.0781610012054443
Validation loss: 2.0372212330500283

Epoch: 6| Step: 2
Training loss: 2.123215675354004
Validation loss: 2.0245112578074136

Epoch: 6| Step: 3
Training loss: 2.706210136413574
Validation loss: 2.00862854719162

Epoch: 6| Step: 4
Training loss: 2.206742763519287
Validation loss: 2.0018604596455893

Epoch: 6| Step: 5
Training loss: 1.709230661392212
Validation loss: 2.005423843860626

Epoch: 6| Step: 6
Training loss: 2.313892364501953
Validation loss: 2.003159244855245

Epoch: 6| Step: 7
Training loss: 1.8603074550628662
Validation loss: 2.006844639778137

Epoch: 6| Step: 8
Training loss: 2.4153594970703125
Validation loss: 1.9934320449829102

Epoch: 6| Step: 9
Training loss: 2.093736171722412
Validation loss: 2.005967636903127

Epoch: 6| Step: 10
Training loss: 2.1197760105133057
Validation loss: 2.008544127146403

Epoch: 6| Step: 11
Training loss: 1.6613273620605469
Validation loss: 2.0131667256355286

Epoch: 6| Step: 12
Training loss: 2.6420817375183105
Validation loss: 1.9969051678975422

Epoch: 6| Step: 13
Training loss: 1.5540688037872314
Validation loss: 2.0052215456962585

Epoch: 110| Step: 0
Training loss: 2.1724631786346436
Validation loss: 2.0081774393717446

Epoch: 6| Step: 1
Training loss: 2.0161359310150146
Validation loss: 2.0096200704574585

Epoch: 6| Step: 2
Training loss: 1.8266257047653198
Validation loss: 2.0098279317220054

Epoch: 6| Step: 3
Training loss: 2.222446918487549
Validation loss: 2.016426424185435

Epoch: 6| Step: 4
Training loss: 2.1953418254852295
Validation loss: 2.0168677965799966

Epoch: 6| Step: 5
Training loss: 2.577340841293335
Validation loss: 2.012560188770294

Epoch: 6| Step: 6
Training loss: 1.8614574670791626
Validation loss: 2.012728830178579

Epoch: 6| Step: 7
Training loss: 2.7948861122131348
Validation loss: 2.018730123837789

Epoch: 6| Step: 8
Training loss: 2.257277250289917
Validation loss: 2.0191903511683145

Epoch: 6| Step: 9
Training loss: 1.9004511833190918
Validation loss: 2.0213424960772195

Epoch: 6| Step: 10
Training loss: 1.9723577499389648
Validation loss: 2.013369898001353

Epoch: 6| Step: 11
Training loss: 2.0209336280822754
Validation loss: 2.0260600646336875

Epoch: 6| Step: 12
Training loss: 1.8566750288009644
Validation loss: 2.0314279993375144

Epoch: 6| Step: 13
Training loss: 1.9721803665161133
Validation loss: 2.0295595129330954

Epoch: 111| Step: 0
Training loss: 2.670762300491333
Validation loss: 2.0338716904322305

Epoch: 6| Step: 1
Training loss: 1.8387744426727295
Validation loss: 2.0391237338383994

Epoch: 6| Step: 2
Training loss: 2.3477392196655273
Validation loss: 2.054727852344513

Epoch: 6| Step: 3
Training loss: 2.501291275024414
Validation loss: 2.079618513584137

Epoch: 6| Step: 4
Training loss: 1.7393624782562256
Validation loss: 2.065917650858561

Epoch: 6| Step: 5
Training loss: 2.5709261894226074
Validation loss: 2.0932016372680664

Epoch: 6| Step: 6
Training loss: 2.1110169887542725
Validation loss: 2.0998917619387307

Epoch: 6| Step: 7
Training loss: 2.436678886413574
Validation loss: 2.093635857105255

Epoch: 6| Step: 8
Training loss: 2.485790729522705
Validation loss: 2.0683815677960715

Epoch: 6| Step: 9
Training loss: 2.0789377689361572
Validation loss: 2.057831565539042

Epoch: 6| Step: 10
Training loss: 1.4638981819152832
Validation loss: 2.03139191865921

Epoch: 6| Step: 11
Training loss: 1.237781286239624
Validation loss: 2.0169997413953147

Epoch: 6| Step: 12
Training loss: 2.550977945327759
Validation loss: 2.0056608517964682

Epoch: 6| Step: 13
Training loss: 1.9682161808013916
Validation loss: 2.007433811823527

Epoch: 112| Step: 0
Training loss: 1.7308388948440552
Validation loss: 2.0034218430519104

Epoch: 6| Step: 1
Training loss: 2.3071494102478027
Validation loss: 2.007909874121348

Epoch: 6| Step: 2
Training loss: 2.20742130279541
Validation loss: 2.0131274660428367

Epoch: 6| Step: 3
Training loss: 2.041450262069702
Validation loss: 2.0163481632868447

Epoch: 6| Step: 4
Training loss: 2.1565122604370117
Validation loss: 2.016748865445455

Epoch: 6| Step: 5
Training loss: 2.087501049041748
Validation loss: 2.0115111271540322

Epoch: 6| Step: 6
Training loss: 2.3239712715148926
Validation loss: 2.018263657887777

Epoch: 6| Step: 7
Training loss: 1.9602776765823364
Validation loss: 2.009724199771881

Epoch: 6| Step: 8
Training loss: 2.491077423095703
Validation loss: 2.0104695558547974

Epoch: 6| Step: 9
Training loss: 2.2898998260498047
Validation loss: 2.001560946305593

Epoch: 6| Step: 10
Training loss: 2.3303213119506836
Validation loss: 1.9980810085932414

Epoch: 6| Step: 11
Training loss: 1.386334776878357
Validation loss: 1.9977525472640991

Epoch: 6| Step: 12
Training loss: 2.1799211502075195
Validation loss: 1.9982588092486064

Epoch: 6| Step: 13
Training loss: 2.3261680603027344
Validation loss: 2.004469613234202

Epoch: 113| Step: 0
Training loss: 1.9196771383285522
Validation loss: 2.0081010659535727

Epoch: 6| Step: 1
Training loss: 2.1592063903808594
Validation loss: 2.010586758454641

Epoch: 6| Step: 2
Training loss: 2.2340450286865234
Validation loss: 2.014605085055033

Epoch: 6| Step: 3
Training loss: 2.2725648880004883
Validation loss: 2.01250692208608

Epoch: 6| Step: 4
Training loss: 2.172459602355957
Validation loss: 2.009281059106191

Epoch: 6| Step: 5
Training loss: 2.2217602729797363
Validation loss: 2.0198328296343484

Epoch: 6| Step: 6
Training loss: 2.1719398498535156
Validation loss: 2.020556390285492

Epoch: 6| Step: 7
Training loss: 2.1489405632019043
Validation loss: 2.0185361901919046

Epoch: 6| Step: 8
Training loss: 2.0033230781555176
Validation loss: 2.0202075839042664

Epoch: 6| Step: 9
Training loss: 1.9109432697296143
Validation loss: 2.0233957767486572

Epoch: 6| Step: 10
Training loss: 2.3980085849761963
Validation loss: 2.0194664796193442

Epoch: 6| Step: 11
Training loss: 1.5083884000778198
Validation loss: 2.0147304932276406

Epoch: 6| Step: 12
Training loss: 2.631406307220459
Validation loss: 2.0213311115900674

Epoch: 6| Step: 13
Training loss: 2.0142953395843506
Validation loss: 2.011858324209849

Epoch: 114| Step: 0
Training loss: 1.9562911987304688
Validation loss: 2.0136751929918923

Epoch: 6| Step: 1
Training loss: 1.8777307271957397
Validation loss: 2.0126373966534934

Epoch: 6| Step: 2
Training loss: 2.2566800117492676
Validation loss: 2.0189510782559714

Epoch: 6| Step: 3
Training loss: 1.906534194946289
Validation loss: 2.019316534201304

Epoch: 6| Step: 4
Training loss: 2.159543037414551
Validation loss: 2.0194992423057556

Epoch: 6| Step: 5
Training loss: 2.4349305629730225
Validation loss: 2.025879899660746

Epoch: 6| Step: 6
Training loss: 2.2222790718078613
Validation loss: 2.0190680821736655

Epoch: 6| Step: 7
Training loss: 1.9432766437530518
Validation loss: 2.016583204269409

Epoch: 6| Step: 8
Training loss: 2.2502763271331787
Validation loss: 2.018211325009664

Epoch: 6| Step: 9
Training loss: 2.5850343704223633
Validation loss: 2.031051675478617

Epoch: 6| Step: 10
Training loss: 1.2757463455200195
Validation loss: 2.0351919531822205

Epoch: 6| Step: 11
Training loss: 2.4307596683502197
Validation loss: 2.0320813258488974

Epoch: 6| Step: 12
Training loss: 2.4633634090423584
Validation loss: 2.0458768208821616

Epoch: 6| Step: 13
Training loss: 1.8644453287124634
Validation loss: 2.043043613433838

Epoch: 115| Step: 0
Training loss: 1.6042178869247437
Validation loss: 2.049168566862742

Epoch: 6| Step: 1
Training loss: 2.2690861225128174
Validation loss: 2.0573589205741882

Epoch: 6| Step: 2
Training loss: 2.256199836730957
Validation loss: 2.0583396355311074

Epoch: 6| Step: 3
Training loss: 1.6901735067367554
Validation loss: 2.055249512195587

Epoch: 6| Step: 4
Training loss: 2.591766834259033
Validation loss: 2.0606340567270913

Epoch: 6| Step: 5
Training loss: 2.244109630584717
Validation loss: 2.0572089354197183

Epoch: 6| Step: 6
Training loss: 2.8336265087127686
Validation loss: 2.056004524230957

Epoch: 6| Step: 7
Training loss: 1.5885279178619385
Validation loss: 2.037267029285431

Epoch: 6| Step: 8
Training loss: 2.5203800201416016
Validation loss: 2.0457959175109863

Epoch: 6| Step: 9
Training loss: 2.1609232425689697
Validation loss: 2.0270514686902366

Epoch: 6| Step: 10
Training loss: 2.1374735832214355
Validation loss: 2.0247130393981934

Epoch: 6| Step: 11
Training loss: 1.9846693277359009
Validation loss: 2.0311458309491477

Epoch: 6| Step: 12
Training loss: 2.0108819007873535
Validation loss: 2.032870650291443

Epoch: 6| Step: 13
Training loss: 1.7719694375991821
Validation loss: 2.0358647306760154

Epoch: 116| Step: 0
Training loss: 2.582092761993408
Validation loss: 2.0270073413848877

Epoch: 6| Step: 1
Training loss: 1.7372616529464722
Validation loss: 2.0292335947354636

Epoch: 6| Step: 2
Training loss: 1.898396611213684
Validation loss: 2.024210492769877

Epoch: 6| Step: 3
Training loss: 1.8963665962219238
Validation loss: 2.0257871548334756

Epoch: 6| Step: 4
Training loss: 1.9568541049957275
Validation loss: 2.032079259554545

Epoch: 6| Step: 5
Training loss: 2.0340535640716553
Validation loss: 2.027223507563273

Epoch: 6| Step: 6
Training loss: 2.657367467880249
Validation loss: 2.0342632134755454

Epoch: 6| Step: 7
Training loss: 2.392620086669922
Validation loss: 2.039278268814087

Epoch: 6| Step: 8
Training loss: 1.9694149494171143
Validation loss: 2.0406962434450784

Epoch: 6| Step: 9
Training loss: 2.994576930999756
Validation loss: 2.0248165329297385

Epoch: 6| Step: 10
Training loss: 1.5383821725845337
Validation loss: 2.0309020479520163

Epoch: 6| Step: 11
Training loss: 1.770653486251831
Validation loss: 2.0366756518681846

Epoch: 6| Step: 12
Training loss: 2.260812282562256
Validation loss: 2.041690488656362

Epoch: 6| Step: 13
Training loss: 2.127729654312134
Validation loss: 2.054465651512146

Epoch: 117| Step: 0
Training loss: 2.195662498474121
Validation loss: 2.0445140997568765

Epoch: 6| Step: 1
Training loss: 1.8470594882965088
Validation loss: 2.0584327777226767

Epoch: 6| Step: 2
Training loss: 1.4946064949035645
Validation loss: 2.0418770909309387

Epoch: 6| Step: 3
Training loss: 2.1574082374572754
Validation loss: 2.0350746711095176

Epoch: 6| Step: 4
Training loss: 1.9438166618347168
Validation loss: 2.0389206806818643

Epoch: 6| Step: 5
Training loss: 2.3367972373962402
Validation loss: 2.047459900379181

Epoch: 6| Step: 6
Training loss: 2.0239100456237793
Validation loss: 2.0432739655176797

Epoch: 6| Step: 7
Training loss: 1.8565268516540527
Validation loss: 2.0526275436083474

Epoch: 6| Step: 8
Training loss: 2.408302068710327
Validation loss: 2.054691513379415

Epoch: 6| Step: 9
Training loss: 2.371748447418213
Validation loss: 2.0602463285128274

Epoch: 6| Step: 10
Training loss: 2.5734503269195557
Validation loss: 2.0514663457870483

Epoch: 6| Step: 11
Training loss: 1.9219036102294922
Validation loss: 2.040073891480764

Epoch: 6| Step: 12
Training loss: 2.4577341079711914
Validation loss: 2.0424200693766275

Epoch: 6| Step: 13
Training loss: 1.9257513284683228
Validation loss: 2.027717371781667

Epoch: 118| Step: 0
Training loss: 2.187709331512451
Validation loss: 2.0185638864835105

Epoch: 6| Step: 1
Training loss: 2.2063450813293457
Validation loss: 2.015109141667684

Epoch: 6| Step: 2
Training loss: 2.1657395362854004
Validation loss: 2.024608314037323

Epoch: 6| Step: 3
Training loss: 1.7300279140472412
Validation loss: 2.0211780071258545

Epoch: 6| Step: 4
Training loss: 2.1767868995666504
Validation loss: 2.021865129470825

Epoch: 6| Step: 5
Training loss: 2.481260061264038
Validation loss: 2.028143584728241

Epoch: 6| Step: 6
Training loss: 1.251792550086975
Validation loss: 2.0280179580052695

Epoch: 6| Step: 7
Training loss: 1.8046433925628662
Validation loss: 2.0258021553357444

Epoch: 6| Step: 8
Training loss: 2.0015807151794434
Validation loss: 2.026803890864054

Epoch: 6| Step: 9
Training loss: 2.646423816680908
Validation loss: 2.0252580444018045

Epoch: 6| Step: 10
Training loss: 2.212433338165283
Validation loss: 2.0175166924794516

Epoch: 6| Step: 11
Training loss: 1.8786967992782593
Validation loss: 2.0200438102086387

Epoch: 6| Step: 12
Training loss: 1.9952068328857422
Validation loss: 2.0189267794291177

Epoch: 6| Step: 13
Training loss: 2.542119026184082
Validation loss: 2.0209832986195884

Epoch: 119| Step: 0
Training loss: 1.384394645690918
Validation loss: 2.031387368837992

Epoch: 6| Step: 1
Training loss: 2.3443331718444824
Validation loss: 2.0332957108815513

Epoch: 6| Step: 2
Training loss: 1.8386869430541992
Validation loss: 2.036282777786255

Epoch: 6| Step: 3
Training loss: 1.64216947555542
Validation loss: 2.022151231765747

Epoch: 6| Step: 4
Training loss: 2.3566224575042725
Validation loss: 2.0225216348965964

Epoch: 6| Step: 5
Training loss: 1.2136297225952148
Validation loss: 2.0243652860323587

Epoch: 6| Step: 6
Training loss: 2.5133469104766846
Validation loss: 2.036718209584554

Epoch: 6| Step: 7
Training loss: 2.788848638534546
Validation loss: 2.023410459359487

Epoch: 6| Step: 8
Training loss: 2.1478612422943115
Validation loss: 2.0319181084632874

Epoch: 6| Step: 9
Training loss: 2.1449203491210938
Validation loss: 2.02165025472641

Epoch: 6| Step: 10
Training loss: 2.312163829803467
Validation loss: 2.029339849948883

Epoch: 6| Step: 11
Training loss: 2.5480916500091553
Validation loss: 2.02963517109553

Epoch: 6| Step: 12
Training loss: 1.7155811786651611
Validation loss: 2.0248185197512307

Epoch: 6| Step: 13
Training loss: 2.3353676795959473
Validation loss: 2.021440088748932

Epoch: 120| Step: 0
Training loss: 2.0327038764953613
Validation loss: 2.024279554684957

Epoch: 6| Step: 1
Training loss: 1.9830864667892456
Validation loss: 2.0258595943450928

Epoch: 6| Step: 2
Training loss: 1.9421415328979492
Validation loss: 2.0317705869674683

Epoch: 6| Step: 3
Training loss: 1.8578588962554932
Validation loss: 2.025635242462158

Epoch: 6| Step: 4
Training loss: 2.924365520477295
Validation loss: 2.0181690454483032

Epoch: 6| Step: 5
Training loss: 2.177830934524536
Validation loss: 2.0248989264170327

Epoch: 6| Step: 6
Training loss: 1.6103646755218506
Validation loss: 2.0329018235206604

Epoch: 6| Step: 7
Training loss: 2.3391823768615723
Validation loss: 2.0198956529299417

Epoch: 6| Step: 8
Training loss: 1.7602964639663696
Validation loss: 2.026866873105367

Epoch: 6| Step: 9
Training loss: 2.7530126571655273
Validation loss: 2.0307636857032776

Epoch: 6| Step: 10
Training loss: 2.051711320877075
Validation loss: 2.0342381993929544

Epoch: 6| Step: 11
Training loss: 2.240708351135254
Validation loss: 2.0368919372558594

Epoch: 6| Step: 12
Training loss: 1.6971302032470703
Validation loss: 2.037951032320658

Epoch: 6| Step: 13
Training loss: 1.871382713317871
Validation loss: 2.0218551754951477

Epoch: 121| Step: 0
Training loss: 1.414031982421875
Validation loss: 2.0332307616869607

Epoch: 6| Step: 1
Training loss: 2.4343230724334717
Validation loss: 2.0391368865966797

Epoch: 6| Step: 2
Training loss: 1.9216694831848145
Validation loss: 2.036538044611613

Epoch: 6| Step: 3
Training loss: 2.54864239692688
Validation loss: 2.0402360955874124

Epoch: 6| Step: 4
Training loss: 2.0462207794189453
Validation loss: 2.028075615564982

Epoch: 6| Step: 5
Training loss: 1.937800645828247
Validation loss: 2.029609223206838

Epoch: 6| Step: 6
Training loss: 2.070882797241211
Validation loss: 2.0321187178293862

Epoch: 6| Step: 7
Training loss: 2.2676732540130615
Validation loss: 2.027551790078481

Epoch: 6| Step: 8
Training loss: 2.428772449493408
Validation loss: 2.038741191228231

Epoch: 6| Step: 9
Training loss: 2.0722029209136963
Validation loss: 2.0345048705736795

Epoch: 6| Step: 10
Training loss: 2.115995407104492
Validation loss: 2.062690238157908

Epoch: 6| Step: 11
Training loss: 1.4310319423675537
Validation loss: 2.046476423740387

Epoch: 6| Step: 12
Training loss: 2.6749935150146484
Validation loss: 2.061466932296753

Epoch: 6| Step: 13
Training loss: 1.857656478881836
Validation loss: 2.062867840131124

Epoch: 122| Step: 0
Training loss: 2.3208227157592773
Validation loss: 2.073555866877238

Epoch: 6| Step: 1
Training loss: 1.7771296501159668
Validation loss: 2.0819655855496726

Epoch: 6| Step: 2
Training loss: 1.3472280502319336
Validation loss: 2.0769766569137573

Epoch: 6| Step: 3
Training loss: 2.629972457885742
Validation loss: 2.083008964856466

Epoch: 6| Step: 4
Training loss: 1.9265108108520508
Validation loss: 2.0662527481714883

Epoch: 6| Step: 5
Training loss: 2.603248119354248
Validation loss: 2.060394207636515

Epoch: 6| Step: 6
Training loss: 2.1106185913085938
Validation loss: 2.0543293555577598

Epoch: 6| Step: 7
Training loss: 2.1813130378723145
Validation loss: 2.047380526860555

Epoch: 6| Step: 8
Training loss: 2.342517375946045
Validation loss: 2.034739315509796

Epoch: 6| Step: 9
Training loss: 1.6724961996078491
Validation loss: 2.0354789098103843

Epoch: 6| Step: 10
Training loss: 1.9931435585021973
Validation loss: 2.027147650718689

Epoch: 6| Step: 11
Training loss: 1.991658329963684
Validation loss: 2.018037577470144

Epoch: 6| Step: 12
Training loss: 2.146773338317871
Validation loss: 2.0209002097447715

Epoch: 6| Step: 13
Training loss: 2.340472459793091
Validation loss: 2.015787641207377

Epoch: 123| Step: 0
Training loss: 1.6937172412872314
Validation loss: 2.0244789520899453

Epoch: 6| Step: 1
Training loss: 2.593468189239502
Validation loss: 2.023699998855591

Epoch: 6| Step: 2
Training loss: 1.846634864807129
Validation loss: 2.020316163698832

Epoch: 6| Step: 3
Training loss: 1.5590929985046387
Validation loss: 2.015453279018402

Epoch: 6| Step: 4
Training loss: 1.9781708717346191
Validation loss: 2.0303133924802146

Epoch: 6| Step: 5
Training loss: 2.0890631675720215
Validation loss: 2.024455269177755

Epoch: 6| Step: 6
Training loss: 2.019899606704712
Validation loss: 2.023309270540873

Epoch: 6| Step: 7
Training loss: 2.057394504547119
Validation loss: 2.0204272667566934

Epoch: 6| Step: 8
Training loss: 2.2025256156921387
Validation loss: 2.0360201795895896

Epoch: 6| Step: 9
Training loss: 1.9622806310653687
Validation loss: 2.034376382827759

Epoch: 6| Step: 10
Training loss: 2.4083611965179443
Validation loss: 2.0329647262891135

Epoch: 6| Step: 11
Training loss: 2.594165802001953
Validation loss: 2.0238516132036843

Epoch: 6| Step: 12
Training loss: 2.458404064178467
Validation loss: 2.018407642841339

Epoch: 6| Step: 13
Training loss: 1.6845448017120361
Validation loss: 2.022488991419474

Epoch: 124| Step: 0
Training loss: 1.763159990310669
Validation loss: 2.0307081937789917

Epoch: 6| Step: 1
Training loss: 1.6908539533615112
Validation loss: 2.031769851843516

Epoch: 6| Step: 2
Training loss: 1.818190574645996
Validation loss: 2.03997411330541

Epoch: 6| Step: 3
Training loss: 1.4415028095245361
Validation loss: 2.0341118772824607

Epoch: 6| Step: 4
Training loss: 2.3739023208618164
Validation loss: 2.032076358795166

Epoch: 6| Step: 5
Training loss: 2.1389966011047363
Validation loss: 2.0438894629478455

Epoch: 6| Step: 6
Training loss: 2.366211414337158
Validation loss: 2.032867987950643

Epoch: 6| Step: 7
Training loss: 2.234745979309082
Validation loss: 2.0391891598701477

Epoch: 6| Step: 8
Training loss: 2.066235065460205
Validation loss: 2.0430601835250854

Epoch: 6| Step: 9
Training loss: 2.7800753116607666
Validation loss: 2.0427233974138894

Epoch: 6| Step: 10
Training loss: 1.9939123392105103
Validation loss: 2.037932197252909

Epoch: 6| Step: 11
Training loss: 2.23639178276062
Validation loss: 2.0360965927441916

Epoch: 6| Step: 12
Training loss: 1.9894739389419556
Validation loss: 2.044088284174601

Epoch: 6| Step: 13
Training loss: 2.276801586151123
Validation loss: 2.0471067428588867

Epoch: 125| Step: 0
Training loss: 2.235065460205078
Validation loss: 2.0372633139292398

Epoch: 6| Step: 1
Training loss: 2.4167532920837402
Validation loss: 2.0410702427228293

Epoch: 6| Step: 2
Training loss: 2.3017196655273438
Validation loss: 2.042795419692993

Epoch: 6| Step: 3
Training loss: 1.551252007484436
Validation loss: 2.0521936615308127

Epoch: 6| Step: 4
Training loss: 2.3144173622131348
Validation loss: 2.0528385639190674

Epoch: 6| Step: 5
Training loss: 1.5462849140167236
Validation loss: 2.06629486878713

Epoch: 6| Step: 6
Training loss: 2.0287675857543945
Validation loss: 2.0658140977223716

Epoch: 6| Step: 7
Training loss: 1.7682230472564697
Validation loss: 2.05436376730601

Epoch: 6| Step: 8
Training loss: 2.5312228202819824
Validation loss: 2.067639092604319

Epoch: 6| Step: 9
Training loss: 2.0003104209899902
Validation loss: 2.068155884742737

Epoch: 6| Step: 10
Training loss: 2.1674232482910156
Validation loss: 2.0615243911743164

Epoch: 6| Step: 11
Training loss: 2.1798200607299805
Validation loss: 2.050766189893087

Epoch: 6| Step: 12
Training loss: 1.8382995128631592
Validation loss: 2.0474547942479453

Epoch: 6| Step: 13
Training loss: 2.3163232803344727
Validation loss: 2.045706590016683

Epoch: 126| Step: 0
Training loss: 2.3222696781158447
Validation loss: 2.0251397490501404

Epoch: 6| Step: 1
Training loss: 2.2215092182159424
Validation loss: 2.034719705581665

Epoch: 6| Step: 2
Training loss: 1.9927663803100586
Validation loss: 2.0239522655804953

Epoch: 6| Step: 3
Training loss: 2.3507790565490723
Validation loss: 2.0329981446266174

Epoch: 6| Step: 4
Training loss: 2.0724234580993652
Validation loss: 2.0407997568448386

Epoch: 6| Step: 5
Training loss: 2.18163800239563
Validation loss: 2.041621724764506

Epoch: 6| Step: 6
Training loss: 1.815765619277954
Validation loss: 2.043899655342102

Epoch: 6| Step: 7
Training loss: 2.1684370040893555
Validation loss: 2.0375948746999106

Epoch: 6| Step: 8
Training loss: 1.6533329486846924
Validation loss: 2.0551847020785012

Epoch: 6| Step: 9
Training loss: 2.157270908355713
Validation loss: 2.0624817411104837

Epoch: 6| Step: 10
Training loss: 2.5842666625976562
Validation loss: 2.050628145535787

Epoch: 6| Step: 11
Training loss: 1.4015121459960938
Validation loss: 2.073584000269572

Epoch: 6| Step: 12
Training loss: 1.683672547340393
Validation loss: 2.0568227767944336

Epoch: 6| Step: 13
Training loss: 2.3471145629882812
Validation loss: 2.0776040156682334

Epoch: 127| Step: 0
Training loss: 1.8929767608642578
Validation loss: 2.0663989186286926

Epoch: 6| Step: 1
Training loss: 1.1606473922729492
Validation loss: 2.0671021739641824

Epoch: 6| Step: 2
Training loss: 2.23507022857666
Validation loss: 2.0770655274391174

Epoch: 6| Step: 3
Training loss: 1.7135238647460938
Validation loss: 2.0665865739186606

Epoch: 6| Step: 4
Training loss: 2.2740676403045654
Validation loss: 2.0693611105283103

Epoch: 6| Step: 5
Training loss: 2.6064271926879883
Validation loss: 2.050520380338033

Epoch: 6| Step: 6
Training loss: 2.2558984756469727
Validation loss: 2.0626920064290366

Epoch: 6| Step: 7
Training loss: 2.2890474796295166
Validation loss: 2.0515294273694358

Epoch: 6| Step: 8
Training loss: 2.5840535163879395
Validation loss: 2.050858994325002

Epoch: 6| Step: 9
Training loss: 1.5001548528671265
Validation loss: 2.0338332851727805

Epoch: 6| Step: 10
Training loss: 2.619626522064209
Validation loss: 2.038521329561869

Epoch: 6| Step: 11
Training loss: 1.8722255229949951
Validation loss: 2.0375635425249734

Epoch: 6| Step: 12
Training loss: 2.5754647254943848
Validation loss: 2.030551254749298

Epoch: 6| Step: 13
Training loss: 1.6958510875701904
Validation loss: 2.047889292240143

Epoch: 128| Step: 0
Training loss: 1.970023274421692
Validation loss: 2.0383764108022056

Epoch: 6| Step: 1
Training loss: 1.946229100227356
Validation loss: 2.0405607422192893

Epoch: 6| Step: 2
Training loss: 1.8649554252624512
Validation loss: 2.0317221681276956

Epoch: 6| Step: 3
Training loss: 1.8423715829849243
Validation loss: 2.0427244504292807

Epoch: 6| Step: 4
Training loss: 1.5991058349609375
Validation loss: 2.0415682395299277

Epoch: 6| Step: 5
Training loss: 2.058154582977295
Validation loss: 2.045869608720144

Epoch: 6| Step: 6
Training loss: 2.762136459350586
Validation loss: 2.049044450124105

Epoch: 6| Step: 7
Training loss: 2.234386920928955
Validation loss: 2.0512894789377847

Epoch: 6| Step: 8
Training loss: 2.3100874423980713
Validation loss: 2.0492856899897256

Epoch: 6| Step: 9
Training loss: 2.1131014823913574
Validation loss: 2.0471664865811667

Epoch: 6| Step: 10
Training loss: 2.4258241653442383
Validation loss: 2.0541203220685325

Epoch: 6| Step: 11
Training loss: 2.293752670288086
Validation loss: 2.038363774617513

Epoch: 6| Step: 12
Training loss: 1.7215635776519775
Validation loss: 2.0470104217529297

Epoch: 6| Step: 13
Training loss: 2.078622579574585
Validation loss: 2.049169143040975

Epoch: 129| Step: 0
Training loss: 2.3867440223693848
Validation loss: 2.0400725603103638

Epoch: 6| Step: 1
Training loss: 2.134132146835327
Validation loss: 2.049777706464132

Epoch: 6| Step: 2
Training loss: 1.7607362270355225
Validation loss: 2.036681036154429

Epoch: 6| Step: 3
Training loss: 2.0924251079559326
Validation loss: 2.035060922304789

Epoch: 6| Step: 4
Training loss: 2.177823066711426
Validation loss: 2.0214438835779824

Epoch: 6| Step: 5
Training loss: 1.50783109664917
Validation loss: 2.0172542333602905

Epoch: 6| Step: 6
Training loss: 2.684664726257324
Validation loss: 2.03068079551061

Epoch: 6| Step: 7
Training loss: 1.6621592044830322
Validation loss: 2.035715917746226

Epoch: 6| Step: 8
Training loss: 1.9525628089904785
Validation loss: 2.0284421841303506

Epoch: 6| Step: 9
Training loss: 1.7217836380004883
Validation loss: 2.0276074608167014

Epoch: 6| Step: 10
Training loss: 2.2507662773132324
Validation loss: 2.0245769023895264

Epoch: 6| Step: 11
Training loss: 1.625566840171814
Validation loss: 2.0248977541923523

Epoch: 6| Step: 12
Training loss: 3.002046823501587
Validation loss: 2.032615860303243

Epoch: 6| Step: 13
Training loss: 2.499647378921509
Validation loss: 2.0273155570030212

Epoch: 130| Step: 0
Training loss: 1.620270013809204
Validation loss: 2.0396052598953247

Epoch: 6| Step: 1
Training loss: 2.531397819519043
Validation loss: 2.028653343518575

Epoch: 6| Step: 2
Training loss: 1.6429377794265747
Validation loss: 2.0430087645848594

Epoch: 6| Step: 3
Training loss: 1.5405341386795044
Validation loss: 2.0621344248453775

Epoch: 6| Step: 4
Training loss: 2.207531213760376
Validation loss: 2.0713672637939453

Epoch: 6| Step: 5
Training loss: 2.645714282989502
Validation loss: 2.072682480017344

Epoch: 6| Step: 6
Training loss: 1.7377593517303467
Validation loss: 2.0750985940297446

Epoch: 6| Step: 7
Training loss: 1.9360315799713135
Validation loss: 2.079634646574656

Epoch: 6| Step: 8
Training loss: 1.6363521814346313
Validation loss: 2.0691809256871543

Epoch: 6| Step: 9
Training loss: 2.249612331390381
Validation loss: 2.05937925974528

Epoch: 6| Step: 10
Training loss: 2.3593835830688477
Validation loss: 2.0480186541875205

Epoch: 6| Step: 11
Training loss: 1.843550205230713
Validation loss: 2.050863345464071

Epoch: 6| Step: 12
Training loss: 2.4581403732299805
Validation loss: 2.0338019728660583

Epoch: 6| Step: 13
Training loss: 2.297780990600586
Validation loss: 2.0357247988382974

Epoch: 131| Step: 0
Training loss: 2.078324556350708
Validation loss: 2.0302218000094094

Epoch: 6| Step: 1
Training loss: 1.8761860132217407
Validation loss: 2.033580203851064

Epoch: 6| Step: 2
Training loss: 2.4433069229125977
Validation loss: 2.028756241003672

Epoch: 6| Step: 3
Training loss: 3.071713924407959
Validation loss: 2.0346280336380005

Epoch: 6| Step: 4
Training loss: 2.1418888568878174
Validation loss: 2.0331467191378274

Epoch: 6| Step: 5
Training loss: 2.0420172214508057
Validation loss: 2.0404465397198996

Epoch: 6| Step: 6
Training loss: 1.6185863018035889
Validation loss: 2.029380758603414

Epoch: 6| Step: 7
Training loss: 1.4607532024383545
Validation loss: 2.0298925638198853

Epoch: 6| Step: 8
Training loss: 2.6881587505340576
Validation loss: 2.026218295097351

Epoch: 6| Step: 9
Training loss: 2.1865715980529785
Validation loss: 2.0254454811414084

Epoch: 6| Step: 10
Training loss: 1.8197827339172363
Validation loss: 2.0369635621706643

Epoch: 6| Step: 11
Training loss: 2.436964511871338
Validation loss: 2.032101809978485

Epoch: 6| Step: 12
Training loss: 2.457138776779175
Validation loss: 2.035137097040812

Epoch: 6| Step: 13
Training loss: 1.294654130935669
Validation loss: 2.0348461667696633

Epoch: 132| Step: 0
Training loss: 2.400623321533203
Validation loss: 2.050308028856913

Epoch: 6| Step: 1
Training loss: 1.6159305572509766
Validation loss: 2.0602734088897705

Epoch: 6| Step: 2
Training loss: 2.2464451789855957
Validation loss: 2.0579803784688315

Epoch: 6| Step: 3
Training loss: 2.189326286315918
Validation loss: 2.052448113759359

Epoch: 6| Step: 4
Training loss: 2.60056209564209
Validation loss: 2.056523601214091

Epoch: 6| Step: 5
Training loss: 1.8916805982589722
Validation loss: 2.0622055729230246

Epoch: 6| Step: 6
Training loss: 2.116950035095215
Validation loss: 2.0779693325360618

Epoch: 6| Step: 7
Training loss: 2.1882379055023193
Validation loss: 2.073050856590271

Epoch: 6| Step: 8
Training loss: 1.6162362098693848
Validation loss: 2.0828558603922525

Epoch: 6| Step: 9
Training loss: 1.516648769378662
Validation loss: 2.096014161904653

Epoch: 6| Step: 10
Training loss: 1.6268959045410156
Validation loss: 2.0910112063090005

Epoch: 6| Step: 11
Training loss: 2.0819525718688965
Validation loss: 2.0864771604537964

Epoch: 6| Step: 12
Training loss: 2.931699752807617
Validation loss: 2.0939294894536338

Epoch: 6| Step: 13
Training loss: 2.1586461067199707
Validation loss: 2.0891930063565574

Epoch: 133| Step: 0
Training loss: 2.7749431133270264
Validation loss: 2.0682268738746643

Epoch: 6| Step: 1
Training loss: 1.474823236465454
Validation loss: 2.0531665484110513

Epoch: 6| Step: 2
Training loss: 1.9423140287399292
Validation loss: 2.0402338902155557

Epoch: 6| Step: 3
Training loss: 1.9531500339508057
Validation loss: 2.04006165266037

Epoch: 6| Step: 4
Training loss: 2.8589115142822266
Validation loss: 2.0387041370073953

Epoch: 6| Step: 5
Training loss: 1.7083958387374878
Validation loss: 2.0283740560213723

Epoch: 6| Step: 6
Training loss: 1.8490800857543945
Validation loss: 2.036198318004608

Epoch: 6| Step: 7
Training loss: 1.9428706169128418
Validation loss: 2.0311342080434165

Epoch: 6| Step: 8
Training loss: 1.8724615573883057
Validation loss: 2.043788433074951

Epoch: 6| Step: 9
Training loss: 2.489840030670166
Validation loss: 2.030725638071696

Epoch: 6| Step: 10
Training loss: 2.6882801055908203
Validation loss: 2.036957065264384

Epoch: 6| Step: 11
Training loss: 2.0448694229125977
Validation loss: 2.034131944179535

Epoch: 6| Step: 12
Training loss: 1.9704129695892334
Validation loss: 2.0356318950653076

Epoch: 6| Step: 13
Training loss: 1.8322460651397705
Validation loss: 2.0391611655553183

Epoch: 134| Step: 0
Training loss: 2.3282310962677
Validation loss: 2.041699548562368

Epoch: 6| Step: 1
Training loss: 2.205415725708008
Validation loss: 2.038586755593618

Epoch: 6| Step: 2
Training loss: 1.7318880558013916
Validation loss: 2.040882964928945

Epoch: 6| Step: 3
Training loss: 2.5699877738952637
Validation loss: 2.045867661635081

Epoch: 6| Step: 4
Training loss: 1.6060833930969238
Validation loss: 2.0555597941080728

Epoch: 6| Step: 5
Training loss: 2.035247564315796
Validation loss: 2.0836163560549417

Epoch: 6| Step: 6
Training loss: 1.609909176826477
Validation loss: 2.0710553526878357

Epoch: 6| Step: 7
Training loss: 1.8861461877822876
Validation loss: 2.083788593610128

Epoch: 6| Step: 8
Training loss: 2.1001012325286865
Validation loss: 2.091431717077891

Epoch: 6| Step: 9
Training loss: 2.3427574634552
Validation loss: 2.0982770919799805

Epoch: 6| Step: 10
Training loss: 1.5857751369476318
Validation loss: 2.083130419254303

Epoch: 6| Step: 11
Training loss: 2.768411636352539
Validation loss: 2.0751799941062927

Epoch: 6| Step: 12
Training loss: 2.092602491378784
Validation loss: 2.0717826684316

Epoch: 6| Step: 13
Training loss: 2.115694522857666
Validation loss: 2.0602422952651978

Epoch: 135| Step: 0
Training loss: 1.8298391103744507
Validation loss: 2.064489742120107

Epoch: 6| Step: 1
Training loss: 2.3334858417510986
Validation loss: 2.063766817251841

Epoch: 6| Step: 2
Training loss: 1.7716453075408936
Validation loss: 2.0603949228922525

Epoch: 6| Step: 3
Training loss: 2.0730857849121094
Validation loss: 2.0571012695630393

Epoch: 6| Step: 4
Training loss: 2.1711931228637695
Validation loss: 2.0687153935432434

Epoch: 6| Step: 5
Training loss: 1.913104772567749
Validation loss: 2.0756724874178567

Epoch: 6| Step: 6
Training loss: 1.9248521327972412
Validation loss: 2.0717567006746926

Epoch: 6| Step: 7
Training loss: 2.213880777359009
Validation loss: 2.066719969113668

Epoch: 6| Step: 8
Training loss: 2.3886022567749023
Validation loss: 2.08509894212087

Epoch: 6| Step: 9
Training loss: 2.5268397331237793
Validation loss: 2.0744831760724387

Epoch: 6| Step: 10
Training loss: 2.2324633598327637
Validation loss: 2.0549067656199136

Epoch: 6| Step: 11
Training loss: 2.0132157802581787
Validation loss: 2.0608755151430764

Epoch: 6| Step: 12
Training loss: 1.6005125045776367
Validation loss: 2.068916161855062

Epoch: 6| Step: 13
Training loss: 1.683673620223999
Validation loss: 2.0644949674606323

Epoch: 136| Step: 0
Training loss: 2.1593098640441895
Validation loss: 2.0777222911516824

Epoch: 6| Step: 1
Training loss: 2.6700439453125
Validation loss: 2.0805370807647705

Epoch: 6| Step: 2
Training loss: 1.9996930360794067
Validation loss: 2.0884108742078147

Epoch: 6| Step: 3
Training loss: 1.9865792989730835
Validation loss: 2.0871846675872803

Epoch: 6| Step: 4
Training loss: 1.8975530862808228
Validation loss: 2.084635337193807

Epoch: 6| Step: 5
Training loss: 1.6148713827133179
Validation loss: 2.081095814704895

Epoch: 6| Step: 6
Training loss: 1.6644530296325684
Validation loss: 2.06403241554896

Epoch: 6| Step: 7
Training loss: 2.812859058380127
Validation loss: 2.054951469103495

Epoch: 6| Step: 8
Training loss: 1.7506935596466064
Validation loss: 2.063202460606893

Epoch: 6| Step: 9
Training loss: 1.8462255001068115
Validation loss: 2.0595136284828186

Epoch: 6| Step: 10
Training loss: 1.8337068557739258
Validation loss: 2.0526172518730164

Epoch: 6| Step: 11
Training loss: 1.5846701860427856
Validation loss: 2.0597752928733826

Epoch: 6| Step: 12
Training loss: 2.747425079345703
Validation loss: 2.0619763334592185

Epoch: 6| Step: 13
Training loss: 2.085753917694092
Validation loss: 2.058303157488505

Epoch: 137| Step: 0
Training loss: 1.7480113506317139
Validation loss: 2.0709744493166604

Epoch: 6| Step: 1
Training loss: 1.9837133884429932
Validation loss: 2.075209657351176

Epoch: 6| Step: 2
Training loss: 2.4204721450805664
Validation loss: 2.0537480314572654

Epoch: 6| Step: 3
Training loss: 2.723081111907959
Validation loss: 2.0584993163744607

Epoch: 6| Step: 4
Training loss: 1.7905443906784058
Validation loss: 2.058718224366506

Epoch: 6| Step: 5
Training loss: 1.366858959197998
Validation loss: 2.037825802961985

Epoch: 6| Step: 6
Training loss: 2.501711845397949
Validation loss: 2.0392940044403076

Epoch: 6| Step: 7
Training loss: 1.970331072807312
Validation loss: 2.0528037548065186

Epoch: 6| Step: 8
Training loss: 2.689828634262085
Validation loss: 2.047526160875956

Epoch: 6| Step: 9
Training loss: 2.243053913116455
Validation loss: 2.0727498531341553

Epoch: 6| Step: 10
Training loss: 2.072395086288452
Validation loss: 2.058850725491842

Epoch: 6| Step: 11
Training loss: 1.8749275207519531
Validation loss: 2.048369745413462

Epoch: 6| Step: 12
Training loss: 1.3696354627609253
Validation loss: 2.0546629627545676

Epoch: 6| Step: 13
Training loss: 1.852208137512207
Validation loss: 2.0455745657285056

Epoch: 138| Step: 0
Training loss: 2.094184637069702
Validation loss: 2.054073750972748

Epoch: 6| Step: 1
Training loss: 2.013920783996582
Validation loss: 2.0414884090423584

Epoch: 6| Step: 2
Training loss: 2.0684239864349365
Validation loss: 2.0360430479049683

Epoch: 6| Step: 3
Training loss: 1.6433765888214111
Validation loss: 2.037101169427236

Epoch: 6| Step: 4
Training loss: 2.0530383586883545
Validation loss: 2.0367074608802795

Epoch: 6| Step: 5
Training loss: 1.982312560081482
Validation loss: 2.058374524116516

Epoch: 6| Step: 6
Training loss: 2.102762222290039
Validation loss: 2.0727410515149436

Epoch: 6| Step: 7
Training loss: 2.601710557937622
Validation loss: 2.0862773060798645

Epoch: 6| Step: 8
Training loss: 1.9834572076797485
Validation loss: 2.1081741054852805

Epoch: 6| Step: 9
Training loss: 2.2926769256591797
Validation loss: 2.0968366861343384

Epoch: 6| Step: 10
Training loss: 1.8714399337768555
Validation loss: 2.0827985803286233

Epoch: 6| Step: 11
Training loss: 1.84232497215271
Validation loss: 2.091482182343801

Epoch: 6| Step: 12
Training loss: 2.2599685192108154
Validation loss: 2.0770371357599893

Epoch: 6| Step: 13
Training loss: 2.2089662551879883
Validation loss: 2.0643612146377563

Epoch: 139| Step: 0
Training loss: 1.771965503692627
Validation loss: 2.0627471804618835

Epoch: 6| Step: 1
Training loss: 1.9175578355789185
Validation loss: 2.054922600587209

Epoch: 6| Step: 2
Training loss: 2.023296356201172
Validation loss: 2.057779769102732

Epoch: 6| Step: 3
Training loss: 2.259580612182617
Validation loss: 2.0601526697476706

Epoch: 6| Step: 4
Training loss: 1.8103224039077759
Validation loss: 2.070192893346151

Epoch: 6| Step: 5
Training loss: 2.1750049591064453
Validation loss: 2.0676861802736917

Epoch: 6| Step: 6
Training loss: 2.6108238697052
Validation loss: 2.063831011454264

Epoch: 6| Step: 7
Training loss: 1.9026529788970947
Validation loss: 2.0533716281255088

Epoch: 6| Step: 8
Training loss: 2.4689974784851074
Validation loss: 2.0620458523432412

Epoch: 6| Step: 9
Training loss: 2.1799373626708984
Validation loss: 2.0607652266820273

Epoch: 6| Step: 10
Training loss: 1.5787931680679321
Validation loss: 2.0464589595794678

Epoch: 6| Step: 11
Training loss: 1.9756791591644287
Validation loss: 2.06419038772583

Epoch: 6| Step: 12
Training loss: 2.2980308532714844
Validation loss: 2.0621169408162436

Epoch: 6| Step: 13
Training loss: 1.6399471759796143
Validation loss: 2.058048983414968

Epoch: 140| Step: 0
Training loss: 2.2077369689941406
Validation loss: 2.049709975719452

Epoch: 6| Step: 1
Training loss: 2.1243655681610107
Validation loss: 2.0567493438720703

Epoch: 6| Step: 2
Training loss: 2.514416217803955
Validation loss: 2.0706804990768433

Epoch: 6| Step: 3
Training loss: 1.9780036211013794
Validation loss: 2.065366188685099

Epoch: 6| Step: 4
Training loss: 1.7877869606018066
Validation loss: 2.065910975138346

Epoch: 6| Step: 5
Training loss: 1.9527019262313843
Validation loss: 2.065092384815216

Epoch: 6| Step: 6
Training loss: 2.0377862453460693
Validation loss: 2.068603197733561

Epoch: 6| Step: 7
Training loss: 2.18662691116333
Validation loss: 2.0822550455729165

Epoch: 6| Step: 8
Training loss: 1.5001070499420166
Validation loss: 2.074876526991526

Epoch: 6| Step: 9
Training loss: 1.8840806484222412
Validation loss: 2.068506379922231

Epoch: 6| Step: 10
Training loss: 2.4132590293884277
Validation loss: 2.0784777402877808

Epoch: 6| Step: 11
Training loss: 1.4888262748718262
Validation loss: 2.0763349135716758

Epoch: 6| Step: 12
Training loss: 2.4420549869537354
Validation loss: 2.0717623631159463

Epoch: 6| Step: 13
Training loss: 2.2993175983428955
Validation loss: 2.0553781390190125

Epoch: 141| Step: 0
Training loss: 2.599503993988037
Validation loss: 2.0624104936917624

Epoch: 6| Step: 1
Training loss: 1.9863636493682861
Validation loss: 2.0614513754844666

Epoch: 6| Step: 2
Training loss: 2.044156551361084
Validation loss: 2.070204794406891

Epoch: 6| Step: 3
Training loss: 2.1127054691314697
Validation loss: 2.0706217288970947

Epoch: 6| Step: 4
Training loss: 2.257394790649414
Validation loss: 2.080150306224823

Epoch: 6| Step: 5
Training loss: 1.8792005777359009
Validation loss: 2.1010138193766275

Epoch: 6| Step: 6
Training loss: 2.4511775970458984
Validation loss: 2.094998300075531

Epoch: 6| Step: 7
Training loss: 2.1037590503692627
Validation loss: 2.097591499487559

Epoch: 6| Step: 8
Training loss: 2.584280014038086
Validation loss: 2.081219732761383

Epoch: 6| Step: 9
Training loss: 1.7342441082000732
Validation loss: 2.078313112258911

Epoch: 6| Step: 10
Training loss: 2.0052108764648438
Validation loss: 2.065444072087606

Epoch: 6| Step: 11
Training loss: 1.7495027780532837
Validation loss: 2.063267628351847

Epoch: 6| Step: 12
Training loss: 2.316211462020874
Validation loss: 2.0580159624417624

Epoch: 6| Step: 13
Training loss: 1.3094279766082764
Validation loss: 2.0460183024406433

Epoch: 142| Step: 0
Training loss: 2.509762763977051
Validation loss: 2.051782190799713

Epoch: 6| Step: 1
Training loss: 2.254167079925537
Validation loss: 2.0446006655693054

Epoch: 6| Step: 2
Training loss: 1.9521608352661133
Validation loss: 2.039043962955475

Epoch: 6| Step: 3
Training loss: 2.041276454925537
Validation loss: 2.0371298789978027

Epoch: 6| Step: 4
Training loss: 1.7347207069396973
Validation loss: 2.031451106071472

Epoch: 6| Step: 5
Training loss: 1.8931677341461182
Validation loss: 2.0508415500322976

Epoch: 6| Step: 6
Training loss: 2.265000343322754
Validation loss: 2.064454992612203

Epoch: 6| Step: 7
Training loss: 2.839185953140259
Validation loss: 2.0799981355667114

Epoch: 6| Step: 8
Training loss: 1.7740540504455566
Validation loss: 2.0769556562105813

Epoch: 6| Step: 9
Training loss: 1.9372906684875488
Validation loss: 2.074015657107035

Epoch: 6| Step: 10
Training loss: 1.6515452861785889
Validation loss: 2.0738792419433594

Epoch: 6| Step: 11
Training loss: 1.4196134805679321
Validation loss: 2.05429216225942

Epoch: 6| Step: 12
Training loss: 2.2860703468322754
Validation loss: 2.061024804910024

Epoch: 6| Step: 13
Training loss: 2.2449469566345215
Validation loss: 2.057855506738027

Epoch: 143| Step: 0
Training loss: 1.8312394618988037
Validation loss: 2.041209956010183

Epoch: 6| Step: 1
Training loss: 2.468012809753418
Validation loss: 2.0510907967885337

Epoch: 6| Step: 2
Training loss: 1.7702836990356445
Validation loss: 2.0299580891927085

Epoch: 6| Step: 3
Training loss: 2.1168599128723145
Validation loss: 2.039796014626821

Epoch: 6| Step: 4
Training loss: 2.702819347381592
Validation loss: 2.034142335255941

Epoch: 6| Step: 5
Training loss: 1.606478214263916
Validation loss: 2.0352606972058616

Epoch: 6| Step: 6
Training loss: 1.8051354885101318
Validation loss: 2.029638191064199

Epoch: 6| Step: 7
Training loss: 2.029740333557129
Validation loss: 2.036047379175822

Epoch: 6| Step: 8
Training loss: 2.8474488258361816
Validation loss: 2.0334704717000327

Epoch: 6| Step: 9
Training loss: 1.6629799604415894
Validation loss: 2.0339504281679788

Epoch: 6| Step: 10
Training loss: 2.295330047607422
Validation loss: 2.0437159339586892

Epoch: 6| Step: 11
Training loss: 2.0162506103515625
Validation loss: 2.0326416889826455

Epoch: 6| Step: 12
Training loss: 1.8663582801818848
Validation loss: 2.051605006059011

Epoch: 6| Step: 13
Training loss: 1.8989067077636719
Validation loss: 2.0655792951583862

Epoch: 144| Step: 0
Training loss: 1.5120271444320679
Validation loss: 2.0719842314720154

Epoch: 6| Step: 1
Training loss: 2.7506661415100098
Validation loss: 2.0610448320706687

Epoch: 6| Step: 2
Training loss: 2.278329849243164
Validation loss: 2.06095023949941

Epoch: 6| Step: 3
Training loss: 2.245926856994629
Validation loss: 2.072640379269918

Epoch: 6| Step: 4
Training loss: 1.9572558403015137
Validation loss: 2.080325265725454

Epoch: 6| Step: 5
Training loss: 1.7953531742095947
Validation loss: 2.0847765803337097

Epoch: 6| Step: 6
Training loss: 1.599044919013977
Validation loss: 2.0866699616114297

Epoch: 6| Step: 7
Training loss: 2.0011801719665527
Validation loss: 2.0780786871910095

Epoch: 6| Step: 8
Training loss: 1.8826651573181152
Validation loss: 2.075384338696798

Epoch: 6| Step: 9
Training loss: 2.567613124847412
Validation loss: 2.069139838218689

Epoch: 6| Step: 10
Training loss: 1.6099653244018555
Validation loss: 2.0722419023513794

Epoch: 6| Step: 11
Training loss: 1.9941928386688232
Validation loss: 2.0597922801971436

Epoch: 6| Step: 12
Training loss: 2.3434910774230957
Validation loss: 2.0519126256306968

Epoch: 6| Step: 13
Training loss: 2.0542869567871094
Validation loss: 2.0475761691729226

Epoch: 145| Step: 0
Training loss: 2.4130988121032715
Validation loss: 2.0447901288668313

Epoch: 6| Step: 1
Training loss: 2.3704946041107178
Validation loss: 2.0497071146965027

Epoch: 6| Step: 2
Training loss: 2.004206657409668
Validation loss: 2.0477035641670227

Epoch: 6| Step: 3
Training loss: 2.3611984252929688
Validation loss: 2.0409738222757974

Epoch: 6| Step: 4
Training loss: 1.9521323442459106
Validation loss: 2.052639921506246

Epoch: 6| Step: 5
Training loss: 1.4746302366256714
Validation loss: 2.055937667687734

Epoch: 6| Step: 6
Training loss: 1.6704614162445068
Validation loss: 2.06837926308314

Epoch: 6| Step: 7
Training loss: 1.9071695804595947
Validation loss: 2.076986829439799

Epoch: 6| Step: 8
Training loss: 1.7645549774169922
Validation loss: 2.0860156416893005

Epoch: 6| Step: 9
Training loss: 1.7505799531936646
Validation loss: 2.0843515594800315

Epoch: 6| Step: 10
Training loss: 2.4766855239868164
Validation loss: 2.09500382343928

Epoch: 6| Step: 11
Training loss: 2.476719617843628
Validation loss: 2.1063676873842874

Epoch: 6| Step: 12
Training loss: 2.3932197093963623
Validation loss: 2.093395213286082

Epoch: 6| Step: 13
Training loss: 1.681849718093872
Validation loss: 2.0884159803390503

Epoch: 146| Step: 0
Training loss: 2.543776512145996
Validation loss: 2.094552516937256

Epoch: 6| Step: 1
Training loss: 2.0717527866363525
Validation loss: 2.0807373325030007

Epoch: 6| Step: 2
Training loss: 2.7054057121276855
Validation loss: 2.0781835516293845

Epoch: 6| Step: 3
Training loss: 1.8830469846725464
Validation loss: 2.0707902709643045

Epoch: 6| Step: 4
Training loss: 1.7285287380218506
Validation loss: 2.0557206670443215

Epoch: 6| Step: 5
Training loss: 1.6926579475402832
Validation loss: 2.0649495124816895

Epoch: 6| Step: 6
Training loss: 1.997469425201416
Validation loss: 2.052561342716217

Epoch: 6| Step: 7
Training loss: 2.58998441696167
Validation loss: 2.0544784665107727

Epoch: 6| Step: 8
Training loss: 1.9499437808990479
Validation loss: 2.0409631729125977

Epoch: 6| Step: 9
Training loss: 1.9254627227783203
Validation loss: 2.056465744972229

Epoch: 6| Step: 10
Training loss: 2.0721378326416016
Validation loss: 2.0574079751968384

Epoch: 6| Step: 11
Training loss: 1.7245609760284424
Validation loss: 2.054718017578125

Epoch: 6| Step: 12
Training loss: 2.1370792388916016
Validation loss: 2.0605622927347818

Epoch: 6| Step: 13
Training loss: 1.8191707134246826
Validation loss: 2.059687932332357

Epoch: 147| Step: 0
Training loss: 1.972357988357544
Validation loss: 2.0690865317980447

Epoch: 6| Step: 1
Training loss: 1.825777530670166
Validation loss: 2.060108562310537

Epoch: 6| Step: 2
Training loss: 1.84843111038208
Validation loss: 2.0560487707455954

Epoch: 6| Step: 3
Training loss: 2.14086651802063
Validation loss: 2.0655880173047385

Epoch: 6| Step: 4
Training loss: 1.8053478002548218
Validation loss: 2.0658013423283896

Epoch: 6| Step: 5
Training loss: 2.1657681465148926
Validation loss: 2.07045845190684

Epoch: 6| Step: 6
Training loss: 1.8060170412063599
Validation loss: 2.074331780274709

Epoch: 6| Step: 7
Training loss: 2.0596160888671875
Validation loss: 2.0596322615941367

Epoch: 6| Step: 8
Training loss: 1.5318708419799805
Validation loss: 2.0633567770322165

Epoch: 6| Step: 9
Training loss: 2.1484742164611816
Validation loss: 2.0675824085871377

Epoch: 6| Step: 10
Training loss: 2.8650336265563965
Validation loss: 2.083886464436849

Epoch: 6| Step: 11
Training loss: 1.7332160472869873
Validation loss: 2.094977080821991

Epoch: 6| Step: 12
Training loss: 2.7568774223327637
Validation loss: 2.069717506567637

Epoch: 6| Step: 13
Training loss: 2.1562249660491943
Validation loss: 2.083579738934835

Epoch: 148| Step: 0
Training loss: 1.4287432432174683
Validation loss: 2.090608795483907

Epoch: 6| Step: 1
Training loss: 1.6733424663543701
Validation loss: 2.0904401739438376

Epoch: 6| Step: 2
Training loss: 1.9820466041564941
Validation loss: 2.081673483053843

Epoch: 6| Step: 3
Training loss: 1.8584530353546143
Validation loss: 2.0845773816108704

Epoch: 6| Step: 4
Training loss: 1.4684115648269653
Validation loss: 2.069953282674154

Epoch: 6| Step: 5
Training loss: 2.7866625785827637
Validation loss: 2.084892749786377

Epoch: 6| Step: 6
Training loss: 2.14401912689209
Validation loss: 2.089846392472585

Epoch: 6| Step: 7
Training loss: 2.574157238006592
Validation loss: 2.0846964518229165

Epoch: 6| Step: 8
Training loss: 2.265979766845703
Validation loss: 2.073858062426249

Epoch: 6| Step: 9
Training loss: 2.02290940284729
Validation loss: 2.080420116583506

Epoch: 6| Step: 10
Training loss: 1.5237945318222046
Validation loss: 2.0680861870447793

Epoch: 6| Step: 11
Training loss: 2.212324619293213
Validation loss: 2.0826807618141174

Epoch: 6| Step: 12
Training loss: 2.0582964420318604
Validation loss: 2.075434148311615

Epoch: 6| Step: 13
Training loss: 2.2430434226989746
Validation loss: 2.077720880508423

Epoch: 149| Step: 0
Training loss: 2.2854843139648438
Validation loss: 2.082452932993571

Epoch: 6| Step: 1
Training loss: 2.0614683628082275
Validation loss: 2.068783481915792

Epoch: 6| Step: 2
Training loss: 2.002762794494629
Validation loss: 2.0692143638928733

Epoch: 6| Step: 3
Training loss: 2.17329478263855
Validation loss: 2.081158538659414

Epoch: 6| Step: 4
Training loss: 1.4576036930084229
Validation loss: 2.0596877535184226

Epoch: 6| Step: 5
Training loss: 2.2873804569244385
Validation loss: 2.0669506390889487

Epoch: 6| Step: 6
Training loss: 1.9109666347503662
Validation loss: 2.061770419279734

Epoch: 6| Step: 7
Training loss: 2.158479690551758
Validation loss: 2.074015220006307

Epoch: 6| Step: 8
Training loss: 2.572080135345459
Validation loss: 2.061021347840627

Epoch: 6| Step: 9
Training loss: 1.831284523010254
Validation loss: 2.060575465361277

Epoch: 6| Step: 10
Training loss: 2.6821203231811523
Validation loss: 2.0690125624338784

Epoch: 6| Step: 11
Training loss: 1.5083391666412354
Validation loss: 2.0722875197728476

Epoch: 6| Step: 12
Training loss: 2.549720287322998
Validation loss: 2.076101620992025

Epoch: 6| Step: 13
Training loss: 1.5487947463989258
Validation loss: 2.058978041013082

Epoch: 150| Step: 0
Training loss: 1.560246467590332
Validation loss: 2.050655702749888

Epoch: 6| Step: 1
Training loss: 2.3728675842285156
Validation loss: 2.050876875718435

Epoch: 6| Step: 2
Training loss: 1.8269591331481934
Validation loss: 2.0508044958114624

Epoch: 6| Step: 3
Training loss: 1.6546074151992798
Validation loss: 2.0479413072268167

Epoch: 6| Step: 4
Training loss: 2.1168298721313477
Validation loss: 2.050764520963033

Epoch: 6| Step: 5
Training loss: 2.45797061920166
Validation loss: 2.042345941066742

Epoch: 6| Step: 6
Training loss: 1.9746628999710083
Validation loss: 2.045355478922526

Epoch: 6| Step: 7
Training loss: 2.6141698360443115
Validation loss: 2.0442654291788735

Epoch: 6| Step: 8
Training loss: 2.337280035018921
Validation loss: 2.0333673556645713

Epoch: 6| Step: 9
Training loss: 2.326824188232422
Validation loss: 2.044066846370697

Epoch: 6| Step: 10
Training loss: 2.3488569259643555
Validation loss: 2.035901109377543

Epoch: 6| Step: 11
Training loss: 1.6269991397857666
Validation loss: 2.0413590470949807

Epoch: 6| Step: 12
Training loss: 1.487585425376892
Validation loss: 2.043086528778076

Epoch: 6| Step: 13
Training loss: 1.958396553993225
Validation loss: 2.0507755676905313

Epoch: 151| Step: 0
Training loss: 2.0435664653778076
Validation loss: 2.0664650599161782

Epoch: 6| Step: 1
Training loss: 1.5203789472579956
Validation loss: 2.057415763537089

Epoch: 6| Step: 2
Training loss: 1.5783154964447021
Validation loss: 2.070773442586263

Epoch: 6| Step: 3
Training loss: 2.285574197769165
Validation loss: 2.076368232568105

Epoch: 6| Step: 4
Training loss: 1.969193696975708
Validation loss: 2.069532593091329

Epoch: 6| Step: 5
Training loss: 2.463540554046631
Validation loss: 2.068064252535502

Epoch: 6| Step: 6
Training loss: 2.3483943939208984
Validation loss: 2.0795782009760537

Epoch: 6| Step: 7
Training loss: 2.0970962047576904
Validation loss: 2.0725587606430054

Epoch: 6| Step: 8
Training loss: 1.8285119533538818
Validation loss: 2.0857909123102822

Epoch: 6| Step: 9
Training loss: 2.130859136581421
Validation loss: 2.091923952102661

Epoch: 6| Step: 10
Training loss: 1.7441112995147705
Validation loss: 2.08264551560084

Epoch: 6| Step: 11
Training loss: 1.3362959623336792
Validation loss: 2.086380441983541

Epoch: 6| Step: 12
Training loss: 1.8446481227874756
Validation loss: 2.0854473312695823

Epoch: 6| Step: 13
Training loss: 3.1575727462768555
Validation loss: 2.0793784658114114

Epoch: 152| Step: 0
Training loss: 1.7733948230743408
Validation loss: 2.052617132663727

Epoch: 6| Step: 1
Training loss: 2.6325223445892334
Validation loss: 2.0487838784853616

Epoch: 6| Step: 2
Training loss: 1.83739173412323
Validation loss: 2.0512231985727944

Epoch: 6| Step: 3
Training loss: 1.874163031578064
Validation loss: 2.0500601728757224

Epoch: 6| Step: 4
Training loss: 2.1365485191345215
Validation loss: 2.0646350979804993

Epoch: 6| Step: 5
Training loss: 2.051290273666382
Validation loss: 2.0554712613423667

Epoch: 6| Step: 6
Training loss: 1.837523102760315
Validation loss: 2.0560688972473145

Epoch: 6| Step: 7
Training loss: 2.151975154876709
Validation loss: 2.075405697027842

Epoch: 6| Step: 8
Training loss: 2.292747974395752
Validation loss: 2.0698055426279702

Epoch: 6| Step: 9
Training loss: 2.068739414215088
Validation loss: 2.0726860562960305

Epoch: 6| Step: 10
Training loss: 1.7537413835525513
Validation loss: 2.078405221303304

Epoch: 6| Step: 11
Training loss: 2.158484935760498
Validation loss: 2.0765608747800193

Epoch: 6| Step: 12
Training loss: 2.044236421585083
Validation loss: 2.082038621107737

Epoch: 6| Step: 13
Training loss: 2.0343308448791504
Validation loss: 2.067011058330536

Epoch: 153| Step: 0
Training loss: 2.1569161415100098
Validation loss: 2.085005005200704

Epoch: 6| Step: 1
Training loss: 1.7385947704315186
Validation loss: 2.0827680826187134

Epoch: 6| Step: 2
Training loss: 2.0087509155273438
Validation loss: 2.081391235192617

Epoch: 6| Step: 3
Training loss: 2.069462776184082
Validation loss: 2.077155033747355

Epoch: 6| Step: 4
Training loss: 2.5074872970581055
Validation loss: 2.083395302295685

Epoch: 6| Step: 5
Training loss: 2.0829620361328125
Validation loss: 2.0806074738502502

Epoch: 6| Step: 6
Training loss: 2.222017765045166
Validation loss: 2.085480352242788

Epoch: 6| Step: 7
Training loss: 2.0430550575256348
Validation loss: 2.086345394452413

Epoch: 6| Step: 8
Training loss: 1.7561585903167725
Validation loss: 2.088997026284536

Epoch: 6| Step: 9
Training loss: 1.6085816621780396
Validation loss: 2.0924758315086365

Epoch: 6| Step: 10
Training loss: 1.757944107055664
Validation loss: 2.072998662789663

Epoch: 6| Step: 11
Training loss: 1.4580090045928955
Validation loss: 2.0771371126174927

Epoch: 6| Step: 12
Training loss: 2.3884079456329346
Validation loss: 2.0739693641662598

Epoch: 6| Step: 13
Training loss: 2.4843735694885254
Validation loss: 2.0803550680478415

Epoch: 154| Step: 0
Training loss: 2.011812210083008
Validation loss: 2.051478366057078

Epoch: 6| Step: 1
Training loss: 1.8568172454833984
Validation loss: 2.0646246671676636

Epoch: 6| Step: 2
Training loss: 1.9044854640960693
Validation loss: 2.0637216567993164

Epoch: 6| Step: 3
Training loss: 2.367424249649048
Validation loss: 2.0548894008000693

Epoch: 6| Step: 4
Training loss: 1.9335968494415283
Validation loss: 2.0534971555074057

Epoch: 6| Step: 5
Training loss: 1.9800070524215698
Validation loss: 2.070873419443766

Epoch: 6| Step: 6
Training loss: 1.8782280683517456
Validation loss: 2.0768847664197287

Epoch: 6| Step: 7
Training loss: 1.8490593433380127
Validation loss: 2.0775660276412964

Epoch: 6| Step: 8
Training loss: 1.9302884340286255
Validation loss: 2.0843146244684854

Epoch: 6| Step: 9
Training loss: 1.659290075302124
Validation loss: 2.0981993873914084

Epoch: 6| Step: 10
Training loss: 2.3256211280822754
Validation loss: 2.104771614074707

Epoch: 6| Step: 11
Training loss: 2.2956528663635254
Validation loss: 2.1139714320500693

Epoch: 6| Step: 12
Training loss: 2.1750264167785645
Validation loss: 2.1130093137423196

Epoch: 6| Step: 13
Training loss: 2.3278932571411133
Validation loss: 2.1290544072786965

Epoch: 155| Step: 0
Training loss: 2.156024932861328
Validation loss: 2.118697007497152

Epoch: 6| Step: 1
Training loss: 2.037795066833496
Validation loss: 2.1201062202453613

Epoch: 6| Step: 2
Training loss: 1.959038496017456
Validation loss: 2.1004591981569924

Epoch: 6| Step: 3
Training loss: 2.291599750518799
Validation loss: 2.0878439942995706

Epoch: 6| Step: 4
Training loss: 2.644968032836914
Validation loss: 2.0840887228647866

Epoch: 6| Step: 5
Training loss: 1.9936243295669556
Validation loss: 2.077505668004354

Epoch: 6| Step: 6
Training loss: 2.284069538116455
Validation loss: 2.067549546559652

Epoch: 6| Step: 7
Training loss: 1.7719072103500366
Validation loss: 2.070979058742523

Epoch: 6| Step: 8
Training loss: 1.8891136646270752
Validation loss: 2.0810038844744363

Epoch: 6| Step: 9
Training loss: 1.598217487335205
Validation loss: 2.089579979578654

Epoch: 6| Step: 10
Training loss: 1.994079351425171
Validation loss: 2.080053428808848

Epoch: 6| Step: 11
Training loss: 1.4044811725616455
Validation loss: 2.0972041289011636

Epoch: 6| Step: 12
Training loss: 2.3339076042175293
Validation loss: 2.0991577903429666

Epoch: 6| Step: 13
Training loss: 2.1549386978149414
Validation loss: 2.0882943868637085

Epoch: 156| Step: 0
Training loss: 1.6705458164215088
Validation loss: 2.0773454904556274

Epoch: 6| Step: 1
Training loss: 1.562066912651062
Validation loss: 2.078628738721212

Epoch: 6| Step: 2
Training loss: 2.6183347702026367
Validation loss: 2.0834325154622397

Epoch: 6| Step: 3
Training loss: 2.1196882724761963
Validation loss: 2.0793737967809043

Epoch: 6| Step: 4
Training loss: 1.728013038635254
Validation loss: 2.0642126202583313

Epoch: 6| Step: 5
Training loss: 1.885678768157959
Validation loss: 2.0559573968251548

Epoch: 6| Step: 6
Training loss: 2.349933624267578
Validation loss: 2.0631166299184165

Epoch: 6| Step: 7
Training loss: 1.9838666915893555
Validation loss: 2.0650357206662497

Epoch: 6| Step: 8
Training loss: 2.1558496952056885
Validation loss: 2.079693873723348

Epoch: 6| Step: 9
Training loss: 1.744239330291748
Validation loss: 2.0824188590049744

Epoch: 6| Step: 10
Training loss: 2.1654295921325684
Validation loss: 2.072306434313456

Epoch: 6| Step: 11
Training loss: 1.6749801635742188
Validation loss: 2.0701303283373513

Epoch: 6| Step: 12
Training loss: 2.5879669189453125
Validation loss: 2.059039831161499

Epoch: 6| Step: 13
Training loss: 2.007840394973755
Validation loss: 2.0638486742973328

Epoch: 157| Step: 0
Training loss: 1.8254945278167725
Validation loss: 2.067731022834778

Epoch: 6| Step: 1
Training loss: 2.1093335151672363
Validation loss: 2.0644809206326804

Epoch: 6| Step: 2
Training loss: 2.2393598556518555
Validation loss: 2.077361047267914

Epoch: 6| Step: 3
Training loss: 1.6532840728759766
Validation loss: 2.0677292943000793

Epoch: 6| Step: 4
Training loss: 1.6989980936050415
Validation loss: 2.0847877065340676

Epoch: 6| Step: 5
Training loss: 1.853388786315918
Validation loss: 2.0833872159322104

Epoch: 6| Step: 6
Training loss: 1.80070161819458
Validation loss: 2.078019400437673

Epoch: 6| Step: 7
Training loss: 2.1626176834106445
Validation loss: 2.0759078661600747

Epoch: 6| Step: 8
Training loss: 2.4998044967651367
Validation loss: 2.0851715207099915

Epoch: 6| Step: 9
Training loss: 1.5762012004852295
Validation loss: 2.0751099586486816

Epoch: 6| Step: 10
Training loss: 1.9496567249298096
Validation loss: 2.075458586215973

Epoch: 6| Step: 11
Training loss: 2.374343156814575
Validation loss: 2.080993672211965

Epoch: 6| Step: 12
Training loss: 2.2989141941070557
Validation loss: 2.0731032689412436

Epoch: 6| Step: 13
Training loss: 2.1440179347991943
Validation loss: 2.080543875694275

Epoch: 158| Step: 0
Training loss: 2.099306106567383
Validation loss: 2.0664730270703635

Epoch: 6| Step: 1
Training loss: 1.7840352058410645
Validation loss: 2.062595784664154

Epoch: 6| Step: 2
Training loss: 2.1604106426239014
Validation loss: 2.0751564701398215

Epoch: 6| Step: 3
Training loss: 1.79408860206604
Validation loss: 2.0926122864087424

Epoch: 6| Step: 4
Training loss: 2.0533206462860107
Validation loss: 2.0910999377568564

Epoch: 6| Step: 5
Training loss: 2.5281834602355957
Validation loss: 2.0925419529279075

Epoch: 6| Step: 6
Training loss: 2.4531335830688477
Validation loss: 2.0791498025258384

Epoch: 6| Step: 7
Training loss: 1.670912504196167
Validation loss: 2.0834290186564126

Epoch: 6| Step: 8
Training loss: 1.9495668411254883
Validation loss: 2.096975862979889

Epoch: 6| Step: 9
Training loss: 1.5453715324401855
Validation loss: 2.083072245121002

Epoch: 6| Step: 10
Training loss: 1.7845516204833984
Validation loss: 2.0822678804397583

Epoch: 6| Step: 11
Training loss: 2.037095785140991
Validation loss: 2.094226916631063

Epoch: 6| Step: 12
Training loss: 2.2896227836608887
Validation loss: 2.0664149125417075

Epoch: 6| Step: 13
Training loss: 2.0083982944488525
Validation loss: 2.0745911796887717

Epoch: 159| Step: 0
Training loss: 2.208531379699707
Validation loss: 2.05891219774882

Epoch: 6| Step: 1
Training loss: 1.961350679397583
Validation loss: 2.078570604324341

Epoch: 6| Step: 2
Training loss: 1.612388253211975
Validation loss: 2.0745765964190164

Epoch: 6| Step: 3
Training loss: 2.383817195892334
Validation loss: 2.074034333229065

Epoch: 6| Step: 4
Training loss: 2.783895254135132
Validation loss: 2.07330854733785

Epoch: 6| Step: 5
Training loss: 2.133707046508789
Validation loss: 2.068131705125173

Epoch: 6| Step: 6
Training loss: 2.4957504272460938
Validation loss: 2.0717506806055703

Epoch: 6| Step: 7
Training loss: 1.152494192123413
Validation loss: 2.064378837744395

Epoch: 6| Step: 8
Training loss: 2.0851645469665527
Validation loss: 2.072881360848745

Epoch: 6| Step: 9
Training loss: 1.8491930961608887
Validation loss: 2.074051042397817

Epoch: 6| Step: 10
Training loss: 2.404890537261963
Validation loss: 2.08635413646698

Epoch: 6| Step: 11
Training loss: 1.4315522909164429
Validation loss: 2.0927427609761557

Epoch: 6| Step: 12
Training loss: 1.929060459136963
Validation loss: 2.1022711594899497

Epoch: 6| Step: 13
Training loss: 2.1120810508728027
Validation loss: 2.117273430029551

Epoch: 160| Step: 0
Training loss: 1.9734230041503906
Validation loss: 2.1038798888524375

Epoch: 6| Step: 1
Training loss: 1.9177912473678589
Validation loss: 2.1150732239087424

Epoch: 6| Step: 2
Training loss: 2.3980913162231445
Validation loss: 2.0980716347694397

Epoch: 6| Step: 3
Training loss: 2.6010899543762207
Validation loss: 2.0960012674331665

Epoch: 6| Step: 4
Training loss: 1.4144032001495361
Validation loss: 2.0955062905947366

Epoch: 6| Step: 5
Training loss: 1.4786401987075806
Validation loss: 2.09348330895106

Epoch: 6| Step: 6
Training loss: 2.4560136795043945
Validation loss: 2.065214157104492

Epoch: 6| Step: 7
Training loss: 2.3199453353881836
Validation loss: 2.0716928044954934

Epoch: 6| Step: 8
Training loss: 1.6533870697021484
Validation loss: 2.0746550957361856

Epoch: 6| Step: 9
Training loss: 1.3777554035186768
Validation loss: 2.0785962541898093

Epoch: 6| Step: 10
Training loss: 1.5617218017578125
Validation loss: 2.069130857785543

Epoch: 6| Step: 11
Training loss: 2.196622133255005
Validation loss: 2.0735824505488076

Epoch: 6| Step: 12
Training loss: 2.7605605125427246
Validation loss: 2.079578618208567

Epoch: 6| Step: 13
Training loss: 2.4314749240875244
Validation loss: 2.068344076474508

Epoch: 161| Step: 0
Training loss: 1.7303344011306763
Validation loss: 2.081103245417277

Epoch: 6| Step: 1
Training loss: 1.8658037185668945
Validation loss: 2.070410509904226

Epoch: 6| Step: 2
Training loss: 1.8727986812591553
Validation loss: 2.0755218664805093

Epoch: 6| Step: 3
Training loss: 1.8185440301895142
Validation loss: 2.076697826385498

Epoch: 6| Step: 4
Training loss: 2.4362406730651855
Validation loss: 2.087358772754669

Epoch: 6| Step: 5
Training loss: 2.142780303955078
Validation loss: 2.0982043544451394

Epoch: 6| Step: 6
Training loss: 1.8508256673812866
Validation loss: 2.0819940765698752

Epoch: 6| Step: 7
Training loss: 2.151639699935913
Validation loss: 2.1062482595443726

Epoch: 6| Step: 8
Training loss: 2.194530963897705
Validation loss: 2.0907057722409568

Epoch: 6| Step: 9
Training loss: 1.6343467235565186
Validation loss: 2.1085110704104104

Epoch: 6| Step: 10
Training loss: 2.025695323944092
Validation loss: 2.1152260303497314

Epoch: 6| Step: 11
Training loss: 2.0389037132263184
Validation loss: 2.093363026777903

Epoch: 6| Step: 12
Training loss: 2.7689733505249023
Validation loss: 2.0931371450424194

Epoch: 6| Step: 13
Training loss: 1.8632794618606567
Validation loss: 2.090735117594401

Epoch: 162| Step: 0
Training loss: 1.8067066669464111
Validation loss: 2.0689870516459146

Epoch: 6| Step: 1
Training loss: 1.9277698993682861
Validation loss: 2.081377069155375

Epoch: 6| Step: 2
Training loss: 2.1938226222991943
Validation loss: 2.073771059513092

Epoch: 6| Step: 3
Training loss: 2.2688660621643066
Validation loss: 2.0654852787653604

Epoch: 6| Step: 4
Training loss: 2.5419650077819824
Validation loss: 2.0580426255861917

Epoch: 6| Step: 5
Training loss: 2.148385524749756
Validation loss: 2.0616565942764282

Epoch: 6| Step: 6
Training loss: 1.6712627410888672
Validation loss: 2.063594341278076

Epoch: 6| Step: 7
Training loss: 2.136929750442505
Validation loss: 2.065470357735952

Epoch: 6| Step: 8
Training loss: 1.8317975997924805
Validation loss: 2.075619955857595

Epoch: 6| Step: 9
Training loss: 2.1395344734191895
Validation loss: 2.078984101613363

Epoch: 6| Step: 10
Training loss: 1.9560381174087524
Validation loss: 2.088520427544912

Epoch: 6| Step: 11
Training loss: 1.2296795845031738
Validation loss: 2.1092509428660073

Epoch: 6| Step: 12
Training loss: 2.1059885025024414
Validation loss: 2.111945311228434

Epoch: 6| Step: 13
Training loss: 2.3790175914764404
Validation loss: 2.1355934540430703

Epoch: 163| Step: 0
Training loss: 2.088616132736206
Validation loss: 2.125996192296346

Epoch: 6| Step: 1
Training loss: 2.2311604022979736
Validation loss: 2.122743328412374

Epoch: 6| Step: 2
Training loss: 1.8461334705352783
Validation loss: 2.1251983046531677

Epoch: 6| Step: 3
Training loss: 2.098973274230957
Validation loss: 2.127387444178263

Epoch: 6| Step: 4
Training loss: 2.114039897918701
Validation loss: 2.109964390595754

Epoch: 6| Step: 5
Training loss: 1.7560656070709229
Validation loss: 2.114426294962565

Epoch: 6| Step: 6
Training loss: 2.8168442249298096
Validation loss: 2.12162979443868

Epoch: 6| Step: 7
Training loss: 2.4542245864868164
Validation loss: 2.098658243815104

Epoch: 6| Step: 8
Training loss: 2.1568856239318848
Validation loss: 2.0815329551696777

Epoch: 6| Step: 9
Training loss: 1.7323449850082397
Validation loss: 2.087083101272583

Epoch: 6| Step: 10
Training loss: 1.8516802787780762
Validation loss: 2.083528717358907

Epoch: 6| Step: 11
Training loss: 1.670914649963379
Validation loss: 2.0930781761805215

Epoch: 6| Step: 12
Training loss: 1.9208974838256836
Validation loss: 2.0907533764839172

Epoch: 6| Step: 13
Training loss: 1.8547046184539795
Validation loss: 2.0919954578081765

Epoch: 164| Step: 0
Training loss: 2.0772976875305176
Validation loss: 2.092524786790212

Epoch: 6| Step: 1
Training loss: 1.5277650356292725
Validation loss: 2.117901007334391

Epoch: 6| Step: 2
Training loss: 1.8439669609069824
Validation loss: 2.108737568060557

Epoch: 6| Step: 3
Training loss: 1.9749505519866943
Validation loss: 2.0969521204630532

Epoch: 6| Step: 4
Training loss: 2.9426612854003906
Validation loss: 2.0954042871793113

Epoch: 6| Step: 5
Training loss: 1.7459174394607544
Validation loss: 2.0893203814824424

Epoch: 6| Step: 6
Training loss: 2.23404598236084
Validation loss: 2.0957029660542807

Epoch: 6| Step: 7
Training loss: 2.159541606903076
Validation loss: 2.0898645520210266

Epoch: 6| Step: 8
Training loss: 2.2129156589508057
Validation loss: 2.100558320681254

Epoch: 6| Step: 9
Training loss: 1.75144362449646
Validation loss: 2.0879262685775757

Epoch: 6| Step: 10
Training loss: 1.60011887550354
Validation loss: 2.074094514052073

Epoch: 6| Step: 11
Training loss: 1.7536379098892212
Validation loss: 2.065467894077301

Epoch: 6| Step: 12
Training loss: 2.162360191345215
Validation loss: 2.081198990345001

Epoch: 6| Step: 13
Training loss: 2.2832894325256348
Validation loss: 2.0695627331733704

Epoch: 165| Step: 0
Training loss: 1.8488976955413818
Validation loss: 2.076663156350454

Epoch: 6| Step: 1
Training loss: 2.20993971824646
Validation loss: 2.061308662096659

Epoch: 6| Step: 2
Training loss: 2.65726375579834
Validation loss: 2.0629530549049377

Epoch: 6| Step: 3
Training loss: 1.988362431526184
Validation loss: 2.0630462765693665

Epoch: 6| Step: 4
Training loss: 1.9029128551483154
Validation loss: 2.055816133817037

Epoch: 6| Step: 5
Training loss: 2.1303606033325195
Validation loss: 2.0632768273353577

Epoch: 6| Step: 6
Training loss: 2.089104175567627
Validation loss: 2.063570201396942

Epoch: 6| Step: 7
Training loss: 2.020423412322998
Validation loss: 2.057124614715576

Epoch: 6| Step: 8
Training loss: 2.0913710594177246
Validation loss: 2.0531094670295715

Epoch: 6| Step: 9
Training loss: 1.8847088813781738
Validation loss: 2.0755157470703125

Epoch: 6| Step: 10
Training loss: 2.141812324523926
Validation loss: 2.0722264448801675

Epoch: 6| Step: 11
Training loss: 2.094205856323242
Validation loss: 2.084409753481547

Epoch: 6| Step: 12
Training loss: 1.764457106590271
Validation loss: 2.0859862764676413

Epoch: 6| Step: 13
Training loss: 1.5736132860183716
Validation loss: 2.0908332665761313

Epoch: 166| Step: 0
Training loss: 1.7723978757858276
Validation loss: 2.091180761655172

Epoch: 6| Step: 1
Training loss: 2.0642988681793213
Validation loss: 2.0874061385790506

Epoch: 6| Step: 2
Training loss: 1.7867748737335205
Validation loss: 2.091630538304647

Epoch: 6| Step: 3
Training loss: 2.0159835815429688
Validation loss: 2.0839431285858154

Epoch: 6| Step: 4
Training loss: 2.662994146347046
Validation loss: 2.086136440436045

Epoch: 6| Step: 5
Training loss: 2.6690595149993896
Validation loss: 2.0791462461153665

Epoch: 6| Step: 6
Training loss: 2.4226062297821045
Validation loss: 2.0771358013153076

Epoch: 6| Step: 7
Training loss: 2.2880280017852783
Validation loss: 2.076099455356598

Epoch: 6| Step: 8
Training loss: 1.5318737030029297
Validation loss: 2.069652040799459

Epoch: 6| Step: 9
Training loss: 1.3987617492675781
Validation loss: 2.0691508452097573

Epoch: 6| Step: 10
Training loss: 2.4233415126800537
Validation loss: 2.0674395759900412

Epoch: 6| Step: 11
Training loss: 1.944782018661499
Validation loss: 2.056218465169271

Epoch: 6| Step: 12
Training loss: 1.7806955575942993
Validation loss: 2.0713860392570496

Epoch: 6| Step: 13
Training loss: 1.5455336570739746
Validation loss: 2.060078978538513

Epoch: 167| Step: 0
Training loss: 2.205357074737549
Validation loss: 2.0585529804229736

Epoch: 6| Step: 1
Training loss: 2.5834274291992188
Validation loss: 2.0651702086130777

Epoch: 6| Step: 2
Training loss: 1.4720619916915894
Validation loss: 2.062756896018982

Epoch: 6| Step: 3
Training loss: 1.4099293947219849
Validation loss: 2.0689907471338906

Epoch: 6| Step: 4
Training loss: 2.2682130336761475
Validation loss: 2.0768947998682656

Epoch: 6| Step: 5
Training loss: 2.20340895652771
Validation loss: 2.0751304427782693

Epoch: 6| Step: 6
Training loss: 2.0093111991882324
Validation loss: 2.0900484124819436

Epoch: 6| Step: 7
Training loss: 2.1108927726745605
Validation loss: 2.089054842789968

Epoch: 6| Step: 8
Training loss: 1.7558386325836182
Validation loss: 2.1028480927149453

Epoch: 6| Step: 9
Training loss: 2.076737403869629
Validation loss: 2.095501701037089

Epoch: 6| Step: 10
Training loss: 2.1595325469970703
Validation loss: 2.0857208967208862

Epoch: 6| Step: 11
Training loss: 1.5603206157684326
Validation loss: 2.0908218820889792

Epoch: 6| Step: 12
Training loss: 2.1995396614074707
Validation loss: 2.0994388858477273

Epoch: 6| Step: 13
Training loss: 1.9149857759475708
Validation loss: 2.1031407515207925

Epoch: 168| Step: 0
Training loss: 1.6145963668823242
Validation loss: 2.08390078941981

Epoch: 6| Step: 1
Training loss: 1.8975863456726074
Validation loss: 2.087603489557902

Epoch: 6| Step: 2
Training loss: 2.2657570838928223
Validation loss: 2.0968440771102905

Epoch: 6| Step: 3
Training loss: 2.7957422733306885
Validation loss: 2.1015366911888123

Epoch: 6| Step: 4
Training loss: 1.8179080486297607
Validation loss: 2.1097621520360312

Epoch: 6| Step: 5
Training loss: 1.7319684028625488
Validation loss: 2.104611317316691

Epoch: 6| Step: 6
Training loss: 2.710064172744751
Validation loss: 2.111967464288076

Epoch: 6| Step: 7
Training loss: 1.9657191038131714
Validation loss: 2.115827202796936

Epoch: 6| Step: 8
Training loss: 1.9468965530395508
Validation loss: 2.1214170257250466

Epoch: 6| Step: 9
Training loss: 1.548386812210083
Validation loss: 2.1195457577705383

Epoch: 6| Step: 10
Training loss: 1.8443734645843506
Validation loss: 2.1295262575149536

Epoch: 6| Step: 11
Training loss: 2.3902392387390137
Validation loss: 2.133705178896586

Epoch: 6| Step: 12
Training loss: 1.367079257965088
Validation loss: 2.120270788669586

Epoch: 6| Step: 13
Training loss: 1.9011582136154175
Validation loss: 2.1286256313323975

Epoch: 169| Step: 0
Training loss: 2.298617362976074
Validation loss: 2.1298770904541016

Epoch: 6| Step: 1
Training loss: 2.2586865425109863
Validation loss: 2.1292364597320557

Epoch: 6| Step: 2
Training loss: 2.5795235633850098
Validation loss: 2.1404494841893515

Epoch: 6| Step: 3
Training loss: 1.5739526748657227
Validation loss: 2.1215968132019043

Epoch: 6| Step: 4
Training loss: 1.8336703777313232
Validation loss: 2.097840746243795

Epoch: 6| Step: 5
Training loss: 1.8647379875183105
Validation loss: 2.099916179974874

Epoch: 6| Step: 6
Training loss: 2.493520736694336
Validation loss: 2.100338419278463

Epoch: 6| Step: 7
Training loss: 1.9774829149246216
Validation loss: 2.085016667842865

Epoch: 6| Step: 8
Training loss: 1.9234540462493896
Validation loss: 2.0870473782221475

Epoch: 6| Step: 9
Training loss: 1.969930648803711
Validation loss: 2.0678550402323403

Epoch: 6| Step: 10
Training loss: 2.4524483680725098
Validation loss: 2.0697959860165915

Epoch: 6| Step: 11
Training loss: 1.5428509712219238
Validation loss: 2.0742280085881553

Epoch: 6| Step: 12
Training loss: 1.914566993713379
Validation loss: 2.074167331059774

Epoch: 6| Step: 13
Training loss: 1.9368999004364014
Validation loss: 2.081282138824463

Epoch: 170| Step: 0
Training loss: 2.4285197257995605
Validation loss: 2.090462108453115

Epoch: 6| Step: 1
Training loss: 1.9686945676803589
Validation loss: 2.1060909032821655

Epoch: 6| Step: 2
Training loss: 2.028343915939331
Validation loss: 2.1181665658950806

Epoch: 6| Step: 3
Training loss: 1.9564708471298218
Validation loss: 2.1280994415283203

Epoch: 6| Step: 4
Training loss: 2.7837953567504883
Validation loss: 2.1467829942703247

Epoch: 6| Step: 5
Training loss: 1.855863332748413
Validation loss: 2.151207745075226

Epoch: 6| Step: 6
Training loss: 1.5005691051483154
Validation loss: 2.1428609093030295

Epoch: 6| Step: 7
Training loss: 1.822066307067871
Validation loss: 2.1316107710202536

Epoch: 6| Step: 8
Training loss: 1.9701941013336182
Validation loss: 2.1304120620091758

Epoch: 6| Step: 9
Training loss: 2.330343723297119
Validation loss: 2.1241336464881897

Epoch: 6| Step: 10
Training loss: 2.2406439781188965
Validation loss: 2.107661247253418

Epoch: 6| Step: 11
Training loss: 1.8617901802062988
Validation loss: 2.100219249725342

Epoch: 6| Step: 12
Training loss: 1.694487452507019
Validation loss: 2.085192700227102

Epoch: 6| Step: 13
Training loss: 2.0869266986846924
Validation loss: 2.074130197366079

Epoch: 171| Step: 0
Training loss: 1.8885523080825806
Validation loss: 2.069676617781321

Epoch: 6| Step: 1
Training loss: 1.8470113277435303
Validation loss: 2.060063660144806

Epoch: 6| Step: 2
Training loss: 2.959139108657837
Validation loss: 2.056727866331736

Epoch: 6| Step: 3
Training loss: 1.7512706518173218
Validation loss: 2.0650532046953836

Epoch: 6| Step: 4
Training loss: 2.2402760982513428
Validation loss: 2.0612520376841226

Epoch: 6| Step: 5
Training loss: 2.2731714248657227
Validation loss: 2.0582215984662375

Epoch: 6| Step: 6
Training loss: 1.9807499647140503
Validation loss: 2.0594023863474527

Epoch: 6| Step: 7
Training loss: 1.701502799987793
Validation loss: 2.073819100856781

Epoch: 6| Step: 8
Training loss: 2.0550951957702637
Validation loss: 2.0608842372894287

Epoch: 6| Step: 9
Training loss: 1.7410821914672852
Validation loss: 2.087669392426809

Epoch: 6| Step: 10
Training loss: 1.434779405593872
Validation loss: 2.1242497762044272

Epoch: 6| Step: 11
Training loss: 2.7805967330932617
Validation loss: 2.0940317710240683

Epoch: 6| Step: 12
Training loss: 1.2715579271316528
Validation loss: 2.095024903615316

Epoch: 6| Step: 13
Training loss: 2.82236647605896
Validation loss: 2.1135533849398294

Epoch: 172| Step: 0
Training loss: 2.227018356323242
Validation loss: 2.108705679575602

Epoch: 6| Step: 1
Training loss: 1.5378755331039429
Validation loss: 2.0972185532251992

Epoch: 6| Step: 2
Training loss: 2.0306589603424072
Validation loss: 2.1018718481063843

Epoch: 6| Step: 3
Training loss: 2.504101037979126
Validation loss: 2.095822354157766

Epoch: 6| Step: 4
Training loss: 2.2910215854644775
Validation loss: 2.0912047624588013

Epoch: 6| Step: 5
Training loss: 2.118786573410034
Validation loss: 2.0773507754007974

Epoch: 6| Step: 6
Training loss: 1.7800158262252808
Validation loss: 2.0721911986668906

Epoch: 6| Step: 7
Training loss: 1.7324782609939575
Validation loss: 2.05922665198644

Epoch: 6| Step: 8
Training loss: 2.2836999893188477
Validation loss: 2.073239346345266

Epoch: 6| Step: 9
Training loss: 2.2767295837402344
Validation loss: 2.076290269692739

Epoch: 6| Step: 10
Training loss: 1.778090476989746
Validation loss: 2.0651297171910605

Epoch: 6| Step: 11
Training loss: 2.01570987701416
Validation loss: 2.076434016227722

Epoch: 6| Step: 12
Training loss: 1.6493988037109375
Validation loss: 2.070426066716512

Epoch: 6| Step: 13
Training loss: 1.7623920440673828
Validation loss: 2.062980671723684

Epoch: 173| Step: 0
Training loss: 2.12166428565979
Validation loss: 2.0750564336776733

Epoch: 6| Step: 1
Training loss: 1.7253113985061646
Validation loss: 2.0629000465075173

Epoch: 6| Step: 2
Training loss: 1.376997470855713
Validation loss: 2.063826779524485

Epoch: 6| Step: 3
Training loss: 2.1083507537841797
Validation loss: 2.0729658802350364

Epoch: 6| Step: 4
Training loss: 1.7347865104675293
Validation loss: 2.072087347507477

Epoch: 6| Step: 5
Training loss: 1.9304816722869873
Validation loss: 2.0884916385014853

Epoch: 6| Step: 6
Training loss: 1.7570934295654297
Validation loss: 2.092627386252085

Epoch: 6| Step: 7
Training loss: 2.022883415222168
Validation loss: 2.1029587388038635

Epoch: 6| Step: 8
Training loss: 2.3931291103363037
Validation loss: 2.1083399057388306

Epoch: 6| Step: 9
Training loss: 2.627744197845459
Validation loss: 2.094439665476481

Epoch: 6| Step: 10
Training loss: 1.9831924438476562
Validation loss: 2.1167337894439697

Epoch: 6| Step: 11
Training loss: 2.2443246841430664
Validation loss: 2.093952258427938

Epoch: 6| Step: 12
Training loss: 2.3953843116760254
Validation loss: 2.0912930170694985

Epoch: 6| Step: 13
Training loss: 1.8783340454101562
Validation loss: 2.0917060375213623

Epoch: 174| Step: 0
Training loss: 1.3868885040283203
Validation loss: 2.074086050192515

Epoch: 6| Step: 1
Training loss: 1.5608640909194946
Validation loss: 2.0820682644844055

Epoch: 6| Step: 2
Training loss: 1.948258638381958
Validation loss: 2.077971935272217

Epoch: 6| Step: 3
Training loss: 2.2003836631774902
Validation loss: 2.0823908050855002

Epoch: 6| Step: 4
Training loss: 2.6469063758850098
Validation loss: 2.091270327568054

Epoch: 6| Step: 5
Training loss: 1.950360894203186
Validation loss: 2.0700776974360147

Epoch: 6| Step: 6
Training loss: 1.8372961282730103
Validation loss: 2.0811540285746255

Epoch: 6| Step: 7
Training loss: 2.209815502166748
Validation loss: 2.0821805397669473

Epoch: 6| Step: 8
Training loss: 1.8371272087097168
Validation loss: 2.0841464400291443

Epoch: 6| Step: 9
Training loss: 2.257612943649292
Validation loss: 2.0835994879404702

Epoch: 6| Step: 10
Training loss: 1.7987937927246094
Validation loss: 2.0800761580467224

Epoch: 6| Step: 11
Training loss: 1.8069112300872803
Validation loss: 2.0861829916636148

Epoch: 6| Step: 12
Training loss: 2.0435702800750732
Validation loss: 2.083588401476542

Epoch: 6| Step: 13
Training loss: 2.294969081878662
Validation loss: 2.089646577835083

Epoch: 175| Step: 0
Training loss: 2.0682644844055176
Validation loss: 2.0933783451716104

Epoch: 6| Step: 1
Training loss: 1.3902337551116943
Validation loss: 2.091358562310537

Epoch: 6| Step: 2
Training loss: 2.034780502319336
Validation loss: 2.0927425026893616

Epoch: 6| Step: 3
Training loss: 2.167451858520508
Validation loss: 2.092120865980784

Epoch: 6| Step: 4
Training loss: 1.9734621047973633
Validation loss: 2.086024065812429

Epoch: 6| Step: 5
Training loss: 1.2355122566223145
Validation loss: 2.087828516960144

Epoch: 6| Step: 6
Training loss: 2.80204439163208
Validation loss: 2.0948206981023154

Epoch: 6| Step: 7
Training loss: 2.6047093868255615
Validation loss: 2.078408698240916

Epoch: 6| Step: 8
Training loss: 2.191152572631836
Validation loss: 2.0927387475967407

Epoch: 6| Step: 9
Training loss: 2.1874780654907227
Validation loss: 2.1018360455830893

Epoch: 6| Step: 10
Training loss: 2.26375412940979
Validation loss: 2.095884164174398

Epoch: 6| Step: 11
Training loss: 0.9278049468994141
Validation loss: 2.1046882271766663

Epoch: 6| Step: 12
Training loss: 1.550146460533142
Validation loss: 2.1158879001935325

Epoch: 6| Step: 13
Training loss: 2.5919651985168457
Validation loss: 2.108267625172933

Epoch: 176| Step: 0
Training loss: 2.342740058898926
Validation loss: 2.1404115358988443

Epoch: 6| Step: 1
Training loss: 2.430286169052124
Validation loss: 2.123764455318451

Epoch: 6| Step: 2
Training loss: 1.578789234161377
Validation loss: 2.12402872244517

Epoch: 6| Step: 3
Training loss: 1.4800372123718262
Validation loss: 2.1057961781819663

Epoch: 6| Step: 4
Training loss: 2.188149929046631
Validation loss: 2.1074108680089316

Epoch: 6| Step: 5
Training loss: 2.0271811485290527
Validation loss: 2.1095975836118064

Epoch: 6| Step: 6
Training loss: 1.3214884996414185
Validation loss: 2.107824464639028

Epoch: 6| Step: 7
Training loss: 1.5483407974243164
Validation loss: 2.0971311132113137

Epoch: 6| Step: 8
Training loss: 1.5329068899154663
Validation loss: 2.085288961728414

Epoch: 6| Step: 9
Training loss: 2.050065040588379
Validation loss: 2.0874083638191223

Epoch: 6| Step: 10
Training loss: 2.227193832397461
Validation loss: 2.086994787057241

Epoch: 6| Step: 11
Training loss: 2.728011131286621
Validation loss: 2.0824174284934998

Epoch: 6| Step: 12
Training loss: 2.316006660461426
Validation loss: 2.0863845149676004

Epoch: 6| Step: 13
Training loss: 2.5691943168640137
Validation loss: 2.088579793771108

Epoch: 177| Step: 0
Training loss: 1.7157866954803467
Validation loss: 2.08100692431132

Epoch: 6| Step: 1
Training loss: 1.1742255687713623
Validation loss: 2.087039033571879

Epoch: 6| Step: 2
Training loss: 1.657609462738037
Validation loss: 2.0881457527478537

Epoch: 6| Step: 3
Training loss: 1.9383187294006348
Validation loss: 2.104359289010366

Epoch: 6| Step: 4
Training loss: 2.3524093627929688
Validation loss: 2.1057904958724976

Epoch: 6| Step: 5
Training loss: 1.7778217792510986
Validation loss: 2.110585351785024

Epoch: 6| Step: 6
Training loss: 2.1563472747802734
Validation loss: 2.100691278775533

Epoch: 6| Step: 7
Training loss: 1.6284971237182617
Validation loss: 2.1084429820378623

Epoch: 6| Step: 8
Training loss: 2.025467872619629
Validation loss: 2.1357460419336953

Epoch: 6| Step: 9
Training loss: 2.179408550262451
Validation loss: 2.1297192176183066

Epoch: 6| Step: 10
Training loss: 1.6187381744384766
Validation loss: 2.124392867088318

Epoch: 6| Step: 11
Training loss: 3.012809991836548
Validation loss: 2.1161410212516785

Epoch: 6| Step: 12
Training loss: 2.7915873527526855
Validation loss: 2.105073650677999

Epoch: 6| Step: 13
Training loss: 2.042638063430786
Validation loss: 2.106754938761393

Epoch: 178| Step: 0
Training loss: 2.0120949745178223
Validation loss: 2.1033851703008017

Epoch: 6| Step: 1
Training loss: 1.456080675125122
Validation loss: 2.103290398915609

Epoch: 6| Step: 2
Training loss: 2.239415168762207
Validation loss: 2.0878588954607644

Epoch: 6| Step: 3
Training loss: 2.405243396759033
Validation loss: 2.085541824499766

Epoch: 6| Step: 4
Training loss: 2.02244234085083
Validation loss: 2.086256484190623

Epoch: 6| Step: 5
Training loss: 2.020441770553589
Validation loss: 2.0865856806437173

Epoch: 6| Step: 6
Training loss: 1.9928321838378906
Validation loss: 2.0918317437171936

Epoch: 6| Step: 7
Training loss: 1.932206630706787
Validation loss: 2.088898181915283

Epoch: 6| Step: 8
Training loss: 1.4105355739593506
Validation loss: 2.079671065012614

Epoch: 6| Step: 9
Training loss: 1.9961704015731812
Validation loss: 2.1011110742886863

Epoch: 6| Step: 10
Training loss: 2.4923887252807617
Validation loss: 2.096538325150808

Epoch: 6| Step: 11
Training loss: 1.7798771858215332
Validation loss: 2.0977537035942078

Epoch: 6| Step: 12
Training loss: 2.118622303009033
Validation loss: 2.1191497246424356

Epoch: 6| Step: 13
Training loss: 2.248213291168213
Validation loss: 2.1169647574424744

Epoch: 179| Step: 0
Training loss: 1.6910135746002197
Validation loss: 2.1168091098467507

Epoch: 6| Step: 1
Training loss: 1.7272225618362427
Validation loss: 2.1282284458478293

Epoch: 6| Step: 2
Training loss: 1.0279021263122559
Validation loss: 2.140713155269623

Epoch: 6| Step: 3
Training loss: 1.8606590032577515
Validation loss: 2.1367181142171225

Epoch: 6| Step: 4
Training loss: 2.3850889205932617
Validation loss: 2.1474239428838096

Epoch: 6| Step: 5
Training loss: 2.660491943359375
Validation loss: 2.145793894926707

Epoch: 6| Step: 6
Training loss: 2.510161876678467
Validation loss: 2.1592078606287637

Epoch: 6| Step: 7
Training loss: 2.221367835998535
Validation loss: 2.1423864165941873

Epoch: 6| Step: 8
Training loss: 2.2453861236572266
Validation loss: 2.1379313270250955

Epoch: 6| Step: 9
Training loss: 1.4651681184768677
Validation loss: 2.1516557931900024

Epoch: 6| Step: 10
Training loss: 2.147897958755493
Validation loss: 2.116729180018107

Epoch: 6| Step: 11
Training loss: 2.1776018142700195
Validation loss: 2.1088391145070395

Epoch: 6| Step: 12
Training loss: 1.4503451585769653
Validation loss: 2.1252792278925576

Epoch: 6| Step: 13
Training loss: 2.1930489540100098
Validation loss: 2.1294660170873008

Epoch: 180| Step: 0
Training loss: 1.8119982481002808
Validation loss: 2.102498253186544

Epoch: 6| Step: 1
Training loss: 2.420755386352539
Validation loss: 2.1143799225489297

Epoch: 6| Step: 2
Training loss: 2.163926362991333
Validation loss: 2.1117886702219644

Epoch: 6| Step: 3
Training loss: 2.1877832412719727
Validation loss: 2.1127186020215354

Epoch: 6| Step: 4
Training loss: 1.983117938041687
Validation loss: 2.131085991859436

Epoch: 6| Step: 5
Training loss: 1.8690640926361084
Validation loss: 2.123600939909617

Epoch: 6| Step: 6
Training loss: 2.079094886779785
Validation loss: 2.1316980918248496

Epoch: 6| Step: 7
Training loss: 2.195585250854492
Validation loss: 2.1282137433687844

Epoch: 6| Step: 8
Training loss: 1.7813220024108887
Validation loss: 2.143588741620382

Epoch: 6| Step: 9
Training loss: 1.9599337577819824
Validation loss: 2.153183619181315

Epoch: 6| Step: 10
Training loss: 1.6754775047302246
Validation loss: 2.12988011042277

Epoch: 6| Step: 11
Training loss: 1.8104041814804077
Validation loss: 2.1202699144681296

Epoch: 6| Step: 12
Training loss: 1.9554262161254883
Validation loss: 2.121919314066569

Epoch: 6| Step: 13
Training loss: 1.604522705078125
Validation loss: 2.132084588209788

Epoch: 181| Step: 0
Training loss: 1.8289841413497925
Validation loss: 2.1344842116038003

Epoch: 6| Step: 1
Training loss: 2.461418867111206
Validation loss: 2.134641428788503

Epoch: 6| Step: 2
Training loss: 2.364621639251709
Validation loss: 2.1344929933547974

Epoch: 6| Step: 3
Training loss: 2.0105092525482178
Validation loss: 2.1169486244519553

Epoch: 6| Step: 4
Training loss: 2.2081127166748047
Validation loss: 2.1175060470898948

Epoch: 6| Step: 5
Training loss: 2.2245211601257324
Validation loss: 2.1228631138801575

Epoch: 6| Step: 6
Training loss: 1.2179491519927979
Validation loss: 2.1223538319269815

Epoch: 6| Step: 7
Training loss: 1.5520660877227783
Validation loss: 2.1208654642105103

Epoch: 6| Step: 8
Training loss: 1.6788933277130127
Validation loss: 2.126305043697357

Epoch: 6| Step: 9
Training loss: 1.9448223114013672
Validation loss: 2.146398425102234

Epoch: 6| Step: 10
Training loss: 1.8344489336013794
Validation loss: 2.138963301976522

Epoch: 6| Step: 11
Training loss: 1.5732264518737793
Validation loss: 2.1280827124913535

Epoch: 6| Step: 12
Training loss: 2.701443910598755
Validation loss: 2.1207926670710244

Epoch: 6| Step: 13
Training loss: 1.758400797843933
Validation loss: 2.107673625151316

Epoch: 182| Step: 0
Training loss: 2.410503387451172
Validation loss: 2.1061854362487793

Epoch: 6| Step: 1
Training loss: 1.5706532001495361
Validation loss: 2.1030529538790383

Epoch: 6| Step: 2
Training loss: 1.8654098510742188
Validation loss: 2.105760951836904

Epoch: 6| Step: 3
Training loss: 1.840989351272583
Validation loss: 2.1065531969070435

Epoch: 6| Step: 4
Training loss: 2.74176025390625
Validation loss: 2.1185303727785745

Epoch: 6| Step: 5
Training loss: 2.0334086418151855
Validation loss: 2.1340370575586953

Epoch: 6| Step: 6
Training loss: 1.5638775825500488
Validation loss: 2.1201091011365256

Epoch: 6| Step: 7
Training loss: 1.8085033893585205
Validation loss: 2.1369325319925943

Epoch: 6| Step: 8
Training loss: 1.6842156648635864
Validation loss: 2.135841647783915

Epoch: 6| Step: 9
Training loss: 2.0514159202575684
Validation loss: 2.1339335242907205

Epoch: 6| Step: 10
Training loss: 2.0333750247955322
Validation loss: 2.1451425552368164

Epoch: 6| Step: 11
Training loss: 1.760537028312683
Validation loss: 2.12148517370224

Epoch: 6| Step: 12
Training loss: 1.6799242496490479
Validation loss: 2.11727374792099

Epoch: 6| Step: 13
Training loss: 2.5507402420043945
Validation loss: 2.132171889146169

Epoch: 183| Step: 0
Training loss: 1.846153736114502
Validation loss: 2.122799336910248

Epoch: 6| Step: 1
Training loss: 1.9790798425674438
Validation loss: 2.142482121785482

Epoch: 6| Step: 2
Training loss: 1.6808401346206665
Validation loss: 2.1149789889653525

Epoch: 6| Step: 3
Training loss: 2.267899513244629
Validation loss: 2.099637269973755

Epoch: 6| Step: 4
Training loss: 1.5626254081726074
Validation loss: 2.109614372253418

Epoch: 6| Step: 5
Training loss: 1.9739984273910522
Validation loss: 2.1078635652860007

Epoch: 6| Step: 6
Training loss: 2.147213935852051
Validation loss: 2.0864612460136414

Epoch: 6| Step: 7
Training loss: 2.5431301593780518
Validation loss: 2.0968783696492515

Epoch: 6| Step: 8
Training loss: 2.1703412532806396
Validation loss: 2.1029149691263833

Epoch: 6| Step: 9
Training loss: 1.8030375242233276
Validation loss: 2.0983275373776755

Epoch: 6| Step: 10
Training loss: 2.6248247623443604
Validation loss: 2.086893916130066

Epoch: 6| Step: 11
Training loss: 1.7782268524169922
Validation loss: 2.1057794292767844

Epoch: 6| Step: 12
Training loss: 1.7654420137405396
Validation loss: 2.1046348412831626

Epoch: 6| Step: 13
Training loss: 1.8951539993286133
Validation loss: 2.096232990423838

Epoch: 184| Step: 0
Training loss: 1.8291302919387817
Validation loss: 2.109094778696696

Epoch: 6| Step: 1
Training loss: 2.037384033203125
Validation loss: 2.1118018428484597

Epoch: 6| Step: 2
Training loss: 2.6711666584014893
Validation loss: 2.122138818105062

Epoch: 6| Step: 3
Training loss: 2.307727813720703
Validation loss: 2.13640703757604

Epoch: 6| Step: 4
Training loss: 1.6898033618927002
Validation loss: 2.1216233372688293

Epoch: 6| Step: 5
Training loss: 2.1113381385803223
Validation loss: 2.1341645320256553

Epoch: 6| Step: 6
Training loss: 1.7995048761367798
Validation loss: 2.135808825492859

Epoch: 6| Step: 7
Training loss: 2.163614273071289
Validation loss: 2.117793341477712

Epoch: 6| Step: 8
Training loss: 1.6516191959381104
Validation loss: 2.120793263117472

Epoch: 6| Step: 9
Training loss: 1.8428447246551514
Validation loss: 2.118183155854543

Epoch: 6| Step: 10
Training loss: 2.4572248458862305
Validation loss: 2.121944785118103

Epoch: 6| Step: 11
Training loss: 1.9618239402770996
Validation loss: 2.106458862622579

Epoch: 6| Step: 12
Training loss: 1.6700167655944824
Validation loss: 2.1055375734965005

Epoch: 6| Step: 13
Training loss: 1.4454751014709473
Validation loss: 2.106399734814962

Epoch: 185| Step: 0
Training loss: 2.2750461101531982
Validation loss: 2.1091248194376626

Epoch: 6| Step: 1
Training loss: 2.0190556049346924
Validation loss: 2.102422217528025

Epoch: 6| Step: 2
Training loss: 1.3057701587677002
Validation loss: 2.0932483673095703

Epoch: 6| Step: 3
Training loss: 1.4501934051513672
Validation loss: 2.104536771774292

Epoch: 6| Step: 4
Training loss: 1.4031809568405151
Validation loss: 2.1051881313323975

Epoch: 6| Step: 5
Training loss: 1.834538221359253
Validation loss: 2.112508217493693

Epoch: 6| Step: 6
Training loss: 2.147716999053955
Validation loss: 2.132772664229075

Epoch: 6| Step: 7
Training loss: 1.6401869058609009
Validation loss: 2.1253862579663596

Epoch: 6| Step: 8
Training loss: 1.6378988027572632
Validation loss: 2.129887064297994

Epoch: 6| Step: 9
Training loss: 2.9968924522399902
Validation loss: 2.119254469871521

Epoch: 6| Step: 10
Training loss: 2.0429553985595703
Validation loss: 2.1334622502326965

Epoch: 6| Step: 11
Training loss: 2.177152633666992
Validation loss: 2.144109030564626

Epoch: 6| Step: 12
Training loss: 2.5211076736450195
Validation loss: 2.147125025590261

Epoch: 6| Step: 13
Training loss: 2.022545337677002
Validation loss: 2.1286567052205405

Epoch: 186| Step: 0
Training loss: 2.055893898010254
Validation loss: 2.134425421555837

Epoch: 6| Step: 1
Training loss: 1.814299464225769
Validation loss: 2.1281646291414895

Epoch: 6| Step: 2
Training loss: 1.4385547637939453
Validation loss: 2.1428787310918174

Epoch: 6| Step: 3
Training loss: 2.1946754455566406
Validation loss: 2.124096473058065

Epoch: 6| Step: 4
Training loss: 2.5366034507751465
Validation loss: 2.123996297518412

Epoch: 6| Step: 5
Training loss: 2.1305770874023438
Validation loss: 2.1304816802342734

Epoch: 6| Step: 6
Training loss: 2.3429346084594727
Validation loss: 2.14087837934494

Epoch: 6| Step: 7
Training loss: 1.8466455936431885
Validation loss: 2.1200804909070334

Epoch: 6| Step: 8
Training loss: 1.431673526763916
Validation loss: 2.1211452881495156

Epoch: 6| Step: 9
Training loss: 2.4091906547546387
Validation loss: 2.135913093884786

Epoch: 6| Step: 10
Training loss: 1.675126314163208
Validation loss: 2.1142846743265786

Epoch: 6| Step: 11
Training loss: 2.028752565383911
Validation loss: 2.1248303651809692

Epoch: 6| Step: 12
Training loss: 1.6670169830322266
Validation loss: 2.113977015018463

Epoch: 6| Step: 13
Training loss: 1.822052240371704
Validation loss: 2.14812966187795

Epoch: 187| Step: 0
Training loss: 2.106826066970825
Validation loss: 2.1196367740631104

Epoch: 6| Step: 1
Training loss: 2.061115264892578
Validation loss: 2.1249344746271768

Epoch: 6| Step: 2
Training loss: 1.6032488346099854
Validation loss: 2.1285572250684104

Epoch: 6| Step: 3
Training loss: 2.0084917545318604
Validation loss: 2.1351906061172485

Epoch: 6| Step: 4
Training loss: 1.689280390739441
Validation loss: 2.1027870178222656

Epoch: 6| Step: 5
Training loss: 1.8830821514129639
Validation loss: 2.1242480278015137

Epoch: 6| Step: 6
Training loss: 1.9355862140655518
Validation loss: 2.1078656117121377

Epoch: 6| Step: 7
Training loss: 2.8016228675842285
Validation loss: 2.1138274669647217

Epoch: 6| Step: 8
Training loss: 2.6019511222839355
Validation loss: 2.1178072492281594

Epoch: 6| Step: 9
Training loss: 2.2551426887512207
Validation loss: 2.1110344330469766

Epoch: 6| Step: 10
Training loss: 1.3472535610198975
Validation loss: 2.1240444580713906

Epoch: 6| Step: 11
Training loss: 1.8788466453552246
Validation loss: 2.123077630996704

Epoch: 6| Step: 12
Training loss: 1.6565580368041992
Validation loss: 2.102523465951284

Epoch: 6| Step: 13
Training loss: 1.7015979290008545
Validation loss: 2.144651214281718

Epoch: 188| Step: 0
Training loss: 2.172860860824585
Validation loss: 2.1420878171920776

Epoch: 6| Step: 1
Training loss: 1.9771161079406738
Validation loss: 2.122192084789276

Epoch: 6| Step: 2
Training loss: 1.8832119703292847
Validation loss: 2.11930521329244

Epoch: 6| Step: 3
Training loss: 1.2679179906845093
Validation loss: 2.1187837521235147

Epoch: 6| Step: 4
Training loss: 2.0903332233428955
Validation loss: 2.1296689907709756

Epoch: 6| Step: 5
Training loss: 1.9224042892456055
Validation loss: 2.133844017982483

Epoch: 6| Step: 6
Training loss: 1.77809739112854
Validation loss: 2.1384631792704263

Epoch: 6| Step: 7
Training loss: 1.7926032543182373
Validation loss: 2.1327046751976013

Epoch: 6| Step: 8
Training loss: 1.7059637308120728
Validation loss: 2.1581389705340066

Epoch: 6| Step: 9
Training loss: 2.2493956089019775
Validation loss: 2.1432863076527915

Epoch: 6| Step: 10
Training loss: 2.6952834129333496
Validation loss: 2.1195784409840903

Epoch: 6| Step: 11
Training loss: 2.41713285446167
Validation loss: 2.1317643324534097

Epoch: 6| Step: 12
Training loss: 1.3509130477905273
Validation loss: 2.1256593664487204

Epoch: 6| Step: 13
Training loss: 1.9947150945663452
Validation loss: 2.119330962498983

Epoch: 189| Step: 0
Training loss: 2.1439595222473145
Validation loss: 2.1343729496002197

Epoch: 6| Step: 1
Training loss: 1.816972255706787
Validation loss: 2.1101389129956565

Epoch: 6| Step: 2
Training loss: 2.232048749923706
Validation loss: 2.135878324508667

Epoch: 6| Step: 3
Training loss: 1.637068748474121
Validation loss: 2.1366635958353677

Epoch: 6| Step: 4
Training loss: 1.4623641967773438
Validation loss: 2.1345275243123374

Epoch: 6| Step: 5
Training loss: 2.3488268852233887
Validation loss: 2.133626639842987

Epoch: 6| Step: 6
Training loss: 1.8177541494369507
Validation loss: 2.1486034393310547

Epoch: 6| Step: 7
Training loss: 2.112752914428711
Validation loss: 2.1622411012649536

Epoch: 6| Step: 8
Training loss: 2.197685956954956
Validation loss: 2.174791475137075

Epoch: 6| Step: 9
Training loss: 1.7379415035247803
Validation loss: 2.169338901837667

Epoch: 6| Step: 10
Training loss: 2.5022854804992676
Validation loss: 2.176871736844381

Epoch: 6| Step: 11
Training loss: 2.127969741821289
Validation loss: 2.154874642690023

Epoch: 6| Step: 12
Training loss: 2.0249319076538086
Validation loss: 2.1588457822799683

Epoch: 6| Step: 13
Training loss: 1.604804515838623
Validation loss: 2.129631598790487

Epoch: 190| Step: 0
Training loss: 1.555902123451233
Validation loss: 2.130814850330353

Epoch: 6| Step: 1
Training loss: 1.706818699836731
Validation loss: 2.1206459204355874

Epoch: 6| Step: 2
Training loss: 2.1767690181732178
Validation loss: 2.1208210786183677

Epoch: 6| Step: 3
Training loss: 2.3042855262756348
Validation loss: 2.1221318443616233

Epoch: 6| Step: 4
Training loss: 1.9823966026306152
Validation loss: 2.12332675854365

Epoch: 6| Step: 5
Training loss: 1.9544615745544434
Validation loss: 2.1112122734387717

Epoch: 6| Step: 6
Training loss: 2.261740207672119
Validation loss: 2.107156773408254

Epoch: 6| Step: 7
Training loss: 2.1451122760772705
Validation loss: 2.103857159614563

Epoch: 6| Step: 8
Training loss: 2.7848432064056396
Validation loss: 2.136750260988871

Epoch: 6| Step: 9
Training loss: 1.8715988397598267
Validation loss: 2.134865919748942

Epoch: 6| Step: 10
Training loss: 1.4700875282287598
Validation loss: 2.1295716961224875

Epoch: 6| Step: 11
Training loss: 1.3237632513046265
Validation loss: 2.121655265490214

Epoch: 6| Step: 12
Training loss: 2.364143133163452
Validation loss: 2.1349568168322244

Epoch: 6| Step: 13
Training loss: 1.7994990348815918
Validation loss: 2.1454930901527405

Epoch: 191| Step: 0
Training loss: 1.5464153289794922
Validation loss: 2.1592211922009787

Epoch: 6| Step: 1
Training loss: 1.9860193729400635
Validation loss: 2.1360912720362344

Epoch: 6| Step: 2
Training loss: 1.802877426147461
Validation loss: 2.1199533343315125

Epoch: 6| Step: 3
Training loss: 1.8036425113677979
Validation loss: 2.146881103515625

Epoch: 6| Step: 4
Training loss: 1.68317449092865
Validation loss: 2.125740667184194

Epoch: 6| Step: 5
Training loss: 2.2110419273376465
Validation loss: 2.10788357257843

Epoch: 6| Step: 6
Training loss: 2.1299943923950195
Validation loss: 2.094967563947042

Epoch: 6| Step: 7
Training loss: 1.399531602859497
Validation loss: 2.115877389907837

Epoch: 6| Step: 8
Training loss: 2.712116003036499
Validation loss: 2.115963876247406

Epoch: 6| Step: 9
Training loss: 2.051879405975342
Validation loss: 2.12070365746816

Epoch: 6| Step: 10
Training loss: 2.1561636924743652
Validation loss: 2.126591364542643

Epoch: 6| Step: 11
Training loss: 1.8836193084716797
Validation loss: 2.123386283715566

Epoch: 6| Step: 12
Training loss: 2.339017868041992
Validation loss: 2.132283171017965

Epoch: 6| Step: 13
Training loss: 1.9052042961120605
Validation loss: 2.1315417885780334

Epoch: 192| Step: 0
Training loss: 2.5925064086914062
Validation loss: 2.1327747305234275

Epoch: 6| Step: 1
Training loss: 2.527158737182617
Validation loss: 2.1411171356836953

Epoch: 6| Step: 2
Training loss: 2.3523473739624023
Validation loss: 2.127499997615814

Epoch: 6| Step: 3
Training loss: 1.4784023761749268
Validation loss: 2.1305348873138428

Epoch: 6| Step: 4
Training loss: 1.8086074590682983
Validation loss: 2.1264198621114097

Epoch: 6| Step: 5
Training loss: 1.549249291419983
Validation loss: 2.142214377721151

Epoch: 6| Step: 6
Training loss: 1.9514353275299072
Validation loss: 2.128470778465271

Epoch: 6| Step: 7
Training loss: 1.840746283531189
Validation loss: 2.1128783424695334

Epoch: 6| Step: 8
Training loss: 1.6240990161895752
Validation loss: 2.1203125715255737

Epoch: 6| Step: 9
Training loss: 2.002189874649048
Validation loss: 2.1223117311795554

Epoch: 6| Step: 10
Training loss: 1.6097251176834106
Validation loss: 2.1299761732419333

Epoch: 6| Step: 11
Training loss: 1.7946054935455322
Validation loss: 2.1115210254987082

Epoch: 6| Step: 12
Training loss: 2.6193466186523438
Validation loss: 2.1382885575294495

Epoch: 6| Step: 13
Training loss: 1.7978687286376953
Validation loss: 2.1310980717341104

Epoch: 193| Step: 0
Training loss: 1.5743876695632935
Validation loss: 2.126466751098633

Epoch: 6| Step: 1
Training loss: 2.319127321243286
Validation loss: 2.133419672648112

Epoch: 6| Step: 2
Training loss: 2.1627578735351562
Validation loss: 2.1220361789067588

Epoch: 6| Step: 3
Training loss: 1.6678940057754517
Validation loss: 2.130344053109487

Epoch: 6| Step: 4
Training loss: 1.9362704753875732
Validation loss: 2.1199050347010293

Epoch: 6| Step: 5
Training loss: 1.7935070991516113
Validation loss: 2.1206828951835632

Epoch: 6| Step: 6
Training loss: 2.2972421646118164
Validation loss: 2.127647320429484

Epoch: 6| Step: 7
Training loss: 1.72390615940094
Validation loss: 2.1241206526756287

Epoch: 6| Step: 8
Training loss: 2.2876930236816406
Validation loss: 2.1241084734598794

Epoch: 6| Step: 9
Training loss: 1.8999642133712769
Validation loss: 2.125102718671163

Epoch: 6| Step: 10
Training loss: 1.8254156112670898
Validation loss: 2.124189635117849

Epoch: 6| Step: 11
Training loss: 2.412841796875
Validation loss: 2.1242635250091553

Epoch: 6| Step: 12
Training loss: 1.6711318492889404
Validation loss: 2.1173405845959983

Epoch: 6| Step: 13
Training loss: 1.5883060693740845
Validation loss: 2.1263938347498574

Epoch: 194| Step: 0
Training loss: 2.286365032196045
Validation loss: 2.117408355077108

Epoch: 6| Step: 1
Training loss: 2.4651286602020264
Validation loss: 2.128978451093038

Epoch: 6| Step: 2
Training loss: 1.9057199954986572
Validation loss: 2.1235621571540833

Epoch: 6| Step: 3
Training loss: 2.8383610248565674
Validation loss: 2.130562682946523

Epoch: 6| Step: 4
Training loss: 1.5841875076293945
Validation loss: 2.122896432876587

Epoch: 6| Step: 5
Training loss: 1.4815669059753418
Validation loss: 2.12275622288386

Epoch: 6| Step: 6
Training loss: 2.385622024536133
Validation loss: 2.127612590789795

Epoch: 6| Step: 7
Training loss: 1.3719322681427002
Validation loss: 2.1144073208173118

Epoch: 6| Step: 8
Training loss: 1.1170616149902344
Validation loss: 2.1413097977638245

Epoch: 6| Step: 9
Training loss: 2.2890570163726807
Validation loss: 2.112675905227661

Epoch: 6| Step: 10
Training loss: 1.9229837656021118
Validation loss: 2.1290352940559387

Epoch: 6| Step: 11
Training loss: 1.267585039138794
Validation loss: 2.1470848321914673

Epoch: 6| Step: 12
Training loss: 2.2876577377319336
Validation loss: 2.1317291855812073

Epoch: 6| Step: 13
Training loss: 2.0327911376953125
Validation loss: 2.1379421750704446

Epoch: 195| Step: 0
Training loss: 1.5258556604385376
Validation loss: 2.149523218472799

Epoch: 6| Step: 1
Training loss: 1.8828216791152954
Validation loss: 2.1231929858525596

Epoch: 6| Step: 2
Training loss: 2.1970596313476562
Validation loss: 2.1383109887441

Epoch: 6| Step: 3
Training loss: 2.6893975734710693
Validation loss: 2.119702696800232

Epoch: 6| Step: 4
Training loss: 1.3335758447647095
Validation loss: 2.1281558672587075

Epoch: 6| Step: 5
Training loss: 1.6018965244293213
Validation loss: 2.1335128347078958

Epoch: 6| Step: 6
Training loss: 1.3347424268722534
Validation loss: 2.1348926424980164

Epoch: 6| Step: 7
Training loss: 1.9887421131134033
Validation loss: 2.1312458515167236

Epoch: 6| Step: 8
Training loss: 1.75472092628479
Validation loss: 2.1406805515289307

Epoch: 6| Step: 9
Training loss: 1.687258005142212
Validation loss: 2.1335553725560508

Epoch: 6| Step: 10
Training loss: 2.2672085762023926
Validation loss: 2.134361684322357

Epoch: 6| Step: 11
Training loss: 2.068143844604492
Validation loss: 2.135008454322815

Epoch: 6| Step: 12
Training loss: 2.802443504333496
Validation loss: 2.1343694925308228

Epoch: 6| Step: 13
Training loss: 2.0416276454925537
Validation loss: 2.134488860766093

Epoch: 196| Step: 0
Training loss: 1.5758390426635742
Validation loss: 2.140179673830668

Epoch: 6| Step: 1
Training loss: 1.7360329627990723
Validation loss: 2.1437454223632812

Epoch: 6| Step: 2
Training loss: 2.0644500255584717
Validation loss: 2.1378540992736816

Epoch: 6| Step: 3
Training loss: 1.5969417095184326
Validation loss: 2.144999384880066

Epoch: 6| Step: 4
Training loss: 2.38006591796875
Validation loss: 2.1446197827657065

Epoch: 6| Step: 5
Training loss: 1.7233076095581055
Validation loss: 2.1325514117876687

Epoch: 6| Step: 6
Training loss: 2.002854347229004
Validation loss: 2.151680866877238

Epoch: 6| Step: 7
Training loss: 1.7844507694244385
Validation loss: 2.1486304799715676

Epoch: 6| Step: 8
Training loss: 2.0307459831237793
Validation loss: 2.140993316968282

Epoch: 6| Step: 9
Training loss: 1.8636960983276367
Validation loss: 2.1471264163653054

Epoch: 6| Step: 10
Training loss: 1.9129035472869873
Validation loss: 2.1476954420407615

Epoch: 6| Step: 11
Training loss: 2.1282601356506348
Validation loss: 2.148149768511454

Epoch: 6| Step: 12
Training loss: 2.0883092880249023
Validation loss: 2.16202704111735

Epoch: 6| Step: 13
Training loss: 2.218602418899536
Validation loss: 2.158252457777659

Epoch: 197| Step: 0
Training loss: 1.6439337730407715
Validation loss: 2.1451372702916465

Epoch: 6| Step: 1
Training loss: 1.717905044555664
Validation loss: 2.136437475681305

Epoch: 6| Step: 2
Training loss: 1.7935700416564941
Validation loss: 2.1437365214029946

Epoch: 6| Step: 3
Training loss: 1.9646775722503662
Validation loss: 2.1529110272725425

Epoch: 6| Step: 4
Training loss: 2.3007664680480957
Validation loss: 2.132472276687622

Epoch: 6| Step: 5
Training loss: 1.6984922885894775
Validation loss: 2.154207249482473

Epoch: 6| Step: 6
Training loss: 1.6026917695999146
Validation loss: 2.1399811704953513

Epoch: 6| Step: 7
Training loss: 2.4888672828674316
Validation loss: 2.1334091424942017

Epoch: 6| Step: 8
Training loss: 1.6624778509140015
Validation loss: 2.136074880758921

Epoch: 6| Step: 9
Training loss: 2.0167288780212402
Validation loss: 2.1398666302363076

Epoch: 6| Step: 10
Training loss: 2.115797519683838
Validation loss: 2.151522239049276

Epoch: 6| Step: 11
Training loss: 2.0143184661865234
Validation loss: 2.1495327154795327

Epoch: 6| Step: 12
Training loss: 2.022054672241211
Validation loss: 2.140659272670746

Epoch: 6| Step: 13
Training loss: 1.9553632736206055
Validation loss: 2.141799529393514

Epoch: 198| Step: 0
Training loss: 2.668764352798462
Validation loss: 2.1575094858805337

Epoch: 6| Step: 1
Training loss: 1.8777780532836914
Validation loss: 2.148673137029012

Epoch: 6| Step: 2
Training loss: 2.049163341522217
Validation loss: 2.1389032006263733

Epoch: 6| Step: 3
Training loss: 2.135923385620117
Validation loss: 2.1477393309275308

Epoch: 6| Step: 4
Training loss: 1.8125343322753906
Validation loss: 2.138195753097534

Epoch: 6| Step: 5
Training loss: 1.6312694549560547
Validation loss: 2.145385225613912

Epoch: 6| Step: 6
Training loss: 1.3739404678344727
Validation loss: 2.1470744212468467

Epoch: 6| Step: 7
Training loss: 1.8389720916748047
Validation loss: 2.1463586886723838

Epoch: 6| Step: 8
Training loss: 1.8488636016845703
Validation loss: 2.1445420185724893

Epoch: 6| Step: 9
Training loss: 1.591301441192627
Validation loss: 2.155260463555654

Epoch: 6| Step: 10
Training loss: 1.617438554763794
Validation loss: 2.1626010735829673

Epoch: 6| Step: 11
Training loss: 1.9562757015228271
Validation loss: 2.176865041255951

Epoch: 6| Step: 12
Training loss: 2.3199427127838135
Validation loss: 2.1721192797025046

Epoch: 6| Step: 13
Training loss: 2.141946315765381
Validation loss: 2.184048851331075

Epoch: 199| Step: 0
Training loss: 1.8666131496429443
Validation loss: 2.1802834272384644

Epoch: 6| Step: 1
Training loss: 1.4061288833618164
Validation loss: 2.1755592823028564

Epoch: 6| Step: 2
Training loss: 1.7613396644592285
Validation loss: 2.174715598424276

Epoch: 6| Step: 3
Training loss: 2.652282953262329
Validation loss: 2.159601072470347

Epoch: 6| Step: 4
Training loss: 2.3826122283935547
Validation loss: 2.1623878876368203

Epoch: 6| Step: 5
Training loss: 2.5401787757873535
Validation loss: 2.1476786732673645

Epoch: 6| Step: 6
Training loss: 1.3631595373153687
Validation loss: 2.1513507763544717

Epoch: 6| Step: 7
Training loss: 1.6888375282287598
Validation loss: 2.1313160061836243

Epoch: 6| Step: 8
Training loss: 1.821336030960083
Validation loss: 2.11885658899943

Epoch: 6| Step: 9
Training loss: 2.2399277687072754
Validation loss: 2.1219932436943054

Epoch: 6| Step: 10
Training loss: 1.839906930923462
Validation loss: 2.1334375540415444

Epoch: 6| Step: 11
Training loss: 2.1475391387939453
Validation loss: 2.1368751724561057

Epoch: 6| Step: 12
Training loss: 1.8338881731033325
Validation loss: 2.1395634412765503

Epoch: 6| Step: 13
Training loss: 1.8157206773757935
Validation loss: 2.1308660308519998

Epoch: 200| Step: 0
Training loss: 1.9352679252624512
Validation loss: 2.1515525182088218

Epoch: 6| Step: 1
Training loss: 1.6384011507034302
Validation loss: 2.157620290915171

Epoch: 6| Step: 2
Training loss: 2.0128679275512695
Validation loss: 2.1564476092656455

Epoch: 6| Step: 3
Training loss: 2.1674447059631348
Validation loss: 2.1538833181063333

Epoch: 6| Step: 4
Training loss: 1.8176394701004028
Validation loss: 2.163074254989624

Epoch: 6| Step: 5
Training loss: 1.7415744066238403
Validation loss: 2.156011978785197

Epoch: 6| Step: 6
Training loss: 2.270656108856201
Validation loss: 2.1339279611905417

Epoch: 6| Step: 7
Training loss: 2.7244553565979004
Validation loss: 2.1422178149223328

Epoch: 6| Step: 8
Training loss: 1.697167992591858
Validation loss: 2.132178008556366

Epoch: 6| Step: 9
Training loss: 1.5496195554733276
Validation loss: 2.1563969055811563

Epoch: 6| Step: 10
Training loss: 2.516054630279541
Validation loss: 2.152431607246399

Epoch: 6| Step: 11
Training loss: 1.8837318420410156
Validation loss: 2.165676732858022

Epoch: 6| Step: 12
Training loss: 1.7032212018966675
Validation loss: 2.153978923956553

Epoch: 6| Step: 13
Training loss: 1.4363605976104736
Validation loss: 2.151148955027262

Epoch: 201| Step: 0
Training loss: 1.8444855213165283
Validation loss: 2.1629488865534463

Epoch: 6| Step: 1
Training loss: 1.3105742931365967
Validation loss: 2.130743980407715

Epoch: 6| Step: 2
Training loss: 2.5352237224578857
Validation loss: 2.1503416101137796

Epoch: 6| Step: 3
Training loss: 1.4722105264663696
Validation loss: 2.148862361907959

Epoch: 6| Step: 4
Training loss: 2.5726168155670166
Validation loss: 2.1494606733322144

Epoch: 6| Step: 5
Training loss: 2.6068015098571777
Validation loss: 2.1336715618769326

Epoch: 6| Step: 6
Training loss: 1.8787951469421387
Validation loss: 2.143515666325887

Epoch: 6| Step: 7
Training loss: 1.8806174993515015
Validation loss: 2.140324850877126

Epoch: 6| Step: 8
Training loss: 1.7614299058914185
Validation loss: 2.1488651037216187

Epoch: 6| Step: 9
Training loss: 2.0552127361297607
Validation loss: 2.1462870836257935

Epoch: 6| Step: 10
Training loss: 1.8058596849441528
Validation loss: 2.150889575481415

Epoch: 6| Step: 11
Training loss: 1.887954592704773
Validation loss: 2.148004333178202

Epoch: 6| Step: 12
Training loss: 1.6079421043395996
Validation loss: 2.141179839769999

Epoch: 6| Step: 13
Training loss: 2.1258158683776855
Validation loss: 2.1496375600496926

Epoch: 202| Step: 0
Training loss: 1.5134565830230713
Validation loss: 2.141420920689901

Epoch: 6| Step: 1
Training loss: 1.9486238956451416
Validation loss: 2.1590214371681213

Epoch: 6| Step: 2
Training loss: 2.1990628242492676
Validation loss: 2.1679553389549255

Epoch: 6| Step: 3
Training loss: 1.6551131010055542
Validation loss: 2.136775096257528

Epoch: 6| Step: 4
Training loss: 1.7747769355773926
Validation loss: 2.1533005436261496

Epoch: 6| Step: 5
Training loss: 2.3187918663024902
Validation loss: 2.157195786635081

Epoch: 6| Step: 6
Training loss: 1.6158055067062378
Validation loss: 2.1672152876853943

Epoch: 6| Step: 7
Training loss: 2.284292221069336
Validation loss: 2.164521892865499

Epoch: 6| Step: 8
Training loss: 1.9258280992507935
Validation loss: 2.1791436076164246

Epoch: 6| Step: 9
Training loss: 2.336035966873169
Validation loss: 2.149320363998413

Epoch: 6| Step: 10
Training loss: 1.543617606163025
Validation loss: 2.1697841684023538

Epoch: 6| Step: 11
Training loss: 2.313964366912842
Validation loss: 2.1607447067896524

Epoch: 6| Step: 12
Training loss: 2.153961181640625
Validation loss: 2.1543532411257424

Epoch: 6| Step: 13
Training loss: 1.6742289066314697
Validation loss: 2.1691289146741233

Epoch: 203| Step: 0
Training loss: 1.7132599353790283
Validation loss: 2.1585222085316977

Epoch: 6| Step: 1
Training loss: 2.1503348350524902
Validation loss: 2.1624087492624917

Epoch: 6| Step: 2
Training loss: 2.1233580112457275
Validation loss: 2.154360850652059

Epoch: 6| Step: 3
Training loss: 2.621070623397827
Validation loss: 2.1587670842806497

Epoch: 6| Step: 4
Training loss: 1.8122596740722656
Validation loss: 2.158408800760905

Epoch: 6| Step: 5
Training loss: 1.9694937467575073
Validation loss: 2.1569813887278237

Epoch: 6| Step: 6
Training loss: 1.8036363124847412
Validation loss: 2.158249835173289

Epoch: 6| Step: 7
Training loss: 2.1345877647399902
Validation loss: 2.1861858566602073

Epoch: 6| Step: 8
Training loss: 1.923632025718689
Validation loss: 2.1630998452504477

Epoch: 6| Step: 9
Training loss: 1.3752741813659668
Validation loss: 2.1536430517832437

Epoch: 6| Step: 10
Training loss: 1.401703953742981
Validation loss: 2.1730918685595193

Epoch: 6| Step: 11
Training loss: 1.65459406375885
Validation loss: 2.1746612985928855

Epoch: 6| Step: 12
Training loss: 1.9898568391799927
Validation loss: 2.1682446797688804

Epoch: 6| Step: 13
Training loss: 2.150794506072998
Validation loss: 2.174046039581299

Epoch: 204| Step: 0
Training loss: 1.8380500078201294
Validation loss: 2.150819996992747

Epoch: 6| Step: 1
Training loss: 2.0005030632019043
Validation loss: 2.1668840646743774

Epoch: 6| Step: 2
Training loss: 1.6329392194747925
Validation loss: 2.159651458263397

Epoch: 6| Step: 3
Training loss: 2.00935697555542
Validation loss: 2.164419094721476

Epoch: 6| Step: 4
Training loss: 2.22468900680542
Validation loss: 2.170155127843221

Epoch: 6| Step: 5
Training loss: 1.491379737854004
Validation loss: 2.1514551639556885

Epoch: 6| Step: 6
Training loss: 1.5855188369750977
Validation loss: 2.1579106648763022

Epoch: 6| Step: 7
Training loss: 1.6973764896392822
Validation loss: 2.142459531625112

Epoch: 6| Step: 8
Training loss: 1.7298167943954468
Validation loss: 2.1641862193743386

Epoch: 6| Step: 9
Training loss: 2.0637710094451904
Validation loss: 2.1757537126541138

Epoch: 6| Step: 10
Training loss: 1.544262170791626
Validation loss: 2.1550497810045877

Epoch: 6| Step: 11
Training loss: 2.3158981800079346
Validation loss: 2.171200474103292

Epoch: 6| Step: 12
Training loss: 2.458099842071533
Validation loss: 2.1682329376538596

Epoch: 6| Step: 13
Training loss: 2.111542224884033
Validation loss: 2.170524756113688

Epoch: 205| Step: 0
Training loss: 2.0829434394836426
Validation loss: 2.159796416759491

Epoch: 6| Step: 1
Training loss: 1.5339215993881226
Validation loss: 2.155692378679911

Epoch: 6| Step: 2
Training loss: 2.039623737335205
Validation loss: 2.183774014314016

Epoch: 6| Step: 3
Training loss: 1.9237123727798462
Validation loss: 2.1584051052729287

Epoch: 6| Step: 4
Training loss: 1.9102227687835693
Validation loss: 2.1623106598854065

Epoch: 6| Step: 5
Training loss: 2.1415510177612305
Validation loss: 2.162280321121216

Epoch: 6| Step: 6
Training loss: 1.7163535356521606
Validation loss: 2.1527729829152427

Epoch: 6| Step: 7
Training loss: 2.22408390045166
Validation loss: 2.171756148338318

Epoch: 6| Step: 8
Training loss: 1.5719633102416992
Validation loss: 2.1644286712010703

Epoch: 6| Step: 9
Training loss: 1.792768120765686
Validation loss: 2.1626248558362327

Epoch: 6| Step: 10
Training loss: 1.9666074514389038
Validation loss: 2.1570494969685874

Epoch: 6| Step: 11
Training loss: 2.061192750930786
Validation loss: 2.163958191871643

Epoch: 6| Step: 12
Training loss: 2.0424537658691406
Validation loss: 2.160647173722585

Epoch: 6| Step: 13
Training loss: 2.015096664428711
Validation loss: 2.175745189189911

Epoch: 206| Step: 0
Training loss: 1.8148972988128662
Validation loss: 2.175078252951304

Epoch: 6| Step: 1
Training loss: 1.431540846824646
Validation loss: 2.165829598903656

Epoch: 6| Step: 2
Training loss: 2.3731327056884766
Validation loss: 2.1816808183987937

Epoch: 6| Step: 3
Training loss: 1.5293506383895874
Validation loss: 2.1720736225446067

Epoch: 6| Step: 4
Training loss: 2.273055076599121
Validation loss: 2.1877423524856567

Epoch: 6| Step: 5
Training loss: 1.2887310981750488
Validation loss: 2.1837551593780518

Epoch: 6| Step: 6
Training loss: 2.634891986846924
Validation loss: 2.1847556034723916

Epoch: 6| Step: 7
Training loss: 2.2515621185302734
Validation loss: 2.1707917849222818

Epoch: 6| Step: 8
Training loss: 1.9921032190322876
Validation loss: 2.16981170574824

Epoch: 6| Step: 9
Training loss: 2.317601442337036
Validation loss: 2.1474422613779702

Epoch: 6| Step: 10
Training loss: 1.768740177154541
Validation loss: 2.1492324670155845

Epoch: 6| Step: 11
Training loss: 1.6917393207550049
Validation loss: 2.1631056467692056

Epoch: 6| Step: 12
Training loss: 1.6982263326644897
Validation loss: 2.1504714488983154

Epoch: 6| Step: 13
Training loss: 1.6005058288574219
Validation loss: 2.155835489432017

Epoch: 207| Step: 0
Training loss: 1.736053228378296
Validation loss: 2.1663413047790527

Epoch: 6| Step: 1
Training loss: 2.09537935256958
Validation loss: 2.1587727665901184

Epoch: 6| Step: 2
Training loss: 1.5315443277359009
Validation loss: 2.169063409169515

Epoch: 6| Step: 3
Training loss: 2.829678535461426
Validation loss: 2.1829540729522705

Epoch: 6| Step: 4
Training loss: 1.390855312347412
Validation loss: 2.154404362042745

Epoch: 6| Step: 5
Training loss: 1.2270598411560059
Validation loss: 2.1842001477877298

Epoch: 6| Step: 6
Training loss: 1.7349172830581665
Validation loss: 2.1756033897399902

Epoch: 6| Step: 7
Training loss: 2.0341110229492188
Validation loss: 2.156571388244629

Epoch: 6| Step: 8
Training loss: 1.301218032836914
Validation loss: 2.163534164428711

Epoch: 6| Step: 9
Training loss: 2.0776634216308594
Validation loss: 2.1797754565874734

Epoch: 6| Step: 10
Training loss: 2.0478572845458984
Validation loss: 2.170508066813151

Epoch: 6| Step: 11
Training loss: 1.8165963888168335
Validation loss: 2.1700475215911865

Epoch: 6| Step: 12
Training loss: 2.223989963531494
Validation loss: 2.163997173309326

Epoch: 6| Step: 13
Training loss: 2.4439620971679688
Validation loss: 2.1670436461766562

Epoch: 208| Step: 0
Training loss: 2.3761653900146484
Validation loss: 2.1615550915400186

Epoch: 6| Step: 1
Training loss: 1.9513986110687256
Validation loss: 2.1806554396947226

Epoch: 6| Step: 2
Training loss: 1.6503854990005493
Validation loss: 2.1932833790779114

Epoch: 6| Step: 3
Training loss: 1.681433916091919
Validation loss: 2.1906990011533103

Epoch: 6| Step: 4
Training loss: 1.4883465766906738
Validation loss: 2.174815595149994

Epoch: 6| Step: 5
Training loss: 1.7639789581298828
Validation loss: 2.1904605428377786

Epoch: 6| Step: 6
Training loss: 1.7102386951446533
Validation loss: 2.181999166806539

Epoch: 6| Step: 7
Training loss: 1.8877846002578735
Validation loss: 2.1719537576039634

Epoch: 6| Step: 8
Training loss: 1.8570706844329834
Validation loss: 2.166975657145182

Epoch: 6| Step: 9
Training loss: 2.4732613563537598
Validation loss: 2.1776711146036782

Epoch: 6| Step: 10
Training loss: 1.6113195419311523
Validation loss: 2.1867302656173706

Epoch: 6| Step: 11
Training loss: 1.89292573928833
Validation loss: 2.1471049388249717

Epoch: 6| Step: 12
Training loss: 2.1621439456939697
Validation loss: 2.1483198205629983

Epoch: 6| Step: 13
Training loss: 2.1355276107788086
Validation loss: 2.167473256587982

Epoch: 209| Step: 0
Training loss: 1.719704508781433
Validation loss: 2.158980151017507

Epoch: 6| Step: 1
Training loss: 1.4487264156341553
Validation loss: 2.150017023086548

Epoch: 6| Step: 2
Training loss: 1.695404291152954
Validation loss: 2.160364846388499

Epoch: 6| Step: 3
Training loss: 2.0953333377838135
Validation loss: 2.163311799367269

Epoch: 6| Step: 4
Training loss: 1.446346402168274
Validation loss: 2.1771154602368674

Epoch: 6| Step: 5
Training loss: 2.6533946990966797
Validation loss: 2.1746496756871543

Epoch: 6| Step: 6
Training loss: 1.825179100036621
Validation loss: 2.167524973551432

Epoch: 6| Step: 7
Training loss: 1.68126380443573
Validation loss: 2.179436425367991

Epoch: 6| Step: 8
Training loss: 1.823035478591919
Validation loss: 2.166251758734385

Epoch: 6| Step: 9
Training loss: 1.9824693202972412
Validation loss: 2.184581716855367

Epoch: 6| Step: 10
Training loss: 2.4307122230529785
Validation loss: 2.1874937613805137

Epoch: 6| Step: 11
Training loss: 2.1819026470184326
Validation loss: 2.1901082197825112

Epoch: 6| Step: 12
Training loss: 1.9095280170440674
Validation loss: 2.212613801161448

Epoch: 6| Step: 13
Training loss: 1.8064864873886108
Validation loss: 2.192710558573405

Epoch: 210| Step: 0
Training loss: 2.0976006984710693
Validation loss: 2.189150412877401

Epoch: 6| Step: 1
Training loss: 2.204315662384033
Validation loss: 2.193055431048075

Epoch: 6| Step: 2
Training loss: 1.5688369274139404
Validation loss: 2.152719497680664

Epoch: 6| Step: 3
Training loss: 2.4504873752593994
Validation loss: 2.152488589286804

Epoch: 6| Step: 4
Training loss: 2.042336940765381
Validation loss: 2.148050586382548

Epoch: 6| Step: 5
Training loss: 2.2658567428588867
Validation loss: 2.1396822333335876

Epoch: 6| Step: 6
Training loss: 1.733166217803955
Validation loss: 2.146212915579478

Epoch: 6| Step: 7
Training loss: 2.4612488746643066
Validation loss: 2.145680566628774

Epoch: 6| Step: 8
Training loss: 1.8543691635131836
Validation loss: 2.1541587710380554

Epoch: 6| Step: 9
Training loss: 1.7635928392410278
Validation loss: 2.1510274012883506

Epoch: 6| Step: 10
Training loss: 2.010679006576538
Validation loss: 2.1515903075536094

Epoch: 6| Step: 11
Training loss: 1.7103875875473022
Validation loss: 2.168271541595459

Epoch: 6| Step: 12
Training loss: 1.8459103107452393
Validation loss: 2.1699803272883096

Epoch: 6| Step: 13
Training loss: 1.6471377611160278
Validation loss: 2.1658175388971963

Epoch: 211| Step: 0
Training loss: 2.1010851860046387
Validation loss: 2.191058953603109

Epoch: 6| Step: 1
Training loss: 1.4631879329681396
Validation loss: 2.18776140610377

Epoch: 6| Step: 2
Training loss: 1.7764403820037842
Validation loss: 2.197788675626119

Epoch: 6| Step: 3
Training loss: 1.5175436735153198
Validation loss: 2.219419519106547

Epoch: 6| Step: 4
Training loss: 1.9093611240386963
Validation loss: 2.201492746671041

Epoch: 6| Step: 5
Training loss: 2.179166316986084
Validation loss: 2.1954681873321533

Epoch: 6| Step: 6
Training loss: 1.6501355171203613
Validation loss: 2.1986243526140847

Epoch: 6| Step: 7
Training loss: 1.8223927021026611
Validation loss: 2.2168278296788535

Epoch: 6| Step: 8
Training loss: 1.9748225212097168
Validation loss: 2.1795659263928733

Epoch: 6| Step: 9
Training loss: 1.6964631080627441
Validation loss: 2.1811317006746926

Epoch: 6| Step: 10
Training loss: 1.5062305927276611
Validation loss: 2.170630931854248

Epoch: 6| Step: 11
Training loss: 2.8639814853668213
Validation loss: 2.161568800608317

Epoch: 6| Step: 12
Training loss: 2.2817845344543457
Validation loss: 2.157526969909668

Epoch: 6| Step: 13
Training loss: 2.1537256240844727
Validation loss: 2.1419133941332498

Epoch: 212| Step: 0
Training loss: 2.5788490772247314
Validation loss: 2.1469268997510276

Epoch: 6| Step: 1
Training loss: 1.9882774353027344
Validation loss: 2.1560694773991904

Epoch: 6| Step: 2
Training loss: 2.5872015953063965
Validation loss: 2.1624850630760193

Epoch: 6| Step: 3
Training loss: 1.7754837274551392
Validation loss: 2.1693843603134155

Epoch: 6| Step: 4
Training loss: 1.7952375411987305
Validation loss: 2.1675051053365073

Epoch: 6| Step: 5
Training loss: 0.9416810870170593
Validation loss: 2.1899142066637673

Epoch: 6| Step: 6
Training loss: 1.9098314046859741
Validation loss: 2.17793478568395

Epoch: 6| Step: 7
Training loss: 2.390960693359375
Validation loss: 2.188016434510549

Epoch: 6| Step: 8
Training loss: 1.665653109550476
Validation loss: 2.202781558036804

Epoch: 6| Step: 9
Training loss: 1.1308974027633667
Validation loss: 2.1989060044288635

Epoch: 6| Step: 10
Training loss: 2.5412793159484863
Validation loss: 2.1970741152763367

Epoch: 6| Step: 11
Training loss: 1.7235033512115479
Validation loss: 2.186245322227478

Epoch: 6| Step: 12
Training loss: 2.11930251121521
Validation loss: 2.165687004725138

Epoch: 6| Step: 13
Training loss: 1.765228509902954
Validation loss: 2.200634241104126

Epoch: 213| Step: 0
Training loss: 2.237168312072754
Validation loss: 2.1761521100997925

Epoch: 6| Step: 1
Training loss: 1.7267118692398071
Validation loss: 2.177284002304077

Epoch: 6| Step: 2
Training loss: 2.856091022491455
Validation loss: 2.1798117558161416

Epoch: 6| Step: 3
Training loss: 2.3091278076171875
Validation loss: 2.1690258979797363

Epoch: 6| Step: 4
Training loss: 2.0441980361938477
Validation loss: 2.1581774155298867

Epoch: 6| Step: 5
Training loss: 1.5003303289413452
Validation loss: 2.166005253791809

Epoch: 6| Step: 6
Training loss: 1.8316359519958496
Validation loss: 2.170950770378113

Epoch: 6| Step: 7
Training loss: 1.946897029876709
Validation loss: 2.167503595352173

Epoch: 6| Step: 8
Training loss: 1.5368735790252686
Validation loss: 2.1413992842038474

Epoch: 6| Step: 9
Training loss: 1.4876267910003662
Validation loss: 2.15359099706014

Epoch: 6| Step: 10
Training loss: 1.2577438354492188
Validation loss: 2.1380261977513633

Epoch: 6| Step: 11
Training loss: 1.7472021579742432
Validation loss: 2.144693752129873

Epoch: 6| Step: 12
Training loss: 2.0573489665985107
Validation loss: 2.1705384055773416

Epoch: 6| Step: 13
Training loss: 2.21804141998291
Validation loss: 2.178252657254537

Epoch: 214| Step: 0
Training loss: 1.793151617050171
Validation loss: 2.1482751766840615

Epoch: 6| Step: 1
Training loss: 1.3203668594360352
Validation loss: 2.1722704569498696

Epoch: 6| Step: 2
Training loss: 1.7592068910598755
Validation loss: 2.1614118218421936

Epoch: 6| Step: 3
Training loss: 2.4398012161254883
Validation loss: 2.161872605482737

Epoch: 6| Step: 4
Training loss: 2.0134546756744385
Validation loss: 2.1613550186157227

Epoch: 6| Step: 5
Training loss: 1.958506464958191
Validation loss: 2.185670495033264

Epoch: 6| Step: 6
Training loss: 2.4406914710998535
Validation loss: 2.185448149840037

Epoch: 6| Step: 7
Training loss: 2.018648862838745
Validation loss: 2.18098775545756

Epoch: 6| Step: 8
Training loss: 1.6907055377960205
Validation loss: 2.201055924097697

Epoch: 6| Step: 9
Training loss: 1.7384016513824463
Validation loss: 2.196252087752024

Epoch: 6| Step: 10
Training loss: 1.8743000030517578
Validation loss: 2.2022316257158914

Epoch: 6| Step: 11
Training loss: 1.7296282052993774
Validation loss: 2.1734995245933533

Epoch: 6| Step: 12
Training loss: 2.222393274307251
Validation loss: 2.161858081817627

Epoch: 6| Step: 13
Training loss: 1.832625389099121
Validation loss: 2.1824916998545327

Epoch: 215| Step: 0
Training loss: 1.9375550746917725
Validation loss: 2.1653777956962585

Epoch: 6| Step: 1
Training loss: 2.3618054389953613
Validation loss: 2.1689144174257913

Epoch: 6| Step: 2
Training loss: 1.2385873794555664
Validation loss: 2.1683938105901084

Epoch: 6| Step: 3
Training loss: 1.6854968070983887
Validation loss: 2.1555834213892617

Epoch: 6| Step: 4
Training loss: 1.8453991413116455
Validation loss: 2.1653292973836265

Epoch: 6| Step: 5
Training loss: 2.220806837081909
Validation loss: 2.159997800985972

Epoch: 6| Step: 6
Training loss: 1.5954598188400269
Validation loss: 2.182117740313212

Epoch: 6| Step: 7
Training loss: 2.360018491744995
Validation loss: 2.1612170537312827

Epoch: 6| Step: 8
Training loss: 1.3904788494110107
Validation loss: 2.1873897314071655

Epoch: 6| Step: 9
Training loss: 1.673905372619629
Validation loss: 2.1763070027033486

Epoch: 6| Step: 10
Training loss: 2.392263650894165
Validation loss: 2.1802732348442078

Epoch: 6| Step: 11
Training loss: 1.8511228561401367
Validation loss: 2.187044600645701

Epoch: 6| Step: 12
Training loss: 2.3259265422821045
Validation loss: 2.1693707505861917

Epoch: 6| Step: 13
Training loss: 1.5321801900863647
Validation loss: 2.188254654407501

Epoch: 216| Step: 0
Training loss: 2.031573534011841
Validation loss: 2.179960290590922

Epoch: 6| Step: 1
Training loss: 1.6867872476577759
Validation loss: 2.1912981271743774

Epoch: 6| Step: 2
Training loss: 2.0621862411499023
Validation loss: 2.1854960918426514

Epoch: 6| Step: 3
Training loss: 1.697676420211792
Validation loss: 2.1891905864079795

Epoch: 6| Step: 4
Training loss: 1.8420991897583008
Validation loss: 2.178820272286733

Epoch: 6| Step: 5
Training loss: 1.4994865655899048
Validation loss: 2.187835156917572

Epoch: 6| Step: 6
Training loss: 1.8610279560089111
Validation loss: 2.1900826891263327

Epoch: 6| Step: 7
Training loss: 1.9577115774154663
Validation loss: 2.1652468840281167

Epoch: 6| Step: 8
Training loss: 2.293455123901367
Validation loss: 2.1707759896914163

Epoch: 6| Step: 9
Training loss: 1.7107250690460205
Validation loss: 2.1631816228230796

Epoch: 6| Step: 10
Training loss: 1.8199741840362549
Validation loss: 2.172977944215139

Epoch: 6| Step: 11
Training loss: 1.8985472917556763
Validation loss: 2.1590001583099365

Epoch: 6| Step: 12
Training loss: 1.7748997211456299
Validation loss: 2.159098426500956

Epoch: 6| Step: 13
Training loss: 2.2549071311950684
Validation loss: 2.1831012765566506

Epoch: 217| Step: 0
Training loss: 1.6889081001281738
Validation loss: 2.179024815559387

Epoch: 6| Step: 1
Training loss: 1.789245367050171
Validation loss: 2.1723795930544534

Epoch: 6| Step: 2
Training loss: 1.9507689476013184
Validation loss: 2.1591811577479043

Epoch: 6| Step: 3
Training loss: 2.310837745666504
Validation loss: 2.1681528091430664

Epoch: 6| Step: 4
Training loss: 1.7691487073898315
Validation loss: 2.174115081628164

Epoch: 6| Step: 5
Training loss: 2.269379138946533
Validation loss: 2.167289157708486

Epoch: 6| Step: 6
Training loss: 1.7495077848434448
Validation loss: 2.1711828112602234

Epoch: 6| Step: 7
Training loss: 1.6529070138931274
Validation loss: 2.154942055543264

Epoch: 6| Step: 8
Training loss: 1.8286826610565186
Validation loss: 2.1689857045809426

Epoch: 6| Step: 9
Training loss: 1.9777172803878784
Validation loss: 2.1690714160601297

Epoch: 6| Step: 10
Training loss: 1.6668795347213745
Validation loss: 2.182535449663798

Epoch: 6| Step: 11
Training loss: 2.0957324504852295
Validation loss: 2.1809480587641397

Epoch: 6| Step: 12
Training loss: 2.2977259159088135
Validation loss: 2.1832072734832764

Epoch: 6| Step: 13
Training loss: 1.3509405851364136
Validation loss: 2.186600903669993

Epoch: 218| Step: 0
Training loss: 2.039680004119873
Validation loss: 2.219481945037842

Epoch: 6| Step: 1
Training loss: 1.6264818906784058
Validation loss: 2.1884920398394265

Epoch: 6| Step: 2
Training loss: 1.4714373350143433
Validation loss: 2.202165146668752

Epoch: 6| Step: 3
Training loss: 2.0546207427978516
Validation loss: 2.2030638655026755

Epoch: 6| Step: 4
Training loss: 2.166515350341797
Validation loss: 2.218215982119242

Epoch: 6| Step: 5
Training loss: 1.1962103843688965
Validation loss: 2.2171442906061807

Epoch: 6| Step: 6
Training loss: 1.8633010387420654
Validation loss: 2.2041229009628296

Epoch: 6| Step: 7
Training loss: 2.020219326019287
Validation loss: 2.215417802333832

Epoch: 6| Step: 8
Training loss: 1.8212436437606812
Validation loss: 2.20276540517807

Epoch: 6| Step: 9
Training loss: 2.222722053527832
Validation loss: 2.226600190003713

Epoch: 6| Step: 10
Training loss: 1.871324062347412
Validation loss: 2.191925843556722

Epoch: 6| Step: 11
Training loss: 1.860411286354065
Validation loss: 2.2014827728271484

Epoch: 6| Step: 12
Training loss: 1.9808728694915771
Validation loss: 2.212005058924357

Epoch: 6| Step: 13
Training loss: 2.256152629852295
Validation loss: 2.205922702948252

Epoch: 219| Step: 0
Training loss: 1.9332871437072754
Validation loss: 2.195267995198568

Epoch: 6| Step: 1
Training loss: 1.2254371643066406
Validation loss: 2.1888805429140725

Epoch: 6| Step: 2
Training loss: 1.6956743001937866
Validation loss: 2.17976576089859

Epoch: 6| Step: 3
Training loss: 1.96351158618927
Validation loss: 2.1960864265759787

Epoch: 6| Step: 4
Training loss: 1.7378944158554077
Validation loss: 2.1971911589304605

Epoch: 6| Step: 5
Training loss: 2.0741372108459473
Validation loss: 2.1986664533615112

Epoch: 6| Step: 6
Training loss: 1.7300536632537842
Validation loss: 2.211516519387563

Epoch: 6| Step: 7
Training loss: 2.2805867195129395
Validation loss: 2.1816216707229614

Epoch: 6| Step: 8
Training loss: 1.815869927406311
Validation loss: 2.1990063389142356

Epoch: 6| Step: 9
Training loss: 1.5452431440353394
Validation loss: 2.2214252750078836

Epoch: 6| Step: 10
Training loss: 2.209779977798462
Validation loss: 2.169437805811564

Epoch: 6| Step: 11
Training loss: 2.1000208854675293
Validation loss: 2.2026658256848655

Epoch: 6| Step: 12
Training loss: 1.9823980331420898
Validation loss: 2.175075868765513

Epoch: 6| Step: 13
Training loss: 2.4453985691070557
Validation loss: 2.1776999036471048

Epoch: 220| Step: 0
Training loss: 1.381331205368042
Validation loss: 2.1640236377716064

Epoch: 6| Step: 1
Training loss: 2.0226492881774902
Validation loss: 2.1694766680399575

Epoch: 6| Step: 2
Training loss: 1.6338146924972534
Validation loss: 2.167202035586039

Epoch: 6| Step: 3
Training loss: 2.2675387859344482
Validation loss: 2.1720088521639505

Epoch: 6| Step: 4
Training loss: 1.5568510293960571
Validation loss: 2.1791664958000183

Epoch: 6| Step: 5
Training loss: 1.4729702472686768
Validation loss: 2.1694032549858093

Epoch: 6| Step: 6
Training loss: 1.567021369934082
Validation loss: 2.1851354837417603

Epoch: 6| Step: 7
Training loss: 2.1651389598846436
Validation loss: 2.19025989373525

Epoch: 6| Step: 8
Training loss: 2.3998396396636963
Validation loss: 2.1904272039731345

Epoch: 6| Step: 9
Training loss: 1.682494878768921
Validation loss: 2.174053947130839

Epoch: 6| Step: 10
Training loss: 2.1212172508239746
Validation loss: 2.1951820453008017

Epoch: 6| Step: 11
Training loss: 2.5231053829193115
Validation loss: 2.182723561922709

Epoch: 6| Step: 12
Training loss: 2.200604200363159
Validation loss: 2.1780421336491904

Epoch: 6| Step: 13
Training loss: 1.7224117517471313
Validation loss: 2.151096741358439

Epoch: 221| Step: 0
Training loss: 2.5128793716430664
Validation loss: 2.1528106530507407

Epoch: 6| Step: 1
Training loss: 2.017157554626465
Validation loss: 2.1464062333106995

Epoch: 6| Step: 2
Training loss: 1.5284925699234009
Validation loss: 2.1648278633753457

Epoch: 6| Step: 3
Training loss: 1.7798840999603271
Validation loss: 2.1631609996159873

Epoch: 6| Step: 4
Training loss: 2.1810436248779297
Validation loss: 2.1620635390281677

Epoch: 6| Step: 5
Training loss: 1.7890169620513916
Validation loss: 2.165933589140574

Epoch: 6| Step: 6
Training loss: 1.538670539855957
Validation loss: 2.175216019153595

Epoch: 6| Step: 7
Training loss: 1.8143839836120605
Validation loss: 2.1882503032684326

Epoch: 6| Step: 8
Training loss: 2.451725959777832
Validation loss: 2.1662327448527017

Epoch: 6| Step: 9
Training loss: 1.4003430604934692
Validation loss: 2.182610015074412

Epoch: 6| Step: 10
Training loss: 1.6587342023849487
Validation loss: 2.176600476106008

Epoch: 6| Step: 11
Training loss: 1.701368808746338
Validation loss: 2.18695459763209

Epoch: 6| Step: 12
Training loss: 2.1599838733673096
Validation loss: 2.196716864903768

Epoch: 6| Step: 13
Training loss: 1.830993413925171
Validation loss: 2.189002275466919

Epoch: 222| Step: 0
Training loss: 2.0995984077453613
Validation loss: 2.1894500652949014

Epoch: 6| Step: 1
Training loss: 2.7999629974365234
Validation loss: 2.1765143275260925

Epoch: 6| Step: 2
Training loss: 1.5690171718597412
Validation loss: 2.1811719139417014

Epoch: 6| Step: 3
Training loss: 2.2519733905792236
Validation loss: 2.194531281789144

Epoch: 6| Step: 4
Training loss: 1.5872950553894043
Validation loss: 2.176942825317383

Epoch: 6| Step: 5
Training loss: 1.4908217191696167
Validation loss: 2.193617343902588

Epoch: 6| Step: 6
Training loss: 1.5381386280059814
Validation loss: 2.192380964756012

Epoch: 6| Step: 7
Training loss: 1.8244906663894653
Validation loss: 2.1979331175486245

Epoch: 6| Step: 8
Training loss: 1.6864519119262695
Validation loss: 2.186959763367971

Epoch: 6| Step: 9
Training loss: 1.431786060333252
Validation loss: 2.1818626324335733

Epoch: 6| Step: 10
Training loss: 1.4291553497314453
Validation loss: 2.184614916642507

Epoch: 6| Step: 11
Training loss: 2.345694065093994
Validation loss: 2.1884200970331826

Epoch: 6| Step: 12
Training loss: 2.210822105407715
Validation loss: 2.183160940806071

Epoch: 6| Step: 13
Training loss: 1.8067339658737183
Validation loss: 2.1933095852533975

Epoch: 223| Step: 0
Training loss: 1.8528707027435303
Validation loss: 2.189044018586477

Epoch: 6| Step: 1
Training loss: 2.5868356227874756
Validation loss: 2.20798929532369

Epoch: 6| Step: 2
Training loss: 1.6865285634994507
Validation loss: 2.1865557034810386

Epoch: 6| Step: 3
Training loss: 2.02040958404541
Validation loss: 2.19450048605601

Epoch: 6| Step: 4
Training loss: 2.2186012268066406
Validation loss: 2.1827577352523804

Epoch: 6| Step: 5
Training loss: 2.1827292442321777
Validation loss: 2.1990281144777932

Epoch: 6| Step: 6
Training loss: 1.5285887718200684
Validation loss: 2.179665764172872

Epoch: 6| Step: 7
Training loss: 1.6679091453552246
Validation loss: 2.17175684372584

Epoch: 6| Step: 8
Training loss: 1.242013931274414
Validation loss: 2.1768497029940286

Epoch: 6| Step: 9
Training loss: 1.93712317943573
Validation loss: 2.1674389640490213

Epoch: 6| Step: 10
Training loss: 2.267714500427246
Validation loss: 2.1618513266245523

Epoch: 6| Step: 11
Training loss: 1.6131353378295898
Validation loss: 2.1930586099624634

Epoch: 6| Step: 12
Training loss: 1.5618579387664795
Validation loss: 2.2063074111938477

Epoch: 6| Step: 13
Training loss: 2.12363600730896
Validation loss: 2.2088027596473694

Epoch: 224| Step: 0
Training loss: 1.99674654006958
Validation loss: 2.2043989499409995

Epoch: 6| Step: 1
Training loss: 1.9553163051605225
Validation loss: 2.202002704143524

Epoch: 6| Step: 2
Training loss: 1.8259730339050293
Validation loss: 2.229421635468801

Epoch: 6| Step: 3
Training loss: 1.9040827751159668
Validation loss: 2.2271029551823935

Epoch: 6| Step: 4
Training loss: 1.9492721557617188
Validation loss: 2.2021491328875222

Epoch: 6| Step: 5
Training loss: 1.5860495567321777
Validation loss: 2.2021074692408242

Epoch: 6| Step: 6
Training loss: 1.2338489294052124
Validation loss: 2.193345069885254

Epoch: 6| Step: 7
Training loss: 2.2290899753570557
Validation loss: 2.2047146757443747

Epoch: 6| Step: 8
Training loss: 1.562704086303711
Validation loss: 2.1980963349342346

Epoch: 6| Step: 9
Training loss: 2.3279314041137695
Validation loss: 2.194301664829254

Epoch: 6| Step: 10
Training loss: 2.260937452316284
Validation loss: 2.199501713116964

Epoch: 6| Step: 11
Training loss: 2.032399892807007
Validation loss: 2.198174158732096

Epoch: 6| Step: 12
Training loss: 1.9258227348327637
Validation loss: 2.193585991859436

Epoch: 6| Step: 13
Training loss: 1.7001285552978516
Validation loss: 2.2070589462916055

Epoch: 225| Step: 0
Training loss: 1.662171483039856
Validation loss: 2.2013673782348633

Epoch: 6| Step: 1
Training loss: 2.5155720710754395
Validation loss: 2.2044256925582886

Epoch: 6| Step: 2
Training loss: 1.877894401550293
Validation loss: 2.205139636993408

Epoch: 6| Step: 3
Training loss: 2.574202537536621
Validation loss: 2.21273402372996

Epoch: 6| Step: 4
Training loss: 1.4713696241378784
Validation loss: 2.203472097714742

Epoch: 6| Step: 5
Training loss: 2.1093950271606445
Validation loss: 2.196845531463623

Epoch: 6| Step: 6
Training loss: 1.4320836067199707
Validation loss: 2.205407460530599

Epoch: 6| Step: 7
Training loss: 2.1410369873046875
Validation loss: 2.2022547125816345

Epoch: 6| Step: 8
Training loss: 2.1308579444885254
Validation loss: 2.199928124745687

Epoch: 6| Step: 9
Training loss: 1.9153846502304077
Validation loss: 2.2067312002182007

Epoch: 6| Step: 10
Training loss: 1.4402540922164917
Validation loss: 2.2136528889338174

Epoch: 6| Step: 11
Training loss: 1.641535758972168
Validation loss: 2.1994815866152444

Epoch: 6| Step: 12
Training loss: 2.036275863647461
Validation loss: 2.196811079978943

Epoch: 6| Step: 13
Training loss: 1.365149736404419
Validation loss: 2.186841865380605

Epoch: 226| Step: 0
Training loss: 1.3541948795318604
Validation loss: 2.215142627557119

Epoch: 6| Step: 1
Training loss: 1.7829244136810303
Validation loss: 2.2088362773259482

Epoch: 6| Step: 2
Training loss: 1.130176067352295
Validation loss: 2.1939179499944053

Epoch: 6| Step: 3
Training loss: 1.589876651763916
Validation loss: 2.204183797041575

Epoch: 6| Step: 4
Training loss: 1.691518783569336
Validation loss: 2.172279953956604

Epoch: 6| Step: 5
Training loss: 1.5694477558135986
Validation loss: 2.201512575149536

Epoch: 6| Step: 6
Training loss: 1.8026249408721924
Validation loss: 2.198454717795054

Epoch: 6| Step: 7
Training loss: 1.9330940246582031
Validation loss: 2.201143980026245

Epoch: 6| Step: 8
Training loss: 2.231393575668335
Validation loss: 2.229300936063131

Epoch: 6| Step: 9
Training loss: 1.5590920448303223
Validation loss: 2.2060462832450867

Epoch: 6| Step: 10
Training loss: 2.368250846862793
Validation loss: 2.2315869331359863

Epoch: 6| Step: 11
Training loss: 2.5979552268981934
Validation loss: 2.2100051840146384

Epoch: 6| Step: 12
Training loss: 2.184814453125
Validation loss: 2.22695392370224

Epoch: 6| Step: 13
Training loss: 1.9851906299591064
Validation loss: 2.228714644908905

Epoch: 227| Step: 0
Training loss: 1.2187821865081787
Validation loss: 2.2472127079963684

Epoch: 6| Step: 1
Training loss: 2.0680835247039795
Validation loss: 2.2199345032374063

Epoch: 6| Step: 2
Training loss: 1.4931073188781738
Validation loss: 2.2205917040506997

Epoch: 6| Step: 3
Training loss: 1.299962043762207
Validation loss: 2.2504799167315164

Epoch: 6| Step: 4
Training loss: 2.0159502029418945
Validation loss: 2.2329125006993613

Epoch: 6| Step: 5
Training loss: 1.527522325515747
Validation loss: 2.2014384865760803

Epoch: 6| Step: 6
Training loss: 2.2220234870910645
Validation loss: 2.207296133041382

Epoch: 6| Step: 7
Training loss: 1.2591450214385986
Validation loss: 2.197912057240804

Epoch: 6| Step: 8
Training loss: 2.0781426429748535
Validation loss: 2.183543562889099

Epoch: 6| Step: 9
Training loss: 2.813171863555908
Validation loss: 2.1772515376408896

Epoch: 6| Step: 10
Training loss: 2.369105339050293
Validation loss: 2.166936536629995

Epoch: 6| Step: 11
Training loss: 1.8744860887527466
Validation loss: 2.1768741408983865

Epoch: 6| Step: 12
Training loss: 2.832376003265381
Validation loss: 2.188174764315287

Epoch: 6| Step: 13
Training loss: 1.4704127311706543
Validation loss: 2.1851513783137

Epoch: 228| Step: 0
Training loss: 1.9881908893585205
Validation loss: 2.182871321837107

Epoch: 6| Step: 1
Training loss: 1.7602052688598633
Validation loss: 2.1828317443529763

Epoch: 6| Step: 2
Training loss: 2.1681339740753174
Validation loss: 2.200217147668203

Epoch: 6| Step: 3
Training loss: 1.5358306169509888
Validation loss: 2.1926923791567483

Epoch: 6| Step: 4
Training loss: 2.0354676246643066
Validation loss: 2.2165727814038596

Epoch: 6| Step: 5
Training loss: 1.5976645946502686
Validation loss: 2.2231720089912415

Epoch: 6| Step: 6
Training loss: 1.3583786487579346
Validation loss: 2.2300265630086265

Epoch: 6| Step: 7
Training loss: 2.3336734771728516
Validation loss: 2.227857987085978

Epoch: 6| Step: 8
Training loss: 1.5490050315856934
Validation loss: 2.2364012598991394

Epoch: 6| Step: 9
Training loss: 1.5786467790603638
Validation loss: 2.2386214335759482

Epoch: 6| Step: 10
Training loss: 2.632997751235962
Validation loss: 2.222507059574127

Epoch: 6| Step: 11
Training loss: 1.3859834671020508
Validation loss: 2.227235972881317

Epoch: 6| Step: 12
Training loss: 2.3270349502563477
Validation loss: 2.230754872163137

Epoch: 6| Step: 13
Training loss: 2.125023603439331
Validation loss: 2.2080816626548767

Epoch: 229| Step: 0
Training loss: 1.5621442794799805
Validation loss: 2.215580463409424

Epoch: 6| Step: 1
Training loss: 1.7233835458755493
Validation loss: 2.203607439994812

Epoch: 6| Step: 2
Training loss: 1.56553316116333
Validation loss: 2.22659440835317

Epoch: 6| Step: 3
Training loss: 2.802772045135498
Validation loss: 2.1905502676963806

Epoch: 6| Step: 4
Training loss: 1.5689001083374023
Validation loss: 2.19558314482371

Epoch: 6| Step: 5
Training loss: 1.7659810781478882
Validation loss: 2.2074734965960183

Epoch: 6| Step: 6
Training loss: 1.3480286598205566
Validation loss: 2.206397533416748

Epoch: 6| Step: 7
Training loss: 2.3167481422424316
Validation loss: 2.2170586585998535

Epoch: 6| Step: 8
Training loss: 2.3318653106689453
Validation loss: 2.2035569548606873

Epoch: 6| Step: 9
Training loss: 2.2893505096435547
Validation loss: 2.2060396671295166

Epoch: 6| Step: 10
Training loss: 1.687925934791565
Validation loss: 2.2217499812444053

Epoch: 6| Step: 11
Training loss: 1.651444435119629
Validation loss: 2.204451402028402

Epoch: 6| Step: 12
Training loss: 1.6566457748413086
Validation loss: 2.2048721512158713

Epoch: 6| Step: 13
Training loss: 1.8839902877807617
Validation loss: 2.2167773246765137

Epoch: 230| Step: 0
Training loss: 1.7519969940185547
Validation loss: 2.1944783329963684

Epoch: 6| Step: 1
Training loss: 2.2523269653320312
Validation loss: 2.210554758707682

Epoch: 6| Step: 2
Training loss: 1.707120656967163
Validation loss: 2.1984769105911255

Epoch: 6| Step: 3
Training loss: 1.9621949195861816
Validation loss: 2.198833247025808

Epoch: 6| Step: 4
Training loss: 1.9511957168579102
Validation loss: 2.205405116081238

Epoch: 6| Step: 5
Training loss: 1.697077751159668
Validation loss: 2.186482866605123

Epoch: 6| Step: 6
Training loss: 1.7525062561035156
Validation loss: 2.178967297077179

Epoch: 6| Step: 7
Training loss: 1.3672834634780884
Validation loss: 2.198100487391154

Epoch: 6| Step: 8
Training loss: 1.3778598308563232
Validation loss: 2.178264598051707

Epoch: 6| Step: 9
Training loss: 1.7719261646270752
Validation loss: 2.1820881565411887

Epoch: 6| Step: 10
Training loss: 2.047325849533081
Validation loss: 2.172108550866445

Epoch: 6| Step: 11
Training loss: 2.331925392150879
Validation loss: 2.1505490938822427

Epoch: 6| Step: 12
Training loss: 2.0774624347686768
Validation loss: 2.1743063926696777

Epoch: 6| Step: 13
Training loss: 2.370924949645996
Validation loss: 2.1855008006095886

Epoch: 231| Step: 0
Training loss: 2.746255397796631
Validation loss: 2.1825706164042153

Epoch: 6| Step: 1
Training loss: 2.364051103591919
Validation loss: 2.1782963275909424

Epoch: 6| Step: 2
Training loss: 1.8139517307281494
Validation loss: 2.1805981000264487

Epoch: 6| Step: 3
Training loss: 1.9387030601501465
Validation loss: 2.196997026602427

Epoch: 6| Step: 4
Training loss: 1.4059228897094727
Validation loss: 2.213488499323527

Epoch: 6| Step: 5
Training loss: 2.0731143951416016
Validation loss: 2.2181063095728555

Epoch: 6| Step: 6
Training loss: 1.652674674987793
Validation loss: 2.200879236062368

Epoch: 6| Step: 7
Training loss: 1.7891826629638672
Validation loss: 2.212404489517212

Epoch: 6| Step: 8
Training loss: 2.353684186935425
Validation loss: 2.208033720652262

Epoch: 6| Step: 9
Training loss: 1.8705703020095825
Validation loss: 2.196236232916514

Epoch: 6| Step: 10
Training loss: 1.9578642845153809
Validation loss: 2.2210573554039

Epoch: 6| Step: 11
Training loss: 1.3949832916259766
Validation loss: 2.219739476839701

Epoch: 6| Step: 12
Training loss: 1.489168405532837
Validation loss: 2.189227819442749

Epoch: 6| Step: 13
Training loss: 1.2515196800231934
Validation loss: 2.2029912869135537

Epoch: 232| Step: 0
Training loss: 1.4754889011383057
Validation loss: 2.200304090976715

Epoch: 6| Step: 1
Training loss: 1.8684931993484497
Validation loss: 2.201381802558899

Epoch: 6| Step: 2
Training loss: 2.2523927688598633
Validation loss: 2.209330360094706

Epoch: 6| Step: 3
Training loss: 2.0934946537017822
Validation loss: 2.1979492704073587

Epoch: 6| Step: 4
Training loss: 2.0386271476745605
Validation loss: 2.2085399627685547

Epoch: 6| Step: 5
Training loss: 1.4221727848052979
Validation loss: 2.2058387994766235

Epoch: 6| Step: 6
Training loss: 2.2173831462860107
Validation loss: 2.1956891218821206

Epoch: 6| Step: 7
Training loss: 1.9826992750167847
Validation loss: 2.205993930498759

Epoch: 6| Step: 8
Training loss: 1.536044716835022
Validation loss: 2.209458867708842

Epoch: 6| Step: 9
Training loss: 1.3415310382843018
Validation loss: 2.224159916241964

Epoch: 6| Step: 10
Training loss: 2.208892822265625
Validation loss: 2.228206435839335

Epoch: 6| Step: 11
Training loss: 1.8652534484863281
Validation loss: 2.219663759072622

Epoch: 6| Step: 12
Training loss: 1.9098892211914062
Validation loss: 2.236581007639567

Epoch: 6| Step: 13
Training loss: 1.5918830633163452
Validation loss: 2.2235220670700073

Epoch: 233| Step: 0
Training loss: 2.074208974838257
Validation loss: 2.2316165765126548

Epoch: 6| Step: 1
Training loss: 2.3282570838928223
Validation loss: 2.23254386583964

Epoch: 6| Step: 2
Training loss: 1.407688021659851
Validation loss: 2.214042524496714

Epoch: 6| Step: 3
Training loss: 2.1867098808288574
Validation loss: 2.2136754592259726

Epoch: 6| Step: 4
Training loss: 2.4189834594726562
Validation loss: 2.218057374159495

Epoch: 6| Step: 5
Training loss: 1.6165556907653809
Validation loss: 2.229819337526957

Epoch: 6| Step: 6
Training loss: 1.6034667491912842
Validation loss: 2.225858529408773

Epoch: 6| Step: 7
Training loss: 1.4066754579544067
Validation loss: 2.2099832892417908

Epoch: 6| Step: 8
Training loss: 1.9699965715408325
Validation loss: 2.2357155879338584

Epoch: 6| Step: 9
Training loss: 1.76931893825531
Validation loss: 2.2351608673731485

Epoch: 6| Step: 10
Training loss: 1.624299168586731
Validation loss: 2.218955338001251

Epoch: 6| Step: 11
Training loss: 1.4718830585479736
Validation loss: 2.2152060866355896

Epoch: 6| Step: 12
Training loss: 1.7718093395233154
Validation loss: 2.2267064452171326

Epoch: 6| Step: 13
Training loss: 2.1996777057647705
Validation loss: 2.229803721110026

Epoch: 234| Step: 0
Training loss: 1.887624979019165
Validation loss: 2.211961507797241

Epoch: 6| Step: 1
Training loss: 1.231378197669983
Validation loss: 2.222888191541036

Epoch: 6| Step: 2
Training loss: 1.9334931373596191
Validation loss: 2.2267653544743857

Epoch: 6| Step: 3
Training loss: 1.1672348976135254
Validation loss: 2.1908417542775473

Epoch: 6| Step: 4
Training loss: 2.588728904724121
Validation loss: 2.2111579179763794

Epoch: 6| Step: 5
Training loss: 1.9967496395111084
Validation loss: 2.2305256128311157

Epoch: 6| Step: 6
Training loss: 1.930550456047058
Validation loss: 2.198454737663269

Epoch: 6| Step: 7
Training loss: 1.7868499755859375
Validation loss: 2.193637430667877

Epoch: 6| Step: 8
Training loss: 1.5907777547836304
Validation loss: 2.2157256404558816

Epoch: 6| Step: 9
Training loss: 2.19566011428833
Validation loss: 2.209646999835968

Epoch: 6| Step: 10
Training loss: 1.959949254989624
Validation loss: 2.2015233039855957

Epoch: 6| Step: 11
Training loss: 1.9670125246047974
Validation loss: 2.2109714349110923

Epoch: 6| Step: 12
Training loss: 1.4507052898406982
Validation loss: 2.2029024958610535

Epoch: 6| Step: 13
Training loss: 2.231935739517212
Validation loss: 2.2101482152938843

Epoch: 235| Step: 0
Training loss: 2.539968252182007
Validation loss: 2.2133193413416543

Epoch: 6| Step: 1
Training loss: 1.7753583192825317
Validation loss: 2.203217566013336

Epoch: 6| Step: 2
Training loss: 1.642197608947754
Validation loss: 2.2137174805005393

Epoch: 6| Step: 3
Training loss: 2.0885238647460938
Validation loss: 2.211873392264048

Epoch: 6| Step: 4
Training loss: 1.9471040964126587
Validation loss: 2.2120796044667563

Epoch: 6| Step: 5
Training loss: 1.7618471384048462
Validation loss: 2.23816841840744

Epoch: 6| Step: 6
Training loss: 1.7831807136535645
Validation loss: 2.2512123584747314

Epoch: 6| Step: 7
Training loss: 1.9310548305511475
Validation loss: 2.2320862809816995

Epoch: 6| Step: 8
Training loss: 1.8432387113571167
Validation loss: 2.252790927886963

Epoch: 6| Step: 9
Training loss: 1.9396514892578125
Validation loss: 2.2345499197642007

Epoch: 6| Step: 10
Training loss: 1.9210572242736816
Validation loss: 2.2395837704340615

Epoch: 6| Step: 11
Training loss: 1.9070707559585571
Validation loss: 2.2382957140604653

Epoch: 6| Step: 12
Training loss: 1.3060306310653687
Validation loss: 2.2348750233650208

Epoch: 6| Step: 13
Training loss: 2.109477996826172
Validation loss: 2.217401067415873

Epoch: 236| Step: 0
Training loss: 2.083995819091797
Validation loss: 2.206038514773051

Epoch: 6| Step: 1
Training loss: 1.9917587041854858
Validation loss: 2.180511752764384

Epoch: 6| Step: 2
Training loss: 1.7224392890930176
Validation loss: 2.162968337535858

Epoch: 6| Step: 3
Training loss: 2.5151655673980713
Validation loss: 2.166330575942993

Epoch: 6| Step: 4
Training loss: 1.830316424369812
Validation loss: 2.1759660045305886

Epoch: 6| Step: 5
Training loss: 1.8624954223632812
Validation loss: 2.1655391454696655

Epoch: 6| Step: 6
Training loss: 2.3128085136413574
Validation loss: 2.1566660404205322

Epoch: 6| Step: 7
Training loss: 1.8907995223999023
Validation loss: 2.1786526640256247

Epoch: 6| Step: 8
Training loss: 1.6814311742782593
Validation loss: 2.1856887340545654

Epoch: 6| Step: 9
Training loss: 1.7626678943634033
Validation loss: 2.197323461373647

Epoch: 6| Step: 10
Training loss: 2.092283010482788
Validation loss: 2.1967295010884604

Epoch: 6| Step: 11
Training loss: 1.229760766029358
Validation loss: 2.2173421382904053

Epoch: 6| Step: 12
Training loss: 1.5170583724975586
Validation loss: 2.243081192175547

Epoch: 6| Step: 13
Training loss: 2.236560583114624
Validation loss: 2.241441229979197

Epoch: 237| Step: 0
Training loss: 1.9516992568969727
Validation loss: 2.2520673274993896

Epoch: 6| Step: 1
Training loss: 2.226588249206543
Validation loss: 2.2362441619237265

Epoch: 6| Step: 2
Training loss: 1.779585599899292
Validation loss: 2.2635051012039185

Epoch: 6| Step: 3
Training loss: 1.9088438749313354
Validation loss: 2.2632827758789062

Epoch: 6| Step: 4
Training loss: 2.3636128902435303
Validation loss: 2.2391080061594644

Epoch: 6| Step: 5
Training loss: 1.9212710857391357
Validation loss: 2.213590085506439

Epoch: 6| Step: 6
Training loss: 1.9475622177124023
Validation loss: 2.245653748512268

Epoch: 6| Step: 7
Training loss: 1.5452101230621338
Validation loss: 2.2266933719317117

Epoch: 6| Step: 8
Training loss: 1.879596471786499
Validation loss: 2.2203867038091025

Epoch: 6| Step: 9
Training loss: 1.1247354745864868
Validation loss: 2.2036114732424417

Epoch: 6| Step: 10
Training loss: 1.9671661853790283
Validation loss: 2.2059850494066873

Epoch: 6| Step: 11
Training loss: 1.3607701063156128
Validation loss: 2.214244325955709

Epoch: 6| Step: 12
Training loss: 2.491637945175171
Validation loss: 2.200876692930857

Epoch: 6| Step: 13
Training loss: 1.6860780715942383
Validation loss: 2.2031770944595337

Epoch: 238| Step: 0
Training loss: 1.62699294090271
Validation loss: 2.2162532806396484

Epoch: 6| Step: 1
Training loss: 1.8259806632995605
Validation loss: 2.1986491878827414

Epoch: 6| Step: 2
Training loss: 1.5714175701141357
Validation loss: 2.2121451695760093

Epoch: 6| Step: 3
Training loss: 1.4297840595245361
Validation loss: 2.2043853600819907

Epoch: 6| Step: 4
Training loss: 1.9951813220977783
Validation loss: 2.2247213323911033

Epoch: 6| Step: 5
Training loss: 2.1094043254852295
Validation loss: 2.2245877583821616

Epoch: 6| Step: 6
Training loss: 0.8120000958442688
Validation loss: 2.239823659261068

Epoch: 6| Step: 7
Training loss: 2.531555652618408
Validation loss: 2.2347381512324014

Epoch: 6| Step: 8
Training loss: 2.047677755355835
Validation loss: 2.2280373175938926

Epoch: 6| Step: 9
Training loss: 1.7084300518035889
Validation loss: 2.2321930527687073

Epoch: 6| Step: 10
Training loss: 1.8452181816101074
Validation loss: 2.2388661901156106

Epoch: 6| Step: 11
Training loss: 1.9062565565109253
Validation loss: 2.211100935935974

Epoch: 6| Step: 12
Training loss: 2.1693356037139893
Validation loss: 2.234222153822581

Epoch: 6| Step: 13
Training loss: 2.3557794094085693
Validation loss: 2.200591742992401

Epoch: 239| Step: 0
Training loss: 1.435235857963562
Validation loss: 2.2053433656692505

Epoch: 6| Step: 1
Training loss: 1.7459585666656494
Validation loss: 2.212436298529307

Epoch: 6| Step: 2
Training loss: 2.0024642944335938
Validation loss: 2.1960927645365396

Epoch: 6| Step: 3
Training loss: 2.3390893936157227
Validation loss: 2.210164427757263

Epoch: 6| Step: 4
Training loss: 2.1425704956054688
Validation loss: 2.2220744689305625

Epoch: 6| Step: 5
Training loss: 1.9482471942901611
Validation loss: 2.2055940429369607

Epoch: 6| Step: 6
Training loss: 2.159759521484375
Validation loss: 2.218073864777883

Epoch: 6| Step: 7
Training loss: 1.9086352586746216
Validation loss: 2.2441415588061013

Epoch: 6| Step: 8
Training loss: 1.419196605682373
Validation loss: 2.209567666053772

Epoch: 6| Step: 9
Training loss: 1.523141622543335
Validation loss: 2.2246404886245728

Epoch: 6| Step: 10
Training loss: 1.5475096702575684
Validation loss: 2.235029478867849

Epoch: 6| Step: 11
Training loss: 1.9773736000061035
Validation loss: 2.207409918308258

Epoch: 6| Step: 12
Training loss: 1.4299051761627197
Validation loss: 2.2211679220199585

Epoch: 6| Step: 13
Training loss: 2.4714369773864746
Validation loss: 2.2038875222206116

Epoch: 240| Step: 0
Training loss: 2.10056734085083
Validation loss: 2.217197378476461

Epoch: 6| Step: 1
Training loss: 1.8700456619262695
Validation loss: 2.214206119378408

Epoch: 6| Step: 2
Training loss: 1.7877678871154785
Validation loss: 2.205545802911123

Epoch: 6| Step: 3
Training loss: 1.7471752166748047
Validation loss: 2.191039502620697

Epoch: 6| Step: 4
Training loss: 2.0193581581115723
Validation loss: 2.2150519688924155

Epoch: 6| Step: 5
Training loss: 1.3185193538665771
Validation loss: 2.207083523273468

Epoch: 6| Step: 6
Training loss: 1.5070470571517944
Validation loss: 2.201818287372589

Epoch: 6| Step: 7
Training loss: 2.231675624847412
Validation loss: 2.2224687933921814

Epoch: 6| Step: 8
Training loss: 2.0471553802490234
Validation loss: 2.2389057675997415

Epoch: 6| Step: 9
Training loss: 1.5527243614196777
Validation loss: 2.210018197695414

Epoch: 6| Step: 10
Training loss: 2.553922653198242
Validation loss: 2.2233792543411255

Epoch: 6| Step: 11
Training loss: 1.7528929710388184
Validation loss: 2.2110379934310913

Epoch: 6| Step: 12
Training loss: 1.860999345779419
Validation loss: 2.2482478419939675

Epoch: 6| Step: 13
Training loss: 1.5316671133041382
Validation loss: 2.2405265967051187

Epoch: 241| Step: 0
Training loss: 1.8050591945648193
Validation loss: 2.253315806388855

Epoch: 6| Step: 1
Training loss: 2.1380512714385986
Validation loss: 2.218015114466349

Epoch: 6| Step: 2
Training loss: 1.5308912992477417
Validation loss: 2.2385016282399497

Epoch: 6| Step: 3
Training loss: 1.8171756267547607
Validation loss: 2.2373942931493125

Epoch: 6| Step: 4
Training loss: 2.2993621826171875
Validation loss: 2.2364817460378013

Epoch: 6| Step: 5
Training loss: 1.7606761455535889
Validation loss: 2.224072198073069

Epoch: 6| Step: 6
Training loss: 1.8911561965942383
Validation loss: 2.2527767022450766

Epoch: 6| Step: 7
Training loss: 2.2674357891082764
Validation loss: 2.2109410166740417

Epoch: 6| Step: 8
Training loss: 1.9213160276412964
Validation loss: 2.211349825064341

Epoch: 6| Step: 9
Training loss: 1.5744489431381226
Validation loss: 2.185938080151876

Epoch: 6| Step: 10
Training loss: 1.7935941219329834
Validation loss: 2.1752031644185386

Epoch: 6| Step: 11
Training loss: 2.281806230545044
Validation loss: 2.1839523911476135

Epoch: 6| Step: 12
Training loss: 1.7287850379943848
Validation loss: 2.1663612922032676

Epoch: 6| Step: 13
Training loss: 1.8964794874191284
Validation loss: 2.1938685377438865

Epoch: 242| Step: 0
Training loss: 1.7073802947998047
Validation loss: 2.1747334400812783

Epoch: 6| Step: 1
Training loss: 1.6916917562484741
Validation loss: 2.17225190003713

Epoch: 6| Step: 2
Training loss: 1.7967684268951416
Validation loss: 2.1737619439760842

Epoch: 6| Step: 3
Training loss: 1.3129740953445435
Validation loss: 2.200815955797831

Epoch: 6| Step: 4
Training loss: 1.3437780141830444
Validation loss: 2.187904179096222

Epoch: 6| Step: 5
Training loss: 2.8440279960632324
Validation loss: 2.214676082134247

Epoch: 6| Step: 6
Training loss: 2.070830821990967
Validation loss: 2.2200640638669333

Epoch: 6| Step: 7
Training loss: 1.9263319969177246
Validation loss: 2.2389414310455322

Epoch: 6| Step: 8
Training loss: 1.8710136413574219
Validation loss: 2.2324986656506858

Epoch: 6| Step: 9
Training loss: 1.876375675201416
Validation loss: 2.2571462988853455

Epoch: 6| Step: 10
Training loss: 2.1593515872955322
Validation loss: 2.2357471585273743

Epoch: 6| Step: 11
Training loss: 1.8597242832183838
Validation loss: 2.2556666334470115

Epoch: 6| Step: 12
Training loss: 1.7426204681396484
Validation loss: 2.240607182184855

Epoch: 6| Step: 13
Training loss: 2.1864006519317627
Validation loss: 2.2392247517903647

Epoch: 243| Step: 0
Training loss: 1.5859864950180054
Validation loss: 2.2328115900357566

Epoch: 6| Step: 1
Training loss: 1.5385465621948242
Validation loss: 2.219301223754883

Epoch: 6| Step: 2
Training loss: 1.3957712650299072
Validation loss: 2.2172269225120544

Epoch: 6| Step: 3
Training loss: 2.0821304321289062
Validation loss: 2.2136113246281943

Epoch: 6| Step: 4
Training loss: 1.714735984802246
Validation loss: 2.203437348206838

Epoch: 6| Step: 5
Training loss: 2.0369253158569336
Validation loss: 2.2204132278760276

Epoch: 6| Step: 6
Training loss: 1.4777354001998901
Validation loss: 2.2123329043388367

Epoch: 6| Step: 7
Training loss: 2.03482985496521
Validation loss: 2.1992556850115457

Epoch: 6| Step: 8
Training loss: 1.9674708843231201
Validation loss: 2.210241357485453

Epoch: 6| Step: 9
Training loss: 2.2987890243530273
Validation loss: 2.2097078363100686

Epoch: 6| Step: 10
Training loss: 1.804903507232666
Validation loss: 2.1931275725364685

Epoch: 6| Step: 11
Training loss: 2.055586099624634
Validation loss: 2.198758840560913

Epoch: 6| Step: 12
Training loss: 1.314401388168335
Validation loss: 2.223199248313904

Epoch: 6| Step: 13
Training loss: 2.3183979988098145
Validation loss: 2.217170079549154

Epoch: 244| Step: 0
Training loss: 1.534476399421692
Validation loss: 2.2265454729398093

Epoch: 6| Step: 1
Training loss: 1.7492902278900146
Validation loss: 2.2259961565335593

Epoch: 6| Step: 2
Training loss: 1.818139672279358
Validation loss: 2.233313739299774

Epoch: 6| Step: 3
Training loss: 1.616476058959961
Validation loss: 2.2308678229649863

Epoch: 6| Step: 4
Training loss: 1.2210829257965088
Validation loss: 2.2272317012151084

Epoch: 6| Step: 5
Training loss: 1.6203256845474243
Validation loss: 2.219407240549723

Epoch: 6| Step: 6
Training loss: 2.025003433227539
Validation loss: 2.2187952200571694

Epoch: 6| Step: 7
Training loss: 2.0515100955963135
Validation loss: 2.227967997392019

Epoch: 6| Step: 8
Training loss: 1.9550764560699463
Validation loss: 2.2116509477297464

Epoch: 6| Step: 9
Training loss: 1.9052499532699585
Validation loss: 2.233056386311849

Epoch: 6| Step: 10
Training loss: 2.1298789978027344
Validation loss: 2.215074360370636

Epoch: 6| Step: 11
Training loss: 1.9662359952926636
Validation loss: 2.2414602835973105

Epoch: 6| Step: 12
Training loss: 2.0564682483673096
Validation loss: 2.239059845606486

Epoch: 6| Step: 13
Training loss: 1.8656855821609497
Validation loss: 2.2431445519129434

Epoch: 245| Step: 0
Training loss: 2.284752607345581
Validation loss: 2.221081713835398

Epoch: 6| Step: 1
Training loss: 2.3049826622009277
Validation loss: 2.2134132981300354

Epoch: 6| Step: 2
Training loss: 1.2490956783294678
Validation loss: 2.232298195362091

Epoch: 6| Step: 3
Training loss: 1.591742992401123
Validation loss: 2.2219852209091187

Epoch: 6| Step: 4
Training loss: 2.0050034523010254
Validation loss: 2.2136364181836448

Epoch: 6| Step: 5
Training loss: 2.015150547027588
Validation loss: 2.212848206361135

Epoch: 6| Step: 6
Training loss: 1.9558182954788208
Validation loss: 2.2159566481908164

Epoch: 6| Step: 7
Training loss: 1.4770293235778809
Validation loss: 2.2213281790415444

Epoch: 6| Step: 8
Training loss: 1.832975149154663
Validation loss: 2.22140904267629

Epoch: 6| Step: 9
Training loss: 2.1500978469848633
Validation loss: 2.2358808716138205

Epoch: 6| Step: 10
Training loss: 1.82196044921875
Validation loss: 2.2456191976865134

Epoch: 6| Step: 11
Training loss: 1.5373437404632568
Validation loss: 2.249051014582316

Epoch: 6| Step: 12
Training loss: 1.8522346019744873
Validation loss: 2.2634902397791543

Epoch: 6| Step: 13
Training loss: 1.4389383792877197
Validation loss: 2.252106865247091

Epoch: 246| Step: 0
Training loss: 1.748653769493103
Validation loss: 2.2550138036410012

Epoch: 6| Step: 1
Training loss: 1.773079752922058
Validation loss: 2.258538087209066

Epoch: 6| Step: 2
Training loss: 1.440407395362854
Validation loss: 2.248296240965525

Epoch: 6| Step: 3
Training loss: 2.025516986846924
Validation loss: 2.251959244410197

Epoch: 6| Step: 4
Training loss: 1.7916591167449951
Validation loss: 2.229668994744619

Epoch: 6| Step: 5
Training loss: 1.852562665939331
Validation loss: 2.2478450735410056

Epoch: 6| Step: 6
Training loss: 1.6514657735824585
Validation loss: 2.240166445573171

Epoch: 6| Step: 7
Training loss: 2.078026294708252
Validation loss: 2.228194077809652

Epoch: 6| Step: 8
Training loss: 2.01519775390625
Validation loss: 2.2246623039245605

Epoch: 6| Step: 9
Training loss: 1.7498955726623535
Validation loss: 2.220631937185923

Epoch: 6| Step: 10
Training loss: 2.105496406555176
Validation loss: 2.218359967072805

Epoch: 6| Step: 11
Training loss: 1.7541743516921997
Validation loss: 2.20302414894104

Epoch: 6| Step: 12
Training loss: 2.1220381259918213
Validation loss: 2.2016345063845315

Epoch: 6| Step: 13
Training loss: 1.61977219581604
Validation loss: 2.1991117199261985

Epoch: 247| Step: 0
Training loss: 1.6737536191940308
Validation loss: 2.193839887777964

Epoch: 6| Step: 1
Training loss: 1.9366810321807861
Validation loss: 2.204758644104004

Epoch: 6| Step: 2
Training loss: 1.7190144062042236
Validation loss: 2.2147116661071777

Epoch: 6| Step: 3
Training loss: 2.326970338821411
Validation loss: 2.2120616833368936

Epoch: 6| Step: 4
Training loss: 1.1197158098220825
Validation loss: 2.2527690728505454

Epoch: 6| Step: 5
Training loss: 2.0005674362182617
Validation loss: 2.233218232790629

Epoch: 6| Step: 6
Training loss: 2.432374954223633
Validation loss: 2.2458090782165527

Epoch: 6| Step: 7
Training loss: 1.3289008140563965
Validation loss: 2.2719274163246155

Epoch: 6| Step: 8
Training loss: 1.7264916896820068
Validation loss: 2.257946332295736

Epoch: 6| Step: 9
Training loss: 1.766679286956787
Validation loss: 2.243429442246755

Epoch: 6| Step: 10
Training loss: 2.3572378158569336
Validation loss: 2.2886977990468345

Epoch: 6| Step: 11
Training loss: 1.6985256671905518
Validation loss: 2.2594141165415444

Epoch: 6| Step: 12
Training loss: 1.6909496784210205
Validation loss: 2.286640763282776

Epoch: 6| Step: 13
Training loss: 1.6748936176300049
Validation loss: 2.2534166971842446

Epoch: 248| Step: 0
Training loss: 2.2282395362854004
Validation loss: 2.258432368437449

Epoch: 6| Step: 1
Training loss: 1.9673651456832886
Validation loss: 2.25068990389506

Epoch: 6| Step: 2
Training loss: 2.110790252685547
Validation loss: 2.221657077471415

Epoch: 6| Step: 3
Training loss: 2.3945868015289307
Validation loss: 2.2151005268096924

Epoch: 6| Step: 4
Training loss: 1.8286652565002441
Validation loss: 2.203822374343872

Epoch: 6| Step: 5
Training loss: 1.5102310180664062
Validation loss: 2.2026718656222024

Epoch: 6| Step: 6
Training loss: 1.643860936164856
Validation loss: 2.2211503982543945

Epoch: 6| Step: 7
Training loss: 1.1893779039382935
Validation loss: 2.238003055254618

Epoch: 6| Step: 8
Training loss: 1.5648680925369263
Validation loss: 2.243398388226827

Epoch: 6| Step: 9
Training loss: 2.408198833465576
Validation loss: 2.228451410929362

Epoch: 6| Step: 10
Training loss: 2.23970365524292
Validation loss: 2.226188063621521

Epoch: 6| Step: 11
Training loss: 1.3794795274734497
Validation loss: 2.21068545182546

Epoch: 6| Step: 12
Training loss: 1.6768100261688232
Validation loss: 2.2124762535095215

Epoch: 6| Step: 13
Training loss: 1.5510289669036865
Validation loss: 2.238004763921102

Epoch: 249| Step: 0
Training loss: 2.1069412231445312
Validation loss: 2.234935224056244

Epoch: 6| Step: 1
Training loss: 1.821340560913086
Validation loss: 2.2374087373415628

Epoch: 6| Step: 2
Training loss: 1.4635393619537354
Validation loss: 2.2471667528152466

Epoch: 6| Step: 3
Training loss: 1.5988974571228027
Validation loss: 2.254400074481964

Epoch: 6| Step: 4
Training loss: 1.3143386840820312
Validation loss: 2.2486634055773416

Epoch: 6| Step: 5
Training loss: 1.7157306671142578
Validation loss: 2.276311218738556

Epoch: 6| Step: 6
Training loss: 2.3774313926696777
Validation loss: 2.226276616255442

Epoch: 6| Step: 7
Training loss: 1.5742127895355225
Validation loss: 2.2433606386184692

Epoch: 6| Step: 8
Training loss: 1.4551202058792114
Validation loss: 2.241200645764669

Epoch: 6| Step: 9
Training loss: 2.0025548934936523
Validation loss: 2.241211950778961

Epoch: 6| Step: 10
Training loss: 1.516042709350586
Validation loss: 2.2605313658714294

Epoch: 6| Step: 11
Training loss: 2.3288185596466064
Validation loss: 2.2528367837270102

Epoch: 6| Step: 12
Training loss: 1.9410990476608276
Validation loss: 2.241175353527069

Epoch: 6| Step: 13
Training loss: 2.114938974380493
Validation loss: 2.2628075083096824

Epoch: 250| Step: 0
Training loss: 1.9804973602294922
Validation loss: 2.2102789680163064

Epoch: 6| Step: 1
Training loss: 2.2111117839813232
Validation loss: 2.210806687672933

Epoch: 6| Step: 2
Training loss: 1.8225675821304321
Validation loss: 2.194430430730184

Epoch: 6| Step: 3
Training loss: 1.4291160106658936
Validation loss: 2.221523106098175

Epoch: 6| Step: 4
Training loss: 1.5396735668182373
Validation loss: 2.2297744154930115

Epoch: 6| Step: 5
Training loss: 2.3117637634277344
Validation loss: 2.215342899163564

Epoch: 6| Step: 6
Training loss: 1.7226591110229492
Validation loss: 2.219621260960897

Epoch: 6| Step: 7
Training loss: 1.858333945274353
Validation loss: 2.2216296990712485

Epoch: 6| Step: 8
Training loss: 2.4803853034973145
Validation loss: 2.2223340272903442

Epoch: 6| Step: 9
Training loss: 1.3152093887329102
Validation loss: 2.224865814050039

Epoch: 6| Step: 10
Training loss: 1.456023931503296
Validation loss: 2.199240227540334

Epoch: 6| Step: 11
Training loss: 1.4016927480697632
Validation loss: 2.210645318031311

Epoch: 6| Step: 12
Training loss: 1.7948119640350342
Validation loss: 2.2003817558288574

Epoch: 6| Step: 13
Training loss: 2.2523982524871826
Validation loss: 2.212616582711538

Epoch: 251| Step: 0
Training loss: 2.4478447437286377
Validation loss: 2.193837563196818

Epoch: 6| Step: 1
Training loss: 1.9641910791397095
Validation loss: 2.1959945360819497

Epoch: 6| Step: 2
Training loss: 1.702714443206787
Validation loss: 2.201966921488444

Epoch: 6| Step: 3
Training loss: 1.6067299842834473
Validation loss: 2.2131508588790894

Epoch: 6| Step: 4
Training loss: 2.1072118282318115
Validation loss: 2.21775092681249

Epoch: 6| Step: 5
Training loss: 1.4844528436660767
Validation loss: 2.209563732147217

Epoch: 6| Step: 6
Training loss: 1.8228787183761597
Validation loss: 2.2268126606941223

Epoch: 6| Step: 7
Training loss: 1.4174082279205322
Validation loss: 2.2445887128512063

Epoch: 6| Step: 8
Training loss: 1.8699750900268555
Validation loss: 2.2372886538505554

Epoch: 6| Step: 9
Training loss: 1.6926690340042114
Validation loss: 2.250852624575297

Epoch: 6| Step: 10
Training loss: 1.4245598316192627
Validation loss: 2.2907756765683494

Epoch: 6| Step: 11
Training loss: 1.6821215152740479
Validation loss: 2.269742965698242

Epoch: 6| Step: 12
Training loss: 2.2017574310302734
Validation loss: 2.260799507300059

Epoch: 6| Step: 13
Training loss: 2.0076088905334473
Validation loss: 2.2712176044782004

Epoch: 252| Step: 0
Training loss: 1.4455842971801758
Validation loss: 2.281893491744995

Epoch: 6| Step: 1
Training loss: 1.5952364206314087
Validation loss: 2.2614276806513467

Epoch: 6| Step: 2
Training loss: 1.7129478454589844
Validation loss: 2.2556456923484802

Epoch: 6| Step: 3
Training loss: 2.177359104156494
Validation loss: 2.226367970307668

Epoch: 6| Step: 4
Training loss: 2.334744453430176
Validation loss: 2.2182148496309915

Epoch: 6| Step: 5
Training loss: 2.0074734687805176
Validation loss: 2.2527275482813516

Epoch: 6| Step: 6
Training loss: 2.334414005279541
Validation loss: 2.2444030046463013

Epoch: 6| Step: 7
Training loss: 1.5916166305541992
Validation loss: 2.2355101307233176

Epoch: 6| Step: 8
Training loss: 2.480820894241333
Validation loss: 2.2340482274691262

Epoch: 6| Step: 9
Training loss: 1.2355363368988037
Validation loss: 2.2334791819254556

Epoch: 6| Step: 10
Training loss: 1.2421965599060059
Validation loss: 2.244568665822347

Epoch: 6| Step: 11
Training loss: 1.3596413135528564
Validation loss: 2.246641476949056

Epoch: 6| Step: 12
Training loss: 1.6588294506072998
Validation loss: 2.2383387684822083

Epoch: 6| Step: 13
Training loss: 2.1264896392822266
Validation loss: 2.219905138015747

Epoch: 253| Step: 0
Training loss: 1.0609568357467651
Validation loss: 2.233282228310903

Epoch: 6| Step: 1
Training loss: 1.4476358890533447
Validation loss: 2.233237067858378

Epoch: 6| Step: 2
Training loss: 1.5998146533966064
Validation loss: 2.201621135075887

Epoch: 6| Step: 3
Training loss: 1.9703965187072754
Validation loss: 2.220550298690796

Epoch: 6| Step: 4
Training loss: 2.4002959728240967
Validation loss: 2.203052560488383

Epoch: 6| Step: 5
Training loss: 2.1614575386047363
Validation loss: 2.1926340063412986

Epoch: 6| Step: 6
Training loss: 2.2989344596862793
Validation loss: 2.1882305343945823

Epoch: 6| Step: 7
Training loss: 2.0683181285858154
Validation loss: 2.185989479223887

Epoch: 6| Step: 8
Training loss: 1.8873502016067505
Validation loss: 2.1945058703422546

Epoch: 6| Step: 9
Training loss: 1.4261486530303955
Validation loss: 2.2129643758138022

Epoch: 6| Step: 10
Training loss: 2.198955774307251
Validation loss: 2.224796255429586

Epoch: 6| Step: 11
Training loss: 1.9549168348312378
Validation loss: 2.2463401357332864

Epoch: 6| Step: 12
Training loss: 1.4268772602081299
Validation loss: 2.2544150352478027

Epoch: 6| Step: 13
Training loss: 1.4127185344696045
Validation loss: 2.281464775403341

Epoch: 254| Step: 0
Training loss: 2.10538387298584
Validation loss: 2.2464534441630044

Epoch: 6| Step: 1
Training loss: 2.1712841987609863
Validation loss: 2.276356816291809

Epoch: 6| Step: 2
Training loss: 2.0104970932006836
Validation loss: 2.2789127826690674

Epoch: 6| Step: 3
Training loss: 1.5887939929962158
Validation loss: 2.2625556588172913

Epoch: 6| Step: 4
Training loss: 1.3288733959197998
Validation loss: 2.254144847393036

Epoch: 6| Step: 5
Training loss: 2.066279649734497
Validation loss: 2.1957093477249146

Epoch: 6| Step: 6
Training loss: 1.8643734455108643
Validation loss: 2.215978980064392

Epoch: 6| Step: 7
Training loss: 1.600367546081543
Validation loss: 2.235030730565389

Epoch: 6| Step: 8
Training loss: 2.4994380474090576
Validation loss: 2.212640106678009

Epoch: 6| Step: 9
Training loss: 1.4246270656585693
Validation loss: 2.212363839149475

Epoch: 6| Step: 10
Training loss: 1.4981120824813843
Validation loss: 2.221343517303467

Epoch: 6| Step: 11
Training loss: 1.1675868034362793
Validation loss: 2.2200241088867188

Epoch: 6| Step: 12
Training loss: 1.9349018335342407
Validation loss: 2.2016185323397317

Epoch: 6| Step: 13
Training loss: 2.26124906539917
Validation loss: 2.2250067392985025

Epoch: 255| Step: 0
Training loss: 2.1498584747314453
Validation loss: 2.2255424658457437

Epoch: 6| Step: 1
Training loss: 1.384468674659729
Validation loss: 2.2663067976633706

Epoch: 6| Step: 2
Training loss: 0.9680417776107788
Validation loss: 2.237422068913778

Epoch: 6| Step: 3
Training loss: 1.4222416877746582
Validation loss: 2.279493490854899

Epoch: 6| Step: 4
Training loss: 2.204679489135742
Validation loss: 2.2770071029663086

Epoch: 6| Step: 5
Training loss: 1.875544786453247
Validation loss: 2.2547471721967063

Epoch: 6| Step: 6
Training loss: 1.7631593942642212
Validation loss: 2.2593952218691506

Epoch: 6| Step: 7
Training loss: 1.9451756477355957
Validation loss: 2.2728957136472068

Epoch: 6| Step: 8
Training loss: 1.774458408355713
Validation loss: 2.274584253629049

Epoch: 6| Step: 9
Training loss: 2.72941255569458
Validation loss: 2.2840469082196555

Epoch: 6| Step: 10
Training loss: 1.2695319652557373
Validation loss: 2.241922756036123

Epoch: 6| Step: 11
Training loss: 1.8932348489761353
Validation loss: 2.247266093889872

Epoch: 6| Step: 12
Training loss: 1.8504748344421387
Validation loss: 2.268972873687744

Epoch: 6| Step: 13
Training loss: 2.111825942993164
Validation loss: 2.243925134340922

Epoch: 256| Step: 0
Training loss: 1.8297338485717773
Validation loss: 2.2405283053716025

Epoch: 6| Step: 1
Training loss: 1.892656683921814
Validation loss: 2.240566869576772

Epoch: 6| Step: 2
Training loss: 1.2689443826675415
Validation loss: 2.2519976695378623

Epoch: 6| Step: 3
Training loss: 1.5179049968719482
Validation loss: 2.2482494910558066

Epoch: 6| Step: 4
Training loss: 2.3194265365600586
Validation loss: 2.2746315002441406

Epoch: 6| Step: 5
Training loss: 1.773348331451416
Validation loss: 2.267381489276886

Epoch: 6| Step: 6
Training loss: 2.092592716217041
Validation loss: 2.262938658396403

Epoch: 6| Step: 7
Training loss: 2.153993606567383
Validation loss: 2.2529074947039285

Epoch: 6| Step: 8
Training loss: 1.906604290008545
Validation loss: 2.2671504616737366

Epoch: 6| Step: 9
Training loss: 2.6327106952667236
Validation loss: 2.2704511880874634

Epoch: 6| Step: 10
Training loss: 0.9223299026489258
Validation loss: 2.2431127230326333

Epoch: 6| Step: 11
Training loss: 2.0548839569091797
Validation loss: 2.2497273683547974

Epoch: 6| Step: 12
Training loss: 1.5846443176269531
Validation loss: 2.2361045281092324

Epoch: 6| Step: 13
Training loss: 1.3766343593597412
Validation loss: 2.212334156036377

Epoch: 257| Step: 0
Training loss: 1.6623320579528809
Validation loss: 2.213946600755056

Epoch: 6| Step: 1
Training loss: 1.9452850818634033
Validation loss: 2.2209221720695496

Epoch: 6| Step: 2
Training loss: 2.1091837882995605
Validation loss: 2.202137013276418

Epoch: 6| Step: 3
Training loss: 2.136746883392334
Validation loss: 2.208829641342163

Epoch: 6| Step: 4
Training loss: 1.9866201877593994
Validation loss: 2.219072381655375

Epoch: 6| Step: 5
Training loss: 1.6247239112854004
Validation loss: 2.1990772485733032

Epoch: 6| Step: 6
Training loss: 1.4339679479599
Validation loss: 2.212283968925476

Epoch: 6| Step: 7
Training loss: 1.4339382648468018
Validation loss: 2.213728884855906

Epoch: 6| Step: 8
Training loss: 1.1455267667770386
Validation loss: 2.233965734640757

Epoch: 6| Step: 9
Training loss: 1.7079131603240967
Validation loss: 2.2272376219431558

Epoch: 6| Step: 10
Training loss: 2.1506400108337402
Validation loss: 2.2185441056887307

Epoch: 6| Step: 11
Training loss: 1.3774518966674805
Validation loss: 2.2601555784543357

Epoch: 6| Step: 12
Training loss: 1.8462207317352295
Validation loss: 2.2341721455256143

Epoch: 6| Step: 13
Training loss: 2.5445897579193115
Validation loss: 2.2432995438575745

Epoch: 258| Step: 0
Training loss: 1.6627962589263916
Validation loss: 2.2218425075213113

Epoch: 6| Step: 1
Training loss: 1.8130450248718262
Validation loss: 2.242681086063385

Epoch: 6| Step: 2
Training loss: 1.4601104259490967
Validation loss: 2.235470453898112

Epoch: 6| Step: 3
Training loss: 2.2339608669281006
Validation loss: 2.225118100643158

Epoch: 6| Step: 4
Training loss: 1.8001419305801392
Validation loss: 2.21336837609609

Epoch: 6| Step: 5
Training loss: 1.7108428478240967
Validation loss: 2.251049796740214

Epoch: 6| Step: 6
Training loss: 2.2188827991485596
Validation loss: 2.2197883129119873

Epoch: 6| Step: 7
Training loss: 1.6960971355438232
Validation loss: 2.225411136945089

Epoch: 6| Step: 8
Training loss: 1.974522352218628
Validation loss: 2.219571848710378

Epoch: 6| Step: 9
Training loss: 2.0430455207824707
Validation loss: 2.2285873691240945

Epoch: 6| Step: 10
Training loss: 1.0631942749023438
Validation loss: 2.24078639348348

Epoch: 6| Step: 11
Training loss: 1.9861963987350464
Validation loss: 2.2303264141082764

Epoch: 6| Step: 12
Training loss: 2.2164559364318848
Validation loss: 2.22976815700531

Epoch: 6| Step: 13
Training loss: 1.309218406677246
Validation loss: 2.2049192984898887

Epoch: 259| Step: 0
Training loss: 1.7930635213851929
Validation loss: 2.219733993212382

Epoch: 6| Step: 1
Training loss: 1.7179946899414062
Validation loss: 2.2389036615689597

Epoch: 6| Step: 2
Training loss: 2.1154751777648926
Validation loss: 2.2650792002677917

Epoch: 6| Step: 3
Training loss: 1.8369061946868896
Validation loss: 2.2523272037506104

Epoch: 6| Step: 4
Training loss: 1.3917630910873413
Validation loss: 2.2406758069992065

Epoch: 6| Step: 5
Training loss: 2.220691680908203
Validation loss: 2.2678513129552207

Epoch: 6| Step: 6
Training loss: 1.4736076593399048
Validation loss: 2.2435246308644614

Epoch: 6| Step: 7
Training loss: 1.3549561500549316
Validation loss: 2.229273815949758

Epoch: 6| Step: 8
Training loss: 2.1069884300231934
Validation loss: 2.231508453687032

Epoch: 6| Step: 9
Training loss: 1.8103970289230347
Validation loss: 2.230987548828125

Epoch: 6| Step: 10
Training loss: 2.139129161834717
Validation loss: 2.2385878364245095

Epoch: 6| Step: 11
Training loss: 2.1275908946990967
Validation loss: 2.233876665433248

Epoch: 6| Step: 12
Training loss: 1.4334311485290527
Validation loss: 2.235114097595215

Epoch: 6| Step: 13
Training loss: 1.843268871307373
Validation loss: 2.2350929180781045

Epoch: 260| Step: 0
Training loss: 1.4146099090576172
Validation loss: 2.2398449977238974

Epoch: 6| Step: 1
Training loss: 1.8503342866897583
Validation loss: 2.2533713380495706

Epoch: 6| Step: 2
Training loss: 2.0421173572540283
Validation loss: 2.2502018809318542

Epoch: 6| Step: 3
Training loss: 2.222968578338623
Validation loss: 2.250385026137034

Epoch: 6| Step: 4
Training loss: 2.6134841442108154
Validation loss: 2.252490838368734

Epoch: 6| Step: 5
Training loss: 2.1138076782226562
Validation loss: 2.2451581756273904

Epoch: 6| Step: 6
Training loss: 1.7738157510757446
Validation loss: 2.2584744493166604

Epoch: 6| Step: 7
Training loss: 1.7011140584945679
Validation loss: 2.2255812287330627

Epoch: 6| Step: 8
Training loss: 1.5074470043182373
Validation loss: 2.2507610519727073

Epoch: 6| Step: 9
Training loss: 1.6815181970596313
Validation loss: 2.2212719917297363

Epoch: 6| Step: 10
Training loss: 1.3636136054992676
Validation loss: 2.252550959587097

Epoch: 6| Step: 11
Training loss: 1.8543529510498047
Validation loss: 2.2360207438468933

Epoch: 6| Step: 12
Training loss: 1.077146053314209
Validation loss: 2.2151607275009155

Epoch: 6| Step: 13
Training loss: 1.9763233661651611
Validation loss: 2.2225359678268433

Epoch: 261| Step: 0
Training loss: 1.9320006370544434
Validation loss: 2.2214242617289224

Epoch: 6| Step: 1
Training loss: 2.2970833778381348
Validation loss: 2.214990476767222

Epoch: 6| Step: 2
Training loss: 2.2645673751831055
Validation loss: 2.2182056506474814

Epoch: 6| Step: 3
Training loss: 0.8544822931289673
Validation loss: 2.243099788824717

Epoch: 6| Step: 4
Training loss: 1.5313479900360107
Validation loss: 2.2351625561714172

Epoch: 6| Step: 5
Training loss: 1.5939135551452637
Validation loss: 2.2454027930895486

Epoch: 6| Step: 6
Training loss: 1.4553669691085815
Validation loss: 2.24993759393692

Epoch: 6| Step: 7
Training loss: 1.65733003616333
Validation loss: 2.2389942606290183

Epoch: 6| Step: 8
Training loss: 1.251694917678833
Validation loss: 2.230988085269928

Epoch: 6| Step: 9
Training loss: 2.2821602821350098
Validation loss: 2.246950606505076

Epoch: 6| Step: 10
Training loss: 2.0522661209106445
Validation loss: 2.2569860021273294

Epoch: 6| Step: 11
Training loss: 1.730225920677185
Validation loss: 2.2624003489812217

Epoch: 6| Step: 12
Training loss: 1.8205080032348633
Validation loss: 2.2574908336003623

Epoch: 6| Step: 13
Training loss: 2.215858221054077
Validation loss: 2.2672876914342246

Epoch: 262| Step: 0
Training loss: 1.6619441509246826
Validation loss: 2.25741716225942

Epoch: 6| Step: 1
Training loss: 1.6809920072555542
Validation loss: 2.272817293802897

Epoch: 6| Step: 2
Training loss: 2.45047664642334
Validation loss: 2.249242583910624

Epoch: 6| Step: 3
Training loss: 1.9974608421325684
Validation loss: 2.252791384855906

Epoch: 6| Step: 4
Training loss: 1.4294896125793457
Validation loss: 2.2299219568570456

Epoch: 6| Step: 5
Training loss: 2.1424856185913086
Validation loss: 2.2271419366200766

Epoch: 6| Step: 6
Training loss: 1.9191107749938965
Validation loss: 2.232884685198466

Epoch: 6| Step: 7
Training loss: 1.983852505683899
Validation loss: 2.2282539010047913

Epoch: 6| Step: 8
Training loss: 1.5446994304656982
Validation loss: 2.259122848510742

Epoch: 6| Step: 9
Training loss: 1.0481207370758057
Validation loss: 2.2421050469080606

Epoch: 6| Step: 10
Training loss: 1.3238722085952759
Validation loss: 2.2763449947039285

Epoch: 6| Step: 11
Training loss: 1.9459797143936157
Validation loss: 2.26299641529719

Epoch: 6| Step: 12
Training loss: 1.9899982213974
Validation loss: 2.2955390214920044

Epoch: 6| Step: 13
Training loss: 1.8642873764038086
Validation loss: 2.2790807088216147

Epoch: 263| Step: 0
Training loss: 2.2938499450683594
Validation loss: 2.2820831139882407

Epoch: 6| Step: 1
Training loss: 1.0996344089508057
Validation loss: 2.2816100319226584

Epoch: 6| Step: 2
Training loss: 2.098308563232422
Validation loss: 2.2674949566523233

Epoch: 6| Step: 3
Training loss: 2.1477129459381104
Validation loss: 2.297315498193105

Epoch: 6| Step: 4
Training loss: 1.8925461769104004
Validation loss: 2.2793583075205484

Epoch: 6| Step: 5
Training loss: 1.4439971446990967
Validation loss: 2.267210364341736

Epoch: 6| Step: 6
Training loss: 1.726373553276062
Validation loss: 2.256614625453949

Epoch: 6| Step: 7
Training loss: 1.8989523649215698
Validation loss: 2.2478782733281455

Epoch: 6| Step: 8
Training loss: 2.1079840660095215
Validation loss: 2.2596755027770996

Epoch: 6| Step: 9
Training loss: 2.313772678375244
Validation loss: 2.2408358256022134

Epoch: 6| Step: 10
Training loss: 1.70554518699646
Validation loss: 2.2561590671539307

Epoch: 6| Step: 11
Training loss: 1.421684741973877
Validation loss: 2.2620810071627298

Epoch: 6| Step: 12
Training loss: 1.4681663513183594
Validation loss: 2.2578617334365845

Epoch: 6| Step: 13
Training loss: 1.3753255605697632
Validation loss: 2.2843769788742065

Epoch: 264| Step: 0
Training loss: 1.800489902496338
Validation loss: 2.259530782699585

Epoch: 6| Step: 1
Training loss: 3.107226848602295
Validation loss: 2.290323853492737

Epoch: 6| Step: 2
Training loss: 1.6426619291305542
Validation loss: 2.2863778670628867

Epoch: 6| Step: 3
Training loss: 1.0976852178573608
Validation loss: 2.2577492396036782

Epoch: 6| Step: 4
Training loss: 2.303651809692383
Validation loss: 2.2764533360799155

Epoch: 6| Step: 5
Training loss: 2.2595767974853516
Validation loss: 2.2787407437960305

Epoch: 6| Step: 6
Training loss: 0.9239429831504822
Validation loss: 2.2585494915644326

Epoch: 6| Step: 7
Training loss: 1.5409176349639893
Validation loss: 2.278046945730845

Epoch: 6| Step: 8
Training loss: 1.319651484489441
Validation loss: 2.272977113723755

Epoch: 6| Step: 9
Training loss: 2.081699848175049
Validation loss: 2.2817426323890686

Epoch: 6| Step: 10
Training loss: 2.107869863510132
Validation loss: 2.2581711411476135

Epoch: 6| Step: 11
Training loss: 1.6791267395019531
Validation loss: 2.2794325947761536

Epoch: 6| Step: 12
Training loss: 1.8897111415863037
Validation loss: 2.254617134730021

Epoch: 6| Step: 13
Training loss: 1.4940778017044067
Validation loss: 2.2654662132263184

Epoch: 265| Step: 0
Training loss: 2.3479950428009033
Validation loss: 2.285965303579966

Epoch: 6| Step: 1
Training loss: 1.5961382389068604
Validation loss: 2.251930753389994

Epoch: 6| Step: 2
Training loss: 1.4631056785583496
Validation loss: 2.278611421585083

Epoch: 6| Step: 3
Training loss: 1.9712624549865723
Validation loss: 2.247927745183309

Epoch: 6| Step: 4
Training loss: 1.330322265625
Validation loss: 2.240976929664612

Epoch: 6| Step: 5
Training loss: 2.0341174602508545
Validation loss: 2.2417646249135337

Epoch: 6| Step: 6
Training loss: 1.7580809593200684
Validation loss: 2.2540267507235208

Epoch: 6| Step: 7
Training loss: 1.8721027374267578
Validation loss: 2.2776168386141458

Epoch: 6| Step: 8
Training loss: 1.938044548034668
Validation loss: 2.2435513138771057

Epoch: 6| Step: 9
Training loss: 1.1903101205825806
Validation loss: 2.260767380396525

Epoch: 6| Step: 10
Training loss: 1.8076218366622925
Validation loss: 2.261375387509664

Epoch: 6| Step: 11
Training loss: 2.3957066535949707
Validation loss: 2.2543568213780723

Epoch: 6| Step: 12
Training loss: 1.7655510902404785
Validation loss: 2.25065678358078

Epoch: 6| Step: 13
Training loss: 1.4825856685638428
Validation loss: 2.2499566674232483

Epoch: 266| Step: 0
Training loss: 1.6808679103851318
Validation loss: 2.231363217035929

Epoch: 6| Step: 1
Training loss: 2.698082447052002
Validation loss: 2.2299596071243286

Epoch: 6| Step: 2
Training loss: 1.5691546201705933
Validation loss: 2.2229291598002114

Epoch: 6| Step: 3
Training loss: 1.501059651374817
Validation loss: 2.2181255420049033

Epoch: 6| Step: 4
Training loss: 2.703214406967163
Validation loss: 2.2206430037816367

Epoch: 6| Step: 5
Training loss: 1.891089916229248
Validation loss: 2.2385654052098594

Epoch: 6| Step: 6
Training loss: 1.5837013721466064
Validation loss: 2.2034897208213806

Epoch: 6| Step: 7
Training loss: 2.455134868621826
Validation loss: 2.224610447883606

Epoch: 6| Step: 8
Training loss: 1.2460546493530273
Validation loss: 2.2326765855153403

Epoch: 6| Step: 9
Training loss: 1.6004469394683838
Validation loss: 2.2140285770098367

Epoch: 6| Step: 10
Training loss: 1.385122537612915
Validation loss: 2.2120511134465537

Epoch: 6| Step: 11
Training loss: 1.8280882835388184
Validation loss: 2.2361608346303306

Epoch: 6| Step: 12
Training loss: 1.63067626953125
Validation loss: 2.2367457151412964

Epoch: 6| Step: 13
Training loss: 1.3445966243743896
Validation loss: 2.2189695835113525

Epoch: 267| Step: 0
Training loss: 1.5837416648864746
Validation loss: 2.2194079160690308

Epoch: 6| Step: 1
Training loss: 1.9395959377288818
Validation loss: 2.2308164834976196

Epoch: 6| Step: 2
Training loss: 1.364038348197937
Validation loss: 2.230411152044932

Epoch: 6| Step: 3
Training loss: 1.671626091003418
Validation loss: 2.235917806625366

Epoch: 6| Step: 4
Training loss: 1.6151915788650513
Validation loss: 2.252089738845825

Epoch: 6| Step: 5
Training loss: 2.1709699630737305
Validation loss: 2.2270936965942383

Epoch: 6| Step: 6
Training loss: 1.4149360656738281
Validation loss: 2.253545065720876

Epoch: 6| Step: 7
Training loss: 1.8032572269439697
Validation loss: 2.24583766857783

Epoch: 6| Step: 8
Training loss: 2.0214390754699707
Validation loss: 2.250565489133199

Epoch: 6| Step: 9
Training loss: 2.15920352935791
Validation loss: 2.272123078505198

Epoch: 6| Step: 10
Training loss: 2.119957208633423
Validation loss: 2.2770164012908936

Epoch: 6| Step: 11
Training loss: 1.942542552947998
Validation loss: 2.2789266109466553

Epoch: 6| Step: 12
Training loss: 1.6044566631317139
Validation loss: 2.2893423040707908

Epoch: 6| Step: 13
Training loss: 1.5376774072647095
Validation loss: 2.2581629355748496

Epoch: 268| Step: 0
Training loss: 1.7280359268188477
Validation loss: 2.266399383544922

Epoch: 6| Step: 1
Training loss: 1.332205057144165
Validation loss: 2.276766280333201

Epoch: 6| Step: 2
Training loss: 1.835923194885254
Validation loss: 2.271185517311096

Epoch: 6| Step: 3
Training loss: 1.5430350303649902
Validation loss: 2.264484445254008

Epoch: 6| Step: 4
Training loss: 2.058488368988037
Validation loss: 2.2440205415089927

Epoch: 6| Step: 5
Training loss: 1.3229405879974365
Validation loss: 2.280874768892924

Epoch: 6| Step: 6
Training loss: 1.5730525255203247
Validation loss: 2.2676225900650024

Epoch: 6| Step: 7
Training loss: 1.2208809852600098
Validation loss: 2.265021562576294

Epoch: 6| Step: 8
Training loss: 1.5684490203857422
Validation loss: 2.253456691900889

Epoch: 6| Step: 9
Training loss: 2.142259359359741
Validation loss: 2.2921979228655496

Epoch: 6| Step: 10
Training loss: 2.3405256271362305
Validation loss: 2.2535791198412576

Epoch: 6| Step: 11
Training loss: 1.7864400148391724
Validation loss: 2.255887766679128

Epoch: 6| Step: 12
Training loss: 2.5388360023498535
Validation loss: 2.2441805601119995

Epoch: 6| Step: 13
Training loss: 1.9351840019226074
Validation loss: 2.272031009197235

Epoch: 269| Step: 0
Training loss: 1.3429930210113525
Validation loss: 2.247824410597483

Epoch: 6| Step: 1
Training loss: 2.3280534744262695
Validation loss: 2.2539416551589966

Epoch: 6| Step: 2
Training loss: 2.006563425064087
Validation loss: 2.2408504684766135

Epoch: 6| Step: 3
Training loss: 1.5808510780334473
Validation loss: 2.2422972122828164

Epoch: 6| Step: 4
Training loss: 1.8800793886184692
Validation loss: 2.2270464301109314

Epoch: 6| Step: 5
Training loss: 1.9786655902862549
Validation loss: 2.2481802900632224

Epoch: 6| Step: 6
Training loss: 2.146543025970459
Validation loss: 2.2311283548672995

Epoch: 6| Step: 7
Training loss: 2.161545991897583
Validation loss: 2.2418479720751443

Epoch: 6| Step: 8
Training loss: 1.5520066022872925
Validation loss: 2.24541566769282

Epoch: 6| Step: 9
Training loss: 1.8044759035110474
Validation loss: 2.2624865969022117

Epoch: 6| Step: 10
Training loss: 1.7331002950668335
Validation loss: 2.2526756723721824

Epoch: 6| Step: 11
Training loss: 1.4202215671539307
Validation loss: 2.240144729614258

Epoch: 6| Step: 12
Training loss: 1.5815544128417969
Validation loss: 2.267681121826172

Epoch: 6| Step: 13
Training loss: 1.3844760656356812
Validation loss: 2.2590821584065757

Epoch: 270| Step: 0
Training loss: 1.2964580059051514
Validation loss: 2.264337102572123

Epoch: 6| Step: 1
Training loss: 2.286205291748047
Validation loss: 2.263009707132975

Epoch: 6| Step: 2
Training loss: 2.0503907203674316
Validation loss: 2.2556309700012207

Epoch: 6| Step: 3
Training loss: 1.597947597503662
Validation loss: 2.2264329393704734

Epoch: 6| Step: 4
Training loss: 1.935190200805664
Validation loss: 2.2418068051338196

Epoch: 6| Step: 5
Training loss: 1.3504407405853271
Validation loss: 2.268288552761078

Epoch: 6| Step: 6
Training loss: 2.2021589279174805
Validation loss: 2.2542757193247476

Epoch: 6| Step: 7
Training loss: 1.1148624420166016
Validation loss: 2.2443323135375977

Epoch: 6| Step: 8
Training loss: 2.2539420127868652
Validation loss: 2.2380284468332925

Epoch: 6| Step: 9
Training loss: 1.944594383239746
Validation loss: 2.269379218419393

Epoch: 6| Step: 10
Training loss: 1.713982343673706
Validation loss: 2.2777730226516724

Epoch: 6| Step: 11
Training loss: 1.4074535369873047
Validation loss: 2.2791176438331604

Epoch: 6| Step: 12
Training loss: 1.7321078777313232
Validation loss: 2.2675302426020303

Epoch: 6| Step: 13
Training loss: 1.897679090499878
Validation loss: 2.263218879699707

Epoch: 271| Step: 0
Training loss: 2.0009493827819824
Validation loss: 2.2663307189941406

Epoch: 6| Step: 1
Training loss: 1.8649932146072388
Validation loss: 2.251528779665629

Epoch: 6| Step: 2
Training loss: 1.706458568572998
Validation loss: 2.2471519311269126

Epoch: 6| Step: 3
Training loss: 1.798548698425293
Validation loss: 2.2249561746915183

Epoch: 6| Step: 4
Training loss: 2.1650876998901367
Validation loss: 2.252889355023702

Epoch: 6| Step: 5
Training loss: 1.4124903678894043
Validation loss: 2.261452635129293

Epoch: 6| Step: 6
Training loss: 1.7324072122573853
Validation loss: 2.26007608572642

Epoch: 6| Step: 7
Training loss: 1.9385385513305664
Validation loss: 2.2446651458740234

Epoch: 6| Step: 8
Training loss: 1.3454720973968506
Validation loss: 2.272162993748983

Epoch: 6| Step: 9
Training loss: 1.9641286134719849
Validation loss: 2.2471497853597007

Epoch: 6| Step: 10
Training loss: 1.9379364252090454
Validation loss: 2.2403735717137656

Epoch: 6| Step: 11
Training loss: 2.0416765213012695
Validation loss: 2.236159324645996

Epoch: 6| Step: 12
Training loss: 2.145378589630127
Validation loss: 2.2170005440711975

Epoch: 6| Step: 13
Training loss: 1.1092393398284912
Validation loss: 2.2484174370765686

Epoch: 272| Step: 0
Training loss: 1.8975515365600586
Validation loss: 2.2553939819335938

Epoch: 6| Step: 1
Training loss: 1.8525992631912231
Validation loss: 2.2730207641919455

Epoch: 6| Step: 2
Training loss: 1.1118745803833008
Validation loss: 2.2319549719492593

Epoch: 6| Step: 3
Training loss: 1.7392332553863525
Validation loss: 2.2439831693967185

Epoch: 6| Step: 4
Training loss: 2.004868984222412
Validation loss: 2.2466018994649253

Epoch: 6| Step: 5
Training loss: 1.8473172187805176
Validation loss: 2.270699898401896

Epoch: 6| Step: 6
Training loss: 1.5948868989944458
Validation loss: 2.246325214703878

Epoch: 6| Step: 7
Training loss: 1.535430908203125
Validation loss: 2.2483664552370706

Epoch: 6| Step: 8
Training loss: 1.766273021697998
Validation loss: 2.2513739665349326

Epoch: 6| Step: 9
Training loss: 1.6429903507232666
Validation loss: 2.2616952061653137

Epoch: 6| Step: 10
Training loss: 2.5902538299560547
Validation loss: 2.245776653289795

Epoch: 6| Step: 11
Training loss: 1.775001049041748
Validation loss: 2.2386028369267783

Epoch: 6| Step: 12
Training loss: 1.822060465812683
Validation loss: 2.2517019708951316

Epoch: 6| Step: 13
Training loss: 1.635685920715332
Validation loss: 2.249613801638285

Epoch: 273| Step: 0
Training loss: 2.747190475463867
Validation loss: 2.2533541123072305

Epoch: 6| Step: 1
Training loss: 1.9791913032531738
Validation loss: 2.2589367230733237

Epoch: 6| Step: 2
Training loss: 1.6434321403503418
Validation loss: 2.2215864260991416

Epoch: 6| Step: 3
Training loss: 1.6674140691757202
Validation loss: 2.2527383168538413

Epoch: 6| Step: 4
Training loss: 2.3542797565460205
Validation loss: 2.234175662199656

Epoch: 6| Step: 5
Training loss: 1.9949054718017578
Validation loss: 2.2444814642270408

Epoch: 6| Step: 6
Training loss: 1.182126522064209
Validation loss: 2.2543101708094277

Epoch: 6| Step: 7
Training loss: 1.8166217803955078
Validation loss: 2.266185482343038

Epoch: 6| Step: 8
Training loss: 1.6975754499435425
Validation loss: 2.275834341843923

Epoch: 6| Step: 9
Training loss: 1.194153070449829
Validation loss: 2.283368706703186

Epoch: 6| Step: 10
Training loss: 2.5512218475341797
Validation loss: 2.2607713540395102

Epoch: 6| Step: 11
Training loss: 1.6060699224472046
Validation loss: 2.2674181858698526

Epoch: 6| Step: 12
Training loss: 1.016434907913208
Validation loss: 2.261453092098236

Epoch: 6| Step: 13
Training loss: 1.0855045318603516
Validation loss: 2.247699737548828

Epoch: 274| Step: 0
Training loss: 1.5417665243148804
Validation loss: 2.244906564553579

Epoch: 6| Step: 1
Training loss: 2.002878189086914
Validation loss: 2.230237682660421

Epoch: 6| Step: 2
Training loss: 1.5173250436782837
Validation loss: 2.221349914868673

Epoch: 6| Step: 3
Training loss: 1.6164621114730835
Validation loss: 2.214685340722402

Epoch: 6| Step: 4
Training loss: 1.8053109645843506
Validation loss: 2.239090383052826

Epoch: 6| Step: 5
Training loss: 1.3060669898986816
Validation loss: 2.2249834537506104

Epoch: 6| Step: 6
Training loss: 1.8070454597473145
Validation loss: 2.249339759349823

Epoch: 6| Step: 7
Training loss: 1.171750783920288
Validation loss: 2.2259167035420737

Epoch: 6| Step: 8
Training loss: 1.9632669687271118
Validation loss: 2.2678087751070657

Epoch: 6| Step: 9
Training loss: 2.477046012878418
Validation loss: 2.2665147185325623

Epoch: 6| Step: 10
Training loss: 2.4146625995635986
Validation loss: 2.2518139282862344

Epoch: 6| Step: 11
Training loss: 2.015873432159424
Validation loss: 2.284956693649292

Epoch: 6| Step: 12
Training loss: 1.692350149154663
Validation loss: 2.264840066432953

Epoch: 6| Step: 13
Training loss: 1.7640899419784546
Validation loss: 2.2740939458211265

Epoch: 275| Step: 0
Training loss: 1.975708246231079
Validation loss: 2.2489596009254456

Epoch: 6| Step: 1
Training loss: 1.3998920917510986
Validation loss: 2.2498960892359414

Epoch: 6| Step: 2
Training loss: 1.6929872035980225
Validation loss: 2.2538787722587585

Epoch: 6| Step: 3
Training loss: 2.2569408416748047
Validation loss: 2.225322703520457

Epoch: 6| Step: 4
Training loss: 1.3714004755020142
Validation loss: 2.244207044442495

Epoch: 6| Step: 5
Training loss: 1.378554105758667
Validation loss: 2.2115668058395386

Epoch: 6| Step: 6
Training loss: 1.2947849035263062
Validation loss: 2.1954360008239746

Epoch: 6| Step: 7
Training loss: 1.5852251052856445
Validation loss: 2.194002906481425

Epoch: 6| Step: 8
Training loss: 2.4396300315856934
Validation loss: 2.21018252770106

Epoch: 6| Step: 9
Training loss: 1.96904456615448
Validation loss: 2.2119312286376953

Epoch: 6| Step: 10
Training loss: 2.1855175495147705
Validation loss: 2.225926995277405

Epoch: 6| Step: 11
Training loss: 2.55125093460083
Validation loss: 2.2428344090779624

Epoch: 6| Step: 12
Training loss: 1.6517055034637451
Validation loss: 2.2800386349360147

Epoch: 6| Step: 13
Training loss: 1.3508367538452148
Validation loss: 2.2488508423169455

Epoch: 276| Step: 0
Training loss: 1.7403713464736938
Validation loss: 2.264844059944153

Epoch: 6| Step: 1
Training loss: 1.6410428285598755
Validation loss: 2.2706106106440225

Epoch: 6| Step: 2
Training loss: 1.8527586460113525
Validation loss: 2.2492496967315674

Epoch: 6| Step: 3
Training loss: 1.4851747751235962
Validation loss: 2.2822059988975525

Epoch: 6| Step: 4
Training loss: 1.7336630821228027
Validation loss: 2.2513904770215354

Epoch: 6| Step: 5
Training loss: 1.5722837448120117
Validation loss: 2.2284393906593323

Epoch: 6| Step: 6
Training loss: 2.039832830429077
Validation loss: 2.2270325422286987

Epoch: 6| Step: 7
Training loss: 2.5284945964813232
Validation loss: 2.2253417571385703

Epoch: 6| Step: 8
Training loss: 1.6272759437561035
Validation loss: 2.241758565107981

Epoch: 6| Step: 9
Training loss: 2.400522470474243
Validation loss: 2.2271403471628823

Epoch: 6| Step: 10
Training loss: 1.3268389701843262
Validation loss: 2.2485963900883994

Epoch: 6| Step: 11
Training loss: 1.733712911605835
Validation loss: 2.2549255092938743

Epoch: 6| Step: 12
Training loss: 1.4109516143798828
Validation loss: 2.260647634665171

Epoch: 6| Step: 13
Training loss: 1.945870041847229
Validation loss: 2.2962255676587424

Epoch: 277| Step: 0
Training loss: 1.9887856245040894
Validation loss: 2.3205251693725586

Epoch: 6| Step: 1
Training loss: 2.2434334754943848
Validation loss: 2.297744870185852

Epoch: 6| Step: 2
Training loss: 2.0197372436523438
Validation loss: 2.2934654553731284

Epoch: 6| Step: 3
Training loss: 1.4599393606185913
Validation loss: 2.2751077016194663

Epoch: 6| Step: 4
Training loss: 1.7477941513061523
Validation loss: 2.2532995144526162

Epoch: 6| Step: 5
Training loss: 1.6878963708877563
Validation loss: 2.264338572820028

Epoch: 6| Step: 6
Training loss: 0.8140324354171753
Validation loss: 2.2502731879552207

Epoch: 6| Step: 7
Training loss: 1.7863153219223022
Validation loss: 2.233521024386088

Epoch: 6| Step: 8
Training loss: 2.222759962081909
Validation loss: 2.2439295649528503

Epoch: 6| Step: 9
Training loss: 1.6855919361114502
Validation loss: 2.24250328540802

Epoch: 6| Step: 10
Training loss: 2.393488883972168
Validation loss: 2.228575905164083

Epoch: 6| Step: 11
Training loss: 1.1567919254302979
Validation loss: 2.25776473681132

Epoch: 6| Step: 12
Training loss: 1.7183178663253784
Validation loss: 2.261945048967997

Epoch: 6| Step: 13
Training loss: 1.7684614658355713
Validation loss: 2.2639277974764505

Epoch: 278| Step: 0
Training loss: 1.6107686758041382
Validation loss: 2.25653346379598

Epoch: 6| Step: 1
Training loss: 2.2296788692474365
Validation loss: 2.26198140780131

Epoch: 6| Step: 2
Training loss: 1.4936702251434326
Validation loss: 2.273746371269226

Epoch: 6| Step: 3
Training loss: 1.6126679182052612
Validation loss: 2.2600719928741455

Epoch: 6| Step: 4
Training loss: 1.8929356336593628
Validation loss: 2.242788553237915

Epoch: 6| Step: 5
Training loss: 1.6925042867660522
Validation loss: 2.2319029768308005

Epoch: 6| Step: 6
Training loss: 2.241305351257324
Validation loss: 2.245343863964081

Epoch: 6| Step: 7
Training loss: 1.2844476699829102
Validation loss: 2.251645545164744

Epoch: 6| Step: 8
Training loss: 1.142806053161621
Validation loss: 2.238785703976949

Epoch: 6| Step: 9
Training loss: 2.3691515922546387
Validation loss: 2.2551257610321045

Epoch: 6| Step: 10
Training loss: 2.2573633193969727
Validation loss: 2.2378211418787637

Epoch: 6| Step: 11
Training loss: 1.3421170711517334
Validation loss: 2.244969149430593

Epoch: 6| Step: 12
Training loss: 1.8172425031661987
Validation loss: 2.2548606793085733

Epoch: 6| Step: 13
Training loss: 1.5849984884262085
Validation loss: 2.2647205591201782

Epoch: 279| Step: 0
Training loss: 2.129739284515381
Validation loss: 2.261363665262858

Epoch: 6| Step: 1
Training loss: 1.0173308849334717
Validation loss: 2.261755108833313

Epoch: 6| Step: 2
Training loss: 1.973327398300171
Validation loss: 2.2985450426737466

Epoch: 6| Step: 3
Training loss: 1.5218162536621094
Validation loss: 2.2596170902252197

Epoch: 6| Step: 4
Training loss: 2.130399703979492
Validation loss: 2.306140104929606

Epoch: 6| Step: 5
Training loss: 1.4903589487075806
Validation loss: 2.2902082999547324

Epoch: 6| Step: 6
Training loss: 1.2215626239776611
Validation loss: 2.290998717149099

Epoch: 6| Step: 7
Training loss: 1.9211132526397705
Validation loss: 2.3151835401852927

Epoch: 6| Step: 8
Training loss: 1.544417142868042
Validation loss: 2.2950586875279746

Epoch: 6| Step: 9
Training loss: 2.1394121646881104
Validation loss: 2.2560704946517944

Epoch: 6| Step: 10
Training loss: 1.218714714050293
Validation loss: 2.283363660176595

Epoch: 6| Step: 11
Training loss: 2.306382894515991
Validation loss: 2.272704005241394

Epoch: 6| Step: 12
Training loss: 1.6661181449890137
Validation loss: 2.239655335744222

Epoch: 6| Step: 13
Training loss: 2.0713462829589844
Validation loss: 2.2425864338874817

Epoch: 280| Step: 0
Training loss: 1.197040319442749
Validation loss: 2.245619455973307

Epoch: 6| Step: 1
Training loss: 2.0593442916870117
Validation loss: 2.2495129903157554

Epoch: 6| Step: 2
Training loss: 1.696864366531372
Validation loss: 2.2265775203704834

Epoch: 6| Step: 3
Training loss: 1.61794114112854
Validation loss: 2.232527017593384

Epoch: 6| Step: 4
Training loss: 2.2210636138916016
Validation loss: 2.2384479641914368

Epoch: 6| Step: 5
Training loss: 1.6472753286361694
Validation loss: 2.228655974070231

Epoch: 6| Step: 6
Training loss: 1.9568495750427246
Validation loss: 2.20270973443985

Epoch: 6| Step: 7
Training loss: 1.7542550563812256
Validation loss: 2.2074574629465737

Epoch: 6| Step: 8
Training loss: 1.5902917385101318
Validation loss: 2.2385224103927612

Epoch: 6| Step: 9
Training loss: 1.2585783004760742
Validation loss: 2.2501729329427085

Epoch: 6| Step: 10
Training loss: 0.6495673656463623
Validation loss: 2.2640593449274697

Epoch: 6| Step: 11
Training loss: 2.4175097942352295
Validation loss: 2.2486974795659385

Epoch: 6| Step: 12
Training loss: 2.252749443054199
Validation loss: 2.2627788384755454

Epoch: 6| Step: 13
Training loss: 2.086336851119995
Validation loss: 2.290975491205851

Epoch: 281| Step: 0
Training loss: 2.0847387313842773
Validation loss: 2.263393759727478

Epoch: 6| Step: 1
Training loss: 2.1548619270324707
Validation loss: 2.277152101198832

Epoch: 6| Step: 2
Training loss: 1.302951693534851
Validation loss: 2.267616868019104

Epoch: 6| Step: 3
Training loss: 1.8866429328918457
Validation loss: 2.277731776237488

Epoch: 6| Step: 4
Training loss: 1.474524974822998
Validation loss: 2.281149466832479

Epoch: 6| Step: 5
Training loss: 1.862914800643921
Validation loss: 2.252820869286855

Epoch: 6| Step: 6
Training loss: 1.3411312103271484
Validation loss: 2.28507665793101

Epoch: 6| Step: 7
Training loss: 1.9346684217453003
Validation loss: 2.2689425150553384

Epoch: 6| Step: 8
Training loss: 1.0652990341186523
Validation loss: 2.254459857940674

Epoch: 6| Step: 9
Training loss: 1.772903561592102
Validation loss: 2.247103452682495

Epoch: 6| Step: 10
Training loss: 1.4631452560424805
Validation loss: 2.2544583876927695

Epoch: 6| Step: 11
Training loss: 2.154198169708252
Validation loss: 2.244712551434835

Epoch: 6| Step: 12
Training loss: 2.0333471298217773
Validation loss: 2.2159049113591514

Epoch: 6| Step: 13
Training loss: 1.560298204421997
Validation loss: 2.2241360346476235

Epoch: 282| Step: 0
Training loss: 1.5375590324401855
Validation loss: 2.227864424387614

Epoch: 6| Step: 1
Training loss: 2.092996597290039
Validation loss: 2.2145761052767434

Epoch: 6| Step: 2
Training loss: 2.023232936859131
Validation loss: 2.2153621912002563

Epoch: 6| Step: 3
Training loss: 1.8247991800308228
Validation loss: 2.2058199048042297

Epoch: 6| Step: 4
Training loss: 2.129223346710205
Validation loss: 2.2251513600349426

Epoch: 6| Step: 5
Training loss: 1.1794061660766602
Validation loss: 2.2449636459350586

Epoch: 6| Step: 6
Training loss: 2.155771255493164
Validation loss: 2.243384758631388

Epoch: 6| Step: 7
Training loss: 1.570565104484558
Validation loss: 2.250499884287516

Epoch: 6| Step: 8
Training loss: 1.8996316194534302
Validation loss: 2.306232770284017

Epoch: 6| Step: 9
Training loss: 1.6793432235717773
Validation loss: 2.285132805506388

Epoch: 6| Step: 10
Training loss: 1.39286470413208
Validation loss: 2.3137813011805215

Epoch: 6| Step: 11
Training loss: 1.2734369039535522
Validation loss: 2.298214395840963

Epoch: 6| Step: 12
Training loss: 2.2326033115386963
Validation loss: 2.275621851285299

Epoch: 6| Step: 13
Training loss: 1.821221113204956
Validation loss: 2.249379873275757

Epoch: 283| Step: 0
Training loss: 1.9634788036346436
Validation loss: 2.2699103355407715

Epoch: 6| Step: 1
Training loss: 1.7844884395599365
Validation loss: 2.242270549138387

Epoch: 6| Step: 2
Training loss: 1.9993479251861572
Validation loss: 2.2547593911488852

Epoch: 6| Step: 3
Training loss: 1.3107361793518066
Validation loss: 2.210688312848409

Epoch: 6| Step: 4
Training loss: 2.3184814453125
Validation loss: 2.2189928690592446

Epoch: 6| Step: 5
Training loss: 1.5820577144622803
Validation loss: 2.1953984101613364

Epoch: 6| Step: 6
Training loss: 1.8168370723724365
Validation loss: 2.1884328921635947

Epoch: 6| Step: 7
Training loss: 1.4153658151626587
Validation loss: 2.1857404708862305

Epoch: 6| Step: 8
Training loss: 1.7152247428894043
Validation loss: 2.1977482438087463

Epoch: 6| Step: 9
Training loss: 2.5421247482299805
Validation loss: 2.1904422442118325

Epoch: 6| Step: 10
Training loss: 1.85456383228302
Validation loss: 2.1740724245707193

Epoch: 6| Step: 11
Training loss: 2.353289842605591
Validation loss: 2.1954636772473655

Epoch: 6| Step: 12
Training loss: 1.9352049827575684
Validation loss: 2.1971678535143533

Epoch: 6| Step: 13
Training loss: 1.2640817165374756
Validation loss: 2.197028915087382

Epoch: 284| Step: 0
Training loss: 2.144406795501709
Validation loss: 2.221245288848877

Epoch: 6| Step: 1
Training loss: 2.02131986618042
Validation loss: 2.2000449299812317

Epoch: 6| Step: 2
Training loss: 1.462999939918518
Validation loss: 2.2101289431254068

Epoch: 6| Step: 3
Training loss: 1.5296239852905273
Validation loss: 2.213231881459554

Epoch: 6| Step: 4
Training loss: 1.3115007877349854
Validation loss: 2.1975218256314597

Epoch: 6| Step: 5
Training loss: 2.0667548179626465
Validation loss: 2.1918572584788003

Epoch: 6| Step: 6
Training loss: 1.6235320568084717
Validation loss: 2.20403923590978

Epoch: 6| Step: 7
Training loss: 1.78269624710083
Validation loss: 2.208006044228872

Epoch: 6| Step: 8
Training loss: 1.3248271942138672
Validation loss: 2.202385107676188

Epoch: 6| Step: 9
Training loss: 2.3407607078552246
Validation loss: 2.210330824057261

Epoch: 6| Step: 10
Training loss: 2.2538890838623047
Validation loss: 2.172312060991923

Epoch: 6| Step: 11
Training loss: 2.0219225883483887
Validation loss: 2.2013983925183616

Epoch: 6| Step: 12
Training loss: 2.025003433227539
Validation loss: 2.181295871734619

Epoch: 6| Step: 13
Training loss: 2.3715457916259766
Validation loss: 2.200032333532969

Epoch: 285| Step: 0
Training loss: 2.1865532398223877
Validation loss: 2.1964836915334067

Epoch: 6| Step: 1
Training loss: 1.2329585552215576
Validation loss: 2.20145054658254

Epoch: 6| Step: 2
Training loss: 1.6491886377334595
Validation loss: 2.2037812074025473

Epoch: 6| Step: 3
Training loss: 2.151169538497925
Validation loss: 2.185154438018799

Epoch: 6| Step: 4
Training loss: 1.9989135265350342
Validation loss: 2.206032077471415

Epoch: 6| Step: 5
Training loss: 1.8808705806732178
Validation loss: 2.190492351849874

Epoch: 6| Step: 6
Training loss: 1.512519359588623
Validation loss: 2.224949518839518

Epoch: 6| Step: 7
Training loss: 1.4837520122528076
Validation loss: 2.2156952023506165

Epoch: 6| Step: 8
Training loss: 1.4884358644485474
Validation loss: 2.187716066837311

Epoch: 6| Step: 9
Training loss: 1.818408489227295
Validation loss: 2.2082108656565347

Epoch: 6| Step: 10
Training loss: 1.8032429218292236
Validation loss: 2.200241287549337

Epoch: 6| Step: 11
Training loss: 2.1741750240325928
Validation loss: 2.1883281469345093

Epoch: 6| Step: 12
Training loss: 1.2809157371520996
Validation loss: 2.1984402338663735

Epoch: 6| Step: 13
Training loss: 2.473519802093506
Validation loss: 2.2007415890693665

Epoch: 286| Step: 0
Training loss: 1.9678399562835693
Validation loss: 2.19483749071757

Epoch: 6| Step: 1
Training loss: 2.1018340587615967
Validation loss: 2.1890586415926614

Epoch: 6| Step: 2
Training loss: 2.2479519844055176
Validation loss: 2.2092175483703613

Epoch: 6| Step: 3
Training loss: 1.3201831579208374
Validation loss: 2.189358671506246

Epoch: 6| Step: 4
Training loss: 2.1727657318115234
Validation loss: 2.2101553678512573

Epoch: 6| Step: 5
Training loss: 1.8587528467178345
Validation loss: 2.1736900210380554

Epoch: 6| Step: 6
Training loss: 1.4380369186401367
Validation loss: 2.1995097001393638

Epoch: 6| Step: 7
Training loss: 1.4791845083236694
Validation loss: 2.218679924805959

Epoch: 6| Step: 8
Training loss: 1.6305582523345947
Validation loss: 2.1846235394477844

Epoch: 6| Step: 9
Training loss: 1.6550487279891968
Validation loss: 2.2151973446210227

Epoch: 6| Step: 10
Training loss: 2.1177330017089844
Validation loss: 2.1875661611557007

Epoch: 6| Step: 11
Training loss: 1.038008451461792
Validation loss: 2.202118436495463

Epoch: 6| Step: 12
Training loss: 1.6294342279434204
Validation loss: 2.191430687904358

Epoch: 6| Step: 13
Training loss: 2.100767135620117
Validation loss: 2.1753483215967813

Epoch: 287| Step: 0
Training loss: 2.0586934089660645
Validation loss: 2.1980188687642417

Epoch: 6| Step: 1
Training loss: 2.0451881885528564
Validation loss: 2.2173189520835876

Epoch: 6| Step: 2
Training loss: 1.4652481079101562
Validation loss: 2.2089455922444663

Epoch: 6| Step: 3
Training loss: 1.9157347679138184
Validation loss: 2.237682898839315

Epoch: 6| Step: 4
Training loss: 1.419476866722107
Validation loss: 2.2387933333714805

Epoch: 6| Step: 5
Training loss: 1.7965444326400757
Validation loss: 2.2485732237497964

Epoch: 6| Step: 6
Training loss: 1.1626619100570679
Validation loss: 2.2542591492335

Epoch: 6| Step: 7
Training loss: 1.4424095153808594
Validation loss: 2.2388485272725425

Epoch: 6| Step: 8
Training loss: 1.6004045009613037
Validation loss: 2.272944529851278

Epoch: 6| Step: 9
Training loss: 2.285468578338623
Validation loss: 2.2786043286323547

Epoch: 6| Step: 10
Training loss: 1.83450186252594
Validation loss: 2.2434117992719016

Epoch: 6| Step: 11
Training loss: 1.113818645477295
Validation loss: 2.2500940561294556

Epoch: 6| Step: 12
Training loss: 1.5684055089950562
Validation loss: 2.243205189704895

Epoch: 6| Step: 13
Training loss: 2.5356414318084717
Validation loss: 2.252650558948517

Epoch: 288| Step: 0
Training loss: 1.5944747924804688
Validation loss: 2.2696359157562256

Epoch: 6| Step: 1
Training loss: 1.3961983919143677
Validation loss: 2.265310287475586

Epoch: 6| Step: 2
Training loss: 1.6449308395385742
Validation loss: 2.262619137763977

Epoch: 6| Step: 3
Training loss: 1.4739261865615845
Validation loss: 2.2716423869132996

Epoch: 6| Step: 4
Training loss: 2.1792192459106445
Validation loss: 2.2621132135391235

Epoch: 6| Step: 5
Training loss: 1.6370093822479248
Validation loss: 2.228570520877838

Epoch: 6| Step: 6
Training loss: 1.8125077486038208
Validation loss: 2.2332587242126465

Epoch: 6| Step: 7
Training loss: 1.000301480293274
Validation loss: 2.2382206320762634

Epoch: 6| Step: 8
Training loss: 2.444917917251587
Validation loss: 2.227810502052307

Epoch: 6| Step: 9
Training loss: 2.066166877746582
Validation loss: 2.2548441290855408

Epoch: 6| Step: 10
Training loss: 1.636000633239746
Validation loss: 2.263364394505819

Epoch: 6| Step: 11
Training loss: 2.159808874130249
Validation loss: 2.243120531241099

Epoch: 6| Step: 12
Training loss: 1.19667387008667
Validation loss: 2.281354308128357

Epoch: 6| Step: 13
Training loss: 1.7583675384521484
Validation loss: 2.2929158012072244

Epoch: 289| Step: 0
Training loss: 1.8914991617202759
Validation loss: 2.325430711110433

Epoch: 6| Step: 1
Training loss: 1.5883582830429077
Validation loss: 2.300997277100881

Epoch: 6| Step: 2
Training loss: 1.74492609500885
Validation loss: 2.295221189657847

Epoch: 6| Step: 3
Training loss: 2.318970203399658
Validation loss: 2.2865283489227295

Epoch: 6| Step: 4
Training loss: 1.0545170307159424
Validation loss: 2.2837599913279214

Epoch: 6| Step: 5
Training loss: 1.3772424459457397
Validation loss: 2.2675132354100547

Epoch: 6| Step: 6
Training loss: 1.5784660577774048
Validation loss: 2.2672230005264282

Epoch: 6| Step: 7
Training loss: 2.2090582847595215
Validation loss: 2.2658853928248086

Epoch: 6| Step: 8
Training loss: 3.005671262741089
Validation loss: 2.292897661526998

Epoch: 6| Step: 9
Training loss: 1.606445550918579
Validation loss: 2.2903117736180625

Epoch: 6| Step: 10
Training loss: 1.559177279472351
Validation loss: 2.286629319190979

Epoch: 6| Step: 11
Training loss: 1.4592275619506836
Validation loss: 2.2884055376052856

Epoch: 6| Step: 12
Training loss: 1.8974945545196533
Validation loss: 2.324926277001699

Epoch: 6| Step: 13
Training loss: 1.2694675922393799
Validation loss: 2.2800636688868203

Epoch: 290| Step: 0
Training loss: 2.308969497680664
Validation loss: 2.2918597062428794

Epoch: 6| Step: 1
Training loss: 1.6487585306167603
Validation loss: 2.304336349169413

Epoch: 6| Step: 2
Training loss: 1.4183475971221924
Validation loss: 2.2757567962010703

Epoch: 6| Step: 3
Training loss: 2.191852569580078
Validation loss: 2.286203145980835

Epoch: 6| Step: 4
Training loss: 1.7972924709320068
Validation loss: 2.2816179593404136

Epoch: 6| Step: 5
Training loss: 1.4205137491226196
Validation loss: 2.258856952190399

Epoch: 6| Step: 6
Training loss: 1.4039833545684814
Validation loss: 2.2591576178868613

Epoch: 6| Step: 7
Training loss: 1.153488039970398
Validation loss: 2.2552606662114463

Epoch: 6| Step: 8
Training loss: 2.6319289207458496
Validation loss: 2.248789886633555

Epoch: 6| Step: 9
Training loss: 1.6645349264144897
Validation loss: 2.267938574155172

Epoch: 6| Step: 10
Training loss: 1.5903115272521973
Validation loss: 2.2568693359692893

Epoch: 6| Step: 11
Training loss: 1.8684674501419067
Validation loss: 2.275494317213694

Epoch: 6| Step: 12
Training loss: 1.2322750091552734
Validation loss: 2.2669663429260254

Epoch: 6| Step: 13
Training loss: 1.760019063949585
Validation loss: 2.296223998069763

Epoch: 291| Step: 0
Training loss: 1.286181926727295
Validation loss: 2.306602418422699

Epoch: 6| Step: 1
Training loss: 2.015047550201416
Validation loss: 2.3215147058169046

Epoch: 6| Step: 2
Training loss: 1.2931127548217773
Validation loss: 2.3051466941833496

Epoch: 6| Step: 3
Training loss: 1.9960296154022217
Validation loss: 2.293014168739319

Epoch: 6| Step: 4
Training loss: 1.6867992877960205
Validation loss: 2.276045640309652

Epoch: 6| Step: 5
Training loss: 2.0290043354034424
Validation loss: 2.252036690711975

Epoch: 6| Step: 6
Training loss: 2.0323729515075684
Validation loss: 2.2972970406214395

Epoch: 6| Step: 7
Training loss: 1.69155752658844
Validation loss: 2.2879499594370523

Epoch: 6| Step: 8
Training loss: 1.0300408601760864
Validation loss: 2.252848744392395

Epoch: 6| Step: 9
Training loss: 1.483716607093811
Validation loss: 2.266696830590566

Epoch: 6| Step: 10
Training loss: 2.2414560317993164
Validation loss: 2.249394118785858

Epoch: 6| Step: 11
Training loss: 1.5846033096313477
Validation loss: 2.2613518635431924

Epoch: 6| Step: 12
Training loss: 1.6821198463439941
Validation loss: 2.255977233250936

Epoch: 6| Step: 13
Training loss: 1.9533195495605469
Validation loss: 2.2791107892990112

Epoch: 292| Step: 0
Training loss: 0.9784998297691345
Validation loss: 2.2717405557632446

Epoch: 6| Step: 1
Training loss: 1.7212183475494385
Validation loss: 2.2721362113952637

Epoch: 6| Step: 2
Training loss: 1.9286701679229736
Validation loss: 2.2945976654688516

Epoch: 6| Step: 3
Training loss: 1.6013718843460083
Validation loss: 2.3141127228736877

Epoch: 6| Step: 4
Training loss: 1.3792462348937988
Validation loss: 2.2860718369483948

Epoch: 6| Step: 5
Training loss: 2.0884528160095215
Validation loss: 2.3085702459017434

Epoch: 6| Step: 6
Training loss: 1.8168784379959106
Validation loss: 2.3269004027048745

Epoch: 6| Step: 7
Training loss: 1.9021098613739014
Validation loss: 2.31525049606959

Epoch: 6| Step: 8
Training loss: 1.9024693965911865
Validation loss: 2.311297078927358

Epoch: 6| Step: 9
Training loss: 2.0379433631896973
Validation loss: 2.325777987639109

Epoch: 6| Step: 10
Training loss: 1.9508769512176514
Validation loss: 2.2958821256955466

Epoch: 6| Step: 11
Training loss: 1.5341253280639648
Validation loss: 2.2834583123524985

Epoch: 6| Step: 12
Training loss: 1.4312975406646729
Validation loss: 2.284917414188385

Epoch: 6| Step: 13
Training loss: 1.6051137447357178
Validation loss: 2.284925123055776

Epoch: 293| Step: 0
Training loss: 1.3226302862167358
Validation loss: 2.240866462389628

Epoch: 6| Step: 1
Training loss: 1.3506258726119995
Validation loss: 2.25286865234375

Epoch: 6| Step: 2
Training loss: 1.5426615476608276
Validation loss: 2.2405596574147544

Epoch: 6| Step: 3
Training loss: 1.8273950815200806
Validation loss: 2.2358680168787637

Epoch: 6| Step: 4
Training loss: 1.448312759399414
Validation loss: 2.2330676913261414

Epoch: 6| Step: 5
Training loss: 2.023530960083008
Validation loss: 2.2129627664883933

Epoch: 6| Step: 6
Training loss: 2.2171850204467773
Validation loss: 2.2163286010424295

Epoch: 6| Step: 7
Training loss: 1.8863863945007324
Validation loss: 2.2118279536565146

Epoch: 6| Step: 8
Training loss: 2.571859359741211
Validation loss: 2.234081526597341

Epoch: 6| Step: 9
Training loss: 1.6039292812347412
Validation loss: 2.238223055998484

Epoch: 6| Step: 10
Training loss: 2.287522315979004
Validation loss: 2.252769668896993

Epoch: 6| Step: 11
Training loss: 1.4895819425582886
Validation loss: 2.2758304675420127

Epoch: 6| Step: 12
Training loss: 1.2707716226577759
Validation loss: 2.245139201482137

Epoch: 6| Step: 13
Training loss: 1.747797966003418
Validation loss: 2.233157197634379

Epoch: 294| Step: 0
Training loss: 1.9311579465866089
Validation loss: 2.2411188085873923

Epoch: 6| Step: 1
Training loss: 1.776076078414917
Validation loss: 2.2465489308039346

Epoch: 6| Step: 2
Training loss: 1.7302565574645996
Validation loss: 2.232762634754181

Epoch: 6| Step: 3
Training loss: 1.8385074138641357
Validation loss: 2.249490658442179

Epoch: 6| Step: 4
Training loss: 1.9695955514907837
Validation loss: 2.239710807800293

Epoch: 6| Step: 5
Training loss: 1.7090121507644653
Validation loss: 2.2705572644869485

Epoch: 6| Step: 6
Training loss: 2.4975390434265137
Validation loss: 2.259695529937744

Epoch: 6| Step: 7
Training loss: 1.3404333591461182
Validation loss: 2.2626949747403464

Epoch: 6| Step: 8
Training loss: 1.2480823993682861
Validation loss: 2.2885905504226685

Epoch: 6| Step: 9
Training loss: 1.2610152959823608
Validation loss: 2.275260309378306

Epoch: 6| Step: 10
Training loss: 1.6557995080947876
Validation loss: 2.2914549708366394

Epoch: 6| Step: 11
Training loss: 1.1862436532974243
Validation loss: 2.3150190114974976

Epoch: 6| Step: 12
Training loss: 2.0963330268859863
Validation loss: 2.3054600954055786

Epoch: 6| Step: 13
Training loss: 1.7556703090667725
Validation loss: 2.283232490221659

Epoch: 295| Step: 0
Training loss: 1.9906047582626343
Validation loss: 2.3037531773249307

Epoch: 6| Step: 1
Training loss: 1.4799987077713013
Validation loss: 2.308570623397827

Epoch: 6| Step: 2
Training loss: 1.6052124500274658
Validation loss: 2.283639450867971

Epoch: 6| Step: 3
Training loss: 2.116337537765503
Validation loss: 2.268457571665446

Epoch: 6| Step: 4
Training loss: 1.4292951822280884
Validation loss: 2.2487715681393943

Epoch: 6| Step: 5
Training loss: 1.9260356426239014
Validation loss: 2.2155858675638833

Epoch: 6| Step: 6
Training loss: 1.7355265617370605
Validation loss: 2.2175605297088623

Epoch: 6| Step: 7
Training loss: 1.0950779914855957
Validation loss: 2.2326560417811074

Epoch: 6| Step: 8
Training loss: 1.8387950658798218
Validation loss: 2.233230551083883

Epoch: 6| Step: 9
Training loss: 2.2030889987945557
Validation loss: 2.229131897290548

Epoch: 6| Step: 10
Training loss: 1.1494543552398682
Validation loss: 2.216054916381836

Epoch: 6| Step: 11
Training loss: 1.9471964836120605
Validation loss: 2.245061198870341

Epoch: 6| Step: 12
Training loss: 1.9059334993362427
Validation loss: 2.2400068442026773

Epoch: 6| Step: 13
Training loss: 1.9512778520584106
Validation loss: 2.2564021150271096

Epoch: 296| Step: 0
Training loss: 2.213047981262207
Validation loss: 2.296521464983622

Epoch: 6| Step: 1
Training loss: 1.9809999465942383
Validation loss: 2.2921255032221475

Epoch: 6| Step: 2
Training loss: 1.9042426347732544
Validation loss: 2.281333645184835

Epoch: 6| Step: 3
Training loss: 1.252784252166748
Validation loss: 2.307440161705017

Epoch: 6| Step: 4
Training loss: 2.117295742034912
Validation loss: 2.2819407979647317

Epoch: 6| Step: 5
Training loss: 1.0530602931976318
Validation loss: 2.289232770601908

Epoch: 6| Step: 6
Training loss: 1.7460763454437256
Validation loss: 2.2822433710098267

Epoch: 6| Step: 7
Training loss: 2.402482032775879
Validation loss: 2.2681228121121726

Epoch: 6| Step: 8
Training loss: 1.6564230918884277
Validation loss: 2.2553537487983704

Epoch: 6| Step: 9
Training loss: 1.3990559577941895
Validation loss: 2.274231771628062

Epoch: 6| Step: 10
Training loss: 1.3338301181793213
Validation loss: 2.2507387002309165

Epoch: 6| Step: 11
Training loss: 1.3118574619293213
Validation loss: 2.261436661084493

Epoch: 6| Step: 12
Training loss: 1.9828639030456543
Validation loss: 2.2821164727211

Epoch: 6| Step: 13
Training loss: 1.8820569515228271
Validation loss: 2.2468535701433816

Epoch: 297| Step: 0
Training loss: 1.6786935329437256
Validation loss: 2.260796149571737

Epoch: 6| Step: 1
Training loss: 1.4468908309936523
Validation loss: 2.2341756025950112

Epoch: 6| Step: 2
Training loss: 1.7795425653457642
Validation loss: 2.276230255762736

Epoch: 6| Step: 3
Training loss: 1.6765131950378418
Validation loss: 2.2455044984817505

Epoch: 6| Step: 4
Training loss: 1.563126802444458
Validation loss: 2.3015518387158713

Epoch: 6| Step: 5
Training loss: 1.7233096361160278
Validation loss: 2.296224276224772

Epoch: 6| Step: 6
Training loss: 2.1856467723846436
Validation loss: 2.259688158830007

Epoch: 6| Step: 7
Training loss: 1.200585126876831
Validation loss: 2.280331611633301

Epoch: 6| Step: 8
Training loss: 1.6198267936706543
Validation loss: 2.2497396071751914

Epoch: 6| Step: 9
Training loss: 2.540515899658203
Validation loss: 2.2215069929758706

Epoch: 6| Step: 10
Training loss: 1.892155408859253
Validation loss: 2.22384520371755

Epoch: 6| Step: 11
Training loss: 2.177704334259033
Validation loss: 2.2008034189542136

Epoch: 6| Step: 12
Training loss: 1.5699217319488525
Validation loss: 2.1992271542549133

Epoch: 6| Step: 13
Training loss: 1.1826646327972412
Validation loss: 2.2320982813835144

Epoch: 298| Step: 0
Training loss: 1.7781658172607422
Validation loss: 2.211142122745514

Epoch: 6| Step: 1
Training loss: 2.003065824508667
Validation loss: 2.236563821633657

Epoch: 6| Step: 2
Training loss: 1.6799559593200684
Validation loss: 2.258273263772329

Epoch: 6| Step: 3
Training loss: 1.6445164680480957
Validation loss: 2.2568394343058267

Epoch: 6| Step: 4
Training loss: 1.9971232414245605
Validation loss: 2.2536145448684692

Epoch: 6| Step: 5
Training loss: 1.5766310691833496
Validation loss: 2.2321024934450784

Epoch: 6| Step: 6
Training loss: 1.1155316829681396
Validation loss: 2.2513003746668496

Epoch: 6| Step: 7
Training loss: 1.598384141921997
Validation loss: 2.253414571285248

Epoch: 6| Step: 8
Training loss: 1.5479906797409058
Validation loss: 2.2367542386054993

Epoch: 6| Step: 9
Training loss: 1.3059715032577515
Validation loss: 2.2561567624409995

Epoch: 6| Step: 10
Training loss: 1.7653270959854126
Validation loss: 2.2630565563837686

Epoch: 6| Step: 11
Training loss: 1.2450101375579834
Validation loss: 2.2681551575660706

Epoch: 6| Step: 12
Training loss: 2.677788257598877
Validation loss: 2.266269326210022

Epoch: 6| Step: 13
Training loss: 1.969590425491333
Validation loss: 2.23624457915624

Epoch: 299| Step: 0
Training loss: 1.9333585500717163
Validation loss: 2.2491785089174905

Epoch: 6| Step: 1
Training loss: 1.2959580421447754
Validation loss: 2.2654837369918823

Epoch: 6| Step: 2
Training loss: 2.0150058269500732
Validation loss: 2.278794785340627

Epoch: 6| Step: 3
Training loss: 1.6318399906158447
Validation loss: 2.261939803759257

Epoch: 6| Step: 4
Training loss: 2.106261730194092
Validation loss: 2.2806764046351113

Epoch: 6| Step: 5
Training loss: 2.204874038696289
Validation loss: 2.3091726700464883

Epoch: 6| Step: 6
Training loss: 1.5413768291473389
Validation loss: 2.3066431283950806

Epoch: 6| Step: 7
Training loss: 2.231092929840088
Validation loss: 2.315410614013672

Epoch: 6| Step: 8
Training loss: 1.8559186458587646
Validation loss: 2.2838116884231567

Epoch: 6| Step: 9
Training loss: 1.544252872467041
Validation loss: 2.2726653814315796

Epoch: 6| Step: 10
Training loss: 1.457385778427124
Validation loss: 2.267531375090281

Epoch: 6| Step: 11
Training loss: 1.7164009809494019
Validation loss: 2.264745573202769

Epoch: 6| Step: 12
Training loss: 1.7041168212890625
Validation loss: 2.252887407938639

Epoch: 6| Step: 13
Training loss: 1.763723373413086
Validation loss: 2.2377531131108603

Epoch: 300| Step: 0
Training loss: 1.7056066989898682
Validation loss: 2.2297181487083435

Epoch: 6| Step: 1
Training loss: 1.884000301361084
Validation loss: 2.226746400197347

Epoch: 6| Step: 2
Training loss: 1.4267395734786987
Validation loss: 2.2432157595952353

Epoch: 6| Step: 3
Training loss: 1.918115496635437
Validation loss: 2.2445382674535117

Epoch: 6| Step: 4
Training loss: 1.1387253999710083
Validation loss: 2.279375751813253

Epoch: 6| Step: 5
Training loss: 1.7736883163452148
Validation loss: 2.264874001344045

Epoch: 6| Step: 6
Training loss: 1.2769299745559692
Validation loss: 2.2742307980855307

Epoch: 6| Step: 7
Training loss: 2.159175157546997
Validation loss: 2.2633373737335205

Epoch: 6| Step: 8
Training loss: 1.4422169923782349
Validation loss: 2.2902795871098838

Epoch: 6| Step: 9
Training loss: 1.6255266666412354
Validation loss: 2.2840701142946878

Epoch: 6| Step: 10
Training loss: 1.6560148000717163
Validation loss: 2.2610815167427063

Epoch: 6| Step: 11
Training loss: 2.40073823928833
Validation loss: 2.276802440484365

Epoch: 6| Step: 12
Training loss: 2.2091197967529297
Validation loss: 2.276898900667826

Epoch: 6| Step: 13
Training loss: 1.5776728391647339
Validation loss: 2.274514377117157

Epoch: 301| Step: 0
Training loss: 1.622377872467041
Validation loss: 2.2901938358942666

Epoch: 6| Step: 1
Training loss: 1.262420892715454
Validation loss: 2.3000184098879495

Epoch: 6| Step: 2
Training loss: 1.783765435218811
Validation loss: 2.2926396131515503

Epoch: 6| Step: 3
Training loss: 1.1069746017456055
Validation loss: 2.3158284028371177

Epoch: 6| Step: 4
Training loss: 2.534611940383911
Validation loss: 2.3022399147351584

Epoch: 6| Step: 5
Training loss: 1.7004367113113403
Validation loss: 2.2970807552337646

Epoch: 6| Step: 6
Training loss: 1.6986472606658936
Validation loss: 2.2824153304100037

Epoch: 6| Step: 7
Training loss: 1.4844974279403687
Validation loss: 2.2892856995264688

Epoch: 6| Step: 8
Training loss: 2.464057445526123
Validation loss: 2.282242218653361

Epoch: 6| Step: 9
Training loss: 1.2485458850860596
Validation loss: 2.2750308911005654

Epoch: 6| Step: 10
Training loss: 1.1955838203430176
Validation loss: 2.2684685985247293

Epoch: 6| Step: 11
Training loss: 2.113661289215088
Validation loss: 2.3133013248443604

Epoch: 6| Step: 12
Training loss: 1.6085623502731323
Validation loss: 2.3073575099309287

Epoch: 6| Step: 13
Training loss: 1.9053151607513428
Validation loss: 2.299083709716797

Epoch: 302| Step: 0
Training loss: 1.9752004146575928
Validation loss: 2.2909441788991294

Epoch: 6| Step: 1
Training loss: 1.1797137260437012
Validation loss: 2.2849105993906655

Epoch: 6| Step: 2
Training loss: 1.5608617067337036
Validation loss: 2.2744153141975403

Epoch: 6| Step: 3
Training loss: 1.4161837100982666
Validation loss: 2.315189083417257

Epoch: 6| Step: 4
Training loss: 1.472341775894165
Validation loss: 2.269480268160502

Epoch: 6| Step: 5
Training loss: 1.3545602560043335
Validation loss: 2.2609244187672934

Epoch: 6| Step: 6
Training loss: 1.4180145263671875
Validation loss: 2.2794886430104575

Epoch: 6| Step: 7
Training loss: 1.8435559272766113
Validation loss: 2.279059092203776

Epoch: 6| Step: 8
Training loss: 1.8344347476959229
Validation loss: 2.253463645776113

Epoch: 6| Step: 9
Training loss: 2.8334429264068604
Validation loss: 2.2760244607925415

Epoch: 6| Step: 10
Training loss: 1.682485818862915
Validation loss: 2.2910569111506143

Epoch: 6| Step: 11
Training loss: 1.8876183032989502
Validation loss: 2.258514146010081

Epoch: 6| Step: 12
Training loss: 1.5673493146896362
Validation loss: 2.2510521014531455

Epoch: 6| Step: 13
Training loss: 1.3157037496566772
Validation loss: 2.2826728224754333

Epoch: 303| Step: 0
Training loss: 2.1661531925201416
Validation loss: 2.2726935942967734

Epoch: 6| Step: 1
Training loss: 1.3001048564910889
Validation loss: 2.2804603576660156

Epoch: 6| Step: 2
Training loss: 1.676182508468628
Validation loss: 2.259425381819407

Epoch: 6| Step: 3
Training loss: 1.4405441284179688
Validation loss: 2.2587323983510337

Epoch: 6| Step: 4
Training loss: 2.020040512084961
Validation loss: 2.2819350163141885

Epoch: 6| Step: 5
Training loss: 1.3309574127197266
Validation loss: 2.264913002649943

Epoch: 6| Step: 6
Training loss: 1.5307807922363281
Validation loss: 2.2919125159581504

Epoch: 6| Step: 7
Training loss: 1.3377740383148193
Validation loss: 2.2744443813959756

Epoch: 6| Step: 8
Training loss: 2.0615386962890625
Validation loss: 2.268309990564982

Epoch: 6| Step: 9
Training loss: 2.417909622192383
Validation loss: 2.287678837776184

Epoch: 6| Step: 10
Training loss: 1.6060457229614258
Validation loss: 2.29698646068573

Epoch: 6| Step: 11
Training loss: 1.3242406845092773
Validation loss: 2.303619305292765

Epoch: 6| Step: 12
Training loss: 1.4973671436309814
Validation loss: 2.2992047468821206

Epoch: 6| Step: 13
Training loss: 1.4181007146835327
Validation loss: 2.3011109828948975

Epoch: 304| Step: 0
Training loss: 2.021526336669922
Validation loss: 2.2618450919787088

Epoch: 6| Step: 1
Training loss: 1.86014986038208
Validation loss: 2.2359796365102134

Epoch: 6| Step: 2
Training loss: 1.3112738132476807
Validation loss: 2.2272960344950357

Epoch: 6| Step: 3
Training loss: 2.9689178466796875
Validation loss: 2.1972111463546753

Epoch: 6| Step: 4
Training loss: 1.8483598232269287
Validation loss: 2.218405306339264

Epoch: 6| Step: 5
Training loss: 1.4940502643585205
Validation loss: 2.2082003951072693

Epoch: 6| Step: 6
Training loss: 2.0150978565216064
Validation loss: 2.218855063120524

Epoch: 6| Step: 7
Training loss: 2.3434383869171143
Validation loss: 2.2016332149505615

Epoch: 6| Step: 8
Training loss: 2.0496206283569336
Validation loss: 2.19778964916865

Epoch: 6| Step: 9
Training loss: 1.3909331560134888
Validation loss: 2.202203909556071

Epoch: 6| Step: 10
Training loss: 0.9743618965148926
Validation loss: 2.1890488862991333

Epoch: 6| Step: 11
Training loss: 1.5740554332733154
Validation loss: 2.198755661646525

Epoch: 6| Step: 12
Training loss: 1.9041805267333984
Validation loss: 2.223501761754354

Epoch: 6| Step: 13
Training loss: 1.3249874114990234
Validation loss: 2.255821625391642

Epoch: 305| Step: 0
Training loss: 1.193749189376831
Validation loss: 2.282438596089681

Epoch: 6| Step: 1
Training loss: 1.673641562461853
Validation loss: 2.3096555868784585

Epoch: 6| Step: 2
Training loss: 1.695713996887207
Validation loss: 2.3330445686976113

Epoch: 6| Step: 3
Training loss: 1.877042293548584
Validation loss: 2.37063600619634

Epoch: 6| Step: 4
Training loss: 1.6906042098999023
Validation loss: 2.326155662536621

Epoch: 6| Step: 5
Training loss: 2.5253868103027344
Validation loss: 2.3112693627675376

Epoch: 6| Step: 6
Training loss: 1.7642250061035156
Validation loss: 2.2964587608973184

Epoch: 6| Step: 7
Training loss: 1.7450945377349854
Validation loss: 2.2815502882003784

Epoch: 6| Step: 8
Training loss: 1.2801129817962646
Validation loss: 2.29030833641688

Epoch: 6| Step: 9
Training loss: 1.6656397581100464
Validation loss: 2.2696586648623147

Epoch: 6| Step: 10
Training loss: 1.573070764541626
Validation loss: 2.237122138341268

Epoch: 6| Step: 11
Training loss: 1.2424405813217163
Validation loss: 2.258390506108602

Epoch: 6| Step: 12
Training loss: 1.7662891149520874
Validation loss: 2.244290272394816

Epoch: 6| Step: 13
Training loss: 3.0285348892211914
Validation loss: 2.2381712198257446

Epoch: 306| Step: 0
Training loss: 1.9930980205535889
Validation loss: 2.226666430632273

Epoch: 6| Step: 1
Training loss: 2.037583112716675
Validation loss: 2.250814139842987

Epoch: 6| Step: 2
Training loss: 1.895639419555664
Validation loss: 2.2625778118769326

Epoch: 6| Step: 3
Training loss: 1.8820316791534424
Validation loss: 2.2745283047358194

Epoch: 6| Step: 4
Training loss: 1.9000095129013062
Validation loss: 2.2990986108779907

Epoch: 6| Step: 5
Training loss: 0.9914312362670898
Validation loss: 2.2544618248939514

Epoch: 6| Step: 6
Training loss: 1.800844669342041
Validation loss: 2.3076137701670327

Epoch: 6| Step: 7
Training loss: 1.4080491065979004
Validation loss: 2.286572754383087

Epoch: 6| Step: 8
Training loss: 1.329866647720337
Validation loss: 2.290149370829264

Epoch: 6| Step: 9
Training loss: 1.7675418853759766
Validation loss: 2.2914099295934043

Epoch: 6| Step: 10
Training loss: 2.2350564002990723
Validation loss: 2.2918442487716675

Epoch: 6| Step: 11
Training loss: 1.5913026332855225
Validation loss: 2.2730297644933066

Epoch: 6| Step: 12
Training loss: 1.8429346084594727
Validation loss: 2.2896074453989663

Epoch: 6| Step: 13
Training loss: 1.3360750675201416
Validation loss: 2.2810922066370645

Epoch: 307| Step: 0
Training loss: 1.3111876249313354
Validation loss: 2.3143125772476196

Epoch: 6| Step: 1
Training loss: 1.3606781959533691
Validation loss: 2.2591850757598877

Epoch: 6| Step: 2
Training loss: 2.0886471271514893
Validation loss: 2.3089942932128906

Epoch: 6| Step: 3
Training loss: 1.8800098896026611
Validation loss: 2.250271658102671

Epoch: 6| Step: 4
Training loss: 1.6802170276641846
Validation loss: 2.293083111445109

Epoch: 6| Step: 5
Training loss: 1.7037183046340942
Validation loss: 2.2704878648122153

Epoch: 6| Step: 6
Training loss: 1.936933159828186
Validation loss: 2.2859203020731607

Epoch: 6| Step: 7
Training loss: 1.246727705001831
Validation loss: 2.259964942932129

Epoch: 6| Step: 8
Training loss: 1.1751140356063843
Validation loss: 2.2899468739827475

Epoch: 6| Step: 9
Training loss: 2.078333854675293
Validation loss: 2.2952619791030884

Epoch: 6| Step: 10
Training loss: 2.203077793121338
Validation loss: 2.2900768518447876

Epoch: 6| Step: 11
Training loss: 1.8494220972061157
Validation loss: 2.30284990866979

Epoch: 6| Step: 12
Training loss: 1.4597735404968262
Validation loss: 2.297717253367106

Epoch: 6| Step: 13
Training loss: 1.2983989715576172
Validation loss: 2.291351934274038

Epoch: 308| Step: 0
Training loss: 1.6197047233581543
Validation loss: 2.287061393260956

Epoch: 6| Step: 1
Training loss: 1.370100975036621
Validation loss: 2.2732545336087546

Epoch: 6| Step: 2
Training loss: 1.232877492904663
Validation loss: 2.2895841002464294

Epoch: 6| Step: 3
Training loss: 1.336617112159729
Validation loss: 2.2802983125050864

Epoch: 6| Step: 4
Training loss: 2.0138843059539795
Validation loss: 2.2658431132634482

Epoch: 6| Step: 5
Training loss: 1.3270533084869385
Validation loss: 2.273619016011556

Epoch: 6| Step: 6
Training loss: 2.012615442276001
Validation loss: 2.229877154032389

Epoch: 6| Step: 7
Training loss: 1.388380527496338
Validation loss: 2.257627805074056

Epoch: 6| Step: 8
Training loss: 1.2559664249420166
Validation loss: 2.2567074298858643

Epoch: 6| Step: 9
Training loss: 2.5915379524230957
Validation loss: 2.2758044004440308

Epoch: 6| Step: 10
Training loss: 2.1862988471984863
Validation loss: 2.269007702668508

Epoch: 6| Step: 11
Training loss: 1.9645278453826904
Validation loss: 2.310899019241333

Epoch: 6| Step: 12
Training loss: 1.114593744277954
Validation loss: 2.283663829167684

Epoch: 6| Step: 13
Training loss: 2.3608574867248535
Validation loss: 2.301553169886271

Epoch: 309| Step: 0
Training loss: 1.7722469568252563
Validation loss: 2.308187464872996

Epoch: 6| Step: 1
Training loss: 1.5761942863464355
Validation loss: 2.2862419486045837

Epoch: 6| Step: 2
Training loss: 1.9232590198516846
Validation loss: 2.3091119726498923

Epoch: 6| Step: 3
Training loss: 1.8354511260986328
Validation loss: 2.295354108015696

Epoch: 6| Step: 4
Training loss: 1.437613606452942
Validation loss: 2.291701555252075

Epoch: 6| Step: 5
Training loss: 1.440869927406311
Validation loss: 2.2790155609448752

Epoch: 6| Step: 6
Training loss: 1.7544556856155396
Validation loss: 2.2938877741495767

Epoch: 6| Step: 7
Training loss: 1.7953503131866455
Validation loss: 2.2419815063476562

Epoch: 6| Step: 8
Training loss: 2.974365234375
Validation loss: 2.2403483986854553

Epoch: 6| Step: 9
Training loss: 1.652200698852539
Validation loss: 2.2377134561538696

Epoch: 6| Step: 10
Training loss: 1.5712553262710571
Validation loss: 2.2654051780700684

Epoch: 6| Step: 11
Training loss: 1.550386905670166
Validation loss: 2.2664088209470115

Epoch: 6| Step: 12
Training loss: 1.1257190704345703
Validation loss: 2.2962132692337036

Epoch: 6| Step: 13
Training loss: 1.0008928775787354
Validation loss: 2.249502638975779

Epoch: 310| Step: 0
Training loss: 1.3839740753173828
Validation loss: 2.2789844274520874

Epoch: 6| Step: 1
Training loss: 1.5602810382843018
Validation loss: 2.298741579055786

Epoch: 6| Step: 2
Training loss: 2.282792806625366
Validation loss: 2.276749610900879

Epoch: 6| Step: 3
Training loss: 1.4573144912719727
Validation loss: 2.2853403091430664

Epoch: 6| Step: 4
Training loss: 1.637176513671875
Validation loss: 2.312657415866852

Epoch: 6| Step: 5
Training loss: 2.1360785961151123
Validation loss: 2.2755793730417886

Epoch: 6| Step: 6
Training loss: 1.7097728252410889
Validation loss: 2.294049064318339

Epoch: 6| Step: 7
Training loss: 1.5084919929504395
Validation loss: 2.2824283440907798

Epoch: 6| Step: 8
Training loss: 1.905490756034851
Validation loss: 2.3040988445281982

Epoch: 6| Step: 9
Training loss: 1.9379137754440308
Validation loss: 2.3071165482203164

Epoch: 6| Step: 10
Training loss: 1.6609892845153809
Validation loss: 2.3173595666885376

Epoch: 6| Step: 11
Training loss: 1.4369055032730103
Validation loss: 2.2836817502975464

Epoch: 6| Step: 12
Training loss: 1.785860538482666
Validation loss: 2.2694013913472495

Epoch: 6| Step: 13
Training loss: 1.3103115558624268
Validation loss: 2.2403740088144937

Epoch: 311| Step: 0
Training loss: 2.453019142150879
Validation loss: 2.2553924322128296

Epoch: 6| Step: 1
Training loss: 1.7655391693115234
Validation loss: 2.245559255282084

Epoch: 6| Step: 2
Training loss: 2.419604778289795
Validation loss: 2.247150182723999

Epoch: 6| Step: 3
Training loss: 1.6483410596847534
Validation loss: 2.276904881000519

Epoch: 6| Step: 4
Training loss: 1.6847202777862549
Validation loss: 2.2527777353922525

Epoch: 6| Step: 5
Training loss: 1.9599146842956543
Validation loss: 2.289729138215383

Epoch: 6| Step: 6
Training loss: 1.4820849895477295
Validation loss: 2.296407322088877

Epoch: 6| Step: 7
Training loss: 1.2863061428070068
Validation loss: 2.286642849445343

Epoch: 6| Step: 8
Training loss: 1.284468650817871
Validation loss: 2.332068999608358

Epoch: 6| Step: 9
Training loss: 1.5578362941741943
Validation loss: 2.311591883500417

Epoch: 6| Step: 10
Training loss: 1.142187237739563
Validation loss: 2.261483053366343

Epoch: 6| Step: 11
Training loss: 2.077192783355713
Validation loss: 2.2470378081003823

Epoch: 6| Step: 12
Training loss: 1.758457899093628
Validation loss: 2.2557812531789145

Epoch: 6| Step: 13
Training loss: 1.743346929550171
Validation loss: 2.2197418212890625

Epoch: 312| Step: 0
Training loss: 1.476574420928955
Validation loss: 2.2691816886266074

Epoch: 6| Step: 1
Training loss: 2.046915054321289
Validation loss: 2.236632466316223

Epoch: 6| Step: 2
Training loss: 1.611708164215088
Validation loss: 2.24673722187678

Epoch: 6| Step: 3
Training loss: 1.8999207019805908
Validation loss: 2.2402194937070212

Epoch: 6| Step: 4
Training loss: 1.4867271184921265
Validation loss: 2.2447043855985007

Epoch: 6| Step: 5
Training loss: 1.1206655502319336
Validation loss: 2.2471311489741006

Epoch: 6| Step: 6
Training loss: 1.967573881149292
Validation loss: 2.234327733516693

Epoch: 6| Step: 7
Training loss: 2.213935613632202
Validation loss: 2.2236133813858032

Epoch: 6| Step: 8
Training loss: 1.097949504852295
Validation loss: 2.2394195199012756

Epoch: 6| Step: 9
Training loss: 1.3785096406936646
Validation loss: 2.2417457501093545

Epoch: 6| Step: 10
Training loss: 2.5594263076782227
Validation loss: 2.221785287062327

Epoch: 6| Step: 11
Training loss: 1.3507740497589111
Validation loss: 2.2273687521616616

Epoch: 6| Step: 12
Training loss: 2.300262451171875
Validation loss: 2.207105120023092

Epoch: 6| Step: 13
Training loss: 1.4205653667449951
Validation loss: 2.265982508659363

Epoch: 313| Step: 0
Training loss: 1.32218337059021
Validation loss: 2.239770213762919

Epoch: 6| Step: 1
Training loss: 1.4905900955200195
Validation loss: 2.2316054503122964

Epoch: 6| Step: 2
Training loss: 1.7484010457992554
Validation loss: 2.264643390973409

Epoch: 6| Step: 3
Training loss: 1.6497607231140137
Validation loss: 2.2760712107022605

Epoch: 6| Step: 4
Training loss: 2.21549916267395
Validation loss: 2.2786080837249756

Epoch: 6| Step: 5
Training loss: 1.889302134513855
Validation loss: 2.325949192047119

Epoch: 6| Step: 6
Training loss: 1.4234821796417236
Validation loss: 2.328911383946737

Epoch: 6| Step: 7
Training loss: 1.2570617198944092
Validation loss: 2.33465842405955

Epoch: 6| Step: 8
Training loss: 1.9399304389953613
Validation loss: 2.297317385673523

Epoch: 6| Step: 9
Training loss: 2.132476329803467
Validation loss: 2.294666051864624

Epoch: 6| Step: 10
Training loss: 1.1823234558105469
Validation loss: 2.2939542531967163

Epoch: 6| Step: 11
Training loss: 2.310642957687378
Validation loss: 2.2543760736783347

Epoch: 6| Step: 12
Training loss: 1.6142878532409668
Validation loss: 2.29748264948527

Epoch: 6| Step: 13
Training loss: 1.7245326042175293
Validation loss: 2.2869608402252197

Epoch: 314| Step: 0
Training loss: 2.072489023208618
Validation loss: 2.272877891858419

Epoch: 6| Step: 1
Training loss: 1.756163239479065
Validation loss: 2.317470908164978

Epoch: 6| Step: 2
Training loss: 1.7878296375274658
Validation loss: 2.2785869439442954

Epoch: 6| Step: 3
Training loss: 1.4770749807357788
Validation loss: 2.3206968307495117

Epoch: 6| Step: 4
Training loss: 1.7691547870635986
Validation loss: 2.275978167851766

Epoch: 6| Step: 5
Training loss: 1.787600040435791
Validation loss: 2.322523554166158

Epoch: 6| Step: 6
Training loss: 2.2315874099731445
Validation loss: 2.2923518816630044

Epoch: 6| Step: 7
Training loss: 1.4253299236297607
Validation loss: 2.289701541264852

Epoch: 6| Step: 8
Training loss: 1.5790637731552124
Validation loss: 2.2989414731661477

Epoch: 6| Step: 9
Training loss: 1.9018104076385498
Validation loss: 2.2591283122698465

Epoch: 6| Step: 10
Training loss: 1.4674626588821411
Validation loss: 2.2719122171401978

Epoch: 6| Step: 11
Training loss: 1.0330719947814941
Validation loss: 2.2704766988754272

Epoch: 6| Step: 12
Training loss: 1.4372265338897705
Validation loss: 2.249418020248413

Epoch: 6| Step: 13
Training loss: 1.4525084495544434
Validation loss: 2.2539150714874268

Epoch: 315| Step: 0
Training loss: 1.4018895626068115
Validation loss: 2.2577618956565857

Epoch: 6| Step: 1
Training loss: 1.3065440654754639
Validation loss: 2.2542232473691306

Epoch: 6| Step: 2
Training loss: 1.9995524883270264
Validation loss: 2.25706539551417

Epoch: 6| Step: 3
Training loss: 1.2728317975997925
Validation loss: 2.273610452810923

Epoch: 6| Step: 4
Training loss: 1.8554801940917969
Validation loss: 2.268117825190226

Epoch: 6| Step: 5
Training loss: 1.3035516738891602
Validation loss: 2.2729342778523765

Epoch: 6| Step: 6
Training loss: 1.8660850524902344
Validation loss: 2.300924221674601

Epoch: 6| Step: 7
Training loss: 1.322545051574707
Validation loss: 2.2863152821858725

Epoch: 6| Step: 8
Training loss: 1.066633939743042
Validation loss: 2.298134525616964

Epoch: 6| Step: 9
Training loss: 1.2843413352966309
Validation loss: 2.2597606579462686

Epoch: 6| Step: 10
Training loss: 1.5934957265853882
Validation loss: 2.280351976553599

Epoch: 6| Step: 11
Training loss: 3.2370901107788086
Validation loss: 2.2420616944630942

Epoch: 6| Step: 12
Training loss: 1.1720865964889526
Validation loss: 2.2727315425872803

Epoch: 6| Step: 13
Training loss: 2.3417582511901855
Validation loss: 2.273758808771769

Epoch: 316| Step: 0
Training loss: 1.1242767572402954
Validation loss: 2.287944038709005

Epoch: 6| Step: 1
Training loss: 2.2287793159484863
Validation loss: 2.266193409760793

Epoch: 6| Step: 2
Training loss: 1.7007255554199219
Validation loss: 2.3003710905710855

Epoch: 6| Step: 3
Training loss: 1.8430098295211792
Validation loss: 2.3299517035484314

Epoch: 6| Step: 4
Training loss: 2.4554970264434814
Validation loss: 2.3305611610412598

Epoch: 6| Step: 5
Training loss: 1.5948549509048462
Validation loss: 2.3243261774381003

Epoch: 6| Step: 6
Training loss: 1.1386008262634277
Validation loss: 2.329229553540548

Epoch: 6| Step: 7
Training loss: 1.1840007305145264
Validation loss: 2.344610095024109

Epoch: 6| Step: 8
Training loss: 1.926329255104065
Validation loss: 2.3140373627344766

Epoch: 6| Step: 9
Training loss: 1.6727584600448608
Validation loss: 2.2746537923812866

Epoch: 6| Step: 10
Training loss: 1.9132877588272095
Validation loss: 2.2510390281677246

Epoch: 6| Step: 11
Training loss: 1.425166130065918
Validation loss: 2.2681634426116943

Epoch: 6| Step: 12
Training loss: 1.4444500207901
Validation loss: 2.243800938129425

Epoch: 6| Step: 13
Training loss: 1.5612503290176392
Validation loss: 2.258526861667633

Epoch: 317| Step: 0
Training loss: 2.031125068664551
Validation loss: 2.2636327743530273

Epoch: 6| Step: 1
Training loss: 2.6350183486938477
Validation loss: 2.2461281021436057

Epoch: 6| Step: 2
Training loss: 1.6887457370758057
Validation loss: 2.2751451532046

Epoch: 6| Step: 3
Training loss: 1.2055423259735107
Validation loss: 2.3012404441833496

Epoch: 6| Step: 4
Training loss: 1.6339774131774902
Validation loss: 2.3022645711898804

Epoch: 6| Step: 5
Training loss: 1.3032840490341187
Validation loss: 2.295740763346354

Epoch: 6| Step: 6
Training loss: 1.9386639595031738
Validation loss: 2.3258879582087197

Epoch: 6| Step: 7
Training loss: 1.5037565231323242
Validation loss: 2.3200408617655435

Epoch: 6| Step: 8
Training loss: 1.0705887079238892
Validation loss: 2.3250402212142944

Epoch: 6| Step: 9
Training loss: 1.3454874753952026
Validation loss: 2.308294494946798

Epoch: 6| Step: 10
Training loss: 1.7324297428131104
Validation loss: 2.2905842065811157

Epoch: 6| Step: 11
Training loss: 1.2662253379821777
Validation loss: 2.2856255571047464

Epoch: 6| Step: 12
Training loss: 2.3144583702087402
Validation loss: 2.2726893623669944

Epoch: 6| Step: 13
Training loss: 1.5925511121749878
Validation loss: 2.2619508703549704

Epoch: 318| Step: 0
Training loss: 2.090820789337158
Validation loss: 2.279913822809855

Epoch: 6| Step: 1
Training loss: 1.6357452869415283
Validation loss: 2.2585948705673218

Epoch: 6| Step: 2
Training loss: 1.1921586990356445
Validation loss: 2.320058584213257

Epoch: 6| Step: 3
Training loss: 1.8725941181182861
Validation loss: 2.309066871802012

Epoch: 6| Step: 4
Training loss: 2.3713440895080566
Validation loss: 2.308334231376648

Epoch: 6| Step: 5
Training loss: 1.6562923192977905
Validation loss: 2.3124613960584006

Epoch: 6| Step: 6
Training loss: 1.3644040822982788
Validation loss: 2.308991769949595

Epoch: 6| Step: 7
Training loss: 1.5462549924850464
Validation loss: 2.2962013681729636

Epoch: 6| Step: 8
Training loss: 1.4813203811645508
Validation loss: 2.311603367328644

Epoch: 6| Step: 9
Training loss: 1.282217264175415
Validation loss: 2.2966202894846597

Epoch: 6| Step: 10
Training loss: 1.16779363155365
Validation loss: 2.3415674368540444

Epoch: 6| Step: 11
Training loss: 1.5611226558685303
Validation loss: 2.325615962346395

Epoch: 6| Step: 12
Training loss: 0.958244264125824
Validation loss: 2.3327250878016152

Epoch: 6| Step: 13
Training loss: 2.4928975105285645
Validation loss: 2.3440997997919717

Epoch: 319| Step: 0
Training loss: 1.662365198135376
Validation loss: 2.306688666343689

Epoch: 6| Step: 1
Training loss: 1.3539257049560547
Validation loss: 2.3147202928860984

Epoch: 6| Step: 2
Training loss: 1.456857681274414
Validation loss: 2.303428033987681

Epoch: 6| Step: 3
Training loss: 1.203165888786316
Validation loss: 2.3318888346354165

Epoch: 6| Step: 4
Training loss: 2.0620460510253906
Validation loss: 2.3062552014986673

Epoch: 6| Step: 5
Training loss: 1.2506886720657349
Validation loss: 2.2833905617396035

Epoch: 6| Step: 6
Training loss: 1.5161850452423096
Validation loss: 2.2805037101109824

Epoch: 6| Step: 7
Training loss: 2.19529390335083
Validation loss: 2.3139219681421914

Epoch: 6| Step: 8
Training loss: 2.2226195335388184
Validation loss: 2.2693395018577576

Epoch: 6| Step: 9
Training loss: 1.1629691123962402
Validation loss: 2.281895418961843

Epoch: 6| Step: 10
Training loss: 1.3299031257629395
Validation loss: 2.2679815888404846

Epoch: 6| Step: 11
Training loss: 1.6253397464752197
Validation loss: 2.250454227129618

Epoch: 6| Step: 12
Training loss: 2.3576440811157227
Validation loss: 2.2403785983721414

Epoch: 6| Step: 13
Training loss: 1.2605681419372559
Validation loss: 2.247224589188894

Epoch: 320| Step: 0
Training loss: 1.603867769241333
Validation loss: 2.238153636455536

Epoch: 6| Step: 1
Training loss: 1.0800622701644897
Validation loss: 2.2308577497800193

Epoch: 6| Step: 2
Training loss: 1.5737943649291992
Validation loss: 2.2425816456476846

Epoch: 6| Step: 3
Training loss: 1.822833776473999
Validation loss: 2.237207611401876

Epoch: 6| Step: 4
Training loss: 1.330663800239563
Validation loss: 2.239188075065613

Epoch: 6| Step: 5
Training loss: 1.9381744861602783
Validation loss: 2.270226458708445

Epoch: 6| Step: 6
Training loss: 1.3592164516448975
Validation loss: 2.243128021558126

Epoch: 6| Step: 7
Training loss: 1.420865774154663
Validation loss: 2.26652721563975

Epoch: 6| Step: 8
Training loss: 1.2397282123565674
Validation loss: 2.301177223523458

Epoch: 6| Step: 9
Training loss: 1.8912663459777832
Validation loss: 2.2905003825823465

Epoch: 6| Step: 10
Training loss: 1.8588956594467163
Validation loss: 2.313237428665161

Epoch: 6| Step: 11
Training loss: 2.167381525039673
Validation loss: 2.3061689734458923

Epoch: 6| Step: 12
Training loss: 1.7695896625518799
Validation loss: 2.287341833114624

Epoch: 6| Step: 13
Training loss: 1.709862232208252
Validation loss: 2.33062614997228

Epoch: 321| Step: 0
Training loss: 1.4224785566329956
Validation loss: 2.3064235051472983

Epoch: 6| Step: 1
Training loss: 1.6311732530593872
Validation loss: 2.323470870653788

Epoch: 6| Step: 2
Training loss: 2.077501058578491
Validation loss: 2.314209520816803

Epoch: 6| Step: 3
Training loss: 1.615766167640686
Validation loss: 2.3016770680745444

Epoch: 6| Step: 4
Training loss: 2.5749282836914062
Validation loss: 2.279739042123159

Epoch: 6| Step: 5
Training loss: 2.1496362686157227
Validation loss: 2.3212717374165854

Epoch: 6| Step: 6
Training loss: 1.10042142868042
Validation loss: 2.3085049192110696

Epoch: 6| Step: 7
Training loss: 1.484870433807373
Validation loss: 2.3294268449147544

Epoch: 6| Step: 8
Training loss: 1.6508979797363281
Validation loss: 2.3173332810401917

Epoch: 6| Step: 9
Training loss: 1.516840934753418
Validation loss: 2.283783515294393

Epoch: 6| Step: 10
Training loss: 1.9773473739624023
Validation loss: 2.294825037320455

Epoch: 6| Step: 11
Training loss: 1.3506293296813965
Validation loss: 2.345952848593394

Epoch: 6| Step: 12
Training loss: 1.215726375579834
Validation loss: 2.274348795413971

Epoch: 6| Step: 13
Training loss: 1.6159933805465698
Validation loss: 2.2321563959121704

Epoch: 322| Step: 0
Training loss: 1.95113205909729
Validation loss: 2.2395546634991965

Epoch: 6| Step: 1
Training loss: 1.0785192251205444
Validation loss: 2.2450045148531594

Epoch: 6| Step: 2
Training loss: 1.9321573972702026
Validation loss: 2.225412746270498

Epoch: 6| Step: 3
Training loss: 1.2537622451782227
Validation loss: 2.2379070520401

Epoch: 6| Step: 4
Training loss: 1.391563892364502
Validation loss: 2.297363042831421

Epoch: 6| Step: 5
Training loss: 2.552231788635254
Validation loss: 2.265744904677073

Epoch: 6| Step: 6
Training loss: 1.7677128314971924
Validation loss: 2.2610640128453574

Epoch: 6| Step: 7
Training loss: 1.4000749588012695
Validation loss: 2.2798465490341187

Epoch: 6| Step: 8
Training loss: 2.133481502532959
Validation loss: 2.28322700659434

Epoch: 6| Step: 9
Training loss: 1.6390140056610107
Validation loss: 2.288022994995117

Epoch: 6| Step: 10
Training loss: 2.0233306884765625
Validation loss: 2.283145288626353

Epoch: 6| Step: 11
Training loss: 0.9672541618347168
Validation loss: 2.330636998017629

Epoch: 6| Step: 12
Training loss: 1.3798344135284424
Validation loss: 2.302547117074331

Epoch: 6| Step: 13
Training loss: 1.705296277999878
Validation loss: 2.292211651802063

Epoch: 323| Step: 0
Training loss: 1.5376216173171997
Validation loss: 2.2914361159006753

Epoch: 6| Step: 1
Training loss: 1.7900362014770508
Validation loss: 2.2843180298805237

Epoch: 6| Step: 2
Training loss: 1.4469798803329468
Validation loss: 2.2824276288350425

Epoch: 6| Step: 3
Training loss: 1.1582810878753662
Validation loss: 2.2734599908192954

Epoch: 6| Step: 4
Training loss: 1.4215607643127441
Validation loss: 2.2663618524869285

Epoch: 6| Step: 5
Training loss: 1.8050631284713745
Validation loss: 2.276418368021647

Epoch: 6| Step: 6
Training loss: 1.7770991325378418
Validation loss: 2.295204003651937

Epoch: 6| Step: 7
Training loss: 1.7681523561477661
Validation loss: 2.315810958544413

Epoch: 6| Step: 8
Training loss: 1.4798505306243896
Validation loss: 2.329387843608856

Epoch: 6| Step: 9
Training loss: 1.612439751625061
Validation loss: 2.3226760824521384

Epoch: 6| Step: 10
Training loss: 1.284745216369629
Validation loss: 2.305855174859365

Epoch: 6| Step: 11
Training loss: 1.7690017223358154
Validation loss: 2.312128007411957

Epoch: 6| Step: 12
Training loss: 2.0261526107788086
Validation loss: 2.2792888283729553

Epoch: 6| Step: 13
Training loss: 2.25571870803833
Validation loss: 2.3271709084510803

Epoch: 324| Step: 0
Training loss: 2.6419143676757812
Validation loss: 2.3015722036361694

Epoch: 6| Step: 1
Training loss: 1.767554759979248
Validation loss: 2.2662808100382485

Epoch: 6| Step: 2
Training loss: 2.0554466247558594
Validation loss: 2.2519745429356894

Epoch: 6| Step: 3
Training loss: 1.7558810710906982
Validation loss: 2.257145265738169

Epoch: 6| Step: 4
Training loss: 0.8601540327072144
Validation loss: 2.274307827154795

Epoch: 6| Step: 5
Training loss: 1.4774800539016724
Validation loss: 2.259655793507894

Epoch: 6| Step: 6
Training loss: 1.1408874988555908
Validation loss: 2.2347821593284607

Epoch: 6| Step: 7
Training loss: 2.0201103687286377
Validation loss: 2.257313052813212

Epoch: 6| Step: 8
Training loss: 1.4661563634872437
Validation loss: 2.2695810397466025

Epoch: 6| Step: 9
Training loss: 1.872922420501709
Validation loss: 2.2726203401883445

Epoch: 6| Step: 10
Training loss: 2.4015769958496094
Validation loss: 2.2651634216308594

Epoch: 6| Step: 11
Training loss: 0.9592239856719971
Validation loss: 2.256844401359558

Epoch: 6| Step: 12
Training loss: 1.7252674102783203
Validation loss: 2.2748335798581443

Epoch: 6| Step: 13
Training loss: 1.171571969985962
Validation loss: 2.2795449097951255

Epoch: 325| Step: 0
Training loss: 1.3531384468078613
Validation loss: 2.2919786175092063

Epoch: 6| Step: 1
Training loss: 1.4632771015167236
Validation loss: 2.2529855966567993

Epoch: 6| Step: 2
Training loss: 2.415849208831787
Validation loss: 2.2788731257120767

Epoch: 6| Step: 3
Training loss: 1.959951400756836
Validation loss: 2.240313092867533

Epoch: 6| Step: 4
Training loss: 1.6744251251220703
Validation loss: 2.2731109857559204

Epoch: 6| Step: 5
Training loss: 1.3391363620758057
Validation loss: 2.307900349299113

Epoch: 6| Step: 6
Training loss: 1.6313072443008423
Validation loss: 2.25990221897761

Epoch: 6| Step: 7
Training loss: 0.9359272718429565
Validation loss: 2.2817696730295816

Epoch: 6| Step: 8
Training loss: 1.3468427658081055
Validation loss: 2.2961692810058594

Epoch: 6| Step: 9
Training loss: 1.7432223558425903
Validation loss: 2.273704548676809

Epoch: 6| Step: 10
Training loss: 2.3203701972961426
Validation loss: 2.3423181573549905

Epoch: 6| Step: 11
Training loss: 1.4374710321426392
Validation loss: 2.29975418249766

Epoch: 6| Step: 12
Training loss: 1.9979268312454224
Validation loss: 2.3032987316449485

Epoch: 6| Step: 13
Training loss: 1.3819211721420288
Validation loss: 2.2772119442621865

Epoch: 326| Step: 0
Training loss: 1.3773256540298462
Validation loss: 2.2945244312286377

Epoch: 6| Step: 1
Training loss: 0.87187659740448
Validation loss: 2.2751243511835733

Epoch: 6| Step: 2
Training loss: 2.131618022918701
Validation loss: 2.2814062039057412

Epoch: 6| Step: 3
Training loss: 1.0517561435699463
Validation loss: 2.2607417702674866

Epoch: 6| Step: 4
Training loss: 1.4473094940185547
Validation loss: 2.301152288913727

Epoch: 6| Step: 5
Training loss: 1.6706196069717407
Validation loss: 2.2664427757263184

Epoch: 6| Step: 6
Training loss: 1.527475357055664
Validation loss: 2.24863471587499

Epoch: 6| Step: 7
Training loss: 1.9829155206680298
Validation loss: 2.273030996322632

Epoch: 6| Step: 8
Training loss: 1.4087138175964355
Validation loss: 2.24329408009847

Epoch: 6| Step: 9
Training loss: 1.8112679719924927
Validation loss: 2.2698132594426474

Epoch: 6| Step: 10
Training loss: 1.3377103805541992
Validation loss: 2.302675942579905

Epoch: 6| Step: 11
Training loss: 2.240334987640381
Validation loss: 2.3027172883351645

Epoch: 6| Step: 12
Training loss: 1.7618082761764526
Validation loss: 2.3036404649416604

Epoch: 6| Step: 13
Training loss: 1.539589762687683
Validation loss: 2.312017560005188

Epoch: 327| Step: 0
Training loss: 1.7570159435272217
Validation loss: 2.3036144971847534

Epoch: 6| Step: 1
Training loss: 1.0987356901168823
Validation loss: 2.296624024709066

Epoch: 6| Step: 2
Training loss: 1.4562416076660156
Validation loss: 2.315681536992391

Epoch: 6| Step: 3
Training loss: 1.8588513135910034
Validation loss: 2.2995037833849588

Epoch: 6| Step: 4
Training loss: 1.801743984222412
Validation loss: 2.2851283152898154

Epoch: 6| Step: 5
Training loss: 1.679450273513794
Validation loss: 2.3006012042363486

Epoch: 6| Step: 6
Training loss: 1.8541882038116455
Validation loss: 2.2961824337641397

Epoch: 6| Step: 7
Training loss: 1.6344985961914062
Validation loss: 2.281469225883484

Epoch: 6| Step: 8
Training loss: 1.080241084098816
Validation loss: 2.314665118853251

Epoch: 6| Step: 9
Training loss: 1.8532928228378296
Validation loss: 2.3026942014694214

Epoch: 6| Step: 10
Training loss: 1.5985385179519653
Validation loss: 2.3101688027381897

Epoch: 6| Step: 11
Training loss: 1.489852786064148
Validation loss: 2.3027946750322976

Epoch: 6| Step: 12
Training loss: 1.7440351247787476
Validation loss: 2.316519618034363

Epoch: 6| Step: 13
Training loss: 1.8452800512313843
Validation loss: 2.3098977406819663

Epoch: 328| Step: 0
Training loss: 1.260615587234497
Validation loss: 2.279735585053762

Epoch: 6| Step: 1
Training loss: 2.5645532608032227
Validation loss: 2.281221071879069

Epoch: 6| Step: 2
Training loss: 1.3656352758407593
Validation loss: 2.295100688934326

Epoch: 6| Step: 3
Training loss: 1.6356793642044067
Validation loss: 2.27438356479009

Epoch: 6| Step: 4
Training loss: 2.059046983718872
Validation loss: 2.284244477748871

Epoch: 6| Step: 5
Training loss: 1.7167937755584717
Validation loss: 2.2883797883987427

Epoch: 6| Step: 6
Training loss: 1.2500239610671997
Validation loss: 2.28760035832723

Epoch: 6| Step: 7
Training loss: 1.165057897567749
Validation loss: 2.2792611122131348

Epoch: 6| Step: 8
Training loss: 2.28786039352417
Validation loss: 2.3377177715301514

Epoch: 6| Step: 9
Training loss: 1.6103503704071045
Validation loss: 2.2958872318267822

Epoch: 6| Step: 10
Training loss: 1.1495870351791382
Validation loss: 2.336768011252085

Epoch: 6| Step: 11
Training loss: 1.1425724029541016
Validation loss: 2.329503059387207

Epoch: 6| Step: 12
Training loss: 1.7574747800827026
Validation loss: 2.3000503182411194

Epoch: 6| Step: 13
Training loss: 1.5815958976745605
Validation loss: 2.3170108000437417

Epoch: 329| Step: 0
Training loss: 2.80143404006958
Validation loss: 2.3021326065063477

Epoch: 6| Step: 1
Training loss: 1.0077506303787231
Validation loss: 2.3168161710103354

Epoch: 6| Step: 2
Training loss: 1.7668148279190063
Validation loss: 2.2867408792177835

Epoch: 6| Step: 3
Training loss: 1.5364447832107544
Validation loss: 2.30669242143631

Epoch: 6| Step: 4
Training loss: 2.32192325592041
Validation loss: 2.2899640997250876

Epoch: 6| Step: 5
Training loss: 1.4082908630371094
Validation loss: 2.259365677833557

Epoch: 6| Step: 6
Training loss: 1.2619218826293945
Validation loss: 2.2806193431218467

Epoch: 6| Step: 7
Training loss: 0.971640944480896
Validation loss: 2.289025823275248

Epoch: 6| Step: 8
Training loss: 1.8004376888275146
Validation loss: 2.2984325091044107

Epoch: 6| Step: 9
Training loss: 1.7041488885879517
Validation loss: 2.3304237127304077

Epoch: 6| Step: 10
Training loss: 1.6665618419647217
Validation loss: 2.315229574839274

Epoch: 6| Step: 11
Training loss: 1.249026894569397
Validation loss: 2.323821266492208

Epoch: 6| Step: 12
Training loss: 1.0977176427841187
Validation loss: 2.324481209119161

Epoch: 6| Step: 13
Training loss: 1.6860733032226562
Validation loss: 2.3183104594548545

Epoch: 330| Step: 0
Training loss: 1.4976305961608887
Validation loss: 2.3020480473836265

Epoch: 6| Step: 1
Training loss: 0.8447751998901367
Validation loss: 2.311993340651194

Epoch: 6| Step: 2
Training loss: 1.1038398742675781
Validation loss: 2.292840282122294

Epoch: 6| Step: 3
Training loss: 1.4669525623321533
Validation loss: 2.3186486959457397

Epoch: 6| Step: 4
Training loss: 1.2200207710266113
Validation loss: 2.289825956026713

Epoch: 6| Step: 5
Training loss: 2.055067539215088
Validation loss: 2.3154700001080832

Epoch: 6| Step: 6
Training loss: 2.5880019664764404
Validation loss: 2.311490456263224

Epoch: 6| Step: 7
Training loss: 1.1334097385406494
Validation loss: 2.3280451893806458

Epoch: 6| Step: 8
Training loss: 1.1278049945831299
Validation loss: 2.3119691212972007

Epoch: 6| Step: 9
Training loss: 1.9851911067962646
Validation loss: 2.2946534951527915

Epoch: 6| Step: 10
Training loss: 1.7812098264694214
Validation loss: 2.3193606535593667

Epoch: 6| Step: 11
Training loss: 1.8411874771118164
Validation loss: 2.3373310565948486

Epoch: 6| Step: 12
Training loss: 2.239368438720703
Validation loss: 2.3064537048339844

Epoch: 6| Step: 13
Training loss: 1.4628105163574219
Validation loss: 2.317474643389384

Epoch: 331| Step: 0
Training loss: 1.1737295389175415
Validation loss: 2.2879608472188315

Epoch: 6| Step: 1
Training loss: 1.8689160346984863
Validation loss: 2.32142166296641

Epoch: 6| Step: 2
Training loss: 1.5453755855560303
Validation loss: 2.3305904865264893

Epoch: 6| Step: 3
Training loss: 1.4558358192443848
Validation loss: 2.2790918151537576

Epoch: 6| Step: 4
Training loss: 1.393881916999817
Validation loss: 2.325052797794342

Epoch: 6| Step: 5
Training loss: 1.4286270141601562
Validation loss: 2.312344233194987

Epoch: 6| Step: 6
Training loss: 1.9923295974731445
Validation loss: 2.3066186904907227

Epoch: 6| Step: 7
Training loss: 1.210921287536621
Validation loss: 2.294103999932607

Epoch: 6| Step: 8
Training loss: 1.4965237379074097
Validation loss: 2.3149508436520896

Epoch: 6| Step: 9
Training loss: 1.3297169208526611
Validation loss: 2.291770577430725

Epoch: 6| Step: 10
Training loss: 1.2834489345550537
Validation loss: 2.318488438924154

Epoch: 6| Step: 11
Training loss: 2.0816311836242676
Validation loss: 2.3351932168006897

Epoch: 6| Step: 12
Training loss: 2.0897908210754395
Validation loss: 2.2765963474909463

Epoch: 6| Step: 13
Training loss: 2.028430461883545
Validation loss: 2.2643115123113

Epoch: 332| Step: 0
Training loss: 1.904054880142212
Validation loss: 2.297256569067637

Epoch: 6| Step: 1
Training loss: 1.7550625801086426
Validation loss: 2.2491944233576455

Epoch: 6| Step: 2
Training loss: 1.0006213188171387
Validation loss: 2.2720250487327576

Epoch: 6| Step: 3
Training loss: 2.3175764083862305
Validation loss: 2.27481081088384

Epoch: 6| Step: 4
Training loss: 2.152127265930176
Validation loss: 2.2650700211524963

Epoch: 6| Step: 5
Training loss: 1.0426411628723145
Validation loss: 2.2349221110343933

Epoch: 6| Step: 6
Training loss: 1.4602762460708618
Validation loss: 2.2576868136723838

Epoch: 6| Step: 7
Training loss: 1.1861228942871094
Validation loss: 2.2537043491999307

Epoch: 6| Step: 8
Training loss: 2.0888266563415527
Validation loss: 2.272754728794098

Epoch: 6| Step: 9
Training loss: 1.83845055103302
Validation loss: 2.2696626583735147

Epoch: 6| Step: 10
Training loss: 1.838855504989624
Validation loss: 2.2646389603614807

Epoch: 6| Step: 11
Training loss: 1.54645836353302
Validation loss: 2.26492840051651

Epoch: 6| Step: 12
Training loss: 1.3016440868377686
Validation loss: 2.283257325490316

Epoch: 6| Step: 13
Training loss: 1.7261855602264404
Validation loss: 2.3425787488619485

Epoch: 333| Step: 0
Training loss: 2.075625419616699
Validation loss: 2.2952640453974404

Epoch: 6| Step: 1
Training loss: 0.7528244853019714
Validation loss: 2.308652420838674

Epoch: 6| Step: 2
Training loss: 2.2663917541503906
Validation loss: 2.2686681350072226

Epoch: 6| Step: 3
Training loss: 1.8625391721725464
Validation loss: 2.305239280064901

Epoch: 6| Step: 4
Training loss: 0.9469392895698547
Validation loss: 2.26659087340037

Epoch: 6| Step: 5
Training loss: 1.1730319261550903
Validation loss: 2.2433781226476035

Epoch: 6| Step: 6
Training loss: 1.7718183994293213
Validation loss: 2.2446674505869546

Epoch: 6| Step: 7
Training loss: 1.7138004302978516
Validation loss: 2.3239593505859375

Epoch: 6| Step: 8
Training loss: 1.1337419748306274
Validation loss: 2.273205320040385

Epoch: 6| Step: 9
Training loss: 1.201480746269226
Validation loss: 2.279144028822581

Epoch: 6| Step: 10
Training loss: 2.437690496444702
Validation loss: 2.294278105099996

Epoch: 6| Step: 11
Training loss: 1.5187445878982544
Validation loss: 2.3057242234547934

Epoch: 6| Step: 12
Training loss: 1.3958762884140015
Validation loss: 2.269477923711141

Epoch: 6| Step: 13
Training loss: 2.3861289024353027
Validation loss: 2.2605828841527305

Epoch: 334| Step: 0
Training loss: 0.948771595954895
Validation loss: 2.2911227146784463

Epoch: 6| Step: 1
Training loss: 1.3999886512756348
Validation loss: 2.2772616942723594

Epoch: 6| Step: 2
Training loss: 1.7579009532928467
Validation loss: 2.2584896087646484

Epoch: 6| Step: 3
Training loss: 1.4858448505401611
Validation loss: 2.3138312498728433

Epoch: 6| Step: 4
Training loss: 1.4256634712219238
Validation loss: 2.299914797147115

Epoch: 6| Step: 5
Training loss: 2.0740342140197754
Validation loss: 2.3003244002660117

Epoch: 6| Step: 6
Training loss: 1.5485219955444336
Validation loss: 2.2672516107559204

Epoch: 6| Step: 7
Training loss: 1.6108952760696411
Validation loss: 2.302190601825714

Epoch: 6| Step: 8
Training loss: 1.8155584335327148
Validation loss: 2.2578621904055276

Epoch: 6| Step: 9
Training loss: 2.159173011779785
Validation loss: 2.2774547934532166

Epoch: 6| Step: 10
Training loss: 1.9886950254440308
Validation loss: 2.2647420366605124

Epoch: 6| Step: 11
Training loss: 0.9902516007423401
Validation loss: 2.2752649982770285

Epoch: 6| Step: 12
Training loss: 1.2841484546661377
Validation loss: 2.294548749923706

Epoch: 6| Step: 13
Training loss: 1.7883093357086182
Validation loss: 2.3002474109331765

Epoch: 335| Step: 0
Training loss: 2.2033774852752686
Validation loss: 2.304541746775309

Epoch: 6| Step: 1
Training loss: 1.6523960828781128
Validation loss: 2.2844314773877463

Epoch: 6| Step: 2
Training loss: 1.863508701324463
Validation loss: 2.3044297099113464

Epoch: 6| Step: 3
Training loss: 1.094542384147644
Validation loss: 2.279245217641195

Epoch: 6| Step: 4
Training loss: 1.6904406547546387
Validation loss: 2.270827611287435

Epoch: 6| Step: 5
Training loss: 1.8158395290374756
Validation loss: 2.281055728594462

Epoch: 6| Step: 6
Training loss: 1.580960750579834
Validation loss: 2.326375444730123

Epoch: 6| Step: 7
Training loss: 1.0210235118865967
Validation loss: 2.301912566026052

Epoch: 6| Step: 8
Training loss: 1.517417073249817
Validation loss: 2.282589097817739

Epoch: 6| Step: 9
Training loss: 1.5596623420715332
Validation loss: 2.2792170445124307

Epoch: 6| Step: 10
Training loss: 1.4655776023864746
Validation loss: 2.294516106446584

Epoch: 6| Step: 11
Training loss: 1.0046632289886475
Validation loss: 2.305614709854126

Epoch: 6| Step: 12
Training loss: 1.9075889587402344
Validation loss: 2.299087127049764

Epoch: 6| Step: 13
Training loss: 1.5312778949737549
Validation loss: 2.293400466442108

Epoch: 336| Step: 0
Training loss: 1.2966251373291016
Validation loss: 2.298698127269745

Epoch: 6| Step: 1
Training loss: 1.0081759691238403
Validation loss: 2.2894272605578103

Epoch: 6| Step: 2
Training loss: 1.0237674713134766
Validation loss: 2.3079230586687722

Epoch: 6| Step: 3
Training loss: 1.6478556394577026
Validation loss: 2.321841299533844

Epoch: 6| Step: 4
Training loss: 2.183316946029663
Validation loss: 2.3192548354466758

Epoch: 6| Step: 5
Training loss: 2.245817184448242
Validation loss: 2.311722695827484

Epoch: 6| Step: 6
Training loss: 0.795391857624054
Validation loss: 2.2963104844093323

Epoch: 6| Step: 7
Training loss: 1.6714696884155273
Validation loss: 2.3058215578397117

Epoch: 6| Step: 8
Training loss: 1.7608363628387451
Validation loss: 2.321112414201101

Epoch: 6| Step: 9
Training loss: 1.7800871133804321
Validation loss: 2.303459644317627

Epoch: 6| Step: 10
Training loss: 1.8587231636047363
Validation loss: 2.293473541736603

Epoch: 6| Step: 11
Training loss: 1.3781741857528687
Validation loss: 2.2903273502985635

Epoch: 6| Step: 12
Training loss: 1.33998703956604
Validation loss: 2.3105672200520835

Epoch: 6| Step: 13
Training loss: 1.8600575923919678
Validation loss: 2.352502703666687

Epoch: 337| Step: 0
Training loss: 2.3434886932373047
Validation loss: 2.3260170817375183

Epoch: 6| Step: 1
Training loss: 1.6419832706451416
Validation loss: 2.3267133434613547

Epoch: 6| Step: 2
Training loss: 2.1631577014923096
Validation loss: 2.341984192530314

Epoch: 6| Step: 3
Training loss: 1.247856616973877
Validation loss: 2.3255160450935364

Epoch: 6| Step: 4
Training loss: 1.4451918601989746
Validation loss: 2.3021833300590515

Epoch: 6| Step: 5
Training loss: 1.2012906074523926
Validation loss: 2.3135403593381247

Epoch: 6| Step: 6
Training loss: 1.6883366107940674
Validation loss: 2.28219872713089

Epoch: 6| Step: 7
Training loss: 1.5059230327606201
Validation loss: 2.315098444620768

Epoch: 6| Step: 8
Training loss: 1.5243490934371948
Validation loss: 2.311034142971039

Epoch: 6| Step: 9
Training loss: 1.2267858982086182
Validation loss: 2.279541015625

Epoch: 6| Step: 10
Training loss: 1.5147545337677002
Validation loss: 2.287636717160543

Epoch: 6| Step: 11
Training loss: 1.575553297996521
Validation loss: 2.2810765902201333

Epoch: 6| Step: 12
Training loss: 1.1161808967590332
Validation loss: 2.3256994088490806

Epoch: 6| Step: 13
Training loss: 1.7772612571716309
Validation loss: 2.3004140059153237

Epoch: 338| Step: 0
Training loss: 1.3191335201263428
Validation loss: 2.3190821011861167

Epoch: 6| Step: 1
Training loss: 1.2248921394348145
Validation loss: 2.331528981526693

Epoch: 6| Step: 2
Training loss: 2.166471004486084
Validation loss: 2.331207553545634

Epoch: 6| Step: 3
Training loss: 1.4756455421447754
Validation loss: 2.3276766538619995

Epoch: 6| Step: 4
Training loss: 1.573547601699829
Validation loss: 2.3405722975730896

Epoch: 6| Step: 5
Training loss: 1.4043259620666504
Validation loss: 2.3094197511672974

Epoch: 6| Step: 6
Training loss: 1.5154120922088623
Validation loss: 2.316957672437032

Epoch: 6| Step: 7
Training loss: 1.887371301651001
Validation loss: 2.2934449315071106

Epoch: 6| Step: 8
Training loss: 2.2198843955993652
Validation loss: 2.2892842888832092

Epoch: 6| Step: 9
Training loss: 0.997820258140564
Validation loss: 2.2801212271054587

Epoch: 6| Step: 10
Training loss: 1.2207684516906738
Validation loss: 2.257467190424601

Epoch: 6| Step: 11
Training loss: 1.9014782905578613
Validation loss: 2.2882710695266724

Epoch: 6| Step: 12
Training loss: 1.4176294803619385
Validation loss: 2.2414416074752808

Epoch: 6| Step: 13
Training loss: 1.5500086545944214
Validation loss: 2.2586962381998696

Epoch: 339| Step: 0
Training loss: 1.2489604949951172
Validation loss: 2.271330952644348

Epoch: 6| Step: 1
Training loss: 1.5766196250915527
Validation loss: 2.2776920994122825

Epoch: 6| Step: 2
Training loss: 1.6615269184112549
Validation loss: 2.288645585378011

Epoch: 6| Step: 3
Training loss: 2.100254535675049
Validation loss: 2.314369022846222

Epoch: 6| Step: 4
Training loss: 1.9107950925827026
Validation loss: 2.3188066482543945

Epoch: 6| Step: 5
Training loss: 1.3681678771972656
Validation loss: 2.2867263555526733

Epoch: 6| Step: 6
Training loss: 1.4640047550201416
Validation loss: 2.3097118933995566

Epoch: 6| Step: 7
Training loss: 1.3899024724960327
Validation loss: 2.2977280219395957

Epoch: 6| Step: 8
Training loss: 1.9179704189300537
Validation loss: 2.3161690632502236

Epoch: 6| Step: 9
Training loss: 1.9029440879821777
Validation loss: 2.2926378647486367

Epoch: 6| Step: 10
Training loss: 1.2533128261566162
Validation loss: 2.333237051963806

Epoch: 6| Step: 11
Training loss: 1.272881269454956
Validation loss: 2.2452632188796997

Epoch: 6| Step: 12
Training loss: 0.9638556838035583
Validation loss: 2.300183415412903

Epoch: 6| Step: 13
Training loss: 2.1411292552948
Validation loss: 2.30180162191391

Epoch: 340| Step: 0
Training loss: 0.9434149265289307
Validation loss: 2.3282350301742554

Epoch: 6| Step: 1
Training loss: 0.9762522578239441
Validation loss: 2.3348474899927774

Epoch: 6| Step: 2
Training loss: 2.149367332458496
Validation loss: 2.3161738912264505

Epoch: 6| Step: 3
Training loss: 1.4849845170974731
Validation loss: 2.3041365146636963

Epoch: 6| Step: 4
Training loss: 1.5333967208862305
Validation loss: 2.303339203198751

Epoch: 6| Step: 5
Training loss: 1.5487207174301147
Validation loss: 2.2896962563196817

Epoch: 6| Step: 6
Training loss: 1.196439266204834
Validation loss: 2.3142656286557517

Epoch: 6| Step: 7
Training loss: 2.3079724311828613
Validation loss: 2.313048263390859

Epoch: 6| Step: 8
Training loss: 1.5795085430145264
Validation loss: 2.3365097443262735

Epoch: 6| Step: 9
Training loss: 1.579087495803833
Validation loss: 2.297291020552317

Epoch: 6| Step: 10
Training loss: 1.6113232374191284
Validation loss: 2.3180490136146545

Epoch: 6| Step: 11
Training loss: 1.3623936176300049
Validation loss: 2.3122388124465942

Epoch: 6| Step: 12
Training loss: 1.6861144304275513
Validation loss: 2.3394229412078857

Epoch: 6| Step: 13
Training loss: 2.0084307193756104
Validation loss: 2.348052501678467

Epoch: 341| Step: 0
Training loss: 1.6284713745117188
Validation loss: 2.358638902505239

Epoch: 6| Step: 1
Training loss: 1.3238240480422974
Validation loss: 2.3148431181907654

Epoch: 6| Step: 2
Training loss: 2.1160054206848145
Validation loss: 2.323168992996216

Epoch: 6| Step: 3
Training loss: 2.613149642944336
Validation loss: 2.2974594036738076

Epoch: 6| Step: 4
Training loss: 1.9847898483276367
Validation loss: 2.3048550486564636

Epoch: 6| Step: 5
Training loss: 1.3995020389556885
Validation loss: 2.313570241133372

Epoch: 6| Step: 6
Training loss: 1.6221117973327637
Validation loss: 2.274662713209788

Epoch: 6| Step: 7
Training loss: 1.4963213205337524
Validation loss: 2.2498934268951416

Epoch: 6| Step: 8
Training loss: 1.212849497795105
Validation loss: 2.2345417141914368

Epoch: 6| Step: 9
Training loss: 1.8127434253692627
Validation loss: 2.2858135104179382

Epoch: 6| Step: 10
Training loss: 1.221580147743225
Validation loss: 2.2755579551060996

Epoch: 6| Step: 11
Training loss: 1.2958654165267944
Validation loss: 2.2734868923823037

Epoch: 6| Step: 12
Training loss: 0.738796591758728
Validation loss: 2.2706669767697654

Epoch: 6| Step: 13
Training loss: 1.6070749759674072
Validation loss: 2.2689550518989563

Epoch: 342| Step: 0
Training loss: 1.9510247707366943
Validation loss: 2.3079559803009033

Epoch: 6| Step: 1
Training loss: 1.9082591533660889
Validation loss: 2.2992743651072183

Epoch: 6| Step: 2
Training loss: 1.1777093410491943
Validation loss: 2.2818545500437417

Epoch: 6| Step: 3
Training loss: 1.437424659729004
Validation loss: 2.3241483767827353

Epoch: 6| Step: 4
Training loss: 1.646336317062378
Validation loss: 2.3307205041249595

Epoch: 6| Step: 5
Training loss: 1.1262930631637573
Validation loss: 2.344534695148468

Epoch: 6| Step: 6
Training loss: 1.8004039525985718
Validation loss: 2.341023564338684

Epoch: 6| Step: 7
Training loss: 1.1748454570770264
Validation loss: 2.3547070423762

Epoch: 6| Step: 8
Training loss: 1.9933499097824097
Validation loss: 2.3417704502741494

Epoch: 6| Step: 9
Training loss: 1.3997375965118408
Validation loss: 2.3332221508026123

Epoch: 6| Step: 10
Training loss: 1.512495517730713
Validation loss: 2.327109456062317

Epoch: 6| Step: 11
Training loss: 2.232827663421631
Validation loss: 2.3274429043134055

Epoch: 6| Step: 12
Training loss: 1.2998576164245605
Validation loss: 2.316705067952474

Epoch: 6| Step: 13
Training loss: 1.4527411460876465
Validation loss: 2.3058981895446777

Epoch: 343| Step: 0
Training loss: 2.260707139968872
Validation loss: 2.321246385574341

Epoch: 6| Step: 1
Training loss: 1.8925044536590576
Validation loss: 2.313108960787455

Epoch: 6| Step: 2
Training loss: 1.1658008098602295
Validation loss: 2.3062949577967324

Epoch: 6| Step: 3
Training loss: 1.2612742185592651
Validation loss: 2.321842074394226

Epoch: 6| Step: 4
Training loss: 1.9726823568344116
Validation loss: 2.3245593309402466

Epoch: 6| Step: 5
Training loss: 1.8217406272888184
Validation loss: 2.2879027724266052

Epoch: 6| Step: 6
Training loss: 1.1617534160614014
Validation loss: 2.3114014069239297

Epoch: 6| Step: 7
Training loss: 1.713984727859497
Validation loss: 2.302698274453481

Epoch: 6| Step: 8
Training loss: 1.4196751117706299
Validation loss: 2.3037786881128945

Epoch: 6| Step: 9
Training loss: 1.0357537269592285
Validation loss: 2.2404492497444153

Epoch: 6| Step: 10
Training loss: 1.6425375938415527
Validation loss: 2.2801300485928855

Epoch: 6| Step: 11
Training loss: 0.9915798902511597
Validation loss: 2.2769957383473716

Epoch: 6| Step: 12
Training loss: 1.507840633392334
Validation loss: 2.266883432865143

Epoch: 6| Step: 13
Training loss: 2.161442279815674
Validation loss: 2.2458512584368386

Epoch: 344| Step: 0
Training loss: 0.7371075749397278
Validation loss: 2.2839404145876565

Epoch: 6| Step: 1
Training loss: 2.1479294300079346
Validation loss: 2.2609657446543374

Epoch: 6| Step: 2
Training loss: 1.860162615776062
Validation loss: 2.25270942846934

Epoch: 6| Step: 3
Training loss: 1.7112094163894653
Validation loss: 2.227530022462209

Epoch: 6| Step: 4
Training loss: 0.8123493194580078
Validation loss: 2.266771892706553

Epoch: 6| Step: 5
Training loss: 0.836611270904541
Validation loss: 2.257947007815043

Epoch: 6| Step: 6
Training loss: 2.077873706817627
Validation loss: 2.236537456512451

Epoch: 6| Step: 7
Training loss: 1.2569530010223389
Validation loss: 2.2712276180585227

Epoch: 6| Step: 8
Training loss: 1.946345329284668
Validation loss: 2.2621875007947287

Epoch: 6| Step: 9
Training loss: 1.3810272216796875
Validation loss: 2.2833075523376465

Epoch: 6| Step: 10
Training loss: 1.3892114162445068
Validation loss: 2.2817899783452353

Epoch: 6| Step: 11
Training loss: 1.8396282196044922
Validation loss: 2.297717114289602

Epoch: 6| Step: 12
Training loss: 1.650171160697937
Validation loss: 2.33519717057546

Epoch: 6| Step: 13
Training loss: 2.0468008518218994
Validation loss: 2.347153822580973

Epoch: 345| Step: 0
Training loss: 0.8975492715835571
Validation loss: 2.307566245396932

Epoch: 6| Step: 1
Training loss: 1.9650945663452148
Validation loss: 2.2787125507990518

Epoch: 6| Step: 2
Training loss: 1.7795186042785645
Validation loss: 2.344007651011149

Epoch: 6| Step: 3
Training loss: 0.8616394400596619
Validation loss: 2.3202589948972068

Epoch: 6| Step: 4
Training loss: 1.3779637813568115
Validation loss: 2.3151798645655313

Epoch: 6| Step: 5
Training loss: 1.6842412948608398
Validation loss: 2.298868477344513

Epoch: 6| Step: 6
Training loss: 1.9752379655838013
Validation loss: 2.3280585209528604

Epoch: 6| Step: 7
Training loss: 1.6443567276000977
Validation loss: 2.311567008495331

Epoch: 6| Step: 8
Training loss: 1.8359720706939697
Validation loss: 2.3277053435643515

Epoch: 6| Step: 9
Training loss: 1.880255937576294
Validation loss: 2.3095455964406333

Epoch: 6| Step: 10
Training loss: 1.4537156820297241
Validation loss: 2.3205774227778115

Epoch: 6| Step: 11
Training loss: 1.4285976886749268
Validation loss: 2.3155564864476523

Epoch: 6| Step: 12
Training loss: 1.7715682983398438
Validation loss: 2.277726491292318

Epoch: 6| Step: 13
Training loss: 0.9683860540390015
Validation loss: 2.344630539417267

Epoch: 346| Step: 0
Training loss: 1.1624913215637207
Validation loss: 2.2789265712102256

Epoch: 6| Step: 1
Training loss: 1.1991631984710693
Validation loss: 2.2785775462786355

Epoch: 6| Step: 2
Training loss: 1.4891858100891113
Validation loss: 2.2703753312428794

Epoch: 6| Step: 3
Training loss: 0.8925961852073669
Validation loss: 2.2715883255004883

Epoch: 6| Step: 4
Training loss: 1.1870911121368408
Validation loss: 2.2837501764297485

Epoch: 6| Step: 5
Training loss: 2.7226061820983887
Validation loss: 2.2721065680185952

Epoch: 6| Step: 6
Training loss: 0.6917925477027893
Validation loss: 2.2587079207102456

Epoch: 6| Step: 7
Training loss: 1.6021723747253418
Validation loss: 2.271501382191976

Epoch: 6| Step: 8
Training loss: 1.9681154489517212
Validation loss: 2.270622889200846

Epoch: 6| Step: 9
Training loss: 1.7107441425323486
Validation loss: 2.26929901043574

Epoch: 6| Step: 10
Training loss: 1.7792434692382812
Validation loss: 2.2662355105082193

Epoch: 6| Step: 11
Training loss: 1.5643655061721802
Validation loss: 2.2883723775545755

Epoch: 6| Step: 12
Training loss: 2.0895497798919678
Validation loss: 2.2372593879699707

Epoch: 6| Step: 13
Training loss: 1.5714004039764404
Validation loss: 2.2754388650258384

Epoch: 347| Step: 0
Training loss: 1.4194787740707397
Validation loss: 2.3042121728261313

Epoch: 6| Step: 1
Training loss: 1.5736725330352783
Validation loss: 2.2926780382792153

Epoch: 6| Step: 2
Training loss: 1.3580175638198853
Validation loss: 2.3026035030682883

Epoch: 6| Step: 3
Training loss: 1.861458659172058
Validation loss: 2.307536025842031

Epoch: 6| Step: 4
Training loss: 1.7141005992889404
Validation loss: 2.290296753247579

Epoch: 6| Step: 5
Training loss: 1.520853042602539
Validation loss: 2.305277645587921

Epoch: 6| Step: 6
Training loss: 1.1062666177749634
Validation loss: 2.273217817147573

Epoch: 6| Step: 7
Training loss: 1.1796858310699463
Validation loss: 2.2814624110857644

Epoch: 6| Step: 8
Training loss: 1.272623062133789
Validation loss: 2.2756869395573935

Epoch: 6| Step: 9
Training loss: 1.7920753955841064
Validation loss: 2.2586098313331604

Epoch: 6| Step: 10
Training loss: 1.8530244827270508
Validation loss: 2.2804260651270547

Epoch: 6| Step: 11
Training loss: 2.0520143508911133
Validation loss: 2.26009871562322

Epoch: 6| Step: 12
Training loss: 1.2494382858276367
Validation loss: 2.2879766623179116

Epoch: 6| Step: 13
Training loss: 2.3033933639526367
Validation loss: 2.2793442408243814

Epoch: 348| Step: 0
Training loss: 1.6644052267074585
Validation loss: 2.285655200481415

Epoch: 6| Step: 1
Training loss: 1.3659234046936035
Validation loss: 2.315904219945272

Epoch: 6| Step: 2
Training loss: 1.6252192258834839
Validation loss: 2.3054487903912864

Epoch: 6| Step: 3
Training loss: 1.209765076637268
Validation loss: 2.3162253697713218

Epoch: 6| Step: 4
Training loss: 1.0158876180648804
Validation loss: 2.333820720513662

Epoch: 6| Step: 5
Training loss: 2.109896183013916
Validation loss: 2.33952005704244

Epoch: 6| Step: 6
Training loss: 1.9965333938598633
Validation loss: 2.3414836724599204

Epoch: 6| Step: 7
Training loss: 1.6964268684387207
Validation loss: 2.338131328423818

Epoch: 6| Step: 8
Training loss: 0.9755497574806213
Validation loss: 2.3364307483037314

Epoch: 6| Step: 9
Training loss: 2.4953789710998535
Validation loss: 2.348464330037435

Epoch: 6| Step: 10
Training loss: 1.429037094116211
Validation loss: 2.3106823762257895

Epoch: 6| Step: 11
Training loss: 1.233553171157837
Validation loss: 2.30577286084493

Epoch: 6| Step: 12
Training loss: 1.2085773944854736
Validation loss: 2.321918487548828

Epoch: 6| Step: 13
Training loss: 1.548567533493042
Validation loss: 2.324233591556549

Epoch: 349| Step: 0
Training loss: 1.813973307609558
Validation loss: 2.2827303409576416

Epoch: 6| Step: 1
Training loss: 1.3273086547851562
Validation loss: 2.293035864830017

Epoch: 6| Step: 2
Training loss: 1.6572157144546509
Validation loss: 2.3089744647343955

Epoch: 6| Step: 3
Training loss: 1.5626431703567505
Validation loss: 2.2846067547798157

Epoch: 6| Step: 4
Training loss: 1.480239987373352
Validation loss: 2.30385285615921

Epoch: 6| Step: 5
Training loss: 1.5485423803329468
Validation loss: 2.3152026732762656

Epoch: 6| Step: 6
Training loss: 1.324920415878296
Validation loss: 2.3319837848345437

Epoch: 6| Step: 7
Training loss: 1.6274669170379639
Validation loss: 2.343700925509135

Epoch: 6| Step: 8
Training loss: 2.005932331085205
Validation loss: 2.3376638889312744

Epoch: 6| Step: 9
Training loss: 1.4222677946090698
Validation loss: 2.3271460930506387

Epoch: 6| Step: 10
Training loss: 1.1164530515670776
Validation loss: 2.301407774289449

Epoch: 6| Step: 11
Training loss: 1.3978290557861328
Validation loss: 2.309690833091736

Epoch: 6| Step: 12
Training loss: 1.6476048231124878
Validation loss: 2.3100310365358987

Epoch: 6| Step: 13
Training loss: 1.6000115871429443
Validation loss: 2.2581255038579306

Epoch: 350| Step: 0
Training loss: 1.3411924839019775
Validation loss: 2.3202967842419944

Epoch: 6| Step: 1
Training loss: 1.6022558212280273
Validation loss: 2.3229248921076455

Epoch: 6| Step: 2
Training loss: 0.8044387102127075
Validation loss: 2.288407802581787

Epoch: 6| Step: 3
Training loss: 1.7770651578903198
Validation loss: 2.2970524231592813

Epoch: 6| Step: 4
Training loss: 1.4298086166381836
Validation loss: 2.294023851553599

Epoch: 6| Step: 5
Training loss: 1.6829971075057983
Validation loss: 2.2711325685183206

Epoch: 6| Step: 6
Training loss: 1.3170137405395508
Validation loss: 2.3210469484329224

Epoch: 6| Step: 7
Training loss: 1.562885046005249
Validation loss: 2.3259878555933633

Epoch: 6| Step: 8
Training loss: 1.7161500453948975
Validation loss: 2.3417010505994162

Epoch: 6| Step: 9
Training loss: 1.4330357313156128
Validation loss: 2.356858809789022

Epoch: 6| Step: 10
Training loss: 1.543637990951538
Validation loss: 2.340439716974894

Epoch: 6| Step: 11
Training loss: 1.8188331127166748
Validation loss: 2.3382822076479592

Epoch: 6| Step: 12
Training loss: 1.9347399473190308
Validation loss: 2.3152504364649453

Epoch: 6| Step: 13
Training loss: 1.640663981437683
Validation loss: 2.3055291771888733

Epoch: 351| Step: 0
Training loss: 1.6702195405960083
Validation loss: 2.2736616333325705

Epoch: 6| Step: 1
Training loss: 1.812434434890747
Validation loss: 2.279415945212046

Epoch: 6| Step: 2
Training loss: 2.216693639755249
Validation loss: 2.2534590562184653

Epoch: 6| Step: 3
Training loss: 1.6910476684570312
Validation loss: 2.2921388745307922

Epoch: 6| Step: 4
Training loss: 1.9772464036941528
Validation loss: 2.3138474027315774

Epoch: 6| Step: 5
Training loss: 0.7240626811981201
Validation loss: 2.3269917368888855

Epoch: 6| Step: 6
Training loss: 2.2519407272338867
Validation loss: 2.3173753221829734

Epoch: 6| Step: 7
Training loss: 1.154102087020874
Validation loss: 2.326754411061605

Epoch: 6| Step: 8
Training loss: 1.6471349000930786
Validation loss: 2.3074477314949036

Epoch: 6| Step: 9
Training loss: 1.7238656282424927
Validation loss: 2.2946362694104514

Epoch: 6| Step: 10
Training loss: 1.3212571144104004
Validation loss: 2.285884062449137

Epoch: 6| Step: 11
Training loss: 1.364734172821045
Validation loss: 2.254468321800232

Epoch: 6| Step: 12
Training loss: 1.2970548868179321
Validation loss: 2.282952864964803

Epoch: 6| Step: 13
Training loss: 1.1786874532699585
Validation loss: 2.279857794443766

Epoch: 352| Step: 0
Training loss: 0.9996744990348816
Validation loss: 2.270326852798462

Epoch: 6| Step: 1
Training loss: 1.631160855293274
Validation loss: 2.288192550341288

Epoch: 6| Step: 2
Training loss: 1.6387144327163696
Validation loss: 2.2585280537605286

Epoch: 6| Step: 3
Training loss: 1.191617488861084
Validation loss: 2.248128056526184

Epoch: 6| Step: 4
Training loss: 1.4511301517486572
Validation loss: 2.2755450010299683

Epoch: 6| Step: 5
Training loss: 2.3499865531921387
Validation loss: 2.2774266997973123

Epoch: 6| Step: 6
Training loss: 1.5286259651184082
Validation loss: 2.2652262647946677

Epoch: 6| Step: 7
Training loss: 1.0313698053359985
Validation loss: 2.270940641562144

Epoch: 6| Step: 8
Training loss: 1.8347158432006836
Validation loss: 2.2823355992635093

Epoch: 6| Step: 9
Training loss: 1.033294439315796
Validation loss: 2.292758285999298

Epoch: 6| Step: 10
Training loss: 1.8881375789642334
Validation loss: 2.298754413922628

Epoch: 6| Step: 11
Training loss: 1.4195261001586914
Validation loss: 2.314317266146342

Epoch: 6| Step: 12
Training loss: 2.2224655151367188
Validation loss: 2.312009592851003

Epoch: 6| Step: 13
Training loss: 1.5038248300552368
Validation loss: 2.288988709449768

Epoch: 353| Step: 0
Training loss: 1.365269660949707
Validation loss: 2.2960580786069236

Epoch: 6| Step: 1
Training loss: 1.5957059860229492
Validation loss: 2.3090489904085794

Epoch: 6| Step: 2
Training loss: 1.943493127822876
Validation loss: 2.2880307038625083

Epoch: 6| Step: 3
Training loss: 1.5545575618743896
Validation loss: 2.3460499246915183

Epoch: 6| Step: 4
Training loss: 1.595611572265625
Validation loss: 2.3323614994684854

Epoch: 6| Step: 5
Training loss: 2.1106221675872803
Validation loss: 2.3493499954541526

Epoch: 6| Step: 6
Training loss: 1.2849839925765991
Validation loss: 2.3344852924346924

Epoch: 6| Step: 7
Training loss: 1.1519232988357544
Validation loss: 2.279384970664978

Epoch: 6| Step: 8
Training loss: 0.9745994806289673
Validation loss: 2.28590456644694

Epoch: 6| Step: 9
Training loss: 1.754494309425354
Validation loss: 2.276347041130066

Epoch: 6| Step: 10
Training loss: 1.878666877746582
Validation loss: 2.266425907611847

Epoch: 6| Step: 11
Training loss: 1.395885705947876
Validation loss: 2.2865288257598877

Epoch: 6| Step: 12
Training loss: 1.4998599290847778
Validation loss: 2.290138522783915

Epoch: 6| Step: 13
Training loss: 1.8986701965332031
Validation loss: 2.281393051147461

Epoch: 354| Step: 0
Training loss: 2.253258466720581
Validation loss: 2.2918782234191895

Epoch: 6| Step: 1
Training loss: 1.4615478515625
Validation loss: 2.2885388135910034

Epoch: 6| Step: 2
Training loss: 1.6126058101654053
Validation loss: 2.3214535315831504

Epoch: 6| Step: 3
Training loss: 1.0603630542755127
Validation loss: 2.3348772724469504

Epoch: 6| Step: 4
Training loss: 1.5070452690124512
Validation loss: 2.366292436917623

Epoch: 6| Step: 5
Training loss: 1.5542750358581543
Validation loss: 2.323645293712616

Epoch: 6| Step: 6
Training loss: 1.611307978630066
Validation loss: 2.330445150534312

Epoch: 6| Step: 7
Training loss: 1.1537803411483765
Validation loss: 2.310507337252299

Epoch: 6| Step: 8
Training loss: 2.013319492340088
Validation loss: 2.3276695807774863

Epoch: 6| Step: 9
Training loss: 1.3803060054779053
Validation loss: 2.3308348258336387

Epoch: 6| Step: 10
Training loss: 1.2134630680084229
Validation loss: 2.344410161177317

Epoch: 6| Step: 11
Training loss: 2.002534866333008
Validation loss: 2.352967143058777

Epoch: 6| Step: 12
Training loss: 1.511136531829834
Validation loss: 2.331982453664144

Epoch: 6| Step: 13
Training loss: 1.8225784301757812
Validation loss: 2.337529460589091

Epoch: 355| Step: 0
Training loss: 1.0429744720458984
Validation loss: 2.3319116632143655

Epoch: 6| Step: 1
Training loss: 1.3643896579742432
Validation loss: 2.3310761054356894

Epoch: 6| Step: 2
Training loss: 0.9556208848953247
Validation loss: 2.3407860596974692

Epoch: 6| Step: 3
Training loss: 1.497927188873291
Validation loss: 2.311318556467692

Epoch: 6| Step: 4
Training loss: 2.304706335067749
Validation loss: 2.321360150973002

Epoch: 6| Step: 5
Training loss: 0.7252400517463684
Validation loss: 2.337605873743693

Epoch: 6| Step: 6
Training loss: 1.7476134300231934
Validation loss: 2.319997251033783

Epoch: 6| Step: 7
Training loss: 1.8282397985458374
Validation loss: 2.2963762283325195

Epoch: 6| Step: 8
Training loss: 1.061548113822937
Validation loss: 2.3402045567830405

Epoch: 6| Step: 9
Training loss: 1.3336505889892578
Validation loss: 2.346927205721537

Epoch: 6| Step: 10
Training loss: 1.968446969985962
Validation loss: 2.3066765864690146

Epoch: 6| Step: 11
Training loss: 2.606806755065918
Validation loss: 2.3216434717178345

Epoch: 6| Step: 12
Training loss: 1.314115047454834
Validation loss: 2.279955188433329

Epoch: 6| Step: 13
Training loss: 1.2232754230499268
Validation loss: 2.2740829984347024

Epoch: 356| Step: 0
Training loss: 1.4430487155914307
Validation loss: 2.3258515000343323

Epoch: 6| Step: 1
Training loss: 2.5272300243377686
Validation loss: 2.335104068120321

Epoch: 6| Step: 2
Training loss: 1.459867238998413
Validation loss: 2.3454505999883017

Epoch: 6| Step: 3
Training loss: 0.8354953527450562
Validation loss: 2.337306340535482

Epoch: 6| Step: 4
Training loss: 1.7011969089508057
Validation loss: 2.3515238165855408

Epoch: 6| Step: 5
Training loss: 0.961464524269104
Validation loss: 2.3502718210220337

Epoch: 6| Step: 6
Training loss: 1.5446853637695312
Validation loss: 2.3513158758481345

Epoch: 6| Step: 7
Training loss: 1.5085325241088867
Validation loss: 2.3263895908991494

Epoch: 6| Step: 8
Training loss: 2.2385544776916504
Validation loss: 2.3050992488861084

Epoch: 6| Step: 9
Training loss: 1.1581628322601318
Validation loss: 2.353612760702769

Epoch: 6| Step: 10
Training loss: 1.8046318292617798
Validation loss: 2.295916279157003

Epoch: 6| Step: 11
Training loss: 1.3464603424072266
Validation loss: 2.3522605895996094

Epoch: 6| Step: 12
Training loss: 1.0939750671386719
Validation loss: 2.333228369553884

Epoch: 6| Step: 13
Training loss: 1.5935981273651123
Validation loss: 2.3253410855929055

Epoch: 357| Step: 0
Training loss: 1.730085015296936
Validation loss: 2.352555831273397

Epoch: 6| Step: 1
Training loss: 1.6831326484680176
Validation loss: 2.3211652040481567

Epoch: 6| Step: 2
Training loss: 1.4540678262710571
Validation loss: 2.3373600244522095

Epoch: 6| Step: 3
Training loss: 1.2280399799346924
Validation loss: 2.312563141187032

Epoch: 6| Step: 4
Training loss: 1.7815743684768677
Validation loss: 2.2913416624069214

Epoch: 6| Step: 5
Training loss: 1.2600417137145996
Validation loss: 2.3373306592305503

Epoch: 6| Step: 6
Training loss: 1.621732234954834
Validation loss: 2.290277441342672

Epoch: 6| Step: 7
Training loss: 1.3761776685714722
Validation loss: 2.2980916500091553

Epoch: 6| Step: 8
Training loss: 1.545677661895752
Validation loss: 2.3271589875221252

Epoch: 6| Step: 9
Training loss: 0.6670217514038086
Validation loss: 2.342474023501078

Epoch: 6| Step: 10
Training loss: 1.714228630065918
Validation loss: 2.298241297403971

Epoch: 6| Step: 11
Training loss: 1.809303641319275
Validation loss: 2.2580524484316506

Epoch: 6| Step: 12
Training loss: 1.4555975198745728
Validation loss: 2.2622847159703574

Epoch: 6| Step: 13
Training loss: 1.2874864339828491
Validation loss: 2.3085871934890747

Epoch: 358| Step: 0
Training loss: 1.44437575340271
Validation loss: 2.274148861567179

Epoch: 6| Step: 1
Training loss: 1.5317524671554565
Validation loss: 2.262077808380127

Epoch: 6| Step: 2
Training loss: 1.2430083751678467
Validation loss: 2.294746001561483

Epoch: 6| Step: 3
Training loss: 1.4912140369415283
Validation loss: 2.303726633389791

Epoch: 6| Step: 4
Training loss: 2.2099356651306152
Validation loss: 2.269826869169871

Epoch: 6| Step: 5
Training loss: 2.6335818767547607
Validation loss: 2.282677094141642

Epoch: 6| Step: 6
Training loss: 1.2286977767944336
Validation loss: 2.2663848201433816

Epoch: 6| Step: 7
Training loss: 1.2929902076721191
Validation loss: 2.271074970563253

Epoch: 6| Step: 8
Training loss: 1.7265961170196533
Validation loss: 2.319192051887512

Epoch: 6| Step: 9
Training loss: 1.4415616989135742
Validation loss: 2.2712477842966714

Epoch: 6| Step: 10
Training loss: 1.4308817386627197
Validation loss: 2.3332900603612265

Epoch: 6| Step: 11
Training loss: 0.8133111000061035
Validation loss: 2.318051298459371

Epoch: 6| Step: 12
Training loss: 1.8785321712493896
Validation loss: 2.327967325846354

Epoch: 6| Step: 13
Training loss: 1.2451982498168945
Validation loss: 2.328379988670349

Epoch: 359| Step: 0
Training loss: 1.6071447134017944
Validation loss: 2.309968888759613

Epoch: 6| Step: 1
Training loss: 1.9418928623199463
Validation loss: 2.3139082392056785

Epoch: 6| Step: 2
Training loss: 2.0589468479156494
Validation loss: 2.362725774447123

Epoch: 6| Step: 3
Training loss: 1.2456470727920532
Validation loss: 2.378535827000936

Epoch: 6| Step: 4
Training loss: 1.2611608505249023
Validation loss: 2.3226515650749207

Epoch: 6| Step: 5
Training loss: 0.9363419413566589
Validation loss: 2.372280160586039

Epoch: 6| Step: 6
Training loss: 2.1227829456329346
Validation loss: 2.4008354345957437

Epoch: 6| Step: 7
Training loss: 1.8381435871124268
Validation loss: 2.3780739506085715

Epoch: 6| Step: 8
Training loss: 1.374528408050537
Validation loss: 2.348896543184916

Epoch: 6| Step: 9
Training loss: 1.1332731246948242
Validation loss: 2.3627235492070517

Epoch: 6| Step: 10
Training loss: 1.2189066410064697
Validation loss: 2.341406544049581

Epoch: 6| Step: 11
Training loss: 0.9868208169937134
Validation loss: 2.3523279428482056

Epoch: 6| Step: 12
Training loss: 1.1840602159500122
Validation loss: 2.2791151205698648

Epoch: 6| Step: 13
Training loss: 1.8620644807815552
Validation loss: 2.280259589354197

Epoch: 360| Step: 0
Training loss: 2.0529842376708984
Validation loss: 2.262896180152893

Epoch: 6| Step: 1
Training loss: 0.9401856660842896
Validation loss: 2.2893163164456687

Epoch: 6| Step: 2
Training loss: 1.5210556983947754
Validation loss: 2.2908354997634888

Epoch: 6| Step: 3
Training loss: 2.0951294898986816
Validation loss: 2.2909443974494934

Epoch: 6| Step: 4
Training loss: 1.6535062789916992
Validation loss: 2.293286383152008

Epoch: 6| Step: 5
Training loss: 0.7449095845222473
Validation loss: 2.333599011103312

Epoch: 6| Step: 6
Training loss: 1.8512828350067139
Validation loss: 2.387293259302775

Epoch: 6| Step: 7
Training loss: 1.5067442655563354
Validation loss: 2.3768845399220786

Epoch: 6| Step: 8
Training loss: 1.1175798177719116
Validation loss: 2.372135639190674

Epoch: 6| Step: 9
Training loss: 2.129910469055176
Validation loss: 2.3884007334709167

Epoch: 6| Step: 10
Training loss: 0.9084166288375854
Validation loss: 2.34825865427653

Epoch: 6| Step: 11
Training loss: 1.6438868045806885
Validation loss: 2.34836878379186

Epoch: 6| Step: 12
Training loss: 1.3697729110717773
Validation loss: 2.3446184396743774

Epoch: 6| Step: 13
Training loss: 1.7162103652954102
Validation loss: 2.2966754833857217

Epoch: 361| Step: 0
Training loss: 1.8478330373764038
Validation loss: 2.295971234639486

Epoch: 6| Step: 1
Training loss: 1.61349356174469
Validation loss: 2.2789364655812583

Epoch: 6| Step: 2
Training loss: 1.4675495624542236
Validation loss: 2.2728458642959595

Epoch: 6| Step: 3
Training loss: 1.6964805126190186
Validation loss: 2.260829190413157

Epoch: 6| Step: 4
Training loss: 1.7491841316223145
Validation loss: 2.299270490805308

Epoch: 6| Step: 5
Training loss: 1.6469407081604004
Validation loss: 2.314106265703837

Epoch: 6| Step: 6
Training loss: 1.317946195602417
Validation loss: 2.256520410378774

Epoch: 6| Step: 7
Training loss: 1.403836727142334
Validation loss: 2.3155019084612527

Epoch: 6| Step: 8
Training loss: 1.6424819231033325
Validation loss: 2.318085273106893

Epoch: 6| Step: 9
Training loss: 1.5359525680541992
Validation loss: 2.3435071309407554

Epoch: 6| Step: 10
Training loss: 1.582141637802124
Validation loss: 2.3121500412623086

Epoch: 6| Step: 11
Training loss: 1.6256507635116577
Validation loss: 2.3256188233693442

Epoch: 6| Step: 12
Training loss: 1.368425965309143
Validation loss: 2.348246157169342

Epoch: 6| Step: 13
Training loss: 1.1343854665756226
Validation loss: 2.3292969862620034

Epoch: 362| Step: 0
Training loss: 1.0224496126174927
Validation loss: 2.3055303494135537

Epoch: 6| Step: 1
Training loss: 1.342653751373291
Validation loss: 2.3142627080281577

Epoch: 6| Step: 2
Training loss: 2.0266666412353516
Validation loss: 2.322460969289144

Epoch: 6| Step: 3
Training loss: 1.0224568843841553
Validation loss: 2.3443639874458313

Epoch: 6| Step: 4
Training loss: 1.6253479719161987
Validation loss: 2.290625214576721

Epoch: 6| Step: 5
Training loss: 1.3135921955108643
Validation loss: 2.2921066880226135

Epoch: 6| Step: 6
Training loss: 1.2039858102798462
Validation loss: 2.291433334350586

Epoch: 6| Step: 7
Training loss: 1.768561840057373
Validation loss: 2.314369877179464

Epoch: 6| Step: 8
Training loss: 1.6536335945129395
Validation loss: 2.3060856660207114

Epoch: 6| Step: 9
Training loss: 1.2862329483032227
Validation loss: 2.246252179145813

Epoch: 6| Step: 10
Training loss: 1.4873473644256592
Validation loss: 2.286161402861277

Epoch: 6| Step: 11
Training loss: 1.7128379344940186
Validation loss: 2.2848594784736633

Epoch: 6| Step: 12
Training loss: 1.911794662475586
Validation loss: 2.2874467968940735

Epoch: 6| Step: 13
Training loss: 1.594653844833374
Validation loss: 2.326223532358805

Epoch: 363| Step: 0
Training loss: 1.7319084405899048
Validation loss: 2.329740583896637

Epoch: 6| Step: 1
Training loss: 1.2336480617523193
Validation loss: 2.328997790813446

Epoch: 6| Step: 2
Training loss: 2.0209875106811523
Validation loss: 2.3192696372667947

Epoch: 6| Step: 3
Training loss: 1.4266247749328613
Validation loss: 2.328329563140869

Epoch: 6| Step: 4
Training loss: 0.8043932914733887
Validation loss: 2.3392560879389444

Epoch: 6| Step: 5
Training loss: 1.6389741897583008
Validation loss: 2.3416579167048135

Epoch: 6| Step: 6
Training loss: 1.09389328956604
Validation loss: 2.35983415444692

Epoch: 6| Step: 7
Training loss: 1.6131662130355835
Validation loss: 2.3484074076016745

Epoch: 6| Step: 8
Training loss: 1.7599661350250244
Validation loss: 2.3548067013422647

Epoch: 6| Step: 9
Training loss: 1.2711544036865234
Validation loss: 2.3498944640159607

Epoch: 6| Step: 10
Training loss: 1.2058072090148926
Validation loss: 2.35936039686203

Epoch: 6| Step: 11
Training loss: 1.3806767463684082
Validation loss: 2.332551042238871

Epoch: 6| Step: 12
Training loss: 1.5141513347625732
Validation loss: 2.3385708332061768

Epoch: 6| Step: 13
Training loss: 2.1311914920806885
Validation loss: 2.3193061153093972

Epoch: 364| Step: 0
Training loss: 1.3586063385009766
Validation loss: 2.312080144882202

Epoch: 6| Step: 1
Training loss: 2.488265037536621
Validation loss: 2.3214036424954734

Epoch: 6| Step: 2
Training loss: 1.0285061597824097
Validation loss: 2.3096319437026978

Epoch: 6| Step: 3
Training loss: 2.0499236583709717
Validation loss: 2.34213920434316

Epoch: 6| Step: 4
Training loss: 1.4043185710906982
Validation loss: 2.32431032260259

Epoch: 6| Step: 5
Training loss: 1.4382212162017822
Validation loss: 2.2948940793673196

Epoch: 6| Step: 6
Training loss: 1.1399998664855957
Validation loss: 2.2961421410242715

Epoch: 6| Step: 7
Training loss: 1.0078153610229492
Validation loss: 2.294779042402903

Epoch: 6| Step: 8
Training loss: 1.6256699562072754
Validation loss: 2.3229538003603616

Epoch: 6| Step: 9
Training loss: 1.4445744752883911
Validation loss: 2.288597265879313

Epoch: 6| Step: 10
Training loss: 1.2550760507583618
Validation loss: 2.3040780623753867

Epoch: 6| Step: 11
Training loss: 1.475834608078003
Validation loss: 2.2686100006103516

Epoch: 6| Step: 12
Training loss: 1.2377605438232422
Validation loss: 2.2614011764526367

Epoch: 6| Step: 13
Training loss: 1.8403451442718506
Validation loss: 2.2669634222984314

Epoch: 365| Step: 0
Training loss: 1.0480557680130005
Validation loss: 2.2819629311561584

Epoch: 6| Step: 1
Training loss: 1.5101147890090942
Validation loss: 2.260077953338623

Epoch: 6| Step: 2
Training loss: 1.8841755390167236
Validation loss: 2.2672818104426065

Epoch: 6| Step: 3
Training loss: 1.0419108867645264
Validation loss: 2.2995799779891968

Epoch: 6| Step: 4
Training loss: 1.619470238685608
Validation loss: 2.2997869849205017

Epoch: 6| Step: 5
Training loss: 1.4842746257781982
Validation loss: 2.314457813898722

Epoch: 6| Step: 6
Training loss: 1.41554594039917
Validation loss: 2.3254420359929404

Epoch: 6| Step: 7
Training loss: 1.161628246307373
Validation loss: 2.3493837118148804

Epoch: 6| Step: 8
Training loss: 2.2190065383911133
Validation loss: 2.3276281356811523

Epoch: 6| Step: 9
Training loss: 1.8232821226119995
Validation loss: 2.3408090273539224

Epoch: 6| Step: 10
Training loss: 0.9113113284111023
Validation loss: 2.329068382581075

Epoch: 6| Step: 11
Training loss: 1.709397792816162
Validation loss: 2.3563690781593323

Epoch: 6| Step: 12
Training loss: 1.8174225091934204
Validation loss: 2.3516236543655396

Epoch: 6| Step: 13
Training loss: 0.7633852362632751
Validation loss: 2.3007699251174927

Epoch: 366| Step: 0
Training loss: 1.405961513519287
Validation loss: 2.3162690003712973

Epoch: 6| Step: 1
Training loss: 1.638183355331421
Validation loss: 2.305997093518575

Epoch: 6| Step: 2
Training loss: 1.3690528869628906
Validation loss: 2.289742370446523

Epoch: 6| Step: 3
Training loss: 1.2558743953704834
Validation loss: 2.262456158796946

Epoch: 6| Step: 4
Training loss: 2.1385934352874756
Validation loss: 2.2826178669929504

Epoch: 6| Step: 5
Training loss: 1.3382238149642944
Validation loss: 2.2859238187472024

Epoch: 6| Step: 6
Training loss: 1.485066533088684
Validation loss: 2.2639493544896445

Epoch: 6| Step: 7
Training loss: 1.3272173404693604
Validation loss: 2.2902400294939675

Epoch: 6| Step: 8
Training loss: 1.4713733196258545
Validation loss: 2.286357124646505

Epoch: 6| Step: 9
Training loss: 1.469881296157837
Validation loss: 2.2766083081563315

Epoch: 6| Step: 10
Training loss: 2.0572335720062256
Validation loss: 2.2955476442972818

Epoch: 6| Step: 11
Training loss: 1.2432743310928345
Validation loss: 2.3092301289240518

Epoch: 6| Step: 12
Training loss: 0.8711049556732178
Validation loss: 2.342646916707357

Epoch: 6| Step: 13
Training loss: 1.8825819492340088
Validation loss: 2.339737892150879

Epoch: 367| Step: 0
Training loss: 1.5574594736099243
Validation loss: 2.3435311516126

Epoch: 6| Step: 1
Training loss: 1.8361809253692627
Validation loss: 2.3452672958374023

Epoch: 6| Step: 2
Training loss: 0.8728790283203125
Validation loss: 2.3516193429629006

Epoch: 6| Step: 3
Training loss: 1.0319656133651733
Validation loss: 2.3482450048128762

Epoch: 6| Step: 4
Training loss: 1.639227032661438
Validation loss: 2.3402498364448547

Epoch: 6| Step: 5
Training loss: 1.5709078311920166
Validation loss: 2.3574631611506143

Epoch: 6| Step: 6
Training loss: 2.341158390045166
Validation loss: 2.3680866161982217

Epoch: 6| Step: 7
Training loss: 2.016324043273926
Validation loss: 2.3803704182306924

Epoch: 6| Step: 8
Training loss: 1.6881628036499023
Validation loss: 2.3705082734425864

Epoch: 6| Step: 9
Training loss: 1.7314205169677734
Validation loss: 2.406362692515055

Epoch: 6| Step: 10
Training loss: 1.1554656028747559
Validation loss: 2.3549598852793374

Epoch: 6| Step: 11
Training loss: 1.2494663000106812
Validation loss: 2.385128299395243

Epoch: 6| Step: 12
Training loss: 1.5708820819854736
Validation loss: 2.3520996371905007

Epoch: 6| Step: 13
Training loss: 1.346811294555664
Validation loss: 2.341820319493612

Epoch: 368| Step: 0
Training loss: 1.101961374282837
Validation loss: 2.3069961071014404

Epoch: 6| Step: 1
Training loss: 1.408994436264038
Validation loss: 2.33155886332194

Epoch: 6| Step: 2
Training loss: 1.7763609886169434
Validation loss: 2.356769402821859

Epoch: 6| Step: 3
Training loss: 1.5127122402191162
Validation loss: 2.2780843377113342

Epoch: 6| Step: 4
Training loss: 1.186164379119873
Validation loss: 2.3215826749801636

Epoch: 6| Step: 5
Training loss: 1.005745530128479
Validation loss: 2.295833150545756

Epoch: 6| Step: 6
Training loss: 1.4917168617248535
Validation loss: 2.2862345377604165

Epoch: 6| Step: 7
Training loss: 2.2144904136657715
Validation loss: 2.3141284386316934

Epoch: 6| Step: 8
Training loss: 1.4345424175262451
Validation loss: 2.3073593775431314

Epoch: 6| Step: 9
Training loss: 1.5271565914154053
Validation loss: 2.2980546156565347

Epoch: 6| Step: 10
Training loss: 1.5504885911941528
Validation loss: 2.3104936679204306

Epoch: 6| Step: 11
Training loss: 1.3420608043670654
Validation loss: 2.2644358476003013

Epoch: 6| Step: 12
Training loss: 1.1265379190444946
Validation loss: 2.2996666630109153

Epoch: 6| Step: 13
Training loss: 1.6403582096099854
Validation loss: 2.3331684271494546

Epoch: 369| Step: 0
Training loss: 1.158889651298523
Validation loss: 2.327652931213379

Epoch: 6| Step: 1
Training loss: 1.1382462978363037
Validation loss: 2.3441420197486877

Epoch: 6| Step: 2
Training loss: 1.6893190145492554
Validation loss: 2.304460108280182

Epoch: 6| Step: 3
Training loss: 1.3039109706878662
Validation loss: 2.318486452102661

Epoch: 6| Step: 4
Training loss: 1.4286158084869385
Validation loss: 2.341739853223165

Epoch: 6| Step: 5
Training loss: 1.6667453050613403
Validation loss: 2.32837184270223

Epoch: 6| Step: 6
Training loss: 1.1552066802978516
Validation loss: 2.3419950803120932

Epoch: 6| Step: 7
Training loss: 2.144636392593384
Validation loss: 2.290333072344462

Epoch: 6| Step: 8
Training loss: 0.8662718534469604
Validation loss: 2.273747722307841

Epoch: 6| Step: 9
Training loss: 2.015451431274414
Validation loss: 2.3235947291056314

Epoch: 6| Step: 10
Training loss: 2.4517769813537598
Validation loss: 2.3002820213635764

Epoch: 6| Step: 11
Training loss: 1.5465525388717651
Validation loss: 2.3186795711517334

Epoch: 6| Step: 12
Training loss: 0.4536122679710388
Validation loss: 2.3157838185628257

Epoch: 6| Step: 13
Training loss: 1.5034759044647217
Validation loss: 2.339116632938385

Epoch: 370| Step: 0
Training loss: 1.489890694618225
Validation loss: 2.2888543605804443

Epoch: 6| Step: 1
Training loss: 0.9504421949386597
Validation loss: 2.3458675146102905

Epoch: 6| Step: 2
Training loss: 1.540631651878357
Validation loss: 2.3157745401064553

Epoch: 6| Step: 3
Training loss: 0.9452797770500183
Validation loss: 2.3700518012046814

Epoch: 6| Step: 4
Training loss: 1.1487345695495605
Validation loss: 2.3478426535924277

Epoch: 6| Step: 5
Training loss: 1.4908275604248047
Validation loss: 2.344857136408488

Epoch: 6| Step: 6
Training loss: 1.8270028829574585
Validation loss: 2.3252608378728232

Epoch: 6| Step: 7
Training loss: 1.493890404701233
Validation loss: 2.3391780455907187

Epoch: 6| Step: 8
Training loss: 1.6571483612060547
Validation loss: 2.325094004472097

Epoch: 6| Step: 9
Training loss: 1.1571531295776367
Validation loss: 2.357834756374359

Epoch: 6| Step: 10
Training loss: 1.5545227527618408
Validation loss: 2.3175222078959146

Epoch: 6| Step: 11
Training loss: 2.013807773590088
Validation loss: 2.294332961241404

Epoch: 6| Step: 12
Training loss: 1.558851718902588
Validation loss: 2.314607044061025

Epoch: 6| Step: 13
Training loss: 2.4046385288238525
Validation loss: 2.3164244492848716

Epoch: 371| Step: 0
Training loss: 2.1461598873138428
Validation loss: 2.308384815851847

Epoch: 6| Step: 1
Training loss: 1.984960675239563
Validation loss: 2.3475367228190103

Epoch: 6| Step: 2
Training loss: 1.4213181734085083
Validation loss: 2.359774390856425

Epoch: 6| Step: 3
Training loss: 1.202500343322754
Validation loss: 2.351189454396566

Epoch: 6| Step: 4
Training loss: 1.6483612060546875
Validation loss: 2.3375316858291626

Epoch: 6| Step: 5
Training loss: 1.8101952075958252
Validation loss: 2.343866149584452

Epoch: 6| Step: 6
Training loss: 1.0079063177108765
Validation loss: 2.305249651273092

Epoch: 6| Step: 7
Training loss: 1.2210291624069214
Validation loss: 2.3059216936429343

Epoch: 6| Step: 8
Training loss: 1.3182671070098877
Validation loss: 2.2695713440577188

Epoch: 6| Step: 9
Training loss: 1.6804739236831665
Validation loss: 2.2801456650098166

Epoch: 6| Step: 10
Training loss: 1.2206683158874512
Validation loss: 2.260189334551493

Epoch: 6| Step: 11
Training loss: 1.5020232200622559
Validation loss: 2.2463412086168923

Epoch: 6| Step: 12
Training loss: 1.4756197929382324
Validation loss: 2.2488026221593223

Epoch: 6| Step: 13
Training loss: 1.1022896766662598
Validation loss: 2.2625149488449097

Epoch: 372| Step: 0
Training loss: 1.3136463165283203
Validation loss: 2.269535938898722

Epoch: 6| Step: 1
Training loss: 1.5524158477783203
Validation loss: 2.31506355603536

Epoch: 6| Step: 2
Training loss: 0.9783170223236084
Validation loss: 2.269981344540914

Epoch: 6| Step: 3
Training loss: 1.322722315788269
Validation loss: 2.319824695587158

Epoch: 6| Step: 4
Training loss: 1.9597103595733643
Validation loss: 2.2618970473607383

Epoch: 6| Step: 5
Training loss: 2.5476622581481934
Validation loss: 2.323291798432668

Epoch: 6| Step: 6
Training loss: 1.2033238410949707
Validation loss: 2.327697475751241

Epoch: 6| Step: 7
Training loss: 1.1238906383514404
Validation loss: 2.300732135772705

Epoch: 6| Step: 8
Training loss: 1.9940078258514404
Validation loss: 2.3395624359448752

Epoch: 6| Step: 9
Training loss: 1.0575554370880127
Validation loss: 2.3044275840123496

Epoch: 6| Step: 10
Training loss: 0.434236615896225
Validation loss: 2.356660624345144

Epoch: 6| Step: 11
Training loss: 1.6906667947769165
Validation loss: 2.347084164619446

Epoch: 6| Step: 12
Training loss: 1.3764959573745728
Validation loss: 2.3976136445999146

Epoch: 6| Step: 13
Training loss: 1.4191102981567383
Validation loss: 2.3259627421696982

Epoch: 373| Step: 0
Training loss: 1.5077632665634155
Validation loss: 2.30883397658666

Epoch: 6| Step: 1
Training loss: 1.77581787109375
Validation loss: 2.3071325222651162

Epoch: 6| Step: 2
Training loss: 1.4194438457489014
Validation loss: 2.329847991466522

Epoch: 6| Step: 3
Training loss: 1.2601898908615112
Validation loss: 2.3262039025624595

Epoch: 6| Step: 4
Training loss: 1.2624820470809937
Validation loss: 2.2985917727152505

Epoch: 6| Step: 5
Training loss: 1.558544397354126
Validation loss: 2.292264441649119

Epoch: 6| Step: 6
Training loss: 1.2398748397827148
Validation loss: 2.292338212331136

Epoch: 6| Step: 7
Training loss: 1.4118688106536865
Validation loss: 2.3152822256088257

Epoch: 6| Step: 8
Training loss: 1.3490910530090332
Validation loss: 2.3366365830103555

Epoch: 6| Step: 9
Training loss: 1.3526372909545898
Validation loss: 2.3463863730430603

Epoch: 6| Step: 10
Training loss: 1.5831406116485596
Validation loss: 2.3278841376304626

Epoch: 6| Step: 11
Training loss: 1.300952434539795
Validation loss: 2.3804672956466675

Epoch: 6| Step: 12
Training loss: 1.1352298259735107
Validation loss: 2.3633111317952475

Epoch: 6| Step: 13
Training loss: 1.7805860042572021
Validation loss: 2.345900535583496

Epoch: 374| Step: 0
Training loss: 1.2089680433273315
Validation loss: 2.3714556097984314

Epoch: 6| Step: 1
Training loss: 0.9617272019386292
Validation loss: 2.362650156021118

Epoch: 6| Step: 2
Training loss: 1.8269829750061035
Validation loss: 2.342727621396383

Epoch: 6| Step: 3
Training loss: 1.1061002016067505
Validation loss: 2.3767438332239785

Epoch: 6| Step: 4
Training loss: 1.6496670246124268
Validation loss: 2.3687007427215576

Epoch: 6| Step: 5
Training loss: 2.08396315574646
Validation loss: 2.302269915739695

Epoch: 6| Step: 6
Training loss: 1.0637292861938477
Validation loss: 2.3453973531723022

Epoch: 6| Step: 7
Training loss: 1.6525038480758667
Validation loss: 2.336874266465505

Epoch: 6| Step: 8
Training loss: 1.7630882263183594
Validation loss: 2.252493381500244

Epoch: 6| Step: 9
Training loss: 1.0139718055725098
Validation loss: 2.2985916137695312

Epoch: 6| Step: 10
Training loss: 1.366472601890564
Validation loss: 2.2914107839266458

Epoch: 6| Step: 11
Training loss: 1.9248006343841553
Validation loss: 2.2915902932484946

Epoch: 6| Step: 12
Training loss: 0.7637649774551392
Validation loss: 2.236838420232137

Epoch: 6| Step: 13
Training loss: 1.5282182693481445
Validation loss: 2.2662639021873474

Epoch: 375| Step: 0
Training loss: 1.7543660402297974
Validation loss: 2.271760880947113

Epoch: 6| Step: 1
Training loss: 2.0004453659057617
Validation loss: 2.2681757609049478

Epoch: 6| Step: 2
Training loss: 1.1475074291229248
Validation loss: 2.266495704650879

Epoch: 6| Step: 3
Training loss: 1.7916955947875977
Validation loss: 2.264531890551249

Epoch: 6| Step: 4
Training loss: 1.390381097793579
Validation loss: 2.3045217990875244

Epoch: 6| Step: 5
Training loss: 0.9696065187454224
Validation loss: 2.303255001703898

Epoch: 6| Step: 6
Training loss: 0.5230424404144287
Validation loss: 2.309485673904419

Epoch: 6| Step: 7
Training loss: 1.2871954441070557
Validation loss: 2.32635227839152

Epoch: 6| Step: 8
Training loss: 1.9633784294128418
Validation loss: 2.305513024330139

Epoch: 6| Step: 9
Training loss: 1.5862855911254883
Validation loss: 2.3435158332188926

Epoch: 6| Step: 10
Training loss: 0.8329878449440002
Validation loss: 2.3442286252975464

Epoch: 6| Step: 11
Training loss: 1.2027976512908936
Validation loss: 2.3317017356554666

Epoch: 6| Step: 12
Training loss: 2.016248941421509
Validation loss: 2.2847603956858316

Epoch: 6| Step: 13
Training loss: 1.5836597681045532
Validation loss: 2.2771050135294595

Epoch: 376| Step: 0
Training loss: 0.9361264705657959
Validation loss: 2.3380635579427085

Epoch: 6| Step: 1
Training loss: 1.3401377201080322
Validation loss: 2.308182199796041

Epoch: 6| Step: 2
Training loss: 1.014812707901001
Validation loss: 2.273441513379415

Epoch: 6| Step: 3
Training loss: 1.9191312789916992
Validation loss: 2.3167895873387656

Epoch: 6| Step: 4
Training loss: 1.3673622608184814
Validation loss: 2.2513328790664673

Epoch: 6| Step: 5
Training loss: 1.9043240547180176
Validation loss: 2.268335004647573

Epoch: 6| Step: 6
Training loss: 1.310149908065796
Validation loss: 2.2757007678349814

Epoch: 6| Step: 7
Training loss: 1.673209547996521
Validation loss: 2.22424844900767

Epoch: 6| Step: 8
Training loss: 0.9890636205673218
Validation loss: 2.260968883832296

Epoch: 6| Step: 9
Training loss: 1.712911605834961
Validation loss: 2.3037792841593423

Epoch: 6| Step: 10
Training loss: 1.4012924432754517
Validation loss: 2.2914486726125083

Epoch: 6| Step: 11
Training loss: 1.6770744323730469
Validation loss: 2.28097273906072

Epoch: 6| Step: 12
Training loss: 1.0649254322052002
Validation loss: 2.306810657183329

Epoch: 6| Step: 13
Training loss: 1.199669599533081
Validation loss: 2.2597908973693848

Epoch: 377| Step: 0
Training loss: 1.6891844272613525
Validation loss: 2.3198809226353965

Epoch: 6| Step: 1
Training loss: 1.8695745468139648
Validation loss: 2.3439824978510537

Epoch: 6| Step: 2
Training loss: 1.2473042011260986
Validation loss: 2.3472810983657837

Epoch: 6| Step: 3
Training loss: 1.7699848413467407
Validation loss: 2.305495341618856

Epoch: 6| Step: 4
Training loss: 1.3069539070129395
Validation loss: 2.308091104030609

Epoch: 6| Step: 5
Training loss: 1.6051709651947021
Validation loss: 2.2908568382263184

Epoch: 6| Step: 6
Training loss: 1.281130313873291
Validation loss: 2.3363839785257974

Epoch: 6| Step: 7
Training loss: 1.6740931272506714
Validation loss: 2.3046837647755942

Epoch: 6| Step: 8
Training loss: 0.8059059977531433
Validation loss: 2.3300873239835105

Epoch: 6| Step: 9
Training loss: 1.7566014528274536
Validation loss: 2.2984423836072287

Epoch: 6| Step: 10
Training loss: 1.5712984800338745
Validation loss: 2.296806752681732

Epoch: 6| Step: 11
Training loss: 1.5140457153320312
Validation loss: 2.2740299105644226

Epoch: 6| Step: 12
Training loss: 0.6516371965408325
Validation loss: 2.327306310335795

Epoch: 6| Step: 13
Training loss: 1.2133837938308716
Validation loss: 2.283746083577474

Epoch: 378| Step: 0
Training loss: 1.2536197900772095
Validation loss: 2.2958229780197144

Epoch: 6| Step: 1
Training loss: 1.4183433055877686
Validation loss: 2.3157050808270774

Epoch: 6| Step: 2
Training loss: 1.0669432878494263
Validation loss: 2.263856371243795

Epoch: 6| Step: 3
Training loss: 1.9962739944458008
Validation loss: 2.2652413050333657

Epoch: 6| Step: 4
Training loss: 2.2335214614868164
Validation loss: 2.271965821584066

Epoch: 6| Step: 5
Training loss: 2.4068055152893066
Validation loss: 2.2472795248031616

Epoch: 6| Step: 6
Training loss: 1.973304271697998
Validation loss: 2.2393053770065308

Epoch: 6| Step: 7
Training loss: 0.8462461829185486
Validation loss: 2.2456430991490683

Epoch: 6| Step: 8
Training loss: 1.5220506191253662
Validation loss: 2.260402421156565

Epoch: 6| Step: 9
Training loss: 1.7624268531799316
Validation loss: 2.2689440647761026

Epoch: 6| Step: 10
Training loss: 1.2258234024047852
Validation loss: 2.3136152227719626

Epoch: 6| Step: 11
Training loss: 1.7319083213806152
Validation loss: 2.308166821797689

Epoch: 6| Step: 12
Training loss: 1.4037195444107056
Validation loss: 2.3236262003580728

Epoch: 6| Step: 13
Training loss: 1.0896804332733154
Validation loss: 2.3191598852475486

Epoch: 379| Step: 0
Training loss: 2.112694025039673
Validation loss: 2.3127413988113403

Epoch: 6| Step: 1
Training loss: 1.7279706001281738
Validation loss: 2.317227562268575

Epoch: 6| Step: 2
Training loss: 1.5404331684112549
Validation loss: 2.2909777561823526

Epoch: 6| Step: 3
Training loss: 0.9812451004981995
Validation loss: 2.3214284777641296

Epoch: 6| Step: 4
Training loss: 1.6982207298278809
Validation loss: 2.320435881614685

Epoch: 6| Step: 5
Training loss: 1.1520994901657104
Validation loss: 2.303465962409973

Epoch: 6| Step: 6
Training loss: 1.4513442516326904
Validation loss: 2.2128645976384482

Epoch: 6| Step: 7
Training loss: 2.1007261276245117
Validation loss: 2.292815387248993

Epoch: 6| Step: 8
Training loss: 1.5160220861434937
Validation loss: 2.2561659018198648

Epoch: 6| Step: 9
Training loss: 1.5220019817352295
Validation loss: 2.2582642634709678

Epoch: 6| Step: 10
Training loss: 1.6658447980880737
Validation loss: 2.250761866569519

Epoch: 6| Step: 11
Training loss: 1.1292204856872559
Validation loss: 2.228885610898336

Epoch: 6| Step: 12
Training loss: 0.773574948310852
Validation loss: 2.2727597753206887

Epoch: 6| Step: 13
Training loss: 1.6445808410644531
Validation loss: 2.2398137847582498

Epoch: 380| Step: 0
Training loss: 1.3175674676895142
Validation loss: 2.261413017908732

Epoch: 6| Step: 1
Training loss: 1.6614439487457275
Validation loss: 2.2681776682535806

Epoch: 6| Step: 2
Training loss: 1.5078227519989014
Validation loss: 2.283050020535787

Epoch: 6| Step: 3
Training loss: 1.845995306968689
Validation loss: 2.309716284275055

Epoch: 6| Step: 4
Training loss: 1.3064790964126587
Validation loss: 2.318912704785665

Epoch: 6| Step: 5
Training loss: 1.7353386878967285
Validation loss: 2.338955362637838

Epoch: 6| Step: 6
Training loss: 1.0369269847869873
Validation loss: 2.2787227431933084

Epoch: 6| Step: 7
Training loss: 1.3407340049743652
Validation loss: 2.277458131313324

Epoch: 6| Step: 8
Training loss: 1.9931049346923828
Validation loss: 2.251363138357798

Epoch: 6| Step: 9
Training loss: 1.1601842641830444
Validation loss: 2.240497867266337

Epoch: 6| Step: 10
Training loss: 1.4229470491409302
Validation loss: 2.2614641586939492

Epoch: 6| Step: 11
Training loss: 1.448155403137207
Validation loss: 2.2429722348848977

Epoch: 6| Step: 12
Training loss: 1.5365386009216309
Validation loss: 2.2572471300760903

Epoch: 6| Step: 13
Training loss: 1.4258828163146973
Validation loss: 2.231604258219401

Epoch: 381| Step: 0
Training loss: 0.9546483755111694
Validation loss: 2.2796090841293335

Epoch: 6| Step: 1
Training loss: 1.485673189163208
Validation loss: 2.2425885995229087

Epoch: 6| Step: 2
Training loss: 0.9189860224723816
Validation loss: 2.255288243293762

Epoch: 6| Step: 3
Training loss: 1.9397985935211182
Validation loss: 2.2933586041132608

Epoch: 6| Step: 4
Training loss: 1.3887919187545776
Validation loss: 2.2406723499298096

Epoch: 6| Step: 5
Training loss: 1.5178180932998657
Validation loss: 2.300447702407837

Epoch: 6| Step: 6
Training loss: 1.582165002822876
Validation loss: 2.265417456626892

Epoch: 6| Step: 7
Training loss: 2.362825632095337
Validation loss: 2.307884077231089

Epoch: 6| Step: 8
Training loss: 1.531948447227478
Validation loss: 2.3258541425069175

Epoch: 6| Step: 9
Training loss: 1.3985267877578735
Validation loss: 2.3344354828198752

Epoch: 6| Step: 10
Training loss: 1.137756586074829
Validation loss: 2.3216851949691772

Epoch: 6| Step: 11
Training loss: 1.3314900398254395
Validation loss: 2.275130252043406

Epoch: 6| Step: 12
Training loss: 1.2618108987808228
Validation loss: 2.319838802019755

Epoch: 6| Step: 13
Training loss: 1.5585315227508545
Validation loss: 2.2904813289642334

Epoch: 382| Step: 0
Training loss: 1.4439361095428467
Validation loss: 2.258873701095581

Epoch: 6| Step: 1
Training loss: 0.7935646772384644
Validation loss: 2.270071049531301

Epoch: 6| Step: 2
Training loss: 0.8662939071655273
Validation loss: 2.2713886499404907

Epoch: 6| Step: 3
Training loss: 1.1979365348815918
Validation loss: 2.260991334915161

Epoch: 6| Step: 4
Training loss: 1.1294853687286377
Validation loss: 2.2855120102564492

Epoch: 6| Step: 5
Training loss: 2.02117657661438
Validation loss: 2.2991305589675903

Epoch: 6| Step: 6
Training loss: 1.3268557786941528
Validation loss: 2.2860509753227234

Epoch: 6| Step: 7
Training loss: 1.1466147899627686
Validation loss: 2.3225154081980386

Epoch: 6| Step: 8
Training loss: 1.8070881366729736
Validation loss: 2.2843196590741477

Epoch: 6| Step: 9
Training loss: 0.9111775159835815
Validation loss: 2.2492517630259194

Epoch: 6| Step: 10
Training loss: 1.3065932989120483
Validation loss: 2.2939616441726685

Epoch: 6| Step: 11
Training loss: 1.654577374458313
Validation loss: 2.273433049519857

Epoch: 6| Step: 12
Training loss: 2.1612887382507324
Validation loss: 2.302332639694214

Epoch: 6| Step: 13
Training loss: 2.4370503425598145
Validation loss: 2.3005345662434897

Epoch: 383| Step: 0
Training loss: 1.2862982749938965
Validation loss: 2.2899962067604065

Epoch: 6| Step: 1
Training loss: 1.4946258068084717
Validation loss: 2.278654177983602

Epoch: 6| Step: 2
Training loss: 1.1638939380645752
Validation loss: 2.3043393890062966

Epoch: 6| Step: 3
Training loss: 1.2503104209899902
Validation loss: 2.2782922188440957

Epoch: 6| Step: 4
Training loss: 2.2353901863098145
Validation loss: 2.3023196856180825

Epoch: 6| Step: 5
Training loss: 2.051616668701172
Validation loss: 2.2705561319986978

Epoch: 6| Step: 6
Training loss: 1.2630168199539185
Validation loss: 2.2732266982396445

Epoch: 6| Step: 7
Training loss: 1.724635362625122
Validation loss: 2.2671972513198853

Epoch: 6| Step: 8
Training loss: 0.9821471571922302
Validation loss: 2.323756297429403

Epoch: 6| Step: 9
Training loss: 1.6842398643493652
Validation loss: 2.257183611392975

Epoch: 6| Step: 10
Training loss: 0.8099279403686523
Validation loss: 2.277186155319214

Epoch: 6| Step: 11
Training loss: 0.9997147917747498
Validation loss: 2.2648080786069236

Epoch: 6| Step: 12
Training loss: 1.982650876045227
Validation loss: 2.2702091137568154

Epoch: 6| Step: 13
Training loss: 2.174227714538574
Validation loss: 2.311353305975596

Epoch: 384| Step: 0
Training loss: 1.215279459953308
Validation loss: 2.396860043207804

Epoch: 6| Step: 1
Training loss: 0.9994697570800781
Validation loss: 2.331067522366842

Epoch: 6| Step: 2
Training loss: 1.3828157186508179
Validation loss: 2.326668302218119

Epoch: 6| Step: 3
Training loss: 1.6068953275680542
Validation loss: 2.3234601616859436

Epoch: 6| Step: 4
Training loss: 1.5009372234344482
Validation loss: 2.3188806970914206

Epoch: 6| Step: 5
Training loss: 1.7438225746154785
Validation loss: 2.3400917847951255

Epoch: 6| Step: 6
Training loss: 1.5085561275482178
Validation loss: 2.400038162867228

Epoch: 6| Step: 7
Training loss: 1.9850670099258423
Validation loss: 2.3926031390825906

Epoch: 6| Step: 8
Training loss: 1.2599613666534424
Validation loss: 2.43121999502182

Epoch: 6| Step: 9
Training loss: 1.2627274990081787
Validation loss: 2.4565691153208413

Epoch: 6| Step: 10
Training loss: 1.4275686740875244
Validation loss: 2.4485100706418357

Epoch: 6| Step: 11
Training loss: 1.3318692445755005
Validation loss: 2.433534562587738

Epoch: 6| Step: 12
Training loss: 1.7271676063537598
Validation loss: 2.470077077547709

Epoch: 6| Step: 13
Training loss: 1.8053264617919922
Validation loss: 2.441402316093445

Epoch: 385| Step: 0
Training loss: 1.4819326400756836
Validation loss: 2.4282127618789673

Epoch: 6| Step: 1
Training loss: 0.9912962317466736
Validation loss: 2.40057102839152

Epoch: 6| Step: 2
Training loss: 1.5144373178482056
Validation loss: 2.4010629653930664

Epoch: 6| Step: 3
Training loss: 1.3657575845718384
Validation loss: 2.3363652427991233

Epoch: 6| Step: 4
Training loss: 1.4526152610778809
Validation loss: 2.3274702231089273

Epoch: 6| Step: 5
Training loss: 1.5805586576461792
Validation loss: 2.383124311765035

Epoch: 6| Step: 6
Training loss: 1.4452455043792725
Validation loss: 2.317597587903341

Epoch: 6| Step: 7
Training loss: 1.610656499862671
Validation loss: 2.298400620619456

Epoch: 6| Step: 8
Training loss: 1.1668143272399902
Validation loss: 2.3102664152781167

Epoch: 6| Step: 9
Training loss: 1.6715497970581055
Validation loss: 2.3198118011156716

Epoch: 6| Step: 10
Training loss: 1.7536547183990479
Validation loss: 2.347012758255005

Epoch: 6| Step: 11
Training loss: 1.0011374950408936
Validation loss: 2.350264608860016

Epoch: 6| Step: 12
Training loss: 1.6698288917541504
Validation loss: 2.3481987714767456

Epoch: 6| Step: 13
Training loss: 1.1955467462539673
Validation loss: 2.315802534421285

Epoch: 386| Step: 0
Training loss: 1.1707037687301636
Validation loss: 2.294912099838257

Epoch: 6| Step: 1
Training loss: 1.3928037881851196
Validation loss: 2.3313366373380027

Epoch: 6| Step: 2
Training loss: 1.506659746170044
Validation loss: 2.301636536916097

Epoch: 6| Step: 3
Training loss: 0.7870109677314758
Validation loss: 2.3215502897898355

Epoch: 6| Step: 4
Training loss: 1.3074332475662231
Validation loss: 2.331505616505941

Epoch: 6| Step: 5
Training loss: 1.9514429569244385
Validation loss: 2.3539621035257974

Epoch: 6| Step: 6
Training loss: 1.3470394611358643
Validation loss: 2.3132293025652566

Epoch: 6| Step: 7
Training loss: 1.396592140197754
Validation loss: 2.3214826583862305

Epoch: 6| Step: 8
Training loss: 1.8048477172851562
Validation loss: 2.3051569064458213

Epoch: 6| Step: 9
Training loss: 2.439235210418701
Validation loss: 2.246738096078237

Epoch: 6| Step: 10
Training loss: 1.2291069030761719
Validation loss: 2.2863662242889404

Epoch: 6| Step: 11
Training loss: 0.9156515598297119
Validation loss: 2.2843693097432456

Epoch: 6| Step: 12
Training loss: 1.1278618574142456
Validation loss: 2.259652554988861

Epoch: 6| Step: 13
Training loss: 1.2476179599761963
Validation loss: 2.265001893043518

Epoch: 387| Step: 0
Training loss: 1.1195694208145142
Validation loss: 2.258962074915568

Epoch: 6| Step: 1
Training loss: 1.3021292686462402
Validation loss: 2.275558829307556

Epoch: 6| Step: 2
Training loss: 0.8928433060646057
Validation loss: 2.2859076261520386

Epoch: 6| Step: 3
Training loss: 1.2889554500579834
Validation loss: 2.299736797809601

Epoch: 6| Step: 4
Training loss: 1.7395224571228027
Validation loss: 2.2507245540618896

Epoch: 6| Step: 5
Training loss: 1.2277308702468872
Validation loss: 2.3082221349080405

Epoch: 6| Step: 6
Training loss: 1.8897805213928223
Validation loss: 2.3049279054005942

Epoch: 6| Step: 7
Training loss: 1.6308937072753906
Validation loss: 2.3142830530802407

Epoch: 6| Step: 8
Training loss: 1.146146297454834
Validation loss: 2.279901365439097

Epoch: 6| Step: 9
Training loss: 1.5659592151641846
Validation loss: 2.3472219506899514

Epoch: 6| Step: 10
Training loss: 1.8540518283843994
Validation loss: 2.326542019844055

Epoch: 6| Step: 11
Training loss: 1.0985339879989624
Validation loss: 2.3139439026514688

Epoch: 6| Step: 12
Training loss: 1.4335216283798218
Validation loss: 2.308638016382853

Epoch: 6| Step: 13
Training loss: 1.0734260082244873
Validation loss: 2.282574017842611

Epoch: 388| Step: 0
Training loss: 2.7689452171325684
Validation loss: 2.2863965233167014

Epoch: 6| Step: 1
Training loss: 0.9004335999488831
Validation loss: 2.2670714457829795

Epoch: 6| Step: 2
Training loss: 0.8191460371017456
Validation loss: 2.3046772877375283

Epoch: 6| Step: 3
Training loss: 0.9351262450218201
Validation loss: 2.3242536187171936

Epoch: 6| Step: 4
Training loss: 1.476065993309021
Validation loss: 2.342316528161367

Epoch: 6| Step: 5
Training loss: 1.3618528842926025
Validation loss: 2.363220671812693

Epoch: 6| Step: 6
Training loss: 2.3610177040100098
Validation loss: 2.3864465157190957

Epoch: 6| Step: 7
Training loss: 1.6633706092834473
Validation loss: 2.404097318649292

Epoch: 6| Step: 8
Training loss: 1.260125756263733
Validation loss: 2.398607770601908

Epoch: 6| Step: 9
Training loss: 0.7357056140899658
Validation loss: 2.3407191236813865

Epoch: 6| Step: 10
Training loss: 1.8893415927886963
Validation loss: 2.3597620328267417

Epoch: 6| Step: 11
Training loss: 1.277747631072998
Validation loss: 2.3723851442337036

Epoch: 6| Step: 12
Training loss: 1.1311066150665283
Validation loss: 2.381493886311849

Epoch: 6| Step: 13
Training loss: 1.2132655382156372
Validation loss: 2.3754180669784546

Epoch: 389| Step: 0
Training loss: 1.5021936893463135
Validation loss: 2.3237321774164834

Epoch: 6| Step: 1
Training loss: 0.7891479730606079
Validation loss: 2.310025374094645

Epoch: 6| Step: 2
Training loss: 1.3420631885528564
Validation loss: 2.3574225107828775

Epoch: 6| Step: 3
Training loss: 1.4579466581344604
Validation loss: 2.3563902775446572

Epoch: 6| Step: 4
Training loss: 1.1511452198028564
Validation loss: 2.3089064359664917

Epoch: 6| Step: 5
Training loss: 0.7418831586837769
Validation loss: 2.3188737630844116

Epoch: 6| Step: 6
Training loss: 2.049677848815918
Validation loss: 2.3415154019991555

Epoch: 6| Step: 7
Training loss: 1.2274515628814697
Validation loss: 2.347024222215017

Epoch: 6| Step: 8
Training loss: 1.258579969406128
Validation loss: 2.3170239528020224

Epoch: 6| Step: 9
Training loss: 1.4018373489379883
Validation loss: 2.3548053900400796

Epoch: 6| Step: 10
Training loss: 1.2004761695861816
Validation loss: 2.3280868530273438

Epoch: 6| Step: 11
Training loss: 1.4391757249832153
Validation loss: 2.3915063738822937

Epoch: 6| Step: 12
Training loss: 2.205732822418213
Validation loss: 2.404589374860128

Epoch: 6| Step: 13
Training loss: 1.7249479293823242
Validation loss: 2.385515650113424

Epoch: 390| Step: 0
Training loss: 1.0125725269317627
Validation loss: 2.390199601650238

Epoch: 6| Step: 1
Training loss: 1.4017212390899658
Validation loss: 2.4189536571502686

Epoch: 6| Step: 2
Training loss: 1.1475098133087158
Validation loss: 2.403076489766439

Epoch: 6| Step: 3
Training loss: 1.511705994606018
Validation loss: 2.4374958078066506

Epoch: 6| Step: 4
Training loss: 1.367281436920166
Validation loss: 2.4369663993517556

Epoch: 6| Step: 5
Training loss: 1.376044750213623
Validation loss: 2.386782646179199

Epoch: 6| Step: 6
Training loss: 1.316306710243225
Validation loss: 2.3693964083989463

Epoch: 6| Step: 7
Training loss: 2.178852081298828
Validation loss: 2.39377361536026

Epoch: 6| Step: 8
Training loss: 1.7435122728347778
Validation loss: 2.405731121699015

Epoch: 6| Step: 9
Training loss: 1.7192583084106445
Validation loss: 2.329885264237722

Epoch: 6| Step: 10
Training loss: 1.1865743398666382
Validation loss: 2.3471009929974875

Epoch: 6| Step: 11
Training loss: 1.7478060722351074
Validation loss: 2.348104198773702

Epoch: 6| Step: 12
Training loss: 1.708418846130371
Validation loss: 2.2916066646575928

Epoch: 6| Step: 13
Training loss: 0.8960520029067993
Validation loss: 2.3299348950386047

Epoch: 391| Step: 0
Training loss: 1.9640716314315796
Validation loss: 2.301040987173716

Epoch: 6| Step: 1
Training loss: 0.887946367263794
Validation loss: 2.3170502185821533

Epoch: 6| Step: 2
Training loss: 1.0891362428665161
Validation loss: 2.3039607206980386

Epoch: 6| Step: 3
Training loss: 1.284938097000122
Validation loss: 2.339130083719889

Epoch: 6| Step: 4
Training loss: 1.8622230291366577
Validation loss: 2.3066508769989014

Epoch: 6| Step: 5
Training loss: 1.7143354415893555
Validation loss: 2.3147629698117576

Epoch: 6| Step: 6
Training loss: 1.7926957607269287
Validation loss: 2.319207946459452

Epoch: 6| Step: 7
Training loss: 1.235660433769226
Validation loss: 2.328821142514547

Epoch: 6| Step: 8
Training loss: 1.6144676208496094
Validation loss: 2.2671099305152893

Epoch: 6| Step: 9
Training loss: 1.5313711166381836
Validation loss: 2.293595095475515

Epoch: 6| Step: 10
Training loss: 0.9949427843093872
Validation loss: 2.2833944956461587

Epoch: 6| Step: 11
Training loss: 1.4517453908920288
Validation loss: 2.2732505202293396

Epoch: 6| Step: 12
Training loss: 1.263627052307129
Validation loss: 2.3008095026016235

Epoch: 6| Step: 13
Training loss: 0.5713781118392944
Validation loss: 2.2795310815175376

Epoch: 392| Step: 0
Training loss: 1.5152931213378906
Validation loss: 2.2600032488505044

Epoch: 6| Step: 1
Training loss: 1.1227630376815796
Validation loss: 2.2854395707448325

Epoch: 6| Step: 2
Training loss: 1.6700111627578735
Validation loss: 2.254341264565786

Epoch: 6| Step: 3
Training loss: 2.015798807144165
Validation loss: 2.2790467937787375

Epoch: 6| Step: 4
Training loss: 1.2330217361450195
Validation loss: 2.290019412835439

Epoch: 6| Step: 5
Training loss: 0.8147542476654053
Validation loss: 2.3047083814938865

Epoch: 6| Step: 6
Training loss: 0.6484501361846924
Validation loss: 2.3135550816853843

Epoch: 6| Step: 7
Training loss: 1.476896047592163
Validation loss: 2.340982357660929

Epoch: 6| Step: 8
Training loss: 1.5312604904174805
Validation loss: 2.312363088130951

Epoch: 6| Step: 9
Training loss: 1.7555198669433594
Validation loss: 2.2862292528152466

Epoch: 6| Step: 10
Training loss: 1.9402084350585938
Validation loss: 2.2911019921302795

Epoch: 6| Step: 11
Training loss: 1.9378612041473389
Validation loss: 2.327950636545817

Epoch: 6| Step: 12
Training loss: 1.7141163349151611
Validation loss: 2.3547858794530234

Epoch: 6| Step: 13
Training loss: 1.5223462581634521
Validation loss: 2.319683094819387

Epoch: 393| Step: 0
Training loss: 0.9875128269195557
Validation loss: 2.325203994909922

Epoch: 6| Step: 1
Training loss: 1.7384724617004395
Validation loss: 2.284220576286316

Epoch: 6| Step: 2
Training loss: 1.5611088275909424
Validation loss: 2.302680253982544

Epoch: 6| Step: 3
Training loss: 1.3016023635864258
Validation loss: 2.3053065737088523

Epoch: 6| Step: 4
Training loss: 1.3855921030044556
Validation loss: 2.356707493464152

Epoch: 6| Step: 5
Training loss: 1.347700834274292
Validation loss: 2.3104120095570884

Epoch: 6| Step: 6
Training loss: 0.8128342628479004
Validation loss: 2.3007657130559287

Epoch: 6| Step: 7
Training loss: 1.27895188331604
Validation loss: 2.333164095878601

Epoch: 6| Step: 8
Training loss: 1.7195769548416138
Validation loss: 2.35917866230011

Epoch: 6| Step: 9
Training loss: 1.3235127925872803
Validation loss: 2.339599370956421

Epoch: 6| Step: 10
Training loss: 1.1370857954025269
Validation loss: 2.3509939511617026

Epoch: 6| Step: 11
Training loss: 1.845643401145935
Validation loss: 2.318302869796753

Epoch: 6| Step: 12
Training loss: 1.4815843105316162
Validation loss: 2.2938848733901978

Epoch: 6| Step: 13
Training loss: 1.0891748666763306
Validation loss: 2.2835630973180137

Epoch: 394| Step: 0
Training loss: 1.3056498765945435
Validation loss: 2.304899255434672

Epoch: 6| Step: 1
Training loss: 1.4931260347366333
Validation loss: 2.3091251452763877

Epoch: 6| Step: 2
Training loss: 2.248572826385498
Validation loss: 2.3208528757095337

Epoch: 6| Step: 3
Training loss: 1.0720582008361816
Validation loss: 2.3614336053530374

Epoch: 6| Step: 4
Training loss: 1.6891026496887207
Validation loss: 2.3413830995559692

Epoch: 6| Step: 5
Training loss: 1.8998857736587524
Validation loss: 2.369653860727946

Epoch: 6| Step: 6
Training loss: 0.8799623250961304
Validation loss: 2.3400611877441406

Epoch: 6| Step: 7
Training loss: 1.319469928741455
Validation loss: 2.3556822339693704

Epoch: 6| Step: 8
Training loss: 1.0677350759506226
Validation loss: 2.337180256843567

Epoch: 6| Step: 9
Training loss: 0.9325268864631653
Validation loss: 2.340451796849569

Epoch: 6| Step: 10
Training loss: 1.1477205753326416
Validation loss: 2.329709827899933

Epoch: 6| Step: 11
Training loss: 1.8072724342346191
Validation loss: 2.352029244105021

Epoch: 6| Step: 12
Training loss: 0.9294147491455078
Validation loss: 2.2899165550867715

Epoch: 6| Step: 13
Training loss: 1.093519926071167
Validation loss: 2.3159377773602805

Epoch: 395| Step: 0
Training loss: 0.7373155355453491
Validation loss: 2.298500935236613

Epoch: 6| Step: 1
Training loss: 1.2594815492630005
Validation loss: 2.330243627230326

Epoch: 6| Step: 2
Training loss: 1.018369197845459
Validation loss: 2.2457738320032754

Epoch: 6| Step: 3
Training loss: 0.9330216646194458
Validation loss: 2.1951425472895303

Epoch: 6| Step: 4
Training loss: 1.7748022079467773
Validation loss: 2.184318423271179

Epoch: 6| Step: 5
Training loss: 1.363144040107727
Validation loss: 2.245394229888916

Epoch: 6| Step: 6
Training loss: 1.6035516262054443
Validation loss: 2.231537103652954

Epoch: 6| Step: 7
Training loss: 1.1588488817214966
Validation loss: 2.2303317983945212

Epoch: 6| Step: 8
Training loss: 1.152872085571289
Validation loss: 2.235888918240865

Epoch: 6| Step: 9
Training loss: 1.610016107559204
Validation loss: 2.26218851407369

Epoch: 6| Step: 10
Training loss: 2.1543431282043457
Validation loss: 2.264966070652008

Epoch: 6| Step: 11
Training loss: 1.9704022407531738
Validation loss: 2.2879260579744973

Epoch: 6| Step: 12
Training loss: 1.480943202972412
Validation loss: 2.2600915829340615

Epoch: 6| Step: 13
Training loss: 1.3690519332885742
Validation loss: 2.301811933517456

Epoch: 396| Step: 0
Training loss: 1.4999504089355469
Validation loss: 2.2910159826278687

Epoch: 6| Step: 1
Training loss: 2.0547447204589844
Validation loss: 2.2665244340896606

Epoch: 6| Step: 2
Training loss: 1.5416730642318726
Validation loss: 2.2769652207692466

Epoch: 6| Step: 3
Training loss: 1.3225003480911255
Validation loss: 2.3030954400698342

Epoch: 6| Step: 4
Training loss: 1.1582181453704834
Validation loss: 2.289501448472341

Epoch: 6| Step: 5
Training loss: 1.2113593816757202
Validation loss: 2.3210085233052573

Epoch: 6| Step: 6
Training loss: 2.290743827819824
Validation loss: 2.2967014710108438

Epoch: 6| Step: 7
Training loss: 1.2541155815124512
Validation loss: 2.29385773340861

Epoch: 6| Step: 8
Training loss: 0.9411619901657104
Validation loss: 2.305926521619161

Epoch: 6| Step: 9
Training loss: 1.7166672945022583
Validation loss: 2.306688825289408

Epoch: 6| Step: 10
Training loss: 1.170447587966919
Validation loss: 2.244175136089325

Epoch: 6| Step: 11
Training loss: 1.029120683670044
Validation loss: 2.274632692337036

Epoch: 6| Step: 12
Training loss: 1.5809755325317383
Validation loss: 2.2364434003829956

Epoch: 6| Step: 13
Training loss: 0.6180002689361572
Validation loss: 2.244944453239441

Epoch: 397| Step: 0
Training loss: 1.1925855875015259
Validation loss: 2.2834182381629944

Epoch: 6| Step: 1
Training loss: 2.002291202545166
Validation loss: 2.2594269712766013

Epoch: 6| Step: 2
Training loss: 1.7553672790527344
Validation loss: 2.231052796045939

Epoch: 6| Step: 3
Training loss: 1.0137355327606201
Validation loss: 2.225904186566671

Epoch: 6| Step: 4
Training loss: 1.3093554973602295
Validation loss: 2.293368657430013

Epoch: 6| Step: 5
Training loss: 0.7494858503341675
Validation loss: 2.2476296623547873

Epoch: 6| Step: 6
Training loss: 1.5272881984710693
Validation loss: 2.282391389211019

Epoch: 6| Step: 7
Training loss: 1.2508363723754883
Validation loss: 2.3042526841163635

Epoch: 6| Step: 8
Training loss: 1.0281060934066772
Validation loss: 2.327590902646383

Epoch: 6| Step: 9
Training loss: 1.5314416885375977
Validation loss: 2.3686405420303345

Epoch: 6| Step: 10
Training loss: 2.0140037536621094
Validation loss: 2.363680283228556

Epoch: 6| Step: 11
Training loss: 0.7071346044540405
Validation loss: 2.355326294898987

Epoch: 6| Step: 12
Training loss: 1.943382740020752
Validation loss: 2.375312844912211

Epoch: 6| Step: 13
Training loss: 1.0839636325836182
Validation loss: 2.3217739860216775

Epoch: 398| Step: 0
Training loss: 1.1877543926239014
Validation loss: 2.3548359473546348

Epoch: 6| Step: 1
Training loss: 0.5907279253005981
Validation loss: 2.3237725098927817

Epoch: 6| Step: 2
Training loss: 0.7295700907707214
Validation loss: 2.270066738128662

Epoch: 6| Step: 3
Training loss: 1.0908329486846924
Validation loss: 2.256001273790995

Epoch: 6| Step: 4
Training loss: 1.2391966581344604
Validation loss: 2.247788389523824

Epoch: 6| Step: 5
Training loss: 1.1718406677246094
Validation loss: 2.2978662252426147

Epoch: 6| Step: 6
Training loss: 1.3935061693191528
Validation loss: 2.2956936359405518

Epoch: 6| Step: 7
Training loss: 1.9976286888122559
Validation loss: 2.306211749712626

Epoch: 6| Step: 8
Training loss: 1.8767433166503906
Validation loss: 2.2847795486450195

Epoch: 6| Step: 9
Training loss: 2.342495918273926
Validation loss: 2.2600438594818115

Epoch: 6| Step: 10
Training loss: 1.1721736192703247
Validation loss: 2.2732388575871787

Epoch: 6| Step: 11
Training loss: 1.0586023330688477
Validation loss: 2.283730924129486

Epoch: 6| Step: 12
Training loss: 2.063591480255127
Validation loss: 2.2547686100006104

Epoch: 6| Step: 13
Training loss: 0.9970410466194153
Validation loss: 2.322009245554606

Epoch: 399| Step: 0
Training loss: 2.1703946590423584
Validation loss: 2.321671704451243

Epoch: 6| Step: 1
Training loss: 1.0623441934585571
Validation loss: 2.3264012336730957

Epoch: 6| Step: 2
Training loss: 1.5884768962860107
Validation loss: 2.285857935746511

Epoch: 6| Step: 3
Training loss: 1.641705870628357
Validation loss: 2.2063531478246055

Epoch: 6| Step: 4
Training loss: 1.1610169410705566
Validation loss: 2.2633580565452576

Epoch: 6| Step: 5
Training loss: 1.386566162109375
Validation loss: 2.245128651460012

Epoch: 6| Step: 6
Training loss: 1.4290655851364136
Validation loss: 2.280676623185476

Epoch: 6| Step: 7
Training loss: 1.493318796157837
Validation loss: 2.259826103846232

Epoch: 6| Step: 8
Training loss: 0.6791192889213562
Validation loss: 2.236061672369639

Epoch: 6| Step: 9
Training loss: 0.835180938243866
Validation loss: 2.2123021880785623

Epoch: 6| Step: 10
Training loss: 2.092583656311035
Validation loss: 2.222039759159088

Epoch: 6| Step: 11
Training loss: 1.3871945142745972
Validation loss: 2.231830358505249

Epoch: 6| Step: 12
Training loss: 1.128226399421692
Validation loss: 2.235327204068502

Epoch: 6| Step: 13
Training loss: 1.4545786380767822
Validation loss: 2.2190370758374534

Epoch: 400| Step: 0
Training loss: 1.7142832279205322
Validation loss: 2.2527408798535666

Epoch: 6| Step: 1
Training loss: 1.1430878639221191
Validation loss: 2.31626965602239

Epoch: 6| Step: 2
Training loss: 0.9010298848152161
Validation loss: 2.305943230787913

Epoch: 6| Step: 3
Training loss: 1.360796332359314
Validation loss: 2.2974570194880166

Epoch: 6| Step: 4
Training loss: 1.645265817642212
Validation loss: 2.3133633931477866

Epoch: 6| Step: 5
Training loss: 0.6270928382873535
Validation loss: 2.320350686709086

Epoch: 6| Step: 6
Training loss: 0.9685138463973999
Validation loss: 2.250775476296743

Epoch: 6| Step: 7
Training loss: 1.985853910446167
Validation loss: 2.260683298110962

Epoch: 6| Step: 8
Training loss: 1.045557975769043
Validation loss: 2.291688402493795

Epoch: 6| Step: 9
Training loss: 1.5349810123443604
Validation loss: 2.27325830856959

Epoch: 6| Step: 10
Training loss: 0.8851410150527954
Validation loss: 2.265923857688904

Epoch: 6| Step: 11
Training loss: 1.6133852005004883
Validation loss: 2.2422901590665183

Epoch: 6| Step: 12
Training loss: 2.1057677268981934
Validation loss: 2.2651144663492837

Epoch: 6| Step: 13
Training loss: 1.6964585781097412
Validation loss: 2.2764315009117126

Epoch: 401| Step: 0
Training loss: 1.116599678993225
Validation loss: 2.2619137366612754

Epoch: 6| Step: 1
Training loss: 1.411182165145874
Validation loss: 2.3179702957471213

Epoch: 6| Step: 2
Training loss: 1.331758975982666
Validation loss: 2.305473566055298

Epoch: 6| Step: 3
Training loss: 0.666833758354187
Validation loss: 2.3369096716245017

Epoch: 6| Step: 4
Training loss: 0.7320621013641357
Validation loss: 2.3554922342300415

Epoch: 6| Step: 5
Training loss: 1.05424165725708
Validation loss: 2.3632853627204895

Epoch: 6| Step: 6
Training loss: 1.9171793460845947
Validation loss: 2.377386748790741

Epoch: 6| Step: 7
Training loss: 2.0722339153289795
Validation loss: 2.415020704269409

Epoch: 6| Step: 8
Training loss: 1.706842064857483
Validation loss: 2.419243892033895

Epoch: 6| Step: 9
Training loss: 1.310439109802246
Validation loss: 2.420516093571981

Epoch: 6| Step: 10
Training loss: 0.9524372816085815
Validation loss: 2.4004509846369424

Epoch: 6| Step: 11
Training loss: 1.7730499505996704
Validation loss: 2.4000113805135093

Epoch: 6| Step: 12
Training loss: 1.6114468574523926
Validation loss: 2.3840434551239014

Epoch: 6| Step: 13
Training loss: 1.206316590309143
Validation loss: 2.368876318136851

Epoch: 402| Step: 0
Training loss: 1.7171151638031006
Validation loss: 2.3199104269345603

Epoch: 6| Step: 1
Training loss: 1.294020175933838
Validation loss: 2.306480805079142

Epoch: 6| Step: 2
Training loss: 0.9790972471237183
Validation loss: 2.3135021527608237

Epoch: 6| Step: 3
Training loss: 1.782482624053955
Validation loss: 2.2733150521914163

Epoch: 6| Step: 4
Training loss: 1.567429542541504
Validation loss: 2.289866785208384

Epoch: 6| Step: 5
Training loss: 1.8992364406585693
Validation loss: 2.2424422105153403

Epoch: 6| Step: 6
Training loss: 2.1097326278686523
Validation loss: 2.3048161268234253

Epoch: 6| Step: 7
Training loss: 1.2958396673202515
Validation loss: 2.29392143090566

Epoch: 6| Step: 8
Training loss: 0.9115782976150513
Validation loss: 2.251868486404419

Epoch: 6| Step: 9
Training loss: 0.78289794921875
Validation loss: 2.273783723513285

Epoch: 6| Step: 10
Training loss: 1.111424446105957
Validation loss: 2.256916562716166

Epoch: 6| Step: 11
Training loss: 1.627504825592041
Validation loss: 2.244916339715322

Epoch: 6| Step: 12
Training loss: 1.1943159103393555
Validation loss: 2.3329432805379233

Epoch: 6| Step: 13
Training loss: 0.7501449584960938
Validation loss: 2.2909922997156777

Epoch: 403| Step: 0
Training loss: 1.7132766246795654
Validation loss: 2.3642512957255044

Epoch: 6| Step: 1
Training loss: 1.190337061882019
Validation loss: 2.3070048491160073

Epoch: 6| Step: 2
Training loss: 0.8487555384635925
Validation loss: 2.3567647536595664

Epoch: 6| Step: 3
Training loss: 1.2242649793624878
Validation loss: 2.308200458685557

Epoch: 6| Step: 4
Training loss: 1.1851822137832642
Validation loss: 2.3366987307866416

Epoch: 6| Step: 5
Training loss: 1.3967797756195068
Validation loss: 2.2989348570505777

Epoch: 6| Step: 6
Training loss: 1.192566156387329
Validation loss: 2.2893166542053223

Epoch: 6| Step: 7
Training loss: 2.14632511138916
Validation loss: 2.293427844842275

Epoch: 6| Step: 8
Training loss: 1.452055811882019
Validation loss: 2.2712727189064026

Epoch: 6| Step: 9
Training loss: 1.4856781959533691
Validation loss: 2.2834333578745523

Epoch: 6| Step: 10
Training loss: 1.231369972229004
Validation loss: 2.288711210091909

Epoch: 6| Step: 11
Training loss: 1.288198471069336
Validation loss: 2.3180693785349527

Epoch: 6| Step: 12
Training loss: 1.0285180807113647
Validation loss: 2.2535800337791443

Epoch: 6| Step: 13
Training loss: 1.3818258047103882
Validation loss: 2.287889917691549

Epoch: 404| Step: 0
Training loss: 1.0860482454299927
Validation loss: 2.2782808542251587

Epoch: 6| Step: 1
Training loss: 1.33047616481781
Validation loss: 2.3055388927459717

Epoch: 6| Step: 2
Training loss: 1.2915308475494385
Validation loss: 2.2703241308530173

Epoch: 6| Step: 3
Training loss: 1.145210862159729
Validation loss: 2.3046677708625793

Epoch: 6| Step: 4
Training loss: 1.456256628036499
Validation loss: 2.309956192970276

Epoch: 6| Step: 5
Training loss: 1.0354995727539062
Validation loss: 2.298649628957113

Epoch: 6| Step: 6
Training loss: 1.4288990497589111
Validation loss: 2.276099423567454

Epoch: 6| Step: 7
Training loss: 1.0094656944274902
Validation loss: 2.284920652707418

Epoch: 6| Step: 8
Training loss: 1.791958212852478
Validation loss: 2.2805325786272683

Epoch: 6| Step: 9
Training loss: 1.43303644657135
Validation loss: 2.3035102486610413

Epoch: 6| Step: 10
Training loss: 1.122532844543457
Validation loss: 2.302674174308777

Epoch: 6| Step: 11
Training loss: 2.124177932739258
Validation loss: 2.3304741581281028

Epoch: 6| Step: 12
Training loss: 0.8504287004470825
Validation loss: 2.3380505442619324

Epoch: 6| Step: 13
Training loss: 1.3213298320770264
Validation loss: 2.275456746419271

Epoch: 405| Step: 0
Training loss: 0.7440316677093506
Validation loss: 2.3418521682421365

Epoch: 6| Step: 1
Training loss: 0.7920463681221008
Validation loss: 2.3522146344184875

Epoch: 6| Step: 2
Training loss: 1.667074203491211
Validation loss: 2.3370405038197837

Epoch: 6| Step: 3
Training loss: 0.7278493642807007
Validation loss: 2.364967624346415

Epoch: 6| Step: 4
Training loss: 1.4754257202148438
Validation loss: 2.347048004468282

Epoch: 6| Step: 5
Training loss: 1.7823907136917114
Validation loss: 2.3331222931543985

Epoch: 6| Step: 6
Training loss: 1.002079725265503
Validation loss: 2.3484007517496743

Epoch: 6| Step: 7
Training loss: 1.383908748626709
Validation loss: 2.3958152731259665

Epoch: 6| Step: 8
Training loss: 1.5010335445404053
Validation loss: 2.3606362342834473

Epoch: 6| Step: 9
Training loss: 0.6608186960220337
Validation loss: 2.3641975124677024

Epoch: 6| Step: 10
Training loss: 1.8833476305007935
Validation loss: 2.3177963892618814

Epoch: 6| Step: 11
Training loss: 2.181629180908203
Validation loss: 2.373721798261007

Epoch: 6| Step: 12
Training loss: 1.8016774654388428
Validation loss: 2.3067514499028525

Epoch: 6| Step: 13
Training loss: 0.9500609636306763
Validation loss: 2.3438915014266968

Epoch: 406| Step: 0
Training loss: 1.6293307542800903
Validation loss: 2.3096112410227456

Epoch: 6| Step: 1
Training loss: 1.7769498825073242
Validation loss: 2.3240737915039062

Epoch: 6| Step: 2
Training loss: 2.109586000442505
Validation loss: 2.298699935277303

Epoch: 6| Step: 3
Training loss: 1.257380723953247
Validation loss: 2.385255495707194

Epoch: 6| Step: 4
Training loss: 0.7904839515686035
Validation loss: 2.30974805355072

Epoch: 6| Step: 5
Training loss: 1.1118847131729126
Validation loss: 2.2868332068125405

Epoch: 6| Step: 6
Training loss: 1.0893369913101196
Validation loss: 2.371415356794993

Epoch: 6| Step: 7
Training loss: 0.9006032943725586
Validation loss: 2.2879599730173745

Epoch: 6| Step: 8
Training loss: 1.297353744506836
Validation loss: 2.3178372184435525

Epoch: 6| Step: 9
Training loss: 1.2150993347167969
Validation loss: 2.256118575731913

Epoch: 6| Step: 10
Training loss: 1.0697827339172363
Validation loss: 2.286244591077169

Epoch: 6| Step: 11
Training loss: 1.5419185161590576
Validation loss: 2.2591712474823

Epoch: 6| Step: 12
Training loss: 2.102196216583252
Validation loss: 2.284288783868154

Epoch: 6| Step: 13
Training loss: 1.3043735027313232
Validation loss: 2.2984645764033

Epoch: 407| Step: 0
Training loss: 1.862504005432129
Validation loss: 2.2656855384508767

Epoch: 6| Step: 1
Training loss: 0.6992781162261963
Validation loss: 2.256828268369039

Epoch: 6| Step: 2
Training loss: 1.5335373878479004
Validation loss: 2.2815182407697043

Epoch: 6| Step: 3
Training loss: 0.6092061996459961
Validation loss: 2.274196743965149

Epoch: 6| Step: 4
Training loss: 1.8458471298217773
Validation loss: 2.248563845952352

Epoch: 6| Step: 5
Training loss: 1.4900012016296387
Validation loss: 2.275576174259186

Epoch: 6| Step: 6
Training loss: 1.3790857791900635
Validation loss: 2.307325541973114

Epoch: 6| Step: 7
Training loss: 1.1601173877716064
Validation loss: 2.2549654841423035

Epoch: 6| Step: 8
Training loss: 0.7026869058609009
Validation loss: 2.280293067296346

Epoch: 6| Step: 9
Training loss: 1.323129653930664
Validation loss: 2.2932705879211426

Epoch: 6| Step: 10
Training loss: 1.1537096500396729
Validation loss: 2.3242592414220176

Epoch: 6| Step: 11
Training loss: 1.4451810121536255
Validation loss: 2.3696622451146445

Epoch: 6| Step: 12
Training loss: 1.3529853820800781
Validation loss: 2.3235949675242105

Epoch: 6| Step: 13
Training loss: 1.2440835237503052
Validation loss: 2.3269416093826294

Epoch: 408| Step: 0
Training loss: 1.6341898441314697
Validation loss: 2.3321295181910195

Epoch: 6| Step: 1
Training loss: 1.616356611251831
Validation loss: 2.37976602713267

Epoch: 6| Step: 2
Training loss: 1.1298381090164185
Validation loss: 2.3698591788609824

Epoch: 6| Step: 3
Training loss: 0.7408324480056763
Validation loss: 2.3840542236963906

Epoch: 6| Step: 4
Training loss: 1.3602524995803833
Validation loss: 2.287801742553711

Epoch: 6| Step: 5
Training loss: 0.9686960577964783
Validation loss: 2.301385502020518

Epoch: 6| Step: 6
Training loss: 0.7134188413619995
Validation loss: 2.3226280212402344

Epoch: 6| Step: 7
Training loss: 1.508634090423584
Validation loss: 2.2933155298233032

Epoch: 6| Step: 8
Training loss: 1.414331316947937
Validation loss: 2.3226937850316367

Epoch: 6| Step: 9
Training loss: 2.1865410804748535
Validation loss: 2.333022872606913

Epoch: 6| Step: 10
Training loss: 1.4744867086410522
Validation loss: 2.3438937266667685

Epoch: 6| Step: 11
Training loss: 1.1102644205093384
Validation loss: 2.3841613133748374

Epoch: 6| Step: 12
Training loss: 0.7749251127243042
Validation loss: 2.3124125003814697

Epoch: 6| Step: 13
Training loss: 1.8006809949874878
Validation loss: 2.3326353828112283

Epoch: 409| Step: 0
Training loss: 1.541449785232544
Validation loss: 2.3643182118733725

Epoch: 6| Step: 1
Training loss: 1.0321907997131348
Validation loss: 2.3331287105878196

Epoch: 6| Step: 2
Training loss: 1.069540023803711
Validation loss: 2.326932966709137

Epoch: 6| Step: 3
Training loss: 1.491079330444336
Validation loss: 2.37510617574056

Epoch: 6| Step: 4
Training loss: 1.4983131885528564
Validation loss: 2.350583831469218

Epoch: 6| Step: 5
Training loss: 1.6862249374389648
Validation loss: 2.3183218240737915

Epoch: 6| Step: 6
Training loss: 1.850000262260437
Validation loss: 2.2938287258148193

Epoch: 6| Step: 7
Training loss: 0.8080867528915405
Validation loss: 2.2753845850626626

Epoch: 6| Step: 8
Training loss: 1.349302887916565
Validation loss: 2.309902866681417

Epoch: 6| Step: 9
Training loss: 1.1121693849563599
Validation loss: 2.2973122596740723

Epoch: 6| Step: 10
Training loss: 0.637748122215271
Validation loss: 2.2865238984425864

Epoch: 6| Step: 11
Training loss: 1.513415813446045
Validation loss: 2.2784557938575745

Epoch: 6| Step: 12
Training loss: 1.2690107822418213
Validation loss: 2.231599748134613

Epoch: 6| Step: 13
Training loss: 0.9116216897964478
Validation loss: 2.2811683813730874

Epoch: 410| Step: 0
Training loss: 1.0306422710418701
Validation loss: 2.2331736087799072

Epoch: 6| Step: 1
Training loss: 1.3782000541687012
Validation loss: 2.2765959103902182

Epoch: 6| Step: 2
Training loss: 0.891643762588501
Validation loss: 2.315407713254293

Epoch: 6| Step: 3
Training loss: 1.9700431823730469
Validation loss: 2.2684579888979592

Epoch: 6| Step: 4
Training loss: 1.0895646810531616
Validation loss: 2.281491498152415

Epoch: 6| Step: 5
Training loss: 1.1447539329528809
Validation loss: 2.3049111366271973

Epoch: 6| Step: 6
Training loss: 2.111912488937378
Validation loss: 2.3004113833109536

Epoch: 6| Step: 7
Training loss: 1.0979831218719482
Validation loss: 2.323970675468445

Epoch: 6| Step: 8
Training loss: 0.9605022668838501
Validation loss: 2.36156298716863

Epoch: 6| Step: 9
Training loss: 0.8992646336555481
Validation loss: 2.2926961183547974

Epoch: 6| Step: 10
Training loss: 0.9321566820144653
Validation loss: 2.3133579889933267

Epoch: 6| Step: 11
Training loss: 1.4189956188201904
Validation loss: 2.3223512768745422

Epoch: 6| Step: 12
Training loss: 1.593487024307251
Validation loss: 2.3161983688672385

Epoch: 6| Step: 13
Training loss: 1.142533540725708
Validation loss: 2.327261288960775

Epoch: 411| Step: 0
Training loss: 1.2314971685409546
Validation loss: 2.335165103276571

Epoch: 6| Step: 1
Training loss: 1.3373489379882812
Validation loss: 2.333033800125122

Epoch: 6| Step: 2
Training loss: 1.1748883724212646
Validation loss: 2.35601278146108

Epoch: 6| Step: 3
Training loss: 1.289229154586792
Validation loss: 2.3693058689435325

Epoch: 6| Step: 4
Training loss: 1.8419581651687622
Validation loss: 2.341585357983907

Epoch: 6| Step: 5
Training loss: 1.0825847387313843
Validation loss: 2.3734124898910522

Epoch: 6| Step: 6
Training loss: 1.7869608402252197
Validation loss: 2.383593281110128

Epoch: 6| Step: 7
Training loss: 0.5743675231933594
Validation loss: 2.363807717959086

Epoch: 6| Step: 8
Training loss: 1.0949656963348389
Validation loss: 2.3714922666549683

Epoch: 6| Step: 9
Training loss: 0.8642656803131104
Validation loss: 2.433441996574402

Epoch: 6| Step: 10
Training loss: 1.7317161560058594
Validation loss: 2.413811286290487

Epoch: 6| Step: 11
Training loss: 1.0230673551559448
Validation loss: 2.413812220096588

Epoch: 6| Step: 12
Training loss: 1.565429925918579
Validation loss: 2.3726688226064048

Epoch: 6| Step: 13
Training loss: 1.188064694404602
Validation loss: 2.362192392349243

Epoch: 412| Step: 0
Training loss: 0.7938675880432129
Validation loss: 2.3749173482259116

Epoch: 6| Step: 1
Training loss: 0.6239067316055298
Validation loss: 2.2998905777931213

Epoch: 6| Step: 2
Training loss: 1.4766381978988647
Validation loss: 2.3436045249303183

Epoch: 6| Step: 3
Training loss: 0.8471987843513489
Validation loss: 2.304586867491404

Epoch: 6| Step: 4
Training loss: 1.8572883605957031
Validation loss: 2.2938676277796426

Epoch: 6| Step: 5
Training loss: 1.7188386917114258
Validation loss: 2.3204306165377298

Epoch: 6| Step: 6
Training loss: 1.4045283794403076
Validation loss: 2.2649865547815957

Epoch: 6| Step: 7
Training loss: 1.2220327854156494
Validation loss: 2.2744192679723105

Epoch: 6| Step: 8
Training loss: 1.7745988368988037
Validation loss: 2.3146563172340393

Epoch: 6| Step: 9
Training loss: 1.4298526048660278
Validation loss: 2.3271323243776956

Epoch: 6| Step: 10
Training loss: 1.7835698127746582
Validation loss: 2.3163411219914756

Epoch: 6| Step: 11
Training loss: 1.0689460039138794
Validation loss: 2.3603827357292175

Epoch: 6| Step: 12
Training loss: 1.0879287719726562
Validation loss: 2.328783710797628

Epoch: 6| Step: 13
Training loss: 1.0417909622192383
Validation loss: 2.3789658149083457

Epoch: 413| Step: 0
Training loss: 0.4729255437850952
Validation loss: 2.3139649629592896

Epoch: 6| Step: 1
Training loss: 1.3254659175872803
Validation loss: 2.2988462448120117

Epoch: 6| Step: 2
Training loss: 1.6758402585983276
Validation loss: 2.290534416834513

Epoch: 6| Step: 3
Training loss: 0.813453197479248
Validation loss: 2.2964172760645547

Epoch: 6| Step: 4
Training loss: 0.6540651321411133
Validation loss: 2.310197949409485

Epoch: 6| Step: 5
Training loss: 1.471998691558838
Validation loss: 2.282212018966675

Epoch: 6| Step: 6
Training loss: 2.3852853775024414
Validation loss: 2.3376198212305703

Epoch: 6| Step: 7
Training loss: 1.162041425704956
Validation loss: 2.2654406229654946

Epoch: 6| Step: 8
Training loss: 1.4444074630737305
Validation loss: 2.2489407062530518

Epoch: 6| Step: 9
Training loss: 1.5068576335906982
Validation loss: 2.268135448296865

Epoch: 6| Step: 10
Training loss: 1.7510251998901367
Validation loss: 2.2951489686965942

Epoch: 6| Step: 11
Training loss: 1.110846996307373
Validation loss: 2.2980212966601052

Epoch: 6| Step: 12
Training loss: 1.1220442056655884
Validation loss: 2.316666603088379

Epoch: 6| Step: 13
Training loss: 1.4160583019256592
Validation loss: 2.319989184538523

Epoch: 414| Step: 0
Training loss: 0.9591185450553894
Validation loss: 2.307848592599233

Epoch: 6| Step: 1
Training loss: 1.4518338441848755
Validation loss: 2.367495894432068

Epoch: 6| Step: 2
Training loss: 0.7849203944206238
Validation loss: 2.4145854314168296

Epoch: 6| Step: 3
Training loss: 1.6236382722854614
Validation loss: 2.3786070744196572

Epoch: 6| Step: 4
Training loss: 1.8472990989685059
Validation loss: 2.381361464659373

Epoch: 6| Step: 5
Training loss: 1.3010849952697754
Validation loss: 2.3188604712486267

Epoch: 6| Step: 6
Training loss: 1.2584004402160645
Validation loss: 2.401858707269033

Epoch: 6| Step: 7
Training loss: 1.161163568496704
Validation loss: 2.334329386552175

Epoch: 6| Step: 8
Training loss: 1.2322280406951904
Validation loss: 2.330915073553721

Epoch: 6| Step: 9
Training loss: 1.3453189134597778
Validation loss: 2.3152709007263184

Epoch: 6| Step: 10
Training loss: 0.9830214381217957
Validation loss: 2.30139168103536

Epoch: 6| Step: 11
Training loss: 0.8543983101844788
Validation loss: 2.310385207335154

Epoch: 6| Step: 12
Training loss: 1.7466862201690674
Validation loss: 2.3258686463038125

Epoch: 6| Step: 13
Training loss: 1.2821296453475952
Validation loss: 2.333033879597982

Epoch: 415| Step: 0
Training loss: 1.1316415071487427
Validation loss: 2.3225287000338235

Epoch: 6| Step: 1
Training loss: 1.5536235570907593
Validation loss: 2.3137640754381814

Epoch: 6| Step: 2
Training loss: 1.8922505378723145
Validation loss: 2.300706664721171

Epoch: 6| Step: 3
Training loss: 1.152464747428894
Validation loss: 2.3700355291366577

Epoch: 6| Step: 4
Training loss: 0.9572576284408569
Validation loss: 2.3782295187314353

Epoch: 6| Step: 5
Training loss: 1.6421418190002441
Validation loss: 2.286062399546305

Epoch: 6| Step: 6
Training loss: 1.122326374053955
Validation loss: 2.353533168633779

Epoch: 6| Step: 7
Training loss: 1.1231987476348877
Validation loss: 2.3206709225972495

Epoch: 6| Step: 8
Training loss: 1.3838948011398315
Validation loss: 2.30351984500885

Epoch: 6| Step: 9
Training loss: 1.088197946548462
Validation loss: 2.2718870043754578

Epoch: 6| Step: 10
Training loss: 0.9617620706558228
Validation loss: 2.313960393269857

Epoch: 6| Step: 11
Training loss: 1.1871370077133179
Validation loss: 2.3159839312235513

Epoch: 6| Step: 12
Training loss: 1.150583267211914
Validation loss: 2.3300108512242637

Epoch: 6| Step: 13
Training loss: 1.618848204612732
Validation loss: 2.24170583486557

Epoch: 416| Step: 0
Training loss: 1.7703969478607178
Validation loss: 2.3038031260172525

Epoch: 6| Step: 1
Training loss: 1.8933165073394775
Validation loss: 2.2906126181284585

Epoch: 6| Step: 2
Training loss: 1.219161033630371
Validation loss: 2.334771156311035

Epoch: 6| Step: 3
Training loss: 1.082709789276123
Validation loss: 2.3056904872258506

Epoch: 6| Step: 4
Training loss: 1.49903404712677
Validation loss: 2.3365681171417236

Epoch: 6| Step: 5
Training loss: 0.8000411987304688
Validation loss: 2.2859010299046836

Epoch: 6| Step: 6
Training loss: 0.8535415530204773
Validation loss: 2.294831375281016

Epoch: 6| Step: 7
Training loss: 0.9470452666282654
Validation loss: 2.3011351029078164

Epoch: 6| Step: 8
Training loss: 0.7849704027175903
Validation loss: 2.2712045907974243

Epoch: 6| Step: 9
Training loss: 1.9646058082580566
Validation loss: 2.240707298119863

Epoch: 6| Step: 10
Training loss: 1.8420974016189575
Validation loss: 2.2556382417678833

Epoch: 6| Step: 11
Training loss: 1.105494737625122
Validation loss: 2.2575217286745706

Epoch: 6| Step: 12
Training loss: 1.1488714218139648
Validation loss: 2.265437444051107

Epoch: 6| Step: 13
Training loss: 0.7855126857757568
Validation loss: 2.2766029834747314

Epoch: 417| Step: 0
Training loss: 1.2287840843200684
Validation loss: 2.24866114060084

Epoch: 6| Step: 1
Training loss: 0.5493683815002441
Validation loss: 2.2306714057922363

Epoch: 6| Step: 2
Training loss: 2.2558951377868652
Validation loss: 2.267262558142344

Epoch: 6| Step: 3
Training loss: 0.8993367552757263
Validation loss: 2.25113578637441

Epoch: 6| Step: 4
Training loss: 1.055750846862793
Validation loss: 2.247336427370707

Epoch: 6| Step: 5
Training loss: 0.5356853008270264
Validation loss: 2.2724735538164773

Epoch: 6| Step: 6
Training loss: 1.653654932975769
Validation loss: 2.2947306632995605

Epoch: 6| Step: 7
Training loss: 1.5034308433532715
Validation loss: 2.285698572794596

Epoch: 6| Step: 8
Training loss: 1.2430965900421143
Validation loss: 2.246324102083842

Epoch: 6| Step: 9
Training loss: 1.3101301193237305
Validation loss: 2.2956192890803018

Epoch: 6| Step: 10
Training loss: 1.4964532852172852
Validation loss: 2.320807695388794

Epoch: 6| Step: 11
Training loss: 0.7927684783935547
Validation loss: 2.343728542327881

Epoch: 6| Step: 12
Training loss: 1.2669477462768555
Validation loss: 2.305086374282837

Epoch: 6| Step: 13
Training loss: 1.8160638809204102
Validation loss: 2.3179017305374146

Epoch: 418| Step: 0
Training loss: 1.373986005783081
Validation loss: 2.3450190226236978

Epoch: 6| Step: 1
Training loss: 1.3297526836395264
Validation loss: 2.3249482909838357

Epoch: 6| Step: 2
Training loss: 2.165013313293457
Validation loss: 2.329086343447367

Epoch: 6| Step: 3
Training loss: 1.3645524978637695
Validation loss: 2.322779337565104

Epoch: 6| Step: 4
Training loss: 0.8855654001235962
Validation loss: 2.318982561429342

Epoch: 6| Step: 5
Training loss: 1.0555166006088257
Validation loss: 2.304293215274811

Epoch: 6| Step: 6
Training loss: 1.0850470066070557
Validation loss: 2.2979220946629844

Epoch: 6| Step: 7
Training loss: 1.2135961055755615
Validation loss: 2.288284401098887

Epoch: 6| Step: 8
Training loss: 1.4429543018341064
Validation loss: 2.2800408005714417

Epoch: 6| Step: 9
Training loss: 1.2269213199615479
Validation loss: 2.2299828131993613

Epoch: 6| Step: 10
Training loss: 1.3748211860656738
Validation loss: 2.3035194079081216

Epoch: 6| Step: 11
Training loss: 1.0489044189453125
Validation loss: 2.2465113004048667

Epoch: 6| Step: 12
Training loss: 1.107701063156128
Validation loss: 2.3116938273111978

Epoch: 6| Step: 13
Training loss: 1.2013356685638428
Validation loss: 2.2807077368100486

Epoch: 419| Step: 0
Training loss: 1.4894639253616333
Validation loss: 2.2564388314882913

Epoch: 6| Step: 1
Training loss: 0.9473820924758911
Validation loss: 2.301369786262512

Epoch: 6| Step: 2
Training loss: 1.1343356370925903
Validation loss: 2.282651980717977

Epoch: 6| Step: 3
Training loss: 0.5665796995162964
Validation loss: 2.3027711311976113

Epoch: 6| Step: 4
Training loss: 1.8348712921142578
Validation loss: 2.2727293570836387

Epoch: 6| Step: 5
Training loss: 1.3186664581298828
Validation loss: 2.2750714222590127

Epoch: 6| Step: 6
Training loss: 1.2195117473602295
Validation loss: 2.2824333906173706

Epoch: 6| Step: 7
Training loss: 1.000067949295044
Validation loss: 2.285369555155436

Epoch: 6| Step: 8
Training loss: 1.208802580833435
Validation loss: 2.283243457476298

Epoch: 6| Step: 9
Training loss: 2.414680242538452
Validation loss: 2.283313433329264

Epoch: 6| Step: 10
Training loss: 0.47978466749191284
Validation loss: 2.2312045892079673

Epoch: 6| Step: 11
Training loss: 1.458489179611206
Validation loss: 2.291777511437734

Epoch: 6| Step: 12
Training loss: 1.3871021270751953
Validation loss: 2.2764084935188293

Epoch: 6| Step: 13
Training loss: 1.2040599584579468
Validation loss: 2.2565967639287314

Epoch: 420| Step: 0
Training loss: 1.3635365962982178
Validation loss: 2.280920167764028

Epoch: 6| Step: 1
Training loss: 1.3480536937713623
Validation loss: 2.3162357807159424

Epoch: 6| Step: 2
Training loss: 1.9968854188919067
Validation loss: 2.300583024819692

Epoch: 6| Step: 3
Training loss: 0.7530354261398315
Validation loss: 2.292168915271759

Epoch: 6| Step: 4
Training loss: 0.7274307608604431
Validation loss: 2.2853691577911377

Epoch: 6| Step: 5
Training loss: 1.7084447145462036
Validation loss: 2.343608021736145

Epoch: 6| Step: 6
Training loss: 1.0755188465118408
Validation loss: 2.37358550230662

Epoch: 6| Step: 7
Training loss: 1.4466252326965332
Validation loss: 2.3608872493108115

Epoch: 6| Step: 8
Training loss: 1.3349802494049072
Validation loss: 2.3732593854268393

Epoch: 6| Step: 9
Training loss: 1.1859328746795654
Validation loss: 2.3675946394602456

Epoch: 6| Step: 10
Training loss: 2.1502439975738525
Validation loss: 2.4061391353607178

Epoch: 6| Step: 11
Training loss: 1.2880053520202637
Validation loss: 2.391557772954305

Epoch: 6| Step: 12
Training loss: 1.426627516746521
Validation loss: 2.4225422938664756

Epoch: 6| Step: 13
Training loss: 0.7227927446365356
Validation loss: 2.441246231396993

Epoch: 421| Step: 0
Training loss: 2.23832631111145
Validation loss: 2.38090580701828

Epoch: 6| Step: 1
Training loss: 1.3284838199615479
Validation loss: 2.366930584112803

Epoch: 6| Step: 2
Training loss: 0.9030255675315857
Validation loss: 2.334569493929545

Epoch: 6| Step: 3
Training loss: 0.9615766406059265
Validation loss: 2.3097185492515564

Epoch: 6| Step: 4
Training loss: 0.783108115196228
Validation loss: 2.300461212793986

Epoch: 6| Step: 5
Training loss: 0.8272769451141357
Validation loss: 2.2570945620536804

Epoch: 6| Step: 6
Training loss: 1.0698838233947754
Validation loss: 2.3069207668304443

Epoch: 6| Step: 7
Training loss: 1.1152981519699097
Validation loss: 2.308630367120107

Epoch: 6| Step: 8
Training loss: 1.3011916875839233
Validation loss: 2.2684713999430337

Epoch: 6| Step: 9
Training loss: 1.287879228591919
Validation loss: 2.251150071620941

Epoch: 6| Step: 10
Training loss: 1.313523530960083
Validation loss: 2.2862181266148887

Epoch: 6| Step: 11
Training loss: 1.2518662214279175
Validation loss: 2.330482761065165

Epoch: 6| Step: 12
Training loss: 1.6639354228973389
Validation loss: 2.305051942666372

Epoch: 6| Step: 13
Training loss: 1.7392261028289795
Validation loss: 2.3109167416890464

Epoch: 422| Step: 0
Training loss: 1.228997826576233
Validation loss: 2.282770852247874

Epoch: 6| Step: 1
Training loss: 1.6584171056747437
Validation loss: 2.321599284807841

Epoch: 6| Step: 2
Training loss: 1.6279041767120361
Validation loss: 2.3156319657961526

Epoch: 6| Step: 3
Training loss: 1.0879827737808228
Validation loss: 2.419657210508982

Epoch: 6| Step: 4
Training loss: 1.6806204319000244
Validation loss: 2.3992274602254233

Epoch: 6| Step: 5
Training loss: 1.2346701622009277
Validation loss: 2.4154504934946694

Epoch: 6| Step: 6
Training loss: 1.2634344100952148
Validation loss: 2.3645188411076865

Epoch: 6| Step: 7
Training loss: 1.6264479160308838
Validation loss: 2.3462766806284585

Epoch: 6| Step: 8
Training loss: 0.7812353372573853
Validation loss: 2.278668204943339

Epoch: 6| Step: 9
Training loss: 1.7301452159881592
Validation loss: 2.249890228112539

Epoch: 6| Step: 10
Training loss: 1.0893123149871826
Validation loss: 2.310605525970459

Epoch: 6| Step: 11
Training loss: 0.9838216304779053
Validation loss: 2.2828004360198975

Epoch: 6| Step: 12
Training loss: 1.3510947227478027
Validation loss: 2.2490564982096353

Epoch: 6| Step: 13
Training loss: 1.4735898971557617
Validation loss: 2.2377395232518515

Epoch: 423| Step: 0
Training loss: 1.270439863204956
Validation loss: 2.251924753189087

Epoch: 6| Step: 1
Training loss: 1.35518479347229
Validation loss: 2.3067296544710794

Epoch: 6| Step: 2
Training loss: 0.6018862128257751
Validation loss: 2.254403034845988

Epoch: 6| Step: 3
Training loss: 0.8995566964149475
Validation loss: 2.3675102591514587

Epoch: 6| Step: 4
Training loss: 1.523743748664856
Validation loss: 2.374483029047648

Epoch: 6| Step: 5
Training loss: 1.5219285488128662
Validation loss: 2.376566926638285

Epoch: 6| Step: 6
Training loss: 1.577742099761963
Validation loss: 2.3887014389038086

Epoch: 6| Step: 7
Training loss: 1.1646740436553955
Validation loss: 2.3860965569814048

Epoch: 6| Step: 8
Training loss: 1.2535927295684814
Validation loss: 2.4263195196787515

Epoch: 6| Step: 9
Training loss: 1.0819270610809326
Validation loss: 2.3453234434127808

Epoch: 6| Step: 10
Training loss: 1.89886474609375
Validation loss: 2.3676421443621316

Epoch: 6| Step: 11
Training loss: 0.8194205164909363
Validation loss: 2.321175535519918

Epoch: 6| Step: 12
Training loss: 1.4405248165130615
Validation loss: 2.342397173245748

Epoch: 6| Step: 13
Training loss: 1.6054660081863403
Validation loss: 2.347857197125753

Epoch: 424| Step: 0
Training loss: 1.3559329509735107
Validation loss: 2.322140355904897

Epoch: 6| Step: 1
Training loss: 0.8668493032455444
Validation loss: 2.3396600087483725

Epoch: 6| Step: 2
Training loss: 1.2608716487884521
Validation loss: 2.3470086057980857

Epoch: 6| Step: 3
Training loss: 1.161628246307373
Validation loss: 2.2627357045809426

Epoch: 6| Step: 4
Training loss: 1.096006989479065
Validation loss: 2.270931820074717

Epoch: 6| Step: 5
Training loss: 1.6053225994110107
Validation loss: 2.286385198434194

Epoch: 6| Step: 6
Training loss: 1.2644881010055542
Validation loss: 2.275645832220713

Epoch: 6| Step: 7
Training loss: 1.0250322818756104
Validation loss: 2.217707554499308

Epoch: 6| Step: 8
Training loss: 1.559894323348999
Validation loss: 2.2242983182271323

Epoch: 6| Step: 9
Training loss: 1.2566298246383667
Validation loss: 2.217140018939972

Epoch: 6| Step: 10
Training loss: 1.0246334075927734
Validation loss: 2.2322282791137695

Epoch: 6| Step: 11
Training loss: 1.5301849842071533
Validation loss: 2.2499874432881675

Epoch: 6| Step: 12
Training loss: 1.44765043258667
Validation loss: 2.205017884572347

Epoch: 6| Step: 13
Training loss: 1.1033005714416504
Validation loss: 2.250334004561106

Epoch: 425| Step: 0
Training loss: 1.030733585357666
Validation loss: 2.271671930948893

Epoch: 6| Step: 1
Training loss: 1.0769400596618652
Validation loss: 2.3156138261159263

Epoch: 6| Step: 2
Training loss: 0.8980759978294373
Validation loss: 2.307436009248098

Epoch: 6| Step: 3
Training loss: 1.0071985721588135
Validation loss: 2.303959528605143

Epoch: 6| Step: 4
Training loss: 0.962762176990509
Validation loss: 2.2864786783854165

Epoch: 6| Step: 5
Training loss: 0.8036544322967529
Validation loss: 2.277069608370463

Epoch: 6| Step: 6
Training loss: 1.741700530052185
Validation loss: 2.2534369230270386

Epoch: 6| Step: 7
Training loss: 1.268904447555542
Validation loss: 2.2497018575668335

Epoch: 6| Step: 8
Training loss: 1.163672924041748
Validation loss: 2.231117228666941

Epoch: 6| Step: 9
Training loss: 1.066287636756897
Validation loss: 2.267669419447581

Epoch: 6| Step: 10
Training loss: 1.9657320976257324
Validation loss: 2.2578776478767395

Epoch: 6| Step: 11
Training loss: 1.4075255393981934
Validation loss: 2.2168883879979453

Epoch: 6| Step: 12
Training loss: 1.6350845098495483
Validation loss: 2.238713502883911

Epoch: 6| Step: 13
Training loss: 1.7378429174423218
Validation loss: 2.2791077693303428

Epoch: 426| Step: 0
Training loss: 0.9287413358688354
Validation loss: 2.2636051376660666

Epoch: 6| Step: 1
Training loss: 1.6985623836517334
Validation loss: 2.2460044821103415

Epoch: 6| Step: 2
Training loss: 0.5971972346305847
Validation loss: 2.2092674175898233

Epoch: 6| Step: 3
Training loss: 1.7813373804092407
Validation loss: 2.2367810010910034

Epoch: 6| Step: 4
Training loss: 0.6914905309677124
Validation loss: 2.2869017521540322

Epoch: 6| Step: 5
Training loss: 1.0289814472198486
Validation loss: 2.273564020792643

Epoch: 6| Step: 6
Training loss: 0.7985323071479797
Validation loss: 2.256211757659912

Epoch: 6| Step: 7
Training loss: 1.3076311349868774
Validation loss: 2.2304744323094687

Epoch: 6| Step: 8
Training loss: 1.0277154445648193
Validation loss: 2.3132023016611734

Epoch: 6| Step: 9
Training loss: 1.6798113584518433
Validation loss: 2.2987471421559653

Epoch: 6| Step: 10
Training loss: 1.7451465129852295
Validation loss: 2.270786702632904

Epoch: 6| Step: 11
Training loss: 1.3402044773101807
Validation loss: 2.2940954764684043

Epoch: 6| Step: 12
Training loss: 0.955260694026947
Validation loss: 2.293612480163574

Epoch: 6| Step: 13
Training loss: 2.1063427925109863
Validation loss: 2.316020409266154

Epoch: 427| Step: 0
Training loss: 1.5507569313049316
Validation loss: 2.343146244684855

Epoch: 6| Step: 1
Training loss: 1.979659080505371
Validation loss: 2.391734480857849

Epoch: 6| Step: 2
Training loss: 0.7719539999961853
Validation loss: 2.396038810412089

Epoch: 6| Step: 3
Training loss: 1.1731586456298828
Validation loss: 2.4115604956944785

Epoch: 6| Step: 4
Training loss: 0.8997073173522949
Validation loss: 2.4562695423762

Epoch: 6| Step: 5
Training loss: 1.643539309501648
Validation loss: 2.401366710662842

Epoch: 6| Step: 6
Training loss: 1.1293151378631592
Validation loss: 2.4040667613347373

Epoch: 6| Step: 7
Training loss: 1.3729486465454102
Validation loss: 2.3980279167493186

Epoch: 6| Step: 8
Training loss: 1.6621181964874268
Validation loss: 2.4250503381093345

Epoch: 6| Step: 9
Training loss: 0.6018695831298828
Validation loss: 2.325751841068268

Epoch: 6| Step: 10
Training loss: 0.9700766801834106
Validation loss: 2.3399055202802024

Epoch: 6| Step: 11
Training loss: 1.1673730611801147
Validation loss: 2.4058568676312766

Epoch: 6| Step: 12
Training loss: 1.730945110321045
Validation loss: 2.3450430432955423

Epoch: 6| Step: 13
Training loss: 0.8271370530128479
Validation loss: 2.340565264225006

Epoch: 428| Step: 0
Training loss: 0.7344247102737427
Validation loss: 2.3160403768221536

Epoch: 6| Step: 1
Training loss: 1.2132384777069092
Validation loss: 2.334127505620321

Epoch: 6| Step: 2
Training loss: 1.7930963039398193
Validation loss: 2.3140452901522317

Epoch: 6| Step: 3
Training loss: 1.306923508644104
Validation loss: 2.360744138558706

Epoch: 6| Step: 4
Training loss: 1.194223165512085
Validation loss: 2.3540260394414267

Epoch: 6| Step: 5
Training loss: 1.4771696329116821
Validation loss: 2.316692590713501

Epoch: 6| Step: 6
Training loss: 1.1960140466690063
Validation loss: 2.2992013096809387

Epoch: 6| Step: 7
Training loss: 1.1541168689727783
Validation loss: 2.2857468922932944

Epoch: 6| Step: 8
Training loss: 1.5100176334381104
Validation loss: 2.252339859803518

Epoch: 6| Step: 9
Training loss: 1.0887444019317627
Validation loss: 2.269675612449646

Epoch: 6| Step: 10
Training loss: 1.3549840450286865
Validation loss: 2.2180733680725098

Epoch: 6| Step: 11
Training loss: 1.591201663017273
Validation loss: 2.2837407191594443

Epoch: 6| Step: 12
Training loss: 2.323772430419922
Validation loss: 2.268933415412903

Epoch: 6| Step: 13
Training loss: 0.5858201384544373
Validation loss: 2.2578728199005127

Epoch: 429| Step: 0
Training loss: 0.5440036654472351
Validation loss: 2.2764951388041177

Epoch: 6| Step: 1
Training loss: 0.7092316150665283
Validation loss: 2.30325053135554

Epoch: 6| Step: 2
Training loss: 1.4471333026885986
Validation loss: 2.283388614654541

Epoch: 6| Step: 3
Training loss: 0.6226850748062134
Validation loss: 2.297619660695394

Epoch: 6| Step: 4
Training loss: 1.107314109802246
Validation loss: 2.308249274889628

Epoch: 6| Step: 5
Training loss: 1.2085870504379272
Validation loss: 2.3092534144719443

Epoch: 6| Step: 6
Training loss: 1.006904125213623
Validation loss: 2.280435880025228

Epoch: 6| Step: 7
Training loss: 1.932288408279419
Validation loss: 2.3058916131655374

Epoch: 6| Step: 8
Training loss: 1.6411755084991455
Validation loss: 2.3205092748006186

Epoch: 6| Step: 9
Training loss: 1.4956616163253784
Validation loss: 2.281913677851359

Epoch: 6| Step: 10
Training loss: 1.198722004890442
Validation loss: 2.317440847555796

Epoch: 6| Step: 11
Training loss: 1.434946894645691
Validation loss: 2.3312824964523315

Epoch: 6| Step: 12
Training loss: 0.9687312841415405
Validation loss: 2.3203481435775757

Epoch: 6| Step: 13
Training loss: 1.4586915969848633
Validation loss: 2.341159780820211

Epoch: 430| Step: 0
Training loss: 0.9903322458267212
Validation loss: 2.3148871660232544

Epoch: 6| Step: 1
Training loss: 0.9155933260917664
Validation loss: 2.2900516589482627

Epoch: 6| Step: 2
Training loss: 0.590753436088562
Validation loss: 2.31178218126297

Epoch: 6| Step: 3
Training loss: 0.955944299697876
Validation loss: 2.328720450401306

Epoch: 6| Step: 4
Training loss: 1.3873419761657715
Validation loss: 2.2441280682881675

Epoch: 6| Step: 5
Training loss: 1.134009599685669
Validation loss: 2.2696897983551025

Epoch: 6| Step: 6
Training loss: 1.1271039247512817
Validation loss: 2.25322159131368

Epoch: 6| Step: 7
Training loss: 1.166042447090149
Validation loss: 2.2057749032974243

Epoch: 6| Step: 8
Training loss: 1.6576900482177734
Validation loss: 2.251672923564911

Epoch: 6| Step: 9
Training loss: 0.974486768245697
Validation loss: 2.2390334010124207

Epoch: 6| Step: 10
Training loss: 1.4395878314971924
Validation loss: 2.2224433422088623

Epoch: 6| Step: 11
Training loss: 1.340095043182373
Validation loss: 2.2418694297472634

Epoch: 6| Step: 12
Training loss: 2.7384347915649414
Validation loss: 2.2624008456865945

Epoch: 6| Step: 13
Training loss: 1.158679723739624
Validation loss: 2.310285131136576

Epoch: 431| Step: 0
Training loss: 1.4080133438110352
Validation loss: 2.3393829663594565

Epoch: 6| Step: 1
Training loss: 1.8885576725006104
Validation loss: 2.3653329412142434

Epoch: 6| Step: 2
Training loss: 1.448221206665039
Validation loss: 2.3410663406054177

Epoch: 6| Step: 3
Training loss: 1.801148533821106
Validation loss: 2.29077676932017

Epoch: 6| Step: 4
Training loss: 1.1166667938232422
Validation loss: 2.23705784479777

Epoch: 6| Step: 5
Training loss: 0.8808069229125977
Validation loss: 2.233242412408193

Epoch: 6| Step: 6
Training loss: 0.9750802516937256
Validation loss: 2.265981078147888

Epoch: 6| Step: 7
Training loss: 1.6451857089996338
Validation loss: 2.205306033293406

Epoch: 6| Step: 8
Training loss: 1.6001038551330566
Validation loss: 2.2578097383181253

Epoch: 6| Step: 9
Training loss: 0.859326183795929
Validation loss: 2.281291961669922

Epoch: 6| Step: 10
Training loss: 1.2779512405395508
Validation loss: 2.2493107318878174

Epoch: 6| Step: 11
Training loss: 1.066473126411438
Validation loss: 2.30563493569692

Epoch: 6| Step: 12
Training loss: 0.7980989217758179
Validation loss: 2.2586474617322287

Epoch: 6| Step: 13
Training loss: 1.1035211086273193
Validation loss: 2.311636209487915

Epoch: 432| Step: 0
Training loss: 1.0808578729629517
Validation loss: 2.32801345984141

Epoch: 6| Step: 1
Training loss: 0.8090819120407104
Validation loss: 2.3026914993921914

Epoch: 6| Step: 2
Training loss: 1.041499376296997
Validation loss: 2.2999135653177896

Epoch: 6| Step: 3
Training loss: 1.6989738941192627
Validation loss: 2.343410074710846

Epoch: 6| Step: 4
Training loss: 0.9217574596405029
Validation loss: 2.315824051698049

Epoch: 6| Step: 5
Training loss: 1.737365961074829
Validation loss: 2.3211896618207297

Epoch: 6| Step: 6
Training loss: 1.3033329248428345
Validation loss: 2.3287532726923623

Epoch: 6| Step: 7
Training loss: 1.3671762943267822
Validation loss: 2.294616480668386

Epoch: 6| Step: 8
Training loss: 1.0115301609039307
Validation loss: 2.247627079486847

Epoch: 6| Step: 9
Training loss: 1.326671838760376
Validation loss: 2.2920433481534324

Epoch: 6| Step: 10
Training loss: 1.2940709590911865
Validation loss: 2.2737509409586587

Epoch: 6| Step: 11
Training loss: 0.7933660745620728
Validation loss: 2.260205864906311

Epoch: 6| Step: 12
Training loss: 0.7082012891769409
Validation loss: 2.293073852856954

Epoch: 6| Step: 13
Training loss: 1.8615009784698486
Validation loss: 2.2692786852518716

Epoch: 433| Step: 0
Training loss: 0.8251110911369324
Validation loss: 2.2475294272104898

Epoch: 6| Step: 1
Training loss: 1.2992136478424072
Validation loss: 2.2846489747365317

Epoch: 6| Step: 2
Training loss: 1.5334160327911377
Validation loss: 2.268389344215393

Epoch: 6| Step: 3
Training loss: 0.7951624393463135
Validation loss: 2.3186256885528564

Epoch: 6| Step: 4
Training loss: 0.8458019495010376
Validation loss: 2.3117969036102295

Epoch: 6| Step: 5
Training loss: 1.56879723072052
Validation loss: 2.2883115808169046

Epoch: 6| Step: 6
Training loss: 1.3734867572784424
Validation loss: 2.282289147377014

Epoch: 6| Step: 7
Training loss: 1.604590654373169
Validation loss: 2.279898186524709

Epoch: 6| Step: 8
Training loss: 1.6722873449325562
Validation loss: 2.3217275937398276

Epoch: 6| Step: 9
Training loss: 0.9719924330711365
Validation loss: 2.292047639687856

Epoch: 6| Step: 10
Training loss: 1.7407002449035645
Validation loss: 2.304704467455546

Epoch: 6| Step: 11
Training loss: 1.156787395477295
Validation loss: 2.2648821274439492

Epoch: 6| Step: 12
Training loss: 0.9896538853645325
Validation loss: 2.3882605036099753

Epoch: 6| Step: 13
Training loss: 1.1652014255523682
Validation loss: 2.3435518940289817

Epoch: 434| Step: 0
Training loss: 1.5667877197265625
Validation loss: 2.3648512959480286

Epoch: 6| Step: 1
Training loss: 1.4572807550430298
Validation loss: 2.388556480407715

Epoch: 6| Step: 2
Training loss: 1.8158206939697266
Validation loss: 2.4291314681371055

Epoch: 6| Step: 3
Training loss: 1.4546408653259277
Validation loss: 2.4080130457878113

Epoch: 6| Step: 4
Training loss: 1.1361157894134521
Validation loss: 2.362840016682943

Epoch: 6| Step: 5
Training loss: 1.314990758895874
Validation loss: 2.3711696664492288

Epoch: 6| Step: 6
Training loss: 1.331329107284546
Validation loss: 2.34797211488088

Epoch: 6| Step: 7
Training loss: 1.4494569301605225
Validation loss: 2.370605707168579

Epoch: 6| Step: 8
Training loss: 1.8546479940414429
Validation loss: 2.3680105209350586

Epoch: 6| Step: 9
Training loss: 0.9646716713905334
Validation loss: 2.3112972180048623

Epoch: 6| Step: 10
Training loss: 0.5672425031661987
Validation loss: 2.343834181626638

Epoch: 6| Step: 11
Training loss: 0.9080035090446472
Validation loss: 2.272308071454366

Epoch: 6| Step: 12
Training loss: 0.8618395328521729
Validation loss: 2.3440614541371665

Epoch: 6| Step: 13
Training loss: 0.7229430079460144
Validation loss: 2.379602531592051

Epoch: 435| Step: 0
Training loss: 1.9523508548736572
Validation loss: 2.364187320073446

Epoch: 6| Step: 1
Training loss: 1.1039881706237793
Validation loss: 2.3092817266782126

Epoch: 6| Step: 2
Training loss: 0.813972532749176
Validation loss: 2.345320741335551

Epoch: 6| Step: 3
Training loss: 0.5730164647102356
Validation loss: 2.3180908958117166

Epoch: 6| Step: 4
Training loss: 1.2829389572143555
Validation loss: 2.2719047466913858

Epoch: 6| Step: 5
Training loss: 1.1343892812728882
Validation loss: 2.289023776849111

Epoch: 6| Step: 6
Training loss: 1.1757140159606934
Validation loss: 2.298765182495117

Epoch: 6| Step: 7
Training loss: 1.366520881652832
Validation loss: 2.2979296445846558

Epoch: 6| Step: 8
Training loss: 0.8755379915237427
Validation loss: 2.3197993636131287

Epoch: 6| Step: 9
Training loss: 0.7978801727294922
Validation loss: 2.327703873316447

Epoch: 6| Step: 10
Training loss: 1.2530667781829834
Validation loss: 2.3362518548965454

Epoch: 6| Step: 11
Training loss: 1.2245427370071411
Validation loss: 2.28862335284551

Epoch: 6| Step: 12
Training loss: 1.9658366441726685
Validation loss: 2.2836442987124124

Epoch: 6| Step: 13
Training loss: 1.27048659324646
Validation loss: 2.310243805249532

Epoch: 436| Step: 0
Training loss: 0.7960759401321411
Validation loss: 2.2489291628201804

Epoch: 6| Step: 1
Training loss: 0.9772050976753235
Validation loss: 2.2768724163373313

Epoch: 6| Step: 2
Training loss: 0.9294469356536865
Validation loss: 2.2935858368873596

Epoch: 6| Step: 3
Training loss: 1.5967180728912354
Validation loss: 2.2924023270606995

Epoch: 6| Step: 4
Training loss: 0.8647422790527344
Validation loss: 2.3261466026306152

Epoch: 6| Step: 5
Training loss: 2.0577750205993652
Validation loss: 2.2574026584625244

Epoch: 6| Step: 6
Training loss: 1.8025236129760742
Validation loss: 2.330780843893687

Epoch: 6| Step: 7
Training loss: 1.162891149520874
Validation loss: 2.225583295027415

Epoch: 6| Step: 8
Training loss: 0.6173954010009766
Validation loss: 2.1821358601252236

Epoch: 6| Step: 9
Training loss: 0.7519314289093018
Validation loss: 2.2642852862675986

Epoch: 6| Step: 10
Training loss: 1.884831190109253
Validation loss: 2.2118234237035117

Epoch: 6| Step: 11
Training loss: 0.9069479703903198
Validation loss: 2.247044642766317

Epoch: 6| Step: 12
Training loss: 1.3180365562438965
Validation loss: 2.2029937704404197

Epoch: 6| Step: 13
Training loss: 1.0827490091323853
Validation loss: 2.236967941125234

Epoch: 437| Step: 0
Training loss: 1.320176124572754
Validation loss: 2.281265159447988

Epoch: 6| Step: 1
Training loss: 0.928972601890564
Validation loss: 2.2206448713938394

Epoch: 6| Step: 2
Training loss: 0.739587664604187
Validation loss: 2.2387298345565796

Epoch: 6| Step: 3
Training loss: 1.0944582223892212
Validation loss: 2.266858160495758

Epoch: 6| Step: 4
Training loss: 0.9695459008216858
Validation loss: 2.258759001890818

Epoch: 6| Step: 5
Training loss: 1.5655534267425537
Validation loss: 2.2908234198888144

Epoch: 6| Step: 6
Training loss: 0.9579864740371704
Validation loss: 2.3157336513201394

Epoch: 6| Step: 7
Training loss: 0.781007707118988
Validation loss: 2.3146777351697287

Epoch: 6| Step: 8
Training loss: 1.2422432899475098
Validation loss: 2.269099791844686

Epoch: 6| Step: 9
Training loss: 0.8546540141105652
Validation loss: 2.330776254336039

Epoch: 6| Step: 10
Training loss: 1.611711025238037
Validation loss: 2.304812709490458

Epoch: 6| Step: 11
Training loss: 1.5457987785339355
Validation loss: 2.2542664210001626

Epoch: 6| Step: 12
Training loss: 1.5711684226989746
Validation loss: 2.258457442124685

Epoch: 6| Step: 13
Training loss: 1.3064584732055664
Validation loss: 2.256097416083018

Epoch: 438| Step: 0
Training loss: 1.7832090854644775
Validation loss: 2.247964362303416

Epoch: 6| Step: 1
Training loss: 1.6653227806091309
Validation loss: 2.2860612074534097

Epoch: 6| Step: 2
Training loss: 0.8449538946151733
Validation loss: 2.2365819811820984

Epoch: 6| Step: 3
Training loss: 0.7972236275672913
Validation loss: 2.2810056805610657

Epoch: 6| Step: 4
Training loss: 1.5490273237228394
Validation loss: 2.2965569496154785

Epoch: 6| Step: 5
Training loss: 1.1338305473327637
Validation loss: 2.2759620348612466

Epoch: 6| Step: 6
Training loss: 0.8525971174240112
Validation loss: 2.295510729153951

Epoch: 6| Step: 7
Training loss: 0.6667391061782837
Validation loss: 2.275538166364034

Epoch: 6| Step: 8
Training loss: 1.59920072555542
Validation loss: 2.326877554257711

Epoch: 6| Step: 9
Training loss: 0.5955100059509277
Validation loss: 2.3168751001358032

Epoch: 6| Step: 10
Training loss: 0.7861925363540649
Validation loss: 2.2961241205533347

Epoch: 6| Step: 11
Training loss: 0.7718135118484497
Validation loss: 2.330594261487325

Epoch: 6| Step: 12
Training loss: 1.8973798751831055
Validation loss: 2.3478320638338723

Epoch: 6| Step: 13
Training loss: 1.665452480316162
Validation loss: 2.363150715827942

Epoch: 439| Step: 0
Training loss: 1.4464528560638428
Validation loss: 2.307127078374227

Epoch: 6| Step: 1
Training loss: 0.8723315596580505
Validation loss: 2.330681105454763

Epoch: 6| Step: 2
Training loss: 1.0065908432006836
Validation loss: 2.3426507115364075

Epoch: 6| Step: 3
Training loss: 1.5899184942245483
Validation loss: 2.399782737096151

Epoch: 6| Step: 4
Training loss: 1.2205851078033447
Validation loss: 2.398627976576487

Epoch: 6| Step: 5
Training loss: 1.7014744281768799
Validation loss: 2.343923509120941

Epoch: 6| Step: 6
Training loss: 1.1862330436706543
Validation loss: 2.374463597933451

Epoch: 6| Step: 7
Training loss: 1.1470961570739746
Validation loss: 2.349639415740967

Epoch: 6| Step: 8
Training loss: 0.7825972437858582
Validation loss: 2.3225478728612265

Epoch: 6| Step: 9
Training loss: 0.5124315023422241
Validation loss: 2.2876729567845664

Epoch: 6| Step: 10
Training loss: 1.4319156408309937
Validation loss: 2.25859405597051

Epoch: 6| Step: 11
Training loss: 0.6821483373641968
Validation loss: 2.2868746320406594

Epoch: 6| Step: 12
Training loss: 1.1563513278961182
Validation loss: 2.286471883455912

Epoch: 6| Step: 13
Training loss: 1.2715020179748535
Validation loss: 2.2893588542938232

Epoch: 440| Step: 0
Training loss: 1.2659235000610352
Validation loss: 2.3676482836405435

Epoch: 6| Step: 1
Training loss: 0.6974848508834839
Validation loss: 2.3117894728978476

Epoch: 6| Step: 2
Training loss: 1.562029242515564
Validation loss: 2.2886511087417603

Epoch: 6| Step: 3
Training loss: 0.8113498687744141
Validation loss: 2.2654138803482056

Epoch: 6| Step: 4
Training loss: 1.7953898906707764
Validation loss: 2.2614569067955017

Epoch: 6| Step: 5
Training loss: 1.5480707883834839
Validation loss: 2.234305719534556

Epoch: 6| Step: 6
Training loss: 1.3642504215240479
Validation loss: 2.2383845845858255

Epoch: 6| Step: 7
Training loss: 0.5823517441749573
Validation loss: 2.2419085105260215

Epoch: 6| Step: 8
Training loss: 1.165416955947876
Validation loss: 2.2839666406313577

Epoch: 6| Step: 9
Training loss: 1.1576159000396729
Validation loss: 2.2428778409957886

Epoch: 6| Step: 10
Training loss: 1.383744239807129
Validation loss: 2.2373483379681907

Epoch: 6| Step: 11
Training loss: 1.1568812131881714
Validation loss: 2.2605545918146768

Epoch: 6| Step: 12
Training loss: 1.2717005014419556
Validation loss: 2.275422434012095

Epoch: 6| Step: 13
Training loss: 1.1436679363250732
Validation loss: 2.211289882659912

Epoch: 441| Step: 0
Training loss: 1.4450832605361938
Validation loss: 2.2411072651545205

Epoch: 6| Step: 1
Training loss: 1.3801236152648926
Validation loss: 2.2073001662890115

Epoch: 6| Step: 2
Training loss: 1.0083590745925903
Validation loss: 2.215195596218109

Epoch: 6| Step: 3
Training loss: 1.1020933389663696
Validation loss: 2.2591851552327475

Epoch: 6| Step: 4
Training loss: 1.6969109773635864
Validation loss: 2.233381450176239

Epoch: 6| Step: 5
Training loss: 1.193537712097168
Validation loss: 2.2587820291519165

Epoch: 6| Step: 6
Training loss: 0.5763075351715088
Validation loss: 2.2837947607040405

Epoch: 6| Step: 7
Training loss: 0.9843664169311523
Validation loss: 2.2771965662638345

Epoch: 6| Step: 8
Training loss: 1.7540267705917358
Validation loss: 2.2684090733528137

Epoch: 6| Step: 9
Training loss: 1.4081896543502808
Validation loss: 2.2588034868240356

Epoch: 6| Step: 10
Training loss: 0.9591866135597229
Validation loss: 2.2511787017186484

Epoch: 6| Step: 11
Training loss: 1.029279351234436
Validation loss: 2.2958170970280967

Epoch: 6| Step: 12
Training loss: 1.0528645515441895
Validation loss: 2.2927042643229165

Epoch: 6| Step: 13
Training loss: 0.9732105731964111
Validation loss: 2.257483104864756

Epoch: 442| Step: 0
Training loss: 1.7111812829971313
Validation loss: 2.2628151178359985

Epoch: 6| Step: 1
Training loss: 0.7141796350479126
Validation loss: 2.2473915020624795

Epoch: 6| Step: 2
Training loss: 1.209808349609375
Validation loss: 2.2624062101046243

Epoch: 6| Step: 3
Training loss: 1.3024272918701172
Validation loss: 2.26987357934316

Epoch: 6| Step: 4
Training loss: 1.4837286472320557
Validation loss: 2.3446637789408364

Epoch: 6| Step: 5
Training loss: 1.1200940608978271
Validation loss: 2.3800860246022544

Epoch: 6| Step: 6
Training loss: 1.3514233827590942
Validation loss: 2.3269403179486594

Epoch: 6| Step: 7
Training loss: 1.193892002105713
Validation loss: 2.3030711015065513

Epoch: 6| Step: 8
Training loss: 0.9839946031570435
Validation loss: 2.3311304847399392

Epoch: 6| Step: 9
Training loss: 0.825852632522583
Validation loss: 2.2941704988479614

Epoch: 6| Step: 10
Training loss: 1.357041835784912
Validation loss: 2.335674524307251

Epoch: 6| Step: 11
Training loss: 1.2312088012695312
Validation loss: 2.248545209566752

Epoch: 6| Step: 12
Training loss: 0.7261708974838257
Validation loss: 2.3327300945917764

Epoch: 6| Step: 13
Training loss: 1.0792158842086792
Validation loss: 2.3252877593040466

Epoch: 443| Step: 0
Training loss: 1.5694562196731567
Validation loss: 2.3552016019821167

Epoch: 6| Step: 1
Training loss: 1.950524091720581
Validation loss: 2.3125252723693848

Epoch: 6| Step: 2
Training loss: 1.1598498821258545
Validation loss: 2.3615877827008567

Epoch: 6| Step: 3
Training loss: 1.0643235445022583
Validation loss: 2.424308200677236

Epoch: 6| Step: 4
Training loss: 0.8127384185791016
Validation loss: 2.4261690775553384

Epoch: 6| Step: 5
Training loss: 0.6223084926605225
Validation loss: 2.3967700799306235

Epoch: 6| Step: 6
Training loss: 1.1872931718826294
Validation loss: 2.4183330138524375

Epoch: 6| Step: 7
Training loss: 1.5383477210998535
Validation loss: 2.3447426160176597

Epoch: 6| Step: 8
Training loss: 1.1856944561004639
Validation loss: 2.3513635794321694

Epoch: 6| Step: 9
Training loss: 0.9285643696784973
Validation loss: 2.3153132796287537

Epoch: 6| Step: 10
Training loss: 0.7130985260009766
Validation loss: 2.327995777130127

Epoch: 6| Step: 11
Training loss: 1.5407315492630005
Validation loss: 2.264501412709554

Epoch: 6| Step: 12
Training loss: 1.3016844987869263
Validation loss: 2.295182545979818

Epoch: 6| Step: 13
Training loss: 0.7110592126846313
Validation loss: 2.2342206239700317

Epoch: 444| Step: 0
Training loss: 1.4588457345962524
Validation loss: 2.2419385512669883

Epoch: 6| Step: 1
Training loss: 0.8027856945991516
Validation loss: 2.228864828745524

Epoch: 6| Step: 2
Training loss: 1.0047531127929688
Validation loss: 2.249717593193054

Epoch: 6| Step: 3
Training loss: 1.323882818222046
Validation loss: 2.2500430941581726

Epoch: 6| Step: 4
Training loss: 0.3860396146774292
Validation loss: 2.2469023863474527

Epoch: 6| Step: 5
Training loss: 1.282366394996643
Validation loss: 2.2472576101620994

Epoch: 6| Step: 6
Training loss: 1.2221683263778687
Validation loss: 2.2623464266459146

Epoch: 6| Step: 7
Training loss: 1.4954378604888916
Validation loss: 2.253451645374298

Epoch: 6| Step: 8
Training loss: 1.431282877922058
Validation loss: 2.251969496409098

Epoch: 6| Step: 9
Training loss: 0.911475419998169
Validation loss: 2.2220788995424905

Epoch: 6| Step: 10
Training loss: 1.539763331413269
Validation loss: 2.2882511615753174

Epoch: 6| Step: 11
Training loss: 1.4078346490859985
Validation loss: 2.2853206793467202

Epoch: 6| Step: 12
Training loss: 1.1889500617980957
Validation loss: 2.2923179467519126

Epoch: 6| Step: 13
Training loss: 1.1723380088806152
Validation loss: 2.37104340394338

Epoch: 445| Step: 0
Training loss: 0.6885034441947937
Validation loss: 2.350994030634562

Epoch: 6| Step: 1
Training loss: 0.9047926664352417
Validation loss: 2.301901936531067

Epoch: 6| Step: 2
Training loss: 1.5427284240722656
Validation loss: 2.337583899497986

Epoch: 6| Step: 3
Training loss: 1.3449625968933105
Validation loss: 2.2876365582148233

Epoch: 6| Step: 4
Training loss: 1.751347541809082
Validation loss: 2.270622213681539

Epoch: 6| Step: 5
Training loss: 0.8077111840248108
Validation loss: 2.286852717399597

Epoch: 6| Step: 6
Training loss: 1.5049748420715332
Validation loss: 2.3010937174161277

Epoch: 6| Step: 7
Training loss: 1.0158687829971313
Validation loss: 2.3209343552589417

Epoch: 6| Step: 8
Training loss: 0.9036256074905396
Validation loss: 2.262549956639608

Epoch: 6| Step: 9
Training loss: 1.3098279237747192
Validation loss: 2.3381327788035073

Epoch: 6| Step: 10
Training loss: 1.3579072952270508
Validation loss: 2.2813721895217896

Epoch: 6| Step: 11
Training loss: 0.7472549080848694
Validation loss: 2.260798474152883

Epoch: 6| Step: 12
Training loss: 0.5418754816055298
Validation loss: 2.2849941651026406

Epoch: 6| Step: 13
Training loss: 1.5816283226013184
Validation loss: 2.268988092740377

Epoch: 446| Step: 0
Training loss: 1.325361728668213
Validation loss: 2.293067197004954

Epoch: 6| Step: 1
Training loss: 0.957938551902771
Validation loss: 2.2906059424082437

Epoch: 6| Step: 2
Training loss: 0.5772121548652649
Validation loss: 2.272983888785044

Epoch: 6| Step: 3
Training loss: 1.4365088939666748
Validation loss: 2.311861594518026

Epoch: 6| Step: 4
Training loss: 1.6069955825805664
Validation loss: 2.2827818989753723

Epoch: 6| Step: 5
Training loss: 0.6536358594894409
Validation loss: 2.336525638898214

Epoch: 6| Step: 6
Training loss: 0.8397802114486694
Validation loss: 2.277313550313314

Epoch: 6| Step: 7
Training loss: 0.6078234910964966
Validation loss: 2.31037300825119

Epoch: 6| Step: 8
Training loss: 1.34427011013031
Validation loss: 2.354913036028544

Epoch: 6| Step: 9
Training loss: 1.8432649374008179
Validation loss: 2.3131148417790732

Epoch: 6| Step: 10
Training loss: 0.8794499039649963
Validation loss: 2.3415555357933044

Epoch: 6| Step: 11
Training loss: 0.8149034380912781
Validation loss: 2.311021169026693

Epoch: 6| Step: 12
Training loss: 1.6103132963180542
Validation loss: 2.3112065196037292

Epoch: 6| Step: 13
Training loss: 2.0388739109039307
Validation loss: 2.362300674120585

Epoch: 447| Step: 0
Training loss: 1.1519362926483154
Validation loss: 2.371588925520579

Epoch: 6| Step: 1
Training loss: 1.3788409233093262
Validation loss: 2.3200189073880515

Epoch: 6| Step: 2
Training loss: 1.2919827699661255
Validation loss: 2.3420963287353516

Epoch: 6| Step: 3
Training loss: 1.092716097831726
Validation loss: 2.393591523170471

Epoch: 6| Step: 4
Training loss: 0.9982743263244629
Validation loss: 2.2883069117863974

Epoch: 6| Step: 5
Training loss: 1.9278910160064697
Validation loss: 2.321339249610901

Epoch: 6| Step: 6
Training loss: 1.2281607389450073
Validation loss: 2.251017133394877

Epoch: 6| Step: 7
Training loss: 0.9422099590301514
Validation loss: 2.2648472785949707

Epoch: 6| Step: 8
Training loss: 0.9793918132781982
Validation loss: 2.259373426437378

Epoch: 6| Step: 9
Training loss: 1.2005611658096313
Validation loss: 2.318400263786316

Epoch: 6| Step: 10
Training loss: 1.1934337615966797
Validation loss: 2.2966126203536987

Epoch: 6| Step: 11
Training loss: 1.1754298210144043
Validation loss: 2.320164660612742

Epoch: 6| Step: 12
Training loss: 1.3350201845169067
Validation loss: 2.310752749443054

Epoch: 6| Step: 13
Training loss: 1.0819976329803467
Validation loss: 2.2931505044301352

Epoch: 448| Step: 0
Training loss: 1.6606152057647705
Validation loss: 2.2888616720835366

Epoch: 6| Step: 1
Training loss: 1.5930440425872803
Validation loss: 2.2056623498598733

Epoch: 6| Step: 2
Training loss: 0.830977201461792
Validation loss: 2.314117670059204

Epoch: 6| Step: 3
Training loss: 1.6470239162445068
Validation loss: 2.4008420507113137

Epoch: 6| Step: 4
Training loss: 1.3384406566619873
Validation loss: 2.435342768828074

Epoch: 6| Step: 5
Training loss: 1.459003210067749
Validation loss: 2.389667590459188

Epoch: 6| Step: 6
Training loss: 1.7360270023345947
Validation loss: 2.3757721185684204

Epoch: 6| Step: 7
Training loss: 1.437736988067627
Validation loss: 2.3562129735946655

Epoch: 6| Step: 8
Training loss: 1.0483860969543457
Validation loss: 2.327667713165283

Epoch: 6| Step: 9
Training loss: 1.3872416019439697
Validation loss: 2.223281661669413

Epoch: 6| Step: 10
Training loss: 0.9843498468399048
Validation loss: 2.2555792530377707

Epoch: 6| Step: 11
Training loss: 1.3888851404190063
Validation loss: 2.2108357350031533

Epoch: 6| Step: 12
Training loss: 1.252655029296875
Validation loss: 2.222889542579651

Epoch: 6| Step: 13
Training loss: 1.155122995376587
Validation loss: 2.252826770146688

Epoch: 449| Step: 0
Training loss: 0.8697898983955383
Validation loss: 2.2368224064509072

Epoch: 6| Step: 1
Training loss: 0.9329777956008911
Validation loss: 2.2484965125719705

Epoch: 6| Step: 2
Training loss: 1.4420711994171143
Validation loss: 2.266403158505758

Epoch: 6| Step: 3
Training loss: 0.6703226566314697
Validation loss: 2.312656342983246

Epoch: 6| Step: 4
Training loss: 1.036149024963379
Validation loss: 2.284583568572998

Epoch: 6| Step: 5
Training loss: 2.1054775714874268
Validation loss: 2.2519241770108542

Epoch: 6| Step: 6
Training loss: 1.5023083686828613
Validation loss: 2.369753082593282

Epoch: 6| Step: 7
Training loss: 1.3619853258132935
Validation loss: 2.3695255517959595

Epoch: 6| Step: 8
Training loss: 1.6588857173919678
Validation loss: 2.337751805782318

Epoch: 6| Step: 9
Training loss: 1.4868810176849365
Validation loss: 2.3353269894917807

Epoch: 6| Step: 10
Training loss: 0.9554466009140015
Validation loss: 2.2737075289090476

Epoch: 6| Step: 11
Training loss: 0.9775491952896118
Validation loss: 2.3180866837501526

Epoch: 6| Step: 12
Training loss: 1.6384263038635254
Validation loss: 2.3231663505236306

Epoch: 6| Step: 13
Training loss: 0.91168212890625
Validation loss: 2.272420366605123

Epoch: 450| Step: 0
Training loss: 1.6756126880645752
Validation loss: 2.296356201171875

Epoch: 6| Step: 1
Training loss: 1.1707544326782227
Validation loss: 2.276565988858541

Epoch: 6| Step: 2
Training loss: 0.9012174606323242
Validation loss: 2.2834517558415732

Epoch: 6| Step: 3
Training loss: 1.2649948596954346
Validation loss: 2.3098420898119607

Epoch: 6| Step: 4
Training loss: 0.693683385848999
Validation loss: 2.320782423019409

Epoch: 6| Step: 5
Training loss: 1.7024791240692139
Validation loss: 2.280593434969584

Epoch: 6| Step: 6
Training loss: 1.1925368309020996
Validation loss: 2.3394280870755515

Epoch: 6| Step: 7
Training loss: 0.6512050628662109
Validation loss: 2.2834744850794473

Epoch: 6| Step: 8
Training loss: 1.6424981355667114
Validation loss: 2.30615762869517

Epoch: 6| Step: 9
Training loss: 0.7819010019302368
Validation loss: 2.288541932900747

Epoch: 6| Step: 10
Training loss: 1.387674331665039
Validation loss: 2.2531795104344687

Epoch: 6| Step: 11
Training loss: 1.0360746383666992
Validation loss: 2.2766303022702536

Epoch: 6| Step: 12
Training loss: 1.4775044918060303
Validation loss: 2.276549239953359

Epoch: 6| Step: 13
Training loss: 0.6955526471138
Validation loss: 2.2732016841570535

Testing loss: 1.907905660944877
