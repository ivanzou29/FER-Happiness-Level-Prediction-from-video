Epoch: 1| Step: 0
Training loss: 5.438901901245117
Validation loss: 5.269044399261475

Epoch: 6| Step: 1
Training loss: 3.6989147663116455
Validation loss: 5.2675251960754395

Epoch: 6| Step: 2
Training loss: 4.9982523918151855
Validation loss: 5.265941222508748

Epoch: 6| Step: 3
Training loss: 7.115265846252441
Validation loss: 5.264506816864014

Epoch: 6| Step: 4
Training loss: 5.46480655670166
Validation loss: 5.263035217920939

Epoch: 6| Step: 5
Training loss: 6.443842887878418
Validation loss: 5.261549870173137

Epoch: 6| Step: 6
Training loss: 5.2743072509765625
Validation loss: 5.2600570519765215

Epoch: 6| Step: 7
Training loss: 5.285031318664551
Validation loss: 5.258607308069865

Epoch: 6| Step: 8
Training loss: 3.976372241973877
Validation loss: 5.257066647211711

Epoch: 6| Step: 9
Training loss: 6.417123794555664
Validation loss: 5.25549578666687

Epoch: 6| Step: 10
Training loss: 6.317265033721924
Validation loss: 5.253924608230591

Epoch: 6| Step: 11
Training loss: 4.772116661071777
Validation loss: 5.252185026804606

Epoch: 6| Step: 12
Training loss: 4.882544040679932
Validation loss: 5.250478029251099

Epoch: 6| Step: 13
Training loss: 4.515116214752197
Validation loss: 5.248690764109294

Epoch: 2| Step: 0
Training loss: 5.759720802307129
Validation loss: 5.246779680252075

Epoch: 6| Step: 1
Training loss: 4.883437156677246
Validation loss: 5.2447958787282305

Epoch: 6| Step: 2
Training loss: 5.4317779541015625
Validation loss: 5.242722034454346

Epoch: 6| Step: 3
Training loss: 4.278237342834473
Validation loss: 5.240561803181966

Epoch: 6| Step: 4
Training loss: 5.294003009796143
Validation loss: 5.238396247227986

Epoch: 6| Step: 5
Training loss: 4.6692938804626465
Validation loss: 5.236090580622355

Epoch: 6| Step: 6
Training loss: 5.315958023071289
Validation loss: 5.233811616897583

Epoch: 6| Step: 7
Training loss: 5.626767158508301
Validation loss: 5.2312999566396075

Epoch: 6| Step: 8
Training loss: 5.54805850982666
Validation loss: 5.228591203689575

Epoch: 6| Step: 9
Training loss: 5.525686264038086
Validation loss: 5.2257992426554365

Epoch: 6| Step: 10
Training loss: 4.877321243286133
Validation loss: 5.2229117552439375

Epoch: 6| Step: 11
Training loss: 5.223750114440918
Validation loss: 5.219924966494243

Epoch: 6| Step: 12
Training loss: 5.739563941955566
Validation loss: 5.216716051101685

Epoch: 6| Step: 13
Training loss: 6.042647361755371
Validation loss: 5.2133861382802325

Epoch: 3| Step: 0
Training loss: 5.6703643798828125
Validation loss: 5.209790945053101

Epoch: 6| Step: 1
Training loss: 4.982511520385742
Validation loss: 5.206035137176514

Epoch: 6| Step: 2
Training loss: 6.002562522888184
Validation loss: 5.202296733856201

Epoch: 6| Step: 3
Training loss: 4.37135648727417
Validation loss: 5.198137998580933

Epoch: 6| Step: 4
Training loss: 4.36668062210083
Validation loss: 5.194003979365031

Epoch: 6| Step: 5
Training loss: 5.167740821838379
Validation loss: 5.189544200897217

Epoch: 6| Step: 6
Training loss: 5.517433166503906
Validation loss: 5.184644778569539

Epoch: 6| Step: 7
Training loss: 4.753490447998047
Validation loss: 5.179910341898601

Epoch: 6| Step: 8
Training loss: 5.375189781188965
Validation loss: 5.174658139546712

Epoch: 6| Step: 9
Training loss: 5.542017936706543
Validation loss: 5.169110377629598

Epoch: 6| Step: 10
Training loss: 6.665580749511719
Validation loss: 5.163533369700114

Epoch: 6| Step: 11
Training loss: 5.089264869689941
Validation loss: 5.157676458358765

Epoch: 6| Step: 12
Training loss: 5.00213623046875
Validation loss: 5.151288350423177

Epoch: 6| Step: 13
Training loss: 5.0180768966674805
Validation loss: 5.145136833190918

Epoch: 4| Step: 0
Training loss: 4.783412456512451
Validation loss: 5.138133525848389

Epoch: 6| Step: 1
Training loss: 5.449606895446777
Validation loss: 5.131373604138692

Epoch: 6| Step: 2
Training loss: 5.519927501678467
Validation loss: 5.124143123626709

Epoch: 6| Step: 3
Training loss: 5.271919250488281
Validation loss: 5.116863012313843

Epoch: 6| Step: 4
Training loss: 4.899737358093262
Validation loss: 5.10906966527303

Epoch: 6| Step: 5
Training loss: 5.012376308441162
Validation loss: 5.101276834805806

Epoch: 6| Step: 6
Training loss: 4.734206199645996
Validation loss: 5.093527714411418

Epoch: 6| Step: 7
Training loss: 4.858372688293457
Validation loss: 5.085272153218587

Epoch: 6| Step: 8
Training loss: 4.499068260192871
Validation loss: 5.077048699061076

Epoch: 6| Step: 9
Training loss: 5.452315330505371
Validation loss: 5.068781693776448

Epoch: 6| Step: 10
Training loss: 5.57659912109375
Validation loss: 5.060007572174072

Epoch: 6| Step: 11
Training loss: 5.494204998016357
Validation loss: 5.051302075386047

Epoch: 6| Step: 12
Training loss: 5.5500898361206055
Validation loss: 5.0423431396484375

Epoch: 6| Step: 13
Training loss: 5.176610946655273
Validation loss: 5.03340220451355

Epoch: 5| Step: 0
Training loss: 4.675606727600098
Validation loss: 5.024067838986714

Epoch: 6| Step: 1
Training loss: 5.819293975830078
Validation loss: 5.014974753061931

Epoch: 6| Step: 2
Training loss: 5.01406192779541
Validation loss: 5.0054372151692705

Epoch: 6| Step: 3
Training loss: 5.344257831573486
Validation loss: 4.996318976084392

Epoch: 6| Step: 4
Training loss: 5.6384782791137695
Validation loss: 4.987365007400513

Epoch: 6| Step: 5
Training loss: 4.1913018226623535
Validation loss: 4.978094816207886

Epoch: 6| Step: 6
Training loss: 3.8131909370422363
Validation loss: 4.968896269798279

Epoch: 6| Step: 7
Training loss: 4.833163261413574
Validation loss: 4.95966649055481

Epoch: 6| Step: 8
Training loss: 5.939240455627441
Validation loss: 4.950770934422811

Epoch: 6| Step: 9
Training loss: 5.441481113433838
Validation loss: 4.941812078158061

Epoch: 6| Step: 10
Training loss: 5.4358367919921875
Validation loss: 4.932881434758504

Epoch: 6| Step: 11
Training loss: 5.485122203826904
Validation loss: 4.924040953318278

Epoch: 6| Step: 12
Training loss: 4.572082042694092
Validation loss: 4.915421883265178

Epoch: 6| Step: 13
Training loss: 4.4600114822387695
Validation loss: 4.907286445299785

Epoch: 6| Step: 0
Training loss: 4.316498756408691
Validation loss: 4.898887077967326

Epoch: 6| Step: 1
Training loss: 5.110024929046631
Validation loss: 4.891023715337117

Epoch: 6| Step: 2
Training loss: 6.031952381134033
Validation loss: 4.88330324490865

Epoch: 6| Step: 3
Training loss: 3.5088353157043457
Validation loss: 4.875641425450643

Epoch: 6| Step: 4
Training loss: 5.1656646728515625
Validation loss: 4.867860237757365

Epoch: 6| Step: 5
Training loss: 5.125378608703613
Validation loss: 4.860252618789673

Epoch: 6| Step: 6
Training loss: 5.0228071212768555
Validation loss: 4.852660576502482

Epoch: 6| Step: 7
Training loss: 4.554117202758789
Validation loss: 4.845118602116902

Epoch: 6| Step: 8
Training loss: 4.950571060180664
Validation loss: 4.83741561571757

Epoch: 6| Step: 9
Training loss: 5.461846828460693
Validation loss: 4.829899708429973

Epoch: 6| Step: 10
Training loss: 5.402980804443359
Validation loss: 4.822637279828389

Epoch: 6| Step: 11
Training loss: 4.727133750915527
Validation loss: 4.8151960372924805

Epoch: 6| Step: 12
Training loss: 5.413187026977539
Validation loss: 4.807865619659424

Epoch: 6| Step: 13
Training loss: 4.313660621643066
Validation loss: 4.800906697909038

Epoch: 7| Step: 0
Training loss: 5.165126800537109
Validation loss: 4.79393728574117

Epoch: 6| Step: 1
Training loss: 4.532405853271484
Validation loss: 4.787310242652893

Epoch: 6| Step: 2
Training loss: 4.644160747528076
Validation loss: 4.7805832624435425

Epoch: 6| Step: 3
Training loss: 5.017311096191406
Validation loss: 4.7742776075998945

Epoch: 6| Step: 4
Training loss: 4.893205642700195
Validation loss: 4.767598787943522

Epoch: 6| Step: 5
Training loss: 4.520895004272461
Validation loss: 4.761236190795898

Epoch: 6| Step: 6
Training loss: 4.132599830627441
Validation loss: 4.7551398277282715

Epoch: 6| Step: 7
Training loss: 4.546967506408691
Validation loss: 4.748995065689087

Epoch: 6| Step: 8
Training loss: 6.147034645080566
Validation loss: 4.742951075236003

Epoch: 6| Step: 9
Training loss: 5.326631546020508
Validation loss: 4.737187743186951

Epoch: 6| Step: 10
Training loss: 4.036564826965332
Validation loss: 4.73096760114034

Epoch: 6| Step: 11
Training loss: 5.027467250823975
Validation loss: 4.724899649620056

Epoch: 6| Step: 12
Training loss: 4.447382926940918
Validation loss: 4.718922297159831

Epoch: 6| Step: 13
Training loss: 5.385477066040039
Validation loss: 4.713041226069133

Epoch: 8| Step: 0
Training loss: 4.799698829650879
Validation loss: 4.707135597864787

Epoch: 6| Step: 1
Training loss: 5.366906642913818
Validation loss: 4.701081871986389

Epoch: 6| Step: 2
Training loss: 5.461921215057373
Validation loss: 4.695087790489197

Epoch: 6| Step: 3
Training loss: 4.264172554016113
Validation loss: 4.688978910446167

Epoch: 6| Step: 4
Training loss: 4.373453140258789
Validation loss: 4.682783206303914

Epoch: 6| Step: 5
Training loss: 3.796438217163086
Validation loss: 4.676807165145874

Epoch: 6| Step: 6
Training loss: 6.107807159423828
Validation loss: 4.670582135518392

Epoch: 6| Step: 7
Training loss: 5.068118095397949
Validation loss: 4.6643102169036865

Epoch: 6| Step: 8
Training loss: 4.971574783325195
Validation loss: 4.657750964164734

Epoch: 6| Step: 9
Training loss: 5.101049423217773
Validation loss: 4.65137521425883

Epoch: 6| Step: 10
Training loss: 3.592149257659912
Validation loss: 4.645026842753093

Epoch: 6| Step: 11
Training loss: 4.829689979553223
Validation loss: 4.638326207796733

Epoch: 6| Step: 12
Training loss: 4.388516426086426
Validation loss: 4.631985425949097

Epoch: 6| Step: 13
Training loss: 4.545830726623535
Validation loss: 4.625265002250671

Epoch: 9| Step: 0
Training loss: 5.179232597351074
Validation loss: 4.618308703104655

Epoch: 6| Step: 1
Training loss: 4.2596821784973145
Validation loss: 4.611426949501038

Epoch: 6| Step: 2
Training loss: 4.425437927246094
Validation loss: 4.604598641395569

Epoch: 6| Step: 3
Training loss: 4.870541572570801
Validation loss: 4.597819566726685

Epoch: 6| Step: 4
Training loss: 5.538969039916992
Validation loss: 4.59106691678365

Epoch: 6| Step: 5
Training loss: 5.196981430053711
Validation loss: 4.5845522085825605

Epoch: 6| Step: 6
Training loss: 4.881069183349609
Validation loss: 4.57755176226298

Epoch: 6| Step: 7
Training loss: 5.534916877746582
Validation loss: 4.570802132288615

Epoch: 6| Step: 8
Training loss: 4.132035255432129
Validation loss: 4.56339955329895

Epoch: 6| Step: 9
Training loss: 4.463018417358398
Validation loss: 4.556137879689534

Epoch: 6| Step: 10
Training loss: 4.616118907928467
Validation loss: 4.548432032267253

Epoch: 6| Step: 11
Training loss: 3.888888359069824
Validation loss: 4.539311488469441

Epoch: 6| Step: 12
Training loss: 3.931424617767334
Validation loss: 4.530591090520223

Epoch: 6| Step: 13
Training loss: 4.514487266540527
Validation loss: 4.523185571034749

Epoch: 10| Step: 0
Training loss: 5.590412139892578
Validation loss: 4.516114989916484

Epoch: 6| Step: 1
Training loss: 4.045383930206299
Validation loss: 4.509669383366902

Epoch: 6| Step: 2
Training loss: 3.673522710800171
Validation loss: 4.502315203348796

Epoch: 6| Step: 3
Training loss: 5.28037166595459
Validation loss: 4.495150446891785

Epoch: 6| Step: 4
Training loss: 4.215457439422607
Validation loss: 4.4883937040964765

Epoch: 6| Step: 5
Training loss: 5.131337642669678
Validation loss: 4.481027603149414

Epoch: 6| Step: 6
Training loss: 5.012427806854248
Validation loss: 4.474285523096721

Epoch: 6| Step: 7
Training loss: 5.303589820861816
Validation loss: 4.4668543338775635

Epoch: 6| Step: 8
Training loss: 5.384975433349609
Validation loss: 4.459972063700358

Epoch: 6| Step: 9
Training loss: 4.048041343688965
Validation loss: 4.452410856882731

Epoch: 6| Step: 10
Training loss: 4.296030044555664
Validation loss: 4.445520997047424

Epoch: 6| Step: 11
Training loss: 3.5743730068206787
Validation loss: 4.438384731610616

Epoch: 6| Step: 12
Training loss: 5.051535606384277
Validation loss: 4.4319238265355425

Epoch: 6| Step: 13
Training loss: 3.5187971591949463
Validation loss: 4.424865245819092

Epoch: 11| Step: 0
Training loss: 3.9174580574035645
Validation loss: 4.418441375096639

Epoch: 6| Step: 1
Training loss: 5.930615425109863
Validation loss: 4.411774555842082

Epoch: 6| Step: 2
Training loss: 4.454756736755371
Validation loss: 4.405087828636169

Epoch: 6| Step: 3
Training loss: 3.564470052719116
Validation loss: 4.399128675460815

Epoch: 6| Step: 4
Training loss: 4.86556339263916
Validation loss: 4.391980012257894

Epoch: 6| Step: 5
Training loss: 4.418672561645508
Validation loss: 4.385119358698527

Epoch: 6| Step: 6
Training loss: 4.450188636779785
Validation loss: 4.378306070963542

Epoch: 6| Step: 7
Training loss: 4.205321311950684
Validation loss: 4.370977958043416

Epoch: 6| Step: 8
Training loss: 4.869409084320068
Validation loss: 4.363097747166951

Epoch: 6| Step: 9
Training loss: 4.6374711990356445
Validation loss: 4.354687929153442

Epoch: 6| Step: 10
Training loss: 4.387078285217285
Validation loss: 4.345756570498149

Epoch: 6| Step: 11
Training loss: 3.902431011199951
Validation loss: 4.3372321128845215

Epoch: 6| Step: 12
Training loss: 4.906059265136719
Validation loss: 4.328507860501607

Epoch: 6| Step: 13
Training loss: 4.345905303955078
Validation loss: 4.319833715756734

Epoch: 12| Step: 0
Training loss: 3.270524501800537
Validation loss: 4.3109854857126875

Epoch: 6| Step: 1
Training loss: 5.196518898010254
Validation loss: 4.303317228953044

Epoch: 6| Step: 2
Training loss: 5.316504955291748
Validation loss: 4.294159015019734

Epoch: 6| Step: 3
Training loss: 4.004053592681885
Validation loss: 4.286192019780477

Epoch: 6| Step: 4
Training loss: 3.7738075256347656
Validation loss: 4.278254787127177

Epoch: 6| Step: 5
Training loss: 5.451607704162598
Validation loss: 4.269822319348653

Epoch: 6| Step: 6
Training loss: 3.9569973945617676
Validation loss: 4.26202929019928

Epoch: 6| Step: 7
Training loss: 5.366320610046387
Validation loss: 4.253827134768168

Epoch: 6| Step: 8
Training loss: 4.108481407165527
Validation loss: 4.245667854944865

Epoch: 6| Step: 9
Training loss: 4.336250305175781
Validation loss: 4.238297899564107

Epoch: 6| Step: 10
Training loss: 4.376120567321777
Validation loss: 4.22988490263621

Epoch: 6| Step: 11
Training loss: 4.4918975830078125
Validation loss: 4.222390969594319

Epoch: 6| Step: 12
Training loss: 3.6301515102386475
Validation loss: 4.2146782875061035

Epoch: 6| Step: 13
Training loss: 4.1344895362854
Validation loss: 4.207408547401428

Epoch: 13| Step: 0
Training loss: 4.691878318786621
Validation loss: 4.1997214158376055

Epoch: 6| Step: 1
Training loss: 4.383631706237793
Validation loss: 4.193136056264241

Epoch: 6| Step: 2
Training loss: 4.440947532653809
Validation loss: 4.184824506441752

Epoch: 6| Step: 3
Training loss: 4.053837776184082
Validation loss: 4.177765846252441

Epoch: 6| Step: 4
Training loss: 3.4580819606781006
Validation loss: 4.170056502024333

Epoch: 6| Step: 5
Training loss: 3.976491928100586
Validation loss: 4.163784543673198

Epoch: 6| Step: 6
Training loss: 3.710944652557373
Validation loss: 4.156687418619792

Epoch: 6| Step: 7
Training loss: 4.504805088043213
Validation loss: 4.149498740832011

Epoch: 6| Step: 8
Training loss: 4.571139335632324
Validation loss: 4.142524639765422

Epoch: 6| Step: 9
Training loss: 5.599634647369385
Validation loss: 4.136012117067973

Epoch: 6| Step: 10
Training loss: 3.512505531311035
Validation loss: 4.129364728927612

Epoch: 6| Step: 11
Training loss: 3.8762426376342773
Validation loss: 4.123574415842692

Epoch: 6| Step: 12
Training loss: 4.598210334777832
Validation loss: 4.116726318995158

Epoch: 6| Step: 13
Training loss: 4.69565486907959
Validation loss: 4.1115134954452515

Epoch: 14| Step: 0
Training loss: 3.220802068710327
Validation loss: 4.104469219843547

Epoch: 6| Step: 1
Training loss: 4.487826824188232
Validation loss: 4.097438971201579

Epoch: 6| Step: 2
Training loss: 4.20052433013916
Validation loss: 4.091511567433675

Epoch: 6| Step: 3
Training loss: 3.427564859390259
Validation loss: 4.084847728411357

Epoch: 6| Step: 4
Training loss: 4.234031677246094
Validation loss: 4.078847885131836

Epoch: 6| Step: 5
Training loss: 4.627562999725342
Validation loss: 4.073583006858826

Epoch: 6| Step: 6
Training loss: 5.3289008140563965
Validation loss: 4.067032217979431

Epoch: 6| Step: 7
Training loss: 3.8029534816741943
Validation loss: 4.060982942581177

Epoch: 6| Step: 8
Training loss: 4.104226589202881
Validation loss: 4.05456789334615

Epoch: 6| Step: 9
Training loss: 5.177070140838623
Validation loss: 4.04850709438324

Epoch: 6| Step: 10
Training loss: 4.637907028198242
Validation loss: 4.04191513856252

Epoch: 6| Step: 11
Training loss: 4.15421199798584
Validation loss: 4.035659193992615

Epoch: 6| Step: 12
Training loss: 4.395229339599609
Validation loss: 4.029545942942302

Epoch: 6| Step: 13
Training loss: 3.07663631439209
Validation loss: 4.023982445398967

Epoch: 15| Step: 0
Training loss: 3.0899715423583984
Validation loss: 4.017822265625

Epoch: 6| Step: 1
Training loss: 2.9312102794647217
Validation loss: 4.012623747189839

Epoch: 6| Step: 2
Training loss: 5.905884742736816
Validation loss: 4.0073758363723755

Epoch: 6| Step: 3
Training loss: 4.593804359436035
Validation loss: 4.00143579641978

Epoch: 6| Step: 4
Training loss: 3.7693991661071777
Validation loss: 3.9949113527933755

Epoch: 6| Step: 5
Training loss: 3.8664205074310303
Validation loss: 3.9896590312321982

Epoch: 6| Step: 6
Training loss: 3.993123769760132
Validation loss: 3.9834341208140054

Epoch: 6| Step: 7
Training loss: 3.5366642475128174
Validation loss: 3.9782467683156333

Epoch: 6| Step: 8
Training loss: 4.074220657348633
Validation loss: 3.9723755518595376

Epoch: 6| Step: 9
Training loss: 5.392963886260986
Validation loss: 3.9658856789271035

Epoch: 6| Step: 10
Training loss: 3.750851631164551
Validation loss: 3.9612854719161987

Epoch: 6| Step: 11
Training loss: 4.668422222137451
Validation loss: 3.9547610680262246

Epoch: 6| Step: 12
Training loss: 4.164050102233887
Validation loss: 3.949283758799235

Epoch: 6| Step: 13
Training loss: 4.009030342102051
Validation loss: 3.9445109764734902

Epoch: 16| Step: 0
Training loss: 4.297896385192871
Validation loss: 3.9392669598261514

Epoch: 6| Step: 1
Training loss: 3.9569802284240723
Validation loss: 3.9333858092625937

Epoch: 6| Step: 2
Training loss: 3.6648635864257812
Validation loss: 3.9283085664113364

Epoch: 6| Step: 3
Training loss: 5.171431064605713
Validation loss: 3.9222548802693686

Epoch: 6| Step: 4
Training loss: 3.1730451583862305
Validation loss: 3.916716376940409

Epoch: 6| Step: 5
Training loss: 3.0232887268066406
Validation loss: 3.9116317431131997

Epoch: 6| Step: 6
Training loss: 4.112692832946777
Validation loss: 3.9062863190968833

Epoch: 6| Step: 7
Training loss: 4.456204414367676
Validation loss: 3.9013459285100303

Epoch: 6| Step: 8
Training loss: 4.14305305480957
Validation loss: 3.896173079808553

Epoch: 6| Step: 9
Training loss: 4.489418029785156
Validation loss: 3.8913392225901284

Epoch: 6| Step: 10
Training loss: 4.4764790534973145
Validation loss: 3.885719815889994

Epoch: 6| Step: 11
Training loss: 3.3227922916412354
Validation loss: 3.881307363510132

Epoch: 6| Step: 12
Training loss: 3.861130952835083
Validation loss: 3.875856598218282

Epoch: 6| Step: 13
Training loss: 4.609807968139648
Validation loss: 3.8711266120274863

Epoch: 17| Step: 0
Training loss: 4.139995098114014
Validation loss: 3.8661500215530396

Epoch: 6| Step: 1
Training loss: 4.277315616607666
Validation loss: 3.861081083615621

Epoch: 6| Step: 2
Training loss: 4.015956878662109
Validation loss: 3.85641082127889

Epoch: 6| Step: 3
Training loss: 4.4704670906066895
Validation loss: 3.8516496419906616

Epoch: 6| Step: 4
Training loss: 4.312003135681152
Validation loss: 3.847081263860067

Epoch: 6| Step: 5
Training loss: 4.591557025909424
Validation loss: 3.8425674438476562

Epoch: 6| Step: 6
Training loss: 3.448338031768799
Validation loss: 3.837760408719381

Epoch: 6| Step: 7
Training loss: 4.6178669929504395
Validation loss: 3.832749327023824

Epoch: 6| Step: 8
Training loss: 3.7892422676086426
Validation loss: 3.8280264139175415

Epoch: 6| Step: 9
Training loss: 2.8843114376068115
Validation loss: 3.8227094411849976

Epoch: 6| Step: 10
Training loss: 4.5836992263793945
Validation loss: 3.8182931343714395

Epoch: 6| Step: 11
Training loss: 3.5889501571655273
Validation loss: 3.813736836115519

Epoch: 6| Step: 12
Training loss: 4.152647972106934
Validation loss: 3.8096358378728232

Epoch: 6| Step: 13
Training loss: 2.9933958053588867
Validation loss: 3.804712494214376

Epoch: 18| Step: 0
Training loss: 3.673525810241699
Validation loss: 3.8004388014475503

Epoch: 6| Step: 1
Training loss: 3.3193888664245605
Validation loss: 3.796464681625366

Epoch: 6| Step: 2
Training loss: 4.281055450439453
Validation loss: 3.7926085392634072

Epoch: 6| Step: 3
Training loss: 3.778092384338379
Validation loss: 3.7882421016693115

Epoch: 6| Step: 4
Training loss: 4.09561014175415
Validation loss: 3.7853615283966064

Epoch: 6| Step: 5
Training loss: 3.297499656677246
Validation loss: 3.7796106735865274

Epoch: 6| Step: 6
Training loss: 4.706315517425537
Validation loss: 3.7754677136739097

Epoch: 6| Step: 7
Training loss: 4.82247257232666
Validation loss: 3.7720731099446616

Epoch: 6| Step: 8
Training loss: 3.6568078994750977
Validation loss: 3.767993370691935

Epoch: 6| Step: 9
Training loss: 4.121818542480469
Validation loss: 3.762726068496704

Epoch: 6| Step: 10
Training loss: 3.636416435241699
Validation loss: 3.758635997772217

Epoch: 6| Step: 11
Training loss: 2.7867238521575928
Validation loss: 3.7541877826054892

Epoch: 6| Step: 12
Training loss: 4.3480072021484375
Validation loss: 3.749652067820231

Epoch: 6| Step: 13
Training loss: 4.492123603820801
Validation loss: 3.7451744874318442

Epoch: 19| Step: 0
Training loss: 3.444345235824585
Validation loss: 3.7409075101216636

Epoch: 6| Step: 1
Training loss: 4.642786026000977
Validation loss: 3.7368597189585366

Epoch: 6| Step: 2
Training loss: 4.1546807289123535
Validation loss: 3.73233954111735

Epoch: 6| Step: 3
Training loss: 3.8336033821105957
Validation loss: 3.727583328882853

Epoch: 6| Step: 4
Training loss: 3.261418342590332
Validation loss: 3.723901073137919

Epoch: 6| Step: 5
Training loss: 4.777069568634033
Validation loss: 3.719259023666382

Epoch: 6| Step: 6
Training loss: 3.0872998237609863
Validation loss: 3.7150894006093345

Epoch: 6| Step: 7
Training loss: 3.7095890045166016
Validation loss: 3.710889975229899

Epoch: 6| Step: 8
Training loss: 4.429300785064697
Validation loss: 3.7067925135294595

Epoch: 6| Step: 9
Training loss: 3.8498306274414062
Validation loss: 3.702260375022888

Epoch: 6| Step: 10
Training loss: 3.4677422046661377
Validation loss: 3.6978675524393716

Epoch: 6| Step: 11
Training loss: 3.1920833587646484
Validation loss: 3.6933306455612183

Epoch: 6| Step: 12
Training loss: 4.674217224121094
Validation loss: 3.6890315214792886

Epoch: 6| Step: 13
Training loss: 3.6955127716064453
Validation loss: 3.6845939556757608

Epoch: 20| Step: 0
Training loss: 3.2676382064819336
Validation loss: 3.6804331143697104

Epoch: 6| Step: 1
Training loss: 3.809372663497925
Validation loss: 3.67607581615448

Epoch: 6| Step: 2
Training loss: 3.6316592693328857
Validation loss: 3.671743909517924

Epoch: 6| Step: 3
Training loss: 4.4123334884643555
Validation loss: 3.6680557330449424

Epoch: 6| Step: 4
Training loss: 2.933580160140991
Validation loss: 3.6648857593536377

Epoch: 6| Step: 5
Training loss: 4.144721984863281
Validation loss: 3.6587368647257485

Epoch: 6| Step: 6
Training loss: 4.447536468505859
Validation loss: 3.65417750676473

Epoch: 6| Step: 7
Training loss: 3.0905580520629883
Validation loss: 3.6498772700627646

Epoch: 6| Step: 8
Training loss: 4.322879791259766
Validation loss: 3.64781661828359

Epoch: 6| Step: 9
Training loss: 3.648345947265625
Validation loss: 3.6412967443466187

Epoch: 6| Step: 10
Training loss: 3.8845999240875244
Validation loss: 3.6363773345947266

Epoch: 6| Step: 11
Training loss: 3.011605739593506
Validation loss: 3.6317479610443115

Epoch: 6| Step: 12
Training loss: 4.268833637237549
Validation loss: 3.6271095673243203

Epoch: 6| Step: 13
Training loss: 4.505499362945557
Validation loss: 3.6221263806025186

Epoch: 21| Step: 0
Training loss: 3.555760145187378
Validation loss: 3.617796301841736

Epoch: 6| Step: 1
Training loss: 4.173467636108398
Validation loss: 3.6132538318634033

Epoch: 6| Step: 2
Training loss: 3.817143440246582
Validation loss: 3.6085923512776694

Epoch: 6| Step: 3
Training loss: 3.7692158222198486
Validation loss: 3.603813091913859

Epoch: 6| Step: 4
Training loss: 4.023272514343262
Validation loss: 3.59871236483256

Epoch: 6| Step: 5
Training loss: 3.3203482627868652
Validation loss: 3.5939777294794717

Epoch: 6| Step: 6
Training loss: 3.9149086475372314
Validation loss: 3.588827649752299

Epoch: 6| Step: 7
Training loss: 3.1615514755249023
Validation loss: 3.584303696950277

Epoch: 6| Step: 8
Training loss: 4.263340473175049
Validation loss: 3.5805559555689492

Epoch: 6| Step: 9
Training loss: 3.4476022720336914
Validation loss: 3.578147212664286

Epoch: 6| Step: 10
Training loss: 3.353285789489746
Validation loss: 3.5796556075414023

Epoch: 6| Step: 11
Training loss: 3.939370632171631
Validation loss: 3.566324154535929

Epoch: 6| Step: 12
Training loss: 3.50807523727417
Validation loss: 3.5623955726623535

Epoch: 6| Step: 13
Training loss: 4.300435543060303
Validation loss: 3.5584880908330283

Epoch: 22| Step: 0
Training loss: 4.455752372741699
Validation loss: 3.5565892855326333

Epoch: 6| Step: 1
Training loss: 3.6456077098846436
Validation loss: 3.5510648488998413

Epoch: 6| Step: 2
Training loss: 3.8040759563446045
Validation loss: 3.5472338994344077

Epoch: 6| Step: 3
Training loss: 4.464027404785156
Validation loss: 3.5413910945256553

Epoch: 6| Step: 4
Training loss: 4.022334098815918
Validation loss: 3.5376076698303223

Epoch: 6| Step: 5
Training loss: 3.7733066082000732
Validation loss: 3.5326433579126992

Epoch: 6| Step: 6
Training loss: 3.938457489013672
Validation loss: 3.5275965531667075

Epoch: 6| Step: 7
Training loss: 3.0634679794311523
Validation loss: 3.523109237353007

Epoch: 6| Step: 8
Training loss: 3.6665658950805664
Validation loss: 3.518319924672445

Epoch: 6| Step: 9
Training loss: 2.951964855194092
Validation loss: 3.5140079259872437

Epoch: 6| Step: 10
Training loss: 3.2444005012512207
Validation loss: 3.5098662773768106

Epoch: 6| Step: 11
Training loss: 2.5770950317382812
Validation loss: 3.5048563877741494

Epoch: 6| Step: 12
Training loss: 4.009092330932617
Validation loss: 3.500090400377909

Epoch: 6| Step: 13
Training loss: 4.066645622253418
Validation loss: 3.49586550394694

Epoch: 23| Step: 0
Training loss: 3.8063626289367676
Validation loss: 3.4908642371495566

Epoch: 6| Step: 1
Training loss: 3.320340633392334
Validation loss: 3.4861964782079062

Epoch: 6| Step: 2
Training loss: 4.106076240539551
Validation loss: 3.481890559196472

Epoch: 6| Step: 3
Training loss: 3.5755980014801025
Validation loss: 3.4770572980244956

Epoch: 6| Step: 4
Training loss: 4.009343147277832
Validation loss: 3.472595731417338

Epoch: 6| Step: 5
Training loss: 3.654046058654785
Validation loss: 3.4677329063415527

Epoch: 6| Step: 6
Training loss: 3.2966551780700684
Validation loss: 3.463210145632426

Epoch: 6| Step: 7
Training loss: 3.8544836044311523
Validation loss: 3.458603620529175

Epoch: 6| Step: 8
Training loss: 3.758126735687256
Validation loss: 3.454033374786377

Epoch: 6| Step: 9
Training loss: 3.3047454357147217
Validation loss: 3.449023644129435

Epoch: 6| Step: 10
Training loss: 2.8312721252441406
Validation loss: 3.4449994564056396

Epoch: 6| Step: 11
Training loss: 3.283109664916992
Validation loss: 3.440807342529297

Epoch: 6| Step: 12
Training loss: 4.522446155548096
Validation loss: 3.4363417625427246

Epoch: 6| Step: 13
Training loss: 3.4726767539978027
Validation loss: 3.431591788927714

Epoch: 24| Step: 0
Training loss: 3.5678720474243164
Validation loss: 3.4273770650227866

Epoch: 6| Step: 1
Training loss: 3.5676839351654053
Validation loss: 3.42300013701121

Epoch: 6| Step: 2
Training loss: 3.5404248237609863
Validation loss: 3.4183938105901084

Epoch: 6| Step: 3
Training loss: 5.330923557281494
Validation loss: 3.4142726262410483

Epoch: 6| Step: 4
Training loss: 3.299344778060913
Validation loss: 3.409973661104838

Epoch: 6| Step: 5
Training loss: 3.343993663787842
Validation loss: 3.4053741693496704

Epoch: 6| Step: 6
Training loss: 3.0633206367492676
Validation loss: 3.400777896245321

Epoch: 6| Step: 7
Training loss: 2.6465909481048584
Validation loss: 3.3965240319569907

Epoch: 6| Step: 8
Training loss: 3.719390392303467
Validation loss: 3.3923683166503906

Epoch: 6| Step: 9
Training loss: 2.8300297260284424
Validation loss: 3.387895941734314

Epoch: 6| Step: 10
Training loss: 3.451633930206299
Validation loss: 3.3840620120366416

Epoch: 6| Step: 11
Training loss: 4.1482625007629395
Validation loss: 3.379806081453959

Epoch: 6| Step: 12
Training loss: 3.8517491817474365
Validation loss: 3.375693202018738

Epoch: 6| Step: 13
Training loss: 3.5776867866516113
Validation loss: 3.3710020780563354

Epoch: 25| Step: 0
Training loss: 2.878666877746582
Validation loss: 3.366840958595276

Epoch: 6| Step: 1
Training loss: 2.5587029457092285
Validation loss: 3.3623055617014566

Epoch: 6| Step: 2
Training loss: 3.4913573265075684
Validation loss: 3.3581254879633584

Epoch: 6| Step: 3
Training loss: 3.378732681274414
Validation loss: 3.3540309270222983

Epoch: 6| Step: 4
Training loss: 3.5978941917419434
Validation loss: 3.350119948387146

Epoch: 6| Step: 5
Training loss: 4.354738235473633
Validation loss: 3.346041202545166

Epoch: 6| Step: 6
Training loss: 4.652618885040283
Validation loss: 3.341821312904358

Epoch: 6| Step: 7
Training loss: 3.6435394287109375
Validation loss: 3.337493896484375

Epoch: 6| Step: 8
Training loss: 3.5336990356445312
Validation loss: 3.333539366722107

Epoch: 6| Step: 9
Training loss: 3.9091479778289795
Validation loss: 3.32893439133962

Epoch: 6| Step: 10
Training loss: 3.1047756671905518
Validation loss: 3.324733098347982

Epoch: 6| Step: 11
Training loss: 3.2612242698669434
Validation loss: 3.3203943173090615

Epoch: 6| Step: 12
Training loss: 3.617152214050293
Validation loss: 3.3157222668329873

Epoch: 6| Step: 13
Training loss: 3.1563069820404053
Validation loss: 3.3119391600290933

Epoch: 26| Step: 0
Training loss: 4.1786580085754395
Validation loss: 3.307693918546041

Epoch: 6| Step: 1
Training loss: 3.164663314819336
Validation loss: 3.3032390673955283

Epoch: 6| Step: 2
Training loss: 2.798151731491089
Validation loss: 3.298750122388204

Epoch: 6| Step: 3
Training loss: 2.8055551052093506
Validation loss: 3.294457991917928

Epoch: 6| Step: 4
Training loss: 3.0361862182617188
Validation loss: 3.290157993634542

Epoch: 6| Step: 5
Training loss: 3.464120388031006
Validation loss: 3.286351760228475

Epoch: 6| Step: 6
Training loss: 2.361003875732422
Validation loss: 3.2819637854894004

Epoch: 6| Step: 7
Training loss: 3.5543980598449707
Validation loss: 3.27824330329895

Epoch: 6| Step: 8
Training loss: 3.592587471008301
Validation loss: 3.274349013964335

Epoch: 6| Step: 9
Training loss: 4.660040378570557
Validation loss: 3.2705194552739463

Epoch: 6| Step: 10
Training loss: 3.4449868202209473
Validation loss: 3.2665117184321084

Epoch: 6| Step: 11
Training loss: 3.8459274768829346
Validation loss: 3.262477238972982

Epoch: 6| Step: 12
Training loss: 3.754256248474121
Validation loss: 3.258640925089518

Epoch: 6| Step: 13
Training loss: 3.7549352645874023
Validation loss: 3.254437526067098

Epoch: 27| Step: 0
Training loss: 4.138530254364014
Validation loss: 3.2505774100621543

Epoch: 6| Step: 1
Training loss: 3.2591605186462402
Validation loss: 3.2464479207992554

Epoch: 6| Step: 2
Training loss: 3.7418994903564453
Validation loss: 3.242550253868103

Epoch: 6| Step: 3
Training loss: 4.281007289886475
Validation loss: 3.2382260958353677

Epoch: 6| Step: 4
Training loss: 3.277454137802124
Validation loss: 3.2342135906219482

Epoch: 6| Step: 5
Training loss: 4.234772205352783
Validation loss: 3.2303355932235718

Epoch: 6| Step: 6
Training loss: 3.6720945835113525
Validation loss: 3.2261164585749307

Epoch: 6| Step: 7
Training loss: 3.5208592414855957
Validation loss: 3.221704284350077

Epoch: 6| Step: 8
Training loss: 2.837406873703003
Validation loss: 3.217711846033732

Epoch: 6| Step: 9
Training loss: 3.2240443229675293
Validation loss: 3.213649014631907

Epoch: 6| Step: 10
Training loss: 2.4632556438446045
Validation loss: 3.2097086906433105

Epoch: 6| Step: 11
Training loss: 3.1574907302856445
Validation loss: 3.2060341835021973

Epoch: 6| Step: 12
Training loss: 2.925940990447998
Validation loss: 3.202493190765381

Epoch: 6| Step: 13
Training loss: 2.9414584636688232
Validation loss: 3.198737382888794

Epoch: 28| Step: 0
Training loss: 3.753277540206909
Validation loss: 3.195001562436422

Epoch: 6| Step: 1
Training loss: 3.3749876022338867
Validation loss: 3.191209355990092

Epoch: 6| Step: 2
Training loss: 3.687453269958496
Validation loss: 3.187228520711263

Epoch: 6| Step: 3
Training loss: 2.761824607849121
Validation loss: 3.184036294619242

Epoch: 6| Step: 4
Training loss: 3.7079315185546875
Validation loss: 3.1796920696894326

Epoch: 6| Step: 5
Training loss: 3.34348201751709
Validation loss: 3.1765346924463906

Epoch: 6| Step: 6
Training loss: 3.350388526916504
Validation loss: 3.1713122526804605

Epoch: 6| Step: 7
Training loss: 3.483752727508545
Validation loss: 3.1676469246546426

Epoch: 6| Step: 8
Training loss: 2.7932448387145996
Validation loss: 3.1631033420562744

Epoch: 6| Step: 9
Training loss: 3.7513391971588135
Validation loss: 3.159100433190664

Epoch: 6| Step: 10
Training loss: 3.351818561553955
Validation loss: 3.1547704537709556

Epoch: 6| Step: 11
Training loss: 3.449331045150757
Validation loss: 3.15108315149943

Epoch: 6| Step: 12
Training loss: 3.313737392425537
Validation loss: 3.147231380144755

Epoch: 6| Step: 13
Training loss: 2.851985454559326
Validation loss: 3.1433066527048745

Epoch: 29| Step: 0
Training loss: 3.2771198749542236
Validation loss: 3.1414890686670938

Epoch: 6| Step: 1
Training loss: 3.5258705615997314
Validation loss: 3.139093518257141

Epoch: 6| Step: 2
Training loss: 2.767070770263672
Validation loss: 3.1323533058166504

Epoch: 6| Step: 3
Training loss: 2.6017420291900635
Validation loss: 3.128852287928263

Epoch: 6| Step: 4
Training loss: 3.1296608448028564
Validation loss: 3.127131700515747

Epoch: 6| Step: 5
Training loss: 2.5495834350585938
Validation loss: 3.1274704535802207

Epoch: 6| Step: 6
Training loss: 3.713926315307617
Validation loss: 3.1241056521733603

Epoch: 6| Step: 7
Training loss: 4.54298210144043
Validation loss: 3.118868350982666

Epoch: 6| Step: 8
Training loss: 3.7613468170166016
Validation loss: 3.113267660140991

Epoch: 6| Step: 9
Training loss: 4.264730453491211
Validation loss: 3.1080036560694375

Epoch: 6| Step: 10
Training loss: 3.2616610527038574
Validation loss: 3.103099266688029

Epoch: 6| Step: 11
Training loss: 2.611384868621826
Validation loss: 3.0991798639297485

Epoch: 6| Step: 12
Training loss: 2.7620089054107666
Validation loss: 3.095564683278402

Epoch: 6| Step: 13
Training loss: 3.5413360595703125
Validation loss: 3.0925838947296143

Epoch: 30| Step: 0
Training loss: 3.237968683242798
Validation loss: 3.08936075369517

Epoch: 6| Step: 1
Training loss: 3.3120317459106445
Validation loss: 3.086087425549825

Epoch: 6| Step: 2
Training loss: 3.768256187438965
Validation loss: 3.082726995150248

Epoch: 6| Step: 3
Training loss: 3.050698757171631
Validation loss: 3.0785117149353027

Epoch: 6| Step: 4
Training loss: 3.0123863220214844
Validation loss: 3.0747946898142495

Epoch: 6| Step: 5
Training loss: 3.208242416381836
Validation loss: 3.0722158749898276

Epoch: 6| Step: 6
Training loss: 3.376211643218994
Validation loss: 3.06818695863088

Epoch: 6| Step: 7
Training loss: 3.498760223388672
Validation loss: 3.0645938714345298

Epoch: 6| Step: 8
Training loss: 2.850677490234375
Validation loss: 3.0606550772984824

Epoch: 6| Step: 9
Training loss: 3.7234907150268555
Validation loss: 3.05700675646464

Epoch: 6| Step: 10
Training loss: 3.4038004875183105
Validation loss: 3.052943388621012

Epoch: 6| Step: 11
Training loss: 2.3218917846679688
Validation loss: 3.0486717224121094

Epoch: 6| Step: 12
Training loss: 3.5504472255706787
Validation loss: 3.044151167074839

Epoch: 6| Step: 13
Training loss: 3.2699246406555176
Validation loss: 3.041315714518229

Epoch: 31| Step: 0
Training loss: 2.478817939758301
Validation loss: 3.0381924311319985

Epoch: 6| Step: 1
Training loss: 2.867905378341675
Validation loss: 3.034321745236715

Epoch: 6| Step: 2
Training loss: 3.8118250370025635
Validation loss: 3.0311015446980796

Epoch: 6| Step: 3
Training loss: 3.6223011016845703
Validation loss: 3.02763831615448

Epoch: 6| Step: 4
Training loss: 3.4690606594085693
Validation loss: 3.0242127180099487

Epoch: 6| Step: 5
Training loss: 2.3820295333862305
Validation loss: 3.020651896794637

Epoch: 6| Step: 6
Training loss: 3.8050689697265625
Validation loss: 3.0178939501444497

Epoch: 6| Step: 7
Training loss: 3.4933791160583496
Validation loss: 3.013901670773824

Epoch: 6| Step: 8
Training loss: 3.314274787902832
Validation loss: 3.0098777214686074

Epoch: 6| Step: 9
Training loss: 3.299358367919922
Validation loss: 3.0063709020614624

Epoch: 6| Step: 10
Training loss: 3.058749198913574
Validation loss: 3.0032902161280313

Epoch: 6| Step: 11
Training loss: 3.243826389312744
Validation loss: 2.9992322524388633

Epoch: 6| Step: 12
Training loss: 2.429227828979492
Validation loss: 2.9957326650619507

Epoch: 6| Step: 13
Training loss: 3.630821704864502
Validation loss: 2.9932449658711753

Epoch: 32| Step: 0
Training loss: 3.2623867988586426
Validation loss: 3.0036678314208984

Epoch: 6| Step: 1
Training loss: 2.713451862335205
Validation loss: 2.9868197043736777

Epoch: 6| Step: 2
Training loss: 3.260223627090454
Validation loss: 2.984549363454183

Epoch: 6| Step: 3
Training loss: 2.9433538913726807
Validation loss: 2.981600006421407

Epoch: 6| Step: 4
Training loss: 2.6670236587524414
Validation loss: 2.9804234504699707

Epoch: 6| Step: 5
Training loss: 3.6748900413513184
Validation loss: 2.9776137272516885

Epoch: 6| Step: 6
Training loss: 3.5116496086120605
Validation loss: 2.976725975672404

Epoch: 6| Step: 7
Training loss: 2.9587154388427734
Validation loss: 2.971291979153951

Epoch: 6| Step: 8
Training loss: 2.9002513885498047
Validation loss: 2.9662099281946817

Epoch: 6| Step: 9
Training loss: 3.313178539276123
Validation loss: 2.9633023738861084

Epoch: 6| Step: 10
Training loss: 2.65220046043396
Validation loss: 2.9596978425979614

Epoch: 6| Step: 11
Training loss: 3.869314193725586
Validation loss: 2.9569890896479287

Epoch: 6| Step: 12
Training loss: 3.1084580421447754
Validation loss: 2.9542504151662192

Epoch: 6| Step: 13
Training loss: 3.499953269958496
Validation loss: 2.9504084984461465

Epoch: 33| Step: 0
Training loss: 4.008955001831055
Validation loss: 2.9472325245539346

Epoch: 6| Step: 1
Training loss: 2.706192970275879
Validation loss: 2.943303426106771

Epoch: 6| Step: 2
Training loss: 4.099636077880859
Validation loss: 2.939540425936381

Epoch: 6| Step: 3
Training loss: 3.3681836128234863
Validation loss: 2.9358037312825522

Epoch: 6| Step: 4
Training loss: 3.2174530029296875
Validation loss: 2.9317488272984824

Epoch: 6| Step: 5
Training loss: 2.923342227935791
Validation loss: 2.9280179341634116

Epoch: 6| Step: 6
Training loss: 3.3620755672454834
Validation loss: 2.9248082637786865

Epoch: 6| Step: 7
Training loss: 3.0686137676239014
Validation loss: 2.921000281969706

Epoch: 6| Step: 8
Training loss: 2.8303253650665283
Validation loss: 2.917171855767568

Epoch: 6| Step: 9
Training loss: 2.526881694793701
Validation loss: 2.914042115211487

Epoch: 6| Step: 10
Training loss: 2.396731376647949
Validation loss: 2.910441597302755

Epoch: 6| Step: 11
Training loss: 2.949867010116577
Validation loss: 2.9073598782221475

Epoch: 6| Step: 12
Training loss: 3.3861494064331055
Validation loss: 2.9040766954421997

Epoch: 6| Step: 13
Training loss: 2.940603256225586
Validation loss: 2.900939186414083

Epoch: 34| Step: 0
Training loss: 3.9368348121643066
Validation loss: 2.8978888193766275

Epoch: 6| Step: 1
Training loss: 2.443058490753174
Validation loss: 2.8946176767349243

Epoch: 6| Step: 2
Training loss: 3.1382267475128174
Validation loss: 2.891140580177307

Epoch: 6| Step: 3
Training loss: 3.3353240489959717
Validation loss: 2.8880873123804727

Epoch: 6| Step: 4
Training loss: 2.964301347732544
Validation loss: 2.884502112865448

Epoch: 6| Step: 5
Training loss: 3.1097283363342285
Validation loss: 2.8811111052831015

Epoch: 6| Step: 6
Training loss: 2.7017409801483154
Validation loss: 2.8777451713879905

Epoch: 6| Step: 7
Training loss: 3.2479543685913086
Validation loss: 2.8749003410339355

Epoch: 6| Step: 8
Training loss: 3.262739419937134
Validation loss: 2.8713043530782065

Epoch: 6| Step: 9
Training loss: 3.3500969409942627
Validation loss: 2.8684023221333823

Epoch: 6| Step: 10
Training loss: 2.736790180206299
Validation loss: 2.865834395090739

Epoch: 6| Step: 11
Training loss: 2.7552926540374756
Validation loss: 2.8628578186035156

Epoch: 6| Step: 12
Training loss: 3.013537883758545
Validation loss: 2.8608901103337607

Epoch: 6| Step: 13
Training loss: 3.2033934593200684
Validation loss: 2.857846220334371

Epoch: 35| Step: 0
Training loss: 2.807690143585205
Validation loss: 2.8543824752171836

Epoch: 6| Step: 1
Training loss: 3.273649215698242
Validation loss: 2.8512847423553467

Epoch: 6| Step: 2
Training loss: 2.8437657356262207
Validation loss: 2.8488982915878296

Epoch: 6| Step: 3
Training loss: 3.3282546997070312
Validation loss: 2.8472282886505127

Epoch: 6| Step: 4
Training loss: 3.143064022064209
Validation loss: 2.8435511191685996

Epoch: 6| Step: 5
Training loss: 2.806208610534668
Validation loss: 2.840296149253845

Epoch: 6| Step: 6
Training loss: 3.6678929328918457
Validation loss: 2.838057001431783

Epoch: 6| Step: 7
Training loss: 3.397627592086792
Validation loss: 2.8345736265182495

Epoch: 6| Step: 8
Training loss: 2.9400084018707275
Validation loss: 2.8317198355992637

Epoch: 6| Step: 9
Training loss: 2.7440202236175537
Validation loss: 2.8284400701522827

Epoch: 6| Step: 10
Training loss: 3.4952268600463867
Validation loss: 2.8244805335998535

Epoch: 6| Step: 11
Training loss: 2.5974576473236084
Validation loss: 2.8212399085362754

Epoch: 6| Step: 12
Training loss: 2.7057600021362305
Validation loss: 2.8178457419077554

Epoch: 6| Step: 13
Training loss: 2.8886983394622803
Validation loss: 2.8148429791132608

Epoch: 36| Step: 0
Training loss: 3.061561107635498
Validation loss: 2.8121526638666787

Epoch: 6| Step: 1
Training loss: 3.168041944503784
Validation loss: 2.809184948603312

Epoch: 6| Step: 2
Training loss: 3.3632593154907227
Validation loss: 2.806230147679647

Epoch: 6| Step: 3
Training loss: 2.739340305328369
Validation loss: 2.803507089614868

Epoch: 6| Step: 4
Training loss: 2.984060764312744
Validation loss: 2.800518055756887

Epoch: 6| Step: 5
Training loss: 3.5698838233947754
Validation loss: 2.797333081563314

Epoch: 6| Step: 6
Training loss: 1.8685710430145264
Validation loss: 2.794150710105896

Epoch: 6| Step: 7
Training loss: 3.038257122039795
Validation loss: 2.7914010286331177

Epoch: 6| Step: 8
Training loss: 2.664720296859741
Validation loss: 2.7886655728022256

Epoch: 6| Step: 9
Training loss: 3.2120957374572754
Validation loss: 2.7860912084579468

Epoch: 6| Step: 10
Training loss: 3.7784876823425293
Validation loss: 2.7840725978215537

Epoch: 6| Step: 11
Training loss: 2.8557281494140625
Validation loss: 2.781610449155172

Epoch: 6| Step: 12
Training loss: 3.1916263103485107
Validation loss: 2.7781585454940796

Epoch: 6| Step: 13
Training loss: 2.599642515182495
Validation loss: 2.7752728859583535

Epoch: 37| Step: 0
Training loss: 3.1507985591888428
Validation loss: 2.7713624636332193

Epoch: 6| Step: 1
Training loss: 2.930983543395996
Validation loss: 2.7685245275497437

Epoch: 6| Step: 2
Training loss: 2.7853870391845703
Validation loss: 2.7668232520421348

Epoch: 6| Step: 3
Training loss: 2.490081787109375
Validation loss: 2.763706843058268

Epoch: 6| Step: 4
Training loss: 2.4401960372924805
Validation loss: 2.761435031890869

Epoch: 6| Step: 5
Training loss: 2.9074604511260986
Validation loss: 2.7588114738464355

Epoch: 6| Step: 6
Training loss: 2.4017224311828613
Validation loss: 2.756516933441162

Epoch: 6| Step: 7
Training loss: 2.6867892742156982
Validation loss: 2.7527445952097573

Epoch: 6| Step: 8
Training loss: 3.4357151985168457
Validation loss: 2.751326600710551

Epoch: 6| Step: 9
Training loss: 3.174075126647949
Validation loss: 2.7484705050786338

Epoch: 6| Step: 10
Training loss: 3.146336793899536
Validation loss: 2.745895584424337

Epoch: 6| Step: 11
Training loss: 2.9873924255371094
Validation loss: 2.7435941298802695

Epoch: 6| Step: 12
Training loss: 3.0371341705322266
Validation loss: 2.739957094192505

Epoch: 6| Step: 13
Training loss: 3.9145312309265137
Validation loss: 2.737517992655436

Epoch: 38| Step: 0
Training loss: 2.839289665222168
Validation loss: 2.7345921198527017

Epoch: 6| Step: 1
Training loss: 2.920485496520996
Validation loss: 2.732348322868347

Epoch: 6| Step: 2
Training loss: 2.8671517372131348
Validation loss: 2.7307003339131675

Epoch: 6| Step: 3
Training loss: 3.118081569671631
Validation loss: 2.725913921991984

Epoch: 6| Step: 4
Training loss: 3.4464917182922363
Validation loss: 2.7244089444478354

Epoch: 6| Step: 5
Training loss: 2.7652747631073
Validation loss: 2.7217776775360107

Epoch: 6| Step: 6
Training loss: 3.1435914039611816
Validation loss: 2.7150058348973594

Epoch: 6| Step: 7
Training loss: 2.734786033630371
Validation loss: 2.712712367375692

Epoch: 6| Step: 8
Training loss: 2.453986167907715
Validation loss: 2.7105675538380942

Epoch: 6| Step: 9
Training loss: 3.2932074069976807
Validation loss: 2.7088661591211953

Epoch: 6| Step: 10
Training loss: 2.673281192779541
Validation loss: 2.706047852834066

Epoch: 6| Step: 11
Training loss: 2.673598289489746
Validation loss: 2.7045183579126992

Epoch: 6| Step: 12
Training loss: 2.736025810241699
Validation loss: 2.7018692096074424

Epoch: 6| Step: 13
Training loss: 3.252551317214966
Validation loss: 2.697424292564392

Epoch: 39| Step: 0
Training loss: 3.134127140045166
Validation loss: 2.7005364100138345

Epoch: 6| Step: 1
Training loss: 3.2818779945373535
Validation loss: 2.689949075380961

Epoch: 6| Step: 2
Training loss: 2.903445243835449
Validation loss: 2.688015023867289

Epoch: 6| Step: 3
Training loss: 2.3558077812194824
Validation loss: 2.6855995257695517

Epoch: 6| Step: 4
Training loss: 3.0321874618530273
Validation loss: 2.6831825176874795

Epoch: 6| Step: 5
Training loss: 2.992720127105713
Validation loss: 2.681189934412638

Epoch: 6| Step: 6
Training loss: 3.0174262523651123
Validation loss: 2.685808082421621

Epoch: 6| Step: 7
Training loss: 3.0668082237243652
Validation loss: 2.6803993384043374

Epoch: 6| Step: 8
Training loss: 2.357553243637085
Validation loss: 2.669865846633911

Epoch: 6| Step: 9
Training loss: 2.7165565490722656
Validation loss: 2.667748133341471

Epoch: 6| Step: 10
Training loss: 2.986367702484131
Validation loss: 2.664005676905314

Epoch: 6| Step: 11
Training loss: 3.8395867347717285
Validation loss: 2.661123792330424

Epoch: 6| Step: 12
Training loss: 2.2385053634643555
Validation loss: 2.6587279240290322

Epoch: 6| Step: 13
Training loss: 2.4937403202056885
Validation loss: 2.655973235766093

Epoch: 40| Step: 0
Training loss: 1.8842297792434692
Validation loss: 2.6546512444814048

Epoch: 6| Step: 1
Training loss: 2.865525007247925
Validation loss: 2.652419924736023

Epoch: 6| Step: 2
Training loss: 3.0553321838378906
Validation loss: 2.651397387186686

Epoch: 6| Step: 3
Training loss: 2.5072216987609863
Validation loss: 2.6511632998784385

Epoch: 6| Step: 4
Training loss: 2.8819198608398438
Validation loss: 2.646103779474894

Epoch: 6| Step: 5
Training loss: 2.6676316261291504
Validation loss: 2.6433284282684326

Epoch: 6| Step: 6
Training loss: 3.049123764038086
Validation loss: 2.6438555320103965

Epoch: 6| Step: 7
Training loss: 3.4412765502929688
Validation loss: 2.6417076587677

Epoch: 6| Step: 8
Training loss: 3.7251200675964355
Validation loss: 2.6359341144561768

Epoch: 6| Step: 9
Training loss: 3.1872520446777344
Validation loss: 2.6276034911473594

Epoch: 6| Step: 10
Training loss: 2.0891010761260986
Validation loss: 2.6239615281422934

Epoch: 6| Step: 11
Training loss: 2.8669610023498535
Validation loss: 2.621700922648112

Epoch: 6| Step: 12
Training loss: 3.015561580657959
Validation loss: 2.61822118361791

Epoch: 6| Step: 13
Training loss: 2.5350418090820312
Validation loss: 2.619483709335327

Epoch: 41| Step: 0
Training loss: 2.6264734268188477
Validation loss: 2.619100054105123

Epoch: 6| Step: 1
Training loss: 2.9531848430633545
Validation loss: 2.616321047147115

Epoch: 6| Step: 2
Training loss: 2.7516326904296875
Validation loss: 2.6139280796051025

Epoch: 6| Step: 3
Training loss: 2.993191957473755
Validation loss: 2.6117906967798867

Epoch: 6| Step: 4
Training loss: 2.6610779762268066
Validation loss: 2.606689969698588

Epoch: 6| Step: 5
Training loss: 2.7537078857421875
Validation loss: 2.603678603967031

Epoch: 6| Step: 6
Training loss: 2.6711912155151367
Validation loss: 2.599453647931417

Epoch: 6| Step: 7
Training loss: 2.977804183959961
Validation loss: 2.5969144701957703

Epoch: 6| Step: 8
Training loss: 2.580329656600952
Validation loss: 2.592648228009542

Epoch: 6| Step: 9
Training loss: 2.4678306579589844
Validation loss: 2.590065519014994

Epoch: 6| Step: 10
Training loss: 2.4959728717803955
Validation loss: 2.5859495600064597

Epoch: 6| Step: 11
Training loss: 3.516589641571045
Validation loss: 2.5825156768163047

Epoch: 6| Step: 12
Training loss: 2.6818389892578125
Validation loss: 2.577622652053833

Epoch: 6| Step: 13
Training loss: 3.124399185180664
Validation loss: 2.5751195549964905

Epoch: 42| Step: 0
Training loss: 2.5891246795654297
Validation loss: 2.5718042850494385

Epoch: 6| Step: 1
Training loss: 2.7477426528930664
Validation loss: 2.569808999697367

Epoch: 6| Step: 2
Training loss: 2.8162083625793457
Validation loss: 2.567548473676046

Epoch: 6| Step: 3
Training loss: 2.968944549560547
Validation loss: 2.565977414449056

Epoch: 6| Step: 4
Training loss: 2.421018123626709
Validation loss: 2.564688781897227

Epoch: 6| Step: 5
Training loss: 3.3628687858581543
Validation loss: 2.5605998833974204

Epoch: 6| Step: 6
Training loss: 2.0368902683258057
Validation loss: 2.5592755675315857

Epoch: 6| Step: 7
Training loss: 2.8972346782684326
Validation loss: 2.556943893432617

Epoch: 6| Step: 8
Training loss: 3.271129608154297
Validation loss: 2.554992437362671

Epoch: 6| Step: 9
Training loss: 2.4559831619262695
Validation loss: 2.553939461708069

Epoch: 6| Step: 10
Training loss: 2.584484100341797
Validation loss: 2.5463560422261557

Epoch: 6| Step: 11
Training loss: 2.68467378616333
Validation loss: 2.5472995042800903

Epoch: 6| Step: 12
Training loss: 3.057670831680298
Validation loss: 2.5451727708180747

Epoch: 6| Step: 13
Training loss: 2.7175731658935547
Validation loss: 2.539996782938639

Epoch: 43| Step: 0
Training loss: 2.813359498977661
Validation loss: 2.5383770068486533

Epoch: 6| Step: 1
Training loss: 3.0657808780670166
Validation loss: 2.534402092297872

Epoch: 6| Step: 2
Training loss: 2.766847610473633
Validation loss: 2.5322506030400596

Epoch: 6| Step: 3
Training loss: 2.759460926055908
Validation loss: 2.529832363128662

Epoch: 6| Step: 4
Training loss: 2.989431381225586
Validation loss: 2.528269330660502

Epoch: 6| Step: 5
Training loss: 3.420351505279541
Validation loss: 2.5250351826349893

Epoch: 6| Step: 6
Training loss: 2.826615810394287
Validation loss: 2.5227076609929404

Epoch: 6| Step: 7
Training loss: 3.1058807373046875
Validation loss: 2.5229018529256186

Epoch: 6| Step: 8
Training loss: 2.372239828109741
Validation loss: 2.51966921488444

Epoch: 6| Step: 9
Training loss: 2.1226859092712402
Validation loss: 2.5154582262039185

Epoch: 6| Step: 10
Training loss: 2.7367336750030518
Validation loss: 2.5122598012288413

Epoch: 6| Step: 11
Training loss: 2.2201452255249023
Validation loss: 2.508104920387268

Epoch: 6| Step: 12
Training loss: 2.423945903778076
Validation loss: 2.506424387296041

Epoch: 6| Step: 13
Training loss: 2.419891119003296
Validation loss: 2.501738429069519

Epoch: 44| Step: 0
Training loss: 2.606344223022461
Validation loss: 2.5014676253000894

Epoch: 6| Step: 1
Training loss: 2.869144916534424
Validation loss: 2.4977449973424277

Epoch: 6| Step: 2
Training loss: 2.171238422393799
Validation loss: 2.494246999422709

Epoch: 6| Step: 3
Training loss: 2.885056972503662
Validation loss: 2.492034991582235

Epoch: 6| Step: 4
Training loss: 3.411653757095337
Validation loss: 2.4901723066965737

Epoch: 6| Step: 5
Training loss: 2.1147193908691406
Validation loss: 2.4868540366490683

Epoch: 6| Step: 6
Training loss: 2.4043164253234863
Validation loss: 2.486363728841146

Epoch: 6| Step: 7
Training loss: 2.635185956954956
Validation loss: 2.4809894959131875

Epoch: 6| Step: 8
Training loss: 2.537552833557129
Validation loss: 2.478776216506958

Epoch: 6| Step: 9
Training loss: 2.9300012588500977
Validation loss: 2.477051575978597

Epoch: 6| Step: 10
Training loss: 3.011922836303711
Validation loss: 2.4787954489390054

Epoch: 6| Step: 11
Training loss: 2.295107841491699
Validation loss: 2.474432329336802

Epoch: 6| Step: 12
Training loss: 2.3127613067626953
Validation loss: 2.4693554639816284

Epoch: 6| Step: 13
Training loss: 3.317143440246582
Validation loss: 2.4680217703183494

Epoch: 45| Step: 0
Training loss: 2.864671468734741
Validation loss: 2.4668546517690024

Epoch: 6| Step: 1
Training loss: 2.2631521224975586
Validation loss: 2.4643587271372476

Epoch: 6| Step: 2
Training loss: 3.0700936317443848
Validation loss: 2.4645748933156333

Epoch: 6| Step: 3
Training loss: 2.2979190349578857
Validation loss: 2.457910696665446

Epoch: 6| Step: 4
Training loss: 2.557429790496826
Validation loss: 2.4703667958577475

Epoch: 6| Step: 5
Training loss: 2.8226191997528076
Validation loss: 2.461192468802134

Epoch: 6| Step: 6
Training loss: 2.696389675140381
Validation loss: 2.458513696988424

Epoch: 6| Step: 7
Training loss: 2.5047130584716797
Validation loss: 2.4622050523757935

Epoch: 6| Step: 8
Training loss: 2.3372714519500732
Validation loss: 2.4497424761454263

Epoch: 6| Step: 9
Training loss: 2.586855173110962
Validation loss: 2.441957473754883

Epoch: 6| Step: 10
Training loss: 2.0068576335906982
Validation loss: 2.441041191418966

Epoch: 6| Step: 11
Training loss: 3.2077133655548096
Validation loss: 2.436283270517985

Epoch: 6| Step: 12
Training loss: 3.012050151824951
Validation loss: 2.435259779294332

Epoch: 6| Step: 13
Training loss: 2.6778149604797363
Validation loss: 2.43436070283254

Epoch: 46| Step: 0
Training loss: 2.23482346534729
Validation loss: 2.4306416511535645

Epoch: 6| Step: 1
Training loss: 2.215674877166748
Validation loss: 2.4278722008069358

Epoch: 6| Step: 2
Training loss: 2.9410109519958496
Validation loss: 2.4257117907206216

Epoch: 6| Step: 3
Training loss: 2.050194025039673
Validation loss: 2.424365520477295

Epoch: 6| Step: 4
Training loss: 3.0796492099761963
Validation loss: 2.4206720193227134

Epoch: 6| Step: 5
Training loss: 2.5561282634735107
Validation loss: 2.416400591532389

Epoch: 6| Step: 6
Training loss: 2.576239585876465
Validation loss: 2.418159464995066

Epoch: 6| Step: 7
Training loss: 2.7018680572509766
Validation loss: 2.4161450068155923

Epoch: 6| Step: 8
Training loss: 2.8836655616760254
Validation loss: 2.411330779393514

Epoch: 6| Step: 9
Training loss: 2.407439947128296
Validation loss: 2.405211587746938

Epoch: 6| Step: 10
Training loss: 2.409576416015625
Validation loss: 2.402402917544047

Epoch: 6| Step: 11
Training loss: 3.197547197341919
Validation loss: 2.401558538277944

Epoch: 6| Step: 12
Training loss: 2.5381839275360107
Validation loss: 2.4004444678624473

Epoch: 6| Step: 13
Training loss: 2.651717185974121
Validation loss: 2.3973851203918457

Epoch: 47| Step: 0
Training loss: 2.730567455291748
Validation loss: 2.3941920598347983

Epoch: 6| Step: 1
Training loss: 2.9782724380493164
Validation loss: 2.3900992472966514

Epoch: 6| Step: 2
Training loss: 2.3763914108276367
Validation loss: 2.390097975730896

Epoch: 6| Step: 3
Training loss: 2.43485689163208
Validation loss: 2.389596621195475

Epoch: 6| Step: 4
Training loss: 2.3730967044830322
Validation loss: 2.39000674088796

Epoch: 6| Step: 5
Training loss: 2.767374038696289
Validation loss: 2.3898980617523193

Epoch: 6| Step: 6
Training loss: 2.7717628479003906
Validation loss: 2.389683643976847

Epoch: 6| Step: 7
Training loss: 2.375986099243164
Validation loss: 2.396124005317688

Epoch: 6| Step: 8
Training loss: 2.8276729583740234
Validation loss: 2.387055973211924

Epoch: 6| Step: 9
Training loss: 2.1388261318206787
Validation loss: 2.3812957604726157

Epoch: 6| Step: 10
Training loss: 2.3441662788391113
Validation loss: 2.3720770279566445

Epoch: 6| Step: 11
Training loss: 2.616879463195801
Validation loss: 2.3701281944910684

Epoch: 6| Step: 12
Training loss: 2.679152488708496
Validation loss: 2.3686607281366983

Epoch: 6| Step: 13
Training loss: 2.44716739654541
Validation loss: 2.367241144180298

Epoch: 48| Step: 0
Training loss: 1.9804288148880005
Validation loss: 2.3640180428822837

Epoch: 6| Step: 1
Training loss: 3.1022682189941406
Validation loss: 2.3614987333615622

Epoch: 6| Step: 2
Training loss: 2.7837562561035156
Validation loss: 2.360885977745056

Epoch: 6| Step: 3
Training loss: 3.354466676712036
Validation loss: 2.3549840847651162

Epoch: 6| Step: 4
Training loss: 2.4694690704345703
Validation loss: 2.3543593883514404

Epoch: 6| Step: 5
Training loss: 2.5322327613830566
Validation loss: 2.3515661160151162

Epoch: 6| Step: 6
Training loss: 2.7028117179870605
Validation loss: 2.348269999027252

Epoch: 6| Step: 7
Training loss: 1.6878407001495361
Validation loss: 2.3470969200134277

Epoch: 6| Step: 8
Training loss: 3.0936477184295654
Validation loss: 2.3431302309036255

Epoch: 6| Step: 9
Training loss: 2.6283090114593506
Validation loss: 2.338556627432505

Epoch: 6| Step: 10
Training loss: 2.627262592315674
Validation loss: 2.3445176680882773

Epoch: 6| Step: 11
Training loss: 2.0208675861358643
Validation loss: 2.341395914554596

Epoch: 6| Step: 12
Training loss: 1.931235432624817
Validation loss: 2.3371774355570474

Epoch: 6| Step: 13
Training loss: 2.415985584259033
Validation loss: 2.3335378170013428

Epoch: 49| Step: 0
Training loss: 2.142913818359375
Validation loss: 2.333932856718699

Epoch: 6| Step: 1
Training loss: 2.736905813217163
Validation loss: 2.3270554542541504

Epoch: 6| Step: 2
Training loss: 3.207132577896118
Validation loss: 2.3319464723269143

Epoch: 6| Step: 3
Training loss: 2.2738122940063477
Validation loss: 2.3323851823806763

Epoch: 6| Step: 4
Training loss: 2.1364669799804688
Validation loss: 2.3340654770533242

Epoch: 6| Step: 5
Training loss: 2.589841842651367
Validation loss: 2.3327758510907493

Epoch: 6| Step: 6
Training loss: 2.661098003387451
Validation loss: 2.3328551252683005

Epoch: 6| Step: 7
Training loss: 2.2527658939361572
Validation loss: 2.325359563032786

Epoch: 6| Step: 8
Training loss: 2.2624764442443848
Validation loss: 2.3255536556243896

Epoch: 6| Step: 9
Training loss: 3.235280990600586
Validation loss: 2.318039576212565

Epoch: 6| Step: 10
Training loss: 2.524509906768799
Validation loss: 2.3119327823321023

Epoch: 6| Step: 11
Training loss: 2.708362102508545
Validation loss: 2.305222670237223

Epoch: 6| Step: 12
Training loss: 2.140460252761841
Validation loss: 2.3039376735687256

Epoch: 6| Step: 13
Training loss: 2.024289846420288
Validation loss: 2.3019272883733115

Epoch: 50| Step: 0
Training loss: 2.837496280670166
Validation loss: 2.299194097518921

Epoch: 6| Step: 1
Training loss: 2.062999725341797
Validation loss: 2.296088218688965

Epoch: 6| Step: 2
Training loss: 1.9642471075057983
Validation loss: 2.2939294576644897

Epoch: 6| Step: 3
Training loss: 2.4821300506591797
Validation loss: 2.294239362080892

Epoch: 6| Step: 4
Training loss: 2.517064094543457
Validation loss: 2.288115978240967

Epoch: 6| Step: 5
Training loss: 2.750770330429077
Validation loss: 2.284345785776774

Epoch: 6| Step: 6
Training loss: 2.5597262382507324
Validation loss: 2.2817407846450806

Epoch: 6| Step: 7
Training loss: 2.5054681301116943
Validation loss: 2.284113049507141

Epoch: 6| Step: 8
Training loss: 2.247330665588379
Validation loss: 2.2751014828681946

Epoch: 6| Step: 9
Training loss: 2.8528528213500977
Validation loss: 2.279967466990153

Epoch: 6| Step: 10
Training loss: 1.8878169059753418
Validation loss: 2.274606982866923

Epoch: 6| Step: 11
Training loss: 2.216525077819824
Validation loss: 2.2733724117279053

Epoch: 6| Step: 12
Training loss: 2.856276035308838
Validation loss: 2.2693788607915244

Epoch: 6| Step: 13
Training loss: 2.407461166381836
Validation loss: 2.2740655541419983

Epoch: 51| Step: 0
Training loss: 2.291243314743042
Validation loss: 2.2746797800064087

Epoch: 6| Step: 1
Training loss: 1.9500099420547485
Validation loss: 2.26584662993749

Epoch: 6| Step: 2
Training loss: 2.7527408599853516
Validation loss: 2.2660834391911826

Epoch: 6| Step: 3
Training loss: 2.8313727378845215
Validation loss: 2.2598594029744468

Epoch: 6| Step: 4
Training loss: 2.194477081298828
Validation loss: 2.2556382616360984

Epoch: 6| Step: 5
Training loss: 2.388446569442749
Validation loss: 2.253104567527771

Epoch: 6| Step: 6
Training loss: 2.3320508003234863
Validation loss: 2.2515110969543457

Epoch: 6| Step: 7
Training loss: 2.3559257984161377
Validation loss: 2.2499775290489197

Epoch: 6| Step: 8
Training loss: 2.538182258605957
Validation loss: 2.2467915217081704

Epoch: 6| Step: 9
Training loss: 2.642441749572754
Validation loss: 2.246448556582133

Epoch: 6| Step: 10
Training loss: 2.3645381927490234
Validation loss: 2.242375155289968

Epoch: 6| Step: 11
Training loss: 2.771063804626465
Validation loss: 2.2414998412132263

Epoch: 6| Step: 12
Training loss: 2.2000083923339844
Validation loss: 2.240683356920878

Epoch: 6| Step: 13
Training loss: 2.077415943145752
Validation loss: 2.2343693574269614

Epoch: 52| Step: 0
Training loss: 2.353808879852295
Validation loss: 2.235677699247996

Epoch: 6| Step: 1
Training loss: 2.5228450298309326
Validation loss: 2.229158083597819

Epoch: 6| Step: 2
Training loss: 2.417357921600342
Validation loss: 2.2289884289105735

Epoch: 6| Step: 3
Training loss: 2.5044748783111572
Validation loss: 2.2218812505404153

Epoch: 6| Step: 4
Training loss: 2.544994354248047
Validation loss: 2.220822294553121

Epoch: 6| Step: 5
Training loss: 2.3633227348327637
Validation loss: 2.218892196814219

Epoch: 6| Step: 6
Training loss: 2.6060643196105957
Validation loss: 2.2165187199910483

Epoch: 6| Step: 7
Training loss: 2.2843611240386963
Validation loss: 2.2178293466567993

Epoch: 6| Step: 8
Training loss: 2.655634880065918
Validation loss: 2.217540184656779

Epoch: 6| Step: 9
Training loss: 1.7647594213485718
Validation loss: 2.20993040005366

Epoch: 6| Step: 10
Training loss: 2.209421157836914
Validation loss: 2.219022512435913

Epoch: 6| Step: 11
Training loss: 2.5724587440490723
Validation loss: 2.214652339617411

Epoch: 6| Step: 12
Training loss: 2.24771785736084
Validation loss: 2.2178263664245605

Epoch: 6| Step: 13
Training loss: 2.2171154022216797
Validation loss: 2.213022609551748

Epoch: 53| Step: 0
Training loss: 1.6712169647216797
Validation loss: 2.2157989939053855

Epoch: 6| Step: 1
Training loss: 2.6477160453796387
Validation loss: 2.2090806563695273

Epoch: 6| Step: 2
Training loss: 1.510420560836792
Validation loss: 2.2083531419436135

Epoch: 6| Step: 3
Training loss: 2.62367844581604
Validation loss: 2.203906297683716

Epoch: 6| Step: 4
Training loss: 1.962753415107727
Validation loss: 2.203996419906616

Epoch: 6| Step: 5
Training loss: 2.570141077041626
Validation loss: 2.2040767470995584

Epoch: 6| Step: 6
Training loss: 2.3487911224365234
Validation loss: 2.202522933483124

Epoch: 6| Step: 7
Training loss: 2.9183998107910156
Validation loss: 2.2004439433415732

Epoch: 6| Step: 8
Training loss: 2.2276711463928223
Validation loss: 2.1961938540140786

Epoch: 6| Step: 9
Training loss: 2.1318514347076416
Validation loss: 2.1931419372558594

Epoch: 6| Step: 10
Training loss: 2.640373706817627
Validation loss: 2.1858792702356973

Epoch: 6| Step: 11
Training loss: 1.8740079402923584
Validation loss: 2.1868282755215964

Epoch: 6| Step: 12
Training loss: 3.225005626678467
Validation loss: 2.179693102836609

Epoch: 6| Step: 13
Training loss: 2.4227824211120605
Validation loss: 2.1789201895395913

Epoch: 54| Step: 0
Training loss: 2.5126113891601562
Validation loss: 2.19011922677358

Epoch: 6| Step: 1
Training loss: 2.69796085357666
Validation loss: 2.1958653926849365

Epoch: 6| Step: 2
Training loss: 2.2737536430358887
Validation loss: 2.2002450227737427

Epoch: 6| Step: 3
Training loss: 2.091909885406494
Validation loss: 2.1991398533185325

Epoch: 6| Step: 4
Training loss: 2.2495615482330322
Validation loss: 2.199498732884725

Epoch: 6| Step: 5
Training loss: 2.328707695007324
Validation loss: 2.196582019329071

Epoch: 6| Step: 6
Training loss: 2.5752880573272705
Validation loss: 2.182283798853556

Epoch: 6| Step: 7
Training loss: 2.490292549133301
Validation loss: 2.1673512061436973

Epoch: 6| Step: 8
Training loss: 2.452249526977539
Validation loss: 2.16680254538854

Epoch: 6| Step: 9
Training loss: 2.564056873321533
Validation loss: 2.174334188302358

Epoch: 6| Step: 10
Training loss: 2.162127733230591
Validation loss: 2.175545950730642

Epoch: 6| Step: 11
Training loss: 1.9607274532318115
Validation loss: 2.1796213388442993

Epoch: 6| Step: 12
Training loss: 1.9909098148345947
Validation loss: 2.18515545129776

Epoch: 6| Step: 13
Training loss: 2.3163931369781494
Validation loss: 2.189684569835663

Epoch: 55| Step: 0
Training loss: 2.308568000793457
Validation loss: 2.2038756012916565

Epoch: 6| Step: 1
Training loss: 2.4156851768493652
Validation loss: 2.2118274172147117

Epoch: 6| Step: 2
Training loss: 2.096930980682373
Validation loss: 2.210760792096456

Epoch: 6| Step: 3
Training loss: 1.7596981525421143
Validation loss: 2.189729611078898

Epoch: 6| Step: 4
Training loss: 1.8521108627319336
Validation loss: 2.175698141256968

Epoch: 6| Step: 5
Training loss: 2.249749183654785
Validation loss: 2.171785354614258

Epoch: 6| Step: 6
Training loss: 2.7576544284820557
Validation loss: 2.1614116430282593

Epoch: 6| Step: 7
Training loss: 2.230191707611084
Validation loss: 2.153411646684011

Epoch: 6| Step: 8
Training loss: 2.7528774738311768
Validation loss: 2.150166312853495

Epoch: 6| Step: 9
Training loss: 2.6698355674743652
Validation loss: 2.14785764614741

Epoch: 6| Step: 10
Training loss: 2.5440144538879395
Validation loss: 2.147097369035085

Epoch: 6| Step: 11
Training loss: 2.189863681793213
Validation loss: 2.14093287785848

Epoch: 6| Step: 12
Training loss: 2.395134449005127
Validation loss: 2.1416128476460776

Epoch: 6| Step: 13
Training loss: 2.447242259979248
Validation loss: 2.140972057978312

Epoch: 56| Step: 0
Training loss: 2.014864921569824
Validation loss: 2.1372469464937844

Epoch: 6| Step: 1
Training loss: 2.099281072616577
Validation loss: 2.1351552406946817

Epoch: 6| Step: 2
Training loss: 2.6221566200256348
Validation loss: 2.139023542404175

Epoch: 6| Step: 3
Training loss: 2.7654762268066406
Validation loss: 2.1349915663401284

Epoch: 6| Step: 4
Training loss: 2.664581775665283
Validation loss: 2.143618166446686

Epoch: 6| Step: 5
Training loss: 1.68759286403656
Validation loss: 2.1324446201324463

Epoch: 6| Step: 6
Training loss: 2.2292468547821045
Validation loss: 2.133332908153534

Epoch: 6| Step: 7
Training loss: 2.2316224575042725
Validation loss: 2.1325761874516806

Epoch: 6| Step: 8
Training loss: 2.4489870071411133
Validation loss: 2.125609815120697

Epoch: 6| Step: 9
Training loss: 2.075504779815674
Validation loss: 2.1248435576756797

Epoch: 6| Step: 10
Training loss: 2.3987655639648438
Validation loss: 2.127482771873474

Epoch: 6| Step: 11
Training loss: 2.7136645317077637
Validation loss: 2.128573715686798

Epoch: 6| Step: 12
Training loss: 2.0260050296783447
Validation loss: 2.1318353613217673

Epoch: 6| Step: 13
Training loss: 2.0491199493408203
Validation loss: 2.128608306248983

Epoch: 57| Step: 0
Training loss: 2.227431297302246
Validation loss: 2.1289986968040466

Epoch: 6| Step: 1
Training loss: 2.0662593841552734
Validation loss: 2.129843294620514

Epoch: 6| Step: 2
Training loss: 2.491913080215454
Validation loss: 2.1283369263013205

Epoch: 6| Step: 3
Training loss: 1.7332838773727417
Validation loss: 2.133013347784678

Epoch: 6| Step: 4
Training loss: 2.183932065963745
Validation loss: 2.121254245440165

Epoch: 6| Step: 5
Training loss: 1.8968887329101562
Validation loss: 2.124316851298014

Epoch: 6| Step: 6
Training loss: 2.9371743202209473
Validation loss: 2.115843633810679

Epoch: 6| Step: 7
Training loss: 1.961525797843933
Validation loss: 2.1122003396352134

Epoch: 6| Step: 8
Training loss: 2.784801721572876
Validation loss: 2.1141503850618997

Epoch: 6| Step: 9
Training loss: 1.946121335029602
Validation loss: 2.107256293296814

Epoch: 6| Step: 10
Training loss: 2.645111083984375
Validation loss: 2.1071566144625344

Epoch: 6| Step: 11
Training loss: 2.025761127471924
Validation loss: 2.113141576449076

Epoch: 6| Step: 12
Training loss: 2.9923064708709717
Validation loss: 2.1063863237698874

Epoch: 6| Step: 13
Training loss: 1.967603325843811
Validation loss: 2.1113351583480835

Epoch: 58| Step: 0
Training loss: 2.0279271602630615
Validation loss: 2.11550243695577

Epoch: 6| Step: 1
Training loss: 2.4692087173461914
Validation loss: 2.123141566912333

Epoch: 6| Step: 2
Training loss: 2.155381679534912
Validation loss: 2.123641769091288

Epoch: 6| Step: 3
Training loss: 2.0197455883026123
Validation loss: 2.1104195515314736

Epoch: 6| Step: 4
Training loss: 2.169720411300659
Validation loss: 2.107851028442383

Epoch: 6| Step: 5
Training loss: 2.9738974571228027
Validation loss: 2.0997327764829

Epoch: 6| Step: 6
Training loss: 2.1665449142456055
Validation loss: 2.1088109016418457

Epoch: 6| Step: 7
Training loss: 1.727459192276001
Validation loss: 2.1065396865208945

Epoch: 6| Step: 8
Training loss: 2.0506863594055176
Validation loss: 2.108453392982483

Epoch: 6| Step: 9
Training loss: 2.659754991531372
Validation loss: 2.10525651772817

Epoch: 6| Step: 10
Training loss: 2.2834584712982178
Validation loss: 2.1068957845369973

Epoch: 6| Step: 11
Training loss: 2.246272087097168
Validation loss: 2.1054594914118447

Epoch: 6| Step: 12
Training loss: 2.2949788570404053
Validation loss: 2.1019198894500732

Epoch: 6| Step: 13
Training loss: 2.5846962928771973
Validation loss: 2.0942304730415344

Epoch: 59| Step: 0
Training loss: 2.3786468505859375
Validation loss: 2.0942645271619162

Epoch: 6| Step: 1
Training loss: 2.23819637298584
Validation loss: 2.093274195988973

Epoch: 6| Step: 2
Training loss: 1.7861320972442627
Validation loss: 2.094301621119181

Epoch: 6| Step: 3
Training loss: 2.3182196617126465
Validation loss: 2.10108745098114

Epoch: 6| Step: 4
Training loss: 2.563425064086914
Validation loss: 2.0999679366747537

Epoch: 6| Step: 5
Training loss: 2.052048444747925
Validation loss: 2.0917885104815164

Epoch: 6| Step: 6
Training loss: 2.3630893230438232
Validation loss: 2.095148205757141

Epoch: 6| Step: 7
Training loss: 2.748983860015869
Validation loss: 2.0942776997884116

Epoch: 6| Step: 8
Training loss: 2.850006580352783
Validation loss: 2.0908122261365256

Epoch: 6| Step: 9
Training loss: 1.8470640182495117
Validation loss: 2.095825990041097

Epoch: 6| Step: 10
Training loss: 2.0999226570129395
Validation loss: 2.095131516456604

Epoch: 6| Step: 11
Training loss: 2.6433887481689453
Validation loss: 2.0915449261665344

Epoch: 6| Step: 12
Training loss: 1.4963419437408447
Validation loss: 2.0915737748146057

Epoch: 6| Step: 13
Training loss: 2.0220911502838135
Validation loss: 2.1188918948173523

Epoch: 60| Step: 0
Training loss: 1.976398229598999
Validation loss: 2.1162409583727517

Epoch: 6| Step: 1
Training loss: 2.4545578956604004
Validation loss: 2.1188841660817466

Epoch: 6| Step: 2
Training loss: 2.636216163635254
Validation loss: 2.1103675166765847

Epoch: 6| Step: 3
Training loss: 1.723296880722046
Validation loss: 2.0875171025594077

Epoch: 6| Step: 4
Training loss: 2.3673219680786133
Validation loss: 2.0756568113962808

Epoch: 6| Step: 5
Training loss: 1.6513817310333252
Validation loss: 2.070827583471934

Epoch: 6| Step: 6
Training loss: 2.5308022499084473
Validation loss: 2.0698217948277793

Epoch: 6| Step: 7
Training loss: 1.9152882099151611
Validation loss: 2.067914386590322

Epoch: 6| Step: 8
Training loss: 2.751173496246338
Validation loss: 2.0742611289024353

Epoch: 6| Step: 9
Training loss: 2.1553220748901367
Validation loss: 2.0731402238210044

Epoch: 6| Step: 10
Training loss: 1.8206762075424194
Validation loss: 2.0794478058815002

Epoch: 6| Step: 11
Training loss: 2.7769694328308105
Validation loss: 2.0730440815289817

Epoch: 6| Step: 12
Training loss: 1.8019750118255615
Validation loss: 2.072410543759664

Epoch: 6| Step: 13
Training loss: 2.7495336532592773
Validation loss: 2.0850236415863037

Epoch: 61| Step: 0
Training loss: 2.174367904663086
Validation loss: 2.0809284448623657

Epoch: 6| Step: 1
Training loss: 1.632612943649292
Validation loss: 2.0881436467170715

Epoch: 6| Step: 2
Training loss: 2.2434444427490234
Validation loss: 2.0691489775975547

Epoch: 6| Step: 3
Training loss: 2.393397331237793
Validation loss: 2.067776342233022

Epoch: 6| Step: 4
Training loss: 1.9884909391403198
Validation loss: 2.064391831556956

Epoch: 6| Step: 5
Training loss: 2.0412099361419678
Validation loss: 2.0602049231529236

Epoch: 6| Step: 6
Training loss: 1.860269546508789
Validation loss: 2.0723631978034973

Epoch: 6| Step: 7
Training loss: 2.4640097618103027
Validation loss: 2.076112667719523

Epoch: 6| Step: 8
Training loss: 2.772900104522705
Validation loss: 2.0688358346621194

Epoch: 6| Step: 9
Training loss: 1.9868295192718506
Validation loss: 2.070899029572805

Epoch: 6| Step: 10
Training loss: 2.4640026092529297
Validation loss: 2.0734076499938965

Epoch: 6| Step: 11
Training loss: 2.39080810546875
Validation loss: 2.0829325318336487

Epoch: 6| Step: 12
Training loss: 2.5595903396606445
Validation loss: 2.066063622633616

Epoch: 6| Step: 13
Training loss: 2.3155343532562256
Validation loss: 2.059766332308451

Epoch: 62| Step: 0
Training loss: 1.4900860786437988
Validation loss: 2.0571892857551575

Epoch: 6| Step: 1
Training loss: 2.463808059692383
Validation loss: 2.053192973136902

Epoch: 6| Step: 2
Training loss: 3.025865077972412
Validation loss: 2.0544594128926597

Epoch: 6| Step: 3
Training loss: 2.174083709716797
Validation loss: 2.0567065477371216

Epoch: 6| Step: 4
Training loss: 1.7849185466766357
Validation loss: 2.0637116034825644

Epoch: 6| Step: 5
Training loss: 1.9321764707565308
Validation loss: 2.066746552785238

Epoch: 6| Step: 6
Training loss: 1.7268867492675781
Validation loss: 2.065977474053701

Epoch: 6| Step: 7
Training loss: 2.208885908126831
Validation loss: 2.069048285484314

Epoch: 6| Step: 8
Training loss: 2.199888229370117
Validation loss: 2.0673962434132895

Epoch: 6| Step: 9
Training loss: 2.96195650100708
Validation loss: 2.066469351450602

Epoch: 6| Step: 10
Training loss: 2.1922717094421387
Validation loss: 2.0646132230758667

Epoch: 6| Step: 11
Training loss: 2.4690141677856445
Validation loss: 2.0613362391789756

Epoch: 6| Step: 12
Training loss: 2.2559242248535156
Validation loss: 2.0629712343215942

Epoch: 6| Step: 13
Training loss: 2.347921848297119
Validation loss: 2.0668463706970215

Epoch: 63| Step: 0
Training loss: 2.4355854988098145
Validation loss: 2.0584672689437866

Epoch: 6| Step: 1
Training loss: 2.958223819732666
Validation loss: 2.054633458455404

Epoch: 6| Step: 2
Training loss: 2.009504795074463
Validation loss: 2.049952268600464

Epoch: 6| Step: 3
Training loss: 1.6684823036193848
Validation loss: 2.049389402071635

Epoch: 6| Step: 4
Training loss: 1.9679991006851196
Validation loss: 2.0462881127993264

Epoch: 6| Step: 5
Training loss: 2.451629877090454
Validation loss: 2.0468158523241677

Epoch: 6| Step: 6
Training loss: 2.180717706680298
Validation loss: 2.044506629308065

Epoch: 6| Step: 7
Training loss: 1.6821331977844238
Validation loss: 2.046016494433085

Epoch: 6| Step: 8
Training loss: 2.06195068359375
Validation loss: 2.04783962170283

Epoch: 6| Step: 9
Training loss: 2.1605656147003174
Validation loss: 2.0482375224431357

Epoch: 6| Step: 10
Training loss: 2.6053359508514404
Validation loss: 2.0467557509740195

Epoch: 6| Step: 11
Training loss: 2.1062309741973877
Validation loss: 2.0415035088857016

Epoch: 6| Step: 12
Training loss: 2.369595527648926
Validation loss: 2.047730545202891

Epoch: 6| Step: 13
Training loss: 2.405522108078003
Validation loss: 2.0452433625857034

Epoch: 64| Step: 0
Training loss: 2.592616319656372
Validation loss: 2.060504158337911

Epoch: 6| Step: 1
Training loss: 2.1581950187683105
Validation loss: 2.0647300680478415

Epoch: 6| Step: 2
Training loss: 2.4191997051239014
Validation loss: 2.0744933485984802

Epoch: 6| Step: 3
Training loss: 2.5945885181427
Validation loss: 2.0925879081090293

Epoch: 6| Step: 4
Training loss: 1.5579965114593506
Validation loss: 2.0771450996398926

Epoch: 6| Step: 5
Training loss: 2.770533800125122
Validation loss: 2.0842612981796265

Epoch: 6| Step: 6
Training loss: 1.7904869318008423
Validation loss: 2.068334380785624

Epoch: 6| Step: 7
Training loss: 2.797945022583008
Validation loss: 2.0660579403241477

Epoch: 6| Step: 8
Training loss: 1.7765769958496094
Validation loss: 2.0480266412099204

Epoch: 6| Step: 9
Training loss: 2.2292847633361816
Validation loss: 2.039370059967041

Epoch: 6| Step: 10
Training loss: 2.163203239440918
Validation loss: 2.0356295506159463

Epoch: 6| Step: 11
Training loss: 1.6254141330718994
Validation loss: 2.0363296071688333

Epoch: 6| Step: 12
Training loss: 2.132359504699707
Validation loss: 2.0382389227549234

Epoch: 6| Step: 13
Training loss: 2.227098226547241
Validation loss: 2.0466776887575784

Epoch: 65| Step: 0
Training loss: 1.6141993999481201
Validation loss: 2.0469971100489297

Epoch: 6| Step: 1
Training loss: 2.4478163719177246
Validation loss: 2.0463095704714456

Epoch: 6| Step: 2
Training loss: 2.3297128677368164
Validation loss: 2.0444010297457376

Epoch: 6| Step: 3
Training loss: 2.326206684112549
Validation loss: 2.041636308034261

Epoch: 6| Step: 4
Training loss: 2.613985061645508
Validation loss: 2.0412379105885825

Epoch: 6| Step: 5
Training loss: 2.3429765701293945
Validation loss: 2.0429704785346985

Epoch: 6| Step: 6
Training loss: 2.685305595397949
Validation loss: 2.0271684328715005

Epoch: 6| Step: 7
Training loss: 2.131709575653076
Validation loss: 2.031607687473297

Epoch: 6| Step: 8
Training loss: 2.409315586090088
Validation loss: 2.0279622872670493

Epoch: 6| Step: 9
Training loss: 1.4437726736068726
Validation loss: 2.0315361420313516

Epoch: 6| Step: 10
Training loss: 2.255614757537842
Validation loss: 2.0503451824188232

Epoch: 6| Step: 11
Training loss: 2.168607473373413
Validation loss: 2.0669177571932473

Epoch: 6| Step: 12
Training loss: 2.436105251312256
Validation loss: 2.077362676461538

Epoch: 6| Step: 13
Training loss: 1.9218230247497559
Validation loss: 2.0656061371167502

Epoch: 66| Step: 0
Training loss: 2.656456708908081
Validation loss: 2.063262144724528

Epoch: 6| Step: 1
Training loss: 2.608954668045044
Validation loss: 2.0594906012217202

Epoch: 6| Step: 2
Training loss: 2.0517778396606445
Validation loss: 2.0575605233510337

Epoch: 6| Step: 3
Training loss: 2.529876947402954
Validation loss: 2.049421727657318

Epoch: 6| Step: 4
Training loss: 2.317154884338379
Validation loss: 2.038420021533966

Epoch: 6| Step: 5
Training loss: 2.1523218154907227
Validation loss: 2.026618500550588

Epoch: 6| Step: 6
Training loss: 2.258976459503174
Validation loss: 2.028241515159607

Epoch: 6| Step: 7
Training loss: 1.9930109977722168
Validation loss: 2.0327711502710977

Epoch: 6| Step: 8
Training loss: 2.417119264602661
Validation loss: 2.034871757030487

Epoch: 6| Step: 9
Training loss: 2.0976572036743164
Validation loss: 2.0241228342056274

Epoch: 6| Step: 10
Training loss: 1.4530746936798096
Validation loss: 2.027193009853363

Epoch: 6| Step: 11
Training loss: 2.277094841003418
Validation loss: 2.0376727978388467

Epoch: 6| Step: 12
Training loss: 1.7848681211471558
Validation loss: 2.0370690623919168

Epoch: 6| Step: 13
Training loss: 2.2188382148742676
Validation loss: 2.031392256418864

Epoch: 67| Step: 0
Training loss: 1.531300663948059
Validation loss: 2.0317628979682922

Epoch: 6| Step: 1
Training loss: 2.3952059745788574
Validation loss: 2.028829514980316

Epoch: 6| Step: 2
Training loss: 2.1516525745391846
Validation loss: 2.035080830256144

Epoch: 6| Step: 3
Training loss: 2.472850799560547
Validation loss: 2.0391109387079873

Epoch: 6| Step: 4
Training loss: 2.420254707336426
Validation loss: 2.035502096017202

Epoch: 6| Step: 5
Training loss: 1.9997525215148926
Validation loss: 2.030371983846029

Epoch: 6| Step: 6
Training loss: 2.374087333679199
Validation loss: 2.0297104914983115

Epoch: 6| Step: 7
Training loss: 2.714315891265869
Validation loss: 2.043931305408478

Epoch: 6| Step: 8
Training loss: 2.3677010536193848
Validation loss: 2.0353379050890603

Epoch: 6| Step: 9
Training loss: 1.7784315347671509
Validation loss: 2.0294752518335977

Epoch: 6| Step: 10
Training loss: 2.002257823944092
Validation loss: 2.033678869406382

Epoch: 6| Step: 11
Training loss: 2.273815631866455
Validation loss: 2.0344396233558655

Epoch: 6| Step: 12
Training loss: 1.8636813163757324
Validation loss: 2.0465426445007324

Epoch: 6| Step: 13
Training loss: 2.379384994506836
Validation loss: 2.0434574087460837

Epoch: 68| Step: 0
Training loss: 2.413574695587158
Validation loss: 2.0447636246681213

Epoch: 6| Step: 1
Training loss: 2.2155489921569824
Validation loss: 2.0409006079037986

Epoch: 6| Step: 2
Training loss: 2.628148317337036
Validation loss: 2.0306948026021323

Epoch: 6| Step: 3
Training loss: 2.219722270965576
Validation loss: 2.0303995013237

Epoch: 6| Step: 4
Training loss: 2.3155417442321777
Validation loss: 2.026067614555359

Epoch: 6| Step: 5
Training loss: 1.8563849925994873
Validation loss: 2.0283159414927163

Epoch: 6| Step: 6
Training loss: 2.0959770679473877
Validation loss: 2.0313724676767984

Epoch: 6| Step: 7
Training loss: 2.1470706462860107
Validation loss: 2.0335840582847595

Epoch: 6| Step: 8
Training loss: 2.1834897994995117
Validation loss: 2.0280354420344033

Epoch: 6| Step: 9
Training loss: 1.7427358627319336
Validation loss: 2.0357733368873596

Epoch: 6| Step: 10
Training loss: 1.9906747341156006
Validation loss: 2.0226827263832092

Epoch: 6| Step: 11
Training loss: 2.025298595428467
Validation loss: 2.024320820967356

Epoch: 6| Step: 12
Training loss: 2.2472453117370605
Validation loss: 2.030395030975342

Epoch: 6| Step: 13
Training loss: 2.6216254234313965
Validation loss: 2.0238311688105264

Epoch: 69| Step: 0
Training loss: 2.859957695007324
Validation loss: 2.0499770045280457

Epoch: 6| Step: 1
Training loss: 2.4027559757232666
Validation loss: 2.0596446990966797

Epoch: 6| Step: 2
Training loss: 1.9038949012756348
Validation loss: 2.069294810295105

Epoch: 6| Step: 3
Training loss: 2.392331838607788
Validation loss: 2.0685469706853232

Epoch: 6| Step: 4
Training loss: 1.916885495185852
Validation loss: 2.0617969036102295

Epoch: 6| Step: 5
Training loss: 2.3617513179779053
Validation loss: 2.0485235850016275

Epoch: 6| Step: 6
Training loss: 1.482058048248291
Validation loss: 2.0539638002713523

Epoch: 6| Step: 7
Training loss: 1.9335682392120361
Validation loss: 2.050955653190613

Epoch: 6| Step: 8
Training loss: 2.7670607566833496
Validation loss: 2.0515756209691367

Epoch: 6| Step: 9
Training loss: 2.015470266342163
Validation loss: 2.0338226159413657

Epoch: 6| Step: 10
Training loss: 2.4776954650878906
Validation loss: 2.0471882820129395

Epoch: 6| Step: 11
Training loss: 1.2955849170684814
Validation loss: 2.0455783804257712

Epoch: 6| Step: 12
Training loss: 2.7849202156066895
Validation loss: 2.0327011744181314

Epoch: 6| Step: 13
Training loss: 1.877866506576538
Validation loss: 2.032072683175405

Epoch: 70| Step: 0
Training loss: 1.9906359910964966
Validation loss: 2.0334797501564026

Epoch: 6| Step: 1
Training loss: 2.302025318145752
Validation loss: 2.0376757184664407

Epoch: 6| Step: 2
Training loss: 2.381730556488037
Validation loss: 2.031972348690033

Epoch: 6| Step: 3
Training loss: 2.309262275695801
Validation loss: 2.023115654786428

Epoch: 6| Step: 4
Training loss: 1.830143928527832
Validation loss: 2.0335019628206887

Epoch: 6| Step: 5
Training loss: 2.9787917137145996
Validation loss: 2.0266405741373696

Epoch: 6| Step: 6
Training loss: 1.3723210096359253
Validation loss: 2.029306789239248

Epoch: 6| Step: 7
Training loss: 1.4932831525802612
Validation loss: 2.0229855378468833

Epoch: 6| Step: 8
Training loss: 2.8793678283691406
Validation loss: 2.0200690229733786

Epoch: 6| Step: 9
Training loss: 1.8055102825164795
Validation loss: 2.0263362725575766

Epoch: 6| Step: 10
Training loss: 2.593717575073242
Validation loss: 2.032183587551117

Epoch: 6| Step: 11
Training loss: 2.2778072357177734
Validation loss: 2.0410813689231873

Epoch: 6| Step: 12
Training loss: 2.5695228576660156
Validation loss: 2.052694340546926

Epoch: 6| Step: 13
Training loss: 1.7201671600341797
Validation loss: 2.054901917775472

Epoch: 71| Step: 0
Training loss: 2.3466744422912598
Validation loss: 2.060526708761851

Epoch: 6| Step: 1
Training loss: 2.4701571464538574
Validation loss: 2.039500375588735

Epoch: 6| Step: 2
Training loss: 2.1560821533203125
Validation loss: 2.038932502269745

Epoch: 6| Step: 3
Training loss: 2.7183051109313965
Validation loss: 2.029523015022278

Epoch: 6| Step: 4
Training loss: 2.008424758911133
Validation loss: 2.0197639067967734

Epoch: 6| Step: 5
Training loss: 2.8060998916625977
Validation loss: 2.027979532877604

Epoch: 6| Step: 6
Training loss: 2.367664337158203
Validation loss: 2.028984288374583

Epoch: 6| Step: 7
Training loss: 2.0552515983581543
Validation loss: 2.0323836406071982

Epoch: 6| Step: 8
Training loss: 1.6783605813980103
Validation loss: 2.0272770126660666

Epoch: 6| Step: 9
Training loss: 1.9543274641036987
Validation loss: 2.022256096204122

Epoch: 6| Step: 10
Training loss: 1.9952564239501953
Validation loss: 2.0252268513043723

Epoch: 6| Step: 11
Training loss: 1.1825510263442993
Validation loss: 2.0247772932052612

Epoch: 6| Step: 12
Training loss: 2.3866934776306152
Validation loss: 2.0285455783208213

Epoch: 6| Step: 13
Training loss: 2.3769288063049316
Validation loss: 2.040011942386627

Epoch: 72| Step: 0
Training loss: 1.9468152523040771
Validation loss: 2.0727904240290322

Epoch: 6| Step: 1
Training loss: 2.1935672760009766
Validation loss: 2.0797557830810547

Epoch: 6| Step: 2
Training loss: 1.932334542274475
Validation loss: 2.0754967530568442

Epoch: 6| Step: 3
Training loss: 1.8350989818572998
Validation loss: 2.075327972571055

Epoch: 6| Step: 4
Training loss: 2.1355671882629395
Validation loss: 2.066618581612905

Epoch: 6| Step: 5
Training loss: 2.5946085453033447
Validation loss: 2.0584786335627236

Epoch: 6| Step: 6
Training loss: 2.2754361629486084
Validation loss: 2.034894645214081

Epoch: 6| Step: 7
Training loss: 1.9577621221542358
Validation loss: 2.0278469920158386

Epoch: 6| Step: 8
Training loss: 1.9781503677368164
Validation loss: 2.0248000820477805

Epoch: 6| Step: 9
Training loss: 2.025714874267578
Validation loss: 2.0312520464261374

Epoch: 6| Step: 10
Training loss: 2.011359691619873
Validation loss: 2.0184637904167175

Epoch: 6| Step: 11
Training loss: 2.331955671310425
Validation loss: 2.0202398697535195

Epoch: 6| Step: 12
Training loss: 2.309838056564331
Validation loss: 2.017120083173116

Epoch: 6| Step: 13
Training loss: 2.845487117767334
Validation loss: 2.013128399848938

Epoch: 73| Step: 0
Training loss: 2.1851508617401123
Validation loss: 2.0151138305664062

Epoch: 6| Step: 1
Training loss: 1.8028035163879395
Validation loss: 2.0118829011917114

Epoch: 6| Step: 2
Training loss: 1.765341877937317
Validation loss: 2.0176706314086914

Epoch: 6| Step: 3
Training loss: 2.1328139305114746
Validation loss: 2.0224124987920127

Epoch: 6| Step: 4
Training loss: 2.79984450340271
Validation loss: 2.0276800990104675

Epoch: 6| Step: 5
Training loss: 2.076373338699341
Validation loss: 2.0417877038319907

Epoch: 6| Step: 6
Training loss: 2.081418991088867
Validation loss: 2.038499196370443

Epoch: 6| Step: 7
Training loss: 2.3239071369171143
Validation loss: 2.052130937576294

Epoch: 6| Step: 8
Training loss: 2.797673225402832
Validation loss: 2.0507630109786987

Epoch: 6| Step: 9
Training loss: 2.091214179992676
Validation loss: 2.0533353885014853

Epoch: 6| Step: 10
Training loss: 2.4314284324645996
Validation loss: 2.0554418365160623

Epoch: 6| Step: 11
Training loss: 1.3491899967193604
Validation loss: 2.045408288637797

Epoch: 6| Step: 12
Training loss: 2.2506766319274902
Validation loss: 2.036316990852356

Epoch: 6| Step: 13
Training loss: 2.3265976905822754
Validation loss: 2.027189791202545

Epoch: 74| Step: 0
Training loss: 1.86165452003479
Validation loss: 2.021403511365255

Epoch: 6| Step: 1
Training loss: 2.051086902618408
Validation loss: 2.026259660720825

Epoch: 6| Step: 2
Training loss: 2.500399112701416
Validation loss: 2.0278095602989197

Epoch: 6| Step: 3
Training loss: 2.3601150512695312
Validation loss: 2.0249018470446267

Epoch: 6| Step: 4
Training loss: 2.1435742378234863
Validation loss: 2.0438499252001443

Epoch: 6| Step: 5
Training loss: 2.6736679077148438
Validation loss: 2.045606851577759

Epoch: 6| Step: 6
Training loss: 2.417835235595703
Validation loss: 2.0468215942382812

Epoch: 6| Step: 7
Training loss: 2.4561331272125244
Validation loss: 2.0401167074839273

Epoch: 6| Step: 8
Training loss: 1.6555042266845703
Validation loss: 2.056612471739451

Epoch: 6| Step: 9
Training loss: 1.8992990255355835
Validation loss: 2.054399251937866

Epoch: 6| Step: 10
Training loss: 2.127516031265259
Validation loss: 2.050484359264374

Epoch: 6| Step: 11
Training loss: 2.3434863090515137
Validation loss: 2.0557817220687866

Epoch: 6| Step: 12
Training loss: 1.5813876390457153
Validation loss: 2.045917590459188

Epoch: 6| Step: 13
Training loss: 2.1859774589538574
Validation loss: 2.0424106319745383

Epoch: 75| Step: 0
Training loss: 1.9593404531478882
Validation loss: 2.0456320444742837

Epoch: 6| Step: 1
Training loss: 2.230614423751831
Validation loss: 2.044571121533712

Epoch: 6| Step: 2
Training loss: 2.381411075592041
Validation loss: 2.051085631052653

Epoch: 6| Step: 3
Training loss: 2.0589792728424072
Validation loss: 2.0452895561854043

Epoch: 6| Step: 4
Training loss: 2.1729164123535156
Validation loss: 2.0332361261049905

Epoch: 6| Step: 5
Training loss: 2.1303186416625977
Validation loss: 2.028473138809204

Epoch: 6| Step: 6
Training loss: 1.7843217849731445
Validation loss: 2.025572876135508

Epoch: 6| Step: 7
Training loss: 3.007193088531494
Validation loss: 2.0278256138165793

Epoch: 6| Step: 8
Training loss: 1.6412291526794434
Validation loss: 2.031668206055959

Epoch: 6| Step: 9
Training loss: 2.4438118934631348
Validation loss: 2.0229932069778442

Epoch: 6| Step: 10
Training loss: 2.1509628295898438
Validation loss: 2.024967849254608

Epoch: 6| Step: 11
Training loss: 2.1386399269104004
Validation loss: 2.020500202973684

Epoch: 6| Step: 12
Training loss: 1.9062538146972656
Validation loss: 2.0120227138201394

Epoch: 6| Step: 13
Training loss: 2.2280282974243164
Validation loss: 2.020574629306793

Epoch: 76| Step: 0
Training loss: 1.7336697578430176
Validation loss: 2.0202192862828574

Epoch: 6| Step: 1
Training loss: 2.1832449436187744
Validation loss: 2.0212474266688027

Epoch: 6| Step: 2
Training loss: 2.046077013015747
Validation loss: 2.030379911263784

Epoch: 6| Step: 3
Training loss: 1.9929518699645996
Validation loss: 2.04636812210083

Epoch: 6| Step: 4
Training loss: 2.2539384365081787
Validation loss: 2.056188444296519

Epoch: 6| Step: 5
Training loss: 2.2667083740234375
Validation loss: 2.059800942738851

Epoch: 6| Step: 6
Training loss: 2.173187494277954
Validation loss: 2.0682321786880493

Epoch: 6| Step: 7
Training loss: 1.9094736576080322
Validation loss: 2.082229812939962

Epoch: 6| Step: 8
Training loss: 2.6481077671051025
Validation loss: 2.0860327084859214

Epoch: 6| Step: 9
Training loss: 2.2986903190612793
Validation loss: 2.0775941610336304

Epoch: 6| Step: 10
Training loss: 2.779548406600952
Validation loss: 2.082338194052378

Epoch: 6| Step: 11
Training loss: 1.8027163743972778
Validation loss: 2.0705465277036033

Epoch: 6| Step: 12
Training loss: 2.3106560707092285
Validation loss: 2.0659332076708474

Epoch: 6| Step: 13
Training loss: 2.1964752674102783
Validation loss: 2.0568297704060874

Epoch: 77| Step: 0
Training loss: 1.7660245895385742
Validation loss: 2.047072112560272

Epoch: 6| Step: 1
Training loss: 2.444709062576294
Validation loss: 2.036719004313151

Epoch: 6| Step: 2
Training loss: 1.8834038972854614
Validation loss: 2.0234237710634866

Epoch: 6| Step: 3
Training loss: 2.0209691524505615
Validation loss: 2.0177959402402244

Epoch: 6| Step: 4
Training loss: 2.551023006439209
Validation loss: 2.005521754423777

Epoch: 6| Step: 5
Training loss: 2.1321001052856445
Validation loss: 2.0124770998954773

Epoch: 6| Step: 6
Training loss: 2.0433173179626465
Validation loss: 2.0043764313062034

Epoch: 6| Step: 7
Training loss: 1.8515087366104126
Validation loss: 2.006821115811666

Epoch: 6| Step: 8
Training loss: 2.355905055999756
Validation loss: 2.008412798245748

Epoch: 6| Step: 9
Training loss: 1.8953372240066528
Validation loss: 2.007848540941874

Epoch: 6| Step: 10
Training loss: 2.0284264087677
Validation loss: 2.010342836380005

Epoch: 6| Step: 11
Training loss: 1.9610806703567505
Validation loss: 2.0176694790522256

Epoch: 6| Step: 12
Training loss: 2.749694585800171
Validation loss: 2.0155449708302817

Epoch: 6| Step: 13
Training loss: 2.643754720687866
Validation loss: 2.0185107390085855

Epoch: 78| Step: 0
Training loss: 2.4379780292510986
Validation loss: 2.0197452505429587

Epoch: 6| Step: 1
Training loss: 2.240064859390259
Validation loss: 2.02206822236379

Epoch: 6| Step: 2
Training loss: 1.9042434692382812
Validation loss: 2.0203075806299844

Epoch: 6| Step: 3
Training loss: 2.4704604148864746
Validation loss: 2.0211017727851868

Epoch: 6| Step: 4
Training loss: 1.7883919477462769
Validation loss: 2.0229572852452598

Epoch: 6| Step: 5
Training loss: 2.4583702087402344
Validation loss: 2.0166871349016824

Epoch: 6| Step: 6
Training loss: 1.729783296585083
Validation loss: 2.014272451400757

Epoch: 6| Step: 7
Training loss: 1.9474655389785767
Validation loss: 2.020316561063131

Epoch: 6| Step: 8
Training loss: 2.721348524093628
Validation loss: 2.025290588537852

Epoch: 6| Step: 9
Training loss: 2.1371655464172363
Validation loss: 2.031502584616343

Epoch: 6| Step: 10
Training loss: 2.1231095790863037
Validation loss: 2.0263694127400718

Epoch: 6| Step: 11
Training loss: 1.6635239124298096
Validation loss: 2.0369430979092917

Epoch: 6| Step: 12
Training loss: 2.023702621459961
Validation loss: 2.041150152683258

Epoch: 6| Step: 13
Training loss: 2.378553867340088
Validation loss: 2.0301353534062705

Epoch: 79| Step: 0
Training loss: 2.1538448333740234
Validation loss: 2.0323934157689414

Epoch: 6| Step: 1
Training loss: 2.0625410079956055
Validation loss: 2.0288724303245544

Epoch: 6| Step: 2
Training loss: 2.1370046138763428
Validation loss: 2.009191950162252

Epoch: 6| Step: 3
Training loss: 2.5647287368774414
Validation loss: 2.016311446825663

Epoch: 6| Step: 4
Training loss: 2.2821409702301025
Validation loss: 2.019651770591736

Epoch: 6| Step: 5
Training loss: 2.249570846557617
Validation loss: 2.012986699740092

Epoch: 6| Step: 6
Training loss: 1.9635498523712158
Validation loss: 2.0201778014500937

Epoch: 6| Step: 7
Training loss: 2.0809860229492188
Validation loss: 2.0337245066960654

Epoch: 6| Step: 8
Training loss: 1.886191964149475
Validation loss: 2.0360288619995117

Epoch: 6| Step: 9
Training loss: 1.3938120603561401
Validation loss: 2.045871694882711

Epoch: 6| Step: 10
Training loss: 2.3380112648010254
Validation loss: 2.0461881955464682

Epoch: 6| Step: 11
Training loss: 2.363858938217163
Validation loss: 2.033240795135498

Epoch: 6| Step: 12
Training loss: 2.3160905838012695
Validation loss: 2.0398108959198

Epoch: 6| Step: 13
Training loss: 2.1325697898864746
Validation loss: 2.0394312540690103

Epoch: 80| Step: 0
Training loss: 1.283571481704712
Validation loss: 2.0399492184321084

Epoch: 6| Step: 1
Training loss: 2.0968222618103027
Validation loss: 2.0430328249931335

Epoch: 6| Step: 2
Training loss: 2.208617687225342
Validation loss: 2.034544368584951

Epoch: 6| Step: 3
Training loss: 1.8846261501312256
Validation loss: 2.0340128938357034

Epoch: 6| Step: 4
Training loss: 2.107390880584717
Validation loss: 2.0334102710088096

Epoch: 6| Step: 5
Training loss: 1.6559561491012573
Validation loss: 2.0268580516179404

Epoch: 6| Step: 6
Training loss: 2.6497018337249756
Validation loss: 2.024888753890991

Epoch: 6| Step: 7
Training loss: 2.3486833572387695
Validation loss: 2.0383612910906472

Epoch: 6| Step: 8
Training loss: 2.4349489212036133
Validation loss: 2.03252120812734

Epoch: 6| Step: 9
Training loss: 2.3388633728027344
Validation loss: 2.0302634239196777

Epoch: 6| Step: 10
Training loss: 2.458488941192627
Validation loss: 2.040198882420858

Epoch: 6| Step: 11
Training loss: 1.6764060258865356
Validation loss: 2.026901066303253

Epoch: 6| Step: 12
Training loss: 2.5688397884368896
Validation loss: 2.023948589960734

Epoch: 6| Step: 13
Training loss: 2.1712703704833984
Validation loss: 2.023732542991638

Epoch: 81| Step: 0
Training loss: 1.8280586004257202
Validation loss: 2.03328138589859

Epoch: 6| Step: 1
Training loss: 1.928969144821167
Validation loss: 2.034033795197805

Epoch: 6| Step: 2
Training loss: 2.45394229888916
Validation loss: 2.044803341229757

Epoch: 6| Step: 3
Training loss: 1.561040997505188
Validation loss: 2.0478053092956543

Epoch: 6| Step: 4
Training loss: 2.2513930797576904
Validation loss: 2.0635072191556296

Epoch: 6| Step: 5
Training loss: 2.766845703125
Validation loss: 2.055179456869761

Epoch: 6| Step: 6
Training loss: 2.5204944610595703
Validation loss: 2.051151772340139

Epoch: 6| Step: 7
Training loss: 1.5062326192855835
Validation loss: 2.0334399541219077

Epoch: 6| Step: 8
Training loss: 2.2038989067077637
Validation loss: 2.0252046386400857

Epoch: 6| Step: 9
Training loss: 2.9040160179138184
Validation loss: 2.017595966657003

Epoch: 6| Step: 10
Training loss: 1.845231056213379
Validation loss: 2.009775618712107

Epoch: 6| Step: 11
Training loss: 2.0492584705352783
Validation loss: 2.0101897915204368

Epoch: 6| Step: 12
Training loss: 1.834376573562622
Validation loss: 2.010620733102163

Epoch: 6| Step: 13
Training loss: 2.513551712036133
Validation loss: 2.003455420335134

Epoch: 82| Step: 0
Training loss: 2.0178277492523193
Validation loss: 2.00998987754186

Epoch: 6| Step: 1
Training loss: 2.667315721511841
Validation loss: 2.006999055544535

Epoch: 6| Step: 2
Training loss: 2.117802143096924
Validation loss: 2.013421614964803

Epoch: 6| Step: 3
Training loss: 2.251638412475586
Validation loss: 2.0164870023727417

Epoch: 6| Step: 4
Training loss: 1.9098533391952515
Validation loss: 2.013641675313314

Epoch: 6| Step: 5
Training loss: 1.645586371421814
Validation loss: 2.0242650906244912

Epoch: 6| Step: 6
Training loss: 1.9576609134674072
Validation loss: 2.0240637262662253

Epoch: 6| Step: 7
Training loss: 2.405360698699951
Validation loss: 2.0318177342414856

Epoch: 6| Step: 8
Training loss: 1.3417975902557373
Validation loss: 2.0484588543574014

Epoch: 6| Step: 9
Training loss: 2.314055919647217
Validation loss: 2.05378919839859

Epoch: 6| Step: 10
Training loss: 2.362028121948242
Validation loss: 2.044210056463877

Epoch: 6| Step: 11
Training loss: 2.3580880165100098
Validation loss: 2.0394709507624307

Epoch: 6| Step: 12
Training loss: 1.9027020931243896
Validation loss: 2.0397560596466064

Epoch: 6| Step: 13
Training loss: 2.84972882270813
Validation loss: 2.0266245206197104

Epoch: 83| Step: 0
Training loss: 1.5249037742614746
Validation loss: 2.029747426509857

Epoch: 6| Step: 1
Training loss: 2.5315299034118652
Validation loss: 2.019708236058553

Epoch: 6| Step: 2
Training loss: 2.3581862449645996
Validation loss: 2.022637665271759

Epoch: 6| Step: 3
Training loss: 2.259688377380371
Validation loss: 2.0211217602094016

Epoch: 6| Step: 4
Training loss: 1.9030005931854248
Validation loss: 2.0223042170206704

Epoch: 6| Step: 5
Training loss: 1.5826326608657837
Validation loss: 2.020197788874308

Epoch: 6| Step: 6
Training loss: 2.7943382263183594
Validation loss: 2.0217519799868264

Epoch: 6| Step: 7
Training loss: 2.35286545753479
Validation loss: 2.025773803393046

Epoch: 6| Step: 8
Training loss: 2.182934045791626
Validation loss: 2.0290001034736633

Epoch: 6| Step: 9
Training loss: 1.8421614170074463
Validation loss: 2.029565989971161

Epoch: 6| Step: 10
Training loss: 1.85986328125
Validation loss: 2.0404738585154214

Epoch: 6| Step: 11
Training loss: 2.2494471073150635
Validation loss: 2.0405938625335693

Epoch: 6| Step: 12
Training loss: 2.3302838802337646
Validation loss: 2.0531588991483054

Epoch: 6| Step: 13
Training loss: 2.2186636924743652
Validation loss: 2.056615730126699

Epoch: 84| Step: 0
Training loss: 2.1434879302978516
Validation loss: 2.044922490914663

Epoch: 6| Step: 1
Training loss: 1.6596224308013916
Validation loss: 2.04360024134318

Epoch: 6| Step: 2
Training loss: 2.183828353881836
Validation loss: 2.050167699654897

Epoch: 6| Step: 3
Training loss: 2.3240487575531006
Validation loss: 2.041761636734009

Epoch: 6| Step: 4
Training loss: 2.460632562637329
Validation loss: 2.038057784239451

Epoch: 6| Step: 5
Training loss: 2.1027674674987793
Validation loss: 2.028077940146128

Epoch: 6| Step: 6
Training loss: 1.7763326168060303
Validation loss: 2.0322755773862204

Epoch: 6| Step: 7
Training loss: 2.4791836738586426
Validation loss: 2.0353031158447266

Epoch: 6| Step: 8
Training loss: 1.407150387763977
Validation loss: 2.0291840632756553

Epoch: 6| Step: 9
Training loss: 1.8438067436218262
Validation loss: 2.028338929017385

Epoch: 6| Step: 10
Training loss: 2.8287320137023926
Validation loss: 2.022889196872711

Epoch: 6| Step: 11
Training loss: 2.395962715148926
Validation loss: 2.009646693865458

Epoch: 6| Step: 12
Training loss: 2.246236801147461
Validation loss: 2.021133462587992

Epoch: 6| Step: 13
Training loss: 1.8383382558822632
Validation loss: 2.0256023009618125

Epoch: 85| Step: 0
Training loss: 1.5678832530975342
Validation loss: 2.024823784828186

Epoch: 6| Step: 1
Training loss: 2.219179153442383
Validation loss: 2.025697191556295

Epoch: 6| Step: 2
Training loss: 2.6990702152252197
Validation loss: 2.02814910809199

Epoch: 6| Step: 3
Training loss: 1.8507661819458008
Validation loss: 2.035025417804718

Epoch: 6| Step: 4
Training loss: 1.8152124881744385
Validation loss: 2.02984611193339

Epoch: 6| Step: 5
Training loss: 2.1827731132507324
Validation loss: 2.03413979212443

Epoch: 6| Step: 6
Training loss: 2.9306321144104004
Validation loss: 2.055567741394043

Epoch: 6| Step: 7
Training loss: 2.071417808532715
Validation loss: 2.042363782723745

Epoch: 6| Step: 8
Training loss: 2.306929588317871
Validation loss: 2.0415992935498557

Epoch: 6| Step: 9
Training loss: 2.3140125274658203
Validation loss: 2.0427098274230957

Epoch: 6| Step: 10
Training loss: 2.3202438354492188
Validation loss: 2.039286454518636

Epoch: 6| Step: 11
Training loss: 2.0723793506622314
Validation loss: 2.0283085306485495

Epoch: 6| Step: 12
Training loss: 1.9038033485412598
Validation loss: 2.0162150065104165

Epoch: 6| Step: 13
Training loss: 1.7589926719665527
Validation loss: 2.021194557348887

Epoch: 86| Step: 0
Training loss: 2.159634590148926
Validation loss: 2.0164103905359902

Epoch: 6| Step: 1
Training loss: 1.5812723636627197
Validation loss: 2.0170766512552896

Epoch: 6| Step: 2
Training loss: 1.8392865657806396
Validation loss: 2.0274383227030435

Epoch: 6| Step: 3
Training loss: 2.2606077194213867
Validation loss: 2.0328434109687805

Epoch: 6| Step: 4
Training loss: 2.7800779342651367
Validation loss: 2.028196096420288

Epoch: 6| Step: 5
Training loss: 2.1135878562927246
Validation loss: 2.0155720909436545

Epoch: 6| Step: 6
Training loss: 1.7431249618530273
Validation loss: 2.0141597787539163

Epoch: 6| Step: 7
Training loss: 2.199662685394287
Validation loss: 2.020851453145345

Epoch: 6| Step: 8
Training loss: 2.201955556869507
Validation loss: 2.0330838362375894

Epoch: 6| Step: 9
Training loss: 2.692251443862915
Validation loss: 2.041220545768738

Epoch: 6| Step: 10
Training loss: 2.3795881271362305
Validation loss: 2.045984387397766

Epoch: 6| Step: 11
Training loss: 2.2049262523651123
Validation loss: 2.048452933629354

Epoch: 6| Step: 12
Training loss: 2.0696630477905273
Validation loss: 2.028481642405192

Epoch: 6| Step: 13
Training loss: 1.650085210800171
Validation loss: 2.034898658593496

Epoch: 87| Step: 0
Training loss: 2.3623831272125244
Validation loss: 2.0269723733266196

Epoch: 6| Step: 1
Training loss: 1.9381608963012695
Validation loss: 2.018676976362864

Epoch: 6| Step: 2
Training loss: 1.8926301002502441
Validation loss: 2.0205652713775635

Epoch: 6| Step: 3
Training loss: 2.124929666519165
Validation loss: 2.0214911500612893

Epoch: 6| Step: 4
Training loss: 2.2190322875976562
Validation loss: 2.014893035093943

Epoch: 6| Step: 5
Training loss: 2.424488067626953
Validation loss: 2.0196296771367392

Epoch: 6| Step: 6
Training loss: 2.1306607723236084
Validation loss: 2.027091125647227

Epoch: 6| Step: 7
Training loss: 1.7471469640731812
Validation loss: 2.0130812724431357

Epoch: 6| Step: 8
Training loss: 2.468975305557251
Validation loss: 2.0189178387324014

Epoch: 6| Step: 9
Training loss: 1.9034812450408936
Validation loss: 2.006991465886434

Epoch: 6| Step: 10
Training loss: 2.7001028060913086
Validation loss: 2.0230173468589783

Epoch: 6| Step: 11
Training loss: 2.089338779449463
Validation loss: 2.0202075242996216

Epoch: 6| Step: 12
Training loss: 1.6230820417404175
Validation loss: 2.031017621358236

Epoch: 6| Step: 13
Training loss: 2.1167125701904297
Validation loss: 2.0232757329940796

Epoch: 88| Step: 0
Training loss: 2.206625461578369
Validation loss: 2.0206146438916526

Epoch: 6| Step: 1
Training loss: 2.2861289978027344
Validation loss: 2.031517227490743

Epoch: 6| Step: 2
Training loss: 1.9271260499954224
Validation loss: 2.04253359635671

Epoch: 6| Step: 3
Training loss: 2.178837299346924
Validation loss: 2.032096564769745

Epoch: 6| Step: 4
Training loss: 2.061779737472534
Validation loss: 2.0244234005610147

Epoch: 6| Step: 5
Training loss: 1.9889447689056396
Validation loss: 2.0378308494885764

Epoch: 6| Step: 6
Training loss: 2.1676270961761475
Validation loss: 2.0193143089612327

Epoch: 6| Step: 7
Training loss: 1.6140789985656738
Validation loss: 2.022193948427836

Epoch: 6| Step: 8
Training loss: 2.130702018737793
Validation loss: 2.0249419808387756

Epoch: 6| Step: 9
Training loss: 1.8297873735427856
Validation loss: 2.0305874149004617

Epoch: 6| Step: 10
Training loss: 2.167572021484375
Validation loss: 2.0229846239089966

Epoch: 6| Step: 11
Training loss: 2.3493309020996094
Validation loss: 2.0121201872825623

Epoch: 6| Step: 12
Training loss: 2.664701461791992
Validation loss: 2.002163747946421

Epoch: 6| Step: 13
Training loss: 2.362678050994873
Validation loss: 2.016598025957743

Epoch: 89| Step: 0
Training loss: 1.6577224731445312
Validation loss: 2.0259110728899636

Epoch: 6| Step: 1
Training loss: 2.7268905639648438
Validation loss: 2.035443286101023

Epoch: 6| Step: 2
Training loss: 1.9226198196411133
Validation loss: 2.028355836868286

Epoch: 6| Step: 3
Training loss: 2.364689588546753
Validation loss: 2.032425026098887

Epoch: 6| Step: 4
Training loss: 2.141246795654297
Validation loss: 2.0494301120440164

Epoch: 6| Step: 5
Training loss: 1.7131242752075195
Validation loss: 2.024293382962545

Epoch: 6| Step: 6
Training loss: 1.6724183559417725
Validation loss: 2.032238562901815

Epoch: 6| Step: 7
Training loss: 1.7481577396392822
Validation loss: 2.040433665116628

Epoch: 6| Step: 8
Training loss: 2.2234506607055664
Validation loss: 2.055359502633413

Epoch: 6| Step: 9
Training loss: 2.1076292991638184
Validation loss: 2.0352246165275574

Epoch: 6| Step: 10
Training loss: 2.192412853240967
Validation loss: 2.041535417238871

Epoch: 6| Step: 11
Training loss: 2.26654314994812
Validation loss: 2.01800670226415

Epoch: 6| Step: 12
Training loss: 2.594179153442383
Validation loss: 2.007121721903483

Epoch: 6| Step: 13
Training loss: 2.3777332305908203
Validation loss: 2.006592075030009

Epoch: 90| Step: 0
Training loss: 1.8661733865737915
Validation loss: 2.029354214668274

Epoch: 6| Step: 1
Training loss: 2.372342586517334
Validation loss: 2.025275548299154

Epoch: 6| Step: 2
Training loss: 2.2075271606445312
Validation loss: 2.0332902669906616

Epoch: 6| Step: 3
Training loss: 2.051720142364502
Validation loss: 2.0311209758122764

Epoch: 6| Step: 4
Training loss: 2.284444808959961
Validation loss: 2.034725526968638

Epoch: 6| Step: 5
Training loss: 2.6998963356018066
Validation loss: 2.040150264898936

Epoch: 6| Step: 6
Training loss: 1.9359235763549805
Validation loss: 2.026907722155253

Epoch: 6| Step: 7
Training loss: 2.3572945594787598
Validation loss: 2.0408082008361816

Epoch: 6| Step: 8
Training loss: 1.9802472591400146
Validation loss: 2.031248847643534

Epoch: 6| Step: 9
Training loss: 1.9684958457946777
Validation loss: 2.0331504344940186

Epoch: 6| Step: 10
Training loss: 2.106851577758789
Validation loss: 2.0370147228240967

Epoch: 6| Step: 11
Training loss: 1.578728437423706
Validation loss: 2.027247409025828

Epoch: 6| Step: 12
Training loss: 2.3809313774108887
Validation loss: 2.0233277877171836

Epoch: 6| Step: 13
Training loss: 2.9459168910980225
Validation loss: 2.024905800819397

Epoch: 91| Step: 0
Training loss: 2.221904754638672
Validation loss: 2.019974966843923

Epoch: 6| Step: 1
Training loss: 2.3732657432556152
Validation loss: 2.020134230454763

Epoch: 6| Step: 2
Training loss: 1.491758108139038
Validation loss: 2.0234912236531577

Epoch: 6| Step: 3
Training loss: 1.4886751174926758
Validation loss: 2.0283836921056113

Epoch: 6| Step: 4
Training loss: 2.958984375
Validation loss: 2.0188769499460855

Epoch: 6| Step: 5
Training loss: 1.4626457691192627
Validation loss: 2.0277511874834695

Epoch: 6| Step: 6
Training loss: 2.833860397338867
Validation loss: 2.01932962735494

Epoch: 6| Step: 7
Training loss: 2.117715835571289
Validation loss: 2.0235975980758667

Epoch: 6| Step: 8
Training loss: 1.5706777572631836
Validation loss: 2.050142506758372

Epoch: 6| Step: 9
Training loss: 2.26476788520813
Validation loss: 2.0632745226224265

Epoch: 6| Step: 10
Training loss: 1.8767778873443604
Validation loss: 2.070544421672821

Epoch: 6| Step: 11
Training loss: 2.9165940284729004
Validation loss: 2.0645724534988403

Epoch: 6| Step: 12
Training loss: 2.2964491844177246
Validation loss: 2.0677145520846048

Epoch: 6| Step: 13
Training loss: 2.47709321975708
Validation loss: 2.072211583455404

Epoch: 92| Step: 0
Training loss: 2.5093588829040527
Validation loss: 2.058934191862742

Epoch: 6| Step: 1
Training loss: 1.926579236984253
Validation loss: 2.0396063327789307

Epoch: 6| Step: 2
Training loss: 2.3819522857666016
Validation loss: 2.04014124472936

Epoch: 6| Step: 3
Training loss: 1.9232505559921265
Validation loss: 2.0398553609848022

Epoch: 6| Step: 4
Training loss: 2.3526620864868164
Validation loss: 2.0384127696355185

Epoch: 6| Step: 5
Training loss: 2.297609806060791
Validation loss: 2.042048434416453

Epoch: 6| Step: 6
Training loss: 2.111267566680908
Validation loss: 2.041315714518229

Epoch: 6| Step: 7
Training loss: 2.27868390083313
Validation loss: 2.045823613802592

Epoch: 6| Step: 8
Training loss: 2.1726863384246826
Validation loss: 2.04158608118693

Epoch: 6| Step: 9
Training loss: 2.495738983154297
Validation loss: 2.0320003827412925

Epoch: 6| Step: 10
Training loss: 1.9876055717468262
Validation loss: 2.029375592867533

Epoch: 6| Step: 11
Training loss: 1.9156159162521362
Validation loss: 2.033357838789622

Epoch: 6| Step: 12
Training loss: 1.688799262046814
Validation loss: 2.022236784299215

Epoch: 6| Step: 13
Training loss: 1.5987614393234253
Validation loss: 2.0280127127965293

Epoch: 93| Step: 0
Training loss: 2.457698345184326
Validation loss: 2.0200934211413064

Epoch: 6| Step: 1
Training loss: 1.6432629823684692
Validation loss: 2.0118441184361777

Epoch: 6| Step: 2
Training loss: 2.2871954441070557
Validation loss: 2.016126275062561

Epoch: 6| Step: 3
Training loss: 2.0173799991607666
Validation loss: 2.0084999998410544

Epoch: 6| Step: 4
Training loss: 2.173419713973999
Validation loss: 2.0159470438957214

Epoch: 6| Step: 5
Training loss: 2.8319859504699707
Validation loss: 2.0070407390594482

Epoch: 6| Step: 6
Training loss: 2.145688056945801
Validation loss: 2.0113733609517417

Epoch: 6| Step: 7
Training loss: 2.156184196472168
Validation loss: 2.0097832679748535

Epoch: 6| Step: 8
Training loss: 1.9686903953552246
Validation loss: 2.004850745201111

Epoch: 6| Step: 9
Training loss: 2.1880884170532227
Validation loss: 2.00877054532369

Epoch: 6| Step: 10
Training loss: 1.8487693071365356
Validation loss: 2.0078699390093484

Epoch: 6| Step: 11
Training loss: 2.0633139610290527
Validation loss: 2.0085766514142356

Epoch: 6| Step: 12
Training loss: 1.9219632148742676
Validation loss: 2.0164854923884072

Epoch: 6| Step: 13
Training loss: 2.154927968978882
Validation loss: 2.0188016494115195

Epoch: 94| Step: 0
Training loss: 2.529910087585449
Validation loss: 2.0310344099998474

Epoch: 6| Step: 1
Training loss: 2.4280483722686768
Validation loss: 2.0275038679440818

Epoch: 6| Step: 2
Training loss: 2.422266960144043
Validation loss: 2.0358213980992637

Epoch: 6| Step: 3
Training loss: 1.9370299577713013
Validation loss: 2.0342323382695517

Epoch: 6| Step: 4
Training loss: 2.45721173286438
Validation loss: 2.038540780544281

Epoch: 6| Step: 5
Training loss: 2.303813934326172
Validation loss: 2.0251639684041343

Epoch: 6| Step: 6
Training loss: 1.7521768808364868
Validation loss: 2.0228336652119956

Epoch: 6| Step: 7
Training loss: 1.8586108684539795
Validation loss: 2.0186613400777182

Epoch: 6| Step: 8
Training loss: 2.6363654136657715
Validation loss: 2.022469480832418

Epoch: 6| Step: 9
Training loss: 1.7282755374908447
Validation loss: 2.017366647720337

Epoch: 6| Step: 10
Training loss: 1.6928720474243164
Validation loss: 2.0249863465627036

Epoch: 6| Step: 11
Training loss: 2.057704210281372
Validation loss: 2.034877280394236

Epoch: 6| Step: 12
Training loss: 1.9162062406539917
Validation loss: 2.0300026337305703

Epoch: 6| Step: 13
Training loss: 2.181262493133545
Validation loss: 2.0253638426462808

Epoch: 95| Step: 0
Training loss: 2.1901910305023193
Validation loss: 2.0364062388738

Epoch: 6| Step: 1
Training loss: 2.4343132972717285
Validation loss: 2.0294242699941

Epoch: 6| Step: 2
Training loss: 1.6850416660308838
Validation loss: 2.0379626154899597

Epoch: 6| Step: 3
Training loss: 2.2790651321411133
Validation loss: 2.0258546670277915

Epoch: 6| Step: 4
Training loss: 1.9671369791030884
Validation loss: 2.0274397929509482

Epoch: 6| Step: 5
Training loss: 2.0990161895751953
Validation loss: 2.021852115790049

Epoch: 6| Step: 6
Training loss: 2.586686134338379
Validation loss: 2.0132142305374146

Epoch: 6| Step: 7
Training loss: 1.863598108291626
Validation loss: 2.0126905043919883

Epoch: 6| Step: 8
Training loss: 2.039984703063965
Validation loss: 2.0124986370404563

Epoch: 6| Step: 9
Training loss: 2.303866386413574
Validation loss: 2.015850861867269

Epoch: 6| Step: 10
Training loss: 2.165595054626465
Validation loss: 2.014042377471924

Epoch: 6| Step: 11
Training loss: 2.0951852798461914
Validation loss: 2.012793560822805

Epoch: 6| Step: 12
Training loss: 2.4774320125579834
Validation loss: 2.0094441374142966

Epoch: 6| Step: 13
Training loss: 1.7383928298950195
Validation loss: 2.0244418581326804

Epoch: 96| Step: 0
Training loss: 1.912505865097046
Validation loss: 2.0182807644208274

Epoch: 6| Step: 1
Training loss: 2.136704444885254
Validation loss: 2.0184460282325745

Epoch: 6| Step: 2
Training loss: 1.4636298418045044
Validation loss: 2.024188756942749

Epoch: 6| Step: 3
Training loss: 2.1644136905670166
Validation loss: 2.0190996130307517

Epoch: 6| Step: 4
Training loss: 2.830902099609375
Validation loss: 2.0305871764818826

Epoch: 6| Step: 5
Training loss: 1.8713687658309937
Validation loss: 2.0214818517367044

Epoch: 6| Step: 6
Training loss: 2.213101863861084
Validation loss: 2.034270147482554

Epoch: 6| Step: 7
Training loss: 1.8657941818237305
Validation loss: 2.0283743739128113

Epoch: 6| Step: 8
Training loss: 2.8266539573669434
Validation loss: 2.0374768575032554

Epoch: 6| Step: 9
Training loss: 1.6499963998794556
Validation loss: 2.0385495026906333

Epoch: 6| Step: 10
Training loss: 2.223292589187622
Validation loss: 2.0311857064565024

Epoch: 6| Step: 11
Training loss: 2.32395601272583
Validation loss: 2.029967109362284

Epoch: 6| Step: 12
Training loss: 2.2077322006225586
Validation loss: 2.0373844305674234

Epoch: 6| Step: 13
Training loss: 2.007812023162842
Validation loss: 2.0359705289204917

Epoch: 97| Step: 0
Training loss: 2.3770341873168945
Validation loss: 2.041022260983785

Epoch: 6| Step: 1
Training loss: 1.8708350658416748
Validation loss: 2.0339343547821045

Epoch: 6| Step: 2
Training loss: 1.6681863069534302
Validation loss: 2.029405097166697

Epoch: 6| Step: 3
Training loss: 2.460252046585083
Validation loss: 2.030744731426239

Epoch: 6| Step: 4
Training loss: 2.053071975708008
Validation loss: 2.0223883589108786

Epoch: 6| Step: 5
Training loss: 1.911393165588379
Validation loss: 2.024769047896067

Epoch: 6| Step: 6
Training loss: 2.338214635848999
Validation loss: 2.0230703155199685

Epoch: 6| Step: 7
Training loss: 2.6018600463867188
Validation loss: 2.0152783393859863

Epoch: 6| Step: 8
Training loss: 2.160982370376587
Validation loss: 2.028221825758616

Epoch: 6| Step: 9
Training loss: 1.9137223958969116
Validation loss: 2.018675704797109

Epoch: 6| Step: 10
Training loss: 1.323524832725525
Validation loss: 2.020009617010752

Epoch: 6| Step: 11
Training loss: 2.1913294792175293
Validation loss: 2.015926500161489

Epoch: 6| Step: 12
Training loss: 2.3498106002807617
Validation loss: 2.021839678287506

Epoch: 6| Step: 13
Training loss: 2.6320571899414062
Validation loss: 2.029160479704539

Epoch: 98| Step: 0
Training loss: 2.0723490715026855
Validation loss: 2.0345290501912436

Epoch: 6| Step: 1
Training loss: 2.330702304840088
Validation loss: 2.0322044293085733

Epoch: 6| Step: 2
Training loss: 2.383896589279175
Validation loss: 2.0357871651649475

Epoch: 6| Step: 3
Training loss: 1.8626517057418823
Validation loss: 2.0341757933298745

Epoch: 6| Step: 4
Training loss: 2.3239917755126953
Validation loss: 2.034445842107137

Epoch: 6| Step: 5
Training loss: 2.2943973541259766
Validation loss: 2.036962330341339

Epoch: 6| Step: 6
Training loss: 2.0224616527557373
Validation loss: 2.0367949406305947

Epoch: 6| Step: 7
Training loss: 1.9447208642959595
Validation loss: 2.029025137424469

Epoch: 6| Step: 8
Training loss: 1.7067906856536865
Validation loss: 2.0336476961771646

Epoch: 6| Step: 9
Training loss: 1.7868212461471558
Validation loss: 2.0325037638346353

Epoch: 6| Step: 10
Training loss: 1.70680570602417
Validation loss: 2.024103105068207

Epoch: 6| Step: 11
Training loss: 2.0572876930236816
Validation loss: 2.02437025308609

Epoch: 6| Step: 12
Training loss: 2.442579984664917
Validation loss: 2.0151319106419883

Epoch: 6| Step: 13
Training loss: 2.485844135284424
Validation loss: 2.0183643897374473

Epoch: 99| Step: 0
Training loss: 2.463070869445801
Validation loss: 2.0090142289797464

Epoch: 6| Step: 1
Training loss: 1.737448811531067
Validation loss: 2.0181895891825357

Epoch: 6| Step: 2
Training loss: 2.6960558891296387
Validation loss: 2.01770555973053

Epoch: 6| Step: 3
Training loss: 2.1326799392700195
Validation loss: 2.0122006138165793

Epoch: 6| Step: 4
Training loss: 1.9982730150222778
Validation loss: 2.0245951612790427

Epoch: 6| Step: 5
Training loss: 2.0821571350097656
Validation loss: 2.0129220287005105

Epoch: 6| Step: 6
Training loss: 1.9591431617736816
Validation loss: 2.0157810846964517

Epoch: 6| Step: 7
Training loss: 1.882169246673584
Validation loss: 2.0197969476381936

Epoch: 6| Step: 8
Training loss: 1.7997956275939941
Validation loss: 2.0238532026608786

Epoch: 6| Step: 9
Training loss: 1.9883086681365967
Validation loss: 2.031234939893087

Epoch: 6| Step: 10
Training loss: 2.275362491607666
Validation loss: 2.0399325688680015

Epoch: 6| Step: 11
Training loss: 2.276252269744873
Validation loss: 2.048395812511444

Epoch: 6| Step: 12
Training loss: 2.0659899711608887
Validation loss: 2.0398568908373513

Epoch: 6| Step: 13
Training loss: 2.2126145362854004
Validation loss: 2.0436113476753235

Epoch: 100| Step: 0
Training loss: 1.9092464447021484
Validation loss: 2.050200124581655

Epoch: 6| Step: 1
Training loss: 1.8547658920288086
Validation loss: 2.047296106815338

Epoch: 6| Step: 2
Training loss: 2.057896852493286
Validation loss: 2.0437225103378296

Epoch: 6| Step: 3
Training loss: 2.29086971282959
Validation loss: 2.037892162799835

Epoch: 6| Step: 4
Training loss: 1.5711511373519897
Validation loss: 2.036820352077484

Epoch: 6| Step: 5
Training loss: 2.0987191200256348
Validation loss: 2.030181566874186

Epoch: 6| Step: 6
Training loss: 2.0865859985351562
Validation loss: 2.034135361512502

Epoch: 6| Step: 7
Training loss: 2.3512604236602783
Validation loss: 2.0369301438331604

Epoch: 6| Step: 8
Training loss: 2.1201300621032715
Validation loss: 2.0338151256243386

Epoch: 6| Step: 9
Training loss: 2.7681729793548584
Validation loss: 2.037037471930186

Epoch: 6| Step: 10
Training loss: 1.9483118057250977
Validation loss: 2.0369154810905457

Epoch: 6| Step: 11
Training loss: 1.8256611824035645
Validation loss: 2.0251652002334595

Epoch: 6| Step: 12
Training loss: 2.561690330505371
Validation loss: 2.0257726311683655

Epoch: 6| Step: 13
Training loss: 2.035996198654175
Validation loss: 2.0254275798797607

Epoch: 101| Step: 0
Training loss: 2.4623398780822754
Validation loss: 2.0278759400049844

Epoch: 6| Step: 1
Training loss: 2.012387752532959
Validation loss: 2.0230579773585

Epoch: 6| Step: 2
Training loss: 1.5454792976379395
Validation loss: 2.0239675442377725

Epoch: 6| Step: 3
Training loss: 2.259774923324585
Validation loss: 2.0309922893842063

Epoch: 6| Step: 4
Training loss: 2.340364456176758
Validation loss: 2.021635810534159

Epoch: 6| Step: 5
Training loss: 1.5704247951507568
Validation loss: 2.0225649078687034

Epoch: 6| Step: 6
Training loss: 1.7877333164215088
Validation loss: 2.023688793182373

Epoch: 6| Step: 7
Training loss: 1.8671770095825195
Validation loss: 2.0173362294832864

Epoch: 6| Step: 8
Training loss: 2.3910317420959473
Validation loss: 2.024794042110443

Epoch: 6| Step: 9
Training loss: 2.214761257171631
Validation loss: 2.028169016043345

Epoch: 6| Step: 10
Training loss: 2.3423149585723877
Validation loss: 2.0253496567408242

Epoch: 6| Step: 11
Training loss: 2.190288543701172
Validation loss: 2.0361407001813254

Epoch: 6| Step: 12
Training loss: 2.2591235637664795
Validation loss: 2.0253227949142456

Epoch: 6| Step: 13
Training loss: 2.1679604053497314
Validation loss: 2.0355761647224426

Epoch: 102| Step: 0
Training loss: 2.154149293899536
Validation loss: 2.037271777788798

Epoch: 6| Step: 1
Training loss: 1.8217061758041382
Validation loss: 2.0520222385724387

Epoch: 6| Step: 2
Training loss: 2.6659364700317383
Validation loss: 2.0518054167429605

Epoch: 6| Step: 3
Training loss: 1.9555840492248535
Validation loss: 2.070662279923757

Epoch: 6| Step: 4
Training loss: 2.7020158767700195
Validation loss: 2.061170438925425

Epoch: 6| Step: 5
Training loss: 2.163630247116089
Validation loss: 2.051489313443502

Epoch: 6| Step: 6
Training loss: 1.6559725999832153
Validation loss: 2.0450916290283203

Epoch: 6| Step: 7
Training loss: 1.6085541248321533
Validation loss: 2.0348874727884927

Epoch: 6| Step: 8
Training loss: 2.6562256813049316
Validation loss: 2.031267205874125

Epoch: 6| Step: 9
Training loss: 1.697512149810791
Validation loss: 2.0363570054372153

Epoch: 6| Step: 10
Training loss: 2.3202707767486572
Validation loss: 2.028237243493398

Epoch: 6| Step: 11
Training loss: 2.00313138961792
Validation loss: 2.0287508567174277

Epoch: 6| Step: 12
Training loss: 1.800789475440979
Validation loss: 2.02955553929011

Epoch: 6| Step: 13
Training loss: 2.3593578338623047
Validation loss: 2.0238601565361023

Epoch: 103| Step: 0
Training loss: 1.9317595958709717
Validation loss: 2.0242847005526223

Epoch: 6| Step: 1
Training loss: 2.4332306385040283
Validation loss: 2.02471391359965

Epoch: 6| Step: 2
Training loss: 1.865261435508728
Validation loss: 2.0261778036753335

Epoch: 6| Step: 3
Training loss: 2.026340961456299
Validation loss: 2.0161107381184897

Epoch: 6| Step: 4
Training loss: 1.73485267162323
Validation loss: 2.0311416188875833

Epoch: 6| Step: 5
Training loss: 2.147533893585205
Validation loss: 2.0376096765200296

Epoch: 6| Step: 6
Training loss: 2.2865731716156006
Validation loss: 2.035827100276947

Epoch: 6| Step: 7
Training loss: 2.886946678161621
Validation loss: 2.0362223784128823

Epoch: 6| Step: 8
Training loss: 2.1965153217315674
Validation loss: 2.0397228995958963

Epoch: 6| Step: 9
Training loss: 1.694056749343872
Validation loss: 2.0393298864364624

Epoch: 6| Step: 10
Training loss: 2.2360289096832275
Validation loss: 2.0500561594963074

Epoch: 6| Step: 11
Training loss: 1.9055275917053223
Validation loss: 2.0427090525627136

Epoch: 6| Step: 12
Training loss: 2.5258336067199707
Validation loss: 2.0406084060668945

Epoch: 6| Step: 13
Training loss: 1.7400071620941162
Validation loss: 2.0292146801948547

Epoch: 104| Step: 0
Training loss: 2.3797316551208496
Validation loss: 2.0336612661679587

Epoch: 6| Step: 1
Training loss: 2.108548164367676
Validation loss: 2.0375243425369263

Epoch: 6| Step: 2
Training loss: 2.0901641845703125
Validation loss: 2.03290585676829

Epoch: 6| Step: 3
Training loss: 1.9034700393676758
Validation loss: 2.0222099224726358

Epoch: 6| Step: 4
Training loss: 2.1222314834594727
Validation loss: 2.0217935840288797

Epoch: 6| Step: 5
Training loss: 1.9655063152313232
Validation loss: 2.0218303004900613

Epoch: 6| Step: 6
Training loss: 2.0202879905700684
Validation loss: 2.0315130750338235

Epoch: 6| Step: 7
Training loss: 1.7739689350128174
Validation loss: 2.0191566348075867

Epoch: 6| Step: 8
Training loss: 3.134676456451416
Validation loss: 2.026325782140096

Epoch: 6| Step: 9
Training loss: 1.850954294204712
Validation loss: 2.037455896536509

Epoch: 6| Step: 10
Training loss: 1.5530214309692383
Validation loss: 2.049185335636139

Epoch: 6| Step: 11
Training loss: 2.492234230041504
Validation loss: 2.0396492878595986

Epoch: 6| Step: 12
Training loss: 1.8455857038497925
Validation loss: 2.039922833442688

Epoch: 6| Step: 13
Training loss: 2.4920430183410645
Validation loss: 2.046283225218455

Epoch: 105| Step: 0
Training loss: 1.9970391988754272
Validation loss: 2.042634387811025

Epoch: 6| Step: 1
Training loss: 2.5236330032348633
Validation loss: 2.032747228940328

Epoch: 6| Step: 2
Training loss: 2.124049663543701
Validation loss: 2.0478007992108664

Epoch: 6| Step: 3
Training loss: 2.024930000305176
Validation loss: 2.039241890112559

Epoch: 6| Step: 4
Training loss: 2.4819555282592773
Validation loss: 2.042069395383199

Epoch: 6| Step: 5
Training loss: 2.2239646911621094
Validation loss: 2.0364303986231485

Epoch: 6| Step: 6
Training loss: 3.151092529296875
Validation loss: 2.030805071194967

Epoch: 6| Step: 7
Training loss: 1.805985689163208
Validation loss: 2.0292526284853616

Epoch: 6| Step: 8
Training loss: 1.8310400247573853
Validation loss: 2.024990757306417

Epoch: 6| Step: 9
Training loss: 2.26705265045166
Validation loss: 2.023965140183767

Epoch: 6| Step: 10
Training loss: 1.091116189956665
Validation loss: 2.0377316077550254

Epoch: 6| Step: 11
Training loss: 2.250640392303467
Validation loss: 2.030089279015859

Epoch: 6| Step: 12
Training loss: 1.7045248746871948
Validation loss: 2.045018414656321

Epoch: 6| Step: 13
Training loss: 1.943469524383545
Validation loss: 2.038010815779368

Epoch: 106| Step: 0
Training loss: 2.2428224086761475
Validation loss: 2.042350431283315

Epoch: 6| Step: 1
Training loss: 2.3527183532714844
Validation loss: 2.035256544748942

Epoch: 6| Step: 2
Training loss: 1.8387609720230103
Validation loss: 2.0322855909665427

Epoch: 6| Step: 3
Training loss: 1.6892898082733154
Validation loss: 2.032932221889496

Epoch: 6| Step: 4
Training loss: 1.8928600549697876
Validation loss: 2.030847648779551

Epoch: 6| Step: 5
Training loss: 1.505949854850769
Validation loss: 2.027313510576884

Epoch: 6| Step: 6
Training loss: 2.6716229915618896
Validation loss: 2.0220459699630737

Epoch: 6| Step: 7
Training loss: 2.3567962646484375
Validation loss: 2.0338740150133767

Epoch: 6| Step: 8
Training loss: 2.0431456565856934
Validation loss: 2.0315943161646524

Epoch: 6| Step: 9
Training loss: 1.9856159687042236
Validation loss: 2.0280404488245645

Epoch: 6| Step: 10
Training loss: 2.292212963104248
Validation loss: 2.027709146340688

Epoch: 6| Step: 11
Training loss: 2.2678518295288086
Validation loss: 2.029394189516703

Epoch: 6| Step: 12
Training loss: 2.3695034980773926
Validation loss: 2.0285359621047974

Epoch: 6| Step: 13
Training loss: 1.8840712308883667
Validation loss: 2.0361725886662803

Epoch: 107| Step: 0
Training loss: 2.0942201614379883
Validation loss: 2.0321511228879294

Epoch: 6| Step: 1
Training loss: 1.9697574377059937
Validation loss: 2.032193740208944

Epoch: 6| Step: 2
Training loss: 2.3134231567382812
Validation loss: 2.0357486406962075

Epoch: 6| Step: 3
Training loss: 2.46633243560791
Validation loss: 2.023586312929789

Epoch: 6| Step: 4
Training loss: 2.456758737564087
Validation loss: 2.0307297309239707

Epoch: 6| Step: 5
Training loss: 2.006864547729492
Validation loss: 2.038960079352061

Epoch: 6| Step: 6
Training loss: 2.0416297912597656
Validation loss: 2.026693105697632

Epoch: 6| Step: 7
Training loss: 2.3555636405944824
Validation loss: 2.027328312397003

Epoch: 6| Step: 8
Training loss: 1.6844573020935059
Validation loss: 2.024109423160553

Epoch: 6| Step: 9
Training loss: 2.2967324256896973
Validation loss: 2.0187897086143494

Epoch: 6| Step: 10
Training loss: 2.3385469913482666
Validation loss: 2.027324994405111

Epoch: 6| Step: 11
Training loss: 2.055742025375366
Validation loss: 2.0255706707636514

Epoch: 6| Step: 12
Training loss: 1.4963427782058716
Validation loss: 2.02853924036026

Epoch: 6| Step: 13
Training loss: 1.9291317462921143
Validation loss: 2.033555567264557

Epoch: 108| Step: 0
Training loss: 2.1044840812683105
Validation loss: 2.053135097026825

Epoch: 6| Step: 1
Training loss: 2.714745283126831
Validation loss: 2.0482982198397317

Epoch: 6| Step: 2
Training loss: 2.2713871002197266
Validation loss: 2.0746971368789673

Epoch: 6| Step: 3
Training loss: 1.929308533668518
Validation loss: 2.0709067384401956

Epoch: 6| Step: 4
Training loss: 2.2178449630737305
Validation loss: 2.0814917286237082

Epoch: 6| Step: 5
Training loss: 2.3579659461975098
Validation loss: 2.0686514377593994

Epoch: 6| Step: 6
Training loss: 2.4397683143615723
Validation loss: 2.0652262965838113

Epoch: 6| Step: 7
Training loss: 2.445589065551758
Validation loss: 2.034024099508921

Epoch: 6| Step: 8
Training loss: 1.5230157375335693
Validation loss: 2.019730567932129

Epoch: 6| Step: 9
Training loss: 1.8619625568389893
Validation loss: 2.0077786644299827

Epoch: 6| Step: 10
Training loss: 1.720740556716919
Validation loss: 2.0122989813486734

Epoch: 6| Step: 11
Training loss: 2.3108320236206055
Validation loss: 2.0220256646474204

Epoch: 6| Step: 12
Training loss: 1.7824370861053467
Validation loss: 2.0314707358678183

Epoch: 6| Step: 13
Training loss: 2.25533390045166
Validation loss: 2.030671993891398

Epoch: 109| Step: 0
Training loss: 2.365445137023926
Validation loss: 2.039796014626821

Epoch: 6| Step: 1
Training loss: 2.0787758827209473
Validation loss: 2.0431005160013833

Epoch: 6| Step: 2
Training loss: 2.1330409049987793
Validation loss: 2.0490695436795554

Epoch: 6| Step: 3
Training loss: 2.4056508541107178
Validation loss: 2.0424121022224426

Epoch: 6| Step: 4
Training loss: 1.7979364395141602
Validation loss: 2.0503089229265847

Epoch: 6| Step: 5
Training loss: 1.9757746458053589
Validation loss: 2.051094194253286

Epoch: 6| Step: 6
Training loss: 2.3423759937286377
Validation loss: 2.0561619798342385

Epoch: 6| Step: 7
Training loss: 1.9595292806625366
Validation loss: 2.0524481932322183

Epoch: 6| Step: 8
Training loss: 2.4079082012176514
Validation loss: 2.059062421321869

Epoch: 6| Step: 9
Training loss: 2.3432583808898926
Validation loss: 2.0548176169395447

Epoch: 6| Step: 10
Training loss: 2.221658706665039
Validation loss: 2.051492750644684

Epoch: 6| Step: 11
Training loss: 2.4924230575561523
Validation loss: 2.05099880695343

Epoch: 6| Step: 12
Training loss: 1.839491844177246
Validation loss: 2.0534260471661887

Epoch: 6| Step: 13
Training loss: 2.1707396507263184
Validation loss: 2.049546400705973

Epoch: 110| Step: 0
Training loss: 2.2111339569091797
Validation loss: 2.0408460895220437

Epoch: 6| Step: 1
Training loss: 2.284975290298462
Validation loss: 2.033143937587738

Epoch: 6| Step: 2
Training loss: 2.5605785846710205
Validation loss: 2.024113953113556

Epoch: 6| Step: 3
Training loss: 1.927233099937439
Validation loss: 2.013714611530304

Epoch: 6| Step: 4
Training loss: 2.5187153816223145
Validation loss: 2.022839605808258

Epoch: 6| Step: 5
Training loss: 1.9149850606918335
Validation loss: 2.020898222923279

Epoch: 6| Step: 6
Training loss: 1.8204299211502075
Validation loss: 2.0200118025143943

Epoch: 6| Step: 7
Training loss: 2.1033225059509277
Validation loss: 2.0214969714482627

Epoch: 6| Step: 8
Training loss: 1.5931382179260254
Validation loss: 2.031557023525238

Epoch: 6| Step: 9
Training loss: 2.0672638416290283
Validation loss: 2.0309582352638245

Epoch: 6| Step: 10
Training loss: 2.2076034545898438
Validation loss: 2.0355383356412253

Epoch: 6| Step: 11
Training loss: 1.6544663906097412
Validation loss: 2.0294927755991616

Epoch: 6| Step: 12
Training loss: 2.2122113704681396
Validation loss: 2.0347607731819153

Epoch: 6| Step: 13
Training loss: 2.3264148235321045
Validation loss: 2.041754881540934

Epoch: 111| Step: 0
Training loss: 2.25813364982605
Validation loss: 2.055339733759562

Epoch: 6| Step: 1
Training loss: 1.9262927770614624
Validation loss: 2.058599869410197

Epoch: 6| Step: 2
Training loss: 2.250788927078247
Validation loss: 2.059851964314779

Epoch: 6| Step: 3
Training loss: 2.365927219390869
Validation loss: 2.056796133518219

Epoch: 6| Step: 4
Training loss: 1.6261976957321167
Validation loss: 2.0618473291397095

Epoch: 6| Step: 5
Training loss: 2.2133593559265137
Validation loss: 2.0571264227231345

Epoch: 6| Step: 6
Training loss: 2.0094854831695557
Validation loss: 2.0492905974388123

Epoch: 6| Step: 7
Training loss: 2.389497995376587
Validation loss: 2.0413864254951477

Epoch: 6| Step: 8
Training loss: 2.0936336517333984
Validation loss: 2.0464429457982383

Epoch: 6| Step: 9
Training loss: 2.106245994567871
Validation loss: 2.0449583530426025

Epoch: 6| Step: 10
Training loss: 2.0722620487213135
Validation loss: 2.040625194708506

Epoch: 6| Step: 11
Training loss: 1.8187590837478638
Validation loss: 2.040156066417694

Epoch: 6| Step: 12
Training loss: 2.1725878715515137
Validation loss: 2.036481241385142

Epoch: 6| Step: 13
Training loss: 1.7961853742599487
Validation loss: 2.039313793182373

Epoch: 112| Step: 0
Training loss: 2.7841601371765137
Validation loss: 2.022796948750814

Epoch: 6| Step: 1
Training loss: 2.327709913253784
Validation loss: 2.029034197330475

Epoch: 6| Step: 2
Training loss: 1.388749361038208
Validation loss: 2.029825488726298

Epoch: 6| Step: 3
Training loss: 2.1971096992492676
Validation loss: 2.0311098098754883

Epoch: 6| Step: 4
Training loss: 2.454103469848633
Validation loss: 2.0271372397740683

Epoch: 6| Step: 5
Training loss: 2.0046725273132324
Validation loss: 2.028291702270508

Epoch: 6| Step: 6
Training loss: 1.4189422130584717
Validation loss: 2.024934768676758

Epoch: 6| Step: 7
Training loss: 2.3148481845855713
Validation loss: 2.0269330938657126

Epoch: 6| Step: 8
Training loss: 1.9754610061645508
Validation loss: 2.0303757588068643

Epoch: 6| Step: 9
Training loss: 2.612990617752075
Validation loss: 2.027484178543091

Epoch: 6| Step: 10
Training loss: 2.1690056324005127
Validation loss: 2.027583122253418

Epoch: 6| Step: 11
Training loss: 1.3474504947662354
Validation loss: 2.0373120506604514

Epoch: 6| Step: 12
Training loss: 2.2091879844665527
Validation loss: 2.0216914216677346

Epoch: 6| Step: 13
Training loss: 2.049572229385376
Validation loss: 2.03769858678182

Epoch: 113| Step: 0
Training loss: 2.27816104888916
Validation loss: 2.0389596621195474

Epoch: 6| Step: 1
Training loss: 2.3641037940979004
Validation loss: 2.0438721974690757

Epoch: 6| Step: 2
Training loss: 2.6584599018096924
Validation loss: 2.0521640181541443

Epoch: 6| Step: 3
Training loss: 1.8857365846633911
Validation loss: 2.039609968662262

Epoch: 6| Step: 4
Training loss: 2.3042759895324707
Validation loss: 2.0334324638048806

Epoch: 6| Step: 5
Training loss: 2.169377565383911
Validation loss: 2.039210041364034

Epoch: 6| Step: 6
Training loss: 2.4508566856384277
Validation loss: 2.0380191604296365

Epoch: 6| Step: 7
Training loss: 1.5947117805480957
Validation loss: 2.0317793687184653

Epoch: 6| Step: 8
Training loss: 1.5355685949325562
Validation loss: 2.0429845054944358

Epoch: 6| Step: 9
Training loss: 1.7654470205307007
Validation loss: 2.0331162214279175

Epoch: 6| Step: 10
Training loss: 2.380950689315796
Validation loss: 2.0463391542434692

Epoch: 6| Step: 11
Training loss: 2.1512019634246826
Validation loss: 2.046418050924937

Epoch: 6| Step: 12
Training loss: 1.826338291168213
Validation loss: 2.043062686920166

Epoch: 6| Step: 13
Training loss: 1.9123427867889404
Validation loss: 2.0357948541641235

Epoch: 114| Step: 0
Training loss: 2.205404758453369
Validation loss: 2.0331269900004068

Epoch: 6| Step: 1
Training loss: 2.27028751373291
Validation loss: 2.037459452946981

Epoch: 6| Step: 2
Training loss: 2.2277088165283203
Validation loss: 2.0359967152277627

Epoch: 6| Step: 3
Training loss: 2.3101866245269775
Validation loss: 2.040652354558309

Epoch: 6| Step: 4
Training loss: 1.6814308166503906
Validation loss: 2.037188470363617

Epoch: 6| Step: 5
Training loss: 1.984086513519287
Validation loss: 2.0361565947532654

Epoch: 6| Step: 6
Training loss: 1.9980576038360596
Validation loss: 2.0384379625320435

Epoch: 6| Step: 7
Training loss: 2.1401214599609375
Validation loss: 2.032534658908844

Epoch: 6| Step: 8
Training loss: 2.139268398284912
Validation loss: 2.043026546637217

Epoch: 6| Step: 9
Training loss: 2.3005740642547607
Validation loss: 2.0318016409873962

Epoch: 6| Step: 10
Training loss: 1.9434305429458618
Validation loss: 2.026838699976603

Epoch: 6| Step: 11
Training loss: 1.7135601043701172
Validation loss: 2.0307149291038513

Epoch: 6| Step: 12
Training loss: 2.039952278137207
Validation loss: 2.0398969451586404

Epoch: 6| Step: 13
Training loss: 2.0721592903137207
Validation loss: 2.0250519712766013

Epoch: 115| Step: 0
Training loss: 2.178379535675049
Validation loss: 2.035486360390981

Epoch: 6| Step: 1
Training loss: 1.69056236743927
Validation loss: 2.0347434282302856

Epoch: 6| Step: 2
Training loss: 2.105421543121338
Validation loss: 2.036526401837667

Epoch: 6| Step: 3
Training loss: 2.0397253036499023
Validation loss: 2.0435140132904053

Epoch: 6| Step: 4
Training loss: 2.0794405937194824
Validation loss: 2.037860929965973

Epoch: 6| Step: 5
Training loss: 2.2430062294006348
Validation loss: 2.0297410090764365

Epoch: 6| Step: 6
Training loss: 2.1085877418518066
Validation loss: 2.0313225785891214

Epoch: 6| Step: 7
Training loss: 2.044159412384033
Validation loss: 2.026907126108805

Epoch: 6| Step: 8
Training loss: 2.954802989959717
Validation loss: 2.023622751235962

Epoch: 6| Step: 9
Training loss: 1.5817004442214966
Validation loss: 2.0354288617769876

Epoch: 6| Step: 10
Training loss: 2.426135540008545
Validation loss: 2.038594345251719

Epoch: 6| Step: 11
Training loss: 2.3478407859802246
Validation loss: 2.034945011138916

Epoch: 6| Step: 12
Training loss: 1.8791342973709106
Validation loss: 2.0299721558888755

Epoch: 6| Step: 13
Training loss: 1.3878235816955566
Validation loss: 2.038488030433655

Epoch: 116| Step: 0
Training loss: 2.0759940147399902
Validation loss: 2.0338980754216514

Epoch: 6| Step: 1
Training loss: 1.90478515625
Validation loss: 2.0316705902417502

Epoch: 6| Step: 2
Training loss: 2.184661626815796
Validation loss: 2.0315778851509094

Epoch: 6| Step: 3
Training loss: 1.3445329666137695
Validation loss: 2.0340755184491477

Epoch: 6| Step: 4
Training loss: 2.1764934062957764
Validation loss: 2.0405406753222146

Epoch: 6| Step: 5
Training loss: 2.2889678478240967
Validation loss: 2.048148254553477

Epoch: 6| Step: 6
Training loss: 2.5441434383392334
Validation loss: 2.0362077951431274

Epoch: 6| Step: 7
Training loss: 2.085944175720215
Validation loss: 2.041751245657603

Epoch: 6| Step: 8
Training loss: 2.269284248352051
Validation loss: 2.03127384185791

Epoch: 6| Step: 9
Training loss: 2.3468282222747803
Validation loss: 2.032011409600576

Epoch: 6| Step: 10
Training loss: 2.006199598312378
Validation loss: 2.0287108222643533

Epoch: 6| Step: 11
Training loss: 2.64062237739563
Validation loss: 2.0346908370653787

Epoch: 6| Step: 12
Training loss: 1.9653823375701904
Validation loss: 2.0245644251505532

Epoch: 6| Step: 13
Training loss: 1.297240972518921
Validation loss: 2.0271852811177573

Epoch: 117| Step: 0
Training loss: 1.912869930267334
Validation loss: 2.01871927579244

Epoch: 6| Step: 1
Training loss: 2.561352252960205
Validation loss: 2.031281133492788

Epoch: 6| Step: 2
Training loss: 2.2817063331604004
Validation loss: 2.042035222053528

Epoch: 6| Step: 3
Training loss: 2.2946228981018066
Validation loss: 2.043742914994558

Epoch: 6| Step: 4
Training loss: 2.101656675338745
Validation loss: 2.0328240593274436

Epoch: 6| Step: 5
Training loss: 1.683043122291565
Validation loss: 2.0263192653656006

Epoch: 6| Step: 6
Training loss: 2.203955888748169
Validation loss: 2.0276095072428384

Epoch: 6| Step: 7
Training loss: 2.2071785926818848
Validation loss: 2.0186623334884644

Epoch: 6| Step: 8
Training loss: 2.080362319946289
Validation loss: 2.0144306421279907

Epoch: 6| Step: 9
Training loss: 1.9068917036056519
Validation loss: 2.0235931277275085

Epoch: 6| Step: 10
Training loss: 1.6262978315353394
Validation loss: 2.026518185933431

Epoch: 6| Step: 11
Training loss: 2.0189321041107178
Validation loss: 2.027888317902883

Epoch: 6| Step: 12
Training loss: 1.7490191459655762
Validation loss: 2.0275975863138833

Epoch: 6| Step: 13
Training loss: 2.6736631393432617
Validation loss: 2.0208583076794944

Epoch: 118| Step: 0
Training loss: 1.6922770738601685
Validation loss: 2.0280381043752036

Epoch: 6| Step: 1
Training loss: 2.5535736083984375
Validation loss: 2.0375086267789206

Epoch: 6| Step: 2
Training loss: 1.9629688262939453
Validation loss: 2.0296307603518167

Epoch: 6| Step: 3
Training loss: 2.759026050567627
Validation loss: 2.037538766860962

Epoch: 6| Step: 4
Training loss: 2.6217894554138184
Validation loss: 2.0361199577649436

Epoch: 6| Step: 5
Training loss: 1.7262415885925293
Validation loss: 2.0365171432495117

Epoch: 6| Step: 6
Training loss: 2.432351589202881
Validation loss: 2.036187171936035

Epoch: 6| Step: 7
Training loss: 2.1490886211395264
Validation loss: 2.0287926197052

Epoch: 6| Step: 8
Training loss: 1.9814579486846924
Validation loss: 2.0329394539197287

Epoch: 6| Step: 9
Training loss: 1.3111882209777832
Validation loss: 2.036124527454376

Epoch: 6| Step: 10
Training loss: 1.7629355192184448
Validation loss: 2.0452489654223123

Epoch: 6| Step: 11
Training loss: 2.1504108905792236
Validation loss: 2.048024833202362

Epoch: 6| Step: 12
Training loss: 2.46488618850708
Validation loss: 2.0535913705825806

Epoch: 6| Step: 13
Training loss: 1.713403344154358
Validation loss: 2.0567760864893594

Epoch: 119| Step: 0
Training loss: 1.838051199913025
Validation loss: 2.033431828022003

Epoch: 6| Step: 1
Training loss: 2.2074756622314453
Validation loss: 2.043430745601654

Epoch: 6| Step: 2
Training loss: 2.386033535003662
Validation loss: 2.041532814502716

Epoch: 6| Step: 3
Training loss: 1.5606720447540283
Validation loss: 2.037774900595347

Epoch: 6| Step: 4
Training loss: 1.8694195747375488
Validation loss: 2.041029135386149

Epoch: 6| Step: 5
Training loss: 2.231520414352417
Validation loss: 2.0329431295394897

Epoch: 6| Step: 6
Training loss: 2.448817014694214
Validation loss: 2.0326902667681375

Epoch: 6| Step: 7
Training loss: 1.915956735610962
Validation loss: 2.040289024511973

Epoch: 6| Step: 8
Training loss: 2.3128981590270996
Validation loss: 2.033605953057607

Epoch: 6| Step: 9
Training loss: 2.549445152282715
Validation loss: 2.0403581062952676

Epoch: 6| Step: 10
Training loss: 1.9534614086151123
Validation loss: 2.043259382247925

Epoch: 6| Step: 11
Training loss: 1.7831103801727295
Validation loss: 2.045083463191986

Epoch: 6| Step: 12
Training loss: 1.9941495656967163
Validation loss: 2.051144540309906

Epoch: 6| Step: 13
Training loss: 2.037167549133301
Validation loss: 2.0383289655049643

Epoch: 120| Step: 0
Training loss: 2.07766056060791
Validation loss: 2.034260173638662

Epoch: 6| Step: 1
Training loss: 1.642574667930603
Validation loss: 2.0509184201558432

Epoch: 6| Step: 2
Training loss: 2.4731850624084473
Validation loss: 2.03538970152537

Epoch: 6| Step: 3
Training loss: 2.060061454772949
Validation loss: 2.031285127003988

Epoch: 6| Step: 4
Training loss: 2.2110495567321777
Validation loss: 2.0474230647087097

Epoch: 6| Step: 5
Training loss: 2.181730270385742
Validation loss: 2.036868413289388

Epoch: 6| Step: 6
Training loss: 2.514458417892456
Validation loss: 2.0378669102986655

Epoch: 6| Step: 7
Training loss: 2.0207958221435547
Validation loss: 2.0549496610959372

Epoch: 6| Step: 8
Training loss: 2.0422234535217285
Validation loss: 2.033125857512156

Epoch: 6| Step: 9
Training loss: 1.8700921535491943
Validation loss: 2.0334540009498596

Epoch: 6| Step: 10
Training loss: 1.9105393886566162
Validation loss: 2.039648254712423

Epoch: 6| Step: 11
Training loss: 1.737564206123352
Validation loss: 2.0430041750272117

Epoch: 6| Step: 12
Training loss: 2.478595733642578
Validation loss: 2.0339471300443015

Epoch: 6| Step: 13
Training loss: 2.0119454860687256
Validation loss: 2.030994455019633

Epoch: 121| Step: 0
Training loss: 1.9141290187835693
Validation loss: 2.0267759760220847

Epoch: 6| Step: 1
Training loss: 2.146030902862549
Validation loss: 2.024876435597738

Epoch: 6| Step: 2
Training loss: 1.9211182594299316
Validation loss: 2.0270790656407676

Epoch: 6| Step: 3
Training loss: 2.3223845958709717
Validation loss: 2.0282368063926697

Epoch: 6| Step: 4
Training loss: 1.5197054147720337
Validation loss: 2.0182793140411377

Epoch: 6| Step: 5
Training loss: 1.4870595932006836
Validation loss: 2.0252005060513816

Epoch: 6| Step: 6
Training loss: 1.9959378242492676
Validation loss: 2.022620220979055

Epoch: 6| Step: 7
Training loss: 1.8107330799102783
Validation loss: 2.0253174702326455

Epoch: 6| Step: 8
Training loss: 2.4028446674346924
Validation loss: 2.021248002847036

Epoch: 6| Step: 9
Training loss: 2.2901511192321777
Validation loss: 2.031665543715159

Epoch: 6| Step: 10
Training loss: 2.0642223358154297
Validation loss: 2.0273457566897073

Epoch: 6| Step: 11
Training loss: 2.328923225402832
Validation loss: 2.022066116333008

Epoch: 6| Step: 12
Training loss: 2.7007131576538086
Validation loss: 2.0335808595021567

Epoch: 6| Step: 13
Training loss: 2.1578197479248047
Validation loss: 2.0411544839541116

Epoch: 122| Step: 0
Training loss: 1.9851529598236084
Validation loss: 2.028824965159098

Epoch: 6| Step: 1
Training loss: 2.635005474090576
Validation loss: 2.0393864512443542

Epoch: 6| Step: 2
Training loss: 2.2844226360321045
Validation loss: 2.0297210415204368

Epoch: 6| Step: 3
Training loss: 1.9222620725631714
Validation loss: 2.0344140330950418

Epoch: 6| Step: 4
Training loss: 2.257561445236206
Validation loss: 2.0175668398539224

Epoch: 6| Step: 5
Training loss: 1.585139274597168
Validation loss: 2.0150489807128906

Epoch: 6| Step: 6
Training loss: 1.975090742111206
Validation loss: 2.015664597352346

Epoch: 6| Step: 7
Training loss: 2.0691208839416504
Validation loss: 2.0144280989964805

Epoch: 6| Step: 8
Training loss: 1.7621747255325317
Validation loss: 2.0152176221211753

Epoch: 6| Step: 9
Training loss: 2.013486385345459
Validation loss: 2.0158944725990295

Epoch: 6| Step: 10
Training loss: 2.608546018600464
Validation loss: 2.021817207336426

Epoch: 6| Step: 11
Training loss: 1.9666435718536377
Validation loss: 2.0192975997924805

Epoch: 6| Step: 12
Training loss: 1.9764511585235596
Validation loss: 2.0169219374656677

Epoch: 6| Step: 13
Training loss: 1.9326975345611572
Validation loss: 2.0221911470095315

Epoch: 123| Step: 0
Training loss: 2.555837631225586
Validation loss: 2.028754731019338

Epoch: 6| Step: 1
Training loss: 1.780417799949646
Validation loss: 2.0255250334739685

Epoch: 6| Step: 2
Training loss: 1.629225730895996
Validation loss: 2.020314792792002

Epoch: 6| Step: 3
Training loss: 2.1487512588500977
Validation loss: 2.0284772713979087

Epoch: 6| Step: 4
Training loss: 2.4632205963134766
Validation loss: 2.019650101661682

Epoch: 6| Step: 5
Training loss: 2.054481029510498
Validation loss: 2.03131494919459

Epoch: 6| Step: 6
Training loss: 2.2615485191345215
Validation loss: 2.02943362792333

Epoch: 6| Step: 7
Training loss: 1.9329824447631836
Validation loss: 2.0303843220074973

Epoch: 6| Step: 8
Training loss: 2.131199359893799
Validation loss: 2.037044584751129

Epoch: 6| Step: 9
Training loss: 1.5276466608047485
Validation loss: 2.024529278278351

Epoch: 6| Step: 10
Training loss: 2.01578950881958
Validation loss: 2.0380693674087524

Epoch: 6| Step: 11
Training loss: 2.1163041591644287
Validation loss: 2.0294978817303977

Epoch: 6| Step: 12
Training loss: 2.5352723598480225
Validation loss: 2.041842043399811

Epoch: 6| Step: 13
Training loss: 1.8627514839172363
Validation loss: 2.046372393767039

Epoch: 124| Step: 0
Training loss: 2.0718789100646973
Validation loss: 2.037404636542002

Epoch: 6| Step: 1
Training loss: 2.2330713272094727
Validation loss: 2.0426979660987854

Epoch: 6| Step: 2
Training loss: 2.2568860054016113
Validation loss: 2.044055243333181

Epoch: 6| Step: 3
Training loss: 2.2285375595092773
Validation loss: 2.039911925792694

Epoch: 6| Step: 4
Training loss: 1.6096179485321045
Validation loss: 2.0448410709698996

Epoch: 6| Step: 5
Training loss: 2.1981117725372314
Validation loss: 2.038373033205668

Epoch: 6| Step: 6
Training loss: 1.8679356575012207
Validation loss: 2.033678730328878

Epoch: 6| Step: 7
Training loss: 2.2717223167419434
Validation loss: 2.039545714855194

Epoch: 6| Step: 8
Training loss: 2.420156478881836
Validation loss: 2.0371994773546853

Epoch: 6| Step: 9
Training loss: 1.7955703735351562
Validation loss: 2.0450470646222434

Epoch: 6| Step: 10
Training loss: 1.6401913166046143
Validation loss: 2.0313331683476767

Epoch: 6| Step: 11
Training loss: 2.1197659969329834
Validation loss: 2.039988120396932

Epoch: 6| Step: 12
Training loss: 2.3810853958129883
Validation loss: 2.044707775115967

Epoch: 6| Step: 13
Training loss: 1.6329106092453003
Validation loss: 2.039701521396637

Epoch: 125| Step: 0
Training loss: 1.7132081985473633
Validation loss: 2.053658664226532

Epoch: 6| Step: 1
Training loss: 2.5649876594543457
Validation loss: 2.0447826385498047

Epoch: 6| Step: 2
Training loss: 1.4432735443115234
Validation loss: 2.0502684712409973

Epoch: 6| Step: 3
Training loss: 2.1185317039489746
Validation loss: 2.0542723139127097

Epoch: 6| Step: 4
Training loss: 2.454753875732422
Validation loss: 2.053197979927063

Epoch: 6| Step: 5
Training loss: 1.9578766822814941
Validation loss: 2.043744703133901

Epoch: 6| Step: 6
Training loss: 2.155988931655884
Validation loss: 2.043896516164144

Epoch: 6| Step: 7
Training loss: 2.1377170085906982
Validation loss: 2.0342233777046204

Epoch: 6| Step: 8
Training loss: 2.015599012374878
Validation loss: 2.03686132033666

Epoch: 6| Step: 9
Training loss: 2.24641752243042
Validation loss: 2.04734601577123

Epoch: 6| Step: 10
Training loss: 1.957332730293274
Validation loss: 2.0406143267949424

Epoch: 6| Step: 11
Training loss: 1.8130606412887573
Validation loss: 2.0452680587768555

Epoch: 6| Step: 12
Training loss: 2.0777299404144287
Validation loss: 2.0380672216415405

Epoch: 6| Step: 13
Training loss: 2.0939669609069824
Validation loss: 2.0426525274912515

Epoch: 126| Step: 0
Training loss: 2.06598162651062
Validation loss: 2.040399650732676

Epoch: 6| Step: 1
Training loss: 1.5841718912124634
Validation loss: 2.0390234192212424

Epoch: 6| Step: 2
Training loss: 2.454082727432251
Validation loss: 2.0297714471817017

Epoch: 6| Step: 3
Training loss: 2.1237831115722656
Validation loss: 2.0446019172668457

Epoch: 6| Step: 4
Training loss: 1.974648356437683
Validation loss: 2.025252719720205

Epoch: 6| Step: 5
Training loss: 1.9796690940856934
Validation loss: 2.047043561935425

Epoch: 6| Step: 6
Training loss: 2.1590182781219482
Validation loss: 2.0460699796676636

Epoch: 6| Step: 7
Training loss: 2.179706573486328
Validation loss: 2.0481394131978354

Epoch: 6| Step: 8
Training loss: 1.8388855457305908
Validation loss: 2.0405702193578086

Epoch: 6| Step: 9
Training loss: 1.4521088600158691
Validation loss: 2.0492778619130454

Epoch: 6| Step: 10
Training loss: 2.211264133453369
Validation loss: 2.0570526719093323

Epoch: 6| Step: 11
Training loss: 2.441239356994629
Validation loss: 2.0453994472821555

Epoch: 6| Step: 12
Training loss: 2.4432246685028076
Validation loss: 2.039332548777262

Epoch: 6| Step: 13
Training loss: 1.8024241924285889
Validation loss: 2.0487390756607056

Epoch: 127| Step: 0
Training loss: 2.266011953353882
Validation loss: 2.0438016255696616

Epoch: 6| Step: 1
Training loss: 2.2720227241516113
Validation loss: 2.040819843610128

Epoch: 6| Step: 2
Training loss: 1.564622163772583
Validation loss: 2.0531648993492126

Epoch: 6| Step: 3
Training loss: 1.9166271686553955
Validation loss: 2.0402963161468506

Epoch: 6| Step: 4
Training loss: 1.674636960029602
Validation loss: 2.0352123975753784

Epoch: 6| Step: 5
Training loss: 1.8483352661132812
Validation loss: 2.0424041946729026

Epoch: 6| Step: 6
Training loss: 2.2386837005615234
Validation loss: 2.0430537462234497

Epoch: 6| Step: 7
Training loss: 1.4717546701431274
Validation loss: 2.0408679842948914

Epoch: 6| Step: 8
Training loss: 2.3968915939331055
Validation loss: 2.022939840952555

Epoch: 6| Step: 9
Training loss: 2.554037570953369
Validation loss: 2.026187539100647

Epoch: 6| Step: 10
Training loss: 2.2199490070343018
Validation loss: 2.0270566940307617

Epoch: 6| Step: 11
Training loss: 2.1770341396331787
Validation loss: 2.0327093998591104

Epoch: 6| Step: 12
Training loss: 2.2818679809570312
Validation loss: 2.0229846636454263

Epoch: 6| Step: 13
Training loss: 1.8575677871704102
Validation loss: 2.0264951388041177

Epoch: 128| Step: 0
Training loss: 2.0821328163146973
Validation loss: 2.0226725339889526

Epoch: 6| Step: 1
Training loss: 2.832023859024048
Validation loss: 2.0250791907310486

Epoch: 6| Step: 2
Training loss: 2.079922914505005
Validation loss: 2.024918854236603

Epoch: 6| Step: 3
Training loss: 1.8503698110580444
Validation loss: 2.024509390195211

Epoch: 6| Step: 4
Training loss: 2.279987335205078
Validation loss: 2.0216368436813354

Epoch: 6| Step: 5
Training loss: 1.9954801797866821
Validation loss: 2.0222990115483603

Epoch: 6| Step: 6
Training loss: 2.112107276916504
Validation loss: 2.031834304332733

Epoch: 6| Step: 7
Training loss: 2.4870710372924805
Validation loss: 2.0277873476346335

Epoch: 6| Step: 8
Training loss: 1.2364692687988281
Validation loss: 2.0267318884531655

Epoch: 6| Step: 9
Training loss: 1.9420512914657593
Validation loss: 2.0364731550216675

Epoch: 6| Step: 10
Training loss: 2.5012669563293457
Validation loss: 2.036111811796824

Epoch: 6| Step: 11
Training loss: 1.997260332107544
Validation loss: 2.05636594692866

Epoch: 6| Step: 12
Training loss: 2.1224591732025146
Validation loss: 2.0576506853103638

Epoch: 6| Step: 13
Training loss: 1.4641046524047852
Validation loss: 2.0550184845924377

Epoch: 129| Step: 0
Training loss: 1.80498206615448
Validation loss: 2.0464669863382974

Epoch: 6| Step: 1
Training loss: 2.3815999031066895
Validation loss: 2.0476429065068564

Epoch: 6| Step: 2
Training loss: 2.137965679168701
Validation loss: 2.0316646496454873

Epoch: 6| Step: 3
Training loss: 2.300480842590332
Validation loss: 2.0383940736452737

Epoch: 6| Step: 4
Training loss: 1.8435832262039185
Validation loss: 2.028523067633311

Epoch: 6| Step: 5
Training loss: 1.8224568367004395
Validation loss: 2.0299407641092935

Epoch: 6| Step: 6
Training loss: 2.3181464672088623
Validation loss: 2.033357878526052

Epoch: 6| Step: 7
Training loss: 1.7146719694137573
Validation loss: 2.0353605349858603

Epoch: 6| Step: 8
Training loss: 2.0964536666870117
Validation loss: 2.041950821876526

Epoch: 6| Step: 9
Training loss: 2.3092145919799805
Validation loss: 2.0348403453826904

Epoch: 6| Step: 10
Training loss: 1.9617664813995361
Validation loss: 2.028108994166056

Epoch: 6| Step: 11
Training loss: 2.2111029624938965
Validation loss: 2.0498950481414795

Epoch: 6| Step: 12
Training loss: 2.0838465690612793
Validation loss: 2.0510999957720437

Epoch: 6| Step: 13
Training loss: 1.6085234880447388
Validation loss: 2.065725346406301

Epoch: 130| Step: 0
Training loss: 2.2653064727783203
Validation loss: 2.045653541882833

Epoch: 6| Step: 1
Training loss: 2.06819486618042
Validation loss: 2.0559072494506836

Epoch: 6| Step: 2
Training loss: 1.7652720212936401
Validation loss: 2.0634445945421853

Epoch: 6| Step: 3
Training loss: 1.8883806467056274
Validation loss: 2.0571909149487815

Epoch: 6| Step: 4
Training loss: 1.8661246299743652
Validation loss: 2.045690596103668

Epoch: 6| Step: 5
Training loss: 2.0855886936187744
Validation loss: 2.051320652167002

Epoch: 6| Step: 6
Training loss: 2.527566432952881
Validation loss: 2.0339226524035134

Epoch: 6| Step: 7
Training loss: 1.719075322151184
Validation loss: 2.0443439284960427

Epoch: 6| Step: 8
Training loss: 2.0163300037384033
Validation loss: 2.047900438308716

Epoch: 6| Step: 9
Training loss: 1.9213790893554688
Validation loss: 2.0347039699554443

Epoch: 6| Step: 10
Training loss: 2.284771203994751
Validation loss: 2.0436944365501404

Epoch: 6| Step: 11
Training loss: 2.118222951889038
Validation loss: 2.045722802480062

Epoch: 6| Step: 12
Training loss: 1.9909591674804688
Validation loss: 2.03890860080719

Epoch: 6| Step: 13
Training loss: 2.0947368144989014
Validation loss: 2.0523473620414734

Epoch: 131| Step: 0
Training loss: 2.2704837322235107
Validation loss: 2.0454509258270264

Epoch: 6| Step: 1
Training loss: 1.9892563819885254
Validation loss: 2.0612975358963013

Epoch: 6| Step: 2
Training loss: 1.8417725563049316
Validation loss: 2.065869172414144

Epoch: 6| Step: 3
Training loss: 1.9259127378463745
Validation loss: 2.0653788248697915

Epoch: 6| Step: 4
Training loss: 1.8395553827285767
Validation loss: 2.0614819129308066

Epoch: 6| Step: 5
Training loss: 2.0005075931549072
Validation loss: 2.059548834959666

Epoch: 6| Step: 6
Training loss: 2.04974102973938
Validation loss: 2.0544055104255676

Epoch: 6| Step: 7
Training loss: 1.7929600477218628
Validation loss: 2.0609575112660727

Epoch: 6| Step: 8
Training loss: 1.6272386312484741
Validation loss: 2.0619252920150757

Epoch: 6| Step: 9
Training loss: 2.0858113765716553
Validation loss: 2.0561975240707397

Epoch: 6| Step: 10
Training loss: 2.116518974304199
Validation loss: 2.0617953141530356

Epoch: 6| Step: 11
Training loss: 2.037566900253296
Validation loss: 2.0629853208859763

Epoch: 6| Step: 12
Training loss: 2.1166841983795166
Validation loss: 2.051730970541636

Epoch: 6| Step: 13
Training loss: 2.9775500297546387
Validation loss: 2.0470839540163674

Epoch: 132| Step: 0
Training loss: 1.904068112373352
Validation loss: 2.038488825162252

Epoch: 6| Step: 1
Training loss: 2.0107016563415527
Validation loss: 2.05176834265391

Epoch: 6| Step: 2
Training loss: 2.4676015377044678
Validation loss: 2.0567832787831626

Epoch: 6| Step: 3
Training loss: 1.9333300590515137
Validation loss: 2.049311359723409

Epoch: 6| Step: 4
Training loss: 1.5843158960342407
Validation loss: 2.059348781903585

Epoch: 6| Step: 5
Training loss: 2.3562862873077393
Validation loss: 2.0612242023150125

Epoch: 6| Step: 6
Training loss: 1.1202633380889893
Validation loss: 2.047028680642446

Epoch: 6| Step: 7
Training loss: 1.593691110610962
Validation loss: 2.0645704666773477

Epoch: 6| Step: 8
Training loss: 2.6610794067382812
Validation loss: 2.0661304195721946

Epoch: 6| Step: 9
Training loss: 2.0237553119659424
Validation loss: 2.0695481499036155

Epoch: 6| Step: 10
Training loss: 1.8836634159088135
Validation loss: 2.0772897005081177

Epoch: 6| Step: 11
Training loss: 2.4383738040924072
Validation loss: 2.096015751361847

Epoch: 6| Step: 12
Training loss: 2.374241352081299
Validation loss: 2.0779664119084678

Epoch: 6| Step: 13
Training loss: 2.433110237121582
Validation loss: 2.0788914561271667

Epoch: 133| Step: 0
Training loss: 1.9414082765579224
Validation loss: 2.073432981967926

Epoch: 6| Step: 1
Training loss: 2.236158847808838
Validation loss: 2.0645082592964172

Epoch: 6| Step: 2
Training loss: 2.5969924926757812
Validation loss: 2.059113701184591

Epoch: 6| Step: 3
Training loss: 1.9499846696853638
Validation loss: 2.0650991598765054

Epoch: 6| Step: 4
Training loss: 1.8500828742980957
Validation loss: 2.0600364009539285

Epoch: 6| Step: 5
Training loss: 2.519659996032715
Validation loss: 2.0709258119265237

Epoch: 6| Step: 6
Training loss: 2.411099910736084
Validation loss: 2.052565316359202

Epoch: 6| Step: 7
Training loss: 1.836841106414795
Validation loss: 2.054170866807302

Epoch: 6| Step: 8
Training loss: 1.9775772094726562
Validation loss: 2.053000887235006

Epoch: 6| Step: 9
Training loss: 1.800940990447998
Validation loss: 2.0556487242380777

Epoch: 6| Step: 10
Training loss: 1.7394686937332153
Validation loss: 2.054306944211324

Epoch: 6| Step: 11
Training loss: 1.9459577798843384
Validation loss: 2.055891235669454

Epoch: 6| Step: 12
Training loss: 2.076324462890625
Validation loss: 2.0485887130101523

Epoch: 6| Step: 13
Training loss: 1.454388976097107
Validation loss: 2.0638778805732727

Epoch: 134| Step: 0
Training loss: 2.4182486534118652
Validation loss: 2.077048599720001

Epoch: 6| Step: 1
Training loss: 2.058713436126709
Validation loss: 2.064874211947123

Epoch: 6| Step: 2
Training loss: 1.413906216621399
Validation loss: 2.0422322948773703

Epoch: 6| Step: 3
Training loss: 2.1865992546081543
Validation loss: 2.0501937866210938

Epoch: 6| Step: 4
Training loss: 1.7081458568572998
Validation loss: 2.0537120501200357

Epoch: 6| Step: 5
Training loss: 2.280888795852661
Validation loss: 2.0447486639022827

Epoch: 6| Step: 6
Training loss: 2.1176626682281494
Validation loss: 2.049255927403768

Epoch: 6| Step: 7
Training loss: 2.5196337699890137
Validation loss: 2.0495956341425576

Epoch: 6| Step: 8
Training loss: 2.166132926940918
Validation loss: 2.0441836516062417

Epoch: 6| Step: 9
Training loss: 1.9759641885757446
Validation loss: 2.0437158147493997

Epoch: 6| Step: 10
Training loss: 2.4554083347320557
Validation loss: 2.039929986000061

Epoch: 6| Step: 11
Training loss: 2.3366222381591797
Validation loss: 2.0402053197224936

Epoch: 6| Step: 12
Training loss: 1.6929755210876465
Validation loss: 2.0537603894869485

Epoch: 6| Step: 13
Training loss: 1.4616880416870117
Validation loss: 2.0632285277048745

Epoch: 135| Step: 0
Training loss: 2.768296480178833
Validation loss: 2.0418334205945334

Epoch: 6| Step: 1
Training loss: 1.8079955577850342
Validation loss: 2.0480599204699197

Epoch: 6| Step: 2
Training loss: 2.240291118621826
Validation loss: 2.03841495513916

Epoch: 6| Step: 3
Training loss: 1.9638886451721191
Validation loss: 2.040903608004252

Epoch: 6| Step: 4
Training loss: 2.030709743499756
Validation loss: 2.039456049601237

Epoch: 6| Step: 5
Training loss: 2.47617244720459
Validation loss: 2.0414262811342874

Epoch: 6| Step: 6
Training loss: 1.8012959957122803
Validation loss: 2.0436026056607566

Epoch: 6| Step: 7
Training loss: 1.8751760721206665
Validation loss: 2.0382840832074485

Epoch: 6| Step: 8
Training loss: 1.9650083780288696
Validation loss: 2.0405845046043396

Epoch: 6| Step: 9
Training loss: 2.0695624351501465
Validation loss: 2.042602320512136

Epoch: 6| Step: 10
Training loss: 1.734240174293518
Validation loss: 2.0615968108177185

Epoch: 6| Step: 11
Training loss: 1.8602778911590576
Validation loss: 2.063363174597422

Epoch: 6| Step: 12
Training loss: 1.6627073287963867
Validation loss: 2.0913803974787393

Epoch: 6| Step: 13
Training loss: 2.4953041076660156
Validation loss: 2.087097922960917

Epoch: 136| Step: 0
Training loss: 2.122140407562256
Validation loss: 2.084310750166575

Epoch: 6| Step: 1
Training loss: 2.2795522212982178
Validation loss: 2.0678115288416543

Epoch: 6| Step: 2
Training loss: 2.3174831867218018
Validation loss: 2.062171220779419

Epoch: 6| Step: 3
Training loss: 2.31136417388916
Validation loss: 2.054129699865977

Epoch: 6| Step: 4
Training loss: 1.7950530052185059
Validation loss: 2.0575505097707114

Epoch: 6| Step: 5
Training loss: 2.106003761291504
Validation loss: 2.056262214978536

Epoch: 6| Step: 6
Training loss: 1.6102921962738037
Validation loss: 2.0438872973124185

Epoch: 6| Step: 7
Training loss: 2.098361015319824
Validation loss: 2.05739426612854

Epoch: 6| Step: 8
Training loss: 2.6153383255004883
Validation loss: 2.0571509997049966

Epoch: 6| Step: 9
Training loss: 1.9741532802581787
Validation loss: 2.0574866930643716

Epoch: 6| Step: 10
Training loss: 2.160222053527832
Validation loss: 2.061450262864431

Epoch: 6| Step: 11
Training loss: 2.0496363639831543
Validation loss: 2.0604711969693503

Epoch: 6| Step: 12
Training loss: 1.853432297706604
Validation loss: 2.061913788318634

Epoch: 6| Step: 13
Training loss: 1.6331300735473633
Validation loss: 2.0582308173179626

Epoch: 137| Step: 0
Training loss: 1.92459237575531
Validation loss: 2.0592268109321594

Epoch: 6| Step: 1
Training loss: 1.9269574880599976
Validation loss: 2.056828260421753

Epoch: 6| Step: 2
Training loss: 1.597731113433838
Validation loss: 2.064870854218801

Epoch: 6| Step: 3
Training loss: 2.12701153755188
Validation loss: 2.0651217897733054

Epoch: 6| Step: 4
Training loss: 2.3232781887054443
Validation loss: 2.0693243741989136

Epoch: 6| Step: 5
Training loss: 2.011526584625244
Validation loss: 2.058083951473236

Epoch: 6| Step: 6
Training loss: 1.6644833087921143
Validation loss: 2.062157611052195

Epoch: 6| Step: 7
Training loss: 1.8749796152114868
Validation loss: 2.0570154587427774

Epoch: 6| Step: 8
Training loss: 2.0651378631591797
Validation loss: 2.050567150115967

Epoch: 6| Step: 9
Training loss: 2.1126949787139893
Validation loss: 2.0478057066599527

Epoch: 6| Step: 10
Training loss: 2.4180142879486084
Validation loss: 2.0566366314888

Epoch: 6| Step: 11
Training loss: 2.052489757537842
Validation loss: 2.059016684691111

Epoch: 6| Step: 12
Training loss: 1.7889251708984375
Validation loss: 2.0505280097325644

Epoch: 6| Step: 13
Training loss: 2.4615743160247803
Validation loss: 2.059445937474569

Epoch: 138| Step: 0
Training loss: 2.674116611480713
Validation loss: 2.059932748476664

Epoch: 6| Step: 1
Training loss: 1.9399055242538452
Validation loss: 2.0487473805745444

Epoch: 6| Step: 2
Training loss: 2.076831579208374
Validation loss: 2.061394969622294

Epoch: 6| Step: 3
Training loss: 1.8075629472732544
Validation loss: 2.0625296433766684

Epoch: 6| Step: 4
Training loss: 1.7914425134658813
Validation loss: 2.0664798816045127

Epoch: 6| Step: 5
Training loss: 1.9077085256576538
Validation loss: 2.0557820796966553

Epoch: 6| Step: 6
Training loss: 1.5017883777618408
Validation loss: 2.071277836958567

Epoch: 6| Step: 7
Training loss: 2.3145925998687744
Validation loss: 2.0591018199920654

Epoch: 6| Step: 8
Training loss: 2.1077122688293457
Validation loss: 2.0642950733502707

Epoch: 6| Step: 9
Training loss: 1.9796262979507446
Validation loss: 2.055742383003235

Epoch: 6| Step: 10
Training loss: 1.8822708129882812
Validation loss: 2.064270297686259

Epoch: 6| Step: 11
Training loss: 2.14914608001709
Validation loss: 2.0504982074101767

Epoch: 6| Step: 12
Training loss: 2.212196111679077
Validation loss: 2.0622247656186423

Epoch: 6| Step: 13
Training loss: 2.187441825866699
Validation loss: 2.05479230483373

Epoch: 139| Step: 0
Training loss: 2.517118453979492
Validation loss: 2.0629406174023948

Epoch: 6| Step: 1
Training loss: 2.116528034210205
Validation loss: 2.062501827875773

Epoch: 6| Step: 2
Training loss: 1.715239405632019
Validation loss: 2.0490673383076987

Epoch: 6| Step: 3
Training loss: 2.1838788986206055
Validation loss: 2.0571996569633484

Epoch: 6| Step: 4
Training loss: 2.0036697387695312
Validation loss: 2.0578566789627075

Epoch: 6| Step: 5
Training loss: 2.1398439407348633
Validation loss: 2.0564475854237876

Epoch: 6| Step: 6
Training loss: 2.1020314693450928
Validation loss: 2.046052654584249

Epoch: 6| Step: 7
Training loss: 2.4511659145355225
Validation loss: 2.0674051443735757

Epoch: 6| Step: 8
Training loss: 2.287532329559326
Validation loss: 2.050203879674276

Epoch: 6| Step: 9
Training loss: 1.533639907836914
Validation loss: 2.047895848751068

Epoch: 6| Step: 10
Training loss: 1.6240605115890503
Validation loss: 2.0615776975949607

Epoch: 6| Step: 11
Training loss: 1.9394689798355103
Validation loss: 2.075472672780355

Epoch: 6| Step: 12
Training loss: 1.9652355909347534
Validation loss: 2.0633912881215415

Epoch: 6| Step: 13
Training loss: 1.7236382961273193
Validation loss: 2.0441482067108154

Epoch: 140| Step: 0
Training loss: 1.5528860092163086
Validation loss: 2.071864287058512

Epoch: 6| Step: 1
Training loss: 2.148331642150879
Validation loss: 2.0501195391019187

Epoch: 6| Step: 2
Training loss: 1.518819808959961
Validation loss: 2.0611169934272766

Epoch: 6| Step: 3
Training loss: 1.6419695615768433
Validation loss: 2.0672754049301147

Epoch: 6| Step: 4
Training loss: 2.1214489936828613
Validation loss: 2.05556458234787

Epoch: 6| Step: 5
Training loss: 1.773677110671997
Validation loss: 2.0667803486188254

Epoch: 6| Step: 6
Training loss: 2.2276158332824707
Validation loss: 2.0707168777783713

Epoch: 6| Step: 7
Training loss: 1.4940423965454102
Validation loss: 2.065611481666565

Epoch: 6| Step: 8
Training loss: 1.9429678916931152
Validation loss: 2.0479348500569663

Epoch: 6| Step: 9
Training loss: 2.1119542121887207
Validation loss: 2.0641478101412454

Epoch: 6| Step: 10
Training loss: 2.45406436920166
Validation loss: 2.0586292346318564

Epoch: 6| Step: 11
Training loss: 2.1341428756713867
Validation loss: 2.0659821033477783

Epoch: 6| Step: 12
Training loss: 2.74759578704834
Validation loss: 2.0628521839777627

Epoch: 6| Step: 13
Training loss: 2.375072717666626
Validation loss: 2.0541959206263223

Epoch: 141| Step: 0
Training loss: 2.418241024017334
Validation loss: 2.0656295816103616

Epoch: 6| Step: 1
Training loss: 2.4321179389953613
Validation loss: 2.0590301752090454

Epoch: 6| Step: 2
Training loss: 1.945690393447876
Validation loss: 2.057087500890096

Epoch: 6| Step: 3
Training loss: 1.8708469867706299
Validation loss: 2.061085303624471

Epoch: 6| Step: 4
Training loss: 1.6486363410949707
Validation loss: 2.0734959046045938

Epoch: 6| Step: 5
Training loss: 1.495226263999939
Validation loss: 2.0633643666903176

Epoch: 6| Step: 6
Training loss: 2.530010461807251
Validation loss: 2.0531741976737976

Epoch: 6| Step: 7
Training loss: 1.9232714176177979
Validation loss: 2.048403024673462

Epoch: 6| Step: 8
Training loss: 1.7756162881851196
Validation loss: 2.0649739106496177

Epoch: 6| Step: 9
Training loss: 2.442686080932617
Validation loss: 2.0564234455426535

Epoch: 6| Step: 10
Training loss: 1.512094497680664
Validation loss: 2.0682473381360373

Epoch: 6| Step: 11
Training loss: 2.335209846496582
Validation loss: 2.060084899266561

Epoch: 6| Step: 12
Training loss: 1.845955729484558
Validation loss: 2.0768580436706543

Epoch: 6| Step: 13
Training loss: 2.061737298965454
Validation loss: 2.076225459575653

Epoch: 142| Step: 0
Training loss: 2.343900442123413
Validation loss: 2.065758009751638

Epoch: 6| Step: 1
Training loss: 1.8992260694503784
Validation loss: 2.0558644930521646

Epoch: 6| Step: 2
Training loss: 1.848135232925415
Validation loss: 2.0577908158302307

Epoch: 6| Step: 3
Training loss: 2.008432388305664
Validation loss: 2.069001098473867

Epoch: 6| Step: 4
Training loss: 1.869096279144287
Validation loss: 2.0652637283007302

Epoch: 6| Step: 5
Training loss: 2.6323540210723877
Validation loss: 2.062446117401123

Epoch: 6| Step: 6
Training loss: 2.5648398399353027
Validation loss: 2.0677977403004966

Epoch: 6| Step: 7
Training loss: 1.7562050819396973
Validation loss: 2.046860078970591

Epoch: 6| Step: 8
Training loss: 1.570253610610962
Validation loss: 2.0542260011037192

Epoch: 6| Step: 9
Training loss: 2.033975124359131
Validation loss: 2.055500328540802

Epoch: 6| Step: 10
Training loss: 2.166917085647583
Validation loss: 2.04444283246994

Epoch: 6| Step: 11
Training loss: 2.0207877159118652
Validation loss: 2.0387605826059976

Epoch: 6| Step: 12
Training loss: 1.9776415824890137
Validation loss: 2.0438044468561807

Epoch: 6| Step: 13
Training loss: 1.5312504768371582
Validation loss: 2.053813616434733

Epoch: 143| Step: 0
Training loss: 2.2612996101379395
Validation loss: 2.055420200030009

Epoch: 6| Step: 1
Training loss: 1.9185335636138916
Validation loss: 2.036985198656718

Epoch: 6| Step: 2
Training loss: 1.6904983520507812
Validation loss: 2.040423313776652

Epoch: 6| Step: 3
Training loss: 2.253413677215576
Validation loss: 2.050960143407186

Epoch: 6| Step: 4
Training loss: 2.6605541706085205
Validation loss: 2.0566979249318442

Epoch: 6| Step: 5
Training loss: 1.577998161315918
Validation loss: 2.060350219408671

Epoch: 6| Step: 6
Training loss: 1.647557258605957
Validation loss: 2.054967204729716

Epoch: 6| Step: 7
Training loss: 2.0603387355804443
Validation loss: 2.0663889249165854

Epoch: 6| Step: 8
Training loss: 2.635469436645508
Validation loss: 2.067710200945536

Epoch: 6| Step: 9
Training loss: 1.8323602676391602
Validation loss: 2.0601176023483276

Epoch: 6| Step: 10
Training loss: 2.4917266368865967
Validation loss: 2.0555779735247293

Epoch: 6| Step: 11
Training loss: 1.686621904373169
Validation loss: 2.049959897994995

Epoch: 6| Step: 12
Training loss: 1.9202537536621094
Validation loss: 2.0683414538701377

Epoch: 6| Step: 13
Training loss: 1.4424351453781128
Validation loss: 2.0661404530207315

Epoch: 144| Step: 0
Training loss: 1.5694456100463867
Validation loss: 2.0643106500307717

Epoch: 6| Step: 1
Training loss: 2.5444397926330566
Validation loss: 2.070113698641459

Epoch: 6| Step: 2
Training loss: 1.8845008611679077
Validation loss: 2.060675303141276

Epoch: 6| Step: 3
Training loss: 1.9819293022155762
Validation loss: 2.0697348713874817

Epoch: 6| Step: 4
Training loss: 2.4019851684570312
Validation loss: 2.064179797967275

Epoch: 6| Step: 5
Training loss: 1.951188325881958
Validation loss: 2.073402484258016

Epoch: 6| Step: 6
Training loss: 1.762810230255127
Validation loss: 2.0520553390185037

Epoch: 6| Step: 7
Training loss: 2.063145399093628
Validation loss: 2.0433951218922934

Epoch: 6| Step: 8
Training loss: 1.5760895013809204
Validation loss: 2.0414644678433738

Epoch: 6| Step: 9
Training loss: 2.086947441101074
Validation loss: 2.04506383339564

Epoch: 6| Step: 10
Training loss: 2.21551513671875
Validation loss: 2.0562745531400046

Epoch: 6| Step: 11
Training loss: 2.469383716583252
Validation loss: 2.069579064846039

Epoch: 6| Step: 12
Training loss: 1.5489354133605957
Validation loss: 2.057523787021637

Epoch: 6| Step: 13
Training loss: 2.0867652893066406
Validation loss: 2.0633927981058755

Epoch: 145| Step: 0
Training loss: 1.9486732482910156
Validation loss: 2.0539349714914956

Epoch: 6| Step: 1
Training loss: 2.1064844131469727
Validation loss: 2.0549070835113525

Epoch: 6| Step: 2
Training loss: 2.633331298828125
Validation loss: 2.06855442126592

Epoch: 6| Step: 3
Training loss: 1.8258111476898193
Validation loss: 2.057756165663401

Epoch: 6| Step: 4
Training loss: 1.926407814025879
Validation loss: 2.0483179887135825

Epoch: 6| Step: 5
Training loss: 2.103196859359741
Validation loss: 2.0538655122121177

Epoch: 6| Step: 6
Training loss: 2.398003578186035
Validation loss: 2.0511266589164734

Epoch: 6| Step: 7
Training loss: 1.6668355464935303
Validation loss: 2.061162074406942

Epoch: 6| Step: 8
Training loss: 1.8170075416564941
Validation loss: 2.0517104864120483

Epoch: 6| Step: 9
Training loss: 2.348679542541504
Validation loss: 2.048325697580973

Epoch: 6| Step: 10
Training loss: 1.672611951828003
Validation loss: 2.0508468548456826

Epoch: 6| Step: 11
Training loss: 1.7353146076202393
Validation loss: 2.0593475500742593

Epoch: 6| Step: 12
Training loss: 1.9955799579620361
Validation loss: 2.082186142603556

Epoch: 6| Step: 13
Training loss: 2.2676854133605957
Validation loss: 2.0602768659591675

Epoch: 146| Step: 0
Training loss: 1.7259221076965332
Validation loss: 2.0565612514813743

Epoch: 6| Step: 1
Training loss: 2.7599010467529297
Validation loss: 2.052745203177134

Epoch: 6| Step: 2
Training loss: 2.098141670227051
Validation loss: 2.0535703897476196

Epoch: 6| Step: 3
Training loss: 1.951594352722168
Validation loss: 2.0359838406244912

Epoch: 6| Step: 4
Training loss: 2.087669849395752
Validation loss: 2.038321395715078

Epoch: 6| Step: 5
Training loss: 1.8986454010009766
Validation loss: 2.0408228039741516

Epoch: 6| Step: 6
Training loss: 2.282679557800293
Validation loss: 2.053571939468384

Epoch: 6| Step: 7
Training loss: 1.7109644412994385
Validation loss: 2.0375481247901917

Epoch: 6| Step: 8
Training loss: 1.847501516342163
Validation loss: 2.041215936342875

Epoch: 6| Step: 9
Training loss: 1.8278436660766602
Validation loss: 2.062452713648478

Epoch: 6| Step: 10
Training loss: 1.895015001296997
Validation loss: 2.043160080909729

Epoch: 6| Step: 11
Training loss: 2.227602243423462
Validation loss: 2.0472381711006165

Epoch: 6| Step: 12
Training loss: 2.0892393589019775
Validation loss: 2.06491619348526

Epoch: 6| Step: 13
Training loss: 1.9103657007217407
Validation loss: 2.0552526911099753

Epoch: 147| Step: 0
Training loss: 1.7564125061035156
Validation loss: 2.047903597354889

Epoch: 6| Step: 1
Training loss: 2.331878185272217
Validation loss: 2.042221983273824

Epoch: 6| Step: 2
Training loss: 2.313863515853882
Validation loss: 2.0659178694089255

Epoch: 6| Step: 3
Training loss: 1.833938717842102
Validation loss: 2.06813383102417

Epoch: 6| Step: 4
Training loss: 1.996982216835022
Validation loss: 2.0604575077692666

Epoch: 6| Step: 5
Training loss: 2.0560994148254395
Validation loss: 2.0731342236200967

Epoch: 6| Step: 6
Training loss: 1.9446933269500732
Validation loss: 2.062626361846924

Epoch: 6| Step: 7
Training loss: 2.1309735774993896
Validation loss: 2.053006728490194

Epoch: 6| Step: 8
Training loss: 1.6101301908493042
Validation loss: 2.04253226518631

Epoch: 6| Step: 9
Training loss: 1.7432796955108643
Validation loss: 2.0470823645591736

Epoch: 6| Step: 10
Training loss: 2.012012481689453
Validation loss: 2.0387497544288635

Epoch: 6| Step: 11
Training loss: 2.164961814880371
Validation loss: 2.0489434798558555

Epoch: 6| Step: 12
Training loss: 2.4114766120910645
Validation loss: 2.05289234717687

Epoch: 6| Step: 13
Training loss: 2.108757972717285
Validation loss: 2.0563260316848755

Epoch: 148| Step: 0
Training loss: 2.2993862628936768
Validation loss: 2.0553756753603616

Epoch: 6| Step: 1
Training loss: 2.0299222469329834
Validation loss: 2.0566609303156533

Epoch: 6| Step: 2
Training loss: 2.140902519226074
Validation loss: 2.0600733558336892

Epoch: 6| Step: 3
Training loss: 1.606971025466919
Validation loss: 2.0551147063573203

Epoch: 6| Step: 4
Training loss: 2.460207223892212
Validation loss: 2.0413029193878174

Epoch: 6| Step: 5
Training loss: 2.5838258266448975
Validation loss: 2.0596790711085

Epoch: 6| Step: 6
Training loss: 1.7631428241729736
Validation loss: 2.04540886481603

Epoch: 6| Step: 7
Training loss: 1.8920984268188477
Validation loss: 2.044617553551992

Epoch: 6| Step: 8
Training loss: 2.296705722808838
Validation loss: 2.046485185623169

Epoch: 6| Step: 9
Training loss: 1.895856499671936
Validation loss: 2.0376068154970803

Epoch: 6| Step: 10
Training loss: 1.9281649589538574
Validation loss: 2.0446341832478843

Epoch: 6| Step: 11
Training loss: 1.9171651601791382
Validation loss: 2.0531360308329263

Epoch: 6| Step: 12
Training loss: 1.8866281509399414
Validation loss: 2.0600558718045554

Epoch: 6| Step: 13
Training loss: 1.7310024499893188
Validation loss: 2.065405706564585

Epoch: 149| Step: 0
Training loss: 1.8704664707183838
Validation loss: 2.0820342302322388

Epoch: 6| Step: 1
Training loss: 2.2985763549804688
Validation loss: 2.073250671227773

Epoch: 6| Step: 2
Training loss: 2.005286693572998
Validation loss: 2.0758389234542847

Epoch: 6| Step: 3
Training loss: 1.6796120405197144
Validation loss: 2.088679393132528

Epoch: 6| Step: 4
Training loss: 1.6902799606323242
Validation loss: 2.0759771863619485

Epoch: 6| Step: 5
Training loss: 1.4380922317504883
Validation loss: 2.0688494046529136

Epoch: 6| Step: 6
Training loss: 2.497982978820801
Validation loss: 2.0708473920822144

Epoch: 6| Step: 7
Training loss: 2.7777516841888428
Validation loss: 2.055636942386627

Epoch: 6| Step: 8
Training loss: 2.038102865219116
Validation loss: 2.060759981473287

Epoch: 6| Step: 9
Training loss: 1.5740225315093994
Validation loss: 2.0500113566716514

Epoch: 6| Step: 10
Training loss: 2.3771958351135254
Validation loss: 2.051985740661621

Epoch: 6| Step: 11
Training loss: 1.8001084327697754
Validation loss: 2.0584189693133035

Epoch: 6| Step: 12
Training loss: 2.344788074493408
Validation loss: 2.063914100329081

Epoch: 6| Step: 13
Training loss: 1.975009799003601
Validation loss: 2.0636062820752463

Epoch: 150| Step: 0
Training loss: 2.6213502883911133
Validation loss: 2.051648815472921

Epoch: 6| Step: 1
Training loss: 2.792058229446411
Validation loss: 2.0650341908137

Epoch: 6| Step: 2
Training loss: 2.1938586235046387
Validation loss: 2.050350805123647

Epoch: 6| Step: 3
Training loss: 1.937873363494873
Validation loss: 2.0563941399256387

Epoch: 6| Step: 4
Training loss: 2.4342398643493652
Validation loss: 2.058804472287496

Epoch: 6| Step: 5
Training loss: 1.8298574686050415
Validation loss: 2.0558801094690957

Epoch: 6| Step: 6
Training loss: 1.751543641090393
Validation loss: 2.056163271268209

Epoch: 6| Step: 7
Training loss: 1.879503607749939
Validation loss: 2.057627320289612

Epoch: 6| Step: 8
Training loss: 1.5135016441345215
Validation loss: 2.0522408882776895

Epoch: 6| Step: 9
Training loss: 1.8772982358932495
Validation loss: 2.0445082585016885

Epoch: 6| Step: 10
Training loss: 1.8812956809997559
Validation loss: 2.048313875993093

Epoch: 6| Step: 11
Training loss: 1.8546000719070435
Validation loss: 2.0408511956532798

Epoch: 6| Step: 12
Training loss: 1.8732831478118896
Validation loss: 2.055501858393351

Epoch: 6| Step: 13
Training loss: 2.059631824493408
Validation loss: 2.0526505510012307

Epoch: 151| Step: 0
Training loss: 1.9557578563690186
Validation loss: 2.062063733736674

Epoch: 6| Step: 1
Training loss: 2.4416844844818115
Validation loss: 2.0561498006184897

Epoch: 6| Step: 2
Training loss: 1.983146071434021
Validation loss: 2.0544045766194663

Epoch: 6| Step: 3
Training loss: 1.3025829792022705
Validation loss: 2.059128920237223

Epoch: 6| Step: 4
Training loss: 1.282405138015747
Validation loss: 2.0502657294273376

Epoch: 6| Step: 5
Training loss: 2.5014281272888184
Validation loss: 2.0529619057973227

Epoch: 6| Step: 6
Training loss: 2.219931125640869
Validation loss: 2.0553802053133645

Epoch: 6| Step: 7
Training loss: 2.036529541015625
Validation loss: 2.045184334119161

Epoch: 6| Step: 8
Training loss: 1.7117438316345215
Validation loss: 2.0434288581212363

Epoch: 6| Step: 9
Training loss: 1.8046455383300781
Validation loss: 2.0296987096468606

Epoch: 6| Step: 10
Training loss: 2.771728992462158
Validation loss: 2.036292294661204

Epoch: 6| Step: 11
Training loss: 2.398679256439209
Validation loss: 2.0376056830088296

Epoch: 6| Step: 12
Training loss: 1.7305657863616943
Validation loss: 2.0391748944918313

Epoch: 6| Step: 13
Training loss: 1.9026153087615967
Validation loss: 2.0357874035835266

Epoch: 152| Step: 0
Training loss: 1.3831467628479004
Validation loss: 2.0379865964253745

Epoch: 6| Step: 1
Training loss: 2.3598010540008545
Validation loss: 2.0471161802609763

Epoch: 6| Step: 2
Training loss: 1.5920839309692383
Validation loss: 2.0457730293273926

Epoch: 6| Step: 3
Training loss: 1.9535462856292725
Validation loss: 2.0441446701685586

Epoch: 6| Step: 4
Training loss: 1.816781759262085
Validation loss: 2.040701150894165

Epoch: 6| Step: 5
Training loss: 2.9050309658050537
Validation loss: 2.038394053777059

Epoch: 6| Step: 6
Training loss: 2.879912853240967
Validation loss: 2.0494932532310486

Epoch: 6| Step: 7
Training loss: 1.4677588939666748
Validation loss: 2.047853708267212

Epoch: 6| Step: 8
Training loss: 1.9661973714828491
Validation loss: 2.0667401552200317

Epoch: 6| Step: 9
Training loss: 1.5427048206329346
Validation loss: 2.053544739882151

Epoch: 6| Step: 10
Training loss: 1.9829127788543701
Validation loss: 2.0540980895360312

Epoch: 6| Step: 11
Training loss: 2.5661041736602783
Validation loss: 2.046215812365214

Epoch: 6| Step: 12
Training loss: 1.7015011310577393
Validation loss: 2.058092713356018

Epoch: 6| Step: 13
Training loss: 1.835587978363037
Validation loss: 2.0556692481040955

Epoch: 153| Step: 0
Training loss: 2.340923547744751
Validation loss: 2.059453288714091

Epoch: 6| Step: 1
Training loss: 2.154383420944214
Validation loss: 2.04928457736969

Epoch: 6| Step: 2
Training loss: 1.7264879941940308
Validation loss: 2.0452174743016562

Epoch: 6| Step: 3
Training loss: 1.669372320175171
Validation loss: 2.0496761202812195

Epoch: 6| Step: 4
Training loss: 2.4151196479797363
Validation loss: 2.0518888433774314

Epoch: 6| Step: 5
Training loss: 1.9697751998901367
Validation loss: 2.0540607372919717

Epoch: 6| Step: 6
Training loss: 1.6812465190887451
Validation loss: 2.0454543431599936

Epoch: 6| Step: 7
Training loss: 1.99971342086792
Validation loss: 2.0535853107770285

Epoch: 6| Step: 8
Training loss: 1.9141517877578735
Validation loss: 2.0593822399775186

Epoch: 6| Step: 9
Training loss: 1.910808801651001
Validation loss: 2.051293929417928

Epoch: 6| Step: 10
Training loss: 1.5299220085144043
Validation loss: 2.041692078113556

Epoch: 6| Step: 11
Training loss: 1.6260825395584106
Validation loss: 2.036736706892649

Epoch: 6| Step: 12
Training loss: 2.3262791633605957
Validation loss: 2.0468555291493735

Epoch: 6| Step: 13
Training loss: 2.7236011028289795
Validation loss: 2.051408131917318

Epoch: 154| Step: 0
Training loss: 1.865186333656311
Validation loss: 2.0440205931663513

Epoch: 6| Step: 1
Training loss: 1.7047007083892822
Validation loss: 2.054660201072693

Epoch: 6| Step: 2
Training loss: 1.809187650680542
Validation loss: 2.051679273446401

Epoch: 6| Step: 3
Training loss: 2.5268211364746094
Validation loss: 2.0551719864209494

Epoch: 6| Step: 4
Training loss: 1.9094030857086182
Validation loss: 2.048314948876699

Epoch: 6| Step: 5
Training loss: 1.7929799556732178
Validation loss: 2.043306350708008

Epoch: 6| Step: 6
Training loss: 1.9642622470855713
Validation loss: 2.0425531466801963

Epoch: 6| Step: 7
Training loss: 2.248041868209839
Validation loss: 2.0592230757077536

Epoch: 6| Step: 8
Training loss: 2.3440351486206055
Validation loss: 2.0537861585617065

Epoch: 6| Step: 9
Training loss: 2.25834321975708
Validation loss: 2.052359481652578

Epoch: 6| Step: 10
Training loss: 1.7480742931365967
Validation loss: 2.0434583028157554

Epoch: 6| Step: 11
Training loss: 2.2266592979431152
Validation loss: 2.0528193712234497

Epoch: 6| Step: 12
Training loss: 1.998254418373108
Validation loss: 2.032780130704244

Epoch: 6| Step: 13
Training loss: 1.3901586532592773
Validation loss: 2.0414488116900125

Epoch: 155| Step: 0
Training loss: 2.495338201522827
Validation loss: 2.033788005510966

Epoch: 6| Step: 1
Training loss: 1.726785659790039
Validation loss: 2.033731997013092

Epoch: 6| Step: 2
Training loss: 2.3666610717773438
Validation loss: 2.028736094633738

Epoch: 6| Step: 3
Training loss: 2.1488919258117676
Validation loss: 2.0324639876683555

Epoch: 6| Step: 4
Training loss: 1.9035205841064453
Validation loss: 2.0388245383898416

Epoch: 6| Step: 5
Training loss: 2.104890823364258
Validation loss: 2.0379897554715476

Epoch: 6| Step: 6
Training loss: 1.9279918670654297
Validation loss: 2.0327585538228354

Epoch: 6| Step: 7
Training loss: 1.6708258390426636
Validation loss: 2.035022040208181

Epoch: 6| Step: 8
Training loss: 2.278834581375122
Validation loss: 2.0465606848398843

Epoch: 6| Step: 9
Training loss: 2.022197723388672
Validation loss: 2.0502370595932007

Epoch: 6| Step: 10
Training loss: 1.6116437911987305
Validation loss: 2.0607306162516275

Epoch: 6| Step: 11
Training loss: 2.284458637237549
Validation loss: 2.079313655694326

Epoch: 6| Step: 12
Training loss: 1.5762596130371094
Validation loss: 2.0839319626490274

Epoch: 6| Step: 13
Training loss: 2.0615813732147217
Validation loss: 2.0573469599088035

Epoch: 156| Step: 0
Training loss: 1.8502753973007202
Validation loss: 2.0588881572087607

Epoch: 6| Step: 1
Training loss: 2.125619888305664
Validation loss: 2.0520143707593284

Epoch: 6| Step: 2
Training loss: 1.5940507650375366
Validation loss: 2.066502630710602

Epoch: 6| Step: 3
Training loss: 2.4945425987243652
Validation loss: 2.0691155592600503

Epoch: 6| Step: 4
Training loss: 2.0794429779052734
Validation loss: 2.0634323755900064

Epoch: 6| Step: 5
Training loss: 2.5076465606689453
Validation loss: 2.0580334663391113

Epoch: 6| Step: 6
Training loss: 2.3095762729644775
Validation loss: 2.059081753094991

Epoch: 6| Step: 7
Training loss: 1.5788369178771973
Validation loss: 2.071240703264872

Epoch: 6| Step: 8
Training loss: 1.76491379737854
Validation loss: 2.0520960092544556

Epoch: 6| Step: 9
Training loss: 1.4575282335281372
Validation loss: 2.0596729119618735

Epoch: 6| Step: 10
Training loss: 2.4235527515411377
Validation loss: 2.0778289238611856

Epoch: 6| Step: 11
Training loss: 1.8870394229888916
Validation loss: 2.077579836050669

Epoch: 6| Step: 12
Training loss: 1.5676445960998535
Validation loss: 2.0904788970947266

Epoch: 6| Step: 13
Training loss: 2.4676032066345215
Validation loss: 2.092246353626251

Epoch: 157| Step: 0
Training loss: 2.4287924766540527
Validation loss: 2.1055051485697427

Epoch: 6| Step: 1
Training loss: 2.029811382293701
Validation loss: 2.1088207761446633

Epoch: 6| Step: 2
Training loss: 1.1722025871276855
Validation loss: 2.1038378874460855

Epoch: 6| Step: 3
Training loss: 1.8448984622955322
Validation loss: 2.1138554414113364

Epoch: 6| Step: 4
Training loss: 1.9897103309631348
Validation loss: 2.12117467323939

Epoch: 6| Step: 5
Training loss: 1.9194401502609253
Validation loss: 2.090842604637146

Epoch: 6| Step: 6
Training loss: 2.229478359222412
Validation loss: 2.08055579662323

Epoch: 6| Step: 7
Training loss: 2.152456045150757
Validation loss: 2.0856765707333884

Epoch: 6| Step: 8
Training loss: 2.775520086288452
Validation loss: 2.0777627825737

Epoch: 6| Step: 9
Training loss: 1.7869032621383667
Validation loss: 2.0717506607373557

Epoch: 6| Step: 10
Training loss: 1.705749750137329
Validation loss: 2.080471932888031

Epoch: 6| Step: 11
Training loss: 1.5268572568893433
Validation loss: 2.0715195735295615

Epoch: 6| Step: 12
Training loss: 1.735190749168396
Validation loss: 2.0797119140625

Epoch: 6| Step: 13
Training loss: 2.411552906036377
Validation loss: 2.0726375778516135

Epoch: 158| Step: 0
Training loss: 2.739208698272705
Validation loss: 2.0683143536249795

Epoch: 6| Step: 1
Training loss: 2.306565284729004
Validation loss: 2.055058499177297

Epoch: 6| Step: 2
Training loss: 1.2865662574768066
Validation loss: 2.0533273418744407

Epoch: 6| Step: 3
Training loss: 2.3601131439208984
Validation loss: 2.0688000917434692

Epoch: 6| Step: 4
Training loss: 1.7854934930801392
Validation loss: 2.052549958229065

Epoch: 6| Step: 5
Training loss: 2.546647787094116
Validation loss: 2.051033536593119

Epoch: 6| Step: 6
Training loss: 1.4583054780960083
Validation loss: 2.049489895502726

Epoch: 6| Step: 7
Training loss: 2.230776786804199
Validation loss: 2.0540372133255005

Epoch: 6| Step: 8
Training loss: 1.6448943614959717
Validation loss: 2.0536320010821023

Epoch: 6| Step: 9
Training loss: 1.6888930797576904
Validation loss: 2.0483433405558267

Epoch: 6| Step: 10
Training loss: 2.4943270683288574
Validation loss: 2.0581994454065957

Epoch: 6| Step: 11
Training loss: 2.091932773590088
Validation loss: 2.0550761818885803

Epoch: 6| Step: 12
Training loss: 2.074930191040039
Validation loss: 2.0628759463628135

Epoch: 6| Step: 13
Training loss: 1.382378101348877
Validation loss: 2.0771724780400596

Epoch: 159| Step: 0
Training loss: 2.2234833240509033
Validation loss: 2.0900398890177407

Epoch: 6| Step: 1
Training loss: 2.0346004962921143
Validation loss: 2.0808624823888144

Epoch: 6| Step: 2
Training loss: 2.5628857612609863
Validation loss: 2.088007469971975

Epoch: 6| Step: 3
Training loss: 2.219790458679199
Validation loss: 2.0876020590464273

Epoch: 6| Step: 4
Training loss: 1.4234814643859863
Validation loss: 2.077436069647471

Epoch: 6| Step: 5
Training loss: 1.7567932605743408
Validation loss: 2.0882094899813333

Epoch: 6| Step: 6
Training loss: 2.2006964683532715
Validation loss: 2.0720946987469993

Epoch: 6| Step: 7
Training loss: 1.9851875305175781
Validation loss: 2.070545037587484

Epoch: 6| Step: 8
Training loss: 2.042508125305176
Validation loss: 2.0769569476445517

Epoch: 6| Step: 9
Training loss: 1.8578362464904785
Validation loss: 2.0556850830713906

Epoch: 6| Step: 10
Training loss: 1.770378828048706
Validation loss: 2.065288543701172

Epoch: 6| Step: 11
Training loss: 2.0540618896484375
Validation loss: 2.0567782322565713

Epoch: 6| Step: 12
Training loss: 2.3788630962371826
Validation loss: 2.059381127357483

Epoch: 6| Step: 13
Training loss: 1.2532036304473877
Validation loss: 2.0537224610646567

Epoch: 160| Step: 0
Training loss: 2.378746271133423
Validation loss: 2.0507177313168845

Epoch: 6| Step: 1
Training loss: 1.1716067790985107
Validation loss: 2.0468632181485495

Epoch: 6| Step: 2
Training loss: 1.9582048654556274
Validation loss: 2.05348147948583

Epoch: 6| Step: 3
Training loss: 2.145857334136963
Validation loss: 2.0567245880762735

Epoch: 6| Step: 4
Training loss: 2.188842296600342
Validation loss: 2.055053412914276

Epoch: 6| Step: 5
Training loss: 1.7192177772521973
Validation loss: 2.0534050861994424

Epoch: 6| Step: 6
Training loss: 1.6297537088394165
Validation loss: 2.047059973080953

Epoch: 6| Step: 7
Training loss: 1.480098009109497
Validation loss: 2.0506399869918823

Epoch: 6| Step: 8
Training loss: 2.095954656600952
Validation loss: 2.0586540897687278

Epoch: 6| Step: 9
Training loss: 2.7468037605285645
Validation loss: 2.061983029047648

Epoch: 6| Step: 10
Training loss: 2.1504783630371094
Validation loss: 2.0693280895551047

Epoch: 6| Step: 11
Training loss: 2.1407485008239746
Validation loss: 2.05678391456604

Epoch: 6| Step: 12
Training loss: 2.0607481002807617
Validation loss: 2.062055011590322

Epoch: 6| Step: 13
Training loss: 2.134970188140869
Validation loss: 2.0691412488619485

Epoch: 161| Step: 0
Training loss: 1.7759610414505005
Validation loss: 2.0567264358202615

Epoch: 6| Step: 1
Training loss: 2.101607322692871
Validation loss: 2.0707175930341086

Epoch: 6| Step: 2
Training loss: 1.9859102964401245
Validation loss: 2.0650582909584045

Epoch: 6| Step: 3
Training loss: 1.626713514328003
Validation loss: 2.0796700716018677

Epoch: 6| Step: 4
Training loss: 1.6142504215240479
Validation loss: 2.061192790667216

Epoch: 6| Step: 5
Training loss: 2.743152379989624
Validation loss: 2.0655412673950195

Epoch: 6| Step: 6
Training loss: 2.305542469024658
Validation loss: 2.0682518680890403

Epoch: 6| Step: 7
Training loss: 2.1861560344696045
Validation loss: 2.0722954273223877

Epoch: 6| Step: 8
Training loss: 1.4975688457489014
Validation loss: 2.0630070765813193

Epoch: 6| Step: 9
Training loss: 1.573371410369873
Validation loss: 2.0675201416015625

Epoch: 6| Step: 10
Training loss: 2.3268229961395264
Validation loss: 2.0717600186665854

Epoch: 6| Step: 11
Training loss: 1.7509124279022217
Validation loss: 2.077929457028707

Epoch: 6| Step: 12
Training loss: 2.558431625366211
Validation loss: 2.068959732850393

Epoch: 6| Step: 13
Training loss: 1.910204529762268
Validation loss: 2.0589890281359353

Epoch: 162| Step: 0
Training loss: 1.5936535596847534
Validation loss: 2.0698400735855103

Epoch: 6| Step: 1
Training loss: 1.8120554685592651
Validation loss: 2.09693710009257

Epoch: 6| Step: 2
Training loss: 3.1382012367248535
Validation loss: 2.073183218638102

Epoch: 6| Step: 3
Training loss: 2.2535014152526855
Validation loss: 2.089898149172465

Epoch: 6| Step: 4
Training loss: 1.4213815927505493
Validation loss: 2.0599597096443176

Epoch: 6| Step: 5
Training loss: 1.9545605182647705
Validation loss: 2.062589248021444

Epoch: 6| Step: 6
Training loss: 2.5084388256073
Validation loss: 2.0556856791178384

Epoch: 6| Step: 7
Training loss: 1.8032981157302856
Validation loss: 2.0520994861920676

Epoch: 6| Step: 8
Training loss: 2.1251931190490723
Validation loss: 2.053275167942047

Epoch: 6| Step: 9
Training loss: 1.3206443786621094
Validation loss: 2.0557156602541604

Epoch: 6| Step: 10
Training loss: 2.248581886291504
Validation loss: 2.051233251889547

Epoch: 6| Step: 11
Training loss: 1.6409528255462646
Validation loss: 2.066635807355245

Epoch: 6| Step: 12
Training loss: 1.7948557138442993
Validation loss: 2.05788783232371

Epoch: 6| Step: 13
Training loss: 2.3310046195983887
Validation loss: 2.0569952527681985

Epoch: 163| Step: 0
Training loss: 2.1352157592773438
Validation loss: 2.0486916303634644

Epoch: 6| Step: 1
Training loss: 1.9138374328613281
Validation loss: 2.04400626818339

Epoch: 6| Step: 2
Training loss: 1.6822421550750732
Validation loss: 2.036548693974813

Epoch: 6| Step: 3
Training loss: 2.009070873260498
Validation loss: 2.0405661861101785

Epoch: 6| Step: 4
Training loss: 2.360380172729492
Validation loss: 2.0374158223470054

Epoch: 6| Step: 5
Training loss: 1.5858674049377441
Validation loss: 2.037306288878123

Epoch: 6| Step: 6
Training loss: 2.4098401069641113
Validation loss: 2.054305136203766

Epoch: 6| Step: 7
Training loss: 2.033522605895996
Validation loss: 2.0551124215126038

Epoch: 6| Step: 8
Training loss: 1.9185376167297363
Validation loss: 2.0624749660491943

Epoch: 6| Step: 9
Training loss: 1.9344723224639893
Validation loss: 2.0602171222368875

Epoch: 6| Step: 10
Training loss: 1.801932454109192
Validation loss: 2.0608699719111123

Epoch: 6| Step: 11
Training loss: 2.6245040893554688
Validation loss: 2.0710073113441467

Epoch: 6| Step: 12
Training loss: 2.0511631965637207
Validation loss: 2.0526426434516907

Epoch: 6| Step: 13
Training loss: 1.355347990989685
Validation loss: 2.050869862238566

Epoch: 164| Step: 0
Training loss: 1.896238923072815
Validation loss: 2.0626694361368814

Epoch: 6| Step: 1
Training loss: 1.5858370065689087
Validation loss: 2.058025519053141

Epoch: 6| Step: 2
Training loss: 2.2239990234375
Validation loss: 2.0665076772371926

Epoch: 6| Step: 3
Training loss: 1.9911301136016846
Validation loss: 2.057755947113037

Epoch: 6| Step: 4
Training loss: 1.9535815715789795
Validation loss: 2.0639965732892356

Epoch: 6| Step: 5
Training loss: 1.7285199165344238
Validation loss: 2.056852877140045

Epoch: 6| Step: 6
Training loss: 2.179600238800049
Validation loss: 2.0842705965042114

Epoch: 6| Step: 7
Training loss: 2.0941858291625977
Validation loss: 2.074310382207235

Epoch: 6| Step: 8
Training loss: 2.223381519317627
Validation loss: 2.0878384510676065

Epoch: 6| Step: 9
Training loss: 1.9886902570724487
Validation loss: 2.084565281867981

Epoch: 6| Step: 10
Training loss: 1.6144393682479858
Validation loss: 2.06767867008845

Epoch: 6| Step: 11
Training loss: 2.2766757011413574
Validation loss: 2.07974636554718

Epoch: 6| Step: 12
Training loss: 1.533487319946289
Validation loss: 2.0852341453234353

Epoch: 6| Step: 13
Training loss: 2.1741063594818115
Validation loss: 2.0797247091929116

Epoch: 165| Step: 0
Training loss: 1.869112491607666
Validation loss: 2.0811283389727273

Epoch: 6| Step: 1
Training loss: 2.3904807567596436
Validation loss: 2.0745519399642944

Epoch: 6| Step: 2
Training loss: 1.5632696151733398
Validation loss: 2.074942429860433

Epoch: 6| Step: 3
Training loss: 2.4021854400634766
Validation loss: 2.079078515370687

Epoch: 6| Step: 4
Training loss: 1.7266191244125366
Validation loss: 2.0774672627449036

Epoch: 6| Step: 5
Training loss: 1.8915618658065796
Validation loss: 2.075177311897278

Epoch: 6| Step: 6
Training loss: 1.6599128246307373
Validation loss: 2.080196797847748

Epoch: 6| Step: 7
Training loss: 2.5958337783813477
Validation loss: 2.076789915561676

Epoch: 6| Step: 8
Training loss: 1.4248390197753906
Validation loss: 2.072134812672933

Epoch: 6| Step: 9
Training loss: 2.2548184394836426
Validation loss: 2.0916969577471414

Epoch: 6| Step: 10
Training loss: 1.9716073274612427
Validation loss: 2.081844985485077

Epoch: 6| Step: 11
Training loss: 1.6041035652160645
Validation loss: 2.08080526192983

Epoch: 6| Step: 12
Training loss: 1.9436585903167725
Validation loss: 2.0824499328931174

Epoch: 6| Step: 13
Training loss: 2.1772866249084473
Validation loss: 2.083290159702301

Epoch: 166| Step: 0
Training loss: 2.47568416595459
Validation loss: 2.084755619366964

Epoch: 6| Step: 1
Training loss: 1.7977956533432007
Validation loss: 2.075922171274821

Epoch: 6| Step: 2
Training loss: 1.917712688446045
Validation loss: 2.088333487510681

Epoch: 6| Step: 3
Training loss: 2.3767144680023193
Validation loss: 2.0869508385658264

Epoch: 6| Step: 4
Training loss: 2.1745662689208984
Validation loss: 2.0749385158220925

Epoch: 6| Step: 5
Training loss: 2.005751609802246
Validation loss: 2.0732869505882263

Epoch: 6| Step: 6
Training loss: 2.0779266357421875
Validation loss: 2.088158428668976

Epoch: 6| Step: 7
Training loss: 1.989959716796875
Validation loss: 2.0829328894615173

Epoch: 6| Step: 8
Training loss: 1.6229560375213623
Validation loss: 2.081163207689921

Epoch: 6| Step: 9
Training loss: 2.0244569778442383
Validation loss: 2.0790200233459473

Epoch: 6| Step: 10
Training loss: 2.1740283966064453
Validation loss: 2.072456737359365

Epoch: 6| Step: 11
Training loss: 1.7376422882080078
Validation loss: 2.065872152646383

Epoch: 6| Step: 12
Training loss: 1.6875108480453491
Validation loss: 2.072549343109131

Epoch: 6| Step: 13
Training loss: 1.4941023588180542
Validation loss: 2.065510412057241

Epoch: 167| Step: 0
Training loss: 2.0806565284729004
Validation loss: 2.0665586789449057

Epoch: 6| Step: 1
Training loss: 1.851379632949829
Validation loss: 2.0675689379374185

Epoch: 6| Step: 2
Training loss: 2.481360673904419
Validation loss: 2.06432036558787

Epoch: 6| Step: 3
Training loss: 1.3126198053359985
Validation loss: 2.0726054112116494

Epoch: 6| Step: 4
Training loss: 2.125318765640259
Validation loss: 2.0642851193745932

Epoch: 6| Step: 5
Training loss: 2.282526969909668
Validation loss: 2.0720606644948325

Epoch: 6| Step: 6
Training loss: 2.2557291984558105
Validation loss: 2.0719288984934487

Epoch: 6| Step: 7
Training loss: 1.4890296459197998
Validation loss: 2.064557055632273

Epoch: 6| Step: 8
Training loss: 1.781379222869873
Validation loss: 2.072682201862335

Epoch: 6| Step: 9
Training loss: 1.7117021083831787
Validation loss: 2.0804057717323303

Epoch: 6| Step: 10
Training loss: 2.1451587677001953
Validation loss: 2.0746248364448547

Epoch: 6| Step: 11
Training loss: 2.3206615447998047
Validation loss: 2.058026353518168

Epoch: 6| Step: 12
Training loss: 2.228917360305786
Validation loss: 2.0913319190343223

Epoch: 6| Step: 13
Training loss: 1.7496367692947388
Validation loss: 2.0908209880193076

Epoch: 168| Step: 0
Training loss: 2.3068203926086426
Validation loss: 2.0995765129725137

Epoch: 6| Step: 1
Training loss: 1.9164927005767822
Validation loss: 2.086567242940267

Epoch: 6| Step: 2
Training loss: 2.6987602710723877
Validation loss: 2.077905257542928

Epoch: 6| Step: 3
Training loss: 1.8685665130615234
Validation loss: 2.0684551000595093

Epoch: 6| Step: 4
Training loss: 1.8666300773620605
Validation loss: 2.053756833076477

Epoch: 6| Step: 5
Training loss: 1.7503902912139893
Validation loss: 2.062002976735433

Epoch: 6| Step: 6
Training loss: 2.0221338272094727
Validation loss: 2.0604926347732544

Epoch: 6| Step: 7
Training loss: 2.064546585083008
Validation loss: 2.0551298459370932

Epoch: 6| Step: 8
Training loss: 2.5108847618103027
Validation loss: 2.0670682787895203

Epoch: 6| Step: 9
Training loss: 1.8333123922348022
Validation loss: 2.071752389272054

Epoch: 6| Step: 10
Training loss: 1.6273103952407837
Validation loss: 2.0778144001960754

Epoch: 6| Step: 11
Training loss: 1.8168854713439941
Validation loss: 2.0733392238616943

Epoch: 6| Step: 12
Training loss: 1.9373457431793213
Validation loss: 2.086030821005503

Epoch: 6| Step: 13
Training loss: 1.8244481086730957
Validation loss: 2.0906399488449097

Epoch: 169| Step: 0
Training loss: 2.1231119632720947
Validation loss: 2.089568078517914

Epoch: 6| Step: 1
Training loss: 2.5405986309051514
Validation loss: 2.0873623291651406

Epoch: 6| Step: 2
Training loss: 2.016482353210449
Validation loss: 2.1442039211591086

Epoch: 6| Step: 3
Training loss: 2.0906054973602295
Validation loss: 2.129694104194641

Epoch: 6| Step: 4
Training loss: 1.6399414539337158
Validation loss: 2.156861166159312

Epoch: 6| Step: 5
Training loss: 1.6713684797286987
Validation loss: 2.127814749876658

Epoch: 6| Step: 6
Training loss: 1.7704441547393799
Validation loss: 2.1089938481648765

Epoch: 6| Step: 7
Training loss: 1.9697519540786743
Validation loss: 2.1231053471565247

Epoch: 6| Step: 8
Training loss: 1.9743664264678955
Validation loss: 2.1170827945073447

Epoch: 6| Step: 9
Training loss: 2.0542526245117188
Validation loss: 2.0703559120496116

Epoch: 6| Step: 10
Training loss: 2.028526782989502
Validation loss: 2.076952596505483

Epoch: 6| Step: 11
Training loss: 2.1087398529052734
Validation loss: 2.0873522758483887

Epoch: 6| Step: 12
Training loss: 2.4609622955322266
Validation loss: 2.086905380090078

Epoch: 6| Step: 13
Training loss: 1.7172054052352905
Validation loss: 2.0781771143277488

Epoch: 170| Step: 0
Training loss: 2.5504584312438965
Validation loss: 2.0692824323972068

Epoch: 6| Step: 1
Training loss: 1.380260944366455
Validation loss: 2.0869602958361306

Epoch: 6| Step: 2
Training loss: 1.591233253479004
Validation loss: 2.0899966756502786

Epoch: 6| Step: 3
Training loss: 1.8477860689163208
Validation loss: 2.0814390579859414

Epoch: 6| Step: 4
Training loss: 2.0518927574157715
Validation loss: 2.0849711100260415

Epoch: 6| Step: 5
Training loss: 1.799225926399231
Validation loss: 2.083031713962555

Epoch: 6| Step: 6
Training loss: 2.4637274742126465
Validation loss: 2.0825863679250083

Epoch: 6| Step: 7
Training loss: 1.848039150238037
Validation loss: 2.082068920135498

Epoch: 6| Step: 8
Training loss: 2.335122585296631
Validation loss: 2.0871194998423257

Epoch: 6| Step: 9
Training loss: 2.580801248550415
Validation loss: 2.0795292456944785

Epoch: 6| Step: 10
Training loss: 1.9442611932754517
Validation loss: 2.0922144651412964

Epoch: 6| Step: 11
Training loss: 2.044283390045166
Validation loss: 2.090568244457245

Epoch: 6| Step: 12
Training loss: 2.0943286418914795
Validation loss: 2.0993980169296265

Epoch: 6| Step: 13
Training loss: 1.5022494792938232
Validation loss: 2.104661842187246

Epoch: 171| Step: 0
Training loss: 2.657419204711914
Validation loss: 2.112087666988373

Epoch: 6| Step: 1
Training loss: 1.590085744857788
Validation loss: 2.101850708325704

Epoch: 6| Step: 2
Training loss: 1.5078812837600708
Validation loss: 2.0985739827156067

Epoch: 6| Step: 3
Training loss: 2.52970027923584
Validation loss: 2.0935975114504495

Epoch: 6| Step: 4
Training loss: 1.9721678495407104
Validation loss: 2.0784963568051658

Epoch: 6| Step: 5
Training loss: 1.5560302734375
Validation loss: 2.089554031689962

Epoch: 6| Step: 6
Training loss: 1.933349847793579
Validation loss: 2.098112682501475

Epoch: 6| Step: 7
Training loss: 1.9226032495498657
Validation loss: 2.0981761614481607

Epoch: 6| Step: 8
Training loss: 1.7978028059005737
Validation loss: 2.092786510785421

Epoch: 6| Step: 9
Training loss: 1.693692922592163
Validation loss: 2.09301221370697

Epoch: 6| Step: 10
Training loss: 2.1950197219848633
Validation loss: 2.0716570019721985

Epoch: 6| Step: 11
Training loss: 1.7356444597244263
Validation loss: 2.095038910706838

Epoch: 6| Step: 12
Training loss: 2.1056625843048096
Validation loss: 2.0987334847450256

Epoch: 6| Step: 13
Training loss: 2.199103832244873
Validation loss: 2.0860700011253357

Epoch: 172| Step: 0
Training loss: 2.3305699825286865
Validation loss: 2.095686157544454

Epoch: 6| Step: 1
Training loss: 1.7900325059890747
Validation loss: 2.093629240989685

Epoch: 6| Step: 2
Training loss: 2.0780692100524902
Validation loss: 2.08388880888621

Epoch: 6| Step: 3
Training loss: 1.8397014141082764
Validation loss: 2.086780289808909

Epoch: 6| Step: 4
Training loss: 1.628447413444519
Validation loss: 2.0849376122156777

Epoch: 6| Step: 5
Training loss: 1.756734848022461
Validation loss: 2.0951556166013083

Epoch: 6| Step: 6
Training loss: 2.190908432006836
Validation loss: 2.0664527217547097

Epoch: 6| Step: 7
Training loss: 1.963791012763977
Validation loss: 2.0864330927530923

Epoch: 6| Step: 8
Training loss: 1.5583469867706299
Validation loss: 2.075693945089976

Epoch: 6| Step: 9
Training loss: 1.7981352806091309
Validation loss: 2.083359678586324

Epoch: 6| Step: 10
Training loss: 2.033693790435791
Validation loss: 2.06971683104833

Epoch: 6| Step: 11
Training loss: 1.7272000312805176
Validation loss: 2.0725054939587912

Epoch: 6| Step: 12
Training loss: 2.7023158073425293
Validation loss: 2.0740829507509866

Epoch: 6| Step: 13
Training loss: 1.989058494567871
Validation loss: 2.0543272693951926

Epoch: 173| Step: 0
Training loss: 2.178807020187378
Validation loss: 2.0700213511784873

Epoch: 6| Step: 1
Training loss: 2.5077638626098633
Validation loss: 2.0624570647875466

Epoch: 6| Step: 2
Training loss: 1.790649652481079
Validation loss: 2.0634337266286216

Epoch: 6| Step: 3
Training loss: 1.820559024810791
Validation loss: 2.0548879702885947

Epoch: 6| Step: 4
Training loss: 2.1553056240081787
Validation loss: 2.0549685955047607

Epoch: 6| Step: 5
Training loss: 1.4423681497573853
Validation loss: 2.0623684525489807

Epoch: 6| Step: 6
Training loss: 2.6935434341430664
Validation loss: 2.0749565958976746

Epoch: 6| Step: 7
Training loss: 1.4315110445022583
Validation loss: 2.067560056845347

Epoch: 6| Step: 8
Training loss: 2.2356302738189697
Validation loss: 2.072922865549723

Epoch: 6| Step: 9
Training loss: 1.7668800354003906
Validation loss: 2.075764238834381

Epoch: 6| Step: 10
Training loss: 1.782822608947754
Validation loss: 2.0779427886009216

Epoch: 6| Step: 11
Training loss: 2.2816379070281982
Validation loss: 2.0791136821111045

Epoch: 6| Step: 12
Training loss: 1.404130458831787
Validation loss: 2.0790887077649436

Epoch: 6| Step: 13
Training loss: 1.6853396892547607
Validation loss: 2.075429161389669

Epoch: 174| Step: 0
Training loss: 2.051511287689209
Validation loss: 2.0794169306755066

Epoch: 6| Step: 1
Training loss: 1.9519160985946655
Validation loss: 2.0966964761416116

Epoch: 6| Step: 2
Training loss: 2.0799217224121094
Validation loss: 2.1061548988024392

Epoch: 6| Step: 3
Training loss: 2.104602336883545
Validation loss: 2.094603737195333

Epoch: 6| Step: 4
Training loss: 2.957258701324463
Validation loss: 2.104319413503011

Epoch: 6| Step: 5
Training loss: 1.9089306592941284
Validation loss: 2.1129519939422607

Epoch: 6| Step: 6
Training loss: 1.869828701019287
Validation loss: 2.1038982470830283

Epoch: 6| Step: 7
Training loss: 1.6965980529785156
Validation loss: 2.098399798075358

Epoch: 6| Step: 8
Training loss: 2.124952554702759
Validation loss: 2.097826441129049

Epoch: 6| Step: 9
Training loss: 1.9911959171295166
Validation loss: 2.1119222243626914

Epoch: 6| Step: 10
Training loss: 1.585805892944336
Validation loss: 2.1007480223973594

Epoch: 6| Step: 11
Training loss: 1.816314935684204
Validation loss: 2.119975666205088

Epoch: 6| Step: 12
Training loss: 1.5765678882598877
Validation loss: 2.096747020880381

Epoch: 6| Step: 13
Training loss: 1.9007922410964966
Validation loss: 2.107757111390432

Epoch: 175| Step: 0
Training loss: 1.7082924842834473
Validation loss: 2.1111416021982827

Epoch: 6| Step: 1
Training loss: 2.071470022201538
Validation loss: 2.0987992684046426

Epoch: 6| Step: 2
Training loss: 2.939659833908081
Validation loss: 2.10439795255661

Epoch: 6| Step: 3
Training loss: 2.1937057971954346
Validation loss: 2.1114346782366433

Epoch: 6| Step: 4
Training loss: 1.3629919290542603
Validation loss: 2.106588085492452

Epoch: 6| Step: 5
Training loss: 2.223816156387329
Validation loss: 2.1118937730789185

Epoch: 6| Step: 6
Training loss: 2.1194682121276855
Validation loss: 2.097337027390798

Epoch: 6| Step: 7
Training loss: 1.3615832328796387
Validation loss: 2.0919026136398315

Epoch: 6| Step: 8
Training loss: 2.170158863067627
Validation loss: 2.1081773241360984

Epoch: 6| Step: 9
Training loss: 1.9590282440185547
Validation loss: 2.100035468737284

Epoch: 6| Step: 10
Training loss: 1.701178789138794
Validation loss: 2.0995865861574807

Epoch: 6| Step: 11
Training loss: 1.2361652851104736
Validation loss: 2.097297251224518

Epoch: 6| Step: 12
Training loss: 2.4265007972717285
Validation loss: 2.092518428961436

Epoch: 6| Step: 13
Training loss: 1.578070878982544
Validation loss: 2.0807398160298667

Epoch: 176| Step: 0
Training loss: 1.9836162328720093
Validation loss: 2.096340815226237

Epoch: 6| Step: 1
Training loss: 1.9275648593902588
Validation loss: 2.097226142883301

Epoch: 6| Step: 2
Training loss: 1.9753339290618896
Validation loss: 2.09462442000707

Epoch: 6| Step: 3
Training loss: 1.4429906606674194
Validation loss: 2.0914239088694253

Epoch: 6| Step: 4
Training loss: 2.2403221130371094
Validation loss: 2.0922911365826926

Epoch: 6| Step: 5
Training loss: 1.974212646484375
Validation loss: 2.084859331448873

Epoch: 6| Step: 6
Training loss: 2.2935984134674072
Validation loss: 2.0862314303716025

Epoch: 6| Step: 7
Training loss: 2.2622437477111816
Validation loss: 2.0778433680534363

Epoch: 6| Step: 8
Training loss: 2.406003475189209
Validation loss: 2.0898567040761313

Epoch: 6| Step: 9
Training loss: 1.8261501789093018
Validation loss: 2.091018478075663

Epoch: 6| Step: 10
Training loss: 1.6967358589172363
Validation loss: 2.089378535747528

Epoch: 6| Step: 11
Training loss: 1.6918890476226807
Validation loss: 2.087290088335673

Epoch: 6| Step: 12
Training loss: 2.1626617908477783
Validation loss: 2.08867084980011

Epoch: 6| Step: 13
Training loss: 1.543050765991211
Validation loss: 2.102834781010946

Epoch: 177| Step: 0
Training loss: 1.881944179534912
Validation loss: 2.08362223704656

Epoch: 6| Step: 1
Training loss: 1.4459408521652222
Validation loss: 2.091395298639933

Epoch: 6| Step: 2
Training loss: 1.63046133518219
Validation loss: 2.0799509088198342

Epoch: 6| Step: 3
Training loss: 1.6178746223449707
Validation loss: 2.077864090601603

Epoch: 6| Step: 4
Training loss: 1.9038488864898682
Validation loss: 2.084062953790029

Epoch: 6| Step: 5
Training loss: 1.8252607583999634
Validation loss: 2.0808746019999185

Epoch: 6| Step: 6
Training loss: 1.6219193935394287
Validation loss: 2.093086580435435

Epoch: 6| Step: 7
Training loss: 1.598738670349121
Validation loss: 2.090393344561259

Epoch: 6| Step: 8
Training loss: 2.1391425132751465
Validation loss: 2.079115609327952

Epoch: 6| Step: 9
Training loss: 2.0045576095581055
Validation loss: 2.0754454334576926

Epoch: 6| Step: 10
Training loss: 2.457329511642456
Validation loss: 2.081398665904999

Epoch: 6| Step: 11
Training loss: 2.394357681274414
Validation loss: 2.087059438228607

Epoch: 6| Step: 12
Training loss: 1.8864153623580933
Validation loss: 2.1090691089630127

Epoch: 6| Step: 13
Training loss: 2.698721170425415
Validation loss: 2.100121815999349

Epoch: 178| Step: 0
Training loss: 1.9877562522888184
Validation loss: 2.091257890065511

Epoch: 6| Step: 1
Training loss: 1.9454162120819092
Validation loss: 2.1020944913228354

Epoch: 6| Step: 2
Training loss: 2.1839141845703125
Validation loss: 2.100258449713389

Epoch: 6| Step: 3
Training loss: 1.8253614902496338
Validation loss: 2.0883008440335593

Epoch: 6| Step: 4
Training loss: 1.6724967956542969
Validation loss: 2.088417132695516

Epoch: 6| Step: 5
Training loss: 2.610656261444092
Validation loss: 2.0876405040423074

Epoch: 6| Step: 6
Training loss: 2.107970952987671
Validation loss: 2.100530465443929

Epoch: 6| Step: 7
Training loss: 1.7210004329681396
Validation loss: 2.1030364433924356

Epoch: 6| Step: 8
Training loss: 1.981713891029358
Validation loss: 2.083354353904724

Epoch: 6| Step: 9
Training loss: 1.8309555053710938
Validation loss: 2.0785693923632302

Epoch: 6| Step: 10
Training loss: 1.3620538711547852
Validation loss: 2.0943533976872764

Epoch: 6| Step: 11
Training loss: 1.7064820528030396
Validation loss: 2.0977925856908164

Epoch: 6| Step: 12
Training loss: 1.8291159868240356
Validation loss: 2.098378856976827

Epoch: 6| Step: 13
Training loss: 2.148259401321411
Validation loss: 2.0862597624460855

Epoch: 179| Step: 0
Training loss: 2.251248598098755
Validation loss: 2.0939711729685464

Epoch: 6| Step: 1
Training loss: 2.140059471130371
Validation loss: 2.090114116668701

Epoch: 6| Step: 2
Training loss: 2.3909950256347656
Validation loss: 2.108857572078705

Epoch: 6| Step: 3
Training loss: 1.56821608543396
Validation loss: 2.1020817359288535

Epoch: 6| Step: 4
Training loss: 1.3635683059692383
Validation loss: 2.0864129662513733

Epoch: 6| Step: 5
Training loss: 2.35430908203125
Validation loss: 2.084512631098429

Epoch: 6| Step: 6
Training loss: 1.4688068628311157
Validation loss: 2.0944202542304993

Epoch: 6| Step: 7
Training loss: 2.0836219787597656
Validation loss: 2.095127900441488

Epoch: 6| Step: 8
Training loss: 1.8727333545684814
Validation loss: 2.0915942589441934

Epoch: 6| Step: 9
Training loss: 1.680429458618164
Validation loss: 2.1074792544047036

Epoch: 6| Step: 10
Training loss: 2.542623996734619
Validation loss: 2.0917215744654336

Epoch: 6| Step: 11
Training loss: 1.6490702629089355
Validation loss: 2.0949795246124268

Epoch: 6| Step: 12
Training loss: 1.5683039426803589
Validation loss: 2.089945693810781

Epoch: 6| Step: 13
Training loss: 2.078094005584717
Validation loss: 2.082723100980123

Epoch: 180| Step: 0
Training loss: 2.431541919708252
Validation loss: 2.090264678001404

Epoch: 6| Step: 1
Training loss: 1.8734004497528076
Validation loss: 2.090163509051005

Epoch: 6| Step: 2
Training loss: 1.5152604579925537
Validation loss: 2.1033100684483848

Epoch: 6| Step: 3
Training loss: 1.7589032649993896
Validation loss: 2.092942217985789

Epoch: 6| Step: 4
Training loss: 1.846260666847229
Validation loss: 2.096799075603485

Epoch: 6| Step: 5
Training loss: 2.16528058052063
Validation loss: 2.1059863169988

Epoch: 6| Step: 6
Training loss: 2.3952102661132812
Validation loss: 2.098481814066569

Epoch: 6| Step: 7
Training loss: 2.121018886566162
Validation loss: 2.101259231567383

Epoch: 6| Step: 8
Training loss: 1.8919847011566162
Validation loss: 2.0888388554255166

Epoch: 6| Step: 9
Training loss: 1.859581708908081
Validation loss: 2.0904022256533303

Epoch: 6| Step: 10
Training loss: 1.8410762548446655
Validation loss: 2.088359316190084

Epoch: 6| Step: 11
Training loss: 1.8234723806381226
Validation loss: 2.0948611299196878

Epoch: 6| Step: 12
Training loss: 1.8472696542739868
Validation loss: 2.0941277543703714

Epoch: 6| Step: 13
Training loss: 1.9259843826293945
Validation loss: 2.0772562424341836

Epoch: 181| Step: 0
Training loss: 1.8753002882003784
Validation loss: 2.0847425858179727

Epoch: 6| Step: 1
Training loss: 2.1226892471313477
Validation loss: 2.08819846312205

Epoch: 6| Step: 2
Training loss: 1.6713305711746216
Validation loss: 2.108896315097809

Epoch: 6| Step: 3
Training loss: 1.524484634399414
Validation loss: 2.102163771788279

Epoch: 6| Step: 4
Training loss: 1.9150649309158325
Validation loss: 2.0963316361109414

Epoch: 6| Step: 5
Training loss: 2.5183680057525635
Validation loss: 2.0901989340782166

Epoch: 6| Step: 6
Training loss: 2.063856601715088
Validation loss: 2.0735193689664206

Epoch: 6| Step: 7
Training loss: 1.9039947986602783
Validation loss: 2.0783586303393045

Epoch: 6| Step: 8
Training loss: 1.8875315189361572
Validation loss: 2.079348921775818

Epoch: 6| Step: 9
Training loss: 2.0530152320861816
Validation loss: 2.071267525355021

Epoch: 6| Step: 10
Training loss: 1.9908883571624756
Validation loss: 2.07174684604009

Epoch: 6| Step: 11
Training loss: 1.6899681091308594
Validation loss: 2.083575963973999

Epoch: 6| Step: 12
Training loss: 1.6086843013763428
Validation loss: 2.0827303926150003

Epoch: 6| Step: 13
Training loss: 2.5547266006469727
Validation loss: 2.0988255739212036

Epoch: 182| Step: 0
Training loss: 1.8776750564575195
Validation loss: 2.094545324643453

Epoch: 6| Step: 1
Training loss: 1.958655595779419
Validation loss: 2.0983115235964456

Epoch: 6| Step: 2
Training loss: 2.2752480506896973
Validation loss: 2.0958484411239624

Epoch: 6| Step: 3
Training loss: 2.047020435333252
Validation loss: 2.0861659248669944

Epoch: 6| Step: 4
Training loss: 2.192958354949951
Validation loss: 2.105716268221537

Epoch: 6| Step: 5
Training loss: 2.0528151988983154
Validation loss: 2.099417984485626

Epoch: 6| Step: 6
Training loss: 1.8069220781326294
Validation loss: 2.09496808052063

Epoch: 6| Step: 7
Training loss: 2.614896774291992
Validation loss: 2.101954241593679

Epoch: 6| Step: 8
Training loss: 1.7612794637680054
Validation loss: 2.0933905442555747

Epoch: 6| Step: 9
Training loss: 2.1652603149414062
Validation loss: 2.0992756684621177

Epoch: 6| Step: 10
Training loss: 1.8631919622421265
Validation loss: 2.1065170566240945

Epoch: 6| Step: 11
Training loss: 1.659225344657898
Validation loss: 2.0932030280431113

Epoch: 6| Step: 12
Training loss: 1.6154499053955078
Validation loss: 2.094674209753672

Epoch: 6| Step: 13
Training loss: 1.4389162063598633
Validation loss: 2.1105316281318665

Epoch: 183| Step: 0
Training loss: 2.3294336795806885
Validation loss: 2.1038915316263833

Epoch: 6| Step: 1
Training loss: 1.6758875846862793
Validation loss: 2.1233927607536316

Epoch: 6| Step: 2
Training loss: 2.2574503421783447
Validation loss: 2.123642166455587

Epoch: 6| Step: 3
Training loss: 2.14888334274292
Validation loss: 2.1117848555246987

Epoch: 6| Step: 4
Training loss: 1.6278443336486816
Validation loss: 2.1144599119822183

Epoch: 6| Step: 5
Training loss: 1.593739628791809
Validation loss: 2.085695286591848

Epoch: 6| Step: 6
Training loss: 2.050090789794922
Validation loss: 2.105199933052063

Epoch: 6| Step: 7
Training loss: 2.1790990829467773
Validation loss: 2.09271776676178

Epoch: 6| Step: 8
Training loss: 1.4178192615509033
Validation loss: 2.088511308034261

Epoch: 6| Step: 9
Training loss: 2.215834140777588
Validation loss: 2.097886383533478

Epoch: 6| Step: 10
Training loss: 2.232935905456543
Validation loss: 2.1025492548942566

Epoch: 6| Step: 11
Training loss: 1.8815070390701294
Validation loss: 2.0962594151496887

Epoch: 6| Step: 12
Training loss: 2.1821579933166504
Validation loss: 2.091064771016439

Epoch: 6| Step: 13
Training loss: 1.9309449195861816
Validation loss: 2.0858439803123474

Epoch: 184| Step: 0
Training loss: 1.2744512557983398
Validation loss: 2.0900649229685464

Epoch: 6| Step: 1
Training loss: 3.4982104301452637
Validation loss: 2.086963097254435

Epoch: 6| Step: 2
Training loss: 2.569456100463867
Validation loss: 2.091381549835205

Epoch: 6| Step: 3
Training loss: 1.71864652633667
Validation loss: 2.087342321872711

Epoch: 6| Step: 4
Training loss: 2.185776710510254
Validation loss: 2.0918198426564536

Epoch: 6| Step: 5
Training loss: 1.8180015087127686
Validation loss: 2.0907375613848367

Epoch: 6| Step: 6
Training loss: 1.2345483303070068
Validation loss: 2.0859514474868774

Epoch: 6| Step: 7
Training loss: 1.496314287185669
Validation loss: 2.0884426832199097

Epoch: 6| Step: 8
Training loss: 1.92645263671875
Validation loss: 2.084445675214132

Epoch: 6| Step: 9
Training loss: 1.72440505027771
Validation loss: 2.088211635748545

Epoch: 6| Step: 10
Training loss: 2.218571186065674
Validation loss: 2.1023614406585693

Epoch: 6| Step: 11
Training loss: 1.9469895362854004
Validation loss: 2.0936181942621865

Epoch: 6| Step: 12
Training loss: 1.5883954763412476
Validation loss: 2.1193105975786843

Epoch: 6| Step: 13
Training loss: 1.9196133613586426
Validation loss: 2.122968157132467

Epoch: 185| Step: 0
Training loss: 2.3785927295684814
Validation loss: 2.1256712476412454

Epoch: 6| Step: 1
Training loss: 1.6488687992095947
Validation loss: 2.1216676831245422

Epoch: 6| Step: 2
Training loss: 1.6182053089141846
Validation loss: 2.116674760977427

Epoch: 6| Step: 3
Training loss: 2.1344025135040283
Validation loss: 2.1106815735499063

Epoch: 6| Step: 4
Training loss: 1.7177734375
Validation loss: 2.103031098842621

Epoch: 6| Step: 5
Training loss: 2.1070637702941895
Validation loss: 2.101016879081726

Epoch: 6| Step: 6
Training loss: 2.4630985260009766
Validation loss: 2.1027135451634726

Epoch: 6| Step: 7
Training loss: 2.514854907989502
Validation loss: 2.1043057640393577

Epoch: 6| Step: 8
Training loss: 2.1131317615509033
Validation loss: 2.109308878580729

Epoch: 6| Step: 9
Training loss: 1.9065320491790771
Validation loss: 2.1062548756599426

Epoch: 6| Step: 10
Training loss: 1.168788194656372
Validation loss: 2.102897047996521

Epoch: 6| Step: 11
Training loss: 1.784926414489746
Validation loss: 2.1002657214800515

Epoch: 6| Step: 12
Training loss: 1.4976390600204468
Validation loss: 2.0891566276550293

Epoch: 6| Step: 13
Training loss: 1.9875528812408447
Validation loss: 2.097306768099467

Epoch: 186| Step: 0
Training loss: 2.146047830581665
Validation loss: 2.0967098275820413

Epoch: 6| Step: 1
Training loss: 2.0258336067199707
Validation loss: 2.0964295466740928

Epoch: 6| Step: 2
Training loss: 2.1320199966430664
Validation loss: 2.098119576772054

Epoch: 6| Step: 3
Training loss: 1.7679662704467773
Validation loss: 2.092325985431671

Epoch: 6| Step: 4
Training loss: 1.8426276445388794
Validation loss: 2.0972346663475037

Epoch: 6| Step: 5
Training loss: 1.8268537521362305
Validation loss: 2.0898663997650146

Epoch: 6| Step: 6
Training loss: 1.6570826768875122
Validation loss: 2.101117511590322

Epoch: 6| Step: 7
Training loss: 1.7420110702514648
Validation loss: 2.093139350414276

Epoch: 6| Step: 8
Training loss: 1.6040306091308594
Validation loss: 2.09746124347051

Epoch: 6| Step: 9
Training loss: 1.5297482013702393
Validation loss: 2.0995708306630454

Epoch: 6| Step: 10
Training loss: 2.136397123336792
Validation loss: 2.08795428276062

Epoch: 6| Step: 11
Training loss: 1.8990247249603271
Validation loss: 2.085050642490387

Epoch: 6| Step: 12
Training loss: 2.6963376998901367
Validation loss: 2.119640906651815

Epoch: 6| Step: 13
Training loss: 1.6807665824890137
Validation loss: 2.0966705083847046

Epoch: 187| Step: 0
Training loss: 1.8418980836868286
Validation loss: 2.1020869612693787

Epoch: 6| Step: 1
Training loss: 2.046642303466797
Validation loss: 2.099114497502645

Epoch: 6| Step: 2
Training loss: 1.7623729705810547
Validation loss: 2.109566410382589

Epoch: 6| Step: 3
Training loss: 1.9373912811279297
Validation loss: 2.101161460081736

Epoch: 6| Step: 4
Training loss: 2.154411554336548
Validation loss: 2.114028533299764

Epoch: 6| Step: 5
Training loss: 2.6498706340789795
Validation loss: 2.1186187267303467

Epoch: 6| Step: 6
Training loss: 1.625575065612793
Validation loss: 2.1073471307754517

Epoch: 6| Step: 7
Training loss: 1.6579842567443848
Validation loss: 2.108256995677948

Epoch: 6| Step: 8
Training loss: 2.352884531021118
Validation loss: 2.122154116630554

Epoch: 6| Step: 9
Training loss: 1.6002215147018433
Validation loss: 2.1192007859547934

Epoch: 6| Step: 10
Training loss: 1.837937355041504
Validation loss: 2.097523331642151

Epoch: 6| Step: 11
Training loss: 1.5602055788040161
Validation loss: 2.100524286429087

Epoch: 6| Step: 12
Training loss: 1.585498332977295
Validation loss: 2.115523874759674

Epoch: 6| Step: 13
Training loss: 2.158142566680908
Validation loss: 2.1102444330851235

Epoch: 188| Step: 0
Training loss: 1.7426118850708008
Validation loss: 2.098819315433502

Epoch: 6| Step: 1
Training loss: 1.6675283908843994
Validation loss: 2.107810854911804

Epoch: 6| Step: 2
Training loss: 1.48329496383667
Validation loss: 2.1056172847747803

Epoch: 6| Step: 3
Training loss: 1.630417823791504
Validation loss: 2.112433910369873

Epoch: 6| Step: 4
Training loss: 1.3197253942489624
Validation loss: 2.1116546193758645

Epoch: 6| Step: 5
Training loss: 2.7307331562042236
Validation loss: 2.110355854034424

Epoch: 6| Step: 6
Training loss: 2.1764354705810547
Validation loss: 2.106153428554535

Epoch: 6| Step: 7
Training loss: 1.9499602317810059
Validation loss: 2.0888194839159646

Epoch: 6| Step: 8
Training loss: 2.1678414344787598
Validation loss: 2.0997241735458374

Epoch: 6| Step: 9
Training loss: 2.6277103424072266
Validation loss: 2.0963122049967446

Epoch: 6| Step: 10
Training loss: 1.4343597888946533
Validation loss: 2.1077015002568564

Epoch: 6| Step: 11
Training loss: 2.3942043781280518
Validation loss: 2.0835258762041726

Epoch: 6| Step: 12
Training loss: 1.661661148071289
Validation loss: 2.0999881823857627

Epoch: 6| Step: 13
Training loss: 1.6502317190170288
Validation loss: 2.1084289948145547

Epoch: 189| Step: 0
Training loss: 1.7476630210876465
Validation loss: 2.1067119240760803

Epoch: 6| Step: 1
Training loss: 2.1972908973693848
Validation loss: 2.1026219725608826

Epoch: 6| Step: 2
Training loss: 1.7043735980987549
Validation loss: 2.1228307485580444

Epoch: 6| Step: 3
Training loss: 1.7992808818817139
Validation loss: 2.0932643016179404

Epoch: 6| Step: 4
Training loss: 2.0662546157836914
Validation loss: 2.1190638740857444

Epoch: 6| Step: 5
Training loss: 1.5560150146484375
Validation loss: 2.1145880023638406

Epoch: 6| Step: 6
Training loss: 2.029270648956299
Validation loss: 2.105395416418711

Epoch: 6| Step: 7
Training loss: 2.972576141357422
Validation loss: 2.109831670920054

Epoch: 6| Step: 8
Training loss: 1.7519091367721558
Validation loss: 2.1090739965438843

Epoch: 6| Step: 9
Training loss: 1.6617624759674072
Validation loss: 2.1098780632019043

Epoch: 6| Step: 10
Training loss: 2.044471263885498
Validation loss: 2.1068288286527

Epoch: 6| Step: 11
Training loss: 1.8495380878448486
Validation loss: 2.124295949935913

Epoch: 6| Step: 12
Training loss: 1.7405586242675781
Validation loss: 2.137319286664327

Epoch: 6| Step: 13
Training loss: 1.805765151977539
Validation loss: 2.1175225575764975

Epoch: 190| Step: 0
Training loss: 1.5188751220703125
Validation loss: 2.0991191466649375

Epoch: 6| Step: 1
Training loss: 1.6889948844909668
Validation loss: 2.1195031007130942

Epoch: 6| Step: 2
Training loss: 2.0784788131713867
Validation loss: 2.1203545928001404

Epoch: 6| Step: 3
Training loss: 2.378056049346924
Validation loss: 2.1278884212176004

Epoch: 6| Step: 4
Training loss: 1.6256554126739502
Validation loss: 2.120389004548391

Epoch: 6| Step: 5
Training loss: 1.8685017824172974
Validation loss: 2.115501125653585

Epoch: 6| Step: 6
Training loss: 2.2127652168273926
Validation loss: 2.112553894519806

Epoch: 6| Step: 7
Training loss: 1.6925177574157715
Validation loss: 2.110192875067393

Epoch: 6| Step: 8
Training loss: 2.0552587509155273
Validation loss: 2.096992870171865

Epoch: 6| Step: 9
Training loss: 2.303403377532959
Validation loss: 2.0943395098050437

Epoch: 6| Step: 10
Training loss: 1.996655821800232
Validation loss: 2.108987271785736

Epoch: 6| Step: 11
Training loss: 2.2357091903686523
Validation loss: 2.10092822710673

Epoch: 6| Step: 12
Training loss: 1.8621656894683838
Validation loss: 2.079034924507141

Epoch: 6| Step: 13
Training loss: 1.6221767663955688
Validation loss: 2.0875070095062256

Epoch: 191| Step: 0
Training loss: 1.8278422355651855
Validation loss: 2.0865525007247925

Epoch: 6| Step: 1
Training loss: 2.3215103149414062
Validation loss: 2.093368887901306

Epoch: 6| Step: 2
Training loss: 1.850987434387207
Validation loss: 2.093445062637329

Epoch: 6| Step: 3
Training loss: 1.9058678150177002
Validation loss: 2.1018406748771667

Epoch: 6| Step: 4
Training loss: 1.629741907119751
Validation loss: 2.1034444769223533

Epoch: 6| Step: 5
Training loss: 1.9580254554748535
Validation loss: 2.1027795473734536

Epoch: 6| Step: 6
Training loss: 2.295783519744873
Validation loss: 2.092093904813131

Epoch: 6| Step: 7
Training loss: 1.816665768623352
Validation loss: 2.0847688913345337

Epoch: 6| Step: 8
Training loss: 1.7840065956115723
Validation loss: 2.0830519795417786

Epoch: 6| Step: 9
Training loss: 1.7897694110870361
Validation loss: 2.0823618372281394

Epoch: 6| Step: 10
Training loss: 2.070535182952881
Validation loss: 2.0994852582613626

Epoch: 6| Step: 11
Training loss: 2.362806797027588
Validation loss: 2.0979620615641275

Epoch: 6| Step: 12
Training loss: 1.5552904605865479
Validation loss: 2.0924541552861533

Epoch: 6| Step: 13
Training loss: 1.760286808013916
Validation loss: 2.087324380874634

Epoch: 192| Step: 0
Training loss: 2.6795902252197266
Validation loss: 2.0908416509628296

Epoch: 6| Step: 1
Training loss: 1.9433622360229492
Validation loss: 2.0929189920425415

Epoch: 6| Step: 2
Training loss: 2.0518531799316406
Validation loss: 2.110089421272278

Epoch: 6| Step: 3
Training loss: 1.4977896213531494
Validation loss: 2.1029868920644126

Epoch: 6| Step: 4
Training loss: 1.034027099609375
Validation loss: 2.0920788248380027

Epoch: 6| Step: 5
Training loss: 1.9816532135009766
Validation loss: 2.085701048374176

Epoch: 6| Step: 6
Training loss: 1.9346201419830322
Validation loss: 2.1035895148913064

Epoch: 6| Step: 7
Training loss: 1.9301934242248535
Validation loss: 2.103107531865438

Epoch: 6| Step: 8
Training loss: 1.9120784997940063
Validation loss: 2.0919262170791626

Epoch: 6| Step: 9
Training loss: 1.8217424154281616
Validation loss: 2.083551506201426

Epoch: 6| Step: 10
Training loss: 1.9801892042160034
Validation loss: 2.098807911078135

Epoch: 6| Step: 11
Training loss: 1.8402986526489258
Validation loss: 2.0968759059906006

Epoch: 6| Step: 12
Training loss: 1.6908307075500488
Validation loss: 2.1104769110679626

Epoch: 6| Step: 13
Training loss: 2.342294216156006
Validation loss: 2.0867581168810525

Epoch: 193| Step: 0
Training loss: 2.2045230865478516
Validation loss: 2.091732660929362

Epoch: 6| Step: 1
Training loss: 1.1950033903121948
Validation loss: 2.1064038077990213

Epoch: 6| Step: 2
Training loss: 2.254910945892334
Validation loss: 2.0942643086115518

Epoch: 6| Step: 3
Training loss: 2.11818528175354
Validation loss: 2.1005943218866983

Epoch: 6| Step: 4
Training loss: 1.4281895160675049
Validation loss: 2.1117809613545737

Epoch: 6| Step: 5
Training loss: 1.802449107170105
Validation loss: 2.130026340484619

Epoch: 6| Step: 6
Training loss: 2.2801761627197266
Validation loss: 2.1090773940086365

Epoch: 6| Step: 7
Training loss: 2.1174933910369873
Validation loss: 2.100359936555227

Epoch: 6| Step: 8
Training loss: 1.7307772636413574
Validation loss: 2.1078089078267417

Epoch: 6| Step: 9
Training loss: 2.4070701599121094
Validation loss: 2.11163596312205

Epoch: 6| Step: 10
Training loss: 2.1034445762634277
Validation loss: 2.0931742787361145

Epoch: 6| Step: 11
Training loss: 1.4647153615951538
Validation loss: 2.095292111237844

Epoch: 6| Step: 12
Training loss: 2.1934428215026855
Validation loss: 2.096030354499817

Epoch: 6| Step: 13
Training loss: 1.3729608058929443
Validation loss: 2.08732016881307

Epoch: 194| Step: 0
Training loss: 2.511287212371826
Validation loss: 2.110368549823761

Epoch: 6| Step: 1
Training loss: 2.2338433265686035
Validation loss: 2.100030859311422

Epoch: 6| Step: 2
Training loss: 1.6606431007385254
Validation loss: 2.092287222544352

Epoch: 6| Step: 3
Training loss: 1.9717024564743042
Validation loss: 2.110608537991842

Epoch: 6| Step: 4
Training loss: 2.106703758239746
Validation loss: 2.109765569368998

Epoch: 6| Step: 5
Training loss: 1.4716966152191162
Validation loss: 2.104721168677012

Epoch: 6| Step: 6
Training loss: 1.8744750022888184
Validation loss: 2.1255210638046265

Epoch: 6| Step: 7
Training loss: 1.9865432977676392
Validation loss: 2.0974738796552024

Epoch: 6| Step: 8
Training loss: 2.402674913406372
Validation loss: 2.109640916188558

Epoch: 6| Step: 9
Training loss: 1.7932240962982178
Validation loss: 2.1090234915415444

Epoch: 6| Step: 10
Training loss: 1.7371056079864502
Validation loss: 2.111024638017019

Epoch: 6| Step: 11
Training loss: 1.6616355180740356
Validation loss: 2.096655309200287

Epoch: 6| Step: 12
Training loss: 1.890891432762146
Validation loss: 2.1098931431770325

Epoch: 6| Step: 13
Training loss: 1.221038579940796
Validation loss: 2.097222904364268

Epoch: 195| Step: 0
Training loss: 1.8261510133743286
Validation loss: 2.1226828893025718

Epoch: 6| Step: 1
Training loss: 1.8955755233764648
Validation loss: 2.115437467892965

Epoch: 6| Step: 2
Training loss: 2.0384960174560547
Validation loss: 2.0920930902163186

Epoch: 6| Step: 3
Training loss: 1.8355729579925537
Validation loss: 2.1078607638676963

Epoch: 6| Step: 4
Training loss: 1.8415919542312622
Validation loss: 2.095747729142507

Epoch: 6| Step: 5
Training loss: 1.9701457023620605
Validation loss: 2.092022438844045

Epoch: 6| Step: 6
Training loss: 2.3213748931884766
Validation loss: 2.1035783092180886

Epoch: 6| Step: 7
Training loss: 1.9087141752243042
Validation loss: 2.1040926973025003

Epoch: 6| Step: 8
Training loss: 1.8809322118759155
Validation loss: 2.0950807531674704

Epoch: 6| Step: 9
Training loss: 2.0589792728424072
Validation loss: 2.1041464805603027

Epoch: 6| Step: 10
Training loss: 2.2219924926757812
Validation loss: 2.1009319027264914

Epoch: 6| Step: 11
Training loss: 1.7314643859863281
Validation loss: 2.1057292819023132

Epoch: 6| Step: 12
Training loss: 2.050889015197754
Validation loss: 2.119303524494171

Epoch: 6| Step: 13
Training loss: 1.3573150634765625
Validation loss: 2.090891718864441

Epoch: 196| Step: 0
Training loss: 1.833725094795227
Validation loss: 2.107118785381317

Epoch: 6| Step: 1
Training loss: 1.8842241764068604
Validation loss: 2.1070874532063804

Epoch: 6| Step: 2
Training loss: 1.6070574522018433
Validation loss: 2.105385661125183

Epoch: 6| Step: 3
Training loss: 1.633008360862732
Validation loss: 2.1007242798805237

Epoch: 6| Step: 4
Training loss: 2.5411741733551025
Validation loss: 2.10359126329422

Epoch: 6| Step: 5
Training loss: 1.6751527786254883
Validation loss: 2.0938018361727395

Epoch: 6| Step: 6
Training loss: 1.9744904041290283
Validation loss: 2.094236691792806

Epoch: 6| Step: 7
Training loss: 1.6675338745117188
Validation loss: 2.1073997616767883

Epoch: 6| Step: 8
Training loss: 1.8100327253341675
Validation loss: 2.104721426963806

Epoch: 6| Step: 9
Training loss: 2.232043743133545
Validation loss: 2.110873222351074

Epoch: 6| Step: 10
Training loss: 2.038034439086914
Validation loss: 2.125433921813965

Epoch: 6| Step: 11
Training loss: 1.6447138786315918
Validation loss: 2.117054601510366

Epoch: 6| Step: 12
Training loss: 2.5352044105529785
Validation loss: 2.1113698879877725

Epoch: 6| Step: 13
Training loss: 1.8561052083969116
Validation loss: 2.1043183406194053

Epoch: 197| Step: 0
Training loss: 1.4182724952697754
Validation loss: 2.11516801516215

Epoch: 6| Step: 1
Training loss: 1.7269688844680786
Validation loss: 2.121801495552063

Epoch: 6| Step: 2
Training loss: 1.6038196086883545
Validation loss: 2.1305832266807556

Epoch: 6| Step: 3
Training loss: 2.273390769958496
Validation loss: 2.1097901463508606

Epoch: 6| Step: 4
Training loss: 1.6760311126708984
Validation loss: 2.1223822037378945

Epoch: 6| Step: 5
Training loss: 1.8247487545013428
Validation loss: 2.1157785256703696

Epoch: 6| Step: 6
Training loss: 2.1142780780792236
Validation loss: 2.1039987206459045

Epoch: 6| Step: 7
Training loss: 2.075679302215576
Validation loss: 2.1222002704938254

Epoch: 6| Step: 8
Training loss: 2.1063742637634277
Validation loss: 2.120644211769104

Epoch: 6| Step: 9
Training loss: 1.646820306777954
Validation loss: 2.1129878958066306

Epoch: 6| Step: 10
Training loss: 1.6642237901687622
Validation loss: 2.102638324101766

Epoch: 6| Step: 11
Training loss: 2.2730154991149902
Validation loss: 2.1053880055745444

Epoch: 6| Step: 12
Training loss: 2.202909469604492
Validation loss: 2.111296236515045

Epoch: 6| Step: 13
Training loss: 2.455467700958252
Validation loss: 2.1073558926582336

Epoch: 198| Step: 0
Training loss: 1.4839909076690674
Validation loss: 2.1197351018587747

Epoch: 6| Step: 1
Training loss: 2.3341240882873535
Validation loss: 2.1177478035291037

Epoch: 6| Step: 2
Training loss: 1.8584022521972656
Validation loss: 2.1226062575976052

Epoch: 6| Step: 3
Training loss: 2.201462507247925
Validation loss: 2.1224012772242227

Epoch: 6| Step: 4
Training loss: 1.5416765213012695
Validation loss: 2.1156911651293435

Epoch: 6| Step: 5
Training loss: 1.5255359411239624
Validation loss: 2.1237974762916565

Epoch: 6| Step: 6
Training loss: 2.5515830516815186
Validation loss: 2.101854940255483

Epoch: 6| Step: 7
Training loss: 1.5269079208374023
Validation loss: 2.110251863797506

Epoch: 6| Step: 8
Training loss: 1.8678295612335205
Validation loss: 2.1097606420516968

Epoch: 6| Step: 9
Training loss: 2.2581944465637207
Validation loss: 2.092829684416453

Epoch: 6| Step: 10
Training loss: 2.1663949489593506
Validation loss: 2.0939976374308267

Epoch: 6| Step: 11
Training loss: 1.8575536012649536
Validation loss: 2.10380220413208

Epoch: 6| Step: 12
Training loss: 1.972522258758545
Validation loss: 2.1213406324386597

Epoch: 6| Step: 13
Training loss: 1.3628911972045898
Validation loss: 2.1097949147224426

Epoch: 199| Step: 0
Training loss: 1.7219678163528442
Validation loss: 2.111304740111033

Epoch: 6| Step: 1
Training loss: 1.6765947341918945
Validation loss: 2.131305535634359

Epoch: 6| Step: 2
Training loss: 1.6076228618621826
Validation loss: 2.1075541973114014

Epoch: 6| Step: 3
Training loss: 1.7013157606124878
Validation loss: 2.119184374809265

Epoch: 6| Step: 4
Training loss: 1.8981494903564453
Validation loss: 2.1065059701601663

Epoch: 6| Step: 5
Training loss: 1.6092134714126587
Validation loss: 2.116308013598124

Epoch: 6| Step: 6
Training loss: 1.8307690620422363
Validation loss: 2.122761329015096

Epoch: 6| Step: 7
Training loss: 2.2320783138275146
Validation loss: 2.1054386496543884

Epoch: 6| Step: 8
Training loss: 1.936474084854126
Validation loss: 2.0816652178764343

Epoch: 6| Step: 9
Training loss: 2.4388914108276367
Validation loss: 2.1112418174743652

Epoch: 6| Step: 10
Training loss: 2.056891441345215
Validation loss: 2.114010135332743

Epoch: 6| Step: 11
Training loss: 1.8881112337112427
Validation loss: 2.1037981510162354

Epoch: 6| Step: 12
Training loss: 1.8016133308410645
Validation loss: 2.106640378634135

Epoch: 6| Step: 13
Training loss: 2.1522085666656494
Validation loss: 2.102804481983185

Epoch: 200| Step: 0
Training loss: 2.0135347843170166
Validation loss: 2.097500423590342

Epoch: 6| Step: 1
Training loss: 1.6032514572143555
Validation loss: 2.108349084854126

Epoch: 6| Step: 2
Training loss: 1.948822021484375
Validation loss: 2.089978496233622

Epoch: 6| Step: 3
Training loss: 2.200282573699951
Validation loss: 2.1004483501116433

Epoch: 6| Step: 4
Training loss: 2.1298351287841797
Validation loss: 2.107718368371328

Epoch: 6| Step: 5
Training loss: 1.8523298501968384
Validation loss: 2.1058412194252014

Epoch: 6| Step: 6
Training loss: 2.2854795455932617
Validation loss: 2.1288131872812905

Epoch: 6| Step: 7
Training loss: 1.9568028450012207
Validation loss: 2.118667562802633

Epoch: 6| Step: 8
Training loss: 2.0207948684692383
Validation loss: 2.1318479776382446

Epoch: 6| Step: 9
Training loss: 2.140533924102783
Validation loss: 2.1165271401405334

Epoch: 6| Step: 10
Training loss: 2.0030264854431152
Validation loss: 2.1200615962346396

Epoch: 6| Step: 11
Training loss: 1.8433806896209717
Validation loss: 2.125031510988871

Epoch: 6| Step: 12
Training loss: 1.4553338289260864
Validation loss: 2.107643743356069

Epoch: 6| Step: 13
Training loss: 1.4855871200561523
Validation loss: 2.107684830824534

Epoch: 201| Step: 0
Training loss: 1.9227676391601562
Validation loss: 2.097706397374471

Epoch: 6| Step: 1
Training loss: 2.5603933334350586
Validation loss: 2.119857132434845

Epoch: 6| Step: 2
Training loss: 1.2554311752319336
Validation loss: 2.1170588533083596

Epoch: 6| Step: 3
Training loss: 1.4925578832626343
Validation loss: 2.1389254331588745

Epoch: 6| Step: 4
Training loss: 1.7509582042694092
Validation loss: 2.1185742219289145

Epoch: 6| Step: 5
Training loss: 1.733586072921753
Validation loss: 2.1146669387817383

Epoch: 6| Step: 6
Training loss: 2.117771625518799
Validation loss: 2.0995307564735413

Epoch: 6| Step: 7
Training loss: 1.9236856698989868
Validation loss: 2.120857755343119

Epoch: 6| Step: 8
Training loss: 2.2764837741851807
Validation loss: 2.122925122578939

Epoch: 6| Step: 9
Training loss: 2.3330137729644775
Validation loss: 2.126592457294464

Epoch: 6| Step: 10
Training loss: 1.8457388877868652
Validation loss: 2.1243088841438293

Epoch: 6| Step: 11
Training loss: 1.8248343467712402
Validation loss: 2.121694803237915

Epoch: 6| Step: 12
Training loss: 2.254544258117676
Validation loss: 2.104418317476908

Epoch: 6| Step: 13
Training loss: 1.311884880065918
Validation loss: 2.106143315633138

Epoch: 202| Step: 0
Training loss: 2.79443359375
Validation loss: 2.1161239544550576

Epoch: 6| Step: 1
Training loss: 1.7095510959625244
Validation loss: 2.108001192410787

Epoch: 6| Step: 2
Training loss: 1.465898036956787
Validation loss: 2.117415726184845

Epoch: 6| Step: 3
Training loss: 1.385439395904541
Validation loss: 2.1145608027776084

Epoch: 6| Step: 4
Training loss: 1.4862959384918213
Validation loss: 2.114981253941854

Epoch: 6| Step: 5
Training loss: 1.9779486656188965
Validation loss: 2.1166369120279946

Epoch: 6| Step: 6
Training loss: 2.210691452026367
Validation loss: 2.1219275991121926

Epoch: 6| Step: 7
Training loss: 2.407628297805786
Validation loss: 2.09829580783844

Epoch: 6| Step: 8
Training loss: 1.595393419265747
Validation loss: 2.122146944204966

Epoch: 6| Step: 9
Training loss: 1.9013079404830933
Validation loss: 2.1092143654823303

Epoch: 6| Step: 10
Training loss: 1.9057464599609375
Validation loss: 2.124436914920807

Epoch: 6| Step: 11
Training loss: 1.9473391771316528
Validation loss: 2.108903487523397

Epoch: 6| Step: 12
Training loss: 2.0060343742370605
Validation loss: 2.115175724029541

Epoch: 6| Step: 13
Training loss: 1.4479312896728516
Validation loss: 2.1179106036822

Epoch: 203| Step: 0
Training loss: 1.5711262226104736
Validation loss: 2.1210573315620422

Epoch: 6| Step: 1
Training loss: 1.9307161569595337
Validation loss: 2.1119084556897483

Epoch: 6| Step: 2
Training loss: 2.446702241897583
Validation loss: 2.1146525541941323

Epoch: 6| Step: 3
Training loss: 1.7449630498886108
Validation loss: 2.1090747117996216

Epoch: 6| Step: 4
Training loss: 1.6916513442993164
Validation loss: 2.1158050100008645

Epoch: 6| Step: 5
Training loss: 2.680063486099243
Validation loss: 2.108340779940287

Epoch: 6| Step: 6
Training loss: 1.7535244226455688
Validation loss: 2.116102119286855

Epoch: 6| Step: 7
Training loss: 2.076118230819702
Validation loss: 2.1055270234743753

Epoch: 6| Step: 8
Training loss: 1.5067909955978394
Validation loss: 2.098733822504679

Epoch: 6| Step: 9
Training loss: 1.915617823600769
Validation loss: 2.102042774359385

Epoch: 6| Step: 10
Training loss: 2.3423004150390625
Validation loss: 2.0981483459472656

Epoch: 6| Step: 11
Training loss: 1.6812933683395386
Validation loss: 2.108751038710276

Epoch: 6| Step: 12
Training loss: 1.8430509567260742
Validation loss: 2.101262887318929

Epoch: 6| Step: 13
Training loss: 1.474913477897644
Validation loss: 2.1070934534072876

Epoch: 204| Step: 0
Training loss: 2.0690484046936035
Validation loss: 2.1154685616493225

Epoch: 6| Step: 1
Training loss: 1.7041599750518799
Validation loss: 2.102099517981211

Epoch: 6| Step: 2
Training loss: 2.0875422954559326
Validation loss: 2.1056451002756753

Epoch: 6| Step: 3
Training loss: 2.039405584335327
Validation loss: 2.1146139899889627

Epoch: 6| Step: 4
Training loss: 2.1263625621795654
Validation loss: 2.105613191922506

Epoch: 6| Step: 5
Training loss: 2.308393955230713
Validation loss: 2.109887719154358

Epoch: 6| Step: 6
Training loss: 1.5377016067504883
Validation loss: 2.1073268254597983

Epoch: 6| Step: 7
Training loss: 1.4048418998718262
Validation loss: 2.1128563284873962

Epoch: 6| Step: 8
Training loss: 1.8721073865890503
Validation loss: 2.112807273864746

Epoch: 6| Step: 9
Training loss: 2.2650930881500244
Validation loss: 2.1242814461390176

Epoch: 6| Step: 10
Training loss: 1.469449758529663
Validation loss: 2.116626044114431

Epoch: 6| Step: 11
Training loss: 1.8726882934570312
Validation loss: 2.113958418369293

Epoch: 6| Step: 12
Training loss: 2.3328347206115723
Validation loss: 2.1393559177716575

Epoch: 6| Step: 13
Training loss: 1.586878776550293
Validation loss: 2.1268938183784485

Epoch: 205| Step: 0
Training loss: 2.5130817890167236
Validation loss: 2.126232922077179

Epoch: 6| Step: 1
Training loss: 1.2425310611724854
Validation loss: 2.1247081756591797

Epoch: 6| Step: 2
Training loss: 1.9276437759399414
Validation loss: 2.1300115386644998

Epoch: 6| Step: 3
Training loss: 2.245286226272583
Validation loss: 2.137397567431132

Epoch: 6| Step: 4
Training loss: 1.9159955978393555
Validation loss: 2.1322155793507895

Epoch: 6| Step: 5
Training loss: 1.8432940244674683
Validation loss: 2.1284490823745728

Epoch: 6| Step: 6
Training loss: 1.9745945930480957
Validation loss: 2.1107612252235413

Epoch: 6| Step: 7
Training loss: 2.307225227355957
Validation loss: 2.1249911785125732

Epoch: 6| Step: 8
Training loss: 2.3840432167053223
Validation loss: 2.1286683877309165

Epoch: 6| Step: 9
Training loss: 1.6574480533599854
Validation loss: 2.1191489696502686

Epoch: 6| Step: 10
Training loss: 0.9631040096282959
Validation loss: 2.107672611872355

Epoch: 6| Step: 11
Training loss: 2.025300979614258
Validation loss: 2.1173694133758545

Epoch: 6| Step: 12
Training loss: 2.1216578483581543
Validation loss: 2.11435995499293

Epoch: 6| Step: 13
Training loss: 1.380894660949707
Validation loss: 2.1265861789385476

Epoch: 206| Step: 0
Training loss: 1.655685544013977
Validation loss: 2.125542481740316

Epoch: 6| Step: 1
Training loss: 1.9559402465820312
Validation loss: 2.1135266423225403

Epoch: 6| Step: 2
Training loss: 2.534186601638794
Validation loss: 2.1121910413106284

Epoch: 6| Step: 3
Training loss: 1.8857755661010742
Validation loss: 2.118692855040232

Epoch: 6| Step: 4
Training loss: 1.828488826751709
Validation loss: 2.110807180404663

Epoch: 6| Step: 5
Training loss: 1.6285057067871094
Validation loss: 2.1281465689341226

Epoch: 6| Step: 6
Training loss: 1.55037522315979
Validation loss: 2.126460095246633

Epoch: 6| Step: 7
Training loss: 2.100430488586426
Validation loss: 2.1318768660227456

Epoch: 6| Step: 8
Training loss: 1.921574592590332
Validation loss: 2.1042420069376626

Epoch: 6| Step: 9
Training loss: 1.3766200542449951
Validation loss: 2.1127283771832785

Epoch: 6| Step: 10
Training loss: 1.7876262664794922
Validation loss: 2.1236413717269897

Epoch: 6| Step: 11
Training loss: 1.86875581741333
Validation loss: 2.1345993876457214

Epoch: 6| Step: 12
Training loss: 2.213214159011841
Validation loss: 2.1171576182047525

Epoch: 6| Step: 13
Training loss: 1.8569889068603516
Validation loss: 2.1127707958221436

Epoch: 207| Step: 0
Training loss: 2.2070508003234863
Validation loss: 2.128176728884379

Epoch: 6| Step: 1
Training loss: 2.1858837604522705
Validation loss: 2.1167269547780356

Epoch: 6| Step: 2
Training loss: 2.204648017883301
Validation loss: 2.10695747534434

Epoch: 6| Step: 3
Training loss: 1.7931547164916992
Validation loss: 2.1295566956202188

Epoch: 6| Step: 4
Training loss: 1.7398285865783691
Validation loss: 2.1209571162859597

Epoch: 6| Step: 5
Training loss: 1.7676547765731812
Validation loss: 2.120600680510203

Epoch: 6| Step: 6
Training loss: 1.6865942478179932
Validation loss: 2.1177416245142617

Epoch: 6| Step: 7
Training loss: 1.3540728092193604
Validation loss: 2.129695773124695

Epoch: 6| Step: 8
Training loss: 2.0406746864318848
Validation loss: 2.1292011737823486

Epoch: 6| Step: 9
Training loss: 1.7200310230255127
Validation loss: 2.1210216283798218

Epoch: 6| Step: 10
Training loss: 1.7905298471450806
Validation loss: 2.122900684674581

Epoch: 6| Step: 11
Training loss: 1.6617413759231567
Validation loss: 2.1170754631360373

Epoch: 6| Step: 12
Training loss: 2.0933291912078857
Validation loss: 2.134661376476288

Epoch: 6| Step: 13
Training loss: 2.1566381454467773
Validation loss: 2.1335456569989524

Epoch: 208| Step: 0
Training loss: 2.0238208770751953
Validation loss: 2.1216827829678855

Epoch: 6| Step: 1
Training loss: 1.987168550491333
Validation loss: 2.1254082123438516

Epoch: 6| Step: 2
Training loss: 1.7830440998077393
Validation loss: 2.125701447327932

Epoch: 6| Step: 3
Training loss: 1.537355899810791
Validation loss: 2.1194026867548623

Epoch: 6| Step: 4
Training loss: 2.509575366973877
Validation loss: 2.128634214401245

Epoch: 6| Step: 5
Training loss: 1.7718645334243774
Validation loss: 2.1184775630633035

Epoch: 6| Step: 6
Training loss: 2.8125131130218506
Validation loss: 2.113379200299581

Epoch: 6| Step: 7
Training loss: 1.267496943473816
Validation loss: 2.1391930182774863

Epoch: 6| Step: 8
Training loss: 1.7477695941925049
Validation loss: 2.1466554403305054

Epoch: 6| Step: 9
Training loss: 1.8362855911254883
Validation loss: 2.1339828173319497

Epoch: 6| Step: 10
Training loss: 2.256779909133911
Validation loss: 2.1297953128814697

Epoch: 6| Step: 11
Training loss: 1.4220950603485107
Validation loss: 2.1338785886764526

Epoch: 6| Step: 12
Training loss: 1.9002983570098877
Validation loss: 2.140594998995463

Epoch: 6| Step: 13
Training loss: 1.4340450763702393
Validation loss: 2.125539720058441

Epoch: 209| Step: 0
Training loss: 1.500722885131836
Validation loss: 2.129932403564453

Epoch: 6| Step: 1
Training loss: 1.9184585809707642
Validation loss: 2.1357651948928833

Epoch: 6| Step: 2
Training loss: 1.7271884679794312
Validation loss: 2.1192525823911033

Epoch: 6| Step: 3
Training loss: 2.2837395668029785
Validation loss: 2.1079895893732705

Epoch: 6| Step: 4
Training loss: 1.9654340744018555
Validation loss: 2.1049372355143228

Epoch: 6| Step: 5
Training loss: 2.0133578777313232
Validation loss: 2.118564565976461

Epoch: 6| Step: 6
Training loss: 1.5394216775894165
Validation loss: 2.128123124440511

Epoch: 6| Step: 7
Training loss: 2.231893301010132
Validation loss: 2.120786964893341

Epoch: 6| Step: 8
Training loss: 2.009890079498291
Validation loss: 2.1120680769284568

Epoch: 6| Step: 9
Training loss: 1.7137691974639893
Validation loss: 2.105331540107727

Epoch: 6| Step: 10
Training loss: 2.055248737335205
Validation loss: 2.118661959966024

Epoch: 6| Step: 11
Training loss: 2.0826001167297363
Validation loss: 2.1096779505411782

Epoch: 6| Step: 12
Training loss: 1.715951919555664
Validation loss: 2.1235810915629068

Epoch: 6| Step: 13
Training loss: 2.071251392364502
Validation loss: 2.1158642371495566

Epoch: 210| Step: 0
Training loss: 1.4897691011428833
Validation loss: 2.1033700108528137

Epoch: 6| Step: 1
Training loss: 2.2818195819854736
Validation loss: 2.1159090797106423

Epoch: 6| Step: 2
Training loss: 2.329721212387085
Validation loss: 2.110558867454529

Epoch: 6| Step: 3
Training loss: 1.4734580516815186
Validation loss: 2.111574033896128

Epoch: 6| Step: 4
Training loss: 1.3258185386657715
Validation loss: 2.1158244808514914

Epoch: 6| Step: 5
Training loss: 2.5343704223632812
Validation loss: 2.1233463883399963

Epoch: 6| Step: 6
Training loss: 1.6544437408447266
Validation loss: 2.115143676598867

Epoch: 6| Step: 7
Training loss: 1.6406916379928589
Validation loss: 2.102896571159363

Epoch: 6| Step: 8
Training loss: 2.513302803039551
Validation loss: 2.1204814116160073

Epoch: 6| Step: 9
Training loss: 1.939022421836853
Validation loss: 2.112482786178589

Epoch: 6| Step: 10
Training loss: 1.7975298166275024
Validation loss: 2.122145334879557

Epoch: 6| Step: 11
Training loss: 1.5298593044281006
Validation loss: 2.1093578139940896

Epoch: 6| Step: 12
Training loss: 2.0465309619903564
Validation loss: 2.1181931098302207

Epoch: 6| Step: 13
Training loss: 1.8089673519134521
Validation loss: 2.120115021864573

Epoch: 211| Step: 0
Training loss: 1.9026424884796143
Validation loss: 2.0980285008748374

Epoch: 6| Step: 1
Training loss: 1.8440525531768799
Validation loss: 2.126731355985006

Epoch: 6| Step: 2
Training loss: 1.6583932638168335
Validation loss: 2.1147269010543823

Epoch: 6| Step: 3
Training loss: 2.056588888168335
Validation loss: 2.1204868157704673

Epoch: 6| Step: 4
Training loss: 1.5351643562316895
Validation loss: 2.1148770650227866

Epoch: 6| Step: 5
Training loss: 2.2867212295532227
Validation loss: 2.131349782148997

Epoch: 6| Step: 6
Training loss: 1.1481528282165527
Validation loss: 2.1131762266159058

Epoch: 6| Step: 7
Training loss: 1.8257677555084229
Validation loss: 2.10681813955307

Epoch: 6| Step: 8
Training loss: 2.4317660331726074
Validation loss: 2.1251771251360574

Epoch: 6| Step: 9
Training loss: 2.336090087890625
Validation loss: 2.1225311160087585

Epoch: 6| Step: 10
Training loss: 1.6504563093185425
Validation loss: 2.1179256240526834

Epoch: 6| Step: 11
Training loss: 1.6138875484466553
Validation loss: 2.1211318572362265

Epoch: 6| Step: 12
Training loss: 1.5974560976028442
Validation loss: 2.1233359575271606

Epoch: 6| Step: 13
Training loss: 2.0749666690826416
Validation loss: 2.101457357406616

Epoch: 212| Step: 0
Training loss: 1.8171346187591553
Validation loss: 2.1219533483187356

Epoch: 6| Step: 1
Training loss: 1.434389591217041
Validation loss: 2.1012842059135437

Epoch: 6| Step: 2
Training loss: 2.2325892448425293
Validation loss: 2.1187785466512046

Epoch: 6| Step: 3
Training loss: 1.494960069656372
Validation loss: 2.1175661087036133

Epoch: 6| Step: 4
Training loss: 2.2288625240325928
Validation loss: 2.1050788958867392

Epoch: 6| Step: 5
Training loss: 1.560660481452942
Validation loss: 2.1153674721717834

Epoch: 6| Step: 6
Training loss: 1.4930287599563599
Validation loss: 2.1379630963007608

Epoch: 6| Step: 7
Training loss: 1.2548915147781372
Validation loss: 2.1159613529841104

Epoch: 6| Step: 8
Training loss: 1.968643307685852
Validation loss: 2.1109557350476584

Epoch: 6| Step: 9
Training loss: 2.4263663291931152
Validation loss: 2.1255208452542624

Epoch: 6| Step: 10
Training loss: 2.3850698471069336
Validation loss: 2.1209693352381387

Epoch: 6| Step: 11
Training loss: 2.013610363006592
Validation loss: 2.1277700662612915

Epoch: 6| Step: 12
Training loss: 1.9821068048477173
Validation loss: 2.126262664794922

Epoch: 6| Step: 13
Training loss: 1.4805407524108887
Validation loss: 2.1273278991381326

Epoch: 213| Step: 0
Training loss: 2.12905216217041
Validation loss: 2.1006449659665427

Epoch: 6| Step: 1
Training loss: 1.7788982391357422
Validation loss: 2.1233944098154702

Epoch: 6| Step: 2
Training loss: 1.3224272727966309
Validation loss: 2.097216546535492

Epoch: 6| Step: 3
Training loss: 1.5015026330947876
Validation loss: 2.1288443009058633

Epoch: 6| Step: 4
Training loss: 2.137415885925293
Validation loss: 2.1088473995526633

Epoch: 6| Step: 5
Training loss: 1.1610209941864014
Validation loss: 2.1328537464141846

Epoch: 6| Step: 6
Training loss: 2.143190860748291
Validation loss: 2.1260753870010376

Epoch: 6| Step: 7
Training loss: 1.7758166790008545
Validation loss: 2.133581360181173

Epoch: 6| Step: 8
Training loss: 1.642208456993103
Validation loss: 2.137038767337799

Epoch: 6| Step: 9
Training loss: 1.9052826166152954
Validation loss: 2.1300100286801658

Epoch: 6| Step: 10
Training loss: 2.454122543334961
Validation loss: 2.129861811796824

Epoch: 6| Step: 11
Training loss: 2.174654245376587
Validation loss: 2.1249501506487527

Epoch: 6| Step: 12
Training loss: 1.9389986991882324
Validation loss: 2.1302746534347534

Epoch: 6| Step: 13
Training loss: 1.5667259693145752
Validation loss: 2.1492639780044556

Epoch: 214| Step: 0
Training loss: 2.1180737018585205
Validation loss: 2.140827496846517

Epoch: 6| Step: 1
Training loss: 2.0044078826904297
Validation loss: 2.1439937949180603

Epoch: 6| Step: 2
Training loss: 1.660302996635437
Validation loss: 2.128650426864624

Epoch: 6| Step: 3
Training loss: 2.357565402984619
Validation loss: 2.1478758255640664

Epoch: 6| Step: 4
Training loss: 2.1311092376708984
Validation loss: 2.1436449686686196

Epoch: 6| Step: 5
Training loss: 1.4611271619796753
Validation loss: 2.1372662782669067

Epoch: 6| Step: 6
Training loss: 1.6896798610687256
Validation loss: 2.120573957761129

Epoch: 6| Step: 7
Training loss: 1.821047306060791
Validation loss: 2.1185452342033386

Epoch: 6| Step: 8
Training loss: 2.1306748390197754
Validation loss: 2.1104511618614197

Epoch: 6| Step: 9
Training loss: 2.026864528656006
Validation loss: 2.1231541633605957

Epoch: 6| Step: 10
Training loss: 1.612546682357788
Validation loss: 2.1084075570106506

Epoch: 6| Step: 11
Training loss: 1.5225133895874023
Validation loss: 2.1352737744649253

Epoch: 6| Step: 12
Training loss: 1.4268677234649658
Validation loss: 2.1207650899887085

Epoch: 6| Step: 13
Training loss: 2.152005672454834
Validation loss: 2.130903879801432

Epoch: 215| Step: 0
Training loss: 2.091470718383789
Validation loss: 2.140467663606008

Epoch: 6| Step: 1
Training loss: 1.866590976715088
Validation loss: 2.1319137811660767

Epoch: 6| Step: 2
Training loss: 2.2657952308654785
Validation loss: 2.1506393551826477

Epoch: 6| Step: 3
Training loss: 1.6116039752960205
Validation loss: 2.1323073506355286

Epoch: 6| Step: 4
Training loss: 1.3922550678253174
Validation loss: 2.127018133799235

Epoch: 6| Step: 5
Training loss: 2.2029480934143066
Validation loss: 2.143021504084269

Epoch: 6| Step: 6
Training loss: 1.5946240425109863
Validation loss: 2.1251540184020996

Epoch: 6| Step: 7
Training loss: 1.8824481964111328
Validation loss: 2.1293548345565796

Epoch: 6| Step: 8
Training loss: 1.9900867938995361
Validation loss: 2.1174599726994834

Epoch: 6| Step: 9
Training loss: 1.932480812072754
Validation loss: 2.1270618637402854

Epoch: 6| Step: 10
Training loss: 1.9151511192321777
Validation loss: 2.132417400677999

Epoch: 6| Step: 11
Training loss: 1.9193224906921387
Validation loss: 2.1366114020347595

Epoch: 6| Step: 12
Training loss: 1.2905113697052002
Validation loss: 2.142067074775696

Epoch: 6| Step: 13
Training loss: 1.8672876358032227
Validation loss: 2.1457536021868386

Epoch: 216| Step: 0
Training loss: 2.1497302055358887
Validation loss: 2.137324253718058

Epoch: 6| Step: 1
Training loss: 1.6887898445129395
Validation loss: 2.1440800031026206

Epoch: 6| Step: 2
Training loss: 1.904165506362915
Validation loss: 2.14908500512441

Epoch: 6| Step: 3
Training loss: 1.298567533493042
Validation loss: 2.1431832313537598

Epoch: 6| Step: 4
Training loss: 1.3420615196228027
Validation loss: 2.1315278808275857

Epoch: 6| Step: 5
Training loss: 2.1915040016174316
Validation loss: 2.1494906346003213

Epoch: 6| Step: 6
Training loss: 1.9799330234527588
Validation loss: 2.1324992974599204

Epoch: 6| Step: 7
Training loss: 2.076211929321289
Validation loss: 2.128119786580404

Epoch: 6| Step: 8
Training loss: 2.4663186073303223
Validation loss: 2.123157242933909

Epoch: 6| Step: 9
Training loss: 1.8818278312683105
Validation loss: 2.133630176385244

Epoch: 6| Step: 10
Training loss: 2.0614047050476074
Validation loss: 2.1389315724372864

Epoch: 6| Step: 11
Training loss: 1.5741925239562988
Validation loss: 2.1143336296081543

Epoch: 6| Step: 12
Training loss: 1.341752052307129
Validation loss: 2.119580070177714

Epoch: 6| Step: 13
Training loss: 1.7993078231811523
Validation loss: 2.122555692990621

Epoch: 217| Step: 0
Training loss: 1.1962721347808838
Validation loss: 2.1469939947128296

Epoch: 6| Step: 1
Training loss: 2.3420562744140625
Validation loss: 2.1460149685541787

Epoch: 6| Step: 2
Training loss: 1.3989731073379517
Validation loss: 2.136301259199778

Epoch: 6| Step: 3
Training loss: 1.9741110801696777
Validation loss: 2.1571523745854697

Epoch: 6| Step: 4
Training loss: 1.725636601448059
Validation loss: 2.1405638456344604

Epoch: 6| Step: 5
Training loss: 1.8009016513824463
Validation loss: 2.1530206402142844

Epoch: 6| Step: 6
Training loss: 2.552549362182617
Validation loss: 2.150175670782725

Epoch: 6| Step: 7
Training loss: 1.7094508409500122
Validation loss: 2.1354112029075623

Epoch: 6| Step: 8
Training loss: 1.8389779329299927
Validation loss: 2.1439457337061563

Epoch: 6| Step: 9
Training loss: 2.0477776527404785
Validation loss: 2.129746357599894

Epoch: 6| Step: 10
Training loss: 1.8570187091827393
Validation loss: 2.1402169466018677

Epoch: 6| Step: 11
Training loss: 1.715414047241211
Validation loss: 2.1494290828704834

Epoch: 6| Step: 12
Training loss: 2.105360984802246
Validation loss: 2.1448248823483786

Epoch: 6| Step: 13
Training loss: 1.4218394756317139
Validation loss: 2.1477187275886536

Epoch: 218| Step: 0
Training loss: 1.7481993436813354
Validation loss: 2.1304269234339395

Epoch: 6| Step: 1
Training loss: 1.462005376815796
Validation loss: 2.1480321884155273

Epoch: 6| Step: 2
Training loss: 2.759681463241577
Validation loss: 2.126992424329122

Epoch: 6| Step: 3
Training loss: 2.479470729827881
Validation loss: 2.121396561463674

Epoch: 6| Step: 4
Training loss: 1.8153231143951416
Validation loss: 2.1432955463727317

Epoch: 6| Step: 5
Training loss: 1.589935064315796
Validation loss: 2.1125802596410117

Epoch: 6| Step: 6
Training loss: 1.7598977088928223
Validation loss: 2.1252622604370117

Epoch: 6| Step: 7
Training loss: 1.575702428817749
Validation loss: 2.1144004265467324

Epoch: 6| Step: 8
Training loss: 1.4902937412261963
Validation loss: 2.1197201212247214

Epoch: 6| Step: 9
Training loss: 1.3937010765075684
Validation loss: 2.1163264314333596

Epoch: 6| Step: 10
Training loss: 1.7274223566055298
Validation loss: 2.1204466223716736

Epoch: 6| Step: 11
Training loss: 1.9164270162582397
Validation loss: 2.1407033801078796

Epoch: 6| Step: 12
Training loss: 1.9595890045166016
Validation loss: 2.1524208386739097

Epoch: 6| Step: 13
Training loss: 2.120725631713867
Validation loss: 2.1551987131436667

Epoch: 219| Step: 0
Training loss: 1.5292611122131348
Validation loss: 2.1569908261299133

Epoch: 6| Step: 1
Training loss: 2.109855890274048
Validation loss: 2.146480917930603

Epoch: 6| Step: 2
Training loss: 2.4568710327148438
Validation loss: 2.145876129468282

Epoch: 6| Step: 3
Training loss: 2.3191277980804443
Validation loss: 2.148991366227468

Epoch: 6| Step: 4
Training loss: 1.5708129405975342
Validation loss: 2.1429742177327475

Epoch: 6| Step: 5
Training loss: 1.400094985961914
Validation loss: 2.1256128748257956

Epoch: 6| Step: 6
Training loss: 1.6003680229187012
Validation loss: 2.1261151830355325

Epoch: 6| Step: 7
Training loss: 1.5374858379364014
Validation loss: 2.150141656398773

Epoch: 6| Step: 8
Training loss: 2.220837354660034
Validation loss: 2.147566835085551

Epoch: 6| Step: 9
Training loss: 2.581547498703003
Validation loss: 2.155816972255707

Epoch: 6| Step: 10
Training loss: 1.577073097229004
Validation loss: 2.1338632504145303

Epoch: 6| Step: 11
Training loss: 1.623075246810913
Validation loss: 2.127300481001536

Epoch: 6| Step: 12
Training loss: 1.5674216747283936
Validation loss: 2.141319970289866

Epoch: 6| Step: 13
Training loss: 1.457546591758728
Validation loss: 2.143469254175822

Epoch: 220| Step: 0
Training loss: 1.9091405868530273
Validation loss: 2.150135099887848

Epoch: 6| Step: 1
Training loss: 1.8417879343032837
Validation loss: 2.140251080195109

Epoch: 6| Step: 2
Training loss: 1.2537040710449219
Validation loss: 2.1384117801984153

Epoch: 6| Step: 3
Training loss: 2.1554393768310547
Validation loss: 2.1290396650632224

Epoch: 6| Step: 4
Training loss: 1.4511122703552246
Validation loss: 2.1450660030047097

Epoch: 6| Step: 5
Training loss: 2.4145846366882324
Validation loss: 2.1304448445638022

Epoch: 6| Step: 6
Training loss: 1.7982492446899414
Validation loss: 2.1366848150889077

Epoch: 6| Step: 7
Training loss: 1.1112494468688965
Validation loss: 2.1168466210365295

Epoch: 6| Step: 8
Training loss: 3.1750993728637695
Validation loss: 2.125600278377533

Epoch: 6| Step: 9
Training loss: 2.1651813983917236
Validation loss: 2.1339815258979797

Epoch: 6| Step: 10
Training loss: 1.626147985458374
Validation loss: 2.1198297142982483

Epoch: 6| Step: 11
Training loss: 1.4920800924301147
Validation loss: 2.1278520822525024

Epoch: 6| Step: 12
Training loss: 1.3120760917663574
Validation loss: 2.1075143814086914

Epoch: 6| Step: 13
Training loss: 2.0557103157043457
Validation loss: 2.1221160888671875

Epoch: 221| Step: 0
Training loss: 2.1333584785461426
Validation loss: 2.1391450564066568

Epoch: 6| Step: 1
Training loss: 1.9765565395355225
Validation loss: 2.107858975728353

Epoch: 6| Step: 2
Training loss: 1.9946497678756714
Validation loss: 2.127257287502289

Epoch: 6| Step: 3
Training loss: 1.5337345600128174
Validation loss: 2.111408770084381

Epoch: 6| Step: 4
Training loss: 1.3470481634140015
Validation loss: 2.128012180328369

Epoch: 6| Step: 5
Training loss: 1.7505584955215454
Validation loss: 2.106404741605123

Epoch: 6| Step: 6
Training loss: 1.793522596359253
Validation loss: 2.124928911526998

Epoch: 6| Step: 7
Training loss: 1.6032328605651855
Validation loss: 2.1201160550117493

Epoch: 6| Step: 8
Training loss: 1.7645847797393799
Validation loss: 2.1203331549962363

Epoch: 6| Step: 9
Training loss: 2.319014549255371
Validation loss: 2.1294674277305603

Epoch: 6| Step: 10
Training loss: 2.4382736682891846
Validation loss: 2.1181963682174683

Epoch: 6| Step: 11
Training loss: 1.4903616905212402
Validation loss: 2.1145119667053223

Epoch: 6| Step: 12
Training loss: 2.3117358684539795
Validation loss: 2.1432745258013406

Epoch: 6| Step: 13
Training loss: 1.47176194190979
Validation loss: 2.1127266883850098

Epoch: 222| Step: 0
Training loss: 1.4348340034484863
Validation loss: 2.1169382532437644

Epoch: 6| Step: 1
Training loss: 1.219670295715332
Validation loss: 2.1281962593396506

Epoch: 6| Step: 2
Training loss: 1.6829358339309692
Validation loss: 2.1281609535217285

Epoch: 6| Step: 3
Training loss: 2.3953616619110107
Validation loss: 2.1091851592063904

Epoch: 6| Step: 4
Training loss: 2.6179943084716797
Validation loss: 2.118874748547872

Epoch: 6| Step: 5
Training loss: 1.7540605068206787
Validation loss: 2.106342931588491

Epoch: 6| Step: 6
Training loss: 1.7352311611175537
Validation loss: 2.1107032696406045

Epoch: 6| Step: 7
Training loss: 1.720597743988037
Validation loss: 2.116616725921631

Epoch: 6| Step: 8
Training loss: 2.120251417160034
Validation loss: 2.135637084643046

Epoch: 6| Step: 9
Training loss: 1.8788669109344482
Validation loss: 2.1186307271321616

Epoch: 6| Step: 10
Training loss: 1.3419926166534424
Validation loss: 2.1267968018849692

Epoch: 6| Step: 11
Training loss: 2.524142265319824
Validation loss: 2.1253000696500144

Epoch: 6| Step: 12
Training loss: 1.4504199028015137
Validation loss: 2.127700368563334

Epoch: 6| Step: 13
Training loss: 1.757530927658081
Validation loss: 2.13129061460495

Epoch: 223| Step: 0
Training loss: 2.0557610988616943
Validation loss: 2.127928912639618

Epoch: 6| Step: 1
Training loss: 1.4559330940246582
Validation loss: 2.1536963979403176

Epoch: 6| Step: 2
Training loss: 1.7953331470489502
Validation loss: 2.1283331314722695

Epoch: 6| Step: 3
Training loss: 2.393728017807007
Validation loss: 2.125070114930471

Epoch: 6| Step: 4
Training loss: 1.9978835582733154
Validation loss: 2.12954052289327

Epoch: 6| Step: 5
Training loss: 1.4225209951400757
Validation loss: 2.136012335618337

Epoch: 6| Step: 6
Training loss: 1.4496171474456787
Validation loss: 2.1321154038111367

Epoch: 6| Step: 7
Training loss: 2.5007355213165283
Validation loss: 2.126608411471049

Epoch: 6| Step: 8
Training loss: 2.1905858516693115
Validation loss: 2.14411723613739

Epoch: 6| Step: 9
Training loss: 1.5519800186157227
Validation loss: 2.142967104911804

Epoch: 6| Step: 10
Training loss: 1.9404754638671875
Validation loss: 2.1225773294766745

Epoch: 6| Step: 11
Training loss: 1.3895760774612427
Validation loss: 2.133863687515259

Epoch: 6| Step: 12
Training loss: 1.7432148456573486
Validation loss: 2.1500107248624167

Epoch: 6| Step: 13
Training loss: 1.493733525276184
Validation loss: 2.1454973816871643

Epoch: 224| Step: 0
Training loss: 1.7795741558074951
Validation loss: 2.137123703956604

Epoch: 6| Step: 1
Training loss: 1.960904598236084
Validation loss: 2.126550575097402

Epoch: 6| Step: 2
Training loss: 2.3227357864379883
Validation loss: 2.139770269393921

Epoch: 6| Step: 3
Training loss: 1.572715163230896
Validation loss: 2.1383291284243264

Epoch: 6| Step: 4
Training loss: 1.5606775283813477
Validation loss: 2.1528644959131875

Epoch: 6| Step: 5
Training loss: 1.819462537765503
Validation loss: 2.1210354765256247

Epoch: 6| Step: 6
Training loss: 2.1481716632843018
Validation loss: 2.1216864585876465

Epoch: 6| Step: 7
Training loss: 2.0187244415283203
Validation loss: 2.1230506896972656

Epoch: 6| Step: 8
Training loss: 1.8253724575042725
Validation loss: 2.1199134985605874

Epoch: 6| Step: 9
Training loss: 2.3163022994995117
Validation loss: 2.1398186882336936

Epoch: 6| Step: 10
Training loss: 1.136229157447815
Validation loss: 2.122761150201162

Epoch: 6| Step: 11
Training loss: 2.1928131580352783
Validation loss: 2.1208663980166116

Epoch: 6| Step: 12
Training loss: 1.5208803415298462
Validation loss: 2.1166463692982993

Epoch: 6| Step: 13
Training loss: 1.4659538269042969
Validation loss: 2.1201751430829368

Epoch: 225| Step: 0
Training loss: 1.5659948587417603
Validation loss: 2.1332883834838867

Epoch: 6| Step: 1
Training loss: 1.8913770914077759
Validation loss: 2.1286622484525046

Epoch: 6| Step: 2
Training loss: 2.0848920345306396
Validation loss: 2.136259933312734

Epoch: 6| Step: 3
Training loss: 0.9859219789505005
Validation loss: 2.1089998682339988

Epoch: 6| Step: 4
Training loss: 1.9706065654754639
Validation loss: 2.1294002334276834

Epoch: 6| Step: 5
Training loss: 1.927302598953247
Validation loss: 2.123677213986715

Epoch: 6| Step: 6
Training loss: 1.559005856513977
Validation loss: 2.125613510608673

Epoch: 6| Step: 7
Training loss: 2.029360771179199
Validation loss: 2.122490187486013

Epoch: 6| Step: 8
Training loss: 2.0696914196014404
Validation loss: 2.1305543382962546

Epoch: 6| Step: 9
Training loss: 2.1594085693359375
Validation loss: 2.131539205710093

Epoch: 6| Step: 10
Training loss: 1.5895988941192627
Validation loss: 2.1336218317349753

Epoch: 6| Step: 11
Training loss: 2.191434383392334
Validation loss: 2.1454418897628784

Epoch: 6| Step: 12
Training loss: 1.2703771591186523
Validation loss: 2.1521809299786887

Epoch: 6| Step: 13
Training loss: 1.6951966285705566
Validation loss: 2.136062522729238

Epoch: 226| Step: 0
Training loss: 1.7013435363769531
Validation loss: 2.152758161226908

Epoch: 6| Step: 1
Training loss: 2.2833051681518555
Validation loss: 2.1561342676480613

Epoch: 6| Step: 2
Training loss: 1.5256495475769043
Validation loss: 2.150918702284495

Epoch: 6| Step: 3
Training loss: 1.8399312496185303
Validation loss: 2.127476930618286

Epoch: 6| Step: 4
Training loss: 1.1695483922958374
Validation loss: 2.1344523827234902

Epoch: 6| Step: 5
Training loss: 1.8405189514160156
Validation loss: 2.132018427054087

Epoch: 6| Step: 6
Training loss: 3.02360200881958
Validation loss: 2.1301320791244507

Epoch: 6| Step: 7
Training loss: 1.3836898803710938
Validation loss: 2.1207887530326843

Epoch: 6| Step: 8
Training loss: 1.7166893482208252
Validation loss: 2.1181581815083823

Epoch: 6| Step: 9
Training loss: 1.8381445407867432
Validation loss: 2.1008352835973105

Epoch: 6| Step: 10
Training loss: 1.9267500638961792
Validation loss: 2.1447200973828635

Epoch: 6| Step: 11
Training loss: 1.819443941116333
Validation loss: 2.104348639647166

Epoch: 6| Step: 12
Training loss: 1.7084020376205444
Validation loss: 2.1379382610321045

Epoch: 6| Step: 13
Training loss: 1.6716887950897217
Validation loss: 2.1506542960802713

Epoch: 227| Step: 0
Training loss: 1.6291372776031494
Validation loss: 2.1493419210116067

Epoch: 6| Step: 1
Training loss: 2.1119675636291504
Validation loss: 2.1589478055636087

Epoch: 6| Step: 2
Training loss: 1.7501099109649658
Validation loss: 2.144462764263153

Epoch: 6| Step: 3
Training loss: 2.4948482513427734
Validation loss: 2.148040155569712

Epoch: 6| Step: 4
Training loss: 1.9694595336914062
Validation loss: 2.1696490049362183

Epoch: 6| Step: 5
Training loss: 1.3468378782272339
Validation loss: 2.16995362440745

Epoch: 6| Step: 6
Training loss: 1.4567112922668457
Validation loss: 2.1569859981536865

Epoch: 6| Step: 7
Training loss: 2.148250102996826
Validation loss: 2.156826138496399

Epoch: 6| Step: 8
Training loss: 1.938458800315857
Validation loss: 2.1430544257164

Epoch: 6| Step: 9
Training loss: 2.027373790740967
Validation loss: 2.1209271947542825

Epoch: 6| Step: 10
Training loss: 1.5770390033721924
Validation loss: 2.1580334107081094

Epoch: 6| Step: 11
Training loss: 2.3245725631713867
Validation loss: 2.1434035698572793

Epoch: 6| Step: 12
Training loss: 1.7904659509658813
Validation loss: 2.139985978603363

Epoch: 6| Step: 13
Training loss: 1.6972911357879639
Validation loss: 2.135914385318756

Epoch: 228| Step: 0
Training loss: 2.2613468170166016
Validation loss: 2.148412028948466

Epoch: 6| Step: 1
Training loss: 2.0003743171691895
Validation loss: 2.130590339501699

Epoch: 6| Step: 2
Training loss: 1.4292470216751099
Validation loss: 2.158982753753662

Epoch: 6| Step: 3
Training loss: 1.6636886596679688
Validation loss: 2.134892443815867

Epoch: 6| Step: 4
Training loss: 2.4719810485839844
Validation loss: 2.1541201869646707

Epoch: 6| Step: 5
Training loss: 1.5541311502456665
Validation loss: 2.1534918347994485

Epoch: 6| Step: 6
Training loss: 1.6218070983886719
Validation loss: 2.1436328490575156

Epoch: 6| Step: 7
Training loss: 1.9859739542007446
Validation loss: 2.1433582305908203

Epoch: 6| Step: 8
Training loss: 1.4746286869049072
Validation loss: 2.122021794319153

Epoch: 6| Step: 9
Training loss: 2.198343515396118
Validation loss: 2.139978210131327

Epoch: 6| Step: 10
Training loss: 1.972238302230835
Validation loss: 2.1374346017837524

Epoch: 6| Step: 11
Training loss: 1.7275536060333252
Validation loss: 2.123628815015157

Epoch: 6| Step: 12
Training loss: 1.2434697151184082
Validation loss: 2.1156951189041138

Epoch: 6| Step: 13
Training loss: 1.8642804622650146
Validation loss: 2.105292717615763

Epoch: 229| Step: 0
Training loss: 1.4681333303451538
Validation loss: 2.0988185008366904

Epoch: 6| Step: 1
Training loss: 2.4269301891326904
Validation loss: 2.1151186426480613

Epoch: 6| Step: 2
Training loss: 1.8024903535842896
Validation loss: 2.1310383876164756

Epoch: 6| Step: 3
Training loss: 1.249565601348877
Validation loss: 2.1029568711916604

Epoch: 6| Step: 4
Training loss: 2.5286240577697754
Validation loss: 2.121134579181671

Epoch: 6| Step: 5
Training loss: 2.0704002380371094
Validation loss: 2.1208998362223306

Epoch: 6| Step: 6
Training loss: 1.5072453022003174
Validation loss: 2.1308491627375283

Epoch: 6| Step: 7
Training loss: 1.65317964553833
Validation loss: 2.1223116914431253

Epoch: 6| Step: 8
Training loss: 2.0322136878967285
Validation loss: 2.135722041130066

Epoch: 6| Step: 9
Training loss: 1.7933248281478882
Validation loss: 2.1369635264078775

Epoch: 6| Step: 10
Training loss: 1.4646306037902832
Validation loss: 2.1333452065785727

Epoch: 6| Step: 11
Training loss: 1.3914344310760498
Validation loss: 2.130580027898153

Epoch: 6| Step: 12
Training loss: 2.344707489013672
Validation loss: 2.114948292573293

Epoch: 6| Step: 13
Training loss: 1.9863560199737549
Validation loss: 2.1161661744117737

Epoch: 230| Step: 0
Training loss: 1.5948686599731445
Validation loss: 2.1095921993255615

Epoch: 6| Step: 1
Training loss: 1.418637752532959
Validation loss: 2.130519966284434

Epoch: 6| Step: 2
Training loss: 1.7067962884902954
Validation loss: 2.1379700700441995

Epoch: 6| Step: 3
Training loss: 1.7345601320266724
Validation loss: 2.1060396432876587

Epoch: 6| Step: 4
Training loss: 2.274529457092285
Validation loss: 2.123839239279429

Epoch: 6| Step: 5
Training loss: 1.4496855735778809
Validation loss: 2.121972680091858

Epoch: 6| Step: 6
Training loss: 2.2664577960968018
Validation loss: 2.1384783585866294

Epoch: 6| Step: 7
Training loss: 1.885509729385376
Validation loss: 2.118925412495931

Epoch: 6| Step: 8
Training loss: 1.3075580596923828
Validation loss: 2.099942902723948

Epoch: 6| Step: 9
Training loss: 1.6831129789352417
Validation loss: 2.110510210196177

Epoch: 6| Step: 10
Training loss: 1.8636705875396729
Validation loss: 2.118181884288788

Epoch: 6| Step: 11
Training loss: 1.9518694877624512
Validation loss: 2.1404254833857217

Epoch: 6| Step: 12
Training loss: 1.7568705081939697
Validation loss: 2.1344688733418784

Epoch: 6| Step: 13
Training loss: 2.194209098815918
Validation loss: 2.1438733339309692

Epoch: 231| Step: 0
Training loss: 2.546938180923462
Validation loss: 2.141184449195862

Epoch: 6| Step: 1
Training loss: 1.5543229579925537
Validation loss: 2.1517626841863

Epoch: 6| Step: 2
Training loss: 1.862809658050537
Validation loss: 2.1416582663853965

Epoch: 6| Step: 3
Training loss: 1.6472212076187134
Validation loss: 2.1265076796213784

Epoch: 6| Step: 4
Training loss: 1.912219762802124
Validation loss: 2.1385911305745444

Epoch: 6| Step: 5
Training loss: 2.172126531600952
Validation loss: 2.130611697832743

Epoch: 6| Step: 6
Training loss: 1.2927393913269043
Validation loss: 2.145813286304474

Epoch: 6| Step: 7
Training loss: 2.054858922958374
Validation loss: 2.0948848327000937

Epoch: 6| Step: 8
Training loss: 2.088961124420166
Validation loss: 2.1329132517178855

Epoch: 6| Step: 9
Training loss: 1.2365503311157227
Validation loss: 2.106511930624644

Epoch: 6| Step: 10
Training loss: 2.15787935256958
Validation loss: 2.120523194471995

Epoch: 6| Step: 11
Training loss: 1.8972253799438477
Validation loss: 2.126210033893585

Epoch: 6| Step: 12
Training loss: 1.953467845916748
Validation loss: 2.129710336526235

Epoch: 6| Step: 13
Training loss: 1.228136420249939
Validation loss: 2.1250405510266623

Epoch: 232| Step: 0
Training loss: 1.9023370742797852
Validation loss: 2.131642202536265

Epoch: 6| Step: 1
Training loss: 1.6672773361206055
Validation loss: 2.1166306138038635

Epoch: 6| Step: 2
Training loss: 1.8110947608947754
Validation loss: 2.149271309375763

Epoch: 6| Step: 3
Training loss: 1.459040880203247
Validation loss: 2.13616011540095

Epoch: 6| Step: 4
Training loss: 2.268944263458252
Validation loss: 2.1379343469937644

Epoch: 6| Step: 5
Training loss: 1.8849687576293945
Validation loss: 2.1314162015914917

Epoch: 6| Step: 6
Training loss: 1.7651524543762207
Validation loss: 2.1446954011917114

Epoch: 6| Step: 7
Training loss: 2.467271089553833
Validation loss: 2.143309493859609

Epoch: 6| Step: 8
Training loss: 1.4133802652359009
Validation loss: 2.1367170810699463

Epoch: 6| Step: 9
Training loss: 1.493298053741455
Validation loss: 2.142738660176595

Epoch: 6| Step: 10
Training loss: 2.1792826652526855
Validation loss: 2.130219320456187

Epoch: 6| Step: 11
Training loss: 1.8077471256256104
Validation loss: 2.13273423910141

Epoch: 6| Step: 12
Training loss: 1.5312974452972412
Validation loss: 2.12313973903656

Epoch: 6| Step: 13
Training loss: 1.4536855220794678
Validation loss: 2.1097330451011658

Epoch: 233| Step: 0
Training loss: 1.9523900747299194
Validation loss: 2.124311625957489

Epoch: 6| Step: 1
Training loss: 1.7156741619110107
Validation loss: 2.1284475326538086

Epoch: 6| Step: 2
Training loss: 1.9326238632202148
Validation loss: 2.106341024239858

Epoch: 6| Step: 3
Training loss: 2.116520643234253
Validation loss: 2.1065994699796042

Epoch: 6| Step: 4
Training loss: 1.5325863361358643
Validation loss: 2.126923084259033

Epoch: 6| Step: 5
Training loss: 2.1203322410583496
Validation loss: 2.1321956515312195

Epoch: 6| Step: 6
Training loss: 1.3673981428146362
Validation loss: 2.1585760513941445

Epoch: 6| Step: 7
Training loss: 2.1170434951782227
Validation loss: 2.155546486377716

Epoch: 6| Step: 8
Training loss: 1.3353909254074097
Validation loss: 2.154921074708303

Epoch: 6| Step: 9
Training loss: 1.823923110961914
Validation loss: 2.148380478223165

Epoch: 6| Step: 10
Training loss: 1.543066382408142
Validation loss: 2.1533955335617065

Epoch: 6| Step: 11
Training loss: 2.0090675354003906
Validation loss: 2.136938512325287

Epoch: 6| Step: 12
Training loss: 1.6758970022201538
Validation loss: 2.144121289253235

Epoch: 6| Step: 13
Training loss: 2.606959342956543
Validation loss: 2.135571777820587

Epoch: 234| Step: 0
Training loss: 1.2014085054397583
Validation loss: 2.1269097328186035

Epoch: 6| Step: 1
Training loss: 1.8695638179779053
Validation loss: 2.1374798814455667

Epoch: 6| Step: 2
Training loss: 1.708091139793396
Validation loss: 2.128880560398102

Epoch: 6| Step: 3
Training loss: 1.923327922821045
Validation loss: 2.120675504207611

Epoch: 6| Step: 4
Training loss: 1.4419962167739868
Validation loss: 2.1366804440816245

Epoch: 6| Step: 5
Training loss: 1.674582600593567
Validation loss: 2.1236342191696167

Epoch: 6| Step: 6
Training loss: 1.6731566190719604
Validation loss: 2.104487578074137

Epoch: 6| Step: 7
Training loss: 2.040635585784912
Validation loss: 2.1238603989283242

Epoch: 6| Step: 8
Training loss: 1.740476369857788
Validation loss: 2.1140147844950357

Epoch: 6| Step: 9
Training loss: 1.7553842067718506
Validation loss: 2.1283651987711587

Epoch: 6| Step: 10
Training loss: 2.379214286804199
Validation loss: 2.116258760293325

Epoch: 6| Step: 11
Training loss: 2.1861629486083984
Validation loss: 2.1246372858683267

Epoch: 6| Step: 12
Training loss: 1.5497095584869385
Validation loss: 2.137438933054606

Epoch: 6| Step: 13
Training loss: 1.8985438346862793
Validation loss: 2.1379910111427307

Epoch: 235| Step: 0
Training loss: 1.8960283994674683
Validation loss: 2.115747034549713

Epoch: 6| Step: 1
Training loss: 1.9256422519683838
Validation loss: 2.1518102486928306

Epoch: 6| Step: 2
Training loss: 0.8635678291320801
Validation loss: 2.1362191438674927

Epoch: 6| Step: 3
Training loss: 2.404414176940918
Validation loss: 2.1285444100697837

Epoch: 6| Step: 4
Training loss: 2.3341336250305176
Validation loss: 2.11984654267629

Epoch: 6| Step: 5
Training loss: 1.7431038618087769
Validation loss: 2.12772528330485

Epoch: 6| Step: 6
Training loss: 1.66920804977417
Validation loss: 2.133896549542745

Epoch: 6| Step: 7
Training loss: 1.960466980934143
Validation loss: 2.1085668206214905

Epoch: 6| Step: 8
Training loss: 1.4022738933563232
Validation loss: 2.132643540700277

Epoch: 6| Step: 9
Training loss: 1.7616420984268188
Validation loss: 2.1451463103294373

Epoch: 6| Step: 10
Training loss: 1.7317408323287964
Validation loss: 2.1417094071706138

Epoch: 6| Step: 11
Training loss: 1.4634099006652832
Validation loss: 2.1400949358940125

Epoch: 6| Step: 12
Training loss: 2.0109710693359375
Validation loss: 2.1420129338900247

Epoch: 6| Step: 13
Training loss: 1.8816118240356445
Validation loss: 2.1571833888689675

Epoch: 236| Step: 0
Training loss: 1.7180781364440918
Validation loss: 2.140537202358246

Epoch: 6| Step: 1
Training loss: 1.834545612335205
Validation loss: 2.153871476650238

Epoch: 6| Step: 2
Training loss: 1.539426326751709
Validation loss: 2.134335994720459

Epoch: 6| Step: 3
Training loss: 1.624516248703003
Validation loss: 2.1346104542414346

Epoch: 6| Step: 4
Training loss: 2.2063450813293457
Validation loss: 2.155369242032369

Epoch: 6| Step: 5
Training loss: 1.0437567234039307
Validation loss: 2.1475075483322144

Epoch: 6| Step: 6
Training loss: 1.8884050846099854
Validation loss: 2.1513389945030212

Epoch: 6| Step: 7
Training loss: 1.3466553688049316
Validation loss: 2.1446925600369773

Epoch: 6| Step: 8
Training loss: 2.7127246856689453
Validation loss: 2.143892546494802

Epoch: 6| Step: 9
Training loss: 1.5581789016723633
Validation loss: 2.14624031384786

Epoch: 6| Step: 10
Training loss: 2.35490083694458
Validation loss: 2.1388165950775146

Epoch: 6| Step: 11
Training loss: 1.7011748552322388
Validation loss: 2.130935271581014

Epoch: 6| Step: 12
Training loss: 1.6473990678787231
Validation loss: 2.127502143383026

Epoch: 6| Step: 13
Training loss: 1.608192801475525
Validation loss: 2.109532276789347

Epoch: 237| Step: 0
Training loss: 1.9733754396438599
Validation loss: 2.1241343021392822

Epoch: 6| Step: 1
Training loss: 1.5260753631591797
Validation loss: 2.1220351258913674

Epoch: 6| Step: 2
Training loss: 1.4926629066467285
Validation loss: 2.1493904987970986

Epoch: 6| Step: 3
Training loss: 2.0578675270080566
Validation loss: 2.1435720523198447

Epoch: 6| Step: 4
Training loss: 1.7712290287017822
Validation loss: 2.1405873894691467

Epoch: 6| Step: 5
Training loss: 1.810265302658081
Validation loss: 2.155903617540995

Epoch: 6| Step: 6
Training loss: 1.6081175804138184
Validation loss: 2.1607492963473

Epoch: 6| Step: 7
Training loss: 2.1010360717773438
Validation loss: 2.166301886240641

Epoch: 6| Step: 8
Training loss: 2.0203652381896973
Validation loss: 2.1156811118125916

Epoch: 6| Step: 9
Training loss: 1.43876314163208
Validation loss: 2.1548526883125305

Epoch: 6| Step: 10
Training loss: 1.9354248046875
Validation loss: 2.134823282559713

Epoch: 6| Step: 11
Training loss: 1.4303429126739502
Validation loss: 2.1284916400909424

Epoch: 6| Step: 12
Training loss: 1.6110026836395264
Validation loss: 2.1266032457351685

Epoch: 6| Step: 13
Training loss: 2.1400890350341797
Validation loss: 2.1450597047805786

Epoch: 238| Step: 0
Training loss: 2.762005090713501
Validation loss: 2.13833757241567

Epoch: 6| Step: 1
Training loss: 1.6840604543685913
Validation loss: 2.1266775528589883

Epoch: 6| Step: 2
Training loss: 1.437439203262329
Validation loss: 2.1089648008346558

Epoch: 6| Step: 3
Training loss: 1.7901016473770142
Validation loss: 2.1164164741834006

Epoch: 6| Step: 4
Training loss: 1.9099416732788086
Validation loss: 2.1335551341374717

Epoch: 6| Step: 5
Training loss: 1.7789785861968994
Validation loss: 2.121167222658793

Epoch: 6| Step: 6
Training loss: 1.8919605016708374
Validation loss: 2.134558101495107

Epoch: 6| Step: 7
Training loss: 1.3763034343719482
Validation loss: 2.1187398433685303

Epoch: 6| Step: 8
Training loss: 1.6456999778747559
Validation loss: 2.114730795224508

Epoch: 6| Step: 9
Training loss: 2.1041736602783203
Validation loss: 2.1107826232910156

Epoch: 6| Step: 10
Training loss: 1.4278908967971802
Validation loss: 2.1055197517077127

Epoch: 6| Step: 11
Training loss: 2.2313613891601562
Validation loss: 2.1101416746775308

Epoch: 6| Step: 12
Training loss: 1.686084270477295
Validation loss: 2.1332446535428367

Epoch: 6| Step: 13
Training loss: 1.9439027309417725
Validation loss: 2.1012808879216514

Epoch: 239| Step: 0
Training loss: 2.6993398666381836
Validation loss: 2.1150585214296975

Epoch: 6| Step: 1
Training loss: 1.7573926448822021
Validation loss: 2.130371332168579

Epoch: 6| Step: 2
Training loss: 1.72532320022583
Validation loss: 2.1325417359670005

Epoch: 6| Step: 3
Training loss: 1.9219484329223633
Validation loss: 2.134919285774231

Epoch: 6| Step: 4
Training loss: 1.3266286849975586
Validation loss: 2.1376400192578635

Epoch: 6| Step: 5
Training loss: 1.5648388862609863
Validation loss: 2.1405279437700906

Epoch: 6| Step: 6
Training loss: 2.803171396255493
Validation loss: 2.1378318270047507

Epoch: 6| Step: 7
Training loss: 2.093658447265625
Validation loss: 2.125805377960205

Epoch: 6| Step: 8
Training loss: 1.4536571502685547
Validation loss: 2.1258066495259604

Epoch: 6| Step: 9
Training loss: 2.2044613361358643
Validation loss: 2.1466801961263022

Epoch: 6| Step: 10
Training loss: 1.3733139038085938
Validation loss: 2.145440697669983

Epoch: 6| Step: 11
Training loss: 1.785266637802124
Validation loss: 2.1483583450317383

Epoch: 6| Step: 12
Training loss: 1.6514593362808228
Validation loss: 2.1667102575302124

Epoch: 6| Step: 13
Training loss: 1.032428503036499
Validation loss: 2.1389313538869223

Epoch: 240| Step: 0
Training loss: 1.649827480316162
Validation loss: 2.1485989093780518

Epoch: 6| Step: 1
Training loss: 1.0912998914718628
Validation loss: 2.1400681138038635

Epoch: 6| Step: 2
Training loss: 1.6426401138305664
Validation loss: 2.140490094820658

Epoch: 6| Step: 3
Training loss: 1.9504492282867432
Validation loss: 2.1331220269203186

Epoch: 6| Step: 4
Training loss: 2.368472099304199
Validation loss: 2.1315587759017944

Epoch: 6| Step: 5
Training loss: 2.235273838043213
Validation loss: 2.135981798171997

Epoch: 6| Step: 6
Training loss: 1.6269186735153198
Validation loss: 2.14317778746287

Epoch: 6| Step: 7
Training loss: 1.0020875930786133
Validation loss: 2.1503768960634866

Epoch: 6| Step: 8
Training loss: 1.6054577827453613
Validation loss: 2.141765594482422

Epoch: 6| Step: 9
Training loss: 1.7172925472259521
Validation loss: 2.1471579869588218

Epoch: 6| Step: 10
Training loss: 2.4887051582336426
Validation loss: 2.1463749011357627

Epoch: 6| Step: 11
Training loss: 2.542116641998291
Validation loss: 2.1429736216863

Epoch: 6| Step: 12
Training loss: 1.3087716102600098
Validation loss: 2.1584455569585166

Epoch: 6| Step: 13
Training loss: 1.4187061786651611
Validation loss: 2.1456926663716636

Epoch: 241| Step: 0
Training loss: 1.7231216430664062
Validation loss: 2.160328964392344

Epoch: 6| Step: 1
Training loss: 1.301455020904541
Validation loss: 2.1309794584910073

Epoch: 6| Step: 2
Training loss: 1.7622921466827393
Validation loss: 2.1340009768803916

Epoch: 6| Step: 3
Training loss: 1.5568599700927734
Validation loss: 2.1430819829305015

Epoch: 6| Step: 4
Training loss: 1.893983244895935
Validation loss: 2.1424168745676675

Epoch: 6| Step: 5
Training loss: 2.43031644821167
Validation loss: 2.1301673650741577

Epoch: 6| Step: 6
Training loss: 2.289222240447998
Validation loss: 2.1334335009256997

Epoch: 6| Step: 7
Training loss: 1.9233441352844238
Validation loss: 2.120571712652842

Epoch: 6| Step: 8
Training loss: 1.2765344381332397
Validation loss: 2.1490442951520285

Epoch: 6| Step: 9
Training loss: 1.6662037372589111
Validation loss: 2.1244175831476846

Epoch: 6| Step: 10
Training loss: 1.9456682205200195
Validation loss: 2.14841490983963

Epoch: 6| Step: 11
Training loss: 1.4274243116378784
Validation loss: 2.1403745214144387

Epoch: 6| Step: 12
Training loss: 1.8018851280212402
Validation loss: 2.153750797112783

Epoch: 6| Step: 13
Training loss: 1.7268133163452148
Validation loss: 2.1428825855255127

Epoch: 242| Step: 0
Training loss: 1.8340444564819336
Validation loss: 2.1375482082366943

Epoch: 6| Step: 1
Training loss: 1.714604377746582
Validation loss: 2.1633495887120566

Epoch: 6| Step: 2
Training loss: 2.161240577697754
Validation loss: 2.1522493163744607

Epoch: 6| Step: 3
Training loss: 1.459215760231018
Validation loss: 2.1497599482536316

Epoch: 6| Step: 4
Training loss: 2.330716133117676
Validation loss: 2.1575039625167847

Epoch: 6| Step: 5
Training loss: 1.7384411096572876
Validation loss: 2.165513892968496

Epoch: 6| Step: 6
Training loss: 1.1563071012496948
Validation loss: 2.1594237685203552

Epoch: 6| Step: 7
Training loss: 1.7048636674880981
Validation loss: 2.134694814682007

Epoch: 6| Step: 8
Training loss: 1.550331473350525
Validation loss: 2.159713943799337

Epoch: 6| Step: 9
Training loss: 1.46427321434021
Validation loss: 2.1564655105272927

Epoch: 6| Step: 10
Training loss: 1.6995810270309448
Validation loss: 2.162174959977468

Epoch: 6| Step: 11
Training loss: 2.093658447265625
Validation loss: 2.1608450412750244

Epoch: 6| Step: 12
Training loss: 2.297153949737549
Validation loss: 2.15552681684494

Epoch: 6| Step: 13
Training loss: 1.127372145652771
Validation loss: 2.151683509349823

Epoch: 243| Step: 0
Training loss: 2.7275609970092773
Validation loss: 2.13881254196167

Epoch: 6| Step: 1
Training loss: 1.6405609846115112
Validation loss: 2.1198682387669883

Epoch: 6| Step: 2
Training loss: 2.1376867294311523
Validation loss: 2.126404047012329

Epoch: 6| Step: 3
Training loss: 1.455938458442688
Validation loss: 2.1217214465141296

Epoch: 6| Step: 4
Training loss: 1.8795719146728516
Validation loss: 2.1467684706052146

Epoch: 6| Step: 5
Training loss: 1.3593083620071411
Validation loss: 2.1474417646725974

Epoch: 6| Step: 6
Training loss: 1.554642677307129
Validation loss: 2.1446701685587564

Epoch: 6| Step: 7
Training loss: 2.1398227214813232
Validation loss: 2.1604456504185996

Epoch: 6| Step: 8
Training loss: 1.5697448253631592
Validation loss: 2.152097205320994

Epoch: 6| Step: 9
Training loss: 1.5080764293670654
Validation loss: 2.1316315134366355

Epoch: 6| Step: 10
Training loss: 1.436389684677124
Validation loss: 2.1279327670733132

Epoch: 6| Step: 11
Training loss: 2.0589613914489746
Validation loss: 2.135053873062134

Epoch: 6| Step: 12
Training loss: 1.2712953090667725
Validation loss: 2.1180439591407776

Epoch: 6| Step: 13
Training loss: 2.2742199897766113
Validation loss: 2.08391942580541

Epoch: 244| Step: 0
Training loss: 2.252065420150757
Validation loss: 2.090286910533905

Epoch: 6| Step: 1
Training loss: 1.5894514322280884
Validation loss: 2.0842051903406777

Epoch: 6| Step: 2
Training loss: 1.6730225086212158
Validation loss: 2.0835511883099875

Epoch: 6| Step: 3
Training loss: 1.9069899320602417
Validation loss: 2.1079822182655334

Epoch: 6| Step: 4
Training loss: 1.6116105318069458
Validation loss: 2.1181271274884543

Epoch: 6| Step: 5
Training loss: 1.5091867446899414
Validation loss: 2.137412210305532

Epoch: 6| Step: 6
Training loss: 1.8931399583816528
Validation loss: 2.117316206296285

Epoch: 6| Step: 7
Training loss: 2.2436046600341797
Validation loss: 2.1196064154307046

Epoch: 6| Step: 8
Training loss: 1.8858107328414917
Validation loss: 2.1122961242993674

Epoch: 6| Step: 9
Training loss: 2.279674530029297
Validation loss: 2.120936095714569

Epoch: 6| Step: 10
Training loss: 1.4991493225097656
Validation loss: 2.1373320817947388

Epoch: 6| Step: 11
Training loss: 1.6251918077468872
Validation loss: 2.145721654097239

Epoch: 6| Step: 12
Training loss: 1.5234873294830322
Validation loss: 2.1329304575920105

Epoch: 6| Step: 13
Training loss: 1.3889904022216797
Validation loss: 2.130689481894175

Epoch: 245| Step: 0
Training loss: 1.6776032447814941
Validation loss: 2.119993726412455

Epoch: 6| Step: 1
Training loss: 2.0474460124969482
Validation loss: 2.126672863960266

Epoch: 6| Step: 2
Training loss: 1.5534226894378662
Validation loss: 2.129486858844757

Epoch: 6| Step: 3
Training loss: 2.1638245582580566
Validation loss: 2.1408379673957825

Epoch: 6| Step: 4
Training loss: 1.9833331108093262
Validation loss: 2.133938789367676

Epoch: 6| Step: 5
Training loss: 1.4383445978164673
Validation loss: 2.1321276227633157

Epoch: 6| Step: 6
Training loss: 1.7325708866119385
Validation loss: 2.119076669216156

Epoch: 6| Step: 7
Training loss: 1.471388339996338
Validation loss: 2.1250975330670676

Epoch: 6| Step: 8
Training loss: 1.6078295707702637
Validation loss: 2.098545034726461

Epoch: 6| Step: 9
Training loss: 1.8391821384429932
Validation loss: 2.1460174719492593

Epoch: 6| Step: 10
Training loss: 1.3092820644378662
Validation loss: 2.124886174996694

Epoch: 6| Step: 11
Training loss: 1.7894020080566406
Validation loss: 2.12747460603714

Epoch: 6| Step: 12
Training loss: 2.4014077186584473
Validation loss: 2.1329848368962607

Epoch: 6| Step: 13
Training loss: 1.7178623676300049
Validation loss: 2.121203521887461

Epoch: 246| Step: 0
Training loss: 1.3862195014953613
Validation loss: 2.1366385022799173

Epoch: 6| Step: 1
Training loss: 1.2084581851959229
Validation loss: 2.134187340736389

Epoch: 6| Step: 2
Training loss: 1.7607333660125732
Validation loss: 2.1476180950800576

Epoch: 6| Step: 3
Training loss: 1.0938124656677246
Validation loss: 2.1495620807011924

Epoch: 6| Step: 4
Training loss: 2.0019569396972656
Validation loss: 2.1444514989852905

Epoch: 6| Step: 5
Training loss: 2.2805891036987305
Validation loss: 2.13997753461202

Epoch: 6| Step: 6
Training loss: 1.4277594089508057
Validation loss: 2.1444358825683594

Epoch: 6| Step: 7
Training loss: 2.1572468280792236
Validation loss: 2.139535109202067

Epoch: 6| Step: 8
Training loss: 1.8753550052642822
Validation loss: 2.117738505204519

Epoch: 6| Step: 9
Training loss: 1.6045398712158203
Validation loss: 2.1316428184509277

Epoch: 6| Step: 10
Training loss: 1.607212781906128
Validation loss: 2.125013073285421

Epoch: 6| Step: 11
Training loss: 2.157900810241699
Validation loss: 2.144722104072571

Epoch: 6| Step: 12
Training loss: 2.02592134475708
Validation loss: 2.135745942592621

Epoch: 6| Step: 13
Training loss: 1.8736202716827393
Validation loss: 2.1210153102874756

Epoch: 247| Step: 0
Training loss: 2.335552215576172
Validation loss: 2.1192314823468528

Epoch: 6| Step: 1
Training loss: 1.4416563510894775
Validation loss: 2.140641172726949

Epoch: 6| Step: 2
Training loss: 2.210056781768799
Validation loss: 2.1323657433191934

Epoch: 6| Step: 3
Training loss: 1.6298818588256836
Validation loss: 2.1134376724561057

Epoch: 6| Step: 4
Training loss: 1.7278399467468262
Validation loss: 2.1204232772191367

Epoch: 6| Step: 5
Training loss: 1.833204984664917
Validation loss: 2.151829779148102

Epoch: 6| Step: 6
Training loss: 1.681066870689392
Validation loss: 2.12583335240682

Epoch: 6| Step: 7
Training loss: 0.656261682510376
Validation loss: 2.126165529092153

Epoch: 6| Step: 8
Training loss: 2.613297462463379
Validation loss: 2.146705667177836

Epoch: 6| Step: 9
Training loss: 1.5174380540847778
Validation loss: 2.123149295647939

Epoch: 6| Step: 10
Training loss: 1.9695160388946533
Validation loss: 2.134637633959452

Epoch: 6| Step: 11
Training loss: 1.7043335437774658
Validation loss: 2.116822600364685

Epoch: 6| Step: 12
Training loss: 1.6673344373703003
Validation loss: 2.1241931716601052

Epoch: 6| Step: 13
Training loss: 1.534087896347046
Validation loss: 2.1069880525271096

Epoch: 248| Step: 0
Training loss: 1.9802052974700928
Validation loss: 2.106479982535044

Epoch: 6| Step: 1
Training loss: 1.7211756706237793
Validation loss: 2.1114119489987693

Epoch: 6| Step: 2
Training loss: 2.125011682510376
Validation loss: 2.1287002563476562

Epoch: 6| Step: 3
Training loss: 1.9781036376953125
Validation loss: 2.136842747529348

Epoch: 6| Step: 4
Training loss: 1.1204028129577637
Validation loss: 2.130405902862549

Epoch: 6| Step: 5
Training loss: 2.166557788848877
Validation loss: 2.135125676790873

Epoch: 6| Step: 6
Training loss: 1.5527677536010742
Validation loss: 2.160631537437439

Epoch: 6| Step: 7
Training loss: 1.2666431665420532
Validation loss: 2.136821190516154

Epoch: 6| Step: 8
Training loss: 1.3633135557174683
Validation loss: 2.139298597971598

Epoch: 6| Step: 9
Training loss: 2.2507076263427734
Validation loss: 2.1533926725387573

Epoch: 6| Step: 10
Training loss: 1.4779629707336426
Validation loss: 2.160731256008148

Epoch: 6| Step: 11
Training loss: 1.8598151206970215
Validation loss: 2.1612428029378257

Epoch: 6| Step: 12
Training loss: 1.8996756076812744
Validation loss: 2.138457735379537

Epoch: 6| Step: 13
Training loss: 1.554133653640747
Validation loss: 2.1104097962379456

Epoch: 249| Step: 0
Training loss: 2.089268445968628
Validation loss: 2.1227052410443625

Epoch: 6| Step: 1
Training loss: 1.8321685791015625
Validation loss: 2.096863567829132

Epoch: 6| Step: 2
Training loss: 1.566324234008789
Validation loss: 2.118932604789734

Epoch: 6| Step: 3
Training loss: 1.391785740852356
Validation loss: 2.126401980717977

Epoch: 6| Step: 4
Training loss: 2.1999473571777344
Validation loss: 2.0974669257799783

Epoch: 6| Step: 5
Training loss: 1.6125187873840332
Validation loss: 2.1267117261886597

Epoch: 6| Step: 6
Training loss: 1.9859764575958252
Validation loss: 2.1077110966046653

Epoch: 6| Step: 7
Training loss: 1.8803900480270386
Validation loss: 2.1446962356567383

Epoch: 6| Step: 8
Training loss: 1.428554654121399
Validation loss: 2.1174230774243674

Epoch: 6| Step: 9
Training loss: 1.694924235343933
Validation loss: 2.1232643127441406

Epoch: 6| Step: 10
Training loss: 2.452620267868042
Validation loss: 2.156360944112142

Epoch: 6| Step: 11
Training loss: 1.2144477367401123
Validation loss: 2.150144378344218

Epoch: 6| Step: 12
Training loss: 1.948175311088562
Validation loss: 2.1535634795824685

Epoch: 6| Step: 13
Training loss: 1.4759161472320557
Validation loss: 2.1452314058939614

Epoch: 250| Step: 0
Training loss: 2.0375406742095947
Validation loss: 2.1685965061187744

Epoch: 6| Step: 1
Training loss: 1.9729173183441162
Validation loss: 2.164901852607727

Epoch: 6| Step: 2
Training loss: 1.549361228942871
Validation loss: 2.149919251600901

Epoch: 6| Step: 3
Training loss: 2.4420130252838135
Validation loss: 2.141261577606201

Epoch: 6| Step: 4
Training loss: 1.6101529598236084
Validation loss: 2.145190119743347

Epoch: 6| Step: 5
Training loss: 2.0572993755340576
Validation loss: 2.12443341811498

Epoch: 6| Step: 6
Training loss: 1.9290382862091064
Validation loss: 2.1301902731259665

Epoch: 6| Step: 7
Training loss: 2.413789749145508
Validation loss: 2.117194096247355

Epoch: 6| Step: 8
Training loss: 1.2877159118652344
Validation loss: 2.131833295027415

Epoch: 6| Step: 9
Training loss: 1.3930878639221191
Validation loss: 2.0990912318229675

Epoch: 6| Step: 10
Training loss: 1.8405990600585938
Validation loss: 2.1312124530474343

Epoch: 6| Step: 11
Training loss: 1.8887405395507812
Validation loss: 2.1214537024497986

Epoch: 6| Step: 12
Training loss: 1.2433834075927734
Validation loss: 2.1394590536753335

Epoch: 6| Step: 13
Training loss: 1.6788313388824463
Validation loss: 2.1267289320627847

Epoch: 251| Step: 0
Training loss: 1.9321156740188599
Validation loss: 2.132112960020701

Epoch: 6| Step: 1
Training loss: 1.3948523998260498
Validation loss: 2.1163278023401895

Epoch: 6| Step: 2
Training loss: 2.0858988761901855
Validation loss: 2.1063440839449563

Epoch: 6| Step: 3
Training loss: 1.549211025238037
Validation loss: 2.144427498181661

Epoch: 6| Step: 4
Training loss: 1.5721168518066406
Validation loss: 2.138402541478475

Epoch: 6| Step: 5
Training loss: 2.1485345363616943
Validation loss: 2.1363317569096885

Epoch: 6| Step: 6
Training loss: 1.8607232570648193
Validation loss: 2.1180543303489685

Epoch: 6| Step: 7
Training loss: 1.5793393850326538
Validation loss: 2.1415958801905313

Epoch: 6| Step: 8
Training loss: 1.2831494808197021
Validation loss: 2.1226291259129844

Epoch: 6| Step: 9
Training loss: 1.6070995330810547
Validation loss: 2.1333860556284585

Epoch: 6| Step: 10
Training loss: 2.031320333480835
Validation loss: 2.117758333683014

Epoch: 6| Step: 11
Training loss: 1.1744153499603271
Validation loss: 2.124840875466665

Epoch: 6| Step: 12
Training loss: 2.343064785003662
Validation loss: 2.1319313049316406

Epoch: 6| Step: 13
Training loss: 2.059345245361328
Validation loss: 2.1288633743921914

Epoch: 252| Step: 0
Training loss: 2.3889784812927246
Validation loss: 2.1384251713752747

Epoch: 6| Step: 1
Training loss: 1.560213327407837
Validation loss: 2.1382773915926614

Epoch: 6| Step: 2
Training loss: 1.6399019956588745
Validation loss: 2.146529277165731

Epoch: 6| Step: 3
Training loss: 1.7154889106750488
Validation loss: 2.131531774997711

Epoch: 6| Step: 4
Training loss: 2.2572994232177734
Validation loss: 2.154559016227722

Epoch: 6| Step: 5
Training loss: 2.1356945037841797
Validation loss: 2.1487237215042114

Epoch: 6| Step: 6
Training loss: 1.8541940450668335
Validation loss: 2.1514918009440103

Epoch: 6| Step: 7
Training loss: 1.9260189533233643
Validation loss: 2.163200537363688

Epoch: 6| Step: 8
Training loss: 1.429556965827942
Validation loss: 2.143368204434713

Epoch: 6| Step: 9
Training loss: 1.588876724243164
Validation loss: 2.151052097479502

Epoch: 6| Step: 10
Training loss: 0.9363033175468445
Validation loss: 2.1456149419148765

Epoch: 6| Step: 11
Training loss: 1.6156773567199707
Validation loss: 2.1447081367174783

Epoch: 6| Step: 12
Training loss: 1.529177188873291
Validation loss: 2.1267597874005637

Epoch: 6| Step: 13
Training loss: 1.5182347297668457
Validation loss: 2.146608571211497

Epoch: 253| Step: 0
Training loss: 1.9586390256881714
Validation loss: 2.128348728020986

Epoch: 6| Step: 1
Training loss: 2.4943478107452393
Validation loss: 2.1229827404022217

Epoch: 6| Step: 2
Training loss: 2.3463549613952637
Validation loss: 2.1298288106918335

Epoch: 6| Step: 3
Training loss: 2.1292104721069336
Validation loss: 2.154933492342631

Epoch: 6| Step: 4
Training loss: 1.8859972953796387
Validation loss: 2.148980975151062

Epoch: 6| Step: 5
Training loss: 1.324648141860962
Validation loss: 2.150985916455587

Epoch: 6| Step: 6
Training loss: 1.3564149141311646
Validation loss: 2.1429214477539062

Epoch: 6| Step: 7
Training loss: 1.389069676399231
Validation loss: 2.1166126132011414

Epoch: 6| Step: 8
Training loss: 1.621492624282837
Validation loss: 2.1256848176320395

Epoch: 6| Step: 9
Training loss: 1.3108577728271484
Validation loss: 2.1287402311960855

Epoch: 6| Step: 10
Training loss: 1.825577974319458
Validation loss: 2.1206998229026794

Epoch: 6| Step: 11
Training loss: 1.417489767074585
Validation loss: 2.1342914700508118

Epoch: 6| Step: 12
Training loss: 1.5567176342010498
Validation loss: 2.1338775555292764

Epoch: 6| Step: 13
Training loss: 1.2748818397521973
Validation loss: 2.1436567505200705

Epoch: 254| Step: 0
Training loss: 1.7963823080062866
Validation loss: 2.130185822645823

Epoch: 6| Step: 1
Training loss: 1.781019687652588
Validation loss: 2.1517527302106223

Epoch: 6| Step: 2
Training loss: 2.055351734161377
Validation loss: 2.15048356850942

Epoch: 6| Step: 3
Training loss: 1.8760130405426025
Validation loss: 2.1296021342277527

Epoch: 6| Step: 4
Training loss: 1.953709363937378
Validation loss: 2.1342382232348123

Epoch: 6| Step: 5
Training loss: 2.366617202758789
Validation loss: 2.129477620124817

Epoch: 6| Step: 6
Training loss: 1.7307696342468262
Validation loss: 2.136273821194967

Epoch: 6| Step: 7
Training loss: 1.8567678928375244
Validation loss: 2.1154029965400696

Epoch: 6| Step: 8
Training loss: 1.7357046604156494
Validation loss: 2.121583342552185

Epoch: 6| Step: 9
Training loss: 1.5149431228637695
Validation loss: 2.124510129292806

Epoch: 6| Step: 10
Training loss: 1.6901357173919678
Validation loss: 2.1625109910964966

Epoch: 6| Step: 11
Training loss: 1.9052181243896484
Validation loss: 2.128223995367686

Epoch: 6| Step: 12
Training loss: 1.151166319847107
Validation loss: 2.1378034353256226

Epoch: 6| Step: 13
Training loss: 0.8070353865623474
Validation loss: 2.1274818579355874

Epoch: 255| Step: 0
Training loss: 1.7806763648986816
Validation loss: 2.1258556048075357

Epoch: 6| Step: 1
Training loss: 1.6191563606262207
Validation loss: 2.119628349939982

Epoch: 6| Step: 2
Training loss: 0.9302136898040771
Validation loss: 2.1527445912361145

Epoch: 6| Step: 3
Training loss: 1.3566583395004272
Validation loss: 2.1211448907852173

Epoch: 6| Step: 4
Training loss: 2.5539557933807373
Validation loss: 2.1158321698506675

Epoch: 6| Step: 5
Training loss: 1.7687060832977295
Validation loss: 2.112724264462789

Epoch: 6| Step: 6
Training loss: 1.9492435455322266
Validation loss: 2.1257375677426658

Epoch: 6| Step: 7
Training loss: 2.13265061378479
Validation loss: 2.115584413210551

Epoch: 6| Step: 8
Training loss: 2.2920491695404053
Validation loss: 2.1134142676989236

Epoch: 6| Step: 9
Training loss: 1.6391932964324951
Validation loss: 2.112754702568054

Epoch: 6| Step: 10
Training loss: 1.0862756967544556
Validation loss: 2.124917984008789

Epoch: 6| Step: 11
Training loss: 1.4721271991729736
Validation loss: 2.1175058682759604

Epoch: 6| Step: 12
Training loss: 1.6611989736557007
Validation loss: 2.130018134911855

Epoch: 6| Step: 13
Training loss: 2.2133617401123047
Validation loss: 2.104346732298533

Epoch: 256| Step: 0
Training loss: 1.1224358081817627
Validation loss: 2.132169167200724

Epoch: 6| Step: 1
Training loss: 1.924178957939148
Validation loss: 2.1362516283988953

Epoch: 6| Step: 2
Training loss: 0.9954250454902649
Validation loss: 2.150638480981191

Epoch: 6| Step: 3
Training loss: 1.3802556991577148
Validation loss: 2.1500741442044577

Epoch: 6| Step: 4
Training loss: 1.4198452234268188
Validation loss: 2.1402894059816995

Epoch: 6| Step: 5
Training loss: 1.9828214645385742
Validation loss: 2.159099598725637

Epoch: 6| Step: 6
Training loss: 1.888568639755249
Validation loss: 2.1586455702781677

Epoch: 6| Step: 7
Training loss: 1.9374943971633911
Validation loss: 2.152563472588857

Epoch: 6| Step: 8
Training loss: 2.156947612762451
Validation loss: 2.1539185643196106

Epoch: 6| Step: 9
Training loss: 2.40897536277771
Validation loss: 2.1483062505722046

Epoch: 6| Step: 10
Training loss: 2.0058112144470215
Validation loss: 2.1121195753415427

Epoch: 6| Step: 11
Training loss: 1.7019498348236084
Validation loss: 2.123085002104441

Epoch: 6| Step: 12
Training loss: 1.4596306085586548
Validation loss: 2.1230862935384116

Epoch: 6| Step: 13
Training loss: 1.9606317281723022
Validation loss: 2.126077930132548

Epoch: 257| Step: 0
Training loss: 1.5319722890853882
Validation loss: 2.1089929739634194

Epoch: 6| Step: 1
Training loss: 2.281238079071045
Validation loss: 2.1394307216008506

Epoch: 6| Step: 2
Training loss: 1.0772758722305298
Validation loss: 2.108149607976278

Epoch: 6| Step: 3
Training loss: 1.3904743194580078
Validation loss: 2.1225155790646872

Epoch: 6| Step: 4
Training loss: 2.08713960647583
Validation loss: 2.1205703814824424

Epoch: 6| Step: 5
Training loss: 1.6546969413757324
Validation loss: 2.1032145619392395

Epoch: 6| Step: 6
Training loss: 1.6236166954040527
Validation loss: 2.1422637899716697

Epoch: 6| Step: 7
Training loss: 1.727227807044983
Validation loss: 2.1184296210606894

Epoch: 6| Step: 8
Training loss: 2.1339528560638428
Validation loss: 2.1250082651774087

Epoch: 6| Step: 9
Training loss: 1.9040229320526123
Validation loss: 2.13763564825058

Epoch: 6| Step: 10
Training loss: 1.5671576261520386
Validation loss: 2.1173014839490256

Epoch: 6| Step: 11
Training loss: 1.152625322341919
Validation loss: 2.1218618750572205

Epoch: 6| Step: 12
Training loss: 2.0385854244232178
Validation loss: 2.1299853324890137

Epoch: 6| Step: 13
Training loss: 1.650736689567566
Validation loss: 2.1239460706710815

Epoch: 258| Step: 0
Training loss: 2.0037167072296143
Validation loss: 2.127393205960592

Epoch: 6| Step: 1
Training loss: 2.218024730682373
Validation loss: 2.120579799016317

Epoch: 6| Step: 2
Training loss: 1.52312433719635
Validation loss: 2.1122722824414573

Epoch: 6| Step: 3
Training loss: 1.5509936809539795
Validation loss: 2.1101256211598716

Epoch: 6| Step: 4
Training loss: 1.8819444179534912
Validation loss: 2.114472726980845

Epoch: 6| Step: 5
Training loss: 2.0475430488586426
Validation loss: 2.1391682426134744

Epoch: 6| Step: 6
Training loss: 1.0765917301177979
Validation loss: 2.1364044348398843

Epoch: 6| Step: 7
Training loss: 1.789840579032898
Validation loss: 2.1199042598406472

Epoch: 6| Step: 8
Training loss: 2.0833444595336914
Validation loss: 2.117650548617045

Epoch: 6| Step: 9
Training loss: 1.3794584274291992
Validation loss: 2.1342703302701316

Epoch: 6| Step: 10
Training loss: 1.8063162565231323
Validation loss: 2.148508886496226

Epoch: 6| Step: 11
Training loss: 1.138359785079956
Validation loss: 2.1301202972730002

Epoch: 6| Step: 12
Training loss: 1.5852630138397217
Validation loss: 2.109042525291443

Epoch: 6| Step: 13
Training loss: 1.4331583976745605
Validation loss: 2.1144991318384805

Epoch: 259| Step: 0
Training loss: 1.2490766048431396
Validation loss: 2.109081228574117

Epoch: 6| Step: 1
Training loss: 1.6720869541168213
Validation loss: 2.1180750330289206

Epoch: 6| Step: 2
Training loss: 1.8687949180603027
Validation loss: 2.117318948109945

Epoch: 6| Step: 3
Training loss: 1.3976099491119385
Validation loss: 2.1084604263305664

Epoch: 6| Step: 4
Training loss: 1.8856887817382812
Validation loss: 2.11786154905955

Epoch: 6| Step: 5
Training loss: 2.1751708984375
Validation loss: 2.1229365269343057

Epoch: 6| Step: 6
Training loss: 1.3418679237365723
Validation loss: 2.1450835267702737

Epoch: 6| Step: 7
Training loss: 1.249023675918579
Validation loss: 2.1230627298355103

Epoch: 6| Step: 8
Training loss: 1.924692988395691
Validation loss: 2.122908969720205

Epoch: 6| Step: 9
Training loss: 1.6452503204345703
Validation loss: 2.09966508547465

Epoch: 6| Step: 10
Training loss: 2.1275136470794678
Validation loss: 2.103867530822754

Epoch: 6| Step: 11
Training loss: 0.9130640625953674
Validation loss: 2.1040550072987876

Epoch: 6| Step: 12
Training loss: 2.280855655670166
Validation loss: 2.1141175826390586

Epoch: 6| Step: 13
Training loss: 1.9151039123535156
Validation loss: 2.1124050617218018

Epoch: 260| Step: 0
Training loss: 1.5689609050750732
Validation loss: 2.1266210476557412

Epoch: 6| Step: 1
Training loss: 1.8612949848175049
Validation loss: 2.128190577030182

Epoch: 6| Step: 2
Training loss: 1.6803507804870605
Validation loss: 2.119927148024241

Epoch: 6| Step: 3
Training loss: 1.960438847541809
Validation loss: 2.146052082379659

Epoch: 6| Step: 4
Training loss: 2.079735040664673
Validation loss: 2.1242454449335733

Epoch: 6| Step: 5
Training loss: 1.7801462411880493
Validation loss: 2.1075841784477234

Epoch: 6| Step: 6
Training loss: 1.8394396305084229
Validation loss: 2.1135603984196982

Epoch: 6| Step: 7
Training loss: 1.3254321813583374
Validation loss: 2.0818472504615784

Epoch: 6| Step: 8
Training loss: 2.1802713871002197
Validation loss: 2.118504265944163

Epoch: 6| Step: 9
Training loss: 1.653965711593628
Validation loss: 2.100431422392527

Epoch: 6| Step: 10
Training loss: 1.4215936660766602
Validation loss: 2.0909114678700766

Epoch: 6| Step: 11
Training loss: 2.227884292602539
Validation loss: 2.1073071161905923

Epoch: 6| Step: 12
Training loss: 1.5617581605911255
Validation loss: 2.1101054549217224

Epoch: 6| Step: 13
Training loss: 1.3203625679016113
Validation loss: 2.090970198313395

Epoch: 261| Step: 0
Training loss: 1.6158784627914429
Validation loss: 2.104040960470835

Epoch: 6| Step: 1
Training loss: 1.9298996925354004
Validation loss: 2.0871742169062295

Epoch: 6| Step: 2
Training loss: 1.689197301864624
Validation loss: 2.146293838818868

Epoch: 6| Step: 3
Training loss: 1.547545075416565
Validation loss: 2.146128753821055

Epoch: 6| Step: 4
Training loss: 1.4301518201828003
Validation loss: 2.12114816904068

Epoch: 6| Step: 5
Training loss: 2.261202812194824
Validation loss: 2.1365940968195596

Epoch: 6| Step: 6
Training loss: 1.8983674049377441
Validation loss: 2.126639465490977

Epoch: 6| Step: 7
Training loss: 2.266274929046631
Validation loss: 2.1144397060076394

Epoch: 6| Step: 8
Training loss: 2.0569515228271484
Validation loss: 2.122523526350657

Epoch: 6| Step: 9
Training loss: 1.5574201345443726
Validation loss: 2.153269370396932

Epoch: 6| Step: 10
Training loss: 1.2431888580322266
Validation loss: 2.151003837585449

Epoch: 6| Step: 11
Training loss: 2.318472385406494
Validation loss: 2.161279002825419

Epoch: 6| Step: 12
Training loss: 1.4576013088226318
Validation loss: 2.1486260493596396

Epoch: 6| Step: 13
Training loss: 2.12909197807312
Validation loss: 2.1534752249717712

Epoch: 262| Step: 0
Training loss: 1.4082030057907104
Validation loss: 2.1674795150756836

Epoch: 6| Step: 1
Training loss: 1.5733168125152588
Validation loss: 2.1387181282043457

Epoch: 6| Step: 2
Training loss: 2.037031650543213
Validation loss: 2.140149394671122

Epoch: 6| Step: 3
Training loss: 1.733788013458252
Validation loss: 2.1195606787999473

Epoch: 6| Step: 4
Training loss: 1.3259683847427368
Validation loss: 2.1143340865770974

Epoch: 6| Step: 5
Training loss: 1.2924401760101318
Validation loss: 2.1205113331476846

Epoch: 6| Step: 6
Training loss: 2.1690425872802734
Validation loss: 2.1220024625460305

Epoch: 6| Step: 7
Training loss: 2.0688529014587402
Validation loss: 2.1088217298189798

Epoch: 6| Step: 8
Training loss: 1.9566314220428467
Validation loss: 2.108866532643636

Epoch: 6| Step: 9
Training loss: 2.1182944774627686
Validation loss: 2.1064868569374084

Epoch: 6| Step: 10
Training loss: 1.5358941555023193
Validation loss: 2.10853519042333

Epoch: 6| Step: 11
Training loss: 1.279212236404419
Validation loss: 2.1082226634025574

Epoch: 6| Step: 12
Training loss: 1.90456223487854
Validation loss: 2.086049218972524

Epoch: 6| Step: 13
Training loss: 1.423421025276184
Validation loss: 2.114279627799988

Epoch: 263| Step: 0
Training loss: 1.8858757019042969
Validation loss: 2.0763096610705056

Epoch: 6| Step: 1
Training loss: 1.3921531438827515
Validation loss: 2.1237523357073465

Epoch: 6| Step: 2
Training loss: 1.3453565835952759
Validation loss: 2.1346285541852317

Epoch: 6| Step: 3
Training loss: 1.240113377571106
Validation loss: 2.1310068170229592

Epoch: 6| Step: 4
Training loss: 1.6900906562805176
Validation loss: 2.1316084067026773

Epoch: 6| Step: 5
Training loss: 1.9822596311569214
Validation loss: 2.1162510315577188

Epoch: 6| Step: 6
Training loss: 1.2545102834701538
Validation loss: 2.1268593867619834

Epoch: 6| Step: 7
Training loss: 2.4248337745666504
Validation loss: 2.135572671890259

Epoch: 6| Step: 8
Training loss: 1.869305968284607
Validation loss: 2.158722718556722

Epoch: 6| Step: 9
Training loss: 1.6884679794311523
Validation loss: 2.149212419986725

Epoch: 6| Step: 10
Training loss: 1.7214510440826416
Validation loss: 2.1341490348180137

Epoch: 6| Step: 11
Training loss: 2.0086498260498047
Validation loss: 2.1510488192240396

Epoch: 6| Step: 12
Training loss: 1.9369006156921387
Validation loss: 2.1367546717325845

Epoch: 6| Step: 13
Training loss: 1.4907252788543701
Validation loss: 2.1240709026654563

Epoch: 264| Step: 0
Training loss: 1.5078825950622559
Validation loss: 2.130175153414408

Epoch: 6| Step: 1
Training loss: 1.033813238143921
Validation loss: 2.1012510855992637

Epoch: 6| Step: 2
Training loss: 2.7746479511260986
Validation loss: 2.0711814363797507

Epoch: 6| Step: 3
Training loss: 2.6046552658081055
Validation loss: 2.084454278151194

Epoch: 6| Step: 4
Training loss: 1.3922220468521118
Validation loss: 2.0900630156199136

Epoch: 6| Step: 5
Training loss: 1.3994181156158447
Validation loss: 2.0922722220420837

Epoch: 6| Step: 6
Training loss: 2.19364070892334
Validation loss: 2.089571257432302

Epoch: 6| Step: 7
Training loss: 1.461225986480713
Validation loss: 2.0866536696751914

Epoch: 6| Step: 8
Training loss: 1.3861702680587769
Validation loss: 2.089189112186432

Epoch: 6| Step: 9
Training loss: 1.6445271968841553
Validation loss: 2.0928834875424704

Epoch: 6| Step: 10
Training loss: 1.236851453781128
Validation loss: 2.0921654303868613

Epoch: 6| Step: 11
Training loss: 1.4285221099853516
Validation loss: 2.1039756337801614

Epoch: 6| Step: 12
Training loss: 1.5068033933639526
Validation loss: 2.1420219937960305

Epoch: 6| Step: 13
Training loss: 2.0332207679748535
Validation loss: 2.136402686436971

Epoch: 265| Step: 0
Training loss: 1.8374848365783691
Validation loss: 2.1190765698750815

Epoch: 6| Step: 1
Training loss: 1.327789545059204
Validation loss: 2.1347087621688843

Epoch: 6| Step: 2
Training loss: 1.857659101486206
Validation loss: 2.1111461321512857

Epoch: 6| Step: 3
Training loss: 2.229154109954834
Validation loss: 2.0952319304148355

Epoch: 6| Step: 4
Training loss: 1.5111117362976074
Validation loss: 2.084567348162333

Epoch: 6| Step: 5
Training loss: 1.0258992910385132
Validation loss: 2.1077426075935364

Epoch: 6| Step: 6
Training loss: 1.8853857517242432
Validation loss: 2.0857429107030234

Epoch: 6| Step: 7
Training loss: 1.7052327394485474
Validation loss: 2.08248104651769

Epoch: 6| Step: 8
Training loss: 1.7703965902328491
Validation loss: 2.126950661341349

Epoch: 6| Step: 9
Training loss: 1.9156501293182373
Validation loss: 2.1242180864016214

Epoch: 6| Step: 10
Training loss: 1.25881028175354
Validation loss: 2.1248353918393454

Epoch: 6| Step: 11
Training loss: 2.0706052780151367
Validation loss: 2.1187477906545005

Epoch: 6| Step: 12
Training loss: 1.3244911432266235
Validation loss: 2.1013229489326477

Epoch: 6| Step: 13
Training loss: 1.826864242553711
Validation loss: 2.126966635386149

Epoch: 266| Step: 0
Training loss: 1.7292020320892334
Validation loss: 2.133942484855652

Epoch: 6| Step: 1
Training loss: 1.5969269275665283
Validation loss: 2.112114747365316

Epoch: 6| Step: 2
Training loss: 1.129467487335205
Validation loss: 2.1091083884239197

Epoch: 6| Step: 3
Training loss: 1.66336989402771
Validation loss: 2.1067803502082825

Epoch: 6| Step: 4
Training loss: 1.326833724975586
Validation loss: 2.121271848678589

Epoch: 6| Step: 5
Training loss: 1.4491349458694458
Validation loss: 2.099994341532389

Epoch: 6| Step: 6
Training loss: 2.3893229961395264
Validation loss: 2.112621823946635

Epoch: 6| Step: 7
Training loss: 1.9795953035354614
Validation loss: 2.0868347883224487

Epoch: 6| Step: 8
Training loss: 1.627603530883789
Validation loss: 2.0872198343276978

Epoch: 6| Step: 9
Training loss: 1.5688023567199707
Validation loss: 2.0714821020762124

Epoch: 6| Step: 10
Training loss: 1.8422605991363525
Validation loss: 2.081822137037913

Epoch: 6| Step: 11
Training loss: 1.095304250717163
Validation loss: 2.097597320874532

Epoch: 6| Step: 12
Training loss: 1.9385626316070557
Validation loss: 2.108671466509501

Epoch: 6| Step: 13
Training loss: 1.9097363948822021
Validation loss: 2.128046135107676

Epoch: 267| Step: 0
Training loss: 1.0984019041061401
Validation loss: 2.1300549705823264

Epoch: 6| Step: 1
Training loss: 2.1880009174346924
Validation loss: 2.1146581371625266

Epoch: 6| Step: 2
Training loss: 2.1875925064086914
Validation loss: 2.128653268019358

Epoch: 6| Step: 3
Training loss: 1.5791420936584473
Validation loss: 2.1173288027445474

Epoch: 6| Step: 4
Training loss: 1.8579766750335693
Validation loss: 2.1133130192756653

Epoch: 6| Step: 5
Training loss: 1.3264213800430298
Validation loss: 2.094624161720276

Epoch: 6| Step: 6
Training loss: 1.687479019165039
Validation loss: 2.108790417512258

Epoch: 6| Step: 7
Training loss: 1.156731367111206
Validation loss: 2.0945061643918357

Epoch: 6| Step: 8
Training loss: 1.3056185245513916
Validation loss: 2.066981931527456

Epoch: 6| Step: 9
Training loss: 2.027376413345337
Validation loss: 2.0827234586079917

Epoch: 6| Step: 10
Training loss: 1.8559703826904297
Validation loss: 2.092792054017385

Epoch: 6| Step: 11
Training loss: 2.2783002853393555
Validation loss: 2.114737590154012

Epoch: 6| Step: 12
Training loss: 1.9702658653259277
Validation loss: 2.1135720213254294

Epoch: 6| Step: 13
Training loss: 1.3035082817077637
Validation loss: 2.0913625160853067

Epoch: 268| Step: 0
Training loss: 1.8215627670288086
Validation loss: 2.107942740122477

Epoch: 6| Step: 1
Training loss: 1.7183974981307983
Validation loss: 2.1083619395891824

Epoch: 6| Step: 2
Training loss: 1.2929320335388184
Validation loss: 2.0944788257280984

Epoch: 6| Step: 3
Training loss: 1.7744505405426025
Validation loss: 2.093190689881643

Epoch: 6| Step: 4
Training loss: 2.036611318588257
Validation loss: 2.1134095788002014

Epoch: 6| Step: 5
Training loss: 1.4098930358886719
Validation loss: 2.1054237882296243

Epoch: 6| Step: 6
Training loss: 1.8212685585021973
Validation loss: 2.100273847579956

Epoch: 6| Step: 7
Training loss: 1.660703420639038
Validation loss: 2.0829054713249207

Epoch: 6| Step: 8
Training loss: 1.9557820558547974
Validation loss: 2.116049865881602

Epoch: 6| Step: 9
Training loss: 2.3748362064361572
Validation loss: 2.0965614120165506

Epoch: 6| Step: 10
Training loss: 1.5268806219100952
Validation loss: 2.115848124027252

Epoch: 6| Step: 11
Training loss: 1.5685005187988281
Validation loss: 2.134321630001068

Epoch: 6| Step: 12
Training loss: 1.451860785484314
Validation loss: 2.1429545084635415

Epoch: 6| Step: 13
Training loss: 1.6875582933425903
Validation loss: 2.143637935320536

Epoch: 269| Step: 0
Training loss: 1.6556084156036377
Validation loss: 2.1416147351264954

Epoch: 6| Step: 1
Training loss: 2.0438032150268555
Validation loss: 2.1384284694989524

Epoch: 6| Step: 2
Training loss: 2.143339157104492
Validation loss: 2.1225742300351462

Epoch: 6| Step: 3
Training loss: 1.1386691331863403
Validation loss: 2.134374221165975

Epoch: 6| Step: 4
Training loss: 2.3557565212249756
Validation loss: 2.1150386134783425

Epoch: 6| Step: 5
Training loss: 1.5721023082733154
Validation loss: 2.10831485191981

Epoch: 6| Step: 6
Training loss: 1.1639087200164795
Validation loss: 2.116355021794637

Epoch: 6| Step: 7
Training loss: 1.2380809783935547
Validation loss: 2.1188039779663086

Epoch: 6| Step: 8
Training loss: 1.5214383602142334
Validation loss: 2.095936139424642

Epoch: 6| Step: 9
Training loss: 1.376893401145935
Validation loss: 2.1355618834495544

Epoch: 6| Step: 10
Training loss: 2.6887431144714355
Validation loss: 2.1069793105125427

Epoch: 6| Step: 11
Training loss: 2.4522900581359863
Validation loss: 2.1453433831532798

Epoch: 6| Step: 12
Training loss: 0.8925740122795105
Validation loss: 2.1165568033854165

Epoch: 6| Step: 13
Training loss: 2.0516371726989746
Validation loss: 2.1050099531809487

Epoch: 270| Step: 0
Training loss: 2.1218409538269043
Validation loss: 2.125776926676432

Epoch: 6| Step: 1
Training loss: 1.0617270469665527
Validation loss: 2.1365033984184265

Epoch: 6| Step: 2
Training loss: 1.292503833770752
Validation loss: 2.1257905761400857

Epoch: 6| Step: 3
Training loss: 1.1873133182525635
Validation loss: 2.125444153944651

Epoch: 6| Step: 4
Training loss: 1.4424911737442017
Validation loss: 2.156813462575277

Epoch: 6| Step: 5
Training loss: 1.6861964464187622
Validation loss: 2.1604101856549582

Epoch: 6| Step: 6
Training loss: 1.2194855213165283
Validation loss: 2.156354566415151

Epoch: 6| Step: 7
Training loss: 2.0789129734039307
Validation loss: 2.1334292888641357

Epoch: 6| Step: 8
Training loss: 1.9431480169296265
Validation loss: 2.1459410190582275

Epoch: 6| Step: 9
Training loss: 2.5785584449768066
Validation loss: 2.1232945919036865

Epoch: 6| Step: 10
Training loss: 1.567927598953247
Validation loss: 2.102691650390625

Epoch: 6| Step: 11
Training loss: 1.7954130172729492
Validation loss: 2.129947622617086

Epoch: 6| Step: 12
Training loss: 1.9928876161575317
Validation loss: 2.135551611582438

Epoch: 6| Step: 13
Training loss: 1.44242262840271
Validation loss: 2.137866040070852

Epoch: 271| Step: 0
Training loss: 1.7403318881988525
Validation loss: 2.127756436665853

Epoch: 6| Step: 1
Training loss: 1.390230655670166
Validation loss: 2.136330167452494

Epoch: 6| Step: 2
Training loss: 1.5439414978027344
Validation loss: 2.130005876223246

Epoch: 6| Step: 3
Training loss: 1.4839801788330078
Validation loss: 2.1362122694651284

Epoch: 6| Step: 4
Training loss: 1.5299129486083984
Validation loss: 2.1190022031466165

Epoch: 6| Step: 5
Training loss: 1.5731279850006104
Validation loss: 2.1247010032335916

Epoch: 6| Step: 6
Training loss: 1.9091520309448242
Validation loss: 2.1049139300982156

Epoch: 6| Step: 7
Training loss: 2.1166772842407227
Validation loss: 2.1078022519747415

Epoch: 6| Step: 8
Training loss: 1.5765537023544312
Validation loss: 2.1147089203198752

Epoch: 6| Step: 9
Training loss: 1.352466344833374
Validation loss: 2.118977109591166

Epoch: 6| Step: 10
Training loss: 1.4088478088378906
Validation loss: 2.14811380704244

Epoch: 6| Step: 11
Training loss: 2.099043369293213
Validation loss: 2.1288182139396667

Epoch: 6| Step: 12
Training loss: 1.7446491718292236
Validation loss: 2.127583702405294

Epoch: 6| Step: 13
Training loss: 1.9601845741271973
Validation loss: 2.1309878627459207

Epoch: 272| Step: 0
Training loss: 1.819120168685913
Validation loss: 2.109978278477987

Epoch: 6| Step: 1
Training loss: 2.237947463989258
Validation loss: 2.162710169951121

Epoch: 6| Step: 2
Training loss: 1.6918132305145264
Validation loss: 2.1479872266451516

Epoch: 6| Step: 3
Training loss: 1.1064459085464478
Validation loss: 2.1311772664388022

Epoch: 6| Step: 4
Training loss: 1.623471736907959
Validation loss: 2.150868237018585

Epoch: 6| Step: 5
Training loss: 1.6853827238082886
Validation loss: 2.1388081709543862

Epoch: 6| Step: 6
Training loss: 1.1114060878753662
Validation loss: 2.11174076795578

Epoch: 6| Step: 7
Training loss: 1.4821572303771973
Validation loss: 2.124812583128611

Epoch: 6| Step: 8
Training loss: 1.5834177732467651
Validation loss: 2.1394731601079306

Epoch: 6| Step: 9
Training loss: 2.104921817779541
Validation loss: 2.1320640643437705

Epoch: 6| Step: 10
Training loss: 2.250373125076294
Validation loss: 2.1020736694335938

Epoch: 6| Step: 11
Training loss: 1.6970503330230713
Validation loss: 2.098055362701416

Epoch: 6| Step: 12
Training loss: 0.956747829914093
Validation loss: 2.0887296001116433

Epoch: 6| Step: 13
Training loss: 1.7525153160095215
Validation loss: 2.0836981336275735

Epoch: 273| Step: 0
Training loss: 1.5475988388061523
Validation loss: 2.076745390892029

Epoch: 6| Step: 1
Training loss: 1.2928142547607422
Validation loss: 2.0895838538805642

Epoch: 6| Step: 2
Training loss: 1.6368480920791626
Validation loss: 2.0892454187075296

Epoch: 6| Step: 3
Training loss: 1.6595714092254639
Validation loss: 2.109276910622915

Epoch: 6| Step: 4
Training loss: 2.0364246368408203
Validation loss: 2.1179506381352744

Epoch: 6| Step: 5
Training loss: 1.1543595790863037
Validation loss: 2.098472833633423

Epoch: 6| Step: 6
Training loss: 1.1375610828399658
Validation loss: 2.087063173453013

Epoch: 6| Step: 7
Training loss: 2.6447653770446777
Validation loss: 2.1058435837427774

Epoch: 6| Step: 8
Training loss: 1.6514384746551514
Validation loss: 2.098346213499705

Epoch: 6| Step: 9
Training loss: 1.738168478012085
Validation loss: 2.128404716650645

Epoch: 6| Step: 10
Training loss: 1.7706751823425293
Validation loss: 2.1477507948875427

Epoch: 6| Step: 11
Training loss: 1.8298442363739014
Validation loss: 2.153683582941691

Epoch: 6| Step: 12
Training loss: 1.5670353174209595
Validation loss: 2.1489060322443643

Epoch: 6| Step: 13
Training loss: 2.0295522212982178
Validation loss: 2.1661518812179565

Epoch: 274| Step: 0
Training loss: 1.415923833847046
Validation loss: 2.121963381767273

Epoch: 6| Step: 1
Training loss: 1.8912346363067627
Validation loss: 2.129899322986603

Epoch: 6| Step: 2
Training loss: 2.118772268295288
Validation loss: 2.0929176608721414

Epoch: 6| Step: 3
Training loss: 1.568685531616211
Validation loss: 2.0970030228296914

Epoch: 6| Step: 4
Training loss: 1.3834646940231323
Validation loss: 2.064326802889506

Epoch: 6| Step: 5
Training loss: 1.9267479181289673
Validation loss: 2.092047850290934

Epoch: 6| Step: 6
Training loss: 1.3916006088256836
Validation loss: 2.1077824433644614

Epoch: 6| Step: 7
Training loss: 2.0103073120117188
Validation loss: 2.093774199485779

Epoch: 6| Step: 8
Training loss: 0.9780027866363525
Validation loss: 2.1157310803731284

Epoch: 6| Step: 9
Training loss: 2.078211784362793
Validation loss: 2.1025148232777915

Epoch: 6| Step: 10
Training loss: 1.569444179534912
Validation loss: 2.1099249919255576

Epoch: 6| Step: 11
Training loss: 1.0927420854568481
Validation loss: 2.1149807373682656

Epoch: 6| Step: 12
Training loss: 1.830023169517517
Validation loss: 2.1180633703867593

Epoch: 6| Step: 13
Training loss: 1.6539676189422607
Validation loss: 2.1006893515586853

Epoch: 275| Step: 0
Training loss: 1.7155593633651733
Validation loss: 2.09282519419988

Epoch: 6| Step: 1
Training loss: 1.6823368072509766
Validation loss: 2.1168184876441956

Epoch: 6| Step: 2
Training loss: 1.6234261989593506
Validation loss: 2.0928293069203696

Epoch: 6| Step: 3
Training loss: 1.3694343566894531
Validation loss: 2.1182870070139566

Epoch: 6| Step: 4
Training loss: 1.471362590789795
Validation loss: 2.128920098145803

Epoch: 6| Step: 5
Training loss: 1.7679295539855957
Validation loss: 2.0861635208129883

Epoch: 6| Step: 6
Training loss: 1.4620270729064941
Validation loss: 2.1100142002105713

Epoch: 6| Step: 7
Training loss: 2.2266831398010254
Validation loss: 2.109466294447581

Epoch: 6| Step: 8
Training loss: 2.2266581058502197
Validation loss: 2.1084043383598328

Epoch: 6| Step: 9
Training loss: 1.8888710737228394
Validation loss: 2.1081112225850425

Epoch: 6| Step: 10
Training loss: 1.2100882530212402
Validation loss: 2.122511903444926

Epoch: 6| Step: 11
Training loss: 1.199286699295044
Validation loss: 2.113899747530619

Epoch: 6| Step: 12
Training loss: 1.2967259883880615
Validation loss: 2.1200145483016968

Epoch: 6| Step: 13
Training loss: 1.629327416419983
Validation loss: 2.0908788442611694

Epoch: 276| Step: 0
Training loss: 1.7654879093170166
Validation loss: 2.0709428985913596

Epoch: 6| Step: 1
Training loss: 1.4449083805084229
Validation loss: 2.0814723571141562

Epoch: 6| Step: 2
Training loss: 2.1977009773254395
Validation loss: 2.0875600377718606

Epoch: 6| Step: 3
Training loss: 1.0415555238723755
Validation loss: 2.101314922173818

Epoch: 6| Step: 4
Training loss: 1.6272944211959839
Validation loss: 2.0920735597610474

Epoch: 6| Step: 5
Training loss: 1.6259076595306396
Validation loss: 2.101611057917277

Epoch: 6| Step: 6
Training loss: 1.705143928527832
Validation loss: 2.130346099535624

Epoch: 6| Step: 7
Training loss: 1.817299723625183
Validation loss: 2.127210338910421

Epoch: 6| Step: 8
Training loss: 1.317065715789795
Validation loss: 2.102155327796936

Epoch: 6| Step: 9
Training loss: 1.729013442993164
Validation loss: 2.132489105065664

Epoch: 6| Step: 10
Training loss: 1.2396026849746704
Validation loss: 2.1085166335105896

Epoch: 6| Step: 11
Training loss: 1.597611904144287
Validation loss: 2.126993417739868

Epoch: 6| Step: 12
Training loss: 1.9253417253494263
Validation loss: 2.1263888080914817

Epoch: 6| Step: 13
Training loss: 1.8574328422546387
Validation loss: 2.118359168370565

Epoch: 277| Step: 0
Training loss: 1.6309581995010376
Validation loss: 2.122601270675659

Epoch: 6| Step: 1
Training loss: 2.164659023284912
Validation loss: 2.115674058596293

Epoch: 6| Step: 2
Training loss: 1.5981382131576538
Validation loss: 2.1154374281565347

Epoch: 6| Step: 3
Training loss: 2.03363037109375
Validation loss: 2.127738436063131

Epoch: 6| Step: 4
Training loss: 1.7644717693328857
Validation loss: 2.1381154656410217

Epoch: 6| Step: 5
Training loss: 1.7165992259979248
Validation loss: 2.1469590067863464

Epoch: 6| Step: 6
Training loss: 1.3410637378692627
Validation loss: 2.1227286060651145

Epoch: 6| Step: 7
Training loss: 0.9242057800292969
Validation loss: 2.093439439932505

Epoch: 6| Step: 8
Training loss: 1.7967495918273926
Validation loss: 2.0868844985961914

Epoch: 6| Step: 9
Training loss: 1.5971033573150635
Validation loss: 2.099301815032959

Epoch: 6| Step: 10
Training loss: 1.5148117542266846
Validation loss: 2.1305182576179504

Epoch: 6| Step: 11
Training loss: 1.8148789405822754
Validation loss: 2.1513820687929788

Epoch: 6| Step: 12
Training loss: 1.418984055519104
Validation loss: 2.1569546262423196

Epoch: 6| Step: 13
Training loss: 1.9099452495574951
Validation loss: 2.167585253715515

Epoch: 278| Step: 0
Training loss: 1.5718252658843994
Validation loss: 2.165023446083069

Epoch: 6| Step: 1
Training loss: 1.9633857011795044
Validation loss: 2.1667026480038962

Epoch: 6| Step: 2
Training loss: 2.356846809387207
Validation loss: 2.121453285217285

Epoch: 6| Step: 3
Training loss: 1.8819324970245361
Validation loss: 2.129484554131826

Epoch: 6| Step: 4
Training loss: 1.2599501609802246
Validation loss: 2.0988645950953164

Epoch: 6| Step: 5
Training loss: 1.875889778137207
Validation loss: 2.0998263557751975

Epoch: 6| Step: 6
Training loss: 1.5478770732879639
Validation loss: 2.136767049630483

Epoch: 6| Step: 7
Training loss: 1.6819182634353638
Validation loss: 2.0889805356661477

Epoch: 6| Step: 8
Training loss: 1.6864427328109741
Validation loss: 2.1033156315485635

Epoch: 6| Step: 9
Training loss: 1.6107373237609863
Validation loss: 2.091541806856791

Epoch: 6| Step: 10
Training loss: 1.8327536582946777
Validation loss: 2.0902414123217263

Epoch: 6| Step: 11
Training loss: 1.3653488159179688
Validation loss: 2.1016815106074014

Epoch: 6| Step: 12
Training loss: 1.3963998556137085
Validation loss: 2.096620241800944

Epoch: 6| Step: 13
Training loss: 1.5387425422668457
Validation loss: 2.101026932398478

Epoch: 279| Step: 0
Training loss: 1.650069236755371
Validation loss: 2.105312963326772

Epoch: 6| Step: 1
Training loss: 1.1942843198776245
Validation loss: 2.090351323286692

Epoch: 6| Step: 2
Training loss: 1.6405909061431885
Validation loss: 2.0960474014282227

Epoch: 6| Step: 3
Training loss: 1.3977664709091187
Validation loss: 2.088354746500651

Epoch: 6| Step: 4
Training loss: 1.965924859046936
Validation loss: 2.064885199069977

Epoch: 6| Step: 5
Training loss: 1.432326316833496
Validation loss: 2.0812148253122964

Epoch: 6| Step: 6
Training loss: 1.6714978218078613
Validation loss: 2.1083067258199057

Epoch: 6| Step: 7
Training loss: 1.395212173461914
Validation loss: 2.0997366905212402

Epoch: 6| Step: 8
Training loss: 2.576848030090332
Validation loss: 2.115850110848745

Epoch: 6| Step: 9
Training loss: 1.9008280038833618
Validation loss: 2.0645020802815757

Epoch: 6| Step: 10
Training loss: 1.848709225654602
Validation loss: 2.0614220102628074

Epoch: 6| Step: 11
Training loss: 1.3265607357025146
Validation loss: 2.0757848819096885

Epoch: 6| Step: 12
Training loss: 1.2509469985961914
Validation loss: 2.098208506902059

Epoch: 6| Step: 13
Training loss: 1.5138455629348755
Validation loss: 2.085086405277252

Epoch: 280| Step: 0
Training loss: 1.6652517318725586
Validation loss: 2.1272774736086526

Epoch: 6| Step: 1
Training loss: 1.308546781539917
Validation loss: 2.0938031673431396

Epoch: 6| Step: 2
Training loss: 2.146444082260132
Validation loss: 2.09880801041921

Epoch: 6| Step: 3
Training loss: 1.4764642715454102
Validation loss: 2.0928816000620523

Epoch: 6| Step: 4
Training loss: 1.9037829637527466
Validation loss: 2.1372234423955283

Epoch: 6| Step: 5
Training loss: 1.8439593315124512
Validation loss: 2.0864035884539285

Epoch: 6| Step: 6
Training loss: 2.1373050212860107
Validation loss: 2.07295028368632

Epoch: 6| Step: 7
Training loss: 1.7191245555877686
Validation loss: 2.080735524495443

Epoch: 6| Step: 8
Training loss: 1.89457368850708
Validation loss: 2.1077229181925454

Epoch: 6| Step: 9
Training loss: 1.1237505674362183
Validation loss: 2.1343438625335693

Epoch: 6| Step: 10
Training loss: 0.9979950189590454
Validation loss: 2.181480864683787

Epoch: 6| Step: 11
Training loss: 1.5331549644470215
Validation loss: 2.14414248863856

Epoch: 6| Step: 12
Training loss: 1.6903223991394043
Validation loss: 2.1734612186749778

Epoch: 6| Step: 13
Training loss: 1.2583413124084473
Validation loss: 2.1647097071011863

Epoch: 281| Step: 0
Training loss: 1.674363136291504
Validation loss: 2.14337694644928

Epoch: 6| Step: 1
Training loss: 1.7833436727523804
Validation loss: 2.1438902219136557

Epoch: 6| Step: 2
Training loss: 1.3679513931274414
Validation loss: 2.094629446665446

Epoch: 6| Step: 3
Training loss: 1.7814972400665283
Validation loss: 2.0865270694096885

Epoch: 6| Step: 4
Training loss: 1.5868899822235107
Validation loss: 2.0974263747533164

Epoch: 6| Step: 5
Training loss: 0.7607512474060059
Validation loss: 2.0934534271558127

Epoch: 6| Step: 6
Training loss: 1.623021125793457
Validation loss: 2.0876762866973877

Epoch: 6| Step: 7
Training loss: 1.56727135181427
Validation loss: 2.0745643377304077

Epoch: 6| Step: 8
Training loss: 1.710461974143982
Validation loss: 2.0924979050954184

Epoch: 6| Step: 9
Training loss: 1.5399318933486938
Validation loss: 2.0960166851679483

Epoch: 6| Step: 10
Training loss: 1.9861469268798828
Validation loss: 2.096377730369568

Epoch: 6| Step: 11
Training loss: 1.8866949081420898
Validation loss: 2.1142261226971946

Epoch: 6| Step: 12
Training loss: 1.5027680397033691
Validation loss: 2.069620112578074

Epoch: 6| Step: 13
Training loss: 1.5633513927459717
Validation loss: 2.091593782107035

Epoch: 282| Step: 0
Training loss: 1.372413992881775
Validation loss: 2.129988153775533

Epoch: 6| Step: 1
Training loss: 0.915164589881897
Validation loss: 2.104837437470754

Epoch: 6| Step: 2
Training loss: 1.5738483667373657
Validation loss: 2.089576462904612

Epoch: 6| Step: 3
Training loss: 1.3342654705047607
Validation loss: 2.089327037334442

Epoch: 6| Step: 4
Training loss: 1.124181866645813
Validation loss: 2.073504169782003

Epoch: 6| Step: 5
Training loss: 1.8507198095321655
Validation loss: 2.0906227231025696

Epoch: 6| Step: 6
Training loss: 1.854694128036499
Validation loss: 2.0804601113001504

Epoch: 6| Step: 7
Training loss: 2.0904312133789062
Validation loss: 2.110511064529419

Epoch: 6| Step: 8
Training loss: 2.1379687786102295
Validation loss: 2.1119800806045532

Epoch: 6| Step: 9
Training loss: 1.860532522201538
Validation loss: 2.1194380124409995

Epoch: 6| Step: 10
Training loss: 2.046938419342041
Validation loss: 2.129692316055298

Epoch: 6| Step: 11
Training loss: 1.3362046480178833
Validation loss: 2.1353739897410073

Epoch: 6| Step: 12
Training loss: 1.6385256052017212
Validation loss: 2.124876240889231

Epoch: 6| Step: 13
Training loss: 1.730238676071167
Validation loss: 2.0916927655537925

Epoch: 283| Step: 0
Training loss: 1.3965954780578613
Validation loss: 2.071824610233307

Epoch: 6| Step: 1
Training loss: 1.509333848953247
Validation loss: 2.061537226041158

Epoch: 6| Step: 2
Training loss: 1.209747314453125
Validation loss: 2.060223380724589

Epoch: 6| Step: 3
Training loss: 1.3662469387054443
Validation loss: 2.07025412718455

Epoch: 6| Step: 4
Training loss: 1.9032306671142578
Validation loss: 2.110647996266683

Epoch: 6| Step: 5
Training loss: 1.715445637702942
Validation loss: 2.0997233788172402

Epoch: 6| Step: 6
Training loss: 1.7447705268859863
Validation loss: 2.0652204155921936

Epoch: 6| Step: 7
Training loss: 1.784053921699524
Validation loss: 2.1148040692011514

Epoch: 6| Step: 8
Training loss: 1.7247824668884277
Validation loss: 2.0854369600613913

Epoch: 6| Step: 9
Training loss: 1.4680078029632568
Validation loss: 2.0778176188468933

Epoch: 6| Step: 10
Training loss: 1.7844278812408447
Validation loss: 2.0693175991376243

Epoch: 6| Step: 11
Training loss: 1.2888669967651367
Validation loss: 2.0596268574396768

Epoch: 6| Step: 12
Training loss: 1.8918724060058594
Validation loss: 2.0617650349934897

Epoch: 6| Step: 13
Training loss: 1.6779255867004395
Validation loss: 2.083962062994639

Epoch: 284| Step: 0
Training loss: 2.448577404022217
Validation loss: 2.079351305961609

Epoch: 6| Step: 1
Training loss: 1.8428921699523926
Validation loss: 2.075989385445913

Epoch: 6| Step: 2
Training loss: 1.0191786289215088
Validation loss: 2.0517714818318686

Epoch: 6| Step: 3
Training loss: 1.770038366317749
Validation loss: 2.0628998478253684

Epoch: 6| Step: 4
Training loss: 2.14359712600708
Validation loss: 2.070099433263143

Epoch: 6| Step: 5
Training loss: 1.4332886934280396
Validation loss: 2.063332756360372

Epoch: 6| Step: 6
Training loss: 1.420555830001831
Validation loss: 2.0738137563069663

Epoch: 6| Step: 7
Training loss: 1.4926936626434326
Validation loss: 2.0765406092007956

Epoch: 6| Step: 8
Training loss: 1.4813599586486816
Validation loss: 2.1298229694366455

Epoch: 6| Step: 9
Training loss: 1.3018732070922852
Validation loss: 2.143865247567495

Epoch: 6| Step: 10
Training loss: 1.4383431673049927
Validation loss: 2.152412533760071

Epoch: 6| Step: 11
Training loss: 1.594778299331665
Validation loss: 2.125065187613169

Epoch: 6| Step: 12
Training loss: 2.0686826705932617
Validation loss: 2.075638691584269

Epoch: 6| Step: 13
Training loss: 0.9458229541778564
Validation loss: 2.0883567333221436

Epoch: 285| Step: 0
Training loss: 1.2574278116226196
Validation loss: 2.064550499121348

Epoch: 6| Step: 1
Training loss: 1.694231390953064
Validation loss: 2.070113698641459

Epoch: 6| Step: 2
Training loss: 1.6512775421142578
Validation loss: 2.0819392999013266

Epoch: 6| Step: 3
Training loss: 1.7950174808502197
Validation loss: 2.0780569116274514

Epoch: 6| Step: 4
Training loss: 1.7014943361282349
Validation loss: 2.1046860416730246

Epoch: 6| Step: 5
Training loss: 0.9743461012840271
Validation loss: 2.097574830055237

Epoch: 6| Step: 6
Training loss: 1.629339575767517
Validation loss: 2.0784096320470176

Epoch: 6| Step: 7
Training loss: 1.1440497636795044
Validation loss: 2.064253091812134

Epoch: 6| Step: 8
Training loss: 1.5462573766708374
Validation loss: 2.057237466176351

Epoch: 6| Step: 9
Training loss: 1.921553134918213
Validation loss: 2.0680490136146545

Epoch: 6| Step: 10
Training loss: 1.2056326866149902
Validation loss: 2.0465009411176047

Epoch: 6| Step: 11
Training loss: 1.9060412645339966
Validation loss: 2.092947026093801

Epoch: 6| Step: 12
Training loss: 1.666944146156311
Validation loss: 2.1386810541152954

Epoch: 6| Step: 13
Training loss: 1.7508227825164795
Validation loss: 2.1208598216374717

Epoch: 286| Step: 0
Training loss: 1.6151926517486572
Validation loss: 2.1589592496554055

Epoch: 6| Step: 1
Training loss: 1.6904996633529663
Validation loss: 2.124701817830404

Epoch: 6| Step: 2
Training loss: 0.9371832609176636
Validation loss: 2.109241505463918

Epoch: 6| Step: 3
Training loss: 1.7334907054901123
Validation loss: 2.0739252964655557

Epoch: 6| Step: 4
Training loss: 1.844730019569397
Validation loss: 2.060957133769989

Epoch: 6| Step: 5
Training loss: 1.1523019075393677
Validation loss: 2.059662421544393

Epoch: 6| Step: 6
Training loss: 1.3279603719711304
Validation loss: 2.1025769313176474

Epoch: 6| Step: 7
Training loss: 1.1343368291854858
Validation loss: 2.1147260665893555

Epoch: 6| Step: 8
Training loss: 1.7751978635787964
Validation loss: 2.1452434062957764

Epoch: 6| Step: 9
Training loss: 1.454620361328125
Validation loss: 2.1081189115842185

Epoch: 6| Step: 10
Training loss: 2.4107236862182617
Validation loss: 2.1307098865509033

Epoch: 6| Step: 11
Training loss: 1.723890781402588
Validation loss: 2.1293874979019165

Epoch: 6| Step: 12
Training loss: 1.6757864952087402
Validation loss: 2.1157209475835166

Epoch: 6| Step: 13
Training loss: 2.0159411430358887
Validation loss: 2.0846784909566245

Epoch: 287| Step: 0
Training loss: 1.3222813606262207
Validation loss: 2.074870506922404

Epoch: 6| Step: 1
Training loss: 2.3573625087738037
Validation loss: 2.088719149430593

Epoch: 6| Step: 2
Training loss: 1.5064334869384766
Validation loss: 2.104437450567881

Epoch: 6| Step: 3
Training loss: 0.7719522714614868
Validation loss: 2.1431812246640525

Epoch: 6| Step: 4
Training loss: 1.1512935161590576
Validation loss: 2.118222713470459

Epoch: 6| Step: 5
Training loss: 1.9854998588562012
Validation loss: 2.118042270342509

Epoch: 6| Step: 6
Training loss: 1.5933668613433838
Validation loss: 2.108141819636027

Epoch: 6| Step: 7
Training loss: 2.268995761871338
Validation loss: 2.1084646582603455

Epoch: 6| Step: 8
Training loss: 1.5223127603530884
Validation loss: 2.103572448094686

Epoch: 6| Step: 9
Training loss: 1.4838405847549438
Validation loss: 2.072740852832794

Epoch: 6| Step: 10
Training loss: 1.7768921852111816
Validation loss: 2.093398928642273

Epoch: 6| Step: 11
Training loss: 1.50467848777771
Validation loss: 2.105225920677185

Epoch: 6| Step: 12
Training loss: 1.5020999908447266
Validation loss: 2.061084429423014

Epoch: 6| Step: 13
Training loss: 1.0812734365463257
Validation loss: 2.0566712419191995

Epoch: 288| Step: 0
Training loss: 1.6231708526611328
Validation loss: 2.0599060455958047

Epoch: 6| Step: 1
Training loss: 2.6036524772644043
Validation loss: 2.1001996994018555

Epoch: 6| Step: 2
Training loss: 1.5745586156845093
Validation loss: 2.089870274066925

Epoch: 6| Step: 3
Training loss: 2.180975914001465
Validation loss: 2.116548260052999

Epoch: 6| Step: 4
Training loss: 2.1341965198516846
Validation loss: 2.129727820555369

Epoch: 6| Step: 5
Training loss: 1.0920659303665161
Validation loss: 2.085939864317576

Epoch: 6| Step: 6
Training loss: 1.1035311222076416
Validation loss: 2.0796890457471213

Epoch: 6| Step: 7
Training loss: 1.5768797397613525
Validation loss: 2.05318417151769

Epoch: 6| Step: 8
Training loss: 1.2871429920196533
Validation loss: 2.068514029184977

Epoch: 6| Step: 9
Training loss: 1.4311473369598389
Validation loss: 2.0820446610450745

Epoch: 6| Step: 10
Training loss: 1.9665589332580566
Validation loss: 2.0803062121073403

Epoch: 6| Step: 11
Training loss: 1.3192839622497559
Validation loss: 2.0918701688448587

Epoch: 6| Step: 12
Training loss: 1.1804184913635254
Validation loss: 2.0807719628016152

Epoch: 6| Step: 13
Training loss: 1.4330304861068726
Validation loss: 2.0960811177889505

Epoch: 289| Step: 0
Training loss: 1.7943084239959717
Validation loss: 2.099467078844706

Epoch: 6| Step: 1
Training loss: 1.8571865558624268
Validation loss: 2.079063137372335

Epoch: 6| Step: 2
Training loss: 2.0440003871917725
Validation loss: 2.0510284503300986

Epoch: 6| Step: 3
Training loss: 1.3543541431427002
Validation loss: 2.049392898877462

Epoch: 6| Step: 4
Training loss: 2.0257625579833984
Validation loss: 2.0887965758641562

Epoch: 6| Step: 5
Training loss: 2.0660881996154785
Validation loss: 2.0817193587621055

Epoch: 6| Step: 6
Training loss: 1.902085781097412
Validation loss: 2.17608376344045

Epoch: 6| Step: 7
Training loss: 1.450831651687622
Validation loss: 2.069083094596863

Epoch: 6| Step: 8
Training loss: 1.065676212310791
Validation loss: 2.0940046906471252

Epoch: 6| Step: 9
Training loss: 1.0747418403625488
Validation loss: 2.078148623307546

Epoch: 6| Step: 10
Training loss: 1.1609041690826416
Validation loss: 2.065029501914978

Epoch: 6| Step: 11
Training loss: 1.582066535949707
Validation loss: 2.0659735202789307

Epoch: 6| Step: 12
Training loss: 1.7238342761993408
Validation loss: 2.08391010761261

Epoch: 6| Step: 13
Training loss: 1.7728140354156494
Validation loss: 2.0689292748769126

Epoch: 290| Step: 0
Training loss: 1.4599254131317139
Validation loss: 2.0907169779141745

Epoch: 6| Step: 1
Training loss: 1.459489107131958
Validation loss: 2.1088534394900003

Epoch: 6| Step: 2
Training loss: 1.2426297664642334
Validation loss: 2.0857093135515847

Epoch: 6| Step: 3
Training loss: 2.177891492843628
Validation loss: 2.0875872373580933

Epoch: 6| Step: 4
Training loss: 1.748460054397583
Validation loss: 2.0722942550977073

Epoch: 6| Step: 5
Training loss: 0.8089767098426819
Validation loss: 2.0996270775794983

Epoch: 6| Step: 6
Training loss: 1.8520212173461914
Validation loss: 2.125266353289286

Epoch: 6| Step: 7
Training loss: 1.5206362009048462
Validation loss: 2.123961170514425

Epoch: 6| Step: 8
Training loss: 1.9984004497528076
Validation loss: 2.0994665026664734

Epoch: 6| Step: 9
Training loss: 0.8195214867591858
Validation loss: 2.0731393694877625

Epoch: 6| Step: 10
Training loss: 1.7446097135543823
Validation loss: 2.0747616291046143

Epoch: 6| Step: 11
Training loss: 1.2421287298202515
Validation loss: 2.0794820189476013

Epoch: 6| Step: 12
Training loss: 1.5639245510101318
Validation loss: 2.0933215022087097

Epoch: 6| Step: 13
Training loss: 1.8406734466552734
Validation loss: 2.112913111845652

Epoch: 291| Step: 0
Training loss: 1.4373128414154053
Validation loss: 2.0951712330182395

Epoch: 6| Step: 1
Training loss: 1.6576793193817139
Validation loss: 2.1066178480784097

Epoch: 6| Step: 2
Training loss: 2.2580158710479736
Validation loss: 2.0738074580828347

Epoch: 6| Step: 3
Training loss: 1.23799729347229
Validation loss: 2.081136782964071

Epoch: 6| Step: 4
Training loss: 2.01771879196167
Validation loss: 2.1024723649024963

Epoch: 6| Step: 5
Training loss: 1.8869507312774658
Validation loss: 2.1114211281140647

Epoch: 6| Step: 6
Training loss: 1.770429253578186
Validation loss: 2.094476898511251

Epoch: 6| Step: 7
Training loss: 1.226313829421997
Validation loss: 2.0753637552261353

Epoch: 6| Step: 8
Training loss: 1.455357551574707
Validation loss: 2.095568140347799

Epoch: 6| Step: 9
Training loss: 1.7492822408676147
Validation loss: 2.087533473968506

Epoch: 6| Step: 10
Training loss: 1.0045652389526367
Validation loss: 2.056016981601715

Epoch: 6| Step: 11
Training loss: 1.144289493560791
Validation loss: 2.0859458247820535

Epoch: 6| Step: 12
Training loss: 1.81591796875
Validation loss: 2.086792985598246

Epoch: 6| Step: 13
Training loss: 1.1735451221466064
Validation loss: 2.0764415661493936

Epoch: 292| Step: 0
Training loss: 1.5790960788726807
Validation loss: 2.100774347782135

Epoch: 6| Step: 1
Training loss: 1.4055452346801758
Validation loss: 2.12209951877594

Epoch: 6| Step: 2
Training loss: 2.2362446784973145
Validation loss: 2.1138848066329956

Epoch: 6| Step: 3
Training loss: 1.9566376209259033
Validation loss: 2.1274551351865134

Epoch: 6| Step: 4
Training loss: 1.0869369506835938
Validation loss: 2.114907463391622

Epoch: 6| Step: 5
Training loss: 1.4833331108093262
Validation loss: 2.081180532773336

Epoch: 6| Step: 6
Training loss: 1.627448320388794
Validation loss: 2.155690689881643

Epoch: 6| Step: 7
Training loss: 1.899928092956543
Validation loss: 2.1404439012209573

Epoch: 6| Step: 8
Training loss: 1.3723738193511963
Validation loss: 2.130485494931539

Epoch: 6| Step: 9
Training loss: 1.086043357849121
Validation loss: 2.117265522480011

Epoch: 6| Step: 10
Training loss: 1.428631067276001
Validation loss: 2.1024224758148193

Epoch: 6| Step: 11
Training loss: 1.5563312768936157
Validation loss: 2.0871020754178367

Epoch: 6| Step: 12
Training loss: 1.7953057289123535
Validation loss: 2.066197633743286

Epoch: 6| Step: 13
Training loss: 1.3029866218566895
Validation loss: 2.067346672217051

Epoch: 293| Step: 0
Training loss: 1.2866201400756836
Validation loss: 2.048214554786682

Epoch: 6| Step: 1
Training loss: 0.7175605893135071
Validation loss: 2.0516382455825806

Epoch: 6| Step: 2
Training loss: 1.8296873569488525
Validation loss: 2.0872249801953635

Epoch: 6| Step: 3
Training loss: 1.3321892023086548
Validation loss: 2.0708237886428833

Epoch: 6| Step: 4
Training loss: 1.7869833707809448
Validation loss: 2.0913096268971763

Epoch: 6| Step: 5
Training loss: 1.220137357711792
Validation loss: 2.0797181526819863

Epoch: 6| Step: 6
Training loss: 1.5466278791427612
Validation loss: 2.086126665274302

Epoch: 6| Step: 7
Training loss: 2.141559600830078
Validation loss: 2.0537628531455994

Epoch: 6| Step: 8
Training loss: 2.0367095470428467
Validation loss: 2.091971298058828

Epoch: 6| Step: 9
Training loss: 1.8099234104156494
Validation loss: 2.0516889492670694

Epoch: 6| Step: 10
Training loss: 0.7373132109642029
Validation loss: 2.0608301957448325

Epoch: 6| Step: 11
Training loss: 1.8343971967697144
Validation loss: 2.0791919231414795

Epoch: 6| Step: 12
Training loss: 1.8931537866592407
Validation loss: 2.108911911646525

Epoch: 6| Step: 13
Training loss: 1.2466984987258911
Validation loss: 2.0904857913653054

Epoch: 294| Step: 0
Training loss: 1.2279062271118164
Validation loss: 2.1016231775283813

Epoch: 6| Step: 1
Training loss: 1.4963889122009277
Validation loss: 2.097934683163961

Epoch: 6| Step: 2
Training loss: 1.1353150606155396
Validation loss: 2.0406192739804587

Epoch: 6| Step: 3
Training loss: 1.199255347251892
Validation loss: 2.0957261323928833

Epoch: 6| Step: 4
Training loss: 1.210654616355896
Validation loss: 2.0696887572606406

Epoch: 6| Step: 5
Training loss: 1.5366566181182861
Validation loss: 2.047204852104187

Epoch: 6| Step: 6
Training loss: 1.4370481967926025
Validation loss: 2.0985058148701987

Epoch: 6| Step: 7
Training loss: 1.850588321685791
Validation loss: 2.1199371019999185

Epoch: 6| Step: 8
Training loss: 1.8814506530761719
Validation loss: 2.1349701484044394

Epoch: 6| Step: 9
Training loss: 1.2272520065307617
Validation loss: 2.1189571619033813

Epoch: 6| Step: 10
Training loss: 2.2567481994628906
Validation loss: 2.1630570888519287

Epoch: 6| Step: 11
Training loss: 1.2958623170852661
Validation loss: 2.155542333920797

Epoch: 6| Step: 12
Training loss: 2.4176321029663086
Validation loss: 2.127372086048126

Epoch: 6| Step: 13
Training loss: 1.4732718467712402
Validation loss: 2.0997106631596885

Epoch: 295| Step: 0
Training loss: 0.9994431138038635
Validation loss: 2.1114540497461953

Epoch: 6| Step: 1
Training loss: 1.5754388570785522
Validation loss: 2.0686840613683066

Epoch: 6| Step: 2
Training loss: 0.8661954402923584
Validation loss: 2.0447369813919067

Epoch: 6| Step: 3
Training loss: 1.9623910188674927
Validation loss: 2.0660670002301535

Epoch: 6| Step: 4
Training loss: 2.3973512649536133
Validation loss: 2.054423213005066

Epoch: 6| Step: 5
Training loss: 0.9349104166030884
Validation loss: 2.084209700425466

Epoch: 6| Step: 6
Training loss: 1.12367582321167
Validation loss: 2.09301765759786

Epoch: 6| Step: 7
Training loss: 2.296696186065674
Validation loss: 2.0637577374776206

Epoch: 6| Step: 8
Training loss: 2.174222469329834
Validation loss: 2.068984031677246

Epoch: 6| Step: 9
Training loss: 0.9320835471153259
Validation loss: 2.0494505763053894

Epoch: 6| Step: 10
Training loss: 1.5167818069458008
Validation loss: 2.069816211859385

Epoch: 6| Step: 11
Training loss: 1.9529528617858887
Validation loss: 2.066907982031504

Epoch: 6| Step: 12
Training loss: 1.5941667556762695
Validation loss: 2.0699192881584167

Epoch: 6| Step: 13
Training loss: 1.1308493614196777
Validation loss: 2.111067831516266

Epoch: 296| Step: 0
Training loss: 0.9382381439208984
Validation loss: 2.0665687123934426

Epoch: 6| Step: 1
Training loss: 2.6069283485412598
Validation loss: 2.075188080469767

Epoch: 6| Step: 2
Training loss: 2.348555088043213
Validation loss: 2.0877273082733154

Epoch: 6| Step: 3
Training loss: 1.1845815181732178
Validation loss: 2.0985846718152366

Epoch: 6| Step: 4
Training loss: 0.8543580770492554
Validation loss: 2.077672839164734

Epoch: 6| Step: 5
Training loss: 1.2148468494415283
Validation loss: 2.079085409641266

Epoch: 6| Step: 6
Training loss: 1.4478223323822021
Validation loss: 2.069004317124685

Epoch: 6| Step: 7
Training loss: 0.9332003593444824
Validation loss: 2.0854064226150513

Epoch: 6| Step: 8
Training loss: 1.272392749786377
Validation loss: 2.065299113591512

Epoch: 6| Step: 9
Training loss: 1.6873805522918701
Validation loss: 2.0634489258130393

Epoch: 6| Step: 10
Training loss: 1.251878023147583
Validation loss: 2.0519107580184937

Epoch: 6| Step: 11
Training loss: 1.3264992237091064
Validation loss: 2.060575087865194

Epoch: 6| Step: 12
Training loss: 1.7053465843200684
Validation loss: 2.069688359896342

Epoch: 6| Step: 13
Training loss: 2.2873430252075195
Validation loss: 2.0860673983891806

Epoch: 297| Step: 0
Training loss: 2.1329903602600098
Validation loss: 2.092057526111603

Epoch: 6| Step: 1
Training loss: 1.779991626739502
Validation loss: 2.1048314770062766

Epoch: 6| Step: 2
Training loss: 1.8080809116363525
Validation loss: 2.100866357485453

Epoch: 6| Step: 3
Training loss: 0.805565595626831
Validation loss: 2.134289105733236

Epoch: 6| Step: 4
Training loss: 1.409935474395752
Validation loss: 2.12906813621521

Epoch: 6| Step: 5
Training loss: 1.8989039659500122
Validation loss: 2.1515525182088218

Epoch: 6| Step: 6
Training loss: 0.9883096218109131
Validation loss: 2.1575738191604614

Epoch: 6| Step: 7
Training loss: 1.5097622871398926
Validation loss: 2.174333691596985

Epoch: 6| Step: 8
Training loss: 1.9912455081939697
Validation loss: 2.1420576572418213

Epoch: 6| Step: 9
Training loss: 1.593446969985962
Validation loss: 2.083158791065216

Epoch: 6| Step: 10
Training loss: 1.5615417957305908
Validation loss: 2.0857159892717996

Epoch: 6| Step: 11
Training loss: 2.0006353855133057
Validation loss: 2.1042542656262717

Epoch: 6| Step: 12
Training loss: 1.611234426498413
Validation loss: 2.1248738368352256

Epoch: 6| Step: 13
Training loss: 0.827123761177063
Validation loss: 2.1375300685564675

Epoch: 298| Step: 0
Training loss: 1.8553639650344849
Validation loss: 2.141656239827474

Epoch: 6| Step: 1
Training loss: 1.1184992790222168
Validation loss: 2.1265005668004355

Epoch: 6| Step: 2
Training loss: 1.3538564443588257
Validation loss: 2.065954585870107

Epoch: 6| Step: 3
Training loss: 1.5524710416793823
Validation loss: 2.05086350440979

Epoch: 6| Step: 4
Training loss: 2.584510326385498
Validation loss: 2.0782902240753174

Epoch: 6| Step: 5
Training loss: 1.7623169422149658
Validation loss: 2.0871824622154236

Epoch: 6| Step: 6
Training loss: 1.756542444229126
Validation loss: 2.0998372236887612

Epoch: 6| Step: 7
Training loss: 1.7087327241897583
Validation loss: 2.1194913387298584

Epoch: 6| Step: 8
Training loss: 1.4564658403396606
Validation loss: 2.1092196106910706

Epoch: 6| Step: 9
Training loss: 2.277416706085205
Validation loss: 2.108397881189982

Epoch: 6| Step: 10
Training loss: 1.1208772659301758
Validation loss: 2.0884422262509665

Epoch: 6| Step: 11
Training loss: 1.3256785869598389
Validation loss: 2.0837572813034058

Epoch: 6| Step: 12
Training loss: 1.006028413772583
Validation loss: 2.1126403411229453

Epoch: 6| Step: 13
Training loss: 1.8779855966567993
Validation loss: 2.1162999471028647

Epoch: 299| Step: 0
Training loss: 1.2995120286941528
Validation loss: 2.110874275366465

Epoch: 6| Step: 1
Training loss: 2.134674072265625
Validation loss: 2.121571640173594

Epoch: 6| Step: 2
Training loss: 2.577864646911621
Validation loss: 2.1465915044148765

Epoch: 6| Step: 3
Training loss: 1.291126012802124
Validation loss: 2.1025079091389975

Epoch: 6| Step: 4
Training loss: 1.4425556659698486
Validation loss: 2.1256291468938193

Epoch: 6| Step: 5
Training loss: 0.839322566986084
Validation loss: 2.1280741890271506

Epoch: 6| Step: 6
Training loss: 1.2500988245010376
Validation loss: 2.1167412996292114

Epoch: 6| Step: 7
Training loss: 2.097316026687622
Validation loss: 2.130488336086273

Epoch: 6| Step: 8
Training loss: 1.3788257837295532
Validation loss: 2.118665099143982

Epoch: 6| Step: 9
Training loss: 1.7195559740066528
Validation loss: 2.0905529260635376

Epoch: 6| Step: 10
Training loss: 2.1527271270751953
Validation loss: 2.051407217979431

Epoch: 6| Step: 11
Training loss: 1.1181670427322388
Validation loss: 2.075191537539164

Epoch: 6| Step: 12
Training loss: 1.3614516258239746
Validation loss: 2.0505969524383545

Epoch: 6| Step: 13
Training loss: 1.665269136428833
Validation loss: 2.0673787792523703

Epoch: 300| Step: 0
Training loss: 1.200820803642273
Validation loss: 2.056449035803477

Epoch: 6| Step: 1
Training loss: 1.8401843309402466
Validation loss: 2.0723873178164163

Epoch: 6| Step: 2
Training loss: 1.7429392337799072
Validation loss: 2.1106781562169394

Epoch: 6| Step: 3
Training loss: 2.01289701461792
Validation loss: 2.0745057264963784

Epoch: 6| Step: 4
Training loss: 1.678323745727539
Validation loss: 2.0824022690455117

Epoch: 6| Step: 5
Training loss: 1.2484080791473389
Validation loss: 2.081299901008606

Epoch: 6| Step: 6
Training loss: 0.8727191686630249
Validation loss: 2.1045533816019693

Epoch: 6| Step: 7
Training loss: 1.117224097251892
Validation loss: 2.1068470080693564

Epoch: 6| Step: 8
Training loss: 2.198579788208008
Validation loss: 2.0847715735435486

Epoch: 6| Step: 9
Training loss: 0.6486833095550537
Validation loss: 2.111723085244497

Epoch: 6| Step: 10
Training loss: 0.9338718056678772
Validation loss: 2.1090539495150247

Epoch: 6| Step: 11
Training loss: 1.413805603981018
Validation loss: 2.122540990511576

Epoch: 6| Step: 12
Training loss: 2.0103092193603516
Validation loss: 2.104980488618215

Epoch: 6| Step: 13
Training loss: 1.5980687141418457
Validation loss: 2.1321941614151

Epoch: 301| Step: 0
Training loss: 1.0575246810913086
Validation loss: 2.10237322251002

Epoch: 6| Step: 1
Training loss: 1.4415137767791748
Validation loss: 2.117800295352936

Epoch: 6| Step: 2
Training loss: 2.1373658180236816
Validation loss: 2.103492319583893

Epoch: 6| Step: 3
Training loss: 1.3576998710632324
Validation loss: 2.070088883241018

Epoch: 6| Step: 4
Training loss: 1.826237440109253
Validation loss: 2.080180207888285

Epoch: 6| Step: 5
Training loss: 2.088918685913086
Validation loss: 2.09714275598526

Epoch: 6| Step: 6
Training loss: 0.722748339176178
Validation loss: 2.095062037309011

Epoch: 6| Step: 7
Training loss: 1.4905788898468018
Validation loss: 2.075906753540039

Epoch: 6| Step: 8
Training loss: 1.4505510330200195
Validation loss: 2.0859073201815286

Epoch: 6| Step: 9
Training loss: 1.1670801639556885
Validation loss: 2.0670465230941772

Epoch: 6| Step: 10
Training loss: 1.1592965126037598
Validation loss: 2.0518528819084167

Epoch: 6| Step: 11
Training loss: 2.093562602996826
Validation loss: 2.051502744356791

Epoch: 6| Step: 12
Training loss: 1.6348576545715332
Validation loss: 2.04788871606191

Epoch: 6| Step: 13
Training loss: 0.9283395409584045
Validation loss: 2.0823895931243896

Epoch: 302| Step: 0
Training loss: 1.0288536548614502
Validation loss: 2.0659542083740234

Epoch: 6| Step: 1
Training loss: 1.7932379245758057
Validation loss: 2.0757976373036704

Epoch: 6| Step: 2
Training loss: 2.014413833618164
Validation loss: 2.0650266806284585

Epoch: 6| Step: 3
Training loss: 1.2853515148162842
Validation loss: 2.077380915482839

Epoch: 6| Step: 4
Training loss: 1.215880274772644
Validation loss: 2.1468979716300964

Epoch: 6| Step: 5
Training loss: 1.245067834854126
Validation loss: 2.166507283846537

Epoch: 6| Step: 6
Training loss: 1.4135481119155884
Validation loss: 2.125257213910421

Epoch: 6| Step: 7
Training loss: 1.5336577892303467
Validation loss: 2.175864656766256

Epoch: 6| Step: 8
Training loss: 1.8496448993682861
Validation loss: 2.1316301623980203

Epoch: 6| Step: 9
Training loss: 1.1763408184051514
Validation loss: 2.12972621122996

Epoch: 6| Step: 10
Training loss: 1.4865498542785645
Validation loss: 2.1075569788614907

Epoch: 6| Step: 11
Training loss: 1.748459815979004
Validation loss: 2.0962191621462503

Epoch: 6| Step: 12
Training loss: 1.3102943897247314
Validation loss: 2.0936670700709024

Epoch: 6| Step: 13
Training loss: 1.4875069856643677
Validation loss: 2.11285537481308

Epoch: 303| Step: 0
Training loss: 1.6917617321014404
Validation loss: 2.070150295893351

Epoch: 6| Step: 1
Training loss: 1.645184874534607
Validation loss: 2.063861628373464

Epoch: 6| Step: 2
Training loss: 0.9552956819534302
Validation loss: 2.0761290391286216

Epoch: 6| Step: 3
Training loss: 1.2175679206848145
Validation loss: 2.0623744130134583

Epoch: 6| Step: 4
Training loss: 1.331742525100708
Validation loss: 2.1005243261655173

Epoch: 6| Step: 5
Training loss: 1.7756556272506714
Validation loss: 2.0892207821210227

Epoch: 6| Step: 6
Training loss: 1.7388678789138794
Validation loss: 2.1450573801994324

Epoch: 6| Step: 7
Training loss: 2.125917434692383
Validation loss: 2.1947683691978455

Epoch: 6| Step: 8
Training loss: 1.7938883304595947
Validation loss: 2.159677028656006

Epoch: 6| Step: 9
Training loss: 1.005702257156372
Validation loss: 2.1775848269462585

Epoch: 6| Step: 10
Training loss: 1.4856784343719482
Validation loss: 2.1527138153711953

Epoch: 6| Step: 11
Training loss: 0.941286563873291
Validation loss: 2.1009607315063477

Epoch: 6| Step: 12
Training loss: 1.7159515619277954
Validation loss: 2.057313402493795

Epoch: 6| Step: 13
Training loss: 1.3131210803985596
Validation loss: 2.05344025293986

Epoch: 304| Step: 0
Training loss: 1.3673362731933594
Validation loss: 2.0857146183649697

Epoch: 6| Step: 1
Training loss: 1.1609920263290405
Validation loss: 2.060864567756653

Epoch: 6| Step: 2
Training loss: 1.9479777812957764
Validation loss: 2.0659634669621787

Epoch: 6| Step: 3
Training loss: 1.1747546195983887
Validation loss: 2.086564779281616

Epoch: 6| Step: 4
Training loss: 0.9540646076202393
Validation loss: 2.044130722681681

Epoch: 6| Step: 5
Training loss: 1.1039942502975464
Validation loss: 2.0254687865575156

Epoch: 6| Step: 6
Training loss: 1.4778977632522583
Validation loss: 2.0724233786265054

Epoch: 6| Step: 7
Training loss: 2.077083110809326
Validation loss: 2.0650795896848044

Epoch: 6| Step: 8
Training loss: 1.4720569849014282
Validation loss: 2.0806445280710855

Epoch: 6| Step: 9
Training loss: 0.7805492281913757
Validation loss: 2.0464218854904175

Epoch: 6| Step: 10
Training loss: 1.6151633262634277
Validation loss: 2.06344872713089

Epoch: 6| Step: 11
Training loss: 1.4316126108169556
Validation loss: 2.0403455893198648

Epoch: 6| Step: 12
Training loss: 1.199737787246704
Validation loss: 2.0616918206214905

Epoch: 6| Step: 13
Training loss: 2.5208346843719482
Validation loss: 2.0550208489100137

Epoch: 305| Step: 0
Training loss: 1.6047604084014893
Validation loss: 2.087967852751414

Epoch: 6| Step: 1
Training loss: 1.393311858177185
Validation loss: 2.1336572567621865

Epoch: 6| Step: 2
Training loss: 1.8029528856277466
Validation loss: 2.2056485613187156

Epoch: 6| Step: 3
Training loss: 1.2827870845794678
Validation loss: 2.2114769220352173

Epoch: 6| Step: 4
Training loss: 1.1243711709976196
Validation loss: 2.160714864730835

Epoch: 6| Step: 5
Training loss: 1.117841362953186
Validation loss: 2.1618921955426535

Epoch: 6| Step: 6
Training loss: 1.756737470626831
Validation loss: 2.079314927260081

Epoch: 6| Step: 7
Training loss: 1.8749480247497559
Validation loss: 2.113767683506012

Epoch: 6| Step: 8
Training loss: 1.2212176322937012
Validation loss: 2.08469420671463

Epoch: 6| Step: 9
Training loss: 2.222256660461426
Validation loss: 2.134238521258036

Epoch: 6| Step: 10
Training loss: 1.1975122690200806
Validation loss: 2.137762486934662

Epoch: 6| Step: 11
Training loss: 2.8443775177001953
Validation loss: 2.130251109600067

Epoch: 6| Step: 12
Training loss: 1.1996065378189087
Validation loss: 2.0959784189860025

Epoch: 6| Step: 13
Training loss: 0.8461700081825256
Validation loss: 2.037358045578003

Epoch: 306| Step: 0
Training loss: 0.7763704657554626
Validation loss: 2.044828633467356

Epoch: 6| Step: 1
Training loss: 1.9233062267303467
Validation loss: 2.036392549673716

Epoch: 6| Step: 2
Training loss: 1.8189330101013184
Validation loss: 2.0378393729527793

Epoch: 6| Step: 3
Training loss: 1.3026893138885498
Validation loss: 2.079919616381327

Epoch: 6| Step: 4
Training loss: 1.1093835830688477
Validation loss: 2.110549211502075

Epoch: 6| Step: 5
Training loss: 1.1839666366577148
Validation loss: 2.110378543535868

Epoch: 6| Step: 6
Training loss: 1.7905030250549316
Validation loss: 2.1153746048609414

Epoch: 6| Step: 7
Training loss: 1.7224104404449463
Validation loss: 2.0822993516921997

Epoch: 6| Step: 8
Training loss: 1.1396071910858154
Validation loss: 2.0589342514673867

Epoch: 6| Step: 9
Training loss: 0.9462423920631409
Validation loss: 2.028332690397898

Epoch: 6| Step: 10
Training loss: 2.4546594619750977
Validation loss: 2.0316683451334634

Epoch: 6| Step: 11
Training loss: 1.182118535041809
Validation loss: 2.0510775446891785

Epoch: 6| Step: 12
Training loss: 1.783888816833496
Validation loss: 2.0280417005221048

Epoch: 6| Step: 13
Training loss: 1.2791187763214111
Validation loss: 2.039405425389608

Epoch: 307| Step: 0
Training loss: 2.047880172729492
Validation loss: 2.054654121398926

Epoch: 6| Step: 1
Training loss: 1.3191503286361694
Validation loss: 2.056635022163391

Epoch: 6| Step: 2
Training loss: 2.4917590618133545
Validation loss: 2.0656216144561768

Epoch: 6| Step: 3
Training loss: 1.581937551498413
Validation loss: 2.101034184296926

Epoch: 6| Step: 4
Training loss: 1.4284037351608276
Validation loss: 2.125882387161255

Epoch: 6| Step: 5
Training loss: 1.0625509023666382
Validation loss: 2.07276717821757

Epoch: 6| Step: 6
Training loss: 1.5320971012115479
Validation loss: 2.0815903743108115

Epoch: 6| Step: 7
Training loss: 1.314539909362793
Validation loss: 2.0721847812334695

Epoch: 6| Step: 8
Training loss: 1.3054267168045044
Validation loss: 2.0951520601908364

Epoch: 6| Step: 9
Training loss: 1.666172981262207
Validation loss: 2.047783374786377

Epoch: 6| Step: 10
Training loss: 0.5210539102554321
Validation loss: 2.100898881753286

Epoch: 6| Step: 11
Training loss: 0.7311795353889465
Validation loss: 2.091346879800161

Epoch: 6| Step: 12
Training loss: 1.5505019426345825
Validation loss: 2.0910335977872214

Epoch: 6| Step: 13
Training loss: 1.4454185962677002
Validation loss: 2.080751578013102

Epoch: 308| Step: 0
Training loss: 2.1276638507843018
Validation loss: 2.0586469372113547

Epoch: 6| Step: 1
Training loss: 1.8876852989196777
Validation loss: 2.092778444290161

Epoch: 6| Step: 2
Training loss: 1.2682234048843384
Validation loss: 2.0404014190038047

Epoch: 6| Step: 3
Training loss: 1.6065579652786255
Validation loss: 2.057221611340841

Epoch: 6| Step: 4
Training loss: 1.7340691089630127
Validation loss: 2.0902074376742044

Epoch: 6| Step: 5
Training loss: 1.208662986755371
Validation loss: 2.127902547518412

Epoch: 6| Step: 6
Training loss: 1.1622207164764404
Validation loss: 2.1152236064275107

Epoch: 6| Step: 7
Training loss: 1.7315261363983154
Validation loss: 2.0985589027404785

Epoch: 6| Step: 8
Training loss: 1.1944904327392578
Validation loss: 2.109412590662638

Epoch: 6| Step: 9
Training loss: 0.6084071397781372
Validation loss: 2.119024852911631

Epoch: 6| Step: 10
Training loss: 1.6882296800613403
Validation loss: 2.10525381565094

Epoch: 6| Step: 11
Training loss: 1.4036588668823242
Validation loss: 2.101593335469564

Epoch: 6| Step: 12
Training loss: 1.2641102075576782
Validation loss: 2.0845810572306314

Epoch: 6| Step: 13
Training loss: 1.049860954284668
Validation loss: 2.037947336832682

Epoch: 309| Step: 0
Training loss: 1.4180325269699097
Validation loss: 2.082094391187032

Epoch: 6| Step: 1
Training loss: 1.214213252067566
Validation loss: 2.075633446375529

Epoch: 6| Step: 2
Training loss: 1.4648323059082031
Validation loss: 2.064809282620748

Epoch: 6| Step: 3
Training loss: 0.9331533312797546
Validation loss: 2.0527109702428183

Epoch: 6| Step: 4
Training loss: 0.6979457139968872
Validation loss: 2.08770751953125

Epoch: 6| Step: 5
Training loss: 1.8717942237854004
Validation loss: 2.0833444197972617

Epoch: 6| Step: 6
Training loss: 2.2466013431549072
Validation loss: 2.124839425086975

Epoch: 6| Step: 7
Training loss: 1.9002131223678589
Validation loss: 2.1642481287320456

Epoch: 6| Step: 8
Training loss: 2.035085678100586
Validation loss: 2.1633019844690957

Epoch: 6| Step: 9
Training loss: 1.5362625122070312
Validation loss: 2.1766859889030457

Epoch: 6| Step: 10
Training loss: 1.142583966255188
Validation loss: 2.2094277143478394

Epoch: 6| Step: 11
Training loss: 1.8364286422729492
Validation loss: 2.1550720930099487

Epoch: 6| Step: 12
Training loss: 1.2497215270996094
Validation loss: 2.173052986462911

Epoch: 6| Step: 13
Training loss: 1.5331904888153076
Validation loss: 2.1875102718671164

Epoch: 310| Step: 0
Training loss: 2.488403797149658
Validation loss: 2.1446679830551147

Epoch: 6| Step: 1
Training loss: 1.2665445804595947
Validation loss: 2.129430115222931

Epoch: 6| Step: 2
Training loss: 1.5921337604522705
Validation loss: 2.1382519801457724

Epoch: 6| Step: 3
Training loss: 1.185202717781067
Validation loss: 2.114262580871582

Epoch: 6| Step: 4
Training loss: 1.6254560947418213
Validation loss: 2.145230154196421

Epoch: 6| Step: 5
Training loss: 1.974018931388855
Validation loss: 2.0895052552223206

Epoch: 6| Step: 6
Training loss: 1.6738908290863037
Validation loss: 2.146198312441508

Epoch: 6| Step: 7
Training loss: 0.9649356603622437
Validation loss: 2.1252856055895486

Epoch: 6| Step: 8
Training loss: 1.1848838329315186
Validation loss: 2.0618922114372253

Epoch: 6| Step: 9
Training loss: 1.1789679527282715
Validation loss: 2.0233734051386514

Epoch: 6| Step: 10
Training loss: 1.4755809307098389
Validation loss: 2.031492273012797

Epoch: 6| Step: 11
Training loss: 0.9463491439819336
Validation loss: 2.046976149082184

Epoch: 6| Step: 12
Training loss: 1.5221850872039795
Validation loss: 2.062833607196808

Epoch: 6| Step: 13
Training loss: 2.111900806427002
Validation loss: 2.0716623266537986

Epoch: 311| Step: 0
Training loss: 1.5553441047668457
Validation loss: 2.119289000829061

Epoch: 6| Step: 1
Training loss: 0.7722481489181519
Validation loss: 2.1537668307622275

Epoch: 6| Step: 2
Training loss: 1.6599407196044922
Validation loss: 2.1419125398000083

Epoch: 6| Step: 3
Training loss: 2.905757427215576
Validation loss: 2.2054105401039124

Epoch: 6| Step: 4
Training loss: 1.4858499765396118
Validation loss: 2.189751366774241

Epoch: 6| Step: 5
Training loss: 1.1308743953704834
Validation loss: 2.1574729482332864

Epoch: 6| Step: 6
Training loss: 1.7762110233306885
Validation loss: 2.1586079200108848

Epoch: 6| Step: 7
Training loss: 1.2706284523010254
Validation loss: 2.139903505643209

Epoch: 6| Step: 8
Training loss: 1.1780803203582764
Validation loss: 2.112511456012726

Epoch: 6| Step: 9
Training loss: 1.8734287023544312
Validation loss: 2.098823308944702

Epoch: 6| Step: 10
Training loss: 0.5302925109863281
Validation loss: 2.0203914244969687

Epoch: 6| Step: 11
Training loss: 1.674483299255371
Validation loss: 1.9843397339185078

Epoch: 6| Step: 12
Training loss: 1.3761637210845947
Validation loss: 1.9910158514976501

Epoch: 6| Step: 13
Training loss: 1.4408955574035645
Validation loss: 2.034587244192759

Epoch: 312| Step: 0
Training loss: 1.7877371311187744
Validation loss: 2.0308783451716104

Epoch: 6| Step: 1
Training loss: 1.5015807151794434
Validation loss: 2.0077348550160727

Epoch: 6| Step: 2
Training loss: 1.4035589694976807
Validation loss: 2.063247501850128

Epoch: 6| Step: 3
Training loss: 1.0445899963378906
Validation loss: 2.03447691599528

Epoch: 6| Step: 4
Training loss: 1.3871122598648071
Validation loss: 2.032011349995931

Epoch: 6| Step: 5
Training loss: 1.7745611667633057
Validation loss: 2.0866575837135315

Epoch: 6| Step: 6
Training loss: 1.253976821899414
Validation loss: 2.1158204674720764

Epoch: 6| Step: 7
Training loss: 1.4470442533493042
Validation loss: 2.142986257870992

Epoch: 6| Step: 8
Training loss: 1.4764487743377686
Validation loss: 2.160047094027201

Epoch: 6| Step: 9
Training loss: 1.3248684406280518
Validation loss: 2.192042827606201

Epoch: 6| Step: 10
Training loss: 1.583099126815796
Validation loss: 2.160151561101278

Epoch: 6| Step: 11
Training loss: 1.5670511722564697
Validation loss: 2.1550085147221885

Epoch: 6| Step: 12
Training loss: 1.7382107973098755
Validation loss: 2.189071853955587

Epoch: 6| Step: 13
Training loss: 1.2509195804595947
Validation loss: 2.122511327266693

Epoch: 313| Step: 0
Training loss: 0.9903506636619568
Validation loss: 2.132755756378174

Epoch: 6| Step: 1
Training loss: 1.5992469787597656
Validation loss: 2.124727169672648

Epoch: 6| Step: 2
Training loss: 1.9582457542419434
Validation loss: 2.114380180835724

Epoch: 6| Step: 3
Training loss: 1.1446995735168457
Validation loss: 2.0913788278897605

Epoch: 6| Step: 4
Training loss: 2.0074493885040283
Validation loss: 2.082826614379883

Epoch: 6| Step: 5
Training loss: 0.926749587059021
Validation loss: 2.0623724659283957

Epoch: 6| Step: 6
Training loss: 1.422433853149414
Validation loss: 2.066781997680664

Epoch: 6| Step: 7
Training loss: 1.4075720310211182
Validation loss: 2.0589965184529624

Epoch: 6| Step: 8
Training loss: 2.0478525161743164
Validation loss: 2.0471484859784446

Epoch: 6| Step: 9
Training loss: 1.4667179584503174
Validation loss: 2.0933043162027993

Epoch: 6| Step: 10
Training loss: 1.516018033027649
Validation loss: 2.0584729512532554

Epoch: 6| Step: 11
Training loss: 1.4602184295654297
Validation loss: 2.0708975791931152

Epoch: 6| Step: 12
Training loss: 1.1945734024047852
Validation loss: 2.072876195112864

Epoch: 6| Step: 13
Training loss: 1.530083179473877
Validation loss: 2.0573657552401223

Epoch: 314| Step: 0
Training loss: 1.8715182542800903
Validation loss: 2.1048364639282227

Epoch: 6| Step: 1
Training loss: 1.390120506286621
Validation loss: 2.0734196503957114

Epoch: 6| Step: 2
Training loss: 1.5248332023620605
Validation loss: 2.0754306515057883

Epoch: 6| Step: 3
Training loss: 1.495169758796692
Validation loss: 2.0831641952196756

Epoch: 6| Step: 4
Training loss: 1.3966144323349
Validation loss: 2.0667006174723306

Epoch: 6| Step: 5
Training loss: 2.521261692047119
Validation loss: 2.123491664727529

Epoch: 6| Step: 6
Training loss: 0.9753089547157288
Validation loss: 2.09473725159963

Epoch: 6| Step: 7
Training loss: 1.2930532693862915
Validation loss: 2.0871510903040567

Epoch: 6| Step: 8
Training loss: 1.302171230316162
Validation loss: 2.118262072404226

Epoch: 6| Step: 9
Training loss: 1.209693193435669
Validation loss: 2.1117741664250693

Epoch: 6| Step: 10
Training loss: 1.9112608432769775
Validation loss: 2.0851984222730002

Epoch: 6| Step: 11
Training loss: 1.2187063694000244
Validation loss: 2.0703240235646567

Epoch: 6| Step: 12
Training loss: 0.9223458170890808
Validation loss: 2.0580864747365317

Epoch: 6| Step: 13
Training loss: 0.9870184659957886
Validation loss: 2.0578750173250833

Epoch: 315| Step: 0
Training loss: 1.103542447090149
Validation loss: 2.0618598659833274

Epoch: 6| Step: 1
Training loss: 1.3587549924850464
Validation loss: 2.095936894416809

Epoch: 6| Step: 2
Training loss: 1.4372279644012451
Validation loss: 2.119853933652242

Epoch: 6| Step: 3
Training loss: 1.6767842769622803
Validation loss: 2.093009968598684

Epoch: 6| Step: 4
Training loss: 1.275646448135376
Validation loss: 2.068243066469828

Epoch: 6| Step: 5
Training loss: 1.889479637145996
Validation loss: 2.023281912008921

Epoch: 6| Step: 6
Training loss: 1.1209936141967773
Validation loss: 2.03113200267156

Epoch: 6| Step: 7
Training loss: 1.2929480075836182
Validation loss: 2.0323216915130615

Epoch: 6| Step: 8
Training loss: 1.539229393005371
Validation loss: 2.052501897017161

Epoch: 6| Step: 9
Training loss: 2.1167635917663574
Validation loss: 2.0382606585820517

Epoch: 6| Step: 10
Training loss: 1.1390994787216187
Validation loss: 2.0739841063817344

Epoch: 6| Step: 11
Training loss: 1.2243812084197998
Validation loss: 2.094979246457418

Epoch: 6| Step: 12
Training loss: 0.9496134519577026
Validation loss: 2.083403984705607

Epoch: 6| Step: 13
Training loss: 1.141464114189148
Validation loss: 2.0515918930371604

Epoch: 316| Step: 0
Training loss: 1.5400569438934326
Validation loss: 2.102693577607473

Epoch: 6| Step: 1
Training loss: 1.5488603115081787
Validation loss: 2.1221208572387695

Epoch: 6| Step: 2
Training loss: 1.7136051654815674
Validation loss: 2.13554984331131

Epoch: 6| Step: 3
Training loss: 1.3663610219955444
Validation loss: 2.143868108590444

Epoch: 6| Step: 4
Training loss: 1.3039309978485107
Validation loss: 2.149330417315165

Epoch: 6| Step: 5
Training loss: 0.6213258504867554
Validation loss: 2.166005035241445

Epoch: 6| Step: 6
Training loss: 1.4825973510742188
Validation loss: 2.132755935192108

Epoch: 6| Step: 7
Training loss: 0.8446120023727417
Validation loss: 2.118303676446279

Epoch: 6| Step: 8
Training loss: 1.703332543373108
Validation loss: 2.127644161383311

Epoch: 6| Step: 9
Training loss: 1.6295194625854492
Validation loss: 2.1008909145991006

Epoch: 6| Step: 10
Training loss: 1.4636293649673462
Validation loss: 2.0736642678578696

Epoch: 6| Step: 11
Training loss: 1.9881291389465332
Validation loss: 2.1016527811686196

Epoch: 6| Step: 12
Training loss: 0.8308255672454834
Validation loss: 2.075825254122416

Epoch: 6| Step: 13
Training loss: 1.753777265548706
Validation loss: 2.0826232035954795

Epoch: 317| Step: 0
Training loss: 1.4612431526184082
Validation loss: 2.0913491249084473

Epoch: 6| Step: 1
Training loss: 1.2308530807495117
Validation loss: 2.0965100526809692

Epoch: 6| Step: 2
Training loss: 1.156679391860962
Validation loss: 2.094036261240641

Epoch: 6| Step: 3
Training loss: 1.6188602447509766
Validation loss: 2.071244955062866

Epoch: 6| Step: 4
Training loss: 1.748921513557434
Validation loss: 2.034932633241018

Epoch: 6| Step: 5
Training loss: 1.162919282913208
Validation loss: 2.0819289684295654

Epoch: 6| Step: 6
Training loss: 0.7197742462158203
Validation loss: 2.151801268259684

Epoch: 6| Step: 7
Training loss: 1.7064330577850342
Validation loss: 2.156582792599996

Epoch: 6| Step: 8
Training loss: 1.6214336156845093
Validation loss: 2.158541977405548

Epoch: 6| Step: 9
Training loss: 2.1698484420776367
Validation loss: 2.1455073157946267

Epoch: 6| Step: 10
Training loss: 1.2690843343734741
Validation loss: 2.1384459932645163

Epoch: 6| Step: 11
Training loss: 1.264390230178833
Validation loss: 2.1377376119295755

Epoch: 6| Step: 12
Training loss: 0.9205208420753479
Validation loss: 2.1047336657842

Epoch: 6| Step: 13
Training loss: 1.6052625179290771
Validation loss: 2.0772222677866616

Epoch: 318| Step: 0
Training loss: 1.2233641147613525
Validation loss: 2.0658781925837197

Epoch: 6| Step: 1
Training loss: 1.1353652477264404
Validation loss: 2.0590924620628357

Epoch: 6| Step: 2
Training loss: 1.3690881729125977
Validation loss: 2.0583436687787375

Epoch: 6| Step: 3
Training loss: 1.0090560913085938
Validation loss: 2.0636326471964517

Epoch: 6| Step: 4
Training loss: 1.7349587678909302
Validation loss: 2.085920770963033

Epoch: 6| Step: 5
Training loss: 1.5735337734222412
Validation loss: 2.096739967664083

Epoch: 6| Step: 6
Training loss: 1.502178430557251
Validation loss: 2.117649952570597

Epoch: 6| Step: 7
Training loss: 1.5785518884658813
Validation loss: 2.152651031812032

Epoch: 6| Step: 8
Training loss: 1.6655097007751465
Validation loss: 2.161068081855774

Epoch: 6| Step: 9
Training loss: 1.4658136367797852
Validation loss: 2.174512565135956

Epoch: 6| Step: 10
Training loss: 1.1726690530776978
Validation loss: 2.159717599550883

Epoch: 6| Step: 11
Training loss: 1.652965784072876
Validation loss: 2.1955296794573465

Epoch: 6| Step: 12
Training loss: 1.913488745689392
Validation loss: 2.202018678188324

Epoch: 6| Step: 13
Training loss: 0.8759278059005737
Validation loss: 2.1424840887387595

Epoch: 319| Step: 0
Training loss: 1.081039309501648
Validation loss: 2.111359159151713

Epoch: 6| Step: 1
Training loss: 1.3830575942993164
Validation loss: 2.090139091014862

Epoch: 6| Step: 2
Training loss: 1.4011187553405762
Validation loss: 2.097581148147583

Epoch: 6| Step: 3
Training loss: 1.2943379878997803
Validation loss: 2.0997204979260764

Epoch: 6| Step: 4
Training loss: 1.2117054462432861
Validation loss: 2.086461285750071

Epoch: 6| Step: 5
Training loss: 1.3302911520004272
Validation loss: 2.1033178567886353

Epoch: 6| Step: 6
Training loss: 1.110195517539978
Validation loss: 2.087099850177765

Epoch: 6| Step: 7
Training loss: 1.9099376201629639
Validation loss: 2.040147066116333

Epoch: 6| Step: 8
Training loss: 1.4464528560638428
Validation loss: 2.0852137406667075

Epoch: 6| Step: 9
Training loss: 1.2115200757980347
Validation loss: 2.134586493174235

Epoch: 6| Step: 10
Training loss: 1.753061056137085
Validation loss: 2.1436654329299927

Epoch: 6| Step: 11
Training loss: 1.487377643585205
Validation loss: 2.120101730028788

Epoch: 6| Step: 12
Training loss: 1.6858453750610352
Validation loss: 2.070106565952301

Epoch: 6| Step: 13
Training loss: 1.2519917488098145
Validation loss: 2.027649402618408

Epoch: 320| Step: 0
Training loss: 1.2302589416503906
Validation loss: 2.0582536458969116

Epoch: 6| Step: 1
Training loss: 1.5943098068237305
Validation loss: 2.015955328941345

Epoch: 6| Step: 2
Training loss: 1.2682907581329346
Validation loss: 2.0540286898612976

Epoch: 6| Step: 3
Training loss: 1.550931692123413
Validation loss: 2.0710490147272744

Epoch: 6| Step: 4
Training loss: 1.5548055171966553
Validation loss: 2.060982127984365

Epoch: 6| Step: 5
Training loss: 1.8917315006256104
Validation loss: 2.140949308872223

Epoch: 6| Step: 6
Training loss: 1.2075406312942505
Validation loss: 2.1150293747584024

Epoch: 6| Step: 7
Training loss: 0.7895304560661316
Validation loss: 2.1167009671529136

Epoch: 6| Step: 8
Training loss: 1.1455681324005127
Validation loss: 2.0837580959002175

Epoch: 6| Step: 9
Training loss: 1.3293673992156982
Validation loss: 2.067212680975596

Epoch: 6| Step: 10
Training loss: 1.2839123010635376
Validation loss: 2.048992117245992

Epoch: 6| Step: 11
Training loss: 0.8889833688735962
Validation loss: 2.062597870826721

Epoch: 6| Step: 12
Training loss: 1.8004752397537231
Validation loss: 2.085481643676758

Epoch: 6| Step: 13
Training loss: 1.7613122463226318
Validation loss: 2.0889720916748047

Epoch: 321| Step: 0
Training loss: 1.4218082427978516
Validation loss: 2.091257949670156

Epoch: 6| Step: 1
Training loss: 2.120047092437744
Validation loss: 2.079401433467865

Epoch: 6| Step: 2
Training loss: 1.0443789958953857
Validation loss: 2.074438472588857

Epoch: 6| Step: 3
Training loss: 1.4161843061447144
Validation loss: 2.0864654978116355

Epoch: 6| Step: 4
Training loss: 1.0596177577972412
Validation loss: 2.123451034228007

Epoch: 6| Step: 5
Training loss: 1.2893590927124023
Validation loss: 2.097837249437968

Epoch: 6| Step: 6
Training loss: 2.0491533279418945
Validation loss: 2.1062488357226052

Epoch: 6| Step: 7
Training loss: 1.5988240242004395
Validation loss: 2.1309622526168823

Epoch: 6| Step: 8
Training loss: 1.3228564262390137
Validation loss: 2.069484055042267

Epoch: 6| Step: 9
Training loss: 1.377961277961731
Validation loss: 2.0946296056111655

Epoch: 6| Step: 10
Training loss: 0.7495755553245544
Validation loss: 2.0977163116137185

Epoch: 6| Step: 11
Training loss: 0.8945384621620178
Validation loss: 2.122692664464315

Epoch: 6| Step: 12
Training loss: 1.603651762008667
Validation loss: 2.0829435189565024

Epoch: 6| Step: 13
Training loss: 1.3816685676574707
Validation loss: 2.1067712903022766

Epoch: 322| Step: 0
Training loss: 1.282771348953247
Validation loss: 2.0554737647374473

Epoch: 6| Step: 1
Training loss: 1.139200210571289
Validation loss: 2.041513899962107

Epoch: 6| Step: 2
Training loss: 1.0794405937194824
Validation loss: 2.0689807136853537

Epoch: 6| Step: 3
Training loss: 1.5465517044067383
Validation loss: 2.0508482654889426

Epoch: 6| Step: 4
Training loss: 1.3328461647033691
Validation loss: 2.049104154109955

Epoch: 6| Step: 5
Training loss: 1.1388757228851318
Validation loss: 2.081656297047933

Epoch: 6| Step: 6
Training loss: 1.5705173015594482
Validation loss: 2.0862170457839966

Epoch: 6| Step: 7
Training loss: 0.5958499312400818
Validation loss: 2.105006535847982

Epoch: 6| Step: 8
Training loss: 1.537581205368042
Validation loss: 2.05548095703125

Epoch: 6| Step: 9
Training loss: 1.9566999673843384
Validation loss: 2.0689815084139505

Epoch: 6| Step: 10
Training loss: 1.1041662693023682
Validation loss: 2.066563626130422

Epoch: 6| Step: 11
Training loss: 1.7063822746276855
Validation loss: 2.0593128403027854

Epoch: 6| Step: 12
Training loss: 1.778932809829712
Validation loss: 2.0174481868743896

Epoch: 6| Step: 13
Training loss: 1.3058719635009766
Validation loss: 2.0232555866241455

Epoch: 323| Step: 0
Training loss: 1.2214319705963135
Validation loss: 2.0445552468299866

Epoch: 6| Step: 1
Training loss: 0.8778208494186401
Validation loss: 2.0647078156471252

Epoch: 6| Step: 2
Training loss: 1.675241470336914
Validation loss: 2.049370765686035

Epoch: 6| Step: 3
Training loss: 1.047489047050476
Validation loss: 2.052912473678589

Epoch: 6| Step: 4
Training loss: 1.4188232421875
Validation loss: 2.094299852848053

Epoch: 6| Step: 5
Training loss: 1.178928017616272
Validation loss: 2.125233987967173

Epoch: 6| Step: 6
Training loss: 1.7807505130767822
Validation loss: 2.093750794728597

Epoch: 6| Step: 7
Training loss: 1.5821945667266846
Validation loss: 2.107979158560435

Epoch: 6| Step: 8
Training loss: 1.4615044593811035
Validation loss: 2.133769392967224

Epoch: 6| Step: 9
Training loss: 1.3422644138336182
Validation loss: 2.103143572807312

Epoch: 6| Step: 10
Training loss: 1.3662464618682861
Validation loss: 2.1206600864728293

Epoch: 6| Step: 11
Training loss: 1.0971195697784424
Validation loss: 2.1127861936887107

Epoch: 6| Step: 12
Training loss: 1.758285403251648
Validation loss: 2.0675453344980874

Epoch: 6| Step: 13
Training loss: 1.2335100173950195
Validation loss: 2.0694018602371216

Epoch: 324| Step: 0
Training loss: 1.3651411533355713
Validation loss: 2.083852767944336

Epoch: 6| Step: 1
Training loss: 1.3506616353988647
Validation loss: 2.0914955536524453

Epoch: 6| Step: 2
Training loss: 1.6963961124420166
Validation loss: 2.0652385155359902

Epoch: 6| Step: 3
Training loss: 1.1852184534072876
Validation loss: 2.068462332089742

Epoch: 6| Step: 4
Training loss: 1.8752892017364502
Validation loss: 2.0528622468312583

Epoch: 6| Step: 5
Training loss: 1.818726658821106
Validation loss: 2.1298677921295166

Epoch: 6| Step: 6
Training loss: 1.2696645259857178
Validation loss: 2.1815288265546164

Epoch: 6| Step: 7
Training loss: 0.9421901106834412
Validation loss: 2.2252474625905356

Epoch: 6| Step: 8
Training loss: 1.8976600170135498
Validation loss: 2.235375146071116

Epoch: 6| Step: 9
Training loss: 1.421958327293396
Validation loss: 2.1862972577412925

Epoch: 6| Step: 10
Training loss: 1.1513407230377197
Validation loss: 2.159961779912313

Epoch: 6| Step: 11
Training loss: 1.0762323141098022
Validation loss: 2.1307239333788552

Epoch: 6| Step: 12
Training loss: 1.4460891485214233
Validation loss: 2.1352832317352295

Epoch: 6| Step: 13
Training loss: 0.8747758269309998
Validation loss: 2.088734964529673

Epoch: 325| Step: 0
Training loss: 0.9951879382133484
Validation loss: 2.074230909347534

Epoch: 6| Step: 1
Training loss: 1.236203908920288
Validation loss: 2.0345258514086404

Epoch: 6| Step: 2
Training loss: 1.6185263395309448
Validation loss: 2.0570693810780845

Epoch: 6| Step: 3
Training loss: 1.7176311016082764
Validation loss: 2.0636929472287497

Epoch: 6| Step: 4
Training loss: 2.1426219940185547
Validation loss: 2.0592771569887796

Epoch: 6| Step: 5
Training loss: 0.9396769404411316
Validation loss: 2.1087911327679953

Epoch: 6| Step: 6
Training loss: 1.6165400743484497
Validation loss: 2.086080769697825

Epoch: 6| Step: 7
Training loss: 1.5635566711425781
Validation loss: 2.108507057030996

Epoch: 6| Step: 8
Training loss: 1.0291593074798584
Validation loss: 2.0515311559041343

Epoch: 6| Step: 9
Training loss: 1.3253962993621826
Validation loss: 2.0742214918136597

Epoch: 6| Step: 10
Training loss: 1.4187853336334229
Validation loss: 2.083750565846761

Epoch: 6| Step: 11
Training loss: 0.8603943586349487
Validation loss: 2.0477768977483115

Epoch: 6| Step: 12
Training loss: 1.4912245273590088
Validation loss: 2.0506579279899597

Epoch: 6| Step: 13
Training loss: 0.8949077129364014
Validation loss: 2.070548673470815

Epoch: 326| Step: 0
Training loss: 1.4895603656768799
Validation loss: 2.09408970673879

Epoch: 6| Step: 1
Training loss: 0.882085382938385
Validation loss: 2.1059515674908957

Epoch: 6| Step: 2
Training loss: 1.44976806640625
Validation loss: 2.12029621998469

Epoch: 6| Step: 3
Training loss: 1.0663613080978394
Validation loss: 2.078162590662638

Epoch: 6| Step: 4
Training loss: 1.474366545677185
Validation loss: 2.0839674870173135

Epoch: 6| Step: 5
Training loss: 1.737663984298706
Validation loss: 2.07313201824824

Epoch: 6| Step: 6
Training loss: 1.371720314025879
Validation loss: 2.09598175684611

Epoch: 6| Step: 7
Training loss: 1.4814245700836182
Validation loss: 2.082814653714498

Epoch: 6| Step: 8
Training loss: 1.1712884902954102
Validation loss: 2.028347452481588

Epoch: 6| Step: 9
Training loss: 2.1108005046844482
Validation loss: 2.0195422172546387

Epoch: 6| Step: 10
Training loss: 1.490728497505188
Validation loss: 2.0139431754748025

Epoch: 6| Step: 11
Training loss: 0.8914546966552734
Validation loss: 2.0396019419034324

Epoch: 6| Step: 12
Training loss: 1.3164746761322021
Validation loss: 2.0224667390187583

Epoch: 6| Step: 13
Training loss: 1.2016888856887817
Validation loss: 2.017817715803782

Epoch: 327| Step: 0
Training loss: 1.3504154682159424
Validation loss: 2.018290936946869

Epoch: 6| Step: 1
Training loss: 1.6721484661102295
Validation loss: 2.057595451672872

Epoch: 6| Step: 2
Training loss: 1.3223042488098145
Validation loss: 2.038853108882904

Epoch: 6| Step: 3
Training loss: 1.1629133224487305
Validation loss: 2.0817720691363015

Epoch: 6| Step: 4
Training loss: 1.3533802032470703
Validation loss: 2.077596445878347

Epoch: 6| Step: 5
Training loss: 1.0609568357467651
Validation loss: 2.127879480520884

Epoch: 6| Step: 6
Training loss: 1.4971177577972412
Validation loss: 2.0883765618006387

Epoch: 6| Step: 7
Training loss: 1.263156533241272
Validation loss: 2.117694834868113

Epoch: 6| Step: 8
Training loss: 1.7673760652542114
Validation loss: 2.0963341196378074

Epoch: 6| Step: 9
Training loss: 1.4821295738220215
Validation loss: 2.094038645426432

Epoch: 6| Step: 10
Training loss: 0.9735155701637268
Validation loss: 2.0928907791773477

Epoch: 6| Step: 11
Training loss: 1.8020906448364258
Validation loss: 2.0914066632588706

Epoch: 6| Step: 12
Training loss: 1.543116569519043
Validation loss: 2.0976024866104126

Epoch: 6| Step: 13
Training loss: 0.8294483423233032
Validation loss: 2.0808878739674888

Epoch: 328| Step: 0
Training loss: 1.4588866233825684
Validation loss: 2.052289287249247

Epoch: 6| Step: 1
Training loss: 1.0329077243804932
Validation loss: 2.0704543193181357

Epoch: 6| Step: 2
Training loss: 1.5172746181488037
Validation loss: 2.083882530530294

Epoch: 6| Step: 3
Training loss: 1.1693708896636963
Validation loss: 2.1172120571136475

Epoch: 6| Step: 4
Training loss: 1.52004075050354
Validation loss: 2.1724582513173423

Epoch: 6| Step: 5
Training loss: 1.520941972732544
Validation loss: 2.241526742776235

Epoch: 6| Step: 6
Training loss: 1.684675931930542
Validation loss: 2.2627522349357605

Epoch: 6| Step: 7
Training loss: 1.3296478986740112
Validation loss: 2.29599799712499

Epoch: 6| Step: 8
Training loss: 1.3729650974273682
Validation loss: 2.199839929739634

Epoch: 6| Step: 9
Training loss: 1.3749157190322876
Validation loss: 2.1556175351142883

Epoch: 6| Step: 10
Training loss: 1.4614458084106445
Validation loss: 2.148743132750193

Epoch: 6| Step: 11
Training loss: 2.519990921020508
Validation loss: 2.191268503665924

Epoch: 6| Step: 12
Training loss: 1.8654532432556152
Validation loss: 2.1969744165738425

Epoch: 6| Step: 13
Training loss: 1.776064395904541
Validation loss: 2.188653747240702

Epoch: 329| Step: 0
Training loss: 2.0975587368011475
Validation loss: 2.179563800493876

Epoch: 6| Step: 1
Training loss: 1.192984938621521
Validation loss: 2.1374310652414956

Epoch: 6| Step: 2
Training loss: 1.2837893962860107
Validation loss: 2.086904207865397

Epoch: 6| Step: 3
Training loss: 1.6251354217529297
Validation loss: 2.0945880810419717

Epoch: 6| Step: 4
Training loss: 1.5094552040100098
Validation loss: 2.1075885891914368

Epoch: 6| Step: 5
Training loss: 1.3917981386184692
Validation loss: 2.141699473063151

Epoch: 6| Step: 6
Training loss: 1.4024379253387451
Validation loss: 2.17950705687205

Epoch: 6| Step: 7
Training loss: 1.8851933479309082
Validation loss: 2.168520907560984

Epoch: 6| Step: 8
Training loss: 1.2754480838775635
Validation loss: 2.1025129556655884

Epoch: 6| Step: 9
Training loss: 1.0258666276931763
Validation loss: 2.135213335355123

Epoch: 6| Step: 10
Training loss: 0.9693876504898071
Validation loss: 2.1437817215919495

Epoch: 6| Step: 11
Training loss: 1.613458275794983
Validation loss: 2.1194844047228494

Epoch: 6| Step: 12
Training loss: 1.1387325525283813
Validation loss: 2.114818036556244

Epoch: 6| Step: 13
Training loss: 1.3989331722259521
Validation loss: 2.1408164302508035

Epoch: 330| Step: 0
Training loss: 1.5191140174865723
Validation loss: 2.146342853705088

Epoch: 6| Step: 1
Training loss: 1.828914999961853
Validation loss: 2.138265589872996

Epoch: 6| Step: 2
Training loss: 1.040543556213379
Validation loss: 2.159830411275228

Epoch: 6| Step: 3
Training loss: 1.2650809288024902
Validation loss: 2.127634346485138

Epoch: 6| Step: 4
Training loss: 1.146080493927002
Validation loss: 2.130306084950765

Epoch: 6| Step: 5
Training loss: 1.0489516258239746
Validation loss: 2.084789792696635

Epoch: 6| Step: 6
Training loss: 1.6624321937561035
Validation loss: 2.06736954053243

Epoch: 6| Step: 7
Training loss: 1.7606925964355469
Validation loss: 2.0813387632369995

Epoch: 6| Step: 8
Training loss: 2.037257194519043
Validation loss: 2.1169089476267495

Epoch: 6| Step: 9
Training loss: 1.2271567583084106
Validation loss: 2.0826685031255088

Epoch: 6| Step: 10
Training loss: 0.9092395901679993
Validation loss: 2.0918057362238565

Epoch: 6| Step: 11
Training loss: 1.28432035446167
Validation loss: 2.0184154907862344

Epoch: 6| Step: 12
Training loss: 0.6935329437255859
Validation loss: 2.0621332923571267

Epoch: 6| Step: 13
Training loss: 1.4987635612487793
Validation loss: 2.0620569586753845

Epoch: 331| Step: 0
Training loss: 1.4184950590133667
Validation loss: 2.0837093790372214

Epoch: 6| Step: 1
Training loss: 1.422004222869873
Validation loss: 2.0920305252075195

Epoch: 6| Step: 2
Training loss: 1.0662249326705933
Validation loss: 2.1230443120002747

Epoch: 6| Step: 3
Training loss: 1.1858174800872803
Validation loss: 2.098742643992106

Epoch: 6| Step: 4
Training loss: 1.2706778049468994
Validation loss: 2.0867177645365396

Epoch: 6| Step: 5
Training loss: 1.563586950302124
Validation loss: 2.1039545138676963

Epoch: 6| Step: 6
Training loss: 0.9631152153015137
Validation loss: 2.1063466668128967

Epoch: 6| Step: 7
Training loss: 1.259506106376648
Validation loss: 2.097926080226898

Epoch: 6| Step: 8
Training loss: 1.506757140159607
Validation loss: 2.13140078385671

Epoch: 6| Step: 9
Training loss: 1.4649227857589722
Validation loss: 2.130558709303538

Epoch: 6| Step: 10
Training loss: 1.6601941585540771
Validation loss: 2.104643980662028

Epoch: 6| Step: 11
Training loss: 1.3433960676193237
Validation loss: 2.096636394659678

Epoch: 6| Step: 12
Training loss: 0.91607666015625
Validation loss: 2.0932376782099404

Epoch: 6| Step: 13
Training loss: 1.5409209728240967
Validation loss: 2.0392227371533713

Epoch: 332| Step: 0
Training loss: 1.711737871170044
Validation loss: 2.0572500427563987

Epoch: 6| Step: 1
Training loss: 1.6692285537719727
Validation loss: 2.0903831919034324

Epoch: 6| Step: 2
Training loss: 1.1320821046829224
Validation loss: 2.0633764465649924

Epoch: 6| Step: 3
Training loss: 1.2289752960205078
Validation loss: 2.07702229420344

Epoch: 6| Step: 4
Training loss: 1.3072091341018677
Validation loss: 2.096675674120585

Epoch: 6| Step: 5
Training loss: 1.9650905132293701
Validation loss: 2.057261308034261

Epoch: 6| Step: 6
Training loss: 0.9124716520309448
Validation loss: 2.065760393937429

Epoch: 6| Step: 7
Training loss: 1.4639267921447754
Validation loss: 2.0753473242123923

Epoch: 6| Step: 8
Training loss: 1.2187343835830688
Validation loss: 2.0994958678881326

Epoch: 6| Step: 9
Training loss: 1.49700927734375
Validation loss: 2.094862401485443

Epoch: 6| Step: 10
Training loss: 1.2411481142044067
Validation loss: 2.1777329246203103

Epoch: 6| Step: 11
Training loss: 0.9473302960395813
Validation loss: 2.144270340601603

Epoch: 6| Step: 12
Training loss: 0.925172746181488
Validation loss: 2.1257800261179605

Epoch: 6| Step: 13
Training loss: 1.9117085933685303
Validation loss: 2.123769164085388

Epoch: 333| Step: 0
Training loss: 1.0780514478683472
Validation loss: 2.1186017990112305

Epoch: 6| Step: 1
Training loss: 1.394461750984192
Validation loss: 2.082518716653188

Epoch: 6| Step: 2
Training loss: 0.9718760251998901
Validation loss: 2.078193187713623

Epoch: 6| Step: 3
Training loss: 0.7102766633033752
Validation loss: 2.0815193255742392

Epoch: 6| Step: 4
Training loss: 1.8634990453720093
Validation loss: 2.071051994959513

Epoch: 6| Step: 5
Training loss: 1.557720422744751
Validation loss: 2.0839658975601196

Epoch: 6| Step: 6
Training loss: 1.0779539346694946
Validation loss: 2.1088234583536782

Epoch: 6| Step: 7
Training loss: 0.938068151473999
Validation loss: 2.0965757369995117

Epoch: 6| Step: 8
Training loss: 1.639793038368225
Validation loss: 2.152862866719564

Epoch: 6| Step: 9
Training loss: 1.4427530765533447
Validation loss: 2.1370967427889505

Epoch: 6| Step: 10
Training loss: 1.6811717748641968
Validation loss: 2.1599511901537576

Epoch: 6| Step: 11
Training loss: 1.637080430984497
Validation loss: 2.124381105105082

Epoch: 6| Step: 12
Training loss: 0.9588956832885742
Validation loss: 2.1592219273249307

Epoch: 6| Step: 13
Training loss: 1.5706255435943604
Validation loss: 2.117332855860392

Epoch: 334| Step: 0
Training loss: 1.0489856004714966
Validation loss: 2.1287887493769326

Epoch: 6| Step: 1
Training loss: 0.9305603504180908
Validation loss: 2.0764070550600686

Epoch: 6| Step: 2
Training loss: 1.0391449928283691
Validation loss: 2.0790127913157144

Epoch: 6| Step: 3
Training loss: 1.1184022426605225
Validation loss: 2.092541535695394

Epoch: 6| Step: 4
Training loss: 1.6474647521972656
Validation loss: 2.05152436097463

Epoch: 6| Step: 5
Training loss: 1.231669306755066
Validation loss: 2.08769424756368

Epoch: 6| Step: 6
Training loss: 1.6637494564056396
Validation loss: 2.0644147793451944

Epoch: 6| Step: 7
Training loss: 0.4648974537849426
Validation loss: 2.1046811938285828

Epoch: 6| Step: 8
Training loss: 1.1403172016143799
Validation loss: 2.0618519385655723

Epoch: 6| Step: 9
Training loss: 1.6899524927139282
Validation loss: 2.0692456563313804

Epoch: 6| Step: 10
Training loss: 1.4046070575714111
Validation loss: 2.057095527648926

Epoch: 6| Step: 11
Training loss: 2.0907299518585205
Validation loss: 2.098801553249359

Epoch: 6| Step: 12
Training loss: 1.4143544435501099
Validation loss: 2.0435203313827515

Epoch: 6| Step: 13
Training loss: 1.1915422677993774
Validation loss: 2.1106231411298118

Epoch: 335| Step: 0
Training loss: 1.3520488739013672
Validation loss: 2.137496769428253

Epoch: 6| Step: 1
Training loss: 0.8812006711959839
Validation loss: 2.101605792840322

Epoch: 6| Step: 2
Training loss: 1.1489031314849854
Validation loss: 2.1744277278582254

Epoch: 6| Step: 3
Training loss: 1.5666840076446533
Validation loss: 2.1627642114957175

Epoch: 6| Step: 4
Training loss: 1.17180597782135
Validation loss: 2.175553282101949

Epoch: 6| Step: 5
Training loss: 0.6362572908401489
Validation loss: 2.1405144929885864

Epoch: 6| Step: 6
Training loss: 1.6407890319824219
Validation loss: 2.09416933854421

Epoch: 6| Step: 7
Training loss: 1.6253182888031006
Validation loss: 2.1263780196507773

Epoch: 6| Step: 8
Training loss: 1.0757704973220825
Validation loss: 2.0980621178944907

Epoch: 6| Step: 9
Training loss: 1.1918617486953735
Validation loss: 2.1482519110043845

Epoch: 6| Step: 10
Training loss: 1.324404001235962
Validation loss: 2.1549825270970664

Epoch: 6| Step: 11
Training loss: 1.992173194885254
Validation loss: 2.1245288848876953

Epoch: 6| Step: 12
Training loss: 1.4692349433898926
Validation loss: 2.106971502304077

Epoch: 6| Step: 13
Training loss: 1.6862390041351318
Validation loss: 2.1089913646380105

Epoch: 336| Step: 0
Training loss: 0.9674728512763977
Validation loss: 2.117626368999481

Epoch: 6| Step: 1
Training loss: 1.2886428833007812
Validation loss: 2.0909499128659568

Epoch: 6| Step: 2
Training loss: 1.4686607122421265
Validation loss: 2.082980195681254

Epoch: 6| Step: 3
Training loss: 1.182330846786499
Validation loss: 2.072190503279368

Epoch: 6| Step: 4
Training loss: 1.6689754724502563
Validation loss: 2.1151969830195108

Epoch: 6| Step: 5
Training loss: 1.3685355186462402
Validation loss: 2.003279189268748

Epoch: 6| Step: 6
Training loss: 0.8675826191902161
Validation loss: 2.0359701116879783

Epoch: 6| Step: 7
Training loss: 1.8836250305175781
Validation loss: 2.034783939520518

Epoch: 6| Step: 8
Training loss: 1.6223968267440796
Validation loss: 2.0474786162376404

Epoch: 6| Step: 9
Training loss: 2.000941514968872
Validation loss: 2.0683451890945435

Epoch: 6| Step: 10
Training loss: 0.9976709485054016
Validation loss: 2.0575284361839294

Epoch: 6| Step: 11
Training loss: 1.6141939163208008
Validation loss: 2.0840174555778503

Epoch: 6| Step: 12
Training loss: 1.075423002243042
Validation loss: 2.0799031257629395

Epoch: 6| Step: 13
Training loss: 0.7253354787826538
Validation loss: 2.1621938347816467

Epoch: 337| Step: 0
Training loss: 1.6282081604003906
Validation loss: 2.208481272061666

Epoch: 6| Step: 1
Training loss: 0.7682029008865356
Validation loss: 2.219761371612549

Epoch: 6| Step: 2
Training loss: 1.0622267723083496
Validation loss: 2.194160799185435

Epoch: 6| Step: 3
Training loss: 1.5466724634170532
Validation loss: 2.158306876818339

Epoch: 6| Step: 4
Training loss: 1.5162162780761719
Validation loss: 2.1256228486696878

Epoch: 6| Step: 5
Training loss: 1.381932020187378
Validation loss: 2.135375519593557

Epoch: 6| Step: 6
Training loss: 0.5720650553703308
Validation loss: 2.1141231258710227

Epoch: 6| Step: 7
Training loss: 1.1332297325134277
Validation loss: 2.133431136608124

Epoch: 6| Step: 8
Training loss: 1.368340015411377
Validation loss: 2.0916202465693154

Epoch: 6| Step: 9
Training loss: 1.259087085723877
Validation loss: 2.078816592693329

Epoch: 6| Step: 10
Training loss: 1.1324529647827148
Validation loss: 2.099130074183146

Epoch: 6| Step: 11
Training loss: 2.1410374641418457
Validation loss: 2.12490181128184

Epoch: 6| Step: 12
Training loss: 0.6544083952903748
Validation loss: 2.12678732474645

Epoch: 6| Step: 13
Training loss: 1.8775851726531982
Validation loss: 2.111036539077759

Epoch: 338| Step: 0
Training loss: 0.8873775005340576
Validation loss: 2.105291247367859

Epoch: 6| Step: 1
Training loss: 1.2581905126571655
Validation loss: 2.087059219678243

Epoch: 6| Step: 2
Training loss: 1.195115327835083
Validation loss: 2.0452874104181924

Epoch: 6| Step: 3
Training loss: 1.687633991241455
Validation loss: 2.0912895997365317

Epoch: 6| Step: 4
Training loss: 1.107349157333374
Validation loss: 2.1049387454986572

Epoch: 6| Step: 5
Training loss: 2.5745224952697754
Validation loss: 2.1185745199521384

Epoch: 6| Step: 6
Training loss: 1.1692757606506348
Validation loss: 2.138010303179423

Epoch: 6| Step: 7
Training loss: 1.343815803527832
Validation loss: 2.092235565185547

Epoch: 6| Step: 8
Training loss: 0.9109271764755249
Validation loss: 2.0995111068089805

Epoch: 6| Step: 9
Training loss: 1.1280142068862915
Validation loss: 2.0584146976470947

Epoch: 6| Step: 10
Training loss: 1.7256008386611938
Validation loss: 2.0917078057924905

Epoch: 6| Step: 11
Training loss: 0.8127081394195557
Validation loss: 2.082665582497915

Epoch: 6| Step: 12
Training loss: 0.9037305116653442
Validation loss: 2.1060867309570312

Epoch: 6| Step: 13
Training loss: 0.8394020795822144
Validation loss: 2.0918506185213723

Epoch: 339| Step: 0
Training loss: 0.9877126812934875
Validation loss: 2.0831045905749

Epoch: 6| Step: 1
Training loss: 1.4985638856887817
Validation loss: 2.1195459564526877

Epoch: 6| Step: 2
Training loss: 1.0470404624938965
Validation loss: 2.1421774427096048

Epoch: 6| Step: 3
Training loss: 0.9742332696914673
Validation loss: 2.124547262986501

Epoch: 6| Step: 4
Training loss: 1.0554029941558838
Validation loss: 2.0943980614344277

Epoch: 6| Step: 5
Training loss: 1.711834192276001
Validation loss: 2.1401132146517434

Epoch: 6| Step: 6
Training loss: 1.0162091255187988
Validation loss: 2.077349384625753

Epoch: 6| Step: 7
Training loss: 1.5296149253845215
Validation loss: 2.076980233192444

Epoch: 6| Step: 8
Training loss: 1.3866320848464966
Validation loss: 2.1206564903259277

Epoch: 6| Step: 9
Training loss: 1.7158863544464111
Validation loss: 2.1591875553131104

Epoch: 6| Step: 10
Training loss: 0.6572948098182678
Validation loss: 2.093337913354238

Epoch: 6| Step: 11
Training loss: 1.262451410293579
Validation loss: 2.091203769048055

Epoch: 6| Step: 12
Training loss: 1.3986645936965942
Validation loss: 2.1198981404304504

Epoch: 6| Step: 13
Training loss: 1.4422688484191895
Validation loss: 2.173219700654348

Epoch: 340| Step: 0
Training loss: 1.2765650749206543
Validation loss: 2.1735076904296875

Epoch: 6| Step: 1
Training loss: 1.3295011520385742
Validation loss: 2.209814707438151

Epoch: 6| Step: 2
Training loss: 1.0282353162765503
Validation loss: 2.20322052637736

Epoch: 6| Step: 3
Training loss: 1.972543716430664
Validation loss: 2.1857112646102905

Epoch: 6| Step: 4
Training loss: 1.134268045425415
Validation loss: 2.1904674967130027

Epoch: 6| Step: 5
Training loss: 1.0981037616729736
Validation loss: 2.1286679108937583

Epoch: 6| Step: 6
Training loss: 0.664680540561676
Validation loss: 2.092888832092285

Epoch: 6| Step: 7
Training loss: 1.2523553371429443
Validation loss: 2.1290190617243447

Epoch: 6| Step: 8
Training loss: 1.2625385522842407
Validation loss: 2.1103695233662925

Epoch: 6| Step: 9
Training loss: 1.5636229515075684
Validation loss: 2.1107690930366516

Epoch: 6| Step: 10
Training loss: 1.4112365245819092
Validation loss: 2.0633750557899475

Epoch: 6| Step: 11
Training loss: 1.818251371383667
Validation loss: 2.089156150817871

Epoch: 6| Step: 12
Training loss: 1.3814274072647095
Validation loss: 2.0572776198387146

Epoch: 6| Step: 13
Training loss: 1.2623999118804932
Validation loss: 2.0404725472132363

Epoch: 341| Step: 0
Training loss: 1.31553316116333
Validation loss: 2.0716430942217507

Epoch: 6| Step: 1
Training loss: 1.9524712562561035
Validation loss: 2.1117438872655234

Epoch: 6| Step: 2
Training loss: 1.4653581380844116
Validation loss: 2.0528873006502786

Epoch: 6| Step: 3
Training loss: 1.1078332662582397
Validation loss: 2.0970334808031716

Epoch: 6| Step: 4
Training loss: 0.994483470916748
Validation loss: 2.1195636987686157

Epoch: 6| Step: 5
Training loss: 1.4552650451660156
Validation loss: 2.119967599709829

Epoch: 6| Step: 6
Training loss: 1.4581620693206787
Validation loss: 2.093175987402598

Epoch: 6| Step: 7
Training loss: 1.4116863012313843
Validation loss: 2.107914467652639

Epoch: 6| Step: 8
Training loss: 1.5299406051635742
Validation loss: 2.08230984210968

Epoch: 6| Step: 9
Training loss: 0.991360604763031
Validation loss: 2.059347669283549

Epoch: 6| Step: 10
Training loss: 1.2843043804168701
Validation loss: 2.0455503265062966

Epoch: 6| Step: 11
Training loss: 0.7529866099357605
Validation loss: 2.0724702874819436

Epoch: 6| Step: 12
Training loss: 0.8796011209487915
Validation loss: 2.0378360549608865

Epoch: 6| Step: 13
Training loss: 0.7651575803756714
Validation loss: 2.076902985572815

Epoch: 342| Step: 0
Training loss: 1.0966706275939941
Validation loss: 2.045385221640269

Epoch: 6| Step: 1
Training loss: 1.5273935794830322
Validation loss: 2.0317129095395408

Epoch: 6| Step: 2
Training loss: 1.0622832775115967
Validation loss: 2.063424030939738

Epoch: 6| Step: 3
Training loss: 1.2464042901992798
Validation loss: 2.0512980421384177

Epoch: 6| Step: 4
Training loss: 1.8287336826324463
Validation loss: 2.055148482322693

Epoch: 6| Step: 5
Training loss: 1.2557108402252197
Validation loss: 2.028011739253998

Epoch: 6| Step: 6
Training loss: 1.172142744064331
Validation loss: 2.115184803803762

Epoch: 6| Step: 7
Training loss: 0.7368011474609375
Validation loss: 2.06213649113973

Epoch: 6| Step: 8
Training loss: 1.5498037338256836
Validation loss: 2.0863752563794455

Epoch: 6| Step: 9
Training loss: 1.6033360958099365
Validation loss: 2.0899827678998313

Epoch: 6| Step: 10
Training loss: 1.0469293594360352
Validation loss: 2.0860027074813843

Epoch: 6| Step: 11
Training loss: 1.5393316745758057
Validation loss: 2.1105542182922363

Epoch: 6| Step: 12
Training loss: 1.2109777927398682
Validation loss: 2.131961226463318

Epoch: 6| Step: 13
Training loss: 1.053234338760376
Validation loss: 2.090690275033315

Epoch: 343| Step: 0
Training loss: 0.9199599027633667
Validation loss: 2.0620276927948

Epoch: 6| Step: 1
Training loss: 1.021647334098816
Validation loss: 2.067704419294993

Epoch: 6| Step: 2
Training loss: 1.208249807357788
Validation loss: 2.033930997053782

Epoch: 6| Step: 3
Training loss: 1.4598718881607056
Validation loss: 2.0692195494969687

Epoch: 6| Step: 4
Training loss: 1.1329728364944458
Validation loss: 2.0620537996292114

Epoch: 6| Step: 5
Training loss: 1.7438089847564697
Validation loss: 2.092563569545746

Epoch: 6| Step: 6
Training loss: 1.634063482284546
Validation loss: 2.062356094519297

Epoch: 6| Step: 7
Training loss: 0.9951940774917603
Validation loss: 2.0684384306271872

Epoch: 6| Step: 8
Training loss: 1.666902780532837
Validation loss: 2.0863561431566873

Epoch: 6| Step: 9
Training loss: 1.3012385368347168
Validation loss: 2.0816328724225364

Epoch: 6| Step: 10
Training loss: 1.2635910511016846
Validation loss: 2.120242178440094

Epoch: 6| Step: 11
Training loss: 1.504137635231018
Validation loss: 2.104767402013143

Epoch: 6| Step: 12
Training loss: 1.3300127983093262
Validation loss: 2.1166266004244485

Epoch: 6| Step: 13
Training loss: 0.5710845589637756
Validation loss: 2.1306015650431314

Epoch: 344| Step: 0
Training loss: 1.714526891708374
Validation loss: 2.1745238304138184

Epoch: 6| Step: 1
Training loss: 1.3741974830627441
Validation loss: 2.1528005798657737

Epoch: 6| Step: 2
Training loss: 1.4732964038848877
Validation loss: 2.1766964197158813

Epoch: 6| Step: 3
Training loss: 1.4674391746520996
Validation loss: 2.120522459348043

Epoch: 6| Step: 4
Training loss: 0.9753005504608154
Validation loss: 2.1517204443613687

Epoch: 6| Step: 5
Training loss: 0.7401973605155945
Validation loss: 2.1924574772516885

Epoch: 6| Step: 6
Training loss: 1.6636722087860107
Validation loss: 2.1140860517819724

Epoch: 6| Step: 7
Training loss: 1.3202793598175049
Validation loss: 2.0890709360440574

Epoch: 6| Step: 8
Training loss: 1.2660800218582153
Validation loss: 2.0616749127705893

Epoch: 6| Step: 9
Training loss: 0.9064035415649414
Validation loss: 2.0602226853370667

Epoch: 6| Step: 10
Training loss: 0.8991360068321228
Validation loss: 2.104985992113749

Epoch: 6| Step: 11
Training loss: 1.4468518495559692
Validation loss: 2.071820914745331

Epoch: 6| Step: 12
Training loss: 1.0528666973114014
Validation loss: 2.082084039847056

Epoch: 6| Step: 13
Training loss: 1.8915636539459229
Validation loss: 2.045687715212504

Epoch: 345| Step: 0
Training loss: 1.3740779161453247
Validation loss: 2.0375004212061563

Epoch: 6| Step: 1
Training loss: 1.3292162418365479
Validation loss: 2.0769347151120505

Epoch: 6| Step: 2
Training loss: 1.3004379272460938
Validation loss: 2.1097146471341452

Epoch: 6| Step: 3
Training loss: 0.6928802728652954
Validation loss: 2.1084960301717124

Epoch: 6| Step: 4
Training loss: 1.0305180549621582
Validation loss: 2.114287495613098

Epoch: 6| Step: 5
Training loss: 0.7261210680007935
Validation loss: 2.094723622004191

Epoch: 6| Step: 6
Training loss: 1.5313773155212402
Validation loss: 2.0789769291877747

Epoch: 6| Step: 7
Training loss: 2.0372073650360107
Validation loss: 2.1456321477890015

Epoch: 6| Step: 8
Training loss: 1.0772749185562134
Validation loss: 2.107737183570862

Epoch: 6| Step: 9
Training loss: 1.0954453945159912
Validation loss: 2.1361093322436013

Epoch: 6| Step: 10
Training loss: 0.5842148065567017
Validation loss: 2.1435693502426147

Epoch: 6| Step: 11
Training loss: 2.0068118572235107
Validation loss: 2.1004676620165506

Epoch: 6| Step: 12
Training loss: 1.8980119228363037
Validation loss: 2.1479011376698813

Epoch: 6| Step: 13
Training loss: 0.6699519157409668
Validation loss: 2.1342245737711587

Epoch: 346| Step: 0
Training loss: 1.4822524785995483
Validation loss: 2.0736917654673257

Epoch: 6| Step: 1
Training loss: 0.9007485508918762
Validation loss: 2.07081005970637

Epoch: 6| Step: 2
Training loss: 0.8248027563095093
Validation loss: 2.0325114925702414

Epoch: 6| Step: 3
Training loss: 1.310552954673767
Validation loss: 2.060473680496216

Epoch: 6| Step: 4
Training loss: 1.254775047302246
Validation loss: 2.055113216241201

Epoch: 6| Step: 5
Training loss: 1.093347430229187
Validation loss: 2.0383726159731546

Epoch: 6| Step: 6
Training loss: 1.0501359701156616
Validation loss: 2.0846041440963745

Epoch: 6| Step: 7
Training loss: 1.657120943069458
Validation loss: 2.067898452281952

Epoch: 6| Step: 8
Training loss: 2.1412434577941895
Validation loss: 2.095055957635244

Epoch: 6| Step: 9
Training loss: 1.083571434020996
Validation loss: 2.111340661843618

Epoch: 6| Step: 10
Training loss: 1.0208853483200073
Validation loss: 2.136444548765818

Epoch: 6| Step: 11
Training loss: 1.1841169595718384
Validation loss: 2.1363282799720764

Epoch: 6| Step: 12
Training loss: 1.241190791130066
Validation loss: 2.113109827041626

Epoch: 6| Step: 13
Training loss: 1.2670528888702393
Validation loss: 2.0931679407755532

Epoch: 347| Step: 0
Training loss: 1.0828981399536133
Validation loss: 2.102849841117859

Epoch: 6| Step: 1
Training loss: 1.5027518272399902
Validation loss: 2.0810102621714273

Epoch: 6| Step: 2
Training loss: 1.1246354579925537
Validation loss: 2.0778401295344033

Epoch: 6| Step: 3
Training loss: 0.8102994561195374
Validation loss: 2.08176855246226

Epoch: 6| Step: 4
Training loss: 0.9506127238273621
Validation loss: 2.0777002771695456

Epoch: 6| Step: 5
Training loss: 1.3582442998886108
Validation loss: 2.077928900718689

Epoch: 6| Step: 6
Training loss: 0.7609551548957825
Validation loss: 2.062410910924276

Epoch: 6| Step: 7
Training loss: 1.03413724899292
Validation loss: 2.1208027601242065

Epoch: 6| Step: 8
Training loss: 1.196270227432251
Validation loss: 2.079100728034973

Epoch: 6| Step: 9
Training loss: 1.1233983039855957
Validation loss: 2.129105349381765

Epoch: 6| Step: 10
Training loss: 1.596480131149292
Validation loss: 2.0850081046422324

Epoch: 6| Step: 11
Training loss: 1.4639737606048584
Validation loss: 2.092542747656504

Epoch: 6| Step: 12
Training loss: 2.171152114868164
Validation loss: 2.070740262667338

Epoch: 6| Step: 13
Training loss: 1.0765143632888794
Validation loss: 2.0657105843226113

Epoch: 348| Step: 0
Training loss: 0.5422166585922241
Validation loss: 2.055105964342753

Epoch: 6| Step: 1
Training loss: 1.2523365020751953
Validation loss: 2.077118535836538

Epoch: 6| Step: 2
Training loss: 1.0435950756072998
Validation loss: 2.0739365220069885

Epoch: 6| Step: 3
Training loss: 1.2640502452850342
Validation loss: 2.051089823246002

Epoch: 6| Step: 4
Training loss: 1.0817577838897705
Validation loss: 2.0548146963119507

Epoch: 6| Step: 5
Training loss: 2.3578782081604004
Validation loss: 2.0741452177365622

Epoch: 6| Step: 6
Training loss: 0.6393355131149292
Validation loss: 2.068962653477987

Epoch: 6| Step: 7
Training loss: 1.0638840198516846
Validation loss: 2.0897197127342224

Epoch: 6| Step: 8
Training loss: 1.2620532512664795
Validation loss: 2.052877505620321

Epoch: 6| Step: 9
Training loss: 1.3695487976074219
Validation loss: 2.100781877835592

Epoch: 6| Step: 10
Training loss: 1.7281728982925415
Validation loss: 2.042775551478068

Epoch: 6| Step: 11
Training loss: 0.45468419790267944
Validation loss: 2.014857212702433

Epoch: 6| Step: 12
Training loss: 1.2630600929260254
Validation loss: 2.010541101296743

Epoch: 6| Step: 13
Training loss: 1.5373609066009521
Validation loss: 2.08089949687322

Epoch: 349| Step: 0
Training loss: 1.428396224975586
Validation loss: 2.0544791420300803

Epoch: 6| Step: 1
Training loss: 1.1043732166290283
Validation loss: 2.091582238674164

Epoch: 6| Step: 2
Training loss: 1.660636067390442
Validation loss: 2.0885403156280518

Epoch: 6| Step: 3
Training loss: 1.234283685684204
Validation loss: 2.13176695505778

Epoch: 6| Step: 4
Training loss: 0.765699565410614
Validation loss: 2.059839944044749

Epoch: 6| Step: 5
Training loss: 1.5913448333740234
Validation loss: 2.0981578628222146

Epoch: 6| Step: 6
Training loss: 1.0833611488342285
Validation loss: 2.0808876355489097

Epoch: 6| Step: 7
Training loss: 2.0008456707000732
Validation loss: 2.0960824688275657

Epoch: 6| Step: 8
Training loss: 1.1806776523590088
Validation loss: 2.1057922641436257

Epoch: 6| Step: 9
Training loss: 1.014413595199585
Validation loss: 2.120916505654653

Epoch: 6| Step: 10
Training loss: 1.233903169631958
Validation loss: 2.126782854398092

Epoch: 6| Step: 11
Training loss: 1.0230259895324707
Validation loss: 2.083756387233734

Epoch: 6| Step: 12
Training loss: 1.5325701236724854
Validation loss: 2.038613220055898

Epoch: 6| Step: 13
Training loss: 1.179884672164917
Validation loss: 2.1132609049479165

Epoch: 350| Step: 0
Training loss: 0.8412413597106934
Validation loss: 2.112457553545634

Epoch: 6| Step: 1
Training loss: 1.0627764463424683
Validation loss: 2.1431257724761963

Epoch: 6| Step: 2
Training loss: 0.9837749600410461
Validation loss: 2.149593969186147

Epoch: 6| Step: 3
Training loss: 1.8510277271270752
Validation loss: 2.151696781317393

Epoch: 6| Step: 4
Training loss: 2.374486207962036
Validation loss: 2.108184258143107

Epoch: 6| Step: 5
Training loss: 0.891674280166626
Validation loss: 2.0649207631746926

Epoch: 6| Step: 6
Training loss: 1.5016167163848877
Validation loss: 2.1001035968462625

Epoch: 6| Step: 7
Training loss: 1.0696547031402588
Validation loss: 2.0991405646006265

Epoch: 6| Step: 8
Training loss: 0.8917388319969177
Validation loss: 2.0882638096809387

Epoch: 6| Step: 9
Training loss: 1.0683584213256836
Validation loss: 2.0781718095143638

Epoch: 6| Step: 10
Training loss: 1.503739833831787
Validation loss: 2.0628711581230164

Epoch: 6| Step: 11
Training loss: 0.8955467939376831
Validation loss: 2.0406059424082437

Epoch: 6| Step: 12
Training loss: 1.353719711303711
Validation loss: 2.0064631501833596

Epoch: 6| Step: 13
Training loss: 1.1048309803009033
Validation loss: 2.0529635151227317

Epoch: 351| Step: 0
Training loss: 0.7665327191352844
Validation loss: 2.0511102279027305

Epoch: 6| Step: 1
Training loss: 1.755429744720459
Validation loss: 2.029190957546234

Epoch: 6| Step: 2
Training loss: 0.827670156955719
Validation loss: 2.0509809652964273

Epoch: 6| Step: 3
Training loss: 1.563105583190918
Validation loss: 2.0496173898379006

Epoch: 6| Step: 4
Training loss: 0.8124616742134094
Validation loss: 2.030907909075419

Epoch: 6| Step: 5
Training loss: 1.424717903137207
Validation loss: 2.0131688515345254

Epoch: 6| Step: 6
Training loss: 1.1179232597351074
Validation loss: 2.0379335085550943

Epoch: 6| Step: 7
Training loss: 0.917040228843689
Validation loss: 2.0829633474349976

Epoch: 6| Step: 8
Training loss: 1.2760074138641357
Validation loss: 2.1370261708895364

Epoch: 6| Step: 9
Training loss: 1.680065393447876
Validation loss: 2.1554774244626365

Epoch: 6| Step: 10
Training loss: 0.9806046485900879
Validation loss: 2.1346814235051474

Epoch: 6| Step: 11
Training loss: 2.118854522705078
Validation loss: 2.117303470770518

Epoch: 6| Step: 12
Training loss: 0.8500709533691406
Validation loss: 2.1120723684628806

Epoch: 6| Step: 13
Training loss: 1.6785850524902344
Validation loss: 2.056001345316569

Epoch: 352| Step: 0
Training loss: 0.7480161190032959
Validation loss: 2.114410161972046

Epoch: 6| Step: 1
Training loss: 2.0708112716674805
Validation loss: 2.09059602022171

Epoch: 6| Step: 2
Training loss: 0.9275420308113098
Validation loss: 2.1459874312082925

Epoch: 6| Step: 3
Training loss: 1.7990355491638184
Validation loss: 2.1839353243509927

Epoch: 6| Step: 4
Training loss: 1.2820298671722412
Validation loss: 2.2040383021036782

Epoch: 6| Step: 5
Training loss: 1.2251049280166626
Validation loss: 2.1571054061253867

Epoch: 6| Step: 6
Training loss: 1.2955217361450195
Validation loss: 2.128766119480133

Epoch: 6| Step: 7
Training loss: 1.029173731803894
Validation loss: 2.026363412539164

Epoch: 6| Step: 8
Training loss: 1.8898168802261353
Validation loss: 2.079081118106842

Epoch: 6| Step: 9
Training loss: 1.009386658668518
Validation loss: 2.096066872278849

Epoch: 6| Step: 10
Training loss: 1.0440833568572998
Validation loss: 2.1399830182393393

Epoch: 6| Step: 11
Training loss: 1.436529517173767
Validation loss: 2.1548748215039573

Epoch: 6| Step: 12
Training loss: 2.228731155395508
Validation loss: 2.1835569739341736

Epoch: 6| Step: 13
Training loss: 0.8783413171768188
Validation loss: 2.17023241519928

Epoch: 353| Step: 0
Training loss: 0.8953163623809814
Validation loss: 2.1325217286745706

Epoch: 6| Step: 1
Training loss: 1.401618242263794
Validation loss: 2.152536928653717

Epoch: 6| Step: 2
Training loss: 1.1771514415740967
Validation loss: 2.1253168980280557

Epoch: 6| Step: 3
Training loss: 1.3412821292877197
Validation loss: 2.1953282753626504

Epoch: 6| Step: 4
Training loss: 1.1316264867782593
Validation loss: 2.078132470448812

Epoch: 6| Step: 5
Training loss: 1.3567392826080322
Validation loss: 2.080807308355967

Epoch: 6| Step: 6
Training loss: 0.722644031047821
Validation loss: 2.065912048021952

Epoch: 6| Step: 7
Training loss: 1.2195026874542236
Validation loss: 2.088016708691915

Epoch: 6| Step: 8
Training loss: 1.432726502418518
Validation loss: 2.036359886328379

Epoch: 6| Step: 9
Training loss: 0.7508155107498169
Validation loss: 2.035983761151632

Epoch: 6| Step: 10
Training loss: 0.9959851503372192
Validation loss: 2.064742624759674

Epoch: 6| Step: 11
Training loss: 1.6962465047836304
Validation loss: 2.044911781946818

Epoch: 6| Step: 12
Training loss: 2.203216075897217
Validation loss: 2.070432186126709

Epoch: 6| Step: 13
Training loss: 1.2857332229614258
Validation loss: 2.02047997713089

Epoch: 354| Step: 0
Training loss: 0.7315833568572998
Validation loss: 2.044447402159373

Epoch: 6| Step: 1
Training loss: 1.1572120189666748
Validation loss: 2.0603295962015786

Epoch: 6| Step: 2
Training loss: 1.7539606094360352
Validation loss: 2.0549535751342773

Epoch: 6| Step: 3
Training loss: 1.8758184909820557
Validation loss: 2.0798323154449463

Epoch: 6| Step: 4
Training loss: 1.5021772384643555
Validation loss: 2.128089110056559

Epoch: 6| Step: 5
Training loss: 0.6837881207466125
Validation loss: 2.0666907827059426

Epoch: 6| Step: 6
Training loss: 1.2118401527404785
Validation loss: 2.0625348885854087

Epoch: 6| Step: 7
Training loss: 0.9224610328674316
Validation loss: 2.1416686177253723

Epoch: 6| Step: 8
Training loss: 0.9643141627311707
Validation loss: 2.1167065103848777

Epoch: 6| Step: 9
Training loss: 1.0500730276107788
Validation loss: 2.076589524745941

Epoch: 6| Step: 10
Training loss: 0.5883486866950989
Validation loss: 2.072798808415731

Epoch: 6| Step: 11
Training loss: 1.4870078563690186
Validation loss: 2.080776492754618

Epoch: 6| Step: 12
Training loss: 0.91706383228302
Validation loss: 2.0457427700360618

Epoch: 6| Step: 13
Training loss: 1.7254725694656372
Validation loss: 2.022093971570333

Epoch: 355| Step: 0
Training loss: 0.9824343919754028
Validation loss: 2.052252689997355

Epoch: 6| Step: 1
Training loss: 1.2094343900680542
Validation loss: 2.0449590484301248

Epoch: 6| Step: 2
Training loss: 1.2866544723510742
Validation loss: 2.1020960211753845

Epoch: 6| Step: 3
Training loss: 1.0828505754470825
Validation loss: 2.0790500243504844

Epoch: 6| Step: 4
Training loss: 1.1454352140426636
Validation loss: 2.0849326848983765

Epoch: 6| Step: 5
Training loss: 0.7377544045448303
Validation loss: 2.0926045576731362

Epoch: 6| Step: 6
Training loss: 1.041077971458435
Validation loss: 2.0776077111562095

Epoch: 6| Step: 7
Training loss: 1.7451077699661255
Validation loss: 2.0824201504389444

Epoch: 6| Step: 8
Training loss: 1.094785451889038
Validation loss: 2.070719540119171

Epoch: 6| Step: 9
Training loss: 1.2097892761230469
Validation loss: 2.095519204934438

Epoch: 6| Step: 10
Training loss: 1.2750704288482666
Validation loss: 2.0774863958358765

Epoch: 6| Step: 11
Training loss: 1.0899136066436768
Validation loss: 2.142020066579183

Epoch: 6| Step: 12
Training loss: 1.8962604999542236
Validation loss: 2.109080155690511

Epoch: 6| Step: 13
Training loss: 1.0809705257415771
Validation loss: 2.1219604214032493

Epoch: 356| Step: 0
Training loss: 0.9789098501205444
Validation loss: 2.140250086784363

Epoch: 6| Step: 1
Training loss: 1.7188918590545654
Validation loss: 2.1472273667653403

Epoch: 6| Step: 2
Training loss: 1.5804789066314697
Validation loss: 2.1322482228279114

Epoch: 6| Step: 3
Training loss: 0.8673208951950073
Validation loss: 2.167593022187551

Epoch: 6| Step: 4
Training loss: 0.9073454141616821
Validation loss: 2.1618862549463906

Epoch: 6| Step: 5
Training loss: 1.415912389755249
Validation loss: 2.1679218411445618

Epoch: 6| Step: 6
Training loss: 0.9706166982650757
Validation loss: 2.1275333762168884

Epoch: 6| Step: 7
Training loss: 0.8311148881912231
Validation loss: 2.057296852270762

Epoch: 6| Step: 8
Training loss: 1.126560926437378
Validation loss: 2.0759788354237876

Epoch: 6| Step: 9
Training loss: 1.0228192806243896
Validation loss: 2.0993810892105103

Epoch: 6| Step: 10
Training loss: 1.4017068147659302
Validation loss: 2.091344177722931

Epoch: 6| Step: 11
Training loss: 1.3270587921142578
Validation loss: 2.1046897967656455

Epoch: 6| Step: 12
Training loss: 1.4271082878112793
Validation loss: 2.0991051197052

Epoch: 6| Step: 13
Training loss: 1.0953011512756348
Validation loss: 2.114712874094645

Epoch: 357| Step: 0
Training loss: 1.1372917890548706
Validation loss: 2.0992886225382485

Epoch: 6| Step: 1
Training loss: 1.9031202793121338
Validation loss: 2.08601184686025

Epoch: 6| Step: 2
Training loss: 1.6962523460388184
Validation loss: 2.1055851578712463

Epoch: 6| Step: 3
Training loss: 1.19130277633667
Validation loss: 2.1541734735171

Epoch: 6| Step: 4
Training loss: 1.2362329959869385
Validation loss: 2.2586695353190103

Epoch: 6| Step: 5
Training loss: 1.877570390701294
Validation loss: 2.2588569720586142

Epoch: 6| Step: 6
Training loss: 1.6086398363113403
Validation loss: 2.215455631415049

Epoch: 6| Step: 7
Training loss: 0.9409475326538086
Validation loss: 2.1351011196772256

Epoch: 6| Step: 8
Training loss: 1.5959134101867676
Validation loss: 2.065698722998301

Epoch: 6| Step: 9
Training loss: 1.145236611366272
Validation loss: 2.0569726626078286

Epoch: 6| Step: 10
Training loss: 0.6929547786712646
Validation loss: 2.075989762941996

Epoch: 6| Step: 11
Training loss: 1.0748432874679565
Validation loss: 2.1058345238367715

Epoch: 6| Step: 12
Training loss: 1.1342262029647827
Validation loss: 2.129195292790731

Epoch: 6| Step: 13
Training loss: 1.4175407886505127
Validation loss: 2.138385812441508

Epoch: 358| Step: 0
Training loss: 1.046999216079712
Validation loss: 2.110760589440664

Epoch: 6| Step: 1
Training loss: 1.374120831489563
Validation loss: 2.0772531032562256

Epoch: 6| Step: 2
Training loss: 0.6802394390106201
Validation loss: 2.080762207508087

Epoch: 6| Step: 3
Training loss: 1.2802867889404297
Validation loss: 2.0577314297358194

Epoch: 6| Step: 4
Training loss: 0.7616176009178162
Validation loss: 2.0848729411760965

Epoch: 6| Step: 5
Training loss: 0.8891029357910156
Validation loss: 2.130663593610128

Epoch: 6| Step: 6
Training loss: 1.7343602180480957
Validation loss: 2.1814406514167786

Epoch: 6| Step: 7
Training loss: 1.448927640914917
Validation loss: 2.166676342487335

Epoch: 6| Step: 8
Training loss: 1.6588243246078491
Validation loss: 2.154083569844564

Epoch: 6| Step: 9
Training loss: 1.222620964050293
Validation loss: 2.112747589747111

Epoch: 6| Step: 10
Training loss: 1.0573616027832031
Validation loss: 2.1434775590896606

Epoch: 6| Step: 11
Training loss: 1.6818835735321045
Validation loss: 2.1434975266456604

Epoch: 6| Step: 12
Training loss: 1.743628740310669
Validation loss: 2.08732662598292

Epoch: 6| Step: 13
Training loss: 1.0791552066802979
Validation loss: 2.150719324747721

Epoch: 359| Step: 0
Training loss: 0.9988903403282166
Validation loss: 2.151046574115753

Epoch: 6| Step: 1
Training loss: 1.143917202949524
Validation loss: 2.136444946130117

Epoch: 6| Step: 2
Training loss: 1.0454800128936768
Validation loss: 2.1117953856786094

Epoch: 6| Step: 3
Training loss: 1.1629525423049927
Validation loss: 2.044019341468811

Epoch: 6| Step: 4
Training loss: 0.9929850101470947
Validation loss: 2.0551894505818686

Epoch: 6| Step: 5
Training loss: 0.8560488224029541
Validation loss: 2.105686823527018

Epoch: 6| Step: 6
Training loss: 0.9697310924530029
Validation loss: 2.1237535079320273

Epoch: 6| Step: 7
Training loss: 1.4089930057525635
Validation loss: 2.1664666136105857

Epoch: 6| Step: 8
Training loss: 1.390354871749878
Validation loss: 2.122401793797811

Epoch: 6| Step: 9
Training loss: 1.9283491373062134
Validation loss: 2.1172263423601785

Epoch: 6| Step: 10
Training loss: 1.2705053091049194
Validation loss: 2.1248992681503296

Epoch: 6| Step: 11
Training loss: 0.7641793489456177
Validation loss: 2.099408427874247

Epoch: 6| Step: 12
Training loss: 1.289752721786499
Validation loss: 2.101282020409902

Epoch: 6| Step: 13
Training loss: 1.5353689193725586
Validation loss: 2.1079795757929483

Epoch: 360| Step: 0
Training loss: 1.2580697536468506
Validation loss: 2.0615098675092063

Epoch: 6| Step: 1
Training loss: 1.1395007371902466
Validation loss: 2.10791277885437

Epoch: 6| Step: 2
Training loss: 1.2685542106628418
Validation loss: 2.1071545282999673

Epoch: 6| Step: 3
Training loss: 0.7530399560928345
Validation loss: 2.072276790936788

Epoch: 6| Step: 4
Training loss: 1.4466670751571655
Validation loss: 2.121667206287384

Epoch: 6| Step: 5
Training loss: 0.8348361253738403
Validation loss: 2.065199136734009

Epoch: 6| Step: 6
Training loss: 0.45701074600219727
Validation loss: 2.0708943208058677

Epoch: 6| Step: 7
Training loss: 1.563833236694336
Validation loss: 2.0668118397394815

Epoch: 6| Step: 8
Training loss: 1.1174688339233398
Validation loss: 2.0216596523920694

Epoch: 6| Step: 9
Training loss: 2.065093517303467
Validation loss: 2.0550606846809387

Epoch: 6| Step: 10
Training loss: 1.3071231842041016
Validation loss: 2.0254809657732644

Epoch: 6| Step: 11
Training loss: 0.9723938703536987
Validation loss: 2.0129657983779907

Epoch: 6| Step: 12
Training loss: 1.2097108364105225
Validation loss: 2.0132142901420593

Epoch: 6| Step: 13
Training loss: 0.6592001914978027
Validation loss: 2.062796711921692

Epoch: 361| Step: 0
Training loss: 1.217825174331665
Validation loss: 2.058960735797882

Epoch: 6| Step: 1
Training loss: 1.317122220993042
Validation loss: 2.0564205249150596

Epoch: 6| Step: 2
Training loss: 0.8476342558860779
Validation loss: 2.003655711809794

Epoch: 6| Step: 3
Training loss: 1.1551016569137573
Validation loss: 2.0484042962392173

Epoch: 6| Step: 4
Training loss: 1.2170467376708984
Validation loss: 2.0562587777773538

Epoch: 6| Step: 5
Training loss: 1.6405141353607178
Validation loss: 2.115136762460073

Epoch: 6| Step: 6
Training loss: 0.7623051404953003
Validation loss: 2.1011688907941184

Epoch: 6| Step: 7
Training loss: 1.654768466949463
Validation loss: 2.1322340965270996

Epoch: 6| Step: 8
Training loss: 1.4002059698104858
Validation loss: 2.176087280114492

Epoch: 6| Step: 9
Training loss: 0.8961567878723145
Validation loss: 2.21111007531484

Epoch: 6| Step: 10
Training loss: 0.8390170931816101
Validation loss: 2.223094125588735

Epoch: 6| Step: 11
Training loss: 1.3190662860870361
Validation loss: 2.1479069789250693

Epoch: 6| Step: 12
Training loss: 1.46217942237854
Validation loss: 2.0879612962404885

Epoch: 6| Step: 13
Training loss: 1.5355569124221802
Validation loss: 2.0997142791748047

Epoch: 362| Step: 0
Training loss: 1.5366737842559814
Validation loss: 2.1384089390436807

Epoch: 6| Step: 1
Training loss: 1.1892204284667969
Validation loss: 2.170495311419169

Epoch: 6| Step: 2
Training loss: 2.1336543560028076
Validation loss: 2.2334556182225547

Epoch: 6| Step: 3
Training loss: 1.0532660484313965
Validation loss: 2.189410150051117

Epoch: 6| Step: 4
Training loss: 1.2154886722564697
Validation loss: 2.158416668574015

Epoch: 6| Step: 5
Training loss: 1.41552734375
Validation loss: 2.1587699254353843

Epoch: 6| Step: 6
Training loss: 1.2256640195846558
Validation loss: 2.140066146850586

Epoch: 6| Step: 7
Training loss: 1.235129714012146
Validation loss: 2.135989864667257

Epoch: 6| Step: 8
Training loss: 1.3913406133651733
Validation loss: 2.1396411259969077

Epoch: 6| Step: 9
Training loss: 0.790821373462677
Validation loss: 2.17403644323349

Epoch: 6| Step: 10
Training loss: 1.017961025238037
Validation loss: 2.1707564194997153

Epoch: 6| Step: 11
Training loss: 0.813847541809082
Validation loss: 2.1634692351023355

Epoch: 6| Step: 12
Training loss: 1.4399981498718262
Validation loss: 2.163197875022888

Epoch: 6| Step: 13
Training loss: 1.181903600692749
Validation loss: 2.1768924395243325

Epoch: 363| Step: 0
Training loss: 1.2032434940338135
Validation loss: 2.1476346850395203

Epoch: 6| Step: 1
Training loss: 0.8213354349136353
Validation loss: 2.1285571455955505

Epoch: 6| Step: 2
Training loss: 0.8583990335464478
Validation loss: 2.128834287325541

Epoch: 6| Step: 3
Training loss: 1.621626377105713
Validation loss: 2.0972275932629905

Epoch: 6| Step: 4
Training loss: 1.2932794094085693
Validation loss: 2.1015126705169678

Epoch: 6| Step: 5
Training loss: 0.7196743488311768
Validation loss: 2.0883717934290567

Epoch: 6| Step: 6
Training loss: 1.1281511783599854
Validation loss: 2.058515806992849

Epoch: 6| Step: 7
Training loss: 0.8128316402435303
Validation loss: 2.0629982153574624

Epoch: 6| Step: 8
Training loss: 1.9366720914840698
Validation loss: 2.0681870778401694

Epoch: 6| Step: 9
Training loss: 0.8559180498123169
Validation loss: 2.071071743965149

Epoch: 6| Step: 10
Training loss: 0.931181788444519
Validation loss: 2.094607730706533

Epoch: 6| Step: 11
Training loss: 1.5115337371826172
Validation loss: 2.047099451224009

Epoch: 6| Step: 12
Training loss: 1.1742730140686035
Validation loss: 2.0423291126887

Epoch: 6| Step: 13
Training loss: 1.266100287437439
Validation loss: 2.039811293284098

Epoch: 364| Step: 0
Training loss: 1.3103623390197754
Validation loss: 2.098423659801483

Epoch: 6| Step: 1
Training loss: 0.8612106442451477
Validation loss: 2.1246405839920044

Epoch: 6| Step: 2
Training loss: 2.2947187423706055
Validation loss: 2.1171108881632485

Epoch: 6| Step: 3
Training loss: 1.1241693496704102
Validation loss: 2.140909651915232

Epoch: 6| Step: 4
Training loss: 1.0003520250320435
Validation loss: 2.1191081404685974

Epoch: 6| Step: 5
Training loss: 0.9427676796913147
Validation loss: 2.1101993521054587

Epoch: 6| Step: 6
Training loss: 1.2751526832580566
Validation loss: 2.0842944383621216

Epoch: 6| Step: 7
Training loss: 1.5203309059143066
Validation loss: 2.1718526085217795

Epoch: 6| Step: 8
Training loss: 1.1785284280776978
Validation loss: 2.1228230595588684

Epoch: 6| Step: 9
Training loss: 1.035115361213684
Validation loss: 2.1087748408317566

Epoch: 6| Step: 10
Training loss: 1.1592023372650146
Validation loss: 2.126648227373759

Epoch: 6| Step: 11
Training loss: 0.9366086721420288
Validation loss: 2.115641931692759

Epoch: 6| Step: 12
Training loss: 1.5149725675582886
Validation loss: 2.0897790590922036

Epoch: 6| Step: 13
Training loss: 0.5738551020622253
Validation loss: 2.070168912410736

Epoch: 365| Step: 0
Training loss: 1.2645092010498047
Validation loss: 2.154913345972697

Epoch: 6| Step: 1
Training loss: 0.9084886312484741
Validation loss: 2.1448580622673035

Epoch: 6| Step: 2
Training loss: 1.505479335784912
Validation loss: 2.1487881541252136

Epoch: 6| Step: 3
Training loss: 1.1822142601013184
Validation loss: 2.1124581694602966

Epoch: 6| Step: 4
Training loss: 1.7199063301086426
Validation loss: 2.1394556760787964

Epoch: 6| Step: 5
Training loss: 1.1804990768432617
Validation loss: 2.0891836881637573

Epoch: 6| Step: 6
Training loss: 1.3880118131637573
Validation loss: 2.1026629209518433

Epoch: 6| Step: 7
Training loss: 0.9508119225502014
Validation loss: 2.0992332696914673

Epoch: 6| Step: 8
Training loss: 0.9896107316017151
Validation loss: 2.1087679862976074

Epoch: 6| Step: 9
Training loss: 1.5560836791992188
Validation loss: 2.122554381688436

Epoch: 6| Step: 10
Training loss: 0.9267432689666748
Validation loss: 2.1425892313321433

Epoch: 6| Step: 11
Training loss: 1.2960249185562134
Validation loss: 2.1221527258555093

Epoch: 6| Step: 12
Training loss: 0.6831150054931641
Validation loss: 2.128133316834768

Epoch: 6| Step: 13
Training loss: 1.239920973777771
Validation loss: 2.1062183380126953

Epoch: 366| Step: 0
Training loss: 0.6566429734230042
Validation loss: 2.1148751974105835

Epoch: 6| Step: 1
Training loss: 1.7309068441390991
Validation loss: 2.140314062436422

Epoch: 6| Step: 2
Training loss: 1.6859697103500366
Validation loss: 2.1479347149531045

Epoch: 6| Step: 3
Training loss: 0.8677546381950378
Validation loss: 2.140013496081034

Epoch: 6| Step: 4
Training loss: 1.1123366355895996
Validation loss: 2.162358820438385

Epoch: 6| Step: 5
Training loss: 1.126236081123352
Validation loss: 2.1471071243286133

Epoch: 6| Step: 6
Training loss: 1.5458070039749146
Validation loss: 2.0911013881365457

Epoch: 6| Step: 7
Training loss: 0.4599706530570984
Validation loss: 2.106957217057546

Epoch: 6| Step: 8
Training loss: 1.85140061378479
Validation loss: 2.13011372089386

Epoch: 6| Step: 9
Training loss: 0.9725696444511414
Validation loss: 2.092257340749105

Epoch: 6| Step: 10
Training loss: 1.9533308744430542
Validation loss: 2.13683021068573

Epoch: 6| Step: 11
Training loss: 0.8577337265014648
Validation loss: 2.1102695067723594

Epoch: 6| Step: 12
Training loss: 1.022216558456421
Validation loss: 2.1601935426394143

Epoch: 6| Step: 13
Training loss: 0.7571723461151123
Validation loss: 2.1454577445983887

Epoch: 367| Step: 0
Training loss: 1.5118179321289062
Validation loss: 2.1700873374938965

Epoch: 6| Step: 1
Training loss: 0.7855035066604614
Validation loss: 2.116392989953359

Epoch: 6| Step: 2
Training loss: 1.3371827602386475
Validation loss: 2.095660308996836

Epoch: 6| Step: 3
Training loss: 1.018854022026062
Validation loss: 2.05888565381368

Epoch: 6| Step: 4
Training loss: 0.9741163849830627
Validation loss: 2.0364673733711243

Epoch: 6| Step: 5
Training loss: 1.262845516204834
Validation loss: 2.0313393076260886

Epoch: 6| Step: 6
Training loss: 1.0958166122436523
Validation loss: 2.068898340066274

Epoch: 6| Step: 7
Training loss: 1.1140029430389404
Validation loss: 2.041243056456248

Epoch: 6| Step: 8
Training loss: 1.4450994729995728
Validation loss: 2.0754299561182656

Epoch: 6| Step: 9
Training loss: 0.9347195625305176
Validation loss: 2.094379941622416

Epoch: 6| Step: 10
Training loss: 1.3673133850097656
Validation loss: 2.0619863867759705

Epoch: 6| Step: 11
Training loss: 0.9403691291809082
Validation loss: 2.098905165990194

Epoch: 6| Step: 12
Training loss: 0.9320015907287598
Validation loss: 2.1179151137669883

Epoch: 6| Step: 13
Training loss: 1.8053736686706543
Validation loss: 2.0894505381584167

Epoch: 368| Step: 0
Training loss: 1.3089677095413208
Validation loss: 2.095942656199137

Epoch: 6| Step: 1
Training loss: 0.9894946813583374
Validation loss: 2.1310924688975015

Epoch: 6| Step: 2
Training loss: 0.9644768238067627
Validation loss: 2.1307802398999534

Epoch: 6| Step: 3
Training loss: 0.9884706139564514
Validation loss: 2.0278437534968057

Epoch: 6| Step: 4
Training loss: 1.4438986778259277
Validation loss: 2.043225427468618

Epoch: 6| Step: 5
Training loss: 1.3233059644699097
Validation loss: 2.0349743962287903

Epoch: 6| Step: 6
Training loss: 0.8520783185958862
Validation loss: 2.039050499598185

Epoch: 6| Step: 7
Training loss: 1.4573023319244385
Validation loss: 2.035962541898092

Epoch: 6| Step: 8
Training loss: 0.6414691209793091
Validation loss: 2.0873265862464905

Epoch: 6| Step: 9
Training loss: 0.884171724319458
Validation loss: 2.1000790198644004

Epoch: 6| Step: 10
Training loss: 1.6117125749588013
Validation loss: 2.118643800417582

Epoch: 6| Step: 11
Training loss: 1.3338689804077148
Validation loss: 2.085816820462545

Epoch: 6| Step: 12
Training loss: 1.0879206657409668
Validation loss: 2.1346564888954163

Epoch: 6| Step: 13
Training loss: 1.247968316078186
Validation loss: 2.1175456047058105

Epoch: 369| Step: 0
Training loss: 1.1778498888015747
Validation loss: 2.15299916267395

Epoch: 6| Step: 1
Training loss: 1.0230858325958252
Validation loss: 2.19595867395401

Epoch: 6| Step: 2
Training loss: 1.4024157524108887
Validation loss: 2.192167599995931

Epoch: 6| Step: 3
Training loss: 1.1805604696273804
Validation loss: 2.1377737323443093

Epoch: 6| Step: 4
Training loss: 0.8550888299942017
Validation loss: 2.11547988653183

Epoch: 6| Step: 5
Training loss: 1.621567726135254
Validation loss: 2.111989200115204

Epoch: 6| Step: 6
Training loss: 1.2166459560394287
Validation loss: 2.1227380633354187

Epoch: 6| Step: 7
Training loss: 0.986484169960022
Validation loss: 2.164351145426432

Epoch: 6| Step: 8
Training loss: 1.0148457288742065
Validation loss: 2.1193382143974304

Epoch: 6| Step: 9
Training loss: 0.8915367126464844
Validation loss: 2.124092956384023

Epoch: 6| Step: 10
Training loss: 1.0165562629699707
Validation loss: 2.1812976598739624

Epoch: 6| Step: 11
Training loss: 1.2102817296981812
Validation loss: 2.130927483240763

Epoch: 6| Step: 12
Training loss: 1.1259760856628418
Validation loss: 2.116168737411499

Epoch: 6| Step: 13
Training loss: 1.3036737442016602
Validation loss: 2.1195815801620483

Epoch: 370| Step: 0
Training loss: 1.2281372547149658
Validation loss: 2.18242617448171

Epoch: 6| Step: 1
Training loss: 0.8305900692939758
Validation loss: 2.1640203992525735

Epoch: 6| Step: 2
Training loss: 1.404930830001831
Validation loss: 2.1080663601557412

Epoch: 6| Step: 3
Training loss: 1.5591472387313843
Validation loss: 2.1047730445861816

Epoch: 6| Step: 4
Training loss: 0.8362528085708618
Validation loss: 2.060934821764628

Epoch: 6| Step: 5
Training loss: 0.8810580968856812
Validation loss: 2.080627679824829

Epoch: 6| Step: 6
Training loss: 1.5583183765411377
Validation loss: 2.074371794859568

Epoch: 6| Step: 7
Training loss: 0.8648891448974609
Validation loss: 2.0770314733187356

Epoch: 6| Step: 8
Training loss: 1.1862156391143799
Validation loss: 2.1092469493548074

Epoch: 6| Step: 9
Training loss: 0.6792992353439331
Validation loss: 2.094805379708608

Epoch: 6| Step: 10
Training loss: 0.9360352754592896
Validation loss: 2.0451950232187905

Epoch: 6| Step: 11
Training loss: 1.5205830335617065
Validation loss: 2.021601418654124

Epoch: 6| Step: 12
Training loss: 1.4509129524230957
Validation loss: 2.052725374698639

Epoch: 6| Step: 13
Training loss: 1.1617376804351807
Validation loss: 2.042632579803467

Epoch: 371| Step: 0
Training loss: 1.3245056867599487
Validation loss: 2.082465728123983

Epoch: 6| Step: 1
Training loss: 1.137406587600708
Validation loss: 2.032490531603495

Epoch: 6| Step: 2
Training loss: 1.1343169212341309
Validation loss: 2.0551434755325317

Epoch: 6| Step: 3
Training loss: 1.219861388206482
Validation loss: 2.1011977195739746

Epoch: 6| Step: 4
Training loss: 0.7137169241905212
Validation loss: 2.0867122411727905

Epoch: 6| Step: 5
Training loss: 0.7556922435760498
Validation loss: 2.152307649453481

Epoch: 6| Step: 6
Training loss: 1.3535957336425781
Validation loss: 2.0902737379074097

Epoch: 6| Step: 7
Training loss: 1.304302453994751
Validation loss: 2.1834736267725625

Epoch: 6| Step: 8
Training loss: 1.1427139043807983
Validation loss: 2.167499840259552

Epoch: 6| Step: 9
Training loss: 1.0868403911590576
Validation loss: 2.19073752562205

Epoch: 6| Step: 10
Training loss: 1.5667251348495483
Validation loss: 2.2275213599205017

Epoch: 6| Step: 11
Training loss: 1.2866170406341553
Validation loss: 2.220603585243225

Epoch: 6| Step: 12
Training loss: 1.25703763961792
Validation loss: 2.1879156033198037

Epoch: 6| Step: 13
Training loss: 1.4564683437347412
Validation loss: 2.2235836585362754

Epoch: 372| Step: 0
Training loss: 1.1711560487747192
Validation loss: 2.155999024709066

Epoch: 6| Step: 1
Training loss: 1.2914944887161255
Validation loss: 2.1415547728538513

Epoch: 6| Step: 2
Training loss: 0.9752728343009949
Validation loss: 2.1128563483556113

Epoch: 6| Step: 3
Training loss: 1.7289742231369019
Validation loss: 2.071020940939585

Epoch: 6| Step: 4
Training loss: 1.2535758018493652
Validation loss: 2.0781433979670205

Epoch: 6| Step: 5
Training loss: 0.9797295331954956
Validation loss: 2.0896658500035605

Epoch: 6| Step: 6
Training loss: 1.090161919593811
Validation loss: 2.1349741021792092

Epoch: 6| Step: 7
Training loss: 1.3807899951934814
Validation loss: 2.1280945936838784

Epoch: 6| Step: 8
Training loss: 1.5425074100494385
Validation loss: 2.171182096004486

Epoch: 6| Step: 9
Training loss: 1.3662372827529907
Validation loss: 2.1887886126836142

Epoch: 6| Step: 10
Training loss: 1.3067020177841187
Validation loss: 2.14576788743337

Epoch: 6| Step: 11
Training loss: 1.3890771865844727
Validation loss: 2.1510167717933655

Epoch: 6| Step: 12
Training loss: 0.5732710361480713
Validation loss: 2.1068387031555176

Epoch: 6| Step: 13
Training loss: 1.4785970449447632
Validation loss: 2.152229825655619

Epoch: 373| Step: 0
Training loss: 0.8264526128768921
Validation loss: 2.1419502894083657

Epoch: 6| Step: 1
Training loss: 1.8940361738204956
Validation loss: 2.1890178521474204

Epoch: 6| Step: 2
Training loss: 1.733043909072876
Validation loss: 2.2037609020868936

Epoch: 6| Step: 3
Training loss: 1.205072283744812
Validation loss: 2.2181456685066223

Epoch: 6| Step: 4
Training loss: 1.217993974685669
Validation loss: 2.2266457080841064

Epoch: 6| Step: 5
Training loss: 1.2686649560928345
Validation loss: 2.1967148979504905

Epoch: 6| Step: 6
Training loss: 1.2523194551467896
Validation loss: 2.168392241001129

Epoch: 6| Step: 7
Training loss: 1.1394022703170776
Validation loss: 2.094753623008728

Epoch: 6| Step: 8
Training loss: 0.9809839725494385
Validation loss: 2.1207916140556335

Epoch: 6| Step: 9
Training loss: 0.8817427158355713
Validation loss: 2.1175026098887124

Epoch: 6| Step: 10
Training loss: 1.8938443660736084
Validation loss: 2.1588154633839927

Epoch: 6| Step: 11
Training loss: 1.1130472421646118
Validation loss: 2.200638989607493

Epoch: 6| Step: 12
Training loss: 0.9524726867675781
Validation loss: 2.1506882508595786

Epoch: 6| Step: 13
Training loss: 1.3395495414733887
Validation loss: 2.158304810523987

Epoch: 374| Step: 0
Training loss: 0.5783026814460754
Validation loss: 2.130333582560221

Epoch: 6| Step: 1
Training loss: 0.6899388432502747
Validation loss: 2.11085577805837

Epoch: 6| Step: 2
Training loss: 0.8659098148345947
Validation loss: 2.1079364021619162

Epoch: 6| Step: 3
Training loss: 0.9045184254646301
Validation loss: 2.1353951692581177

Epoch: 6| Step: 4
Training loss: 1.3325865268707275
Validation loss: 2.1306610107421875

Epoch: 6| Step: 5
Training loss: 1.1819393634796143
Validation loss: 2.069818655649821

Epoch: 6| Step: 6
Training loss: 1.2505292892456055
Validation loss: 2.135296662648519

Epoch: 6| Step: 7
Training loss: 0.9699223041534424
Validation loss: 2.0809212923049927

Epoch: 6| Step: 8
Training loss: 1.4381933212280273
Validation loss: 2.066514790058136

Epoch: 6| Step: 9
Training loss: 1.3770725727081299
Validation loss: 2.0520285765329995

Epoch: 6| Step: 10
Training loss: 1.4758598804473877
Validation loss: 2.0676284035046897

Epoch: 6| Step: 11
Training loss: 1.1608548164367676
Validation loss: 2.0960379242897034

Epoch: 6| Step: 12
Training loss: 1.2930011749267578
Validation loss: 2.0587027072906494

Epoch: 6| Step: 13
Training loss: 1.0351544618606567
Validation loss: 2.0995129346847534

Epoch: 375| Step: 0
Training loss: 0.5098490715026855
Validation loss: 2.08979465564092

Epoch: 6| Step: 1
Training loss: 1.380511999130249
Validation loss: 2.058455208937327

Epoch: 6| Step: 2
Training loss: 1.3282344341278076
Validation loss: 2.05516125758489

Epoch: 6| Step: 3
Training loss: 1.2421400547027588
Validation loss: 2.0415659745534263

Epoch: 6| Step: 4
Training loss: 0.6734695434570312
Validation loss: 2.0879988272984824

Epoch: 6| Step: 5
Training loss: 1.196446418762207
Validation loss: 2.0887529651323953

Epoch: 6| Step: 6
Training loss: 1.0735112428665161
Validation loss: 2.071525514125824

Epoch: 6| Step: 7
Training loss: 1.0454434156417847
Validation loss: 2.0558099349339805

Epoch: 6| Step: 8
Training loss: 1.3644424676895142
Validation loss: 2.0670762260754905

Epoch: 6| Step: 9
Training loss: 1.1998565196990967
Validation loss: 2.0633747776349387

Epoch: 6| Step: 10
Training loss: 1.3664183616638184
Validation loss: 2.0316965579986572

Epoch: 6| Step: 11
Training loss: 1.8484870195388794
Validation loss: 2.0895098447799683

Epoch: 6| Step: 12
Training loss: 1.1968752145767212
Validation loss: 2.0802514950434365

Epoch: 6| Step: 13
Training loss: 0.6391340494155884
Validation loss: 2.071177144845327

Epoch: 376| Step: 0
Training loss: 0.8763020038604736
Validation loss: 2.1069941322008767

Epoch: 6| Step: 1
Training loss: 1.2386122941970825
Validation loss: 2.105428993701935

Epoch: 6| Step: 2
Training loss: 0.8814671039581299
Validation loss: 2.125335156917572

Epoch: 6| Step: 3
Training loss: 1.2955632209777832
Validation loss: 2.169654289881388

Epoch: 6| Step: 4
Training loss: 1.4926319122314453
Validation loss: 2.141514837741852

Epoch: 6| Step: 5
Training loss: 1.1193180084228516
Validation loss: 2.1148286859194436

Epoch: 6| Step: 6
Training loss: 1.3277692794799805
Validation loss: 2.100291152795156

Epoch: 6| Step: 7
Training loss: 0.9823006391525269
Validation loss: 2.0957552790641785

Epoch: 6| Step: 8
Training loss: 0.8847095966339111
Validation loss: 2.14264182249705

Epoch: 6| Step: 9
Training loss: 0.8840272426605225
Validation loss: 2.165657083193461

Epoch: 6| Step: 10
Training loss: 1.254626989364624
Validation loss: 2.166583220163981

Epoch: 6| Step: 11
Training loss: 1.3447532653808594
Validation loss: 2.1313828031222024

Epoch: 6| Step: 12
Training loss: 1.366707682609558
Validation loss: 2.1274431347846985

Epoch: 6| Step: 13
Training loss: 1.7488435506820679
Validation loss: 2.1054994662602744

Epoch: 377| Step: 0
Training loss: 1.22955322265625
Validation loss: 2.1339510480562844

Epoch: 6| Step: 1
Training loss: 1.6505643129348755
Validation loss: 2.12520303328832

Epoch: 6| Step: 2
Training loss: 1.9074606895446777
Validation loss: 2.149430990219116

Epoch: 6| Step: 3
Training loss: 1.228104591369629
Validation loss: 2.21462074915568

Epoch: 6| Step: 4
Training loss: 0.9036444425582886
Validation loss: 2.2382781902949014

Epoch: 6| Step: 5
Training loss: 1.0966825485229492
Validation loss: 2.205679953098297

Epoch: 6| Step: 6
Training loss: 1.1816964149475098
Validation loss: 2.1609036723772683

Epoch: 6| Step: 7
Training loss: 0.8482725024223328
Validation loss: 2.0941803455352783

Epoch: 6| Step: 8
Training loss: 0.41769760847091675
Validation loss: 2.0545406142870584

Epoch: 6| Step: 9
Training loss: 1.9670143127441406
Validation loss: 2.0228923757870994

Epoch: 6| Step: 10
Training loss: 1.048646330833435
Validation loss: 2.057597557703654

Epoch: 6| Step: 11
Training loss: 0.9570764303207397
Validation loss: 2.0353498657544455

Epoch: 6| Step: 12
Training loss: 1.2665477991104126
Validation loss: 2.036285936832428

Epoch: 6| Step: 13
Training loss: 0.5361375212669373
Validation loss: 2.0365423560142517

Epoch: 378| Step: 0
Training loss: 0.8928232192993164
Validation loss: 2.0353466868400574

Epoch: 6| Step: 1
Training loss: 1.4130674600601196
Validation loss: 2.022858520348867

Epoch: 6| Step: 2
Training loss: 1.2239899635314941
Validation loss: 2.0558943152427673

Epoch: 6| Step: 3
Training loss: 0.4065319895744324
Validation loss: 2.0560013254483542

Epoch: 6| Step: 4
Training loss: 0.9746043086051941
Validation loss: 2.0697572429974875

Epoch: 6| Step: 5
Training loss: 1.0843665599822998
Validation loss: 2.0653262933095298

Epoch: 6| Step: 6
Training loss: 1.8626124858856201
Validation loss: 2.0776599248250327

Epoch: 6| Step: 7
Training loss: 0.9108969569206238
Validation loss: 2.072407364845276

Epoch: 6| Step: 8
Training loss: 1.2348487377166748
Validation loss: 2.088575998942057

Epoch: 6| Step: 9
Training loss: 0.9923967123031616
Validation loss: 2.0787116289138794

Epoch: 6| Step: 10
Training loss: 1.0938520431518555
Validation loss: 2.0072874228159585

Epoch: 6| Step: 11
Training loss: 1.2565977573394775
Validation loss: 2.044998129208883

Epoch: 6| Step: 12
Training loss: 0.9573231339454651
Validation loss: 2.0683141946792603

Epoch: 6| Step: 13
Training loss: 1.1313769817352295
Validation loss: 2.0663554668426514

Epoch: 379| Step: 0
Training loss: 1.0342326164245605
Validation loss: 2.061169981956482

Epoch: 6| Step: 1
Training loss: 2.154482364654541
Validation loss: 2.0507126649220786

Epoch: 6| Step: 2
Training loss: 1.4901440143585205
Validation loss: 2.0737735629081726

Epoch: 6| Step: 3
Training loss: 1.132610559463501
Validation loss: 2.1077171166737876

Epoch: 6| Step: 4
Training loss: 0.8617618680000305
Validation loss: 2.089039464791616

Epoch: 6| Step: 5
Training loss: 1.702252745628357
Validation loss: 2.1085424224535623

Epoch: 6| Step: 6
Training loss: 0.8790830373764038
Validation loss: 2.138310213883718

Epoch: 6| Step: 7
Training loss: 1.2031575441360474
Validation loss: 2.14861931403478

Epoch: 6| Step: 8
Training loss: 0.8645519614219666
Validation loss: 2.1597502628962197

Epoch: 6| Step: 9
Training loss: 1.0126605033874512
Validation loss: 2.1831493377685547

Epoch: 6| Step: 10
Training loss: 0.9087342023849487
Validation loss: 2.1132213274637857

Epoch: 6| Step: 11
Training loss: 0.815595269203186
Validation loss: 2.0822388927141824

Epoch: 6| Step: 12
Training loss: 1.294188380241394
Validation loss: 2.0744616786638894

Epoch: 6| Step: 13
Training loss: 0.936525285243988
Validation loss: 2.105278273423513

Epoch: 380| Step: 0
Training loss: 0.579620361328125
Validation loss: 2.10900084177653

Epoch: 6| Step: 1
Training loss: 1.3836876153945923
Validation loss: 2.1211591362953186

Epoch: 6| Step: 2
Training loss: 1.475117564201355
Validation loss: 2.15413631995519

Epoch: 6| Step: 3
Training loss: 0.7485991716384888
Validation loss: 2.105861802895864

Epoch: 6| Step: 4
Training loss: 0.7934380769729614
Validation loss: 2.0712905128796897

Epoch: 6| Step: 5
Training loss: 1.1704564094543457
Validation loss: 2.1173000931739807

Epoch: 6| Step: 6
Training loss: 1.2631278038024902
Validation loss: 2.0483417908350625

Epoch: 6| Step: 7
Training loss: 1.2411384582519531
Validation loss: 2.068542261918386

Epoch: 6| Step: 8
Training loss: 1.4985135793685913
Validation loss: 2.127714137236277

Epoch: 6| Step: 9
Training loss: 1.6391860246658325
Validation loss: 2.087685227394104

Epoch: 6| Step: 10
Training loss: 1.341196894645691
Validation loss: 2.133114278316498

Epoch: 6| Step: 11
Training loss: 1.0218563079833984
Validation loss: 2.0938435395558677

Epoch: 6| Step: 12
Training loss: 1.1220695972442627
Validation loss: 2.1453601320584617

Epoch: 6| Step: 13
Training loss: 0.7722939848899841
Validation loss: 2.119343082110087

Epoch: 381| Step: 0
Training loss: 0.8491241931915283
Validation loss: 2.0747225483258567

Epoch: 6| Step: 1
Training loss: 0.7083019614219666
Validation loss: 2.1183403531710305

Epoch: 6| Step: 2
Training loss: 1.0637357234954834
Validation loss: 2.0603566765785217

Epoch: 6| Step: 3
Training loss: 1.2994098663330078
Validation loss: 2.05880077679952

Epoch: 6| Step: 4
Training loss: 1.9184966087341309
Validation loss: 2.0846017400423684

Epoch: 6| Step: 5
Training loss: 0.9998760223388672
Validation loss: 2.063476284344991

Epoch: 6| Step: 6
Training loss: 0.9191425442695618
Validation loss: 2.069482207298279

Epoch: 6| Step: 7
Training loss: 0.759758472442627
Validation loss: 2.050861140092214

Epoch: 6| Step: 8
Training loss: 1.5391324758529663
Validation loss: 2.0723025600115457

Epoch: 6| Step: 9
Training loss: 0.8176929354667664
Validation loss: 2.060452163219452

Epoch: 6| Step: 10
Training loss: 1.5743706226348877
Validation loss: 2.0527674754460654

Epoch: 6| Step: 11
Training loss: 1.5293121337890625
Validation loss: 2.0760172406832376

Epoch: 6| Step: 12
Training loss: 1.019312858581543
Validation loss: 2.075243333975474

Epoch: 6| Step: 13
Training loss: 1.0606865882873535
Validation loss: 2.112162391344706

Epoch: 382| Step: 0
Training loss: 1.800796627998352
Validation loss: 2.079360524813334

Epoch: 6| Step: 1
Training loss: 0.8518462181091309
Validation loss: 2.078046460946401

Epoch: 6| Step: 2
Training loss: 1.6722664833068848
Validation loss: 2.0784348845481873

Epoch: 6| Step: 3
Training loss: 1.0772647857666016
Validation loss: 2.09463898340861

Epoch: 6| Step: 4
Training loss: 1.309680461883545
Validation loss: 2.1026995380719504

Epoch: 6| Step: 5
Training loss: 1.2262499332427979
Validation loss: 2.0900023778279624

Epoch: 6| Step: 6
Training loss: 0.8964760303497314
Validation loss: 2.1378983855247498

Epoch: 6| Step: 7
Training loss: 0.8059890270233154
Validation loss: 2.078491767247518

Epoch: 6| Step: 8
Training loss: 0.8273471593856812
Validation loss: 2.097421944141388

Epoch: 6| Step: 9
Training loss: 1.3017387390136719
Validation loss: 2.0466731588045755

Epoch: 6| Step: 10
Training loss: 0.5856929421424866
Validation loss: 2.0438712437947593

Epoch: 6| Step: 11
Training loss: 0.8923777341842651
Validation loss: 2.0662268002827964

Epoch: 6| Step: 12
Training loss: 0.6585119366645813
Validation loss: 2.029622197151184

Epoch: 6| Step: 13
Training loss: 1.5044572353363037
Validation loss: 2.035771687825521

Epoch: 383| Step: 0
Training loss: 1.4680906534194946
Validation loss: 2.03328667084376

Epoch: 6| Step: 1
Training loss: 1.3586982488632202
Validation loss: 2.046520173549652

Epoch: 6| Step: 2
Training loss: 0.9001105427742004
Validation loss: 2.0591850678126016

Epoch: 6| Step: 3
Training loss: 1.3055648803710938
Validation loss: 2.0432681242624917

Epoch: 6| Step: 4
Training loss: 1.4536784887313843
Validation loss: 2.070525606473287

Epoch: 6| Step: 5
Training loss: 0.9133256673812866
Validation loss: 2.102495312690735

Epoch: 6| Step: 6
Training loss: 0.949529230594635
Validation loss: 2.0717151363690696

Epoch: 6| Step: 7
Training loss: 1.4415098428726196
Validation loss: 2.0831963221232095

Epoch: 6| Step: 8
Training loss: 1.0975767374038696
Validation loss: 2.099517583847046

Epoch: 6| Step: 9
Training loss: 1.0681679248809814
Validation loss: 2.1421284476915994

Epoch: 6| Step: 10
Training loss: 0.8735370635986328
Validation loss: 2.0800964633623757

Epoch: 6| Step: 11
Training loss: 1.229271650314331
Validation loss: 2.099860747655233

Epoch: 6| Step: 12
Training loss: 0.5082221627235413
Validation loss: 2.097590605417887

Epoch: 6| Step: 13
Training loss: 1.0299710035324097
Validation loss: 2.1026376287142434

Epoch: 384| Step: 0
Training loss: 1.5103837251663208
Validation loss: 2.0813432733217874

Epoch: 6| Step: 1
Training loss: 1.1693999767303467
Validation loss: 2.117948293685913

Epoch: 6| Step: 2
Training loss: 1.083549976348877
Validation loss: 2.094017287095388

Epoch: 6| Step: 3
Training loss: 1.3571081161499023
Validation loss: 2.1106122533480325

Epoch: 6| Step: 4
Training loss: 1.132153034210205
Validation loss: 2.081689695517222

Epoch: 6| Step: 5
Training loss: 0.7323071956634521
Validation loss: 2.097415328025818

Epoch: 6| Step: 6
Training loss: 0.804349422454834
Validation loss: 2.1265934705734253

Epoch: 6| Step: 7
Training loss: 1.5098845958709717
Validation loss: 2.0583338141441345

Epoch: 6| Step: 8
Training loss: 0.681187629699707
Validation loss: 2.099086046218872

Epoch: 6| Step: 9
Training loss: 1.0846307277679443
Validation loss: 2.096199691295624

Epoch: 6| Step: 10
Training loss: 0.8837013244628906
Validation loss: 2.0824649135271707

Epoch: 6| Step: 11
Training loss: 1.2082138061523438
Validation loss: 2.0779977242151895

Epoch: 6| Step: 12
Training loss: 0.7335934042930603
Validation loss: 2.089937071005503

Epoch: 6| Step: 13
Training loss: 0.9531604647636414
Validation loss: 2.0961937506993613

Epoch: 385| Step: 0
Training loss: 1.6807818412780762
Validation loss: 2.0827570160230002

Epoch: 6| Step: 1
Training loss: 1.577427625656128
Validation loss: 2.134041746457418

Epoch: 6| Step: 2
Training loss: 1.088347315788269
Validation loss: 2.0882331331570945

Epoch: 6| Step: 3
Training loss: 1.0129952430725098
Validation loss: 2.103160262107849

Epoch: 6| Step: 4
Training loss: 1.0743913650512695
Validation loss: 2.082407514254252

Epoch: 6| Step: 5
Training loss: 1.2903342247009277
Validation loss: 2.0960694750150046

Epoch: 6| Step: 6
Training loss: 1.2608351707458496
Validation loss: 2.102163473765055

Epoch: 6| Step: 7
Training loss: 1.1075801849365234
Validation loss: 2.0898543198903403

Epoch: 6| Step: 8
Training loss: 0.5753980875015259
Validation loss: 2.0924164851506553

Epoch: 6| Step: 9
Training loss: 0.6482088565826416
Validation loss: 2.0618810455004373

Epoch: 6| Step: 10
Training loss: 0.6808260679244995
Validation loss: 2.0442466735839844

Epoch: 6| Step: 11
Training loss: 1.2675869464874268
Validation loss: 2.051371415456136

Epoch: 6| Step: 12
Training loss: 0.9129557609558105
Validation loss: 2.064332584540049

Epoch: 6| Step: 13
Training loss: 0.6597564220428467
Validation loss: 2.040706972281138

Epoch: 386| Step: 0
Training loss: 1.2171590328216553
Validation loss: 2.066176176071167

Epoch: 6| Step: 1
Training loss: 0.8909258842468262
Validation loss: 2.048963169256846

Epoch: 6| Step: 2
Training loss: 1.2727253437042236
Validation loss: 2.058162530263265

Epoch: 6| Step: 3
Training loss: 1.8019750118255615
Validation loss: 2.0882714788118997

Epoch: 6| Step: 4
Training loss: 1.067241907119751
Validation loss: 2.060943841934204

Epoch: 6| Step: 5
Training loss: 1.85739004611969
Validation loss: 2.078549345334371

Epoch: 6| Step: 6
Training loss: 1.0818977355957031
Validation loss: 2.120616137981415

Epoch: 6| Step: 7
Training loss: 0.9339790940284729
Validation loss: 2.1501802802085876

Epoch: 6| Step: 8
Training loss: 0.5185147523880005
Validation loss: 2.151675283908844

Epoch: 6| Step: 9
Training loss: 1.0376667976379395
Validation loss: 2.166984796524048

Epoch: 6| Step: 10
Training loss: 1.0247631072998047
Validation loss: 2.1051385203997293

Epoch: 6| Step: 11
Training loss: 1.71183180809021
Validation loss: 2.094002624352773

Epoch: 6| Step: 12
Training loss: 0.5622429251670837
Validation loss: 2.1004097064336142

Epoch: 6| Step: 13
Training loss: 0.7376947402954102
Validation loss: 2.1392387747764587

Epoch: 387| Step: 0
Training loss: 1.2952946424484253
Validation loss: 2.0993732611338296

Epoch: 6| Step: 1
Training loss: 1.7990200519561768
Validation loss: 2.0807159543037415

Epoch: 6| Step: 2
Training loss: 1.1426575183868408
Validation loss: 2.1195459763209024

Epoch: 6| Step: 3
Training loss: 1.58334481716156
Validation loss: 2.1506556471188865

Epoch: 6| Step: 4
Training loss: 1.553236722946167
Validation loss: 2.1117814580599465

Epoch: 6| Step: 5
Training loss: 0.9195692539215088
Validation loss: 2.132770220438639

Epoch: 6| Step: 6
Training loss: 1.120542049407959
Validation loss: 2.0613067746162415

Epoch: 6| Step: 7
Training loss: 1.0458072423934937
Validation loss: 2.067303160826365

Epoch: 6| Step: 8
Training loss: 0.756384551525116
Validation loss: 2.031393746534983

Epoch: 6| Step: 9
Training loss: 1.6096593141555786
Validation loss: 2.041751980781555

Epoch: 6| Step: 10
Training loss: 0.2963186204433441
Validation loss: 2.095959266026815

Epoch: 6| Step: 11
Training loss: 1.0840375423431396
Validation loss: 2.087901691595713

Epoch: 6| Step: 12
Training loss: 0.8409056663513184
Validation loss: 2.1146464347839355

Epoch: 6| Step: 13
Training loss: 1.051327109336853
Validation loss: 2.1101984779040017

Epoch: 388| Step: 0
Training loss: 0.8881661295890808
Validation loss: 2.0749773184458413

Epoch: 6| Step: 1
Training loss: 0.9732725620269775
Validation loss: 2.098582923412323

Epoch: 6| Step: 2
Training loss: 1.1308021545410156
Validation loss: 2.054570178190867

Epoch: 6| Step: 3
Training loss: 1.0530147552490234
Validation loss: 2.165117065111796

Epoch: 6| Step: 4
Training loss: 1.535351276397705
Validation loss: 2.1576629877090454

Epoch: 6| Step: 5
Training loss: 0.8958802819252014
Validation loss: 2.127408723036448

Epoch: 6| Step: 6
Training loss: 1.131089687347412
Validation loss: 2.174299438794454

Epoch: 6| Step: 7
Training loss: 1.0645017623901367
Validation loss: 2.124231497446696

Epoch: 6| Step: 8
Training loss: 1.0576198101043701
Validation loss: 2.085378428300222

Epoch: 6| Step: 9
Training loss: 0.6819068193435669
Validation loss: 2.1264280875523887

Epoch: 6| Step: 10
Training loss: 1.3649483919143677
Validation loss: 2.1126122872034707

Epoch: 6| Step: 11
Training loss: 0.9753493070602417
Validation loss: 2.1035930514335632

Epoch: 6| Step: 12
Training loss: 1.4837234020233154
Validation loss: 2.044432799021403

Epoch: 6| Step: 13
Training loss: 0.9498522281646729
Validation loss: 2.0843758980433145

Epoch: 389| Step: 0
Training loss: 1.0358433723449707
Validation loss: 2.0754847725232444

Epoch: 6| Step: 1
Training loss: 0.8967077732086182
Validation loss: 2.05965389808019

Epoch: 6| Step: 2
Training loss: 0.7496612668037415
Validation loss: 2.0932193199793496

Epoch: 6| Step: 3
Training loss: 0.986543595790863
Validation loss: 2.1575862765312195

Epoch: 6| Step: 4
Training loss: 0.607804536819458
Validation loss: 2.0681903759638467

Epoch: 6| Step: 5
Training loss: 1.4282643795013428
Validation loss: 2.118569095929464

Epoch: 6| Step: 6
Training loss: 1.2918801307678223
Validation loss: 2.1468287309010825

Epoch: 6| Step: 7
Training loss: 2.0454583168029785
Validation loss: 2.0406241416931152

Epoch: 6| Step: 8
Training loss: 1.4503488540649414
Validation loss: 2.1069111426671348

Epoch: 6| Step: 9
Training loss: 1.217164158821106
Validation loss: 2.0732670029004416

Epoch: 6| Step: 10
Training loss: 0.5514981746673584
Validation loss: 2.0573697288831077

Epoch: 6| Step: 11
Training loss: 1.2448666095733643
Validation loss: 2.0267564256985984

Epoch: 6| Step: 12
Training loss: 0.5753048062324524
Validation loss: 2.058358073234558

Epoch: 6| Step: 13
Training loss: 0.8283628225326538
Validation loss: 2.0873188773790994

Epoch: 390| Step: 0
Training loss: 2.0934133529663086
Validation loss: 2.0672398606936135

Epoch: 6| Step: 1
Training loss: 0.8762611746788025
Validation loss: 2.0465506116549173

Epoch: 6| Step: 2
Training loss: 1.418344497680664
Validation loss: 2.0887442231178284

Epoch: 6| Step: 3
Training loss: 0.8386715054512024
Validation loss: 2.05504709482193

Epoch: 6| Step: 4
Training loss: 1.1956267356872559
Validation loss: 2.1025680700937905

Epoch: 6| Step: 5
Training loss: 0.9342947006225586
Validation loss: 2.105979065100352

Epoch: 6| Step: 6
Training loss: 1.0017598867416382
Validation loss: 2.1203747590382895

Epoch: 6| Step: 7
Training loss: 0.8493216633796692
Validation loss: 2.0633142590522766

Epoch: 6| Step: 8
Training loss: 1.0080056190490723
Validation loss: 2.0629026293754578

Epoch: 6| Step: 9
Training loss: 1.5006749629974365
Validation loss: 2.0076315800348916

Epoch: 6| Step: 10
Training loss: 1.1254384517669678
Validation loss: 2.040768643220266

Epoch: 6| Step: 11
Training loss: 1.0335359573364258
Validation loss: 2.0666192372639975

Epoch: 6| Step: 12
Training loss: 0.7740182876586914
Validation loss: 2.05803515513738

Epoch: 6| Step: 13
Training loss: 0.6204162836074829
Validation loss: 2.085268954435984

Epoch: 391| Step: 0
Training loss: 1.0974946022033691
Validation loss: 2.0940038561820984

Epoch: 6| Step: 1
Training loss: 0.728403627872467
Validation loss: 2.1241188049316406

Epoch: 6| Step: 2
Training loss: 1.2605032920837402
Validation loss: 2.123528301715851

Epoch: 6| Step: 3
Training loss: 0.9254317283630371
Validation loss: 2.1601364811261496

Epoch: 6| Step: 4
Training loss: 0.8263455629348755
Validation loss: 2.14693013827006

Epoch: 6| Step: 5
Training loss: 1.2332137823104858
Validation loss: 2.2000420888264975

Epoch: 6| Step: 6
Training loss: 1.1767497062683105
Validation loss: 2.1889477372169495

Epoch: 6| Step: 7
Training loss: 1.3755362033843994
Validation loss: 2.199700355529785

Epoch: 6| Step: 8
Training loss: 1.2186455726623535
Validation loss: 2.1655425429344177

Epoch: 6| Step: 9
Training loss: 1.315309762954712
Validation loss: 2.0432396133740744

Epoch: 6| Step: 10
Training loss: 0.9282026290893555
Validation loss: 2.050389508406321

Epoch: 6| Step: 11
Training loss: 1.681786060333252
Validation loss: 2.0568235516548157

Epoch: 6| Step: 12
Training loss: 0.8449475765228271
Validation loss: 2.027388552824656

Epoch: 6| Step: 13
Training loss: 1.1943403482437134
Validation loss: 2.0648340781529746

Epoch: 392| Step: 0
Training loss: 1.6928523778915405
Validation loss: 2.086146354675293

Epoch: 6| Step: 1
Training loss: 1.2798163890838623
Validation loss: 2.122632384300232

Epoch: 6| Step: 2
Training loss: 1.2014132738113403
Validation loss: 2.1385860244433084

Epoch: 6| Step: 3
Training loss: 1.2447941303253174
Validation loss: 2.1396509210268655

Epoch: 6| Step: 4
Training loss: 1.5711870193481445
Validation loss: 2.1083850264549255

Epoch: 6| Step: 5
Training loss: 1.1531957387924194
Validation loss: 2.107266445954641

Epoch: 6| Step: 6
Training loss: 1.2715942859649658
Validation loss: 2.1308639645576477

Epoch: 6| Step: 7
Training loss: 1.025563359260559
Validation loss: 2.1762807766596475

Epoch: 6| Step: 8
Training loss: 1.250948429107666
Validation loss: 2.1994686921437583

Epoch: 6| Step: 9
Training loss: 0.7363128066062927
Validation loss: 2.201199014981588

Epoch: 6| Step: 10
Training loss: 0.8353078365325928
Validation loss: 2.181229035059611

Epoch: 6| Step: 11
Training loss: 1.274811863899231
Validation loss: 2.1851768096288047

Epoch: 6| Step: 12
Training loss: 1.2083170413970947
Validation loss: 2.159510870774587

Epoch: 6| Step: 13
Training loss: 0.3703535497188568
Validation loss: 2.110362191994985

Epoch: 393| Step: 0
Training loss: 0.9449353814125061
Validation loss: 2.0852778355280557

Epoch: 6| Step: 1
Training loss: 1.2587785720825195
Validation loss: 2.103795131047567

Epoch: 6| Step: 2
Training loss: 1.167273998260498
Validation loss: 2.1611104011535645

Epoch: 6| Step: 3
Training loss: 1.10603666305542
Validation loss: 2.1950591802597046

Epoch: 6| Step: 4
Training loss: 1.675581932067871
Validation loss: 2.2349940141042075

Epoch: 6| Step: 5
Training loss: 2.2847142219543457
Validation loss: 2.2167776028315225

Epoch: 6| Step: 6
Training loss: 1.720353126525879
Validation loss: 2.198856314023336

Epoch: 6| Step: 7
Training loss: 1.289679765701294
Validation loss: 2.1527723471323648

Epoch: 6| Step: 8
Training loss: 0.6490055918693542
Validation loss: 2.16056360801061

Epoch: 6| Step: 9
Training loss: 0.64686119556427
Validation loss: 2.0827057361602783

Epoch: 6| Step: 10
Training loss: 1.1033861637115479
Validation loss: 2.1202595233917236

Epoch: 6| Step: 11
Training loss: 1.3276857137680054
Validation loss: 2.135973115762075

Epoch: 6| Step: 12
Training loss: 1.599700927734375
Validation loss: 2.187387009461721

Epoch: 6| Step: 13
Training loss: 1.8583757877349854
Validation loss: 2.2830926378568015

Epoch: 394| Step: 0
Training loss: 1.6051265001296997
Validation loss: 2.232948064804077

Epoch: 6| Step: 1
Training loss: 1.6557031869888306
Validation loss: 2.1865479151407876

Epoch: 6| Step: 2
Training loss: 1.3240382671356201
Validation loss: 2.2052776217460632

Epoch: 6| Step: 3
Training loss: 1.056455373764038
Validation loss: 2.128688712914785

Epoch: 6| Step: 4
Training loss: 1.429503083229065
Validation loss: 2.1146183411280313

Epoch: 6| Step: 5
Training loss: 1.2584373950958252
Validation loss: 2.166618585586548

Epoch: 6| Step: 6
Training loss: 0.7653703689575195
Validation loss: 2.132163147131602

Epoch: 6| Step: 7
Training loss: 1.440603494644165
Validation loss: 2.1668061216672263

Epoch: 6| Step: 8
Training loss: 1.1104174852371216
Validation loss: 2.1681243181228638

Epoch: 6| Step: 9
Training loss: 1.8949998617172241
Validation loss: 2.107195417086283

Epoch: 6| Step: 10
Training loss: 0.8228616714477539
Validation loss: 2.1486662228902182

Epoch: 6| Step: 11
Training loss: 0.6866735219955444
Validation loss: 2.106020371119181

Epoch: 6| Step: 12
Training loss: 0.997444748878479
Validation loss: 2.092125435670217

Epoch: 6| Step: 13
Training loss: 1.445131540298462
Validation loss: 2.0855995814005532

Epoch: 395| Step: 0
Training loss: 0.8705428838729858
Validation loss: 2.1027901570002236

Epoch: 6| Step: 1
Training loss: 1.2144038677215576
Validation loss: 2.130300521850586

Epoch: 6| Step: 2
Training loss: 1.1584892272949219
Validation loss: 2.097363531589508

Epoch: 6| Step: 3
Training loss: 1.9037941694259644
Validation loss: 2.092300017674764

Epoch: 6| Step: 4
Training loss: 0.915134847164154
Validation loss: 2.1166115204493203

Epoch: 6| Step: 5
Training loss: 1.7966713905334473
Validation loss: 2.096231520175934

Epoch: 6| Step: 6
Training loss: 1.179714322090149
Validation loss: 2.08343243598938

Epoch: 6| Step: 7
Training loss: 0.7431963086128235
Validation loss: 2.038067619005839

Epoch: 6| Step: 8
Training loss: 1.052836298942566
Validation loss: 2.0325122276941934

Epoch: 6| Step: 9
Training loss: 0.8022959232330322
Validation loss: 2.091819981733958

Epoch: 6| Step: 10
Training loss: 0.7362596988677979
Validation loss: 2.1472174723943076

Epoch: 6| Step: 11
Training loss: 1.301372766494751
Validation loss: 2.1119006077448526

Epoch: 6| Step: 12
Training loss: 0.8491843938827515
Validation loss: 2.114197254180908

Epoch: 6| Step: 13
Training loss: 1.4229474067687988
Validation loss: 2.1181215047836304

Epoch: 396| Step: 0
Training loss: 1.7687461376190186
Validation loss: 2.094719171524048

Epoch: 6| Step: 1
Training loss: 1.3403195142745972
Validation loss: 2.0589599609375

Epoch: 6| Step: 2
Training loss: 0.9353393912315369
Validation loss: 2.0311127305030823

Epoch: 6| Step: 3
Training loss: 1.4015637636184692
Validation loss: 2.0178884267807007

Epoch: 6| Step: 4
Training loss: 1.514315128326416
Validation loss: 2.0436772108078003

Epoch: 6| Step: 5
Training loss: 0.8686342239379883
Validation loss: 2.0705642104148865

Epoch: 6| Step: 6
Training loss: 1.0570719242095947
Validation loss: 2.0968600312868753

Epoch: 6| Step: 7
Training loss: 1.3362956047058105
Validation loss: 2.0891286532084146

Epoch: 6| Step: 8
Training loss: 0.8070257902145386
Validation loss: 2.0668689409891763

Epoch: 6| Step: 9
Training loss: 1.298427700996399
Validation loss: 2.040286401907603

Epoch: 6| Step: 10
Training loss: 0.5276311039924622
Validation loss: 2.019028921922048

Epoch: 6| Step: 11
Training loss: 1.2059818506240845
Validation loss: 2.098655958970388

Epoch: 6| Step: 12
Training loss: 0.6616005301475525
Validation loss: 2.0661652286847434

Epoch: 6| Step: 13
Training loss: 0.5288412570953369
Validation loss: 2.077634414037069

Epoch: 397| Step: 0
Training loss: 1.122148036956787
Validation loss: 2.1153804461161294

Epoch: 6| Step: 1
Training loss: 1.1045422554016113
Validation loss: 2.102299710114797

Epoch: 6| Step: 2
Training loss: 0.9049186706542969
Validation loss: 2.0833128492037454

Epoch: 6| Step: 3
Training loss: 1.5789728164672852
Validation loss: 2.0972617069880166

Epoch: 6| Step: 4
Training loss: 1.1467921733856201
Validation loss: 2.0665926535924277

Epoch: 6| Step: 5
Training loss: 1.3229796886444092
Validation loss: 2.0678205688794455

Epoch: 6| Step: 6
Training loss: 0.7128617167472839
Validation loss: 2.0724701484044394

Epoch: 6| Step: 7
Training loss: 0.9204768538475037
Validation loss: 2.086102326711019

Epoch: 6| Step: 8
Training loss: 0.8312535881996155
Validation loss: 2.115041673183441

Epoch: 6| Step: 9
Training loss: 1.095409631729126
Validation loss: 2.0829784075419107

Epoch: 6| Step: 10
Training loss: 0.615511417388916
Validation loss: 2.0926775137583413

Epoch: 6| Step: 11
Training loss: 1.1625910997390747
Validation loss: 2.0769092241923013

Epoch: 6| Step: 12
Training loss: 0.9939533472061157
Validation loss: 2.098173896471659

Epoch: 6| Step: 13
Training loss: 0.8530187606811523
Validation loss: 2.0663849314053855

Epoch: 398| Step: 0
Training loss: 1.0214204788208008
Validation loss: 2.0747088392575583

Epoch: 6| Step: 1
Training loss: 0.682152271270752
Validation loss: 2.0767549673716226

Epoch: 6| Step: 2
Training loss: 0.5522241592407227
Validation loss: 2.084456205368042

Epoch: 6| Step: 3
Training loss: 1.557920217514038
Validation loss: 2.038769861062368

Epoch: 6| Step: 4
Training loss: 0.9092510938644409
Validation loss: 2.0704946716626487

Epoch: 6| Step: 5
Training loss: 1.5627763271331787
Validation loss: 2.0276347597440085

Epoch: 6| Step: 6
Training loss: 1.3468431234359741
Validation loss: 2.048527240753174

Epoch: 6| Step: 7
Training loss: 0.7272080183029175
Validation loss: 2.0530598759651184

Epoch: 6| Step: 8
Training loss: 1.0150117874145508
Validation loss: 2.077216466267904

Epoch: 6| Step: 9
Training loss: 0.5057636499404907
Validation loss: 2.0586761633555093

Epoch: 6| Step: 10
Training loss: 0.853962779045105
Validation loss: 2.080919067064921

Epoch: 6| Step: 11
Training loss: 1.2456004619598389
Validation loss: 2.054771065711975

Epoch: 6| Step: 12
Training loss: 1.0932466983795166
Validation loss: 2.0525041619936624

Epoch: 6| Step: 13
Training loss: 1.5409579277038574
Validation loss: 2.053739845752716

Epoch: 399| Step: 0
Training loss: 0.9936437606811523
Validation loss: 2.024941146373749

Epoch: 6| Step: 1
Training loss: 1.1912899017333984
Validation loss: 2.061848978201548

Epoch: 6| Step: 2
Training loss: 1.0831468105316162
Validation loss: 2.136336704095205

Epoch: 6| Step: 3
Training loss: 1.145763874053955
Validation loss: 2.1043818394343057

Epoch: 6| Step: 4
Training loss: 1.1210784912109375
Validation loss: 2.0892698764801025

Epoch: 6| Step: 5
Training loss: 0.9910126328468323
Validation loss: 2.083718399206797

Epoch: 6| Step: 6
Training loss: 0.602709174156189
Validation loss: 2.0812180836995444

Epoch: 6| Step: 7
Training loss: 1.1954140663146973
Validation loss: 2.028761108716329

Epoch: 6| Step: 8
Training loss: 0.7876369953155518
Validation loss: 2.036770741144816

Epoch: 6| Step: 9
Training loss: 1.5135384798049927
Validation loss: 2.024671971797943

Epoch: 6| Step: 10
Training loss: 1.0969184637069702
Validation loss: 2.0656755566596985

Epoch: 6| Step: 11
Training loss: 0.929736316204071
Validation loss: 2.0540701746940613

Epoch: 6| Step: 12
Training loss: 0.9331221580505371
Validation loss: 2.04344650109609

Epoch: 6| Step: 13
Training loss: 1.248581886291504
Validation loss: 2.0577440659205117

Epoch: 400| Step: 0
Training loss: 1.3576961755752563
Validation loss: 2.0683070619901023

Epoch: 6| Step: 1
Training loss: 0.7103801965713501
Validation loss: 2.0387760202089944

Epoch: 6| Step: 2
Training loss: 1.2790758609771729
Validation loss: 2.1039658784866333

Epoch: 6| Step: 3
Training loss: 1.0764460563659668
Validation loss: 2.102174083391825

Epoch: 6| Step: 4
Training loss: 0.5495694279670715
Validation loss: 2.1156490246454873

Epoch: 6| Step: 5
Training loss: 0.9849973917007446
Validation loss: 2.097730815410614

Epoch: 6| Step: 6
Training loss: 0.9893344044685364
Validation loss: 2.0871148904164634

Epoch: 6| Step: 7
Training loss: 1.5971624851226807
Validation loss: 2.086112598578135

Epoch: 6| Step: 8
Training loss: 1.1002424955368042
Validation loss: 2.108182648817698

Epoch: 6| Step: 9
Training loss: 1.0873832702636719
Validation loss: 2.1052658359209695

Epoch: 6| Step: 10
Training loss: 1.316737413406372
Validation loss: 2.0774205923080444

Epoch: 6| Step: 11
Training loss: 0.9991654753684998
Validation loss: 2.0584261417388916

Epoch: 6| Step: 12
Training loss: 0.36683404445648193
Validation loss: 2.053150475025177

Epoch: 6| Step: 13
Training loss: 0.7673648595809937
Validation loss: 2.0754630168279014

Testing loss: 1.9170933198585784
