Epoch: 1| Step: 0
Training loss: 4.855478763580322
Validation loss: 5.332169036070506

Epoch: 5| Step: 1
Training loss: 6.2434916496276855
Validation loss: 5.329903761545817

Epoch: 5| Step: 2
Training loss: 6.62139368057251
Validation loss: 5.3277949293454485

Epoch: 5| Step: 3
Training loss: 5.164801597595215
Validation loss: 5.32579626639684

Epoch: 5| Step: 4
Training loss: 6.131155490875244
Validation loss: 5.323856254418691

Epoch: 5| Step: 5
Training loss: 4.835214614868164
Validation loss: 5.321967800458272

Epoch: 5| Step: 6
Training loss: 4.708351135253906
Validation loss: 5.320209403832753

Epoch: 5| Step: 7
Training loss: 5.401923179626465
Validation loss: 5.318423509597778

Epoch: 5| Step: 8
Training loss: 5.442326545715332
Validation loss: 5.31654425462087

Epoch: 5| Step: 9
Training loss: 4.263754844665527
Validation loss: 5.314699351787567

Epoch: 5| Step: 10
Training loss: 5.062527656555176
Validation loss: 5.312867363293965

Epoch: 5| Step: 11
Training loss: 8.242680549621582
Validation loss: 5.310903588930766

Epoch: 2| Step: 0
Training loss: 5.498724460601807
Validation loss: 5.308875838915507

Epoch: 5| Step: 1
Training loss: 4.381131172180176
Validation loss: 5.306735813617706

Epoch: 5| Step: 2
Training loss: 5.083770275115967
Validation loss: 5.304600973924001

Epoch: 5| Step: 3
Training loss: 5.096348285675049
Validation loss: 5.3022676308949785

Epoch: 5| Step: 4
Training loss: 5.5112433433532715
Validation loss: 5.299910724163055

Epoch: 5| Step: 5
Training loss: 4.721813201904297
Validation loss: 5.297390997409821

Epoch: 5| Step: 6
Training loss: 5.350274085998535
Validation loss: 5.294809301694234

Epoch: 5| Step: 7
Training loss: 5.946681022644043
Validation loss: 5.292161862055461

Epoch: 5| Step: 8
Training loss: 6.0796895027160645
Validation loss: 5.289320965607961

Epoch: 5| Step: 9
Training loss: 5.645825386047363
Validation loss: 5.286522885163625

Epoch: 5| Step: 10
Training loss: 5.2816009521484375
Validation loss: 5.283370037873586

Epoch: 5| Step: 11
Training loss: 7.480531215667725
Validation loss: 5.280192693074544

Epoch: 3| Step: 0
Training loss: 4.391261100769043
Validation loss: 5.27668156226476

Epoch: 5| Step: 1
Training loss: 4.81198787689209
Validation loss: 5.273046970367432

Epoch: 5| Step: 2
Training loss: 5.200259208679199
Validation loss: 5.269290169080098

Epoch: 5| Step: 3
Training loss: 5.906371116638184
Validation loss: 5.265462239583333

Epoch: 5| Step: 4
Training loss: 5.437047958374023
Validation loss: 5.261504113674164

Epoch: 5| Step: 5
Training loss: 5.515483856201172
Validation loss: 5.257292628288269

Epoch: 5| Step: 6
Training loss: 5.314334869384766
Validation loss: 5.252903978029887

Epoch: 5| Step: 7
Training loss: 6.4188408851623535
Validation loss: 5.248278180758159

Epoch: 5| Step: 8
Training loss: 5.002603054046631
Validation loss: 5.243562360604604

Epoch: 5| Step: 9
Training loss: 5.734579563140869
Validation loss: 5.238693515459697

Epoch: 5| Step: 10
Training loss: 5.036718368530273
Validation loss: 5.233577748139699

Epoch: 5| Step: 11
Training loss: 4.377474784851074
Validation loss: 5.228216846783956

Epoch: 4| Step: 0
Training loss: 5.692924499511719
Validation loss: 5.222688456376393

Epoch: 5| Step: 1
Training loss: 5.331982612609863
Validation loss: 5.217009623845418

Epoch: 5| Step: 2
Training loss: 5.748251914978027
Validation loss: 5.210985064506531

Epoch: 5| Step: 3
Training loss: 5.518661022186279
Validation loss: 5.204579492410024

Epoch: 5| Step: 4
Training loss: 5.356936931610107
Validation loss: 5.198241730531056

Epoch: 5| Step: 5
Training loss: 5.753109455108643
Validation loss: 5.191717187563579

Epoch: 5| Step: 6
Training loss: 4.8969831466674805
Validation loss: 5.185122072696686

Epoch: 5| Step: 7
Training loss: 4.308326244354248
Validation loss: 5.178005079428355

Epoch: 5| Step: 8
Training loss: 5.229419708251953
Validation loss: 5.1706968148549395

Epoch: 5| Step: 9
Training loss: 5.864690780639648
Validation loss: 5.163002709547679

Epoch: 5| Step: 10
Training loss: 4.321577072143555
Validation loss: 5.1553530891736346

Epoch: 5| Step: 11
Training loss: 4.520482540130615
Validation loss: 5.147680997848511

Epoch: 5| Step: 0
Training loss: 4.753065586090088
Validation loss: 5.139689425627391

Epoch: 5| Step: 1
Training loss: 5.558783054351807
Validation loss: 5.131713509559631

Epoch: 5| Step: 2
Training loss: 5.416860103607178
Validation loss: 5.1237032016118365

Epoch: 5| Step: 3
Training loss: 5.4149065017700195
Validation loss: 5.115504662195842

Epoch: 5| Step: 4
Training loss: 5.424077987670898
Validation loss: 5.107275625069936

Epoch: 5| Step: 5
Training loss: 4.952736854553223
Validation loss: 5.098874747753143

Epoch: 5| Step: 6
Training loss: 5.1998491287231445
Validation loss: 5.090536922216415

Epoch: 5| Step: 7
Training loss: 4.195900917053223
Validation loss: 5.08245187997818

Epoch: 5| Step: 8
Training loss: 4.09382438659668
Validation loss: 5.073964595794678

Epoch: 5| Step: 9
Training loss: 6.1410064697265625
Validation loss: 5.065991421540578

Epoch: 5| Step: 10
Training loss: 5.953028678894043
Validation loss: 5.057352185249329

Epoch: 5| Step: 11
Training loss: 4.185204029083252
Validation loss: 5.049053569634755

Epoch: 6| Step: 0
Training loss: 4.871492385864258
Validation loss: 5.040883322556813

Epoch: 5| Step: 1
Training loss: 4.966104030609131
Validation loss: 5.032052218914032

Epoch: 5| Step: 2
Training loss: 5.229790210723877
Validation loss: 5.023380080858867

Epoch: 5| Step: 3
Training loss: 4.236100196838379
Validation loss: 5.0144641399383545

Epoch: 5| Step: 4
Training loss: 4.995960235595703
Validation loss: 5.0054832100868225

Epoch: 5| Step: 5
Training loss: 5.037284851074219
Validation loss: 4.9961662491162615

Epoch: 5| Step: 6
Training loss: 6.595101833343506
Validation loss: 4.9872422615687055

Epoch: 5| Step: 7
Training loss: 4.417869567871094
Validation loss: 4.978061358133952

Epoch: 5| Step: 8
Training loss: 5.570981025695801
Validation loss: 4.969376623630524

Epoch: 5| Step: 9
Training loss: 4.783130168914795
Validation loss: 4.959988971551259

Epoch: 5| Step: 10
Training loss: 5.439059257507324
Validation loss: 4.950831015904744

Epoch: 5| Step: 11
Training loss: 3.5513970851898193
Validation loss: 4.941536386807759

Epoch: 7| Step: 0
Training loss: 4.7548041343688965
Validation loss: 4.932896474997203

Epoch: 5| Step: 1
Training loss: 4.173192024230957
Validation loss: 4.923718432585399

Epoch: 5| Step: 2
Training loss: 4.18109130859375
Validation loss: 4.914644241333008

Epoch: 5| Step: 3
Training loss: 5.106593132019043
Validation loss: 4.905700137217839

Epoch: 5| Step: 4
Training loss: 5.122174263000488
Validation loss: 4.896387070417404

Epoch: 5| Step: 5
Training loss: 4.799902439117432
Validation loss: 4.886321127414703

Epoch: 5| Step: 6
Training loss: 6.296178340911865
Validation loss: 4.8767813841501875

Epoch: 5| Step: 7
Training loss: 5.394585609436035
Validation loss: 4.867050429185231

Epoch: 5| Step: 8
Training loss: 5.246336936950684
Validation loss: 4.858539303143819

Epoch: 5| Step: 9
Training loss: 4.2362895011901855
Validation loss: 4.850636869668961

Epoch: 5| Step: 10
Training loss: 5.460247039794922
Validation loss: 4.842411120732625

Epoch: 5| Step: 11
Training loss: 4.480572700500488
Validation loss: 4.834098478158315

Epoch: 8| Step: 0
Training loss: 4.183991432189941
Validation loss: 4.826393187046051

Epoch: 5| Step: 1
Training loss: 4.850742340087891
Validation loss: 4.818544864654541

Epoch: 5| Step: 2
Training loss: 5.2481489181518555
Validation loss: 4.811124126116435

Epoch: 5| Step: 3
Training loss: 4.660496711730957
Validation loss: 4.803390979766846

Epoch: 5| Step: 4
Training loss: 5.433882713317871
Validation loss: 4.795951048533122

Epoch: 5| Step: 5
Training loss: 5.06610107421875
Validation loss: 4.7888462742169695

Epoch: 5| Step: 6
Training loss: 4.279648303985596
Validation loss: 4.781298438707988

Epoch: 5| Step: 7
Training loss: 4.337242126464844
Validation loss: 4.773957093556722

Epoch: 5| Step: 8
Training loss: 4.839535713195801
Validation loss: 4.766516307989757

Epoch: 5| Step: 9
Training loss: 5.470763206481934
Validation loss: 4.759091377258301

Epoch: 5| Step: 10
Training loss: 5.465249061584473
Validation loss: 4.751742720603943

Epoch: 5| Step: 11
Training loss: 3.9289708137512207
Validation loss: 4.744192818800609

Epoch: 9| Step: 0
Training loss: 5.227848052978516
Validation loss: 4.736352801322937

Epoch: 5| Step: 1
Training loss: 5.407821178436279
Validation loss: 4.728295187155406

Epoch: 5| Step: 2
Training loss: 4.3671159744262695
Validation loss: 4.720588564872742

Epoch: 5| Step: 3
Training loss: 4.473366737365723
Validation loss: 4.713059941927592

Epoch: 5| Step: 4
Training loss: 5.075697898864746
Validation loss: 4.705021361509959

Epoch: 5| Step: 5
Training loss: 4.584918975830078
Validation loss: 4.697613914807637

Epoch: 5| Step: 6
Training loss: 4.4729461669921875
Validation loss: 4.690069675445557

Epoch: 5| Step: 7
Training loss: 3.6488468647003174
Validation loss: 4.6822958787282305

Epoch: 5| Step: 8
Training loss: 4.710022926330566
Validation loss: 4.674593071142833

Epoch: 5| Step: 9
Training loss: 4.890280246734619
Validation loss: 4.667649914820989

Epoch: 5| Step: 10
Training loss: 5.733843803405762
Validation loss: 4.6600797573725385

Epoch: 5| Step: 11
Training loss: 5.405647277832031
Validation loss: 4.653387188911438

Epoch: 10| Step: 0
Training loss: 4.772562503814697
Validation loss: 4.646039088567098

Epoch: 5| Step: 1
Training loss: 4.830397129058838
Validation loss: 4.639212389787038

Epoch: 5| Step: 2
Training loss: 4.633301258087158
Validation loss: 4.6323310534159345

Epoch: 5| Step: 3
Training loss: 5.814587593078613
Validation loss: 4.625600636005402

Epoch: 5| Step: 4
Training loss: 4.666525840759277
Validation loss: 4.618448078632355

Epoch: 5| Step: 5
Training loss: 3.715346097946167
Validation loss: 4.6122117439905805

Epoch: 5| Step: 6
Training loss: 4.377787113189697
Validation loss: 4.605589131514232

Epoch: 5| Step: 7
Training loss: 4.667051792144775
Validation loss: 4.599163701136907

Epoch: 5| Step: 8
Training loss: 4.281574726104736
Validation loss: 4.592084487279256

Epoch: 5| Step: 9
Training loss: 5.105720520019531
Validation loss: 4.585972607135773

Epoch: 5| Step: 10
Training loss: 5.078798294067383
Validation loss: 4.579110066095988

Epoch: 5| Step: 11
Training loss: 4.022008419036865
Validation loss: 4.5724901755650835

Epoch: 11| Step: 0
Training loss: 4.348752021789551
Validation loss: 4.565399030844371

Epoch: 5| Step: 1
Training loss: 4.506819725036621
Validation loss: 4.558701992034912

Epoch: 5| Step: 2
Training loss: 4.115633964538574
Validation loss: 4.551736772060394

Epoch: 5| Step: 3
Training loss: 4.074993133544922
Validation loss: 4.545122782389323

Epoch: 5| Step: 4
Training loss: 4.062440872192383
Validation loss: 4.538282036781311

Epoch: 5| Step: 5
Training loss: 4.955388069152832
Validation loss: 4.53186172246933

Epoch: 5| Step: 6
Training loss: 4.920845985412598
Validation loss: 4.524949083725612

Epoch: 5| Step: 7
Training loss: 5.03591251373291
Validation loss: 4.51835568745931

Epoch: 5| Step: 8
Training loss: 4.688605308532715
Validation loss: 4.511471251646678

Epoch: 5| Step: 9
Training loss: 4.925353050231934
Validation loss: 4.504905939102173

Epoch: 5| Step: 10
Training loss: 4.931381702423096
Validation loss: 4.498581349849701

Epoch: 5| Step: 11
Training loss: 6.743080139160156
Validation loss: 4.491990874210994

Epoch: 12| Step: 0
Training loss: 5.093331336975098
Validation loss: 4.484793146451314

Epoch: 5| Step: 1
Training loss: 4.667743682861328
Validation loss: 4.479136109352112

Epoch: 5| Step: 2
Training loss: 4.538741588592529
Validation loss: 4.472098718086879

Epoch: 5| Step: 3
Training loss: 3.946092128753662
Validation loss: 4.465739607810974

Epoch: 5| Step: 4
Training loss: 5.235080242156982
Validation loss: 4.459397474924724

Epoch: 5| Step: 5
Training loss: 4.9599223136901855
Validation loss: 4.453263928492864

Epoch: 5| Step: 6
Training loss: 5.172372817993164
Validation loss: 4.44726237654686

Epoch: 5| Step: 7
Training loss: 3.8315677642822266
Validation loss: 4.440653085708618

Epoch: 5| Step: 8
Training loss: 5.052570819854736
Validation loss: 4.434446821610133

Epoch: 5| Step: 9
Training loss: 3.9751198291778564
Validation loss: 4.4276533126831055

Epoch: 5| Step: 10
Training loss: 3.4461941719055176
Validation loss: 4.420888245105743

Epoch: 5| Step: 11
Training loss: 5.983749866485596
Validation loss: 4.414319038391113

Epoch: 13| Step: 0
Training loss: 3.9333572387695312
Validation loss: 4.407613813877106

Epoch: 5| Step: 1
Training loss: 4.765621662139893
Validation loss: 4.400392731030782

Epoch: 5| Step: 2
Training loss: 5.078381538391113
Validation loss: 4.393720467885335

Epoch: 5| Step: 3
Training loss: 5.3478899002075195
Validation loss: 4.3858970403671265

Epoch: 5| Step: 4
Training loss: 3.915891170501709
Validation loss: 4.3787293036778765

Epoch: 5| Step: 5
Training loss: 4.3697919845581055
Validation loss: 4.370986421902974

Epoch: 5| Step: 6
Training loss: 3.8694519996643066
Validation loss: 4.36393728852272

Epoch: 5| Step: 7
Training loss: 4.055816173553467
Validation loss: 4.3565976818402605

Epoch: 5| Step: 8
Training loss: 4.669668197631836
Validation loss: 4.349365154902141

Epoch: 5| Step: 9
Training loss: 4.829926490783691
Validation loss: 4.34209527571996

Epoch: 5| Step: 10
Training loss: 4.5012407302856445
Validation loss: 4.3350216547648115

Epoch: 5| Step: 11
Training loss: 4.702221870422363
Validation loss: 4.32850256562233

Epoch: 14| Step: 0
Training loss: 3.891730546951294
Validation loss: 4.321807086467743

Epoch: 5| Step: 1
Training loss: 5.285467624664307
Validation loss: 4.3158778349558515

Epoch: 5| Step: 2
Training loss: 4.5031867027282715
Validation loss: 4.309423387050629

Epoch: 5| Step: 3
Training loss: 4.024669647216797
Validation loss: 4.303043156862259

Epoch: 5| Step: 4
Training loss: 4.555988311767578
Validation loss: 4.297093550364177

Epoch: 5| Step: 5
Training loss: 4.282601356506348
Validation loss: 4.290792127450307

Epoch: 5| Step: 6
Training loss: 4.946918964385986
Validation loss: 4.284572184085846

Epoch: 5| Step: 7
Training loss: 4.6746931076049805
Validation loss: 4.278463035821915

Epoch: 5| Step: 8
Training loss: 3.2609546184539795
Validation loss: 4.272616217533748

Epoch: 5| Step: 9
Training loss: 4.152572154998779
Validation loss: 4.267185012499492

Epoch: 5| Step: 10
Training loss: 4.580604553222656
Validation loss: 4.261351704597473

Epoch: 5| Step: 11
Training loss: 6.494999885559082
Validation loss: 4.255373428265254

Epoch: 15| Step: 0
Training loss: 3.4187417030334473
Validation loss: 4.249890148639679

Epoch: 5| Step: 1
Training loss: 5.112746238708496
Validation loss: 4.244406412045161

Epoch: 5| Step: 2
Training loss: 5.332357883453369
Validation loss: 4.238136291503906

Epoch: 5| Step: 3
Training loss: 4.265593528747559
Validation loss: 4.231947014729182

Epoch: 5| Step: 4
Training loss: 4.3547844886779785
Validation loss: 4.2259320716063185

Epoch: 5| Step: 5
Training loss: 3.804964780807495
Validation loss: 4.220346013704936

Epoch: 5| Step: 6
Training loss: 4.306402683258057
Validation loss: 4.215503831704457

Epoch: 5| Step: 7
Training loss: 4.291977405548096
Validation loss: 4.209095100561778

Epoch: 5| Step: 8
Training loss: 3.953744888305664
Validation loss: 4.2023696800072985

Epoch: 5| Step: 9
Training loss: 4.728244781494141
Validation loss: 4.196854372819264

Epoch: 5| Step: 10
Training loss: 4.233333587646484
Validation loss: 4.191461731990178

Epoch: 5| Step: 11
Training loss: 4.7095136642456055
Validation loss: 4.186979154745738

Epoch: 16| Step: 0
Training loss: 5.050976753234863
Validation loss: 4.18123518427213

Epoch: 5| Step: 1
Training loss: 4.235182285308838
Validation loss: 4.175305128097534

Epoch: 5| Step: 2
Training loss: 4.384890079498291
Validation loss: 4.170568943023682

Epoch: 5| Step: 3
Training loss: 4.265610694885254
Validation loss: 4.1656065583229065

Epoch: 5| Step: 4
Training loss: 4.709498405456543
Validation loss: 4.158999969561894

Epoch: 5| Step: 5
Training loss: 5.2466936111450195
Validation loss: 4.153551598389943

Epoch: 5| Step: 6
Training loss: 4.0137834548950195
Validation loss: 4.148088693618774

Epoch: 5| Step: 7
Training loss: 4.178513526916504
Validation loss: 4.142892907063167

Epoch: 5| Step: 8
Training loss: 4.404392242431641
Validation loss: 4.137834876775742

Epoch: 5| Step: 9
Training loss: 3.6216025352478027
Validation loss: 4.132706721623738

Epoch: 5| Step: 10
Training loss: 2.8010857105255127
Validation loss: 4.12795286377271

Epoch: 5| Step: 11
Training loss: 5.77231502532959
Validation loss: 4.122693508863449

Epoch: 17| Step: 0
Training loss: 4.156620025634766
Validation loss: 4.1180853843688965

Epoch: 5| Step: 1
Training loss: 4.37689208984375
Validation loss: 4.11306157708168

Epoch: 5| Step: 2
Training loss: 4.88650369644165
Validation loss: 4.108774195114772

Epoch: 5| Step: 3
Training loss: 4.327164649963379
Validation loss: 4.102604448795319

Epoch: 5| Step: 4
Training loss: 4.4642815589904785
Validation loss: 4.097888916730881

Epoch: 5| Step: 5
Training loss: 4.790030002593994
Validation loss: 4.093057880798976

Epoch: 5| Step: 6
Training loss: 3.5877678394317627
Validation loss: 4.087334771951039

Epoch: 5| Step: 7
Training loss: 3.4908058643341064
Validation loss: 4.082839796940486

Epoch: 5| Step: 8
Training loss: 3.8335037231445312
Validation loss: 4.078369220097859

Epoch: 5| Step: 9
Training loss: 4.790133953094482
Validation loss: 4.073204894860585

Epoch: 5| Step: 10
Training loss: 3.8491969108581543
Validation loss: 4.068144649267197

Epoch: 5| Step: 11
Training loss: 4.349930763244629
Validation loss: 4.062670558691025

Epoch: 18| Step: 0
Training loss: 3.355820417404175
Validation loss: 4.05893940726916

Epoch: 5| Step: 1
Training loss: 4.475971221923828
Validation loss: 4.054525196552277

Epoch: 5| Step: 2
Training loss: 3.645728349685669
Validation loss: 4.049166232347488

Epoch: 5| Step: 3
Training loss: 4.652829647064209
Validation loss: 4.0441567202409106

Epoch: 5| Step: 4
Training loss: 3.2097721099853516
Validation loss: 4.039248506228129

Epoch: 5| Step: 5
Training loss: 4.1109514236450195
Validation loss: 4.035514424244563

Epoch: 5| Step: 6
Training loss: 4.681248664855957
Validation loss: 4.031217515468597

Epoch: 5| Step: 7
Training loss: 4.2159223556518555
Validation loss: 4.02745979030927

Epoch: 5| Step: 8
Training loss: 4.468994617462158
Validation loss: 4.02182059486707

Epoch: 5| Step: 9
Training loss: 4.958901882171631
Validation loss: 4.017231682936351

Epoch: 5| Step: 10
Training loss: 4.613533973693848
Validation loss: 4.011220415433248

Epoch: 5| Step: 11
Training loss: 1.9969096183776855
Validation loss: 4.007492154836655

Epoch: 19| Step: 0
Training loss: 4.5555739402771
Validation loss: 4.003244539101918

Epoch: 5| Step: 1
Training loss: 3.7981762886047363
Validation loss: 3.9986080527305603

Epoch: 5| Step: 2
Training loss: 4.089240074157715
Validation loss: 3.9939396679401398

Epoch: 5| Step: 3
Training loss: 5.1955461502075195
Validation loss: 3.989478647708893

Epoch: 5| Step: 4
Training loss: 3.0433990955352783
Validation loss: 3.984858532746633

Epoch: 5| Step: 5
Training loss: 4.468568801879883
Validation loss: 3.9789659082889557

Epoch: 5| Step: 6
Training loss: 4.857414245605469
Validation loss: 3.9739352663358054

Epoch: 5| Step: 7
Training loss: 4.169241905212402
Validation loss: 3.9693510631720224

Epoch: 5| Step: 8
Training loss: 3.486422061920166
Validation loss: 3.965554048617681

Epoch: 5| Step: 9
Training loss: 3.86767578125
Validation loss: 3.9609227081139884

Epoch: 5| Step: 10
Training loss: 3.8283963203430176
Validation loss: 3.956203122933706

Epoch: 5| Step: 11
Training loss: 4.191088676452637
Validation loss: 3.9507981141408286

Epoch: 20| Step: 0
Training loss: 3.9504306316375732
Validation loss: 3.946567932764689

Epoch: 5| Step: 1
Training loss: 4.139931678771973
Validation loss: 3.9416074752807617

Epoch: 5| Step: 2
Training loss: 4.481903076171875
Validation loss: 3.937014122804006

Epoch: 5| Step: 3
Training loss: 3.6970725059509277
Validation loss: 3.9320184091726937

Epoch: 5| Step: 4
Training loss: 3.542980670928955
Validation loss: 3.927270531654358

Epoch: 5| Step: 5
Training loss: 4.565542697906494
Validation loss: 3.922163635492325

Epoch: 5| Step: 6
Training loss: 5.011274337768555
Validation loss: 3.917247474193573

Epoch: 5| Step: 7
Training loss: 3.365224838256836
Validation loss: 3.912080576022466

Epoch: 5| Step: 8
Training loss: 4.426117420196533
Validation loss: 3.9075484573841095

Epoch: 5| Step: 9
Training loss: 3.8566977977752686
Validation loss: 3.903171638647715

Epoch: 5| Step: 10
Training loss: 3.836826801300049
Validation loss: 3.89969069759051

Epoch: 5| Step: 11
Training loss: 3.5743284225463867
Validation loss: 3.8941830098629

Epoch: 21| Step: 0
Training loss: 4.724390029907227
Validation loss: 3.888970583677292

Epoch: 5| Step: 1
Training loss: 4.036151885986328
Validation loss: 3.8855017721652985

Epoch: 5| Step: 2
Training loss: 3.4438061714172363
Validation loss: 3.879961530367533

Epoch: 5| Step: 3
Training loss: 4.2497968673706055
Validation loss: 3.875396192073822

Epoch: 5| Step: 4
Training loss: 4.175232887268066
Validation loss: 3.8704336881637573

Epoch: 5| Step: 5
Training loss: 3.2016937732696533
Validation loss: 3.865601678689321

Epoch: 5| Step: 6
Training loss: 4.204285621643066
Validation loss: 3.8614136775334678

Epoch: 5| Step: 7
Training loss: 4.184945583343506
Validation loss: 3.8561430970827737

Epoch: 5| Step: 8
Training loss: 4.655985355377197
Validation loss: 3.851306656996409

Epoch: 5| Step: 9
Training loss: 3.882509231567383
Validation loss: 3.8458977540334067

Epoch: 5| Step: 10
Training loss: 3.6957015991210938
Validation loss: 3.841582238674164

Epoch: 5| Step: 11
Training loss: 2.7860922813415527
Validation loss: 3.8370138506094613

Epoch: 22| Step: 0
Training loss: 4.346951007843018
Validation loss: 3.8322077095508575

Epoch: 5| Step: 1
Training loss: 3.7434189319610596
Validation loss: 3.8269907732804618

Epoch: 5| Step: 2
Training loss: 4.225841045379639
Validation loss: 3.822837322950363

Epoch: 5| Step: 3
Training loss: 4.303316116333008
Validation loss: 3.8188359340031943

Epoch: 5| Step: 4
Training loss: 4.276524543762207
Validation loss: 3.8137924472490945

Epoch: 5| Step: 5
Training loss: 3.421984910964966
Validation loss: 3.808876713116964

Epoch: 5| Step: 6
Training loss: 4.697291851043701
Validation loss: 3.8055575489997864

Epoch: 5| Step: 7
Training loss: 4.033909797668457
Validation loss: 3.8012358844280243

Epoch: 5| Step: 8
Training loss: 4.453568458557129
Validation loss: 3.7968973914782205

Epoch: 5| Step: 9
Training loss: 3.0580523014068604
Validation loss: 3.7915199597676597

Epoch: 5| Step: 10
Training loss: 3.2085769176483154
Validation loss: 3.7858769496281943

Epoch: 5| Step: 11
Training loss: 3.223252296447754
Validation loss: 3.780960500240326

Epoch: 23| Step: 0
Training loss: 3.4395179748535156
Validation loss: 3.777125507593155

Epoch: 5| Step: 1
Training loss: 4.458845615386963
Validation loss: 3.7712300519148507

Epoch: 5| Step: 2
Training loss: 4.701213359832764
Validation loss: 3.764819920063019

Epoch: 5| Step: 3
Training loss: 4.4010210037231445
Validation loss: 3.760197470585505

Epoch: 5| Step: 4
Training loss: 3.9363644123077393
Validation loss: 3.754636377096176

Epoch: 5| Step: 5
Training loss: 3.023571252822876
Validation loss: 3.749633808930715

Epoch: 5| Step: 6
Training loss: 4.067771911621094
Validation loss: 3.744585325320562

Epoch: 5| Step: 7
Training loss: 3.308771848678589
Validation loss: 3.7400784393151603

Epoch: 5| Step: 8
Training loss: 3.785135269165039
Validation loss: 3.734340637922287

Epoch: 5| Step: 9
Training loss: 4.159923553466797
Validation loss: 3.729401777187983

Epoch: 5| Step: 10
Training loss: 3.8188610076904297
Validation loss: 3.7251129845778146

Epoch: 5| Step: 11
Training loss: 3.390131950378418
Validation loss: 3.7199864586194358

Epoch: 24| Step: 0
Training loss: 4.237235069274902
Validation loss: 3.714746415615082

Epoch: 5| Step: 1
Training loss: 3.7550430297851562
Validation loss: 3.710920572280884

Epoch: 5| Step: 2
Training loss: 4.1601972579956055
Validation loss: 3.706316808859507

Epoch: 5| Step: 3
Training loss: 3.7331931591033936
Validation loss: 3.7014293471972146

Epoch: 5| Step: 4
Training loss: 3.2466087341308594
Validation loss: 3.695524434248606

Epoch: 5| Step: 5
Training loss: 4.000216484069824
Validation loss: 3.6916765669981637

Epoch: 5| Step: 6
Training loss: 3.170403003692627
Validation loss: 3.6868776679039

Epoch: 5| Step: 7
Training loss: 3.1449687480926514
Validation loss: 3.682748874028524

Epoch: 5| Step: 8
Training loss: 3.435863494873047
Validation loss: 3.67751615246137

Epoch: 5| Step: 9
Training loss: 4.762030601501465
Validation loss: 3.672402540842692

Epoch: 5| Step: 10
Training loss: 4.725823879241943
Validation loss: 3.6690202057361603

Epoch: 5| Step: 11
Training loss: 3.903402805328369
Validation loss: 3.6634577910105386

Epoch: 25| Step: 0
Training loss: 3.1634795665740967
Validation loss: 3.6583166122436523

Epoch: 5| Step: 1
Training loss: 3.2239863872528076
Validation loss: 3.653611163298289

Epoch: 5| Step: 2
Training loss: 3.449261426925659
Validation loss: 3.6491146286328635

Epoch: 5| Step: 3
Training loss: 4.462328910827637
Validation loss: 3.645009368658066

Epoch: 5| Step: 4
Training loss: 3.5023951530456543
Validation loss: 3.640680174032847

Epoch: 5| Step: 5
Training loss: 3.9721577167510986
Validation loss: 3.6352713306744895

Epoch: 5| Step: 6
Training loss: 4.386689186096191
Validation loss: 3.6291122337182364

Epoch: 5| Step: 7
Training loss: 4.070535659790039
Validation loss: 3.6284048557281494

Epoch: 5| Step: 8
Training loss: 3.6649787425994873
Validation loss: 3.621870627005895

Epoch: 5| Step: 9
Training loss: 3.8491177558898926
Validation loss: 3.61563312013944

Epoch: 5| Step: 10
Training loss: 3.953484058380127
Validation loss: 3.611583004395167

Epoch: 5| Step: 11
Training loss: 4.097502708435059
Validation loss: 3.6072170734405518

Epoch: 26| Step: 0
Training loss: 2.800485134124756
Validation loss: 3.6012200911839805

Epoch: 5| Step: 1
Training loss: 3.8199806213378906
Validation loss: 3.5959547062714896

Epoch: 5| Step: 2
Training loss: 3.959376573562622
Validation loss: 3.5918621122837067

Epoch: 5| Step: 3
Training loss: 3.9149093627929688
Validation loss: 3.587053596973419

Epoch: 5| Step: 4
Training loss: 3.932330369949341
Validation loss: 3.581211348374685

Epoch: 5| Step: 5
Training loss: 4.397374629974365
Validation loss: 3.576342990001043

Epoch: 5| Step: 6
Training loss: 3.1232457160949707
Validation loss: 3.5713313817977905

Epoch: 5| Step: 7
Training loss: 3.356175184249878
Validation loss: 3.5663814743359885

Epoch: 5| Step: 8
Training loss: 4.725496768951416
Validation loss: 3.56126802166303

Epoch: 5| Step: 9
Training loss: 3.569227695465088
Validation loss: 3.5561736822128296

Epoch: 5| Step: 10
Training loss: 3.4956583976745605
Validation loss: 3.55111371477445

Epoch: 5| Step: 11
Training loss: 3.945962905883789
Validation loss: 3.5458461344242096

Epoch: 27| Step: 0
Training loss: 3.4935085773468018
Validation loss: 3.5412839353084564

Epoch: 5| Step: 1
Training loss: 3.9367783069610596
Validation loss: 3.5366261104742684

Epoch: 5| Step: 2
Training loss: 4.362063884735107
Validation loss: 3.5311389366785684

Epoch: 5| Step: 3
Training loss: 3.4657654762268066
Validation loss: 3.525647689898809

Epoch: 5| Step: 4
Training loss: 4.27182674407959
Validation loss: 3.520861546198527

Epoch: 5| Step: 5
Training loss: 3.2531116008758545
Validation loss: 3.515725235144297

Epoch: 5| Step: 6
Training loss: 4.437562465667725
Validation loss: 3.511417726675669

Epoch: 5| Step: 7
Training loss: 3.7655322551727295
Validation loss: 3.5057842830816903

Epoch: 5| Step: 8
Training loss: 3.203242063522339
Validation loss: 3.5008664429187775

Epoch: 5| Step: 9
Training loss: 2.8041958808898926
Validation loss: 3.4970105787118277

Epoch: 5| Step: 10
Training loss: 3.491680860519409
Validation loss: 3.4923031628131866

Epoch: 5| Step: 11
Training loss: 3.881469249725342
Validation loss: 3.4872996707757316

Epoch: 28| Step: 0
Training loss: 3.6243882179260254
Validation loss: 3.4824042518933616

Epoch: 5| Step: 1
Training loss: 3.7646708488464355
Validation loss: 3.4774526059627533

Epoch: 5| Step: 2
Training loss: 2.264655590057373
Validation loss: 3.473254750172297

Epoch: 5| Step: 3
Training loss: 3.9897103309631348
Validation loss: 3.4690789878368378

Epoch: 5| Step: 4
Training loss: 3.094604969024658
Validation loss: 3.4645838141441345

Epoch: 5| Step: 5
Training loss: 3.656031847000122
Validation loss: 3.4597824116547904

Epoch: 5| Step: 6
Training loss: 3.9888858795166016
Validation loss: 3.455187757809957

Epoch: 5| Step: 7
Training loss: 3.4876761436462402
Validation loss: 3.450777808825175

Epoch: 5| Step: 8
Training loss: 3.8386597633361816
Validation loss: 3.4463965396086373

Epoch: 5| Step: 9
Training loss: 3.5690064430236816
Validation loss: 3.4421030779679618

Epoch: 5| Step: 10
Training loss: 4.2845659255981445
Validation loss: 3.4375288784503937

Epoch: 5| Step: 11
Training loss: 5.141361236572266
Validation loss: 3.432620048522949

Epoch: 29| Step: 0
Training loss: 3.9712605476379395
Validation loss: 3.4273308515548706

Epoch: 5| Step: 1
Training loss: 3.8321120738983154
Validation loss: 3.42229562997818

Epoch: 5| Step: 2
Training loss: 3.919628143310547
Validation loss: 3.416746417681376

Epoch: 5| Step: 3
Training loss: 3.1012110710144043
Validation loss: 3.4118952453136444

Epoch: 5| Step: 4
Training loss: 3.4472103118896484
Validation loss: 3.4074262281258902

Epoch: 5| Step: 5
Training loss: 4.530372619628906
Validation loss: 3.401946097612381

Epoch: 5| Step: 6
Training loss: 3.3088150024414062
Validation loss: 3.3978730042775473

Epoch: 5| Step: 7
Training loss: 3.463710069656372
Validation loss: 3.392622580130895

Epoch: 5| Step: 8
Training loss: 2.8703601360321045
Validation loss: 3.3875215550263724

Epoch: 5| Step: 9
Training loss: 3.3355555534362793
Validation loss: 3.383090158303579

Epoch: 5| Step: 10
Training loss: 3.143932580947876
Validation loss: 3.3780029316743216

Epoch: 5| Step: 11
Training loss: 5.377423286437988
Validation loss: 3.374883989493052

Epoch: 30| Step: 0
Training loss: 3.8092403411865234
Validation loss: 3.3711406191190085

Epoch: 5| Step: 1
Training loss: 3.425288677215576
Validation loss: 3.3644712964693704

Epoch: 5| Step: 2
Training loss: 3.8122031688690186
Validation loss: 3.359409918387731

Epoch: 5| Step: 3
Training loss: 4.150660037994385
Validation loss: 3.3544482986132302

Epoch: 5| Step: 4
Training loss: 3.2935550212860107
Validation loss: 3.350212683280309

Epoch: 5| Step: 5
Training loss: 3.3311266899108887
Validation loss: 3.3456329504648843

Epoch: 5| Step: 6
Training loss: 3.1912758350372314
Validation loss: 3.341019024451574

Epoch: 5| Step: 7
Training loss: 3.408496379852295
Validation loss: 3.335929125547409

Epoch: 5| Step: 8
Training loss: 3.7678170204162598
Validation loss: 3.3311995565891266

Epoch: 5| Step: 9
Training loss: 3.4315407276153564
Validation loss: 3.3264933923880258

Epoch: 5| Step: 10
Training loss: 3.47967791557312
Validation loss: 3.3226067622502646

Epoch: 5| Step: 11
Training loss: 1.4162278175354004
Validation loss: 3.3175435860951743

Epoch: 31| Step: 0
Training loss: 2.986609697341919
Validation loss: 3.3123733500639596

Epoch: 5| Step: 1
Training loss: 3.568354845046997
Validation loss: 3.308269460995992

Epoch: 5| Step: 2
Training loss: 3.654284954071045
Validation loss: 3.30386150876681

Epoch: 5| Step: 3
Training loss: 3.2452456951141357
Validation loss: 3.299150029818217

Epoch: 5| Step: 4
Training loss: 4.0336198806762695
Validation loss: 3.2950996657212577

Epoch: 5| Step: 5
Training loss: 3.4408645629882812
Validation loss: 3.290532191594442

Epoch: 5| Step: 6
Training loss: 2.7451438903808594
Validation loss: 3.2864090502262115

Epoch: 5| Step: 7
Training loss: 3.8280959129333496
Validation loss: 3.282187342643738

Epoch: 5| Step: 8
Training loss: 3.96321177482605
Validation loss: 3.2781138320763907

Epoch: 5| Step: 9
Training loss: 3.533113956451416
Validation loss: 3.274293899536133

Epoch: 5| Step: 10
Training loss: 2.950590133666992
Validation loss: 3.2692518830299377

Epoch: 5| Step: 11
Training loss: 4.348148345947266
Validation loss: 3.2653613885243735

Epoch: 32| Step: 0
Training loss: 3.4480652809143066
Validation loss: 3.2604857881863913

Epoch: 5| Step: 1
Training loss: 3.1615734100341797
Validation loss: 3.2563425501187644

Epoch: 5| Step: 2
Training loss: 3.7390084266662598
Validation loss: 3.252433270215988

Epoch: 5| Step: 3
Training loss: 4.240927696228027
Validation loss: 3.2470862766106925

Epoch: 5| Step: 4
Training loss: 2.6060829162597656
Validation loss: 3.2428782085577645

Epoch: 5| Step: 5
Training loss: 2.7151741981506348
Validation loss: 3.238657792409261

Epoch: 5| Step: 6
Training loss: 3.804673433303833
Validation loss: 3.234689553578695

Epoch: 5| Step: 7
Training loss: 4.315239906311035
Validation loss: 3.2300641536712646

Epoch: 5| Step: 8
Training loss: 3.533801555633545
Validation loss: 3.225831240415573

Epoch: 5| Step: 9
Training loss: 3.089177370071411
Validation loss: 3.221243530511856

Epoch: 5| Step: 10
Training loss: 2.8653531074523926
Validation loss: 3.2170602480570474

Epoch: 5| Step: 11
Training loss: 3.757294178009033
Validation loss: 3.2125488817691803

Epoch: 33| Step: 0
Training loss: 3.644909381866455
Validation loss: 3.208486686150233

Epoch: 5| Step: 1
Training loss: 3.515334367752075
Validation loss: 3.204521765311559

Epoch: 5| Step: 2
Training loss: 3.6202759742736816
Validation loss: 3.2006539503733316

Epoch: 5| Step: 3
Training loss: 3.500218629837036
Validation loss: 3.1957065065701804

Epoch: 5| Step: 4
Training loss: 3.746596574783325
Validation loss: 3.1914871434370675

Epoch: 5| Step: 5
Training loss: 2.8130111694335938
Validation loss: 3.1878427962462106

Epoch: 5| Step: 6
Training loss: 3.7768661975860596
Validation loss: 3.183182636896769

Epoch: 5| Step: 7
Training loss: 2.7831625938415527
Validation loss: 3.1791677673657737

Epoch: 5| Step: 8
Training loss: 2.7922236919403076
Validation loss: 3.1746702094872794

Epoch: 5| Step: 9
Training loss: 3.105093479156494
Validation loss: 3.17069481809934

Epoch: 5| Step: 10
Training loss: 4.017967700958252
Validation loss: 3.166611135005951

Epoch: 5| Step: 11
Training loss: 2.1426172256469727
Validation loss: 3.1622712910175323

Epoch: 34| Step: 0
Training loss: 3.3237545490264893
Validation loss: 3.1582376857598624

Epoch: 5| Step: 1
Training loss: 3.1351661682128906
Validation loss: 3.154150277376175

Epoch: 5| Step: 2
Training loss: 3.5103023052215576
Validation loss: 3.149677574634552

Epoch: 5| Step: 3
Training loss: 3.8025970458984375
Validation loss: 3.145335465669632

Epoch: 5| Step: 4
Training loss: 2.2914175987243652
Validation loss: 3.1415763994057975

Epoch: 5| Step: 5
Training loss: 3.2610390186309814
Validation loss: 3.137462059656779

Epoch: 5| Step: 6
Training loss: 3.4813568592071533
Validation loss: 3.133314768473307

Epoch: 5| Step: 7
Training loss: 3.4713549613952637
Validation loss: 3.1286738216876984

Epoch: 5| Step: 8
Training loss: 3.280057430267334
Validation loss: 3.1248214344183602

Epoch: 5| Step: 9
Training loss: 3.4218380451202393
Validation loss: 3.1204790472984314

Epoch: 5| Step: 10
Training loss: 3.587780475616455
Validation loss: 3.1167159577210746

Epoch: 5| Step: 11
Training loss: 3.346557140350342
Validation loss: 3.112495183944702

Epoch: 35| Step: 0
Training loss: 3.582401752471924
Validation loss: 3.1080012818177543

Epoch: 5| Step: 1
Training loss: 2.43046498298645
Validation loss: 3.1046851178010306

Epoch: 5| Step: 2
Training loss: 3.301326274871826
Validation loss: 3.1010033984978995

Epoch: 5| Step: 3
Training loss: 2.862969398498535
Validation loss: 3.0974969069163003

Epoch: 5| Step: 4
Training loss: 3.3624300956726074
Validation loss: 3.0942791203657785

Epoch: 5| Step: 5
Training loss: 4.015028953552246
Validation loss: 3.0904617408911386

Epoch: 5| Step: 6
Training loss: 3.646376371383667
Validation loss: 3.086872418721517

Epoch: 5| Step: 7
Training loss: 3.3545658588409424
Validation loss: 3.0833217004934945

Epoch: 5| Step: 8
Training loss: 2.9805684089660645
Validation loss: 3.079369475444158

Epoch: 5| Step: 9
Training loss: 3.3583335876464844
Validation loss: 3.076215237379074

Epoch: 5| Step: 10
Training loss: 3.428603410720825
Validation loss: 3.072408378124237

Epoch: 5| Step: 11
Training loss: 2.0640134811401367
Validation loss: 3.067828247944514

Epoch: 36| Step: 0
Training loss: 2.7188100814819336
Validation loss: 3.065306087334951

Epoch: 5| Step: 1
Training loss: 3.332207441329956
Validation loss: 3.061776578426361

Epoch: 5| Step: 2
Training loss: 3.4264285564422607
Validation loss: 3.0588062703609467

Epoch: 5| Step: 3
Training loss: 3.4399406909942627
Validation loss: 3.0556154747804007

Epoch: 5| Step: 4
Training loss: 3.4035582542419434
Validation loss: 3.0516297817230225

Epoch: 5| Step: 5
Training loss: 2.5536227226257324
Validation loss: 3.048604339361191

Epoch: 5| Step: 6
Training loss: 3.60327410697937
Validation loss: 3.045304755369822

Epoch: 5| Step: 7
Training loss: 3.35455060005188
Validation loss: 3.0419844587643943

Epoch: 5| Step: 8
Training loss: 3.0599284172058105
Validation loss: 3.0385093788305917

Epoch: 5| Step: 9
Training loss: 3.3816475868225098
Validation loss: 3.035379707813263

Epoch: 5| Step: 10
Training loss: 3.3766536712646484
Validation loss: 3.0316666265328727

Epoch: 5| Step: 11
Training loss: 3.079115390777588
Validation loss: 3.028257558743159

Epoch: 37| Step: 0
Training loss: 3.412705183029175
Validation loss: 3.0244482258955636

Epoch: 5| Step: 1
Training loss: 3.2728195190429688
Validation loss: 3.021438807249069

Epoch: 5| Step: 2
Training loss: 4.4303083419799805
Validation loss: 3.017521023750305

Epoch: 5| Step: 3
Training loss: 2.941215753555298
Validation loss: 3.0150897204875946

Epoch: 5| Step: 4
Training loss: 2.7220165729522705
Validation loss: 3.0108811358610788

Epoch: 5| Step: 5
Training loss: 2.716187000274658
Validation loss: 3.0076554218928018

Epoch: 5| Step: 6
Training loss: 3.737806797027588
Validation loss: 3.0138595501581826

Epoch: 5| Step: 7
Training loss: 3.281442642211914
Validation loss: 3.000130852063497

Epoch: 5| Step: 8
Training loss: 2.4986934661865234
Validation loss: 2.995464930931727

Epoch: 5| Step: 9
Training loss: 2.8527870178222656
Validation loss: 2.9915993014971414

Epoch: 5| Step: 10
Training loss: 3.4778969287872314
Validation loss: 2.9879893163839975

Epoch: 5| Step: 11
Training loss: 2.493899345397949
Validation loss: 2.984566867351532

Epoch: 38| Step: 0
Training loss: 3.263928174972534
Validation loss: 2.9816075960795083

Epoch: 5| Step: 1
Training loss: 3.0236330032348633
Validation loss: 2.9792077938715615

Epoch: 5| Step: 2
Training loss: 3.490145206451416
Validation loss: 2.976071357727051

Epoch: 5| Step: 3
Training loss: 3.7986252307891846
Validation loss: 2.972509950399399

Epoch: 5| Step: 4
Training loss: 2.8223297595977783
Validation loss: 2.9691398541132608

Epoch: 5| Step: 5
Training loss: 2.9774010181427
Validation loss: 2.9657316505908966

Epoch: 5| Step: 6
Training loss: 2.723600149154663
Validation loss: 2.9627795815467834

Epoch: 5| Step: 7
Training loss: 3.5236973762512207
Validation loss: 2.9592509170373282

Epoch: 5| Step: 8
Training loss: 3.3599624633789062
Validation loss: 2.9565082788467407

Epoch: 5| Step: 9
Training loss: 2.6996049880981445
Validation loss: 2.9528436362743378

Epoch: 5| Step: 10
Training loss: 3.1920742988586426
Validation loss: 2.949288626511892

Epoch: 5| Step: 11
Training loss: 2.784719705581665
Validation loss: 2.9458710749944053

Epoch: 39| Step: 0
Training loss: 2.8203341960906982
Validation loss: 2.9425968726476035

Epoch: 5| Step: 1
Training loss: 2.6660571098327637
Validation loss: 2.939968466758728

Epoch: 5| Step: 2
Training loss: 3.3947062492370605
Validation loss: 2.9366439878940582

Epoch: 5| Step: 3
Training loss: 2.7593894004821777
Validation loss: 2.9331666827201843

Epoch: 5| Step: 4
Training loss: 3.319140911102295
Validation loss: 2.9294778406620026

Epoch: 5| Step: 5
Training loss: 3.0848898887634277
Validation loss: 2.9262271523475647

Epoch: 5| Step: 6
Training loss: 3.154921054840088
Validation loss: 2.9233722388744354

Epoch: 5| Step: 7
Training loss: 3.26017689704895
Validation loss: 2.9194268882274628

Epoch: 5| Step: 8
Training loss: 2.875880241394043
Validation loss: 2.9163089096546173

Epoch: 5| Step: 9
Training loss: 2.979677677154541
Validation loss: 2.913266658782959

Epoch: 5| Step: 10
Training loss: 4.120731353759766
Validation loss: 2.909823407729467

Epoch: 5| Step: 11
Training loss: 3.0097556114196777
Validation loss: 2.9067653020222983

Epoch: 40| Step: 0
Training loss: 3.577021360397339
Validation loss: 2.9032913943131766

Epoch: 5| Step: 1
Training loss: 3.028749942779541
Validation loss: 2.9000972509384155

Epoch: 5| Step: 2
Training loss: 3.5306668281555176
Validation loss: 2.8971710999806723

Epoch: 5| Step: 3
Training loss: 2.897057294845581
Validation loss: 2.893039514621099

Epoch: 5| Step: 4
Training loss: 2.576751708984375
Validation loss: 2.890129784742991

Epoch: 5| Step: 5
Training loss: 3.107640027999878
Validation loss: 2.887551575899124

Epoch: 5| Step: 6
Training loss: 2.7597270011901855
Validation loss: 2.8830094734827676

Epoch: 5| Step: 7
Training loss: 3.5563271045684814
Validation loss: 2.8796752393245697

Epoch: 5| Step: 8
Training loss: 2.5780274868011475
Validation loss: 2.876734028259913

Epoch: 5| Step: 9
Training loss: 2.442577838897705
Validation loss: 2.8743268648783364

Epoch: 5| Step: 10
Training loss: 3.555011034011841
Validation loss: 2.8713439305623374

Epoch: 5| Step: 11
Training loss: 5.165003776550293
Validation loss: 2.867311308781306

Epoch: 41| Step: 0
Training loss: 3.013772487640381
Validation loss: 2.8634251852830253

Epoch: 5| Step: 1
Training loss: 3.2203564643859863
Validation loss: 2.8608055810133615

Epoch: 5| Step: 2
Training loss: 3.6046433448791504
Validation loss: 2.8576949139436087

Epoch: 5| Step: 3
Training loss: 2.7171387672424316
Validation loss: 2.854736973841985

Epoch: 5| Step: 4
Training loss: 2.8200817108154297
Validation loss: 2.851039777199427

Epoch: 5| Step: 5
Training loss: 2.476027011871338
Validation loss: 2.846749464670817

Epoch: 5| Step: 6
Training loss: 3.699404239654541
Validation loss: 2.8452940781911216

Epoch: 5| Step: 7
Training loss: 3.040451765060425
Validation loss: 2.8398719231287637

Epoch: 5| Step: 8
Training loss: 2.793879985809326
Validation loss: 2.8368084828058877

Epoch: 5| Step: 9
Training loss: 3.260619640350342
Validation loss: 2.8334726095199585

Epoch: 5| Step: 10
Training loss: 2.894808053970337
Validation loss: 2.8306513130664825

Epoch: 5| Step: 11
Training loss: 3.3572068214416504
Validation loss: 2.8272490004698434

Epoch: 42| Step: 0
Training loss: 3.0570931434631348
Validation loss: 2.822467625141144

Epoch: 5| Step: 1
Training loss: 2.9136407375335693
Validation loss: 2.819785863161087

Epoch: 5| Step: 2
Training loss: 3.5743184089660645
Validation loss: 2.8179226418336234

Epoch: 5| Step: 3
Training loss: 2.728809356689453
Validation loss: 2.8152334491411843

Epoch: 5| Step: 4
Training loss: 3.219250440597534
Validation loss: 2.811085273822149

Epoch: 5| Step: 5
Training loss: 3.0513007640838623
Validation loss: 2.820201575756073

Epoch: 5| Step: 6
Training loss: 3.033669948577881
Validation loss: 2.806013618906339

Epoch: 5| Step: 7
Training loss: 2.5890865325927734
Validation loss: 2.802364389101664

Epoch: 5| Step: 8
Training loss: 2.9107666015625
Validation loss: 2.8033752044041953

Epoch: 5| Step: 9
Training loss: 3.448085308074951
Validation loss: 2.7984957297643027

Epoch: 5| Step: 10
Training loss: 2.6700406074523926
Validation loss: 2.792795568704605

Epoch: 5| Step: 11
Training loss: 2.9749107360839844
Validation loss: 2.791292558113734

Epoch: 43| Step: 0
Training loss: 3.1500344276428223
Validation loss: 2.7919842104117074

Epoch: 5| Step: 1
Training loss: 2.6648786067962646
Validation loss: 2.789452999830246

Epoch: 5| Step: 2
Training loss: 2.912933111190796
Validation loss: 2.7834507624308267

Epoch: 5| Step: 3
Training loss: 3.4492504596710205
Validation loss: 2.7789420088132224

Epoch: 5| Step: 4
Training loss: 2.638603925704956
Validation loss: 2.7754558523495994

Epoch: 5| Step: 5
Training loss: 3.3867766857147217
Validation loss: 2.771985719601313

Epoch: 5| Step: 6
Training loss: 2.7262656688690186
Validation loss: 2.771503488222758

Epoch: 5| Step: 7
Training loss: 2.5816524028778076
Validation loss: 2.76816326379776

Epoch: 5| Step: 8
Training loss: 3.238616943359375
Validation loss: 2.764725903669993

Epoch: 5| Step: 9
Training loss: 2.8429627418518066
Validation loss: 2.7599888145923615

Epoch: 5| Step: 10
Training loss: 3.4085726737976074
Validation loss: 2.756346066792806

Epoch: 5| Step: 11
Training loss: 2.138141632080078
Validation loss: 2.7532537281513214

Epoch: 44| Step: 0
Training loss: 3.048597812652588
Validation loss: 2.7506129344304404

Epoch: 5| Step: 1
Training loss: 2.804443597793579
Validation loss: 2.7473267912864685

Epoch: 5| Step: 2
Training loss: 2.9346020221710205
Validation loss: 2.7449564337730408

Epoch: 5| Step: 3
Training loss: 2.7586605548858643
Validation loss: 2.7410498758157096

Epoch: 5| Step: 4
Training loss: 2.8385066986083984
Validation loss: 2.737898757060369

Epoch: 5| Step: 5
Training loss: 3.403722047805786
Validation loss: 2.73545303940773

Epoch: 5| Step: 6
Training loss: 3.3244857788085938
Validation loss: 2.731762776772181

Epoch: 5| Step: 7
Training loss: 2.9471805095672607
Validation loss: 2.730083425839742

Epoch: 5| Step: 8
Training loss: 2.81807017326355
Validation loss: 2.726486454407374

Epoch: 5| Step: 9
Training loss: 3.3874640464782715
Validation loss: 2.7225147783756256

Epoch: 5| Step: 10
Training loss: 2.109945058822632
Validation loss: 2.719001809755961

Epoch: 5| Step: 11
Training loss: 3.1006953716278076
Validation loss: 2.7151363591353097

Epoch: 45| Step: 0
Training loss: 2.3085007667541504
Validation loss: 2.7133903205394745

Epoch: 5| Step: 1
Training loss: 2.877030849456787
Validation loss: 2.712047745784124

Epoch: 5| Step: 2
Training loss: 3.2964560985565186
Validation loss: 2.709235519170761

Epoch: 5| Step: 3
Training loss: 2.9517455101013184
Validation loss: 2.7081984480222068

Epoch: 5| Step: 4
Training loss: 3.0139057636260986
Validation loss: 2.7077583471934

Epoch: 5| Step: 5
Training loss: 3.176910877227783
Validation loss: 2.711857110261917

Epoch: 5| Step: 6
Training loss: 2.9995646476745605
Validation loss: 2.753018150726954

Epoch: 5| Step: 7
Training loss: 2.899245023727417
Validation loss: 2.7380343278249106

Epoch: 5| Step: 8
Training loss: 2.1622490882873535
Validation loss: 2.6911404927571616

Epoch: 5| Step: 9
Training loss: 3.3876044750213623
Validation loss: 2.689127335945765

Epoch: 5| Step: 10
Training loss: 3.225764036178589
Validation loss: 2.68859726190567

Epoch: 5| Step: 11
Training loss: 1.4218541383743286
Validation loss: 2.6864883601665497

Epoch: 46| Step: 0
Training loss: 2.225524425506592
Validation loss: 2.6867399414380393

Epoch: 5| Step: 1
Training loss: 3.5248401165008545
Validation loss: 2.688419759273529

Epoch: 5| Step: 2
Training loss: 2.9622840881347656
Validation loss: 2.684039225180944

Epoch: 5| Step: 3
Training loss: 2.4340720176696777
Validation loss: 2.680158237616221

Epoch: 5| Step: 4
Training loss: 3.4789466857910156
Validation loss: 2.6853086153666177

Epoch: 5| Step: 5
Training loss: 2.492122173309326
Validation loss: 2.675911774237951

Epoch: 5| Step: 6
Training loss: 2.3999810218811035
Validation loss: 2.668788621822993

Epoch: 5| Step: 7
Training loss: 2.8539276123046875
Validation loss: 2.665057450532913

Epoch: 5| Step: 8
Training loss: 3.163566827774048
Validation loss: 2.661579961578051

Epoch: 5| Step: 9
Training loss: 2.809250831604004
Validation loss: 2.658965746561686

Epoch: 5| Step: 10
Training loss: 3.341770887374878
Validation loss: 2.6553665697574615

Epoch: 5| Step: 11
Training loss: 2.631669044494629
Validation loss: 2.6491033931573233

Epoch: 47| Step: 0
Training loss: 3.1122536659240723
Validation loss: 2.645946115255356

Epoch: 5| Step: 1
Training loss: 2.4538116455078125
Validation loss: 2.642968863248825

Epoch: 5| Step: 2
Training loss: 2.849871873855591
Validation loss: 2.639801561832428

Epoch: 5| Step: 3
Training loss: 3.1740329265594482
Validation loss: 2.637227306763331

Epoch: 5| Step: 4
Training loss: 2.4308109283447266
Validation loss: 2.6302084028720856

Epoch: 5| Step: 5
Training loss: 2.598051071166992
Validation loss: 2.628384123245875

Epoch: 5| Step: 6
Training loss: 2.2558658123016357
Validation loss: 2.6267629067103067

Epoch: 5| Step: 7
Training loss: 2.7360570430755615
Validation loss: 2.6223517060279846

Epoch: 5| Step: 8
Training loss: 3.6611886024475098
Validation loss: 2.6197671393553414

Epoch: 5| Step: 9
Training loss: 2.782975196838379
Validation loss: 2.616772542397181

Epoch: 5| Step: 10
Training loss: 3.03462290763855
Validation loss: 2.613189240296682

Epoch: 5| Step: 11
Training loss: 3.1232986450195312
Validation loss: 2.610075424114863

Epoch: 48| Step: 0
Training loss: 3.587883472442627
Validation loss: 2.6060905754566193

Epoch: 5| Step: 1
Training loss: 2.6079647541046143
Validation loss: 2.6023335456848145

Epoch: 5| Step: 2
Training loss: 3.1053247451782227
Validation loss: 2.598574976126353

Epoch: 5| Step: 3
Training loss: 2.219841718673706
Validation loss: 2.5940129458904266

Epoch: 5| Step: 4
Training loss: 2.9196577072143555
Validation loss: 2.588370382785797

Epoch: 5| Step: 5
Training loss: 2.3074135780334473
Validation loss: 2.588536928097407

Epoch: 5| Step: 6
Training loss: 2.4392335414886475
Validation loss: 2.5907323161760965

Epoch: 5| Step: 7
Training loss: 3.0128703117370605
Validation loss: 2.593865538636843

Epoch: 5| Step: 8
Training loss: 2.8467278480529785
Validation loss: 2.5805014173189798

Epoch: 5| Step: 9
Training loss: 3.0905239582061768
Validation loss: 2.5767535070578256

Epoch: 5| Step: 10
Training loss: 2.7120919227600098
Validation loss: 2.572192132472992

Epoch: 5| Step: 11
Training loss: 2.2071714401245117
Validation loss: 2.5689945220947266

Epoch: 49| Step: 0
Training loss: 2.670628786087036
Validation loss: 2.5673083563645682

Epoch: 5| Step: 1
Training loss: 2.497514247894287
Validation loss: 2.56616081794103

Epoch: 5| Step: 2
Training loss: 2.6168923377990723
Validation loss: 2.563497081398964

Epoch: 5| Step: 3
Training loss: 2.482907772064209
Validation loss: 2.5617476602395377

Epoch: 5| Step: 4
Training loss: 2.7851686477661133
Validation loss: 2.5581664045651755

Epoch: 5| Step: 5
Training loss: 3.3705992698669434
Validation loss: 2.5517515937487283

Epoch: 5| Step: 6
Training loss: 2.9466633796691895
Validation loss: 2.5484227339426675

Epoch: 5| Step: 7
Training loss: 2.2499747276306152
Validation loss: 2.5475883881251016

Epoch: 5| Step: 8
Training loss: 3.24406361579895
Validation loss: 2.5455366373062134

Epoch: 5| Step: 9
Training loss: 3.0387721061706543
Validation loss: 2.5450791120529175

Epoch: 5| Step: 10
Training loss: 2.117506742477417
Validation loss: 2.5438061455885568

Epoch: 5| Step: 11
Training loss: 3.613954782485962
Validation loss: 2.536968241135279

Epoch: 50| Step: 0
Training loss: 2.290221929550171
Validation loss: 2.5567966401576996

Epoch: 5| Step: 1
Training loss: 3.0314431190490723
Validation loss: 2.5697443981965384

Epoch: 5| Step: 2
Training loss: 2.9776761531829834
Validation loss: 2.572058548529943

Epoch: 5| Step: 3
Training loss: 2.7759392261505127
Validation loss: 2.5625127653280892

Epoch: 5| Step: 4
Training loss: 2.004805326461792
Validation loss: 2.539546330769857

Epoch: 5| Step: 5
Training loss: 2.4484214782714844
Validation loss: 2.5262094040711722

Epoch: 5| Step: 6
Training loss: 2.1079330444335938
Validation loss: 2.52059738834699

Epoch: 5| Step: 7
Training loss: 3.5039095878601074
Validation loss: 2.5203627894322076

Epoch: 5| Step: 8
Training loss: 3.048558235168457
Validation loss: 2.520674705505371

Epoch: 5| Step: 9
Training loss: 2.8032519817352295
Validation loss: 2.5174620846907296

Epoch: 5| Step: 10
Training loss: 2.9614624977111816
Validation loss: 2.5117477774620056

Epoch: 5| Step: 11
Training loss: 3.4925918579101562
Validation loss: 2.504123409589132

Epoch: 51| Step: 0
Training loss: 3.0498855113983154
Validation loss: 2.504952003558477

Epoch: 5| Step: 1
Training loss: 2.397642135620117
Validation loss: 2.5082037250200906

Epoch: 5| Step: 2
Training loss: 2.799994945526123
Validation loss: 2.5042903621991477

Epoch: 5| Step: 3
Training loss: 2.934844493865967
Validation loss: 2.4963809053103128

Epoch: 5| Step: 4
Training loss: 2.7040951251983643
Validation loss: 2.4928545455137887

Epoch: 5| Step: 5
Training loss: 2.40183687210083
Validation loss: 2.4874212443828583

Epoch: 5| Step: 6
Training loss: 2.658752202987671
Validation loss: 2.48752494653066

Epoch: 5| Step: 7
Training loss: 2.2313971519470215
Validation loss: 2.4832060734430947

Epoch: 5| Step: 8
Training loss: 2.9743361473083496
Validation loss: 2.4831639329592385

Epoch: 5| Step: 9
Training loss: 2.381840467453003
Validation loss: 2.479475900530815

Epoch: 5| Step: 10
Training loss: 3.0625720024108887
Validation loss: 2.4747460583845773

Epoch: 5| Step: 11
Training loss: 2.324282169342041
Validation loss: 2.472888787587484

Epoch: 52| Step: 0
Training loss: 2.546875
Validation loss: 2.4697086960077286

Epoch: 5| Step: 1
Training loss: 2.388294219970703
Validation loss: 2.464696874221166

Epoch: 5| Step: 2
Training loss: 3.0798873901367188
Validation loss: 2.464378386735916

Epoch: 5| Step: 3
Training loss: 3.033621311187744
Validation loss: 2.4655310809612274

Epoch: 5| Step: 4
Training loss: 2.7662224769592285
Validation loss: 2.473991413911184

Epoch: 5| Step: 5
Training loss: 2.8702876567840576
Validation loss: 2.4768639703591666

Epoch: 5| Step: 6
Training loss: 2.4390525817871094
Validation loss: 2.4853640099366507

Epoch: 5| Step: 7
Training loss: 2.2234411239624023
Validation loss: 2.4636575281620026

Epoch: 5| Step: 8
Training loss: 2.764939785003662
Validation loss: 2.4524972637494407

Epoch: 5| Step: 9
Training loss: 2.745384454727173
Validation loss: 2.4493457973003387

Epoch: 5| Step: 10
Training loss: 2.3478386402130127
Validation loss: 2.448978533347448

Epoch: 5| Step: 11
Training loss: 2.4126458168029785
Validation loss: 2.4500602334737778

Epoch: 53| Step: 0
Training loss: 3.0779738426208496
Validation loss: 2.4526226818561554

Epoch: 5| Step: 1
Training loss: 2.4053115844726562
Validation loss: 2.453755875428518

Epoch: 5| Step: 2
Training loss: 2.61865496635437
Validation loss: 2.452031453450521

Epoch: 5| Step: 3
Training loss: 3.0619423389434814
Validation loss: 2.4427356918652854

Epoch: 5| Step: 4
Training loss: 2.5770773887634277
Validation loss: 2.43770424524943

Epoch: 5| Step: 5
Training loss: 2.605675220489502
Validation loss: 2.431110660235087

Epoch: 5| Step: 6
Training loss: 2.6410725116729736
Validation loss: 2.4271459380785623

Epoch: 5| Step: 7
Training loss: 2.1364433765411377
Validation loss: 2.4193363388379416

Epoch: 5| Step: 8
Training loss: 2.300950050354004
Validation loss: 2.421721781293551

Epoch: 5| Step: 9
Training loss: 2.4860639572143555
Validation loss: 2.443204621473948

Epoch: 5| Step: 10
Training loss: 2.776231050491333
Validation loss: 2.4702996412913003

Epoch: 5| Step: 11
Training loss: 3.9151220321655273
Validation loss: 2.4741722643375397

Epoch: 54| Step: 0
Training loss: 2.3930633068084717
Validation loss: 2.450655907392502

Epoch: 5| Step: 1
Training loss: 2.146043300628662
Validation loss: 2.407515545686086

Epoch: 5| Step: 2
Training loss: 2.596778392791748
Validation loss: 2.4036123553911843

Epoch: 5| Step: 3
Training loss: 2.5880720615386963
Validation loss: 2.405809928973516

Epoch: 5| Step: 4
Training loss: 2.499377727508545
Validation loss: 2.4076738754908242

Epoch: 5| Step: 5
Training loss: 3.034180164337158
Validation loss: 2.4103805124759674

Epoch: 5| Step: 6
Training loss: 2.731682777404785
Validation loss: 2.421978404124578

Epoch: 5| Step: 7
Training loss: 2.8039422035217285
Validation loss: 2.4338496923446655

Epoch: 5| Step: 8
Training loss: 2.7975761890411377
Validation loss: 2.415672183036804

Epoch: 5| Step: 9
Training loss: 2.0993120670318604
Validation loss: 2.4030210077762604

Epoch: 5| Step: 10
Training loss: 2.9512779712677
Validation loss: 2.3935485978921256

Epoch: 5| Step: 11
Training loss: 1.9937522411346436
Validation loss: 2.3850955019394555

Epoch: 55| Step: 0
Training loss: 1.8922131061553955
Validation loss: 2.381571759780248

Epoch: 5| Step: 1
Training loss: 2.505495071411133
Validation loss: 2.3785083641608558

Epoch: 5| Step: 2
Training loss: 2.326145648956299
Validation loss: 2.3721437553564706

Epoch: 5| Step: 3
Training loss: 2.556877374649048
Validation loss: 2.3937684198220572

Epoch: 5| Step: 4
Training loss: 3.4900906085968018
Validation loss: 2.394863575696945

Epoch: 5| Step: 5
Training loss: 2.8722634315490723
Validation loss: 2.3849953214327493

Epoch: 5| Step: 6
Training loss: 2.7181386947631836
Validation loss: 2.370990460117658

Epoch: 5| Step: 7
Training loss: 2.6670470237731934
Validation loss: 2.363109568754832

Epoch: 5| Step: 8
Training loss: 2.4530701637268066
Validation loss: 2.360382894674937

Epoch: 5| Step: 9
Training loss: 2.372389316558838
Validation loss: 2.3602796494960785

Epoch: 5| Step: 10
Training loss: 2.2522027492523193
Validation loss: 2.3573096642891564

Epoch: 5| Step: 11
Training loss: 2.6335554122924805
Validation loss: 2.357608879605929

Epoch: 56| Step: 0
Training loss: 2.7499001026153564
Validation loss: 2.3580487767855325

Epoch: 5| Step: 1
Training loss: 2.9581027030944824
Validation loss: 2.357789913813273

Epoch: 5| Step: 2
Training loss: 2.5508410930633545
Validation loss: 2.357129082083702

Epoch: 5| Step: 3
Training loss: 2.9311575889587402
Validation loss: 2.3559030642112098

Epoch: 5| Step: 4
Training loss: 2.641162157058716
Validation loss: 2.3529737989107766

Epoch: 5| Step: 5
Training loss: 1.6616284847259521
Validation loss: 2.352663775285085

Epoch: 5| Step: 6
Training loss: 2.999746799468994
Validation loss: 2.3484661877155304

Epoch: 5| Step: 7
Training loss: 2.2540316581726074
Validation loss: 2.3443625966707864

Epoch: 5| Step: 8
Training loss: 2.302827835083008
Validation loss: 2.3411554098129272

Epoch: 5| Step: 9
Training loss: 2.5638294219970703
Validation loss: 2.338766763607661

Epoch: 5| Step: 10
Training loss: 2.172163724899292
Validation loss: 2.3331872125466666

Epoch: 5| Step: 11
Training loss: 2.7027430534362793
Validation loss: 2.330739210049311

Epoch: 57| Step: 0
Training loss: 3.084102153778076
Validation loss: 2.331645945707957

Epoch: 5| Step: 1
Training loss: 2.061082124710083
Validation loss: 2.3289780418078103

Epoch: 5| Step: 2
Training loss: 2.530874729156494
Validation loss: 2.3232931991418204

Epoch: 5| Step: 3
Training loss: 2.528811454772949
Validation loss: 2.322322736183802

Epoch: 5| Step: 4
Training loss: 2.79929780960083
Validation loss: 2.322577719887098

Epoch: 5| Step: 5
Training loss: 2.3328464031219482
Validation loss: 2.32999125123024

Epoch: 5| Step: 6
Training loss: 1.9148257970809937
Validation loss: 2.338910013437271

Epoch: 5| Step: 7
Training loss: 2.537621021270752
Validation loss: 2.3334414710601172

Epoch: 5| Step: 8
Training loss: 2.6206674575805664
Validation loss: 2.3154700497786203

Epoch: 5| Step: 9
Training loss: 2.6980385780334473
Validation loss: 2.3050273060798645

Epoch: 5| Step: 10
Training loss: 2.3495872020721436
Validation loss: 2.3014986415704093

Epoch: 5| Step: 11
Training loss: 2.0546531677246094
Validation loss: 2.3079631527264914

Epoch: 58| Step: 0
Training loss: 2.285738706588745
Validation loss: 2.3032512913147607

Epoch: 5| Step: 1
Training loss: 2.609665870666504
Validation loss: 2.3037766913572946

Epoch: 5| Step: 2
Training loss: 2.536220073699951
Validation loss: 2.302382990717888

Epoch: 5| Step: 3
Training loss: 2.522667407989502
Validation loss: 2.304731329282125

Epoch: 5| Step: 4
Training loss: 2.855093479156494
Validation loss: 2.29790132244428

Epoch: 5| Step: 5
Training loss: 2.0326831340789795
Validation loss: 2.2965660393238068

Epoch: 5| Step: 6
Training loss: 2.562527894973755
Validation loss: 2.3024426947037377

Epoch: 5| Step: 7
Training loss: 2.5703043937683105
Validation loss: 2.2965615689754486

Epoch: 5| Step: 8
Training loss: 2.473991870880127
Validation loss: 2.2926861941814423

Epoch: 5| Step: 9
Training loss: 2.1222429275512695
Validation loss: 2.2843237618605294

Epoch: 5| Step: 10
Training loss: 2.5213534832000732
Validation loss: 2.2853251099586487

Epoch: 5| Step: 11
Training loss: 2.2871885299682617
Validation loss: 2.282196501890818

Epoch: 59| Step: 0
Training loss: 2.5868043899536133
Validation loss: 2.2821452617645264

Epoch: 5| Step: 1
Training loss: 3.0023880004882812
Validation loss: 2.2832454244295755

Epoch: 5| Step: 2
Training loss: 2.0266354084014893
Validation loss: 2.280986040830612

Epoch: 5| Step: 3
Training loss: 2.43023419380188
Validation loss: 2.2783830612897873

Epoch: 5| Step: 4
Training loss: 2.5646040439605713
Validation loss: 2.2787749568621316

Epoch: 5| Step: 5
Training loss: 2.3395323753356934
Validation loss: 2.2711586356163025

Epoch: 5| Step: 6
Training loss: 2.3176703453063965
Validation loss: 2.272867798805237

Epoch: 5| Step: 7
Training loss: 2.440355062484741
Validation loss: 2.2677584290504456

Epoch: 5| Step: 8
Training loss: 2.2650303840637207
Validation loss: 2.2649874488512673

Epoch: 5| Step: 9
Training loss: 2.747824192047119
Validation loss: 2.2622231592734656

Epoch: 5| Step: 10
Training loss: 2.0195345878601074
Validation loss: 2.2592825392882028

Epoch: 5| Step: 11
Training loss: 2.4557294845581055
Validation loss: 2.2597280889749527

Epoch: 60| Step: 0
Training loss: 2.477834701538086
Validation loss: 2.2548930943012238

Epoch: 5| Step: 1
Training loss: 2.462902545928955
Validation loss: 2.2513902336359024

Epoch: 5| Step: 2
Training loss: 2.723628282546997
Validation loss: 2.2503394931554794

Epoch: 5| Step: 3
Training loss: 1.5915569067001343
Validation loss: 2.2474782864252725

Epoch: 5| Step: 4
Training loss: 2.2187962532043457
Validation loss: 2.245567182699839

Epoch: 5| Step: 5
Training loss: 3.07171368598938
Validation loss: 2.2495012084643045

Epoch: 5| Step: 6
Training loss: 2.29032564163208
Validation loss: 2.2382913728555045

Epoch: 5| Step: 7
Training loss: 2.543623447418213
Validation loss: 2.239077349503835

Epoch: 5| Step: 8
Training loss: 2.3169333934783936
Validation loss: 2.236911798516909

Epoch: 5| Step: 9
Training loss: 2.429319381713867
Validation loss: 2.235485757390658

Epoch: 5| Step: 10
Training loss: 2.452418804168701
Validation loss: 2.2323539157708487

Epoch: 5| Step: 11
Training loss: 1.4165117740631104
Validation loss: 2.2324631909529367

Epoch: 61| Step: 0
Training loss: 2.4038705825805664
Validation loss: 2.229747250676155

Epoch: 5| Step: 1
Training loss: 2.31197190284729
Validation loss: 2.237570270895958

Epoch: 5| Step: 2
Training loss: 1.8760391473770142
Validation loss: 2.2521180858214698

Epoch: 5| Step: 3
Training loss: 2.6516430377960205
Validation loss: 2.250855877995491

Epoch: 5| Step: 4
Training loss: 2.5101513862609863
Validation loss: 2.2600354899962745

Epoch: 5| Step: 5
Training loss: 2.1547975540161133
Validation loss: 2.2757488787174225

Epoch: 5| Step: 6
Training loss: 2.1004135608673096
Validation loss: 2.2756279905637107

Epoch: 5| Step: 7
Training loss: 3.4656455516815186
Validation loss: 2.259300798177719

Epoch: 5| Step: 8
Training loss: 2.0196845531463623
Validation loss: 2.214409972230593

Epoch: 5| Step: 9
Training loss: 2.6655972003936768
Validation loss: 2.2030053436756134

Epoch: 5| Step: 10
Training loss: 2.392482042312622
Validation loss: 2.2147683600584664

Epoch: 5| Step: 11
Training loss: 2.508876085281372
Validation loss: 2.2217167715231576

Epoch: 62| Step: 0
Training loss: 2.595665216445923
Validation loss: 2.2213310996691384

Epoch: 5| Step: 1
Training loss: 2.2079787254333496
Validation loss: 2.2318683365980783

Epoch: 5| Step: 2
Training loss: 2.262267589569092
Validation loss: 2.2403969913721085

Epoch: 5| Step: 3
Training loss: 2.7733588218688965
Validation loss: 2.2459254562854767

Epoch: 5| Step: 4
Training loss: 2.3555808067321777
Validation loss: 2.2504010001818338

Epoch: 5| Step: 5
Training loss: 2.500882625579834
Validation loss: 2.2350732684135437

Epoch: 5| Step: 6
Training loss: 2.2034244537353516
Validation loss: 2.230634262164434

Epoch: 5| Step: 7
Training loss: 2.2625412940979004
Validation loss: 2.2192253271738687

Epoch: 5| Step: 8
Training loss: 2.2270667552948
Validation loss: 2.214849665760994

Epoch: 5| Step: 9
Training loss: 2.1433444023132324
Validation loss: 2.2125603357950845

Epoch: 5| Step: 10
Training loss: 2.420459270477295
Validation loss: 2.2093308021624884

Epoch: 5| Step: 11
Training loss: 3.5039806365966797
Validation loss: 2.2084210167328515

Epoch: 63| Step: 0
Training loss: 2.0635018348693848
Validation loss: 2.204412450393041

Epoch: 5| Step: 1
Training loss: 2.683743476867676
Validation loss: 2.2025180558363595

Epoch: 5| Step: 2
Training loss: 2.443309783935547
Validation loss: 2.2009905825058618

Epoch: 5| Step: 3
Training loss: 2.7225353717803955
Validation loss: 2.1987138936916986

Epoch: 5| Step: 4
Training loss: 2.4646012783050537
Validation loss: 2.1974312365055084

Epoch: 5| Step: 5
Training loss: 2.147120475769043
Validation loss: 2.2001607418060303

Epoch: 5| Step: 6
Training loss: 2.5189616680145264
Validation loss: 2.1943304439385733

Epoch: 5| Step: 7
Training loss: 2.034834384918213
Validation loss: 2.194977636138598

Epoch: 5| Step: 8
Training loss: 2.596073865890503
Validation loss: 2.188808709383011

Epoch: 5| Step: 9
Training loss: 1.7361361980438232
Validation loss: 2.182149514555931

Epoch: 5| Step: 10
Training loss: 2.626081705093384
Validation loss: 2.1856025705734887

Epoch: 5| Step: 11
Training loss: 1.4646971225738525
Validation loss: 2.18214084704717

Epoch: 64| Step: 0
Training loss: 2.769110918045044
Validation loss: 2.180421367287636

Epoch: 5| Step: 1
Training loss: 1.8314319849014282
Validation loss: 2.179202521840731

Epoch: 5| Step: 2
Training loss: 2.1279242038726807
Validation loss: 2.1775818218787513

Epoch: 5| Step: 3
Training loss: 2.198441982269287
Validation loss: 2.174963484207789

Epoch: 5| Step: 4
Training loss: 2.421553611755371
Validation loss: 2.1759835680325827

Epoch: 5| Step: 5
Training loss: 1.9511770009994507
Validation loss: 2.1749683618545532

Epoch: 5| Step: 6
Training loss: 2.7771549224853516
Validation loss: 2.1712836027145386

Epoch: 5| Step: 7
Training loss: 2.056151866912842
Validation loss: 2.162980412443479

Epoch: 5| Step: 8
Training loss: 3.0906593799591064
Validation loss: 2.1695038874944053

Epoch: 5| Step: 9
Training loss: 2.4460556507110596
Validation loss: 2.1636925687392554

Epoch: 5| Step: 10
Training loss: 2.294332981109619
Validation loss: 2.1643443256616592

Epoch: 5| Step: 11
Training loss: 0.7969878315925598
Validation loss: 2.1684532264868417

Epoch: 65| Step: 0
Training loss: 2.338900089263916
Validation loss: 2.172323559721311

Epoch: 5| Step: 1
Training loss: 2.679565906524658
Validation loss: 2.16971388955911

Epoch: 5| Step: 2
Training loss: 2.480302572250366
Validation loss: 2.1702667077382407

Epoch: 5| Step: 3
Training loss: 1.8231127262115479
Validation loss: 2.168514668941498

Epoch: 5| Step: 4
Training loss: 2.330972194671631
Validation loss: 2.169208566347758

Epoch: 5| Step: 5
Training loss: 2.215541124343872
Validation loss: 2.1710194249947867

Epoch: 5| Step: 6
Training loss: 2.325099468231201
Validation loss: 2.1696449667215347

Epoch: 5| Step: 7
Training loss: 2.322723388671875
Validation loss: 2.1675491283337274

Epoch: 5| Step: 8
Training loss: 2.4287078380584717
Validation loss: 2.166979119181633

Epoch: 5| Step: 9
Training loss: 2.2056403160095215
Validation loss: 2.1619655390580497

Epoch: 5| Step: 10
Training loss: 2.2972030639648438
Validation loss: 2.1577477355798087

Epoch: 5| Step: 11
Training loss: 3.0008389949798584
Validation loss: 2.154519726832708

Epoch: 66| Step: 0
Training loss: 2.4897451400756836
Validation loss: 2.1496922622124353

Epoch: 5| Step: 1
Training loss: 2.6858408451080322
Validation loss: 2.146848142147064

Epoch: 5| Step: 2
Training loss: 2.5407018661499023
Validation loss: 2.148193677266439

Epoch: 5| Step: 3
Training loss: 2.047274589538574
Validation loss: 2.1474715570608773

Epoch: 5| Step: 4
Training loss: 2.2347073554992676
Validation loss: 2.143708815177282

Epoch: 5| Step: 5
Training loss: 2.759132146835327
Validation loss: 2.140961597363154

Epoch: 5| Step: 6
Training loss: 1.8083865642547607
Validation loss: 2.1343106975158057

Epoch: 5| Step: 7
Training loss: 1.807141900062561
Validation loss: 2.134594147404035

Epoch: 5| Step: 8
Training loss: 2.278726100921631
Validation loss: 2.1371407409509025

Epoch: 5| Step: 9
Training loss: 2.1267411708831787
Validation loss: 2.1349484970172248

Epoch: 5| Step: 10
Training loss: 2.375972032546997
Validation loss: 2.1442077656586966

Epoch: 5| Step: 11
Training loss: 3.0917415618896484
Validation loss: 2.1379447678724923

Epoch: 67| Step: 0
Training loss: 2.4165844917297363
Validation loss: 2.1464243630568185

Epoch: 5| Step: 1
Training loss: 1.8039194345474243
Validation loss: 2.155103623867035

Epoch: 5| Step: 2
Training loss: 2.439600944519043
Validation loss: 2.1655247509479523

Epoch: 5| Step: 3
Training loss: 1.871408224105835
Validation loss: 2.1628525058428445

Epoch: 5| Step: 4
Training loss: 3.2766737937927246
Validation loss: 2.1586647778749466

Epoch: 5| Step: 5
Training loss: 1.9289190769195557
Validation loss: 2.1576999376217523

Epoch: 5| Step: 6
Training loss: 1.8086059093475342
Validation loss: 2.142722358306249

Epoch: 5| Step: 7
Training loss: 2.8904271125793457
Validation loss: 2.1216565469900766

Epoch: 5| Step: 8
Training loss: 2.4312429428100586
Validation loss: 2.117136299610138

Epoch: 5| Step: 9
Training loss: 2.234292984008789
Validation loss: 2.117433493336042

Epoch: 5| Step: 10
Training loss: 2.5441393852233887
Validation loss: 2.123708506425222

Epoch: 5| Step: 11
Training loss: 0.9634275436401367
Validation loss: 2.128472700715065

Epoch: 68| Step: 0
Training loss: 1.9096174240112305
Validation loss: 2.123985638221105

Epoch: 5| Step: 1
Training loss: 1.9688152074813843
Validation loss: 2.1262963116168976

Epoch: 5| Step: 2
Training loss: 2.5840160846710205
Validation loss: 2.119890217979749

Epoch: 5| Step: 3
Training loss: 2.915454149246216
Validation loss: 2.121745223800341

Epoch: 5| Step: 4
Training loss: 2.341343879699707
Validation loss: 2.1222113519906998

Epoch: 5| Step: 5
Training loss: 1.8068822622299194
Validation loss: 2.120722139875094

Epoch: 5| Step: 6
Training loss: 2.2189598083496094
Validation loss: 2.1169695456822715

Epoch: 5| Step: 7
Training loss: 2.404723644256592
Validation loss: 2.1101874758799872

Epoch: 5| Step: 8
Training loss: 2.852074384689331
Validation loss: 2.1113181859254837

Epoch: 5| Step: 9
Training loss: 1.3993396759033203
Validation loss: 2.10906575123469

Epoch: 5| Step: 10
Training loss: 2.819683074951172
Validation loss: 2.1070132553577423

Epoch: 5| Step: 11
Training loss: 1.814995527267456
Validation loss: 2.107746869325638

Epoch: 69| Step: 0
Training loss: 1.618956208229065
Validation loss: 2.0946737130482993

Epoch: 5| Step: 1
Training loss: 2.164106845855713
Validation loss: 2.095250830054283

Epoch: 5| Step: 2
Training loss: 2.067166805267334
Validation loss: 2.10493957499663

Epoch: 5| Step: 3
Training loss: 2.6388704776763916
Validation loss: 2.1116762260595956

Epoch: 5| Step: 4
Training loss: 2.752267837524414
Validation loss: 2.132892996072769

Epoch: 5| Step: 5
Training loss: 2.5912251472473145
Validation loss: 2.1245386550823846

Epoch: 5| Step: 6
Training loss: 2.1493024826049805
Validation loss: 2.119643891851107

Epoch: 5| Step: 7
Training loss: 1.9166934490203857
Validation loss: 2.126371368765831

Epoch: 5| Step: 8
Training loss: 2.387575387954712
Validation loss: 2.1118706862131753

Epoch: 5| Step: 9
Training loss: 2.583519458770752
Validation loss: 2.1267630060513816

Epoch: 5| Step: 10
Training loss: 2.170976161956787
Validation loss: 2.1042919208606086

Epoch: 5| Step: 11
Training loss: 2.9322288036346436
Validation loss: 2.1174935698509216

Epoch: 70| Step: 0
Training loss: 2.1555709838867188
Validation loss: 2.103717401623726

Epoch: 5| Step: 1
Training loss: 2.2318196296691895
Validation loss: 2.095490942398707

Epoch: 5| Step: 2
Training loss: 2.394909381866455
Validation loss: 2.0889516125122705

Epoch: 5| Step: 3
Training loss: 1.9402477741241455
Validation loss: 2.0838919430971146

Epoch: 5| Step: 4
Training loss: 2.213630199432373
Validation loss: 2.084851493438085

Epoch: 5| Step: 5
Training loss: 2.050778865814209
Validation loss: 2.0836276908715567

Epoch: 5| Step: 6
Training loss: 2.7658448219299316
Validation loss: 2.0887903968493142

Epoch: 5| Step: 7
Training loss: 2.743013858795166
Validation loss: 2.1001183142264686

Epoch: 5| Step: 8
Training loss: 2.340554714202881
Validation loss: 2.097238560517629

Epoch: 5| Step: 9
Training loss: 2.3787498474121094
Validation loss: 2.1065550396839776

Epoch: 5| Step: 10
Training loss: 1.8066688776016235
Validation loss: 2.1053925504287085

Epoch: 5| Step: 11
Training loss: 1.5207206010818481
Validation loss: 2.1059153030316033

Epoch: 71| Step: 0
Training loss: 2.268450975418091
Validation loss: 2.088641345500946

Epoch: 5| Step: 1
Training loss: 2.1179287433624268
Validation loss: 2.082133799791336

Epoch: 5| Step: 2
Training loss: 1.8825006484985352
Validation loss: 2.0755234360694885

Epoch: 5| Step: 3
Training loss: 2.1688039302825928
Validation loss: 2.0782553056875863

Epoch: 5| Step: 4
Training loss: 2.364218235015869
Validation loss: 2.0800198117891946

Epoch: 5| Step: 5
Training loss: 2.207477331161499
Validation loss: 2.0755732705195746

Epoch: 5| Step: 6
Training loss: 2.1092352867126465
Validation loss: 2.07759161790212

Epoch: 5| Step: 7
Training loss: 2.4667153358459473
Validation loss: 2.0716957102219262

Epoch: 5| Step: 8
Training loss: 2.2772040367126465
Validation loss: 2.076234449942907

Epoch: 5| Step: 9
Training loss: 2.2632102966308594
Validation loss: 2.0795822540918985

Epoch: 5| Step: 10
Training loss: 2.271137237548828
Validation loss: 2.07920249303182

Epoch: 5| Step: 11
Training loss: 3.324016809463501
Validation loss: 2.071122353275617

Epoch: 72| Step: 0
Training loss: 2.038804292678833
Validation loss: 2.0746657898028693

Epoch: 5| Step: 1
Training loss: 3.0436503887176514
Validation loss: 2.06541441877683

Epoch: 5| Step: 2
Training loss: 2.077266216278076
Validation loss: 2.0624067236979804

Epoch: 5| Step: 3
Training loss: 2.0450961589813232
Validation loss: 2.066043416659037

Epoch: 5| Step: 4
Training loss: 2.0737507343292236
Validation loss: 2.056516259908676

Epoch: 5| Step: 5
Training loss: 1.8592090606689453
Validation loss: 2.064435417453448

Epoch: 5| Step: 6
Training loss: 1.8599929809570312
Validation loss: 2.058496211965879

Epoch: 5| Step: 7
Training loss: 2.5337424278259277
Validation loss: 2.0584501723448434

Epoch: 5| Step: 8
Training loss: 2.079826831817627
Validation loss: 2.0616700847943625

Epoch: 5| Step: 9
Training loss: 2.1226372718811035
Validation loss: 2.056906854112943

Epoch: 5| Step: 10
Training loss: 2.6195602416992188
Validation loss: 2.059402748942375

Epoch: 5| Step: 11
Training loss: 2.9358737468719482
Validation loss: 2.0701230665047965

Epoch: 73| Step: 0
Training loss: 2.296433925628662
Validation loss: 2.0849743286768594

Epoch: 5| Step: 1
Training loss: 2.3488693237304688
Validation loss: 2.0807413508494697

Epoch: 5| Step: 2
Training loss: 2.5107266902923584
Validation loss: 2.0822669516007104

Epoch: 5| Step: 3
Training loss: 1.6224594116210938
Validation loss: 2.0739006251096725

Epoch: 5| Step: 4
Training loss: 2.166862964630127
Validation loss: 2.0663826117912927

Epoch: 5| Step: 5
Training loss: 2.0540387630462646
Validation loss: 2.0805095434188843

Epoch: 5| Step: 6
Training loss: 2.053736448287964
Validation loss: 2.078545168042183

Epoch: 5| Step: 7
Training loss: 2.9231975078582764
Validation loss: 2.0651713212331138

Epoch: 5| Step: 8
Training loss: 2.055629014968872
Validation loss: 2.0644542078177133

Epoch: 5| Step: 9
Training loss: 2.329969644546509
Validation loss: 2.0592647592226663

Epoch: 5| Step: 10
Training loss: 2.179499387741089
Validation loss: 2.058089092373848

Epoch: 5| Step: 11
Training loss: 2.050720691680908
Validation loss: 2.0529085050026574

Epoch: 74| Step: 0
Training loss: 2.1026875972747803
Validation loss: 2.051519880692164

Epoch: 5| Step: 1
Training loss: 2.0380587577819824
Validation loss: 2.055395652850469

Epoch: 5| Step: 2
Training loss: 2.265603542327881
Validation loss: 2.0738282998402915

Epoch: 5| Step: 3
Training loss: 2.302158832550049
Validation loss: 2.0860468397537866

Epoch: 5| Step: 4
Training loss: 2.4598870277404785
Validation loss: 2.0852259397506714

Epoch: 5| Step: 5
Training loss: 2.228349208831787
Validation loss: 2.091827621062597

Epoch: 5| Step: 6
Training loss: 2.472036838531494
Validation loss: 2.0915697564681373

Epoch: 5| Step: 7
Training loss: 2.122464656829834
Validation loss: 2.0841424812873206

Epoch: 5| Step: 8
Training loss: 2.0918095111846924
Validation loss: 2.0797753632068634

Epoch: 5| Step: 9
Training loss: 1.8757379055023193
Validation loss: 2.064756765961647

Epoch: 5| Step: 10
Training loss: 2.3414478302001953
Validation loss: 2.069255659977595

Epoch: 5| Step: 11
Training loss: 2.6709389686584473
Validation loss: 2.0598335713148117

Epoch: 75| Step: 0
Training loss: 2.717550754547119
Validation loss: 2.0672035415967307

Epoch: 5| Step: 1
Training loss: 2.159350633621216
Validation loss: 2.062300910552343

Epoch: 5| Step: 2
Training loss: 2.2948172092437744
Validation loss: 2.0671370873848596

Epoch: 5| Step: 3
Training loss: 2.1871347427368164
Validation loss: 2.055596873164177

Epoch: 5| Step: 4
Training loss: 2.0404531955718994
Validation loss: 2.0606815268596015

Epoch: 5| Step: 5
Training loss: 1.9553943872451782
Validation loss: 2.0582254379987717

Epoch: 5| Step: 6
Training loss: 1.977838158607483
Validation loss: 2.0511865665515265

Epoch: 5| Step: 7
Training loss: 2.625060558319092
Validation loss: 2.0460334420204163

Epoch: 5| Step: 8
Training loss: 1.792778730392456
Validation loss: 2.0489958077669144

Epoch: 5| Step: 9
Training loss: 1.977569341659546
Validation loss: 2.046638786792755

Epoch: 5| Step: 10
Training loss: 2.411234140396118
Validation loss: 2.0428738643725715

Epoch: 5| Step: 11
Training loss: 2.8823838233947754
Validation loss: 2.057275449236234

Epoch: 76| Step: 0
Training loss: 2.1865525245666504
Validation loss: 2.0560681770245233

Epoch: 5| Step: 1
Training loss: 2.3350377082824707
Validation loss: 2.06124809384346

Epoch: 5| Step: 2
Training loss: 1.8789527416229248
Validation loss: 2.053313285112381

Epoch: 5| Step: 3
Training loss: 1.7409034967422485
Validation loss: 2.061558574438095

Epoch: 5| Step: 4
Training loss: 2.2317423820495605
Validation loss: 2.052521973848343

Epoch: 5| Step: 5
Training loss: 2.665602684020996
Validation loss: 2.0519576917092004

Epoch: 5| Step: 6
Training loss: 1.6808849573135376
Validation loss: 2.044911046822866

Epoch: 5| Step: 7
Training loss: 2.698137044906616
Validation loss: 2.03695555528005

Epoch: 5| Step: 8
Training loss: 2.57950758934021
Validation loss: 2.041802018880844

Epoch: 5| Step: 9
Training loss: 2.517570972442627
Validation loss: 2.049092302719752

Epoch: 5| Step: 10
Training loss: 1.7999718189239502
Validation loss: 2.046396171053251

Epoch: 5| Step: 11
Training loss: 1.1236577033996582
Validation loss: 2.0376373877127967

Epoch: 77| Step: 0
Training loss: 2.57328200340271
Validation loss: 2.049082880218824

Epoch: 5| Step: 1
Training loss: 1.7168400287628174
Validation loss: 2.043098598718643

Epoch: 5| Step: 2
Training loss: 2.048752784729004
Validation loss: 2.0391632715861

Epoch: 5| Step: 3
Training loss: 1.8216224908828735
Validation loss: 2.0273101727167764

Epoch: 5| Step: 4
Training loss: 2.0105717182159424
Validation loss: 2.0310976256926856

Epoch: 5| Step: 5
Training loss: 2.3517403602600098
Validation loss: 2.0246675213178

Epoch: 5| Step: 6
Training loss: 2.3369803428649902
Validation loss: 2.030744637052218

Epoch: 5| Step: 7
Training loss: 2.4359726905822754
Validation loss: 2.039493133624395

Epoch: 5| Step: 8
Training loss: 2.343461036682129
Validation loss: 2.0270308454831443

Epoch: 5| Step: 9
Training loss: 1.9349403381347656
Validation loss: 2.0318354864915213

Epoch: 5| Step: 10
Training loss: 2.345571994781494
Validation loss: 2.0297043522198996

Epoch: 5| Step: 11
Training loss: 3.292785406112671
Validation loss: 2.042944992582003

Epoch: 78| Step: 0
Training loss: 2.028594732284546
Validation loss: 2.050722151994705

Epoch: 5| Step: 1
Training loss: 2.558967113494873
Validation loss: 2.042288139462471

Epoch: 5| Step: 2
Training loss: 2.6174323558807373
Validation loss: 2.0333173970381417

Epoch: 5| Step: 3
Training loss: 2.1089630126953125
Validation loss: 2.0338981300592422

Epoch: 5| Step: 4
Training loss: 2.0818965435028076
Validation loss: 2.0285514096419015

Epoch: 5| Step: 5
Training loss: 2.3839941024780273
Validation loss: 2.036496857802073

Epoch: 5| Step: 6
Training loss: 2.0678670406341553
Validation loss: 2.030977646509806

Epoch: 5| Step: 7
Training loss: 1.9872767925262451
Validation loss: 2.0339584400256476

Epoch: 5| Step: 8
Training loss: 2.108828544616699
Validation loss: 2.029692366719246

Epoch: 5| Step: 9
Training loss: 2.155611515045166
Validation loss: 2.0335408598184586

Epoch: 5| Step: 10
Training loss: 2.011216640472412
Validation loss: 2.037446439266205

Epoch: 5| Step: 11
Training loss: 1.8316023349761963
Validation loss: 2.0507814437150955

Epoch: 79| Step: 0
Training loss: 2.0723695755004883
Validation loss: 2.050264219443003

Epoch: 5| Step: 1
Training loss: 2.493018388748169
Validation loss: 2.044989282886187

Epoch: 5| Step: 2
Training loss: 1.8602430820465088
Validation loss: 2.043503612279892

Epoch: 5| Step: 3
Training loss: 1.8657623529434204
Validation loss: 2.0356061359246573

Epoch: 5| Step: 4
Training loss: 2.115891695022583
Validation loss: 2.0391274293263755

Epoch: 5| Step: 5
Training loss: 2.2957634925842285
Validation loss: 2.0350103924671807

Epoch: 5| Step: 6
Training loss: 2.263237714767456
Validation loss: 2.0464449673891068

Epoch: 5| Step: 7
Training loss: 2.2308154106140137
Validation loss: 2.0366613070170083

Epoch: 5| Step: 8
Training loss: 1.9579464197158813
Validation loss: 2.0393042216698327

Epoch: 5| Step: 9
Training loss: 1.8294273614883423
Validation loss: 2.031923145055771

Epoch: 5| Step: 10
Training loss: 3.0886361598968506
Validation loss: 2.039199968179067

Epoch: 5| Step: 11
Training loss: 2.083005428314209
Validation loss: 2.030097226301829

Epoch: 80| Step: 0
Training loss: 2.494511604309082
Validation loss: 2.0328592409690223

Epoch: 5| Step: 1
Training loss: 2.9925544261932373
Validation loss: 2.0309727837642035

Epoch: 5| Step: 2
Training loss: 1.5054572820663452
Validation loss: 2.033655489484469

Epoch: 5| Step: 3
Training loss: 2.1628007888793945
Validation loss: 2.0408650785684586

Epoch: 5| Step: 4
Training loss: 2.0028560161590576
Validation loss: 2.0374684582153955

Epoch: 5| Step: 5
Training loss: 1.8254963159561157
Validation loss: 2.0309996406237283

Epoch: 5| Step: 6
Training loss: 1.7971820831298828
Validation loss: 2.0255895952383676

Epoch: 5| Step: 7
Training loss: 2.2597248554229736
Validation loss: 2.0277316520611444

Epoch: 5| Step: 8
Training loss: 2.1449525356292725
Validation loss: 2.0367510318756104

Epoch: 5| Step: 9
Training loss: 2.486201524734497
Validation loss: 2.0388719936211905

Epoch: 5| Step: 10
Training loss: 2.3124117851257324
Validation loss: 2.0449683517217636

Epoch: 5| Step: 11
Training loss: 3.3927271366119385
Validation loss: 2.047437071800232

Epoch: 81| Step: 0
Training loss: 2.100222110748291
Validation loss: 2.023325433333715

Epoch: 5| Step: 1
Training loss: 2.344815731048584
Validation loss: 2.0241715709368386

Epoch: 5| Step: 2
Training loss: 2.6315243244171143
Validation loss: 2.025270476937294

Epoch: 5| Step: 3
Training loss: 1.968747854232788
Validation loss: 2.032454192638397

Epoch: 5| Step: 4
Training loss: 2.1965465545654297
Validation loss: 2.0263927429914474

Epoch: 5| Step: 5
Training loss: 1.707820177078247
Validation loss: 2.0270479371150336

Epoch: 5| Step: 6
Training loss: 2.431737184524536
Validation loss: 2.027879868944486

Epoch: 5| Step: 7
Training loss: 2.17271089553833
Validation loss: 2.028679450352987

Epoch: 5| Step: 8
Training loss: 2.167839765548706
Validation loss: 2.0244420717159906

Epoch: 5| Step: 9
Training loss: 2.1942780017852783
Validation loss: 2.0257319857676825

Epoch: 5| Step: 10
Training loss: 2.0321240425109863
Validation loss: 2.0255933503309884

Epoch: 5| Step: 11
Training loss: 2.1068472862243652
Validation loss: 2.0270470480124154

Epoch: 82| Step: 0
Training loss: 2.3446044921875
Validation loss: 2.0282371093829474

Epoch: 5| Step: 1
Training loss: 2.2383041381835938
Validation loss: 2.032357861598333

Epoch: 5| Step: 2
Training loss: 2.6341545581817627
Validation loss: 2.032927324374517

Epoch: 5| Step: 3
Training loss: 2.565869092941284
Validation loss: 2.0316257625818253

Epoch: 5| Step: 4
Training loss: 2.4789798259735107
Validation loss: 2.031624346971512

Epoch: 5| Step: 5
Training loss: 2.209062099456787
Validation loss: 2.0398732324441275

Epoch: 5| Step: 6
Training loss: 1.8371398448944092
Validation loss: 2.0338742385307946

Epoch: 5| Step: 7
Training loss: 1.991823434829712
Validation loss: 2.029260570804278

Epoch: 5| Step: 8
Training loss: 1.622304916381836
Validation loss: 2.022887130578359

Epoch: 5| Step: 9
Training loss: 1.5501222610473633
Validation loss: 2.024344354867935

Epoch: 5| Step: 10
Training loss: 2.4928972721099854
Validation loss: 2.024385223786036

Epoch: 5| Step: 11
Training loss: 2.1705541610717773
Validation loss: 2.0296133359273276

Epoch: 83| Step: 0
Training loss: 2.2760720252990723
Validation loss: 2.036720092097918

Epoch: 5| Step: 1
Training loss: 2.474714517593384
Validation loss: 2.034821088115374

Epoch: 5| Step: 2
Training loss: 2.185790538787842
Validation loss: 2.04436103006204

Epoch: 5| Step: 3
Training loss: 2.0870158672332764
Validation loss: 2.0465526978174844

Epoch: 5| Step: 4
Training loss: 2.3930153846740723
Validation loss: 2.051531434059143

Epoch: 5| Step: 5
Training loss: 1.9034843444824219
Validation loss: 2.052341565489769

Epoch: 5| Step: 6
Training loss: 2.384030818939209
Validation loss: 2.053251842657725

Epoch: 5| Step: 7
Training loss: 2.302434206008911
Validation loss: 2.063619206349055

Epoch: 5| Step: 8
Training loss: 1.978771448135376
Validation loss: 2.066726118326187

Epoch: 5| Step: 9
Training loss: 2.2829105854034424
Validation loss: 2.052825669447581

Epoch: 5| Step: 10
Training loss: 1.6596486568450928
Validation loss: 2.0664389530817666

Epoch: 5| Step: 11
Training loss: 1.88179612159729
Validation loss: 2.0420430998007455

Epoch: 84| Step: 0
Training loss: 1.7432283163070679
Validation loss: 2.039313331246376

Epoch: 5| Step: 1
Training loss: 2.3578248023986816
Validation loss: 2.0374483913183212

Epoch: 5| Step: 2
Training loss: 2.370568037033081
Validation loss: 2.0348160912593207

Epoch: 5| Step: 3
Training loss: 1.376081109046936
Validation loss: 2.0242591500282288

Epoch: 5| Step: 4
Training loss: 2.208322286605835
Validation loss: 2.0289120276769004

Epoch: 5| Step: 5
Training loss: 2.5574119091033936
Validation loss: 2.0265349745750427

Epoch: 5| Step: 6
Training loss: 1.9404404163360596
Validation loss: 2.0190589825312295

Epoch: 5| Step: 7
Training loss: 2.2010841369628906
Validation loss: 2.025083288550377

Epoch: 5| Step: 8
Training loss: 2.255861759185791
Validation loss: 2.029387613137563

Epoch: 5| Step: 9
Training loss: 2.3580503463745117
Validation loss: 2.0157179087400436

Epoch: 5| Step: 10
Training loss: 2.581343173980713
Validation loss: 2.0231626282135644

Epoch: 5| Step: 11
Training loss: 2.0091052055358887
Validation loss: 2.018928602337837

Epoch: 85| Step: 0
Training loss: 1.9448492527008057
Validation loss: 2.0183919121821723

Epoch: 5| Step: 1
Training loss: 1.6378685235977173
Validation loss: 2.0249888201554618

Epoch: 5| Step: 2
Training loss: 2.20619535446167
Validation loss: 2.02587454020977

Epoch: 5| Step: 3
Training loss: 2.4242873191833496
Validation loss: 2.025252476334572

Epoch: 5| Step: 4
Training loss: 2.1855309009552
Validation loss: 2.0291576236486435

Epoch: 5| Step: 5
Training loss: 2.2523045539855957
Validation loss: 2.033067891995112

Epoch: 5| Step: 6
Training loss: 2.789227247238159
Validation loss: 2.0369811952114105

Epoch: 5| Step: 7
Training loss: 2.425776720046997
Validation loss: 2.0436073541641235

Epoch: 5| Step: 8
Training loss: 1.7746200561523438
Validation loss: 2.0373308956623077

Epoch: 5| Step: 9
Training loss: 2.5154292583465576
Validation loss: 2.028133347630501

Epoch: 5| Step: 10
Training loss: 1.7742373943328857
Validation loss: 2.0177734196186066

Epoch: 5| Step: 11
Training loss: 1.2518346309661865
Validation loss: 2.0206940745313964

Epoch: 86| Step: 0
Training loss: 1.8648312091827393
Validation loss: 2.015988936026891

Epoch: 5| Step: 1
Training loss: 2.5340991020202637
Validation loss: 2.020959973335266

Epoch: 5| Step: 2
Training loss: 1.9800441265106201
Validation loss: 2.0304000973701477

Epoch: 5| Step: 3
Training loss: 2.0495781898498535
Validation loss: 2.0297205497821174

Epoch: 5| Step: 4
Training loss: 2.0872018337249756
Validation loss: 2.0261607666810355

Epoch: 5| Step: 5
Training loss: 2.1691384315490723
Validation loss: 2.026545430223147

Epoch: 5| Step: 6
Training loss: 2.504791498184204
Validation loss: 2.023936480283737

Epoch: 5| Step: 7
Training loss: 2.1816437244415283
Validation loss: 2.0222915957371392

Epoch: 5| Step: 8
Training loss: 2.0473110675811768
Validation loss: 2.0274865527947745

Epoch: 5| Step: 9
Training loss: 2.283705472946167
Validation loss: 2.02036980787913

Epoch: 5| Step: 10
Training loss: 2.2931103706359863
Validation loss: 2.0176089654366174

Epoch: 5| Step: 11
Training loss: 2.0798630714416504
Validation loss: 2.0240249186754227

Epoch: 87| Step: 0
Training loss: 1.991283655166626
Validation loss: 2.027821938196818

Epoch: 5| Step: 1
Training loss: 2.4586265087127686
Validation loss: 2.039034381508827

Epoch: 5| Step: 2
Training loss: 1.9864248037338257
Validation loss: 2.0397495329380035

Epoch: 5| Step: 3
Training loss: 1.5288432836532593
Validation loss: 2.0515002508958182

Epoch: 5| Step: 4
Training loss: 2.045978546142578
Validation loss: 2.057352369030317

Epoch: 5| Step: 5
Training loss: 1.845306158065796
Validation loss: 2.054962163170179

Epoch: 5| Step: 6
Training loss: 1.6890398263931274
Validation loss: 2.052722459038099

Epoch: 5| Step: 7
Training loss: 2.587855815887451
Validation loss: 2.075771118203799

Epoch: 5| Step: 8
Training loss: 2.091383457183838
Validation loss: 2.0663161824146905

Epoch: 5| Step: 9
Training loss: 2.992584228515625
Validation loss: 2.0541256268819175

Epoch: 5| Step: 10
Training loss: 2.7286782264709473
Validation loss: 2.042487328251203

Epoch: 5| Step: 11
Training loss: 2.334001064300537
Validation loss: 2.0278168618679047

Epoch: 88| Step: 0
Training loss: 2.345935821533203
Validation loss: 2.01568241417408

Epoch: 5| Step: 1
Training loss: 2.6250085830688477
Validation loss: 2.0248023569583893

Epoch: 5| Step: 2
Training loss: 2.1239161491394043
Validation loss: 2.029363895455996

Epoch: 5| Step: 3
Training loss: 1.5437135696411133
Validation loss: 2.030012076099714

Epoch: 5| Step: 4
Training loss: 2.122337579727173
Validation loss: 2.029113600651423

Epoch: 5| Step: 5
Training loss: 2.0423331260681152
Validation loss: 2.025173619389534

Epoch: 5| Step: 6
Training loss: 1.942980170249939
Validation loss: 2.030928462743759

Epoch: 5| Step: 7
Training loss: 1.8379710912704468
Validation loss: 2.0287101368109384

Epoch: 5| Step: 8
Training loss: 2.4607372283935547
Validation loss: 2.0229190637667975

Epoch: 5| Step: 9
Training loss: 2.5306167602539062
Validation loss: 2.021907006700834

Epoch: 5| Step: 10
Training loss: 2.271315097808838
Validation loss: 2.024408385157585

Epoch: 5| Step: 11
Training loss: 2.9111275672912598
Validation loss: 2.0245207846164703

Epoch: 89| Step: 0
Training loss: 1.9075069427490234
Validation loss: 2.020290791988373

Epoch: 5| Step: 1
Training loss: 2.008265972137451
Validation loss: 2.0260956287384033

Epoch: 5| Step: 2
Training loss: 1.6435238122940063
Validation loss: 2.0154957671960196

Epoch: 5| Step: 3
Training loss: 1.864866852760315
Validation loss: 2.021500582496325

Epoch: 5| Step: 4
Training loss: 2.358072280883789
Validation loss: 2.018043428659439

Epoch: 5| Step: 5
Training loss: 2.207886219024658
Validation loss: 2.022328366835912

Epoch: 5| Step: 6
Training loss: 2.43599271774292
Validation loss: 2.0136815359195075

Epoch: 5| Step: 7
Training loss: 2.2031257152557373
Validation loss: 2.01830825706323

Epoch: 5| Step: 8
Training loss: 2.38429594039917
Validation loss: 2.0111465752124786

Epoch: 5| Step: 9
Training loss: 2.3303914070129395
Validation loss: 2.00966614484787

Epoch: 5| Step: 10
Training loss: 2.6588480472564697
Validation loss: 2.0187929024298987

Epoch: 5| Step: 11
Training loss: 2.2131612300872803
Validation loss: 2.009283016125361

Epoch: 90| Step: 0
Training loss: 2.587790012359619
Validation loss: 2.0229431043068566

Epoch: 5| Step: 1
Training loss: 2.4205448627471924
Validation loss: 2.020951360464096

Epoch: 5| Step: 2
Training loss: 1.8313624858856201
Validation loss: 2.019497588276863

Epoch: 5| Step: 3
Training loss: 2.547461748123169
Validation loss: 2.0243194699287415

Epoch: 5| Step: 4
Training loss: 2.4632325172424316
Validation loss: 2.025288477540016

Epoch: 5| Step: 5
Training loss: 2.1499264240264893
Validation loss: 2.0283510188261666

Epoch: 5| Step: 6
Training loss: 1.873570203781128
Validation loss: 2.0231738736232123

Epoch: 5| Step: 7
Training loss: 1.8477108478546143
Validation loss: 2.0354985495408378

Epoch: 5| Step: 8
Training loss: 1.7645641565322876
Validation loss: 2.036379814147949

Epoch: 5| Step: 9
Training loss: 1.7869722843170166
Validation loss: 2.040261576573054

Epoch: 5| Step: 10
Training loss: 2.6937947273254395
Validation loss: 2.041202023625374

Epoch: 5| Step: 11
Training loss: 2.062161922454834
Validation loss: 2.051185096303622

Epoch: 91| Step: 0
Training loss: 2.287169933319092
Validation loss: 2.0350488126277924

Epoch: 5| Step: 1
Training loss: 2.605502128601074
Validation loss: 2.027369106809298

Epoch: 5| Step: 2
Training loss: 1.948965072631836
Validation loss: 2.0341439992189407

Epoch: 5| Step: 3
Training loss: 2.457085371017456
Validation loss: 2.0262368271748223

Epoch: 5| Step: 4
Training loss: 2.5991809368133545
Validation loss: 2.021095489462217

Epoch: 5| Step: 5
Training loss: 2.250293254852295
Validation loss: 2.015204762419065

Epoch: 5| Step: 6
Training loss: 2.319754123687744
Validation loss: 2.0251262237628302

Epoch: 5| Step: 7
Training loss: 2.137312889099121
Validation loss: 2.0165283232927322

Epoch: 5| Step: 8
Training loss: 1.2803303003311157
Validation loss: 2.0298248877127967

Epoch: 5| Step: 9
Training loss: 1.692138671875
Validation loss: 2.026226053635279

Epoch: 5| Step: 10
Training loss: 1.865303635597229
Validation loss: 2.0180008908112845

Epoch: 5| Step: 11
Training loss: 3.445706367492676
Validation loss: 2.0198487589756646

Epoch: 92| Step: 0
Training loss: 2.2382030487060547
Validation loss: 2.0477914412816367

Epoch: 5| Step: 1
Training loss: 2.240917444229126
Validation loss: 2.034982184569041

Epoch: 5| Step: 2
Training loss: 2.2374331951141357
Validation loss: 2.0325164844592414

Epoch: 5| Step: 3
Training loss: 2.3688292503356934
Validation loss: 2.0563108126322427

Epoch: 5| Step: 4
Training loss: 2.228320598602295
Validation loss: 2.0440342128276825

Epoch: 5| Step: 5
Training loss: 2.1433091163635254
Validation loss: 2.0409619907538095

Epoch: 5| Step: 6
Training loss: 2.0904929637908936
Validation loss: 2.0462267448504767

Epoch: 5| Step: 7
Training loss: 2.1345391273498535
Validation loss: 2.041850437720617

Epoch: 5| Step: 8
Training loss: 2.19708251953125
Validation loss: 2.0335007260243096

Epoch: 5| Step: 9
Training loss: 2.240551471710205
Validation loss: 2.0268931488196054

Epoch: 5| Step: 10
Training loss: 2.026968479156494
Validation loss: 2.0186019043127694

Epoch: 5| Step: 11
Training loss: 0.5164057016372681
Validation loss: 2.013767421245575

Epoch: 93| Step: 0
Training loss: 2.6318399906158447
Validation loss: 2.018851970632871

Epoch: 5| Step: 1
Training loss: 2.2215569019317627
Validation loss: 2.0181340823570886

Epoch: 5| Step: 2
Training loss: 1.8998836278915405
Validation loss: 2.0147280593713126

Epoch: 5| Step: 3
Training loss: 1.9007415771484375
Validation loss: 2.016670842965444

Epoch: 5| Step: 4
Training loss: 2.569179058074951
Validation loss: 2.0157486448685327

Epoch: 5| Step: 5
Training loss: 1.8297306299209595
Validation loss: 2.028723567724228

Epoch: 5| Step: 6
Training loss: 1.9954341650009155
Validation loss: 2.0331555108229318

Epoch: 5| Step: 7
Training loss: 1.8311030864715576
Validation loss: 2.032626822590828

Epoch: 5| Step: 8
Training loss: 2.0735745429992676
Validation loss: 2.0243023882309594

Epoch: 5| Step: 9
Training loss: 2.7234320640563965
Validation loss: 2.038333142797152

Epoch: 5| Step: 10
Training loss: 2.0185344219207764
Validation loss: 2.0442650467157364

Epoch: 5| Step: 11
Training loss: 1.8611425161361694
Validation loss: 2.0391379296779633

Epoch: 94| Step: 0
Training loss: 1.5132691860198975
Validation loss: 2.0397874464591346

Epoch: 5| Step: 1
Training loss: 2.4336650371551514
Validation loss: 2.049756015340487

Epoch: 5| Step: 2
Training loss: 2.2935338020324707
Validation loss: 2.037184705336889

Epoch: 5| Step: 3
Training loss: 2.2373831272125244
Validation loss: 2.026913414398829

Epoch: 5| Step: 4
Training loss: 2.0796334743499756
Validation loss: 2.033443972468376

Epoch: 5| Step: 5
Training loss: 2.334800958633423
Validation loss: 2.0287549098332724

Epoch: 5| Step: 6
Training loss: 2.3816561698913574
Validation loss: 2.033869390686353

Epoch: 5| Step: 7
Training loss: 1.772886037826538
Validation loss: 2.026162659128507

Epoch: 5| Step: 8
Training loss: 2.0540764331817627
Validation loss: 2.0239282300074897

Epoch: 5| Step: 9
Training loss: 2.677471876144409
Validation loss: 2.0169163992007575

Epoch: 5| Step: 10
Training loss: 1.926282525062561
Validation loss: 2.023554652929306

Epoch: 5| Step: 11
Training loss: 1.6415982246398926
Validation loss: 2.024331937233607

Epoch: 95| Step: 0
Training loss: 2.1721839904785156
Validation loss: 2.0239883164564767

Epoch: 5| Step: 1
Training loss: 1.9370492696762085
Validation loss: 2.035908733805021

Epoch: 5| Step: 2
Training loss: 2.181509017944336
Validation loss: 2.0483627766370773

Epoch: 5| Step: 3
Training loss: 2.5586514472961426
Validation loss: 2.0462202032407126

Epoch: 5| Step: 4
Training loss: 2.4248886108398438
Validation loss: 2.070567548274994

Epoch: 5| Step: 5
Training loss: 1.7924007177352905
Validation loss: 2.0611269076665244

Epoch: 5| Step: 6
Training loss: 2.357240915298462
Validation loss: 2.0498541792233786

Epoch: 5| Step: 7
Training loss: 2.370856523513794
Validation loss: 2.0477540642023087

Epoch: 5| Step: 8
Training loss: 1.711077332496643
Validation loss: 2.0356116543213525

Epoch: 5| Step: 9
Training loss: 2.1165249347686768
Validation loss: 2.0242687364419303

Epoch: 5| Step: 10
Training loss: 2.0085105895996094
Validation loss: 2.025461400548617

Epoch: 5| Step: 11
Training loss: 3.286594867706299
Validation loss: 2.0230235755443573

Epoch: 96| Step: 0
Training loss: 1.722678542137146
Validation loss: 2.0173532168070474

Epoch: 5| Step: 1
Training loss: 1.8513692617416382
Validation loss: 2.0218403736750283

Epoch: 5| Step: 2
Training loss: 1.979536771774292
Validation loss: 2.0166587779919305

Epoch: 5| Step: 3
Training loss: 2.0858302116394043
Validation loss: 2.0140807032585144

Epoch: 5| Step: 4
Training loss: 1.9229274988174438
Validation loss: 2.0040696312983832

Epoch: 5| Step: 5
Training loss: 2.793175220489502
Validation loss: 2.012589454650879

Epoch: 5| Step: 6
Training loss: 2.6648824214935303
Validation loss: 2.014915098746618

Epoch: 5| Step: 7
Training loss: 2.2477447986602783
Validation loss: 2.016255388657252

Epoch: 5| Step: 8
Training loss: 2.1579463481903076
Validation loss: 2.0028242617845535

Epoch: 5| Step: 9
Training loss: 2.0193533897399902
Validation loss: 2.002029155691465

Epoch: 5| Step: 10
Training loss: 2.058149814605713
Validation loss: 2.010425960024198

Epoch: 5| Step: 11
Training loss: 3.0526340007781982
Validation loss: 2.011297563711802

Epoch: 97| Step: 0
Training loss: 2.6123108863830566
Validation loss: 2.0089047253131866

Epoch: 5| Step: 1
Training loss: 2.178534984588623
Validation loss: 2.003915404280027

Epoch: 5| Step: 2
Training loss: 1.9230210781097412
Validation loss: 2.015220656991005

Epoch: 5| Step: 3
Training loss: 1.9906774759292603
Validation loss: 2.0136645336945853

Epoch: 5| Step: 4
Training loss: 1.9601151943206787
Validation loss: 2.0105172048012414

Epoch: 5| Step: 5
Training loss: 2.6097474098205566
Validation loss: 2.004530896743139

Epoch: 5| Step: 6
Training loss: 2.0364158153533936
Validation loss: 2.0185123085975647

Epoch: 5| Step: 7
Training loss: 1.847751259803772
Validation loss: 2.0067576120297113

Epoch: 5| Step: 8
Training loss: 1.9963268041610718
Validation loss: 2.016702115535736

Epoch: 5| Step: 9
Training loss: 2.0266501903533936
Validation loss: 2.0136717508236566

Epoch: 5| Step: 10
Training loss: 2.4273576736450195
Validation loss: 2.0245138506094613

Epoch: 5| Step: 11
Training loss: 1.5952492952346802
Validation loss: 2.020053674777349

Epoch: 98| Step: 0
Training loss: 2.1369028091430664
Validation loss: 2.0374347617228827

Epoch: 5| Step: 1
Training loss: 2.3185882568359375
Validation loss: 2.0275500218073526

Epoch: 5| Step: 2
Training loss: 1.8227393627166748
Validation loss: 2.0163216342528663

Epoch: 5| Step: 3
Training loss: 2.4098052978515625
Validation loss: 2.0165610313415527

Epoch: 5| Step: 4
Training loss: 2.1698222160339355
Validation loss: 2.006745845079422

Epoch: 5| Step: 5
Training loss: 1.7431514263153076
Validation loss: 2.00691889723142

Epoch: 5| Step: 6
Training loss: 1.9533507823944092
Validation loss: 2.010531783103943

Epoch: 5| Step: 7
Training loss: 2.0277867317199707
Validation loss: 2.0148813178141913

Epoch: 5| Step: 8
Training loss: 2.55761981010437
Validation loss: 1.9990789492925007

Epoch: 5| Step: 9
Training loss: 2.556710720062256
Validation loss: 2.0098919173081717

Epoch: 5| Step: 10
Training loss: 2.175597667694092
Validation loss: 2.008554140726725

Epoch: 5| Step: 11
Training loss: 1.6133791208267212
Validation loss: 2.0028992344935737

Epoch: 99| Step: 0
Training loss: 2.29496431350708
Validation loss: 2.006194998820623

Epoch: 5| Step: 1
Training loss: 2.350919723510742
Validation loss: 2.009875868757566

Epoch: 5| Step: 2
Training loss: 1.6902081966400146
Validation loss: 2.0195112923781076

Epoch: 5| Step: 3
Training loss: 2.3115615844726562
Validation loss: 2.032755752404531

Epoch: 5| Step: 4
Training loss: 2.1193079948425293
Validation loss: 2.039623330036799

Epoch: 5| Step: 5
Training loss: 1.947106957435608
Validation loss: 2.0576831797758737

Epoch: 5| Step: 6
Training loss: 1.9330596923828125
Validation loss: 2.0560400784015656

Epoch: 5| Step: 7
Training loss: 2.3818583488464355
Validation loss: 2.065405542651812

Epoch: 5| Step: 8
Training loss: 2.1107382774353027
Validation loss: 2.050557712713877

Epoch: 5| Step: 9
Training loss: 2.0880954265594482
Validation loss: 2.0452321420113244

Epoch: 5| Step: 10
Training loss: 2.265925645828247
Validation loss: 2.03230486313502

Epoch: 5| Step: 11
Training loss: 3.3260064125061035
Validation loss: 2.02752115825812

Epoch: 100| Step: 0
Training loss: 2.428165912628174
Validation loss: 2.018796846270561

Epoch: 5| Step: 1
Training loss: 2.005964994430542
Validation loss: 2.0063802550236383

Epoch: 5| Step: 2
Training loss: 2.3161091804504395
Validation loss: 1.9986147632201512

Epoch: 5| Step: 3
Training loss: 2.547028064727783
Validation loss: 2.0024684021870294

Epoch: 5| Step: 4
Training loss: 1.83469557762146
Validation loss: 2.0033178329467773

Epoch: 5| Step: 5
Training loss: 1.9581177234649658
Validation loss: 2.0043044139941535

Epoch: 5| Step: 6
Training loss: 2.7281339168548584
Validation loss: 1.9969290147225063

Epoch: 5| Step: 7
Training loss: 1.4807567596435547
Validation loss: 2.0011138767004013

Epoch: 5| Step: 8
Training loss: 2.5382580757141113
Validation loss: 1.9980660925308864

Epoch: 5| Step: 9
Training loss: 1.4763901233673096
Validation loss: 2.0098636398712793

Epoch: 5| Step: 10
Training loss: 2.0194900035858154
Validation loss: 2.010213499267896

Epoch: 5| Step: 11
Training loss: 2.7000293731689453
Validation loss: 2.010180955131849

Epoch: 101| Step: 0
Training loss: 1.8128395080566406
Validation loss: 2.0153921743234

Epoch: 5| Step: 1
Training loss: 2.181335687637329
Validation loss: 2.0185752709706626

Epoch: 5| Step: 2
Training loss: 2.103163957595825
Validation loss: 2.016028473774592

Epoch: 5| Step: 3
Training loss: 1.818838119506836
Validation loss: 2.018034060796102

Epoch: 5| Step: 4
Training loss: 2.0617966651916504
Validation loss: 2.007360488176346

Epoch: 5| Step: 5
Training loss: 2.472923994064331
Validation loss: 2.0198785066604614

Epoch: 5| Step: 6
Training loss: 2.212925434112549
Validation loss: 2.02493908504645

Epoch: 5| Step: 7
Training loss: 2.408092975616455
Validation loss: 2.02036289870739

Epoch: 5| Step: 8
Training loss: 2.316157341003418
Validation loss: 2.0151587078968682

Epoch: 5| Step: 9
Training loss: 1.7991794347763062
Validation loss: 2.0215406815210977

Epoch: 5| Step: 10
Training loss: 2.389192581176758
Validation loss: 2.0219756911198297

Epoch: 5| Step: 11
Training loss: 2.115403652191162
Validation loss: 2.0199993948141732

Epoch: 102| Step: 0
Training loss: 1.9193904399871826
Validation loss: 2.026580130060514

Epoch: 5| Step: 1
Training loss: 1.9129337072372437
Validation loss: 2.017484719554583

Epoch: 5| Step: 2
Training loss: 2.8343887329101562
Validation loss: 2.0257641772429147

Epoch: 5| Step: 3
Training loss: 1.748206377029419
Validation loss: 2.0380857586860657

Epoch: 5| Step: 4
Training loss: 2.499600887298584
Validation loss: 2.031843195358912

Epoch: 5| Step: 5
Training loss: 1.8013511896133423
Validation loss: 2.0373007704814277

Epoch: 5| Step: 6
Training loss: 2.2494637966156006
Validation loss: 2.03958327571551

Epoch: 5| Step: 7
Training loss: 2.3626532554626465
Validation loss: 2.045825401941935

Epoch: 5| Step: 8
Training loss: 1.7800058126449585
Validation loss: 2.037515550851822

Epoch: 5| Step: 9
Training loss: 2.0152506828308105
Validation loss: 2.0282925963401794

Epoch: 5| Step: 10
Training loss: 2.544771909713745
Validation loss: 2.051373213529587

Epoch: 5| Step: 11
Training loss: 0.8903713226318359
Validation loss: 2.023147647579511

Epoch: 103| Step: 0
Training loss: 2.0344395637512207
Validation loss: 2.02185095846653

Epoch: 5| Step: 1
Training loss: 2.0152204036712646
Validation loss: 2.022807021935781

Epoch: 5| Step: 2
Training loss: 2.161750555038452
Validation loss: 2.0127174804608026

Epoch: 5| Step: 3
Training loss: 1.6730144023895264
Validation loss: 2.01037069161733

Epoch: 5| Step: 4
Training loss: 2.1286354064941406
Validation loss: 2.0069207002719245

Epoch: 5| Step: 5
Training loss: 2.3722891807556152
Validation loss: 2.0077325055996575

Epoch: 5| Step: 6
Training loss: 2.245652914047241
Validation loss: 2.0099044144153595

Epoch: 5| Step: 7
Training loss: 2.299572467803955
Validation loss: 2.0130221247673035

Epoch: 5| Step: 8
Training loss: 2.3970746994018555
Validation loss: 2.008173475662867

Epoch: 5| Step: 9
Training loss: 2.092649221420288
Validation loss: 2.0155891875425973

Epoch: 5| Step: 10
Training loss: 2.050605297088623
Validation loss: 2.018869936466217

Epoch: 5| Step: 11
Training loss: 3.2613232135772705
Validation loss: 2.0088342229525247

Epoch: 104| Step: 0
Training loss: 2.4241950511932373
Validation loss: 2.0059266785780587

Epoch: 5| Step: 1
Training loss: 2.1972434520721436
Validation loss: 2.005662923057874

Epoch: 5| Step: 2
Training loss: 1.844146966934204
Validation loss: 2.00369801123937

Epoch: 5| Step: 3
Training loss: 2.0626845359802246
Validation loss: 2.0038242439428964

Epoch: 5| Step: 4
Training loss: 2.3691141605377197
Validation loss: 1.998962089419365

Epoch: 5| Step: 5
Training loss: 2.17182993888855
Validation loss: 1.997643346587817

Epoch: 5| Step: 6
Training loss: 2.1985201835632324
Validation loss: 2.007092004021009

Epoch: 5| Step: 7
Training loss: 2.0826187133789062
Validation loss: 2.0170643031597137

Epoch: 5| Step: 8
Training loss: 2.0886118412017822
Validation loss: 2.0281793673833213

Epoch: 5| Step: 9
Training loss: 2.093787431716919
Validation loss: 2.030140752593676

Epoch: 5| Step: 10
Training loss: 2.175391435623169
Validation loss: 2.0336668143669763

Epoch: 5| Step: 11
Training loss: 2.0995402336120605
Validation loss: 2.037354916334152

Epoch: 105| Step: 0
Training loss: 2.0209031105041504
Validation loss: 2.0243831227223077

Epoch: 5| Step: 1
Training loss: 1.9393466711044312
Validation loss: 2.0209877838691077

Epoch: 5| Step: 2
Training loss: 1.8950811624526978
Validation loss: 2.0224142571290336

Epoch: 5| Step: 3
Training loss: 2.158433437347412
Validation loss: 2.0227074225743613

Epoch: 5| Step: 4
Training loss: 1.9639174938201904
Validation loss: 2.0333143323659897

Epoch: 5| Step: 5
Training loss: 2.2024178504943848
Validation loss: 2.0277030169963837

Epoch: 5| Step: 6
Training loss: 2.1237497329711914
Validation loss: 2.033523922165235

Epoch: 5| Step: 7
Training loss: 1.7629165649414062
Validation loss: 2.026508395870527

Epoch: 5| Step: 8
Training loss: 1.8222719430923462
Validation loss: 2.0373789370059967

Epoch: 5| Step: 9
Training loss: 2.770777463912964
Validation loss: 2.0374838411808014

Epoch: 5| Step: 10
Training loss: 2.5072414875030518
Validation loss: 2.0246294736862183

Epoch: 5| Step: 11
Training loss: 2.647580862045288
Validation loss: 2.016231576601664

Epoch: 106| Step: 0
Training loss: 2.668172836303711
Validation loss: 2.013952245314916

Epoch: 5| Step: 1
Training loss: 2.0324761867523193
Validation loss: 2.0147090554237366

Epoch: 5| Step: 2
Training loss: 1.616061806678772
Validation loss: 2.0147192726532617

Epoch: 5| Step: 3
Training loss: 2.3605101108551025
Validation loss: 2.0149688571691513

Epoch: 5| Step: 4
Training loss: 1.7388042211532593
Validation loss: 2.0141225109497705

Epoch: 5| Step: 5
Training loss: 2.1990439891815186
Validation loss: 2.0179590781529746

Epoch: 5| Step: 6
Training loss: 2.1939187049865723
Validation loss: 2.010970468322436

Epoch: 5| Step: 7
Training loss: 2.111048698425293
Validation loss: 2.0175915161768594

Epoch: 5| Step: 8
Training loss: 2.3321902751922607
Validation loss: 2.0066744536161423

Epoch: 5| Step: 9
Training loss: 2.442317485809326
Validation loss: 2.0112678607304892

Epoch: 5| Step: 10
Training loss: 2.060385227203369
Validation loss: 2.0174309760332108

Epoch: 5| Step: 11
Training loss: 1.509880781173706
Validation loss: 2.0280761818091073

Epoch: 107| Step: 0
Training loss: 1.9411919116973877
Validation loss: 2.014591937263807

Epoch: 5| Step: 1
Training loss: 2.6062591075897217
Validation loss: 2.021492878595988

Epoch: 5| Step: 2
Training loss: 2.157773971557617
Validation loss: 2.0266179740428925

Epoch: 5| Step: 3
Training loss: 2.017131805419922
Validation loss: 2.0286436080932617

Epoch: 5| Step: 4
Training loss: 2.2860867977142334
Validation loss: 2.0354226877292

Epoch: 5| Step: 5
Training loss: 2.0837783813476562
Validation loss: 2.035118336478869

Epoch: 5| Step: 6
Training loss: 2.243882656097412
Validation loss: 2.036526689926783

Epoch: 5| Step: 7
Training loss: 1.988348364830017
Validation loss: 2.035427043835322

Epoch: 5| Step: 8
Training loss: 1.7960395812988281
Validation loss: 2.0396590183178582

Epoch: 5| Step: 9
Training loss: 1.9522777795791626
Validation loss: 2.0331324140230813

Epoch: 5| Step: 10
Training loss: 2.4852182865142822
Validation loss: 2.038081799944242

Epoch: 5| Step: 11
Training loss: 1.2737431526184082
Validation loss: 2.0336792518695197

Epoch: 108| Step: 0
Training loss: 1.8210697174072266
Validation loss: 2.0253339807192483

Epoch: 5| Step: 1
Training loss: 2.4822726249694824
Validation loss: 2.0175597220659256

Epoch: 5| Step: 2
Training loss: 1.9648357629776
Validation loss: 2.0163272420565286

Epoch: 5| Step: 3
Training loss: 1.6963237524032593
Validation loss: 2.009336993098259

Epoch: 5| Step: 4
Training loss: 2.6464030742645264
Validation loss: 2.015015040834745

Epoch: 5| Step: 5
Training loss: 2.0693631172180176
Validation loss: 2.0122582465410233

Epoch: 5| Step: 6
Training loss: 2.097661018371582
Validation loss: 2.0228996872901917

Epoch: 5| Step: 7
Training loss: 2.009742021560669
Validation loss: 2.0187874287366867

Epoch: 5| Step: 8
Training loss: 2.71183705329895
Validation loss: 2.022600010037422

Epoch: 5| Step: 9
Training loss: 1.9738699197769165
Validation loss: 2.024875119328499

Epoch: 5| Step: 10
Training loss: 1.9841620922088623
Validation loss: 2.0140744050343833

Epoch: 5| Step: 11
Training loss: 1.526669979095459
Validation loss: 2.0103391657272973

Epoch: 109| Step: 0
Training loss: 2.1587681770324707
Validation loss: 2.0165092994769416

Epoch: 5| Step: 1
Training loss: 1.7633094787597656
Validation loss: 2.0146037687857947

Epoch: 5| Step: 2
Training loss: 2.1924304962158203
Validation loss: 2.0139198154211044

Epoch: 5| Step: 3
Training loss: 2.2792563438415527
Validation loss: 2.029593606789907

Epoch: 5| Step: 4
Training loss: 2.42521333694458
Validation loss: 2.0258509467045465

Epoch: 5| Step: 5
Training loss: 2.2253870964050293
Validation loss: 2.0263454765081406

Epoch: 5| Step: 6
Training loss: 1.6584523916244507
Validation loss: 2.037514885266622

Epoch: 5| Step: 7
Training loss: 1.8716557025909424
Validation loss: 2.0432135115067163

Epoch: 5| Step: 8
Training loss: 2.44928240776062
Validation loss: 2.0352234542369843

Epoch: 5| Step: 9
Training loss: 1.9105030298233032
Validation loss: 2.0453031907478967

Epoch: 5| Step: 10
Training loss: 2.3548150062561035
Validation loss: 2.051388069987297

Epoch: 5| Step: 11
Training loss: 2.0187911987304688
Validation loss: 2.04766383767128

Epoch: 110| Step: 0
Training loss: 2.4034276008605957
Validation loss: 2.0380570391813913

Epoch: 5| Step: 1
Training loss: 2.04878306388855
Validation loss: 2.0252379924058914

Epoch: 5| Step: 2
Training loss: 2.3152928352355957
Validation loss: 2.030712445576986

Epoch: 5| Step: 3
Training loss: 1.9343140125274658
Validation loss: 2.0176113545894623

Epoch: 5| Step: 4
Training loss: 2.5332932472229004
Validation loss: 2.02428204814593

Epoch: 5| Step: 5
Training loss: 2.7067599296569824
Validation loss: 2.0232225159804025

Epoch: 5| Step: 6
Training loss: 1.8915420770645142
Validation loss: 2.0289882769187293

Epoch: 5| Step: 7
Training loss: 1.2291182279586792
Validation loss: 2.0389295667409897

Epoch: 5| Step: 8
Training loss: 2.0973877906799316
Validation loss: 2.0289180924495063

Epoch: 5| Step: 9
Training loss: 2.3566460609436035
Validation loss: 2.0268772641817727

Epoch: 5| Step: 10
Training loss: 2.0769872665405273
Validation loss: 2.030626197655996

Epoch: 5| Step: 11
Training loss: 2.0634331703186035
Validation loss: 2.021050234635671

Epoch: 111| Step: 0
Training loss: 1.4552079439163208
Validation loss: 2.0331301391124725

Epoch: 5| Step: 1
Training loss: 2.3328821659088135
Validation loss: 2.0448924551407495

Epoch: 5| Step: 2
Training loss: 2.671492099761963
Validation loss: 2.042038172483444

Epoch: 5| Step: 3
Training loss: 1.9152450561523438
Validation loss: 2.0492018908262253

Epoch: 5| Step: 4
Training loss: 2.122307777404785
Validation loss: 2.0548153668642044

Epoch: 5| Step: 5
Training loss: 2.3263590335845947
Validation loss: 2.0692010472218194

Epoch: 5| Step: 6
Training loss: 2.1363251209259033
Validation loss: 2.0721953064203262

Epoch: 5| Step: 7
Training loss: 1.9318691492080688
Validation loss: 2.0504628916581473

Epoch: 5| Step: 8
Training loss: 2.442155122756958
Validation loss: 2.0422571996847787

Epoch: 5| Step: 9
Training loss: 2.3610329627990723
Validation loss: 2.037737419207891

Epoch: 5| Step: 10
Training loss: 2.0620429515838623
Validation loss: 2.044315059979757

Epoch: 5| Step: 11
Training loss: 2.094430446624756
Validation loss: 2.0362194081147513

Epoch: 112| Step: 0
Training loss: 1.9136760234832764
Validation loss: 2.04560757180055

Epoch: 5| Step: 1
Training loss: 2.3038458824157715
Validation loss: 2.038648843765259

Epoch: 5| Step: 2
Training loss: 1.4638803005218506
Validation loss: 2.0369474987188974

Epoch: 5| Step: 3
Training loss: 2.0990071296691895
Validation loss: 2.0503080934286118

Epoch: 5| Step: 4
Training loss: 1.912567377090454
Validation loss: 2.0484715004762015

Epoch: 5| Step: 5
Training loss: 2.6765494346618652
Validation loss: 2.0470381577809653

Epoch: 5| Step: 6
Training loss: 2.1292455196380615
Validation loss: 2.053297465046247

Epoch: 5| Step: 7
Training loss: 2.224771022796631
Validation loss: 2.0722589840491614

Epoch: 5| Step: 8
Training loss: 2.4559826850891113
Validation loss: 2.069460059205691

Epoch: 5| Step: 9
Training loss: 2.224992513656616
Validation loss: 2.063499838113785

Epoch: 5| Step: 10
Training loss: 2.19718861579895
Validation loss: 2.0650177001953125

Epoch: 5| Step: 11
Training loss: 0.8806231021881104
Validation loss: 2.054336299498876

Epoch: 113| Step: 0
Training loss: 2.130030870437622
Validation loss: 2.057607054710388

Epoch: 5| Step: 1
Training loss: 2.4811575412750244
Validation loss: 2.0452772080898285

Epoch: 5| Step: 2
Training loss: 1.9917808771133423
Validation loss: 2.040876418352127

Epoch: 5| Step: 3
Training loss: 2.0206685066223145
Validation loss: 2.024253194530805

Epoch: 5| Step: 4
Training loss: 1.703017234802246
Validation loss: 2.0266023178895316

Epoch: 5| Step: 5
Training loss: 2.167670726776123
Validation loss: 2.0269690454006195

Epoch: 5| Step: 6
Training loss: 2.1873650550842285
Validation loss: 2.022654806574186

Epoch: 5| Step: 7
Training loss: 2.305048942565918
Validation loss: 2.009815146525701

Epoch: 5| Step: 8
Training loss: 2.5237882137298584
Validation loss: 2.021740436553955

Epoch: 5| Step: 9
Training loss: 1.8265444040298462
Validation loss: 2.0268960942824683

Epoch: 5| Step: 10
Training loss: 1.9955251216888428
Validation loss: 2.0159244338671365

Epoch: 5| Step: 11
Training loss: 2.026003837585449
Validation loss: 2.020935301979383

Epoch: 114| Step: 0
Training loss: 2.504145383834839
Validation loss: 2.0342488239208856

Epoch: 5| Step: 1
Training loss: 2.1599228382110596
Validation loss: 2.026880443096161

Epoch: 5| Step: 2
Training loss: 1.4980146884918213
Validation loss: 2.0269098033507666

Epoch: 5| Step: 3
Training loss: 2.1785502433776855
Validation loss: 2.020587901274363

Epoch: 5| Step: 4
Training loss: 1.8811286687850952
Validation loss: 2.0350168446699777

Epoch: 5| Step: 5
Training loss: 1.9124095439910889
Validation loss: 2.037825122475624

Epoch: 5| Step: 6
Training loss: 2.336200714111328
Validation loss: 2.0549005766709647

Epoch: 5| Step: 7
Training loss: 1.830054521560669
Validation loss: 2.0526996701955795

Epoch: 5| Step: 8
Training loss: 2.1717453002929688
Validation loss: 2.050645132859548

Epoch: 5| Step: 9
Training loss: 2.0128581523895264
Validation loss: 2.032571002840996

Epoch: 5| Step: 10
Training loss: 2.218839645385742
Validation loss: 2.023144612709681

Epoch: 5| Step: 11
Training loss: 3.882573127746582
Validation loss: 2.02126777668794

Epoch: 115| Step: 0
Training loss: 1.8953237533569336
Validation loss: 2.0167615165313086

Epoch: 5| Step: 1
Training loss: 2.841278076171875
Validation loss: 2.0247950553894043

Epoch: 5| Step: 2
Training loss: 2.058396816253662
Validation loss: 2.0215394447247186

Epoch: 5| Step: 3
Training loss: 2.356910228729248
Validation loss: 2.0267278850078583

Epoch: 5| Step: 4
Training loss: 2.0270214080810547
Validation loss: 2.0334301938613257

Epoch: 5| Step: 5
Training loss: 2.1039235591888428
Validation loss: 2.032144675652186

Epoch: 5| Step: 6
Training loss: 2.1514649391174316
Validation loss: 2.039091924826304

Epoch: 5| Step: 7
Training loss: 2.2868261337280273
Validation loss: 2.036233365535736

Epoch: 5| Step: 8
Training loss: 1.8147611618041992
Validation loss: 2.0349182983239493

Epoch: 5| Step: 9
Training loss: 2.1116726398468018
Validation loss: 2.0230328092972436

Epoch: 5| Step: 10
Training loss: 2.05027437210083
Validation loss: 2.025823508699735

Epoch: 5| Step: 11
Training loss: 2.486546039581299
Validation loss: 2.0228204429149628

Epoch: 116| Step: 0
Training loss: 2.3256328105926514
Validation loss: 2.009250203768412

Epoch: 5| Step: 1
Training loss: 1.8174097537994385
Validation loss: 2.0143063416083655

Epoch: 5| Step: 2
Training loss: 2.048780679702759
Validation loss: 2.0251524100701013

Epoch: 5| Step: 3
Training loss: 2.5158393383026123
Validation loss: 2.0458027919133506

Epoch: 5| Step: 4
Training loss: 1.5490429401397705
Validation loss: 2.0412504772345224

Epoch: 5| Step: 5
Training loss: 2.41920804977417
Validation loss: 2.0682381937901178

Epoch: 5| Step: 6
Training loss: 2.1770381927490234
Validation loss: 2.085257758696874

Epoch: 5| Step: 7
Training loss: 2.3003063201904297
Validation loss: 2.115254064400991

Epoch: 5| Step: 8
Training loss: 2.3189454078674316
Validation loss: 2.0933022697766623

Epoch: 5| Step: 9
Training loss: 1.9916422367095947
Validation loss: 2.0801643232504525

Epoch: 5| Step: 10
Training loss: 2.062084197998047
Validation loss: 2.0749392211437225

Epoch: 5| Step: 11
Training loss: 3.1897239685058594
Validation loss: 2.052387222647667

Epoch: 117| Step: 0
Training loss: 2.229405164718628
Validation loss: 2.0495582173268

Epoch: 5| Step: 1
Training loss: 1.7171046733856201
Validation loss: 2.046918878952662

Epoch: 5| Step: 2
Training loss: 1.5328290462493896
Validation loss: 2.0528900027275085

Epoch: 5| Step: 3
Training loss: 2.1735987663269043
Validation loss: 2.0358834266662598

Epoch: 5| Step: 4
Training loss: 2.4291558265686035
Validation loss: 2.026345511277517

Epoch: 5| Step: 5
Training loss: 2.1965560913085938
Validation loss: 2.0297426531712213

Epoch: 5| Step: 6
Training loss: 2.351499557495117
Validation loss: 2.0210522413253784

Epoch: 5| Step: 7
Training loss: 2.2867531776428223
Validation loss: 2.014547328154246

Epoch: 5| Step: 8
Training loss: 1.741877555847168
Validation loss: 2.0164296627044678

Epoch: 5| Step: 9
Training loss: 2.504946708679199
Validation loss: 2.0240699698527655

Epoch: 5| Step: 10
Training loss: 2.1857590675354004
Validation loss: 2.020075033108393

Epoch: 5| Step: 11
Training loss: 2.328187942504883
Validation loss: 2.0242313543955484

Epoch: 118| Step: 0
Training loss: 1.697291374206543
Validation loss: 2.0177243997653327

Epoch: 5| Step: 1
Training loss: 3.32104229927063
Validation loss: 2.022725303967794

Epoch: 5| Step: 2
Training loss: 1.6468464136123657
Validation loss: 2.0208231707413993

Epoch: 5| Step: 3
Training loss: 1.8053687810897827
Validation loss: 2.013821020722389

Epoch: 5| Step: 4
Training loss: 2.354111909866333
Validation loss: 2.015813941756884

Epoch: 5| Step: 5
Training loss: 2.316100597381592
Validation loss: 2.020252803961436

Epoch: 5| Step: 6
Training loss: 1.681152105331421
Validation loss: 2.022544945279757

Epoch: 5| Step: 7
Training loss: 1.7478481531143188
Validation loss: 2.0163779109716415

Epoch: 5| Step: 8
Training loss: 2.4923930168151855
Validation loss: 2.025587057073911

Epoch: 5| Step: 9
Training loss: 2.5866823196411133
Validation loss: 2.024419238169988

Epoch: 5| Step: 10
Training loss: 1.5308678150177002
Validation loss: 2.0142678916454315

Epoch: 5| Step: 11
Training loss: 2.3034324645996094
Validation loss: 2.0233970234791436

Epoch: 119| Step: 0
Training loss: 1.823813796043396
Validation loss: 2.0138113846381507

Epoch: 5| Step: 1
Training loss: 2.387598752975464
Validation loss: 2.0262936552365622

Epoch: 5| Step: 2
Training loss: 2.0153167247772217
Validation loss: 2.029471422235171

Epoch: 5| Step: 3
Training loss: 1.8054335117340088
Validation loss: 2.023685226837794

Epoch: 5| Step: 4
Training loss: 2.3245034217834473
Validation loss: 2.0166468967994056

Epoch: 5| Step: 5
Training loss: 1.9748084545135498
Validation loss: 2.020061900218328

Epoch: 5| Step: 6
Training loss: 2.246870756149292
Validation loss: 2.0259617964426675

Epoch: 5| Step: 7
Training loss: 2.1591198444366455
Validation loss: 2.025770033399264

Epoch: 5| Step: 8
Training loss: 2.0290284156799316
Validation loss: 2.02569442987442

Epoch: 5| Step: 9
Training loss: 2.557098150253296
Validation loss: 2.022848218679428

Epoch: 5| Step: 10
Training loss: 1.9250351190567017
Validation loss: 2.012692848841349

Epoch: 5| Step: 11
Training loss: 0.8734407424926758
Validation loss: 2.016239290436109

Epoch: 120| Step: 0
Training loss: 1.9701011180877686
Validation loss: 2.024469092488289

Epoch: 5| Step: 1
Training loss: 2.065171003341675
Validation loss: 2.02401469151179

Epoch: 5| Step: 2
Training loss: 1.5456979274749756
Validation loss: 2.029475043217341

Epoch: 5| Step: 3
Training loss: 2.4839370250701904
Validation loss: 2.0474646339813867

Epoch: 5| Step: 4
Training loss: 2.031416416168213
Validation loss: 2.054629385471344

Epoch: 5| Step: 5
Training loss: 1.8768703937530518
Validation loss: 2.053371881445249

Epoch: 5| Step: 6
Training loss: 2.3194167613983154
Validation loss: 2.059206331769625

Epoch: 5| Step: 7
Training loss: 2.0995631217956543
Validation loss: 2.0592222859462104

Epoch: 5| Step: 8
Training loss: 2.0234551429748535
Validation loss: 2.058311844865481

Epoch: 5| Step: 9
Training loss: 2.463606595993042
Validation loss: 2.0363429387410483

Epoch: 5| Step: 10
Training loss: 2.117962598800659
Validation loss: 2.0245113472143808

Epoch: 5| Step: 11
Training loss: 2.5853214263916016
Validation loss: 2.0095205207665763

Epoch: 121| Step: 0
Training loss: 2.01505708694458
Validation loss: 2.00302562614282

Epoch: 5| Step: 1
Training loss: 1.747153878211975
Validation loss: 2.008725290497144

Epoch: 5| Step: 2
Training loss: 1.9120261669158936
Validation loss: 2.0049184958140054

Epoch: 5| Step: 3
Training loss: 2.607822895050049
Validation loss: 2.0158438086509705

Epoch: 5| Step: 4
Training loss: 2.27341365814209
Validation loss: 2.0100669910510383

Epoch: 5| Step: 5
Training loss: 1.4902231693267822
Validation loss: 2.0164733777443566

Epoch: 5| Step: 6
Training loss: 1.7626330852508545
Validation loss: 2.025574117898941

Epoch: 5| Step: 7
Training loss: 2.445129632949829
Validation loss: 2.0244924426078796

Epoch: 5| Step: 8
Training loss: 2.6513020992279053
Validation loss: 2.028915231426557

Epoch: 5| Step: 9
Training loss: 1.9020681381225586
Validation loss: 2.0468228658040366

Epoch: 5| Step: 10
Training loss: 2.057239532470703
Validation loss: 2.030553420384725

Epoch: 5| Step: 11
Training loss: 2.701140880584717
Validation loss: 2.0301745931307473

Epoch: 122| Step: 0
Training loss: 2.4363293647766113
Validation loss: 2.050652782122294

Epoch: 5| Step: 1
Training loss: 2.064795970916748
Validation loss: 2.0434752106666565

Epoch: 5| Step: 2
Training loss: 2.2588906288146973
Validation loss: 2.0576418240865073

Epoch: 5| Step: 3
Training loss: 1.8150027990341187
Validation loss: 2.049505040049553

Epoch: 5| Step: 4
Training loss: 2.3119094371795654
Validation loss: 2.0509768575429916

Epoch: 5| Step: 5
Training loss: 1.6799532175064087
Validation loss: 2.0491898407538733

Epoch: 5| Step: 6
Training loss: 2.2225558757781982
Validation loss: 2.030708134174347

Epoch: 5| Step: 7
Training loss: 1.962411642074585
Validation loss: 2.0218392511208854

Epoch: 5| Step: 8
Training loss: 1.4711447954177856
Validation loss: 2.034611244996389

Epoch: 5| Step: 9
Training loss: 2.414083480834961
Validation loss: 2.029076193769773

Epoch: 5| Step: 10
Training loss: 2.4348654747009277
Validation loss: 2.019363353649775

Epoch: 5| Step: 11
Training loss: 1.9049705266952515
Validation loss: 2.0311726878086724

Epoch: 123| Step: 0
Training loss: 1.8067744970321655
Validation loss: 2.0305579801400504

Epoch: 5| Step: 1
Training loss: 2.4982540607452393
Validation loss: 2.05477807422479

Epoch: 5| Step: 2
Training loss: 2.0157673358917236
Validation loss: 2.0689601004123688

Epoch: 5| Step: 3
Training loss: 1.8355671167373657
Validation loss: 2.085628648598989

Epoch: 5| Step: 4
Training loss: 1.5303035974502563
Validation loss: 2.0902259896198907

Epoch: 5| Step: 5
Training loss: 2.3073883056640625
Validation loss: 2.078994204600652

Epoch: 5| Step: 6
Training loss: 2.3813602924346924
Validation loss: 2.0700803399086

Epoch: 5| Step: 7
Training loss: 2.581355571746826
Validation loss: 2.063525080680847

Epoch: 5| Step: 8
Training loss: 1.8675596714019775
Validation loss: 2.055366044243177

Epoch: 5| Step: 9
Training loss: 2.1279969215393066
Validation loss: 2.0442981074253717

Epoch: 5| Step: 10
Training loss: 2.0020995140075684
Validation loss: 2.0372303128242493

Epoch: 5| Step: 11
Training loss: 2.923400640487671
Validation loss: 2.0338396777709327

Epoch: 124| Step: 0
Training loss: 2.165167808532715
Validation loss: 2.0216809461514154

Epoch: 5| Step: 1
Training loss: 2.0144314765930176
Validation loss: 2.0174304048220315

Epoch: 5| Step: 2
Training loss: 2.2193284034729004
Validation loss: 2.0207282255093255

Epoch: 5| Step: 3
Training loss: 2.0004305839538574
Validation loss: 2.018399655818939

Epoch: 5| Step: 4
Training loss: 1.5259135961532593
Validation loss: 2.021540100375811

Epoch: 5| Step: 5
Training loss: 2.3071346282958984
Validation loss: 2.02480382223924

Epoch: 5| Step: 6
Training loss: 1.9791492223739624
Validation loss: 2.0121621241172156

Epoch: 5| Step: 7
Training loss: 2.2493529319763184
Validation loss: 2.010768378774325

Epoch: 5| Step: 8
Training loss: 2.457249641418457
Validation loss: 2.0183644940455756

Epoch: 5| Step: 9
Training loss: 2.4593095779418945
Validation loss: 2.0188614080349603

Epoch: 5| Step: 10
Training loss: 1.6764122247695923
Validation loss: 2.0228187491496405

Epoch: 5| Step: 11
Training loss: 1.8617703914642334
Validation loss: 2.0335908780495324

Epoch: 125| Step: 0
Training loss: 1.9257580041885376
Validation loss: 2.0504234383503595

Epoch: 5| Step: 1
Training loss: 2.419227361679077
Validation loss: 2.0397871236006417

Epoch: 5| Step: 2
Training loss: 2.007730007171631
Validation loss: 2.040544485052427

Epoch: 5| Step: 3
Training loss: 2.6479363441467285
Validation loss: 2.0363332082827887

Epoch: 5| Step: 4
Training loss: 1.9776824712753296
Validation loss: 2.023041680455208

Epoch: 5| Step: 5
Training loss: 1.9804580211639404
Validation loss: 2.027528097232183

Epoch: 5| Step: 6
Training loss: 2.0104405879974365
Validation loss: 2.038667564590772

Epoch: 5| Step: 7
Training loss: 1.589057207107544
Validation loss: 2.029861936966578

Epoch: 5| Step: 8
Training loss: 1.925614595413208
Validation loss: 2.041404590010643

Epoch: 5| Step: 9
Training loss: 2.1270270347595215
Validation loss: 2.048821657896042

Epoch: 5| Step: 10
Training loss: 2.2533693313598633
Validation loss: 2.0462215493122735

Epoch: 5| Step: 11
Training loss: 1.3246734142303467
Validation loss: 2.0657229820887246

Epoch: 126| Step: 0
Training loss: 2.6493990421295166
Validation loss: 2.060214107235273

Epoch: 5| Step: 1
Training loss: 2.0226502418518066
Validation loss: 2.046805818875631

Epoch: 5| Step: 2
Training loss: 1.6409275531768799
Validation loss: 2.0541062156359353

Epoch: 5| Step: 3
Training loss: 1.8850133419036865
Validation loss: 2.04919325808684

Epoch: 5| Step: 4
Training loss: 2.2679765224456787
Validation loss: 2.0443674673636756

Epoch: 5| Step: 5
Training loss: 1.6972347497940063
Validation loss: 2.0358453591664634

Epoch: 5| Step: 6
Training loss: 1.9031116962432861
Validation loss: 2.0386625031630197

Epoch: 5| Step: 7
Training loss: 2.2951087951660156
Validation loss: 2.0532054205735526

Epoch: 5| Step: 8
Training loss: 2.324678897857666
Validation loss: 2.0547226866086326

Epoch: 5| Step: 9
Training loss: 2.085939884185791
Validation loss: 2.0448926190535226

Epoch: 5| Step: 10
Training loss: 2.163830041885376
Validation loss: 2.0387638012568154

Epoch: 5| Step: 11
Training loss: 2.7040295600891113
Validation loss: 2.039433533946673

Epoch: 127| Step: 0
Training loss: 1.8045156002044678
Validation loss: 2.05037126938502

Epoch: 5| Step: 1
Training loss: 2.335742950439453
Validation loss: 2.033946712811788

Epoch: 5| Step: 2
Training loss: 2.5377461910247803
Validation loss: 2.03761824965477

Epoch: 5| Step: 3
Training loss: 1.703404426574707
Validation loss: 2.03753200173378

Epoch: 5| Step: 4
Training loss: 1.7474956512451172
Validation loss: 2.0597911278406777

Epoch: 5| Step: 5
Training loss: 2.188161611557007
Validation loss: 2.0486521869897842

Epoch: 5| Step: 6
Training loss: 2.4274322986602783
Validation loss: 2.0522646655639014

Epoch: 5| Step: 7
Training loss: 2.4797215461730957
Validation loss: 2.04241211215655

Epoch: 5| Step: 8
Training loss: 1.9015560150146484
Validation loss: 2.036126658320427

Epoch: 5| Step: 9
Training loss: 2.3725764751434326
Validation loss: 2.027364437778791

Epoch: 5| Step: 10
Training loss: 1.621201515197754
Validation loss: 2.037423183520635

Epoch: 5| Step: 11
Training loss: 1.0904077291488647
Validation loss: 2.0157309720913568

Epoch: 128| Step: 0
Training loss: 1.5566436052322388
Validation loss: 2.0211380074421563

Epoch: 5| Step: 1
Training loss: 2.271531343460083
Validation loss: 2.022708609700203

Epoch: 5| Step: 2
Training loss: 1.9449145793914795
Validation loss: 2.0192838360865912

Epoch: 5| Step: 3
Training loss: 2.7527172565460205
Validation loss: 2.012160430351893

Epoch: 5| Step: 4
Training loss: 2.332380533218384
Validation loss: 2.0253378252188363

Epoch: 5| Step: 5
Training loss: 1.950120210647583
Validation loss: 2.0219299693902335

Epoch: 5| Step: 6
Training loss: 2.133273124694824
Validation loss: 2.0227948874235153

Epoch: 5| Step: 7
Training loss: 1.9399166107177734
Validation loss: 2.0219984898964563

Epoch: 5| Step: 8
Training loss: 1.9759715795516968
Validation loss: 2.0313546111186347

Epoch: 5| Step: 9
Training loss: 1.749063491821289
Validation loss: 2.031449551383654

Epoch: 5| Step: 10
Training loss: 2.2649052143096924
Validation loss: 2.054955547054609

Epoch: 5| Step: 11
Training loss: 1.9057990312576294
Validation loss: 2.0573448538780212

Epoch: 129| Step: 0
Training loss: 2.6390013694763184
Validation loss: 2.0571626325448356

Epoch: 5| Step: 1
Training loss: 2.008993625640869
Validation loss: 2.0406543215115867

Epoch: 5| Step: 2
Training loss: 2.2213892936706543
Validation loss: 2.049338052670161

Epoch: 5| Step: 3
Training loss: 1.9071203470230103
Validation loss: 2.0343013356129327

Epoch: 5| Step: 4
Training loss: 1.9863144159317017
Validation loss: 2.033848817149798

Epoch: 5| Step: 5
Training loss: 2.1283764839172363
Validation loss: 2.031054601073265

Epoch: 5| Step: 6
Training loss: 1.85260009765625
Validation loss: 2.041262944539388

Epoch: 5| Step: 7
Training loss: 1.7162673473358154
Validation loss: 2.0510163803895316

Epoch: 5| Step: 8
Training loss: 2.2398033142089844
Validation loss: 2.0587563614050546

Epoch: 5| Step: 9
Training loss: 2.2643885612487793
Validation loss: 2.0837240715821586

Epoch: 5| Step: 10
Training loss: 2.126465082168579
Validation loss: 2.0958939542373023

Epoch: 5| Step: 11
Training loss: 1.3826136589050293
Validation loss: 2.1119627406199775

Epoch: 130| Step: 0
Training loss: 2.3195958137512207
Validation loss: 2.0738769471645355

Epoch: 5| Step: 1
Training loss: 2.208192825317383
Validation loss: 2.050363153219223

Epoch: 5| Step: 2
Training loss: 1.6377668380737305
Validation loss: 2.045568739374479

Epoch: 5| Step: 3
Training loss: 1.7527427673339844
Validation loss: 2.038593292236328

Epoch: 5| Step: 4
Training loss: 2.1561214923858643
Validation loss: 2.0375617196162543

Epoch: 5| Step: 5
Training loss: 2.1514878273010254
Validation loss: 2.032071421543757

Epoch: 5| Step: 6
Training loss: 1.7837263345718384
Validation loss: 2.0208456963300705

Epoch: 5| Step: 7
Training loss: 1.9260079860687256
Validation loss: 2.0285317997137704

Epoch: 5| Step: 8
Training loss: 1.8951303958892822
Validation loss: 2.034052928288778

Epoch: 5| Step: 9
Training loss: 2.56166672706604
Validation loss: 2.030590375264486

Epoch: 5| Step: 10
Training loss: 2.4784646034240723
Validation loss: 2.0287326822678247

Epoch: 5| Step: 11
Training loss: 1.5988779067993164
Validation loss: 2.038911526401838

Epoch: 131| Step: 0
Training loss: 2.1099071502685547
Validation loss: 2.04627592364947

Epoch: 5| Step: 1
Training loss: 2.7197728157043457
Validation loss: 2.0624779959519706

Epoch: 5| Step: 2
Training loss: 1.7251085042953491
Validation loss: 2.0834218859672546

Epoch: 5| Step: 3
Training loss: 2.276334047317505
Validation loss: 2.0931213249762854

Epoch: 5| Step: 4
Training loss: 2.3026814460754395
Validation loss: 2.128721311688423

Epoch: 5| Step: 5
Training loss: 1.8528587818145752
Validation loss: 2.1359649201234183

Epoch: 5| Step: 6
Training loss: 1.7211053371429443
Validation loss: 2.1254564076662064

Epoch: 5| Step: 7
Training loss: 2.514211654663086
Validation loss: 2.0951868295669556

Epoch: 5| Step: 8
Training loss: 1.9184688329696655
Validation loss: 2.0824967374404273

Epoch: 5| Step: 9
Training loss: 2.1108665466308594
Validation loss: 2.0609691937764487

Epoch: 5| Step: 10
Training loss: 2.1605818271636963
Validation loss: 2.036743233601252

Epoch: 5| Step: 11
Training loss: 2.7692103385925293
Validation loss: 2.017984300851822

Epoch: 132| Step: 0
Training loss: 1.9859405755996704
Validation loss: 2.012640565633774

Epoch: 5| Step: 1
Training loss: 1.8080081939697266
Validation loss: 2.009102831284205

Epoch: 5| Step: 2
Training loss: 1.7438156604766846
Validation loss: 2.021491840481758

Epoch: 5| Step: 3
Training loss: 2.1459033489227295
Validation loss: 2.028872256477674

Epoch: 5| Step: 4
Training loss: 2.429008960723877
Validation loss: 2.0328113734722137

Epoch: 5| Step: 5
Training loss: 2.3983802795410156
Validation loss: 2.025332654515902

Epoch: 5| Step: 6
Training loss: 1.7932510375976562
Validation loss: 2.0325707346200943

Epoch: 5| Step: 7
Training loss: 2.3416600227355957
Validation loss: 2.027155031760534

Epoch: 5| Step: 8
Training loss: 2.309382915496826
Validation loss: 2.034920463959376

Epoch: 5| Step: 9
Training loss: 2.3496203422546387
Validation loss: 2.0317377199729285

Epoch: 5| Step: 10
Training loss: 2.3278472423553467
Validation loss: 2.0446475942929587

Epoch: 5| Step: 11
Training loss: 2.167238235473633
Validation loss: 2.034562200307846

Epoch: 133| Step: 0
Training loss: 2.1363632678985596
Validation loss: 2.0328365564346313

Epoch: 5| Step: 1
Training loss: 2.191710948944092
Validation loss: 2.0356215039889016

Epoch: 5| Step: 2
Training loss: 2.245687961578369
Validation loss: 2.0301988224188485

Epoch: 5| Step: 3
Training loss: 2.4016611576080322
Validation loss: 2.0266733517249427

Epoch: 5| Step: 4
Training loss: 1.9462125301361084
Validation loss: 2.032033940156301

Epoch: 5| Step: 5
Training loss: 1.9188525676727295
Validation loss: 2.0262543310721717

Epoch: 5| Step: 6
Training loss: 2.168926954269409
Validation loss: 2.034081215659777

Epoch: 5| Step: 7
Training loss: 2.6265745162963867
Validation loss: 2.022848069667816

Epoch: 5| Step: 8
Training loss: 2.128380060195923
Validation loss: 2.032991886138916

Epoch: 5| Step: 9
Training loss: 1.5486987829208374
Validation loss: 2.0393987049659095

Epoch: 5| Step: 10
Training loss: 2.302828311920166
Validation loss: 2.028092419107755

Epoch: 5| Step: 11
Training loss: 1.63081693649292
Validation loss: 2.035179371635119

Epoch: 134| Step: 0
Training loss: 2.3541152477264404
Validation loss: 2.0449326634407043

Epoch: 5| Step: 1
Training loss: 2.2124054431915283
Validation loss: 2.0286447952191033

Epoch: 5| Step: 2
Training loss: 2.0255346298217773
Validation loss: 2.0492315044005713

Epoch: 5| Step: 3
Training loss: 2.3544116020202637
Validation loss: 2.0532297094662986

Epoch: 5| Step: 4
Training loss: 2.2410216331481934
Validation loss: 2.0572608759005866

Epoch: 5| Step: 5
Training loss: 1.8944950103759766
Validation loss: 2.0520490805308023

Epoch: 5| Step: 6
Training loss: 2.103802442550659
Validation loss: 2.0460239350795746

Epoch: 5| Step: 7
Training loss: 2.229595184326172
Validation loss: 2.0489943524201712

Epoch: 5| Step: 8
Training loss: 1.9792871475219727
Validation loss: 2.055086980263392

Epoch: 5| Step: 9
Training loss: 1.6414821147918701
Validation loss: 2.0640735775232315

Epoch: 5| Step: 10
Training loss: 2.083939790725708
Validation loss: 2.051835065086683

Epoch: 5| Step: 11
Training loss: 1.2650725841522217
Validation loss: 2.0532486538092294

Epoch: 135| Step: 0
Training loss: 2.910799264907837
Validation loss: 2.0566585610310235

Epoch: 5| Step: 1
Training loss: 1.8481346368789673
Validation loss: 2.047975078225136

Epoch: 5| Step: 2
Training loss: 2.037412166595459
Validation loss: 2.0469374457995095

Epoch: 5| Step: 3
Training loss: 2.0525612831115723
Validation loss: 2.0550372848908105

Epoch: 5| Step: 4
Training loss: 1.7229881286621094
Validation loss: 2.05083329975605

Epoch: 5| Step: 5
Training loss: 1.7746717929840088
Validation loss: 2.043172463774681

Epoch: 5| Step: 6
Training loss: 2.3677666187286377
Validation loss: 2.043079301714897

Epoch: 5| Step: 7
Training loss: 2.2735047340393066
Validation loss: 2.0433103839556375

Epoch: 5| Step: 8
Training loss: 2.269225597381592
Validation loss: 2.036637524763743

Epoch: 5| Step: 9
Training loss: 2.200479030609131
Validation loss: 2.0379177133242288

Epoch: 5| Step: 10
Training loss: 1.3303115367889404
Validation loss: 2.0458336820205054

Epoch: 5| Step: 11
Training loss: 1.8435848951339722
Validation loss: 2.034078672528267

Epoch: 136| Step: 0
Training loss: 1.9438445568084717
Validation loss: 2.0528995295365653

Epoch: 5| Step: 1
Training loss: 2.1596827507019043
Validation loss: 2.059155359864235

Epoch: 5| Step: 2
Training loss: 2.0398032665252686
Validation loss: 2.0750187089045844

Epoch: 5| Step: 3
Training loss: 2.070573329925537
Validation loss: 2.05698769291242

Epoch: 5| Step: 4
Training loss: 1.7260128259658813
Validation loss: 2.063349018494288

Epoch: 5| Step: 5
Training loss: 2.6929664611816406
Validation loss: 2.0590838690598807

Epoch: 5| Step: 6
Training loss: 1.6919622421264648
Validation loss: 2.059986690680186

Epoch: 5| Step: 7
Training loss: 2.0621070861816406
Validation loss: 2.06570757428805

Epoch: 5| Step: 8
Training loss: 1.6770700216293335
Validation loss: 2.0562884509563446

Epoch: 5| Step: 9
Training loss: 2.172417402267456
Validation loss: 2.0506601333618164

Epoch: 5| Step: 10
Training loss: 2.398998737335205
Validation loss: 2.045723577340444

Epoch: 5| Step: 11
Training loss: 2.695197582244873
Validation loss: 2.0464876194794974

Epoch: 137| Step: 0
Training loss: 2.0234198570251465
Validation loss: 2.039999673763911

Epoch: 5| Step: 1
Training loss: 1.5204895734786987
Validation loss: 2.056438515583674

Epoch: 5| Step: 2
Training loss: 2.378772735595703
Validation loss: 2.050228794415792

Epoch: 5| Step: 3
Training loss: 2.3938822746276855
Validation loss: 2.0554427256186805

Epoch: 5| Step: 4
Training loss: 1.6481506824493408
Validation loss: 2.066649948557218

Epoch: 5| Step: 5
Training loss: 1.9820867776870728
Validation loss: 2.075770929455757

Epoch: 5| Step: 6
Training loss: 2.3350718021392822
Validation loss: 2.066850190361341

Epoch: 5| Step: 7
Training loss: 2.3586201667785645
Validation loss: 2.0723649511734643

Epoch: 5| Step: 8
Training loss: 1.59376060962677
Validation loss: 2.074191381533941

Epoch: 5| Step: 9
Training loss: 2.639894962310791
Validation loss: 2.0854521493117013

Epoch: 5| Step: 10
Training loss: 1.5731050968170166
Validation loss: 2.072422221302986

Epoch: 5| Step: 11
Training loss: 2.2953810691833496
Validation loss: 2.0735540191332498

Epoch: 138| Step: 0
Training loss: 2.3092331886291504
Validation loss: 2.069186498721441

Epoch: 5| Step: 1
Training loss: 1.2670098543167114
Validation loss: 2.070678174495697

Epoch: 5| Step: 2
Training loss: 2.1098875999450684
Validation loss: 2.0591378808021545

Epoch: 5| Step: 3
Training loss: 1.8828067779541016
Validation loss: 2.062529429793358

Epoch: 5| Step: 4
Training loss: 1.944685935974121
Validation loss: 2.0446675568819046

Epoch: 5| Step: 5
Training loss: 2.011716842651367
Validation loss: 2.047600651780764

Epoch: 5| Step: 6
Training loss: 2.4243366718292236
Validation loss: 2.049439628918966

Epoch: 5| Step: 7
Training loss: 1.5656869411468506
Validation loss: 2.053924838701884

Epoch: 5| Step: 8
Training loss: 2.537158250808716
Validation loss: 2.0595207065343857

Epoch: 5| Step: 9
Training loss: 2.0746970176696777
Validation loss: 2.058031772573789

Epoch: 5| Step: 10
Training loss: 2.2829127311706543
Validation loss: 2.0688348511854806

Epoch: 5| Step: 11
Training loss: 2.0617260932922363
Validation loss: 2.076741928855578

Epoch: 139| Step: 0
Training loss: 2.0056650638580322
Validation loss: 2.085285703341166

Epoch: 5| Step: 1
Training loss: 2.4745192527770996
Validation loss: 2.0791670779387155

Epoch: 5| Step: 2
Training loss: 1.5590969324111938
Validation loss: 2.079566697279612

Epoch: 5| Step: 3
Training loss: 1.819645881652832
Validation loss: 2.0747248232364655

Epoch: 5| Step: 4
Training loss: 2.3321785926818848
Validation loss: 2.0642691353956857

Epoch: 5| Step: 5
Training loss: 2.4342453479766846
Validation loss: 2.0599539081255593

Epoch: 5| Step: 6
Training loss: 2.373108148574829
Validation loss: 2.0587597588698068

Epoch: 5| Step: 7
Training loss: 1.8327038288116455
Validation loss: 2.0466837187608085

Epoch: 5| Step: 8
Training loss: 1.9422028064727783
Validation loss: 2.0601831674575806

Epoch: 5| Step: 9
Training loss: 1.8867782354354858
Validation loss: 2.0456852267185845

Epoch: 5| Step: 10
Training loss: 1.9489355087280273
Validation loss: 2.0400775025288262

Epoch: 5| Step: 11
Training loss: 1.2705634832382202
Validation loss: 2.0565672665834427

Epoch: 140| Step: 0
Training loss: 1.429819107055664
Validation loss: 2.0614386896292367

Epoch: 5| Step: 1
Training loss: 1.7930071353912354
Validation loss: 2.088914001981417

Epoch: 5| Step: 2
Training loss: 2.191307783126831
Validation loss: 2.0861985931793847

Epoch: 5| Step: 3
Training loss: 2.2725234031677246
Validation loss: 2.0979419400294623

Epoch: 5| Step: 4
Training loss: 2.247499465942383
Validation loss: 2.1199036637941995

Epoch: 5| Step: 5
Training loss: 3.0128865242004395
Validation loss: 2.1120708684126535

Epoch: 5| Step: 6
Training loss: 2.148939847946167
Validation loss: 2.0979790141185126

Epoch: 5| Step: 7
Training loss: 1.8078100681304932
Validation loss: 2.097877870003382

Epoch: 5| Step: 8
Training loss: 2.13688588142395
Validation loss: 2.092852642138799

Epoch: 5| Step: 9
Training loss: 1.6019306182861328
Validation loss: 2.0880933503309884

Epoch: 5| Step: 10
Training loss: 2.0115041732788086
Validation loss: 2.0696211606264114

Epoch: 5| Step: 11
Training loss: 2.1833269596099854
Validation loss: 2.0574432810147605

Epoch: 141| Step: 0
Training loss: 2.1879985332489014
Validation loss: 2.0530494103829064

Epoch: 5| Step: 1
Training loss: 2.1080944538116455
Validation loss: 2.0492637902498245

Epoch: 5| Step: 2
Training loss: 2.0111374855041504
Validation loss: 2.052433500687281

Epoch: 5| Step: 3
Training loss: 1.6569175720214844
Validation loss: 2.050034741560618

Epoch: 5| Step: 4
Training loss: 1.844644546508789
Validation loss: 2.0509296655654907

Epoch: 5| Step: 5
Training loss: 2.077415943145752
Validation loss: 2.0388982743024826

Epoch: 5| Step: 6
Training loss: 2.3909666538238525
Validation loss: 2.050574913620949

Epoch: 5| Step: 7
Training loss: 2.4438350200653076
Validation loss: 2.0506131251653037

Epoch: 5| Step: 8
Training loss: 1.8400062322616577
Validation loss: 2.0528328120708466

Epoch: 5| Step: 9
Training loss: 2.0722830295562744
Validation loss: 2.060968597730001

Epoch: 5| Step: 10
Training loss: 1.8718812465667725
Validation loss: 2.064489816625913

Epoch: 5| Step: 11
Training loss: 2.434108257293701
Validation loss: 2.0576766977707543

Epoch: 142| Step: 0
Training loss: 2.1415412425994873
Validation loss: 2.070289393266042

Epoch: 5| Step: 1
Training loss: 1.5337777137756348
Validation loss: 2.064552277326584

Epoch: 5| Step: 2
Training loss: 2.244948625564575
Validation loss: 2.0680304020643234

Epoch: 5| Step: 3
Training loss: 2.09590220451355
Validation loss: 2.065006817380587

Epoch: 5| Step: 4
Training loss: 2.439267635345459
Validation loss: 2.067082643508911

Epoch: 5| Step: 5
Training loss: 2.0779004096984863
Validation loss: 2.067616884907087

Epoch: 5| Step: 6
Training loss: 1.816184639930725
Validation loss: 2.0644798576831818

Epoch: 5| Step: 7
Training loss: 1.7924209833145142
Validation loss: 2.0671131710211434

Epoch: 5| Step: 8
Training loss: 1.8994643688201904
Validation loss: 2.0529436816771827

Epoch: 5| Step: 9
Training loss: 2.2095961570739746
Validation loss: 2.05406561990579

Epoch: 5| Step: 10
Training loss: 1.9203811883926392
Validation loss: 2.0603372951348624

Epoch: 5| Step: 11
Training loss: 2.6366841793060303
Validation loss: 2.0569070180257163

Epoch: 143| Step: 0
Training loss: 2.3027687072753906
Validation loss: 2.0507435450951257

Epoch: 5| Step: 1
Training loss: 1.8865569829940796
Validation loss: 2.054118514060974

Epoch: 5| Step: 2
Training loss: 1.5448095798492432
Validation loss: 2.0377737631400428

Epoch: 5| Step: 3
Training loss: 2.4271881580352783
Validation loss: 2.0868443747361503

Epoch: 5| Step: 4
Training loss: 2.383530378341675
Validation loss: 2.0780002176761627

Epoch: 5| Step: 5
Training loss: 1.4528058767318726
Validation loss: 2.092795208096504

Epoch: 5| Step: 6
Training loss: 1.9766108989715576
Validation loss: 2.093451281388601

Epoch: 5| Step: 7
Training loss: 1.8235410451889038
Validation loss: 2.10985038181146

Epoch: 5| Step: 8
Training loss: 2.142740249633789
Validation loss: 2.101723978916804

Epoch: 5| Step: 9
Training loss: 1.9563570022583008
Validation loss: 2.077996402978897

Epoch: 5| Step: 10
Training loss: 2.3535499572753906
Validation loss: 2.0889948308467865

Epoch: 5| Step: 11
Training loss: 3.1070499420166016
Validation loss: 2.088112751642863

Epoch: 144| Step: 0
Training loss: 1.484964370727539
Validation loss: 2.0776698291301727

Epoch: 5| Step: 1
Training loss: 2.584470272064209
Validation loss: 2.067147970199585

Epoch: 5| Step: 2
Training loss: 1.8977864980697632
Validation loss: 2.0656867921352386

Epoch: 5| Step: 3
Training loss: 1.9368326663970947
Validation loss: 2.063046524922053

Epoch: 5| Step: 4
Training loss: 2.8014895915985107
Validation loss: 2.0644998302062354

Epoch: 5| Step: 5
Training loss: 1.872135877609253
Validation loss: 2.0750343054533005

Epoch: 5| Step: 6
Training loss: 2.028383731842041
Validation loss: 2.0757821599642434

Epoch: 5| Step: 7
Training loss: 2.3702189922332764
Validation loss: 2.0733270744482675

Epoch: 5| Step: 8
Training loss: 1.1650159358978271
Validation loss: 2.0828439394632974

Epoch: 5| Step: 9
Training loss: 2.216696262359619
Validation loss: 2.087979475657145

Epoch: 5| Step: 10
Training loss: 1.9789037704467773
Validation loss: 2.0802619258562722

Epoch: 5| Step: 11
Training loss: 2.3003616333007812
Validation loss: 2.0879127035538354

Epoch: 145| Step: 0
Training loss: 2.01448917388916
Validation loss: 2.0934461454550424

Epoch: 5| Step: 1
Training loss: 2.0047454833984375
Validation loss: 2.1014320154984794

Epoch: 5| Step: 2
Training loss: 2.530982732772827
Validation loss: 2.0991421043872833

Epoch: 5| Step: 3
Training loss: 2.330350875854492
Validation loss: 2.1047814190387726

Epoch: 5| Step: 4
Training loss: 2.295588731765747
Validation loss: 2.103652293483416

Epoch: 5| Step: 5
Training loss: 1.7794077396392822
Validation loss: 2.0976281811793647

Epoch: 5| Step: 6
Training loss: 2.0526700019836426
Validation loss: 2.0973840852578483

Epoch: 5| Step: 7
Training loss: 1.390195608139038
Validation loss: 2.08699939151605

Epoch: 5| Step: 8
Training loss: 2.3499507904052734
Validation loss: 2.0767862200737

Epoch: 5| Step: 9
Training loss: 1.707779884338379
Validation loss: 2.090915635228157

Epoch: 5| Step: 10
Training loss: 1.6184428930282593
Validation loss: 2.0877565294504166

Epoch: 5| Step: 11
Training loss: 3.3833136558532715
Validation loss: 2.073186621069908

Epoch: 146| Step: 0
Training loss: 2.2938599586486816
Validation loss: 2.066834623614947

Epoch: 5| Step: 1
Training loss: 1.9439274072647095
Validation loss: 2.067115212480227

Epoch: 5| Step: 2
Training loss: 1.524055004119873
Validation loss: 2.07311641673247

Epoch: 5| Step: 3
Training loss: 2.2271015644073486
Validation loss: 2.0791093905766806

Epoch: 5| Step: 4
Training loss: 2.1244630813598633
Validation loss: 2.0727896938721337

Epoch: 5| Step: 5
Training loss: 1.3953979015350342
Validation loss: 2.0672323952118554

Epoch: 5| Step: 6
Training loss: 2.0214736461639404
Validation loss: 2.082354813814163

Epoch: 5| Step: 7
Training loss: 2.513993740081787
Validation loss: 2.070956587791443

Epoch: 5| Step: 8
Training loss: 1.857765555381775
Validation loss: 2.0798178712526956

Epoch: 5| Step: 9
Training loss: 2.34470796585083
Validation loss: 2.103882605830828

Epoch: 5| Step: 10
Training loss: 1.9925439357757568
Validation loss: 2.0976070016622543

Epoch: 5| Step: 11
Training loss: 2.049943447113037
Validation loss: 2.107758949200312

Epoch: 147| Step: 0
Training loss: 1.9737746715545654
Validation loss: 2.097917233904203

Epoch: 5| Step: 1
Training loss: 1.791446328163147
Validation loss: 2.0891315887371698

Epoch: 5| Step: 2
Training loss: 2.084232807159424
Validation loss: 2.082889884710312

Epoch: 5| Step: 3
Training loss: 2.147355794906616
Validation loss: 2.0841689010461173

Epoch: 5| Step: 4
Training loss: 2.461940288543701
Validation loss: 2.0755781531333923

Epoch: 5| Step: 5
Training loss: 2.4910335540771484
Validation loss: 2.072058921058973

Epoch: 5| Step: 6
Training loss: 2.499413013458252
Validation loss: 2.0604664087295532

Epoch: 5| Step: 7
Training loss: 1.7181131839752197
Validation loss: 2.0605906347433725

Epoch: 5| Step: 8
Training loss: 1.9472367763519287
Validation loss: 2.061357021331787

Epoch: 5| Step: 9
Training loss: 1.8015680313110352
Validation loss: 2.0700010855992637

Epoch: 5| Step: 10
Training loss: 1.601220726966858
Validation loss: 2.0682799220085144

Epoch: 5| Step: 11
Training loss: 2.634603500366211
Validation loss: 2.068363224466642

Epoch: 148| Step: 0
Training loss: 2.0124099254608154
Validation loss: 2.068457161386808

Epoch: 5| Step: 1
Training loss: 1.5643770694732666
Validation loss: 2.091796229283015

Epoch: 5| Step: 2
Training loss: 1.9809372425079346
Validation loss: 2.091958229740461

Epoch: 5| Step: 3
Training loss: 1.6975882053375244
Validation loss: 2.0938473443190255

Epoch: 5| Step: 4
Training loss: 1.8870328664779663
Validation loss: 2.122458537419637

Epoch: 5| Step: 5
Training loss: 2.3883094787597656
Validation loss: 2.143136536081632

Epoch: 5| Step: 6
Training loss: 1.9593515396118164
Validation loss: 2.1392529159784317

Epoch: 5| Step: 7
Training loss: 2.3305304050445557
Validation loss: 2.159978156288465

Epoch: 5| Step: 8
Training loss: 2.3884449005126953
Validation loss: 2.1353169282277427

Epoch: 5| Step: 9
Training loss: 1.6111280918121338
Validation loss: 2.115275800228119

Epoch: 5| Step: 10
Training loss: 3.146918535232544
Validation loss: 2.087130760153135

Epoch: 5| Step: 11
Training loss: 1.9094281196594238
Validation loss: 2.0683636317650476

Epoch: 149| Step: 0
Training loss: 1.7404969930648804
Validation loss: 2.0547002951304116

Epoch: 5| Step: 1
Training loss: 1.9471431970596313
Validation loss: 2.0481607814629874

Epoch: 5| Step: 2
Training loss: 2.0197811126708984
Validation loss: 2.0543749233086905

Epoch: 5| Step: 3
Training loss: 2.4678311347961426
Validation loss: 2.0471595327059426

Epoch: 5| Step: 4
Training loss: 2.0042378902435303
Validation loss: 2.0521548936764398

Epoch: 5| Step: 5
Training loss: 2.333371162414551
Validation loss: 2.0467982788880668

Epoch: 5| Step: 6
Training loss: 2.2187225818634033
Validation loss: 2.042510077357292

Epoch: 5| Step: 7
Training loss: 1.2951266765594482
Validation loss: 2.0461831937233605

Epoch: 5| Step: 8
Training loss: 2.1343510150909424
Validation loss: 2.040217697620392

Epoch: 5| Step: 9
Training loss: 1.9316825866699219
Validation loss: 2.0544679214557013

Epoch: 5| Step: 10
Training loss: 2.2781496047973633
Validation loss: 2.0543156961599984

Epoch: 5| Step: 11
Training loss: 3.3376102447509766
Validation loss: 2.0579745968182883

Epoch: 150| Step: 0
Training loss: 2.3377528190612793
Validation loss: 2.0821836292743683

Epoch: 5| Step: 1
Training loss: 1.931171178817749
Validation loss: 2.1021034667889276

Epoch: 5| Step: 2
Training loss: 2.357781410217285
Validation loss: 2.1201354414224625

Epoch: 5| Step: 3
Training loss: 1.8609832525253296
Validation loss: 2.1125474969546

Epoch: 5| Step: 4
Training loss: 1.744459867477417
Validation loss: 2.1137193938096366

Epoch: 5| Step: 5
Training loss: 1.9609225988388062
Validation loss: 2.1155024568239846

Epoch: 5| Step: 6
Training loss: 2.402000665664673
Validation loss: 2.13135989010334

Epoch: 5| Step: 7
Training loss: 2.317392587661743
Validation loss: 2.1140553752581277

Epoch: 5| Step: 8
Training loss: 1.8276994228363037
Validation loss: 2.1174195061127343

Epoch: 5| Step: 9
Training loss: 1.6721538305282593
Validation loss: 2.116335153579712

Epoch: 5| Step: 10
Training loss: 2.1046557426452637
Validation loss: 2.094300443927447

Epoch: 5| Step: 11
Training loss: 1.4617525339126587
Validation loss: 2.0676170786221824

Epoch: 151| Step: 0
Training loss: 2.280048131942749
Validation loss: 2.079642723004023

Epoch: 5| Step: 1
Training loss: 1.694837212562561
Validation loss: 2.0765879452228546

Epoch: 5| Step: 2
Training loss: 2.3688504695892334
Validation loss: 2.0791524151961007

Epoch: 5| Step: 3
Training loss: 2.216097831726074
Validation loss: 2.0694045225779214

Epoch: 5| Step: 4
Training loss: 1.943756103515625
Validation loss: 2.0657138576110206

Epoch: 5| Step: 5
Training loss: 2.877354145050049
Validation loss: 2.0702081322669983

Epoch: 5| Step: 6
Training loss: 1.929603934288025
Validation loss: 2.0751711626847587

Epoch: 5| Step: 7
Training loss: 2.2062888145446777
Validation loss: 2.0662456452846527

Epoch: 5| Step: 8
Training loss: 1.4994093179702759
Validation loss: 2.0773394455512366

Epoch: 5| Step: 9
Training loss: 1.9929087162017822
Validation loss: 2.0770229498545327

Epoch: 5| Step: 10
Training loss: 1.6521915197372437
Validation loss: 2.0760017136732736

Epoch: 5| Step: 11
Training loss: 2.1226892471313477
Validation loss: 2.0759132653474808

Epoch: 152| Step: 0
Training loss: 1.4805691242218018
Validation loss: 2.1004640559355416

Epoch: 5| Step: 1
Training loss: 2.108792543411255
Validation loss: 2.1155641873677573

Epoch: 5| Step: 2
Training loss: 1.7298457622528076
Validation loss: 2.12097275753816

Epoch: 5| Step: 3
Training loss: 2.321928024291992
Validation loss: 2.134614661335945

Epoch: 5| Step: 4
Training loss: 2.074160575866699
Validation loss: 2.12491882344087

Epoch: 5| Step: 5
Training loss: 2.325261354446411
Validation loss: 2.1201427032550177

Epoch: 5| Step: 6
Training loss: 2.298283100128174
Validation loss: 2.0926491618156433

Epoch: 5| Step: 7
Training loss: 2.1017003059387207
Validation loss: 2.0786469131708145

Epoch: 5| Step: 8
Training loss: 2.062927722930908
Validation loss: 2.0854356586933136

Epoch: 5| Step: 9
Training loss: 2.266192674636841
Validation loss: 2.091461425026258

Epoch: 5| Step: 10
Training loss: 1.947986364364624
Validation loss: 2.090839962164561

Epoch: 5| Step: 11
Training loss: 1.6670234203338623
Validation loss: 2.0927770336469016

Epoch: 153| Step: 0
Training loss: 1.3249353170394897
Validation loss: 2.091955855488777

Epoch: 5| Step: 1
Training loss: 2.100220203399658
Validation loss: 2.106072093049685

Epoch: 5| Step: 2
Training loss: 2.2185354232788086
Validation loss: 2.0999802400668464

Epoch: 5| Step: 3
Training loss: 1.9151986837387085
Validation loss: 2.1149440010388694

Epoch: 5| Step: 4
Training loss: 1.5878190994262695
Validation loss: 2.1083621929089227

Epoch: 5| Step: 5
Training loss: 2.2048418521881104
Validation loss: 2.131749456127485

Epoch: 5| Step: 6
Training loss: 2.836343765258789
Validation loss: 2.1139524430036545

Epoch: 5| Step: 7
Training loss: 1.609230399131775
Validation loss: 2.119423881173134

Epoch: 5| Step: 8
Training loss: 2.1384243965148926
Validation loss: 2.1019085297981897

Epoch: 5| Step: 9
Training loss: 2.3459091186523438
Validation loss: 2.117702936132749

Epoch: 5| Step: 10
Training loss: 2.1358883380889893
Validation loss: 2.093863993883133

Epoch: 5| Step: 11
Training loss: 0.8683627843856812
Validation loss: 2.100361501177152

Epoch: 154| Step: 0
Training loss: 1.6215683221817017
Validation loss: 2.0833150148391724

Epoch: 5| Step: 1
Training loss: 2.2955479621887207
Validation loss: 2.085577428340912

Epoch: 5| Step: 2
Training loss: 1.7565749883651733
Validation loss: 2.0981720288594565

Epoch: 5| Step: 3
Training loss: 2.2656795978546143
Validation loss: 2.0896355460087457

Epoch: 5| Step: 4
Training loss: 2.3001058101654053
Validation loss: 2.0895154972871146

Epoch: 5| Step: 5
Training loss: 1.9883466958999634
Validation loss: 2.0864514857530594

Epoch: 5| Step: 6
Training loss: 1.920892357826233
Validation loss: 2.095905830462774

Epoch: 5| Step: 7
Training loss: 1.7715370655059814
Validation loss: 2.111391991376877

Epoch: 5| Step: 8
Training loss: 2.930480480194092
Validation loss: 2.1063590546449027

Epoch: 5| Step: 9
Training loss: 1.5550791025161743
Validation loss: 2.099707414706548

Epoch: 5| Step: 10
Training loss: 1.5111184120178223
Validation loss: 2.1155538161595664

Epoch: 5| Step: 11
Training loss: 2.073610544204712
Validation loss: 2.1218470434347787

Epoch: 155| Step: 0
Training loss: 1.974482774734497
Validation loss: 2.1346920281648636

Epoch: 5| Step: 1
Training loss: 2.164043664932251
Validation loss: 2.1297533263762793

Epoch: 5| Step: 2
Training loss: 1.9010694026947021
Validation loss: 2.1278762916723886

Epoch: 5| Step: 3
Training loss: 2.725714683532715
Validation loss: 2.129773964484533

Epoch: 5| Step: 4
Training loss: 2.509469985961914
Validation loss: 2.110663299759229

Epoch: 5| Step: 5
Training loss: 1.577154517173767
Validation loss: 2.1297716399033866

Epoch: 5| Step: 6
Training loss: 1.9331703186035156
Validation loss: 2.1345162789026895

Epoch: 5| Step: 7
Training loss: 2.0071685314178467
Validation loss: 2.1033376902341843

Epoch: 5| Step: 8
Training loss: 1.8065736293792725
Validation loss: 2.099953055381775

Epoch: 5| Step: 9
Training loss: 2.007108211517334
Validation loss: 2.089348167181015

Epoch: 5| Step: 10
Training loss: 1.7963874340057373
Validation loss: 2.087513526280721

Epoch: 5| Step: 11
Training loss: 1.3157663345336914
Validation loss: 2.0888444979985556

Epoch: 156| Step: 0
Training loss: 1.763307809829712
Validation loss: 2.072349180777868

Epoch: 5| Step: 1
Training loss: 2.4524736404418945
Validation loss: 2.0666256745656333

Epoch: 5| Step: 2
Training loss: 2.1369147300720215
Validation loss: 2.0626393208901086

Epoch: 5| Step: 3
Training loss: 2.4044528007507324
Validation loss: 2.0654657582441964

Epoch: 5| Step: 4
Training loss: 2.171278715133667
Validation loss: 2.070479149619738

Epoch: 5| Step: 5
Training loss: 1.794097661972046
Validation loss: 2.068043132623037

Epoch: 5| Step: 6
Training loss: 1.9023164510726929
Validation loss: 2.0633149445056915

Epoch: 5| Step: 7
Training loss: 1.7436130046844482
Validation loss: 2.0797517200311026

Epoch: 5| Step: 8
Training loss: 1.9659570455551147
Validation loss: 2.080230544010798

Epoch: 5| Step: 9
Training loss: 2.068769931793213
Validation loss: 2.085466300447782

Epoch: 5| Step: 10
Training loss: 2.17756986618042
Validation loss: 2.104304159681002

Epoch: 5| Step: 11
Training loss: 1.1772974729537964
Validation loss: 2.110085388024648

Epoch: 157| Step: 0
Training loss: 2.2348570823669434
Validation loss: 2.103554750482241

Epoch: 5| Step: 1
Training loss: 2.052578926086426
Validation loss: 2.1229366610447564

Epoch: 5| Step: 2
Training loss: 2.2684245109558105
Validation loss: 2.1223258475462594

Epoch: 5| Step: 3
Training loss: 1.9480243921279907
Validation loss: 2.112298866113027

Epoch: 5| Step: 4
Training loss: 2.1135170459747314
Validation loss: 2.111879661679268

Epoch: 5| Step: 5
Training loss: 1.6129413843154907
Validation loss: 2.0932858983675637

Epoch: 5| Step: 6
Training loss: 1.7280704975128174
Validation loss: 2.1061970392862954

Epoch: 5| Step: 7
Training loss: 1.8138885498046875
Validation loss: 2.099488690495491

Epoch: 5| Step: 8
Training loss: 1.9528052806854248
Validation loss: 2.0980911552906036

Epoch: 5| Step: 9
Training loss: 2.2350149154663086
Validation loss: 2.1085369984308877

Epoch: 5| Step: 10
Training loss: 2.012561321258545
Validation loss: 2.114617665608724

Epoch: 5| Step: 11
Training loss: 2.212454080581665
Validation loss: 2.097236449519793

Epoch: 158| Step: 0
Training loss: 2.6909475326538086
Validation loss: 2.113894000649452

Epoch: 5| Step: 1
Training loss: 2.109421730041504
Validation loss: 2.111792912085851

Epoch: 5| Step: 2
Training loss: 1.8779188394546509
Validation loss: 2.1143352687358856

Epoch: 5| Step: 3
Training loss: 2.1978063583374023
Validation loss: 2.0922634651263556

Epoch: 5| Step: 4
Training loss: 1.456987738609314
Validation loss: 2.1050789008537927

Epoch: 5| Step: 5
Training loss: 2.5016140937805176
Validation loss: 2.0907237082719803

Epoch: 5| Step: 6
Training loss: 1.743935227394104
Validation loss: 2.0810048331816993

Epoch: 5| Step: 7
Training loss: 2.254013776779175
Validation loss: 2.090082347393036

Epoch: 5| Step: 8
Training loss: 1.8137089014053345
Validation loss: 2.1089633454879126

Epoch: 5| Step: 9
Training loss: 1.5807098150253296
Validation loss: 2.120459829767545

Epoch: 5| Step: 10
Training loss: 1.7746388912200928
Validation loss: 2.107936014731725

Epoch: 5| Step: 11
Training loss: 2.005309581756592
Validation loss: 2.1148345669110618

Epoch: 159| Step: 0
Training loss: 1.637428641319275
Validation loss: 2.1324397027492523

Epoch: 5| Step: 1
Training loss: 2.081150531768799
Validation loss: 2.119720935821533

Epoch: 5| Step: 2
Training loss: 2.166011333465576
Validation loss: 2.1319061319033303

Epoch: 5| Step: 3
Training loss: 2.06343412399292
Validation loss: 2.1203095813592276

Epoch: 5| Step: 4
Training loss: 3.0784974098205566
Validation loss: 2.1298434336980185

Epoch: 5| Step: 5
Training loss: 1.8415340185165405
Validation loss: 2.1108505527178445

Epoch: 5| Step: 6
Training loss: 2.060624599456787
Validation loss: 2.1151546935240426

Epoch: 5| Step: 7
Training loss: 1.6582269668579102
Validation loss: 2.0891143083572388

Epoch: 5| Step: 8
Training loss: 2.017043113708496
Validation loss: 2.090326557556788

Epoch: 5| Step: 9
Training loss: 1.618141531944275
Validation loss: 2.0822388231754303

Epoch: 5| Step: 10
Training loss: 1.8746795654296875
Validation loss: 2.0782486498355865

Epoch: 5| Step: 11
Training loss: 1.522426962852478
Validation loss: 2.0949988067150116

Epoch: 160| Step: 0
Training loss: 1.5878567695617676
Validation loss: 2.0848312427600226

Epoch: 5| Step: 1
Training loss: 1.9771476984024048
Validation loss: 2.115218753616015

Epoch: 5| Step: 2
Training loss: 1.7436050176620483
Validation loss: 2.1175501545270285

Epoch: 5| Step: 3
Training loss: 2.3034157752990723
Validation loss: 2.13928293188413

Epoch: 5| Step: 4
Training loss: 2.04337477684021
Validation loss: 2.146245092153549

Epoch: 5| Step: 5
Training loss: 1.8336741924285889
Validation loss: 2.176739126443863

Epoch: 5| Step: 6
Training loss: 1.9987987279891968
Validation loss: 2.17685075600942

Epoch: 5| Step: 7
Training loss: 1.863790512084961
Validation loss: 2.1605969170729318

Epoch: 5| Step: 8
Training loss: 3.193260431289673
Validation loss: 2.161499192317327

Epoch: 5| Step: 9
Training loss: 2.25691294670105
Validation loss: 2.1366627713044486

Epoch: 5| Step: 10
Training loss: 1.6068639755249023
Validation loss: 2.1157172371943793

Epoch: 5| Step: 11
Training loss: 1.0888588428497314
Validation loss: 2.108124256134033

Epoch: 161| Step: 0
Training loss: 2.6266050338745117
Validation loss: 2.074204385280609

Epoch: 5| Step: 1
Training loss: 2.1013500690460205
Validation loss: 2.061599170168241

Epoch: 5| Step: 2
Training loss: 1.9607746601104736
Validation loss: 2.0536717971165976

Epoch: 5| Step: 3
Training loss: 2.347808837890625
Validation loss: 2.061276669303576

Epoch: 5| Step: 4
Training loss: 2.5633511543273926
Validation loss: 2.0732624232769012

Epoch: 5| Step: 5
Training loss: 1.7493536472320557
Validation loss: 2.0795802672704062

Epoch: 5| Step: 6
Training loss: 2.144627332687378
Validation loss: 2.075580671429634

Epoch: 5| Step: 7
Training loss: 2.2330355644226074
Validation loss: 2.0808865129947662

Epoch: 5| Step: 8
Training loss: 2.2911288738250732
Validation loss: 2.083913207054138

Epoch: 5| Step: 9
Training loss: 2.017786741256714
Validation loss: 2.083703046043714

Epoch: 5| Step: 10
Training loss: 1.8504838943481445
Validation loss: 2.078224018216133

Epoch: 5| Step: 11
Training loss: 1.3140231370925903
Validation loss: 2.0711254278818765

Epoch: 162| Step: 0
Training loss: 2.1866583824157715
Validation loss: 2.060593197743098

Epoch: 5| Step: 1
Training loss: 2.238492250442505
Validation loss: 2.0494933128356934

Epoch: 5| Step: 2
Training loss: 2.457477569580078
Validation loss: 2.032966380318006

Epoch: 5| Step: 3
Training loss: 2.346015453338623
Validation loss: 2.0287188291549683

Epoch: 5| Step: 4
Training loss: 2.0717592239379883
Validation loss: 2.0181273768345513

Epoch: 5| Step: 5
Training loss: 2.330186367034912
Validation loss: 2.0062718838453293

Epoch: 5| Step: 6
Training loss: 1.965074896812439
Validation loss: 2.014687344431877

Epoch: 5| Step: 7
Training loss: 1.9945323467254639
Validation loss: 2.014831985036532

Epoch: 5| Step: 8
Training loss: 1.9523319005966187
Validation loss: 2.0168703148762384

Epoch: 5| Step: 9
Training loss: 2.0472893714904785
Validation loss: 2.0125196079413095

Epoch: 5| Step: 10
Training loss: 2.130157947540283
Validation loss: 2.0340731789668403

Epoch: 5| Step: 11
Training loss: 1.6257238388061523
Validation loss: 2.038374831279119

Epoch: 163| Step: 0
Training loss: 2.6709094047546387
Validation loss: 2.0485228846470513

Epoch: 5| Step: 1
Training loss: 2.0681021213531494
Validation loss: 2.0587774217128754

Epoch: 5| Step: 2
Training loss: 2.0924017429351807
Validation loss: 2.0687058667341867

Epoch: 5| Step: 3
Training loss: 2.4904913902282715
Validation loss: 2.0578174591064453

Epoch: 5| Step: 4
Training loss: 2.141557216644287
Validation loss: 2.065480267008146

Epoch: 5| Step: 5
Training loss: 1.7697391510009766
Validation loss: 2.0705846895774207

Epoch: 5| Step: 6
Training loss: 1.7157166004180908
Validation loss: 2.076963876684507

Epoch: 5| Step: 7
Training loss: 2.0077357292175293
Validation loss: 2.0848991672197976

Epoch: 5| Step: 8
Training loss: 1.9646943807601929
Validation loss: 2.097612460454305

Epoch: 5| Step: 9
Training loss: 1.9018404483795166
Validation loss: 2.098939781387647

Epoch: 5| Step: 10
Training loss: 1.8097560405731201
Validation loss: 2.1097697665294013

Epoch: 5| Step: 11
Training loss: 1.9976645708084106
Validation loss: 2.1185768942038217

Epoch: 164| Step: 0
Training loss: 1.7403770685195923
Validation loss: 2.139770324031512

Epoch: 5| Step: 1
Training loss: 1.882211685180664
Validation loss: 2.1251792261997857

Epoch: 5| Step: 2
Training loss: 2.00349760055542
Validation loss: 2.1195107797781625

Epoch: 5| Step: 3
Training loss: 2.6763968467712402
Validation loss: 2.1191301196813583

Epoch: 5| Step: 4
Training loss: 1.5143706798553467
Validation loss: 2.116874357064565

Epoch: 5| Step: 5
Training loss: 2.103419065475464
Validation loss: 2.110042234261831

Epoch: 5| Step: 6
Training loss: 2.1112236976623535
Validation loss: 2.1107444564501443

Epoch: 5| Step: 7
Training loss: 2.032636880874634
Validation loss: 2.0999076465765634

Epoch: 5| Step: 8
Training loss: 2.171912431716919
Validation loss: 2.1053125659624734

Epoch: 5| Step: 9
Training loss: 2.003926992416382
Validation loss: 2.088362996776899

Epoch: 5| Step: 10
Training loss: 2.071244478225708
Validation loss: 2.0839506685733795

Epoch: 5| Step: 11
Training loss: 1.5985689163208008
Validation loss: 2.0904474556446075

Epoch: 165| Step: 0
Training loss: 1.5128015279769897
Validation loss: 2.0900950133800507

Epoch: 5| Step: 1
Training loss: 1.2696802616119385
Validation loss: 2.0859468082586923

Epoch: 5| Step: 2
Training loss: 1.910536527633667
Validation loss: 2.074687292178472

Epoch: 5| Step: 3
Training loss: 2.1758148670196533
Validation loss: 2.085814615090688

Epoch: 5| Step: 4
Training loss: 2.2366464138031006
Validation loss: 2.0823100159565606

Epoch: 5| Step: 5
Training loss: 2.6986453533172607
Validation loss: 2.0764346768458686

Epoch: 5| Step: 6
Training loss: 1.839917778968811
Validation loss: 2.0745911598205566

Epoch: 5| Step: 7
Training loss: 1.9036086797714233
Validation loss: 2.0881128907203674

Epoch: 5| Step: 8
Training loss: 2.230536699295044
Validation loss: 2.082032466928164

Epoch: 5| Step: 9
Training loss: 2.153963088989258
Validation loss: 2.081772491335869

Epoch: 5| Step: 10
Training loss: 2.059431791305542
Validation loss: 2.096644014120102

Epoch: 5| Step: 11
Training loss: 2.211632251739502
Validation loss: 2.0918469627698264

Epoch: 166| Step: 0
Training loss: 1.9611852169036865
Validation loss: 2.095457375049591

Epoch: 5| Step: 1
Training loss: 1.96343195438385
Validation loss: 2.103580658634504

Epoch: 5| Step: 2
Training loss: 1.3418972492218018
Validation loss: 2.1119096924861274

Epoch: 5| Step: 3
Training loss: 1.853155493736267
Validation loss: 2.104008287191391

Epoch: 5| Step: 4
Training loss: 2.016953945159912
Validation loss: 2.109016219774882

Epoch: 5| Step: 5
Training loss: 1.838651418685913
Validation loss: 2.111704871058464

Epoch: 5| Step: 6
Training loss: 1.878938913345337
Validation loss: 2.102694804469744

Epoch: 5| Step: 7
Training loss: 1.8439563512802124
Validation loss: 2.102678949634234

Epoch: 5| Step: 8
Training loss: 2.1085782051086426
Validation loss: 2.1139383961757026

Epoch: 5| Step: 9
Training loss: 2.4371418952941895
Validation loss: 2.114769458770752

Epoch: 5| Step: 10
Training loss: 2.8229873180389404
Validation loss: 2.1463419049978256

Epoch: 5| Step: 11
Training loss: 1.426633358001709
Validation loss: 2.1283888667821884

Epoch: 167| Step: 0
Training loss: 1.8181135654449463
Validation loss: 2.127036194006602

Epoch: 5| Step: 1
Training loss: 2.3754849433898926
Validation loss: 2.14174647629261

Epoch: 5| Step: 2
Training loss: 1.7452945709228516
Validation loss: 2.133294547597567

Epoch: 5| Step: 3
Training loss: 2.412087917327881
Validation loss: 2.127074976762136

Epoch: 5| Step: 4
Training loss: 2.019603729248047
Validation loss: 2.1094683408737183

Epoch: 5| Step: 5
Training loss: 1.713287115097046
Validation loss: 2.1300247808297477

Epoch: 5| Step: 6
Training loss: 1.6471916437149048
Validation loss: 2.1194000939528146

Epoch: 5| Step: 7
Training loss: 2.1106154918670654
Validation loss: 2.0934285620848336

Epoch: 5| Step: 8
Training loss: 1.7395795583724976
Validation loss: 2.109059671560923

Epoch: 5| Step: 9
Training loss: 2.4811668395996094
Validation loss: 2.098230982820193

Epoch: 5| Step: 10
Training loss: 1.618705153465271
Validation loss: 2.0872466415166855

Epoch: 5| Step: 11
Training loss: 2.1867146492004395
Validation loss: 2.0728250046571097

Epoch: 168| Step: 0
Training loss: 1.959429383277893
Validation loss: 2.073721985022227

Epoch: 5| Step: 1
Training loss: 1.5515590906143188
Validation loss: 2.069798320531845

Epoch: 5| Step: 2
Training loss: 2.3506178855895996
Validation loss: 2.0699603855609894

Epoch: 5| Step: 3
Training loss: 2.294483184814453
Validation loss: 2.0714206248521805

Epoch: 5| Step: 4
Training loss: 1.7363088130950928
Validation loss: 2.072260449330012

Epoch: 5| Step: 5
Training loss: 2.814500331878662
Validation loss: 2.074307382106781

Epoch: 5| Step: 6
Training loss: 2.1556503772735596
Validation loss: 2.0638390431801477

Epoch: 5| Step: 7
Training loss: 1.398271918296814
Validation loss: 2.0858565072218576

Epoch: 5| Step: 8
Training loss: 2.192159652709961
Validation loss: 2.09005568921566

Epoch: 5| Step: 9
Training loss: 1.893497109413147
Validation loss: 2.0937750140825906

Epoch: 5| Step: 10
Training loss: 1.5245506763458252
Validation loss: 2.1143759985764823

Epoch: 5| Step: 11
Training loss: 2.114725351333618
Validation loss: 2.104361886779467

Epoch: 169| Step: 0
Training loss: 2.3415749073028564
Validation loss: 2.113298619786898

Epoch: 5| Step: 1
Training loss: 2.077517509460449
Validation loss: 2.1200697819391885

Epoch: 5| Step: 2
Training loss: 1.8399131298065186
Validation loss: 2.108212267359098

Epoch: 5| Step: 3
Training loss: 1.9679901599884033
Validation loss: 2.1131243904431662

Epoch: 5| Step: 4
Training loss: 1.8051074743270874
Validation loss: 2.1092038502295813

Epoch: 5| Step: 5
Training loss: 1.8283443450927734
Validation loss: 2.099232628941536

Epoch: 5| Step: 6
Training loss: 1.8848434686660767
Validation loss: 2.099032541116079

Epoch: 5| Step: 7
Training loss: 2.1095023155212402
Validation loss: 2.0961947639783225

Epoch: 5| Step: 8
Training loss: 2.3652939796447754
Validation loss: 2.0823108901580176

Epoch: 5| Step: 9
Training loss: 1.5832583904266357
Validation loss: 2.100858137011528

Epoch: 5| Step: 10
Training loss: 2.094008207321167
Validation loss: 2.0868996729453406

Epoch: 5| Step: 11
Training loss: 1.4244450330734253
Validation loss: 2.0932344992955527

Epoch: 170| Step: 0
Training loss: 1.3952162265777588
Validation loss: 2.075074036916097

Epoch: 5| Step: 1
Training loss: 1.7329952716827393
Validation loss: 2.071731905142466

Epoch: 5| Step: 2
Training loss: 2.01971435546875
Validation loss: 2.0669544637203217

Epoch: 5| Step: 3
Training loss: 1.8891994953155518
Validation loss: 2.0667733450730643

Epoch: 5| Step: 4
Training loss: 2.1764702796936035
Validation loss: 2.0649280150731406

Epoch: 5| Step: 5
Training loss: 2.101917266845703
Validation loss: 2.0668719013532004

Epoch: 5| Step: 6
Training loss: 1.8121376037597656
Validation loss: 2.0926106373469033

Epoch: 5| Step: 7
Training loss: 2.1537866592407227
Validation loss: 2.0858345180749893

Epoch: 5| Step: 8
Training loss: 2.5220630168914795
Validation loss: 2.0996087541182837

Epoch: 5| Step: 9
Training loss: 1.8714580535888672
Validation loss: 2.1207529505093894

Epoch: 5| Step: 10
Training loss: 1.969695806503296
Validation loss: 2.127774993578593

Epoch: 5| Step: 11
Training loss: 3.059548854827881
Validation loss: 2.1399183173974357

Epoch: 171| Step: 0
Training loss: 1.5718374252319336
Validation loss: 2.146614581346512

Epoch: 5| Step: 1
Training loss: 2.317044734954834
Validation loss: 2.137238328655561

Epoch: 5| Step: 2
Training loss: 2.2453396320343018
Validation loss: 2.1145470241705575

Epoch: 5| Step: 3
Training loss: 2.299387216567993
Validation loss: 2.117090165615082

Epoch: 5| Step: 4
Training loss: 2.293640613555908
Validation loss: 2.132466326157252

Epoch: 5| Step: 5
Training loss: 1.9560320377349854
Validation loss: 2.1333540777365365

Epoch: 5| Step: 6
Training loss: 2.492161273956299
Validation loss: 2.1398363461097083

Epoch: 5| Step: 7
Training loss: 1.6328128576278687
Validation loss: 2.1196288019418716

Epoch: 5| Step: 8
Training loss: 1.6294351816177368
Validation loss: 2.0933133562405906

Epoch: 5| Step: 9
Training loss: 1.991697072982788
Validation loss: 2.1078815509875617

Epoch: 5| Step: 10
Training loss: 1.5425983667373657
Validation loss: 2.11132221420606

Epoch: 5| Step: 11
Training loss: 1.1234560012817383
Validation loss: 2.1309382220109305

Epoch: 172| Step: 0
Training loss: 2.147886276245117
Validation loss: 2.115354518095652

Epoch: 5| Step: 1
Training loss: 2.0534873008728027
Validation loss: 2.1292535811662674

Epoch: 5| Step: 2
Training loss: 0.9339404106140137
Validation loss: 2.132674217224121

Epoch: 5| Step: 3
Training loss: 1.696071982383728
Validation loss: 2.141919066508611

Epoch: 5| Step: 4
Training loss: 1.8908920288085938
Validation loss: 2.1446362932523093

Epoch: 5| Step: 5
Training loss: 2.414782762527466
Validation loss: 2.1499592860539756

Epoch: 5| Step: 6
Training loss: 1.9993219375610352
Validation loss: 2.1619160870711007

Epoch: 5| Step: 7
Training loss: 2.558875560760498
Validation loss: 2.1386048843463263

Epoch: 5| Step: 8
Training loss: 1.5658905506134033
Validation loss: 2.129122316837311

Epoch: 5| Step: 9
Training loss: 2.163438320159912
Validation loss: 2.1271421213944754

Epoch: 5| Step: 10
Training loss: 2.3247742652893066
Validation loss: 2.109789714217186

Epoch: 5| Step: 11
Training loss: 0.917055606842041
Validation loss: 2.1003858546415963

Epoch: 173| Step: 0
Training loss: 1.7553991079330444
Validation loss: 2.1013998985290527

Epoch: 5| Step: 1
Training loss: 1.9600343704223633
Validation loss: 2.086193839708964

Epoch: 5| Step: 2
Training loss: 1.6944043636322021
Validation loss: 2.0816167145967484

Epoch: 5| Step: 3
Training loss: 1.3938347101211548
Validation loss: 2.080976183215777

Epoch: 5| Step: 4
Training loss: 2.0925216674804688
Validation loss: 2.0923031667868295

Epoch: 5| Step: 5
Training loss: 1.863651990890503
Validation loss: 2.0841648479302726

Epoch: 5| Step: 6
Training loss: 1.9995750188827515
Validation loss: 2.0937573115030923

Epoch: 5| Step: 7
Training loss: 2.8170623779296875
Validation loss: 2.13757132490476

Epoch: 5| Step: 8
Training loss: 1.5726096630096436
Validation loss: 2.1457544962565103

Epoch: 5| Step: 9
Training loss: 2.390584945678711
Validation loss: 2.1530283242464066

Epoch: 5| Step: 10
Training loss: 2.0490341186523438
Validation loss: 2.1623443216085434

Epoch: 5| Step: 11
Training loss: 3.1155786514282227
Validation loss: 2.17208697895209

Epoch: 174| Step: 0
Training loss: 2.6753063201904297
Validation loss: 2.165688226620356

Epoch: 5| Step: 1
Training loss: 2.455935001373291
Validation loss: 2.14436182876428

Epoch: 5| Step: 2
Training loss: 1.9480552673339844
Validation loss: 2.144403338432312

Epoch: 5| Step: 3
Training loss: 2.0458271503448486
Validation loss: 2.1283022512992225

Epoch: 5| Step: 4
Training loss: 1.6485754251480103
Validation loss: 2.1099209636449814

Epoch: 5| Step: 5
Training loss: 1.6363773345947266
Validation loss: 2.109631508588791

Epoch: 5| Step: 6
Training loss: 1.4612358808517456
Validation loss: 2.1065187603235245

Epoch: 5| Step: 7
Training loss: 1.6303972005844116
Validation loss: 2.1090667645136514

Epoch: 5| Step: 8
Training loss: 2.54520845413208
Validation loss: 2.1136629482110343

Epoch: 5| Step: 9
Training loss: 1.9672260284423828
Validation loss: 2.1245172321796417

Epoch: 5| Step: 10
Training loss: 1.9190231561660767
Validation loss: 2.1233966002861657

Epoch: 5| Step: 11
Training loss: 0.9770300388336182
Validation loss: 2.112863058845202

Epoch: 175| Step: 0
Training loss: 1.9867902994155884
Validation loss: 2.1183354010184607

Epoch: 5| Step: 1
Training loss: 1.9131381511688232
Validation loss: 2.1244585663080215

Epoch: 5| Step: 2
Training loss: 2.1975979804992676
Validation loss: 2.1169230739275613

Epoch: 5| Step: 3
Training loss: 1.5022027492523193
Validation loss: 2.1261556645234427

Epoch: 5| Step: 4
Training loss: 1.7926973104476929
Validation loss: 2.123821347951889

Epoch: 5| Step: 5
Training loss: 1.8910305500030518
Validation loss: 2.1071180254220963

Epoch: 5| Step: 6
Training loss: 2.2866885662078857
Validation loss: 2.1193867127100625

Epoch: 5| Step: 7
Training loss: 1.8868221044540405
Validation loss: 2.1248841285705566

Epoch: 5| Step: 8
Training loss: 1.7286163568496704
Validation loss: 2.126615564028422

Epoch: 5| Step: 9
Training loss: 1.9095227718353271
Validation loss: 2.1237206558386483

Epoch: 5| Step: 10
Training loss: 2.437283992767334
Validation loss: 2.1263598004976907

Epoch: 5| Step: 11
Training loss: 1.6110368967056274
Validation loss: 2.1139749586582184

Epoch: 176| Step: 0
Training loss: 1.8817062377929688
Validation loss: 2.132987529039383

Epoch: 5| Step: 1
Training loss: 1.8038406372070312
Validation loss: 2.096276501814524

Epoch: 5| Step: 2
Training loss: 1.6486345529556274
Validation loss: 2.097798769672712

Epoch: 5| Step: 3
Training loss: 2.0759570598602295
Validation loss: 2.0834645430246987

Epoch: 5| Step: 4
Training loss: 2.3334782123565674
Validation loss: 2.0901848127444587

Epoch: 5| Step: 5
Training loss: 2.05216646194458
Validation loss: 2.074841156601906

Epoch: 5| Step: 6
Training loss: 1.6185901165008545
Validation loss: 2.0825708210468292

Epoch: 5| Step: 7
Training loss: 1.5977108478546143
Validation loss: 2.0962127447128296

Epoch: 5| Step: 8
Training loss: 2.5488393306732178
Validation loss: 2.0861044228076935

Epoch: 5| Step: 9
Training loss: 2.3063864707946777
Validation loss: 2.099385589361191

Epoch: 5| Step: 10
Training loss: 2.106464385986328
Validation loss: 2.115594446659088

Epoch: 5| Step: 11
Training loss: 1.5948656797409058
Validation loss: 2.127185339728991

Epoch: 177| Step: 0
Training loss: 2.4853460788726807
Validation loss: 2.1128644744555154

Epoch: 5| Step: 1
Training loss: 1.9652669429779053
Validation loss: 2.1072038114070892

Epoch: 5| Step: 2
Training loss: 1.6646229028701782
Validation loss: 2.1154912809530892

Epoch: 5| Step: 3
Training loss: 1.7445675134658813
Validation loss: 2.109597514073054

Epoch: 5| Step: 4
Training loss: 2.447503089904785
Validation loss: 2.1097401082515717

Epoch: 5| Step: 5
Training loss: 2.1549105644226074
Validation loss: 2.110508327682813

Epoch: 5| Step: 6
Training loss: 1.5388782024383545
Validation loss: 2.11621600886186

Epoch: 5| Step: 7
Training loss: 2.329848527908325
Validation loss: 2.1178082078695297

Epoch: 5| Step: 8
Training loss: 1.450592041015625
Validation loss: 2.1219595074653625

Epoch: 5| Step: 9
Training loss: 1.5903984308242798
Validation loss: 2.142545868953069

Epoch: 5| Step: 10
Training loss: 2.009077787399292
Validation loss: 2.1393703718980155

Epoch: 5| Step: 11
Training loss: 1.886266827583313
Validation loss: 2.138306885957718

Epoch: 178| Step: 0
Training loss: 1.7835623025894165
Validation loss: 2.1222210228443146

Epoch: 5| Step: 1
Training loss: 1.4476956129074097
Validation loss: 2.108904182910919

Epoch: 5| Step: 2
Training loss: 2.568647623062134
Validation loss: 2.1038974821567535

Epoch: 5| Step: 3
Training loss: 1.951088309288025
Validation loss: 2.095089867711067

Epoch: 5| Step: 4
Training loss: 1.9624032974243164
Validation loss: 2.097087020675341

Epoch: 5| Step: 5
Training loss: 2.1055846214294434
Validation loss: 2.0883159587780633

Epoch: 5| Step: 6
Training loss: 1.9992872476577759
Validation loss: 2.084398736556371

Epoch: 5| Step: 7
Training loss: 2.27846622467041
Validation loss: 2.0841620614131293

Epoch: 5| Step: 8
Training loss: 1.8380115032196045
Validation loss: 2.0899190505345664

Epoch: 5| Step: 9
Training loss: 2.2584266662597656
Validation loss: 2.088389645020167

Epoch: 5| Step: 10
Training loss: 2.041137218475342
Validation loss: 2.0909683605035148

Epoch: 5| Step: 11
Training loss: 1.3220062255859375
Validation loss: 2.098022003968557

Epoch: 179| Step: 0
Training loss: 1.6326624155044556
Validation loss: 2.0914532989263535

Epoch: 5| Step: 1
Training loss: 2.4739608764648438
Validation loss: 2.101434047023455

Epoch: 5| Step: 2
Training loss: 2.3281567096710205
Validation loss: 2.088656301299731

Epoch: 5| Step: 3
Training loss: 1.6872574090957642
Validation loss: 2.0942995150883994

Epoch: 5| Step: 4
Training loss: 2.371086597442627
Validation loss: 2.0862571597099304

Epoch: 5| Step: 5
Training loss: 1.7805570363998413
Validation loss: 2.0903849403063455

Epoch: 5| Step: 6
Training loss: 2.0845205783843994
Validation loss: 2.089153657356898

Epoch: 5| Step: 7
Training loss: 2.2781789302825928
Validation loss: 2.1203908125559487

Epoch: 5| Step: 8
Training loss: 1.375876784324646
Validation loss: 2.114191472530365

Epoch: 5| Step: 9
Training loss: 1.925052285194397
Validation loss: 2.1268366475900016

Epoch: 5| Step: 10
Training loss: 1.986914038658142
Validation loss: 2.1302219132582345

Epoch: 5| Step: 11
Training loss: 1.9275578260421753
Validation loss: 2.138454337914785

Epoch: 180| Step: 0
Training loss: 1.6964876651763916
Validation loss: 2.1443272531032562

Epoch: 5| Step: 1
Training loss: 2.0158133506774902
Validation loss: 2.1352456460396447

Epoch: 5| Step: 2
Training loss: 1.5912659168243408
Validation loss: 2.11896946032842

Epoch: 5| Step: 3
Training loss: 2.0364151000976562
Validation loss: 2.125319624940554

Epoch: 5| Step: 4
Training loss: 2.330343008041382
Validation loss: 2.138212482134501

Epoch: 5| Step: 5
Training loss: 1.6812702417373657
Validation loss: 2.144472603996595

Epoch: 5| Step: 6
Training loss: 1.97835373878479
Validation loss: 2.1308496048053107

Epoch: 5| Step: 7
Training loss: 2.2842109203338623
Validation loss: 2.118365928530693

Epoch: 5| Step: 8
Training loss: 2.1340861320495605
Validation loss: 2.120807866255442

Epoch: 5| Step: 9
Training loss: 1.8126884698867798
Validation loss: 2.107664848367373

Epoch: 5| Step: 10
Training loss: 1.801395058631897
Validation loss: 2.094761778910955

Epoch: 5| Step: 11
Training loss: 2.231843948364258
Validation loss: 2.0974520444869995

Epoch: 181| Step: 0
Training loss: 2.1929190158843994
Validation loss: 2.0985883325338364

Epoch: 5| Step: 1
Training loss: 1.8182426691055298
Validation loss: 2.096488277117411

Epoch: 5| Step: 2
Training loss: 1.5254865884780884
Validation loss: 2.098234166701635

Epoch: 5| Step: 3
Training loss: 1.5769541263580322
Validation loss: 2.111566444238027

Epoch: 5| Step: 4
Training loss: 1.8111568689346313
Validation loss: 2.1077316999435425

Epoch: 5| Step: 5
Training loss: 2.534543037414551
Validation loss: 2.1278886795043945

Epoch: 5| Step: 6
Training loss: 2.3527419567108154
Validation loss: 2.1470822443564734

Epoch: 5| Step: 7
Training loss: 1.9829223155975342
Validation loss: 2.170481855670611

Epoch: 5| Step: 8
Training loss: 1.6172319650650024
Validation loss: 2.172598749399185

Epoch: 5| Step: 9
Training loss: 1.9796552658081055
Validation loss: 2.1558292160431543

Epoch: 5| Step: 10
Training loss: 2.703566312789917
Validation loss: 2.179410085082054

Epoch: 5| Step: 11
Training loss: 1.5090349912643433
Validation loss: 2.1569745739301047

Epoch: 182| Step: 0
Training loss: 1.1872891187667847
Validation loss: 2.1590296030044556

Epoch: 5| Step: 1
Training loss: 1.8942210674285889
Validation loss: 2.1408243576685586

Epoch: 5| Step: 2
Training loss: 1.9703090190887451
Validation loss: 2.142405038078626

Epoch: 5| Step: 3
Training loss: 1.9786913394927979
Validation loss: 2.1728544930617013

Epoch: 5| Step: 4
Training loss: 2.1271955966949463
Validation loss: 2.126783157388369

Epoch: 5| Step: 5
Training loss: 2.5334792137145996
Validation loss: 2.114640245834986

Epoch: 5| Step: 6
Training loss: 1.600002646446228
Validation loss: 2.114871526757876

Epoch: 5| Step: 7
Training loss: 2.1465375423431396
Validation loss: 2.097340698043505

Epoch: 5| Step: 8
Training loss: 2.0133373737335205
Validation loss: 2.098393132289251

Epoch: 5| Step: 9
Training loss: 2.14436936378479
Validation loss: 2.093149557709694

Epoch: 5| Step: 10
Training loss: 2.10349702835083
Validation loss: 2.1028093844652176

Epoch: 5| Step: 11
Training loss: 1.669306993484497
Validation loss: 2.1059155464172363

Epoch: 183| Step: 0
Training loss: 1.6824356317520142
Validation loss: 2.1056981732447944

Epoch: 5| Step: 1
Training loss: 1.9131536483764648
Validation loss: 2.1051946878433228

Epoch: 5| Step: 2
Training loss: 1.783227562904358
Validation loss: 2.1245873868465424

Epoch: 5| Step: 3
Training loss: 1.3702561855316162
Validation loss: 2.1312162776788077

Epoch: 5| Step: 4
Training loss: 1.8219144344329834
Validation loss: 2.1344450960556665

Epoch: 5| Step: 5
Training loss: 2.101167917251587
Validation loss: 2.1437061727046967

Epoch: 5| Step: 6
Training loss: 1.5091601610183716
Validation loss: 2.1375847905874252

Epoch: 5| Step: 7
Training loss: 2.6362946033477783
Validation loss: 2.1245161443948746

Epoch: 5| Step: 8
Training loss: 2.495115041732788
Validation loss: 2.131617267926534

Epoch: 5| Step: 9
Training loss: 1.7512328624725342
Validation loss: 2.1251709113518396

Epoch: 5| Step: 10
Training loss: 2.448516368865967
Validation loss: 2.1284003059069314

Epoch: 5| Step: 11
Training loss: 1.6494845151901245
Validation loss: 2.1246864100297294

Epoch: 184| Step: 0
Training loss: 1.8828719854354858
Validation loss: 2.1297707756360373

Epoch: 5| Step: 1
Training loss: 1.9546432495117188
Validation loss: 2.107257907589277

Epoch: 5| Step: 2
Training loss: 2.5141444206237793
Validation loss: 2.102098931868871

Epoch: 5| Step: 3
Training loss: 1.7230288982391357
Validation loss: 2.098961502313614

Epoch: 5| Step: 4
Training loss: 1.5310089588165283
Validation loss: 2.1025183498859406

Epoch: 5| Step: 5
Training loss: 1.6717989444732666
Validation loss: 2.0995543201764426

Epoch: 5| Step: 6
Training loss: 2.005824565887451
Validation loss: 2.103336840867996

Epoch: 5| Step: 7
Training loss: 2.240016222000122
Validation loss: 2.1264673670132956

Epoch: 5| Step: 8
Training loss: 1.6982109546661377
Validation loss: 2.112936099370321

Epoch: 5| Step: 9
Training loss: 1.9052337408065796
Validation loss: 2.143649458885193

Epoch: 5| Step: 10
Training loss: 2.5369551181793213
Validation loss: 2.1515875508387885

Epoch: 5| Step: 11
Training loss: 1.997524619102478
Validation loss: 2.1448455452919006

Epoch: 185| Step: 0
Training loss: 2.257488250732422
Validation loss: 2.1845071216424308

Epoch: 5| Step: 1
Training loss: 1.9452279806137085
Validation loss: 2.1726139237483344

Epoch: 5| Step: 2
Training loss: 1.915808916091919
Validation loss: 2.1771602431933084

Epoch: 5| Step: 3
Training loss: 1.9630861282348633
Validation loss: 2.184104616443316

Epoch: 5| Step: 4
Training loss: 2.6651008129119873
Validation loss: 2.146048148473104

Epoch: 5| Step: 5
Training loss: 2.4107234477996826
Validation loss: 2.135183090964953

Epoch: 5| Step: 6
Training loss: 1.8030071258544922
Validation loss: 2.1242424696683884

Epoch: 5| Step: 7
Training loss: 1.445891261100769
Validation loss: 2.138829400142034

Epoch: 5| Step: 8
Training loss: 2.055771827697754
Validation loss: 2.1261169413725534

Epoch: 5| Step: 9
Training loss: 1.5433324575424194
Validation loss: 2.1163825939098992

Epoch: 5| Step: 10
Training loss: 1.7528263330459595
Validation loss: 2.1121388375759125

Epoch: 5| Step: 11
Training loss: 2.088117837905884
Validation loss: 2.1070200701554618

Epoch: 186| Step: 0
Training loss: 1.6536567211151123
Validation loss: 2.1131571531295776

Epoch: 5| Step: 1
Training loss: 2.0928988456726074
Validation loss: 2.1101451367139816

Epoch: 5| Step: 2
Training loss: 2.397982120513916
Validation loss: 2.101530616482099

Epoch: 5| Step: 3
Training loss: 1.7769403457641602
Validation loss: 2.1192585279544196

Epoch: 5| Step: 4
Training loss: 1.9322417974472046
Validation loss: 2.1107187966505685

Epoch: 5| Step: 5
Training loss: 1.9049110412597656
Validation loss: 2.113245189189911

Epoch: 5| Step: 6
Training loss: 1.7985280752182007
Validation loss: 2.1227508982022605

Epoch: 5| Step: 7
Training loss: 2.013983964920044
Validation loss: 2.1337662686904273

Epoch: 5| Step: 8
Training loss: 1.6882257461547852
Validation loss: 2.1197053591410318

Epoch: 5| Step: 9
Training loss: 2.0299880504608154
Validation loss: 2.146462341149648

Epoch: 5| Step: 10
Training loss: 2.034755229949951
Validation loss: 2.142629951238632

Epoch: 5| Step: 11
Training loss: 2.4304022789001465
Validation loss: 2.11073129872481

Epoch: 187| Step: 0
Training loss: 1.6038360595703125
Validation loss: 2.117866968115171

Epoch: 5| Step: 1
Training loss: 2.051117181777954
Validation loss: 2.124778946240743

Epoch: 5| Step: 2
Training loss: 2.2230942249298096
Validation loss: 2.115665098031362

Epoch: 5| Step: 3
Training loss: 1.5600497722625732
Validation loss: 2.116908719142278

Epoch: 5| Step: 4
Training loss: 2.3182902336120605
Validation loss: 2.1241403122742972

Epoch: 5| Step: 5
Training loss: 1.7215362787246704
Validation loss: 2.1444705426692963

Epoch: 5| Step: 6
Training loss: 1.6407077312469482
Validation loss: 2.1496044794718423

Epoch: 5| Step: 7
Training loss: 1.8704955577850342
Validation loss: 2.1406390915314355

Epoch: 5| Step: 8
Training loss: 1.849424123764038
Validation loss: 2.146628220876058

Epoch: 5| Step: 9
Training loss: 1.9618566036224365
Validation loss: 2.1793846487998962

Epoch: 5| Step: 10
Training loss: 2.157639265060425
Validation loss: 2.1634248048067093

Epoch: 5| Step: 11
Training loss: 4.238254070281982
Validation loss: 2.15784981350104

Epoch: 188| Step: 0
Training loss: 1.5149738788604736
Validation loss: 2.138158639272054

Epoch: 5| Step: 1
Training loss: 1.5240967273712158
Validation loss: 2.1450392256180444

Epoch: 5| Step: 2
Training loss: 1.777035117149353
Validation loss: 2.130954066912333

Epoch: 5| Step: 3
Training loss: 2.3100528717041016
Validation loss: 2.127639298637708

Epoch: 5| Step: 4
Training loss: 1.9190256595611572
Validation loss: 2.1216222693522773

Epoch: 5| Step: 5
Training loss: 2.230234384536743
Validation loss: 2.135823756456375

Epoch: 5| Step: 6
Training loss: 1.379581093788147
Validation loss: 2.121659278869629

Epoch: 5| Step: 7
Training loss: 2.3202457427978516
Validation loss: 2.132550368706385

Epoch: 5| Step: 8
Training loss: 1.8432941436767578
Validation loss: 2.14072622358799

Epoch: 5| Step: 9
Training loss: 2.543823480606079
Validation loss: 2.105385651191076

Epoch: 5| Step: 10
Training loss: 1.4556243419647217
Validation loss: 2.1214771370093026

Epoch: 5| Step: 11
Training loss: 2.650658130645752
Validation loss: 2.1372065941492715

Epoch: 189| Step: 0
Training loss: 1.8750282526016235
Validation loss: 2.122531980276108

Epoch: 5| Step: 1
Training loss: 1.9248549938201904
Validation loss: 2.1363810996214547

Epoch: 5| Step: 2
Training loss: 1.6004972457885742
Validation loss: 2.1448864489793777

Epoch: 5| Step: 3
Training loss: 2.3504228591918945
Validation loss: 2.1297544191281

Epoch: 5| Step: 4
Training loss: 2.233572006225586
Validation loss: 2.148279224832853

Epoch: 5| Step: 5
Training loss: 1.5162147283554077
Validation loss: 2.1427113314469657

Epoch: 5| Step: 6
Training loss: 1.5988706350326538
Validation loss: 2.1549933552742004

Epoch: 5| Step: 7
Training loss: 2.2887520790100098
Validation loss: 2.144571845730146

Epoch: 5| Step: 8
Training loss: 1.87714421749115
Validation loss: 2.168873886267344

Epoch: 5| Step: 9
Training loss: 1.5978299379348755
Validation loss: 2.1827951272328696

Epoch: 5| Step: 10
Training loss: 2.4023947715759277
Validation loss: 2.1799515088399253

Epoch: 5| Step: 11
Training loss: 1.7785866260528564
Validation loss: 2.1710182428359985

Epoch: 190| Step: 0
Training loss: 1.7849409580230713
Validation loss: 2.158258020877838

Epoch: 5| Step: 1
Training loss: 1.8563178777694702
Validation loss: 2.1470739295085273

Epoch: 5| Step: 2
Training loss: 1.4419021606445312
Validation loss: 2.146591454744339

Epoch: 5| Step: 3
Training loss: 1.7531776428222656
Validation loss: 2.1289690484603248

Epoch: 5| Step: 4
Training loss: 1.3686786890029907
Validation loss: 2.1116341402133307

Epoch: 5| Step: 5
Training loss: 2.7254574298858643
Validation loss: 2.1120210935672126

Epoch: 5| Step: 6
Training loss: 1.8841984272003174
Validation loss: 2.1264482190211615

Epoch: 5| Step: 7
Training loss: 2.5033187866210938
Validation loss: 2.133530189593633

Epoch: 5| Step: 8
Training loss: 1.8478214740753174
Validation loss: 2.121732925375303

Epoch: 5| Step: 9
Training loss: 1.937021255493164
Validation loss: 2.1275233179330826

Epoch: 5| Step: 10
Training loss: 2.0107271671295166
Validation loss: 2.135180393854777

Epoch: 5| Step: 11
Training loss: 2.1779472827911377
Validation loss: 2.1491587658723197

Epoch: 191| Step: 0
Training loss: 1.7279722690582275
Validation loss: 2.1407322784264884

Epoch: 5| Step: 1
Training loss: 2.2157981395721436
Validation loss: 2.1497984379529953

Epoch: 5| Step: 2
Training loss: 2.3073947429656982
Validation loss: 2.139609823624293

Epoch: 5| Step: 3
Training loss: 2.3495631217956543
Validation loss: 2.176559860507647

Epoch: 5| Step: 4
Training loss: 1.7165729999542236
Validation loss: 2.186635802189509

Epoch: 5| Step: 5
Training loss: 1.725829839706421
Validation loss: 2.1689609636863074

Epoch: 5| Step: 6
Training loss: 2.138064384460449
Validation loss: 2.1798322399457297

Epoch: 5| Step: 7
Training loss: 1.747995376586914
Validation loss: 2.161446377635002

Epoch: 5| Step: 8
Training loss: 1.4352774620056152
Validation loss: 2.1486810445785522

Epoch: 5| Step: 9
Training loss: 1.9863742589950562
Validation loss: 2.1364478270212808

Epoch: 5| Step: 10
Training loss: 1.5934553146362305
Validation loss: 2.1289271861314774

Epoch: 5| Step: 11
Training loss: 2.6219260692596436
Validation loss: 2.1412029961744943

Epoch: 192| Step: 0
Training loss: 1.585767149925232
Validation loss: 2.1202673067649207

Epoch: 5| Step: 1
Training loss: 1.6654434204101562
Validation loss: 2.134769002596537

Epoch: 5| Step: 2
Training loss: 2.3136916160583496
Validation loss: 2.124736502766609

Epoch: 5| Step: 3
Training loss: 2.514681339263916
Validation loss: 2.1131039013465247

Epoch: 5| Step: 4
Training loss: 1.7141504287719727
Validation loss: 2.1407549331585565

Epoch: 5| Step: 5
Training loss: 2.1947569847106934
Validation loss: 2.153462211290995

Epoch: 5| Step: 6
Training loss: 2.2243857383728027
Validation loss: 2.1630108008782067

Epoch: 5| Step: 7
Training loss: 2.0377964973449707
Validation loss: 2.1877704759438834

Epoch: 5| Step: 8
Training loss: 1.4099621772766113
Validation loss: 2.1948695480823517

Epoch: 5| Step: 9
Training loss: 1.5997741222381592
Validation loss: 2.1769960820674896

Epoch: 5| Step: 10
Training loss: 1.572930097579956
Validation loss: 2.1827762027581534

Epoch: 5| Step: 11
Training loss: 2.4736881256103516
Validation loss: 2.1654294431209564

Epoch: 193| Step: 0
Training loss: 1.6777446269989014
Validation loss: 2.1383654276529946

Epoch: 5| Step: 1
Training loss: 2.0701534748077393
Validation loss: 2.1430261731147766

Epoch: 5| Step: 2
Training loss: 1.7231247425079346
Validation loss: 2.11909057199955

Epoch: 5| Step: 3
Training loss: 1.8706775903701782
Validation loss: 2.106662223736445

Epoch: 5| Step: 4
Training loss: 2.310966968536377
Validation loss: 2.111018886168798

Epoch: 5| Step: 5
Training loss: 1.8019886016845703
Validation loss: 2.1244026124477386

Epoch: 5| Step: 6
Training loss: 2.0114192962646484
Validation loss: 2.112164164582888

Epoch: 5| Step: 7
Training loss: 2.147446393966675
Validation loss: 2.111385295788447

Epoch: 5| Step: 8
Training loss: 2.054313898086548
Validation loss: 2.1029954304297767

Epoch: 5| Step: 9
Training loss: 1.7120956182479858
Validation loss: 2.1060858269532523

Epoch: 5| Step: 10
Training loss: 1.6311542987823486
Validation loss: 2.1344583332538605

Epoch: 5| Step: 11
Training loss: 2.6854069232940674
Validation loss: 2.1362913101911545

Epoch: 194| Step: 0
Training loss: 2.4488909244537354
Validation loss: 2.146606077750524

Epoch: 5| Step: 1
Training loss: 1.5646378993988037
Validation loss: 2.173977106809616

Epoch: 5| Step: 2
Training loss: 1.9820261001586914
Validation loss: 2.185273841023445

Epoch: 5| Step: 3
Training loss: 1.742164969444275
Validation loss: 2.187487711509069

Epoch: 5| Step: 4
Training loss: 1.3742036819458008
Validation loss: 2.188671797513962

Epoch: 5| Step: 5
Training loss: 1.773685097694397
Validation loss: 2.1500695596138635

Epoch: 5| Step: 6
Training loss: 1.97978937625885
Validation loss: 2.1531330943107605

Epoch: 5| Step: 7
Training loss: 2.170341968536377
Validation loss: 2.1268223275740943

Epoch: 5| Step: 8
Training loss: 1.8781030178070068
Validation loss: 2.123242119948069

Epoch: 5| Step: 9
Training loss: 2.110452651977539
Validation loss: 2.1025575349728265

Epoch: 5| Step: 10
Training loss: 1.969430923461914
Validation loss: 2.10377370317777

Epoch: 5| Step: 11
Training loss: 2.3491036891937256
Validation loss: 2.1004220247268677

Epoch: 195| Step: 0
Training loss: 2.0525360107421875
Validation loss: 2.085054188966751

Epoch: 5| Step: 1
Training loss: 2.577366828918457
Validation loss: 2.0871879110733667

Epoch: 5| Step: 2
Training loss: 1.334141731262207
Validation loss: 2.089374785621961

Epoch: 5| Step: 3
Training loss: 1.9652316570281982
Validation loss: 2.103830948472023

Epoch: 5| Step: 4
Training loss: 1.6409000158309937
Validation loss: 2.0992626349131265

Epoch: 5| Step: 5
Training loss: 1.9566596746444702
Validation loss: 2.113068073987961

Epoch: 5| Step: 6
Training loss: 1.8966522216796875
Validation loss: 2.118189518650373

Epoch: 5| Step: 7
Training loss: 2.1770730018615723
Validation loss: 2.141219069560369

Epoch: 5| Step: 8
Training loss: 2.10163950920105
Validation loss: 2.1701964884996414

Epoch: 5| Step: 9
Training loss: 2.1029279232025146
Validation loss: 2.152454043428103

Epoch: 5| Step: 10
Training loss: 1.6792957782745361
Validation loss: 2.1579999029636383

Epoch: 5| Step: 11
Training loss: 1.4621330499649048
Validation loss: 2.1763589680194855

Epoch: 196| Step: 0
Training loss: 1.9959590435028076
Validation loss: 2.168487826983134

Epoch: 5| Step: 1
Training loss: 2.0481181144714355
Validation loss: 2.154023910562197

Epoch: 5| Step: 2
Training loss: 1.684701919555664
Validation loss: 2.1638741195201874

Epoch: 5| Step: 3
Training loss: 1.745086669921875
Validation loss: 2.1448928912480674

Epoch: 5| Step: 4
Training loss: 1.8592097759246826
Validation loss: 2.1463342706362405

Epoch: 5| Step: 5
Training loss: 1.8238967657089233
Validation loss: 2.1420990228652954

Epoch: 5| Step: 6
Training loss: 2.4542489051818848
Validation loss: 2.140293593207995

Epoch: 5| Step: 7
Training loss: 1.4961036443710327
Validation loss: 2.1170718918244043

Epoch: 5| Step: 8
Training loss: 1.9191722869873047
Validation loss: 2.1362908333539963

Epoch: 5| Step: 9
Training loss: 2.092552661895752
Validation loss: 2.1200351814428964

Epoch: 5| Step: 10
Training loss: 2.035799741744995
Validation loss: 2.135746975739797

Epoch: 5| Step: 11
Training loss: 1.5645742416381836
Validation loss: 2.1323970208565393

Epoch: 197| Step: 0
Training loss: 1.9268300533294678
Validation loss: 2.136944537361463

Epoch: 5| Step: 1
Training loss: 1.9432475566864014
Validation loss: 2.163497949639956

Epoch: 5| Step: 2
Training loss: 1.9757750034332275
Validation loss: 2.1679167598485947

Epoch: 5| Step: 3
Training loss: 1.783879041671753
Validation loss: 2.1684387922286987

Epoch: 5| Step: 4
Training loss: 2.0179812908172607
Validation loss: 2.1801991164684296

Epoch: 5| Step: 5
Training loss: 2.1780447959899902
Validation loss: 2.1967947433392205

Epoch: 5| Step: 6
Training loss: 1.774275541305542
Validation loss: 2.2074902405341468

Epoch: 5| Step: 7
Training loss: 1.3300541639328003
Validation loss: 2.199513534704844

Epoch: 5| Step: 8
Training loss: 2.0525012016296387
Validation loss: 2.1887010435263314

Epoch: 5| Step: 9
Training loss: 2.0557947158813477
Validation loss: 2.221022138992945

Epoch: 5| Step: 10
Training loss: 2.202263832092285
Validation loss: 2.1744759480158486

Epoch: 5| Step: 11
Training loss: 0.8877548575401306
Validation loss: 2.1817133873701096

Epoch: 198| Step: 0
Training loss: 1.9584804773330688
Validation loss: 2.171114126841227

Epoch: 5| Step: 1
Training loss: 1.545593500137329
Validation loss: 2.1404150277376175

Epoch: 5| Step: 2
Training loss: 2.252222776412964
Validation loss: 2.151180629928907

Epoch: 5| Step: 3
Training loss: 1.743310570716858
Validation loss: 2.153302624821663

Epoch: 5| Step: 4
Training loss: 1.9046828746795654
Validation loss: 2.1513764460881553

Epoch: 5| Step: 5
Training loss: 1.9751980304718018
Validation loss: 2.1535450369119644

Epoch: 5| Step: 6
Training loss: 2.056530475616455
Validation loss: 2.1464149355888367

Epoch: 5| Step: 7
Training loss: 1.647437334060669
Validation loss: 2.1583245346943536

Epoch: 5| Step: 8
Training loss: 2.078948736190796
Validation loss: 2.181269039710363

Epoch: 5| Step: 9
Training loss: 1.6586666107177734
Validation loss: 2.1943952242533364

Epoch: 5| Step: 10
Training loss: 2.0183472633361816
Validation loss: 2.2197535087664924

Epoch: 5| Step: 11
Training loss: 2.1765856742858887
Validation loss: 2.211727052927017

Epoch: 199| Step: 0
Training loss: 1.6142345666885376
Validation loss: 2.2276894251505532

Epoch: 5| Step: 1
Training loss: 1.6636136770248413
Validation loss: 2.192314008871714

Epoch: 5| Step: 2
Training loss: 1.9818012714385986
Validation loss: 2.195005496342977

Epoch: 5| Step: 3
Training loss: 1.4418827295303345
Validation loss: 2.210692966977755

Epoch: 5| Step: 4
Training loss: 2.1293222904205322
Validation loss: 2.1907672186692557

Epoch: 5| Step: 5
Training loss: 2.418205738067627
Validation loss: 2.1731447875499725

Epoch: 5| Step: 6
Training loss: 1.7913386821746826
Validation loss: 2.1489044427871704

Epoch: 5| Step: 7
Training loss: 2.0757129192352295
Validation loss: 2.153988649447759

Epoch: 5| Step: 8
Training loss: 1.8446743488311768
Validation loss: 2.129388059178988

Epoch: 5| Step: 9
Training loss: 2.2054123878479004
Validation loss: 2.1313448746999106

Epoch: 5| Step: 10
Training loss: 2.0338354110717773
Validation loss: 2.1591593275467553

Epoch: 5| Step: 11
Training loss: 1.416377305984497
Validation loss: 2.169035628437996

Epoch: 200| Step: 0
Training loss: 1.6109073162078857
Validation loss: 2.180823157231013

Epoch: 5| Step: 1
Training loss: 1.3279684782028198
Validation loss: 2.218273694316546

Epoch: 5| Step: 2
Training loss: 2.377007246017456
Validation loss: 2.232898091276487

Epoch: 5| Step: 3
Training loss: 1.9938087463378906
Validation loss: 2.2408304711182914

Epoch: 5| Step: 4
Training loss: 1.7136818170547485
Validation loss: 2.220697750647863

Epoch: 5| Step: 5
Training loss: 2.0532891750335693
Validation loss: 2.218909124533335

Epoch: 5| Step: 6
Training loss: 2.0441524982452393
Validation loss: 2.2185728549957275

Epoch: 5| Step: 7
Training loss: 2.3315677642822266
Validation loss: 2.1931760013103485

Epoch: 5| Step: 8
Training loss: 1.7890713214874268
Validation loss: 2.178587645292282

Epoch: 5| Step: 9
Training loss: 2.244873285293579
Validation loss: 2.16183532277743

Epoch: 5| Step: 10
Training loss: 1.9821516275405884
Validation loss: 2.173273980617523

Epoch: 5| Step: 11
Training loss: 0.9422919750213623
Validation loss: 2.1672548751036325

Epoch: 201| Step: 0
Training loss: 2.502265453338623
Validation loss: 2.191550314426422

Epoch: 5| Step: 1
Training loss: 1.629977822303772
Validation loss: 2.1827161411444345

Epoch: 5| Step: 2
Training loss: 1.7003660202026367
Validation loss: 2.1934804916381836

Epoch: 5| Step: 3
Training loss: 1.8018543720245361
Validation loss: 2.175267497698466

Epoch: 5| Step: 4
Training loss: 1.5346400737762451
Validation loss: 2.1491489509741464

Epoch: 5| Step: 5
Training loss: 2.174694299697876
Validation loss: 2.143837799628576

Epoch: 5| Step: 6
Training loss: 1.7939860820770264
Validation loss: 2.119878888130188

Epoch: 5| Step: 7
Training loss: 2.126183032989502
Validation loss: 2.115588610370954

Epoch: 5| Step: 8
Training loss: 2.0616540908813477
Validation loss: 2.1210510631402335

Epoch: 5| Step: 9
Training loss: 2.24483585357666
Validation loss: 2.1198272903760276

Epoch: 5| Step: 10
Training loss: 1.8843309879302979
Validation loss: 2.122413451472918

Epoch: 5| Step: 11
Training loss: 0.6699889898300171
Validation loss: 2.1233596801757812

Epoch: 202| Step: 0
Training loss: 2.138998508453369
Validation loss: 2.108957419792811

Epoch: 5| Step: 1
Training loss: 1.9331591129302979
Validation loss: 2.132244805494944

Epoch: 5| Step: 2
Training loss: 2.248526096343994
Validation loss: 2.1213496327400208

Epoch: 5| Step: 3
Training loss: 1.7353785037994385
Validation loss: 2.137041504184405

Epoch: 5| Step: 4
Training loss: 1.9122467041015625
Validation loss: 2.1297101974487305

Epoch: 5| Step: 5
Training loss: 1.5589464902877808
Validation loss: 2.14206999540329

Epoch: 5| Step: 6
Training loss: 1.6789051294326782
Validation loss: 2.1378299047549567

Epoch: 5| Step: 7
Training loss: 2.073009967803955
Validation loss: 2.146917333205541

Epoch: 5| Step: 8
Training loss: 2.0619559288024902
Validation loss: 2.10780002673467

Epoch: 5| Step: 9
Training loss: 2.2062973976135254
Validation loss: 2.129893953601519

Epoch: 5| Step: 10
Training loss: 1.5980048179626465
Validation loss: 2.134518871704737

Epoch: 5| Step: 11
Training loss: 1.266364336013794
Validation loss: 2.1260484009981155

Epoch: 203| Step: 0
Training loss: 2.0054409503936768
Validation loss: 2.1556266943613687

Epoch: 5| Step: 1
Training loss: 1.4385201930999756
Validation loss: 2.1841352035601935

Epoch: 5| Step: 2
Training loss: 1.5821095705032349
Validation loss: 2.199047247568766

Epoch: 5| Step: 3
Training loss: 2.1776881217956543
Validation loss: 2.1820065478483834

Epoch: 5| Step: 4
Training loss: 2.237351179122925
Validation loss: 2.18372709552447

Epoch: 5| Step: 5
Training loss: 1.9389450550079346
Validation loss: 2.155812591314316

Epoch: 5| Step: 6
Training loss: 1.9014898538589478
Validation loss: 2.1598996222019196

Epoch: 5| Step: 7
Training loss: 2.4212753772735596
Validation loss: 2.1123396505912146

Epoch: 5| Step: 8
Training loss: 2.013509750366211
Validation loss: 2.102470487356186

Epoch: 5| Step: 9
Training loss: 2.1647090911865234
Validation loss: 2.1059600263834

Epoch: 5| Step: 10
Training loss: 1.8316471576690674
Validation loss: 2.0906776785850525

Epoch: 5| Step: 11
Training loss: 2.4778356552124023
Validation loss: 2.0806663433710733

Epoch: 204| Step: 0
Training loss: 2.0574653148651123
Validation loss: 2.085498576362928

Epoch: 5| Step: 1
Training loss: 1.5957130193710327
Validation loss: 2.089391311009725

Epoch: 5| Step: 2
Training loss: 2.0329749584198
Validation loss: 2.081474165121714

Epoch: 5| Step: 3
Training loss: 2.3227410316467285
Validation loss: 2.088676462570826

Epoch: 5| Step: 4
Training loss: 1.584845781326294
Validation loss: 2.1059696972370148

Epoch: 5| Step: 5
Training loss: 1.84592604637146
Validation loss: 2.1177616914113364

Epoch: 5| Step: 6
Training loss: 1.7340059280395508
Validation loss: 2.146133611599604

Epoch: 5| Step: 7
Training loss: 1.948590874671936
Validation loss: 2.1358348429203033

Epoch: 5| Step: 8
Training loss: 2.217324733734131
Validation loss: 2.154794613520304

Epoch: 5| Step: 9
Training loss: 1.5996553897857666
Validation loss: 2.1748435149590173

Epoch: 5| Step: 10
Training loss: 2.3313841819763184
Validation loss: 2.1776130696137748

Epoch: 5| Step: 11
Training loss: 1.9655627012252808
Validation loss: 2.1977780212958655

Epoch: 205| Step: 0
Training loss: 2.0450940132141113
Validation loss: 2.195009176929792

Epoch: 5| Step: 1
Training loss: 1.8139177560806274
Validation loss: 2.220088710387548

Epoch: 5| Step: 2
Training loss: 2.1329522132873535
Validation loss: 2.1975188851356506

Epoch: 5| Step: 3
Training loss: 1.817868947982788
Validation loss: 2.193975508213043

Epoch: 5| Step: 4
Training loss: 2.053741931915283
Validation loss: 2.183660795291265

Epoch: 5| Step: 5
Training loss: 1.6861385107040405
Validation loss: 2.182412400841713

Epoch: 5| Step: 6
Training loss: 1.9147440195083618
Validation loss: 2.1687214573224387

Epoch: 5| Step: 7
Training loss: 2.231884479522705
Validation loss: 2.1415613989035287

Epoch: 5| Step: 8
Training loss: 2.181110382080078
Validation loss: 2.1410937954982123

Epoch: 5| Step: 9
Training loss: 1.901124358177185
Validation loss: 2.1493173638979592

Epoch: 5| Step: 10
Training loss: 1.3177083730697632
Validation loss: 2.1661136696736016

Epoch: 5| Step: 11
Training loss: 2.34375
Validation loss: 2.163094441095988

Epoch: 206| Step: 0
Training loss: 1.3721206188201904
Validation loss: 2.155651956796646

Epoch: 5| Step: 1
Training loss: 1.7999088764190674
Validation loss: 2.1609739810228348

Epoch: 5| Step: 2
Training loss: 1.9680169820785522
Validation loss: 2.180583193898201

Epoch: 5| Step: 3
Training loss: 1.6899265050888062
Validation loss: 2.182956119378408

Epoch: 5| Step: 4
Training loss: 1.9939569234848022
Validation loss: 2.202666292587916

Epoch: 5| Step: 5
Training loss: 1.802554726600647
Validation loss: 2.1841021925210953

Epoch: 5| Step: 6
Training loss: 2.4585120677948
Validation loss: 2.200719436009725

Epoch: 5| Step: 7
Training loss: 2.507161855697632
Validation loss: 2.2032310217618942

Epoch: 5| Step: 8
Training loss: 1.7912060022354126
Validation loss: 2.1948327124118805

Epoch: 5| Step: 9
Training loss: 1.9824413061141968
Validation loss: 2.156965066989263

Epoch: 5| Step: 10
Training loss: 1.6737464666366577
Validation loss: 2.1403007755676904

Epoch: 5| Step: 11
Training loss: 1.7882827520370483
Validation loss: 2.1244730254014335

Epoch: 207| Step: 0
Training loss: 2.3768444061279297
Validation loss: 2.1086320132017136

Epoch: 5| Step: 1
Training loss: 1.9143857955932617
Validation loss: 2.102419743935267

Epoch: 5| Step: 2
Training loss: 2.292621612548828
Validation loss: 2.1057230085134506

Epoch: 5| Step: 3
Training loss: 1.9717190265655518
Validation loss: 2.0847393622001014

Epoch: 5| Step: 4
Training loss: 1.8613498210906982
Validation loss: 2.108519991238912

Epoch: 5| Step: 5
Training loss: 1.8289190530776978
Validation loss: 2.1042813062667847

Epoch: 5| Step: 6
Training loss: 2.1191725730895996
Validation loss: 2.092231646180153

Epoch: 5| Step: 7
Training loss: 1.8831148147583008
Validation loss: 2.110973452528318

Epoch: 5| Step: 8
Training loss: 1.4023816585540771
Validation loss: 2.121876840790113

Epoch: 5| Step: 9
Training loss: 2.1055469512939453
Validation loss: 2.146903400619825

Epoch: 5| Step: 10
Training loss: 1.972254991531372
Validation loss: 2.1488610357046127

Epoch: 5| Step: 11
Training loss: 1.606921911239624
Validation loss: 2.162344088157018

Epoch: 208| Step: 0
Training loss: 2.233494997024536
Validation loss: 2.2072385996580124

Epoch: 5| Step: 1
Training loss: 2.7448220252990723
Validation loss: 2.2047649125258126

Epoch: 5| Step: 2
Training loss: 1.6402908563613892
Validation loss: 2.225535417596499

Epoch: 5| Step: 3
Training loss: 1.8872573375701904
Validation loss: 2.2154359817504883

Epoch: 5| Step: 4
Training loss: 1.7042157649993896
Validation loss: 2.1895382553339005

Epoch: 5| Step: 5
Training loss: 1.8362220525741577
Validation loss: 2.1842271784941354

Epoch: 5| Step: 6
Training loss: 1.3889106512069702
Validation loss: 2.163703590631485

Epoch: 5| Step: 7
Training loss: 1.6548421382904053
Validation loss: 2.1540825366973877

Epoch: 5| Step: 8
Training loss: 1.8742873668670654
Validation loss: 2.153517226378123

Epoch: 5| Step: 9
Training loss: 1.9976660013198853
Validation loss: 2.1373647252718606

Epoch: 5| Step: 10
Training loss: 2.070089817047119
Validation loss: 2.1323438783486686

Epoch: 5| Step: 11
Training loss: 2.5570054054260254
Validation loss: 2.1385047237078347

Epoch: 209| Step: 0
Training loss: 2.564202308654785
Validation loss: 2.1144170065720878

Epoch: 5| Step: 1
Training loss: 1.9097778797149658
Validation loss: 2.1187273114919662

Epoch: 5| Step: 2
Training loss: 1.8925197124481201
Validation loss: 2.1130465964476266

Epoch: 5| Step: 3
Training loss: 1.7423168420791626
Validation loss: 2.1154306679964066

Epoch: 5| Step: 4
Training loss: 1.6053905487060547
Validation loss: 2.145908390482267

Epoch: 5| Step: 5
Training loss: 1.794900894165039
Validation loss: 2.1207850674788156

Epoch: 5| Step: 6
Training loss: 1.9980770349502563
Validation loss: 2.1248100648323693

Epoch: 5| Step: 7
Training loss: 2.177974224090576
Validation loss: 2.148301546772321

Epoch: 5| Step: 8
Training loss: 1.6293487548828125
Validation loss: 2.150570491949717

Epoch: 5| Step: 9
Training loss: 2.016618013381958
Validation loss: 2.151763101418813

Epoch: 5| Step: 10
Training loss: 2.3246207237243652
Validation loss: 2.156164978941282

Epoch: 5| Step: 11
Training loss: 1.8374483585357666
Validation loss: 2.134433001279831

Epoch: 210| Step: 0
Training loss: 2.062519073486328
Validation loss: 2.1658170372247696

Epoch: 5| Step: 1
Training loss: 1.9492107629776
Validation loss: 2.1791817595561347

Epoch: 5| Step: 2
Training loss: 2.275636672973633
Validation loss: 2.1661836902300515

Epoch: 5| Step: 3
Training loss: 1.6723026037216187
Validation loss: 2.1686632484197617

Epoch: 5| Step: 4
Training loss: 1.4518153667449951
Validation loss: 2.153491119543711

Epoch: 5| Step: 5
Training loss: 1.8943052291870117
Validation loss: 2.167491485675176

Epoch: 5| Step: 6
Training loss: 2.341501474380493
Validation loss: 2.151988923549652

Epoch: 5| Step: 7
Training loss: 1.700773000717163
Validation loss: 2.1567291021347046

Epoch: 5| Step: 8
Training loss: 1.4845025539398193
Validation loss: 2.152808884779612

Epoch: 5| Step: 9
Training loss: 2.6332602500915527
Validation loss: 2.1637172301610312

Epoch: 5| Step: 10
Training loss: 1.6914215087890625
Validation loss: 2.168632611632347

Epoch: 5| Step: 11
Training loss: 1.5291039943695068
Validation loss: 2.150287628173828

Epoch: 211| Step: 0
Training loss: 2.1223502159118652
Validation loss: 2.163551698128382

Epoch: 5| Step: 1
Training loss: 1.716893196105957
Validation loss: 2.145209307471911

Epoch: 5| Step: 2
Training loss: 2.230654001235962
Validation loss: 2.138752594590187

Epoch: 5| Step: 3
Training loss: 2.1688055992126465
Validation loss: 2.1383561243613562

Epoch: 5| Step: 4
Training loss: 2.062478542327881
Validation loss: 2.1529617458581924

Epoch: 5| Step: 5
Training loss: 2.033916473388672
Validation loss: 2.149646153052648

Epoch: 5| Step: 6
Training loss: 2.04251766204834
Validation loss: 2.1462957561016083

Epoch: 5| Step: 7
Training loss: 1.6431891918182373
Validation loss: 2.1543450355529785

Epoch: 5| Step: 8
Training loss: 1.5187400579452515
Validation loss: 2.1505889346202216

Epoch: 5| Step: 9
Training loss: 1.2995238304138184
Validation loss: 2.1521011193593345

Epoch: 5| Step: 10
Training loss: 1.9577324390411377
Validation loss: 2.1653540432453156

Epoch: 5| Step: 11
Training loss: 2.1781742572784424
Validation loss: 2.1504426697889962

Epoch: 212| Step: 0
Training loss: 1.308974027633667
Validation loss: 2.195019001762072

Epoch: 5| Step: 1
Training loss: 1.7578855752944946
Validation loss: 2.1979053616523743

Epoch: 5| Step: 2
Training loss: 2.0094337463378906
Validation loss: 2.211662471294403

Epoch: 5| Step: 3
Training loss: 1.8800599575042725
Validation loss: 2.235950062672297

Epoch: 5| Step: 4
Training loss: 2.033017635345459
Validation loss: 2.229540541768074

Epoch: 5| Step: 5
Training loss: 2.3267276287078857
Validation loss: 2.2157727976640067

Epoch: 5| Step: 6
Training loss: 2.0901308059692383
Validation loss: 2.2269746561845145

Epoch: 5| Step: 7
Training loss: 2.0139644145965576
Validation loss: 2.229850302139918

Epoch: 5| Step: 8
Training loss: 1.7618786096572876
Validation loss: 2.2119009693463645

Epoch: 5| Step: 9
Training loss: 1.961724042892456
Validation loss: 2.1944301625092826

Epoch: 5| Step: 10
Training loss: 1.7038357257843018
Validation loss: 2.192737569411596

Epoch: 5| Step: 11
Training loss: 1.607969880104065
Validation loss: 2.15407532453537

Epoch: 213| Step: 0
Training loss: 1.7192414999008179
Validation loss: 2.160040338834127

Epoch: 5| Step: 1
Training loss: 1.4492439031600952
Validation loss: 2.153149942557017

Epoch: 5| Step: 2
Training loss: 1.7292133569717407
Validation loss: 2.1556194027264914

Epoch: 5| Step: 3
Training loss: 1.878003478050232
Validation loss: 2.1574845612049103

Epoch: 5| Step: 4
Training loss: 1.9971864223480225
Validation loss: 2.1546732733647027

Epoch: 5| Step: 5
Training loss: 1.4900439977645874
Validation loss: 2.1315915336211524

Epoch: 5| Step: 6
Training loss: 1.973491907119751
Validation loss: 2.1383261481920877

Epoch: 5| Step: 7
Training loss: 2.1490848064422607
Validation loss: 2.1378759890794754

Epoch: 5| Step: 8
Training loss: 2.073176860809326
Validation loss: 2.141403779387474

Epoch: 5| Step: 9
Training loss: 2.5686168670654297
Validation loss: 2.170597796638807

Epoch: 5| Step: 10
Training loss: 1.9654572010040283
Validation loss: 2.1768682499726615

Epoch: 5| Step: 11
Training loss: 1.6077141761779785
Validation loss: 2.1706329782803855

Epoch: 214| Step: 0
Training loss: 2.228695869445801
Validation loss: 2.2171194354693093

Epoch: 5| Step: 1
Training loss: 2.0128979682922363
Validation loss: 2.243272473414739

Epoch: 5| Step: 2
Training loss: 1.5566974878311157
Validation loss: 2.27326762676239

Epoch: 5| Step: 3
Training loss: 2.019102096557617
Validation loss: 2.276532237728437

Epoch: 5| Step: 4
Training loss: 2.3136391639709473
Validation loss: 2.2762834330399833

Epoch: 5| Step: 5
Training loss: 1.9211208820343018
Validation loss: 2.269926756620407

Epoch: 5| Step: 6
Training loss: 1.9989595413208008
Validation loss: 2.2639028082291284

Epoch: 5| Step: 7
Training loss: 1.946577787399292
Validation loss: 2.2260201275348663

Epoch: 5| Step: 8
Training loss: 1.7256063222885132
Validation loss: 2.194567451874415

Epoch: 5| Step: 9
Training loss: 1.3379299640655518
Validation loss: 2.1722787668307624

Epoch: 5| Step: 10
Training loss: 2.293762445449829
Validation loss: 2.1469156543413797

Epoch: 5| Step: 11
Training loss: 1.0299304723739624
Validation loss: 2.1425213714440665

Epoch: 215| Step: 0
Training loss: 1.8559105396270752
Validation loss: 2.146166125933329

Epoch: 5| Step: 1
Training loss: 1.8235111236572266
Validation loss: 2.1418772588173547

Epoch: 5| Step: 2
Training loss: 1.9824415445327759
Validation loss: 2.1441569278637567

Epoch: 5| Step: 3
Training loss: 1.3252400159835815
Validation loss: 2.172679622968038

Epoch: 5| Step: 4
Training loss: 1.4919748306274414
Validation loss: 2.2074596881866455

Epoch: 5| Step: 5
Training loss: 1.738014578819275
Validation loss: 2.1968615849812827

Epoch: 5| Step: 6
Training loss: 2.267745018005371
Validation loss: 2.220145414272944

Epoch: 5| Step: 7
Training loss: 2.4516568183898926
Validation loss: 2.2325904170672097

Epoch: 5| Step: 8
Training loss: 1.98281991481781
Validation loss: 2.22453980644544

Epoch: 5| Step: 9
Training loss: 1.9332458972930908
Validation loss: 2.230350842078527

Epoch: 5| Step: 10
Training loss: 2.14253568649292
Validation loss: 2.240215619405111

Epoch: 5| Step: 11
Training loss: 1.4454381465911865
Validation loss: 2.2017142474651337

Epoch: 216| Step: 0
Training loss: 1.9352989196777344
Validation loss: 2.186806400616964

Epoch: 5| Step: 1
Training loss: 1.7076467275619507
Validation loss: 2.1713679482539496

Epoch: 5| Step: 2
Training loss: 1.773927927017212
Validation loss: 2.1565028727054596

Epoch: 5| Step: 3
Training loss: 2.1673481464385986
Validation loss: 2.158568263053894

Epoch: 5| Step: 4
Training loss: 1.8867918252944946
Validation loss: 2.153539409240087

Epoch: 5| Step: 5
Training loss: 1.875065565109253
Validation loss: 2.1593186408281326

Epoch: 5| Step: 6
Training loss: 1.495022177696228
Validation loss: 2.163562223315239

Epoch: 5| Step: 7
Training loss: 1.8489711284637451
Validation loss: 2.1474359234174094

Epoch: 5| Step: 8
Training loss: 2.321232557296753
Validation loss: 2.176013926664988

Epoch: 5| Step: 9
Training loss: 1.8214447498321533
Validation loss: 2.165317897995313

Epoch: 5| Step: 10
Training loss: 1.9215528964996338
Validation loss: 2.1913640002409616

Epoch: 5| Step: 11
Training loss: 1.5185389518737793
Validation loss: 2.18771231174469

Epoch: 217| Step: 0
Training loss: 1.8055126667022705
Validation loss: 2.217159395416578

Epoch: 5| Step: 1
Training loss: 2.2693490982055664
Validation loss: 2.2277978559335074

Epoch: 5| Step: 2
Training loss: 2.166085720062256
Validation loss: 2.2099947929382324

Epoch: 5| Step: 3
Training loss: 2.4397072792053223
Validation loss: 2.2190958857536316

Epoch: 5| Step: 4
Training loss: 2.037217617034912
Validation loss: 2.213592732946078

Epoch: 5| Step: 5
Training loss: 1.3041088581085205
Validation loss: 2.20555346707503

Epoch: 5| Step: 6
Training loss: 1.649163007736206
Validation loss: 2.1766928980747857

Epoch: 5| Step: 7
Training loss: 1.9930274486541748
Validation loss: 2.170708398024241

Epoch: 5| Step: 8
Training loss: 1.4106863737106323
Validation loss: 2.165767326951027

Epoch: 5| Step: 9
Training loss: 1.8699023723602295
Validation loss: 2.156057129303614

Epoch: 5| Step: 10
Training loss: 1.6902568340301514
Validation loss: 2.1613498677810035

Epoch: 5| Step: 11
Training loss: 1.0579073429107666
Validation loss: 2.1644952595233917

Epoch: 218| Step: 0
Training loss: 2.3456006050109863
Validation loss: 2.163268302877744

Epoch: 5| Step: 1
Training loss: 1.5414178371429443
Validation loss: 2.171838348110517

Epoch: 5| Step: 2
Training loss: 2.0026159286499023
Validation loss: 2.164061948657036

Epoch: 5| Step: 3
Training loss: 1.8434721231460571
Validation loss: 2.1789729992548623

Epoch: 5| Step: 4
Training loss: 1.441340684890747
Validation loss: 2.1639364759127298

Epoch: 5| Step: 5
Training loss: 2.0653767585754395
Validation loss: 2.1793317645788193

Epoch: 5| Step: 6
Training loss: 1.3626039028167725
Validation loss: 2.1837667524814606

Epoch: 5| Step: 7
Training loss: 1.605432152748108
Validation loss: 2.194021850824356

Epoch: 5| Step: 8
Training loss: 1.9189441204071045
Validation loss: 2.1946534663438797

Epoch: 5| Step: 9
Training loss: 1.2766714096069336
Validation loss: 2.212148611744245

Epoch: 5| Step: 10
Training loss: 2.6467466354370117
Validation loss: 2.2062003761529922

Epoch: 5| Step: 11
Training loss: 3.6024351119995117
Validation loss: 2.2139540115992227

Epoch: 219| Step: 0
Training loss: 1.4573466777801514
Validation loss: 2.2172887126604715

Epoch: 5| Step: 1
Training loss: 2.1228857040405273
Validation loss: 2.2465031345685325

Epoch: 5| Step: 2
Training loss: 2.264997959136963
Validation loss: 2.2508430182933807

Epoch: 5| Step: 3
Training loss: 1.874487280845642
Validation loss: 2.248731111486753

Epoch: 5| Step: 4
Training loss: 2.119762420654297
Validation loss: 2.2218831926584244

Epoch: 5| Step: 5
Training loss: 2.0027904510498047
Validation loss: 2.2209029694398246

Epoch: 5| Step: 6
Training loss: 1.913272500038147
Validation loss: 2.2174621671438217

Epoch: 5| Step: 7
Training loss: 1.5297353267669678
Validation loss: 2.182453433672587

Epoch: 5| Step: 8
Training loss: 2.278146505355835
Validation loss: 2.1793281684319177

Epoch: 5| Step: 9
Training loss: 1.9452956914901733
Validation loss: 2.168582951029142

Epoch: 5| Step: 10
Training loss: 2.0347795486450195
Validation loss: 2.152332454919815

Epoch: 5| Step: 11
Training loss: 1.8544756174087524
Validation loss: 2.1450457026561103

Epoch: 220| Step: 0
Training loss: 1.8305743932724
Validation loss: 2.1415330320596695

Epoch: 5| Step: 1
Training loss: 1.6587440967559814
Validation loss: 2.1413080592950187

Epoch: 5| Step: 2
Training loss: 2.371755599975586
Validation loss: 2.1464790205160775

Epoch: 5| Step: 3
Training loss: 1.8356794118881226
Validation loss: 2.1300425877173743

Epoch: 5| Step: 4
Training loss: 2.385615348815918
Validation loss: 2.139202371239662

Epoch: 5| Step: 5
Training loss: 1.6811336278915405
Validation loss: 2.1434713999430337

Epoch: 5| Step: 6
Training loss: 2.085675001144409
Validation loss: 2.163454825679461

Epoch: 5| Step: 7
Training loss: 1.8845638036727905
Validation loss: 2.1681394229332605

Epoch: 5| Step: 8
Training loss: 1.3447083234786987
Validation loss: 2.1729067067305246

Epoch: 5| Step: 9
Training loss: 2.3898346424102783
Validation loss: 2.183889721830686

Epoch: 5| Step: 10
Training loss: 1.5015212297439575
Validation loss: 2.2034806609153748

Epoch: 5| Step: 11
Training loss: 1.2651209831237793
Validation loss: 2.205172767241796

Epoch: 221| Step: 0
Training loss: 2.1897053718566895
Validation loss: 2.2206325232982635

Epoch: 5| Step: 1
Training loss: 1.9128658771514893
Validation loss: 2.2101658284664154

Epoch: 5| Step: 2
Training loss: 1.8057129383087158
Validation loss: 2.19631498058637

Epoch: 5| Step: 3
Training loss: 2.1322579383850098
Validation loss: 2.1788594325383506

Epoch: 5| Step: 4
Training loss: 1.6042057275772095
Validation loss: 2.1695036192735038

Epoch: 5| Step: 5
Training loss: 1.7688806056976318
Validation loss: 2.173617015282313

Epoch: 5| Step: 6
Training loss: 1.400368094444275
Validation loss: 2.1515137255191803

Epoch: 5| Step: 7
Training loss: 1.8975553512573242
Validation loss: 2.156023050347964

Epoch: 5| Step: 8
Training loss: 1.9315494298934937
Validation loss: 2.1560630053281784

Epoch: 5| Step: 9
Training loss: 2.092170476913452
Validation loss: 2.1419202238321304

Epoch: 5| Step: 10
Training loss: 1.7470890283584595
Validation loss: 2.1536905616521835

Epoch: 5| Step: 11
Training loss: 1.6630154848098755
Validation loss: 2.1950060029824576

Epoch: 222| Step: 0
Training loss: 2.0208444595336914
Validation loss: 2.2140916287899017

Epoch: 5| Step: 1
Training loss: 1.7757962942123413
Validation loss: 2.1988986680905023

Epoch: 5| Step: 2
Training loss: 1.8302326202392578
Validation loss: 2.2246613949537277

Epoch: 5| Step: 3
Training loss: 1.5436151027679443
Validation loss: 2.2243167211612067

Epoch: 5| Step: 4
Training loss: 1.6984798908233643
Validation loss: 2.2086485028266907

Epoch: 5| Step: 5
Training loss: 1.7142059803009033
Validation loss: 2.193948894739151

Epoch: 5| Step: 6
Training loss: 1.511555552482605
Validation loss: 2.193885415792465

Epoch: 5| Step: 7
Training loss: 1.8327770233154297
Validation loss: 2.2015532155831656

Epoch: 5| Step: 8
Training loss: 2.4345836639404297
Validation loss: 2.1741065680980682

Epoch: 5| Step: 9
Training loss: 1.8180640935897827
Validation loss: 2.1810504098733268

Epoch: 5| Step: 10
Training loss: 1.6384083032608032
Validation loss: 2.152422547340393

Epoch: 5| Step: 11
Training loss: 4.079369068145752
Validation loss: 2.1857861280441284

Epoch: 223| Step: 0
Training loss: 1.7498680353164673
Validation loss: 2.149047220746676

Epoch: 5| Step: 1
Training loss: 2.460139751434326
Validation loss: 2.1470733880996704

Epoch: 5| Step: 2
Training loss: 1.6920630931854248
Validation loss: 2.153367335597674

Epoch: 5| Step: 3
Training loss: 2.022373914718628
Validation loss: 2.1572914769252143

Epoch: 5| Step: 4
Training loss: 1.5547735691070557
Validation loss: 2.1651836037635803

Epoch: 5| Step: 5
Training loss: 1.7956374883651733
Validation loss: 2.169650301337242

Epoch: 5| Step: 6
Training loss: 1.5139235258102417
Validation loss: 2.16364578406016

Epoch: 5| Step: 7
Training loss: 2.1530635356903076
Validation loss: 2.1704112788041434

Epoch: 5| Step: 8
Training loss: 1.7632160186767578
Validation loss: 2.171544000506401

Epoch: 5| Step: 9
Training loss: 1.78180730342865
Validation loss: 2.1747062106927237

Epoch: 5| Step: 10
Training loss: 1.7599241733551025
Validation loss: 2.2077245761950812

Epoch: 5| Step: 11
Training loss: 2.686420440673828
Validation loss: 2.208816573023796

Epoch: 224| Step: 0
Training loss: 1.9216406345367432
Validation loss: 2.1727376828591027

Epoch: 5| Step: 1
Training loss: 1.6615486145019531
Validation loss: 2.1923726995786033

Epoch: 5| Step: 2
Training loss: 1.9565861225128174
Validation loss: 2.159114271402359

Epoch: 5| Step: 3
Training loss: 2.651658535003662
Validation loss: 2.151740421851476

Epoch: 5| Step: 4
Training loss: 1.6723945140838623
Validation loss: 2.1478997568289437

Epoch: 5| Step: 5
Training loss: 1.2812029123306274
Validation loss: 2.150343040625254

Epoch: 5| Step: 6
Training loss: 1.8152517080307007
Validation loss: 2.1507720947265625

Epoch: 5| Step: 7
Training loss: 2.018134832382202
Validation loss: 2.1660132010777793

Epoch: 5| Step: 8
Training loss: 1.7386579513549805
Validation loss: 2.172586311896642

Epoch: 5| Step: 9
Training loss: 1.9687039852142334
Validation loss: 2.2048774858315787

Epoch: 5| Step: 10
Training loss: 1.928097128868103
Validation loss: 2.2313355952501297

Epoch: 5| Step: 11
Training loss: 1.754016637802124
Validation loss: 2.2213857620954514

Epoch: 225| Step: 0
Training loss: 2.122244358062744
Validation loss: 2.225658491253853

Epoch: 5| Step: 1
Training loss: 2.105534076690674
Validation loss: 2.1931824733813605

Epoch: 5| Step: 2
Training loss: 2.2604329586029053
Validation loss: 2.1965956638256707

Epoch: 5| Step: 3
Training loss: 1.977607011795044
Validation loss: 2.1844405829906464

Epoch: 5| Step: 4
Training loss: 1.738262414932251
Validation loss: 2.1936084926128387

Epoch: 5| Step: 5
Training loss: 2.0064444541931152
Validation loss: 2.17738672097524

Epoch: 5| Step: 6
Training loss: 1.4935606718063354
Validation loss: 2.1542339076598487

Epoch: 5| Step: 7
Training loss: 1.6897189617156982
Validation loss: 2.1559061159690223

Epoch: 5| Step: 8
Training loss: 1.784217119216919
Validation loss: 2.154327099521955

Epoch: 5| Step: 9
Training loss: 1.4191151857376099
Validation loss: 2.1361978302399316

Epoch: 5| Step: 10
Training loss: 1.7627627849578857
Validation loss: 2.1580404738585153

Epoch: 5| Step: 11
Training loss: 2.29325795173645
Validation loss: 2.1369373401006064

Epoch: 226| Step: 0
Training loss: 1.7246942520141602
Validation loss: 2.1880186746517816

Epoch: 5| Step: 1
Training loss: 1.7910630702972412
Validation loss: 2.199048856894175

Epoch: 5| Step: 2
Training loss: 2.451742649078369
Validation loss: 2.1875256101290383

Epoch: 5| Step: 3
Training loss: 1.571783185005188
Validation loss: 2.2009931902090707

Epoch: 5| Step: 4
Training loss: 1.7206652164459229
Validation loss: 2.2077102760473886

Epoch: 5| Step: 5
Training loss: 1.7194433212280273
Validation loss: 2.182054062684377

Epoch: 5| Step: 6
Training loss: 2.5462119579315186
Validation loss: 2.2146173119544983

Epoch: 5| Step: 7
Training loss: 1.271302342414856
Validation loss: 2.1889781455198922

Epoch: 5| Step: 8
Training loss: 1.7101796865463257
Validation loss: 2.200994392236074

Epoch: 5| Step: 9
Training loss: 2.189810276031494
Validation loss: 2.1921142240365348

Epoch: 5| Step: 10
Training loss: 1.3165432214736938
Validation loss: 2.1851498087247214

Epoch: 5| Step: 11
Training loss: 2.4454479217529297
Validation loss: 2.1944081087907157

Epoch: 227| Step: 0
Training loss: 2.06709623336792
Validation loss: 2.1807811558246613

Epoch: 5| Step: 1
Training loss: 1.514996886253357
Validation loss: 2.1800173074007034

Epoch: 5| Step: 2
Training loss: 1.6070120334625244
Validation loss: 2.178949390848478

Epoch: 5| Step: 3
Training loss: 2.0449862480163574
Validation loss: 2.1764023303985596

Epoch: 5| Step: 4
Training loss: 2.066814422607422
Validation loss: 2.179148162404696

Epoch: 5| Step: 5
Training loss: 1.6299750804901123
Validation loss: 2.1795795361200967

Epoch: 5| Step: 6
Training loss: 1.5254929065704346
Validation loss: 2.168812702099482

Epoch: 5| Step: 7
Training loss: 1.7336227893829346
Validation loss: 2.1820523043473563

Epoch: 5| Step: 8
Training loss: 1.921674370765686
Validation loss: 2.178719366590182

Epoch: 5| Step: 9
Training loss: 2.2712149620056152
Validation loss: 2.1590695083141327

Epoch: 5| Step: 10
Training loss: 1.7777280807495117
Validation loss: 2.1901410023371377

Epoch: 5| Step: 11
Training loss: 1.6639677286148071
Validation loss: 2.163263668616613

Epoch: 228| Step: 0
Training loss: 2.1463537216186523
Validation loss: 2.195213198661804

Epoch: 5| Step: 1
Training loss: 2.2929940223693848
Validation loss: 2.2153791338205338

Epoch: 5| Step: 2
Training loss: 2.2593979835510254
Validation loss: 2.2269000113010406

Epoch: 5| Step: 3
Training loss: 1.9384896755218506
Validation loss: 2.227936108907064

Epoch: 5| Step: 4
Training loss: 1.4644134044647217
Validation loss: 2.2627654621998468

Epoch: 5| Step: 5
Training loss: 1.6860545873641968
Validation loss: 2.2704663077990213

Epoch: 5| Step: 6
Training loss: 1.759619116783142
Validation loss: 2.273561348517736

Epoch: 5| Step: 7
Training loss: 1.7179960012435913
Validation loss: 2.3020737866560617

Epoch: 5| Step: 8
Training loss: 1.6575218439102173
Validation loss: 2.2617786526679993

Epoch: 5| Step: 9
Training loss: 1.9774065017700195
Validation loss: 2.2630621890227

Epoch: 5| Step: 10
Training loss: 1.8923532962799072
Validation loss: 2.2487592001756034

Epoch: 5| Step: 11
Training loss: 0.9466565847396851
Validation loss: 2.218402703603109

Epoch: 229| Step: 0
Training loss: 2.014281749725342
Validation loss: 2.19526415069898

Epoch: 5| Step: 1
Training loss: 2.169949769973755
Validation loss: 2.178826550642649

Epoch: 5| Step: 2
Training loss: 1.3844964504241943
Validation loss: 2.170863394935926

Epoch: 5| Step: 3
Training loss: 1.208024263381958
Validation loss: 2.142679030696551

Epoch: 5| Step: 4
Training loss: 1.6535580158233643
Validation loss: 2.1504588623841605

Epoch: 5| Step: 5
Training loss: 2.048001527786255
Validation loss: 2.146996349096298

Epoch: 5| Step: 6
Training loss: 2.0721614360809326
Validation loss: 2.1488142559925714

Epoch: 5| Step: 7
Training loss: 1.4112383127212524
Validation loss: 2.158746232589086

Epoch: 5| Step: 8
Training loss: 2.1496593952178955
Validation loss: 2.1810766557852426

Epoch: 5| Step: 9
Training loss: 1.880086898803711
Validation loss: 2.1909310022989907

Epoch: 5| Step: 10
Training loss: 2.2333779335021973
Validation loss: 2.2027472158273063

Epoch: 5| Step: 11
Training loss: 2.9435341358184814
Validation loss: 2.218779524167379

Epoch: 230| Step: 0
Training loss: 2.3542964458465576
Validation loss: 2.2309721062580743

Epoch: 5| Step: 1
Training loss: 2.2120425701141357
Validation loss: 2.245167374610901

Epoch: 5| Step: 2
Training loss: 1.5558537244796753
Validation loss: 2.2466360529263816

Epoch: 5| Step: 3
Training loss: 1.694401502609253
Validation loss: 2.236919383207957

Epoch: 5| Step: 4
Training loss: 2.006406307220459
Validation loss: 2.231470505396525

Epoch: 5| Step: 5
Training loss: 2.049412488937378
Validation loss: 2.2416561047236123

Epoch: 5| Step: 6
Training loss: 1.9545519351959229
Validation loss: 2.220070074001948

Epoch: 5| Step: 7
Training loss: 1.924984335899353
Validation loss: 2.196595683693886

Epoch: 5| Step: 8
Training loss: 1.4645087718963623
Validation loss: 2.2198982735474906

Epoch: 5| Step: 9
Training loss: 1.2737321853637695
Validation loss: 2.227119266986847

Epoch: 5| Step: 10
Training loss: 1.6669504642486572
Validation loss: 2.21951362490654

Epoch: 5| Step: 11
Training loss: 0.8645343780517578
Validation loss: 2.213633562127749

Epoch: 231| Step: 0
Training loss: 1.519501805305481
Validation loss: 2.21297579507033

Epoch: 5| Step: 1
Training loss: 2.653243064880371
Validation loss: 2.1809546699126563

Epoch: 5| Step: 2
Training loss: 2.2862560749053955
Validation loss: 2.162711595495542

Epoch: 5| Step: 3
Training loss: 1.5320602655410767
Validation loss: 2.164370968937874

Epoch: 5| Step: 4
Training loss: 1.828932523727417
Validation loss: 2.1509913901487985

Epoch: 5| Step: 5
Training loss: 1.4245483875274658
Validation loss: 2.1372551023960114

Epoch: 5| Step: 6
Training loss: 2.26552152633667
Validation loss: 2.1518118580182395

Epoch: 5| Step: 7
Training loss: 1.6905171871185303
Validation loss: 2.155665472149849

Epoch: 5| Step: 8
Training loss: 1.3782508373260498
Validation loss: 2.1895910600821176

Epoch: 5| Step: 9
Training loss: 1.9460070133209229
Validation loss: 2.2138407826423645

Epoch: 5| Step: 10
Training loss: 1.971796989440918
Validation loss: 2.2162604878346124

Epoch: 5| Step: 11
Training loss: 0.7635269165039062
Validation loss: 2.233653962612152

Epoch: 232| Step: 0
Training loss: 2.137737274169922
Validation loss: 2.265580107768377

Epoch: 5| Step: 1
Training loss: 2.0701847076416016
Validation loss: 2.277574767669042

Epoch: 5| Step: 2
Training loss: 2.3019604682922363
Validation loss: 2.26840149362882

Epoch: 5| Step: 3
Training loss: 1.0491715669631958
Validation loss: 2.2636735439300537

Epoch: 5| Step: 4
Training loss: 1.6684715747833252
Validation loss: 2.2690151085456214

Epoch: 5| Step: 5
Training loss: 2.1524837017059326
Validation loss: 2.2380400002002716

Epoch: 5| Step: 6
Training loss: 1.9175803661346436
Validation loss: 2.242008000612259

Epoch: 5| Step: 7
Training loss: 1.5164471864700317
Validation loss: 2.2125711192687354

Epoch: 5| Step: 8
Training loss: 1.3464854955673218
Validation loss: 2.2032179733117423

Epoch: 5| Step: 9
Training loss: 1.9451522827148438
Validation loss: 2.17300013701121

Epoch: 5| Step: 10
Training loss: 2.1749393939971924
Validation loss: 2.1840740740299225

Epoch: 5| Step: 11
Training loss: 1.204915165901184
Validation loss: 2.1608876387278237

Epoch: 233| Step: 0
Training loss: 1.6023151874542236
Validation loss: 2.1744547883669534

Epoch: 5| Step: 1
Training loss: 2.3813464641571045
Validation loss: 2.1580102245012918

Epoch: 5| Step: 2
Training loss: 1.745465636253357
Validation loss: 2.1736668149630227

Epoch: 5| Step: 3
Training loss: 1.8186699151992798
Validation loss: 2.1793241997559867

Epoch: 5| Step: 4
Training loss: 2.172889471054077
Validation loss: 2.191946804523468

Epoch: 5| Step: 5
Training loss: 2.119675636291504
Validation loss: 2.1912378321091333

Epoch: 5| Step: 6
Training loss: 1.0023057460784912
Validation loss: 2.185892899831136

Epoch: 5| Step: 7
Training loss: 1.662535309791565
Validation loss: 2.2075388381878533

Epoch: 5| Step: 8
Training loss: 2.1031179428100586
Validation loss: 2.2423342068990073

Epoch: 5| Step: 9
Training loss: 1.6164623498916626
Validation loss: 2.2384042193492255

Epoch: 5| Step: 10
Training loss: 2.0972900390625
Validation loss: 2.2969413697719574

Epoch: 5| Step: 11
Training loss: 1.4612960815429688
Validation loss: 2.268099546432495

Epoch: 234| Step: 0
Training loss: 1.6751925945281982
Validation loss: 2.2580124835173288

Epoch: 5| Step: 1
Training loss: 1.857683777809143
Validation loss: 2.287331521511078

Epoch: 5| Step: 2
Training loss: 1.544316053390503
Validation loss: 2.215303361415863

Epoch: 5| Step: 3
Training loss: 1.981039047241211
Validation loss: 2.2094726264476776

Epoch: 5| Step: 4
Training loss: 2.2607338428497314
Validation loss: 2.175322781006495

Epoch: 5| Step: 5
Training loss: 1.8189939260482788
Validation loss: 2.1688070595264435

Epoch: 5| Step: 6
Training loss: 1.706743836402893
Validation loss: 2.163316930333773

Epoch: 5| Step: 7
Training loss: 1.6441417932510376
Validation loss: 2.162130892276764

Epoch: 5| Step: 8
Training loss: 2.1238837242126465
Validation loss: 2.170279105504354

Epoch: 5| Step: 9
Training loss: 2.0773422718048096
Validation loss: 2.1688894033432007

Epoch: 5| Step: 10
Training loss: 1.5159738063812256
Validation loss: 2.174880256255468

Epoch: 5| Step: 11
Training loss: 2.569284439086914
Validation loss: 2.2071035504341125

Epoch: 235| Step: 0
Training loss: 1.449800729751587
Validation loss: 2.2426127245028815

Epoch: 5| Step: 1
Training loss: 1.4826180934906006
Validation loss: 2.2152756452560425

Epoch: 5| Step: 2
Training loss: 2.189138412475586
Validation loss: 2.247423122326533

Epoch: 5| Step: 3
Training loss: 1.5389041900634766
Validation loss: 2.235503911972046

Epoch: 5| Step: 4
Training loss: 1.8384500741958618
Validation loss: 2.2631860872109733

Epoch: 5| Step: 5
Training loss: 2.2482128143310547
Validation loss: 2.235598494609197

Epoch: 5| Step: 6
Training loss: 1.685339331626892
Validation loss: 2.210345054666201

Epoch: 5| Step: 7
Training loss: 2.3700790405273438
Validation loss: 2.2282836685578027

Epoch: 5| Step: 8
Training loss: 1.4403116703033447
Validation loss: 2.237158219019572

Epoch: 5| Step: 9
Training loss: 1.9849103689193726
Validation loss: 2.208790292342504

Epoch: 5| Step: 10
Training loss: 1.8079763650894165
Validation loss: 2.2474974989891052

Epoch: 5| Step: 11
Training loss: 1.0275298357009888
Validation loss: 2.2227224310239158

Epoch: 236| Step: 0
Training loss: 1.5746076107025146
Validation loss: 2.2017168005307517

Epoch: 5| Step: 1
Training loss: 1.7516593933105469
Validation loss: 2.1990752716859183

Epoch: 5| Step: 2
Training loss: 1.785997986793518
Validation loss: 2.1948652466138205

Epoch: 5| Step: 3
Training loss: 2.610896587371826
Validation loss: 2.1783520380655923

Epoch: 5| Step: 4
Training loss: 2.3385424613952637
Validation loss: 2.1679671903451285

Epoch: 5| Step: 5
Training loss: 1.7920684814453125
Validation loss: 2.1745410760243735

Epoch: 5| Step: 6
Training loss: 2.1212005615234375
Validation loss: 2.1940807600816092

Epoch: 5| Step: 7
Training loss: 1.965951681137085
Validation loss: 2.190875917673111

Epoch: 5| Step: 8
Training loss: 1.362882375717163
Validation loss: 2.204230854908625

Epoch: 5| Step: 9
Training loss: 1.9275773763656616
Validation loss: 2.195040504137675

Epoch: 5| Step: 10
Training loss: 1.5035470724105835
Validation loss: 2.2087355752786

Epoch: 5| Step: 11
Training loss: 2.3300986289978027
Validation loss: 2.2072544495264688

Epoch: 237| Step: 0
Training loss: 1.8868372440338135
Validation loss: 2.2164507806301117

Epoch: 5| Step: 1
Training loss: 1.9770784378051758
Validation loss: 2.2475087443987527

Epoch: 5| Step: 2
Training loss: 1.8153603076934814
Validation loss: 2.242534185449282

Epoch: 5| Step: 3
Training loss: 1.7535651922225952
Validation loss: 2.257988582054774

Epoch: 5| Step: 4
Training loss: 2.0408432483673096
Validation loss: 2.2340920766194663

Epoch: 5| Step: 5
Training loss: 1.8951103687286377
Validation loss: 2.2406306167443595

Epoch: 5| Step: 6
Training loss: 1.708325982093811
Validation loss: 2.248459820946058

Epoch: 5| Step: 7
Training loss: 1.6832730770111084
Validation loss: 2.244145711263021

Epoch: 5| Step: 8
Training loss: 1.7629082202911377
Validation loss: 2.2358016769091287

Epoch: 5| Step: 9
Training loss: 2.0731735229492188
Validation loss: 2.253699774543444

Epoch: 5| Step: 10
Training loss: 1.777308702468872
Validation loss: 2.2303479264179864

Epoch: 5| Step: 11
Training loss: 1.2431459426879883
Validation loss: 2.2012609938780465

Epoch: 238| Step: 0
Training loss: 1.57470703125
Validation loss: 2.1854949394861856

Epoch: 5| Step: 1
Training loss: 1.840376615524292
Validation loss: 2.1856525291999183

Epoch: 5| Step: 2
Training loss: 1.703582763671875
Validation loss: 2.1704325824975967

Epoch: 5| Step: 3
Training loss: 1.5727640390396118
Validation loss: 2.176791161298752

Epoch: 5| Step: 4
Training loss: 2.18571400642395
Validation loss: 2.179255227247874

Epoch: 5| Step: 5
Training loss: 1.5873621702194214
Validation loss: 2.1936302483081818

Epoch: 5| Step: 6
Training loss: 1.928727388381958
Validation loss: 2.200420389572779

Epoch: 5| Step: 7
Training loss: 1.7574329376220703
Validation loss: 2.24945638080438

Epoch: 5| Step: 8
Training loss: 1.8130979537963867
Validation loss: 2.2352028687795005

Epoch: 5| Step: 9
Training loss: 2.1378448009490967
Validation loss: 2.2353848963975906

Epoch: 5| Step: 10
Training loss: 2.126228094100952
Validation loss: 2.2129970441261926

Epoch: 5| Step: 11
Training loss: 2.347476005554199
Validation loss: 2.226059148708979

Epoch: 239| Step: 0
Training loss: 1.756360650062561
Validation loss: 2.231821129719416

Epoch: 5| Step: 1
Training loss: 1.4841142892837524
Validation loss: 2.1999227007230124

Epoch: 5| Step: 2
Training loss: 1.7663875818252563
Validation loss: 2.206042697032293

Epoch: 5| Step: 3
Training loss: 1.887094259262085
Validation loss: 2.1931310842434564

Epoch: 5| Step: 4
Training loss: 1.446439266204834
Validation loss: 2.1844564179579415

Epoch: 5| Step: 5
Training loss: 2.014594793319702
Validation loss: 2.176801179846128

Epoch: 5| Step: 6
Training loss: 1.9266881942749023
Validation loss: 2.20735140144825

Epoch: 5| Step: 7
Training loss: 1.8155200481414795
Validation loss: 2.1983159879843392

Epoch: 5| Step: 8
Training loss: 2.3714423179626465
Validation loss: 2.2023935317993164

Epoch: 5| Step: 9
Training loss: 1.4432098865509033
Validation loss: 2.215380554397901

Epoch: 5| Step: 10
Training loss: 2.186673641204834
Validation loss: 2.230492497483889

Epoch: 5| Step: 11
Training loss: 1.2424838542938232
Validation loss: 2.191954791545868

Epoch: 240| Step: 0
Training loss: 2.1308224201202393
Validation loss: 2.199461743235588

Epoch: 5| Step: 1
Training loss: 1.718224287033081
Validation loss: 2.173639083902041

Epoch: 5| Step: 2
Training loss: 1.312436580657959
Validation loss: 2.1567070931196213

Epoch: 5| Step: 3
Training loss: 1.7222923040390015
Validation loss: 2.1516750852266946

Epoch: 5| Step: 4
Training loss: 1.891783356666565
Validation loss: 2.1513333270947137

Epoch: 5| Step: 5
Training loss: 1.6887668371200562
Validation loss: 2.1717848678429923

Epoch: 5| Step: 6
Training loss: 1.791991949081421
Validation loss: 2.197506010532379

Epoch: 5| Step: 7
Training loss: 1.5297588109970093
Validation loss: 2.228245367606481

Epoch: 5| Step: 8
Training loss: 2.4501845836639404
Validation loss: 2.21922305226326

Epoch: 5| Step: 9
Training loss: 1.734222650527954
Validation loss: 2.2684017419815063

Epoch: 5| Step: 10
Training loss: 2.2041873931884766
Validation loss: 2.264105260372162

Epoch: 5| Step: 11
Training loss: 1.3186841011047363
Validation loss: 2.257967154184977

Epoch: 241| Step: 0
Training loss: 1.9305013418197632
Validation loss: 2.2473117957512536

Epoch: 5| Step: 1
Training loss: 1.7079875469207764
Validation loss: 2.184982786575953

Epoch: 5| Step: 2
Training loss: 1.7578846216201782
Validation loss: 2.1442046960194907

Epoch: 5| Step: 3
Training loss: 1.8412463665008545
Validation loss: 2.1332054436206818

Epoch: 5| Step: 4
Training loss: 2.382930278778076
Validation loss: 2.1721115658680596

Epoch: 5| Step: 5
Training loss: 1.6559650897979736
Validation loss: 2.149131362636884

Epoch: 5| Step: 6
Training loss: 1.841848611831665
Validation loss: 2.143251657485962

Epoch: 5| Step: 7
Training loss: 1.9025570154190063
Validation loss: 2.20965468386809

Epoch: 5| Step: 8
Training loss: 1.4463993310928345
Validation loss: 2.2133331298828125

Epoch: 5| Step: 9
Training loss: 2.1140596866607666
Validation loss: 2.2360875407854715

Epoch: 5| Step: 10
Training loss: 1.6535472869873047
Validation loss: 2.2560712496439614

Epoch: 5| Step: 11
Training loss: 2.900702476501465
Validation loss: 2.227591340740522

Epoch: 242| Step: 0
Training loss: 1.6197073459625244
Validation loss: 2.2548455595970154

Epoch: 5| Step: 1
Training loss: 1.980324387550354
Validation loss: 2.2421037952105203

Epoch: 5| Step: 2
Training loss: 1.9815607070922852
Validation loss: 2.2584673265616098

Epoch: 5| Step: 3
Training loss: 1.7462942600250244
Validation loss: 2.267073839902878

Epoch: 5| Step: 4
Training loss: 2.6258931159973145
Validation loss: 2.232725828886032

Epoch: 5| Step: 5
Training loss: 2.083350658416748
Validation loss: 2.2451253732045493

Epoch: 5| Step: 6
Training loss: 1.5160129070281982
Validation loss: 2.24935316046079

Epoch: 5| Step: 7
Training loss: 1.5072510242462158
Validation loss: 2.22308649122715

Epoch: 5| Step: 8
Training loss: 1.894169569015503
Validation loss: 2.2203224251667657

Epoch: 5| Step: 9
Training loss: 1.9058167934417725
Validation loss: 2.2179468075434365

Epoch: 5| Step: 10
Training loss: 1.3191519975662231
Validation loss: 2.2150115966796875

Epoch: 5| Step: 11
Training loss: 1.491714596748352
Validation loss: 2.194213037689527

Epoch: 243| Step: 0
Training loss: 1.9038431644439697
Validation loss: 2.1870594223340354

Epoch: 5| Step: 1
Training loss: 2.2117390632629395
Validation loss: 2.207062472899755

Epoch: 5| Step: 2
Training loss: 1.3127214908599854
Validation loss: 2.215543041626612

Epoch: 5| Step: 3
Training loss: 1.9953515529632568
Validation loss: 2.2337040503819785

Epoch: 5| Step: 4
Training loss: 2.5763981342315674
Validation loss: 2.2189684212207794

Epoch: 5| Step: 5
Training loss: 1.1794507503509521
Validation loss: 2.23163474102815

Epoch: 5| Step: 6
Training loss: 1.2383614778518677
Validation loss: 2.241772343715032

Epoch: 5| Step: 7
Training loss: 1.6779108047485352
Validation loss: 2.253548781077067

Epoch: 5| Step: 8
Training loss: 2.2073330879211426
Validation loss: 2.2350260416666665

Epoch: 5| Step: 9
Training loss: 1.6926196813583374
Validation loss: 2.221685230731964

Epoch: 5| Step: 10
Training loss: 1.972426414489746
Validation loss: 2.2251910865306854

Epoch: 5| Step: 11
Training loss: 1.484259009361267
Validation loss: 2.2340235114097595

Epoch: 244| Step: 0
Training loss: 1.305680513381958
Validation loss: 2.180736859639486

Epoch: 5| Step: 1
Training loss: 1.7119592428207397
Validation loss: 2.157626082499822

Epoch: 5| Step: 2
Training loss: 2.321150541305542
Validation loss: 2.14946581919988

Epoch: 5| Step: 3
Training loss: 1.915604829788208
Validation loss: 2.162614405155182

Epoch: 5| Step: 4
Training loss: 1.8009235858917236
Validation loss: 2.1513240138689675

Epoch: 5| Step: 5
Training loss: 1.912519097328186
Validation loss: 2.144799083471298

Epoch: 5| Step: 6
Training loss: 2.4576241970062256
Validation loss: 2.15508038798968

Epoch: 5| Step: 7
Training loss: 2.0154945850372314
Validation loss: 2.148309901356697

Epoch: 5| Step: 8
Training loss: 0.9946655035018921
Validation loss: 2.156696786483129

Epoch: 5| Step: 9
Training loss: 2.1087405681610107
Validation loss: 2.175515577197075

Epoch: 5| Step: 10
Training loss: 1.873557686805725
Validation loss: 2.1625917007525763

Epoch: 5| Step: 11
Training loss: 1.4227811098098755
Validation loss: 2.1705555270115533

Epoch: 245| Step: 0
Training loss: 1.4212397336959839
Validation loss: 2.1838010450204215

Epoch: 5| Step: 1
Training loss: 1.9444555044174194
Validation loss: 2.19719131787618

Epoch: 5| Step: 2
Training loss: 2.1332221031188965
Validation loss: 2.1871757209300995

Epoch: 5| Step: 3
Training loss: 2.034254550933838
Validation loss: 2.1729519963264465

Epoch: 5| Step: 4
Training loss: 1.1383472681045532
Validation loss: 2.158396835128466

Epoch: 5| Step: 5
Training loss: 1.8584896326065063
Validation loss: 2.1681966284910836

Epoch: 5| Step: 6
Training loss: 1.9921611547470093
Validation loss: 2.174254740277926

Epoch: 5| Step: 7
Training loss: 2.0331764221191406
Validation loss: 2.1487942785024643

Epoch: 5| Step: 8
Training loss: 1.823647141456604
Validation loss: 2.165172522266706

Epoch: 5| Step: 9
Training loss: 1.7887401580810547
Validation loss: 2.1679420173168182

Epoch: 5| Step: 10
Training loss: 2.0549449920654297
Validation loss: 2.1657598416010537

Epoch: 5| Step: 11
Training loss: 2.9764184951782227
Validation loss: 2.1926817893981934

Epoch: 246| Step: 0
Training loss: 1.8399055004119873
Validation loss: 2.195354168613752

Epoch: 5| Step: 1
Training loss: 1.726999044418335
Validation loss: 2.1950547297795615

Epoch: 5| Step: 2
Training loss: 1.8763272762298584
Validation loss: 2.2029202580451965

Epoch: 5| Step: 3
Training loss: 1.5897369384765625
Validation loss: 2.1986397902170816

Epoch: 5| Step: 4
Training loss: 2.057642698287964
Validation loss: 2.2046407709519067

Epoch: 5| Step: 5
Training loss: 1.9824059009552002
Validation loss: 2.221010227998098

Epoch: 5| Step: 6
Training loss: 1.8630443811416626
Validation loss: 2.2074675808350244

Epoch: 5| Step: 7
Training loss: 2.224613904953003
Validation loss: 2.2376173784335456

Epoch: 5| Step: 8
Training loss: 1.6801278591156006
Validation loss: 2.2153156648079553

Epoch: 5| Step: 9
Training loss: 1.7729337215423584
Validation loss: 2.192493036389351

Epoch: 5| Step: 10
Training loss: 1.3749315738677979
Validation loss: 2.206653485695521

Epoch: 5| Step: 11
Training loss: 0.9341793060302734
Validation loss: 2.1938827286163964

Epoch: 247| Step: 0
Training loss: 1.6194404363632202
Validation loss: 2.18703260521094

Epoch: 5| Step: 1
Training loss: 1.6580177545547485
Validation loss: 2.1660274664560952

Epoch: 5| Step: 2
Training loss: 2.8079495429992676
Validation loss: 2.2187896221876144

Epoch: 5| Step: 3
Training loss: 1.6884294748306274
Validation loss: 2.2021093517541885

Epoch: 5| Step: 4
Training loss: 1.8474363088607788
Validation loss: 2.2417519440253577

Epoch: 5| Step: 5
Training loss: 1.3237297534942627
Validation loss: 2.215071678161621

Epoch: 5| Step: 6
Training loss: 1.8777961730957031
Validation loss: 2.2417186945676804

Epoch: 5| Step: 7
Training loss: 1.4010425806045532
Validation loss: 2.2297821044921875

Epoch: 5| Step: 8
Training loss: 1.9817701578140259
Validation loss: 2.243492220838865

Epoch: 5| Step: 9
Training loss: 2.0145983695983887
Validation loss: 2.2612563967704773

Epoch: 5| Step: 10
Training loss: 1.7450014352798462
Validation loss: 2.254006043076515

Epoch: 5| Step: 11
Training loss: 1.781721591949463
Validation loss: 2.2748999496301017

Epoch: 248| Step: 0
Training loss: 1.9163118600845337
Validation loss: 2.2651312202215195

Epoch: 5| Step: 1
Training loss: 2.466362953186035
Validation loss: 2.2417946656545005

Epoch: 5| Step: 2
Training loss: 1.6347274780273438
Validation loss: 2.219122350215912

Epoch: 5| Step: 3
Training loss: 2.1184182167053223
Validation loss: 2.185308893521627

Epoch: 5| Step: 4
Training loss: 2.048245668411255
Validation loss: 2.1794236401716867

Epoch: 5| Step: 5
Training loss: 1.5430339574813843
Validation loss: 2.202305401364962

Epoch: 5| Step: 6
Training loss: 1.346878170967102
Validation loss: 2.2046267737944922

Epoch: 5| Step: 7
Training loss: 1.5888324975967407
Validation loss: 2.2063295990228653

Epoch: 5| Step: 8
Training loss: 1.8268115520477295
Validation loss: 2.2203734815120697

Epoch: 5| Step: 9
Training loss: 1.3450547456741333
Validation loss: 2.2003967414299646

Epoch: 5| Step: 10
Training loss: 1.987431287765503
Validation loss: 2.200627326965332

Epoch: 5| Step: 11
Training loss: 0.953327476978302
Validation loss: 2.2134231527646384

Epoch: 249| Step: 0
Training loss: 1.666935682296753
Validation loss: 2.206668401757876

Epoch: 5| Step: 1
Training loss: 1.6427940130233765
Validation loss: 2.1842434406280518

Epoch: 5| Step: 2
Training loss: 2.008953809738159
Validation loss: 2.1866949101289115

Epoch: 5| Step: 3
Training loss: 1.7662408351898193
Validation loss: 2.1819278796513877

Epoch: 5| Step: 4
Training loss: 1.4022749662399292
Validation loss: 2.1914092004299164

Epoch: 5| Step: 5
Training loss: 2.610743999481201
Validation loss: 2.1822893768548965

Epoch: 5| Step: 6
Training loss: 1.4307427406311035
Validation loss: 2.2005941718816757

Epoch: 5| Step: 7
Training loss: 1.579933524131775
Validation loss: 2.188615471124649

Epoch: 5| Step: 8
Training loss: 1.772762656211853
Validation loss: 2.1932396392027536

Epoch: 5| Step: 9
Training loss: 1.8174701929092407
Validation loss: 2.201641251643499

Epoch: 5| Step: 10
Training loss: 2.0779411792755127
Validation loss: 2.2153813391923904

Epoch: 5| Step: 11
Training loss: 0.8830480575561523
Validation loss: 2.219587132334709

Epoch: 250| Step: 0
Training loss: 1.8629090785980225
Validation loss: 2.2116997987031937

Epoch: 5| Step: 1
Training loss: 2.189326763153076
Validation loss: 2.2469376424948373

Epoch: 5| Step: 2
Training loss: 1.5691049098968506
Validation loss: 2.2306723296642303

Epoch: 5| Step: 3
Training loss: 1.3604580163955688
Validation loss: 2.201498011747996

Epoch: 5| Step: 4
Training loss: 2.2106597423553467
Validation loss: 2.2257087032000222

Epoch: 5| Step: 5
Training loss: 1.8123382329940796
Validation loss: 2.234148015578588

Epoch: 5| Step: 6
Training loss: 1.3828957080841064
Validation loss: 2.2193566858768463

Epoch: 5| Step: 7
Training loss: 1.819095253944397
Validation loss: 2.2214461117982864

Epoch: 5| Step: 8
Training loss: 2.134749412536621
Validation loss: 2.2125254571437836

Epoch: 5| Step: 9
Training loss: 1.5800483226776123
Validation loss: 2.248001535733541

Epoch: 5| Step: 10
Training loss: 1.6803268194198608
Validation loss: 2.261220688621203

Epoch: 5| Step: 11
Training loss: 1.9372293949127197
Validation loss: 2.2945142139991126

Epoch: 251| Step: 0
Training loss: 1.5958961248397827
Validation loss: 2.277593900760015

Epoch: 5| Step: 1
Training loss: 1.5118051767349243
Validation loss: 2.2620887557665506

Epoch: 5| Step: 2
Training loss: 1.8332502841949463
Validation loss: 2.214184030890465

Epoch: 5| Step: 3
Training loss: 1.6144527196884155
Validation loss: 2.223672275741895

Epoch: 5| Step: 4
Training loss: 1.9130070209503174
Validation loss: 2.193215176463127

Epoch: 5| Step: 5
Training loss: 1.7955405712127686
Validation loss: 2.1825916916131973

Epoch: 5| Step: 6
Training loss: 2.2097015380859375
Validation loss: 2.162020350495974

Epoch: 5| Step: 7
Training loss: 1.6116158962249756
Validation loss: 2.1616351852814355

Epoch: 5| Step: 8
Training loss: 2.1537280082702637
Validation loss: 2.183956945935885

Epoch: 5| Step: 9
Training loss: 1.6846492290496826
Validation loss: 2.1745678186416626

Epoch: 5| Step: 10
Training loss: 1.9432014226913452
Validation loss: 2.185774087905884

Epoch: 5| Step: 11
Training loss: 3.2806825637817383
Validation loss: 2.2116295993328094

Epoch: 252| Step: 0
Training loss: 1.939455270767212
Validation loss: 2.2358538657426834

Epoch: 5| Step: 1
Training loss: 1.5937703847885132
Validation loss: 2.2674282242854438

Epoch: 5| Step: 2
Training loss: 1.4299225807189941
Validation loss: 2.306890308856964

Epoch: 5| Step: 3
Training loss: 1.5932023525238037
Validation loss: 2.30220565199852

Epoch: 5| Step: 4
Training loss: 1.9106003046035767
Validation loss: 2.318404366572698

Epoch: 5| Step: 5
Training loss: 1.9606618881225586
Validation loss: 2.3349297642707825

Epoch: 5| Step: 6
Training loss: 2.0602169036865234
Validation loss: 2.3248718082904816

Epoch: 5| Step: 7
Training loss: 2.238187074661255
Validation loss: 2.3181383510430655

Epoch: 5| Step: 8
Training loss: 1.8012317419052124
Validation loss: 2.2771238883336387

Epoch: 5| Step: 9
Training loss: 1.5961101055145264
Validation loss: 2.235142966111501

Epoch: 5| Step: 10
Training loss: 1.846365213394165
Validation loss: 2.2347881396611533

Epoch: 5| Step: 11
Training loss: 2.5616002082824707
Validation loss: 2.2141453623771667

Epoch: 253| Step: 0
Training loss: 1.1440119743347168
Validation loss: 2.1899970372517905

Epoch: 5| Step: 1
Training loss: 1.6427571773529053
Validation loss: 2.2043983141581216

Epoch: 5| Step: 2
Training loss: 1.6056702136993408
Validation loss: 2.1774299095074334

Epoch: 5| Step: 3
Training loss: 1.7939907312393188
Validation loss: 2.187164142727852

Epoch: 5| Step: 4
Training loss: 2.0044467449188232
Validation loss: 2.1869952380657196

Epoch: 5| Step: 5
Training loss: 1.9534580707550049
Validation loss: 2.206314409772555

Epoch: 5| Step: 6
Training loss: 1.756481409072876
Validation loss: 2.2290496826171875

Epoch: 5| Step: 7
Training loss: 1.5891516208648682
Validation loss: 2.229188779989878

Epoch: 5| Step: 8
Training loss: 2.071734666824341
Validation loss: 2.2352049549420676

Epoch: 5| Step: 9
Training loss: 2.255315065383911
Validation loss: 2.21848696966966

Epoch: 5| Step: 10
Training loss: 2.125739097595215
Validation loss: 2.2362667272488275

Epoch: 5| Step: 11
Training loss: 1.3806068897247314
Validation loss: 2.227280596892039

Epoch: 254| Step: 0
Training loss: 1.8830640316009521
Validation loss: 2.2512406508127847

Epoch: 5| Step: 1
Training loss: 1.7321596145629883
Validation loss: 2.2578516801198325

Epoch: 5| Step: 2
Training loss: 1.8140815496444702
Validation loss: 2.2514554262161255

Epoch: 5| Step: 3
Training loss: 1.847219705581665
Validation loss: 2.269419237971306

Epoch: 5| Step: 4
Training loss: 1.4117783308029175
Validation loss: 2.2664319376150766

Epoch: 5| Step: 5
Training loss: 1.4512497186660767
Validation loss: 2.254634290933609

Epoch: 5| Step: 6
Training loss: 1.9384582042694092
Validation loss: 2.2325074672698975

Epoch: 5| Step: 7
Training loss: 1.5231478214263916
Validation loss: 2.2497802674770355

Epoch: 5| Step: 8
Training loss: 1.8396755456924438
Validation loss: 2.170141026377678

Epoch: 5| Step: 9
Training loss: 2.2154598236083984
Validation loss: 2.1753912965456643

Epoch: 5| Step: 10
Training loss: 1.8635890483856201
Validation loss: 2.1707365959882736

Epoch: 5| Step: 11
Training loss: 1.5412631034851074
Validation loss: 2.1679423302412033

Epoch: 255| Step: 0
Training loss: 2.2264087200164795
Validation loss: 2.1572243670622506

Epoch: 5| Step: 1
Training loss: 1.720028281211853
Validation loss: 2.165108174085617

Epoch: 5| Step: 2
Training loss: 1.3199373483657837
Validation loss: 2.1302276800076165

Epoch: 5| Step: 3
Training loss: 1.9129104614257812
Validation loss: 2.1455463965733848

Epoch: 5| Step: 4
Training loss: 2.1902782917022705
Validation loss: 2.1463347574075065

Epoch: 5| Step: 5
Training loss: 2.5292179584503174
Validation loss: 2.154429624478022

Epoch: 5| Step: 6
Training loss: 2.156646728515625
Validation loss: 2.1739130119482675

Epoch: 5| Step: 7
Training loss: 1.5626626014709473
Validation loss: 2.1786690751711526

Epoch: 5| Step: 8
Training loss: 2.094268560409546
Validation loss: 2.1951436201731362

Epoch: 5| Step: 9
Training loss: 1.2182329893112183
Validation loss: 2.217301994562149

Epoch: 5| Step: 10
Training loss: 1.47762131690979
Validation loss: 2.2545787692070007

Epoch: 5| Step: 11
Training loss: 2.4063363075256348
Validation loss: 2.275173599521319

Epoch: 256| Step: 0
Training loss: 1.4488216638565063
Validation loss: 2.2698551019032798

Epoch: 5| Step: 1
Training loss: 1.9995310306549072
Validation loss: 2.248530993858973

Epoch: 5| Step: 2
Training loss: 1.2645782232284546
Validation loss: 2.2388836393753686

Epoch: 5| Step: 3
Training loss: 1.2971383333206177
Validation loss: 2.206152235468229

Epoch: 5| Step: 4
Training loss: 2.11118483543396
Validation loss: 2.1811324258645377

Epoch: 5| Step: 5
Training loss: 1.6062284708023071
Validation loss: 2.2037614981333413

Epoch: 5| Step: 6
Training loss: 2.1193103790283203
Validation loss: 2.2066917220751443

Epoch: 5| Step: 7
Training loss: 1.3070248365402222
Validation loss: 2.1768462310234704

Epoch: 5| Step: 8
Training loss: 1.9291279315948486
Validation loss: 2.188596785068512

Epoch: 5| Step: 9
Training loss: 2.274289608001709
Validation loss: 2.177538717786471

Epoch: 5| Step: 10
Training loss: 2.068871259689331
Validation loss: 2.194395442803701

Epoch: 5| Step: 11
Training loss: 3.086214065551758
Validation loss: 2.197664757569631

Epoch: 257| Step: 0
Training loss: 1.5198848247528076
Validation loss: 2.207328592737516

Epoch: 5| Step: 1
Training loss: 1.275468349456787
Validation loss: 2.222133611639341

Epoch: 5| Step: 2
Training loss: 1.5621795654296875
Validation loss: 2.2232391784588494

Epoch: 5| Step: 3
Training loss: 1.9316104650497437
Validation loss: 2.2350192964076996

Epoch: 5| Step: 4
Training loss: 2.1384835243225098
Validation loss: 2.281663795312246

Epoch: 5| Step: 5
Training loss: 2.0790696144104004
Validation loss: 2.2574723263581595

Epoch: 5| Step: 6
Training loss: 1.6838268041610718
Validation loss: 2.245203047990799

Epoch: 5| Step: 7
Training loss: 1.57087242603302
Validation loss: 2.2200649281342826

Epoch: 5| Step: 8
Training loss: 2.0249671936035156
Validation loss: 2.219440460205078

Epoch: 5| Step: 9
Training loss: 1.7752689123153687
Validation loss: 2.2359527150789895

Epoch: 5| Step: 10
Training loss: 1.6890132427215576
Validation loss: 2.223413497209549

Epoch: 5| Step: 11
Training loss: 2.596468687057495
Validation loss: 2.214860330025355

Epoch: 258| Step: 0
Training loss: 2.593925952911377
Validation loss: 2.1995361844698587

Epoch: 5| Step: 1
Training loss: 2.015887498855591
Validation loss: 2.1765898118416467

Epoch: 5| Step: 2
Training loss: 1.523638367652893
Validation loss: 2.18279992043972

Epoch: 5| Step: 3
Training loss: 1.3418699502944946
Validation loss: 2.170009975632032

Epoch: 5| Step: 4
Training loss: 1.9359769821166992
Validation loss: 2.179060975710551

Epoch: 5| Step: 5
Training loss: 1.4890820980072021
Validation loss: 2.1801258524258933

Epoch: 5| Step: 6
Training loss: 1.6492202281951904
Validation loss: 2.17613277832667

Epoch: 5| Step: 7
Training loss: 1.8965442180633545
Validation loss: 2.2220883071422577

Epoch: 5| Step: 8
Training loss: 2.080848217010498
Validation loss: 2.2674857874711356

Epoch: 5| Step: 9
Training loss: 1.7625083923339844
Validation loss: 2.234790802001953

Epoch: 5| Step: 10
Training loss: 1.218489408493042
Validation loss: 2.2628475228945413

Epoch: 5| Step: 11
Training loss: 1.979130506515503
Validation loss: 2.2662651439507804

Epoch: 259| Step: 0
Training loss: 1.1793290376663208
Validation loss: 2.2718781183163324

Epoch: 5| Step: 1
Training loss: 1.84235417842865
Validation loss: 2.246912181377411

Epoch: 5| Step: 2
Training loss: 1.571394443511963
Validation loss: 2.223430554072062

Epoch: 5| Step: 3
Training loss: 1.7277809381484985
Validation loss: 2.2005758782227836

Epoch: 5| Step: 4
Training loss: 1.74440598487854
Validation loss: 2.183319812019666

Epoch: 5| Step: 5
Training loss: 2.144690990447998
Validation loss: 2.157558480898539

Epoch: 5| Step: 6
Training loss: 1.5697892904281616
Validation loss: 2.1731879512468972

Epoch: 5| Step: 7
Training loss: 1.376214623451233
Validation loss: 2.15772807598114

Epoch: 5| Step: 8
Training loss: 2.1565775871276855
Validation loss: 2.1637461284796395

Epoch: 5| Step: 9
Training loss: 2.328047037124634
Validation loss: 2.1967889169851937

Epoch: 5| Step: 10
Training loss: 1.6061092615127563
Validation loss: 2.2201874057451882

Epoch: 5| Step: 11
Training loss: 2.4221880435943604
Validation loss: 2.2214655528465905

Epoch: 260| Step: 0
Training loss: 1.1768341064453125
Validation loss: 2.242943450808525

Epoch: 5| Step: 1
Training loss: 1.2587835788726807
Validation loss: 2.2669860323270163

Epoch: 5| Step: 2
Training loss: 1.7965898513793945
Validation loss: 2.2375184694925943

Epoch: 5| Step: 3
Training loss: 2.089210271835327
Validation loss: 2.254512697458267

Epoch: 5| Step: 4
Training loss: 2.9034454822540283
Validation loss: 2.2255883117516837

Epoch: 5| Step: 5
Training loss: 1.7380192279815674
Validation loss: 2.245126058657964

Epoch: 5| Step: 6
Training loss: 1.738229751586914
Validation loss: 2.2383717795213065

Epoch: 5| Step: 7
Training loss: 2.173555612564087
Validation loss: 2.2203438381354013

Epoch: 5| Step: 8
Training loss: 1.5553169250488281
Validation loss: 2.2112123171488443

Epoch: 5| Step: 9
Training loss: 1.0974047183990479
Validation loss: 2.2162630458672843

Epoch: 5| Step: 10
Training loss: 1.4810887575149536
Validation loss: 2.2030217250188193

Epoch: 5| Step: 11
Training loss: 2.4600319862365723
Validation loss: 2.2138026853402457

Epoch: 261| Step: 0
Training loss: 1.2340991497039795
Validation loss: 2.218528394897779

Epoch: 5| Step: 1
Training loss: 2.0024819374084473
Validation loss: 2.197320908308029

Epoch: 5| Step: 2
Training loss: 1.425002932548523
Validation loss: 2.2334661930799484

Epoch: 5| Step: 3
Training loss: 2.53029727935791
Validation loss: 2.256932556629181

Epoch: 5| Step: 4
Training loss: 1.9702527523040771
Validation loss: 2.272500062982241

Epoch: 5| Step: 5
Training loss: 2.064180850982666
Validation loss: 2.2804508407910666

Epoch: 5| Step: 6
Training loss: 1.5997239351272583
Validation loss: 2.272726833820343

Epoch: 5| Step: 7
Training loss: 1.9401447772979736
Validation loss: 2.277262881398201

Epoch: 5| Step: 8
Training loss: 1.5954638719558716
Validation loss: 2.260301207502683

Epoch: 5| Step: 9
Training loss: 1.4559680223464966
Validation loss: 2.252566864093145

Epoch: 5| Step: 10
Training loss: 1.3387619256973267
Validation loss: 2.242275059223175

Epoch: 5| Step: 11
Training loss: 2.082672119140625
Validation loss: 2.2338744898637137

Epoch: 262| Step: 0
Training loss: 1.7160383462905884
Validation loss: 2.222340404987335

Epoch: 5| Step: 1
Training loss: 1.6050236225128174
Validation loss: 2.2461342215538025

Epoch: 5| Step: 2
Training loss: 2.0529353618621826
Validation loss: 2.223443776369095

Epoch: 5| Step: 3
Training loss: 1.9124329090118408
Validation loss: 2.2531245152155557

Epoch: 5| Step: 4
Training loss: 1.535631775856018
Validation loss: 2.2801112880309424

Epoch: 5| Step: 5
Training loss: 1.5049984455108643
Validation loss: 2.2685448924700418

Epoch: 5| Step: 6
Training loss: 1.9794782400131226
Validation loss: 2.2731517453988395

Epoch: 5| Step: 7
Training loss: 1.4436919689178467
Validation loss: 2.2909656167030334

Epoch: 5| Step: 8
Training loss: 1.3186233043670654
Validation loss: 2.283097207546234

Epoch: 5| Step: 9
Training loss: 2.0298871994018555
Validation loss: 2.32831409573555

Epoch: 5| Step: 10
Training loss: 1.9175760746002197
Validation loss: 2.316171318292618

Epoch: 5| Step: 11
Training loss: 1.9085437059402466
Validation loss: 2.320921391248703

Epoch: 263| Step: 0
Training loss: 2.0240745544433594
Validation loss: 2.3070303052663803

Epoch: 5| Step: 1
Training loss: 1.3603079319000244
Validation loss: 2.268173406521479

Epoch: 5| Step: 2
Training loss: 1.3849915266036987
Validation loss: 2.229438970486323

Epoch: 5| Step: 3
Training loss: 1.5156283378601074
Validation loss: 2.2064775228500366

Epoch: 5| Step: 4
Training loss: 1.9939253330230713
Validation loss: 2.1997266858816147

Epoch: 5| Step: 5
Training loss: 2.1002869606018066
Validation loss: 2.1839142193396888

Epoch: 5| Step: 6
Training loss: 1.979353666305542
Validation loss: 2.207704837123553

Epoch: 5| Step: 7
Training loss: 1.9862903356552124
Validation loss: 2.2391588588555655

Epoch: 5| Step: 8
Training loss: 1.625001311302185
Validation loss: 2.256918410460154

Epoch: 5| Step: 9
Training loss: 1.5548851490020752
Validation loss: 2.2615446945031485

Epoch: 5| Step: 10
Training loss: 1.8053467273712158
Validation loss: 2.2495166758696237

Epoch: 5| Step: 11
Training loss: 1.0195069313049316
Validation loss: 2.2708280434211097

Epoch: 264| Step: 0
Training loss: 1.3971062898635864
Validation loss: 2.304553513725599

Epoch: 5| Step: 1
Training loss: 1.5344407558441162
Validation loss: 2.289449100693067

Epoch: 5| Step: 2
Training loss: 1.706451177597046
Validation loss: 2.2632915874322257

Epoch: 5| Step: 3
Training loss: 2.7122809886932373
Validation loss: 2.2950633615255356

Epoch: 5| Step: 4
Training loss: 1.5281364917755127
Validation loss: 2.259840726852417

Epoch: 5| Step: 5
Training loss: 1.5710872411727905
Validation loss: 2.2392743875583014

Epoch: 5| Step: 6
Training loss: 1.6258509159088135
Validation loss: 2.2157703886429467

Epoch: 5| Step: 7
Training loss: 1.750108003616333
Validation loss: 2.1802424639463425

Epoch: 5| Step: 8
Training loss: 1.9025943279266357
Validation loss: 2.1763900816440582

Epoch: 5| Step: 9
Training loss: 1.897027611732483
Validation loss: 2.1726433585087457

Epoch: 5| Step: 10
Training loss: 1.4982802867889404
Validation loss: 2.1745275954405465

Epoch: 5| Step: 11
Training loss: 1.1876099109649658
Validation loss: 2.179460197687149

Epoch: 265| Step: 0
Training loss: 2.165109157562256
Validation loss: 2.1945460389057794

Epoch: 5| Step: 1
Training loss: 1.5041528940200806
Validation loss: 2.206843306620916

Epoch: 5| Step: 2
Training loss: 1.5979783535003662
Validation loss: 2.2082886894543967

Epoch: 5| Step: 3
Training loss: 1.5316303968429565
Validation loss: 2.2248755246400833

Epoch: 5| Step: 4
Training loss: 1.3194016218185425
Validation loss: 2.2489378352959952

Epoch: 5| Step: 5
Training loss: 1.5450143814086914
Validation loss: 2.259609361489614

Epoch: 5| Step: 6
Training loss: 2.4354403018951416
Validation loss: 2.2575509746869407

Epoch: 5| Step: 7
Training loss: 1.9731298685073853
Validation loss: 2.232220937808355

Epoch: 5| Step: 8
Training loss: 2.0734169483184814
Validation loss: 2.2467729250590005

Epoch: 5| Step: 9
Training loss: 1.832707405090332
Validation loss: 2.2112002770105996

Epoch: 5| Step: 10
Training loss: 1.7296130657196045
Validation loss: 2.2092443903287253

Epoch: 5| Step: 11
Training loss: 1.0284559726715088
Validation loss: 2.19346292813619

Epoch: 266| Step: 0
Training loss: 1.3856855630874634
Validation loss: 2.214965268969536

Epoch: 5| Step: 1
Training loss: 2.4632468223571777
Validation loss: 2.1724890967210135

Epoch: 5| Step: 2
Training loss: 1.230202555656433
Validation loss: 2.19151064256827

Epoch: 5| Step: 3
Training loss: 1.1019538640975952
Validation loss: 2.1918422083059945

Epoch: 5| Step: 4
Training loss: 1.9745502471923828
Validation loss: 2.2060256550709405

Epoch: 5| Step: 5
Training loss: 1.7801802158355713
Validation loss: 2.209583893418312

Epoch: 5| Step: 6
Training loss: 1.772243857383728
Validation loss: 2.221059317390124

Epoch: 5| Step: 7
Training loss: 2.140519142150879
Validation loss: 2.212097644805908

Epoch: 5| Step: 8
Training loss: 1.5714246034622192
Validation loss: 2.248833030462265

Epoch: 5| Step: 9
Training loss: 1.8484899997711182
Validation loss: 2.275253360470136

Epoch: 5| Step: 10
Training loss: 1.5807465314865112
Validation loss: 2.2809908290704093

Epoch: 5| Step: 11
Training loss: 1.6370866298675537
Validation loss: 2.26725601653258

Epoch: 267| Step: 0
Training loss: 1.4332364797592163
Validation loss: 2.2836086601018906

Epoch: 5| Step: 1
Training loss: 1.5426599979400635
Validation loss: 2.3031107584635415

Epoch: 5| Step: 2
Training loss: 1.5689786672592163
Validation loss: 2.279660498102506

Epoch: 5| Step: 3
Training loss: 1.9330112934112549
Validation loss: 2.257277558247248

Epoch: 5| Step: 4
Training loss: 2.490333080291748
Validation loss: 2.2229793469111123

Epoch: 5| Step: 5
Training loss: 1.6980876922607422
Validation loss: 2.188422739505768

Epoch: 5| Step: 6
Training loss: 2.0388267040252686
Validation loss: 2.16746257742246

Epoch: 5| Step: 7
Training loss: 1.3299719095230103
Validation loss: 2.1623504807551703

Epoch: 5| Step: 8
Training loss: 1.8205331563949585
Validation loss: 2.1589574366807938

Epoch: 5| Step: 9
Training loss: 1.5987788438796997
Validation loss: 2.157639965415001

Epoch: 5| Step: 10
Training loss: 1.843213677406311
Validation loss: 2.149945840239525

Epoch: 5| Step: 11
Training loss: 2.666393280029297
Validation loss: 2.173742721478144

Epoch: 268| Step: 0
Training loss: 2.5867159366607666
Validation loss: 2.174424315492312

Epoch: 5| Step: 1
Training loss: 1.6964969635009766
Validation loss: 2.1777816911538443

Epoch: 5| Step: 2
Training loss: 1.9913740158081055
Validation loss: 2.1921162456274033

Epoch: 5| Step: 3
Training loss: 1.357601523399353
Validation loss: 2.226991504430771

Epoch: 5| Step: 4
Training loss: 1.957535743713379
Validation loss: 2.229442318280538

Epoch: 5| Step: 5
Training loss: 1.110819697380066
Validation loss: 2.2147271633148193

Epoch: 5| Step: 6
Training loss: 1.3894555568695068
Validation loss: 2.207754204670588

Epoch: 5| Step: 7
Training loss: 1.5206701755523682
Validation loss: 2.2339109083016715

Epoch: 5| Step: 8
Training loss: 2.1556315422058105
Validation loss: 2.2370606561501822

Epoch: 5| Step: 9
Training loss: 1.8767999410629272
Validation loss: 2.2672649323940277

Epoch: 5| Step: 10
Training loss: 1.1517177820205688
Validation loss: 2.261373003323873

Epoch: 5| Step: 11
Training loss: 1.3721438646316528
Validation loss: 2.2704563041528067

Epoch: 269| Step: 0
Training loss: 1.564957857131958
Validation loss: 2.2541772921880088

Epoch: 5| Step: 1
Training loss: 1.7264842987060547
Validation loss: 2.292432760198911

Epoch: 5| Step: 2
Training loss: 1.5157052278518677
Validation loss: 2.2856719146172204

Epoch: 5| Step: 3
Training loss: 1.3594976663589478
Validation loss: 2.300659308830897

Epoch: 5| Step: 4
Training loss: 1.8739500045776367
Validation loss: 2.291832685470581

Epoch: 5| Step: 5
Training loss: 1.6936012506484985
Validation loss: 2.3158757785956063

Epoch: 5| Step: 6
Training loss: 2.0544583797454834
Validation loss: 2.309268370270729

Epoch: 5| Step: 7
Training loss: 1.3813245296478271
Validation loss: 2.2953848391771317

Epoch: 5| Step: 8
Training loss: 2.1903183460235596
Validation loss: 2.282651662826538

Epoch: 5| Step: 9
Training loss: 1.7222001552581787
Validation loss: 2.269453763961792

Epoch: 5| Step: 10
Training loss: 1.682570219039917
Validation loss: 2.2888692915439606

Epoch: 5| Step: 11
Training loss: 2.0910096168518066
Validation loss: 2.260402873158455

Epoch: 270| Step: 0
Training loss: 2.1330604553222656
Validation loss: 2.251882125933965

Epoch: 5| Step: 1
Training loss: 2.359395980834961
Validation loss: 2.227723757425944

Epoch: 5| Step: 2
Training loss: 1.4300974607467651
Validation loss: 2.2138156642516456

Epoch: 5| Step: 3
Training loss: 1.3675400018692017
Validation loss: 2.2055080085992813

Epoch: 5| Step: 4
Training loss: 1.3644652366638184
Validation loss: 2.1901244620482125

Epoch: 5| Step: 5
Training loss: 1.1894099712371826
Validation loss: 2.1928648253281913

Epoch: 5| Step: 6
Training loss: 1.7523075342178345
Validation loss: 2.1925756434599557

Epoch: 5| Step: 7
Training loss: 1.9015493392944336
Validation loss: 2.178588425119718

Epoch: 5| Step: 8
Training loss: 1.8114540576934814
Validation loss: 2.177827556927999

Epoch: 5| Step: 9
Training loss: 1.8817417621612549
Validation loss: 2.199918737014135

Epoch: 5| Step: 10
Training loss: 1.5200235843658447
Validation loss: 2.1928277214368186

Epoch: 5| Step: 11
Training loss: 2.5746254920959473
Validation loss: 2.2239968180656433

Epoch: 271| Step: 0
Training loss: 1.784067153930664
Validation loss: 2.1969550947348275

Epoch: 5| Step: 1
Training loss: 1.489026665687561
Validation loss: 2.2332574675480523

Epoch: 5| Step: 2
Training loss: 2.082111120223999
Validation loss: 2.2135184506575265

Epoch: 5| Step: 3
Training loss: 1.3874406814575195
Validation loss: 2.2161067028840384

Epoch: 5| Step: 4
Training loss: 0.8265436291694641
Validation loss: 2.2112820744514465

Epoch: 5| Step: 5
Training loss: 1.6469690799713135
Validation loss: 2.24444746474425

Epoch: 5| Step: 6
Training loss: 1.5717689990997314
Validation loss: 2.2441002478202186

Epoch: 5| Step: 7
Training loss: 1.6798893213272095
Validation loss: 2.223947763442993

Epoch: 5| Step: 8
Training loss: 1.76150643825531
Validation loss: 2.1994528422753015

Epoch: 5| Step: 9
Training loss: 2.3837978839874268
Validation loss: 2.181985209385554

Epoch: 5| Step: 10
Training loss: 2.2066574096679688
Validation loss: 2.164156993230184

Epoch: 5| Step: 11
Training loss: 2.3883371353149414
Validation loss: 2.198675016562144

Epoch: 272| Step: 0
Training loss: 1.2560598850250244
Validation loss: 2.208276321490606

Epoch: 5| Step: 1
Training loss: 1.2425296306610107
Validation loss: 2.2387264470259347

Epoch: 5| Step: 2
Training loss: 1.3626432418823242
Validation loss: 2.244390547275543

Epoch: 5| Step: 3
Training loss: 1.6686744689941406
Validation loss: 2.2469035585721335

Epoch: 5| Step: 4
Training loss: 1.7532333135604858
Validation loss: 2.298051118850708

Epoch: 5| Step: 5
Training loss: 2.105440616607666
Validation loss: 2.2805827111005783

Epoch: 5| Step: 6
Training loss: 1.3460215330123901
Validation loss: 2.2564755578835807

Epoch: 5| Step: 7
Training loss: 2.166410207748413
Validation loss: 2.2589388688405356

Epoch: 5| Step: 8
Training loss: 2.5869898796081543
Validation loss: 2.2299338777860007

Epoch: 5| Step: 9
Training loss: 1.8903528451919556
Validation loss: 2.240846445163091

Epoch: 5| Step: 10
Training loss: 1.6266483068466187
Validation loss: 2.180050561825434

Epoch: 5| Step: 11
Training loss: 0.8421233892440796
Validation loss: 2.203916291395823

Epoch: 273| Step: 0
Training loss: 1.1652138233184814
Validation loss: 2.2070972422758737

Epoch: 5| Step: 1
Training loss: 1.6116691827774048
Validation loss: 2.220482458670934

Epoch: 5| Step: 2
Training loss: 1.7484004497528076
Validation loss: 2.253783330321312

Epoch: 5| Step: 3
Training loss: 2.371870517730713
Validation loss: 2.246352175871531

Epoch: 5| Step: 4
Training loss: 1.7545833587646484
Validation loss: 2.2321839382251105

Epoch: 5| Step: 5
Training loss: 2.046419858932495
Validation loss: 2.2428948084513345

Epoch: 5| Step: 6
Training loss: 2.4098594188690186
Validation loss: 2.26712374885877

Epoch: 5| Step: 7
Training loss: 1.8710708618164062
Validation loss: 2.265248035391172

Epoch: 5| Step: 8
Training loss: 1.954215407371521
Validation loss: 2.245235169927279

Epoch: 5| Step: 9
Training loss: 1.2736632823944092
Validation loss: 2.210705409447352

Epoch: 5| Step: 10
Training loss: 1.5873894691467285
Validation loss: 2.24703556795915

Epoch: 5| Step: 11
Training loss: 0.9659847617149353
Validation loss: 2.231671636303266

Epoch: 274| Step: 0
Training loss: 1.8199571371078491
Validation loss: 2.2153166631857553

Epoch: 5| Step: 1
Training loss: 1.7987362146377563
Validation loss: 2.1815275798241296

Epoch: 5| Step: 2
Training loss: 1.5785882472991943
Validation loss: 2.1743418922026954

Epoch: 5| Step: 3
Training loss: 1.8136571645736694
Validation loss: 2.1606234858433404

Epoch: 5| Step: 4
Training loss: 2.1423840522766113
Validation loss: 2.1543464263280234

Epoch: 5| Step: 5
Training loss: 2.125633716583252
Validation loss: 2.171694586674372

Epoch: 5| Step: 6
Training loss: 1.261518955230713
Validation loss: 2.1629459857940674

Epoch: 5| Step: 7
Training loss: 1.6944456100463867
Validation loss: 2.2288474341233573

Epoch: 5| Step: 8
Training loss: 1.5282998085021973
Validation loss: 2.250889798005422

Epoch: 5| Step: 9
Training loss: 1.7261327505111694
Validation loss: 2.2879479030768075

Epoch: 5| Step: 10
Training loss: 1.7454601526260376
Validation loss: 2.277549664179484

Epoch: 5| Step: 11
Training loss: 1.5754611492156982
Validation loss: 2.2940744012594223

Epoch: 275| Step: 0
Training loss: 1.9159324169158936
Validation loss: 2.2779805858929953

Epoch: 5| Step: 1
Training loss: 1.9993655681610107
Validation loss: 2.2944582402706146

Epoch: 5| Step: 2
Training loss: 1.3826873302459717
Validation loss: 2.290605624516805

Epoch: 5| Step: 3
Training loss: 2.2907328605651855
Validation loss: 2.278924951950709

Epoch: 5| Step: 4
Training loss: 1.5956496000289917
Validation loss: 2.274765357375145

Epoch: 5| Step: 5
Training loss: 1.2340978384017944
Validation loss: 2.260793765385946

Epoch: 5| Step: 6
Training loss: 1.9127212762832642
Validation loss: 2.253603547811508

Epoch: 5| Step: 7
Training loss: 2.0467734336853027
Validation loss: 2.248716652393341

Epoch: 5| Step: 8
Training loss: 1.3331562280654907
Validation loss: 2.2165993452072144

Epoch: 5| Step: 9
Training loss: 1.6963005065917969
Validation loss: 2.22781632343928

Epoch: 5| Step: 10
Training loss: 1.4001538753509521
Validation loss: 2.238113686442375

Epoch: 5| Step: 11
Training loss: 0.6714316606521606
Validation loss: 2.259601136048635

Epoch: 276| Step: 0
Training loss: 1.8209959268569946
Validation loss: 2.2462379237016044

Epoch: 5| Step: 1
Training loss: 1.3687118291854858
Validation loss: 2.2097579340140023

Epoch: 5| Step: 2
Training loss: 2.027111053466797
Validation loss: 2.2389929592609406

Epoch: 5| Step: 3
Training loss: 1.574228286743164
Validation loss: 2.2195305873950324

Epoch: 5| Step: 4
Training loss: 1.861821174621582
Validation loss: 2.2216029266516366

Epoch: 5| Step: 5
Training loss: 1.5057859420776367
Validation loss: 2.229780728618304

Epoch: 5| Step: 6
Training loss: 2.4299476146698
Validation loss: 2.2511816769838333

Epoch: 5| Step: 7
Training loss: 1.3658592700958252
Validation loss: 2.234995126724243

Epoch: 5| Step: 8
Training loss: 1.7298072576522827
Validation loss: 2.243534321586291

Epoch: 5| Step: 9
Training loss: 1.261245608329773
Validation loss: 2.249065190553665

Epoch: 5| Step: 10
Training loss: 1.496725082397461
Validation loss: 2.28050505121549

Epoch: 5| Step: 11
Training loss: 1.2449766397476196
Validation loss: 2.278884698947271

Epoch: 277| Step: 0
Training loss: 1.0904805660247803
Validation loss: 2.2405807276566825

Epoch: 5| Step: 1
Training loss: 1.857693076133728
Validation loss: 2.20500976840655

Epoch: 5| Step: 2
Training loss: 1.4364404678344727
Validation loss: 2.1885818243026733

Epoch: 5| Step: 3
Training loss: 2.194084644317627
Validation loss: 2.169221724073092

Epoch: 5| Step: 4
Training loss: 2.010021686553955
Validation loss: 2.190946395198504

Epoch: 5| Step: 5
Training loss: 1.2886415719985962
Validation loss: 2.1726806610822678

Epoch: 5| Step: 6
Training loss: 1.9200992584228516
Validation loss: 2.229270577430725

Epoch: 5| Step: 7
Training loss: 1.1649115085601807
Validation loss: 2.2468075255552926

Epoch: 5| Step: 8
Training loss: 2.0397887229919434
Validation loss: 2.238542214035988

Epoch: 5| Step: 9
Training loss: 1.5173474550247192
Validation loss: 2.2684033811092377

Epoch: 5| Step: 10
Training loss: 1.869956374168396
Validation loss: 2.2775408824284873

Epoch: 5| Step: 11
Training loss: 2.6715760231018066
Validation loss: 2.2896432280540466

Epoch: 278| Step: 0
Training loss: 1.4848363399505615
Validation loss: 2.3045497089624405

Epoch: 5| Step: 1
Training loss: 2.4900293350219727
Validation loss: 2.3258814960718155

Epoch: 5| Step: 2
Training loss: 1.7008898258209229
Validation loss: 2.306337277094523

Epoch: 5| Step: 3
Training loss: 1.8611230850219727
Validation loss: 2.3053251455227532

Epoch: 5| Step: 4
Training loss: 1.434795618057251
Validation loss: 2.3409596582253775

Epoch: 5| Step: 5
Training loss: 1.772351622581482
Validation loss: 2.3103099366029105

Epoch: 5| Step: 6
Training loss: 1.6269203424453735
Validation loss: 2.3148275961478553

Epoch: 5| Step: 7
Training loss: 2.5810978412628174
Validation loss: 2.279833436012268

Epoch: 5| Step: 8
Training loss: 1.5856778621673584
Validation loss: 2.2744761208693185

Epoch: 5| Step: 9
Training loss: 1.6630691289901733
Validation loss: 2.2479667166868844

Epoch: 5| Step: 10
Training loss: 1.3096001148223877
Validation loss: 2.2524976829687753

Epoch: 5| Step: 11
Training loss: 1.3491628170013428
Validation loss: 2.2254960536956787

Epoch: 279| Step: 0
Training loss: 2.0218665599823
Validation loss: 2.1913638760646186

Epoch: 5| Step: 1
Training loss: 1.7314317226409912
Validation loss: 2.2022765080134072

Epoch: 5| Step: 2
Training loss: 1.9761139154434204
Validation loss: 2.1712959905465445

Epoch: 5| Step: 3
Training loss: 1.6358219385147095
Validation loss: 2.185569107532501

Epoch: 5| Step: 4
Training loss: 1.595139741897583
Validation loss: 2.1821380257606506

Epoch: 5| Step: 5
Training loss: 1.5227787494659424
Validation loss: 2.181165819366773

Epoch: 5| Step: 6
Training loss: 2.123549699783325
Validation loss: 2.213737870256106

Epoch: 5| Step: 7
Training loss: 1.763920545578003
Validation loss: 2.2232921520868936

Epoch: 5| Step: 8
Training loss: 1.6610723733901978
Validation loss: 2.2432424128055573

Epoch: 5| Step: 9
Training loss: 1.5919709205627441
Validation loss: 2.2353423138459525

Epoch: 5| Step: 10
Training loss: 2.170928478240967
Validation loss: 2.268922597169876

Epoch: 5| Step: 11
Training loss: 1.8377543687820435
Validation loss: 2.2947452316681543

Epoch: 280| Step: 0
Training loss: 2.240586280822754
Validation loss: 2.3219129045804343

Epoch: 5| Step: 1
Training loss: 1.416663646697998
Validation loss: 2.3050814966360726

Epoch: 5| Step: 2
Training loss: 1.1756316423416138
Validation loss: 2.3076671361923218

Epoch: 5| Step: 3
Training loss: 1.82830011844635
Validation loss: 2.310622677206993

Epoch: 5| Step: 4
Training loss: 2.1501986980438232
Validation loss: 2.3073631624380746

Epoch: 5| Step: 5
Training loss: 2.207979440689087
Validation loss: 2.2726765175660453

Epoch: 5| Step: 6
Training loss: 1.164914608001709
Validation loss: 2.257720718781153

Epoch: 5| Step: 7
Training loss: 1.6910167932510376
Validation loss: 2.2648878693580627

Epoch: 5| Step: 8
Training loss: 1.9113517999649048
Validation loss: 2.2081143856048584

Epoch: 5| Step: 9
Training loss: 1.761268973350525
Validation loss: 2.1833784580230713

Epoch: 5| Step: 10
Training loss: 0.9620911478996277
Validation loss: 2.2041383733352027

Epoch: 5| Step: 11
Training loss: 0.9265871644020081
Validation loss: 2.208208844065666

Epoch: 281| Step: 0
Training loss: 1.7888545989990234
Validation loss: 2.189357101917267

Epoch: 5| Step: 1
Training loss: 2.0462284088134766
Validation loss: 2.203604608774185

Epoch: 5| Step: 2
Training loss: 1.20131516456604
Validation loss: 2.171658386786779

Epoch: 5| Step: 3
Training loss: 1.6440330743789673
Validation loss: 2.172999953230222

Epoch: 5| Step: 4
Training loss: 1.5980732440948486
Validation loss: 2.1478227376937866

Epoch: 5| Step: 5
Training loss: 1.7660671472549438
Validation loss: 2.209692120552063

Epoch: 5| Step: 6
Training loss: 1.1744145154953003
Validation loss: 2.2060681035121283

Epoch: 5| Step: 7
Training loss: 1.8802547454833984
Validation loss: 2.2471400250991187

Epoch: 5| Step: 8
Training loss: 1.8872268199920654
Validation loss: 2.284939924875895

Epoch: 5| Step: 9
Training loss: 1.8199243545532227
Validation loss: 2.3293791810671487

Epoch: 5| Step: 10
Training loss: 1.84365713596344
Validation loss: 2.317269509037336

Epoch: 5| Step: 11
Training loss: 1.5229138135910034
Validation loss: 2.321889171997706

Epoch: 282| Step: 0
Training loss: 2.308961868286133
Validation loss: 2.3143527507781982

Epoch: 5| Step: 1
Training loss: 2.216188430786133
Validation loss: 2.36246857047081

Epoch: 5| Step: 2
Training loss: 2.261563777923584
Validation loss: 2.36010080575943

Epoch: 5| Step: 3
Training loss: 2.65631103515625
Validation loss: 2.3519945442676544

Epoch: 5| Step: 4
Training loss: 1.7761094570159912
Validation loss: 2.347649941841761

Epoch: 5| Step: 5
Training loss: 1.589447021484375
Validation loss: 2.303632582227389

Epoch: 5| Step: 6
Training loss: 1.4785805940628052
Validation loss: 2.300719211498896

Epoch: 5| Step: 7
Training loss: 1.6641285419464111
Validation loss: 2.2994294116894403

Epoch: 5| Step: 8
Training loss: 0.9968484044075012
Validation loss: 2.2076746126015983

Epoch: 5| Step: 9
Training loss: 2.1352944374084473
Validation loss: 2.227376783887545

Epoch: 5| Step: 10
Training loss: 1.6341850757598877
Validation loss: 2.2170648872852325

Epoch: 5| Step: 11
Training loss: 1.1912955045700073
Validation loss: 2.2147882729768753

Epoch: 283| Step: 0
Training loss: 1.1902728080749512
Validation loss: 2.179376562436422

Epoch: 5| Step: 1
Training loss: 1.796542763710022
Validation loss: 2.1768904328346252

Epoch: 5| Step: 2
Training loss: 2.1846694946289062
Validation loss: 2.164449875553449

Epoch: 5| Step: 3
Training loss: 2.106506109237671
Validation loss: 2.1608229329188666

Epoch: 5| Step: 4
Training loss: 1.741655707359314
Validation loss: 2.157261644800504

Epoch: 5| Step: 5
Training loss: 1.589252233505249
Validation loss: 2.175969898700714

Epoch: 5| Step: 6
Training loss: 2.0797364711761475
Validation loss: 2.1804040670394897

Epoch: 5| Step: 7
Training loss: 1.9900089502334595
Validation loss: 2.19037518898646

Epoch: 5| Step: 8
Training loss: 1.235762119293213
Validation loss: 2.228138655424118

Epoch: 5| Step: 9
Training loss: 1.345542311668396
Validation loss: 2.2527965356906257

Epoch: 5| Step: 10
Training loss: 1.7300888299942017
Validation loss: 2.2667265037695565

Epoch: 5| Step: 11
Training loss: 0.8954058885574341
Validation loss: 2.2942804296811423

Epoch: 284| Step: 0
Training loss: 2.049757480621338
Validation loss: 2.2962425549825034

Epoch: 5| Step: 1
Training loss: 1.7694202661514282
Validation loss: 2.33719339966774

Epoch: 5| Step: 2
Training loss: 1.8282496929168701
Validation loss: 2.276387800772985

Epoch: 5| Step: 3
Training loss: 1.6139990091323853
Validation loss: 2.287316163380941

Epoch: 5| Step: 4
Training loss: 1.4793659448623657
Validation loss: 2.280636856953303

Epoch: 5| Step: 5
Training loss: 1.5965946912765503
Validation loss: 2.3117151657740274

Epoch: 5| Step: 6
Training loss: 1.9318592548370361
Validation loss: 2.2959550817807517

Epoch: 5| Step: 7
Training loss: 1.480089783668518
Validation loss: 2.2659257849057517

Epoch: 5| Step: 8
Training loss: 2.401864767074585
Validation loss: 2.243422960241636

Epoch: 5| Step: 9
Training loss: 1.7814586162567139
Validation loss: 2.2440364013115564

Epoch: 5| Step: 10
Training loss: 1.5066412687301636
Validation loss: 2.232329120238622

Epoch: 5| Step: 11
Training loss: 1.1961075067520142
Validation loss: 2.23406583070755

Epoch: 285| Step: 0
Training loss: 1.2604821920394897
Validation loss: 2.243226041396459

Epoch: 5| Step: 1
Training loss: 2.0221028327941895
Validation loss: 2.2594765524069467

Epoch: 5| Step: 2
Training loss: 1.4042326211929321
Validation loss: 2.2463618566592536

Epoch: 5| Step: 3
Training loss: 2.2142276763916016
Validation loss: 2.277880698442459

Epoch: 5| Step: 4
Training loss: 1.347383737564087
Validation loss: 2.258692671855291

Epoch: 5| Step: 5
Training loss: 2.0768818855285645
Validation loss: 2.261516824364662

Epoch: 5| Step: 6
Training loss: 2.04231595993042
Validation loss: 2.2285195092360177

Epoch: 5| Step: 7
Training loss: 1.3270944356918335
Validation loss: 2.224194477001826

Epoch: 5| Step: 8
Training loss: 1.4206664562225342
Validation loss: 2.2180841863155365

Epoch: 5| Step: 9
Training loss: 1.8160839080810547
Validation loss: 2.240562597910563

Epoch: 5| Step: 10
Training loss: 1.2784278392791748
Validation loss: 2.24259452521801

Epoch: 5| Step: 11
Training loss: 2.464742660522461
Validation loss: 2.224808176358541

Epoch: 286| Step: 0
Training loss: 1.4894657135009766
Validation loss: 2.2614575574795404

Epoch: 5| Step: 1
Training loss: 1.2607791423797607
Validation loss: 2.25064854323864

Epoch: 5| Step: 2
Training loss: 1.8027547597885132
Validation loss: 2.248531704147657

Epoch: 5| Step: 3
Training loss: 0.941730797290802
Validation loss: 2.264528974890709

Epoch: 5| Step: 4
Training loss: 1.0704036951065063
Validation loss: 2.272971342007319

Epoch: 5| Step: 5
Training loss: 1.4851958751678467
Validation loss: 2.2749410221974053

Epoch: 5| Step: 6
Training loss: 1.6939592361450195
Validation loss: 2.2316860208908715

Epoch: 5| Step: 7
Training loss: 1.8270190954208374
Validation loss: 2.2494322707255683

Epoch: 5| Step: 8
Training loss: 2.2738900184631348
Validation loss: 2.248422235250473

Epoch: 5| Step: 9
Training loss: 2.052044153213501
Validation loss: 2.2371320029099784

Epoch: 5| Step: 10
Training loss: 1.8817031383514404
Validation loss: 2.230160097281138

Epoch: 5| Step: 11
Training loss: 2.9131438732147217
Validation loss: 2.2418563961982727

Epoch: 287| Step: 0
Training loss: 1.1947275400161743
Validation loss: 2.2533359775940576

Epoch: 5| Step: 1
Training loss: 1.6978718042373657
Validation loss: 2.266781523823738

Epoch: 5| Step: 2
Training loss: 1.1266196966171265
Validation loss: 2.2292497952779136

Epoch: 5| Step: 3
Training loss: 2.4268693923950195
Validation loss: 2.254707410931587

Epoch: 5| Step: 4
Training loss: 1.5051462650299072
Validation loss: 2.232572535673777

Epoch: 5| Step: 5
Training loss: 1.5225803852081299
Validation loss: 2.2497574786345163

Epoch: 5| Step: 6
Training loss: 1.9556159973144531
Validation loss: 2.252266585826874

Epoch: 5| Step: 7
Training loss: 2.166532039642334
Validation loss: 2.2768981655438743

Epoch: 5| Step: 8
Training loss: 1.473739743232727
Validation loss: 2.2366024206082025

Epoch: 5| Step: 9
Training loss: 1.3326964378356934
Validation loss: 2.223696564634641

Epoch: 5| Step: 10
Training loss: 1.8993946313858032
Validation loss: 2.2210493832826614

Epoch: 5| Step: 11
Training loss: 0.558994710445404
Validation loss: 2.2240954289833703

Epoch: 288| Step: 0
Training loss: 1.3715870380401611
Validation loss: 2.247906059026718

Epoch: 5| Step: 1
Training loss: 1.8322923183441162
Validation loss: 2.202133963505427

Epoch: 5| Step: 2
Training loss: 1.3733751773834229
Validation loss: 2.2266912261644998

Epoch: 5| Step: 3
Training loss: 1.5194817781448364
Validation loss: 2.222233513991038

Epoch: 5| Step: 4
Training loss: 1.5186197757720947
Validation loss: 2.1842923015356064

Epoch: 5| Step: 5
Training loss: 2.186398983001709
Validation loss: 2.1629206190506616

Epoch: 5| Step: 6
Training loss: 1.6453473567962646
Validation loss: 2.165230835477511

Epoch: 5| Step: 7
Training loss: 1.392257809638977
Validation loss: 2.1866766015688577

Epoch: 5| Step: 8
Training loss: 1.6447118520736694
Validation loss: 2.1934019972880683

Epoch: 5| Step: 9
Training loss: 1.511692762374878
Validation loss: 2.209966396292051

Epoch: 5| Step: 10
Training loss: 2.618083953857422
Validation loss: 2.225151111682256

Epoch: 5| Step: 11
Training loss: 1.4236141443252563
Validation loss: 2.28017595410347

Epoch: 289| Step: 0
Training loss: 1.9511146545410156
Validation loss: 2.2870964407920837

Epoch: 5| Step: 1
Training loss: 1.4627889394760132
Validation loss: 2.307997465133667

Epoch: 5| Step: 2
Training loss: 1.685312032699585
Validation loss: 2.292122612396876

Epoch: 5| Step: 3
Training loss: 2.0738275051116943
Validation loss: 2.2828571448723474

Epoch: 5| Step: 4
Training loss: 2.00435733795166
Validation loss: 2.2857665022214255

Epoch: 5| Step: 5
Training loss: 1.3499971628189087
Validation loss: 2.275195221106211

Epoch: 5| Step: 6
Training loss: 2.080416440963745
Validation loss: 2.2496071557203927

Epoch: 5| Step: 7
Training loss: 1.2745420932769775
Validation loss: 2.233700384696325

Epoch: 5| Step: 8
Training loss: 1.3939586877822876
Validation loss: 2.238067626953125

Epoch: 5| Step: 9
Training loss: 1.703805923461914
Validation loss: 2.233740637699763

Epoch: 5| Step: 10
Training loss: 1.5284483432769775
Validation loss: 2.2374759117762246

Epoch: 5| Step: 11
Training loss: 1.4079952239990234
Validation loss: 2.195388744274775

Epoch: 290| Step: 0
Training loss: 1.3676199913024902
Validation loss: 2.2199562241633735

Epoch: 5| Step: 1
Training loss: 1.4563401937484741
Validation loss: 2.2105217476685843

Epoch: 5| Step: 2
Training loss: 1.8841251134872437
Validation loss: 2.2247166534264884

Epoch: 5| Step: 3
Training loss: 1.6940780878067017
Validation loss: 2.2149310559034348

Epoch: 5| Step: 4
Training loss: 1.6065967082977295
Validation loss: 2.2253086318572364

Epoch: 5| Step: 5
Training loss: 2.5951626300811768
Validation loss: 2.2351054747899375

Epoch: 5| Step: 6
Training loss: 1.476388931274414
Validation loss: 2.2744877636432648

Epoch: 5| Step: 7
Training loss: 1.6006110906600952
Validation loss: 2.2461163302262626

Epoch: 5| Step: 8
Training loss: 1.5482957363128662
Validation loss: 2.241364061832428

Epoch: 5| Step: 9
Training loss: 1.0403468608856201
Validation loss: 2.26068585117658

Epoch: 5| Step: 10
Training loss: 1.746731162071228
Validation loss: 2.2313239922126136

Epoch: 5| Step: 11
Training loss: 2.13455867767334
Validation loss: 2.2114597956339517

Epoch: 291| Step: 0
Training loss: 1.4343228340148926
Validation loss: 2.2136887460947037

Epoch: 5| Step: 1
Training loss: 1.300353765487671
Validation loss: 2.218641549348831

Epoch: 5| Step: 2
Training loss: 1.2831008434295654
Validation loss: 2.233811895052592

Epoch: 5| Step: 3
Training loss: 1.912813425064087
Validation loss: 2.255569115281105

Epoch: 5| Step: 4
Training loss: 1.3925286531448364
Validation loss: 2.225490480661392

Epoch: 5| Step: 5
Training loss: 1.5416314601898193
Validation loss: 2.2617281874020896

Epoch: 5| Step: 6
Training loss: 1.4956865310668945
Validation loss: 2.234761491417885

Epoch: 5| Step: 7
Training loss: 1.5970534086227417
Validation loss: 2.2478311558564505

Epoch: 5| Step: 8
Training loss: 1.3416998386383057
Validation loss: 2.2498386253913245

Epoch: 5| Step: 9
Training loss: 2.4325523376464844
Validation loss: 2.2406522631645203

Epoch: 5| Step: 10
Training loss: 2.281813144683838
Validation loss: 2.224341779947281

Epoch: 5| Step: 11
Training loss: 1.7522974014282227
Validation loss: 2.220120678345362

Epoch: 292| Step: 0
Training loss: 1.4257539510726929
Validation loss: 2.2664996087551117

Epoch: 5| Step: 1
Training loss: 1.3305987119674683
Validation loss: 2.2524178524812064

Epoch: 5| Step: 2
Training loss: 1.781370759010315
Validation loss: 2.227196584145228

Epoch: 5| Step: 3
Training loss: 1.3591763973236084
Validation loss: 2.232661952575048

Epoch: 5| Step: 4
Training loss: 1.4573659896850586
Validation loss: 2.2383184731006622

Epoch: 5| Step: 5
Training loss: 1.1500552892684937
Validation loss: 2.225494464238485

Epoch: 5| Step: 6
Training loss: 2.5508482456207275
Validation loss: 2.226710855960846

Epoch: 5| Step: 7
Training loss: 1.8839069604873657
Validation loss: 2.1875317295392356

Epoch: 5| Step: 8
Training loss: 1.4890692234039307
Validation loss: 2.209025114774704

Epoch: 5| Step: 9
Training loss: 1.6695737838745117
Validation loss: 2.2048407594362893

Epoch: 5| Step: 10
Training loss: 2.0420355796813965
Validation loss: 2.2097374200820923

Epoch: 5| Step: 11
Training loss: 0.854053258895874
Validation loss: 2.1899261673291526

Epoch: 293| Step: 0
Training loss: 1.7674442529678345
Validation loss: 2.1697330276171365

Epoch: 5| Step: 1
Training loss: 1.3520987033843994
Validation loss: 2.178547198573748

Epoch: 5| Step: 2
Training loss: 1.6699199676513672
Validation loss: 2.189708024263382

Epoch: 5| Step: 3
Training loss: 1.8888332843780518
Validation loss: 2.2107054392496743

Epoch: 5| Step: 4
Training loss: 1.608837366104126
Validation loss: 2.205969452857971

Epoch: 5| Step: 5
Training loss: 2.001250743865967
Validation loss: 2.2238370875517526

Epoch: 5| Step: 6
Training loss: 1.2018204927444458
Validation loss: 2.21142249306043

Epoch: 5| Step: 7
Training loss: 2.1555418968200684
Validation loss: 2.21795987089475

Epoch: 5| Step: 8
Training loss: 1.6637874841690063
Validation loss: 2.241907835006714

Epoch: 5| Step: 9
Training loss: 1.6200344562530518
Validation loss: 2.26430677374204

Epoch: 5| Step: 10
Training loss: 1.2183973789215088
Validation loss: 2.2363200883070626

Epoch: 5| Step: 11
Training loss: 1.0027108192443848
Validation loss: 2.2497945179541907

Epoch: 294| Step: 0
Training loss: 1.2587875127792358
Validation loss: 2.2595721234877906

Epoch: 5| Step: 1
Training loss: 1.1759898662567139
Validation loss: 2.2518573701381683

Epoch: 5| Step: 2
Training loss: 1.8923518657684326
Validation loss: 2.2345246771971383

Epoch: 5| Step: 3
Training loss: 1.7145519256591797
Validation loss: 2.265981763601303

Epoch: 5| Step: 4
Training loss: 1.440940022468567
Validation loss: 2.2393081734577813

Epoch: 5| Step: 5
Training loss: 1.8132526874542236
Validation loss: 2.264965310692787

Epoch: 5| Step: 6
Training loss: 1.0946398973464966
Validation loss: 2.24198388059934

Epoch: 5| Step: 7
Training loss: 1.7369575500488281
Validation loss: 2.273122251033783

Epoch: 5| Step: 8
Training loss: 1.9677793979644775
Validation loss: 2.2351190646489463

Epoch: 5| Step: 9
Training loss: 1.984833002090454
Validation loss: 2.251176337401072

Epoch: 5| Step: 10
Training loss: 1.686754822731018
Validation loss: 2.229778011639913

Epoch: 5| Step: 11
Training loss: 1.8644139766693115
Validation loss: 2.2431611816088357

Epoch: 295| Step: 0
Training loss: 1.7671371698379517
Validation loss: 2.2620783547560372

Epoch: 5| Step: 1
Training loss: 1.5182405710220337
Validation loss: 2.229688917597135

Epoch: 5| Step: 2
Training loss: 1.6113542318344116
Validation loss: 2.2309838235378265

Epoch: 5| Step: 3
Training loss: 1.394747018814087
Validation loss: 2.217177594701449

Epoch: 5| Step: 4
Training loss: 1.5302385091781616
Validation loss: 2.199902872244517

Epoch: 5| Step: 5
Training loss: 1.3301498889923096
Validation loss: 2.209425816933314

Epoch: 5| Step: 6
Training loss: 1.594983458518982
Validation loss: 2.227193067471186

Epoch: 5| Step: 7
Training loss: 1.4544522762298584
Validation loss: 2.243318865696589

Epoch: 5| Step: 8
Training loss: 1.6191476583480835
Validation loss: 2.250251750151316

Epoch: 5| Step: 9
Training loss: 2.1205544471740723
Validation loss: 2.268885682026545

Epoch: 5| Step: 10
Training loss: 2.330172300338745
Validation loss: 2.285356253385544

Epoch: 5| Step: 11
Training loss: 1.4827001094818115
Validation loss: 2.285232295592626

Epoch: 296| Step: 0
Training loss: 1.3783190250396729
Validation loss: 2.244864304860433

Epoch: 5| Step: 1
Training loss: 1.4725759029388428
Validation loss: 2.2698661237955093

Epoch: 5| Step: 2
Training loss: 1.3074462413787842
Validation loss: 2.2602883925040564

Epoch: 5| Step: 3
Training loss: 1.4712120294570923
Validation loss: 2.242739657560984

Epoch: 5| Step: 4
Training loss: 1.6789796352386475
Validation loss: 2.1947164982557297

Epoch: 5| Step: 5
Training loss: 1.654710054397583
Validation loss: 2.1704152673482895

Epoch: 5| Step: 6
Training loss: 1.858384132385254
Validation loss: 2.207899332046509

Epoch: 5| Step: 7
Training loss: 2.2061357498168945
Validation loss: 2.1691496272881827

Epoch: 5| Step: 8
Training loss: 1.6504318714141846
Validation loss: 2.1408279488484063

Epoch: 5| Step: 9
Training loss: 2.1019768714904785
Validation loss: 2.147426724433899

Epoch: 5| Step: 10
Training loss: 1.3436684608459473
Validation loss: 2.171895826856295

Epoch: 5| Step: 11
Training loss: 1.1507648229599
Validation loss: 2.1868863701820374

Epoch: 297| Step: 0
Training loss: 1.4911127090454102
Validation loss: 2.193054844935735

Epoch: 5| Step: 1
Training loss: 1.4421485662460327
Validation loss: 2.226737762490908

Epoch: 5| Step: 2
Training loss: 1.280826449394226
Validation loss: 2.2179606556892395

Epoch: 5| Step: 3
Training loss: 1.8476167917251587
Validation loss: 2.2518649150927863

Epoch: 5| Step: 4
Training loss: 1.765012502670288
Validation loss: 2.2666353285312653

Epoch: 5| Step: 5
Training loss: 1.44491708278656
Validation loss: 2.2550746401151023

Epoch: 5| Step: 6
Training loss: 1.2743076086044312
Validation loss: 2.301610231399536

Epoch: 5| Step: 7
Training loss: 1.5688751935958862
Validation loss: 2.3042371024688086

Epoch: 5| Step: 8
Training loss: 1.5523849725723267
Validation loss: 2.287041043241819

Epoch: 5| Step: 9
Training loss: 2.311511516571045
Validation loss: 2.256878972053528

Epoch: 5| Step: 10
Training loss: 1.7881078720092773
Validation loss: 2.2395641605059304

Epoch: 5| Step: 11
Training loss: 0.8477514982223511
Validation loss: 2.204003324111303

Epoch: 298| Step: 0
Training loss: 1.5791854858398438
Validation loss: 2.215522130330404

Epoch: 5| Step: 1
Training loss: 1.3821901082992554
Validation loss: 2.210511843363444

Epoch: 5| Step: 2
Training loss: 1.6454395055770874
Validation loss: 2.1871620217959085

Epoch: 5| Step: 3
Training loss: 0.9947927594184875
Validation loss: 2.1770584185918174

Epoch: 5| Step: 4
Training loss: 1.6888643503189087
Validation loss: 2.178598384062449

Epoch: 5| Step: 5
Training loss: 1.92952561378479
Validation loss: 2.198847030599912

Epoch: 5| Step: 6
Training loss: 1.9042965173721313
Validation loss: 2.171526168783506

Epoch: 5| Step: 7
Training loss: 1.9880292415618896
Validation loss: 2.2112834105889

Epoch: 5| Step: 8
Training loss: 1.306044101715088
Validation loss: 2.224811092019081

Epoch: 5| Step: 9
Training loss: 1.8547664880752563
Validation loss: 2.2271035263935723

Epoch: 5| Step: 10
Training loss: 1.9706615209579468
Validation loss: 2.2413700272639594

Epoch: 5| Step: 11
Training loss: 0.9744472503662109
Validation loss: 2.258672167857488

Epoch: 299| Step: 0
Training loss: 2.1674909591674805
Validation loss: 2.260120997826258

Epoch: 5| Step: 1
Training loss: 1.9523357152938843
Validation loss: 2.2254247864087424

Epoch: 5| Step: 2
Training loss: 2.3204777240753174
Validation loss: 2.2143136660257974

Epoch: 5| Step: 3
Training loss: 1.384119987487793
Validation loss: 2.188211997350057

Epoch: 5| Step: 4
Training loss: 1.7043895721435547
Validation loss: 2.2061880230903625

Epoch: 5| Step: 5
Training loss: 1.472249150276184
Validation loss: 2.2159013549486795

Epoch: 5| Step: 6
Training loss: 1.0320453643798828
Validation loss: 2.2039873202641806

Epoch: 5| Step: 7
Training loss: 1.4508507251739502
Validation loss: 2.2118063817421594

Epoch: 5| Step: 8
Training loss: 1.6707149744033813
Validation loss: 2.2069539527098336

Epoch: 5| Step: 9
Training loss: 1.6424915790557861
Validation loss: 2.2123706142107644

Epoch: 5| Step: 10
Training loss: 1.229027509689331
Validation loss: 2.1989063074191413

Epoch: 5| Step: 11
Training loss: 1.357379674911499
Validation loss: 2.223802760243416

Epoch: 300| Step: 0
Training loss: 2.068470001220703
Validation loss: 2.235271394252777

Epoch: 5| Step: 1
Training loss: 1.3301165103912354
Validation loss: 2.250568225979805

Epoch: 5| Step: 2
Training loss: 1.6353496313095093
Validation loss: 2.2600914935270944

Epoch: 5| Step: 3
Training loss: 1.3956950902938843
Validation loss: 2.236969530582428

Epoch: 5| Step: 4
Training loss: 1.823028802871704
Validation loss: 2.259846786657969

Epoch: 5| Step: 5
Training loss: 1.9497311115264893
Validation loss: 2.23176276187102

Epoch: 5| Step: 6
Training loss: 1.373201608657837
Validation loss: 2.237384001413981

Epoch: 5| Step: 7
Training loss: 1.6024929285049438
Validation loss: 2.2706863383452096

Epoch: 5| Step: 8
Training loss: 2.0061278343200684
Validation loss: 2.2770911306142807

Epoch: 5| Step: 9
Training loss: 1.2404282093048096
Validation loss: 2.266312062740326

Epoch: 5| Step: 10
Training loss: 1.3457691669464111
Validation loss: 2.268135686715444

Epoch: 5| Step: 11
Training loss: 0.6859629154205322
Validation loss: 2.2511942237615585

Epoch: 301| Step: 0
Training loss: 1.392287015914917
Validation loss: 2.280706783135732

Epoch: 5| Step: 1
Training loss: 1.8487342596054077
Validation loss: 2.300420641899109

Epoch: 5| Step: 2
Training loss: 1.594517707824707
Validation loss: 2.277066876490911

Epoch: 5| Step: 3
Training loss: 1.6235488653182983
Validation loss: 2.2842041750748954

Epoch: 5| Step: 4
Training loss: 1.2607154846191406
Validation loss: 2.2745495438575745

Epoch: 5| Step: 5
Training loss: 1.7830556631088257
Validation loss: 2.273299569884936

Epoch: 5| Step: 6
Training loss: 1.7893520593643188
Validation loss: 2.270439386367798

Epoch: 5| Step: 7
Training loss: 1.8941781520843506
Validation loss: 2.2510207345088324

Epoch: 5| Step: 8
Training loss: 1.7074838876724243
Validation loss: 2.238046189149221

Epoch: 5| Step: 9
Training loss: 1.0531032085418701
Validation loss: 2.2065168420473733

Epoch: 5| Step: 10
Training loss: 1.6595722436904907
Validation loss: 2.2148140221834183

Epoch: 5| Step: 11
Training loss: 0.7332053780555725
Validation loss: 2.2238832215468087

Epoch: 302| Step: 0
Training loss: 1.6334095001220703
Validation loss: 2.2311660846074424

Epoch: 5| Step: 1
Training loss: 1.4207165241241455
Validation loss: 2.221750939885775

Epoch: 5| Step: 2
Training loss: 1.8281543254852295
Validation loss: 2.2363473773002625

Epoch: 5| Step: 3
Training loss: 1.926984429359436
Validation loss: 2.24370875954628

Epoch: 5| Step: 4
Training loss: 1.5677309036254883
Validation loss: 2.213295350472132

Epoch: 5| Step: 5
Training loss: 1.8153812885284424
Validation loss: 2.1780765851338706

Epoch: 5| Step: 6
Training loss: 1.6512105464935303
Validation loss: 2.2028532226880393

Epoch: 5| Step: 7
Training loss: 1.7220914363861084
Validation loss: 2.2102056046326957

Epoch: 5| Step: 8
Training loss: 1.229918122291565
Validation loss: 2.2320427199204764

Epoch: 5| Step: 9
Training loss: 1.4290754795074463
Validation loss: 2.2392929742733636

Epoch: 5| Step: 10
Training loss: 1.415595293045044
Validation loss: 2.263025184472402

Epoch: 5| Step: 11
Training loss: 0.6801936626434326
Validation loss: 2.275985836982727

Epoch: 303| Step: 0
Training loss: 1.8701597452163696
Validation loss: 2.2490328699350357

Epoch: 5| Step: 1
Training loss: 1.784895658493042
Validation loss: 2.20281191666921

Epoch: 5| Step: 2
Training loss: 1.5452171564102173
Validation loss: 2.227405076225599

Epoch: 5| Step: 3
Training loss: 1.09906005859375
Validation loss: 2.2093041092157364

Epoch: 5| Step: 4
Training loss: 2.0111594200134277
Validation loss: 2.188100054860115

Epoch: 5| Step: 5
Training loss: 2.2231459617614746
Validation loss: 2.214143400390943

Epoch: 5| Step: 6
Training loss: 1.4606469869613647
Validation loss: 2.205393890539805

Epoch: 5| Step: 7
Training loss: 1.9633533954620361
Validation loss: 2.2310657699902854

Epoch: 5| Step: 8
Training loss: 1.7944272756576538
Validation loss: 2.2580050826072693

Epoch: 5| Step: 9
Training loss: 1.319324254989624
Validation loss: 2.2472728242476783

Epoch: 5| Step: 10
Training loss: 1.4751068353652954
Validation loss: 2.262477641304334

Epoch: 5| Step: 11
Training loss: 1.2794352769851685
Validation loss: 2.2476721008618674

Epoch: 304| Step: 0
Training loss: 1.9128715991973877
Validation loss: 2.2787056217590966

Epoch: 5| Step: 1
Training loss: 1.8522096872329712
Validation loss: 2.246081843972206

Epoch: 5| Step: 2
Training loss: 1.453951120376587
Validation loss: 2.2600666284561157

Epoch: 5| Step: 3
Training loss: 1.485020399093628
Validation loss: 2.2821229497591653

Epoch: 5| Step: 4
Training loss: 1.0799839496612549
Validation loss: 2.285370111465454

Epoch: 5| Step: 5
Training loss: 1.6733427047729492
Validation loss: 2.2928268015384674

Epoch: 5| Step: 6
Training loss: 2.0466866493225098
Validation loss: 2.276540299256643

Epoch: 5| Step: 7
Training loss: 1.5972931385040283
Validation loss: 2.2118975619475045

Epoch: 5| Step: 8
Training loss: 1.498038649559021
Validation loss: 2.2377599577109017

Epoch: 5| Step: 9
Training loss: 2.0344619750976562
Validation loss: 2.247994234164556

Epoch: 5| Step: 10
Training loss: 1.4887161254882812
Validation loss: 2.2309626092513404

Epoch: 5| Step: 11
Training loss: 0.6198466420173645
Validation loss: 2.2394833862781525

Epoch: 305| Step: 0
Training loss: 1.6702255010604858
Validation loss: 2.2362612187862396

Epoch: 5| Step: 1
Training loss: 1.4064356088638306
Validation loss: 2.2365320126215615

Epoch: 5| Step: 2
Training loss: 1.5441631078720093
Validation loss: 2.184446632862091

Epoch: 5| Step: 3
Training loss: 1.0483983755111694
Validation loss: 2.2039348731438317

Epoch: 5| Step: 4
Training loss: 1.6921249628067017
Validation loss: 2.200847620765368

Epoch: 5| Step: 5
Training loss: 1.302276611328125
Validation loss: 2.206827158729235

Epoch: 5| Step: 6
Training loss: 1.8730636835098267
Validation loss: 2.2129857490460076

Epoch: 5| Step: 7
Training loss: 1.8916256427764893
Validation loss: 2.242427001396815

Epoch: 5| Step: 8
Training loss: 1.7299083471298218
Validation loss: 2.2237786948680878

Epoch: 5| Step: 9
Training loss: 1.960961937904358
Validation loss: 2.220140924056371

Epoch: 5| Step: 10
Training loss: 1.7828190326690674
Validation loss: 2.226202776034673

Epoch: 5| Step: 11
Training loss: 1.1757092475891113
Validation loss: 2.2249718606472015

Epoch: 306| Step: 0
Training loss: 1.4299561977386475
Validation loss: 2.2292125125726066

Epoch: 5| Step: 1
Training loss: 1.6948750019073486
Validation loss: 2.2436001151800156

Epoch: 5| Step: 2
Training loss: 1.7041559219360352
Validation loss: 2.2637372612953186

Epoch: 5| Step: 3
Training loss: 1.7426360845565796
Validation loss: 2.262727568546931

Epoch: 5| Step: 4
Training loss: 1.8226512670516968
Validation loss: 2.243355870246887

Epoch: 5| Step: 5
Training loss: 1.9419782161712646
Validation loss: 2.249477724234263

Epoch: 5| Step: 6
Training loss: 1.5867650508880615
Validation loss: 2.2184055546919503

Epoch: 5| Step: 7
Training loss: 1.5818912982940674
Validation loss: 2.2396975308656693

Epoch: 5| Step: 8
Training loss: 1.5324609279632568
Validation loss: 2.204874202609062

Epoch: 5| Step: 9
Training loss: 1.6648948192596436
Validation loss: 2.2068223357200623

Epoch: 5| Step: 10
Training loss: 1.2422406673431396
Validation loss: 2.219510406255722

Epoch: 5| Step: 11
Training loss: 0.8839001655578613
Validation loss: 2.2159662743409476

Epoch: 307| Step: 0
Training loss: 1.4862781763076782
Validation loss: 2.2070718159278235

Epoch: 5| Step: 1
Training loss: 1.4566296339035034
Validation loss: 2.1929484009742737

Epoch: 5| Step: 2
Training loss: 1.9655444622039795
Validation loss: 2.1910859594742456

Epoch: 5| Step: 3
Training loss: 2.342806816101074
Validation loss: 2.1588235795497894

Epoch: 5| Step: 4
Training loss: 1.5749304294586182
Validation loss: 2.169654905796051

Epoch: 5| Step: 5
Training loss: 1.7284071445465088
Validation loss: 2.1576137989759445

Epoch: 5| Step: 6
Training loss: 2.2807891368865967
Validation loss: 2.1837155371904373

Epoch: 5| Step: 7
Training loss: 1.5432778596878052
Validation loss: 2.228035092353821

Epoch: 5| Step: 8
Training loss: 1.6090152263641357
Validation loss: 2.252243161201477

Epoch: 5| Step: 9
Training loss: 1.4716241359710693
Validation loss: 2.25495944917202

Epoch: 5| Step: 10
Training loss: 1.4339241981506348
Validation loss: 2.3049527456363044

Epoch: 5| Step: 11
Training loss: 1.4895809888839722
Validation loss: 2.2989065249760947

Epoch: 308| Step: 0
Training loss: 1.3505456447601318
Validation loss: 2.3210477928320565

Epoch: 5| Step: 1
Training loss: 1.222562313079834
Validation loss: 2.3130056460698447

Epoch: 5| Step: 2
Training loss: 1.4750391244888306
Validation loss: 2.3314093748728433

Epoch: 5| Step: 3
Training loss: 2.4147958755493164
Validation loss: 2.337490459283193

Epoch: 5| Step: 4
Training loss: 1.6917893886566162
Validation loss: 2.3240246325731277

Epoch: 5| Step: 5
Training loss: 1.7292712926864624
Validation loss: 2.290942152341207

Epoch: 5| Step: 6
Training loss: 1.529685139656067
Validation loss: 2.3057929426431656

Epoch: 5| Step: 7
Training loss: 2.3236231803894043
Validation loss: 2.265352721015612

Epoch: 5| Step: 8
Training loss: 1.413892149925232
Validation loss: 2.2438361843427024

Epoch: 5| Step: 9
Training loss: 1.6029272079467773
Validation loss: 2.2563968747854233

Epoch: 5| Step: 10
Training loss: 1.2093020677566528
Validation loss: 2.261855974793434

Epoch: 5| Step: 11
Training loss: 2.6600193977355957
Validation loss: 2.193757047255834

Epoch: 309| Step: 0
Training loss: 1.551303505897522
Validation loss: 2.232098480065664

Epoch: 5| Step: 1
Training loss: 2.0902419090270996
Validation loss: 2.2495680451393127

Epoch: 5| Step: 2
Training loss: 2.453928232192993
Validation loss: 2.2595037718613944

Epoch: 5| Step: 3
Training loss: 1.180615782737732
Validation loss: 2.2730183601379395

Epoch: 5| Step: 4
Training loss: 1.2217848300933838
Validation loss: 2.252090940872828

Epoch: 5| Step: 5
Training loss: 1.8229866027832031
Validation loss: 2.273431753118833

Epoch: 5| Step: 6
Training loss: 1.6529613733291626
Validation loss: 2.279154822230339

Epoch: 5| Step: 7
Training loss: 1.5598787069320679
Validation loss: 2.2650876690944037

Epoch: 5| Step: 8
Training loss: 1.431329369544983
Validation loss: 2.276788681745529

Epoch: 5| Step: 9
Training loss: 1.5230166912078857
Validation loss: 2.234526033202807

Epoch: 5| Step: 10
Training loss: 1.0422382354736328
Validation loss: 2.2545142471790314

Epoch: 5| Step: 11
Training loss: 2.4104971885681152
Validation loss: 2.2590480744838715

Epoch: 310| Step: 0
Training loss: 2.1925199031829834
Validation loss: 2.2549962252378464

Epoch: 5| Step: 1
Training loss: 1.5171066522598267
Validation loss: 2.2337624033292136

Epoch: 5| Step: 2
Training loss: 1.9401013851165771
Validation loss: 2.23440013329188

Epoch: 5| Step: 3
Training loss: 1.2174454927444458
Validation loss: 2.246666510899862

Epoch: 5| Step: 4
Training loss: 1.371531367301941
Validation loss: 2.2443934977054596

Epoch: 5| Step: 5
Training loss: 1.5921368598937988
Validation loss: 2.2549167573451996

Epoch: 5| Step: 6
Training loss: 0.9637397527694702
Validation loss: 2.2280077387889228

Epoch: 5| Step: 7
Training loss: 1.932071328163147
Validation loss: 2.2706256608168283

Epoch: 5| Step: 8
Training loss: 1.2512266635894775
Validation loss: 2.2761298368374505

Epoch: 5| Step: 9
Training loss: 1.7857029438018799
Validation loss: 2.2417234679063163

Epoch: 5| Step: 10
Training loss: 1.4535936117172241
Validation loss: 2.271426200866699

Epoch: 5| Step: 11
Training loss: 1.590234637260437
Validation loss: 2.256590336561203

Epoch: 311| Step: 0
Training loss: 1.667193055152893
Validation loss: 2.2639512568712234

Epoch: 5| Step: 1
Training loss: 1.265268087387085
Validation loss: 2.272194877266884

Epoch: 5| Step: 2
Training loss: 1.8327257633209229
Validation loss: 2.2544739842414856

Epoch: 5| Step: 3
Training loss: 1.8384792804718018
Validation loss: 2.269736776749293

Epoch: 5| Step: 4
Training loss: 1.4280153512954712
Validation loss: 2.2493379364411035

Epoch: 5| Step: 5
Training loss: 1.4865028858184814
Validation loss: 2.2560945401589074

Epoch: 5| Step: 6
Training loss: 1.1570721864700317
Validation loss: 2.2540596425533295

Epoch: 5| Step: 7
Training loss: 2.248753547668457
Validation loss: 2.22889044880867

Epoch: 5| Step: 8
Training loss: 0.7096127271652222
Validation loss: 2.2498216778039932

Epoch: 5| Step: 9
Training loss: 1.3977209329605103
Validation loss: 2.2507111579179764

Epoch: 5| Step: 10
Training loss: 2.0219616889953613
Validation loss: 2.262786477804184

Epoch: 5| Step: 11
Training loss: 1.6382145881652832
Validation loss: 2.2300591270128884

Epoch: 312| Step: 0
Training loss: 1.9696544408798218
Validation loss: 2.227658584713936

Epoch: 5| Step: 1
Training loss: 1.0702078342437744
Validation loss: 2.2360108296076455

Epoch: 5| Step: 2
Training loss: 1.2090259790420532
Validation loss: 2.2252673705418906

Epoch: 5| Step: 3
Training loss: 1.3132165670394897
Validation loss: 2.226891612013181

Epoch: 5| Step: 4
Training loss: 0.9800022840499878
Validation loss: 2.2341981629530587

Epoch: 5| Step: 5
Training loss: 1.7410980463027954
Validation loss: 2.2439857770999274

Epoch: 5| Step: 6
Training loss: 1.4135103225708008
Validation loss: 2.246612692872683

Epoch: 5| Step: 7
Training loss: 1.5047125816345215
Validation loss: 2.2299915552139282

Epoch: 5| Step: 8
Training loss: 1.4360448122024536
Validation loss: 2.2650328824917474

Epoch: 5| Step: 9
Training loss: 2.119234800338745
Validation loss: 2.2910981277624765

Epoch: 5| Step: 10
Training loss: 2.139166831970215
Validation loss: 2.3030199110507965

Epoch: 5| Step: 11
Training loss: 2.541130304336548
Validation loss: 2.296375314394633

Epoch: 313| Step: 0
Training loss: 1.3192325830459595
Validation loss: 2.278152654568354

Epoch: 5| Step: 1
Training loss: 1.447622299194336
Validation loss: 2.2798105577627816

Epoch: 5| Step: 2
Training loss: 1.3263967037200928
Validation loss: 2.263898561398188

Epoch: 5| Step: 3
Training loss: 2.3827109336853027
Validation loss: 2.2569375038146973

Epoch: 5| Step: 4
Training loss: 1.606972336769104
Validation loss: 2.2301978270212808

Epoch: 5| Step: 5
Training loss: 1.3546022176742554
Validation loss: 2.204807221889496

Epoch: 5| Step: 6
Training loss: 2.0311167240142822
Validation loss: 2.2294609596331916

Epoch: 5| Step: 7
Training loss: 1.979168176651001
Validation loss: 2.206790273388227

Epoch: 5| Step: 8
Training loss: 1.3029875755310059
Validation loss: 2.1880745937426886

Epoch: 5| Step: 9
Training loss: 1.1124727725982666
Validation loss: 2.2044077714284263

Epoch: 5| Step: 10
Training loss: 1.6556942462921143
Validation loss: 2.212144454320272

Epoch: 5| Step: 11
Training loss: 1.2419660091400146
Validation loss: 2.190048336982727

Epoch: 314| Step: 0
Training loss: 1.7835880517959595
Validation loss: 2.2242428610722222

Epoch: 5| Step: 1
Training loss: 1.7154852151870728
Validation loss: 2.2763359248638153

Epoch: 5| Step: 2
Training loss: 1.5386757850646973
Validation loss: 2.2676190435886383

Epoch: 5| Step: 3
Training loss: 1.6838035583496094
Validation loss: 2.281308044989904

Epoch: 5| Step: 4
Training loss: 1.788071632385254
Validation loss: 2.2627265801032386

Epoch: 5| Step: 5
Training loss: 0.7387062311172485
Validation loss: 2.26885886490345

Epoch: 5| Step: 6
Training loss: 1.661562204360962
Validation loss: 2.244358718395233

Epoch: 5| Step: 7
Training loss: 1.6442930698394775
Validation loss: 2.2349637945493064

Epoch: 5| Step: 8
Training loss: 1.9196192026138306
Validation loss: 2.2429650872945786

Epoch: 5| Step: 9
Training loss: 1.381622076034546
Validation loss: 2.2446177899837494

Epoch: 5| Step: 10
Training loss: 2.079322338104248
Validation loss: 2.2281426787376404

Epoch: 5| Step: 11
Training loss: 0.7335585355758667
Validation loss: 2.240075866381327

Epoch: 315| Step: 0
Training loss: 1.5207895040512085
Validation loss: 2.2299421280622482

Epoch: 5| Step: 1
Training loss: 1.6537383794784546
Validation loss: 2.2367285390694938

Epoch: 5| Step: 2
Training loss: 1.3571159839630127
Validation loss: 2.2418707559506097

Epoch: 5| Step: 3
Training loss: 1.487065076828003
Validation loss: 2.251788462201754

Epoch: 5| Step: 4
Training loss: 2.266490936279297
Validation loss: 2.2435751259326935

Epoch: 5| Step: 5
Training loss: 1.6037019491195679
Validation loss: 2.2521766424179077

Epoch: 5| Step: 6
Training loss: 1.3983073234558105
Validation loss: 2.2730758289496102

Epoch: 5| Step: 7
Training loss: 1.5004503726959229
Validation loss: 2.275328740477562

Epoch: 5| Step: 8
Training loss: 1.4172776937484741
Validation loss: 2.274569516380628

Epoch: 5| Step: 9
Training loss: 0.8550119400024414
Validation loss: 2.2885394990444183

Epoch: 5| Step: 10
Training loss: 1.8764514923095703
Validation loss: 2.2875578900178275

Epoch: 5| Step: 11
Training loss: 1.6278187036514282
Validation loss: 2.2680852810541787

Epoch: 316| Step: 0
Training loss: 1.792323112487793
Validation loss: 2.2867728571097055

Epoch: 5| Step: 1
Training loss: 0.9592815637588501
Validation loss: 2.2755671789248786

Epoch: 5| Step: 2
Training loss: 1.2872124910354614
Validation loss: 2.2467311322689056

Epoch: 5| Step: 3
Training loss: 1.9386097192764282
Validation loss: 2.2504405776659646

Epoch: 5| Step: 4
Training loss: 1.650846242904663
Validation loss: 2.1825955659151077

Epoch: 5| Step: 5
Training loss: 1.2350444793701172
Validation loss: 2.2099206894636154

Epoch: 5| Step: 6
Training loss: 1.801391839981079
Validation loss: 2.2408443987369537

Epoch: 5| Step: 7
Training loss: 1.4788405895233154
Validation loss: 2.2305079648892083

Epoch: 5| Step: 8
Training loss: 1.5833505392074585
Validation loss: 2.27019735177358

Epoch: 5| Step: 9
Training loss: 2.1815247535705566
Validation loss: 2.270142381389936

Epoch: 5| Step: 10
Training loss: 1.3630132675170898
Validation loss: 2.295037398735682

Epoch: 5| Step: 11
Training loss: 1.7224407196044922
Validation loss: 2.279340222477913

Epoch: 317| Step: 0
Training loss: 1.5601125955581665
Validation loss: 2.2573455522457757

Epoch: 5| Step: 1
Training loss: 1.3948874473571777
Validation loss: 2.2825283855199814

Epoch: 5| Step: 2
Training loss: 0.9263164401054382
Validation loss: 2.246649314959844

Epoch: 5| Step: 3
Training loss: 1.4618866443634033
Validation loss: 2.2650218407313027

Epoch: 5| Step: 4
Training loss: 2.0965359210968018
Validation loss: 2.2575926085313163

Epoch: 5| Step: 5
Training loss: 0.9549830555915833
Validation loss: 2.2317065745592117

Epoch: 5| Step: 6
Training loss: 1.6603524684906006
Validation loss: 2.2336129446824393

Epoch: 5| Step: 7
Training loss: 1.9126991033554077
Validation loss: 2.2292042473951974

Epoch: 5| Step: 8
Training loss: 1.0177638530731201
Validation loss: 2.2349589417378106

Epoch: 5| Step: 9
Training loss: 1.9094288349151611
Validation loss: 2.255912015835444

Epoch: 5| Step: 10
Training loss: 1.6073687076568604
Validation loss: 2.278283258279165

Epoch: 5| Step: 11
Training loss: 2.610912561416626
Validation loss: 2.2746687879165015

Epoch: 318| Step: 0
Training loss: 1.7399177551269531
Validation loss: 2.2795066038767495

Epoch: 5| Step: 1
Training loss: 0.9963746070861816
Validation loss: 2.312963604927063

Epoch: 5| Step: 2
Training loss: 1.8251497745513916
Validation loss: 2.3210490942001343

Epoch: 5| Step: 3
Training loss: 1.937951683998108
Validation loss: 2.3229474325974784

Epoch: 5| Step: 4
Training loss: 1.2948988676071167
Validation loss: 2.3269642194112143

Epoch: 5| Step: 5
Training loss: 1.5662429332733154
Validation loss: 2.3307081361611686

Epoch: 5| Step: 6
Training loss: 2.113407611846924
Validation loss: 2.317278802394867

Epoch: 5| Step: 7
Training loss: 1.340983271598816
Validation loss: 2.298590918382009

Epoch: 5| Step: 8
Training loss: 1.4799458980560303
Validation loss: 2.3017292420069375

Epoch: 5| Step: 9
Training loss: 1.0826284885406494
Validation loss: 2.283317416906357

Epoch: 5| Step: 10
Training loss: 1.4691956043243408
Validation loss: 2.268017609914144

Epoch: 5| Step: 11
Training loss: 3.2368876934051514
Validation loss: 2.237303058306376

Epoch: 319| Step: 0
Training loss: 1.9157381057739258
Validation loss: 2.2515415300925574

Epoch: 5| Step: 1
Training loss: 1.425702452659607
Validation loss: 2.2323247690995536

Epoch: 5| Step: 2
Training loss: 2.282641887664795
Validation loss: 2.2414356221755347

Epoch: 5| Step: 3
Training loss: 2.08857798576355
Validation loss: 2.2441896249850593

Epoch: 5| Step: 4
Training loss: 1.2080018520355225
Validation loss: 2.256491869688034

Epoch: 5| Step: 5
Training loss: 1.2353007793426514
Validation loss: 2.2994198401769004

Epoch: 5| Step: 6
Training loss: 1.5364854335784912
Validation loss: 2.2913065254688263

Epoch: 5| Step: 7
Training loss: 1.528911828994751
Validation loss: 2.275025059779485

Epoch: 5| Step: 8
Training loss: 1.382490634918213
Validation loss: 2.3187242845694223

Epoch: 5| Step: 9
Training loss: 1.9461002349853516
Validation loss: 2.3166624158620834

Epoch: 5| Step: 10
Training loss: 1.5317833423614502
Validation loss: 2.277438133955002

Epoch: 5| Step: 11
Training loss: 1.1685725450515747
Validation loss: 2.266090383132299

Epoch: 320| Step: 0
Training loss: 1.2873249053955078
Validation loss: 2.3052815794944763

Epoch: 5| Step: 1
Training loss: 1.9492433071136475
Validation loss: 2.2630599439144135

Epoch: 5| Step: 2
Training loss: 1.2822823524475098
Validation loss: 2.2598395695288978

Epoch: 5| Step: 3
Training loss: 1.4373306035995483
Validation loss: 2.223689337571462

Epoch: 5| Step: 4
Training loss: 1.444427728652954
Validation loss: 2.218882749478022

Epoch: 5| Step: 5
Training loss: 1.3929461240768433
Validation loss: 2.215919221440951

Epoch: 5| Step: 6
Training loss: 1.6747686862945557
Validation loss: 2.2158712397019067

Epoch: 5| Step: 7
Training loss: 1.569983720779419
Validation loss: 2.2229340970516205

Epoch: 5| Step: 8
Training loss: 1.6622250080108643
Validation loss: 2.2309860239426293

Epoch: 5| Step: 9
Training loss: 1.662469506263733
Validation loss: 2.2349544167518616

Epoch: 5| Step: 10
Training loss: 1.8005462884902954
Validation loss: 2.2202658553918204

Epoch: 5| Step: 11
Training loss: 1.9124197959899902
Validation loss: 2.2212434311707816

Epoch: 321| Step: 0
Training loss: 2.0795865058898926
Validation loss: 2.2348889261484146

Epoch: 5| Step: 1
Training loss: 1.3535442352294922
Validation loss: 2.224937071402868

Epoch: 5| Step: 2
Training loss: 1.4449942111968994
Validation loss: 2.217392176389694

Epoch: 5| Step: 3
Training loss: 2.3302416801452637
Validation loss: 2.266869937380155

Epoch: 5| Step: 4
Training loss: 1.2470905780792236
Validation loss: 2.2761899729569754

Epoch: 5| Step: 5
Training loss: 1.090494155883789
Validation loss: 2.2722087502479553

Epoch: 5| Step: 6
Training loss: 1.6128486394882202
Validation loss: 2.236157238483429

Epoch: 5| Step: 7
Training loss: 1.473716378211975
Validation loss: 2.2356251925230026

Epoch: 5| Step: 8
Training loss: 1.4146807193756104
Validation loss: 2.2160445551077523

Epoch: 5| Step: 9
Training loss: 1.6511669158935547
Validation loss: 2.2110149959723153

Epoch: 5| Step: 10
Training loss: 1.315995454788208
Validation loss: 2.241182873646418

Epoch: 5| Step: 11
Training loss: 2.2467026710510254
Validation loss: 2.225808322429657

Epoch: 322| Step: 0
Training loss: 1.5439493656158447
Validation loss: 2.227317621310552

Epoch: 5| Step: 1
Training loss: 1.3683383464813232
Validation loss: 2.2290995866060257

Epoch: 5| Step: 2
Training loss: 1.6544430255889893
Validation loss: 2.216872145732244

Epoch: 5| Step: 3
Training loss: 1.466799259185791
Validation loss: 2.2267325123151145

Epoch: 5| Step: 4
Training loss: 1.3226685523986816
Validation loss: 2.2143703997135162

Epoch: 5| Step: 5
Training loss: 1.7332954406738281
Validation loss: 2.2296359141667685

Epoch: 5| Step: 6
Training loss: 1.4457581043243408
Validation loss: 2.2408166031042733

Epoch: 5| Step: 7
Training loss: 1.4010423421859741
Validation loss: 2.267267554998398

Epoch: 5| Step: 8
Training loss: 1.3014107942581177
Validation loss: 2.269268890221914

Epoch: 5| Step: 9
Training loss: 1.782396912574768
Validation loss: 2.248467981815338

Epoch: 5| Step: 10
Training loss: 1.6157341003417969
Validation loss: 2.2293287267287574

Epoch: 5| Step: 11
Training loss: 1.086290955543518
Validation loss: 2.243477076292038

Epoch: 323| Step: 0
Training loss: 1.232041358947754
Validation loss: 2.2338976015647254

Epoch: 5| Step: 1
Training loss: 1.511918067932129
Validation loss: 2.2188070913155875

Epoch: 5| Step: 2
Training loss: 1.7559001445770264
Validation loss: 2.201397572954496

Epoch: 5| Step: 3
Training loss: 1.3881466388702393
Validation loss: 2.2122948865095773

Epoch: 5| Step: 4
Training loss: 1.6728131771087646
Validation loss: 2.195441414912542

Epoch: 5| Step: 5
Training loss: 0.9662008285522461
Validation loss: 2.2040828863779702

Epoch: 5| Step: 6
Training loss: 2.0655109882354736
Validation loss: 2.194061736265818

Epoch: 5| Step: 7
Training loss: 1.8175151348114014
Validation loss: 2.211848904689153

Epoch: 5| Step: 8
Training loss: 1.6350361108779907
Validation loss: 2.1982526779174805

Epoch: 5| Step: 9
Training loss: 1.3233444690704346
Validation loss: 2.211276282866796

Epoch: 5| Step: 10
Training loss: 1.9231122732162476
Validation loss: 2.2232871651649475

Epoch: 5| Step: 11
Training loss: 0.9964204430580139
Validation loss: 2.266117309530576

Epoch: 324| Step: 0
Training loss: 1.6032062768936157
Validation loss: 2.2780026396115622

Epoch: 5| Step: 1
Training loss: 1.4241628646850586
Validation loss: 2.311100577314695

Epoch: 5| Step: 2
Training loss: 2.1365585327148438
Validation loss: 2.300577759742737

Epoch: 5| Step: 3
Training loss: 1.3756952285766602
Validation loss: 2.2852861185868583

Epoch: 5| Step: 4
Training loss: 1.7878764867782593
Validation loss: 2.27759716908137

Epoch: 5| Step: 5
Training loss: 1.26614248752594
Validation loss: 2.2557494789361954

Epoch: 5| Step: 6
Training loss: 1.4232085943222046
Validation loss: 2.287488172451655

Epoch: 5| Step: 7
Training loss: 1.4397728443145752
Validation loss: 2.2588900874058404

Epoch: 5| Step: 8
Training loss: 1.118259310722351
Validation loss: 2.231915846467018

Epoch: 5| Step: 9
Training loss: 2.172482967376709
Validation loss: 2.243267218271891

Epoch: 5| Step: 10
Training loss: 1.2221685647964478
Validation loss: 2.2415871918201447

Epoch: 5| Step: 11
Training loss: 0.7119947671890259
Validation loss: 2.229517171780268

Epoch: 325| Step: 0
Training loss: 1.3381726741790771
Validation loss: 2.2119735876719155

Epoch: 5| Step: 1
Training loss: 1.1643295288085938
Validation loss: 2.2321973145008087

Epoch: 5| Step: 2
Training loss: 1.837567687034607
Validation loss: 2.215328554312388

Epoch: 5| Step: 3
Training loss: 1.7761586904525757
Validation loss: 2.220396856466929

Epoch: 5| Step: 4
Training loss: 1.842633843421936
Validation loss: 2.2485154271125793

Epoch: 5| Step: 5
Training loss: 1.9659547805786133
Validation loss: 2.2501028031110764

Epoch: 5| Step: 6
Training loss: 1.6543554067611694
Validation loss: 2.2544558495283127

Epoch: 5| Step: 7
Training loss: 0.8502575159072876
Validation loss: 2.223608116308848

Epoch: 5| Step: 8
Training loss: 1.646662712097168
Validation loss: 2.242388665676117

Epoch: 5| Step: 9
Training loss: 0.924072265625
Validation loss: 2.233768234650294

Epoch: 5| Step: 10
Training loss: 1.5685150623321533
Validation loss: 2.2167678525050483

Epoch: 5| Step: 11
Training loss: 0.9819091558456421
Validation loss: 2.1742136975129447

Epoch: 326| Step: 0
Training loss: 0.9574066400527954
Validation loss: 2.1755465964476266

Epoch: 5| Step: 1
Training loss: 1.859039306640625
Validation loss: 2.198836753765742

Epoch: 5| Step: 2
Training loss: 1.9533138275146484
Validation loss: 2.2203048268953958

Epoch: 5| Step: 3
Training loss: 2.325382947921753
Validation loss: 2.2424600273370743

Epoch: 5| Step: 4
Training loss: 1.8935388326644897
Validation loss: 2.2202008167902627

Epoch: 5| Step: 5
Training loss: 1.4368302822113037
Validation loss: 2.1958217521508536

Epoch: 5| Step: 6
Training loss: 1.5733792781829834
Validation loss: 2.2398700465758643

Epoch: 5| Step: 7
Training loss: 1.2887338399887085
Validation loss: 2.2327354749043784

Epoch: 5| Step: 8
Training loss: 1.2054177522659302
Validation loss: 2.2723265290260315

Epoch: 5| Step: 9
Training loss: 1.0294873714447021
Validation loss: 2.247463126977285

Epoch: 5| Step: 10
Training loss: 1.1758201122283936
Validation loss: 2.2519935419162116

Epoch: 5| Step: 11
Training loss: 1.064180612564087
Validation loss: 2.2798446466525397

Epoch: 327| Step: 0
Training loss: 1.5654315948486328
Validation loss: 2.267072856426239

Epoch: 5| Step: 1
Training loss: 1.2951463460922241
Validation loss: 2.2734942634900412

Epoch: 5| Step: 2
Training loss: 1.4889582395553589
Validation loss: 2.2522051682074866

Epoch: 5| Step: 3
Training loss: 1.7211925983428955
Validation loss: 2.2188910146554313

Epoch: 5| Step: 4
Training loss: 1.6939976215362549
Validation loss: 2.2433977176745734

Epoch: 5| Step: 5
Training loss: 1.6525837182998657
Validation loss: 2.2278853058815002

Epoch: 5| Step: 6
Training loss: 1.8735698461532593
Validation loss: 2.24053988357385

Epoch: 5| Step: 7
Training loss: 1.7431377172470093
Validation loss: 2.246813545624415

Epoch: 5| Step: 8
Training loss: 1.5418533086776733
Validation loss: 2.2570855716864267

Epoch: 5| Step: 9
Training loss: 1.1884844303131104
Validation loss: 2.2598499059677124

Epoch: 5| Step: 10
Training loss: 1.3557775020599365
Validation loss: 2.2167342801888785

Epoch: 5| Step: 11
Training loss: 1.4025561809539795
Validation loss: 2.2498029669125876

Epoch: 328| Step: 0
Training loss: 1.4803261756896973
Validation loss: 2.2366138945023217

Epoch: 5| Step: 1
Training loss: 1.446089506149292
Validation loss: 2.21176478266716

Epoch: 5| Step: 2
Training loss: 1.4793877601623535
Validation loss: 2.214720676342646

Epoch: 5| Step: 3
Training loss: 1.7890056371688843
Validation loss: 2.1940626154343286

Epoch: 5| Step: 4
Training loss: 1.0260883569717407
Validation loss: 2.2009631991386414

Epoch: 5| Step: 5
Training loss: 0.6958154439926147
Validation loss: 2.199308897058169

Epoch: 5| Step: 6
Training loss: 1.751835823059082
Validation loss: 2.1784394085407257

Epoch: 5| Step: 7
Training loss: 1.8558298349380493
Validation loss: 2.1855477690696716

Epoch: 5| Step: 8
Training loss: 1.067954659461975
Validation loss: 2.198287695646286

Epoch: 5| Step: 9
Training loss: 2.2482857704162598
Validation loss: 2.2094058891137442

Epoch: 5| Step: 10
Training loss: 1.303612232208252
Validation loss: 2.2014986673990884

Epoch: 5| Step: 11
Training loss: 2.9308135509490967
Validation loss: 2.2525828580061593

Epoch: 329| Step: 0
Training loss: 1.4003856182098389
Validation loss: 2.253849665323893

Epoch: 5| Step: 1
Training loss: 0.9885087013244629
Validation loss: 2.2396652499834695

Epoch: 5| Step: 2
Training loss: 1.2488532066345215
Validation loss: 2.2800062596797943

Epoch: 5| Step: 3
Training loss: 0.910045325756073
Validation loss: 2.270451615254084

Epoch: 5| Step: 4
Training loss: 1.890523910522461
Validation loss: 2.2475795100132623

Epoch: 5| Step: 5
Training loss: 2.1953330039978027
Validation loss: 2.2395522693792977

Epoch: 5| Step: 6
Training loss: 1.7111976146697998
Validation loss: 2.240674023826917

Epoch: 5| Step: 7
Training loss: 1.738257646560669
Validation loss: 2.2327922731637955

Epoch: 5| Step: 8
Training loss: 1.5384615659713745
Validation loss: 2.251773710052172

Epoch: 5| Step: 9
Training loss: 1.0822832584381104
Validation loss: 2.256537606318792

Epoch: 5| Step: 10
Training loss: 1.016042709350586
Validation loss: 2.23908194899559

Epoch: 5| Step: 11
Training loss: 3.579531192779541
Validation loss: 2.198282981912295

Epoch: 330| Step: 0
Training loss: 1.9335319995880127
Validation loss: 2.2159022043148675

Epoch: 5| Step: 1
Training loss: 1.1851837635040283
Validation loss: 2.226501057545344

Epoch: 5| Step: 2
Training loss: 0.8193381428718567
Validation loss: 2.2511895497639975

Epoch: 5| Step: 3
Training loss: 1.1478803157806396
Validation loss: 2.2358886003494263

Epoch: 5| Step: 4
Training loss: 1.5358915328979492
Validation loss: 2.249222661058108

Epoch: 5| Step: 5
Training loss: 1.3318593502044678
Validation loss: 2.23728409409523

Epoch: 5| Step: 6
Training loss: 1.4496418237686157
Validation loss: 2.2633415361245475

Epoch: 5| Step: 7
Training loss: 1.4891449213027954
Validation loss: 2.2766976008812585

Epoch: 5| Step: 8
Training loss: 1.6745628118515015
Validation loss: 2.2826363295316696

Epoch: 5| Step: 9
Training loss: 1.9787416458129883
Validation loss: 2.2603869835535684

Epoch: 5| Step: 10
Training loss: 1.5570361614227295
Validation loss: 2.3061613738536835

Epoch: 5| Step: 11
Training loss: 2.371873378753662
Validation loss: 2.2783684134483337

Epoch: 331| Step: 0
Training loss: 1.4101474285125732
Validation loss: 2.2714334229628244

Epoch: 5| Step: 1
Training loss: 1.1161632537841797
Validation loss: 2.238396485646566

Epoch: 5| Step: 2
Training loss: 1.8941978216171265
Validation loss: 2.2212309688329697

Epoch: 5| Step: 3
Training loss: 1.7458546161651611
Validation loss: 2.209230730930964

Epoch: 5| Step: 4
Training loss: 1.386299729347229
Validation loss: 2.1983333230018616

Epoch: 5| Step: 5
Training loss: 1.869065284729004
Validation loss: 2.198291306694349

Epoch: 5| Step: 6
Training loss: 1.682358980178833
Validation loss: 2.2104490300019584

Epoch: 5| Step: 7
Training loss: 1.4317591190338135
Validation loss: 2.208902190128962

Epoch: 5| Step: 8
Training loss: 1.3437799215316772
Validation loss: 2.2208029528458915

Epoch: 5| Step: 9
Training loss: 1.4594756364822388
Validation loss: 2.206188440322876

Epoch: 5| Step: 10
Training loss: 1.5299816131591797
Validation loss: 2.199455847342809

Epoch: 5| Step: 11
Training loss: 1.1669031381607056
Validation loss: 2.2034549762805304

Epoch: 332| Step: 0
Training loss: 2.0322022438049316
Validation loss: 2.218983973066012

Epoch: 5| Step: 1
Training loss: 1.5142765045166016
Validation loss: 2.18697198232015

Epoch: 5| Step: 2
Training loss: 1.162232756614685
Validation loss: 2.190044383207957

Epoch: 5| Step: 3
Training loss: 1.2273616790771484
Validation loss: 2.1958510826031366

Epoch: 5| Step: 4
Training loss: 1.8791382312774658
Validation loss: 2.188833713531494

Epoch: 5| Step: 5
Training loss: 1.1793886423110962
Validation loss: 2.202070246140162

Epoch: 5| Step: 6
Training loss: 1.2583177089691162
Validation loss: 2.220541844765345

Epoch: 5| Step: 7
Training loss: 1.9687817096710205
Validation loss: 2.1793173054854074

Epoch: 5| Step: 8
Training loss: 1.368719458580017
Validation loss: 2.2420382549365363

Epoch: 5| Step: 9
Training loss: 1.3090479373931885
Validation loss: 2.2261964877446494

Epoch: 5| Step: 10
Training loss: 1.5012224912643433
Validation loss: 2.2749780863523483

Epoch: 5| Step: 11
Training loss: 0.9439932107925415
Validation loss: 2.2389058470726013

Epoch: 333| Step: 0
Training loss: 1.34524405002594
Validation loss: 2.2134491403897605

Epoch: 5| Step: 1
Training loss: 1.5271199941635132
Validation loss: 2.2386326491832733

Epoch: 5| Step: 2
Training loss: 1.1788092851638794
Validation loss: 2.234386622905731

Epoch: 5| Step: 3
Training loss: 1.3041865825653076
Validation loss: 2.2455624838670096

Epoch: 5| Step: 4
Training loss: 1.7156298160552979
Validation loss: 2.20057246585687

Epoch: 5| Step: 5
Training loss: 1.4112331867218018
Validation loss: 2.2396675447622933

Epoch: 5| Step: 6
Training loss: 1.3541849851608276
Validation loss: 2.236126403013865

Epoch: 5| Step: 7
Training loss: 1.0111104249954224
Validation loss: 2.2190837264060974

Epoch: 5| Step: 8
Training loss: 2.362696647644043
Validation loss: 2.2383705526590347

Epoch: 5| Step: 9
Training loss: 1.5694291591644287
Validation loss: 2.2051169723272324

Epoch: 5| Step: 10
Training loss: 1.255079746246338
Validation loss: 2.214830835660299

Epoch: 5| Step: 11
Training loss: 0.9161797761917114
Validation loss: 2.1914267539978027

Epoch: 334| Step: 0
Training loss: 1.8257688283920288
Validation loss: 2.1988093306620917

Epoch: 5| Step: 1
Training loss: 1.291175127029419
Validation loss: 2.2166870137055716

Epoch: 5| Step: 2
Training loss: 1.9880520105361938
Validation loss: 2.2117477109034858

Epoch: 5| Step: 3
Training loss: 1.6291917562484741
Validation loss: 2.249472181002299

Epoch: 5| Step: 4
Training loss: 1.515470027923584
Validation loss: 2.222137674689293

Epoch: 5| Step: 5
Training loss: 1.9045865535736084
Validation loss: 2.247749691208204

Epoch: 5| Step: 6
Training loss: 1.735661268234253
Validation loss: 2.255739450454712

Epoch: 5| Step: 7
Training loss: 1.1463019847869873
Validation loss: 2.2344068437814713

Epoch: 5| Step: 8
Training loss: 1.3465591669082642
Validation loss: 2.283318370580673

Epoch: 5| Step: 9
Training loss: 0.6573178172111511
Validation loss: 2.2773359020551047

Epoch: 5| Step: 10
Training loss: 1.0961605310440063
Validation loss: 2.2534247438112893

Epoch: 5| Step: 11
Training loss: 1.1968343257904053
Validation loss: 2.2737272828817368

Epoch: 335| Step: 0
Training loss: 1.259564757347107
Validation loss: 2.256537144382795

Epoch: 5| Step: 1
Training loss: 1.4121689796447754
Validation loss: 2.245690812667211

Epoch: 5| Step: 2
Training loss: 1.5176479816436768
Validation loss: 2.2166015853484473

Epoch: 5| Step: 3
Training loss: 1.248552918434143
Validation loss: 2.239296182990074

Epoch: 5| Step: 4
Training loss: 1.3982362747192383
Validation loss: 2.226297696431478

Epoch: 5| Step: 5
Training loss: 2.436069965362549
Validation loss: 2.2331572771072388

Epoch: 5| Step: 6
Training loss: 1.7448627948760986
Validation loss: 2.2234475711981454

Epoch: 5| Step: 7
Training loss: 1.3824052810668945
Validation loss: 2.294143040974935

Epoch: 5| Step: 8
Training loss: 1.1795541048049927
Validation loss: 2.2910437683264413

Epoch: 5| Step: 9
Training loss: 2.1422348022460938
Validation loss: 2.2942183365424476

Epoch: 5| Step: 10
Training loss: 1.343182921409607
Validation loss: 2.3256768534580865

Epoch: 5| Step: 11
Training loss: 1.662419080734253
Validation loss: 2.288139899571737

Epoch: 336| Step: 0
Training loss: 1.2939097881317139
Validation loss: 2.261002689599991

Epoch: 5| Step: 1
Training loss: 1.731042504310608
Validation loss: 2.2307391266028085

Epoch: 5| Step: 2
Training loss: 1.2770177125930786
Validation loss: 2.230514019727707

Epoch: 5| Step: 3
Training loss: 2.1940245628356934
Validation loss: 2.208445052305857

Epoch: 5| Step: 4
Training loss: 1.642961859703064
Validation loss: 2.189403603474299

Epoch: 5| Step: 5
Training loss: 2.135446071624756
Validation loss: 2.1772498041391373

Epoch: 5| Step: 6
Training loss: 2.035524368286133
Validation loss: 2.2019799600044885

Epoch: 5| Step: 7
Training loss: 0.6033816337585449
Validation loss: 2.186819483836492

Epoch: 5| Step: 8
Training loss: 1.138340950012207
Validation loss: 2.2204089065392814

Epoch: 5| Step: 9
Training loss: 1.1706478595733643
Validation loss: 2.2692041993141174

Epoch: 5| Step: 10
Training loss: 1.857637643814087
Validation loss: 2.277535488208135

Epoch: 5| Step: 11
Training loss: 2.904308319091797
Validation loss: 2.3299143662055335

Epoch: 337| Step: 0
Training loss: 1.7947111129760742
Validation loss: 2.341481477022171

Epoch: 5| Step: 1
Training loss: 1.3522319793701172
Validation loss: 2.3463459412256875

Epoch: 5| Step: 2
Training loss: 1.7656103372573853
Validation loss: 2.3522543410460153

Epoch: 5| Step: 3
Training loss: 1.5294592380523682
Validation loss: 2.3317678769429526

Epoch: 5| Step: 4
Training loss: 1.4799869060516357
Validation loss: 2.3444634775320687

Epoch: 5| Step: 5
Training loss: 1.6273998022079468
Validation loss: 2.3145142793655396

Epoch: 5| Step: 6
Training loss: 1.9406344890594482
Validation loss: 2.3203532894452414

Epoch: 5| Step: 7
Training loss: 1.9666736125946045
Validation loss: 2.246719559033712

Epoch: 5| Step: 8
Training loss: 1.6324708461761475
Validation loss: 2.228342662254969

Epoch: 5| Step: 9
Training loss: 2.219040632247925
Validation loss: 2.162675137321154

Epoch: 5| Step: 10
Training loss: 1.3436692953109741
Validation loss: 2.1429889698823295

Epoch: 5| Step: 11
Training loss: 2.248103141784668
Validation loss: 2.1492714434862137

Epoch: 338| Step: 0
Training loss: 1.8352749347686768
Validation loss: 2.1730700184901557

Epoch: 5| Step: 1
Training loss: 1.83220636844635
Validation loss: 2.158052921295166

Epoch: 5| Step: 2
Training loss: 2.0799365043640137
Validation loss: 2.152347574631373

Epoch: 5| Step: 3
Training loss: 1.5325143337249756
Validation loss: 2.155982037385305

Epoch: 5| Step: 4
Training loss: 1.388787031173706
Validation loss: 2.1798561265071235

Epoch: 5| Step: 5
Training loss: 1.2689546346664429
Validation loss: 2.1661454141139984

Epoch: 5| Step: 6
Training loss: 1.8875356912612915
Validation loss: 2.159496655066808

Epoch: 5| Step: 7
Training loss: 1.4945600032806396
Validation loss: 2.185362254579862

Epoch: 5| Step: 8
Training loss: 1.517022728919983
Validation loss: 2.1356055786212287

Epoch: 5| Step: 9
Training loss: 1.254183053970337
Validation loss: 2.1630241920550666

Epoch: 5| Step: 10
Training loss: 1.5070579051971436
Validation loss: 2.145697941382726

Epoch: 5| Step: 11
Training loss: 1.4627772569656372
Validation loss: 2.14816153049469

Epoch: 339| Step: 0
Training loss: 1.450749158859253
Validation loss: 2.168727144598961

Epoch: 5| Step: 1
Training loss: 1.3432124853134155
Validation loss: 2.16565378010273

Epoch: 5| Step: 2
Training loss: 1.5259934663772583
Validation loss: 2.1756824751695

Epoch: 5| Step: 3
Training loss: 1.4708373546600342
Validation loss: 2.173524796962738

Epoch: 5| Step: 4
Training loss: 1.7531375885009766
Validation loss: 2.166300490498543

Epoch: 5| Step: 5
Training loss: 1.3218590021133423
Validation loss: 2.1519520233074823

Epoch: 5| Step: 6
Training loss: 1.744791030883789
Validation loss: 2.160149092475573

Epoch: 5| Step: 7
Training loss: 1.9095571041107178
Validation loss: 2.1588818480571113

Epoch: 5| Step: 8
Training loss: 1.4496396780014038
Validation loss: 2.1754030336936316

Epoch: 5| Step: 9
Training loss: 1.467254400253296
Validation loss: 2.187878802418709

Epoch: 5| Step: 10
Training loss: 1.3846771717071533
Validation loss: 2.21566966176033

Epoch: 5| Step: 11
Training loss: 1.009822130203247
Validation loss: 2.194061199824015

Epoch: 340| Step: 0
Training loss: 1.6904449462890625
Validation loss: 2.193533087770144

Epoch: 5| Step: 1
Training loss: 1.0717756748199463
Validation loss: 2.182663396000862

Epoch: 5| Step: 2
Training loss: 1.4551314115524292
Validation loss: 2.190001825491587

Epoch: 5| Step: 3
Training loss: 1.6653858423233032
Validation loss: 2.1997030079364777

Epoch: 5| Step: 4
Training loss: 1.673011064529419
Validation loss: 2.1816243678331375

Epoch: 5| Step: 5
Training loss: 1.622653603553772
Validation loss: 2.209618260463079

Epoch: 5| Step: 6
Training loss: 0.8682683706283569
Validation loss: 2.214427833755811

Epoch: 5| Step: 7
Training loss: 1.748315453529358
Validation loss: 2.196644355853399

Epoch: 5| Step: 8
Training loss: 1.431560754776001
Validation loss: 2.2231816748778024

Epoch: 5| Step: 9
Training loss: 1.7390305995941162
Validation loss: 2.2739920814832053

Epoch: 5| Step: 10
Training loss: 1.2154103517532349
Validation loss: 2.2531417657931647

Epoch: 5| Step: 11
Training loss: 3.1707122325897217
Validation loss: 2.2594979653755822

Epoch: 341| Step: 0
Training loss: 1.358337640762329
Validation loss: 2.2549926737944284

Epoch: 5| Step: 1
Training loss: 1.088430404663086
Validation loss: 2.23420250415802

Epoch: 5| Step: 2
Training loss: 1.6939218044281006
Validation loss: 2.2251924773057303

Epoch: 5| Step: 3
Training loss: 1.5079758167266846
Validation loss: 2.2284917384386063

Epoch: 5| Step: 4
Training loss: 1.361851453781128
Validation loss: 2.2310815701882043

Epoch: 5| Step: 5
Training loss: 1.4434938430786133
Validation loss: 2.2337785760561624

Epoch: 5| Step: 6
Training loss: 1.667911171913147
Validation loss: 2.2284647723038993

Epoch: 5| Step: 7
Training loss: 0.9036257863044739
Validation loss: 2.212061037619909

Epoch: 5| Step: 8
Training loss: 1.2696115970611572
Validation loss: 2.1805753807226815

Epoch: 5| Step: 9
Training loss: 1.932443618774414
Validation loss: 2.2244419753551483

Epoch: 5| Step: 10
Training loss: 1.0726019144058228
Validation loss: 2.2121746093034744

Epoch: 5| Step: 11
Training loss: 3.2642602920532227
Validation loss: 2.194924841324488

Epoch: 342| Step: 0
Training loss: 1.7194772958755493
Validation loss: 2.1707363228003183

Epoch: 5| Step: 1
Training loss: 1.4654935598373413
Validation loss: 2.186638057231903

Epoch: 5| Step: 2
Training loss: 1.676908254623413
Validation loss: 2.1892455220222473

Epoch: 5| Step: 3
Training loss: 1.6569442749023438
Validation loss: 2.175199950734774

Epoch: 5| Step: 4
Training loss: 0.8241058588027954
Validation loss: 2.1516138364871344

Epoch: 5| Step: 5
Training loss: 1.7711689472198486
Validation loss: 2.1973114758729935

Epoch: 5| Step: 6
Training loss: 1.0547252893447876
Validation loss: 2.200255130728086

Epoch: 5| Step: 7
Training loss: 0.9488741159439087
Validation loss: 2.2039619187513986

Epoch: 5| Step: 8
Training loss: 1.2905538082122803
Validation loss: 2.1992943982283273

Epoch: 5| Step: 9
Training loss: 1.9140727519989014
Validation loss: 2.185730626185735

Epoch: 5| Step: 10
Training loss: 1.393445372581482
Validation loss: 2.2200036148230233

Epoch: 5| Step: 11
Training loss: 1.7428104877471924
Validation loss: 2.2344207714001336

Epoch: 343| Step: 0
Training loss: 1.6270675659179688
Validation loss: 2.2577788829803467

Epoch: 5| Step: 1
Training loss: 1.546583652496338
Validation loss: 2.2092718382676444

Epoch: 5| Step: 2
Training loss: 1.4204285144805908
Validation loss: 2.2337055802345276

Epoch: 5| Step: 3
Training loss: 1.3984609842300415
Validation loss: 2.217649911840757

Epoch: 5| Step: 4
Training loss: 1.7670385837554932
Validation loss: 2.2285569409529367

Epoch: 5| Step: 5
Training loss: 0.7501494288444519
Validation loss: 2.233929986755053

Epoch: 5| Step: 6
Training loss: 1.7432273626327515
Validation loss: 2.1945152978102365

Epoch: 5| Step: 7
Training loss: 1.1916875839233398
Validation loss: 2.194523880879084

Epoch: 5| Step: 8
Training loss: 2.053622007369995
Validation loss: 2.1639596819877625

Epoch: 5| Step: 9
Training loss: 1.1273815631866455
Validation loss: 2.2197446723779044

Epoch: 5| Step: 10
Training loss: 1.3074305057525635
Validation loss: 2.200992777943611

Epoch: 5| Step: 11
Training loss: 1.3683356046676636
Validation loss: 2.1995061188936234

Epoch: 344| Step: 0
Training loss: 1.8245786428451538
Validation loss: 2.219617873430252

Epoch: 5| Step: 1
Training loss: 1.823912262916565
Validation loss: 2.216202904780706

Epoch: 5| Step: 2
Training loss: 1.1538933515548706
Validation loss: 2.248497039079666

Epoch: 5| Step: 3
Training loss: 1.352685570716858
Validation loss: 2.229208623369535

Epoch: 5| Step: 4
Training loss: 1.3017070293426514
Validation loss: 2.216624786456426

Epoch: 5| Step: 5
Training loss: 1.3297704458236694
Validation loss: 2.2501177986462912

Epoch: 5| Step: 6
Training loss: 2.1775975227355957
Validation loss: 2.2751337687174478

Epoch: 5| Step: 7
Training loss: 1.8547849655151367
Validation loss: 2.232382665077845

Epoch: 5| Step: 8
Training loss: 1.6430423259735107
Validation loss: 2.2626456220944724

Epoch: 5| Step: 9
Training loss: 1.324105978012085
Validation loss: 2.2384301026662192

Epoch: 5| Step: 10
Training loss: 0.6970852613449097
Validation loss: 2.2170760134855905

Epoch: 5| Step: 11
Training loss: 0.5980502963066101
Validation loss: 2.240094547470411

Epoch: 345| Step: 0
Training loss: 1.4469935894012451
Validation loss: 2.2355999797582626

Epoch: 5| Step: 1
Training loss: 1.291653037071228
Validation loss: 2.198038270076116

Epoch: 5| Step: 2
Training loss: 2.157313108444214
Validation loss: 2.201725016037623

Epoch: 5| Step: 3
Training loss: 0.8929792642593384
Validation loss: 2.1945258577664695

Epoch: 5| Step: 4
Training loss: 2.3330342769622803
Validation loss: 2.2150681416193643

Epoch: 5| Step: 5
Training loss: 1.1972814798355103
Validation loss: 2.2200537820657096

Epoch: 5| Step: 6
Training loss: 2.297306776046753
Validation loss: 2.2335536976655326

Epoch: 5| Step: 7
Training loss: 1.1511929035186768
Validation loss: 2.2601773937543235

Epoch: 5| Step: 8
Training loss: 1.145081639289856
Validation loss: 2.2643495996793113

Epoch: 5| Step: 9
Training loss: 1.1308929920196533
Validation loss: 2.255768616994222

Epoch: 5| Step: 10
Training loss: 1.0185829401016235
Validation loss: 2.296418065826098

Epoch: 5| Step: 11
Training loss: 1.5385724306106567
Validation loss: 2.2306728065013885

Epoch: 346| Step: 0
Training loss: 1.4072110652923584
Validation loss: 2.291382610797882

Epoch: 5| Step: 1
Training loss: 0.881120502948761
Validation loss: 2.2763613810141883

Epoch: 5| Step: 2
Training loss: 2.001106023788452
Validation loss: 2.2215113987525306

Epoch: 5| Step: 3
Training loss: 1.3055166006088257
Validation loss: 2.217303400238355

Epoch: 5| Step: 4
Training loss: 1.1718699932098389
Validation loss: 2.1946206192175546

Epoch: 5| Step: 5
Training loss: 1.292974591255188
Validation loss: 2.2058988511562347

Epoch: 5| Step: 6
Training loss: 1.5390647649765015
Validation loss: 2.1790318389733634

Epoch: 5| Step: 7
Training loss: 1.9633550643920898
Validation loss: 2.183263972401619

Epoch: 5| Step: 8
Training loss: 1.2295538187026978
Validation loss: 2.166258285442988

Epoch: 5| Step: 9
Training loss: 1.7321159839630127
Validation loss: 2.197252929210663

Epoch: 5| Step: 10
Training loss: 1.0912562608718872
Validation loss: 2.2178630381822586

Epoch: 5| Step: 11
Training loss: 2.0741798877716064
Validation loss: 2.244631270567576

Epoch: 347| Step: 0
Training loss: 1.3075979948043823
Validation loss: 2.2721018393834433

Epoch: 5| Step: 1
Training loss: 1.3859996795654297
Validation loss: 2.279030149181684

Epoch: 5| Step: 2
Training loss: 1.8127658367156982
Validation loss: 2.2851422925790152

Epoch: 5| Step: 3
Training loss: 1.7088991403579712
Validation loss: 2.2539934615294137

Epoch: 5| Step: 4
Training loss: 1.8722116947174072
Validation loss: 2.25452454884847

Epoch: 5| Step: 5
Training loss: 1.0437400341033936
Validation loss: 2.27035990357399

Epoch: 5| Step: 6
Training loss: 1.0835195779800415
Validation loss: 2.2496579935153327

Epoch: 5| Step: 7
Training loss: 1.2683078050613403
Validation loss: 2.222189779082934

Epoch: 5| Step: 8
Training loss: 1.6186081171035767
Validation loss: 2.235342135032018

Epoch: 5| Step: 9
Training loss: 1.1505712270736694
Validation loss: 2.2211587329705558

Epoch: 5| Step: 10
Training loss: 1.1515839099884033
Validation loss: 2.2798296014467874

Epoch: 5| Step: 11
Training loss: 1.6737359762191772
Validation loss: 2.2744160592556

Epoch: 348| Step: 0
Training loss: 1.4266644716262817
Validation loss: 2.2407843271891275

Epoch: 5| Step: 1
Training loss: 1.9470789432525635
Validation loss: 2.2957668403784433

Epoch: 5| Step: 2
Training loss: 2.3777501583099365
Validation loss: 2.288422887523969

Epoch: 5| Step: 3
Training loss: 1.5166285037994385
Validation loss: 2.2937702735265098

Epoch: 5| Step: 4
Training loss: 1.0429059267044067
Validation loss: 2.243672624230385

Epoch: 5| Step: 5
Training loss: 0.7948037385940552
Validation loss: 2.223702162504196

Epoch: 5| Step: 6
Training loss: 1.535668134689331
Validation loss: 2.2495659490426383

Epoch: 5| Step: 7
Training loss: 1.1644604206085205
Validation loss: 2.2320766548315683

Epoch: 5| Step: 8
Training loss: 1.2252782583236694
Validation loss: 2.225475917259852

Epoch: 5| Step: 9
Training loss: 1.5659607648849487
Validation loss: 2.2138360291719437

Epoch: 5| Step: 10
Training loss: 1.1910876035690308
Validation loss: 2.216560959815979

Epoch: 5| Step: 11
Training loss: 1.5544886589050293
Validation loss: 2.20015541712443

Epoch: 349| Step: 0
Training loss: 1.2402980327606201
Validation loss: 2.2089893917242684

Epoch: 5| Step: 1
Training loss: 1.2463624477386475
Validation loss: 2.211754083633423

Epoch: 5| Step: 2
Training loss: 1.5363969802856445
Validation loss: 2.2049350490172706

Epoch: 5| Step: 3
Training loss: 1.1804068088531494
Validation loss: 2.2110127607981362

Epoch: 5| Step: 4
Training loss: 1.3186930418014526
Validation loss: 2.2406165103117623

Epoch: 5| Step: 5
Training loss: 1.5651929378509521
Validation loss: 2.2405222058296204

Epoch: 5| Step: 6
Training loss: 2.2081220149993896
Validation loss: 2.2681409617265067

Epoch: 5| Step: 7
Training loss: 1.2547409534454346
Validation loss: 2.3028664688269296

Epoch: 5| Step: 8
Training loss: 1.4124034643173218
Validation loss: 2.280124306678772

Epoch: 5| Step: 9
Training loss: 1.3644797801971436
Validation loss: 2.2630391865968704

Epoch: 5| Step: 10
Training loss: 1.7029154300689697
Validation loss: 2.2448548128207526

Epoch: 5| Step: 11
Training loss: 1.6536449193954468
Validation loss: 2.229341725508372

Epoch: 350| Step: 0
Training loss: 1.2780532836914062
Validation loss: 2.1888510088125863

Epoch: 5| Step: 1
Training loss: 1.3105404376983643
Validation loss: 2.2094443440437317

Epoch: 5| Step: 2
Training loss: 0.9270588755607605
Validation loss: 2.2047396252552667

Epoch: 5| Step: 3
Training loss: 1.9453461170196533
Validation loss: 2.1692398885885873

Epoch: 5| Step: 4
Training loss: 1.0752345323562622
Validation loss: 2.207101821899414

Epoch: 5| Step: 5
Training loss: 1.2845180034637451
Validation loss: 2.191140075524648

Epoch: 5| Step: 6
Training loss: 1.476934552192688
Validation loss: 2.182572881380717

Epoch: 5| Step: 7
Training loss: 1.7931854724884033
Validation loss: 2.180506557226181

Epoch: 5| Step: 8
Training loss: 1.6353269815444946
Validation loss: 2.1889504939317703

Epoch: 5| Step: 9
Training loss: 1.1955747604370117
Validation loss: 2.1979472736517587

Epoch: 5| Step: 10
Training loss: 1.2489712238311768
Validation loss: 2.209892729918162

Epoch: 5| Step: 11
Training loss: 2.5017971992492676
Validation loss: 2.200719619790713

Epoch: 351| Step: 0
Training loss: 0.8468595743179321
Validation loss: 2.224658747514089

Epoch: 5| Step: 1
Training loss: 1.620257019996643
Validation loss: 2.1993967493375144

Epoch: 5| Step: 2
Training loss: 1.2268352508544922
Validation loss: 2.1988550623257956

Epoch: 5| Step: 3
Training loss: 1.4533954858779907
Validation loss: 2.2156625390052795

Epoch: 5| Step: 4
Training loss: 0.938983142375946
Validation loss: 2.235322972138723

Epoch: 5| Step: 5
Training loss: 1.7791954278945923
Validation loss: 2.2301688541968665

Epoch: 5| Step: 6
Training loss: 1.951475739479065
Validation loss: 2.2305824955304465

Epoch: 5| Step: 7
Training loss: 1.465721845626831
Validation loss: 2.237126335501671

Epoch: 5| Step: 8
Training loss: 1.1505171060562134
Validation loss: 2.18278602262338

Epoch: 5| Step: 9
Training loss: 1.0795629024505615
Validation loss: 2.222819685935974

Epoch: 5| Step: 10
Training loss: 1.5936139822006226
Validation loss: 2.202092930674553

Epoch: 5| Step: 11
Training loss: 1.7880287170410156
Validation loss: 2.1928766667842865

Epoch: 352| Step: 0
Training loss: 1.3454885482788086
Validation loss: 2.1946403980255127

Epoch: 5| Step: 1
Training loss: 1.8600132465362549
Validation loss: 2.2172819475332894

Epoch: 5| Step: 2
Training loss: 1.3370109796524048
Validation loss: 2.1989903251330056

Epoch: 5| Step: 3
Training loss: 2.2069835662841797
Validation loss: 2.1971962054570517

Epoch: 5| Step: 4
Training loss: 1.7197567224502563
Validation loss: 2.239160572489103

Epoch: 5| Step: 5
Training loss: 1.2290903329849243
Validation loss: 2.253284032146136

Epoch: 5| Step: 6
Training loss: 1.1150437593460083
Validation loss: 2.2210363149642944

Epoch: 5| Step: 7
Training loss: 1.07328200340271
Validation loss: 2.209301690260569

Epoch: 5| Step: 8
Training loss: 0.9846729040145874
Validation loss: 2.2318453590075173

Epoch: 5| Step: 9
Training loss: 1.1592622995376587
Validation loss: 2.225477640827497

Epoch: 5| Step: 10
Training loss: 1.4550981521606445
Validation loss: 2.240397890408834

Epoch: 5| Step: 11
Training loss: 0.817744255065918
Validation loss: 2.228754078348478

Epoch: 353| Step: 0
Training loss: 1.0473638772964478
Validation loss: 2.2322517385085425

Epoch: 5| Step: 1
Training loss: 1.1948000192642212
Validation loss: 2.2086797753969827

Epoch: 5| Step: 2
Training loss: 1.2821855545043945
Validation loss: 2.2048824528853097

Epoch: 5| Step: 3
Training loss: 1.4080196619033813
Validation loss: 2.211183408896128

Epoch: 5| Step: 4
Training loss: 1.2058765888214111
Validation loss: 2.1734537929296494

Epoch: 5| Step: 5
Training loss: 1.4919841289520264
Validation loss: 2.185552423199018

Epoch: 5| Step: 6
Training loss: 1.5105136632919312
Validation loss: 2.214204470316569

Epoch: 5| Step: 7
Training loss: 1.391224980354309
Validation loss: 2.204053441683451

Epoch: 5| Step: 8
Training loss: 1.6151838302612305
Validation loss: 2.2187434136867523

Epoch: 5| Step: 9
Training loss: 1.1510286331176758
Validation loss: 2.2144783387581506

Epoch: 5| Step: 10
Training loss: 1.7861661911010742
Validation loss: 2.1956227918465934

Epoch: 5| Step: 11
Training loss: 0.9063510894775391
Validation loss: 2.1905155777931213

Epoch: 354| Step: 0
Training loss: 0.9254692792892456
Validation loss: 2.2480261524518332

Epoch: 5| Step: 1
Training loss: 1.5510468482971191
Validation loss: 2.21881757179896

Epoch: 5| Step: 2
Training loss: 1.4155751466751099
Validation loss: 2.2512342681487403

Epoch: 5| Step: 3
Training loss: 1.7553514242172241
Validation loss: 2.2366140683492026

Epoch: 5| Step: 4
Training loss: 0.8887201547622681
Validation loss: 2.208305840690931

Epoch: 5| Step: 5
Training loss: 1.2617257833480835
Validation loss: 2.215687870979309

Epoch: 5| Step: 6
Training loss: 2.0471622943878174
Validation loss: 2.2191758155822754

Epoch: 5| Step: 7
Training loss: 1.1979180574417114
Validation loss: 2.2396996219952903

Epoch: 5| Step: 8
Training loss: 1.3306379318237305
Validation loss: 2.202675372362137

Epoch: 5| Step: 9
Training loss: 1.3493071794509888
Validation loss: 2.2027075042327247

Epoch: 5| Step: 10
Training loss: 1.8353207111358643
Validation loss: 2.187383621931076

Epoch: 5| Step: 11
Training loss: 0.6763476133346558
Validation loss: 2.220977485179901

Epoch: 355| Step: 0
Training loss: 1.4804304838180542
Validation loss: 2.2541855573654175

Epoch: 5| Step: 1
Training loss: 1.0139811038970947
Validation loss: 2.223770499229431

Epoch: 5| Step: 2
Training loss: 1.177082896232605
Validation loss: 2.2180443356434503

Epoch: 5| Step: 3
Training loss: 1.27468740940094
Validation loss: 2.2350302835305533

Epoch: 5| Step: 4
Training loss: 1.3816742897033691
Validation loss: 2.239325910806656

Epoch: 5| Step: 5
Training loss: 1.2112092971801758
Validation loss: 2.2353683908780417

Epoch: 5| Step: 6
Training loss: 1.2674064636230469
Validation loss: 2.2436380982398987

Epoch: 5| Step: 7
Training loss: 1.6698354482650757
Validation loss: 2.2310243248939514

Epoch: 5| Step: 8
Training loss: 2.0761208534240723
Validation loss: 2.217084358135859

Epoch: 5| Step: 9
Training loss: 1.7203937768936157
Validation loss: 2.200045426686605

Epoch: 5| Step: 10
Training loss: 1.1409857273101807
Validation loss: 2.2069057623545327

Epoch: 5| Step: 11
Training loss: 0.8936605453491211
Validation loss: 2.1998238414525986

Epoch: 356| Step: 0
Training loss: 0.8780685663223267
Validation loss: 2.24367219209671

Epoch: 5| Step: 1
Training loss: 1.4682996273040771
Validation loss: 2.1847274204095206

Epoch: 5| Step: 2
Training loss: 2.025790214538574
Validation loss: 2.186089148124059

Epoch: 5| Step: 3
Training loss: 1.0528672933578491
Validation loss: 2.219199150800705

Epoch: 5| Step: 4
Training loss: 1.6177924871444702
Validation loss: 2.227412795027097

Epoch: 5| Step: 5
Training loss: 1.8546125888824463
Validation loss: 2.2012548595666885

Epoch: 5| Step: 6
Training loss: 1.2375328540802002
Validation loss: 2.2318472067515054

Epoch: 5| Step: 7
Training loss: 0.7225164175033569
Validation loss: 2.224890614549319

Epoch: 5| Step: 8
Training loss: 1.3920422792434692
Validation loss: 2.25009752313296

Epoch: 5| Step: 9
Training loss: 1.2074880599975586
Validation loss: 2.2084830602010093

Epoch: 5| Step: 10
Training loss: 1.4029055833816528
Validation loss: 2.2412652919689813

Epoch: 5| Step: 11
Training loss: 1.9452166557312012
Validation loss: 2.244130924344063

Epoch: 357| Step: 0
Training loss: 1.2008819580078125
Validation loss: 2.209066088000933

Epoch: 5| Step: 1
Training loss: 0.9021835327148438
Validation loss: 2.235153396924337

Epoch: 5| Step: 2
Training loss: 1.3648803234100342
Validation loss: 2.2182617783546448

Epoch: 5| Step: 3
Training loss: 1.729357123374939
Validation loss: 2.1885546346505484

Epoch: 5| Step: 4
Training loss: 0.8823760151863098
Validation loss: 2.205331881841024

Epoch: 5| Step: 5
Training loss: 1.1917803287506104
Validation loss: 2.198791335026423

Epoch: 5| Step: 6
Training loss: 1.7271020412445068
Validation loss: 2.211302394668261

Epoch: 5| Step: 7
Training loss: 1.2409931421279907
Validation loss: 2.238461414972941

Epoch: 5| Step: 8
Training loss: 1.2823433876037598
Validation loss: 2.182443047563235

Epoch: 5| Step: 9
Training loss: 2.102442502975464
Validation loss: 2.1991343200206757

Epoch: 5| Step: 10
Training loss: 1.8362985849380493
Validation loss: 2.2123754719893136

Epoch: 5| Step: 11
Training loss: 2.8120884895324707
Validation loss: 2.2063273191452026

Epoch: 358| Step: 0
Training loss: 1.2066112756729126
Validation loss: 2.205486332376798

Epoch: 5| Step: 1
Training loss: 1.2678663730621338
Validation loss: 2.209291011095047

Epoch: 5| Step: 2
Training loss: 1.14133882522583
Validation loss: 2.1769170661767325

Epoch: 5| Step: 3
Training loss: 2.055428981781006
Validation loss: 2.2220561603705087

Epoch: 5| Step: 4
Training loss: 1.7419618368148804
Validation loss: 2.18686613937219

Epoch: 5| Step: 5
Training loss: 1.4959712028503418
Validation loss: 2.195740948120753

Epoch: 5| Step: 6
Training loss: 1.8047599792480469
Validation loss: 2.226174717148145

Epoch: 5| Step: 7
Training loss: 1.5335791110992432
Validation loss: 2.2101048479477563

Epoch: 5| Step: 8
Training loss: 1.1286309957504272
Validation loss: 2.1996702750523887

Epoch: 5| Step: 9
Training loss: 1.4332811832427979
Validation loss: 2.1803813576698303

Epoch: 5| Step: 10
Training loss: 0.904034435749054
Validation loss: 2.2244892368714013

Epoch: 5| Step: 11
Training loss: 0.7807334661483765
Validation loss: 2.207906802495321

Epoch: 359| Step: 0
Training loss: 1.3979510068893433
Validation loss: 2.2325847297906876

Epoch: 5| Step: 1
Training loss: 1.3803317546844482
Validation loss: 2.217258701721827

Epoch: 5| Step: 2
Training loss: 2.04337739944458
Validation loss: 2.1966418524583182

Epoch: 5| Step: 3
Training loss: 1.095089316368103
Validation loss: 2.210394188761711

Epoch: 5| Step: 4
Training loss: 1.446359634399414
Validation loss: 2.230799982945124

Epoch: 5| Step: 5
Training loss: 1.2924178838729858
Validation loss: 2.2442650695641837

Epoch: 5| Step: 6
Training loss: 1.9942032098770142
Validation loss: 2.225248927871386

Epoch: 5| Step: 7
Training loss: 1.2569153308868408
Validation loss: 2.228277787566185

Epoch: 5| Step: 8
Training loss: 1.6131114959716797
Validation loss: 2.183972309033076

Epoch: 5| Step: 9
Training loss: 1.536510705947876
Validation loss: 2.1986885567506156

Epoch: 5| Step: 10
Training loss: 0.8520215153694153
Validation loss: 2.175807739297549

Epoch: 5| Step: 11
Training loss: 1.2983722686767578
Validation loss: 2.1851525704065957

Epoch: 360| Step: 0
Training loss: 1.577702283859253
Validation loss: 2.1504523853460946

Epoch: 5| Step: 1
Training loss: 1.368186593055725
Validation loss: 2.124715348084768

Epoch: 5| Step: 2
Training loss: 0.6451732516288757
Validation loss: 2.1630696604649224

Epoch: 5| Step: 3
Training loss: 1.7183479070663452
Validation loss: 2.1548206210136414

Epoch: 5| Step: 4
Training loss: 1.3642075061798096
Validation loss: 2.184219499429067

Epoch: 5| Step: 5
Training loss: 1.4052003622055054
Validation loss: 2.1821592251459756

Epoch: 5| Step: 6
Training loss: 1.0979639291763306
Validation loss: 2.1926917880773544

Epoch: 5| Step: 7
Training loss: 1.28257155418396
Validation loss: 2.1940523783365884

Epoch: 5| Step: 8
Training loss: 1.8905388116836548
Validation loss: 2.1930398444334664

Epoch: 5| Step: 9
Training loss: 1.6187232732772827
Validation loss: 2.2053809463977814

Epoch: 5| Step: 10
Training loss: 1.5818450450897217
Validation loss: 2.210293486714363

Epoch: 5| Step: 11
Training loss: 1.2024298906326294
Validation loss: 2.225493768850962

Epoch: 361| Step: 0
Training loss: 1.0336674451828003
Validation loss: 2.231517935792605

Epoch: 5| Step: 1
Training loss: 1.02972412109375
Validation loss: 2.23064993818601

Epoch: 5| Step: 2
Training loss: 1.532325029373169
Validation loss: 2.2207725594441095

Epoch: 5| Step: 3
Training loss: 1.3527586460113525
Validation loss: 2.250070924560229

Epoch: 5| Step: 4
Training loss: 1.5090630054473877
Validation loss: 2.2402357707420983

Epoch: 5| Step: 5
Training loss: 1.352677822113037
Validation loss: 2.2487476468086243

Epoch: 5| Step: 6
Training loss: 1.246600866317749
Validation loss: 2.2330280443032584

Epoch: 5| Step: 7
Training loss: 1.3217142820358276
Validation loss: 2.2523317635059357

Epoch: 5| Step: 8
Training loss: 1.3993942737579346
Validation loss: 2.2062691748142242

Epoch: 5| Step: 9
Training loss: 1.1696864366531372
Validation loss: 2.2297624250253043

Epoch: 5| Step: 10
Training loss: 1.4143164157867432
Validation loss: 2.2314805388450623

Epoch: 5| Step: 11
Training loss: 3.405637264251709
Validation loss: 2.2374948114156723

Epoch: 362| Step: 0
Training loss: 1.5536178350448608
Validation loss: 2.215319355328878

Epoch: 5| Step: 1
Training loss: 0.8307327032089233
Validation loss: 2.214437966545423

Epoch: 5| Step: 2
Training loss: 1.466812014579773
Validation loss: 2.187500382463137

Epoch: 5| Step: 3
Training loss: 1.7110912799835205
Validation loss: 2.2429311672846475

Epoch: 5| Step: 4
Training loss: 1.3939664363861084
Validation loss: 2.246156965692838

Epoch: 5| Step: 5
Training loss: 1.034475564956665
Validation loss: 2.2207156866788864

Epoch: 5| Step: 6
Training loss: 1.214519739151001
Validation loss: 2.244754667083422

Epoch: 5| Step: 7
Training loss: 1.2271535396575928
Validation loss: 2.258594498038292

Epoch: 5| Step: 8
Training loss: 1.8643699884414673
Validation loss: 2.265865703423818

Epoch: 5| Step: 9
Training loss: 0.765026330947876
Validation loss: 2.276159723599752

Epoch: 5| Step: 10
Training loss: 1.521645426750183
Validation loss: 2.285876671473185

Epoch: 5| Step: 11
Training loss: 1.2868237495422363
Validation loss: 2.2629863619804382

Epoch: 363| Step: 0
Training loss: 1.5016919374465942
Validation loss: 2.2370618979136148

Epoch: 5| Step: 1
Training loss: 1.3044540882110596
Validation loss: 2.265637775262197

Epoch: 5| Step: 2
Training loss: 1.2947181463241577
Validation loss: 2.2677876899639764

Epoch: 5| Step: 3
Training loss: 1.8630154132843018
Validation loss: 2.2672525346279144

Epoch: 5| Step: 4
Training loss: 1.4304826259613037
Validation loss: 2.2525405138731003

Epoch: 5| Step: 5
Training loss: 1.308671236038208
Validation loss: 2.214515298604965

Epoch: 5| Step: 6
Training loss: 1.640641450881958
Validation loss: 2.238246738910675

Epoch: 5| Step: 7
Training loss: 1.1979155540466309
Validation loss: 2.238562991221746

Epoch: 5| Step: 8
Training loss: 1.5899569988250732
Validation loss: 2.1875691364208856

Epoch: 5| Step: 9
Training loss: 1.5758031606674194
Validation loss: 2.192855417728424

Epoch: 5| Step: 10
Training loss: 1.1320455074310303
Validation loss: 2.188865974545479

Epoch: 5| Step: 11
Training loss: 0.21739709377288818
Validation loss: 2.187568540374438

Epoch: 364| Step: 0
Training loss: 1.8041346073150635
Validation loss: 2.1763190776109695

Epoch: 5| Step: 1
Training loss: 1.8823648691177368
Validation loss: 2.191826562086741

Epoch: 5| Step: 2
Training loss: 0.707643985748291
Validation loss: 2.167825778325399

Epoch: 5| Step: 3
Training loss: 1.1152722835540771
Validation loss: 2.1995760103066764

Epoch: 5| Step: 4
Training loss: 1.5642889738082886
Validation loss: 2.212279051542282

Epoch: 5| Step: 5
Training loss: 1.3023943901062012
Validation loss: 2.2263090511163077

Epoch: 5| Step: 6
Training loss: 1.253868818283081
Validation loss: 2.221094767252604

Epoch: 5| Step: 7
Training loss: 1.607353925704956
Validation loss: 2.241338695089022

Epoch: 5| Step: 8
Training loss: 1.2069990634918213
Validation loss: 2.235363706946373

Epoch: 5| Step: 9
Training loss: 0.9625617861747742
Validation loss: 2.2438645362854004

Epoch: 5| Step: 10
Training loss: 1.39073646068573
Validation loss: 2.205581784248352

Epoch: 5| Step: 11
Training loss: 1.578536033630371
Validation loss: 2.2224282373984656

Epoch: 365| Step: 0
Training loss: 1.1917321681976318
Validation loss: 2.2313526620467505

Epoch: 5| Step: 1
Training loss: 1.0691478252410889
Validation loss: 2.2365738650163016

Epoch: 5| Step: 2
Training loss: 1.0656547546386719
Validation loss: 2.2119009594122567

Epoch: 5| Step: 3
Training loss: 1.4077210426330566
Validation loss: 2.2363158961137137

Epoch: 5| Step: 4
Training loss: 1.2906192541122437
Validation loss: 2.2120301822821298

Epoch: 5| Step: 5
Training loss: 0.9428888559341431
Validation loss: 2.186953842639923

Epoch: 5| Step: 6
Training loss: 1.5328657627105713
Validation loss: 2.2263905902703605

Epoch: 5| Step: 7
Training loss: 1.8171859979629517
Validation loss: 2.2184345622857413

Epoch: 5| Step: 8
Training loss: 2.0075414180755615
Validation loss: 2.220693697532018

Epoch: 5| Step: 9
Training loss: 1.359163522720337
Validation loss: 2.2647025088469186

Epoch: 5| Step: 10
Training loss: 1.5103821754455566
Validation loss: 2.2342466662327447

Epoch: 5| Step: 11
Training loss: 0.7180633544921875
Validation loss: 2.2361086308956146

Epoch: 366| Step: 0
Training loss: 1.2571839094161987
Validation loss: 2.2442243844270706

Epoch: 5| Step: 1
Training loss: 1.2156492471694946
Validation loss: 2.2647687445084252

Epoch: 5| Step: 2
Training loss: 0.8452063798904419
Validation loss: 2.2596950829029083

Epoch: 5| Step: 3
Training loss: 1.0153669118881226
Validation loss: 2.3021054367224374

Epoch: 5| Step: 4
Training loss: 1.296930193901062
Validation loss: 2.296535780032476

Epoch: 5| Step: 5
Training loss: 1.2164899110794067
Validation loss: 2.263059372703234

Epoch: 5| Step: 6
Training loss: 1.3715934753417969
Validation loss: 2.240380048751831

Epoch: 5| Step: 7
Training loss: 2.016411542892456
Validation loss: 2.2303505738576255

Epoch: 5| Step: 8
Training loss: 1.7722442150115967
Validation loss: 2.182817116379738

Epoch: 5| Step: 9
Training loss: 1.7027593851089478
Validation loss: 2.2387983004252114

Epoch: 5| Step: 10
Training loss: 2.1217432022094727
Validation loss: 2.2076577246189117

Epoch: 5| Step: 11
Training loss: 1.6299567222595215
Validation loss: 2.2188527981440225

Epoch: 367| Step: 0
Training loss: 0.8829914331436157
Validation loss: 2.2506751666466394

Epoch: 5| Step: 1
Training loss: 1.1323297023773193
Validation loss: 2.279606600602468

Epoch: 5| Step: 2
Training loss: 1.8247390985488892
Validation loss: 2.257941077152888

Epoch: 5| Step: 3
Training loss: 1.5732715129852295
Validation loss: 2.2750289936860404

Epoch: 5| Step: 4
Training loss: 1.2589139938354492
Validation loss: 2.3032861153284707

Epoch: 5| Step: 5
Training loss: 0.9562598466873169
Validation loss: 2.2553634891907373

Epoch: 5| Step: 6
Training loss: 0.9592334032058716
Validation loss: 2.2805160929759345

Epoch: 5| Step: 7
Training loss: 2.001028299331665
Validation loss: 2.247754861911138

Epoch: 5| Step: 8
Training loss: 1.8900947570800781
Validation loss: 2.3137093782424927

Epoch: 5| Step: 9
Training loss: 0.9591811299324036
Validation loss: 2.307922144730886

Epoch: 5| Step: 10
Training loss: 1.5282799005508423
Validation loss: 2.282988121112188

Epoch: 5| Step: 11
Training loss: 1.5233323574066162
Validation loss: 2.2990388522545495

Epoch: 368| Step: 0
Training loss: 1.4628711938858032
Validation loss: 2.299541726708412

Epoch: 5| Step: 1
Training loss: 1.3328101634979248
Validation loss: 2.29411352177461

Epoch: 5| Step: 2
Training loss: 1.4924519062042236
Validation loss: 2.2974794606367746

Epoch: 5| Step: 3
Training loss: 1.1654460430145264
Validation loss: 2.281573568781217

Epoch: 5| Step: 4
Training loss: 1.3918367624282837
Validation loss: 2.2454965710639954

Epoch: 5| Step: 5
Training loss: 1.2461268901824951
Validation loss: 2.2395226756731668

Epoch: 5| Step: 6
Training loss: 1.5588469505310059
Validation loss: 2.225884050130844

Epoch: 5| Step: 7
Training loss: 1.1560509204864502
Validation loss: 2.236028239130974

Epoch: 5| Step: 8
Training loss: 1.077771544456482
Validation loss: 2.2381741553545

Epoch: 5| Step: 9
Training loss: 1.9381897449493408
Validation loss: 2.2114294370015464

Epoch: 5| Step: 10
Training loss: 1.4104359149932861
Validation loss: 2.2121232648690543

Epoch: 5| Step: 11
Training loss: 1.243169903755188
Validation loss: 2.206745892763138

Epoch: 369| Step: 0
Training loss: 1.6847600936889648
Validation loss: 2.2095045149326324

Epoch: 5| Step: 1
Training loss: 1.3975130319595337
Validation loss: 2.2388119995594025

Epoch: 5| Step: 2
Training loss: 1.4139153957366943
Validation loss: 2.2212755729754767

Epoch: 5| Step: 3
Training loss: 1.0966988801956177
Validation loss: 2.2068518896897635

Epoch: 5| Step: 4
Training loss: 0.9824197888374329
Validation loss: 2.2288865645726523

Epoch: 5| Step: 5
Training loss: 0.7745869755744934
Validation loss: 2.2096183697382608

Epoch: 5| Step: 6
Training loss: 1.9145011901855469
Validation loss: 2.195434878269831

Epoch: 5| Step: 7
Training loss: 1.3918317556381226
Validation loss: 2.264021580417951

Epoch: 5| Step: 8
Training loss: 1.1088178157806396
Validation loss: 2.236848011612892

Epoch: 5| Step: 9
Training loss: 1.2630927562713623
Validation loss: 2.236977368593216

Epoch: 5| Step: 10
Training loss: 1.4055882692337036
Validation loss: 2.2358195732037225

Epoch: 5| Step: 11
Training loss: 2.8727385997772217
Validation loss: 2.239079217116038

Epoch: 370| Step: 0
Training loss: 1.4465868473052979
Validation loss: 2.2080946813027063

Epoch: 5| Step: 1
Training loss: 1.4856359958648682
Validation loss: 2.2296114365259805

Epoch: 5| Step: 2
Training loss: 1.5947437286376953
Validation loss: 2.162992109855016

Epoch: 5| Step: 3
Training loss: 1.745490312576294
Validation loss: 2.2261708130439124

Epoch: 5| Step: 4
Training loss: 1.158929467201233
Validation loss: 2.2132677137851715

Epoch: 5| Step: 5
Training loss: 1.528719186782837
Validation loss: 2.215634380777677

Epoch: 5| Step: 6
Training loss: 1.0924453735351562
Validation loss: 2.2230701943238578

Epoch: 5| Step: 7
Training loss: 1.2727024555206299
Validation loss: 2.20474844177564

Epoch: 5| Step: 8
Training loss: 1.3278884887695312
Validation loss: 2.249175548553467

Epoch: 5| Step: 9
Training loss: 1.183496356010437
Validation loss: 2.2268469532330832

Epoch: 5| Step: 10
Training loss: 1.2641690969467163
Validation loss: 2.223433087269465

Epoch: 5| Step: 11
Training loss: 1.6312485933303833
Validation loss: 2.2300973335901895

Epoch: 371| Step: 0
Training loss: 1.1211603879928589
Validation loss: 2.2062660406033197

Epoch: 5| Step: 1
Training loss: 1.2861039638519287
Validation loss: 2.2180705666542053

Epoch: 5| Step: 2
Training loss: 1.103179693222046
Validation loss: 2.204376459121704

Epoch: 5| Step: 3
Training loss: 1.3955142498016357
Validation loss: 2.1765043139457703

Epoch: 5| Step: 4
Training loss: 1.0591533184051514
Validation loss: 2.183502326409022

Epoch: 5| Step: 5
Training loss: 1.1811497211456299
Validation loss: 2.1670659631490707

Epoch: 5| Step: 6
Training loss: 1.3158743381500244
Validation loss: 2.1881708403428397

Epoch: 5| Step: 7
Training loss: 1.5647072792053223
Validation loss: 2.156656409303347

Epoch: 5| Step: 8
Training loss: 1.2782313823699951
Validation loss: 2.1790292312701545

Epoch: 5| Step: 9
Training loss: 1.4546211957931519
Validation loss: 2.167959118882815

Epoch: 5| Step: 10
Training loss: 1.4256985187530518
Validation loss: 2.184901093443235

Epoch: 5| Step: 11
Training loss: 2.9765071868896484
Validation loss: 2.175314669807752

Epoch: 372| Step: 0
Training loss: 1.8418251276016235
Validation loss: 2.1796844750642776

Epoch: 5| Step: 1
Training loss: 1.0525150299072266
Validation loss: 2.1751242528359094

Epoch: 5| Step: 2
Training loss: 1.1484864950180054
Validation loss: 2.177002345522245

Epoch: 5| Step: 3
Training loss: 1.3470737934112549
Validation loss: 2.1600272357463837

Epoch: 5| Step: 4
Training loss: 1.2352886199951172
Validation loss: 2.1682455986738205

Epoch: 5| Step: 5
Training loss: 0.8427181243896484
Validation loss: 2.158854524294535

Epoch: 5| Step: 6
Training loss: 1.7377941608428955
Validation loss: 2.1682733247677484

Epoch: 5| Step: 7
Training loss: 1.4300693273544312
Validation loss: 2.180768887201945

Epoch: 5| Step: 8
Training loss: 1.5023279190063477
Validation loss: 2.1933785577615104

Epoch: 5| Step: 9
Training loss: 1.5669924020767212
Validation loss: 2.1843836307525635

Epoch: 5| Step: 10
Training loss: 1.5999914407730103
Validation loss: 2.1908267438411713

Epoch: 5| Step: 11
Training loss: 1.4903454780578613
Validation loss: 2.1824219077825546

Epoch: 373| Step: 0
Training loss: 1.6628749370574951
Validation loss: 2.191724290450414

Epoch: 5| Step: 1
Training loss: 1.4798351526260376
Validation loss: 2.1851461082696915

Epoch: 5| Step: 2
Training loss: 1.7232685089111328
Validation loss: 2.2310661226511

Epoch: 5| Step: 3
Training loss: 1.4959861040115356
Validation loss: 2.200609192252159

Epoch: 5| Step: 4
Training loss: 0.9009130597114563
Validation loss: 2.1695282459259033

Epoch: 5| Step: 5
Training loss: 1.0101196765899658
Validation loss: 2.143858090043068

Epoch: 5| Step: 6
Training loss: 1.6898349523544312
Validation loss: 2.1939412554105124

Epoch: 5| Step: 7
Training loss: 1.82221257686615
Validation loss: 2.198176776369413

Epoch: 5| Step: 8
Training loss: 1.255932092666626
Validation loss: 2.1636778116226196

Epoch: 5| Step: 9
Training loss: 0.9631757736206055
Validation loss: 2.188046157360077

Epoch: 5| Step: 10
Training loss: 1.506028413772583
Validation loss: 2.1710645953814187

Epoch: 5| Step: 11
Training loss: 0.4844512939453125
Validation loss: 2.1780176063378653

Epoch: 374| Step: 0
Training loss: 1.2625812292099
Validation loss: 2.2133869926134744

Epoch: 5| Step: 1
Training loss: 0.9212645292282104
Validation loss: 2.1934964855511985

Epoch: 5| Step: 2
Training loss: 0.5146142244338989
Validation loss: 2.1586269636948905

Epoch: 5| Step: 3
Training loss: 2.095442533493042
Validation loss: 2.17057333389918

Epoch: 5| Step: 4
Training loss: 1.2844955921173096
Validation loss: 2.1663941144943237

Epoch: 5| Step: 5
Training loss: 1.1619364023208618
Validation loss: 2.1827688614527383

Epoch: 5| Step: 6
Training loss: 1.3354766368865967
Validation loss: 2.200530911485354

Epoch: 5| Step: 7
Training loss: 1.3964645862579346
Validation loss: 2.16718698044618

Epoch: 5| Step: 8
Training loss: 1.3396995067596436
Validation loss: 2.1817148377497992

Epoch: 5| Step: 9
Training loss: 1.7761898040771484
Validation loss: 2.1979055603345237

Epoch: 5| Step: 10
Training loss: 1.0034583806991577
Validation loss: 2.2007063130537667

Epoch: 5| Step: 11
Training loss: 2.709465742111206
Validation loss: 2.2278736730416617

Epoch: 375| Step: 0
Training loss: 1.2608379125595093
Validation loss: 2.202783157428106

Epoch: 5| Step: 1
Training loss: 2.3206138610839844
Validation loss: 2.230545068780581

Epoch: 5| Step: 2
Training loss: 0.7772767543792725
Validation loss: 2.2151238520940146

Epoch: 5| Step: 3
Training loss: 1.2450809478759766
Validation loss: 2.2357362707455954

Epoch: 5| Step: 4
Training loss: 0.8615524172782898
Validation loss: 2.2277600318193436

Epoch: 5| Step: 5
Training loss: 1.2571325302124023
Validation loss: 2.2609137197335563

Epoch: 5| Step: 6
Training loss: 1.1278798580169678
Validation loss: 2.208704392115275

Epoch: 5| Step: 7
Training loss: 1.0083351135253906
Validation loss: 2.237825413544973

Epoch: 5| Step: 8
Training loss: 1.4348076581954956
Validation loss: 2.192228446404139

Epoch: 5| Step: 9
Training loss: 1.9173080921173096
Validation loss: 2.2337531447410583

Epoch: 5| Step: 10
Training loss: 1.0564277172088623
Validation loss: 2.2287360380093255

Epoch: 5| Step: 11
Training loss: 2.4773576259613037
Validation loss: 2.2125320533911386

Epoch: 376| Step: 0
Training loss: 1.7793388366699219
Validation loss: 2.2370994687080383

Epoch: 5| Step: 1
Training loss: 1.3261961936950684
Validation loss: 2.218575651446978

Epoch: 5| Step: 2
Training loss: 1.4788795709609985
Validation loss: 2.202514116962751

Epoch: 5| Step: 3
Training loss: 0.7560502886772156
Validation loss: 2.2422527968883514

Epoch: 5| Step: 4
Training loss: 1.3709838390350342
Validation loss: 2.1868541737397513

Epoch: 5| Step: 5
Training loss: 0.759480893611908
Validation loss: 2.2265786031881967

Epoch: 5| Step: 6
Training loss: 1.248488187789917
Validation loss: 2.218875596920649

Epoch: 5| Step: 7
Training loss: 1.5010900497436523
Validation loss: 2.233832448720932

Epoch: 5| Step: 8
Training loss: 1.7311017513275146
Validation loss: 2.21622397005558

Epoch: 5| Step: 9
Training loss: 1.0412572622299194
Validation loss: 2.24114857117335

Epoch: 5| Step: 10
Training loss: 1.318196415901184
Validation loss: 2.2546846171220145

Epoch: 5| Step: 11
Training loss: 1.4892792701721191
Validation loss: 2.216272940238317

Epoch: 377| Step: 0
Training loss: 1.2861686944961548
Validation loss: 2.199787656466166

Epoch: 5| Step: 1
Training loss: 1.3814361095428467
Validation loss: 2.2428293178478875

Epoch: 5| Step: 2
Training loss: 0.8202251195907593
Validation loss: 2.1953664223353067

Epoch: 5| Step: 3
Training loss: 1.6367285251617432
Validation loss: 2.1953479597965875

Epoch: 5| Step: 4
Training loss: 0.8644299507141113
Validation loss: 2.236068914333979

Epoch: 5| Step: 5
Training loss: 0.9553041458129883
Validation loss: 2.216901108622551

Epoch: 5| Step: 6
Training loss: 0.8120460510253906
Validation loss: 2.219294955333074

Epoch: 5| Step: 7
Training loss: 2.1165666580200195
Validation loss: 2.1921268304189048

Epoch: 5| Step: 8
Training loss: 1.6826398372650146
Validation loss: 2.192187935113907

Epoch: 5| Step: 9
Training loss: 1.503200650215149
Validation loss: 2.204298903544744

Epoch: 5| Step: 10
Training loss: 1.200673222541809
Validation loss: 2.220331445336342

Epoch: 5| Step: 11
Training loss: 0.3237866759300232
Validation loss: 2.191931282480558

Epoch: 378| Step: 0
Training loss: 1.4226967096328735
Validation loss: 2.2302459478378296

Epoch: 5| Step: 1
Training loss: 1.2205007076263428
Validation loss: 2.218894382317861

Epoch: 5| Step: 2
Training loss: 1.85051691532135
Validation loss: 2.206373617053032

Epoch: 5| Step: 3
Training loss: 0.6338160037994385
Validation loss: 2.203680401047071

Epoch: 5| Step: 4
Training loss: 1.0083328485488892
Validation loss: 2.216478099425634

Epoch: 5| Step: 5
Training loss: 1.9412094354629517
Validation loss: 2.2177326530218124

Epoch: 5| Step: 6
Training loss: 1.0854889154434204
Validation loss: 2.2176288962364197

Epoch: 5| Step: 7
Training loss: 1.4716488122940063
Validation loss: 2.256344278653463

Epoch: 5| Step: 8
Training loss: 1.2150312662124634
Validation loss: 2.2198874155680337

Epoch: 5| Step: 9
Training loss: 1.4263678789138794
Validation loss: 2.2206536730130515

Epoch: 5| Step: 10
Training loss: 0.9399959444999695
Validation loss: 2.177522669235865

Epoch: 5| Step: 11
Training loss: 0.6623623371124268
Validation loss: 2.1828861782948175

Epoch: 379| Step: 0
Training loss: 1.0753810405731201
Validation loss: 2.2185298254092536

Epoch: 5| Step: 1
Training loss: 1.6404491662979126
Validation loss: 2.2133143643538156

Epoch: 5| Step: 2
Training loss: 1.648019552230835
Validation loss: 2.234563797712326

Epoch: 5| Step: 3
Training loss: 1.2249969244003296
Validation loss: 2.2263890306154885

Epoch: 5| Step: 4
Training loss: 1.4857804775238037
Validation loss: 2.226850455005964

Epoch: 5| Step: 5
Training loss: 1.099501371383667
Validation loss: 2.2394122978051505

Epoch: 5| Step: 6
Training loss: 1.2633823156356812
Validation loss: 2.232568065325419

Epoch: 5| Step: 7
Training loss: 1.3285938501358032
Validation loss: 2.218513617912928

Epoch: 5| Step: 8
Training loss: 1.43380868434906
Validation loss: 2.24809963007768

Epoch: 5| Step: 9
Training loss: 1.006679654121399
Validation loss: 2.2379334469636283

Epoch: 5| Step: 10
Training loss: 0.9532634019851685
Validation loss: 2.231544077396393

Epoch: 5| Step: 11
Training loss: 0.7008969783782959
Validation loss: 2.22813056409359

Epoch: 380| Step: 0
Training loss: 1.1487507820129395
Validation loss: 2.220275123914083

Epoch: 5| Step: 1
Training loss: 1.3614258766174316
Validation loss: 2.2279095202684402

Epoch: 5| Step: 2
Training loss: 1.002952218055725
Validation loss: 2.2275601625442505

Epoch: 5| Step: 3
Training loss: 0.81782066822052
Validation loss: 2.2407083213329315

Epoch: 5| Step: 4
Training loss: 1.0483201742172241
Validation loss: 2.1774338434139886

Epoch: 5| Step: 5
Training loss: 1.6175487041473389
Validation loss: 2.203263739744822

Epoch: 5| Step: 6
Training loss: 1.0343761444091797
Validation loss: 2.2044260750214257

Epoch: 5| Step: 7
Training loss: 1.2944124937057495
Validation loss: 2.176248997449875

Epoch: 5| Step: 8
Training loss: 1.7385050058364868
Validation loss: 2.2223758548498154

Epoch: 5| Step: 9
Training loss: 1.4269870519638062
Validation loss: 2.176117410262426

Epoch: 5| Step: 10
Training loss: 1.4496010541915894
Validation loss: 2.2078354259332023

Epoch: 5| Step: 11
Training loss: 0.5937432050704956
Validation loss: 2.2324256797631583

Epoch: 381| Step: 0
Training loss: 0.8951679468154907
Validation loss: 2.234117721517881

Epoch: 5| Step: 1
Training loss: 1.2671860456466675
Validation loss: 2.181450625260671

Epoch: 5| Step: 2
Training loss: 1.9455115795135498
Validation loss: 2.215343991915385

Epoch: 5| Step: 3
Training loss: 1.4791682958602905
Validation loss: 2.2006448805332184

Epoch: 5| Step: 4
Training loss: 1.0761733055114746
Validation loss: 2.207844987511635

Epoch: 5| Step: 5
Training loss: 0.8960396647453308
Validation loss: 2.2236510813236237

Epoch: 5| Step: 6
Training loss: 0.942338764667511
Validation loss: 2.2064275542894998

Epoch: 5| Step: 7
Training loss: 1.373228669166565
Validation loss: 2.195470631122589

Epoch: 5| Step: 8
Training loss: 1.100550889968872
Validation loss: 2.195683171351751

Epoch: 5| Step: 9
Training loss: 1.285123586654663
Validation loss: 2.2091615349054337

Epoch: 5| Step: 10
Training loss: 1.6057555675506592
Validation loss: 2.1935709565877914

Epoch: 5| Step: 11
Training loss: 0.7717305421829224
Validation loss: 2.2062785079081855

Epoch: 382| Step: 0
Training loss: 1.5414412021636963
Validation loss: 2.2291087607542672

Epoch: 5| Step: 1
Training loss: 0.6909797191619873
Validation loss: 2.222720111409823

Epoch: 5| Step: 2
Training loss: 1.333074927330017
Validation loss: 2.2225391815106073

Epoch: 5| Step: 3
Training loss: 0.7603190541267395
Validation loss: 2.183952813347181

Epoch: 5| Step: 4
Training loss: 1.1563962697982788
Validation loss: 2.1948727567990622

Epoch: 5| Step: 5
Training loss: 1.4212312698364258
Validation loss: 2.2051297426223755

Epoch: 5| Step: 6
Training loss: 1.0478336811065674
Validation loss: 2.1659482270479202

Epoch: 5| Step: 7
Training loss: 1.045714259147644
Validation loss: 2.191726808746656

Epoch: 5| Step: 8
Training loss: 1.389305830001831
Validation loss: 2.187989741563797

Epoch: 5| Step: 9
Training loss: 1.7938649654388428
Validation loss: 2.1684970408678055

Epoch: 5| Step: 10
Training loss: 1.884905457496643
Validation loss: 2.151760602990786

Epoch: 5| Step: 11
Training loss: 2.4614505767822266
Validation loss: 2.186632583538691

Epoch: 383| Step: 0
Training loss: 1.0608619451522827
Validation loss: 2.1756282498439155

Epoch: 5| Step: 1
Training loss: 1.4071848392486572
Validation loss: 2.2084625214338303

Epoch: 5| Step: 2
Training loss: 1.0636858940124512
Validation loss: 2.182354653875033

Epoch: 5| Step: 3
Training loss: 1.4960291385650635
Validation loss: 2.1522676795721054

Epoch: 5| Step: 4
Training loss: 1.0358941555023193
Validation loss: 2.1705897649129233

Epoch: 5| Step: 5
Training loss: 2.2320494651794434
Validation loss: 2.1652632504701614

Epoch: 5| Step: 6
Training loss: 1.6353797912597656
Validation loss: 2.1554393569628396

Epoch: 5| Step: 7
Training loss: 0.8524713516235352
Validation loss: 2.172491729259491

Epoch: 5| Step: 8
Training loss: 1.3398879766464233
Validation loss: 2.1506416698296866

Epoch: 5| Step: 9
Training loss: 1.2292559146881104
Validation loss: 2.1840275824069977

Epoch: 5| Step: 10
Training loss: 0.7769546508789062
Validation loss: 2.19851283232371

Epoch: 5| Step: 11
Training loss: 1.958418607711792
Validation loss: 2.166182021299998

Epoch: 384| Step: 0
Training loss: 0.9605507850646973
Validation loss: 2.1693312575419745

Epoch: 5| Step: 1
Training loss: 1.2430952787399292
Validation loss: 2.222484012444814

Epoch: 5| Step: 2
Training loss: 1.0390369892120361
Validation loss: 2.1763662844896317

Epoch: 5| Step: 3
Training loss: 1.346316933631897
Validation loss: 2.1914581855138144

Epoch: 5| Step: 4
Training loss: 1.1980628967285156
Validation loss: 2.1744465927282968

Epoch: 5| Step: 5
Training loss: 0.8705824017524719
Validation loss: 2.180750305453936

Epoch: 5| Step: 6
Training loss: 1.7040185928344727
Validation loss: 2.1847750693559647

Epoch: 5| Step: 7
Training loss: 0.8851562738418579
Validation loss: 2.188965544104576

Epoch: 5| Step: 8
Training loss: 1.5554864406585693
Validation loss: 2.2099861601988473

Epoch: 5| Step: 9
Training loss: 1.2812817096710205
Validation loss: 2.1469436585903168

Epoch: 5| Step: 10
Training loss: 1.4179495573043823
Validation loss: 2.1689235270023346

Epoch: 5| Step: 11
Training loss: 0.654755711555481
Validation loss: 2.172073562939962

Epoch: 385| Step: 0
Training loss: 1.2214794158935547
Validation loss: 2.2072288493315377

Epoch: 5| Step: 1
Training loss: 0.984814465045929
Validation loss: 2.1951597134272256

Epoch: 5| Step: 2
Training loss: 1.0513088703155518
Validation loss: 2.2027088900407157

Epoch: 5| Step: 3
Training loss: 1.631774663925171
Validation loss: 2.185984472433726

Epoch: 5| Step: 4
Training loss: 1.607389211654663
Validation loss: 2.1817508786916733

Epoch: 5| Step: 5
Training loss: 1.8836040496826172
Validation loss: 2.1854811956485114

Epoch: 5| Step: 6
Training loss: 1.0341928005218506
Validation loss: 2.192777012785276

Epoch: 5| Step: 7
Training loss: 1.4460034370422363
Validation loss: 2.2412145684162774

Epoch: 5| Step: 8
Training loss: 1.4083058834075928
Validation loss: 2.186481679479281

Epoch: 5| Step: 9
Training loss: 0.9609588384628296
Validation loss: 2.19561900695165

Epoch: 5| Step: 10
Training loss: 1.2080767154693604
Validation loss: 2.1894050588210425

Epoch: 5| Step: 11
Training loss: 1.397399663925171
Validation loss: 2.2052122255166373

Epoch: 386| Step: 0
Training loss: 1.3881196975708008
Validation loss: 2.2136565496524176

Epoch: 5| Step: 1
Training loss: 1.261597990989685
Validation loss: 2.19917464752992

Epoch: 5| Step: 2
Training loss: 0.9527190327644348
Validation loss: 2.1693872759739556

Epoch: 5| Step: 3
Training loss: 0.8455535769462585
Validation loss: 2.1810996383428574

Epoch: 5| Step: 4
Training loss: 1.2980127334594727
Validation loss: 2.1888785858949027

Epoch: 5| Step: 5
Training loss: 0.9637376666069031
Validation loss: 2.2300055772066116

Epoch: 5| Step: 6
Training loss: 1.73095703125
Validation loss: 2.180267403523127

Epoch: 5| Step: 7
Training loss: 1.532364845275879
Validation loss: 2.2181506703297296

Epoch: 5| Step: 8
Training loss: 1.6245473623275757
Validation loss: 2.201082934935888

Epoch: 5| Step: 9
Training loss: 1.0801852941513062
Validation loss: 2.226160774628321

Epoch: 5| Step: 10
Training loss: 1.1530694961547852
Validation loss: 2.194418951869011

Epoch: 5| Step: 11
Training loss: 0.332003116607666
Validation loss: 2.228184163570404

Epoch: 387| Step: 0
Training loss: 1.0026302337646484
Validation loss: 2.227657367785772

Epoch: 5| Step: 1
Training loss: 1.3354461193084717
Validation loss: 2.213747948408127

Epoch: 5| Step: 2
Training loss: 1.2239322662353516
Validation loss: 2.2231622288624444

Epoch: 5| Step: 3
Training loss: 1.287624478340149
Validation loss: 2.15097106496493

Epoch: 5| Step: 4
Training loss: 0.7320388555526733
Validation loss: 2.1673539181550345

Epoch: 5| Step: 5
Training loss: 1.6131500005722046
Validation loss: 2.213488757610321

Epoch: 5| Step: 6
Training loss: 1.4553595781326294
Validation loss: 2.2103693087895713

Epoch: 5| Step: 7
Training loss: 1.0091906785964966
Validation loss: 2.199549913406372

Epoch: 5| Step: 8
Training loss: 1.1689378023147583
Validation loss: 2.1948098142941794

Epoch: 5| Step: 9
Training loss: 1.2945482730865479
Validation loss: 2.234941611687342

Epoch: 5| Step: 10
Training loss: 1.315824270248413
Validation loss: 2.2391717433929443

Epoch: 5| Step: 11
Training loss: 2.3154828548431396
Validation loss: 2.206941157579422

Epoch: 388| Step: 0
Training loss: 1.1967618465423584
Validation loss: 2.1715046217044196

Epoch: 5| Step: 1
Training loss: 1.2729285955429077
Validation loss: 2.1598309179147086

Epoch: 5| Step: 2
Training loss: 1.3474611043930054
Validation loss: 2.1938586284716926

Epoch: 5| Step: 3
Training loss: 1.1612365245819092
Validation loss: 2.170192673802376

Epoch: 5| Step: 4
Training loss: 1.3205318450927734
Validation loss: 2.1819885720809302

Epoch: 5| Step: 5
Training loss: 1.8096497058868408
Validation loss: 2.193070004383723

Epoch: 5| Step: 6
Training loss: 0.8209999799728394
Validation loss: 2.1917902479569116

Epoch: 5| Step: 7
Training loss: 1.0990509986877441
Validation loss: 2.1835978825887046

Epoch: 5| Step: 8
Training loss: 1.128453016281128
Validation loss: 2.2024343411127725

Epoch: 5| Step: 9
Training loss: 1.1532965898513794
Validation loss: 2.1834389766057334

Epoch: 5| Step: 10
Training loss: 1.3061888217926025
Validation loss: 2.2094517201185226

Epoch: 5| Step: 11
Training loss: 1.4368573427200317
Validation loss: 2.234720533092817

Epoch: 389| Step: 0
Training loss: 1.022153615951538
Validation loss: 2.2024781008561454

Epoch: 5| Step: 1
Training loss: 1.6449697017669678
Validation loss: 2.2470869223276773

Epoch: 5| Step: 2
Training loss: 1.1940202713012695
Validation loss: 2.2398410538832345

Epoch: 5| Step: 3
Training loss: 0.7094370126724243
Validation loss: 2.211216981212298

Epoch: 5| Step: 4
Training loss: 1.2293028831481934
Validation loss: 2.212306762735049

Epoch: 5| Step: 5
Training loss: 1.6419250965118408
Validation loss: 2.250929892063141

Epoch: 5| Step: 6
Training loss: 1.332589030265808
Validation loss: 2.214217404524485

Epoch: 5| Step: 7
Training loss: 1.1674888134002686
Validation loss: 2.2051311284303665

Epoch: 5| Step: 8
Training loss: 1.0670310258865356
Validation loss: 2.27479879061381

Epoch: 5| Step: 9
Training loss: 1.754595398902893
Validation loss: 2.2599802712599435

Epoch: 5| Step: 10
Training loss: 0.7406123876571655
Validation loss: 2.2373677293459573

Epoch: 5| Step: 11
Training loss: 1.005505919456482
Validation loss: 2.238367314140002

Epoch: 390| Step: 0
Training loss: 1.2201322317123413
Validation loss: 2.2339094976584115

Epoch: 5| Step: 1
Training loss: 0.7127722501754761
Validation loss: 2.219235807657242

Epoch: 5| Step: 2
Training loss: 1.9590256214141846
Validation loss: 2.2436274687449136

Epoch: 5| Step: 3
Training loss: 1.2677152156829834
Validation loss: 2.2564526001612344

Epoch: 5| Step: 4
Training loss: 1.0194170475006104
Validation loss: 2.2154078781604767

Epoch: 5| Step: 5
Training loss: 1.3595445156097412
Validation loss: 2.244230637947718

Epoch: 5| Step: 6
Training loss: 1.3908634185791016
Validation loss: 2.229943866531054

Epoch: 5| Step: 7
Training loss: 1.5486863851547241
Validation loss: 2.231078545252482

Epoch: 5| Step: 8
Training loss: 0.929781436920166
Validation loss: 2.219261879722277

Epoch: 5| Step: 9
Training loss: 1.6486091613769531
Validation loss: 2.219400852918625

Epoch: 5| Step: 10
Training loss: 1.0448087453842163
Validation loss: 2.231166571378708

Epoch: 5| Step: 11
Training loss: 0.8870301842689514
Validation loss: 2.2314595033725104

Epoch: 391| Step: 0
Training loss: 1.7330986261367798
Validation loss: 2.2451026340325675

Epoch: 5| Step: 1
Training loss: 1.0202572345733643
Validation loss: 2.210729718208313

Epoch: 5| Step: 2
Training loss: 0.8577769994735718
Validation loss: 2.2291553765535355

Epoch: 5| Step: 3
Training loss: 1.2449665069580078
Validation loss: 2.2338723093271255

Epoch: 5| Step: 4
Training loss: 0.8714791536331177
Validation loss: 2.207550366719564

Epoch: 5| Step: 5
Training loss: 1.4400675296783447
Validation loss: 2.1851109514633813

Epoch: 5| Step: 6
Training loss: 1.3830277919769287
Validation loss: 2.1999934911727905

Epoch: 5| Step: 7
Training loss: 1.7554454803466797
Validation loss: 2.2472356160481772

Epoch: 5| Step: 8
Training loss: 0.8711436986923218
Validation loss: 2.185223932067553

Epoch: 5| Step: 9
Training loss: 1.485344409942627
Validation loss: 2.2177837093671164

Epoch: 5| Step: 10
Training loss: 0.6750190854072571
Validation loss: 2.289173757036527

Epoch: 5| Step: 11
Training loss: 3.012847900390625
Validation loss: 2.213863124450048

Epoch: 392| Step: 0
Training loss: 1.0976908206939697
Validation loss: 2.2515330215295157

Epoch: 5| Step: 1
Training loss: 0.8299018144607544
Validation loss: 2.227876126766205

Epoch: 5| Step: 2
Training loss: 1.2757289409637451
Validation loss: 2.2056457549333572

Epoch: 5| Step: 3
Training loss: 1.2792434692382812
Validation loss: 2.220925142367681

Epoch: 5| Step: 4
Training loss: 1.3028942346572876
Validation loss: 2.2223638147115707

Epoch: 5| Step: 5
Training loss: 1.347797155380249
Validation loss: 2.234009876847267

Epoch: 5| Step: 6
Training loss: 1.1583610773086548
Validation loss: 2.1968155999978385

Epoch: 5| Step: 7
Training loss: 1.3841392993927002
Validation loss: 2.227795680363973

Epoch: 5| Step: 8
Training loss: 1.4804288148880005
Validation loss: 2.2164491415023804

Epoch: 5| Step: 9
Training loss: 1.3411128520965576
Validation loss: 2.182202696800232

Epoch: 5| Step: 10
Training loss: 1.090059757232666
Validation loss: 2.1863595147927604

Epoch: 5| Step: 11
Training loss: 0.2910717725753784
Validation loss: 2.202952856818835

Epoch: 393| Step: 0
Training loss: 1.3770887851715088
Validation loss: 2.1887374222278595

Epoch: 5| Step: 1
Training loss: 1.4675061702728271
Validation loss: 2.218818634748459

Epoch: 5| Step: 2
Training loss: 1.183837652206421
Validation loss: 2.2018821984529495

Epoch: 5| Step: 3
Training loss: 0.5809762477874756
Validation loss: 2.234169065952301

Epoch: 5| Step: 4
Training loss: 1.328951120376587
Validation loss: 2.2386268079280853

Epoch: 5| Step: 5
Training loss: 0.9958592653274536
Validation loss: 2.2225116988023124

Epoch: 5| Step: 6
Training loss: 1.2705246210098267
Validation loss: 2.229523246486982

Epoch: 5| Step: 7
Training loss: 0.7965912222862244
Validation loss: 2.2119034628073373

Epoch: 5| Step: 8
Training loss: 1.3011577129364014
Validation loss: 2.185707857211431

Epoch: 5| Step: 9
Training loss: 1.7887279987335205
Validation loss: 2.201555013656616

Epoch: 5| Step: 10
Training loss: 1.1352757215499878
Validation loss: 2.2331833640734353

Epoch: 5| Step: 11
Training loss: 0.6699033379554749
Validation loss: 2.206678440173467

Epoch: 394| Step: 0
Training loss: 1.0158089399337769
Validation loss: 2.2419253637393317

Epoch: 5| Step: 1
Training loss: 1.1529645919799805
Validation loss: 2.2241545766592026

Epoch: 5| Step: 2
Training loss: 1.1828536987304688
Validation loss: 2.2147451639175415

Epoch: 5| Step: 3
Training loss: 1.367182731628418
Validation loss: 2.228970398505529

Epoch: 5| Step: 4
Training loss: 1.1922476291656494
Validation loss: 2.191613311568896

Epoch: 5| Step: 5
Training loss: 0.7073301672935486
Validation loss: 2.199714486797651

Epoch: 5| Step: 6
Training loss: 1.6504977941513062
Validation loss: 2.224221562345823

Epoch: 5| Step: 7
Training loss: 1.0840405225753784
Validation loss: 2.2207118570804596

Epoch: 5| Step: 8
Training loss: 1.568867564201355
Validation loss: 2.2071412056684494

Epoch: 5| Step: 9
Training loss: 1.3477342128753662
Validation loss: 2.1981627295414605

Epoch: 5| Step: 10
Training loss: 1.073250412940979
Validation loss: 2.1978658040364585

Epoch: 5| Step: 11
Training loss: 0.44944441318511963
Validation loss: 2.187445600827535

Epoch: 395| Step: 0
Training loss: 1.1310160160064697
Validation loss: 2.197073628505071

Epoch: 5| Step: 1
Training loss: 1.542400598526001
Validation loss: 2.2374556561311087

Epoch: 5| Step: 2
Training loss: 1.0346918106079102
Validation loss: 2.2220254937807717

Epoch: 5| Step: 3
Training loss: 1.0113742351531982
Validation loss: 2.2006898472706475

Epoch: 5| Step: 4
Training loss: 1.1612128019332886
Validation loss: 2.2025343775749207

Epoch: 5| Step: 5
Training loss: 1.6151883602142334
Validation loss: 2.2207509577274323

Epoch: 5| Step: 6
Training loss: 1.1339733600616455
Validation loss: 2.1822347740332284

Epoch: 5| Step: 7
Training loss: 0.7779358625411987
Validation loss: 2.2328209976355233

Epoch: 5| Step: 8
Training loss: 1.7518937587738037
Validation loss: 2.222155978282293

Epoch: 5| Step: 9
Training loss: 0.7377715110778809
Validation loss: 2.236342286070188

Epoch: 5| Step: 10
Training loss: 1.234816551208496
Validation loss: 2.18254591524601

Epoch: 5| Step: 11
Training loss: 2.154676675796509
Validation loss: 2.2190853555997214

Epoch: 396| Step: 0
Training loss: 0.7812782526016235
Validation loss: 2.2231426437695823

Epoch: 5| Step: 1
Training loss: 0.602824330329895
Validation loss: 2.2065004656712213

Epoch: 5| Step: 2
Training loss: 1.180694580078125
Validation loss: 2.2051286498705545

Epoch: 5| Step: 3
Training loss: 1.2361830472946167
Validation loss: 2.189223895470301

Epoch: 5| Step: 4
Training loss: 0.7747136354446411
Validation loss: 2.220908294121424

Epoch: 5| Step: 5
Training loss: 1.0149492025375366
Validation loss: 2.237438549598058

Epoch: 5| Step: 6
Training loss: 1.7563852071762085
Validation loss: 2.255538582801819

Epoch: 5| Step: 7
Training loss: 1.824461579322815
Validation loss: 2.2192299465338388

Epoch: 5| Step: 8
Training loss: 1.82929265499115
Validation loss: 2.229452202717463

Epoch: 5| Step: 9
Training loss: 0.9798490405082703
Validation loss: 2.211247210701307

Epoch: 5| Step: 10
Training loss: 1.129835605621338
Validation loss: 2.2489844262599945

Epoch: 5| Step: 11
Training loss: 0.9749839305877686
Validation loss: 2.210027446349462

Epoch: 397| Step: 0
Training loss: 1.1500871181488037
Validation loss: 2.2125536600748696

Epoch: 5| Step: 1
Training loss: 1.265886664390564
Validation loss: 2.2372813324133554

Epoch: 5| Step: 2
Training loss: 2.124499559402466
Validation loss: 2.210751935839653

Epoch: 5| Step: 3
Training loss: 1.498712182044983
Validation loss: 2.2228749642769494

Epoch: 5| Step: 4
Training loss: 1.15860915184021
Validation loss: 2.2292935152848563

Epoch: 5| Step: 5
Training loss: 0.7865720391273499
Validation loss: 2.2107211649417877

Epoch: 5| Step: 6
Training loss: 1.20089590549469
Validation loss: 2.2775708734989166

Epoch: 5| Step: 7
Training loss: 0.8865712285041809
Validation loss: 2.2235078563292823

Epoch: 5| Step: 8
Training loss: 1.4141666889190674
Validation loss: 2.246214131514231

Epoch: 5| Step: 9
Training loss: 1.0028164386749268
Validation loss: 2.2264020989338555

Epoch: 5| Step: 10
Training loss: 0.6655237078666687
Validation loss: 2.225991283853849

Epoch: 5| Step: 11
Training loss: 1.0852279663085938
Validation loss: 2.2000297904014587

Epoch: 398| Step: 0
Training loss: 0.6933352947235107
Validation loss: 2.210575540860494

Epoch: 5| Step: 1
Training loss: 0.986833393573761
Validation loss: 2.264001245299975

Epoch: 5| Step: 2
Training loss: 1.483088731765747
Validation loss: 2.234179879228274

Epoch: 5| Step: 3
Training loss: 1.0494344234466553
Validation loss: 2.2351713130871453

Epoch: 5| Step: 4
Training loss: 1.4328725337982178
Validation loss: 2.256662999590238

Epoch: 5| Step: 5
Training loss: 1.2788307666778564
Validation loss: 2.2428276042143502

Epoch: 5| Step: 6
Training loss: 1.077142357826233
Validation loss: 2.2385747830073037

Epoch: 5| Step: 7
Training loss: 1.8813591003417969
Validation loss: 2.2664774556954703

Epoch: 5| Step: 8
Training loss: 1.3200427293777466
Validation loss: 2.211409086982409

Epoch: 5| Step: 9
Training loss: 1.1770908832550049
Validation loss: 2.2431384474039078

Epoch: 5| Step: 10
Training loss: 1.0586740970611572
Validation loss: 2.236751616001129

Epoch: 5| Step: 11
Training loss: 0.7195883989334106
Validation loss: 2.1770732402801514

Epoch: 399| Step: 0
Training loss: 0.8629276156425476
Validation loss: 2.1935496628284454

Epoch: 5| Step: 1
Training loss: 1.4417167901992798
Validation loss: 2.219630390405655

Epoch: 5| Step: 2
Training loss: 1.302726149559021
Validation loss: 2.1703062504529953

Epoch: 5| Step: 3
Training loss: 1.010562777519226
Validation loss: 2.205513129631678

Epoch: 5| Step: 4
Training loss: 0.9375346302986145
Validation loss: 2.198270152012507

Epoch: 5| Step: 5
Training loss: 1.3621031045913696
Validation loss: 2.179989089568456

Epoch: 5| Step: 6
Training loss: 1.3862069845199585
Validation loss: 2.1606054355700812

Epoch: 5| Step: 7
Training loss: 1.450775384902954
Validation loss: 2.162533471981684

Epoch: 5| Step: 8
Training loss: 1.3335881233215332
Validation loss: 2.1967859466870627

Epoch: 5| Step: 9
Training loss: 0.7735057473182678
Validation loss: 2.1878216365973153

Epoch: 5| Step: 10
Training loss: 1.0789003372192383
Validation loss: 2.1654376685619354

Epoch: 5| Step: 11
Training loss: 1.275054693222046
Validation loss: 2.1481500416994095

Epoch: 400| Step: 0
Training loss: 1.0732696056365967
Validation loss: 2.164914866288503

Epoch: 5| Step: 1
Training loss: 1.1532882452011108
Validation loss: 2.1884093979994454

Epoch: 5| Step: 2
Training loss: 1.2515790462493896
Validation loss: 2.1564780523379645

Epoch: 5| Step: 3
Training loss: 1.8203058242797852
Validation loss: 2.2059547354777655

Epoch: 5| Step: 4
Training loss: 0.7073078751564026
Validation loss: 2.209642678499222

Epoch: 5| Step: 5
Training loss: 1.1080957651138306
Validation loss: 2.1745457351207733

Epoch: 5| Step: 6
Training loss: 0.89867103099823
Validation loss: 2.169889082511266

Epoch: 5| Step: 7
Training loss: 1.0570356845855713
Validation loss: 2.1310171633958817

Epoch: 5| Step: 8
Training loss: 2.0360724925994873
Validation loss: 2.12635845442613

Epoch: 5| Step: 9
Training loss: 0.9571331143379211
Validation loss: 2.1347905347744622

Epoch: 5| Step: 10
Training loss: 1.7464258670806885
Validation loss: 2.202416350444158

Epoch: 5| Step: 11
Training loss: 0.6660181283950806
Validation loss: 2.1536236703395844

Epoch: 401| Step: 0
Training loss: 1.7587991952896118
Validation loss: 2.1360344837109246

Epoch: 5| Step: 1
Training loss: 1.4410102367401123
Validation loss: 2.174085964759191

Epoch: 5| Step: 2
Training loss: 1.3919050693511963
Validation loss: 2.172811657190323

Epoch: 5| Step: 3
Training loss: 1.4804781675338745
Validation loss: 2.2011165618896484

Epoch: 5| Step: 4
Training loss: 1.0989888906478882
Validation loss: 2.1627628157536187

Epoch: 5| Step: 5
Training loss: 0.6604617834091187
Validation loss: 2.1664787580569587

Epoch: 5| Step: 6
Training loss: 0.8735197186470032
Validation loss: 2.1527073780695596

Epoch: 5| Step: 7
Training loss: 1.0792382955551147
Validation loss: 2.1399501959482827

Epoch: 5| Step: 8
Training loss: 1.1135880947113037
Validation loss: 2.1573759814103446

Epoch: 5| Step: 9
Training loss: 1.1085624694824219
Validation loss: 2.1794712046782174

Epoch: 5| Step: 10
Training loss: 0.9114065170288086
Validation loss: 2.165586238106092

Epoch: 5| Step: 11
Training loss: 2.1180028915405273
Validation loss: 2.168153872092565

Epoch: 402| Step: 0
Training loss: 1.1192715167999268
Validation loss: 2.1820522248744965

Epoch: 5| Step: 1
Training loss: 1.0348987579345703
Validation loss: 2.1833272029956183

Epoch: 5| Step: 2
Training loss: 1.3610446453094482
Validation loss: 2.2003766198952994

Epoch: 5| Step: 3
Training loss: 1.321649193763733
Validation loss: 2.1809751987457275

Epoch: 5| Step: 4
Training loss: 1.379601240158081
Validation loss: 2.1996337125698724

Epoch: 5| Step: 5
Training loss: 1.324469804763794
Validation loss: 2.2145134607950845

Epoch: 5| Step: 6
Training loss: 1.0603811740875244
Validation loss: 2.231013998389244

Epoch: 5| Step: 7
Training loss: 1.1735336780548096
Validation loss: 2.2035637448231378

Epoch: 5| Step: 8
Training loss: 1.5005443096160889
Validation loss: 2.179851387937864

Epoch: 5| Step: 9
Training loss: 0.7906832695007324
Validation loss: 2.1929054061571756

Epoch: 5| Step: 10
Training loss: 1.5950638055801392
Validation loss: 2.1876356403032937

Epoch: 5| Step: 11
Training loss: 0.706842839717865
Validation loss: 2.2512799352407455

Epoch: 403| Step: 0
Training loss: 0.8857796788215637
Validation loss: 2.225152164697647

Epoch: 5| Step: 1
Training loss: 1.3196121454238892
Validation loss: 2.1931972404321036

Epoch: 5| Step: 2
Training loss: 0.8426409959793091
Validation loss: 2.2058278868595758

Epoch: 5| Step: 3
Training loss: 1.404294729232788
Validation loss: 2.193225771188736

Epoch: 5| Step: 4
Training loss: 1.2549816370010376
Validation loss: 2.2010302543640137

Epoch: 5| Step: 5
Training loss: 1.4001071453094482
Validation loss: 2.2245447089274726

Epoch: 5| Step: 6
Training loss: 1.2605671882629395
Validation loss: 2.2228969981273017

Epoch: 5| Step: 7
Training loss: 1.2031866312026978
Validation loss: 2.201533943414688

Epoch: 5| Step: 8
Training loss: 1.0835597515106201
Validation loss: 2.205046147108078

Epoch: 5| Step: 9
Training loss: 0.970720648765564
Validation loss: 2.214598755041758

Epoch: 5| Step: 10
Training loss: 1.405612587928772
Validation loss: 2.1461102962493896

Epoch: 5| Step: 11
Training loss: 0.493868350982666
Validation loss: 2.191672866543134

Epoch: 404| Step: 0
Training loss: 1.4726831912994385
Validation loss: 2.2209107478459678

Epoch: 5| Step: 1
Training loss: 0.8998206257820129
Validation loss: 2.2146673053503036

Epoch: 5| Step: 2
Training loss: 1.3479077816009521
Validation loss: 2.226327141125997

Epoch: 5| Step: 3
Training loss: 1.0035645961761475
Validation loss: 2.246744324763616

Epoch: 5| Step: 4
Training loss: 1.610377311706543
Validation loss: 2.207590326666832

Epoch: 5| Step: 5
Training loss: 0.8943403363227844
Validation loss: 2.220951388279597

Epoch: 5| Step: 6
Training loss: 1.5966672897338867
Validation loss: 2.1979076266288757

Epoch: 5| Step: 7
Training loss: 1.3786704540252686
Validation loss: 2.183795432249705

Epoch: 5| Step: 8
Training loss: 1.0540952682495117
Validation loss: 2.181823988755544

Epoch: 5| Step: 9
Training loss: 1.3365436792373657
Validation loss: 2.1951383451620736

Epoch: 5| Step: 10
Training loss: 1.0827839374542236
Validation loss: 2.1985707034667334

Epoch: 5| Step: 11
Training loss: 2.053273916244507
Validation loss: 2.206486865878105

Epoch: 405| Step: 0
Training loss: 1.2406548261642456
Validation loss: 2.1897925237814584

Epoch: 5| Step: 1
Training loss: 0.8730841875076294
Validation loss: 2.238965407013893

Epoch: 5| Step: 2
Training loss: 1.4335213899612427
Validation loss: 2.19609343012174

Epoch: 5| Step: 3
Training loss: 1.6538608074188232
Validation loss: 2.2397726277510324

Epoch: 5| Step: 4
Training loss: 0.8769761323928833
Validation loss: 2.2120474924643836

Epoch: 5| Step: 5
Training loss: 1.393005132675171
Validation loss: 2.234603156646093

Epoch: 5| Step: 6
Training loss: 1.2121596336364746
Validation loss: 2.2109181682268777

Epoch: 5| Step: 7
Training loss: 1.104000449180603
Validation loss: 2.243040015300115

Epoch: 5| Step: 8
Training loss: 0.908758282661438
Validation loss: 2.2215713560581207

Epoch: 5| Step: 9
Training loss: 1.1759283542633057
Validation loss: 2.2610803047815957

Epoch: 5| Step: 10
Training loss: 0.669481098651886
Validation loss: 2.2405109802881875

Epoch: 5| Step: 11
Training loss: 2.331082582473755
Validation loss: 2.232369358340899

Epoch: 406| Step: 0
Training loss: 1.7572147846221924
Validation loss: 2.196299691994985

Epoch: 5| Step: 1
Training loss: 1.295614242553711
Validation loss: 2.2447846134503684

Epoch: 5| Step: 2
Training loss: 1.0092045068740845
Validation loss: 2.267511169115702

Epoch: 5| Step: 3
Training loss: 0.970385730266571
Validation loss: 2.2287485798199973

Epoch: 5| Step: 4
Training loss: 1.2394764423370361
Validation loss: 2.27364710966746

Epoch: 5| Step: 5
Training loss: 0.9804530143737793
Validation loss: 2.2560080091158548

Epoch: 5| Step: 6
Training loss: 0.6732677817344666
Validation loss: 2.2649500519037247

Epoch: 5| Step: 7
Training loss: 1.1758161783218384
Validation loss: 2.2696586350599923

Epoch: 5| Step: 8
Training loss: 1.316190481185913
Validation loss: 2.2702631254990897

Epoch: 5| Step: 9
Training loss: 1.6902176141738892
Validation loss: 2.22489986817042

Epoch: 5| Step: 10
Training loss: 1.0494182109832764
Validation loss: 2.2648709416389465

Epoch: 5| Step: 11
Training loss: 0.4094654321670532
Validation loss: 2.2473949939012527

Epoch: 407| Step: 0
Training loss: 0.8287860751152039
Validation loss: 2.2414862513542175

Epoch: 5| Step: 1
Training loss: 1.283397912979126
Validation loss: 2.2516391376654306

Epoch: 5| Step: 2
Training loss: 1.3463767766952515
Validation loss: 2.2584256331125894

Epoch: 5| Step: 3
Training loss: 1.682130217552185
Validation loss: 2.260519251227379

Epoch: 5| Step: 4
Training loss: 1.7154983282089233
Validation loss: 2.2148517022530236

Epoch: 5| Step: 5
Training loss: 1.241204023361206
Validation loss: 2.22841710348924

Epoch: 5| Step: 6
Training loss: 0.8758343458175659
Validation loss: 2.243277668952942

Epoch: 5| Step: 7
Training loss: 0.5851362943649292
Validation loss: 2.2377094825108848

Epoch: 5| Step: 8
Training loss: 0.9899165034294128
Validation loss: 2.206702629725138

Epoch: 5| Step: 9
Training loss: 0.7241371870040894
Validation loss: 2.2453916519880295

Epoch: 5| Step: 10
Training loss: 1.487905502319336
Validation loss: 2.227433572212855

Epoch: 5| Step: 11
Training loss: 2.584299087524414
Validation loss: 2.2369727194309235

Epoch: 408| Step: 0
Training loss: 1.143552303314209
Validation loss: 2.230547328790029

Epoch: 5| Step: 1
Training loss: 1.0464881658554077
Validation loss: 2.2000435888767242

Epoch: 5| Step: 2
Training loss: 0.5697495937347412
Validation loss: 2.2119900633891425

Epoch: 5| Step: 3
Training loss: 2.2142441272735596
Validation loss: 2.1740790605545044

Epoch: 5| Step: 4
Training loss: 1.3533614873886108
Validation loss: 2.187271902958552

Epoch: 5| Step: 5
Training loss: 0.8628219366073608
Validation loss: 2.186746130386988

Epoch: 5| Step: 6
Training loss: 1.2953269481658936
Validation loss: 2.222126136223475

Epoch: 5| Step: 7
Training loss: 1.0070425271987915
Validation loss: 2.2078558802604675

Epoch: 5| Step: 8
Training loss: 0.9018357992172241
Validation loss: 2.2069028119246163

Epoch: 5| Step: 9
Training loss: 1.2111668586730957
Validation loss: 2.18528979520003

Epoch: 5| Step: 10
Training loss: 0.8725757598876953
Validation loss: 2.153913766145706

Epoch: 5| Step: 11
Training loss: 1.3378381729125977
Validation loss: 2.1486680259307227

Epoch: 409| Step: 0
Training loss: 1.3143236637115479
Validation loss: 2.1680438419183097

Epoch: 5| Step: 1
Training loss: 0.7757964134216309
Validation loss: 2.190933624903361

Epoch: 5| Step: 2
Training loss: 1.6729053258895874
Validation loss: 2.1898222814003625

Epoch: 5| Step: 3
Training loss: 0.8815573453903198
Validation loss: 2.166287809610367

Epoch: 5| Step: 4
Training loss: 0.7726327776908875
Validation loss: 2.2247704764207206

Epoch: 5| Step: 5
Training loss: 1.2248947620391846
Validation loss: 2.1713240991036096

Epoch: 5| Step: 6
Training loss: 0.8763879537582397
Validation loss: 2.185802847146988

Epoch: 5| Step: 7
Training loss: 1.4831509590148926
Validation loss: 2.1916166841983795

Epoch: 5| Step: 8
Training loss: 1.1828914880752563
Validation loss: 2.1775540113449097

Epoch: 5| Step: 9
Training loss: 1.4420305490493774
Validation loss: 2.169933329025904

Epoch: 5| Step: 10
Training loss: 1.0976841449737549
Validation loss: 2.163555254538854

Epoch: 5| Step: 11
Training loss: 0.3839530348777771
Validation loss: 2.2094961355129876

Epoch: 410| Step: 0
Training loss: 1.159570336341858
Validation loss: 2.177034303545952

Epoch: 5| Step: 1
Training loss: 1.2488970756530762
Validation loss: 2.186485101779302

Epoch: 5| Step: 2
Training loss: 1.1949923038482666
Validation loss: 2.213445986310641

Epoch: 5| Step: 3
Training loss: 1.4986704587936401
Validation loss: 2.21928878625234

Epoch: 5| Step: 4
Training loss: 1.2243764400482178
Validation loss: 2.1996167302131653

Epoch: 5| Step: 5
Training loss: 1.5487468242645264
Validation loss: 2.2048294295867286

Epoch: 5| Step: 6
Training loss: 1.1229530572891235
Validation loss: 2.175885279973348

Epoch: 5| Step: 7
Training loss: 0.8150909543037415
Validation loss: 2.186372627814611

Epoch: 5| Step: 8
Training loss: 1.6245654821395874
Validation loss: 2.1891304651896157

Epoch: 5| Step: 9
Training loss: 0.5539547801017761
Validation loss: 2.196668565273285

Epoch: 5| Step: 10
Training loss: 0.8388444781303406
Validation loss: 2.19426991045475

Epoch: 5| Step: 11
Training loss: 0.3699347972869873
Validation loss: 2.22916387518247

Epoch: 411| Step: 0
Training loss: 1.0147435665130615
Validation loss: 2.1929399271806083

Epoch: 5| Step: 1
Training loss: 0.7356221675872803
Validation loss: 2.194996992746989

Epoch: 5| Step: 2
Training loss: 1.4649609327316284
Validation loss: 2.196435401837031

Epoch: 5| Step: 3
Training loss: 1.4310824871063232
Validation loss: 2.1811762899160385

Epoch: 5| Step: 4
Training loss: 1.4207656383514404
Validation loss: 2.2032481133937836

Epoch: 5| Step: 5
Training loss: 1.2787091732025146
Validation loss: 2.1824603279431662

Epoch: 5| Step: 6
Training loss: 1.320052981376648
Validation loss: 2.196002885699272

Epoch: 5| Step: 7
Training loss: 1.0278043746948242
Validation loss: 2.1965908110141754

Epoch: 5| Step: 8
Training loss: 0.8711463212966919
Validation loss: 2.1969405313332877

Epoch: 5| Step: 9
Training loss: 1.2838197946548462
Validation loss: 2.195715303222338

Epoch: 5| Step: 10
Training loss: 0.715556263923645
Validation loss: 2.2028476695219674

Epoch: 5| Step: 11
Training loss: 0.35526469349861145
Validation loss: 2.1822012265523276

Epoch: 412| Step: 0
Training loss: 1.15447199344635
Validation loss: 2.2145180702209473

Epoch: 5| Step: 1
Training loss: 0.9787314534187317
Validation loss: 2.1972014904022217

Epoch: 5| Step: 2
Training loss: 1.1105170249938965
Validation loss: 2.1932275891304016

Epoch: 5| Step: 3
Training loss: 1.1146361827850342
Validation loss: 2.214466169476509

Epoch: 5| Step: 4
Training loss: 1.1698004007339478
Validation loss: 2.171034574508667

Epoch: 5| Step: 5
Training loss: 0.9045888781547546
Validation loss: 2.227465182542801

Epoch: 5| Step: 6
Training loss: 0.7992565631866455
Validation loss: 2.172632336616516

Epoch: 5| Step: 7
Training loss: 0.9761089086532593
Validation loss: 2.1839333872000375

Epoch: 5| Step: 8
Training loss: 1.126304030418396
Validation loss: 2.20655158162117

Epoch: 5| Step: 9
Training loss: 1.115995168685913
Validation loss: 2.1583797484636307

Epoch: 5| Step: 10
Training loss: 1.6234514713287354
Validation loss: 2.144344831506411

Epoch: 5| Step: 11
Training loss: 2.131938934326172
Validation loss: 2.2182605316241584

Epoch: 413| Step: 0
Training loss: 1.2368396520614624
Validation loss: 2.20673701663812

Epoch: 5| Step: 1
Training loss: 1.0720173120498657
Validation loss: 2.1850824455420175

Epoch: 5| Step: 2
Training loss: 1.3328547477722168
Validation loss: 2.186162461837133

Epoch: 5| Step: 3
Training loss: 1.2388184070587158
Validation loss: 2.1891211569309235

Epoch: 5| Step: 4
Training loss: 0.7025730013847351
Validation loss: 2.134202445546786

Epoch: 5| Step: 5
Training loss: 1.233843207359314
Validation loss: 2.167851691444715

Epoch: 5| Step: 6
Training loss: 0.6438531875610352
Validation loss: 2.1598315238952637

Epoch: 5| Step: 7
Training loss: 1.6635525226593018
Validation loss: 2.1842368692159653

Epoch: 5| Step: 8
Training loss: 0.8178307414054871
Validation loss: 2.182256435354551

Epoch: 5| Step: 9
Training loss: 1.0228121280670166
Validation loss: 2.1880870958169303

Epoch: 5| Step: 10
Training loss: 1.64533269405365
Validation loss: 2.169657419125239

Epoch: 5| Step: 11
Training loss: 1.5581395626068115
Validation loss: 2.1998375356197357

Epoch: 414| Step: 0
Training loss: 0.928107738494873
Validation loss: 2.2021097540855408

Epoch: 5| Step: 1
Training loss: 1.0326752662658691
Validation loss: 2.23255318403244

Epoch: 5| Step: 2
Training loss: 1.3788936138153076
Validation loss: 2.2201171020666757

Epoch: 5| Step: 3
Training loss: 0.9384955167770386
Validation loss: 2.197015662988027

Epoch: 5| Step: 4
Training loss: 1.7267029285430908
Validation loss: 2.1823671013116837

Epoch: 5| Step: 5
Training loss: 1.0286238193511963
Validation loss: 2.176215951641401

Epoch: 5| Step: 6
Training loss: 1.230896234512329
Validation loss: 2.1844127476215363

Epoch: 5| Step: 7
Training loss: 1.1236287355422974
Validation loss: 2.234928290049235

Epoch: 5| Step: 8
Training loss: 0.8043228387832642
Validation loss: 2.21770046154658

Epoch: 5| Step: 9
Training loss: 1.04904305934906
Validation loss: 2.190308620532354

Epoch: 5| Step: 10
Training loss: 1.2053114175796509
Validation loss: 2.2092387626568475

Epoch: 5| Step: 11
Training loss: 0.4988842010498047
Validation loss: 2.2331762462854385

Epoch: 415| Step: 0
Training loss: 1.8896024227142334
Validation loss: 2.22727969288826

Epoch: 5| Step: 1
Training loss: 0.9116680026054382
Validation loss: 2.224760656555494

Epoch: 5| Step: 2
Training loss: 0.9889044761657715
Validation loss: 2.227051248153051

Epoch: 5| Step: 3
Training loss: 1.9613574743270874
Validation loss: 2.2156985451777778

Epoch: 5| Step: 4
Training loss: 0.960310161113739
Validation loss: 2.278652066985766

Epoch: 5| Step: 5
Training loss: 1.388361930847168
Validation loss: 2.2096154590447745

Epoch: 5| Step: 6
Training loss: 1.2342283725738525
Validation loss: 2.2033185958862305

Epoch: 5| Step: 7
Training loss: 0.7430610656738281
Validation loss: 2.2215397457281747

Epoch: 5| Step: 8
Training loss: 1.292799711227417
Validation loss: 2.2098455677429834

Epoch: 5| Step: 9
Training loss: 0.6972866654396057
Validation loss: 2.204324945807457

Epoch: 5| Step: 10
Training loss: 0.7954885959625244
Validation loss: 2.1747807562351227

Epoch: 5| Step: 11
Training loss: 0.2778398394584656
Validation loss: 2.2462738901376724

Epoch: 416| Step: 0
Training loss: 0.6407356262207031
Validation loss: 2.231582154830297

Epoch: 5| Step: 1
Training loss: 1.0776385068893433
Validation loss: 2.209075237313906

Epoch: 5| Step: 2
Training loss: 1.5952564477920532
Validation loss: 2.2058079292376838

Epoch: 5| Step: 3
Training loss: 0.8223928213119507
Validation loss: 2.2183408389488855

Epoch: 5| Step: 4
Training loss: 0.6111282110214233
Validation loss: 2.198145493865013

Epoch: 5| Step: 5
Training loss: 1.6028547286987305
Validation loss: 2.22144091129303

Epoch: 5| Step: 6
Training loss: 1.2287852764129639
Validation loss: 2.2192944139242172

Epoch: 5| Step: 7
Training loss: 1.2415409088134766
Validation loss: 2.161715646584829

Epoch: 5| Step: 8
Training loss: 1.111924648284912
Validation loss: 2.2210015753904977

Epoch: 5| Step: 9
Training loss: 0.9792273640632629
Validation loss: 2.230780690908432

Epoch: 5| Step: 10
Training loss: 0.7826865911483765
Validation loss: 2.211193243662516

Epoch: 5| Step: 11
Training loss: 3.5108649730682373
Validation loss: 2.1945066303014755

Epoch: 417| Step: 0
Training loss: 0.9944844245910645
Validation loss: 2.188494235277176

Epoch: 5| Step: 1
Training loss: 1.0350923538208008
Validation loss: 2.213635817170143

Epoch: 5| Step: 2
Training loss: 1.1858736276626587
Validation loss: 2.177174746990204

Epoch: 5| Step: 3
Training loss: 1.0386251211166382
Validation loss: 2.2148665140072503

Epoch: 5| Step: 4
Training loss: 1.2347580194473267
Validation loss: 2.2025869439045587

Epoch: 5| Step: 5
Training loss: 1.2552978992462158
Validation loss: 2.1594894230365753

Epoch: 5| Step: 6
Training loss: 1.3247143030166626
Validation loss: 2.2009534935156503

Epoch: 5| Step: 7
Training loss: 1.3780269622802734
Validation loss: 2.1595288813114166

Epoch: 5| Step: 8
Training loss: 0.9701677560806274
Validation loss: 2.1915366848309836

Epoch: 5| Step: 9
Training loss: 1.0236423015594482
Validation loss: 2.144996851682663

Epoch: 5| Step: 10
Training loss: 1.111808180809021
Validation loss: 2.198404937982559

Epoch: 5| Step: 11
Training loss: 0.6677874326705933
Validation loss: 2.2084456582864127

Epoch: 418| Step: 0
Training loss: 0.8179343938827515
Validation loss: 2.202407489220301

Epoch: 5| Step: 1
Training loss: 1.4964569807052612
Validation loss: 2.227989504734675

Epoch: 5| Step: 2
Training loss: 1.018280267715454
Validation loss: 2.228687380750974

Epoch: 5| Step: 3
Training loss: 1.5693360567092896
Validation loss: 2.2046750833590827

Epoch: 5| Step: 4
Training loss: 1.2688167095184326
Validation loss: 2.210487018028895

Epoch: 5| Step: 5
Training loss: 1.5424962043762207
Validation loss: 2.2217959264914193

Epoch: 5| Step: 6
Training loss: 0.8183674812316895
Validation loss: 2.2328592091798782

Epoch: 5| Step: 7
Training loss: 0.8844816088676453
Validation loss: 2.204828232526779

Epoch: 5| Step: 8
Training loss: 1.0334457159042358
Validation loss: 2.2077853282292685

Epoch: 5| Step: 9
Training loss: 0.8026238679885864
Validation loss: 2.257021059592565

Epoch: 5| Step: 10
Training loss: 1.3915364742279053
Validation loss: 2.2170667250951133

Epoch: 5| Step: 11
Training loss: 1.1905797719955444
Validation loss: 2.232743372519811

Epoch: 419| Step: 0
Training loss: 1.42116379737854
Validation loss: 2.2135291745265326

Epoch: 5| Step: 1
Training loss: 1.2901792526245117
Validation loss: 2.2512281040350595

Epoch: 5| Step: 2
Training loss: 1.0115184783935547
Validation loss: 2.261814296245575

Epoch: 5| Step: 3
Training loss: 0.9026451110839844
Validation loss: 2.220382501681646

Epoch: 5| Step: 4
Training loss: 0.6172875165939331
Validation loss: 2.240596224864324

Epoch: 5| Step: 5
Training loss: 1.5353503227233887
Validation loss: 2.1971162060896554

Epoch: 5| Step: 6
Training loss: 0.892072319984436
Validation loss: 2.211973254879316

Epoch: 5| Step: 7
Training loss: 1.0780431032180786
Validation loss: 2.2301098604997

Epoch: 5| Step: 8
Training loss: 0.922897219657898
Validation loss: 2.2068465650081635

Epoch: 5| Step: 9
Training loss: 1.6816898584365845
Validation loss: 2.2011587719122567

Epoch: 5| Step: 10
Training loss: 0.7983539700508118
Validation loss: 2.2331824600696564

Epoch: 5| Step: 11
Training loss: 0.5890277624130249
Validation loss: 2.2293285628159842

Epoch: 420| Step: 0
Training loss: 0.40923529863357544
Validation loss: 2.19019345442454

Epoch: 5| Step: 1
Training loss: 0.755578875541687
Validation loss: 2.203651398420334

Epoch: 5| Step: 2
Training loss: 0.7520450949668884
Validation loss: 2.264768213033676

Epoch: 5| Step: 3
Training loss: 1.8753654956817627
Validation loss: 2.255002419153849

Epoch: 5| Step: 4
Training loss: 1.271112322807312
Validation loss: 2.252595325311025

Epoch: 5| Step: 5
Training loss: 1.1847569942474365
Validation loss: 2.276260574658712

Epoch: 5| Step: 6
Training loss: 1.1538525819778442
Validation loss: 2.2677179674307504

Epoch: 5| Step: 7
Training loss: 1.0992743968963623
Validation loss: 2.2699235578378043

Epoch: 5| Step: 8
Training loss: 1.2246384620666504
Validation loss: 2.2577928652366004

Epoch: 5| Step: 9
Training loss: 1.5015881061553955
Validation loss: 2.2599215656518936

Epoch: 5| Step: 10
Training loss: 0.9284029006958008
Validation loss: 2.2869868775208793

Epoch: 5| Step: 11
Training loss: 0.3048750162124634
Validation loss: 2.2279785176118216

Epoch: 421| Step: 0
Training loss: 1.2966316938400269
Validation loss: 2.229323556025823

Epoch: 5| Step: 1
Training loss: 0.8470662832260132
Validation loss: 2.2341440518697104

Epoch: 5| Step: 2
Training loss: 0.785489022731781
Validation loss: 2.220636193950971

Epoch: 5| Step: 3
Training loss: 1.05991530418396
Validation loss: 2.2288411955038705

Epoch: 5| Step: 4
Training loss: 0.864467978477478
Validation loss: 2.2123881677786508

Epoch: 5| Step: 5
Training loss: 0.8144125938415527
Validation loss: 2.193397348125776

Epoch: 5| Step: 6
Training loss: 1.189024567604065
Validation loss: 2.203790138165156

Epoch: 5| Step: 7
Training loss: 1.3567641973495483
Validation loss: 2.2623924612998962

Epoch: 5| Step: 8
Training loss: 1.6889756917953491
Validation loss: 2.229978308081627

Epoch: 5| Step: 9
Training loss: 0.8152063488960266
Validation loss: 2.2137959798177085

Epoch: 5| Step: 10
Training loss: 0.9677831530570984
Validation loss: 2.2100561062494912

Epoch: 5| Step: 11
Training loss: 1.8326984643936157
Validation loss: 2.2085573077201843

Epoch: 422| Step: 0
Training loss: 0.7916026711463928
Validation loss: 2.212754105528196

Epoch: 5| Step: 1
Training loss: 0.7377883195877075
Validation loss: 2.1946911116441092

Epoch: 5| Step: 2
Training loss: 1.4558618068695068
Validation loss: 2.2273625632127128

Epoch: 5| Step: 3
Training loss: 0.5588641166687012
Validation loss: 2.201290895541509

Epoch: 5| Step: 4
Training loss: 0.7960013747215271
Validation loss: 2.2363157272338867

Epoch: 5| Step: 5
Training loss: 1.2120565176010132
Validation loss: 2.209935113787651

Epoch: 5| Step: 6
Training loss: 1.4941269159317017
Validation loss: 2.2298126171032586

Epoch: 5| Step: 7
Training loss: 1.1146363019943237
Validation loss: 2.2017313043276467

Epoch: 5| Step: 8
Training loss: 1.7879060506820679
Validation loss: 2.188080539306005

Epoch: 5| Step: 9
Training loss: 0.7134560346603394
Validation loss: 2.219629575808843

Epoch: 5| Step: 10
Training loss: 1.1143673658370972
Validation loss: 2.242472012837728

Epoch: 5| Step: 11
Training loss: 0.6164000630378723
Validation loss: 2.209815035263697

Epoch: 423| Step: 0
Training loss: 0.8387492895126343
Validation loss: 2.190093994140625

Epoch: 5| Step: 1
Training loss: 1.184892177581787
Validation loss: 2.216546763976415

Epoch: 5| Step: 2
Training loss: 1.3400871753692627
Validation loss: 2.2154026180505753

Epoch: 5| Step: 3
Training loss: 1.1361230611801147
Validation loss: 2.221692532300949

Epoch: 5| Step: 4
Training loss: 1.3675377368927002
Validation loss: 2.208394780755043

Epoch: 5| Step: 5
Training loss: 1.1244447231292725
Validation loss: 2.222069174051285

Epoch: 5| Step: 6
Training loss: 0.897493839263916
Validation loss: 2.224422718087832

Epoch: 5| Step: 7
Training loss: 0.7183873057365417
Validation loss: 2.2588001688321433

Epoch: 5| Step: 8
Training loss: 1.2140543460845947
Validation loss: 2.17932923634847

Epoch: 5| Step: 9
Training loss: 0.6756026148796082
Validation loss: 2.2053447365760803

Epoch: 5| Step: 10
Training loss: 0.8425841331481934
Validation loss: 2.1932566414276757

Epoch: 5| Step: 11
Training loss: 2.6387317180633545
Validation loss: 2.2099711249272027

Epoch: 424| Step: 0
Training loss: 0.6839162707328796
Validation loss: 2.208677093187968

Epoch: 5| Step: 1
Training loss: 1.273180365562439
Validation loss: 2.2368891686201096

Epoch: 5| Step: 2
Training loss: 1.2726972103118896
Validation loss: 2.202105482419332

Epoch: 5| Step: 3
Training loss: 1.1567811965942383
Validation loss: 2.18748572965463

Epoch: 5| Step: 4
Training loss: 1.1247918605804443
Validation loss: 2.196520129839579

Epoch: 5| Step: 5
Training loss: 1.3869596719741821
Validation loss: 2.1719907373189926

Epoch: 5| Step: 6
Training loss: 1.0159757137298584
Validation loss: 2.194152365128199

Epoch: 5| Step: 7
Training loss: 0.4721490740776062
Validation loss: 2.199659844239553

Epoch: 5| Step: 8
Training loss: 0.6240724325180054
Validation loss: 2.1993746807177863

Epoch: 5| Step: 9
Training loss: 1.266000747680664
Validation loss: 2.178036948045095

Epoch: 5| Step: 10
Training loss: 1.1593284606933594
Validation loss: 2.2344922622044883

Epoch: 5| Step: 11
Training loss: 1.1191459894180298
Validation loss: 2.204705407222112

Epoch: 425| Step: 0
Training loss: 0.8957802057266235
Validation loss: 2.2176070660352707

Epoch: 5| Step: 1
Training loss: 1.3682801723480225
Validation loss: 2.2604571084181466

Epoch: 5| Step: 2
Training loss: 1.6048663854599
Validation loss: 2.247475251555443

Epoch: 5| Step: 3
Training loss: 1.6062803268432617
Validation loss: 2.2394666373729706

Epoch: 5| Step: 4
Training loss: 0.9189678430557251
Validation loss: 2.262681389848391

Epoch: 5| Step: 5
Training loss: 1.3344093561172485
Validation loss: 2.2387115408976874

Epoch: 5| Step: 6
Training loss: 1.2384690046310425
Validation loss: 2.1823151806990304

Epoch: 5| Step: 7
Training loss: 0.9931758642196655
Validation loss: 2.196192299326261

Epoch: 5| Step: 8
Training loss: 0.9612139463424683
Validation loss: 2.1907725632190704

Epoch: 5| Step: 9
Training loss: 1.3920526504516602
Validation loss: 2.194682856400808

Epoch: 5| Step: 10
Training loss: 1.3253567218780518
Validation loss: 2.1970582654078803

Epoch: 5| Step: 11
Training loss: 0.4976363182067871
Validation loss: 2.194900463024775

Epoch: 426| Step: 0
Training loss: 0.9633625745773315
Validation loss: 2.1799384454886117

Epoch: 5| Step: 1
Training loss: 1.7757136821746826
Validation loss: 2.188270390033722

Epoch: 5| Step: 2
Training loss: 1.2048434019088745
Validation loss: 2.18963431318601

Epoch: 5| Step: 3
Training loss: 0.9996896982192993
Validation loss: 2.198337803284327

Epoch: 5| Step: 4
Training loss: 1.4281575679779053
Validation loss: 2.190178240338961

Epoch: 5| Step: 5
Training loss: 1.1693449020385742
Validation loss: 2.176701327164968

Epoch: 5| Step: 6
Training loss: 0.9623491168022156
Validation loss: 2.173481067021688

Epoch: 5| Step: 7
Training loss: 1.0374596118927002
Validation loss: 2.2487796197334924

Epoch: 5| Step: 8
Training loss: 0.920002281665802
Validation loss: 2.1695833653211594

Epoch: 5| Step: 9
Training loss: 1.1359747648239136
Validation loss: 2.16824671626091

Epoch: 5| Step: 10
Training loss: 1.0704922676086426
Validation loss: 2.2357466717561087

Epoch: 5| Step: 11
Training loss: 0.720935583114624
Validation loss: 2.1962834199269614

Epoch: 427| Step: 0
Training loss: 1.1859874725341797
Validation loss: 2.2151907781759896

Epoch: 5| Step: 1
Training loss: 1.1677831411361694
Validation loss: 2.198596422870954

Epoch: 5| Step: 2
Training loss: 1.3717249631881714
Validation loss: 2.2410174210866294

Epoch: 5| Step: 3
Training loss: 1.1305296421051025
Validation loss: 2.2270262142022452

Epoch: 5| Step: 4
Training loss: 0.9853226542472839
Validation loss: 2.1891576051712036

Epoch: 5| Step: 5
Training loss: 1.2583972215652466
Validation loss: 2.208814725279808

Epoch: 5| Step: 6
Training loss: 0.7975874543190002
Validation loss: 2.2124580840269723

Epoch: 5| Step: 7
Training loss: 1.028993844985962
Validation loss: 2.2301511267820993

Epoch: 5| Step: 8
Training loss: 1.2344655990600586
Validation loss: 2.212125023206075

Epoch: 5| Step: 9
Training loss: 1.359378695487976
Validation loss: 2.2189889550209045

Epoch: 5| Step: 10
Training loss: 0.8408405184745789
Validation loss: 2.224949926137924

Epoch: 5| Step: 11
Training loss: 0.6701304316520691
Validation loss: 2.2617918103933334

Epoch: 428| Step: 0
Training loss: 1.1288087368011475
Validation loss: 2.2417167723178864

Epoch: 5| Step: 1
Training loss: 0.9600079655647278
Validation loss: 2.265713800986608

Epoch: 5| Step: 2
Training loss: 1.2205313444137573
Validation loss: 2.2193936556577682

Epoch: 5| Step: 3
Training loss: 0.6688796281814575
Validation loss: 2.257413998246193

Epoch: 5| Step: 4
Training loss: 1.0811389684677124
Validation loss: 2.230912139018377

Epoch: 5| Step: 5
Training loss: 1.1014163494110107
Validation loss: 2.2116916875044503

Epoch: 5| Step: 6
Training loss: 1.603062629699707
Validation loss: 2.2507083465655646

Epoch: 5| Step: 7
Training loss: 1.0558642148971558
Validation loss: 2.2766493956247964

Epoch: 5| Step: 8
Training loss: 0.8264642953872681
Validation loss: 2.3382058640321097

Epoch: 5| Step: 9
Training loss: 1.2017242908477783
Validation loss: 2.2902705570062003

Epoch: 5| Step: 10
Training loss: 1.7810075283050537
Validation loss: 2.273742953936259

Epoch: 5| Step: 11
Training loss: 1.1961337327957153
Validation loss: 2.207162951429685

Epoch: 429| Step: 0
Training loss: 1.2456111907958984
Validation loss: 2.2735794385274253

Epoch: 5| Step: 1
Training loss: 1.6306089162826538
Validation loss: 2.2383023699124656

Epoch: 5| Step: 2
Training loss: 1.3925443887710571
Validation loss: 2.2673717538515725

Epoch: 5| Step: 3
Training loss: 1.2381962537765503
Validation loss: 2.284826765457789

Epoch: 5| Step: 4
Training loss: 0.7559636831283569
Validation loss: 2.2605635672807693

Epoch: 5| Step: 5
Training loss: 0.5030436515808105
Validation loss: 2.211071863770485

Epoch: 5| Step: 6
Training loss: 1.1501612663269043
Validation loss: 2.224769582351049

Epoch: 5| Step: 7
Training loss: 0.9697176814079285
Validation loss: 2.244413803021113

Epoch: 5| Step: 8
Training loss: 1.0670353174209595
Validation loss: 2.2050422926743827

Epoch: 5| Step: 9
Training loss: 0.7547153234481812
Validation loss: 2.1986882189909616

Epoch: 5| Step: 10
Training loss: 1.2317384481430054
Validation loss: 2.2391663640737534

Epoch: 5| Step: 11
Training loss: 0.48956000804901123
Validation loss: 2.239163895448049

Epoch: 430| Step: 0
Training loss: 1.2975513935089111
Validation loss: 2.214258382717768

Epoch: 5| Step: 1
Training loss: 0.4771852493286133
Validation loss: 2.2136097053686776

Epoch: 5| Step: 2
Training loss: 0.6365568041801453
Validation loss: 2.2332707047462463

Epoch: 5| Step: 3
Training loss: 0.5848894119262695
Validation loss: 2.23202878733476

Epoch: 5| Step: 4
Training loss: 1.083248257637024
Validation loss: 2.2457011689742408

Epoch: 5| Step: 5
Training loss: 1.5067670345306396
Validation loss: 2.2503331899642944

Epoch: 5| Step: 6
Training loss: 1.1265885829925537
Validation loss: 2.230223442117373

Epoch: 5| Step: 7
Training loss: 0.9441024661064148
Validation loss: 2.2255433201789856

Epoch: 5| Step: 8
Training loss: 1.8264633417129517
Validation loss: 2.2085942377646766

Epoch: 5| Step: 9
Training loss: 0.8374409675598145
Validation loss: 2.2328697443008423

Epoch: 5| Step: 10
Training loss: 1.2947872877120972
Validation loss: 2.235476166009903

Epoch: 5| Step: 11
Training loss: 2.179941177368164
Validation loss: 2.2243003447850547

Epoch: 431| Step: 0
Training loss: 1.3412134647369385
Validation loss: 2.2134619057178497

Epoch: 5| Step: 1
Training loss: 1.0115938186645508
Validation loss: 2.2140977482000985

Epoch: 5| Step: 2
Training loss: 1.591822862625122
Validation loss: 2.2383965055147805

Epoch: 5| Step: 3
Training loss: 0.6694009900093079
Validation loss: 2.2370044390360513

Epoch: 5| Step: 4
Training loss: 1.1181561946868896
Validation loss: 2.2345382471879325

Epoch: 5| Step: 5
Training loss: 1.2622182369232178
Validation loss: 2.224789430697759

Epoch: 5| Step: 6
Training loss: 0.5290632247924805
Validation loss: 2.2199420581261315

Epoch: 5| Step: 7
Training loss: 1.5827560424804688
Validation loss: 2.2005522350470224

Epoch: 5| Step: 8
Training loss: 1.3994427919387817
Validation loss: 2.205935170253118

Epoch: 5| Step: 9
Training loss: 0.7977226376533508
Validation loss: 2.2052261382341385

Epoch: 5| Step: 10
Training loss: 0.6599501371383667
Validation loss: 2.1991408864657083

Epoch: 5| Step: 11
Training loss: 0.5211324691772461
Validation loss: 2.2353233695030212

Epoch: 432| Step: 0
Training loss: 0.9310281872749329
Validation loss: 2.196433668335279

Epoch: 5| Step: 1
Training loss: 0.9276539087295532
Validation loss: 2.187963609894117

Epoch: 5| Step: 2
Training loss: 0.9630664587020874
Validation loss: 2.173013577858607

Epoch: 5| Step: 3
Training loss: 1.1901878118515015
Validation loss: 2.214890996615092

Epoch: 5| Step: 4
Training loss: 0.8218952417373657
Validation loss: 2.181004842122396

Epoch: 5| Step: 5
Training loss: 1.5092966556549072
Validation loss: 2.2024924059708915

Epoch: 5| Step: 6
Training loss: 1.0478249788284302
Validation loss: 2.1792197028795877

Epoch: 5| Step: 7
Training loss: 0.7037543058395386
Validation loss: 2.2016928791999817

Epoch: 5| Step: 8
Training loss: 1.5101820230484009
Validation loss: 2.186256726582845

Epoch: 5| Step: 9
Training loss: 1.0165424346923828
Validation loss: 2.1895563999811807

Epoch: 5| Step: 10
Training loss: 0.8469904065132141
Validation loss: 2.2004439532756805

Epoch: 5| Step: 11
Training loss: 1.5946201086044312
Validation loss: 2.2087745120127997

Epoch: 433| Step: 0
Training loss: 1.1010265350341797
Validation loss: 2.1796717643737793

Epoch: 5| Step: 1
Training loss: 1.2449493408203125
Validation loss: 2.196045378843943

Epoch: 5| Step: 2
Training loss: 1.0793040990829468
Validation loss: 2.2367427994807563

Epoch: 5| Step: 3
Training loss: 0.5846236944198608
Validation loss: 2.214791943629583

Epoch: 5| Step: 4
Training loss: 0.8057738542556763
Validation loss: 2.256188382705053

Epoch: 5| Step: 5
Training loss: 1.4674031734466553
Validation loss: 2.1976043780644736

Epoch: 5| Step: 6
Training loss: 1.4888309240341187
Validation loss: 2.225854381918907

Epoch: 5| Step: 7
Training loss: 1.2805849313735962
Validation loss: 2.2339262465635934

Epoch: 5| Step: 8
Training loss: 1.112579345703125
Validation loss: 2.206234415372213

Epoch: 5| Step: 9
Training loss: 0.8298169374465942
Validation loss: 2.2457541277011237

Epoch: 5| Step: 10
Training loss: 0.4118046164512634
Validation loss: 2.1936505287885666

Epoch: 5| Step: 11
Training loss: 1.3844122886657715
Validation loss: 2.2342812567949295

Epoch: 434| Step: 0
Training loss: 1.2830783128738403
Validation loss: 2.245161692301432

Epoch: 5| Step: 1
Training loss: 0.9441696405410767
Validation loss: 2.2254007160663605

Epoch: 5| Step: 2
Training loss: 0.8008653521537781
Validation loss: 2.255069226026535

Epoch: 5| Step: 3
Training loss: 1.2440016269683838
Validation loss: 2.2678700337807336

Epoch: 5| Step: 4
Training loss: 1.089980125427246
Validation loss: 2.2262646853923798

Epoch: 5| Step: 5
Training loss: 1.3251161575317383
Validation loss: 2.2458943029244742

Epoch: 5| Step: 6
Training loss: 1.284663438796997
Validation loss: 2.2396889676650367

Epoch: 5| Step: 7
Training loss: 0.6928761601448059
Validation loss: 2.251146932442983

Epoch: 5| Step: 8
Training loss: 1.0448544025421143
Validation loss: 2.2431979974110923

Epoch: 5| Step: 9
Training loss: 0.8623327016830444
Validation loss: 2.236305226882299

Epoch: 5| Step: 10
Training loss: 0.7101602554321289
Validation loss: 2.2381863494714103

Epoch: 5| Step: 11
Training loss: 2.71501088142395
Validation loss: 2.2405577103296914

Epoch: 435| Step: 0
Training loss: 1.483799695968628
Validation loss: 2.200211857755979

Epoch: 5| Step: 1
Training loss: 1.5335056781768799
Validation loss: 2.2028982688983283

Epoch: 5| Step: 2
Training loss: 0.8291155099868774
Validation loss: 2.231902008255323

Epoch: 5| Step: 3
Training loss: 0.8486320376396179
Validation loss: 2.2076446215311685

Epoch: 5| Step: 4
Training loss: 0.8290634155273438
Validation loss: 2.249039148290952

Epoch: 5| Step: 5
Training loss: 0.8769310712814331
Validation loss: 2.213985393444697

Epoch: 5| Step: 6
Training loss: 1.1384942531585693
Validation loss: 2.21333384513855

Epoch: 5| Step: 7
Training loss: 0.7421477437019348
Validation loss: 2.2330620884895325

Epoch: 5| Step: 8
Training loss: 1.5252931118011475
Validation loss: 2.2000961353381476

Epoch: 5| Step: 9
Training loss: 1.1706156730651855
Validation loss: 2.2093429267406464

Epoch: 5| Step: 10
Training loss: 1.7463016510009766
Validation loss: 2.192746395866076

Epoch: 5| Step: 11
Training loss: 1.1032435894012451
Validation loss: 2.197433720032374

Epoch: 436| Step: 0
Training loss: 1.362499475479126
Validation loss: 2.172862042983373

Epoch: 5| Step: 1
Training loss: 0.9586588144302368
Validation loss: 2.1635977973540625

Epoch: 5| Step: 2
Training loss: 0.8928282856941223
Validation loss: 2.1786954551935196

Epoch: 5| Step: 3
Training loss: 1.0815482139587402
Validation loss: 2.194161425034205

Epoch: 5| Step: 4
Training loss: 1.0749831199645996
Validation loss: 2.1788102785746255

Epoch: 5| Step: 5
Training loss: 1.565002679824829
Validation loss: 2.158879597981771

Epoch: 5| Step: 6
Training loss: 1.272983431816101
Validation loss: 2.2086045841375985

Epoch: 5| Step: 7
Training loss: 1.138595700263977
Validation loss: 2.1658051759004593

Epoch: 5| Step: 8
Training loss: 1.5045063495635986
Validation loss: 2.166970377167066

Epoch: 5| Step: 9
Training loss: 0.5223797559738159
Validation loss: 2.1926323920488358

Epoch: 5| Step: 10
Training loss: 0.47961458563804626
Validation loss: 2.1961647421121597

Epoch: 5| Step: 11
Training loss: 0.26590442657470703
Validation loss: 2.1896656652291617

Epoch: 437| Step: 0
Training loss: 1.0522923469543457
Validation loss: 2.1585303942362466

Epoch: 5| Step: 1
Training loss: 0.6913148164749146
Validation loss: 2.1751570204893746

Epoch: 5| Step: 2
Training loss: 1.3678152561187744
Validation loss: 2.223650942246119

Epoch: 5| Step: 3
Training loss: 1.0660412311553955
Validation loss: 2.2161116699377694

Epoch: 5| Step: 4
Training loss: 1.2887113094329834
Validation loss: 2.20583039522171

Epoch: 5| Step: 5
Training loss: 1.577300786972046
Validation loss: 2.197311520576477

Epoch: 5| Step: 6
Training loss: 1.185072898864746
Validation loss: 2.2073851426442466

Epoch: 5| Step: 7
Training loss: 0.8423234820365906
Validation loss: 2.2333052357037864

Epoch: 5| Step: 8
Training loss: 0.7657420039176941
Validation loss: 2.2340181469917297

Epoch: 5| Step: 9
Training loss: 0.7945201992988586
Validation loss: 2.1765371511379876

Epoch: 5| Step: 10
Training loss: 1.1891003847122192
Validation loss: 2.217775116364161

Epoch: 5| Step: 11
Training loss: 0.7378970384597778
Validation loss: 2.239040568470955

Epoch: 438| Step: 0
Training loss: 1.1444333791732788
Validation loss: 2.2110156267881393

Epoch: 5| Step: 1
Training loss: 0.9394825100898743
Validation loss: 2.2171861430009208

Epoch: 5| Step: 2
Training loss: 0.5543481111526489
Validation loss: 2.250385969877243

Epoch: 5| Step: 3
Training loss: 1.2579574584960938
Validation loss: 2.23678690691789

Epoch: 5| Step: 4
Training loss: 1.132986068725586
Validation loss: 2.2481950422128043

Epoch: 5| Step: 5
Training loss: 0.6483873724937439
Validation loss: 2.235324422518412

Epoch: 5| Step: 6
Training loss: 0.6350852251052856
Validation loss: 2.233173295855522

Epoch: 5| Step: 7
Training loss: 1.0992201566696167
Validation loss: 2.2012390146652856

Epoch: 5| Step: 8
Training loss: 1.6547024250030518
Validation loss: 2.210111399491628

Epoch: 5| Step: 9
Training loss: 1.1346256732940674
Validation loss: 2.224056070049604

Epoch: 5| Step: 10
Training loss: 0.9158045053482056
Validation loss: 2.2036029597123465

Epoch: 5| Step: 11
Training loss: 1.481563687324524
Validation loss: 2.1875354697306952

Epoch: 439| Step: 0
Training loss: 0.8713515996932983
Validation loss: 2.176529347896576

Epoch: 5| Step: 1
Training loss: 0.738487184047699
Validation loss: 2.1734259327252707

Epoch: 5| Step: 2
Training loss: 0.9429561495780945
Validation loss: 2.2151006112496057

Epoch: 5| Step: 3
Training loss: 1.3633065223693848
Validation loss: 2.265233506759008

Epoch: 5| Step: 4
Training loss: 0.8139345049858093
Validation loss: 2.2233122239510217

Epoch: 5| Step: 5
Training loss: 0.7931880950927734
Validation loss: 2.2584661742051444

Epoch: 5| Step: 6
Training loss: 1.0878020524978638
Validation loss: 2.237395336230596

Epoch: 5| Step: 7
Training loss: 0.8151052594184875
Validation loss: 2.219644993543625

Epoch: 5| Step: 8
Training loss: 1.5626105070114136
Validation loss: 2.2221678694089255

Epoch: 5| Step: 9
Training loss: 0.7806718349456787
Validation loss: 2.2528515656789145

Epoch: 5| Step: 10
Training loss: 1.2604262828826904
Validation loss: 2.2249121169249215

Epoch: 5| Step: 11
Training loss: 1.769699215888977
Validation loss: 2.230215013027191

Epoch: 440| Step: 0
Training loss: 1.0040134191513062
Validation loss: 2.1911247074604034

Epoch: 5| Step: 1
Training loss: 0.7812092304229736
Validation loss: 2.1941134681304297

Epoch: 5| Step: 2
Training loss: 0.5889638662338257
Validation loss: 2.2155880828698478

Epoch: 5| Step: 3
Training loss: 0.5358061790466309
Validation loss: 2.2155295262734094

Epoch: 5| Step: 4
Training loss: 0.7769615054130554
Validation loss: 2.189669062693914

Epoch: 5| Step: 5
Training loss: 1.6688520908355713
Validation loss: 2.218404099345207

Epoch: 5| Step: 6
Training loss: 1.3550649881362915
Validation loss: 2.2159962256749473

Epoch: 5| Step: 7
Training loss: 1.4688955545425415
Validation loss: 2.240049039324125

Epoch: 5| Step: 8
Training loss: 1.046974778175354
Validation loss: 2.198300282160441

Epoch: 5| Step: 9
Training loss: 0.9389225244522095
Validation loss: 2.200151950120926

Epoch: 5| Step: 10
Training loss: 0.8596948385238647
Validation loss: 2.238980089624723

Epoch: 5| Step: 11
Training loss: 1.6041630506515503
Validation loss: 2.201187531153361

Epoch: 441| Step: 0
Training loss: 0.8525641560554504
Validation loss: 2.2155806024869285

Epoch: 5| Step: 1
Training loss: 1.3782856464385986
Validation loss: 2.2090444763501487

Epoch: 5| Step: 2
Training loss: 1.2099101543426514
Validation loss: 2.2584400524695716

Epoch: 5| Step: 3
Training loss: 1.2654708623886108
Validation loss: 2.2243970980246863

Epoch: 5| Step: 4
Training loss: 0.9147736430168152
Validation loss: 2.2206881741682687

Epoch: 5| Step: 5
Training loss: 0.8812980651855469
Validation loss: 2.21055705845356

Epoch: 5| Step: 6
Training loss: 0.6310186982154846
Validation loss: 2.2153266221284866

Epoch: 5| Step: 7
Training loss: 1.1446434259414673
Validation loss: 2.2154993563890457

Epoch: 5| Step: 8
Training loss: 1.0337971448898315
Validation loss: 2.2064750095208487

Epoch: 5| Step: 9
Training loss: 1.0675090551376343
Validation loss: 2.162390132745107

Epoch: 5| Step: 10
Training loss: 0.7292593121528625
Validation loss: 2.2176233728726706

Epoch: 5| Step: 11
Training loss: 0.8678749799728394
Validation loss: 2.1874538163344064

Epoch: 442| Step: 0
Training loss: 1.530521035194397
Validation loss: 2.2087753117084503

Epoch: 5| Step: 1
Training loss: 1.062986969947815
Validation loss: 2.260485033194224

Epoch: 5| Step: 2
Training loss: 1.1118770837783813
Validation loss: 2.2189791848262153

Epoch: 5| Step: 3
Training loss: 0.549644410610199
Validation loss: 2.2158735493818917

Epoch: 5| Step: 4
Training loss: 1.0614405870437622
Validation loss: 2.2582507332166037

Epoch: 5| Step: 5
Training loss: 0.8669271469116211
Validation loss: 2.2707836031913757

Epoch: 5| Step: 6
Training loss: 1.3061474561691284
Validation loss: 2.225102891524633

Epoch: 5| Step: 7
Training loss: 0.6958674192428589
Validation loss: 2.2638172606627145

Epoch: 5| Step: 8
Training loss: 1.434147834777832
Validation loss: 2.269045223792394

Epoch: 5| Step: 9
Training loss: 0.6672762632369995
Validation loss: 2.2158864537874856

Epoch: 5| Step: 10
Training loss: 0.6004226207733154
Validation loss: 2.232085367043813

Epoch: 5| Step: 11
Training loss: 0.13170385360717773
Validation loss: 2.1892114778359733

Epoch: 443| Step: 0
Training loss: 1.446112871170044
Validation loss: 2.269231081008911

Epoch: 5| Step: 1
Training loss: 0.9120602607727051
Validation loss: 2.2115411361058555

Epoch: 5| Step: 2
Training loss: 0.6389080882072449
Validation loss: 2.1459418485562005

Epoch: 5| Step: 3
Training loss: 0.8206407427787781
Validation loss: 2.219935188690821

Epoch: 5| Step: 4
Training loss: 1.0695048570632935
Validation loss: 2.1670976976553598

Epoch: 5| Step: 5
Training loss: 1.0529611110687256
Validation loss: 2.1829337080319724

Epoch: 5| Step: 6
Training loss: 1.0068116188049316
Validation loss: 2.2034656554460526

Epoch: 5| Step: 7
Training loss: 1.0293395519256592
Validation loss: 2.1443354884783425

Epoch: 5| Step: 8
Training loss: 1.2091903686523438
Validation loss: 2.1555449664592743

Epoch: 5| Step: 9
Training loss: 1.059160590171814
Validation loss: 2.1760594149430594

Epoch: 5| Step: 10
Training loss: 0.9053282737731934
Validation loss: 2.1508741974830627

Epoch: 5| Step: 11
Training loss: 1.5247902870178223
Validation loss: 2.145592292149862

Epoch: 444| Step: 0
Training loss: 1.0118674039840698
Validation loss: 2.1650866766770682

Epoch: 5| Step: 1
Training loss: 1.1333099603652954
Validation loss: 2.1657643814881644

Epoch: 5| Step: 2
Training loss: 0.8492186665534973
Validation loss: 2.1400027175744376

Epoch: 5| Step: 3
Training loss: 1.0724653005599976
Validation loss: 2.1771357407172522

Epoch: 5| Step: 4
Training loss: 1.192962408065796
Validation loss: 2.1858530739943185

Epoch: 5| Step: 5
Training loss: 1.2779830694198608
Validation loss: 2.1792827596267066

Epoch: 5| Step: 6
Training loss: 1.0085941553115845
Validation loss: 2.1893708308537803

Epoch: 5| Step: 7
Training loss: 1.1022552251815796
Validation loss: 2.205836604038874

Epoch: 5| Step: 8
Training loss: 0.9508905410766602
Validation loss: 2.1609564224878945

Epoch: 5| Step: 9
Training loss: 0.5887185335159302
Validation loss: 2.2019559144973755

Epoch: 5| Step: 10
Training loss: 0.7381724715232849
Validation loss: 2.22797196606795

Epoch: 5| Step: 11
Training loss: 0.39161884784698486
Validation loss: 2.24972373743852

Epoch: 445| Step: 0
Training loss: 0.7416530847549438
Validation loss: 2.2004455228646598

Epoch: 5| Step: 1
Training loss: 1.0676227807998657
Validation loss: 2.2238263388474784

Epoch: 5| Step: 2
Training loss: 1.3212019205093384
Validation loss: 2.2226915111144385

Epoch: 5| Step: 3
Training loss: 1.2349903583526611
Validation loss: 2.2126490275065103

Epoch: 5| Step: 4
Training loss: 1.1944224834442139
Validation loss: 2.2182476421197257

Epoch: 5| Step: 5
Training loss: 0.9804523587226868
Validation loss: 2.2248759865760803

Epoch: 5| Step: 6
Training loss: 0.4891892373561859
Validation loss: 2.1785133679707847

Epoch: 5| Step: 7
Training loss: 0.8665542602539062
Validation loss: 2.1783678432305655

Epoch: 5| Step: 8
Training loss: 1.0588139295578003
Validation loss: 2.1500816444555917

Epoch: 5| Step: 9
Training loss: 0.7216626405715942
Validation loss: 2.170445183912913

Epoch: 5| Step: 10
Training loss: 1.0255976915359497
Validation loss: 2.1806314885616302

Epoch: 5| Step: 11
Training loss: 1.0394270420074463
Validation loss: 2.220794051885605

Epoch: 446| Step: 0
Training loss: 1.0304765701293945
Validation loss: 2.1474695603052774

Epoch: 5| Step: 1
Training loss: 1.0157978534698486
Validation loss: 2.2097534437974296

Epoch: 5| Step: 2
Training loss: 0.7406221628189087
Validation loss: 2.206373537580172

Epoch: 5| Step: 3
Training loss: 0.8326576352119446
Validation loss: 2.2208405236403146

Epoch: 5| Step: 4
Training loss: 0.9593938589096069
Validation loss: 2.2088317026694617

Epoch: 5| Step: 5
Training loss: 0.7075782418251038
Validation loss: 2.21264178554217

Epoch: 5| Step: 6
Training loss: 1.338158130645752
Validation loss: 2.204905867576599

Epoch: 5| Step: 7
Training loss: 1.3798353672027588
Validation loss: 2.19216288626194

Epoch: 5| Step: 8
Training loss: 0.7658208608627319
Validation loss: 2.2434347768624625

Epoch: 5| Step: 9
Training loss: 1.1589083671569824
Validation loss: 2.2227587898572287

Epoch: 5| Step: 10
Training loss: 0.5075890421867371
Validation loss: 2.1781348387400308

Epoch: 5| Step: 11
Training loss: 0.5742595195770264
Validation loss: 2.2312653362751007

Epoch: 447| Step: 0
Training loss: 0.6379463076591492
Validation loss: 2.2251119116942086

Epoch: 5| Step: 1
Training loss: 1.028276801109314
Validation loss: 2.2332420349121094

Epoch: 5| Step: 2
Training loss: 1.6777280569076538
Validation loss: 2.2692522207895913

Epoch: 5| Step: 3
Training loss: 0.7144025564193726
Validation loss: 2.293921689192454

Epoch: 5| Step: 4
Training loss: 1.105201005935669
Validation loss: 2.2252119183540344

Epoch: 5| Step: 5
Training loss: 0.8248337507247925
Validation loss: 2.2320632139841714

Epoch: 5| Step: 6
Training loss: 1.1621142625808716
Validation loss: 2.225443651278814

Epoch: 5| Step: 7
Training loss: 1.1662286520004272
Validation loss: 2.2145785888036094

Epoch: 5| Step: 8
Training loss: 0.6390873789787292
Validation loss: 2.2428832997878394

Epoch: 5| Step: 9
Training loss: 1.00875723361969
Validation loss: 2.2563250164190927

Epoch: 5| Step: 10
Training loss: 0.6030561327934265
Validation loss: 2.1988148391246796

Epoch: 5| Step: 11
Training loss: 1.9844574928283691
Validation loss: 2.2032378713289895

Epoch: 448| Step: 0
Training loss: 0.7369645237922668
Validation loss: 2.229820102453232

Epoch: 5| Step: 1
Training loss: 0.9326183199882507
Validation loss: 2.1998778879642487

Epoch: 5| Step: 2
Training loss: 1.1983869075775146
Validation loss: 2.1977218687534332

Epoch: 5| Step: 3
Training loss: 1.4638607501983643
Validation loss: 2.2479506880044937

Epoch: 5| Step: 4
Training loss: 1.0130980014801025
Validation loss: 2.2049799859523773

Epoch: 5| Step: 5
Training loss: 0.9725791811943054
Validation loss: 2.175890247027079

Epoch: 5| Step: 6
Training loss: 0.7725943922996521
Validation loss: 2.177413339416186

Epoch: 5| Step: 7
Training loss: 1.1377959251403809
Validation loss: 2.222833588719368

Epoch: 5| Step: 8
Training loss: 0.9335979223251343
Validation loss: 2.180663446585337

Epoch: 5| Step: 9
Training loss: 0.8659530878067017
Validation loss: 2.211746573448181

Epoch: 5| Step: 10
Training loss: 0.8482767939567566
Validation loss: 2.2289534509181976

Epoch: 5| Step: 11
Training loss: 0.7017132639884949
Validation loss: 2.1901487360397973

Epoch: 449| Step: 0
Training loss: 0.8318262100219727
Validation loss: 2.1838524788618088

Epoch: 5| Step: 1
Training loss: 0.9074831008911133
Validation loss: 2.207961385448774

Epoch: 5| Step: 2
Training loss: 1.0128154754638672
Validation loss: 2.212190439303716

Epoch: 5| Step: 3
Training loss: 0.864637017250061
Validation loss: 2.2037008106708527

Epoch: 5| Step: 4
Training loss: 0.9919412732124329
Validation loss: 2.1564659426609674

Epoch: 5| Step: 5
Training loss: 0.905859649181366
Validation loss: 2.157754232486089

Epoch: 5| Step: 6
Training loss: 1.0400145053863525
Validation loss: 2.119917020201683

Epoch: 5| Step: 7
Training loss: 0.7980035543441772
Validation loss: 2.1925325890382132

Epoch: 5| Step: 8
Training loss: 1.4225842952728271
Validation loss: 2.186800311009089

Epoch: 5| Step: 9
Training loss: 1.0678669214248657
Validation loss: 2.1766418119271598

Epoch: 5| Step: 10
Training loss: 0.8010932803153992
Validation loss: 2.207426389058431

Epoch: 5| Step: 11
Training loss: 2.1484808921813965
Validation loss: 2.186163544654846

Epoch: 450| Step: 0
Training loss: 0.8841686248779297
Validation loss: 2.1873439451058707

Epoch: 5| Step: 1
Training loss: 0.870884895324707
Validation loss: 2.2337308128674827

Epoch: 5| Step: 2
Training loss: 0.9085168838500977
Validation loss: 2.191353425383568

Epoch: 5| Step: 3
Training loss: 1.4384828805923462
Validation loss: 2.1973979522784552

Epoch: 5| Step: 4
Training loss: 1.0125277042388916
Validation loss: 2.1969256599744162

Epoch: 5| Step: 5
Training loss: 0.7420694828033447
Validation loss: 2.223058114449183

Epoch: 5| Step: 6
Training loss: 1.4226710796356201
Validation loss: 2.18819389740626

Epoch: 5| Step: 7
Training loss: 1.2516731023788452
Validation loss: 2.191929449637731

Epoch: 5| Step: 8
Training loss: 0.7313061952590942
Validation loss: 2.228300924102465

Epoch: 5| Step: 9
Training loss: 0.31008070707321167
Validation loss: 2.1995777984460196

Epoch: 5| Step: 10
Training loss: 0.9483886957168579
Validation loss: 2.222281595071157

Epoch: 5| Step: 11
Training loss: 0.7004225254058838
Validation loss: 2.2450162520011268

Testing loss: 1.9748726894529602
