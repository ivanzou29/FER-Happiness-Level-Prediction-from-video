Epoch: 1| Step: 0
Training loss: 5.402963638305664
Validation loss: 5.614777565002441

Epoch: 5| Step: 1
Training loss: 5.1586785316467285
Validation loss: 5.577976286411285

Epoch: 5| Step: 2
Training loss: 6.0967020988464355
Validation loss: 5.5395132303237915

Epoch: 5| Step: 3
Training loss: 5.669416904449463
Validation loss: 5.504406591256459

Epoch: 5| Step: 4
Training loss: 6.769663333892822
Validation loss: 5.472305019696553

Epoch: 5| Step: 5
Training loss: 5.631970405578613
Validation loss: 5.437574406464894

Epoch: 5| Step: 6
Training loss: 4.320944786071777
Validation loss: 5.404984533786774

Epoch: 5| Step: 7
Training loss: 5.406105995178223
Validation loss: 5.373012185096741

Epoch: 5| Step: 8
Training loss: 4.613222599029541
Validation loss: 5.340410967667897

Epoch: 5| Step: 9
Training loss: 6.559057712554932
Validation loss: 5.309997747341792

Epoch: 5| Step: 10
Training loss: 5.434563636779785
Validation loss: 5.273950119813283

Epoch: 5| Step: 11
Training loss: 2.974067211151123
Validation loss: 5.241464336713155

Epoch: 2| Step: 0
Training loss: 5.48491096496582
Validation loss: 5.211215277512868

Epoch: 5| Step: 1
Training loss: 5.8543853759765625
Validation loss: 5.1776302854220075

Epoch: 5| Step: 2
Training loss: 5.232897758483887
Validation loss: 5.139673014481862

Epoch: 5| Step: 3
Training loss: 4.963709831237793
Validation loss: 5.103813926378886

Epoch: 5| Step: 4
Training loss: 4.196415424346924
Validation loss: 5.067928592363994

Epoch: 5| Step: 5
Training loss: 5.771456718444824
Validation loss: 5.030335783958435

Epoch: 5| Step: 6
Training loss: 5.465291500091553
Validation loss: 4.98824010292689

Epoch: 5| Step: 7
Training loss: 5.258700847625732
Validation loss: 4.951261619726817

Epoch: 5| Step: 8
Training loss: 4.183174133300781
Validation loss: 4.9060567418734236

Epoch: 5| Step: 9
Training loss: 4.561031818389893
Validation loss: 4.861164549986522

Epoch: 5| Step: 10
Training loss: 4.491491794586182
Validation loss: 4.815209488073985

Epoch: 5| Step: 11
Training loss: 7.0834455490112305
Validation loss: 4.770475685596466

Epoch: 3| Step: 0
Training loss: 5.103362083435059
Validation loss: 4.715966562430064

Epoch: 5| Step: 1
Training loss: 4.211269855499268
Validation loss: 4.6628429889678955

Epoch: 5| Step: 2
Training loss: 4.930992126464844
Validation loss: 4.610056062539418

Epoch: 5| Step: 3
Training loss: 4.579449653625488
Validation loss: 4.54935344060262

Epoch: 5| Step: 4
Training loss: 4.2455034255981445
Validation loss: 4.488702456156413

Epoch: 5| Step: 5
Training loss: 3.858912706375122
Validation loss: 4.421291669209798

Epoch: 5| Step: 6
Training loss: 4.336467742919922
Validation loss: 4.360024054845174

Epoch: 5| Step: 7
Training loss: 4.532257080078125
Validation loss: 4.29438070456187

Epoch: 5| Step: 8
Training loss: 4.259108066558838
Validation loss: 4.228686074415843

Epoch: 5| Step: 9
Training loss: 5.195633888244629
Validation loss: 4.160969356695811

Epoch: 5| Step: 10
Training loss: 4.044312477111816
Validation loss: 4.0898493727048235

Epoch: 5| Step: 11
Training loss: 4.889517784118652
Validation loss: 4.009665111700694

Epoch: 4| Step: 0
Training loss: 4.237515926361084
Validation loss: 3.9369145035743713

Epoch: 5| Step: 1
Training loss: 4.244267463684082
Validation loss: 3.866097698609034

Epoch: 5| Step: 2
Training loss: 4.210123062133789
Validation loss: 3.781895707050959

Epoch: 5| Step: 3
Training loss: 2.8277475833892822
Validation loss: 3.703437586625417

Epoch: 5| Step: 4
Training loss: 3.8837597370147705
Validation loss: 3.6274413466453552

Epoch: 5| Step: 5
Training loss: 3.3263683319091797
Validation loss: 3.5558255314826965

Epoch: 5| Step: 6
Training loss: 4.080432891845703
Validation loss: 3.4648326337337494

Epoch: 5| Step: 7
Training loss: 3.2971267700195312
Validation loss: 3.398798336585363

Epoch: 5| Step: 8
Training loss: 3.3251793384552
Validation loss: 3.3135341107845306

Epoch: 5| Step: 9
Training loss: 3.524322509765625
Validation loss: 3.23213337858518

Epoch: 5| Step: 10
Training loss: 2.8799281120300293
Validation loss: 3.1433511773745217

Epoch: 5| Step: 11
Training loss: 2.766963481903076
Validation loss: 3.052164316177368

Epoch: 5| Step: 0
Training loss: 3.555654525756836
Validation loss: 2.988619844118754

Epoch: 5| Step: 1
Training loss: 3.020393133163452
Validation loss: 2.9059458673000336

Epoch: 5| Step: 2
Training loss: 2.644747734069824
Validation loss: 2.823701153198878

Epoch: 5| Step: 3
Training loss: 3.002070426940918
Validation loss: 2.727552463610967

Epoch: 5| Step: 4
Training loss: 2.8402416706085205
Validation loss: 2.6626526614030204

Epoch: 5| Step: 5
Training loss: 2.911943197250366
Validation loss: 2.57058318456014

Epoch: 5| Step: 6
Training loss: 2.677516222000122
Validation loss: 2.483586390813192

Epoch: 5| Step: 7
Training loss: 2.1134839057922363
Validation loss: 2.422619750102361

Epoch: 5| Step: 8
Training loss: 2.1674299240112305
Validation loss: 2.3419568886359534

Epoch: 5| Step: 9
Training loss: 1.7561748027801514
Validation loss: 2.286328782637914

Epoch: 5| Step: 10
Training loss: 2.449733257293701
Validation loss: 2.230815897385279

Epoch: 5| Step: 11
Training loss: 1.5156586170196533
Validation loss: 2.199965258439382

Epoch: 6| Step: 0
Training loss: 2.099116325378418
Validation loss: 2.156166578332583

Epoch: 5| Step: 1
Training loss: 1.9112861156463623
Validation loss: 2.149815872311592

Epoch: 5| Step: 2
Training loss: 2.051689386367798
Validation loss: 2.152051935593287

Epoch: 5| Step: 3
Training loss: 2.225668430328369
Validation loss: 2.134613717595736

Epoch: 5| Step: 4
Training loss: 1.6675426959991455
Validation loss: 2.133947948614756

Epoch: 5| Step: 5
Training loss: 2.5633082389831543
Validation loss: 2.1251295705636344

Epoch: 5| Step: 6
Training loss: 2.6072704792022705
Validation loss: 2.1176143884658813

Epoch: 5| Step: 7
Training loss: 2.927948474884033
Validation loss: 2.1159746100505195

Epoch: 5| Step: 8
Training loss: 1.971300482749939
Validation loss: 2.108187402288119

Epoch: 5| Step: 9
Training loss: 1.6947453022003174
Validation loss: 2.122884785135587

Epoch: 5| Step: 10
Training loss: 1.982562780380249
Validation loss: 2.104768067598343

Epoch: 5| Step: 11
Training loss: 3.043303966522217
Validation loss: 2.0969619750976562

Epoch: 7| Step: 0
Training loss: 2.7209715843200684
Validation loss: 2.1103353798389435

Epoch: 5| Step: 1
Training loss: 2.078542470932007
Validation loss: 2.115851486722628

Epoch: 5| Step: 2
Training loss: 2.40328311920166
Validation loss: 2.1173806140820184

Epoch: 5| Step: 3
Training loss: 1.438370943069458
Validation loss: 2.1207481920719147

Epoch: 5| Step: 4
Training loss: 2.2739741802215576
Validation loss: 2.1061340868473053

Epoch: 5| Step: 5
Training loss: 2.1206085681915283
Validation loss: 2.1151533176501593

Epoch: 5| Step: 6
Training loss: 1.7326056957244873
Validation loss: 2.102429429690043

Epoch: 5| Step: 7
Training loss: 2.2736871242523193
Validation loss: 2.1076103945573172

Epoch: 5| Step: 8
Training loss: 1.987234354019165
Validation loss: 2.1106766064961753

Epoch: 5| Step: 9
Training loss: 1.8018633127212524
Validation loss: 2.1224025140206018

Epoch: 5| Step: 10
Training loss: 2.8278908729553223
Validation loss: 2.102349648873011

Epoch: 5| Step: 11
Training loss: 2.2258334159851074
Validation loss: 2.1029022336006165

Epoch: 8| Step: 0
Training loss: 2.2718405723571777
Validation loss: 2.128157233198484

Epoch: 5| Step: 1
Training loss: 2.1208741664886475
Validation loss: 2.1090307335058847

Epoch: 5| Step: 2
Training loss: 2.0537331104278564
Validation loss: 2.1153292506933212

Epoch: 5| Step: 3
Training loss: 2.5105414390563965
Validation loss: 2.1251217822233834

Epoch: 5| Step: 4
Training loss: 1.4812276363372803
Validation loss: 2.109048758943876

Epoch: 5| Step: 5
Training loss: 2.2152810096740723
Validation loss: 2.1190466384092965

Epoch: 5| Step: 6
Training loss: 1.4899377822875977
Validation loss: 2.1081589659055076

Epoch: 5| Step: 7
Training loss: 1.4430601596832275
Validation loss: 2.1150019665559134

Epoch: 5| Step: 8
Training loss: 2.593979597091675
Validation loss: 2.119120200475057

Epoch: 5| Step: 9
Training loss: 2.7797389030456543
Validation loss: 2.1142559995253882

Epoch: 5| Step: 10
Training loss: 2.6802051067352295
Validation loss: 2.112567921479543

Epoch: 5| Step: 11
Training loss: 1.8762215375900269
Validation loss: 2.101982499162356

Epoch: 9| Step: 0
Training loss: 1.8451350927352905
Validation loss: 2.0942609508832297

Epoch: 5| Step: 1
Training loss: 1.9715811014175415
Validation loss: 2.0906917999188104

Epoch: 5| Step: 2
Training loss: 1.5903602838516235
Validation loss: 2.0883019218842187

Epoch: 5| Step: 3
Training loss: 2.2869720458984375
Validation loss: 2.076519807179769

Epoch: 5| Step: 4
Training loss: 1.8041349649429321
Validation loss: 2.080569585164388

Epoch: 5| Step: 5
Training loss: 2.7667953968048096
Validation loss: 2.0956971695025763

Epoch: 5| Step: 6
Training loss: 2.2579894065856934
Validation loss: 2.082343359788259

Epoch: 5| Step: 7
Training loss: 2.579982042312622
Validation loss: 2.066821684439977

Epoch: 5| Step: 8
Training loss: 1.6554632186889648
Validation loss: 2.0726600736379623

Epoch: 5| Step: 9
Training loss: 2.644763946533203
Validation loss: 2.0707759459813437

Epoch: 5| Step: 10
Training loss: 2.0062973499298096
Validation loss: 2.0806597471237183

Epoch: 5| Step: 11
Training loss: 2.204226016998291
Validation loss: 2.0667995661497116

Epoch: 10| Step: 0
Training loss: 2.0690903663635254
Validation loss: 2.0879877656698227

Epoch: 5| Step: 1
Training loss: 2.0220305919647217
Validation loss: 2.0775022407372794

Epoch: 5| Step: 2
Training loss: 1.8870636224746704
Validation loss: 2.061552489797274

Epoch: 5| Step: 3
Training loss: 2.1329188346862793
Validation loss: 2.094615265727043

Epoch: 5| Step: 4
Training loss: 2.1955084800720215
Validation loss: 2.0683625638484955

Epoch: 5| Step: 5
Training loss: 1.6389796733856201
Validation loss: 2.06748632589976

Epoch: 5| Step: 6
Training loss: 1.9467546939849854
Validation loss: 2.080580602089564

Epoch: 5| Step: 7
Training loss: 1.951258659362793
Validation loss: 2.0626068860292435

Epoch: 5| Step: 8
Training loss: 2.4192020893096924
Validation loss: 2.062174762288729

Epoch: 5| Step: 9
Training loss: 2.4747958183288574
Validation loss: 2.053640772898992

Epoch: 5| Step: 10
Training loss: 2.127617359161377
Validation loss: 2.0827756971120834

Epoch: 5| Step: 11
Training loss: 3.0343780517578125
Validation loss: 2.0698048820098243

Epoch: 11| Step: 0
Training loss: 2.424316167831421
Validation loss: 2.082041750351588

Epoch: 5| Step: 1
Training loss: 2.54451060295105
Validation loss: 2.0761180917421975

Epoch: 5| Step: 2
Training loss: 2.251843214035034
Validation loss: 2.0743754555781684

Epoch: 5| Step: 3
Training loss: 1.9869683980941772
Validation loss: 2.0829761028289795

Epoch: 5| Step: 4
Training loss: 2.0871729850769043
Validation loss: 2.087335452437401

Epoch: 5| Step: 5
Training loss: 1.464259147644043
Validation loss: 2.07781520485878

Epoch: 5| Step: 6
Training loss: 2.0279974937438965
Validation loss: 2.0779315729935965

Epoch: 5| Step: 7
Training loss: 2.010183811187744
Validation loss: 2.0847069174051285

Epoch: 5| Step: 8
Training loss: 1.7922300100326538
Validation loss: 2.076166128118833

Epoch: 5| Step: 9
Training loss: 2.455930233001709
Validation loss: 2.0722279051939645

Epoch: 5| Step: 10
Training loss: 1.924924612045288
Validation loss: 2.0781225065390267

Epoch: 5| Step: 11
Training loss: 2.6050333976745605
Validation loss: 2.0594715823729834

Epoch: 12| Step: 0
Training loss: 1.8775993585586548
Validation loss: 2.052325338125229

Epoch: 5| Step: 1
Training loss: 2.395465612411499
Validation loss: 2.0704071819782257

Epoch: 5| Step: 2
Training loss: 1.3906654119491577
Validation loss: 2.0673186083634696

Epoch: 5| Step: 3
Training loss: 2.3222575187683105
Validation loss: 2.061969687541326

Epoch: 5| Step: 4
Training loss: 1.9521410465240479
Validation loss: 2.060596505800883

Epoch: 5| Step: 5
Training loss: 1.8997166156768799
Validation loss: 2.063903048634529

Epoch: 5| Step: 6
Training loss: 1.892930030822754
Validation loss: 2.0554021100203195

Epoch: 5| Step: 7
Training loss: 2.0834765434265137
Validation loss: 2.0618923703829446

Epoch: 5| Step: 8
Training loss: 2.4268858432769775
Validation loss: 2.06352469821771

Epoch: 5| Step: 9
Training loss: 2.6672000885009766
Validation loss: 2.0611545542875924

Epoch: 5| Step: 10
Training loss: 2.0934293270111084
Validation loss: 2.06837705274423

Epoch: 5| Step: 11
Training loss: 2.554126739501953
Validation loss: 2.0486880987882614

Epoch: 13| Step: 0
Training loss: 1.6923227310180664
Validation loss: 2.066011513272921

Epoch: 5| Step: 1
Training loss: 2.495915412902832
Validation loss: 2.0637203007936478

Epoch: 5| Step: 2
Training loss: 1.811163306236267
Validation loss: 2.0474256376425424

Epoch: 5| Step: 3
Training loss: 2.6112630367279053
Validation loss: 2.0507879753907523

Epoch: 5| Step: 4
Training loss: 2.17916202545166
Validation loss: 2.0729899605115256

Epoch: 5| Step: 5
Training loss: 2.166175365447998
Validation loss: 2.0683065901199975

Epoch: 5| Step: 6
Training loss: 2.1032161712646484
Validation loss: 2.0706253995498023

Epoch: 5| Step: 7
Training loss: 1.8423779010772705
Validation loss: 2.083931719263395

Epoch: 5| Step: 8
Training loss: 2.594754457473755
Validation loss: 2.0685228755076728

Epoch: 5| Step: 9
Training loss: 2.0977957248687744
Validation loss: 2.064952085415522

Epoch: 5| Step: 10
Training loss: 1.3462724685668945
Validation loss: 2.035770977536837

Epoch: 5| Step: 11
Training loss: 2.6224119663238525
Validation loss: 2.0671801964441934

Epoch: 14| Step: 0
Training loss: 1.99778151512146
Validation loss: 2.0538712044556937

Epoch: 5| Step: 1
Training loss: 2.054670810699463
Validation loss: 2.0544718454281488

Epoch: 5| Step: 2
Training loss: 2.232276201248169
Validation loss: 2.06187674899896

Epoch: 5| Step: 3
Training loss: 1.8641237020492554
Validation loss: 2.0458961029847464

Epoch: 5| Step: 4
Training loss: 2.046175718307495
Validation loss: 2.069139321645101

Epoch: 5| Step: 5
Training loss: 2.14243745803833
Validation loss: 2.05850816766421

Epoch: 5| Step: 6
Training loss: 2.6362693309783936
Validation loss: 2.0765472799539566

Epoch: 5| Step: 7
Training loss: 2.0937557220458984
Validation loss: 2.0741290102402368

Epoch: 5| Step: 8
Training loss: 2.158460855484009
Validation loss: 2.063979352513949

Epoch: 5| Step: 9
Training loss: 1.7513433694839478
Validation loss: 2.0718528479337692

Epoch: 5| Step: 10
Training loss: 1.9262901544570923
Validation loss: 2.047931139667829

Epoch: 5| Step: 11
Training loss: 2.2177858352661133
Validation loss: 2.061332846681277

Epoch: 15| Step: 0
Training loss: 1.864532470703125
Validation loss: 2.037676682074865

Epoch: 5| Step: 1
Training loss: 1.9774993658065796
Validation loss: 2.0427494198083878

Epoch: 5| Step: 2
Training loss: 1.8299763202667236
Validation loss: 2.0492916802565255

Epoch: 5| Step: 3
Training loss: 2.038942813873291
Validation loss: 2.0476427475611367

Epoch: 5| Step: 4
Training loss: 2.4381203651428223
Validation loss: 2.0763784696658454

Epoch: 5| Step: 5
Training loss: 1.9140710830688477
Validation loss: 2.069854428370794

Epoch: 5| Step: 6
Training loss: 1.9252464771270752
Validation loss: 2.053719013929367

Epoch: 5| Step: 7
Training loss: 2.2558040618896484
Validation loss: 2.06125038365523

Epoch: 5| Step: 8
Training loss: 2.2249319553375244
Validation loss: 2.0481260120868683

Epoch: 5| Step: 9
Training loss: 2.119635581970215
Validation loss: 2.0532889664173126

Epoch: 5| Step: 10
Training loss: 2.3217945098876953
Validation loss: 2.0464152842760086

Epoch: 5| Step: 11
Training loss: 1.2966268062591553
Validation loss: 2.0583420594533286

Epoch: 16| Step: 0
Training loss: 1.4906491041183472
Validation loss: 2.0616312424341836

Epoch: 5| Step: 1
Training loss: 2.3428759574890137
Validation loss: 2.0536875426769257

Epoch: 5| Step: 2
Training loss: 2.253727674484253
Validation loss: 2.048017422358195

Epoch: 5| Step: 3
Training loss: 1.9796485900878906
Validation loss: 2.0609822968641915

Epoch: 5| Step: 4
Training loss: 1.5553134679794312
Validation loss: 2.039248456557592

Epoch: 5| Step: 5
Training loss: 1.9474003314971924
Validation loss: 2.0538241465886435

Epoch: 5| Step: 6
Training loss: 2.621188163757324
Validation loss: 2.031850020090739

Epoch: 5| Step: 7
Training loss: 2.3675594329833984
Validation loss: 2.053842489918073

Epoch: 5| Step: 8
Training loss: 1.6735540628433228
Validation loss: 2.061678280433019

Epoch: 5| Step: 9
Training loss: 2.3269526958465576
Validation loss: 2.040755127867063

Epoch: 5| Step: 10
Training loss: 2.077179193496704
Validation loss: 2.0703389396270118

Epoch: 5| Step: 11
Training loss: 1.8050007820129395
Validation loss: 2.055613860487938

Epoch: 17| Step: 0
Training loss: 1.8626763820648193
Validation loss: 2.054254690806071

Epoch: 5| Step: 1
Training loss: 1.684766173362732
Validation loss: 2.052263850967089

Epoch: 5| Step: 2
Training loss: 2.1102676391601562
Validation loss: 2.053843383987745

Epoch: 5| Step: 3
Training loss: 1.9595005512237549
Validation loss: 2.054481084148089

Epoch: 5| Step: 4
Training loss: 1.8351116180419922
Validation loss: 2.044829338788986

Epoch: 5| Step: 5
Training loss: 2.107577085494995
Validation loss: 2.0528737058242164

Epoch: 5| Step: 6
Training loss: 2.7109363079071045
Validation loss: 2.046235591173172

Epoch: 5| Step: 7
Training loss: 1.8796275854110718
Validation loss: 2.0481211692094803

Epoch: 5| Step: 8
Training loss: 1.7702451944351196
Validation loss: 2.0557106882333755

Epoch: 5| Step: 9
Training loss: 2.499768018722534
Validation loss: 2.0489156593879065

Epoch: 5| Step: 10
Training loss: 2.2462306022644043
Validation loss: 2.0604377388954163

Epoch: 5| Step: 11
Training loss: 1.3850698471069336
Validation loss: 2.0401351749897003

Epoch: 18| Step: 0
Training loss: 1.7849338054656982
Validation loss: 2.058736185232798

Epoch: 5| Step: 1
Training loss: 1.8987467288970947
Validation loss: 2.0547920068105063

Epoch: 5| Step: 2
Training loss: 2.2654385566711426
Validation loss: 2.0381690661112466

Epoch: 5| Step: 3
Training loss: 2.6411194801330566
Validation loss: 2.0500621845324836

Epoch: 5| Step: 4
Training loss: 1.9876420497894287
Validation loss: 2.0504091133673987

Epoch: 5| Step: 5
Training loss: 1.8386255502700806
Validation loss: 2.066362048188845

Epoch: 5| Step: 6
Training loss: 2.0149238109588623
Validation loss: 2.0605610062678656

Epoch: 5| Step: 7
Training loss: 1.901832938194275
Validation loss: 2.06252687672774

Epoch: 5| Step: 8
Training loss: 1.8090388774871826
Validation loss: 2.0521140843629837

Epoch: 5| Step: 9
Training loss: 2.6055855751037598
Validation loss: 2.0572859148184457

Epoch: 5| Step: 10
Training loss: 1.8119510412216187
Validation loss: 2.0335222333669662

Epoch: 5| Step: 11
Training loss: 2.176297426223755
Validation loss: 2.0486852327982583

Epoch: 19| Step: 0
Training loss: 1.2367743253707886
Validation loss: 2.044670914610227

Epoch: 5| Step: 1
Training loss: 2.4151771068573
Validation loss: 2.0699522793293

Epoch: 5| Step: 2
Training loss: 2.155827283859253
Validation loss: 2.041690394282341

Epoch: 5| Step: 3
Training loss: 2.1600635051727295
Validation loss: 2.047145446141561

Epoch: 5| Step: 4
Training loss: 2.0604491233825684
Validation loss: 2.0586168269316354

Epoch: 5| Step: 5
Training loss: 1.5717195272445679
Validation loss: 2.0639658768971763

Epoch: 5| Step: 6
Training loss: 2.48494815826416
Validation loss: 2.104718029499054

Epoch: 5| Step: 7
Training loss: 2.1103389263153076
Validation loss: 2.0723753521839776

Epoch: 5| Step: 8
Training loss: 1.8948358297348022
Validation loss: 2.081740081310272

Epoch: 5| Step: 9
Training loss: 2.3243236541748047
Validation loss: 2.069718991716703

Epoch: 5| Step: 10
Training loss: 2.3958792686462402
Validation loss: 2.052370468775431

Epoch: 5| Step: 11
Training loss: 2.8236117362976074
Validation loss: 2.0433045824368796

Epoch: 20| Step: 0
Training loss: 1.5917747020721436
Validation loss: 2.056306466460228

Epoch: 5| Step: 1
Training loss: 2.588901996612549
Validation loss: 2.0347730964422226

Epoch: 5| Step: 2
Training loss: 2.748847246170044
Validation loss: 2.067225361863772

Epoch: 5| Step: 3
Training loss: 1.8315229415893555
Validation loss: 2.0520816991726556

Epoch: 5| Step: 4
Training loss: 1.519923448562622
Validation loss: 2.0550982505083084

Epoch: 5| Step: 5
Training loss: 2.098344326019287
Validation loss: 2.072417065501213

Epoch: 5| Step: 6
Training loss: 1.7385324239730835
Validation loss: 2.073023905356725

Epoch: 5| Step: 7
Training loss: 1.8740640878677368
Validation loss: 2.0844953705867133

Epoch: 5| Step: 8
Training loss: 2.5124900341033936
Validation loss: 2.0715212474266687

Epoch: 5| Step: 9
Training loss: 2.2515664100646973
Validation loss: 2.0623233715693154

Epoch: 5| Step: 10
Training loss: 2.2552950382232666
Validation loss: 2.0558395783106485

Epoch: 5| Step: 11
Training loss: 1.6808769702911377
Validation loss: 2.0590338657299676

Epoch: 21| Step: 0
Training loss: 2.201092481613159
Validation loss: 2.0457805146773658

Epoch: 5| Step: 1
Training loss: 2.090428113937378
Validation loss: 2.046795830130577

Epoch: 5| Step: 2
Training loss: 1.636965036392212
Validation loss: 2.0607555309931436

Epoch: 5| Step: 3
Training loss: 2.2919633388519287
Validation loss: 2.037790467341741

Epoch: 5| Step: 4
Training loss: 1.9317958354949951
Validation loss: 2.046614865461985

Epoch: 5| Step: 5
Training loss: 2.1202774047851562
Validation loss: 2.017322137951851

Epoch: 5| Step: 6
Training loss: 2.18070650100708
Validation loss: 2.032445326447487

Epoch: 5| Step: 7
Training loss: 1.854556679725647
Validation loss: 2.0432528803745904

Epoch: 5| Step: 8
Training loss: 1.4472858905792236
Validation loss: 2.0476047496000924

Epoch: 5| Step: 9
Training loss: 1.7509658336639404
Validation loss: 2.049479196468989

Epoch: 5| Step: 10
Training loss: 2.835237979888916
Validation loss: 2.0218554884195328

Epoch: 5| Step: 11
Training loss: 2.3684396743774414
Validation loss: 2.0191114296515784

Epoch: 22| Step: 0
Training loss: 2.081918239593506
Validation loss: 2.0462901343901954

Epoch: 5| Step: 1
Training loss: 1.6603925228118896
Validation loss: 2.0344709903001785

Epoch: 5| Step: 2
Training loss: 1.6544685363769531
Validation loss: 2.0366777082284293

Epoch: 5| Step: 3
Training loss: 2.8576667308807373
Validation loss: 2.05981116493543

Epoch: 5| Step: 4
Training loss: 1.2877358198165894
Validation loss: 2.042837932705879

Epoch: 5| Step: 5
Training loss: 2.3926641941070557
Validation loss: 2.0396132469177246

Epoch: 5| Step: 6
Training loss: 2.4995877742767334
Validation loss: 2.0531150798002877

Epoch: 5| Step: 7
Training loss: 1.913477897644043
Validation loss: 2.022135630249977

Epoch: 5| Step: 8
Training loss: 2.1843795776367188
Validation loss: 2.0490329215923944

Epoch: 5| Step: 9
Training loss: 1.969156265258789
Validation loss: 2.0323685904343924

Epoch: 5| Step: 10
Training loss: 1.7718063592910767
Validation loss: 2.051176145672798

Epoch: 5| Step: 11
Training loss: 1.419108271598816
Validation loss: 2.032084892193476

Epoch: 23| Step: 0
Training loss: 1.8599611520767212
Validation loss: 2.0267144292593002

Epoch: 5| Step: 1
Training loss: 2.497988224029541
Validation loss: 2.0442351202170053

Epoch: 5| Step: 2
Training loss: 2.265353202819824
Validation loss: 2.0425639301538467

Epoch: 5| Step: 3
Training loss: 2.0716309547424316
Validation loss: 2.0412540634473166

Epoch: 5| Step: 4
Training loss: 2.012838840484619
Validation loss: 2.040467937787374

Epoch: 5| Step: 5
Training loss: 2.1510891914367676
Validation loss: 2.030798445145289

Epoch: 5| Step: 6
Training loss: 1.2928314208984375
Validation loss: 2.0373281041781106

Epoch: 5| Step: 7
Training loss: 1.4860390424728394
Validation loss: 2.0375404208898544

Epoch: 5| Step: 8
Training loss: 1.674599289894104
Validation loss: 2.048676773905754

Epoch: 5| Step: 9
Training loss: 2.7154793739318848
Validation loss: 2.04242213567098

Epoch: 5| Step: 10
Training loss: 2.3205409049987793
Validation loss: 2.024481177330017

Epoch: 5| Step: 11
Training loss: 1.9259299039840698
Validation loss: 2.0181777526934943

Epoch: 24| Step: 0
Training loss: 2.0161354541778564
Validation loss: 2.0412624875704446

Epoch: 5| Step: 1
Training loss: 1.9593321084976196
Validation loss: 2.027629002928734

Epoch: 5| Step: 2
Training loss: 2.100635290145874
Validation loss: 2.0608529647191367

Epoch: 5| Step: 3
Training loss: 2.168485641479492
Validation loss: 2.07394972940286

Epoch: 5| Step: 4
Training loss: 1.9729893207550049
Validation loss: 2.086002230644226

Epoch: 5| Step: 5
Training loss: 2.211021900177002
Validation loss: 2.0726938347021737

Epoch: 5| Step: 6
Training loss: 2.186107635498047
Validation loss: 2.084368258714676

Epoch: 5| Step: 7
Training loss: 2.2120046615600586
Validation loss: 2.082787757118543

Epoch: 5| Step: 8
Training loss: 1.4529201984405518
Validation loss: 2.064027026295662

Epoch: 5| Step: 9
Training loss: 2.1893296241760254
Validation loss: 2.0447577933470407

Epoch: 5| Step: 10
Training loss: 2.1160173416137695
Validation loss: 2.049136405189832

Epoch: 5| Step: 11
Training loss: 1.4481074810028076
Validation loss: 2.0302515228589377

Epoch: 25| Step: 0
Training loss: 2.6350414752960205
Validation loss: 2.0308718035618463

Epoch: 5| Step: 1
Training loss: 1.8684444427490234
Validation loss: 2.0636089543501535

Epoch: 5| Step: 2
Training loss: 1.8096634149551392
Validation loss: 2.047479192415873

Epoch: 5| Step: 3
Training loss: 1.5775315761566162
Validation loss: 2.0522718131542206

Epoch: 5| Step: 4
Training loss: 1.7220004796981812
Validation loss: 2.051476905743281

Epoch: 5| Step: 5
Training loss: 2.270141124725342
Validation loss: 2.0582380841175714

Epoch: 5| Step: 6
Training loss: 2.2383744716644287
Validation loss: 2.049603581428528

Epoch: 5| Step: 7
Training loss: 2.573164463043213
Validation loss: 2.0592087457577386

Epoch: 5| Step: 8
Training loss: 2.020169734954834
Validation loss: 2.0506519178549447

Epoch: 5| Step: 9
Training loss: 1.7212663888931274
Validation loss: 2.045459752281507

Epoch: 5| Step: 10
Training loss: 1.9462318420410156
Validation loss: 2.048517107963562

Epoch: 5| Step: 11
Training loss: 1.9205927848815918
Validation loss: 2.047549789150556

Epoch: 26| Step: 0
Training loss: 1.6696012020111084
Validation loss: 2.0242289106051126

Epoch: 5| Step: 1
Training loss: 2.4585015773773193
Validation loss: 2.025304009517034

Epoch: 5| Step: 2
Training loss: 2.1738903522491455
Validation loss: 2.0306451668341956

Epoch: 5| Step: 3
Training loss: 2.1093642711639404
Validation loss: 2.030298108855883

Epoch: 5| Step: 4
Training loss: 2.1866402626037598
Validation loss: 2.066457971930504

Epoch: 5| Step: 5
Training loss: 1.3073869943618774
Validation loss: 2.039878159761429

Epoch: 5| Step: 6
Training loss: 2.037585496902466
Validation loss: 2.041356697678566

Epoch: 5| Step: 7
Training loss: 2.0505521297454834
Validation loss: 2.0414768358071647

Epoch: 5| Step: 8
Training loss: 2.311311960220337
Validation loss: 2.041731908917427

Epoch: 5| Step: 9
Training loss: 2.115396499633789
Validation loss: 2.0324136863152185

Epoch: 5| Step: 10
Training loss: 1.7946805953979492
Validation loss: 2.014066810409228

Epoch: 5| Step: 11
Training loss: 1.432928442955017
Validation loss: 2.0267979502677917

Epoch: 27| Step: 0
Training loss: 2.594818115234375
Validation loss: 2.0332243194182715

Epoch: 5| Step: 1
Training loss: 1.6999927759170532
Validation loss: 2.0303691824277244

Epoch: 5| Step: 2
Training loss: 2.0459485054016113
Validation loss: 2.0484975775082908

Epoch: 5| Step: 3
Training loss: 1.5348565578460693
Validation loss: 2.0235123485326767

Epoch: 5| Step: 4
Training loss: 2.116881847381592
Validation loss: 2.0429702500502267

Epoch: 5| Step: 5
Training loss: 1.7686567306518555
Validation loss: 2.055968776345253

Epoch: 5| Step: 6
Training loss: 1.4473130702972412
Validation loss: 2.026026879747709

Epoch: 5| Step: 7
Training loss: 2.1036465167999268
Validation loss: 2.03836989402771

Epoch: 5| Step: 8
Training loss: 1.8224903345108032
Validation loss: 2.0415576746066413

Epoch: 5| Step: 9
Training loss: 1.6766515970230103
Validation loss: 2.0277069658041

Epoch: 5| Step: 10
Training loss: 2.8370490074157715
Validation loss: 2.0525500774383545

Epoch: 5| Step: 11
Training loss: 2.9099888801574707
Validation loss: 2.036683296163877

Epoch: 28| Step: 0
Training loss: 2.0088565349578857
Validation loss: 2.048894872268041

Epoch: 5| Step: 1
Training loss: 1.7256109714508057
Validation loss: 2.037838781873385

Epoch: 5| Step: 2
Training loss: 2.1850852966308594
Validation loss: 2.039472038547198

Epoch: 5| Step: 3
Training loss: 1.5804731845855713
Validation loss: 2.0328367799520493

Epoch: 5| Step: 4
Training loss: 2.8990397453308105
Validation loss: 2.051673963665962

Epoch: 5| Step: 5
Training loss: 1.9221283197402954
Validation loss: 2.02670527001222

Epoch: 5| Step: 6
Training loss: 2.0062031745910645
Validation loss: 2.0325368642807007

Epoch: 5| Step: 7
Training loss: 1.5587042570114136
Validation loss: 2.0360666712125144

Epoch: 5| Step: 8
Training loss: 2.162660598754883
Validation loss: 2.018420656522115

Epoch: 5| Step: 9
Training loss: 2.281445026397705
Validation loss: 2.0514340301354728

Epoch: 5| Step: 10
Training loss: 1.7934573888778687
Validation loss: 2.0298505624135337

Epoch: 5| Step: 11
Training loss: 2.166640281677246
Validation loss: 2.0394612699747086

Epoch: 29| Step: 0
Training loss: 1.845900297164917
Validation loss: 2.0321722527345023

Epoch: 5| Step: 1
Training loss: 2.517399787902832
Validation loss: 2.0235508928696313

Epoch: 5| Step: 2
Training loss: 2.127624034881592
Validation loss: 2.0220727771520615

Epoch: 5| Step: 3
Training loss: 1.909350037574768
Validation loss: 2.0336345732212067

Epoch: 5| Step: 4
Training loss: 1.4786226749420166
Validation loss: 2.0368782579898834

Epoch: 5| Step: 5
Training loss: 1.7299535274505615
Validation loss: 2.041546111305555

Epoch: 5| Step: 6
Training loss: 1.9367637634277344
Validation loss: 2.048785944779714

Epoch: 5| Step: 7
Training loss: 1.9933055639266968
Validation loss: 2.046192452311516

Epoch: 5| Step: 8
Training loss: 2.351945400238037
Validation loss: 2.0345374842484794

Epoch: 5| Step: 9
Training loss: 1.4908201694488525
Validation loss: 2.0480334808429084

Epoch: 5| Step: 10
Training loss: 2.517420530319214
Validation loss: 2.0327364206314087

Epoch: 5| Step: 11
Training loss: 2.268084764480591
Validation loss: 2.0615056504805884

Epoch: 30| Step: 0
Training loss: 1.8668372631072998
Validation loss: 2.038932283719381

Epoch: 5| Step: 1
Training loss: 1.690313696861267
Validation loss: 2.041098361214002

Epoch: 5| Step: 2
Training loss: 2.1912713050842285
Validation loss: 2.0368079245090485

Epoch: 5| Step: 3
Training loss: 2.372748613357544
Validation loss: 2.0464681734641395

Epoch: 5| Step: 4
Training loss: 1.8066952228546143
Validation loss: 2.0343905289967856

Epoch: 5| Step: 5
Training loss: 1.669232726097107
Validation loss: 2.031724060575167

Epoch: 5| Step: 6
Training loss: 2.404561996459961
Validation loss: 2.0285096118847528

Epoch: 5| Step: 7
Training loss: 1.6731971502304077
Validation loss: 2.0304654091596603

Epoch: 5| Step: 8
Training loss: 1.9587867259979248
Validation loss: 2.035441274444262

Epoch: 5| Step: 9
Training loss: 2.051939010620117
Validation loss: 2.032078370451927

Epoch: 5| Step: 10
Training loss: 2.0174102783203125
Validation loss: 2.0356617669264474

Epoch: 5| Step: 11
Training loss: 2.226745367050171
Validation loss: 2.0430514415105185

Epoch: 31| Step: 0
Training loss: 2.0298619270324707
Validation loss: 2.0393426517645517

Epoch: 5| Step: 1
Training loss: 2.3020052909851074
Validation loss: 2.0207370618979135

Epoch: 5| Step: 2
Training loss: 1.9448997974395752
Validation loss: 2.0131036788225174

Epoch: 5| Step: 3
Training loss: 1.3643256425857544
Validation loss: 2.031762952605883

Epoch: 5| Step: 4
Training loss: 1.821047067642212
Validation loss: 2.0207209438085556

Epoch: 5| Step: 5
Training loss: 2.186713457107544
Validation loss: 2.025327985485395

Epoch: 5| Step: 6
Training loss: 1.8523054122924805
Validation loss: 2.0315681993961334

Epoch: 5| Step: 7
Training loss: 1.5813910961151123
Validation loss: 2.032471070686976

Epoch: 5| Step: 8
Training loss: 2.5130176544189453
Validation loss: 2.032306691010793

Epoch: 5| Step: 9
Training loss: 2.1435885429382324
Validation loss: 2.048771912852923

Epoch: 5| Step: 10
Training loss: 2.248345136642456
Validation loss: 2.0247804323832193

Epoch: 5| Step: 11
Training loss: 1.6351940631866455
Validation loss: 2.0256356497605643

Epoch: 32| Step: 0
Training loss: 2.392469882965088
Validation loss: 2.0428696125745773

Epoch: 5| Step: 1
Training loss: 1.8111435174942017
Validation loss: 2.035620545347532

Epoch: 5| Step: 2
Training loss: 1.6434745788574219
Validation loss: 2.033777564764023

Epoch: 5| Step: 3
Training loss: 1.6045596599578857
Validation loss: 2.0231624792019525

Epoch: 5| Step: 4
Training loss: 2.0628561973571777
Validation loss: 2.058201313018799

Epoch: 5| Step: 5
Training loss: 2.541956663131714
Validation loss: 2.0507513731718063

Epoch: 5| Step: 6
Training loss: 1.781009316444397
Validation loss: 2.0508927752574286

Epoch: 5| Step: 7
Training loss: 1.5862852334976196
Validation loss: 2.0599351723988852

Epoch: 5| Step: 8
Training loss: 2.3846452236175537
Validation loss: 2.056238134702047

Epoch: 5| Step: 9
Training loss: 1.6972919702529907
Validation loss: 2.0395074635744095

Epoch: 5| Step: 10
Training loss: 2.5400969982147217
Validation loss: 2.0535047401984534

Epoch: 5| Step: 11
Training loss: 1.3936305046081543
Validation loss: 2.031097615758578

Epoch: 33| Step: 0
Training loss: 1.9828647375106812
Validation loss: 2.0161826461553574

Epoch: 5| Step: 1
Training loss: 2.0171468257904053
Validation loss: 2.0253532926241555

Epoch: 5| Step: 2
Training loss: 1.8106987476348877
Validation loss: 2.0256249705950418

Epoch: 5| Step: 3
Training loss: 1.9429454803466797
Validation loss: 2.0428863763809204

Epoch: 5| Step: 4
Training loss: 1.5636987686157227
Validation loss: 2.0338543951511383

Epoch: 5| Step: 5
Training loss: 1.8924891948699951
Validation loss: 2.015781198938688

Epoch: 5| Step: 6
Training loss: 2.415112018585205
Validation loss: 2.032527973254522

Epoch: 5| Step: 7
Training loss: 1.577052116394043
Validation loss: 2.050660734375318

Epoch: 5| Step: 8
Training loss: 1.9045295715332031
Validation loss: 2.029640316963196

Epoch: 5| Step: 9
Training loss: 2.407805919647217
Validation loss: 2.066333904862404

Epoch: 5| Step: 10
Training loss: 2.2583675384521484
Validation loss: 2.033500994245211

Epoch: 5| Step: 11
Training loss: 2.676792621612549
Validation loss: 2.0395048757394156

Epoch: 34| Step: 0
Training loss: 1.666407823562622
Validation loss: 2.019107754031817

Epoch: 5| Step: 1
Training loss: 1.8353462219238281
Validation loss: 2.04648295044899

Epoch: 5| Step: 2
Training loss: 1.9527641534805298
Validation loss: 2.030387967824936

Epoch: 5| Step: 3
Training loss: 2.093172311782837
Validation loss: 2.030321925878525

Epoch: 5| Step: 4
Training loss: 2.290799379348755
Validation loss: 2.046346748868624

Epoch: 5| Step: 5
Training loss: 1.9193427562713623
Validation loss: 2.056660935282707

Epoch: 5| Step: 6
Training loss: 2.4238524436950684
Validation loss: 2.041804780562719

Epoch: 5| Step: 7
Training loss: 1.7586452960968018
Validation loss: 2.0454099824031196

Epoch: 5| Step: 8
Training loss: 2.390615940093994
Validation loss: 2.0625889201958976

Epoch: 5| Step: 9
Training loss: 1.6081552505493164
Validation loss: 2.051145374774933

Epoch: 5| Step: 10
Training loss: 1.952754020690918
Validation loss: 2.0398474782705307

Epoch: 5| Step: 11
Training loss: 1.037196159362793
Validation loss: 2.0321067174275718

Epoch: 35| Step: 0
Training loss: 1.722875952720642
Validation loss: 2.0366720110177994

Epoch: 5| Step: 1
Training loss: 2.2717535495758057
Validation loss: 2.047648787498474

Epoch: 5| Step: 2
Training loss: 1.884018898010254
Validation loss: 2.0182272841533027

Epoch: 5| Step: 3
Training loss: 1.9717674255371094
Validation loss: 2.058866038918495

Epoch: 5| Step: 4
Training loss: 2.088103771209717
Validation loss: 2.0526817987362542

Epoch: 5| Step: 5
Training loss: 2.0854740142822266
Validation loss: 2.0563044995069504

Epoch: 5| Step: 6
Training loss: 1.4355028867721558
Validation loss: 2.0547553499539695

Epoch: 5| Step: 7
Training loss: 1.9984203577041626
Validation loss: 2.0464740892251334

Epoch: 5| Step: 8
Training loss: 1.8240324258804321
Validation loss: 2.0864934424559274

Epoch: 5| Step: 9
Training loss: 2.2372899055480957
Validation loss: 2.029765317837397

Epoch: 5| Step: 10
Training loss: 2.0829684734344482
Validation loss: 2.043687269091606

Epoch: 5| Step: 11
Training loss: 2.0752878189086914
Validation loss: 2.013551210363706

Epoch: 36| Step: 0
Training loss: 1.7793136835098267
Validation loss: 2.0369745095570884

Epoch: 5| Step: 1
Training loss: 1.8649437427520752
Validation loss: 2.0510500917832055

Epoch: 5| Step: 2
Training loss: 1.8429664373397827
Validation loss: 2.0490759909152985

Epoch: 5| Step: 3
Training loss: 2.582012176513672
Validation loss: 2.052552009622256

Epoch: 5| Step: 4
Training loss: 1.8920255899429321
Validation loss: 2.0385713328917823

Epoch: 5| Step: 5
Training loss: 1.5602680444717407
Validation loss: 2.046463186542193

Epoch: 5| Step: 6
Training loss: 1.7701342105865479
Validation loss: 2.0504307796557746

Epoch: 5| Step: 7
Training loss: 2.142251491546631
Validation loss: 2.044472719232241

Epoch: 5| Step: 8
Training loss: 2.2373390197753906
Validation loss: 2.06175064543883

Epoch: 5| Step: 9
Training loss: 2.1572325229644775
Validation loss: 2.050060192743937

Epoch: 5| Step: 10
Training loss: 1.815127968788147
Validation loss: 2.059232473373413

Epoch: 5| Step: 11
Training loss: 3.245838165283203
Validation loss: 2.0452780773242316

Epoch: 37| Step: 0
Training loss: 1.7300697565078735
Validation loss: 2.0279816389083862

Epoch: 5| Step: 1
Training loss: 1.6711679697036743
Validation loss: 2.0257795453071594

Epoch: 5| Step: 2
Training loss: 1.644637107849121
Validation loss: 2.0437256544828415

Epoch: 5| Step: 3
Training loss: 2.416752338409424
Validation loss: 2.0471001317103705

Epoch: 5| Step: 4
Training loss: 1.8737175464630127
Validation loss: 2.028543238838514

Epoch: 5| Step: 5
Training loss: 1.8643901348114014
Validation loss: 2.0526156425476074

Epoch: 5| Step: 6
Training loss: 2.2206027507781982
Validation loss: 2.010218525926272

Epoch: 5| Step: 7
Training loss: 2.0232441425323486
Validation loss: 2.0348664969205856

Epoch: 5| Step: 8
Training loss: 2.118865489959717
Validation loss: 2.0466578056414924

Epoch: 5| Step: 9
Training loss: 2.2473812103271484
Validation loss: 2.075191264351209

Epoch: 5| Step: 10
Training loss: 1.7147048711776733
Validation loss: 2.013213058312734

Epoch: 5| Step: 11
Training loss: 2.0176358222961426
Validation loss: 2.044783721367518

Epoch: 38| Step: 0
Training loss: 2.726717472076416
Validation loss: 2.049403667449951

Epoch: 5| Step: 1
Training loss: 2.286456346511841
Validation loss: 2.0586704264084497

Epoch: 5| Step: 2
Training loss: 1.1929564476013184
Validation loss: 2.0537761400143304

Epoch: 5| Step: 3
Training loss: 1.732278823852539
Validation loss: 2.04407832523187

Epoch: 5| Step: 4
Training loss: 2.1708223819732666
Validation loss: 2.062879830598831

Epoch: 5| Step: 5
Training loss: 2.154468297958374
Validation loss: 2.059644430875778

Epoch: 5| Step: 6
Training loss: 1.7731631994247437
Validation loss: 2.0470539033412933

Epoch: 5| Step: 7
Training loss: 1.9979289770126343
Validation loss: 2.0437867244084678

Epoch: 5| Step: 8
Training loss: 1.5953657627105713
Validation loss: 2.051167686780294

Epoch: 5| Step: 9
Training loss: 2.159127712249756
Validation loss: 2.026421477397283

Epoch: 5| Step: 10
Training loss: 1.8746274709701538
Validation loss: 2.0466276009877524

Epoch: 5| Step: 11
Training loss: 0.8688695430755615
Validation loss: 2.0615730782349906

Epoch: 39| Step: 0
Training loss: 1.76296865940094
Validation loss: 2.0314171264568963

Epoch: 5| Step: 1
Training loss: 1.8416931629180908
Validation loss: 2.029659643769264

Epoch: 5| Step: 2
Training loss: 2.425283432006836
Validation loss: 2.0365477949380875

Epoch: 5| Step: 3
Training loss: 2.3215110301971436
Validation loss: 2.0359056194623313

Epoch: 5| Step: 4
Training loss: 2.050161838531494
Validation loss: 2.0315820475419364

Epoch: 5| Step: 5
Training loss: 1.4356169700622559
Validation loss: 2.0532323320706687

Epoch: 5| Step: 6
Training loss: 2.0661911964416504
Validation loss: 2.0321585138638816

Epoch: 5| Step: 7
Training loss: 2.1376607418060303
Validation loss: 2.036096528172493

Epoch: 5| Step: 8
Training loss: 1.6886732578277588
Validation loss: 2.04713207979997

Epoch: 5| Step: 9
Training loss: 2.196990728378296
Validation loss: 2.05780158440272

Epoch: 5| Step: 10
Training loss: 1.535064935684204
Validation loss: 2.032909815510114

Epoch: 5| Step: 11
Training loss: 2.2288947105407715
Validation loss: 2.050774405399958

Epoch: 40| Step: 0
Training loss: 1.8244049549102783
Validation loss: 2.0295156141122184

Epoch: 5| Step: 1
Training loss: 1.4745094776153564
Validation loss: 2.0537789116303125

Epoch: 5| Step: 2
Training loss: 1.758615255355835
Validation loss: 2.0259624322255454

Epoch: 5| Step: 3
Training loss: 2.0536797046661377
Validation loss: 2.043536047140757

Epoch: 5| Step: 4
Training loss: 1.6200180053710938
Validation loss: 2.0594441493352256

Epoch: 5| Step: 5
Training loss: 1.5758650302886963
Validation loss: 2.041459639867147

Epoch: 5| Step: 6
Training loss: 2.089730739593506
Validation loss: 2.044807657599449

Epoch: 5| Step: 7
Training loss: 2.5794575214385986
Validation loss: 2.0431192914644876

Epoch: 5| Step: 8
Training loss: 2.0954642295837402
Validation loss: 2.0443092733621597

Epoch: 5| Step: 9
Training loss: 1.9567826986312866
Validation loss: 2.03044622639815

Epoch: 5| Step: 10
Training loss: 2.3934552669525146
Validation loss: 2.058029219508171

Epoch: 5| Step: 11
Training loss: 2.591461181640625
Validation loss: 2.039516548315684

Epoch: 41| Step: 0
Training loss: 1.2602967023849487
Validation loss: 2.066590170065562

Epoch: 5| Step: 1
Training loss: 1.8340171575546265
Validation loss: 2.030031273762385

Epoch: 5| Step: 2
Training loss: 2.0494322776794434
Validation loss: 2.0312126328547797

Epoch: 5| Step: 3
Training loss: 2.0001769065856934
Validation loss: 2.0349174638589225

Epoch: 5| Step: 4
Training loss: 2.272980213165283
Validation loss: 2.0438782622416816

Epoch: 5| Step: 5
Training loss: 1.8738796710968018
Validation loss: 2.0379188458124795

Epoch: 5| Step: 6
Training loss: 2.03534197807312
Validation loss: 2.031140690048536

Epoch: 5| Step: 7
Training loss: 1.865422010421753
Validation loss: 2.034007246295611

Epoch: 5| Step: 8
Training loss: 1.9117330312728882
Validation loss: 2.0474087049563727

Epoch: 5| Step: 9
Training loss: 2.3442423343658447
Validation loss: 2.0269960711399713

Epoch: 5| Step: 10
Training loss: 1.8519684076309204
Validation loss: 2.025008117159208

Epoch: 5| Step: 11
Training loss: 1.7417140007019043
Validation loss: 2.0440221031506858

Epoch: 42| Step: 0
Training loss: 1.7854225635528564
Validation loss: 2.0344828317562738

Epoch: 5| Step: 1
Training loss: 1.9381067752838135
Validation loss: 2.034583196043968

Epoch: 5| Step: 2
Training loss: 2.3071751594543457
Validation loss: 2.0455180605252585

Epoch: 5| Step: 3
Training loss: 1.5840266942977905
Validation loss: 2.049462139606476

Epoch: 5| Step: 4
Training loss: 1.8840420246124268
Validation loss: 2.0697505374749503

Epoch: 5| Step: 5
Training loss: 2.241421699523926
Validation loss: 2.057400350769361

Epoch: 5| Step: 6
Training loss: 2.4881253242492676
Validation loss: 2.0296335568030677

Epoch: 5| Step: 7
Training loss: 1.9745824337005615
Validation loss: 2.0514103223880134

Epoch: 5| Step: 8
Training loss: 1.9596201181411743
Validation loss: 2.049228767553965

Epoch: 5| Step: 9
Training loss: 1.7352325916290283
Validation loss: 2.0550810595353446

Epoch: 5| Step: 10
Training loss: 1.4898979663848877
Validation loss: 2.024401694536209

Epoch: 5| Step: 11
Training loss: 1.8866069316864014
Validation loss: 2.0493719627459845

Epoch: 43| Step: 0
Training loss: 1.6766103506088257
Validation loss: 2.0351573824882507

Epoch: 5| Step: 1
Training loss: 2.673647165298462
Validation loss: 2.0200779189666114

Epoch: 5| Step: 2
Training loss: 1.7692720890045166
Validation loss: 2.0622399350007377

Epoch: 5| Step: 3
Training loss: 1.965851068496704
Validation loss: 2.035445367296537

Epoch: 5| Step: 4
Training loss: 2.370157241821289
Validation loss: 2.051634912689527

Epoch: 5| Step: 5
Training loss: 1.9774458408355713
Validation loss: 2.0506878594557443

Epoch: 5| Step: 6
Training loss: 1.5554192066192627
Validation loss: 2.035627245903015

Epoch: 5| Step: 7
Training loss: 1.8815090656280518
Validation loss: 2.047140727440516

Epoch: 5| Step: 8
Training loss: 2.1374330520629883
Validation loss: 2.0894596527020135

Epoch: 5| Step: 9
Training loss: 1.6325962543487549
Validation loss: 2.0494295805692673

Epoch: 5| Step: 10
Training loss: 1.7363669872283936
Validation loss: 2.0542835046847663

Epoch: 5| Step: 11
Training loss: 1.6336445808410645
Validation loss: 2.0455452650785446

Epoch: 44| Step: 0
Training loss: 1.8963680267333984
Validation loss: 2.0670740654071174

Epoch: 5| Step: 1
Training loss: 2.1760334968566895
Validation loss: 2.034246395031611

Epoch: 5| Step: 2
Training loss: 1.3340826034545898
Validation loss: 2.0428331742684045

Epoch: 5| Step: 3
Training loss: 2.173440933227539
Validation loss: 2.041322390238444

Epoch: 5| Step: 4
Training loss: 1.687085747718811
Validation loss: 2.0605846693118415

Epoch: 5| Step: 5
Training loss: 2.315293550491333
Validation loss: 2.0280866026878357

Epoch: 5| Step: 6
Training loss: 2.0720372200012207
Validation loss: 2.03287181754907

Epoch: 5| Step: 7
Training loss: 1.960415244102478
Validation loss: 2.0348912378152213

Epoch: 5| Step: 8
Training loss: 1.6853481531143188
Validation loss: 2.0567149768273034

Epoch: 5| Step: 9
Training loss: 1.798762559890747
Validation loss: 2.050856868426005

Epoch: 5| Step: 10
Training loss: 2.354954719543457
Validation loss: 2.028202936053276

Epoch: 5| Step: 11
Training loss: 0.6641314029693604
Validation loss: 2.0510362138350806

Epoch: 45| Step: 0
Training loss: 1.999648094177246
Validation loss: 2.046539078156153

Epoch: 5| Step: 1
Training loss: 1.9462616443634033
Validation loss: 2.0488341947396598

Epoch: 5| Step: 2
Training loss: 1.699243187904358
Validation loss: 2.05103075504303

Epoch: 5| Step: 3
Training loss: 2.4535398483276367
Validation loss: 2.024920880794525

Epoch: 5| Step: 4
Training loss: 1.6513805389404297
Validation loss: 2.0444574703772864

Epoch: 5| Step: 5
Training loss: 1.4311234951019287
Validation loss: 2.0577434500058494

Epoch: 5| Step: 6
Training loss: 2.135885000228882
Validation loss: 2.0500730176766715

Epoch: 5| Step: 7
Training loss: 1.7490133047103882
Validation loss: 2.054664596915245

Epoch: 5| Step: 8
Training loss: 1.8308662176132202
Validation loss: 2.0667541722456613

Epoch: 5| Step: 9
Training loss: 2.271676540374756
Validation loss: 2.027042473355929

Epoch: 5| Step: 10
Training loss: 2.0118179321289062
Validation loss: 2.048246627052625

Epoch: 5| Step: 11
Training loss: 1.3536394834518433
Validation loss: 2.0533614655335746

Epoch: 46| Step: 0
Training loss: 1.9272838830947876
Validation loss: 2.0660428255796432

Epoch: 5| Step: 1
Training loss: 1.8609482049942017
Validation loss: 2.047260860602061

Epoch: 5| Step: 2
Training loss: 1.8889358043670654
Validation loss: 2.027254973848661

Epoch: 5| Step: 3
Training loss: 2.5523741245269775
Validation loss: 2.0284381260474524

Epoch: 5| Step: 4
Training loss: 1.5061445236206055
Validation loss: 2.0374590208133063

Epoch: 5| Step: 5
Training loss: 1.5102684497833252
Validation loss: 2.0377646734317145

Epoch: 5| Step: 6
Training loss: 1.948931097984314
Validation loss: 2.036960984269778

Epoch: 5| Step: 7
Training loss: 1.465221643447876
Validation loss: 2.0307740320762

Epoch: 5| Step: 8
Training loss: 2.734839677810669
Validation loss: 2.053101713458697

Epoch: 5| Step: 9
Training loss: 2.2072525024414062
Validation loss: 2.0451885064442954

Epoch: 5| Step: 10
Training loss: 1.6735944747924805
Validation loss: 2.0360367198785148

Epoch: 5| Step: 11
Training loss: 2.6162455081939697
Validation loss: 2.0401093562444053

Epoch: 47| Step: 0
Training loss: 2.5383169651031494
Validation loss: 2.0445934732755027

Epoch: 5| Step: 1
Training loss: 2.0794308185577393
Validation loss: 2.023721675078074

Epoch: 5| Step: 2
Training loss: 1.5882794857025146
Validation loss: 2.048632820447286

Epoch: 5| Step: 3
Training loss: 1.2953550815582275
Validation loss: 2.047030712167422

Epoch: 5| Step: 4
Training loss: 1.7836511135101318
Validation loss: 2.0499818176031113

Epoch: 5| Step: 5
Training loss: 1.5423624515533447
Validation loss: 2.0370921889940896

Epoch: 5| Step: 6
Training loss: 1.9301456212997437
Validation loss: 2.012579694390297

Epoch: 5| Step: 7
Training loss: 2.6396496295928955
Validation loss: 2.047809824347496

Epoch: 5| Step: 8
Training loss: 1.3645576238632202
Validation loss: 2.059588685631752

Epoch: 5| Step: 9
Training loss: 2.256160259246826
Validation loss: 2.0588329136371613

Epoch: 5| Step: 10
Training loss: 1.9957010746002197
Validation loss: 2.0554059942563376

Epoch: 5| Step: 11
Training loss: 1.4221296310424805
Validation loss: 2.039061556259791

Epoch: 48| Step: 0
Training loss: 1.792262315750122
Validation loss: 2.0536491721868515

Epoch: 5| Step: 1
Training loss: 2.0205321311950684
Validation loss: 2.036747326453527

Epoch: 5| Step: 2
Training loss: 2.2677929401397705
Validation loss: 2.063819169998169

Epoch: 5| Step: 3
Training loss: 2.2779946327209473
Validation loss: 2.0436338434616723

Epoch: 5| Step: 4
Training loss: 1.7521464824676514
Validation loss: 2.0441393901904426

Epoch: 5| Step: 5
Training loss: 1.486789584159851
Validation loss: 2.0592737595240274

Epoch: 5| Step: 6
Training loss: 1.9498437643051147
Validation loss: 2.036177689830462

Epoch: 5| Step: 7
Training loss: 2.2363171577453613
Validation loss: 2.0378004362185798

Epoch: 5| Step: 8
Training loss: 1.605403184890747
Validation loss: 2.029451092084249

Epoch: 5| Step: 9
Training loss: 1.5017101764678955
Validation loss: 2.0327669580777488

Epoch: 5| Step: 10
Training loss: 1.808708906173706
Validation loss: 2.0589114924271903

Epoch: 5| Step: 11
Training loss: 3.1874241828918457
Validation loss: 2.0534129440784454

Epoch: 49| Step: 0
Training loss: 2.1409995555877686
Validation loss: 2.0570918122927346

Epoch: 5| Step: 1
Training loss: 2.232180118560791
Validation loss: 2.04187174141407

Epoch: 5| Step: 2
Training loss: 1.6953489780426025
Validation loss: 2.040712316830953

Epoch: 5| Step: 3
Training loss: 2.3104424476623535
Validation loss: 2.070337727665901

Epoch: 5| Step: 4
Training loss: 1.8122398853302002
Validation loss: 2.049699847896894

Epoch: 5| Step: 5
Training loss: 2.061540365219116
Validation loss: 2.039361680547396

Epoch: 5| Step: 6
Training loss: 1.5895379781723022
Validation loss: 2.032781958580017

Epoch: 5| Step: 7
Training loss: 1.845486044883728
Validation loss: 2.038033331433932

Epoch: 5| Step: 8
Training loss: 1.843346357345581
Validation loss: 2.0302593310674033

Epoch: 5| Step: 9
Training loss: 1.682861328125
Validation loss: 2.0456442534923553

Epoch: 5| Step: 10
Training loss: 1.8715627193450928
Validation loss: 2.036692043145498

Epoch: 5| Step: 11
Training loss: 1.80767023563385
Validation loss: 2.028090476989746

Epoch: 50| Step: 0
Training loss: 2.2540602684020996
Validation loss: 2.042701875170072

Epoch: 5| Step: 1
Training loss: 1.895926833152771
Validation loss: 2.0615803649028144

Epoch: 5| Step: 2
Training loss: 1.7656816244125366
Validation loss: 2.084960247079531

Epoch: 5| Step: 3
Training loss: 1.803234338760376
Validation loss: 2.0702614337205887

Epoch: 5| Step: 4
Training loss: 1.742447853088379
Validation loss: 2.0423685113588967

Epoch: 5| Step: 5
Training loss: 1.6306642293930054
Validation loss: 2.0757521043221154

Epoch: 5| Step: 6
Training loss: 2.4819302558898926
Validation loss: 2.040066381295522

Epoch: 5| Step: 7
Training loss: 2.2369067668914795
Validation loss: 2.0475691854953766

Epoch: 5| Step: 8
Training loss: 2.085496425628662
Validation loss: 2.0116333067417145

Epoch: 5| Step: 9
Training loss: 1.7591850757598877
Validation loss: 2.041670267780622

Epoch: 5| Step: 10
Training loss: 1.7802311182022095
Validation loss: 2.0486613512039185

Epoch: 5| Step: 11
Training loss: 0.8788653612136841
Validation loss: 2.058544397354126

Epoch: 51| Step: 0
Training loss: 1.7600250244140625
Validation loss: 2.04153182109197

Epoch: 5| Step: 1
Training loss: 2.3621392250061035
Validation loss: 2.0492665419975915

Epoch: 5| Step: 2
Training loss: 2.5211665630340576
Validation loss: 2.0400228748718896

Epoch: 5| Step: 3
Training loss: 1.7387338876724243
Validation loss: 2.039865553379059

Epoch: 5| Step: 4
Training loss: 1.4218989610671997
Validation loss: 2.040170898040136

Epoch: 5| Step: 5
Training loss: 1.8439979553222656
Validation loss: 2.048768103122711

Epoch: 5| Step: 6
Training loss: 2.085059642791748
Validation loss: 2.0561747203270593

Epoch: 5| Step: 7
Training loss: 1.7418205738067627
Validation loss: 2.044791559378306

Epoch: 5| Step: 8
Training loss: 1.835745096206665
Validation loss: 2.0516655445098877

Epoch: 5| Step: 9
Training loss: 1.6925338506698608
Validation loss: 2.0365803291400275

Epoch: 5| Step: 10
Training loss: 1.969862937927246
Validation loss: 2.060611536105474

Epoch: 5| Step: 11
Training loss: 2.4095067977905273
Validation loss: 2.0478384693463645

Epoch: 52| Step: 0
Training loss: 2.657763719558716
Validation loss: 2.065153474609057

Epoch: 5| Step: 1
Training loss: 1.5473171472549438
Validation loss: 2.052524209022522

Epoch: 5| Step: 2
Training loss: 1.9228146076202393
Validation loss: 2.0552669564882913

Epoch: 5| Step: 3
Training loss: 2.4258158206939697
Validation loss: 2.0459274649620056

Epoch: 5| Step: 4
Training loss: 2.1196446418762207
Validation loss: 2.036773274342219

Epoch: 5| Step: 5
Training loss: 1.6284606456756592
Validation loss: 2.0477622052033744

Epoch: 5| Step: 6
Training loss: 1.768040657043457
Validation loss: 2.04839551448822

Epoch: 5| Step: 7
Training loss: 1.8291959762573242
Validation loss: 2.052214875817299

Epoch: 5| Step: 8
Training loss: 1.5775244235992432
Validation loss: 2.053555508454641

Epoch: 5| Step: 9
Training loss: 1.5307419300079346
Validation loss: 2.0283125390609107

Epoch: 5| Step: 10
Training loss: 1.7874248027801514
Validation loss: 2.0685645242532096

Epoch: 5| Step: 11
Training loss: 2.089500904083252
Validation loss: 2.0257488638162613

Epoch: 53| Step: 0
Training loss: 2.112036943435669
Validation loss: 2.051172529657682

Epoch: 5| Step: 1
Training loss: 1.9488474130630493
Validation loss: 2.0405352662007012

Epoch: 5| Step: 2
Training loss: 1.6200792789459229
Validation loss: 2.049629971385002

Epoch: 5| Step: 3
Training loss: 1.857945203781128
Validation loss: 2.053134337067604

Epoch: 5| Step: 4
Training loss: 2.0911383628845215
Validation loss: 2.0430949926376343

Epoch: 5| Step: 5
Training loss: 1.8407132625579834
Validation loss: 2.0560498386621475

Epoch: 5| Step: 6
Training loss: 1.6685209274291992
Validation loss: 2.0423714965581894

Epoch: 5| Step: 7
Training loss: 1.9709135293960571
Validation loss: 2.0549436211586

Epoch: 5| Step: 8
Training loss: 1.7877941131591797
Validation loss: 2.046036039789518

Epoch: 5| Step: 9
Training loss: 1.9643192291259766
Validation loss: 2.0290567179520926

Epoch: 5| Step: 10
Training loss: 1.9070333242416382
Validation loss: 2.036003132661184

Epoch: 5| Step: 11
Training loss: 1.8192764520645142
Validation loss: 2.032281627257665

Epoch: 54| Step: 0
Training loss: 2.097597122192383
Validation loss: 2.044662649432818

Epoch: 5| Step: 1
Training loss: 1.7756373882293701
Validation loss: 2.048530081907908

Epoch: 5| Step: 2
Training loss: 1.4802576303482056
Validation loss: 2.0377486050128937

Epoch: 5| Step: 3
Training loss: 1.5647395849227905
Validation loss: 2.0423057824373245

Epoch: 5| Step: 4
Training loss: 2.8035271167755127
Validation loss: 2.031029557188352

Epoch: 5| Step: 5
Training loss: 1.932713270187378
Validation loss: 2.0266257723172507

Epoch: 5| Step: 6
Training loss: 1.6946865320205688
Validation loss: 2.0373500982920327

Epoch: 5| Step: 7
Training loss: 1.6018800735473633
Validation loss: 2.0346106539169946

Epoch: 5| Step: 8
Training loss: 2.0501182079315186
Validation loss: 2.0525629818439484

Epoch: 5| Step: 9
Training loss: 1.9814026355743408
Validation loss: 2.064663221438726

Epoch: 5| Step: 10
Training loss: 1.5460079908370972
Validation loss: 2.0705505708853402

Epoch: 5| Step: 11
Training loss: 1.7464102506637573
Validation loss: 2.048337588707606

Epoch: 55| Step: 0
Training loss: 1.1288232803344727
Validation loss: 2.080928827325503

Epoch: 5| Step: 1
Training loss: 2.174541473388672
Validation loss: 2.0829553405443826

Epoch: 5| Step: 2
Training loss: 1.855658769607544
Validation loss: 2.0893434882164

Epoch: 5| Step: 3
Training loss: 2.3801651000976562
Validation loss: 2.0579095035791397

Epoch: 5| Step: 4
Training loss: 1.3960387706756592
Validation loss: 2.070569063226382

Epoch: 5| Step: 5
Training loss: 1.8686418533325195
Validation loss: 2.0637091199556985

Epoch: 5| Step: 6
Training loss: 2.100055694580078
Validation loss: 2.0602396527926126

Epoch: 5| Step: 7
Training loss: 2.066077947616577
Validation loss: 2.0467308163642883

Epoch: 5| Step: 8
Training loss: 2.264348030090332
Validation loss: 2.049469451109568

Epoch: 5| Step: 9
Training loss: 1.7811371088027954
Validation loss: 2.06820410490036

Epoch: 5| Step: 10
Training loss: 1.835585355758667
Validation loss: 2.061298261086146

Epoch: 5| Step: 11
Training loss: 1.6665760278701782
Validation loss: 2.0414535303910575

Epoch: 56| Step: 0
Training loss: 1.698733925819397
Validation loss: 2.0557986199855804

Epoch: 5| Step: 1
Training loss: 2.508378267288208
Validation loss: 2.0350938588380814

Epoch: 5| Step: 2
Training loss: 1.8063609600067139
Validation loss: 2.033396447698275

Epoch: 5| Step: 3
Training loss: 1.6949129104614258
Validation loss: 2.03039912879467

Epoch: 5| Step: 4
Training loss: 1.995711088180542
Validation loss: 2.052560935417811

Epoch: 5| Step: 5
Training loss: 1.9780819416046143
Validation loss: 2.04139152665933

Epoch: 5| Step: 6
Training loss: 1.7197239398956299
Validation loss: 2.075165346264839

Epoch: 5| Step: 7
Training loss: 1.9359817504882812
Validation loss: 2.064288248618444

Epoch: 5| Step: 8
Training loss: 1.252636432647705
Validation loss: 2.0380900353193283

Epoch: 5| Step: 9
Training loss: 2.2821648120880127
Validation loss: 2.033708636959394

Epoch: 5| Step: 10
Training loss: 1.579266905784607
Validation loss: 2.057550236582756

Epoch: 5| Step: 11
Training loss: 2.0560169219970703
Validation loss: 2.04062287012736

Epoch: 57| Step: 0
Training loss: 1.8157634735107422
Validation loss: 2.0402319381634393

Epoch: 5| Step: 1
Training loss: 2.044973850250244
Validation loss: 2.033324877421061

Epoch: 5| Step: 2
Training loss: 1.4038827419281006
Validation loss: 2.042936032017072

Epoch: 5| Step: 3
Training loss: 2.001570463180542
Validation loss: 2.039886196454366

Epoch: 5| Step: 4
Training loss: 1.8946425914764404
Validation loss: 2.0547219812870026

Epoch: 5| Step: 5
Training loss: 1.7602272033691406
Validation loss: 2.074752777814865

Epoch: 5| Step: 6
Training loss: 1.5117024183273315
Validation loss: 2.057882328828176

Epoch: 5| Step: 7
Training loss: 1.85812246799469
Validation loss: 2.0691593140363693

Epoch: 5| Step: 8
Training loss: 2.0418808460235596
Validation loss: 2.062357470393181

Epoch: 5| Step: 9
Training loss: 1.9753023386001587
Validation loss: 2.0268144557873407

Epoch: 5| Step: 10
Training loss: 2.4487314224243164
Validation loss: 2.072173217932383

Epoch: 5| Step: 11
Training loss: 1.4367953538894653
Validation loss: 2.025396689772606

Epoch: 58| Step: 0
Training loss: 1.7944952249526978
Validation loss: 2.0454591115315757

Epoch: 5| Step: 1
Training loss: 1.7037837505340576
Validation loss: 2.0587824831406274

Epoch: 5| Step: 2
Training loss: 2.066092014312744
Validation loss: 2.055680657426516

Epoch: 5| Step: 3
Training loss: 1.8677183389663696
Validation loss: 2.070123036702474

Epoch: 5| Step: 4
Training loss: 2.2950875759124756
Validation loss: 2.040372754136721

Epoch: 5| Step: 5
Training loss: 1.8845897912979126
Validation loss: 2.043910652399063

Epoch: 5| Step: 6
Training loss: 1.8768393993377686
Validation loss: 2.0440883934497833

Epoch: 5| Step: 7
Training loss: 1.9653804302215576
Validation loss: 2.0597298741340637

Epoch: 5| Step: 8
Training loss: 2.20847225189209
Validation loss: 2.0271443674961724

Epoch: 5| Step: 9
Training loss: 1.4422746896743774
Validation loss: 2.0330714186032615

Epoch: 5| Step: 10
Training loss: 1.9025551080703735
Validation loss: 2.034421851237615

Epoch: 5| Step: 11
Training loss: 0.8630536794662476
Validation loss: 2.0519687036673226

Epoch: 59| Step: 0
Training loss: 1.6365554332733154
Validation loss: 2.023242771625519

Epoch: 5| Step: 1
Training loss: 1.5509434938430786
Validation loss: 2.045424595475197

Epoch: 5| Step: 2
Training loss: 1.4746628999710083
Validation loss: 2.0570031752189

Epoch: 5| Step: 3
Training loss: 2.278418779373169
Validation loss: 2.0571277091900506

Epoch: 5| Step: 4
Training loss: 1.965288758277893
Validation loss: 2.080917830268542

Epoch: 5| Step: 5
Training loss: 1.6452499628067017
Validation loss: 2.0872160295645394

Epoch: 5| Step: 6
Training loss: 2.624601364135742
Validation loss: 2.0867900401353836

Epoch: 5| Step: 7
Training loss: 1.9865798950195312
Validation loss: 2.1026351004838943

Epoch: 5| Step: 8
Training loss: 1.6733407974243164
Validation loss: 2.0792740831772485

Epoch: 5| Step: 9
Training loss: 2.0520710945129395
Validation loss: 2.0564960887034736

Epoch: 5| Step: 10
Training loss: 1.9624156951904297
Validation loss: 2.073681225379308

Epoch: 5| Step: 11
Training loss: 1.1828157901763916
Validation loss: 2.077800298730532

Epoch: 60| Step: 0
Training loss: 2.1963047981262207
Validation loss: 2.0923076570034027

Epoch: 5| Step: 1
Training loss: 1.7009108066558838
Validation loss: 2.025601496299108

Epoch: 5| Step: 2
Training loss: 2.102207660675049
Validation loss: 2.043239027261734

Epoch: 5| Step: 3
Training loss: 1.6756919622421265
Validation loss: 2.0739140113194785

Epoch: 5| Step: 4
Training loss: 1.5576940774917603
Validation loss: 2.0445149739583335

Epoch: 5| Step: 5
Training loss: 1.7338180541992188
Validation loss: 2.0522821843624115

Epoch: 5| Step: 6
Training loss: 2.048821449279785
Validation loss: 2.052781562010447

Epoch: 5| Step: 7
Training loss: 1.7367379665374756
Validation loss: 2.049350226918856

Epoch: 5| Step: 8
Training loss: 1.434504508972168
Validation loss: 2.047162721554438

Epoch: 5| Step: 9
Training loss: 2.284407377243042
Validation loss: 2.0317161281903586

Epoch: 5| Step: 10
Training loss: 1.9771223068237305
Validation loss: 2.0182782312234244

Epoch: 5| Step: 11
Training loss: 1.3910194635391235
Validation loss: 2.0383831411600113

Epoch: 61| Step: 0
Training loss: 1.3630256652832031
Validation loss: 2.075226460893949

Epoch: 5| Step: 1
Training loss: 1.3888204097747803
Validation loss: 2.067760611573855

Epoch: 5| Step: 2
Training loss: 1.8734753131866455
Validation loss: 2.0615203032890954

Epoch: 5| Step: 3
Training loss: 1.8127682209014893
Validation loss: 2.0490052302678428

Epoch: 5| Step: 4
Training loss: 1.596565842628479
Validation loss: 2.092822710673014

Epoch: 5| Step: 5
Training loss: 1.807668924331665
Validation loss: 2.1101061006387076

Epoch: 5| Step: 6
Training loss: 2.172333240509033
Validation loss: 2.0699889808893204

Epoch: 5| Step: 7
Training loss: 1.8567943572998047
Validation loss: 2.0505613833665848

Epoch: 5| Step: 8
Training loss: 2.052738666534424
Validation loss: 2.035337900122007

Epoch: 5| Step: 9
Training loss: 2.050987958908081
Validation loss: 2.029760867357254

Epoch: 5| Step: 10
Training loss: 2.4427952766418457
Validation loss: 2.014466628432274

Epoch: 5| Step: 11
Training loss: 1.02802312374115
Validation loss: 2.018594801425934

Epoch: 62| Step: 0
Training loss: 1.9011367559432983
Validation loss: 2.0408773521582284

Epoch: 5| Step: 1
Training loss: 1.8532568216323853
Validation loss: 2.017160395781199

Epoch: 5| Step: 2
Training loss: 2.0460076332092285
Validation loss: 2.0490180353323617

Epoch: 5| Step: 3
Training loss: 1.9967597723007202
Validation loss: 2.037555222709974

Epoch: 5| Step: 4
Training loss: 2.0687146186828613
Validation loss: 2.085992604494095

Epoch: 5| Step: 5
Training loss: 1.7859523296356201
Validation loss: 2.0448231200377145

Epoch: 5| Step: 6
Training loss: 1.5477609634399414
Validation loss: 2.048383429646492

Epoch: 5| Step: 7
Training loss: 2.692605495452881
Validation loss: 2.032617042462031

Epoch: 5| Step: 8
Training loss: 1.6315997838974
Validation loss: 2.053616334994634

Epoch: 5| Step: 9
Training loss: 1.2038418054580688
Validation loss: 2.0411604593197503

Epoch: 5| Step: 10
Training loss: 2.1484742164611816
Validation loss: 2.0613514383633933

Epoch: 5| Step: 11
Training loss: 0.5004109144210815
Validation loss: 2.059178883830706

Epoch: 63| Step: 0
Training loss: 2.3918285369873047
Validation loss: 2.0676486243804297

Epoch: 5| Step: 1
Training loss: 1.3893376588821411
Validation loss: 2.0533507168293

Epoch: 5| Step: 2
Training loss: 1.87632155418396
Validation loss: 2.079854905605316

Epoch: 5| Step: 3
Training loss: 1.5952184200286865
Validation loss: 2.052831028898557

Epoch: 5| Step: 4
Training loss: 1.7697951793670654
Validation loss: 2.0259724209705987

Epoch: 5| Step: 5
Training loss: 2.2060935497283936
Validation loss: 2.0428259521722794

Epoch: 5| Step: 6
Training loss: 2.0814197063446045
Validation loss: 2.070244292418162

Epoch: 5| Step: 7
Training loss: 1.8283052444458008
Validation loss: 2.0640274782975516

Epoch: 5| Step: 8
Training loss: 2.0289127826690674
Validation loss: 2.0580103745063147

Epoch: 5| Step: 9
Training loss: 1.1790478229522705
Validation loss: 2.0317854632933936

Epoch: 5| Step: 10
Training loss: 1.6352697610855103
Validation loss: 2.045303374528885

Epoch: 5| Step: 11
Training loss: 1.643345594406128
Validation loss: 2.0781712929407754

Epoch: 64| Step: 0
Training loss: 1.4628779888153076
Validation loss: 2.044847990075747

Epoch: 5| Step: 1
Training loss: 2.429816484451294
Validation loss: 2.048164705435435

Epoch: 5| Step: 2
Training loss: 2.0568718910217285
Validation loss: 2.046072334051132

Epoch: 5| Step: 3
Training loss: 1.515270471572876
Validation loss: 2.0305328865846

Epoch: 5| Step: 4
Training loss: 1.6407066583633423
Validation loss: 2.045896957317988

Epoch: 5| Step: 5
Training loss: 1.9186649322509766
Validation loss: 2.064357355237007

Epoch: 5| Step: 6
Training loss: 1.7964227199554443
Validation loss: 2.058635508020719

Epoch: 5| Step: 7
Training loss: 2.0090765953063965
Validation loss: 2.085719342033068

Epoch: 5| Step: 8
Training loss: 1.568845510482788
Validation loss: 2.0448224544525146

Epoch: 5| Step: 9
Training loss: 1.7379289865493774
Validation loss: 2.0623574356238046

Epoch: 5| Step: 10
Training loss: 2.0805370807647705
Validation loss: 2.0574856996536255

Epoch: 5| Step: 11
Training loss: 1.5355260372161865
Validation loss: 2.0441779643297195

Epoch: 65| Step: 0
Training loss: 1.886906623840332
Validation loss: 2.0583050698041916

Epoch: 5| Step: 1
Training loss: 1.125954508781433
Validation loss: 2.086107606689135

Epoch: 5| Step: 2
Training loss: 2.5013985633850098
Validation loss: 2.1029707342386246

Epoch: 5| Step: 3
Training loss: 1.9569623470306396
Validation loss: 2.1177986512581506

Epoch: 5| Step: 4
Training loss: 1.538942575454712
Validation loss: 2.050316338737806

Epoch: 5| Step: 5
Training loss: 1.6586081981658936
Validation loss: 2.058544307947159

Epoch: 5| Step: 6
Training loss: 2.1989293098449707
Validation loss: 2.056516165534655

Epoch: 5| Step: 7
Training loss: 2.159480333328247
Validation loss: 2.0571588377157846

Epoch: 5| Step: 8
Training loss: 1.293988823890686
Validation loss: 2.0853958129882812

Epoch: 5| Step: 9
Training loss: 1.919559121131897
Validation loss: 2.0442807724078498

Epoch: 5| Step: 10
Training loss: 2.0479824542999268
Validation loss: 2.0761735290288925

Epoch: 5| Step: 11
Training loss: 0.3900810480117798
Validation loss: 2.035080373287201

Epoch: 66| Step: 0
Training loss: 1.9887498617172241
Validation loss: 2.0407365361849465

Epoch: 5| Step: 1
Training loss: 2.051530122756958
Validation loss: 2.0296329657236734

Epoch: 5| Step: 2
Training loss: 1.72304368019104
Validation loss: 2.0537132372458777

Epoch: 5| Step: 3
Training loss: 1.9666976928710938
Validation loss: 2.0188406060139337

Epoch: 5| Step: 4
Training loss: 1.7944259643554688
Validation loss: 2.028639485438665

Epoch: 5| Step: 5
Training loss: 1.8080923557281494
Validation loss: 2.0175098230441413

Epoch: 5| Step: 6
Training loss: 1.3689539432525635
Validation loss: 2.067740708589554

Epoch: 5| Step: 7
Training loss: 1.6750446557998657
Validation loss: 2.0412751038869223

Epoch: 5| Step: 8
Training loss: 1.9662387371063232
Validation loss: 2.0893532186746597

Epoch: 5| Step: 9
Training loss: 2.5249569416046143
Validation loss: 2.0980034520228705

Epoch: 5| Step: 10
Training loss: 1.5248140096664429
Validation loss: 2.060533339778582

Epoch: 5| Step: 11
Training loss: 1.351129174232483
Validation loss: 2.0917477905750275

Epoch: 67| Step: 0
Training loss: 1.3124595880508423
Validation loss: 2.053331583738327

Epoch: 5| Step: 1
Training loss: 1.5555369853973389
Validation loss: 2.0436641524235406

Epoch: 5| Step: 2
Training loss: 1.7671664953231812
Validation loss: 2.076206142703692

Epoch: 5| Step: 3
Training loss: 2.3263068199157715
Validation loss: 2.087676092982292

Epoch: 5| Step: 4
Training loss: 2.1441707611083984
Validation loss: 2.0646965404351554

Epoch: 5| Step: 5
Training loss: 1.8575712442398071
Validation loss: 2.0388607482115426

Epoch: 5| Step: 6
Training loss: 1.6822655200958252
Validation loss: 2.0382298032442727

Epoch: 5| Step: 7
Training loss: 1.982999563217163
Validation loss: 2.040863941113154

Epoch: 5| Step: 8
Training loss: 2.2524397373199463
Validation loss: 2.0395478854576745

Epoch: 5| Step: 9
Training loss: 1.496461033821106
Validation loss: 2.024672821164131

Epoch: 5| Step: 10
Training loss: 1.740321159362793
Validation loss: 2.0416378180185952

Epoch: 5| Step: 11
Training loss: 2.13862681388855
Validation loss: 2.0249362687269845

Epoch: 68| Step: 0
Training loss: 1.6815297603607178
Validation loss: 2.026002734899521

Epoch: 5| Step: 1
Training loss: 1.8886821269989014
Validation loss: 2.0601000587145486

Epoch: 5| Step: 2
Training loss: 1.990787148475647
Validation loss: 2.055984318256378

Epoch: 5| Step: 3
Training loss: 2.5976293087005615
Validation loss: 2.0923623144626617

Epoch: 5| Step: 4
Training loss: 1.608344316482544
Validation loss: 2.0727467089891434

Epoch: 5| Step: 5
Training loss: 1.5389368534088135
Validation loss: 2.1140775978565216

Epoch: 5| Step: 6
Training loss: 2.0312492847442627
Validation loss: 2.075245668490728

Epoch: 5| Step: 7
Training loss: 1.3880468606948853
Validation loss: 2.0891285290320716

Epoch: 5| Step: 8
Training loss: 1.3102524280548096
Validation loss: 2.107579027613004

Epoch: 5| Step: 9
Training loss: 1.9213180541992188
Validation loss: 2.0431766410668692

Epoch: 5| Step: 10
Training loss: 1.8816791772842407
Validation loss: 2.051953355471293

Epoch: 5| Step: 11
Training loss: 2.0699589252471924
Validation loss: 2.0473200728495917

Epoch: 69| Step: 0
Training loss: 2.216381788253784
Validation loss: 2.047393108407656

Epoch: 5| Step: 1
Training loss: 1.6467052698135376
Validation loss: 2.047484964132309

Epoch: 5| Step: 2
Training loss: 1.8755512237548828
Validation loss: 2.013072525461515

Epoch: 5| Step: 3
Training loss: 1.7364450693130493
Validation loss: 2.0572383056084314

Epoch: 5| Step: 4
Training loss: 1.8082275390625
Validation loss: 2.036579415202141

Epoch: 5| Step: 5
Training loss: 1.736731767654419
Validation loss: 2.048304478327433

Epoch: 5| Step: 6
Training loss: 1.8317819833755493
Validation loss: 2.04215577741464

Epoch: 5| Step: 7
Training loss: 1.9701627492904663
Validation loss: 2.033238003651301

Epoch: 5| Step: 8
Training loss: 1.7601277828216553
Validation loss: 2.0110159615675607

Epoch: 5| Step: 9
Training loss: 1.680910348892212
Validation loss: 2.041630585988363

Epoch: 5| Step: 10
Training loss: 1.8493893146514893
Validation loss: 2.044488017757734

Epoch: 5| Step: 11
Training loss: 1.436648964881897
Validation loss: 2.037552828590075

Epoch: 70| Step: 0
Training loss: 1.5226659774780273
Validation loss: 2.0797104984521866

Epoch: 5| Step: 1
Training loss: 1.4983903169631958
Validation loss: 2.0643098056316376

Epoch: 5| Step: 2
Training loss: 2.163238763809204
Validation loss: 2.058002849419912

Epoch: 5| Step: 3
Training loss: 2.2308380603790283
Validation loss: 2.0890485793352127

Epoch: 5| Step: 4
Training loss: 1.626966118812561
Validation loss: 2.065806652108828

Epoch: 5| Step: 5
Training loss: 1.6934802532196045
Validation loss: 2.0906483928362527

Epoch: 5| Step: 6
Training loss: 1.7972214221954346
Validation loss: 2.071635847290357

Epoch: 5| Step: 7
Training loss: 1.3199890851974487
Validation loss: 2.0502948413292565

Epoch: 5| Step: 8
Training loss: 1.9571897983551025
Validation loss: 2.0629480183124542

Epoch: 5| Step: 9
Training loss: 2.6845481395721436
Validation loss: 2.0266052782535553

Epoch: 5| Step: 10
Training loss: 1.7099192142486572
Validation loss: 2.0319409370422363

Epoch: 5| Step: 11
Training loss: 0.7430551052093506
Validation loss: 2.0322196930646896

Epoch: 71| Step: 0
Training loss: 1.6502002477645874
Validation loss: 2.0479786843061447

Epoch: 5| Step: 1
Training loss: 2.7524495124816895
Validation loss: 2.072466184695562

Epoch: 5| Step: 2
Training loss: 1.447892189025879
Validation loss: 2.066315313180288

Epoch: 5| Step: 3
Training loss: 1.8567756414413452
Validation loss: 2.064394916097323

Epoch: 5| Step: 4
Training loss: 1.5297513008117676
Validation loss: 2.08253479997317

Epoch: 5| Step: 5
Training loss: 1.32240891456604
Validation loss: 2.0766613533099494

Epoch: 5| Step: 6
Training loss: 1.8469407558441162
Validation loss: 2.0528615017731986

Epoch: 5| Step: 7
Training loss: 1.2975376844406128
Validation loss: 2.063200369477272

Epoch: 5| Step: 8
Training loss: 2.0879077911376953
Validation loss: 2.058981716632843

Epoch: 5| Step: 9
Training loss: 2.0171055793762207
Validation loss: 2.053332348664602

Epoch: 5| Step: 10
Training loss: 2.0214455127716064
Validation loss: 2.009285261233648

Epoch: 5| Step: 11
Training loss: 1.535964012145996
Validation loss: 2.0264855225880942

Epoch: 72| Step: 0
Training loss: 2.2833995819091797
Validation loss: 2.0364721367756524

Epoch: 5| Step: 1
Training loss: 1.4536288976669312
Validation loss: 2.0529330472151437

Epoch: 5| Step: 2
Training loss: 1.1715680360794067
Validation loss: 2.0146375795205436

Epoch: 5| Step: 3
Training loss: 1.7429546117782593
Validation loss: 2.058962052067121

Epoch: 5| Step: 4
Training loss: 1.6043779850006104
Validation loss: 2.044483244419098

Epoch: 5| Step: 5
Training loss: 1.5296742916107178
Validation loss: 2.0786932011445365

Epoch: 5| Step: 6
Training loss: 1.6107828617095947
Validation loss: 2.026526307066282

Epoch: 5| Step: 7
Training loss: 2.2067346572875977
Validation loss: 2.0663198630015054

Epoch: 5| Step: 8
Training loss: 1.2787859439849854
Validation loss: 2.0707518806060157

Epoch: 5| Step: 9
Training loss: 2.218249797821045
Validation loss: 2.0675340046485267

Epoch: 5| Step: 10
Training loss: 2.2412891387939453
Validation loss: 2.097684701283773

Epoch: 5| Step: 11
Training loss: 2.507270336151123
Validation loss: 2.0728688885768256

Epoch: 73| Step: 0
Training loss: 1.8873546123504639
Validation loss: 2.0753053575754166

Epoch: 5| Step: 1
Training loss: 1.93318772315979
Validation loss: 2.089202140768369

Epoch: 5| Step: 2
Training loss: 1.7224041223526
Validation loss: 2.078025425473849

Epoch: 5| Step: 3
Training loss: 2.0628604888916016
Validation loss: 2.086119915048281

Epoch: 5| Step: 4
Training loss: 2.5094027519226074
Validation loss: 2.0660554617643356

Epoch: 5| Step: 5
Training loss: 2.2893118858337402
Validation loss: 2.092972993850708

Epoch: 5| Step: 6
Training loss: 1.589705467224121
Validation loss: 2.0528141309817634

Epoch: 5| Step: 7
Training loss: 1.7471628189086914
Validation loss: 2.038353150089582

Epoch: 5| Step: 8
Training loss: 1.3928260803222656
Validation loss: 2.0518592993418374

Epoch: 5| Step: 9
Training loss: 1.6065762042999268
Validation loss: 2.0592597275972366

Epoch: 5| Step: 10
Training loss: 0.9503283500671387
Validation loss: 2.067175174752871

Epoch: 5| Step: 11
Training loss: 1.8150238990783691
Validation loss: 2.051696320374807

Epoch: 74| Step: 0
Training loss: 1.5646756887435913
Validation loss: 2.058471937974294

Epoch: 5| Step: 1
Training loss: 1.238036870956421
Validation loss: 2.0362310111522675

Epoch: 5| Step: 2
Training loss: 1.8795185089111328
Validation loss: 2.0704235633214316

Epoch: 5| Step: 3
Training loss: 1.752875566482544
Validation loss: 2.060931404431661

Epoch: 5| Step: 4
Training loss: 1.507453203201294
Validation loss: 2.058893491824468

Epoch: 5| Step: 5
Training loss: 2.6507983207702637
Validation loss: 2.0729405035575232

Epoch: 5| Step: 6
Training loss: 1.7559611797332764
Validation loss: 2.0321778804063797

Epoch: 5| Step: 7
Training loss: 1.7696857452392578
Validation loss: 2.0453889966011047

Epoch: 5| Step: 8
Training loss: 1.1168501377105713
Validation loss: 2.062088663379351

Epoch: 5| Step: 9
Training loss: 2.320003032684326
Validation loss: 2.017268826564153

Epoch: 5| Step: 10
Training loss: 2.0573763847351074
Validation loss: 2.0140163550774255

Epoch: 5| Step: 11
Training loss: 1.384427785873413
Validation loss: 2.029594232638677

Epoch: 75| Step: 0
Training loss: 1.2469284534454346
Validation loss: 2.022642786304156

Epoch: 5| Step: 1
Training loss: 1.6594136953353882
Validation loss: 2.035701259970665

Epoch: 5| Step: 2
Training loss: 1.698706030845642
Validation loss: 2.026016483704249

Epoch: 5| Step: 3
Training loss: 1.596186637878418
Validation loss: 2.033331329623858

Epoch: 5| Step: 4
Training loss: 1.983768105506897
Validation loss: 2.0364108979701996

Epoch: 5| Step: 5
Training loss: 1.5614320039749146
Validation loss: 2.030325581630071

Epoch: 5| Step: 6
Training loss: 2.183607578277588
Validation loss: 2.0692142049471536

Epoch: 5| Step: 7
Training loss: 1.4754186868667603
Validation loss: 2.070141186316808

Epoch: 5| Step: 8
Training loss: 1.248830795288086
Validation loss: 2.1116551955540976

Epoch: 5| Step: 9
Training loss: 2.244129180908203
Validation loss: 2.061954692006111

Epoch: 5| Step: 10
Training loss: 2.542792558670044
Validation loss: 2.0824213922023773

Epoch: 5| Step: 11
Training loss: 2.1571249961853027
Validation loss: 2.059188981850942

Epoch: 76| Step: 0
Training loss: 0.995185375213623
Validation loss: 2.0888379365205765

Epoch: 5| Step: 1
Training loss: 1.481321930885315
Validation loss: 2.0296851694583893

Epoch: 5| Step: 2
Training loss: 2.0382323265075684
Validation loss: 2.045890510082245

Epoch: 5| Step: 3
Training loss: 1.8846477270126343
Validation loss: 2.0210208942492804

Epoch: 5| Step: 4
Training loss: 2.433332920074463
Validation loss: 2.0326358129580817

Epoch: 5| Step: 5
Training loss: 1.4816527366638184
Validation loss: 2.020274435480436

Epoch: 5| Step: 6
Training loss: 2.0456855297088623
Validation loss: 2.0499294251203537

Epoch: 5| Step: 7
Training loss: 1.610877275466919
Validation loss: 2.0369610687096915

Epoch: 5| Step: 8
Training loss: 2.0537469387054443
Validation loss: 2.0416594396034875

Epoch: 5| Step: 9
Training loss: 2.1282448768615723
Validation loss: 2.045456593235334

Epoch: 5| Step: 10
Training loss: 1.28788161277771
Validation loss: 2.0571145862340927

Epoch: 5| Step: 11
Training loss: 1.3741077184677124
Validation loss: 2.072182541092237

Epoch: 77| Step: 0
Training loss: 1.6939074993133545
Validation loss: 2.0652861446142197

Epoch: 5| Step: 1
Training loss: 1.8023834228515625
Validation loss: 2.0453493148088455

Epoch: 5| Step: 2
Training loss: 1.5037367343902588
Validation loss: 2.0475757966438928

Epoch: 5| Step: 3
Training loss: 2.2159409523010254
Validation loss: 2.035081312060356

Epoch: 5| Step: 4
Training loss: 2.047727108001709
Validation loss: 2.0492757509152093

Epoch: 5| Step: 5
Training loss: 1.4009374380111694
Validation loss: 2.067699581384659

Epoch: 5| Step: 6
Training loss: 1.6009283065795898
Validation loss: 2.0473060657580695

Epoch: 5| Step: 7
Training loss: 1.4230036735534668
Validation loss: 2.06507741411527

Epoch: 5| Step: 8
Training loss: 1.8968164920806885
Validation loss: 2.066963344812393

Epoch: 5| Step: 9
Training loss: 1.9889949560165405
Validation loss: 2.0710710237423577

Epoch: 5| Step: 10
Training loss: 1.7827695608139038
Validation loss: 2.055876915653547

Epoch: 5| Step: 11
Training loss: 2.03247332572937
Validation loss: 2.0527801314989724

Epoch: 78| Step: 0
Training loss: 1.080397605895996
Validation loss: 2.0532207638025284

Epoch: 5| Step: 1
Training loss: 2.1567511558532715
Validation loss: 2.0722301602363586

Epoch: 5| Step: 2
Training loss: 1.6141678094863892
Validation loss: 2.046337346235911

Epoch: 5| Step: 3
Training loss: 1.6237680912017822
Validation loss: 2.045171841979027

Epoch: 5| Step: 4
Training loss: 1.9687904119491577
Validation loss: 2.0649997144937515

Epoch: 5| Step: 5
Training loss: 1.5076394081115723
Validation loss: 2.0872560938199363

Epoch: 5| Step: 6
Training loss: 1.3620680570602417
Validation loss: 2.0355402678251266

Epoch: 5| Step: 7
Training loss: 1.780879259109497
Validation loss: 2.0522880852222443

Epoch: 5| Step: 8
Training loss: 1.984421730041504
Validation loss: 2.091897343595823

Epoch: 5| Step: 9
Training loss: 2.2023282051086426
Validation loss: 2.091158866882324

Epoch: 5| Step: 10
Training loss: 1.885977029800415
Validation loss: 2.0558315316836038

Epoch: 5| Step: 11
Training loss: 1.1241236925125122
Validation loss: 2.04502143462499

Epoch: 79| Step: 0
Training loss: 1.5921337604522705
Validation loss: 2.050086960196495

Epoch: 5| Step: 1
Training loss: 1.3700817823410034
Validation loss: 2.057647774616877

Epoch: 5| Step: 2
Training loss: 2.161238193511963
Validation loss: 2.04253122707208

Epoch: 5| Step: 3
Training loss: 1.620611548423767
Validation loss: 2.0381220082441964

Epoch: 5| Step: 4
Training loss: 1.6842864751815796
Validation loss: 2.029255857070287

Epoch: 5| Step: 5
Training loss: 1.8957252502441406
Validation loss: 2.0475099633137384

Epoch: 5| Step: 6
Training loss: 1.655763864517212
Validation loss: 2.0244005819161734

Epoch: 5| Step: 7
Training loss: 1.30905020236969
Validation loss: 2.0491847743590674

Epoch: 5| Step: 8
Training loss: 1.5867688655853271
Validation loss: 2.0730966180562973

Epoch: 5| Step: 9
Training loss: 2.2737839221954346
Validation loss: 2.0555408895015717

Epoch: 5| Step: 10
Training loss: 2.055776834487915
Validation loss: 2.058420404791832

Epoch: 5| Step: 11
Training loss: 1.1535921096801758
Validation loss: 2.0432398915290833

Epoch: 80| Step: 0
Training loss: 1.4482828378677368
Validation loss: 2.083603103955587

Epoch: 5| Step: 1
Training loss: 2.1977458000183105
Validation loss: 2.0761759082476297

Epoch: 5| Step: 2
Training loss: 1.6751625537872314
Validation loss: 2.0365767180919647

Epoch: 5| Step: 3
Training loss: 1.7884842157363892
Validation loss: 2.0569754292567572

Epoch: 5| Step: 4
Training loss: 1.4777803421020508
Validation loss: 2.049390306075414

Epoch: 5| Step: 5
Training loss: 1.1541684865951538
Validation loss: 2.076722204685211

Epoch: 5| Step: 6
Training loss: 2.365403652191162
Validation loss: 2.0767466922601066

Epoch: 5| Step: 7
Training loss: 1.6013543605804443
Validation loss: 2.0704011619091034

Epoch: 5| Step: 8
Training loss: 1.7015022039413452
Validation loss: 2.003055070837339

Epoch: 5| Step: 9
Training loss: 1.8225791454315186
Validation loss: 2.0558828562498093

Epoch: 5| Step: 10
Training loss: 1.5795352458953857
Validation loss: 2.0681262711683908

Epoch: 5| Step: 11
Training loss: 1.7020950317382812
Validation loss: 2.0151934921741486

Epoch: 81| Step: 0
Training loss: 1.6989307403564453
Validation loss: 2.0614357690016427

Epoch: 5| Step: 1
Training loss: 2.281118392944336
Validation loss: 2.0536486307779946

Epoch: 5| Step: 2
Training loss: 1.2165030241012573
Validation loss: 2.027663211027781

Epoch: 5| Step: 3
Training loss: 1.188612937927246
Validation loss: 2.0795691212018332

Epoch: 5| Step: 4
Training loss: 1.583511233329773
Validation loss: 2.035763238867124

Epoch: 5| Step: 5
Training loss: 1.5400546789169312
Validation loss: 2.0767837315797806

Epoch: 5| Step: 6
Training loss: 1.822949767112732
Validation loss: 2.017220199108124

Epoch: 5| Step: 7
Training loss: 1.7481186389923096
Validation loss: 2.0406721383333206

Epoch: 5| Step: 8
Training loss: 1.8730199337005615
Validation loss: 2.0278619279464087

Epoch: 5| Step: 9
Training loss: 2.156886577606201
Validation loss: 2.032865951458613

Epoch: 5| Step: 10
Training loss: 2.023057460784912
Validation loss: 2.044068237145742

Epoch: 5| Step: 11
Training loss: 1.0703339576721191
Validation loss: 2.035708169142405

Epoch: 82| Step: 0
Training loss: 1.3435072898864746
Validation loss: 2.0316993246475854

Epoch: 5| Step: 1
Training loss: 2.1942052841186523
Validation loss: 2.081690475344658

Epoch: 5| Step: 2
Training loss: 1.3825663328170776
Validation loss: 2.0745470573504767

Epoch: 5| Step: 3
Training loss: 1.6784881353378296
Validation loss: 2.082814852396647

Epoch: 5| Step: 4
Training loss: 1.7089455127716064
Validation loss: 2.1175073236227036

Epoch: 5| Step: 5
Training loss: 1.4992831945419312
Validation loss: 2.106005291144053

Epoch: 5| Step: 6
Training loss: 2.435378313064575
Validation loss: 2.08463424940904

Epoch: 5| Step: 7
Training loss: 1.7933197021484375
Validation loss: 2.07214292883873

Epoch: 5| Step: 8
Training loss: 1.6335201263427734
Validation loss: 2.0463722000519433

Epoch: 5| Step: 9
Training loss: 1.759084939956665
Validation loss: 2.0426309406757355

Epoch: 5| Step: 10
Training loss: 1.5833351612091064
Validation loss: 2.0351460625727973

Epoch: 5| Step: 11
Training loss: 1.2439757585525513
Validation loss: 2.011863132317861

Epoch: 83| Step: 0
Training loss: 1.9663108587265015
Validation loss: 2.0075955440600715

Epoch: 5| Step: 1
Training loss: 1.6101230382919312
Validation loss: 2.009300798177719

Epoch: 5| Step: 2
Training loss: 2.2889392375946045
Validation loss: 2.0199903895457587

Epoch: 5| Step: 3
Training loss: 1.4727340936660767
Validation loss: 2.0163352539141974

Epoch: 5| Step: 4
Training loss: 1.0194382667541504
Validation loss: 1.9988694737354915

Epoch: 5| Step: 5
Training loss: 1.7378742694854736
Validation loss: 2.0118220994869866

Epoch: 5| Step: 6
Training loss: 1.7845882177352905
Validation loss: 2.0468687812487283

Epoch: 5| Step: 7
Training loss: 1.6532901525497437
Validation loss: 2.0462370216846466

Epoch: 5| Step: 8
Training loss: 2.1949238777160645
Validation loss: 2.062522848447164

Epoch: 5| Step: 9
Training loss: 1.6512352228164673
Validation loss: 2.1008002360661826

Epoch: 5| Step: 10
Training loss: 1.6996352672576904
Validation loss: 2.105038821697235

Epoch: 5| Step: 11
Training loss: 0.8182069063186646
Validation loss: 2.104140261809031

Epoch: 84| Step: 0
Training loss: 1.7888133525848389
Validation loss: 2.066031629840533

Epoch: 5| Step: 1
Training loss: 1.973304033279419
Validation loss: 2.0546181251605353

Epoch: 5| Step: 2
Training loss: 2.2275209426879883
Validation loss: 2.0259638180335364

Epoch: 5| Step: 3
Training loss: 1.7428138256072998
Validation loss: 2.026485492785772

Epoch: 5| Step: 4
Training loss: 1.6580177545547485
Validation loss: 2.0092000514268875

Epoch: 5| Step: 5
Training loss: 1.8335316181182861
Validation loss: 2.003036787112554

Epoch: 5| Step: 6
Training loss: 2.1015870571136475
Validation loss: 2.0147195955117545

Epoch: 5| Step: 7
Training loss: 1.159111738204956
Validation loss: 2.0125094453493753

Epoch: 5| Step: 8
Training loss: 1.4886045455932617
Validation loss: 2.0119259456793466

Epoch: 5| Step: 9
Training loss: 1.7387607097625732
Validation loss: 2.0315545002619424

Epoch: 5| Step: 10
Training loss: 1.2213075160980225
Validation loss: 2.0459880232810974

Epoch: 5| Step: 11
Training loss: 1.9054101705551147
Validation loss: 2.041883185505867

Epoch: 85| Step: 0
Training loss: 2.0848655700683594
Validation loss: 2.054445152481397

Epoch: 5| Step: 1
Training loss: 1.6500232219696045
Validation loss: 2.05035071571668

Epoch: 5| Step: 2
Training loss: 1.468811273574829
Validation loss: 2.0546943793694177

Epoch: 5| Step: 3
Training loss: 2.0748188495635986
Validation loss: 2.0344522098700204

Epoch: 5| Step: 4
Training loss: 1.6588764190673828
Validation loss: 2.017089933156967

Epoch: 5| Step: 5
Training loss: 1.3522282838821411
Validation loss: 2.0156260480483374

Epoch: 5| Step: 6
Training loss: 1.8953138589859009
Validation loss: 2.0260919630527496

Epoch: 5| Step: 7
Training loss: 1.453221321105957
Validation loss: 2.044819156328837

Epoch: 5| Step: 8
Training loss: 2.030052900314331
Validation loss: 1.9713960587978363

Epoch: 5| Step: 9
Training loss: 1.4452190399169922
Validation loss: 2.0053829848766327

Epoch: 5| Step: 10
Training loss: 1.6647945642471313
Validation loss: 2.052061771353086

Epoch: 5| Step: 11
Training loss: 2.1410112380981445
Validation loss: 2.036612167954445

Epoch: 86| Step: 0
Training loss: 1.9341217279434204
Validation loss: 2.0487224807341895

Epoch: 5| Step: 1
Training loss: 1.5213308334350586
Validation loss: 2.0952095985412598

Epoch: 5| Step: 2
Training loss: 1.8171573877334595
Validation loss: 2.101162334283193

Epoch: 5| Step: 3
Training loss: 1.5996614694595337
Validation loss: 2.1131782631079354

Epoch: 5| Step: 4
Training loss: 1.398971438407898
Validation loss: 2.121957629919052

Epoch: 5| Step: 5
Training loss: 1.8534040451049805
Validation loss: 2.1024493078390756

Epoch: 5| Step: 6
Training loss: 1.3165351152420044
Validation loss: 2.0819602409998574

Epoch: 5| Step: 7
Training loss: 1.6250762939453125
Validation loss: 2.0463438779115677

Epoch: 5| Step: 8
Training loss: 1.699558973312378
Validation loss: 2.0761490215857825

Epoch: 5| Step: 9
Training loss: 2.2998409271240234
Validation loss: 2.039799079298973

Epoch: 5| Step: 10
Training loss: 1.7482715845108032
Validation loss: 1.9926190227270126

Epoch: 5| Step: 11
Training loss: 1.51144278049469
Validation loss: 2.0229422797759375

Epoch: 87| Step: 0
Training loss: 1.9264020919799805
Validation loss: 2.006977677345276

Epoch: 5| Step: 1
Training loss: 1.669731855392456
Validation loss: 1.996986856063207

Epoch: 5| Step: 2
Training loss: 2.4560256004333496
Validation loss: 2.0218879133462906

Epoch: 5| Step: 3
Training loss: 1.7842845916748047
Validation loss: 2.029204790790876

Epoch: 5| Step: 4
Training loss: 1.788539171218872
Validation loss: 2.0044960230588913

Epoch: 5| Step: 5
Training loss: 1.5747026205062866
Validation loss: 2.0096889982620874

Epoch: 5| Step: 6
Training loss: 1.6188514232635498
Validation loss: 2.045602411031723

Epoch: 5| Step: 7
Training loss: 1.2211635112762451
Validation loss: 2.025583411256472

Epoch: 5| Step: 8
Training loss: 1.5476620197296143
Validation loss: 2.0288062443335853

Epoch: 5| Step: 9
Training loss: 1.2839040756225586
Validation loss: 2.099673479795456

Epoch: 5| Step: 10
Training loss: 1.7571945190429688
Validation loss: 2.0998062243064246

Epoch: 5| Step: 11
Training loss: 1.2794454097747803
Validation loss: 2.130204270283381

Epoch: 88| Step: 0
Training loss: 1.3143750429153442
Validation loss: 2.0867335498332977

Epoch: 5| Step: 1
Training loss: 1.765616774559021
Validation loss: 2.065767710407575

Epoch: 5| Step: 2
Training loss: 1.7802398204803467
Validation loss: 2.0052970349788666

Epoch: 5| Step: 3
Training loss: 1.094482660293579
Validation loss: 2.0216091126203537

Epoch: 5| Step: 4
Training loss: 1.697675108909607
Validation loss: 2.0054158767064414

Epoch: 5| Step: 5
Training loss: 2.0779173374176025
Validation loss: 2.0159259686867395

Epoch: 5| Step: 6
Training loss: 2.5806756019592285
Validation loss: 2.048388510942459

Epoch: 5| Step: 7
Training loss: 1.3680834770202637
Validation loss: 2.0236640522877374

Epoch: 5| Step: 8
Training loss: 1.6033153533935547
Validation loss: 2.026908059914907

Epoch: 5| Step: 9
Training loss: 1.6638872623443604
Validation loss: 2.0191169331471124

Epoch: 5| Step: 10
Training loss: 1.897202730178833
Validation loss: 2.0187153816223145

Epoch: 5| Step: 11
Training loss: 2.4782168865203857
Validation loss: 2.022687539458275

Epoch: 89| Step: 0
Training loss: 1.9010425806045532
Validation loss: 2.0483667651812234

Epoch: 5| Step: 1
Training loss: 2.0172219276428223
Validation loss: 2.031726211309433

Epoch: 5| Step: 2
Training loss: 2.1645853519439697
Validation loss: 2.050434187054634

Epoch: 5| Step: 3
Training loss: 2.2020516395568848
Validation loss: 2.048811987042427

Epoch: 5| Step: 4
Training loss: 0.8464366793632507
Validation loss: 2.128056446711222

Epoch: 5| Step: 5
Training loss: 1.4070767164230347
Validation loss: 2.108904560407003

Epoch: 5| Step: 6
Training loss: 1.691916823387146
Validation loss: 2.0787152151266732

Epoch: 5| Step: 7
Training loss: 1.8114694356918335
Validation loss: 2.038186972339948

Epoch: 5| Step: 8
Training loss: 1.4858494997024536
Validation loss: 2.023388167222341

Epoch: 5| Step: 9
Training loss: 1.2524696588516235
Validation loss: 1.9969625920057297

Epoch: 5| Step: 10
Training loss: 1.7897850275039673
Validation loss: 2.0231066395839057

Epoch: 5| Step: 11
Training loss: 1.6162807941436768
Validation loss: 2.0366358160972595

Epoch: 90| Step: 0
Training loss: 1.8572664260864258
Validation loss: 2.0406440744797387

Epoch: 5| Step: 1
Training loss: 1.2901936769485474
Validation loss: 2.0183756202459335

Epoch: 5| Step: 2
Training loss: 1.3269696235656738
Validation loss: 2.0163147846857705

Epoch: 5| Step: 3
Training loss: 1.8994861841201782
Validation loss: 2.03507761657238

Epoch: 5| Step: 4
Training loss: 2.0146100521087646
Validation loss: 2.0334686090548835

Epoch: 5| Step: 5
Training loss: 1.7072566747665405
Validation loss: 2.062145655353864

Epoch: 5| Step: 6
Training loss: 2.3176674842834473
Validation loss: 2.0946946342786155

Epoch: 5| Step: 7
Training loss: 2.0140442848205566
Validation loss: 2.0757684210936227

Epoch: 5| Step: 8
Training loss: 1.566206932067871
Validation loss: 2.07135978837808

Epoch: 5| Step: 9
Training loss: 1.2222235202789307
Validation loss: 2.0024720827738443

Epoch: 5| Step: 10
Training loss: 1.232916235923767
Validation loss: 2.0074883798758187

Epoch: 5| Step: 11
Training loss: 2.8781135082244873
Validation loss: 2.0620294213294983

Epoch: 91| Step: 0
Training loss: 2.2236740589141846
Validation loss: 2.0516347835461297

Epoch: 5| Step: 1
Training loss: 1.1142934560775757
Validation loss: 2.0867500603199005

Epoch: 5| Step: 2
Training loss: 1.6487029790878296
Validation loss: 2.0810963809490204

Epoch: 5| Step: 3
Training loss: 1.4802069664001465
Validation loss: 2.036000574628512

Epoch: 5| Step: 4
Training loss: 1.312158226966858
Validation loss: 2.0156079779068627

Epoch: 5| Step: 5
Training loss: 1.9882301092147827
Validation loss: 2.060191268722216

Epoch: 5| Step: 6
Training loss: 1.7105331420898438
Validation loss: 2.05818909406662

Epoch: 5| Step: 7
Training loss: 1.9151376485824585
Validation loss: 2.0279775659243264

Epoch: 5| Step: 8
Training loss: 1.4790432453155518
Validation loss: 2.032248164216677

Epoch: 5| Step: 9
Training loss: 1.4970653057098389
Validation loss: 2.036579435070356

Epoch: 5| Step: 10
Training loss: 1.8919885158538818
Validation loss: 2.0473673393328986

Epoch: 5| Step: 11
Training loss: 1.9452968835830688
Validation loss: 2.0530102203289666

Epoch: 92| Step: 0
Training loss: 2.2617926597595215
Validation loss: 2.0515905767679214

Epoch: 5| Step: 1
Training loss: 2.2613441944122314
Validation loss: 2.048946902155876

Epoch: 5| Step: 2
Training loss: 1.8104900121688843
Validation loss: 2.066095838944117

Epoch: 5| Step: 3
Training loss: 1.2679152488708496
Validation loss: 2.0067317287127175

Epoch: 5| Step: 4
Training loss: 1.1941378116607666
Validation loss: 2.0512682050466537

Epoch: 5| Step: 5
Training loss: 1.2937124967575073
Validation loss: 2.0268856833378472

Epoch: 5| Step: 6
Training loss: 2.44651460647583
Validation loss: 2.0232607573270798

Epoch: 5| Step: 7
Training loss: 1.2992064952850342
Validation loss: 2.0047763337691626

Epoch: 5| Step: 8
Training loss: 1.057051420211792
Validation loss: 2.022354543209076

Epoch: 5| Step: 9
Training loss: 1.8304119110107422
Validation loss: 2.0560631304979324

Epoch: 5| Step: 10
Training loss: 1.1657592058181763
Validation loss: 2.0255288581053414

Epoch: 5| Step: 11
Training loss: 0.870747447013855
Validation loss: 2.112756311893463

Epoch: 93| Step: 0
Training loss: 1.620374083518982
Validation loss: 2.065073937177658

Epoch: 5| Step: 1
Training loss: 1.3663318157196045
Validation loss: 2.115495358904203

Epoch: 5| Step: 2
Training loss: 1.7449274063110352
Validation loss: 2.148118088642756

Epoch: 5| Step: 3
Training loss: 2.1473259925842285
Validation loss: 2.1084357549746833

Epoch: 5| Step: 4
Training loss: 1.1243908405303955
Validation loss: 2.0428939114014306

Epoch: 5| Step: 5
Training loss: 1.699811339378357
Validation loss: 2.0760210504134498

Epoch: 5| Step: 6
Training loss: 1.317043423652649
Validation loss: 2.0298527777194977

Epoch: 5| Step: 7
Training loss: 2.254218816757202
Validation loss: 2.041720971465111

Epoch: 5| Step: 8
Training loss: 1.7466046810150146
Validation loss: 2.0310117304325104

Epoch: 5| Step: 9
Training loss: 1.7041794061660767
Validation loss: 1.9909643630186717

Epoch: 5| Step: 10
Training loss: 1.5185966491699219
Validation loss: 2.0218512217203775

Epoch: 5| Step: 11
Training loss: 1.9391525983810425
Validation loss: 2.0277535070975623

Epoch: 94| Step: 0
Training loss: 1.7654510736465454
Validation loss: 2.000690907239914

Epoch: 5| Step: 1
Training loss: 2.3213210105895996
Validation loss: 2.0182560284932456

Epoch: 5| Step: 2
Training loss: 1.3736116886138916
Validation loss: 2.0306180516878762

Epoch: 5| Step: 3
Training loss: 1.0732500553131104
Validation loss: 2.047832667827606

Epoch: 5| Step: 4
Training loss: 1.275315761566162
Validation loss: 2.030744026104609

Epoch: 5| Step: 5
Training loss: 1.387148141860962
Validation loss: 2.036654750506083

Epoch: 5| Step: 6
Training loss: 1.5517232418060303
Validation loss: 2.0504011313120523

Epoch: 5| Step: 7
Training loss: 2.1052911281585693
Validation loss: 2.092680429418882

Epoch: 5| Step: 8
Training loss: 1.975501298904419
Validation loss: 2.1194804658492408

Epoch: 5| Step: 9
Training loss: 1.572551965713501
Validation loss: 2.0709879994392395

Epoch: 5| Step: 10
Training loss: 1.579419732093811
Validation loss: 2.075956975420316

Epoch: 5| Step: 11
Training loss: 0.8537976741790771
Validation loss: 2.050536592801412

Epoch: 95| Step: 0
Training loss: 1.6578247547149658
Validation loss: 2.0438027530908585

Epoch: 5| Step: 1
Training loss: 1.4094785451889038
Validation loss: 2.0115870386362076

Epoch: 5| Step: 2
Training loss: 1.589423418045044
Validation loss: 2.0326669216156006

Epoch: 5| Step: 3
Training loss: 1.2576677799224854
Validation loss: 2.018790379166603

Epoch: 5| Step: 4
Training loss: 2.2596359252929688
Validation loss: 2.044714793562889

Epoch: 5| Step: 5
Training loss: 1.3446736335754395
Validation loss: 1.993697389960289

Epoch: 5| Step: 6
Training loss: 1.5996681451797485
Validation loss: 2.0304606507221856

Epoch: 5| Step: 7
Training loss: 2.0142598152160645
Validation loss: 2.0885825951894126

Epoch: 5| Step: 8
Training loss: 1.1743252277374268
Validation loss: 2.086119756102562

Epoch: 5| Step: 9
Training loss: 1.9765714406967163
Validation loss: 2.0578060994545617

Epoch: 5| Step: 10
Training loss: 1.3242818117141724
Validation loss: 2.060231029987335

Epoch: 5| Step: 11
Training loss: 2.9260456562042236
Validation loss: 2.083288550376892

Epoch: 96| Step: 0
Training loss: 1.027214527130127
Validation loss: 2.1291282375653586

Epoch: 5| Step: 1
Training loss: 1.1829707622528076
Validation loss: 2.0906777729590735

Epoch: 5| Step: 2
Training loss: 1.4321540594100952
Validation loss: 2.037294626235962

Epoch: 5| Step: 3
Training loss: 1.8160282373428345
Validation loss: 2.0972541173299155

Epoch: 5| Step: 4
Training loss: 1.9466800689697266
Validation loss: 2.0564498702685037

Epoch: 5| Step: 5
Training loss: 1.3534510135650635
Validation loss: 2.0750326861937842

Epoch: 5| Step: 6
Training loss: 1.478416085243225
Validation loss: 2.0678154627482095

Epoch: 5| Step: 7
Training loss: 2.036039352416992
Validation loss: 2.0582664211591086

Epoch: 5| Step: 8
Training loss: 2.3901894092559814
Validation loss: 2.048258582750956

Epoch: 5| Step: 9
Training loss: 1.87190842628479
Validation loss: 1.9976166586081188

Epoch: 5| Step: 10
Training loss: 1.5099002122879028
Validation loss: 2.042954290906588

Epoch: 5| Step: 11
Training loss: 1.5979796648025513
Validation loss: 1.9933365533749263

Epoch: 97| Step: 0
Training loss: 1.3821313381195068
Validation loss: 2.0401834299167

Epoch: 5| Step: 1
Training loss: 1.8031995296478271
Validation loss: 2.0123043805360794

Epoch: 5| Step: 2
Training loss: 1.776057481765747
Validation loss: 2.0719079226255417

Epoch: 5| Step: 3
Training loss: 1.393528938293457
Validation loss: 2.0206889559825263

Epoch: 5| Step: 4
Training loss: 1.7576096057891846
Validation loss: 2.0548941989739737

Epoch: 5| Step: 5
Training loss: 1.8983606100082397
Validation loss: 2.085634633898735

Epoch: 5| Step: 6
Training loss: 1.2818548679351807
Validation loss: 2.1170468231042228

Epoch: 5| Step: 7
Training loss: 1.5481431484222412
Validation loss: 2.0761194129784903

Epoch: 5| Step: 8
Training loss: 1.9191124439239502
Validation loss: 2.0611441334088645

Epoch: 5| Step: 9
Training loss: 1.2508553266525269
Validation loss: 2.0926751842101416

Epoch: 5| Step: 10
Training loss: 1.5429160594940186
Validation loss: 2.0657560328642526

Epoch: 5| Step: 11
Training loss: 1.1887849569320679
Validation loss: 2.045301099618276

Epoch: 98| Step: 0
Training loss: 1.611667275428772
Validation loss: 2.0812900364398956

Epoch: 5| Step: 1
Training loss: 1.5287437438964844
Validation loss: 2.0613973289728165

Epoch: 5| Step: 2
Training loss: 1.480536699295044
Validation loss: 2.0283182710409164

Epoch: 5| Step: 3
Training loss: 1.6843318939208984
Validation loss: 2.054723938306173

Epoch: 5| Step: 4
Training loss: 1.6472852230072021
Validation loss: 2.0639198819796243

Epoch: 5| Step: 5
Training loss: 1.5911997556686401
Validation loss: 2.0582338074843087

Epoch: 5| Step: 6
Training loss: 1.6372267007827759
Validation loss: 2.0481267472108207

Epoch: 5| Step: 7
Training loss: 1.1495593786239624
Validation loss: 2.0390984614690146

Epoch: 5| Step: 8
Training loss: 1.8875315189361572
Validation loss: 2.0069808661937714

Epoch: 5| Step: 9
Training loss: 1.6282669305801392
Validation loss: 1.9954333305358887

Epoch: 5| Step: 10
Training loss: 1.3856055736541748
Validation loss: 2.134109283487002

Epoch: 5| Step: 11
Training loss: 1.1782920360565186
Validation loss: 2.0630673468112946

Epoch: 99| Step: 0
Training loss: 1.032360553741455
Validation loss: 2.0899131993452706

Epoch: 5| Step: 1
Training loss: 1.7535972595214844
Validation loss: 2.0688559661308923

Epoch: 5| Step: 2
Training loss: 1.7509733438491821
Validation loss: 2.1400885631640754

Epoch: 5| Step: 3
Training loss: 1.6640770435333252
Validation loss: 2.0957976977030435

Epoch: 5| Step: 4
Training loss: 1.9476217031478882
Validation loss: 2.109617163737615

Epoch: 5| Step: 5
Training loss: 1.5688573122024536
Validation loss: 2.056739474336306

Epoch: 5| Step: 6
Training loss: 1.4162917137145996
Validation loss: 2.004390130440394

Epoch: 5| Step: 7
Training loss: 1.625923752784729
Validation loss: 2.0719192723433175

Epoch: 5| Step: 8
Training loss: 1.451650857925415
Validation loss: 2.0418958316246667

Epoch: 5| Step: 9
Training loss: 1.5972172021865845
Validation loss: 2.0353878885507584

Epoch: 5| Step: 10
Training loss: 1.0742065906524658
Validation loss: 2.033479859431585

Epoch: 5| Step: 11
Training loss: 2.0661346912384033
Validation loss: 1.9999327659606934

Epoch: 100| Step: 0
Training loss: 1.5360463857650757
Validation loss: 1.9941728313763936

Epoch: 5| Step: 1
Training loss: 1.7417141199111938
Validation loss: 2.009036456545194

Epoch: 5| Step: 2
Training loss: 1.9447205066680908
Validation loss: 2.027023250857989

Epoch: 5| Step: 3
Training loss: 1.658736228942871
Validation loss: 2.0088273882865906

Epoch: 5| Step: 4
Training loss: 1.237647294998169
Validation loss: 1.977596456805865

Epoch: 5| Step: 5
Training loss: 1.7717297077178955
Validation loss: 2.017222205797831

Epoch: 5| Step: 6
Training loss: 1.3546149730682373
Validation loss: 1.9940275351206462

Epoch: 5| Step: 7
Training loss: 1.2075042724609375
Validation loss: 2.0688751389582953

Epoch: 5| Step: 8
Training loss: 2.20733904838562
Validation loss: 2.0538244942824044

Epoch: 5| Step: 9
Training loss: 1.3747105598449707
Validation loss: 2.0668845226367316

Epoch: 5| Step: 10
Training loss: 1.375283122062683
Validation loss: 1.9978824903567631

Epoch: 5| Step: 11
Training loss: 0.8361493945121765
Validation loss: 2.081131706635157

Epoch: 101| Step: 0
Training loss: 1.0989381074905396
Validation loss: 2.076610177755356

Epoch: 5| Step: 1
Training loss: 1.5865415334701538
Validation loss: 2.021811311443647

Epoch: 5| Step: 2
Training loss: 1.424236536026001
Validation loss: 2.0348728696505227

Epoch: 5| Step: 3
Training loss: 1.6350371837615967
Validation loss: 2.0440702686707177

Epoch: 5| Step: 4
Training loss: 1.3961865901947021
Validation loss: 1.9592079520225525

Epoch: 5| Step: 5
Training loss: 1.4242807626724243
Validation loss: 2.0203434030214944

Epoch: 5| Step: 6
Training loss: 1.7370376586914062
Validation loss: 2.013499697049459

Epoch: 5| Step: 7
Training loss: 1.8881285190582275
Validation loss: 2.0210871597131095

Epoch: 5| Step: 8
Training loss: 1.665553331375122
Validation loss: 2.03364106019338

Epoch: 5| Step: 9
Training loss: 1.5315520763397217
Validation loss: 2.043023412426313

Epoch: 5| Step: 10
Training loss: 1.5167280435562134
Validation loss: 2.05080313483874

Epoch: 5| Step: 11
Training loss: 2.376850128173828
Validation loss: 2.004686176776886

Epoch: 102| Step: 0
Training loss: 1.6514742374420166
Validation loss: 1.992426911989848

Epoch: 5| Step: 1
Training loss: 1.1348793506622314
Validation loss: 2.001526633898417

Epoch: 5| Step: 2
Training loss: 1.4739292860031128
Validation loss: 2.0097764432430267

Epoch: 5| Step: 3
Training loss: 1.7030649185180664
Validation loss: 2.0006848673025766

Epoch: 5| Step: 4
Training loss: 1.5467431545257568
Validation loss: 2.0334879060586295

Epoch: 5| Step: 5
Training loss: 1.3960548639297485
Validation loss: 1.9830831736326218

Epoch: 5| Step: 6
Training loss: 1.5493879318237305
Validation loss: 1.991152713696162

Epoch: 5| Step: 7
Training loss: 1.5998016595840454
Validation loss: 2.038836052020391

Epoch: 5| Step: 8
Training loss: 1.9701370000839233
Validation loss: 2.028489132722219

Epoch: 5| Step: 9
Training loss: 1.5882153511047363
Validation loss: 2.0703231443961463

Epoch: 5| Step: 10
Training loss: 1.6068115234375
Validation loss: 2.0531418522198996

Epoch: 5| Step: 11
Training loss: 1.1200405359268188
Validation loss: 2.0579768965641656

Epoch: 103| Step: 0
Training loss: 1.503977656364441
Validation loss: 2.02201838294665

Epoch: 5| Step: 1
Training loss: 1.5127143859863281
Validation loss: 2.0219200551509857

Epoch: 5| Step: 2
Training loss: 1.2977758646011353
Validation loss: 2.0495395412047706

Epoch: 5| Step: 3
Training loss: 1.215129017829895
Validation loss: 2.025099371870359

Epoch: 5| Step: 4
Training loss: 1.1966454982757568
Validation loss: 2.0580890079339347

Epoch: 5| Step: 5
Training loss: 0.9661471247673035
Validation loss: 2.0401237159967422

Epoch: 5| Step: 6
Training loss: 1.91681706905365
Validation loss: 2.0437992165486016

Epoch: 5| Step: 7
Training loss: 1.2257462739944458
Validation loss: 1.9812338302532833

Epoch: 5| Step: 8
Training loss: 2.1951324939727783
Validation loss: 2.034588192900022

Epoch: 5| Step: 9
Training loss: 1.8510735034942627
Validation loss: 2.0894212871789932

Epoch: 5| Step: 10
Training loss: 1.9558368921279907
Validation loss: 2.0883182088534036

Epoch: 5| Step: 11
Training loss: 1.6017590761184692
Validation loss: 2.097668652733167

Epoch: 104| Step: 0
Training loss: 1.65948486328125
Validation loss: 2.076813484231631

Epoch: 5| Step: 1
Training loss: 1.2293970584869385
Validation loss: 2.0958352386951447

Epoch: 5| Step: 2
Training loss: 1.26615309715271
Validation loss: 2.0380509793758392

Epoch: 5| Step: 3
Training loss: 1.6504770517349243
Validation loss: 2.0225041210651398

Epoch: 5| Step: 4
Training loss: 1.8566557168960571
Validation loss: 2.0337167332569757

Epoch: 5| Step: 5
Training loss: 1.53169846534729
Validation loss: 2.021812597910563

Epoch: 5| Step: 6
Training loss: 1.6226608753204346
Validation loss: 2.081054538488388

Epoch: 5| Step: 7
Training loss: 1.2184250354766846
Validation loss: 1.9727007399002712

Epoch: 5| Step: 8
Training loss: 1.3923906087875366
Validation loss: 2.0608793050050735

Epoch: 5| Step: 9
Training loss: 1.7372102737426758
Validation loss: 2.0108465552330017

Epoch: 5| Step: 10
Training loss: 1.3904426097869873
Validation loss: 2.072198376059532

Epoch: 5| Step: 11
Training loss: 0.9699397087097168
Validation loss: 2.046909893552462

Epoch: 105| Step: 0
Training loss: 1.7718651294708252
Validation loss: 2.02407739063104

Epoch: 5| Step: 1
Training loss: 1.5850803852081299
Validation loss: 2.0036867360273996

Epoch: 5| Step: 2
Training loss: 1.323117971420288
Validation loss: 2.011325712005297

Epoch: 5| Step: 3
Training loss: 1.7321317195892334
Validation loss: 2.0235696683327355

Epoch: 5| Step: 4
Training loss: 1.5690281391143799
Validation loss: 2.0225890775521598

Epoch: 5| Step: 5
Training loss: 1.4264215230941772
Validation loss: 2.029655252893766

Epoch: 5| Step: 6
Training loss: 1.3841466903686523
Validation loss: 2.0022610078255334

Epoch: 5| Step: 7
Training loss: 0.9570099115371704
Validation loss: 2.0281165142854056

Epoch: 5| Step: 8
Training loss: 1.7873408794403076
Validation loss: 2.032378762960434

Epoch: 5| Step: 9
Training loss: 1.0954840183258057
Validation loss: 2.042729541659355

Epoch: 5| Step: 10
Training loss: 1.8098371028900146
Validation loss: 2.1050695528586707

Epoch: 5| Step: 11
Training loss: 0.7985283136367798
Validation loss: 2.0554939409097037

Epoch: 106| Step: 0
Training loss: 1.2168182134628296
Validation loss: 2.085393249988556

Epoch: 5| Step: 1
Training loss: 1.711918830871582
Validation loss: 2.1168175290028253

Epoch: 5| Step: 2
Training loss: 2.1027369499206543
Validation loss: 2.0593292812506356

Epoch: 5| Step: 3
Training loss: 1.387468695640564
Validation loss: 2.071622063716253

Epoch: 5| Step: 4
Training loss: 0.6745785474777222
Validation loss: 2.029463514685631

Epoch: 5| Step: 5
Training loss: 1.9689865112304688
Validation loss: 2.036815881729126

Epoch: 5| Step: 6
Training loss: 1.170245885848999
Validation loss: 2.031579911708832

Epoch: 5| Step: 7
Training loss: 1.6193662881851196
Validation loss: 1.9866951803366344

Epoch: 5| Step: 8
Training loss: 1.1689598560333252
Validation loss: 2.0251040905714035

Epoch: 5| Step: 9
Training loss: 1.5322484970092773
Validation loss: 2.0155676752328873

Epoch: 5| Step: 10
Training loss: 1.4226380586624146
Validation loss: 2.046283240119616

Epoch: 5| Step: 11
Training loss: 3.2064971923828125
Validation loss: 2.000857705871264

Epoch: 107| Step: 0
Training loss: 1.4708601236343384
Validation loss: 2.0336381743351617

Epoch: 5| Step: 1
Training loss: 0.7697517275810242
Validation loss: 2.0200324406226478

Epoch: 5| Step: 2
Training loss: 1.5489400625228882
Validation loss: 2.099927286307017

Epoch: 5| Step: 3
Training loss: 1.654524564743042
Validation loss: 2.0904530386130014

Epoch: 5| Step: 4
Training loss: 1.8037761449813843
Validation loss: 2.1025249361991882

Epoch: 5| Step: 5
Training loss: 1.0400638580322266
Validation loss: 2.1245096375544867

Epoch: 5| Step: 6
Training loss: 1.9782817363739014
Validation loss: 2.1019317905108132

Epoch: 5| Step: 7
Training loss: 1.4188183546066284
Validation loss: 2.0669832825660706

Epoch: 5| Step: 8
Training loss: 1.3871290683746338
Validation loss: 2.095866580804189

Epoch: 5| Step: 9
Training loss: 1.512000560760498
Validation loss: 2.0149735510349274

Epoch: 5| Step: 10
Training loss: 1.701367735862732
Validation loss: 1.990184818704923

Epoch: 5| Step: 11
Training loss: 1.697577953338623
Validation loss: 2.0318414320548377

Epoch: 108| Step: 0
Training loss: 1.8441660404205322
Validation loss: 1.9691306600968044

Epoch: 5| Step: 1
Training loss: 1.3344618082046509
Validation loss: 2.0316337595383325

Epoch: 5| Step: 2
Training loss: 2.057663679122925
Validation loss: 2.010181854168574

Epoch: 5| Step: 3
Training loss: 1.1120402812957764
Validation loss: 2.022545243302981

Epoch: 5| Step: 4
Training loss: 1.6093883514404297
Validation loss: 2.0371111035346985

Epoch: 5| Step: 5
Training loss: 0.957114040851593
Validation loss: 2.045599748690923

Epoch: 5| Step: 6
Training loss: 1.3759931325912476
Validation loss: 2.0623357643683753

Epoch: 5| Step: 7
Training loss: 1.3065944910049438
Validation loss: 2.04168135424455

Epoch: 5| Step: 8
Training loss: 1.2288744449615479
Validation loss: 2.0290452192227044

Epoch: 5| Step: 9
Training loss: 1.8953502178192139
Validation loss: 2.1210389931996665

Epoch: 5| Step: 10
Training loss: 1.903193712234497
Validation loss: 2.1570858359336853

Epoch: 5| Step: 11
Training loss: 1.1698005199432373
Validation loss: 2.1818669786055884

Epoch: 109| Step: 0
Training loss: 2.047380208969116
Validation loss: 2.1231246491273246

Epoch: 5| Step: 1
Training loss: 0.6155826449394226
Validation loss: 2.0430010110139847

Epoch: 5| Step: 2
Training loss: 0.9128339886665344
Validation loss: 2.0256816347440085

Epoch: 5| Step: 3
Training loss: 1.44234037399292
Validation loss: 2.055719325939814

Epoch: 5| Step: 4
Training loss: 2.1899588108062744
Validation loss: 2.013209601243337

Epoch: 5| Step: 5
Training loss: 1.8494186401367188
Validation loss: 2.0387809673945108

Epoch: 5| Step: 6
Training loss: 1.1731925010681152
Validation loss: 2.022403379281362

Epoch: 5| Step: 7
Training loss: 1.1362030506134033
Validation loss: 1.9954311748345692

Epoch: 5| Step: 8
Training loss: 1.8110973834991455
Validation loss: 2.0389118740955987

Epoch: 5| Step: 9
Training loss: 1.4774677753448486
Validation loss: 2.0222859233617783

Epoch: 5| Step: 10
Training loss: 1.7586168050765991
Validation loss: 2.08086059987545

Epoch: 5| Step: 11
Training loss: 1.4538580179214478
Validation loss: 2.0862892170747123

Epoch: 110| Step: 0
Training loss: 1.2134228944778442
Validation loss: 2.0629358490308127

Epoch: 5| Step: 1
Training loss: 1.4912770986557007
Validation loss: 2.096350555618604

Epoch: 5| Step: 2
Training loss: 1.5635249614715576
Validation loss: 2.138889580965042

Epoch: 5| Step: 3
Training loss: 2.1006550788879395
Validation loss: 2.1096329987049103

Epoch: 5| Step: 4
Training loss: 1.8222545385360718
Validation loss: 2.075818826754888

Epoch: 5| Step: 5
Training loss: 1.2938110828399658
Validation loss: 2.05428513387839

Epoch: 5| Step: 6
Training loss: 1.1149771213531494
Validation loss: 2.0301634867986045

Epoch: 5| Step: 7
Training loss: 1.4851559400558472
Validation loss: 2.068868046005567

Epoch: 5| Step: 8
Training loss: 1.334549069404602
Validation loss: 2.079613074660301

Epoch: 5| Step: 9
Training loss: 1.3011512756347656
Validation loss: 2.063267399867376

Epoch: 5| Step: 10
Training loss: 1.1482983827590942
Validation loss: 2.0354916006326675

Epoch: 5| Step: 11
Training loss: 1.526059865951538
Validation loss: 2.037539929151535

Epoch: 111| Step: 0
Training loss: 1.5593018531799316
Validation loss: 2.01914710799853

Epoch: 5| Step: 1
Training loss: 1.3663305044174194
Validation loss: 1.9978348364432652

Epoch: 5| Step: 2
Training loss: 1.0406436920166016
Validation loss: 2.0080114205678306

Epoch: 5| Step: 3
Training loss: 1.233751654624939
Validation loss: 2.038687994082769

Epoch: 5| Step: 4
Training loss: 1.2759239673614502
Validation loss: 2.031965191165606

Epoch: 5| Step: 5
Training loss: 1.42886483669281
Validation loss: 2.037220944960912

Epoch: 5| Step: 6
Training loss: 1.2124295234680176
Validation loss: 2.070357988278071

Epoch: 5| Step: 7
Training loss: 1.7418413162231445
Validation loss: 2.0682312647501626

Epoch: 5| Step: 8
Training loss: 1.5390422344207764
Validation loss: 2.1059913486242294

Epoch: 5| Step: 9
Training loss: 1.5319162607192993
Validation loss: 2.08597860733668

Epoch: 5| Step: 10
Training loss: 1.6783263683319092
Validation loss: 2.0913729071617126

Epoch: 5| Step: 11
Training loss: 1.870863676071167
Validation loss: 2.100284536679586

Epoch: 112| Step: 0
Training loss: 1.086978793144226
Validation loss: 2.0635530153910318

Epoch: 5| Step: 1
Training loss: 1.4881505966186523
Validation loss: 2.0688075770934424

Epoch: 5| Step: 2
Training loss: 1.5082100629806519
Validation loss: 2.04941962659359

Epoch: 5| Step: 3
Training loss: 1.6020784378051758
Validation loss: 2.100160370270411

Epoch: 5| Step: 4
Training loss: 1.410148024559021
Validation loss: 2.083032896121343

Epoch: 5| Step: 5
Training loss: 1.1958404779434204
Validation loss: 2.0363622506459556

Epoch: 5| Step: 6
Training loss: 1.6939165592193604
Validation loss: 2.0614929099877677

Epoch: 5| Step: 7
Training loss: 1.2953804731369019
Validation loss: 2.048234313726425

Epoch: 5| Step: 8
Training loss: 2.0069198608398438
Validation loss: 2.0552742332220078

Epoch: 5| Step: 9
Training loss: 1.3279579877853394
Validation loss: 2.044781948129336

Epoch: 5| Step: 10
Training loss: 1.0682222843170166
Validation loss: 2.0723775376876197

Epoch: 5| Step: 11
Training loss: 1.0127381086349487
Validation loss: 2.0624556094408035

Epoch: 113| Step: 0
Training loss: 1.1055200099945068
Validation loss: 2.022789051135381

Epoch: 5| Step: 1
Training loss: 2.0111546516418457
Validation loss: 2.0583771467208862

Epoch: 5| Step: 2
Training loss: 1.6851205825805664
Validation loss: 2.0033615976572037

Epoch: 5| Step: 3
Training loss: 1.696804404258728
Validation loss: 2.054152692357699

Epoch: 5| Step: 4
Training loss: 1.5867092609405518
Validation loss: 2.01422585050265

Epoch: 5| Step: 5
Training loss: 1.2491681575775146
Validation loss: 2.043468485275904

Epoch: 5| Step: 6
Training loss: 1.7372251749038696
Validation loss: 2.0228743056456246

Epoch: 5| Step: 7
Training loss: 1.3417397737503052
Validation loss: 2.0499882797400155

Epoch: 5| Step: 8
Training loss: 1.0166337490081787
Validation loss: 2.0222515910863876

Epoch: 5| Step: 9
Training loss: 1.7094624042510986
Validation loss: 2.064627135793368

Epoch: 5| Step: 10
Training loss: 0.9742321968078613
Validation loss: 2.0046513875325522

Epoch: 5| Step: 11
Training loss: 0.7955946922302246
Validation loss: 2.083508238196373

Epoch: 114| Step: 0
Training loss: 1.5585638284683228
Validation loss: 2.1829163879156113

Epoch: 5| Step: 1
Training loss: 1.4152400493621826
Validation loss: 2.1567765971024833

Epoch: 5| Step: 2
Training loss: 1.477977991104126
Validation loss: 2.218027740716934

Epoch: 5| Step: 3
Training loss: 1.5848488807678223
Validation loss: 2.2202567756175995

Epoch: 5| Step: 4
Training loss: 1.7560882568359375
Validation loss: 2.196940690279007

Epoch: 5| Step: 5
Training loss: 1.2818788290023804
Validation loss: 2.0960615277290344

Epoch: 5| Step: 6
Training loss: 1.080353021621704
Validation loss: 2.0437474151452384

Epoch: 5| Step: 7
Training loss: 1.3533213138580322
Validation loss: 1.9673145711421967

Epoch: 5| Step: 8
Training loss: 1.6352535486221313
Validation loss: 2.0056827117999396

Epoch: 5| Step: 9
Training loss: 1.2326042652130127
Validation loss: 2.00288417438666

Epoch: 5| Step: 10
Training loss: 2.085109233856201
Validation loss: 2.0065430055061975

Epoch: 5| Step: 11
Training loss: 0.4600657820701599
Validation loss: 2.0107729037602744

Epoch: 115| Step: 0
Training loss: 1.1513116359710693
Validation loss: 2.027327597141266

Epoch: 5| Step: 1
Training loss: 1.5117372274398804
Validation loss: 2.056948001186053

Epoch: 5| Step: 2
Training loss: 1.453672170639038
Validation loss: 2.05116660396258

Epoch: 5| Step: 3
Training loss: 1.8621937036514282
Validation loss: 2.0344093590974808

Epoch: 5| Step: 4
Training loss: 1.3320366144180298
Validation loss: 2.081851770480474

Epoch: 5| Step: 5
Training loss: 1.1481307744979858
Validation loss: 2.080408533414205

Epoch: 5| Step: 6
Training loss: 1.0003461837768555
Validation loss: 2.0298254787921906

Epoch: 5| Step: 7
Training loss: 1.1042954921722412
Validation loss: 2.0663276662429175

Epoch: 5| Step: 8
Training loss: 2.1168854236602783
Validation loss: 2.056910276412964

Epoch: 5| Step: 9
Training loss: 1.2279869318008423
Validation loss: 2.0662363370259604

Epoch: 5| Step: 10
Training loss: 1.4970741271972656
Validation loss: 2.0449374268452325

Epoch: 5| Step: 11
Training loss: 1.3197797536849976
Validation loss: 2.087497115135193

Epoch: 116| Step: 0
Training loss: 1.2223848104476929
Validation loss: 2.0817552904287973

Epoch: 5| Step: 1
Training loss: 1.022292971611023
Validation loss: 2.1001733243465424

Epoch: 5| Step: 2
Training loss: 1.567768931388855
Validation loss: 2.1161955992380777

Epoch: 5| Step: 3
Training loss: 1.7970170974731445
Validation loss: 2.1297155718008676

Epoch: 5| Step: 4
Training loss: 1.3197147846221924
Validation loss: 2.1327501932779946

Epoch: 5| Step: 5
Training loss: 1.8770530223846436
Validation loss: 2.1238289227088294

Epoch: 5| Step: 6
Training loss: 0.8204644322395325
Validation loss: 2.098423346877098

Epoch: 5| Step: 7
Training loss: 1.5578659772872925
Validation loss: 2.066972275575002

Epoch: 5| Step: 8
Training loss: 1.4585810899734497
Validation loss: 2.050240715344747

Epoch: 5| Step: 9
Training loss: 1.5078693628311157
Validation loss: 2.0514230032761893

Epoch: 5| Step: 10
Training loss: 1.2320945262908936
Validation loss: 2.0645312666893005

Epoch: 5| Step: 11
Training loss: 1.0623775720596313
Validation loss: 2.0412427137295404

Epoch: 117| Step: 0
Training loss: 1.7722218036651611
Validation loss: 2.052006423473358

Epoch: 5| Step: 1
Training loss: 1.3640488386154175
Validation loss: 2.061220129330953

Epoch: 5| Step: 2
Training loss: 1.0478391647338867
Validation loss: 2.0280313938856125

Epoch: 5| Step: 3
Training loss: 1.6328299045562744
Validation loss: 2.0910860300064087

Epoch: 5| Step: 4
Training loss: 1.7430833578109741
Validation loss: 2.0487421651681266

Epoch: 5| Step: 5
Training loss: 1.1529946327209473
Validation loss: 2.1067174772421517

Epoch: 5| Step: 6
Training loss: 1.320942759513855
Validation loss: 2.090950538714727

Epoch: 5| Step: 7
Training loss: 1.1697518825531006
Validation loss: 2.085461974143982

Epoch: 5| Step: 8
Training loss: 1.535218358039856
Validation loss: 2.0351462115844092

Epoch: 5| Step: 9
Training loss: 1.1785153150558472
Validation loss: 2.0940237939357758

Epoch: 5| Step: 10
Training loss: 1.4322906732559204
Validation loss: 2.0612605661153793

Epoch: 5| Step: 11
Training loss: 0.7979902029037476
Validation loss: 2.104562520980835

Epoch: 118| Step: 0
Training loss: 1.167258620262146
Validation loss: 2.088393817345301

Epoch: 5| Step: 1
Training loss: 1.6309187412261963
Validation loss: 2.0435607035954795

Epoch: 5| Step: 2
Training loss: 1.452976942062378
Validation loss: 2.0941289762655892

Epoch: 5| Step: 3
Training loss: 1.585506558418274
Validation loss: 2.1190613557895026

Epoch: 5| Step: 4
Training loss: 1.2149059772491455
Validation loss: 1.9991338054339092

Epoch: 5| Step: 5
Training loss: 1.1739740371704102
Validation loss: 2.0450197805960975

Epoch: 5| Step: 6
Training loss: 1.705157995223999
Validation loss: 2.01125305891037

Epoch: 5| Step: 7
Training loss: 1.42868971824646
Validation loss: 2.0212105562289557

Epoch: 5| Step: 8
Training loss: 0.911516547203064
Validation loss: 2.044249211748441

Epoch: 5| Step: 9
Training loss: 1.3967067003250122
Validation loss: 2.084573065241178

Epoch: 5| Step: 10
Training loss: 1.2786462306976318
Validation loss: 2.070471460620562

Epoch: 5| Step: 11
Training loss: 1.294053554534912
Validation loss: 2.092079530159632

Epoch: 119| Step: 0
Training loss: 1.1111286878585815
Validation loss: 2.0985960563023887

Epoch: 5| Step: 1
Training loss: 1.3364943265914917
Validation loss: 2.069625586271286

Epoch: 5| Step: 2
Training loss: 1.143784761428833
Validation loss: 2.0691531201203666

Epoch: 5| Step: 3
Training loss: 1.6632907390594482
Validation loss: 2.0607908169428506

Epoch: 5| Step: 4
Training loss: 1.0367321968078613
Validation loss: 2.113159199555715

Epoch: 5| Step: 5
Training loss: 1.318448781967163
Validation loss: 2.0286611914634705

Epoch: 5| Step: 6
Training loss: 0.9128161668777466
Validation loss: 2.0073145727316537

Epoch: 5| Step: 7
Training loss: 2.0148072242736816
Validation loss: 2.036973853905996

Epoch: 5| Step: 8
Training loss: 1.0081064701080322
Validation loss: 2.0072636157274246

Epoch: 5| Step: 9
Training loss: 1.535400629043579
Validation loss: 2.0110515455404916

Epoch: 5| Step: 10
Training loss: 1.515468955039978
Validation loss: 1.9633237967888515

Epoch: 5| Step: 11
Training loss: 1.9962923526763916
Validation loss: 1.9902388751506805

Epoch: 120| Step: 0
Training loss: 0.8059538006782532
Validation loss: 2.004169151186943

Epoch: 5| Step: 1
Training loss: 1.3712565898895264
Validation loss: 2.0232016493876777

Epoch: 5| Step: 2
Training loss: 1.202734351158142
Validation loss: 1.9885278393824894

Epoch: 5| Step: 3
Training loss: 1.5082964897155762
Validation loss: 2.0651334524154663

Epoch: 5| Step: 4
Training loss: 1.4491546154022217
Validation loss: 2.0626301864782968

Epoch: 5| Step: 5
Training loss: 1.0284570455551147
Validation loss: 2.0824098140001297

Epoch: 5| Step: 6
Training loss: 1.1021194458007812
Validation loss: 2.042476420601209

Epoch: 5| Step: 7
Training loss: 1.6977227926254272
Validation loss: 2.0373069445292153

Epoch: 5| Step: 8
Training loss: 1.042689323425293
Validation loss: 2.0238952289024987

Epoch: 5| Step: 9
Training loss: 1.1040685176849365
Validation loss: 2.0258236626784005

Epoch: 5| Step: 10
Training loss: 1.9617655277252197
Validation loss: 2.0094433228174844

Epoch: 5| Step: 11
Training loss: 1.9418177604675293
Validation loss: 2.067297860980034

Epoch: 121| Step: 0
Training loss: 1.3640153408050537
Validation loss: 2.0191524575153985

Epoch: 5| Step: 1
Training loss: 1.0088846683502197
Validation loss: 2.0246720711390176

Epoch: 5| Step: 2
Training loss: 0.921427845954895
Validation loss: 2.040344774723053

Epoch: 5| Step: 3
Training loss: 1.4619101285934448
Validation loss: 2.06141992410024

Epoch: 5| Step: 4
Training loss: 1.3512306213378906
Validation loss: 2.0872818728288016

Epoch: 5| Step: 5
Training loss: 1.1805665493011475
Validation loss: 2.0844643662373223

Epoch: 5| Step: 6
Training loss: 1.1598386764526367
Validation loss: 2.11005370815595

Epoch: 5| Step: 7
Training loss: 1.2188756465911865
Validation loss: 2.1064253747463226

Epoch: 5| Step: 8
Training loss: 1.6544158458709717
Validation loss: 2.0696526716152825

Epoch: 5| Step: 9
Training loss: 1.4425913095474243
Validation loss: 2.0461221486330032

Epoch: 5| Step: 10
Training loss: 1.5385271310806274
Validation loss: 2.0322115421295166

Epoch: 5| Step: 11
Training loss: 1.7875714302062988
Validation loss: 2.0738867868979773

Epoch: 122| Step: 0
Training loss: 1.0090076923370361
Validation loss: 2.02428936958313

Epoch: 5| Step: 1
Training loss: 1.531524896621704
Validation loss: 2.0595382104317346

Epoch: 5| Step: 2
Training loss: 1.2908012866973877
Validation loss: 2.065028746922811

Epoch: 5| Step: 3
Training loss: 1.1196115016937256
Validation loss: 2.091642508904139

Epoch: 5| Step: 4
Training loss: 1.4484914541244507
Validation loss: 2.143906777103742

Epoch: 5| Step: 5
Training loss: 1.8499634265899658
Validation loss: 2.145067021250725

Epoch: 5| Step: 6
Training loss: 0.8313466906547546
Validation loss: 2.1375519931316376

Epoch: 5| Step: 7
Training loss: 0.8922189474105835
Validation loss: 2.092173218727112

Epoch: 5| Step: 8
Training loss: 2.207542896270752
Validation loss: 2.0703372061252594

Epoch: 5| Step: 9
Training loss: 1.3588154315948486
Validation loss: 2.031366487344106

Epoch: 5| Step: 10
Training loss: 1.5069749355316162
Validation loss: 2.0275370677312217

Epoch: 5| Step: 11
Training loss: 0.3953424096107483
Validation loss: 2.039730673034986

Epoch: 123| Step: 0
Training loss: 1.5128486156463623
Validation loss: 2.034789909919103

Epoch: 5| Step: 1
Training loss: 1.2078971862792969
Validation loss: 2.0584764778614044

Epoch: 5| Step: 2
Training loss: 0.7702348828315735
Validation loss: 2.064070055882136

Epoch: 5| Step: 3
Training loss: 1.2787803411483765
Validation loss: 2.006070151925087

Epoch: 5| Step: 4
Training loss: 0.9637578725814819
Validation loss: 2.045888975262642

Epoch: 5| Step: 5
Training loss: 1.7014529705047607
Validation loss: 2.1142719984054565

Epoch: 5| Step: 6
Training loss: 0.8569307327270508
Validation loss: 2.0850998212893805

Epoch: 5| Step: 7
Training loss: 0.546657919883728
Validation loss: 2.0992082357406616

Epoch: 5| Step: 8
Training loss: 1.7767698764801025
Validation loss: 2.0615428437789283

Epoch: 5| Step: 9
Training loss: 1.9780677556991577
Validation loss: 2.107303892572721

Epoch: 5| Step: 10
Training loss: 1.46018385887146
Validation loss: 2.0428369641304016

Epoch: 5| Step: 11
Training loss: 1.2253248691558838
Validation loss: 2.08634019891421

Epoch: 124| Step: 0
Training loss: 1.3303625583648682
Validation loss: 2.052121122678121

Epoch: 5| Step: 1
Training loss: 0.9166412353515625
Validation loss: 2.0557337552309036

Epoch: 5| Step: 2
Training loss: 1.7784274816513062
Validation loss: 2.0723316967487335

Epoch: 5| Step: 3
Training loss: 1.5078991651535034
Validation loss: 2.0679813424746194

Epoch: 5| Step: 4
Training loss: 1.1540110111236572
Validation loss: 2.0397538443406424

Epoch: 5| Step: 5
Training loss: 0.8081073760986328
Validation loss: 2.0230719645818076

Epoch: 5| Step: 6
Training loss: 1.1711443662643433
Validation loss: 2.0301278233528137

Epoch: 5| Step: 7
Training loss: 1.7039051055908203
Validation loss: 2.004748543103536

Epoch: 5| Step: 8
Training loss: 1.1255038976669312
Validation loss: 1.9947585264841716

Epoch: 5| Step: 9
Training loss: 1.2421226501464844
Validation loss: 2.0221994519233704

Epoch: 5| Step: 10
Training loss: 0.9540799260139465
Validation loss: 2.007706249753634

Epoch: 5| Step: 11
Training loss: 1.4375574588775635
Validation loss: 2.023246387640635

Epoch: 125| Step: 0
Training loss: 1.4852144718170166
Validation loss: 2.1199343651533127

Epoch: 5| Step: 1
Training loss: 1.3742061853408813
Validation loss: 2.115979035695394

Epoch: 5| Step: 2
Training loss: 1.916452169418335
Validation loss: 2.0968563308318457

Epoch: 5| Step: 3
Training loss: 1.647007942199707
Validation loss: 2.0792234937349954

Epoch: 5| Step: 4
Training loss: 1.249648094177246
Validation loss: 2.098400662342707

Epoch: 5| Step: 5
Training loss: 1.1787595748901367
Validation loss: 2.0584264596303306

Epoch: 5| Step: 6
Training loss: 0.9906139373779297
Validation loss: 2.057242602109909

Epoch: 5| Step: 7
Training loss: 1.3907692432403564
Validation loss: 2.0356777360041938

Epoch: 5| Step: 8
Training loss: 0.9564876556396484
Validation loss: 2.0502205888430276

Epoch: 5| Step: 9
Training loss: 1.5617024898529053
Validation loss: 2.0572523027658463

Epoch: 5| Step: 10
Training loss: 0.7075042724609375
Validation loss: 2.0468878000974655

Epoch: 5| Step: 11
Training loss: 1.4275758266448975
Validation loss: 2.010627085963885

Epoch: 126| Step: 0
Training loss: 1.5674597024917603
Validation loss: 2.039135977625847

Epoch: 5| Step: 1
Training loss: 1.5755410194396973
Validation loss: 2.0681485335032144

Epoch: 5| Step: 2
Training loss: 0.8904544115066528
Validation loss: 2.045023043950399

Epoch: 5| Step: 3
Training loss: 1.37581467628479
Validation loss: 2.137317677338918

Epoch: 5| Step: 4
Training loss: 1.8048574924468994
Validation loss: 2.1254512667655945

Epoch: 5| Step: 5
Training loss: 1.1594654321670532
Validation loss: 2.12197678287824

Epoch: 5| Step: 6
Training loss: 1.0981489419937134
Validation loss: 2.1708852648735046

Epoch: 5| Step: 7
Training loss: 0.5431885719299316
Validation loss: 2.0523572663466134

Epoch: 5| Step: 8
Training loss: 1.313285231590271
Validation loss: 2.0843016107877097

Epoch: 5| Step: 9
Training loss: 1.05288827419281
Validation loss: 2.0683264334996543

Epoch: 5| Step: 10
Training loss: 1.5288479328155518
Validation loss: 2.073665122191111

Epoch: 5| Step: 11
Training loss: 1.1303566694259644
Validation loss: 2.0767198701699576

Epoch: 127| Step: 0
Training loss: 1.6008069515228271
Validation loss: 2.0662187288204827

Epoch: 5| Step: 1
Training loss: 1.0758320093154907
Validation loss: 2.070809245109558

Epoch: 5| Step: 2
Training loss: 1.2706254720687866
Validation loss: 2.088242535789808

Epoch: 5| Step: 3
Training loss: 1.3474962711334229
Validation loss: 2.182883063952128

Epoch: 5| Step: 4
Training loss: 1.5825798511505127
Validation loss: 2.1498548686504364

Epoch: 5| Step: 5
Training loss: 0.7779055833816528
Validation loss: 2.142342120409012

Epoch: 5| Step: 6
Training loss: 1.1381185054779053
Validation loss: 2.1778021156787872

Epoch: 5| Step: 7
Training loss: 1.2648298740386963
Validation loss: 2.1634693642457328

Epoch: 5| Step: 8
Training loss: 0.9504337310791016
Validation loss: 2.066653937101364

Epoch: 5| Step: 9
Training loss: 1.53255033493042
Validation loss: 2.020612140496572

Epoch: 5| Step: 10
Training loss: 1.1163769960403442
Validation loss: 2.04636657734712

Epoch: 5| Step: 11
Training loss: 0.9789732694625854
Validation loss: 2.0690404077370963

Epoch: 128| Step: 0
Training loss: 1.7645397186279297
Validation loss: 2.0508394291003547

Epoch: 5| Step: 1
Training loss: 1.1112515926361084
Validation loss: 2.0758626212676368

Epoch: 5| Step: 2
Training loss: 1.0095479488372803
Validation loss: 2.0689008931318917

Epoch: 5| Step: 3
Training loss: 1.3881828784942627
Validation loss: 2.0297450870275497

Epoch: 5| Step: 4
Training loss: 1.5541913509368896
Validation loss: 2.075368642807007

Epoch: 5| Step: 5
Training loss: 1.4920356273651123
Validation loss: 2.1498550524314246

Epoch: 5| Step: 6
Training loss: 1.2193970680236816
Validation loss: 2.1447359969218573

Epoch: 5| Step: 7
Training loss: 1.242145299911499
Validation loss: 2.0908356209596

Epoch: 5| Step: 8
Training loss: 0.8911436200141907
Validation loss: 2.051043763756752

Epoch: 5| Step: 9
Training loss: 1.1911327838897705
Validation loss: 2.100726678967476

Epoch: 5| Step: 10
Training loss: 1.0555814504623413
Validation loss: 2.1171001344919205

Epoch: 5| Step: 11
Training loss: 1.0635087490081787
Validation loss: 2.111173470815023

Epoch: 129| Step: 0
Training loss: 1.4479459524154663
Validation loss: 2.1066998491684594

Epoch: 5| Step: 1
Training loss: 1.0794757604599
Validation loss: 2.074554363886515

Epoch: 5| Step: 2
Training loss: 0.8417838215827942
Validation loss: 2.080987592538198

Epoch: 5| Step: 3
Training loss: 1.4434750080108643
Validation loss: 2.0370370348294577

Epoch: 5| Step: 4
Training loss: 1.091107964515686
Validation loss: 2.0396290918191275

Epoch: 5| Step: 5
Training loss: 1.687527060508728
Validation loss: 2.0800470213095346

Epoch: 5| Step: 6
Training loss: 1.3361302614212036
Validation loss: 2.0391260335842767

Epoch: 5| Step: 7
Training loss: 1.1200811862945557
Validation loss: 2.065980871518453

Epoch: 5| Step: 8
Training loss: 0.7746464014053345
Validation loss: 2.0611680448055267

Epoch: 5| Step: 9
Training loss: 1.4618613719940186
Validation loss: 2.1061145017544427

Epoch: 5| Step: 10
Training loss: 1.2607039213180542
Validation loss: 2.1846233010292053

Epoch: 5| Step: 11
Training loss: 2.575904369354248
Validation loss: 2.1441334138313928

Epoch: 130| Step: 0
Training loss: 1.503011703491211
Validation loss: 2.1228288412094116

Epoch: 5| Step: 1
Training loss: 1.389960527420044
Validation loss: 2.0893924832344055

Epoch: 5| Step: 2
Training loss: 1.3915599584579468
Validation loss: 2.0466419061024985

Epoch: 5| Step: 3
Training loss: 0.8725849390029907
Validation loss: 2.0008981029192605

Epoch: 5| Step: 4
Training loss: 1.0431767702102661
Validation loss: 2.048985406756401

Epoch: 5| Step: 5
Training loss: 1.2849937677383423
Validation loss: 2.0400171180566153

Epoch: 5| Step: 6
Training loss: 1.4367167949676514
Validation loss: 2.0276446491479874

Epoch: 5| Step: 7
Training loss: 0.9345623254776001
Validation loss: 2.0385779390732446

Epoch: 5| Step: 8
Training loss: 1.60153067111969
Validation loss: 2.0620405077934265

Epoch: 5| Step: 9
Training loss: 1.3291784524917603
Validation loss: 2.1115081906318665

Epoch: 5| Step: 10
Training loss: 1.0999351739883423
Validation loss: 2.0783036649227142

Epoch: 5| Step: 11
Training loss: 1.1398361921310425
Validation loss: 2.1696752409140267

Epoch: 131| Step: 0
Training loss: 1.2735297679901123
Validation loss: 2.174887935320536

Epoch: 5| Step: 1
Training loss: 1.3371576070785522
Validation loss: 2.198711017767588

Epoch: 5| Step: 2
Training loss: 1.397704005241394
Validation loss: 2.121526136994362

Epoch: 5| Step: 3
Training loss: 1.9564138650894165
Validation loss: 2.098607897758484

Epoch: 5| Step: 4
Training loss: 1.2915170192718506
Validation loss: 2.1214869916439056

Epoch: 5| Step: 5
Training loss: 1.0232036113739014
Validation loss: 2.050954202810923

Epoch: 5| Step: 6
Training loss: 0.806086540222168
Validation loss: 2.0409053961435952

Epoch: 5| Step: 7
Training loss: 0.9773972630500793
Validation loss: 2.0713838040828705

Epoch: 5| Step: 8
Training loss: 1.1184905767440796
Validation loss: 2.0512936214605966

Epoch: 5| Step: 9
Training loss: 1.2642838954925537
Validation loss: 2.056293338537216

Epoch: 5| Step: 10
Training loss: 0.9286573529243469
Validation loss: 2.057711879412333

Epoch: 5| Step: 11
Training loss: 1.3889720439910889
Validation loss: 2.095230226715406

Epoch: 132| Step: 0
Training loss: 1.413399338722229
Validation loss: 2.0664309362570443

Epoch: 5| Step: 1
Training loss: 0.4624961018562317
Validation loss: 2.0577306300401688

Epoch: 5| Step: 2
Training loss: 1.4717546701431274
Validation loss: 2.0651758263508477

Epoch: 5| Step: 3
Training loss: 1.533137559890747
Validation loss: 2.0526939034461975

Epoch: 5| Step: 4
Training loss: 1.4512951374053955
Validation loss: 2.04655330379804

Epoch: 5| Step: 5
Training loss: 0.9187353849411011
Validation loss: 2.0332093685865402

Epoch: 5| Step: 6
Training loss: 1.575958013534546
Validation loss: 2.0321906308333078

Epoch: 5| Step: 7
Training loss: 0.974460244178772
Validation loss: 2.0458560635646186

Epoch: 5| Step: 8
Training loss: 1.057969331741333
Validation loss: 2.0544546395540237

Epoch: 5| Step: 9
Training loss: 1.1839642524719238
Validation loss: 2.055889129638672

Epoch: 5| Step: 10
Training loss: 1.2293713092803955
Validation loss: 2.0581553826729455

Epoch: 5| Step: 11
Training loss: 1.1124680042266846
Validation loss: 2.0489396850268045

Epoch: 133| Step: 0
Training loss: 1.6046717166900635
Validation loss: 2.135305350025495

Epoch: 5| Step: 1
Training loss: 1.0623129606246948
Validation loss: 2.1650969088077545

Epoch: 5| Step: 2
Training loss: 1.274542212486267
Validation loss: 2.1478629956642785

Epoch: 5| Step: 3
Training loss: 1.4367969036102295
Validation loss: 2.13123419880867

Epoch: 5| Step: 4
Training loss: 1.2393580675125122
Validation loss: 2.1113700022300086

Epoch: 5| Step: 5
Training loss: 1.4180974960327148
Validation loss: 2.0795998026927314

Epoch: 5| Step: 6
Training loss: 0.9102158546447754
Validation loss: 2.0820393164952598

Epoch: 5| Step: 7
Training loss: 1.11045241355896
Validation loss: 2.050095185637474

Epoch: 5| Step: 8
Training loss: 1.0638210773468018
Validation loss: 2.050447722276052

Epoch: 5| Step: 9
Training loss: 1.2580885887145996
Validation loss: 2.038150737682978

Epoch: 5| Step: 10
Training loss: 0.9700161218643188
Validation loss: 2.1013926217953363

Epoch: 5| Step: 11
Training loss: 0.8368561267852783
Validation loss: 2.0701673924922943

Epoch: 134| Step: 0
Training loss: 1.4117319583892822
Validation loss: 2.1401502390702567

Epoch: 5| Step: 1
Training loss: 1.3304888010025024
Validation loss: 2.1838845908641815

Epoch: 5| Step: 2
Training loss: 1.2978980541229248
Validation loss: 2.2200865944226584

Epoch: 5| Step: 3
Training loss: 1.1473276615142822
Validation loss: 2.215846210718155

Epoch: 5| Step: 4
Training loss: 0.8846861124038696
Validation loss: 2.107487991452217

Epoch: 5| Step: 5
Training loss: 0.7681296467781067
Validation loss: 2.103205606341362

Epoch: 5| Step: 6
Training loss: 1.519611120223999
Validation loss: 2.0650841295719147

Epoch: 5| Step: 7
Training loss: 1.866430640220642
Validation loss: 2.014545902609825

Epoch: 5| Step: 8
Training loss: 0.6722151041030884
Validation loss: 2.0321203718582788

Epoch: 5| Step: 9
Training loss: 1.5186258554458618
Validation loss: 2.055860390265783

Epoch: 5| Step: 10
Training loss: 1.1502736806869507
Validation loss: 2.05234361688296

Epoch: 5| Step: 11
Training loss: 1.3936431407928467
Validation loss: 2.078959107398987

Epoch: 135| Step: 0
Training loss: 0.9968990087509155
Validation loss: 2.117251068353653

Epoch: 5| Step: 1
Training loss: 0.9010220766067505
Validation loss: 2.1100062479575477

Epoch: 5| Step: 2
Training loss: 1.1897947788238525
Validation loss: 2.1641503870487213

Epoch: 5| Step: 3
Training loss: 0.9082626104354858
Validation loss: 2.175523733099302

Epoch: 5| Step: 4
Training loss: 1.670623779296875
Validation loss: 2.1995544830958047

Epoch: 5| Step: 5
Training loss: 1.1893775463104248
Validation loss: 2.107811043659846

Epoch: 5| Step: 6
Training loss: 1.7391681671142578
Validation loss: 2.1297016541163125

Epoch: 5| Step: 7
Training loss: 0.9338122606277466
Validation loss: 2.0451133648554483

Epoch: 5| Step: 8
Training loss: 1.4317156076431274
Validation loss: 2.057575831810633

Epoch: 5| Step: 9
Training loss: 0.655154824256897
Validation loss: 2.0651037146647773

Epoch: 5| Step: 10
Training loss: 1.0611883401870728
Validation loss: 2.1084286123514175

Epoch: 5| Step: 11
Training loss: 0.37806636095046997
Validation loss: 2.0430108308792114

Epoch: 136| Step: 0
Training loss: 1.0311787128448486
Validation loss: 2.0907982687155404

Epoch: 5| Step: 1
Training loss: 1.6897764205932617
Validation loss: 2.089752048254013

Epoch: 5| Step: 2
Training loss: 1.265741229057312
Validation loss: 2.141892910003662

Epoch: 5| Step: 3
Training loss: 0.8429424166679382
Validation loss: 2.153377185265223

Epoch: 5| Step: 4
Training loss: 1.6759498119354248
Validation loss: 2.1532456129789352

Epoch: 5| Step: 5
Training loss: 1.5685664415359497
Validation loss: 2.1740298370520272

Epoch: 5| Step: 6
Training loss: 0.9132930040359497
Validation loss: 2.17724317808946

Epoch: 5| Step: 7
Training loss: 1.0136592388153076
Validation loss: 2.1210751831531525

Epoch: 5| Step: 8
Training loss: 1.0824679136276245
Validation loss: 2.0468558420737586

Epoch: 5| Step: 9
Training loss: 0.9684425592422485
Validation loss: 2.0519685596227646

Epoch: 5| Step: 10
Training loss: 0.7533864378929138
Validation loss: 2.08641425271829

Epoch: 5| Step: 11
Training loss: 0.6428782939910889
Validation loss: 2.1187785317500434

Epoch: 137| Step: 0
Training loss: 1.158353567123413
Validation loss: 2.0639445831378302

Epoch: 5| Step: 1
Training loss: 0.9654325246810913
Validation loss: 2.1142626802126565

Epoch: 5| Step: 2
Training loss: 1.5916857719421387
Validation loss: 2.1675259421269097

Epoch: 5| Step: 3
Training loss: 1.1408660411834717
Validation loss: 2.0983227541049323

Epoch: 5| Step: 4
Training loss: 1.0485517978668213
Validation loss: 2.137855460246404

Epoch: 5| Step: 5
Training loss: 1.0271178483963013
Validation loss: 2.092900256315867

Epoch: 5| Step: 6
Training loss: 1.0681027173995972
Validation loss: 2.0700550576051078

Epoch: 5| Step: 7
Training loss: 1.1958457231521606
Validation loss: 2.100480700532595

Epoch: 5| Step: 8
Training loss: 0.7645114064216614
Validation loss: 2.073359707991282

Epoch: 5| Step: 9
Training loss: 1.2279857397079468
Validation loss: 2.056562766432762

Epoch: 5| Step: 10
Training loss: 1.0879848003387451
Validation loss: 2.0514897952477136

Epoch: 5| Step: 11
Training loss: 1.1579872369766235
Validation loss: 2.072927325963974

Epoch: 138| Step: 0
Training loss: 0.8049463033676147
Validation loss: 2.0870098869005838

Epoch: 5| Step: 1
Training loss: 1.195570707321167
Validation loss: 2.074074332912763

Epoch: 5| Step: 2
Training loss: 1.4507008790969849
Validation loss: 2.093511233727137

Epoch: 5| Step: 3
Training loss: 1.626707673072815
Validation loss: 2.0882437229156494

Epoch: 5| Step: 4
Training loss: 1.16654372215271
Validation loss: 2.0741077959537506

Epoch: 5| Step: 5
Training loss: 0.659398078918457
Validation loss: 2.0875850319862366

Epoch: 5| Step: 6
Training loss: 1.3726260662078857
Validation loss: 2.0651777734359107

Epoch: 5| Step: 7
Training loss: 0.7862556576728821
Validation loss: 2.084194933374723

Epoch: 5| Step: 8
Training loss: 0.9398430585861206
Validation loss: 2.0972824742396674

Epoch: 5| Step: 9
Training loss: 1.3712549209594727
Validation loss: 2.144791771968206

Epoch: 5| Step: 10
Training loss: 0.8332660794258118
Validation loss: 2.1661718686421714

Epoch: 5| Step: 11
Training loss: 0.6947263479232788
Validation loss: 2.183336486419042

Epoch: 139| Step: 0
Training loss: 0.9882875680923462
Validation loss: 2.1962203631798425

Epoch: 5| Step: 1
Training loss: 1.3561619520187378
Validation loss: 2.2847692370414734

Epoch: 5| Step: 2
Training loss: 1.1009697914123535
Validation loss: 2.228777269522349

Epoch: 5| Step: 3
Training loss: 1.2345149517059326
Validation loss: 2.1423578759034476

Epoch: 5| Step: 4
Training loss: 1.6812264919281006
Validation loss: 2.097885320583979

Epoch: 5| Step: 5
Training loss: 1.1891772747039795
Validation loss: 2.0953350563844046

Epoch: 5| Step: 6
Training loss: 1.684382677078247
Validation loss: 2.088716834783554

Epoch: 5| Step: 7
Training loss: 1.6071618795394897
Validation loss: 2.0159110029538474

Epoch: 5| Step: 8
Training loss: 0.9813474416732788
Validation loss: 2.0432216028372445

Epoch: 5| Step: 9
Training loss: 1.0642884969711304
Validation loss: 2.1067378520965576

Epoch: 5| Step: 10
Training loss: 0.7617437243461609
Validation loss: 2.0943922946850457

Epoch: 5| Step: 11
Training loss: 0.9157817363739014
Validation loss: 2.09955965479215

Epoch: 140| Step: 0
Training loss: 0.7946918606758118
Validation loss: 2.1066588858763375

Epoch: 5| Step: 1
Training loss: 1.3155033588409424
Validation loss: 2.2380604644616446

Epoch: 5| Step: 2
Training loss: 1.6587833166122437
Validation loss: 2.1903378715117774

Epoch: 5| Step: 3
Training loss: 1.2869541645050049
Validation loss: 2.2160093088944754

Epoch: 5| Step: 4
Training loss: 1.507003664970398
Validation loss: 2.1627312997976937

Epoch: 5| Step: 5
Training loss: 0.7247062921524048
Validation loss: 2.1437473595142365

Epoch: 5| Step: 6
Training loss: 1.018206000328064
Validation loss: 2.0702197502056756

Epoch: 5| Step: 7
Training loss: 1.0311213731765747
Validation loss: 2.045132358868917

Epoch: 5| Step: 8
Training loss: 1.6012500524520874
Validation loss: 2.0412222295999527

Epoch: 5| Step: 9
Training loss: 1.096224069595337
Validation loss: 2.0545442700386047

Epoch: 5| Step: 10
Training loss: 1.36898672580719
Validation loss: 2.0610584119955697

Epoch: 5| Step: 11
Training loss: 1.6996715068817139
Validation loss: 2.1129651417334876

Epoch: 141| Step: 0
Training loss: 0.666965126991272
Validation loss: 2.023518999417623

Epoch: 5| Step: 1
Training loss: 1.1677541732788086
Validation loss: 2.0560409277677536

Epoch: 5| Step: 2
Training loss: 1.492387056350708
Validation loss: 2.054598276813825

Epoch: 5| Step: 3
Training loss: 0.8611456751823425
Validation loss: 2.117334306240082

Epoch: 5| Step: 4
Training loss: 1.1559810638427734
Validation loss: 2.1230888615051904

Epoch: 5| Step: 5
Training loss: 1.1900895833969116
Validation loss: 2.1043763359387717

Epoch: 5| Step: 6
Training loss: 0.5262304544448853
Validation loss: 2.111753841241201

Epoch: 5| Step: 7
Training loss: 0.9499880075454712
Validation loss: 2.0739456613858542

Epoch: 5| Step: 8
Training loss: 1.6336686611175537
Validation loss: 2.1150885621706643

Epoch: 5| Step: 9
Training loss: 1.4030108451843262
Validation loss: 2.1153114835421243

Epoch: 5| Step: 10
Training loss: 0.782353401184082
Validation loss: 2.1493232746918998

Epoch: 5| Step: 11
Training loss: 0.7474812269210815
Validation loss: 2.078809231519699

Epoch: 142| Step: 0
Training loss: 0.8905499577522278
Validation loss: 2.1341897547245026

Epoch: 5| Step: 1
Training loss: 0.9085633158683777
Validation loss: 2.1445402055978775

Epoch: 5| Step: 2
Training loss: 1.1716073751449585
Validation loss: 2.151421700914701

Epoch: 5| Step: 3
Training loss: 1.1219823360443115
Validation loss: 2.090248386065165

Epoch: 5| Step: 4
Training loss: 1.5353128910064697
Validation loss: 2.0783910751342773

Epoch: 5| Step: 5
Training loss: 0.9345132112503052
Validation loss: 2.0910099297761917

Epoch: 5| Step: 6
Training loss: 1.1094661951065063
Validation loss: 2.1041197925806046

Epoch: 5| Step: 7
Training loss: 1.2981414794921875
Validation loss: 2.1084702809651694

Epoch: 5| Step: 8
Training loss: 1.2138285636901855
Validation loss: 2.116034135222435

Epoch: 5| Step: 9
Training loss: 0.7079148292541504
Validation loss: 2.1315434873104095

Epoch: 5| Step: 10
Training loss: 1.030491590499878
Validation loss: 2.1046391278505325

Epoch: 5| Step: 11
Training loss: 0.5062276124954224
Validation loss: 2.110743224620819

Epoch: 143| Step: 0
Training loss: 1.0306041240692139
Validation loss: 2.2388035307327905

Epoch: 5| Step: 1
Training loss: 1.4838933944702148
Validation loss: 2.246703346570333

Epoch: 5| Step: 2
Training loss: 1.6124255657196045
Validation loss: 2.2372090419133506

Epoch: 5| Step: 3
Training loss: 0.8766530752182007
Validation loss: 2.173708220322927

Epoch: 5| Step: 4
Training loss: 0.6628144383430481
Validation loss: 2.141699438293775

Epoch: 5| Step: 5
Training loss: 1.0125901699066162
Validation loss: 2.1473893572886786

Epoch: 5| Step: 6
Training loss: 1.2517608404159546
Validation loss: 2.0413745443026223

Epoch: 5| Step: 7
Training loss: 1.094779133796692
Validation loss: 2.0471978237231574

Epoch: 5| Step: 8
Training loss: 0.9036090970039368
Validation loss: 2.102789451678594

Epoch: 5| Step: 9
Training loss: 1.0750731229782104
Validation loss: 2.045617481072744

Epoch: 5| Step: 10
Training loss: 1.1779334545135498
Validation loss: 2.090507651368777

Epoch: 5| Step: 11
Training loss: 0.7728441953659058
Validation loss: 2.082777554790179

Epoch: 144| Step: 0
Training loss: 0.904682993888855
Validation loss: 2.1106008291244507

Epoch: 5| Step: 1
Training loss: 1.2703063488006592
Validation loss: 2.1401953299840293

Epoch: 5| Step: 2
Training loss: 1.235342025756836
Validation loss: 2.100472872455915

Epoch: 5| Step: 3
Training loss: 0.739937424659729
Validation loss: 2.1145375470320382

Epoch: 5| Step: 4
Training loss: 1.2252333164215088
Validation loss: 2.084965333342552

Epoch: 5| Step: 5
Training loss: 1.3286550045013428
Validation loss: 2.1064060777425766

Epoch: 5| Step: 6
Training loss: 0.9035142660140991
Validation loss: 2.073417916893959

Epoch: 5| Step: 7
Training loss: 1.032517671585083
Validation loss: 2.041861832141876

Epoch: 5| Step: 8
Training loss: 0.9953228235244751
Validation loss: 2.1101375073194504

Epoch: 5| Step: 9
Training loss: 0.8152155876159668
Validation loss: 2.0380484064420066

Epoch: 5| Step: 10
Training loss: 1.1514339447021484
Validation loss: 2.0799962679545083

Epoch: 5| Step: 11
Training loss: 1.0755009651184082
Validation loss: 2.0681707163651786

Epoch: 145| Step: 0
Training loss: 0.9111361503601074
Validation loss: 2.0589628467957177

Epoch: 5| Step: 1
Training loss: 0.9818896055221558
Validation loss: 2.0697137266397476

Epoch: 5| Step: 2
Training loss: 0.8935204744338989
Validation loss: 2.1007355550924935

Epoch: 5| Step: 3
Training loss: 0.9480913281440735
Validation loss: 2.0991012106339135

Epoch: 5| Step: 4
Training loss: 1.2832838296890259
Validation loss: 2.1190105428298316

Epoch: 5| Step: 5
Training loss: 0.9658296704292297
Validation loss: 2.160563051700592

Epoch: 5| Step: 6
Training loss: 1.0392926931381226
Validation loss: 2.1273186703523

Epoch: 5| Step: 7
Training loss: 1.093148112297058
Validation loss: 2.1267605870962143

Epoch: 5| Step: 8
Training loss: 1.1587107181549072
Validation loss: 2.134515662988027

Epoch: 5| Step: 9
Training loss: 1.0789300203323364
Validation loss: 2.190051486094793

Epoch: 5| Step: 10
Training loss: 1.1689337491989136
Validation loss: 2.1322003255287805

Epoch: 5| Step: 11
Training loss: 0.6364077925682068
Validation loss: 2.1384826600551605

Epoch: 146| Step: 0
Training loss: 1.0302903652191162
Validation loss: 2.1558682372172675

Epoch: 5| Step: 1
Training loss: 1.4731125831604004
Validation loss: 2.0802359680334725

Epoch: 5| Step: 2
Training loss: 0.48687776923179626
Validation loss: 2.1792662342389426

Epoch: 5| Step: 3
Training loss: 1.0470441579818726
Validation loss: 2.096725141008695

Epoch: 5| Step: 4
Training loss: 0.9367793202400208
Validation loss: 2.0803537468115487

Epoch: 5| Step: 5
Training loss: 1.2676793336868286
Validation loss: 2.150538851817449

Epoch: 5| Step: 6
Training loss: 0.8180540204048157
Validation loss: 2.1303228636582694

Epoch: 5| Step: 7
Training loss: 0.4607551693916321
Validation loss: 2.152943084637324

Epoch: 5| Step: 8
Training loss: 1.2927501201629639
Validation loss: 2.151427999138832

Epoch: 5| Step: 9
Training loss: 1.1935338973999023
Validation loss: 2.1495202581087747

Epoch: 5| Step: 10
Training loss: 1.0997869968414307
Validation loss: 2.111726979414622

Epoch: 5| Step: 11
Training loss: 0.6317406892776489
Validation loss: 2.0978074769179025

Epoch: 147| Step: 0
Training loss: 1.2386698722839355
Validation loss: 2.1147116174300513

Epoch: 5| Step: 1
Training loss: 1.0079773664474487
Validation loss: 2.130068322022756

Epoch: 5| Step: 2
Training loss: 0.6780881881713867
Validation loss: 2.116161232193311

Epoch: 5| Step: 3
Training loss: 1.3267320394515991
Validation loss: 2.142816270391146

Epoch: 5| Step: 4
Training loss: 0.9950448274612427
Validation loss: 2.106526086727778

Epoch: 5| Step: 5
Training loss: 1.0559203624725342
Validation loss: 2.1150964250167212

Epoch: 5| Step: 6
Training loss: 1.5683923959732056
Validation loss: 2.077020506064097

Epoch: 5| Step: 7
Training loss: 0.9333158731460571
Validation loss: 2.0997100472450256

Epoch: 5| Step: 8
Training loss: 0.8337984085083008
Validation loss: 2.1164150337378183

Epoch: 5| Step: 9
Training loss: 0.8600183725357056
Validation loss: 2.0886273731788

Epoch: 5| Step: 10
Training loss: 0.951310932636261
Validation loss: 2.0914131651322045

Epoch: 5| Step: 11
Training loss: 1.6134822368621826
Validation loss: 2.1349048415819802

Epoch: 148| Step: 0
Training loss: 0.7551604509353638
Validation loss: 2.142263556520144

Epoch: 5| Step: 1
Training loss: 0.947239875793457
Validation loss: 2.082049091657003

Epoch: 5| Step: 2
Training loss: 0.7155822515487671
Validation loss: 2.099147414167722

Epoch: 5| Step: 3
Training loss: 1.287310242652893
Validation loss: 2.1264567027489343

Epoch: 5| Step: 4
Training loss: 0.5281602740287781
Validation loss: 2.165841390689214

Epoch: 5| Step: 5
Training loss: 1.093743085861206
Validation loss: 2.0951636085907617

Epoch: 5| Step: 6
Training loss: 0.8666871190071106
Validation loss: 2.0907470881938934

Epoch: 5| Step: 7
Training loss: 0.9120961427688599
Validation loss: 2.066134989261627

Epoch: 5| Step: 8
Training loss: 1.1600925922393799
Validation loss: 2.080855463941892

Epoch: 5| Step: 9
Training loss: 1.41228449344635
Validation loss: 2.043792496124903

Epoch: 5| Step: 10
Training loss: 1.4407175779342651
Validation loss: 2.0499174495538077

Epoch: 5| Step: 11
Training loss: 0.1924036741256714
Validation loss: 2.104573746522268

Epoch: 149| Step: 0
Training loss: 0.7639456391334534
Validation loss: 2.0612564086914062

Epoch: 5| Step: 1
Training loss: 1.3267910480499268
Validation loss: 2.09188782175382

Epoch: 5| Step: 2
Training loss: 0.6475439071655273
Validation loss: 2.110614001750946

Epoch: 5| Step: 3
Training loss: 1.2504384517669678
Validation loss: 2.1275465389092765

Epoch: 5| Step: 4
Training loss: 0.8719045519828796
Validation loss: 2.1146720747152963

Epoch: 5| Step: 5
Training loss: 0.9288396835327148
Validation loss: 2.141464347640673

Epoch: 5| Step: 6
Training loss: 0.7249091267585754
Validation loss: 2.1102539201577506

Epoch: 5| Step: 7
Training loss: 0.8321927785873413
Validation loss: 2.1490481992562613

Epoch: 5| Step: 8
Training loss: 1.0921846628189087
Validation loss: 2.108478009700775

Epoch: 5| Step: 9
Training loss: 0.9637470245361328
Validation loss: 2.128826076785723

Epoch: 5| Step: 10
Training loss: 1.325465202331543
Validation loss: 2.088845431804657

Epoch: 5| Step: 11
Training loss: 0.9163780212402344
Validation loss: 2.1475390692551932

Epoch: 150| Step: 0
Training loss: 1.0006924867630005
Validation loss: 2.127140775322914

Epoch: 5| Step: 1
Training loss: 0.9727194905281067
Validation loss: 2.1204186926285424

Epoch: 5| Step: 2
Training loss: 0.8245494961738586
Validation loss: 2.143905907869339

Epoch: 5| Step: 3
Training loss: 1.2261170148849487
Validation loss: 2.1096673558155694

Epoch: 5| Step: 4
Training loss: 0.8356156349182129
Validation loss: 2.102945253252983

Epoch: 5| Step: 5
Training loss: 0.8800506591796875
Validation loss: 2.069291189312935

Epoch: 5| Step: 6
Training loss: 1.1092485189437866
Validation loss: 2.0872711837291718

Epoch: 5| Step: 7
Training loss: 0.7765368223190308
Validation loss: 2.1686887592077255

Epoch: 5| Step: 8
Training loss: 0.7821176648139954
Validation loss: 2.1818784226973853

Epoch: 5| Step: 9
Training loss: 1.2580002546310425
Validation loss: 2.1616627871990204

Epoch: 5| Step: 10
Training loss: 1.2018239498138428
Validation loss: 2.165241986513138

Epoch: 5| Step: 11
Training loss: 1.6791731119155884
Validation loss: 2.078794384996096

Epoch: 151| Step: 0
Training loss: 0.9273015856742859
Validation loss: 2.106680149833361

Epoch: 5| Step: 1
Training loss: 1.1115347146987915
Validation loss: 2.045957257350286

Epoch: 5| Step: 2
Training loss: 1.0365872383117676
Validation loss: 2.0710705121358237

Epoch: 5| Step: 3
Training loss: 0.726028323173523
Validation loss: 2.0658322274684906

Epoch: 5| Step: 4
Training loss: 1.1407506465911865
Validation loss: 2.0631679197152457

Epoch: 5| Step: 5
Training loss: 1.0606307983398438
Validation loss: 2.08737480143706

Epoch: 5| Step: 6
Training loss: 0.8603178858757019
Validation loss: 2.1252825210491815

Epoch: 5| Step: 7
Training loss: 0.710953414440155
Validation loss: 2.1131343940893808

Epoch: 5| Step: 8
Training loss: 1.2380473613739014
Validation loss: 2.1540616105000177

Epoch: 5| Step: 9
Training loss: 1.2893028259277344
Validation loss: 2.1137727995713553

Epoch: 5| Step: 10
Training loss: 0.869345486164093
Validation loss: 2.135775273044904

Epoch: 5| Step: 11
Training loss: 1.365476131439209
Validation loss: 2.1008411745230355

Epoch: 152| Step: 0
Training loss: 0.932197093963623
Validation loss: 2.080667555332184

Epoch: 5| Step: 1
Training loss: 0.7370007038116455
Validation loss: 2.1054864625136056

Epoch: 5| Step: 2
Training loss: 0.9078728556632996
Validation loss: 2.0840784311294556

Epoch: 5| Step: 3
Training loss: 1.0489373207092285
Validation loss: 2.099513923128446

Epoch: 5| Step: 4
Training loss: 1.0985676050186157
Validation loss: 2.0670938144127526

Epoch: 5| Step: 5
Training loss: 1.3229955434799194
Validation loss: 2.126419256130854

Epoch: 5| Step: 6
Training loss: 1.1259245872497559
Validation loss: 2.0890369613965354

Epoch: 5| Step: 7
Training loss: 0.5473202466964722
Validation loss: 2.1301887929439545

Epoch: 5| Step: 8
Training loss: 1.1741517782211304
Validation loss: 2.108020688096682

Epoch: 5| Step: 9
Training loss: 1.260252594947815
Validation loss: 2.073187609513601

Epoch: 5| Step: 10
Training loss: 0.6465871930122375
Validation loss: 2.108145738641421

Epoch: 5| Step: 11
Training loss: 1.2279728651046753
Validation loss: 2.147374302148819

Epoch: 153| Step: 0
Training loss: 0.7283526659011841
Validation loss: 2.136901319026947

Epoch: 5| Step: 1
Training loss: 1.2756805419921875
Validation loss: 2.1761158605416617

Epoch: 5| Step: 2
Training loss: 1.1487873792648315
Validation loss: 2.174209251999855

Epoch: 5| Step: 3
Training loss: 0.6716586947441101
Validation loss: 2.092249567310015

Epoch: 5| Step: 4
Training loss: 0.8117227554321289
Validation loss: 2.070814554889997

Epoch: 5| Step: 5
Training loss: 1.1838756799697876
Validation loss: 2.080947404106458

Epoch: 5| Step: 6
Training loss: 0.6475772857666016
Validation loss: 2.108604282140732

Epoch: 5| Step: 7
Training loss: 1.0936975479125977
Validation loss: 2.0979760736227036

Epoch: 5| Step: 8
Training loss: 1.1765871047973633
Validation loss: 2.1234233379364014

Epoch: 5| Step: 9
Training loss: 1.2124983072280884
Validation loss: 2.1590469032526016

Epoch: 5| Step: 10
Training loss: 0.7617872357368469
Validation loss: 2.12077197432518

Epoch: 5| Step: 11
Training loss: 0.9286812543869019
Validation loss: 2.0805197904507318

Epoch: 154| Step: 0
Training loss: 1.3009836673736572
Validation loss: 2.1161717772483826

Epoch: 5| Step: 1
Training loss: 0.8516627550125122
Validation loss: 2.1819436997175217

Epoch: 5| Step: 2
Training loss: 0.7391639947891235
Validation loss: 2.136530081431071

Epoch: 5| Step: 3
Training loss: 1.0725702047348022
Validation loss: 2.1570491890112558

Epoch: 5| Step: 4
Training loss: 0.7219399213790894
Validation loss: 2.100007340312004

Epoch: 5| Step: 5
Training loss: 1.0080407857894897
Validation loss: 2.1819230814774833

Epoch: 5| Step: 6
Training loss: 0.8492439389228821
Validation loss: 2.115335385004679

Epoch: 5| Step: 7
Training loss: 0.8996014595031738
Validation loss: 2.1287391235431037

Epoch: 5| Step: 8
Training loss: 1.0986461639404297
Validation loss: 2.0776678969462714

Epoch: 5| Step: 9
Training loss: 1.148254156112671
Validation loss: 2.1316214402516684

Epoch: 5| Step: 10
Training loss: 0.5976463556289673
Validation loss: 2.1301520466804504

Epoch: 5| Step: 11
Training loss: 0.8412180542945862
Validation loss: 2.1203938672939935

Epoch: 155| Step: 0
Training loss: 0.5756572484970093
Validation loss: 2.2035311261812844

Epoch: 5| Step: 1
Training loss: 1.677930474281311
Validation loss: 2.21844012538592

Epoch: 5| Step: 2
Training loss: 1.0491844415664673
Validation loss: 2.1190224240223565

Epoch: 5| Step: 3
Training loss: 0.9283410906791687
Validation loss: 2.165232499440511

Epoch: 5| Step: 4
Training loss: 1.0108094215393066
Validation loss: 2.1053796907265983

Epoch: 5| Step: 5
Training loss: 0.8833643198013306
Validation loss: 2.117317924896876

Epoch: 5| Step: 6
Training loss: 0.9035089612007141
Validation loss: 2.1188406397898993

Epoch: 5| Step: 7
Training loss: 0.5810696482658386
Validation loss: 2.1491855482260385

Epoch: 5| Step: 8
Training loss: 0.740858256816864
Validation loss: 2.1495371560255685

Epoch: 5| Step: 9
Training loss: 1.1222245693206787
Validation loss: 2.159870887796084

Epoch: 5| Step: 10
Training loss: 1.284656286239624
Validation loss: 2.181049883365631

Epoch: 5| Step: 11
Training loss: 0.5094788074493408
Validation loss: 2.187661459048589

Epoch: 156| Step: 0
Training loss: 1.2537082433700562
Validation loss: 2.1849458465973535

Epoch: 5| Step: 1
Training loss: 1.0711108446121216
Validation loss: 2.1535979509353638

Epoch: 5| Step: 2
Training loss: 0.6449626684188843
Validation loss: 2.0923676093419394

Epoch: 5| Step: 3
Training loss: 0.8479019999504089
Validation loss: 2.033728505174319

Epoch: 5| Step: 4
Training loss: 1.3158161640167236
Validation loss: 2.0394983688990274

Epoch: 5| Step: 5
Training loss: 1.184936761856079
Validation loss: 2.03533403078715

Epoch: 5| Step: 6
Training loss: 0.9694802165031433
Validation loss: 1.9692187557617824

Epoch: 5| Step: 7
Training loss: 1.0003612041473389
Validation loss: 2.080618808666865

Epoch: 5| Step: 8
Training loss: 0.9325984716415405
Validation loss: 2.082343176007271

Epoch: 5| Step: 9
Training loss: 0.7580772638320923
Validation loss: 2.0827067494392395

Epoch: 5| Step: 10
Training loss: 0.8686326742172241
Validation loss: 2.168856913844744

Epoch: 5| Step: 11
Training loss: 0.9102096557617188
Validation loss: 2.1768660147984824

Epoch: 157| Step: 0
Training loss: 1.0490792989730835
Validation loss: 2.1553696393966675

Epoch: 5| Step: 1
Training loss: 0.4331742823123932
Validation loss: 2.157933235168457

Epoch: 5| Step: 2
Training loss: 0.8885305523872375
Validation loss: 2.084809362888336

Epoch: 5| Step: 3
Training loss: 1.0023213624954224
Validation loss: 2.0694164435068765

Epoch: 5| Step: 4
Training loss: 1.1861566305160522
Validation loss: 2.041771719853083

Epoch: 5| Step: 5
Training loss: 0.9583030939102173
Validation loss: 2.053323522210121

Epoch: 5| Step: 6
Training loss: 1.1206251382827759
Validation loss: 2.052000174919764

Epoch: 5| Step: 7
Training loss: 1.148285150527954
Validation loss: 2.07836377620697

Epoch: 5| Step: 8
Training loss: 1.0869969129562378
Validation loss: 2.1619962602853775

Epoch: 5| Step: 9
Training loss: 0.5727658271789551
Validation loss: 2.1087103535731635

Epoch: 5| Step: 10
Training loss: 1.0939632654190063
Validation loss: 2.1089269568522773

Epoch: 5| Step: 11
Training loss: 0.759648323059082
Validation loss: 2.142201075951258

Epoch: 158| Step: 0
Training loss: 0.9715856313705444
Validation loss: 2.062018076578776

Epoch: 5| Step: 1
Training loss: 0.8566561937332153
Validation loss: 2.093215505282084

Epoch: 5| Step: 2
Training loss: 0.6248507499694824
Validation loss: 2.0457935680945716

Epoch: 5| Step: 3
Training loss: 0.5366919636726379
Validation loss: 2.0396009584267936

Epoch: 5| Step: 4
Training loss: 0.979698657989502
Validation loss: 2.0532804181178412

Epoch: 5| Step: 5
Training loss: 0.9567340016365051
Validation loss: 2.086390351255735

Epoch: 5| Step: 6
Training loss: 0.7679494619369507
Validation loss: 2.147603839635849

Epoch: 5| Step: 7
Training loss: 1.6135438680648804
Validation loss: 2.1287781099478402

Epoch: 5| Step: 8
Training loss: 1.0657585859298706
Validation loss: 2.1545919676621756

Epoch: 5| Step: 9
Training loss: 0.966991126537323
Validation loss: 2.107077638308207

Epoch: 5| Step: 10
Training loss: 0.7983757853507996
Validation loss: 2.1698594937721887

Epoch: 5| Step: 11
Training loss: 1.6786277294158936
Validation loss: 2.098030765851339

Epoch: 159| Step: 0
Training loss: 0.9659303426742554
Validation loss: 2.1244779278834662

Epoch: 5| Step: 1
Training loss: 0.9753447771072388
Validation loss: 2.04558136065801

Epoch: 5| Step: 2
Training loss: 1.4699658155441284
Validation loss: 2.0475436647733054

Epoch: 5| Step: 3
Training loss: 0.5420035719871521
Validation loss: 2.0622520744800568

Epoch: 5| Step: 4
Training loss: 0.7906848192214966
Validation loss: 2.129890446861585

Epoch: 5| Step: 5
Training loss: 1.1808931827545166
Validation loss: 2.099225401878357

Epoch: 5| Step: 6
Training loss: 0.7066887021064758
Validation loss: 2.0857705026865005

Epoch: 5| Step: 7
Training loss: 0.9556882977485657
Validation loss: 2.1156332790851593

Epoch: 5| Step: 8
Training loss: 0.7046852111816406
Validation loss: 2.2128565311431885

Epoch: 5| Step: 9
Training loss: 1.1048202514648438
Validation loss: 2.202252055207888

Epoch: 5| Step: 10
Training loss: 1.015131950378418
Validation loss: 2.1614223619302115

Epoch: 5| Step: 11
Training loss: 0.352899432182312
Validation loss: 2.1455071518818536

Epoch: 160| Step: 0
Training loss: 0.9432209730148315
Validation loss: 2.1072006225585938

Epoch: 5| Step: 1
Training loss: 0.7823184728622437
Validation loss: 2.1082950035730996

Epoch: 5| Step: 2
Training loss: 1.4170148372650146
Validation loss: 2.0704924960931144

Epoch: 5| Step: 3
Training loss: 1.0696022510528564
Validation loss: 2.101155608892441

Epoch: 5| Step: 4
Training loss: 0.8630523681640625
Validation loss: 2.034314418832461

Epoch: 5| Step: 5
Training loss: 0.8202530741691589
Validation loss: 2.0898613184690475

Epoch: 5| Step: 6
Training loss: 0.8966755867004395
Validation loss: 2.093256081144015

Epoch: 5| Step: 7
Training loss: 0.43493756651878357
Validation loss: 2.134432683388392

Epoch: 5| Step: 8
Training loss: 0.5519503355026245
Validation loss: 2.125807190934817

Epoch: 5| Step: 9
Training loss: 0.8202564120292664
Validation loss: 2.1408999611934028

Epoch: 5| Step: 10
Training loss: 0.7460182309150696
Validation loss: 2.0802479833364487

Epoch: 5| Step: 11
Training loss: 1.4481289386749268
Validation loss: 2.150514225165049

Epoch: 161| Step: 0
Training loss: 1.5687663555145264
Validation loss: 2.113300601641337

Epoch: 5| Step: 1
Training loss: 1.0267356634140015
Validation loss: 2.1202808916568756

Epoch: 5| Step: 2
Training loss: 0.5037578344345093
Validation loss: 2.0881138294935226

Epoch: 5| Step: 3
Training loss: 1.535828948020935
Validation loss: 2.047628333171209

Epoch: 5| Step: 4
Training loss: 0.9511052370071411
Validation loss: 2.022999515136083

Epoch: 5| Step: 5
Training loss: 0.6410920023918152
Validation loss: 2.099018394947052

Epoch: 5| Step: 6
Training loss: 0.6309436559677124
Validation loss: 2.09655599296093

Epoch: 5| Step: 7
Training loss: 0.7911270260810852
Validation loss: 2.0796215583880744

Epoch: 5| Step: 8
Training loss: 0.4108096957206726
Validation loss: 2.135126143693924

Epoch: 5| Step: 9
Training loss: 0.8075979351997375
Validation loss: 2.147779698173205

Epoch: 5| Step: 10
Training loss: 1.0948668718338013
Validation loss: 2.2084714819987616

Epoch: 5| Step: 11
Training loss: 0.8464441299438477
Validation loss: 2.184573377172152

Epoch: 162| Step: 0
Training loss: 0.7539979815483093
Validation loss: 2.111358498533567

Epoch: 5| Step: 1
Training loss: 0.4779544770717621
Validation loss: 2.14659990866979

Epoch: 5| Step: 2
Training loss: 1.545083999633789
Validation loss: 2.0830305020014444

Epoch: 5| Step: 3
Training loss: 1.0954267978668213
Validation loss: 2.0932682851950326

Epoch: 5| Step: 4
Training loss: 0.9396769404411316
Validation loss: 2.1295070499181747

Epoch: 5| Step: 5
Training loss: 1.178038477897644
Validation loss: 2.144784231980642

Epoch: 5| Step: 6
Training loss: 0.7490324974060059
Validation loss: 2.184500222404798

Epoch: 5| Step: 7
Training loss: 0.7714672088623047
Validation loss: 2.144546464085579

Epoch: 5| Step: 8
Training loss: 1.0439307689666748
Validation loss: 2.1633799771467843

Epoch: 5| Step: 9
Training loss: 0.5407942533493042
Validation loss: 2.268548548221588

Epoch: 5| Step: 10
Training loss: 0.9794338345527649
Validation loss: 2.224805081884066

Epoch: 5| Step: 11
Training loss: 1.3553465604782104
Validation loss: 2.2035434742768607

Epoch: 163| Step: 0
Training loss: 0.601812481880188
Validation loss: 2.148106500506401

Epoch: 5| Step: 1
Training loss: 1.0306662321090698
Validation loss: 2.087250679731369

Epoch: 5| Step: 2
Training loss: 0.5661693811416626
Validation loss: 2.1346537371476493

Epoch: 5| Step: 3
Training loss: 0.7353938221931458
Validation loss: 2.106878767410914

Epoch: 5| Step: 4
Training loss: 1.2451541423797607
Validation loss: 2.1071736365556717

Epoch: 5| Step: 5
Training loss: 0.7989989519119263
Validation loss: 2.1244382013877234

Epoch: 5| Step: 6
Training loss: 1.1836731433868408
Validation loss: 2.0852257907390594

Epoch: 5| Step: 7
Training loss: 1.4103014469146729
Validation loss: 2.163811892271042

Epoch: 5| Step: 8
Training loss: 0.9346068501472473
Validation loss: 2.209949860970179

Epoch: 5| Step: 9
Training loss: 0.7824100255966187
Validation loss: 2.219682216644287

Epoch: 5| Step: 10
Training loss: 1.4193766117095947
Validation loss: 2.191021059950193

Epoch: 5| Step: 11
Training loss: 0.09760785102844238
Validation loss: 2.1093665063381195

Epoch: 164| Step: 0
Training loss: 1.0488486289978027
Validation loss: 2.1085900415976844

Epoch: 5| Step: 1
Training loss: 0.6012455224990845
Validation loss: 2.0940431157747903

Epoch: 5| Step: 2
Training loss: 0.8949838876724243
Validation loss: 2.115591978033384

Epoch: 5| Step: 3
Training loss: 0.9279969930648804
Validation loss: 2.0590114692846933

Epoch: 5| Step: 4
Training loss: 0.7136120796203613
Validation loss: 2.082550515731176

Epoch: 5| Step: 5
Training loss: 0.981673538684845
Validation loss: 2.060261676708857

Epoch: 5| Step: 6
Training loss: 0.9619600176811218
Validation loss: 2.135073115428289

Epoch: 5| Step: 7
Training loss: 0.5919319987297058
Validation loss: 2.1082671880722046

Epoch: 5| Step: 8
Training loss: 0.8113577961921692
Validation loss: 2.1611416339874268

Epoch: 5| Step: 9
Training loss: 1.0777533054351807
Validation loss: 2.162674367427826

Epoch: 5| Step: 10
Training loss: 1.169830560684204
Validation loss: 2.1744162241617837

Epoch: 5| Step: 11
Training loss: 0.407575786113739
Validation loss: 2.238502010703087

Epoch: 165| Step: 0
Training loss: 0.8544944524765015
Validation loss: 2.145313416918119

Epoch: 5| Step: 1
Training loss: 0.8050282597541809
Validation loss: 2.2360015163818994

Epoch: 5| Step: 2
Training loss: 1.5625522136688232
Validation loss: 2.206598401069641

Epoch: 5| Step: 3
Training loss: 1.2338908910751343
Validation loss: 2.1360786308844886

Epoch: 5| Step: 4
Training loss: 0.9425638318061829
Validation loss: 2.1249676644802094

Epoch: 5| Step: 5
Training loss: 0.729805588722229
Validation loss: 2.1637765864531198

Epoch: 5| Step: 6
Training loss: 0.8810809850692749
Validation loss: 2.1518247574567795

Epoch: 5| Step: 7
Training loss: 0.49663764238357544
Validation loss: 2.1227053652207055

Epoch: 5| Step: 8
Training loss: 0.7200061082839966
Validation loss: 2.0836557348569236

Epoch: 5| Step: 9
Training loss: 1.0117419958114624
Validation loss: 2.1467156261205673

Epoch: 5| Step: 10
Training loss: 0.6842879056930542
Validation loss: 2.1650341947873435

Epoch: 5| Step: 11
Training loss: 0.8939194679260254
Validation loss: 2.206372171640396

Epoch: 166| Step: 0
Training loss: 1.1579822301864624
Validation loss: 2.217919280131658

Epoch: 5| Step: 1
Training loss: 0.605187714099884
Validation loss: 2.296177710096041

Epoch: 5| Step: 2
Training loss: 1.0344078540802002
Validation loss: 2.1634137332439423

Epoch: 5| Step: 3
Training loss: 0.7348217964172363
Validation loss: 2.1063750932614007

Epoch: 5| Step: 4
Training loss: 0.8920788764953613
Validation loss: 2.1089529941479364

Epoch: 5| Step: 5
Training loss: 0.8382129669189453
Validation loss: 2.120010574658712

Epoch: 5| Step: 6
Training loss: 1.1591979265213013
Validation loss: 2.0729065040747323

Epoch: 5| Step: 7
Training loss: 1.0820868015289307
Validation loss: 2.099621911843618

Epoch: 5| Step: 8
Training loss: 0.6703283786773682
Validation loss: 2.1492190659046173

Epoch: 5| Step: 9
Training loss: 0.565893292427063
Validation loss: 2.1449042558670044

Epoch: 5| Step: 10
Training loss: 0.9342994689941406
Validation loss: 2.204919377962748

Epoch: 5| Step: 11
Training loss: 0.6680928468704224
Validation loss: 2.2581160366535187

Epoch: 167| Step: 0
Training loss: 1.2506763935089111
Validation loss: 2.266751686731974

Epoch: 5| Step: 1
Training loss: 1.193928599357605
Validation loss: 2.278656264146169

Epoch: 5| Step: 2
Training loss: 0.7417306900024414
Validation loss: 2.2431085308392844

Epoch: 5| Step: 3
Training loss: 0.6208318471908569
Validation loss: 2.185343916217486

Epoch: 5| Step: 4
Training loss: 1.2990550994873047
Validation loss: 2.1351485004027686

Epoch: 5| Step: 5
Training loss: 0.6243265867233276
Validation loss: 2.1074762443701425

Epoch: 5| Step: 6
Training loss: 0.7669556140899658
Validation loss: 2.0779347320397696

Epoch: 5| Step: 7
Training loss: 0.7871651649475098
Validation loss: 2.130557398001353

Epoch: 5| Step: 8
Training loss: 1.30718994140625
Validation loss: 2.0921275913715363

Epoch: 5| Step: 9
Training loss: 0.6789771914482117
Validation loss: 2.106108362476031

Epoch: 5| Step: 10
Training loss: 0.7741715908050537
Validation loss: 2.1050413300593696

Epoch: 5| Step: 11
Training loss: 1.2777525186538696
Validation loss: 2.138321022192637

Epoch: 168| Step: 0
Training loss: 0.578201413154602
Validation loss: 2.0988630106051764

Epoch: 5| Step: 1
Training loss: 1.429612159729004
Validation loss: 2.145401289065679

Epoch: 5| Step: 2
Training loss: 0.949848473072052
Validation loss: 2.181375816464424

Epoch: 5| Step: 3
Training loss: 0.840100884437561
Validation loss: 2.141705945134163

Epoch: 5| Step: 4
Training loss: 0.7690410614013672
Validation loss: 2.135934521754583

Epoch: 5| Step: 5
Training loss: 0.4411088526248932
Validation loss: 2.1216156582037606

Epoch: 5| Step: 6
Training loss: 0.6707911491394043
Validation loss: 2.1052424063285193

Epoch: 5| Step: 7
Training loss: 1.1337666511535645
Validation loss: 2.1626201272010803

Epoch: 5| Step: 8
Training loss: 1.022210717201233
Validation loss: 2.111522043744723

Epoch: 5| Step: 9
Training loss: 0.8082437515258789
Validation loss: 2.104506701231003

Epoch: 5| Step: 10
Training loss: 0.6635344624519348
Validation loss: 2.1076216449340186

Epoch: 5| Step: 11
Training loss: 0.9070242643356323
Validation loss: 2.119838853677114

Epoch: 169| Step: 0
Training loss: 0.8346840143203735
Validation loss: 2.1532025138537088

Epoch: 5| Step: 1
Training loss: 0.9970723390579224
Validation loss: 2.217371493577957

Epoch: 5| Step: 2
Training loss: 0.8216608762741089
Validation loss: 2.2534297655026116

Epoch: 5| Step: 3
Training loss: 0.714496374130249
Validation loss: 2.1869899878899255

Epoch: 5| Step: 4
Training loss: 0.5937238931655884
Validation loss: 2.2354371547698975

Epoch: 5| Step: 5
Training loss: 0.6740939617156982
Validation loss: 2.166495139400164

Epoch: 5| Step: 6
Training loss: 0.5900529623031616
Validation loss: 2.1196022033691406

Epoch: 5| Step: 7
Training loss: 1.1938711404800415
Validation loss: 2.1312221586704254

Epoch: 5| Step: 8
Training loss: 0.6733152270317078
Validation loss: 2.128975361585617

Epoch: 5| Step: 9
Training loss: 0.8134201169013977
Validation loss: 2.138547276457151

Epoch: 5| Step: 10
Training loss: 0.9854335784912109
Validation loss: 2.1315121551354728

Epoch: 5| Step: 11
Training loss: 2.4640703201293945
Validation loss: 2.1672320018212

Epoch: 170| Step: 0
Training loss: 0.6032558083534241
Validation loss: 2.1952928602695465

Epoch: 5| Step: 1
Training loss: 0.7565187215805054
Validation loss: 2.2172382374604545

Epoch: 5| Step: 2
Training loss: 1.0578404664993286
Validation loss: 2.2131780982017517

Epoch: 5| Step: 3
Training loss: 0.8950151205062866
Validation loss: 2.169720227519671

Epoch: 5| Step: 4
Training loss: 0.38123100996017456
Validation loss: 2.1517934004465737

Epoch: 5| Step: 5
Training loss: 0.5963947772979736
Validation loss: 2.1399445881446204

Epoch: 5| Step: 6
Training loss: 0.6545694470405579
Validation loss: 2.1371998290220895

Epoch: 5| Step: 7
Training loss: 1.2765718698501587
Validation loss: 2.092334136366844

Epoch: 5| Step: 8
Training loss: 1.1504006385803223
Validation loss: 2.177341843644778

Epoch: 5| Step: 9
Training loss: 1.0174977779388428
Validation loss: 2.129777650038401

Epoch: 5| Step: 10
Training loss: 0.8618118166923523
Validation loss: 2.15538260837396

Epoch: 5| Step: 11
Training loss: 1.2541701793670654
Validation loss: 2.1721905767917633

Epoch: 171| Step: 0
Training loss: 1.1403512954711914
Validation loss: 2.2378502637147903

Epoch: 5| Step: 1
Training loss: 0.8217049837112427
Validation loss: 2.2175762752691903

Epoch: 5| Step: 2
Training loss: 0.5577782988548279
Validation loss: 2.191338171561559

Epoch: 5| Step: 3
Training loss: 1.3302819728851318
Validation loss: 2.1538835714260736

Epoch: 5| Step: 4
Training loss: 0.6849809885025024
Validation loss: 2.110494911670685

Epoch: 5| Step: 5
Training loss: 0.7247189879417419
Validation loss: 2.0400967746973038

Epoch: 5| Step: 6
Training loss: 0.9421118497848511
Validation loss: 2.0951998829841614

Epoch: 5| Step: 7
Training loss: 0.8429789543151855
Validation loss: 2.11457829674085

Epoch: 5| Step: 8
Training loss: 0.9292465448379517
Validation loss: 2.1288331896066666

Epoch: 5| Step: 9
Training loss: 0.8717430233955383
Validation loss: 2.1718687216440835

Epoch: 5| Step: 10
Training loss: 0.7821532487869263
Validation loss: 2.139898737271627

Epoch: 5| Step: 11
Training loss: 0.23213064670562744
Validation loss: 2.1931696186463037

Epoch: 172| Step: 0
Training loss: 0.8838310241699219
Validation loss: 2.1778878768285117

Epoch: 5| Step: 1
Training loss: 0.33205848932266235
Validation loss: 2.191842337449392

Epoch: 5| Step: 2
Training loss: 1.2266147136688232
Validation loss: 2.1868810455004373

Epoch: 5| Step: 3
Training loss: 0.6701762080192566
Validation loss: 2.144213338692983

Epoch: 5| Step: 4
Training loss: 0.5088685750961304
Validation loss: 2.139441723624865

Epoch: 5| Step: 5
Training loss: 1.5664899349212646
Validation loss: 2.2387921760479608

Epoch: 5| Step: 6
Training loss: 0.9631193280220032
Validation loss: 2.1975032091140747

Epoch: 5| Step: 7
Training loss: 0.5143531560897827
Validation loss: 2.198467656970024

Epoch: 5| Step: 8
Training loss: 0.6348393559455872
Validation loss: 2.210313101609548

Epoch: 5| Step: 9
Training loss: 0.92948979139328
Validation loss: 2.2207302153110504

Epoch: 5| Step: 10
Training loss: 0.7510522603988647
Validation loss: 2.1978043913841248

Epoch: 5| Step: 11
Training loss: 0.5753415822982788
Validation loss: 2.2304913798967996

Epoch: 173| Step: 0
Training loss: 0.6422063112258911
Validation loss: 2.2060954372088113

Epoch: 5| Step: 1
Training loss: 1.2126741409301758
Validation loss: 2.16059817870458

Epoch: 5| Step: 2
Training loss: 1.0128511190414429
Validation loss: 2.192229410012563

Epoch: 5| Step: 3
Training loss: 1.0671297311782837
Validation loss: 2.2373996575673423

Epoch: 5| Step: 4
Training loss: 0.6520638465881348
Validation loss: 2.1815432707468667

Epoch: 5| Step: 5
Training loss: 0.5976065397262573
Validation loss: 2.2171313961346946

Epoch: 5| Step: 6
Training loss: 0.7950646877288818
Validation loss: 2.1617257495721183

Epoch: 5| Step: 7
Training loss: 0.48697739839553833
Validation loss: 2.1986774454514184

Epoch: 5| Step: 8
Training loss: 0.9131800532341003
Validation loss: 2.1211520781119666

Epoch: 5| Step: 9
Training loss: 0.8198451995849609
Validation loss: 2.175086627403895

Epoch: 5| Step: 10
Training loss: 0.6744444966316223
Validation loss: 2.189232995112737

Epoch: 5| Step: 11
Training loss: 0.6818988919258118
Validation loss: 2.206680089235306

Epoch: 174| Step: 0
Training loss: 0.731148362159729
Validation loss: 2.1703308572371802

Epoch: 5| Step: 1
Training loss: 0.7556565403938293
Validation loss: 2.1683769822120667

Epoch: 5| Step: 2
Training loss: 0.4946870803833008
Validation loss: 2.1578744997580848

Epoch: 5| Step: 3
Training loss: 0.6263106465339661
Validation loss: 2.12951797246933

Epoch: 5| Step: 4
Training loss: 1.2077525854110718
Validation loss: 2.139608790477117

Epoch: 5| Step: 5
Training loss: 0.7579363584518433
Validation loss: 2.108200172583262

Epoch: 5| Step: 6
Training loss: 1.1559563875198364
Validation loss: 2.0926272372404733

Epoch: 5| Step: 7
Training loss: 1.200873613357544
Validation loss: 2.1144410769144693

Epoch: 5| Step: 8
Training loss: 0.9048164486885071
Validation loss: 2.0699934462706246

Epoch: 5| Step: 9
Training loss: 0.7598088383674622
Validation loss: 2.08373299241066

Epoch: 5| Step: 10
Training loss: 0.7154432535171509
Validation loss: 2.0950517058372498

Epoch: 5| Step: 11
Training loss: 0.6920608878135681
Validation loss: 2.1693769792715707

Epoch: 175| Step: 0
Training loss: 0.6672422289848328
Validation loss: 2.1846295098463693

Epoch: 5| Step: 1
Training loss: 1.076805830001831
Validation loss: 2.2864424884319305

Epoch: 5| Step: 2
Training loss: 0.6824870109558105
Validation loss: 2.1955620596806207

Epoch: 5| Step: 3
Training loss: 0.6935585141181946
Validation loss: 2.2005278021097183

Epoch: 5| Step: 4
Training loss: 0.41171568632125854
Validation loss: 2.1243133892615638

Epoch: 5| Step: 5
Training loss: 1.282002568244934
Validation loss: 2.0762057254711785

Epoch: 5| Step: 6
Training loss: 1.4068273305892944
Validation loss: 2.049514094988505

Epoch: 5| Step: 7
Training loss: 1.1567118167877197
Validation loss: 2.0507829835017524

Epoch: 5| Step: 8
Training loss: 0.7971681356430054
Validation loss: 2.118038977185885

Epoch: 5| Step: 9
Training loss: 0.6025621891021729
Validation loss: 2.106562594572703

Epoch: 5| Step: 10
Training loss: 1.1591660976409912
Validation loss: 2.199549620350202

Epoch: 5| Step: 11
Training loss: 0.2937607169151306
Validation loss: 2.181592643260956

Testing loss: 1.9809794871927164
