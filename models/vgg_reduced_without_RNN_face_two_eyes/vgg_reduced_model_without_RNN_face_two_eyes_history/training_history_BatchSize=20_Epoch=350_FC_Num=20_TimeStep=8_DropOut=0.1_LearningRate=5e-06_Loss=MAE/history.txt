Epoch: 1| Step: 0
Training loss: 4.633528709411621
Validation loss: 4.893328706423442

Epoch: 5| Step: 1
Training loss: 5.537914276123047
Validation loss: 4.866132448116939

Epoch: 5| Step: 2
Training loss: 5.410996437072754
Validation loss: 4.844328065713246

Epoch: 5| Step: 3
Training loss: 4.6448259353637695
Validation loss: 4.821782489617665

Epoch: 5| Step: 4
Training loss: 4.409839630126953
Validation loss: 4.799786597490311

Epoch: 5| Step: 5
Training loss: 5.704500675201416
Validation loss: 4.779097298781077

Epoch: 5| Step: 6
Training loss: 4.530759811401367
Validation loss: 4.759016364812851

Epoch: 5| Step: 7
Training loss: 4.492848873138428
Validation loss: 4.736472288767497

Epoch: 5| Step: 8
Training loss: 4.182159423828125
Validation loss: 4.71549391746521

Epoch: 5| Step: 9
Training loss: 5.220794200897217
Validation loss: 4.695931057135264

Epoch: 5| Step: 10
Training loss: 4.820620059967041
Validation loss: 4.669922570387523

Epoch: 5| Step: 11
Training loss: 4.446188926696777
Validation loss: 4.648157119750977

Epoch: 2| Step: 0
Training loss: 4.702993392944336
Validation loss: 4.625682473182678

Epoch: 5| Step: 1
Training loss: 5.215025901794434
Validation loss: 4.599666972955068

Epoch: 5| Step: 2
Training loss: 4.6504411697387695
Validation loss: 4.571010182301204

Epoch: 5| Step: 3
Training loss: 4.60570764541626
Validation loss: 4.546586841344833

Epoch: 5| Step: 4
Training loss: 4.658886909484863
Validation loss: 4.517207582791646

Epoch: 5| Step: 5
Training loss: 4.277508735656738
Validation loss: 4.48683096965154

Epoch: 5| Step: 6
Training loss: 5.273963928222656
Validation loss: 4.457735160986583

Epoch: 5| Step: 7
Training loss: 4.837703227996826
Validation loss: 4.425455550352733

Epoch: 5| Step: 8
Training loss: 4.607834815979004
Validation loss: 4.3940005501111346

Epoch: 5| Step: 9
Training loss: 3.9887752532958984
Validation loss: 4.355611135562261

Epoch: 5| Step: 10
Training loss: 3.738201141357422
Validation loss: 4.321340550978978

Epoch: 5| Step: 11
Training loss: 3.563230514526367
Validation loss: 4.2867878178755445

Epoch: 3| Step: 0
Training loss: 4.808287620544434
Validation loss: 4.250893751780192

Epoch: 5| Step: 1
Training loss: 3.682049512863159
Validation loss: 4.213854839404424

Epoch: 5| Step: 2
Training loss: 3.903629779815674
Validation loss: 4.1728203892707825

Epoch: 5| Step: 3
Training loss: 3.9295763969421387
Validation loss: 4.133546551068624

Epoch: 5| Step: 4
Training loss: 3.8545994758605957
Validation loss: 4.093985676765442

Epoch: 5| Step: 5
Training loss: 5.551814079284668
Validation loss: 4.048586885134379

Epoch: 5| Step: 6
Training loss: 3.6149611473083496
Validation loss: 4.011294176181157

Epoch: 5| Step: 7
Training loss: 3.797769069671631
Validation loss: 3.9617872734864554

Epoch: 5| Step: 8
Training loss: 4.315451145172119
Validation loss: 3.919816166162491

Epoch: 5| Step: 9
Training loss: 4.059187889099121
Validation loss: 3.8656041423479715

Epoch: 5| Step: 10
Training loss: 4.443832874298096
Validation loss: 3.820418268442154

Epoch: 5| Step: 11
Training loss: 3.2430806159973145
Validation loss: 3.7724415063858032

Epoch: 4| Step: 0
Training loss: 4.895493507385254
Validation loss: 3.7157855331897736

Epoch: 5| Step: 1
Training loss: 2.7903950214385986
Validation loss: 3.6608622074127197

Epoch: 5| Step: 2
Training loss: 4.106208324432373
Validation loss: 3.600341647863388

Epoch: 5| Step: 3
Training loss: 3.710935592651367
Validation loss: 3.5374923845132193

Epoch: 5| Step: 4
Training loss: 3.7045509815216064
Validation loss: 3.474319726228714

Epoch: 5| Step: 5
Training loss: 3.5828285217285156
Validation loss: 3.416116257508596

Epoch: 5| Step: 6
Training loss: 2.70514178276062
Validation loss: 3.343637297550837

Epoch: 5| Step: 7
Training loss: 3.276189088821411
Validation loss: 3.2860353688398996

Epoch: 5| Step: 8
Training loss: 3.6277365684509277
Validation loss: 3.2169434130191803

Epoch: 5| Step: 9
Training loss: 3.3749454021453857
Validation loss: 3.1488407850265503

Epoch: 5| Step: 10
Training loss: 2.873471736907959
Validation loss: 3.081603745619456

Epoch: 5| Step: 11
Training loss: 5.142264366149902
Validation loss: 3.0225108563899994

Epoch: 5| Step: 0
Training loss: 3.253169298171997
Validation loss: 2.9360446532567344

Epoch: 5| Step: 1
Training loss: 3.4148197174072266
Validation loss: 2.8627170523007712

Epoch: 5| Step: 2
Training loss: 2.5498175621032715
Validation loss: 2.78691573937734

Epoch: 5| Step: 3
Training loss: 2.654221773147583
Validation loss: 2.713943511247635

Epoch: 5| Step: 4
Training loss: 2.4146487712860107
Validation loss: 2.6232689122358956

Epoch: 5| Step: 5
Training loss: 2.918164014816284
Validation loss: 2.5473734736442566

Epoch: 5| Step: 6
Training loss: 2.6446428298950195
Validation loss: 2.4537469844023385

Epoch: 5| Step: 7
Training loss: 1.916265845298767
Validation loss: 2.389739731947581

Epoch: 5| Step: 8
Training loss: 2.5507330894470215
Validation loss: 2.3141839057207108

Epoch: 5| Step: 9
Training loss: 2.0554776191711426
Validation loss: 2.272414897878965

Epoch: 5| Step: 10
Training loss: 2.3926548957824707
Validation loss: 2.201858232418696

Epoch: 5| Step: 11
Training loss: 2.5105044841766357
Validation loss: 2.1538459261258445

Epoch: 6| Step: 0
Training loss: 1.8644053936004639
Validation loss: 2.13918174803257

Epoch: 5| Step: 1
Training loss: 1.8805124759674072
Validation loss: 2.123742704590162

Epoch: 5| Step: 2
Training loss: 2.883826494216919
Validation loss: 2.097065652410189

Epoch: 5| Step: 3
Training loss: 2.066046953201294
Validation loss: 2.086241145928701

Epoch: 5| Step: 4
Training loss: 2.5229992866516113
Validation loss: 2.0887421518564224

Epoch: 5| Step: 5
Training loss: 1.8907829523086548
Validation loss: 2.0788749903440475

Epoch: 5| Step: 6
Training loss: 2.1681504249572754
Validation loss: 2.0812613318363824

Epoch: 5| Step: 7
Training loss: 2.6372230052948
Validation loss: 2.058817277352015

Epoch: 5| Step: 8
Training loss: 2.02532696723938
Validation loss: 2.0664928406476974

Epoch: 5| Step: 9
Training loss: 1.7676308155059814
Validation loss: 2.0438397377729416

Epoch: 5| Step: 10
Training loss: 1.6374566555023193
Validation loss: 2.0431773513555527

Epoch: 5| Step: 11
Training loss: 1.9521760940551758
Validation loss: 2.065044720967611

Epoch: 7| Step: 0
Training loss: 2.3681108951568604
Validation loss: 2.047589788834254

Epoch: 5| Step: 1
Training loss: 1.571510910987854
Validation loss: 2.0583920975526175

Epoch: 5| Step: 2
Training loss: 2.0159928798675537
Validation loss: 2.070111577709516

Epoch: 5| Step: 3
Training loss: 2.04341197013855
Validation loss: 2.066584641734759

Epoch: 5| Step: 4
Training loss: 1.941545844078064
Validation loss: 2.0570525427659354

Epoch: 5| Step: 5
Training loss: 2.186673402786255
Validation loss: 2.062079826990763

Epoch: 5| Step: 6
Training loss: 1.9499763250350952
Validation loss: 2.0428621619939804

Epoch: 5| Step: 7
Training loss: 1.816353440284729
Validation loss: 2.0618902196486792

Epoch: 5| Step: 8
Training loss: 2.099385976791382
Validation loss: 2.0594054410854974

Epoch: 5| Step: 9
Training loss: 1.9414088726043701
Validation loss: 2.0604114333788552

Epoch: 5| Step: 10
Training loss: 2.78812837600708
Validation loss: 2.055850068728129

Epoch: 5| Step: 11
Training loss: 3.547497272491455
Validation loss: 2.0574899464845657

Epoch: 8| Step: 0
Training loss: 2.151989459991455
Validation loss: 2.059762105345726

Epoch: 5| Step: 1
Training loss: 2.341963529586792
Validation loss: 2.0577477365732193

Epoch: 5| Step: 2
Training loss: 1.5073089599609375
Validation loss: 2.0516570607821145

Epoch: 5| Step: 3
Training loss: 1.9876865148544312
Validation loss: 2.03678235411644

Epoch: 5| Step: 4
Training loss: 1.8537101745605469
Validation loss: 2.0507310330867767

Epoch: 5| Step: 5
Training loss: 2.636270046234131
Validation loss: 2.031735504666964

Epoch: 5| Step: 6
Training loss: 2.2082557678222656
Validation loss: 2.042745992541313

Epoch: 5| Step: 7
Training loss: 2.245791435241699
Validation loss: 2.0666238218545914

Epoch: 5| Step: 8
Training loss: 2.2803103923797607
Validation loss: 2.025157868862152

Epoch: 5| Step: 9
Training loss: 1.9485019445419312
Validation loss: 2.0462489873170853

Epoch: 5| Step: 10
Training loss: 1.4774086475372314
Validation loss: 2.056293527285258

Epoch: 5| Step: 11
Training loss: 3.1595635414123535
Validation loss: 2.0405898094177246

Epoch: 9| Step: 0
Training loss: 2.0263166427612305
Validation loss: 2.0422853976488113

Epoch: 5| Step: 1
Training loss: 2.251925468444824
Validation loss: 2.0306138495604196

Epoch: 5| Step: 2
Training loss: 2.3355846405029297
Validation loss: 2.0413639694452286

Epoch: 5| Step: 3
Training loss: 1.6596943140029907
Validation loss: 2.0523424297571182

Epoch: 5| Step: 4
Training loss: 2.1051173210144043
Validation loss: 2.0506317913532257

Epoch: 5| Step: 5
Training loss: 2.6075031757354736
Validation loss: 2.0440428654352822

Epoch: 5| Step: 6
Training loss: 2.1625711917877197
Validation loss: 2.0727183669805527

Epoch: 5| Step: 7
Training loss: 2.3880410194396973
Validation loss: 2.0677464654048285

Epoch: 5| Step: 8
Training loss: 1.7700647115707397
Validation loss: 2.069360683361689

Epoch: 5| Step: 9
Training loss: 2.239290714263916
Validation loss: 2.036078318953514

Epoch: 5| Step: 10
Training loss: 1.7081966400146484
Validation loss: 2.0704157849152884

Epoch: 5| Step: 11
Training loss: 0.8169739842414856
Validation loss: 2.045946309963862

Epoch: 10| Step: 0
Training loss: 1.9520995616912842
Validation loss: 2.0608970373868942

Epoch: 5| Step: 1
Training loss: 2.2991976737976074
Validation loss: 2.0406881173451743

Epoch: 5| Step: 2
Training loss: 2.1218271255493164
Validation loss: 2.048940201600393

Epoch: 5| Step: 3
Training loss: 1.8494548797607422
Validation loss: 2.0396926601727805

Epoch: 5| Step: 4
Training loss: 2.0806288719177246
Validation loss: 2.0327347864707312

Epoch: 5| Step: 5
Training loss: 1.638623833656311
Validation loss: 2.0394584834575653

Epoch: 5| Step: 6
Training loss: 2.4289727210998535
Validation loss: 2.0191912154356637

Epoch: 5| Step: 7
Training loss: 1.963627815246582
Validation loss: 2.040167679389318

Epoch: 5| Step: 8
Training loss: 2.6651716232299805
Validation loss: 2.0289496779441833

Epoch: 5| Step: 9
Training loss: 2.1963891983032227
Validation loss: 2.0378214567899704

Epoch: 5| Step: 10
Training loss: 1.6033073663711548
Validation loss: 2.030480901400248

Epoch: 5| Step: 11
Training loss: 0.9982477426528931
Validation loss: 2.0432937194903693

Epoch: 11| Step: 0
Training loss: 2.3848204612731934
Validation loss: 2.034455115596453

Epoch: 5| Step: 1
Training loss: 1.781778335571289
Validation loss: 2.026634564002355

Epoch: 5| Step: 2
Training loss: 2.3246912956237793
Validation loss: 2.031158705552419

Epoch: 5| Step: 3
Training loss: 1.7769584655761719
Validation loss: 2.037815605600675

Epoch: 5| Step: 4
Training loss: 2.3290820121765137
Validation loss: 2.0511717945337296

Epoch: 5| Step: 5
Training loss: 2.4190783500671387
Validation loss: 2.0253149370352426

Epoch: 5| Step: 6
Training loss: 2.6973087787628174
Validation loss: 2.0229098945856094

Epoch: 5| Step: 7
Training loss: 1.948560357093811
Validation loss: 2.025558903813362

Epoch: 5| Step: 8
Training loss: 1.2910878658294678
Validation loss: 2.0429411828517914

Epoch: 5| Step: 9
Training loss: 1.4326450824737549
Validation loss: 2.02890083193779

Epoch: 5| Step: 10
Training loss: 2.1298108100891113
Validation loss: 2.024568180243174

Epoch: 5| Step: 11
Training loss: 2.300910711288452
Validation loss: 2.01472861568133

Epoch: 12| Step: 0
Training loss: 1.8783912658691406
Validation loss: 2.021830971042315

Epoch: 5| Step: 1
Training loss: 1.6012462377548218
Validation loss: 2.0029940654834113

Epoch: 5| Step: 2
Training loss: 1.5958201885223389
Validation loss: 2.0335710446039834

Epoch: 5| Step: 3
Training loss: 2.1075525283813477
Validation loss: 2.036599944035212

Epoch: 5| Step: 4
Training loss: 2.569622039794922
Validation loss: 2.0273557156324387

Epoch: 5| Step: 5
Training loss: 1.8674064874649048
Validation loss: 2.0269558082024255

Epoch: 5| Step: 6
Training loss: 1.9967892169952393
Validation loss: 2.025056873758634

Epoch: 5| Step: 7
Training loss: 2.3303098678588867
Validation loss: 2.026924600203832

Epoch: 5| Step: 8
Training loss: 2.142129421234131
Validation loss: 2.00700381398201

Epoch: 5| Step: 9
Training loss: 2.1388158798217773
Validation loss: 2.032267322142919

Epoch: 5| Step: 10
Training loss: 2.1107726097106934
Validation loss: 2.030130445957184

Epoch: 5| Step: 11
Training loss: 1.916853427886963
Validation loss: 2.0264910012483597

Epoch: 13| Step: 0
Training loss: 2.4823806285858154
Validation loss: 2.019611323873202

Epoch: 5| Step: 1
Training loss: 2.140421152114868
Validation loss: 2.0206312189499536

Epoch: 5| Step: 2
Training loss: 1.7511066198349
Validation loss: 2.0429082264502845

Epoch: 5| Step: 3
Training loss: 1.6689363718032837
Validation loss: 2.0039190302292504

Epoch: 5| Step: 4
Training loss: 2.1450448036193848
Validation loss: 2.013578936457634

Epoch: 5| Step: 5
Training loss: 2.0278267860412598
Validation loss: 2.0333469063043594

Epoch: 5| Step: 6
Training loss: 1.666632056236267
Validation loss: 2.0237430334091187

Epoch: 5| Step: 7
Training loss: 2.5152859687805176
Validation loss: 2.0137899219989777

Epoch: 5| Step: 8
Training loss: 2.1409337520599365
Validation loss: 2.033470958471298

Epoch: 5| Step: 9
Training loss: 1.8630459308624268
Validation loss: 2.0170864313840866

Epoch: 5| Step: 10
Training loss: 1.9221309423446655
Validation loss: 2.020969236890475

Epoch: 5| Step: 11
Training loss: 2.5026087760925293
Validation loss: 2.010730043053627

Epoch: 14| Step: 0
Training loss: 2.498225450515747
Validation loss: 2.0238340546687446

Epoch: 5| Step: 1
Training loss: 1.4559046030044556
Validation loss: 2.017106056213379

Epoch: 5| Step: 2
Training loss: 1.8025939464569092
Validation loss: 2.017026409506798

Epoch: 5| Step: 3
Training loss: 2.1414780616760254
Validation loss: 2.01522404452165

Epoch: 5| Step: 4
Training loss: 1.7437269687652588
Validation loss: 2.0344340006510415

Epoch: 5| Step: 5
Training loss: 2.370128631591797
Validation loss: 2.022748430569967

Epoch: 5| Step: 6
Training loss: 2.054547071456909
Validation loss: 2.025060713291168

Epoch: 5| Step: 7
Training loss: 2.6711244583129883
Validation loss: 2.02515701452891

Epoch: 5| Step: 8
Training loss: 2.377992630004883
Validation loss: 2.012899617354075

Epoch: 5| Step: 9
Training loss: 1.8897171020507812
Validation loss: 2.0140229960282645

Epoch: 5| Step: 10
Training loss: 1.4629367589950562
Validation loss: 2.0324101696411767

Epoch: 5| Step: 11
Training loss: 1.4698988199234009
Validation loss: 2.0055935035149255

Epoch: 15| Step: 0
Training loss: 2.0674781799316406
Validation loss: 1.9897265881299973

Epoch: 5| Step: 1
Training loss: 2.0793704986572266
Validation loss: 2.0157569646835327

Epoch: 5| Step: 2
Training loss: 1.742396593093872
Validation loss: 2.0112636536359787

Epoch: 5| Step: 3
Training loss: 2.2506656646728516
Validation loss: 2.030495216449102

Epoch: 5| Step: 4
Training loss: 3.1141202449798584
Validation loss: 2.0089976092179618

Epoch: 5| Step: 5
Training loss: 2.221230983734131
Validation loss: 2.0077488074700036

Epoch: 5| Step: 6
Training loss: 1.8133264780044556
Validation loss: 2.0213398337364197

Epoch: 5| Step: 7
Training loss: 1.8948169946670532
Validation loss: 1.995268354813258

Epoch: 5| Step: 8
Training loss: 1.6010236740112305
Validation loss: 2.0181614756584167

Epoch: 5| Step: 9
Training loss: 1.4973812103271484
Validation loss: 2.0160439560810723

Epoch: 5| Step: 10
Training loss: 1.975635290145874
Validation loss: 2.0109199533859887

Epoch: 5| Step: 11
Training loss: 1.9240463972091675
Validation loss: 2.008463576436043

Epoch: 16| Step: 0
Training loss: 1.7956607341766357
Validation loss: 2.017060468594233

Epoch: 5| Step: 1
Training loss: 2.42195463180542
Validation loss: 2.0309719194968543

Epoch: 5| Step: 2
Training loss: 1.8909378051757812
Validation loss: 2.000816668073336

Epoch: 5| Step: 3
Training loss: 3.0650575160980225
Validation loss: 2.0093877812226615

Epoch: 5| Step: 4
Training loss: 1.4373042583465576
Validation loss: 2.0153911958138147

Epoch: 5| Step: 5
Training loss: 2.187941074371338
Validation loss: 2.0220198233922324

Epoch: 5| Step: 6
Training loss: 1.5261934995651245
Validation loss: 2.017430563767751

Epoch: 5| Step: 7
Training loss: 2.2967662811279297
Validation loss: 1.9999319513638814

Epoch: 5| Step: 8
Training loss: 1.748248815536499
Validation loss: 2.010049045085907

Epoch: 5| Step: 9
Training loss: 2.1125736236572266
Validation loss: 2.006831188996633

Epoch: 5| Step: 10
Training loss: 1.864678978919983
Validation loss: 2.0042736480633416

Epoch: 5| Step: 11
Training loss: 2.019780397415161
Validation loss: 2.0084598660469055

Epoch: 17| Step: 0
Training loss: 1.670511245727539
Validation loss: 2.0120159089565277

Epoch: 5| Step: 1
Training loss: 2.4671425819396973
Validation loss: 2.0102753241856894

Epoch: 5| Step: 2
Training loss: 2.0147433280944824
Validation loss: 2.023039549589157

Epoch: 5| Step: 3
Training loss: 1.898131012916565
Validation loss: 2.0129042168458304

Epoch: 5| Step: 4
Training loss: 1.5788236856460571
Validation loss: 2.030933678150177

Epoch: 5| Step: 5
Training loss: 2.533581495285034
Validation loss: 1.998906706770261

Epoch: 5| Step: 6
Training loss: 2.0154223442077637
Validation loss: 2.0043022135893502

Epoch: 5| Step: 7
Training loss: 1.7683823108673096
Validation loss: 2.0306187073389688

Epoch: 5| Step: 8
Training loss: 1.8046386241912842
Validation loss: 1.9971737066904705

Epoch: 5| Step: 9
Training loss: 1.9181770086288452
Validation loss: 2.0031298051277795

Epoch: 5| Step: 10
Training loss: 2.45174503326416
Validation loss: 2.011714036266009

Epoch: 5| Step: 11
Training loss: 2.186873435974121
Validation loss: 1.9900827606519063

Epoch: 18| Step: 0
Training loss: 1.8974735736846924
Validation loss: 2.015724793076515

Epoch: 5| Step: 1
Training loss: 1.928288459777832
Validation loss: 1.9956013212601345

Epoch: 5| Step: 2
Training loss: 1.8745771646499634
Validation loss: 1.9976170013348262

Epoch: 5| Step: 3
Training loss: 2.0370123386383057
Validation loss: 2.032367765903473

Epoch: 5| Step: 4
Training loss: 2.6166319847106934
Validation loss: 2.0102410465478897

Epoch: 5| Step: 5
Training loss: 2.062377691268921
Validation loss: 2.0121180564165115

Epoch: 5| Step: 6
Training loss: 2.1280438899993896
Validation loss: 2.013986508051554

Epoch: 5| Step: 7
Training loss: 1.7983646392822266
Validation loss: 1.9985156456629436

Epoch: 5| Step: 8
Training loss: 2.0707759857177734
Validation loss: 1.9798477838436763

Epoch: 5| Step: 9
Training loss: 1.7024074792861938
Validation loss: 1.9979570508003235

Epoch: 5| Step: 10
Training loss: 1.9865039587020874
Validation loss: 1.9922913908958435

Epoch: 5| Step: 11
Training loss: 1.9821534156799316
Validation loss: 2.0055332680543265

Epoch: 19| Step: 0
Training loss: 1.816485047340393
Validation loss: 2.0115260730187097

Epoch: 5| Step: 1
Training loss: 1.988534927368164
Validation loss: 1.97940394282341

Epoch: 5| Step: 2
Training loss: 1.3725507259368896
Validation loss: 2.0081552267074585

Epoch: 5| Step: 3
Training loss: 2.2342820167541504
Validation loss: 2.016659880677859

Epoch: 5| Step: 4
Training loss: 1.8915646076202393
Validation loss: 2.0029366860787072

Epoch: 5| Step: 5
Training loss: 2.2116470336914062
Validation loss: 2.014492854475975

Epoch: 5| Step: 6
Training loss: 2.0491933822631836
Validation loss: 2.0199868083000183

Epoch: 5| Step: 7
Training loss: 1.7383352518081665
Validation loss: 1.996709982554118

Epoch: 5| Step: 8
Training loss: 2.617764949798584
Validation loss: 1.985877404610316

Epoch: 5| Step: 9
Training loss: 2.229940891265869
Validation loss: 2.0272159526745477

Epoch: 5| Step: 10
Training loss: 1.9872121810913086
Validation loss: 1.9962754448254902

Epoch: 5| Step: 11
Training loss: 1.019080638885498
Validation loss: 2.0030026187499366

Epoch: 20| Step: 0
Training loss: 1.8184051513671875
Validation loss: 1.9942796677350998

Epoch: 5| Step: 1
Training loss: 1.8846534490585327
Validation loss: 1.9973803361256917

Epoch: 5| Step: 2
Training loss: 2.0213425159454346
Validation loss: 2.0020386278629303

Epoch: 5| Step: 3
Training loss: 2.506166458129883
Validation loss: 2.0149655093749366

Epoch: 5| Step: 4
Training loss: 2.095228433609009
Validation loss: 2.0095149924357734

Epoch: 5| Step: 5
Training loss: 1.6272151470184326
Validation loss: 1.9855355024337769

Epoch: 5| Step: 6
Training loss: 1.963258147239685
Validation loss: 1.995371808608373

Epoch: 5| Step: 7
Training loss: 1.9504474401474
Validation loss: 1.9958945016066234

Epoch: 5| Step: 8
Training loss: 2.170475721359253
Validation loss: 2.0037716180086136

Epoch: 5| Step: 9
Training loss: 2.0648720264434814
Validation loss: 1.9995456089576085

Epoch: 5| Step: 10
Training loss: 1.7282981872558594
Validation loss: 2.0203978468974433

Epoch: 5| Step: 11
Training loss: 1.9277575016021729
Validation loss: 2.0022144267956414

Epoch: 21| Step: 0
Training loss: 1.9635753631591797
Validation loss: 1.9798262019952138

Epoch: 5| Step: 1
Training loss: 1.6425435543060303
Validation loss: 2.0046834647655487

Epoch: 5| Step: 2
Training loss: 1.9765573740005493
Validation loss: 1.9839130739370983

Epoch: 5| Step: 3
Training loss: 2.277585029602051
Validation loss: 1.9926244765520096

Epoch: 5| Step: 4
Training loss: 1.7458641529083252
Validation loss: 1.9972446461518605

Epoch: 5| Step: 5
Training loss: 1.24843168258667
Validation loss: 1.9854800154765446

Epoch: 5| Step: 6
Training loss: 1.978231430053711
Validation loss: 1.9832337250312169

Epoch: 5| Step: 7
Training loss: 1.6711117029190063
Validation loss: 2.0021291822195053

Epoch: 5| Step: 8
Training loss: 3.0765435695648193
Validation loss: 1.9979526897271473

Epoch: 5| Step: 9
Training loss: 2.2575573921203613
Validation loss: 1.9743048300345738

Epoch: 5| Step: 10
Training loss: 2.2623484134674072
Validation loss: 1.997550184528033

Epoch: 5| Step: 11
Training loss: 1.9925397634506226
Validation loss: 1.9993918736775715

Epoch: 22| Step: 0
Training loss: 2.582615375518799
Validation loss: 2.0140568365653357

Epoch: 5| Step: 1
Training loss: 2.017082929611206
Validation loss: 2.0028961847225824

Epoch: 5| Step: 2
Training loss: 1.5811431407928467
Validation loss: 1.9917645851771038

Epoch: 5| Step: 3
Training loss: 1.7456598281860352
Validation loss: 2.010913332303365

Epoch: 5| Step: 4
Training loss: 1.9470579624176025
Validation loss: 2.0171757886807122

Epoch: 5| Step: 5
Training loss: 2.0615334510803223
Validation loss: 1.9947720815738041

Epoch: 5| Step: 6
Training loss: 2.0087459087371826
Validation loss: 2.016609400510788

Epoch: 5| Step: 7
Training loss: 1.255084753036499
Validation loss: 2.016755531231562

Epoch: 5| Step: 8
Training loss: 2.0144057273864746
Validation loss: 2.0053982635339103

Epoch: 5| Step: 9
Training loss: 2.243870496749878
Validation loss: 1.9976362933715184

Epoch: 5| Step: 10
Training loss: 2.6335320472717285
Validation loss: 1.9960383176803589

Epoch: 5| Step: 11
Training loss: 1.6233762502670288
Validation loss: 2.0000789066155753

Epoch: 23| Step: 0
Training loss: 1.1714022159576416
Validation loss: 1.9975540240605671

Epoch: 5| Step: 1
Training loss: 2.393962860107422
Validation loss: 1.9864347179730732

Epoch: 5| Step: 2
Training loss: 1.4141415357589722
Validation loss: 1.9946431368589401

Epoch: 5| Step: 3
Training loss: 2.0824520587921143
Validation loss: 1.989478791753451

Epoch: 5| Step: 4
Training loss: 2.0332884788513184
Validation loss: 1.9973176072041194

Epoch: 5| Step: 5
Training loss: 2.1001648902893066
Validation loss: 1.9974750032027562

Epoch: 5| Step: 6
Training loss: 1.8807977437973022
Validation loss: 1.9872621695200603

Epoch: 5| Step: 7
Training loss: 2.2833046913146973
Validation loss: 1.9895090411106746

Epoch: 5| Step: 8
Training loss: 2.3406784534454346
Validation loss: 1.9975131700436275

Epoch: 5| Step: 9
Training loss: 1.8958412408828735
Validation loss: 1.9860140532255173

Epoch: 5| Step: 10
Training loss: 2.3650381565093994
Validation loss: 1.9884787946939468

Epoch: 5| Step: 11
Training loss: 1.9923639297485352
Validation loss: 1.9977619101603825

Epoch: 24| Step: 0
Training loss: 1.8058090209960938
Validation loss: 1.9817544917265575

Epoch: 5| Step: 1
Training loss: 1.445205807685852
Validation loss: 1.9903387029965718

Epoch: 5| Step: 2
Training loss: 2.1315417289733887
Validation loss: 1.978844980398814

Epoch: 5| Step: 3
Training loss: 2.2070508003234863
Validation loss: 1.9916410197814305

Epoch: 5| Step: 4
Training loss: 1.0002044439315796
Validation loss: 1.9882185558478038

Epoch: 5| Step: 5
Training loss: 1.826106071472168
Validation loss: 1.9854150265455246

Epoch: 5| Step: 6
Training loss: 1.9317432641983032
Validation loss: 1.9748383065064747

Epoch: 5| Step: 7
Training loss: 2.6289336681365967
Validation loss: 1.9807707965373993

Epoch: 5| Step: 8
Training loss: 2.390200138092041
Validation loss: 1.989232396086057

Epoch: 5| Step: 9
Training loss: 2.624060869216919
Validation loss: 1.978875031073888

Epoch: 5| Step: 10
Training loss: 2.085075855255127
Validation loss: 1.978699783484141

Epoch: 5| Step: 11
Training loss: 1.5202758312225342
Validation loss: 2.000968500971794

Epoch: 25| Step: 0
Training loss: 2.216460704803467
Validation loss: 1.9696297546227772

Epoch: 5| Step: 1
Training loss: 1.6945581436157227
Validation loss: 1.9880690723657608

Epoch: 5| Step: 2
Training loss: 1.9471355676651
Validation loss: 1.993149921298027

Epoch: 5| Step: 3
Training loss: 2.0506744384765625
Validation loss: 1.989166498184204

Epoch: 5| Step: 4
Training loss: 2.3557052612304688
Validation loss: 1.988537107904752

Epoch: 5| Step: 5
Training loss: 1.8420429229736328
Validation loss: 1.9925196717182796

Epoch: 5| Step: 6
Training loss: 1.8437097072601318
Validation loss: 2.0026564995447793

Epoch: 5| Step: 7
Training loss: 2.266055107116699
Validation loss: 1.9979077974955242

Epoch: 5| Step: 8
Training loss: 2.136914014816284
Validation loss: 1.9989587167898815

Epoch: 5| Step: 9
Training loss: 2.174619197845459
Validation loss: 1.9872866719961166

Epoch: 5| Step: 10
Training loss: 1.3478091955184937
Validation loss: 2.008115937312444

Epoch: 5| Step: 11
Training loss: 2.444593667984009
Validation loss: 1.981743852297465

Epoch: 26| Step: 0
Training loss: 1.8139612674713135
Validation loss: 1.9964100420475006

Epoch: 5| Step: 1
Training loss: 1.8711779117584229
Validation loss: 1.9741889635721843

Epoch: 5| Step: 2
Training loss: 2.4252824783325195
Validation loss: 2.009023313721021

Epoch: 5| Step: 3
Training loss: 2.4756486415863037
Validation loss: 1.9854268729686737

Epoch: 5| Step: 4
Training loss: 1.9575669765472412
Validation loss: 1.992561509211858

Epoch: 5| Step: 5
Training loss: 1.577649712562561
Validation loss: 1.9813590745131175

Epoch: 5| Step: 6
Training loss: 1.8866437673568726
Validation loss: 2.005175312360128

Epoch: 5| Step: 7
Training loss: 2.207209587097168
Validation loss: 1.9992377758026123

Epoch: 5| Step: 8
Training loss: 2.1185240745544434
Validation loss: 1.9981287270784378

Epoch: 5| Step: 9
Training loss: 1.8044198751449585
Validation loss: 2.001911476254463

Epoch: 5| Step: 10
Training loss: 1.8861865997314453
Validation loss: 2.011411557594935

Epoch: 5| Step: 11
Training loss: 0.9933998584747314
Validation loss: 1.9833554724852245

Epoch: 27| Step: 0
Training loss: 1.7426363229751587
Validation loss: 2.0069778710603714

Epoch: 5| Step: 1
Training loss: 1.7207705974578857
Validation loss: 1.9825014919042587

Epoch: 5| Step: 2
Training loss: 2.4234166145324707
Validation loss: 1.9950787673393886

Epoch: 5| Step: 3
Training loss: 2.284275531768799
Validation loss: 2.0154915948708854

Epoch: 5| Step: 4
Training loss: 1.9023853540420532
Validation loss: 1.9824653416872025

Epoch: 5| Step: 5
Training loss: 2.636504650115967
Validation loss: 1.9946452776590984

Epoch: 5| Step: 6
Training loss: 2.0174736976623535
Validation loss: 1.9816992829243343

Epoch: 5| Step: 7
Training loss: 1.845963478088379
Validation loss: 1.9952115664879482

Epoch: 5| Step: 8
Training loss: 2.3213911056518555
Validation loss: 2.010244275132815

Epoch: 5| Step: 9
Training loss: 1.260704755783081
Validation loss: 2.005127047499021

Epoch: 5| Step: 10
Training loss: 2.044463634490967
Validation loss: 2.002187122901281

Epoch: 5| Step: 11
Training loss: 2.0285327434539795
Validation loss: 1.9919430861870449

Epoch: 28| Step: 0
Training loss: 1.9965671300888062
Validation loss: 1.9924498001734416

Epoch: 5| Step: 1
Training loss: 1.8926784992218018
Validation loss: 1.9905484269062679

Epoch: 5| Step: 2
Training loss: 1.8136237859725952
Validation loss: 1.9897718131542206

Epoch: 5| Step: 3
Training loss: 2.146233081817627
Validation loss: 1.986545632282893

Epoch: 5| Step: 4
Training loss: 2.0177667140960693
Validation loss: 1.9755783925453823

Epoch: 5| Step: 5
Training loss: 2.0204055309295654
Validation loss: 1.9869512269894283

Epoch: 5| Step: 6
Training loss: 2.19677996635437
Validation loss: 1.997468853990237

Epoch: 5| Step: 7
Training loss: 1.8881877660751343
Validation loss: 1.969904750585556

Epoch: 5| Step: 8
Training loss: 1.8083913326263428
Validation loss: 1.9977976381778717

Epoch: 5| Step: 9
Training loss: 1.6874452829360962
Validation loss: 1.9897972345352173

Epoch: 5| Step: 10
Training loss: 1.7991529703140259
Validation loss: 2.005458742380142

Epoch: 5| Step: 11
Training loss: 3.531228542327881
Validation loss: 2.0114709039529166

Epoch: 29| Step: 0
Training loss: 3.2023277282714844
Validation loss: 1.9850378185510635

Epoch: 5| Step: 1
Training loss: 1.5931366682052612
Validation loss: 2.014551733930906

Epoch: 5| Step: 2
Training loss: 1.8043915033340454
Validation loss: 1.9946072101593018

Epoch: 5| Step: 3
Training loss: 1.358818769454956
Validation loss: 2.012038692831993

Epoch: 5| Step: 4
Training loss: 1.800899863243103
Validation loss: 1.9958715190490086

Epoch: 5| Step: 5
Training loss: 2.014533042907715
Validation loss: 2.012873644630114

Epoch: 5| Step: 6
Training loss: 1.8437789678573608
Validation loss: 2.0028939694166183

Epoch: 5| Step: 7
Training loss: 2.1611602306365967
Validation loss: 2.0222648779551187

Epoch: 5| Step: 8
Training loss: 2.1239194869995117
Validation loss: 1.9872671365737915

Epoch: 5| Step: 9
Training loss: 1.370309591293335
Validation loss: 1.9862907528877258

Epoch: 5| Step: 10
Training loss: 2.655139446258545
Validation loss: 2.0038340389728546

Epoch: 5| Step: 11
Training loss: 0.7799211740493774
Validation loss: 1.9819598545630772

Epoch: 30| Step: 0
Training loss: 1.5342614650726318
Validation loss: 1.98752457400163

Epoch: 5| Step: 1
Training loss: 1.6712121963500977
Validation loss: 1.9930266837279003

Epoch: 5| Step: 2
Training loss: 1.9237934350967407
Validation loss: 2.00687009592851

Epoch: 5| Step: 3
Training loss: 2.0711588859558105
Validation loss: 2.022478441397349

Epoch: 5| Step: 4
Training loss: 2.3036725521087646
Validation loss: 2.0379569431145987

Epoch: 5| Step: 5
Training loss: 2.2598230838775635
Validation loss: 2.0363482932249704

Epoch: 5| Step: 6
Training loss: 1.9455314874649048
Validation loss: 2.0527922362089157

Epoch: 5| Step: 7
Training loss: 1.5356429815292358
Validation loss: 2.021668002009392

Epoch: 5| Step: 8
Training loss: 2.231367588043213
Validation loss: 2.0466918845971427

Epoch: 5| Step: 9
Training loss: 2.3480916023254395
Validation loss: 2.016803130507469

Epoch: 5| Step: 10
Training loss: 2.365577220916748
Validation loss: 1.9986176540454228

Epoch: 5| Step: 11
Training loss: 0.9894512295722961
Validation loss: 1.9949687520662944

Epoch: 31| Step: 0
Training loss: 1.586249828338623
Validation loss: 1.999432623386383

Epoch: 5| Step: 1
Training loss: 2.19451904296875
Validation loss: 2.000073343515396

Epoch: 5| Step: 2
Training loss: 1.3894259929656982
Validation loss: 1.9808225433031719

Epoch: 5| Step: 3
Training loss: 1.6676177978515625
Validation loss: 1.985799600680669

Epoch: 5| Step: 4
Training loss: 2.4503536224365234
Validation loss: 1.9918793837229412

Epoch: 5| Step: 5
Training loss: 2.313520908355713
Validation loss: 1.989333172639211

Epoch: 5| Step: 6
Training loss: 2.5401833057403564
Validation loss: 1.9720267206430435

Epoch: 5| Step: 7
Training loss: 1.7658923864364624
Validation loss: 1.9881219665209453

Epoch: 5| Step: 8
Training loss: 1.7515045404434204
Validation loss: 1.9778989801804225

Epoch: 5| Step: 9
Training loss: 2.0830628871917725
Validation loss: 1.9865434368451436

Epoch: 5| Step: 10
Training loss: 1.9242737293243408
Validation loss: 1.9734009504318237

Epoch: 5| Step: 11
Training loss: 2.393599510192871
Validation loss: 1.9925995916128159

Epoch: 32| Step: 0
Training loss: 1.771113634109497
Validation loss: 1.973492716749509

Epoch: 5| Step: 1
Training loss: 2.6725401878356934
Validation loss: 1.9732698053121567

Epoch: 5| Step: 2
Training loss: 1.8912627696990967
Validation loss: 1.9933503866195679

Epoch: 5| Step: 3
Training loss: 1.8299596309661865
Validation loss: 1.9854280004898708

Epoch: 5| Step: 4
Training loss: 1.9085133075714111
Validation loss: 1.9880803177754085

Epoch: 5| Step: 5
Training loss: 1.2655819654464722
Validation loss: 1.9898255815108616

Epoch: 5| Step: 6
Training loss: 1.849561095237732
Validation loss: 1.9795107195774715

Epoch: 5| Step: 7
Training loss: 1.3045763969421387
Validation loss: 1.9851293563842773

Epoch: 5| Step: 8
Training loss: 2.685955762863159
Validation loss: 1.9836671600739162

Epoch: 5| Step: 9
Training loss: 1.9628560543060303
Validation loss: 1.979145144422849

Epoch: 5| Step: 10
Training loss: 2.1684482097625732
Validation loss: 1.988238165775935

Epoch: 5| Step: 11
Training loss: 2.4602432250976562
Validation loss: 1.9897951732079189

Epoch: 33| Step: 0
Training loss: 1.852264404296875
Validation loss: 2.018288960059484

Epoch: 5| Step: 1
Training loss: 1.567164421081543
Validation loss: 2.005401144425074

Epoch: 5| Step: 2
Training loss: 1.7995929718017578
Validation loss: 2.0224921107292175

Epoch: 5| Step: 3
Training loss: 2.277625560760498
Validation loss: 2.0178063859542212

Epoch: 5| Step: 4
Training loss: 1.7947499752044678
Validation loss: 2.032317946354548

Epoch: 5| Step: 5
Training loss: 2.0612080097198486
Validation loss: 2.0080533772706985

Epoch: 5| Step: 6
Training loss: 2.1703877449035645
Validation loss: 2.0470999429623284

Epoch: 5| Step: 7
Training loss: 2.334287166595459
Validation loss: 2.022654116153717

Epoch: 5| Step: 8
Training loss: 1.9179531335830688
Validation loss: 2.018142595887184

Epoch: 5| Step: 9
Training loss: 2.4309985637664795
Validation loss: 1.9986584782600403

Epoch: 5| Step: 10
Training loss: 1.501274824142456
Validation loss: 1.9935685296853383

Epoch: 5| Step: 11
Training loss: 1.4481018781661987
Validation loss: 2.016557514667511

Epoch: 34| Step: 0
Training loss: 2.854597568511963
Validation loss: 1.9950392295916874

Epoch: 5| Step: 1
Training loss: 2.3161895275115967
Validation loss: 1.9963547835747402

Epoch: 5| Step: 2
Training loss: 1.47585129737854
Validation loss: 2.001471425096194

Epoch: 5| Step: 3
Training loss: 2.4444355964660645
Validation loss: 2.0014133056004844

Epoch: 5| Step: 4
Training loss: 1.6203361749649048
Validation loss: 1.9966008861859639

Epoch: 5| Step: 5
Training loss: 1.8858362436294556
Validation loss: 2.003656486670176

Epoch: 5| Step: 6
Training loss: 1.8519914150238037
Validation loss: 2.015732392668724

Epoch: 5| Step: 7
Training loss: 1.8685098886489868
Validation loss: 2.0002593050400415

Epoch: 5| Step: 8
Training loss: 2.107950210571289
Validation loss: 1.9984567264715831

Epoch: 5| Step: 9
Training loss: 1.472898244857788
Validation loss: 2.004296988248825

Epoch: 5| Step: 10
Training loss: 1.5529447793960571
Validation loss: 1.9881736437479656

Epoch: 5| Step: 11
Training loss: 2.5913331508636475
Validation loss: 2.000794291496277

Epoch: 35| Step: 0
Training loss: 2.064814805984497
Validation loss: 1.9975610574086506

Epoch: 5| Step: 1
Training loss: 1.8364837169647217
Validation loss: 1.9612489740053813

Epoch: 5| Step: 2
Training loss: 2.2497243881225586
Validation loss: 1.989392990867297

Epoch: 5| Step: 3
Training loss: 1.608793020248413
Validation loss: 1.9909917116165161

Epoch: 5| Step: 4
Training loss: 1.7791846990585327
Validation loss: 1.9698699166377385

Epoch: 5| Step: 5
Training loss: 2.2573964595794678
Validation loss: 1.9713082313537598

Epoch: 5| Step: 6
Training loss: 1.804586410522461
Validation loss: 1.9978764702876408

Epoch: 5| Step: 7
Training loss: 2.318082809448242
Validation loss: 1.9694581429163616

Epoch: 5| Step: 8
Training loss: 1.274780035018921
Validation loss: 1.9742338458697002

Epoch: 5| Step: 9
Training loss: 1.7513935565948486
Validation loss: 1.9831455151240032

Epoch: 5| Step: 10
Training loss: 2.5249571800231934
Validation loss: 1.95805528263251

Epoch: 5| Step: 11
Training loss: 2.124042510986328
Validation loss: 1.9767187684774399

Epoch: 36| Step: 0
Training loss: 1.4283009767532349
Validation loss: 1.977465182542801

Epoch: 5| Step: 1
Training loss: 2.045356035232544
Validation loss: 1.9808723231156666

Epoch: 5| Step: 2
Training loss: 1.3874342441558838
Validation loss: 2.0087642669677734

Epoch: 5| Step: 3
Training loss: 1.8597939014434814
Validation loss: 1.9869570632775624

Epoch: 5| Step: 4
Training loss: 2.3150417804718018
Validation loss: 1.994716927409172

Epoch: 5| Step: 5
Training loss: 1.8786665201187134
Validation loss: 1.9839516878128052

Epoch: 5| Step: 6
Training loss: 2.4309566020965576
Validation loss: 2.0184290955464044

Epoch: 5| Step: 7
Training loss: 1.963402509689331
Validation loss: 2.0075613260269165

Epoch: 5| Step: 8
Training loss: 1.751287817955017
Validation loss: 2.007392570376396

Epoch: 5| Step: 9
Training loss: 2.3363964557647705
Validation loss: 2.016076778372129

Epoch: 5| Step: 10
Training loss: 2.0953311920166016
Validation loss: 2.0424224734306335

Epoch: 5| Step: 11
Training loss: 1.852886438369751
Validation loss: 2.0063000271717706

Epoch: 37| Step: 0
Training loss: 1.8033053874969482
Validation loss: 1.9965023050705593

Epoch: 5| Step: 1
Training loss: 1.7961574792861938
Validation loss: 2.028163035710653

Epoch: 5| Step: 2
Training loss: 1.388201117515564
Validation loss: 2.0046203831831613

Epoch: 5| Step: 3
Training loss: 1.439294457435608
Validation loss: 1.9970241487026215

Epoch: 5| Step: 4
Training loss: 1.8520848751068115
Validation loss: 2.001055270433426

Epoch: 5| Step: 5
Training loss: 2.3300182819366455
Validation loss: 1.9934976448615391

Epoch: 5| Step: 6
Training loss: 2.2541069984436035
Validation loss: 1.980656385421753

Epoch: 5| Step: 7
Training loss: 2.5528481006622314
Validation loss: 1.98319511115551

Epoch: 5| Step: 8
Training loss: 2.060267686843872
Validation loss: 1.9723118146260579

Epoch: 5| Step: 9
Training loss: 1.9180831909179688
Validation loss: 1.9682286431392033

Epoch: 5| Step: 10
Training loss: 1.97641921043396
Validation loss: 1.9693556477626164

Epoch: 5| Step: 11
Training loss: 1.482885479927063
Validation loss: 1.9891193707784016

Epoch: 38| Step: 0
Training loss: 1.8742488622665405
Validation loss: 1.9781656314929326

Epoch: 5| Step: 1
Training loss: 1.5750404596328735
Validation loss: 1.9974531382322311

Epoch: 5| Step: 2
Training loss: 1.8184986114501953
Validation loss: 1.9849167615175247

Epoch: 5| Step: 3
Training loss: 2.415478229522705
Validation loss: 1.9800775796175003

Epoch: 5| Step: 4
Training loss: 2.100576877593994
Validation loss: 1.9778584043184917

Epoch: 5| Step: 5
Training loss: 1.8782241344451904
Validation loss: 1.9549557814995449

Epoch: 5| Step: 6
Training loss: 1.7357629537582397
Validation loss: 1.965966910123825

Epoch: 5| Step: 7
Training loss: 2.248138666152954
Validation loss: 1.9795795530080795

Epoch: 5| Step: 8
Training loss: 2.284318685531616
Validation loss: 1.9774391502141953

Epoch: 5| Step: 9
Training loss: 1.3318049907684326
Validation loss: 1.9839124927918117

Epoch: 5| Step: 10
Training loss: 2.0111122131347656
Validation loss: 1.9916634062925975

Epoch: 5| Step: 11
Training loss: 3.252106189727783
Validation loss: 1.9667881776889165

Epoch: 39| Step: 0
Training loss: 2.2675371170043945
Validation loss: 1.9754487574100494

Epoch: 5| Step: 1
Training loss: 1.6423094272613525
Validation loss: 2.0021659384171167

Epoch: 5| Step: 2
Training loss: 1.2569836378097534
Validation loss: 1.9951192339261372

Epoch: 5| Step: 3
Training loss: 2.1172263622283936
Validation loss: 1.99010136226813

Epoch: 5| Step: 4
Training loss: 1.7301833629608154
Validation loss: 1.998930384715398

Epoch: 5| Step: 5
Training loss: 2.4051880836486816
Validation loss: 1.999699021379153

Epoch: 5| Step: 6
Training loss: 1.5112037658691406
Validation loss: 1.9811744789282482

Epoch: 5| Step: 7
Training loss: 2.1592562198638916
Validation loss: 2.0113912324110665

Epoch: 5| Step: 8
Training loss: 1.4810868501663208
Validation loss: 1.9938675910234451

Epoch: 5| Step: 9
Training loss: 2.1482231616973877
Validation loss: 1.9760414411624272

Epoch: 5| Step: 10
Training loss: 2.374129056930542
Validation loss: 2.00574067234993

Epoch: 5| Step: 11
Training loss: 1.930106282234192
Validation loss: 1.991405228773753

Epoch: 40| Step: 0
Training loss: 2.021580934524536
Validation loss: 2.0105306853850684

Epoch: 5| Step: 1
Training loss: 2.141408681869507
Validation loss: 1.9919571727514267

Epoch: 5| Step: 2
Training loss: 2.9711296558380127
Validation loss: 2.0066693226496377

Epoch: 5| Step: 3
Training loss: 2.0454914569854736
Validation loss: 1.9763585080703099

Epoch: 5| Step: 4
Training loss: 1.5839636325836182
Validation loss: 1.9698466211557388

Epoch: 5| Step: 5
Training loss: 1.4881010055541992
Validation loss: 1.9625280598799388

Epoch: 5| Step: 6
Training loss: 2.1566073894500732
Validation loss: 1.9693786054849625

Epoch: 5| Step: 7
Training loss: 1.5084375143051147
Validation loss: 1.9644736051559448

Epoch: 5| Step: 8
Training loss: 1.9041147232055664
Validation loss: 1.9680612683296204

Epoch: 5| Step: 9
Training loss: 1.7426204681396484
Validation loss: 1.9684379200140636

Epoch: 5| Step: 10
Training loss: 1.7395368814468384
Validation loss: 1.9926786422729492

Epoch: 5| Step: 11
Training loss: 1.6378483772277832
Validation loss: 1.9915434370438259

Epoch: 41| Step: 0
Training loss: 1.8321349620819092
Validation loss: 1.9919529755910237

Epoch: 5| Step: 1
Training loss: 1.4184261560440063
Validation loss: 2.0053309500217438

Epoch: 5| Step: 2
Training loss: 1.6134817600250244
Validation loss: 1.979825382431348

Epoch: 5| Step: 3
Training loss: 2.138286828994751
Validation loss: 2.001942425966263

Epoch: 5| Step: 4
Training loss: 1.9430382251739502
Validation loss: 2.0084569404522576

Epoch: 5| Step: 5
Training loss: 1.6415345668792725
Validation loss: 2.0064316590627036

Epoch: 5| Step: 6
Training loss: 1.8422012329101562
Validation loss: 2.0121622731288276

Epoch: 5| Step: 7
Training loss: 2.04137921333313
Validation loss: 1.999299983183543

Epoch: 5| Step: 8
Training loss: 2.187058687210083
Validation loss: 2.011018067598343

Epoch: 5| Step: 9
Training loss: 2.2766051292419434
Validation loss: 2.0010025948286057

Epoch: 5| Step: 10
Training loss: 2.403848171234131
Validation loss: 1.9840494294961293

Epoch: 5| Step: 11
Training loss: 0.8689279556274414
Validation loss: 1.9852470407883327

Epoch: 42| Step: 0
Training loss: 1.2895070314407349
Validation loss: 1.9729444881280263

Epoch: 5| Step: 1
Training loss: 1.9320147037506104
Validation loss: 1.9932701985041301

Epoch: 5| Step: 2
Training loss: 2.31367564201355
Validation loss: 2.0337737699349723

Epoch: 5| Step: 3
Training loss: 2.1287004947662354
Validation loss: 2.0709484269221625

Epoch: 5| Step: 4
Training loss: 1.7137857675552368
Validation loss: 2.023037980000178

Epoch: 5| Step: 5
Training loss: 2.0558836460113525
Validation loss: 2.037462150057157

Epoch: 5| Step: 6
Training loss: 2.4633357524871826
Validation loss: 2.0528143594662347

Epoch: 5| Step: 7
Training loss: 1.7946189641952515
Validation loss: 2.043623298406601

Epoch: 5| Step: 8
Training loss: 2.166411876678467
Validation loss: 2.0431223809719086

Epoch: 5| Step: 9
Training loss: 1.5284373760223389
Validation loss: 2.0115026384592056

Epoch: 5| Step: 10
Training loss: 1.8243173360824585
Validation loss: 1.9949271281560261

Epoch: 5| Step: 11
Training loss: 2.0433688163757324
Validation loss: 1.9884034097194672

Epoch: 43| Step: 0
Training loss: 2.4921963214874268
Validation loss: 2.003944600621859

Epoch: 5| Step: 1
Training loss: 1.4322433471679688
Validation loss: 1.9948661277691524

Epoch: 5| Step: 2
Training loss: 1.8218482732772827
Validation loss: 1.9578861743211746

Epoch: 5| Step: 3
Training loss: 1.7355048656463623
Validation loss: 2.002080202102661

Epoch: 5| Step: 4
Training loss: 1.5367379188537598
Validation loss: 1.9716525624195735

Epoch: 5| Step: 5
Training loss: 2.4295618534088135
Validation loss: 1.9919711450735729

Epoch: 5| Step: 6
Training loss: 1.9658743143081665
Validation loss: 1.9857460260391235

Epoch: 5| Step: 7
Training loss: 1.955524206161499
Validation loss: 1.9972594181696575

Epoch: 5| Step: 8
Training loss: 2.196153163909912
Validation loss: 1.977646827697754

Epoch: 5| Step: 9
Training loss: 2.351515293121338
Validation loss: 1.978537807861964

Epoch: 5| Step: 10
Training loss: 1.4113168716430664
Validation loss: 2.007642298936844

Epoch: 5| Step: 11
Training loss: 0.6593227982521057
Validation loss: 1.9738142987092335

Epoch: 44| Step: 0
Training loss: 2.49493145942688
Validation loss: 2.0194257696469626

Epoch: 5| Step: 1
Training loss: 1.1373544931411743
Validation loss: 2.0017005999883017

Epoch: 5| Step: 2
Training loss: 1.6145308017730713
Validation loss: 2.0106588204701743

Epoch: 5| Step: 3
Training loss: 1.9202778339385986
Validation loss: 2.0202890932559967

Epoch: 5| Step: 4
Training loss: 2.5847651958465576
Validation loss: 2.0078649520874023

Epoch: 5| Step: 5
Training loss: 2.080679416656494
Validation loss: 2.0175396651029587

Epoch: 5| Step: 6
Training loss: 1.5668635368347168
Validation loss: 2.012935762604078

Epoch: 5| Step: 7
Training loss: 1.68777596950531
Validation loss: 1.9619276821613312

Epoch: 5| Step: 8
Training loss: 1.9459768533706665
Validation loss: 1.9907261580228806

Epoch: 5| Step: 9
Training loss: 2.0815930366516113
Validation loss: 1.9587784508864086

Epoch: 5| Step: 10
Training loss: 2.143860340118408
Validation loss: 1.9844191670417786

Epoch: 5| Step: 11
Training loss: 2.148500919342041
Validation loss: 1.9700722148021061

Epoch: 45| Step: 0
Training loss: 2.425881862640381
Validation loss: 1.9878648767868679

Epoch: 5| Step: 1
Training loss: 1.299274206161499
Validation loss: 1.9755104929208755

Epoch: 5| Step: 2
Training loss: 1.5196857452392578
Validation loss: 1.961299533645312

Epoch: 5| Step: 3
Training loss: 1.9897403717041016
Validation loss: 1.9816635151704152

Epoch: 5| Step: 4
Training loss: 2.3885936737060547
Validation loss: 1.9920236865679424

Epoch: 5| Step: 5
Training loss: 2.1024374961853027
Validation loss: 1.9891430288553238

Epoch: 5| Step: 6
Training loss: 2.256781816482544
Validation loss: 1.964763383070628

Epoch: 5| Step: 7
Training loss: 1.9018566608428955
Validation loss: 1.9770768880844116

Epoch: 5| Step: 8
Training loss: 1.5806009769439697
Validation loss: 1.9990843484799068

Epoch: 5| Step: 9
Training loss: 1.4735915660858154
Validation loss: 1.9680548558632533

Epoch: 5| Step: 10
Training loss: 1.8648936748504639
Validation loss: 1.9587691674629848

Epoch: 5| Step: 11
Training loss: 2.7500641345977783
Validation loss: 1.976344461242358

Epoch: 46| Step: 0
Training loss: 1.4104034900665283
Validation loss: 1.9756359706322353

Epoch: 5| Step: 1
Training loss: 2.2676005363464355
Validation loss: 1.9773271530866623

Epoch: 5| Step: 2
Training loss: 2.5460219383239746
Validation loss: 1.9845429559548695

Epoch: 5| Step: 3
Training loss: 1.8289222717285156
Validation loss: 1.9992989053328831

Epoch: 5| Step: 4
Training loss: 1.1845595836639404
Validation loss: 2.0012075106302896

Epoch: 5| Step: 5
Training loss: 2.267122268676758
Validation loss: 2.0028698444366455

Epoch: 5| Step: 6
Training loss: 1.7537095546722412
Validation loss: 2.003070001800855

Epoch: 5| Step: 7
Training loss: 1.5969598293304443
Validation loss: 1.9992215484380722

Epoch: 5| Step: 8
Training loss: 1.4388917684555054
Validation loss: 2.0127299427986145

Epoch: 5| Step: 9
Training loss: 2.6923987865448
Validation loss: 2.016605868935585

Epoch: 5| Step: 10
Training loss: 1.6239169836044312
Validation loss: 2.018667459487915

Epoch: 5| Step: 11
Training loss: 3.0009610652923584
Validation loss: 2.0193354040384293

Epoch: 47| Step: 0
Training loss: 2.064756155014038
Validation loss: 2.016119678815206

Epoch: 5| Step: 1
Training loss: 1.7279586791992188
Validation loss: 2.015825033187866

Epoch: 5| Step: 2
Training loss: 1.9112827777862549
Validation loss: 1.9958369384209316

Epoch: 5| Step: 3
Training loss: 1.6504123210906982
Validation loss: 2.0127369314432144

Epoch: 5| Step: 4
Training loss: 2.015947103500366
Validation loss: 1.9717454761266708

Epoch: 5| Step: 5
Training loss: 2.5049071311950684
Validation loss: 1.987640490134557

Epoch: 5| Step: 6
Training loss: 2.1244330406188965
Validation loss: 2.0111941347519555

Epoch: 5| Step: 7
Training loss: 2.250044345855713
Validation loss: 1.9721232702334721

Epoch: 5| Step: 8
Training loss: 1.9199014902114868
Validation loss: 1.9834569990634918

Epoch: 5| Step: 9
Training loss: 1.4573239088058472
Validation loss: 1.9706191221872966

Epoch: 5| Step: 10
Training loss: 1.2811191082000732
Validation loss: 1.9665870318810146

Epoch: 5| Step: 11
Training loss: 1.9254506826400757
Validation loss: 1.9662873893976212

Epoch: 48| Step: 0
Training loss: 1.7153056859970093
Validation loss: 1.9908925890922546

Epoch: 5| Step: 1
Training loss: 1.7348569631576538
Validation loss: 1.987693578004837

Epoch: 5| Step: 2
Training loss: 1.8606655597686768
Validation loss: 1.9877600173155467

Epoch: 5| Step: 3
Training loss: 1.4049546718597412
Validation loss: 2.0221680402755737

Epoch: 5| Step: 4
Training loss: 2.0270214080810547
Validation loss: 2.025405600667

Epoch: 5| Step: 5
Training loss: 1.8130309581756592
Validation loss: 2.0236548334360123

Epoch: 5| Step: 6
Training loss: 2.167858362197876
Validation loss: 2.0345884958902993

Epoch: 5| Step: 7
Training loss: 2.1813862323760986
Validation loss: 2.073473647236824

Epoch: 5| Step: 8
Training loss: 2.687699556350708
Validation loss: 2.063149407505989

Epoch: 5| Step: 9
Training loss: 1.642809510231018
Validation loss: 2.0357363671064377

Epoch: 5| Step: 10
Training loss: 1.88114333152771
Validation loss: 2.042012318968773

Epoch: 5| Step: 11
Training loss: 2.49550199508667
Validation loss: 2.032941371202469

Epoch: 49| Step: 0
Training loss: 1.5813583135604858
Validation loss: 2.049287259578705

Epoch: 5| Step: 1
Training loss: 2.46515154838562
Validation loss: 2.0025559812784195

Epoch: 5| Step: 2
Training loss: 1.4857081174850464
Validation loss: 2.0063574612140656

Epoch: 5| Step: 3
Training loss: 1.6267471313476562
Validation loss: 2.0147442469994226

Epoch: 5| Step: 4
Training loss: 1.6158040761947632
Validation loss: 1.9792535851399105

Epoch: 5| Step: 5
Training loss: 1.3455528020858765
Validation loss: 1.9941324541966121

Epoch: 5| Step: 6
Training loss: 1.8792988061904907
Validation loss: 1.9904995560646057

Epoch: 5| Step: 7
Training loss: 1.7746555805206299
Validation loss: 2.02523972094059

Epoch: 5| Step: 8
Training loss: 2.443380832672119
Validation loss: 2.000218148032824

Epoch: 5| Step: 9
Training loss: 1.8769619464874268
Validation loss: 1.9828456789255142

Epoch: 5| Step: 10
Training loss: 2.7838797569274902
Validation loss: 1.9917195588350296

Epoch: 5| Step: 11
Training loss: 1.5980679988861084
Validation loss: 2.00074336429437

Epoch: 50| Step: 0
Training loss: 2.1915578842163086
Validation loss: 1.9786914537350337

Epoch: 5| Step: 1
Training loss: 2.0537495613098145
Validation loss: 2.0037465691566467

Epoch: 5| Step: 2
Training loss: 1.6408542394638062
Validation loss: 1.9764427095651627

Epoch: 5| Step: 3
Training loss: 1.3924386501312256
Validation loss: 1.9615105589230855

Epoch: 5| Step: 4
Training loss: 2.2454545497894287
Validation loss: 1.9541146804889042

Epoch: 5| Step: 5
Training loss: 1.7093433141708374
Validation loss: 1.9634602467219036

Epoch: 5| Step: 6
Training loss: 2.1892762184143066
Validation loss: 1.9677464018265407

Epoch: 5| Step: 7
Training loss: 2.0936224460601807
Validation loss: 1.961099997162819

Epoch: 5| Step: 8
Training loss: 1.9820753335952759
Validation loss: 1.97260320186615

Epoch: 5| Step: 9
Training loss: 1.8982670307159424
Validation loss: 1.9888696322838466

Epoch: 5| Step: 10
Training loss: 1.7771533727645874
Validation loss: 1.9920402020215988

Epoch: 5| Step: 11
Training loss: 1.866335153579712
Validation loss: 1.963615929087003

Epoch: 51| Step: 0
Training loss: 1.6516739130020142
Validation loss: 1.9695525070031483

Epoch: 5| Step: 1
Training loss: 2.071509838104248
Validation loss: 1.9963694761196773

Epoch: 5| Step: 2
Training loss: 1.7183269262313843
Validation loss: 1.9849521567424138

Epoch: 5| Step: 3
Training loss: 1.4244956970214844
Validation loss: 2.0089861502250037

Epoch: 5| Step: 4
Training loss: 2.1580357551574707
Validation loss: 2.0207309474547706

Epoch: 5| Step: 5
Training loss: 1.4503719806671143
Validation loss: 2.0121988356113434

Epoch: 5| Step: 6
Training loss: 2.310436725616455
Validation loss: 2.0390018075704575

Epoch: 5| Step: 7
Training loss: 1.9965381622314453
Validation loss: 2.0197852353254953

Epoch: 5| Step: 8
Training loss: 1.5372962951660156
Validation loss: 2.0524888386329017

Epoch: 5| Step: 9
Training loss: 1.9694799184799194
Validation loss: 2.0074103424946466

Epoch: 5| Step: 10
Training loss: 2.1657474040985107
Validation loss: 2.035073439280192

Epoch: 5| Step: 11
Training loss: 2.045708417892456
Validation loss: 2.029032046596209

Epoch: 52| Step: 0
Training loss: 1.5750751495361328
Validation loss: 2.0052087008953094

Epoch: 5| Step: 1
Training loss: 1.726951241493225
Validation loss: 1.9937944213549297

Epoch: 5| Step: 2
Training loss: 1.7494733333587646
Validation loss: 2.0212914844353995

Epoch: 5| Step: 3
Training loss: 2.0260117053985596
Validation loss: 2.0102877219518027

Epoch: 5| Step: 4
Training loss: 2.175591230392456
Validation loss: 1.9864065100749333

Epoch: 5| Step: 5
Training loss: 1.7928107976913452
Validation loss: 1.9899466236432393

Epoch: 5| Step: 6
Training loss: 2.1037096977233887
Validation loss: 1.9574019412199657

Epoch: 5| Step: 7
Training loss: 1.7466942071914673
Validation loss: 2.002774938941002

Epoch: 5| Step: 8
Training loss: 1.7968593835830688
Validation loss: 1.9846348613500595

Epoch: 5| Step: 9
Training loss: 2.117614269256592
Validation loss: 1.990843375523885

Epoch: 5| Step: 10
Training loss: 1.776637077331543
Validation loss: 1.9737332661946614

Epoch: 5| Step: 11
Training loss: 1.4563177824020386
Validation loss: 1.976858099301656

Epoch: 53| Step: 0
Training loss: 1.9099658727645874
Validation loss: 1.9739761849244435

Epoch: 5| Step: 1
Training loss: 2.3002538681030273
Validation loss: 1.9614142179489136

Epoch: 5| Step: 2
Training loss: 1.786348581314087
Validation loss: 1.9866651048262913

Epoch: 5| Step: 3
Training loss: 2.076343297958374
Validation loss: 2.004898409048716

Epoch: 5| Step: 4
Training loss: 2.033926486968994
Validation loss: 2.0125596473614373

Epoch: 5| Step: 5
Training loss: 1.7948442697525024
Validation loss: 2.0144921094179153

Epoch: 5| Step: 6
Training loss: 1.5855953693389893
Validation loss: 1.9949269791444142

Epoch: 5| Step: 7
Training loss: 1.9840068817138672
Validation loss: 2.0396746893723807

Epoch: 5| Step: 8
Training loss: 2.0461058616638184
Validation loss: 2.0152175525824227

Epoch: 5| Step: 9
Training loss: 1.6047954559326172
Validation loss: 2.000748932361603

Epoch: 5| Step: 10
Training loss: 1.6943849325180054
Validation loss: 1.9805662284294765

Epoch: 5| Step: 11
Training loss: 1.9668657779693604
Validation loss: 1.9701953927675884

Epoch: 54| Step: 0
Training loss: 1.8504215478897095
Validation loss: 1.9955105980237324

Epoch: 5| Step: 1
Training loss: 1.7958946228027344
Validation loss: 1.9684853454430897

Epoch: 5| Step: 2
Training loss: 1.794321060180664
Validation loss: 1.9887091318766277

Epoch: 5| Step: 3
Training loss: 1.7545009851455688
Validation loss: 1.998248115181923

Epoch: 5| Step: 4
Training loss: 1.3403899669647217
Validation loss: 1.9680472761392593

Epoch: 5| Step: 5
Training loss: 1.4500116109848022
Validation loss: 1.9526636600494385

Epoch: 5| Step: 6
Training loss: 1.6635329723358154
Validation loss: 1.9820012748241425

Epoch: 5| Step: 7
Training loss: 2.2093851566314697
Validation loss: 2.006974066297213

Epoch: 5| Step: 8
Training loss: 2.070054531097412
Validation loss: 1.9970791538556416

Epoch: 5| Step: 9
Training loss: 2.31119966506958
Validation loss: 2.0191029061873755

Epoch: 5| Step: 10
Training loss: 2.48500394821167
Validation loss: 1.9957695056994755

Epoch: 5| Step: 11
Training loss: 1.524906039237976
Validation loss: 2.020220309495926

Epoch: 55| Step: 0
Training loss: 2.0880565643310547
Validation loss: 2.0045032898585

Epoch: 5| Step: 1
Training loss: 2.272252321243286
Validation loss: 1.9783285160859425

Epoch: 5| Step: 2
Training loss: 1.256360650062561
Validation loss: 1.988155464331309

Epoch: 5| Step: 3
Training loss: 2.479335308074951
Validation loss: 1.9743388990561168

Epoch: 5| Step: 4
Training loss: 1.282478928565979
Validation loss: 1.9494507312774658

Epoch: 5| Step: 5
Training loss: 1.9930248260498047
Validation loss: 1.9417935013771057

Epoch: 5| Step: 6
Training loss: 1.9628254175186157
Validation loss: 1.9857626507679622

Epoch: 5| Step: 7
Training loss: 2.0403671264648438
Validation loss: 1.969914734363556

Epoch: 5| Step: 8
Training loss: 1.6626784801483154
Validation loss: 1.9702256123224895

Epoch: 5| Step: 9
Training loss: 1.831176996231079
Validation loss: 1.9441364854574203

Epoch: 5| Step: 10
Training loss: 1.7130677700042725
Validation loss: 1.9686488310496013

Epoch: 5| Step: 11
Training loss: 1.920425534248352
Validation loss: 1.981505845983823

Epoch: 56| Step: 0
Training loss: 1.6599876880645752
Validation loss: 1.9522212743759155

Epoch: 5| Step: 1
Training loss: 1.5926940441131592
Validation loss: 1.978265181183815

Epoch: 5| Step: 2
Training loss: 2.253516674041748
Validation loss: 1.9998061209917068

Epoch: 5| Step: 3
Training loss: 2.0610435009002686
Validation loss: 2.047419806321462

Epoch: 5| Step: 4
Training loss: 2.0221123695373535
Validation loss: 2.052727301915487

Epoch: 5| Step: 5
Training loss: 1.8074524402618408
Validation loss: 2.057047580679258

Epoch: 5| Step: 6
Training loss: 1.8899009227752686
Validation loss: 2.019957805673281

Epoch: 5| Step: 7
Training loss: 2.481571674346924
Validation loss: 2.07440776626269

Epoch: 5| Step: 8
Training loss: 1.5670706033706665
Validation loss: 2.044372876485189

Epoch: 5| Step: 9
Training loss: 1.8336279392242432
Validation loss: 2.0291613837083182

Epoch: 5| Step: 10
Training loss: 1.8427727222442627
Validation loss: 2.0071466118097305

Epoch: 5| Step: 11
Training loss: 0.6865625381469727
Validation loss: 1.9924469043811162

Epoch: 57| Step: 0
Training loss: 2.2209715843200684
Validation loss: 1.9870736996332805

Epoch: 5| Step: 1
Training loss: 2.1422762870788574
Validation loss: 1.9921971758206685

Epoch: 5| Step: 2
Training loss: 1.881662130355835
Validation loss: 1.9713779042164485

Epoch: 5| Step: 3
Training loss: 1.912917137145996
Validation loss: 1.9500995030005772

Epoch: 5| Step: 4
Training loss: 2.0950472354888916
Validation loss: 2.0028256624937057

Epoch: 5| Step: 5
Training loss: 1.2250407934188843
Validation loss: 1.9612060338258743

Epoch: 5| Step: 6
Training loss: 1.5708849430084229
Validation loss: 2.0051029125849404

Epoch: 5| Step: 7
Training loss: 1.98980712890625
Validation loss: 1.9548295140266418

Epoch: 5| Step: 8
Training loss: 2.1389808654785156
Validation loss: 1.961629683772723

Epoch: 5| Step: 9
Training loss: 1.3190691471099854
Validation loss: 2.0177056342363358

Epoch: 5| Step: 10
Training loss: 1.7620315551757812
Validation loss: 1.955140382051468

Epoch: 5| Step: 11
Training loss: 2.103793144226074
Validation loss: 1.9572075257698696

Epoch: 58| Step: 0
Training loss: 1.892091155052185
Validation loss: 1.9842048635085423

Epoch: 5| Step: 1
Training loss: 2.346273183822632
Validation loss: 1.993751883506775

Epoch: 5| Step: 2
Training loss: 1.4948794841766357
Validation loss: 2.03777710100015

Epoch: 5| Step: 3
Training loss: 2.171990156173706
Validation loss: 2.000439574321111

Epoch: 5| Step: 4
Training loss: 1.5258582830429077
Validation loss: 2.0307394166787467

Epoch: 5| Step: 5
Training loss: 1.4081090688705444
Validation loss: 2.02690297861894

Epoch: 5| Step: 6
Training loss: 1.0572702884674072
Validation loss: 2.0071458468834558

Epoch: 5| Step: 7
Training loss: 1.8778879642486572
Validation loss: 2.020412956674894

Epoch: 5| Step: 8
Training loss: 1.9267936944961548
Validation loss: 2.011166070898374

Epoch: 5| Step: 9
Training loss: 2.4653890132904053
Validation loss: 1.998168518145879

Epoch: 5| Step: 10
Training loss: 2.061781406402588
Validation loss: 2.0091901620229087

Epoch: 5| Step: 11
Training loss: 2.49807071685791
Validation loss: 2.0041943987210593

Epoch: 59| Step: 0
Training loss: 1.7667462825775146
Validation loss: 2.0221468607584634

Epoch: 5| Step: 1
Training loss: 1.7864662408828735
Validation loss: 2.0058304915825524

Epoch: 5| Step: 2
Training loss: 1.7076622247695923
Validation loss: 1.9769484599431355

Epoch: 5| Step: 3
Training loss: 2.295436143875122
Validation loss: 1.9748099148273468

Epoch: 5| Step: 4
Training loss: 1.75434148311615
Validation loss: 1.9891274372736614

Epoch: 5| Step: 5
Training loss: 1.804512619972229
Validation loss: 1.9693942368030548

Epoch: 5| Step: 6
Training loss: 1.9533096551895142
Validation loss: 1.975138932466507

Epoch: 5| Step: 7
Training loss: 1.9088796377182007
Validation loss: 1.9741375346978505

Epoch: 5| Step: 8
Training loss: 1.5329848527908325
Validation loss: 1.9663371940453847

Epoch: 5| Step: 9
Training loss: 2.225801706314087
Validation loss: 1.9709221770366032

Epoch: 5| Step: 10
Training loss: 1.4995932579040527
Validation loss: 1.9484767317771912

Epoch: 5| Step: 11
Training loss: 2.419830083847046
Validation loss: 1.9785621911287308

Epoch: 60| Step: 0
Training loss: 1.9169647693634033
Validation loss: 1.984350969394048

Epoch: 5| Step: 1
Training loss: 1.2915531396865845
Validation loss: 1.971351573864619

Epoch: 5| Step: 2
Training loss: 2.063349485397339
Validation loss: 1.9966419488191605

Epoch: 5| Step: 3
Training loss: 1.9545400142669678
Validation loss: 1.9778456290562947

Epoch: 5| Step: 4
Training loss: 2.0216925144195557
Validation loss: 1.9985523919264476

Epoch: 5| Step: 5
Training loss: 1.953513741493225
Validation loss: 1.9977652877569199

Epoch: 5| Step: 6
Training loss: 2.432623863220215
Validation loss: 1.9779171297947566

Epoch: 5| Step: 7
Training loss: 2.1146061420440674
Validation loss: 2.0106599926948547

Epoch: 5| Step: 8
Training loss: 1.1791141033172607
Validation loss: 1.961291308204333

Epoch: 5| Step: 9
Training loss: 1.5240585803985596
Validation loss: 2.0026149998108544

Epoch: 5| Step: 10
Training loss: 1.9647560119628906
Validation loss: 2.0003039787213006

Epoch: 5| Step: 11
Training loss: 1.0666664838790894
Validation loss: 1.9977498600880306

Epoch: 61| Step: 0
Training loss: 2.144695997238159
Validation loss: 2.02044245103995

Epoch: 5| Step: 1
Training loss: 1.7868385314941406
Validation loss: 1.9819218218326569

Epoch: 5| Step: 2
Training loss: 1.517711877822876
Validation loss: 1.979169691602389

Epoch: 5| Step: 3
Training loss: 2.086733341217041
Validation loss: 1.9924490799506505

Epoch: 5| Step: 4
Training loss: 2.292743682861328
Validation loss: 1.9979003419478734

Epoch: 5| Step: 5
Training loss: 1.3009237051010132
Validation loss: 1.9861142039299011

Epoch: 5| Step: 6
Training loss: 1.4899042844772339
Validation loss: 2.0107631236314774

Epoch: 5| Step: 7
Training loss: 2.4248428344726562
Validation loss: 1.9603895743687947

Epoch: 5| Step: 8
Training loss: 1.9804713726043701
Validation loss: 1.9460664292176564

Epoch: 5| Step: 9
Training loss: 1.5844833850860596
Validation loss: 2.003632068634033

Epoch: 5| Step: 10
Training loss: 1.7315410375595093
Validation loss: 1.9671057065327961

Epoch: 5| Step: 11
Training loss: 1.541746735572815
Validation loss: 1.9650749166806538

Epoch: 62| Step: 0
Training loss: 2.201211452484131
Validation loss: 1.9984116454919179

Epoch: 5| Step: 1
Training loss: 1.492244005203247
Validation loss: 1.984150116642316

Epoch: 5| Step: 2
Training loss: 1.9302647113800049
Validation loss: 1.9884101649125416

Epoch: 5| Step: 3
Training loss: 2.2148373126983643
Validation loss: 2.0338610808054605

Epoch: 5| Step: 4
Training loss: 2.8788225650787354
Validation loss: 1.9882485965887706

Epoch: 5| Step: 5
Training loss: 2.0915770530700684
Validation loss: 1.978345826268196

Epoch: 5| Step: 6
Training loss: 2.0968832969665527
Validation loss: 1.995334307352702

Epoch: 5| Step: 7
Training loss: 1.2062480449676514
Validation loss: 2.0015983879566193

Epoch: 5| Step: 8
Training loss: 1.2110799551010132
Validation loss: 2.0088093082110086

Epoch: 5| Step: 9
Training loss: 1.2214571237564087
Validation loss: 1.9607693254947662

Epoch: 5| Step: 10
Training loss: 1.9092350006103516
Validation loss: 1.963322992126147

Epoch: 5| Step: 11
Training loss: 0.5866988301277161
Validation loss: 1.980149656534195

Epoch: 63| Step: 0
Training loss: 1.9321463108062744
Validation loss: 1.9992450674374898

Epoch: 5| Step: 1
Training loss: 2.5517163276672363
Validation loss: 2.0209721674521766

Epoch: 5| Step: 2
Training loss: 1.627197265625
Validation loss: 2.0082871317863464

Epoch: 5| Step: 3
Training loss: 1.7111917734146118
Validation loss: 1.9890831261873245

Epoch: 5| Step: 4
Training loss: 2.1544485092163086
Validation loss: 2.021231790383657

Epoch: 5| Step: 5
Training loss: 1.6235984563827515
Validation loss: 2.0010711699724197

Epoch: 5| Step: 6
Training loss: 1.7306270599365234
Validation loss: 1.9794684946537018

Epoch: 5| Step: 7
Training loss: 1.4994232654571533
Validation loss: 1.9989417642354965

Epoch: 5| Step: 8
Training loss: 1.7966368198394775
Validation loss: 1.9707316358884175

Epoch: 5| Step: 9
Training loss: 1.543536901473999
Validation loss: 2.0072822173436484

Epoch: 5| Step: 10
Training loss: 1.8971531391143799
Validation loss: 1.9811042547225952

Epoch: 5| Step: 11
Training loss: 2.019052267074585
Validation loss: 1.9897508571545284

Epoch: 64| Step: 0
Training loss: 1.4404386281967163
Validation loss: 1.9618090639511745

Epoch: 5| Step: 1
Training loss: 1.8313722610473633
Validation loss: 1.9554271896680195

Epoch: 5| Step: 2
Training loss: 1.4899965524673462
Validation loss: 1.976512496670087

Epoch: 5| Step: 3
Training loss: 1.706661581993103
Validation loss: 2.0020759950081506

Epoch: 5| Step: 4
Training loss: 1.5933552980422974
Validation loss: 1.9725975741942723

Epoch: 5| Step: 5
Training loss: 1.6674220561981201
Validation loss: 1.9841392437616985

Epoch: 5| Step: 6
Training loss: 2.5314526557922363
Validation loss: 2.0072629203399024

Epoch: 5| Step: 7
Training loss: 1.866830587387085
Validation loss: 1.9728654970725377

Epoch: 5| Step: 8
Training loss: 2.2989845275878906
Validation loss: 1.9951940874258678

Epoch: 5| Step: 9
Training loss: 1.643202543258667
Validation loss: 1.9656520336866379

Epoch: 5| Step: 10
Training loss: 1.7806113958358765
Validation loss: 1.9478149662415187

Epoch: 5| Step: 11
Training loss: 2.64259672164917
Validation loss: 1.9666561583677928

Epoch: 65| Step: 0
Training loss: 1.2967042922973633
Validation loss: 2.008505721886953

Epoch: 5| Step: 1
Training loss: 1.7520716190338135
Validation loss: 2.0159300913413367

Epoch: 5| Step: 2
Training loss: 1.3894613981246948
Validation loss: 2.009309301773707

Epoch: 5| Step: 3
Training loss: 2.1204586029052734
Validation loss: 1.9978622893492382

Epoch: 5| Step: 4
Training loss: 1.7767078876495361
Validation loss: 2.018919989466667

Epoch: 5| Step: 5
Training loss: 1.6251819133758545
Validation loss: 2.028852025667826

Epoch: 5| Step: 6
Training loss: 1.6785799264907837
Validation loss: 2.040054440498352

Epoch: 5| Step: 7
Training loss: 1.9562673568725586
Validation loss: 2.020720144112905

Epoch: 5| Step: 8
Training loss: 2.2119593620300293
Validation loss: 2.0334005455176034

Epoch: 5| Step: 9
Training loss: 2.0988693237304688
Validation loss: 1.9858454316854477

Epoch: 5| Step: 10
Training loss: 2.1276650428771973
Validation loss: 1.9861195236444473

Epoch: 5| Step: 11
Training loss: 1.813584566116333
Validation loss: 1.992411216100057

Epoch: 66| Step: 0
Training loss: 2.0230183601379395
Validation loss: 1.9944788962602615

Epoch: 5| Step: 1
Training loss: 1.7355153560638428
Validation loss: 1.982184961438179

Epoch: 5| Step: 2
Training loss: 1.8461780548095703
Validation loss: 1.978805626432101

Epoch: 5| Step: 3
Training loss: 1.5827823877334595
Validation loss: 1.9857702602942784

Epoch: 5| Step: 4
Training loss: 1.941712737083435
Validation loss: 1.9925335347652435

Epoch: 5| Step: 5
Training loss: 1.6851637363433838
Validation loss: 1.9802549133698146

Epoch: 5| Step: 6
Training loss: 1.5482014417648315
Validation loss: 1.9886844009160995

Epoch: 5| Step: 7
Training loss: 1.9232336282730103
Validation loss: 1.9904078791538875

Epoch: 5| Step: 8
Training loss: 1.7088956832885742
Validation loss: 1.9821828057368596

Epoch: 5| Step: 9
Training loss: 1.8949220180511475
Validation loss: 1.9841156800587971

Epoch: 5| Step: 10
Training loss: 2.2326722145080566
Validation loss: 1.9719029863675435

Epoch: 5| Step: 11
Training loss: 1.3553712368011475
Validation loss: 1.9601034224033356

Epoch: 67| Step: 0
Training loss: 1.495818853378296
Validation loss: 1.9613600720961888

Epoch: 5| Step: 1
Training loss: 1.3543236255645752
Validation loss: 1.951495110988617

Epoch: 5| Step: 2
Training loss: 1.6760890483856201
Validation loss: 1.9563720872004826

Epoch: 5| Step: 3
Training loss: 2.2433838844299316
Validation loss: 1.9802440106868744

Epoch: 5| Step: 4
Training loss: 1.4897887706756592
Validation loss: 1.9937049100796382

Epoch: 5| Step: 5
Training loss: 1.9616925716400146
Validation loss: 1.937041312456131

Epoch: 5| Step: 6
Training loss: 1.658200979232788
Validation loss: 1.9600389848152797

Epoch: 5| Step: 7
Training loss: 1.3283321857452393
Validation loss: 1.9594522764285405

Epoch: 5| Step: 8
Training loss: 2.642725944519043
Validation loss: 1.975241243839264

Epoch: 5| Step: 9
Training loss: 1.6300499439239502
Validation loss: 1.9846132049957912

Epoch: 5| Step: 10
Training loss: 2.2546703815460205
Validation loss: 1.9745190888643265

Epoch: 5| Step: 11
Training loss: 2.6393136978149414
Validation loss: 1.9868720869223278

Epoch: 68| Step: 0
Training loss: 2.121676206588745
Validation loss: 1.988883728782336

Epoch: 5| Step: 1
Training loss: 1.7096374034881592
Validation loss: 1.968340943257014

Epoch: 5| Step: 2
Training loss: 1.5755869150161743
Validation loss: 2.022774189710617

Epoch: 5| Step: 3
Training loss: 1.6766469478607178
Validation loss: 2.001604194442431

Epoch: 5| Step: 4
Training loss: 1.8834104537963867
Validation loss: 2.0180329432090125

Epoch: 5| Step: 5
Training loss: 1.599549651145935
Validation loss: 2.059898758927981

Epoch: 5| Step: 6
Training loss: 1.9287217855453491
Validation loss: 2.0481460640827813

Epoch: 5| Step: 7
Training loss: 1.5300171375274658
Validation loss: 2.0414443214734397

Epoch: 5| Step: 8
Training loss: 2.5391204357147217
Validation loss: 2.0520487328370414

Epoch: 5| Step: 9
Training loss: 1.7344919443130493
Validation loss: 2.0677367399136224

Epoch: 5| Step: 10
Training loss: 1.8096644878387451
Validation loss: 2.0040723433097205

Epoch: 5| Step: 11
Training loss: 2.2379610538482666
Validation loss: 1.9983250697453816

Epoch: 69| Step: 0
Training loss: 2.0943408012390137
Validation loss: 1.9722599387168884

Epoch: 5| Step: 1
Training loss: 1.96286940574646
Validation loss: 1.9836714764436085

Epoch: 5| Step: 2
Training loss: 1.585251808166504
Validation loss: 1.9688446323076885

Epoch: 5| Step: 3
Training loss: 2.1362545490264893
Validation loss: 1.956614464521408

Epoch: 5| Step: 4
Training loss: 2.0323145389556885
Validation loss: 1.9493603507677715

Epoch: 5| Step: 5
Training loss: 1.7797095775604248
Validation loss: 1.9569687296946843

Epoch: 5| Step: 6
Training loss: 1.4761685132980347
Validation loss: 1.9682418207327526

Epoch: 5| Step: 7
Training loss: 1.6762454509735107
Validation loss: 1.950234815478325

Epoch: 5| Step: 8
Training loss: 1.7383188009262085
Validation loss: 1.9604396224021912

Epoch: 5| Step: 9
Training loss: 1.8824150562286377
Validation loss: 1.9506265471378963

Epoch: 5| Step: 10
Training loss: 1.7512096166610718
Validation loss: 1.9682039817174275

Epoch: 5| Step: 11
Training loss: 1.3216218948364258
Validation loss: 1.9447535971800487

Epoch: 70| Step: 0
Training loss: 1.609229326248169
Validation loss: 1.9880356540282567

Epoch: 5| Step: 1
Training loss: 2.062770128250122
Validation loss: 1.9907349000374477

Epoch: 5| Step: 2
Training loss: 2.0968213081359863
Validation loss: 1.9971207827329636

Epoch: 5| Step: 3
Training loss: 1.367680311203003
Validation loss: 2.0174543956915536

Epoch: 5| Step: 4
Training loss: 2.173837423324585
Validation loss: 2.0423761854569116

Epoch: 5| Step: 5
Training loss: 1.317394495010376
Validation loss: 2.024019772807757

Epoch: 5| Step: 6
Training loss: 1.85991632938385
Validation loss: 2.054504230618477

Epoch: 5| Step: 7
Training loss: 1.49764084815979
Validation loss: 2.0842018822828927

Epoch: 5| Step: 8
Training loss: 2.091445207595825
Validation loss: 2.0350483109553656

Epoch: 5| Step: 9
Training loss: 1.0304687023162842
Validation loss: 2.040070583422979

Epoch: 5| Step: 10
Training loss: 2.702014446258545
Validation loss: 2.0508534014225006

Epoch: 5| Step: 11
Training loss: 2.1413631439208984
Validation loss: 1.9968289186557133

Epoch: 71| Step: 0
Training loss: 1.2709884643554688
Validation loss: 1.9862623711427052

Epoch: 5| Step: 1
Training loss: 2.203282356262207
Validation loss: 1.980962519844373

Epoch: 5| Step: 2
Training loss: 1.534044861793518
Validation loss: 1.9835553516944249

Epoch: 5| Step: 3
Training loss: 2.1139533519744873
Validation loss: 1.9842060059309006

Epoch: 5| Step: 4
Training loss: 1.4573440551757812
Validation loss: 1.9516844203074772

Epoch: 5| Step: 5
Training loss: 2.207227945327759
Validation loss: 1.9632878204186757

Epoch: 5| Step: 6
Training loss: 2.2045578956604004
Validation loss: 1.9691250026226044

Epoch: 5| Step: 7
Training loss: 1.692201018333435
Validation loss: 1.9564709117015202

Epoch: 5| Step: 8
Training loss: 1.3912720680236816
Validation loss: 1.9898612201213837

Epoch: 5| Step: 9
Training loss: 1.3362834453582764
Validation loss: 1.9524608900149663

Epoch: 5| Step: 10
Training loss: 2.027681827545166
Validation loss: 1.976724495490392

Epoch: 5| Step: 11
Training loss: 2.9197895526885986
Validation loss: 1.9790825247764587

Epoch: 72| Step: 0
Training loss: 1.6096222400665283
Validation loss: 1.9973326722780864

Epoch: 5| Step: 1
Training loss: 1.7931667566299438
Validation loss: 2.0438158214092255

Epoch: 5| Step: 2
Training loss: 1.639182686805725
Validation loss: 1.992013285557429

Epoch: 5| Step: 3
Training loss: 2.348768949508667
Validation loss: 1.9985078275203705

Epoch: 5| Step: 4
Training loss: 2.0517160892486572
Validation loss: 2.013142466545105

Epoch: 5| Step: 5
Training loss: 2.2903456687927246
Validation loss: 2.040348847707113

Epoch: 5| Step: 6
Training loss: 1.3327534198760986
Validation loss: 2.001547714074453

Epoch: 5| Step: 7
Training loss: 1.9673722982406616
Validation loss: 2.0117407391468682

Epoch: 5| Step: 8
Training loss: 1.0981667041778564
Validation loss: 2.026923576990763

Epoch: 5| Step: 9
Training loss: 1.811087965965271
Validation loss: 1.9967669645945232

Epoch: 5| Step: 10
Training loss: 1.8006480932235718
Validation loss: 2.0119106521209082

Epoch: 5| Step: 11
Training loss: 1.0109130144119263
Validation loss: 1.9614998002847035

Epoch: 73| Step: 0
Training loss: 1.6273767948150635
Validation loss: 2.032972310980161

Epoch: 5| Step: 1
Training loss: 2.3712270259857178
Validation loss: 1.9839523335297902

Epoch: 5| Step: 2
Training loss: 1.3499200344085693
Validation loss: 2.003832439581553

Epoch: 5| Step: 3
Training loss: 1.9462487697601318
Validation loss: 1.9971543004115422

Epoch: 5| Step: 4
Training loss: 1.205476999282837
Validation loss: 1.9602847248315811

Epoch: 5| Step: 5
Training loss: 1.4592666625976562
Validation loss: 1.9802916397651036

Epoch: 5| Step: 6
Training loss: 1.1461585760116577
Validation loss: 1.9779125501712163

Epoch: 5| Step: 7
Training loss: 2.379436731338501
Validation loss: 1.9923304716746013

Epoch: 5| Step: 8
Training loss: 2.3818840980529785
Validation loss: 1.9874567588170369

Epoch: 5| Step: 9
Training loss: 1.8812220096588135
Validation loss: 1.9718177715937297

Epoch: 5| Step: 10
Training loss: 1.6954063177108765
Validation loss: 2.0136800507704415

Epoch: 5| Step: 11
Training loss: 2.4829816818237305
Validation loss: 1.9956308454275131

Epoch: 74| Step: 0
Training loss: 1.4025413990020752
Validation loss: 2.0477507412433624

Epoch: 5| Step: 1
Training loss: 1.4111658334732056
Validation loss: 2.028888687491417

Epoch: 5| Step: 2
Training loss: 1.8198349475860596
Validation loss: 2.027248278260231

Epoch: 5| Step: 3
Training loss: 1.6764522790908813
Validation loss: 2.064592093229294

Epoch: 5| Step: 4
Training loss: 2.52081561088562
Validation loss: 2.092764521638552

Epoch: 5| Step: 5
Training loss: 2.277986526489258
Validation loss: 2.120084971189499

Epoch: 5| Step: 6
Training loss: 2.1436972618103027
Validation loss: 2.0440025528271994

Epoch: 5| Step: 7
Training loss: 1.4456589221954346
Validation loss: 2.07181279361248

Epoch: 5| Step: 8
Training loss: 1.7218097448349
Validation loss: 2.0006130586067834

Epoch: 5| Step: 9
Training loss: 1.2735933065414429
Validation loss: 2.0214965840180716

Epoch: 5| Step: 10
Training loss: 2.3543033599853516
Validation loss: 1.9870214064915974

Epoch: 5| Step: 11
Training loss: 0.6387913823127747
Validation loss: 1.96343199412028

Epoch: 75| Step: 0
Training loss: 1.5370266437530518
Validation loss: 1.9901042034228642

Epoch: 5| Step: 1
Training loss: 2.1286206245422363
Validation loss: 1.9689835508664448

Epoch: 5| Step: 2
Training loss: 2.1331405639648438
Validation loss: 1.9571652213732402

Epoch: 5| Step: 3
Training loss: 2.1659164428710938
Validation loss: 1.9859386384487152

Epoch: 5| Step: 4
Training loss: 1.6253970861434937
Validation loss: 1.9571378032366435

Epoch: 5| Step: 5
Training loss: 1.1770837306976318
Validation loss: 1.9802350103855133

Epoch: 5| Step: 6
Training loss: 1.3038172721862793
Validation loss: 1.9595785439014435

Epoch: 5| Step: 7
Training loss: 2.11091685295105
Validation loss: 2.026909510294596

Epoch: 5| Step: 8
Training loss: 1.6576521396636963
Validation loss: 1.9830102721850078

Epoch: 5| Step: 9
Training loss: 1.7509129047393799
Validation loss: 2.0040076275666556

Epoch: 5| Step: 10
Training loss: 1.9861475229263306
Validation loss: 2.0009858856598535

Epoch: 5| Step: 11
Training loss: 0.9587066173553467
Validation loss: 2.035746450225512

Epoch: 76| Step: 0
Training loss: 2.093043327331543
Validation loss: 1.9686035911242168

Epoch: 5| Step: 1
Training loss: 1.4410520792007446
Validation loss: 2.002442037065824

Epoch: 5| Step: 2
Training loss: 1.6844110488891602
Validation loss: 2.0034458537896476

Epoch: 5| Step: 3
Training loss: 1.7561371326446533
Validation loss: 2.018860310316086

Epoch: 5| Step: 4
Training loss: 1.762620210647583
Validation loss: 2.0138427913188934

Epoch: 5| Step: 5
Training loss: 1.6269896030426025
Validation loss: 1.97104208668073

Epoch: 5| Step: 6
Training loss: 1.6193288564682007
Validation loss: 2.0045573115348816

Epoch: 5| Step: 7
Training loss: 1.3476498126983643
Validation loss: 2.0418889025847116

Epoch: 5| Step: 8
Training loss: 1.8195215463638306
Validation loss: 2.0210417012373605

Epoch: 5| Step: 9
Training loss: 1.9731109142303467
Validation loss: 2.041091655691465

Epoch: 5| Step: 10
Training loss: 1.945471167564392
Validation loss: 2.013070454200109

Epoch: 5| Step: 11
Training loss: 2.604107618331909
Validation loss: 2.031122257312139

Epoch: 77| Step: 0
Training loss: 2.0514321327209473
Validation loss: 2.0079078525304794

Epoch: 5| Step: 1
Training loss: 2.0453999042510986
Validation loss: 1.9850998918215434

Epoch: 5| Step: 2
Training loss: 1.9011722803115845
Validation loss: 1.94791679084301

Epoch: 5| Step: 3
Training loss: 0.931616485118866
Validation loss: 1.981169432401657

Epoch: 5| Step: 4
Training loss: 1.582657814025879
Validation loss: 1.9726517548163731

Epoch: 5| Step: 5
Training loss: 1.603272795677185
Validation loss: 1.9802266160647075

Epoch: 5| Step: 6
Training loss: 2.5365114212036133
Validation loss: 1.9289842694997787

Epoch: 5| Step: 7
Training loss: 1.3092796802520752
Validation loss: 1.9584383815526962

Epoch: 5| Step: 8
Training loss: 2.0959982872009277
Validation loss: 1.9599464684724808

Epoch: 5| Step: 9
Training loss: 1.6616184711456299
Validation loss: 1.970437193910281

Epoch: 5| Step: 10
Training loss: 1.6399005651474
Validation loss: 1.9896599799394608

Epoch: 5| Step: 11
Training loss: 3.485344886779785
Validation loss: 1.9768723547458649

Epoch: 78| Step: 0
Training loss: 2.022238254547119
Validation loss: 1.9745976775884628

Epoch: 5| Step: 1
Training loss: 2.182246446609497
Validation loss: 1.9676542232433956

Epoch: 5| Step: 2
Training loss: 1.450816035270691
Validation loss: 1.9908689210812252

Epoch: 5| Step: 3
Training loss: 1.4755152463912964
Validation loss: 2.0492955346902213

Epoch: 5| Step: 4
Training loss: 1.5121870040893555
Validation loss: 2.031644160548846

Epoch: 5| Step: 5
Training loss: 1.8557074069976807
Validation loss: 2.019286180535952

Epoch: 5| Step: 6
Training loss: 1.9293718338012695
Validation loss: 1.9921673834323883

Epoch: 5| Step: 7
Training loss: 1.5278221368789673
Validation loss: 2.0342039267222085

Epoch: 5| Step: 8
Training loss: 1.6101394891738892
Validation loss: 2.0494559655586877

Epoch: 5| Step: 9
Training loss: 1.9382272958755493
Validation loss: 1.9882196933031082

Epoch: 5| Step: 10
Training loss: 1.4902210235595703
Validation loss: 1.960166911284129

Epoch: 5| Step: 11
Training loss: 2.8966574668884277
Validation loss: 1.9722204804420471

Epoch: 79| Step: 0
Training loss: 1.2269420623779297
Validation loss: 1.976841206351916

Epoch: 5| Step: 1
Training loss: 2.170830249786377
Validation loss: 1.959051216642062

Epoch: 5| Step: 2
Training loss: 2.021484851837158
Validation loss: 1.9618556002775829

Epoch: 5| Step: 3
Training loss: 2.0029685497283936
Validation loss: 1.964822272459666

Epoch: 5| Step: 4
Training loss: 2.064357280731201
Validation loss: 1.9847959876060486

Epoch: 5| Step: 5
Training loss: 1.6502958536148071
Validation loss: 1.9804677814245224

Epoch: 5| Step: 6
Training loss: 1.4377583265304565
Validation loss: 1.947081337372462

Epoch: 5| Step: 7
Training loss: 2.458545684814453
Validation loss: 1.936141197880109

Epoch: 5| Step: 8
Training loss: 1.6164510250091553
Validation loss: 1.9625570178031921

Epoch: 5| Step: 9
Training loss: 1.6663291454315186
Validation loss: 1.9495622913042705

Epoch: 5| Step: 10
Training loss: 1.6052840948104858
Validation loss: 1.9354124416907628

Epoch: 5| Step: 11
Training loss: 2.3119966983795166
Validation loss: 1.9961300988992055

Epoch: 80| Step: 0
Training loss: 1.6088180541992188
Validation loss: 1.9785272131363552

Epoch: 5| Step: 1
Training loss: 2.2112011909484863
Validation loss: 2.055800810456276

Epoch: 5| Step: 2
Training loss: 2.3681042194366455
Validation loss: 2.017473667860031

Epoch: 5| Step: 3
Training loss: 1.2744594812393188
Validation loss: 2.013575846950213

Epoch: 5| Step: 4
Training loss: 1.6708393096923828
Validation loss: 1.9707981248696644

Epoch: 5| Step: 5
Training loss: 1.5379865169525146
Validation loss: 1.9944281627734501

Epoch: 5| Step: 6
Training loss: 1.4319913387298584
Validation loss: 1.9941090593735378

Epoch: 5| Step: 7
Training loss: 1.625044584274292
Validation loss: 2.0232271254062653

Epoch: 5| Step: 8
Training loss: 1.9383481740951538
Validation loss: 2.0266344050566354

Epoch: 5| Step: 9
Training loss: 1.5633424520492554
Validation loss: 2.0023629715045295

Epoch: 5| Step: 10
Training loss: 1.5388158559799194
Validation loss: 1.9681234409411748

Epoch: 5| Step: 11
Training loss: 2.588930606842041
Validation loss: 1.987009068330129

Epoch: 81| Step: 0
Training loss: 1.5570261478424072
Validation loss: 2.0122070660193763

Epoch: 5| Step: 1
Training loss: 1.537499189376831
Validation loss: 2.0045418639977775

Epoch: 5| Step: 2
Training loss: 1.5191080570220947
Validation loss: 2.0434104849894843

Epoch: 5| Step: 3
Training loss: 2.4856021404266357
Validation loss: 2.0267287542422614

Epoch: 5| Step: 4
Training loss: 1.4095582962036133
Validation loss: 1.9830199281374614

Epoch: 5| Step: 5
Training loss: 1.7883236408233643
Validation loss: 2.007249509294828

Epoch: 5| Step: 6
Training loss: 1.364454746246338
Validation loss: 2.034366955359777

Epoch: 5| Step: 7
Training loss: 1.9088596105575562
Validation loss: 1.9791475633780162

Epoch: 5| Step: 8
Training loss: 1.7903589010238647
Validation loss: 1.9847001979748409

Epoch: 5| Step: 9
Training loss: 1.8567136526107788
Validation loss: 1.9678912262121837

Epoch: 5| Step: 10
Training loss: 1.390312671661377
Validation loss: 1.9580833117167156

Epoch: 5| Step: 11
Training loss: 3.1469175815582275
Validation loss: 1.9982800881067913

Epoch: 82| Step: 0
Training loss: 2.2877578735351562
Validation loss: 1.9834253042936325

Epoch: 5| Step: 1
Training loss: 1.8972046375274658
Validation loss: 1.9966040005286534

Epoch: 5| Step: 2
Training loss: 1.4395419359207153
Validation loss: 1.967766394217809

Epoch: 5| Step: 3
Training loss: 1.6519966125488281
Validation loss: 1.9583833614985149

Epoch: 5| Step: 4
Training loss: 1.7289764881134033
Validation loss: 1.964771827061971

Epoch: 5| Step: 5
Training loss: 1.7855567932128906
Validation loss: 1.9824887414773305

Epoch: 5| Step: 6
Training loss: 1.3221042156219482
Validation loss: 1.977339933315913

Epoch: 5| Step: 7
Training loss: 1.5791301727294922
Validation loss: 1.9774542848269145

Epoch: 5| Step: 8
Training loss: 1.5442652702331543
Validation loss: 1.964899907509486

Epoch: 5| Step: 9
Training loss: 1.6496877670288086
Validation loss: 1.9648886273304622

Epoch: 5| Step: 10
Training loss: 1.6595404148101807
Validation loss: 1.9748181998729706

Epoch: 5| Step: 11
Training loss: 1.2936991453170776
Validation loss: 2.0136076509952545

Epoch: 83| Step: 0
Training loss: 2.0321407318115234
Validation loss: 1.9895980805158615

Epoch: 5| Step: 1
Training loss: 1.9298839569091797
Validation loss: 1.9854485889275868

Epoch: 5| Step: 2
Training loss: 1.9161827564239502
Validation loss: 1.9819849977890651

Epoch: 5| Step: 3
Training loss: 1.812101125717163
Validation loss: 1.9863367279370625

Epoch: 5| Step: 4
Training loss: 1.4384053945541382
Validation loss: 1.9444296310345333

Epoch: 5| Step: 5
Training loss: 1.3314592838287354
Validation loss: 1.9942798366149266

Epoch: 5| Step: 6
Training loss: 1.7811247110366821
Validation loss: 1.9647798140843709

Epoch: 5| Step: 7
Training loss: 1.6761023998260498
Validation loss: 2.0063558220863342

Epoch: 5| Step: 8
Training loss: 1.8007380962371826
Validation loss: 2.0266898026069007

Epoch: 5| Step: 9
Training loss: 1.313437581062317
Validation loss: 1.9781439006328583

Epoch: 5| Step: 10
Training loss: 1.6192830801010132
Validation loss: 1.9787040799856186

Epoch: 5| Step: 11
Training loss: 2.3377366065979004
Validation loss: 1.9701943347851436

Epoch: 84| Step: 0
Training loss: 2.0148801803588867
Validation loss: 1.993068774541219

Epoch: 5| Step: 1
Training loss: 1.5512088537216187
Validation loss: 1.9432371656099956

Epoch: 5| Step: 2
Training loss: 1.9505828619003296
Validation loss: 1.9209853559732437

Epoch: 5| Step: 3
Training loss: 1.5240490436553955
Validation loss: 1.959323063492775

Epoch: 5| Step: 4
Training loss: 1.9860470294952393
Validation loss: 1.9394859075546265

Epoch: 5| Step: 5
Training loss: 1.7008254528045654
Validation loss: 1.9714837968349457

Epoch: 5| Step: 6
Training loss: 2.136920213699341
Validation loss: 1.9331365178028743

Epoch: 5| Step: 7
Training loss: 0.9337717890739441
Validation loss: 1.9420642505089443

Epoch: 5| Step: 8
Training loss: 1.6293704509735107
Validation loss: 2.0035337259372077

Epoch: 5| Step: 9
Training loss: 1.3964519500732422
Validation loss: 1.9704072227080662

Epoch: 5| Step: 10
Training loss: 1.975555658340454
Validation loss: 2.0301538606484733

Epoch: 5| Step: 11
Training loss: 2.012810707092285
Validation loss: 2.0099167972803116

Epoch: 85| Step: 0
Training loss: 1.6492369174957275
Validation loss: 2.079471935828527

Epoch: 5| Step: 1
Training loss: 1.448809027671814
Validation loss: 2.0298211574554443

Epoch: 5| Step: 2
Training loss: 1.68527090549469
Validation loss: 2.0479281644026437

Epoch: 5| Step: 3
Training loss: 1.7559149265289307
Validation loss: 2.0380845069885254

Epoch: 5| Step: 4
Training loss: 1.7618076801300049
Validation loss: 2.0687997291485467

Epoch: 5| Step: 5
Training loss: 2.21006441116333
Validation loss: 1.9959877332051594

Epoch: 5| Step: 6
Training loss: 1.5670315027236938
Validation loss: 1.9957252144813538

Epoch: 5| Step: 7
Training loss: 1.6741325855255127
Validation loss: 1.9569280097881954

Epoch: 5| Step: 8
Training loss: 1.7079885005950928
Validation loss: 1.9745567291975021

Epoch: 5| Step: 9
Training loss: 1.4291713237762451
Validation loss: 1.9732242127259572

Epoch: 5| Step: 10
Training loss: 1.6030973196029663
Validation loss: 1.9525796125332515

Epoch: 5| Step: 11
Training loss: 1.3983384370803833
Validation loss: 1.9620086054007213

Epoch: 86| Step: 0
Training loss: 1.9733855724334717
Validation loss: 1.9557711730400722

Epoch: 5| Step: 1
Training loss: 1.5776063203811646
Validation loss: 1.9654477039972942

Epoch: 5| Step: 2
Training loss: 2.0434305667877197
Validation loss: 1.9549557914336522

Epoch: 5| Step: 3
Training loss: 1.609898567199707
Validation loss: 1.984802986184756

Epoch: 5| Step: 4
Training loss: 1.786429762840271
Validation loss: 1.9546076903740566

Epoch: 5| Step: 5
Training loss: 1.5242314338684082
Validation loss: 1.9831138948599498

Epoch: 5| Step: 6
Training loss: 1.6471307277679443
Validation loss: 1.9370166957378387

Epoch: 5| Step: 7
Training loss: 1.4868748188018799
Validation loss: 1.9772991488377254

Epoch: 5| Step: 8
Training loss: 1.6913961172103882
Validation loss: 1.998635749022166

Epoch: 5| Step: 9
Training loss: 2.0816433429718018
Validation loss: 1.975240225593249

Epoch: 5| Step: 10
Training loss: 1.6930205821990967
Validation loss: 2.0122764011224112

Epoch: 5| Step: 11
Training loss: 1.1061148643493652
Validation loss: 2.0058706402778625

Epoch: 87| Step: 0
Training loss: 1.6450614929199219
Validation loss: 2.0031121373176575

Epoch: 5| Step: 1
Training loss: 1.6584899425506592
Validation loss: 1.9960256864627202

Epoch: 5| Step: 2
Training loss: 1.385839819908142
Validation loss: 2.052535836895307

Epoch: 5| Step: 3
Training loss: 1.900694489479065
Validation loss: 2.005394940574964

Epoch: 5| Step: 4
Training loss: 1.5466914176940918
Validation loss: 2.043797473112742

Epoch: 5| Step: 5
Training loss: 1.9753730297088623
Validation loss: 1.9719707071781158

Epoch: 5| Step: 6
Training loss: 1.4721205234527588
Validation loss: 1.9663370350996654

Epoch: 5| Step: 7
Training loss: 1.6904065608978271
Validation loss: 1.9838685194651287

Epoch: 5| Step: 8
Training loss: 1.2184884548187256
Validation loss: 1.9812216113011043

Epoch: 5| Step: 9
Training loss: 1.7591371536254883
Validation loss: 1.9711566865444183

Epoch: 5| Step: 10
Training loss: 2.157869815826416
Validation loss: 1.9663740694522858

Epoch: 5| Step: 11
Training loss: 1.1309688091278076
Validation loss: 1.9806418021519978

Epoch: 88| Step: 0
Training loss: 1.4312777519226074
Validation loss: 1.9986991633971531

Epoch: 5| Step: 1
Training loss: 1.8933051824569702
Validation loss: 1.9584637532631557

Epoch: 5| Step: 2
Training loss: 1.5096644163131714
Validation loss: 2.0427910486857095

Epoch: 5| Step: 3
Training loss: 1.4435091018676758
Validation loss: 2.0081496139367423

Epoch: 5| Step: 4
Training loss: 1.4650201797485352
Validation loss: 2.0087151527404785

Epoch: 5| Step: 5
Training loss: 1.2260596752166748
Validation loss: 2.058141832550367

Epoch: 5| Step: 6
Training loss: 1.8453361988067627
Validation loss: 2.0476843068997064

Epoch: 5| Step: 7
Training loss: 1.5282573699951172
Validation loss: 2.007854148745537

Epoch: 5| Step: 8
Training loss: 2.0683984756469727
Validation loss: 2.020073120792707

Epoch: 5| Step: 9
Training loss: 1.6483688354492188
Validation loss: 2.0479824046293893

Epoch: 5| Step: 10
Training loss: 2.390101909637451
Validation loss: 2.04060331483682

Epoch: 5| Step: 11
Training loss: 0.5370453596115112
Validation loss: 2.006232182184855

Epoch: 89| Step: 0
Training loss: 1.404796838760376
Validation loss: 2.021389270822207

Epoch: 5| Step: 1
Training loss: 1.6068661212921143
Validation loss: 1.990059291323026

Epoch: 5| Step: 2
Training loss: 1.2374852895736694
Validation loss: 2.023972968260447

Epoch: 5| Step: 3
Training loss: 1.6093858480453491
Validation loss: 2.0027100443840027

Epoch: 5| Step: 4
Training loss: 1.494929313659668
Validation loss: 1.9688257724046707

Epoch: 5| Step: 5
Training loss: 1.5796903371810913
Validation loss: 2.033585195740064

Epoch: 5| Step: 6
Training loss: 2.358128786087036
Validation loss: 2.033079912265142

Epoch: 5| Step: 7
Training loss: 1.4495853185653687
Validation loss: 2.012483616669973

Epoch: 5| Step: 8
Training loss: 1.757716417312622
Validation loss: 2.017537216345469

Epoch: 5| Step: 9
Training loss: 1.6635425090789795
Validation loss: 2.0065651684999466

Epoch: 5| Step: 10
Training loss: 2.013159990310669
Validation loss: 1.9663602858781815

Epoch: 5| Step: 11
Training loss: 2.4354729652404785
Validation loss: 1.9229896018902461

Epoch: 90| Step: 0
Training loss: 1.7382272481918335
Validation loss: 1.9529522508382797

Epoch: 5| Step: 1
Training loss: 1.5841178894042969
Validation loss: 1.9555521259705226

Epoch: 5| Step: 2
Training loss: 1.6327524185180664
Validation loss: 1.950803538163503

Epoch: 5| Step: 3
Training loss: 1.615860939025879
Validation loss: 2.0131530662377677

Epoch: 5| Step: 4
Training loss: 1.9830248355865479
Validation loss: 1.9843739817539852

Epoch: 5| Step: 5
Training loss: 1.5547488927841187
Validation loss: 2.003017231822014

Epoch: 5| Step: 6
Training loss: 1.0154907703399658
Validation loss: 2.015030632416407

Epoch: 5| Step: 7
Training loss: 1.5645843744277954
Validation loss: 2.0231451988220215

Epoch: 5| Step: 8
Training loss: 1.9469356536865234
Validation loss: 2.0524463454882302

Epoch: 5| Step: 9
Training loss: 1.6694399118423462
Validation loss: 2.0672969023386636

Epoch: 5| Step: 10
Training loss: 1.964597463607788
Validation loss: 2.017909283439318

Epoch: 5| Step: 11
Training loss: 1.937971830368042
Validation loss: 2.0667982002099357

Epoch: 91| Step: 0
Training loss: 1.5443837642669678
Validation loss: 2.0038937280575433

Epoch: 5| Step: 1
Training loss: 1.4355353116989136
Validation loss: 1.9888467192649841

Epoch: 5| Step: 2
Training loss: 1.3486652374267578
Validation loss: 1.956885462005933

Epoch: 5| Step: 3
Training loss: 1.652364730834961
Validation loss: 1.9543310850858688

Epoch: 5| Step: 4
Training loss: 2.152745485305786
Validation loss: 1.9400355915228527

Epoch: 5| Step: 5
Training loss: 1.8815065622329712
Validation loss: 1.9573877304792404

Epoch: 5| Step: 6
Training loss: 1.34481680393219
Validation loss: 1.98626775542895

Epoch: 5| Step: 7
Training loss: 2.1251320838928223
Validation loss: 1.9700316588083904

Epoch: 5| Step: 8
Training loss: 1.5479859113693237
Validation loss: 1.9738600502411525

Epoch: 5| Step: 9
Training loss: 2.04337215423584
Validation loss: 1.953288142879804

Epoch: 5| Step: 10
Training loss: 1.338958978652954
Validation loss: 2.013979494571686

Epoch: 5| Step: 11
Training loss: 1.0153952836990356
Validation loss: 1.9921001096566517

Epoch: 92| Step: 0
Training loss: 1.8623073101043701
Validation loss: 2.0400454004605613

Epoch: 5| Step: 1
Training loss: 1.7405798435211182
Validation loss: 2.0800147652626038

Epoch: 5| Step: 2
Training loss: 1.6252959966659546
Validation loss: 2.0720179279645285

Epoch: 5| Step: 3
Training loss: 1.9751882553100586
Validation loss: 2.0838373551766076

Epoch: 5| Step: 4
Training loss: 1.5940837860107422
Validation loss: 2.0662484069665275

Epoch: 5| Step: 5
Training loss: 1.43897545337677
Validation loss: 2.041217476129532

Epoch: 5| Step: 6
Training loss: 1.6761192083358765
Validation loss: 2.037189930677414

Epoch: 5| Step: 7
Training loss: 1.6099967956542969
Validation loss: 2.0208838333686194

Epoch: 5| Step: 8
Training loss: 1.3626424074172974
Validation loss: 2.015767738223076

Epoch: 5| Step: 9
Training loss: 1.4125802516937256
Validation loss: 1.969697838028272

Epoch: 5| Step: 10
Training loss: 1.8301305770874023
Validation loss: 1.971085583170255

Epoch: 5| Step: 11
Training loss: 1.586888313293457
Validation loss: 1.978956754008929

Epoch: 93| Step: 0
Training loss: 1.717816948890686
Validation loss: 1.927194893360138

Epoch: 5| Step: 1
Training loss: 2.0645840167999268
Validation loss: 1.9412620862325032

Epoch: 5| Step: 2
Training loss: 1.493747591972351
Validation loss: 1.9519254714250565

Epoch: 5| Step: 3
Training loss: 1.2609139680862427
Validation loss: 1.981539989511172

Epoch: 5| Step: 4
Training loss: 1.4397051334381104
Validation loss: 2.0089381486177444

Epoch: 5| Step: 5
Training loss: 1.8288538455963135
Validation loss: 2.0044500132401786

Epoch: 5| Step: 6
Training loss: 1.397740364074707
Validation loss: 2.0536015232404075

Epoch: 5| Step: 7
Training loss: 1.630408525466919
Validation loss: 2.0412383675575256

Epoch: 5| Step: 8
Training loss: 1.7088596820831299
Validation loss: 2.0639973978201547

Epoch: 5| Step: 9
Training loss: 1.2656629085540771
Validation loss: 2.0139970729748407

Epoch: 5| Step: 10
Training loss: 1.9942487478256226
Validation loss: 2.063494548201561

Epoch: 5| Step: 11
Training loss: 2.01198410987854
Validation loss: 2.0145196865002313

Epoch: 94| Step: 0
Training loss: 2.106926679611206
Validation loss: 1.996793121099472

Epoch: 5| Step: 1
Training loss: 0.9639418721199036
Validation loss: 1.9953816682100296

Epoch: 5| Step: 2
Training loss: 1.6754928827285767
Validation loss: 1.9668097247680028

Epoch: 5| Step: 3
Training loss: 1.3121435642242432
Validation loss: 1.9859229276577632

Epoch: 5| Step: 4
Training loss: 1.7301479578018188
Validation loss: 1.9737056444088619

Epoch: 5| Step: 5
Training loss: 1.7005596160888672
Validation loss: 1.9643748303254445

Epoch: 5| Step: 6
Training loss: 1.5796021223068237
Validation loss: 1.9220948616663616

Epoch: 5| Step: 7
Training loss: 2.0198044776916504
Validation loss: 1.9397185444831848

Epoch: 5| Step: 8
Training loss: 1.8612072467803955
Validation loss: 1.9425756235917409

Epoch: 5| Step: 9
Training loss: 1.6761434078216553
Validation loss: 1.9595651874939601

Epoch: 5| Step: 10
Training loss: 1.3202295303344727
Validation loss: 1.9681083957354228

Epoch: 5| Step: 11
Training loss: 2.29300856590271
Validation loss: 2.0412249118089676

Epoch: 95| Step: 0
Training loss: 1.3807313442230225
Validation loss: 2.034778450926145

Epoch: 5| Step: 1
Training loss: 1.4328280687332153
Validation loss: 2.01276396214962

Epoch: 5| Step: 2
Training loss: 1.4902822971343994
Validation loss: 2.025126278400421

Epoch: 5| Step: 3
Training loss: 2.0965380668640137
Validation loss: 2.035300388932228

Epoch: 5| Step: 4
Training loss: 1.5845627784729004
Validation loss: 2.048970172802607

Epoch: 5| Step: 5
Training loss: 1.1996076107025146
Validation loss: 2.03968553741773

Epoch: 5| Step: 6
Training loss: 1.7824323177337646
Validation loss: 2.03267436226209

Epoch: 5| Step: 7
Training loss: 2.1558914184570312
Validation loss: 2.043657600879669

Epoch: 5| Step: 8
Training loss: 1.3925397396087646
Validation loss: 1.989881490667661

Epoch: 5| Step: 9
Training loss: 1.5495244264602661
Validation loss: 2.012332797050476

Epoch: 5| Step: 10
Training loss: 1.3072768449783325
Validation loss: 1.9733785937229793

Epoch: 5| Step: 11
Training loss: 1.7299907207489014
Validation loss: 2.0052214761575065

Epoch: 96| Step: 0
Training loss: 1.6892731189727783
Validation loss: 2.0014662643273673

Epoch: 5| Step: 1
Training loss: 1.6716150045394897
Validation loss: 1.9865069339672725

Epoch: 5| Step: 2
Training loss: 1.8246574401855469
Validation loss: 1.989979475736618

Epoch: 5| Step: 3
Training loss: 1.245057463645935
Validation loss: 1.9578298777341843

Epoch: 5| Step: 4
Training loss: 1.5732002258300781
Validation loss: 1.9624424030383427

Epoch: 5| Step: 5
Training loss: 1.2497799396514893
Validation loss: 1.9896621604760487

Epoch: 5| Step: 6
Training loss: 1.6042125225067139
Validation loss: 1.9813064932823181

Epoch: 5| Step: 7
Training loss: 1.8519599437713623
Validation loss: 1.9788702030976613

Epoch: 5| Step: 8
Training loss: 2.1748087406158447
Validation loss: 2.0032368699709573

Epoch: 5| Step: 9
Training loss: 1.509948492050171
Validation loss: 2.0124529947837195

Epoch: 5| Step: 10
Training loss: 1.3485870361328125
Validation loss: 2.003166049718857

Epoch: 5| Step: 11
Training loss: 1.8301458358764648
Validation loss: 2.0215133726596832

Epoch: 97| Step: 0
Training loss: 1.0719839334487915
Validation loss: 2.0393057266871133

Epoch: 5| Step: 1
Training loss: 1.945880651473999
Validation loss: 2.0092812975247702

Epoch: 5| Step: 2
Training loss: 1.2988035678863525
Validation loss: 1.9882757812738419

Epoch: 5| Step: 3
Training loss: 1.6194827556610107
Validation loss: 1.9764351298411686

Epoch: 5| Step: 4
Training loss: 1.3448166847229004
Validation loss: 1.9788496394952138

Epoch: 5| Step: 5
Training loss: 2.1289303302764893
Validation loss: 1.9783791502316792

Epoch: 5| Step: 6
Training loss: 1.9698196649551392
Validation loss: 1.9740481823682785

Epoch: 5| Step: 7
Training loss: 1.7188310623168945
Validation loss: 1.9748745014270146

Epoch: 5| Step: 8
Training loss: 1.1967499256134033
Validation loss: 1.9683097004890442

Epoch: 5| Step: 9
Training loss: 1.619978904724121
Validation loss: 1.998414193590482

Epoch: 5| Step: 10
Training loss: 1.30810546875
Validation loss: 2.0465143769979477

Epoch: 5| Step: 11
Training loss: 1.7411059141159058
Validation loss: 2.006912335753441

Epoch: 98| Step: 0
Training loss: 1.3315672874450684
Validation loss: 1.9997776448726654

Epoch: 5| Step: 1
Training loss: 1.5240330696105957
Validation loss: 2.0060331225395203

Epoch: 5| Step: 2
Training loss: 1.8022218942642212
Validation loss: 2.0181765655676522

Epoch: 5| Step: 3
Training loss: 1.244118332862854
Validation loss: 1.9860361764828365

Epoch: 5| Step: 4
Training loss: 1.6904579401016235
Validation loss: 1.9749147643645604

Epoch: 5| Step: 5
Training loss: 1.9846235513687134
Validation loss: 1.9754774570465088

Epoch: 5| Step: 6
Training loss: 2.065335512161255
Validation loss: 1.9881818344195683

Epoch: 5| Step: 7
Training loss: 1.1495484113693237
Validation loss: 1.975893422961235

Epoch: 5| Step: 8
Training loss: 1.79507577419281
Validation loss: 1.9632213513056438

Epoch: 5| Step: 9
Training loss: 1.4431442022323608
Validation loss: 1.9751706421375275

Epoch: 5| Step: 10
Training loss: 1.1801621913909912
Validation loss: 1.9666763494412105

Epoch: 5| Step: 11
Training loss: 1.5919420719146729
Validation loss: 1.9777686595916748

Epoch: 99| Step: 0
Training loss: 1.3559789657592773
Validation loss: 1.9649881273508072

Epoch: 5| Step: 1
Training loss: 1.3887896537780762
Validation loss: 1.970557043949763

Epoch: 5| Step: 2
Training loss: 1.3960829973220825
Validation loss: 1.9904316167036693

Epoch: 5| Step: 3
Training loss: 0.7955349683761597
Validation loss: 1.9931520173947017

Epoch: 5| Step: 4
Training loss: 1.8228561878204346
Validation loss: 2.0530385126670203

Epoch: 5| Step: 5
Training loss: 1.5025372505187988
Validation loss: 2.0529102881749473

Epoch: 5| Step: 6
Training loss: 1.179233193397522
Validation loss: 2.0443613876899085

Epoch: 5| Step: 7
Training loss: 1.8419700860977173
Validation loss: 2.057859147588412

Epoch: 5| Step: 8
Training loss: 2.1602425575256348
Validation loss: 2.0228628665208817

Epoch: 5| Step: 9
Training loss: 1.756813406944275
Validation loss: 1.9975730180740356

Epoch: 5| Step: 10
Training loss: 1.676910638809204
Validation loss: 1.9451720068852107

Epoch: 5| Step: 11
Training loss: 2.5242302417755127
Validation loss: 1.953268438577652

Epoch: 100| Step: 0
Training loss: 1.7986074686050415
Validation loss: 1.918504590789477

Epoch: 5| Step: 1
Training loss: 1.575446367263794
Validation loss: 1.986090327302615

Epoch: 5| Step: 2
Training loss: 1.5420963764190674
Validation loss: 1.8946893513202667

Epoch: 5| Step: 3
Training loss: 2.123462677001953
Validation loss: 1.9260838975509007

Epoch: 5| Step: 4
Training loss: 1.7834594249725342
Validation loss: 1.9599086493253708

Epoch: 5| Step: 5
Training loss: 1.31063973903656
Validation loss: 1.9721228281656902

Epoch: 5| Step: 6
Training loss: 1.4467289447784424
Validation loss: 2.0476297587156296

Epoch: 5| Step: 7
Training loss: 1.171090841293335
Validation loss: 2.034895117084185

Epoch: 5| Step: 8
Training loss: 1.3366508483886719
Validation loss: 1.9986361861228943

Epoch: 5| Step: 9
Training loss: 1.7585853338241577
Validation loss: 1.9991492579380672

Epoch: 5| Step: 10
Training loss: 1.4147870540618896
Validation loss: 2.0231614311536155

Epoch: 5| Step: 11
Training loss: 1.1534266471862793
Validation loss: 2.011669014890989

Epoch: 101| Step: 0
Training loss: 1.5351899862289429
Validation loss: 1.9660633206367493

Epoch: 5| Step: 1
Training loss: 1.6000782251358032
Validation loss: 1.9894890983899434

Epoch: 5| Step: 2
Training loss: 1.402564287185669
Validation loss: 1.961059997479121

Epoch: 5| Step: 3
Training loss: 1.0561044216156006
Validation loss: 1.9518353740374248

Epoch: 5| Step: 4
Training loss: 1.4708276987075806
Validation loss: 1.9279416799545288

Epoch: 5| Step: 5
Training loss: 2.0657646656036377
Validation loss: 1.9330959469079971

Epoch: 5| Step: 6
Training loss: 1.4609804153442383
Validation loss: 1.9629521767298381

Epoch: 5| Step: 7
Training loss: 1.440356969833374
Validation loss: 1.9505385706822078

Epoch: 5| Step: 8
Training loss: 1.3752472400665283
Validation loss: 1.9952402810255687

Epoch: 5| Step: 9
Training loss: 1.2455683946609497
Validation loss: 1.9986708064874013

Epoch: 5| Step: 10
Training loss: 2.119333028793335
Validation loss: 2.0028633922338486

Epoch: 5| Step: 11
Training loss: 2.2341268062591553
Validation loss: 2.0339612464110055

Epoch: 102| Step: 0
Training loss: 1.525964379310608
Validation loss: 2.029991254210472

Epoch: 5| Step: 1
Training loss: 1.5871566534042358
Validation loss: 1.9827681084473927

Epoch: 5| Step: 2
Training loss: 1.5231273174285889
Validation loss: 1.978360300262769

Epoch: 5| Step: 3
Training loss: 1.432895302772522
Validation loss: 1.9382831205924351

Epoch: 5| Step: 4
Training loss: 1.7971923351287842
Validation loss: 1.9427324682474136

Epoch: 5| Step: 5
Training loss: 1.7609630823135376
Validation loss: 1.9584967195987701

Epoch: 5| Step: 6
Training loss: 1.1982041597366333
Validation loss: 1.9473098417123158

Epoch: 5| Step: 7
Training loss: 1.4308279752731323
Validation loss: 1.969130923350652

Epoch: 5| Step: 8
Training loss: 1.6689674854278564
Validation loss: 2.0161036054293313

Epoch: 5| Step: 9
Training loss: 1.4026881456375122
Validation loss: 2.0403492550055184

Epoch: 5| Step: 10
Training loss: 1.6291916370391846
Validation loss: 2.0214077780644097

Epoch: 5| Step: 11
Training loss: 1.4908292293548584
Validation loss: 2.045491799712181

Epoch: 103| Step: 0
Training loss: 1.6045128107070923
Validation loss: 2.0544286568959556

Epoch: 5| Step: 1
Training loss: 1.4902925491333008
Validation loss: 1.9893257121245067

Epoch: 5| Step: 2
Training loss: 1.3629415035247803
Validation loss: 2.0034650514523187

Epoch: 5| Step: 3
Training loss: 1.2885382175445557
Validation loss: 2.016757016380628

Epoch: 5| Step: 4
Training loss: 1.769472360610962
Validation loss: 1.9362037281195323

Epoch: 5| Step: 5
Training loss: 1.855156660079956
Validation loss: 1.9953791151444118

Epoch: 5| Step: 6
Training loss: 1.9301869869232178
Validation loss: 1.9481309453646343

Epoch: 5| Step: 7
Training loss: 1.842890977859497
Validation loss: 1.916285405556361

Epoch: 5| Step: 8
Training loss: 1.2681629657745361
Validation loss: 1.9212219665447872

Epoch: 5| Step: 9
Training loss: 1.0401347875595093
Validation loss: 1.919508288304011

Epoch: 5| Step: 10
Training loss: 1.4157836437225342
Validation loss: 1.9725178430477779

Epoch: 5| Step: 11
Training loss: 2.093594789505005
Validation loss: 1.9768356134494145

Epoch: 104| Step: 0
Training loss: 1.1253961324691772
Validation loss: 2.026921103398005

Epoch: 5| Step: 1
Training loss: 1.7008321285247803
Validation loss: 2.044505854447683

Epoch: 5| Step: 2
Training loss: 1.8369134664535522
Validation loss: 2.078489934404691

Epoch: 5| Step: 3
Training loss: 1.2312051057815552
Validation loss: 2.040608748793602

Epoch: 5| Step: 4
Training loss: 1.4847087860107422
Validation loss: 2.053511828184128

Epoch: 5| Step: 5
Training loss: 1.6728289127349854
Validation loss: 2.099102333188057

Epoch: 5| Step: 6
Training loss: 1.5672374963760376
Validation loss: 2.038391316930453

Epoch: 5| Step: 7
Training loss: 1.4980167150497437
Validation loss: 2.010422259569168

Epoch: 5| Step: 8
Training loss: 1.4243035316467285
Validation loss: 1.9988689074913661

Epoch: 5| Step: 9
Training loss: 1.922818899154663
Validation loss: 1.9971959988276164

Epoch: 5| Step: 10
Training loss: 1.179517149925232
Validation loss: 1.9894466648499172

Epoch: 5| Step: 11
Training loss: 1.9190690517425537
Validation loss: 2.015736828247706

Epoch: 105| Step: 0
Training loss: 1.58894944190979
Validation loss: 1.9370045761267345

Epoch: 5| Step: 1
Training loss: 1.9720216989517212
Validation loss: 1.9419827212889988

Epoch: 5| Step: 2
Training loss: 1.4440288543701172
Validation loss: 1.9599849979082744

Epoch: 5| Step: 3
Training loss: 1.6868623495101929
Validation loss: 1.922877808411916

Epoch: 5| Step: 4
Training loss: 1.3583464622497559
Validation loss: 1.9452278117338817

Epoch: 5| Step: 5
Training loss: 1.5760091543197632
Validation loss: 1.963597799340884

Epoch: 5| Step: 6
Training loss: 1.623613953590393
Validation loss: 1.9992762406667073

Epoch: 5| Step: 7
Training loss: 1.589449167251587
Validation loss: 1.988446315129598

Epoch: 5| Step: 8
Training loss: 1.8289692401885986
Validation loss: 2.038552388548851

Epoch: 5| Step: 9
Training loss: 0.8019850850105286
Validation loss: 2.021458327770233

Epoch: 5| Step: 10
Training loss: 1.176144003868103
Validation loss: 2.0525788565476737

Epoch: 5| Step: 11
Training loss: 0.8090850114822388
Validation loss: 2.0482610364754996

Epoch: 106| Step: 0
Training loss: 1.319727897644043
Validation loss: 2.0743050376574197

Epoch: 5| Step: 1
Training loss: 1.4193603992462158
Validation loss: 2.021010090907415

Epoch: 5| Step: 2
Training loss: 1.0513979196548462
Validation loss: 1.9986817588408787

Epoch: 5| Step: 3
Training loss: 1.3641893863677979
Validation loss: 1.9794284452994664

Epoch: 5| Step: 4
Training loss: 2.1894001960754395
Validation loss: 1.9473995169003804

Epoch: 5| Step: 5
Training loss: 1.8860422372817993
Validation loss: 1.98427747686704

Epoch: 5| Step: 6
Training loss: 1.3531858921051025
Validation loss: 1.9280357112487156

Epoch: 5| Step: 7
Training loss: 1.1534637212753296
Validation loss: 1.964142620563507

Epoch: 5| Step: 8
Training loss: 1.2641825675964355
Validation loss: 1.9241448442141216

Epoch: 5| Step: 9
Training loss: 2.002838611602783
Validation loss: 1.9426172971725464

Epoch: 5| Step: 10
Training loss: 1.5307011604309082
Validation loss: 1.9963696350653966

Epoch: 5| Step: 11
Training loss: 1.300703763961792
Validation loss: 1.9801326046387355

Epoch: 107| Step: 0
Training loss: 1.5311154127120972
Validation loss: 2.007082919279734

Epoch: 5| Step: 1
Training loss: 1.011646032333374
Validation loss: 2.01609601577123

Epoch: 5| Step: 2
Training loss: 1.6021287441253662
Validation loss: 2.0211536238590875

Epoch: 5| Step: 3
Training loss: 1.4557385444641113
Validation loss: 1.9970194399356842

Epoch: 5| Step: 4
Training loss: 1.4332678318023682
Validation loss: 2.0147950251897178

Epoch: 5| Step: 5
Training loss: 1.6626018285751343
Validation loss: 2.010157282153765

Epoch: 5| Step: 6
Training loss: 1.4781588315963745
Validation loss: 2.012132480740547

Epoch: 5| Step: 7
Training loss: 1.4091256856918335
Validation loss: 1.987373948097229

Epoch: 5| Step: 8
Training loss: 1.009661316871643
Validation loss: 2.034532606601715

Epoch: 5| Step: 9
Training loss: 1.6316664218902588
Validation loss: 1.9417544653018315

Epoch: 5| Step: 10
Training loss: 1.9694976806640625
Validation loss: 1.9447566668192546

Epoch: 5| Step: 11
Training loss: 1.3238683938980103
Validation loss: 1.9546812623739243

Epoch: 108| Step: 0
Training loss: 1.4862810373306274
Validation loss: 1.933958426117897

Epoch: 5| Step: 1
Training loss: 1.585003137588501
Validation loss: 1.9364045361677806

Epoch: 5| Step: 2
Training loss: 1.2317726612091064
Validation loss: 1.9098995178937912

Epoch: 5| Step: 3
Training loss: 1.0551859140396118
Validation loss: 1.9620514512062073

Epoch: 5| Step: 4
Training loss: 1.697551965713501
Validation loss: 1.969728449980418

Epoch: 5| Step: 5
Training loss: 2.2001850605010986
Validation loss: 2.0066037327051163

Epoch: 5| Step: 6
Training loss: 1.833794355392456
Validation loss: 2.0352557599544525

Epoch: 5| Step: 7
Training loss: 1.329546332359314
Validation loss: 2.093100662032763

Epoch: 5| Step: 8
Training loss: 1.0488166809082031
Validation loss: 1.995322197675705

Epoch: 5| Step: 9
Training loss: 1.0276347398757935
Validation loss: 2.035775601863861

Epoch: 5| Step: 10
Training loss: 1.6612193584442139
Validation loss: 1.9419269164403279

Epoch: 5| Step: 11
Training loss: 1.9512723684310913
Validation loss: 1.9260192215442657

Epoch: 109| Step: 0
Training loss: 1.4584729671478271
Validation loss: 1.9350597709417343

Epoch: 5| Step: 1
Training loss: 1.7065101861953735
Validation loss: 1.9144285023212433

Epoch: 5| Step: 2
Training loss: 1.5494968891143799
Validation loss: 1.9386473695437114

Epoch: 5| Step: 3
Training loss: 1.9021726846694946
Validation loss: 1.930694321791331

Epoch: 5| Step: 4
Training loss: 1.2656118869781494
Validation loss: 1.9498910456895828

Epoch: 5| Step: 5
Training loss: 1.9039506912231445
Validation loss: 1.9198506722847621

Epoch: 5| Step: 6
Training loss: 1.616254448890686
Validation loss: 1.9101142883300781

Epoch: 5| Step: 7
Training loss: 1.1766705513000488
Validation loss: 1.9686086128155391

Epoch: 5| Step: 8
Training loss: 1.1894757747650146
Validation loss: 1.9332738767067592

Epoch: 5| Step: 9
Training loss: 1.420419454574585
Validation loss: 1.958080862959226

Epoch: 5| Step: 10
Training loss: 1.052814245223999
Validation loss: 1.9863418241341908

Epoch: 5| Step: 11
Training loss: 1.6018397808074951
Validation loss: 2.013884574174881

Epoch: 110| Step: 0
Training loss: 1.3755524158477783
Validation loss: 2.0076701442400613

Epoch: 5| Step: 1
Training loss: 1.0642162561416626
Validation loss: 1.9857212354739506

Epoch: 5| Step: 2
Training loss: 1.782288908958435
Validation loss: 2.0058747231960297

Epoch: 5| Step: 3
Training loss: 1.3095829486846924
Validation loss: 1.974032332499822

Epoch: 5| Step: 4
Training loss: 1.42312753200531
Validation loss: 1.9435000866651535

Epoch: 5| Step: 5
Training loss: 1.4521514177322388
Validation loss: 1.9156205852826436

Epoch: 5| Step: 6
Training loss: 1.63627028465271
Validation loss: 1.9570042043924332

Epoch: 5| Step: 7
Training loss: 1.9342920780181885
Validation loss: 1.9688238700230916

Epoch: 5| Step: 8
Training loss: 1.59220552444458
Validation loss: 1.9773118048906326

Epoch: 5| Step: 9
Training loss: 0.810043215751648
Validation loss: 1.9096694389979045

Epoch: 5| Step: 10
Training loss: 1.7042551040649414
Validation loss: 1.9852983156840007

Epoch: 5| Step: 11
Training loss: 1.0219684839248657
Validation loss: 2.0254058688879013

Epoch: 111| Step: 0
Training loss: 1.251883864402771
Validation loss: 1.9841279188791912

Epoch: 5| Step: 1
Training loss: 1.2287893295288086
Validation loss: 2.0631138930718103

Epoch: 5| Step: 2
Training loss: 1.3382889032363892
Validation loss: 2.0636008381843567

Epoch: 5| Step: 3
Training loss: 1.1350383758544922
Validation loss: 2.1085961163043976

Epoch: 5| Step: 4
Training loss: 1.9295486211776733
Validation loss: 2.1010128458340964

Epoch: 5| Step: 5
Training loss: 1.7589130401611328
Validation loss: 2.0017606814702353

Epoch: 5| Step: 6
Training loss: 1.6177959442138672
Validation loss: 1.9750167280435562

Epoch: 5| Step: 7
Training loss: 1.3831778764724731
Validation loss: 1.9554811517397563

Epoch: 5| Step: 8
Training loss: 1.4888713359832764
Validation loss: 1.939852550625801

Epoch: 5| Step: 9
Training loss: 1.531597375869751
Validation loss: 1.923734873533249

Epoch: 5| Step: 10
Training loss: 1.4913232326507568
Validation loss: 1.9232962032159169

Epoch: 5| Step: 11
Training loss: 1.404008150100708
Validation loss: 1.9104844282070796

Epoch: 112| Step: 0
Training loss: 1.5385377407073975
Validation loss: 1.9292645901441574

Epoch: 5| Step: 1
Training loss: 1.2424572706222534
Validation loss: 1.9573249518871307

Epoch: 5| Step: 2
Training loss: 1.295936107635498
Validation loss: 2.0070227781931558

Epoch: 5| Step: 3
Training loss: 1.7405437231063843
Validation loss: 1.9720057100057602

Epoch: 5| Step: 4
Training loss: 1.4940444231033325
Validation loss: 2.023633842666944

Epoch: 5| Step: 5
Training loss: 1.0477699041366577
Validation loss: 2.0922840933005014

Epoch: 5| Step: 6
Training loss: 1.679830551147461
Validation loss: 2.053418646256129

Epoch: 5| Step: 7
Training loss: 1.3735120296478271
Validation loss: 2.058214838306109

Epoch: 5| Step: 8
Training loss: 1.3338596820831299
Validation loss: 2.080025245745977

Epoch: 5| Step: 9
Training loss: 1.2617981433868408
Validation loss: 2.024823715289434

Epoch: 5| Step: 10
Training loss: 1.721456527709961
Validation loss: 1.9979295680920284

Epoch: 5| Step: 11
Training loss: 2.1628284454345703
Validation loss: 1.9831512073675792

Epoch: 113| Step: 0
Training loss: 1.5630788803100586
Validation loss: 1.9792826225360234

Epoch: 5| Step: 1
Training loss: 1.0881586074829102
Validation loss: 1.9552117586135864

Epoch: 5| Step: 2
Training loss: 1.9613155126571655
Validation loss: 1.940985918045044

Epoch: 5| Step: 3
Training loss: 1.453326940536499
Validation loss: 1.913517211874326

Epoch: 5| Step: 4
Training loss: 1.8425836563110352
Validation loss: 1.9467263917128246

Epoch: 5| Step: 5
Training loss: 1.0884873867034912
Validation loss: 1.9408579816420872

Epoch: 5| Step: 6
Training loss: 0.9893181920051575
Validation loss: 1.953919877608617

Epoch: 5| Step: 7
Training loss: 1.1323139667510986
Validation loss: 1.9872382928927739

Epoch: 5| Step: 8
Training loss: 1.4887595176696777
Validation loss: 2.0676228602727256

Epoch: 5| Step: 9
Training loss: 1.813997507095337
Validation loss: 2.1020298451185226

Epoch: 5| Step: 10
Training loss: 1.7476224899291992
Validation loss: 2.157460277279218

Epoch: 5| Step: 11
Training loss: 1.165653944015503
Validation loss: 2.1141495406627655

Epoch: 114| Step: 0
Training loss: 1.6014912128448486
Validation loss: 2.0779074678818383

Epoch: 5| Step: 1
Training loss: 1.4048006534576416
Validation loss: 2.0948821703592935

Epoch: 5| Step: 2
Training loss: 1.1113872528076172
Validation loss: 2.0562798430522284

Epoch: 5| Step: 3
Training loss: 1.4054625034332275
Validation loss: 1.9849200745423634

Epoch: 5| Step: 4
Training loss: 1.3151147365570068
Validation loss: 1.9442304819822311

Epoch: 5| Step: 5
Training loss: 1.4734255075454712
Validation loss: 1.8964001884063084

Epoch: 5| Step: 6
Training loss: 1.2940269708633423
Validation loss: 1.9057876964410145

Epoch: 5| Step: 7
Training loss: 1.4425103664398193
Validation loss: 1.8776759306589763

Epoch: 5| Step: 8
Training loss: 1.3055388927459717
Validation loss: 1.9159993330637615

Epoch: 5| Step: 9
Training loss: 1.7006374597549438
Validation loss: 1.895426203807195

Epoch: 5| Step: 10
Training loss: 1.4915491342544556
Validation loss: 1.9505608081817627

Epoch: 5| Step: 11
Training loss: 1.7755998373031616
Validation loss: 1.9579048504432042

Epoch: 115| Step: 0
Training loss: 1.6561743021011353
Validation loss: 2.0402031391859055

Epoch: 5| Step: 1
Training loss: 1.1903398036956787
Validation loss: 2.0074480921030045

Epoch: 5| Step: 2
Training loss: 1.2403150796890259
Validation loss: 1.993862271308899

Epoch: 5| Step: 3
Training loss: 1.4481736421585083
Validation loss: 1.9878427982330322

Epoch: 5| Step: 4
Training loss: 1.6335928440093994
Validation loss: 2.0036572962999344

Epoch: 5| Step: 5
Training loss: 1.5652172565460205
Validation loss: 2.0117519001166024

Epoch: 5| Step: 6
Training loss: 1.0624405145645142
Validation loss: 1.9920715540647507

Epoch: 5| Step: 7
Training loss: 1.5330995321273804
Validation loss: 1.9494736790657043

Epoch: 5| Step: 8
Training loss: 0.5835335850715637
Validation loss: 1.916359509030978

Epoch: 5| Step: 9
Training loss: 1.831277847290039
Validation loss: 1.937805066506068

Epoch: 5| Step: 10
Training loss: 1.3450210094451904
Validation loss: 1.9813674638668697

Epoch: 5| Step: 11
Training loss: 1.1177701950073242
Validation loss: 1.9650204330682755

Epoch: 116| Step: 0
Training loss: 1.2966712713241577
Validation loss: 1.9880649000406265

Epoch: 5| Step: 1
Training loss: 1.9148584604263306
Validation loss: 2.0168354511260986

Epoch: 5| Step: 2
Training loss: 0.8598974943161011
Validation loss: 2.0259888768196106

Epoch: 5| Step: 3
Training loss: 1.6877400875091553
Validation loss: 2.017337958017985

Epoch: 5| Step: 4
Training loss: 1.184996247291565
Validation loss: 2.033825765053431

Epoch: 5| Step: 5
Training loss: 1.377556562423706
Validation loss: 2.037730574607849

Epoch: 5| Step: 6
Training loss: 1.149061679840088
Validation loss: 2.025193676352501

Epoch: 5| Step: 7
Training loss: 1.3587453365325928
Validation loss: 1.9845309108495712

Epoch: 5| Step: 8
Training loss: 1.3919792175292969
Validation loss: 1.958150401711464

Epoch: 5| Step: 9
Training loss: 1.6634184122085571
Validation loss: 2.0017573138078055

Epoch: 5| Step: 10
Training loss: 1.0934498310089111
Validation loss: 1.9966211120287578

Epoch: 5| Step: 11
Training loss: 2.0893490314483643
Validation loss: 2.0074466168880463

Epoch: 117| Step: 0
Training loss: 1.9628158807754517
Validation loss: 2.0283736288547516

Epoch: 5| Step: 1
Training loss: 1.3918160200119019
Validation loss: 2.085688685377439

Epoch: 5| Step: 2
Training loss: 1.2661632299423218
Validation loss: 2.038260449965795

Epoch: 5| Step: 3
Training loss: 1.088201880455017
Validation loss: 2.033290227254232

Epoch: 5| Step: 4
Training loss: 0.9831247329711914
Validation loss: 1.984300618370374

Epoch: 5| Step: 5
Training loss: 1.7676788568496704
Validation loss: 1.9709255248308182

Epoch: 5| Step: 6
Training loss: 1.3285096883773804
Validation loss: 1.9288253883520763

Epoch: 5| Step: 7
Training loss: 1.7910897731781006
Validation loss: 1.9332289944092433

Epoch: 5| Step: 8
Training loss: 1.1004431247711182
Validation loss: 1.9174216240644455

Epoch: 5| Step: 9
Training loss: 1.578057050704956
Validation loss: 1.9982661604881287

Epoch: 5| Step: 10
Training loss: 1.0851285457611084
Validation loss: 1.9414923538764317

Epoch: 5| Step: 11
Training loss: 1.3866186141967773
Validation loss: 1.9777657439311345

Epoch: 118| Step: 0
Training loss: 1.7664525508880615
Validation loss: 1.9721009681622188

Epoch: 5| Step: 1
Training loss: 0.9936760067939758
Validation loss: 2.0401382446289062

Epoch: 5| Step: 2
Training loss: 0.9790464639663696
Validation loss: 2.037162557244301

Epoch: 5| Step: 3
Training loss: 1.1025111675262451
Validation loss: 1.991444965203603

Epoch: 5| Step: 4
Training loss: 1.210097074508667
Validation loss: 1.9997498542070389

Epoch: 5| Step: 5
Training loss: 1.3008235692977905
Validation loss: 1.9970501412947972

Epoch: 5| Step: 6
Training loss: 1.8012415170669556
Validation loss: 2.022449811299642

Epoch: 5| Step: 7
Training loss: 1.319960355758667
Validation loss: 1.9423416902621586

Epoch: 5| Step: 8
Training loss: 1.4273681640625
Validation loss: 1.9940647731224697

Epoch: 5| Step: 9
Training loss: 0.9999029040336609
Validation loss: 1.9891109963258107

Epoch: 5| Step: 10
Training loss: 1.4249258041381836
Validation loss: 1.94371963540713

Epoch: 5| Step: 11
Training loss: 2.5980777740478516
Validation loss: 1.9371613611777623

Epoch: 119| Step: 0
Training loss: 1.2753206491470337
Validation loss: 1.9624241888523102

Epoch: 5| Step: 1
Training loss: 1.8362871408462524
Validation loss: 1.9473178188006084

Epoch: 5| Step: 2
Training loss: 1.0366562604904175
Validation loss: 1.900626316666603

Epoch: 5| Step: 3
Training loss: 1.4179831743240356
Validation loss: 1.9165252248446147

Epoch: 5| Step: 4
Training loss: 1.011422038078308
Validation loss: 1.9655464043219883

Epoch: 5| Step: 5
Training loss: 1.1716171503067017
Validation loss: 1.9440157761176426

Epoch: 5| Step: 6
Training loss: 1.7402503490447998
Validation loss: 1.949739247560501

Epoch: 5| Step: 7
Training loss: 1.2749309539794922
Validation loss: 2.0243267565965652

Epoch: 5| Step: 8
Training loss: 1.4232382774353027
Validation loss: 1.9650005549192429

Epoch: 5| Step: 9
Training loss: 1.2729015350341797
Validation loss: 2.0215293218692145

Epoch: 5| Step: 10
Training loss: 1.2310370206832886
Validation loss: 2.0219431966543198

Epoch: 5| Step: 11
Training loss: 0.5249925255775452
Validation loss: 1.9893392473459244

Epoch: 120| Step: 0
Training loss: 1.4322080612182617
Validation loss: 1.9425045847892761

Epoch: 5| Step: 1
Training loss: 1.9353530406951904
Validation loss: 1.9048045823971431

Epoch: 5| Step: 2
Training loss: 1.177777886390686
Validation loss: 1.9410112847884495

Epoch: 5| Step: 3
Training loss: 1.2108954191207886
Validation loss: 1.9086643507083256

Epoch: 5| Step: 4
Training loss: 1.3179798126220703
Validation loss: 1.9260418961445491

Epoch: 5| Step: 5
Training loss: 1.5295343399047852
Validation loss: 1.9048901150623958

Epoch: 5| Step: 6
Training loss: 1.24038827419281
Validation loss: 1.9396139482657115

Epoch: 5| Step: 7
Training loss: 1.5689016580581665
Validation loss: 1.9370511621236801

Epoch: 5| Step: 8
Training loss: 1.4677544832229614
Validation loss: 1.983591303229332

Epoch: 5| Step: 9
Training loss: 0.743475079536438
Validation loss: 1.9762775748968124

Epoch: 5| Step: 10
Training loss: 1.0568044185638428
Validation loss: 2.0571799675623574

Epoch: 5| Step: 11
Training loss: 1.342451572418213
Validation loss: 2.0780733625094094

Epoch: 121| Step: 0
Training loss: 0.8395903706550598
Validation loss: 2.135274663567543

Epoch: 5| Step: 1
Training loss: 1.798071265220642
Validation loss: 2.0422435651222863

Epoch: 5| Step: 2
Training loss: 1.2669281959533691
Validation loss: 2.0326528499523797

Epoch: 5| Step: 3
Training loss: 1.393399715423584
Validation loss: 2.1217767149209976

Epoch: 5| Step: 4
Training loss: 1.25075364112854
Validation loss: 1.993912970026334

Epoch: 5| Step: 5
Training loss: 0.8301023244857788
Validation loss: 1.9841213822364807

Epoch: 5| Step: 6
Training loss: 1.3739261627197266
Validation loss: 1.9576319257418315

Epoch: 5| Step: 7
Training loss: 1.1830532550811768
Validation loss: 1.945657471815745

Epoch: 5| Step: 8
Training loss: 1.2776014804840088
Validation loss: 1.900227556626002

Epoch: 5| Step: 9
Training loss: 1.8709064722061157
Validation loss: 1.927404950062434

Epoch: 5| Step: 10
Training loss: 1.2967541217803955
Validation loss: 1.9073654611905415

Epoch: 5| Step: 11
Training loss: 1.5874109268188477
Validation loss: 1.958820606271426

Epoch: 122| Step: 0
Training loss: 0.9068134427070618
Validation loss: 1.9513997534910839

Epoch: 5| Step: 1
Training loss: 1.1319342851638794
Validation loss: 1.980378046631813

Epoch: 5| Step: 2
Training loss: 1.76120126247406
Validation loss: 2.0125071505705514

Epoch: 5| Step: 3
Training loss: 1.404200792312622
Validation loss: 2.053759271899859

Epoch: 5| Step: 4
Training loss: 1.8843410015106201
Validation loss: 2.152794395883878

Epoch: 5| Step: 5
Training loss: 1.4690240621566772
Validation loss: 2.1001296589771905

Epoch: 5| Step: 6
Training loss: 1.305950403213501
Validation loss: 2.066110596060753

Epoch: 5| Step: 7
Training loss: 1.317583441734314
Validation loss: 2.074770376086235

Epoch: 5| Step: 8
Training loss: 1.0481407642364502
Validation loss: 2.0564049184322357

Epoch: 5| Step: 9
Training loss: 1.0845425128936768
Validation loss: 1.9572999328374863

Epoch: 5| Step: 10
Training loss: 1.03986394405365
Validation loss: 1.953912044564883

Epoch: 5| Step: 11
Training loss: 1.8966233730316162
Validation loss: 1.8760289549827576

Epoch: 123| Step: 0
Training loss: 1.3668285608291626
Validation loss: 1.9400975505510967

Epoch: 5| Step: 1
Training loss: 1.586612343788147
Validation loss: 1.9007653892040253

Epoch: 5| Step: 2
Training loss: 1.0644755363464355
Validation loss: 1.9170225809017818

Epoch: 5| Step: 3
Training loss: 1.116486668586731
Validation loss: 1.938066730896632

Epoch: 5| Step: 4
Training loss: 1.08655846118927
Validation loss: 1.9850472609202068

Epoch: 5| Step: 5
Training loss: 1.3501819372177124
Validation loss: 2.0102029343446097

Epoch: 5| Step: 6
Training loss: 1.184488296508789
Validation loss: 2.03399957716465

Epoch: 5| Step: 7
Training loss: 1.5676898956298828
Validation loss: 2.022667273879051

Epoch: 5| Step: 8
Training loss: 2.2615342140197754
Validation loss: 2.0651342322429023

Epoch: 5| Step: 9
Training loss: 1.3718258142471313
Validation loss: 2.0747920274734497

Epoch: 5| Step: 10
Training loss: 1.4067041873931885
Validation loss: 2.0490175833304725

Epoch: 5| Step: 11
Training loss: 0.6465546488761902
Validation loss: 2.0673253536224365

Epoch: 124| Step: 0
Training loss: 1.4914052486419678
Validation loss: 1.9780290673176448

Epoch: 5| Step: 1
Training loss: 1.4893791675567627
Validation loss: 1.9370398074388504

Epoch: 5| Step: 2
Training loss: 0.9082173109054565
Validation loss: 1.9070643335580826

Epoch: 5| Step: 3
Training loss: 1.4523556232452393
Validation loss: 1.934824362397194

Epoch: 5| Step: 4
Training loss: 1.5004242658615112
Validation loss: 1.939425840973854

Epoch: 5| Step: 5
Training loss: 1.4301408529281616
Validation loss: 1.9175693988800049

Epoch: 5| Step: 6
Training loss: 1.4398353099822998
Validation loss: 1.9098979036013286

Epoch: 5| Step: 7
Training loss: 1.1044548749923706
Validation loss: 1.9434390018383663

Epoch: 5| Step: 8
Training loss: 1.3953665494918823
Validation loss: 1.9790392965078354

Epoch: 5| Step: 9
Training loss: 1.6391260623931885
Validation loss: 2.0372564991315207

Epoch: 5| Step: 10
Training loss: 1.3930389881134033
Validation loss: 2.093718777100245

Epoch: 5| Step: 11
Training loss: 1.7593895196914673
Validation loss: 2.1141239205996194

Epoch: 125| Step: 0
Training loss: 2.0437798500061035
Validation loss: 2.087083121140798

Epoch: 5| Step: 1
Training loss: 1.0809831619262695
Validation loss: 2.0549776454766593

Epoch: 5| Step: 2
Training loss: 1.3308206796646118
Validation loss: 1.9917072753111522

Epoch: 5| Step: 3
Training loss: 1.173537015914917
Validation loss: 2.0376752614974976

Epoch: 5| Step: 4
Training loss: 1.0268402099609375
Validation loss: 2.0285039097070694

Epoch: 5| Step: 5
Training loss: 0.9960856437683105
Validation loss: 1.9765198330084484

Epoch: 5| Step: 6
Training loss: 0.8253639936447144
Validation loss: 1.9726183861494064

Epoch: 5| Step: 7
Training loss: 1.775286078453064
Validation loss: 1.9812658826510112

Epoch: 5| Step: 8
Training loss: 0.897354006767273
Validation loss: 1.9870957483847935

Epoch: 5| Step: 9
Training loss: 1.597706913948059
Validation loss: 1.9661977241436641

Epoch: 5| Step: 10
Training loss: 0.705750584602356
Validation loss: 1.9645347992579143

Epoch: 5| Step: 11
Training loss: 2.1507973670959473
Validation loss: 2.002058729529381

Epoch: 126| Step: 0
Training loss: 1.0787105560302734
Validation loss: 2.049273798863093

Epoch: 5| Step: 1
Training loss: 0.9920960664749146
Validation loss: 1.9633228927850723

Epoch: 5| Step: 2
Training loss: 1.3033145666122437
Validation loss: 2.0486848950386047

Epoch: 5| Step: 3
Training loss: 1.460251808166504
Validation loss: 2.023961822191874

Epoch: 5| Step: 4
Training loss: 1.2295501232147217
Validation loss: 2.0579050381978354

Epoch: 5| Step: 5
Training loss: 1.391526460647583
Validation loss: 2.05565116306146

Epoch: 5| Step: 6
Training loss: 1.1280781030654907
Validation loss: 1.9826202789942424

Epoch: 5| Step: 7
Training loss: 1.3983893394470215
Validation loss: 1.97332697113355

Epoch: 5| Step: 8
Training loss: 1.3431589603424072
Validation loss: 1.9382099310557048

Epoch: 5| Step: 9
Training loss: 1.3599951267242432
Validation loss: 1.9372762491305668

Epoch: 5| Step: 10
Training loss: 1.2937076091766357
Validation loss: 1.949160411953926

Epoch: 5| Step: 11
Training loss: 1.3977398872375488
Validation loss: 1.9687819729248683

Epoch: 127| Step: 0
Training loss: 1.018398642539978
Validation loss: 1.949451391895612

Epoch: 5| Step: 1
Training loss: 1.662261724472046
Validation loss: 2.0036596010128656

Epoch: 5| Step: 2
Training loss: 1.178139328956604
Validation loss: 1.9629145463307698

Epoch: 5| Step: 3
Training loss: 0.7747251391410828
Validation loss: 2.0267718782027564

Epoch: 5| Step: 4
Training loss: 0.7383090257644653
Validation loss: 2.030206024646759

Epoch: 5| Step: 5
Training loss: 0.9484327435493469
Validation loss: 1.9548148562510808

Epoch: 5| Step: 6
Training loss: 1.4648774862289429
Validation loss: 1.9995775769154231

Epoch: 5| Step: 7
Training loss: 1.2597190141677856
Validation loss: 2.023430327574412

Epoch: 5| Step: 8
Training loss: 1.6502084732055664
Validation loss: 2.0302679340044656

Epoch: 5| Step: 9
Training loss: 1.2729346752166748
Validation loss: 1.9982231209675472

Epoch: 5| Step: 10
Training loss: 1.2735850811004639
Validation loss: 2.0083394894997277

Epoch: 5| Step: 11
Training loss: 2.0069055557250977
Validation loss: 2.01543927192688

Epoch: 128| Step: 0
Training loss: 1.1566870212554932
Validation loss: 1.9505617171525955

Epoch: 5| Step: 1
Training loss: 1.16927170753479
Validation loss: 1.9344794352849324

Epoch: 5| Step: 2
Training loss: 1.5438824892044067
Validation loss: 1.9296855131785076

Epoch: 5| Step: 3
Training loss: 0.9818688631057739
Validation loss: 1.9404266675313313

Epoch: 5| Step: 4
Training loss: 0.9037973284721375
Validation loss: 1.954029604792595

Epoch: 5| Step: 5
Training loss: 1.5633660554885864
Validation loss: 1.9475728968779247

Epoch: 5| Step: 6
Training loss: 1.193323016166687
Validation loss: 1.915880451599757

Epoch: 5| Step: 7
Training loss: 1.1296718120574951
Validation loss: 1.923633764187495

Epoch: 5| Step: 8
Training loss: 0.8175294995307922
Validation loss: 2.021522189180056

Epoch: 5| Step: 9
Training loss: 1.5524628162384033
Validation loss: 2.077605038881302

Epoch: 5| Step: 10
Training loss: 1.3061233758926392
Validation loss: 2.0176261514425278

Epoch: 5| Step: 11
Training loss: 0.5259892344474792
Validation loss: 2.0212518175443015

Epoch: 129| Step: 0
Training loss: 1.0702629089355469
Validation loss: 2.0385676473379135

Epoch: 5| Step: 1
Training loss: 1.534663438796997
Validation loss: 1.9748575985431671

Epoch: 5| Step: 2
Training loss: 1.1287002563476562
Validation loss: 1.9816238631804783

Epoch: 5| Step: 3
Training loss: 0.734291672706604
Validation loss: 1.9693166067202885

Epoch: 5| Step: 4
Training loss: 1.4335699081420898
Validation loss: 1.9803768545389175

Epoch: 5| Step: 5
Training loss: 0.960122287273407
Validation loss: 2.005086918671926

Epoch: 5| Step: 6
Training loss: 1.0960150957107544
Validation loss: 2.0061961263418198

Epoch: 5| Step: 7
Training loss: 1.4408800601959229
Validation loss: 2.0235126862923303

Epoch: 5| Step: 8
Training loss: 1.2606867551803589
Validation loss: 2.014552732308706

Epoch: 5| Step: 9
Training loss: 1.6448135375976562
Validation loss: 1.9538577298323314

Epoch: 5| Step: 10
Training loss: 1.1203954219818115
Validation loss: 2.000172878305117

Epoch: 5| Step: 11
Training loss: 0.6278347373008728
Validation loss: 1.9801026731729507

Epoch: 130| Step: 0
Training loss: 0.8062192797660828
Validation loss: 1.9956058710813522

Epoch: 5| Step: 1
Training loss: 1.2308276891708374
Validation loss: 1.930538073182106

Epoch: 5| Step: 2
Training loss: 1.3055074214935303
Validation loss: 1.9761378467082977

Epoch: 5| Step: 3
Training loss: 1.4255735874176025
Validation loss: 1.9347480088472366

Epoch: 5| Step: 4
Training loss: 1.1313060522079468
Validation loss: 1.9550387114286423

Epoch: 5| Step: 5
Training loss: 0.9854727983474731
Validation loss: 1.950659101208051

Epoch: 5| Step: 6
Training loss: 1.1927579641342163
Validation loss: 2.01716086268425

Epoch: 5| Step: 7
Training loss: 1.2932718992233276
Validation loss: 2.0255616704622903

Epoch: 5| Step: 8
Training loss: 1.2637367248535156
Validation loss: 2.0230544010798135

Epoch: 5| Step: 9
Training loss: 1.3608301877975464
Validation loss: 2.0291406561930976

Epoch: 5| Step: 10
Training loss: 1.5890916585922241
Validation loss: 2.09899107615153

Epoch: 5| Step: 11
Training loss: 0.96010422706604
Validation loss: 2.0042106211185455

Epoch: 131| Step: 0
Training loss: 1.286994218826294
Validation loss: 2.0431750218073526

Epoch: 5| Step: 1
Training loss: 0.8389690518379211
Validation loss: 2.045513927936554

Epoch: 5| Step: 2
Training loss: 0.9964048266410828
Validation loss: 1.9466596792141597

Epoch: 5| Step: 3
Training loss: 0.9023470878601074
Validation loss: 1.9370957066615422

Epoch: 5| Step: 4
Training loss: 1.5386806726455688
Validation loss: 1.9747604876756668

Epoch: 5| Step: 5
Training loss: 1.1990420818328857
Validation loss: 1.9326648116111755

Epoch: 5| Step: 6
Training loss: 1.1162775754928589
Validation loss: 1.9788875877857208

Epoch: 5| Step: 7
Training loss: 1.2334325313568115
Validation loss: 1.9773688167333603

Epoch: 5| Step: 8
Training loss: 1.4743695259094238
Validation loss: 2.0485353618860245

Epoch: 5| Step: 9
Training loss: 1.385703682899475
Validation loss: 2.0504838476578393

Epoch: 5| Step: 10
Training loss: 1.0220035314559937
Validation loss: 1.9906736314296722

Epoch: 5| Step: 11
Training loss: 1.4403438568115234
Validation loss: 2.0056457618872323

Epoch: 132| Step: 0
Training loss: 1.006969928741455
Validation loss: 2.029593567053477

Epoch: 5| Step: 1
Training loss: 0.9551033973693848
Validation loss: 1.9724943737188976

Epoch: 5| Step: 2
Training loss: 1.244431495666504
Validation loss: 1.930008073647817

Epoch: 5| Step: 3
Training loss: 1.1939141750335693
Validation loss: 1.9571168373028438

Epoch: 5| Step: 4
Training loss: 1.0781193971633911
Validation loss: 1.9494705647230148

Epoch: 5| Step: 5
Training loss: 1.5603774785995483
Validation loss: 1.952937866250674

Epoch: 5| Step: 6
Training loss: 1.020031452178955
Validation loss: 1.9255605240662892

Epoch: 5| Step: 7
Training loss: 1.0224239826202393
Validation loss: 1.9740094244480133

Epoch: 5| Step: 8
Training loss: 1.7039220333099365
Validation loss: 2.049780547618866

Epoch: 5| Step: 9
Training loss: 1.0822407007217407
Validation loss: 2.015842487414678

Epoch: 5| Step: 10
Training loss: 1.1314140558242798
Validation loss: 2.1324614683787027

Epoch: 5| Step: 11
Training loss: 1.7396119832992554
Validation loss: 2.0736162116130195

Epoch: 133| Step: 0
Training loss: 1.3726565837860107
Validation loss: 2.065877318382263

Epoch: 5| Step: 1
Training loss: 0.6395584344863892
Validation loss: 1.9891803165276845

Epoch: 5| Step: 2
Training loss: 1.1499937772750854
Validation loss: 1.9504618098338444

Epoch: 5| Step: 3
Training loss: 1.0243524312973022
Validation loss: 1.9234045843283336

Epoch: 5| Step: 4
Training loss: 1.2103432416915894
Validation loss: 1.8870418320099513

Epoch: 5| Step: 5
Training loss: 1.5655922889709473
Validation loss: 1.9438720395167668

Epoch: 5| Step: 6
Training loss: 1.3570988178253174
Validation loss: 1.8890029539664586

Epoch: 5| Step: 7
Training loss: 1.311234474182129
Validation loss: 1.9447529415289562

Epoch: 5| Step: 8
Training loss: 1.372265100479126
Validation loss: 1.946115493774414

Epoch: 5| Step: 9
Training loss: 1.4209524393081665
Validation loss: 2.007470498482386

Epoch: 5| Step: 10
Training loss: 0.9186426401138306
Validation loss: 2.029686455925306

Epoch: 5| Step: 11
Training loss: 1.9840092658996582
Validation loss: 2.088523437579473

Epoch: 134| Step: 0
Training loss: 1.0337680578231812
Validation loss: 2.185362547636032

Epoch: 5| Step: 1
Training loss: 1.6053543090820312
Validation loss: 2.1289520959059396

Epoch: 5| Step: 2
Training loss: 1.505321741104126
Validation loss: 2.117227181792259

Epoch: 5| Step: 3
Training loss: 0.7690250277519226
Validation loss: 2.0649123390515647

Epoch: 5| Step: 4
Training loss: 1.2664973735809326
Validation loss: 2.063400680820147

Epoch: 5| Step: 5
Training loss: 1.3302043676376343
Validation loss: 1.998327871163686

Epoch: 5| Step: 6
Training loss: 0.685823917388916
Validation loss: 1.9667998105287552

Epoch: 5| Step: 7
Training loss: 1.5043485164642334
Validation loss: 1.933632731437683

Epoch: 5| Step: 8
Training loss: 1.2023327350616455
Validation loss: 1.9500085016091664

Epoch: 5| Step: 9
Training loss: 0.7453960180282593
Validation loss: 1.9914275656143825

Epoch: 5| Step: 10
Training loss: 1.3540197610855103
Validation loss: 1.9946870158116023

Epoch: 5| Step: 11
Training loss: 1.0062626600265503
Validation loss: 2.0220391054948172

Epoch: 135| Step: 0
Training loss: 1.367993712425232
Validation loss: 1.998785709341367

Epoch: 5| Step: 1
Training loss: 1.067168116569519
Validation loss: 2.0798030147949853

Epoch: 5| Step: 2
Training loss: 1.1095123291015625
Validation loss: 2.017411455512047

Epoch: 5| Step: 3
Training loss: 2.047621488571167
Validation loss: 2.0731349686781564

Epoch: 5| Step: 4
Training loss: 1.0688351392745972
Validation loss: 2.09128537774086

Epoch: 5| Step: 5
Training loss: 1.120436191558838
Validation loss: 2.131568267941475

Epoch: 5| Step: 6
Training loss: 0.7679527997970581
Validation loss: 2.1078338672717414

Epoch: 5| Step: 7
Training loss: 1.2008005380630493
Validation loss: 2.004849558075269

Epoch: 5| Step: 8
Training loss: 0.6722387075424194
Validation loss: 1.9967118352651596

Epoch: 5| Step: 9
Training loss: 1.0688066482543945
Validation loss: 1.9424578448136647

Epoch: 5| Step: 10
Training loss: 1.1252837181091309
Validation loss: 1.9082004676262538

Epoch: 5| Step: 11
Training loss: 1.790777564048767
Validation loss: 1.965593049923579

Epoch: 136| Step: 0
Training loss: 1.0573866367340088
Validation loss: 1.8575512270132701

Epoch: 5| Step: 1
Training loss: 0.9740139245986938
Validation loss: 1.94994921485583

Epoch: 5| Step: 2
Training loss: 1.376405954360962
Validation loss: 2.0067744106054306

Epoch: 5| Step: 3
Training loss: 1.0010013580322266
Validation loss: 2.024436498681704

Epoch: 5| Step: 4
Training loss: 1.6468088626861572
Validation loss: 2.0819173703591027

Epoch: 5| Step: 5
Training loss: 0.8435332179069519
Validation loss: 2.1678712566693625

Epoch: 5| Step: 6
Training loss: 1.545915126800537
Validation loss: 2.1304007122913995

Epoch: 5| Step: 7
Training loss: 1.4159681797027588
Validation loss: 2.092264950275421

Epoch: 5| Step: 8
Training loss: 0.9525489807128906
Validation loss: 1.9907126973072689

Epoch: 5| Step: 9
Training loss: 1.1195858716964722
Validation loss: 1.9533575425545375

Epoch: 5| Step: 10
Training loss: 0.9369597434997559
Validation loss: 1.9198232839504878

Epoch: 5| Step: 11
Training loss: 0.7559757232666016
Validation loss: 1.9116157442331314

Epoch: 137| Step: 0
Training loss: 1.4345632791519165
Validation loss: 1.941543276111285

Epoch: 5| Step: 1
Training loss: 1.18027663230896
Validation loss: 1.9172807733217876

Epoch: 5| Step: 2
Training loss: 0.9718774557113647
Validation loss: 1.9486371080080669

Epoch: 5| Step: 3
Training loss: 1.1514242887496948
Validation loss: 1.9531667232513428

Epoch: 5| Step: 4
Training loss: 0.6826682090759277
Validation loss: 1.9955614258845646

Epoch: 5| Step: 5
Training loss: 1.4759666919708252
Validation loss: 2.0592661847670874

Epoch: 5| Step: 6
Training loss: 1.3010679483413696
Validation loss: 2.0249724090099335

Epoch: 5| Step: 7
Training loss: 1.1902868747711182
Validation loss: 2.0815502901872

Epoch: 5| Step: 8
Training loss: 1.3345463275909424
Validation loss: 2.067630112171173

Epoch: 5| Step: 9
Training loss: 1.0758674144744873
Validation loss: 2.0232124676307044

Epoch: 5| Step: 10
Training loss: 1.1373264789581299
Validation loss: 1.9809481352567673

Epoch: 5| Step: 11
Training loss: 1.1666232347488403
Validation loss: 1.970039263367653

Epoch: 138| Step: 0
Training loss: 0.9882456660270691
Validation loss: 1.9149965196847916

Epoch: 5| Step: 1
Training loss: 0.8438501358032227
Validation loss: 1.9084141304095585

Epoch: 5| Step: 2
Training loss: 0.8591564297676086
Validation loss: 1.8739717155694962

Epoch: 5| Step: 3
Training loss: 1.672318696975708
Validation loss: 1.9387319435675938

Epoch: 5| Step: 4
Training loss: 1.1107999086380005
Validation loss: 1.9675611307223637

Epoch: 5| Step: 5
Training loss: 0.989088237285614
Validation loss: 1.919172962506612

Epoch: 5| Step: 6
Training loss: 1.2910667657852173
Validation loss: 1.9791407386461894

Epoch: 5| Step: 7
Training loss: 1.5371606349945068
Validation loss: 1.997064436475436

Epoch: 5| Step: 8
Training loss: 0.701912522315979
Validation loss: 1.9535630196332932

Epoch: 5| Step: 9
Training loss: 1.2565542459487915
Validation loss: 1.9913560698429744

Epoch: 5| Step: 10
Training loss: 1.3039864301681519
Validation loss: 2.0386421978473663

Epoch: 5| Step: 11
Training loss: 0.9353988766670227
Validation loss: 2.0638654232025146

Epoch: 139| Step: 0
Training loss: 1.0077016353607178
Validation loss: 2.067107006907463

Epoch: 5| Step: 1
Training loss: 1.0845348834991455
Validation loss: 1.9956458310286205

Epoch: 5| Step: 2
Training loss: 0.8226801753044128
Validation loss: 1.9303776423136394

Epoch: 5| Step: 3
Training loss: 0.9821766018867493
Validation loss: 1.9558822115262349

Epoch: 5| Step: 4
Training loss: 0.6908982396125793
Validation loss: 1.9531916628281276

Epoch: 5| Step: 5
Training loss: 1.873811960220337
Validation loss: 1.9301289667685826

Epoch: 5| Step: 6
Training loss: 1.6498222351074219
Validation loss: 2.0101035783688226

Epoch: 5| Step: 7
Training loss: 1.4315403699874878
Validation loss: 1.9525583982467651

Epoch: 5| Step: 8
Training loss: 1.1644244194030762
Validation loss: 2.025391494234403

Epoch: 5| Step: 9
Training loss: 0.8812254071235657
Validation loss: 2.0124909232060113

Epoch: 5| Step: 10
Training loss: 0.9486593008041382
Validation loss: 2.0689606020847955

Epoch: 5| Step: 11
Training loss: 0.487582802772522
Validation loss: 2.0414385249217353

Epoch: 140| Step: 0
Training loss: 1.3608301877975464
Validation loss: 2.039767846465111

Epoch: 5| Step: 1
Training loss: 0.7065767049789429
Validation loss: 2.090545430779457

Epoch: 5| Step: 2
Training loss: 1.013174057006836
Validation loss: 2.0977675318717957

Epoch: 5| Step: 3
Training loss: 1.11147141456604
Validation loss: 2.070870632926623

Epoch: 5| Step: 4
Training loss: 0.7780047059059143
Validation loss: 2.0737249304850898

Epoch: 5| Step: 5
Training loss: 1.5591003894805908
Validation loss: 1.9967549641927083

Epoch: 5| Step: 6
Training loss: 0.8027079701423645
Validation loss: 1.9697324633598328

Epoch: 5| Step: 7
Training loss: 0.864515483379364
Validation loss: 1.952732225259145

Epoch: 5| Step: 8
Training loss: 1.547655701637268
Validation loss: 1.9590564221143723

Epoch: 5| Step: 9
Training loss: 0.8962703943252563
Validation loss: 1.9234422395626705

Epoch: 5| Step: 10
Training loss: 1.4041863679885864
Validation loss: 1.9369316498438518

Epoch: 5| Step: 11
Training loss: 0.47556740045547485
Validation loss: 1.9798897604147594

Epoch: 141| Step: 0
Training loss: 1.8732770681381226
Validation loss: 2.018694519996643

Epoch: 5| Step: 1
Training loss: 0.755835771560669
Validation loss: 2.072719698150953

Epoch: 5| Step: 2
Training loss: 1.1056458950042725
Validation loss: 1.962716336051623

Epoch: 5| Step: 3
Training loss: 0.6307446360588074
Validation loss: 2.0052751898765564

Epoch: 5| Step: 4
Training loss: 1.229641079902649
Validation loss: 2.02298574646314

Epoch: 5| Step: 5
Training loss: 1.161533236503601
Validation loss: 2.028216153383255

Epoch: 5| Step: 6
Training loss: 1.2022507190704346
Validation loss: 1.9648637622594833

Epoch: 5| Step: 7
Training loss: 0.978415846824646
Validation loss: 1.945791279276212

Epoch: 5| Step: 8
Training loss: 1.0911535024642944
Validation loss: 1.929100478688876

Epoch: 5| Step: 9
Training loss: 0.6084121465682983
Validation loss: 1.9772827476263046

Epoch: 5| Step: 10
Training loss: 1.2299085855484009
Validation loss: 1.9831027587254841

Epoch: 5| Step: 11
Training loss: 1.3375948667526245
Validation loss: 1.9795871476332347

Epoch: 142| Step: 0
Training loss: 1.2064749002456665
Validation loss: 1.966560463110606

Epoch: 5| Step: 1
Training loss: 0.7211927771568298
Validation loss: 2.003059690197309

Epoch: 5| Step: 2
Training loss: 1.099957823753357
Validation loss: 1.9744251867135365

Epoch: 5| Step: 3
Training loss: 0.8043896555900574
Validation loss: 2.02348855137825

Epoch: 5| Step: 4
Training loss: 1.4479032754898071
Validation loss: 2.027647236982981

Epoch: 5| Step: 5
Training loss: 0.9317265748977661
Validation loss: 2.093765288591385

Epoch: 5| Step: 6
Training loss: 1.0622060298919678
Validation loss: 2.107140635450681

Epoch: 5| Step: 7
Training loss: 1.2728519439697266
Validation loss: 2.021942138671875

Epoch: 5| Step: 8
Training loss: 0.9819863438606262
Validation loss: 1.9732008874416351

Epoch: 5| Step: 9
Training loss: 0.8165503740310669
Validation loss: 1.9916889071464539

Epoch: 5| Step: 10
Training loss: 1.6217241287231445
Validation loss: 1.9635057896375656

Epoch: 5| Step: 11
Training loss: 1.1152855157852173
Validation loss: 1.9344809850056965

Epoch: 143| Step: 0
Training loss: 1.1898852586746216
Validation loss: 1.9707021564245224

Epoch: 5| Step: 1
Training loss: 1.3643221855163574
Validation loss: 1.9652642806371052

Epoch: 5| Step: 2
Training loss: 0.9006670117378235
Validation loss: 2.0415024061997733

Epoch: 5| Step: 3
Training loss: 0.6609731912612915
Validation loss: 2.0287419656912484

Epoch: 5| Step: 4
Training loss: 1.359515905380249
Validation loss: 2.0638411740461984

Epoch: 5| Step: 5
Training loss: 0.8604841232299805
Validation loss: 2.0460014839967093

Epoch: 5| Step: 6
Training loss: 1.1045453548431396
Validation loss: 2.027028575539589

Epoch: 5| Step: 7
Training loss: 0.8963483572006226
Validation loss: 2.020953342318535

Epoch: 5| Step: 8
Training loss: 1.1088674068450928
Validation loss: 1.982754960656166

Epoch: 5| Step: 9
Training loss: 0.8385723233222961
Validation loss: 2.0387140909830728

Epoch: 5| Step: 10
Training loss: 0.972597599029541
Validation loss: 2.0176611145337424

Epoch: 5| Step: 11
Training loss: 0.4999905824661255
Validation loss: 1.9564790924390156

Epoch: 144| Step: 0
Training loss: 1.1394894123077393
Validation loss: 2.0596981793642044

Epoch: 5| Step: 1
Training loss: 1.0981614589691162
Validation loss: 2.0948111166556678

Epoch: 5| Step: 2
Training loss: 1.4741722345352173
Validation loss: 2.049350122610728

Epoch: 5| Step: 3
Training loss: 1.073809027671814
Validation loss: 2.088850279649099

Epoch: 5| Step: 4
Training loss: 0.6716844439506531
Validation loss: 2.0343699802954993

Epoch: 5| Step: 5
Training loss: 1.1965630054473877
Validation loss: 2.0397740453481674

Epoch: 5| Step: 6
Training loss: 0.781021773815155
Validation loss: 2.022459884484609

Epoch: 5| Step: 7
Training loss: 1.4001215696334839
Validation loss: 1.9267249405384064

Epoch: 5| Step: 8
Training loss: 0.993429958820343
Validation loss: 1.9317563126484554

Epoch: 5| Step: 9
Training loss: 0.8493880033493042
Validation loss: 2.0018948912620544

Epoch: 5| Step: 10
Training loss: 1.2483800649642944
Validation loss: 1.9461799363295238

Epoch: 5| Step: 11
Training loss: 1.6079928874969482
Validation loss: 1.9317618856827419

Epoch: 145| Step: 0
Training loss: 1.3496315479278564
Validation loss: 1.9653104841709137

Epoch: 5| Step: 1
Training loss: 1.2146072387695312
Validation loss: 2.0461215327183404

Epoch: 5| Step: 2
Training loss: 1.0870336294174194
Validation loss: 2.0644238690535226

Epoch: 5| Step: 3
Training loss: 1.1217610836029053
Validation loss: 2.1031910181045532

Epoch: 5| Step: 4
Training loss: 1.2126327753067017
Validation loss: 2.1107397824525833

Epoch: 5| Step: 5
Training loss: 0.8329635858535767
Validation loss: 2.091492791970571

Epoch: 5| Step: 6
Training loss: 1.0833631753921509
Validation loss: 2.069924076398214

Epoch: 5| Step: 7
Training loss: 1.02008056640625
Validation loss: 1.9663422107696533

Epoch: 5| Step: 8
Training loss: 1.3440111875534058
Validation loss: 1.9545041223367055

Epoch: 5| Step: 9
Training loss: 1.0413702726364136
Validation loss: 1.979089801510175

Epoch: 5| Step: 10
Training loss: 0.6056825518608093
Validation loss: 1.9172069032986958

Epoch: 5| Step: 11
Training loss: 0.25914067029953003
Validation loss: 1.9700509508450825

Epoch: 146| Step: 0
Training loss: 0.6840038895606995
Validation loss: 1.9877020517985027

Epoch: 5| Step: 1
Training loss: 1.0534842014312744
Validation loss: 2.027330239613851

Epoch: 5| Step: 2
Training loss: 1.0765832662582397
Validation loss: 1.9742179065942764

Epoch: 5| Step: 3
Training loss: 1.1442692279815674
Validation loss: 2.0271254976590476

Epoch: 5| Step: 4
Training loss: 0.9655741453170776
Validation loss: 2.0034155398607254

Epoch: 5| Step: 5
Training loss: 1.0639252662658691
Validation loss: 2.033823495109876

Epoch: 5| Step: 6
Training loss: 0.787263810634613
Validation loss: 2.0695402026176453

Epoch: 5| Step: 7
Training loss: 1.0909700393676758
Validation loss: 2.117858479420344

Epoch: 5| Step: 8
Training loss: 0.7559806704521179
Validation loss: 2.0772538483142853

Epoch: 5| Step: 9
Training loss: 0.9537129402160645
Validation loss: 2.037240152557691

Epoch: 5| Step: 10
Training loss: 1.596842885017395
Validation loss: 2.054520567258199

Epoch: 5| Step: 11
Training loss: 0.9151283502578735
Validation loss: 1.9895202219486237

Epoch: 147| Step: 0
Training loss: 1.1066553592681885
Validation loss: 2.00652614235878

Epoch: 5| Step: 1
Training loss: 1.2744301557540894
Validation loss: 1.9325538128614426

Epoch: 5| Step: 2
Training loss: 1.1187171936035156
Validation loss: 1.9843259453773499

Epoch: 5| Step: 3
Training loss: 1.0624185800552368
Validation loss: 1.9834674447774887

Epoch: 5| Step: 4
Training loss: 1.3224766254425049
Validation loss: 1.9907155682643254

Epoch: 5| Step: 5
Training loss: 0.5655810236930847
Validation loss: 2.0116265465815864

Epoch: 5| Step: 6
Training loss: 0.9857840538024902
Validation loss: 2.032283663749695

Epoch: 5| Step: 7
Training loss: 1.0146623849868774
Validation loss: 2.1445491909980774

Epoch: 5| Step: 8
Training loss: 0.8774234056472778
Validation loss: 2.097094322244326

Epoch: 5| Step: 9
Training loss: 0.7951921224594116
Validation loss: 2.0340281476577124

Epoch: 5| Step: 10
Training loss: 1.0520727634429932
Validation loss: 2.000371848543485

Epoch: 5| Step: 11
Training loss: 2.411778450012207
Validation loss: 1.9803924361864726

Epoch: 148| Step: 0
Training loss: 0.9324215054512024
Validation loss: 2.022232244412104

Epoch: 5| Step: 1
Training loss: 0.7965360283851624
Validation loss: 1.91954705119133

Epoch: 5| Step: 2
Training loss: 1.1540931463241577
Validation loss: 1.9089402010043461

Epoch: 5| Step: 3
Training loss: 1.179983377456665
Validation loss: 1.9612127989530563

Epoch: 5| Step: 4
Training loss: 0.9548836946487427
Validation loss: 1.9597191264232

Epoch: 5| Step: 5
Training loss: 0.9767833948135376
Validation loss: 2.000119611620903

Epoch: 5| Step: 6
Training loss: 0.9227349162101746
Validation loss: 1.9648977468411128

Epoch: 5| Step: 7
Training loss: 1.3330357074737549
Validation loss: 2.0046284993489585

Epoch: 5| Step: 8
Training loss: 1.2759034633636475
Validation loss: 2.01654119292895

Epoch: 5| Step: 9
Training loss: 1.1518594026565552
Validation loss: 2.106491049130758

Epoch: 5| Step: 10
Training loss: 1.0322787761688232
Validation loss: 2.088693087299665

Epoch: 5| Step: 11
Training loss: 1.0253970623016357
Validation loss: 2.176384528477987

Epoch: 149| Step: 0
Training loss: 1.071001648902893
Validation loss: 2.056830480694771

Epoch: 5| Step: 1
Training loss: 1.018930196762085
Validation loss: 2.0606723676125207

Epoch: 5| Step: 2
Training loss: 1.4627494812011719
Validation loss: 1.965364654858907

Epoch: 5| Step: 3
Training loss: 1.3351248502731323
Validation loss: 1.9908669938643773

Epoch: 5| Step: 4
Training loss: 0.8171771168708801
Validation loss: 1.9551238318284352

Epoch: 5| Step: 5
Training loss: 1.1147956848144531
Validation loss: 2.0269824316104255

Epoch: 5| Step: 6
Training loss: 0.8999019861221313
Validation loss: 1.9577413002649944

Epoch: 5| Step: 7
Training loss: 1.0035473108291626
Validation loss: 1.949442391594251

Epoch: 5| Step: 8
Training loss: 1.0719482898712158
Validation loss: 2.0061996479829154

Epoch: 5| Step: 9
Training loss: 1.1633085012435913
Validation loss: 2.084923505783081

Epoch: 5| Step: 10
Training loss: 0.6953507661819458
Validation loss: 2.0887644290924072

Epoch: 5| Step: 11
Training loss: 0.24181035161018372
Validation loss: 2.030151749650637

Epoch: 150| Step: 0
Training loss: 0.8092870712280273
Validation loss: 2.072194462021192

Epoch: 5| Step: 1
Training loss: 0.9868227243423462
Validation loss: 2.0635389437278113

Epoch: 5| Step: 2
Training loss: 0.9745495915412903
Validation loss: 2.0159854789574942

Epoch: 5| Step: 3
Training loss: 1.0442802906036377
Validation loss: 1.9900520741939545

Epoch: 5| Step: 4
Training loss: 0.6833108067512512
Validation loss: 1.959634597102801

Epoch: 5| Step: 5
Training loss: 1.353423833847046
Validation loss: 1.9937547792991002

Epoch: 5| Step: 6
Training loss: 1.250730276107788
Validation loss: 2.0062522292137146

Epoch: 5| Step: 7
Training loss: 0.8603682518005371
Validation loss: 1.9763771742582321

Epoch: 5| Step: 8
Training loss: 0.9788514375686646
Validation loss: 2.002316395441691

Epoch: 5| Step: 9
Training loss: 0.922315776348114
Validation loss: 1.9595709790786107

Epoch: 5| Step: 10
Training loss: 0.870590329170227
Validation loss: 2.0235321323076882

Epoch: 5| Step: 11
Training loss: 1.033818244934082
Validation loss: 1.9432589660088222

Epoch: 151| Step: 0
Training loss: 0.8329519033432007
Validation loss: 2.0125053425629935

Epoch: 5| Step: 1
Training loss: 0.862387478351593
Validation loss: 2.0064630111058555

Epoch: 5| Step: 2
Training loss: 0.7388275265693665
Validation loss: 2.060144007205963

Epoch: 5| Step: 3
Training loss: 1.0512256622314453
Validation loss: 2.117956961194674

Epoch: 5| Step: 4
Training loss: 1.1923458576202393
Validation loss: 2.1161048412323

Epoch: 5| Step: 5
Training loss: 1.1686985492706299
Validation loss: 2.020799150069555

Epoch: 5| Step: 6
Training loss: 0.8083831071853638
Validation loss: 2.005855585138003

Epoch: 5| Step: 7
Training loss: 0.9534577131271362
Validation loss: 1.9592286696036656

Epoch: 5| Step: 8
Training loss: 1.1029040813446045
Validation loss: 2.0186676482359567

Epoch: 5| Step: 9
Training loss: 1.1256119012832642
Validation loss: 1.964218298594157

Epoch: 5| Step: 10
Training loss: 1.4828182458877563
Validation loss: 2.017490496238073

Epoch: 5| Step: 11
Training loss: 0.7171511650085449
Validation loss: 1.972787191470464

Epoch: 152| Step: 0
Training loss: 1.2834672927856445
Validation loss: 2.0595346788565316

Epoch: 5| Step: 1
Training loss: 1.0759109258651733
Validation loss: 2.02593902250131

Epoch: 5| Step: 2
Training loss: 1.1249700784683228
Validation loss: 2.0440052648385367

Epoch: 5| Step: 3
Training loss: 0.7308529615402222
Validation loss: 2.045796439051628

Epoch: 5| Step: 4
Training loss: 0.8486549258232117
Validation loss: 2.0306058873732886

Epoch: 5| Step: 5
Training loss: 0.6413230299949646
Validation loss: 2.037110522389412

Epoch: 5| Step: 6
Training loss: 1.126784324645996
Validation loss: 2.0585611512263617

Epoch: 5| Step: 7
Training loss: 1.2181851863861084
Validation loss: 2.0772896657387414

Epoch: 5| Step: 8
Training loss: 0.6557575464248657
Validation loss: 2.0382390369971595

Epoch: 5| Step: 9
Training loss: 0.7873134613037109
Validation loss: 1.9738274067640305

Epoch: 5| Step: 10
Training loss: 0.8324430584907532
Validation loss: 1.9536073207855225

Epoch: 5| Step: 11
Training loss: 1.0863254070281982
Validation loss: 1.9829613864421844

Epoch: 153| Step: 0
Training loss: 1.0818061828613281
Validation loss: 1.942831759651502

Epoch: 5| Step: 1
Training loss: 0.9428960680961609
Validation loss: 1.985752801100413

Epoch: 5| Step: 2
Training loss: 0.834053635597229
Validation loss: 1.9855685879786809

Epoch: 5| Step: 3
Training loss: 0.7849167585372925
Validation loss: 2.0153889755407968

Epoch: 5| Step: 4
Training loss: 1.2839884757995605
Validation loss: 2.06173437833786

Epoch: 5| Step: 5
Training loss: 0.5697101354598999
Validation loss: 2.0763879070679345

Epoch: 5| Step: 6
Training loss: 0.9628362655639648
Validation loss: 2.0787195563316345

Epoch: 5| Step: 7
Training loss: 0.7863580584526062
Validation loss: 2.03484645485878

Epoch: 5| Step: 8
Training loss: 1.0627520084381104
Validation loss: 2.0474723279476166

Epoch: 5| Step: 9
Training loss: 1.391958475112915
Validation loss: 1.998861014842987

Epoch: 5| Step: 10
Training loss: 0.8537088632583618
Validation loss: 2.0472885270913443

Epoch: 5| Step: 11
Training loss: 0.5988273024559021
Validation loss: 2.073258022467295

Epoch: 154| Step: 0
Training loss: 0.9212102890014648
Validation loss: 2.0411961525678635

Epoch: 5| Step: 1
Training loss: 0.6621872186660767
Validation loss: 2.039583370089531

Epoch: 5| Step: 2
Training loss: 0.9188284873962402
Validation loss: 2.089755803346634

Epoch: 5| Step: 3
Training loss: 0.7234473824501038
Validation loss: 2.145454208056132

Epoch: 5| Step: 4
Training loss: 0.9998879432678223
Validation loss: 2.15190356473128

Epoch: 5| Step: 5
Training loss: 0.6529170274734497
Validation loss: 2.065674955646197

Epoch: 5| Step: 6
Training loss: 1.1575754880905151
Validation loss: 2.0457794864972434

Epoch: 5| Step: 7
Training loss: 0.8533366322517395
Validation loss: 2.0121374825636544

Epoch: 5| Step: 8
Training loss: 1.2840893268585205
Validation loss: 1.984396532177925

Epoch: 5| Step: 9
Training loss: 1.3843190670013428
Validation loss: 1.9539969166119893

Epoch: 5| Step: 10
Training loss: 1.03080153465271
Validation loss: 1.9785585602124531

Epoch: 5| Step: 11
Training loss: 1.176596760749817
Validation loss: 2.0517071386178336

Epoch: 155| Step: 0
Training loss: 0.8546196222305298
Validation loss: 2.0304178247849145

Epoch: 5| Step: 1
Training loss: 1.5324000120162964
Validation loss: 1.9873655488093693

Epoch: 5| Step: 2
Training loss: 0.7616775631904602
Validation loss: 1.97096752623717

Epoch: 5| Step: 3
Training loss: 0.7351942658424377
Validation loss: 1.9686054289340973

Epoch: 5| Step: 4
Training loss: 1.3825080394744873
Validation loss: 2.0343163212140403

Epoch: 5| Step: 5
Training loss: 0.862784743309021
Validation loss: 2.058462088306745

Epoch: 5| Step: 6
Training loss: 0.526060938835144
Validation loss: 2.0865706503391266

Epoch: 5| Step: 7
Training loss: 1.116722822189331
Validation loss: 2.0495126942793527

Epoch: 5| Step: 8
Training loss: 0.9786275625228882
Validation loss: 2.068471228082975

Epoch: 5| Step: 9
Training loss: 0.6445600390434265
Validation loss: 2.0421649118264518

Epoch: 5| Step: 10
Training loss: 0.8923624753952026
Validation loss: 2.005350490411123

Epoch: 5| Step: 11
Training loss: 1.9053385257720947
Validation loss: 2.0041839530070624

Epoch: 156| Step: 0
Training loss: 1.3501096963882446
Validation loss: 2.0128706942001977

Epoch: 5| Step: 1
Training loss: 0.9555637240409851
Validation loss: 1.9435469607512157

Epoch: 5| Step: 2
Training loss: 0.8943175077438354
Validation loss: 1.965741644303004

Epoch: 5| Step: 3
Training loss: 1.116857647895813
Validation loss: 2.001230001449585

Epoch: 5| Step: 4
Training loss: 0.6254630088806152
Validation loss: 2.017102926969528

Epoch: 5| Step: 5
Training loss: 0.9851702451705933
Validation loss: 1.9337388227383296

Epoch: 5| Step: 6
Training loss: 0.5920360684394836
Validation loss: 2.0247528652350106

Epoch: 5| Step: 7
Training loss: 1.3265726566314697
Validation loss: 2.0490155071020126

Epoch: 5| Step: 8
Training loss: 0.9850553274154663
Validation loss: 2.0393714904785156

Epoch: 5| Step: 9
Training loss: 1.0193344354629517
Validation loss: 2.057990233103434

Epoch: 5| Step: 10
Training loss: 0.7065329551696777
Validation loss: 2.104363262653351

Epoch: 5| Step: 11
Training loss: 1.4412668943405151
Validation loss: 2.0203312585751214

Epoch: 157| Step: 0
Training loss: 1.326099157333374
Validation loss: 1.9789355744918187

Epoch: 5| Step: 1
Training loss: 1.1030818223953247
Validation loss: 2.031705136100451

Epoch: 5| Step: 2
Training loss: 1.0830869674682617
Validation loss: 1.9981394161780675

Epoch: 5| Step: 3
Training loss: 0.6229215860366821
Validation loss: 2.000391662120819

Epoch: 5| Step: 4
Training loss: 0.7993919253349304
Validation loss: 2.009775494535764

Epoch: 5| Step: 5
Training loss: 0.9905533790588379
Validation loss: 2.028953184684118

Epoch: 5| Step: 6
Training loss: 0.7070863842964172
Validation loss: 2.0071470042069754

Epoch: 5| Step: 7
Training loss: 0.7540690302848816
Validation loss: 2.083467647433281

Epoch: 5| Step: 8
Training loss: 0.8110232353210449
Validation loss: 2.1327383617560067

Epoch: 5| Step: 9
Training loss: 0.7116909623146057
Validation loss: 2.0682426939407983

Epoch: 5| Step: 10
Training loss: 0.9686121940612793
Validation loss: 2.0194354255994162

Epoch: 5| Step: 11
Training loss: 0.46060657501220703
Validation loss: 2.057140350341797

Epoch: 158| Step: 0
Training loss: 0.7265504598617554
Validation loss: 2.0612581024567285

Epoch: 5| Step: 1
Training loss: 0.6994341611862183
Validation loss: 2.0719803671042123

Epoch: 5| Step: 2
Training loss: 0.6036500334739685
Validation loss: 2.0878968636194863

Epoch: 5| Step: 3
Training loss: 0.6536097526550293
Validation loss: 2.0599606186151505

Epoch: 5| Step: 4
Training loss: 1.3805992603302002
Validation loss: 2.052240014076233

Epoch: 5| Step: 5
Training loss: 1.0841126441955566
Validation loss: 2.126458744208018

Epoch: 5| Step: 6
Training loss: 0.8132952451705933
Validation loss: 2.0542946606874466

Epoch: 5| Step: 7
Training loss: 0.5734740495681763
Validation loss: 2.0593211352825165

Epoch: 5| Step: 8
Training loss: 1.304537296295166
Validation loss: 2.0919100046157837

Epoch: 5| Step: 9
Training loss: 0.9953950047492981
Validation loss: 2.1079227526982627

Epoch: 5| Step: 10
Training loss: 0.9619454145431519
Validation loss: 2.071619297067324

Epoch: 5| Step: 11
Training loss: 1.135343313217163
Validation loss: 2.0707477231820426

Epoch: 159| Step: 0
Training loss: 0.5357694625854492
Validation loss: 2.0163501004378

Epoch: 5| Step: 1
Training loss: 0.7627863883972168
Validation loss: 1.9967197130123775

Epoch: 5| Step: 2
Training loss: 1.120029330253601
Validation loss: 1.9876660754283269

Epoch: 5| Step: 3
Training loss: 0.8120600581169128
Validation loss: 1.9729904234409332

Epoch: 5| Step: 4
Training loss: 1.0100823640823364
Validation loss: 2.0227553447087607

Epoch: 5| Step: 5
Training loss: 1.263306736946106
Validation loss: 2.0145960648854575

Epoch: 5| Step: 6
Training loss: 0.9791038632392883
Validation loss: 2.053833489616712

Epoch: 5| Step: 7
Training loss: 0.7616203427314758
Validation loss: 1.9677507032950718

Epoch: 5| Step: 8
Training loss: 0.790521502494812
Validation loss: 1.992789273460706

Epoch: 5| Step: 9
Training loss: 0.6179589033126831
Validation loss: 2.011816158890724

Epoch: 5| Step: 10
Training loss: 1.2343300580978394
Validation loss: 2.0564074714978537

Epoch: 5| Step: 11
Training loss: 1.071782112121582
Validation loss: 2.028127839167913

Epoch: 160| Step: 0
Training loss: 1.0820823907852173
Validation loss: 2.0296507328748703

Epoch: 5| Step: 1
Training loss: 0.5947696566581726
Validation loss: 2.042159249385198

Epoch: 5| Step: 2
Training loss: 0.7938968539237976
Validation loss: 2.0117796609799066

Epoch: 5| Step: 3
Training loss: 1.095507264137268
Validation loss: 2.0406653930743537

Epoch: 5| Step: 4
Training loss: 0.5327186584472656
Validation loss: 2.0407699098189673

Epoch: 5| Step: 5
Training loss: 1.0385643243789673
Validation loss: 2.023266782363256

Epoch: 5| Step: 6
Training loss: 0.774583637714386
Validation loss: 2.030756264925003

Epoch: 5| Step: 7
Training loss: 0.7031741142272949
Validation loss: 2.0741696457068124

Epoch: 5| Step: 8
Training loss: 0.8506501317024231
Validation loss: 2.067731554309527

Epoch: 5| Step: 9
Training loss: 1.3760602474212646
Validation loss: 2.059434806307157

Epoch: 5| Step: 10
Training loss: 0.672511100769043
Validation loss: 2.0669723798831305

Epoch: 5| Step: 11
Training loss: 0.9458836317062378
Validation loss: 2.0642884373664856

Epoch: 161| Step: 0
Training loss: 0.7388268113136292
Validation loss: 1.994938388466835

Epoch: 5| Step: 1
Training loss: 1.2633121013641357
Validation loss: 1.9492619733015697

Epoch: 5| Step: 2
Training loss: 0.6864227056503296
Validation loss: 1.9948903967936833

Epoch: 5| Step: 3
Training loss: 0.7074666023254395
Validation loss: 1.9703761041164398

Epoch: 5| Step: 4
Training loss: 1.0800825357437134
Validation loss: 1.9758424560228984

Epoch: 5| Step: 5
Training loss: 1.3602488040924072
Validation loss: 2.0908345530430474

Epoch: 5| Step: 6
Training loss: 0.6806384325027466
Validation loss: 2.0546513199806213

Epoch: 5| Step: 7
Training loss: 1.0607496500015259
Validation loss: 2.1288066804409027

Epoch: 5| Step: 8
Training loss: 0.6341420412063599
Validation loss: 2.0765665024518967

Epoch: 5| Step: 9
Training loss: 1.0523810386657715
Validation loss: 2.148012340068817

Epoch: 5| Step: 10
Training loss: 1.0563901662826538
Validation loss: 2.078670471906662

Epoch: 5| Step: 11
Training loss: 0.21500331163406372
Validation loss: 2.0140834152698517

Epoch: 162| Step: 0
Training loss: 0.9642716646194458
Validation loss: 1.9436785479386647

Epoch: 5| Step: 1
Training loss: 1.0309016704559326
Validation loss: 1.9376787394285202

Epoch: 5| Step: 2
Training loss: 0.8500728607177734
Validation loss: 1.9923679778973262

Epoch: 5| Step: 3
Training loss: 1.0193196535110474
Validation loss: 1.9683660169442494

Epoch: 5| Step: 4
Training loss: 0.5867447853088379
Validation loss: 2.053625206152598

Epoch: 5| Step: 5
Training loss: 0.73601233959198
Validation loss: 2.041446805000305

Epoch: 5| Step: 6
Training loss: 1.1627787351608276
Validation loss: 2.1488738705714545

Epoch: 5| Step: 7
Training loss: 1.278464913368225
Validation loss: 2.0862395763397217

Epoch: 5| Step: 8
Training loss: 0.9848138093948364
Validation loss: 2.0810719778140387

Epoch: 5| Step: 9
Training loss: 0.998059868812561
Validation loss: 2.0660079270601273

Epoch: 5| Step: 10
Training loss: 0.8815999031066895
Validation loss: 1.9779201398293178

Epoch: 5| Step: 11
Training loss: 1.0055935382843018
Validation loss: 2.0782873829205832

Epoch: 163| Step: 0
Training loss: 0.4493023753166199
Validation loss: 1.9635685483614604

Epoch: 5| Step: 1
Training loss: 0.8771997690200806
Validation loss: 1.9495677302281063

Epoch: 5| Step: 2
Training loss: 0.8517608642578125
Validation loss: 1.980691636602084

Epoch: 5| Step: 3
Training loss: 1.208519458770752
Validation loss: 2.0020442406336465

Epoch: 5| Step: 4
Training loss: 0.7274644374847412
Validation loss: 1.9350497325261433

Epoch: 5| Step: 5
Training loss: 1.2156352996826172
Validation loss: 2.018738642334938

Epoch: 5| Step: 6
Training loss: 0.4661620259284973
Validation loss: 2.0379801789919534

Epoch: 5| Step: 7
Training loss: 1.1243566274642944
Validation loss: 2.036055957277616

Epoch: 5| Step: 8
Training loss: 1.1059821844100952
Validation loss: 2.020115395387014

Epoch: 5| Step: 9
Training loss: 0.8231898546218872
Validation loss: 2.0467904011408486

Epoch: 5| Step: 10
Training loss: 0.6527827382087708
Validation loss: 2.096389333407084

Epoch: 5| Step: 11
Training loss: 1.1494261026382446
Validation loss: 2.036954020460447

Epoch: 164| Step: 0
Training loss: 0.9265652894973755
Validation loss: 1.985412190357844

Epoch: 5| Step: 1
Training loss: 0.5014675855636597
Validation loss: 1.9546495229005814

Epoch: 5| Step: 2
Training loss: 0.7866634130477905
Validation loss: 2.0037334114313126

Epoch: 5| Step: 3
Training loss: 0.9125028848648071
Validation loss: 1.948504904905955

Epoch: 5| Step: 4
Training loss: 0.7523494362831116
Validation loss: 1.955918734272321

Epoch: 5| Step: 5
Training loss: 0.7274985313415527
Validation loss: 1.9346030056476593

Epoch: 5| Step: 6
Training loss: 1.0910005569458008
Validation loss: 1.989740565419197

Epoch: 5| Step: 7
Training loss: 1.1356130838394165
Validation loss: 2.0143321404854455

Epoch: 5| Step: 8
Training loss: 0.812183678150177
Validation loss: 2.062538762887319

Epoch: 5| Step: 9
Training loss: 1.022597074508667
Validation loss: 2.06195201476415

Epoch: 5| Step: 10
Training loss: 0.8120457530021667
Validation loss: 2.0644042094548545

Epoch: 5| Step: 11
Training loss: 1.7925655841827393
Validation loss: 2.069686690966288

Epoch: 165| Step: 0
Training loss: 0.5655360817909241
Validation loss: 2.0281183073918023

Epoch: 5| Step: 1
Training loss: 0.8351260423660278
Validation loss: 2.0565338681141534

Epoch: 5| Step: 2
Training loss: 0.8872388601303101
Validation loss: 2.0007945646842322

Epoch: 5| Step: 3
Training loss: 1.0282789468765259
Validation loss: 1.9963042785724003

Epoch: 5| Step: 4
Training loss: 1.0042922496795654
Validation loss: 2.049503281712532

Epoch: 5| Step: 5
Training loss: 0.7363670468330383
Validation loss: 2.008526394764582

Epoch: 5| Step: 6
Training loss: 0.7378404140472412
Validation loss: 2.0627031326293945

Epoch: 5| Step: 7
Training loss: 0.8453400731086731
Validation loss: 2.0379369457562766

Epoch: 5| Step: 8
Training loss: 1.1772836446762085
Validation loss: 2.0148741950591407

Epoch: 5| Step: 9
Training loss: 0.6241081953048706
Validation loss: 2.019852409760157

Epoch: 5| Step: 10
Training loss: 0.7862300872802734
Validation loss: 1.9545886814594269

Epoch: 5| Step: 11
Training loss: 1.0361030101776123
Validation loss: 1.970626766482989

Epoch: 166| Step: 0
Training loss: 0.7708349227905273
Validation loss: 2.0196880201498666

Epoch: 5| Step: 1
Training loss: 1.113723874092102
Validation loss: 1.9870947152376175

Epoch: 5| Step: 2
Training loss: 1.0285618305206299
Validation loss: 2.0269571095705032

Epoch: 5| Step: 3
Training loss: 0.6802656054496765
Validation loss: 2.0314851850271225

Epoch: 5| Step: 4
Training loss: 0.769881546497345
Validation loss: 2.0276591231425605

Epoch: 5| Step: 5
Training loss: 0.5225423574447632
Validation loss: 2.0838083823521933

Epoch: 5| Step: 6
Training loss: 0.7273924946784973
Validation loss: 2.0685317864020667

Epoch: 5| Step: 7
Training loss: 1.0952608585357666
Validation loss: 2.015509858727455

Epoch: 5| Step: 8
Training loss: 0.6969907879829407
Validation loss: 2.033160169919332

Epoch: 5| Step: 9
Training loss: 1.0634204149246216
Validation loss: 1.9877300610144932

Epoch: 5| Step: 10
Training loss: 0.8342849016189575
Validation loss: 1.9507957249879837

Epoch: 5| Step: 11
Training loss: 0.34890425205230713
Validation loss: 1.9820085267225902

Epoch: 167| Step: 0
Training loss: 0.552489161491394
Validation loss: 2.018100788195928

Epoch: 5| Step: 1
Training loss: 0.7057897448539734
Validation loss: 2.0124983191490173

Epoch: 5| Step: 2
Training loss: 0.6711030006408691
Validation loss: 1.99346262216568

Epoch: 5| Step: 3
Training loss: 0.7948276400566101
Validation loss: 2.0702543358008065

Epoch: 5| Step: 4
Training loss: 0.8481813669204712
Validation loss: 2.0896952549616494

Epoch: 5| Step: 5
Training loss: 0.6749270558357239
Validation loss: 2.1141607562700906

Epoch: 5| Step: 6
Training loss: 0.9890472292900085
Validation loss: 2.066338822245598

Epoch: 5| Step: 7
Training loss: 1.5883424282073975
Validation loss: 2.0363687624533973

Epoch: 5| Step: 8
Training loss: 0.9217950701713562
Validation loss: 1.9906797458728154

Epoch: 5| Step: 9
Training loss: 0.905012309551239
Validation loss: 1.9577693243821461

Epoch: 5| Step: 10
Training loss: 0.5683097839355469
Validation loss: 1.945882226030032

Epoch: 5| Step: 11
Training loss: 0.9142128229141235
Validation loss: 1.9891606370608013

Epoch: 168| Step: 0
Training loss: 0.4570697247982025
Validation loss: 1.9887775679429371

Epoch: 5| Step: 1
Training loss: 1.0136816501617432
Validation loss: 2.0559073934952417

Epoch: 5| Step: 2
Training loss: 0.8134979009628296
Validation loss: 2.000902126232783

Epoch: 5| Step: 3
Training loss: 0.8105312585830688
Validation loss: 2.073135962088903

Epoch: 5| Step: 4
Training loss: 1.174009084701538
Validation loss: 2.0689485718806586

Epoch: 5| Step: 5
Training loss: 0.8533692359924316
Validation loss: 2.0244147330522537

Epoch: 5| Step: 6
Training loss: 0.8975632786750793
Validation loss: 2.0887246231238046

Epoch: 5| Step: 7
Training loss: 1.0034339427947998
Validation loss: 2.05998965104421

Epoch: 5| Step: 8
Training loss: 0.9058705568313599
Validation loss: 2.00077552596728

Epoch: 5| Step: 9
Training loss: 0.5970814824104309
Validation loss: 1.9669964959224064

Epoch: 5| Step: 10
Training loss: 0.9974962472915649
Validation loss: 1.9625892341136932

Epoch: 5| Step: 11
Training loss: 0.4988371431827545
Validation loss: 2.0539292146762214

Epoch: 169| Step: 0
Training loss: 0.9620622396469116
Validation loss: 2.0064640790224075

Epoch: 5| Step: 1
Training loss: 0.9239943623542786
Validation loss: 2.052724232276281

Epoch: 5| Step: 2
Training loss: 1.2033071517944336
Validation loss: 2.053577115138372

Epoch: 5| Step: 3
Training loss: 0.6498985886573792
Validation loss: 2.093638668457667

Epoch: 5| Step: 4
Training loss: 0.9126359820365906
Validation loss: 2.0725382367769876

Epoch: 5| Step: 5
Training loss: 0.6208739280700684
Validation loss: 2.1071369697650275

Epoch: 5| Step: 6
Training loss: 0.6945024728775024
Validation loss: 2.141974081595739

Epoch: 5| Step: 7
Training loss: 1.2951337099075317
Validation loss: 2.0982893109321594

Epoch: 5| Step: 8
Training loss: 0.5843900442123413
Validation loss: 2.043000857035319

Epoch: 5| Step: 9
Training loss: 0.6504424810409546
Validation loss: 2.068204775452614

Epoch: 5| Step: 10
Training loss: 0.5525020360946655
Validation loss: 1.9965308556954067

Epoch: 5| Step: 11
Training loss: 0.5540164113044739
Validation loss: 2.0454470614592233

Epoch: 170| Step: 0
Training loss: 0.7583039402961731
Validation loss: 2.0581097304821014

Epoch: 5| Step: 1
Training loss: 0.7755798101425171
Validation loss: 2.0125403304894767

Epoch: 5| Step: 2
Training loss: 0.9958856701850891
Validation loss: 2.0683536579211554

Epoch: 5| Step: 3
Training loss: 0.6832643747329712
Validation loss: 2.085861255725225

Epoch: 5| Step: 4
Training loss: 0.8449233770370483
Validation loss: 2.1423481355110803

Epoch: 5| Step: 5
Training loss: 0.8931583166122437
Validation loss: 2.105721265077591

Epoch: 5| Step: 6
Training loss: 0.8602156639099121
Validation loss: 2.075645476579666

Epoch: 5| Step: 7
Training loss: 0.5804470181465149
Validation loss: 2.071243643760681

Epoch: 5| Step: 8
Training loss: 0.9359626770019531
Validation loss: 2.0499699264764786

Epoch: 5| Step: 9
Training loss: 0.4875831604003906
Validation loss: 2.0232118318478265

Epoch: 5| Step: 10
Training loss: 1.4734777212142944
Validation loss: 2.02642027537028

Epoch: 5| Step: 11
Training loss: 0.9045737981796265
Validation loss: 2.0409680902957916

Epoch: 171| Step: 0
Training loss: 0.7517013549804688
Validation loss: 1.9608290940523148

Epoch: 5| Step: 1
Training loss: 1.187536358833313
Validation loss: 2.0363927284876504

Epoch: 5| Step: 2
Training loss: 0.8169924020767212
Validation loss: 2.093987464904785

Epoch: 5| Step: 3
Training loss: 0.4593636393547058
Validation loss: 2.0793276876211166

Epoch: 5| Step: 4
Training loss: 0.4444805085659027
Validation loss: 2.07158300280571

Epoch: 5| Step: 5
Training loss: 0.9472749829292297
Validation loss: 2.0655126124620438

Epoch: 5| Step: 6
Training loss: 1.0634915828704834
Validation loss: 2.0771359304587045

Epoch: 5| Step: 7
Training loss: 0.5767873525619507
Validation loss: 2.0156091849009194

Epoch: 5| Step: 8
Training loss: 0.9024927020072937
Validation loss: 2.002588947614034

Epoch: 5| Step: 9
Training loss: 0.9622186422348022
Validation loss: 2.077510436375936

Epoch: 5| Step: 10
Training loss: 0.7948593497276306
Validation loss: 2.0008120636145272

Epoch: 5| Step: 11
Training loss: 0.8709320425987244
Validation loss: 2.0443237026532493

Epoch: 172| Step: 0
Training loss: 0.9316046833992004
Validation loss: 2.0298243910074234

Epoch: 5| Step: 1
Training loss: 1.0118467807769775
Validation loss: 2.0445474833250046

Epoch: 5| Step: 2
Training loss: 0.7463599443435669
Validation loss: 2.007455344001452

Epoch: 5| Step: 3
Training loss: 0.4790326654911041
Validation loss: 1.9525080521901448

Epoch: 5| Step: 4
Training loss: 1.35541570186615
Validation loss: 2.016785606741905

Epoch: 5| Step: 5
Training loss: 1.0151708126068115
Validation loss: 2.043114165465037

Epoch: 5| Step: 6
Training loss: 0.6804527044296265
Validation loss: 2.040233631928762

Epoch: 5| Step: 7
Training loss: 0.7917019724845886
Validation loss: 2.0346496303876243

Epoch: 5| Step: 8
Training loss: 1.0082619190216064
Validation loss: 2.089574654897054

Epoch: 5| Step: 9
Training loss: 0.6403273344039917
Validation loss: 2.080042908589045

Epoch: 5| Step: 10
Training loss: 0.5438359975814819
Validation loss: 2.1153134802977243

Epoch: 5| Step: 11
Training loss: 0.1900177001953125
Validation loss: 2.085724264383316

Epoch: 173| Step: 0
Training loss: 0.646772563457489
Validation loss: 2.0812833458185196

Epoch: 5| Step: 1
Training loss: 0.9055109024047852
Validation loss: 2.0694768826166787

Epoch: 5| Step: 2
Training loss: 1.0808149576187134
Validation loss: 2.0732500652472177

Epoch: 5| Step: 3
Training loss: 1.421248197555542
Validation loss: 2.072149614493052

Epoch: 5| Step: 4
Training loss: 0.9053661227226257
Validation loss: 2.0984531342983246

Epoch: 5| Step: 5
Training loss: 0.7956498861312866
Validation loss: 1.999305859208107

Epoch: 5| Step: 6
Training loss: 0.5017340779304504
Validation loss: 1.9735389798879623

Epoch: 5| Step: 7
Training loss: 0.8007446527481079
Validation loss: 2.0409474670886993

Epoch: 5| Step: 8
Training loss: 0.31880220770835876
Validation loss: 2.0355428556601205

Epoch: 5| Step: 9
Training loss: 0.5731179118156433
Validation loss: 2.0526260435581207

Epoch: 5| Step: 10
Training loss: 0.9180344343185425
Validation loss: 2.0316201696793237

Epoch: 5| Step: 11
Training loss: 0.4948192238807678
Validation loss: 2.1450694451729455

Epoch: 174| Step: 0
Training loss: 1.1086277961730957
Validation loss: 2.0657899181048074

Epoch: 5| Step: 1
Training loss: 1.1870638132095337
Validation loss: 2.0600611120462418

Epoch: 5| Step: 2
Training loss: 0.7432197332382202
Validation loss: 2.0685514559348426

Epoch: 5| Step: 3
Training loss: 0.7095080614089966
Validation loss: 1.988689586520195

Epoch: 5| Step: 4
Training loss: 0.9358112215995789
Validation loss: 2.0262430608272552

Epoch: 5| Step: 5
Training loss: 0.7094092965126038
Validation loss: 2.0599644978841147

Epoch: 5| Step: 6
Training loss: 0.5052127838134766
Validation loss: 2.0775062640508017

Epoch: 5| Step: 7
Training loss: 0.8495065569877625
Validation loss: 2.048859640955925

Epoch: 5| Step: 8
Training loss: 0.6059108972549438
Validation loss: 2.0227905909220376

Epoch: 5| Step: 9
Training loss: 0.8907496333122253
Validation loss: 2.1274397472540536

Epoch: 5| Step: 10
Training loss: 0.6442654728889465
Validation loss: 2.0320189744234085

Epoch: 5| Step: 11
Training loss: 0.16412538290023804
Validation loss: 2.0645460883776345

Epoch: 175| Step: 0
Training loss: 0.696392834186554
Validation loss: 1.9892465025186539

Epoch: 5| Step: 1
Training loss: 0.5579541921615601
Validation loss: 2.0197153786818185

Epoch: 5| Step: 2
Training loss: 1.140548586845398
Validation loss: 2.0070904393990836

Epoch: 5| Step: 3
Training loss: 0.6945242881774902
Validation loss: 1.9734678914149602

Epoch: 5| Step: 4
Training loss: 0.7984565496444702
Validation loss: 2.0866190443436303

Epoch: 5| Step: 5
Training loss: 0.9492471814155579
Validation loss: 1.9968860844771068

Epoch: 5| Step: 6
Training loss: 0.5716349482536316
Validation loss: 2.023205275336901

Epoch: 5| Step: 7
Training loss: 1.0211743116378784
Validation loss: 2.046125133832296

Epoch: 5| Step: 8
Training loss: 1.0172654390335083
Validation loss: 2.0779128472010293

Epoch: 5| Step: 9
Training loss: 0.7527119517326355
Validation loss: 2.0973185946544013

Epoch: 5| Step: 10
Training loss: 0.7585585117340088
Validation loss: 2.0219571540753045

Epoch: 5| Step: 11
Training loss: 0.2987034320831299
Validation loss: 2.030854657292366

Epoch: 176| Step: 0
Training loss: 0.681708812713623
Validation loss: 1.9856402029593785

Epoch: 5| Step: 1
Training loss: 0.6921900510787964
Validation loss: 2.0037012745936713

Epoch: 5| Step: 2
Training loss: 0.9391496777534485
Validation loss: 1.9897309343020122

Epoch: 5| Step: 3
Training loss: 0.6428387761116028
Validation loss: 2.045466204484304

Epoch: 5| Step: 4
Training loss: 0.7616631388664246
Validation loss: 2.0651948352654776

Epoch: 5| Step: 5
Training loss: 1.2809089422225952
Validation loss: 2.026166836420695

Epoch: 5| Step: 6
Training loss: 0.535919189453125
Validation loss: 2.0261796017487845

Epoch: 5| Step: 7
Training loss: 0.6918724775314331
Validation loss: 2.042973498503367

Epoch: 5| Step: 8
Training loss: 0.7417165040969849
Validation loss: 2.113527054588

Epoch: 5| Step: 9
Training loss: 1.1136577129364014
Validation loss: 2.103429858883222

Epoch: 5| Step: 10
Training loss: 0.6786149144172668
Validation loss: 2.096371759970983

Epoch: 5| Step: 11
Training loss: 1.1726168394088745
Validation loss: 2.0864840547243753

Epoch: 177| Step: 0
Training loss: 0.4405926764011383
Validation loss: 2.0544740855693817

Epoch: 5| Step: 1
Training loss: 0.5908626317977905
Validation loss: 2.092989921569824

Epoch: 5| Step: 2
Training loss: 1.0844935178756714
Validation loss: 2.0567740400632224

Epoch: 5| Step: 3
Training loss: 0.7719937562942505
Validation loss: 1.9940119882424672

Epoch: 5| Step: 4
Training loss: 0.708804190158844
Validation loss: 2.086846391359965

Epoch: 5| Step: 5
Training loss: 0.7257623076438904
Validation loss: 2.027727574110031

Epoch: 5| Step: 6
Training loss: 0.8747745752334595
Validation loss: 2.0306339114904404

Epoch: 5| Step: 7
Training loss: 0.7376013994216919
Validation loss: 1.9869078397750854

Epoch: 5| Step: 8
Training loss: 0.7233402132987976
Validation loss: 2.072660098473231

Epoch: 5| Step: 9
Training loss: 0.9258367419242859
Validation loss: 2.0601962159077325

Epoch: 5| Step: 10
Training loss: 0.7110447883605957
Validation loss: 2.0708304941654205

Epoch: 5| Step: 11
Training loss: 0.20200330018997192
Validation loss: 2.0512265463670096

Epoch: 178| Step: 0
Training loss: 0.49569782614707947
Validation loss: 2.072933758298556

Epoch: 5| Step: 1
Training loss: 0.6899915933609009
Validation loss: 2.0690087974071503

Epoch: 5| Step: 2
Training loss: 0.9838883280754089
Validation loss: 2.0791558672984443

Epoch: 5| Step: 3
Training loss: 1.0220015048980713
Validation loss: 2.0731651335954666

Epoch: 5| Step: 4
Training loss: 0.6120799779891968
Validation loss: 2.0311394979556403

Epoch: 5| Step: 5
Training loss: 0.5108288526535034
Validation loss: 2.038020138939222

Epoch: 5| Step: 6
Training loss: 0.7970001697540283
Validation loss: 2.043945143620173

Epoch: 5| Step: 7
Training loss: 0.766512930393219
Validation loss: 1.9956756432851155

Epoch: 5| Step: 8
Training loss: 1.0524742603302002
Validation loss: 2.0258708149194717

Epoch: 5| Step: 9
Training loss: 0.9656432271003723
Validation loss: 1.9475699265797932

Epoch: 5| Step: 10
Training loss: 0.400123655796051
Validation loss: 2.0330107609430947

Epoch: 5| Step: 11
Training loss: 0.936729907989502
Validation loss: 2.1133188953002295

Epoch: 179| Step: 0
Training loss: 0.46617335081100464
Validation loss: 2.0665794710318246

Epoch: 5| Step: 1
Training loss: 0.6612901091575623
Validation loss: 2.04300549129645

Epoch: 5| Step: 2
Training loss: 0.8994867205619812
Validation loss: 2.0536481887102127

Epoch: 5| Step: 3
Training loss: 1.0540883541107178
Validation loss: 2.060346861680349

Epoch: 5| Step: 4
Training loss: 0.5540386438369751
Validation loss: 2.039481977621714

Epoch: 5| Step: 5
Training loss: 1.0441290140151978
Validation loss: 2.0308762788772583

Epoch: 5| Step: 6
Training loss: 1.1362230777740479
Validation loss: 2.035725216070811

Epoch: 5| Step: 7
Training loss: 0.5944660902023315
Validation loss: 2.048622732361158

Epoch: 5| Step: 8
Training loss: 0.4450860619544983
Validation loss: 2.0275554805994034

Epoch: 5| Step: 9
Training loss: 0.662211537361145
Validation loss: 2.046857406695684

Epoch: 5| Step: 10
Training loss: 0.6007886528968811
Validation loss: 2.0771084129810333

Epoch: 5| Step: 11
Training loss: 0.48184823989868164
Validation loss: 2.0441073874632516

Epoch: 180| Step: 0
Training loss: 0.6039106249809265
Validation loss: 2.2107177674770355

Epoch: 5| Step: 1
Training loss: 0.8190507888793945
Validation loss: 2.1697581509749093

Epoch: 5| Step: 2
Training loss: 0.8956753015518188
Validation loss: 2.117973883946737

Epoch: 5| Step: 3
Training loss: 0.4142259657382965
Validation loss: 2.1138633688290915

Epoch: 5| Step: 4
Training loss: 0.3646540343761444
Validation loss: 2.023319979508718

Epoch: 5| Step: 5
Training loss: 0.6526052951812744
Validation loss: 2.0376458913087845

Epoch: 5| Step: 6
Training loss: 0.8955575227737427
Validation loss: 2.044872909784317

Epoch: 5| Step: 7
Training loss: 1.3396832942962646
Validation loss: 2.0531858454147973

Epoch: 5| Step: 8
Training loss: 1.2178876399993896
Validation loss: 2.0633647590875626

Epoch: 5| Step: 9
Training loss: 0.8064489364624023
Validation loss: 2.0885826299587884

Epoch: 5| Step: 10
Training loss: 0.692018449306488
Validation loss: 2.1410426845153174

Epoch: 5| Step: 11
Training loss: 0.7972771525382996
Validation loss: 2.114864006638527

Epoch: 181| Step: 0
Training loss: 0.7082225680351257
Validation loss: 2.1860778083403907

Epoch: 5| Step: 1
Training loss: 0.9942291378974915
Validation loss: 2.0806457002957663

Epoch: 5| Step: 2
Training loss: 1.1005775928497314
Validation loss: 2.0567478785912194

Epoch: 5| Step: 3
Training loss: 1.1968820095062256
Validation loss: 2.055649697780609

Epoch: 5| Step: 4
Training loss: 0.851872444152832
Validation loss: 1.9873359352350235

Epoch: 5| Step: 5
Training loss: 0.6444178819656372
Validation loss: 2.0260921716690063

Epoch: 5| Step: 6
Training loss: 0.5893111228942871
Validation loss: 2.0463962306578956

Epoch: 5| Step: 7
Training loss: 0.7475674152374268
Validation loss: 2.018566017349561

Epoch: 5| Step: 8
Training loss: 0.7798797488212585
Validation loss: 2.0694435040156045

Epoch: 5| Step: 9
Training loss: 0.6190259456634521
Validation loss: 2.0791092614332833

Epoch: 5| Step: 10
Training loss: 0.5667601823806763
Validation loss: 2.092482348283132

Epoch: 5| Step: 11
Training loss: 0.4397803843021393
Validation loss: 2.1157799710830054

Epoch: 182| Step: 0
Training loss: 0.7650116682052612
Validation loss: 2.0310730040073395

Epoch: 5| Step: 1
Training loss: 0.384579598903656
Validation loss: 2.045968865354856

Epoch: 5| Step: 2
Training loss: 0.7785020470619202
Validation loss: 1.953410526116689

Epoch: 5| Step: 3
Training loss: 0.7877765893936157
Validation loss: 1.98530879120032

Epoch: 5| Step: 4
Training loss: 0.7696405649185181
Validation loss: 1.979003335038821

Epoch: 5| Step: 5
Training loss: 0.625839352607727
Validation loss: 1.961267426609993

Epoch: 5| Step: 6
Training loss: 0.6163471937179565
Validation loss: 2.0535623729228973

Epoch: 5| Step: 7
Training loss: 1.0394961833953857
Validation loss: 2.0615682105223336

Epoch: 5| Step: 8
Training loss: 0.8563620448112488
Validation loss: 2.066073566675186

Epoch: 5| Step: 9
Training loss: 0.7843044996261597
Validation loss: 2.1119537403186164

Epoch: 5| Step: 10
Training loss: 1.2657009363174438
Validation loss: 2.0972968141237893

Epoch: 5| Step: 11
Training loss: 0.6749688386917114
Validation loss: 2.0986196398735046

Epoch: 183| Step: 0
Training loss: 1.0044803619384766
Validation loss: 2.08210052549839

Epoch: 5| Step: 1
Training loss: 0.3972216546535492
Validation loss: 2.0549614479144416

Epoch: 5| Step: 2
Training loss: 0.2935711741447449
Validation loss: 1.9854470193386078

Epoch: 5| Step: 3
Training loss: 1.08571195602417
Validation loss: 1.9849000970522563

Epoch: 5| Step: 4
Training loss: 0.7970057129859924
Validation loss: 1.9656484524408977

Epoch: 5| Step: 5
Training loss: 1.4267351627349854
Validation loss: 1.9900208860635757

Epoch: 5| Step: 6
Training loss: 0.7160223722457886
Validation loss: 1.9831778506437938

Epoch: 5| Step: 7
Training loss: 0.7444455027580261
Validation loss: 1.9995857179164886

Epoch: 5| Step: 8
Training loss: 0.6249191761016846
Validation loss: 2.0741749107837677

Epoch: 5| Step: 9
Training loss: 0.6855067014694214
Validation loss: 2.1264720956484475

Epoch: 5| Step: 10
Training loss: 1.0645514726638794
Validation loss: 2.0646693060795465

Epoch: 5| Step: 11
Training loss: 0.6105412244796753
Validation loss: 2.1158424417177835

Epoch: 184| Step: 0
Training loss: 0.5942294597625732
Validation loss: 2.096470460295677

Epoch: 5| Step: 1
Training loss: 0.592737078666687
Validation loss: 2.015871306260427

Epoch: 5| Step: 2
Training loss: 1.3589656352996826
Validation loss: 2.0514780481656394

Epoch: 5| Step: 3
Training loss: 0.5980750322341919
Validation loss: 1.989571213722229

Epoch: 5| Step: 4
Training loss: 0.7536758184432983
Validation loss: 2.026426821947098

Epoch: 5| Step: 5
Training loss: 0.9265397191047668
Validation loss: 1.9692814896504085

Epoch: 5| Step: 6
Training loss: 0.75227290391922
Validation loss: 1.9915060997009277

Epoch: 5| Step: 7
Training loss: 0.6661614775657654
Validation loss: 2.008039742708206

Epoch: 5| Step: 8
Training loss: 0.7184374928474426
Validation loss: 2.0574571837981543

Epoch: 5| Step: 9
Training loss: 1.0634788274765015
Validation loss: 2.0577163944641748

Epoch: 5| Step: 10
Training loss: 0.6586082577705383
Validation loss: 2.158112575610479

Epoch: 5| Step: 11
Training loss: 0.9620591402053833
Validation loss: 2.0920863300561905

Epoch: 185| Step: 0
Training loss: 0.9948613047599792
Validation loss: 2.155605619152387

Epoch: 5| Step: 1
Training loss: 0.7802974581718445
Validation loss: 2.1719971845547357

Epoch: 5| Step: 2
Training loss: 0.9490568041801453
Validation loss: 2.1611530780792236

Epoch: 5| Step: 3
Training loss: 0.42058295011520386
Validation loss: 2.031223331888517

Epoch: 5| Step: 4
Training loss: 0.8107373118400574
Validation loss: 2.023402671019236

Epoch: 5| Step: 5
Training loss: 0.8472245931625366
Validation loss: 2.0512361228466034

Epoch: 5| Step: 6
Training loss: 0.9215186834335327
Validation loss: 2.0233369867006936

Epoch: 5| Step: 7
Training loss: 0.7813524007797241
Validation loss: 2.008395438392957

Epoch: 5| Step: 8
Training loss: 0.694837749004364
Validation loss: 2.005935952067375

Epoch: 5| Step: 9
Training loss: 0.514980137348175
Validation loss: 2.0057819932699203

Epoch: 5| Step: 10
Training loss: 0.7208787202835083
Validation loss: 2.0159452011187873

Epoch: 5| Step: 11
Training loss: 1.351793646812439
Validation loss: 2.07554100950559

Epoch: 186| Step: 0
Training loss: 0.4913276731967926
Validation loss: 2.0501643816630044

Epoch: 5| Step: 1
Training loss: 0.6574668884277344
Validation loss: 2.044784257809321

Epoch: 5| Step: 2
Training loss: 0.7240563631057739
Validation loss: 2.0425594449043274

Epoch: 5| Step: 3
Training loss: 0.8348490595817566
Validation loss: 2.1397116631269455

Epoch: 5| Step: 4
Training loss: 0.9199509620666504
Validation loss: 2.144660805662473

Epoch: 5| Step: 5
Training loss: 1.0553619861602783
Validation loss: 2.096432387828827

Epoch: 5| Step: 6
Training loss: 0.49394193291664124
Validation loss: 2.092847923437754

Epoch: 5| Step: 7
Training loss: 0.6229531764984131
Validation loss: 2.033011053999265

Epoch: 5| Step: 8
Training loss: 0.7792407274246216
Validation loss: 2.0347631722688675

Epoch: 5| Step: 9
Training loss: 0.46180862188339233
Validation loss: 2.0191734035809836

Epoch: 5| Step: 10
Training loss: 0.6644522547721863
Validation loss: 2.018748864531517

Epoch: 5| Step: 11
Training loss: 0.8658195734024048
Validation loss: 2.090517356991768

Epoch: 187| Step: 0
Training loss: 0.4623977243900299
Validation loss: 2.077720324198405

Epoch: 5| Step: 1
Training loss: 0.6728900074958801
Validation loss: 2.1057643393675485

Epoch: 5| Step: 2
Training loss: 1.0827748775482178
Validation loss: 2.0883626292149224

Epoch: 5| Step: 3
Training loss: 0.7779041528701782
Validation loss: 2.127112333973249

Epoch: 5| Step: 4
Training loss: 0.5744987726211548
Validation loss: 2.103196387489637

Epoch: 5| Step: 5
Training loss: 0.7632176280021667
Validation loss: 2.1160976588726044

Epoch: 5| Step: 6
Training loss: 0.9764944314956665
Validation loss: 2.043125703930855

Epoch: 5| Step: 7
Training loss: 0.44583791494369507
Validation loss: 2.0373122791449227

Epoch: 5| Step: 8
Training loss: 0.6716563105583191
Validation loss: 2.04443929096063

Epoch: 5| Step: 9
Training loss: 0.465156614780426
Validation loss: 2.001216471195221

Epoch: 5| Step: 10
Training loss: 0.9614721536636353
Validation loss: 2.049920300642649

Epoch: 5| Step: 11
Training loss: 0.4736185073852539
Validation loss: 2.090417911609014

Epoch: 188| Step: 0
Training loss: 0.5086238980293274
Validation loss: 2.127645492553711

Epoch: 5| Step: 1
Training loss: 0.5587987899780273
Validation loss: 2.097464313109716

Epoch: 5| Step: 2
Training loss: 0.6500833630561829
Validation loss: 2.1188356379667916

Epoch: 5| Step: 3
Training loss: 0.6403853893280029
Validation loss: 2.1296905676523843

Epoch: 5| Step: 4
Training loss: 0.5582374334335327
Validation loss: 2.103624035914739

Epoch: 5| Step: 5
Training loss: 1.0845707654953003
Validation loss: 2.1408974130948386

Epoch: 5| Step: 6
Training loss: 0.915066123008728
Validation loss: 2.1186794489622116

Epoch: 5| Step: 7
Training loss: 0.5471197962760925
Validation loss: 2.025194078683853

Epoch: 5| Step: 8
Training loss: 1.043286919593811
Validation loss: 2.057942400376002

Epoch: 5| Step: 9
Training loss: 0.5871700048446655
Validation loss: 2.076933200160662

Epoch: 5| Step: 10
Training loss: 0.9223529696464539
Validation loss: 2.100872019926707

Epoch: 5| Step: 11
Training loss: 0.5674782395362854
Validation loss: 2.0444936007261276

Epoch: 189| Step: 0
Training loss: 0.7896782755851746
Validation loss: 2.171163206299146

Epoch: 5| Step: 1
Training loss: 0.6345304846763611
Validation loss: 2.138919229308764

Epoch: 5| Step: 2
Training loss: 1.0205367803573608
Validation loss: 2.0401744643847146

Epoch: 5| Step: 3
Training loss: 0.5412859916687012
Validation loss: 2.070172513524691

Epoch: 5| Step: 4
Training loss: 0.6690247058868408
Validation loss: 2.08148030936718

Epoch: 5| Step: 5
Training loss: 0.5963444709777832
Validation loss: 2.0540528148412704

Epoch: 5| Step: 6
Training loss: 0.5224785804748535
Validation loss: 2.096323311328888

Epoch: 5| Step: 7
Training loss: 1.2735350131988525
Validation loss: 2.0722936193148294

Epoch: 5| Step: 8
Training loss: 0.7722338438034058
Validation loss: 2.034338742494583

Epoch: 5| Step: 9
Training loss: 0.4959178864955902
Validation loss: 2.032501141230265

Epoch: 5| Step: 10
Training loss: 0.5330540537834167
Validation loss: 2.038355271021525

Epoch: 5| Step: 11
Training loss: 0.4609394073486328
Validation loss: 2.0877201010783515

Epoch: 190| Step: 0
Training loss: 0.5921052694320679
Validation loss: 2.084958756963412

Epoch: 5| Step: 1
Training loss: 1.3334871530532837
Validation loss: 2.0251033504803977

Epoch: 5| Step: 2
Training loss: 0.6831059455871582
Validation loss: 2.0373030404249826

Epoch: 5| Step: 3
Training loss: 0.9308872222900391
Validation loss: 2.0362698286771774

Epoch: 5| Step: 4
Training loss: 0.31943053007125854
Validation loss: 2.073694253961245

Epoch: 5| Step: 5
Training loss: 0.8780134320259094
Validation loss: 2.0655592332283654

Epoch: 5| Step: 6
Training loss: 0.6347914934158325
Validation loss: 2.006355827053388

Epoch: 5| Step: 7
Training loss: 0.7944269776344299
Validation loss: 2.062094663580259

Epoch: 5| Step: 8
Training loss: 0.4523870348930359
Validation loss: 2.021620531876882

Epoch: 5| Step: 9
Training loss: 0.5416275262832642
Validation loss: 2.0528676758209863

Epoch: 5| Step: 10
Training loss: 0.4408819079399109
Validation loss: 2.138003205259641

Epoch: 5| Step: 11
Training loss: 0.7593292593955994
Validation loss: 2.084781676530838

Epoch: 191| Step: 0
Training loss: 0.5810931921005249
Validation loss: 2.1021535893281302

Epoch: 5| Step: 1
Training loss: 0.3027186095714569
Validation loss: 2.0423355301221213

Epoch: 5| Step: 2
Training loss: 0.9117902517318726
Validation loss: 2.0894747227430344

Epoch: 5| Step: 3
Training loss: 0.4521335959434509
Validation loss: 2.137424742182096

Epoch: 5| Step: 4
Training loss: 0.9531259536743164
Validation loss: 2.0763473312060037

Epoch: 5| Step: 5
Training loss: 0.7178001403808594
Validation loss: 2.1556506206591926

Epoch: 5| Step: 6
Training loss: 0.6947115063667297
Validation loss: 2.090475777784983

Epoch: 5| Step: 7
Training loss: 0.977171778678894
Validation loss: 2.0636583318312964

Epoch: 5| Step: 8
Training loss: 0.7508484721183777
Validation loss: 2.0904585669438043

Epoch: 5| Step: 9
Training loss: 0.6460902094841003
Validation loss: 2.1164565136035285

Epoch: 5| Step: 10
Training loss: 0.4697416424751282
Validation loss: 2.0799470841884613

Epoch: 5| Step: 11
Training loss: 0.22944104671478271
Validation loss: 2.097482075293859

Epoch: 192| Step: 0
Training loss: 0.7200670838356018
Validation loss: 2.034591550628344

Epoch: 5| Step: 1
Training loss: 0.32629668712615967
Validation loss: 2.0199814836184182

Epoch: 5| Step: 2
Training loss: 0.4321443438529968
Validation loss: 2.0691172033548355

Epoch: 5| Step: 3
Training loss: 0.669969379901886
Validation loss: 2.024753138422966

Epoch: 5| Step: 4
Training loss: 1.074268102645874
Validation loss: 2.0782347867886224

Epoch: 5| Step: 5
Training loss: 0.7905118465423584
Validation loss: 2.155563751856486

Epoch: 5| Step: 6
Training loss: 0.9924052953720093
Validation loss: 2.1226871609687805

Epoch: 5| Step: 7
Training loss: 0.46868544816970825
Validation loss: 2.0673236697912216

Epoch: 5| Step: 8
Training loss: 0.6087819337844849
Validation loss: 2.1144770781199136

Epoch: 5| Step: 9
Training loss: 0.7135897278785706
Validation loss: 2.0440224011739097

Epoch: 5| Step: 10
Training loss: 0.6837911605834961
Validation loss: 1.9927889555692673

Epoch: 5| Step: 11
Training loss: 0.4018404483795166
Validation loss: 2.039152363936106

Epoch: 193| Step: 0
Training loss: 0.6759156584739685
Validation loss: 2.0692876180013022

Epoch: 5| Step: 1
Training loss: 0.43475237488746643
Validation loss: 2.0426789820194244

Epoch: 5| Step: 2
Training loss: 0.45510751008987427
Validation loss: 2.046880488594373

Epoch: 5| Step: 3
Training loss: 0.4349033236503601
Validation loss: 2.078583891193072

Epoch: 5| Step: 4
Training loss: 0.6724190711975098
Validation loss: 2.0168218115965524

Epoch: 5| Step: 5
Training loss: 1.1495860815048218
Validation loss: 2.0890942066907883

Epoch: 5| Step: 6
Training loss: 0.5096480846405029
Validation loss: 2.142731656630834

Epoch: 5| Step: 7
Training loss: 0.5951417684555054
Validation loss: 2.098434309164683

Epoch: 5| Step: 8
Training loss: 0.5499330759048462
Validation loss: 2.116235628724098

Epoch: 5| Step: 9
Training loss: 1.070381760597229
Validation loss: 2.053675095240275

Epoch: 5| Step: 10
Training loss: 0.6930489540100098
Validation loss: 2.05557914574941

Epoch: 5| Step: 11
Training loss: 0.36733919382095337
Validation loss: 2.0185858408610025

Epoch: 194| Step: 0
Training loss: 0.4637426733970642
Validation loss: 2.0158374110857644

Epoch: 5| Step: 1
Training loss: 0.9723745584487915
Validation loss: 2.058588206768036

Epoch: 5| Step: 2
Training loss: 0.6405371427536011
Validation loss: 2.032350013653437

Epoch: 5| Step: 3
Training loss: 0.4867541193962097
Validation loss: 2.047289585073789

Epoch: 5| Step: 4
Training loss: 0.5936671495437622
Validation loss: 2.091941252350807

Epoch: 5| Step: 5
Training loss: 0.8374810218811035
Validation loss: 2.173499052723249

Epoch: 5| Step: 6
Training loss: 0.5506006479263306
Validation loss: 2.066739742954572

Epoch: 5| Step: 7
Training loss: 0.47198915481567383
Validation loss: 2.1094513138135276

Epoch: 5| Step: 8
Training loss: 0.48004111647605896
Validation loss: 2.049499988555908

Epoch: 5| Step: 9
Training loss: 0.9108039140701294
Validation loss: 2.0414791802565255

Epoch: 5| Step: 10
Training loss: 1.0467195510864258
Validation loss: 2.0574524650971093

Epoch: 5| Step: 11
Training loss: 0.32228362560272217
Validation loss: 2.0576893240213394

Epoch: 195| Step: 0
Training loss: 0.7292284965515137
Validation loss: 2.076013669371605

Epoch: 5| Step: 1
Training loss: 0.7247282266616821
Validation loss: 2.059554800391197

Epoch: 5| Step: 2
Training loss: 0.5737036466598511
Validation loss: 2.026148955027262

Epoch: 5| Step: 3
Training loss: 0.5087109208106995
Validation loss: 2.047112171848615

Epoch: 5| Step: 4
Training loss: 0.750616729259491
Validation loss: 2.0615531504154205

Epoch: 5| Step: 5
Training loss: 0.6327522993087769
Validation loss: 2.053675949573517

Epoch: 5| Step: 6
Training loss: 0.6971946954727173
Validation loss: 2.0564260681470237

Epoch: 5| Step: 7
Training loss: 0.5170987844467163
Validation loss: 2.137404272953669

Epoch: 5| Step: 8
Training loss: 0.6018222570419312
Validation loss: 2.0670564075311026

Epoch: 5| Step: 9
Training loss: 0.7966383099555969
Validation loss: 2.0769566794236503

Epoch: 5| Step: 10
Training loss: 0.9998235702514648
Validation loss: 2.0971431881189346

Epoch: 5| Step: 11
Training loss: 0.6144273281097412
Validation loss: 2.09271377325058

Epoch: 196| Step: 0
Training loss: 0.827245831489563
Validation loss: 2.0292603969573975

Epoch: 5| Step: 1
Training loss: 0.7706709504127502
Validation loss: 2.1150586704413095

Epoch: 5| Step: 2
Training loss: 0.6404196619987488
Validation loss: 2.140636667609215

Epoch: 5| Step: 3
Training loss: 0.6055909991264343
Validation loss: 2.12536350886027

Epoch: 5| Step: 4
Training loss: 0.6714069247245789
Validation loss: 2.0263350903987885

Epoch: 5| Step: 5
Training loss: 0.7067686319351196
Validation loss: 2.116471146543821

Epoch: 5| Step: 6
Training loss: 0.7756859064102173
Validation loss: 2.139360169569651

Epoch: 5| Step: 7
Training loss: 0.43145743012428284
Validation loss: 2.0591496527194977

Epoch: 5| Step: 8
Training loss: 0.7502083778381348
Validation loss: 2.042974586288134

Epoch: 5| Step: 9
Training loss: 0.6640027165412903
Validation loss: 2.0375598818063736

Epoch: 5| Step: 10
Training loss: 0.6654354929924011
Validation loss: 2.102048690120379

Epoch: 5| Step: 11
Training loss: 0.12455213069915771
Validation loss: 2.148393467068672

Epoch: 197| Step: 0
Training loss: 0.4171353280544281
Validation loss: 2.0773559908072152

Epoch: 5| Step: 1
Training loss: 0.4515567421913147
Validation loss: 2.0671090334653854

Epoch: 5| Step: 2
Training loss: 0.6242902874946594
Validation loss: 2.0523707469304404

Epoch: 5| Step: 3
Training loss: 0.9974477887153625
Validation loss: 2.0884038458267846

Epoch: 5| Step: 4
Training loss: 0.6738969087600708
Validation loss: 2.1377137104670205

Epoch: 5| Step: 5
Training loss: 0.7614207863807678
Validation loss: 2.0971443355083466

Epoch: 5| Step: 6
Training loss: 0.37736982107162476
Validation loss: 2.0938446819782257

Epoch: 5| Step: 7
Training loss: 0.5782985091209412
Validation loss: 2.07012739777565

Epoch: 5| Step: 8
Training loss: 0.7353715896606445
Validation loss: 2.075616846481959

Epoch: 5| Step: 9
Training loss: 0.6349920630455017
Validation loss: 2.0653970539569855

Epoch: 5| Step: 10
Training loss: 0.9585124850273132
Validation loss: 2.0667502035697303

Epoch: 5| Step: 11
Training loss: 0.2475217878818512
Validation loss: 2.0555886725584664

Epoch: 198| Step: 0
Training loss: 0.7410246729850769
Validation loss: 2.0409676482280097

Epoch: 5| Step: 1
Training loss: 0.49506205320358276
Validation loss: 2.080106402436892

Epoch: 5| Step: 2
Training loss: 0.4628409743309021
Validation loss: 2.0301756213108697

Epoch: 5| Step: 3
Training loss: 0.8486069440841675
Validation loss: 2.0685481478770575

Epoch: 5| Step: 4
Training loss: 1.248120903968811
Validation loss: 2.0713770190874734

Epoch: 5| Step: 5
Training loss: 0.6999076008796692
Validation loss: 2.0662461817264557

Epoch: 5| Step: 6
Training loss: 0.54470294713974
Validation loss: 2.0585209478934607

Epoch: 5| Step: 7
Training loss: 0.7175045013427734
Validation loss: 2.111859440803528

Epoch: 5| Step: 8
Training loss: 0.5574707984924316
Validation loss: 2.1011985143025718

Epoch: 5| Step: 9
Training loss: 0.4221985340118408
Validation loss: 2.098548114299774

Epoch: 5| Step: 10
Training loss: 0.8680263757705688
Validation loss: 2.056459660331408

Epoch: 5| Step: 11
Training loss: 0.23998242616653442
Validation loss: 2.0944258868694305

Epoch: 199| Step: 0
Training loss: 0.9319764971733093
Validation loss: 2.05681519707044

Epoch: 5| Step: 1
Training loss: 0.49837103486061096
Validation loss: 2.039467379450798

Epoch: 5| Step: 2
Training loss: 0.4050534665584564
Validation loss: 2.044322445988655

Epoch: 5| Step: 3
Training loss: 0.7780474424362183
Validation loss: 2.061184843381246

Epoch: 5| Step: 4
Training loss: 0.8618687391281128
Validation loss: 2.093375489115715

Epoch: 5| Step: 5
Training loss: 0.7817850112915039
Validation loss: 2.0936625748872757

Epoch: 5| Step: 6
Training loss: 0.6347100734710693
Validation loss: 2.1177711288134256

Epoch: 5| Step: 7
Training loss: 0.5967692136764526
Validation loss: 2.1574763655662537

Epoch: 5| Step: 8
Training loss: 0.5411317944526672
Validation loss: 2.1054082016150155

Epoch: 5| Step: 9
Training loss: 0.6300662755966187
Validation loss: 2.02419642607371

Epoch: 5| Step: 10
Training loss: 0.7170519828796387
Validation loss: 2.0980915327866874

Epoch: 5| Step: 11
Training loss: 0.2276861071586609
Validation loss: 2.0785255829493203

Epoch: 200| Step: 0
Training loss: 0.44435185194015503
Validation loss: 2.03279018898805

Epoch: 5| Step: 1
Training loss: 0.5751804709434509
Validation loss: 2.0865859985351562

Epoch: 5| Step: 2
Training loss: 0.7459524869918823
Validation loss: 2.083306699991226

Epoch: 5| Step: 3
Training loss: 0.3698815703392029
Validation loss: 2.0605228592952094

Epoch: 5| Step: 4
Training loss: 0.5114818811416626
Validation loss: 2.0240713407595954

Epoch: 5| Step: 5
Training loss: 0.8589364886283875
Validation loss: 2.0864875316619873

Epoch: 5| Step: 6
Training loss: 0.3633151054382324
Validation loss: 2.0138804217179618

Epoch: 5| Step: 7
Training loss: 0.5445200204849243
Validation loss: 2.0703005691369376

Epoch: 5| Step: 8
Training loss: 0.9887961149215698
Validation loss: 2.082275847593943

Epoch: 5| Step: 9
Training loss: 0.7147310972213745
Validation loss: 2.0383366296688714

Epoch: 5| Step: 10
Training loss: 0.7768880128860474
Validation loss: 2.037318547566732

Epoch: 5| Step: 11
Training loss: 1.0827031135559082
Validation loss: 2.036506245533625

Epoch: 201| Step: 0
Training loss: 1.0599137544631958
Validation loss: 2.0598470667997995

Epoch: 5| Step: 1
Training loss: 0.39688530564308167
Validation loss: 2.0769239962100983

Epoch: 5| Step: 2
Training loss: 0.5144877433776855
Validation loss: 2.0615988026062646

Epoch: 5| Step: 3
Training loss: 0.5741147994995117
Validation loss: 2.0682261089483895

Epoch: 5| Step: 4
Training loss: 0.5779777765274048
Validation loss: 2.101292073726654

Epoch: 5| Step: 5
Training loss: 0.4286833703517914
Validation loss: 2.113423337539037

Epoch: 5| Step: 6
Training loss: 0.8194618225097656
Validation loss: 2.1018623411655426

Epoch: 5| Step: 7
Training loss: 0.41098135709762573
Validation loss: 2.0915253857771554

Epoch: 5| Step: 8
Training loss: 0.573336124420166
Validation loss: 2.0957696437835693

Epoch: 5| Step: 9
Training loss: 0.8665252923965454
Validation loss: 2.101404825846354

Epoch: 5| Step: 10
Training loss: 0.6331169605255127
Validation loss: 2.111150602499644

Epoch: 5| Step: 11
Training loss: 1.7314400672912598
Validation loss: 2.1176676700512567

Epoch: 202| Step: 0
Training loss: 0.458238422870636
Validation loss: 2.0490670601526895

Epoch: 5| Step: 1
Training loss: 0.7845843434333801
Validation loss: 2.0498626281817756

Epoch: 5| Step: 2
Training loss: 0.866899847984314
Validation loss: 2.0360340625047684

Epoch: 5| Step: 3
Training loss: 0.536424994468689
Validation loss: 2.0865239749352136

Epoch: 5| Step: 4
Training loss: 0.6308296322822571
Validation loss: 2.0536781201759973

Epoch: 5| Step: 5
Training loss: 0.45155054330825806
Validation loss: 2.0630051841338477

Epoch: 5| Step: 6
Training loss: 0.6439085006713867
Validation loss: 2.088643799225489

Epoch: 5| Step: 7
Training loss: 1.0351812839508057
Validation loss: 2.1020324379205704

Epoch: 5| Step: 8
Training loss: 0.4661102294921875
Validation loss: 2.081395834684372

Epoch: 5| Step: 9
Training loss: 0.7834215760231018
Validation loss: 2.027351359526316

Epoch: 5| Step: 10
Training loss: 0.4548662304878235
Validation loss: 2.0600943018992743

Epoch: 5| Step: 11
Training loss: 0.28020191192626953
Validation loss: 2.0967670480410256

Epoch: 203| Step: 0
Training loss: 0.8219432830810547
Validation loss: 2.0883085081974664

Epoch: 5| Step: 1
Training loss: 0.7120881080627441
Validation loss: 2.04758827884992

Epoch: 5| Step: 2
Training loss: 0.45845890045166016
Validation loss: 2.0610393434762955

Epoch: 5| Step: 3
Training loss: 0.6177136301994324
Validation loss: 2.0932566622893014

Epoch: 5| Step: 4
Training loss: 0.5819891691207886
Validation loss: 2.0177454352378845

Epoch: 5| Step: 5
Training loss: 0.5549083948135376
Validation loss: 2.0525325536727905

Epoch: 5| Step: 6
Training loss: 0.7325543165206909
Validation loss: 2.141098126769066

Epoch: 5| Step: 7
Training loss: 0.6232826113700867
Validation loss: 2.1898454825083413

Epoch: 5| Step: 8
Training loss: 0.7481502294540405
Validation loss: 2.0970729192097983

Epoch: 5| Step: 9
Training loss: 0.5163421630859375
Validation loss: 2.089968611796697

Epoch: 5| Step: 10
Training loss: 0.7748714685440063
Validation loss: 2.0912784536679587

Epoch: 5| Step: 11
Training loss: 1.0004661083221436
Validation loss: 2.0144637574752173

Epoch: 204| Step: 0
Training loss: 0.7745116949081421
Validation loss: 2.051656350493431

Epoch: 5| Step: 1
Training loss: 0.8307641744613647
Validation loss: 2.075135886669159

Epoch: 5| Step: 2
Training loss: 0.6112920045852661
Validation loss: 2.127802386879921

Epoch: 5| Step: 3
Training loss: 0.40403491258621216
Validation loss: 2.0027188112338385

Epoch: 5| Step: 4
Training loss: 0.6908671259880066
Validation loss: 2.036969463030497

Epoch: 5| Step: 5
Training loss: 1.0359283685684204
Validation loss: 2.0425386081139245

Epoch: 5| Step: 6
Training loss: 0.7187919020652771
Validation loss: 2.0477721889813743

Epoch: 5| Step: 7
Training loss: 0.6332014799118042
Validation loss: 2.069497396548589

Epoch: 5| Step: 8
Training loss: 0.31662502884864807
Validation loss: 2.0894830326239267

Epoch: 5| Step: 9
Training loss: 0.4792866110801697
Validation loss: 2.1057934015989304

Epoch: 5| Step: 10
Training loss: 0.541382908821106
Validation loss: 2.1774823864301047

Epoch: 5| Step: 11
Training loss: 1.010561466217041
Validation loss: 2.102600574493408

Epoch: 205| Step: 0
Training loss: 0.8318080902099609
Validation loss: 2.086583137512207

Epoch: 5| Step: 1
Training loss: 0.4583875238895416
Validation loss: 2.0737191438674927

Epoch: 5| Step: 2
Training loss: 0.6666024327278137
Validation loss: 2.054562881588936

Epoch: 5| Step: 3
Training loss: 0.7854014039039612
Validation loss: 2.1233989894390106

Epoch: 5| Step: 4
Training loss: 0.5224040150642395
Validation loss: 2.1698963890473046

Epoch: 5| Step: 5
Training loss: 0.5553236603736877
Validation loss: 2.1124784499406815

Epoch: 5| Step: 6
Training loss: 0.3732565939426422
Validation loss: 2.1035973777373633

Epoch: 5| Step: 7
Training loss: 0.7334297895431519
Validation loss: 2.139427592357

Epoch: 5| Step: 8
Training loss: 0.3869926333427429
Validation loss: 2.0868715147177377

Epoch: 5| Step: 9
Training loss: 0.9635028839111328
Validation loss: 2.1177650690078735

Epoch: 5| Step: 10
Training loss: 0.6289263963699341
Validation loss: 2.115633284052213

Epoch: 5| Step: 11
Training loss: 0.1703435182571411
Validation loss: 2.117572396993637

Epoch: 206| Step: 0
Training loss: 0.9407528042793274
Validation loss: 2.0716901322205863

Epoch: 5| Step: 1
Training loss: 0.9072306752204895
Validation loss: 2.0748784045378366

Epoch: 5| Step: 2
Training loss: 0.6860690116882324
Validation loss: 2.0950856606165567

Epoch: 5| Step: 3
Training loss: 0.30897825956344604
Validation loss: 2.127114405234655

Epoch: 5| Step: 4
Training loss: 0.8034771084785461
Validation loss: 2.0859268556038537

Epoch: 5| Step: 5
Training loss: 0.4956400394439697
Validation loss: 2.1007350931564965

Epoch: 5| Step: 6
Training loss: 0.38289403915405273
Validation loss: 2.0925808548927307

Epoch: 5| Step: 7
Training loss: 0.5218741297721863
Validation loss: 2.059554090102514

Epoch: 5| Step: 8
Training loss: 0.4018988609313965
Validation loss: 2.0718725124994912

Epoch: 5| Step: 9
Training loss: 0.7366580963134766
Validation loss: 2.0043941040833793

Epoch: 5| Step: 10
Training loss: 0.764914870262146
Validation loss: 2.04574686785539

Epoch: 5| Step: 11
Training loss: 0.5653798580169678
Validation loss: 2.009192114075025

Epoch: 207| Step: 0
Training loss: 0.6606782078742981
Validation loss: 2.073076734940211

Epoch: 5| Step: 1
Training loss: 0.37969738245010376
Validation loss: 2.0930582731962204

Epoch: 5| Step: 2
Training loss: 0.8293285369873047
Validation loss: 2.058476741115252

Epoch: 5| Step: 3
Training loss: 0.5804603695869446
Validation loss: 2.06061481932799

Epoch: 5| Step: 4
Training loss: 0.6343132257461548
Validation loss: 2.109166532754898

Epoch: 5| Step: 5
Training loss: 0.6217471957206726
Validation loss: 2.0813087075948715

Epoch: 5| Step: 6
Training loss: 0.5025233030319214
Validation loss: 2.0567840933799744

Epoch: 5| Step: 7
Training loss: 0.5773605108261108
Validation loss: 2.0560310781002045

Epoch: 5| Step: 8
Training loss: 0.40319767594337463
Validation loss: 2.0951106448968253

Epoch: 5| Step: 9
Training loss: 0.6276571154594421
Validation loss: 2.0765162309010825

Epoch: 5| Step: 10
Training loss: 0.7826935052871704
Validation loss: 2.069792240858078

Epoch: 5| Step: 11
Training loss: 0.9618939161300659
Validation loss: 2.062715455889702

Epoch: 208| Step: 0
Training loss: 0.5453146696090698
Validation loss: 2.106730510791143

Epoch: 5| Step: 1
Training loss: 0.6524713635444641
Validation loss: 2.1183198938767114

Epoch: 5| Step: 2
Training loss: 0.41553163528442383
Validation loss: 2.094446341196696

Epoch: 5| Step: 3
Training loss: 0.30256515741348267
Validation loss: 2.0644518733024597

Epoch: 5| Step: 4
Training loss: 0.5860092043876648
Validation loss: 2.111851453781128

Epoch: 5| Step: 5
Training loss: 0.8773930668830872
Validation loss: 2.0713290572166443

Epoch: 5| Step: 6
Training loss: 0.687963604927063
Validation loss: 2.0993357598781586

Epoch: 5| Step: 7
Training loss: 0.6557301878929138
Validation loss: 2.138328477740288

Epoch: 5| Step: 8
Training loss: 0.7257475852966309
Validation loss: 2.1033631563186646

Epoch: 5| Step: 9
Training loss: 0.8792020678520203
Validation loss: 2.0847425162792206

Epoch: 5| Step: 10
Training loss: 0.579603374004364
Validation loss: 2.1213463147481284

Epoch: 5| Step: 11
Training loss: 0.5884907245635986
Validation loss: 2.0771569460630417

Epoch: 209| Step: 0
Training loss: 0.6598199605941772
Validation loss: 2.094679594039917

Epoch: 5| Step: 1
Training loss: 0.796451985836029
Validation loss: 2.1142466912666955

Epoch: 5| Step: 2
Training loss: 0.5665696263313293
Validation loss: 2.1014284243186316

Epoch: 5| Step: 3
Training loss: 0.5437184572219849
Validation loss: 2.0991795361042023

Epoch: 5| Step: 4
Training loss: 0.4682542681694031
Validation loss: 2.147355298201243

Epoch: 5| Step: 5
Training loss: 0.31127697229385376
Validation loss: 2.13005564113458

Epoch: 5| Step: 6
Training loss: 0.74797523021698
Validation loss: 2.123878781994184

Epoch: 5| Step: 7
Training loss: 0.9325879216194153
Validation loss: 2.131897528966268

Epoch: 5| Step: 8
Training loss: 0.5147618055343628
Validation loss: 2.124582275748253

Epoch: 5| Step: 9
Training loss: 0.6173109412193298
Validation loss: 2.103605260451635

Epoch: 5| Step: 10
Training loss: 0.8300420641899109
Validation loss: 2.098728890220324

Epoch: 5| Step: 11
Training loss: 0.2851409912109375
Validation loss: 2.094668835401535

Epoch: 210| Step: 0
Training loss: 0.5486377477645874
Validation loss: 2.1146056751410165

Epoch: 5| Step: 1
Training loss: 0.8481589555740356
Validation loss: 2.091228872537613

Epoch: 5| Step: 2
Training loss: 0.5474602580070496
Validation loss: 2.076289862394333

Epoch: 5| Step: 3
Training loss: 0.3898066580295563
Validation loss: 2.0844427943229675

Epoch: 5| Step: 4
Training loss: 0.5454607009887695
Validation loss: 2.1415874610344567

Epoch: 5| Step: 5
Training loss: 0.7416645884513855
Validation loss: 2.109042152762413

Epoch: 5| Step: 6
Training loss: 0.5468848347663879
Validation loss: 2.095125377178192

Epoch: 5| Step: 7
Training loss: 0.8783552050590515
Validation loss: 2.06498388449351

Epoch: 5| Step: 8
Training loss: 0.6282572150230408
Validation loss: 2.039085179567337

Epoch: 5| Step: 9
Training loss: 0.2876787781715393
Validation loss: 2.0912833015124

Epoch: 5| Step: 10
Training loss: 0.8093683123588562
Validation loss: 2.077540506919225

Epoch: 5| Step: 11
Training loss: 0.21078509092330933
Validation loss: 2.02293353776137

Epoch: 211| Step: 0
Training loss: 0.3034176230430603
Validation loss: 2.0503740161657333

Epoch: 5| Step: 1
Training loss: 0.6525042653083801
Validation loss: 2.052992964784304

Epoch: 5| Step: 2
Training loss: 0.774173378944397
Validation loss: 2.0332217663526535

Epoch: 5| Step: 3
Training loss: 0.9116361737251282
Validation loss: 2.0138331254323325

Epoch: 5| Step: 4
Training loss: 0.5797156691551208
Validation loss: 2.0932294130325317

Epoch: 5| Step: 5
Training loss: 0.3265576958656311
Validation loss: 2.0895047585169473

Epoch: 5| Step: 6
Training loss: 0.8198482394218445
Validation loss: 2.1025116642316184

Epoch: 5| Step: 7
Training loss: 0.7008576393127441
Validation loss: 2.1713395019372306

Epoch: 5| Step: 8
Training loss: 0.9680048823356628
Validation loss: 2.1381460626920066

Epoch: 5| Step: 9
Training loss: 1.129058599472046
Validation loss: 2.1136328279972076

Epoch: 5| Step: 10
Training loss: 0.729627788066864
Validation loss: 2.0799163480599723

Epoch: 5| Step: 11
Training loss: 0.2257857769727707
Validation loss: 2.135434150695801

Epoch: 212| Step: 0
Training loss: 0.8344175219535828
Validation loss: 2.0445772310098014

Epoch: 5| Step: 1
Training loss: 0.3997277319431305
Validation loss: 2.094323347012202

Epoch: 5| Step: 2
Training loss: 0.6362881660461426
Validation loss: 2.007033040126165

Epoch: 5| Step: 3
Training loss: 0.6196786165237427
Validation loss: 2.036745031674703

Epoch: 5| Step: 4
Training loss: 0.6918582320213318
Validation loss: 2.043591563900312

Epoch: 5| Step: 5
Training loss: 0.6326307058334351
Validation loss: 2.0900083780288696

Epoch: 5| Step: 6
Training loss: 0.6263612508773804
Validation loss: 2.0564813564221063

Epoch: 5| Step: 7
Training loss: 0.5021851658821106
Validation loss: 2.115348373850187

Epoch: 5| Step: 8
Training loss: 0.7207158207893372
Validation loss: 2.111420397957166

Epoch: 5| Step: 9
Training loss: 0.44714394211769104
Validation loss: 2.088313177227974

Epoch: 5| Step: 10
Training loss: 0.5087687373161316
Validation loss: 2.08992629746596

Epoch: 5| Step: 11
Training loss: 0.5802289247512817
Validation loss: 2.121386006474495

Epoch: 213| Step: 0
Training loss: 0.6871798038482666
Validation loss: 2.0743279655774436

Epoch: 5| Step: 1
Training loss: 0.5264885425567627
Validation loss: 2.08159431318442

Epoch: 5| Step: 2
Training loss: 0.4594550132751465
Validation loss: 2.0974107633034387

Epoch: 5| Step: 3
Training loss: 0.4871329665184021
Validation loss: 2.0563771526018777

Epoch: 5| Step: 4
Training loss: 0.41227492690086365
Validation loss: 2.1049939741690955

Epoch: 5| Step: 5
Training loss: 0.6869634985923767
Validation loss: 2.104198858141899

Epoch: 5| Step: 6
Training loss: 0.5503064393997192
Validation loss: 2.117694934209188

Epoch: 5| Step: 7
Training loss: 0.7108587026596069
Validation loss: 2.092828576763471

Epoch: 5| Step: 8
Training loss: 0.749215841293335
Validation loss: 2.1177556167046228

Epoch: 5| Step: 9
Training loss: 0.6787075996398926
Validation loss: 2.1208372960488

Epoch: 5| Step: 10
Training loss: 0.6145378947257996
Validation loss: 2.047010526061058

Epoch: 5| Step: 11
Training loss: 0.8763554096221924
Validation loss: 2.0795123229424157

Epoch: 214| Step: 0
Training loss: 0.52021723985672
Validation loss: 2.1376474698384604

Epoch: 5| Step: 1
Training loss: 0.5584332346916199
Validation loss: 2.082940489053726

Epoch: 5| Step: 2
Training loss: 0.7600491046905518
Validation loss: 2.0809835294882455

Epoch: 5| Step: 3
Training loss: 0.43595972657203674
Validation loss: 2.0629978328943253

Epoch: 5| Step: 4
Training loss: 0.37623509764671326
Validation loss: 2.072299376130104

Epoch: 5| Step: 5
Training loss: 0.8818120956420898
Validation loss: 2.091726173957189

Epoch: 5| Step: 6
Training loss: 0.5136479139328003
Validation loss: 2.1127044955889382

Epoch: 5| Step: 7
Training loss: 0.7133496999740601
Validation loss: 2.1054570029179254

Epoch: 5| Step: 8
Training loss: 0.7354357838630676
Validation loss: 2.1246867030858994

Epoch: 5| Step: 9
Training loss: 0.8027946352958679
Validation loss: 2.083908806244532

Epoch: 5| Step: 10
Training loss: 0.5480071306228638
Validation loss: 2.0782266557216644

Epoch: 5| Step: 11
Training loss: 0.575426459312439
Validation loss: 2.119952673713366

Epoch: 215| Step: 0
Training loss: 0.8598904609680176
Validation loss: 2.084669758876165

Epoch: 5| Step: 1
Training loss: 0.48610973358154297
Validation loss: 2.0747269292672477

Epoch: 5| Step: 2
Training loss: 0.5816363096237183
Validation loss: 2.0691366543372474

Epoch: 5| Step: 3
Training loss: 0.39529648423194885
Validation loss: 2.1548968801895776

Epoch: 5| Step: 4
Training loss: 0.5356295108795166
Validation loss: 2.131867468357086

Epoch: 5| Step: 5
Training loss: 0.3832513689994812
Validation loss: 2.1498697251081467

Epoch: 5| Step: 6
Training loss: 0.741497814655304
Validation loss: 2.126419425010681

Epoch: 5| Step: 7
Training loss: 0.3613714277744293
Validation loss: 2.169040491183599

Epoch: 5| Step: 8
Training loss: 0.8098249435424805
Validation loss: 2.1482081711292267

Epoch: 5| Step: 9
Training loss: 0.5427886247634888
Validation loss: 2.0932043343782425

Epoch: 5| Step: 10
Training loss: 0.5897588729858398
Validation loss: 2.1529373476902642

Epoch: 5| Step: 11
Training loss: 1.5815349817276
Validation loss: 2.0716791500647864

Epoch: 216| Step: 0
Training loss: 0.458646684885025
Validation loss: 2.096908450126648

Epoch: 5| Step: 1
Training loss: 0.4395987391471863
Validation loss: 2.0936580995718637

Epoch: 5| Step: 2
Training loss: 0.6326645016670227
Validation loss: 2.0984349995851517

Epoch: 5| Step: 3
Training loss: 0.6986274719238281
Validation loss: 2.1121040334304175

Epoch: 5| Step: 4
Training loss: 0.4089243412017822
Validation loss: 2.070988823970159

Epoch: 5| Step: 5
Training loss: 0.4167171120643616
Validation loss: 2.1037849386533103

Epoch: 5| Step: 6
Training loss: 0.22769208252429962
Validation loss: 2.0625017235676446

Epoch: 5| Step: 7
Training loss: 1.0640373229980469
Validation loss: 2.084770212570826

Epoch: 5| Step: 8
Training loss: 0.5604015588760376
Validation loss: 2.061579242348671

Epoch: 5| Step: 9
Training loss: 0.6979765892028809
Validation loss: 2.08205047249794

Epoch: 5| Step: 10
Training loss: 0.6043013334274292
Validation loss: 2.045124833782514

Epoch: 5| Step: 11
Training loss: 0.68163001537323
Validation loss: 2.068186109264692

Epoch: 217| Step: 0
Training loss: 0.5677609443664551
Validation loss: 2.0920317669709525

Epoch: 5| Step: 1
Training loss: 0.8344818949699402
Validation loss: 2.0847978591918945

Epoch: 5| Step: 2
Training loss: 0.6691204905509949
Validation loss: 2.0579254925251007

Epoch: 5| Step: 3
Training loss: 0.6441400051116943
Validation loss: 2.036032641927401

Epoch: 5| Step: 4
Training loss: 0.43427786231040955
Validation loss: 2.0329261670509973

Epoch: 5| Step: 5
Training loss: 0.6647045612335205
Validation loss: 2.0370541910330453

Epoch: 5| Step: 6
Training loss: 0.4639841914176941
Validation loss: 2.085683509707451

Epoch: 5| Step: 7
Training loss: 0.44919055700302124
Validation loss: 2.054960841933886

Epoch: 5| Step: 8
Training loss: 0.670789361000061
Validation loss: 2.106927275657654

Epoch: 5| Step: 9
Training loss: 0.5264492630958557
Validation loss: 2.123783598343531

Epoch: 5| Step: 10
Training loss: 0.8473525047302246
Validation loss: 2.1689183761676154

Epoch: 5| Step: 11
Training loss: 0.8233258724212646
Validation loss: 2.1058017909526825

Epoch: 218| Step: 0
Training loss: 0.5278798341751099
Validation loss: 2.0804801881313324

Epoch: 5| Step: 1
Training loss: 0.45324334502220154
Validation loss: 2.087788080175718

Epoch: 5| Step: 2
Training loss: 0.8743292689323425
Validation loss: 2.0554491182168326

Epoch: 5| Step: 3
Training loss: 0.6098091006278992
Validation loss: 2.012002189954122

Epoch: 5| Step: 4
Training loss: 0.8732174038887024
Validation loss: 2.0389945109685264

Epoch: 5| Step: 5
Training loss: 0.7010459899902344
Validation loss: 2.097350319226583

Epoch: 5| Step: 6
Training loss: 0.5199761390686035
Validation loss: 2.078852375348409

Epoch: 5| Step: 7
Training loss: 0.7375130653381348
Validation loss: 2.086753030618032

Epoch: 5| Step: 8
Training loss: 0.8623207807540894
Validation loss: 2.0562729835510254

Epoch: 5| Step: 9
Training loss: 0.35384345054626465
Validation loss: 2.087138002117475

Epoch: 5| Step: 10
Training loss: 0.41266387701034546
Validation loss: 2.074562440315882

Epoch: 5| Step: 11
Training loss: 0.4971151351928711
Validation loss: 2.0804504255453744

Epoch: 219| Step: 0
Training loss: 0.5927523374557495
Validation loss: 2.0447874069213867

Epoch: 5| Step: 1
Training loss: 0.643067479133606
Validation loss: 2.0916010439395905

Epoch: 5| Step: 2
Training loss: 1.0348182916641235
Validation loss: 2.0097451408704123

Epoch: 5| Step: 3
Training loss: 0.7527499794960022
Validation loss: 2.0567840735117593

Epoch: 5| Step: 4
Training loss: 0.6363053917884827
Validation loss: 2.109034771720568

Epoch: 5| Step: 5
Training loss: 0.3190026879310608
Validation loss: 2.0925266991058984

Epoch: 5| Step: 6
Training loss: 0.41615206003189087
Validation loss: 2.1787315954764686

Epoch: 5| Step: 7
Training loss: 0.32041135430336
Validation loss: 2.155774181087812

Epoch: 5| Step: 8
Training loss: 0.6262823939323425
Validation loss: 2.1477594077587128

Epoch: 5| Step: 9
Training loss: 0.8816627264022827
Validation loss: 2.1288118412097297

Epoch: 5| Step: 10
Training loss: 0.5609839558601379
Validation loss: 2.086205616593361

Epoch: 5| Step: 11
Training loss: 0.2709118127822876
Validation loss: 2.1415974497795105

Epoch: 220| Step: 0
Training loss: 0.31731149554252625
Validation loss: 2.1321688691775003

Epoch: 5| Step: 1
Training loss: 0.5251067876815796
Validation loss: 2.163690075278282

Epoch: 5| Step: 2
Training loss: 0.39845436811447144
Validation loss: 2.125905195871989

Epoch: 5| Step: 3
Training loss: 0.7523884177207947
Validation loss: 2.108801379799843

Epoch: 5| Step: 4
Training loss: 0.6213769912719727
Validation loss: 2.1401038666566214

Epoch: 5| Step: 5
Training loss: 0.31603842973709106
Validation loss: 2.1276364773511887

Epoch: 5| Step: 6
Training loss: 0.5687407851219177
Validation loss: 2.19156006971995

Epoch: 5| Step: 7
Training loss: 0.6396849751472473
Validation loss: 2.2295256902774176

Epoch: 5| Step: 8
Training loss: 0.9128181338310242
Validation loss: 2.1931333343187966

Epoch: 5| Step: 9
Training loss: 0.7880403399467468
Validation loss: 2.1497933665911355

Epoch: 5| Step: 10
Training loss: 0.6334758400917053
Validation loss: 2.1409724752108255

Epoch: 5| Step: 11
Training loss: 1.0536670684814453
Validation loss: 2.1755628089110055

Epoch: 221| Step: 0
Training loss: 0.6030505895614624
Validation loss: 2.120665887991587

Epoch: 5| Step: 1
Training loss: 0.581488311290741
Validation loss: 2.067543089389801

Epoch: 5| Step: 2
Training loss: 0.37373003363609314
Validation loss: 2.1414992213249207

Epoch: 5| Step: 3
Training loss: 0.8977959752082825
Validation loss: 2.1206736067930856

Epoch: 5| Step: 4
Training loss: 0.4442957937717438
Validation loss: 2.1065030793348947

Epoch: 5| Step: 5
Training loss: 0.48921871185302734
Validation loss: 2.1595319459835687

Epoch: 5| Step: 6
Training loss: 0.46672481298446655
Validation loss: 2.1041967322429023

Epoch: 5| Step: 7
Training loss: 0.45964640378952026
Validation loss: 2.119669740398725

Epoch: 5| Step: 8
Training loss: 0.7858632802963257
Validation loss: 2.063348005215327

Epoch: 5| Step: 9
Training loss: 0.6379910707473755
Validation loss: 2.081188832720121

Epoch: 5| Step: 10
Training loss: 0.7716115713119507
Validation loss: 2.1235204339027405

Epoch: 5| Step: 11
Training loss: 0.13186991214752197
Validation loss: 2.095720648765564

Epoch: 222| Step: 0
Training loss: 0.577086329460144
Validation loss: 2.129540209968885

Epoch: 5| Step: 1
Training loss: 0.5232627987861633
Validation loss: 2.0869472473859787

Epoch: 5| Step: 2
Training loss: 0.6557294130325317
Validation loss: 2.1250915428002677

Epoch: 5| Step: 3
Training loss: 0.47013601660728455
Validation loss: 2.1736184606949487

Epoch: 5| Step: 4
Training loss: 0.35042062401771545
Validation loss: 2.077188769976298

Epoch: 5| Step: 5
Training loss: 0.6172305345535278
Validation loss: 2.129342714945475

Epoch: 5| Step: 6
Training loss: 0.5927273035049438
Validation loss: 2.163093780477842

Epoch: 5| Step: 7
Training loss: 0.5681824684143066
Validation loss: 2.124233032266299

Epoch: 5| Step: 8
Training loss: 0.5937826037406921
Validation loss: 2.1114480594793954

Epoch: 5| Step: 9
Training loss: 0.8339131474494934
Validation loss: 2.1231897672017417

Epoch: 5| Step: 10
Training loss: 0.3340456783771515
Validation loss: 2.1063179473082223

Epoch: 5| Step: 11
Training loss: 0.35389983654022217
Validation loss: 2.0560473601023355

Epoch: 223| Step: 0
Training loss: 0.6513159871101379
Validation loss: 2.0699249456326165

Epoch: 5| Step: 1
Training loss: 0.7412235140800476
Validation loss: 2.1138084729512534

Epoch: 5| Step: 2
Training loss: 0.5182200074195862
Validation loss: 2.118814835945765

Epoch: 5| Step: 3
Training loss: 0.384633332490921
Validation loss: 2.1286447743574777

Epoch: 5| Step: 4
Training loss: 0.2868272066116333
Validation loss: 2.1396149893601737

Epoch: 5| Step: 5
Training loss: 0.3649756908416748
Validation loss: 2.0997897684574127

Epoch: 5| Step: 6
Training loss: 0.6673140525817871
Validation loss: 2.0908943861722946

Epoch: 5| Step: 7
Training loss: 0.5553759932518005
Validation loss: 2.0981260240077972

Epoch: 5| Step: 8
Training loss: 0.6589383482933044
Validation loss: 2.097766881187757

Epoch: 5| Step: 9
Training loss: 0.4210028648376465
Validation loss: 2.089719990889231

Epoch: 5| Step: 10
Training loss: 0.882280707359314
Validation loss: 2.1343367248773575

Epoch: 5| Step: 11
Training loss: 0.388883113861084
Validation loss: 2.1545063108205795

Epoch: 224| Step: 0
Training loss: 0.6842414140701294
Validation loss: 2.142300099134445

Epoch: 5| Step: 1
Training loss: 0.8480289578437805
Validation loss: 2.1642238795757294

Epoch: 5| Step: 2
Training loss: 0.6950391530990601
Validation loss: 2.18833589553833

Epoch: 5| Step: 3
Training loss: 0.43939080834388733
Validation loss: 2.1859575311342874

Epoch: 5| Step: 4
Training loss: 0.7697661519050598
Validation loss: 2.149288902680079

Epoch: 5| Step: 5
Training loss: 0.7567778825759888
Validation loss: 2.1077207078536353

Epoch: 5| Step: 6
Training loss: 0.6877338290214539
Validation loss: 2.085451011856397

Epoch: 5| Step: 7
Training loss: 0.333499014377594
Validation loss: 2.1106353203455606

Epoch: 5| Step: 8
Training loss: 0.5872331857681274
Validation loss: 2.0572096655766168

Epoch: 5| Step: 9
Training loss: 0.6730290651321411
Validation loss: 2.0612892707188926

Epoch: 5| Step: 10
Training loss: 0.35324805974960327
Validation loss: 2.132022807995478

Epoch: 5| Step: 11
Training loss: 0.3500082492828369
Validation loss: 2.083439807097117

Epoch: 225| Step: 0
Training loss: 0.3803766369819641
Validation loss: 2.1200907975435257

Epoch: 5| Step: 1
Training loss: 0.7283774614334106
Validation loss: 2.147683784365654

Epoch: 5| Step: 2
Training loss: 0.4196349084377289
Validation loss: 2.179098298152288

Epoch: 5| Step: 3
Training loss: 0.4836927354335785
Validation loss: 2.1764873017867408

Epoch: 5| Step: 4
Training loss: 0.4541175365447998
Validation loss: 2.1006849259138107

Epoch: 5| Step: 5
Training loss: 0.5470250844955444
Validation loss: 2.1313007473945618

Epoch: 5| Step: 6
Training loss: 0.6535495519638062
Validation loss: 2.0825595259666443

Epoch: 5| Step: 7
Training loss: 0.3609790503978729
Validation loss: 2.134666899840037

Epoch: 5| Step: 8
Training loss: 0.5206389427185059
Validation loss: 2.088544105490049

Epoch: 5| Step: 9
Training loss: 0.8302914500236511
Validation loss: 2.0536552419265113

Epoch: 5| Step: 10
Training loss: 0.5816450119018555
Validation loss: 2.0501269102096558

Epoch: 5| Step: 11
Training loss: 0.6097699403762817
Validation loss: 2.1773723860581717

Epoch: 226| Step: 0
Training loss: 0.5652059316635132
Validation loss: 2.1018096605936685

Epoch: 5| Step: 1
Training loss: 0.32328781485557556
Validation loss: 2.131043349703153

Epoch: 5| Step: 2
Training loss: 0.5341160297393799
Validation loss: 2.1478693187236786

Epoch: 5| Step: 3
Training loss: 0.5554298162460327
Validation loss: 2.1659671862920127

Epoch: 5| Step: 4
Training loss: 0.4920128285884857
Validation loss: 2.1869389712810516

Epoch: 5| Step: 5
Training loss: 0.9412804841995239
Validation loss: 2.1732911119858422

Epoch: 5| Step: 6
Training loss: 0.6225509643554688
Validation loss: 2.113922263185183

Epoch: 5| Step: 7
Training loss: 0.41949644684791565
Validation loss: 2.1003779073556266

Epoch: 5| Step: 8
Training loss: 0.3650842308998108
Validation loss: 2.1268004328012466

Epoch: 5| Step: 9
Training loss: 0.5293108224868774
Validation loss: 2.1363279670476913

Epoch: 5| Step: 10
Training loss: 0.8809381723403931
Validation loss: 2.1367069482803345

Epoch: 5| Step: 11
Training loss: 0.12068772315979004
Validation loss: 2.1188726276159286

Epoch: 227| Step: 0
Training loss: 0.6891593337059021
Validation loss: 2.0939816435178122

Epoch: 5| Step: 1
Training loss: 0.5677490830421448
Validation loss: 2.139516348640124

Epoch: 5| Step: 2
Training loss: 0.37537091970443726
Validation loss: 2.0725367615620294

Epoch: 5| Step: 3
Training loss: 1.0012702941894531
Validation loss: 2.1156898140907288

Epoch: 5| Step: 4
Training loss: 0.3167780935764313
Validation loss: 2.012035330136617

Epoch: 5| Step: 5
Training loss: 0.529582142829895
Validation loss: 2.106713831424713

Epoch: 5| Step: 6
Training loss: 0.4991956651210785
Validation loss: 2.110835909843445

Epoch: 5| Step: 7
Training loss: 0.4586721360683441
Validation loss: 2.101335475842158

Epoch: 5| Step: 8
Training loss: 0.6152995824813843
Validation loss: 2.0846263766288757

Epoch: 5| Step: 9
Training loss: 0.442221462726593
Validation loss: 2.074723482131958

Epoch: 5| Step: 10
Training loss: 0.5129247903823853
Validation loss: 2.0801155219475427

Epoch: 5| Step: 11
Training loss: 0.37648433446884155
Validation loss: 2.0774133751789727

Epoch: 228| Step: 0
Training loss: 0.8561121225357056
Validation loss: 2.1078712145487466

Epoch: 5| Step: 1
Training loss: 0.35757142305374146
Validation loss: 2.115384687980016

Epoch: 5| Step: 2
Training loss: 0.401266485452652
Validation loss: 2.178917611638705

Epoch: 5| Step: 3
Training loss: 0.5088950991630554
Validation loss: 2.205302635828654

Epoch: 5| Step: 4
Training loss: 0.3581233620643616
Validation loss: 2.1377684473991394

Epoch: 5| Step: 5
Training loss: 0.6862152218818665
Validation loss: 2.142322316765785

Epoch: 5| Step: 6
Training loss: 0.5803111791610718
Validation loss: 2.133409137527148

Epoch: 5| Step: 7
Training loss: 0.41583317518234253
Validation loss: 2.1130783359209695

Epoch: 5| Step: 8
Training loss: 0.6564521789550781
Validation loss: 2.0785270780324936

Epoch: 5| Step: 9
Training loss: 0.4149020314216614
Validation loss: 2.1011913816134133

Epoch: 5| Step: 10
Training loss: 0.7101517915725708
Validation loss: 2.0748187055190406

Epoch: 5| Step: 11
Training loss: 0.6409783959388733
Validation loss: 2.1009593407313027

Epoch: 229| Step: 0
Training loss: 0.43130818009376526
Validation loss: 2.078405484557152

Epoch: 5| Step: 1
Training loss: 0.3248036801815033
Validation loss: 2.1073538959026337

Epoch: 5| Step: 2
Training loss: 0.5920819044113159
Validation loss: 2.0819528996944427

Epoch: 5| Step: 3
Training loss: 0.3789104223251343
Validation loss: 2.1423213531573615

Epoch: 5| Step: 4
Training loss: 0.933483898639679
Validation loss: 2.1594464580217996

Epoch: 5| Step: 5
Training loss: 0.38498979806900024
Validation loss: 2.1163402696450553

Epoch: 5| Step: 6
Training loss: 0.45173636078834534
Validation loss: 2.0993828078111014

Epoch: 5| Step: 7
Training loss: 0.7873241305351257
Validation loss: 2.0847556591033936

Epoch: 5| Step: 8
Training loss: 0.6975191235542297
Validation loss: 2.084492484728495

Epoch: 5| Step: 9
Training loss: 0.5218798518180847
Validation loss: 2.041093463699023

Epoch: 5| Step: 10
Training loss: 0.6051254868507385
Validation loss: 2.0372075339158378

Epoch: 5| Step: 11
Training loss: 0.860295295715332
Validation loss: 2.057134658098221

Epoch: 230| Step: 0
Training loss: 0.7709800004959106
Validation loss: 2.0726515700419745

Epoch: 5| Step: 1
Training loss: 0.655204176902771
Validation loss: 2.1266162246465683

Epoch: 5| Step: 2
Training loss: 0.6052418351173401
Validation loss: 2.122480163971583

Epoch: 5| Step: 3
Training loss: 0.8279241323471069
Validation loss: 2.142158349355062

Epoch: 5| Step: 4
Training loss: 0.6212190389633179
Validation loss: 2.124486416578293

Epoch: 5| Step: 5
Training loss: 0.562106192111969
Validation loss: 2.0948740541934967

Epoch: 5| Step: 6
Training loss: 0.30096694827079773
Validation loss: 2.0827657679716745

Epoch: 5| Step: 7
Training loss: 0.437906414270401
Validation loss: 2.081509013970693

Epoch: 5| Step: 8
Training loss: 0.5421240925788879
Validation loss: 2.044661412636439

Epoch: 5| Step: 9
Training loss: 0.7466446161270142
Validation loss: 2.027292107542356

Epoch: 5| Step: 10
Training loss: 0.5690950155258179
Validation loss: 2.0869523137807846

Epoch: 5| Step: 11
Training loss: 0.10830181837081909
Validation loss: 2.0941449453433356

Epoch: 231| Step: 0
Training loss: 0.6913338899612427
Validation loss: 2.118798186381658

Epoch: 5| Step: 1
Training loss: 0.5467481017112732
Validation loss: 2.129660035173098

Epoch: 5| Step: 2
Training loss: 0.7056490182876587
Validation loss: 2.093306506673495

Epoch: 5| Step: 3
Training loss: 0.8535893559455872
Validation loss: 2.188324640194575

Epoch: 5| Step: 4
Training loss: 0.3063787519931793
Validation loss: 2.1861831148465476

Epoch: 5| Step: 5
Training loss: 0.5036402940750122
Validation loss: 2.152046928803126

Epoch: 5| Step: 6
Training loss: 0.6228179335594177
Validation loss: 2.1964068710803986

Epoch: 5| Step: 7
Training loss: 0.4061817526817322
Validation loss: 2.1878358125686646

Epoch: 5| Step: 8
Training loss: 0.3834361135959625
Validation loss: 2.1175851126511893

Epoch: 5| Step: 9
Training loss: 0.4624854028224945
Validation loss: 2.05591390033563

Epoch: 5| Step: 10
Training loss: 0.31242430210113525
Validation loss: 2.156868805487951

Epoch: 5| Step: 11
Training loss: 0.5742224454879761
Validation loss: 2.129435896873474

Epoch: 232| Step: 0
Training loss: 0.45041871070861816
Validation loss: 2.1199893107016883

Epoch: 5| Step: 1
Training loss: 0.6457255482673645
Validation loss: 2.0616031885147095

Epoch: 5| Step: 2
Training loss: 0.8468402028083801
Validation loss: 2.132061004638672

Epoch: 5| Step: 3
Training loss: 0.3245161473751068
Validation loss: 2.0792177816232047

Epoch: 5| Step: 4
Training loss: 0.756003737449646
Validation loss: 2.124202142159144

Epoch: 5| Step: 5
Training loss: 0.43891477584838867
Validation loss: 2.103797202308973

Epoch: 5| Step: 6
Training loss: 0.7684488296508789
Validation loss: 2.109220008055369

Epoch: 5| Step: 7
Training loss: 0.47266045212745667
Validation loss: 2.1177764534950256

Epoch: 5| Step: 8
Training loss: 0.3991665244102478
Validation loss: 2.132894059022268

Epoch: 5| Step: 9
Training loss: 0.31778016686439514
Validation loss: 2.1178659896055856

Epoch: 5| Step: 10
Training loss: 0.6009541153907776
Validation loss: 2.127067804336548

Epoch: 5| Step: 11
Training loss: 0.8778508901596069
Validation loss: 2.1021581490834556

Epoch: 233| Step: 0
Training loss: 0.29872092604637146
Validation loss: 2.126115138332049

Epoch: 5| Step: 1
Training loss: 0.397602379322052
Validation loss: 2.183145900567373

Epoch: 5| Step: 2
Training loss: 0.44662055373191833
Validation loss: 2.1827823321024575

Epoch: 5| Step: 3
Training loss: 0.46457403898239136
Validation loss: 2.1786959866682687

Epoch: 5| Step: 4
Training loss: 0.5909439325332642
Validation loss: 2.1476946274439492

Epoch: 5| Step: 5
Training loss: 0.7237216234207153
Validation loss: 2.133835345506668

Epoch: 5| Step: 6
Training loss: 1.000882625579834
Validation loss: 2.0866892536481223

Epoch: 5| Step: 7
Training loss: 0.5990157127380371
Validation loss: 2.1619410465161004

Epoch: 5| Step: 8
Training loss: 0.4477974772453308
Validation loss: 2.1302910447120667

Epoch: 5| Step: 9
Training loss: 0.34233665466308594
Validation loss: 2.1812576154867807

Epoch: 5| Step: 10
Training loss: 0.5453694462776184
Validation loss: 2.1875460942586265

Epoch: 5| Step: 11
Training loss: 0.41312727332115173
Validation loss: 2.1906157483657203

Epoch: 234| Step: 0
Training loss: 0.3032134175300598
Validation loss: 2.1478654543558755

Epoch: 5| Step: 1
Training loss: 0.32300201058387756
Validation loss: 2.2009839663902917

Epoch: 5| Step: 2
Training loss: 1.0046876668930054
Validation loss: 2.1330199042956033

Epoch: 5| Step: 3
Training loss: 0.5204986333847046
Validation loss: 2.1290942430496216

Epoch: 5| Step: 4
Training loss: 0.38243764638900757
Validation loss: 2.0934829463561377

Epoch: 5| Step: 5
Training loss: 0.4108816981315613
Validation loss: 2.133881226181984

Epoch: 5| Step: 6
Training loss: 0.3872484862804413
Validation loss: 2.1599646707375846

Epoch: 5| Step: 7
Training loss: 0.26301121711730957
Validation loss: 2.1008086651563644

Epoch: 5| Step: 8
Training loss: 0.5505169034004211
Validation loss: 2.0976216942071915

Epoch: 5| Step: 9
Training loss: 0.5735419988632202
Validation loss: 2.1095352123181024

Epoch: 5| Step: 10
Training loss: 0.8428066372871399
Validation loss: 2.1334063013394675

Epoch: 5| Step: 11
Training loss: 0.4159320890903473
Validation loss: 2.172920604546865

Epoch: 235| Step: 0
Training loss: 0.5705119371414185
Validation loss: 2.2009513278802237

Epoch: 5| Step: 1
Training loss: 0.4571158289909363
Validation loss: 2.184434403975805

Epoch: 5| Step: 2
Training loss: 0.39806514978408813
Validation loss: 2.0893197854359946

Epoch: 5| Step: 3
Training loss: 0.5242429971694946
Validation loss: 2.041459863384565

Epoch: 5| Step: 4
Training loss: 0.3744131624698639
Validation loss: 2.136336639523506

Epoch: 5| Step: 5
Training loss: 1.1023972034454346
Validation loss: 2.123732546965281

Epoch: 5| Step: 6
Training loss: 0.5100275278091431
Validation loss: 2.1559105118115744

Epoch: 5| Step: 7
Training loss: 0.5058571100234985
Validation loss: 2.1560393621524176

Epoch: 5| Step: 8
Training loss: 0.5432682037353516
Validation loss: 2.133518561720848

Epoch: 5| Step: 9
Training loss: 0.5117594003677368
Validation loss: 2.0923976053794227

Epoch: 5| Step: 10
Training loss: 0.5035828351974487
Validation loss: 2.1003662049770355

Epoch: 5| Step: 11
Training loss: 0.5337771773338318
Validation loss: 2.167852242787679

Epoch: 236| Step: 0
Training loss: 0.4930049777030945
Validation loss: 2.1067956338326135

Epoch: 5| Step: 1
Training loss: 0.8289843797683716
Validation loss: 2.0793791313966117

Epoch: 5| Step: 2
Training loss: 0.6552091240882874
Validation loss: 2.08805579940478

Epoch: 5| Step: 3
Training loss: 0.7123995423316956
Validation loss: 2.041576792796453

Epoch: 5| Step: 4
Training loss: 0.5193454027175903
Validation loss: 2.0745982229709625

Epoch: 5| Step: 5
Training loss: 0.3210139572620392
Validation loss: 2.082292596499125

Epoch: 5| Step: 6
Training loss: 0.4211978018283844
Validation loss: 2.0836445838212967

Epoch: 5| Step: 7
Training loss: 0.5345669984817505
Validation loss: 2.1092234601577124

Epoch: 5| Step: 8
Training loss: 0.591063380241394
Validation loss: 2.1450508336226144

Epoch: 5| Step: 9
Training loss: 0.5016489028930664
Validation loss: 2.0908821721871695

Epoch: 5| Step: 10
Training loss: 0.3615959882736206
Validation loss: 2.1144660810629525

Epoch: 5| Step: 11
Training loss: 0.550757646560669
Validation loss: 2.136289750536283

Epoch: 237| Step: 0
Training loss: 0.4739662706851959
Validation loss: 2.175994565089544

Epoch: 5| Step: 1
Training loss: 0.49913516640663147
Validation loss: 2.074607158700625

Epoch: 5| Step: 2
Training loss: 0.46863263845443726
Validation loss: 2.1651943723360696

Epoch: 5| Step: 3
Training loss: 0.4894157350063324
Validation loss: 2.166513661543528

Epoch: 5| Step: 4
Training loss: 0.6421312093734741
Validation loss: 2.095342382788658

Epoch: 5| Step: 5
Training loss: 0.5707599520683289
Validation loss: 2.11725352704525

Epoch: 5| Step: 6
Training loss: 0.3144007623195648
Validation loss: 2.0996207197507224

Epoch: 5| Step: 7
Training loss: 0.98004150390625
Validation loss: 2.1248889913161597

Epoch: 5| Step: 8
Training loss: 0.40689605474472046
Validation loss: 2.10700931151708

Epoch: 5| Step: 9
Training loss: 0.3691667914390564
Validation loss: 2.156092862288157

Epoch: 5| Step: 10
Training loss: 0.5270631909370422
Validation loss: 2.1168975283702216

Epoch: 5| Step: 11
Training loss: 0.5252470970153809
Validation loss: 2.1229268312454224

Epoch: 238| Step: 0
Training loss: 0.3311610817909241
Validation loss: 2.0968688825766244

Epoch: 5| Step: 1
Training loss: 0.44203394651412964
Validation loss: 2.044076899687449

Epoch: 5| Step: 2
Training loss: 0.44202250242233276
Validation loss: 2.096692383289337

Epoch: 5| Step: 3
Training loss: 0.6923109292984009
Validation loss: 2.0560413797696433

Epoch: 5| Step: 4
Training loss: 0.6797345876693726
Validation loss: 2.088686709602674

Epoch: 5| Step: 5
Training loss: 0.45281895995140076
Validation loss: 2.1286921997865043

Epoch: 5| Step: 6
Training loss: 0.4312703013420105
Validation loss: 2.085436299443245

Epoch: 5| Step: 7
Training loss: 0.522516667842865
Validation loss: 2.1659544110298157

Epoch: 5| Step: 8
Training loss: 0.5007633566856384
Validation loss: 2.09474079310894

Epoch: 5| Step: 9
Training loss: 0.6632528305053711
Validation loss: 2.1104919662078223

Epoch: 5| Step: 10
Training loss: 0.40013185143470764
Validation loss: 2.087840368350347

Epoch: 5| Step: 11
Training loss: 0.6005664467811584
Validation loss: 2.108894338210424

Epoch: 239| Step: 0
Training loss: 0.44165390729904175
Validation loss: 2.0905723174413047

Epoch: 5| Step: 1
Training loss: 0.39655980467796326
Validation loss: 2.0822503517071405

Epoch: 5| Step: 2
Training loss: 0.41796770691871643
Validation loss: 2.10259211063385

Epoch: 5| Step: 3
Training loss: 0.3250110447406769
Validation loss: 2.1004141867160797

Epoch: 5| Step: 4
Training loss: 0.19629937410354614
Validation loss: 2.117578829328219

Epoch: 5| Step: 5
Training loss: 0.665162205696106
Validation loss: 2.121129274368286

Epoch: 5| Step: 6
Training loss: 0.41372084617614746
Validation loss: 2.143280158440272

Epoch: 5| Step: 7
Training loss: 0.44643068313598633
Validation loss: 2.149802173177401

Epoch: 5| Step: 8
Training loss: 0.6016391515731812
Validation loss: 2.1211653848489127

Epoch: 5| Step: 9
Training loss: 0.5926183462142944
Validation loss: 2.1359351525704064

Epoch: 5| Step: 10
Training loss: 0.9328411221504211
Validation loss: 2.1135981182257333

Epoch: 5| Step: 11
Training loss: 0.323986291885376
Validation loss: 2.0806832114855447

Epoch: 240| Step: 0
Training loss: 0.5497575998306274
Validation loss: 2.1290247788031897

Epoch: 5| Step: 1
Training loss: 0.4202902913093567
Validation loss: 2.1361815432707467

Epoch: 5| Step: 2
Training loss: 0.33795401453971863
Validation loss: 2.140782212217649

Epoch: 5| Step: 3
Training loss: 0.5420582294464111
Validation loss: 2.097901319464048

Epoch: 5| Step: 4
Training loss: 0.5983048677444458
Validation loss: 2.1545947194099426

Epoch: 5| Step: 5
Training loss: 0.4737970232963562
Validation loss: 2.1487438678741455

Epoch: 5| Step: 6
Training loss: 0.32920923829078674
Validation loss: 2.0708809892336526

Epoch: 5| Step: 7
Training loss: 0.6963616609573364
Validation loss: 2.100599631667137

Epoch: 5| Step: 8
Training loss: 0.4251018166542053
Validation loss: 2.0938405990600586

Epoch: 5| Step: 9
Training loss: 0.7877545952796936
Validation loss: 2.0978997896114984

Epoch: 5| Step: 10
Training loss: 0.5697118043899536
Validation loss: 2.0875705977280936

Epoch: 5| Step: 11
Training loss: 0.21246790885925293
Validation loss: 2.10418002307415

Epoch: 241| Step: 0
Training loss: 0.32564201951026917
Validation loss: 2.072973365585009

Epoch: 5| Step: 1
Training loss: 0.45302706956863403
Validation loss: 2.093559205532074

Epoch: 5| Step: 2
Training loss: 0.6600367426872253
Validation loss: 2.1746963610251746

Epoch: 5| Step: 3
Training loss: 0.6793068051338196
Validation loss: 2.1724048256874084

Epoch: 5| Step: 4
Training loss: 0.5185257792472839
Validation loss: 2.1092195014158883

Epoch: 5| Step: 5
Training loss: 0.38094231486320496
Validation loss: 2.151438663403193

Epoch: 5| Step: 6
Training loss: 0.26926738023757935
Validation loss: 2.1139578918615975

Epoch: 5| Step: 7
Training loss: 0.5401166677474976
Validation loss: 2.125195413827896

Epoch: 5| Step: 8
Training loss: 0.448519229888916
Validation loss: 2.079822992285093

Epoch: 5| Step: 9
Training loss: 0.48938536643981934
Validation loss: 2.0659216940402985

Epoch: 5| Step: 10
Training loss: 0.7126694917678833
Validation loss: 2.0973710467418036

Epoch: 5| Step: 11
Training loss: 0.48217809200286865
Validation loss: 2.126154532035192

Epoch: 242| Step: 0
Training loss: 0.48235446214675903
Validation loss: 2.179622227946917

Epoch: 5| Step: 1
Training loss: 0.6053858995437622
Validation loss: 2.2540768682956696

Epoch: 5| Step: 2
Training loss: 0.8302013278007507
Validation loss: 2.1937992523113885

Epoch: 5| Step: 3
Training loss: 0.5549901723861694
Validation loss: 2.255709240833918

Epoch: 5| Step: 4
Training loss: 0.6531481146812439
Validation loss: 2.193451543649038

Epoch: 5| Step: 5
Training loss: 0.39868974685668945
Validation loss: 2.16660583515962

Epoch: 5| Step: 6
Training loss: 0.4770281910896301
Validation loss: 2.1335169076919556

Epoch: 5| Step: 7
Training loss: 0.6106477975845337
Validation loss: 2.155910740296046

Epoch: 5| Step: 8
Training loss: 0.4349202513694763
Validation loss: 2.104722003142039

Epoch: 5| Step: 9
Training loss: 0.694396436214447
Validation loss: 2.0940319995085397

Epoch: 5| Step: 10
Training loss: 0.7850035429000854
Validation loss: 2.080283522605896

Epoch: 5| Step: 11
Training loss: 0.342255175113678
Validation loss: 2.1312506645917892

Epoch: 243| Step: 0
Training loss: 0.31329146027565
Validation loss: 2.0929337441921234

Epoch: 5| Step: 1
Training loss: 0.8574385643005371
Validation loss: 2.177356014649073

Epoch: 5| Step: 2
Training loss: 0.5011144876480103
Validation loss: 2.161573648452759

Epoch: 5| Step: 3
Training loss: 0.46172595024108887
Validation loss: 2.1578958332538605

Epoch: 5| Step: 4
Training loss: 0.43681302666664124
Validation loss: 2.169757922490438

Epoch: 5| Step: 5
Training loss: 0.5825449824333191
Validation loss: 2.1092155228058496

Epoch: 5| Step: 6
Training loss: 0.8917186856269836
Validation loss: 2.1053594996531806

Epoch: 5| Step: 7
Training loss: 0.5440014600753784
Validation loss: 2.133033166329066

Epoch: 5| Step: 8
Training loss: 0.41268056631088257
Validation loss: 2.1060023307800293

Epoch: 5| Step: 9
Training loss: 0.28532853722572327
Validation loss: 2.0773408859968185

Epoch: 5| Step: 10
Training loss: 0.7528695464134216
Validation loss: 2.09909787774086

Epoch: 5| Step: 11
Training loss: 0.33377689123153687
Validation loss: 2.1175343493620553

Epoch: 244| Step: 0
Training loss: 0.3652350604534149
Validation loss: 2.1703391869862876

Epoch: 5| Step: 1
Training loss: 0.6943190693855286
Validation loss: 2.0932670136292777

Epoch: 5| Step: 2
Training loss: 0.7135065197944641
Validation loss: 2.0825486332178116

Epoch: 5| Step: 3
Training loss: 0.44096532464027405
Validation loss: 2.0947057753801346

Epoch: 5| Step: 4
Training loss: 0.5865346193313599
Validation loss: 2.1755501131216683

Epoch: 5| Step: 5
Training loss: 0.678385853767395
Validation loss: 2.1187231739362082

Epoch: 5| Step: 6
Training loss: 0.3036341071128845
Validation loss: 2.1540649086236954

Epoch: 5| Step: 7
Training loss: 0.45946693420410156
Validation loss: 2.175527885556221

Epoch: 5| Step: 8
Training loss: 0.33962956070899963
Validation loss: 2.1449739784002304

Epoch: 5| Step: 9
Training loss: 0.4693368077278137
Validation loss: 2.14453815917174

Epoch: 5| Step: 10
Training loss: 0.6077972650527954
Validation loss: 2.1533599148193994

Epoch: 5| Step: 11
Training loss: 0.5451867580413818
Validation loss: 2.1026252259810767

Epoch: 245| Step: 0
Training loss: 0.5991724133491516
Validation loss: 2.0514097660779953

Epoch: 5| Step: 1
Training loss: 0.44103294610977173
Validation loss: 2.105102260907491

Epoch: 5| Step: 2
Training loss: 0.5389978289604187
Validation loss: 2.089000478386879

Epoch: 5| Step: 3
Training loss: 0.6057172417640686
Validation loss: 2.0861110538244247

Epoch: 5| Step: 4
Training loss: 0.3744947016239166
Validation loss: 2.0988897184530892

Epoch: 5| Step: 5
Training loss: 0.7449571490287781
Validation loss: 2.1770176043113074

Epoch: 5| Step: 6
Training loss: 0.4752878248691559
Validation loss: 2.1624092012643814

Epoch: 5| Step: 7
Training loss: 0.3425014019012451
Validation loss: 2.1842930068572364

Epoch: 5| Step: 8
Training loss: 0.539088249206543
Validation loss: 2.141114036242167

Epoch: 5| Step: 9
Training loss: 0.38135385513305664
Validation loss: 2.1326810667912164

Epoch: 5| Step: 10
Training loss: 0.6827041506767273
Validation loss: 2.104974403977394

Epoch: 5| Step: 11
Training loss: 0.2390168309211731
Validation loss: 2.090797538558642

Epoch: 246| Step: 0
Training loss: 0.3975929617881775
Validation loss: 2.0562932143608728

Epoch: 5| Step: 1
Training loss: 0.33058038353919983
Validation loss: 2.0918799142042794

Epoch: 5| Step: 2
Training loss: 0.8432672619819641
Validation loss: 2.040470520655314

Epoch: 5| Step: 3
Training loss: 0.3371199667453766
Validation loss: 2.062130639950434

Epoch: 5| Step: 4
Training loss: 0.25878629088401794
Validation loss: 2.08308544754982

Epoch: 5| Step: 5
Training loss: 0.47258129715919495
Validation loss: 2.1672239700953164

Epoch: 5| Step: 6
Training loss: 0.7407220602035522
Validation loss: 2.132897218068441

Epoch: 5| Step: 7
Training loss: 0.674042284488678
Validation loss: 2.043400228023529

Epoch: 5| Step: 8
Training loss: 0.427243709564209
Validation loss: 2.1525033116340637

Epoch: 5| Step: 9
Training loss: 0.6678800582885742
Validation loss: 2.0643784403800964

Epoch: 5| Step: 10
Training loss: 0.32348522543907166
Validation loss: 2.1056551883618035

Epoch: 5| Step: 11
Training loss: 0.2847750186920166
Validation loss: 2.0750250816345215

Epoch: 247| Step: 0
Training loss: 0.38126182556152344
Validation loss: 2.0995701452096305

Epoch: 5| Step: 1
Training loss: 0.5207943916320801
Validation loss: 2.120222886403402

Epoch: 5| Step: 2
Training loss: 0.31748589873313904
Validation loss: 2.1471130500237146

Epoch: 5| Step: 3
Training loss: 0.469899982213974
Validation loss: 2.1021445641915

Epoch: 5| Step: 4
Training loss: 0.6260538697242737
Validation loss: 2.1376356333494186

Epoch: 5| Step: 5
Training loss: 0.3180873394012451
Validation loss: 2.1275356908639274

Epoch: 5| Step: 6
Training loss: 0.47211799025535583
Validation loss: 2.1271524280309677

Epoch: 5| Step: 7
Training loss: 0.44818004965782166
Validation loss: 2.192776764432589

Epoch: 5| Step: 8
Training loss: 0.5933052897453308
Validation loss: 2.1092811226844788

Epoch: 5| Step: 9
Training loss: 0.6317262649536133
Validation loss: 2.095711683233579

Epoch: 5| Step: 10
Training loss: 0.3329342007637024
Validation loss: 2.0884567697842917

Epoch: 5| Step: 11
Training loss: 0.6614973545074463
Validation loss: 2.1643449862798056

Epoch: 248| Step: 0
Training loss: 0.5563598871231079
Validation loss: 2.1136109431584678

Epoch: 5| Step: 1
Training loss: 0.6584370732307434
Validation loss: 2.049720674753189

Epoch: 5| Step: 2
Training loss: 0.5604581236839294
Validation loss: 2.069127927223841

Epoch: 5| Step: 3
Training loss: 0.6615212559700012
Validation loss: 2.087800736228625

Epoch: 5| Step: 4
Training loss: 0.7507981061935425
Validation loss: 2.1143666058778763

Epoch: 5| Step: 5
Training loss: 0.5233154892921448
Validation loss: 2.160712411006292

Epoch: 5| Step: 6
Training loss: 0.6675034165382385
Validation loss: 2.173320780197779

Epoch: 5| Step: 7
Training loss: 0.40251588821411133
Validation loss: 2.2097754975159964

Epoch: 5| Step: 8
Training loss: 0.4855741858482361
Validation loss: 2.1874599754810333

Epoch: 5| Step: 9
Training loss: 0.42314425110816956
Validation loss: 2.1531275560458503

Epoch: 5| Step: 10
Training loss: 0.4079208970069885
Validation loss: 2.1330944498380027

Epoch: 5| Step: 11
Training loss: 0.8797246813774109
Validation loss: 2.117138624191284

Epoch: 249| Step: 0
Training loss: 0.37697452306747437
Validation loss: 2.1210104723771415

Epoch: 5| Step: 1
Training loss: 0.5945335626602173
Validation loss: 2.051766743262609

Epoch: 5| Step: 2
Training loss: 0.573306679725647
Validation loss: 2.0563619981209436

Epoch: 5| Step: 3
Training loss: 0.2747670114040375
Validation loss: 2.0873487889766693

Epoch: 5| Step: 4
Training loss: 0.4768006205558777
Validation loss: 2.138713796933492

Epoch: 5| Step: 5
Training loss: 0.7450225353240967
Validation loss: 2.096385528643926

Epoch: 5| Step: 6
Training loss: 0.6568300127983093
Validation loss: 2.133792688449224

Epoch: 5| Step: 7
Training loss: 0.29437798261642456
Validation loss: 2.1108204821745553

Epoch: 5| Step: 8
Training loss: 0.4745710492134094
Validation loss: 2.128296360373497

Epoch: 5| Step: 9
Training loss: 0.4688572883605957
Validation loss: 2.1120704213778176

Epoch: 5| Step: 10
Training loss: 0.44443219900131226
Validation loss: 2.118702530860901

Epoch: 5| Step: 11
Training loss: 0.22736692428588867
Validation loss: 2.160111496845881

Epoch: 250| Step: 0
Training loss: 0.4123002886772156
Validation loss: 2.141615261634191

Epoch: 5| Step: 1
Training loss: 0.3229850232601166
Validation loss: 2.1402416775623956

Epoch: 5| Step: 2
Training loss: 0.4895435869693756
Validation loss: 2.108186811208725

Epoch: 5| Step: 3
Training loss: 0.49410781264305115
Validation loss: 2.1732959747314453

Epoch: 5| Step: 4
Training loss: 0.4925817549228668
Validation loss: 2.1738114058971405

Epoch: 5| Step: 5
Training loss: 0.8119514584541321
Validation loss: 2.1589992344379425

Epoch: 5| Step: 6
Training loss: 0.4948503077030182
Validation loss: 2.196617459257444

Epoch: 5| Step: 7
Training loss: 0.42120686173439026
Validation loss: 2.1657579441865287

Epoch: 5| Step: 8
Training loss: 0.7071558237075806
Validation loss: 2.0705771247545877

Epoch: 5| Step: 9
Training loss: 0.4561111032962799
Validation loss: 2.141756147146225

Epoch: 5| Step: 10
Training loss: 0.38267782330513
Validation loss: 2.104923501610756

Epoch: 5| Step: 11
Training loss: 0.41508227586746216
Validation loss: 2.098815525571505

Epoch: 251| Step: 0
Training loss: 0.6056987643241882
Validation loss: 2.1117297361294427

Epoch: 5| Step: 1
Training loss: 0.5101369023323059
Validation loss: 2.094134971499443

Epoch: 5| Step: 2
Training loss: 0.5004301071166992
Validation loss: 2.1225545605023703

Epoch: 5| Step: 3
Training loss: 0.46955519914627075
Validation loss: 2.1065346598625183

Epoch: 5| Step: 4
Training loss: 0.27145057916641235
Validation loss: 2.090385084350904

Epoch: 5| Step: 5
Training loss: 0.4651781916618347
Validation loss: 2.1278057446082435

Epoch: 5| Step: 6
Training loss: 0.7014158964157104
Validation loss: 2.1595425556103387

Epoch: 5| Step: 7
Training loss: 0.45283302664756775
Validation loss: 2.156653339664141

Epoch: 5| Step: 8
Training loss: 0.4738498330116272
Validation loss: 2.128394385178884

Epoch: 5| Step: 9
Training loss: 0.35302507877349854
Validation loss: 2.115919217467308

Epoch: 5| Step: 10
Training loss: 0.4542902112007141
Validation loss: 2.159197837114334

Epoch: 5| Step: 11
Training loss: 0.15417981147766113
Validation loss: 2.0902026345332465

Epoch: 252| Step: 0
Training loss: 0.46243366599082947
Validation loss: 2.143301044901212

Epoch: 5| Step: 1
Training loss: 0.4314437806606293
Validation loss: 2.1164957682291665

Epoch: 5| Step: 2
Training loss: 0.3989351689815521
Validation loss: 2.12616328895092

Epoch: 5| Step: 3
Training loss: 0.3653417229652405
Validation loss: 2.1052089482545853

Epoch: 5| Step: 4
Training loss: 0.45318517088890076
Validation loss: 2.0907954573631287

Epoch: 5| Step: 5
Training loss: 0.47089892625808716
Validation loss: 2.1659180422623954

Epoch: 5| Step: 6
Training loss: 0.7855815887451172
Validation loss: 2.1925305078426995

Epoch: 5| Step: 7
Training loss: 0.41070857644081116
Validation loss: 2.1571780939896903

Epoch: 5| Step: 8
Training loss: 0.29053598642349243
Validation loss: 2.20315291484197

Epoch: 5| Step: 9
Training loss: 0.624286413192749
Validation loss: 2.1186403383811316

Epoch: 5| Step: 10
Training loss: 0.3101426959037781
Validation loss: 2.1333483258883157

Epoch: 5| Step: 11
Training loss: 0.9204815030097961
Validation loss: 2.1479428509871163

Epoch: 253| Step: 0
Training loss: 0.2980428636074066
Validation loss: 2.085665633281072

Epoch: 5| Step: 1
Training loss: 0.5007128119468689
Validation loss: 2.097662071386973

Epoch: 5| Step: 2
Training loss: 0.5976064205169678
Validation loss: 2.0977435360352197

Epoch: 5| Step: 3
Training loss: 0.5443994998931885
Validation loss: 2.1432842016220093

Epoch: 5| Step: 4
Training loss: 0.5706493854522705
Validation loss: 2.153447146217028

Epoch: 5| Step: 5
Training loss: 0.601849377155304
Validation loss: 2.1615826984246573

Epoch: 5| Step: 6
Training loss: 0.5237823724746704
Validation loss: 2.099524110555649

Epoch: 5| Step: 7
Training loss: 0.6263949871063232
Validation loss: 2.1086137692133584

Epoch: 5| Step: 8
Training loss: 0.29572057723999023
Validation loss: 2.0887759029865265

Epoch: 5| Step: 9
Training loss: 0.4196808934211731
Validation loss: 2.119697079062462

Epoch: 5| Step: 10
Training loss: 0.488679975271225
Validation loss: 2.032653957605362

Epoch: 5| Step: 11
Training loss: 0.32498234510421753
Validation loss: 2.022187277674675

Epoch: 254| Step: 0
Training loss: 0.7005313038825989
Validation loss: 2.127486894528071

Epoch: 5| Step: 1
Training loss: 0.3738524317741394
Validation loss: 2.0843460907538733

Epoch: 5| Step: 2
Training loss: 0.4064858555793762
Validation loss: 2.1333092699448266

Epoch: 5| Step: 3
Training loss: 0.2954203486442566
Validation loss: 2.127016787727674

Epoch: 5| Step: 4
Training loss: 0.4342423379421234
Validation loss: 2.1361953218777976

Epoch: 5| Step: 5
Training loss: 0.5264609456062317
Validation loss: 2.115366667509079

Epoch: 5| Step: 6
Training loss: 0.3642893433570862
Validation loss: 2.0918273429075875

Epoch: 5| Step: 7
Training loss: 0.5203143358230591
Validation loss: 2.1174632410208383

Epoch: 5| Step: 8
Training loss: 0.43419259786605835
Validation loss: 2.1248665302991867

Epoch: 5| Step: 9
Training loss: 0.4864789843559265
Validation loss: 2.08881314098835

Epoch: 5| Step: 10
Training loss: 0.35098880529403687
Validation loss: 2.141552150249481

Epoch: 5| Step: 11
Training loss: 0.32539796829223633
Validation loss: 2.110335717598597

Epoch: 255| Step: 0
Training loss: 0.4068979322910309
Validation loss: 2.1672051499287286

Epoch: 5| Step: 1
Training loss: 0.5591354370117188
Validation loss: 2.1513928969701133

Epoch: 5| Step: 2
Training loss: 0.43292665481567383
Validation loss: 2.1081530849138894

Epoch: 5| Step: 3
Training loss: 0.375826895236969
Validation loss: 2.158115411798159

Epoch: 5| Step: 4
Training loss: 0.3922939896583557
Validation loss: 2.1496976912021637

Epoch: 5| Step: 5
Training loss: 0.37450262904167175
Validation loss: 2.104208623369535

Epoch: 5| Step: 6
Training loss: 0.3625432848930359
Validation loss: 2.0819428165753684

Epoch: 5| Step: 7
Training loss: 0.6787809133529663
Validation loss: 2.084182103474935

Epoch: 5| Step: 8
Training loss: 0.3381692171096802
Validation loss: 2.2107478380203247

Epoch: 5| Step: 9
Training loss: 0.7314141988754272
Validation loss: 2.1570741484562554

Epoch: 5| Step: 10
Training loss: 0.28007516264915466
Validation loss: 2.1568656812111535

Epoch: 5| Step: 11
Training loss: 0.4918643832206726
Validation loss: 2.1571867813666663

Epoch: 256| Step: 0
Training loss: 0.5228317975997925
Validation loss: 2.174363667766253

Epoch: 5| Step: 1
Training loss: 0.6593219637870789
Validation loss: 2.1079517354567847

Epoch: 5| Step: 2
Training loss: 0.3485109806060791
Validation loss: 2.0323379188776016

Epoch: 5| Step: 3
Training loss: 0.27572786808013916
Validation loss: 2.131340498725573

Epoch: 5| Step: 4
Training loss: 0.5267337560653687
Validation loss: 2.1081029077370963

Epoch: 5| Step: 5
Training loss: 0.5625689625740051
Validation loss: 2.1258798390626907

Epoch: 5| Step: 6
Training loss: 0.2722538709640503
Validation loss: 2.1464083045721054

Epoch: 5| Step: 7
Training loss: 0.45557206869125366
Validation loss: 2.1762585043907166

Epoch: 5| Step: 8
Training loss: 0.2421492040157318
Validation loss: 2.1232082645098367

Epoch: 5| Step: 9
Training loss: 0.4683547019958496
Validation loss: 2.1694470047950745

Epoch: 5| Step: 10
Training loss: 0.5233908891677856
Validation loss: 2.141421233614286

Epoch: 5| Step: 11
Training loss: 1.5875722169876099
Validation loss: 2.116787374019623

Epoch: 257| Step: 0
Training loss: 0.389823853969574
Validation loss: 2.0740865617990494

Epoch: 5| Step: 1
Training loss: 0.718512237071991
Validation loss: 2.0527525693178177

Epoch: 5| Step: 2
Training loss: 0.40940070152282715
Validation loss: 2.070826902985573

Epoch: 5| Step: 3
Training loss: 0.39928799867630005
Validation loss: 2.1263582358757653

Epoch: 5| Step: 4
Training loss: 0.3618658483028412
Validation loss: 2.1344945480426154

Epoch: 5| Step: 5
Training loss: 0.3077097535133362
Validation loss: 2.140766719977061

Epoch: 5| Step: 6
Training loss: 0.3189225196838379
Validation loss: 2.1786941836277642

Epoch: 5| Step: 7
Training loss: 0.47658881545066833
Validation loss: 2.121865769227346

Epoch: 5| Step: 8
Training loss: 0.7406790852546692
Validation loss: 2.1268325994412103

Epoch: 5| Step: 9
Training loss: 0.303984671831131
Validation loss: 2.119224136074384

Epoch: 5| Step: 10
Training loss: 0.5511170029640198
Validation loss: 2.145803968111674

Epoch: 5| Step: 11
Training loss: 0.16153711080551147
Validation loss: 2.0932415823141732

Epoch: 258| Step: 0
Training loss: 0.30741462111473083
Validation loss: 2.1228544314702353

Epoch: 5| Step: 1
Training loss: 0.3108222484588623
Validation loss: 2.1354483316342034

Epoch: 5| Step: 2
Training loss: 0.6377800703048706
Validation loss: 2.1309232115745544

Epoch: 5| Step: 3
Training loss: 0.21900740265846252
Validation loss: 2.1361637910207114

Epoch: 5| Step: 4
Training loss: 0.26978397369384766
Validation loss: 2.141729066769282

Epoch: 5| Step: 5
Training loss: 0.4758940637111664
Validation loss: 2.08748988310496

Epoch: 5| Step: 6
Training loss: 0.4989088177680969
Validation loss: 2.081429193417231

Epoch: 5| Step: 7
Training loss: 0.6075894236564636
Validation loss: 2.1700568795204163

Epoch: 5| Step: 8
Training loss: 0.6501362919807434
Validation loss: 2.159936507542928

Epoch: 5| Step: 9
Training loss: 0.4117010533809662
Validation loss: 2.0713708251714706

Epoch: 5| Step: 10
Training loss: 0.5230662226676941
Validation loss: 2.1127587308486304

Epoch: 5| Step: 11
Training loss: 0.3613169193267822
Validation loss: 2.0704134106636047

Epoch: 259| Step: 0
Training loss: 0.5029715299606323
Validation loss: 2.1058512677749

Epoch: 5| Step: 1
Training loss: 0.30904293060302734
Validation loss: 2.058135767777761

Epoch: 5| Step: 2
Training loss: 0.6209045052528381
Validation loss: 2.08024355272452

Epoch: 5| Step: 3
Training loss: 0.35158389806747437
Validation loss: 2.1489640971024833

Epoch: 5| Step: 4
Training loss: 0.39041686058044434
Validation loss: 2.1059771329164505

Epoch: 5| Step: 5
Training loss: 0.3269864022731781
Validation loss: 2.116081972916921

Epoch: 5| Step: 6
Training loss: 0.2906847596168518
Validation loss: 2.1799168785413108

Epoch: 5| Step: 7
Training loss: 0.41618943214416504
Validation loss: 2.085958883166313

Epoch: 5| Step: 8
Training loss: 0.42954641580581665
Validation loss: 2.171453813711802

Epoch: 5| Step: 9
Training loss: 0.5360070466995239
Validation loss: 2.1380222539107003

Epoch: 5| Step: 10
Training loss: 0.9458128809928894
Validation loss: 2.113779127597809

Epoch: 5| Step: 11
Training loss: 0.43158870935440063
Validation loss: 2.04752653837204

Epoch: 260| Step: 0
Training loss: 0.6424281001091003
Validation loss: 2.0442958772182465

Epoch: 5| Step: 1
Training loss: 0.6566334962844849
Validation loss: 2.0224413325389228

Epoch: 5| Step: 2
Training loss: 0.55438232421875
Validation loss: 2.081906740864118

Epoch: 5| Step: 3
Training loss: 0.6091607213020325
Validation loss: 2.0859257529179254

Epoch: 5| Step: 4
Training loss: 0.3723965287208557
Validation loss: 2.1237815618515015

Epoch: 5| Step: 5
Training loss: 0.3090360760688782
Validation loss: 2.1663315445184708

Epoch: 5| Step: 6
Training loss: 0.55463707447052
Validation loss: 2.1389280954996743

Epoch: 5| Step: 7
Training loss: 0.28241291642189026
Validation loss: 2.1357767383257547

Epoch: 5| Step: 8
Training loss: 0.6823228597640991
Validation loss: 2.136118233203888

Epoch: 5| Step: 9
Training loss: 0.4334157109260559
Validation loss: 2.1387855311234794

Epoch: 5| Step: 10
Training loss: 0.375005841255188
Validation loss: 2.087333545088768

Epoch: 5| Step: 11
Training loss: 0.3124869465827942
Validation loss: 2.1066985527674356

Epoch: 261| Step: 0
Training loss: 0.39118754863739014
Validation loss: 2.1254130750894547

Epoch: 5| Step: 1
Training loss: 0.44316452741622925
Validation loss: 2.099211275577545

Epoch: 5| Step: 2
Training loss: 0.3531878590583801
Validation loss: 2.146008754769961

Epoch: 5| Step: 3
Training loss: 0.337060809135437
Validation loss: 2.1989763925472894

Epoch: 5| Step: 4
Training loss: 0.3007933497428894
Validation loss: 2.092102805773417

Epoch: 5| Step: 5
Training loss: 0.7713867425918579
Validation loss: 2.163278102874756

Epoch: 5| Step: 6
Training loss: 0.4961931109428406
Validation loss: 2.2128270268440247

Epoch: 5| Step: 7
Training loss: 0.28922197222709656
Validation loss: 2.176061342159907

Epoch: 5| Step: 8
Training loss: 0.9137207269668579
Validation loss: 2.208592956264814

Epoch: 5| Step: 9
Training loss: 0.26143789291381836
Validation loss: 2.1610858142375946

Epoch: 5| Step: 10
Training loss: 0.42474299669265747
Validation loss: 2.175074408451716

Epoch: 5| Step: 11
Training loss: 0.36431288719177246
Validation loss: 2.1998334477345147

Epoch: 262| Step: 0
Training loss: 0.3980349600315094
Validation loss: 2.182741160194079

Epoch: 5| Step: 1
Training loss: 0.5128989815711975
Validation loss: 2.1136670957008996

Epoch: 5| Step: 2
Training loss: 0.4144035279750824
Validation loss: 2.131600002447764

Epoch: 5| Step: 3
Training loss: 0.527215301990509
Validation loss: 2.1716035703818

Epoch: 5| Step: 4
Training loss: 0.45575374364852905
Validation loss: 2.159622440735499

Epoch: 5| Step: 5
Training loss: 0.4873911738395691
Validation loss: 2.1577440996964774

Epoch: 5| Step: 6
Training loss: 0.24077439308166504
Validation loss: 2.1786979039510093

Epoch: 5| Step: 7
Training loss: 0.28540655970573425
Validation loss: 2.1156120846668878

Epoch: 5| Step: 8
Training loss: 0.6392847299575806
Validation loss: 2.107160747051239

Epoch: 5| Step: 9
Training loss: 0.6267655491828918
Validation loss: 2.1074362794558206

Epoch: 5| Step: 10
Training loss: 0.6127220988273621
Validation loss: 2.1492728888988495

Epoch: 5| Step: 11
Training loss: 0.4249996244907379
Validation loss: 2.1740386188030243

Epoch: 263| Step: 0
Training loss: 0.2558891475200653
Validation loss: 2.183133825659752

Epoch: 5| Step: 1
Training loss: 0.556248664855957
Validation loss: 2.179575582345327

Epoch: 5| Step: 2
Training loss: 0.7316468358039856
Validation loss: 2.1602431486050286

Epoch: 5| Step: 3
Training loss: 0.3922782838344574
Validation loss: 2.185950900117556

Epoch: 5| Step: 4
Training loss: 0.4171670377254486
Validation loss: 2.208967864513397

Epoch: 5| Step: 5
Training loss: 0.443295419216156
Validation loss: 2.113476872444153

Epoch: 5| Step: 6
Training loss: 0.4540784955024719
Validation loss: 2.1622985899448395

Epoch: 5| Step: 7
Training loss: 0.6481047868728638
Validation loss: 2.195450405279795

Epoch: 5| Step: 8
Training loss: 0.3621930181980133
Validation loss: 2.1699915875991187

Epoch: 5| Step: 9
Training loss: 0.27706846594810486
Validation loss: 2.1716101119915643

Epoch: 5| Step: 10
Training loss: 0.42262396216392517
Validation loss: 2.1731949945290885

Epoch: 5| Step: 11
Training loss: 0.40268731117248535
Validation loss: 2.176058828830719

Epoch: 264| Step: 0
Training loss: 0.44918403029441833
Validation loss: 2.181436608235041

Epoch: 5| Step: 1
Training loss: 0.3672977685928345
Validation loss: 2.2043269872665405

Epoch: 5| Step: 2
Training loss: 0.4210161566734314
Validation loss: 2.2055832942326865

Epoch: 5| Step: 3
Training loss: 0.5297119617462158
Validation loss: 2.1776690930128098

Epoch: 5| Step: 4
Training loss: 0.2675803005695343
Validation loss: 2.1851314852635064

Epoch: 5| Step: 5
Training loss: 0.4517194330692291
Validation loss: 2.1529025932153067

Epoch: 5| Step: 6
Training loss: 0.39379850029945374
Validation loss: 2.1577757596969604

Epoch: 5| Step: 7
Training loss: 0.3101879060268402
Validation loss: 2.162098785241445

Epoch: 5| Step: 8
Training loss: 0.5287918448448181
Validation loss: 2.1036080718040466

Epoch: 5| Step: 9
Training loss: 0.4589892029762268
Validation loss: 2.1580156286557517

Epoch: 5| Step: 10
Training loss: 0.9298405647277832
Validation loss: 2.145207166671753

Epoch: 5| Step: 11
Training loss: 0.25843316316604614
Validation loss: 2.146277109781901

Epoch: 265| Step: 0
Training loss: 0.3428052067756653
Validation loss: 2.118618036309878

Epoch: 5| Step: 1
Training loss: 0.5228883028030396
Validation loss: 2.087029288212458

Epoch: 5| Step: 2
Training loss: 0.7238880395889282
Validation loss: 2.1145930687586465

Epoch: 5| Step: 3
Training loss: 0.31363582611083984
Validation loss: 2.101242184638977

Epoch: 5| Step: 4
Training loss: 0.352131187915802
Validation loss: 2.1181691785653434

Epoch: 5| Step: 5
Training loss: 0.3892729580402374
Validation loss: 2.0705848187208176

Epoch: 5| Step: 6
Training loss: 0.5711278915405273
Validation loss: 2.15688619017601

Epoch: 5| Step: 7
Training loss: 0.28777486085891724
Validation loss: 2.091965844233831

Epoch: 5| Step: 8
Training loss: 0.18672522902488708
Validation loss: 2.139856626590093

Epoch: 5| Step: 9
Training loss: 0.6450649499893188
Validation loss: 2.111647437016169

Epoch: 5| Step: 10
Training loss: 0.3738030195236206
Validation loss: 2.1143998404343924

Epoch: 5| Step: 11
Training loss: 0.15790246427059174
Validation loss: 2.111461112896601

Epoch: 266| Step: 0
Training loss: 0.41729670763015747
Validation loss: 2.148435185352961

Epoch: 5| Step: 1
Training loss: 0.3267981708049774
Validation loss: 2.168832540512085

Epoch: 5| Step: 2
Training loss: 0.3671112060546875
Validation loss: 2.129994347691536

Epoch: 5| Step: 3
Training loss: 0.33041635155677795
Validation loss: 2.0858895828326545

Epoch: 5| Step: 4
Training loss: 0.3820747435092926
Validation loss: 2.0616836150487265

Epoch: 5| Step: 5
Training loss: 0.31368565559387207
Validation loss: 2.050151656071345

Epoch: 5| Step: 6
Training loss: 0.5384038090705872
Validation loss: 2.13725416858991

Epoch: 5| Step: 7
Training loss: 0.9323716163635254
Validation loss: 2.123171200354894

Epoch: 5| Step: 8
Training loss: 0.2887168526649475
Validation loss: 2.1210652887821198

Epoch: 5| Step: 9
Training loss: 0.519616425037384
Validation loss: 2.134079565604528

Epoch: 5| Step: 10
Training loss: 0.36166149377822876
Validation loss: 2.153013954559962

Epoch: 5| Step: 11
Training loss: 0.7690904140472412
Validation loss: 2.164966697494189

Epoch: 267| Step: 0
Training loss: 0.3264400362968445
Validation loss: 2.1399651815493903

Epoch: 5| Step: 1
Training loss: 0.43105754256248474
Validation loss: 2.1865324477354684

Epoch: 5| Step: 2
Training loss: 0.4896792769432068
Validation loss: 2.172289475798607

Epoch: 5| Step: 3
Training loss: 0.5923437476158142
Validation loss: 2.123854542771975

Epoch: 5| Step: 4
Training loss: 0.3634979724884033
Validation loss: 2.1846403082211814

Epoch: 5| Step: 5
Training loss: 0.6872695088386536
Validation loss: 2.1134098768234253

Epoch: 5| Step: 6
Training loss: 0.3682180345058441
Validation loss: 2.1273544232050576

Epoch: 5| Step: 7
Training loss: 0.39961251616477966
Validation loss: 2.13762300213178

Epoch: 5| Step: 8
Training loss: 0.3740276098251343
Validation loss: 2.1275008072455726

Epoch: 5| Step: 9
Training loss: 0.4064050316810608
Validation loss: 2.122880056500435

Epoch: 5| Step: 10
Training loss: 0.228348970413208
Validation loss: 2.120919813712438

Epoch: 5| Step: 11
Training loss: 0.5436601638793945
Validation loss: 2.1473536839087806

Epoch: 268| Step: 0
Training loss: 0.46336644887924194
Validation loss: 2.1522875328858695

Epoch: 5| Step: 1
Training loss: 0.6437667608261108
Validation loss: 2.153133680423101

Epoch: 5| Step: 2
Training loss: 0.4969889521598816
Validation loss: 2.192406177520752

Epoch: 5| Step: 3
Training loss: 0.40992027521133423
Validation loss: 2.1389633864164352

Epoch: 5| Step: 4
Training loss: 0.4298178553581238
Validation loss: 2.1297825078169503

Epoch: 5| Step: 5
Training loss: 0.4063492715358734
Validation loss: 2.134113689263662

Epoch: 5| Step: 6
Training loss: 0.5672582387924194
Validation loss: 2.0954082210858664

Epoch: 5| Step: 7
Training loss: 0.2813350558280945
Validation loss: 2.075521652897199

Epoch: 5| Step: 8
Training loss: 0.35253024101257324
Validation loss: 2.0887271563212075

Epoch: 5| Step: 9
Training loss: 0.34440499544143677
Validation loss: 2.1089873760938644

Epoch: 5| Step: 10
Training loss: 0.36488017439842224
Validation loss: 2.073762242992719

Epoch: 5| Step: 11
Training loss: 1.0247904062271118
Validation loss: 2.136920750141144

Epoch: 269| Step: 0
Training loss: 0.45937561988830566
Validation loss: 2.1690307358900704

Epoch: 5| Step: 1
Training loss: 0.4724629521369934
Validation loss: 2.2240167955557504

Epoch: 5| Step: 2
Training loss: 0.3755345940589905
Validation loss: 2.189459944764773

Epoch: 5| Step: 3
Training loss: 0.2910396158695221
Validation loss: 2.1313191950321198

Epoch: 5| Step: 4
Training loss: 0.29591548442840576
Validation loss: 2.155131548643112

Epoch: 5| Step: 5
Training loss: 0.3044751286506653
Validation loss: 2.116856654485067

Epoch: 5| Step: 6
Training loss: 0.41088932752609253
Validation loss: 2.1164913177490234

Epoch: 5| Step: 7
Training loss: 0.7501195073127747
Validation loss: 2.1095656702915826

Epoch: 5| Step: 8
Training loss: 0.44966602325439453
Validation loss: 2.1273570209741592

Epoch: 5| Step: 9
Training loss: 0.709153413772583
Validation loss: 2.104180097579956

Epoch: 5| Step: 10
Training loss: 0.6446880102157593
Validation loss: 2.1197037945191064

Epoch: 5| Step: 11
Training loss: 0.26626431941986084
Validation loss: 2.1673724154631295

Epoch: 270| Step: 0
Training loss: 0.24719607830047607
Validation loss: 2.1673408299684525

Epoch: 5| Step: 1
Training loss: 0.5811967849731445
Validation loss: 2.221349467833837

Epoch: 5| Step: 2
Training loss: 0.4681147634983063
Validation loss: 2.2389954030513763

Epoch: 5| Step: 3
Training loss: 1.0217607021331787
Validation loss: 2.234523117542267

Epoch: 5| Step: 4
Training loss: 0.5879560708999634
Validation loss: 2.242486303051313

Epoch: 5| Step: 5
Training loss: 0.27560147643089294
Validation loss: 2.1665922105312347

Epoch: 5| Step: 6
Training loss: 0.3322084844112396
Validation loss: 2.0964058935642242

Epoch: 5| Step: 7
Training loss: 0.4629317820072174
Validation loss: 2.0837761610746384

Epoch: 5| Step: 8
Training loss: 0.3885519802570343
Validation loss: 2.1107982099056244

Epoch: 5| Step: 9
Training loss: 0.5645511746406555
Validation loss: 2.071813772122065

Epoch: 5| Step: 10
Training loss: 0.38518157601356506
Validation loss: 2.102800632516543

Epoch: 5| Step: 11
Training loss: 1.270381212234497
Validation loss: 2.1404264519611993

Epoch: 271| Step: 0
Training loss: 0.48353052139282227
Validation loss: 2.121200382709503

Epoch: 5| Step: 1
Training loss: 0.42017799615859985
Validation loss: 2.168511445323626

Epoch: 5| Step: 2
Training loss: 0.380718469619751
Validation loss: 2.176156222820282

Epoch: 5| Step: 3
Training loss: 0.49603143334388733
Validation loss: 2.2011067072550454

Epoch: 5| Step: 4
Training loss: 0.42951393127441406
Validation loss: 2.2253060191869736

Epoch: 5| Step: 5
Training loss: 0.4539925158023834
Validation loss: 2.181415711839994

Epoch: 5| Step: 6
Training loss: 0.4412148594856262
Validation loss: 2.1788859566052756

Epoch: 5| Step: 7
Training loss: 0.3009570240974426
Validation loss: 2.1593822737534842

Epoch: 5| Step: 8
Training loss: 0.8321064710617065
Validation loss: 2.1717329621315002

Epoch: 5| Step: 9
Training loss: 0.5558616518974304
Validation loss: 2.155613640944163

Epoch: 5| Step: 10
Training loss: 0.42115917801856995
Validation loss: 2.1038621217012405

Epoch: 5| Step: 11
Training loss: 0.3368189334869385
Validation loss: 2.1193198412656784

Epoch: 272| Step: 0
Training loss: 0.5443569421768188
Validation loss: 2.0815921326478324

Epoch: 5| Step: 1
Training loss: 0.6385650634765625
Validation loss: 2.092877378066381

Epoch: 5| Step: 2
Training loss: 0.782239556312561
Validation loss: 2.1788194676240287

Epoch: 5| Step: 3
Training loss: 0.44859933853149414
Validation loss: 2.18875482181708

Epoch: 5| Step: 4
Training loss: 0.6315685510635376
Validation loss: 2.183490683635076

Epoch: 5| Step: 5
Training loss: 0.2910139858722687
Validation loss: 2.209861288468043

Epoch: 5| Step: 6
Training loss: 0.4600868225097656
Validation loss: 2.1520462234814963

Epoch: 5| Step: 7
Training loss: 0.44103437662124634
Validation loss: 2.1153683016697564

Epoch: 5| Step: 8
Training loss: 0.3310673236846924
Validation loss: 2.1108583211898804

Epoch: 5| Step: 9
Training loss: 0.35390332341194153
Validation loss: 2.11856617530187

Epoch: 5| Step: 10
Training loss: 0.28988319635391235
Validation loss: 2.1071783055861792

Epoch: 5| Step: 11
Training loss: 0.25128173828125
Validation loss: 2.1478523860375085

Epoch: 273| Step: 0
Training loss: 0.44663891196250916
Validation loss: 2.1057230482498803

Epoch: 5| Step: 1
Training loss: 0.495011568069458
Validation loss: 2.075518250465393

Epoch: 5| Step: 2
Training loss: 0.48783206939697266
Validation loss: 2.09097188214461

Epoch: 5| Step: 3
Training loss: 0.7300694584846497
Validation loss: 2.060277317961057

Epoch: 5| Step: 4
Training loss: 0.3550751805305481
Validation loss: 2.1143485009670258

Epoch: 5| Step: 5
Training loss: 0.3393287658691406
Validation loss: 2.1078457136948905

Epoch: 5| Step: 6
Training loss: 0.4848688244819641
Validation loss: 2.183215926090876

Epoch: 5| Step: 7
Training loss: 0.5646552443504333
Validation loss: 2.1426885028680167

Epoch: 5| Step: 8
Training loss: 0.43105608224868774
Validation loss: 2.2197852383057275

Epoch: 5| Step: 9
Training loss: 0.3110676109790802
Validation loss: 2.1543898036082587

Epoch: 5| Step: 10
Training loss: 0.4096148908138275
Validation loss: 2.134607563416163

Epoch: 5| Step: 11
Training loss: 0.6822774410247803
Validation loss: 2.1892234881718955

Epoch: 274| Step: 0
Training loss: 0.30696672201156616
Validation loss: 2.1737564355134964

Epoch: 5| Step: 1
Training loss: 0.4902040362358093
Validation loss: 2.1217996130386987

Epoch: 5| Step: 2
Training loss: 0.5495084524154663
Validation loss: 2.1714562276999154

Epoch: 5| Step: 3
Training loss: 0.32407528162002563
Validation loss: 2.1599778632322946

Epoch: 5| Step: 4
Training loss: 0.7185787558555603
Validation loss: 2.1789883176485696

Epoch: 5| Step: 5
Training loss: 0.7619457840919495
Validation loss: 2.211005906263987

Epoch: 5| Step: 6
Training loss: 0.2959287762641907
Validation loss: 2.2168539514144263

Epoch: 5| Step: 7
Training loss: 0.4515058100223541
Validation loss: 2.141416162252426

Epoch: 5| Step: 8
Training loss: 0.5144423246383667
Validation loss: 2.1985777616500854

Epoch: 5| Step: 9
Training loss: 0.3974100649356842
Validation loss: 2.1772375951210656

Epoch: 5| Step: 10
Training loss: 0.3563419580459595
Validation loss: 2.1443645308415094

Epoch: 5| Step: 11
Training loss: 0.4277939796447754
Validation loss: 2.181718409061432

Epoch: 275| Step: 0
Training loss: 0.3836222290992737
Validation loss: 2.156231075525284

Epoch: 5| Step: 1
Training loss: 0.4377458989620209
Validation loss: 2.166500687599182

Epoch: 5| Step: 2
Training loss: 0.4666828513145447
Validation loss: 2.063808331886927

Epoch: 5| Step: 3
Training loss: 0.3614712059497833
Validation loss: 2.202705209453901

Epoch: 5| Step: 4
Training loss: 0.44605159759521484
Validation loss: 2.1591727634270987

Epoch: 5| Step: 5
Training loss: 0.49571600556373596
Validation loss: 2.201346983512243

Epoch: 5| Step: 6
Training loss: 0.6356136202812195
Validation loss: 2.186472167571386

Epoch: 5| Step: 7
Training loss: 0.4873267114162445
Validation loss: 2.1668440997600555

Epoch: 5| Step: 8
Training loss: 0.5557268857955933
Validation loss: 2.207914466659228

Epoch: 5| Step: 9
Training loss: 0.46276623010635376
Validation loss: 2.156294817725817

Epoch: 5| Step: 10
Training loss: 0.3458530008792877
Validation loss: 2.161031315724055

Epoch: 5| Step: 11
Training loss: 0.24453401565551758
Validation loss: 2.1282486468553543

Epoch: 276| Step: 0
Training loss: 0.5475656986236572
Validation loss: 2.1262141466140747

Epoch: 5| Step: 1
Training loss: 0.43871182203292847
Validation loss: 2.152040809392929

Epoch: 5| Step: 2
Training loss: 0.8877460360527039
Validation loss: 2.1258040318886438

Epoch: 5| Step: 3
Training loss: 0.5450454950332642
Validation loss: 2.136198123296102

Epoch: 5| Step: 4
Training loss: 0.574063777923584
Validation loss: 2.144409825404485

Epoch: 5| Step: 5
Training loss: 0.528979480266571
Validation loss: 2.1336654126644135

Epoch: 5| Step: 6
Training loss: 0.3618403375148773
Validation loss: 2.1567326386769614

Epoch: 5| Step: 7
Training loss: 0.343437135219574
Validation loss: 2.221708118915558

Epoch: 5| Step: 8
Training loss: 0.3692316710948944
Validation loss: 2.223984291156133

Epoch: 5| Step: 9
Training loss: 0.2556435763835907
Validation loss: 2.1535326341787973

Epoch: 5| Step: 10
Training loss: 0.46870049834251404
Validation loss: 2.1593899627526603

Epoch: 5| Step: 11
Training loss: 0.3551282286643982
Validation loss: 2.148066704471906

Epoch: 277| Step: 0
Training loss: 0.42381611466407776
Validation loss: 2.1141338795423508

Epoch: 5| Step: 1
Training loss: 0.3776255249977112
Validation loss: 2.0869521449009576

Epoch: 5| Step: 2
Training loss: 0.5591334104537964
Validation loss: 2.0769531428813934

Epoch: 5| Step: 3
Training loss: 0.5399062037467957
Validation loss: 2.119141529003779

Epoch: 5| Step: 4
Training loss: 0.3254871964454651
Validation loss: 2.0938011407852173

Epoch: 5| Step: 5
Training loss: 0.36022937297821045
Validation loss: 2.1232040971517563

Epoch: 5| Step: 6
Training loss: 0.7363341450691223
Validation loss: 2.1776922146479287

Epoch: 5| Step: 7
Training loss: 0.8122873306274414
Validation loss: 2.179880847533544

Epoch: 5| Step: 8
Training loss: 0.5009283423423767
Validation loss: 2.1742825408776603

Epoch: 5| Step: 9
Training loss: 0.6705327033996582
Validation loss: 2.1530952701965966

Epoch: 5| Step: 10
Training loss: 0.1679903119802475
Validation loss: 2.18877907594045

Epoch: 5| Step: 11
Training loss: 0.17212867736816406
Validation loss: 2.177975684404373

Epoch: 278| Step: 0
Training loss: 0.39561375975608826
Validation loss: 2.1481438825527825

Epoch: 5| Step: 1
Training loss: 0.30806559324264526
Validation loss: 2.081767832239469

Epoch: 5| Step: 2
Training loss: 0.4380267262458801
Validation loss: 2.1130936394135156

Epoch: 5| Step: 3
Training loss: 0.42332035303115845
Validation loss: 2.064765820900599

Epoch: 5| Step: 4
Training loss: 0.4028233587741852
Validation loss: 2.1042182793219886

Epoch: 5| Step: 5
Training loss: 0.31298279762268066
Validation loss: 2.154970491925875

Epoch: 5| Step: 6
Training loss: 0.3118572235107422
Validation loss: 2.137954850991567

Epoch: 5| Step: 7
Training loss: 0.4176509380340576
Validation loss: 2.17498787244161

Epoch: 5| Step: 8
Training loss: 0.8545911908149719
Validation loss: 2.150895764430364

Epoch: 5| Step: 9
Training loss: 0.46950215101242065
Validation loss: 2.1729446798563004

Epoch: 5| Step: 10
Training loss: 0.3646194338798523
Validation loss: 2.087395340204239

Epoch: 5| Step: 11
Training loss: 1.2098699808120728
Validation loss: 2.1504612118005753

Epoch: 279| Step: 0
Training loss: 0.3333441913127899
Validation loss: 2.1799290776252747

Epoch: 5| Step: 1
Training loss: 0.4435901641845703
Validation loss: 2.2505374451478324

Epoch: 5| Step: 2
Training loss: 0.4725465774536133
Validation loss: 2.218972538908323

Epoch: 5| Step: 3
Training loss: 0.3951907157897949
Validation loss: 2.176801472902298

Epoch: 5| Step: 4
Training loss: 0.8339107632637024
Validation loss: 2.156053597728411

Epoch: 5| Step: 5
Training loss: 0.40372100472450256
Validation loss: 2.102965166171392

Epoch: 5| Step: 6
Training loss: 0.5314751863479614
Validation loss: 2.1467613031466803

Epoch: 5| Step: 7
Training loss: 0.37487077713012695
Validation loss: 2.1025606989860535

Epoch: 5| Step: 8
Training loss: 0.48136574029922485
Validation loss: 2.088898445169131

Epoch: 5| Step: 9
Training loss: 0.3537483513355255
Validation loss: 2.1221324553092322

Epoch: 5| Step: 10
Training loss: 0.42284315824508667
Validation loss: 2.1310686270395913

Epoch: 5| Step: 11
Training loss: 0.31533709168434143
Validation loss: 2.165564755598704

Epoch: 280| Step: 0
Training loss: 0.36969393491744995
Validation loss: 2.1611403226852417

Epoch: 5| Step: 1
Training loss: 0.48440393805503845
Validation loss: 2.1307594726483026

Epoch: 5| Step: 2
Training loss: 0.569484293460846
Validation loss: 2.176109731197357

Epoch: 5| Step: 3
Training loss: 0.7874168753623962
Validation loss: 2.165480613708496

Epoch: 5| Step: 4
Training loss: 0.31369510293006897
Validation loss: 2.1110071192185083

Epoch: 5| Step: 5
Training loss: 0.40501707792282104
Validation loss: 2.095520943403244

Epoch: 5| Step: 6
Training loss: 0.3867667317390442
Validation loss: 2.0492334365844727

Epoch: 5| Step: 7
Training loss: 0.45720893144607544
Validation loss: 2.0674770126740136

Epoch: 5| Step: 8
Training loss: 0.5397294163703918
Validation loss: 2.1309412072102227

Epoch: 5| Step: 9
Training loss: 0.30952149629592896
Validation loss: 2.1203725089629493

Epoch: 5| Step: 10
Training loss: 0.3146781921386719
Validation loss: 2.114967996875445

Epoch: 5| Step: 11
Training loss: 0.20065081119537354
Validation loss: 2.102279081940651

Epoch: 281| Step: 0
Training loss: 0.6273384690284729
Validation loss: 2.1572256684303284

Epoch: 5| Step: 1
Training loss: 0.2813132405281067
Validation loss: 2.1322413931290307

Epoch: 5| Step: 2
Training loss: 0.518170177936554
Validation loss: 2.176466370622317

Epoch: 5| Step: 3
Training loss: 0.39718690514564514
Validation loss: 2.194001962741216

Epoch: 5| Step: 4
Training loss: 0.4346259534358978
Validation loss: 2.2159714798132577

Epoch: 5| Step: 5
Training loss: 0.35357198119163513
Validation loss: 2.1939614762862525

Epoch: 5| Step: 6
Training loss: 0.3731982707977295
Validation loss: 2.2069327433904014

Epoch: 5| Step: 7
Training loss: 0.5589149594306946
Validation loss: 2.171867067615191

Epoch: 5| Step: 8
Training loss: 0.37676873803138733
Validation loss: 2.158289462327957

Epoch: 5| Step: 9
Training loss: 0.5312842130661011
Validation loss: 2.168692241112391

Epoch: 5| Step: 10
Training loss: 0.3504509925842285
Validation loss: 2.169890820980072

Epoch: 5| Step: 11
Training loss: 0.2096487581729889
Validation loss: 2.1909672915935516

Epoch: 282| Step: 0
Training loss: 0.3614140748977661
Validation loss: 2.2183715105056763

Epoch: 5| Step: 1
Training loss: 0.3314267694950104
Validation loss: 2.1987774471441903

Epoch: 5| Step: 2
Training loss: 0.4851300120353699
Validation loss: 2.2539188464482627

Epoch: 5| Step: 3
Training loss: 0.6310678720474243
Validation loss: 2.295646831393242

Epoch: 5| Step: 4
Training loss: 0.6102526187896729
Validation loss: 2.2658841013908386

Epoch: 5| Step: 5
Training loss: 0.4142456650733948
Validation loss: 2.2545879582564035

Epoch: 5| Step: 6
Training loss: 0.2924443483352661
Validation loss: 2.23221392929554

Epoch: 5| Step: 7
Training loss: 0.26217493414878845
Validation loss: 2.1708200573921204

Epoch: 5| Step: 8
Training loss: 0.3425702154636383
Validation loss: 2.2033201108376184

Epoch: 5| Step: 9
Training loss: 1.0349775552749634
Validation loss: 2.183978632092476

Epoch: 5| Step: 10
Training loss: 0.49778977036476135
Validation loss: 2.1369721392790475

Epoch: 5| Step: 11
Training loss: 0.44385969638824463
Validation loss: 2.1957183430592218

Epoch: 283| Step: 0
Training loss: 0.26367977261543274
Validation loss: 2.1849578072627387

Epoch: 5| Step: 1
Training loss: 0.9357845187187195
Validation loss: 2.1946398317813873

Epoch: 5| Step: 2
Training loss: 0.6451011896133423
Validation loss: 2.2001989781856537

Epoch: 5| Step: 3
Training loss: 0.28260791301727295
Validation loss: 2.1229148358106613

Epoch: 5| Step: 4
Training loss: 0.4517795145511627
Validation loss: 2.183883855740229

Epoch: 5| Step: 5
Training loss: 0.57317054271698
Validation loss: 2.1822311729192734

Epoch: 5| Step: 6
Training loss: 0.21909156441688538
Validation loss: 2.185099631547928

Epoch: 5| Step: 7
Training loss: 0.3571105897426605
Validation loss: 2.1644285122553506

Epoch: 5| Step: 8
Training loss: 0.3455181121826172
Validation loss: 2.1566053877274194

Epoch: 5| Step: 9
Training loss: 0.3612675368785858
Validation loss: 2.1341284910837808

Epoch: 5| Step: 10
Training loss: 0.37029534578323364
Validation loss: 2.1692795803149543

Epoch: 5| Step: 11
Training loss: 0.13026833534240723
Validation loss: 2.1707244515419006

Epoch: 284| Step: 0
Training loss: 0.37700819969177246
Validation loss: 2.1568412284056344

Epoch: 5| Step: 1
Training loss: 0.43141913414001465
Validation loss: 2.079069380958875

Epoch: 5| Step: 2
Training loss: 0.3929516673088074
Validation loss: 2.0864331275224686

Epoch: 5| Step: 3
Training loss: 0.3403533101081848
Validation loss: 2.142778734366099

Epoch: 5| Step: 4
Training loss: 0.5052942037582397
Validation loss: 2.1188117464383445

Epoch: 5| Step: 5
Training loss: 0.24630041420459747
Validation loss: 2.1732704490423203

Epoch: 5| Step: 6
Training loss: 0.27371206879615784
Validation loss: 2.1797624429066977

Epoch: 5| Step: 7
Training loss: 0.3819490969181061
Validation loss: 2.1749750624100366

Epoch: 5| Step: 8
Training loss: 0.3945176601409912
Validation loss: 2.185578480362892

Epoch: 5| Step: 9
Training loss: 0.3443264663219452
Validation loss: 2.1418382028738656

Epoch: 5| Step: 10
Training loss: 0.6658554673194885
Validation loss: 2.2212406744559607

Epoch: 5| Step: 11
Training loss: 0.36923936009407043
Validation loss: 2.1619111051162085

Epoch: 285| Step: 0
Training loss: 0.5127661824226379
Validation loss: 2.1596625049908957

Epoch: 5| Step: 1
Training loss: 0.6275185942649841
Validation loss: 2.2110738257567086

Epoch: 5| Step: 2
Training loss: 0.29716360569000244
Validation loss: 2.180166612068812

Epoch: 5| Step: 3
Training loss: 0.3167956471443176
Validation loss: 2.2064096530278525

Epoch: 5| Step: 4
Training loss: 0.6093458533287048
Validation loss: 2.2250353197256723

Epoch: 5| Step: 5
Training loss: 0.2540125250816345
Validation loss: 2.137744680047035

Epoch: 5| Step: 6
Training loss: 0.2791844308376312
Validation loss: 2.153272494673729

Epoch: 5| Step: 7
Training loss: 0.42972707748413086
Validation loss: 2.1939386427402496

Epoch: 5| Step: 8
Training loss: 0.2740693986415863
Validation loss: 2.12348643441995

Epoch: 5| Step: 9
Training loss: 0.41142693161964417
Validation loss: 2.1910240401824317

Epoch: 5| Step: 10
Training loss: 0.3075365424156189
Validation loss: 2.149417613943418

Epoch: 5| Step: 11
Training loss: 0.10398924350738525
Validation loss: 2.1390136828025184

Epoch: 286| Step: 0
Training loss: 0.43160057067871094
Validation loss: 2.149332414070765

Epoch: 5| Step: 1
Training loss: 0.4531998634338379
Validation loss: 2.066943178574244

Epoch: 5| Step: 2
Training loss: 0.5009026527404785
Validation loss: 2.1124979158242545

Epoch: 5| Step: 3
Training loss: 0.2880406975746155
Validation loss: 2.089729905128479

Epoch: 5| Step: 4
Training loss: 0.25104016065597534
Validation loss: 2.1158213963111243

Epoch: 5| Step: 5
Training loss: 0.24732664227485657
Validation loss: 2.126524642109871

Epoch: 5| Step: 6
Training loss: 0.31358271837234497
Validation loss: 2.157575339078903

Epoch: 5| Step: 7
Training loss: 0.27012041211128235
Validation loss: 2.1665620704491935

Epoch: 5| Step: 8
Training loss: 0.765360951423645
Validation loss: 2.1478477269411087

Epoch: 5| Step: 9
Training loss: 0.4413211941719055
Validation loss: 2.1338449021180472

Epoch: 5| Step: 10
Training loss: 0.460590124130249
Validation loss: 2.132896582285563

Epoch: 5| Step: 11
Training loss: 0.6770305633544922
Validation loss: 2.1396873543659845

Epoch: 287| Step: 0
Training loss: 0.5301816463470459
Validation loss: 2.1722509215275445

Epoch: 5| Step: 1
Training loss: 0.407775342464447
Validation loss: 2.1604488094647727

Epoch: 5| Step: 2
Training loss: 0.2602714002132416
Validation loss: 2.1894125839074454

Epoch: 5| Step: 3
Training loss: 0.7362115979194641
Validation loss: 2.140301138162613

Epoch: 5| Step: 4
Training loss: 0.38968271017074585
Validation loss: 2.136789634823799

Epoch: 5| Step: 5
Training loss: 0.20329265296459198
Validation loss: 2.1761940071980157

Epoch: 5| Step: 6
Training loss: 0.27323389053344727
Validation loss: 2.1557050247987113

Epoch: 5| Step: 7
Training loss: 0.35918372869491577
Validation loss: 2.135865867137909

Epoch: 5| Step: 8
Training loss: 0.4070459306240082
Validation loss: 2.1349966625372567

Epoch: 5| Step: 9
Training loss: 0.2619621455669403
Validation loss: 2.1735231826702752

Epoch: 5| Step: 10
Training loss: 0.3991500437259674
Validation loss: 2.1304188817739487

Epoch: 5| Step: 11
Training loss: 0.5996847748756409
Validation loss: 2.183191786209742

Epoch: 288| Step: 0
Training loss: 0.4988119602203369
Validation loss: 2.1540884971618652

Epoch: 5| Step: 1
Training loss: 0.5664477348327637
Validation loss: 2.1831271052360535

Epoch: 5| Step: 2
Training loss: 0.544662356376648
Validation loss: 2.150241643190384

Epoch: 5| Step: 3
Training loss: 0.34711748361587524
Validation loss: 2.2226436883211136

Epoch: 5| Step: 4
Training loss: 0.423327773809433
Validation loss: 2.213515525062879

Epoch: 5| Step: 5
Training loss: 0.31902843713760376
Validation loss: 2.1680576155583062

Epoch: 5| Step: 6
Training loss: 0.7958961725234985
Validation loss: 2.179905821879705

Epoch: 5| Step: 7
Training loss: 0.3378685414791107
Validation loss: 2.150374099612236

Epoch: 5| Step: 8
Training loss: 0.3076784014701843
Validation loss: 2.1673382222652435

Epoch: 5| Step: 9
Training loss: 0.3436663746833801
Validation loss: 2.1644306679566703

Epoch: 5| Step: 10
Training loss: 0.2839253544807434
Validation loss: 2.234046677748362

Epoch: 5| Step: 11
Training loss: 0.24637186527252197
Validation loss: 2.167708953221639

Epoch: 289| Step: 0
Training loss: 0.2645765244960785
Validation loss: 2.1794138650099435

Epoch: 5| Step: 1
Training loss: 0.4496578276157379
Validation loss: 2.2300884276628494

Epoch: 5| Step: 2
Training loss: 0.43549519777297974
Validation loss: 2.2302899261315665

Epoch: 5| Step: 3
Training loss: 0.40565308928489685
Validation loss: 2.1744574159383774

Epoch: 5| Step: 4
Training loss: 0.29848894476890564
Validation loss: 2.2560208439826965

Epoch: 5| Step: 5
Training loss: 0.6216379404067993
Validation loss: 2.219192902247111

Epoch: 5| Step: 6
Training loss: 0.3317566514015198
Validation loss: 2.2278129359086356

Epoch: 5| Step: 7
Training loss: 0.8443931341171265
Validation loss: 2.164836565653483

Epoch: 5| Step: 8
Training loss: 0.24686694145202637
Validation loss: 2.1795710921287537

Epoch: 5| Step: 9
Training loss: 0.3270460069179535
Validation loss: 2.1593249489863715

Epoch: 5| Step: 10
Training loss: 0.3480812907218933
Validation loss: 2.109009032448133

Epoch: 5| Step: 11
Training loss: 0.3758736252784729
Validation loss: 2.1206286599238715

Epoch: 290| Step: 0
Training loss: 0.5465452075004578
Validation loss: 2.1250493278106055

Epoch: 5| Step: 1
Training loss: 0.24268785119056702
Validation loss: 2.137155165274938

Epoch: 5| Step: 2
Training loss: 0.34882110357284546
Validation loss: 2.1599481999874115

Epoch: 5| Step: 3
Training loss: 0.27001795172691345
Validation loss: 2.1703570733467736

Epoch: 5| Step: 4
Training loss: 0.6208829879760742
Validation loss: 2.192425717910131

Epoch: 5| Step: 5
Training loss: 0.3697642683982849
Validation loss: 2.143922065695127

Epoch: 5| Step: 6
Training loss: 0.35364025831222534
Validation loss: 2.1867664655049643

Epoch: 5| Step: 7
Training loss: 0.3997488021850586
Validation loss: 2.156681085626284

Epoch: 5| Step: 8
Training loss: 0.2847154140472412
Validation loss: 2.1619051098823547

Epoch: 5| Step: 9
Training loss: 0.44787874817848206
Validation loss: 2.16921458641688

Epoch: 5| Step: 10
Training loss: 0.36413392424583435
Validation loss: 2.103842263420423

Epoch: 5| Step: 11
Training loss: 0.5083815455436707
Validation loss: 2.1637308299541473

Epoch: 291| Step: 0
Training loss: 0.30493974685668945
Validation loss: 2.1292001952727637

Epoch: 5| Step: 1
Training loss: 0.2295418232679367
Validation loss: 2.1292496720949807

Epoch: 5| Step: 2
Training loss: 0.29291069507598877
Validation loss: 2.1707739929358163

Epoch: 5| Step: 3
Training loss: 0.4020845293998718
Validation loss: 2.1120255142450333

Epoch: 5| Step: 4
Training loss: 0.6287513971328735
Validation loss: 2.152661547064781

Epoch: 5| Step: 5
Training loss: 0.49928778409957886
Validation loss: 2.1339786648750305

Epoch: 5| Step: 6
Training loss: 0.5278967022895813
Validation loss: 2.119661663969358

Epoch: 5| Step: 7
Training loss: 0.2870098650455475
Validation loss: 2.156084363659223

Epoch: 5| Step: 8
Training loss: 0.27526140213012695
Validation loss: 2.1315031001965203

Epoch: 5| Step: 9
Training loss: 0.4164707660675049
Validation loss: 2.1490292151769004

Epoch: 5| Step: 10
Training loss: 0.40073245763778687
Validation loss: 2.185931662718455

Epoch: 5| Step: 11
Training loss: 0.17583799362182617
Validation loss: 2.1868019849061966

Epoch: 292| Step: 0
Training loss: 0.38859280943870544
Validation loss: 2.205354407429695

Epoch: 5| Step: 1
Training loss: 0.7554254531860352
Validation loss: 2.17842144270738

Epoch: 5| Step: 2
Training loss: 0.34337663650512695
Validation loss: 2.1520110368728638

Epoch: 5| Step: 3
Training loss: 0.30512529611587524
Validation loss: 2.137879411379496

Epoch: 5| Step: 4
Training loss: 0.37520143389701843
Validation loss: 2.188171366850535

Epoch: 5| Step: 5
Training loss: 0.2393207997083664
Validation loss: 2.167078067859014

Epoch: 5| Step: 6
Training loss: 0.4409116804599762
Validation loss: 2.176069512963295

Epoch: 5| Step: 7
Training loss: 0.2536798119544983
Validation loss: 2.134084721406301

Epoch: 5| Step: 8
Training loss: 0.4680899679660797
Validation loss: 2.1595508505900702

Epoch: 5| Step: 9
Training loss: 0.3024972379207611
Validation loss: 2.1283874760071435

Epoch: 5| Step: 10
Training loss: 0.5469219088554382
Validation loss: 2.1823335190614066

Epoch: 5| Step: 11
Training loss: 0.4612913131713867
Validation loss: 2.1772475639979043

Epoch: 293| Step: 0
Training loss: 0.2767210006713867
Validation loss: 2.162229453523954

Epoch: 5| Step: 1
Training loss: 0.6086539030075073
Validation loss: 2.2115183919668198

Epoch: 5| Step: 2
Training loss: 0.25915688276290894
Validation loss: 2.159790719548861

Epoch: 5| Step: 3
Training loss: 0.33659982681274414
Validation loss: 2.1391114791234336

Epoch: 5| Step: 4
Training loss: 0.5318859815597534
Validation loss: 2.1525883078575134

Epoch: 5| Step: 5
Training loss: 0.27469170093536377
Validation loss: 2.149029850959778

Epoch: 5| Step: 6
Training loss: 0.6971752643585205
Validation loss: 2.0838975310325623

Epoch: 5| Step: 7
Training loss: 0.5277727842330933
Validation loss: 2.072436352570852

Epoch: 5| Step: 8
Training loss: 0.39732351899147034
Validation loss: 2.107034449776014

Epoch: 5| Step: 9
Training loss: 0.38315996527671814
Validation loss: 2.100699578722318

Epoch: 5| Step: 10
Training loss: 0.39802780747413635
Validation loss: 2.146738891800245

Epoch: 5| Step: 11
Training loss: 0.3826422691345215
Validation loss: 2.106855263312658

Epoch: 294| Step: 0
Training loss: 0.30577316880226135
Validation loss: 2.080991730093956

Epoch: 5| Step: 1
Training loss: 0.42437833547592163
Validation loss: 2.117193877696991

Epoch: 5| Step: 2
Training loss: 0.2758614122867584
Validation loss: 2.133733739455541

Epoch: 5| Step: 3
Training loss: 0.38061147928237915
Validation loss: 2.135715385278066

Epoch: 5| Step: 4
Training loss: 0.4325161874294281
Validation loss: 2.1537129878997803

Epoch: 5| Step: 5
Training loss: 0.4144977629184723
Validation loss: 2.1529807249704995

Epoch: 5| Step: 6
Training loss: 0.28806811571121216
Validation loss: 2.132515470186869

Epoch: 5| Step: 7
Training loss: 0.44010090827941895
Validation loss: 2.1490872899691262

Epoch: 5| Step: 8
Training loss: 0.37659400701522827
Validation loss: 2.111238807439804

Epoch: 5| Step: 9
Training loss: 0.4515470564365387
Validation loss: 2.1633190910021463

Epoch: 5| Step: 10
Training loss: 0.5776883363723755
Validation loss: 2.163786987463633

Epoch: 5| Step: 11
Training loss: 0.2794763743877411
Validation loss: 2.165493428707123

Epoch: 295| Step: 0
Training loss: 0.5925279855728149
Validation loss: 2.1771813879410424

Epoch: 5| Step: 1
Training loss: 0.4348176121711731
Validation loss: 2.1569926887750626

Epoch: 5| Step: 2
Training loss: 0.3093408942222595
Validation loss: 2.173799475034078

Epoch: 5| Step: 3
Training loss: 0.36829230189323425
Validation loss: 2.14368403951327

Epoch: 5| Step: 4
Training loss: 0.34049469232559204
Validation loss: 2.1446179946263633

Epoch: 5| Step: 5
Training loss: 0.2526363730430603
Validation loss: 2.169708569844564

Epoch: 5| Step: 6
Training loss: 0.3624129891395569
Validation loss: 2.1091677149136863

Epoch: 5| Step: 7
Training loss: 0.6672723293304443
Validation loss: 2.168342555562655

Epoch: 5| Step: 8
Training loss: 0.4159272313117981
Validation loss: 2.125785003105799

Epoch: 5| Step: 9
Training loss: 0.2832582890987396
Validation loss: 2.121438999970754

Epoch: 5| Step: 10
Training loss: 0.3686099052429199
Validation loss: 2.1640887012084327

Epoch: 5| Step: 11
Training loss: 0.15911024808883667
Validation loss: 2.0958010156949363

Epoch: 296| Step: 0
Training loss: 0.20873478055000305
Validation loss: 2.1621059676011405

Epoch: 5| Step: 1
Training loss: 0.42197760939598083
Validation loss: 2.162939637899399

Epoch: 5| Step: 2
Training loss: 0.42086586356163025
Validation loss: 2.1715506613254547

Epoch: 5| Step: 3
Training loss: 0.29952579736709595
Validation loss: 2.171611721316973

Epoch: 5| Step: 4
Training loss: 0.4877520203590393
Validation loss: 2.178902750213941

Epoch: 5| Step: 5
Training loss: 0.307899534702301
Validation loss: 2.2188489933808646

Epoch: 5| Step: 6
Training loss: 0.7940911054611206
Validation loss: 2.2361731131871543

Epoch: 5| Step: 7
Training loss: 0.3028384745121002
Validation loss: 2.186996544400851

Epoch: 5| Step: 8
Training loss: 0.35590532422065735
Validation loss: 2.2243292729059854

Epoch: 5| Step: 9
Training loss: 0.41751012206077576
Validation loss: 2.1739706099033356

Epoch: 5| Step: 10
Training loss: 0.39688315987586975
Validation loss: 2.1351595669984818

Epoch: 5| Step: 11
Training loss: 0.34864717721939087
Validation loss: 2.1478321005900702

Epoch: 297| Step: 0
Training loss: 0.4644344747066498
Validation loss: 2.168427606423696

Epoch: 5| Step: 1
Training loss: 0.2675919532775879
Validation loss: 2.12700026233991

Epoch: 5| Step: 2
Training loss: 0.3632104992866516
Validation loss: 2.13988067706426

Epoch: 5| Step: 3
Training loss: 0.48847347497940063
Validation loss: 2.1765672465165458

Epoch: 5| Step: 4
Training loss: 0.4842609465122223
Validation loss: 2.150234724084536

Epoch: 5| Step: 5
Training loss: 0.38902318477630615
Validation loss: 2.182239214579264

Epoch: 5| Step: 6
Training loss: 0.21047988533973694
Validation loss: 2.174138923486074

Epoch: 5| Step: 7
Training loss: 0.7245150208473206
Validation loss: 2.137162779768308

Epoch: 5| Step: 8
Training loss: 0.3780425488948822
Validation loss: 2.1522024671236673

Epoch: 5| Step: 9
Training loss: 0.2811567783355713
Validation loss: 2.1299457202355065

Epoch: 5| Step: 10
Training loss: 0.3609967827796936
Validation loss: 2.109338959058126

Epoch: 5| Step: 11
Training loss: 0.25089573860168457
Validation loss: 2.1194105992714563

Epoch: 298| Step: 0
Training loss: 0.27444005012512207
Validation loss: 2.075485880176226

Epoch: 5| Step: 1
Training loss: 0.46664151549339294
Validation loss: 2.161446124315262

Epoch: 5| Step: 2
Training loss: 0.42410001158714294
Validation loss: 2.1789965331554413

Epoch: 5| Step: 3
Training loss: 0.7205509543418884
Validation loss: 2.1343808819850287

Epoch: 5| Step: 4
Training loss: 0.36879292130470276
Validation loss: 2.1531425515810647

Epoch: 5| Step: 5
Training loss: 0.2520740032196045
Validation loss: 2.1402339041233063

Epoch: 5| Step: 6
Training loss: 0.3299296498298645
Validation loss: 2.1700362066427865

Epoch: 5| Step: 7
Training loss: 0.296983540058136
Validation loss: 2.0962241689364114

Epoch: 5| Step: 8
Training loss: 0.36338600516319275
Validation loss: 2.1015625496705375

Epoch: 5| Step: 9
Training loss: 0.33142879605293274
Validation loss: 2.094561422864596

Epoch: 5| Step: 10
Training loss: 0.5401327610015869
Validation loss: 2.0667023360729218

Epoch: 5| Step: 11
Training loss: 0.30428820848464966
Validation loss: 2.1415786296129227

Epoch: 299| Step: 0
Training loss: 0.3664727807044983
Validation loss: 2.1330705732107162

Epoch: 5| Step: 1
Training loss: 0.3646526336669922
Validation loss: 2.1256669561068215

Epoch: 5| Step: 2
Training loss: 0.2844417691230774
Validation loss: 2.1634141703446708

Epoch: 5| Step: 3
Training loss: 0.40300455689430237
Validation loss: 2.124621053536733

Epoch: 5| Step: 4
Training loss: 0.46898192167282104
Validation loss: 2.0965339293082557

Epoch: 5| Step: 5
Training loss: 0.5794880986213684
Validation loss: 2.1206992268562317

Epoch: 5| Step: 6
Training loss: 0.431816428899765
Validation loss: 2.131202424565951

Epoch: 5| Step: 7
Training loss: 0.29147854447364807
Validation loss: 2.141484022140503

Epoch: 5| Step: 8
Training loss: 0.7017025947570801
Validation loss: 2.121688430507978

Epoch: 5| Step: 9
Training loss: 0.3190002143383026
Validation loss: 2.0878231823444366

Epoch: 5| Step: 10
Training loss: 0.3122335970401764
Validation loss: 2.1591584384441376

Epoch: 5| Step: 11
Training loss: 0.12467396259307861
Validation loss: 2.089774966239929

Epoch: 300| Step: 0
Training loss: 0.2933611273765564
Validation loss: 2.159530599912008

Epoch: 5| Step: 1
Training loss: 0.46656209230422974
Validation loss: 2.1192541867494583

Epoch: 5| Step: 2
Training loss: 0.5849939584732056
Validation loss: 2.1769239703814187

Epoch: 5| Step: 3
Training loss: 0.36968329548835754
Validation loss: 2.1518494337797165

Epoch: 5| Step: 4
Training loss: 0.2582339942455292
Validation loss: 2.134273280700048

Epoch: 5| Step: 5
Training loss: 0.32089105248451233
Validation loss: 2.1660874088605246

Epoch: 5| Step: 6
Training loss: 0.31330248713493347
Validation loss: 2.190264771382014

Epoch: 5| Step: 7
Training loss: 0.18427667021751404
Validation loss: 2.1658874452114105

Epoch: 5| Step: 8
Training loss: 0.4602173864841461
Validation loss: 2.204785406589508

Epoch: 5| Step: 9
Training loss: 0.3872799575328827
Validation loss: 2.1815082182486853

Epoch: 5| Step: 10
Training loss: 0.45705461502075195
Validation loss: 2.1377604752779007

Epoch: 5| Step: 11
Training loss: 0.2621488571166992
Validation loss: 2.158555338780085

Epoch: 301| Step: 0
Training loss: 0.4909609854221344
Validation loss: 2.0866617610057197

Epoch: 5| Step: 1
Training loss: 0.40688854455947876
Validation loss: 2.0788880487283072

Epoch: 5| Step: 2
Training loss: 0.556540846824646
Validation loss: 2.0751287043094635

Epoch: 5| Step: 3
Training loss: 0.6783044934272766
Validation loss: 2.0802126924196878

Epoch: 5| Step: 4
Training loss: 0.31418177485466003
Validation loss: 2.080745592713356

Epoch: 5| Step: 5
Training loss: 0.30118411779403687
Validation loss: 2.1025204062461853

Epoch: 5| Step: 6
Training loss: 0.3076171278953552
Validation loss: 2.096169635653496

Epoch: 5| Step: 7
Training loss: 0.23247186839580536
Validation loss: 2.103298525015513

Epoch: 5| Step: 8
Training loss: 0.30878040194511414
Validation loss: 2.123063877224922

Epoch: 5| Step: 9
Training loss: 0.37779533863067627
Validation loss: 2.135082890590032

Epoch: 5| Step: 10
Training loss: 0.4308960437774658
Validation loss: 2.160711720585823

Epoch: 5| Step: 11
Training loss: 0.2809543311595917
Validation loss: 2.1654920180638633

Epoch: 302| Step: 0
Training loss: 0.36912664771080017
Validation loss: 2.143907050291697

Epoch: 5| Step: 1
Training loss: 0.2530410885810852
Validation loss: 2.143842577934265

Epoch: 5| Step: 2
Training loss: 0.2326175719499588
Validation loss: 2.124282404780388

Epoch: 5| Step: 3
Training loss: 0.3482359051704407
Validation loss: 2.1685514003038406

Epoch: 5| Step: 4
Training loss: 0.4026156961917877
Validation loss: 2.14390196899573

Epoch: 5| Step: 5
Training loss: 0.44015535712242126
Validation loss: 2.1283878882726035

Epoch: 5| Step: 6
Training loss: 0.4634207785129547
Validation loss: 2.189700707793236

Epoch: 5| Step: 7
Training loss: 0.2982025444507599
Validation loss: 2.164659226934115

Epoch: 5| Step: 8
Training loss: 0.7545231580734253
Validation loss: 2.1689444283644357

Epoch: 5| Step: 9
Training loss: 0.2501903474330902
Validation loss: 2.1503366430600486

Epoch: 5| Step: 10
Training loss: 0.49329280853271484
Validation loss: 2.162705843647321

Epoch: 5| Step: 11
Training loss: 0.3670027256011963
Validation loss: 2.1261721650759378

Epoch: 303| Step: 0
Training loss: 0.2293715476989746
Validation loss: 2.1746197938919067

Epoch: 5| Step: 1
Training loss: 0.48107385635375977
Validation loss: 2.248686204353968

Epoch: 5| Step: 2
Training loss: 0.25737297534942627
Validation loss: 2.1830129524072013

Epoch: 5| Step: 3
Training loss: 1.0702749490737915
Validation loss: 2.173712283372879

Epoch: 5| Step: 4
Training loss: 0.3483462929725647
Validation loss: 2.189004883170128

Epoch: 5| Step: 5
Training loss: 0.4034869074821472
Validation loss: 2.171247720718384

Epoch: 5| Step: 6
Training loss: 0.3592512011528015
Validation loss: 2.1810594896475473

Epoch: 5| Step: 7
Training loss: 0.23248648643493652
Validation loss: 2.14090525607268

Epoch: 5| Step: 8
Training loss: 0.4402080476284027
Validation loss: 2.100996802250544

Epoch: 5| Step: 9
Training loss: 0.27579379081726074
Validation loss: 2.0878460158904395

Epoch: 5| Step: 10
Training loss: 0.3565388023853302
Validation loss: 2.064284101128578

Epoch: 5| Step: 11
Training loss: 0.5399158000946045
Validation loss: 2.1113683034976325

Epoch: 304| Step: 0
Training loss: 0.28124886751174927
Validation loss: 2.1331487546364465

Epoch: 5| Step: 1
Training loss: 0.19477243721485138
Validation loss: 2.0948427617549896

Epoch: 5| Step: 2
Training loss: 0.3766292631626129
Validation loss: 2.1629831393559775

Epoch: 5| Step: 3
Training loss: 0.3266898989677429
Validation loss: 2.196081961194674

Epoch: 5| Step: 4
Training loss: 0.37289881706237793
Validation loss: 2.1775853037834167

Epoch: 5| Step: 5
Training loss: 0.4332399368286133
Validation loss: 2.161145950357119

Epoch: 5| Step: 6
Training loss: 0.37666022777557373
Validation loss: 2.1848418712615967

Epoch: 5| Step: 7
Training loss: 0.5153563618659973
Validation loss: 2.119768818219503

Epoch: 5| Step: 8
Training loss: 0.3331393003463745
Validation loss: 2.112866222858429

Epoch: 5| Step: 9
Training loss: 0.4127487242221832
Validation loss: 2.120388388633728

Epoch: 5| Step: 10
Training loss: 0.8112385869026184
Validation loss: 2.149708608786265

Epoch: 5| Step: 11
Training loss: 0.7546603679656982
Validation loss: 2.119946618874868

Epoch: 305| Step: 0
Training loss: 0.27260178327560425
Validation loss: 2.1695158183574677

Epoch: 5| Step: 1
Training loss: 0.18143220245838165
Validation loss: 2.1421541025241218

Epoch: 5| Step: 2
Training loss: 0.36519908905029297
Validation loss: 2.172241340080897

Epoch: 5| Step: 3
Training loss: 0.386404812335968
Validation loss: 2.177674184242884

Epoch: 5| Step: 4
Training loss: 0.6802268624305725
Validation loss: 2.145442987481753

Epoch: 5| Step: 5
Training loss: 0.3274979889392853
Validation loss: 2.093315079808235

Epoch: 5| Step: 6
Training loss: 0.3088454604148865
Validation loss: 2.1546500821908317

Epoch: 5| Step: 7
Training loss: 0.5291938185691833
Validation loss: 2.1612279067436853

Epoch: 5| Step: 8
Training loss: 0.28435105085372925
Validation loss: 2.123807097474734

Epoch: 5| Step: 9
Training loss: 0.26186293363571167
Validation loss: 2.059620752930641

Epoch: 5| Step: 10
Training loss: 0.4671684205532074
Validation loss: 2.1125985980033875

Epoch: 5| Step: 11
Training loss: 0.2259044647216797
Validation loss: 2.130138725042343

Epoch: 306| Step: 0
Training loss: 0.38743430376052856
Validation loss: 2.103654677669207

Epoch: 5| Step: 1
Training loss: 0.3331923484802246
Validation loss: 2.1464042911926904

Epoch: 5| Step: 2
Training loss: 0.5467461347579956
Validation loss: 2.169909343123436

Epoch: 5| Step: 3
Training loss: 0.40483197569847107
Validation loss: 2.1868926932414374

Epoch: 5| Step: 4
Training loss: 0.4254661202430725
Validation loss: 2.1460988521575928

Epoch: 5| Step: 5
Training loss: 0.23703065514564514
Validation loss: 2.148346314827601

Epoch: 5| Step: 6
Training loss: 0.2755069434642792
Validation loss: 2.1454638044039407

Epoch: 5| Step: 7
Training loss: 0.2699160575866699
Validation loss: 2.1219625075658164

Epoch: 5| Step: 8
Training loss: 0.29051724076271057
Validation loss: 2.155787537495295

Epoch: 5| Step: 9
Training loss: 0.36705851554870605
Validation loss: 2.1814089020093284

Epoch: 5| Step: 10
Training loss: 0.47468096017837524
Validation loss: 2.147565394639969

Epoch: 5| Step: 11
Training loss: 0.08609706163406372
Validation loss: 2.1334805389245353

Epoch: 307| Step: 0
Training loss: 0.3527609407901764
Validation loss: 2.1146563241879144

Epoch: 5| Step: 1
Training loss: 0.3275904059410095
Validation loss: 2.1714221835136414

Epoch: 5| Step: 2
Training loss: 0.34712153673171997
Validation loss: 2.1322330186764398

Epoch: 5| Step: 3
Training loss: 0.35697221755981445
Validation loss: 2.1610874235630035

Epoch: 5| Step: 4
Training loss: 0.19166100025177002
Validation loss: 2.167202969392141

Epoch: 5| Step: 5
Training loss: 0.349539190530777
Validation loss: 2.1820684423049292

Epoch: 5| Step: 6
Training loss: 0.5273963212966919
Validation loss: 2.170161714156469

Epoch: 5| Step: 7
Training loss: 0.3170643150806427
Validation loss: 2.172690436244011

Epoch: 5| Step: 8
Training loss: 0.30960288643836975
Validation loss: 2.1516008178393045

Epoch: 5| Step: 9
Training loss: 0.5912081003189087
Validation loss: 2.1399828841288886

Epoch: 5| Step: 10
Training loss: 0.4945299029350281
Validation loss: 2.1346787561972937

Epoch: 5| Step: 11
Training loss: 0.43049973249435425
Validation loss: 2.1840990483760834

Epoch: 308| Step: 0
Training loss: 0.28619375824928284
Validation loss: 2.1957874447107315

Epoch: 5| Step: 1
Training loss: 0.42727017402648926
Validation loss: 2.117979188760122

Epoch: 5| Step: 2
Training loss: 0.2823568880558014
Validation loss: 2.154536028703054

Epoch: 5| Step: 3
Training loss: 0.2568685710430145
Validation loss: 2.1636733214060464

Epoch: 5| Step: 4
Training loss: 0.4040430188179016
Validation loss: 2.1534767150878906

Epoch: 5| Step: 5
Training loss: 0.4035261571407318
Validation loss: 2.2016232858101525

Epoch: 5| Step: 6
Training loss: 0.266484797000885
Validation loss: 2.128384287158648

Epoch: 5| Step: 7
Training loss: 0.37836840748786926
Validation loss: 2.1399360497792563

Epoch: 5| Step: 8
Training loss: 0.23659634590148926
Validation loss: 2.13165844976902

Epoch: 5| Step: 9
Training loss: 0.6633415222167969
Validation loss: 2.10998065272967

Epoch: 5| Step: 10
Training loss: 0.4486822187900543
Validation loss: 2.0921170711517334

Epoch: 5| Step: 11
Training loss: 0.09152477979660034
Validation loss: 2.109782596429189

Epoch: 309| Step: 0
Training loss: 0.2622695565223694
Validation loss: 2.0759123315413794

Epoch: 5| Step: 1
Training loss: 0.5411216616630554
Validation loss: 2.1444840679566064

Epoch: 5| Step: 2
Training loss: 0.40534257888793945
Validation loss: 2.115702897310257

Epoch: 5| Step: 3
Training loss: 0.3192334771156311
Validation loss: 2.1420416086912155

Epoch: 5| Step: 4
Training loss: 0.3062133491039276
Validation loss: 2.1862234274546304

Epoch: 5| Step: 5
Training loss: 0.7365304231643677
Validation loss: 2.108305056889852

Epoch: 5| Step: 6
Training loss: 0.5212923884391785
Validation loss: 2.1185025622447333

Epoch: 5| Step: 7
Training loss: 0.30893412232398987
Validation loss: 2.140658666690191

Epoch: 5| Step: 8
Training loss: 0.3303294777870178
Validation loss: 2.156269227464994

Epoch: 5| Step: 9
Training loss: 0.21816758811473846
Validation loss: 2.10004693766435

Epoch: 5| Step: 10
Training loss: 0.3092535138130188
Validation loss: 2.107076480984688

Epoch: 5| Step: 11
Training loss: 0.17905044555664062
Validation loss: 2.1351012190183005

Epoch: 310| Step: 0
Training loss: 0.6396520733833313
Validation loss: 2.1116543213526406

Epoch: 5| Step: 1
Training loss: 0.3634493350982666
Validation loss: 2.15812020500501

Epoch: 5| Step: 2
Training loss: 0.2798751890659332
Validation loss: 2.1438940664132438

Epoch: 5| Step: 3
Training loss: 0.26627761125564575
Validation loss: 2.161947617928187

Epoch: 5| Step: 4
Training loss: 0.4143349230289459
Validation loss: 2.157813787460327

Epoch: 5| Step: 5
Training loss: 0.3661934435367584
Validation loss: 2.191705510020256

Epoch: 5| Step: 6
Training loss: 0.4788142144680023
Validation loss: 2.1355973333120346

Epoch: 5| Step: 7
Training loss: 0.33508598804473877
Validation loss: 2.132891595363617

Epoch: 5| Step: 8
Training loss: 0.2280050814151764
Validation loss: 2.1219713737567267

Epoch: 5| Step: 9
Training loss: 0.5240090489387512
Validation loss: 2.121663734316826

Epoch: 5| Step: 10
Training loss: 0.2593420147895813
Validation loss: 2.159628316760063

Epoch: 5| Step: 11
Training loss: 0.1793665587902069
Validation loss: 2.1552445391813913

Epoch: 311| Step: 0
Training loss: 0.31937843561172485
Validation loss: 2.1496062576770782

Epoch: 5| Step: 1
Training loss: 0.23523664474487305
Validation loss: 2.188792179028193

Epoch: 5| Step: 2
Training loss: 0.3566820025444031
Validation loss: 2.1877803603808084

Epoch: 5| Step: 3
Training loss: 0.28592392802238464
Validation loss: 2.1770207285881042

Epoch: 5| Step: 4
Training loss: 0.4779490530490875
Validation loss: 2.195577159523964

Epoch: 5| Step: 5
Training loss: 0.39527279138565063
Validation loss: 2.1105640729268393

Epoch: 5| Step: 6
Training loss: 0.3245343863964081
Validation loss: 2.146019617716471

Epoch: 5| Step: 7
Training loss: 0.3783925175666809
Validation loss: 2.1433477302392325

Epoch: 5| Step: 8
Training loss: 0.3928411602973938
Validation loss: 2.1856950322786965

Epoch: 5| Step: 9
Training loss: 0.31236395239830017
Validation loss: 2.148825148741404

Epoch: 5| Step: 10
Training loss: 0.6823917627334595
Validation loss: 2.137822816769282

Epoch: 5| Step: 11
Training loss: 0.17033636569976807
Validation loss: 2.126048117876053

Epoch: 312| Step: 0
Training loss: 0.3580494523048401
Validation loss: 2.1784541408220925

Epoch: 5| Step: 1
Training loss: 0.47479963302612305
Validation loss: 2.1492392669121423

Epoch: 5| Step: 2
Training loss: 0.13533149659633636
Validation loss: 2.178387006123861

Epoch: 5| Step: 3
Training loss: 0.30384188890457153
Validation loss: 2.172357052564621

Epoch: 5| Step: 4
Training loss: 0.3226931393146515
Validation loss: 2.1242836117744446

Epoch: 5| Step: 5
Training loss: 0.7397618293762207
Validation loss: 2.204442873597145

Epoch: 5| Step: 6
Training loss: 0.32857638597488403
Validation loss: 2.155660559733709

Epoch: 5| Step: 7
Training loss: 0.24875135719776154
Validation loss: 2.172857334216436

Epoch: 5| Step: 8
Training loss: 0.37706655263900757
Validation loss: 2.1652810871601105

Epoch: 5| Step: 9
Training loss: 0.3450848162174225
Validation loss: 2.159855385621389

Epoch: 5| Step: 10
Training loss: 0.3545135259628296
Validation loss: 2.1406152099370956

Epoch: 5| Step: 11
Training loss: 0.6850783228874207
Validation loss: 2.1427970131238303

Epoch: 313| Step: 0
Training loss: 0.25440600514411926
Validation loss: 2.1694752126932144

Epoch: 5| Step: 1
Training loss: 0.30623865127563477
Validation loss: 2.1164433856805167

Epoch: 5| Step: 2
Training loss: 0.28528016805648804
Validation loss: 2.1214788953463235

Epoch: 5| Step: 3
Training loss: 0.3560336232185364
Validation loss: 2.176373397310575

Epoch: 5| Step: 4
Training loss: 0.2199123203754425
Validation loss: 2.1093298345804214

Epoch: 5| Step: 5
Training loss: 0.39186573028564453
Validation loss: 2.087561453382174

Epoch: 5| Step: 6
Training loss: 0.48286157846450806
Validation loss: 2.152450680732727

Epoch: 5| Step: 7
Training loss: 0.5977174639701843
Validation loss: 2.1738761762777963

Epoch: 5| Step: 8
Training loss: 0.2954750657081604
Validation loss: 2.1569937765598297

Epoch: 5| Step: 9
Training loss: 0.505551278591156
Validation loss: 2.1587145576874414

Epoch: 5| Step: 10
Training loss: 0.2600051462650299
Validation loss: 2.122376655538877

Epoch: 5| Step: 11
Training loss: 0.6312977075576782
Validation loss: 2.164920434355736

Epoch: 314| Step: 0
Training loss: 0.3133091926574707
Validation loss: 2.221332013607025

Epoch: 5| Step: 1
Training loss: 0.38608241081237793
Validation loss: 2.179089387257894

Epoch: 5| Step: 2
Training loss: 0.38485637307167053
Validation loss: 2.22022645175457

Epoch: 5| Step: 3
Training loss: 0.23738963901996613
Validation loss: 2.234938452641169

Epoch: 5| Step: 4
Training loss: 0.25935739278793335
Validation loss: 2.1888209780057273

Epoch: 5| Step: 5
Training loss: 0.6090766191482544
Validation loss: 2.1916419565677643

Epoch: 5| Step: 6
Training loss: 0.5242670774459839
Validation loss: 2.1580802698930106

Epoch: 5| Step: 7
Training loss: 0.4098079800605774
Validation loss: 2.165214548508326

Epoch: 5| Step: 8
Training loss: 0.508309543132782
Validation loss: 2.1785051375627518

Epoch: 5| Step: 9
Training loss: 0.32262858748435974
Validation loss: 2.1600874960422516

Epoch: 5| Step: 10
Training loss: 0.384592205286026
Validation loss: 2.1915571838617325

Epoch: 5| Step: 11
Training loss: 0.1681550145149231
Validation loss: 2.2278846402963004

Epoch: 315| Step: 0
Training loss: 0.6870183944702148
Validation loss: 2.2055105169614158

Epoch: 5| Step: 1
Training loss: 0.2558518052101135
Validation loss: 2.197413752476374

Epoch: 5| Step: 2
Training loss: 0.38011032342910767
Validation loss: 2.2286708652973175

Epoch: 5| Step: 3
Training loss: 0.2822224199771881
Validation loss: 2.17769131064415

Epoch: 5| Step: 4
Training loss: 0.4921589493751526
Validation loss: 2.181226854523023

Epoch: 5| Step: 5
Training loss: 0.30025702714920044
Validation loss: 2.1310362865527472

Epoch: 5| Step: 6
Training loss: 0.4396093785762787
Validation loss: 2.1930200904607773

Epoch: 5| Step: 7
Training loss: 0.3794979453086853
Validation loss: 2.1050406098365784

Epoch: 5| Step: 8
Training loss: 0.2824813425540924
Validation loss: 2.1322666058937707

Epoch: 5| Step: 9
Training loss: 0.3827752470970154
Validation loss: 2.1396212776501975

Epoch: 5| Step: 10
Training loss: 0.3133573830127716
Validation loss: 2.1404823313156762

Epoch: 5| Step: 11
Training loss: 0.4076484739780426
Validation loss: 2.144171173373858

Epoch: 316| Step: 0
Training loss: 0.2454369068145752
Validation loss: 2.171516925096512

Epoch: 5| Step: 1
Training loss: 0.30583861470222473
Validation loss: 2.163800925016403

Epoch: 5| Step: 2
Training loss: 0.22911322116851807
Validation loss: 2.1633296559254327

Epoch: 5| Step: 3
Training loss: 0.37302830815315247
Validation loss: 2.1367874095837274

Epoch: 5| Step: 4
Training loss: 0.3831576704978943
Validation loss: 2.1082930266857147

Epoch: 5| Step: 5
Training loss: 0.7395545244216919
Validation loss: 2.1539323876301446

Epoch: 5| Step: 6
Training loss: 0.23707620799541473
Validation loss: 2.087237556775411

Epoch: 5| Step: 7
Training loss: 0.522471010684967
Validation loss: 2.180241381128629

Epoch: 5| Step: 8
Training loss: 0.275251567363739
Validation loss: 2.1650297145048776

Epoch: 5| Step: 9
Training loss: 0.4224754273891449
Validation loss: 2.130085979898771

Epoch: 5| Step: 10
Training loss: 0.26693588495254517
Validation loss: 2.1234244207541146

Epoch: 5| Step: 11
Training loss: 0.3949894905090332
Validation loss: 2.1518263469139733

Epoch: 317| Step: 0
Training loss: 0.5040901303291321
Validation loss: 2.1385248750448227

Epoch: 5| Step: 1
Training loss: 0.23444607853889465
Validation loss: 2.086173271139463

Epoch: 5| Step: 2
Training loss: 0.2144145965576172
Validation loss: 2.1835226714611053

Epoch: 5| Step: 3
Training loss: 0.2371077835559845
Validation loss: 2.182527760664622

Epoch: 5| Step: 4
Training loss: 0.337281733751297
Validation loss: 2.1347027122974396

Epoch: 5| Step: 5
Training loss: 0.33378711342811584
Validation loss: 2.1243530809879303

Epoch: 5| Step: 6
Training loss: 0.3301381766796112
Validation loss: 2.1698895692825317

Epoch: 5| Step: 7
Training loss: 0.3559674024581909
Validation loss: 2.161228949824969

Epoch: 5| Step: 8
Training loss: 0.2721070647239685
Validation loss: 2.154703895250956

Epoch: 5| Step: 9
Training loss: 0.26684507727622986
Validation loss: 2.1626414954662323

Epoch: 5| Step: 10
Training loss: 0.3383379578590393
Validation loss: 2.1892091582218804

Epoch: 5| Step: 11
Training loss: 2.7184383869171143
Validation loss: 2.1302264581123986

Epoch: 318| Step: 0
Training loss: 0.22916467487812042
Validation loss: 2.133884390195211

Epoch: 5| Step: 1
Training loss: 0.338009774684906
Validation loss: 2.1654627472162247

Epoch: 5| Step: 2
Training loss: 0.28541749715805054
Validation loss: 2.167392129699389

Epoch: 5| Step: 3
Training loss: 0.3986069858074188
Validation loss: 2.2060798903306327

Epoch: 5| Step: 4
Training loss: 0.2782530188560486
Validation loss: 2.180280258258184

Epoch: 5| Step: 5
Training loss: 0.6983597278594971
Validation loss: 2.149249345064163

Epoch: 5| Step: 6
Training loss: 0.3722989559173584
Validation loss: 2.136981725692749

Epoch: 5| Step: 7
Training loss: 0.5867044925689697
Validation loss: 2.12978266676267

Epoch: 5| Step: 8
Training loss: 0.3057820200920105
Validation loss: 2.127499903241793

Epoch: 5| Step: 9
Training loss: 0.2770402729511261
Validation loss: 2.177148977915446

Epoch: 5| Step: 10
Training loss: 0.433881938457489
Validation loss: 2.2266673098007836

Epoch: 5| Step: 11
Training loss: 0.29754316806793213
Validation loss: 2.1682671904563904

Epoch: 319| Step: 0
Training loss: 0.5997418165206909
Validation loss: 2.1503465274969735

Epoch: 5| Step: 1
Training loss: 0.32588791847229004
Validation loss: 2.1424376418193183

Epoch: 5| Step: 2
Training loss: 0.2161666452884674
Validation loss: 2.1109762837489447

Epoch: 5| Step: 3
Training loss: 0.3433806300163269
Validation loss: 2.196773186326027

Epoch: 5| Step: 4
Training loss: 0.30745071172714233
Validation loss: 2.184021924932798

Epoch: 5| Step: 5
Training loss: 0.3252469301223755
Validation loss: 2.171980232000351

Epoch: 5| Step: 6
Training loss: 0.3640034794807434
Validation loss: 2.1561362047990165

Epoch: 5| Step: 7
Training loss: 0.24650058150291443
Validation loss: 2.2157839636007943

Epoch: 5| Step: 8
Training loss: 0.4599800705909729
Validation loss: 2.1760905236005783

Epoch: 5| Step: 9
Training loss: 0.6253578662872314
Validation loss: 2.222846100727717

Epoch: 5| Step: 10
Training loss: 0.28832724690437317
Validation loss: 2.194230784972509

Epoch: 5| Step: 11
Training loss: 0.3789149522781372
Validation loss: 2.1860213379065194

Epoch: 320| Step: 0
Training loss: 0.35992494225502014
Validation loss: 2.1976776470740638

Epoch: 5| Step: 1
Training loss: 0.20945140719413757
Validation loss: 2.2016361008087793

Epoch: 5| Step: 2
Training loss: 0.597130298614502
Validation loss: 2.169806718826294

Epoch: 5| Step: 3
Training loss: 0.37944403290748596
Validation loss: 2.1967574010292688

Epoch: 5| Step: 4
Training loss: 0.31005316972732544
Validation loss: 2.186709334452947

Epoch: 5| Step: 5
Training loss: 0.3473276197910309
Validation loss: 2.182069023450216

Epoch: 5| Step: 6
Training loss: 0.2637175917625427
Validation loss: 2.1973866373300552

Epoch: 5| Step: 7
Training loss: 0.23865440487861633
Validation loss: 2.2315575579802194

Epoch: 5| Step: 8
Training loss: 0.566363513469696
Validation loss: 2.2465346852938333

Epoch: 5| Step: 9
Training loss: 0.4728507995605469
Validation loss: 2.204789857069651

Epoch: 5| Step: 10
Training loss: 0.22922268509864807
Validation loss: 2.1479783852895102

Epoch: 5| Step: 11
Training loss: 0.3077037036418915
Validation loss: 2.1166118880112967

Epoch: 321| Step: 0
Training loss: 0.26155099272727966
Validation loss: 2.182868242263794

Epoch: 5| Step: 1
Training loss: 0.5408735871315002
Validation loss: 2.206858476003011

Epoch: 5| Step: 2
Training loss: 0.23273205757141113
Validation loss: 2.1964197854200997

Epoch: 5| Step: 3
Training loss: 0.3106602728366852
Validation loss: 2.177420745293299

Epoch: 5| Step: 4
Training loss: 0.2871188223361969
Validation loss: 2.23519137998422

Epoch: 5| Step: 5
Training loss: 0.2613754868507385
Validation loss: 2.2137707074483237

Epoch: 5| Step: 6
Training loss: 0.3946875035762787
Validation loss: 2.2006114721298218

Epoch: 5| Step: 7
Training loss: 0.2897241413593292
Validation loss: 2.2443918685118356

Epoch: 5| Step: 8
Training loss: 0.7465035915374756
Validation loss: 2.2273356368144355

Epoch: 5| Step: 9
Training loss: 0.25902265310287476
Validation loss: 2.202223539352417

Epoch: 5| Step: 10
Training loss: 0.39931195974349976
Validation loss: 2.2206149150927863

Epoch: 5| Step: 11
Training loss: 0.1667346954345703
Validation loss: 2.197215368350347

Epoch: 322| Step: 0
Training loss: 0.1759205311536789
Validation loss: 2.1713894307613373

Epoch: 5| Step: 1
Training loss: 0.2561773657798767
Validation loss: 2.1785307079553604

Epoch: 5| Step: 2
Training loss: 0.42625170946121216
Validation loss: 2.2049894084533057

Epoch: 5| Step: 3
Training loss: 0.24888408184051514
Validation loss: 2.1537797451019287

Epoch: 5| Step: 4
Training loss: 0.3103671371936798
Validation loss: 2.1432648052771888

Epoch: 5| Step: 5
Training loss: 0.4487083852291107
Validation loss: 2.144297242164612

Epoch: 5| Step: 6
Training loss: 0.4242297112941742
Validation loss: 2.188516398270925

Epoch: 5| Step: 7
Training loss: 0.7350863218307495
Validation loss: 2.103206450740496

Epoch: 5| Step: 8
Training loss: 0.24388842284679413
Validation loss: 2.1390607903401055

Epoch: 5| Step: 9
Training loss: 0.2823545038700104
Validation loss: 2.1509640167156854

Epoch: 5| Step: 10
Training loss: 0.29066967964172363
Validation loss: 2.1480997751156488

Epoch: 5| Step: 11
Training loss: 0.18951958417892456
Validation loss: 2.1896758675575256

Epoch: 323| Step: 0
Training loss: 0.32778260111808777
Validation loss: 2.2111559410889945

Epoch: 5| Step: 1
Training loss: 0.21706843376159668
Validation loss: 2.203158294161161

Epoch: 5| Step: 2
Training loss: 0.2702799439430237
Validation loss: 2.1507365157206855

Epoch: 5| Step: 3
Training loss: 0.3129802346229553
Validation loss: 2.16414745648702

Epoch: 5| Step: 4
Training loss: 0.3927851915359497
Validation loss: 2.1139014859994254

Epoch: 5| Step: 5
Training loss: 0.43970805406570435
Validation loss: 2.0893395394086838

Epoch: 5| Step: 6
Training loss: 0.24092908203601837
Validation loss: 2.1772538671890893

Epoch: 5| Step: 7
Training loss: 0.1922222375869751
Validation loss: 2.1065411468346915

Epoch: 5| Step: 8
Training loss: 0.32531431317329407
Validation loss: 2.194535255432129

Epoch: 5| Step: 9
Training loss: 0.2752615511417389
Validation loss: 2.14653450747331

Epoch: 5| Step: 10
Training loss: 0.6301484107971191
Validation loss: 2.183823600411415

Epoch: 5| Step: 11
Training loss: 1.5369131565093994
Validation loss: 2.174123595158259

Epoch: 324| Step: 0
Training loss: 0.20426616072654724
Validation loss: 2.1902938882509866

Epoch: 5| Step: 1
Training loss: 0.4215499758720398
Validation loss: 2.1647942612568536

Epoch: 5| Step: 2
Training loss: 0.2523607909679413
Validation loss: 2.1840192824602127

Epoch: 5| Step: 3
Training loss: 0.28642359375953674
Validation loss: 2.174455846349398

Epoch: 5| Step: 4
Training loss: 0.601851224899292
Validation loss: 2.231646880507469

Epoch: 5| Step: 5
Training loss: 0.4435575008392334
Validation loss: 2.2046000162760415

Epoch: 5| Step: 6
Training loss: 0.3716875910758972
Validation loss: 2.2010750571886697

Epoch: 5| Step: 7
Training loss: 0.3083493113517761
Validation loss: 2.1507693976163864

Epoch: 5| Step: 8
Training loss: 0.4675789773464203
Validation loss: 2.2009235322475433

Epoch: 5| Step: 9
Training loss: 0.28987917304039
Validation loss: 2.1534824073314667

Epoch: 5| Step: 10
Training loss: 0.22885027527809143
Validation loss: 2.1442229648431144

Epoch: 5| Step: 11
Training loss: 0.5041569471359253
Validation loss: 2.1306741138299308

Epoch: 325| Step: 0
Training loss: 0.348392128944397
Validation loss: 2.134727125366529

Epoch: 5| Step: 1
Training loss: 0.8184102773666382
Validation loss: 2.122911830743154

Epoch: 5| Step: 2
Training loss: 0.2015693187713623
Validation loss: 2.1696945130825043

Epoch: 5| Step: 3
Training loss: 0.2794981598854065
Validation loss: 2.1429732690254846

Epoch: 5| Step: 4
Training loss: 0.2750137746334076
Validation loss: 2.1933759649594626

Epoch: 5| Step: 5
Training loss: 0.3395830988883972
Validation loss: 2.198075463374456

Epoch: 5| Step: 6
Training loss: 0.2975305914878845
Validation loss: 2.1863080163796744

Epoch: 5| Step: 7
Training loss: 0.28183022141456604
Validation loss: 2.1581995089848838

Epoch: 5| Step: 8
Training loss: 0.5061918497085571
Validation loss: 2.158426304658254

Epoch: 5| Step: 9
Training loss: 0.31300386786460876
Validation loss: 2.1635757386684418

Epoch: 5| Step: 10
Training loss: 0.21587803959846497
Validation loss: 2.155928075313568

Epoch: 5| Step: 11
Training loss: 0.23200595378875732
Validation loss: 2.1509564916292825

Epoch: 326| Step: 0
Training loss: 0.34786128997802734
Validation loss: 2.1783679525057473

Epoch: 5| Step: 1
Training loss: 0.3120494484901428
Validation loss: 2.210805043578148

Epoch: 5| Step: 2
Training loss: 0.3593555688858032
Validation loss: 2.171364516019821

Epoch: 5| Step: 3
Training loss: 0.36615657806396484
Validation loss: 2.179847319920858

Epoch: 5| Step: 4
Training loss: 0.3535119891166687
Validation loss: 2.2171611189842224

Epoch: 5| Step: 5
Training loss: 0.48654231429100037
Validation loss: 2.152883365750313

Epoch: 5| Step: 6
Training loss: 0.8069754838943481
Validation loss: 2.127037212252617

Epoch: 5| Step: 7
Training loss: 0.3802863657474518
Validation loss: 2.140677978595098

Epoch: 5| Step: 8
Training loss: 0.27972665429115295
Validation loss: 2.1647490511337915

Epoch: 5| Step: 9
Training loss: 0.24367716908454895
Validation loss: 2.1633499364058175

Epoch: 5| Step: 10
Training loss: 0.32696333527565
Validation loss: 2.127508799235026

Epoch: 5| Step: 11
Training loss: 0.24117839336395264
Validation loss: 2.1495226373275123

Epoch: 327| Step: 0
Training loss: 0.2097836285829544
Validation loss: 2.1274246672789254

Epoch: 5| Step: 1
Training loss: 0.23944005370140076
Validation loss: 2.135009601712227

Epoch: 5| Step: 2
Training loss: 0.3321217894554138
Validation loss: 2.1425347328186035

Epoch: 5| Step: 3
Training loss: 0.3196314871311188
Validation loss: 2.1655393242836

Epoch: 5| Step: 4
Training loss: 0.3018438220024109
Validation loss: 2.181180939078331

Epoch: 5| Step: 5
Training loss: 0.3943411707878113
Validation loss: 2.135013217727343

Epoch: 5| Step: 6
Training loss: 0.7534879446029663
Validation loss: 2.1860892872015634

Epoch: 5| Step: 7
Training loss: 0.3596985340118408
Validation loss: 2.172040561834971

Epoch: 5| Step: 8
Training loss: 0.4143083691596985
Validation loss: 2.1989080756902695

Epoch: 5| Step: 9
Training loss: 0.2782270014286041
Validation loss: 2.2050042003393173

Epoch: 5| Step: 10
Training loss: 0.28377750515937805
Validation loss: 2.2166277368863425

Epoch: 5| Step: 11
Training loss: 0.29140257835388184
Validation loss: 2.185722569624583

Epoch: 328| Step: 0
Training loss: 0.7950023412704468
Validation loss: 2.223638822635015

Epoch: 5| Step: 1
Training loss: 0.19073037803173065
Validation loss: 2.2316868801911673

Epoch: 5| Step: 2
Training loss: 0.4018821120262146
Validation loss: 2.2087664107481637

Epoch: 5| Step: 3
Training loss: 0.2721540927886963
Validation loss: 2.1623788625001907

Epoch: 5| Step: 4
Training loss: 0.3188612163066864
Validation loss: 2.1680310567220054

Epoch: 5| Step: 5
Training loss: 0.2815335988998413
Validation loss: 2.173247992992401

Epoch: 5| Step: 6
Training loss: 0.3189052939414978
Validation loss: 2.149814357360204

Epoch: 5| Step: 7
Training loss: 0.4569620192050934
Validation loss: 2.232054183880488

Epoch: 5| Step: 8
Training loss: 0.36545830965042114
Validation loss: 2.180658280849457

Epoch: 5| Step: 9
Training loss: 0.3514203131198883
Validation loss: 2.107255885998408

Epoch: 5| Step: 10
Training loss: 0.2902495265007019
Validation loss: 2.181136046846708

Epoch: 5| Step: 11
Training loss: 0.3260425627231598
Validation loss: 2.129545196890831

Epoch: 329| Step: 0
Training loss: 0.5976470112800598
Validation loss: 2.1611702342828116

Epoch: 5| Step: 1
Training loss: 0.2814645767211914
Validation loss: 2.1889315446217856

Epoch: 5| Step: 2
Training loss: 0.2786557674407959
Validation loss: 2.1680681854486465

Epoch: 5| Step: 3
Training loss: 0.3546063303947449
Validation loss: 2.1714685261249542

Epoch: 5| Step: 4
Training loss: 0.2560597062110901
Validation loss: 2.193438857793808

Epoch: 5| Step: 5
Training loss: 0.30537670850753784
Validation loss: 2.151926025748253

Epoch: 5| Step: 6
Training loss: 0.2840389609336853
Validation loss: 2.1523693104585013

Epoch: 5| Step: 7
Training loss: 0.408440500497818
Validation loss: 2.1532290826241174

Epoch: 5| Step: 8
Training loss: 0.31862661242485046
Validation loss: 2.1467677851517997

Epoch: 5| Step: 9
Training loss: 0.45865726470947266
Validation loss: 2.1619088649749756

Epoch: 5| Step: 10
Training loss: 0.4156344532966614
Validation loss: 2.2127292156219482

Epoch: 5| Step: 11
Training loss: 0.791176438331604
Validation loss: 2.1873031308253608

Epoch: 330| Step: 0
Training loss: 0.32204800844192505
Validation loss: 2.145003169775009

Epoch: 5| Step: 1
Training loss: 0.24169130623340607
Validation loss: 2.1819173842668533

Epoch: 5| Step: 2
Training loss: 0.4473096430301666
Validation loss: 2.1725037644306817

Epoch: 5| Step: 3
Training loss: 0.383638858795166
Validation loss: 2.1422660648822784

Epoch: 5| Step: 4
Training loss: 0.2981833815574646
Validation loss: 2.1177194813887277

Epoch: 5| Step: 5
Training loss: 0.2702573537826538
Validation loss: 2.1071877479553223

Epoch: 5| Step: 6
Training loss: 0.6637436151504517
Validation loss: 2.1334316035111747

Epoch: 5| Step: 7
Training loss: 0.32359614968299866
Validation loss: 2.1382782409588494

Epoch: 5| Step: 8
Training loss: 0.3049720525741577
Validation loss: 2.1429284463326135

Epoch: 5| Step: 9
Training loss: 0.24758532643318176
Validation loss: 2.156154155731201

Epoch: 5| Step: 10
Training loss: 0.3587159514427185
Validation loss: 2.1785099605719247

Epoch: 5| Step: 11
Training loss: 0.2594255208969116
Validation loss: 2.184425671895345

Epoch: 331| Step: 0
Training loss: 0.5322918891906738
Validation loss: 2.1734438439210257

Epoch: 5| Step: 1
Training loss: 0.32408541440963745
Validation loss: 2.1220933149258294

Epoch: 5| Step: 2
Training loss: 0.31913694739341736
Validation loss: 2.10173337161541

Epoch: 5| Step: 3
Training loss: 0.21500298380851746
Validation loss: 2.1113470097382865

Epoch: 5| Step: 4
Training loss: 0.4057236313819885
Validation loss: 2.1116002599398294

Epoch: 5| Step: 5
Training loss: 0.3790434002876282
Validation loss: 2.1386254082123437

Epoch: 5| Step: 6
Training loss: 0.3343551456928253
Validation loss: 2.1075512766838074

Epoch: 5| Step: 7
Training loss: 0.2738855481147766
Validation loss: 2.126541996995608

Epoch: 5| Step: 8
Training loss: 0.19787058234214783
Validation loss: 2.138974050680796

Epoch: 5| Step: 9
Training loss: 0.43331223726272583
Validation loss: 2.1566507518291473

Epoch: 5| Step: 10
Training loss: 0.3085932731628418
Validation loss: 2.200587605436643

Epoch: 5| Step: 11
Training loss: 0.5026148557662964
Validation loss: 2.1937121550242105

Epoch: 332| Step: 0
Training loss: 0.28489363193511963
Validation loss: 2.1843195309241614

Epoch: 5| Step: 1
Training loss: 0.40757864713668823
Validation loss: 2.1911007265249887

Epoch: 5| Step: 2
Training loss: 0.4891977906227112
Validation loss: 2.1606086591879525

Epoch: 5| Step: 3
Training loss: 0.2103608101606369
Validation loss: 2.152808497349421

Epoch: 5| Step: 4
Training loss: 0.3647635579109192
Validation loss: 2.121881196896235

Epoch: 5| Step: 5
Training loss: 0.7704523801803589
Validation loss: 2.0961597661177316

Epoch: 5| Step: 6
Training loss: 0.28007709980010986
Validation loss: 2.133403311173121

Epoch: 5| Step: 7
Training loss: 0.4695783257484436
Validation loss: 2.1400923331578574

Epoch: 5| Step: 8
Training loss: 0.23597994446754456
Validation loss: 2.139994964003563

Epoch: 5| Step: 9
Training loss: 0.24952411651611328
Validation loss: 2.1148674388726554

Epoch: 5| Step: 10
Training loss: 0.2726970613002777
Validation loss: 2.1372724920511246

Epoch: 5| Step: 11
Training loss: 0.3671451508998871
Validation loss: 2.204757258296013

Epoch: 333| Step: 0
Training loss: 0.4685511589050293
Validation loss: 2.121931736667951

Epoch: 5| Step: 1
Training loss: 0.3936586081981659
Validation loss: 2.1245646874109902

Epoch: 5| Step: 2
Training loss: 0.22783079743385315
Validation loss: 2.1582882553339005

Epoch: 5| Step: 3
Training loss: 0.7172138094902039
Validation loss: 2.112923855582873

Epoch: 5| Step: 4
Training loss: 0.307411253452301
Validation loss: 2.1390401671330133

Epoch: 5| Step: 5
Training loss: 0.3135698437690735
Validation loss: 2.1133878429730735

Epoch: 5| Step: 6
Training loss: 0.3008180260658264
Validation loss: 2.1037182410558066

Epoch: 5| Step: 7
Training loss: 0.18027858436107635
Validation loss: 2.1551951666673026

Epoch: 5| Step: 8
Training loss: 0.22983136773109436
Validation loss: 2.1077701101700463

Epoch: 5| Step: 9
Training loss: 0.40656405687332153
Validation loss: 2.153647909561793

Epoch: 5| Step: 10
Training loss: 0.309330552816391
Validation loss: 2.1105008920033774

Epoch: 5| Step: 11
Training loss: 0.29868030548095703
Validation loss: 2.096989711125692

Epoch: 334| Step: 0
Training loss: 0.3927231431007385
Validation loss: 2.132831205924352

Epoch: 5| Step: 1
Training loss: 0.7292877435684204
Validation loss: 2.203622500101725

Epoch: 5| Step: 2
Training loss: 0.3556041717529297
Validation loss: 2.160423000653585

Epoch: 5| Step: 3
Training loss: 0.34600958228111267
Validation loss: 2.1703566958506904

Epoch: 5| Step: 4
Training loss: 0.3762473165988922
Validation loss: 2.1876318206389747

Epoch: 5| Step: 5
Training loss: 0.19313915073871613
Validation loss: 2.181698794166247

Epoch: 5| Step: 6
Training loss: 0.35757696628570557
Validation loss: 2.1337336897850037

Epoch: 5| Step: 7
Training loss: 0.2692398726940155
Validation loss: 2.1526523480812707

Epoch: 5| Step: 8
Training loss: 0.24971754848957062
Validation loss: 2.14161217212677

Epoch: 5| Step: 9
Training loss: 0.3935076594352722
Validation loss: 2.156842698653539

Epoch: 5| Step: 10
Training loss: 0.22854578495025635
Validation loss: 2.1425784081220627

Epoch: 5| Step: 11
Training loss: 0.5133874416351318
Validation loss: 2.1502421498298645

Epoch: 335| Step: 0
Training loss: 0.5704725980758667
Validation loss: 2.1639827291170755

Epoch: 5| Step: 1
Training loss: 0.6036707162857056
Validation loss: 2.1629722913106284

Epoch: 5| Step: 2
Training loss: 0.30847615003585815
Validation loss: 2.1700508693854013

Epoch: 5| Step: 3
Training loss: 0.41949939727783203
Validation loss: 2.2345570623874664

Epoch: 5| Step: 4
Training loss: 0.3316499590873718
Validation loss: 2.1740917613108954

Epoch: 5| Step: 5
Training loss: 0.26046496629714966
Validation loss: 2.1849180459976196

Epoch: 5| Step: 6
Training loss: 0.21700720489025116
Validation loss: 2.1904947658379874

Epoch: 5| Step: 7
Training loss: 0.36206895112991333
Validation loss: 2.1320419311523438

Epoch: 5| Step: 8
Training loss: 0.2320047914981842
Validation loss: 2.12027145922184

Epoch: 5| Step: 9
Training loss: 0.3192932903766632
Validation loss: 2.0805144806702933

Epoch: 5| Step: 10
Training loss: 0.26519984006881714
Validation loss: 2.089105193813642

Epoch: 5| Step: 11
Training loss: 0.1749463677406311
Validation loss: 2.077064280708631

Epoch: 336| Step: 0
Training loss: 0.2882232069969177
Validation loss: 2.069495509068171

Epoch: 5| Step: 1
Training loss: 0.25844213366508484
Validation loss: 2.067585811018944

Epoch: 5| Step: 2
Training loss: 0.8085541725158691
Validation loss: 2.124780764182409

Epoch: 5| Step: 3
Training loss: 0.23666813969612122
Validation loss: 2.1617349088191986

Epoch: 5| Step: 4
Training loss: 0.38632068037986755
Validation loss: 2.1811596055825553

Epoch: 5| Step: 5
Training loss: 0.2882808744907379
Validation loss: 2.1163981407880783

Epoch: 5| Step: 6
Training loss: 0.27867454290390015
Validation loss: 2.1332550843556723

Epoch: 5| Step: 7
Training loss: 0.2295263707637787
Validation loss: 2.127922693888346

Epoch: 5| Step: 8
Training loss: 0.37454456090927124
Validation loss: 2.13311205804348

Epoch: 5| Step: 9
Training loss: 0.40770024061203003
Validation loss: 2.0983107735713324

Epoch: 5| Step: 10
Training loss: 0.35080426931381226
Validation loss: 2.087060878674189

Epoch: 5| Step: 11
Training loss: 0.28012996912002563
Validation loss: 2.1886872053146362

Epoch: 337| Step: 0
Training loss: 0.4959161877632141
Validation loss: 2.1615750839312873

Epoch: 5| Step: 1
Training loss: 0.5319521427154541
Validation loss: 2.1576243489980698

Epoch: 5| Step: 2
Training loss: 0.333249568939209
Validation loss: 2.1339221000671387

Epoch: 5| Step: 3
Training loss: 0.2963921129703522
Validation loss: 2.210037405292193

Epoch: 5| Step: 4
Training loss: 0.24146361649036407
Validation loss: 2.2709549268086753

Epoch: 5| Step: 5
Training loss: 0.274138867855072
Validation loss: 2.1879305243492126

Epoch: 5| Step: 6
Training loss: 0.21899648010730743
Validation loss: 2.2230725636084876

Epoch: 5| Step: 7
Training loss: 0.36923888325691223
Validation loss: 2.1850116848945618

Epoch: 5| Step: 8
Training loss: 0.3929056227207184
Validation loss: 2.1177941213051477

Epoch: 5| Step: 9
Training loss: 0.6886413097381592
Validation loss: 2.1102940340836844

Epoch: 5| Step: 10
Training loss: 0.40687936544418335
Validation loss: 2.158868824442228

Epoch: 5| Step: 11
Training loss: 0.15102937817573547
Validation loss: 2.1405955900748572

Epoch: 338| Step: 0
Training loss: 0.41023358702659607
Validation loss: 2.1726351281007132

Epoch: 5| Step: 1
Training loss: 0.2425682544708252
Validation loss: 2.136828492085139

Epoch: 5| Step: 2
Training loss: 0.5939586758613586
Validation loss: 2.203594143191973

Epoch: 5| Step: 3
Training loss: 0.2288566380739212
Validation loss: 2.1656150420506797

Epoch: 5| Step: 4
Training loss: 0.36414292454719543
Validation loss: 2.1669195741415024

Epoch: 5| Step: 5
Training loss: 0.3833879828453064
Validation loss: 2.222598413626353

Epoch: 5| Step: 6
Training loss: 0.5272746682167053
Validation loss: 2.23172590136528

Epoch: 5| Step: 7
Training loss: 0.3386504650115967
Validation loss: 2.1871903439362845

Epoch: 5| Step: 8
Training loss: 0.3605497479438782
Validation loss: 2.2205627461274466

Epoch: 5| Step: 9
Training loss: 0.23587211966514587
Validation loss: 2.1601271629333496

Epoch: 5| Step: 10
Training loss: 0.36164143681526184
Validation loss: 2.1213198751211166

Epoch: 5| Step: 11
Training loss: 0.23891496658325195
Validation loss: 2.1516979982455573

Epoch: 339| Step: 0
Training loss: 0.4311237335205078
Validation loss: 2.1018767903248468

Epoch: 5| Step: 1
Training loss: 0.4109935164451599
Validation loss: 2.128265197078387

Epoch: 5| Step: 2
Training loss: 0.40143194794654846
Validation loss: 2.1026153365770974

Epoch: 5| Step: 3
Training loss: 0.2141406536102295
Validation loss: 2.150574485460917

Epoch: 5| Step: 4
Training loss: 0.5443530082702637
Validation loss: 2.1252897729476294

Epoch: 5| Step: 5
Training loss: 0.2516799569129944
Validation loss: 2.1335265040397644

Epoch: 5| Step: 6
Training loss: 0.37233152985572815
Validation loss: 2.181908925374349

Epoch: 5| Step: 7
Training loss: 0.3320446312427521
Validation loss: 2.17335898677508

Epoch: 5| Step: 8
Training loss: 0.5700680017471313
Validation loss: 2.1676772187153497

Epoch: 5| Step: 9
Training loss: 0.2577928602695465
Validation loss: 2.1402814090251923

Epoch: 5| Step: 10
Training loss: 0.1497059166431427
Validation loss: 2.163368528087934

Epoch: 5| Step: 11
Training loss: 0.27062374353408813
Validation loss: 2.1391070187091827

Epoch: 340| Step: 0
Training loss: 0.22006647288799286
Validation loss: 2.1633035192886987

Epoch: 5| Step: 1
Training loss: 0.5529751181602478
Validation loss: 2.0809427946805954

Epoch: 5| Step: 2
Training loss: 0.4049082398414612
Validation loss: 2.0874655842781067

Epoch: 5| Step: 3
Training loss: 0.23821201920509338
Validation loss: 2.089402904113134

Epoch: 5| Step: 4
Training loss: 0.38472211360931396
Validation loss: 2.1297211050987244

Epoch: 5| Step: 5
Training loss: 0.3110181987285614
Validation loss: 2.0874570657809577

Epoch: 5| Step: 6
Training loss: 0.625743567943573
Validation loss: 2.2119288245836892

Epoch: 5| Step: 7
Training loss: 0.3825080394744873
Validation loss: 2.1854167133569717

Epoch: 5| Step: 8
Training loss: 0.3886234760284424
Validation loss: 2.1267849107583365

Epoch: 5| Step: 9
Training loss: 0.31227803230285645
Validation loss: 2.219140579303106

Epoch: 5| Step: 10
Training loss: 0.35733383893966675
Validation loss: 2.191993325948715

Epoch: 5| Step: 11
Training loss: 0.11877846717834473
Validation loss: 2.135734220345815

Epoch: 341| Step: 0
Training loss: 0.25397953391075134
Validation loss: 2.1471876253684363

Epoch: 5| Step: 1
Training loss: 0.37239810824394226
Validation loss: 2.1479497651259103

Epoch: 5| Step: 2
Training loss: 0.300828218460083
Validation loss: 2.1213609079519906

Epoch: 5| Step: 3
Training loss: 0.37432175874710083
Validation loss: 2.1179769933223724

Epoch: 5| Step: 4
Training loss: 0.3917052745819092
Validation loss: 2.120271181066831

Epoch: 5| Step: 5
Training loss: 0.3610146641731262
Validation loss: 2.207704484462738

Epoch: 5| Step: 6
Training loss: 0.23926229774951935
Validation loss: 2.197858144839605

Epoch: 5| Step: 7
Training loss: 0.4306492805480957
Validation loss: 2.2213844309250512

Epoch: 5| Step: 8
Training loss: 0.6349490284919739
Validation loss: 2.1542848497629166

Epoch: 5| Step: 9
Training loss: 0.2458200752735138
Validation loss: 2.1237581819295883

Epoch: 5| Step: 10
Training loss: 0.3252308964729309
Validation loss: 2.1577798426151276

Epoch: 5| Step: 11
Training loss: 0.12979692220687866
Validation loss: 2.1747101644674935

Epoch: 342| Step: 0
Training loss: 0.3312188386917114
Validation loss: 2.1925518910090127

Epoch: 5| Step: 1
Training loss: 0.2823159694671631
Validation loss: 2.1707889487346015

Epoch: 5| Step: 2
Training loss: 0.5723081827163696
Validation loss: 2.185763567686081

Epoch: 5| Step: 3
Training loss: 0.25038087368011475
Validation loss: 2.1733702619870505

Epoch: 5| Step: 4
Training loss: 0.3106875717639923
Validation loss: 2.1517891635497413

Epoch: 5| Step: 5
Training loss: 0.2556445002555847
Validation loss: 2.163704107205073

Epoch: 5| Step: 6
Training loss: 0.2109728753566742
Validation loss: 2.165477911631266

Epoch: 5| Step: 7
Training loss: 0.4738686978816986
Validation loss: 2.181286742289861

Epoch: 5| Step: 8
Training loss: 0.21497711539268494
Validation loss: 2.1784441471099854

Epoch: 5| Step: 9
Training loss: 0.40985530614852905
Validation loss: 2.201239198446274

Epoch: 5| Step: 10
Training loss: 0.3181077539920807
Validation loss: 2.2027569115161896

Epoch: 5| Step: 11
Training loss: 0.3349330425262451
Validation loss: 2.1914234856764474

Epoch: 343| Step: 0
Training loss: 0.3074573278427124
Validation loss: 2.220397169391314

Epoch: 5| Step: 1
Training loss: 0.30126795172691345
Validation loss: 2.219861110051473

Epoch: 5| Step: 2
Training loss: 0.2166070193052292
Validation loss: 2.236500988403956

Epoch: 5| Step: 3
Training loss: 0.31572845578193665
Validation loss: 2.1779030362764993

Epoch: 5| Step: 4
Training loss: 0.27913302183151245
Validation loss: 2.182623565196991

Epoch: 5| Step: 5
Training loss: 0.25052276253700256
Validation loss: 2.136991168061892

Epoch: 5| Step: 6
Training loss: 0.2451435625553131
Validation loss: 2.1610008080800376

Epoch: 5| Step: 7
Training loss: 0.2915826439857483
Validation loss: 2.128903259833654

Epoch: 5| Step: 8
Training loss: 0.37199607491493225
Validation loss: 2.135227253039678

Epoch: 5| Step: 9
Training loss: 0.3097427189350128
Validation loss: 2.1426007449626923

Epoch: 5| Step: 10
Training loss: 0.9420011639595032
Validation loss: 2.058120315273603

Epoch: 5| Step: 11
Training loss: 0.8626009225845337
Validation loss: 2.1917228400707245

Epoch: 344| Step: 0
Training loss: 0.1959492713212967
Validation loss: 2.168930937846502

Epoch: 5| Step: 1
Training loss: 0.39601072669029236
Validation loss: 2.186690390110016

Epoch: 5| Step: 2
Training loss: 0.25424307584762573
Validation loss: 2.1498780101537704

Epoch: 5| Step: 3
Training loss: 0.32144445180892944
Validation loss: 2.1819328467051187

Epoch: 5| Step: 4
Training loss: 0.2052311897277832
Validation loss: 2.1490092178185782

Epoch: 5| Step: 5
Training loss: 0.2848135828971863
Validation loss: 2.159875303506851

Epoch: 5| Step: 6
Training loss: 0.33276066184043884
Validation loss: 2.121799558401108

Epoch: 5| Step: 7
Training loss: 0.5569098591804504
Validation loss: 2.09316423535347

Epoch: 5| Step: 8
Training loss: 0.5209513902664185
Validation loss: 2.1036501626173654

Epoch: 5| Step: 9
Training loss: 0.35530126094818115
Validation loss: 2.1309583485126495

Epoch: 5| Step: 10
Training loss: 0.5384736061096191
Validation loss: 2.164759556452433

Epoch: 5| Step: 11
Training loss: 0.3725976347923279
Validation loss: 2.1816623359918594

Epoch: 345| Step: 0
Training loss: 0.35014235973358154
Validation loss: 2.182245746254921

Epoch: 5| Step: 1
Training loss: 0.3814101219177246
Validation loss: 2.175629436969757

Epoch: 5| Step: 2
Training loss: 0.2439928948879242
Validation loss: 2.1212562123934426

Epoch: 5| Step: 3
Training loss: 0.40453410148620605
Validation loss: 2.1174090007940927

Epoch: 5| Step: 4
Training loss: 0.20101532340049744
Validation loss: 2.0967376828193665

Epoch: 5| Step: 5
Training loss: 0.2573109269142151
Validation loss: 2.1524124244848886

Epoch: 5| Step: 6
Training loss: 0.5282598733901978
Validation loss: 2.150649845600128

Epoch: 5| Step: 7
Training loss: 0.18860551714897156
Validation loss: 2.102924798925718

Epoch: 5| Step: 8
Training loss: 0.32519349455833435
Validation loss: 2.111154784758886

Epoch: 5| Step: 9
Training loss: 0.47886571288108826
Validation loss: 2.1238801976044974

Epoch: 5| Step: 10
Training loss: 0.3435962200164795
Validation loss: 2.1455061584711075

Epoch: 5| Step: 11
Training loss: 0.09527397155761719
Validation loss: 2.211209312081337

Epoch: 346| Step: 0
Training loss: 0.5094763040542603
Validation loss: 2.1393958777189255

Epoch: 5| Step: 1
Training loss: 0.29943642020225525
Validation loss: 2.172330061594645

Epoch: 5| Step: 2
Training loss: 0.32914647459983826
Validation loss: 2.2017686615387597

Epoch: 5| Step: 3
Training loss: 0.30969834327697754
Validation loss: 2.1774758249521255

Epoch: 5| Step: 4
Training loss: 0.2167457640171051
Validation loss: 2.198551336924235

Epoch: 5| Step: 5
Training loss: 0.6479098796844482
Validation loss: 2.151157865921656

Epoch: 5| Step: 6
Training loss: 0.27159181237220764
Validation loss: 2.14963964621226

Epoch: 5| Step: 7
Training loss: 0.2951030433177948
Validation loss: 2.147307018438975

Epoch: 5| Step: 8
Training loss: 0.19281263649463654
Validation loss: 2.1741351932287216

Epoch: 5| Step: 9
Training loss: 0.3446144759654999
Validation loss: 2.15142231186231

Epoch: 5| Step: 10
Training loss: 0.259966641664505
Validation loss: 2.116725961367289

Epoch: 5| Step: 11
Training loss: 0.3892933130264282
Validation loss: 2.1261878858009973

Epoch: 347| Step: 0
Training loss: 0.2855493724346161
Validation loss: 2.159845381975174

Epoch: 5| Step: 1
Training loss: 0.3611432909965515
Validation loss: 2.163911283016205

Epoch: 5| Step: 2
Training loss: 0.3548036515712738
Validation loss: 2.218337739507357

Epoch: 5| Step: 3
Training loss: 0.2924017906188965
Validation loss: 2.182083194454511

Epoch: 5| Step: 4
Training loss: 0.27535170316696167
Validation loss: 2.1849089761575065

Epoch: 5| Step: 5
Training loss: 0.3745831847190857
Validation loss: 2.1815618773301444

Epoch: 5| Step: 6
Training loss: 0.2788666784763336
Validation loss: 2.204044987758001

Epoch: 5| Step: 7
Training loss: 0.608171820640564
Validation loss: 2.099324345588684

Epoch: 5| Step: 8
Training loss: 0.5065630078315735
Validation loss: 2.116028979420662

Epoch: 5| Step: 9
Training loss: 0.5014209151268005
Validation loss: 2.115045780936877

Epoch: 5| Step: 10
Training loss: 0.3496805727481842
Validation loss: 2.0866060157616935

Epoch: 5| Step: 11
Training loss: 0.21564757823944092
Validation loss: 2.111348142226537

Epoch: 348| Step: 0
Training loss: 0.2069563865661621
Validation loss: 2.1553116043408713

Epoch: 5| Step: 1
Training loss: 0.32591524720191956
Validation loss: 2.1866281032562256

Epoch: 5| Step: 2
Training loss: 0.36682429909706116
Validation loss: 2.133220672607422

Epoch: 5| Step: 3
Training loss: 0.3618963956832886
Validation loss: 2.164386530717214

Epoch: 5| Step: 4
Training loss: 0.23967070877552032
Validation loss: 2.176191290219625

Epoch: 5| Step: 5
Training loss: 0.2933560013771057
Validation loss: 2.099426915248235

Epoch: 5| Step: 6
Training loss: 0.464177668094635
Validation loss: 2.158332943916321

Epoch: 5| Step: 7
Training loss: 0.22424378991127014
Validation loss: 2.1428934931755066

Epoch: 5| Step: 8
Training loss: 0.33549726009368896
Validation loss: 2.1536237746477127

Epoch: 5| Step: 9
Training loss: 0.3134382963180542
Validation loss: 2.095513939857483

Epoch: 5| Step: 10
Training loss: 0.6060068011283875
Validation loss: 2.1289816399415336

Epoch: 5| Step: 11
Training loss: 0.10186472535133362
Validation loss: 2.14913476506869

Epoch: 349| Step: 0
Training loss: 0.3793884813785553
Validation loss: 2.1123954753081002

Epoch: 5| Step: 1
Training loss: 0.21814242005348206
Validation loss: 2.1195127119620643

Epoch: 5| Step: 2
Training loss: 0.32502317428588867
Validation loss: 2.0978748251994452

Epoch: 5| Step: 3
Training loss: 0.2357569932937622
Validation loss: 2.154287983973821

Epoch: 5| Step: 4
Training loss: 0.229209303855896
Validation loss: 2.0889068444569907

Epoch: 5| Step: 5
Training loss: 0.41126638650894165
Validation loss: 2.1593074202537537

Epoch: 5| Step: 6
Training loss: 0.2943781912326813
Validation loss: 2.1579927504062653

Epoch: 5| Step: 7
Training loss: 0.25446805357933044
Validation loss: 2.1831796864668527

Epoch: 5| Step: 8
Training loss: 0.42776042222976685
Validation loss: 2.1541179915269217

Epoch: 5| Step: 9
Training loss: 0.37739336490631104
Validation loss: 2.184978966911634

Epoch: 5| Step: 10
Training loss: 0.7127517461776733
Validation loss: 2.110991751154264

Epoch: 5| Step: 11
Training loss: 0.27470922470092773
Validation loss: 2.16775514682134

Epoch: 350| Step: 0
Training loss: 0.32499563694000244
Validation loss: 2.13157985607783

Epoch: 5| Step: 1
Training loss: 0.3249281942844391
Validation loss: 2.155142620205879

Epoch: 5| Step: 2
Training loss: 0.19986280798912048
Validation loss: 2.184994305173556

Epoch: 5| Step: 3
Training loss: 0.25047963857650757
Validation loss: 2.1658429702123008

Epoch: 5| Step: 4
Training loss: 0.8176736831665039
Validation loss: 2.1284647583961487

Epoch: 5| Step: 5
Training loss: 0.20175671577453613
Validation loss: 2.1604228615760803

Epoch: 5| Step: 6
Training loss: 0.32066237926483154
Validation loss: 2.1652057667573295

Epoch: 5| Step: 7
Training loss: 0.17859673500061035
Validation loss: 2.11516206463178

Epoch: 5| Step: 8
Training loss: 0.14990414679050446
Validation loss: 2.1086548417806625

Epoch: 5| Step: 9
Training loss: 0.4397687017917633
Validation loss: 2.1093135277430215

Epoch: 5| Step: 10
Training loss: 0.31276556849479675
Validation loss: 2.190032958984375

Epoch: 5| Step: 11
Training loss: 0.27462005615234375
Validation loss: 2.112680529554685

Testing loss: 1.9308144531661657
